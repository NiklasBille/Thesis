>>> Starting run for dataset: tox21
Running RANDOM configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.8_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.8
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6926200
[Epoch 1; Iter    60/  209] train: loss: 0.6936488
[Epoch 1; Iter    90/  209] train: loss: 0.6932487
[Epoch 1; Iter   120/  209] train: loss: 0.6922450
[Epoch 1; Iter   150/  209] train: loss: 0.6930720
[Epoch 1; Iter   180/  209] train: loss: 0.6921930
[Epoch 1] ogbg-moltox21: 0.478590 val loss: 0.692568
[Epoch 1] ogbg-moltox21: 0.496060 test loss: 0.692505
[Epoch 2; Iter     1/  209] train: loss: 0.6928928
[Epoch 2; Iter    31/  209] train: loss: 0.6940140
[Epoch 2; Iter    61/  209] train: loss: 0.6927888
[Epoch 2; Iter    91/  209] train: loss: 0.6920293
[Epoch 2; Iter   121/  209] train: loss: 0.6915825
[Epoch 2; Iter   151/  209] train: loss: 0.6920767
[Epoch 2; Iter   181/  209] train: loss: 0.6901033
[Epoch 2] ogbg-moltox21: 0.487623 val loss: 0.690958
[Epoch 2] ogbg-moltox21: 0.504393 test loss: 0.690853
[Epoch 3; Iter     2/  209] train: loss: 0.6911004
[Epoch 3; Iter    32/  209] train: loss: 0.6909177
[Epoch 3; Iter    62/  209] train: loss: 0.6908168
[Epoch 3; Iter    92/  209] train: loss: 0.6896442
[Epoch 3; Iter   122/  209] train: loss: 0.6901345
[Epoch 3; Iter   152/  209] train: loss: 0.6887928
[Epoch 3; Iter   182/  209] train: loss: 0.6887454
[Epoch 3] ogbg-moltox21: 0.489989 val loss: 0.688600
[Epoch 3] ogbg-moltox21: 0.503725 test loss: 0.688524
[Epoch 4; Iter     3/  209] train: loss: 0.6882349
[Epoch 4; Iter    33/  209] train: loss: 0.6883415
[Epoch 4; Iter    63/  209] train: loss: 0.6883867
[Epoch 4; Iter    93/  209] train: loss: 0.6813798
[Epoch 4; Iter   123/  209] train: loss: 0.6572197
[Epoch 4; Iter   153/  209] train: loss: 0.6359064
[Epoch 4; Iter   183/  209] train: loss: 0.5798198
[Epoch 4] ogbg-moltox21: 0.732563 val loss: 0.534707
[Epoch 4] ogbg-moltox21: 0.742231 test loss: 0.525603
[Epoch 5; Iter     4/  209] train: loss: 0.5418898
[Epoch 5; Iter    34/  209] train: loss: 0.5091389
[Epoch 5; Iter    64/  209] train: loss: 0.4540013
[Epoch 5; Iter    94/  209] train: loss: 0.3778825
[Epoch 5; Iter   124/  209] train: loss: 0.3285412
[Epoch 5; Iter   154/  209] train: loss: 0.3682517
[Epoch 5; Iter   184/  209] train: loss: 0.2677961
[Epoch 5] ogbg-moltox21: 0.789488 val loss: 0.271882
[Epoch 5] ogbg-moltox21: 0.775155 test loss: 0.273125
[Epoch 6; Iter     5/  209] train: loss: 0.2698499
[Epoch 6; Iter    35/  209] train: loss: 0.2806343
[Epoch 6; Iter    65/  209] train: loss: 0.2525009
[Epoch 6; Iter    95/  209] train: loss: 0.1464337
[Epoch 6; Iter   125/  209] train: loss: 0.2455048
[Epoch 6; Iter   155/  209] train: loss: 0.2479490
[Epoch 6; Iter   185/  209] train: loss: 0.2599008
[Epoch 6] ogbg-moltox21: 0.781522 val loss: 0.246943
[Epoch 6] ogbg-moltox21: 0.776979 test loss: 0.229637
[Epoch 7; Iter     6/  209] train: loss: 0.2921394
[Epoch 7; Iter    36/  209] train: loss: 0.2308134
[Epoch 7; Iter    66/  209] train: loss: 0.2000908
[Epoch 7; Iter    96/  209] train: loss: 0.1659271
[Epoch 7; Iter   126/  209] train: loss: 0.1677793
[Epoch 7; Iter   156/  209] train: loss: 0.1816161
[Epoch 7; Iter   186/  209] train: loss: 0.1979400
[Epoch 7] ogbg-moltox21: 0.738979 val loss: 0.280868
[Epoch 7] ogbg-moltox21: 0.707302 test loss: 0.287115
[Epoch 8; Iter     7/  209] train: loss: 0.1758583
[Epoch 8; Iter    37/  209] train: loss: 0.2830332
[Epoch 8; Iter    67/  209] train: loss: 0.2489197
[Epoch 8; Iter    97/  209] train: loss: 0.2238272
[Epoch 8; Iter   127/  209] train: loss: 0.1691210
[Epoch 8; Iter   157/  209] train: loss: 0.3093947
[Epoch 8; Iter   187/  209] train: loss: 0.2594748
[Epoch 8] ogbg-moltox21: 0.787130 val loss: 0.234785
[Epoch 8] ogbg-moltox21: 0.769393 test loss: 0.218782
[Epoch 9; Iter     8/  209] train: loss: 0.3144450
[Epoch 9; Iter    38/  209] train: loss: 0.2218336
[Epoch 9; Iter    68/  209] train: loss: 0.2091680
[Epoch 9; Iter    98/  209] train: loss: 0.2798361
[Epoch 9; Iter   128/  209] train: loss: 0.1920706
[Epoch 9; Iter   158/  209] train: loss: 0.2038042
[Epoch 9; Iter   188/  209] train: loss: 0.1322470
[Epoch 9] ogbg-moltox21: 0.815709 val loss: 0.224231
[Epoch 9] ogbg-moltox21: 0.804911 test loss: 0.211240
[Epoch 10; Iter     9/  209] train: loss: 0.1410084
[Epoch 10; Iter    39/  209] train: loss: 0.2210974
[Epoch 10; Iter    69/  209] train: loss: 0.2418734
[Epoch 10; Iter    99/  209] train: loss: 0.1450300
[Epoch 10; Iter   129/  209] train: loss: 0.2118867
[Epoch 10; Iter   159/  209] train: loss: 0.1539070
[Epoch 10; Iter   189/  209] train: loss: 0.2417557
[Epoch 10] ogbg-moltox21: 0.810780 val loss: 0.228196
[Epoch 10] ogbg-moltox21: 0.786285 test loss: 0.223623
[Epoch 11; Iter    10/  209] train: loss: 0.2250613
[Epoch 11; Iter    40/  209] train: loss: 0.2072911
[Epoch 11; Iter    70/  209] train: loss: 0.1604513
[Epoch 11; Iter   100/  209] train: loss: 0.2178864
[Epoch 11; Iter   130/  209] train: loss: 0.1850361
[Epoch 11; Iter   160/  209] train: loss: 0.2607138
[Epoch 11; Iter   190/  209] train: loss: 0.2459908
[Epoch 11] ogbg-moltox21: 0.826763 val loss: 0.217557
[Epoch 11] ogbg-moltox21: 0.801960 test loss: 0.213077
[Epoch 12; Iter    11/  209] train: loss: 0.2497801
[Epoch 12; Iter    41/  209] train: loss: 0.2468722
[Epoch 12; Iter    71/  209] train: loss: 0.2667031
[Epoch 12; Iter   101/  209] train: loss: 0.1605056
[Epoch 12; Iter   131/  209] train: loss: 0.1537392
[Epoch 12; Iter   161/  209] train: loss: 0.1503142
[Epoch 12; Iter   191/  209] train: loss: 0.1125756
[Epoch 12] ogbg-moltox21: 0.823364 val loss: 0.227051
[Epoch 12] ogbg-moltox21: 0.808368 test loss: 0.211289
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.8_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.8
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930545
[Epoch 1; Iter    60/  209] train: loss: 0.6927426
[Epoch 1; Iter    90/  209] train: loss: 0.6933177
[Epoch 1; Iter   120/  209] train: loss: 0.6930205
[Epoch 1; Iter   150/  209] train: loss: 0.6928617
[Epoch 1; Iter   180/  209] train: loss: 0.6920912
[Epoch 1] ogbg-moltox21: 0.498492 val loss: 0.692646
[Epoch 1] ogbg-moltox21: 0.532150 test loss: 0.692206
[Epoch 2; Iter     1/  209] train: loss: 0.6926138
[Epoch 2; Iter    31/  209] train: loss: 0.6919574
[Epoch 2; Iter    61/  209] train: loss: 0.6917357
[Epoch 2; Iter    91/  209] train: loss: 0.6918562
[Epoch 2; Iter   121/  209] train: loss: 0.6913405
[Epoch 2; Iter   151/  209] train: loss: 0.6904975
[Epoch 2; Iter   181/  209] train: loss: 0.6908779
[Epoch 2] ogbg-moltox21: 0.507993 val loss: 0.691321
[Epoch 2] ogbg-moltox21: 0.541827 test loss: 0.690857
[Epoch 3; Iter     2/  209] train: loss: 0.6901032
[Epoch 3; Iter    32/  209] train: loss: 0.6915232
[Epoch 3; Iter    62/  209] train: loss: 0.6898238
[Epoch 3; Iter    92/  209] train: loss: 0.6894398
[Epoch 3; Iter   122/  209] train: loss: 0.6891999
[Epoch 3; Iter   152/  209] train: loss: 0.6887224
[Epoch 3; Iter   182/  209] train: loss: 0.6882706
[Epoch 3] ogbg-moltox21: 0.517341 val loss: 0.687975
[Epoch 3] ogbg-moltox21: 0.549931 test loss: 0.687466
[Epoch 4; Iter     3/  209] train: loss: 0.6881671
[Epoch 4; Iter    33/  209] train: loss: 0.6877576
[Epoch 4; Iter    63/  209] train: loss: 0.6860034
[Epoch 4; Iter    93/  209] train: loss: 0.6817762
[Epoch 4; Iter   123/  209] train: loss: 0.6639949
[Epoch 4; Iter   153/  209] train: loss: 0.6191741
[Epoch 4; Iter   183/  209] train: loss: 0.5868784
[Epoch 4] ogbg-moltox21: 0.724844 val loss: 0.550776
[Epoch 4] ogbg-moltox21: 0.736809 test loss: 0.540608
[Epoch 5; Iter     4/  209] train: loss: 0.5332555
[Epoch 5; Iter    34/  209] train: loss: 0.4714449
[Epoch 5; Iter    64/  209] train: loss: 0.4341944
[Epoch 5; Iter    94/  209] train: loss: 0.3882440
[Epoch 5; Iter   124/  209] train: loss: 0.3206372
[Epoch 5; Iter   154/  209] train: loss: 0.3018104
[Epoch 5; Iter   184/  209] train: loss: 0.2665864
[Epoch 5] ogbg-moltox21: 0.770364 val loss: 0.276265
[Epoch 5] ogbg-moltox21: 0.767535 test loss: 0.261855
[Epoch 6; Iter     5/  209] train: loss: 0.1999731
[Epoch 6; Iter    35/  209] train: loss: 0.2614659
[Epoch 6; Iter    65/  209] train: loss: 0.3066398
[Epoch 6; Iter    95/  209] train: loss: 0.3024730
[Epoch 6; Iter   125/  209] train: loss: 0.2025074
[Epoch 6; Iter   155/  209] train: loss: 0.1544072
[Epoch 6; Iter   185/  209] train: loss: 0.2211776
[Epoch 6] ogbg-moltox21: 0.763186 val loss: 0.243963
[Epoch 6] ogbg-moltox21: 0.743654 test loss: 0.232447
[Epoch 7; Iter     6/  209] train: loss: 0.1519284
[Epoch 7; Iter    36/  209] train: loss: 0.1673438
[Epoch 7; Iter    66/  209] train: loss: 0.1823647
[Epoch 7; Iter    96/  209] train: loss: 0.1792577
[Epoch 7; Iter   126/  209] train: loss: 0.1159658
[Epoch 7; Iter   156/  209] train: loss: 0.1591517
[Epoch 7; Iter   186/  209] train: loss: 0.1844385
[Epoch 7] ogbg-moltox21: 0.448860 val loss: 0.390208
[Epoch 7] ogbg-moltox21: 0.474859 test loss: 0.387545
[Epoch 8; Iter     7/  209] train: loss: 0.3135372
[Epoch 8; Iter    37/  209] train: loss: 0.1981939
[Epoch 8; Iter    67/  209] train: loss: 0.1070189
[Epoch 8; Iter    97/  209] train: loss: 0.2573648
[Epoch 8; Iter   127/  209] train: loss: 0.2566804
[Epoch 8; Iter   157/  209] train: loss: 0.3104675
[Epoch 8; Iter   187/  209] train: loss: 0.1480376
[Epoch 8] ogbg-moltox21: 0.785940 val loss: 0.260748
[Epoch 8] ogbg-moltox21: 0.782426 test loss: 0.239466
[Epoch 9; Iter     8/  209] train: loss: 0.2514525
[Epoch 9; Iter    38/  209] train: loss: 0.1808196
[Epoch 9; Iter    68/  209] train: loss: 0.2760801
[Epoch 9; Iter    98/  209] train: loss: 0.2275112
[Epoch 9; Iter   128/  209] train: loss: 0.1791540
[Epoch 9; Iter   158/  209] train: loss: 0.3715881
[Epoch 9; Iter   188/  209] train: loss: 0.2053427
[Epoch 9] ogbg-moltox21: 0.826576 val loss: 0.228484
[Epoch 9] ogbg-moltox21: 0.784851 test loss: 0.221947
[Epoch 10; Iter     9/  209] train: loss: 0.2077251
[Epoch 10; Iter    39/  209] train: loss: 0.1792771
[Epoch 10; Iter    69/  209] train: loss: 0.2605836
[Epoch 10; Iter    99/  209] train: loss: 0.2489357
[Epoch 10; Iter   129/  209] train: loss: 0.2978056
[Epoch 10; Iter   159/  209] train: loss: 0.2552454
[Epoch 10; Iter   189/  209] train: loss: 0.2826774
[Epoch 10] ogbg-moltox21: 0.818363 val loss: 0.220808
[Epoch 10] ogbg-moltox21: 0.791134 test loss: 0.215929
[Epoch 11; Iter    10/  209] train: loss: 0.3441120
[Epoch 11; Iter    40/  209] train: loss: 0.1760148
[Epoch 11; Iter    70/  209] train: loss: 0.2099913
[Epoch 11; Iter   100/  209] train: loss: 0.2377663
[Epoch 11; Iter   130/  209] train: loss: 0.2828390
[Epoch 11; Iter   160/  209] train: loss: 0.2504016
[Epoch 11; Iter   190/  209] train: loss: 0.1735165
[Epoch 11] ogbg-moltox21: 0.822229 val loss: 0.226467
[Epoch 11] ogbg-moltox21: 0.813118 test loss: 0.214902
[Epoch 12; Iter    11/  209] train: loss: 0.2064479
[Epoch 12; Iter    41/  209] train: loss: 0.2013724
[Epoch 12; Iter    71/  209] train: loss: 0.1668283
[Epoch 12; Iter   101/  209] train: loss: 0.1204606
[Epoch 12; Iter   131/  209] train: loss: 0.3050328
[Epoch 12; Iter   161/  209] train: loss: 0.1482698
[Epoch 12; Iter   191/  209] train: loss: 0.2761511
[Epoch 12] ogbg-moltox21: 0.821898 val loss: 0.215132
[Epoch 12] ogbg-moltox21: 0.805698 test loss: 0.208935
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.8_4_26-05_09-18-11
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.8
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935001
[Epoch 1; Iter    60/  209] train: loss: 0.6928067
[Epoch 1; Iter    90/  209] train: loss: 0.6947011
[Epoch 1; Iter   120/  209] train: loss: 0.6927704
[Epoch 1; Iter   150/  209] train: loss: 0.6928442
[Epoch 1; Iter   180/  209] train: loss: 0.6923425
[Epoch 1] ogbg-moltox21: 0.507187 val loss: 0.692968
[Epoch 1] ogbg-moltox21: 0.512303 test loss: 0.692852
[Epoch 2; Iter     1/  209] train: loss: 0.6929141
[Epoch 2; Iter    31/  209] train: loss: 0.6925403
[Epoch 2; Iter    61/  209] train: loss: 0.6927730
[Epoch 2; Iter    91/  209] train: loss: 0.6925112
[Epoch 2; Iter   121/  209] train: loss: 0.6921007
[Epoch 2; Iter   151/  209] train: loss: 0.6916003
[Epoch 2; Iter   181/  209] train: loss: 0.6906294
[Epoch 2] ogbg-moltox21: 0.508856 val loss: 0.691271
[Epoch 2] ogbg-moltox21: 0.512550 test loss: 0.691159
[Epoch 3; Iter     2/  209] train: loss: 0.6919706
[Epoch 3; Iter    32/  209] train: loss: 0.6909268
[Epoch 3; Iter    62/  209] train: loss: 0.6910455
[Epoch 3; Iter    92/  209] train: loss: 0.6891565
[Epoch 3; Iter   122/  209] train: loss: 0.6899339
[Epoch 3; Iter   152/  209] train: loss: 0.6891387
[Epoch 3; Iter   182/  209] train: loss: 0.6890609
[Epoch 3] ogbg-moltox21: 0.514202 val loss: 0.688585
[Epoch 3] ogbg-moltox21: 0.516257 test loss: 0.688450
[Epoch 4; Iter     3/  209] train: loss: 0.6882831
[Epoch 4; Iter    33/  209] train: loss: 0.6882718
[Epoch 4; Iter    63/  209] train: loss: 0.6869917
[Epoch 4; Iter    93/  209] train: loss: 0.6813427
[Epoch 4; Iter   123/  209] train: loss: 0.6571084
[Epoch 4; Iter   153/  209] train: loss: 0.6291652
[Epoch 4; Iter   183/  209] train: loss: 0.5854144
[Epoch 4] ogbg-moltox21: 0.712962 val loss: 0.536179
[Epoch 4] ogbg-moltox21: 0.724346 test loss: 0.529087
[Epoch 5; Iter     4/  209] train: loss: 0.5310947
[Epoch 5; Iter    34/  209] train: loss: 0.4856203
[Epoch 5; Iter    64/  209] train: loss: 0.4568367
[Epoch 5; Iter    94/  209] train: loss: 0.3704848
[Epoch 5; Iter   124/  209] train: loss: 0.3417915
[Epoch 5; Iter   154/  209] train: loss: 0.2643940
[Epoch 5; Iter   184/  209] train: loss: 0.2577721
[Epoch 5] ogbg-moltox21: 0.759275 val loss: 0.278656
[Epoch 5] ogbg-moltox21: 0.749376 test loss: 0.267764
[Epoch 6; Iter     5/  209] train: loss: 0.3199968
[Epoch 6; Iter    35/  209] train: loss: 0.2505472
[Epoch 6; Iter    65/  209] train: loss: 0.1858380
[Epoch 6; Iter    95/  209] train: loss: 0.1686497
[Epoch 6; Iter   125/  209] train: loss: 0.2030084
[Epoch 6; Iter   155/  209] train: loss: 0.2225686
[Epoch 6; Iter   185/  209] train: loss: 0.1922979
[Epoch 6] ogbg-moltox21: 0.760164 val loss: 0.246421
[Epoch 6] ogbg-moltox21: 0.728253 test loss: 0.237327
[Epoch 7; Iter     6/  209] train: loss: 0.3830803
[Epoch 7; Iter    36/  209] train: loss: 0.3187453
[Epoch 7; Iter    66/  209] train: loss: 0.2831073
[Epoch 7; Iter    96/  209] train: loss: 0.1893959
[Epoch 7; Iter   126/  209] train: loss: 0.2101632
[Epoch 7; Iter   156/  209] train: loss: 0.1861296
[Epoch 7; Iter   186/  209] train: loss: 0.1783032
[Epoch 7] ogbg-moltox21: 0.767939 val loss: 0.246159
[Epoch 7] ogbg-moltox21: 0.741778 test loss: 0.241879
[Epoch 8; Iter     7/  209] train: loss: 0.1938352
[Epoch 8; Iter    37/  209] train: loss: 0.2310443
[Epoch 8; Iter    67/  209] train: loss: 0.2527579
[Epoch 8; Iter    97/  209] train: loss: 0.1728260
[Epoch 8; Iter   127/  209] train: loss: 0.1925546
[Epoch 8; Iter   157/  209] train: loss: 0.1891106
[Epoch 8; Iter   187/  209] train: loss: 0.2125438
[Epoch 8] ogbg-moltox21: 0.814729 val loss: 0.227949
[Epoch 8] ogbg-moltox21: 0.793181 test loss: 0.221952
[Epoch 9; Iter     8/  209] train: loss: 0.1884061
[Epoch 9; Iter    38/  209] train: loss: 0.1130255
[Epoch 9; Iter    68/  209] train: loss: 0.2510008
[Epoch 9; Iter    98/  209] train: loss: 0.1667737
[Epoch 9; Iter   128/  209] train: loss: 0.1958024
[Epoch 9; Iter   158/  209] train: loss: 0.1542771
[Epoch 9; Iter   188/  209] train: loss: 0.1787182
[Epoch 9] ogbg-moltox21: 0.812080 val loss: 0.219739
[Epoch 9] ogbg-moltox21: 0.782379 test loss: 0.216424
[Epoch 10; Iter     9/  209] train: loss: 0.2139089
[Epoch 10; Iter    39/  209] train: loss: 0.2609611
[Epoch 10; Iter    69/  209] train: loss: 0.2428734
[Epoch 10; Iter    99/  209] train: loss: 0.2677214
[Epoch 10; Iter   129/  209] train: loss: 0.2764988
[Epoch 10; Iter   159/  209] train: loss: 0.1649782
[Epoch 10; Iter   189/  209] train: loss: 0.1943635
[Epoch 10] ogbg-moltox21: 0.826250 val loss: 0.217208
[Epoch 10] ogbg-moltox21: 0.798344 test loss: 0.215986
[Epoch 11; Iter    10/  209] train: loss: 0.1999234
[Epoch 11; Iter    40/  209] train: loss: 0.2644763
[Epoch 11; Iter    70/  209] train: loss: 0.2078992
[Epoch 11; Iter   100/  209] train: loss: 0.1682115
[Epoch 11; Iter   130/  209] train: loss: 0.2266343
[Epoch 11; Iter   160/  209] train: loss: 0.1778491
[Epoch 11; Iter   190/  209] train: loss: 0.2280377
[Epoch 11] ogbg-moltox21: 0.834864 val loss: 0.221606
[Epoch 11] ogbg-moltox21: 0.816319 test loss: 0.214632
[Epoch 12; Iter    11/  209] train: loss: 0.2205438
[Epoch 12; Iter    41/  209] train: loss: 0.2387924
[Epoch 12; Iter    71/  209] train: loss: 0.1637301
[Epoch 12; Iter   101/  209] train: loss: 0.1729431
[Epoch 12; Iter   131/  209] train: loss: 0.2017550
[Epoch 12; Iter   161/  209] train: loss: 0.1561505
[Epoch 12; Iter   191/  209] train: loss: 0.1312098
[Epoch 12] ogbg-moltox21: 0.846168 val loss: 0.210210
[Epoch 12] ogbg-moltox21: 0.821185 test loss: 0.202816
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.7_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.7
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6932403
[Epoch 1; Iter    60/  183] train: loss: 0.6926853
[Epoch 1; Iter    90/  183] train: loss: 0.6934465
[Epoch 1; Iter   120/  183] train: loss: 0.6926587
[Epoch 1; Iter   150/  183] train: loss: 0.6925283
[Epoch 1; Iter   180/  183] train: loss: 0.6928655
[Epoch 1] ogbg-moltox21: 0.489397 val loss: 0.692528
[Epoch 1] ogbg-moltox21: 0.509229 test loss: 0.692287
[Epoch 2; Iter    27/  183] train: loss: 0.6918658
[Epoch 2; Iter    57/  183] train: loss: 0.6922518
[Epoch 2; Iter    87/  183] train: loss: 0.6922068
[Epoch 2; Iter   117/  183] train: loss: 0.6927596
[Epoch 2; Iter   147/  183] train: loss: 0.6921056
[Epoch 2; Iter   177/  183] train: loss: 0.6912860
[Epoch 2] ogbg-moltox21: 0.501253 val loss: 0.691335
[Epoch 2] ogbg-moltox21: 0.520629 test loss: 0.691127
[Epoch 3; Iter    24/  183] train: loss: 0.6905935
[Epoch 3; Iter    54/  183] train: loss: 0.6909587
[Epoch 3; Iter    84/  183] train: loss: 0.6900733
[Epoch 3; Iter   114/  183] train: loss: 0.6897506
[Epoch 3; Iter   144/  183] train: loss: 0.6895885
[Epoch 3; Iter   174/  183] train: loss: 0.6892633
[Epoch 3] ogbg-moltox21: 0.509668 val loss: 0.689277
[Epoch 3] ogbg-moltox21: 0.528659 test loss: 0.689094
[Epoch 4; Iter    21/  183] train: loss: 0.6889381
[Epoch 4; Iter    51/  183] train: loss: 0.6892080
[Epoch 4; Iter    81/  183] train: loss: 0.6872678
[Epoch 4; Iter   111/  183] train: loss: 0.6875734
[Epoch 4; Iter   141/  183] train: loss: 0.6867181
[Epoch 4; Iter   171/  183] train: loss: 0.6818092
[Epoch 4] ogbg-moltox21: 0.675919 val loss: 0.678853
[Epoch 4] ogbg-moltox21: 0.695590 test loss: 0.678319
[Epoch 5; Iter    18/  183] train: loss: 0.6591620
[Epoch 5; Iter    48/  183] train: loss: 0.6208524
[Epoch 5; Iter    78/  183] train: loss: 0.5770919
[Epoch 5; Iter   108/  183] train: loss: 0.5239756
[Epoch 5; Iter   138/  183] train: loss: 0.4831619
[Epoch 5; Iter   168/  183] train: loss: 0.4263856
[Epoch 5] ogbg-moltox21: 0.717846 val loss: 0.413996
[Epoch 5] ogbg-moltox21: 0.753811 test loss: 0.411914
[Epoch 6; Iter    15/  183] train: loss: 0.3680045
[Epoch 6; Iter    45/  183] train: loss: 0.3076212
[Epoch 6; Iter    75/  183] train: loss: 0.2868524
[Epoch 6; Iter   105/  183] train: loss: 0.2930718
[Epoch 6; Iter   135/  183] train: loss: 0.2555877
[Epoch 6; Iter   165/  183] train: loss: 0.3188592
[Epoch 6] ogbg-moltox21: 0.738233 val loss: 0.267117
[Epoch 6] ogbg-moltox21: 0.784846 test loss: 0.245525
[Epoch 7; Iter    12/  183] train: loss: 0.2797989
[Epoch 7; Iter    42/  183] train: loss: 0.1774209
[Epoch 7; Iter    72/  183] train: loss: 0.2279061
[Epoch 7; Iter   102/  183] train: loss: 0.1503803
[Epoch 7; Iter   132/  183] train: loss: 0.2573078
[Epoch 7; Iter   162/  183] train: loss: 0.2885690
[Epoch 7] ogbg-moltox21: 0.744576 val loss: 0.277542
[Epoch 7] ogbg-moltox21: 0.785897 test loss: 0.231841
[Epoch 8; Iter     9/  183] train: loss: 0.1755858
[Epoch 8; Iter    39/  183] train: loss: 0.2149696
[Epoch 8; Iter    69/  183] train: loss: 0.3097930
[Epoch 8; Iter    99/  183] train: loss: 0.1810970
[Epoch 8; Iter   129/  183] train: loss: 0.3033707
[Epoch 8; Iter   159/  183] train: loss: 0.2505897
[Epoch 8] ogbg-moltox21: 0.737695 val loss: 0.234468
[Epoch 8] ogbg-moltox21: 0.705095 test loss: 0.250390
[Epoch 9; Iter     6/  183] train: loss: 0.2198544
[Epoch 9; Iter    36/  183] train: loss: 0.2072306
[Epoch 9; Iter    66/  183] train: loss: 0.2715243
[Epoch 9; Iter    96/  183] train: loss: 0.1826379
[Epoch 9; Iter   126/  183] train: loss: 0.1653864
[Epoch 9; Iter   156/  183] train: loss: 0.2229668
[Epoch 9] ogbg-moltox21: 0.743647 val loss: 0.236856
[Epoch 9] ogbg-moltox21: 0.772221 test loss: 0.244853
[Epoch 10; Iter     3/  183] train: loss: 0.2265640
[Epoch 10; Iter    33/  183] train: loss: 0.1756553
[Epoch 10; Iter    63/  183] train: loss: 0.2453195
[Epoch 10; Iter    93/  183] train: loss: 0.2017533
[Epoch 10; Iter   123/  183] train: loss: 0.1192921
[Epoch 10; Iter   153/  183] train: loss: 0.2107069
[Epoch 10; Iter   183/  183] train: loss: 0.1714302
[Epoch 10] ogbg-moltox21: 0.782897 val loss: 0.213371
[Epoch 10] ogbg-moltox21: 0.799837 test loss: 0.214542
[Epoch 11; Iter    30/  183] train: loss: 0.2215884
[Epoch 11; Iter    60/  183] train: loss: 0.2159703
[Epoch 11; Iter    90/  183] train: loss: 0.1473837
[Epoch 11; Iter   120/  183] train: loss: 0.1865036
[Epoch 11; Iter   150/  183] train: loss: 0.1414564
[Epoch 11; Iter   180/  183] train: loss: 0.2018010
[Epoch 11] ogbg-moltox21: 0.779455 val loss: 0.219391
[Epoch 11] ogbg-moltox21: 0.799800 test loss: 0.215332
[Epoch 12; Iter    27/  183] train: loss: 0.2170661
[Epoch 12; Iter    57/  183] train: loss: 0.1708952
[Epoch 12; Iter    87/  183] train: loss: 0.2772030
[Epoch 12; Iter   117/  183] train: loss: 0.1665542
[Epoch 12; Iter   147/  183] train: loss: 0.2218086
[Epoch 12; Iter   177/  183] train: loss: 0.1548001
[Epoch 12] ogbg-moltox21: 0.797470 val loss: 0.210740
[Epoch 12] ogbg-moltox21: 0.821214 test loss: 0.211679
[Epoch 13; Iter    24/  183] train: loss: 0.2756866
[Epoch 13; Iter    54/  183] train: loss: 0.1967684
[Epoch 13; Iter    84/  183] train: loss: 0.1912087
[Epoch 13; Iter   114/  183] train: loss: 0.2067167
[Epoch 13; Iter   144/  183] train: loss: 0.1754708
[Epoch 13; Iter   174/  183] train: loss: 0.2115957
[Epoch 13] ogbg-moltox21: 0.789468 val loss: 0.216744
[Epoch 13] ogbg-moltox21: 0.810076 test loss: 0.219124
[Epoch 14; Iter    21/  183] train: loss: 0.2206573
[Epoch 14; Iter    51/  183] train: loss: 0.1949316
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.7_4_26-05_09-18-11
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.7
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6932772
[Epoch 1; Iter    60/  183] train: loss: 0.6937287
[Epoch 1; Iter    90/  183] train: loss: 0.6931976
[Epoch 1; Iter   120/  183] train: loss: 0.6931512
[Epoch 1; Iter   150/  183] train: loss: 0.6927422
[Epoch 1; Iter   180/  183] train: loss: 0.6924080
[Epoch 1] ogbg-moltox21: 0.526882 val loss: 0.692964
[Epoch 1] ogbg-moltox21: 0.510626 test loss: 0.692967
[Epoch 2; Iter    27/  183] train: loss: 0.6929024
[Epoch 2; Iter    57/  183] train: loss: 0.6925620
[Epoch 2; Iter    87/  183] train: loss: 0.6919855
[Epoch 2; Iter   117/  183] train: loss: 0.6907604
[Epoch 2; Iter   147/  183] train: loss: 0.6921954
[Epoch 2; Iter   177/  183] train: loss: 0.6918864
[Epoch 2] ogbg-moltox21: 0.524435 val loss: 0.691508
[Epoch 2] ogbg-moltox21: 0.506551 test loss: 0.691506
[Epoch 3; Iter    24/  183] train: loss: 0.6913414
[Epoch 3; Iter    54/  183] train: loss: 0.6914852
[Epoch 3; Iter    84/  183] train: loss: 0.6908042
[Epoch 3; Iter   114/  183] train: loss: 0.6909255
[Epoch 3; Iter   144/  183] train: loss: 0.6901774
[Epoch 3; Iter   174/  183] train: loss: 0.6902762
[Epoch 3] ogbg-moltox21: 0.530589 val loss: 0.689607
[Epoch 3] ogbg-moltox21: 0.515007 test loss: 0.689635
[Epoch 4; Iter    21/  183] train: loss: 0.6893396
[Epoch 4; Iter    51/  183] train: loss: 0.6892684
[Epoch 4; Iter    81/  183] train: loss: 0.6879693
[Epoch 4; Iter   111/  183] train: loss: 0.6881800
[Epoch 4; Iter   141/  183] train: loss: 0.6866574
[Epoch 4; Iter   171/  183] train: loss: 0.6814130
[Epoch 4] ogbg-moltox21: 0.671838 val loss: 0.681289
[Epoch 4] ogbg-moltox21: 0.713470 test loss: 0.680862
[Epoch 5; Iter    18/  183] train: loss: 0.6645048
[Epoch 5; Iter    48/  183] train: loss: 0.6187717
[Epoch 5; Iter    78/  183] train: loss: 0.5805461
[Epoch 5; Iter   108/  183] train: loss: 0.5236929
[Epoch 5; Iter   138/  183] train: loss: 0.4700911
[Epoch 5; Iter   168/  183] train: loss: 0.4067440
[Epoch 5] ogbg-moltox21: 0.737156 val loss: 0.408376
[Epoch 5] ogbg-moltox21: 0.782780 test loss: 0.405105
[Epoch 6; Iter    15/  183] train: loss: 0.3630069
[Epoch 6; Iter    45/  183] train: loss: 0.3488921
[Epoch 6; Iter    75/  183] train: loss: 0.2976421
[Epoch 6; Iter   105/  183] train: loss: 0.3015558
[Epoch 6; Iter   135/  183] train: loss: 0.2939516
[Epoch 6; Iter   165/  183] train: loss: 0.2329327
[Epoch 6] ogbg-moltox21: 0.742424 val loss: 0.243925
[Epoch 6] ogbg-moltox21: 0.761875 test loss: 0.240106
[Epoch 7; Iter    12/  183] train: loss: 0.2372578
[Epoch 7; Iter    42/  183] train: loss: 0.1600695
[Epoch 7; Iter    72/  183] train: loss: 0.1977713
[Epoch 7; Iter   102/  183] train: loss: 0.3754087
[Epoch 7; Iter   132/  183] train: loss: 0.1605591
[Epoch 7; Iter   162/  183] train: loss: 0.2270528
[Epoch 7] ogbg-moltox21: 0.738035 val loss: 0.234093
[Epoch 7] ogbg-moltox21: 0.773588 test loss: 0.233259
[Epoch 8; Iter     9/  183] train: loss: 0.1818226
[Epoch 8; Iter    39/  183] train: loss: 0.2632886
[Epoch 8; Iter    69/  183] train: loss: 0.2200095
[Epoch 8; Iter    99/  183] train: loss: 0.2515873
[Epoch 8; Iter   129/  183] train: loss: 0.2083341
[Epoch 8; Iter   159/  183] train: loss: 0.1733937
[Epoch 8] ogbg-moltox21: 0.737844 val loss: 0.235463
[Epoch 8] ogbg-moltox21: 0.735953 test loss: 0.255310
[Epoch 9; Iter     6/  183] train: loss: 0.2705508
[Epoch 9; Iter    36/  183] train: loss: 0.1645912
[Epoch 9; Iter    66/  183] train: loss: 0.1839906
[Epoch 9; Iter    96/  183] train: loss: 0.1392271
[Epoch 9; Iter   126/  183] train: loss: 0.2098701
[Epoch 9; Iter   156/  183] train: loss: 0.2723708
[Epoch 9] ogbg-moltox21: 0.753826 val loss: 0.224626
[Epoch 9] ogbg-moltox21: 0.771764 test loss: 0.225829
[Epoch 10; Iter     3/  183] train: loss: 0.2340215
[Epoch 10; Iter    33/  183] train: loss: 0.1670010
[Epoch 10; Iter    63/  183] train: loss: 0.2043803
[Epoch 10; Iter    93/  183] train: loss: 0.2087566
[Epoch 10; Iter   123/  183] train: loss: 0.1690633
[Epoch 10; Iter   153/  183] train: loss: 0.2019319
[Epoch 10; Iter   183/  183] train: loss: 0.2046194
[Epoch 10] ogbg-moltox21: 0.763082 val loss: 0.223044
[Epoch 10] ogbg-moltox21: 0.790275 test loss: 0.223027
[Epoch 11; Iter    30/  183] train: loss: 0.2230411
[Epoch 11; Iter    60/  183] train: loss: 0.1780094
[Epoch 11; Iter    90/  183] train: loss: 0.1560702
[Epoch 11; Iter   120/  183] train: loss: 0.2117214
[Epoch 11; Iter   150/  183] train: loss: 0.1674436
[Epoch 11; Iter   180/  183] train: loss: 0.1737175
[Epoch 11] ogbg-moltox21: 0.788131 val loss: 0.213570
[Epoch 11] ogbg-moltox21: 0.825142 test loss: 0.213864
[Epoch 12; Iter    27/  183] train: loss: 0.2591169
[Epoch 12; Iter    57/  183] train: loss: 0.3037520
[Epoch 12; Iter    87/  183] train: loss: 0.1240108
[Epoch 12; Iter   117/  183] train: loss: 0.2135092
[Epoch 12; Iter   147/  183] train: loss: 0.1626192
[Epoch 12; Iter   177/  183] train: loss: 0.3057822
[Epoch 12] ogbg-moltox21: 0.790862 val loss: 0.209592
[Epoch 12] ogbg-moltox21: 0.819086 test loss: 0.206321
[Epoch 13; Iter    24/  183] train: loss: 0.2115424
[Epoch 13; Iter    54/  183] train: loss: 0.2314435
[Epoch 13; Iter    84/  183] train: loss: 0.1297591
[Epoch 13; Iter   114/  183] train: loss: 0.2409032
[Epoch 13; Iter   144/  183] train: loss: 0.2272128
[Epoch 13; Iter   174/  183] train: loss: 0.2167227
[Epoch 13] ogbg-moltox21: 0.788388 val loss: 0.206498
[Epoch 13] ogbg-moltox21: 0.808036 test loss: 0.213683
[Epoch 14; Iter    21/  183] train: loss: 0.2037254
[Epoch 14; Iter    51/  183] train: loss: 0.2013351
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.7_6_26-05_09-18-11
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.7
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6925122
[Epoch 1; Iter    60/  183] train: loss: 0.6922638
[Epoch 1; Iter    90/  183] train: loss: 0.6933537
[Epoch 1; Iter   120/  183] train: loss: 0.6925592
[Epoch 1; Iter   150/  183] train: loss: 0.6937681
[Epoch 1; Iter   180/  183] train: loss: 0.6932783
[Epoch 1] ogbg-moltox21: 0.463922 val loss: 0.692672
[Epoch 1] ogbg-moltox21: 0.492387 test loss: 0.692496
[Epoch 2; Iter    27/  183] train: loss: 0.6928549
[Epoch 2; Iter    57/  183] train: loss: 0.6921779
[Epoch 2; Iter    87/  183] train: loss: 0.6920869
[Epoch 2; Iter   117/  183] train: loss: 0.6921484
[Epoch 2; Iter   147/  183] train: loss: 0.6920794
[Epoch 2; Iter   177/  183] train: loss: 0.6912711
[Epoch 2] ogbg-moltox21: 0.473208 val loss: 0.691580
[Epoch 2] ogbg-moltox21: 0.499038 test loss: 0.691421
[Epoch 3; Iter    24/  183] train: loss: 0.6912302
[Epoch 3; Iter    54/  183] train: loss: 0.6912788
[Epoch 3; Iter    84/  183] train: loss: 0.6909801
[Epoch 3; Iter   114/  183] train: loss: 0.6907743
[Epoch 3; Iter   144/  183] train: loss: 0.6893994
[Epoch 3; Iter   174/  183] train: loss: 0.6887200
[Epoch 3] ogbg-moltox21: 0.477573 val loss: 0.689560
[Epoch 3] ogbg-moltox21: 0.505464 test loss: 0.689430
[Epoch 4; Iter    21/  183] train: loss: 0.6891290
[Epoch 4; Iter    51/  183] train: loss: 0.6895028
[Epoch 4; Iter    81/  183] train: loss: 0.6883321
[Epoch 4; Iter   111/  183] train: loss: 0.6874945
[Epoch 4; Iter   141/  183] train: loss: 0.6877190
[Epoch 4; Iter   171/  183] train: loss: 0.6826453
[Epoch 4] ogbg-moltox21: 0.687848 val loss: 0.682898
[Epoch 4] ogbg-moltox21: 0.731072 test loss: 0.681981
[Epoch 5; Iter    18/  183] train: loss: 0.6678762
[Epoch 5; Iter    48/  183] train: loss: 0.6162357
[Epoch 5; Iter    78/  183] train: loss: 0.5993685
[Epoch 5; Iter   108/  183] train: loss: 0.5490617
[Epoch 5; Iter   138/  183] train: loss: 0.4784171
[Epoch 5; Iter   168/  183] train: loss: 0.4273117
[Epoch 5] ogbg-moltox21: 0.734172 val loss: 0.384506
[Epoch 5] ogbg-moltox21: 0.779517 test loss: 0.381513
[Epoch 6; Iter    15/  183] train: loss: 0.3931812
[Epoch 6; Iter    45/  183] train: loss: 0.3794463
[Epoch 6; Iter    75/  183] train: loss: 0.2796522
[Epoch 6; Iter   105/  183] train: loss: 0.2422408
[Epoch 6; Iter   135/  183] train: loss: 0.2552923
[Epoch 6; Iter   165/  183] train: loss: 0.2066314
[Epoch 6] ogbg-moltox21: 0.742439 val loss: 0.239417
[Epoch 6] ogbg-moltox21: 0.772572 test loss: 0.239155
[Epoch 7; Iter    12/  183] train: loss: 0.2983414
[Epoch 7; Iter    42/  183] train: loss: 0.2116610
[Epoch 7; Iter    72/  183] train: loss: 0.2413055
[Epoch 7; Iter   102/  183] train: loss: 0.2230719
[Epoch 7; Iter   132/  183] train: loss: 0.2949205
[Epoch 7; Iter   162/  183] train: loss: 0.1676636
[Epoch 7] ogbg-moltox21: 0.758503 val loss: 0.224819
[Epoch 7] ogbg-moltox21: 0.792865 test loss: 0.224500
[Epoch 8; Iter     9/  183] train: loss: 0.1787625
[Epoch 8; Iter    39/  183] train: loss: 0.2608541
[Epoch 8; Iter    69/  183] train: loss: 0.2454585
[Epoch 8; Iter    99/  183] train: loss: 0.1928588
[Epoch 8; Iter   129/  183] train: loss: 0.1733633
[Epoch 8; Iter   159/  183] train: loss: 0.2127374
[Epoch 8] ogbg-moltox21: 0.737572 val loss: 0.227954
[Epoch 8] ogbg-moltox21: 0.738939 test loss: 0.236647
[Epoch 9; Iter     6/  183] train: loss: 0.1639658
[Epoch 9; Iter    36/  183] train: loss: 0.2374971
[Epoch 9; Iter    66/  183] train: loss: 0.1692965
[Epoch 9; Iter    96/  183] train: loss: 0.2188566
[Epoch 9; Iter   126/  183] train: loss: 0.1842623
[Epoch 9; Iter   156/  183] train: loss: 0.2182295
[Epoch 9] ogbg-moltox21: 0.769400 val loss: 0.216955
[Epoch 9] ogbg-moltox21: 0.794758 test loss: 0.224776
[Epoch 10; Iter     3/  183] train: loss: 0.2545237
[Epoch 10; Iter    33/  183] train: loss: 0.2860642
[Epoch 10; Iter    63/  183] train: loss: 0.1746015
[Epoch 10; Iter    93/  183] train: loss: 0.2183462
[Epoch 10; Iter   123/  183] train: loss: 0.2570357
[Epoch 10; Iter   153/  183] train: loss: 0.1828874
[Epoch 10; Iter   183/  183] train: loss: 0.3174985
[Epoch 10] ogbg-moltox21: 0.770353 val loss: 0.219704
[Epoch 10] ogbg-moltox21: 0.794320 test loss: 0.224979
[Epoch 11; Iter    30/  183] train: loss: 0.2731340
[Epoch 11; Iter    60/  183] train: loss: 0.2096953
[Epoch 11; Iter    90/  183] train: loss: 0.1507483
[Epoch 11; Iter   120/  183] train: loss: 0.1853402
[Epoch 11; Iter   150/  183] train: loss: 0.1905888
[Epoch 11; Iter   180/  183] train: loss: 0.1974861
[Epoch 11] ogbg-moltox21: 0.768185 val loss: 0.220192
[Epoch 11] ogbg-moltox21: 0.775375 test loss: 0.228288
[Epoch 12; Iter    27/  183] train: loss: 0.2362721
[Epoch 12; Iter    57/  183] train: loss: 0.2412542
[Epoch 12; Iter    87/  183] train: loss: 0.1604260
[Epoch 12; Iter   117/  183] train: loss: 0.1607513
[Epoch 12; Iter   147/  183] train: loss: 0.2039641
[Epoch 12; Iter   177/  183] train: loss: 0.2460031
[Epoch 12] ogbg-moltox21: 0.720384 val loss: 0.237959
[Epoch 12] ogbg-moltox21: 0.740530 test loss: 0.242381
[Epoch 13; Iter    24/  183] train: loss: 0.1882917
[Epoch 13; Iter    54/  183] train: loss: 0.2033437
[Epoch 13; Iter    84/  183] train: loss: 0.1890671
[Epoch 13; Iter   114/  183] train: loss: 0.2089893
[Epoch 13; Iter   144/  183] train: loss: 0.2487476
[Epoch 13; Iter   174/  183] train: loss: 0.2441141
[Epoch 13] ogbg-moltox21: 0.742334 val loss: 0.397067
[Epoch 13] ogbg-moltox21: 0.759460 test loss: 0.330978
[Epoch 14; Iter    21/  183] train: loss: 0.1924829
[Epoch 14; Iter    51/  183] train: loss: 0.1518001
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.6_4_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.6
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6937597
[Epoch 1; Iter    60/  157] train: loss: 0.6931638
[Epoch 1; Iter    90/  157] train: loss: 0.6932974
[Epoch 1; Iter   120/  157] train: loss: 0.6928995
[Epoch 1; Iter   150/  157] train: loss: 0.6929851
[Epoch 1] ogbg-moltox21: 0.523235 val loss: 0.692975
[Epoch 1] ogbg-moltox21: 0.511214 test loss: 0.693022
[Epoch 2; Iter    23/  157] train: loss: 0.6939744
[Epoch 2; Iter    53/  157] train: loss: 0.6924664
[Epoch 2; Iter    83/  157] train: loss: 0.6926929
[Epoch 2; Iter   113/  157] train: loss: 0.6927534
[Epoch 2; Iter   143/  157] train: loss: 0.6915101
[Epoch 2] ogbg-moltox21: 0.523444 val loss: 0.692130
[Epoch 2] ogbg-moltox21: 0.511073 test loss: 0.692204
[Epoch 3; Iter    16/  157] train: loss: 0.6912088
[Epoch 3; Iter    46/  157] train: loss: 0.6922467
[Epoch 3; Iter    76/  157] train: loss: 0.6917968
[Epoch 3; Iter   106/  157] train: loss: 0.6912224
[Epoch 3; Iter   136/  157] train: loss: 0.6910781
[Epoch 3] ogbg-moltox21: 0.532141 val loss: 0.690687
[Epoch 3] ogbg-moltox21: 0.514825 test loss: 0.690799
[Epoch 4; Iter     9/  157] train: loss: 0.6898465
[Epoch 4; Iter    39/  157] train: loss: 0.6905050
[Epoch 4; Iter    69/  157] train: loss: 0.6892045
[Epoch 4; Iter    99/  157] train: loss: 0.6890470
[Epoch 4; Iter   129/  157] train: loss: 0.6889856
[Epoch 4] ogbg-moltox21: 0.532556 val loss: 0.688303
[Epoch 4] ogbg-moltox21: 0.515124 test loss: 0.688463
[Epoch 5; Iter     2/  157] train: loss: 0.6885228
[Epoch 5; Iter    32/  157] train: loss: 0.6874398
[Epoch 5; Iter    62/  157] train: loss: 0.6867889
[Epoch 5; Iter    92/  157] train: loss: 0.6816024
[Epoch 5; Iter   122/  157] train: loss: 0.6625700
[Epoch 5; Iter   152/  157] train: loss: 0.6205037
[Epoch 5] ogbg-moltox21: 0.723048 val loss: 0.630208
[Epoch 5] ogbg-moltox21: 0.720631 test loss: 0.633051
[Epoch 6; Iter    25/  157] train: loss: 0.5873702
[Epoch 6; Iter    55/  157] train: loss: 0.5556131
[Epoch 6; Iter    85/  157] train: loss: 0.5033571
[Epoch 6; Iter   115/  157] train: loss: 0.4194556
[Epoch 6; Iter   145/  157] train: loss: 0.3948494
[Epoch 6] ogbg-moltox21: 0.751460 val loss: 0.331179
[Epoch 6] ogbg-moltox21: 0.763559 test loss: 0.337875
[Epoch 7; Iter    18/  157] train: loss: 0.3337075
[Epoch 7; Iter    48/  157] train: loss: 0.2778732
[Epoch 7; Iter    78/  157] train: loss: 0.2396526
[Epoch 7; Iter   108/  157] train: loss: 0.2757587
[Epoch 7; Iter   138/  157] train: loss: 0.2640318
[Epoch 7] ogbg-moltox21: 0.759516 val loss: 0.236961
[Epoch 7] ogbg-moltox21: 0.756793 test loss: 0.250143
[Epoch 8; Iter    11/  157] train: loss: 0.2576600
[Epoch 8; Iter    41/  157] train: loss: 0.2829971
[Epoch 8; Iter    71/  157] train: loss: 0.2961291
[Epoch 8; Iter   101/  157] train: loss: 0.1579491
[Epoch 8; Iter   131/  157] train: loss: 0.1716919
[Epoch 8] ogbg-moltox21: 0.765364 val loss: 0.213013
[Epoch 8] ogbg-moltox21: 0.763198 test loss: 0.231616
[Epoch 9; Iter     4/  157] train: loss: 0.2178703
[Epoch 9; Iter    34/  157] train: loss: 0.1593566
[Epoch 9; Iter    64/  157] train: loss: 0.2218983
[Epoch 9; Iter    94/  157] train: loss: 0.2521646
[Epoch 9; Iter   124/  157] train: loss: 0.1982963
[Epoch 9; Iter   154/  157] train: loss: 0.2864424
[Epoch 9] ogbg-moltox21: 0.766824 val loss: 0.220583
[Epoch 9] ogbg-moltox21: 0.784268 test loss: 0.234629
[Epoch 10; Iter    27/  157] train: loss: 0.2459177
[Epoch 10; Iter    57/  157] train: loss: 0.2189829
[Epoch 10; Iter    87/  157] train: loss: 0.2925324
[Epoch 10; Iter   117/  157] train: loss: 0.1451259
[Epoch 10; Iter   147/  157] train: loss: 0.2176590
[Epoch 10] ogbg-moltox21: 0.774670 val loss: 0.206044
[Epoch 10] ogbg-moltox21: 0.774738 test loss: 0.229770
[Epoch 11; Iter    20/  157] train: loss: 0.2139170
[Epoch 11; Iter    50/  157] train: loss: 0.2217842
[Epoch 11; Iter    80/  157] train: loss: 0.1705091
[Epoch 11; Iter   110/  157] train: loss: 0.1880093
[Epoch 11; Iter   140/  157] train: loss: 0.2772480
[Epoch 11] ogbg-moltox21: 0.774622 val loss: 0.216110
[Epoch 11] ogbg-moltox21: 0.782567 test loss: 0.231948
[Epoch 12; Iter    13/  157] train: loss: 0.2026827
[Epoch 12; Iter    43/  157] train: loss: 0.2823170
[Epoch 12; Iter    73/  157] train: loss: 0.2963680
[Epoch 12; Iter   103/  157] train: loss: 0.1433121
[Epoch 12; Iter   133/  157] train: loss: 0.1582987
[Epoch 12] ogbg-moltox21: 0.792173 val loss: 0.214181
[Epoch 12] ogbg-moltox21: 0.784954 test loss: 0.228153
[Epoch 13; Iter     6/  157] train: loss: 0.2166013
[Epoch 13; Iter    36/  157] train: loss: 0.2169229
[Epoch 13; Iter    66/  157] train: loss: 0.2121296
[Epoch 13; Iter    96/  157] train: loss: 0.1991498
[Epoch 13; Iter   126/  157] train: loss: 0.1828791
[Epoch 13; Iter   156/  157] train: loss: 0.2219321
[Epoch 13] ogbg-moltox21: 0.811985 val loss: 0.230035
[Epoch 13] ogbg-moltox21: 0.811187 test loss: 0.212810
[Epoch 14; Iter    29/  157] train: loss: 0.1972452
[Epoch 14; Iter    59/  157] train: loss: 0.1715270
[Epoch 14; Iter    89/  157] train: loss: 0.1862886
[Epoch 14; Iter   119/  157] train: loss: 0.2516371
[Epoch 14; Iter   149/  157] train: loss: 0.2608096
[Epoch 14] ogbg-moltox21: 0.747335 val loss: 0.218317
[Epoch 14] ogbg-moltox21: 0.743103 test loss: 0.238504
[Epoch 15; Iter    22/  157] train: loss: 0.2531601
[Epoch 15; Iter    52/  157] train: loss: 0.1864719
[Epoch 15; Iter    82/  157] train: loss: 0.2399232
[Epoch 15; Iter   112/  157] train: loss: 0.1732150
[Epoch 15; Iter   142/  157] train: loss: 0.3873531
[Epoch 15] ogbg-moltox21: 0.751985 val loss: 0.256952
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.6_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.6
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6931350
[Epoch 1; Iter    60/  157] train: loss: 0.6928636
[Epoch 1; Iter    90/  157] train: loss: 0.6933984
[Epoch 1; Iter   120/  157] train: loss: 0.6929404
[Epoch 1; Iter   150/  157] train: loss: 0.6922181
[Epoch 1] ogbg-moltox21: 0.480578 val loss: 0.692881
[Epoch 1] ogbg-moltox21: 0.488477 test loss: 0.692772
[Epoch 2; Iter    23/  157] train: loss: 0.6917444
[Epoch 2; Iter    53/  157] train: loss: 0.6923664
[Epoch 2; Iter    83/  157] train: loss: 0.6922700
[Epoch 2; Iter   113/  157] train: loss: 0.6921278
[Epoch 2; Iter   143/  157] train: loss: 0.6914461
[Epoch 2] ogbg-moltox21: 0.481622 val loss: 0.691920
[Epoch 2] ogbg-moltox21: 0.489784 test loss: 0.691827
[Epoch 3; Iter    16/  157] train: loss: 0.6916746
[Epoch 3; Iter    46/  157] train: loss: 0.6924006
[Epoch 3; Iter    76/  157] train: loss: 0.6915914
[Epoch 3; Iter   106/  157] train: loss: 0.6913732
[Epoch 3; Iter   136/  157] train: loss: 0.6904239
[Epoch 3] ogbg-moltox21: 0.480134 val loss: 0.690468
[Epoch 3] ogbg-moltox21: 0.492272 test loss: 0.690406
[Epoch 4; Iter     9/  157] train: loss: 0.6904827
[Epoch 4; Iter    39/  157] train: loss: 0.6902443
[Epoch 4; Iter    69/  157] train: loss: 0.6901382
[Epoch 4; Iter    99/  157] train: loss: 0.6889788
[Epoch 4; Iter   129/  157] train: loss: 0.6892250
[Epoch 4] ogbg-moltox21: 0.483770 val loss: 0.688194
[Epoch 4] ogbg-moltox21: 0.499318 test loss: 0.688177
[Epoch 5; Iter     2/  157] train: loss: 0.6888435
[Epoch 5; Iter    32/  157] train: loss: 0.6873134
[Epoch 5; Iter    62/  157] train: loss: 0.6870908
[Epoch 5; Iter    92/  157] train: loss: 0.6824299
[Epoch 5; Iter   122/  157] train: loss: 0.6597698
[Epoch 5; Iter   152/  157] train: loss: 0.6350192
[Epoch 5] ogbg-moltox21: 0.730519 val loss: 0.623557
[Epoch 5] ogbg-moltox21: 0.729974 test loss: 0.626569
[Epoch 6; Iter    25/  157] train: loss: 0.5705173
[Epoch 6; Iter    55/  157] train: loss: 0.5414976
[Epoch 6; Iter    85/  157] train: loss: 0.4831499
[Epoch 6; Iter   115/  157] train: loss: 0.4254933
[Epoch 6; Iter   145/  157] train: loss: 0.4429913
[Epoch 6] ogbg-moltox21: 0.732499 val loss: 0.392199
[Epoch 6] ogbg-moltox21: 0.754406 test loss: 0.397810
[Epoch 7; Iter    18/  157] train: loss: 0.3080888
[Epoch 7; Iter    48/  157] train: loss: 0.2579539
[Epoch 7; Iter    78/  157] train: loss: 0.2811500
[Epoch 7; Iter   108/  157] train: loss: 0.2750655
[Epoch 7; Iter   138/  157] train: loss: 0.2497252
[Epoch 7] ogbg-moltox21: 0.750805 val loss: 0.228705
[Epoch 7] ogbg-moltox21: 0.734055 test loss: 0.246942
[Epoch 8; Iter    11/  157] train: loss: 0.1726220
[Epoch 8; Iter    41/  157] train: loss: 0.2321323
[Epoch 8; Iter    71/  157] train: loss: 0.2088832
[Epoch 8; Iter   101/  157] train: loss: 0.2870093
[Epoch 8; Iter   131/  157] train: loss: 0.1595325
[Epoch 8] ogbg-moltox21: 0.759428 val loss: 0.215653
[Epoch 8] ogbg-moltox21: 0.778940 test loss: 0.231689
[Epoch 9; Iter     4/  157] train: loss: 0.2740758
[Epoch 9; Iter    34/  157] train: loss: 0.1847637
[Epoch 9; Iter    64/  157] train: loss: 0.2480936
[Epoch 9; Iter    94/  157] train: loss: 0.2270556
[Epoch 9; Iter   124/  157] train: loss: 0.1763247
[Epoch 9; Iter   154/  157] train: loss: 0.2648222
[Epoch 9] ogbg-moltox21: 0.764250 val loss: 0.211040
[Epoch 9] ogbg-moltox21: 0.778096 test loss: 0.226853
[Epoch 10; Iter    27/  157] train: loss: 0.3232974
[Epoch 10; Iter    57/  157] train: loss: 0.1702715
[Epoch 10; Iter    87/  157] train: loss: 0.1763209
[Epoch 10; Iter   117/  157] train: loss: 0.1671216
[Epoch 10; Iter   147/  157] train: loss: 0.1496622
[Epoch 10] ogbg-moltox21: 0.757690 val loss: 0.227733
[Epoch 10] ogbg-moltox21: 0.749115 test loss: 0.247410
[Epoch 11; Iter    20/  157] train: loss: 0.1451345
[Epoch 11; Iter    50/  157] train: loss: 0.2582390
[Epoch 11; Iter    80/  157] train: loss: 0.2005173
[Epoch 11; Iter   110/  157] train: loss: 0.2657807
[Epoch 11; Iter   140/  157] train: loss: 0.3510185
[Epoch 11] ogbg-moltox21: 0.769528 val loss: 0.239128
[Epoch 11] ogbg-moltox21: 0.790714 test loss: 0.242663
[Epoch 12; Iter    13/  157] train: loss: 0.0933237
[Epoch 12; Iter    43/  157] train: loss: 0.1260099
[Epoch 12; Iter    73/  157] train: loss: 0.1515120
[Epoch 12; Iter   103/  157] train: loss: 0.1946823
[Epoch 12; Iter   133/  157] train: loss: 0.1775252
[Epoch 12] ogbg-moltox21: 0.779145 val loss: 0.203061
[Epoch 12] ogbg-moltox21: 0.776959 test loss: 0.223739
[Epoch 13; Iter     6/  157] train: loss: 0.1478495
[Epoch 13; Iter    36/  157] train: loss: 0.1416007
[Epoch 13; Iter    66/  157] train: loss: 0.2154213
[Epoch 13; Iter    96/  157] train: loss: 0.2129776
[Epoch 13; Iter   126/  157] train: loss: 0.1779310
[Epoch 13; Iter   156/  157] train: loss: 0.1522672
[Epoch 13] ogbg-moltox21: 0.796718 val loss: 0.197345
[Epoch 13] ogbg-moltox21: 0.816126 test loss: 0.209139
[Epoch 14; Iter    29/  157] train: loss: 0.1820581
[Epoch 14; Iter    59/  157] train: loss: 0.1582864
[Epoch 14; Iter    89/  157] train: loss: 0.1637656
[Epoch 14; Iter   119/  157] train: loss: 0.1655271
[Epoch 14; Iter   149/  157] train: loss: 0.2770968
[Epoch 14] ogbg-moltox21: 0.804755 val loss: 0.208730
[Epoch 14] ogbg-moltox21: 0.813505 test loss: 0.213417
[Epoch 15; Iter    22/  157] train: loss: 0.1931092
[Epoch 15; Iter    52/  157] train: loss: 0.1045913
[Epoch 15; Iter    82/  157] train: loss: 0.1704663
[Epoch 15; Iter   112/  157] train: loss: 0.1771863
[Epoch 15; Iter   142/  157] train: loss: 0.1504347
[Epoch 15] ogbg-moltox21: 0.805306 val loss: 0.196483
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_random=0.6_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_random=0.6
logdir: runs/split/3DInfomax/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6923046
[Epoch 1; Iter    60/  157] train: loss: 0.6933624
[Epoch 1; Iter    90/  157] train: loss: 0.6923449
[Epoch 1; Iter   120/  157] train: loss: 0.6922671
[Epoch 1; Iter   150/  157] train: loss: 0.6926008
[Epoch 1] ogbg-moltox21: 0.502357 val loss: 0.692787
[Epoch 1] ogbg-moltox21: 0.511619 test loss: 0.692597
[Epoch 2; Iter    23/  157] train: loss: 0.6921672
[Epoch 2; Iter    53/  157] train: loss: 0.6923916
[Epoch 2; Iter    83/  157] train: loss: 0.6934304
[Epoch 2; Iter   113/  157] train: loss: 0.6924168
[Epoch 2; Iter   143/  157] train: loss: 0.6917270
[Epoch 2] ogbg-moltox21: 0.502395 val loss: 0.691820
[Epoch 2] ogbg-moltox21: 0.510918 test loss: 0.691676
[Epoch 3; Iter    16/  157] train: loss: 0.6907841
[Epoch 3; Iter    46/  157] train: loss: 0.6921361
[Epoch 3; Iter    76/  157] train: loss: 0.6912684
[Epoch 3; Iter   106/  157] train: loss: 0.6905209
[Epoch 3; Iter   136/  157] train: loss: 0.6899065
[Epoch 3] ogbg-moltox21: 0.509743 val loss: 0.690265
[Epoch 3] ogbg-moltox21: 0.520289 test loss: 0.690134
[Epoch 4; Iter     9/  157] train: loss: 0.6899468
[Epoch 4; Iter    39/  157] train: loss: 0.6896026
[Epoch 4; Iter    69/  157] train: loss: 0.6891902
[Epoch 4; Iter    99/  157] train: loss: 0.6890735
[Epoch 4; Iter   129/  157] train: loss: 0.6880704
[Epoch 4] ogbg-moltox21: 0.516867 val loss: 0.687831
[Epoch 4] ogbg-moltox21: 0.528454 test loss: 0.687736
[Epoch 5; Iter     2/  157] train: loss: 0.6875456
[Epoch 5; Iter    32/  157] train: loss: 0.6870909
[Epoch 5; Iter    62/  157] train: loss: 0.6863987
[Epoch 5; Iter    92/  157] train: loss: 0.6824676
[Epoch 5; Iter   122/  157] train: loss: 0.6604357
[Epoch 5; Iter   152/  157] train: loss: 0.6288723
[Epoch 5] ogbg-moltox21: 0.722343 val loss: 0.630343
[Epoch 5] ogbg-moltox21: 0.735730 test loss: 0.631180
[Epoch 6; Iter    25/  157] train: loss: 0.5997367
[Epoch 6; Iter    55/  157] train: loss: 0.5224493
[Epoch 6; Iter    85/  157] train: loss: 0.4954109
[Epoch 6; Iter   115/  157] train: loss: 0.4048508
[Epoch 6; Iter   145/  157] train: loss: 0.4162246
[Epoch 6] ogbg-moltox21: 0.748867 val loss: 0.348653
[Epoch 6] ogbg-moltox21: 0.767116 test loss: 0.357706
[Epoch 7; Iter    18/  157] train: loss: 0.3310560
[Epoch 7; Iter    48/  157] train: loss: 0.2966147
[Epoch 7; Iter    78/  157] train: loss: 0.2733869
[Epoch 7; Iter   108/  157] train: loss: 0.2688366
[Epoch 7; Iter   138/  157] train: loss: 0.2538444
[Epoch 7] ogbg-moltox21: 0.752364 val loss: 0.231708
[Epoch 7] ogbg-moltox21: 0.763402 test loss: 0.248345
[Epoch 8; Iter    11/  157] train: loss: 0.2279262
[Epoch 8; Iter    41/  157] train: loss: 0.2866522
[Epoch 8; Iter    71/  157] train: loss: 0.2197773
[Epoch 8; Iter   101/  157] train: loss: 0.2032892
[Epoch 8; Iter   131/  157] train: loss: 0.1650475
[Epoch 8] ogbg-moltox21: 0.767720 val loss: 0.211041
[Epoch 8] ogbg-moltox21: 0.784914 test loss: 0.230382
[Epoch 9; Iter     4/  157] train: loss: 0.1677699
[Epoch 9; Iter    34/  157] train: loss: 0.1553122
[Epoch 9; Iter    64/  157] train: loss: 0.1686445
[Epoch 9; Iter    94/  157] train: loss: 0.2006748
[Epoch 9; Iter   124/  157] train: loss: 0.2173951
[Epoch 9; Iter   154/  157] train: loss: 0.2141450
[Epoch 9] ogbg-moltox21: 0.767963 val loss: 0.216432
[Epoch 9] ogbg-moltox21: 0.798072 test loss: 0.223202
[Epoch 10; Iter    27/  157] train: loss: 0.1997067
[Epoch 10; Iter    57/  157] train: loss: 0.2318738
[Epoch 10; Iter    87/  157] train: loss: 0.2666631
[Epoch 10; Iter   117/  157] train: loss: 0.2147553
[Epoch 10; Iter   147/  157] train: loss: 0.2126147
[Epoch 10] ogbg-moltox21: 0.753633 val loss: 0.234907
[Epoch 10] ogbg-moltox21: 0.767466 test loss: 0.261144
[Epoch 11; Iter    20/  157] train: loss: 0.2214559
[Epoch 11; Iter    50/  157] train: loss: 0.2372238
[Epoch 11; Iter    80/  157] train: loss: 0.1527603
[Epoch 11; Iter   110/  157] train: loss: 0.1974672
[Epoch 11; Iter   140/  157] train: loss: 0.2071389
[Epoch 11] ogbg-moltox21: 0.748066 val loss: 0.213034
[Epoch 11] ogbg-moltox21: 0.770891 test loss: 0.231129
[Epoch 12; Iter    13/  157] train: loss: 0.1400813
[Epoch 12; Iter    43/  157] train: loss: 0.3341277
[Epoch 12; Iter    73/  157] train: loss: 0.2218421
[Epoch 12; Iter   103/  157] train: loss: 0.1729012
[Epoch 12; Iter   133/  157] train: loss: 0.2025419
[Epoch 12] ogbg-moltox21: 0.779460 val loss: 0.237316
[Epoch 12] ogbg-moltox21: 0.800544 test loss: 0.231093
[Epoch 13; Iter     6/  157] train: loss: 0.2355659
[Epoch 13; Iter    36/  157] train: loss: 0.2593619
[Epoch 13; Iter    66/  157] train: loss: 0.1842761
[Epoch 13; Iter    96/  157] train: loss: 0.1713060
[Epoch 13; Iter   126/  157] train: loss: 0.1730758
[Epoch 13; Iter   156/  157] train: loss: 0.2645602
[Epoch 13] ogbg-moltox21: 0.787960 val loss: 0.200520
[Epoch 13] ogbg-moltox21: 0.789971 test loss: 0.219983
[Epoch 14; Iter    29/  157] train: loss: 0.1539750
[Epoch 14; Iter    59/  157] train: loss: 0.1607646
[Epoch 14; Iter    89/  157] train: loss: 0.1887052
[Epoch 14; Iter   119/  157] train: loss: 0.2689632
[Epoch 14; Iter   149/  157] train: loss: 0.2999482
[Epoch 14] ogbg-moltox21: 0.803995 val loss: 0.196120
[Epoch 14] ogbg-moltox21: 0.816204 test loss: 0.213036
[Epoch 15; Iter    22/  157] train: loss: 0.1356627
[Epoch 15; Iter    52/  157] train: loss: 0.2681432
[Epoch 15; Iter    82/  157] train: loss: 0.3454376
[Epoch 15; Iter   112/  157] train: loss: 0.2839971
[Epoch 15; Iter   142/  157] train: loss: 0.1640057
[Epoch 15] ogbg-moltox21: 0.765106 val loss: 0.212742
[Epoch 13; Iter    12/  209] train: loss: 0.1805338
[Epoch 13; Iter    42/  209] train: loss: 0.1448203
[Epoch 13; Iter    72/  209] train: loss: 0.2086623
[Epoch 13; Iter   102/  209] train: loss: 0.3342735
[Epoch 13; Iter   132/  209] train: loss: 0.1589634
[Epoch 13; Iter   162/  209] train: loss: 0.1957149
[Epoch 13; Iter   192/  209] train: loss: 0.1384312
[Epoch 13] ogbg-moltox21: 0.834952 val loss: 0.208659
[Epoch 13] ogbg-moltox21: 0.822972 test loss: 0.235908
[Epoch 14; Iter    13/  209] train: loss: 0.1877141
[Epoch 14; Iter    43/  209] train: loss: 0.1511804
[Epoch 14; Iter    73/  209] train: loss: 0.2775351
[Epoch 14; Iter   103/  209] train: loss: 0.2236556
[Epoch 14; Iter   133/  209] train: loss: 0.1384569
[Epoch 14; Iter   163/  209] train: loss: 0.1949891
[Epoch 14; Iter   193/  209] train: loss: 0.1880388
[Epoch 14] ogbg-moltox21: 0.824705 val loss: 0.217382
[Epoch 14] ogbg-moltox21: 0.813065 test loss: 0.208443
[Epoch 15; Iter    14/  209] train: loss: 0.1075126
[Epoch 15; Iter    44/  209] train: loss: 0.1898688
[Epoch 15; Iter    74/  209] train: loss: 0.1922406
[Epoch 15; Iter   104/  209] train: loss: 0.3245349
[Epoch 15; Iter   134/  209] train: loss: 0.2031920
[Epoch 15; Iter   164/  209] train: loss: 0.1584588
[Epoch 15; Iter   194/  209] train: loss: 0.1202169
[Epoch 15] ogbg-moltox21: 0.840639 val loss: 0.212234
[Epoch 15] ogbg-moltox21: 0.826056 test loss: 0.212406
[Epoch 16; Iter    15/  209] train: loss: 0.1323275
[Epoch 16; Iter    45/  209] train: loss: 0.2253080
[Epoch 16; Iter    75/  209] train: loss: 0.1171416
[Epoch 16; Iter   105/  209] train: loss: 0.1626240
[Epoch 16; Iter   135/  209] train: loss: 0.1280934
[Epoch 16; Iter   165/  209] train: loss: 0.1997814
[Epoch 16; Iter   195/  209] train: loss: 0.1641951
[Epoch 16] ogbg-moltox21: 0.841530 val loss: 0.209535
[Epoch 16] ogbg-moltox21: 0.820883 test loss: 0.211687
[Epoch 17; Iter    16/  209] train: loss: 0.1689244
[Epoch 17; Iter    46/  209] train: loss: 0.1997326
[Epoch 17; Iter    76/  209] train: loss: 0.1827853
[Epoch 17; Iter   106/  209] train: loss: 0.1829420
[Epoch 17; Iter   136/  209] train: loss: 0.1169323
[Epoch 17; Iter   166/  209] train: loss: 0.1872686
[Epoch 17; Iter   196/  209] train: loss: 0.1215251
[Epoch 17] ogbg-moltox21: 0.844450 val loss: 0.207043
[Epoch 17] ogbg-moltox21: 0.831976 test loss: 0.212710
[Epoch 18; Iter    17/  209] train: loss: 0.1896605
[Epoch 18; Iter    47/  209] train: loss: 0.1144083
[Epoch 18; Iter    77/  209] train: loss: 0.2252615
[Epoch 18; Iter   107/  209] train: loss: 0.1533897
[Epoch 18; Iter   137/  209] train: loss: 0.1890607
[Epoch 18; Iter   167/  209] train: loss: 0.1675136
[Epoch 18; Iter   197/  209] train: loss: 0.1748464
[Epoch 18] ogbg-moltox21: 0.836657 val loss: 0.205113
[Epoch 18] ogbg-moltox21: 0.832752 test loss: 0.201073
[Epoch 19; Iter    18/  209] train: loss: 0.1597586
[Epoch 19; Iter    48/  209] train: loss: 0.0979171
[Epoch 19; Iter    78/  209] train: loss: 0.2610787
[Epoch 19; Iter   108/  209] train: loss: 0.1135239
[Epoch 19; Iter   138/  209] train: loss: 0.1665859
[Epoch 19; Iter   168/  209] train: loss: 0.2896043
[Epoch 19; Iter   198/  209] train: loss: 0.1912109
[Epoch 19] ogbg-moltox21: 0.833451 val loss: 0.214173
[Epoch 19] ogbg-moltox21: 0.843981 test loss: 0.205128
[Epoch 20; Iter    19/  209] train: loss: 0.1764439
[Epoch 20; Iter    49/  209] train: loss: 0.1956611
[Epoch 20; Iter    79/  209] train: loss: 0.1918020
[Epoch 20; Iter   109/  209] train: loss: 0.1769530
[Epoch 20; Iter   139/  209] train: loss: 0.2042356
[Epoch 20; Iter   169/  209] train: loss: 0.1459357
[Epoch 20; Iter   199/  209] train: loss: 0.1898831
[Epoch 20] ogbg-moltox21: 0.831144 val loss: 0.216618
[Epoch 20] ogbg-moltox21: 0.817764 test loss: 0.206065
[Epoch 21; Iter    20/  209] train: loss: 0.1252523
[Epoch 21; Iter    50/  209] train: loss: 0.1843574
[Epoch 21; Iter    80/  209] train: loss: 0.2743376
[Epoch 21; Iter   110/  209] train: loss: 0.1742798
[Epoch 21; Iter   140/  209] train: loss: 0.1358958
[Epoch 21; Iter   170/  209] train: loss: 0.1394340
[Epoch 21; Iter   200/  209] train: loss: 0.2409711
[Epoch 21] ogbg-moltox21: 0.852666 val loss: 0.209433
[Epoch 21] ogbg-moltox21: 0.847873 test loss: 0.198548
[Epoch 22; Iter    21/  209] train: loss: 0.1288790
[Epoch 22; Iter    51/  209] train: loss: 0.1217417
[Epoch 22; Iter    81/  209] train: loss: 0.2029691
[Epoch 22; Iter   111/  209] train: loss: 0.1365311
[Epoch 22; Iter   141/  209] train: loss: 0.1319671
[Epoch 22; Iter   171/  209] train: loss: 0.1941781
[Epoch 22; Iter   201/  209] train: loss: 0.0834530
[Epoch 22] ogbg-moltox21: 0.839839 val loss: 0.241315
[Epoch 22] ogbg-moltox21: 0.851793 test loss: 0.194844
[Epoch 23; Iter    22/  209] train: loss: 0.1570156
[Epoch 23; Iter    52/  209] train: loss: 0.2011942
[Epoch 23; Iter    82/  209] train: loss: 0.1361745
[Epoch 23; Iter   112/  209] train: loss: 0.1697550
[Epoch 23; Iter   142/  209] train: loss: 0.1717875
[Epoch 23; Iter   172/  209] train: loss: 0.1244427
[Epoch 23; Iter   202/  209] train: loss: 0.1900270
[Epoch 23] ogbg-moltox21: 0.858997 val loss: 0.217057
[Epoch 23] ogbg-moltox21: 0.855595 test loss: 0.188136
[Epoch 24; Iter    23/  209] train: loss: 0.1870636
[Epoch 24; Iter    53/  209] train: loss: 0.1508677
[Epoch 24; Iter    83/  209] train: loss: 0.1637162
[Epoch 24; Iter   113/  209] train: loss: 0.1534126
[Epoch 24; Iter   143/  209] train: loss: 0.2457720
[Epoch 24; Iter   173/  209] train: loss: 0.1742188
[Epoch 24; Iter   203/  209] train: loss: 0.1402416
[Epoch 24] ogbg-moltox21: 0.842972 val loss: 0.213084
[Epoch 24] ogbg-moltox21: 0.822990 test loss: 0.202596
[Epoch 25; Iter    24/  209] train: loss: 0.1389594
[Epoch 25; Iter    54/  209] train: loss: 0.1158450
[Epoch 25; Iter    84/  209] train: loss: 0.2941204
[Epoch 25; Iter   114/  209] train: loss: 0.1598008
[Epoch 25; Iter   144/  209] train: loss: 0.1850179
[Epoch 25; Iter   174/  209] train: loss: 0.1405452
[Epoch 25; Iter   204/  209] train: loss: 0.1489896
[Epoch 25] ogbg-moltox21: 0.843319 val loss: 0.213809
[Epoch 25] ogbg-moltox21: 0.836212 test loss: 0.206747
[Epoch 26; Iter    25/  209] train: loss: 0.2591179
[Epoch 26; Iter    55/  209] train: loss: 0.2699976
[Epoch 26; Iter    85/  209] train: loss: 0.1443894
[Epoch 26; Iter   115/  209] train: loss: 0.2516909
[Epoch 26; Iter   145/  209] train: loss: 0.1224469
[Epoch 26; Iter   175/  209] train: loss: 0.1438311
[Epoch 26; Iter   205/  209] train: loss: 0.1371833
[Epoch 26] ogbg-moltox21: 0.861019 val loss: 0.205984
[Epoch 26] ogbg-moltox21: 0.846962 test loss: 0.189602
[Epoch 27; Iter    26/  209] train: loss: 0.1524709
[Epoch 27; Iter    56/  209] train: loss: 0.1291094
[Epoch 27; Iter    86/  209] train: loss: 0.2155112
[Epoch 27; Iter   116/  209] train: loss: 0.1814770
[Epoch 27; Iter   146/  209] train: loss: 0.1761741
[Epoch 27; Iter   176/  209] train: loss: 0.2684989
[Epoch 27; Iter   206/  209] train: loss: 0.1488287
[Epoch 27] ogbg-moltox21: 0.842817 val loss: 0.209796
[Epoch 27] ogbg-moltox21: 0.817250 test loss: 0.203419
[Epoch 28; Iter    27/  209] train: loss: 0.1547047
[Epoch 28; Iter    57/  209] train: loss: 0.2089952
[Epoch 28; Iter    87/  209] train: loss: 0.1462968
[Epoch 28; Iter   117/  209] train: loss: 0.1685041
[Epoch 28; Iter   147/  209] train: loss: 0.1361670
[Epoch 28; Iter   177/  209] train: loss: 0.1385660
[Epoch 28; Iter   207/  209] train: loss: 0.1873866
[Epoch 28] ogbg-moltox21: 0.857119 val loss: 0.225758
[Epoch 28] ogbg-moltox21: 0.855996 test loss: 0.196118
[Epoch 29; Iter    28/  209] train: loss: 0.1162727
[Epoch 29; Iter    58/  209] train: loss: 0.1818757
[Epoch 29; Iter    88/  209] train: loss: 0.1317576
[Epoch 29; Iter   118/  209] train: loss: 0.2279969
[Epoch 29; Iter   148/  209] train: loss: 0.1632275
[Epoch 29; Iter   178/  209] train: loss: 0.1454427
[Epoch 29; Iter   208/  209] train: loss: 0.0940304
[Epoch 29] ogbg-moltox21: 0.866535 val loss: 0.192746
[Epoch 29] ogbg-moltox21: 0.853331 test loss: 0.188940
[Epoch 30; Iter    29/  209] train: loss: 0.1659042
[Epoch 30; Iter    59/  209] train: loss: 0.1073241
[Epoch 13; Iter    12/  209] train: loss: 0.1709494
[Epoch 13; Iter    42/  209] train: loss: 0.1531802
[Epoch 13; Iter    72/  209] train: loss: 0.1397986
[Epoch 13; Iter   102/  209] train: loss: 0.2364521
[Epoch 13; Iter   132/  209] train: loss: 0.1725052
[Epoch 13; Iter   162/  209] train: loss: 0.1937418
[Epoch 13; Iter   192/  209] train: loss: 0.1996091
[Epoch 13] ogbg-moltox21: 0.839027 val loss: 0.211006
[Epoch 13] ogbg-moltox21: 0.812910 test loss: 0.207405
[Epoch 14; Iter    13/  209] train: loss: 0.1506291
[Epoch 14; Iter    43/  209] train: loss: 0.1319366
[Epoch 14; Iter    73/  209] train: loss: 0.1709900
[Epoch 14; Iter   103/  209] train: loss: 0.2105775
[Epoch 14; Iter   133/  209] train: loss: 0.1441075
[Epoch 14; Iter   163/  209] train: loss: 0.1280416
[Epoch 14; Iter   193/  209] train: loss: 0.3277630
[Epoch 14] ogbg-moltox21: 0.841564 val loss: 0.212459
[Epoch 14] ogbg-moltox21: 0.825500 test loss: 0.209918
[Epoch 15; Iter    14/  209] train: loss: 0.1720458
[Epoch 15; Iter    44/  209] train: loss: 0.2266938
[Epoch 15; Iter    74/  209] train: loss: 0.1847216
[Epoch 15; Iter   104/  209] train: loss: 0.2524834
[Epoch 15; Iter   134/  209] train: loss: 0.1010244
[Epoch 15; Iter   164/  209] train: loss: 0.2345851
[Epoch 15; Iter   194/  209] train: loss: 0.1296968
[Epoch 15] ogbg-moltox21: 0.846592 val loss: 0.200482
[Epoch 15] ogbg-moltox21: 0.839233 test loss: 0.192770
[Epoch 16; Iter    15/  209] train: loss: 0.1756756
[Epoch 16; Iter    45/  209] train: loss: 0.1836568
[Epoch 16; Iter    75/  209] train: loss: 0.1403754
[Epoch 16; Iter   105/  209] train: loss: 0.1774181
[Epoch 16; Iter   135/  209] train: loss: 0.1642123
[Epoch 16; Iter   165/  209] train: loss: 0.1566649
[Epoch 16; Iter   195/  209] train: loss: 0.2086240
[Epoch 16] ogbg-moltox21: 0.844160 val loss: 0.207551
[Epoch 16] ogbg-moltox21: 0.823018 test loss: 0.203325
[Epoch 17; Iter    16/  209] train: loss: 0.1716092
[Epoch 17; Iter    46/  209] train: loss: 0.1394582
[Epoch 17; Iter    76/  209] train: loss: 0.1395645
[Epoch 17; Iter   106/  209] train: loss: 0.1309835
[Epoch 17; Iter   136/  209] train: loss: 0.1810941
[Epoch 17; Iter   166/  209] train: loss: 0.1781423
[Epoch 17; Iter   196/  209] train: loss: 0.1640643
[Epoch 17] ogbg-moltox21: 0.847012 val loss: 0.207552
[Epoch 17] ogbg-moltox21: 0.847276 test loss: 0.196431
[Epoch 18; Iter    17/  209] train: loss: 0.2004420
[Epoch 18; Iter    47/  209] train: loss: 0.1993670
[Epoch 18; Iter    77/  209] train: loss: 0.2241638
[Epoch 18; Iter   107/  209] train: loss: 0.1194101
[Epoch 18; Iter   137/  209] train: loss: 0.1379820
[Epoch 18; Iter   167/  209] train: loss: 0.1997759
[Epoch 18; Iter   197/  209] train: loss: 0.2405040
[Epoch 18] ogbg-moltox21: 0.849428 val loss: 0.202257
[Epoch 18] ogbg-moltox21: 0.840435 test loss: 0.196203
[Epoch 19; Iter    18/  209] train: loss: 0.2212151
[Epoch 19; Iter    48/  209] train: loss: 0.2417891
[Epoch 19; Iter    78/  209] train: loss: 0.1487943
[Epoch 19; Iter   108/  209] train: loss: 0.3043139
[Epoch 19; Iter   138/  209] train: loss: 0.2438278
[Epoch 19; Iter   168/  209] train: loss: 0.1681103
[Epoch 19; Iter   198/  209] train: loss: 0.1690457
[Epoch 19] ogbg-moltox21: 0.837361 val loss: 0.216211
[Epoch 19] ogbg-moltox21: 0.841519 test loss: 0.201266
[Epoch 20; Iter    19/  209] train: loss: 0.1925133
[Epoch 20; Iter    49/  209] train: loss: 0.1662999
[Epoch 20; Iter    79/  209] train: loss: 0.1603752
[Epoch 20; Iter   109/  209] train: loss: 0.2015245
[Epoch 20; Iter   139/  209] train: loss: 0.2221665
[Epoch 20; Iter   169/  209] train: loss: 0.1833839
[Epoch 20; Iter   199/  209] train: loss: 0.1726546
[Epoch 20] ogbg-moltox21: 0.846088 val loss: 0.203949
[Epoch 20] ogbg-moltox21: 0.839123 test loss: 0.192663
[Epoch 21; Iter    20/  209] train: loss: 0.1348169
[Epoch 21; Iter    50/  209] train: loss: 0.1550039
[Epoch 21; Iter    80/  209] train: loss: 0.1292042
[Epoch 21; Iter   110/  209] train: loss: 0.1339813
[Epoch 21; Iter   140/  209] train: loss: 0.2005068
[Epoch 21; Iter   170/  209] train: loss: 0.1777473
[Epoch 21; Iter   200/  209] train: loss: 0.1681689
[Epoch 21] ogbg-moltox21: 0.846109 val loss: 0.208911
[Epoch 21] ogbg-moltox21: 0.841256 test loss: 0.196888
[Epoch 22; Iter    21/  209] train: loss: 0.1772328
[Epoch 22; Iter    51/  209] train: loss: 0.1001756
[Epoch 22; Iter    81/  209] train: loss: 0.1458192
[Epoch 22; Iter   111/  209] train: loss: 0.2176003
[Epoch 22; Iter   141/  209] train: loss: 0.1567257
[Epoch 22; Iter   171/  209] train: loss: 0.2092737
[Epoch 22; Iter   201/  209] train: loss: 0.1250018
[Epoch 22] ogbg-moltox21: 0.850438 val loss: 0.289243
[Epoch 22] ogbg-moltox21: 0.833335 test loss: 0.201099
[Epoch 23; Iter    22/  209] train: loss: 0.1749446
[Epoch 23; Iter    52/  209] train: loss: 0.3014001
[Epoch 23; Iter    82/  209] train: loss: 0.3019900
[Epoch 23; Iter   112/  209] train: loss: 0.2143750
[Epoch 23; Iter   142/  209] train: loss: 0.1714192
[Epoch 23; Iter   172/  209] train: loss: 0.1716544
[Epoch 23; Iter   202/  209] train: loss: 0.2138961
[Epoch 23] ogbg-moltox21: 0.791232 val loss: 0.249120
[Epoch 23] ogbg-moltox21: 0.771632 test loss: 0.236869
[Epoch 24; Iter    23/  209] train: loss: 0.1424090
[Epoch 24; Iter    53/  209] train: loss: 0.1394497
[Epoch 24; Iter    83/  209] train: loss: 0.2082662
[Epoch 24; Iter   113/  209] train: loss: 0.2159669
[Epoch 24; Iter   143/  209] train: loss: 0.2309388
[Epoch 24; Iter   173/  209] train: loss: 0.1421492
[Epoch 24; Iter   203/  209] train: loss: 0.2150461
[Epoch 24] ogbg-moltox21: 0.818482 val loss: 0.225485
[Epoch 24] ogbg-moltox21: 0.784573 test loss: 0.220516
[Epoch 25; Iter    24/  209] train: loss: 0.2227825
[Epoch 25; Iter    54/  209] train: loss: 0.1700041
[Epoch 25; Iter    84/  209] train: loss: 0.1832540
[Epoch 25; Iter   114/  209] train: loss: 0.2615542
[Epoch 25; Iter   144/  209] train: loss: 0.1874835
[Epoch 25; Iter   174/  209] train: loss: 0.1823764
[Epoch 25; Iter   204/  209] train: loss: 0.2015928
[Epoch 25] ogbg-moltox21: 0.829717 val loss: 0.220780
[Epoch 25] ogbg-moltox21: 0.804862 test loss: 0.216385
[Epoch 26; Iter    25/  209] train: loss: 0.1509184
[Epoch 26; Iter    55/  209] train: loss: 0.1798171
[Epoch 26; Iter    85/  209] train: loss: 0.0919208
[Epoch 26; Iter   115/  209] train: loss: 0.2324029
[Epoch 26; Iter   145/  209] train: loss: 0.1267370
[Epoch 26; Iter   175/  209] train: loss: 0.3701843
[Epoch 26; Iter   205/  209] train: loss: 0.1823178
[Epoch 26] ogbg-moltox21: 0.843931 val loss: 0.209936
[Epoch 26] ogbg-moltox21: 0.834714 test loss: 0.205502
[Epoch 27; Iter    26/  209] train: loss: 0.2227830
[Epoch 27; Iter    56/  209] train: loss: 0.1944191
[Epoch 27; Iter    86/  209] train: loss: 0.1400895
[Epoch 27; Iter   116/  209] train: loss: 0.1615046
[Epoch 27; Iter   146/  209] train: loss: 0.1429704
[Epoch 27; Iter   176/  209] train: loss: 0.1625267
[Epoch 27; Iter   206/  209] train: loss: 0.1890572
[Epoch 27] ogbg-moltox21: 0.847961 val loss: 0.201663
[Epoch 27] ogbg-moltox21: 0.824582 test loss: 0.202699
[Epoch 28; Iter    27/  209] train: loss: 0.1770492
[Epoch 28; Iter    57/  209] train: loss: 0.1304780
[Epoch 28; Iter    87/  209] train: loss: 0.1155762
[Epoch 28; Iter   117/  209] train: loss: 0.2795047
[Epoch 28; Iter   147/  209] train: loss: 0.1582155
[Epoch 28; Iter   177/  209] train: loss: 0.1714841
[Epoch 28; Iter   207/  209] train: loss: 0.1505477
[Epoch 28] ogbg-moltox21: 0.847394 val loss: 0.206184
[Epoch 28] ogbg-moltox21: 0.831721 test loss: 0.195789
[Epoch 29; Iter    28/  209] train: loss: 0.1170160
[Epoch 29; Iter    58/  209] train: loss: 0.1944385
[Epoch 29; Iter    88/  209] train: loss: 0.1715338
[Epoch 29; Iter   118/  209] train: loss: 0.2018200
[Epoch 29; Iter   148/  209] train: loss: 0.1149090
[Epoch 29; Iter   178/  209] train: loss: 0.2161555
[Epoch 29; Iter   208/  209] train: loss: 0.2104186
[Epoch 29] ogbg-moltox21: 0.844342 val loss: 0.206472
[Epoch 29] ogbg-moltox21: 0.840893 test loss: 0.200133
[Epoch 30; Iter    29/  209] train: loss: 0.1272964
[Epoch 30; Iter    59/  209] train: loss: 0.0989260
[Epoch 13; Iter    12/  209] train: loss: 0.1554630
[Epoch 13; Iter    42/  209] train: loss: 0.1972171
[Epoch 13; Iter    72/  209] train: loss: 0.1176077
[Epoch 13; Iter   102/  209] train: loss: 0.2103268
[Epoch 13; Iter   132/  209] train: loss: 0.1847910
[Epoch 13; Iter   162/  209] train: loss: 0.2279764
[Epoch 13; Iter   192/  209] train: loss: 0.2967665
[Epoch 13] ogbg-moltox21: 0.816157 val loss: 0.297717
[Epoch 13] ogbg-moltox21: 0.767620 test loss: 0.230624
[Epoch 14; Iter    13/  209] train: loss: 0.1797905
[Epoch 14; Iter    43/  209] train: loss: 0.0927695
[Epoch 14; Iter    73/  209] train: loss: 0.2468991
[Epoch 14; Iter   103/  209] train: loss: 0.1984225
[Epoch 14; Iter   133/  209] train: loss: 0.2277988
[Epoch 14; Iter   163/  209] train: loss: 0.2044803
[Epoch 14; Iter   193/  209] train: loss: 0.2513382
[Epoch 14] ogbg-moltox21: 0.815307 val loss: 0.247782
[Epoch 14] ogbg-moltox21: 0.793449 test loss: 0.257672
[Epoch 15; Iter    14/  209] train: loss: 0.2186927
[Epoch 15; Iter    44/  209] train: loss: 0.1846174
[Epoch 15; Iter    74/  209] train: loss: 0.1404849
[Epoch 15; Iter   104/  209] train: loss: 0.1460916
[Epoch 15; Iter   134/  209] train: loss: 0.1898575
[Epoch 15; Iter   164/  209] train: loss: 0.1524260
[Epoch 15; Iter   194/  209] train: loss: 0.2603442
[Epoch 15] ogbg-moltox21: 0.817184 val loss: 0.224658
[Epoch 15] ogbg-moltox21: 0.816100 test loss: 0.215966
[Epoch 16; Iter    15/  209] train: loss: 0.2474234
[Epoch 16; Iter    45/  209] train: loss: 0.1719665
[Epoch 16; Iter    75/  209] train: loss: 0.1537138
[Epoch 16; Iter   105/  209] train: loss: 0.1930477
[Epoch 16; Iter   135/  209] train: loss: 0.2502962
[Epoch 16; Iter   165/  209] train: loss: 0.1375166
[Epoch 16; Iter   195/  209] train: loss: 0.2072843
[Epoch 16] ogbg-moltox21: 0.830580 val loss: 0.215217
[Epoch 16] ogbg-moltox21: 0.808057 test loss: 0.219964
[Epoch 17; Iter    16/  209] train: loss: 0.1804257
[Epoch 17; Iter    46/  209] train: loss: 0.2522007
[Epoch 17; Iter    76/  209] train: loss: 0.1834079
[Epoch 17; Iter   106/  209] train: loss: 0.1610218
[Epoch 17; Iter   136/  209] train: loss: 0.1886830
[Epoch 17; Iter   166/  209] train: loss: 0.1553858
[Epoch 17; Iter   196/  209] train: loss: 0.2386039
[Epoch 17] ogbg-moltox21: 0.819724 val loss: 0.230961
[Epoch 17] ogbg-moltox21: 0.802632 test loss: 0.221437
[Epoch 18; Iter    17/  209] train: loss: 0.1533318
[Epoch 18; Iter    47/  209] train: loss: 0.1641296
[Epoch 18; Iter    77/  209] train: loss: 0.2245696
[Epoch 18; Iter   107/  209] train: loss: 0.2667535
[Epoch 18; Iter   137/  209] train: loss: 0.2340469
[Epoch 18; Iter   167/  209] train: loss: 0.2239910
[Epoch 18; Iter   197/  209] train: loss: 0.1676572
[Epoch 18] ogbg-moltox21: 0.829482 val loss: 0.256067
[Epoch 18] ogbg-moltox21: 0.832357 test loss: 0.233191
[Epoch 19; Iter    18/  209] train: loss: 0.1881441
[Epoch 19; Iter    48/  209] train: loss: 0.1497823
[Epoch 19; Iter    78/  209] train: loss: 0.1459049
[Epoch 19; Iter   108/  209] train: loss: 0.0931334
[Epoch 19; Iter   138/  209] train: loss: 0.2097528
[Epoch 19; Iter   168/  209] train: loss: 0.1563444
[Epoch 19; Iter   198/  209] train: loss: 0.1645701
[Epoch 19] ogbg-moltox21: 0.845688 val loss: 0.211509
[Epoch 19] ogbg-moltox21: 0.837888 test loss: 0.209178
[Epoch 20; Iter    19/  209] train: loss: 0.1927551
[Epoch 20; Iter    49/  209] train: loss: 0.1678226
[Epoch 20; Iter    79/  209] train: loss: 0.2406687
[Epoch 20; Iter   109/  209] train: loss: 0.2975110
[Epoch 20; Iter   139/  209] train: loss: 0.1419846
[Epoch 20; Iter   169/  209] train: loss: 0.1733491
[Epoch 20; Iter   199/  209] train: loss: 0.2060767
[Epoch 20] ogbg-moltox21: 0.855114 val loss: 0.225995
[Epoch 20] ogbg-moltox21: 0.836257 test loss: 0.288779
[Epoch 21; Iter    20/  209] train: loss: 0.1677694
[Epoch 21; Iter    50/  209] train: loss: 0.1403125
[Epoch 21; Iter    80/  209] train: loss: 0.1176971
[Epoch 21; Iter   110/  209] train: loss: 0.2332926
[Epoch 21; Iter   140/  209] train: loss: 0.1601926
[Epoch 21; Iter   170/  209] train: loss: 0.1779753
[Epoch 21; Iter   200/  209] train: loss: 0.1638842
[Epoch 21] ogbg-moltox21: 0.861833 val loss: 0.200733
[Epoch 21] ogbg-moltox21: 0.836595 test loss: 0.197069
[Epoch 22; Iter    21/  209] train: loss: 0.0860401
[Epoch 22; Iter    51/  209] train: loss: 0.1770318
[Epoch 22; Iter    81/  209] train: loss: 0.2283178
[Epoch 22; Iter   111/  209] train: loss: 0.1686483
[Epoch 22; Iter   141/  209] train: loss: 0.1720396
[Epoch 22; Iter   171/  209] train: loss: 0.1478923
[Epoch 22; Iter   201/  209] train: loss: 0.1848107
[Epoch 22] ogbg-moltox21: 0.861008 val loss: 0.197518
[Epoch 22] ogbg-moltox21: 0.834950 test loss: 0.193857
[Epoch 23; Iter    22/  209] train: loss: 0.1365282
[Epoch 23; Iter    52/  209] train: loss: 0.1827331
[Epoch 23; Iter    82/  209] train: loss: 0.1580983
[Epoch 23; Iter   112/  209] train: loss: 0.1143048
[Epoch 23; Iter   142/  209] train: loss: 0.2161283
[Epoch 23; Iter   172/  209] train: loss: 0.1952622
[Epoch 23; Iter   202/  209] train: loss: 0.1949061
[Epoch 23] ogbg-moltox21: 0.842632 val loss: 0.207496
[Epoch 23] ogbg-moltox21: 0.838533 test loss: 0.198956
[Epoch 24; Iter    23/  209] train: loss: 0.2162857
[Epoch 24; Iter    53/  209] train: loss: 0.2707202
[Epoch 24; Iter    83/  209] train: loss: 0.1430539
[Epoch 24; Iter   113/  209] train: loss: 0.1580310
[Epoch 24; Iter   143/  209] train: loss: 0.1776560
[Epoch 24; Iter   173/  209] train: loss: 0.2316910
[Epoch 24; Iter   203/  209] train: loss: 0.1265137
[Epoch 24] ogbg-moltox21: 0.851444 val loss: 0.205908
[Epoch 24] ogbg-moltox21: 0.837265 test loss: 0.199576
[Epoch 25; Iter    24/  209] train: loss: 0.1912755
[Epoch 25; Iter    54/  209] train: loss: 0.1631017
[Epoch 25; Iter    84/  209] train: loss: 0.1947914
[Epoch 25; Iter   114/  209] train: loss: 0.1799018
[Epoch 25; Iter   144/  209] train: loss: 0.0899760
[Epoch 25; Iter   174/  209] train: loss: 0.1924796
[Epoch 25; Iter   204/  209] train: loss: 0.1126026
[Epoch 25] ogbg-moltox21: 0.844162 val loss: 0.202450
[Epoch 25] ogbg-moltox21: 0.839823 test loss: 0.313929
[Epoch 26; Iter    25/  209] train: loss: 0.1511751
[Epoch 26; Iter    55/  209] train: loss: 0.1230419
[Epoch 26; Iter    85/  209] train: loss: 0.1610249
[Epoch 26; Iter   115/  209] train: loss: 0.1700662
[Epoch 26; Iter   145/  209] train: loss: 0.1312671
[Epoch 26; Iter   175/  209] train: loss: 0.2286046
[Epoch 26; Iter   205/  209] train: loss: 0.1124312
[Epoch 26] ogbg-moltox21: 0.852704 val loss: 0.198116
[Epoch 26] ogbg-moltox21: 0.828258 test loss: 0.414341
[Epoch 27; Iter    26/  209] train: loss: 0.1100398
[Epoch 27; Iter    56/  209] train: loss: 0.0964365
[Epoch 27; Iter    86/  209] train: loss: 0.1126947
[Epoch 27; Iter   116/  209] train: loss: 0.2437001
[Epoch 27; Iter   146/  209] train: loss: 0.1003232
[Epoch 27; Iter   176/  209] train: loss: 0.1234555
[Epoch 27; Iter   206/  209] train: loss: 0.1650804
[Epoch 27] ogbg-moltox21: 0.862062 val loss: 0.198347
[Epoch 27] ogbg-moltox21: 0.840440 test loss: 0.222270
[Epoch 28; Iter    27/  209] train: loss: 0.2041396
[Epoch 28; Iter    57/  209] train: loss: 0.2626084
[Epoch 28; Iter    87/  209] train: loss: 0.1799535
[Epoch 28; Iter   117/  209] train: loss: 0.1555513
[Epoch 28; Iter   147/  209] train: loss: 0.1633484
[Epoch 28; Iter   177/  209] train: loss: 0.1158151
[Epoch 28; Iter   207/  209] train: loss: 0.1808561
[Epoch 28] ogbg-moltox21: 0.850557 val loss: 0.201916
[Epoch 28] ogbg-moltox21: 0.846278 test loss: 0.188284
[Epoch 29; Iter    28/  209] train: loss: 0.1466407
[Epoch 29; Iter    58/  209] train: loss: 0.1806634
[Epoch 29; Iter    88/  209] train: loss: 0.1550630
[Epoch 29; Iter   118/  209] train: loss: 0.2528267
[Epoch 29; Iter   148/  209] train: loss: 0.1492035
[Epoch 29; Iter   178/  209] train: loss: 0.1596877
[Epoch 29; Iter   208/  209] train: loss: 0.0935789
[Epoch 29] ogbg-moltox21: 0.864338 val loss: 0.198843
[Epoch 29] ogbg-moltox21: 0.850779 test loss: 0.189414
[Epoch 30; Iter    29/  209] train: loss: 0.1465857
[Epoch 30; Iter    59/  209] train: loss: 0.1436251
[Epoch 14; Iter    81/  183] train: loss: 0.1928110
[Epoch 14; Iter   111/  183] train: loss: 0.1955114
[Epoch 14; Iter   141/  183] train: loss: 0.1628189
[Epoch 14; Iter   171/  183] train: loss: 0.1915886
[Epoch 14] ogbg-moltox21: 0.811075 val loss: 0.209616
[Epoch 14] ogbg-moltox21: 0.824919 test loss: 0.213167
[Epoch 15; Iter    18/  183] train: loss: 0.1635139
[Epoch 15; Iter    48/  183] train: loss: 0.1328752
[Epoch 15; Iter    78/  183] train: loss: 0.2078310
[Epoch 15; Iter   108/  183] train: loss: 0.1244986
[Epoch 15; Iter   138/  183] train: loss: 0.1238678
[Epoch 15; Iter   168/  183] train: loss: 0.1882972
[Epoch 15] ogbg-moltox21: 0.812193 val loss: 0.202720
[Epoch 15] ogbg-moltox21: 0.827612 test loss: 0.206178
[Epoch 16; Iter    15/  183] train: loss: 0.1544773
[Epoch 16; Iter    45/  183] train: loss: 0.1416626
[Epoch 16; Iter    75/  183] train: loss: 0.2317740
[Epoch 16; Iter   105/  183] train: loss: 0.1459659
[Epoch 16; Iter   135/  183] train: loss: 0.1577324
[Epoch 16; Iter   165/  183] train: loss: 0.2132172
[Epoch 16] ogbg-moltox21: 0.806284 val loss: 0.205263
[Epoch 16] ogbg-moltox21: 0.828111 test loss: 0.202505
[Epoch 17; Iter    12/  183] train: loss: 0.1419762
[Epoch 17; Iter    42/  183] train: loss: 0.1690989
[Epoch 17; Iter    72/  183] train: loss: 0.1304695
[Epoch 17; Iter   102/  183] train: loss: 0.2859755
[Epoch 17; Iter   132/  183] train: loss: 0.2491623
[Epoch 17; Iter   162/  183] train: loss: 0.2505815
[Epoch 17] ogbg-moltox21: 0.824338 val loss: 0.206285
[Epoch 17] ogbg-moltox21: 0.834943 test loss: 0.216270
[Epoch 18; Iter     9/  183] train: loss: 0.2125087
[Epoch 18; Iter    39/  183] train: loss: 0.1523283
[Epoch 18; Iter    69/  183] train: loss: 0.1258100
[Epoch 18; Iter    99/  183] train: loss: 0.1359146
[Epoch 18; Iter   129/  183] train: loss: 0.2487215
[Epoch 18; Iter   159/  183] train: loss: 0.2170633
[Epoch 18] ogbg-moltox21: 0.822364 val loss: 0.197893
[Epoch 18] ogbg-moltox21: 0.830389 test loss: 0.206225
[Epoch 19; Iter     6/  183] train: loss: 0.1325668
[Epoch 19; Iter    36/  183] train: loss: 0.1785301
[Epoch 19; Iter    66/  183] train: loss: 0.2991965
[Epoch 19; Iter    96/  183] train: loss: 0.1809844
[Epoch 19; Iter   126/  183] train: loss: 0.1594883
[Epoch 19; Iter   156/  183] train: loss: 0.1753853
[Epoch 19] ogbg-moltox21: 0.810392 val loss: 0.201706
[Epoch 19] ogbg-moltox21: 0.818459 test loss: 0.210320
[Epoch 20; Iter     3/  183] train: loss: 0.1882385
[Epoch 20; Iter    33/  183] train: loss: 0.1617807
[Epoch 20; Iter    63/  183] train: loss: 0.1683044
[Epoch 20; Iter    93/  183] train: loss: 0.2139459
[Epoch 20; Iter   123/  183] train: loss: 0.1927056
[Epoch 20; Iter   153/  183] train: loss: 0.1646140
[Epoch 20; Iter   183/  183] train: loss: 0.1959865
[Epoch 20] ogbg-moltox21: 0.828275 val loss: 0.194959
[Epoch 20] ogbg-moltox21: 0.830567 test loss: 0.199318
[Epoch 21; Iter    30/  183] train: loss: 0.1244558
[Epoch 21; Iter    60/  183] train: loss: 0.1812812
[Epoch 21; Iter    90/  183] train: loss: 0.1769748
[Epoch 21; Iter   120/  183] train: loss: 0.1472402
[Epoch 21; Iter   150/  183] train: loss: 0.2011243
[Epoch 21; Iter   180/  183] train: loss: 0.2032775
[Epoch 21] ogbg-moltox21: 0.805476 val loss: 0.202505
[Epoch 21] ogbg-moltox21: 0.819429 test loss: 0.205659
[Epoch 22; Iter    27/  183] train: loss: 0.1170575
[Epoch 22; Iter    57/  183] train: loss: 0.1995304
[Epoch 22; Iter    87/  183] train: loss: 0.1982009
[Epoch 22; Iter   117/  183] train: loss: 0.2029745
[Epoch 22; Iter   147/  183] train: loss: 0.2171537
[Epoch 22; Iter   177/  183] train: loss: 0.2836217
[Epoch 22] ogbg-moltox21: 0.824760 val loss: 0.196538
[Epoch 22] ogbg-moltox21: 0.847593 test loss: 0.195664
[Epoch 23; Iter    24/  183] train: loss: 0.2616132
[Epoch 23; Iter    54/  183] train: loss: 0.1769408
[Epoch 23; Iter    84/  183] train: loss: 0.1737865
[Epoch 23; Iter   114/  183] train: loss: 0.1744863
[Epoch 23; Iter   144/  183] train: loss: 0.1611736
[Epoch 23; Iter   174/  183] train: loss: 0.1980822
[Epoch 23] ogbg-moltox21: 0.833284 val loss: 0.194845
[Epoch 23] ogbg-moltox21: 0.839117 test loss: 0.203014
[Epoch 24; Iter    21/  183] train: loss: 0.1968732
[Epoch 24; Iter    51/  183] train: loss: 0.1739308
[Epoch 24; Iter    81/  183] train: loss: 0.2344822
[Epoch 24; Iter   111/  183] train: loss: 0.1939127
[Epoch 24; Iter   141/  183] train: loss: 0.1482865
[Epoch 24; Iter   171/  183] train: loss: 0.1271942
[Epoch 24] ogbg-moltox21: 0.829091 val loss: 0.194552
[Epoch 24] ogbg-moltox21: 0.840125 test loss: 0.200973
[Epoch 25; Iter    18/  183] train: loss: 0.1758312
[Epoch 25; Iter    48/  183] train: loss: 0.2015973
[Epoch 25; Iter    78/  183] train: loss: 0.1242488
[Epoch 25; Iter   108/  183] train: loss: 0.2518666
[Epoch 25; Iter   138/  183] train: loss: 0.1543666
[Epoch 25; Iter   168/  183] train: loss: 0.1996469
[Epoch 25] ogbg-moltox21: 0.824165 val loss: 0.197244
[Epoch 25] ogbg-moltox21: 0.832614 test loss: 0.203762
[Epoch 26; Iter    15/  183] train: loss: 0.1543103
[Epoch 26; Iter    45/  183] train: loss: 0.1848621
[Epoch 26; Iter    75/  183] train: loss: 0.1802609
[Epoch 26; Iter   105/  183] train: loss: 0.2171547
[Epoch 26; Iter   135/  183] train: loss: 0.1512696
[Epoch 26; Iter   165/  183] train: loss: 0.1543339
[Epoch 26] ogbg-moltox21: 0.827900 val loss: 0.191578
[Epoch 26] ogbg-moltox21: 0.837053 test loss: 0.197985
[Epoch 27; Iter    12/  183] train: loss: 0.1264958
[Epoch 27; Iter    42/  183] train: loss: 0.1860347
[Epoch 27; Iter    72/  183] train: loss: 0.1722070
[Epoch 27; Iter   102/  183] train: loss: 0.2028836
[Epoch 27; Iter   132/  183] train: loss: 0.2103166
[Epoch 27; Iter   162/  183] train: loss: 0.1249883
[Epoch 27] ogbg-moltox21: 0.828284 val loss: 0.219770
[Epoch 27] ogbg-moltox21: 0.844596 test loss: 0.198126
[Epoch 28; Iter     9/  183] train: loss: 0.2070350
[Epoch 28; Iter    39/  183] train: loss: 0.2707592
[Epoch 28; Iter    69/  183] train: loss: 0.1916611
[Epoch 28; Iter    99/  183] train: loss: 0.1381658
[Epoch 28; Iter   129/  183] train: loss: 0.2829092
[Epoch 28; Iter   159/  183] train: loss: 0.0979885
[Epoch 28] ogbg-moltox21: 0.828611 val loss: 0.192180
[Epoch 28] ogbg-moltox21: 0.843714 test loss: 0.194605
[Epoch 29; Iter     6/  183] train: loss: 0.2120313
[Epoch 29; Iter    36/  183] train: loss: 0.1738470
[Epoch 29; Iter    66/  183] train: loss: 0.2870881
[Epoch 29; Iter    96/  183] train: loss: 0.1677104
[Epoch 29; Iter   126/  183] train: loss: 0.1747995
[Epoch 29; Iter   156/  183] train: loss: 0.2034415
[Epoch 29] ogbg-moltox21: 0.814624 val loss: 0.201004
[Epoch 29] ogbg-moltox21: 0.838085 test loss: 0.200422
[Epoch 30; Iter     3/  183] train: loss: 0.1355312
[Epoch 30; Iter    33/  183] train: loss: 0.1122926
[Epoch 30; Iter    63/  183] train: loss: 0.2125400
[Epoch 30; Iter    93/  183] train: loss: 0.2329315
[Epoch 30; Iter   123/  183] train: loss: 0.1802379
[Epoch 30; Iter   153/  183] train: loss: 0.2533337
[Epoch 30; Iter   183/  183] train: loss: 0.1336415
[Epoch 30] ogbg-moltox21: 0.820715 val loss: 0.199339
[Epoch 30] ogbg-moltox21: 0.838641 test loss: 0.199748
[Epoch 31; Iter    30/  183] train: loss: 0.1051269
[Epoch 31; Iter    60/  183] train: loss: 0.1756680
[Epoch 31; Iter    90/  183] train: loss: 0.1643344
[Epoch 31; Iter   120/  183] train: loss: 0.1990458
[Epoch 31; Iter   150/  183] train: loss: 0.1747682
[Epoch 31; Iter   180/  183] train: loss: 0.1928077
[Epoch 31] ogbg-moltox21: 0.831448 val loss: 0.197280
[Epoch 31] ogbg-moltox21: 0.844574 test loss: 0.198219
[Epoch 32; Iter    27/  183] train: loss: 0.1818895
[Epoch 32; Iter    57/  183] train: loss: 0.1192056
[Epoch 32; Iter    87/  183] train: loss: 0.2083512
[Epoch 32; Iter   117/  183] train: loss: 0.1512515
[Epoch 32; Iter   147/  183] train: loss: 0.1325163
[Epoch 32; Iter   177/  183] train: loss: 0.1298412
[Epoch 32] ogbg-moltox21: 0.836437 val loss: 0.193643
[Epoch 32] ogbg-moltox21: 0.850991 test loss: 0.194159
[Epoch 33; Iter    24/  183] train: loss: 0.2030091
[Epoch 33; Iter    54/  183] train: loss: 0.2118162
[Epoch 33; Iter    84/  183] train: loss: 0.1560055
[Epoch 14; Iter    81/  183] train: loss: 0.1409259
[Epoch 14; Iter   111/  183] train: loss: 0.2323284
[Epoch 14; Iter   141/  183] train: loss: 0.2392683
[Epoch 14; Iter   171/  183] train: loss: 0.2288345
[Epoch 14] ogbg-moltox21: 0.813483 val loss: 0.204787
[Epoch 14] ogbg-moltox21: 0.835793 test loss: 0.205719
[Epoch 15; Iter    18/  183] train: loss: 0.1428707
[Epoch 15; Iter    48/  183] train: loss: 0.1396867
[Epoch 15; Iter    78/  183] train: loss: 0.1481525
[Epoch 15; Iter   108/  183] train: loss: 0.1666593
[Epoch 15; Iter   138/  183] train: loss: 0.2173718
[Epoch 15; Iter   168/  183] train: loss: 0.1999511
[Epoch 15] ogbg-moltox21: 0.804977 val loss: 0.204946
[Epoch 15] ogbg-moltox21: 0.822608 test loss: 0.212503
[Epoch 16; Iter    15/  183] train: loss: 0.1374258
[Epoch 16; Iter    45/  183] train: loss: 0.1952965
[Epoch 16; Iter    75/  183] train: loss: 0.1457153
[Epoch 16; Iter   105/  183] train: loss: 0.1355786
[Epoch 16; Iter   135/  183] train: loss: 0.1322382
[Epoch 16; Iter   165/  183] train: loss: 0.1742667
[Epoch 16] ogbg-moltox21: 0.805468 val loss: 0.206779
[Epoch 16] ogbg-moltox21: 0.824447 test loss: 0.207617
[Epoch 17; Iter    12/  183] train: loss: 0.1437011
[Epoch 17; Iter    42/  183] train: loss: 0.1954684
[Epoch 17; Iter    72/  183] train: loss: 0.1465834
[Epoch 17; Iter   102/  183] train: loss: 0.1933026
[Epoch 17; Iter   132/  183] train: loss: 0.1773412
[Epoch 17; Iter   162/  183] train: loss: 0.1848463
[Epoch 17] ogbg-moltox21: 0.814746 val loss: 0.204747
[Epoch 17] ogbg-moltox21: 0.832191 test loss: 0.205433
[Epoch 18; Iter     9/  183] train: loss: 0.2480824
[Epoch 18; Iter    39/  183] train: loss: 0.2319601
[Epoch 18; Iter    69/  183] train: loss: 0.1617385
[Epoch 18; Iter    99/  183] train: loss: 0.2141132
[Epoch 18; Iter   129/  183] train: loss: 0.1510686
[Epoch 18; Iter   159/  183] train: loss: 0.1808940
[Epoch 18] ogbg-moltox21: 0.801489 val loss: 0.207040
[Epoch 18] ogbg-moltox21: 0.829706 test loss: 0.203712
[Epoch 19; Iter     6/  183] train: loss: 0.2299341
[Epoch 19; Iter    36/  183] train: loss: 0.1978002
[Epoch 19; Iter    66/  183] train: loss: 0.1896575
[Epoch 19; Iter    96/  183] train: loss: 0.2057824
[Epoch 19; Iter   126/  183] train: loss: 0.1299860
[Epoch 19; Iter   156/  183] train: loss: 0.1860741
[Epoch 19] ogbg-moltox21: 0.811149 val loss: 0.200626
[Epoch 19] ogbg-moltox21: 0.834315 test loss: 0.199590
[Epoch 20; Iter     3/  183] train: loss: 0.2319444
[Epoch 20; Iter    33/  183] train: loss: 0.2533303
[Epoch 20; Iter    63/  183] train: loss: 0.1203934
[Epoch 20; Iter    93/  183] train: loss: 0.1899452
[Epoch 20; Iter   123/  183] train: loss: 0.2013450
[Epoch 20; Iter   153/  183] train: loss: 0.2083869
[Epoch 20; Iter   183/  183] train: loss: 0.2479912
[Epoch 20] ogbg-moltox21: 0.818357 val loss: 0.197825
[Epoch 20] ogbg-moltox21: 0.838668 test loss: 0.202392
[Epoch 21; Iter    30/  183] train: loss: 0.1265763
[Epoch 21; Iter    60/  183] train: loss: 0.1572852
[Epoch 21; Iter    90/  183] train: loss: 0.1952436
[Epoch 21; Iter   120/  183] train: loss: 0.1819237
[Epoch 21; Iter   150/  183] train: loss: 0.1940241
[Epoch 21; Iter   180/  183] train: loss: 0.1794741
[Epoch 21] ogbg-moltox21: 0.824394 val loss: 0.201213
[Epoch 21] ogbg-moltox21: 0.848166 test loss: 0.202555
[Epoch 22; Iter    27/  183] train: loss: 0.2259203
[Epoch 22; Iter    57/  183] train: loss: 0.1627093
[Epoch 22; Iter    87/  183] train: loss: 0.2086623
[Epoch 22; Iter   117/  183] train: loss: 0.1741761
[Epoch 22; Iter   147/  183] train: loss: 0.1661924
[Epoch 22; Iter   177/  183] train: loss: 0.2081457
[Epoch 22] ogbg-moltox21: 0.812070 val loss: 0.202946
[Epoch 22] ogbg-moltox21: 0.835626 test loss: 0.203703
[Epoch 23; Iter    24/  183] train: loss: 0.1740443
[Epoch 23; Iter    54/  183] train: loss: 0.1457489
[Epoch 23; Iter    84/  183] train: loss: 0.1937739
[Epoch 23; Iter   114/  183] train: loss: 0.2233792
[Epoch 23; Iter   144/  183] train: loss: 0.2009655
[Epoch 23; Iter   174/  183] train: loss: 0.1430662
[Epoch 23] ogbg-moltox21: 0.806016 val loss: 0.207259
[Epoch 23] ogbg-moltox21: 0.838052 test loss: 0.206362
[Epoch 24; Iter    21/  183] train: loss: 0.1152965
[Epoch 24; Iter    51/  183] train: loss: 0.1890661
[Epoch 24; Iter    81/  183] train: loss: 0.1974008
[Epoch 24; Iter   111/  183] train: loss: 0.1957077
[Epoch 24; Iter   141/  183] train: loss: 0.1325577
[Epoch 24; Iter   171/  183] train: loss: 0.1292534
[Epoch 24] ogbg-moltox21: 0.820842 val loss: 0.200394
[Epoch 24] ogbg-moltox21: 0.837894 test loss: 0.200723
[Epoch 25; Iter    18/  183] train: loss: 0.1458855
[Epoch 25; Iter    48/  183] train: loss: 0.0885697
[Epoch 25; Iter    78/  183] train: loss: 0.1880189
[Epoch 25; Iter   108/  183] train: loss: 0.1938419
[Epoch 25; Iter   138/  183] train: loss: 0.1019800
[Epoch 25; Iter   168/  183] train: loss: 0.2164614
[Epoch 25] ogbg-moltox21: 0.814384 val loss: 0.201644
[Epoch 25] ogbg-moltox21: 0.834966 test loss: 0.202757
[Epoch 26; Iter    15/  183] train: loss: 0.1387893
[Epoch 26; Iter    45/  183] train: loss: 0.1975454
[Epoch 26; Iter    75/  183] train: loss: 0.1390415
[Epoch 26; Iter   105/  183] train: loss: 0.2007216
[Epoch 26; Iter   135/  183] train: loss: 0.1521861
[Epoch 26; Iter   165/  183] train: loss: 0.1328547
[Epoch 26] ogbg-moltox21: 0.821721 val loss: 0.202299
[Epoch 26] ogbg-moltox21: 0.845308 test loss: 0.200544
[Epoch 27; Iter    12/  183] train: loss: 0.2367881
[Epoch 27; Iter    42/  183] train: loss: 0.1645417
[Epoch 27; Iter    72/  183] train: loss: 0.1271783
[Epoch 27; Iter   102/  183] train: loss: 0.1611488
[Epoch 27; Iter   132/  183] train: loss: 0.1818269
[Epoch 27; Iter   162/  183] train: loss: 0.1113987
[Epoch 27] ogbg-moltox21: 0.818720 val loss: 0.201004
[Epoch 27] ogbg-moltox21: 0.842191 test loss: 0.199639
[Epoch 28; Iter     9/  183] train: loss: 0.1378771
[Epoch 28; Iter    39/  183] train: loss: 0.1741522
[Epoch 28; Iter    69/  183] train: loss: 0.1530927
[Epoch 28; Iter    99/  183] train: loss: 0.3007148
[Epoch 28; Iter   129/  183] train: loss: 0.2294207
[Epoch 28; Iter   159/  183] train: loss: 0.0899411
[Epoch 28] ogbg-moltox21: 0.821679 val loss: 0.232536
[Epoch 28] ogbg-moltox21: 0.837752 test loss: 0.201511
[Epoch 29; Iter     6/  183] train: loss: 0.1737551
[Epoch 29; Iter    36/  183] train: loss: 0.1328188
[Epoch 29; Iter    66/  183] train: loss: 0.1226952
[Epoch 29; Iter    96/  183] train: loss: 0.2746854
[Epoch 29; Iter   126/  183] train: loss: 0.1704593
[Epoch 29; Iter   156/  183] train: loss: 0.1440286
[Epoch 29] ogbg-moltox21: 0.793822 val loss: 0.207644
[Epoch 29] ogbg-moltox21: 0.825080 test loss: 0.210035
[Epoch 30; Iter     3/  183] train: loss: 0.1320366
[Epoch 30; Iter    33/  183] train: loss: 0.1959333
[Epoch 30; Iter    63/  183] train: loss: 0.1821181
[Epoch 30; Iter    93/  183] train: loss: 0.1976465
[Epoch 30; Iter   123/  183] train: loss: 0.2714688
[Epoch 30; Iter   153/  183] train: loss: 0.1269223
[Epoch 30; Iter   183/  183] train: loss: 0.1769366
[Epoch 30] ogbg-moltox21: 0.833907 val loss: 0.200304
[Epoch 30] ogbg-moltox21: 0.859011 test loss: 0.195328
[Epoch 31; Iter    30/  183] train: loss: 0.1433314
[Epoch 31; Iter    60/  183] train: loss: 0.1724409
[Epoch 31; Iter    90/  183] train: loss: 0.1644874
[Epoch 31; Iter   120/  183] train: loss: 0.1310183
[Epoch 31; Iter   150/  183] train: loss: 0.1507202
[Epoch 31; Iter   180/  183] train: loss: 0.1834880
[Epoch 31] ogbg-moltox21: 0.821775 val loss: 0.202249
[Epoch 31] ogbg-moltox21: 0.837070 test loss: 0.207010
[Epoch 32; Iter    27/  183] train: loss: 0.1640074
[Epoch 32; Iter    57/  183] train: loss: 0.3128992
[Epoch 32; Iter    87/  183] train: loss: 0.1419260
[Epoch 32; Iter   117/  183] train: loss: 0.1297905
[Epoch 32; Iter   147/  183] train: loss: 0.1989472
[Epoch 32; Iter   177/  183] train: loss: 0.1351659
[Epoch 32] ogbg-moltox21: 0.826913 val loss: 0.199936
[Epoch 32] ogbg-moltox21: 0.841092 test loss: 0.194532
[Epoch 33; Iter    24/  183] train: loss: 0.2070241
[Epoch 33; Iter    54/  183] train: loss: 0.1004426
[Epoch 33; Iter    84/  183] train: loss: 0.2129733
[Epoch 14; Iter    81/  183] train: loss: 0.2099155
[Epoch 14; Iter   111/  183] train: loss: 0.1951989
[Epoch 14; Iter   141/  183] train: loss: 0.2160826
[Epoch 14; Iter   171/  183] train: loss: 0.1410470
[Epoch 14] ogbg-moltox21: 0.758093 val loss: 0.235532
[Epoch 14] ogbg-moltox21: 0.782176 test loss: 0.231922
[Epoch 15; Iter    18/  183] train: loss: 0.3212620
[Epoch 15; Iter    48/  183] train: loss: 0.2024937
[Epoch 15; Iter    78/  183] train: loss: 0.1823860
[Epoch 15; Iter   108/  183] train: loss: 0.2543898
[Epoch 15; Iter   138/  183] train: loss: 0.2251326
[Epoch 15; Iter   168/  183] train: loss: 0.1569360
[Epoch 15] ogbg-moltox21: 0.783534 val loss: 0.225263
[Epoch 15] ogbg-moltox21: 0.800159 test loss: 0.226111
[Epoch 16; Iter    15/  183] train: loss: 0.1736954
[Epoch 16; Iter    45/  183] train: loss: 0.2314316
[Epoch 16; Iter    75/  183] train: loss: 0.1546415
[Epoch 16; Iter   105/  183] train: loss: 0.1576230
[Epoch 16; Iter   135/  183] train: loss: 0.1357479
[Epoch 16; Iter   165/  183] train: loss: 0.2263180
[Epoch 16] ogbg-moltox21: 0.799870 val loss: 0.209785
[Epoch 16] ogbg-moltox21: 0.820051 test loss: 0.215258
[Epoch 17; Iter    12/  183] train: loss: 0.2490366
[Epoch 17; Iter    42/  183] train: loss: 0.3880036
[Epoch 17; Iter    72/  183] train: loss: 0.2057399
[Epoch 17; Iter   102/  183] train: loss: 0.2120341
[Epoch 17; Iter   132/  183] train: loss: 0.2075327
[Epoch 17; Iter   162/  183] train: loss: 0.1939712
[Epoch 17] ogbg-moltox21: 0.809567 val loss: 0.207104
[Epoch 17] ogbg-moltox21: 0.823402 test loss: 0.209774
[Epoch 18; Iter     9/  183] train: loss: 0.1175738
[Epoch 18; Iter    39/  183] train: loss: 0.1308763
[Epoch 18; Iter    69/  183] train: loss: 0.3114100
[Epoch 18; Iter    99/  183] train: loss: 0.2230340
[Epoch 18; Iter   129/  183] train: loss: 0.3317314
[Epoch 18; Iter   159/  183] train: loss: 0.2302002
[Epoch 18] ogbg-moltox21: 0.808715 val loss: 0.207677
[Epoch 18] ogbg-moltox21: 0.818329 test loss: 0.209905
[Epoch 19; Iter     6/  183] train: loss: 0.1648948
[Epoch 19; Iter    36/  183] train: loss: 0.2965906
[Epoch 19; Iter    66/  183] train: loss: 0.1170713
[Epoch 19; Iter    96/  183] train: loss: 0.2217785
[Epoch 19; Iter   126/  183] train: loss: 0.1897416
[Epoch 19; Iter   156/  183] train: loss: 0.1803652
[Epoch 19] ogbg-moltox21: 0.812720 val loss: 0.206459
[Epoch 19] ogbg-moltox21: 0.832300 test loss: 0.208628
[Epoch 20; Iter     3/  183] train: loss: 0.1640974
[Epoch 20; Iter    33/  183] train: loss: 0.1577620
[Epoch 20; Iter    63/  183] train: loss: 0.1162299
[Epoch 20; Iter    93/  183] train: loss: 0.1254316
[Epoch 20; Iter   123/  183] train: loss: 0.1138385
[Epoch 20; Iter   153/  183] train: loss: 0.1690157
[Epoch 20; Iter   183/  183] train: loss: 0.2013961
[Epoch 20] ogbg-moltox21: 0.819980 val loss: 0.210586
[Epoch 20] ogbg-moltox21: 0.823828 test loss: 0.216318
[Epoch 21; Iter    30/  183] train: loss: 0.2587211
[Epoch 21; Iter    60/  183] train: loss: 0.1836245
[Epoch 21; Iter    90/  183] train: loss: 0.2450533
[Epoch 21; Iter   120/  183] train: loss: 0.1826112
[Epoch 21; Iter   150/  183] train: loss: 0.1664287
[Epoch 21; Iter   180/  183] train: loss: 0.1549724
[Epoch 21] ogbg-moltox21: 0.818338 val loss: 0.201365
[Epoch 21] ogbg-moltox21: 0.837532 test loss: 0.202789
[Epoch 22; Iter    27/  183] train: loss: 0.1047896
[Epoch 22; Iter    57/  183] train: loss: 0.1508240
[Epoch 22; Iter    87/  183] train: loss: 0.2109364
[Epoch 22; Iter   117/  183] train: loss: 0.1976251
[Epoch 22; Iter   147/  183] train: loss: 0.1891328
[Epoch 22; Iter   177/  183] train: loss: 0.1586801
[Epoch 22] ogbg-moltox21: 0.820946 val loss: 0.198504
[Epoch 22] ogbg-moltox21: 0.833163 test loss: 0.198979
[Epoch 23; Iter    24/  183] train: loss: 0.2034039
[Epoch 23; Iter    54/  183] train: loss: 0.1958521
[Epoch 23; Iter    84/  183] train: loss: 0.2025927
[Epoch 23; Iter   114/  183] train: loss: 0.1590312
[Epoch 23; Iter   144/  183] train: loss: 0.2073092
[Epoch 23; Iter   174/  183] train: loss: 0.2689282
[Epoch 23] ogbg-moltox21: 0.815955 val loss: 0.206970
[Epoch 23] ogbg-moltox21: 0.843890 test loss: 0.199204
[Epoch 24; Iter    21/  183] train: loss: 0.2133341
[Epoch 24; Iter    51/  183] train: loss: 0.1472033
[Epoch 24; Iter    81/  183] train: loss: 0.2141847
[Epoch 24; Iter   111/  183] train: loss: 0.1310364
[Epoch 24; Iter   141/  183] train: loss: 0.2200443
[Epoch 24; Iter   171/  183] train: loss: 0.2459605
[Epoch 24] ogbg-moltox21: 0.792963 val loss: 0.208584
[Epoch 24] ogbg-moltox21: 0.811721 test loss: 0.208595
[Epoch 25; Iter    18/  183] train: loss: 0.2755193
[Epoch 25; Iter    48/  183] train: loss: 0.1672052
[Epoch 25; Iter    78/  183] train: loss: 0.1498166
[Epoch 25; Iter   108/  183] train: loss: 0.1618955
[Epoch 25; Iter   138/  183] train: loss: 0.1956505
[Epoch 25; Iter   168/  183] train: loss: 0.2001030
[Epoch 25] ogbg-moltox21: 0.816793 val loss: 0.347037
[Epoch 25] ogbg-moltox21: 0.827545 test loss: 0.324915
[Epoch 26; Iter    15/  183] train: loss: 0.2057698
[Epoch 26; Iter    45/  183] train: loss: 0.1447953
[Epoch 26; Iter    75/  183] train: loss: 0.1173408
[Epoch 26; Iter   105/  183] train: loss: 0.1314389
[Epoch 26; Iter   135/  183] train: loss: 0.2940441
[Epoch 26; Iter   165/  183] train: loss: 0.1263729
[Epoch 26] ogbg-moltox21: 0.825637 val loss: 0.195821
[Epoch 26] ogbg-moltox21: 0.837580 test loss: 0.198430
[Epoch 27; Iter    12/  183] train: loss: 0.1813781
[Epoch 27; Iter    42/  183] train: loss: 0.2244689
[Epoch 27; Iter    72/  183] train: loss: 0.1749902
[Epoch 27; Iter   102/  183] train: loss: 0.1568408
[Epoch 27; Iter   132/  183] train: loss: 0.2418014
[Epoch 27; Iter   162/  183] train: loss: 0.1428583
[Epoch 27] ogbg-moltox21: 0.819410 val loss: 0.203441
[Epoch 27] ogbg-moltox21: 0.831526 test loss: 0.220084
[Epoch 28; Iter     9/  183] train: loss: 0.2579118
[Epoch 28; Iter    39/  183] train: loss: 0.2783624
[Epoch 28; Iter    69/  183] train: loss: 0.1355222
[Epoch 28; Iter    99/  183] train: loss: 0.1042773
[Epoch 28; Iter   129/  183] train: loss: 0.1584842
[Epoch 28; Iter   159/  183] train: loss: 0.2127015
[Epoch 28] ogbg-moltox21: 0.828710 val loss: 0.196230
[Epoch 28] ogbg-moltox21: 0.838721 test loss: 0.212757
[Epoch 29; Iter     6/  183] train: loss: 0.1935433
[Epoch 29; Iter    36/  183] train: loss: 0.2225897
[Epoch 29; Iter    66/  183] train: loss: 0.1360787
[Epoch 29; Iter    96/  183] train: loss: 0.2351643
[Epoch 29; Iter   126/  183] train: loss: 0.1689169
[Epoch 29; Iter   156/  183] train: loss: 0.1363393
[Epoch 29] ogbg-moltox21: 0.820066 val loss: 0.219584
[Epoch 29] ogbg-moltox21: 0.833549 test loss: 0.201797
[Epoch 30; Iter     3/  183] train: loss: 0.1763717
[Epoch 30; Iter    33/  183] train: loss: 0.2004892
[Epoch 30; Iter    63/  183] train: loss: 0.1930133
[Epoch 30; Iter    93/  183] train: loss: 0.2015757
[Epoch 30; Iter   123/  183] train: loss: 0.1453819
[Epoch 30; Iter   153/  183] train: loss: 0.1639686
[Epoch 30; Iter   183/  183] train: loss: 0.2190490
[Epoch 30] ogbg-moltox21: 0.819075 val loss: 0.206031
[Epoch 30] ogbg-moltox21: 0.842088 test loss: 0.205442
[Epoch 31; Iter    30/  183] train: loss: 0.2555164
[Epoch 31; Iter    60/  183] train: loss: 0.1409611
[Epoch 31; Iter    90/  183] train: loss: 0.1331544
[Epoch 31; Iter   120/  183] train: loss: 0.2943234
[Epoch 31; Iter   150/  183] train: loss: 0.1050350
[Epoch 31; Iter   180/  183] train: loss: 0.1759962
[Epoch 31] ogbg-moltox21: 0.828358 val loss: 0.211464
[Epoch 31] ogbg-moltox21: 0.845643 test loss: 0.198877
[Epoch 32; Iter    27/  183] train: loss: 0.1891948
[Epoch 32; Iter    57/  183] train: loss: 0.1820826
[Epoch 32; Iter    87/  183] train: loss: 0.0968219
[Epoch 32; Iter   117/  183] train: loss: 0.1761439
[Epoch 32; Iter   147/  183] train: loss: 0.2126047
[Epoch 32; Iter   177/  183] train: loss: 0.1762941
[Epoch 32] ogbg-moltox21: 0.825516 val loss: 0.199493
[Epoch 32] ogbg-moltox21: 0.840869 test loss: 0.198630
[Epoch 33; Iter    24/  183] train: loss: 0.1631813
[Epoch 33; Iter    54/  183] train: loss: 0.1561795
[Epoch 33; Iter    84/  183] train: loss: 0.2545513
[Epoch 15] ogbg-moltox21: 0.744658 test loss: 0.288187
[Epoch 16; Iter    15/  157] train: loss: 0.1666617
[Epoch 16; Iter    45/  157] train: loss: 0.1557022
[Epoch 16; Iter    75/  157] train: loss: 0.2901241
[Epoch 16; Iter   105/  157] train: loss: 0.1780153
[Epoch 16; Iter   135/  157] train: loss: 0.2455170
[Epoch 16] ogbg-moltox21: 0.776519 val loss: 0.207696
[Epoch 16] ogbg-moltox21: 0.788482 test loss: 0.224536
[Epoch 17; Iter     8/  157] train: loss: 0.1732106
[Epoch 17; Iter    38/  157] train: loss: 0.1708821
[Epoch 17; Iter    68/  157] train: loss: 0.2864520
[Epoch 17; Iter    98/  157] train: loss: 0.2261984
[Epoch 17; Iter   128/  157] train: loss: 0.1422307
[Epoch 17] ogbg-moltox21: 0.773982 val loss: 0.207745
[Epoch 17] ogbg-moltox21: 0.788722 test loss: 0.229004
[Epoch 18; Iter     1/  157] train: loss: 0.2161364
[Epoch 18; Iter    31/  157] train: loss: 0.1166004
[Epoch 18; Iter    61/  157] train: loss: 0.2385608
[Epoch 18; Iter    91/  157] train: loss: 0.1618056
[Epoch 18; Iter   121/  157] train: loss: 0.1213173
[Epoch 18; Iter   151/  157] train: loss: 0.1713818
[Epoch 18] ogbg-moltox21: 0.780869 val loss: 0.211606
[Epoch 18] ogbg-moltox21: 0.792055 test loss: 0.222092
[Epoch 19; Iter    24/  157] train: loss: 0.1625086
[Epoch 19; Iter    54/  157] train: loss: 0.1562719
[Epoch 19; Iter    84/  157] train: loss: 0.1857482
[Epoch 19; Iter   114/  157] train: loss: 0.2544698
[Epoch 19; Iter   144/  157] train: loss: 0.2470126
[Epoch 19] ogbg-moltox21: 0.803144 val loss: 0.201105
[Epoch 19] ogbg-moltox21: 0.810577 test loss: 0.219114
[Epoch 20; Iter    17/  157] train: loss: 0.1797871
[Epoch 20; Iter    47/  157] train: loss: 0.1290790
[Epoch 20; Iter    77/  157] train: loss: 0.1718429
[Epoch 20; Iter   107/  157] train: loss: 0.1666228
[Epoch 20; Iter   137/  157] train: loss: 0.1970374
[Epoch 20] ogbg-moltox21: 0.808404 val loss: 0.197493
[Epoch 20] ogbg-moltox21: 0.816060 test loss: 0.213529
[Epoch 21; Iter    10/  157] train: loss: 0.2628826
[Epoch 21; Iter    40/  157] train: loss: 0.2003161
[Epoch 21; Iter    70/  157] train: loss: 0.2241181
[Epoch 21; Iter   100/  157] train: loss: 0.2068588
[Epoch 21; Iter   130/  157] train: loss: 0.1047395
[Epoch 21] ogbg-moltox21: 0.794228 val loss: 0.198999
[Epoch 21] ogbg-moltox21: 0.807321 test loss: 0.213937
[Epoch 22; Iter     3/  157] train: loss: 0.1679028
[Epoch 22; Iter    33/  157] train: loss: 0.2243927
[Epoch 22; Iter    63/  157] train: loss: 0.2605365
[Epoch 22; Iter    93/  157] train: loss: 0.2275706
[Epoch 22; Iter   123/  157] train: loss: 0.2209084
[Epoch 22; Iter   153/  157] train: loss: 0.1225329
[Epoch 22] ogbg-moltox21: 0.806918 val loss: 0.241040
[Epoch 22] ogbg-moltox21: 0.828945 test loss: 0.208445
[Epoch 23; Iter    26/  157] train: loss: 0.2209354
[Epoch 23; Iter    56/  157] train: loss: 0.2393602
[Epoch 23; Iter    86/  157] train: loss: 0.1388204
[Epoch 23; Iter   116/  157] train: loss: 0.3340163
[Epoch 23; Iter   146/  157] train: loss: 0.2362318
[Epoch 23] ogbg-moltox21: 0.807305 val loss: 0.194178
[Epoch 23] ogbg-moltox21: 0.816497 test loss: 0.211939
[Epoch 24; Iter    19/  157] train: loss: 0.2607490
[Epoch 24; Iter    49/  157] train: loss: 0.2414625
[Epoch 24; Iter    79/  157] train: loss: 0.1852925
[Epoch 24; Iter   109/  157] train: loss: 0.1677130
[Epoch 24; Iter   139/  157] train: loss: 0.1731214
[Epoch 24] ogbg-moltox21: 0.808653 val loss: 0.200911
[Epoch 24] ogbg-moltox21: 0.821875 test loss: 0.210896
[Epoch 25; Iter    12/  157] train: loss: 0.1678091
[Epoch 25; Iter    42/  157] train: loss: 0.1347885
[Epoch 25; Iter    72/  157] train: loss: 0.1265919
[Epoch 25; Iter   102/  157] train: loss: 0.1818283
[Epoch 25; Iter   132/  157] train: loss: 0.2166972
[Epoch 25] ogbg-moltox21: 0.809508 val loss: 0.195924
[Epoch 25] ogbg-moltox21: 0.825333 test loss: 0.211569
[Epoch 26; Iter     5/  157] train: loss: 0.1580666
[Epoch 26; Iter    35/  157] train: loss: 0.2612734
[Epoch 26; Iter    65/  157] train: loss: 0.2609295
[Epoch 26; Iter    95/  157] train: loss: 0.1653580
[Epoch 26; Iter   125/  157] train: loss: 0.1420440
[Epoch 26; Iter   155/  157] train: loss: 0.2398808
[Epoch 26] ogbg-moltox21: 0.821941 val loss: 0.195019
[Epoch 26] ogbg-moltox21: 0.821082 test loss: 0.212449
[Epoch 27; Iter    28/  157] train: loss: 0.1377502
[Epoch 27; Iter    58/  157] train: loss: 0.2498576
[Epoch 27; Iter    88/  157] train: loss: 0.1270109
[Epoch 27; Iter   118/  157] train: loss: 0.1541950
[Epoch 27; Iter   148/  157] train: loss: 0.1644291
[Epoch 27] ogbg-moltox21: 0.821386 val loss: 0.189622
[Epoch 27] ogbg-moltox21: 0.823673 test loss: 0.208652
[Epoch 28; Iter    21/  157] train: loss: 0.2673640
[Epoch 28; Iter    51/  157] train: loss: 0.1398700
[Epoch 28; Iter    81/  157] train: loss: 0.1014938
[Epoch 28; Iter   111/  157] train: loss: 0.1515374
[Epoch 28; Iter   141/  157] train: loss: 0.2208446
[Epoch 28] ogbg-moltox21: 0.823948 val loss: 0.196362
[Epoch 28] ogbg-moltox21: 0.812733 test loss: 0.215046
[Epoch 29; Iter    14/  157] train: loss: 0.2033393
[Epoch 29; Iter    44/  157] train: loss: 0.2406003
[Epoch 29; Iter    74/  157] train: loss: 0.1168779
[Epoch 29; Iter   104/  157] train: loss: 0.2019950
[Epoch 29; Iter   134/  157] train: loss: 0.1334824
[Epoch 29] ogbg-moltox21: 0.807502 val loss: 0.198091
[Epoch 29] ogbg-moltox21: 0.813792 test loss: 0.210991
[Epoch 30; Iter     7/  157] train: loss: 0.1450995
[Epoch 30; Iter    37/  157] train: loss: 0.1460275
[Epoch 30; Iter    67/  157] train: loss: 0.3093626
[Epoch 30; Iter    97/  157] train: loss: 0.1581336
[Epoch 30; Iter   127/  157] train: loss: 0.2019561
[Epoch 30; Iter   157/  157] train: loss: 0.2557747
[Epoch 30] ogbg-moltox21: 0.822578 val loss: 0.189387
[Epoch 30] ogbg-moltox21: 0.835023 test loss: 0.230279
[Epoch 31; Iter    30/  157] train: loss: 0.1429509
[Epoch 31; Iter    60/  157] train: loss: 0.1358366
[Epoch 31; Iter    90/  157] train: loss: 0.2030274
[Epoch 31; Iter   120/  157] train: loss: 0.1854266
[Epoch 31; Iter   150/  157] train: loss: 0.1726083
[Epoch 31] ogbg-moltox21: 0.790826 val loss: 0.209418
[Epoch 31] ogbg-moltox21: 0.800636 test loss: 0.226753
[Epoch 32; Iter    23/  157] train: loss: 0.2131701
[Epoch 32; Iter    53/  157] train: loss: 0.2226009
[Epoch 32; Iter    83/  157] train: loss: 0.2075859
[Epoch 32; Iter   113/  157] train: loss: 0.1479591
[Epoch 32; Iter   143/  157] train: loss: 0.1201498
[Epoch 32] ogbg-moltox21: 0.826288 val loss: 0.195778
[Epoch 32] ogbg-moltox21: 0.824156 test loss: 0.210312
[Epoch 33; Iter    16/  157] train: loss: 0.2272186
[Epoch 33; Iter    46/  157] train: loss: 0.1272470
[Epoch 33; Iter    76/  157] train: loss: 0.2106682
[Epoch 33; Iter   106/  157] train: loss: 0.2091232
[Epoch 33; Iter   136/  157] train: loss: 0.1641063
[Epoch 33] ogbg-moltox21: 0.825505 val loss: 0.191944
[Epoch 33] ogbg-moltox21: 0.825057 test loss: 0.211954
[Epoch 34; Iter     9/  157] train: loss: 0.2040235
[Epoch 34; Iter    39/  157] train: loss: 0.1568291
[Epoch 34; Iter    69/  157] train: loss: 0.1655167
[Epoch 34; Iter    99/  157] train: loss: 0.1112952
[Epoch 34; Iter   129/  157] train: loss: 0.1091167
[Epoch 34] ogbg-moltox21: 0.828145 val loss: 0.231099
[Epoch 34] ogbg-moltox21: 0.806658 test loss: 0.239156
[Epoch 35; Iter     2/  157] train: loss: 0.1215480
[Epoch 35; Iter    32/  157] train: loss: 0.2593226
[Epoch 35; Iter    62/  157] train: loss: 0.1498755
[Epoch 35; Iter    92/  157] train: loss: 0.1312981
[Epoch 35; Iter   122/  157] train: loss: 0.1339433
[Epoch 35; Iter   152/  157] train: loss: 0.2003109
[Epoch 35] ogbg-moltox21: 0.833578 val loss: 0.183795
[Epoch 35] ogbg-moltox21: 0.832379 test loss: 0.203611
[Epoch 36; Iter    25/  157] train: loss: 0.2957554
[Epoch 36; Iter    55/  157] train: loss: 0.2322634
[Epoch 36; Iter    85/  157] train: loss: 0.1130265
[Epoch 36; Iter   115/  157] train: loss: 0.1468737
[Epoch 36; Iter   145/  157] train: loss: 0.1317607
[Epoch 36] ogbg-moltox21: 0.824301 val loss: 0.195263
[Epoch 36] ogbg-moltox21: 0.815600 test loss: 0.220081
[Epoch 37; Iter    18/  157] train: loss: 0.1321110
[Epoch 37; Iter    48/  157] train: loss: 0.1243560
[Epoch 15] ogbg-moltox21: 0.823437 test loss: 0.212266
[Epoch 16; Iter    15/  157] train: loss: 0.1772058
[Epoch 16; Iter    45/  157] train: loss: 0.1002615
[Epoch 16; Iter    75/  157] train: loss: 0.2727570
[Epoch 16; Iter   105/  157] train: loss: 0.1622181
[Epoch 16; Iter   135/  157] train: loss: 0.1844665
[Epoch 16] ogbg-moltox21: 0.817012 val loss: 0.192432
[Epoch 16] ogbg-moltox21: 0.828878 test loss: 0.204347
[Epoch 17; Iter     8/  157] train: loss: 0.1727897
[Epoch 17; Iter    38/  157] train: loss: 0.1338197
[Epoch 17; Iter    68/  157] train: loss: 0.2297499
[Epoch 17; Iter    98/  157] train: loss: 0.2560639
[Epoch 17; Iter   128/  157] train: loss: 0.2411392
[Epoch 17] ogbg-moltox21: 0.824097 val loss: 0.191472
[Epoch 17] ogbg-moltox21: 0.832559 test loss: 0.208667
[Epoch 18; Iter     1/  157] train: loss: 0.2053324
[Epoch 18; Iter    31/  157] train: loss: 0.1009829
[Epoch 18; Iter    61/  157] train: loss: 0.1674294
[Epoch 18; Iter    91/  157] train: loss: 0.1192987
[Epoch 18; Iter   121/  157] train: loss: 0.3033674
[Epoch 18; Iter   151/  157] train: loss: 0.1529934
[Epoch 18] ogbg-moltox21: 0.816509 val loss: 0.194792
[Epoch 18] ogbg-moltox21: 0.830980 test loss: 0.206154
[Epoch 19; Iter    24/  157] train: loss: 0.3460483
[Epoch 19; Iter    54/  157] train: loss: 0.1937780
[Epoch 19; Iter    84/  157] train: loss: 0.1472885
[Epoch 19; Iter   114/  157] train: loss: 0.2540007
[Epoch 19; Iter   144/  157] train: loss: 0.0921593
[Epoch 19] ogbg-moltox21: 0.817494 val loss: 0.190559
[Epoch 19] ogbg-moltox21: 0.833460 test loss: 0.203751
[Epoch 20; Iter    17/  157] train: loss: 0.1499345
[Epoch 20; Iter    47/  157] train: loss: 0.1857362
[Epoch 20; Iter    77/  157] train: loss: 0.2299682
[Epoch 20; Iter   107/  157] train: loss: 0.1865094
[Epoch 20; Iter   137/  157] train: loss: 0.1459849
[Epoch 20] ogbg-moltox21: 0.826186 val loss: 0.188590
[Epoch 20] ogbg-moltox21: 0.835818 test loss: 0.207461
[Epoch 21; Iter    10/  157] train: loss: 0.1806429
[Epoch 21; Iter    40/  157] train: loss: 0.2360639
[Epoch 21; Iter    70/  157] train: loss: 0.2112254
[Epoch 21; Iter   100/  157] train: loss: 0.2135340
[Epoch 21; Iter   130/  157] train: loss: 0.2245977
[Epoch 21] ogbg-moltox21: 0.840518 val loss: 0.181345
[Epoch 21] ogbg-moltox21: 0.845454 test loss: 0.201521
[Epoch 22; Iter     3/  157] train: loss: 0.1784484
[Epoch 22; Iter    33/  157] train: loss: 0.1767030
[Epoch 22; Iter    63/  157] train: loss: 0.1525058
[Epoch 22; Iter    93/  157] train: loss: 0.1445668
[Epoch 22; Iter   123/  157] train: loss: 0.1663502
[Epoch 22; Iter   153/  157] train: loss: 0.2001089
[Epoch 22] ogbg-moltox21: 0.827235 val loss: 0.191435
[Epoch 22] ogbg-moltox21: 0.839656 test loss: 0.204742
[Epoch 23; Iter    26/  157] train: loss: 0.1711334
[Epoch 23; Iter    56/  157] train: loss: 0.1490498
[Epoch 23; Iter    86/  157] train: loss: 0.2078669
[Epoch 23; Iter   116/  157] train: loss: 0.1775860
[Epoch 23; Iter   146/  157] train: loss: 0.1717881
[Epoch 23] ogbg-moltox21: 0.824927 val loss: 0.234077
[Epoch 23] ogbg-moltox21: 0.825276 test loss: 0.227998
[Epoch 24; Iter    19/  157] train: loss: 0.2236023
[Epoch 24; Iter    49/  157] train: loss: 0.2318750
[Epoch 24; Iter    79/  157] train: loss: 0.1601367
[Epoch 24; Iter   109/  157] train: loss: 0.1478837
[Epoch 24; Iter   139/  157] train: loss: 0.2583743
[Epoch 24] ogbg-moltox21: 0.819353 val loss: 0.189641
[Epoch 24] ogbg-moltox21: 0.822393 test loss: 0.252320
[Epoch 25; Iter    12/  157] train: loss: 0.1467880
[Epoch 25; Iter    42/  157] train: loss: 0.2200526
[Epoch 25; Iter    72/  157] train: loss: 0.1925626
[Epoch 25; Iter   102/  157] train: loss: 0.1478786
[Epoch 25; Iter   132/  157] train: loss: 0.2582181
[Epoch 25] ogbg-moltox21: 0.834144 val loss: 0.184912
[Epoch 25] ogbg-moltox21: 0.847299 test loss: 0.197622
[Epoch 26; Iter     5/  157] train: loss: 0.1462393
[Epoch 26; Iter    35/  157] train: loss: 0.1892499
[Epoch 26; Iter    65/  157] train: loss: 0.1646889
[Epoch 26; Iter    95/  157] train: loss: 0.1437915
[Epoch 26; Iter   125/  157] train: loss: 0.1679136
[Epoch 26; Iter   155/  157] train: loss: 0.1114493
[Epoch 26] ogbg-moltox21: 0.821820 val loss: 0.195606
[Epoch 26] ogbg-moltox21: 0.836454 test loss: 0.201336
[Epoch 27; Iter    28/  157] train: loss: 0.2143686
[Epoch 27; Iter    58/  157] train: loss: 0.1601714
[Epoch 27; Iter    88/  157] train: loss: 0.1741523
[Epoch 27; Iter   118/  157] train: loss: 0.1360717
[Epoch 27; Iter   148/  157] train: loss: 0.1812571
[Epoch 27] ogbg-moltox21: 0.835808 val loss: 0.192089
[Epoch 27] ogbg-moltox21: 0.843797 test loss: 0.200844
[Epoch 28; Iter    21/  157] train: loss: 0.1358960
[Epoch 28; Iter    51/  157] train: loss: 0.1900701
[Epoch 28; Iter    81/  157] train: loss: 0.1480796
[Epoch 28; Iter   111/  157] train: loss: 0.2664787
[Epoch 28; Iter   141/  157] train: loss: 0.1617842
[Epoch 28] ogbg-moltox21: 0.830176 val loss: 0.201695
[Epoch 28] ogbg-moltox21: 0.847909 test loss: 0.197691
[Epoch 29; Iter    14/  157] train: loss: 0.1282055
[Epoch 29; Iter    44/  157] train: loss: 0.1892895
[Epoch 29; Iter    74/  157] train: loss: 0.1432132
[Epoch 29; Iter   104/  157] train: loss: 0.2459257
[Epoch 29; Iter   134/  157] train: loss: 0.1336041
[Epoch 29] ogbg-moltox21: 0.825227 val loss: 0.196079
[Epoch 29] ogbg-moltox21: 0.836354 test loss: 0.204894
[Epoch 30; Iter     7/  157] train: loss: 0.2148520
[Epoch 30; Iter    37/  157] train: loss: 0.1843170
[Epoch 30; Iter    67/  157] train: loss: 0.1661233
[Epoch 30; Iter    97/  157] train: loss: 0.2808425
[Epoch 30; Iter   127/  157] train: loss: 0.1135252
[Epoch 30; Iter   157/  157] train: loss: 0.2535935
[Epoch 30] ogbg-moltox21: 0.825009 val loss: 0.210875
[Epoch 30] ogbg-moltox21: 0.820892 test loss: 0.239601
[Epoch 31; Iter    30/  157] train: loss: 0.1434885
[Epoch 31; Iter    60/  157] train: loss: 0.1599512
[Epoch 31; Iter    90/  157] train: loss: 0.1485923
[Epoch 31; Iter   120/  157] train: loss: 0.1602878
[Epoch 31; Iter   150/  157] train: loss: 0.1462870
[Epoch 31] ogbg-moltox21: 0.835441 val loss: 0.188342
[Epoch 31] ogbg-moltox21: 0.836102 test loss: 0.203192
[Epoch 32; Iter    23/  157] train: loss: 0.1155721
[Epoch 32; Iter    53/  157] train: loss: 0.1506694
[Epoch 32; Iter    83/  157] train: loss: 0.1373279
[Epoch 32; Iter   113/  157] train: loss: 0.1447356
[Epoch 32; Iter   143/  157] train: loss: 0.1537309
[Epoch 32] ogbg-moltox21: 0.826098 val loss: 0.202297
[Epoch 32] ogbg-moltox21: 0.832709 test loss: 0.246226
[Epoch 33; Iter    16/  157] train: loss: 0.1216820
[Epoch 33; Iter    46/  157] train: loss: 0.1202018
[Epoch 33; Iter    76/  157] train: loss: 0.1343230
[Epoch 33; Iter   106/  157] train: loss: 0.1797241
[Epoch 33; Iter   136/  157] train: loss: 0.1999353
[Epoch 33] ogbg-moltox21: 0.834753 val loss: 0.189071
[Epoch 33] ogbg-moltox21: 0.843825 test loss: 0.209649
[Epoch 34; Iter     9/  157] train: loss: 0.1764522
[Epoch 34; Iter    39/  157] train: loss: 0.2068601
[Epoch 34; Iter    69/  157] train: loss: 0.1448760
[Epoch 34; Iter    99/  157] train: loss: 0.1750385
[Epoch 34; Iter   129/  157] train: loss: 0.2107634
[Epoch 34] ogbg-moltox21: 0.836062 val loss: 0.214196
[Epoch 34] ogbg-moltox21: 0.839903 test loss: 0.217440
[Epoch 35; Iter     2/  157] train: loss: 0.0995950
[Epoch 35; Iter    32/  157] train: loss: 0.0947027
[Epoch 35; Iter    62/  157] train: loss: 0.1603330
[Epoch 35; Iter    92/  157] train: loss: 0.0708912
[Epoch 35; Iter   122/  157] train: loss: 0.1062590
[Epoch 35; Iter   152/  157] train: loss: 0.1644654
[Epoch 35] ogbg-moltox21: 0.830853 val loss: 0.190587
[Epoch 35] ogbg-moltox21: 0.847404 test loss: 0.199380
[Epoch 36; Iter    25/  157] train: loss: 0.2120078
[Epoch 36; Iter    55/  157] train: loss: 0.1396153
[Epoch 36; Iter    85/  157] train: loss: 0.1756846
[Epoch 36; Iter   115/  157] train: loss: 0.1165572
[Epoch 36; Iter   145/  157] train: loss: 0.0877379
[Epoch 36] ogbg-moltox21: 0.830509 val loss: 0.193723
[Epoch 36] ogbg-moltox21: 0.830196 test loss: 0.210039
[Epoch 37; Iter    18/  157] train: loss: 0.1567385
[Epoch 37; Iter    48/  157] train: loss: 0.2394118
[Epoch 15] ogbg-moltox21: 0.768264 test loss: 0.237650
[Epoch 16; Iter    15/  157] train: loss: 0.1732294
[Epoch 16; Iter    45/  157] train: loss: 0.1615436
[Epoch 16; Iter    75/  157] train: loss: 0.1936274
[Epoch 16; Iter   105/  157] train: loss: 0.2043572
[Epoch 16; Iter   135/  157] train: loss: 0.2800423
[Epoch 16] ogbg-moltox21: 0.773728 val loss: 0.209581
[Epoch 16] ogbg-moltox21: 0.784940 test loss: 0.224857
[Epoch 17; Iter     8/  157] train: loss: 0.1185914
[Epoch 17; Iter    38/  157] train: loss: 0.1652493
[Epoch 17; Iter    68/  157] train: loss: 0.3200576
[Epoch 17; Iter    98/  157] train: loss: 0.3204399
[Epoch 17; Iter   128/  157] train: loss: 0.2186614
[Epoch 17] ogbg-moltox21: 0.800120 val loss: 0.211045
[Epoch 17] ogbg-moltox21: 0.816833 test loss: 0.214419
[Epoch 18; Iter     1/  157] train: loss: 0.1218001
[Epoch 18; Iter    31/  157] train: loss: 0.1862807
[Epoch 18; Iter    61/  157] train: loss: 0.2552055
[Epoch 18; Iter    91/  157] train: loss: 0.1880283
[Epoch 18; Iter   121/  157] train: loss: 0.2504425
[Epoch 18; Iter   151/  157] train: loss: 0.1768700
[Epoch 18] ogbg-moltox21: 0.804604 val loss: 0.196872
[Epoch 18] ogbg-moltox21: 0.812158 test loss: 0.215744
[Epoch 19; Iter    24/  157] train: loss: 0.1300084
[Epoch 19; Iter    54/  157] train: loss: 0.1592800
[Epoch 19; Iter    84/  157] train: loss: 0.1561128
[Epoch 19; Iter   114/  157] train: loss: 0.2377547
[Epoch 19; Iter   144/  157] train: loss: 0.1823176
[Epoch 19] ogbg-moltox21: 0.776920 val loss: 0.205422
[Epoch 19] ogbg-moltox21: 0.795227 test loss: 0.223783
[Epoch 20; Iter    17/  157] train: loss: 0.2052427
[Epoch 20; Iter    47/  157] train: loss: 0.1489201
[Epoch 20; Iter    77/  157] train: loss: 0.2875467
[Epoch 20; Iter   107/  157] train: loss: 0.2211609
[Epoch 20; Iter   137/  157] train: loss: 0.1510181
[Epoch 20] ogbg-moltox21: 0.802533 val loss: 0.195003
[Epoch 20] ogbg-moltox21: 0.813279 test loss: 0.212766
[Epoch 21; Iter    10/  157] train: loss: 0.1709369
[Epoch 21; Iter    40/  157] train: loss: 0.3278223
[Epoch 21; Iter    70/  157] train: loss: 0.1826602
[Epoch 21; Iter   100/  157] train: loss: 0.2040432
[Epoch 21; Iter   130/  157] train: loss: 0.1955136
[Epoch 21] ogbg-moltox21: 0.805220 val loss: 0.193302
[Epoch 21] ogbg-moltox21: 0.821081 test loss: 0.209563
[Epoch 22; Iter     3/  157] train: loss: 0.1936383
[Epoch 22; Iter    33/  157] train: loss: 0.2181108
[Epoch 22; Iter    63/  157] train: loss: 0.1591393
[Epoch 22; Iter    93/  157] train: loss: 0.1680784
[Epoch 22; Iter   123/  157] train: loss: 0.1419409
[Epoch 22; Iter   153/  157] train: loss: 0.1683673
[Epoch 22] ogbg-moltox21: 0.815184 val loss: 0.190903
[Epoch 22] ogbg-moltox21: 0.826502 test loss: 0.206567
[Epoch 23; Iter    26/  157] train: loss: 0.1690918
[Epoch 23; Iter    56/  157] train: loss: 0.2140439
[Epoch 23; Iter    86/  157] train: loss: 0.1720677
[Epoch 23; Iter   116/  157] train: loss: 0.2231885
[Epoch 23; Iter   146/  157] train: loss: 0.1172011
[Epoch 23] ogbg-moltox21: 0.811634 val loss: 0.194959
[Epoch 23] ogbg-moltox21: 0.828473 test loss: 0.204535
[Epoch 24; Iter    19/  157] train: loss: 0.1425304
[Epoch 24; Iter    49/  157] train: loss: 0.1910629
[Epoch 24; Iter    79/  157] train: loss: 0.2565133
[Epoch 24; Iter   109/  157] train: loss: 0.1601967
[Epoch 24; Iter   139/  157] train: loss: 0.2322046
[Epoch 24] ogbg-moltox21: 0.815192 val loss: 0.190663
[Epoch 24] ogbg-moltox21: 0.826652 test loss: 0.207086
[Epoch 25; Iter    12/  157] train: loss: 0.2280402
[Epoch 25; Iter    42/  157] train: loss: 0.1871135
[Epoch 25; Iter    72/  157] train: loss: 0.2037733
[Epoch 25; Iter   102/  157] train: loss: 0.1746325
[Epoch 25; Iter   132/  157] train: loss: 0.2035542
[Epoch 25] ogbg-moltox21: 0.819385 val loss: 0.204080
[Epoch 25] ogbg-moltox21: 0.843660 test loss: 0.208759
[Epoch 26; Iter     5/  157] train: loss: 0.2159472
[Epoch 26; Iter    35/  157] train: loss: 0.1606202
[Epoch 26; Iter    65/  157] train: loss: 0.1516777
[Epoch 26; Iter    95/  157] train: loss: 0.3244628
[Epoch 26; Iter   125/  157] train: loss: 0.1491192
[Epoch 26; Iter   155/  157] train: loss: 0.1332560
[Epoch 26] ogbg-moltox21: 0.829934 val loss: 0.191272
[Epoch 26] ogbg-moltox21: 0.844652 test loss: 0.203194
[Epoch 27; Iter    28/  157] train: loss: 0.1053907
[Epoch 27; Iter    58/  157] train: loss: 0.1568744
[Epoch 27; Iter    88/  157] train: loss: 0.2006223
[Epoch 27; Iter   118/  157] train: loss: 0.1703887
[Epoch 27; Iter   148/  157] train: loss: 0.2525149
[Epoch 27] ogbg-moltox21: 0.810808 val loss: 0.192266
[Epoch 27] ogbg-moltox21: 0.833888 test loss: 0.205324
[Epoch 28; Iter    21/  157] train: loss: 0.1280663
[Epoch 28; Iter    51/  157] train: loss: 0.2438012
[Epoch 28; Iter    81/  157] train: loss: 0.2292577
[Epoch 28; Iter   111/  157] train: loss: 0.2023729
[Epoch 28; Iter   141/  157] train: loss: 0.1711227
[Epoch 28] ogbg-moltox21: 0.829206 val loss: 0.188544
[Epoch 28] ogbg-moltox21: 0.840687 test loss: 0.206112
[Epoch 29; Iter    14/  157] train: loss: 0.1286079
[Epoch 29; Iter    44/  157] train: loss: 0.1862841
[Epoch 29; Iter    74/  157] train: loss: 0.1415192
[Epoch 29; Iter   104/  157] train: loss: 0.2363338
[Epoch 29; Iter   134/  157] train: loss: 0.1579210
[Epoch 29] ogbg-moltox21: 0.825188 val loss: 0.186992
[Epoch 29] ogbg-moltox21: 0.839706 test loss: 0.201234
[Epoch 30; Iter     7/  157] train: loss: 0.1724911
[Epoch 30; Iter    37/  157] train: loss: 0.1038925
[Epoch 30; Iter    67/  157] train: loss: 0.1697963
[Epoch 30; Iter    97/  157] train: loss: 0.2067391
[Epoch 30; Iter   127/  157] train: loss: 0.1941036
[Epoch 30; Iter   157/  157] train: loss: 0.1226606
[Epoch 30] ogbg-moltox21: 0.817692 val loss: 0.197129
[Epoch 30] ogbg-moltox21: 0.835483 test loss: 0.210046
[Epoch 31; Iter    30/  157] train: loss: 0.1628874
[Epoch 31; Iter    60/  157] train: loss: 0.1585447
[Epoch 31; Iter    90/  157] train: loss: 0.1280885
[Epoch 31; Iter   120/  157] train: loss: 0.1521151
[Epoch 31; Iter   150/  157] train: loss: 0.1848628
[Epoch 31] ogbg-moltox21: 0.813500 val loss: 0.193728
[Epoch 31] ogbg-moltox21: 0.833523 test loss: 0.208139
[Epoch 32; Iter    23/  157] train: loss: 0.1712327
[Epoch 32; Iter    53/  157] train: loss: 0.1876398
[Epoch 32; Iter    83/  157] train: loss: 0.1857451
[Epoch 32; Iter   113/  157] train: loss: 0.1854223
[Epoch 32; Iter   143/  157] train: loss: 0.2482852
[Epoch 32] ogbg-moltox21: 0.826482 val loss: 0.188942
[Epoch 32] ogbg-moltox21: 0.836830 test loss: 0.202101
[Epoch 33; Iter    16/  157] train: loss: 0.1184094
[Epoch 33; Iter    46/  157] train: loss: 0.0956678
[Epoch 33; Iter    76/  157] train: loss: 0.1467301
[Epoch 33; Iter   106/  157] train: loss: 0.1463875
[Epoch 33; Iter   136/  157] train: loss: 0.1995794
[Epoch 33] ogbg-moltox21: 0.818582 val loss: 0.191835
[Epoch 33] ogbg-moltox21: 0.838044 test loss: 0.208004
[Epoch 34; Iter     9/  157] train: loss: 0.1371877
[Epoch 34; Iter    39/  157] train: loss: 0.1422045
[Epoch 34; Iter    69/  157] train: loss: 0.1900551
[Epoch 34; Iter    99/  157] train: loss: 0.1468448
[Epoch 34; Iter   129/  157] train: loss: 0.1169416
[Epoch 34] ogbg-moltox21: 0.828828 val loss: 0.188165
[Epoch 34] ogbg-moltox21: 0.845174 test loss: 0.202735
[Epoch 35; Iter     2/  157] train: loss: 0.1562394
[Epoch 35; Iter    32/  157] train: loss: 0.2183904
[Epoch 35; Iter    62/  157] train: loss: 0.2796468
[Epoch 35; Iter    92/  157] train: loss: 0.1123491
[Epoch 35; Iter   122/  157] train: loss: 0.2005783
[Epoch 35; Iter   152/  157] train: loss: 0.1759896
[Epoch 35] ogbg-moltox21: 0.828318 val loss: 0.187244
[Epoch 35] ogbg-moltox21: 0.842232 test loss: 0.201505
[Epoch 36; Iter    25/  157] train: loss: 0.1861070
[Epoch 36; Iter    55/  157] train: loss: 0.1692586
[Epoch 36; Iter    85/  157] train: loss: 0.2298601
[Epoch 36; Iter   115/  157] train: loss: 0.1702220
[Epoch 36; Iter   145/  157] train: loss: 0.1492732
[Epoch 36] ogbg-moltox21: 0.827669 val loss: 0.188799
[Epoch 36] ogbg-moltox21: 0.838776 test loss: 0.203013
[Epoch 37; Iter    18/  157] train: loss: 0.1094556
[Epoch 37; Iter    48/  157] train: loss: 0.1839073
[Epoch 30; Iter    89/  209] train: loss: 0.1258789
[Epoch 30; Iter   119/  209] train: loss: 0.2393402
[Epoch 30; Iter   149/  209] train: loss: 0.2229536
[Epoch 30; Iter   179/  209] train: loss: 0.1450702
[Epoch 30; Iter   209/  209] train: loss: 0.1443529
[Epoch 30] ogbg-moltox21: 0.852990 val loss: 0.204590
[Epoch 30] ogbg-moltox21: 0.864843 test loss: 0.181427
[Epoch 31; Iter    30/  209] train: loss: 0.1046721
[Epoch 31; Iter    60/  209] train: loss: 0.1155021
[Epoch 31; Iter    90/  209] train: loss: 0.1992523
[Epoch 31; Iter   120/  209] train: loss: 0.1114412
[Epoch 31; Iter   150/  209] train: loss: 0.2058362
[Epoch 31; Iter   180/  209] train: loss: 0.1804051
[Epoch 31] ogbg-moltox21: 0.869010 val loss: 0.202926
[Epoch 31] ogbg-moltox21: 0.866306 test loss: 0.181122
[Epoch 32; Iter     1/  209] train: loss: 0.1485195
[Epoch 32; Iter    31/  209] train: loss: 0.1015781
[Epoch 32; Iter    61/  209] train: loss: 0.2510551
[Epoch 32; Iter    91/  209] train: loss: 0.2229967
[Epoch 32; Iter   121/  209] train: loss: 0.1843763
[Epoch 32; Iter   151/  209] train: loss: 0.2000154
[Epoch 32; Iter   181/  209] train: loss: 0.1940336
[Epoch 32] ogbg-moltox21: 0.861011 val loss: 0.213260
[Epoch 32] ogbg-moltox21: 0.847224 test loss: 0.195448
[Epoch 33; Iter     2/  209] train: loss: 0.2030128
[Epoch 33; Iter    32/  209] train: loss: 0.1273970
[Epoch 33; Iter    62/  209] train: loss: 0.1380014
[Epoch 33; Iter    92/  209] train: loss: 0.1377953
[Epoch 33; Iter   122/  209] train: loss: 0.1355024
[Epoch 33; Iter   152/  209] train: loss: 0.1778587
[Epoch 33; Iter   182/  209] train: loss: 0.1475496
[Epoch 33] ogbg-moltox21: 0.865380 val loss: 0.200811
[Epoch 33] ogbg-moltox21: 0.853158 test loss: 0.184509
[Epoch 34; Iter     3/  209] train: loss: 0.1361284
[Epoch 34; Iter    33/  209] train: loss: 0.2045827
[Epoch 34; Iter    63/  209] train: loss: 0.1685122
[Epoch 34; Iter    93/  209] train: loss: 0.1449226
[Epoch 34; Iter   123/  209] train: loss: 0.1517340
[Epoch 34; Iter   153/  209] train: loss: 0.1272920
[Epoch 34; Iter   183/  209] train: loss: 0.1104585
[Epoch 34] ogbg-moltox21: 0.847365 val loss: 0.211356
[Epoch 34] ogbg-moltox21: 0.843000 test loss: 0.186707
[Epoch 35; Iter     4/  209] train: loss: 0.1807322
[Epoch 35; Iter    34/  209] train: loss: 0.1573878
[Epoch 35; Iter    64/  209] train: loss: 0.1011337
[Epoch 35; Iter    94/  209] train: loss: 0.2862688
[Epoch 35; Iter   124/  209] train: loss: 0.1403785
[Epoch 35; Iter   154/  209] train: loss: 0.1516806
[Epoch 35; Iter   184/  209] train: loss: 0.2101915
[Epoch 35] ogbg-moltox21: 0.860727 val loss: 0.200739
[Epoch 35] ogbg-moltox21: 0.852097 test loss: 0.193208
[Epoch 36; Iter     5/  209] train: loss: 0.1693084
[Epoch 36; Iter    35/  209] train: loss: 0.2433943
[Epoch 36; Iter    65/  209] train: loss: 0.1780414
[Epoch 36; Iter    95/  209] train: loss: 0.1162055
[Epoch 36; Iter   125/  209] train: loss: 0.1616990
[Epoch 36; Iter   155/  209] train: loss: 0.1803440
[Epoch 36; Iter   185/  209] train: loss: 0.2173057
[Epoch 36] ogbg-moltox21: 0.873126 val loss: 0.198559
[Epoch 36] ogbg-moltox21: 0.855507 test loss: 0.185739
[Epoch 37; Iter     6/  209] train: loss: 0.1223040
[Epoch 37; Iter    36/  209] train: loss: 0.1204225
[Epoch 37; Iter    66/  209] train: loss: 0.1254046
[Epoch 37; Iter    96/  209] train: loss: 0.1161803
[Epoch 37; Iter   126/  209] train: loss: 0.1175550
[Epoch 37; Iter   156/  209] train: loss: 0.1043378
[Epoch 37; Iter   186/  209] train: loss: 0.1410785
[Epoch 37] ogbg-moltox21: 0.869344 val loss: 0.201110
[Epoch 37] ogbg-moltox21: 0.860550 test loss: 0.186827
[Epoch 38; Iter     7/  209] train: loss: 0.1268145
[Epoch 38; Iter    37/  209] train: loss: 0.1728524
[Epoch 38; Iter    67/  209] train: loss: 0.1006381
[Epoch 38; Iter    97/  209] train: loss: 0.1386383
[Epoch 38; Iter   127/  209] train: loss: 0.1993487
[Epoch 38; Iter   157/  209] train: loss: 0.0970724
[Epoch 38; Iter   187/  209] train: loss: 0.1013118
[Epoch 38] ogbg-moltox21: 0.868675 val loss: 0.202637
[Epoch 38] ogbg-moltox21: 0.858186 test loss: 0.181529
[Epoch 39; Iter     8/  209] train: loss: 0.1253856
[Epoch 39; Iter    38/  209] train: loss: 0.1019164
[Epoch 39; Iter    68/  209] train: loss: 0.1575978
[Epoch 39; Iter    98/  209] train: loss: 0.1625955
[Epoch 39; Iter   128/  209] train: loss: 0.0947546
[Epoch 39; Iter   158/  209] train: loss: 0.1658642
[Epoch 39; Iter   188/  209] train: loss: 0.1194119
[Epoch 39] ogbg-moltox21: 0.867374 val loss: 0.204122
[Epoch 39] ogbg-moltox21: 0.860087 test loss: 0.184947
[Epoch 40; Iter     9/  209] train: loss: 0.1488764
[Epoch 40; Iter    39/  209] train: loss: 0.0833365
[Epoch 40; Iter    69/  209] train: loss: 0.1141479
[Epoch 40; Iter    99/  209] train: loss: 0.1272458
[Epoch 40; Iter   129/  209] train: loss: 0.1443961
[Epoch 40; Iter   159/  209] train: loss: 0.1930322
[Epoch 40; Iter   189/  209] train: loss: 0.2248857
[Epoch 40] ogbg-moltox21: 0.861991 val loss: 0.212253
[Epoch 40] ogbg-moltox21: 0.854748 test loss: 0.190108
[Epoch 41; Iter    10/  209] train: loss: 0.1434423
[Epoch 41; Iter    40/  209] train: loss: 0.1322296
[Epoch 41; Iter    70/  209] train: loss: 0.1327619
[Epoch 41; Iter   100/  209] train: loss: 0.1267771
[Epoch 41; Iter   130/  209] train: loss: 0.1640146
[Epoch 41; Iter   160/  209] train: loss: 0.2377598
[Epoch 41; Iter   190/  209] train: loss: 0.0875314
[Epoch 41] ogbg-moltox21: 0.860376 val loss: 0.210180
[Epoch 41] ogbg-moltox21: 0.854819 test loss: 0.192957
[Epoch 42; Iter    11/  209] train: loss: 0.1708032
[Epoch 42; Iter    41/  209] train: loss: 0.1991101
[Epoch 42; Iter    71/  209] train: loss: 0.1255629
[Epoch 42; Iter   101/  209] train: loss: 0.1478326
[Epoch 42; Iter   131/  209] train: loss: 0.1335236
[Epoch 42; Iter   161/  209] train: loss: 0.1598060
[Epoch 42; Iter   191/  209] train: loss: 0.1834247
[Epoch 42] ogbg-moltox21: 0.864161 val loss: 0.206782
[Epoch 42] ogbg-moltox21: 0.847997 test loss: 0.191257
[Epoch 43; Iter    12/  209] train: loss: 0.0928652
[Epoch 43; Iter    42/  209] train: loss: 0.1176894
[Epoch 43; Iter    72/  209] train: loss: 0.1229436
[Epoch 43; Iter   102/  209] train: loss: 0.1578894
[Epoch 43; Iter   132/  209] train: loss: 0.1149290
[Epoch 43; Iter   162/  209] train: loss: 0.1657914
[Epoch 43; Iter   192/  209] train: loss: 0.1050482
[Epoch 43] ogbg-moltox21: 0.856423 val loss: 0.215807
[Epoch 43] ogbg-moltox21: 0.851308 test loss: 0.198536
[Epoch 44; Iter    13/  209] train: loss: 0.1416452
[Epoch 44; Iter    43/  209] train: loss: 0.1064029
[Epoch 44; Iter    73/  209] train: loss: 0.1363003
[Epoch 44; Iter   103/  209] train: loss: 0.1042757
[Epoch 44; Iter   133/  209] train: loss: 0.1013865
[Epoch 44; Iter   163/  209] train: loss: 0.1587415
[Epoch 44; Iter   193/  209] train: loss: 0.1114930
[Epoch 44] ogbg-moltox21: 0.864224 val loss: 0.207913
[Epoch 44] ogbg-moltox21: 0.850980 test loss: 0.190108
[Epoch 45; Iter    14/  209] train: loss: 0.1655298
[Epoch 45; Iter    44/  209] train: loss: 0.1260566
[Epoch 45; Iter    74/  209] train: loss: 0.0958152
[Epoch 45; Iter   104/  209] train: loss: 0.0992908
[Epoch 45; Iter   134/  209] train: loss: 0.0963264
[Epoch 45; Iter   164/  209] train: loss: 0.1022810
[Epoch 45; Iter   194/  209] train: loss: 0.1453317
[Epoch 45] ogbg-moltox21: 0.857367 val loss: 0.212125
[Epoch 45] ogbg-moltox21: 0.856987 test loss: 0.192100
[Epoch 46; Iter    15/  209] train: loss: 0.1730685
[Epoch 46; Iter    45/  209] train: loss: 0.1015798
[Epoch 46; Iter    75/  209] train: loss: 0.1263104
[Epoch 46; Iter   105/  209] train: loss: 0.0974226
[Epoch 46; Iter   135/  209] train: loss: 0.1540614
[Epoch 46; Iter   165/  209] train: loss: 0.1966768
[Epoch 46; Iter   195/  209] train: loss: 0.0988438
[Epoch 46] ogbg-moltox21: 0.858354 val loss: 0.219940
[Epoch 46] ogbg-moltox21: 0.849013 test loss: 0.197507
[Epoch 47; Iter    16/  209] train: loss: 0.1194532
[Epoch 47; Iter    46/  209] train: loss: 0.1034648
[Epoch 47; Iter    76/  209] train: loss: 0.1122913
[Epoch 47; Iter   106/  209] train: loss: 0.1203087
[Epoch 47; Iter   136/  209] train: loss: 0.1533923
[Epoch 30; Iter    89/  209] train: loss: 0.1802216
[Epoch 30; Iter   119/  209] train: loss: 0.1291977
[Epoch 30; Iter   149/  209] train: loss: 0.1580822
[Epoch 30; Iter   179/  209] train: loss: 0.1570831
[Epoch 30; Iter   209/  209] train: loss: 0.3163597
[Epoch 30] ogbg-moltox21: 0.847890 val loss: 0.207116
[Epoch 30] ogbg-moltox21: 0.823578 test loss: 0.200138
[Epoch 31; Iter    30/  209] train: loss: 0.1450884
[Epoch 31; Iter    60/  209] train: loss: 0.1159812
[Epoch 31; Iter    90/  209] train: loss: 0.1893350
[Epoch 31; Iter   120/  209] train: loss: 0.1979182
[Epoch 31; Iter   150/  209] train: loss: 0.1671238
[Epoch 31; Iter   180/  209] train: loss: 0.2463173
[Epoch 31] ogbg-moltox21: 0.851659 val loss: 0.204730
[Epoch 31] ogbg-moltox21: 0.831863 test loss: 0.197095
[Epoch 32; Iter     1/  209] train: loss: 0.1296554
[Epoch 32; Iter    31/  209] train: loss: 0.1169662
[Epoch 32; Iter    61/  209] train: loss: 0.1267737
[Epoch 32; Iter    91/  209] train: loss: 0.1308031
[Epoch 32; Iter   121/  209] train: loss: 0.1145198
[Epoch 32; Iter   151/  209] train: loss: 0.1278918
[Epoch 32; Iter   181/  209] train: loss: 0.1477348
[Epoch 32] ogbg-moltox21: 0.860836 val loss: 0.202875
[Epoch 32] ogbg-moltox21: 0.841783 test loss: 0.192711
[Epoch 33; Iter     2/  209] train: loss: 0.1097054
[Epoch 33; Iter    32/  209] train: loss: 0.1986096
[Epoch 33; Iter    62/  209] train: loss: 0.1782184
[Epoch 33; Iter    92/  209] train: loss: 0.1721561
[Epoch 33; Iter   122/  209] train: loss: 0.2299038
[Epoch 33; Iter   152/  209] train: loss: 0.2384851
[Epoch 33; Iter   182/  209] train: loss: 0.3034610
[Epoch 33] ogbg-moltox21: 0.865869 val loss: 0.204334
[Epoch 33] ogbg-moltox21: 0.837719 test loss: 0.193776
[Epoch 34; Iter     3/  209] train: loss: 0.1448225
[Epoch 34; Iter    33/  209] train: loss: 0.2506979
[Epoch 34; Iter    63/  209] train: loss: 0.1232358
[Epoch 34; Iter    93/  209] train: loss: 0.1252054
[Epoch 34; Iter   123/  209] train: loss: 0.1415212
[Epoch 34; Iter   153/  209] train: loss: 0.1635195
[Epoch 34; Iter   183/  209] train: loss: 0.1451760
[Epoch 34] ogbg-moltox21: 0.857716 val loss: 0.211096
[Epoch 34] ogbg-moltox21: 0.834828 test loss: 0.213267
[Epoch 35; Iter     4/  209] train: loss: 0.2001460
[Epoch 35; Iter    34/  209] train: loss: 0.2384142
[Epoch 35; Iter    64/  209] train: loss: 0.1733370
[Epoch 35; Iter    94/  209] train: loss: 0.1652674
[Epoch 35; Iter   124/  209] train: loss: 0.2178885
[Epoch 35; Iter   154/  209] train: loss: 0.1362908
[Epoch 35; Iter   184/  209] train: loss: 0.1640009
[Epoch 35] ogbg-moltox21: 0.857632 val loss: 0.207915
[Epoch 35] ogbg-moltox21: 0.851914 test loss: 0.188503
[Epoch 36; Iter     5/  209] train: loss: 0.2083678
[Epoch 36; Iter    35/  209] train: loss: 0.1518652
[Epoch 36; Iter    65/  209] train: loss: 0.1509061
[Epoch 36; Iter    95/  209] train: loss: 0.1624660
[Epoch 36; Iter   125/  209] train: loss: 0.1948167
[Epoch 36; Iter   155/  209] train: loss: 0.2593366
[Epoch 36; Iter   185/  209] train: loss: 0.1726015
[Epoch 36] ogbg-moltox21: 0.866481 val loss: 0.197418
[Epoch 36] ogbg-moltox21: 0.849400 test loss: 0.182902
[Epoch 37; Iter     6/  209] train: loss: 0.1513323
[Epoch 37; Iter    36/  209] train: loss: 0.1615810
[Epoch 37; Iter    66/  209] train: loss: 0.2078995
[Epoch 37; Iter    96/  209] train: loss: 0.1650373
[Epoch 37; Iter   126/  209] train: loss: 0.1501367
[Epoch 37; Iter   156/  209] train: loss: 0.2857211
[Epoch 37; Iter   186/  209] train: loss: 0.1487127
[Epoch 37] ogbg-moltox21: 0.864775 val loss: 0.200442
[Epoch 37] ogbg-moltox21: 0.841867 test loss: 0.192063
[Epoch 38; Iter     7/  209] train: loss: 0.1991224
[Epoch 38; Iter    37/  209] train: loss: 0.1833361
[Epoch 38; Iter    67/  209] train: loss: 0.1480175
[Epoch 38; Iter    97/  209] train: loss: 0.1106709
[Epoch 38; Iter   127/  209] train: loss: 0.0940538
[Epoch 38; Iter   157/  209] train: loss: 0.1130183
[Epoch 38; Iter   187/  209] train: loss: 0.1481457
[Epoch 38] ogbg-moltox21: 0.869760 val loss: 0.196024
[Epoch 38] ogbg-moltox21: 0.844796 test loss: 0.199300
[Epoch 39; Iter     8/  209] train: loss: 0.2628149
[Epoch 39; Iter    38/  209] train: loss: 0.1230378
[Epoch 39; Iter    68/  209] train: loss: 0.1655988
[Epoch 39; Iter    98/  209] train: loss: 0.1231241
[Epoch 39; Iter   128/  209] train: loss: 0.1727924
[Epoch 39; Iter   158/  209] train: loss: 0.2313026
[Epoch 39; Iter   188/  209] train: loss: 0.1602185
[Epoch 39] ogbg-moltox21: 0.870230 val loss: 0.196582
[Epoch 39] ogbg-moltox21: 0.838572 test loss: 0.191257
[Epoch 40; Iter     9/  209] train: loss: 0.1377109
[Epoch 40; Iter    39/  209] train: loss: 0.1454997
[Epoch 40; Iter    69/  209] train: loss: 0.2090349
[Epoch 40; Iter    99/  209] train: loss: 0.1184588
[Epoch 40; Iter   129/  209] train: loss: 0.1653156
[Epoch 40; Iter   159/  209] train: loss: 0.1110284
[Epoch 40; Iter   189/  209] train: loss: 0.1863156
[Epoch 40] ogbg-moltox21: 0.863217 val loss: 0.201234
[Epoch 40] ogbg-moltox21: 0.851564 test loss: 0.187603
[Epoch 41; Iter    10/  209] train: loss: 0.1774563
[Epoch 41; Iter    40/  209] train: loss: 0.1415730
[Epoch 41; Iter    70/  209] train: loss: 0.1856820
[Epoch 41; Iter   100/  209] train: loss: 0.1404245
[Epoch 41; Iter   130/  209] train: loss: 0.1490027
[Epoch 41; Iter   160/  209] train: loss: 0.1630221
[Epoch 41; Iter   190/  209] train: loss: 0.1252889
[Epoch 41] ogbg-moltox21: 0.877220 val loss: 0.199302
[Epoch 41] ogbg-moltox21: 0.851460 test loss: 0.183760
[Epoch 42; Iter    11/  209] train: loss: 0.2220833
[Epoch 42; Iter    41/  209] train: loss: 0.1239574
[Epoch 42; Iter    71/  209] train: loss: 0.1681603
[Epoch 42; Iter   101/  209] train: loss: 0.1371064
[Epoch 42; Iter   131/  209] train: loss: 0.1523085
[Epoch 42; Iter   161/  209] train: loss: 0.2158326
[Epoch 42; Iter   191/  209] train: loss: 0.1670304
[Epoch 42] ogbg-moltox21: 0.864519 val loss: 0.204931
[Epoch 42] ogbg-moltox21: 0.846820 test loss: 0.194320
[Epoch 43; Iter    12/  209] train: loss: 0.1279798
[Epoch 43; Iter    42/  209] train: loss: 0.1868572
[Epoch 43; Iter    72/  209] train: loss: 0.1534919
[Epoch 43; Iter   102/  209] train: loss: 0.1573526
[Epoch 43; Iter   132/  209] train: loss: 0.1556461
[Epoch 43; Iter   162/  209] train: loss: 0.1705815
[Epoch 43; Iter   192/  209] train: loss: 0.1890629
[Epoch 43] ogbg-moltox21: 0.874057 val loss: 0.196993
[Epoch 43] ogbg-moltox21: 0.849064 test loss: 0.194371
[Epoch 44; Iter    13/  209] train: loss: 0.1562449
[Epoch 44; Iter    43/  209] train: loss: 0.1522994
[Epoch 44; Iter    73/  209] train: loss: 0.1536292
[Epoch 44; Iter   103/  209] train: loss: 0.1655989
[Epoch 44; Iter   133/  209] train: loss: 0.1931663
[Epoch 44; Iter   163/  209] train: loss: 0.1272337
[Epoch 44; Iter   193/  209] train: loss: 0.2609939
[Epoch 44] ogbg-moltox21: 0.869699 val loss: 0.201051
[Epoch 44] ogbg-moltox21: 0.839854 test loss: 0.197741
[Epoch 45; Iter    14/  209] train: loss: 0.1197998
[Epoch 45; Iter    44/  209] train: loss: 0.1452763
[Epoch 45; Iter    74/  209] train: loss: 0.1413848
[Epoch 45; Iter   104/  209] train: loss: 0.1198029
[Epoch 45; Iter   134/  209] train: loss: 0.1934678
[Epoch 45; Iter   164/  209] train: loss: 0.1405419
[Epoch 45; Iter   194/  209] train: loss: 0.2656368
[Epoch 45] ogbg-moltox21: 0.872444 val loss: 0.193714
[Epoch 45] ogbg-moltox21: 0.843062 test loss: 0.188971
[Epoch 46; Iter    15/  209] train: loss: 0.2297797
[Epoch 46; Iter    45/  209] train: loss: 0.1206281
[Epoch 46; Iter    75/  209] train: loss: 0.1378410
[Epoch 46; Iter   105/  209] train: loss: 0.1717855
[Epoch 46; Iter   135/  209] train: loss: 0.1293006
[Epoch 46; Iter   165/  209] train: loss: 0.1480375
[Epoch 46; Iter   195/  209] train: loss: 0.0961748
[Epoch 46] ogbg-moltox21: 0.856914 val loss: 0.205642
[Epoch 46] ogbg-moltox21: 0.843246 test loss: 0.199909
[Epoch 47; Iter    16/  209] train: loss: 0.1610301
[Epoch 47; Iter    46/  209] train: loss: 0.1345882
[Epoch 47; Iter    76/  209] train: loss: 0.1683537
[Epoch 47; Iter   106/  209] train: loss: 0.1817338
[Epoch 47; Iter   136/  209] train: loss: 0.2036843
[Epoch 30; Iter    89/  209] train: loss: 0.1505539
[Epoch 30; Iter   119/  209] train: loss: 0.1756681
[Epoch 30; Iter   149/  209] train: loss: 0.1302348
[Epoch 30; Iter   179/  209] train: loss: 0.2026735
[Epoch 30; Iter   209/  209] train: loss: 0.1260516
[Epoch 30] ogbg-moltox21: 0.848679 val loss: 0.199904
[Epoch 30] ogbg-moltox21: 0.851151 test loss: 0.191976
[Epoch 31; Iter    30/  209] train: loss: 0.1605308
[Epoch 31; Iter    60/  209] train: loss: 0.2185919
[Epoch 31; Iter    90/  209] train: loss: 0.1366967
[Epoch 31; Iter   120/  209] train: loss: 0.1467290
[Epoch 31; Iter   150/  209] train: loss: 0.1156925
[Epoch 31; Iter   180/  209] train: loss: 0.2315211
[Epoch 31] ogbg-moltox21: 0.850160 val loss: 0.203867
[Epoch 31] ogbg-moltox21: 0.853278 test loss: 0.186218
[Epoch 32; Iter     1/  209] train: loss: 0.1290416
[Epoch 32; Iter    31/  209] train: loss: 0.1567941
[Epoch 32; Iter    61/  209] train: loss: 0.1751770
[Epoch 32; Iter    91/  209] train: loss: 0.1936139
[Epoch 32; Iter   121/  209] train: loss: 0.1223999
[Epoch 32; Iter   151/  209] train: loss: 0.1790247
[Epoch 32; Iter   181/  209] train: loss: 0.1312075
[Epoch 32] ogbg-moltox21: 0.857706 val loss: 0.200545
[Epoch 32] ogbg-moltox21: 0.839563 test loss: 0.239919
[Epoch 33; Iter     2/  209] train: loss: 0.1987537
[Epoch 33; Iter    32/  209] train: loss: 0.1198699
[Epoch 33; Iter    62/  209] train: loss: 0.1794275
[Epoch 33; Iter    92/  209] train: loss: 0.1491607
[Epoch 33; Iter   122/  209] train: loss: 0.1921467
[Epoch 33; Iter   152/  209] train: loss: 0.1280383
[Epoch 33; Iter   182/  209] train: loss: 0.1258960
[Epoch 33] ogbg-moltox21: 0.868483 val loss: 0.201694
[Epoch 33] ogbg-moltox21: 0.857030 test loss: 0.188036
[Epoch 34; Iter     3/  209] train: loss: 0.1387522
[Epoch 34; Iter    33/  209] train: loss: 0.1510636
[Epoch 34; Iter    63/  209] train: loss: 0.1628414
[Epoch 34; Iter    93/  209] train: loss: 0.1511821
[Epoch 34; Iter   123/  209] train: loss: 0.1616853
[Epoch 34; Iter   153/  209] train: loss: 0.1627012
[Epoch 34; Iter   183/  209] train: loss: 0.1683379
[Epoch 34] ogbg-moltox21: 0.853905 val loss: 0.205750
[Epoch 34] ogbg-moltox21: 0.838573 test loss: 0.212231
[Epoch 35; Iter     4/  209] train: loss: 0.1413924
[Epoch 35; Iter    34/  209] train: loss: 0.2345085
[Epoch 35; Iter    64/  209] train: loss: 0.2086719
[Epoch 35; Iter    94/  209] train: loss: 0.1521834
[Epoch 35; Iter   124/  209] train: loss: 0.0967960
[Epoch 35; Iter   154/  209] train: loss: 0.2134641
[Epoch 35; Iter   184/  209] train: loss: 0.1556728
[Epoch 35] ogbg-moltox21: 0.857128 val loss: 0.203957
[Epoch 35] ogbg-moltox21: 0.841846 test loss: 0.199247
[Epoch 36; Iter     5/  209] train: loss: 0.1193254
[Epoch 36; Iter    35/  209] train: loss: 0.1023544
[Epoch 36; Iter    65/  209] train: loss: 0.1294321
[Epoch 36; Iter    95/  209] train: loss: 0.1271292
[Epoch 36; Iter   125/  209] train: loss: 0.1566695
[Epoch 36; Iter   155/  209] train: loss: 0.1405899
[Epoch 36; Iter   185/  209] train: loss: 0.1594955
[Epoch 36] ogbg-moltox21: 0.860673 val loss: 0.198496
[Epoch 36] ogbg-moltox21: 0.843082 test loss: 0.366331
[Epoch 37; Iter     6/  209] train: loss: 0.2222352
[Epoch 37; Iter    36/  209] train: loss: 0.1732000
[Epoch 37; Iter    66/  209] train: loss: 0.1408549
[Epoch 37; Iter    96/  209] train: loss: 0.1472440
[Epoch 37; Iter   126/  209] train: loss: 0.1401691
[Epoch 37; Iter   156/  209] train: loss: 0.1708139
[Epoch 37; Iter   186/  209] train: loss: 0.1248351
[Epoch 37] ogbg-moltox21: 0.869551 val loss: 0.194699
[Epoch 37] ogbg-moltox21: 0.855293 test loss: 0.239310
[Epoch 38; Iter     7/  209] train: loss: 0.1455139
[Epoch 38; Iter    37/  209] train: loss: 0.0994912
[Epoch 38; Iter    67/  209] train: loss: 0.1105855
[Epoch 38; Iter    97/  209] train: loss: 0.1462459
[Epoch 38; Iter   127/  209] train: loss: 0.0969201
[Epoch 38; Iter   157/  209] train: loss: 0.1835734
[Epoch 38; Iter   187/  209] train: loss: 0.0985318
[Epoch 38] ogbg-moltox21: 0.862001 val loss: 0.198083
[Epoch 38] ogbg-moltox21: 0.851026 test loss: 0.400946
[Epoch 39; Iter     8/  209] train: loss: 0.1170420
[Epoch 39; Iter    38/  209] train: loss: 0.1244680
[Epoch 39; Iter    68/  209] train: loss: 0.2657493
[Epoch 39; Iter    98/  209] train: loss: 0.0840215
[Epoch 39; Iter   128/  209] train: loss: 0.1308962
[Epoch 39; Iter   158/  209] train: loss: 0.1121280
[Epoch 39; Iter   188/  209] train: loss: 0.1111103
[Epoch 39] ogbg-moltox21: 0.860356 val loss: 0.213569
[Epoch 39] ogbg-moltox21: 0.857341 test loss: 0.412504
[Epoch 40; Iter     9/  209] train: loss: 0.1102921
[Epoch 40; Iter    39/  209] train: loss: 0.1485424
[Epoch 40; Iter    69/  209] train: loss: 0.1484908
[Epoch 40; Iter    99/  209] train: loss: 0.1351788
[Epoch 40; Iter   129/  209] train: loss: 0.1319063
[Epoch 40; Iter   159/  209] train: loss: 0.2093603
[Epoch 40; Iter   189/  209] train: loss: 0.1248074
[Epoch 40] ogbg-moltox21: 0.853913 val loss: 0.212844
[Epoch 40] ogbg-moltox21: 0.840870 test loss: 0.571611
[Epoch 41; Iter    10/  209] train: loss: 0.1661972
[Epoch 41; Iter    40/  209] train: loss: 0.1349188
[Epoch 41; Iter    70/  209] train: loss: 0.1708953
[Epoch 41; Iter   100/  209] train: loss: 0.1051102
[Epoch 41; Iter   130/  209] train: loss: 0.1163962
[Epoch 41; Iter   160/  209] train: loss: 0.1225844
[Epoch 41; Iter   190/  209] train: loss: 0.1879956
[Epoch 41] ogbg-moltox21: 0.843714 val loss: 0.221552
[Epoch 41] ogbg-moltox21: 0.847136 test loss: 0.496572
[Epoch 42; Iter    11/  209] train: loss: 0.1273368
[Epoch 42; Iter    41/  209] train: loss: 0.1288665
[Epoch 42; Iter    71/  209] train: loss: 0.1621754
[Epoch 42; Iter   101/  209] train: loss: 0.1573865
[Epoch 42; Iter   131/  209] train: loss: 0.1960448
[Epoch 42; Iter   161/  209] train: loss: 0.1262001
[Epoch 42; Iter   191/  209] train: loss: 0.1352308
[Epoch 42] ogbg-moltox21: 0.859305 val loss: 0.206355
[Epoch 42] ogbg-moltox21: 0.860961 test loss: 0.182963
[Epoch 43; Iter    12/  209] train: loss: 0.1369727
[Epoch 43; Iter    42/  209] train: loss: 0.1436178
[Epoch 43; Iter    72/  209] train: loss: 0.1224623
[Epoch 43; Iter   102/  209] train: loss: 0.0907252
[Epoch 43; Iter   132/  209] train: loss: 0.1145475
[Epoch 43; Iter   162/  209] train: loss: 0.1415632
[Epoch 43; Iter   192/  209] train: loss: 0.1653216
[Epoch 43] ogbg-moltox21: 0.855097 val loss: 0.214713
[Epoch 43] ogbg-moltox21: 0.856768 test loss: 0.187171
[Epoch 44; Iter    13/  209] train: loss: 0.1237083
[Epoch 44; Iter    43/  209] train: loss: 0.1748086
[Epoch 44; Iter    73/  209] train: loss: 0.1428842
[Epoch 44; Iter   103/  209] train: loss: 0.1094803
[Epoch 44; Iter   133/  209] train: loss: 0.1392374
[Epoch 44; Iter   163/  209] train: loss: 0.2010279
[Epoch 44; Iter   193/  209] train: loss: 0.1213619
[Epoch 44] ogbg-moltox21: 0.854825 val loss: 0.203482
[Epoch 44] ogbg-moltox21: 0.841951 test loss: 0.187811
[Epoch 45; Iter    14/  209] train: loss: 0.1757081
[Epoch 45; Iter    44/  209] train: loss: 0.1219348
[Epoch 45; Iter    74/  209] train: loss: 0.1372352
[Epoch 45; Iter   104/  209] train: loss: 0.0822463
[Epoch 45; Iter   134/  209] train: loss: 0.0961638
[Epoch 45; Iter   164/  209] train: loss: 0.1510365
[Epoch 45; Iter   194/  209] train: loss: 0.1248859
[Epoch 45] ogbg-moltox21: 0.859163 val loss: 0.207682
[Epoch 45] ogbg-moltox21: 0.842676 test loss: 0.194622
[Epoch 46; Iter    15/  209] train: loss: 0.0968222
[Epoch 46; Iter    45/  209] train: loss: 0.1479364
[Epoch 46; Iter    75/  209] train: loss: 0.1748057
[Epoch 46; Iter   105/  209] train: loss: 0.1855567
[Epoch 46; Iter   135/  209] train: loss: 0.1524440
[Epoch 46; Iter   165/  209] train: loss: 0.1068604
[Epoch 46; Iter   195/  209] train: loss: 0.2122939
[Epoch 46] ogbg-moltox21: 0.853775 val loss: 0.211845
[Epoch 46] ogbg-moltox21: 0.844938 test loss: 0.197434
[Epoch 47; Iter    16/  209] train: loss: 0.1358302
[Epoch 47; Iter    46/  209] train: loss: 0.1291425
[Epoch 47; Iter    76/  209] train: loss: 0.1299837
[Epoch 47; Iter   106/  209] train: loss: 0.1154448
[Epoch 47; Iter   136/  209] train: loss: 0.0796063
[Epoch 33; Iter   114/  183] train: loss: 0.1458593
[Epoch 33; Iter   144/  183] train: loss: 0.2154349
[Epoch 33; Iter   174/  183] train: loss: 0.1383324
[Epoch 33] ogbg-moltox21: 0.838518 val loss: 0.194077
[Epoch 33] ogbg-moltox21: 0.846130 test loss: 0.195874
[Epoch 34; Iter    21/  183] train: loss: 0.1142875
[Epoch 34; Iter    51/  183] train: loss: 0.1877767
[Epoch 34; Iter    81/  183] train: loss: 0.1018711
[Epoch 34; Iter   111/  183] train: loss: 0.1224416
[Epoch 34; Iter   141/  183] train: loss: 0.1869139
[Epoch 34; Iter   171/  183] train: loss: 0.2373677
[Epoch 34] ogbg-moltox21: 0.835373 val loss: 0.203426
[Epoch 34] ogbg-moltox21: 0.847212 test loss: 0.198019
[Epoch 35; Iter    18/  183] train: loss: 0.1975998
[Epoch 35; Iter    48/  183] train: loss: 0.1189559
[Epoch 35; Iter    78/  183] train: loss: 0.1537351
[Epoch 35; Iter   108/  183] train: loss: 0.1821935
[Epoch 35; Iter   138/  183] train: loss: 0.2578504
[Epoch 35; Iter   168/  183] train: loss: 0.1245033
[Epoch 35] ogbg-moltox21: 0.830908 val loss: 0.190785
[Epoch 35] ogbg-moltox21: 0.846261 test loss: 0.194722
[Epoch 36; Iter    15/  183] train: loss: 0.2235494
[Epoch 36; Iter    45/  183] train: loss: 0.1692239
[Epoch 36; Iter    75/  183] train: loss: 0.2027640
[Epoch 36; Iter   105/  183] train: loss: 0.1721499
[Epoch 36; Iter   135/  183] train: loss: 0.1645345
[Epoch 36; Iter   165/  183] train: loss: 0.0967204
[Epoch 36] ogbg-moltox21: 0.842431 val loss: 0.193202
[Epoch 36] ogbg-moltox21: 0.852290 test loss: 0.189489
[Epoch 37; Iter    12/  183] train: loss: 0.2432744
[Epoch 37; Iter    42/  183] train: loss: 0.1896970
[Epoch 37; Iter    72/  183] train: loss: 0.1616714
[Epoch 37; Iter   102/  183] train: loss: 0.1433653
[Epoch 37; Iter   132/  183] train: loss: 0.0903742
[Epoch 37; Iter   162/  183] train: loss: 0.2547828
[Epoch 37] ogbg-moltox21: 0.828525 val loss: 0.202817
[Epoch 37] ogbg-moltox21: 0.846969 test loss: 0.192217
[Epoch 38; Iter     9/  183] train: loss: 0.1360481
[Epoch 38; Iter    39/  183] train: loss: 0.1785398
[Epoch 38; Iter    69/  183] train: loss: 0.1142763
[Epoch 38; Iter    99/  183] train: loss: 0.1052397
[Epoch 38; Iter   129/  183] train: loss: 0.1330346
[Epoch 38; Iter   159/  183] train: loss: 0.1556740
[Epoch 38] ogbg-moltox21: 0.838774 val loss: 0.213447
[Epoch 38] ogbg-moltox21: 0.854183 test loss: 0.216115
[Epoch 39; Iter     6/  183] train: loss: 0.1267605
[Epoch 39; Iter    36/  183] train: loss: 0.1184407
[Epoch 39; Iter    66/  183] train: loss: 0.1117721
[Epoch 39; Iter    96/  183] train: loss: 0.1387672
[Epoch 39; Iter   126/  183] train: loss: 0.2179829
[Epoch 39; Iter   156/  183] train: loss: 0.1646133
[Epoch 39] ogbg-moltox21: 0.840312 val loss: 0.203348
[Epoch 39] ogbg-moltox21: 0.840833 test loss: 0.198463
[Epoch 40; Iter     3/  183] train: loss: 0.1317561
[Epoch 40; Iter    33/  183] train: loss: 0.1329791
[Epoch 40; Iter    63/  183] train: loss: 0.1713510
[Epoch 40; Iter    93/  183] train: loss: 0.1489422
[Epoch 40; Iter   123/  183] train: loss: 0.1246421
[Epoch 40; Iter   153/  183] train: loss: 0.1436472
[Epoch 40; Iter   183/  183] train: loss: 0.1518770
[Epoch 40] ogbg-moltox21: 0.836620 val loss: 0.227130
[Epoch 40] ogbg-moltox21: 0.850613 test loss: 0.223354
[Epoch 41; Iter    30/  183] train: loss: 0.1763225
[Epoch 41; Iter    60/  183] train: loss: 0.1726694
[Epoch 41; Iter    90/  183] train: loss: 0.1565813
[Epoch 41; Iter   120/  183] train: loss: 0.1794339
[Epoch 41; Iter   150/  183] train: loss: 0.1113534
[Epoch 41; Iter   180/  183] train: loss: 0.1308710
[Epoch 41] ogbg-moltox21: 0.839072 val loss: 0.198135
[Epoch 41] ogbg-moltox21: 0.847893 test loss: 0.195621
[Epoch 42; Iter    27/  183] train: loss: 0.1913916
[Epoch 42; Iter    57/  183] train: loss: 0.0996355
[Epoch 42; Iter    87/  183] train: loss: 0.1567919
[Epoch 42; Iter   117/  183] train: loss: 0.1063090
[Epoch 42; Iter   147/  183] train: loss: 0.1365401
[Epoch 42; Iter   177/  183] train: loss: 0.1964596
[Epoch 42] ogbg-moltox21: 0.838585 val loss: 0.191882
[Epoch 42] ogbg-moltox21: 0.852855 test loss: 0.192642
[Epoch 43; Iter    24/  183] train: loss: 0.1883464
[Epoch 43; Iter    54/  183] train: loss: 0.1552607
[Epoch 43; Iter    84/  183] train: loss: 0.1060559
[Epoch 43; Iter   114/  183] train: loss: 0.1795952
[Epoch 43; Iter   144/  183] train: loss: 0.1278865
[Epoch 43; Iter   174/  183] train: loss: 0.0793458
[Epoch 43] ogbg-moltox21: 0.839489 val loss: 0.199171
[Epoch 43] ogbg-moltox21: 0.853111 test loss: 0.195090
[Epoch 44; Iter    21/  183] train: loss: 0.1093522
[Epoch 44; Iter    51/  183] train: loss: 0.1307273
[Epoch 44; Iter    81/  183] train: loss: 0.1440353
[Epoch 44; Iter   111/  183] train: loss: 0.0831892
[Epoch 44; Iter   141/  183] train: loss: 0.1054524
[Epoch 44; Iter   171/  183] train: loss: 0.0842310
[Epoch 44] ogbg-moltox21: 0.836417 val loss: 0.193397
[Epoch 44] ogbg-moltox21: 0.849725 test loss: 0.196433
[Epoch 45; Iter    18/  183] train: loss: 0.1508106
[Epoch 45; Iter    48/  183] train: loss: 0.1522647
[Epoch 45; Iter    78/  183] train: loss: 0.1279382
[Epoch 45; Iter   108/  183] train: loss: 0.1603976
[Epoch 45; Iter   138/  183] train: loss: 0.0956029
[Epoch 45; Iter   168/  183] train: loss: 0.1411510
[Epoch 45] ogbg-moltox21: 0.837708 val loss: 0.198860
[Epoch 45] ogbg-moltox21: 0.846545 test loss: 0.196439
[Epoch 46; Iter    15/  183] train: loss: 0.1099220
[Epoch 46; Iter    45/  183] train: loss: 0.0755475
[Epoch 46; Iter    75/  183] train: loss: 0.1094425
[Epoch 46; Iter   105/  183] train: loss: 0.1027787
[Epoch 46; Iter   135/  183] train: loss: 0.1468782
[Epoch 46; Iter   165/  183] train: loss: 0.1275058
[Epoch 46] ogbg-moltox21: 0.837410 val loss: 0.193763
[Epoch 46] ogbg-moltox21: 0.851311 test loss: 0.192593
[Epoch 47; Iter    12/  183] train: loss: 0.2124810
[Epoch 47; Iter    42/  183] train: loss: 0.2480646
[Epoch 47; Iter    72/  183] train: loss: 0.1179599
[Epoch 47; Iter   102/  183] train: loss: 0.1269408
[Epoch 47; Iter   132/  183] train: loss: 0.0928150
[Epoch 47; Iter   162/  183] train: loss: 0.1187646
[Epoch 47] ogbg-moltox21: 0.833539 val loss: 0.218069
[Epoch 47] ogbg-moltox21: 0.841158 test loss: 0.205784
[Epoch 48; Iter     9/  183] train: loss: 0.1205748
[Epoch 48; Iter    39/  183] train: loss: 0.1274453
[Epoch 48; Iter    69/  183] train: loss: 0.0734167
[Epoch 48; Iter    99/  183] train: loss: 0.1326847
[Epoch 48; Iter   129/  183] train: loss: 0.1060485
[Epoch 48; Iter   159/  183] train: loss: 0.1022676
[Epoch 48] ogbg-moltox21: 0.829553 val loss: 0.226447
[Epoch 48] ogbg-moltox21: 0.838225 test loss: 0.214806
[Epoch 49; Iter     6/  183] train: loss: 0.1954982
[Epoch 49; Iter    36/  183] train: loss: 0.1010932
[Epoch 49; Iter    66/  183] train: loss: 0.1427164
[Epoch 49; Iter    96/  183] train: loss: 0.1810894
[Epoch 49; Iter   126/  183] train: loss: 0.1695316
[Epoch 49; Iter   156/  183] train: loss: 0.1985918
[Epoch 49] ogbg-moltox21: 0.831991 val loss: 0.202696
[Epoch 49] ogbg-moltox21: 0.844132 test loss: 0.200761
[Epoch 50; Iter     3/  183] train: loss: 0.1659259
[Epoch 50; Iter    33/  183] train: loss: 0.1421355
[Epoch 50; Iter    63/  183] train: loss: 0.0879155
[Epoch 50; Iter    93/  183] train: loss: 0.1789234
[Epoch 50; Iter   123/  183] train: loss: 0.1462957
[Epoch 50; Iter   153/  183] train: loss: 0.1435577
[Epoch 50; Iter   183/  183] train: loss: 0.1062967
[Epoch 50] ogbg-moltox21: 0.835822 val loss: 0.200255
[Epoch 50] ogbg-moltox21: 0.847135 test loss: 0.196395
[Epoch 51; Iter    30/  183] train: loss: 0.1115347
[Epoch 51; Iter    60/  183] train: loss: 0.1354918
[Epoch 51; Iter    90/  183] train: loss: 0.0817975
[Epoch 51; Iter   120/  183] train: loss: 0.1194107
[Epoch 51; Iter   150/  183] train: loss: 0.0681040
[Epoch 51; Iter   180/  183] train: loss: 0.1089069
[Epoch 51] ogbg-moltox21: 0.824090 val loss: 0.210471
[Epoch 51] ogbg-moltox21: 0.837031 test loss: 0.204494
[Epoch 52; Iter    27/  183] train: loss: 0.1276455
[Epoch 52; Iter    57/  183] train: loss: 0.1395939
[Epoch 52; Iter    87/  183] train: loss: 0.1532880
[Epoch 52; Iter   117/  183] train: loss: 0.1824592
[Epoch 33; Iter   114/  183] train: loss: 0.2644939
[Epoch 33; Iter   144/  183] train: loss: 0.1642988
[Epoch 33; Iter   174/  183] train: loss: 0.2046786
[Epoch 33] ogbg-moltox21: 0.814750 val loss: 0.202248
[Epoch 33] ogbg-moltox21: 0.841658 test loss: 0.201685
[Epoch 34; Iter    21/  183] train: loss: 0.2254746
[Epoch 34; Iter    51/  183] train: loss: 0.1233162
[Epoch 34; Iter    81/  183] train: loss: 0.2072075
[Epoch 34; Iter   111/  183] train: loss: 0.3251208
[Epoch 34; Iter   141/  183] train: loss: 0.1301221
[Epoch 34; Iter   171/  183] train: loss: 0.1160409
[Epoch 34] ogbg-moltox21: 0.815178 val loss: 0.202943
[Epoch 34] ogbg-moltox21: 0.840055 test loss: 0.198080
[Epoch 35; Iter    18/  183] train: loss: 0.1476098
[Epoch 35; Iter    48/  183] train: loss: 0.1996561
[Epoch 35; Iter    78/  183] train: loss: 0.1885335
[Epoch 35; Iter   108/  183] train: loss: 0.2303350
[Epoch 35; Iter   138/  183] train: loss: 0.2429300
[Epoch 35; Iter   168/  183] train: loss: 0.1644654
[Epoch 35] ogbg-moltox21: 0.823154 val loss: 0.221149
[Epoch 35] ogbg-moltox21: 0.841457 test loss: 0.202968
[Epoch 36; Iter    15/  183] train: loss: 0.2278599
[Epoch 36; Iter    45/  183] train: loss: 0.1963954
[Epoch 36; Iter    75/  183] train: loss: 0.2136593
[Epoch 36; Iter   105/  183] train: loss: 0.1649412
[Epoch 36; Iter   135/  183] train: loss: 0.1840341
[Epoch 36; Iter   165/  183] train: loss: 0.1726825
[Epoch 36] ogbg-moltox21: 0.810743 val loss: 0.205254
[Epoch 36] ogbg-moltox21: 0.840555 test loss: 0.203612
[Epoch 37; Iter    12/  183] train: loss: 0.1493558
[Epoch 37; Iter    42/  183] train: loss: 0.1286283
[Epoch 37; Iter    72/  183] train: loss: 0.1939825
[Epoch 37; Iter   102/  183] train: loss: 0.2193319
[Epoch 37; Iter   132/  183] train: loss: 0.2173264
[Epoch 37; Iter   162/  183] train: loss: 0.1641545
[Epoch 37] ogbg-moltox21: 0.829208 val loss: 0.194105
[Epoch 37] ogbg-moltox21: 0.848678 test loss: 0.192546
[Epoch 38; Iter     9/  183] train: loss: 0.1980867
[Epoch 38; Iter    39/  183] train: loss: 0.1674720
[Epoch 38; Iter    69/  183] train: loss: 0.2168089
[Epoch 38; Iter    99/  183] train: loss: 0.1109963
[Epoch 38; Iter   129/  183] train: loss: 0.1950168
[Epoch 38; Iter   159/  183] train: loss: 0.1439645
[Epoch 38] ogbg-moltox21: 0.829055 val loss: 0.198465
[Epoch 38] ogbg-moltox21: 0.850017 test loss: 0.194921
[Epoch 39; Iter     6/  183] train: loss: 0.1668568
[Epoch 39; Iter    36/  183] train: loss: 0.1356211
[Epoch 39; Iter    66/  183] train: loss: 0.2204914
[Epoch 39; Iter    96/  183] train: loss: 0.2693838
[Epoch 39; Iter   126/  183] train: loss: 0.1694520
[Epoch 39; Iter   156/  183] train: loss: 0.1733649
[Epoch 39] ogbg-moltox21: 0.834488 val loss: 0.190850
[Epoch 39] ogbg-moltox21: 0.857871 test loss: 0.187004
[Epoch 40; Iter     3/  183] train: loss: 0.2423261
[Epoch 40; Iter    33/  183] train: loss: 0.2359660
[Epoch 40; Iter    63/  183] train: loss: 0.2059962
[Epoch 40; Iter    93/  183] train: loss: 0.2548430
[Epoch 40; Iter   123/  183] train: loss: 0.2342590
[Epoch 40; Iter   153/  183] train: loss: 0.1056986
[Epoch 40; Iter   183/  183] train: loss: 0.1319315
[Epoch 40] ogbg-moltox21: 0.838198 val loss: 0.192490
[Epoch 40] ogbg-moltox21: 0.855792 test loss: 0.188978
[Epoch 41; Iter    30/  183] train: loss: 0.1995705
[Epoch 41; Iter    60/  183] train: loss: 0.1887731
[Epoch 41; Iter    90/  183] train: loss: 0.2259599
[Epoch 41; Iter   120/  183] train: loss: 0.1489624
[Epoch 41; Iter   150/  183] train: loss: 0.2645429
[Epoch 41; Iter   180/  183] train: loss: 0.2599453
[Epoch 41] ogbg-moltox21: 0.831143 val loss: 0.200813
[Epoch 41] ogbg-moltox21: 0.855377 test loss: 0.192542
[Epoch 42; Iter    27/  183] train: loss: 0.1398210
[Epoch 42; Iter    57/  183] train: loss: 0.1204596
[Epoch 42; Iter    87/  183] train: loss: 0.1478308
[Epoch 42; Iter   117/  183] train: loss: 0.1873873
[Epoch 42; Iter   147/  183] train: loss: 0.1468733
[Epoch 42; Iter   177/  183] train: loss: 0.1619389
[Epoch 42] ogbg-moltox21: 0.826550 val loss: 0.196244
[Epoch 42] ogbg-moltox21: 0.844979 test loss: 0.195290
[Epoch 43; Iter    24/  183] train: loss: 0.1660886
[Epoch 43; Iter    54/  183] train: loss: 0.1752266
[Epoch 43; Iter    84/  183] train: loss: 0.1662679
[Epoch 43; Iter   114/  183] train: loss: 0.2002094
[Epoch 43; Iter   144/  183] train: loss: 0.1285831
[Epoch 43; Iter   174/  183] train: loss: 0.1158989
[Epoch 43] ogbg-moltox21: 0.832402 val loss: 0.197563
[Epoch 43] ogbg-moltox21: 0.847739 test loss: 0.193213
[Epoch 44; Iter    21/  183] train: loss: 0.1557884
[Epoch 44; Iter    51/  183] train: loss: 0.2038266
[Epoch 44; Iter    81/  183] train: loss: 0.1619700
[Epoch 44; Iter   111/  183] train: loss: 0.1067635
[Epoch 44; Iter   141/  183] train: loss: 0.1470366
[Epoch 44; Iter   171/  183] train: loss: 0.2130692
[Epoch 44] ogbg-moltox21: 0.830002 val loss: 0.211306
[Epoch 44] ogbg-moltox21: 0.849555 test loss: 0.193184
[Epoch 45; Iter    18/  183] train: loss: 0.1763931
[Epoch 45; Iter    48/  183] train: loss: 0.1635017
[Epoch 45; Iter    78/  183] train: loss: 0.1413780
[Epoch 45; Iter   108/  183] train: loss: 0.1765615
[Epoch 45; Iter   138/  183] train: loss: 0.1810063
[Epoch 45; Iter   168/  183] train: loss: 0.1082380
[Epoch 45] ogbg-moltox21: 0.832467 val loss: 0.197076
[Epoch 45] ogbg-moltox21: 0.852046 test loss: 0.193284
[Epoch 46; Iter    15/  183] train: loss: 0.1341999
[Epoch 46; Iter    45/  183] train: loss: 0.2121626
[Epoch 46; Iter    75/  183] train: loss: 0.1654764
[Epoch 46; Iter   105/  183] train: loss: 0.1619461
[Epoch 46; Iter   135/  183] train: loss: 0.1446919
[Epoch 46; Iter   165/  183] train: loss: 0.2014674
[Epoch 46] ogbg-moltox21: 0.835987 val loss: 0.194624
[Epoch 46] ogbg-moltox21: 0.855732 test loss: 0.190105
[Epoch 47; Iter    12/  183] train: loss: 0.1394347
[Epoch 47; Iter    42/  183] train: loss: 0.0688858
[Epoch 47; Iter    72/  183] train: loss: 0.1180354
[Epoch 47; Iter   102/  183] train: loss: 0.1509452
[Epoch 47; Iter   132/  183] train: loss: 0.2044308
[Epoch 47; Iter   162/  183] train: loss: 0.1169673
[Epoch 47] ogbg-moltox21: 0.823140 val loss: 0.204870
[Epoch 47] ogbg-moltox21: 0.853357 test loss: 0.196942
[Epoch 48; Iter     9/  183] train: loss: 0.1290716
[Epoch 48; Iter    39/  183] train: loss: 0.0908593
[Epoch 48; Iter    69/  183] train: loss: 0.1811686
[Epoch 48; Iter    99/  183] train: loss: 0.1710967
[Epoch 48; Iter   129/  183] train: loss: 0.1956761
[Epoch 48; Iter   159/  183] train: loss: 0.1747689
[Epoch 48] ogbg-moltox21: 0.825485 val loss: 0.203087
[Epoch 48] ogbg-moltox21: 0.845071 test loss: 0.199200
[Epoch 49; Iter     6/  183] train: loss: 0.2386158
[Epoch 49; Iter    36/  183] train: loss: 0.2056766
[Epoch 49; Iter    66/  183] train: loss: 0.1532941
[Epoch 49; Iter    96/  183] train: loss: 0.1845784
[Epoch 49; Iter   126/  183] train: loss: 0.1630255
[Epoch 49; Iter   156/  183] train: loss: 0.1557686
[Epoch 49] ogbg-moltox21: 0.827172 val loss: 0.195252
[Epoch 49] ogbg-moltox21: 0.848625 test loss: 0.190663
[Epoch 50; Iter     3/  183] train: loss: 0.1667745
[Epoch 50; Iter    33/  183] train: loss: 0.1094752
[Epoch 50; Iter    63/  183] train: loss: 0.1317743
[Epoch 50; Iter    93/  183] train: loss: 0.1344914
[Epoch 50; Iter   123/  183] train: loss: 0.1508550
[Epoch 50; Iter   153/  183] train: loss: 0.1767823
[Epoch 50; Iter   183/  183] train: loss: 0.2769666
[Epoch 50] ogbg-moltox21: 0.828624 val loss: 0.199212
[Epoch 50] ogbg-moltox21: 0.846346 test loss: 0.195655
[Epoch 51; Iter    30/  183] train: loss: 0.1448716
[Epoch 51; Iter    60/  183] train: loss: 0.1426022
[Epoch 51; Iter    90/  183] train: loss: 0.1403563
[Epoch 51; Iter   120/  183] train: loss: 0.0968942
[Epoch 51; Iter   150/  183] train: loss: 0.1123944
[Epoch 51; Iter   180/  183] train: loss: 0.1125468
[Epoch 51] ogbg-moltox21: 0.828132 val loss: 0.207000
[Epoch 51] ogbg-moltox21: 0.843633 test loss: 0.200604
[Epoch 52; Iter    27/  183] train: loss: 0.1464064
[Epoch 52; Iter    57/  183] train: loss: 0.1438610
[Epoch 52; Iter    87/  183] train: loss: 0.1311900
[Epoch 52; Iter   117/  183] train: loss: 0.2227120
[Epoch 33; Iter   114/  183] train: loss: 0.1662758
[Epoch 33; Iter   144/  183] train: loss: 0.1772412
[Epoch 33; Iter   174/  183] train: loss: 0.0713716
[Epoch 33] ogbg-moltox21: 0.826530 val loss: 0.202563
[Epoch 33] ogbg-moltox21: 0.850123 test loss: 0.196517
[Epoch 34; Iter    21/  183] train: loss: 0.1767345
[Epoch 34; Iter    51/  183] train: loss: 0.1232379
[Epoch 34; Iter    81/  183] train: loss: 0.1796507
[Epoch 34; Iter   111/  183] train: loss: 0.1296715
[Epoch 34; Iter   141/  183] train: loss: 0.1597414
[Epoch 34; Iter   171/  183] train: loss: 0.1622003
[Epoch 34] ogbg-moltox21: 0.831929 val loss: 0.202128
[Epoch 34] ogbg-moltox21: 0.851843 test loss: 0.200401
[Epoch 35; Iter    18/  183] train: loss: 0.1325220
[Epoch 35; Iter    48/  183] train: loss: 0.1747066
[Epoch 35; Iter    78/  183] train: loss: 0.1647145
[Epoch 35; Iter   108/  183] train: loss: 0.1527585
[Epoch 35; Iter   138/  183] train: loss: 0.1254918
[Epoch 35; Iter   168/  183] train: loss: 0.1632364
[Epoch 35] ogbg-moltox21: 0.832229 val loss: 0.207745
[Epoch 35] ogbg-moltox21: 0.848181 test loss: 0.196522
[Epoch 36; Iter    15/  183] train: loss: 0.2033810
[Epoch 36; Iter    45/  183] train: loss: 0.1781596
[Epoch 36; Iter    75/  183] train: loss: 0.1894140
[Epoch 36; Iter   105/  183] train: loss: 0.1930074
[Epoch 36; Iter   135/  183] train: loss: 0.2391415
[Epoch 36; Iter   165/  183] train: loss: 0.0974176
[Epoch 36] ogbg-moltox21: 0.829053 val loss: 0.194627
[Epoch 36] ogbg-moltox21: 0.853119 test loss: 0.190056
[Epoch 37; Iter    12/  183] train: loss: 0.1574301
[Epoch 37; Iter    42/  183] train: loss: 0.1254809
[Epoch 37; Iter    72/  183] train: loss: 0.1509411
[Epoch 37; Iter   102/  183] train: loss: 0.0869830
[Epoch 37; Iter   132/  183] train: loss: 0.0986563
[Epoch 37; Iter   162/  183] train: loss: 0.1064664
[Epoch 37] ogbg-moltox21: 0.840722 val loss: 0.213999
[Epoch 37] ogbg-moltox21: 0.861225 test loss: 0.193814
[Epoch 38; Iter     9/  183] train: loss: 0.0983398
[Epoch 38; Iter    39/  183] train: loss: 0.1319851
[Epoch 38; Iter    69/  183] train: loss: 0.1553295
[Epoch 38; Iter    99/  183] train: loss: 0.1550360
[Epoch 38; Iter   129/  183] train: loss: 0.1586485
[Epoch 38; Iter   159/  183] train: loss: 0.1687935
[Epoch 38] ogbg-moltox21: 0.844495 val loss: 0.190359
[Epoch 38] ogbg-moltox21: 0.859038 test loss: 0.194106
[Epoch 39; Iter     6/  183] train: loss: 0.1318437
[Epoch 39; Iter    36/  183] train: loss: 0.1250325
[Epoch 39; Iter    66/  183] train: loss: 0.1310068
[Epoch 39; Iter    96/  183] train: loss: 0.1180236
[Epoch 39; Iter   126/  183] train: loss: 0.0955147
[Epoch 39; Iter   156/  183] train: loss: 0.1376771
[Epoch 39] ogbg-moltox21: 0.839808 val loss: 0.199044
[Epoch 39] ogbg-moltox21: 0.858544 test loss: 0.187380
[Epoch 40; Iter     3/  183] train: loss: 0.0875948
[Epoch 40; Iter    33/  183] train: loss: 0.1405890
[Epoch 40; Iter    63/  183] train: loss: 0.1803329
[Epoch 40; Iter    93/  183] train: loss: 0.0974642
[Epoch 40; Iter   123/  183] train: loss: 0.1972252
[Epoch 40; Iter   153/  183] train: loss: 0.1326446
[Epoch 40; Iter   183/  183] train: loss: 0.2522320
[Epoch 40] ogbg-moltox21: 0.840299 val loss: 0.220286
[Epoch 40] ogbg-moltox21: 0.854322 test loss: 0.194290
[Epoch 41; Iter    30/  183] train: loss: 0.0816072
[Epoch 41; Iter    60/  183] train: loss: 0.1585155
[Epoch 41; Iter    90/  183] train: loss: 0.1779307
[Epoch 41; Iter   120/  183] train: loss: 0.0891144
[Epoch 41; Iter   150/  183] train: loss: 0.2143534
[Epoch 41; Iter   180/  183] train: loss: 0.1612789
[Epoch 41] ogbg-moltox21: 0.844722 val loss: 0.192951
[Epoch 41] ogbg-moltox21: 0.853490 test loss: 0.193520
[Epoch 42; Iter    27/  183] train: loss: 0.1449179
[Epoch 42; Iter    57/  183] train: loss: 0.1126705
[Epoch 42; Iter    87/  183] train: loss: 0.1536672
[Epoch 42; Iter   117/  183] train: loss: 0.1268048
[Epoch 42; Iter   147/  183] train: loss: 0.1599556
[Epoch 42; Iter   177/  183] train: loss: 0.0884974
[Epoch 42] ogbg-moltox21: 0.831676 val loss: 0.199853
[Epoch 42] ogbg-moltox21: 0.851047 test loss: 0.195417
[Epoch 43; Iter    24/  183] train: loss: 0.0808296
[Epoch 43; Iter    54/  183] train: loss: 0.1118409
[Epoch 43; Iter    84/  183] train: loss: 0.1566016
[Epoch 43; Iter   114/  183] train: loss: 0.0829881
[Epoch 43; Iter   144/  183] train: loss: 0.1118720
[Epoch 43; Iter   174/  183] train: loss: 0.1839049
[Epoch 43] ogbg-moltox21: 0.839073 val loss: 0.195606
[Epoch 43] ogbg-moltox21: 0.849543 test loss: 0.192469
[Epoch 44; Iter    21/  183] train: loss: 0.1134291
[Epoch 44; Iter    51/  183] train: loss: 0.1656730
[Epoch 44; Iter    81/  183] train: loss: 0.1239322
[Epoch 44; Iter   111/  183] train: loss: 0.1134510
[Epoch 44; Iter   141/  183] train: loss: 0.1791100
[Epoch 44; Iter   171/  183] train: loss: 0.1301256
[Epoch 44] ogbg-moltox21: 0.839797 val loss: 0.211779
[Epoch 44] ogbg-moltox21: 0.853394 test loss: 0.193126
[Epoch 45; Iter    18/  183] train: loss: 0.0671260
[Epoch 45; Iter    48/  183] train: loss: 0.1629041
[Epoch 45; Iter    78/  183] train: loss: 0.1256313
[Epoch 45; Iter   108/  183] train: loss: 0.0645115
[Epoch 45; Iter   138/  183] train: loss: 0.0801569
[Epoch 45; Iter   168/  183] train: loss: 0.1605963
[Epoch 45] ogbg-moltox21: 0.834738 val loss: 0.202859
[Epoch 45] ogbg-moltox21: 0.853402 test loss: 0.192671
[Epoch 46; Iter    15/  183] train: loss: 0.1125168
[Epoch 46; Iter    45/  183] train: loss: 0.1940302
[Epoch 46; Iter    75/  183] train: loss: 0.1059943
[Epoch 46; Iter   105/  183] train: loss: 0.1344837
[Epoch 46; Iter   135/  183] train: loss: 0.1317692
[Epoch 46; Iter   165/  183] train: loss: 0.0860641
[Epoch 46] ogbg-moltox21: 0.829725 val loss: 0.218174
[Epoch 46] ogbg-moltox21: 0.837175 test loss: 0.210399
[Epoch 47; Iter    12/  183] train: loss: 0.0919989
[Epoch 47; Iter    42/  183] train: loss: 0.0912320
[Epoch 47; Iter    72/  183] train: loss: 0.0819746
[Epoch 47; Iter   102/  183] train: loss: 0.0920263
[Epoch 47; Iter   132/  183] train: loss: 0.1596759
[Epoch 47; Iter   162/  183] train: loss: 0.1807596
[Epoch 47] ogbg-moltox21: 0.832779 val loss: 0.212781
[Epoch 47] ogbg-moltox21: 0.844937 test loss: 0.199978
[Epoch 48; Iter     9/  183] train: loss: 0.0812977
[Epoch 48; Iter    39/  183] train: loss: 0.1510508
[Epoch 48; Iter    69/  183] train: loss: 0.1828844
[Epoch 48; Iter    99/  183] train: loss: 0.1203878
[Epoch 48; Iter   129/  183] train: loss: 0.1169791
[Epoch 48; Iter   159/  183] train: loss: 0.1194998
[Epoch 48] ogbg-moltox21: 0.834697 val loss: 0.223111
[Epoch 48] ogbg-moltox21: 0.847241 test loss: 0.206099
[Epoch 49; Iter     6/  183] train: loss: 0.1464204
[Epoch 49; Iter    36/  183] train: loss: 0.1837855
[Epoch 49; Iter    66/  183] train: loss: 0.1458543
[Epoch 49; Iter    96/  183] train: loss: 0.1647352
[Epoch 49; Iter   126/  183] train: loss: 0.1646152
[Epoch 49; Iter   156/  183] train: loss: 0.0967615
[Epoch 49] ogbg-moltox21: 0.835475 val loss: 0.214570
[Epoch 49] ogbg-moltox21: 0.852656 test loss: 0.200653
[Epoch 50; Iter     3/  183] train: loss: 0.1001110
[Epoch 50; Iter    33/  183] train: loss: 0.1309912
[Epoch 50; Iter    63/  183] train: loss: 0.0746648
[Epoch 50; Iter    93/  183] train: loss: 0.0839321
[Epoch 50; Iter   123/  183] train: loss: 0.1251259
[Epoch 50; Iter   153/  183] train: loss: 0.1045862
[Epoch 50; Iter   183/  183] train: loss: 0.1332588
[Epoch 50] ogbg-moltox21: 0.832865 val loss: 0.215725
[Epoch 50] ogbg-moltox21: 0.844238 test loss: 0.205513
[Epoch 51; Iter    30/  183] train: loss: 0.0718579
[Epoch 51; Iter    60/  183] train: loss: 0.1258317
[Epoch 51; Iter    90/  183] train: loss: 0.0954822
[Epoch 51; Iter   120/  183] train: loss: 0.1513139
[Epoch 51; Iter   150/  183] train: loss: 0.1063049
[Epoch 51; Iter   180/  183] train: loss: 0.1062174
[Epoch 51] ogbg-moltox21: 0.830037 val loss: 0.238452
[Epoch 51] ogbg-moltox21: 0.849899 test loss: 0.204727
[Epoch 52; Iter    27/  183] train: loss: 0.1096303
[Epoch 52; Iter    57/  183] train: loss: 0.1414892
[Epoch 52; Iter    87/  183] train: loss: 0.0900290
[Epoch 52; Iter   117/  183] train: loss: 0.1160099
[Epoch 37; Iter    78/  157] train: loss: 0.1366479
[Epoch 37; Iter   108/  157] train: loss: 0.1271471
[Epoch 37; Iter   138/  157] train: loss: 0.1557595
[Epoch 37] ogbg-moltox21: 0.821395 val loss: 0.192140
[Epoch 37] ogbg-moltox21: 0.830201 test loss: 0.248623
[Epoch 38; Iter    11/  157] train: loss: 0.1426071
[Epoch 38; Iter    41/  157] train: loss: 0.1250749
[Epoch 38; Iter    71/  157] train: loss: 0.1375169
[Epoch 38; Iter   101/  157] train: loss: 0.2664753
[Epoch 38; Iter   131/  157] train: loss: 0.1570713
[Epoch 38] ogbg-moltox21: 0.826590 val loss: 0.200922
[Epoch 38] ogbg-moltox21: 0.837486 test loss: 0.232962
[Epoch 39; Iter     4/  157] train: loss: 0.1521303
[Epoch 39; Iter    34/  157] train: loss: 0.1454344
[Epoch 39; Iter    64/  157] train: loss: 0.1365798
[Epoch 39; Iter    94/  157] train: loss: 0.1092317
[Epoch 39; Iter   124/  157] train: loss: 0.1754190
[Epoch 39; Iter   154/  157] train: loss: 0.1303279
[Epoch 39] ogbg-moltox21: 0.829715 val loss: 0.194295
[Epoch 39] ogbg-moltox21: 0.842656 test loss: 0.236760
[Epoch 40; Iter    27/  157] train: loss: 0.1073156
[Epoch 40; Iter    57/  157] train: loss: 0.1338339
[Epoch 40; Iter    87/  157] train: loss: 0.1453263
[Epoch 40; Iter   117/  157] train: loss: 0.1652485
[Epoch 40; Iter   147/  157] train: loss: 0.1545036
[Epoch 40] ogbg-moltox21: 0.824568 val loss: 0.216485
[Epoch 40] ogbg-moltox21: 0.848023 test loss: 0.199914
[Epoch 41; Iter    20/  157] train: loss: 0.1813838
[Epoch 41; Iter    50/  157] train: loss: 0.2120980
[Epoch 41; Iter    80/  157] train: loss: 0.1457298
[Epoch 41; Iter   110/  157] train: loss: 0.1778667
[Epoch 41; Iter   140/  157] train: loss: 0.1206822
[Epoch 41] ogbg-moltox21: 0.837700 val loss: 0.200565
[Epoch 41] ogbg-moltox21: 0.848767 test loss: 0.198542
[Epoch 42; Iter    13/  157] train: loss: 0.1340069
[Epoch 42; Iter    43/  157] train: loss: 0.2378903
[Epoch 42; Iter    73/  157] train: loss: 0.1412994
[Epoch 42; Iter   103/  157] train: loss: 0.1040323
[Epoch 42; Iter   133/  157] train: loss: 0.1526873
[Epoch 42] ogbg-moltox21: 0.837549 val loss: 0.189271
[Epoch 42] ogbg-moltox21: 0.842890 test loss: 0.200118
[Epoch 43; Iter     6/  157] train: loss: 0.1321729
[Epoch 43; Iter    36/  157] train: loss: 0.1032197
[Epoch 43; Iter    66/  157] train: loss: 0.1227771
[Epoch 43; Iter    96/  157] train: loss: 0.1650956
[Epoch 43; Iter   126/  157] train: loss: 0.1661958
[Epoch 43; Iter   156/  157] train: loss: 0.1209976
[Epoch 43] ogbg-moltox21: 0.838143 val loss: 0.186068
[Epoch 43] ogbg-moltox21: 0.847245 test loss: 0.195092
[Epoch 44; Iter    29/  157] train: loss: 0.1403397
[Epoch 44; Iter    59/  157] train: loss: 0.1822779
[Epoch 44; Iter    89/  157] train: loss: 0.1622709
[Epoch 44; Iter   119/  157] train: loss: 0.1409554
[Epoch 44; Iter   149/  157] train: loss: 0.1286520
[Epoch 44] ogbg-moltox21: 0.832151 val loss: 0.185929
[Epoch 44] ogbg-moltox21: 0.845224 test loss: 0.197501
[Epoch 45; Iter    22/  157] train: loss: 0.0968507
[Epoch 45; Iter    52/  157] train: loss: 0.1353228
[Epoch 45; Iter    82/  157] train: loss: 0.1685059
[Epoch 45; Iter   112/  157] train: loss: 0.1085698
[Epoch 45; Iter   142/  157] train: loss: 0.1936475
[Epoch 45] ogbg-moltox21: 0.828206 val loss: 0.193028
[Epoch 45] ogbg-moltox21: 0.836357 test loss: 0.204462
[Epoch 46; Iter    15/  157] train: loss: 0.1735082
[Epoch 46; Iter    45/  157] train: loss: 0.1725630
[Epoch 46; Iter    75/  157] train: loss: 0.1484077
[Epoch 46; Iter   105/  157] train: loss: 0.1840372
[Epoch 46; Iter   135/  157] train: loss: 0.1780735
[Epoch 46] ogbg-moltox21: 0.831966 val loss: 0.206776
[Epoch 46] ogbg-moltox21: 0.846571 test loss: 0.200444
[Epoch 47; Iter     8/  157] train: loss: 0.1223346
[Epoch 47; Iter    38/  157] train: loss: 0.2032564
[Epoch 47; Iter    68/  157] train: loss: 0.1453891
[Epoch 47; Iter    98/  157] train: loss: 0.1830421
[Epoch 47; Iter   128/  157] train: loss: 0.1148232
[Epoch 47] ogbg-moltox21: 0.822347 val loss: 0.190478
[Epoch 47] ogbg-moltox21: 0.834508 test loss: 0.203463
[Epoch 48; Iter     1/  157] train: loss: 0.1048659
[Epoch 48; Iter    31/  157] train: loss: 0.1140560
[Epoch 48; Iter    61/  157] train: loss: 0.1898550
[Epoch 48; Iter    91/  157] train: loss: 0.1957134
[Epoch 48; Iter   121/  157] train: loss: 0.1832964
[Epoch 48; Iter   151/  157] train: loss: 0.1566114
[Epoch 48] ogbg-moltox21: 0.819972 val loss: 0.194037
[Epoch 48] ogbg-moltox21: 0.827583 test loss: 0.208998
[Epoch 49; Iter    24/  157] train: loss: 0.2377903
[Epoch 49; Iter    54/  157] train: loss: 0.2019170
[Epoch 49; Iter    84/  157] train: loss: 0.1282315
[Epoch 49; Iter   114/  157] train: loss: 0.1476378
[Epoch 49; Iter   144/  157] train: loss: 0.1327217
[Epoch 49] ogbg-moltox21: 0.828595 val loss: 0.188813
[Epoch 49] ogbg-moltox21: 0.841592 test loss: 0.199217
[Epoch 50; Iter    17/  157] train: loss: 0.1280831
[Epoch 50; Iter    47/  157] train: loss: 0.1749547
[Epoch 50; Iter    77/  157] train: loss: 0.1413653
[Epoch 50; Iter   107/  157] train: loss: 0.0876949
[Epoch 50; Iter   137/  157] train: loss: 0.2392484
[Epoch 50] ogbg-moltox21: 0.834829 val loss: 0.224808
[Epoch 50] ogbg-moltox21: 0.845403 test loss: 0.201369
[Epoch 51; Iter    10/  157] train: loss: 0.2715820
[Epoch 51; Iter    40/  157] train: loss: 0.1559485
[Epoch 51; Iter    70/  157] train: loss: 0.0945112
[Epoch 51; Iter   100/  157] train: loss: 0.0836750
[Epoch 51; Iter   130/  157] train: loss: 0.1401830
[Epoch 51] ogbg-moltox21: 0.832874 val loss: 0.223865
[Epoch 51] ogbg-moltox21: 0.840696 test loss: 0.201931
[Epoch 52; Iter     3/  157] train: loss: 0.1405553
[Epoch 52; Iter    33/  157] train: loss: 0.2010599
[Epoch 52; Iter    63/  157] train: loss: 0.1110419
[Epoch 52; Iter    93/  157] train: loss: 0.1336511
[Epoch 52; Iter   123/  157] train: loss: 0.1677894
[Epoch 52; Iter   153/  157] train: loss: 0.1706015
[Epoch 52] ogbg-moltox21: 0.826889 val loss: 0.194752
[Epoch 52] ogbg-moltox21: 0.834187 test loss: 0.204856
[Epoch 53; Iter    26/  157] train: loss: 0.1166705
[Epoch 53; Iter    56/  157] train: loss: 0.1795806
[Epoch 53; Iter    86/  157] train: loss: 0.1289983
[Epoch 53; Iter   116/  157] train: loss: 0.1118166
[Epoch 53; Iter   146/  157] train: loss: 0.1841494
[Epoch 53] ogbg-moltox21: 0.827318 val loss: 0.195320
[Epoch 53] ogbg-moltox21: 0.840482 test loss: 0.207566
[Epoch 54; Iter    19/  157] train: loss: 0.1533266
[Epoch 54; Iter    49/  157] train: loss: 0.1116437
[Epoch 54; Iter    79/  157] train: loss: 0.1127269
[Epoch 54; Iter   109/  157] train: loss: 0.1124258
[Epoch 54; Iter   139/  157] train: loss: 0.1177042
[Epoch 54] ogbg-moltox21: 0.835906 val loss: 0.219629
[Epoch 54] ogbg-moltox21: 0.839264 test loss: 0.204981
[Epoch 55; Iter    12/  157] train: loss: 0.1113279
[Epoch 55; Iter    42/  157] train: loss: 0.1738334
[Epoch 55; Iter    72/  157] train: loss: 0.1587605
[Epoch 55; Iter   102/  157] train: loss: 0.1923263
[Epoch 55; Iter   132/  157] train: loss: 0.1645244
[Epoch 55] ogbg-moltox21: 0.833140 val loss: 0.200156
[Epoch 55] ogbg-moltox21: 0.832902 test loss: 0.212871
[Epoch 56; Iter     5/  157] train: loss: 0.1508487
[Epoch 56; Iter    35/  157] train: loss: 0.1051659
[Epoch 56; Iter    65/  157] train: loss: 0.1341924
[Epoch 56; Iter    95/  157] train: loss: 0.1261077
[Epoch 56; Iter   125/  157] train: loss: 0.0858958
[Epoch 56; Iter   155/  157] train: loss: 0.1377685
[Epoch 56] ogbg-moltox21: 0.824142 val loss: 0.204013
[Epoch 56] ogbg-moltox21: 0.839077 test loss: 0.211859
[Epoch 57; Iter    28/  157] train: loss: 0.1355758
[Epoch 57; Iter    58/  157] train: loss: 0.2090033
[Epoch 57; Iter    88/  157] train: loss: 0.1243468
[Epoch 57; Iter   118/  157] train: loss: 0.2161347
[Epoch 57; Iter   148/  157] train: loss: 0.0912977
[Epoch 57] ogbg-moltox21: 0.823711 val loss: 0.201068
[Epoch 57] ogbg-moltox21: 0.834129 test loss: 0.209138
[Epoch 58; Iter    21/  157] train: loss: 0.1246589
[Epoch 58; Iter    51/  157] train: loss: 0.1340069
[Epoch 58; Iter    81/  157] train: loss: 0.1676891
[Epoch 58; Iter   111/  157] train: loss: 0.0941060
[Epoch 58; Iter   141/  157] train: loss: 0.1198814
[Epoch 37; Iter    78/  157] train: loss: 0.1473861
[Epoch 37; Iter   108/  157] train: loss: 0.1479293
[Epoch 37; Iter   138/  157] train: loss: 0.1640934
[Epoch 37] ogbg-moltox21: 0.832378 val loss: 0.189025
[Epoch 37] ogbg-moltox21: 0.839317 test loss: 0.199670
[Epoch 38; Iter    11/  157] train: loss: 0.1507523
[Epoch 38; Iter    41/  157] train: loss: 0.1564314
[Epoch 38; Iter    71/  157] train: loss: 0.1540227
[Epoch 38; Iter   101/  157] train: loss: 0.1655788
[Epoch 38; Iter   131/  157] train: loss: 0.0966386
[Epoch 38] ogbg-moltox21: 0.820560 val loss: 0.522729
[Epoch 38] ogbg-moltox21: 0.841145 test loss: 0.202331
[Epoch 39; Iter     4/  157] train: loss: 0.1296069
[Epoch 39; Iter    34/  157] train: loss: 0.1144873
[Epoch 39; Iter    64/  157] train: loss: 0.0929982
[Epoch 39; Iter    94/  157] train: loss: 0.1502578
[Epoch 39; Iter   124/  157] train: loss: 0.0944683
[Epoch 39; Iter   154/  157] train: loss: 0.1477822
[Epoch 39] ogbg-moltox21: 0.835185 val loss: 0.184105
[Epoch 39] ogbg-moltox21: 0.851483 test loss: 0.193229
[Epoch 40; Iter    27/  157] train: loss: 0.1425896
[Epoch 40; Iter    57/  157] train: loss: 0.1221112
[Epoch 40; Iter    87/  157] train: loss: 0.1286778
[Epoch 40; Iter   117/  157] train: loss: 0.2147457
[Epoch 40; Iter   147/  157] train: loss: 0.1253861
[Epoch 40] ogbg-moltox21: 0.835461 val loss: 0.188600
[Epoch 40] ogbg-moltox21: 0.849515 test loss: 0.198788
[Epoch 41; Iter    20/  157] train: loss: 0.0989582
[Epoch 41; Iter    50/  157] train: loss: 0.1907525
[Epoch 41; Iter    80/  157] train: loss: 0.1760584
[Epoch 41; Iter   110/  157] train: loss: 0.1134766
[Epoch 41; Iter   140/  157] train: loss: 0.1222868
[Epoch 41] ogbg-moltox21: 0.839313 val loss: 0.189439
[Epoch 41] ogbg-moltox21: 0.854240 test loss: 0.194442
[Epoch 42; Iter    13/  157] train: loss: 0.0831358
[Epoch 42; Iter    43/  157] train: loss: 0.1612244
[Epoch 42; Iter    73/  157] train: loss: 0.1368138
[Epoch 42; Iter   103/  157] train: loss: 0.0855651
[Epoch 42; Iter   133/  157] train: loss: 0.1689653
[Epoch 42] ogbg-moltox21: 0.840997 val loss: 0.185121
[Epoch 42] ogbg-moltox21: 0.852378 test loss: 0.196921
[Epoch 43; Iter     6/  157] train: loss: 0.0687186
[Epoch 43; Iter    36/  157] train: loss: 0.1201399
[Epoch 43; Iter    66/  157] train: loss: 0.0849057
[Epoch 43; Iter    96/  157] train: loss: 0.1399036
[Epoch 43; Iter   126/  157] train: loss: 0.1652581
[Epoch 43; Iter   156/  157] train: loss: 0.1060896
[Epoch 43] ogbg-moltox21: 0.838122 val loss: 0.196874
[Epoch 43] ogbg-moltox21: 0.847997 test loss: 0.207286
[Epoch 44; Iter    29/  157] train: loss: 0.0955500
[Epoch 44; Iter    59/  157] train: loss: 0.1058088
[Epoch 44; Iter    89/  157] train: loss: 0.1199990
[Epoch 44; Iter   119/  157] train: loss: 0.1143166
[Epoch 44; Iter   149/  157] train: loss: 0.1655495
[Epoch 44] ogbg-moltox21: 0.837355 val loss: 0.192622
[Epoch 44] ogbg-moltox21: 0.847623 test loss: 0.209377
[Epoch 45; Iter    22/  157] train: loss: 0.1459083
[Epoch 45; Iter    52/  157] train: loss: 0.0984594
[Epoch 45; Iter    82/  157] train: loss: 0.1298606
[Epoch 45; Iter   112/  157] train: loss: 0.0841276
[Epoch 45; Iter   142/  157] train: loss: 0.1217208
[Epoch 45] ogbg-moltox21: 0.834301 val loss: 0.190288
[Epoch 45] ogbg-moltox21: 0.844769 test loss: 0.206134
[Epoch 46; Iter    15/  157] train: loss: 0.1087175
[Epoch 46; Iter    45/  157] train: loss: 0.2298937
[Epoch 46; Iter    75/  157] train: loss: 0.2290951
[Epoch 46; Iter   105/  157] train: loss: 0.1631139
[Epoch 46; Iter   135/  157] train: loss: 0.1400333
[Epoch 46] ogbg-moltox21: 0.828508 val loss: 0.202395
[Epoch 46] ogbg-moltox21: 0.846154 test loss: 0.214075
[Epoch 47; Iter     8/  157] train: loss: 0.1341750
[Epoch 47; Iter    38/  157] train: loss: 0.1134706
[Epoch 47; Iter    68/  157] train: loss: 0.1101522
[Epoch 47; Iter    98/  157] train: loss: 0.1146115
[Epoch 47; Iter   128/  157] train: loss: 0.1197438
[Epoch 47] ogbg-moltox21: 0.832705 val loss: 0.196958
[Epoch 47] ogbg-moltox21: 0.846867 test loss: 0.206505
[Epoch 48; Iter     1/  157] train: loss: 0.0479854
[Epoch 48; Iter    31/  157] train: loss: 0.0881760
[Epoch 48; Iter    61/  157] train: loss: 0.1684732
[Epoch 48; Iter    91/  157] train: loss: 0.0846101
[Epoch 48; Iter   121/  157] train: loss: 0.1948042
[Epoch 48; Iter   151/  157] train: loss: 0.2041387
[Epoch 48] ogbg-moltox21: 0.834252 val loss: 0.194119
[Epoch 48] ogbg-moltox21: 0.854440 test loss: 0.201888
[Epoch 49; Iter    24/  157] train: loss: 0.1055396
[Epoch 49; Iter    54/  157] train: loss: 0.1599912
[Epoch 49; Iter    84/  157] train: loss: 0.1325855
[Epoch 49; Iter   114/  157] train: loss: 0.1383931
[Epoch 49; Iter   144/  157] train: loss: 0.1047925
[Epoch 49] ogbg-moltox21: 0.837812 val loss: 0.195464
[Epoch 49] ogbg-moltox21: 0.847260 test loss: 0.208551
[Epoch 50; Iter    17/  157] train: loss: 0.1042080
[Epoch 50; Iter    47/  157] train: loss: 0.1071915
[Epoch 50; Iter    77/  157] train: loss: 0.1671824
[Epoch 50; Iter   107/  157] train: loss: 0.1072807
[Epoch 50; Iter   137/  157] train: loss: 0.0834926
[Epoch 50] ogbg-moltox21: 0.831853 val loss: 0.196906
[Epoch 50] ogbg-moltox21: 0.846826 test loss: 0.209187
[Epoch 51; Iter    10/  157] train: loss: 0.1128584
[Epoch 51; Iter    40/  157] train: loss: 0.1083242
[Epoch 51; Iter    70/  157] train: loss: 0.1356797
[Epoch 51; Iter   100/  157] train: loss: 0.0705421
[Epoch 51; Iter   130/  157] train: loss: 0.0960403
[Epoch 51] ogbg-moltox21: 0.827355 val loss: 0.203105
[Epoch 51] ogbg-moltox21: 0.843712 test loss: 0.214681
[Epoch 52; Iter     3/  157] train: loss: 0.1253919
[Epoch 52; Iter    33/  157] train: loss: 0.1625035
[Epoch 52; Iter    63/  157] train: loss: 0.1034535
[Epoch 52; Iter    93/  157] train: loss: 0.1142928
[Epoch 52; Iter   123/  157] train: loss: 0.0709856
[Epoch 52; Iter   153/  157] train: loss: 0.1619845
[Epoch 52] ogbg-moltox21: 0.829472 val loss: 0.198921
[Epoch 52] ogbg-moltox21: 0.849342 test loss: 0.210588
[Epoch 53; Iter    26/  157] train: loss: 0.1052644
[Epoch 53; Iter    56/  157] train: loss: 0.1091178
[Epoch 53; Iter    86/  157] train: loss: 0.0537617
[Epoch 53; Iter   116/  157] train: loss: 0.0747829
[Epoch 53; Iter   146/  157] train: loss: 0.1000067
[Epoch 53] ogbg-moltox21: 0.828968 val loss: 0.199018
[Epoch 53] ogbg-moltox21: 0.843018 test loss: 0.213158
[Epoch 54; Iter    19/  157] train: loss: 0.1391079
[Epoch 54; Iter    49/  157] train: loss: 0.1358860
[Epoch 54; Iter    79/  157] train: loss: 0.1121631
[Epoch 54; Iter   109/  157] train: loss: 0.1205164
[Epoch 54; Iter   139/  157] train: loss: 0.0849370
[Epoch 54] ogbg-moltox21: 0.833477 val loss: 0.201913
[Epoch 54] ogbg-moltox21: 0.846657 test loss: 0.208450
[Epoch 55; Iter    12/  157] train: loss: 0.1238120
[Epoch 55; Iter    42/  157] train: loss: 0.1577882
[Epoch 55; Iter    72/  157] train: loss: 0.1005691
[Epoch 55; Iter   102/  157] train: loss: 0.0555995
[Epoch 55; Iter   132/  157] train: loss: 0.0669170
[Epoch 55] ogbg-moltox21: 0.822175 val loss: 0.206490
[Epoch 55] ogbg-moltox21: 0.842047 test loss: 0.215301
[Epoch 56; Iter     5/  157] train: loss: 0.1049134
[Epoch 56; Iter    35/  157] train: loss: 0.0656968
[Epoch 56; Iter    65/  157] train: loss: 0.0958226
[Epoch 56; Iter    95/  157] train: loss: 0.1056735
[Epoch 56; Iter   125/  157] train: loss: 0.1013733
[Epoch 56; Iter   155/  157] train: loss: 0.0846104
[Epoch 56] ogbg-moltox21: 0.827314 val loss: 0.207409
[Epoch 56] ogbg-moltox21: 0.828867 test loss: 0.223358
[Epoch 57; Iter    28/  157] train: loss: 0.0673079
[Epoch 57; Iter    58/  157] train: loss: 0.1114948
[Epoch 57; Iter    88/  157] train: loss: 0.1174117
[Epoch 57; Iter   118/  157] train: loss: 0.1202153
[Epoch 57; Iter   148/  157] train: loss: 0.0933620
[Epoch 57] ogbg-moltox21: 0.823840 val loss: 0.208842
[Epoch 57] ogbg-moltox21: 0.837962 test loss: 0.221314
[Epoch 58; Iter    21/  157] train: loss: 0.1078972
[Epoch 58; Iter    51/  157] train: loss: 0.0920246
[Epoch 58; Iter    81/  157] train: loss: 0.1025587
[Epoch 58; Iter   111/  157] train: loss: 0.0953248
[Epoch 58; Iter   141/  157] train: loss: 0.0722335
[Epoch 37; Iter    78/  157] train: loss: 0.1491317
[Epoch 37; Iter   108/  157] train: loss: 0.1663627
[Epoch 37; Iter   138/  157] train: loss: 0.1567902
[Epoch 37] ogbg-moltox21: 0.827352 val loss: 0.193766
[Epoch 37] ogbg-moltox21: 0.846349 test loss: 0.212343
[Epoch 38; Iter    11/  157] train: loss: 0.2059518
[Epoch 38; Iter    41/  157] train: loss: 0.0952233
[Epoch 38; Iter    71/  157] train: loss: 0.1216294
[Epoch 38; Iter   101/  157] train: loss: 0.1333153
[Epoch 38; Iter   131/  157] train: loss: 0.1705614
[Epoch 38] ogbg-moltox21: 0.814701 val loss: 0.199304
[Epoch 38] ogbg-moltox21: 0.825619 test loss: 0.216811
[Epoch 39; Iter     4/  157] train: loss: 0.1565455
[Epoch 39; Iter    34/  157] train: loss: 0.2009500
[Epoch 39; Iter    64/  157] train: loss: 0.1112720
[Epoch 39; Iter    94/  157] train: loss: 0.1353633
[Epoch 39; Iter   124/  157] train: loss: 0.1859922
[Epoch 39; Iter   154/  157] train: loss: 0.1483295
[Epoch 39] ogbg-moltox21: 0.835974 val loss: 0.188856
[Epoch 39] ogbg-moltox21: 0.848383 test loss: 0.201612
[Epoch 40; Iter    27/  157] train: loss: 0.1250764
[Epoch 40; Iter    57/  157] train: loss: 0.1401379
[Epoch 40; Iter    87/  157] train: loss: 0.1703784
[Epoch 40; Iter   117/  157] train: loss: 0.3049512
[Epoch 40; Iter   147/  157] train: loss: 0.1350861
[Epoch 40] ogbg-moltox21: 0.823722 val loss: 0.190574
[Epoch 40] ogbg-moltox21: 0.847344 test loss: 0.196578
[Epoch 41; Iter    20/  157] train: loss: 0.1187495
[Epoch 41; Iter    50/  157] train: loss: 0.1176222
[Epoch 41; Iter    80/  157] train: loss: 0.2030733
[Epoch 41; Iter   110/  157] train: loss: 0.1382160
[Epoch 41; Iter   140/  157] train: loss: 0.1364106
[Epoch 41] ogbg-moltox21: 0.834717 val loss: 0.185200
[Epoch 41] ogbg-moltox21: 0.850293 test loss: 0.196555
[Epoch 42; Iter    13/  157] train: loss: 0.1494182
[Epoch 42; Iter    43/  157] train: loss: 0.0807463
[Epoch 42; Iter    73/  157] train: loss: 0.2620479
[Epoch 42; Iter   103/  157] train: loss: 0.1220869
[Epoch 42; Iter   133/  157] train: loss: 0.1417513
[Epoch 42] ogbg-moltox21: 0.833008 val loss: 0.185096
[Epoch 42] ogbg-moltox21: 0.846312 test loss: 0.196489
[Epoch 43; Iter     6/  157] train: loss: 0.1072872
[Epoch 43; Iter    36/  157] train: loss: 0.0857619
[Epoch 43; Iter    66/  157] train: loss: 0.1298667
[Epoch 43; Iter    96/  157] train: loss: 0.1947960
[Epoch 43; Iter   126/  157] train: loss: 0.1226847
[Epoch 43; Iter   156/  157] train: loss: 0.1444387
[Epoch 43] ogbg-moltox21: 0.831500 val loss: 0.223033
[Epoch 43] ogbg-moltox21: 0.849566 test loss: 0.203753
[Epoch 44; Iter    29/  157] train: loss: 0.0864672
[Epoch 44; Iter    59/  157] train: loss: 0.1537677
[Epoch 44; Iter    89/  157] train: loss: 0.2239609
[Epoch 44; Iter   119/  157] train: loss: 0.0912639
[Epoch 44; Iter   149/  157] train: loss: 0.1573581
[Epoch 44] ogbg-moltox21: 0.827597 val loss: 0.188073
[Epoch 44] ogbg-moltox21: 0.845852 test loss: 0.200487
[Epoch 45; Iter    22/  157] train: loss: 0.1392005
[Epoch 45; Iter    52/  157] train: loss: 0.1440856
[Epoch 45; Iter    82/  157] train: loss: 0.2135472
[Epoch 45; Iter   112/  157] train: loss: 0.1413649
[Epoch 45; Iter   142/  157] train: loss: 0.0737115
[Epoch 45] ogbg-moltox21: 0.824293 val loss: 0.194451
[Epoch 45] ogbg-moltox21: 0.845922 test loss: 0.202157
[Epoch 46; Iter    15/  157] train: loss: 0.1215154
[Epoch 46; Iter    45/  157] train: loss: 0.1166830
[Epoch 46; Iter    75/  157] train: loss: 0.1310283
[Epoch 46; Iter   105/  157] train: loss: 0.0909898
[Epoch 46; Iter   135/  157] train: loss: 0.1830460
[Epoch 46] ogbg-moltox21: 0.821283 val loss: 0.193648
[Epoch 46] ogbg-moltox21: 0.848281 test loss: 0.202078
[Epoch 47; Iter     8/  157] train: loss: 0.1389443
[Epoch 47; Iter    38/  157] train: loss: 0.1051731
[Epoch 47; Iter    68/  157] train: loss: 0.0970266
[Epoch 47; Iter    98/  157] train: loss: 0.0914543
[Epoch 47; Iter   128/  157] train: loss: 0.1307079
[Epoch 47] ogbg-moltox21: 0.829763 val loss: 0.200953
[Epoch 47] ogbg-moltox21: 0.843691 test loss: 0.205461
[Epoch 48; Iter     1/  157] train: loss: 0.2473051
[Epoch 48; Iter    31/  157] train: loss: 0.0871404
[Epoch 48; Iter    61/  157] train: loss: 0.0947252
[Epoch 48; Iter    91/  157] train: loss: 0.1977589
[Epoch 48; Iter   121/  157] train: loss: 0.1366622
[Epoch 48; Iter   151/  157] train: loss: 0.1386099
[Epoch 48] ogbg-moltox21: 0.818643 val loss: 0.237073
[Epoch 48] ogbg-moltox21: 0.846042 test loss: 0.210724
[Epoch 49; Iter    24/  157] train: loss: 0.1191709
[Epoch 49; Iter    54/  157] train: loss: 0.1364052
[Epoch 49; Iter    84/  157] train: loss: 0.1579686
[Epoch 49; Iter   114/  157] train: loss: 0.1358275
[Epoch 49; Iter   144/  157] train: loss: 0.1204031
[Epoch 49] ogbg-moltox21: 0.831300 val loss: 0.197461
[Epoch 49] ogbg-moltox21: 0.847451 test loss: 0.211637
[Epoch 50; Iter    17/  157] train: loss: 0.0916283
[Epoch 50; Iter    47/  157] train: loss: 0.1987467
[Epoch 50; Iter    77/  157] train: loss: 0.1516736
[Epoch 50; Iter   107/  157] train: loss: 0.0720755
[Epoch 50; Iter   137/  157] train: loss: 0.1225204
[Epoch 50] ogbg-moltox21: 0.818677 val loss: 0.200777
[Epoch 50] ogbg-moltox21: 0.838481 test loss: 0.218833
[Epoch 51; Iter    10/  157] train: loss: 0.1472248
[Epoch 51; Iter    40/  157] train: loss: 0.0924334
[Epoch 51; Iter    70/  157] train: loss: 0.0954267
[Epoch 51; Iter   100/  157] train: loss: 0.1214141
[Epoch 51; Iter   130/  157] train: loss: 0.1989325
[Epoch 51] ogbg-moltox21: 0.823145 val loss: 0.199658
[Epoch 51] ogbg-moltox21: 0.831112 test loss: 0.210169
[Epoch 52; Iter     3/  157] train: loss: 0.1334332
[Epoch 52; Iter    33/  157] train: loss: 0.1160228
[Epoch 52; Iter    63/  157] train: loss: 0.1287719
[Epoch 52; Iter    93/  157] train: loss: 0.1338369
[Epoch 52; Iter   123/  157] train: loss: 0.1018210
[Epoch 52; Iter   153/  157] train: loss: 0.1155366
[Epoch 52] ogbg-moltox21: 0.815776 val loss: 0.199779
[Epoch 52] ogbg-moltox21: 0.835972 test loss: 0.216425
[Epoch 53; Iter    26/  157] train: loss: 0.1139964
[Epoch 53; Iter    56/  157] train: loss: 0.0824778
[Epoch 53; Iter    86/  157] train: loss: 0.1806552
[Epoch 53; Iter   116/  157] train: loss: 0.1027072
[Epoch 53; Iter   146/  157] train: loss: 0.1087392
[Epoch 53] ogbg-moltox21: 0.825683 val loss: 0.196160
[Epoch 53] ogbg-moltox21: 0.841628 test loss: 0.211206
[Epoch 54; Iter    19/  157] train: loss: 0.1390879
[Epoch 54; Iter    49/  157] train: loss: 0.0876149
[Epoch 54; Iter    79/  157] train: loss: 0.1111450
[Epoch 54; Iter   109/  157] train: loss: 0.1161048
[Epoch 54; Iter   139/  157] train: loss: 0.0551658
[Epoch 54] ogbg-moltox21: 0.819798 val loss: 0.202998
[Epoch 54] ogbg-moltox21: 0.833619 test loss: 0.215311
[Epoch 55; Iter    12/  157] train: loss: 0.1250307
[Epoch 55; Iter    42/  157] train: loss: 0.0910524
[Epoch 55; Iter    72/  157] train: loss: 0.1928589
[Epoch 55; Iter   102/  157] train: loss: 0.0796315
[Epoch 55; Iter   132/  157] train: loss: 0.1654183
[Epoch 55] ogbg-moltox21: 0.822861 val loss: 0.200413
[Epoch 55] ogbg-moltox21: 0.832382 test loss: 0.216322
[Epoch 56; Iter     5/  157] train: loss: 0.0927290
[Epoch 56; Iter    35/  157] train: loss: 0.1178930
[Epoch 56; Iter    65/  157] train: loss: 0.1245603
[Epoch 56; Iter    95/  157] train: loss: 0.0815385
[Epoch 56; Iter   125/  157] train: loss: 0.1132451
[Epoch 56; Iter   155/  157] train: loss: 0.1042178
[Epoch 56] ogbg-moltox21: 0.822677 val loss: 0.202071
[Epoch 56] ogbg-moltox21: 0.835301 test loss: 0.215169
[Epoch 57; Iter    28/  157] train: loss: 0.0829645
[Epoch 57; Iter    58/  157] train: loss: 0.0959381
[Epoch 57; Iter    88/  157] train: loss: 0.1725182
[Epoch 57; Iter   118/  157] train: loss: 0.1506330
[Epoch 57; Iter   148/  157] train: loss: 0.0935393
[Epoch 57] ogbg-moltox21: 0.826435 val loss: 0.200294
[Epoch 57] ogbg-moltox21: 0.840478 test loss: 0.212602
[Epoch 58; Iter    21/  157] train: loss: 0.1158830
[Epoch 58; Iter    51/  157] train: loss: 0.0990737
[Epoch 58; Iter    81/  157] train: loss: 0.1132013
[Epoch 58; Iter   111/  157] train: loss: 0.0829503
[Epoch 58; Iter   141/  157] train: loss: 0.0777567
[Epoch 47; Iter   166/  209] train: loss: 0.1797991
[Epoch 47; Iter   196/  209] train: loss: 0.0944478
[Epoch 47] ogbg-moltox21: 0.864577 val loss: 0.196509
[Epoch 47] ogbg-moltox21: 0.844298 test loss: 0.187230
[Epoch 48; Iter    17/  209] train: loss: 0.1286875
[Epoch 48; Iter    47/  209] train: loss: 0.1563828
[Epoch 48; Iter    77/  209] train: loss: 0.2363408
[Epoch 48; Iter   107/  209] train: loss: 0.2222759
[Epoch 48; Iter   137/  209] train: loss: 0.1767817
[Epoch 48; Iter   167/  209] train: loss: 0.1354266
[Epoch 48; Iter   197/  209] train: loss: 0.1082113
[Epoch 48] ogbg-moltox21: 0.864066 val loss: 0.207570
[Epoch 48] ogbg-moltox21: 0.846629 test loss: 0.191369
[Epoch 49; Iter    18/  209] train: loss: 0.1335522
[Epoch 49; Iter    48/  209] train: loss: 0.1752895
[Epoch 49; Iter    78/  209] train: loss: 0.0901949
[Epoch 49; Iter   108/  209] train: loss: 0.1037905
[Epoch 49; Iter   138/  209] train: loss: 0.0966576
[Epoch 49; Iter   168/  209] train: loss: 0.1145308
[Epoch 49; Iter   198/  209] train: loss: 0.1404983
[Epoch 49] ogbg-moltox21: 0.861678 val loss: 0.196124
[Epoch 49] ogbg-moltox21: 0.842010 test loss: 0.234455
[Epoch 50; Iter    19/  209] train: loss: 0.1051858
[Epoch 50; Iter    49/  209] train: loss: 0.1095974
[Epoch 50; Iter    79/  209] train: loss: 0.0938811
[Epoch 50; Iter   109/  209] train: loss: 0.1807304
[Epoch 50; Iter   139/  209] train: loss: 0.1106625
[Epoch 50; Iter   169/  209] train: loss: 0.1201931
[Epoch 50; Iter   199/  209] train: loss: 0.1454148
[Epoch 50] ogbg-moltox21: 0.877437 val loss: 0.193203
[Epoch 50] ogbg-moltox21: 0.847856 test loss: 0.186322
[Epoch 51; Iter    20/  209] train: loss: 0.1289040
[Epoch 51; Iter    50/  209] train: loss: 0.1213199
[Epoch 51; Iter    80/  209] train: loss: 0.1861131
[Epoch 51; Iter   110/  209] train: loss: 0.1668335
[Epoch 51; Iter   140/  209] train: loss: 0.1335844
[Epoch 51; Iter   170/  209] train: loss: 0.2081337
[Epoch 51; Iter   200/  209] train: loss: 0.1397157
[Epoch 51] ogbg-moltox21: 0.870611 val loss: 0.200981
[Epoch 51] ogbg-moltox21: 0.853213 test loss: 0.187882
[Epoch 52; Iter    21/  209] train: loss: 0.1440204
[Epoch 52; Iter    51/  209] train: loss: 0.1400350
[Epoch 52; Iter    81/  209] train: loss: 0.1941618
[Epoch 52; Iter   111/  209] train: loss: 0.0960853
[Epoch 52; Iter   141/  209] train: loss: 0.0969296
[Epoch 52; Iter   171/  209] train: loss: 0.1236693
[Epoch 52; Iter   201/  209] train: loss: 0.0986737
[Epoch 52] ogbg-moltox21: 0.870228 val loss: 0.196395
[Epoch 52] ogbg-moltox21: 0.853828 test loss: 0.193698
[Epoch 53; Iter    22/  209] train: loss: 0.1588386
[Epoch 53; Iter    52/  209] train: loss: 0.0875374
[Epoch 53; Iter    82/  209] train: loss: 0.1232707
[Epoch 53; Iter   112/  209] train: loss: 0.1368918
[Epoch 53; Iter   142/  209] train: loss: 0.0778863
[Epoch 53; Iter   172/  209] train: loss: 0.2141614
[Epoch 53; Iter   202/  209] train: loss: 0.1232259
[Epoch 53] ogbg-moltox21: 0.870521 val loss: 0.196892
[Epoch 53] ogbg-moltox21: 0.850754 test loss: 0.190614
[Epoch 54; Iter    23/  209] train: loss: 0.1337460
[Epoch 54; Iter    53/  209] train: loss: 0.1183357
[Epoch 54; Iter    83/  209] train: loss: 0.1374850
[Epoch 54; Iter   113/  209] train: loss: 0.0893089
[Epoch 54; Iter   143/  209] train: loss: 0.1513481
[Epoch 54; Iter   173/  209] train: loss: 0.0932339
[Epoch 54; Iter   203/  209] train: loss: 0.2198433
[Epoch 54] ogbg-moltox21: 0.856733 val loss: 0.219387
[Epoch 54] ogbg-moltox21: 0.842305 test loss: 0.210252
[Epoch 55; Iter    24/  209] train: loss: 0.1184347
[Epoch 55; Iter    54/  209] train: loss: 0.1059544
[Epoch 55; Iter    84/  209] train: loss: 0.1008323
[Epoch 55; Iter   114/  209] train: loss: 0.0909332
[Epoch 55; Iter   144/  209] train: loss: 0.0991477
[Epoch 55; Iter   174/  209] train: loss: 0.2002104
[Epoch 55; Iter   204/  209] train: loss: 0.1163238
[Epoch 55] ogbg-moltox21: 0.864802 val loss: 0.233213
[Epoch 55] ogbg-moltox21: 0.852928 test loss: 0.264424
[Epoch 56; Iter    25/  209] train: loss: 0.1342351
[Epoch 56; Iter    55/  209] train: loss: 0.1065680
[Epoch 56; Iter    85/  209] train: loss: 0.1530967
[Epoch 56; Iter   115/  209] train: loss: 0.1024982
[Epoch 56; Iter   145/  209] train: loss: 0.2009471
[Epoch 56; Iter   175/  209] train: loss: 0.1585829
[Epoch 56; Iter   205/  209] train: loss: 0.1005941
[Epoch 56] ogbg-moltox21: 0.860095 val loss: 0.211363
[Epoch 56] ogbg-moltox21: 0.851403 test loss: 0.190410
[Epoch 57; Iter    26/  209] train: loss: 0.1462202
[Epoch 57; Iter    56/  209] train: loss: 0.1564592
[Epoch 57; Iter    86/  209] train: loss: 0.0796961
[Epoch 57; Iter   116/  209] train: loss: 0.1921404
[Epoch 57; Iter   146/  209] train: loss: 0.1094353
[Epoch 57; Iter   176/  209] train: loss: 0.1889651
[Epoch 57; Iter   206/  209] train: loss: 0.1098956
[Epoch 57] ogbg-moltox21: 0.862346 val loss: 0.218377
[Epoch 57] ogbg-moltox21: 0.857737 test loss: 0.188398
[Epoch 58; Iter    27/  209] train: loss: 0.1155057
[Epoch 58; Iter    57/  209] train: loss: 0.1120115
[Epoch 58; Iter    87/  209] train: loss: 0.1032658
[Epoch 58; Iter   117/  209] train: loss: 0.1303130
[Epoch 58; Iter   147/  209] train: loss: 0.0548286
[Epoch 58; Iter   177/  209] train: loss: 0.1895714
[Epoch 58; Iter   207/  209] train: loss: 0.1097693
[Epoch 58] ogbg-moltox21: 0.867995 val loss: 0.211143
[Epoch 58] ogbg-moltox21: 0.849187 test loss: 0.203569
[Epoch 59; Iter    28/  209] train: loss: 0.1311682
[Epoch 59; Iter    58/  209] train: loss: 0.0974288
[Epoch 59; Iter    88/  209] train: loss: 0.1334674
[Epoch 59; Iter   118/  209] train: loss: 0.0815137
[Epoch 59; Iter   148/  209] train: loss: 0.1427088
[Epoch 59; Iter   178/  209] train: loss: 0.1616400
[Epoch 59; Iter   208/  209] train: loss: 0.1571606
[Epoch 59] ogbg-moltox21: 0.857006 val loss: 0.223024
[Epoch 59] ogbg-moltox21: 0.848956 test loss: 0.202563
[Epoch 60; Iter    29/  209] train: loss: 0.1299217
[Epoch 60; Iter    59/  209] train: loss: 0.1059398
[Epoch 60; Iter    89/  209] train: loss: 0.0912318
[Epoch 60; Iter   119/  209] train: loss: 0.1681374
[Epoch 60; Iter   149/  209] train: loss: 0.1229580
[Epoch 60; Iter   179/  209] train: loss: 0.0824255
[Epoch 60; Iter   209/  209] train: loss: 0.1135280
[Epoch 60] ogbg-moltox21: 0.865575 val loss: 0.213891
[Epoch 60] ogbg-moltox21: 0.862183 test loss: 0.192410
[Epoch 61; Iter    30/  209] train: loss: 0.0983957
[Epoch 61; Iter    60/  209] train: loss: 0.0792144
[Epoch 61; Iter    90/  209] train: loss: 0.1106090
[Epoch 61; Iter   120/  209] train: loss: 0.0734178
[Epoch 61; Iter   150/  209] train: loss: 0.1452318
[Epoch 61; Iter   180/  209] train: loss: 0.0978958
[Epoch 61] ogbg-moltox21: 0.859951 val loss: 0.214386
[Epoch 61] ogbg-moltox21: 0.856730 test loss: 0.189161
[Epoch 62; Iter     1/  209] train: loss: 0.0973503
[Epoch 62; Iter    31/  209] train: loss: 0.1100246
[Epoch 62; Iter    61/  209] train: loss: 0.1026106
[Epoch 62; Iter    91/  209] train: loss: 0.0862516
[Epoch 62; Iter   121/  209] train: loss: 0.0698534
[Epoch 62; Iter   151/  209] train: loss: 0.0853883
[Epoch 62; Iter   181/  209] train: loss: 0.1896054
[Epoch 62] ogbg-moltox21: 0.856514 val loss: 0.226286
[Epoch 62] ogbg-moltox21: 0.846852 test loss: 0.202974
[Epoch 63; Iter     2/  209] train: loss: 0.1139755
[Epoch 63; Iter    32/  209] train: loss: 0.1039186
[Epoch 63; Iter    62/  209] train: loss: 0.0759570
[Epoch 63; Iter    92/  209] train: loss: 0.1168416
[Epoch 63; Iter   122/  209] train: loss: 0.1404320
[Epoch 63; Iter   152/  209] train: loss: 0.1383542
[Epoch 63; Iter   182/  209] train: loss: 0.1287505
[Epoch 63] ogbg-moltox21: 0.860910 val loss: 0.216642
[Epoch 63] ogbg-moltox21: 0.853631 test loss: 0.197369
[Epoch 64; Iter     3/  209] train: loss: 0.1204030
[Epoch 64; Iter    33/  209] train: loss: 0.0886106
[Epoch 64; Iter    63/  209] train: loss: 0.0984707
[Epoch 64; Iter    93/  209] train: loss: 0.0961809
[Epoch 64; Iter   123/  209] train: loss: 0.0695284
[Epoch 64; Iter   153/  209] train: loss: 0.0764688
[Epoch 64; Iter   183/  209] train: loss: 0.1624049
[Epoch 64] ogbg-moltox21: 0.864011 val loss: 0.223936
[Epoch 47; Iter   166/  209] train: loss: 0.1130639
[Epoch 47; Iter   196/  209] train: loss: 0.1381260
[Epoch 47] ogbg-moltox21: 0.863613 val loss: 0.206895
[Epoch 47] ogbg-moltox21: 0.852445 test loss: 0.216799
[Epoch 48; Iter    17/  209] train: loss: 0.1460675
[Epoch 48; Iter    47/  209] train: loss: 0.1094549
[Epoch 48; Iter    77/  209] train: loss: 0.1446566
[Epoch 48; Iter   107/  209] train: loss: 0.1070273
[Epoch 48; Iter   137/  209] train: loss: 0.0962769
[Epoch 48; Iter   167/  209] train: loss: 0.1723131
[Epoch 48; Iter   197/  209] train: loss: 0.0800624
[Epoch 48] ogbg-moltox21: 0.856222 val loss: 0.250726
[Epoch 48] ogbg-moltox21: 0.843729 test loss: 0.283229
[Epoch 49; Iter    18/  209] train: loss: 0.1401964
[Epoch 49; Iter    48/  209] train: loss: 0.1553270
[Epoch 49; Iter    78/  209] train: loss: 0.1361021
[Epoch 49; Iter   108/  209] train: loss: 0.1765037
[Epoch 49; Iter   138/  209] train: loss: 0.0869769
[Epoch 49; Iter   168/  209] train: loss: 0.1326479
[Epoch 49; Iter   198/  209] train: loss: 0.1185245
[Epoch 49] ogbg-moltox21: 0.858075 val loss: 0.207794
[Epoch 49] ogbg-moltox21: 0.836906 test loss: 0.496460
[Epoch 50; Iter    19/  209] train: loss: 0.1072477
[Epoch 50; Iter    49/  209] train: loss: 0.1256564
[Epoch 50; Iter    79/  209] train: loss: 0.1125750
[Epoch 50; Iter   109/  209] train: loss: 0.0789170
[Epoch 50; Iter   139/  209] train: loss: 0.1126563
[Epoch 50; Iter   169/  209] train: loss: 0.1211893
[Epoch 50; Iter   199/  209] train: loss: 0.2062225
[Epoch 50] ogbg-moltox21: 0.858245 val loss: 0.209805
[Epoch 50] ogbg-moltox21: 0.854369 test loss: 0.196939
[Epoch 51; Iter    20/  209] train: loss: 0.1319176
[Epoch 51; Iter    50/  209] train: loss: 0.0840411
[Epoch 51; Iter    80/  209] train: loss: 0.1852302
[Epoch 51; Iter   110/  209] train: loss: 0.1098992
[Epoch 51; Iter   140/  209] train: loss: 0.1187720
[Epoch 51; Iter   170/  209] train: loss: 0.0868371
[Epoch 51; Iter   200/  209] train: loss: 0.1133959
[Epoch 51] ogbg-moltox21: 0.861746 val loss: 0.209056
[Epoch 51] ogbg-moltox21: 0.848546 test loss: 0.317345
[Epoch 52; Iter    21/  209] train: loss: 0.1169334
[Epoch 52; Iter    51/  209] train: loss: 0.1489207
[Epoch 52; Iter    81/  209] train: loss: 0.1208419
[Epoch 52; Iter   111/  209] train: loss: 0.0778141
[Epoch 52; Iter   141/  209] train: loss: 0.1073252
[Epoch 52; Iter   171/  209] train: loss: 0.1456499
[Epoch 52; Iter   201/  209] train: loss: 0.1568926
[Epoch 52] ogbg-moltox21: 0.857102 val loss: 0.220844
[Epoch 52] ogbg-moltox21: 0.848742 test loss: 0.218024
[Epoch 53; Iter    22/  209] train: loss: 0.1233759
[Epoch 53; Iter    52/  209] train: loss: 0.1250521
[Epoch 53; Iter    82/  209] train: loss: 0.1150739
[Epoch 53; Iter   112/  209] train: loss: 0.0997569
[Epoch 53; Iter   142/  209] train: loss: 0.1194524
[Epoch 53; Iter   172/  209] train: loss: 0.1609729
[Epoch 53; Iter   202/  209] train: loss: 0.1187670
[Epoch 53] ogbg-moltox21: 0.852473 val loss: 0.217473
[Epoch 53] ogbg-moltox21: 0.845764 test loss: 0.200177
[Epoch 54; Iter    23/  209] train: loss: 0.1312202
[Epoch 54; Iter    53/  209] train: loss: 0.0857316
[Epoch 54; Iter    83/  209] train: loss: 0.1012222
[Epoch 54; Iter   113/  209] train: loss: 0.1610934
[Epoch 54; Iter   143/  209] train: loss: 0.1168398
[Epoch 54; Iter   173/  209] train: loss: 0.1318382
[Epoch 54; Iter   203/  209] train: loss: 0.1256644
[Epoch 54] ogbg-moltox21: 0.852222 val loss: 0.218869
[Epoch 54] ogbg-moltox21: 0.848772 test loss: 0.205512
[Epoch 55; Iter    24/  209] train: loss: 0.1239844
[Epoch 55; Iter    54/  209] train: loss: 0.1256347
[Epoch 55; Iter    84/  209] train: loss: 0.0897919
[Epoch 55; Iter   114/  209] train: loss: 0.1762501
[Epoch 55; Iter   144/  209] train: loss: 0.1165776
[Epoch 55; Iter   174/  209] train: loss: 0.1082764
[Epoch 55; Iter   204/  209] train: loss: 0.1507190
[Epoch 55] ogbg-moltox21: 0.853933 val loss: 0.216506
[Epoch 55] ogbg-moltox21: 0.843799 test loss: 0.199883
[Epoch 56; Iter    25/  209] train: loss: 0.1442716
[Epoch 56; Iter    55/  209] train: loss: 0.2268199
[Epoch 56; Iter    85/  209] train: loss: 0.0958335
[Epoch 56; Iter   115/  209] train: loss: 0.1130551
[Epoch 56; Iter   145/  209] train: loss: 0.1015696
[Epoch 56; Iter   175/  209] train: loss: 0.1100795
[Epoch 56; Iter   205/  209] train: loss: 0.1105961
[Epoch 56] ogbg-moltox21: 0.862268 val loss: 0.221548
[Epoch 56] ogbg-moltox21: 0.847454 test loss: 0.385160
[Epoch 57; Iter    26/  209] train: loss: 0.0999988
[Epoch 57; Iter    56/  209] train: loss: 0.1062169
[Epoch 57; Iter    86/  209] train: loss: 0.1997920
[Epoch 57; Iter   116/  209] train: loss: 0.1267987
[Epoch 57; Iter   146/  209] train: loss: 0.1222725
[Epoch 57; Iter   176/  209] train: loss: 0.1020864
[Epoch 57; Iter   206/  209] train: loss: 0.1426193
[Epoch 57] ogbg-moltox21: 0.844126 val loss: 0.226141
[Epoch 57] ogbg-moltox21: 0.844810 test loss: 0.205257
[Epoch 58; Iter    27/  209] train: loss: 0.1337227
[Epoch 58; Iter    57/  209] train: loss: 0.1231593
[Epoch 58; Iter    87/  209] train: loss: 0.0865658
[Epoch 58; Iter   117/  209] train: loss: 0.1455689
[Epoch 58; Iter   147/  209] train: loss: 0.0985077
[Epoch 58; Iter   177/  209] train: loss: 0.1022425
[Epoch 58; Iter   207/  209] train: loss: 0.0919377
[Epoch 58] ogbg-moltox21: 0.848266 val loss: 0.222939
[Epoch 58] ogbg-moltox21: 0.834572 test loss: 0.308637
[Epoch 59; Iter    28/  209] train: loss: 0.1841801
[Epoch 59; Iter    58/  209] train: loss: 0.0668555
[Epoch 59; Iter    88/  209] train: loss: 0.0935303
[Epoch 59; Iter   118/  209] train: loss: 0.1065850
[Epoch 59; Iter   148/  209] train: loss: 0.1085676
[Epoch 59; Iter   178/  209] train: loss: 0.1081629
[Epoch 59; Iter   208/  209] train: loss: 0.1047454
[Epoch 59] ogbg-moltox21: 0.844780 val loss: 0.225255
[Epoch 59] ogbg-moltox21: 0.837457 test loss: 0.214002
[Epoch 60; Iter    29/  209] train: loss: 0.0740153
[Epoch 60; Iter    59/  209] train: loss: 0.1557372
[Epoch 60; Iter    89/  209] train: loss: 0.0994579
[Epoch 60; Iter   119/  209] train: loss: 0.1131383
[Epoch 60; Iter   149/  209] train: loss: 0.0715509
[Epoch 60; Iter   179/  209] train: loss: 0.0637017
[Epoch 60; Iter   209/  209] train: loss: 0.0621095
[Epoch 60] ogbg-moltox21: 0.843088 val loss: 0.225280
[Epoch 60] ogbg-moltox21: 0.845123 test loss: 0.208755
[Epoch 61; Iter    30/  209] train: loss: 0.0855252
[Epoch 61; Iter    60/  209] train: loss: 0.1007995
[Epoch 61; Iter    90/  209] train: loss: 0.0786034
[Epoch 61; Iter   120/  209] train: loss: 0.1077271
[Epoch 61; Iter   150/  209] train: loss: 0.1381104
[Epoch 61; Iter   180/  209] train: loss: 0.1359947
[Epoch 61] ogbg-moltox21: 0.846184 val loss: 0.227714
[Epoch 61] ogbg-moltox21: 0.844348 test loss: 0.315793
[Epoch 62; Iter     1/  209] train: loss: 0.1027246
[Epoch 62; Iter    31/  209] train: loss: 0.1121322
[Epoch 62; Iter    61/  209] train: loss: 0.1220572
[Epoch 62; Iter    91/  209] train: loss: 0.1237904
[Epoch 62; Iter   121/  209] train: loss: 0.1021046
[Epoch 62; Iter   151/  209] train: loss: 0.0990171
[Epoch 62; Iter   181/  209] train: loss: 0.1211913
[Epoch 62] ogbg-moltox21: 0.849546 val loss: 0.220187
[Epoch 62] ogbg-moltox21: 0.845798 test loss: 0.205842
[Epoch 63; Iter     2/  209] train: loss: 0.1344692
[Epoch 63; Iter    32/  209] train: loss: 0.0775964
[Epoch 63; Iter    62/  209] train: loss: 0.0825802
[Epoch 63; Iter    92/  209] train: loss: 0.1042207
[Epoch 63; Iter   122/  209] train: loss: 0.0982924
[Epoch 63; Iter   152/  209] train: loss: 0.1142996
[Epoch 63; Iter   182/  209] train: loss: 0.1359691
[Epoch 63] ogbg-moltox21: 0.850878 val loss: 0.220941
[Epoch 63] ogbg-moltox21: 0.847057 test loss: 0.200952
[Epoch 64; Iter     3/  209] train: loss: 0.0743584
[Epoch 64; Iter    33/  209] train: loss: 0.1267072
[Epoch 64; Iter    63/  209] train: loss: 0.0685874
[Epoch 64; Iter    93/  209] train: loss: 0.0943120
[Epoch 64; Iter   123/  209] train: loss: 0.0726054
[Epoch 64; Iter   153/  209] train: loss: 0.0857775
[Epoch 64; Iter   183/  209] train: loss: 0.0700676
[Epoch 64] ogbg-moltox21: 0.845742 val loss: 0.229038
[Epoch 47; Iter   166/  209] train: loss: 0.1913984
[Epoch 47; Iter   196/  209] train: loss: 0.1246896
[Epoch 47] ogbg-moltox21: 0.853315 val loss: 0.222105
[Epoch 47] ogbg-moltox21: 0.843932 test loss: 0.197969
[Epoch 48; Iter    17/  209] train: loss: 0.1777196
[Epoch 48; Iter    47/  209] train: loss: 0.1509035
[Epoch 48; Iter    77/  209] train: loss: 0.1090187
[Epoch 48; Iter   107/  209] train: loss: 0.0932395
[Epoch 48; Iter   137/  209] train: loss: 0.1069816
[Epoch 48; Iter   167/  209] train: loss: 0.1320638
[Epoch 48; Iter   197/  209] train: loss: 0.1382650
[Epoch 48] ogbg-moltox21: 0.862930 val loss: 0.211190
[Epoch 48] ogbg-moltox21: 0.847224 test loss: 0.201289
[Epoch 49; Iter    18/  209] train: loss: 0.1393200
[Epoch 49; Iter    48/  209] train: loss: 0.1297204
[Epoch 49; Iter    78/  209] train: loss: 0.1022530
[Epoch 49; Iter   108/  209] train: loss: 0.0759869
[Epoch 49; Iter   138/  209] train: loss: 0.0960797
[Epoch 49; Iter   168/  209] train: loss: 0.1789168
[Epoch 49; Iter   198/  209] train: loss: 0.0895470
[Epoch 49] ogbg-moltox21: 0.860981 val loss: 0.216998
[Epoch 49] ogbg-moltox21: 0.843067 test loss: 0.201316
[Epoch 50; Iter    19/  209] train: loss: 0.1523758
[Epoch 50; Iter    49/  209] train: loss: 0.1572575
[Epoch 50; Iter    79/  209] train: loss: 0.1588589
[Epoch 50; Iter   109/  209] train: loss: 0.0745521
[Epoch 50; Iter   139/  209] train: loss: 0.0894809
[Epoch 50; Iter   169/  209] train: loss: 0.1328312
[Epoch 50; Iter   199/  209] train: loss: 0.1177041
[Epoch 50] ogbg-moltox21: 0.849273 val loss: 0.229975
[Epoch 50] ogbg-moltox21: 0.841073 test loss: 0.198893
[Epoch 51; Iter    20/  209] train: loss: 0.0914706
[Epoch 51; Iter    50/  209] train: loss: 0.1453701
[Epoch 51; Iter    80/  209] train: loss: 0.1124990
[Epoch 51; Iter   110/  209] train: loss: 0.1311112
[Epoch 51; Iter   140/  209] train: loss: 0.1372298
[Epoch 51; Iter   170/  209] train: loss: 0.1550488
[Epoch 51; Iter   200/  209] train: loss: 0.1530049
[Epoch 51] ogbg-moltox21: 0.851283 val loss: 0.224314
[Epoch 51] ogbg-moltox21: 0.831491 test loss: 0.208249
[Epoch 52; Iter    21/  209] train: loss: 0.0832859
[Epoch 52; Iter    51/  209] train: loss: 0.1395947
[Epoch 52; Iter    81/  209] train: loss: 0.0885153
[Epoch 52; Iter   111/  209] train: loss: 0.1086983
[Epoch 52; Iter   141/  209] train: loss: 0.0744050
[Epoch 52; Iter   171/  209] train: loss: 0.1010695
[Epoch 52; Iter   201/  209] train: loss: 0.1376231
[Epoch 52] ogbg-moltox21: 0.843173 val loss: 0.237323
[Epoch 52] ogbg-moltox21: 0.834195 test loss: 0.205225
[Epoch 53; Iter    22/  209] train: loss: 0.0871360
[Epoch 53; Iter    52/  209] train: loss: 0.1154994
[Epoch 53; Iter    82/  209] train: loss: 0.1275095
[Epoch 53; Iter   112/  209] train: loss: 0.2293054
[Epoch 53; Iter   142/  209] train: loss: 0.0604301
[Epoch 53; Iter   172/  209] train: loss: 0.1452085
[Epoch 53; Iter   202/  209] train: loss: 0.0833777
[Epoch 53] ogbg-moltox21: 0.849915 val loss: 0.222543
[Epoch 53] ogbg-moltox21: 0.847874 test loss: 0.210469
[Epoch 54; Iter    23/  209] train: loss: 0.1247320
[Epoch 54; Iter    53/  209] train: loss: 0.0618209
[Epoch 54; Iter    83/  209] train: loss: 0.1170472
[Epoch 54; Iter   113/  209] train: loss: 0.0902051
[Epoch 54; Iter   143/  209] train: loss: 0.1016149
[Epoch 54; Iter   173/  209] train: loss: 0.0886391
[Epoch 54; Iter   203/  209] train: loss: 0.0777771
[Epoch 54] ogbg-moltox21: 0.848269 val loss: 0.231893
[Epoch 54] ogbg-moltox21: 0.849027 test loss: 0.203906
[Epoch 55; Iter    24/  209] train: loss: 0.0996291
[Epoch 55; Iter    54/  209] train: loss: 0.0826648
[Epoch 55; Iter    84/  209] train: loss: 0.1046621
[Epoch 55; Iter   114/  209] train: loss: 0.1429076
[Epoch 55; Iter   144/  209] train: loss: 0.1199382
[Epoch 55; Iter   174/  209] train: loss: 0.1085303
[Epoch 55; Iter   204/  209] train: loss: 0.1385854
[Epoch 55] ogbg-moltox21: 0.843829 val loss: 0.235470
[Epoch 55] ogbg-moltox21: 0.842974 test loss: 0.216161
[Epoch 56; Iter    25/  209] train: loss: 0.1201761
[Epoch 56; Iter    55/  209] train: loss: 0.1792937
[Epoch 56; Iter    85/  209] train: loss: 0.0953855
[Epoch 56; Iter   115/  209] train: loss: 0.1336296
[Epoch 56; Iter   145/  209] train: loss: 0.0876870
[Epoch 56; Iter   175/  209] train: loss: 0.1175946
[Epoch 56; Iter   205/  209] train: loss: 0.1186918
[Epoch 56] ogbg-moltox21: 0.845472 val loss: 0.237769
[Epoch 56] ogbg-moltox21: 0.831750 test loss: 0.220583
[Epoch 57; Iter    26/  209] train: loss: 0.0586970
[Epoch 57; Iter    56/  209] train: loss: 0.1206244
[Epoch 57; Iter    86/  209] train: loss: 0.0925636
[Epoch 57; Iter   116/  209] train: loss: 0.0869051
[Epoch 57; Iter   146/  209] train: loss: 0.0606088
[Epoch 57; Iter   176/  209] train: loss: 0.0821169
[Epoch 57; Iter   206/  209] train: loss: 0.1167440
[Epoch 57] ogbg-moltox21: 0.844346 val loss: 0.236013
[Epoch 57] ogbg-moltox21: 0.831456 test loss: 0.275617
[Epoch 58; Iter    27/  209] train: loss: 0.0740853
[Epoch 58; Iter    57/  209] train: loss: 0.0631794
[Epoch 58; Iter    87/  209] train: loss: 0.0912571
[Epoch 58; Iter   117/  209] train: loss: 0.1236393
[Epoch 58; Iter   147/  209] train: loss: 0.1258984
[Epoch 58; Iter   177/  209] train: loss: 0.1421710
[Epoch 58; Iter   207/  209] train: loss: 0.0947707
[Epoch 58] ogbg-moltox21: 0.851981 val loss: 0.228813
[Epoch 58] ogbg-moltox21: 0.843915 test loss: 0.210709
[Epoch 59; Iter    28/  209] train: loss: 0.0791231
[Epoch 59; Iter    58/  209] train: loss: 0.0955419
[Epoch 59; Iter    88/  209] train: loss: 0.0721590
[Epoch 59; Iter   118/  209] train: loss: 0.1166718
[Epoch 59; Iter   148/  209] train: loss: 0.1090893
[Epoch 59; Iter   178/  209] train: loss: 0.0773751
[Epoch 59; Iter   208/  209] train: loss: 0.0703068
[Epoch 59] ogbg-moltox21: 0.857432 val loss: 0.225152
[Epoch 59] ogbg-moltox21: 0.838378 test loss: 0.210703
[Epoch 60; Iter    29/  209] train: loss: 0.0669321
[Epoch 60; Iter    59/  209] train: loss: 0.1197311
[Epoch 60; Iter    89/  209] train: loss: 0.1136576
[Epoch 60; Iter   119/  209] train: loss: 0.1023519
[Epoch 60; Iter   149/  209] train: loss: 0.0877682
[Epoch 60; Iter   179/  209] train: loss: 0.0898047
[Epoch 60; Iter   209/  209] train: loss: 0.0951968
[Epoch 60] ogbg-moltox21: 0.855228 val loss: 0.230942
[Epoch 60] ogbg-moltox21: 0.832465 test loss: 0.218315
[Epoch 61; Iter    30/  209] train: loss: 0.0671612
[Epoch 61; Iter    60/  209] train: loss: 0.0750980
[Epoch 61; Iter    90/  209] train: loss: 0.1098664
[Epoch 61; Iter   120/  209] train: loss: 0.0799725
[Epoch 61; Iter   150/  209] train: loss: 0.1407952
[Epoch 61; Iter   180/  209] train: loss: 0.1236543
[Epoch 61] ogbg-moltox21: 0.843725 val loss: 0.253070
[Epoch 61] ogbg-moltox21: 0.831309 test loss: 0.229598
[Epoch 62; Iter     1/  209] train: loss: 0.0724235
[Epoch 62; Iter    31/  209] train: loss: 0.1164887
[Epoch 62; Iter    61/  209] train: loss: 0.0732588
[Epoch 62; Iter    91/  209] train: loss: 0.0725895
[Epoch 62; Iter   121/  209] train: loss: 0.0786445
[Epoch 62; Iter   151/  209] train: loss: 0.0963247
[Epoch 62; Iter   181/  209] train: loss: 0.0799817
[Epoch 62] ogbg-moltox21: 0.844934 val loss: 0.238778
[Epoch 62] ogbg-moltox21: 0.824895 test loss: 0.224815
[Epoch 63; Iter     2/  209] train: loss: 0.1083956
[Epoch 63; Iter    32/  209] train: loss: 0.0755239
[Epoch 63; Iter    62/  209] train: loss: 0.0654447
[Epoch 63; Iter    92/  209] train: loss: 0.0792576
[Epoch 63; Iter   122/  209] train: loss: 0.0625520
[Epoch 63; Iter   152/  209] train: loss: 0.0881459
[Epoch 63; Iter   182/  209] train: loss: 0.0655294
[Epoch 63] ogbg-moltox21: 0.841740 val loss: 0.247097
[Epoch 63] ogbg-moltox21: 0.828750 test loss: 0.225367
[Epoch 64; Iter     3/  209] train: loss: 0.0964555
[Epoch 64; Iter    33/  209] train: loss: 0.0851383
[Epoch 64; Iter    63/  209] train: loss: 0.0844978
[Epoch 64; Iter    93/  209] train: loss: 0.0616371
[Epoch 64; Iter   123/  209] train: loss: 0.0733862
[Epoch 64; Iter   153/  209] train: loss: 0.0804520
[Epoch 64; Iter   183/  209] train: loss: 0.0670660
[Epoch 64] ogbg-moltox21: 0.835847 val loss: 0.244131
[Epoch 52; Iter   147/  183] train: loss: 0.1299076
[Epoch 52; Iter   177/  183] train: loss: 0.1263224
[Epoch 52] ogbg-moltox21: 0.829654 val loss: 0.205044
[Epoch 52] ogbg-moltox21: 0.849756 test loss: 0.198604
[Epoch 53; Iter    24/  183] train: loss: 0.1277383
[Epoch 53; Iter    54/  183] train: loss: 0.1318261
[Epoch 53; Iter    84/  183] train: loss: 0.1240550
[Epoch 53; Iter   114/  183] train: loss: 0.1528679
[Epoch 53; Iter   144/  183] train: loss: 0.1520573
[Epoch 53; Iter   174/  183] train: loss: 0.2389275
[Epoch 53] ogbg-moltox21: 0.831379 val loss: 0.197828
[Epoch 53] ogbg-moltox21: 0.850374 test loss: 0.191845
[Epoch 54; Iter    21/  183] train: loss: 0.1607111
[Epoch 54; Iter    51/  183] train: loss: 0.2081994
[Epoch 54; Iter    81/  183] train: loss: 0.1174367
[Epoch 54; Iter   111/  183] train: loss: 0.1547144
[Epoch 54; Iter   141/  183] train: loss: 0.1394538
[Epoch 54; Iter   171/  183] train: loss: 0.1202628
[Epoch 54] ogbg-moltox21: 0.834150 val loss: 0.197636
[Epoch 54] ogbg-moltox21: 0.850518 test loss: 0.192553
[Epoch 55; Iter    18/  183] train: loss: 0.1367306
[Epoch 55; Iter    48/  183] train: loss: 0.1642964
[Epoch 55; Iter    78/  183] train: loss: 0.1092979
[Epoch 55; Iter   108/  183] train: loss: 0.2385517
[Epoch 55; Iter   138/  183] train: loss: 0.1783982
[Epoch 55; Iter   168/  183] train: loss: 0.1143702
[Epoch 55] ogbg-moltox21: 0.824726 val loss: 0.205055
[Epoch 55] ogbg-moltox21: 0.845908 test loss: 0.197563
[Epoch 56; Iter    15/  183] train: loss: 0.1082034
[Epoch 56; Iter    45/  183] train: loss: 0.1368232
[Epoch 56; Iter    75/  183] train: loss: 0.1033053
[Epoch 56; Iter   105/  183] train: loss: 0.1142742
[Epoch 56; Iter   135/  183] train: loss: 0.1623333
[Epoch 56; Iter   165/  183] train: loss: 0.1625175
[Epoch 56] ogbg-moltox21: 0.822371 val loss: 0.199930
[Epoch 56] ogbg-moltox21: 0.846693 test loss: 0.196987
[Epoch 57; Iter    12/  183] train: loss: 0.1055640
[Epoch 57; Iter    42/  183] train: loss: 0.1113144
[Epoch 57; Iter    72/  183] train: loss: 0.1249178
[Epoch 57; Iter   102/  183] train: loss: 0.1494534
[Epoch 57; Iter   132/  183] train: loss: 0.1338226
[Epoch 57; Iter   162/  183] train: loss: 0.1659490
[Epoch 57] ogbg-moltox21: 0.820277 val loss: 0.201900
[Epoch 57] ogbg-moltox21: 0.842924 test loss: 0.200150
[Epoch 58; Iter     9/  183] train: loss: 0.1089360
[Epoch 58; Iter    39/  183] train: loss: 0.1124568
[Epoch 58; Iter    69/  183] train: loss: 0.1698934
[Epoch 58; Iter    99/  183] train: loss: 0.1408889
[Epoch 58; Iter   129/  183] train: loss: 0.1216527
[Epoch 58; Iter   159/  183] train: loss: 0.1303444
[Epoch 58] ogbg-moltox21: 0.834062 val loss: 0.197213
[Epoch 58] ogbg-moltox21: 0.848315 test loss: 0.206225
[Epoch 59; Iter     6/  183] train: loss: 0.2029928
[Epoch 59; Iter    36/  183] train: loss: 0.1857825
[Epoch 59; Iter    66/  183] train: loss: 0.1164438
[Epoch 59; Iter    96/  183] train: loss: 0.2202494
[Epoch 59; Iter   126/  183] train: loss: 0.1733386
[Epoch 59; Iter   156/  183] train: loss: 0.2330769
[Epoch 59] ogbg-moltox21: 0.825178 val loss: 0.203803
[Epoch 59] ogbg-moltox21: 0.847911 test loss: 0.196848
[Epoch 60; Iter     3/  183] train: loss: 0.1696167
[Epoch 60; Iter    33/  183] train: loss: 0.1476942
[Epoch 60; Iter    63/  183] train: loss: 0.1073229
[Epoch 60; Iter    93/  183] train: loss: 0.1547605
[Epoch 60; Iter   123/  183] train: loss: 0.1703514
[Epoch 60; Iter   153/  183] train: loss: 0.1101560
[Epoch 60; Iter   183/  183] train: loss: 0.1015348
[Epoch 60] ogbg-moltox21: 0.832244 val loss: 0.202356
[Epoch 60] ogbg-moltox21: 0.848519 test loss: 0.201817
[Epoch 61; Iter    30/  183] train: loss: 0.1135886
[Epoch 61; Iter    60/  183] train: loss: 0.0885333
[Epoch 61; Iter    90/  183] train: loss: 0.1472688
[Epoch 61; Iter   120/  183] train: loss: 0.1569849
[Epoch 61; Iter   150/  183] train: loss: 0.0816025
[Epoch 61; Iter   180/  183] train: loss: 0.1530546
[Epoch 61] ogbg-moltox21: 0.827878 val loss: 0.199155
[Epoch 61] ogbg-moltox21: 0.847027 test loss: 0.197790
[Epoch 62; Iter    27/  183] train: loss: 0.1059320
[Epoch 62; Iter    57/  183] train: loss: 0.0981742
[Epoch 62; Iter    87/  183] train: loss: 0.1762822
[Epoch 62; Iter   117/  183] train: loss: 0.1480867
[Epoch 62; Iter   147/  183] train: loss: 0.1635652
[Epoch 62; Iter   177/  183] train: loss: 0.1726721
[Epoch 62] ogbg-moltox21: 0.836567 val loss: 0.196809
[Epoch 62] ogbg-moltox21: 0.844036 test loss: 0.199420
[Epoch 63; Iter    24/  183] train: loss: 0.1532619
[Epoch 63; Iter    54/  183] train: loss: 0.1157746
[Epoch 63; Iter    84/  183] train: loss: 0.1299825
[Epoch 63; Iter   114/  183] train: loss: 0.1502780
[Epoch 63; Iter   144/  183] train: loss: 0.1261316
[Epoch 63; Iter   174/  183] train: loss: 0.0914063
[Epoch 63] ogbg-moltox21: 0.827278 val loss: 0.202998
[Epoch 63] ogbg-moltox21: 0.845352 test loss: 0.202959
[Epoch 64; Iter    21/  183] train: loss: 0.0984489
[Epoch 64; Iter    51/  183] train: loss: 0.1504435
[Epoch 64; Iter    81/  183] train: loss: 0.0970973
[Epoch 64; Iter   111/  183] train: loss: 0.0822429
[Epoch 64; Iter   141/  183] train: loss: 0.1751537
[Epoch 64; Iter   171/  183] train: loss: 0.1439034
[Epoch 64] ogbg-moltox21: 0.824817 val loss: 0.207309
[Epoch 64] ogbg-moltox21: 0.845208 test loss: 0.204863
[Epoch 65; Iter    18/  183] train: loss: 0.1271177
[Epoch 65; Iter    48/  183] train: loss: 0.1533018
[Epoch 65; Iter    78/  183] train: loss: 0.1092888
[Epoch 65; Iter   108/  183] train: loss: 0.1458981
[Epoch 65; Iter   138/  183] train: loss: 0.1506486
[Epoch 65; Iter   168/  183] train: loss: 0.1487959
[Epoch 65] ogbg-moltox21: 0.824770 val loss: 0.204200
[Epoch 65] ogbg-moltox21: 0.847262 test loss: 0.199630
[Epoch 66; Iter    15/  183] train: loss: 0.1467636
[Epoch 66; Iter    45/  183] train: loss: 0.1314392
[Epoch 66; Iter    75/  183] train: loss: 0.2072895
[Epoch 66; Iter   105/  183] train: loss: 0.1181526
[Epoch 66; Iter   135/  183] train: loss: 0.1106593
[Epoch 66; Iter   165/  183] train: loss: 0.0979718
[Epoch 66] ogbg-moltox21: 0.823059 val loss: 0.203759
[Epoch 66] ogbg-moltox21: 0.843714 test loss: 0.202951
[Epoch 67; Iter    12/  183] train: loss: 0.1007678
[Epoch 67; Iter    42/  183] train: loss: 0.0941486
[Epoch 67; Iter    72/  183] train: loss: 0.0937049
[Epoch 67; Iter   102/  183] train: loss: 0.1776736
[Epoch 67; Iter   132/  183] train: loss: 0.1484983
[Epoch 67; Iter   162/  183] train: loss: 0.1584432
[Epoch 67] ogbg-moltox21: 0.822743 val loss: 0.205623
[Epoch 67] ogbg-moltox21: 0.847495 test loss: 0.199896
[Epoch 68; Iter     9/  183] train: loss: 0.0967912
[Epoch 68; Iter    39/  183] train: loss: 0.0772089
[Epoch 68; Iter    69/  183] train: loss: 0.1853190
[Epoch 68; Iter    99/  183] train: loss: 0.1376521
[Epoch 68; Iter   129/  183] train: loss: 0.1448446
[Epoch 68; Iter   159/  183] train: loss: 0.1448556
[Epoch 68] ogbg-moltox21: 0.827049 val loss: 0.207016
[Epoch 68] ogbg-moltox21: 0.850762 test loss: 0.199893
[Epoch 69; Iter     6/  183] train: loss: 0.2085907
[Epoch 69; Iter    36/  183] train: loss: 0.1339156
[Epoch 69; Iter    66/  183] train: loss: 0.0645206
[Epoch 69; Iter    96/  183] train: loss: 0.1083699
[Epoch 69; Iter   126/  183] train: loss: 0.0780788
[Epoch 69; Iter   156/  183] train: loss: 0.0938945
[Epoch 69] ogbg-moltox21: 0.823212 val loss: 0.217521
[Epoch 69] ogbg-moltox21: 0.844114 test loss: 0.203748
[Epoch 70; Iter     3/  183] train: loss: 0.0983269
[Epoch 70; Iter    33/  183] train: loss: 0.1563745
[Epoch 70; Iter    63/  183] train: loss: 0.0846911
[Epoch 70; Iter    93/  183] train: loss: 0.1414099
[Epoch 70; Iter   123/  183] train: loss: 0.1747877
[Epoch 70; Iter   153/  183] train: loss: 0.1058192
[Epoch 70; Iter   183/  183] train: loss: 0.1387444
[Epoch 70] ogbg-moltox21: 0.816714 val loss: 0.210564
[Epoch 70] ogbg-moltox21: 0.844049 test loss: 0.206698
[Epoch 71; Iter    30/  183] train: loss: 0.0929368
[Epoch 71; Iter    60/  183] train: loss: 0.1408395
[Epoch 71; Iter    90/  183] train: loss: 0.0731125
[Epoch 71; Iter   120/  183] train: loss: 0.0650658
[Epoch 71; Iter   150/  183] train: loss: 0.1227783
[Epoch 52; Iter   147/  183] train: loss: 0.1769435
[Epoch 52; Iter   177/  183] train: loss: 0.0838347
[Epoch 52] ogbg-moltox21: 0.834747 val loss: 0.215309
[Epoch 52] ogbg-moltox21: 0.843216 test loss: 0.202210
[Epoch 53; Iter    24/  183] train: loss: 0.1488563
[Epoch 53; Iter    54/  183] train: loss: 0.1111751
[Epoch 53; Iter    84/  183] train: loss: 0.0965248
[Epoch 53; Iter   114/  183] train: loss: 0.1493745
[Epoch 53; Iter   144/  183] train: loss: 0.1133886
[Epoch 53; Iter   174/  183] train: loss: 0.1055714
[Epoch 53] ogbg-moltox21: 0.820306 val loss: 0.209527
[Epoch 53] ogbg-moltox21: 0.835995 test loss: 0.204933
[Epoch 54; Iter    21/  183] train: loss: 0.0926484
[Epoch 54; Iter    51/  183] train: loss: 0.1220584
[Epoch 54; Iter    81/  183] train: loss: 0.1204038
[Epoch 54; Iter   111/  183] train: loss: 0.0862617
[Epoch 54; Iter   141/  183] train: loss: 0.1342709
[Epoch 54; Iter   171/  183] train: loss: 0.0881127
[Epoch 54] ogbg-moltox21: 0.823700 val loss: 0.206138
[Epoch 54] ogbg-moltox21: 0.839332 test loss: 0.201099
[Epoch 55; Iter    18/  183] train: loss: 0.1357673
[Epoch 55; Iter    48/  183] train: loss: 0.1474642
[Epoch 55; Iter    78/  183] train: loss: 0.1061320
[Epoch 55; Iter   108/  183] train: loss: 0.1055015
[Epoch 55; Iter   138/  183] train: loss: 0.0973018
[Epoch 55; Iter   168/  183] train: loss: 0.0954289
[Epoch 55] ogbg-moltox21: 0.828922 val loss: 0.203093
[Epoch 55] ogbg-moltox21: 0.837509 test loss: 0.199985
[Epoch 56; Iter    15/  183] train: loss: 0.1394086
[Epoch 56; Iter    45/  183] train: loss: 0.1108401
[Epoch 56; Iter    75/  183] train: loss: 0.1251406
[Epoch 56; Iter   105/  183] train: loss: 0.0912718
[Epoch 56; Iter   135/  183] train: loss: 0.1200868
[Epoch 56; Iter   165/  183] train: loss: 0.1126383
[Epoch 56] ogbg-moltox21: 0.825034 val loss: 0.208639
[Epoch 56] ogbg-moltox21: 0.836476 test loss: 0.207899
[Epoch 57; Iter    12/  183] train: loss: 0.1375059
[Epoch 57; Iter    42/  183] train: loss: 0.0942933
[Epoch 57; Iter    72/  183] train: loss: 0.1212415
[Epoch 57; Iter   102/  183] train: loss: 0.1674328
[Epoch 57; Iter   132/  183] train: loss: 0.0677779
[Epoch 57; Iter   162/  183] train: loss: 0.1117722
[Epoch 57] ogbg-moltox21: 0.831178 val loss: 0.206165
[Epoch 57] ogbg-moltox21: 0.845067 test loss: 0.206783
[Epoch 58; Iter     9/  183] train: loss: 0.0952939
[Epoch 58; Iter    39/  183] train: loss: 0.2109937
[Epoch 58; Iter    69/  183] train: loss: 0.1348148
[Epoch 58; Iter    99/  183] train: loss: 0.0816333
[Epoch 58; Iter   129/  183] train: loss: 0.1387088
[Epoch 58; Iter   159/  183] train: loss: 0.1144216
[Epoch 58] ogbg-moltox21: 0.829661 val loss: 0.207726
[Epoch 58] ogbg-moltox21: 0.839257 test loss: 0.277142
[Epoch 59; Iter     6/  183] train: loss: 0.1156540
[Epoch 59; Iter    36/  183] train: loss: 0.0737258
[Epoch 59; Iter    66/  183] train: loss: 0.1243085
[Epoch 59; Iter    96/  183] train: loss: 0.1335016
[Epoch 59; Iter   126/  183] train: loss: 0.0848104
[Epoch 59; Iter   156/  183] train: loss: 0.1597064
[Epoch 59] ogbg-moltox21: 0.817652 val loss: 0.211276
[Epoch 59] ogbg-moltox21: 0.829867 test loss: 0.210026
[Epoch 60; Iter     3/  183] train: loss: 0.0752558
[Epoch 60; Iter    33/  183] train: loss: 0.1392799
[Epoch 60; Iter    63/  183] train: loss: 0.0793891
[Epoch 60; Iter    93/  183] train: loss: 0.1297586
[Epoch 60; Iter   123/  183] train: loss: 0.1619200
[Epoch 60; Iter   153/  183] train: loss: 0.1017656
[Epoch 60; Iter   183/  183] train: loss: 0.1100200
[Epoch 60] ogbg-moltox21: 0.823801 val loss: 0.212458
[Epoch 60] ogbg-moltox21: 0.833503 test loss: 0.207704
[Epoch 61; Iter    30/  183] train: loss: 0.1095529
[Epoch 61; Iter    60/  183] train: loss: 0.1075061
[Epoch 61; Iter    90/  183] train: loss: 0.1682130
[Epoch 61; Iter   120/  183] train: loss: 0.1789818
[Epoch 61; Iter   150/  183] train: loss: 0.1028505
[Epoch 61; Iter   180/  183] train: loss: 0.1591852
[Epoch 61] ogbg-moltox21: 0.821911 val loss: 0.218668
[Epoch 61] ogbg-moltox21: 0.831841 test loss: 0.215509
[Epoch 62; Iter    27/  183] train: loss: 0.0945563
[Epoch 62; Iter    57/  183] train: loss: 0.1196207
[Epoch 62; Iter    87/  183] train: loss: 0.0847106
[Epoch 62; Iter   117/  183] train: loss: 0.1113401
[Epoch 62; Iter   147/  183] train: loss: 0.1281462
[Epoch 62; Iter   177/  183] train: loss: 0.1330060
[Epoch 62] ogbg-moltox21: 0.807476 val loss: 0.228773
[Epoch 62] ogbg-moltox21: 0.826111 test loss: 0.309926
[Epoch 63; Iter    24/  183] train: loss: 0.1667414
[Epoch 63; Iter    54/  183] train: loss: 0.1296240
[Epoch 63; Iter    84/  183] train: loss: 0.1013159
[Epoch 63; Iter   114/  183] train: loss: 0.1391253
[Epoch 63; Iter   144/  183] train: loss: 0.1451683
[Epoch 63; Iter   174/  183] train: loss: 0.0875820
[Epoch 63] ogbg-moltox21: 0.824887 val loss: 0.207195
[Epoch 63] ogbg-moltox21: 0.837888 test loss: 0.209646
[Epoch 64; Iter    21/  183] train: loss: 0.1060815
[Epoch 64; Iter    51/  183] train: loss: 0.0929132
[Epoch 64; Iter    81/  183] train: loss: 0.0973770
[Epoch 64; Iter   111/  183] train: loss: 0.0752518
[Epoch 64; Iter   141/  183] train: loss: 0.0851345
[Epoch 64; Iter   171/  183] train: loss: 0.0489753
[Epoch 64] ogbg-moltox21: 0.826254 val loss: 0.208179
[Epoch 64] ogbg-moltox21: 0.840380 test loss: 0.243177
[Epoch 65; Iter    18/  183] train: loss: 0.1498990
[Epoch 65; Iter    48/  183] train: loss: 0.0814362
[Epoch 65; Iter    78/  183] train: loss: 0.1092949
[Epoch 65; Iter   108/  183] train: loss: 0.0811867
[Epoch 65; Iter   138/  183] train: loss: 0.0553831
[Epoch 65; Iter   168/  183] train: loss: 0.1042954
[Epoch 65] ogbg-moltox21: 0.823532 val loss: 0.209065
[Epoch 65] ogbg-moltox21: 0.837423 test loss: 0.208557
[Epoch 66; Iter    15/  183] train: loss: 0.0717079
[Epoch 66; Iter    45/  183] train: loss: 0.1091047
[Epoch 66; Iter    75/  183] train: loss: 0.1189574
[Epoch 66; Iter   105/  183] train: loss: 0.0597470
[Epoch 66; Iter   135/  183] train: loss: 0.0701945
[Epoch 66; Iter   165/  183] train: loss: 0.1243053
[Epoch 66] ogbg-moltox21: 0.826765 val loss: 0.213648
[Epoch 66] ogbg-moltox21: 0.832067 test loss: 0.222595
[Epoch 67; Iter    12/  183] train: loss: 0.1301486
[Epoch 67; Iter    42/  183] train: loss: 0.1415095
[Epoch 67; Iter    72/  183] train: loss: 0.1113215
[Epoch 67; Iter   102/  183] train: loss: 0.1005121
[Epoch 67; Iter   132/  183] train: loss: 0.0685765
[Epoch 67; Iter   162/  183] train: loss: 0.1103059
[Epoch 67] ogbg-moltox21: 0.824262 val loss: 0.214076
[Epoch 67] ogbg-moltox21: 0.833156 test loss: 0.273482
[Epoch 68; Iter     9/  183] train: loss: 0.0868320
[Epoch 68; Iter    39/  183] train: loss: 0.1193311
[Epoch 68; Iter    69/  183] train: loss: 0.1022479
[Epoch 68; Iter    99/  183] train: loss: 0.0899586
[Epoch 68; Iter   129/  183] train: loss: 0.1149477
[Epoch 68; Iter   159/  183] train: loss: 0.0634927
[Epoch 68] ogbg-moltox21: 0.822626 val loss: 0.217329
[Epoch 68] ogbg-moltox21: 0.831827 test loss: 0.215384
[Epoch 69; Iter     6/  183] train: loss: 0.0982928
[Epoch 69; Iter    36/  183] train: loss: 0.0590948
[Epoch 69; Iter    66/  183] train: loss: 0.0913205
[Epoch 69; Iter    96/  183] train: loss: 0.0970675
[Epoch 69; Iter   126/  183] train: loss: 0.1002695
[Epoch 69; Iter   156/  183] train: loss: 0.0726427
[Epoch 69] ogbg-moltox21: 0.819433 val loss: 0.224768
[Epoch 69] ogbg-moltox21: 0.825341 test loss: 0.231278
[Epoch 70; Iter     3/  183] train: loss: 0.0862706
[Epoch 70; Iter    33/  183] train: loss: 0.1316201
[Epoch 70; Iter    63/  183] train: loss: 0.1172132
[Epoch 70; Iter    93/  183] train: loss: 0.0935709
[Epoch 70; Iter   123/  183] train: loss: 0.1431822
[Epoch 70; Iter   153/  183] train: loss: 0.1465026
[Epoch 70; Iter   183/  183] train: loss: 0.1315469
[Epoch 70] ogbg-moltox21: 0.822788 val loss: 0.218705
[Epoch 70] ogbg-moltox21: 0.829519 test loss: 0.220298
[Epoch 71; Iter    30/  183] train: loss: 0.1189301
[Epoch 71; Iter    60/  183] train: loss: 0.0808607
[Epoch 71; Iter    90/  183] train: loss: 0.0722216
[Epoch 71; Iter   120/  183] train: loss: 0.1137022
[Epoch 71; Iter   150/  183] train: loss: 0.0978426
[Epoch 52; Iter   147/  183] train: loss: 0.1021914
[Epoch 52; Iter   177/  183] train: loss: 0.1257766
[Epoch 52] ogbg-moltox21: 0.834108 val loss: 0.212277
[Epoch 52] ogbg-moltox21: 0.857687 test loss: 0.203899
[Epoch 53; Iter    24/  183] train: loss: 0.0950510
[Epoch 53; Iter    54/  183] train: loss: 0.0820627
[Epoch 53; Iter    84/  183] train: loss: 0.0826905
[Epoch 53; Iter   114/  183] train: loss: 0.1234854
[Epoch 53; Iter   144/  183] train: loss: 0.1417008
[Epoch 53; Iter   174/  183] train: loss: 0.1121571
[Epoch 53] ogbg-moltox21: 0.822504 val loss: 0.224307
[Epoch 53] ogbg-moltox21: 0.840459 test loss: 0.213949
[Epoch 54; Iter    21/  183] train: loss: 0.0615014
[Epoch 54; Iter    51/  183] train: loss: 0.0999202
[Epoch 54; Iter    81/  183] train: loss: 0.0932205
[Epoch 54; Iter   111/  183] train: loss: 0.0949775
[Epoch 54; Iter   141/  183] train: loss: 0.0740685
[Epoch 54; Iter   171/  183] train: loss: 0.1201146
[Epoch 54] ogbg-moltox21: 0.831252 val loss: 0.219209
[Epoch 54] ogbg-moltox21: 0.840022 test loss: 0.213676
[Epoch 55; Iter    18/  183] train: loss: 0.0847398
[Epoch 55; Iter    48/  183] train: loss: 0.0908393
[Epoch 55; Iter    78/  183] train: loss: 0.0769782
[Epoch 55; Iter   108/  183] train: loss: 0.0935514
[Epoch 55; Iter   138/  183] train: loss: 0.0845362
[Epoch 55; Iter   168/  183] train: loss: 0.1324041
[Epoch 55] ogbg-moltox21: 0.830260 val loss: 0.217422
[Epoch 55] ogbg-moltox21: 0.845079 test loss: 0.214120
[Epoch 56; Iter    15/  183] train: loss: 0.0980877
[Epoch 56; Iter    45/  183] train: loss: 0.0683777
[Epoch 56; Iter    75/  183] train: loss: 0.1068454
[Epoch 56; Iter   105/  183] train: loss: 0.1578659
[Epoch 56; Iter   135/  183] train: loss: 0.1099278
[Epoch 56; Iter   165/  183] train: loss: 0.1082689
[Epoch 56] ogbg-moltox21: 0.830146 val loss: 0.244360
[Epoch 56] ogbg-moltox21: 0.842007 test loss: 0.218382
[Epoch 57; Iter    12/  183] train: loss: 0.1015705
[Epoch 57; Iter    42/  183] train: loss: 0.1312907
[Epoch 57; Iter    72/  183] train: loss: 0.1888825
[Epoch 57; Iter   102/  183] train: loss: 0.1011414
[Epoch 57; Iter   132/  183] train: loss: 0.1532155
[Epoch 57; Iter   162/  183] train: loss: 0.0927594
[Epoch 57] ogbg-moltox21: 0.820259 val loss: 0.224308
[Epoch 57] ogbg-moltox21: 0.837348 test loss: 0.215861
[Epoch 58; Iter     9/  183] train: loss: 0.1063468
[Epoch 58; Iter    39/  183] train: loss: 0.0978637
[Epoch 58; Iter    69/  183] train: loss: 0.1752885
[Epoch 58; Iter    99/  183] train: loss: 0.1429019
[Epoch 58; Iter   129/  183] train: loss: 0.0808747
[Epoch 58; Iter   159/  183] train: loss: 0.0490398
[Epoch 58] ogbg-moltox21: 0.835977 val loss: 0.213519
[Epoch 58] ogbg-moltox21: 0.839229 test loss: 0.216046
[Epoch 59; Iter     6/  183] train: loss: 0.1445498
[Epoch 59; Iter    36/  183] train: loss: 0.0743749
[Epoch 59; Iter    66/  183] train: loss: 0.0798183
[Epoch 59; Iter    96/  183] train: loss: 0.0874215
[Epoch 59; Iter   126/  183] train: loss: 0.1130505
[Epoch 59; Iter   156/  183] train: loss: 0.0912448
[Epoch 59] ogbg-moltox21: 0.831842 val loss: 0.231342
[Epoch 59] ogbg-moltox21: 0.840489 test loss: 0.218897
[Epoch 60; Iter     3/  183] train: loss: 0.0726232
[Epoch 60; Iter    33/  183] train: loss: 0.1281013
[Epoch 60; Iter    63/  183] train: loss: 0.1103339
[Epoch 60; Iter    93/  183] train: loss: 0.0989352
[Epoch 60; Iter   123/  183] train: loss: 0.1275809
[Epoch 60; Iter   153/  183] train: loss: 0.0812635
[Epoch 60; Iter   183/  183] train: loss: 0.0931422
[Epoch 60] ogbg-moltox21: 0.834532 val loss: 0.221681
[Epoch 60] ogbg-moltox21: 0.840629 test loss: 0.214997
[Epoch 61; Iter    30/  183] train: loss: 0.0605231
[Epoch 61; Iter    60/  183] train: loss: 0.0923041
[Epoch 61; Iter    90/  183] train: loss: 0.1325544
[Epoch 61; Iter   120/  183] train: loss: 0.0755412
[Epoch 61; Iter   150/  183] train: loss: 0.0688274
[Epoch 61; Iter   180/  183] train: loss: 0.0891582
[Epoch 61] ogbg-moltox21: 0.815822 val loss: 0.224607
[Epoch 61] ogbg-moltox21: 0.825408 test loss: 0.222223
[Epoch 62; Iter    27/  183] train: loss: 0.1058485
[Epoch 62; Iter    57/  183] train: loss: 0.0861580
[Epoch 62; Iter    87/  183] train: loss: 0.1088755
[Epoch 62; Iter   117/  183] train: loss: 0.0948267
[Epoch 62; Iter   147/  183] train: loss: 0.1125645
[Epoch 62; Iter   177/  183] train: loss: 0.0905908
[Epoch 62] ogbg-moltox21: 0.825317 val loss: 0.218546
[Epoch 62] ogbg-moltox21: 0.841754 test loss: 0.218127
[Epoch 63; Iter    24/  183] train: loss: 0.0746682
[Epoch 63; Iter    54/  183] train: loss: 0.0943386
[Epoch 63; Iter    84/  183] train: loss: 0.1258033
[Epoch 63; Iter   114/  183] train: loss: 0.0622493
[Epoch 63; Iter   144/  183] train: loss: 0.0684502
[Epoch 63; Iter   174/  183] train: loss: 0.1528663
[Epoch 63] ogbg-moltox21: 0.829855 val loss: 0.217950
[Epoch 63] ogbg-moltox21: 0.839116 test loss: 0.222154
[Epoch 64; Iter    21/  183] train: loss: 0.0690498
[Epoch 64; Iter    51/  183] train: loss: 0.0841654
[Epoch 64; Iter    81/  183] train: loss: 0.0803596
[Epoch 64; Iter   111/  183] train: loss: 0.0485720
[Epoch 64; Iter   141/  183] train: loss: 0.0929527
[Epoch 64; Iter   171/  183] train: loss: 0.0865783
[Epoch 64] ogbg-moltox21: 0.825456 val loss: 0.223097
[Epoch 64] ogbg-moltox21: 0.834839 test loss: 0.220427
[Epoch 65; Iter    18/  183] train: loss: 0.0891749
[Epoch 65; Iter    48/  183] train: loss: 0.1068650
[Epoch 65; Iter    78/  183] train: loss: 0.1024920
[Epoch 65; Iter   108/  183] train: loss: 0.0935168
[Epoch 65; Iter   138/  183] train: loss: 0.0815565
[Epoch 65; Iter   168/  183] train: loss: 0.0759782
[Epoch 65] ogbg-moltox21: 0.824439 val loss: 0.228719
[Epoch 65] ogbg-moltox21: 0.835894 test loss: 0.223804
[Epoch 66; Iter    15/  183] train: loss: 0.1115822
[Epoch 66; Iter    45/  183] train: loss: 0.0494475
[Epoch 66; Iter    75/  183] train: loss: 0.0596767
[Epoch 66; Iter   105/  183] train: loss: 0.0605708
[Epoch 66; Iter   135/  183] train: loss: 0.1199483
[Epoch 66; Iter   165/  183] train: loss: 0.1133854
[Epoch 66] ogbg-moltox21: 0.828113 val loss: 0.234803
[Epoch 66] ogbg-moltox21: 0.836531 test loss: 0.226839
[Epoch 67; Iter    12/  183] train: loss: 0.0503407
[Epoch 67; Iter    42/  183] train: loss: 0.0827974
[Epoch 67; Iter    72/  183] train: loss: 0.0945675
[Epoch 67; Iter   102/  183] train: loss: 0.1281945
[Epoch 67; Iter   132/  183] train: loss: 0.0876124
[Epoch 67; Iter   162/  183] train: loss: 0.0731516
[Epoch 67] ogbg-moltox21: 0.824378 val loss: 0.232936
[Epoch 67] ogbg-moltox21: 0.825482 test loss: 0.235365
[Epoch 68; Iter     9/  183] train: loss: 0.1111662
[Epoch 68; Iter    39/  183] train: loss: 0.1015993
[Epoch 68; Iter    69/  183] train: loss: 0.0880428
[Epoch 68; Iter    99/  183] train: loss: 0.0902872
[Epoch 68; Iter   129/  183] train: loss: 0.0969308
[Epoch 68; Iter   159/  183] train: loss: 0.0942732
[Epoch 68] ogbg-moltox21: 0.825990 val loss: 0.235278
[Epoch 68] ogbg-moltox21: 0.830386 test loss: 0.238653
[Epoch 69; Iter     6/  183] train: loss: 0.0741544
[Epoch 69; Iter    36/  183] train: loss: 0.0483460
[Epoch 69; Iter    66/  183] train: loss: 0.0644144
[Epoch 69; Iter    96/  183] train: loss: 0.0968149
[Epoch 69; Iter   126/  183] train: loss: 0.0721702
[Epoch 69; Iter   156/  183] train: loss: 0.1063491
[Epoch 69] ogbg-moltox21: 0.819027 val loss: 0.230336
[Epoch 69] ogbg-moltox21: 0.825735 test loss: 0.233150
[Epoch 70; Iter     3/  183] train: loss: 0.0595136
[Epoch 70; Iter    33/  183] train: loss: 0.0593100
[Epoch 70; Iter    63/  183] train: loss: 0.0478287
[Epoch 70; Iter    93/  183] train: loss: 0.0842234
[Epoch 70; Iter   123/  183] train: loss: 0.0635311
[Epoch 70; Iter   153/  183] train: loss: 0.0706063
[Epoch 70; Iter   183/  183] train: loss: 0.0698423
[Epoch 70] ogbg-moltox21: 0.822676 val loss: 0.235036
[Epoch 70] ogbg-moltox21: 0.829620 test loss: 0.237004
[Epoch 71; Iter    30/  183] train: loss: 0.1137410
[Epoch 71; Iter    60/  183] train: loss: 0.0607301
[Epoch 71; Iter    90/  183] train: loss: 0.0614538
[Epoch 71; Iter   120/  183] train: loss: 0.0791777
[Epoch 71; Iter   150/  183] train: loss: 0.0601771
[Epoch 58] ogbg-moltox21: 0.827719 val loss: 0.197919
[Epoch 58] ogbg-moltox21: 0.833702 test loss: 0.208024
[Epoch 59; Iter    14/  157] train: loss: 0.1049197
[Epoch 59; Iter    44/  157] train: loss: 0.1966883
[Epoch 59; Iter    74/  157] train: loss: 0.1088196
[Epoch 59; Iter   104/  157] train: loss: 0.1919536
[Epoch 59; Iter   134/  157] train: loss: 0.1473937
[Epoch 59] ogbg-moltox21: 0.834003 val loss: 0.195667
[Epoch 59] ogbg-moltox21: 0.835215 test loss: 0.209457
[Epoch 60; Iter     7/  157] train: loss: 0.0870631
[Epoch 60; Iter    37/  157] train: loss: 0.1454258
[Epoch 60; Iter    67/  157] train: loss: 0.1081719
[Epoch 60; Iter    97/  157] train: loss: 0.1487606
[Epoch 60; Iter   127/  157] train: loss: 0.1371452
[Epoch 60; Iter   157/  157] train: loss: 0.1094738
[Epoch 60] ogbg-moltox21: 0.828677 val loss: 0.220550
[Epoch 60] ogbg-moltox21: 0.833005 test loss: 0.210858
[Epoch 61; Iter    30/  157] train: loss: 0.1299472
[Epoch 61; Iter    60/  157] train: loss: 0.1271068
[Epoch 61; Iter    90/  157] train: loss: 0.1290623
[Epoch 61; Iter   120/  157] train: loss: 0.1173430
[Epoch 61; Iter   150/  157] train: loss: 0.0881811
[Epoch 61] ogbg-moltox21: 0.827461 val loss: 0.199648
[Epoch 61] ogbg-moltox21: 0.837643 test loss: 0.209081
[Epoch 62; Iter    23/  157] train: loss: 0.1363766
[Epoch 62; Iter    53/  157] train: loss: 0.1628388
[Epoch 62; Iter    83/  157] train: loss: 0.1437120
[Epoch 62; Iter   113/  157] train: loss: 0.0984776
[Epoch 62; Iter   143/  157] train: loss: 0.1482284
[Epoch 62] ogbg-moltox21: 0.817397 val loss: 0.209067
[Epoch 62] ogbg-moltox21: 0.833778 test loss: 0.211298
[Epoch 63; Iter    16/  157] train: loss: 0.0993748
[Epoch 63; Iter    46/  157] train: loss: 0.1109441
[Epoch 63; Iter    76/  157] train: loss: 0.1135865
[Epoch 63; Iter   106/  157] train: loss: 0.1321967
[Epoch 63; Iter   136/  157] train: loss: 0.1385595
[Epoch 63] ogbg-moltox21: 0.826149 val loss: 0.201201
[Epoch 63] ogbg-moltox21: 0.829965 test loss: 0.215449
[Epoch 64; Iter     9/  157] train: loss: 0.1120215
[Epoch 64; Iter    39/  157] train: loss: 0.0892650
[Epoch 64; Iter    69/  157] train: loss: 0.1361468
[Epoch 64; Iter    99/  157] train: loss: 0.0813633
[Epoch 64; Iter   129/  157] train: loss: 0.0989299
[Epoch 64] ogbg-moltox21: 0.824795 val loss: 0.201561
[Epoch 64] ogbg-moltox21: 0.824682 test loss: 0.216070
[Epoch 65; Iter     2/  157] train: loss: 0.1070150
[Epoch 65; Iter    32/  157] train: loss: 0.0960891
[Epoch 65; Iter    62/  157] train: loss: 0.1282563
[Epoch 65; Iter    92/  157] train: loss: 0.1097071
[Epoch 65; Iter   122/  157] train: loss: 0.1002230
[Epoch 65; Iter   152/  157] train: loss: 0.2007804
[Epoch 65] ogbg-moltox21: 0.828473 val loss: 0.199690
[Epoch 65] ogbg-moltox21: 0.829802 test loss: 0.218649
[Epoch 66; Iter    25/  157] train: loss: 0.1539361
[Epoch 66; Iter    55/  157] train: loss: 0.0921643
[Epoch 66; Iter    85/  157] train: loss: 0.1135906
[Epoch 66; Iter   115/  157] train: loss: 0.1030175
[Epoch 66; Iter   145/  157] train: loss: 0.1277508
[Epoch 66] ogbg-moltox21: 0.831146 val loss: 0.204995
[Epoch 66] ogbg-moltox21: 0.826034 test loss: 0.220160
[Epoch 67; Iter    18/  157] train: loss: 0.1260510
[Epoch 67; Iter    48/  157] train: loss: 0.0813728
[Epoch 67; Iter    78/  157] train: loss: 0.1087610
[Epoch 67; Iter   108/  157] train: loss: 0.0911366
[Epoch 67; Iter   138/  157] train: loss: 0.0880083
[Epoch 67] ogbg-moltox21: 0.827402 val loss: 0.201825
[Epoch 67] ogbg-moltox21: 0.835939 test loss: 0.214359
[Epoch 68; Iter    11/  157] train: loss: 0.1154906
[Epoch 68; Iter    41/  157] train: loss: 0.1835093
[Epoch 68; Iter    71/  157] train: loss: 0.0900834
[Epoch 68; Iter   101/  157] train: loss: 0.1170177
[Epoch 68; Iter   131/  157] train: loss: 0.0795142
[Epoch 68] ogbg-moltox21: 0.824446 val loss: 0.205000
[Epoch 68] ogbg-moltox21: 0.831196 test loss: 0.218339
[Epoch 69; Iter     4/  157] train: loss: 0.0881539
[Epoch 69; Iter    34/  157] train: loss: 0.1066879
[Epoch 69; Iter    64/  157] train: loss: 0.1509896
[Epoch 69; Iter    94/  157] train: loss: 0.1200525
[Epoch 69; Iter   124/  157] train: loss: 0.1033154
[Epoch 69; Iter   154/  157] train: loss: 0.0709938
[Epoch 69] ogbg-moltox21: 0.823799 val loss: 0.208586
[Epoch 69] ogbg-moltox21: 0.822748 test loss: 0.226580
[Epoch 70; Iter    27/  157] train: loss: 0.1102360
[Epoch 70; Iter    57/  157] train: loss: 0.0946480
[Epoch 70; Iter    87/  157] train: loss: 0.0702441
[Epoch 70; Iter   117/  157] train: loss: 0.1278271
[Epoch 70; Iter   147/  157] train: loss: 0.0798901
[Epoch 70] ogbg-moltox21: 0.826279 val loss: 0.204553
[Epoch 70] ogbg-moltox21: 0.824586 test loss: 0.220699
[Epoch 71; Iter    20/  157] train: loss: 0.1136721
[Epoch 71; Iter    50/  157] train: loss: 0.1214811
[Epoch 71; Iter    80/  157] train: loss: 0.0717262
[Epoch 71; Iter   110/  157] train: loss: 0.0897882
[Epoch 71; Iter   140/  157] train: loss: 0.1275179
[Epoch 71] ogbg-moltox21: 0.824470 val loss: 0.205259
[Epoch 71] ogbg-moltox21: 0.818589 test loss: 0.225347
[Epoch 72; Iter    13/  157] train: loss: 0.0599467
[Epoch 72; Iter    43/  157] train: loss: 0.1338636
[Epoch 72; Iter    73/  157] train: loss: 0.2264436
[Epoch 72; Iter   103/  157] train: loss: 0.1305532
[Epoch 72; Iter   133/  157] train: loss: 0.1037809
[Epoch 72] ogbg-moltox21: 0.822647 val loss: 0.217371
[Epoch 72] ogbg-moltox21: 0.824978 test loss: 0.223897
[Epoch 73; Iter     6/  157] train: loss: 0.1051701
[Epoch 73; Iter    36/  157] train: loss: 0.0997433
[Epoch 73; Iter    66/  157] train: loss: 0.1063384
[Epoch 73; Iter    96/  157] train: loss: 0.0969509
[Epoch 73; Iter   126/  157] train: loss: 0.0773708
[Epoch 73; Iter   156/  157] train: loss: 0.1051095
[Epoch 73] ogbg-moltox21: 0.823382 val loss: 0.208607
[Epoch 73] ogbg-moltox21: 0.823918 test loss: 0.225120
[Epoch 74; Iter    29/  157] train: loss: 0.2261630
[Epoch 74; Iter    59/  157] train: loss: 0.0836163
[Epoch 74; Iter    89/  157] train: loss: 0.0969385
[Epoch 74; Iter   119/  157] train: loss: 0.1542605
[Epoch 74; Iter   149/  157] train: loss: 0.0754944
[Epoch 74] ogbg-moltox21: 0.814519 val loss: 0.217304
[Epoch 74] ogbg-moltox21: 0.814903 test loss: 0.234819
[Epoch 75; Iter    22/  157] train: loss: 0.0711935
[Epoch 75; Iter    52/  157] train: loss: 0.0891357
[Epoch 75; Iter    82/  157] train: loss: 0.0888922
[Epoch 75; Iter   112/  157] train: loss: 0.1441413
[Epoch 75; Iter   142/  157] train: loss: 0.0978866
[Epoch 75] ogbg-moltox21: 0.824697 val loss: 0.212613
[Epoch 75] ogbg-moltox21: 0.818937 test loss: 0.230623
[Epoch 76; Iter    15/  157] train: loss: 0.0725422
[Epoch 76; Iter    45/  157] train: loss: 0.0720595
[Epoch 76; Iter    75/  157] train: loss: 0.1462064
[Epoch 76; Iter   105/  157] train: loss: 0.1096067
[Epoch 76; Iter   135/  157] train: loss: 0.1257201
[Epoch 76] ogbg-moltox21: 0.822773 val loss: 0.229890
[Epoch 76] ogbg-moltox21: 0.825039 test loss: 0.240550
[Epoch 77; Iter     8/  157] train: loss: 0.0823645
[Epoch 77; Iter    38/  157] train: loss: 0.1302826
[Epoch 77; Iter    68/  157] train: loss: 0.1670887
[Epoch 77; Iter    98/  157] train: loss: 0.0645095
[Epoch 77; Iter   128/  157] train: loss: 0.0950084
[Epoch 77] ogbg-moltox21: 0.825868 val loss: 0.213292
[Epoch 77] ogbg-moltox21: 0.828203 test loss: 0.231649
[Epoch 78; Iter     1/  157] train: loss: 0.0856640
[Epoch 78; Iter    31/  157] train: loss: 0.0773072
[Epoch 78; Iter    61/  157] train: loss: 0.0658196
[Epoch 78; Iter    91/  157] train: loss: 0.1262080
[Epoch 78; Iter   121/  157] train: loss: 0.0927787
[Epoch 78; Iter   151/  157] train: loss: 0.0957905
[Epoch 78] ogbg-moltox21: 0.822563 val loss: 0.215128
[Epoch 78] ogbg-moltox21: 0.823701 test loss: 0.231662
[Epoch 79; Iter    24/  157] train: loss: 0.1251244
[Epoch 79; Iter    54/  157] train: loss: 0.0535792
[Epoch 79; Iter    84/  157] train: loss: 0.0717566
[Epoch 79; Iter   114/  157] train: loss: 0.1170764
[Epoch 79; Iter   144/  157] train: loss: 0.1021501
[Epoch 79] ogbg-moltox21: 0.820583 val loss: 0.215909
[Epoch 79] ogbg-moltox21: 0.818255 test loss: 0.233972
[Epoch 80; Iter    17/  157] train: loss: 0.0459717
[Epoch 58] ogbg-moltox21: 0.825411 val loss: 0.208818
[Epoch 58] ogbg-moltox21: 0.847660 test loss: 0.216096
[Epoch 59; Iter    14/  157] train: loss: 0.1254755
[Epoch 59; Iter    44/  157] train: loss: 0.0858373
[Epoch 59; Iter    74/  157] train: loss: 0.1048831
[Epoch 59; Iter   104/  157] train: loss: 0.0964556
[Epoch 59; Iter   134/  157] train: loss: 0.1466140
[Epoch 59] ogbg-moltox21: 0.824316 val loss: 0.209107
[Epoch 59] ogbg-moltox21: 0.842154 test loss: 0.220277
[Epoch 60; Iter     7/  157] train: loss: 0.1536695
[Epoch 60; Iter    37/  157] train: loss: 0.1342156
[Epoch 60; Iter    67/  157] train: loss: 0.1026413
[Epoch 60; Iter    97/  157] train: loss: 0.1166291
[Epoch 60; Iter   127/  157] train: loss: 0.1114068
[Epoch 60; Iter   157/  157] train: loss: 0.1724196
[Epoch 60] ogbg-moltox21: 0.820941 val loss: 0.216220
[Epoch 60] ogbg-moltox21: 0.836777 test loss: 0.233026
[Epoch 61; Iter    30/  157] train: loss: 0.0714057
[Epoch 61; Iter    60/  157] train: loss: 0.1274728
[Epoch 61; Iter    90/  157] train: loss: 0.1631106
[Epoch 61; Iter   120/  157] train: loss: 0.0910457
[Epoch 61; Iter   150/  157] train: loss: 0.0899973
[Epoch 61] ogbg-moltox21: 0.825966 val loss: 0.213027
[Epoch 61] ogbg-moltox21: 0.836803 test loss: 0.227736
[Epoch 62; Iter    23/  157] train: loss: 0.1434361
[Epoch 62; Iter    53/  157] train: loss: 0.1065196
[Epoch 62; Iter    83/  157] train: loss: 0.1655047
[Epoch 62; Iter   113/  157] train: loss: 0.1939339
[Epoch 62; Iter   143/  157] train: loss: 0.1554406
[Epoch 62] ogbg-moltox21: 0.815175 val loss: 0.218221
[Epoch 62] ogbg-moltox21: 0.838772 test loss: 0.224201
[Epoch 63; Iter    16/  157] train: loss: 0.1200980
[Epoch 63; Iter    46/  157] train: loss: 0.1357376
[Epoch 63; Iter    76/  157] train: loss: 0.0990789
[Epoch 63; Iter   106/  157] train: loss: 0.1274906
[Epoch 63; Iter   136/  157] train: loss: 0.0688156
[Epoch 63] ogbg-moltox21: 0.819877 val loss: 0.212099
[Epoch 63] ogbg-moltox21: 0.843019 test loss: 0.217606
[Epoch 64; Iter     9/  157] train: loss: 0.0702687
[Epoch 64; Iter    39/  157] train: loss: 0.0833170
[Epoch 64; Iter    69/  157] train: loss: 0.0831274
[Epoch 64; Iter    99/  157] train: loss: 0.1244094
[Epoch 64; Iter   129/  157] train: loss: 0.0739386
[Epoch 64] ogbg-moltox21: 0.820582 val loss: 0.221541
[Epoch 64] ogbg-moltox21: 0.840495 test loss: 0.232864
[Epoch 65; Iter     2/  157] train: loss: 0.0861958
[Epoch 65; Iter    32/  157] train: loss: 0.0835779
[Epoch 65; Iter    62/  157] train: loss: 0.0520623
[Epoch 65; Iter    92/  157] train: loss: 0.0719423
[Epoch 65; Iter   122/  157] train: loss: 0.1291219
[Epoch 65; Iter   152/  157] train: loss: 0.0961049
[Epoch 65] ogbg-moltox21: 0.826344 val loss: 0.214226
[Epoch 65] ogbg-moltox21: 0.836439 test loss: 0.231370
[Epoch 66; Iter    25/  157] train: loss: 0.1084552
[Epoch 66; Iter    55/  157] train: loss: 0.0689574
[Epoch 66; Iter    85/  157] train: loss: 0.0717226
[Epoch 66; Iter   115/  157] train: loss: 0.0637822
[Epoch 66; Iter   145/  157] train: loss: 0.1215344
[Epoch 66] ogbg-moltox21: 0.824195 val loss: 0.206880
[Epoch 66] ogbg-moltox21: 0.840461 test loss: 0.218826
[Epoch 67; Iter    18/  157] train: loss: 0.0898262
[Epoch 67; Iter    48/  157] train: loss: 0.0706345
[Epoch 67; Iter    78/  157] train: loss: 0.0786947
[Epoch 67; Iter   108/  157] train: loss: 0.1083440
[Epoch 67; Iter   138/  157] train: loss: 0.0700867
[Epoch 67] ogbg-moltox21: 0.824334 val loss: 0.219481
[Epoch 67] ogbg-moltox21: 0.834311 test loss: 0.249556
[Epoch 68; Iter    11/  157] train: loss: 0.0729148
[Epoch 68; Iter    41/  157] train: loss: 0.0611193
[Epoch 68; Iter    71/  157] train: loss: 0.0615984
[Epoch 68; Iter   101/  157] train: loss: 0.0683965
[Epoch 68; Iter   131/  157] train: loss: 0.0474118
[Epoch 68] ogbg-moltox21: 0.821230 val loss: 0.214704
[Epoch 68] ogbg-moltox21: 0.835483 test loss: 0.229992
[Epoch 69; Iter     4/  157] train: loss: 0.0880691
[Epoch 69; Iter    34/  157] train: loss: 0.0852915
[Epoch 69; Iter    64/  157] train: loss: 0.0571851
[Epoch 69; Iter    94/  157] train: loss: 0.0504707
[Epoch 69; Iter   124/  157] train: loss: 0.1006399
[Epoch 69; Iter   154/  157] train: loss: 0.0888239
[Epoch 69] ogbg-moltox21: 0.823533 val loss: 0.234397
[Epoch 69] ogbg-moltox21: 0.836470 test loss: 0.259867
[Epoch 70; Iter    27/  157] train: loss: 0.0587007
[Epoch 70; Iter    57/  157] train: loss: 0.0480112
[Epoch 70; Iter    87/  157] train: loss: 0.0994285
[Epoch 70; Iter   117/  157] train: loss: 0.0536891
[Epoch 70; Iter   147/  157] train: loss: 0.0810247
[Epoch 70] ogbg-moltox21: 0.821348 val loss: 0.221460
[Epoch 70] ogbg-moltox21: 0.837573 test loss: 0.236877
[Epoch 71; Iter    20/  157] train: loss: 0.0461080
[Epoch 71; Iter    50/  157] train: loss: 0.0921393
[Epoch 71; Iter    80/  157] train: loss: 0.0814348
[Epoch 71; Iter   110/  157] train: loss: 0.0553973
[Epoch 71; Iter   140/  157] train: loss: 0.0652853
[Epoch 71] ogbg-moltox21: 0.822070 val loss: 0.222772
[Epoch 71] ogbg-moltox21: 0.832521 test loss: 0.248447
[Epoch 72; Iter    13/  157] train: loss: 0.1041877
[Epoch 72; Iter    43/  157] train: loss: 0.0709867
[Epoch 72; Iter    73/  157] train: loss: 0.0497243
[Epoch 72; Iter   103/  157] train: loss: 0.0805039
[Epoch 72; Iter   133/  157] train: loss: 0.0918105
[Epoch 72] ogbg-moltox21: 0.826322 val loss: 0.235523
[Epoch 72] ogbg-moltox21: 0.836469 test loss: 0.252856
[Epoch 73; Iter     6/  157] train: loss: 0.0594151
[Epoch 73; Iter    36/  157] train: loss: 0.0541672
[Epoch 73; Iter    66/  157] train: loss: 0.0640874
[Epoch 73; Iter    96/  157] train: loss: 0.0887534
[Epoch 73; Iter   126/  157] train: loss: 0.1204515
[Epoch 73; Iter   156/  157] train: loss: 0.1236249
[Epoch 73] ogbg-moltox21: 0.812257 val loss: 0.232172
[Epoch 73] ogbg-moltox21: 0.822936 test loss: 0.252474
[Epoch 74; Iter    29/  157] train: loss: 0.0282953
[Epoch 74; Iter    59/  157] train: loss: 0.0653350
[Epoch 74; Iter    89/  157] train: loss: 0.0523827
[Epoch 74; Iter   119/  157] train: loss: 0.0963526
[Epoch 74; Iter   149/  157] train: loss: 0.0702668
[Epoch 74] ogbg-moltox21: 0.820219 val loss: 0.233514
[Epoch 74] ogbg-moltox21: 0.834409 test loss: 0.250114
[Epoch 75; Iter    22/  157] train: loss: 0.1047738
[Epoch 75; Iter    52/  157] train: loss: 0.0669043
[Epoch 75; Iter    82/  157] train: loss: 0.1070124
[Epoch 75; Iter   112/  157] train: loss: 0.1317475
[Epoch 75; Iter   142/  157] train: loss: 0.0582437
[Epoch 75] ogbg-moltox21: 0.824739 val loss: 0.223899
[Epoch 75] ogbg-moltox21: 0.832932 test loss: 0.240377
[Epoch 76; Iter    15/  157] train: loss: 0.0753747
[Epoch 76; Iter    45/  157] train: loss: 0.0512111
[Epoch 76; Iter    75/  157] train: loss: 0.0485827
[Epoch 76; Iter   105/  157] train: loss: 0.0706890
[Epoch 76; Iter   135/  157] train: loss: 0.0894228
[Epoch 76] ogbg-moltox21: 0.818475 val loss: 0.229519
[Epoch 76] ogbg-moltox21: 0.830891 test loss: 0.243453
[Epoch 77; Iter     8/  157] train: loss: 0.0615646
[Epoch 77; Iter    38/  157] train: loss: 0.0405997
[Epoch 77; Iter    68/  157] train: loss: 0.0857766
[Epoch 77; Iter    98/  157] train: loss: 0.0666784
[Epoch 77; Iter   128/  157] train: loss: 0.0506475
[Epoch 77] ogbg-moltox21: 0.822952 val loss: 0.231292
[Epoch 77] ogbg-moltox21: 0.835520 test loss: 0.245368
[Epoch 78; Iter     1/  157] train: loss: 0.0918699
[Epoch 78; Iter    31/  157] train: loss: 0.1162469
[Epoch 78; Iter    61/  157] train: loss: 0.0408706
[Epoch 78; Iter    91/  157] train: loss: 0.0681022
[Epoch 78; Iter   121/  157] train: loss: 0.0612426
[Epoch 78; Iter   151/  157] train: loss: 0.0518738
[Epoch 78] ogbg-moltox21: 0.813154 val loss: 0.238854
[Epoch 78] ogbg-moltox21: 0.822087 test loss: 0.260922
[Epoch 79; Iter    24/  157] train: loss: 0.0935804
[Epoch 79; Iter    54/  157] train: loss: 0.0849293
[Epoch 79; Iter    84/  157] train: loss: 0.0543727
[Epoch 79; Iter   114/  157] train: loss: 0.0787222
[Epoch 79; Iter   144/  157] train: loss: 0.0736562
[Epoch 79] ogbg-moltox21: 0.817389 val loss: 0.238025
[Epoch 79] ogbg-moltox21: 0.829913 test loss: 0.255512
[Epoch 80; Iter    17/  157] train: loss: 0.1015680
[Epoch 58] ogbg-moltox21: 0.817147 val loss: 0.215347
[Epoch 58] ogbg-moltox21: 0.827246 test loss: 0.221959
[Epoch 59; Iter    14/  157] train: loss: 0.0707619
[Epoch 59; Iter    44/  157] train: loss: 0.0941379
[Epoch 59; Iter    74/  157] train: loss: 0.1231819
[Epoch 59; Iter   104/  157] train: loss: 0.0988855
[Epoch 59; Iter   134/  157] train: loss: 0.1872622
[Epoch 59] ogbg-moltox21: 0.819769 val loss: 0.213126
[Epoch 59] ogbg-moltox21: 0.835855 test loss: 0.221786
[Epoch 60; Iter     7/  157] train: loss: 0.0980363
[Epoch 60; Iter    37/  157] train: loss: 0.1416761
[Epoch 60; Iter    67/  157] train: loss: 0.1055691
[Epoch 60; Iter    97/  157] train: loss: 0.1080231
[Epoch 60; Iter   127/  157] train: loss: 0.1024211
[Epoch 60; Iter   157/  157] train: loss: 0.0736843
[Epoch 60] ogbg-moltox21: 0.814002 val loss: 0.220414
[Epoch 60] ogbg-moltox21: 0.829701 test loss: 0.228471
[Epoch 61; Iter    30/  157] train: loss: 0.1014011
[Epoch 61; Iter    60/  157] train: loss: 0.1171265
[Epoch 61; Iter    90/  157] train: loss: 0.0881115
[Epoch 61; Iter   120/  157] train: loss: 0.0993975
[Epoch 61; Iter   150/  157] train: loss: 0.1117492
[Epoch 61] ogbg-moltox21: 0.808277 val loss: 0.216709
[Epoch 61] ogbg-moltox21: 0.820606 test loss: 0.236648
[Epoch 62; Iter    23/  157] train: loss: 0.1000785
[Epoch 62; Iter    53/  157] train: loss: 0.0933393
[Epoch 62; Iter    83/  157] train: loss: 0.1044808
[Epoch 62; Iter   113/  157] train: loss: 0.1144795
[Epoch 62; Iter   143/  157] train: loss: 0.1280284
[Epoch 62] ogbg-moltox21: 0.810234 val loss: 0.211306
[Epoch 62] ogbg-moltox21: 0.830162 test loss: 0.231679
[Epoch 63; Iter    16/  157] train: loss: 0.1075085
[Epoch 63; Iter    46/  157] train: loss: 0.0695433
[Epoch 63; Iter    76/  157] train: loss: 0.1108863
[Epoch 63; Iter   106/  157] train: loss: 0.0809163
[Epoch 63; Iter   136/  157] train: loss: 0.1257030
[Epoch 63] ogbg-moltox21: 0.816492 val loss: 0.210033
[Epoch 63] ogbg-moltox21: 0.832963 test loss: 0.224614
[Epoch 64; Iter     9/  157] train: loss: 0.1061453
[Epoch 64; Iter    39/  157] train: loss: 0.0623080
[Epoch 64; Iter    69/  157] train: loss: 0.1251628
[Epoch 64; Iter    99/  157] train: loss: 0.0960272
[Epoch 64; Iter   129/  157] train: loss: 0.1410505
[Epoch 64] ogbg-moltox21: 0.817867 val loss: 0.218831
[Epoch 64] ogbg-moltox21: 0.829972 test loss: 0.231989
[Epoch 65; Iter     2/  157] train: loss: 0.0653791
[Epoch 65; Iter    32/  157] train: loss: 0.1035446
[Epoch 65; Iter    62/  157] train: loss: 0.1867394
[Epoch 65; Iter    92/  157] train: loss: 0.1307994
[Epoch 65; Iter   122/  157] train: loss: 0.1572057
[Epoch 65; Iter   152/  157] train: loss: 0.0963593
[Epoch 65] ogbg-moltox21: 0.810896 val loss: 0.215146
[Epoch 65] ogbg-moltox21: 0.820977 test loss: 0.232666
[Epoch 66; Iter    25/  157] train: loss: 0.0666456
[Epoch 66; Iter    55/  157] train: loss: 0.0552746
[Epoch 66; Iter    85/  157] train: loss: 0.1097164
[Epoch 66; Iter   115/  157] train: loss: 0.0772989
[Epoch 66; Iter   145/  157] train: loss: 0.0748840
[Epoch 66] ogbg-moltox21: 0.824689 val loss: 0.209100
[Epoch 66] ogbg-moltox21: 0.836239 test loss: 0.226379
[Epoch 67; Iter    18/  157] train: loss: 0.0761634
[Epoch 67; Iter    48/  157] train: loss: 0.0796849
[Epoch 67; Iter    78/  157] train: loss: 0.0876458
[Epoch 67; Iter   108/  157] train: loss: 0.0905893
[Epoch 67; Iter   138/  157] train: loss: 0.1025859
[Epoch 67] ogbg-moltox21: 0.804843 val loss: 0.218573
[Epoch 67] ogbg-moltox21: 0.813072 test loss: 0.242018
[Epoch 68; Iter    11/  157] train: loss: 0.0847398
[Epoch 68; Iter    41/  157] train: loss: 0.0549855
[Epoch 68; Iter    71/  157] train: loss: 0.1273648
[Epoch 68; Iter   101/  157] train: loss: 0.0582996
[Epoch 68; Iter   131/  157] train: loss: 0.0906088
[Epoch 68] ogbg-moltox21: 0.814316 val loss: 0.213365
[Epoch 68] ogbg-moltox21: 0.829005 test loss: 0.231865
[Epoch 69; Iter     4/  157] train: loss: 0.0969057
[Epoch 69; Iter    34/  157] train: loss: 0.2362280
[Epoch 69; Iter    64/  157] train: loss: 0.0694381
[Epoch 69; Iter    94/  157] train: loss: 0.0793130
[Epoch 69; Iter   124/  157] train: loss: 0.1162242
[Epoch 69; Iter   154/  157] train: loss: 0.0621047
[Epoch 69] ogbg-moltox21: 0.817582 val loss: 0.220623
[Epoch 69] ogbg-moltox21: 0.827149 test loss: 0.235903
[Epoch 70; Iter    27/  157] train: loss: 0.0453883
[Epoch 70; Iter    57/  157] train: loss: 0.0582954
[Epoch 70; Iter    87/  157] train: loss: 0.0903005
[Epoch 70; Iter   117/  157] train: loss: 0.0459313
[Epoch 70; Iter   147/  157] train: loss: 0.0839395
[Epoch 70] ogbg-moltox21: 0.813882 val loss: 0.218408
[Epoch 70] ogbg-moltox21: 0.821262 test loss: 0.242405
[Epoch 71; Iter    20/  157] train: loss: 0.0871664
[Epoch 71; Iter    50/  157] train: loss: 0.0850211
[Epoch 71; Iter    80/  157] train: loss: 0.0469212
[Epoch 71; Iter   110/  157] train: loss: 0.1034218
[Epoch 71; Iter   140/  157] train: loss: 0.0751947
[Epoch 71] ogbg-moltox21: 0.815943 val loss: 0.221266
[Epoch 71] ogbg-moltox21: 0.820924 test loss: 0.246003
[Epoch 72; Iter    13/  157] train: loss: 0.0672737
[Epoch 72; Iter    43/  157] train: loss: 0.0718709
[Epoch 72; Iter    73/  157] train: loss: 0.0590138
[Epoch 72; Iter   103/  157] train: loss: 0.1047718
[Epoch 72; Iter   133/  157] train: loss: 0.1002830
[Epoch 72] ogbg-moltox21: 0.808629 val loss: 0.231051
[Epoch 72] ogbg-moltox21: 0.818840 test loss: 0.251351
[Epoch 73; Iter     6/  157] train: loss: 0.1067396
[Epoch 73; Iter    36/  157] train: loss: 0.0554623
[Epoch 73; Iter    66/  157] train: loss: 0.1014021
[Epoch 73; Iter    96/  157] train: loss: 0.0953936
[Epoch 73; Iter   126/  157] train: loss: 0.0582595
[Epoch 73; Iter   156/  157] train: loss: 0.0986045
[Epoch 73] ogbg-moltox21: 0.808722 val loss: 0.228556
[Epoch 73] ogbg-moltox21: 0.822695 test loss: 0.250289
[Epoch 74; Iter    29/  157] train: loss: 0.0975672
[Epoch 74; Iter    59/  157] train: loss: 0.0837398
[Epoch 74; Iter    89/  157] train: loss: 0.0478347
[Epoch 74; Iter   119/  157] train: loss: 0.0848045
[Epoch 74; Iter   149/  157] train: loss: 0.0813536
[Epoch 74] ogbg-moltox21: 0.805303 val loss: 0.229107
[Epoch 74] ogbg-moltox21: 0.818466 test loss: 0.251584
[Epoch 75; Iter    22/  157] train: loss: 0.1018778
[Epoch 75; Iter    52/  157] train: loss: 0.1381176
[Epoch 75; Iter    82/  157] train: loss: 0.0521949
[Epoch 75; Iter   112/  157] train: loss: 0.0687732
[Epoch 75; Iter   142/  157] train: loss: 0.0879869
[Epoch 75] ogbg-moltox21: 0.812132 val loss: 0.229353
[Epoch 75] ogbg-moltox21: 0.822072 test loss: 0.250674
[Epoch 76; Iter    15/  157] train: loss: 0.0586693
[Epoch 76; Iter    45/  157] train: loss: 0.1907917
[Epoch 76; Iter    75/  157] train: loss: 0.1002423
[Epoch 76; Iter   105/  157] train: loss: 0.0228752
[Epoch 76; Iter   135/  157] train: loss: 0.0359665
[Epoch 76] ogbg-moltox21: 0.804731 val loss: 0.231615
[Epoch 76] ogbg-moltox21: 0.817378 test loss: 0.256093
[Epoch 77; Iter     8/  157] train: loss: 0.0643978
[Epoch 77; Iter    38/  157] train: loss: 0.0982764
[Epoch 77; Iter    68/  157] train: loss: 0.0932046
[Epoch 77; Iter    98/  157] train: loss: 0.0622976
[Epoch 77; Iter   128/  157] train: loss: 0.0348556
[Epoch 77] ogbg-moltox21: 0.799886 val loss: 0.234941
[Epoch 77] ogbg-moltox21: 0.809424 test loss: 0.263051
[Epoch 78; Iter     1/  157] train: loss: 0.0489086
[Epoch 78; Iter    31/  157] train: loss: 0.0699944
[Epoch 78; Iter    61/  157] train: loss: 0.0394291
[Epoch 78; Iter    91/  157] train: loss: 0.0389441
[Epoch 78; Iter   121/  157] train: loss: 0.0737900
[Epoch 78; Iter   151/  157] train: loss: 0.0295460
[Epoch 78] ogbg-moltox21: 0.803874 val loss: 0.239500
[Epoch 78] ogbg-moltox21: 0.814382 test loss: 0.269160
[Epoch 79; Iter    24/  157] train: loss: 0.0802363
[Epoch 79; Iter    54/  157] train: loss: 0.0810123
[Epoch 79; Iter    84/  157] train: loss: 0.0575919
[Epoch 79; Iter   114/  157] train: loss: 0.1129844
[Epoch 79; Iter   144/  157] train: loss: 0.0696071
[Epoch 79] ogbg-moltox21: 0.807515 val loss: 0.239510
[Epoch 79] ogbg-moltox21: 0.815093 test loss: 0.266409
[Epoch 80; Iter    17/  157] train: loss: 0.0583850
[Epoch 64] ogbg-moltox21: 0.851073 test loss: 0.196347
[Epoch 65; Iter     4/  209] train: loss: 0.1343139
[Epoch 65; Iter    34/  209] train: loss: 0.1509233
[Epoch 65; Iter    64/  209] train: loss: 0.1270890
[Epoch 65; Iter    94/  209] train: loss: 0.1401135
[Epoch 65; Iter   124/  209] train: loss: 0.0944442
[Epoch 65; Iter   154/  209] train: loss: 0.1450579
[Epoch 65; Iter   184/  209] train: loss: 0.1366714
[Epoch 65] ogbg-moltox21: 0.846984 val loss: 0.240372
[Epoch 65] ogbg-moltox21: 0.845622 test loss: 0.209316
[Epoch 66; Iter     5/  209] train: loss: 0.0634606
[Epoch 66; Iter    35/  209] train: loss: 0.0750947
[Epoch 66; Iter    65/  209] train: loss: 0.2398951
[Epoch 66; Iter    95/  209] train: loss: 0.1766114
[Epoch 66; Iter   125/  209] train: loss: 0.0730396
[Epoch 66; Iter   155/  209] train: loss: 0.0923791
[Epoch 66; Iter   185/  209] train: loss: 0.0769780
[Epoch 66] ogbg-moltox21: 0.853334 val loss: 0.228509
[Epoch 66] ogbg-moltox21: 0.840869 test loss: 0.199831
[Epoch 67; Iter     6/  209] train: loss: 0.2251702
[Epoch 67; Iter    36/  209] train: loss: 0.0810960
[Epoch 67; Iter    66/  209] train: loss: 0.1686856
[Epoch 67; Iter    96/  209] train: loss: 0.1190018
[Epoch 67; Iter   126/  209] train: loss: 0.1821193
[Epoch 67; Iter   156/  209] train: loss: 0.1256747
[Epoch 67; Iter   186/  209] train: loss: 0.0821235
[Epoch 67] ogbg-moltox21: 0.856482 val loss: 0.225591
[Epoch 67] ogbg-moltox21: 0.844163 test loss: 0.202547
[Epoch 68; Iter     7/  209] train: loss: 0.1084055
[Epoch 68; Iter    37/  209] train: loss: 0.1418799
[Epoch 68; Iter    67/  209] train: loss: 0.1186166
[Epoch 68; Iter    97/  209] train: loss: 0.0994761
[Epoch 68; Iter   127/  209] train: loss: 0.0991674
[Epoch 68; Iter   157/  209] train: loss: 0.1258728
[Epoch 68; Iter   187/  209] train: loss: 0.0951393
[Epoch 68] ogbg-moltox21: 0.853564 val loss: 0.235098
[Epoch 68] ogbg-moltox21: 0.841344 test loss: 0.208894
[Epoch 69; Iter     8/  209] train: loss: 0.1110318
[Epoch 69; Iter    38/  209] train: loss: 0.1148963
[Epoch 69; Iter    68/  209] train: loss: 0.1363754
[Epoch 69; Iter    98/  209] train: loss: 0.1210630
[Epoch 69; Iter   128/  209] train: loss: 0.1437948
[Epoch 69; Iter   158/  209] train: loss: 0.0770133
[Epoch 69; Iter   188/  209] train: loss: 0.0807693
[Epoch 69] ogbg-moltox21: 0.859523 val loss: 0.226462
[Epoch 69] ogbg-moltox21: 0.838991 test loss: 0.208607
[Epoch 70; Iter     9/  209] train: loss: 0.0992137
[Epoch 70; Iter    39/  209] train: loss: 0.1117366
[Epoch 70; Iter    69/  209] train: loss: 0.0872642
[Epoch 70; Iter    99/  209] train: loss: 0.1302299
[Epoch 70; Iter   129/  209] train: loss: 0.0856111
[Epoch 70; Iter   159/  209] train: loss: 0.0824036
[Epoch 70; Iter   189/  209] train: loss: 0.1550879
[Epoch 70] ogbg-moltox21: 0.860252 val loss: 0.223607
[Epoch 70] ogbg-moltox21: 0.852403 test loss: 0.198092
[Epoch 71; Iter    10/  209] train: loss: 0.1176142
[Epoch 71; Iter    40/  209] train: loss: 0.0684593
[Epoch 71; Iter    70/  209] train: loss: 0.1173314
[Epoch 71; Iter   100/  209] train: loss: 0.1005053
[Epoch 71; Iter   130/  209] train: loss: 0.0830455
[Epoch 71; Iter   160/  209] train: loss: 0.1131533
[Epoch 71; Iter   190/  209] train: loss: 0.1057232
[Epoch 71] ogbg-moltox21: 0.855654 val loss: 0.241532
[Epoch 71] ogbg-moltox21: 0.850807 test loss: 0.221704
[Epoch 72; Iter    11/  209] train: loss: 0.0839811
[Epoch 72; Iter    41/  209] train: loss: 0.0736018
[Epoch 72; Iter    71/  209] train: loss: 0.0660316
[Epoch 72; Iter   101/  209] train: loss: 0.1214875
[Epoch 72; Iter   131/  209] train: loss: 0.0809474
[Epoch 72; Iter   161/  209] train: loss: 0.1791250
[Epoch 72; Iter   191/  209] train: loss: 0.0645204
[Epoch 72] ogbg-moltox21: 0.847719 val loss: 0.242833
[Epoch 72] ogbg-moltox21: 0.848023 test loss: 0.207193
[Epoch 73; Iter    12/  209] train: loss: 0.0705313
[Epoch 73; Iter    42/  209] train: loss: 0.0877820
[Epoch 73; Iter    72/  209] train: loss: 0.0746344
[Epoch 73; Iter   102/  209] train: loss: 0.1028877
[Epoch 73; Iter   132/  209] train: loss: 0.0411686
[Epoch 73; Iter   162/  209] train: loss: 0.1280016
[Epoch 73; Iter   192/  209] train: loss: 0.1423185
[Epoch 73] ogbg-moltox21: 0.849165 val loss: 0.250626
[Epoch 73] ogbg-moltox21: 0.845712 test loss: 0.247555
[Epoch 74; Iter    13/  209] train: loss: 0.1160962
[Epoch 74; Iter    43/  209] train: loss: 0.1071256
[Epoch 74; Iter    73/  209] train: loss: 0.1242703
[Epoch 74; Iter   103/  209] train: loss: 0.1408139
[Epoch 74; Iter   133/  209] train: loss: 0.1189606
[Epoch 74; Iter   163/  209] train: loss: 0.0743549
[Epoch 74; Iter   193/  209] train: loss: 0.0802133
[Epoch 74] ogbg-moltox21: 0.841927 val loss: 0.245831
[Epoch 74] ogbg-moltox21: 0.851136 test loss: 0.208863
[Epoch 75; Iter    14/  209] train: loss: 0.1144702
[Epoch 75; Iter    44/  209] train: loss: 0.1094938
[Epoch 75; Iter    74/  209] train: loss: 0.1124478
[Epoch 75; Iter   104/  209] train: loss: 0.0489705
[Epoch 75; Iter   134/  209] train: loss: 0.1138022
[Epoch 75; Iter   164/  209] train: loss: 0.1110054
[Epoch 75; Iter   194/  209] train: loss: 0.0802646
[Epoch 75] ogbg-moltox21: 0.847308 val loss: 0.243810
[Epoch 75] ogbg-moltox21: 0.842988 test loss: 0.202223
[Epoch 76; Iter    15/  209] train: loss: 0.0911417
[Epoch 76; Iter    45/  209] train: loss: 0.0832949
[Epoch 76; Iter    75/  209] train: loss: 0.0893158
[Epoch 76; Iter   105/  209] train: loss: 0.0811584
[Epoch 76; Iter   135/  209] train: loss: 0.1230433
[Epoch 76; Iter   165/  209] train: loss: 0.1308159
[Epoch 76; Iter   195/  209] train: loss: 0.0857604
[Epoch 76] ogbg-moltox21: 0.852253 val loss: 0.240176
[Epoch 76] ogbg-moltox21: 0.845958 test loss: 0.205520
[Epoch 77; Iter    16/  209] train: loss: 0.0978395
[Epoch 77; Iter    46/  209] train: loss: 0.0594172
[Epoch 77; Iter    76/  209] train: loss: 0.0734656
[Epoch 77; Iter   106/  209] train: loss: 0.0571509
[Epoch 77; Iter   136/  209] train: loss: 0.0810182
[Epoch 77; Iter   166/  209] train: loss: 0.0713319
[Epoch 77; Iter   196/  209] train: loss: 0.0589201
[Epoch 77] ogbg-moltox21: 0.851007 val loss: 0.242733
[Epoch 77] ogbg-moltox21: 0.847785 test loss: 0.204250
[Epoch 78; Iter    17/  209] train: loss: 0.0678738
[Epoch 78; Iter    47/  209] train: loss: 0.0608429
[Epoch 78; Iter    77/  209] train: loss: 0.0573585
[Epoch 78; Iter   107/  209] train: loss: 0.0553335
[Epoch 78; Iter   137/  209] train: loss: 0.0708390
[Epoch 78; Iter   167/  209] train: loss: 0.0500092
[Epoch 78; Iter   197/  209] train: loss: 0.0902988
[Epoch 78] ogbg-moltox21: 0.845230 val loss: 0.250540
[Epoch 78] ogbg-moltox21: 0.842749 test loss: 0.212480
[Epoch 79; Iter    18/  209] train: loss: 0.0476861
[Epoch 79; Iter    48/  209] train: loss: 0.1052557
[Epoch 79; Iter    78/  209] train: loss: 0.0335727
[Epoch 79; Iter   108/  209] train: loss: 0.0650140
[Epoch 79; Iter   138/  209] train: loss: 0.0812788
[Epoch 79; Iter   168/  209] train: loss: 0.0590623
[Epoch 79; Iter   198/  209] train: loss: 0.1051694
[Epoch 79] ogbg-moltox21: 0.843504 val loss: 0.252358
[Epoch 79] ogbg-moltox21: 0.844037 test loss: 0.215531
[Epoch 80; Iter    19/  209] train: loss: 0.0533982
[Epoch 80; Iter    49/  209] train: loss: 0.1016063
[Epoch 80; Iter    79/  209] train: loss: 0.0791843
[Epoch 80; Iter   109/  209] train: loss: 0.0769041
[Epoch 80; Iter   139/  209] train: loss: 0.0745554
[Epoch 80; Iter   169/  209] train: loss: 0.0596333
[Epoch 80; Iter   199/  209] train: loss: 0.0771313
[Epoch 80] ogbg-moltox21: 0.843149 val loss: 0.262895
[Epoch 80] ogbg-moltox21: 0.839930 test loss: 0.219679
[Epoch 81; Iter    20/  209] train: loss: 0.1014644
[Epoch 81; Iter    50/  209] train: loss: 0.1388342
[Epoch 81; Iter    80/  209] train: loss: 0.0737690
[Epoch 81; Iter   110/  209] train: loss: 0.0680793
[Epoch 81; Iter   140/  209] train: loss: 0.1141727
[Epoch 81; Iter   170/  209] train: loss: 0.0890215
[Epoch 81; Iter   200/  209] train: loss: 0.0676378
[Epoch 81] ogbg-moltox21: 0.849830 val loss: 0.257417
[Epoch 81] ogbg-moltox21: 0.850054 test loss: 0.213779
[Epoch 82; Iter    21/  209] train: loss: 0.1081265
[Epoch 64] ogbg-moltox21: 0.843638 test loss: 0.211941
[Epoch 65; Iter     4/  209] train: loss: 0.0819638
[Epoch 65; Iter    34/  209] train: loss: 0.0724044
[Epoch 65; Iter    64/  209] train: loss: 0.0843412
[Epoch 65; Iter    94/  209] train: loss: 0.1405973
[Epoch 65; Iter   124/  209] train: loss: 0.1197313
[Epoch 65; Iter   154/  209] train: loss: 0.1084935
[Epoch 65; Iter   184/  209] train: loss: 0.1326103
[Epoch 65] ogbg-moltox21: 0.844609 val loss: 0.232252
[Epoch 65] ogbg-moltox21: 0.843405 test loss: 0.254579
[Epoch 66; Iter     5/  209] train: loss: 0.1405995
[Epoch 66; Iter    35/  209] train: loss: 0.1454736
[Epoch 66; Iter    65/  209] train: loss: 0.0885624
[Epoch 66; Iter    95/  209] train: loss: 0.1030333
[Epoch 66; Iter   125/  209] train: loss: 0.1374376
[Epoch 66; Iter   155/  209] train: loss: 0.0622946
[Epoch 66; Iter   185/  209] train: loss: 0.1278947
[Epoch 66] ogbg-moltox21: 0.844737 val loss: 0.236997
[Epoch 66] ogbg-moltox21: 0.844829 test loss: 0.214418
[Epoch 67; Iter     6/  209] train: loss: 0.1152329
[Epoch 67; Iter    36/  209] train: loss: 0.1263687
[Epoch 67; Iter    66/  209] train: loss: 0.0915527
[Epoch 67; Iter    96/  209] train: loss: 0.1083803
[Epoch 67; Iter   126/  209] train: loss: 0.0871422
[Epoch 67; Iter   156/  209] train: loss: 0.0676620
[Epoch 67; Iter   186/  209] train: loss: 0.0663760
[Epoch 67] ogbg-moltox21: 0.840000 val loss: 0.238384
[Epoch 67] ogbg-moltox21: 0.841423 test loss: 0.214535
[Epoch 68; Iter     7/  209] train: loss: 0.0591560
[Epoch 68; Iter    37/  209] train: loss: 0.0826714
[Epoch 68; Iter    67/  209] train: loss: 0.1354073
[Epoch 68; Iter    97/  209] train: loss: 0.0523680
[Epoch 68; Iter   127/  209] train: loss: 0.1194107
[Epoch 68; Iter   157/  209] train: loss: 0.0995125
[Epoch 68; Iter   187/  209] train: loss: 0.1219808
[Epoch 68] ogbg-moltox21: 0.835372 val loss: 0.244280
[Epoch 68] ogbg-moltox21: 0.841160 test loss: 0.218853
[Epoch 69; Iter     8/  209] train: loss: 0.1079635
[Epoch 69; Iter    38/  209] train: loss: 0.0848498
[Epoch 69; Iter    68/  209] train: loss: 0.0861019
[Epoch 69; Iter    98/  209] train: loss: 0.1197325
[Epoch 69; Iter   128/  209] train: loss: 0.1464412
[Epoch 69; Iter   158/  209] train: loss: 0.1343441
[Epoch 69; Iter   188/  209] train: loss: 0.0650816
[Epoch 69] ogbg-moltox21: 0.841298 val loss: 0.238873
[Epoch 69] ogbg-moltox21: 0.840877 test loss: 0.216550
[Epoch 70; Iter     9/  209] train: loss: 0.0919401
[Epoch 70; Iter    39/  209] train: loss: 0.0686601
[Epoch 70; Iter    69/  209] train: loss: 0.0821046
[Epoch 70; Iter    99/  209] train: loss: 0.1634724
[Epoch 70; Iter   129/  209] train: loss: 0.0701070
[Epoch 70; Iter   159/  209] train: loss: 0.0702327
[Epoch 70; Iter   189/  209] train: loss: 0.1587176
[Epoch 70] ogbg-moltox21: 0.844880 val loss: 0.240491
[Epoch 70] ogbg-moltox21: 0.845093 test loss: 0.221495
[Epoch 71; Iter    10/  209] train: loss: 0.0511547
[Epoch 71; Iter    40/  209] train: loss: 0.0867248
[Epoch 71; Iter    70/  209] train: loss: 0.0766729
[Epoch 71; Iter   100/  209] train: loss: 0.1033283
[Epoch 71; Iter   130/  209] train: loss: 0.0946501
[Epoch 71; Iter   160/  209] train: loss: 0.0998017
[Epoch 71; Iter   190/  209] train: loss: 0.1109683
[Epoch 71] ogbg-moltox21: 0.840748 val loss: 0.244615
[Epoch 71] ogbg-moltox21: 0.839606 test loss: 0.221130
[Epoch 72; Iter    11/  209] train: loss: 0.0902831
[Epoch 72; Iter    41/  209] train: loss: 0.0773710
[Epoch 72; Iter    71/  209] train: loss: 0.0872102
[Epoch 72; Iter   101/  209] train: loss: 0.0617332
[Epoch 72; Iter   131/  209] train: loss: 0.0962180
[Epoch 72; Iter   161/  209] train: loss: 0.0764214
[Epoch 72; Iter   191/  209] train: loss: 0.0827548
[Epoch 72] ogbg-moltox21: 0.841708 val loss: 0.239987
[Epoch 72] ogbg-moltox21: 0.843948 test loss: 0.223583
[Epoch 73; Iter    12/  209] train: loss: 0.1069664
[Epoch 73; Iter    42/  209] train: loss: 0.0857886
[Epoch 73; Iter    72/  209] train: loss: 0.0980260
[Epoch 73; Iter   102/  209] train: loss: 0.0524011
[Epoch 73; Iter   132/  209] train: loss: 0.0532134
[Epoch 73; Iter   162/  209] train: loss: 0.0678433
[Epoch 73; Iter   192/  209] train: loss: 0.0844381
[Epoch 73] ogbg-moltox21: 0.829827 val loss: 0.247465
[Epoch 73] ogbg-moltox21: 0.834538 test loss: 0.227710
[Epoch 74; Iter    13/  209] train: loss: 0.0831165
[Epoch 74; Iter    43/  209] train: loss: 0.0703781
[Epoch 74; Iter    73/  209] train: loss: 0.0984259
[Epoch 74; Iter   103/  209] train: loss: 0.0995341
[Epoch 74; Iter   133/  209] train: loss: 0.0923047
[Epoch 74; Iter   163/  209] train: loss: 0.0548278
[Epoch 74; Iter   193/  209] train: loss: 0.0736587
[Epoch 74] ogbg-moltox21: 0.842690 val loss: 0.243923
[Epoch 74] ogbg-moltox21: 0.839007 test loss: 0.229550
[Epoch 75; Iter    14/  209] train: loss: 0.0593995
[Epoch 75; Iter    44/  209] train: loss: 0.0936577
[Epoch 75; Iter    74/  209] train: loss: 0.1227934
[Epoch 75; Iter   104/  209] train: loss: 0.1224638
[Epoch 75; Iter   134/  209] train: loss: 0.0874867
[Epoch 75; Iter   164/  209] train: loss: 0.0749963
[Epoch 75; Iter   194/  209] train: loss: 0.1119310
[Epoch 75] ogbg-moltox21: 0.837737 val loss: 0.246669
[Epoch 75] ogbg-moltox21: 0.832032 test loss: 0.233627
[Epoch 76; Iter    15/  209] train: loss: 0.0718472
[Epoch 76; Iter    45/  209] train: loss: 0.0932748
[Epoch 76; Iter    75/  209] train: loss: 0.0957474
[Epoch 76; Iter   105/  209] train: loss: 0.1483721
[Epoch 76; Iter   135/  209] train: loss: 0.0630663
[Epoch 76; Iter   165/  209] train: loss: 0.0678727
[Epoch 76; Iter   195/  209] train: loss: 0.1200028
[Epoch 76] ogbg-moltox21: 0.838768 val loss: 0.255140
[Epoch 76] ogbg-moltox21: 0.843342 test loss: 0.225932
[Epoch 77; Iter    16/  209] train: loss: 0.0517771
[Epoch 77; Iter    46/  209] train: loss: 0.1095616
[Epoch 77; Iter    76/  209] train: loss: 0.1102833
[Epoch 77; Iter   106/  209] train: loss: 0.0682023
[Epoch 77; Iter   136/  209] train: loss: 0.1247834
[Epoch 77; Iter   166/  209] train: loss: 0.0617240
[Epoch 77; Iter   196/  209] train: loss: 0.1702287
[Epoch 77] ogbg-moltox21: 0.830381 val loss: 0.258044
[Epoch 77] ogbg-moltox21: 0.836044 test loss: 0.232827
[Epoch 78; Iter    17/  209] train: loss: 0.0781409
[Epoch 78; Iter    47/  209] train: loss: 0.0944974
[Epoch 78; Iter    77/  209] train: loss: 0.1009169
[Epoch 78; Iter   107/  209] train: loss: 0.1018888
[Epoch 78; Iter   137/  209] train: loss: 0.0691415
[Epoch 78; Iter   167/  209] train: loss: 0.1316669
[Epoch 78; Iter   197/  209] train: loss: 0.0569476
[Epoch 78] ogbg-moltox21: 0.833976 val loss: 0.251302
[Epoch 78] ogbg-moltox21: 0.835721 test loss: 0.234928
[Epoch 79; Iter    18/  209] train: loss: 0.0405478
[Epoch 79; Iter    48/  209] train: loss: 0.0776059
[Epoch 79; Iter    78/  209] train: loss: 0.0899845
[Epoch 79; Iter   108/  209] train: loss: 0.1049717
[Epoch 79; Iter   138/  209] train: loss: 0.1435803
[Epoch 79; Iter   168/  209] train: loss: 0.0833765
[Epoch 79; Iter   198/  209] train: loss: 0.0863780
[Epoch 79] ogbg-moltox21: 0.824453 val loss: 0.263566
[Epoch 79] ogbg-moltox21: 0.836908 test loss: 0.240742
[Epoch 80; Iter    19/  209] train: loss: 0.0963245
[Epoch 80; Iter    49/  209] train: loss: 0.0829254
[Epoch 80; Iter    79/  209] train: loss: 0.0479511
[Epoch 80; Iter   109/  209] train: loss: 0.1091236
[Epoch 80; Iter   139/  209] train: loss: 0.0696358
[Epoch 80; Iter   169/  209] train: loss: 0.0818613
[Epoch 80; Iter   199/  209] train: loss: 0.0742575
[Epoch 80] ogbg-moltox21: 0.833822 val loss: 0.267603
[Epoch 80] ogbg-moltox21: 0.837144 test loss: 0.246267
[Epoch 81; Iter    20/  209] train: loss: 0.0790941
[Epoch 81; Iter    50/  209] train: loss: 0.0932930
[Epoch 81; Iter    80/  209] train: loss: 0.0909213
[Epoch 81; Iter   110/  209] train: loss: 0.1485973
[Epoch 81; Iter   140/  209] train: loss: 0.0673701
[Epoch 81; Iter   170/  209] train: loss: 0.0973553
[Epoch 81; Iter   200/  209] train: loss: 0.0794254
[Epoch 81] ogbg-moltox21: 0.829441 val loss: 0.260541
[Epoch 81] ogbg-moltox21: 0.843291 test loss: 0.232214
[Epoch 82; Iter    21/  209] train: loss: 0.0727231
[Epoch 64] ogbg-moltox21: 0.822586 test loss: 0.234981
[Epoch 65; Iter     4/  209] train: loss: 0.0411031
[Epoch 65; Iter    34/  209] train: loss: 0.1062623
[Epoch 65; Iter    64/  209] train: loss: 0.0866348
[Epoch 65; Iter    94/  209] train: loss: 0.0571523
[Epoch 65; Iter   124/  209] train: loss: 0.0545953
[Epoch 65; Iter   154/  209] train: loss: 0.0843982
[Epoch 65; Iter   184/  209] train: loss: 0.0727897
[Epoch 65] ogbg-moltox21: 0.847905 val loss: 0.247051
[Epoch 65] ogbg-moltox21: 0.829976 test loss: 0.230374
[Epoch 66; Iter     5/  209] train: loss: 0.0735097
[Epoch 66; Iter    35/  209] train: loss: 0.0705072
[Epoch 66; Iter    65/  209] train: loss: 0.0981700
[Epoch 66; Iter    95/  209] train: loss: 0.0572474
[Epoch 66; Iter   125/  209] train: loss: 0.0835310
[Epoch 66; Iter   155/  209] train: loss: 0.0956319
[Epoch 66; Iter   185/  209] train: loss: 0.0373528
[Epoch 66] ogbg-moltox21: 0.843779 val loss: 0.245320
[Epoch 66] ogbg-moltox21: 0.825167 test loss: 0.233435
[Epoch 67; Iter     6/  209] train: loss: 0.0633603
[Epoch 67; Iter    36/  209] train: loss: 0.0932246
[Epoch 67; Iter    66/  209] train: loss: 0.0556237
[Epoch 67; Iter    96/  209] train: loss: 0.0689313
[Epoch 67; Iter   126/  209] train: loss: 0.1431309
[Epoch 67; Iter   156/  209] train: loss: 0.1290963
[Epoch 67; Iter   186/  209] train: loss: 0.0761501
[Epoch 67] ogbg-moltox21: 0.841574 val loss: 0.253136
[Epoch 67] ogbg-moltox21: 0.819697 test loss: 0.241796
[Epoch 68; Iter     7/  209] train: loss: 0.0576490
[Epoch 68; Iter    37/  209] train: loss: 0.1278744
[Epoch 68; Iter    67/  209] train: loss: 0.0874566
[Epoch 68; Iter    97/  209] train: loss: 0.0836377
[Epoch 68; Iter   127/  209] train: loss: 0.0780698
[Epoch 68; Iter   157/  209] train: loss: 0.0482570
[Epoch 68; Iter   187/  209] train: loss: 0.0662524
[Epoch 68] ogbg-moltox21: 0.838310 val loss: 0.262712
[Epoch 68] ogbg-moltox21: 0.821111 test loss: 0.251580
[Epoch 69; Iter     8/  209] train: loss: 0.1299050
[Epoch 69; Iter    38/  209] train: loss: 0.0957986
[Epoch 69; Iter    68/  209] train: loss: 0.0764710
[Epoch 69; Iter    98/  209] train: loss: 0.0564399
[Epoch 69; Iter   128/  209] train: loss: 0.0751286
[Epoch 69; Iter   158/  209] train: loss: 0.0695175
[Epoch 69; Iter   188/  209] train: loss: 0.0691227
[Epoch 69] ogbg-moltox21: 0.834301 val loss: 0.261943
[Epoch 69] ogbg-moltox21: 0.822872 test loss: 0.243526
[Epoch 70; Iter     9/  209] train: loss: 0.1126099
[Epoch 70; Iter    39/  209] train: loss: 0.0671110
[Epoch 70; Iter    69/  209] train: loss: 0.0595542
[Epoch 70; Iter    99/  209] train: loss: 0.0601058
[Epoch 70; Iter   129/  209] train: loss: 0.0695329
[Epoch 70; Iter   159/  209] train: loss: 0.0584182
[Epoch 70; Iter   189/  209] train: loss: 0.0499023
[Epoch 70] ogbg-moltox21: 0.838568 val loss: 0.264042
[Epoch 70] ogbg-moltox21: 0.817696 test loss: 0.254711
[Epoch 71; Iter    10/  209] train: loss: 0.0506517
[Epoch 71; Iter    40/  209] train: loss: 0.1346810
[Epoch 71; Iter    70/  209] train: loss: 0.1195185
[Epoch 71; Iter   100/  209] train: loss: 0.0675555
[Epoch 71; Iter   130/  209] train: loss: 0.0524071
[Epoch 71; Iter   160/  209] train: loss: 0.0929631
[Epoch 71; Iter   190/  209] train: loss: 0.0677731
[Epoch 71] ogbg-moltox21: 0.834312 val loss: 0.261641
[Epoch 71] ogbg-moltox21: 0.823952 test loss: 0.250976
[Epoch 72; Iter    11/  209] train: loss: 0.0860570
[Epoch 72; Iter    41/  209] train: loss: 0.0888738
[Epoch 72; Iter    71/  209] train: loss: 0.0821281
[Epoch 72; Iter   101/  209] train: loss: 0.0606589
[Epoch 72; Iter   131/  209] train: loss: 0.0815951
[Epoch 72; Iter   161/  209] train: loss: 0.0492517
[Epoch 72; Iter   191/  209] train: loss: 0.1060614
[Epoch 72] ogbg-moltox21: 0.838020 val loss: 0.263911
[Epoch 72] ogbg-moltox21: 0.826544 test loss: 0.252334
[Epoch 73; Iter    12/  209] train: loss: 0.0691419
[Epoch 73; Iter    42/  209] train: loss: 0.0567874
[Epoch 73; Iter    72/  209] train: loss: 0.0733780
[Epoch 73; Iter   102/  209] train: loss: 0.0780792
[Epoch 73; Iter   132/  209] train: loss: 0.0586460
[Epoch 73; Iter   162/  209] train: loss: 0.0656405
[Epoch 73; Iter   192/  209] train: loss: 0.0969600
[Epoch 73] ogbg-moltox21: 0.841513 val loss: 0.267852
[Epoch 73] ogbg-moltox21: 0.825075 test loss: 0.253998
[Epoch 74; Iter    13/  209] train: loss: 0.0493653
[Epoch 74; Iter    43/  209] train: loss: 0.1148600
[Epoch 74; Iter    73/  209] train: loss: 0.0482784
[Epoch 74; Iter   103/  209] train: loss: 0.0567725
[Epoch 74; Iter   133/  209] train: loss: 0.0998280
[Epoch 74; Iter   163/  209] train: loss: 0.0728622
[Epoch 74; Iter   193/  209] train: loss: 0.0713032
[Epoch 74] ogbg-moltox21: 0.843621 val loss: 0.268460
[Epoch 74] ogbg-moltox21: 0.822151 test loss: 0.252159
[Epoch 75; Iter    14/  209] train: loss: 0.0985743
[Epoch 75; Iter    44/  209] train: loss: 0.0545719
[Epoch 75; Iter    74/  209] train: loss: 0.0629510
[Epoch 75; Iter   104/  209] train: loss: 0.0697158
[Epoch 75; Iter   134/  209] train: loss: 0.0613449
[Epoch 75; Iter   164/  209] train: loss: 0.0878542
[Epoch 75; Iter   194/  209] train: loss: 0.0675141
[Epoch 75] ogbg-moltox21: 0.831625 val loss: 0.282270
[Epoch 75] ogbg-moltox21: 0.821399 test loss: 0.256279
[Epoch 76; Iter    15/  209] train: loss: 0.1130101
[Epoch 76; Iter    45/  209] train: loss: 0.0706308
[Epoch 76; Iter    75/  209] train: loss: 0.0666933
[Epoch 76; Iter   105/  209] train: loss: 0.0610090
[Epoch 76; Iter   135/  209] train: loss: 0.0560501
[Epoch 76; Iter   165/  209] train: loss: 0.0725664
[Epoch 76; Iter   195/  209] train: loss: 0.0874380
[Epoch 76] ogbg-moltox21: 0.841438 val loss: 0.286803
[Epoch 76] ogbg-moltox21: 0.823414 test loss: 0.257236
[Epoch 77; Iter    16/  209] train: loss: 0.1032876
[Epoch 77; Iter    46/  209] train: loss: 0.0923224
[Epoch 77; Iter    76/  209] train: loss: 0.0383418
[Epoch 77; Iter   106/  209] train: loss: 0.0670036
[Epoch 77; Iter   136/  209] train: loss: 0.0502174
[Epoch 77; Iter   166/  209] train: loss: 0.0794291
[Epoch 77; Iter   196/  209] train: loss: 0.0383703
[Epoch 77] ogbg-moltox21: 0.830422 val loss: 0.275623
[Epoch 77] ogbg-moltox21: 0.820422 test loss: 0.257101
[Epoch 78; Iter    17/  209] train: loss: 0.1308356
[Epoch 78; Iter    47/  209] train: loss: 0.0611955
[Epoch 78; Iter    77/  209] train: loss: 0.0891546
[Epoch 78; Iter   107/  209] train: loss: 0.0422383
[Epoch 78; Iter   137/  209] train: loss: 0.0688885
[Epoch 78; Iter   167/  209] train: loss: 0.1071426
[Epoch 78; Iter   197/  209] train: loss: 0.0690573
[Epoch 78] ogbg-moltox21: 0.840729 val loss: 0.273339
[Epoch 78] ogbg-moltox21: 0.822788 test loss: 0.249190
[Epoch 79; Iter    18/  209] train: loss: 0.0520222
[Epoch 79; Iter    48/  209] train: loss: 0.0707306
[Epoch 79; Iter    78/  209] train: loss: 0.1307510
[Epoch 79; Iter   108/  209] train: loss: 0.0653137
[Epoch 79; Iter   138/  209] train: loss: 0.0618437
[Epoch 79; Iter   168/  209] train: loss: 0.0753497
[Epoch 79; Iter   198/  209] train: loss: 0.0564131
[Epoch 79] ogbg-moltox21: 0.838810 val loss: 0.281940
[Epoch 79] ogbg-moltox21: 0.822586 test loss: 0.259510
[Epoch 80; Iter    19/  209] train: loss: 0.0912780
[Epoch 80; Iter    49/  209] train: loss: 0.0686916
[Epoch 80; Iter    79/  209] train: loss: 0.0682106
[Epoch 80; Iter   109/  209] train: loss: 0.0519331
[Epoch 80; Iter   139/  209] train: loss: 0.0412168
[Epoch 80; Iter   169/  209] train: loss: 0.0517873
[Epoch 80; Iter   199/  209] train: loss: 0.0510396
[Epoch 80] ogbg-moltox21: 0.837239 val loss: 0.280114
[Epoch 80] ogbg-moltox21: 0.818839 test loss: 0.258822
[Epoch 81; Iter    20/  209] train: loss: 0.0613907
[Epoch 81; Iter    50/  209] train: loss: 0.0728930
[Epoch 81; Iter    80/  209] train: loss: 0.0570408
[Epoch 81; Iter   110/  209] train: loss: 0.0744259
[Epoch 81; Iter   140/  209] train: loss: 0.0698528
[Epoch 81; Iter   170/  209] train: loss: 0.0972040
[Epoch 81; Iter   200/  209] train: loss: 0.0743073
[Epoch 81] ogbg-moltox21: 0.837463 val loss: 0.285566
[Epoch 81] ogbg-moltox21: 0.809818 test loss: 0.270338
[Epoch 82; Iter    21/  209] train: loss: 0.0635727
[Epoch 71; Iter   180/  183] train: loss: 0.0893302
[Epoch 71] ogbg-moltox21: 0.820963 val loss: 0.222018
[Epoch 71] ogbg-moltox21: 0.831929 test loss: 0.218717
[Epoch 72; Iter    27/  183] train: loss: 0.0639424
[Epoch 72; Iter    57/  183] train: loss: 0.1319070
[Epoch 72; Iter    87/  183] train: loss: 0.1190946
[Epoch 72; Iter   117/  183] train: loss: 0.0598144
[Epoch 72; Iter   147/  183] train: loss: 0.1668035
[Epoch 72; Iter   177/  183] train: loss: 0.1057584
[Epoch 72] ogbg-moltox21: 0.820266 val loss: 0.222426
[Epoch 72] ogbg-moltox21: 0.830236 test loss: 0.221437
[Epoch 73; Iter    24/  183] train: loss: 0.0885987
[Epoch 73; Iter    54/  183] train: loss: 0.0808749
[Epoch 73; Iter    84/  183] train: loss: 0.1122503
[Epoch 73; Iter   114/  183] train: loss: 0.0796798
[Epoch 73; Iter   144/  183] train: loss: 0.0963676
[Epoch 73; Iter   174/  183] train: loss: 0.0948112
[Epoch 73] ogbg-moltox21: 0.820762 val loss: 0.226122
[Epoch 73] ogbg-moltox21: 0.830947 test loss: 0.221869
[Epoch 74; Iter    21/  183] train: loss: 0.0952694
[Epoch 74; Iter    51/  183] train: loss: 0.0801513
[Epoch 74; Iter    81/  183] train: loss: 0.0514695
[Epoch 74; Iter   111/  183] train: loss: 0.1398257
[Epoch 74; Iter   141/  183] train: loss: 0.0910041
[Epoch 74; Iter   171/  183] train: loss: 0.0883466
[Epoch 74] ogbg-moltox21: 0.820336 val loss: 0.227052
[Epoch 74] ogbg-moltox21: 0.834659 test loss: 0.219525
[Epoch 75; Iter    18/  183] train: loss: 0.0784763
[Epoch 75; Iter    48/  183] train: loss: 0.0795079
[Epoch 75; Iter    78/  183] train: loss: 0.0955567
[Epoch 75; Iter   108/  183] train: loss: 0.1040726
[Epoch 75; Iter   138/  183] train: loss: 0.2144842
[Epoch 75; Iter   168/  183] train: loss: 0.0980842
[Epoch 75] ogbg-moltox21: 0.822449 val loss: 0.229487
[Epoch 75] ogbg-moltox21: 0.829166 test loss: 0.228060
[Epoch 76; Iter    15/  183] train: loss: 0.0748853
[Epoch 76; Iter    45/  183] train: loss: 0.0750041
[Epoch 76; Iter    75/  183] train: loss: 0.1017010
[Epoch 76; Iter   105/  183] train: loss: 0.0499012
[Epoch 76; Iter   135/  183] train: loss: 0.0754152
[Epoch 76; Iter   165/  183] train: loss: 0.1291634
[Epoch 76] ogbg-moltox21: 0.821166 val loss: 0.231497
[Epoch 76] ogbg-moltox21: 0.829129 test loss: 0.229263
[Epoch 77; Iter    12/  183] train: loss: 0.0624794
[Epoch 77; Iter    42/  183] train: loss: 0.0864000
[Epoch 77; Iter    72/  183] train: loss: 0.0552180
[Epoch 77; Iter   102/  183] train: loss: 0.0925836
[Epoch 77; Iter   132/  183] train: loss: 0.1352273
[Epoch 77; Iter   162/  183] train: loss: 0.0566214
[Epoch 77] ogbg-moltox21: 0.815944 val loss: 0.233036
[Epoch 77] ogbg-moltox21: 0.826991 test loss: 0.230990
[Epoch 78; Iter     9/  183] train: loss: 0.0678600
[Epoch 78; Iter    39/  183] train: loss: 0.0836118
[Epoch 78; Iter    69/  183] train: loss: 0.0821661
[Epoch 78; Iter    99/  183] train: loss: 0.0882705
[Epoch 78; Iter   129/  183] train: loss: 0.0961266
[Epoch 78; Iter   159/  183] train: loss: 0.1003827
[Epoch 78] ogbg-moltox21: 0.816257 val loss: 0.234091
[Epoch 78] ogbg-moltox21: 0.829054 test loss: 0.231540
[Epoch 79; Iter     6/  183] train: loss: 0.0901389
[Epoch 79; Iter    36/  183] train: loss: 0.1145538
[Epoch 79; Iter    66/  183] train: loss: 0.1086863
[Epoch 79; Iter    96/  183] train: loss: 0.1025796
[Epoch 79; Iter   126/  183] train: loss: 0.0778782
[Epoch 79; Iter   156/  183] train: loss: 0.1079249
[Epoch 79] ogbg-moltox21: 0.808774 val loss: 0.234325
[Epoch 79] ogbg-moltox21: 0.820252 test loss: 0.235974
[Epoch 80; Iter     3/  183] train: loss: 0.0814113
[Epoch 80; Iter    33/  183] train: loss: 0.0432674
[Epoch 80; Iter    63/  183] train: loss: 0.0566193
[Epoch 80; Iter    93/  183] train: loss: 0.0600085
[Epoch 80; Iter   123/  183] train: loss: 0.0724449
[Epoch 80; Iter   153/  183] train: loss: 0.1168403
[Epoch 80; Iter   183/  183] train: loss: 0.0584017
[Epoch 80] ogbg-moltox21: 0.814501 val loss: 0.237961
[Epoch 80] ogbg-moltox21: 0.826970 test loss: 0.231368
[Epoch 81; Iter    30/  183] train: loss: 0.0731123
[Epoch 81; Iter    60/  183] train: loss: 0.0815330
[Epoch 81; Iter    90/  183] train: loss: 0.0710395
[Epoch 81; Iter   120/  183] train: loss: 0.0641600
[Epoch 81; Iter   150/  183] train: loss: 0.0882844
[Epoch 81; Iter   180/  183] train: loss: 0.1095945
[Epoch 81] ogbg-moltox21: 0.808001 val loss: 0.239164
[Epoch 81] ogbg-moltox21: 0.824318 test loss: 0.234440
[Epoch 82; Iter    27/  183] train: loss: 0.0836100
[Epoch 82; Iter    57/  183] train: loss: 0.0573011
[Epoch 82; Iter    87/  183] train: loss: 0.0699739
[Epoch 82; Iter   117/  183] train: loss: 0.0923582
[Epoch 82; Iter   147/  183] train: loss: 0.1131648
[Epoch 82; Iter   177/  183] train: loss: 0.0501064
[Epoch 82] ogbg-moltox21: 0.818360 val loss: 0.237460
[Epoch 82] ogbg-moltox21: 0.829750 test loss: 0.236237
[Epoch 83; Iter    24/  183] train: loss: 0.0811048
[Epoch 83; Iter    54/  183] train: loss: 0.0659584
[Epoch 83; Iter    84/  183] train: loss: 0.0829922
[Epoch 83; Iter   114/  183] train: loss: 0.0582920
[Epoch 83; Iter   144/  183] train: loss: 0.0640193
[Epoch 83; Iter   174/  183] train: loss: 0.0352713
[Epoch 83] ogbg-moltox21: 0.814392 val loss: 0.239178
[Epoch 83] ogbg-moltox21: 0.827531 test loss: 0.245181
[Epoch 84; Iter    21/  183] train: loss: 0.0552606
[Epoch 84; Iter    51/  183] train: loss: 0.0829354
[Epoch 84; Iter    81/  183] train: loss: 0.0904348
[Epoch 84; Iter   111/  183] train: loss: 0.0903410
[Epoch 84; Iter   141/  183] train: loss: 0.1346584
[Epoch 84; Iter   171/  183] train: loss: 0.1420035
[Epoch 84] ogbg-moltox21: 0.810134 val loss: 0.242752
[Epoch 84] ogbg-moltox21: 0.823532 test loss: 0.240408
[Epoch 85; Iter    18/  183] train: loss: 0.0837026
[Epoch 85; Iter    48/  183] train: loss: 0.0946522
[Epoch 85; Iter    78/  183] train: loss: 0.1223290
[Epoch 85; Iter   108/  183] train: loss: 0.1047332
[Epoch 85; Iter   138/  183] train: loss: 0.0895838
[Epoch 85; Iter   168/  183] train: loss: 0.0447491
[Epoch 85] ogbg-moltox21: 0.808583 val loss: 0.244782
[Epoch 85] ogbg-moltox21: 0.821962 test loss: 0.244249
[Epoch 86; Iter    15/  183] train: loss: 0.0595157
[Epoch 86; Iter    45/  183] train: loss: 0.0517065
[Epoch 86; Iter    75/  183] train: loss: 0.0898452
[Epoch 86; Iter   105/  183] train: loss: 0.0962273
[Epoch 86; Iter   135/  183] train: loss: 0.0862469
[Epoch 86; Iter   165/  183] train: loss: 0.0439676
[Epoch 86] ogbg-moltox21: 0.806352 val loss: 0.252277
[Epoch 86] ogbg-moltox21: 0.819530 test loss: 0.246836
[Epoch 87; Iter    12/  183] train: loss: 0.0773934
[Epoch 87; Iter    42/  183] train: loss: 0.0551458
[Epoch 87; Iter    72/  183] train: loss: 0.1404892
[Epoch 87; Iter   102/  183] train: loss: 0.0370931
[Epoch 87; Iter   132/  183] train: loss: 0.0704459
[Epoch 87; Iter   162/  183] train: loss: 0.0628690
[Epoch 87] ogbg-moltox21: 0.804803 val loss: 0.247093
[Epoch 87] ogbg-moltox21: 0.820401 test loss: 0.242900
[Epoch 88; Iter     9/  183] train: loss: 0.1069443
[Epoch 88; Iter    39/  183] train: loss: 0.1067352
[Epoch 88; Iter    69/  183] train: loss: 0.0389667
[Epoch 88; Iter    99/  183] train: loss: 0.0524488
[Epoch 88; Iter   129/  183] train: loss: 0.0945352
[Epoch 88; Iter   159/  183] train: loss: 0.0379219
[Epoch 88] ogbg-moltox21: 0.809492 val loss: 0.250243
[Epoch 88] ogbg-moltox21: 0.828610 test loss: 0.242604
[Epoch 89; Iter     6/  183] train: loss: 0.0717331
[Epoch 89; Iter    36/  183] train: loss: 0.0686065
[Epoch 89; Iter    66/  183] train: loss: 0.0881688
[Epoch 89; Iter    96/  183] train: loss: 0.0650265
[Epoch 89; Iter   126/  183] train: loss: 0.0558561
[Epoch 89; Iter   156/  183] train: loss: 0.1185269
[Epoch 89] ogbg-moltox21: 0.809784 val loss: 0.247147
[Epoch 89] ogbg-moltox21: 0.825187 test loss: 0.249129
[Epoch 90; Iter     3/  183] train: loss: 0.0692556
[Epoch 90; Iter    33/  183] train: loss: 0.0594068
[Epoch 90; Iter    63/  183] train: loss: 0.0922411
[Epoch 90; Iter    93/  183] train: loss: 0.0753063
[Epoch 90; Iter   123/  183] train: loss: 0.0602047
[Epoch 90; Iter   153/  183] train: loss: 0.0457985
[Epoch 90; Iter   183/  183] train: loss: 0.0983876
[Epoch 71; Iter   180/  183] train: loss: 0.0952774
[Epoch 71] ogbg-moltox21: 0.826316 val loss: 0.204992
[Epoch 71] ogbg-moltox21: 0.848779 test loss: 0.202063
[Epoch 72; Iter    27/  183] train: loss: 0.1330642
[Epoch 72; Iter    57/  183] train: loss: 0.1022780
[Epoch 72; Iter    87/  183] train: loss: 0.1247191
[Epoch 72; Iter   117/  183] train: loss: 0.1210059
[Epoch 72; Iter   147/  183] train: loss: 0.1321358
[Epoch 72; Iter   177/  183] train: loss: 0.0977113
[Epoch 72] ogbg-moltox21: 0.822104 val loss: 0.208242
[Epoch 72] ogbg-moltox21: 0.841458 test loss: 0.205394
[Epoch 73; Iter    24/  183] train: loss: 0.1243648
[Epoch 73; Iter    54/  183] train: loss: 0.1149905
[Epoch 73; Iter    84/  183] train: loss: 0.0944468
[Epoch 73; Iter   114/  183] train: loss: 0.1317304
[Epoch 73; Iter   144/  183] train: loss: 0.0843088
[Epoch 73; Iter   174/  183] train: loss: 0.1044044
[Epoch 73] ogbg-moltox21: 0.820509 val loss: 0.207686
[Epoch 73] ogbg-moltox21: 0.840459 test loss: 0.210063
[Epoch 74; Iter    21/  183] train: loss: 0.0615078
[Epoch 74; Iter    51/  183] train: loss: 0.1048659
[Epoch 74; Iter    81/  183] train: loss: 0.1067653
[Epoch 74; Iter   111/  183] train: loss: 0.1512697
[Epoch 74; Iter   141/  183] train: loss: 0.1293344
[Epoch 74; Iter   171/  183] train: loss: 0.1384605
[Epoch 74] ogbg-moltox21: 0.813632 val loss: 0.214858
[Epoch 74] ogbg-moltox21: 0.832805 test loss: 0.215947
[Epoch 75; Iter    18/  183] train: loss: 0.1358254
[Epoch 75; Iter    48/  183] train: loss: 0.0993425
[Epoch 75; Iter    78/  183] train: loss: 0.1119223
[Epoch 75; Iter   108/  183] train: loss: 0.0750120
[Epoch 75; Iter   138/  183] train: loss: 0.1051215
[Epoch 75; Iter   168/  183] train: loss: 0.1217902
[Epoch 75] ogbg-moltox21: 0.821723 val loss: 0.210876
[Epoch 75] ogbg-moltox21: 0.840962 test loss: 0.210072
[Epoch 76; Iter    15/  183] train: loss: 0.0640897
[Epoch 76; Iter    45/  183] train: loss: 0.1120220
[Epoch 76; Iter    75/  183] train: loss: 0.1165310
[Epoch 76; Iter   105/  183] train: loss: 0.0760195
[Epoch 76; Iter   135/  183] train: loss: 0.1030930
[Epoch 76; Iter   165/  183] train: loss: 0.0754671
[Epoch 76] ogbg-moltox21: 0.824235 val loss: 0.210597
[Epoch 76] ogbg-moltox21: 0.838067 test loss: 0.214525
[Epoch 77; Iter    12/  183] train: loss: 0.1186680
[Epoch 77; Iter    42/  183] train: loss: 0.1132574
[Epoch 77; Iter    72/  183] train: loss: 0.0929138
[Epoch 77; Iter   102/  183] train: loss: 0.1066261
[Epoch 77; Iter   132/  183] train: loss: 0.0979795
[Epoch 77; Iter   162/  183] train: loss: 0.1542835
[Epoch 77] ogbg-moltox21: 0.817676 val loss: 0.212755
[Epoch 77] ogbg-moltox21: 0.839811 test loss: 0.208874
[Epoch 78; Iter     9/  183] train: loss: 0.1073740
[Epoch 78; Iter    39/  183] train: loss: 0.0725115
[Epoch 78; Iter    69/  183] train: loss: 0.1231582
[Epoch 78; Iter    99/  183] train: loss: 0.0937709
[Epoch 78; Iter   129/  183] train: loss: 0.1166246
[Epoch 78; Iter   159/  183] train: loss: 0.1022388
[Epoch 78] ogbg-moltox21: 0.818236 val loss: 0.217855
[Epoch 78] ogbg-moltox21: 0.837331 test loss: 0.217560
[Epoch 79; Iter     6/  183] train: loss: 0.0662606
[Epoch 79; Iter    36/  183] train: loss: 0.0804920
[Epoch 79; Iter    66/  183] train: loss: 0.0830820
[Epoch 79; Iter    96/  183] train: loss: 0.0790022
[Epoch 79; Iter   126/  183] train: loss: 0.0864476
[Epoch 79; Iter   156/  183] train: loss: 0.0837480
[Epoch 79] ogbg-moltox21: 0.816898 val loss: 0.215653
[Epoch 79] ogbg-moltox21: 0.840121 test loss: 0.215229
[Epoch 80; Iter     3/  183] train: loss: 0.1085479
[Epoch 80; Iter    33/  183] train: loss: 0.1084206
[Epoch 80; Iter    63/  183] train: loss: 0.0954129
[Epoch 80; Iter    93/  183] train: loss: 0.1152713
[Epoch 80; Iter   123/  183] train: loss: 0.0978649
[Epoch 80; Iter   153/  183] train: loss: 0.1237007
[Epoch 80; Iter   183/  183] train: loss: 0.0486507
[Epoch 80] ogbg-moltox21: 0.816468 val loss: 0.217743
[Epoch 80] ogbg-moltox21: 0.834732 test loss: 0.213685
[Epoch 81; Iter    30/  183] train: loss: 0.1105764
[Epoch 81; Iter    60/  183] train: loss: 0.1320532
[Epoch 81; Iter    90/  183] train: loss: 0.1471273
[Epoch 81; Iter   120/  183] train: loss: 0.1149946
[Epoch 81; Iter   150/  183] train: loss: 0.0883720
[Epoch 81; Iter   180/  183] train: loss: 0.1200454
[Epoch 81] ogbg-moltox21: 0.818582 val loss: 0.222154
[Epoch 81] ogbg-moltox21: 0.836163 test loss: 0.221236
[Epoch 82; Iter    27/  183] train: loss: 0.1082893
[Epoch 82; Iter    57/  183] train: loss: 0.1581363
[Epoch 82; Iter    87/  183] train: loss: 0.1313852
[Epoch 82; Iter   117/  183] train: loss: 0.0721600
[Epoch 82; Iter   147/  183] train: loss: 0.0704246
[Epoch 82; Iter   177/  183] train: loss: 0.0836098
[Epoch 82] ogbg-moltox21: 0.814485 val loss: 0.279457
[Epoch 82] ogbg-moltox21: 0.833190 test loss: 0.223522
[Epoch 83; Iter    24/  183] train: loss: 0.1379503
[Epoch 83; Iter    54/  183] train: loss: 0.0911165
[Epoch 83; Iter    84/  183] train: loss: 0.0886593
[Epoch 83; Iter   114/  183] train: loss: 0.0824930
[Epoch 83; Iter   144/  183] train: loss: 0.1377661
[Epoch 83; Iter   174/  183] train: loss: 0.1241340
[Epoch 83] ogbg-moltox21: 0.818304 val loss: 0.220982
[Epoch 83] ogbg-moltox21: 0.838618 test loss: 0.220750
[Epoch 84; Iter    21/  183] train: loss: 0.0609908
[Epoch 84; Iter    51/  183] train: loss: 0.1009177
[Epoch 84; Iter    81/  183] train: loss: 0.0571498
[Epoch 84; Iter   111/  183] train: loss: 0.0949083
[Epoch 84; Iter   141/  183] train: loss: 0.0892962
[Epoch 84; Iter   171/  183] train: loss: 0.1093811
[Epoch 84] ogbg-moltox21: 0.814340 val loss: 0.226490
[Epoch 84] ogbg-moltox21: 0.828026 test loss: 0.231998
[Epoch 85; Iter    18/  183] train: loss: 0.0707726
[Epoch 85; Iter    48/  183] train: loss: 0.0935684
[Epoch 85; Iter    78/  183] train: loss: 0.1004611
[Epoch 85; Iter   108/  183] train: loss: 0.1039059
[Epoch 85; Iter   138/  183] train: loss: 0.1056775
[Epoch 85; Iter   168/  183] train: loss: 0.0850257
[Epoch 85] ogbg-moltox21: 0.819958 val loss: 0.219659
[Epoch 85] ogbg-moltox21: 0.832896 test loss: 0.220218
[Epoch 86; Iter    15/  183] train: loss: 0.0937604
[Epoch 86; Iter    45/  183] train: loss: 0.0743598
[Epoch 86; Iter    75/  183] train: loss: 0.0736114
[Epoch 86; Iter   105/  183] train: loss: 0.1486736
[Epoch 86; Iter   135/  183] train: loss: 0.0938112
[Epoch 86; Iter   165/  183] train: loss: 0.1719199
[Epoch 86] ogbg-moltox21: 0.812110 val loss: 0.226623
[Epoch 86] ogbg-moltox21: 0.829621 test loss: 0.226661
[Epoch 87; Iter    12/  183] train: loss: 0.0920122
[Epoch 87; Iter    42/  183] train: loss: 0.0909418
[Epoch 87; Iter    72/  183] train: loss: 0.1551869
[Epoch 87; Iter   102/  183] train: loss: 0.0931328
[Epoch 87; Iter   132/  183] train: loss: 0.0920691
[Epoch 87; Iter   162/  183] train: loss: 0.1566909
[Epoch 87] ogbg-moltox21: 0.811285 val loss: 0.222948
[Epoch 87] ogbg-moltox21: 0.828900 test loss: 0.229055
[Epoch 88; Iter     9/  183] train: loss: 0.1103929
[Epoch 88; Iter    39/  183] train: loss: 0.0617695
[Epoch 88; Iter    69/  183] train: loss: 0.1912971
[Epoch 88; Iter    99/  183] train: loss: 0.1044890
[Epoch 88; Iter   129/  183] train: loss: 0.1258250
[Epoch 88; Iter   159/  183] train: loss: 0.0654422
[Epoch 88] ogbg-moltox21: 0.814970 val loss: 0.231165
[Epoch 88] ogbg-moltox21: 0.828746 test loss: 0.229030
[Epoch 89; Iter     6/  183] train: loss: 0.1235449
[Epoch 89; Iter    36/  183] train: loss: 0.0784075
[Epoch 89; Iter    66/  183] train: loss: 0.0660410
[Epoch 89; Iter    96/  183] train: loss: 0.0825964
[Epoch 89; Iter   126/  183] train: loss: 0.0789158
[Epoch 89; Iter   156/  183] train: loss: 0.1361555
[Epoch 89] ogbg-moltox21: 0.815302 val loss: 0.231025
[Epoch 89] ogbg-moltox21: 0.836555 test loss: 0.232422
[Epoch 90; Iter     3/  183] train: loss: 0.0971139
[Epoch 90; Iter    33/  183] train: loss: 0.0864551
[Epoch 90; Iter    63/  183] train: loss: 0.1158227
[Epoch 90; Iter    93/  183] train: loss: 0.1002205
[Epoch 90; Iter   123/  183] train: loss: 0.0760373
[Epoch 90; Iter   153/  183] train: loss: 0.0946421
[Epoch 90; Iter   183/  183] train: loss: 0.1364294
[Epoch 71; Iter   180/  183] train: loss: 0.0734880
[Epoch 71] ogbg-moltox21: 0.818673 val loss: 0.241921
[Epoch 71] ogbg-moltox21: 0.825955 test loss: 0.238639
[Epoch 72; Iter    27/  183] train: loss: 0.0507198
[Epoch 72; Iter    57/  183] train: loss: 0.0998678
[Epoch 72; Iter    87/  183] train: loss: 0.0652581
[Epoch 72; Iter   117/  183] train: loss: 0.0678880
[Epoch 72; Iter   147/  183] train: loss: 0.0431770
[Epoch 72; Iter   177/  183] train: loss: 0.0527491
[Epoch 72] ogbg-moltox21: 0.824853 val loss: 0.246411
[Epoch 72] ogbg-moltox21: 0.825678 test loss: 0.246845
[Epoch 73; Iter    24/  183] train: loss: 0.0585181
[Epoch 73; Iter    54/  183] train: loss: 0.0669356
[Epoch 73; Iter    84/  183] train: loss: 0.0792765
[Epoch 73; Iter   114/  183] train: loss: 0.1226316
[Epoch 73; Iter   144/  183] train: loss: 0.0614739
[Epoch 73; Iter   174/  183] train: loss: 0.0332728
[Epoch 73] ogbg-moltox21: 0.815647 val loss: 0.247980
[Epoch 73] ogbg-moltox21: 0.825396 test loss: 0.250986
[Epoch 74; Iter    21/  183] train: loss: 0.0743036
[Epoch 74; Iter    51/  183] train: loss: 0.0872010
[Epoch 74; Iter    81/  183] train: loss: 0.0561805
[Epoch 74; Iter   111/  183] train: loss: 0.0599124
[Epoch 74; Iter   141/  183] train: loss: 0.0250039
[Epoch 74; Iter   171/  183] train: loss: 0.0756594
[Epoch 74] ogbg-moltox21: 0.821089 val loss: 0.252840
[Epoch 74] ogbg-moltox21: 0.834833 test loss: 0.243776
[Epoch 75; Iter    18/  183] train: loss: 0.0819810
[Epoch 75; Iter    48/  183] train: loss: 0.0775138
[Epoch 75; Iter    78/  183] train: loss: 0.0997406
[Epoch 75; Iter   108/  183] train: loss: 0.0713122
[Epoch 75; Iter   138/  183] train: loss: 0.0592972
[Epoch 75; Iter   168/  183] train: loss: 0.0764376
[Epoch 75] ogbg-moltox21: 0.821864 val loss: 0.245911
[Epoch 75] ogbg-moltox21: 0.830807 test loss: 0.248775
[Epoch 76; Iter    15/  183] train: loss: 0.0902836
[Epoch 76; Iter    45/  183] train: loss: 0.0562435
[Epoch 76; Iter    75/  183] train: loss: 0.0977412
[Epoch 76; Iter   105/  183] train: loss: 0.0645239
[Epoch 76; Iter   135/  183] train: loss: 0.0508429
[Epoch 76; Iter   165/  183] train: loss: 0.0656455
[Epoch 76] ogbg-moltox21: 0.817878 val loss: 0.249987
[Epoch 76] ogbg-moltox21: 0.825803 test loss: 0.255800
[Epoch 77; Iter    12/  183] train: loss: 0.0657702
[Epoch 77; Iter    42/  183] train: loss: 0.1052332
[Epoch 77; Iter    72/  183] train: loss: 0.0650644
[Epoch 77; Iter   102/  183] train: loss: 0.0725840
[Epoch 77; Iter   132/  183] train: loss: 0.0519777
[Epoch 77; Iter   162/  183] train: loss: 0.0835229
[Epoch 77] ogbg-moltox21: 0.813301 val loss: 0.257006
[Epoch 77] ogbg-moltox21: 0.823093 test loss: 0.254583
[Epoch 78; Iter     9/  183] train: loss: 0.1048147
[Epoch 78; Iter    39/  183] train: loss: 0.0896311
[Epoch 78; Iter    69/  183] train: loss: 0.0937353
[Epoch 78; Iter    99/  183] train: loss: 0.0466578
[Epoch 78; Iter   129/  183] train: loss: 0.0816878
[Epoch 78; Iter   159/  183] train: loss: 0.0657645
[Epoch 78] ogbg-moltox21: 0.819113 val loss: 0.251599
[Epoch 78] ogbg-moltox21: 0.821620 test loss: 0.258261
[Epoch 79; Iter     6/  183] train: loss: 0.0635624
[Epoch 79; Iter    36/  183] train: loss: 0.0722656
[Epoch 79; Iter    66/  183] train: loss: 0.0739625
[Epoch 79; Iter    96/  183] train: loss: 0.0685150
[Epoch 79; Iter   126/  183] train: loss: 0.0964295
[Epoch 79; Iter   156/  183] train: loss: 0.1042748
[Epoch 79] ogbg-moltox21: 0.816879 val loss: 0.262150
[Epoch 79] ogbg-moltox21: 0.822960 test loss: 0.260457
[Epoch 80; Iter     3/  183] train: loss: 0.0700958
[Epoch 80; Iter    33/  183] train: loss: 0.0308044
[Epoch 80; Iter    63/  183] train: loss: 0.0752269
[Epoch 80; Iter    93/  183] train: loss: 0.0663874
[Epoch 80; Iter   123/  183] train: loss: 0.0474636
[Epoch 80; Iter   153/  183] train: loss: 0.0843634
[Epoch 80; Iter   183/  183] train: loss: 0.0855315
[Epoch 80] ogbg-moltox21: 0.824635 val loss: 0.253090
[Epoch 80] ogbg-moltox21: 0.826794 test loss: 0.261967
[Epoch 81; Iter    30/  183] train: loss: 0.0481898
[Epoch 81; Iter    60/  183] train: loss: 0.0748340
[Epoch 81; Iter    90/  183] train: loss: 0.1074949
[Epoch 81; Iter   120/  183] train: loss: 0.0686653
[Epoch 81; Iter   150/  183] train: loss: 0.0567438
[Epoch 81; Iter   180/  183] train: loss: 0.0697532
[Epoch 81] ogbg-moltox21: 0.819770 val loss: 0.252085
[Epoch 81] ogbg-moltox21: 0.820086 test loss: 0.266464
[Epoch 82; Iter    27/  183] train: loss: 0.0590279
[Epoch 82; Iter    57/  183] train: loss: 0.0446472
[Epoch 82; Iter    87/  183] train: loss: 0.0509220
[Epoch 82; Iter   117/  183] train: loss: 0.0929644
[Epoch 82; Iter   147/  183] train: loss: 0.0867586
[Epoch 82; Iter   177/  183] train: loss: 0.0433603
[Epoch 82] ogbg-moltox21: 0.817120 val loss: 0.258593
[Epoch 82] ogbg-moltox21: 0.817647 test loss: 0.270418
[Epoch 83; Iter    24/  183] train: loss: 0.0512196
[Epoch 83; Iter    54/  183] train: loss: 0.0673098
[Epoch 83; Iter    84/  183] train: loss: 0.0520353
[Epoch 83; Iter   114/  183] train: loss: 0.0451865
[Epoch 83; Iter   144/  183] train: loss: 0.0685067
[Epoch 83; Iter   174/  183] train: loss: 0.0905424
[Epoch 83] ogbg-moltox21: 0.809150 val loss: 0.262462
[Epoch 83] ogbg-moltox21: 0.815203 test loss: 0.270318
[Epoch 84; Iter    21/  183] train: loss: 0.0692532
[Epoch 84; Iter    51/  183] train: loss: 0.0616830
[Epoch 84; Iter    81/  183] train: loss: 0.0709829
[Epoch 84; Iter   111/  183] train: loss: 0.0690443
[Epoch 84; Iter   141/  183] train: loss: 0.0937261
[Epoch 84; Iter   171/  183] train: loss: 0.0949501
[Epoch 84] ogbg-moltox21: 0.820053 val loss: 0.264246
[Epoch 84] ogbg-moltox21: 0.827507 test loss: 0.273652
[Epoch 85; Iter    18/  183] train: loss: 0.0964418
[Epoch 85; Iter    48/  183] train: loss: 0.0577889
[Epoch 85; Iter    78/  183] train: loss: 0.0732690
[Epoch 85; Iter   108/  183] train: loss: 0.0708569
[Epoch 85; Iter   138/  183] train: loss: 0.0828241
[Epoch 85; Iter   168/  183] train: loss: 0.0410054
[Epoch 85] ogbg-moltox21: 0.824429 val loss: 0.257774
[Epoch 85] ogbg-moltox21: 0.820439 test loss: 0.271390
[Epoch 86; Iter    15/  183] train: loss: 0.0602514
[Epoch 86; Iter    45/  183] train: loss: 0.0625562
[Epoch 86; Iter    75/  183] train: loss: 0.0511204
[Epoch 86; Iter   105/  183] train: loss: 0.0672732
[Epoch 86; Iter   135/  183] train: loss: 0.0501282
[Epoch 86; Iter   165/  183] train: loss: 0.0678487
[Epoch 86] ogbg-moltox21: 0.826770 val loss: 0.255391
[Epoch 86] ogbg-moltox21: 0.823088 test loss: 0.274002
[Epoch 87; Iter    12/  183] train: loss: 0.0870739
[Epoch 87; Iter    42/  183] train: loss: 0.0663236
[Epoch 87; Iter    72/  183] train: loss: 0.0403952
[Epoch 87; Iter   102/  183] train: loss: 0.0651897
[Epoch 87; Iter   132/  183] train: loss: 0.0658950
[Epoch 87; Iter   162/  183] train: loss: 0.0558120
[Epoch 87] ogbg-moltox21: 0.816613 val loss: 0.259686
[Epoch 87] ogbg-moltox21: 0.822712 test loss: 0.269667
[Epoch 88; Iter     9/  183] train: loss: 0.1079612
[Epoch 88; Iter    39/  183] train: loss: 0.0560675
[Epoch 88; Iter    69/  183] train: loss: 0.0525462
[Epoch 88; Iter    99/  183] train: loss: 0.0271988
[Epoch 88; Iter   129/  183] train: loss: 0.0656838
[Epoch 88; Iter   159/  183] train: loss: 0.0739265
[Epoch 88] ogbg-moltox21: 0.820446 val loss: 0.265846
[Epoch 88] ogbg-moltox21: 0.816349 test loss: 0.282404
[Epoch 89; Iter     6/  183] train: loss: 0.0401874
[Epoch 89; Iter    36/  183] train: loss: 0.0272027
[Epoch 89; Iter    66/  183] train: loss: 0.0646792
[Epoch 89; Iter    96/  183] train: loss: 0.0707601
[Epoch 89; Iter   126/  183] train: loss: 0.1140142
[Epoch 89; Iter   156/  183] train: loss: 0.0274321
[Epoch 89] ogbg-moltox21: 0.814552 val loss: 0.268738
[Epoch 89] ogbg-moltox21: 0.814653 test loss: 0.282141
[Epoch 90; Iter     3/  183] train: loss: 0.0214651
[Epoch 90; Iter    33/  183] train: loss: 0.0305150
[Epoch 90; Iter    63/  183] train: loss: 0.0608849
[Epoch 90; Iter    93/  183] train: loss: 0.0571376
[Epoch 90; Iter   123/  183] train: loss: 0.0783107
[Epoch 90; Iter   153/  183] train: loss: 0.0852412
[Epoch 90; Iter   183/  183] train: loss: 0.0339409
[Epoch 80; Iter    47/  157] train: loss: 0.0829011
[Epoch 80; Iter    77/  157] train: loss: 0.0820466
[Epoch 80; Iter   107/  157] train: loss: 0.0695287
[Epoch 80; Iter   137/  157] train: loss: 0.1090475
[Epoch 80] ogbg-moltox21: 0.820341 val loss: 0.217948
[Epoch 80] ogbg-moltox21: 0.815415 test loss: 0.237466
[Epoch 81; Iter    10/  157] train: loss: 0.1273498
[Epoch 81; Iter    40/  157] train: loss: 0.0967299
[Epoch 81; Iter    70/  157] train: loss: 0.1258983
[Epoch 81; Iter   100/  157] train: loss: 0.0846704
[Epoch 81; Iter   130/  157] train: loss: 0.0980298
[Epoch 81] ogbg-moltox21: 0.820102 val loss: 0.218728
[Epoch 81] ogbg-moltox21: 0.819694 test loss: 0.240253
[Epoch 82; Iter     3/  157] train: loss: 0.0452614
[Epoch 82; Iter    33/  157] train: loss: 0.0849101
[Epoch 82; Iter    63/  157] train: loss: 0.0858765
[Epoch 82; Iter    93/  157] train: loss: 0.1264636
[Epoch 82; Iter   123/  157] train: loss: 0.0894383
[Epoch 82; Iter   153/  157] train: loss: 0.0840902
[Epoch 82] ogbg-moltox21: 0.819486 val loss: 0.221214
[Epoch 82] ogbg-moltox21: 0.814021 test loss: 0.243308
[Epoch 83; Iter    26/  157] train: loss: 0.0899335
[Epoch 83; Iter    56/  157] train: loss: 0.0924633
[Epoch 83; Iter    86/  157] train: loss: 0.0536078
[Epoch 83; Iter   116/  157] train: loss: 0.1103039
[Epoch 83; Iter   146/  157] train: loss: 0.0768517
[Epoch 83] ogbg-moltox21: 0.819942 val loss: 0.220552
[Epoch 83] ogbg-moltox21: 0.815955 test loss: 0.240179
[Epoch 84; Iter    19/  157] train: loss: 0.0716555
[Epoch 84; Iter    49/  157] train: loss: 0.0505222
[Epoch 84; Iter    79/  157] train: loss: 0.0928955
[Epoch 84; Iter   109/  157] train: loss: 0.0955312
[Epoch 84; Iter   139/  157] train: loss: 0.0902858
[Epoch 84] ogbg-moltox21: 0.820407 val loss: 0.228489
[Epoch 84] ogbg-moltox21: 0.816817 test loss: 0.249788
[Epoch 85; Iter    12/  157] train: loss: 0.0723820
[Epoch 85; Iter    42/  157] train: loss: 0.1301496
[Epoch 85; Iter    72/  157] train: loss: 0.0736409
[Epoch 85; Iter   102/  157] train: loss: 0.0922039
[Epoch 85; Iter   132/  157] train: loss: 0.1801583
[Epoch 85] ogbg-moltox21: 0.818615 val loss: 0.224337
[Epoch 85] ogbg-moltox21: 0.816527 test loss: 0.246148
[Epoch 86; Iter     5/  157] train: loss: 0.0886512
[Epoch 86; Iter    35/  157] train: loss: 0.0644160
[Epoch 86; Iter    65/  157] train: loss: 0.0806718
[Epoch 86; Iter    95/  157] train: loss: 0.1034014
[Epoch 86; Iter   125/  157] train: loss: 0.0865871
[Epoch 86; Iter   155/  157] train: loss: 0.0684254
[Epoch 86] ogbg-moltox21: 0.818648 val loss: 0.223244
[Epoch 86] ogbg-moltox21: 0.818967 test loss: 0.238493
[Epoch 87; Iter    28/  157] train: loss: 0.0734325
[Epoch 87; Iter    58/  157] train: loss: 0.0700686
[Epoch 87; Iter    88/  157] train: loss: 0.0694799
[Epoch 87; Iter   118/  157] train: loss: 0.1000964
[Epoch 87; Iter   148/  157] train: loss: 0.0870901
[Epoch 87] ogbg-moltox21: 0.815486 val loss: 0.228978
[Epoch 87] ogbg-moltox21: 0.815133 test loss: 0.246251
[Epoch 88; Iter    21/  157] train: loss: 0.0682509
[Epoch 88; Iter    51/  157] train: loss: 0.0745993
[Epoch 88; Iter    81/  157] train: loss: 0.0982777
[Epoch 88; Iter   111/  157] train: loss: 0.0528262
[Epoch 88; Iter   141/  157] train: loss: 0.0843482
[Epoch 88] ogbg-moltox21: 0.815562 val loss: 0.228861
[Epoch 88] ogbg-moltox21: 0.818487 test loss: 0.246266
[Epoch 89; Iter    14/  157] train: loss: 0.0589045
[Epoch 89; Iter    44/  157] train: loss: 0.1366605
[Epoch 89; Iter    74/  157] train: loss: 0.1060699
[Epoch 89; Iter   104/  157] train: loss: 0.0479099
[Epoch 89; Iter   134/  157] train: loss: 0.0780412
[Epoch 89] ogbg-moltox21: 0.820079 val loss: 0.225482
[Epoch 89] ogbg-moltox21: 0.821412 test loss: 0.244760
[Epoch 90; Iter     7/  157] train: loss: 0.0840129
[Epoch 90; Iter    37/  157] train: loss: 0.0649966
[Epoch 90; Iter    67/  157] train: loss: 0.0634278
[Epoch 90; Iter    97/  157] train: loss: 0.0755146
[Epoch 90; Iter   127/  157] train: loss: 0.0782242
[Epoch 90; Iter   157/  157] train: loss: 0.0308905
[Epoch 90] ogbg-moltox21: 0.821963 val loss: 0.227512
[Epoch 90] ogbg-moltox21: 0.823391 test loss: 0.241325
[Epoch 91; Iter    30/  157] train: loss: 0.0538203
[Epoch 91; Iter    60/  157] train: loss: 0.0676132
[Epoch 91; Iter    90/  157] train: loss: 0.0520654
[Epoch 91; Iter   120/  157] train: loss: 0.0922637
[Epoch 91; Iter   150/  157] train: loss: 0.0615895
[Epoch 91] ogbg-moltox21: 0.818349 val loss: 0.228817
[Epoch 91] ogbg-moltox21: 0.818398 test loss: 0.251779
[Epoch 92; Iter    23/  157] train: loss: 0.0941349
[Epoch 92; Iter    53/  157] train: loss: 0.0570377
[Epoch 92; Iter    83/  157] train: loss: 0.0861143
[Epoch 92; Iter   113/  157] train: loss: 0.0862835
[Epoch 92; Iter   143/  157] train: loss: 0.0885466
[Epoch 92] ogbg-moltox21: 0.821127 val loss: 0.233174
[Epoch 92] ogbg-moltox21: 0.820860 test loss: 0.251371
[Epoch 93; Iter    16/  157] train: loss: 0.0547731
[Epoch 93; Iter    46/  157] train: loss: 0.0421604
[Epoch 93; Iter    76/  157] train: loss: 0.0855900
[Epoch 93; Iter   106/  157] train: loss: 0.0664240
[Epoch 93; Iter   136/  157] train: loss: 0.0550092
[Epoch 93] ogbg-moltox21: 0.817338 val loss: 0.226895
[Epoch 93] ogbg-moltox21: 0.819861 test loss: 0.245421
[Epoch 94; Iter     9/  157] train: loss: 0.0850276
[Epoch 94; Iter    39/  157] train: loss: 0.0779170
[Epoch 94; Iter    69/  157] train: loss: 0.0957274
[Epoch 94; Iter    99/  157] train: loss: 0.0775008
[Epoch 94; Iter   129/  157] train: loss: 0.0479505
[Epoch 94] ogbg-moltox21: 0.819440 val loss: 0.234973
[Epoch 94] ogbg-moltox21: 0.815659 test loss: 0.253103
[Epoch 95; Iter     2/  157] train: loss: 0.0776342
[Epoch 95; Iter    32/  157] train: loss: 0.0665008
[Epoch 95; Iter    62/  157] train: loss: 0.0715078
[Epoch 95; Iter    92/  157] train: loss: 0.0504787
[Epoch 95; Iter   122/  157] train: loss: 0.0968691
[Epoch 95; Iter   152/  157] train: loss: 0.1285766
[Epoch 95] ogbg-moltox21: 0.824268 val loss: 0.231046
[Epoch 95] ogbg-moltox21: 0.812959 test loss: 0.253404
[Epoch 96; Iter    25/  157] train: loss: 0.0568671
[Epoch 96; Iter    55/  157] train: loss: 0.0496703
[Epoch 96; Iter    85/  157] train: loss: 0.0938850
[Epoch 96; Iter   115/  157] train: loss: 0.1643056
[Epoch 96; Iter   145/  157] train: loss: 0.0516180
[Epoch 96] ogbg-moltox21: 0.815358 val loss: 0.230659
[Epoch 96] ogbg-moltox21: 0.812643 test loss: 0.251786
[Epoch 97; Iter    18/  157] train: loss: 0.0760651
[Epoch 97; Iter    48/  157] train: loss: 0.0717617
[Epoch 97; Iter    78/  157] train: loss: 0.1236313
[Epoch 97; Iter   108/  157] train: loss: 0.0668606
[Epoch 97; Iter   138/  157] train: loss: 0.0741635
[Epoch 97] ogbg-moltox21: 0.816845 val loss: 0.240739
[Epoch 97] ogbg-moltox21: 0.813818 test loss: 0.260433
[Epoch 98; Iter    11/  157] train: loss: 0.0739615
[Epoch 98; Iter    41/  157] train: loss: 0.0424808
[Epoch 98; Iter    71/  157] train: loss: 0.0934631
[Epoch 98; Iter   101/  157] train: loss: 0.0546174
[Epoch 98; Iter   131/  157] train: loss: 0.0281899
[Epoch 98] ogbg-moltox21: 0.820172 val loss: 0.231748
[Epoch 98] ogbg-moltox21: 0.814945 test loss: 0.254778
[Epoch 99; Iter     4/  157] train: loss: 0.0684378
[Epoch 99; Iter    34/  157] train: loss: 0.0797662
[Epoch 99; Iter    64/  157] train: loss: 0.0516373
[Epoch 99; Iter    94/  157] train: loss: 0.0500147
[Epoch 99; Iter   124/  157] train: loss: 0.0464119
[Epoch 99; Iter   154/  157] train: loss: 0.0573478
[Epoch 99] ogbg-moltox21: 0.814570 val loss: 0.237649
[Epoch 99] ogbg-moltox21: 0.811358 test loss: 0.258698
[Epoch 100; Iter    27/  157] train: loss: 0.0941863
[Epoch 100; Iter    57/  157] train: loss: 0.0652686
[Epoch 100; Iter    87/  157] train: loss: 0.0769210
[Epoch 100; Iter   117/  157] train: loss: 0.0403759
[Epoch 100; Iter   147/  157] train: loss: 0.0747793
[Epoch 100] ogbg-moltox21: 0.818017 val loss: 0.236021
[Epoch 100] ogbg-moltox21: 0.810527 test loss: 0.259058
[Epoch 101; Iter    20/  157] train: loss: 0.0825700
[Epoch 101; Iter    50/  157] train: loss: 0.0538815
[Epoch 101; Iter    80/  157] train: loss: 0.0864940
[Epoch 101; Iter   110/  157] train: loss: 0.1081255
[Epoch 80; Iter    47/  157] train: loss: 0.0814851
[Epoch 80; Iter    77/  157] train: loss: 0.0627925
[Epoch 80; Iter   107/  157] train: loss: 0.0665485
[Epoch 80; Iter   137/  157] train: loss: 0.0326045
[Epoch 80] ogbg-moltox21: 0.818268 val loss: 0.240094
[Epoch 80] ogbg-moltox21: 0.827634 test loss: 0.258326
[Epoch 81; Iter    10/  157] train: loss: 0.0644464
[Epoch 81; Iter    40/  157] train: loss: 0.0894088
[Epoch 81; Iter    70/  157] train: loss: 0.0598408
[Epoch 81; Iter   100/  157] train: loss: 0.0727910
[Epoch 81; Iter   130/  157] train: loss: 0.0530805
[Epoch 81] ogbg-moltox21: 0.812545 val loss: 0.240489
[Epoch 81] ogbg-moltox21: 0.825052 test loss: 0.264057
[Epoch 82; Iter     3/  157] train: loss: 0.1006762
[Epoch 82; Iter    33/  157] train: loss: 0.0427342
[Epoch 82; Iter    63/  157] train: loss: 0.0793802
[Epoch 82; Iter    93/  157] train: loss: 0.1069659
[Epoch 82; Iter   123/  157] train: loss: 0.0747255
[Epoch 82; Iter   153/  157] train: loss: 0.0757686
[Epoch 82] ogbg-moltox21: 0.820325 val loss: 0.244795
[Epoch 82] ogbg-moltox21: 0.823904 test loss: 0.266832
[Epoch 83; Iter    26/  157] train: loss: 0.0528404
[Epoch 83; Iter    56/  157] train: loss: 0.0688493
[Epoch 83; Iter    86/  157] train: loss: 0.0654423
[Epoch 83; Iter   116/  157] train: loss: 0.0611643
[Epoch 83; Iter   146/  157] train: loss: 0.0579479
[Epoch 83] ogbg-moltox21: 0.813968 val loss: 0.239957
[Epoch 83] ogbg-moltox21: 0.822227 test loss: 0.264259
[Epoch 84; Iter    19/  157] train: loss: 0.0400571
[Epoch 84; Iter    49/  157] train: loss: 0.0823575
[Epoch 84; Iter    79/  157] train: loss: 0.0572836
[Epoch 84; Iter   109/  157] train: loss: 0.0479015
[Epoch 84; Iter   139/  157] train: loss: 0.0932006
[Epoch 84] ogbg-moltox21: 0.815277 val loss: 0.247606
[Epoch 84] ogbg-moltox21: 0.826997 test loss: 0.269466
[Epoch 85; Iter    12/  157] train: loss: 0.0505244
[Epoch 85; Iter    42/  157] train: loss: 0.1839248
[Epoch 85; Iter    72/  157] train: loss: 0.0589902
[Epoch 85; Iter   102/  157] train: loss: 0.0409694
[Epoch 85; Iter   132/  157] train: loss: 0.0677308
[Epoch 85] ogbg-moltox21: 0.812174 val loss: 0.247540
[Epoch 85] ogbg-moltox21: 0.822110 test loss: 0.265050
[Epoch 86; Iter     5/  157] train: loss: 0.0613356
[Epoch 86; Iter    35/  157] train: loss: 0.1029679
[Epoch 86; Iter    65/  157] train: loss: 0.0722766
[Epoch 86; Iter    95/  157] train: loss: 0.1152981
[Epoch 86; Iter   125/  157] train: loss: 0.0687631
[Epoch 86; Iter   155/  157] train: loss: 0.0658029
[Epoch 86] ogbg-moltox21: 0.810257 val loss: 0.251234
[Epoch 86] ogbg-moltox21: 0.824518 test loss: 0.268053
[Epoch 87; Iter    28/  157] train: loss: 0.0530052
[Epoch 87; Iter    58/  157] train: loss: 0.0515134
[Epoch 87; Iter    88/  157] train: loss: 0.0616021
[Epoch 87; Iter   118/  157] train: loss: 0.0609254
[Epoch 87; Iter   148/  157] train: loss: 0.0672153
[Epoch 87] ogbg-moltox21: 0.815425 val loss: 0.248757
[Epoch 87] ogbg-moltox21: 0.826613 test loss: 0.272561
[Epoch 88; Iter    21/  157] train: loss: 0.0813340
[Epoch 88; Iter    51/  157] train: loss: 0.0569040
[Epoch 88; Iter    81/  157] train: loss: 0.0865078
[Epoch 88; Iter   111/  157] train: loss: 0.0829792
[Epoch 88; Iter   141/  157] train: loss: 0.1224240
[Epoch 88] ogbg-moltox21: 0.816531 val loss: 0.254063
[Epoch 88] ogbg-moltox21: 0.820077 test loss: 0.279194
[Epoch 89; Iter    14/  157] train: loss: 0.0510585
[Epoch 89; Iter    44/  157] train: loss: 0.0670209
[Epoch 89; Iter    74/  157] train: loss: 0.0711225
[Epoch 89; Iter   104/  157] train: loss: 0.0865476
[Epoch 89; Iter   134/  157] train: loss: 0.0855380
[Epoch 89] ogbg-moltox21: 0.809451 val loss: 0.249616
[Epoch 89] ogbg-moltox21: 0.825067 test loss: 0.269847
[Epoch 90; Iter     7/  157] train: loss: 0.0434666
[Epoch 90; Iter    37/  157] train: loss: 0.0762333
[Epoch 90; Iter    67/  157] train: loss: 0.0820151
[Epoch 90; Iter    97/  157] train: loss: 0.0683897
[Epoch 90; Iter   127/  157] train: loss: 0.0900026
[Epoch 90; Iter   157/  157] train: loss: 0.0592599
[Epoch 90] ogbg-moltox21: 0.816666 val loss: 0.253881
[Epoch 90] ogbg-moltox21: 0.823396 test loss: 0.281900
[Epoch 91; Iter    30/  157] train: loss: 0.0430110
[Epoch 91; Iter    60/  157] train: loss: 0.0524862
[Epoch 91; Iter    90/  157] train: loss: 0.0665748
[Epoch 91; Iter   120/  157] train: loss: 0.0746528
[Epoch 91; Iter   150/  157] train: loss: 0.0533399
[Epoch 91] ogbg-moltox21: 0.814969 val loss: 0.250105
[Epoch 91] ogbg-moltox21: 0.824217 test loss: 0.273249
[Epoch 92; Iter    23/  157] train: loss: 0.0540275
[Epoch 92; Iter    53/  157] train: loss: 0.0468877
[Epoch 92; Iter    83/  157] train: loss: 0.0484887
[Epoch 92; Iter   113/  157] train: loss: 0.0411849
[Epoch 92; Iter   143/  157] train: loss: 0.0353111
[Epoch 92] ogbg-moltox21: 0.812350 val loss: 0.254458
[Epoch 92] ogbg-moltox21: 0.821615 test loss: 0.279179
[Epoch 93; Iter    16/  157] train: loss: 0.0617007
[Epoch 93; Iter    46/  157] train: loss: 0.0587102
[Epoch 93; Iter    76/  157] train: loss: 0.0743471
[Epoch 93; Iter   106/  157] train: loss: 0.0571441
[Epoch 93; Iter   136/  157] train: loss: 0.0461962
[Epoch 93] ogbg-moltox21: 0.815714 val loss: 0.257581
[Epoch 93] ogbg-moltox21: 0.823191 test loss: 0.284084
[Epoch 94; Iter     9/  157] train: loss: 0.0659274
[Epoch 94; Iter    39/  157] train: loss: 0.0346557
[Epoch 94; Iter    69/  157] train: loss: 0.0362840
[Epoch 94; Iter    99/  157] train: loss: 0.0485195
[Epoch 94; Iter   129/  157] train: loss: 0.0671772
[Epoch 94] ogbg-moltox21: 0.814204 val loss: 0.254467
[Epoch 94] ogbg-moltox21: 0.822363 test loss: 0.281018
[Epoch 95; Iter     2/  157] train: loss: 0.0519609
[Epoch 95; Iter    32/  157] train: loss: 0.0560786
[Epoch 95; Iter    62/  157] train: loss: 0.0771060
[Epoch 95; Iter    92/  157] train: loss: 0.0574447
[Epoch 95; Iter   122/  157] train: loss: 0.0399554
[Epoch 95; Iter   152/  157] train: loss: 0.0496729
[Epoch 95] ogbg-moltox21: 0.815359 val loss: 0.258980
[Epoch 95] ogbg-moltox21: 0.826087 test loss: 0.282765
[Epoch 96; Iter    25/  157] train: loss: 0.0743063
[Epoch 96; Iter    55/  157] train: loss: 0.0437398
[Epoch 96; Iter    85/  157] train: loss: 0.0514982
[Epoch 96; Iter   115/  157] train: loss: 0.0616202
[Epoch 96; Iter   145/  157] train: loss: 0.0244829
[Epoch 96] ogbg-moltox21: 0.816173 val loss: 0.260274
[Epoch 96] ogbg-moltox21: 0.825569 test loss: 0.284650
[Epoch 97; Iter    18/  157] train: loss: 0.0284463
[Epoch 97; Iter    48/  157] train: loss: 0.0577703
[Epoch 97; Iter    78/  157] train: loss: 0.0214526
[Epoch 97; Iter   108/  157] train: loss: 0.0436919
[Epoch 97; Iter   138/  157] train: loss: 0.0302846
[Epoch 97] ogbg-moltox21: 0.815728 val loss: 0.260635
[Epoch 97] ogbg-moltox21: 0.817560 test loss: 0.289859
[Epoch 98; Iter    11/  157] train: loss: 0.0468890
[Epoch 98; Iter    41/  157] train: loss: 0.0601039
[Epoch 98; Iter    71/  157] train: loss: 0.0460174
[Epoch 98; Iter   101/  157] train: loss: 0.0313666
[Epoch 98; Iter   131/  157] train: loss: 0.0428845
[Epoch 98] ogbg-moltox21: 0.812090 val loss: 0.265525
[Epoch 98] ogbg-moltox21: 0.818479 test loss: 0.292130
[Epoch 99; Iter     4/  157] train: loss: 0.0301758
[Epoch 99; Iter    34/  157] train: loss: 0.0451386
[Epoch 99; Iter    64/  157] train: loss: 0.0419673
[Epoch 99; Iter    94/  157] train: loss: 0.0672452
[Epoch 99; Iter   124/  157] train: loss: 0.0556828
[Epoch 99; Iter   154/  157] train: loss: 0.0367406
[Epoch 99] ogbg-moltox21: 0.814395 val loss: 0.262892
[Epoch 99] ogbg-moltox21: 0.820738 test loss: 0.285737
[Epoch 100; Iter    27/  157] train: loss: 0.0239001
[Epoch 100; Iter    57/  157] train: loss: 0.0769753
[Epoch 100; Iter    87/  157] train: loss: 0.0220383
[Epoch 100; Iter   117/  157] train: loss: 0.0523930
[Epoch 100; Iter   147/  157] train: loss: 0.0686824
[Epoch 100] ogbg-moltox21: 0.814811 val loss: 0.263470
[Epoch 100] ogbg-moltox21: 0.821441 test loss: 0.290956
[Epoch 101; Iter    20/  157] train: loss: 0.0570384
[Epoch 101; Iter    50/  157] train: loss: 0.0348403
[Epoch 101; Iter    80/  157] train: loss: 0.0707468
[Epoch 101; Iter   110/  157] train: loss: 0.0336929
[Epoch 80; Iter    47/  157] train: loss: 0.0888268
[Epoch 80; Iter    77/  157] train: loss: 0.0467237
[Epoch 80; Iter   107/  157] train: loss: 0.0658467
[Epoch 80; Iter   137/  157] train: loss: 0.1004521
[Epoch 80] ogbg-moltox21: 0.806576 val loss: 0.244246
[Epoch 80] ogbg-moltox21: 0.819442 test loss: 0.263764
[Epoch 81; Iter    10/  157] train: loss: 0.1282014
[Epoch 81; Iter    40/  157] train: loss: 0.0524302
[Epoch 81; Iter    70/  157] train: loss: 0.0602378
[Epoch 81; Iter   100/  157] train: loss: 0.0683305
[Epoch 81; Iter   130/  157] train: loss: 0.0874428
[Epoch 81] ogbg-moltox21: 0.800191 val loss: 0.244931
[Epoch 81] ogbg-moltox21: 0.808841 test loss: 0.271114
[Epoch 82; Iter     3/  157] train: loss: 0.0446189
[Epoch 82; Iter    33/  157] train: loss: 0.0548078
[Epoch 82; Iter    63/  157] train: loss: 0.0520252
[Epoch 82; Iter    93/  157] train: loss: 0.0665182
[Epoch 82; Iter   123/  157] train: loss: 0.0808269
[Epoch 82; Iter   153/  157] train: loss: 0.0495886
[Epoch 82] ogbg-moltox21: 0.800612 val loss: 0.249158
[Epoch 82] ogbg-moltox21: 0.813146 test loss: 0.275163
[Epoch 83; Iter    26/  157] train: loss: 0.0501675
[Epoch 83; Iter    56/  157] train: loss: 0.1108249
[Epoch 83; Iter    86/  157] train: loss: 0.0732555
[Epoch 83; Iter   116/  157] train: loss: 0.0810650
[Epoch 83; Iter   146/  157] train: loss: 0.0389720
[Epoch 83] ogbg-moltox21: 0.800474 val loss: 0.248323
[Epoch 83] ogbg-moltox21: 0.812801 test loss: 0.270930
[Epoch 84; Iter    19/  157] train: loss: 0.0678756
[Epoch 84; Iter    49/  157] train: loss: 0.0474848
[Epoch 84; Iter    79/  157] train: loss: 0.0749685
[Epoch 84; Iter   109/  157] train: loss: 0.0966221
[Epoch 84; Iter   139/  157] train: loss: 0.0912883
[Epoch 84] ogbg-moltox21: 0.801483 val loss: 0.248986
[Epoch 84] ogbg-moltox21: 0.814752 test loss: 0.270992
[Epoch 85; Iter    12/  157] train: loss: 0.0472947
[Epoch 85; Iter    42/  157] train: loss: 0.0660181
[Epoch 85; Iter    72/  157] train: loss: 0.0444903
[Epoch 85; Iter   102/  157] train: loss: 0.0712137
[Epoch 85; Iter   132/  157] train: loss: 0.0420840
[Epoch 85] ogbg-moltox21: 0.796691 val loss: 0.250645
[Epoch 85] ogbg-moltox21: 0.807388 test loss: 0.279019
[Epoch 86; Iter     5/  157] train: loss: 0.0746974
[Epoch 86; Iter    35/  157] train: loss: 0.0480048
[Epoch 86; Iter    65/  157] train: loss: 0.0738545
[Epoch 86; Iter    95/  157] train: loss: 0.0439799
[Epoch 86; Iter   125/  157] train: loss: 0.0721813
[Epoch 86; Iter   155/  157] train: loss: 0.0589504
[Epoch 86] ogbg-moltox21: 0.796804 val loss: 0.258100
[Epoch 86] ogbg-moltox21: 0.813799 test loss: 0.283588
[Epoch 87; Iter    28/  157] train: loss: 0.0590331
[Epoch 87; Iter    58/  157] train: loss: 0.0602790
[Epoch 87; Iter    88/  157] train: loss: 0.0426391
[Epoch 87; Iter   118/  157] train: loss: 0.0640781
[Epoch 87; Iter   148/  157] train: loss: 0.0651316
[Epoch 87] ogbg-moltox21: 0.790912 val loss: 0.261541
[Epoch 87] ogbg-moltox21: 0.806348 test loss: 0.287983
[Epoch 88; Iter    21/  157] train: loss: 0.1019646
[Epoch 88; Iter    51/  157] train: loss: 0.0484227
[Epoch 88; Iter    81/  157] train: loss: 0.0745657
[Epoch 88; Iter   111/  157] train: loss: 0.0633329
[Epoch 88; Iter   141/  157] train: loss: 0.1093105
[Epoch 88] ogbg-moltox21: 0.799182 val loss: 0.259183
[Epoch 88] ogbg-moltox21: 0.815006 test loss: 0.281635
[Epoch 89; Iter    14/  157] train: loss: 0.0531047
[Epoch 89; Iter    44/  157] train: loss: 0.0390539
[Epoch 89; Iter    74/  157] train: loss: 0.0511487
[Epoch 89; Iter   104/  157] train: loss: 0.0519097
[Epoch 89; Iter   134/  157] train: loss: 0.0576846
[Epoch 89] ogbg-moltox21: 0.802746 val loss: 0.254805
[Epoch 89] ogbg-moltox21: 0.811310 test loss: 0.281063
[Epoch 90; Iter     7/  157] train: loss: 0.0570761
[Epoch 90; Iter    37/  157] train: loss: 0.0381915
[Epoch 90; Iter    67/  157] train: loss: 0.0869684
[Epoch 90; Iter    97/  157] train: loss: 0.0534698
[Epoch 90; Iter   127/  157] train: loss: 0.0831021
[Epoch 90; Iter   157/  157] train: loss: 0.0516872
[Epoch 90] ogbg-moltox21: 0.797428 val loss: 0.264472
[Epoch 90] ogbg-moltox21: 0.807448 test loss: 0.289407
[Epoch 91; Iter    30/  157] train: loss: 0.0560440
[Epoch 91; Iter    60/  157] train: loss: 0.0502251
[Epoch 91; Iter    90/  157] train: loss: 0.0500411
[Epoch 91; Iter   120/  157] train: loss: 0.0589140
[Epoch 91; Iter   150/  157] train: loss: 0.0709213
[Epoch 91] ogbg-moltox21: 0.793094 val loss: 0.268263
[Epoch 91] ogbg-moltox21: 0.804283 test loss: 0.298221
[Epoch 92; Iter    23/  157] train: loss: 0.0686980
[Epoch 92; Iter    53/  157] train: loss: 0.0403025
[Epoch 92; Iter    83/  157] train: loss: 0.0705628
[Epoch 92; Iter   113/  157] train: loss: 0.0493974
[Epoch 92; Iter   143/  157] train: loss: 0.0596813
[Epoch 92] ogbg-moltox21: 0.798068 val loss: 0.263793
[Epoch 92] ogbg-moltox21: 0.808637 test loss: 0.289685
[Epoch 93; Iter    16/  157] train: loss: 0.0556117
[Epoch 93; Iter    46/  157] train: loss: 0.0448883
[Epoch 93; Iter    76/  157] train: loss: 0.0409890
[Epoch 93; Iter   106/  157] train: loss: 0.0530615
[Epoch 93; Iter   136/  157] train: loss: 0.0711625
[Epoch 93] ogbg-moltox21: 0.792470 val loss: 0.270472
[Epoch 93] ogbg-moltox21: 0.804200 test loss: 0.299699
[Epoch 94; Iter     9/  157] train: loss: 0.0720547
[Epoch 94; Iter    39/  157] train: loss: 0.0301280
[Epoch 94; Iter    69/  157] train: loss: 0.0567092
[Epoch 94; Iter    99/  157] train: loss: 0.0259868
[Epoch 94; Iter   129/  157] train: loss: 0.0636863
[Epoch 94] ogbg-moltox21: 0.799584 val loss: 0.268131
[Epoch 94] ogbg-moltox21: 0.810657 test loss: 0.297729
[Epoch 95; Iter     2/  157] train: loss: 0.0347579
[Epoch 95; Iter    32/  157] train: loss: 0.0516960
[Epoch 95; Iter    62/  157] train: loss: 0.0348494
[Epoch 95; Iter    92/  157] train: loss: 0.0522463
[Epoch 95; Iter   122/  157] train: loss: 0.0888975
[Epoch 95; Iter   152/  157] train: loss: 0.0437414
[Epoch 95] ogbg-moltox21: 0.795387 val loss: 0.270701
[Epoch 95] ogbg-moltox21: 0.809375 test loss: 0.298498
[Epoch 96; Iter    25/  157] train: loss: 0.0349090
[Epoch 96; Iter    55/  157] train: loss: 0.0387428
[Epoch 96; Iter    85/  157] train: loss: 0.0373277
[Epoch 96; Iter   115/  157] train: loss: 0.0509312
[Epoch 96; Iter   145/  157] train: loss: 0.0556005
[Epoch 96] ogbg-moltox21: 0.800371 val loss: 0.272256
[Epoch 96] ogbg-moltox21: 0.809575 test loss: 0.305940
[Epoch 97; Iter    18/  157] train: loss: 0.0507758
[Epoch 97; Iter    48/  157] train: loss: 0.0432844
[Epoch 97; Iter    78/  157] train: loss: 0.0567713
[Epoch 97; Iter   108/  157] train: loss: 0.0298087
[Epoch 97; Iter   138/  157] train: loss: 0.0340112
[Epoch 97] ogbg-moltox21: 0.798560 val loss: 0.269309
[Epoch 97] ogbg-moltox21: 0.809639 test loss: 0.296544
[Epoch 98; Iter    11/  157] train: loss: 0.0858218
[Epoch 98; Iter    41/  157] train: loss: 0.0256342
[Epoch 98; Iter    71/  157] train: loss: 0.0536537
[Epoch 98; Iter   101/  157] train: loss: 0.0596323
[Epoch 98; Iter   131/  157] train: loss: 0.0534082
[Epoch 98] ogbg-moltox21: 0.795180 val loss: 0.275995
[Epoch 98] ogbg-moltox21: 0.804939 test loss: 0.305984
[Epoch 99; Iter     4/  157] train: loss: 0.0592786
[Epoch 99; Iter    34/  157] train: loss: 0.0488345
[Epoch 99; Iter    64/  157] train: loss: 0.0465357
[Epoch 99; Iter    94/  157] train: loss: 0.0465164
[Epoch 99; Iter   124/  157] train: loss: 0.0771256
[Epoch 99; Iter   154/  157] train: loss: 0.0358456
[Epoch 99] ogbg-moltox21: 0.791319 val loss: 0.275982
[Epoch 99] ogbg-moltox21: 0.804885 test loss: 0.302793
[Epoch 100; Iter    27/  157] train: loss: 0.0578641
[Epoch 100; Iter    57/  157] train: loss: 0.0602820
[Epoch 100; Iter    87/  157] train: loss: 0.0210272
[Epoch 100; Iter   117/  157] train: loss: 0.0725506
[Epoch 100; Iter   147/  157] train: loss: 0.0648572
[Epoch 100] ogbg-moltox21: 0.795906 val loss: 0.275274
[Epoch 100] ogbg-moltox21: 0.806742 test loss: 0.304670
[Epoch 101; Iter    20/  157] train: loss: 0.0418580
[Epoch 101; Iter    50/  157] train: loss: 0.0179912
[Epoch 101; Iter    80/  157] train: loss: 0.0451481
[Epoch 101; Iter   110/  157] train: loss: 0.0870172
[Epoch 82; Iter    51/  209] train: loss: 0.1049310
[Epoch 82; Iter    81/  209] train: loss: 0.0512417
[Epoch 82; Iter   111/  209] train: loss: 0.0470210
[Epoch 82; Iter   141/  209] train: loss: 0.0959901
[Epoch 82; Iter   171/  209] train: loss: 0.1293214
[Epoch 82; Iter   201/  209] train: loss: 0.0549566
[Epoch 82] ogbg-moltox21: 0.844541 val loss: 0.260939
[Epoch 82] ogbg-moltox21: 0.845730 test loss: 0.218956
[Epoch 83; Iter    22/  209] train: loss: 0.0577662
[Epoch 83; Iter    52/  209] train: loss: 0.0623444
[Epoch 83; Iter    82/  209] train: loss: 0.0796234
[Epoch 83; Iter   112/  209] train: loss: 0.0828615
[Epoch 83; Iter   142/  209] train: loss: 0.0713801
[Epoch 83; Iter   172/  209] train: loss: 0.0751192
[Epoch 83; Iter   202/  209] train: loss: 0.0660344
[Epoch 83] ogbg-moltox21: 0.844706 val loss: 0.260612
[Epoch 83] ogbg-moltox21: 0.843464 test loss: 0.218091
[Epoch 84; Iter    23/  209] train: loss: 0.0930332
[Epoch 84; Iter    53/  209] train: loss: 0.0776760
[Epoch 84; Iter    83/  209] train: loss: 0.1185484
[Epoch 84; Iter   113/  209] train: loss: 0.0493019
[Epoch 84; Iter   143/  209] train: loss: 0.0614496
[Epoch 84; Iter   173/  209] train: loss: 0.0567546
[Epoch 84; Iter   203/  209] train: loss: 0.0904885
[Epoch 84] ogbg-moltox21: 0.847420 val loss: 0.271668
[Epoch 84] ogbg-moltox21: 0.843889 test loss: 0.221355
[Epoch 85; Iter    24/  209] train: loss: 0.0632683
[Epoch 85; Iter    54/  209] train: loss: 0.0974484
[Epoch 85; Iter    84/  209] train: loss: 0.0759686
[Epoch 85; Iter   114/  209] train: loss: 0.0708106
[Epoch 85; Iter   144/  209] train: loss: 0.0773344
[Epoch 85; Iter   174/  209] train: loss: 0.1119999
[Epoch 85; Iter   204/  209] train: loss: 0.0620887
[Epoch 85] ogbg-moltox21: 0.842122 val loss: 0.265854
[Epoch 85] ogbg-moltox21: 0.836679 test loss: 0.224358
[Epoch 86; Iter    25/  209] train: loss: 0.0578343
[Epoch 86; Iter    55/  209] train: loss: 0.0813915
[Epoch 86; Iter    85/  209] train: loss: 0.0503157
[Epoch 86; Iter   115/  209] train: loss: 0.0614084
[Epoch 86; Iter   145/  209] train: loss: 0.0937359
[Epoch 86; Iter   175/  209] train: loss: 0.0803152
[Epoch 86; Iter   205/  209] train: loss: 0.0475687
[Epoch 86] ogbg-moltox21: 0.839186 val loss: 0.268157
[Epoch 86] ogbg-moltox21: 0.836665 test loss: 0.233666
[Epoch 87; Iter    26/  209] train: loss: 0.0537441
[Epoch 87; Iter    56/  209] train: loss: 0.0657094
[Epoch 87; Iter    86/  209] train: loss: 0.0920179
[Epoch 87; Iter   116/  209] train: loss: 0.0879574
[Epoch 87; Iter   146/  209] train: loss: 0.0643513
[Epoch 87; Iter   176/  209] train: loss: 0.0421869
[Epoch 87; Iter   206/  209] train: loss: 0.0874781
[Epoch 87] ogbg-moltox21: 0.848909 val loss: 0.261063
[Epoch 87] ogbg-moltox21: 0.840632 test loss: 0.224466
[Epoch 88; Iter    27/  209] train: loss: 0.0326187
[Epoch 88; Iter    57/  209] train: loss: 0.0915811
[Epoch 88; Iter    87/  209] train: loss: 0.1078194
[Epoch 88; Iter   117/  209] train: loss: 0.0547099
[Epoch 88; Iter   147/  209] train: loss: 0.0976731
[Epoch 88; Iter   177/  209] train: loss: 0.0475265
[Epoch 88; Iter   207/  209] train: loss: 0.0553563
[Epoch 88] ogbg-moltox21: 0.840497 val loss: 0.280563
[Epoch 88] ogbg-moltox21: 0.839472 test loss: 0.234074
[Epoch 89; Iter    28/  209] train: loss: 0.0546920
[Epoch 89; Iter    58/  209] train: loss: 0.1027651
[Epoch 89; Iter    88/  209] train: loss: 0.0777397
[Epoch 89; Iter   118/  209] train: loss: 0.0921813
[Epoch 89; Iter   148/  209] train: loss: 0.0642497
[Epoch 89; Iter   178/  209] train: loss: 0.0686489
[Epoch 89; Iter   208/  209] train: loss: 0.1299292
[Epoch 89] ogbg-moltox21: 0.841998 val loss: 0.274711
[Epoch 89] ogbg-moltox21: 0.842471 test loss: 0.227460
[Epoch 90; Iter    29/  209] train: loss: 0.0893308
[Epoch 90; Iter    59/  209] train: loss: 0.0868578
[Epoch 90; Iter    89/  209] train: loss: 0.0569912
[Epoch 90; Iter   119/  209] train: loss: 0.0835698
[Epoch 90; Iter   149/  209] train: loss: 0.0798537
[Epoch 90; Iter   179/  209] train: loss: 0.0894693
[Epoch 90; Iter   209/  209] train: loss: 0.0935406
[Epoch 90] ogbg-moltox21: 0.839963 val loss: 0.279638
[Epoch 90] ogbg-moltox21: 0.840737 test loss: 0.234024
[Epoch 91; Iter    30/  209] train: loss: 0.1011973
[Epoch 91; Iter    60/  209] train: loss: 0.0636828
[Epoch 91; Iter    90/  209] train: loss: 0.0674689
[Epoch 91; Iter   120/  209] train: loss: 0.1002574
[Epoch 91; Iter   150/  209] train: loss: 0.0649309
[Epoch 91; Iter   180/  209] train: loss: 0.1189561
[Epoch 91] ogbg-moltox21: 0.841042 val loss: 0.272419
[Epoch 91] ogbg-moltox21: 0.843206 test loss: 0.230725
[Epoch 92; Iter     1/  209] train: loss: 0.0742039
[Epoch 92; Iter    31/  209] train: loss: 0.0630793
[Epoch 92; Iter    61/  209] train: loss: 0.0726482
[Epoch 92; Iter    91/  209] train: loss: 0.0779128
[Epoch 92; Iter   121/  209] train: loss: 0.0740269
[Epoch 92; Iter   151/  209] train: loss: 0.0783124
[Epoch 92; Iter   181/  209] train: loss: 0.0881159
[Epoch 92] ogbg-moltox21: 0.842294 val loss: 0.300861
[Epoch 92] ogbg-moltox21: 0.843060 test loss: 0.231770
[Epoch 93; Iter     2/  209] train: loss: 0.0870554
[Epoch 93; Iter    32/  209] train: loss: 0.0680648
[Epoch 93; Iter    62/  209] train: loss: 0.0490135
[Epoch 93; Iter    92/  209] train: loss: 0.0711514
[Epoch 93; Iter   122/  209] train: loss: 0.1064431
[Epoch 93; Iter   152/  209] train: loss: 0.0826439
[Epoch 93; Iter   182/  209] train: loss: 0.1007802
[Epoch 93] ogbg-moltox21: 0.841733 val loss: 0.285898
[Epoch 93] ogbg-moltox21: 0.841089 test loss: 0.238490
[Epoch 94; Iter     3/  209] train: loss: 0.0695278
[Epoch 94; Iter    33/  209] train: loss: 0.0639580
[Epoch 94; Iter    63/  209] train: loss: 0.0785796
[Epoch 94; Iter    93/  209] train: loss: 0.0907098
[Epoch 94; Iter   123/  209] train: loss: 0.0742388
[Epoch 94; Iter   153/  209] train: loss: 0.0832563
[Epoch 94; Iter   183/  209] train: loss: 0.0628125
[Epoch 94] ogbg-moltox21: 0.837229 val loss: 0.298311
[Epoch 94] ogbg-moltox21: 0.835663 test loss: 0.236263
[Epoch 95; Iter     4/  209] train: loss: 0.0708906
[Epoch 95; Iter    34/  209] train: loss: 0.0969662
[Epoch 95; Iter    64/  209] train: loss: 0.1088128
[Epoch 95; Iter    94/  209] train: loss: 0.1089079
[Epoch 95; Iter   124/  209] train: loss: 0.0392853
[Epoch 95; Iter   154/  209] train: loss: 0.0697049
[Epoch 95; Iter   184/  209] train: loss: 0.0551165
[Epoch 95] ogbg-moltox21: 0.842999 val loss: 0.297668
[Epoch 95] ogbg-moltox21: 0.838390 test loss: 0.238656
[Epoch 96; Iter     5/  209] train: loss: 0.0501415
[Epoch 96; Iter    35/  209] train: loss: 0.0658385
[Epoch 96; Iter    65/  209] train: loss: 0.0720411
[Epoch 96; Iter    95/  209] train: loss: 0.0450236
[Epoch 96; Iter   125/  209] train: loss: 0.1117559
[Epoch 96; Iter   155/  209] train: loss: 0.0571535
[Epoch 96; Iter   185/  209] train: loss: 0.0610113
[Epoch 96] ogbg-moltox21: 0.844024 val loss: 0.274889
[Epoch 96] ogbg-moltox21: 0.830492 test loss: 0.243230
[Epoch 97; Iter     6/  209] train: loss: 0.0515644
[Epoch 97; Iter    36/  209] train: loss: 0.0531250
[Epoch 97; Iter    66/  209] train: loss: 0.0502631
[Epoch 97; Iter    96/  209] train: loss: 0.0466645
[Epoch 97; Iter   126/  209] train: loss: 0.0777872
[Epoch 97; Iter   156/  209] train: loss: 0.0699951
[Epoch 97; Iter   186/  209] train: loss: 0.0740984
[Epoch 97] ogbg-moltox21: 0.839790 val loss: 0.305556
[Epoch 97] ogbg-moltox21: 0.835689 test loss: 0.246772
[Epoch 98; Iter     7/  209] train: loss: 0.0358241
[Epoch 98; Iter    37/  209] train: loss: 0.0585300
[Epoch 98; Iter    67/  209] train: loss: 0.0511492
[Epoch 98; Iter    97/  209] train: loss: 0.0429797
[Epoch 98; Iter   127/  209] train: loss: 0.0301179
[Epoch 98; Iter   157/  209] train: loss: 0.0860803
[Epoch 98; Iter   187/  209] train: loss: 0.0559668
[Epoch 98] ogbg-moltox21: 0.836738 val loss: 0.293291
[Epoch 98] ogbg-moltox21: 0.837751 test loss: 0.244266
[Epoch 99; Iter     8/  209] train: loss: 0.0407406
[Epoch 99; Iter    38/  209] train: loss: 0.0571967
[Epoch 99; Iter    68/  209] train: loss: 0.0783624
[Epoch 99; Iter    98/  209] train: loss: 0.0836491
[Epoch 82; Iter    51/  209] train: loss: 0.0798377
[Epoch 82; Iter    81/  209] train: loss: 0.0518019
[Epoch 82; Iter   111/  209] train: loss: 0.0571561
[Epoch 82; Iter   141/  209] train: loss: 0.1151968
[Epoch 82; Iter   171/  209] train: loss: 0.0644913
[Epoch 82; Iter   201/  209] train: loss: 0.0557937
[Epoch 82] ogbg-moltox21: 0.834439 val loss: 0.294381
[Epoch 82] ogbg-moltox21: 0.814820 test loss: 0.303409
[Epoch 83; Iter    22/  209] train: loss: 0.0545914
[Epoch 83; Iter    52/  209] train: loss: 0.0504123
[Epoch 83; Iter    82/  209] train: loss: 0.0375741
[Epoch 83; Iter   112/  209] train: loss: 0.0493657
[Epoch 83; Iter   142/  209] train: loss: 0.0856640
[Epoch 83; Iter   172/  209] train: loss: 0.1208092
[Epoch 83; Iter   202/  209] train: loss: 0.0431546
[Epoch 83] ogbg-moltox21: 0.827398 val loss: 0.292155
[Epoch 83] ogbg-moltox21: 0.813342 test loss: 0.271875
[Epoch 84; Iter    23/  209] train: loss: 0.0635645
[Epoch 84; Iter    53/  209] train: loss: 0.0764584
[Epoch 84; Iter    83/  209] train: loss: 0.1185763
[Epoch 84; Iter   113/  209] train: loss: 0.0646704
[Epoch 84; Iter   143/  209] train: loss: 0.1067514
[Epoch 84; Iter   173/  209] train: loss: 0.0624093
[Epoch 84; Iter   203/  209] train: loss: 0.0539638
[Epoch 84] ogbg-moltox21: 0.828737 val loss: 0.297716
[Epoch 84] ogbg-moltox21: 0.811316 test loss: 0.272389
[Epoch 85; Iter    24/  209] train: loss: 0.0583813
[Epoch 85; Iter    54/  209] train: loss: 0.0478332
[Epoch 85; Iter    84/  209] train: loss: 0.0360150
[Epoch 85; Iter   114/  209] train: loss: 0.1039199
[Epoch 85; Iter   144/  209] train: loss: 0.1041422
[Epoch 85; Iter   174/  209] train: loss: 0.0441706
[Epoch 85; Iter   204/  209] train: loss: 0.0414050
[Epoch 85] ogbg-moltox21: 0.821205 val loss: 0.312848
[Epoch 85] ogbg-moltox21: 0.809913 test loss: 0.280342
[Epoch 86; Iter    25/  209] train: loss: 0.0563832
[Epoch 86; Iter    55/  209] train: loss: 0.0813950
[Epoch 86; Iter    85/  209] train: loss: 0.0635138
[Epoch 86; Iter   115/  209] train: loss: 0.0510457
[Epoch 86; Iter   145/  209] train: loss: 0.0748385
[Epoch 86; Iter   175/  209] train: loss: 0.0606904
[Epoch 86; Iter   205/  209] train: loss: 0.0705709
[Epoch 86] ogbg-moltox21: 0.828758 val loss: 0.294003
[Epoch 86] ogbg-moltox21: 0.818704 test loss: 0.280629
[Epoch 87; Iter    26/  209] train: loss: 0.0357419
[Epoch 87; Iter    56/  209] train: loss: 0.0638554
[Epoch 87; Iter    86/  209] train: loss: 0.0956033
[Epoch 87; Iter   116/  209] train: loss: 0.0563304
[Epoch 87; Iter   146/  209] train: loss: 0.0618867
[Epoch 87; Iter   176/  209] train: loss: 0.0785549
[Epoch 87; Iter   206/  209] train: loss: 0.0597293
[Epoch 87] ogbg-moltox21: 0.824291 val loss: 0.312195
[Epoch 87] ogbg-moltox21: 0.812682 test loss: 0.281651
[Epoch 88; Iter    27/  209] train: loss: 0.0531680
[Epoch 88; Iter    57/  209] train: loss: 0.0491995
[Epoch 88; Iter    87/  209] train: loss: 0.0278986
[Epoch 88; Iter   117/  209] train: loss: 0.0522635
[Epoch 88; Iter   147/  209] train: loss: 0.0901261
[Epoch 88; Iter   177/  209] train: loss: 0.0447528
[Epoch 88; Iter   207/  209] train: loss: 0.0678989
[Epoch 88] ogbg-moltox21: 0.833428 val loss: 0.302023
[Epoch 88] ogbg-moltox21: 0.820444 test loss: 0.273332
[Epoch 89; Iter    28/  209] train: loss: 0.0629494
[Epoch 89; Iter    58/  209] train: loss: 0.0428373
[Epoch 89; Iter    88/  209] train: loss: 0.0950946
[Epoch 89; Iter   118/  209] train: loss: 0.0480745
[Epoch 89; Iter   148/  209] train: loss: 0.0621414
[Epoch 89; Iter   178/  209] train: loss: 0.0989124
[Epoch 89; Iter   208/  209] train: loss: 0.0519595
[Epoch 89] ogbg-moltox21: 0.835902 val loss: 0.300971
[Epoch 89] ogbg-moltox21: 0.815909 test loss: 0.281657
[Epoch 90; Iter    29/  209] train: loss: 0.0555783
[Epoch 90; Iter    59/  209] train: loss: 0.0324047
[Epoch 90; Iter    89/  209] train: loss: 0.0402214
[Epoch 90; Iter   119/  209] train: loss: 0.0286250
[Epoch 90; Iter   149/  209] train: loss: 0.0432179
[Epoch 90; Iter   179/  209] train: loss: 0.0663214
[Epoch 90; Iter   209/  209] train: loss: 0.0555271
[Epoch 90] ogbg-moltox21: 0.832520 val loss: 0.300276
[Epoch 90] ogbg-moltox21: 0.818891 test loss: 0.277169
[Epoch 91; Iter    30/  209] train: loss: 0.0467426
[Epoch 91; Iter    60/  209] train: loss: 0.0779175
[Epoch 91; Iter    90/  209] train: loss: 0.0443196
[Epoch 91; Iter   120/  209] train: loss: 0.0389493
[Epoch 91; Iter   150/  209] train: loss: 0.0250916
[Epoch 91; Iter   180/  209] train: loss: 0.0449024
[Epoch 91] ogbg-moltox21: 0.828244 val loss: 0.308877
[Epoch 91] ogbg-moltox21: 0.812086 test loss: 0.308227
[Epoch 92; Iter     1/  209] train: loss: 0.0443187
[Epoch 92; Iter    31/  209] train: loss: 0.0365482
[Epoch 92; Iter    61/  209] train: loss: 0.0412793
[Epoch 92; Iter    91/  209] train: loss: 0.0566948
[Epoch 92; Iter   121/  209] train: loss: 0.0714720
[Epoch 92; Iter   151/  209] train: loss: 0.0460916
[Epoch 92; Iter   181/  209] train: loss: 0.0626837
[Epoch 92] ogbg-moltox21: 0.833352 val loss: 0.307254
[Epoch 92] ogbg-moltox21: 0.813385 test loss: 0.285963
[Epoch 93; Iter     2/  209] train: loss: 0.0347496
[Epoch 93; Iter    32/  209] train: loss: 0.0491746
[Epoch 93; Iter    62/  209] train: loss: 0.0632690
[Epoch 93; Iter    92/  209] train: loss: 0.0319335
[Epoch 93; Iter   122/  209] train: loss: 0.0744963
[Epoch 93; Iter   152/  209] train: loss: 0.0809188
[Epoch 93; Iter   182/  209] train: loss: 0.0297858
[Epoch 93] ogbg-moltox21: 0.828310 val loss: 0.314334
[Epoch 93] ogbg-moltox21: 0.814450 test loss: 0.296798
[Epoch 94; Iter     3/  209] train: loss: 0.0475361
[Epoch 94; Iter    33/  209] train: loss: 0.0433346
[Epoch 94; Iter    63/  209] train: loss: 0.0496278
[Epoch 94; Iter    93/  209] train: loss: 0.0364746
[Epoch 94; Iter   123/  209] train: loss: 0.0291940
[Epoch 94; Iter   153/  209] train: loss: 0.0419445
[Epoch 94; Iter   183/  209] train: loss: 0.0877763
[Epoch 94] ogbg-moltox21: 0.829290 val loss: 0.311711
[Epoch 94] ogbg-moltox21: 0.813426 test loss: 0.286746
[Epoch 95; Iter     4/  209] train: loss: 0.0183722
[Epoch 95; Iter    34/  209] train: loss: 0.0330124
[Epoch 95; Iter    64/  209] train: loss: 0.0599320
[Epoch 95; Iter    94/  209] train: loss: 0.0584230
[Epoch 95; Iter   124/  209] train: loss: 0.0735856
[Epoch 95; Iter   154/  209] train: loss: 0.0650634
[Epoch 95; Iter   184/  209] train: loss: 0.0336848
[Epoch 95] ogbg-moltox21: 0.828098 val loss: 0.315766
[Epoch 95] ogbg-moltox21: 0.810722 test loss: 0.293898
[Epoch 96; Iter     5/  209] train: loss: 0.0387331
[Epoch 96; Iter    35/  209] train: loss: 0.0326812
[Epoch 96; Iter    65/  209] train: loss: 0.0418928
[Epoch 96; Iter    95/  209] train: loss: 0.0446969
[Epoch 96; Iter   125/  209] train: loss: 0.0447052
[Epoch 96; Iter   155/  209] train: loss: 0.0464818
[Epoch 96; Iter   185/  209] train: loss: 0.0475181
[Epoch 96] ogbg-moltox21: 0.830974 val loss: 0.318272
[Epoch 96] ogbg-moltox21: 0.818581 test loss: 0.291058
[Epoch 97; Iter     6/  209] train: loss: 0.0386541
[Epoch 97; Iter    36/  209] train: loss: 0.0222180
[Epoch 97; Iter    66/  209] train: loss: 0.0473613
[Epoch 97; Iter    96/  209] train: loss: 0.0508883
[Epoch 97; Iter   126/  209] train: loss: 0.0399152
[Epoch 97; Iter   156/  209] train: loss: 0.0430084
[Epoch 97; Iter   186/  209] train: loss: 0.0368977
[Epoch 97] ogbg-moltox21: 0.826202 val loss: 0.319575
[Epoch 97] ogbg-moltox21: 0.815069 test loss: 0.294294
[Epoch 98; Iter     7/  209] train: loss: 0.0212031
[Epoch 98; Iter    37/  209] train: loss: 0.0478122
[Epoch 98; Iter    67/  209] train: loss: 0.0332818
[Epoch 98; Iter    97/  209] train: loss: 0.0678051
[Epoch 98; Iter   127/  209] train: loss: 0.0616879
[Epoch 98; Iter   157/  209] train: loss: 0.0458049
[Epoch 98; Iter   187/  209] train: loss: 0.0288144
[Epoch 98] ogbg-moltox21: 0.827704 val loss: 0.324232
[Epoch 98] ogbg-moltox21: 0.813265 test loss: 0.297464
[Epoch 99; Iter     8/  209] train: loss: 0.0166344
[Epoch 99; Iter    38/  209] train: loss: 0.0846966
[Epoch 99; Iter    68/  209] train: loss: 0.0428602
[Epoch 99; Iter    98/  209] train: loss: 0.0511206
[Epoch 82; Iter    51/  209] train: loss: 0.1367685
[Epoch 82; Iter    81/  209] train: loss: 0.0920646
[Epoch 82; Iter   111/  209] train: loss: 0.0715503
[Epoch 82; Iter   141/  209] train: loss: 0.0832786
[Epoch 82; Iter   171/  209] train: loss: 0.1181589
[Epoch 82; Iter   201/  209] train: loss: 0.1084487
[Epoch 82] ogbg-moltox21: 0.824412 val loss: 0.265134
[Epoch 82] ogbg-moltox21: 0.832965 test loss: 0.249565
[Epoch 83; Iter    22/  209] train: loss: 0.1085417
[Epoch 83; Iter    52/  209] train: loss: 0.0694183
[Epoch 83; Iter    82/  209] train: loss: 0.0841029
[Epoch 83; Iter   112/  209] train: loss: 0.1365894
[Epoch 83; Iter   142/  209] train: loss: 0.0511544
[Epoch 83; Iter   172/  209] train: loss: 0.0495497
[Epoch 83; Iter   202/  209] train: loss: 0.0611491
[Epoch 83] ogbg-moltox21: 0.821822 val loss: 0.268956
[Epoch 83] ogbg-moltox21: 0.827823 test loss: 0.252773
[Epoch 84; Iter    23/  209] train: loss: 0.0515653
[Epoch 84; Iter    53/  209] train: loss: 0.0574373
[Epoch 84; Iter    83/  209] train: loss: 0.1254158
[Epoch 84; Iter   113/  209] train: loss: 0.0495176
[Epoch 84; Iter   143/  209] train: loss: 0.0311257
[Epoch 84; Iter   173/  209] train: loss: 0.0689109
[Epoch 84; Iter   203/  209] train: loss: 0.2061470
[Epoch 84] ogbg-moltox21: 0.829334 val loss: 0.269731
[Epoch 84] ogbg-moltox21: 0.835165 test loss: 0.248712
[Epoch 85; Iter    24/  209] train: loss: 0.0752260
[Epoch 85; Iter    54/  209] train: loss: 0.1105702
[Epoch 85; Iter    84/  209] train: loss: 0.0499117
[Epoch 85; Iter   114/  209] train: loss: 0.1148110
[Epoch 85; Iter   144/  209] train: loss: 0.0574971
[Epoch 85; Iter   174/  209] train: loss: 0.0751767
[Epoch 85; Iter   204/  209] train: loss: 0.0930390
[Epoch 85] ogbg-moltox21: 0.824584 val loss: 0.266519
[Epoch 85] ogbg-moltox21: 0.830888 test loss: 0.260670
[Epoch 86; Iter    25/  209] train: loss: 0.0825951
[Epoch 86; Iter    55/  209] train: loss: 0.1013131
[Epoch 86; Iter    85/  209] train: loss: 0.0507411
[Epoch 86; Iter   115/  209] train: loss: 0.1284368
[Epoch 86; Iter   145/  209] train: loss: 0.0707537
[Epoch 86; Iter   175/  209] train: loss: 0.0757483
[Epoch 86; Iter   205/  209] train: loss: 0.0689249
[Epoch 86] ogbg-moltox21: 0.833133 val loss: 0.273004
[Epoch 86] ogbg-moltox21: 0.830613 test loss: 0.247867
[Epoch 87; Iter    26/  209] train: loss: 0.0792489
[Epoch 87; Iter    56/  209] train: loss: 0.0619527
[Epoch 87; Iter    86/  209] train: loss: 0.0878815
[Epoch 87; Iter   116/  209] train: loss: 0.0530109
[Epoch 87; Iter   146/  209] train: loss: 0.0703467
[Epoch 87; Iter   176/  209] train: loss: 0.0683703
[Epoch 87; Iter   206/  209] train: loss: 0.0665580
[Epoch 87] ogbg-moltox21: 0.823905 val loss: 0.278861
[Epoch 87] ogbg-moltox21: 0.827574 test loss: 0.261281
[Epoch 88; Iter    27/  209] train: loss: 0.0578620
[Epoch 88; Iter    57/  209] train: loss: 0.0744873
[Epoch 88; Iter    87/  209] train: loss: 0.0803954
[Epoch 88; Iter   117/  209] train: loss: 0.0791038
[Epoch 88; Iter   147/  209] train: loss: 0.0739046
[Epoch 88; Iter   177/  209] train: loss: 0.0603802
[Epoch 88; Iter   207/  209] train: loss: 0.0813983
[Epoch 88] ogbg-moltox21: 0.828067 val loss: 0.276279
[Epoch 88] ogbg-moltox21: 0.836500 test loss: 0.252056
[Epoch 89; Iter    28/  209] train: loss: 0.0568664
[Epoch 89; Iter    58/  209] train: loss: 0.0389409
[Epoch 89; Iter    88/  209] train: loss: 0.0605203
[Epoch 89; Iter   118/  209] train: loss: 0.0599189
[Epoch 89; Iter   148/  209] train: loss: 0.0479685
[Epoch 89; Iter   178/  209] train: loss: 0.1304138
[Epoch 89; Iter   208/  209] train: loss: 0.0916476
[Epoch 89] ogbg-moltox21: 0.819796 val loss: 0.285663
[Epoch 89] ogbg-moltox21: 0.829245 test loss: 0.257871
[Epoch 90; Iter    29/  209] train: loss: 0.0431213
[Epoch 90; Iter    59/  209] train: loss: 0.0859723
[Epoch 90; Iter    89/  209] train: loss: 0.0476571
[Epoch 90; Iter   119/  209] train: loss: 0.0849971
[Epoch 90; Iter   149/  209] train: loss: 0.0636711
[Epoch 90; Iter   179/  209] train: loss: 0.0685271
[Epoch 90; Iter   209/  209] train: loss: 0.0646038
[Epoch 90] ogbg-moltox21: 0.824321 val loss: 0.280317
[Epoch 90] ogbg-moltox21: 0.831510 test loss: 0.259557
[Epoch 91; Iter    30/  209] train: loss: 0.0544964
[Epoch 91; Iter    60/  209] train: loss: 0.0610885
[Epoch 91; Iter    90/  209] train: loss: 0.0464454
[Epoch 91; Iter   120/  209] train: loss: 0.0537816
[Epoch 91; Iter   150/  209] train: loss: 0.0623052
[Epoch 91; Iter   180/  209] train: loss: 0.0781479
[Epoch 91] ogbg-moltox21: 0.822402 val loss: 0.285463
[Epoch 91] ogbg-moltox21: 0.828447 test loss: 0.265523
[Epoch 92; Iter     1/  209] train: loss: 0.0815176
[Epoch 92; Iter    31/  209] train: loss: 0.0717648
[Epoch 92; Iter    61/  209] train: loss: 0.0398323
[Epoch 92; Iter    91/  209] train: loss: 0.0611605
[Epoch 92; Iter   121/  209] train: loss: 0.0947893
[Epoch 92; Iter   151/  209] train: loss: 0.0468304
[Epoch 92; Iter   181/  209] train: loss: 0.1352276
[Epoch 92] ogbg-moltox21: 0.822487 val loss: 0.287495
[Epoch 92] ogbg-moltox21: 0.825137 test loss: 0.266816
[Epoch 93; Iter     2/  209] train: loss: 0.0854493
[Epoch 93; Iter    32/  209] train: loss: 0.0806403
[Epoch 93; Iter    62/  209] train: loss: 0.0466926
[Epoch 93; Iter    92/  209] train: loss: 0.0944213
[Epoch 93; Iter   122/  209] train: loss: 0.0438464
[Epoch 93; Iter   152/  209] train: loss: 0.0797197
[Epoch 93; Iter   182/  209] train: loss: 0.0452852
[Epoch 93] ogbg-moltox21: 0.822504 val loss: 0.287606
[Epoch 93] ogbg-moltox21: 0.825798 test loss: 0.262339
[Epoch 94; Iter     3/  209] train: loss: 0.0649096
[Epoch 94; Iter    33/  209] train: loss: 0.0499078
[Epoch 94; Iter    63/  209] train: loss: 0.1462160
[Epoch 94; Iter    93/  209] train: loss: 0.0690061
[Epoch 94; Iter   123/  209] train: loss: 0.0686222
[Epoch 94; Iter   153/  209] train: loss: 0.0337354
[Epoch 94; Iter   183/  209] train: loss: 0.0736919
[Epoch 94] ogbg-moltox21: 0.817773 val loss: 0.294382
[Epoch 94] ogbg-moltox21: 0.821314 test loss: 0.275519
[Epoch 95; Iter     4/  209] train: loss: 0.0401099
[Epoch 95; Iter    34/  209] train: loss: 0.0882302
[Epoch 95; Iter    64/  209] train: loss: 0.0571585
[Epoch 95; Iter    94/  209] train: loss: 0.0534008
[Epoch 95; Iter   124/  209] train: loss: 0.0423671
[Epoch 95; Iter   154/  209] train: loss: 0.0502312
[Epoch 95; Iter   184/  209] train: loss: 0.0664688
[Epoch 95] ogbg-moltox21: 0.824329 val loss: 0.284890
[Epoch 95] ogbg-moltox21: 0.829283 test loss: 0.270359
[Epoch 96; Iter     5/  209] train: loss: 0.0416865
[Epoch 96; Iter    35/  209] train: loss: 0.0393205
[Epoch 96; Iter    65/  209] train: loss: 0.0930912
[Epoch 96; Iter    95/  209] train: loss: 0.0420359
[Epoch 96; Iter   125/  209] train: loss: 0.0539154
[Epoch 96; Iter   155/  209] train: loss: 0.0994850
[Epoch 96; Iter   185/  209] train: loss: 0.0986666
[Epoch 96] ogbg-moltox21: 0.818996 val loss: 0.296217
[Epoch 96] ogbg-moltox21: 0.825090 test loss: 0.274944
[Epoch 97; Iter     6/  209] train: loss: 0.0946094
[Epoch 97; Iter    36/  209] train: loss: 0.0690624
[Epoch 97; Iter    66/  209] train: loss: 0.1029415
[Epoch 97; Iter    96/  209] train: loss: 0.0691623
[Epoch 97; Iter   126/  209] train: loss: 0.0507136
[Epoch 97; Iter   156/  209] train: loss: 0.0607443
[Epoch 97; Iter   186/  209] train: loss: 0.0487443
[Epoch 97] ogbg-moltox21: 0.821023 val loss: 0.293065
[Epoch 97] ogbg-moltox21: 0.825207 test loss: 0.269668
[Epoch 98; Iter     7/  209] train: loss: 0.0419427
[Epoch 98; Iter    37/  209] train: loss: 0.0649666
[Epoch 98; Iter    67/  209] train: loss: 0.0266510
[Epoch 98; Iter    97/  209] train: loss: 0.0443098
[Epoch 98; Iter   127/  209] train: loss: 0.0494054
[Epoch 98; Iter   157/  209] train: loss: 0.0979082
[Epoch 98; Iter   187/  209] train: loss: 0.0342832
[Epoch 98] ogbg-moltox21: 0.811670 val loss: 0.298365
[Epoch 98] ogbg-moltox21: 0.827096 test loss: 0.270334
[Epoch 99; Iter     8/  209] train: loss: 0.0480644
[Epoch 99; Iter    38/  209] train: loss: 0.0509746
[Epoch 99; Iter    68/  209] train: loss: 0.0446345
[Epoch 99; Iter    98/  209] train: loss: 0.0382367
[Epoch 90] ogbg-moltox21: 0.809339 val loss: 0.239696
[Epoch 90] ogbg-moltox21: 0.831526 test loss: 0.231861
[Epoch 91; Iter    30/  183] train: loss: 0.0917025
[Epoch 91; Iter    60/  183] train: loss: 0.1021833
[Epoch 91; Iter    90/  183] train: loss: 0.0723259
[Epoch 91; Iter   120/  183] train: loss: 0.0677807
[Epoch 91; Iter   150/  183] train: loss: 0.0671641
[Epoch 91; Iter   180/  183] train: loss: 0.0763905
[Epoch 91] ogbg-moltox21: 0.811142 val loss: 0.231733
[Epoch 91] ogbg-moltox21: 0.831534 test loss: 0.231726
[Epoch 92; Iter    27/  183] train: loss: 0.0996813
[Epoch 92; Iter    57/  183] train: loss: 0.1529147
[Epoch 92; Iter    87/  183] train: loss: 0.0974953
[Epoch 92; Iter   117/  183] train: loss: 0.0727323
[Epoch 92; Iter   147/  183] train: loss: 0.0739270
[Epoch 92; Iter   177/  183] train: loss: 0.0797208
[Epoch 92] ogbg-moltox21: 0.814342 val loss: 0.234554
[Epoch 92] ogbg-moltox21: 0.830995 test loss: 0.235890
[Epoch 93; Iter    24/  183] train: loss: 0.1107845
[Epoch 93; Iter    54/  183] train: loss: 0.0910053
[Epoch 93; Iter    84/  183] train: loss: 0.0821891
[Epoch 93; Iter   114/  183] train: loss: 0.0994494
[Epoch 93; Iter   144/  183] train: loss: 0.0655173
[Epoch 93; Iter   174/  183] train: loss: 0.1331868
[Epoch 93] ogbg-moltox21: 0.812205 val loss: 0.234750
[Epoch 93] ogbg-moltox21: 0.832326 test loss: 0.233340
[Epoch 94; Iter    21/  183] train: loss: 0.0783156
[Epoch 94; Iter    51/  183] train: loss: 0.0916200
[Epoch 94; Iter    81/  183] train: loss: 0.0646761
[Epoch 94; Iter   111/  183] train: loss: 0.0729588
[Epoch 94; Iter   141/  183] train: loss: 0.0631820
[Epoch 94; Iter   171/  183] train: loss: 0.1486931
[Epoch 94] ogbg-moltox21: 0.811407 val loss: 0.227923
[Epoch 94] ogbg-moltox21: 0.827244 test loss: 0.232507
[Epoch 95; Iter    18/  183] train: loss: 0.1061631
[Epoch 95; Iter    48/  183] train: loss: 0.0908574
[Epoch 95; Iter    78/  183] train: loss: 0.0731494
[Epoch 95; Iter   108/  183] train: loss: 0.1082597
[Epoch 95; Iter   138/  183] train: loss: 0.0839289
[Epoch 95; Iter   168/  183] train: loss: 0.0641735
[Epoch 95] ogbg-moltox21: 0.812234 val loss: 0.233115
[Epoch 95] ogbg-moltox21: 0.826237 test loss: 0.237660
[Epoch 96; Iter    15/  183] train: loss: 0.0653684
[Epoch 96; Iter    45/  183] train: loss: 0.0645197
[Epoch 96; Iter    75/  183] train: loss: 0.0726870
[Epoch 96; Iter   105/  183] train: loss: 0.0842972
[Epoch 96; Iter   135/  183] train: loss: 0.0821368
[Epoch 96; Iter   165/  183] train: loss: 0.1135850
[Epoch 96] ogbg-moltox21: 0.809603 val loss: 0.237137
[Epoch 96] ogbg-moltox21: 0.826423 test loss: 0.236426
[Epoch 97; Iter    12/  183] train: loss: 0.0842447
[Epoch 97; Iter    42/  183] train: loss: 0.0489275
[Epoch 97; Iter    72/  183] train: loss: 0.0601328
[Epoch 97; Iter   102/  183] train: loss: 0.1150723
[Epoch 97; Iter   132/  183] train: loss: 0.0865988
[Epoch 97; Iter   162/  183] train: loss: 0.0988329
[Epoch 97] ogbg-moltox21: 0.804567 val loss: 0.248546
[Epoch 97] ogbg-moltox21: 0.821572 test loss: 0.254068
[Epoch 98; Iter     9/  183] train: loss: 0.0489137
[Epoch 98; Iter    39/  183] train: loss: 0.1151353
[Epoch 98; Iter    69/  183] train: loss: 0.0851122
[Epoch 98; Iter    99/  183] train: loss: 0.0494707
[Epoch 98; Iter   129/  183] train: loss: 0.1228654
[Epoch 98; Iter   159/  183] train: loss: 0.0887417
[Epoch 98] ogbg-moltox21: 0.807997 val loss: 0.234511
[Epoch 98] ogbg-moltox21: 0.821165 test loss: 0.242847
[Epoch 99; Iter     6/  183] train: loss: 0.0828419
[Epoch 99; Iter    36/  183] train: loss: 0.0970227
[Epoch 99; Iter    66/  183] train: loss: 0.1479763
[Epoch 99; Iter    96/  183] train: loss: 0.0605947
[Epoch 99; Iter   126/  183] train: loss: 0.0583581
[Epoch 99; Iter   156/  183] train: loss: 0.1252548
[Epoch 99] ogbg-moltox21: 0.806642 val loss: 0.273281
[Epoch 99] ogbg-moltox21: 0.825091 test loss: 0.275712
[Epoch 100; Iter     3/  183] train: loss: 0.0412173
[Epoch 100; Iter    33/  183] train: loss: 0.0569488
[Epoch 100; Iter    63/  183] train: loss: 0.0613497
[Epoch 100; Iter    93/  183] train: loss: 0.0378655
[Epoch 100; Iter   123/  183] train: loss: 0.1036953
[Epoch 100; Iter   153/  183] train: loss: 0.0965069
[Epoch 100; Iter   183/  183] train: loss: 0.0928805
[Epoch 100] ogbg-moltox21: 0.806583 val loss: 0.236544
[Epoch 100] ogbg-moltox21: 0.826236 test loss: 0.237924
[Epoch 101; Iter    30/  183] train: loss: 0.0492251
[Epoch 101; Iter    60/  183] train: loss: 0.0922895
[Epoch 101; Iter    90/  183] train: loss: 0.0482909
[Epoch 101; Iter   120/  183] train: loss: 0.1005061
[Epoch 101; Iter   150/  183] train: loss: 0.1082947
[Epoch 101; Iter   180/  183] train: loss: 0.0906211
[Epoch 101] ogbg-moltox21: 0.804330 val loss: 0.238505
[Epoch 101] ogbg-moltox21: 0.826564 test loss: 0.240826
[Epoch 102; Iter    27/  183] train: loss: 0.0495661
[Epoch 102; Iter    57/  183] train: loss: 0.0978086
[Epoch 102; Iter    87/  183] train: loss: 0.0504208
[Epoch 102; Iter   117/  183] train: loss: 0.1084395
[Epoch 102; Iter   147/  183] train: loss: 0.0706427
[Epoch 102; Iter   177/  183] train: loss: 0.1023587
[Epoch 102] ogbg-moltox21: 0.808497 val loss: 0.240330
[Epoch 102] ogbg-moltox21: 0.827849 test loss: 0.241871
[Epoch 103; Iter    24/  183] train: loss: 0.0552510
[Epoch 103; Iter    54/  183] train: loss: 0.1116117
[Epoch 103; Iter    84/  183] train: loss: 0.0511020
[Epoch 103; Iter   114/  183] train: loss: 0.0789320
[Epoch 103; Iter   144/  183] train: loss: 0.0555481
[Epoch 103; Iter   174/  183] train: loss: 0.0823458
[Epoch 103] ogbg-moltox21: 0.809547 val loss: 0.244311
[Epoch 103] ogbg-moltox21: 0.831611 test loss: 0.241511
[Epoch 104; Iter    21/  183] train: loss: 0.0675398
[Epoch 104; Iter    51/  183] train: loss: 0.0563124
[Epoch 104; Iter    81/  183] train: loss: 0.0926938
[Epoch 104; Iter   111/  183] train: loss: 0.0685924
[Epoch 104; Iter   141/  183] train: loss: 0.0559391
[Epoch 104; Iter   171/  183] train: loss: 0.0574757
[Epoch 104] ogbg-moltox21: 0.812061 val loss: 0.237984
[Epoch 104] ogbg-moltox21: 0.828905 test loss: 0.246413
[Epoch 105; Iter    18/  183] train: loss: 0.0637931
[Epoch 105; Iter    48/  183] train: loss: 0.0782353
[Epoch 105; Iter    78/  183] train: loss: 0.0933838
[Epoch 105; Iter   108/  183] train: loss: 0.2204987
[Epoch 105; Iter   138/  183] train: loss: 0.0894904
[Epoch 105; Iter   168/  183] train: loss: 0.0846097
[Epoch 105] ogbg-moltox21: 0.806887 val loss: 0.270513
[Epoch 105] ogbg-moltox21: 0.822385 test loss: 0.278560
[Epoch 106; Iter    15/  183] train: loss: 0.1243099
[Epoch 106; Iter    45/  183] train: loss: 0.0513241
[Epoch 106; Iter    75/  183] train: loss: 0.1440491
[Epoch 106; Iter   105/  183] train: loss: 0.0859575
[Epoch 106; Iter   135/  183] train: loss: 0.0606626
[Epoch 106; Iter   165/  183] train: loss: 0.0829095
[Epoch 106] ogbg-moltox21: 0.808263 val loss: 0.247571
[Epoch 106] ogbg-moltox21: 0.819242 test loss: 0.257647
[Epoch 107; Iter    12/  183] train: loss: 0.1587155
[Epoch 107; Iter    42/  183] train: loss: 0.0478184
[Epoch 107; Iter    72/  183] train: loss: 0.0791499
[Epoch 107; Iter   102/  183] train: loss: 0.0707860
[Epoch 107; Iter   132/  183] train: loss: 0.0668819
[Epoch 107; Iter   162/  183] train: loss: 0.0435375
[Epoch 107] ogbg-moltox21: 0.808982 val loss: 0.243359
[Epoch 107] ogbg-moltox21: 0.823175 test loss: 0.248322
[Epoch 108; Iter     9/  183] train: loss: 0.1153255
[Epoch 108; Iter    39/  183] train: loss: 0.0533686
[Epoch 108; Iter    69/  183] train: loss: 0.0615451
[Epoch 108; Iter    99/  183] train: loss: 0.0712121
[Epoch 108; Iter   129/  183] train: loss: 0.0788029
[Epoch 108; Iter   159/  183] train: loss: 0.0840670
[Epoch 108] ogbg-moltox21: 0.808333 val loss: 0.243909
[Epoch 108] ogbg-moltox21: 0.826756 test loss: 0.249875
[Epoch 109; Iter     6/  183] train: loss: 0.0615452
[Epoch 109; Iter    36/  183] train: loss: 0.0856807
[Epoch 109; Iter    66/  183] train: loss: 0.1191920
[Epoch 109; Iter    96/  183] train: loss: 0.1272169
[Epoch 109; Iter   126/  183] train: loss: 0.0640698
[Epoch 109; Iter   156/  183] train: loss: 0.0687044
[Epoch 109] ogbg-moltox21: 0.808145 val loss: 0.252378
[Epoch 90] ogbg-moltox21: 0.808136 val loss: 0.246924
[Epoch 90] ogbg-moltox21: 0.827538 test loss: 0.240683
[Epoch 91; Iter    30/  183] train: loss: 0.0626303
[Epoch 91; Iter    60/  183] train: loss: 0.1117217
[Epoch 91; Iter    90/  183] train: loss: 0.0995832
[Epoch 91; Iter   120/  183] train: loss: 0.0461151
[Epoch 91; Iter   150/  183] train: loss: 0.0514235
[Epoch 91; Iter   180/  183] train: loss: 0.0648333
[Epoch 91] ogbg-moltox21: 0.806824 val loss: 0.246406
[Epoch 91] ogbg-moltox21: 0.819620 test loss: 0.242531
[Epoch 92; Iter    27/  183] train: loss: 0.0657283
[Epoch 92; Iter    57/  183] train: loss: 0.0663122
[Epoch 92; Iter    87/  183] train: loss: 0.0712092
[Epoch 92; Iter   117/  183] train: loss: 0.0581746
[Epoch 92; Iter   147/  183] train: loss: 0.0672439
[Epoch 92; Iter   177/  183] train: loss: 0.0584416
[Epoch 92] ogbg-moltox21: 0.808339 val loss: 0.252535
[Epoch 92] ogbg-moltox21: 0.826684 test loss: 0.246070
[Epoch 93; Iter    24/  183] train: loss: 0.0499187
[Epoch 93; Iter    54/  183] train: loss: 0.0656034
[Epoch 93; Iter    84/  183] train: loss: 0.0504826
[Epoch 93; Iter   114/  183] train: loss: 0.0893922
[Epoch 93; Iter   144/  183] train: loss: 0.0725849
[Epoch 93; Iter   174/  183] train: loss: 0.0769947
[Epoch 93] ogbg-moltox21: 0.805340 val loss: 0.254299
[Epoch 93] ogbg-moltox21: 0.820577 test loss: 0.251927
[Epoch 94; Iter    21/  183] train: loss: 0.0392838
[Epoch 94; Iter    51/  183] train: loss: 0.0328032
[Epoch 94; Iter    81/  183] train: loss: 0.0662862
[Epoch 94; Iter   111/  183] train: loss: 0.0510167
[Epoch 94; Iter   141/  183] train: loss: 0.0677051
[Epoch 94; Iter   171/  183] train: loss: 0.0443379
[Epoch 94] ogbg-moltox21: 0.811003 val loss: 0.250384
[Epoch 94] ogbg-moltox21: 0.825546 test loss: 0.242731
[Epoch 95; Iter    18/  183] train: loss: 0.0741957
[Epoch 95; Iter    48/  183] train: loss: 0.0856082
[Epoch 95; Iter    78/  183] train: loss: 0.0580690
[Epoch 95; Iter   108/  183] train: loss: 0.0855918
[Epoch 95; Iter   138/  183] train: loss: 0.0907810
[Epoch 95; Iter   168/  183] train: loss: 0.0806663
[Epoch 95] ogbg-moltox21: 0.807230 val loss: 0.252157
[Epoch 95] ogbg-moltox21: 0.825267 test loss: 0.248751
[Epoch 96; Iter    15/  183] train: loss: 0.0454809
[Epoch 96; Iter    45/  183] train: loss: 0.0784057
[Epoch 96; Iter    75/  183] train: loss: 0.0382711
[Epoch 96; Iter   105/  183] train: loss: 0.0537441
[Epoch 96; Iter   135/  183] train: loss: 0.0608370
[Epoch 96; Iter   165/  183] train: loss: 0.0807293
[Epoch 96] ogbg-moltox21: 0.803349 val loss: 0.258410
[Epoch 96] ogbg-moltox21: 0.817309 test loss: 0.347041
[Epoch 97; Iter    12/  183] train: loss: 0.0695067
[Epoch 97; Iter    42/  183] train: loss: 0.0642644
[Epoch 97; Iter    72/  183] train: loss: 0.0686984
[Epoch 97; Iter   102/  183] train: loss: 0.0654525
[Epoch 97; Iter   132/  183] train: loss: 0.0469795
[Epoch 97; Iter   162/  183] train: loss: 0.1010886
[Epoch 97] ogbg-moltox21: 0.808911 val loss: 0.253350
[Epoch 97] ogbg-moltox21: 0.827615 test loss: 0.247626
[Epoch 98; Iter     9/  183] train: loss: 0.0554963
[Epoch 98; Iter    39/  183] train: loss: 0.0372989
[Epoch 98; Iter    69/  183] train: loss: 0.1176038
[Epoch 98; Iter    99/  183] train: loss: 0.1085015
[Epoch 98; Iter   129/  183] train: loss: 0.1169882
[Epoch 98; Iter   159/  183] train: loss: 0.0606966
[Epoch 98] ogbg-moltox21: 0.802853 val loss: 0.261909
[Epoch 98] ogbg-moltox21: 0.817612 test loss: 0.261911
[Epoch 99; Iter     6/  183] train: loss: 0.0795304
[Epoch 99; Iter    36/  183] train: loss: 0.0980317
[Epoch 99; Iter    66/  183] train: loss: 0.0535543
[Epoch 99; Iter    96/  183] train: loss: 0.0792706
[Epoch 99; Iter   126/  183] train: loss: 0.0653213
[Epoch 99; Iter   156/  183] train: loss: 0.0664920
[Epoch 99] ogbg-moltox21: 0.804605 val loss: 0.261072
[Epoch 99] ogbg-moltox21: 0.821859 test loss: 0.257946
[Epoch 100; Iter     3/  183] train: loss: 0.0871253
[Epoch 100; Iter    33/  183] train: loss: 0.0726256
[Epoch 100; Iter    63/  183] train: loss: 0.0346976
[Epoch 100; Iter    93/  183] train: loss: 0.0516535
[Epoch 100; Iter   123/  183] train: loss: 0.0701985
[Epoch 100; Iter   153/  183] train: loss: 0.0770333
[Epoch 100; Iter   183/  183] train: loss: 0.0726630
[Epoch 100] ogbg-moltox21: 0.804104 val loss: 0.263186
[Epoch 100] ogbg-moltox21: 0.816843 test loss: 0.308344
[Epoch 101; Iter    30/  183] train: loss: 0.0462919
[Epoch 101; Iter    60/  183] train: loss: 0.0629686
[Epoch 101; Iter    90/  183] train: loss: 0.0676882
[Epoch 101; Iter   120/  183] train: loss: 0.0553070
[Epoch 101; Iter   150/  183] train: loss: 0.0482337
[Epoch 101; Iter   180/  183] train: loss: 0.0490796
[Epoch 101] ogbg-moltox21: 0.807399 val loss: 0.266073
[Epoch 101] ogbg-moltox21: 0.817926 test loss: 0.265076
[Epoch 102; Iter    27/  183] train: loss: 0.0476653
[Epoch 102; Iter    57/  183] train: loss: 0.1045244
[Epoch 102; Iter    87/  183] train: loss: 0.0495373
[Epoch 102; Iter   117/  183] train: loss: 0.0566690
[Epoch 102; Iter   147/  183] train: loss: 0.0647063
[Epoch 102; Iter   177/  183] train: loss: 0.0393318
[Epoch 102] ogbg-moltox21: 0.804608 val loss: 0.267843
[Epoch 102] ogbg-moltox21: 0.821923 test loss: 0.261043
[Epoch 103; Iter    24/  183] train: loss: 0.0840005
[Epoch 103; Iter    54/  183] train: loss: 0.0849302
[Epoch 103; Iter    84/  183] train: loss: 0.0480915
[Epoch 103; Iter   114/  183] train: loss: 0.0620028
[Epoch 103; Iter   144/  183] train: loss: 0.0465248
[Epoch 103; Iter   174/  183] train: loss: 0.0713926
[Epoch 103] ogbg-moltox21: 0.806182 val loss: 0.262708
[Epoch 103] ogbg-moltox21: 0.820404 test loss: 0.260998
[Epoch 104; Iter    21/  183] train: loss: 0.0771171
[Epoch 104; Iter    51/  183] train: loss: 0.0509950
[Epoch 104; Iter    81/  183] train: loss: 0.1087747
[Epoch 104; Iter   111/  183] train: loss: 0.0339396
[Epoch 104; Iter   141/  183] train: loss: 0.0313379
[Epoch 104; Iter   171/  183] train: loss: 0.0868323
[Epoch 104] ogbg-moltox21: 0.802521 val loss: 0.262236
[Epoch 104] ogbg-moltox21: 0.818703 test loss: 0.258279
[Epoch 105; Iter    18/  183] train: loss: 0.0284562
[Epoch 105; Iter    48/  183] train: loss: 0.0680149
[Epoch 105; Iter    78/  183] train: loss: 0.0420580
[Epoch 105; Iter   108/  183] train: loss: 0.0612694
[Epoch 105; Iter   138/  183] train: loss: 0.0649330
[Epoch 105; Iter   168/  183] train: loss: 0.1167214
[Epoch 105] ogbg-moltox21: 0.804001 val loss: 0.270794
[Epoch 105] ogbg-moltox21: 0.817740 test loss: 0.263443
[Epoch 106; Iter    15/  183] train: loss: 0.0637721
[Epoch 106; Iter    45/  183] train: loss: 0.0556053
[Epoch 106; Iter    75/  183] train: loss: 0.0711671
[Epoch 106; Iter   105/  183] train: loss: 0.0461986
[Epoch 106; Iter   135/  183] train: loss: 0.0590750
[Epoch 106; Iter   165/  183] train: loss: 0.0412939
[Epoch 106] ogbg-moltox21: 0.804215 val loss: 0.266682
[Epoch 106] ogbg-moltox21: 0.821359 test loss: 0.260239
[Epoch 107; Iter    12/  183] train: loss: 0.0449511
[Epoch 107; Iter    42/  183] train: loss: 0.0721111
[Epoch 107; Iter    72/  183] train: loss: 0.0773193
[Epoch 107; Iter   102/  183] train: loss: 0.0424032
[Epoch 107; Iter   132/  183] train: loss: 0.0506112
[Epoch 107; Iter   162/  183] train: loss: 0.0621329
[Epoch 107] ogbg-moltox21: 0.805205 val loss: 0.267962
[Epoch 107] ogbg-moltox21: 0.823901 test loss: 0.263295
[Epoch 108; Iter     9/  183] train: loss: 0.0784501
[Epoch 108; Iter    39/  183] train: loss: 0.0402752
[Epoch 108; Iter    69/  183] train: loss: 0.0470192
[Epoch 108; Iter    99/  183] train: loss: 0.0444020
[Epoch 108; Iter   129/  183] train: loss: 0.0661075
[Epoch 108; Iter   159/  183] train: loss: 0.0770296
[Epoch 108] ogbg-moltox21: 0.801314 val loss: 0.271922
[Epoch 108] ogbg-moltox21: 0.814444 test loss: 0.267395
[Epoch 109; Iter     6/  183] train: loss: 0.0324687
[Epoch 109; Iter    36/  183] train: loss: 0.0660527
[Epoch 109; Iter    66/  183] train: loss: 0.0504653
[Epoch 109; Iter    96/  183] train: loss: 0.0372713
[Epoch 109; Iter   126/  183] train: loss: 0.0342823
[Epoch 109; Iter   156/  183] train: loss: 0.0854841
[Epoch 109] ogbg-moltox21: 0.802083 val loss: 0.272644
[Epoch 90] ogbg-moltox21: 0.817540 val loss: 0.269298
[Epoch 90] ogbg-moltox21: 0.815306 test loss: 0.285099
[Epoch 91; Iter    30/  183] train: loss: 0.0360297
[Epoch 91; Iter    60/  183] train: loss: 0.0380814
[Epoch 91; Iter    90/  183] train: loss: 0.0748614
[Epoch 91; Iter   120/  183] train: loss: 0.0302385
[Epoch 91; Iter   150/  183] train: loss: 0.0764294
[Epoch 91; Iter   180/  183] train: loss: 0.0441014
[Epoch 91] ogbg-moltox21: 0.815264 val loss: 0.271518
[Epoch 91] ogbg-moltox21: 0.815538 test loss: 0.287750
[Epoch 92; Iter    27/  183] train: loss: 0.0834263
[Epoch 92; Iter    57/  183] train: loss: 0.0376693
[Epoch 92; Iter    87/  183] train: loss: 0.0558925
[Epoch 92; Iter   117/  183] train: loss: 0.0564156
[Epoch 92; Iter   147/  183] train: loss: 0.0328779
[Epoch 92; Iter   177/  183] train: loss: 0.0320856
[Epoch 92] ogbg-moltox21: 0.810098 val loss: 0.269822
[Epoch 92] ogbg-moltox21: 0.818742 test loss: 0.284173
[Epoch 93; Iter    24/  183] train: loss: 0.0460835
[Epoch 93; Iter    54/  183] train: loss: 0.0931448
[Epoch 93; Iter    84/  183] train: loss: 0.0477962
[Epoch 93; Iter   114/  183] train: loss: 0.0429381
[Epoch 93; Iter   144/  183] train: loss: 0.0494871
[Epoch 93; Iter   174/  183] train: loss: 0.0543351
[Epoch 93] ogbg-moltox21: 0.813166 val loss: 0.277698
[Epoch 93] ogbg-moltox21: 0.812076 test loss: 0.295388
[Epoch 94; Iter    21/  183] train: loss: 0.0320815
[Epoch 94; Iter    51/  183] train: loss: 0.0602087
[Epoch 94; Iter    81/  183] train: loss: 0.0522091
[Epoch 94; Iter   111/  183] train: loss: 0.0559305
[Epoch 94; Iter   141/  183] train: loss: 0.0399422
[Epoch 94; Iter   171/  183] train: loss: 0.0424793
[Epoch 94] ogbg-moltox21: 0.814619 val loss: 0.279669
[Epoch 94] ogbg-moltox21: 0.816409 test loss: 0.290101
[Epoch 95; Iter    18/  183] train: loss: 0.0258203
[Epoch 95; Iter    48/  183] train: loss: 0.0431650
[Epoch 95; Iter    78/  183] train: loss: 0.0814178
[Epoch 95; Iter   108/  183] train: loss: 0.0591843
[Epoch 95; Iter   138/  183] train: loss: 0.0564350
[Epoch 95; Iter   168/  183] train: loss: 0.0300755
[Epoch 95] ogbg-moltox21: 0.816802 val loss: 0.278599
[Epoch 95] ogbg-moltox21: 0.818543 test loss: 0.289594
[Epoch 96; Iter    15/  183] train: loss: 0.0409034
[Epoch 96; Iter    45/  183] train: loss: 0.0497082
[Epoch 96; Iter    75/  183] train: loss: 0.0391054
[Epoch 96; Iter   105/  183] train: loss: 0.0832998
[Epoch 96; Iter   135/  183] train: loss: 0.0903409
[Epoch 96; Iter   165/  183] train: loss: 0.0761132
[Epoch 96] ogbg-moltox21: 0.814359 val loss: 0.275824
[Epoch 96] ogbg-moltox21: 0.817156 test loss: 0.286675
[Epoch 97; Iter    12/  183] train: loss: 0.0376010
[Epoch 97; Iter    42/  183] train: loss: 0.0255277
[Epoch 97; Iter    72/  183] train: loss: 0.0659985
[Epoch 97; Iter   102/  183] train: loss: 0.0446768
[Epoch 97; Iter   132/  183] train: loss: 0.0379301
[Epoch 97; Iter   162/  183] train: loss: 0.0354779
[Epoch 97] ogbg-moltox21: 0.813030 val loss: 0.280369
[Epoch 97] ogbg-moltox21: 0.813617 test loss: 0.296003
[Epoch 98; Iter     9/  183] train: loss: 0.0490346
[Epoch 98; Iter    39/  183] train: loss: 0.0405365
[Epoch 98; Iter    69/  183] train: loss: 0.0635628
[Epoch 98; Iter    99/  183] train: loss: 0.0377275
[Epoch 98; Iter   129/  183] train: loss: 0.0423843
[Epoch 98; Iter   159/  183] train: loss: 0.0315776
[Epoch 98] ogbg-moltox21: 0.814085 val loss: 0.280931
[Epoch 98] ogbg-moltox21: 0.818022 test loss: 0.291649
[Epoch 99; Iter     6/  183] train: loss: 0.0606976
[Epoch 99; Iter    36/  183] train: loss: 0.0539221
[Epoch 99; Iter    66/  183] train: loss: 0.0490873
[Epoch 99; Iter    96/  183] train: loss: 0.0852135
[Epoch 99; Iter   126/  183] train: loss: 0.0591808
[Epoch 99; Iter   156/  183] train: loss: 0.0587949
[Epoch 99] ogbg-moltox21: 0.811770 val loss: 0.278475
[Epoch 99] ogbg-moltox21: 0.816126 test loss: 0.294759
[Epoch 100; Iter     3/  183] train: loss: 0.0348047
[Epoch 100; Iter    33/  183] train: loss: 0.0571619
[Epoch 100; Iter    63/  183] train: loss: 0.0457880
[Epoch 100; Iter    93/  183] train: loss: 0.0419961
[Epoch 100; Iter   123/  183] train: loss: 0.0381813
[Epoch 100; Iter   153/  183] train: loss: 0.0743827
[Epoch 100; Iter   183/  183] train: loss: 0.0339587
[Epoch 100] ogbg-moltox21: 0.812401 val loss: 0.282581
[Epoch 100] ogbg-moltox21: 0.815263 test loss: 0.297037
[Epoch 101; Iter    30/  183] train: loss: 0.0532477
[Epoch 101; Iter    60/  183] train: loss: 0.0517601
[Epoch 101; Iter    90/  183] train: loss: 0.0463166
[Epoch 101; Iter   120/  183] train: loss: 0.0397579
[Epoch 101; Iter   150/  183] train: loss: 0.0376102
[Epoch 101; Iter   180/  183] train: loss: 0.0873722
[Epoch 101] ogbg-moltox21: 0.809874 val loss: 0.285876
[Epoch 101] ogbg-moltox21: 0.813156 test loss: 0.300663
[Epoch 102; Iter    27/  183] train: loss: 0.0506326
[Epoch 102; Iter    57/  183] train: loss: 0.0289722
[Epoch 102; Iter    87/  183] train: loss: 0.0356990
[Epoch 102; Iter   117/  183] train: loss: 0.0521872
[Epoch 102; Iter   147/  183] train: loss: 0.0439181
[Epoch 102; Iter   177/  183] train: loss: 0.0502502
[Epoch 102] ogbg-moltox21: 0.807709 val loss: 0.290451
[Epoch 102] ogbg-moltox21: 0.805422 test loss: 0.313578
[Epoch 103; Iter    24/  183] train: loss: 0.0439062
[Epoch 103; Iter    54/  183] train: loss: 0.0382559
[Epoch 103; Iter    84/  183] train: loss: 0.0519864
[Epoch 103; Iter   114/  183] train: loss: 0.0417551
[Epoch 103; Iter   144/  183] train: loss: 0.0516763
[Epoch 103; Iter   174/  183] train: loss: 0.0546846
[Epoch 103] ogbg-moltox21: 0.807677 val loss: 0.292390
[Epoch 103] ogbg-moltox21: 0.815587 test loss: 0.305712
[Epoch 104; Iter    21/  183] train: loss: 0.0341759
[Epoch 104; Iter    51/  183] train: loss: 0.0336397
[Epoch 104; Iter    81/  183] train: loss: 0.0357367
[Epoch 104; Iter   111/  183] train: loss: 0.0300273
[Epoch 104; Iter   141/  183] train: loss: 0.0378025
[Epoch 104; Iter   171/  183] train: loss: 0.0635754
[Epoch 104] ogbg-moltox21: 0.809975 val loss: 0.290553
[Epoch 104] ogbg-moltox21: 0.813969 test loss: 0.303973
[Epoch 105; Iter    18/  183] train: loss: 0.0475869
[Epoch 105; Iter    48/  183] train: loss: 0.0319509
[Epoch 105; Iter    78/  183] train: loss: 0.0621783
[Epoch 105; Iter   108/  183] train: loss: 0.0507321
[Epoch 105; Iter   138/  183] train: loss: 0.0669692
[Epoch 105; Iter   168/  183] train: loss: 0.0302949
[Epoch 105] ogbg-moltox21: 0.806834 val loss: 0.293290
[Epoch 105] ogbg-moltox21: 0.812742 test loss: 0.303220
[Epoch 106; Iter    15/  183] train: loss: 0.0288595
[Epoch 106; Iter    45/  183] train: loss: 0.0355675
[Epoch 106; Iter    75/  183] train: loss: 0.0446823
[Epoch 106; Iter   105/  183] train: loss: 0.0552203
[Epoch 106; Iter   135/  183] train: loss: 0.0342611
[Epoch 106; Iter   165/  183] train: loss: 0.0552895
[Epoch 106] ogbg-moltox21: 0.811023 val loss: 0.293473
[Epoch 106] ogbg-moltox21: 0.810936 test loss: 0.306526
[Epoch 107; Iter    12/  183] train: loss: 0.0291029
[Epoch 107; Iter    42/  183] train: loss: 0.0578969
[Epoch 107; Iter    72/  183] train: loss: 0.0527899
[Epoch 107; Iter   102/  183] train: loss: 0.0777415
[Epoch 107; Iter   132/  183] train: loss: 0.0301161
[Epoch 107; Iter   162/  183] train: loss: 0.0432043
[Epoch 107] ogbg-moltox21: 0.810969 val loss: 0.290839
[Epoch 107] ogbg-moltox21: 0.817201 test loss: 0.303776
[Epoch 108; Iter     9/  183] train: loss: 0.0591857
[Epoch 108; Iter    39/  183] train: loss: 0.0287514
[Epoch 108; Iter    69/  183] train: loss: 0.0313169
[Epoch 108; Iter    99/  183] train: loss: 0.0314554
[Epoch 108; Iter   129/  183] train: loss: 0.0467455
[Epoch 108; Iter   159/  183] train: loss: 0.0435628
[Epoch 108] ogbg-moltox21: 0.808048 val loss: 0.295900
[Epoch 108] ogbg-moltox21: 0.809253 test loss: 0.312631
[Epoch 109; Iter     6/  183] train: loss: 0.0516124
[Epoch 109; Iter    36/  183] train: loss: 0.0387733
[Epoch 109; Iter    66/  183] train: loss: 0.0492423
[Epoch 109; Iter    96/  183] train: loss: 0.0401990
[Epoch 109; Iter   126/  183] train: loss: 0.0386169
[Epoch 109; Iter   156/  183] train: loss: 0.0694308
[Epoch 109] ogbg-moltox21: 0.803480 val loss: 0.300656
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0545870
[Epoch 101] ogbg-moltox21: 0.818458 val loss: 0.234529
[Epoch 101] ogbg-moltox21: 0.815004 test loss: 0.253024
[Epoch 102; Iter    13/  157] train: loss: 0.0759279
[Epoch 102; Iter    43/  157] train: loss: 0.0738831
[Epoch 102; Iter    73/  157] train: loss: 0.0612593
[Epoch 102; Iter   103/  157] train: loss: 0.1113350
[Epoch 102; Iter   133/  157] train: loss: 0.0649436
[Epoch 102] ogbg-moltox21: 0.824684 val loss: 0.237635
[Epoch 102] ogbg-moltox21: 0.818985 test loss: 0.257919
[Epoch 103; Iter     6/  157] train: loss: 0.0628679
[Epoch 103; Iter    36/  157] train: loss: 0.0641788
[Epoch 103; Iter    66/  157] train: loss: 0.0535537
[Epoch 103; Iter    96/  157] train: loss: 0.0713418
[Epoch 103; Iter   126/  157] train: loss: 0.0392224
[Epoch 103; Iter   156/  157] train: loss: 0.0597932
[Epoch 103] ogbg-moltox21: 0.819769 val loss: 0.237193
[Epoch 103] ogbg-moltox21: 0.818296 test loss: 0.257887
[Epoch 104; Iter    29/  157] train: loss: 0.0540188
[Epoch 104; Iter    59/  157] train: loss: 0.0605563
[Epoch 104; Iter    89/  157] train: loss: 0.0370769
[Epoch 104; Iter   119/  157] train: loss: 0.0775407
[Epoch 104; Iter   149/  157] train: loss: 0.1221643
[Epoch 104] ogbg-moltox21: 0.815940 val loss: 0.242059
[Epoch 104] ogbg-moltox21: 0.818103 test loss: 0.262222
[Epoch 105; Iter    22/  157] train: loss: 0.0568177
[Epoch 105; Iter    52/  157] train: loss: 0.0527990
[Epoch 105; Iter    82/  157] train: loss: 0.0345670
[Epoch 105; Iter   112/  157] train: loss: 0.0704714
[Epoch 105; Iter   142/  157] train: loss: 0.0435709
[Epoch 105] ogbg-moltox21: 0.812945 val loss: 0.245906
[Epoch 105] ogbg-moltox21: 0.813613 test loss: 0.265125
[Epoch 106; Iter    15/  157] train: loss: 0.0629731
[Epoch 106; Iter    45/  157] train: loss: 0.0519093
[Epoch 106; Iter    75/  157] train: loss: 0.0585909
[Epoch 106; Iter   105/  157] train: loss: 0.0630536
[Epoch 106; Iter   135/  157] train: loss: 0.0442630
[Epoch 106] ogbg-moltox21: 0.814388 val loss: 0.250194
[Epoch 106] ogbg-moltox21: 0.815135 test loss: 0.262802
[Epoch 107; Iter     8/  157] train: loss: 0.0349558
[Epoch 107; Iter    38/  157] train: loss: 0.0610597
[Epoch 107; Iter    68/  157] train: loss: 0.0943856
[Epoch 107; Iter    98/  157] train: loss: 0.0632521
[Epoch 107; Iter   128/  157] train: loss: 0.0696096
[Epoch 107] ogbg-moltox21: 0.811548 val loss: 0.246290
[Epoch 107] ogbg-moltox21: 0.813865 test loss: 0.264320
[Epoch 108; Iter     1/  157] train: loss: 0.0711829
[Epoch 108; Iter    31/  157] train: loss: 0.0422075
[Epoch 108; Iter    61/  157] train: loss: 0.1041012
[Epoch 108; Iter    91/  157] train: loss: 0.0744809
[Epoch 108; Iter   121/  157] train: loss: 0.0731911
[Epoch 108; Iter   151/  157] train: loss: 0.0392065
[Epoch 108] ogbg-moltox21: 0.811214 val loss: 0.245828
[Epoch 108] ogbg-moltox21: 0.807410 test loss: 0.265256
[Epoch 109; Iter    24/  157] train: loss: 0.0471087
[Epoch 109; Iter    54/  157] train: loss: 0.1154854
[Epoch 109; Iter    84/  157] train: loss: 0.0311784
[Epoch 109; Iter   114/  157] train: loss: 0.0779668
[Epoch 109; Iter   144/  157] train: loss: 0.0429351
[Epoch 109] ogbg-moltox21: 0.815419 val loss: 0.248823
[Epoch 109] ogbg-moltox21: 0.811144 test loss: 0.269760
[Epoch 110; Iter    17/  157] train: loss: 0.0320536
[Epoch 110; Iter    47/  157] train: loss: 0.0469154
[Epoch 110; Iter    77/  157] train: loss: 0.0548228
[Epoch 110; Iter   107/  157] train: loss: 0.0569036
[Epoch 110; Iter   137/  157] train: loss: 0.0583580
[Epoch 110] ogbg-moltox21: 0.810777 val loss: 0.254146
[Epoch 110] ogbg-moltox21: 0.809991 test loss: 0.269511
[Epoch 111; Iter    10/  157] train: loss: 0.0527600
[Epoch 111; Iter    40/  157] train: loss: 0.0556268
[Epoch 111; Iter    70/  157] train: loss: 0.0565513
[Epoch 111; Iter   100/  157] train: loss: 0.1168632
[Epoch 111; Iter   130/  157] train: loss: 0.0669791
[Epoch 111] ogbg-moltox21: 0.812923 val loss: 0.253932
[Epoch 111] ogbg-moltox21: 0.813899 test loss: 0.268748
[Epoch 112; Iter     3/  157] train: loss: 0.0705782
[Epoch 112; Iter    33/  157] train: loss: 0.0490762
[Epoch 112; Iter    63/  157] train: loss: 0.0535647
[Epoch 112; Iter    93/  157] train: loss: 0.0761449
[Epoch 112; Iter   123/  157] train: loss: 0.0948462
[Epoch 112; Iter   153/  157] train: loss: 0.0348397
[Epoch 112] ogbg-moltox21: 0.814282 val loss: 0.253606
[Epoch 112] ogbg-moltox21: 0.815725 test loss: 0.268228
[Epoch 113; Iter    26/  157] train: loss: 0.0647035
[Epoch 113; Iter    56/  157] train: loss: 0.0697178
[Epoch 113; Iter    86/  157] train: loss: 0.0475450
[Epoch 113; Iter   116/  157] train: loss: 0.0653027
[Epoch 113; Iter   146/  157] train: loss: 0.0513788
[Epoch 113] ogbg-moltox21: 0.809967 val loss: 0.252496
[Epoch 113] ogbg-moltox21: 0.810175 test loss: 0.269617
[Epoch 114; Iter    19/  157] train: loss: 0.0765743
[Epoch 114; Iter    49/  157] train: loss: 0.0370243
[Epoch 114; Iter    79/  157] train: loss: 0.0538122
[Epoch 114; Iter   109/  157] train: loss: 0.1377250
[Epoch 114; Iter   139/  157] train: loss: 0.0211875
[Epoch 114] ogbg-moltox21: 0.813226 val loss: 0.256470
[Epoch 114] ogbg-moltox21: 0.816307 test loss: 0.269589
[Epoch 115; Iter    12/  157] train: loss: 0.0351892
[Epoch 115; Iter    42/  157] train: loss: 0.0651988
[Epoch 115; Iter    72/  157] train: loss: 0.0361044
[Epoch 115; Iter   102/  157] train: loss: 0.0619783
[Epoch 115; Iter   132/  157] train: loss: 0.0568088
[Epoch 115] ogbg-moltox21: 0.810970 val loss: 0.256176
[Epoch 115] ogbg-moltox21: 0.810797 test loss: 0.275397
[Epoch 116; Iter     5/  157] train: loss: 0.1015365
[Epoch 116; Iter    35/  157] train: loss: 0.0571636
[Epoch 116; Iter    65/  157] train: loss: 0.0343520
[Epoch 116; Iter    95/  157] train: loss: 0.0602973
[Epoch 116; Iter   125/  157] train: loss: 0.0385182
[Epoch 116; Iter   155/  157] train: loss: 0.0918964
[Epoch 116] ogbg-moltox21: 0.810623 val loss: 0.254448
[Epoch 116] ogbg-moltox21: 0.810189 test loss: 0.271069
[Epoch 117; Iter    28/  157] train: loss: 0.0312181
[Epoch 117; Iter    58/  157] train: loss: 0.0440241
[Epoch 117; Iter    88/  157] train: loss: 0.0905459
[Epoch 117; Iter   118/  157] train: loss: 0.0323990
[Epoch 117; Iter   148/  157] train: loss: 0.0560036
[Epoch 117] ogbg-moltox21: 0.809193 val loss: 0.255483
[Epoch 117] ogbg-moltox21: 0.807379 test loss: 0.278627
[Epoch 118; Iter    21/  157] train: loss: 0.0368125
[Epoch 118; Iter    51/  157] train: loss: 0.0823707
[Epoch 118; Iter    81/  157] train: loss: 0.0450658
[Epoch 118; Iter   111/  157] train: loss: 0.0777482
[Epoch 118; Iter   141/  157] train: loss: 0.0524193
[Epoch 118] ogbg-moltox21: 0.808627 val loss: 0.258585
[Epoch 118] ogbg-moltox21: 0.815243 test loss: 0.273067
[Epoch 119; Iter    14/  157] train: loss: 0.0282851
[Epoch 119; Iter    44/  157] train: loss: 0.0604471
[Epoch 119; Iter    74/  157] train: loss: 0.0682111
[Epoch 119; Iter   104/  157] train: loss: 0.0440155
[Epoch 119; Iter   134/  157] train: loss: 0.0636108
[Epoch 119] ogbg-moltox21: 0.804755 val loss: 0.256802
[Epoch 119] ogbg-moltox21: 0.808891 test loss: 0.270605
[Epoch 120; Iter     7/  157] train: loss: 0.0242174
[Epoch 120; Iter    37/  157] train: loss: 0.0422150
[Epoch 120; Iter    67/  157] train: loss: 0.0537646
[Epoch 120; Iter    97/  157] train: loss: 0.0342661
[Epoch 120; Iter   127/  157] train: loss: 0.0554647
[Epoch 120; Iter   157/  157] train: loss: 0.0593169
[Epoch 120] ogbg-moltox21: 0.809010 val loss: 0.258569
[Epoch 120] ogbg-moltox21: 0.812267 test loss: 0.271892
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 43.
Statistics on  val_best_checkpoint
mean_pred: -3.631101369857788
std_pred: 2.0347490310668945
mean_targets: nan
std_targets: nan
prcauc: 0.41495932908115263
rocauc: 0.8381434967911637
ogbg-moltox21: 0.8381434967911637
OGBNanLabelBCEWithLogitsLoss: 0.18606758187964278
Statistics on  test
mean_pred: -3.627094268798828
std_pred: 2.0330042839050293
mean_targets: nan
std_targets: nan
prcauc: 0.4810245476861979
rocauc: 0.8472448546397678
ogbg-moltox21: 0.8472448546397678
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0571214
[Epoch 101] ogbg-moltox21: 0.812699 val loss: 0.270720
[Epoch 101] ogbg-moltox21: 0.819344 test loss: 0.296776
[Epoch 102; Iter    13/  157] train: loss: 0.0416527
[Epoch 102; Iter    43/  157] train: loss: 0.0473664
[Epoch 102; Iter    73/  157] train: loss: 0.0405036
[Epoch 102; Iter   103/  157] train: loss: 0.0672618
[Epoch 102; Iter   133/  157] train: loss: 0.0358248
[Epoch 102] ogbg-moltox21: 0.812729 val loss: 0.268684
[Epoch 102] ogbg-moltox21: 0.820545 test loss: 0.297030
[Epoch 103; Iter     6/  157] train: loss: 0.0360876
[Epoch 103; Iter    36/  157] train: loss: 0.0666359
[Epoch 103; Iter    66/  157] train: loss: 0.0573445
[Epoch 103; Iter    96/  157] train: loss: 0.0240039
[Epoch 103; Iter   126/  157] train: loss: 0.0329877
[Epoch 103; Iter   156/  157] train: loss: 0.0466014
[Epoch 103] ogbg-moltox21: 0.815742 val loss: 0.273605
[Epoch 103] ogbg-moltox21: 0.820794 test loss: 0.306330
[Epoch 104; Iter    29/  157] train: loss: 0.0364174
[Epoch 104; Iter    59/  157] train: loss: 0.0650561
[Epoch 104; Iter    89/  157] train: loss: 0.0373685
[Epoch 104; Iter   119/  157] train: loss: 0.0717689
[Epoch 104; Iter   149/  157] train: loss: 0.0578329
[Epoch 104] ogbg-moltox21: 0.812737 val loss: 0.273867
[Epoch 104] ogbg-moltox21: 0.815801 test loss: 0.305772
[Epoch 105; Iter    22/  157] train: loss: 0.0347427
[Epoch 105; Iter    52/  157] train: loss: 0.0406820
[Epoch 105; Iter    82/  157] train: loss: 0.0484199
[Epoch 105; Iter   112/  157] train: loss: 0.0475247
[Epoch 105; Iter   142/  157] train: loss: 0.0475559
[Epoch 105] ogbg-moltox21: 0.813323 val loss: 0.274428
[Epoch 105] ogbg-moltox21: 0.815872 test loss: 0.310355
[Epoch 106; Iter    15/  157] train: loss: 0.0506696
[Epoch 106; Iter    45/  157] train: loss: 0.0185660
[Epoch 106; Iter    75/  157] train: loss: 0.0906530
[Epoch 106; Iter   105/  157] train: loss: 0.0467066
[Epoch 106; Iter   135/  157] train: loss: 0.0401373
[Epoch 106] ogbg-moltox21: 0.811225 val loss: 0.276513
[Epoch 106] ogbg-moltox21: 0.817200 test loss: 0.304289
[Epoch 107; Iter     8/  157] train: loss: 0.0448047
[Epoch 107; Iter    38/  157] train: loss: 0.0515338
[Epoch 107; Iter    68/  157] train: loss: 0.0327424
[Epoch 107; Iter    98/  157] train: loss: 0.0156939
[Epoch 107; Iter   128/  157] train: loss: 0.0513080
[Epoch 107] ogbg-moltox21: 0.810688 val loss: 0.275220
[Epoch 107] ogbg-moltox21: 0.817720 test loss: 0.302251
[Epoch 108; Iter     1/  157] train: loss: 0.0314548
[Epoch 108; Iter    31/  157] train: loss: 0.0363825
[Epoch 108; Iter    61/  157] train: loss: 0.0499239
[Epoch 108; Iter    91/  157] train: loss: 0.0335845
[Epoch 108; Iter   121/  157] train: loss: 0.1138537
[Epoch 108; Iter   151/  157] train: loss: 0.0439682
[Epoch 108] ogbg-moltox21: 0.811506 val loss: 0.273675
[Epoch 108] ogbg-moltox21: 0.816314 test loss: 0.305694
[Epoch 109; Iter    24/  157] train: loss: 0.0356234
[Epoch 109; Iter    54/  157] train: loss: 0.0712980
[Epoch 109; Iter    84/  157] train: loss: 0.0477052
[Epoch 109; Iter   114/  157] train: loss: 0.0356942
[Epoch 109; Iter   144/  157] train: loss: 0.0478528
[Epoch 109] ogbg-moltox21: 0.812983 val loss: 0.277022
[Epoch 109] ogbg-moltox21: 0.817522 test loss: 0.308037
[Epoch 110; Iter    17/  157] train: loss: 0.0435482
[Epoch 110; Iter    47/  157] train: loss: 0.0346055
[Epoch 110; Iter    77/  157] train: loss: 0.0234100
[Epoch 110; Iter   107/  157] train: loss: 0.0489898
[Epoch 110; Iter   137/  157] train: loss: 0.0341293
[Epoch 110] ogbg-moltox21: 0.809787 val loss: 0.277809
[Epoch 110] ogbg-moltox21: 0.815335 test loss: 0.309793
[Epoch 111; Iter    10/  157] train: loss: 0.0471410
[Epoch 111; Iter    40/  157] train: loss: 0.0422039
[Epoch 111; Iter    70/  157] train: loss: 0.0351789
[Epoch 111; Iter   100/  157] train: loss: 0.1149887
[Epoch 111; Iter   130/  157] train: loss: 0.0343811
[Epoch 111] ogbg-moltox21: 0.811850 val loss: 0.281589
[Epoch 111] ogbg-moltox21: 0.814274 test loss: 0.458002
[Epoch 112; Iter     3/  157] train: loss: 0.0439365
[Epoch 112; Iter    33/  157] train: loss: 0.0496166
[Epoch 112; Iter    63/  157] train: loss: 0.0497561
[Epoch 112; Iter    93/  157] train: loss: 0.0373516
[Epoch 112; Iter   123/  157] train: loss: 0.0365058
[Epoch 112; Iter   153/  157] train: loss: 0.0416254
[Epoch 112] ogbg-moltox21: 0.812353 val loss: 0.278099
[Epoch 112] ogbg-moltox21: 0.816647 test loss: 0.321168
[Epoch 113; Iter    26/  157] train: loss: 0.0251605
[Epoch 113; Iter    56/  157] train: loss: 0.0331295
[Epoch 113; Iter    86/  157] train: loss: 0.0401058
[Epoch 113; Iter   116/  157] train: loss: 0.0381042
[Epoch 113; Iter   146/  157] train: loss: 0.0555741
[Epoch 113] ogbg-moltox21: 0.818053 val loss: 0.275884
[Epoch 113] ogbg-moltox21: 0.818162 test loss: 0.379318
[Epoch 114; Iter    19/  157] train: loss: 0.0431307
[Epoch 114; Iter    49/  157] train: loss: 0.0538928
[Epoch 114; Iter    79/  157] train: loss: 0.0513051
[Epoch 114; Iter   109/  157] train: loss: 0.0388761
[Epoch 114; Iter   139/  157] train: loss: 0.0405800
[Epoch 114] ogbg-moltox21: 0.817829 val loss: 0.278550
[Epoch 114] ogbg-moltox21: 0.818498 test loss: 0.313381
[Epoch 115; Iter    12/  157] train: loss: 0.0368196
[Epoch 115; Iter    42/  157] train: loss: 0.0425912
[Epoch 115; Iter    72/  157] train: loss: 0.0331818
[Epoch 115; Iter   102/  157] train: loss: 0.0623338
[Epoch 115; Iter   132/  157] train: loss: 0.0365678
[Epoch 115] ogbg-moltox21: 0.811656 val loss: 0.287997
[Epoch 115] ogbg-moltox21: 0.810463 test loss: 0.444680
[Epoch 116; Iter     5/  157] train: loss: 0.0186600
[Epoch 116; Iter    35/  157] train: loss: 0.0441645
[Epoch 116; Iter    65/  157] train: loss: 0.0385579
[Epoch 116; Iter    95/  157] train: loss: 0.0620706
[Epoch 116; Iter   125/  157] train: loss: 0.0288363
[Epoch 116; Iter   155/  157] train: loss: 0.0513391
[Epoch 116] ogbg-moltox21: 0.816021 val loss: 0.283987
[Epoch 116] ogbg-moltox21: 0.814938 test loss: 0.437348
[Epoch 117; Iter    28/  157] train: loss: 0.0612664
[Epoch 117; Iter    58/  157] train: loss: 0.0369699
[Epoch 117; Iter    88/  157] train: loss: 0.0386509
[Epoch 117; Iter   118/  157] train: loss: 0.0448850
[Epoch 117; Iter   148/  157] train: loss: 0.0601849
[Epoch 117] ogbg-moltox21: 0.812406 val loss: 0.287395
[Epoch 117] ogbg-moltox21: 0.816412 test loss: 0.360585
[Epoch 118; Iter    21/  157] train: loss: 0.0427186
[Epoch 118; Iter    51/  157] train: loss: 0.0446325
[Epoch 118; Iter    81/  157] train: loss: 0.0350121
[Epoch 118; Iter   111/  157] train: loss: 0.0546050
[Epoch 118; Iter   141/  157] train: loss: 0.0371635
[Epoch 118] ogbg-moltox21: 0.811341 val loss: 0.283772
[Epoch 118] ogbg-moltox21: 0.811238 test loss: 0.339543
[Epoch 119; Iter    14/  157] train: loss: 0.0225385
[Epoch 119; Iter    44/  157] train: loss: 0.0279006
[Epoch 119; Iter    74/  157] train: loss: 0.0319595
[Epoch 119; Iter   104/  157] train: loss: 0.0365881
[Epoch 119; Iter   134/  157] train: loss: 0.0221489
[Epoch 119] ogbg-moltox21: 0.811713 val loss: 0.290741
[Epoch 119] ogbg-moltox21: 0.814140 test loss: 0.323890
[Epoch 120; Iter     7/  157] train: loss: 0.0540888
[Epoch 120; Iter    37/  157] train: loss: 0.0236860
[Epoch 120; Iter    67/  157] train: loss: 0.0202548
[Epoch 120; Iter    97/  157] train: loss: 0.0482541
[Epoch 120; Iter   127/  157] train: loss: 0.0550303
[Epoch 120; Iter   157/  157] train: loss: 0.0324199
[Epoch 120] ogbg-moltox21: 0.811250 val loss: 0.289986
[Epoch 120] ogbg-moltox21: 0.815546 test loss: 0.403698
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 42.
Statistics on  val_best_checkpoint
mean_pred: -4.144185543060303
std_pred: 2.3853325843811035
mean_targets: nan
std_targets: nan
prcauc: 0.46118414496896626
rocauc: 0.8409972354583162
ogbg-moltox21: 0.8409972354583162
OGBNanLabelBCEWithLogitsLoss: 0.1851212908074541
Statistics on  test
mean_pred: -4.095330238342285
std_pred: 2.3921663761138916
mean_targets: nan
std_targets: nan
prcauc: 0.49769032228444127
rocauc: 0.852377781735949
ogbg-moltox21: 0.852377781735949
OGBNanLabelBCEWithLogitsLoss: 0.19509194552336098
Statistics on  train
mean_pred: -3.590545415878296
std_pred: 2.684082269668579
mean_targets: nan
std_targets: nan
prcauc: 0.617135450557346
rocauc: 0.9184941279872559
ogbg-moltox21: 0.9184941279872559
OGBNanLabelBCEWithLogitsLoss: 0.1487236434392109
OGBNanLabelBCEWithLogitsLoss: 0.19692105068913046
Statistics on  train
mean_pred: -4.087495803833008
std_pred: 2.5966901779174805
mean_targets: nan
std_targets: nan
prcauc: 0.7160661878789655
rocauc: 0.945672713355639
ogbg-moltox21: 0.945672713355639
OGBNanLabelBCEWithLogitsLoss: 0.12744282560933168
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0543782
[Epoch 101] ogbg-moltox21: 0.790214 val loss: 0.279713
[Epoch 101] ogbg-moltox21: 0.802294 test loss: 0.312463
[Epoch 102; Iter    13/  157] train: loss: 0.0372769
[Epoch 102; Iter    43/  157] train: loss: 0.0630069
[Epoch 102; Iter    73/  157] train: loss: 0.0302645
[Epoch 102; Iter   103/  157] train: loss: 0.0586867
[Epoch 102; Iter   133/  157] train: loss: 0.0292023
[Epoch 102] ogbg-moltox21: 0.793686 val loss: 0.282485
[Epoch 102] ogbg-moltox21: 0.800250 test loss: 0.312350
[Epoch 103; Iter     6/  157] train: loss: 0.0364900
[Epoch 103; Iter    36/  157] train: loss: 0.0280746
[Epoch 103; Iter    66/  157] train: loss: 0.0179022
[Epoch 103; Iter    96/  157] train: loss: 0.0607108
[Epoch 103; Iter   126/  157] train: loss: 0.0427666
[Epoch 103; Iter   156/  157] train: loss: 0.0551982
[Epoch 103] ogbg-moltox21: 0.789464 val loss: 0.282079
[Epoch 103] ogbg-moltox21: 0.801091 test loss: 0.316715
[Epoch 104; Iter    29/  157] train: loss: 0.0312692
[Epoch 104; Iter    59/  157] train: loss: 0.0209903
[Epoch 104; Iter    89/  157] train: loss: 0.0442533
[Epoch 104; Iter   119/  157] train: loss: 0.0316095
[Epoch 104; Iter   149/  157] train: loss: 0.0665194
[Epoch 104] ogbg-moltox21: 0.796101 val loss: 0.282249
[Epoch 104] ogbg-moltox21: 0.807662 test loss: 0.312037
[Epoch 105; Iter    22/  157] train: loss: 0.0540299
[Epoch 105; Iter    52/  157] train: loss: 0.0229949
[Epoch 105; Iter    82/  157] train: loss: 0.0916009
[Epoch 105; Iter   112/  157] train: loss: 0.0221993
[Epoch 105; Iter   142/  157] train: loss: 0.0475740
[Epoch 105] ogbg-moltox21: 0.792757 val loss: 0.288672
[Epoch 105] ogbg-moltox21: 0.801331 test loss: 0.322564
[Epoch 106; Iter    15/  157] train: loss: 0.0484785
[Epoch 106; Iter    45/  157] train: loss: 0.0442763
[Epoch 106; Iter    75/  157] train: loss: 0.0566105
[Epoch 106; Iter   105/  157] train: loss: 0.0462771
[Epoch 106; Iter   135/  157] train: loss: 0.0429080
[Epoch 106] ogbg-moltox21: 0.788396 val loss: 0.286607
[Epoch 106] ogbg-moltox21: 0.800351 test loss: 0.321562
[Epoch 107; Iter     8/  157] train: loss: 0.0339294
[Epoch 107; Iter    38/  157] train: loss: 0.0454337
[Epoch 107; Iter    68/  157] train: loss: 0.0432591
[Epoch 107; Iter    98/  157] train: loss: 0.0474182
[Epoch 107; Iter   128/  157] train: loss: 0.0403135
[Epoch 107] ogbg-moltox21: 0.790947 val loss: 0.290469
[Epoch 107] ogbg-moltox21: 0.800757 test loss: 0.324727
[Epoch 108; Iter     1/  157] train: loss: 0.0176417
[Epoch 108; Iter    31/  157] train: loss: 0.0369180
[Epoch 108; Iter    61/  157] train: loss: 0.0294631
[Epoch 108; Iter    91/  157] train: loss: 0.0317866
[Epoch 108; Iter   121/  157] train: loss: 0.0537882
[Epoch 108; Iter   151/  157] train: loss: 0.0403240
[Epoch 108] ogbg-moltox21: 0.794264 val loss: 0.286707
[Epoch 108] ogbg-moltox21: 0.802744 test loss: 0.322275
[Epoch 109; Iter    24/  157] train: loss: 0.0388214
[Epoch 109; Iter    54/  157] train: loss: 0.0242703
[Epoch 109; Iter    84/  157] train: loss: 0.0328665
[Epoch 109; Iter   114/  157] train: loss: 0.0415566
[Epoch 109; Iter   144/  157] train: loss: 0.0546701
[Epoch 109] ogbg-moltox21: 0.791311 val loss: 0.290552
[Epoch 109] ogbg-moltox21: 0.802422 test loss: 0.325776
[Epoch 110; Iter    17/  157] train: loss: 0.0479376
[Epoch 110; Iter    47/  157] train: loss: 0.0285558
[Epoch 110; Iter    77/  157] train: loss: 0.0249282
[Epoch 110; Iter   107/  157] train: loss: 0.0479260
[Epoch 110; Iter   137/  157] train: loss: 0.0541949
[Epoch 110] ogbg-moltox21: 0.791239 val loss: 0.289764
[Epoch 110] ogbg-moltox21: 0.799245 test loss: 0.329405
[Epoch 111; Iter    10/  157] train: loss: 0.0390246
[Epoch 111; Iter    40/  157] train: loss: 0.0240852
[Epoch 111; Iter    70/  157] train: loss: 0.0382646
[Epoch 111; Iter   100/  157] train: loss: 0.0528634
[Epoch 111; Iter   130/  157] train: loss: 0.0336704
[Epoch 111] ogbg-moltox21: 0.792363 val loss: 0.293299
[Epoch 111] ogbg-moltox21: 0.802391 test loss: 0.332509
[Epoch 112; Iter     3/  157] train: loss: 0.0421589
[Epoch 112; Iter    33/  157] train: loss: 0.0353208
[Epoch 112; Iter    63/  157] train: loss: 0.0643027
[Epoch 112; Iter    93/  157] train: loss: 0.0742560
[Epoch 112; Iter   123/  157] train: loss: 0.0563720
[Epoch 112; Iter   153/  157] train: loss: 0.0551353
[Epoch 112] ogbg-moltox21: 0.794044 val loss: 0.295055
[Epoch 112] ogbg-moltox21: 0.802933 test loss: 0.332081
[Epoch 113; Iter    26/  157] train: loss: 0.0257487
[Epoch 113; Iter    56/  157] train: loss: 0.0305270
[Epoch 113; Iter    86/  157] train: loss: 0.0475122
[Epoch 113; Iter   116/  157] train: loss: 0.0177498
[Epoch 113; Iter   146/  157] train: loss: 0.0345729
[Epoch 113] ogbg-moltox21: 0.786716 val loss: 0.294009
[Epoch 113] ogbg-moltox21: 0.798193 test loss: 0.328448
[Epoch 114; Iter    19/  157] train: loss: 0.0701134
[Epoch 114; Iter    49/  157] train: loss: 0.1066297
[Epoch 114; Iter    79/  157] train: loss: 0.0613274
[Epoch 114; Iter   109/  157] train: loss: 0.0319836
[Epoch 114; Iter   139/  157] train: loss: 0.0543070
[Epoch 114] ogbg-moltox21: 0.791072 val loss: 0.294425
[Epoch 114] ogbg-moltox21: 0.799316 test loss: 0.332983
[Epoch 115; Iter    12/  157] train: loss: 0.0292488
[Epoch 115; Iter    42/  157] train: loss: 0.0486793
[Epoch 115; Iter    72/  157] train: loss: 0.0342002
[Epoch 115; Iter   102/  157] train: loss: 0.0167376
[Epoch 115; Iter   132/  157] train: loss: 0.0257863
[Epoch 115] ogbg-moltox21: 0.794702 val loss: 0.295483
[Epoch 115] ogbg-moltox21: 0.800489 test loss: 0.334094
[Epoch 116; Iter     5/  157] train: loss: 0.0436812
[Epoch 116; Iter    35/  157] train: loss: 0.0395671
[Epoch 116; Iter    65/  157] train: loss: 0.0174745
[Epoch 116; Iter    95/  157] train: loss: 0.0438931
[Epoch 116; Iter   125/  157] train: loss: 0.0301093
[Epoch 116; Iter   155/  157] train: loss: 0.0416933
[Epoch 116] ogbg-moltox21: 0.789035 val loss: 0.292078
[Epoch 116] ogbg-moltox21: 0.795265 test loss: 0.334673
[Epoch 117; Iter    28/  157] train: loss: 0.0272111
[Epoch 117; Iter    58/  157] train: loss: 0.0387909
[Epoch 117; Iter    88/  157] train: loss: 0.0471733
[Epoch 117; Iter   118/  157] train: loss: 0.0265455
[Epoch 117; Iter   148/  157] train: loss: 0.0328995
[Epoch 117] ogbg-moltox21: 0.794429 val loss: 0.297260
[Epoch 117] ogbg-moltox21: 0.804026 test loss: 0.335503
[Epoch 118; Iter    21/  157] train: loss: 0.0232676
[Epoch 118; Iter    51/  157] train: loss: 0.0378647
[Epoch 118; Iter    81/  157] train: loss: 0.0705267
[Epoch 118; Iter   111/  157] train: loss: 0.0490953
[Epoch 118; Iter   141/  157] train: loss: 0.0230090
[Epoch 118] ogbg-moltox21: 0.794877 val loss: 0.302698
[Epoch 118] ogbg-moltox21: 0.804144 test loss: 0.337620
[Epoch 119; Iter    14/  157] train: loss: 0.0322503
[Epoch 119; Iter    44/  157] train: loss: 0.0378840
[Epoch 119; Iter    74/  157] train: loss: 0.0227256
[Epoch 119; Iter   104/  157] train: loss: 0.0419584
[Epoch 119; Iter   134/  157] train: loss: 0.0272605
[Epoch 119] ogbg-moltox21: 0.795501 val loss: 0.298532
[Epoch 119] ogbg-moltox21: 0.804654 test loss: 0.333570
[Epoch 120; Iter     7/  157] train: loss: 0.0381568
[Epoch 120; Iter    37/  157] train: loss: 0.0285166
[Epoch 120; Iter    67/  157] train: loss: 0.0287355
[Epoch 120; Iter    97/  157] train: loss: 0.0362745
[Epoch 120; Iter   127/  157] train: loss: 0.0358366
[Epoch 120; Iter   157/  157] train: loss: 0.0360398
[Epoch 120] ogbg-moltox21: 0.794222 val loss: 0.302280
[Epoch 120] ogbg-moltox21: 0.801473 test loss: 0.340243
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -4.002796649932861
std_pred: 2.2659194469451904
mean_targets: nan
std_targets: nan
prcauc: 0.3911257421291931
rocauc: 0.8359742012925299
ogbg-moltox21: 0.8359742012925299
OGBNanLabelBCEWithLogitsLoss: 0.18885623621490766
Statistics on  test
mean_pred: -3.95792293548584
std_pred: 2.1757335662841797
mean_targets: nan
std_targets: nan
prcauc: 0.44771368636623127
rocauc: 0.8483828547891893
ogbg-moltox21: 0.8483828547891893
OGBNanLabelBCEWithLogitsLoss: 0.20161209424149315
Statistics on  train
mean_pred: -3.937049388885498
std_pred: 2.265594482421875
mean_targets: nan
std_targets: nan
prcauc: 0.5749921565077388
rocauc: 0.9110963766039322
ogbg-moltox21: 0.9110963766039322
OGBNanLabelBCEWithLogitsLoss: 0.155735880041578
All runs completed.
[Epoch 99; Iter   128/  209] train: loss: 0.0863468
[Epoch 99; Iter   158/  209] train: loss: 0.0620827
[Epoch 99; Iter   188/  209] train: loss: 0.0383652
[Epoch 99] ogbg-moltox21: 0.842752 val loss: 0.282958
[Epoch 99] ogbg-moltox21: 0.838598 test loss: 0.240890
[Epoch 100; Iter     9/  209] train: loss: 0.0573651
[Epoch 100; Iter    39/  209] train: loss: 0.0721240
[Epoch 100; Iter    69/  209] train: loss: 0.0536778
[Epoch 100; Iter    99/  209] train: loss: 0.0859454
[Epoch 100; Iter   129/  209] train: loss: 0.0891014
[Epoch 100; Iter   159/  209] train: loss: 0.0747261
[Epoch 100; Iter   189/  209] train: loss: 0.0809745
[Epoch 100] ogbg-moltox21: 0.837503 val loss: 0.288214
[Epoch 100] ogbg-moltox21: 0.832948 test loss: 0.245836
[Epoch 101; Iter    10/  209] train: loss: 0.0434496
[Epoch 101; Iter    40/  209] train: loss: 0.0580973
[Epoch 101; Iter    70/  209] train: loss: 0.0703871
[Epoch 101; Iter   100/  209] train: loss: 0.0992434
[Epoch 101; Iter   130/  209] train: loss: 0.0478388
[Epoch 101; Iter   160/  209] train: loss: 0.0504239
[Epoch 101; Iter   190/  209] train: loss: 0.1140624
[Epoch 101] ogbg-moltox21: 0.838654 val loss: 0.291824
[Epoch 101] ogbg-moltox21: 0.835496 test loss: 0.241188
[Epoch 102; Iter    11/  209] train: loss: 0.0456402
[Epoch 102; Iter    41/  209] train: loss: 0.0721042
[Epoch 102; Iter    71/  209] train: loss: 0.0598566
[Epoch 102; Iter   101/  209] train: loss: 0.0824920
[Epoch 102; Iter   131/  209] train: loss: 0.0304579
[Epoch 102; Iter   161/  209] train: loss: 0.0625758
[Epoch 102; Iter   191/  209] train: loss: 0.0770756
[Epoch 102] ogbg-moltox21: 0.838851 val loss: 0.292788
[Epoch 102] ogbg-moltox21: 0.833396 test loss: 0.250812
[Epoch 103; Iter    12/  209] train: loss: 0.0485947
[Epoch 103; Iter    42/  209] train: loss: 0.0591062
[Epoch 103; Iter    72/  209] train: loss: 0.0629480
[Epoch 103; Iter   102/  209] train: loss: 0.0806623
[Epoch 103; Iter   132/  209] train: loss: 0.0598882
[Epoch 103; Iter   162/  209] train: loss: 0.0410767
[Epoch 103; Iter   192/  209] train: loss: 0.0678670
[Epoch 103] ogbg-moltox21: 0.832767 val loss: 0.301276
[Epoch 103] ogbg-moltox21: 0.832042 test loss: 0.255684
[Epoch 104; Iter    13/  209] train: loss: 0.1160356
[Epoch 104; Iter    43/  209] train: loss: 0.0675511
[Epoch 104; Iter    73/  209] train: loss: 0.0540611
[Epoch 104; Iter   103/  209] train: loss: 0.0399726
[Epoch 104; Iter   133/  209] train: loss: 0.0665986
[Epoch 104; Iter   163/  209] train: loss: 0.0451764
[Epoch 104; Iter   193/  209] train: loss: 0.0650339
[Epoch 104] ogbg-moltox21: 0.831167 val loss: 0.302559
[Epoch 104] ogbg-moltox21: 0.833408 test loss: 0.253561
[Epoch 105; Iter    14/  209] train: loss: 0.0652833
[Epoch 105; Iter    44/  209] train: loss: 0.0608933
[Epoch 105; Iter    74/  209] train: loss: 0.0772365
[Epoch 105; Iter   104/  209] train: loss: 0.0627184
[Epoch 105; Iter   134/  209] train: loss: 0.0424025
[Epoch 105; Iter   164/  209] train: loss: 0.0666508
[Epoch 105; Iter   194/  209] train: loss: 0.0775773
[Epoch 105] ogbg-moltox21: 0.833912 val loss: 0.303952
[Epoch 105] ogbg-moltox21: 0.836285 test loss: 0.257408
[Epoch 106; Iter    15/  209] train: loss: 0.0331709
[Epoch 106; Iter    45/  209] train: loss: 0.0684385
[Epoch 106; Iter    75/  209] train: loss: 0.1146864
[Epoch 106; Iter   105/  209] train: loss: 0.0337561
[Epoch 106; Iter   135/  209] train: loss: 0.1204826
[Epoch 106; Iter   165/  209] train: loss: 0.0517116
[Epoch 106; Iter   195/  209] train: loss: 0.0545627
[Epoch 106] ogbg-moltox21: 0.833530 val loss: 0.317084
[Epoch 106] ogbg-moltox21: 0.833615 test loss: 0.254973
[Epoch 107; Iter    16/  209] train: loss: 0.0383588
[Epoch 107; Iter    46/  209] train: loss: 0.0584467
[Epoch 107; Iter    76/  209] train: loss: 0.0610287
[Epoch 107; Iter   106/  209] train: loss: 0.0527003
[Epoch 107; Iter   136/  209] train: loss: 0.0424616
[Epoch 107; Iter   166/  209] train: loss: 0.0491147
[Epoch 107; Iter   196/  209] train: loss: 0.0308285
[Epoch 107] ogbg-moltox21: 0.829217 val loss: 0.307913
[Epoch 107] ogbg-moltox21: 0.833175 test loss: 0.266036
[Epoch 108; Iter    17/  209] train: loss: 0.0488622
[Epoch 108; Iter    47/  209] train: loss: 0.0395039
[Epoch 108; Iter    77/  209] train: loss: 0.1213934
[Epoch 108; Iter   107/  209] train: loss: 0.0462223
[Epoch 108; Iter   137/  209] train: loss: 0.0429450
[Epoch 108; Iter   167/  209] train: loss: 0.0462391
[Epoch 108; Iter   197/  209] train: loss: 0.0346323
[Epoch 108] ogbg-moltox21: 0.832616 val loss: 0.343497
[Epoch 108] ogbg-moltox21: 0.829920 test loss: 0.262800
[Epoch 109; Iter    18/  209] train: loss: 0.0634562
[Epoch 109; Iter    48/  209] train: loss: 0.0569553
[Epoch 109; Iter    78/  209] train: loss: 0.0403189
[Epoch 109; Iter   108/  209] train: loss: 0.0261587
[Epoch 109; Iter   138/  209] train: loss: 0.0367217
[Epoch 109; Iter   168/  209] train: loss: 0.0520975
[Epoch 109; Iter   198/  209] train: loss: 0.0617749
[Epoch 109] ogbg-moltox21: 0.830437 val loss: 0.309445
[Epoch 109] ogbg-moltox21: 0.832335 test loss: 0.261598
[Epoch 110; Iter    19/  209] train: loss: 0.0438489
[Epoch 110; Iter    49/  209] train: loss: 0.0529956
[Epoch 110; Iter    79/  209] train: loss: 0.0477960
[Epoch 110; Iter   109/  209] train: loss: 0.0326150
[Epoch 110; Iter   139/  209] train: loss: 0.0418775
[Epoch 110; Iter   169/  209] train: loss: 0.0430777
[Epoch 110; Iter   199/  209] train: loss: 0.0471050
[Epoch 110] ogbg-moltox21: 0.828021 val loss: 0.314849
[Epoch 110] ogbg-moltox21: 0.831660 test loss: 0.263168
[Epoch 111; Iter    20/  209] train: loss: 0.0527139
[Epoch 111; Iter    50/  209] train: loss: 0.0428951
[Epoch 111; Iter    80/  209] train: loss: 0.0455574
[Epoch 111; Iter   110/  209] train: loss: 0.0314381
[Epoch 111; Iter   140/  209] train: loss: 0.0255847
[Epoch 111; Iter   170/  209] train: loss: 0.0485802
[Epoch 111; Iter   200/  209] train: loss: 0.0427880
[Epoch 111] ogbg-moltox21: 0.830566 val loss: 0.310856
[Epoch 111] ogbg-moltox21: 0.836640 test loss: 0.263379
[Epoch 112; Iter    21/  209] train: loss: 0.0588730
[Epoch 112; Iter    51/  209] train: loss: 0.0605729
[Epoch 112; Iter    81/  209] train: loss: 0.0624073
[Epoch 112; Iter   111/  209] train: loss: 0.0300485
[Epoch 112; Iter   141/  209] train: loss: 0.1162695
[Epoch 112; Iter   171/  209] train: loss: 0.0396109
[Epoch 112; Iter   201/  209] train: loss: 0.0621697
[Epoch 112] ogbg-moltox21: 0.834819 val loss: 0.315593
[Epoch 112] ogbg-moltox21: 0.831988 test loss: 0.269675
[Epoch 113; Iter    22/  209] train: loss: 0.0727430
[Epoch 113; Iter    52/  209] train: loss: 0.0361586
[Epoch 113; Iter    82/  209] train: loss: 0.0549297
[Epoch 113; Iter   112/  209] train: loss: 0.0810063
[Epoch 113; Iter   142/  209] train: loss: 0.0472204
[Epoch 113; Iter   172/  209] train: loss: 0.0706704
[Epoch 113; Iter   202/  209] train: loss: 0.0309692
[Epoch 113] ogbg-moltox21: 0.833256 val loss: 0.356614
[Epoch 113] ogbg-moltox21: 0.829852 test loss: 0.274650
[Epoch 114; Iter    23/  209] train: loss: 0.0608704
[Epoch 114; Iter    53/  209] train: loss: 0.0543109
[Epoch 114; Iter    83/  209] train: loss: 0.0479904
[Epoch 114; Iter   113/  209] train: loss: 0.0520706
[Epoch 114; Iter   143/  209] train: loss: 0.0428967
[Epoch 114; Iter   173/  209] train: loss: 0.0502722
[Epoch 114; Iter   203/  209] train: loss: 0.0715812
[Epoch 114] ogbg-moltox21: 0.833409 val loss: 0.323380
[Epoch 114] ogbg-moltox21: 0.833187 test loss: 0.268558
[Epoch 115; Iter    24/  209] train: loss: 0.0308010
[Epoch 115; Iter    54/  209] train: loss: 0.0631629
[Epoch 115; Iter    84/  209] train: loss: 0.0353902
[Epoch 115; Iter   114/  209] train: loss: 0.0460958
[Epoch 115; Iter   144/  209] train: loss: 0.0285210
[Epoch 115; Iter   174/  209] train: loss: 0.0281250
[Epoch 115; Iter   204/  209] train: loss: 0.0637944
[Epoch 115] ogbg-moltox21: 0.833320 val loss: 0.372474
[Epoch 115] ogbg-moltox21: 0.833046 test loss: 0.272480
[Epoch 116; Iter    25/  209] train: loss: 0.0229217
[Epoch 116; Iter    55/  209] train: loss: 0.0827672
[Epoch 116; Iter    85/  209] train: loss: 0.0383996
[Epoch 116; Iter   115/  209] train: loss: 0.0478478
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 99; Iter   128/  209] train: loss: 0.0390796
[Epoch 99; Iter   158/  209] train: loss: 0.0425317
[Epoch 99; Iter   188/  209] train: loss: 0.0512567
[Epoch 99] ogbg-moltox21: 0.830049 val loss: 0.314776
[Epoch 99] ogbg-moltox21: 0.817384 test loss: 0.294816
[Epoch 100; Iter     9/  209] train: loss: 0.0336594
[Epoch 100; Iter    39/  209] train: loss: 0.0666386
[Epoch 100; Iter    69/  209] train: loss: 0.0350637
[Epoch 100; Iter    99/  209] train: loss: 0.0620596
[Epoch 100; Iter   129/  209] train: loss: 0.0794442
[Epoch 100; Iter   159/  209] train: loss: 0.0435458
[Epoch 100; Iter   189/  209] train: loss: 0.0376262
[Epoch 100] ogbg-moltox21: 0.827112 val loss: 0.314583
[Epoch 100] ogbg-moltox21: 0.814765 test loss: 0.287811
[Epoch 101; Iter    10/  209] train: loss: 0.0335216
[Epoch 101; Iter    40/  209] train: loss: 0.0722264
[Epoch 101; Iter    70/  209] train: loss: 0.0727051
[Epoch 101; Iter   100/  209] train: loss: 0.0293648
[Epoch 101; Iter   130/  209] train: loss: 0.0687293
[Epoch 101; Iter   160/  209] train: loss: 0.0401489
[Epoch 101; Iter   190/  209] train: loss: 0.0364314
[Epoch 101] ogbg-moltox21: 0.827864 val loss: 0.324523
[Epoch 101] ogbg-moltox21: 0.810918 test loss: 0.300922
[Epoch 102; Iter    11/  209] train: loss: 0.0355252
[Epoch 102; Iter    41/  209] train: loss: 0.0372898
[Epoch 102; Iter    71/  209] train: loss: 0.0450447
[Epoch 102; Iter   101/  209] train: loss: 0.0576995
[Epoch 102; Iter   131/  209] train: loss: 0.0680886
[Epoch 102; Iter   161/  209] train: loss: 0.0452473
[Epoch 102; Iter   191/  209] train: loss: 0.0400873
[Epoch 102] ogbg-moltox21: 0.825405 val loss: 0.327812
[Epoch 102] ogbg-moltox21: 0.811737 test loss: 0.297261
[Epoch 103; Iter    12/  209] train: loss: 0.0540871
[Epoch 103; Iter    42/  209] train: loss: 0.0934664
[Epoch 103; Iter    72/  209] train: loss: 0.0562522
[Epoch 103; Iter   102/  209] train: loss: 0.0415736
[Epoch 103; Iter   132/  209] train: loss: 0.0563146
[Epoch 103; Iter   162/  209] train: loss: 0.0712605
[Epoch 103; Iter   192/  209] train: loss: 0.0293411
[Epoch 103] ogbg-moltox21: 0.832154 val loss: 0.325813
[Epoch 103] ogbg-moltox21: 0.819445 test loss: 0.299757
[Epoch 104; Iter    13/  209] train: loss: 0.0523059
[Epoch 104; Iter    43/  209] train: loss: 0.0239282
[Epoch 104; Iter    73/  209] train: loss: 0.0469827
[Epoch 104; Iter   103/  209] train: loss: 0.0487152
[Epoch 104; Iter   133/  209] train: loss: 0.0391718
[Epoch 104; Iter   163/  209] train: loss: 0.0335880
[Epoch 104; Iter   193/  209] train: loss: 0.1504562
[Epoch 104] ogbg-moltox21: 0.825288 val loss: 0.334725
[Epoch 104] ogbg-moltox21: 0.812762 test loss: 0.307497
[Epoch 105; Iter    14/  209] train: loss: 0.0705770
[Epoch 105; Iter    44/  209] train: loss: 0.0462166
[Epoch 105; Iter    74/  209] train: loss: 0.0361809
[Epoch 105; Iter   104/  209] train: loss: 0.0356489
[Epoch 105; Iter   134/  209] train: loss: 0.0518885
[Epoch 105; Iter   164/  209] train: loss: 0.0599236
[Epoch 105; Iter   194/  209] train: loss: 0.0215091
[Epoch 105] ogbg-moltox21: 0.831494 val loss: 0.325772
[Epoch 105] ogbg-moltox21: 0.813944 test loss: 0.308281
[Epoch 106; Iter    15/  209] train: loss: 0.0540500
[Epoch 106; Iter    45/  209] train: loss: 0.0903949
[Epoch 106; Iter    75/  209] train: loss: 0.0545798
[Epoch 106; Iter   105/  209] train: loss: 0.0375638
[Epoch 106; Iter   135/  209] train: loss: 0.0399978
[Epoch 106; Iter   165/  209] train: loss: 0.0243145
[Epoch 106; Iter   195/  209] train: loss: 0.0511685
[Epoch 106] ogbg-moltox21: 0.829928 val loss: 0.326581
[Epoch 106] ogbg-moltox21: 0.812005 test loss: 0.309300
[Epoch 107; Iter    16/  209] train: loss: 0.0364333
[Epoch 107; Iter    46/  209] train: loss: 0.0414860
[Epoch 107; Iter    76/  209] train: loss: 0.0580834
[Epoch 107; Iter   106/  209] train: loss: 0.0784759
[Epoch 107; Iter   136/  209] train: loss: 0.0345574
[Epoch 107; Iter   166/  209] train: loss: 0.0353161
[Epoch 107; Iter   196/  209] train: loss: 0.0346229
[Epoch 107] ogbg-moltox21: 0.833056 val loss: 0.330240
[Epoch 107] ogbg-moltox21: 0.812214 test loss: 0.311184
[Epoch 108; Iter    17/  209] train: loss: 0.0322032
[Epoch 108; Iter    47/  209] train: loss: 0.0556646
[Epoch 108; Iter    77/  209] train: loss: 0.0365558
[Epoch 108; Iter   107/  209] train: loss: 0.0329181
[Epoch 108; Iter   137/  209] train: loss: 0.0279114
[Epoch 108; Iter   167/  209] train: loss: 0.0386255
[Epoch 108; Iter   197/  209] train: loss: 0.1002753
[Epoch 108] ogbg-moltox21: 0.823728 val loss: 0.338137
[Epoch 108] ogbg-moltox21: 0.811840 test loss: 0.314167
[Epoch 109; Iter    18/  209] train: loss: 0.0593663
[Epoch 109; Iter    48/  209] train: loss: 0.0249499
[Epoch 109; Iter    78/  209] train: loss: 0.0316519
[Epoch 109; Iter   108/  209] train: loss: 0.0193341
[Epoch 109; Iter   138/  209] train: loss: 0.0555993
[Epoch 109; Iter   168/  209] train: loss: 0.0383378
[Epoch 109; Iter   198/  209] train: loss: 0.0501817
[Epoch 109] ogbg-moltox21: 0.827000 val loss: 0.338031
[Epoch 109] ogbg-moltox21: 0.810425 test loss: 0.316852
[Epoch 110; Iter    19/  209] train: loss: 0.0536158
[Epoch 110; Iter    49/  209] train: loss: 0.0537525
[Epoch 110; Iter    79/  209] train: loss: 0.0666996
[Epoch 110; Iter   109/  209] train: loss: 0.0675299
[Epoch 110; Iter   139/  209] train: loss: 0.0705845
[Epoch 110; Iter   169/  209] train: loss: 0.0587808
[Epoch 110; Iter   199/  209] train: loss: 0.0682327
[Epoch 110] ogbg-moltox21: 0.830729 val loss: 0.331929
[Epoch 110] ogbg-moltox21: 0.816993 test loss: 0.307107
[Epoch 111; Iter    20/  209] train: loss: 0.0476558
[Epoch 111; Iter    50/  209] train: loss: 0.0864935
[Epoch 111; Iter    80/  209] train: loss: 0.0285350
[Epoch 111; Iter   110/  209] train: loss: 0.0461815
[Epoch 111; Iter   140/  209] train: loss: 0.0693573
[Epoch 111; Iter   170/  209] train: loss: 0.0481937
[Epoch 111; Iter   200/  209] train: loss: 0.0223064
[Epoch 111] ogbg-moltox21: 0.826972 val loss: 0.340732
[Epoch 111] ogbg-moltox21: 0.811189 test loss: 0.313626
[Epoch 112; Iter    21/  209] train: loss: 0.0353921
[Epoch 112; Iter    51/  209] train: loss: 0.0386677
[Epoch 112; Iter    81/  209] train: loss: 0.1170928
[Epoch 112; Iter   111/  209] train: loss: 0.0552036
[Epoch 112; Iter   141/  209] train: loss: 0.0346870
[Epoch 112; Iter   171/  209] train: loss: 0.0375807
[Epoch 112; Iter   201/  209] train: loss: 0.0174353
[Epoch 112] ogbg-moltox21: 0.825405 val loss: 0.345264
[Epoch 112] ogbg-moltox21: 0.813825 test loss: 0.329332
[Epoch 113; Iter    22/  209] train: loss: 0.0559412
[Epoch 113; Iter    52/  209] train: loss: 0.0251500
[Epoch 113; Iter    82/  209] train: loss: 0.0665000
[Epoch 113; Iter   112/  209] train: loss: 0.0245001
[Epoch 113; Iter   142/  209] train: loss: 0.0477149
[Epoch 113; Iter   172/  209] train: loss: 0.0354769
[Epoch 113; Iter   202/  209] train: loss: 0.0348881
[Epoch 113] ogbg-moltox21: 0.830784 val loss: 0.339667
[Epoch 113] ogbg-moltox21: 0.813910 test loss: 0.318679
[Epoch 114; Iter    23/  209] train: loss: 0.0454036
[Epoch 114; Iter    53/  209] train: loss: 0.0459279
[Epoch 114; Iter    83/  209] train: loss: 0.0429634
[Epoch 114; Iter   113/  209] train: loss: 0.0351209
[Epoch 114; Iter   143/  209] train: loss: 0.0208703
[Epoch 114; Iter   173/  209] train: loss: 0.0468709
[Epoch 114; Iter   203/  209] train: loss: 0.0385287
[Epoch 114] ogbg-moltox21: 0.830731 val loss: 0.342447
[Epoch 114] ogbg-moltox21: 0.818140 test loss: 0.310763
[Epoch 115; Iter    24/  209] train: loss: 0.0328096
[Epoch 115; Iter    54/  209] train: loss: 0.0304117
[Epoch 115; Iter    84/  209] train: loss: 0.0304676
[Epoch 115; Iter   114/  209] train: loss: 0.0434224
[Epoch 115; Iter   144/  209] train: loss: 0.0317097
[Epoch 115; Iter   174/  209] train: loss: 0.0398498
[Epoch 115; Iter   204/  209] train: loss: 0.0371871
[Epoch 115] ogbg-moltox21: 0.826734 val loss: 0.346172
[Epoch 115] ogbg-moltox21: 0.817293 test loss: 0.321074
[Epoch 116; Iter    25/  209] train: loss: 0.0133800
[Epoch 116; Iter    55/  209] train: loss: 0.0400088
[Epoch 116; Iter    85/  209] train: loss: 0.0352708
[Epoch 116; Iter   115/  209] train: loss: 0.0208393
[Epoch 109] ogbg-moltox21: 0.814850 test loss: 0.271000
[Epoch 110; Iter     3/  183] train: loss: 0.0554757
[Epoch 110; Iter    33/  183] train: loss: 0.0330375
[Epoch 110; Iter    63/  183] train: loss: 0.1020314
[Epoch 110; Iter    93/  183] train: loss: 0.0746162
[Epoch 110; Iter   123/  183] train: loss: 0.0283920
[Epoch 110; Iter   153/  183] train: loss: 0.0775668
[Epoch 110; Iter   183/  183] train: loss: 0.0780405
[Epoch 110] ogbg-moltox21: 0.804878 val loss: 0.272362
[Epoch 110] ogbg-moltox21: 0.816361 test loss: 0.269404
[Epoch 111; Iter    30/  183] train: loss: 0.0347747
[Epoch 111; Iter    60/  183] train: loss: 0.0526105
[Epoch 111; Iter    90/  183] train: loss: 0.0528805
[Epoch 111; Iter   120/  183] train: loss: 0.0647997
[Epoch 111; Iter   150/  183] train: loss: 0.0681262
[Epoch 111; Iter   180/  183] train: loss: 0.0489501
[Epoch 111] ogbg-moltox21: 0.796571 val loss: 0.277384
[Epoch 111] ogbg-moltox21: 0.809780 test loss: 0.280577
[Epoch 112; Iter    27/  183] train: loss: 0.0929232
[Epoch 112; Iter    57/  183] train: loss: 0.0634207
[Epoch 112; Iter    87/  183] train: loss: 0.0384689
[Epoch 112; Iter   117/  183] train: loss: 0.0476000
[Epoch 112; Iter   147/  183] train: loss: 0.0720337
[Epoch 112; Iter   177/  183] train: loss: 0.0408363
[Epoch 112] ogbg-moltox21: 0.805214 val loss: 0.280881
[Epoch 112] ogbg-moltox21: 0.820172 test loss: 0.272739
[Epoch 113; Iter    24/  183] train: loss: 0.0509304
[Epoch 113; Iter    54/  183] train: loss: 0.0596452
[Epoch 113; Iter    84/  183] train: loss: 0.0487225
[Epoch 113; Iter   114/  183] train: loss: 0.0762188
[Epoch 113; Iter   144/  183] train: loss: 0.0534785
[Epoch 113; Iter   174/  183] train: loss: 0.0775500
[Epoch 113] ogbg-moltox21: 0.799183 val loss: 0.277854
[Epoch 113] ogbg-moltox21: 0.815415 test loss: 0.275659
[Epoch 114; Iter    21/  183] train: loss: 0.1466850
[Epoch 114; Iter    51/  183] train: loss: 0.0596831
[Epoch 114; Iter    81/  183] train: loss: 0.0375673
[Epoch 114; Iter   111/  183] train: loss: 0.0988692
[Epoch 114; Iter   141/  183] train: loss: 0.0790029
[Epoch 114; Iter   171/  183] train: loss: 0.0412770
[Epoch 114] ogbg-moltox21: 0.801772 val loss: 0.280669
[Epoch 114] ogbg-moltox21: 0.819167 test loss: 0.272495
[Epoch 115; Iter    18/  183] train: loss: 0.0572156
[Epoch 115; Iter    48/  183] train: loss: 0.0534715
[Epoch 115; Iter    78/  183] train: loss: 0.0378060
[Epoch 115; Iter   108/  183] train: loss: 0.0386920
[Epoch 115; Iter   138/  183] train: loss: 0.0691984
[Epoch 115; Iter   168/  183] train: loss: 0.1045661
[Epoch 115] ogbg-moltox21: 0.799242 val loss: 0.283923
[Epoch 115] ogbg-moltox21: 0.816801 test loss: 0.287549
[Epoch 116; Iter    15/  183] train: loss: 0.0349058
[Epoch 116; Iter    45/  183] train: loss: 0.0517713
[Epoch 116; Iter    75/  183] train: loss: 0.0444763
[Epoch 116; Iter   105/  183] train: loss: 0.0514213
[Epoch 116; Iter   135/  183] train: loss: 0.0378755
[Epoch 116; Iter   165/  183] train: loss: 0.0561517
[Epoch 116] ogbg-moltox21: 0.805424 val loss: 0.274324
[Epoch 116] ogbg-moltox21: 0.820587 test loss: 0.325719
[Epoch 117; Iter    12/  183] train: loss: 0.0547109
[Epoch 117; Iter    42/  183] train: loss: 0.0639040
[Epoch 117; Iter    72/  183] train: loss: 0.1084443
[Epoch 117; Iter   102/  183] train: loss: 0.0943069
[Epoch 117; Iter   132/  183] train: loss: 0.0723299
[Epoch 117; Iter   162/  183] train: loss: 0.0383672
[Epoch 117] ogbg-moltox21: 0.801742 val loss: 0.277531
[Epoch 117] ogbg-moltox21: 0.819301 test loss: 0.270470
[Epoch 118; Iter     9/  183] train: loss: 0.0311793
[Epoch 118; Iter    39/  183] train: loss: 0.0771332
[Epoch 118; Iter    69/  183] train: loss: 0.0814916
[Epoch 118; Iter    99/  183] train: loss: 0.0779718
[Epoch 118; Iter   129/  183] train: loss: 0.0624927
[Epoch 118; Iter   159/  183] train: loss: 0.0700587
[Epoch 118] ogbg-moltox21: 0.801349 val loss: 0.281055
[Epoch 118] ogbg-moltox21: 0.819303 test loss: 0.273989
[Epoch 119; Iter     6/  183] train: loss: 0.1146622
[Epoch 119; Iter    36/  183] train: loss: 0.1228787
[Epoch 119; Iter    66/  183] train: loss: 0.0573779
[Epoch 119; Iter    96/  183] train: loss: 0.0408483
[Epoch 119; Iter   126/  183] train: loss: 0.0873751
[Epoch 119; Iter   156/  183] train: loss: 0.0432784
[Epoch 119] ogbg-moltox21: 0.801240 val loss: 0.284650
[Epoch 119] ogbg-moltox21: 0.814872 test loss: 0.280091
[Epoch 120; Iter     3/  183] train: loss: 0.0487114
[Epoch 120; Iter    33/  183] train: loss: 0.0420216
[Epoch 120; Iter    63/  183] train: loss: 0.0370338
[Epoch 120; Iter    93/  183] train: loss: 0.0350215
[Epoch 120; Iter   123/  183] train: loss: 0.0322753
[Epoch 120; Iter   153/  183] train: loss: 0.0246739
[Epoch 120; Iter   183/  183] train: loss: 0.0712459
[Epoch 120] ogbg-moltox21: 0.800908 val loss: 0.280823
[Epoch 120] ogbg-moltox21: 0.817232 test loss: 0.274895
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 36.
Statistics on  val_best_checkpoint
mean_pred: -3.761104106903076
std_pred: 2.108459949493408
mean_targets: nan
std_targets: nan
prcauc: 0.45769405126815416
rocauc: 0.8424309462900118
ogbg-moltox21: 0.8424309462900118
OGBNanLabelBCEWithLogitsLoss: 0.19320203363895416
Statistics on  test
mean_pred: -3.6836631298065186
std_pred: 2.159895896911621
mean_targets: nan
std_targets: nan
prcauc: 0.48147263737350454
rocauc: 0.8522899678967458
ogbg-moltox21: 0.8522899678967458
OGBNanLabelBCEWithLogitsLoss: 0.18948903065174819
Statistics on  train
mean_pred: -3.7354326248168945
std_pred: 2.195464849472046
mean_targets: nan
std_targets: nan
prcauc: 0.5913212384671851
rocauc: 0.9114561151314177
ogbg-moltox21: 0.9114561151314177
OGBNanLabelBCEWithLogitsLoss: 0.15181518655494264
[Epoch 99; Iter   128/  209] train: loss: 0.0595369
[Epoch 99; Iter   158/  209] train: loss: 0.0564952
[Epoch 99; Iter   188/  209] train: loss: 0.0315047
[Epoch 99] ogbg-moltox21: 0.822931 val loss: 0.295037
[Epoch 99] ogbg-moltox21: 0.829919 test loss: 0.270797
[Epoch 100; Iter     9/  209] train: loss: 0.0246109
[Epoch 100; Iter    39/  209] train: loss: 0.0357375
[Epoch 100; Iter    69/  209] train: loss: 0.0445837
[Epoch 100; Iter    99/  209] train: loss: 0.0473042
[Epoch 100; Iter   129/  209] train: loss: 0.0562742
[Epoch 100; Iter   159/  209] train: loss: 0.0720618
[Epoch 100; Iter   189/  209] train: loss: 0.0444963
[Epoch 100] ogbg-moltox21: 0.819894 val loss: 0.304181
[Epoch 100] ogbg-moltox21: 0.824884 test loss: 0.281756
[Epoch 101; Iter    10/  209] train: loss: 0.0656551
[Epoch 101; Iter    40/  209] train: loss: 0.0567494
[Epoch 101; Iter    70/  209] train: loss: 0.0458054
[Epoch 101; Iter   100/  209] train: loss: 0.0815720
[Epoch 101; Iter   130/  209] train: loss: 0.0649381
[Epoch 101; Iter   160/  209] train: loss: 0.0865905
[Epoch 101; Iter   190/  209] train: loss: 0.0538304
[Epoch 101] ogbg-moltox21: 0.819728 val loss: 0.304636
[Epoch 101] ogbg-moltox21: 0.824172 test loss: 0.278727
[Epoch 102; Iter    11/  209] train: loss: 0.0592780
[Epoch 102; Iter    41/  209] train: loss: 0.1178919
[Epoch 102; Iter    71/  209] train: loss: 0.0893319
[Epoch 102; Iter   101/  209] train: loss: 0.0619135
[Epoch 102; Iter   131/  209] train: loss: 0.0646684
[Epoch 102; Iter   161/  209] train: loss: 0.1159491
[Epoch 102; Iter   191/  209] train: loss: 0.0694579
[Epoch 102] ogbg-moltox21: 0.818650 val loss: 0.303920
[Epoch 102] ogbg-moltox21: 0.825768 test loss: 0.279009
[Epoch 103; Iter    12/  209] train: loss: 0.0479274
[Epoch 103; Iter    42/  209] train: loss: 0.0463531
[Epoch 103; Iter    72/  209] train: loss: 0.0495577
[Epoch 103; Iter   102/  209] train: loss: 0.1084332
[Epoch 103; Iter   132/  209] train: loss: 0.0736438
[Epoch 103; Iter   162/  209] train: loss: 0.0473998
[Epoch 103; Iter   192/  209] train: loss: 0.0201131
[Epoch 103] ogbg-moltox21: 0.819556 val loss: 0.304983
[Epoch 103] ogbg-moltox21: 0.823580 test loss: 0.281856
[Epoch 104; Iter    13/  209] train: loss: 0.0421553
[Epoch 104; Iter    43/  209] train: loss: 0.0484204
[Epoch 104; Iter    73/  209] train: loss: 0.0557117
[Epoch 104; Iter   103/  209] train: loss: 0.0587371
[Epoch 104; Iter   133/  209] train: loss: 0.0596902
[Epoch 104; Iter   163/  209] train: loss: 0.0597133
[Epoch 104; Iter   193/  209] train: loss: 0.0715556
[Epoch 104] ogbg-moltox21: 0.818364 val loss: 0.299358
[Epoch 104] ogbg-moltox21: 0.831055 test loss: 0.274902
[Epoch 105; Iter    14/  209] train: loss: 0.0460042
[Epoch 105; Iter    44/  209] train: loss: 0.0315090
[Epoch 105; Iter    74/  209] train: loss: 0.0728939
[Epoch 105; Iter   104/  209] train: loss: 0.0551488
[Epoch 105; Iter   134/  209] train: loss: 0.0376206
[Epoch 105; Iter   164/  209] train: loss: 0.0838893
[Epoch 105; Iter   194/  209] train: loss: 0.0552439
[Epoch 105] ogbg-moltox21: 0.817196 val loss: 0.307475
[Epoch 105] ogbg-moltox21: 0.826339 test loss: 0.282692
[Epoch 106; Iter    15/  209] train: loss: 0.0509667
[Epoch 106; Iter    45/  209] train: loss: 0.0698007
[Epoch 106; Iter    75/  209] train: loss: 0.0403705
[Epoch 106; Iter   105/  209] train: loss: 0.0626249
[Epoch 106; Iter   135/  209] train: loss: 0.0340348
[Epoch 106; Iter   165/  209] train: loss: 0.0408346
[Epoch 106; Iter   195/  209] train: loss: 0.0632973
[Epoch 106] ogbg-moltox21: 0.818549 val loss: 0.307963
[Epoch 106] ogbg-moltox21: 0.823210 test loss: 0.292601
[Epoch 107; Iter    16/  209] train: loss: 0.0492873
[Epoch 107; Iter    46/  209] train: loss: 0.0437525
[Epoch 107; Iter    76/  209] train: loss: 0.0694409
[Epoch 107; Iter   106/  209] train: loss: 0.0377882
[Epoch 107; Iter   136/  209] train: loss: 0.0377312
[Epoch 107; Iter   166/  209] train: loss: 0.0285649
[Epoch 107; Iter   196/  209] train: loss: 0.0696530
[Epoch 107] ogbg-moltox21: 0.817077 val loss: 0.308462
[Epoch 107] ogbg-moltox21: 0.825233 test loss: 0.285913
[Epoch 108; Iter    17/  209] train: loss: 0.0266308
[Epoch 108; Iter    47/  209] train: loss: 0.0648058
[Epoch 108; Iter    77/  209] train: loss: 0.0884223
[Epoch 108; Iter   107/  209] train: loss: 0.0346785
[Epoch 108; Iter   137/  209] train: loss: 0.0647941
[Epoch 108; Iter   167/  209] train: loss: 0.0453154
[Epoch 108; Iter   197/  209] train: loss: 0.0669779
[Epoch 108] ogbg-moltox21: 0.814876 val loss: 0.313285
[Epoch 108] ogbg-moltox21: 0.823804 test loss: 0.289071
[Epoch 109; Iter    18/  209] train: loss: 0.0567177
[Epoch 109; Iter    48/  209] train: loss: 0.0797587
[Epoch 109; Iter    78/  209] train: loss: 0.0805195
[Epoch 109; Iter   108/  209] train: loss: 0.0365788
[Epoch 109; Iter   138/  209] train: loss: 0.0547395
[Epoch 109; Iter   168/  209] train: loss: 0.0462337
[Epoch 109; Iter   198/  209] train: loss: 0.0496660
[Epoch 109] ogbg-moltox21: 0.819877 val loss: 0.317085
[Epoch 109] ogbg-moltox21: 0.825897 test loss: 0.289023
[Epoch 110; Iter    19/  209] train: loss: 0.0266439
[Epoch 110; Iter    49/  209] train: loss: 0.0317160
[Epoch 110; Iter    79/  209] train: loss: 0.0693417
[Epoch 110; Iter   109/  209] train: loss: 0.0398491
[Epoch 110; Iter   139/  209] train: loss: 0.0562395
[Epoch 110; Iter   169/  209] train: loss: 0.0323338
[Epoch 110; Iter   199/  209] train: loss: 0.0550955
[Epoch 110] ogbg-moltox21: 0.819383 val loss: 0.317643
[Epoch 110] ogbg-moltox21: 0.826146 test loss: 0.360431
[Epoch 111; Iter    20/  209] train: loss: 0.0439390
[Epoch 111; Iter    50/  209] train: loss: 0.0624264
[Epoch 111; Iter    80/  209] train: loss: 0.0368372
[Epoch 111; Iter   110/  209] train: loss: 0.1237501
[Epoch 111; Iter   140/  209] train: loss: 0.0246249
[Epoch 111; Iter   170/  209] train: loss: 0.0464055
[Epoch 111; Iter   200/  209] train: loss: 0.0395099
[Epoch 111] ogbg-moltox21: 0.818877 val loss: 0.322906
[Epoch 111] ogbg-moltox21: 0.823546 test loss: 0.301607
[Epoch 112; Iter    21/  209] train: loss: 0.0696766
[Epoch 112; Iter    51/  209] train: loss: 0.0573436
[Epoch 112; Iter    81/  209] train: loss: 0.0593649
[Epoch 112; Iter   111/  209] train: loss: 0.0387836
[Epoch 112; Iter   141/  209] train: loss: 0.0397729
[Epoch 112; Iter   171/  209] train: loss: 0.0555646
[Epoch 112; Iter   201/  209] train: loss: 0.0474418
[Epoch 112] ogbg-moltox21: 0.819536 val loss: 0.318650
[Epoch 112] ogbg-moltox21: 0.829137 test loss: 0.389280
[Epoch 113; Iter    22/  209] train: loss: 0.0347762
[Epoch 113; Iter    52/  209] train: loss: 0.0329544
[Epoch 113; Iter    82/  209] train: loss: 0.0469645
[Epoch 113; Iter   112/  209] train: loss: 0.0842061
[Epoch 113; Iter   142/  209] train: loss: 0.0778001
[Epoch 113; Iter   172/  209] train: loss: 0.0668230
[Epoch 113; Iter   202/  209] train: loss: 0.0472597
[Epoch 113] ogbg-moltox21: 0.820515 val loss: 0.317445
[Epoch 113] ogbg-moltox21: 0.821686 test loss: 0.317173
[Epoch 114; Iter    23/  209] train: loss: 0.0557598
[Epoch 114; Iter    53/  209] train: loss: 0.0875069
[Epoch 114; Iter    83/  209] train: loss: 0.1065924
[Epoch 114; Iter   113/  209] train: loss: 0.0424074
[Epoch 114; Iter   143/  209] train: loss: 0.0459930
[Epoch 114; Iter   173/  209] train: loss: 0.0482083
[Epoch 114; Iter   203/  209] train: loss: 0.0425825
[Epoch 114] ogbg-moltox21: 0.818537 val loss: 0.314226
[Epoch 114] ogbg-moltox21: 0.821913 test loss: 0.294988
[Epoch 115; Iter    24/  209] train: loss: 0.0327185
[Epoch 115; Iter    54/  209] train: loss: 0.0586675
[Epoch 115; Iter    84/  209] train: loss: 0.0633277
[Epoch 115; Iter   114/  209] train: loss: 0.0426465
[Epoch 115; Iter   144/  209] train: loss: 0.0333852
[Epoch 115; Iter   174/  209] train: loss: 0.0426311
[Epoch 115; Iter   204/  209] train: loss: 0.0235814
[Epoch 115] ogbg-moltox21: 0.817412 val loss: 0.321451
[Epoch 115] ogbg-moltox21: 0.826342 test loss: 0.295428
[Epoch 116; Iter    25/  209] train: loss: 0.0309383
[Epoch 116; Iter    55/  209] train: loss: 0.0260029
[Epoch 116; Iter    85/  209] train: loss: 0.0547274
[Epoch 116; Iter   115/  209] train: loss: 0.0462470
[Epoch 109] ogbg-moltox21: 0.821721 test loss: 0.257936
[Epoch 110; Iter     3/  183] train: loss: 0.0801163
[Epoch 110; Iter    33/  183] train: loss: 0.0480685
[Epoch 110; Iter    63/  183] train: loss: 0.0640296
[Epoch 110; Iter    93/  183] train: loss: 0.0601126
[Epoch 110; Iter   123/  183] train: loss: 0.0619344
[Epoch 110; Iter   153/  183] train: loss: 0.0802442
[Epoch 110; Iter   183/  183] train: loss: 0.1079277
[Epoch 110] ogbg-moltox21: 0.810032 val loss: 0.262315
[Epoch 110] ogbg-moltox21: 0.834218 test loss: 0.263659
[Epoch 111; Iter    30/  183] train: loss: 0.0502852
[Epoch 111; Iter    60/  183] train: loss: 0.0964183
[Epoch 111; Iter    90/  183] train: loss: 0.0956581
[Epoch 111; Iter   120/  183] train: loss: 0.0867682
[Epoch 111; Iter   150/  183] train: loss: 0.0643182
[Epoch 111; Iter   180/  183] train: loss: 0.0568605
[Epoch 111] ogbg-moltox21: 0.803084 val loss: 0.308803
[Epoch 111] ogbg-moltox21: 0.823581 test loss: 0.303600
[Epoch 112; Iter    27/  183] train: loss: 0.0610642
[Epoch 112; Iter    57/  183] train: loss: 0.0631874
[Epoch 112; Iter    87/  183] train: loss: 0.1132217
[Epoch 112; Iter   117/  183] train: loss: 0.1212499
[Epoch 112; Iter   147/  183] train: loss: 0.0786435
[Epoch 112; Iter   177/  183] train: loss: 0.0735996
[Epoch 112] ogbg-moltox21: 0.810054 val loss: 0.257819
[Epoch 112] ogbg-moltox21: 0.823749 test loss: 0.269716
[Epoch 113; Iter    24/  183] train: loss: 0.0655068
[Epoch 113; Iter    54/  183] train: loss: 0.0396132
[Epoch 113; Iter    84/  183] train: loss: 0.0840272
[Epoch 113; Iter   114/  183] train: loss: 0.0929446
[Epoch 113; Iter   144/  183] train: loss: 0.0604600
[Epoch 113; Iter   174/  183] train: loss: 0.0462960
[Epoch 113] ogbg-moltox21: 0.808139 val loss: 0.245824
[Epoch 113] ogbg-moltox21: 0.827359 test loss: 0.247583
[Epoch 114; Iter    21/  183] train: loss: 0.0564361
[Epoch 114; Iter    51/  183] train: loss: 0.0429445
[Epoch 114; Iter    81/  183] train: loss: 0.0479537
[Epoch 114; Iter   111/  183] train: loss: 0.0659836
[Epoch 114; Iter   141/  183] train: loss: 0.0445427
[Epoch 114; Iter   171/  183] train: loss: 0.0622433
[Epoch 114] ogbg-moltox21: 0.809374 val loss: 0.247249
[Epoch 114] ogbg-moltox21: 0.825422 test loss: 0.249258
[Epoch 115; Iter    18/  183] train: loss: 0.0993338
[Epoch 115; Iter    48/  183] train: loss: 0.0971137
[Epoch 115; Iter    78/  183] train: loss: 0.0653281
[Epoch 115; Iter   108/  183] train: loss: 0.0635082
[Epoch 115; Iter   138/  183] train: loss: 0.0345928
[Epoch 115; Iter   168/  183] train: loss: 0.0668660
[Epoch 115] ogbg-moltox21: 0.809922 val loss: 0.248306
[Epoch 115] ogbg-moltox21: 0.828219 test loss: 0.248317
[Epoch 116; Iter    15/  183] train: loss: 0.0823579
[Epoch 116; Iter    45/  183] train: loss: 0.1126013
[Epoch 116; Iter    75/  183] train: loss: 0.0752820
[Epoch 116; Iter   105/  183] train: loss: 0.0617783
[Epoch 116; Iter   135/  183] train: loss: 0.0423653
[Epoch 116; Iter   165/  183] train: loss: 0.0352054
[Epoch 116] ogbg-moltox21: 0.810236 val loss: 0.248258
[Epoch 116] ogbg-moltox21: 0.823789 test loss: 0.254658
[Epoch 117; Iter    12/  183] train: loss: 0.0684157
[Epoch 117; Iter    42/  183] train: loss: 0.0761110
[Epoch 117; Iter    72/  183] train: loss: 0.1217366
[Epoch 117; Iter   102/  183] train: loss: 0.1027593
[Epoch 117; Iter   132/  183] train: loss: 0.0716947
[Epoch 117; Iter   162/  183] train: loss: 0.0997919
[Epoch 117] ogbg-moltox21: 0.811176 val loss: 0.253345
[Epoch 117] ogbg-moltox21: 0.825765 test loss: 0.266172
[Epoch 118; Iter     9/  183] train: loss: 0.0575943
[Epoch 118; Iter    39/  183] train: loss: 0.0762400
[Epoch 118; Iter    69/  183] train: loss: 0.0848435
[Epoch 118; Iter    99/  183] train: loss: 0.0631455
[Epoch 118; Iter   129/  183] train: loss: 0.0521895
[Epoch 118; Iter   159/  183] train: loss: 0.0657896
[Epoch 118] ogbg-moltox21: 0.807206 val loss: 0.256820
[Epoch 118] ogbg-moltox21: 0.822578 test loss: 0.262919
[Epoch 119; Iter     6/  183] train: loss: 0.0582318
[Epoch 119; Iter    36/  183] train: loss: 0.0829405
[Epoch 119; Iter    66/  183] train: loss: 0.0374247
[Epoch 119; Iter    96/  183] train: loss: 0.0794985
[Epoch 119; Iter   126/  183] train: loss: 0.0903800
[Epoch 119; Iter   156/  183] train: loss: 0.0571703
[Epoch 119] ogbg-moltox21: 0.808775 val loss: 0.253197
[Epoch 119] ogbg-moltox21: 0.826020 test loss: 0.256442
[Epoch 120; Iter     3/  183] train: loss: 0.0699824
[Epoch 120; Iter    33/  183] train: loss: 0.0567426
[Epoch 120; Iter    63/  183] train: loss: 0.0926506
[Epoch 120; Iter    93/  183] train: loss: 0.0944041
[Epoch 120; Iter   123/  183] train: loss: 0.0661787
[Epoch 120; Iter   153/  183] train: loss: 0.0565312
[Epoch 120; Iter   183/  183] train: loss: 0.0413711
[Epoch 120] ogbg-moltox21: 0.806009 val loss: 0.261551
[Epoch 120] ogbg-moltox21: 0.825185 test loss: 0.257396
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -3.511117696762085
std_pred: 1.984588623046875
mean_targets: nan
std_targets: nan
prcauc: 0.4498902318075515
rocauc: 0.8381978944190475
ogbg-moltox21: 0.8381978944190475
OGBNanLabelBCEWithLogitsLoss: 0.19248959608376026
Statistics on  test
mean_pred: -3.45963454246521
std_pred: 2.0552732944488525
mean_targets: nan
std_targets: nan
prcauc: 0.4861127042744822
rocauc: 0.8557922928239409
ogbg-moltox21: 0.8557922928239409
OGBNanLabelBCEWithLogitsLoss: 0.1889779981225729
Statistics on  train
mean_pred: -3.4912900924682617
std_pred: 2.170952320098877
mean_targets: nan
std_targets: nan
prcauc: 0.5618420328904028
rocauc: 0.9003937356736712
ogbg-moltox21: 0.9003937356736712
OGBNanLabelBCEWithLogitsLoss: 0.16047965311776094
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109] ogbg-moltox21: 0.811905 test loss: 0.307068
[Epoch 110; Iter     3/  183] train: loss: 0.0917451
[Epoch 110; Iter    33/  183] train: loss: 0.0182388
[Epoch 110; Iter    63/  183] train: loss: 0.0254335
[Epoch 110; Iter    93/  183] train: loss: 0.0409016
[Epoch 110; Iter   123/  183] train: loss: 0.0337476
[Epoch 110; Iter   153/  183] train: loss: 0.0198127
[Epoch 110; Iter   183/  183] train: loss: 0.0517534
[Epoch 110] ogbg-moltox21: 0.805888 val loss: 0.301306
[Epoch 110] ogbg-moltox21: 0.814170 test loss: 0.305843
[Epoch 111; Iter    30/  183] train: loss: 0.0407874
[Epoch 111; Iter    60/  183] train: loss: 0.0437064
[Epoch 111; Iter    90/  183] train: loss: 0.0198797
[Epoch 111; Iter   120/  183] train: loss: 0.0266484
[Epoch 111; Iter   150/  183] train: loss: 0.0482401
[Epoch 111; Iter   180/  183] train: loss: 0.0269772
[Epoch 111] ogbg-moltox21: 0.806199 val loss: 0.306547
[Epoch 111] ogbg-moltox21: 0.809948 test loss: 0.316790
[Epoch 112; Iter    27/  183] train: loss: 0.0183964
[Epoch 112; Iter    57/  183] train: loss: 0.0460260
[Epoch 112; Iter    87/  183] train: loss: 0.0278091
[Epoch 112; Iter   117/  183] train: loss: 0.0429068
[Epoch 112; Iter   147/  183] train: loss: 0.0437347
[Epoch 112; Iter   177/  183] train: loss: 0.0467298
[Epoch 112] ogbg-moltox21: 0.809807 val loss: 0.306630
[Epoch 112] ogbg-moltox21: 0.808212 test loss: 0.326350
[Epoch 113; Iter    24/  183] train: loss: 0.0299575
[Epoch 113; Iter    54/  183] train: loss: 0.0513105
[Epoch 113; Iter    84/  183] train: loss: 0.0416832
[Epoch 113; Iter   114/  183] train: loss: 0.0349309
[Epoch 113; Iter   144/  183] train: loss: 0.0330388
[Epoch 113; Iter   174/  183] train: loss: 0.0555260
[Epoch 113] ogbg-moltox21: 0.807582 val loss: 0.302877
[Epoch 113] ogbg-moltox21: 0.808716 test loss: 0.318388
[Epoch 114; Iter    21/  183] train: loss: 0.0370441
[Epoch 114; Iter    51/  183] train: loss: 0.0497003
[Epoch 114; Iter    81/  183] train: loss: 0.0358458
[Epoch 114; Iter   111/  183] train: loss: 0.0331758
[Epoch 114; Iter   141/  183] train: loss: 0.0562926
[Epoch 114; Iter   171/  183] train: loss: 0.0415591
[Epoch 114] ogbg-moltox21: 0.811270 val loss: 0.305587
[Epoch 114] ogbg-moltox21: 0.812420 test loss: 0.318553
[Epoch 115; Iter    18/  183] train: loss: 0.0303059
[Epoch 115; Iter    48/  183] train: loss: 0.0372779
[Epoch 115; Iter    78/  183] train: loss: 0.0450743
[Epoch 115; Iter   108/  183] train: loss: 0.0222138
[Epoch 115; Iter   138/  183] train: loss: 0.0198478
[Epoch 115; Iter   168/  183] train: loss: 0.0290088
[Epoch 115] ogbg-moltox21: 0.807437 val loss: 0.307303
[Epoch 115] ogbg-moltox21: 0.809430 test loss: 0.324682
[Epoch 116; Iter    15/  183] train: loss: 0.0418102
[Epoch 116; Iter    45/  183] train: loss: 0.0612103
[Epoch 116; Iter    75/  183] train: loss: 0.0407674
[Epoch 116; Iter   105/  183] train: loss: 0.0193547
[Epoch 116; Iter   135/  183] train: loss: 0.0573273
[Epoch 116; Iter   165/  183] train: loss: 0.0179193
[Epoch 116] ogbg-moltox21: 0.809744 val loss: 0.304418
[Epoch 116] ogbg-moltox21: 0.811077 test loss: 0.320873
[Epoch 117; Iter    12/  183] train: loss: 0.0376152
[Epoch 117; Iter    42/  183] train: loss: 0.0161293
[Epoch 117; Iter    72/  183] train: loss: 0.0425813
[Epoch 117; Iter   102/  183] train: loss: 0.0369276
[Epoch 117; Iter   132/  183] train: loss: 0.0492304
[Epoch 117; Iter   162/  183] train: loss: 0.0188430
[Epoch 117] ogbg-moltox21: 0.808115 val loss: 0.308194
[Epoch 117] ogbg-moltox21: 0.812101 test loss: 0.325616
[Epoch 118; Iter     9/  183] train: loss: 0.0329690
[Epoch 118; Iter    39/  183] train: loss: 0.0430177
[Epoch 118; Iter    69/  183] train: loss: 0.0435045
[Epoch 118; Iter    99/  183] train: loss: 0.0545650
[Epoch 118; Iter   129/  183] train: loss: 0.0984915
[Epoch 118; Iter   159/  183] train: loss: 0.0239547
[Epoch 118] ogbg-moltox21: 0.808501 val loss: 0.306682
[Epoch 118] ogbg-moltox21: 0.812091 test loss: 0.319855
[Epoch 119; Iter     6/  183] train: loss: 0.0538277
[Epoch 119; Iter    36/  183] train: loss: 0.0500792
[Epoch 119; Iter    66/  183] train: loss: 0.0297688
[Epoch 119; Iter    96/  183] train: loss: 0.0383898
[Epoch 119; Iter   126/  183] train: loss: 0.0545711
[Epoch 119; Iter   156/  183] train: loss: 0.0251279
[Epoch 119] ogbg-moltox21: 0.806102 val loss: 0.311456
[Epoch 119] ogbg-moltox21: 0.808925 test loss: 0.325507
[Epoch 120; Iter     3/  183] train: loss: 0.0766743
[Epoch 120; Iter    33/  183] train: loss: 0.0291624
[Epoch 120; Iter    63/  183] train: loss: 0.0479277
[Epoch 120; Iter    93/  183] train: loss: 0.0394182
[Epoch 120; Iter   123/  183] train: loss: 0.0225422
[Epoch 120; Iter   153/  183] train: loss: 0.0206980
[Epoch 120; Iter   183/  183] train: loss: 0.0514234
[Epoch 120] ogbg-moltox21: 0.810478 val loss: 0.311005
[Epoch 120] ogbg-moltox21: 0.810891 test loss: 0.323165
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 41.
Statistics on  val_best_checkpoint
mean_pred: -4.085781097412109
std_pred: 2.446690559387207
mean_targets: nan
std_targets: nan
prcauc: 0.4986100988645141
rocauc: 0.8447222684364258
ogbg-moltox21: 0.8447222684364258
OGBNanLabelBCEWithLogitsLoss: 0.19295059610158205
Statistics on  test
mean_pred: -4.037593364715576
std_pred: 2.4030041694641113
mean_targets: nan
std_targets: nan
prcauc: 0.4872206234535339
rocauc: 0.8534898202902049
ogbg-moltox21: 0.8534898202902049
OGBNanLabelBCEWithLogitsLoss: 0.1935203919187188
Statistics on  train
mean_pred: -4.047586917877197
std_pred: 2.6756694316864014
mean_targets: nan
std_targets: nan
prcauc: 0.6889502143874348
rocauc: 0.9378618079692242
ogbg-moltox21: 0.9378618079692242
OGBNanLabelBCEWithLogitsLoss: 0.12856777350270682
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0632165
[Epoch 116; Iter   175/  209] train: loss: 0.0591513
[Epoch 116; Iter   205/  209] train: loss: 0.0353632
[Epoch 116] ogbg-moltox21: 0.831729 val loss: 0.327553
[Epoch 116] ogbg-moltox21: 0.832235 test loss: 0.279904
[Epoch 117; Iter    26/  209] train: loss: 0.0378470
[Epoch 117; Iter    56/  209] train: loss: 0.0733244
[Epoch 117; Iter    86/  209] train: loss: 0.0548546
[Epoch 117; Iter   116/  209] train: loss: 0.0350729
[Epoch 117; Iter   146/  209] train: loss: 0.1171398
[Epoch 117; Iter   176/  209] train: loss: 0.0718010
[Epoch 117; Iter   206/  209] train: loss: 0.0488072
[Epoch 117] ogbg-moltox21: 0.831592 val loss: 0.356642
[Epoch 117] ogbg-moltox21: 0.831979 test loss: 0.272213
[Epoch 118; Iter    27/  209] train: loss: 0.0486142
[Epoch 118; Iter    57/  209] train: loss: 0.0386759
[Epoch 118; Iter    87/  209] train: loss: 0.0456152
[Epoch 118; Iter   117/  209] train: loss: 0.0381521
[Epoch 118; Iter   147/  209] train: loss: 0.0596255
[Epoch 118; Iter   177/  209] train: loss: 0.0377337
[Epoch 118; Iter   207/  209] train: loss: 0.0460146
[Epoch 118] ogbg-moltox21: 0.832625 val loss: 0.346819
[Epoch 118] ogbg-moltox21: 0.831981 test loss: 0.280104
[Epoch 119; Iter    28/  209] train: loss: 0.0341626
[Epoch 119; Iter    58/  209] train: loss: 0.0289340
[Epoch 119; Iter    88/  209] train: loss: 0.0305284
[Epoch 119; Iter   118/  209] train: loss: 0.0412255
[Epoch 119; Iter   148/  209] train: loss: 0.0646073
[Epoch 119; Iter   178/  209] train: loss: 0.0453704
[Epoch 119; Iter   208/  209] train: loss: 0.0409844
[Epoch 119] ogbg-moltox21: 0.835864 val loss: 0.360339
[Epoch 119] ogbg-moltox21: 0.836367 test loss: 0.277638
[Epoch 120; Iter    29/  209] train: loss: 0.0360194
[Epoch 120; Iter    59/  209] train: loss: 0.0395020
[Epoch 120; Iter    89/  209] train: loss: 0.0355145
[Epoch 120; Iter   119/  209] train: loss: 0.0468494
[Epoch 120; Iter   149/  209] train: loss: 0.0409305
[Epoch 120; Iter   179/  209] train: loss: 0.0285641
[Epoch 120; Iter   209/  209] train: loss: 0.0359593
[Epoch 120] ogbg-moltox21: 0.833107 val loss: 0.329600
[Epoch 120] ogbg-moltox21: 0.832140 test loss: 0.276728
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 50.
Statistics on  val_best_checkpoint
mean_pred: -3.8368782997131348
std_pred: 2.333771228790283
mean_targets: nan
std_targets: nan
prcauc: 0.5259260563029087
rocauc: 0.8774372226631236
ogbg-moltox21: 0.8774372226631236
OGBNanLabelBCEWithLogitsLoss: 0.19320252841269528
Statistics on  test
mean_pred: -3.902038812637329
std_pred: 2.2724359035491943
mean_targets: nan
std_targets: nan
prcauc: 0.4788686953640664
rocauc: 0.847856024352515
ogbg-moltox21: 0.847856024352515
OGBNanLabelBCEWithLogitsLoss: 0.18632154387456398
Statistics on  train
mean_pred: -3.886535167694092
std_pred: 2.6500794887542725
mean_targets: nan
std_targets: nan
prcauc: 0.7101042263266227
rocauc: 0.937048054670639
ogbg-moltox21: 0.937048054670639
OGBNanLabelBCEWithLogitsLoss: 0.1270033507184549
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0323272
[Epoch 116; Iter   175/  209] train: loss: 0.0497705
[Epoch 116; Iter   205/  209] train: loss: 0.0388898
[Epoch 116] ogbg-moltox21: 0.827230 val loss: 0.343060
[Epoch 116] ogbg-moltox21: 0.812692 test loss: 0.326024
[Epoch 117; Iter    26/  209] train: loss: 0.0298179
[Epoch 117; Iter    56/  209] train: loss: 0.0624452
[Epoch 117; Iter    86/  209] train: loss: 0.0428150
[Epoch 117; Iter   116/  209] train: loss: 0.0481365
[Epoch 117; Iter   146/  209] train: loss: 0.0391708
[Epoch 117; Iter   176/  209] train: loss: 0.0529176
[Epoch 117; Iter   206/  209] train: loss: 0.0270919
[Epoch 117] ogbg-moltox21: 0.826249 val loss: 0.348423
[Epoch 117] ogbg-moltox21: 0.811755 test loss: 0.321059
[Epoch 118; Iter    27/  209] train: loss: 0.0605003
[Epoch 118; Iter    57/  209] train: loss: 0.0409677
[Epoch 118; Iter    87/  209] train: loss: 0.0248679
[Epoch 118; Iter   117/  209] train: loss: 0.0331232
[Epoch 118; Iter   147/  209] train: loss: 0.0359599
[Epoch 118; Iter   177/  209] train: loss: 0.0210538
[Epoch 118; Iter   207/  209] train: loss: 0.0435693
[Epoch 118] ogbg-moltox21: 0.828140 val loss: 0.350933
[Epoch 118] ogbg-moltox21: 0.816444 test loss: 0.323124
[Epoch 119; Iter    28/  209] train: loss: 0.0350528
[Epoch 119; Iter    58/  209] train: loss: 0.0531659
[Epoch 119; Iter    88/  209] train: loss: 0.0398476
[Epoch 119; Iter   118/  209] train: loss: 0.0311961
[Epoch 119; Iter   148/  209] train: loss: 0.0215225
[Epoch 119; Iter   178/  209] train: loss: 0.0290805
[Epoch 119; Iter   208/  209] train: loss: 0.0357811
[Epoch 119] ogbg-moltox21: 0.826177 val loss: 0.351373
[Epoch 119] ogbg-moltox21: 0.811990 test loss: 0.331410
[Epoch 120; Iter    29/  209] train: loss: 0.0313506
[Epoch 120; Iter    59/  209] train: loss: 0.0595532
[Epoch 120; Iter    89/  209] train: loss: 0.0671742
[Epoch 120; Iter   119/  209] train: loss: 0.0442709
[Epoch 120; Iter   149/  209] train: loss: 0.0593147
[Epoch 120; Iter   179/  209] train: loss: 0.0374425
[Epoch 120; Iter   209/  209] train: loss: 0.0363706
[Epoch 120] ogbg-moltox21: 0.824263 val loss: 0.353118
[Epoch 120] ogbg-moltox21: 0.810433 test loss: 0.332116
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 36.
Statistics on  val_best_checkpoint
mean_pred: -3.949023962020874
std_pred: 2.323477029800415
mean_targets: nan
std_targets: nan
prcauc: 0.5273431280568978
rocauc: 0.8731263786553053
ogbg-moltox21: 0.8731263786553053
OGBNanLabelBCEWithLogitsLoss: 0.19855906510794605
Statistics on  test
mean_pred: -3.9875097274780273
std_pred: 2.220973014831543
mean_targets: nan
std_targets: nan
prcauc: 0.48057047640425066
rocauc: 0.8555067166808391
ogbg-moltox21: 0.8555067166808391
OGBNanLabelBCEWithLogitsLoss: 0.18573936212945868
Statistics on  train
mean_pred: -3.9995827674865723
std_pred: 3.05662202835083
mean_targets: nan
std_targets: nan
prcauc: 0.6593462574113983
rocauc: 0.9273840501101184
ogbg-moltox21: 0.9273840501101184
OGBNanLabelBCEWithLogitsLoss: 0.13401716501946653
[Epoch 116; Iter   145/  209] train: loss: 0.0626969
[Epoch 116; Iter   175/  209] train: loss: 0.0527049
[Epoch 116; Iter   205/  209] train: loss: 0.0842853
[Epoch 116] ogbg-moltox21: 0.817393 val loss: 0.324568
[Epoch 116] ogbg-moltox21: 0.824612 test loss: 0.342302
[Epoch 117; Iter    26/  209] train: loss: 0.0556055
[Epoch 117; Iter    56/  209] train: loss: 0.0375350
[Epoch 117; Iter    86/  209] train: loss: 0.0433591
[Epoch 117; Iter   116/  209] train: loss: 0.1092687
[Epoch 117; Iter   146/  209] train: loss: 0.0797158
[Epoch 117; Iter   176/  209] train: loss: 0.0371451
[Epoch 117; Iter   206/  209] train: loss: 0.0503790
[Epoch 117] ogbg-moltox21: 0.817541 val loss: 0.322770
[Epoch 117] ogbg-moltox21: 0.825059 test loss: 0.299793
[Epoch 118; Iter    27/  209] train: loss: 0.0402495
[Epoch 118; Iter    57/  209] train: loss: 0.0448649
[Epoch 118; Iter    87/  209] train: loss: 0.0829891
[Epoch 118; Iter   117/  209] train: loss: 0.0459173
[Epoch 118; Iter   147/  209] train: loss: 0.0275648
[Epoch 118; Iter   177/  209] train: loss: 0.0506964
[Epoch 118; Iter   207/  209] train: loss: 0.0461085
[Epoch 118] ogbg-moltox21: 0.814717 val loss: 0.325414
[Epoch 118] ogbg-moltox21: 0.823765 test loss: 0.352209
[Epoch 119; Iter    28/  209] train: loss: 0.0822206
[Epoch 119; Iter    58/  209] train: loss: 0.0547860
[Epoch 119; Iter    88/  209] train: loss: 0.0383172
[Epoch 119; Iter   118/  209] train: loss: 0.0390900
[Epoch 119; Iter   148/  209] train: loss: 0.0416134
[Epoch 119; Iter   178/  209] train: loss: 0.0415045
[Epoch 119; Iter   208/  209] train: loss: 0.0487771
[Epoch 119] ogbg-moltox21: 0.817140 val loss: 0.330539
[Epoch 119] ogbg-moltox21: 0.827606 test loss: 0.360785
[Epoch 120; Iter    29/  209] train: loss: 0.0363242
[Epoch 120; Iter    59/  209] train: loss: 0.0452740
[Epoch 120; Iter    89/  209] train: loss: 0.0343331
[Epoch 120; Iter   119/  209] train: loss: 0.0669201
[Epoch 120; Iter   149/  209] train: loss: 0.0340491
[Epoch 120; Iter   179/  209] train: loss: 0.0601648
[Epoch 120; Iter   209/  209] train: loss: 0.0463857
[Epoch 120] ogbg-moltox21: 0.811345 val loss: 0.334503
[Epoch 120] ogbg-moltox21: 0.822556 test loss: 0.330664
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 37.
Statistics on  val_best_checkpoint
mean_pred: -3.8416099548339844
std_pred: 2.2047159671783447
mean_targets: nan
std_targets: nan
prcauc: 0.5225012207196523
rocauc: 0.8695508609641381
ogbg-moltox21: 0.8695508609641381
OGBNanLabelBCEWithLogitsLoss: 0.19469879429649423
Statistics on  test
mean_pred: -3.798555612564087
std_pred: 2.4574670791625977
mean_targets: nan
std_targets: nan
prcauc: 0.4104780316796342
rocauc: 0.8552930834623681
ogbg-moltox21: 0.8552930834623681
OGBNanLabelBCEWithLogitsLoss: 0.2393099042000594
Statistics on  train
mean_pred: -3.8693463802337646
std_pred: 2.658658981323242
mean_targets: nan
std_targets: nan
prcauc: 0.6078935536868374
rocauc: 0.9172061628780964
ogbg-moltox21: 0.9172061628780964
OGBNanLabelBCEWithLogitsLoss: 0.1586741807928496
All runs completed.
