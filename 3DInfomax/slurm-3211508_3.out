>>> Starting run for dataset: hiv
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_6_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6937668
[Epoch 1; Iter    60/ 1097] train: loss: 0.6939044
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928584
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924998
[Epoch 1; Iter   150/ 1097] train: loss: 0.6920872
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913102
[Epoch 1; Iter   210/ 1097] train: loss: 0.6897854
[Epoch 1; Iter   240/ 1097] train: loss: 0.6905884
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889262
[Epoch 1; Iter   300/ 1097] train: loss: 0.6895396
[Epoch 1; Iter   330/ 1097] train: loss: 0.6865795
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856121
[Epoch 1; Iter   390/ 1097] train: loss: 0.6907162
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829181
[Epoch 1; Iter   450/ 1097] train: loss: 0.6838868
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798050
[Epoch 1; Iter   510/ 1097] train: loss: 0.6780493
[Epoch 1; Iter   540/ 1097] train: loss: 0.6819426
[Epoch 1; Iter   570/ 1097] train: loss: 0.6786606
[Epoch 1; Iter   600/ 1097] train: loss: 0.6738160
[Epoch 1; Iter   630/ 1097] train: loss: 0.6756099
[Epoch 1; Iter   660/ 1097] train: loss: 0.6737949
[Epoch 1; Iter   690/ 1097] train: loss: 0.6669567
[Epoch 1; Iter   720/ 1097] train: loss: 0.6616233
[Epoch 1; Iter   750/ 1097] train: loss: 0.6409676
[Epoch 1; Iter   780/ 1097] train: loss: 0.6047168
[Epoch 1; Iter   810/ 1097] train: loss: 0.5800083
[Epoch 1; Iter   840/ 1097] train: loss: 0.5072190
[Epoch 1; Iter   870/ 1097] train: loss: 0.4275191
[Epoch 1; Iter   900/ 1097] train: loss: 0.3589137
[Epoch 1; Iter   930/ 1097] train: loss: 0.3826609
[Epoch 1; Iter   960/ 1097] train: loss: 0.2654501
[Epoch 1; Iter   990/ 1097] train: loss: 0.2422700
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2026439
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1209590
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1284503
[Epoch 1] ogbg-molhiv: 0.683345 val loss: 0.122340
[Epoch 1] ogbg-molhiv: 0.626416 test loss: 0.161164
[Epoch 2; Iter    13/ 1097] train: loss: 0.1709080
[Epoch 2; Iter    43/ 1097] train: loss: 0.2325415
[Epoch 2; Iter    73/ 1097] train: loss: 0.0640178
[Epoch 2; Iter   103/ 1097] train: loss: 0.1025014
[Epoch 2; Iter   133/ 1097] train: loss: 0.1965415
[Epoch 2; Iter   163/ 1097] train: loss: 0.1328741
[Epoch 2; Iter   193/ 1097] train: loss: 0.3725084
[Epoch 2; Iter   223/ 1097] train: loss: 0.1569706
[Epoch 2; Iter   253/ 1097] train: loss: 0.2157560
[Epoch 2; Iter   283/ 1097] train: loss: 0.1199250
[Epoch 2; Iter   313/ 1097] train: loss: 0.1219997
[Epoch 2; Iter   343/ 1097] train: loss: 0.1812509
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392434
[Epoch 2; Iter   403/ 1097] train: loss: 0.0581722
[Epoch 2; Iter   433/ 1097] train: loss: 0.1854296
[Epoch 2; Iter   463/ 1097] train: loss: 0.2185357
[Epoch 2; Iter   493/ 1097] train: loss: 0.1547657
[Epoch 2; Iter   523/ 1097] train: loss: 0.2514716
[Epoch 2; Iter   553/ 1097] train: loss: 0.1495342
[Epoch 2; Iter   583/ 1097] train: loss: 0.0567325
[Epoch 2; Iter   613/ 1097] train: loss: 0.2791170
[Epoch 2; Iter   643/ 1097] train: loss: 0.3426515
[Epoch 2; Iter   673/ 1097] train: loss: 0.1526512
[Epoch 2; Iter   703/ 1097] train: loss: 0.1294780
[Epoch 2; Iter   733/ 1097] train: loss: 0.1744879
[Epoch 2; Iter   763/ 1097] train: loss: 0.0292907
[Epoch 2; Iter   793/ 1097] train: loss: 0.1117580
[Epoch 2; Iter   823/ 1097] train: loss: 0.0342074
[Epoch 2; Iter   853/ 1097] train: loss: 0.6452128
[Epoch 2; Iter   883/ 1097] train: loss: 0.1483165
[Epoch 2; Iter   913/ 1097] train: loss: 0.4022065
[Epoch 2; Iter   943/ 1097] train: loss: 0.2681246
[Epoch 2; Iter   973/ 1097] train: loss: 0.0439654
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0956736
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0326561
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0539700
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1552485
[Epoch 2] ogbg-molhiv: 0.644786 val loss: 0.167645
[Epoch 2] ogbg-molhiv: 0.605900 test loss: 0.328189
[Epoch 3; Iter    26/ 1097] train: loss: 0.3072164
[Epoch 3; Iter    56/ 1097] train: loss: 0.1478072
[Epoch 3; Iter    86/ 1097] train: loss: 0.6036936
[Epoch 3; Iter   116/ 1097] train: loss: 0.1262593
[Epoch 3; Iter   146/ 1097] train: loss: 0.1854799
[Epoch 3; Iter   176/ 1097] train: loss: 0.1605697
[Epoch 3; Iter   206/ 1097] train: loss: 0.0526321
[Epoch 3; Iter   236/ 1097] train: loss: 0.4109465
[Epoch 3; Iter   266/ 1097] train: loss: 0.2954975
[Epoch 3; Iter   296/ 1097] train: loss: 0.1546505
[Epoch 3; Iter   326/ 1097] train: loss: 0.1557683
[Epoch 3; Iter   356/ 1097] train: loss: 0.0528993
[Epoch 3; Iter   386/ 1097] train: loss: 0.1050146
[Epoch 3; Iter   416/ 1097] train: loss: 0.1610736
[Epoch 3; Iter   446/ 1097] train: loss: 0.0469070
[Epoch 3; Iter   476/ 1097] train: loss: 0.1886211
[Epoch 3; Iter   506/ 1097] train: loss: 0.0405367
[Epoch 3; Iter   536/ 1097] train: loss: 0.1105667
[Epoch 3; Iter   566/ 1097] train: loss: 0.5293685
[Epoch 3; Iter   596/ 1097] train: loss: 0.4582130
[Epoch 3; Iter   626/ 1097] train: loss: 0.0315163
[Epoch 3; Iter   656/ 1097] train: loss: 0.0314612
[Epoch 3; Iter   686/ 1097] train: loss: 0.3966296
[Epoch 3; Iter   716/ 1097] train: loss: 0.1154893
[Epoch 3; Iter   746/ 1097] train: loss: 0.0979433
[Epoch 3; Iter   776/ 1097] train: loss: 0.2825401
[Epoch 3; Iter   806/ 1097] train: loss: 0.0403301
[Epoch 3; Iter   836/ 1097] train: loss: 0.2633204
[Epoch 3; Iter   866/ 1097] train: loss: 0.0756838
[Epoch 3; Iter   896/ 1097] train: loss: 0.0554950
[Epoch 3; Iter   926/ 1097] train: loss: 0.0302920
[Epoch 3; Iter   956/ 1097] train: loss: 0.0333490
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_4_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931346
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929677
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928356
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923388
[Epoch 1; Iter   150/ 1097] train: loss: 0.6921138
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912631
[Epoch 1; Iter   210/ 1097] train: loss: 0.6896061
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897142
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887900
[Epoch 1; Iter   300/ 1097] train: loss: 0.6884043
[Epoch 1; Iter   330/ 1097] train: loss: 0.6880339
[Epoch 1; Iter   360/ 1097] train: loss: 0.6864935
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840698
[Epoch 1; Iter   420/ 1097] train: loss: 0.6852891
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810420
[Epoch 1; Iter   480/ 1097] train: loss: 0.6808093
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776120
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757873
[Epoch 1; Iter   570/ 1097] train: loss: 0.6737893
[Epoch 1; Iter   600/ 1097] train: loss: 0.6730399
[Epoch 1; Iter   630/ 1097] train: loss: 0.6717930
[Epoch 1; Iter   660/ 1097] train: loss: 0.6726711
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649538
[Epoch 1; Iter   720/ 1097] train: loss: 0.6651986
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408582
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051825
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563256
[Epoch 1; Iter   840/ 1097] train: loss: 0.5016583
[Epoch 1; Iter   870/ 1097] train: loss: 0.4438245
[Epoch 1; Iter   900/ 1097] train: loss: 0.4231094
[Epoch 1; Iter   930/ 1097] train: loss: 0.3857171
[Epoch 1; Iter   960/ 1097] train: loss: 0.3341602
[Epoch 1; Iter   990/ 1097] train: loss: 0.1871833
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1537901
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1230242
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2189800
[Epoch 1] ogbg-molhiv: 0.720299 val loss: 0.172504
[Epoch 1] ogbg-molhiv: 0.711230 test loss: 0.170583
[Epoch 2; Iter    13/ 1097] train: loss: 0.0861137
[Epoch 2; Iter    43/ 1097] train: loss: 0.0948735
[Epoch 2; Iter    73/ 1097] train: loss: 0.0622638
[Epoch 2; Iter   103/ 1097] train: loss: 0.0574091
[Epoch 2; Iter   133/ 1097] train: loss: 0.0480283
[Epoch 2; Iter   163/ 1097] train: loss: 0.0783543
[Epoch 2; Iter   193/ 1097] train: loss: 0.3029076
[Epoch 2; Iter   223/ 1097] train: loss: 0.1551666
[Epoch 2; Iter   253/ 1097] train: loss: 0.3983891
[Epoch 2; Iter   283/ 1097] train: loss: 0.1213823
[Epoch 2; Iter   313/ 1097] train: loss: 0.5697960
[Epoch 2; Iter   343/ 1097] train: loss: 0.1524801
[Epoch 2; Iter   373/ 1097] train: loss: 0.0588810
[Epoch 2; Iter   403/ 1097] train: loss: 0.1114528
[Epoch 2; Iter   433/ 1097] train: loss: 0.4664555
[Epoch 2; Iter   463/ 1097] train: loss: 0.3379234
[Epoch 2; Iter   493/ 1097] train: loss: 0.2027093
[Epoch 2; Iter   523/ 1097] train: loss: 0.0425251
[Epoch 2; Iter   553/ 1097] train: loss: 0.0928934
[Epoch 2; Iter   583/ 1097] train: loss: 0.0939735
[Epoch 2; Iter   613/ 1097] train: loss: 0.0322746
[Epoch 2; Iter   643/ 1097] train: loss: 0.1662632
[Epoch 2; Iter   673/ 1097] train: loss: 0.1568309
[Epoch 2; Iter   703/ 1097] train: loss: 0.1269201
[Epoch 2; Iter   733/ 1097] train: loss: 0.0430935
[Epoch 2; Iter   763/ 1097] train: loss: 0.1391044
[Epoch 2; Iter   793/ 1097] train: loss: 0.2231126
[Epoch 2; Iter   823/ 1097] train: loss: 0.1579557
[Epoch 2; Iter   853/ 1097] train: loss: 0.0359026
[Epoch 2; Iter   883/ 1097] train: loss: 0.1542671
[Epoch 2; Iter   913/ 1097] train: loss: 0.0361512
[Epoch 2; Iter   943/ 1097] train: loss: 0.2724829
[Epoch 2; Iter   973/ 1097] train: loss: 0.2716890
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0300674
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1244579
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1935484
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3339556
[Epoch 2] ogbg-molhiv: 0.729497 val loss: 0.117593
[Epoch 2] ogbg-molhiv: 0.737461 test loss: 0.134207
[Epoch 3; Iter    26/ 1097] train: loss: 0.0394057
[Epoch 3; Iter    56/ 1097] train: loss: 0.2930873
[Epoch 3; Iter    86/ 1097] train: loss: 0.0392348
[Epoch 3; Iter   116/ 1097] train: loss: 0.1432494
[Epoch 3; Iter   146/ 1097] train: loss: 0.0324685
[Epoch 3; Iter   176/ 1097] train: loss: 0.1723433
[Epoch 3; Iter   206/ 1097] train: loss: 0.2110601
[Epoch 3; Iter   236/ 1097] train: loss: 0.2497403
[Epoch 3; Iter   266/ 1097] train: loss: 0.2259473
[Epoch 3; Iter   296/ 1097] train: loss: 0.1610407
[Epoch 3; Iter   326/ 1097] train: loss: 0.0349553
[Epoch 3; Iter   356/ 1097] train: loss: 0.0357124
[Epoch 3; Iter   386/ 1097] train: loss: 0.0289367
[Epoch 3; Iter   416/ 1097] train: loss: 0.0759966
[Epoch 3; Iter   446/ 1097] train: loss: 0.0414723
[Epoch 3; Iter   476/ 1097] train: loss: 0.0351631
[Epoch 3; Iter   506/ 1097] train: loss: 0.2180444
[Epoch 3; Iter   536/ 1097] train: loss: 0.0606583
[Epoch 3; Iter   566/ 1097] train: loss: 0.0396227
[Epoch 3; Iter   596/ 1097] train: loss: 0.3374815
[Epoch 3; Iter   626/ 1097] train: loss: 0.0436380
[Epoch 3; Iter   656/ 1097] train: loss: 0.0377473
[Epoch 3; Iter   686/ 1097] train: loss: 0.1186695
[Epoch 3; Iter   716/ 1097] train: loss: 0.0972105
[Epoch 3; Iter   746/ 1097] train: loss: 0.0324873
[Epoch 3; Iter   776/ 1097] train: loss: 0.1526893
[Epoch 3; Iter   806/ 1097] train: loss: 0.1873743
[Epoch 3; Iter   836/ 1097] train: loss: 0.0265471
[Epoch 3; Iter   866/ 1097] train: loss: 0.3116834
[Epoch 3; Iter   896/ 1097] train: loss: 0.1462387
[Epoch 3; Iter   926/ 1097] train: loss: 0.0288572
[Epoch 3; Iter   956/ 1097] train: loss: 0.1284564
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_5_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931635
[Epoch 1; Iter    60/ 1097] train: loss: 0.6943821
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928144
[Epoch 1; Iter   120/ 1097] train: loss: 0.6937405
[Epoch 1; Iter   150/ 1097] train: loss: 0.6921297
[Epoch 1; Iter   180/ 1097] train: loss: 0.6903898
[Epoch 1; Iter   210/ 1097] train: loss: 0.6910319
[Epoch 1; Iter   240/ 1097] train: loss: 0.6910415
[Epoch 1; Iter   270/ 1097] train: loss: 0.6894438
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879163
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868501
[Epoch 1; Iter   360/ 1097] train: loss: 0.6855925
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843225
[Epoch 1; Iter   420/ 1097] train: loss: 0.6839861
[Epoch 1; Iter   450/ 1097] train: loss: 0.6840432
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796545
[Epoch 1; Iter   510/ 1097] train: loss: 0.6790964
[Epoch 1; Iter   540/ 1097] train: loss: 0.6776018
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742067
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721647
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721866
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678065
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654619
[Epoch 1; Iter   720/ 1097] train: loss: 0.6653349
[Epoch 1; Iter   750/ 1097] train: loss: 0.6415719
[Epoch 1; Iter   780/ 1097] train: loss: 0.6056225
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560692
[Epoch 1; Iter   840/ 1097] train: loss: 0.5041943
[Epoch 1; Iter   870/ 1097] train: loss: 0.4662044
[Epoch 1; Iter   900/ 1097] train: loss: 0.3574550
[Epoch 1; Iter   930/ 1097] train: loss: 0.3155825
[Epoch 1; Iter   960/ 1097] train: loss: 0.2272441
[Epoch 1; Iter   990/ 1097] train: loss: 0.3934979
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2029752
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2275120
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1924295
[Epoch 1] ogbg-molhiv: 0.691940 val loss: 0.126629
[Epoch 1] ogbg-molhiv: 0.692145 test loss: 0.154837
[Epoch 2; Iter    13/ 1097] train: loss: 0.0789248
[Epoch 2; Iter    43/ 1097] train: loss: 0.0685123
[Epoch 2; Iter    73/ 1097] train: loss: 0.0625626
[Epoch 2; Iter   103/ 1097] train: loss: 0.0525911
[Epoch 2; Iter   133/ 1097] train: loss: 0.1263950
[Epoch 2; Iter   163/ 1097] train: loss: 0.0552342
[Epoch 2; Iter   193/ 1097] train: loss: 0.3032627
[Epoch 2; Iter   223/ 1097] train: loss: 0.0485250
[Epoch 2; Iter   253/ 1097] train: loss: 0.1484368
[Epoch 2; Iter   283/ 1097] train: loss: 0.1334209
[Epoch 2; Iter   313/ 1097] train: loss: 0.1288157
[Epoch 2; Iter   343/ 1097] train: loss: 0.0589589
[Epoch 2; Iter   373/ 1097] train: loss: 0.2574062
[Epoch 2; Iter   403/ 1097] train: loss: 0.2180674
[Epoch 2; Iter   433/ 1097] train: loss: 0.1386117
[Epoch 2; Iter   463/ 1097] train: loss: 0.2462260
[Epoch 2; Iter   493/ 1097] train: loss: 0.0344995
[Epoch 2; Iter   523/ 1097] train: loss: 0.0671465
[Epoch 2; Iter   553/ 1097] train: loss: 0.1343661
[Epoch 2; Iter   583/ 1097] train: loss: 0.2688271
[Epoch 2; Iter   613/ 1097] train: loss: 0.1813639
[Epoch 2; Iter   643/ 1097] train: loss: 0.2214275
[Epoch 2; Iter   673/ 1097] train: loss: 0.0330908
[Epoch 2; Iter   703/ 1097] train: loss: 0.0374413
[Epoch 2; Iter   733/ 1097] train: loss: 0.2649907
[Epoch 2; Iter   763/ 1097] train: loss: 0.2200102
[Epoch 2; Iter   793/ 1097] train: loss: 0.1252292
[Epoch 2; Iter   823/ 1097] train: loss: 0.2465561
[Epoch 2; Iter   853/ 1097] train: loss: 0.1091126
[Epoch 2; Iter   883/ 1097] train: loss: 0.0272574
[Epoch 2; Iter   913/ 1097] train: loss: 0.0792237
[Epoch 2; Iter   943/ 1097] train: loss: 0.2070734
[Epoch 2; Iter   973/ 1097] train: loss: 0.2671638
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0758897
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2053843
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1811784
[Epoch 2; Iter  1093/ 1097] train: loss: 0.2158341
[Epoch 2] ogbg-molhiv: 0.717366 val loss: 0.106629
[Epoch 2] ogbg-molhiv: 0.710935 test loss: 0.138890
[Epoch 3; Iter    26/ 1097] train: loss: 0.1504164
[Epoch 3; Iter    56/ 1097] train: loss: 0.1882711
[Epoch 3; Iter    86/ 1097] train: loss: 0.4658043
[Epoch 3; Iter   116/ 1097] train: loss: 0.0496515
[Epoch 3; Iter   146/ 1097] train: loss: 0.0443499
[Epoch 3; Iter   176/ 1097] train: loss: 0.2963053
[Epoch 3; Iter   206/ 1097] train: loss: 0.0286840
[Epoch 3; Iter   236/ 1097] train: loss: 0.0291369
[Epoch 3; Iter   266/ 1097] train: loss: 0.0604880
[Epoch 3; Iter   296/ 1097] train: loss: 0.0315745
[Epoch 3; Iter   326/ 1097] train: loss: 0.4512549
[Epoch 3; Iter   356/ 1097] train: loss: 0.0350233
[Epoch 3; Iter   386/ 1097] train: loss: 0.2961130
[Epoch 3; Iter   416/ 1097] train: loss: 0.0337601
[Epoch 3; Iter   446/ 1097] train: loss: 0.0312754
[Epoch 3; Iter   476/ 1097] train: loss: 0.1170048
[Epoch 3; Iter   506/ 1097] train: loss: 0.0273464
[Epoch 3; Iter   536/ 1097] train: loss: 0.1505006
[Epoch 3; Iter   566/ 1097] train: loss: 0.1069295
[Epoch 3; Iter   596/ 1097] train: loss: 0.1252228
[Epoch 3; Iter   626/ 1097] train: loss: 0.0304097
[Epoch 3; Iter   656/ 1097] train: loss: 0.2188051
[Epoch 3; Iter   686/ 1097] train: loss: 0.0366320
[Epoch 3; Iter   716/ 1097] train: loss: 0.2232785
[Epoch 3; Iter   746/ 1097] train: loss: 0.1409516
[Epoch 3; Iter   776/ 1097] train: loss: 0.2458416
[Epoch 3; Iter   806/ 1097] train: loss: 0.2989621
[Epoch 3; Iter   836/ 1097] train: loss: 0.1077523
[Epoch 3; Iter   866/ 1097] train: loss: 0.0360493
[Epoch 3; Iter   896/ 1097] train: loss: 0.0446668
[Epoch 3; Iter   926/ 1097] train: loss: 0.4754883
[Epoch 3; Iter   956/ 1097] train: loss: 0.0711523
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_6_26-05_09-28-20
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932432
[Epoch 1; Iter    60/ 1097] train: loss: 0.6939290
[Epoch 1; Iter    90/ 1097] train: loss: 0.6914838
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923213
[Epoch 1; Iter   150/ 1097] train: loss: 0.6920445
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913080
[Epoch 1; Iter   210/ 1097] train: loss: 0.6906900
[Epoch 1; Iter   240/ 1097] train: loss: 0.6905314
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889268
[Epoch 1; Iter   300/ 1097] train: loss: 0.6889197
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868726
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856242
[Epoch 1; Iter   390/ 1097] train: loss: 0.6903708
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829060
[Epoch 1; Iter   450/ 1097] train: loss: 0.6847395
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798209
[Epoch 1; Iter   510/ 1097] train: loss: 0.6792711
[Epoch 1; Iter   540/ 1097] train: loss: 0.6814792
[Epoch 1; Iter   570/ 1097] train: loss: 0.6773018
[Epoch 1; Iter   600/ 1097] train: loss: 0.6734499
[Epoch 1; Iter   630/ 1097] train: loss: 0.6762406
[Epoch 1; Iter   660/ 1097] train: loss: 0.6727275
[Epoch 1; Iter   690/ 1097] train: loss: 0.6670963
[Epoch 1; Iter   720/ 1097] train: loss: 0.6615651
[Epoch 1; Iter   750/ 1097] train: loss: 0.6422089
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051424
[Epoch 1; Iter   810/ 1097] train: loss: 0.5802650
[Epoch 1; Iter   840/ 1097] train: loss: 0.5032439
[Epoch 1; Iter   870/ 1097] train: loss: 0.4280176
[Epoch 1; Iter   900/ 1097] train: loss: 0.3599989
[Epoch 1; Iter   930/ 1097] train: loss: 0.3674774
[Epoch 1; Iter   960/ 1097] train: loss: 0.2830441
[Epoch 1; Iter   990/ 1097] train: loss: 0.2396472
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2010991
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1206949
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1279451
[Epoch 1] ogbg-molhiv: 0.637235 val loss: 0.153657
[Epoch 1] ogbg-molhiv: 0.631933 test loss: 0.178002
[Epoch 2; Iter    13/ 1097] train: loss: 0.1706529
[Epoch 2; Iter    43/ 1097] train: loss: 0.2356830
[Epoch 2; Iter    73/ 1097] train: loss: 0.0606494
[Epoch 2; Iter   103/ 1097] train: loss: 0.1062194
[Epoch 2; Iter   133/ 1097] train: loss: 0.1630833
[Epoch 2; Iter   163/ 1097] train: loss: 0.1414899
[Epoch 2; Iter   193/ 1097] train: loss: 0.3648979
[Epoch 2; Iter   223/ 1097] train: loss: 0.1554362
[Epoch 2; Iter   253/ 1097] train: loss: 0.1841890
[Epoch 2; Iter   283/ 1097] train: loss: 0.1376374
[Epoch 2; Iter   313/ 1097] train: loss: 0.0950456
[Epoch 2; Iter   343/ 1097] train: loss: 0.1349215
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392550
[Epoch 2; Iter   403/ 1097] train: loss: 0.0499223
[Epoch 2; Iter   433/ 1097] train: loss: 0.2350298
[Epoch 2; Iter   463/ 1097] train: loss: 0.2222069
[Epoch 2; Iter   493/ 1097] train: loss: 0.1350555
[Epoch 2; Iter   523/ 1097] train: loss: 0.2541783
[Epoch 2; Iter   553/ 1097] train: loss: 0.1546148
[Epoch 2; Iter   583/ 1097] train: loss: 0.0385363
[Epoch 2; Iter   613/ 1097] train: loss: 0.3054174
[Epoch 2; Iter   643/ 1097] train: loss: 0.3608449
[Epoch 2; Iter   673/ 1097] train: loss: 0.1625567
[Epoch 2; Iter   703/ 1097] train: loss: 0.1245665
[Epoch 2; Iter   733/ 1097] train: loss: 0.1451025
[Epoch 2; Iter   763/ 1097] train: loss: 0.0330422
[Epoch 2; Iter   793/ 1097] train: loss: 0.1633166
[Epoch 2; Iter   823/ 1097] train: loss: 0.0318237
[Epoch 2; Iter   853/ 1097] train: loss: 0.5722354
[Epoch 2; Iter   883/ 1097] train: loss: 0.1502224
[Epoch 2; Iter   913/ 1097] train: loss: 0.4341837
[Epoch 2; Iter   943/ 1097] train: loss: 0.2482204
[Epoch 2; Iter   973/ 1097] train: loss: 0.0386981
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1034337
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0347455
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0510309
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1241023
[Epoch 2] ogbg-molhiv: 0.684567 val loss: 0.289732
[Epoch 2] ogbg-molhiv: 0.598088 test loss: 0.226493
[Epoch 3; Iter    26/ 1097] train: loss: 0.2343116
[Epoch 3; Iter    56/ 1097] train: loss: 0.1350639
[Epoch 3; Iter    86/ 1097] train: loss: 0.5363858
[Epoch 3; Iter   116/ 1097] train: loss: 0.1190775
[Epoch 3; Iter   146/ 1097] train: loss: 0.1322823
[Epoch 3; Iter   176/ 1097] train: loss: 0.1425277
[Epoch 3; Iter   206/ 1097] train: loss: 0.0376282
[Epoch 3; Iter   236/ 1097] train: loss: 0.4188837
[Epoch 3; Iter   266/ 1097] train: loss: 0.2666330
[Epoch 3; Iter   296/ 1097] train: loss: 0.1347002
[Epoch 3; Iter   326/ 1097] train: loss: 0.1509339
[Epoch 3; Iter   356/ 1097] train: loss: 0.0385170
[Epoch 3; Iter   386/ 1097] train: loss: 0.1048046
[Epoch 3; Iter   416/ 1097] train: loss: 0.1189069
[Epoch 3; Iter   446/ 1097] train: loss: 0.0344469
[Epoch 3; Iter   476/ 1097] train: loss: 0.0876047
[Epoch 3; Iter   506/ 1097] train: loss: 0.0429656
[Epoch 3; Iter   536/ 1097] train: loss: 0.1771127
[Epoch 3; Iter   566/ 1097] train: loss: 0.4387774
[Epoch 3; Iter   596/ 1097] train: loss: 0.4252828
[Epoch 3; Iter   626/ 1097] train: loss: 0.0311531
[Epoch 3; Iter   656/ 1097] train: loss: 0.0306774
[Epoch 3; Iter   686/ 1097] train: loss: 0.3786686
[Epoch 3; Iter   716/ 1097] train: loss: 0.1332466
[Epoch 3; Iter   746/ 1097] train: loss: 0.0877934
[Epoch 3; Iter   776/ 1097] train: loss: 0.2336310
[Epoch 3; Iter   806/ 1097] train: loss: 0.0343912
[Epoch 3; Iter   836/ 1097] train: loss: 0.2575179
[Epoch 3; Iter   866/ 1097] train: loss: 0.0697722
[Epoch 3; Iter   896/ 1097] train: loss: 0.0596176
[Epoch 3; Iter   926/ 1097] train: loss: 0.0359687
[Epoch 3; Iter   956/ 1097] train: loss: 0.0307245
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_4_26-05_09-28-30
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931373
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929594
[Epoch 1; Iter    90/ 1097] train: loss: 0.6924442
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923314
[Epoch 1; Iter   150/ 1097] train: loss: 0.6916901
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912597
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902300
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897208
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887908
[Epoch 1; Iter   300/ 1097] train: loss: 0.6882349
[Epoch 1; Iter   330/ 1097] train: loss: 0.6878585
[Epoch 1; Iter   360/ 1097] train: loss: 0.6860540
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840680
[Epoch 1; Iter   420/ 1097] train: loss: 0.6862881
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810322
[Epoch 1; Iter   480/ 1097] train: loss: 0.6809990
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776155
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757461
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738144
[Epoch 1; Iter   600/ 1097] train: loss: 0.6735436
[Epoch 1; Iter   630/ 1097] train: loss: 0.6717408
[Epoch 1; Iter   660/ 1097] train: loss: 0.6733069
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649680
[Epoch 1; Iter   720/ 1097] train: loss: 0.6651436
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412953
[Epoch 1; Iter   780/ 1097] train: loss: 0.6057239
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563064
[Epoch 1; Iter   840/ 1097] train: loss: 0.4962647
[Epoch 1; Iter   870/ 1097] train: loss: 0.4470668
[Epoch 1; Iter   900/ 1097] train: loss: 0.4199249
[Epoch 1; Iter   930/ 1097] train: loss: 0.3861295
[Epoch 1; Iter   960/ 1097] train: loss: 0.3739844
[Epoch 1; Iter   990/ 1097] train: loss: 0.1842961
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1506150
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1228141
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2116449
[Epoch 1] ogbg-molhiv: 0.666615 val loss: 0.184878
[Epoch 1] ogbg-molhiv: 0.660963 test loss: 0.203441
[Epoch 2; Iter    13/ 1097] train: loss: 0.0841611
[Epoch 2; Iter    43/ 1097] train: loss: 0.1074128
[Epoch 2; Iter    73/ 1097] train: loss: 0.0629483
[Epoch 2; Iter   103/ 1097] train: loss: 0.0526482
[Epoch 2; Iter   133/ 1097] train: loss: 0.0518376
[Epoch 2; Iter   163/ 1097] train: loss: 0.0909466
[Epoch 2; Iter   193/ 1097] train: loss: 0.2856707
[Epoch 2; Iter   223/ 1097] train: loss: 0.1613456
[Epoch 2; Iter   253/ 1097] train: loss: 0.3831520
[Epoch 2; Iter   283/ 1097] train: loss: 0.1302580
[Epoch 2; Iter   313/ 1097] train: loss: 0.6042686
[Epoch 2; Iter   343/ 1097] train: loss: 0.1643408
[Epoch 2; Iter   373/ 1097] train: loss: 0.0439370
[Epoch 2; Iter   403/ 1097] train: loss: 0.0856008
[Epoch 2; Iter   433/ 1097] train: loss: 0.4476657
[Epoch 2; Iter   463/ 1097] train: loss: 0.2724691
[Epoch 2; Iter   493/ 1097] train: loss: 0.1919468
[Epoch 2; Iter   523/ 1097] train: loss: 0.0400255
[Epoch 2; Iter   553/ 1097] train: loss: 0.1035608
[Epoch 2; Iter   583/ 1097] train: loss: 0.1135345
[Epoch 2; Iter   613/ 1097] train: loss: 0.0336483
[Epoch 2; Iter   643/ 1097] train: loss: 0.1978025
[Epoch 2; Iter   673/ 1097] train: loss: 0.1620965
[Epoch 2; Iter   703/ 1097] train: loss: 0.1487167
[Epoch 2; Iter   733/ 1097] train: loss: 0.0369898
[Epoch 2; Iter   763/ 1097] train: loss: 0.1625061
[Epoch 2; Iter   793/ 1097] train: loss: 0.2485707
[Epoch 2; Iter   823/ 1097] train: loss: 0.1236592
[Epoch 2; Iter   853/ 1097] train: loss: 0.0396668
[Epoch 2; Iter   883/ 1097] train: loss: 0.1686805
[Epoch 2; Iter   913/ 1097] train: loss: 0.0345151
[Epoch 2; Iter   943/ 1097] train: loss: 0.2474559
[Epoch 2; Iter   973/ 1097] train: loss: 0.2855329
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0361307
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1404776
[Epoch 2; Iter  1063/ 1097] train: loss: 0.2046086
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3412097
[Epoch 2] ogbg-molhiv: 0.756231 val loss: 0.236613
[Epoch 2] ogbg-molhiv: 0.731275 test loss: 0.119510
[Epoch 3; Iter    26/ 1097] train: loss: 0.0295216
[Epoch 3; Iter    56/ 1097] train: loss: 0.2764919
[Epoch 3; Iter    86/ 1097] train: loss: 0.0557747
[Epoch 3; Iter   116/ 1097] train: loss: 0.1215474
[Epoch 3; Iter   146/ 1097] train: loss: 0.0310938
[Epoch 3; Iter   176/ 1097] train: loss: 0.1985100
[Epoch 3; Iter   206/ 1097] train: loss: 0.1799899
[Epoch 3; Iter   236/ 1097] train: loss: 0.2863598
[Epoch 3; Iter   266/ 1097] train: loss: 0.2808373
[Epoch 3; Iter   296/ 1097] train: loss: 0.1724082
[Epoch 3; Iter   326/ 1097] train: loss: 0.0490591
[Epoch 3; Iter   356/ 1097] train: loss: 0.0355233
[Epoch 3; Iter   386/ 1097] train: loss: 0.0301529
[Epoch 3; Iter   416/ 1097] train: loss: 0.0718467
[Epoch 3; Iter   446/ 1097] train: loss: 0.0452822
[Epoch 3; Iter   476/ 1097] train: loss: 0.0412344
[Epoch 3; Iter   506/ 1097] train: loss: 0.1672350
[Epoch 3; Iter   536/ 1097] train: loss: 0.0709313
[Epoch 3; Iter   566/ 1097] train: loss: 0.0465850
[Epoch 3; Iter   596/ 1097] train: loss: 0.3363628
[Epoch 3; Iter   626/ 1097] train: loss: 0.0409829
[Epoch 3; Iter   656/ 1097] train: loss: 0.0327030
[Epoch 3; Iter   686/ 1097] train: loss: 0.1284012
[Epoch 3; Iter   716/ 1097] train: loss: 0.1074150
[Epoch 3; Iter   746/ 1097] train: loss: 0.0350878
[Epoch 3; Iter   776/ 1097] train: loss: 0.1774615
[Epoch 3; Iter   806/ 1097] train: loss: 0.2814780
[Epoch 3; Iter   836/ 1097] train: loss: 0.0257683
[Epoch 3; Iter   866/ 1097] train: loss: 0.3488612
[Epoch 3; Iter   896/ 1097] train: loss: 0.0891858
[Epoch 3; Iter   926/ 1097] train: loss: 0.0280591
[Epoch 3; Iter   956/ 1097] train: loss: 0.1226069
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_5_26-05_09-28-25
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931785
[Epoch 1; Iter    60/ 1097] train: loss: 0.6948265
[Epoch 1; Iter    90/ 1097] train: loss: 0.6934670
[Epoch 1; Iter   120/ 1097] train: loss: 0.6941205
[Epoch 1; Iter   150/ 1097] train: loss: 0.6912769
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912782
[Epoch 1; Iter   210/ 1097] train: loss: 0.6920481
[Epoch 1; Iter   240/ 1097] train: loss: 0.6910456
[Epoch 1; Iter   270/ 1097] train: loss: 0.6900606
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879135
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868602
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856139
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843088
[Epoch 1; Iter   420/ 1097] train: loss: 0.6847886
[Epoch 1; Iter   450/ 1097] train: loss: 0.6833422
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796653
[Epoch 1; Iter   510/ 1097] train: loss: 0.6785768
[Epoch 1; Iter   540/ 1097] train: loss: 0.6775469
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742100
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721722
[Epoch 1; Iter   630/ 1097] train: loss: 0.6730629
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678073
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654837
[Epoch 1; Iter   720/ 1097] train: loss: 0.6621163
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412005
[Epoch 1; Iter   780/ 1097] train: loss: 0.6062028
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560594
[Epoch 1; Iter   840/ 1097] train: loss: 0.5052131
[Epoch 1; Iter   870/ 1097] train: loss: 0.4543979
[Epoch 1; Iter   900/ 1097] train: loss: 0.3542163
[Epoch 1; Iter   930/ 1097] train: loss: 0.3129459
[Epoch 1; Iter   960/ 1097] train: loss: 0.2264456
[Epoch 1; Iter   990/ 1097] train: loss: 0.4024276
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1870816
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2368086
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1746044
[Epoch 1] ogbg-molhiv: 0.708070 val loss: 0.388386
[Epoch 1] ogbg-molhiv: 0.675353 test loss: 0.312025
[Epoch 2; Iter    13/ 1097] train: loss: 0.0792859
[Epoch 2; Iter    43/ 1097] train: loss: 0.0677284
[Epoch 2; Iter    73/ 1097] train: loss: 0.0674210
[Epoch 2; Iter   103/ 1097] train: loss: 0.0529831
[Epoch 2; Iter   133/ 1097] train: loss: 0.1198220
[Epoch 2; Iter   163/ 1097] train: loss: 0.0595043
[Epoch 2; Iter   193/ 1097] train: loss: 0.2607442
[Epoch 2; Iter   223/ 1097] train: loss: 0.0508029
[Epoch 2; Iter   253/ 1097] train: loss: 0.1402999
[Epoch 2; Iter   283/ 1097] train: loss: 0.1223001
[Epoch 2; Iter   313/ 1097] train: loss: 0.1292439
[Epoch 2; Iter   343/ 1097] train: loss: 0.0456348
[Epoch 2; Iter   373/ 1097] train: loss: 0.2860563
[Epoch 2; Iter   403/ 1097] train: loss: 0.2087779
[Epoch 2; Iter   433/ 1097] train: loss: 0.1507108
[Epoch 2; Iter   463/ 1097] train: loss: 0.2708758
[Epoch 2; Iter   493/ 1097] train: loss: 0.0359442
[Epoch 2; Iter   523/ 1097] train: loss: 0.0762366
[Epoch 2; Iter   553/ 1097] train: loss: 0.1807282
[Epoch 2; Iter   583/ 1097] train: loss: 0.2589084
[Epoch 2; Iter   613/ 1097] train: loss: 0.1752664
[Epoch 2; Iter   643/ 1097] train: loss: 0.2469854
[Epoch 2; Iter   673/ 1097] train: loss: 0.0368632
[Epoch 2; Iter   703/ 1097] train: loss: 0.0594749
[Epoch 2; Iter   733/ 1097] train: loss: 0.3044374
[Epoch 2; Iter   763/ 1097] train: loss: 0.2400610
[Epoch 2; Iter   793/ 1097] train: loss: 0.1478913
[Epoch 2; Iter   823/ 1097] train: loss: 0.2342046
[Epoch 2; Iter   853/ 1097] train: loss: 0.0825151
[Epoch 2; Iter   883/ 1097] train: loss: 0.0283627
[Epoch 2; Iter   913/ 1097] train: loss: 0.1078677
[Epoch 2; Iter   943/ 1097] train: loss: 0.2064964
[Epoch 2; Iter   973/ 1097] train: loss: 0.2188837
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1100979
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1824153
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1950909
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1691184
[Epoch 2] ogbg-molhiv: 0.672218 val loss: 0.136803
[Epoch 2] ogbg-molhiv: 0.649062 test loss: 0.164896
[Epoch 3; Iter    26/ 1097] train: loss: 0.1608400
[Epoch 3; Iter    56/ 1097] train: loss: 0.1564238
[Epoch 3; Iter    86/ 1097] train: loss: 0.4379459
[Epoch 3; Iter   116/ 1097] train: loss: 0.0528683
[Epoch 3; Iter   146/ 1097] train: loss: 0.0578167
[Epoch 3; Iter   176/ 1097] train: loss: 0.2727444
[Epoch 3; Iter   206/ 1097] train: loss: 0.0264654
[Epoch 3; Iter   236/ 1097] train: loss: 0.0280471
[Epoch 3; Iter   266/ 1097] train: loss: 0.0531700
[Epoch 3; Iter   296/ 1097] train: loss: 0.0339660
[Epoch 3; Iter   326/ 1097] train: loss: 0.4452779
[Epoch 3; Iter   356/ 1097] train: loss: 0.0303025
[Epoch 3; Iter   386/ 1097] train: loss: 0.2544396
[Epoch 3; Iter   416/ 1097] train: loss: 0.0325215
[Epoch 3; Iter   446/ 1097] train: loss: 0.0427426
[Epoch 3; Iter   476/ 1097] train: loss: 0.1288070
[Epoch 3; Iter   506/ 1097] train: loss: 0.0707854
[Epoch 3; Iter   536/ 1097] train: loss: 0.0883872
[Epoch 3; Iter   566/ 1097] train: loss: 0.1181134
[Epoch 3; Iter   596/ 1097] train: loss: 0.1265635
[Epoch 3; Iter   626/ 1097] train: loss: 0.0286428
[Epoch 3; Iter   656/ 1097] train: loss: 0.1909503
[Epoch 3; Iter   686/ 1097] train: loss: 0.0316796
[Epoch 3; Iter   716/ 1097] train: loss: 0.1973134
[Epoch 3; Iter   746/ 1097] train: loss: 0.1367811
[Epoch 3; Iter   776/ 1097] train: loss: 0.2843744
[Epoch 3; Iter   806/ 1097] train: loss: 0.2710490
[Epoch 3; Iter   836/ 1097] train: loss: 0.1369301
[Epoch 3; Iter   866/ 1097] train: loss: 0.0345709
[Epoch 3; Iter   896/ 1097] train: loss: 0.0558556
[Epoch 3; Iter   926/ 1097] train: loss: 0.4522243
[Epoch 3; Iter   956/ 1097] train: loss: 0.1674959
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_6_26-05_09-30-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6929836
[Epoch 1; Iter    60/ 1097] train: loss: 0.6941025
[Epoch 1; Iter    90/ 1097] train: loss: 0.6909129
[Epoch 1; Iter   120/ 1097] train: loss: 0.6925658
[Epoch 1; Iter   150/ 1097] train: loss: 0.6940382
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913170
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902380
[Epoch 1; Iter   240/ 1097] train: loss: 0.6902057
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889209
[Epoch 1; Iter   300/ 1097] train: loss: 0.6900887
[Epoch 1; Iter   330/ 1097] train: loss: 0.6863169
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856021
[Epoch 1; Iter   390/ 1097] train: loss: 0.6893879
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829016
[Epoch 1; Iter   450/ 1097] train: loss: 0.6838576
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798173
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798958
[Epoch 1; Iter   540/ 1097] train: loss: 0.6822278
[Epoch 1; Iter   570/ 1097] train: loss: 0.6780481
[Epoch 1; Iter   600/ 1097] train: loss: 0.6736544
[Epoch 1; Iter   630/ 1097] train: loss: 0.6747472
[Epoch 1; Iter   660/ 1097] train: loss: 0.6725076
[Epoch 1; Iter   690/ 1097] train: loss: 0.6671120
[Epoch 1; Iter   720/ 1097] train: loss: 0.6615101
[Epoch 1; Iter   750/ 1097] train: loss: 0.6417219
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051620
[Epoch 1; Iter   810/ 1097] train: loss: 0.5754365
[Epoch 1; Iter   840/ 1097] train: loss: 0.5005482
[Epoch 1; Iter   870/ 1097] train: loss: 0.4291634
[Epoch 1; Iter   900/ 1097] train: loss: 0.3573335
[Epoch 1; Iter   930/ 1097] train: loss: 0.3568260
[Epoch 1; Iter   960/ 1097] train: loss: 0.2872902
[Epoch 1; Iter   990/ 1097] train: loss: 0.2169419
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1991145
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1210284
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1407672
[Epoch 1] ogbg-molhiv: 0.611065 val loss: 0.114873
[Epoch 1] ogbg-molhiv: 0.547674 test loss: 0.164474
[Epoch 2; Iter    13/ 1097] train: loss: 0.1682212
[Epoch 2; Iter    43/ 1097] train: loss: 0.2544574
[Epoch 2; Iter    73/ 1097] train: loss: 0.0649388
[Epoch 2; Iter   103/ 1097] train: loss: 0.0898721
[Epoch 2; Iter   133/ 1097] train: loss: 0.1712982
[Epoch 2; Iter   163/ 1097] train: loss: 0.1481421
[Epoch 2; Iter   193/ 1097] train: loss: 0.3215616
[Epoch 2; Iter   223/ 1097] train: loss: 0.1389889
[Epoch 2; Iter   253/ 1097] train: loss: 0.1748610
[Epoch 2; Iter   283/ 1097] train: loss: 0.1393055
[Epoch 2; Iter   313/ 1097] train: loss: 0.0988677
[Epoch 2; Iter   343/ 1097] train: loss: 0.1516018
[Epoch 2; Iter   373/ 1097] train: loss: 0.0369817
[Epoch 2; Iter   403/ 1097] train: loss: 0.0419134
[Epoch 2; Iter   433/ 1097] train: loss: 0.2668642
[Epoch 2; Iter   463/ 1097] train: loss: 0.2545271
[Epoch 2; Iter   493/ 1097] train: loss: 0.1589954
[Epoch 2; Iter   523/ 1097] train: loss: 0.2604822
[Epoch 2; Iter   553/ 1097] train: loss: 0.1434582
[Epoch 2; Iter   583/ 1097] train: loss: 0.0417999
[Epoch 2; Iter   613/ 1097] train: loss: 0.2745323
[Epoch 2; Iter   643/ 1097] train: loss: 0.4027928
[Epoch 2; Iter   673/ 1097] train: loss: 0.1712343
[Epoch 2; Iter   703/ 1097] train: loss: 0.1434799
[Epoch 2; Iter   733/ 1097] train: loss: 0.1766362
[Epoch 2; Iter   763/ 1097] train: loss: 0.0326984
[Epoch 2; Iter   793/ 1097] train: loss: 0.1259614
[Epoch 2; Iter   823/ 1097] train: loss: 0.0333604
[Epoch 2; Iter   853/ 1097] train: loss: 0.6245289
[Epoch 2; Iter   883/ 1097] train: loss: 0.1614318
[Epoch 2; Iter   913/ 1097] train: loss: 0.3921075
[Epoch 2; Iter   943/ 1097] train: loss: 0.3408529
[Epoch 2; Iter   973/ 1097] train: loss: 0.0412324
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1086370
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0350552
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0842710
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1206857
[Epoch 2] ogbg-molhiv: 0.675209 val loss: 1.320481
[Epoch 2] ogbg-molhiv: 0.639680 test loss: 0.600041
[Epoch 3; Iter    26/ 1097] train: loss: 0.3640716
[Epoch 3; Iter    56/ 1097] train: loss: 0.1596842
[Epoch 3; Iter    86/ 1097] train: loss: 0.5422960
[Epoch 3; Iter   116/ 1097] train: loss: 0.1622857
[Epoch 3; Iter   146/ 1097] train: loss: 0.1481326
[Epoch 3; Iter   176/ 1097] train: loss: 0.1736616
[Epoch 3; Iter   206/ 1097] train: loss: 0.0374339
[Epoch 3; Iter   236/ 1097] train: loss: 0.4047903
[Epoch 3; Iter   266/ 1097] train: loss: 0.2826456
[Epoch 3; Iter   296/ 1097] train: loss: 0.2166936
[Epoch 3; Iter   326/ 1097] train: loss: 0.1230475
[Epoch 3; Iter   356/ 1097] train: loss: 0.0432957
[Epoch 3; Iter   386/ 1097] train: loss: 0.0980850
[Epoch 3; Iter   416/ 1097] train: loss: 0.1439592
[Epoch 3; Iter   446/ 1097] train: loss: 0.0383229
[Epoch 3; Iter   476/ 1097] train: loss: 0.1582338
[Epoch 3; Iter   506/ 1097] train: loss: 0.0368052
[Epoch 3; Iter   536/ 1097] train: loss: 0.1418716
[Epoch 3; Iter   566/ 1097] train: loss: 0.4526532
[Epoch 3; Iter   596/ 1097] train: loss: 0.3834665
[Epoch 3; Iter   626/ 1097] train: loss: 0.0383066
[Epoch 3; Iter   656/ 1097] train: loss: 0.0319603
[Epoch 3; Iter   686/ 1097] train: loss: 0.3947338
[Epoch 3; Iter   716/ 1097] train: loss: 0.1290038
[Epoch 3; Iter   746/ 1097] train: loss: 0.0817962
[Epoch 3; Iter   776/ 1097] train: loss: 0.2143720
[Epoch 3; Iter   806/ 1097] train: loss: 0.0402961
[Epoch 3; Iter   836/ 1097] train: loss: 0.2599047
[Epoch 3; Iter   866/ 1097] train: loss: 0.0716714
[Epoch 3; Iter   896/ 1097] train: loss: 0.0683235
[Epoch 3; Iter   926/ 1097] train: loss: 0.0379202
[Epoch 3; Iter   956/ 1097] train: loss: 0.0304895
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_5_26-05_09-30-00
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931735
[Epoch 1; Iter    60/ 1097] train: loss: 0.6927472
[Epoch 1; Iter    90/ 1097] train: loss: 0.6932407
[Epoch 1; Iter   120/ 1097] train: loss: 0.6946480
[Epoch 1; Iter   150/ 1097] train: loss: 0.6913855
[Epoch 1; Iter   180/ 1097] train: loss: 0.6914127
[Epoch 1; Iter   210/ 1097] train: loss: 0.6922070
[Epoch 1; Iter   240/ 1097] train: loss: 0.6907763
[Epoch 1; Iter   270/ 1097] train: loss: 0.6896634
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879555
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868681
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856108
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843241
[Epoch 1; Iter   420/ 1097] train: loss: 0.6849182
[Epoch 1; Iter   450/ 1097] train: loss: 0.6824472
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796967
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798174
[Epoch 1; Iter   540/ 1097] train: loss: 0.6775867
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742340
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721607
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721516
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678197
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654792
[Epoch 1; Iter   720/ 1097] train: loss: 0.6628169
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408572
[Epoch 1; Iter   780/ 1097] train: loss: 0.6057367
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563859
[Epoch 1; Iter   840/ 1097] train: loss: 0.5076789
[Epoch 1; Iter   870/ 1097] train: loss: 0.4625482
[Epoch 1; Iter   900/ 1097] train: loss: 0.3582475
[Epoch 1; Iter   930/ 1097] train: loss: 0.3329992
[Epoch 1; Iter   960/ 1097] train: loss: 0.2285669
[Epoch 1; Iter   990/ 1097] train: loss: 0.3873539
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1721659
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2393439
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1820941
[Epoch 1] ogbg-molhiv: 0.579322 val loss: 0.904185
[Epoch 1] ogbg-molhiv: 0.597464 test loss: 0.890505
[Epoch 2; Iter    13/ 1097] train: loss: 0.0863161
[Epoch 2; Iter    43/ 1097] train: loss: 0.0710981
[Epoch 2; Iter    73/ 1097] train: loss: 0.0607391
[Epoch 2; Iter   103/ 1097] train: loss: 0.0534483
[Epoch 2; Iter   133/ 1097] train: loss: 0.1161448
[Epoch 2; Iter   163/ 1097] train: loss: 0.0528869
[Epoch 2; Iter   193/ 1097] train: loss: 0.2620347
[Epoch 2; Iter   223/ 1097] train: loss: 0.0488281
[Epoch 2; Iter   253/ 1097] train: loss: 0.1629804
[Epoch 2; Iter   283/ 1097] train: loss: 0.0969135
[Epoch 2; Iter   313/ 1097] train: loss: 0.1407329
[Epoch 2; Iter   343/ 1097] train: loss: 0.0473019
[Epoch 2; Iter   373/ 1097] train: loss: 0.2496783
[Epoch 2; Iter   403/ 1097] train: loss: 0.2591560
[Epoch 2; Iter   433/ 1097] train: loss: 0.2132138
[Epoch 2; Iter   463/ 1097] train: loss: 0.2599362
[Epoch 2; Iter   493/ 1097] train: loss: 0.0378436
[Epoch 2; Iter   523/ 1097] train: loss: 0.1050996
[Epoch 2; Iter   553/ 1097] train: loss: 0.1703805
[Epoch 2; Iter   583/ 1097] train: loss: 0.2549338
[Epoch 2; Iter   613/ 1097] train: loss: 0.1954471
[Epoch 2; Iter   643/ 1097] train: loss: 0.2307229
[Epoch 2; Iter   673/ 1097] train: loss: 0.0356227
[Epoch 2; Iter   703/ 1097] train: loss: 0.0640479
[Epoch 2; Iter   733/ 1097] train: loss: 0.3182336
[Epoch 2; Iter   763/ 1097] train: loss: 0.2369656
[Epoch 2; Iter   793/ 1097] train: loss: 0.1366294
[Epoch 2; Iter   823/ 1097] train: loss: 0.2269734
[Epoch 2; Iter   853/ 1097] train: loss: 0.0533149
[Epoch 2; Iter   883/ 1097] train: loss: 0.0252673
[Epoch 2; Iter   913/ 1097] train: loss: 0.1330355
[Epoch 2; Iter   943/ 1097] train: loss: 0.1993576
[Epoch 2; Iter   973/ 1097] train: loss: 0.2452305
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1459549
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2633027
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1826296
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1639793
[Epoch 2] ogbg-molhiv: 0.604185 val loss: 0.194704
[Epoch 2] ogbg-molhiv: 0.647060 test loss: 0.143550
[Epoch 3; Iter    26/ 1097] train: loss: 0.1545944
[Epoch 3; Iter    56/ 1097] train: loss: 0.1685915
[Epoch 3; Iter    86/ 1097] train: loss: 0.4683888
[Epoch 3; Iter   116/ 1097] train: loss: 0.0767848
[Epoch 3; Iter   146/ 1097] train: loss: 0.0560289
[Epoch 3; Iter   176/ 1097] train: loss: 0.2620152
[Epoch 3; Iter   206/ 1097] train: loss: 0.0284102
[Epoch 3; Iter   236/ 1097] train: loss: 0.0353672
[Epoch 3; Iter   266/ 1097] train: loss: 0.0352875
[Epoch 3; Iter   296/ 1097] train: loss: 0.0314970
[Epoch 3; Iter   326/ 1097] train: loss: 0.4153710
[Epoch 3; Iter   356/ 1097] train: loss: 0.0352653
[Epoch 3; Iter   386/ 1097] train: loss: 0.2938995
[Epoch 3; Iter   416/ 1097] train: loss: 0.0388118
[Epoch 3; Iter   446/ 1097] train: loss: 0.0446090
[Epoch 3; Iter   476/ 1097] train: loss: 0.1375611
[Epoch 3; Iter   506/ 1097] train: loss: 0.0995236
[Epoch 3; Iter   536/ 1097] train: loss: 0.1387353
[Epoch 3; Iter   566/ 1097] train: loss: 0.0879917
[Epoch 3; Iter   596/ 1097] train: loss: 0.1269473
[Epoch 3; Iter   626/ 1097] train: loss: 0.0330659
[Epoch 3; Iter   656/ 1097] train: loss: 0.1699641
[Epoch 3; Iter   686/ 1097] train: loss: 0.0339214
[Epoch 3; Iter   716/ 1097] train: loss: 0.2382849
[Epoch 3; Iter   746/ 1097] train: loss: 0.1477767
[Epoch 3; Iter   776/ 1097] train: loss: 0.2887600
[Epoch 3; Iter   806/ 1097] train: loss: 0.2693481
[Epoch 3; Iter   836/ 1097] train: loss: 0.1266815
[Epoch 3; Iter   866/ 1097] train: loss: 0.0339850
[Epoch 3; Iter   896/ 1097] train: loss: 0.0409843
[Epoch 3; Iter   926/ 1097] train: loss: 0.5396878
[Epoch 3; Iter   956/ 1097] train: loss: 0.1827231
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_4_26-05_09-30-34
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931368
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929709
[Epoch 1; Iter    90/ 1097] train: loss: 0.6921951
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923326
[Epoch 1; Iter   150/ 1097] train: loss: 0.6924561
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912559
[Epoch 1; Iter   210/ 1097] train: loss: 0.6903683
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897203
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887889
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879462
[Epoch 1; Iter   330/ 1097] train: loss: 0.6872656
[Epoch 1; Iter   360/ 1097] train: loss: 0.6859931
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840538
[Epoch 1; Iter   420/ 1097] train: loss: 0.6865224
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810458
[Epoch 1; Iter   480/ 1097] train: loss: 0.6797777
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776138
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757590
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738002
[Epoch 1; Iter   600/ 1097] train: loss: 0.6727681
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721697
[Epoch 1; Iter   660/ 1097] train: loss: 0.6720569
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649595
[Epoch 1; Iter   720/ 1097] train: loss: 0.6618397
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412876
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051318
[Epoch 1; Iter   810/ 1097] train: loss: 0.5557635
[Epoch 1; Iter   840/ 1097] train: loss: 0.4978102
[Epoch 1; Iter   870/ 1097] train: loss: 0.4444568
[Epoch 1; Iter   900/ 1097] train: loss: 0.4249702
[Epoch 1; Iter   930/ 1097] train: loss: 0.3860976
[Epoch 1; Iter   960/ 1097] train: loss: 0.3881784
[Epoch 1; Iter   990/ 1097] train: loss: 0.1850768
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1512061
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1249333
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2290296
[Epoch 1] ogbg-molhiv: 0.668510 val loss: 0.962422
[Epoch 1] ogbg-molhiv: 0.708693 test loss: 0.843575
[Epoch 2; Iter    13/ 1097] train: loss: 0.0813834
[Epoch 2; Iter    43/ 1097] train: loss: 0.1422385
[Epoch 2; Iter    73/ 1097] train: loss: 0.0608678
[Epoch 2; Iter   103/ 1097] train: loss: 0.0544351
[Epoch 2; Iter   133/ 1097] train: loss: 0.0508846
[Epoch 2; Iter   163/ 1097] train: loss: 0.0940736
[Epoch 2; Iter   193/ 1097] train: loss: 0.2558503
[Epoch 2; Iter   223/ 1097] train: loss: 0.1687566
[Epoch 2; Iter   253/ 1097] train: loss: 0.4089078
[Epoch 2; Iter   283/ 1097] train: loss: 0.1424836
[Epoch 2; Iter   313/ 1097] train: loss: 0.6187941
[Epoch 2; Iter   343/ 1097] train: loss: 0.1622789
[Epoch 2; Iter   373/ 1097] train: loss: 0.0396460
[Epoch 2; Iter   403/ 1097] train: loss: 0.1034128
[Epoch 2; Iter   433/ 1097] train: loss: 0.4745893
[Epoch 2; Iter   463/ 1097] train: loss: 0.3170354
[Epoch 2; Iter   493/ 1097] train: loss: 0.2088373
[Epoch 2; Iter   523/ 1097] train: loss: 0.0399883
[Epoch 2; Iter   553/ 1097] train: loss: 0.1261013
[Epoch 2; Iter   583/ 1097] train: loss: 0.0928304
[Epoch 2; Iter   613/ 1097] train: loss: 0.0338833
[Epoch 2; Iter   643/ 1097] train: loss: 0.1355947
[Epoch 2; Iter   673/ 1097] train: loss: 0.1780350
[Epoch 2; Iter   703/ 1097] train: loss: 0.1735401
[Epoch 2; Iter   733/ 1097] train: loss: 0.0366093
[Epoch 2; Iter   763/ 1097] train: loss: 0.1586913
[Epoch 2; Iter   793/ 1097] train: loss: 0.2537750
[Epoch 2; Iter   823/ 1097] train: loss: 0.1363024
[Epoch 2; Iter   853/ 1097] train: loss: 0.0433283
[Epoch 2; Iter   883/ 1097] train: loss: 0.1658334
[Epoch 2; Iter   913/ 1097] train: loss: 0.0342669
[Epoch 2; Iter   943/ 1097] train: loss: 0.2782497
[Epoch 2; Iter   973/ 1097] train: loss: 0.2791530
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0388291
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1508513
[Epoch 2; Iter  1063/ 1097] train: loss: 0.2103899
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3468712
[Epoch 2] ogbg-molhiv: 0.697506 val loss: 0.239992
[Epoch 2] ogbg-molhiv: 0.672796 test loss: 0.406400
[Epoch 3; Iter    26/ 1097] train: loss: 0.0318270
[Epoch 3; Iter    56/ 1097] train: loss: 0.2424784
[Epoch 3; Iter    86/ 1097] train: loss: 0.0406910
[Epoch 3; Iter   116/ 1097] train: loss: 0.0989473
[Epoch 3; Iter   146/ 1097] train: loss: 0.0291102
[Epoch 3; Iter   176/ 1097] train: loss: 0.1688637
[Epoch 3; Iter   206/ 1097] train: loss: 0.1768174
[Epoch 3; Iter   236/ 1097] train: loss: 0.2737676
[Epoch 3; Iter   266/ 1097] train: loss: 0.2849944
[Epoch 3; Iter   296/ 1097] train: loss: 0.1379984
[Epoch 3; Iter   326/ 1097] train: loss: 0.0386315
[Epoch 3; Iter   356/ 1097] train: loss: 0.0369947
[Epoch 3; Iter   386/ 1097] train: loss: 0.0297865
[Epoch 3; Iter   416/ 1097] train: loss: 0.1046156
[Epoch 3; Iter   446/ 1097] train: loss: 0.0396550
[Epoch 3; Iter   476/ 1097] train: loss: 0.0393035
[Epoch 3; Iter   506/ 1097] train: loss: 0.2003157
[Epoch 3; Iter   536/ 1097] train: loss: 0.0616733
[Epoch 3; Iter   566/ 1097] train: loss: 0.0409020
[Epoch 3; Iter   596/ 1097] train: loss: 0.3268175
[Epoch 3; Iter   626/ 1097] train: loss: 0.0404561
[Epoch 3; Iter   656/ 1097] train: loss: 0.0324846
[Epoch 3; Iter   686/ 1097] train: loss: 0.1212288
[Epoch 3; Iter   716/ 1097] train: loss: 0.1185104
[Epoch 3; Iter   746/ 1097] train: loss: 0.0445538
[Epoch 3; Iter   776/ 1097] train: loss: 0.2562331
[Epoch 3; Iter   806/ 1097] train: loss: 0.2927710
[Epoch 3; Iter   836/ 1097] train: loss: 0.0329278
[Epoch 3; Iter   866/ 1097] train: loss: 0.3419058
[Epoch 3; Iter   896/ 1097] train: loss: 0.1320621
[Epoch 3; Iter   926/ 1097] train: loss: 0.0306758
[Epoch 3; Iter   956/ 1097] train: loss: 0.1958516
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_4_26-05_09-32-45
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931365
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929717
[Epoch 1; Iter    90/ 1097] train: loss: 0.6925332
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923445
[Epoch 1; Iter   150/ 1097] train: loss: 0.6922008
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912544
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902406
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897295
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888016
[Epoch 1; Iter   300/ 1097] train: loss: 0.6880606
[Epoch 1; Iter   330/ 1097] train: loss: 0.6877014
[Epoch 1; Iter   360/ 1097] train: loss: 0.6865961
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840554
[Epoch 1; Iter   420/ 1097] train: loss: 0.6844548
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810336
[Epoch 1; Iter   480/ 1097] train: loss: 0.6812363
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776235
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757724
[Epoch 1; Iter   570/ 1097] train: loss: 0.6737962
[Epoch 1; Iter   600/ 1097] train: loss: 0.6731701
[Epoch 1; Iter   630/ 1097] train: loss: 0.6713842
[Epoch 1; Iter   660/ 1097] train: loss: 0.6718303
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649736
[Epoch 1; Iter   720/ 1097] train: loss: 0.6601234
[Epoch 1; Iter   750/ 1097] train: loss: 0.6413683
[Epoch 1; Iter   780/ 1097] train: loss: 0.6055655
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560836
[Epoch 1; Iter   840/ 1097] train: loss: 0.4966683
[Epoch 1; Iter   870/ 1097] train: loss: 0.4463083
[Epoch 1; Iter   900/ 1097] train: loss: 0.4176069
[Epoch 1; Iter   930/ 1097] train: loss: 0.3774824
[Epoch 1; Iter   960/ 1097] train: loss: 0.3627125
[Epoch 1; Iter   990/ 1097] train: loss: 0.1836723
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1522245
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1206530
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1951133
[Epoch 1] ogbg-molhiv: 0.527239 val loss: 0.964277
[Epoch 1] ogbg-molhiv: 0.496891 test loss: 0.754892
[Epoch 2; Iter    13/ 1097] train: loss: 0.0837421
[Epoch 2; Iter    43/ 1097] train: loss: 0.1314277
[Epoch 2; Iter    73/ 1097] train: loss: 0.0651473
[Epoch 2; Iter   103/ 1097] train: loss: 0.0536544
[Epoch 2; Iter   133/ 1097] train: loss: 0.0517237
[Epoch 2; Iter   163/ 1097] train: loss: 0.1006457
[Epoch 2; Iter   193/ 1097] train: loss: 0.2584257
[Epoch 2; Iter   223/ 1097] train: loss: 0.1707698
[Epoch 2; Iter   253/ 1097] train: loss: 0.3604334
[Epoch 2; Iter   283/ 1097] train: loss: 0.1446003
[Epoch 2; Iter   313/ 1097] train: loss: 0.6028736
[Epoch 2; Iter   343/ 1097] train: loss: 0.1458236
[Epoch 2; Iter   373/ 1097] train: loss: 0.0405429
[Epoch 2; Iter   403/ 1097] train: loss: 0.1430929
[Epoch 2; Iter   433/ 1097] train: loss: 0.4698869
[Epoch 2; Iter   463/ 1097] train: loss: 0.2960469
[Epoch 2; Iter   493/ 1097] train: loss: 0.2025238
[Epoch 2; Iter   523/ 1097] train: loss: 0.0436559
[Epoch 2; Iter   553/ 1097] train: loss: 0.1625743
[Epoch 2; Iter   583/ 1097] train: loss: 0.0845846
[Epoch 2; Iter   613/ 1097] train: loss: 0.0421091
[Epoch 2; Iter   643/ 1097] train: loss: 0.1485837
[Epoch 2; Iter   673/ 1097] train: loss: 0.1550736
[Epoch 2; Iter   703/ 1097] train: loss: 0.1406142
[Epoch 2; Iter   733/ 1097] train: loss: 0.0380667
[Epoch 2; Iter   763/ 1097] train: loss: 0.1437217
[Epoch 2; Iter   793/ 1097] train: loss: 0.2453011
[Epoch 2; Iter   823/ 1097] train: loss: 0.1193583
[Epoch 2; Iter   853/ 1097] train: loss: 0.0359242
[Epoch 2; Iter   883/ 1097] train: loss: 0.1593412
[Epoch 2; Iter   913/ 1097] train: loss: 0.0368956
[Epoch 2; Iter   943/ 1097] train: loss: 0.3388153
[Epoch 2; Iter   973/ 1097] train: loss: 0.2746463
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0395248
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1526794
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1688400
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3757368
[Epoch 2] ogbg-molhiv: 0.585685 val loss: 0.251218
[Epoch 2] ogbg-molhiv: 0.693399 test loss: 0.201268
[Epoch 3; Iter    26/ 1097] train: loss: 0.0330952
[Epoch 3; Iter    56/ 1097] train: loss: 0.2713681
[Epoch 3; Iter    86/ 1097] train: loss: 0.0444755
[Epoch 3; Iter   116/ 1097] train: loss: 0.0972757
[Epoch 3; Iter   146/ 1097] train: loss: 0.0334551
[Epoch 3; Iter   176/ 1097] train: loss: 0.2253328
[Epoch 3; Iter   206/ 1097] train: loss: 0.1790286
[Epoch 3; Iter   236/ 1097] train: loss: 0.2630368
[Epoch 3; Iter   266/ 1097] train: loss: 0.3240950
[Epoch 3; Iter   296/ 1097] train: loss: 0.1577314
[Epoch 3; Iter   326/ 1097] train: loss: 0.0373941
[Epoch 3; Iter   356/ 1097] train: loss: 0.0432459
[Epoch 3; Iter   386/ 1097] train: loss: 0.0329121
[Epoch 3; Iter   416/ 1097] train: loss: 0.1047323
[Epoch 3; Iter   446/ 1097] train: loss: 0.0396207
[Epoch 3; Iter   476/ 1097] train: loss: 0.0390049
[Epoch 3; Iter   506/ 1097] train: loss: 0.2104333
[Epoch 3; Iter   536/ 1097] train: loss: 0.0449768
[Epoch 3; Iter   566/ 1097] train: loss: 0.0386696
[Epoch 3; Iter   596/ 1097] train: loss: 0.3466753
[Epoch 3; Iter   626/ 1097] train: loss: 0.0400860
[Epoch 3; Iter   656/ 1097] train: loss: 0.0911650
[Epoch 3; Iter   686/ 1097] train: loss: 0.1456177
[Epoch 3; Iter   716/ 1097] train: loss: 0.1158544
[Epoch 3; Iter   746/ 1097] train: loss: 0.0418216
[Epoch 3; Iter   776/ 1097] train: loss: 0.2688819
[Epoch 3; Iter   806/ 1097] train: loss: 0.2873384
[Epoch 3; Iter   836/ 1097] train: loss: 0.0301793
[Epoch 3; Iter   866/ 1097] train: loss: 0.3430785
[Epoch 3; Iter   896/ 1097] train: loss: 0.1227246
[Epoch 3; Iter   926/ 1097] train: loss: 0.0297805
[Epoch 3; Iter   956/ 1097] train: loss: 0.1949116
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_6_26-05_09-33-26
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6929076
[Epoch 1; Iter    60/ 1097] train: loss: 0.6943719
[Epoch 1; Iter    90/ 1097] train: loss: 0.6909936
[Epoch 1; Iter   120/ 1097] train: loss: 0.6927298
[Epoch 1; Iter   150/ 1097] train: loss: 0.6934567
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913093
[Epoch 1; Iter   210/ 1097] train: loss: 0.6906065
[Epoch 1; Iter   240/ 1097] train: loss: 0.6901342
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889318
[Epoch 1; Iter   300/ 1097] train: loss: 0.6887952
[Epoch 1; Iter   330/ 1097] train: loss: 0.6873167
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856077
[Epoch 1; Iter   390/ 1097] train: loss: 0.6883816
[Epoch 1; Iter   420/ 1097] train: loss: 0.6828962
[Epoch 1; Iter   450/ 1097] train: loss: 0.6848150
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798326
[Epoch 1; Iter   510/ 1097] train: loss: 0.6806523
[Epoch 1; Iter   540/ 1097] train: loss: 0.6818473
[Epoch 1; Iter   570/ 1097] train: loss: 0.6758271
[Epoch 1; Iter   600/ 1097] train: loss: 0.6737152
[Epoch 1; Iter   630/ 1097] train: loss: 0.6753734
[Epoch 1; Iter   660/ 1097] train: loss: 0.6725132
[Epoch 1; Iter   690/ 1097] train: loss: 0.6671481
[Epoch 1; Iter   720/ 1097] train: loss: 0.6616332
[Epoch 1; Iter   750/ 1097] train: loss: 0.6407339
[Epoch 1; Iter   780/ 1097] train: loss: 0.6062188
[Epoch 1; Iter   810/ 1097] train: loss: 0.5685943
[Epoch 1; Iter   840/ 1097] train: loss: 0.4981526
[Epoch 1; Iter   870/ 1097] train: loss: 0.4334599
[Epoch 1; Iter   900/ 1097] train: loss: 0.3582071
[Epoch 1; Iter   930/ 1097] train: loss: 0.3604268
[Epoch 1; Iter   960/ 1097] train: loss: 0.2831786
[Epoch 1; Iter   990/ 1097] train: loss: 0.2171583
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2123185
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1205899
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1563296
[Epoch 1] ogbg-molhiv: 0.571732 val loss: 3.365988
[Epoch 1] ogbg-molhiv: 0.653068 test loss: 2.940663
[Epoch 2; Iter    13/ 1097] train: loss: 0.1670976
[Epoch 2; Iter    43/ 1097] train: loss: 0.2432278
[Epoch 2; Iter    73/ 1097] train: loss: 0.0659655
[Epoch 2; Iter   103/ 1097] train: loss: 0.1397842
[Epoch 2; Iter   133/ 1097] train: loss: 0.1733047
[Epoch 2; Iter   163/ 1097] train: loss: 0.1317779
[Epoch 2; Iter   193/ 1097] train: loss: 0.3234878
[Epoch 2; Iter   223/ 1097] train: loss: 0.1640767
[Epoch 2; Iter   253/ 1097] train: loss: 0.1953322
[Epoch 2; Iter   283/ 1097] train: loss: 0.1585866
[Epoch 2; Iter   313/ 1097] train: loss: 0.1526300
[Epoch 2; Iter   343/ 1097] train: loss: 0.1529338
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392933
[Epoch 2; Iter   403/ 1097] train: loss: 0.0455188
[Epoch 2; Iter   433/ 1097] train: loss: 0.2457446
[Epoch 2; Iter   463/ 1097] train: loss: 0.2615652
[Epoch 2; Iter   493/ 1097] train: loss: 0.1453463
[Epoch 2; Iter   523/ 1097] train: loss: 0.2656473
[Epoch 2; Iter   553/ 1097] train: loss: 0.1439067
[Epoch 2; Iter   583/ 1097] train: loss: 0.0444642
[Epoch 2; Iter   613/ 1097] train: loss: 0.3202035
[Epoch 2; Iter   643/ 1097] train: loss: 0.3320878
[Epoch 2; Iter   673/ 1097] train: loss: 0.1526702
[Epoch 2; Iter   703/ 1097] train: loss: 0.1369638
[Epoch 2; Iter   733/ 1097] train: loss: 0.1499363
[Epoch 2; Iter   763/ 1097] train: loss: 0.0297759
[Epoch 2; Iter   793/ 1097] train: loss: 0.0911944
[Epoch 2; Iter   823/ 1097] train: loss: 0.0352725
[Epoch 2; Iter   853/ 1097] train: loss: 0.6154681
[Epoch 2; Iter   883/ 1097] train: loss: 0.1432603
[Epoch 2; Iter   913/ 1097] train: loss: 0.3783899
[Epoch 2; Iter   943/ 1097] train: loss: 0.3094657
[Epoch 2; Iter   973/ 1097] train: loss: 0.0376488
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1098767
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0353085
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0585102
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1278707
[Epoch 2] ogbg-molhiv: 0.742266 val loss: 0.459066
[Epoch 2] ogbg-molhiv: 0.695355 test loss: 0.379510
[Epoch 3; Iter    26/ 1097] train: loss: 0.3206243
[Epoch 3; Iter    56/ 1097] train: loss: 0.1729149
[Epoch 3; Iter    86/ 1097] train: loss: 0.5109643
[Epoch 3; Iter   116/ 1097] train: loss: 0.1526941
[Epoch 3; Iter   146/ 1097] train: loss: 0.1482736
[Epoch 3; Iter   176/ 1097] train: loss: 0.1502327
[Epoch 3; Iter   206/ 1097] train: loss: 0.0463639
[Epoch 3; Iter   236/ 1097] train: loss: 0.3496789
[Epoch 3; Iter   266/ 1097] train: loss: 0.2713533
[Epoch 3; Iter   296/ 1097] train: loss: 0.2279667
[Epoch 3; Iter   326/ 1097] train: loss: 0.1550128
[Epoch 3; Iter   356/ 1097] train: loss: 0.0490428
[Epoch 3; Iter   386/ 1097] train: loss: 0.0990162
[Epoch 3; Iter   416/ 1097] train: loss: 0.1184859
[Epoch 3; Iter   446/ 1097] train: loss: 0.0390869
[Epoch 3; Iter   476/ 1097] train: loss: 0.1411483
[Epoch 3; Iter   506/ 1097] train: loss: 0.0576435
[Epoch 3; Iter   536/ 1097] train: loss: 0.1768101
[Epoch 3; Iter   566/ 1097] train: loss: 0.4586182
[Epoch 3; Iter   596/ 1097] train: loss: 0.4284237
[Epoch 3; Iter   626/ 1097] train: loss: 0.0316731
[Epoch 3; Iter   656/ 1097] train: loss: 0.0377493
[Epoch 3; Iter   686/ 1097] train: loss: 0.3669298
[Epoch 3; Iter   716/ 1097] train: loss: 0.1561018
[Epoch 3; Iter   746/ 1097] train: loss: 0.0724760
[Epoch 3; Iter   776/ 1097] train: loss: 0.2057848
[Epoch 3; Iter   806/ 1097] train: loss: 0.0363598
[Epoch 3; Iter   836/ 1097] train: loss: 0.2481459
[Epoch 3; Iter   866/ 1097] train: loss: 0.0889583
[Epoch 3; Iter   896/ 1097] train: loss: 0.0911096
[Epoch 3; Iter   926/ 1097] train: loss: 0.0372682
[Epoch 3; Iter   956/ 1097] train: loss: 0.0376592
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_5_26-05_09-33-40
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932184
[Epoch 1; Iter    60/ 1097] train: loss: 0.6934208
[Epoch 1; Iter    90/ 1097] train: loss: 0.6932592
[Epoch 1; Iter   120/ 1097] train: loss: 0.6940998
[Epoch 1; Iter   150/ 1097] train: loss: 0.6910717
[Epoch 1; Iter   180/ 1097] train: loss: 0.6923596
[Epoch 1; Iter   210/ 1097] train: loss: 0.6912225
[Epoch 1; Iter   240/ 1097] train: loss: 0.6914445
[Epoch 1; Iter   270/ 1097] train: loss: 0.6893069
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879395
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868614
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856220
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843571
[Epoch 1; Iter   420/ 1097] train: loss: 0.6847388
[Epoch 1; Iter   450/ 1097] train: loss: 0.6814957
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796837
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798881
[Epoch 1; Iter   540/ 1097] train: loss: 0.6777537
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742346
[Epoch 1; Iter   600/ 1097] train: loss: 0.6722220
[Epoch 1; Iter   630/ 1097] train: loss: 0.6726218
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678224
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654813
[Epoch 1; Iter   720/ 1097] train: loss: 0.6637139
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411246
[Epoch 1; Iter   780/ 1097] train: loss: 0.6055752
[Epoch 1; Iter   810/ 1097] train: loss: 0.5590557
[Epoch 1; Iter   840/ 1097] train: loss: 0.5135453
[Epoch 1; Iter   870/ 1097] train: loss: 0.4590991
[Epoch 1; Iter   900/ 1097] train: loss: 0.3545045
[Epoch 1; Iter   930/ 1097] train: loss: 0.3150695
[Epoch 1; Iter   960/ 1097] train: loss: 0.2291997
[Epoch 1; Iter   990/ 1097] train: loss: 0.4136755
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1929751
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2346991
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1597579
[Epoch 1] ogbg-molhiv: 0.575106 val loss: 2.128527
[Epoch 1] ogbg-molhiv: 0.632310 test loss: 2.225780
[Epoch 2; Iter    13/ 1097] train: loss: 0.0853576
[Epoch 2; Iter    43/ 1097] train: loss: 0.0733735
[Epoch 2; Iter    73/ 1097] train: loss: 0.0624894
[Epoch 2; Iter   103/ 1097] train: loss: 0.0520319
[Epoch 2; Iter   133/ 1097] train: loss: 0.1176817
[Epoch 2; Iter   163/ 1097] train: loss: 0.0451668
[Epoch 2; Iter   193/ 1097] train: loss: 0.2665616
[Epoch 2; Iter   223/ 1097] train: loss: 0.0567489
[Epoch 2; Iter   253/ 1097] train: loss: 0.1378037
[Epoch 2; Iter   283/ 1097] train: loss: 0.1255347
[Epoch 2; Iter   313/ 1097] train: loss: 0.1347343
[Epoch 2; Iter   343/ 1097] train: loss: 0.0416700
[Epoch 2; Iter   373/ 1097] train: loss: 0.2797507
[Epoch 2; Iter   403/ 1097] train: loss: 0.3361592
[Epoch 2; Iter   433/ 1097] train: loss: 0.1545866
[Epoch 2; Iter   463/ 1097] train: loss: 0.3348128
[Epoch 2; Iter   493/ 1097] train: loss: 0.0387688
[Epoch 2; Iter   523/ 1097] train: loss: 0.1085647
[Epoch 2; Iter   553/ 1097] train: loss: 0.1660825
[Epoch 2; Iter   583/ 1097] train: loss: 0.2653221
[Epoch 2; Iter   613/ 1097] train: loss: 0.1587391
[Epoch 2; Iter   643/ 1097] train: loss: 0.2408033
[Epoch 2; Iter   673/ 1097] train: loss: 0.0366160
[Epoch 2; Iter   703/ 1097] train: loss: 0.0553145
[Epoch 2; Iter   733/ 1097] train: loss: 0.3160486
[Epoch 2; Iter   763/ 1097] train: loss: 0.2420189
[Epoch 2; Iter   793/ 1097] train: loss: 0.1353994
[Epoch 2; Iter   823/ 1097] train: loss: 0.2453550
[Epoch 2; Iter   853/ 1097] train: loss: 0.0531550
[Epoch 2; Iter   883/ 1097] train: loss: 0.0285382
[Epoch 2; Iter   913/ 1097] train: loss: 0.1519428
[Epoch 2; Iter   943/ 1097] train: loss: 0.2186966
[Epoch 2; Iter   973/ 1097] train: loss: 0.2420268
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1567087
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2242238
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1949356
[Epoch 2; Iter  1093/ 1097] train: loss: 0.2040605
[Epoch 2] ogbg-molhiv: 0.602516 val loss: 0.192561
[Epoch 2] ogbg-molhiv: 0.610865 test loss: 0.141726
[Epoch 3; Iter    26/ 1097] train: loss: 0.1750682
[Epoch 3; Iter    56/ 1097] train: loss: 0.1670675
[Epoch 3; Iter    86/ 1097] train: loss: 0.4728419
[Epoch 3; Iter   116/ 1097] train: loss: 0.0864117
[Epoch 3; Iter   146/ 1097] train: loss: 0.0407306
[Epoch 3; Iter   176/ 1097] train: loss: 0.2890295
[Epoch 3; Iter   206/ 1097] train: loss: 0.0292564
[Epoch 3; Iter   236/ 1097] train: loss: 0.0313833
[Epoch 3; Iter   266/ 1097] train: loss: 0.0351988
[Epoch 3; Iter   296/ 1097] train: loss: 0.0296929
[Epoch 3; Iter   326/ 1097] train: loss: 0.4992990
[Epoch 3; Iter   356/ 1097] train: loss: 0.0359404
[Epoch 3; Iter   386/ 1097] train: loss: 0.3157001
[Epoch 3; Iter   416/ 1097] train: loss: 0.0382424
[Epoch 3; Iter   446/ 1097] train: loss: 0.0336950
[Epoch 3; Iter   476/ 1097] train: loss: 0.1524684
[Epoch 3; Iter   506/ 1097] train: loss: 0.1119888
[Epoch 3; Iter   536/ 1097] train: loss: 0.1261919
[Epoch 3; Iter   566/ 1097] train: loss: 0.1206426
[Epoch 3; Iter   596/ 1097] train: loss: 0.1215178
[Epoch 3; Iter   626/ 1097] train: loss: 0.0319174
[Epoch 3; Iter   656/ 1097] train: loss: 0.1802052
[Epoch 3; Iter   686/ 1097] train: loss: 0.0340474
[Epoch 3; Iter   716/ 1097] train: loss: 0.1928474
[Epoch 3; Iter   746/ 1097] train: loss: 0.1293730
[Epoch 3; Iter   776/ 1097] train: loss: 0.3070218
[Epoch 3; Iter   806/ 1097] train: loss: 0.2599915
[Epoch 3; Iter   836/ 1097] train: loss: 0.1411177
[Epoch 3; Iter   866/ 1097] train: loss: 0.0383503
[Epoch 3; Iter   896/ 1097] train: loss: 0.0518845
[Epoch 3; Iter   926/ 1097] train: loss: 0.4366487
[Epoch 3; Iter   956/ 1097] train: loss: 0.1832013
[Epoch 3; Iter   986/ 1097] train: loss: 0.2205703
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0886187
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0879364
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0320302
[Epoch 3] ogbg-molhiv: 0.757578 val loss: 0.313727
[Epoch 3] ogbg-molhiv: 0.758151 test loss: 0.153195
[Epoch 4; Iter     9/ 1097] train: loss: 0.3862506
[Epoch 4; Iter    39/ 1097] train: loss: 0.0940491
[Epoch 4; Iter    69/ 1097] train: loss: 0.1128955
[Epoch 4; Iter    99/ 1097] train: loss: 0.0301854
[Epoch 4; Iter   129/ 1097] train: loss: 0.1329330
[Epoch 4; Iter   159/ 1097] train: loss: 0.4407690
[Epoch 4; Iter   189/ 1097] train: loss: 0.0301290
[Epoch 4; Iter   219/ 1097] train: loss: 0.4241340
[Epoch 4; Iter   249/ 1097] train: loss: 0.0316447
[Epoch 4; Iter   279/ 1097] train: loss: 0.1424044
[Epoch 4; Iter   309/ 1097] train: loss: 0.1523537
[Epoch 4; Iter   339/ 1097] train: loss: 0.0987377
[Epoch 4; Iter   369/ 1097] train: loss: 0.1538679
[Epoch 4; Iter   399/ 1097] train: loss: 0.1536854
[Epoch 4; Iter   429/ 1097] train: loss: 0.0583904
[Epoch 4; Iter   459/ 1097] train: loss: 0.0439027
[Epoch 4; Iter   489/ 1097] train: loss: 0.0319988
[Epoch 4; Iter   519/ 1097] train: loss: 0.0958421
[Epoch 4; Iter   549/ 1097] train: loss: 0.0371313
[Epoch 4; Iter   579/ 1097] train: loss: 0.0381169
[Epoch 4; Iter   609/ 1097] train: loss: 0.2247833
[Epoch 4; Iter   639/ 1097] train: loss: 0.0283901
[Epoch 4; Iter   669/ 1097] train: loss: 0.2152619
[Epoch 4; Iter   699/ 1097] train: loss: 0.0659621
[Epoch 4; Iter   729/ 1097] train: loss: 0.4267885
[Epoch 4; Iter   759/ 1097] train: loss: 0.0380219
[Epoch 4; Iter   789/ 1097] train: loss: 0.3399914
[Epoch 4; Iter   819/ 1097] train: loss: 0.0382286
[Epoch 4; Iter   849/ 1097] train: loss: 0.2287235
[Epoch 4; Iter   879/ 1097] train: loss: 0.1495612
[Epoch 4; Iter   909/ 1097] train: loss: 0.5450599
[Epoch 4; Iter   939/ 1097] train: loss: 0.0446360
[Epoch 4; Iter   969/ 1097] train: loss: 0.0549401
[Epoch 4; Iter   999/ 1097] train: loss: 0.2826192
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2589925
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2007585
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1057084
[Epoch 4] ogbg-molhiv: 0.753503 val loss: 0.541002
[Epoch 4] ogbg-molhiv: 0.745880 test loss: 0.195344
[Epoch 5; Iter    22/ 1097] train: loss: 0.0558346
[Epoch 5; Iter    52/ 1097] train: loss: 0.1292382
[Epoch 5; Iter    82/ 1097] train: loss: 0.4445356
[Epoch 5; Iter   112/ 1097] train: loss: 0.0455009
[Epoch 5; Iter   142/ 1097] train: loss: 0.3113189
[Epoch 5; Iter   172/ 1097] train: loss: 0.1829826
[Epoch 5; Iter   202/ 1097] train: loss: 0.0308545
[Epoch 5; Iter   232/ 1097] train: loss: 0.1733088
[Epoch 5; Iter   262/ 1097] train: loss: 0.1656406
[Epoch 5; Iter   292/ 1097] train: loss: 0.2914168
[Epoch 5; Iter   322/ 1097] train: loss: 0.1638188
[Epoch 5; Iter   352/ 1097] train: loss: 0.1895342
[Epoch 5; Iter   382/ 1097] train: loss: 0.2347591
[Epoch 5; Iter   412/ 1097] train: loss: 0.0395082
[Epoch 5; Iter   442/ 1097] train: loss: 0.1374638
[Epoch 5; Iter   472/ 1097] train: loss: 0.1984218
[Epoch 5; Iter   502/ 1097] train: loss: 0.1259231
[Epoch 5; Iter   532/ 1097] train: loss: 0.0623806
[Epoch 5; Iter   562/ 1097] train: loss: 0.2355453
[Epoch 5; Iter   592/ 1097] train: loss: 0.0595894
[Epoch 5; Iter   622/ 1097] train: loss: 0.1284231
[Epoch 5; Iter   652/ 1097] train: loss: 0.2545489
[Epoch 5; Iter   682/ 1097] train: loss: 0.0264256
[Epoch 5; Iter   712/ 1097] train: loss: 0.2070368
[Epoch 5; Iter   742/ 1097] train: loss: 0.0286681
[Epoch 5; Iter   772/ 1097] train: loss: 0.0341048
[Epoch 5; Iter   802/ 1097] train: loss: 0.1418808
[Epoch 5; Iter   832/ 1097] train: loss: 0.2601145
[Epoch 5; Iter   862/ 1097] train: loss: 0.0614216
[Epoch 5; Iter   892/ 1097] train: loss: 0.0854601
[Epoch 5; Iter   922/ 1097] train: loss: 0.1194702
[Epoch 5; Iter   952/ 1097] train: loss: 0.2429848
[Epoch 5; Iter   982/ 1097] train: loss: 0.0781350
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2686147
[Epoch 5; Iter  1042/ 1097] train: loss: 0.3344289
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0461535
[Epoch 5] ogbg-molhiv: 0.761145 val loss: 0.285643
[Epoch 5] ogbg-molhiv: 0.743307 test loss: 0.139910
[Epoch 6; Iter     5/ 1097] train: loss: 0.2487565
[Epoch 6; Iter    35/ 1097] train: loss: 0.3780073
[Epoch 6; Iter    65/ 1097] train: loss: 0.0406270
[Epoch 6; Iter    95/ 1097] train: loss: 0.1741670
[Epoch 6; Iter   125/ 1097] train: loss: 0.2486059
[Epoch 6; Iter   155/ 1097] train: loss: 0.0601383
[Epoch 6; Iter   185/ 1097] train: loss: 0.1265327
[Epoch 6; Iter   215/ 1097] train: loss: 0.1250868
[Epoch 6; Iter   245/ 1097] train: loss: 0.0492995
[Epoch 6; Iter   275/ 1097] train: loss: 0.1324993
[Epoch 6; Iter   305/ 1097] train: loss: 0.0269651
[Epoch 6; Iter   335/ 1097] train: loss: 0.0301244
[Epoch 6; Iter   365/ 1097] train: loss: 0.0458334
[Epoch 6; Iter   395/ 1097] train: loss: 0.1940893
[Epoch 6; Iter   425/ 1097] train: loss: 0.0446853
[Epoch 6; Iter   455/ 1097] train: loss: 0.2462755
[Epoch 6; Iter   485/ 1097] train: loss: 0.0335216
[Epoch 6; Iter   515/ 1097] train: loss: 0.0417761
[Epoch 6; Iter   545/ 1097] train: loss: 0.1228545
[Epoch 6; Iter   575/ 1097] train: loss: 0.0339848
[Epoch 6; Iter   605/ 1097] train: loss: 0.0607069
[Epoch 6; Iter   635/ 1097] train: loss: 0.1835238
[Epoch 6; Iter   665/ 1097] train: loss: 0.1969190
[Epoch 6; Iter   695/ 1097] train: loss: 0.1616464
[Epoch 6; Iter   725/ 1097] train: loss: 0.3584448
[Epoch 6; Iter   755/ 1097] train: loss: 0.1862202
[Epoch 6; Iter   785/ 1097] train: loss: 0.4218531
[Epoch 6; Iter   815/ 1097] train: loss: 0.0554623
[Epoch 6; Iter   845/ 1097] train: loss: 0.0426868
[Epoch 6; Iter   875/ 1097] train: loss: 0.0762885
[Epoch 6; Iter   905/ 1097] train: loss: 0.1171706
[Epoch 6; Iter   935/ 1097] train: loss: 0.0446465
[Epoch 6; Iter   965/ 1097] train: loss: 0.0438413
[Epoch 6; Iter   995/ 1097] train: loss: 0.0311334
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0844441
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1893203
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2086624
[Epoch 6] ogbg-molhiv: 0.785831 val loss: 0.274933
[Epoch 6] ogbg-molhiv: 0.762357 test loss: 0.192724
[Epoch 7; Iter    18/ 1097] train: loss: 0.0534633
[Epoch 7; Iter    48/ 1097] train: loss: 0.0281291
[Epoch 7; Iter    78/ 1097] train: loss: 0.2001503
[Epoch 7; Iter   108/ 1097] train: loss: 0.2656524
[Epoch 7; Iter   138/ 1097] train: loss: 0.1167167
[Epoch 7; Iter   168/ 1097] train: loss: 0.0270427
[Epoch 7; Iter   198/ 1097] train: loss: 0.2150328
[Epoch 7; Iter   228/ 1097] train: loss: 0.2002728
[Epoch 7; Iter   258/ 1097] train: loss: 0.0215896
[Epoch 7; Iter   288/ 1097] train: loss: 0.0234574
[Epoch 7; Iter   318/ 1097] train: loss: 0.1130865
[Epoch 7; Iter   348/ 1097] train: loss: 0.0268732
[Epoch 7; Iter   378/ 1097] train: loss: 0.2115813
[Epoch 7; Iter   408/ 1097] train: loss: 0.2899941
[Epoch 7; Iter   438/ 1097] train: loss: 0.0580353
[Epoch 7; Iter   468/ 1097] train: loss: 0.0319844
[Epoch 7; Iter   498/ 1097] train: loss: 0.1857526
[Epoch 7; Iter   528/ 1097] train: loss: 0.1006899
[Epoch 7; Iter   558/ 1097] train: loss: 0.0336502
[Epoch 7; Iter   588/ 1097] train: loss: 0.2019135
[Epoch 7; Iter   618/ 1097] train: loss: 0.1662533
[Epoch 7; Iter   648/ 1097] train: loss: 0.0528177
[Epoch 7; Iter   678/ 1097] train: loss: 0.0266896
[Epoch 7; Iter   708/ 1097] train: loss: 0.1899735
[Epoch 7; Iter   738/ 1097] train: loss: 0.1856323
[Epoch 7; Iter   768/ 1097] train: loss: 0.1578502
[Epoch 7; Iter   798/ 1097] train: loss: 0.1147507
[Epoch 7; Iter   828/ 1097] train: loss: 0.0596141
[Epoch 7; Iter   858/ 1097] train: loss: 0.2467908
[Epoch 7; Iter   888/ 1097] train: loss: 0.0410166
[Epoch 7; Iter   918/ 1097] train: loss: 0.1005322
[Epoch 7; Iter   948/ 1097] train: loss: 0.0359729
[Epoch 7; Iter   978/ 1097] train: loss: 0.0599979
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0590355
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0415240
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1798152
[Epoch 7] ogbg-molhiv: 0.762064 val loss: 0.945647
[Epoch 7] ogbg-molhiv: 0.740455 test loss: 0.198696
[Epoch 3; Iter   986/ 1097] train: loss: 0.0334403
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2816857
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0332691
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0889156
[Epoch 3] ogbg-molhiv: 0.733377 val loss: 0.102514
[Epoch 3] ogbg-molhiv: 0.749261 test loss: 0.120978
[Epoch 4; Iter     9/ 1097] train: loss: 0.0625326
[Epoch 4; Iter    39/ 1097] train: loss: 0.0392040
[Epoch 4; Iter    69/ 1097] train: loss: 0.0266443
[Epoch 4; Iter    99/ 1097] train: loss: 0.0287808
[Epoch 4; Iter   129/ 1097] train: loss: 0.2150482
[Epoch 4; Iter   159/ 1097] train: loss: 0.1265253
[Epoch 4; Iter   189/ 1097] train: loss: 0.0445650
[Epoch 4; Iter   219/ 1097] train: loss: 0.0337708
[Epoch 4; Iter   249/ 1097] train: loss: 0.1435616
[Epoch 4; Iter   279/ 1097] train: loss: 0.2212927
[Epoch 4; Iter   309/ 1097] train: loss: 0.0514884
[Epoch 4; Iter   339/ 1097] train: loss: 0.0382258
[Epoch 4; Iter   369/ 1097] train: loss: 0.0742991
[Epoch 4; Iter   399/ 1097] train: loss: 0.2264995
[Epoch 4; Iter   429/ 1097] train: loss: 0.0336091
[Epoch 4; Iter   459/ 1097] train: loss: 0.1530077
[Epoch 4; Iter   489/ 1097] train: loss: 0.0260193
[Epoch 4; Iter   519/ 1097] train: loss: 0.1848639
[Epoch 4; Iter   549/ 1097] train: loss: 0.0461229
[Epoch 4; Iter   579/ 1097] train: loss: 0.0999072
[Epoch 4; Iter   609/ 1097] train: loss: 0.1107781
[Epoch 4; Iter   639/ 1097] train: loss: 0.0916584
[Epoch 4; Iter   669/ 1097] train: loss: 0.2328306
[Epoch 4; Iter   699/ 1097] train: loss: 0.1164729
[Epoch 4; Iter   729/ 1097] train: loss: 0.0367736
[Epoch 4; Iter   759/ 1097] train: loss: 0.0282643
[Epoch 4; Iter   789/ 1097] train: loss: 0.0257932
[Epoch 4; Iter   819/ 1097] train: loss: 0.1436810
[Epoch 4; Iter   849/ 1097] train: loss: 0.0309274
[Epoch 4; Iter   879/ 1097] train: loss: 0.0369829
[Epoch 4; Iter   909/ 1097] train: loss: 0.0344897
[Epoch 4; Iter   939/ 1097] train: loss: 0.3399282
[Epoch 4; Iter   969/ 1097] train: loss: 0.0965298
[Epoch 4; Iter   999/ 1097] train: loss: 0.0337958
[Epoch 4; Iter  1029/ 1097] train: loss: 0.1810039
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1708509
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1691096
[Epoch 4] ogbg-molhiv: 0.788678 val loss: 0.089593
[Epoch 4] ogbg-molhiv: 0.752270 test loss: 0.123006
[Epoch 5; Iter    22/ 1097] train: loss: 0.1017998
[Epoch 5; Iter    52/ 1097] train: loss: 0.1585031
[Epoch 5; Iter    82/ 1097] train: loss: 0.1581564
[Epoch 5; Iter   112/ 1097] train: loss: 0.3935542
[Epoch 5; Iter   142/ 1097] train: loss: 0.3374801
[Epoch 5; Iter   172/ 1097] train: loss: 0.0286852
[Epoch 5; Iter   202/ 1097] train: loss: 0.1790243
[Epoch 5; Iter   232/ 1097] train: loss: 0.2382348
[Epoch 5; Iter   262/ 1097] train: loss: 0.0672089
[Epoch 5; Iter   292/ 1097] train: loss: 0.1880651
[Epoch 5; Iter   322/ 1097] train: loss: 0.0276958
[Epoch 5; Iter   352/ 1097] train: loss: 0.0911542
[Epoch 5; Iter   382/ 1097] train: loss: 0.1440066
[Epoch 5; Iter   412/ 1097] train: loss: 0.2987715
[Epoch 5; Iter   442/ 1097] train: loss: 0.1503921
[Epoch 5; Iter   472/ 1097] train: loss: 0.1059308
[Epoch 5; Iter   502/ 1097] train: loss: 0.1785484
[Epoch 5; Iter   532/ 1097] train: loss: 0.2348067
[Epoch 5; Iter   562/ 1097] train: loss: 0.2835404
[Epoch 5; Iter   592/ 1097] train: loss: 0.0520223
[Epoch 5; Iter   622/ 1097] train: loss: 0.0334840
[Epoch 5; Iter   652/ 1097] train: loss: 0.1035742
[Epoch 5; Iter   682/ 1097] train: loss: 0.1440582
[Epoch 5; Iter   712/ 1097] train: loss: 0.0332348
[Epoch 5; Iter   742/ 1097] train: loss: 0.1492053
[Epoch 5; Iter   772/ 1097] train: loss: 0.2562872
[Epoch 5; Iter   802/ 1097] train: loss: 0.0811073
[Epoch 5; Iter   832/ 1097] train: loss: 0.0551403
[Epoch 5; Iter   862/ 1097] train: loss: 0.0846138
[Epoch 5; Iter   892/ 1097] train: loss: 0.0418323
[Epoch 5; Iter   922/ 1097] train: loss: 0.0363182
[Epoch 5; Iter   952/ 1097] train: loss: 0.0291976
[Epoch 5; Iter   982/ 1097] train: loss: 0.0672113
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0314474
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2210091
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0454108
[Epoch 5] ogbg-molhiv: 0.784952 val loss: 0.080784
[Epoch 5] ogbg-molhiv: 0.752434 test loss: 0.119351
[Epoch 6; Iter     5/ 1097] train: loss: 0.0560403
[Epoch 6; Iter    35/ 1097] train: loss: 0.2648273
[Epoch 6; Iter    65/ 1097] train: loss: 0.0272992
[Epoch 6; Iter    95/ 1097] train: loss: 0.0632152
[Epoch 6; Iter   125/ 1097] train: loss: 0.3728862
[Epoch 6; Iter   155/ 1097] train: loss: 0.2970348
[Epoch 6; Iter   185/ 1097] train: loss: 0.0290284
[Epoch 6; Iter   215/ 1097] train: loss: 0.1500181
[Epoch 6; Iter   245/ 1097] train: loss: 0.2366405
[Epoch 6; Iter   275/ 1097] train: loss: 0.0339964
[Epoch 6; Iter   305/ 1097] train: loss: 0.1649607
[Epoch 6; Iter   335/ 1097] train: loss: 0.0700073
[Epoch 6; Iter   365/ 1097] train: loss: 0.2808619
[Epoch 6; Iter   395/ 1097] train: loss: 0.2559066
[Epoch 6; Iter   425/ 1097] train: loss: 0.0358790
[Epoch 6; Iter   455/ 1097] train: loss: 0.3285229
[Epoch 6; Iter   485/ 1097] train: loss: 0.0331989
[Epoch 6; Iter   515/ 1097] train: loss: 0.1091538
[Epoch 6; Iter   545/ 1097] train: loss: 0.1765362
[Epoch 6; Iter   575/ 1097] train: loss: 0.2344788
[Epoch 6; Iter   605/ 1097] train: loss: 0.0399570
[Epoch 6; Iter   635/ 1097] train: loss: 0.0284712
[Epoch 6; Iter   665/ 1097] train: loss: 0.1988348
[Epoch 6; Iter   695/ 1097] train: loss: 0.1798907
[Epoch 6; Iter   725/ 1097] train: loss: 0.1893843
[Epoch 6; Iter   755/ 1097] train: loss: 0.0517567
[Epoch 6; Iter   785/ 1097] train: loss: 0.1217272
[Epoch 6; Iter   815/ 1097] train: loss: 0.0334541
[Epoch 6; Iter   845/ 1097] train: loss: 0.1261224
[Epoch 6; Iter   875/ 1097] train: loss: 0.1294841
[Epoch 6; Iter   905/ 1097] train: loss: 0.2772962
[Epoch 6; Iter   935/ 1097] train: loss: 0.0320842
[Epoch 6; Iter   965/ 1097] train: loss: 0.0268462
[Epoch 6; Iter   995/ 1097] train: loss: 0.1733303
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1933911
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0262354
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2481316
[Epoch 6] ogbg-molhiv: 0.795234 val loss: 0.082889
[Epoch 6] ogbg-molhiv: 0.765905 test loss: 0.117285
[Epoch 7; Iter    18/ 1097] train: loss: 0.2094202
[Epoch 7; Iter    48/ 1097] train: loss: 0.6607606
[Epoch 7; Iter    78/ 1097] train: loss: 0.3751817
[Epoch 7; Iter   108/ 1097] train: loss: 0.0362693
[Epoch 7; Iter   138/ 1097] train: loss: 0.0213531
[Epoch 7; Iter   168/ 1097] train: loss: 0.0250317
[Epoch 7; Iter   198/ 1097] train: loss: 0.1689922
[Epoch 7; Iter   228/ 1097] train: loss: 0.1529447
[Epoch 7; Iter   258/ 1097] train: loss: 0.1192316
[Epoch 7; Iter   288/ 1097] train: loss: 0.1659409
[Epoch 7; Iter   318/ 1097] train: loss: 0.0359066
[Epoch 7; Iter   348/ 1097] train: loss: 0.0520900
[Epoch 7; Iter   378/ 1097] train: loss: 0.0277319
[Epoch 7; Iter   408/ 1097] train: loss: 0.0405685
[Epoch 7; Iter   438/ 1097] train: loss: 0.0295523
[Epoch 7; Iter   468/ 1097] train: loss: 0.2983337
[Epoch 7; Iter   498/ 1097] train: loss: 0.0432448
[Epoch 7; Iter   528/ 1097] train: loss: 0.0274986
[Epoch 7; Iter   558/ 1097] train: loss: 0.2506319
[Epoch 7; Iter   588/ 1097] train: loss: 0.1014445
[Epoch 7; Iter   618/ 1097] train: loss: 0.1974692
[Epoch 7; Iter   648/ 1097] train: loss: 0.1952559
[Epoch 7; Iter   678/ 1097] train: loss: 0.0832726
[Epoch 7; Iter   708/ 1097] train: loss: 0.0970567
[Epoch 7; Iter   738/ 1097] train: loss: 0.0391584
[Epoch 7; Iter   768/ 1097] train: loss: 0.0797382
[Epoch 7; Iter   798/ 1097] train: loss: 0.1986228
[Epoch 7; Iter   828/ 1097] train: loss: 0.1551442
[Epoch 7; Iter   858/ 1097] train: loss: 0.1001639
[Epoch 7; Iter   888/ 1097] train: loss: 0.0855650
[Epoch 7; Iter   918/ 1097] train: loss: 0.1713616
[Epoch 7; Iter   948/ 1097] train: loss: 0.1584620
[Epoch 7; Iter   978/ 1097] train: loss: 0.0853422
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0253295
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2684586
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0490948
[Epoch 7] ogbg-molhiv: 0.789609 val loss: 0.080140
[Epoch 7] ogbg-molhiv: 0.756424 test loss: 0.115676
[Epoch 3; Iter   986/ 1097] train: loss: 0.0282360
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0251230
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1375426
[Epoch 3; Iter  1076/ 1097] train: loss: 0.3087243
[Epoch 3] ogbg-molhiv: 0.780809 val loss: 0.085807
[Epoch 3] ogbg-molhiv: 0.728340 test loss: 0.124471
[Epoch 4; Iter     9/ 1097] train: loss: 0.1793579
[Epoch 4; Iter    39/ 1097] train: loss: 0.1933269
[Epoch 4; Iter    69/ 1097] train: loss: 0.0416244
[Epoch 4; Iter    99/ 1097] train: loss: 0.2838563
[Epoch 4; Iter   129/ 1097] train: loss: 0.1681812
[Epoch 4; Iter   159/ 1097] train: loss: 0.0876937
[Epoch 4; Iter   189/ 1097] train: loss: 0.2740844
[Epoch 4; Iter   219/ 1097] train: loss: 0.1503020
[Epoch 4; Iter   249/ 1097] train: loss: 0.1641322
[Epoch 4; Iter   279/ 1097] train: loss: 0.1056998
[Epoch 4; Iter   309/ 1097] train: loss: 0.1141609
[Epoch 4; Iter   339/ 1097] train: loss: 0.0290574
[Epoch 4; Iter   369/ 1097] train: loss: 0.1055802
[Epoch 4; Iter   399/ 1097] train: loss: 0.0813220
[Epoch 4; Iter   429/ 1097] train: loss: 0.1767343
[Epoch 4; Iter   459/ 1097] train: loss: 0.0278169
[Epoch 4; Iter   489/ 1097] train: loss: 0.1620589
[Epoch 4; Iter   519/ 1097] train: loss: 0.3038638
[Epoch 4; Iter   549/ 1097] train: loss: 0.1808390
[Epoch 4; Iter   579/ 1097] train: loss: 0.0377782
[Epoch 4; Iter   609/ 1097] train: loss: 0.3103428
[Epoch 4; Iter   639/ 1097] train: loss: 0.3241965
[Epoch 4; Iter   669/ 1097] train: loss: 0.2732227
[Epoch 4; Iter   699/ 1097] train: loss: 0.0324874
[Epoch 4; Iter   729/ 1097] train: loss: 0.1988593
[Epoch 4; Iter   759/ 1097] train: loss: 0.2838763
[Epoch 4; Iter   789/ 1097] train: loss: 0.3708489
[Epoch 4; Iter   819/ 1097] train: loss: 0.1664826
[Epoch 4; Iter   849/ 1097] train: loss: 0.0461646
[Epoch 4; Iter   879/ 1097] train: loss: 0.0283495
[Epoch 4; Iter   909/ 1097] train: loss: 0.3773086
[Epoch 4; Iter   939/ 1097] train: loss: 0.1106164
[Epoch 4; Iter   969/ 1097] train: loss: 0.0392601
[Epoch 4; Iter   999/ 1097] train: loss: 0.1785551
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3615532
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2774177
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0428436
[Epoch 4] ogbg-molhiv: 0.791186 val loss: 0.995821
[Epoch 4] ogbg-molhiv: 0.752809 test loss: 2.248495
[Epoch 5; Iter    22/ 1097] train: loss: 0.3628150
[Epoch 5; Iter    52/ 1097] train: loss: 0.1770769
[Epoch 5; Iter    82/ 1097] train: loss: 0.1046427
[Epoch 5; Iter   112/ 1097] train: loss: 0.0619117
[Epoch 5; Iter   142/ 1097] train: loss: 0.0823573
[Epoch 5; Iter   172/ 1097] train: loss: 0.0394503
[Epoch 5; Iter   202/ 1097] train: loss: 0.0962179
[Epoch 5; Iter   232/ 1097] train: loss: 0.0322781
[Epoch 5; Iter   262/ 1097] train: loss: 0.0416876
[Epoch 5; Iter   292/ 1097] train: loss: 0.1828185
[Epoch 5; Iter   322/ 1097] train: loss: 0.1555110
[Epoch 5; Iter   352/ 1097] train: loss: 0.0612446
[Epoch 5; Iter   382/ 1097] train: loss: 0.2787651
[Epoch 5; Iter   412/ 1097] train: loss: 0.2453213
[Epoch 5; Iter   442/ 1097] train: loss: 0.3473075
[Epoch 5; Iter   472/ 1097] train: loss: 0.1383016
[Epoch 5; Iter   502/ 1097] train: loss: 0.2078004
[Epoch 5; Iter   532/ 1097] train: loss: 0.0572092
[Epoch 5; Iter   562/ 1097] train: loss: 0.0399320
[Epoch 5; Iter   592/ 1097] train: loss: 0.0467700
[Epoch 5; Iter   622/ 1097] train: loss: 0.1230353
[Epoch 5; Iter   652/ 1097] train: loss: 0.1108723
[Epoch 5; Iter   682/ 1097] train: loss: 0.1714260
[Epoch 5; Iter   712/ 1097] train: loss: 0.0279052
[Epoch 5; Iter   742/ 1097] train: loss: 0.1695771
[Epoch 5; Iter   772/ 1097] train: loss: 0.1883430
[Epoch 5; Iter   802/ 1097] train: loss: 0.1392522
[Epoch 5; Iter   832/ 1097] train: loss: 0.0312133
[Epoch 5; Iter   862/ 1097] train: loss: 0.1972554
[Epoch 5; Iter   892/ 1097] train: loss: 0.0477886
[Epoch 5; Iter   922/ 1097] train: loss: 0.3172630
[Epoch 5; Iter   952/ 1097] train: loss: 0.0270963
[Epoch 5; Iter   982/ 1097] train: loss: 0.2813166
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2407015
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2031515
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0477861
[Epoch 5] ogbg-molhiv: 0.775249 val loss: 0.168750
[Epoch 5] ogbg-molhiv: 0.708465 test loss: 0.470078
[Epoch 6; Iter     5/ 1097] train: loss: 0.0795436
[Epoch 6; Iter    35/ 1097] train: loss: 0.0801857
[Epoch 6; Iter    65/ 1097] train: loss: 0.1095342
[Epoch 6; Iter    95/ 1097] train: loss: 0.0432816
[Epoch 6; Iter   125/ 1097] train: loss: 0.1137734
[Epoch 6; Iter   155/ 1097] train: loss: 0.0243676
[Epoch 6; Iter   185/ 1097] train: loss: 0.0214766
[Epoch 6; Iter   215/ 1097] train: loss: 0.3203340
[Epoch 6; Iter   245/ 1097] train: loss: 0.2106807
[Epoch 6; Iter   275/ 1097] train: loss: 0.0273914
[Epoch 6; Iter   305/ 1097] train: loss: 0.0564857
[Epoch 6; Iter   335/ 1097] train: loss: 0.1792855
[Epoch 6; Iter   365/ 1097] train: loss: 0.0571385
[Epoch 6; Iter   395/ 1097] train: loss: 0.2826931
[Epoch 6; Iter   425/ 1097] train: loss: 0.1838132
[Epoch 6; Iter   455/ 1097] train: loss: 0.1162785
[Epoch 6; Iter   485/ 1097] train: loss: 0.1684032
[Epoch 6; Iter   515/ 1097] train: loss: 0.0237380
[Epoch 6; Iter   545/ 1097] train: loss: 0.1557406
[Epoch 6; Iter   575/ 1097] train: loss: 0.0307919
[Epoch 6; Iter   605/ 1097] train: loss: 0.0225101
[Epoch 6; Iter   635/ 1097] train: loss: 0.0260817
[Epoch 6; Iter   665/ 1097] train: loss: 0.0343102
[Epoch 6; Iter   695/ 1097] train: loss: 0.1565851
[Epoch 6; Iter   725/ 1097] train: loss: 0.0273359
[Epoch 6; Iter   755/ 1097] train: loss: 0.0940512
[Epoch 6; Iter   785/ 1097] train: loss: 0.0303421
[Epoch 6; Iter   815/ 1097] train: loss: 0.1251956
[Epoch 6; Iter   845/ 1097] train: loss: 0.0881405
[Epoch 6; Iter   875/ 1097] train: loss: 0.1331940
[Epoch 6; Iter   905/ 1097] train: loss: 0.2804132
[Epoch 6; Iter   935/ 1097] train: loss: 0.1540164
[Epoch 6; Iter   965/ 1097] train: loss: 0.1250805
[Epoch 6; Iter   995/ 1097] train: loss: 0.0432384
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0314520
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0977266
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2258459
[Epoch 6] ogbg-molhiv: 0.782698 val loss: 0.256795
[Epoch 6] ogbg-molhiv: 0.760299 test loss: 0.193640
[Epoch 7; Iter    18/ 1097] train: loss: 0.0343331
[Epoch 7; Iter    48/ 1097] train: loss: 0.0666533
[Epoch 7; Iter    78/ 1097] train: loss: 0.0903987
[Epoch 7; Iter   108/ 1097] train: loss: 0.0292703
[Epoch 7; Iter   138/ 1097] train: loss: 0.0389261
[Epoch 7; Iter   168/ 1097] train: loss: 0.0894292
[Epoch 7; Iter   198/ 1097] train: loss: 0.1024997
[Epoch 7; Iter   228/ 1097] train: loss: 0.0253330
[Epoch 7; Iter   258/ 1097] train: loss: 0.0373037
[Epoch 7; Iter   288/ 1097] train: loss: 0.1046116
[Epoch 7; Iter   318/ 1097] train: loss: 0.0326404
[Epoch 7; Iter   348/ 1097] train: loss: 0.1220612
[Epoch 7; Iter   378/ 1097] train: loss: 0.1155298
[Epoch 7; Iter   408/ 1097] train: loss: 0.1545603
[Epoch 7; Iter   438/ 1097] train: loss: 0.2179063
[Epoch 7; Iter   468/ 1097] train: loss: 0.0271091
[Epoch 7; Iter   498/ 1097] train: loss: 0.0419517
[Epoch 7; Iter   528/ 1097] train: loss: 0.0295699
[Epoch 7; Iter   558/ 1097] train: loss: 0.0617017
[Epoch 7; Iter   588/ 1097] train: loss: 0.3139835
[Epoch 7; Iter   618/ 1097] train: loss: 0.3225848
[Epoch 7; Iter   648/ 1097] train: loss: 0.3361341
[Epoch 7; Iter   678/ 1097] train: loss: 0.0378796
[Epoch 7; Iter   708/ 1097] train: loss: 0.1699160
[Epoch 7; Iter   738/ 1097] train: loss: 0.1672797
[Epoch 7; Iter   768/ 1097] train: loss: 0.0356392
[Epoch 7; Iter   798/ 1097] train: loss: 0.0909415
[Epoch 7; Iter   828/ 1097] train: loss: 0.1040464
[Epoch 7; Iter   858/ 1097] train: loss: 0.0639427
[Epoch 7; Iter   888/ 1097] train: loss: 0.0226229
[Epoch 7; Iter   918/ 1097] train: loss: 0.0698384
[Epoch 7; Iter   948/ 1097] train: loss: 0.1667140
[Epoch 7; Iter   978/ 1097] train: loss: 0.0401243
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1198902
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0252935
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1334026
[Epoch 7] ogbg-molhiv: 0.741280 val loss: 0.163774
[Epoch 7] ogbg-molhiv: 0.748153 test loss: 0.816276
[Epoch 3; Iter   986/ 1097] train: loss: 0.0283640
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0451896
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1504346
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2835383
[Epoch 3] ogbg-molhiv: 0.703866 val loss: 0.366123
[Epoch 3] ogbg-molhiv: 0.648160 test loss: 0.346178
[Epoch 4; Iter     9/ 1097] train: loss: 0.2265087
[Epoch 4; Iter    39/ 1097] train: loss: 0.1892236
[Epoch 4; Iter    69/ 1097] train: loss: 0.0388921
[Epoch 4; Iter    99/ 1097] train: loss: 0.2982976
[Epoch 4; Iter   129/ 1097] train: loss: 0.1387441
[Epoch 4; Iter   159/ 1097] train: loss: 0.1244502
[Epoch 4; Iter   189/ 1097] train: loss: 0.2465242
[Epoch 4; Iter   219/ 1097] train: loss: 0.1757037
[Epoch 4; Iter   249/ 1097] train: loss: 0.2060755
[Epoch 4; Iter   279/ 1097] train: loss: 0.1169213
[Epoch 4; Iter   309/ 1097] train: loss: 0.1231243
[Epoch 4; Iter   339/ 1097] train: loss: 0.0285114
[Epoch 4; Iter   369/ 1097] train: loss: 0.1085049
[Epoch 4; Iter   399/ 1097] train: loss: 0.1209011
[Epoch 4; Iter   429/ 1097] train: loss: 0.1938841
[Epoch 4; Iter   459/ 1097] train: loss: 0.0398241
[Epoch 4; Iter   489/ 1097] train: loss: 0.1440448
[Epoch 4; Iter   519/ 1097] train: loss: 0.2882139
[Epoch 4; Iter   549/ 1097] train: loss: 0.1845179
[Epoch 4; Iter   579/ 1097] train: loss: 0.0372745
[Epoch 4; Iter   609/ 1097] train: loss: 0.3392540
[Epoch 4; Iter   639/ 1097] train: loss: 0.3596972
[Epoch 4; Iter   669/ 1097] train: loss: 0.2883170
[Epoch 4; Iter   699/ 1097] train: loss: 0.0345864
[Epoch 4; Iter   729/ 1097] train: loss: 0.1981062
[Epoch 4; Iter   759/ 1097] train: loss: 0.1974571
[Epoch 4; Iter   789/ 1097] train: loss: 0.3790152
[Epoch 4; Iter   819/ 1097] train: loss: 0.1587109
[Epoch 4; Iter   849/ 1097] train: loss: 0.0375297
[Epoch 4; Iter   879/ 1097] train: loss: 0.0330463
[Epoch 4; Iter   909/ 1097] train: loss: 0.4404026
[Epoch 4; Iter   939/ 1097] train: loss: 0.0984799
[Epoch 4; Iter   969/ 1097] train: loss: 0.0746762
[Epoch 4; Iter   999/ 1097] train: loss: 0.2036873
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3352933
[Epoch 4; Iter  1059/ 1097] train: loss: 0.3010400
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0578674
[Epoch 4] ogbg-molhiv: 0.786869 val loss: 0.086602
[Epoch 4] ogbg-molhiv: 0.715450 test loss: 0.173828
[Epoch 5; Iter    22/ 1097] train: loss: 0.2850050
[Epoch 5; Iter    52/ 1097] train: loss: 0.1523645
[Epoch 5; Iter    82/ 1097] train: loss: 0.1196165
[Epoch 5; Iter   112/ 1097] train: loss: 0.0726450
[Epoch 5; Iter   142/ 1097] train: loss: 0.0827916
[Epoch 5; Iter   172/ 1097] train: loss: 0.0426908
[Epoch 5; Iter   202/ 1097] train: loss: 0.1323755
[Epoch 5; Iter   232/ 1097] train: loss: 0.0324733
[Epoch 5; Iter   262/ 1097] train: loss: 0.0722121
[Epoch 5; Iter   292/ 1097] train: loss: 0.1877317
[Epoch 5; Iter   322/ 1097] train: loss: 0.1645608
[Epoch 5; Iter   352/ 1097] train: loss: 0.0643752
[Epoch 5; Iter   382/ 1097] train: loss: 0.2297062
[Epoch 5; Iter   412/ 1097] train: loss: 0.2552999
[Epoch 5; Iter   442/ 1097] train: loss: 0.2226172
[Epoch 5; Iter   472/ 1097] train: loss: 0.1215040
[Epoch 5; Iter   502/ 1097] train: loss: 0.1776294
[Epoch 5; Iter   532/ 1097] train: loss: 0.0489626
[Epoch 5; Iter   562/ 1097] train: loss: 0.0489366
[Epoch 5; Iter   592/ 1097] train: loss: 0.0451985
[Epoch 5; Iter   622/ 1097] train: loss: 0.1214935
[Epoch 5; Iter   652/ 1097] train: loss: 0.1291384
[Epoch 5; Iter   682/ 1097] train: loss: 0.1482025
[Epoch 5; Iter   712/ 1097] train: loss: 0.0273421
[Epoch 5; Iter   742/ 1097] train: loss: 0.1933614
[Epoch 5; Iter   772/ 1097] train: loss: 0.1684140
[Epoch 5; Iter   802/ 1097] train: loss: 0.2214386
[Epoch 5; Iter   832/ 1097] train: loss: 0.0297836
[Epoch 5; Iter   862/ 1097] train: loss: 0.2351234
[Epoch 5; Iter   892/ 1097] train: loss: 0.0450333
[Epoch 5; Iter   922/ 1097] train: loss: 0.3013011
[Epoch 5; Iter   952/ 1097] train: loss: 0.0260718
[Epoch 5; Iter   982/ 1097] train: loss: 0.2725291
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2571575
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2010105
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0375889
[Epoch 5] ogbg-molhiv: 0.773552 val loss: 0.911158
[Epoch 5] ogbg-molhiv: 0.716972 test loss: 0.233473
[Epoch 6; Iter     5/ 1097] train: loss: 0.0873405
[Epoch 6; Iter    35/ 1097] train: loss: 0.0691587
[Epoch 6; Iter    65/ 1097] train: loss: 0.1052037
[Epoch 6; Iter    95/ 1097] train: loss: 0.0428178
[Epoch 6; Iter   125/ 1097] train: loss: 0.1198641
[Epoch 6; Iter   155/ 1097] train: loss: 0.0322850
[Epoch 6; Iter   185/ 1097] train: loss: 0.0250854
[Epoch 6; Iter   215/ 1097] train: loss: 0.3091985
[Epoch 6; Iter   245/ 1097] train: loss: 0.2341661
[Epoch 6; Iter   275/ 1097] train: loss: 0.0316402
[Epoch 6; Iter   305/ 1097] train: loss: 0.0563984
[Epoch 6; Iter   335/ 1097] train: loss: 0.1495206
[Epoch 6; Iter   365/ 1097] train: loss: 0.0528075
[Epoch 6; Iter   395/ 1097] train: loss: 0.2858846
[Epoch 6; Iter   425/ 1097] train: loss: 0.1543691
[Epoch 6; Iter   455/ 1097] train: loss: 0.1173209
[Epoch 6; Iter   485/ 1097] train: loss: 0.1981760
[Epoch 6; Iter   515/ 1097] train: loss: 0.0296516
[Epoch 6; Iter   545/ 1097] train: loss: 0.1812292
[Epoch 6; Iter   575/ 1097] train: loss: 0.0394771
[Epoch 6; Iter   605/ 1097] train: loss: 0.0274890
[Epoch 6; Iter   635/ 1097] train: loss: 0.0302526
[Epoch 6; Iter   665/ 1097] train: loss: 0.0406996
[Epoch 6; Iter   695/ 1097] train: loss: 0.1673735
[Epoch 6; Iter   725/ 1097] train: loss: 0.0343991
[Epoch 6; Iter   755/ 1097] train: loss: 0.1195533
[Epoch 6; Iter   785/ 1097] train: loss: 0.0288465
[Epoch 6; Iter   815/ 1097] train: loss: 0.1274101
[Epoch 6; Iter   845/ 1097] train: loss: 0.0916761
[Epoch 6; Iter   875/ 1097] train: loss: 0.2002153
[Epoch 6; Iter   905/ 1097] train: loss: 0.3511195
[Epoch 6; Iter   935/ 1097] train: loss: 0.1626410
[Epoch 6; Iter   965/ 1097] train: loss: 0.1149354
[Epoch 6; Iter   995/ 1097] train: loss: 0.0429809
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0288834
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0798804
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2003340
[Epoch 6] ogbg-molhiv: 0.793097 val loss: 0.161958
[Epoch 6] ogbg-molhiv: 0.727102 test loss: 0.144263
[Epoch 7; Iter    18/ 1097] train: loss: 0.0373406
[Epoch 7; Iter    48/ 1097] train: loss: 0.0516720
[Epoch 7; Iter    78/ 1097] train: loss: 0.1097961
[Epoch 7; Iter   108/ 1097] train: loss: 0.0325947
[Epoch 7; Iter   138/ 1097] train: loss: 0.0339512
[Epoch 7; Iter   168/ 1097] train: loss: 0.0982116
[Epoch 7; Iter   198/ 1097] train: loss: 0.0888513
[Epoch 7; Iter   228/ 1097] train: loss: 0.0267363
[Epoch 7; Iter   258/ 1097] train: loss: 0.0850997
[Epoch 7; Iter   288/ 1097] train: loss: 0.1247840
[Epoch 7; Iter   318/ 1097] train: loss: 0.0461689
[Epoch 7; Iter   348/ 1097] train: loss: 0.1891029
[Epoch 7; Iter   378/ 1097] train: loss: 0.1510383
[Epoch 7; Iter   408/ 1097] train: loss: 0.1551450
[Epoch 7; Iter   438/ 1097] train: loss: 0.1745912
[Epoch 7; Iter   468/ 1097] train: loss: 0.0256190
[Epoch 7; Iter   498/ 1097] train: loss: 0.0348264
[Epoch 7; Iter   528/ 1097] train: loss: 0.0260574
[Epoch 7; Iter   558/ 1097] train: loss: 0.0260182
[Epoch 7; Iter   588/ 1097] train: loss: 0.2602385
[Epoch 7; Iter   618/ 1097] train: loss: 0.3208720
[Epoch 7; Iter   648/ 1097] train: loss: 0.2982784
[Epoch 7; Iter   678/ 1097] train: loss: 0.0446695
[Epoch 7; Iter   708/ 1097] train: loss: 0.1991067
[Epoch 7; Iter   738/ 1097] train: loss: 0.1849531
[Epoch 7; Iter   768/ 1097] train: loss: 0.0393251
[Epoch 7; Iter   798/ 1097] train: loss: 0.1773253
[Epoch 7; Iter   828/ 1097] train: loss: 0.1417066
[Epoch 7; Iter   858/ 1097] train: loss: 0.0832942
[Epoch 7; Iter   888/ 1097] train: loss: 0.0245139
[Epoch 7; Iter   918/ 1097] train: loss: 0.0573495
[Epoch 7; Iter   948/ 1097] train: loss: 0.1580923
[Epoch 7; Iter   978/ 1097] train: loss: 0.0320360
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1297985
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0331663
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1645668
[Epoch 7] ogbg-molhiv: 0.771280 val loss: 0.119184
[Epoch 7] ogbg-molhiv: 0.770438 test loss: 0.117549
[Epoch 3; Iter   986/ 1097] train: loss: 0.2905274
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0559927
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0618265
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0321973
[Epoch 3] ogbg-molhiv: 0.746644 val loss: 0.108831
[Epoch 3] ogbg-molhiv: 0.758178 test loss: 0.137749
[Epoch 4; Iter     9/ 1097] train: loss: 0.4417065
[Epoch 4; Iter    39/ 1097] train: loss: 0.1247925
[Epoch 4; Iter    69/ 1097] train: loss: 0.0852927
[Epoch 4; Iter    99/ 1097] train: loss: 0.0559261
[Epoch 4; Iter   129/ 1097] train: loss: 0.1678598
[Epoch 4; Iter   159/ 1097] train: loss: 0.4097250
[Epoch 4; Iter   189/ 1097] train: loss: 0.0329427
[Epoch 4; Iter   219/ 1097] train: loss: 0.3979858
[Epoch 4; Iter   249/ 1097] train: loss: 0.0450365
[Epoch 4; Iter   279/ 1097] train: loss: 0.1126383
[Epoch 4; Iter   309/ 1097] train: loss: 0.1528314
[Epoch 4; Iter   339/ 1097] train: loss: 0.1183206
[Epoch 4; Iter   369/ 1097] train: loss: 0.1149544
[Epoch 4; Iter   399/ 1097] train: loss: 0.1545167
[Epoch 4; Iter   429/ 1097] train: loss: 0.0709186
[Epoch 4; Iter   459/ 1097] train: loss: 0.0320858
[Epoch 4; Iter   489/ 1097] train: loss: 0.0323178
[Epoch 4; Iter   519/ 1097] train: loss: 0.0958915
[Epoch 4; Iter   549/ 1097] train: loss: 0.0394110
[Epoch 4; Iter   579/ 1097] train: loss: 0.0334877
[Epoch 4; Iter   609/ 1097] train: loss: 0.2452286
[Epoch 4; Iter   639/ 1097] train: loss: 0.0294124
[Epoch 4; Iter   669/ 1097] train: loss: 0.2427543
[Epoch 4; Iter   699/ 1097] train: loss: 0.0781523
[Epoch 4; Iter   729/ 1097] train: loss: 0.3726355
[Epoch 4; Iter   759/ 1097] train: loss: 0.0565226
[Epoch 4; Iter   789/ 1097] train: loss: 0.3241040
[Epoch 4; Iter   819/ 1097] train: loss: 0.0350830
[Epoch 4; Iter   849/ 1097] train: loss: 0.2276465
[Epoch 4; Iter   879/ 1097] train: loss: 0.1236598
[Epoch 4; Iter   909/ 1097] train: loss: 0.5095119
[Epoch 4; Iter   939/ 1097] train: loss: 0.0333912
[Epoch 4; Iter   969/ 1097] train: loss: 0.0432123
[Epoch 4; Iter   999/ 1097] train: loss: 0.3333614
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3029038
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2056342
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0775999
[Epoch 4] ogbg-molhiv: 0.745490 val loss: 0.149005
[Epoch 4] ogbg-molhiv: 0.755109 test loss: 0.126339
[Epoch 5; Iter    22/ 1097] train: loss: 0.0529736
[Epoch 5; Iter    52/ 1097] train: loss: 0.1217709
[Epoch 5; Iter    82/ 1097] train: loss: 0.3420508
[Epoch 5; Iter   112/ 1097] train: loss: 0.0722291
[Epoch 5; Iter   142/ 1097] train: loss: 0.3269139
[Epoch 5; Iter   172/ 1097] train: loss: 0.1897464
[Epoch 5; Iter   202/ 1097] train: loss: 0.0287114
[Epoch 5; Iter   232/ 1097] train: loss: 0.1420245
[Epoch 5; Iter   262/ 1097] train: loss: 0.1670668
[Epoch 5; Iter   292/ 1097] train: loss: 0.2727235
[Epoch 5; Iter   322/ 1097] train: loss: 0.1852581
[Epoch 5; Iter   352/ 1097] train: loss: 0.2050150
[Epoch 5; Iter   382/ 1097] train: loss: 0.2636809
[Epoch 5; Iter   412/ 1097] train: loss: 0.0417911
[Epoch 5; Iter   442/ 1097] train: loss: 0.1505007
[Epoch 5; Iter   472/ 1097] train: loss: 0.1981138
[Epoch 5; Iter   502/ 1097] train: loss: 0.1148048
[Epoch 5; Iter   532/ 1097] train: loss: 0.0377183
[Epoch 5; Iter   562/ 1097] train: loss: 0.2504078
[Epoch 5; Iter   592/ 1097] train: loss: 0.0597884
[Epoch 5; Iter   622/ 1097] train: loss: 0.1923855
[Epoch 5; Iter   652/ 1097] train: loss: 0.2356024
[Epoch 5; Iter   682/ 1097] train: loss: 0.0292396
[Epoch 5; Iter   712/ 1097] train: loss: 0.1967008
[Epoch 5; Iter   742/ 1097] train: loss: 0.0270579
[Epoch 5; Iter   772/ 1097] train: loss: 0.0355080
[Epoch 5; Iter   802/ 1097] train: loss: 0.1825928
[Epoch 5; Iter   832/ 1097] train: loss: 0.2760696
[Epoch 5; Iter   862/ 1097] train: loss: 0.0381925
[Epoch 5; Iter   892/ 1097] train: loss: 0.1159165
[Epoch 5; Iter   922/ 1097] train: loss: 0.0956143
[Epoch 5; Iter   952/ 1097] train: loss: 0.2390369
[Epoch 5; Iter   982/ 1097] train: loss: 0.1339480
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2474696
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2840645
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0376699
[Epoch 5] ogbg-molhiv: 0.762845 val loss: 0.120159
[Epoch 5] ogbg-molhiv: 0.760882 test loss: 0.135722
[Epoch 6; Iter     5/ 1097] train: loss: 0.2057441
[Epoch 6; Iter    35/ 1097] train: loss: 0.4103926
[Epoch 6; Iter    65/ 1097] train: loss: 0.0342279
[Epoch 6; Iter    95/ 1097] train: loss: 0.1487509
[Epoch 6; Iter   125/ 1097] train: loss: 0.3048868
[Epoch 6; Iter   155/ 1097] train: loss: 0.0595735
[Epoch 6; Iter   185/ 1097] train: loss: 0.1375965
[Epoch 6; Iter   215/ 1097] train: loss: 0.1408213
[Epoch 6; Iter   245/ 1097] train: loss: 0.0640058
[Epoch 6; Iter   275/ 1097] train: loss: 0.1542104
[Epoch 6; Iter   305/ 1097] train: loss: 0.0315308
[Epoch 6; Iter   335/ 1097] train: loss: 0.0421937
[Epoch 6; Iter   365/ 1097] train: loss: 0.0429180
[Epoch 6; Iter   395/ 1097] train: loss: 0.1290672
[Epoch 6; Iter   425/ 1097] train: loss: 0.0565437
[Epoch 6; Iter   455/ 1097] train: loss: 0.2992877
[Epoch 6; Iter   485/ 1097] train: loss: 0.0345900
[Epoch 6; Iter   515/ 1097] train: loss: 0.1219256
[Epoch 6; Iter   545/ 1097] train: loss: 0.1588985
[Epoch 6; Iter   575/ 1097] train: loss: 0.0370428
[Epoch 6; Iter   605/ 1097] train: loss: 0.0597582
[Epoch 6; Iter   635/ 1097] train: loss: 0.2071685
[Epoch 6; Iter   665/ 1097] train: loss: 0.2152157
[Epoch 6; Iter   695/ 1097] train: loss: 0.2903106
[Epoch 6; Iter   725/ 1097] train: loss: 0.2937962
[Epoch 6; Iter   755/ 1097] train: loss: 0.2917462
[Epoch 6; Iter   785/ 1097] train: loss: 0.4055764
[Epoch 6; Iter   815/ 1097] train: loss: 0.0772801
[Epoch 6; Iter   845/ 1097] train: loss: 0.0329663
[Epoch 6; Iter   875/ 1097] train: loss: 0.0771308
[Epoch 6; Iter   905/ 1097] train: loss: 0.1810951
[Epoch 6; Iter   935/ 1097] train: loss: 0.0642448
[Epoch 6; Iter   965/ 1097] train: loss: 0.0631300
[Epoch 6; Iter   995/ 1097] train: loss: 0.1089511
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1461481
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1508006
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1860052
[Epoch 6] ogbg-molhiv: 0.760873 val loss: 0.089703
[Epoch 6] ogbg-molhiv: 0.714556 test loss: 0.122489
[Epoch 7; Iter    18/ 1097] train: loss: 0.0378814
[Epoch 7; Iter    48/ 1097] train: loss: 0.0337637
[Epoch 7; Iter    78/ 1097] train: loss: 0.1514811
[Epoch 7; Iter   108/ 1097] train: loss: 0.2840567
[Epoch 7; Iter   138/ 1097] train: loss: 0.1753304
[Epoch 7; Iter   168/ 1097] train: loss: 0.0258293
[Epoch 7; Iter   198/ 1097] train: loss: 0.2917140
[Epoch 7; Iter   228/ 1097] train: loss: 0.1693724
[Epoch 7; Iter   258/ 1097] train: loss: 0.0211240
[Epoch 7; Iter   288/ 1097] train: loss: 0.0251979
[Epoch 7; Iter   318/ 1097] train: loss: 0.1860716
[Epoch 7; Iter   348/ 1097] train: loss: 0.0280033
[Epoch 7; Iter   378/ 1097] train: loss: 0.1871184
[Epoch 7; Iter   408/ 1097] train: loss: 0.2652086
[Epoch 7; Iter   438/ 1097] train: loss: 0.0608163
[Epoch 7; Iter   468/ 1097] train: loss: 0.0300380
[Epoch 7; Iter   498/ 1097] train: loss: 0.1876845
[Epoch 7; Iter   528/ 1097] train: loss: 0.1276302
[Epoch 7; Iter   558/ 1097] train: loss: 0.0330069
[Epoch 7; Iter   588/ 1097] train: loss: 0.2155078
[Epoch 7; Iter   618/ 1097] train: loss: 0.1136957
[Epoch 7; Iter   648/ 1097] train: loss: 0.0917897
[Epoch 7; Iter   678/ 1097] train: loss: 0.0328571
[Epoch 7; Iter   708/ 1097] train: loss: 0.2244739
[Epoch 7; Iter   738/ 1097] train: loss: 0.1691525
[Epoch 7; Iter   768/ 1097] train: loss: 0.1755500
[Epoch 7; Iter   798/ 1097] train: loss: 0.1507523
[Epoch 7; Iter   828/ 1097] train: loss: 0.0409944
[Epoch 7; Iter   858/ 1097] train: loss: 0.2149813
[Epoch 7; Iter   888/ 1097] train: loss: 0.0353574
[Epoch 7; Iter   918/ 1097] train: loss: 0.1571153
[Epoch 7; Iter   948/ 1097] train: loss: 0.0419187
[Epoch 7; Iter   978/ 1097] train: loss: 0.0536406
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0472635
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0272671
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1696731
[Epoch 7] ogbg-molhiv: 0.730796 val loss: 0.094357
[Epoch 7] ogbg-molhiv: 0.755625 test loss: 0.117037
[Epoch 3; Iter   986/ 1097] train: loss: 0.0402389
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2848434
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0293655
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1123367
[Epoch 3] ogbg-molhiv: 0.722354 val loss: 0.094730
[Epoch 3] ogbg-molhiv: 0.738336 test loss: 0.120471
[Epoch 4; Iter     9/ 1097] train: loss: 0.0716765
[Epoch 4; Iter    39/ 1097] train: loss: 0.0402382
[Epoch 4; Iter    69/ 1097] train: loss: 0.0274996
[Epoch 4; Iter    99/ 1097] train: loss: 0.0275412
[Epoch 4; Iter   129/ 1097] train: loss: 0.2416076
[Epoch 4; Iter   159/ 1097] train: loss: 0.1403160
[Epoch 4; Iter   189/ 1097] train: loss: 0.0399601
[Epoch 4; Iter   219/ 1097] train: loss: 0.0379655
[Epoch 4; Iter   249/ 1097] train: loss: 0.1415080
[Epoch 4; Iter   279/ 1097] train: loss: 0.2587893
[Epoch 4; Iter   309/ 1097] train: loss: 0.0435335
[Epoch 4; Iter   339/ 1097] train: loss: 0.0502607
[Epoch 4; Iter   369/ 1097] train: loss: 0.0682988
[Epoch 4; Iter   399/ 1097] train: loss: 0.2290367
[Epoch 4; Iter   429/ 1097] train: loss: 0.0314051
[Epoch 4; Iter   459/ 1097] train: loss: 0.1303432
[Epoch 4; Iter   489/ 1097] train: loss: 0.0271264
[Epoch 4; Iter   519/ 1097] train: loss: 0.1694873
[Epoch 4; Iter   549/ 1097] train: loss: 0.0331580
[Epoch 4; Iter   579/ 1097] train: loss: 0.0827491
[Epoch 4; Iter   609/ 1097] train: loss: 0.1352046
[Epoch 4; Iter   639/ 1097] train: loss: 0.1063055
[Epoch 4; Iter   669/ 1097] train: loss: 0.1912109
[Epoch 4; Iter   699/ 1097] train: loss: 0.1060150
[Epoch 4; Iter   729/ 1097] train: loss: 0.0331690
[Epoch 4; Iter   759/ 1097] train: loss: 0.0288598
[Epoch 4; Iter   789/ 1097] train: loss: 0.0356122
[Epoch 4; Iter   819/ 1097] train: loss: 0.1298797
[Epoch 4; Iter   849/ 1097] train: loss: 0.0278236
[Epoch 4; Iter   879/ 1097] train: loss: 0.0559625
[Epoch 4; Iter   909/ 1097] train: loss: 0.0339558
[Epoch 4; Iter   939/ 1097] train: loss: 0.2755828
[Epoch 4; Iter   969/ 1097] train: loss: 0.0715254
[Epoch 4; Iter   999/ 1097] train: loss: 0.0380698
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2156438
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1539651
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1753961
[Epoch 4] ogbg-molhiv: 0.767122 val loss: 1.745616
[Epoch 4] ogbg-molhiv: 0.757089 test loss: 1.434390
[Epoch 5; Iter    22/ 1097] train: loss: 0.1264097
[Epoch 5; Iter    52/ 1097] train: loss: 0.1468964
[Epoch 5; Iter    82/ 1097] train: loss: 0.1487200
[Epoch 5; Iter   112/ 1097] train: loss: 0.3842149
[Epoch 5; Iter   142/ 1097] train: loss: 0.3378121
[Epoch 5; Iter   172/ 1097] train: loss: 0.0288749
[Epoch 5; Iter   202/ 1097] train: loss: 0.1860803
[Epoch 5; Iter   232/ 1097] train: loss: 0.1989372
[Epoch 5; Iter   262/ 1097] train: loss: 0.0453815
[Epoch 5; Iter   292/ 1097] train: loss: 0.1961270
[Epoch 5; Iter   322/ 1097] train: loss: 0.0292777
[Epoch 5; Iter   352/ 1097] train: loss: 0.1206229
[Epoch 5; Iter   382/ 1097] train: loss: 0.1368031
[Epoch 5; Iter   412/ 1097] train: loss: 0.3521530
[Epoch 5; Iter   442/ 1097] train: loss: 0.1300432
[Epoch 5; Iter   472/ 1097] train: loss: 0.1133007
[Epoch 5; Iter   502/ 1097] train: loss: 0.1734112
[Epoch 5; Iter   532/ 1097] train: loss: 0.2326766
[Epoch 5; Iter   562/ 1097] train: loss: 0.2981706
[Epoch 5; Iter   592/ 1097] train: loss: 0.0635704
[Epoch 5; Iter   622/ 1097] train: loss: 0.0378841
[Epoch 5; Iter   652/ 1097] train: loss: 0.1139393
[Epoch 5; Iter   682/ 1097] train: loss: 0.1472413
[Epoch 5; Iter   712/ 1097] train: loss: 0.0294318
[Epoch 5; Iter   742/ 1097] train: loss: 0.1528986
[Epoch 5; Iter   772/ 1097] train: loss: 0.2523045
[Epoch 5; Iter   802/ 1097] train: loss: 0.0655187
[Epoch 5; Iter   832/ 1097] train: loss: 0.0637336
[Epoch 5; Iter   862/ 1097] train: loss: 0.0803326
[Epoch 5; Iter   892/ 1097] train: loss: 0.0444311
[Epoch 5; Iter   922/ 1097] train: loss: 0.0464348
[Epoch 5; Iter   952/ 1097] train: loss: 0.0301758
[Epoch 5; Iter   982/ 1097] train: loss: 0.0714626
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0385877
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2262325
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0399756
[Epoch 5] ogbg-molhiv: 0.743717 val loss: 0.086670
[Epoch 5] ogbg-molhiv: 0.743506 test loss: 0.117916
[Epoch 6; Iter     5/ 1097] train: loss: 0.1132366
[Epoch 6; Iter    35/ 1097] train: loss: 0.3223284
[Epoch 6; Iter    65/ 1097] train: loss: 0.0248737
[Epoch 6; Iter    95/ 1097] train: loss: 0.0730143
[Epoch 6; Iter   125/ 1097] train: loss: 0.4557749
[Epoch 6; Iter   155/ 1097] train: loss: 0.3925524
[Epoch 6; Iter   185/ 1097] train: loss: 0.0335986
[Epoch 6; Iter   215/ 1097] train: loss: 0.1372171
[Epoch 6; Iter   245/ 1097] train: loss: 0.2936650
[Epoch 6; Iter   275/ 1097] train: loss: 0.0416813
[Epoch 6; Iter   305/ 1097] train: loss: 0.1709053
[Epoch 6; Iter   335/ 1097] train: loss: 0.0655553
[Epoch 6; Iter   365/ 1097] train: loss: 0.2568775
[Epoch 6; Iter   395/ 1097] train: loss: 0.2604904
[Epoch 6; Iter   425/ 1097] train: loss: 0.0401213
[Epoch 6; Iter   455/ 1097] train: loss: 0.3579696
[Epoch 6; Iter   485/ 1097] train: loss: 0.0336310
[Epoch 6; Iter   515/ 1097] train: loss: 0.1067733
[Epoch 6; Iter   545/ 1097] train: loss: 0.1879311
[Epoch 6; Iter   575/ 1097] train: loss: 0.1646165
[Epoch 6; Iter   605/ 1097] train: loss: 0.0370105
[Epoch 6; Iter   635/ 1097] train: loss: 0.0301534
[Epoch 6; Iter   665/ 1097] train: loss: 0.2060930
[Epoch 6; Iter   695/ 1097] train: loss: 0.2303516
[Epoch 6; Iter   725/ 1097] train: loss: 0.2158252
[Epoch 6; Iter   755/ 1097] train: loss: 0.0503003
[Epoch 6; Iter   785/ 1097] train: loss: 0.1075529
[Epoch 6; Iter   815/ 1097] train: loss: 0.0375725
[Epoch 6; Iter   845/ 1097] train: loss: 0.0815333
[Epoch 6; Iter   875/ 1097] train: loss: 0.1295419
[Epoch 6; Iter   905/ 1097] train: loss: 0.3315040
[Epoch 6; Iter   935/ 1097] train: loss: 0.0351581
[Epoch 6; Iter   965/ 1097] train: loss: 0.0277897
[Epoch 6; Iter   995/ 1097] train: loss: 0.1570939
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1782520
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0282782
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2087982
[Epoch 6] ogbg-molhiv: 0.786106 val loss: 0.526001
[Epoch 6] ogbg-molhiv: 0.758193 test loss: 0.472797
[Epoch 7; Iter    18/ 1097] train: loss: 0.2018957
[Epoch 7; Iter    48/ 1097] train: loss: 0.7581927
[Epoch 7; Iter    78/ 1097] train: loss: 0.3893885
[Epoch 7; Iter   108/ 1097] train: loss: 0.0415448
[Epoch 7; Iter   138/ 1097] train: loss: 0.0246942
[Epoch 7; Iter   168/ 1097] train: loss: 0.0413201
[Epoch 7; Iter   198/ 1097] train: loss: 0.1655759
[Epoch 7; Iter   228/ 1097] train: loss: 0.1698209
[Epoch 7; Iter   258/ 1097] train: loss: 0.1450005
[Epoch 7; Iter   288/ 1097] train: loss: 0.1799158
[Epoch 7; Iter   318/ 1097] train: loss: 0.0354495
[Epoch 7; Iter   348/ 1097] train: loss: 0.0633124
[Epoch 7; Iter   378/ 1097] train: loss: 0.0262950
[Epoch 7; Iter   408/ 1097] train: loss: 0.0373653
[Epoch 7; Iter   438/ 1097] train: loss: 0.0441235
[Epoch 7; Iter   468/ 1097] train: loss: 0.2351826
[Epoch 7; Iter   498/ 1097] train: loss: 0.0423153
[Epoch 7; Iter   528/ 1097] train: loss: 0.0354523
[Epoch 7; Iter   558/ 1097] train: loss: 0.2802237
[Epoch 7; Iter   588/ 1097] train: loss: 0.2004071
[Epoch 7; Iter   618/ 1097] train: loss: 0.1984669
[Epoch 7; Iter   648/ 1097] train: loss: 0.2031716
[Epoch 7; Iter   678/ 1097] train: loss: 0.0937091
[Epoch 7; Iter   708/ 1097] train: loss: 0.0881533
[Epoch 7; Iter   738/ 1097] train: loss: 0.0470825
[Epoch 7; Iter   768/ 1097] train: loss: 0.1144359
[Epoch 7; Iter   798/ 1097] train: loss: 0.2544943
[Epoch 7; Iter   828/ 1097] train: loss: 0.1675421
[Epoch 7; Iter   858/ 1097] train: loss: 0.2540489
[Epoch 7; Iter   888/ 1097] train: loss: 0.1950087
[Epoch 7; Iter   918/ 1097] train: loss: 0.1477308
[Epoch 7; Iter   948/ 1097] train: loss: 0.1790949
[Epoch 7; Iter   978/ 1097] train: loss: 0.1177387
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0243919
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2719889
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0458244
[Epoch 7] ogbg-molhiv: 0.801575 val loss: 0.360221
[Epoch 7] ogbg-molhiv: 0.760086 test loss: 0.216804
[Epoch 3; Iter   986/ 1097] train: loss: 0.0373331
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0356869
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1268832
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2864563
[Epoch 3] ogbg-molhiv: 0.748864 val loss: 0.085303
[Epoch 3] ogbg-molhiv: 0.711960 test loss: 0.127330
[Epoch 4; Iter     9/ 1097] train: loss: 0.2362702
[Epoch 4; Iter    39/ 1097] train: loss: 0.1745079
[Epoch 4; Iter    69/ 1097] train: loss: 0.0409605
[Epoch 4; Iter    99/ 1097] train: loss: 0.3177418
[Epoch 4; Iter   129/ 1097] train: loss: 0.1685742
[Epoch 4; Iter   159/ 1097] train: loss: 0.0813761
[Epoch 4; Iter   189/ 1097] train: loss: 0.2767805
[Epoch 4; Iter   219/ 1097] train: loss: 0.1920360
[Epoch 4; Iter   249/ 1097] train: loss: 0.1891868
[Epoch 4; Iter   279/ 1097] train: loss: 0.1896883
[Epoch 4; Iter   309/ 1097] train: loss: 0.0829339
[Epoch 4; Iter   339/ 1097] train: loss: 0.0309429
[Epoch 4; Iter   369/ 1097] train: loss: 0.1289713
[Epoch 4; Iter   399/ 1097] train: loss: 0.1495779
[Epoch 4; Iter   429/ 1097] train: loss: 0.1636134
[Epoch 4; Iter   459/ 1097] train: loss: 0.0354055
[Epoch 4; Iter   489/ 1097] train: loss: 0.1608938
[Epoch 4; Iter   519/ 1097] train: loss: 0.3333410
[Epoch 4; Iter   549/ 1097] train: loss: 0.1822280
[Epoch 4; Iter   579/ 1097] train: loss: 0.0322922
[Epoch 4; Iter   609/ 1097] train: loss: 0.3248037
[Epoch 4; Iter   639/ 1097] train: loss: 0.3052079
[Epoch 4; Iter   669/ 1097] train: loss: 0.2690468
[Epoch 4; Iter   699/ 1097] train: loss: 0.0369887
[Epoch 4; Iter   729/ 1097] train: loss: 0.2004274
[Epoch 4; Iter   759/ 1097] train: loss: 0.2209348
[Epoch 4; Iter   789/ 1097] train: loss: 0.3950561
[Epoch 4; Iter   819/ 1097] train: loss: 0.1623002
[Epoch 4; Iter   849/ 1097] train: loss: 0.0435971
[Epoch 4; Iter   879/ 1097] train: loss: 0.0477462
[Epoch 4; Iter   909/ 1097] train: loss: 0.4011831
[Epoch 4; Iter   939/ 1097] train: loss: 0.1252858
[Epoch 4; Iter   969/ 1097] train: loss: 0.0482200
[Epoch 4; Iter   999/ 1097] train: loss: 0.1923167
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2956424
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2839550
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0435120
[Epoch 4] ogbg-molhiv: 0.729647 val loss: 0.092891
[Epoch 4] ogbg-molhiv: 0.721346 test loss: 0.124574
[Epoch 5; Iter    22/ 1097] train: loss: 0.3640666
[Epoch 5; Iter    52/ 1097] train: loss: 0.1750354
[Epoch 5; Iter    82/ 1097] train: loss: 0.0883983
[Epoch 5; Iter   112/ 1097] train: loss: 0.1073708
[Epoch 5; Iter   142/ 1097] train: loss: 0.0944470
[Epoch 5; Iter   172/ 1097] train: loss: 0.0424969
[Epoch 5; Iter   202/ 1097] train: loss: 0.1702759
[Epoch 5; Iter   232/ 1097] train: loss: 0.0441159
[Epoch 5; Iter   262/ 1097] train: loss: 0.0545216
[Epoch 5; Iter   292/ 1097] train: loss: 0.1942616
[Epoch 5; Iter   322/ 1097] train: loss: 0.1562640
[Epoch 5; Iter   352/ 1097] train: loss: 0.0658403
[Epoch 5; Iter   382/ 1097] train: loss: 0.2250571
[Epoch 5; Iter   412/ 1097] train: loss: 0.2956498
[Epoch 5; Iter   442/ 1097] train: loss: 0.2759835
[Epoch 5; Iter   472/ 1097] train: loss: 0.1320210
[Epoch 5; Iter   502/ 1097] train: loss: 0.2041512
[Epoch 5; Iter   532/ 1097] train: loss: 0.0654482
[Epoch 5; Iter   562/ 1097] train: loss: 0.0672940
[Epoch 5; Iter   592/ 1097] train: loss: 0.0427228
[Epoch 5; Iter   622/ 1097] train: loss: 0.1128422
[Epoch 5; Iter   652/ 1097] train: loss: 0.1235450
[Epoch 5; Iter   682/ 1097] train: loss: 0.1547800
[Epoch 5; Iter   712/ 1097] train: loss: 0.0265521
[Epoch 5; Iter   742/ 1097] train: loss: 0.1714000
[Epoch 5; Iter   772/ 1097] train: loss: 0.1614653
[Epoch 5; Iter   802/ 1097] train: loss: 0.2408893
[Epoch 5; Iter   832/ 1097] train: loss: 0.0332110
[Epoch 5; Iter   862/ 1097] train: loss: 0.1855578
[Epoch 5; Iter   892/ 1097] train: loss: 0.0335048
[Epoch 5; Iter   922/ 1097] train: loss: 0.3080989
[Epoch 5; Iter   952/ 1097] train: loss: 0.0263538
[Epoch 5; Iter   982/ 1097] train: loss: 0.2433462
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2497921
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2310732
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0430953
[Epoch 5] ogbg-molhiv: 0.684894 val loss: 0.091072
[Epoch 5] ogbg-molhiv: 0.648068 test loss: 0.128457
[Epoch 6; Iter     5/ 1097] train: loss: 0.0571793
[Epoch 6; Iter    35/ 1097] train: loss: 0.1266349
[Epoch 6; Iter    65/ 1097] train: loss: 0.1352690
[Epoch 6; Iter    95/ 1097] train: loss: 0.0586114
[Epoch 6; Iter   125/ 1097] train: loss: 0.1281729
[Epoch 6; Iter   155/ 1097] train: loss: 0.0261283
[Epoch 6; Iter   185/ 1097] train: loss: 0.0316020
[Epoch 6; Iter   215/ 1097] train: loss: 0.2702404
[Epoch 6; Iter   245/ 1097] train: loss: 0.2473444
[Epoch 6; Iter   275/ 1097] train: loss: 0.0297718
[Epoch 6; Iter   305/ 1097] train: loss: 0.0395327
[Epoch 6; Iter   335/ 1097] train: loss: 0.1986402
[Epoch 6; Iter   365/ 1097] train: loss: 0.0593424
[Epoch 6; Iter   395/ 1097] train: loss: 0.2518321
[Epoch 6; Iter   425/ 1097] train: loss: 0.1684129
[Epoch 6; Iter   455/ 1097] train: loss: 0.1350211
[Epoch 6; Iter   485/ 1097] train: loss: 0.1847183
[Epoch 6; Iter   515/ 1097] train: loss: 0.0275544
[Epoch 6; Iter   545/ 1097] train: loss: 0.1536637
[Epoch 6; Iter   575/ 1097] train: loss: 0.0520446
[Epoch 6; Iter   605/ 1097] train: loss: 0.0321875
[Epoch 6; Iter   635/ 1097] train: loss: 0.0319677
[Epoch 6; Iter   665/ 1097] train: loss: 0.0314188
[Epoch 6; Iter   695/ 1097] train: loss: 0.1688179
[Epoch 6; Iter   725/ 1097] train: loss: 0.0360350
[Epoch 6; Iter   755/ 1097] train: loss: 0.1024447
[Epoch 6; Iter   785/ 1097] train: loss: 0.0283458
[Epoch 6; Iter   815/ 1097] train: loss: 0.1667157
[Epoch 6; Iter   845/ 1097] train: loss: 0.1213594
[Epoch 6; Iter   875/ 1097] train: loss: 0.2057215
[Epoch 6; Iter   905/ 1097] train: loss: 0.3754759
[Epoch 6; Iter   935/ 1097] train: loss: 0.1645745
[Epoch 6; Iter   965/ 1097] train: loss: 0.1070340
[Epoch 6; Iter   995/ 1097] train: loss: 0.0371296
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0312065
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0615083
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1850264
[Epoch 6] ogbg-molhiv: 0.762727 val loss: 0.088627
[Epoch 6] ogbg-molhiv: 0.728394 test loss: 0.129921
[Epoch 7; Iter    18/ 1097] train: loss: 0.0385172
[Epoch 7; Iter    48/ 1097] train: loss: 0.0585165
[Epoch 7; Iter    78/ 1097] train: loss: 0.0919393
[Epoch 7; Iter   108/ 1097] train: loss: 0.0331464
[Epoch 7; Iter   138/ 1097] train: loss: 0.0426962
[Epoch 7; Iter   168/ 1097] train: loss: 0.1020237
[Epoch 7; Iter   198/ 1097] train: loss: 0.1245475
[Epoch 7; Iter   228/ 1097] train: loss: 0.0312672
[Epoch 7; Iter   258/ 1097] train: loss: 0.1021374
[Epoch 7; Iter   288/ 1097] train: loss: 0.0630741
[Epoch 7; Iter   318/ 1097] train: loss: 0.0755437
[Epoch 7; Iter   348/ 1097] train: loss: 0.1918534
[Epoch 7; Iter   378/ 1097] train: loss: 0.1449483
[Epoch 7; Iter   408/ 1097] train: loss: 0.1580382
[Epoch 7; Iter   438/ 1097] train: loss: 0.1354812
[Epoch 7; Iter   468/ 1097] train: loss: 0.0322908
[Epoch 7; Iter   498/ 1097] train: loss: 0.0275233
[Epoch 7; Iter   528/ 1097] train: loss: 0.0384626
[Epoch 7; Iter   558/ 1097] train: loss: 0.1122813
[Epoch 7; Iter   588/ 1097] train: loss: 0.2846960
[Epoch 7; Iter   618/ 1097] train: loss: 0.3174838
[Epoch 7; Iter   648/ 1097] train: loss: 0.3293266
[Epoch 7; Iter   678/ 1097] train: loss: 0.0453388
[Epoch 7; Iter   708/ 1097] train: loss: 0.1777005
[Epoch 7; Iter   738/ 1097] train: loss: 0.1645868
[Epoch 7; Iter   768/ 1097] train: loss: 0.0487111
[Epoch 7; Iter   798/ 1097] train: loss: 0.1017667
[Epoch 7; Iter   828/ 1097] train: loss: 0.1360462
[Epoch 7; Iter   858/ 1097] train: loss: 0.0980123
[Epoch 7; Iter   888/ 1097] train: loss: 0.0305052
[Epoch 7; Iter   918/ 1097] train: loss: 0.0543947
[Epoch 7; Iter   948/ 1097] train: loss: 0.1824752
[Epoch 7; Iter   978/ 1097] train: loss: 0.0497425
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1302514
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0308372
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1799725
[Epoch 7] ogbg-molhiv: 0.735658 val loss: 0.142998
[Epoch 7] ogbg-molhiv: 0.731381 test loss: 0.163597
[Epoch 3; Iter   986/ 1097] train: loss: 0.3365250
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1123506
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0768172
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0396913
[Epoch 3] ogbg-molhiv: 0.730924 val loss: 0.370734
[Epoch 3] ogbg-molhiv: 0.756986 test loss: 0.143026
[Epoch 4; Iter     9/ 1097] train: loss: 0.3844759
[Epoch 4; Iter    39/ 1097] train: loss: 0.0887933
[Epoch 4; Iter    69/ 1097] train: loss: 0.0886767
[Epoch 4; Iter    99/ 1097] train: loss: 0.0318544
[Epoch 4; Iter   129/ 1097] train: loss: 0.1248133
[Epoch 4; Iter   159/ 1097] train: loss: 0.4617574
[Epoch 4; Iter   189/ 1097] train: loss: 0.0310984
[Epoch 4; Iter   219/ 1097] train: loss: 0.3558963
[Epoch 4; Iter   249/ 1097] train: loss: 0.0792551
[Epoch 4; Iter   279/ 1097] train: loss: 0.1374473
[Epoch 4; Iter   309/ 1097] train: loss: 0.1331553
[Epoch 4; Iter   339/ 1097] train: loss: 0.1191280
[Epoch 4; Iter   369/ 1097] train: loss: 0.1433942
[Epoch 4; Iter   399/ 1097] train: loss: 0.1578159
[Epoch 4; Iter   429/ 1097] train: loss: 0.0696245
[Epoch 4; Iter   459/ 1097] train: loss: 0.0335810
[Epoch 4; Iter   489/ 1097] train: loss: 0.0319473
[Epoch 4; Iter   519/ 1097] train: loss: 0.1096160
[Epoch 4; Iter   549/ 1097] train: loss: 0.0422161
[Epoch 4; Iter   579/ 1097] train: loss: 0.0386669
[Epoch 4; Iter   609/ 1097] train: loss: 0.2625175
[Epoch 4; Iter   639/ 1097] train: loss: 0.0292065
[Epoch 4; Iter   669/ 1097] train: loss: 0.2663087
[Epoch 4; Iter   699/ 1097] train: loss: 0.0721233
[Epoch 4; Iter   729/ 1097] train: loss: 0.4040570
[Epoch 4; Iter   759/ 1097] train: loss: 0.0640595
[Epoch 4; Iter   789/ 1097] train: loss: 0.3173824
[Epoch 4; Iter   819/ 1097] train: loss: 0.0364141
[Epoch 4; Iter   849/ 1097] train: loss: 0.2240529
[Epoch 4; Iter   879/ 1097] train: loss: 0.1286203
[Epoch 4; Iter   909/ 1097] train: loss: 0.5274184
[Epoch 4; Iter   939/ 1097] train: loss: 0.0362592
[Epoch 4; Iter   969/ 1097] train: loss: 0.0598000
[Epoch 4; Iter   999/ 1097] train: loss: 0.3020751
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2863901
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2064826
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1034844
[Epoch 4] ogbg-molhiv: 0.699588 val loss: 0.099314
[Epoch 4] ogbg-molhiv: 0.732270 test loss: 0.118723
[Epoch 5; Iter    22/ 1097] train: loss: 0.0487141
[Epoch 5; Iter    52/ 1097] train: loss: 0.1368908
[Epoch 5; Iter    82/ 1097] train: loss: 0.3155103
[Epoch 5; Iter   112/ 1097] train: loss: 0.0389275
[Epoch 5; Iter   142/ 1097] train: loss: 0.3295372
[Epoch 5; Iter   172/ 1097] train: loss: 0.1945859
[Epoch 5; Iter   202/ 1097] train: loss: 0.0315634
[Epoch 5; Iter   232/ 1097] train: loss: 0.1339311
[Epoch 5; Iter   262/ 1097] train: loss: 0.1693380
[Epoch 5; Iter   292/ 1097] train: loss: 0.2871182
[Epoch 5; Iter   322/ 1097] train: loss: 0.1705631
[Epoch 5; Iter   352/ 1097] train: loss: 0.1738982
[Epoch 5; Iter   382/ 1097] train: loss: 0.2773618
[Epoch 5; Iter   412/ 1097] train: loss: 0.0349828
[Epoch 5; Iter   442/ 1097] train: loss: 0.1485834
[Epoch 5; Iter   472/ 1097] train: loss: 0.1524831
[Epoch 5; Iter   502/ 1097] train: loss: 0.1692186
[Epoch 5; Iter   532/ 1097] train: loss: 0.0417467
[Epoch 5; Iter   562/ 1097] train: loss: 0.2402173
[Epoch 5; Iter   592/ 1097] train: loss: 0.0739587
[Epoch 5; Iter   622/ 1097] train: loss: 0.2360783
[Epoch 5; Iter   652/ 1097] train: loss: 0.2486371
[Epoch 5; Iter   682/ 1097] train: loss: 0.0331888
[Epoch 5; Iter   712/ 1097] train: loss: 0.1881034
[Epoch 5; Iter   742/ 1097] train: loss: 0.0270426
[Epoch 5; Iter   772/ 1097] train: loss: 0.0343921
[Epoch 5; Iter   802/ 1097] train: loss: 0.2415675
[Epoch 5; Iter   832/ 1097] train: loss: 0.3323216
[Epoch 5; Iter   862/ 1097] train: loss: 0.1174756
[Epoch 5; Iter   892/ 1097] train: loss: 0.1395807
[Epoch 5; Iter   922/ 1097] train: loss: 0.1295484
[Epoch 5; Iter   952/ 1097] train: loss: 0.2455558
[Epoch 5; Iter   982/ 1097] train: loss: 0.1312424
[Epoch 5; Iter  1012/ 1097] train: loss: 0.3092671
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2475354
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0394581
[Epoch 5] ogbg-molhiv: 0.761516 val loss: 0.232264
[Epoch 5] ogbg-molhiv: 0.726685 test loss: 0.195500
[Epoch 6; Iter     5/ 1097] train: loss: 0.2515711
[Epoch 6; Iter    35/ 1097] train: loss: 0.3801737
[Epoch 6; Iter    65/ 1097] train: loss: 0.0342441
[Epoch 6; Iter    95/ 1097] train: loss: 0.1592343
[Epoch 6; Iter   125/ 1097] train: loss: 0.3053620
[Epoch 6; Iter   155/ 1097] train: loss: 0.1028740
[Epoch 6; Iter   185/ 1097] train: loss: 0.1995301
[Epoch 6; Iter   215/ 1097] train: loss: 0.1603895
[Epoch 6; Iter   245/ 1097] train: loss: 0.1295104
[Epoch 6; Iter   275/ 1097] train: loss: 0.1429764
[Epoch 6; Iter   305/ 1097] train: loss: 0.0385702
[Epoch 6; Iter   335/ 1097] train: loss: 0.0272829
[Epoch 6; Iter   365/ 1097] train: loss: 0.0343525
[Epoch 6; Iter   395/ 1097] train: loss: 0.1788604
[Epoch 6; Iter   425/ 1097] train: loss: 0.0915341
[Epoch 6; Iter   455/ 1097] train: loss: 0.2203111
[Epoch 6; Iter   485/ 1097] train: loss: 0.0377958
[Epoch 6; Iter   515/ 1097] train: loss: 0.1075350
[Epoch 6; Iter   545/ 1097] train: loss: 0.1876995
[Epoch 6; Iter   575/ 1097] train: loss: 0.0433656
[Epoch 6; Iter   605/ 1097] train: loss: 0.0450262
[Epoch 6; Iter   635/ 1097] train: loss: 0.2254285
[Epoch 6; Iter   665/ 1097] train: loss: 0.2256741
[Epoch 6; Iter   695/ 1097] train: loss: 0.3041197
[Epoch 6; Iter   725/ 1097] train: loss: 0.3270655
[Epoch 6; Iter   755/ 1097] train: loss: 0.2705874
[Epoch 6; Iter   785/ 1097] train: loss: 0.4615142
[Epoch 6; Iter   815/ 1097] train: loss: 0.0585661
[Epoch 6; Iter   845/ 1097] train: loss: 0.0384482
[Epoch 6; Iter   875/ 1097] train: loss: 0.1096744
[Epoch 6; Iter   905/ 1097] train: loss: 0.2441870
[Epoch 6; Iter   935/ 1097] train: loss: 0.0752479
[Epoch 6; Iter   965/ 1097] train: loss: 0.1205390
[Epoch 6; Iter   995/ 1097] train: loss: 0.0892472
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0997947
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1570691
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2138163
[Epoch 6] ogbg-molhiv: 0.746561 val loss: 0.379729
[Epoch 6] ogbg-molhiv: 0.693304 test loss: 0.124961
[Epoch 7; Iter    18/ 1097] train: loss: 0.0447183
[Epoch 7; Iter    48/ 1097] train: loss: 0.0407595
[Epoch 7; Iter    78/ 1097] train: loss: 0.2168897
[Epoch 7; Iter   108/ 1097] train: loss: 0.2878288
[Epoch 7; Iter   138/ 1097] train: loss: 0.1540874
[Epoch 7; Iter   168/ 1097] train: loss: 0.0314391
[Epoch 7; Iter   198/ 1097] train: loss: 0.2530770
[Epoch 7; Iter   228/ 1097] train: loss: 0.2154964
[Epoch 7; Iter   258/ 1097] train: loss: 0.0259440
[Epoch 7; Iter   288/ 1097] train: loss: 0.0244835
[Epoch 7; Iter   318/ 1097] train: loss: 0.1861915
[Epoch 7; Iter   348/ 1097] train: loss: 0.0260316
[Epoch 7; Iter   378/ 1097] train: loss: 0.2061692
[Epoch 7; Iter   408/ 1097] train: loss: 0.2805832
[Epoch 7; Iter   438/ 1097] train: loss: 0.0900479
[Epoch 7; Iter   468/ 1097] train: loss: 0.0365434
[Epoch 7; Iter   498/ 1097] train: loss: 0.1603906
[Epoch 7; Iter   528/ 1097] train: loss: 0.0912593
[Epoch 7; Iter   558/ 1097] train: loss: 0.0524116
[Epoch 7; Iter   588/ 1097] train: loss: 0.2752670
[Epoch 7; Iter   618/ 1097] train: loss: 0.1401393
[Epoch 7; Iter   648/ 1097] train: loss: 0.0722877
[Epoch 7; Iter   678/ 1097] train: loss: 0.0290450
[Epoch 7; Iter   708/ 1097] train: loss: 0.1798880
[Epoch 7; Iter   738/ 1097] train: loss: 0.1873007
[Epoch 7; Iter   768/ 1097] train: loss: 0.1648105
[Epoch 7; Iter   798/ 1097] train: loss: 0.1438460
[Epoch 7; Iter   828/ 1097] train: loss: 0.0515512
[Epoch 7; Iter   858/ 1097] train: loss: 0.1375771
[Epoch 7; Iter   888/ 1097] train: loss: 0.0369838
[Epoch 7; Iter   918/ 1097] train: loss: 0.1224357
[Epoch 7; Iter   948/ 1097] train: loss: 0.0406807
[Epoch 7; Iter   978/ 1097] train: loss: 0.0674922
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0563703
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0342370
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1742991
[Epoch 7] ogbg-molhiv: 0.764339 val loss: 1.790693
[Epoch 7] ogbg-molhiv: 0.722107 test loss: 0.427034
[Epoch 3; Iter   986/ 1097] train: loss: 0.0410486
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2790177
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0355560
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2179766
[Epoch 3] ogbg-molhiv: 0.721549 val loss: 2.639211
[Epoch 3] ogbg-molhiv: 0.661302 test loss: 2.754992
[Epoch 4; Iter     9/ 1097] train: loss: 0.0797744
[Epoch 4; Iter    39/ 1097] train: loss: 0.0323590
[Epoch 4; Iter    69/ 1097] train: loss: 0.0396721
[Epoch 4; Iter    99/ 1097] train: loss: 0.0286382
[Epoch 4; Iter   129/ 1097] train: loss: 0.2783708
[Epoch 4; Iter   159/ 1097] train: loss: 0.1076135
[Epoch 4; Iter   189/ 1097] train: loss: 0.0428794
[Epoch 4; Iter   219/ 1097] train: loss: 0.0335013
[Epoch 4; Iter   249/ 1097] train: loss: 0.1612534
[Epoch 4; Iter   279/ 1097] train: loss: 0.2314476
[Epoch 4; Iter   309/ 1097] train: loss: 0.0758952
[Epoch 4; Iter   339/ 1097] train: loss: 0.0548254
[Epoch 4; Iter   369/ 1097] train: loss: 0.0533326
[Epoch 4; Iter   399/ 1097] train: loss: 0.2540210
[Epoch 4; Iter   429/ 1097] train: loss: 0.0364915
[Epoch 4; Iter   459/ 1097] train: loss: 0.1061232
[Epoch 4; Iter   489/ 1097] train: loss: 0.0318247
[Epoch 4; Iter   519/ 1097] train: loss: 0.1682184
[Epoch 4; Iter   549/ 1097] train: loss: 0.0552936
[Epoch 4; Iter   579/ 1097] train: loss: 0.2101338
[Epoch 4; Iter   609/ 1097] train: loss: 0.1684206
[Epoch 4; Iter   639/ 1097] train: loss: 0.1037712
[Epoch 4; Iter   669/ 1097] train: loss: 0.2280868
[Epoch 4; Iter   699/ 1097] train: loss: 0.0891454
[Epoch 4; Iter   729/ 1097] train: loss: 0.0414603
[Epoch 4; Iter   759/ 1097] train: loss: 0.0308827
[Epoch 4; Iter   789/ 1097] train: loss: 0.0280537
[Epoch 4; Iter   819/ 1097] train: loss: 0.1293168
[Epoch 4; Iter   849/ 1097] train: loss: 0.0326686
[Epoch 4; Iter   879/ 1097] train: loss: 0.0311214
[Epoch 4; Iter   909/ 1097] train: loss: 0.0349105
[Epoch 4; Iter   939/ 1097] train: loss: 0.3018297
[Epoch 4; Iter   969/ 1097] train: loss: 0.1138216
[Epoch 4; Iter   999/ 1097] train: loss: 0.0358889
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2179867
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1244476
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1836326
[Epoch 4] ogbg-molhiv: 0.758362 val loss: 0.160406
[Epoch 4] ogbg-molhiv: 0.732706 test loss: 0.158195
[Epoch 5; Iter    22/ 1097] train: loss: 0.0959418
[Epoch 5; Iter    52/ 1097] train: loss: 0.1560661
[Epoch 5; Iter    82/ 1097] train: loss: 0.1529485
[Epoch 5; Iter   112/ 1097] train: loss: 0.4429121
[Epoch 5; Iter   142/ 1097] train: loss: 0.3776709
[Epoch 5; Iter   172/ 1097] train: loss: 0.0287249
[Epoch 5; Iter   202/ 1097] train: loss: 0.1737260
[Epoch 5; Iter   232/ 1097] train: loss: 0.2356901
[Epoch 5; Iter   262/ 1097] train: loss: 0.0394134
[Epoch 5; Iter   292/ 1097] train: loss: 0.1864086
[Epoch 5; Iter   322/ 1097] train: loss: 0.0312141
[Epoch 5; Iter   352/ 1097] train: loss: 0.1086430
[Epoch 5; Iter   382/ 1097] train: loss: 0.0911891
[Epoch 5; Iter   412/ 1097] train: loss: 0.3654018
[Epoch 5; Iter   442/ 1097] train: loss: 0.1296985
[Epoch 5; Iter   472/ 1097] train: loss: 0.1454974
[Epoch 5; Iter   502/ 1097] train: loss: 0.2277371
[Epoch 5; Iter   532/ 1097] train: loss: 0.2806416
[Epoch 5; Iter   562/ 1097] train: loss: 0.2127278
[Epoch 5; Iter   592/ 1097] train: loss: 0.0483484
[Epoch 5; Iter   622/ 1097] train: loss: 0.0296467
[Epoch 5; Iter   652/ 1097] train: loss: 0.1055278
[Epoch 5; Iter   682/ 1097] train: loss: 0.1459078
[Epoch 5; Iter   712/ 1097] train: loss: 0.0260042
[Epoch 5; Iter   742/ 1097] train: loss: 0.1777742
[Epoch 5; Iter   772/ 1097] train: loss: 0.2783319
[Epoch 5; Iter   802/ 1097] train: loss: 0.0790767
[Epoch 5; Iter   832/ 1097] train: loss: 0.0599283
[Epoch 5; Iter   862/ 1097] train: loss: 0.1040501
[Epoch 5; Iter   892/ 1097] train: loss: 0.0461364
[Epoch 5; Iter   922/ 1097] train: loss: 0.0414774
[Epoch 5; Iter   952/ 1097] train: loss: 0.0455184
[Epoch 5; Iter   982/ 1097] train: loss: 0.0773790
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0338111
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2274840
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0419099
[Epoch 5] ogbg-molhiv: 0.742553 val loss: 0.978381
[Epoch 5] ogbg-molhiv: 0.707461 test loss: 0.124300
[Epoch 6; Iter     5/ 1097] train: loss: 0.0834019
[Epoch 6; Iter    35/ 1097] train: loss: 0.2547201
[Epoch 6; Iter    65/ 1097] train: loss: 0.0321470
[Epoch 6; Iter    95/ 1097] train: loss: 0.0549024
[Epoch 6; Iter   125/ 1097] train: loss: 0.3924046
[Epoch 6; Iter   155/ 1097] train: loss: 0.3585001
[Epoch 6; Iter   185/ 1097] train: loss: 0.0492055
[Epoch 6; Iter   215/ 1097] train: loss: 0.1162302
[Epoch 6; Iter   245/ 1097] train: loss: 0.2686239
[Epoch 6; Iter   275/ 1097] train: loss: 0.0474501
[Epoch 6; Iter   305/ 1097] train: loss: 0.2203697
[Epoch 6; Iter   335/ 1097] train: loss: 0.1120291
[Epoch 6; Iter   365/ 1097] train: loss: 0.3313215
[Epoch 6; Iter   395/ 1097] train: loss: 0.3236884
[Epoch 6; Iter   425/ 1097] train: loss: 0.0416144
[Epoch 6; Iter   455/ 1097] train: loss: 0.3547055
[Epoch 6; Iter   485/ 1097] train: loss: 0.0356956
[Epoch 6; Iter   515/ 1097] train: loss: 0.1057721
[Epoch 6; Iter   545/ 1097] train: loss: 0.1677232
[Epoch 6; Iter   575/ 1097] train: loss: 0.1760471
[Epoch 6; Iter   605/ 1097] train: loss: 0.0396971
[Epoch 6; Iter   635/ 1097] train: loss: 0.0306348
[Epoch 6; Iter   665/ 1097] train: loss: 0.2011208
[Epoch 6; Iter   695/ 1097] train: loss: 0.1989948
[Epoch 6; Iter   725/ 1097] train: loss: 0.1825849
[Epoch 6; Iter   755/ 1097] train: loss: 0.0547298
[Epoch 6; Iter   785/ 1097] train: loss: 0.1574384
[Epoch 6; Iter   815/ 1097] train: loss: 0.0338905
[Epoch 6; Iter   845/ 1097] train: loss: 0.1039131
[Epoch 6; Iter   875/ 1097] train: loss: 0.1146834
[Epoch 6; Iter   905/ 1097] train: loss: 0.3011773
[Epoch 6; Iter   935/ 1097] train: loss: 0.0378485
[Epoch 6; Iter   965/ 1097] train: loss: 0.0274277
[Epoch 6; Iter   995/ 1097] train: loss: 0.1879856
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1462979
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0237515
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2142339
[Epoch 6] ogbg-molhiv: 0.797040 val loss: 0.121084
[Epoch 6] ogbg-molhiv: 0.733038 test loss: 0.145229
[Epoch 7; Iter    18/ 1097] train: loss: 0.1757695
[Epoch 7; Iter    48/ 1097] train: loss: 0.7122025
[Epoch 7; Iter    78/ 1097] train: loss: 0.3593976
[Epoch 7; Iter   108/ 1097] train: loss: 0.0423557
[Epoch 7; Iter   138/ 1097] train: loss: 0.0236205
[Epoch 7; Iter   168/ 1097] train: loss: 0.0685648
[Epoch 7; Iter   198/ 1097] train: loss: 0.1810025
[Epoch 7; Iter   228/ 1097] train: loss: 0.1588395
[Epoch 7; Iter   258/ 1097] train: loss: 0.1560326
[Epoch 7; Iter   288/ 1097] train: loss: 0.2173720
[Epoch 7; Iter   318/ 1097] train: loss: 0.0393329
[Epoch 7; Iter   348/ 1097] train: loss: 0.0394360
[Epoch 7; Iter   378/ 1097] train: loss: 0.0302544
[Epoch 7; Iter   408/ 1097] train: loss: 0.0504077
[Epoch 7; Iter   438/ 1097] train: loss: 0.0277809
[Epoch 7; Iter   468/ 1097] train: loss: 0.2929067
[Epoch 7; Iter   498/ 1097] train: loss: 0.0349649
[Epoch 7; Iter   528/ 1097] train: loss: 0.0323624
[Epoch 7; Iter   558/ 1097] train: loss: 0.2662968
[Epoch 7; Iter   588/ 1097] train: loss: 0.1507832
[Epoch 7; Iter   618/ 1097] train: loss: 0.2687093
[Epoch 7; Iter   648/ 1097] train: loss: 0.2240829
[Epoch 7; Iter   678/ 1097] train: loss: 0.1444466
[Epoch 7; Iter   708/ 1097] train: loss: 0.0604306
[Epoch 7; Iter   738/ 1097] train: loss: 0.0275829
[Epoch 7; Iter   768/ 1097] train: loss: 0.0977368
[Epoch 7; Iter   798/ 1097] train: loss: 0.2720194
[Epoch 7; Iter   828/ 1097] train: loss: 0.1719365
[Epoch 7; Iter   858/ 1097] train: loss: 0.2243342
[Epoch 7; Iter   888/ 1097] train: loss: 0.1256495
[Epoch 7; Iter   918/ 1097] train: loss: 0.1775793
[Epoch 7; Iter   948/ 1097] train: loss: 0.1920861
[Epoch 7; Iter   978/ 1097] train: loss: 0.1335107
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0284862
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2390229
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0471142
[Epoch 7] ogbg-molhiv: 0.774263 val loss: 0.132223
[Epoch 7] ogbg-molhiv: 0.753981 test loss: 0.230969
[Epoch 3; Iter   986/ 1097] train: loss: 0.0359927
[Epoch 3; Iter  1016/ 1097] train: loss: 0.3100647
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0309220
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2070954
[Epoch 3] ogbg-molhiv: 0.705798 val loss: 0.130434
[Epoch 3] ogbg-molhiv: 0.679988 test loss: 0.138460
[Epoch 4; Iter     9/ 1097] train: loss: 0.0636878
[Epoch 4; Iter    39/ 1097] train: loss: 0.0280388
[Epoch 4; Iter    69/ 1097] train: loss: 0.0333813
[Epoch 4; Iter    99/ 1097] train: loss: 0.0293691
[Epoch 4; Iter   129/ 1097] train: loss: 0.3063587
[Epoch 4; Iter   159/ 1097] train: loss: 0.0990110
[Epoch 4; Iter   189/ 1097] train: loss: 0.0440284
[Epoch 4; Iter   219/ 1097] train: loss: 0.0362409
[Epoch 4; Iter   249/ 1097] train: loss: 0.1564735
[Epoch 4; Iter   279/ 1097] train: loss: 0.2572688
[Epoch 4; Iter   309/ 1097] train: loss: 0.1022605
[Epoch 4; Iter   339/ 1097] train: loss: 0.0453708
[Epoch 4; Iter   369/ 1097] train: loss: 0.0670187
[Epoch 4; Iter   399/ 1097] train: loss: 0.2313479
[Epoch 4; Iter   429/ 1097] train: loss: 0.0347411
[Epoch 4; Iter   459/ 1097] train: loss: 0.1198970
[Epoch 4; Iter   489/ 1097] train: loss: 0.0366508
[Epoch 4; Iter   519/ 1097] train: loss: 0.1685977
[Epoch 4; Iter   549/ 1097] train: loss: 0.0624159
[Epoch 4; Iter   579/ 1097] train: loss: 0.1197032
[Epoch 4; Iter   609/ 1097] train: loss: 0.1555074
[Epoch 4; Iter   639/ 1097] train: loss: 0.1213029
[Epoch 4; Iter   669/ 1097] train: loss: 0.2154283
[Epoch 4; Iter   699/ 1097] train: loss: 0.0880335
[Epoch 4; Iter   729/ 1097] train: loss: 0.0461941
[Epoch 4; Iter   759/ 1097] train: loss: 0.0319531
[Epoch 4; Iter   789/ 1097] train: loss: 0.0449286
[Epoch 4; Iter   819/ 1097] train: loss: 0.1336993
[Epoch 4; Iter   849/ 1097] train: loss: 0.0318310
[Epoch 4; Iter   879/ 1097] train: loss: 0.0343988
[Epoch 4; Iter   909/ 1097] train: loss: 0.0317009
[Epoch 4; Iter   939/ 1097] train: loss: 0.3200218
[Epoch 4; Iter   969/ 1097] train: loss: 0.1225062
[Epoch 4; Iter   999/ 1097] train: loss: 0.0526695
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2285517
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1145827
[Epoch 4; Iter  1089/ 1097] train: loss: 0.2008596
[Epoch 4] ogbg-molhiv: 0.735165 val loss: 0.137081
[Epoch 4] ogbg-molhiv: 0.707698 test loss: 0.141720
[Epoch 5; Iter    22/ 1097] train: loss: 0.1032033
[Epoch 5; Iter    52/ 1097] train: loss: 0.1558913
[Epoch 5; Iter    82/ 1097] train: loss: 0.1550408
[Epoch 5; Iter   112/ 1097] train: loss: 0.4613813
[Epoch 5; Iter   142/ 1097] train: loss: 0.4068990
[Epoch 5; Iter   172/ 1097] train: loss: 0.0291537
[Epoch 5; Iter   202/ 1097] train: loss: 0.1594773
[Epoch 5; Iter   232/ 1097] train: loss: 0.1674919
[Epoch 5; Iter   262/ 1097] train: loss: 0.0459241
[Epoch 5; Iter   292/ 1097] train: loss: 0.1871843
[Epoch 5; Iter   322/ 1097] train: loss: 0.0319345
[Epoch 5; Iter   352/ 1097] train: loss: 0.1408583
[Epoch 5; Iter   382/ 1097] train: loss: 0.1395566
[Epoch 5; Iter   412/ 1097] train: loss: 0.4101946
[Epoch 5; Iter   442/ 1097] train: loss: 0.1492130
[Epoch 5; Iter   472/ 1097] train: loss: 0.1715486
[Epoch 5; Iter   502/ 1097] train: loss: 0.2102829
[Epoch 5; Iter   532/ 1097] train: loss: 0.2819003
[Epoch 5; Iter   562/ 1097] train: loss: 0.2329600
[Epoch 5; Iter   592/ 1097] train: loss: 0.0379220
[Epoch 5; Iter   622/ 1097] train: loss: 0.0313606
[Epoch 5; Iter   652/ 1097] train: loss: 0.0954616
[Epoch 5; Iter   682/ 1097] train: loss: 0.1621038
[Epoch 5; Iter   712/ 1097] train: loss: 0.0329442
[Epoch 5; Iter   742/ 1097] train: loss: 0.1195375
[Epoch 5; Iter   772/ 1097] train: loss: 0.2788783
[Epoch 5; Iter   802/ 1097] train: loss: 0.0839707
[Epoch 5; Iter   832/ 1097] train: loss: 0.0639494
[Epoch 5; Iter   862/ 1097] train: loss: 0.0929305
[Epoch 5; Iter   892/ 1097] train: loss: 0.0419164
[Epoch 5; Iter   922/ 1097] train: loss: 0.0352938
[Epoch 5; Iter   952/ 1097] train: loss: 0.0841797
[Epoch 5; Iter   982/ 1097] train: loss: 0.0746177
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0353072
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2266345
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0451584
[Epoch 5] ogbg-molhiv: 0.707384 val loss: 0.095988
[Epoch 5] ogbg-molhiv: 0.672641 test loss: 0.134870
[Epoch 6; Iter     5/ 1097] train: loss: 0.1493189
[Epoch 6; Iter    35/ 1097] train: loss: 0.2202974
[Epoch 6; Iter    65/ 1097] train: loss: 0.0310512
[Epoch 6; Iter    95/ 1097] train: loss: 0.0559431
[Epoch 6; Iter   125/ 1097] train: loss: 0.4895004
[Epoch 6; Iter   155/ 1097] train: loss: 0.3973104
[Epoch 6; Iter   185/ 1097] train: loss: 0.0574154
[Epoch 6; Iter   215/ 1097] train: loss: 0.1384877
[Epoch 6; Iter   245/ 1097] train: loss: 0.2663252
[Epoch 6; Iter   275/ 1097] train: loss: 0.0341348
[Epoch 6; Iter   305/ 1097] train: loss: 0.2096530
[Epoch 6; Iter   335/ 1097] train: loss: 0.0442739
[Epoch 6; Iter   365/ 1097] train: loss: 0.2843259
[Epoch 6; Iter   395/ 1097] train: loss: 0.3323900
[Epoch 6; Iter   425/ 1097] train: loss: 0.0429591
[Epoch 6; Iter   455/ 1097] train: loss: 0.2817334
[Epoch 6; Iter   485/ 1097] train: loss: 0.0327411
[Epoch 6; Iter   515/ 1097] train: loss: 0.1409761
[Epoch 6; Iter   545/ 1097] train: loss: 0.1639481
[Epoch 6; Iter   575/ 1097] train: loss: 0.1545591
[Epoch 6; Iter   605/ 1097] train: loss: 0.0374862
[Epoch 6; Iter   635/ 1097] train: loss: 0.0354587
[Epoch 6; Iter   665/ 1097] train: loss: 0.2465180
[Epoch 6; Iter   695/ 1097] train: loss: 0.1702292
[Epoch 6; Iter   725/ 1097] train: loss: 0.1918207
[Epoch 6; Iter   755/ 1097] train: loss: 0.0807910
[Epoch 6; Iter   785/ 1097] train: loss: 0.1064925
[Epoch 6; Iter   815/ 1097] train: loss: 0.0385614
[Epoch 6; Iter   845/ 1097] train: loss: 0.1528793
[Epoch 6; Iter   875/ 1097] train: loss: 0.2091575
[Epoch 6; Iter   905/ 1097] train: loss: 0.3635964
[Epoch 6; Iter   935/ 1097] train: loss: 0.0343956
[Epoch 6; Iter   965/ 1097] train: loss: 0.0322946
[Epoch 6; Iter   995/ 1097] train: loss: 0.2081545
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1548148
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0333147
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2522733
[Epoch 6] ogbg-molhiv: 0.757033 val loss: 0.715085
[Epoch 6] ogbg-molhiv: 0.711505 test loss: 0.608248
[Epoch 7; Iter    18/ 1097] train: loss: 0.1519535
[Epoch 7; Iter    48/ 1097] train: loss: 0.6587597
[Epoch 7; Iter    78/ 1097] train: loss: 0.3820221
[Epoch 7; Iter   108/ 1097] train: loss: 0.0649510
[Epoch 7; Iter   138/ 1097] train: loss: 0.0271894
[Epoch 7; Iter   168/ 1097] train: loss: 0.0942412
[Epoch 7; Iter   198/ 1097] train: loss: 0.1675455
[Epoch 7; Iter   228/ 1097] train: loss: 0.1678394
[Epoch 7; Iter   258/ 1097] train: loss: 0.1115241
[Epoch 7; Iter   288/ 1097] train: loss: 0.1711006
[Epoch 7; Iter   318/ 1097] train: loss: 0.0398547
[Epoch 7; Iter   348/ 1097] train: loss: 0.0402758
[Epoch 7; Iter   378/ 1097] train: loss: 0.0302145
[Epoch 7; Iter   408/ 1097] train: loss: 0.0434565
[Epoch 7; Iter   438/ 1097] train: loss: 0.0331911
[Epoch 7; Iter   468/ 1097] train: loss: 0.2859995
[Epoch 7; Iter   498/ 1097] train: loss: 0.0468171
[Epoch 7; Iter   528/ 1097] train: loss: 0.0380921
[Epoch 7; Iter   558/ 1097] train: loss: 0.2622288
[Epoch 7; Iter   588/ 1097] train: loss: 0.2315157
[Epoch 7; Iter   618/ 1097] train: loss: 0.2726247
[Epoch 7; Iter   648/ 1097] train: loss: 0.1965149
[Epoch 7; Iter   678/ 1097] train: loss: 0.1408885
[Epoch 7; Iter   708/ 1097] train: loss: 0.0768982
[Epoch 7; Iter   738/ 1097] train: loss: 0.0306587
[Epoch 7; Iter   768/ 1097] train: loss: 0.1341723
[Epoch 7; Iter   798/ 1097] train: loss: 0.2406615
[Epoch 7; Iter   828/ 1097] train: loss: 0.1733050
[Epoch 7; Iter   858/ 1097] train: loss: 0.2259731
[Epoch 7; Iter   888/ 1097] train: loss: 0.0882836
[Epoch 7; Iter   918/ 1097] train: loss: 0.1928046
[Epoch 7; Iter   948/ 1097] train: loss: 0.1684493
[Epoch 7; Iter   978/ 1097] train: loss: 0.1287266
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0320245
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2729793
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1005302
[Epoch 7] ogbg-molhiv: 0.729090 val loss: 0.491204
[Epoch 7] ogbg-molhiv: 0.720280 test loss: 0.408296
[Epoch 3; Iter   986/ 1097] train: loss: 0.0502775
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0440162
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1431390
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2528138
[Epoch 3] ogbg-molhiv: 0.744709 val loss: 0.084393
[Epoch 3] ogbg-molhiv: 0.646293 test loss: 0.130488
[Epoch 4; Iter     9/ 1097] train: loss: 0.2339975
[Epoch 4; Iter    39/ 1097] train: loss: 0.1457818
[Epoch 4; Iter    69/ 1097] train: loss: 0.0415489
[Epoch 4; Iter    99/ 1097] train: loss: 0.2986434
[Epoch 4; Iter   129/ 1097] train: loss: 0.1420779
[Epoch 4; Iter   159/ 1097] train: loss: 0.1437110
[Epoch 4; Iter   189/ 1097] train: loss: 0.2553277
[Epoch 4; Iter   219/ 1097] train: loss: 0.1630752
[Epoch 4; Iter   249/ 1097] train: loss: 0.1500432
[Epoch 4; Iter   279/ 1097] train: loss: 0.1914483
[Epoch 4; Iter   309/ 1097] train: loss: 0.1732532
[Epoch 4; Iter   339/ 1097] train: loss: 0.0276571
[Epoch 4; Iter   369/ 1097] train: loss: 0.1185307
[Epoch 4; Iter   399/ 1097] train: loss: 0.1504886
[Epoch 4; Iter   429/ 1097] train: loss: 0.1608883
[Epoch 4; Iter   459/ 1097] train: loss: 0.0360222
[Epoch 4; Iter   489/ 1097] train: loss: 0.1555683
[Epoch 4; Iter   519/ 1097] train: loss: 0.2821422
[Epoch 4; Iter   549/ 1097] train: loss: 0.1950644
[Epoch 4; Iter   579/ 1097] train: loss: 0.0350526
[Epoch 4; Iter   609/ 1097] train: loss: 0.3619588
[Epoch 4; Iter   639/ 1097] train: loss: 0.2655330
[Epoch 4; Iter   669/ 1097] train: loss: 0.3308237
[Epoch 4; Iter   699/ 1097] train: loss: 0.0310095
[Epoch 4; Iter   729/ 1097] train: loss: 0.2447812
[Epoch 4; Iter   759/ 1097] train: loss: 0.1603294
[Epoch 4; Iter   789/ 1097] train: loss: 0.3329460
[Epoch 4; Iter   819/ 1097] train: loss: 0.1557906
[Epoch 4; Iter   849/ 1097] train: loss: 0.0386887
[Epoch 4; Iter   879/ 1097] train: loss: 0.0379283
[Epoch 4; Iter   909/ 1097] train: loss: 0.4138343
[Epoch 4; Iter   939/ 1097] train: loss: 0.1688469
[Epoch 4; Iter   969/ 1097] train: loss: 0.0785184
[Epoch 4; Iter   999/ 1097] train: loss: 0.1911690
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3690318
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2694008
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0433233
[Epoch 4] ogbg-molhiv: 0.721126 val loss: 0.393620
[Epoch 4] ogbg-molhiv: 0.676299 test loss: 0.171978
[Epoch 5; Iter    22/ 1097] train: loss: 0.3460790
[Epoch 5; Iter    52/ 1097] train: loss: 0.1938466
[Epoch 5; Iter    82/ 1097] train: loss: 0.1464570
[Epoch 5; Iter   112/ 1097] train: loss: 0.1208723
[Epoch 5; Iter   142/ 1097] train: loss: 0.1052075
[Epoch 5; Iter   172/ 1097] train: loss: 0.0320265
[Epoch 5; Iter   202/ 1097] train: loss: 0.1417087
[Epoch 5; Iter   232/ 1097] train: loss: 0.0329273
[Epoch 5; Iter   262/ 1097] train: loss: 0.0431856
[Epoch 5; Iter   292/ 1097] train: loss: 0.1780982
[Epoch 5; Iter   322/ 1097] train: loss: 0.1902919
[Epoch 5; Iter   352/ 1097] train: loss: 0.0684270
[Epoch 5; Iter   382/ 1097] train: loss: 0.2236522
[Epoch 5; Iter   412/ 1097] train: loss: 0.2878880
[Epoch 5; Iter   442/ 1097] train: loss: 0.2677917
[Epoch 5; Iter   472/ 1097] train: loss: 0.1432267
[Epoch 5; Iter   502/ 1097] train: loss: 0.1836055
[Epoch 5; Iter   532/ 1097] train: loss: 0.0579187
[Epoch 5; Iter   562/ 1097] train: loss: 0.0499386
[Epoch 5; Iter   592/ 1097] train: loss: 0.0430882
[Epoch 5; Iter   622/ 1097] train: loss: 0.1120597
[Epoch 5; Iter   652/ 1097] train: loss: 0.1275105
[Epoch 5; Iter   682/ 1097] train: loss: 0.1756175
[Epoch 5; Iter   712/ 1097] train: loss: 0.0363245
[Epoch 5; Iter   742/ 1097] train: loss: 0.1930504
[Epoch 5; Iter   772/ 1097] train: loss: 0.1780619
[Epoch 5; Iter   802/ 1097] train: loss: 0.2015474
[Epoch 5; Iter   832/ 1097] train: loss: 0.0341611
[Epoch 5; Iter   862/ 1097] train: loss: 0.1962200
[Epoch 5; Iter   892/ 1097] train: loss: 0.0373979
[Epoch 5; Iter   922/ 1097] train: loss: 0.3401219
[Epoch 5; Iter   952/ 1097] train: loss: 0.0374047
[Epoch 5; Iter   982/ 1097] train: loss: 0.2413543
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2754318
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2129082
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0416918
[Epoch 5] ogbg-molhiv: 0.715002 val loss: 0.105779
[Epoch 5] ogbg-molhiv: 0.722418 test loss: 0.135334
[Epoch 6; Iter     5/ 1097] train: loss: 0.0806309
[Epoch 6; Iter    35/ 1097] train: loss: 0.1101119
[Epoch 6; Iter    65/ 1097] train: loss: 0.1227349
[Epoch 6; Iter    95/ 1097] train: loss: 0.0354514
[Epoch 6; Iter   125/ 1097] train: loss: 0.0915851
[Epoch 6; Iter   155/ 1097] train: loss: 0.0271156
[Epoch 6; Iter   185/ 1097] train: loss: 0.0443488
[Epoch 6; Iter   215/ 1097] train: loss: 0.3659958
[Epoch 6; Iter   245/ 1097] train: loss: 0.2500742
[Epoch 6; Iter   275/ 1097] train: loss: 0.0320694
[Epoch 6; Iter   305/ 1097] train: loss: 0.0367433
[Epoch 6; Iter   335/ 1097] train: loss: 0.1561384
[Epoch 6; Iter   365/ 1097] train: loss: 0.0423906
[Epoch 6; Iter   395/ 1097] train: loss: 0.2852698
[Epoch 6; Iter   425/ 1097] train: loss: 0.1341053
[Epoch 6; Iter   455/ 1097] train: loss: 0.1048153
[Epoch 6; Iter   485/ 1097] train: loss: 0.2235628
[Epoch 6; Iter   515/ 1097] train: loss: 0.0529896
[Epoch 6; Iter   545/ 1097] train: loss: 0.1538440
[Epoch 6; Iter   575/ 1097] train: loss: 0.0411407
[Epoch 6; Iter   605/ 1097] train: loss: 0.0337644
[Epoch 6; Iter   635/ 1097] train: loss: 0.0309545
[Epoch 6; Iter   665/ 1097] train: loss: 0.0326534
[Epoch 6; Iter   695/ 1097] train: loss: 0.1295006
[Epoch 6; Iter   725/ 1097] train: loss: 0.0338547
[Epoch 6; Iter   755/ 1097] train: loss: 0.1521670
[Epoch 6; Iter   785/ 1097] train: loss: 0.0286032
[Epoch 6; Iter   815/ 1097] train: loss: 0.1918889
[Epoch 6; Iter   845/ 1097] train: loss: 0.1374297
[Epoch 6; Iter   875/ 1097] train: loss: 0.1933141
[Epoch 6; Iter   905/ 1097] train: loss: 0.3534327
[Epoch 6; Iter   935/ 1097] train: loss: 0.1865942
[Epoch 6; Iter   965/ 1097] train: loss: 0.1570746
[Epoch 6; Iter   995/ 1097] train: loss: 0.0307005
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0354469
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1014147
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1749303
[Epoch 6] ogbg-molhiv: 0.754960 val loss: 0.221641
[Epoch 6] ogbg-molhiv: 0.633848 test loss: 0.156970
[Epoch 7; Iter    18/ 1097] train: loss: 0.0353350
[Epoch 7; Iter    48/ 1097] train: loss: 0.0840010
[Epoch 7; Iter    78/ 1097] train: loss: 0.1757929
[Epoch 7; Iter   108/ 1097] train: loss: 0.0376583
[Epoch 7; Iter   138/ 1097] train: loss: 0.0390644
[Epoch 7; Iter   168/ 1097] train: loss: 0.1323147
[Epoch 7; Iter   198/ 1097] train: loss: 0.1236171
[Epoch 7; Iter   228/ 1097] train: loss: 0.0297699
[Epoch 7; Iter   258/ 1097] train: loss: 0.0700737
[Epoch 7; Iter   288/ 1097] train: loss: 0.0886423
[Epoch 7; Iter   318/ 1097] train: loss: 0.0548601
[Epoch 7; Iter   348/ 1097] train: loss: 0.1793767
[Epoch 7; Iter   378/ 1097] train: loss: 0.1583338
[Epoch 7; Iter   408/ 1097] train: loss: 0.1395700
[Epoch 7; Iter   438/ 1097] train: loss: 0.1697556
[Epoch 7; Iter   468/ 1097] train: loss: 0.0344396
[Epoch 7; Iter   498/ 1097] train: loss: 0.0510505
[Epoch 7; Iter   528/ 1097] train: loss: 0.0328569
[Epoch 7; Iter   558/ 1097] train: loss: 0.0288855
[Epoch 7; Iter   588/ 1097] train: loss: 0.3005762
[Epoch 7; Iter   618/ 1097] train: loss: 0.3523949
[Epoch 7; Iter   648/ 1097] train: loss: 0.3660401
[Epoch 7; Iter   678/ 1097] train: loss: 0.0490780
[Epoch 7; Iter   708/ 1097] train: loss: 0.1674462
[Epoch 7; Iter   738/ 1097] train: loss: 0.2241179
[Epoch 7; Iter   768/ 1097] train: loss: 0.0401722
[Epoch 7; Iter   798/ 1097] train: loss: 0.1146020
[Epoch 7; Iter   828/ 1097] train: loss: 0.1471719
[Epoch 7; Iter   858/ 1097] train: loss: 0.0863836
[Epoch 7; Iter   888/ 1097] train: loss: 0.0281072
[Epoch 7; Iter   918/ 1097] train: loss: 0.0625190
[Epoch 7; Iter   948/ 1097] train: loss: 0.1575990
[Epoch 7; Iter   978/ 1097] train: loss: 0.0369141
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1497228
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0327089
[Epoch 7; Iter  1068/ 1097] train: loss: 0.2292146
[Epoch 7] ogbg-molhiv: 0.793192 val loss: 0.107208
[Epoch 7] ogbg-molhiv: 0.717573 test loss: 0.124387
[Epoch 3; Iter   986/ 1097] train: loss: 0.2946983
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1213567
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1018091
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0351751
[Epoch 3] ogbg-molhiv: 0.669568 val loss: 0.122216
[Epoch 3] ogbg-molhiv: 0.680181 test loss: 0.121575
[Epoch 4; Iter     9/ 1097] train: loss: 0.3661390
[Epoch 4; Iter    39/ 1097] train: loss: 0.0761309
[Epoch 4; Iter    69/ 1097] train: loss: 0.1034560
[Epoch 4; Iter    99/ 1097] train: loss: 0.0408800
[Epoch 4; Iter   129/ 1097] train: loss: 0.1732273
[Epoch 4; Iter   159/ 1097] train: loss: 0.4526177
[Epoch 4; Iter   189/ 1097] train: loss: 0.0329580
[Epoch 4; Iter   219/ 1097] train: loss: 0.2816765
[Epoch 4; Iter   249/ 1097] train: loss: 0.0366518
[Epoch 4; Iter   279/ 1097] train: loss: 0.1392097
[Epoch 4; Iter   309/ 1097] train: loss: 0.1672503
[Epoch 4; Iter   339/ 1097] train: loss: 0.1039066
[Epoch 4; Iter   369/ 1097] train: loss: 0.1211772
[Epoch 4; Iter   399/ 1097] train: loss: 0.1417351
[Epoch 4; Iter   429/ 1097] train: loss: 0.0570516
[Epoch 4; Iter   459/ 1097] train: loss: 0.0308363
[Epoch 4; Iter   489/ 1097] train: loss: 0.0367110
[Epoch 4; Iter   519/ 1097] train: loss: 0.0994941
[Epoch 4; Iter   549/ 1097] train: loss: 0.0362386
[Epoch 4; Iter   579/ 1097] train: loss: 0.0376377
[Epoch 4; Iter   609/ 1097] train: loss: 0.2373871
[Epoch 4; Iter   639/ 1097] train: loss: 0.0348652
[Epoch 4; Iter   669/ 1097] train: loss: 0.2581359
[Epoch 4; Iter   699/ 1097] train: loss: 0.0952320
[Epoch 4; Iter   729/ 1097] train: loss: 0.3997200
[Epoch 4; Iter   759/ 1097] train: loss: 0.0622685
[Epoch 4; Iter   789/ 1097] train: loss: 0.3477027
[Epoch 4; Iter   819/ 1097] train: loss: 0.0358207
[Epoch 4; Iter   849/ 1097] train: loss: 0.2507594
[Epoch 4; Iter   879/ 1097] train: loss: 0.0986099
[Epoch 4; Iter   909/ 1097] train: loss: 0.5418154
[Epoch 4; Iter   939/ 1097] train: loss: 0.0340471
[Epoch 4; Iter   969/ 1097] train: loss: 0.0384696
[Epoch 4; Iter   999/ 1097] train: loss: 0.2973799
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2841059
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1849109
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0932626
[Epoch 4] ogbg-molhiv: 0.713557 val loss: 0.669104
[Epoch 4] ogbg-molhiv: 0.721279 test loss: 0.168402
[Epoch 5; Iter    22/ 1097] train: loss: 0.0421535
[Epoch 5; Iter    52/ 1097] train: loss: 0.1108779
[Epoch 5; Iter    82/ 1097] train: loss: 0.2925562
[Epoch 5; Iter   112/ 1097] train: loss: 0.0594480
[Epoch 5; Iter   142/ 1097] train: loss: 0.3241306
[Epoch 5; Iter   172/ 1097] train: loss: 0.1872702
[Epoch 5; Iter   202/ 1097] train: loss: 0.0331887
[Epoch 5; Iter   232/ 1097] train: loss: 0.1464081
[Epoch 5; Iter   262/ 1097] train: loss: 0.1713413
[Epoch 5; Iter   292/ 1097] train: loss: 0.2537605
[Epoch 5; Iter   322/ 1097] train: loss: 0.1619978
[Epoch 5; Iter   352/ 1097] train: loss: 0.1622149
[Epoch 5; Iter   382/ 1097] train: loss: 0.3595554
[Epoch 5; Iter   412/ 1097] train: loss: 0.0381502
[Epoch 5; Iter   442/ 1097] train: loss: 0.1532241
[Epoch 5; Iter   472/ 1097] train: loss: 0.1406157
[Epoch 5; Iter   502/ 1097] train: loss: 0.1328222
[Epoch 5; Iter   532/ 1097] train: loss: 0.0361338
[Epoch 5; Iter   562/ 1097] train: loss: 0.3006622
[Epoch 5; Iter   592/ 1097] train: loss: 0.0573516
[Epoch 5; Iter   622/ 1097] train: loss: 0.1686462
[Epoch 5; Iter   652/ 1097] train: loss: 0.2360047
[Epoch 5; Iter   682/ 1097] train: loss: 0.0315504
[Epoch 5; Iter   712/ 1097] train: loss: 0.1896886
[Epoch 5; Iter   742/ 1097] train: loss: 0.0287524
[Epoch 5; Iter   772/ 1097] train: loss: 0.0315712
[Epoch 5; Iter   802/ 1097] train: loss: 0.2669654
[Epoch 5; Iter   832/ 1097] train: loss: 0.2907204
[Epoch 5; Iter   862/ 1097] train: loss: 0.0375308
[Epoch 5; Iter   892/ 1097] train: loss: 0.1104143
[Epoch 5; Iter   922/ 1097] train: loss: 0.1301461
[Epoch 5; Iter   952/ 1097] train: loss: 0.2381973
[Epoch 5; Iter   982/ 1097] train: loss: 0.1506154
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2547122
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2780887
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0370311
[Epoch 5] ogbg-molhiv: 0.720731 val loss: 0.234207
[Epoch 5] ogbg-molhiv: 0.703515 test loss: 0.179939
[Epoch 6; Iter     5/ 1097] train: loss: 0.2043655
[Epoch 6; Iter    35/ 1097] train: loss: 0.4058796
[Epoch 6; Iter    65/ 1097] train: loss: 0.0379888
[Epoch 6; Iter    95/ 1097] train: loss: 0.1626355
[Epoch 6; Iter   125/ 1097] train: loss: 0.2524695
[Epoch 6; Iter   155/ 1097] train: loss: 0.0921844
[Epoch 6; Iter   185/ 1097] train: loss: 0.1747732
[Epoch 6; Iter   215/ 1097] train: loss: 0.1533220
[Epoch 6; Iter   245/ 1097] train: loss: 0.1418210
[Epoch 6; Iter   275/ 1097] train: loss: 0.1520307
[Epoch 6; Iter   305/ 1097] train: loss: 0.0812799
[Epoch 6; Iter   335/ 1097] train: loss: 0.0496767
[Epoch 6; Iter   365/ 1097] train: loss: 0.0365870
[Epoch 6; Iter   395/ 1097] train: loss: 0.1536437
[Epoch 6; Iter   425/ 1097] train: loss: 0.0941528
[Epoch 6; Iter   455/ 1097] train: loss: 0.2729970
[Epoch 6; Iter   485/ 1097] train: loss: 0.0409341
[Epoch 6; Iter   515/ 1097] train: loss: 0.0984968
[Epoch 6; Iter   545/ 1097] train: loss: 0.2087337
[Epoch 6; Iter   575/ 1097] train: loss: 0.0369995
[Epoch 6; Iter   605/ 1097] train: loss: 0.0622087
[Epoch 6; Iter   635/ 1097] train: loss: 0.2079559
[Epoch 6; Iter   665/ 1097] train: loss: 0.2101109
[Epoch 6; Iter   695/ 1097] train: loss: 0.2952775
[Epoch 6; Iter   725/ 1097] train: loss: 0.3059063
[Epoch 6; Iter   755/ 1097] train: loss: 0.3185104
[Epoch 6; Iter   785/ 1097] train: loss: 0.4085800
[Epoch 6; Iter   815/ 1097] train: loss: 0.0944324
[Epoch 6; Iter   845/ 1097] train: loss: 0.0348173
[Epoch 6; Iter   875/ 1097] train: loss: 0.1018428
[Epoch 6; Iter   905/ 1097] train: loss: 0.2692855
[Epoch 6; Iter   935/ 1097] train: loss: 0.1147563
[Epoch 6; Iter   965/ 1097] train: loss: 0.1614725
[Epoch 6; Iter   995/ 1097] train: loss: 0.1438393
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1239319
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1729015
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2406671
[Epoch 6] ogbg-molhiv: 0.743760 val loss: 0.436083
[Epoch 6] ogbg-molhiv: 0.660984 test loss: 0.244996
[Epoch 7; Iter    18/ 1097] train: loss: 0.0445606
[Epoch 7; Iter    48/ 1097] train: loss: 0.0288408
[Epoch 7; Iter    78/ 1097] train: loss: 0.2123108
[Epoch 7; Iter   108/ 1097] train: loss: 0.2516825
[Epoch 7; Iter   138/ 1097] train: loss: 0.2066410
[Epoch 7; Iter   168/ 1097] train: loss: 0.0374994
[Epoch 7; Iter   198/ 1097] train: loss: 0.2608893
[Epoch 7; Iter   228/ 1097] train: loss: 0.1453845
[Epoch 7; Iter   258/ 1097] train: loss: 0.0287275
[Epoch 7; Iter   288/ 1097] train: loss: 0.0214247
[Epoch 7; Iter   318/ 1097] train: loss: 0.2006557
[Epoch 7; Iter   348/ 1097] train: loss: 0.0333788
[Epoch 7; Iter   378/ 1097] train: loss: 0.1798528
[Epoch 7; Iter   408/ 1097] train: loss: 0.2661132
[Epoch 7; Iter   438/ 1097] train: loss: 0.1066520
[Epoch 7; Iter   468/ 1097] train: loss: 0.0394006
[Epoch 7; Iter   498/ 1097] train: loss: 0.1416970
[Epoch 7; Iter   528/ 1097] train: loss: 0.1164803
[Epoch 7; Iter   558/ 1097] train: loss: 0.0471204
[Epoch 7; Iter   588/ 1097] train: loss: 0.2475600
[Epoch 7; Iter   618/ 1097] train: loss: 0.1277410
[Epoch 7; Iter   648/ 1097] train: loss: 0.0806516
[Epoch 7; Iter   678/ 1097] train: loss: 0.0394815
[Epoch 7; Iter   708/ 1097] train: loss: 0.1729860
[Epoch 7; Iter   738/ 1097] train: loss: 0.1607609
[Epoch 7; Iter   768/ 1097] train: loss: 0.1713520
[Epoch 7; Iter   798/ 1097] train: loss: 0.1114551
[Epoch 7; Iter   828/ 1097] train: loss: 0.0333830
[Epoch 7; Iter   858/ 1097] train: loss: 0.1514786
[Epoch 7; Iter   888/ 1097] train: loss: 0.0346992
[Epoch 7; Iter   918/ 1097] train: loss: 0.1597569
[Epoch 7; Iter   948/ 1097] train: loss: 0.0365681
[Epoch 7; Iter   978/ 1097] train: loss: 0.0796567
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0352595
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0328938
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1608969
[Epoch 7] ogbg-molhiv: 0.730597 val loss: 0.264583
[Epoch 7] ogbg-molhiv: 0.698712 test loss: 0.488764
[Epoch 8; Iter     1/ 1097] train: loss: 0.1945917
[Epoch 8; Iter    31/ 1097] train: loss: 0.0727073
[Epoch 8; Iter    61/ 1097] train: loss: 0.1195573
[Epoch 8; Iter    91/ 1097] train: loss: 0.0939687
[Epoch 8; Iter   121/ 1097] train: loss: 0.1344930
[Epoch 8; Iter   151/ 1097] train: loss: 0.0367417
[Epoch 8; Iter   181/ 1097] train: loss: 0.0696283
[Epoch 8; Iter   211/ 1097] train: loss: 0.0454369
[Epoch 8; Iter   241/ 1097] train: loss: 0.0232401
[Epoch 8; Iter   271/ 1097] train: loss: 0.1593257
[Epoch 8; Iter   301/ 1097] train: loss: 0.1780965
[Epoch 8; Iter   331/ 1097] train: loss: 0.1065315
[Epoch 8; Iter   361/ 1097] train: loss: 0.2112280
[Epoch 8; Iter   391/ 1097] train: loss: 0.0267729
[Epoch 8; Iter   421/ 1097] train: loss: 0.2647122
[Epoch 8; Iter   451/ 1097] train: loss: 0.1275585
[Epoch 8; Iter   481/ 1097] train: loss: 0.0418066
[Epoch 8; Iter   511/ 1097] train: loss: 0.0957204
[Epoch 8; Iter   541/ 1097] train: loss: 0.1189667
[Epoch 8; Iter   571/ 1097] train: loss: 0.0998995
[Epoch 8; Iter   601/ 1097] train: loss: 0.3303177
[Epoch 8; Iter   631/ 1097] train: loss: 0.0310095
[Epoch 8; Iter   661/ 1097] train: loss: 0.1801521
[Epoch 8; Iter   691/ 1097] train: loss: 0.1048008
[Epoch 8; Iter   721/ 1097] train: loss: 0.0758374
[Epoch 8; Iter   751/ 1097] train: loss: 0.0703027
[Epoch 8; Iter   781/ 1097] train: loss: 0.1543463
[Epoch 8; Iter   811/ 1097] train: loss: 0.2530167
[Epoch 8; Iter   841/ 1097] train: loss: 0.3154508
[Epoch 8; Iter   871/ 1097] train: loss: 0.2041283
[Epoch 8; Iter   901/ 1097] train: loss: 0.0312549
[Epoch 8; Iter   931/ 1097] train: loss: 0.2006349
[Epoch 8; Iter   961/ 1097] train: loss: 0.0409233
[Epoch 8; Iter   991/ 1097] train: loss: 0.1234868
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3016484
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0306904
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0578443
[Epoch 8] ogbg-molhiv: 0.779244 val loss: 0.671757
[Epoch 8] ogbg-molhiv: 0.759976 test loss: 0.119894
[Epoch 9; Iter    14/ 1097] train: loss: 0.2403185
[Epoch 9; Iter    44/ 1097] train: loss: 0.0299525
[Epoch 9; Iter    74/ 1097] train: loss: 0.0256858
[Epoch 9; Iter   104/ 1097] train: loss: 0.2564633
[Epoch 9; Iter   134/ 1097] train: loss: 0.1032123
[Epoch 9; Iter   164/ 1097] train: loss: 0.1568605
[Epoch 9; Iter   194/ 1097] train: loss: 0.1223111
[Epoch 9; Iter   224/ 1097] train: loss: 0.0305767
[Epoch 9; Iter   254/ 1097] train: loss: 0.3825535
[Epoch 9; Iter   284/ 1097] train: loss: 0.1921297
[Epoch 9; Iter   314/ 1097] train: loss: 0.0978604
[Epoch 9; Iter   344/ 1097] train: loss: 0.5142171
[Epoch 9; Iter   374/ 1097] train: loss: 0.1919185
[Epoch 9; Iter   404/ 1097] train: loss: 0.2299384
[Epoch 9; Iter   434/ 1097] train: loss: 0.0773537
[Epoch 9; Iter   464/ 1097] train: loss: 0.0349489
[Epoch 9; Iter   494/ 1097] train: loss: 0.1719939
[Epoch 9; Iter   524/ 1097] train: loss: 0.0276421
[Epoch 9; Iter   554/ 1097] train: loss: 0.0329216
[Epoch 9; Iter   584/ 1097] train: loss: 0.4431015
[Epoch 9; Iter   614/ 1097] train: loss: 0.1105108
[Epoch 9; Iter   644/ 1097] train: loss: 0.2322015
[Epoch 9; Iter   674/ 1097] train: loss: 0.4547201
[Epoch 9; Iter   704/ 1097] train: loss: 0.1050041
[Epoch 9; Iter   734/ 1097] train: loss: 0.0699706
[Epoch 9; Iter   764/ 1097] train: loss: 0.2975236
[Epoch 9; Iter   794/ 1097] train: loss: 0.1467012
[Epoch 9; Iter   824/ 1097] train: loss: 0.0350336
[Epoch 9; Iter   854/ 1097] train: loss: 0.0422545
[Epoch 9; Iter   884/ 1097] train: loss: 0.0620510
[Epoch 9; Iter   914/ 1097] train: loss: 0.1945322
[Epoch 9; Iter   944/ 1097] train: loss: 0.0361587
[Epoch 9; Iter   974/ 1097] train: loss: 0.0715132
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1349018
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2263684
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3410498
[Epoch 9; Iter  1094/ 1097] train: loss: 0.1878447
[Epoch 9] ogbg-molhiv: 0.745266 val loss: 0.578469
[Epoch 9] ogbg-molhiv: 0.742654 test loss: 0.128810
[Epoch 10; Iter    27/ 1097] train: loss: 0.0352965
[Epoch 10; Iter    57/ 1097] train: loss: 0.0368477
[Epoch 10; Iter    87/ 1097] train: loss: 0.1236647
[Epoch 10; Iter   117/ 1097] train: loss: 0.0476149
[Epoch 10; Iter   147/ 1097] train: loss: 0.3716370
[Epoch 10; Iter   177/ 1097] train: loss: 0.2125832
[Epoch 10; Iter   207/ 1097] train: loss: 0.1863647
[Epoch 10; Iter   237/ 1097] train: loss: 0.0541468
[Epoch 10; Iter   267/ 1097] train: loss: 0.0237589
[Epoch 10; Iter   297/ 1097] train: loss: 0.1759709
[Epoch 10; Iter   327/ 1097] train: loss: 0.0241955
[Epoch 10; Iter   357/ 1097] train: loss: 0.1669231
[Epoch 10; Iter   387/ 1097] train: loss: 0.0850859
[Epoch 10; Iter   417/ 1097] train: loss: 0.0707641
[Epoch 10; Iter   447/ 1097] train: loss: 0.1739303
[Epoch 10; Iter   477/ 1097] train: loss: 0.1413859
[Epoch 10; Iter   507/ 1097] train: loss: 0.1072810
[Epoch 10; Iter   537/ 1097] train: loss: 0.0280099
[Epoch 10; Iter   567/ 1097] train: loss: 0.0305976
[Epoch 10; Iter   597/ 1097] train: loss: 0.0353247
[Epoch 10; Iter   627/ 1097] train: loss: 0.2083713
[Epoch 10; Iter   657/ 1097] train: loss: 0.1533252
[Epoch 10; Iter   687/ 1097] train: loss: 0.0916299
[Epoch 10; Iter   717/ 1097] train: loss: 0.0576490
[Epoch 10; Iter   747/ 1097] train: loss: 0.2076538
[Epoch 10; Iter   777/ 1097] train: loss: 0.2621039
[Epoch 10; Iter   807/ 1097] train: loss: 0.0331510
[Epoch 10; Iter   837/ 1097] train: loss: 0.0320794
[Epoch 10; Iter   867/ 1097] train: loss: 0.0535227
[Epoch 10; Iter   897/ 1097] train: loss: 0.0406101
[Epoch 10; Iter   927/ 1097] train: loss: 0.1577231
[Epoch 10; Iter   957/ 1097] train: loss: 0.0430963
[Epoch 10; Iter   987/ 1097] train: loss: 0.2339614
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2012222
[Epoch 10; Iter  1047/ 1097] train: loss: 0.2016564
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0563500
[Epoch 10] ogbg-molhiv: 0.797515 val loss: 0.077999
[Epoch 10] ogbg-molhiv: 0.766624 test loss: 0.114474
[Epoch 11; Iter    10/ 1097] train: loss: 0.3506870
[Epoch 11; Iter    40/ 1097] train: loss: 0.0376470
[Epoch 11; Iter    70/ 1097] train: loss: 0.1502343
[Epoch 11; Iter   100/ 1097] train: loss: 0.0456301
[Epoch 11; Iter   130/ 1097] train: loss: 0.2449499
[Epoch 11; Iter   160/ 1097] train: loss: 0.0295144
[Epoch 11; Iter   190/ 1097] train: loss: 0.2293213
[Epoch 11; Iter   220/ 1097] train: loss: 0.2712800
[Epoch 11; Iter   250/ 1097] train: loss: 0.1443451
[Epoch 11; Iter   280/ 1097] train: loss: 0.0597012
[Epoch 11; Iter   310/ 1097] train: loss: 0.2124710
[Epoch 11; Iter   340/ 1097] train: loss: 0.0312304
[Epoch 11; Iter   370/ 1097] train: loss: 0.0814343
[Epoch 11; Iter   400/ 1097] train: loss: 0.0759665
[Epoch 11; Iter   430/ 1097] train: loss: 0.2481728
[Epoch 11; Iter   460/ 1097] train: loss: 0.1836489
[Epoch 11; Iter   490/ 1097] train: loss: 0.3219131
[Epoch 11; Iter   520/ 1097] train: loss: 0.1439928
[Epoch 11; Iter   550/ 1097] train: loss: 0.0272868
[Epoch 11; Iter   580/ 1097] train: loss: 0.0539454
[Epoch 11; Iter   610/ 1097] train: loss: 0.0325887
[Epoch 11; Iter   640/ 1097] train: loss: 0.0230350
[Epoch 11; Iter   670/ 1097] train: loss: 0.1446281
[Epoch 11; Iter   700/ 1097] train: loss: 0.1639042
[Epoch 11; Iter   730/ 1097] train: loss: 0.0417376
[Epoch 11; Iter   760/ 1097] train: loss: 0.2919047
[Epoch 11; Iter   790/ 1097] train: loss: 0.2021000
[Epoch 11; Iter   820/ 1097] train: loss: 0.0595884
[Epoch 11; Iter   850/ 1097] train: loss: 0.0476376
[Epoch 11; Iter   880/ 1097] train: loss: 0.2064870
[Epoch 11; Iter   910/ 1097] train: loss: 0.3138567
[Epoch 11; Iter   940/ 1097] train: loss: 0.2765197
[Epoch 11; Iter   970/ 1097] train: loss: 0.2122778
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0473454
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0225152
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1450137
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4248309
[Epoch 11] ogbg-molhiv: 0.788868 val loss: 0.618435
[Epoch 11] ogbg-molhiv: 0.756749 test loss: 0.160967
[Epoch 12; Iter    23/ 1097] train: loss: 0.2384025
[Epoch 12; Iter    53/ 1097] train: loss: 0.0284068
[Epoch 12; Iter    83/ 1097] train: loss: 0.0270755
[Epoch 8; Iter     1/ 1097] train: loss: 0.0800055
[Epoch 8; Iter    31/ 1097] train: loss: 0.1383152
[Epoch 8; Iter    61/ 1097] train: loss: 0.1970050
[Epoch 8; Iter    91/ 1097] train: loss: 0.2479877
[Epoch 8; Iter   121/ 1097] train: loss: 0.0490774
[Epoch 8; Iter   151/ 1097] train: loss: 0.3047006
[Epoch 8; Iter   181/ 1097] train: loss: 0.1974319
[Epoch 8; Iter   211/ 1097] train: loss: 0.2411373
[Epoch 8; Iter   241/ 1097] train: loss: 0.0685265
[Epoch 8; Iter   271/ 1097] train: loss: 0.1375281
[Epoch 8; Iter   301/ 1097] train: loss: 0.0362562
[Epoch 8; Iter   331/ 1097] train: loss: 0.0623049
[Epoch 8; Iter   361/ 1097] train: loss: 0.1525261
[Epoch 8; Iter   391/ 1097] train: loss: 0.0381483
[Epoch 8; Iter   421/ 1097] train: loss: 0.2997779
[Epoch 8; Iter   451/ 1097] train: loss: 0.0239563
[Epoch 8; Iter   481/ 1097] train: loss: 0.1019263
[Epoch 8; Iter   511/ 1097] train: loss: 0.0927716
[Epoch 8; Iter   541/ 1097] train: loss: 0.0306920
[Epoch 8; Iter   571/ 1097] train: loss: 0.4495329
[Epoch 8; Iter   601/ 1097] train: loss: 0.1407524
[Epoch 8; Iter   631/ 1097] train: loss: 0.1151959
[Epoch 8; Iter   661/ 1097] train: loss: 0.0380338
[Epoch 8; Iter   691/ 1097] train: loss: 0.1954107
[Epoch 8; Iter   721/ 1097] train: loss: 0.0961834
[Epoch 8; Iter   751/ 1097] train: loss: 0.0400890
[Epoch 8; Iter   781/ 1097] train: loss: 0.2289031
[Epoch 8; Iter   811/ 1097] train: loss: 0.1078938
[Epoch 8; Iter   841/ 1097] train: loss: 0.0432504
[Epoch 8; Iter   871/ 1097] train: loss: 0.1704151
[Epoch 8; Iter   901/ 1097] train: loss: 0.0280962
[Epoch 8; Iter   931/ 1097] train: loss: 0.0700259
[Epoch 8; Iter   961/ 1097] train: loss: 0.0475876
[Epoch 8; Iter   991/ 1097] train: loss: 0.0291468
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0246657
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0259578
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1700482
[Epoch 8] ogbg-molhiv: 0.788874 val loss: 0.359871
[Epoch 8] ogbg-molhiv: 0.751355 test loss: 0.180199
[Epoch 9; Iter    14/ 1097] train: loss: 0.0238587
[Epoch 9; Iter    44/ 1097] train: loss: 0.0493612
[Epoch 9; Iter    74/ 1097] train: loss: 0.1822755
[Epoch 9; Iter   104/ 1097] train: loss: 0.2875412
[Epoch 9; Iter   134/ 1097] train: loss: 0.2347015
[Epoch 9; Iter   164/ 1097] train: loss: 0.0400261
[Epoch 9; Iter   194/ 1097] train: loss: 0.0519775
[Epoch 9; Iter   224/ 1097] train: loss: 0.0321852
[Epoch 9; Iter   254/ 1097] train: loss: 0.0963700
[Epoch 9; Iter   284/ 1097] train: loss: 0.0497458
[Epoch 9; Iter   314/ 1097] train: loss: 0.0526771
[Epoch 9; Iter   344/ 1097] train: loss: 0.0246982
[Epoch 9; Iter   374/ 1097] train: loss: 0.0462584
[Epoch 9; Iter   404/ 1097] train: loss: 0.1110510
[Epoch 9; Iter   434/ 1097] train: loss: 0.1763365
[Epoch 9; Iter   464/ 1097] train: loss: 0.2027364
[Epoch 9; Iter   494/ 1097] train: loss: 0.0695681
[Epoch 9; Iter   524/ 1097] train: loss: 0.1013659
[Epoch 9; Iter   554/ 1097] train: loss: 0.0375851
[Epoch 9; Iter   584/ 1097] train: loss: 0.1845132
[Epoch 9; Iter   614/ 1097] train: loss: 0.0238297
[Epoch 9; Iter   644/ 1097] train: loss: 0.1894010
[Epoch 9; Iter   674/ 1097] train: loss: 0.0796513
[Epoch 9; Iter   704/ 1097] train: loss: 0.0244650
[Epoch 9; Iter   734/ 1097] train: loss: 0.1068511
[Epoch 9; Iter   764/ 1097] train: loss: 0.1029402
[Epoch 9; Iter   794/ 1097] train: loss: 0.0283454
[Epoch 9; Iter   824/ 1097] train: loss: 0.0315418
[Epoch 9; Iter   854/ 1097] train: loss: 0.0355296
[Epoch 9; Iter   884/ 1097] train: loss: 0.2384610
[Epoch 9; Iter   914/ 1097] train: loss: 0.0249426
[Epoch 9; Iter   944/ 1097] train: loss: 0.1520984
[Epoch 9; Iter   974/ 1097] train: loss: 0.0409314
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1425993
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0961943
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0683542
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0710594
[Epoch 9] ogbg-molhiv: 0.751724 val loss: 0.367996
[Epoch 9] ogbg-molhiv: 0.720607 test loss: 0.144749
[Epoch 10; Iter    27/ 1097] train: loss: 0.1681528
[Epoch 10; Iter    57/ 1097] train: loss: 0.0271261
[Epoch 10; Iter    87/ 1097] train: loss: 0.1984989
[Epoch 10; Iter   117/ 1097] train: loss: 0.0450680
[Epoch 10; Iter   147/ 1097] train: loss: 0.0284273
[Epoch 10; Iter   177/ 1097] train: loss: 0.0243294
[Epoch 10; Iter   207/ 1097] train: loss: 0.0257276
[Epoch 10; Iter   237/ 1097] train: loss: 0.0926022
[Epoch 10; Iter   267/ 1097] train: loss: 0.0210233
[Epoch 10; Iter   297/ 1097] train: loss: 0.0250650
[Epoch 10; Iter   327/ 1097] train: loss: 0.0743994
[Epoch 10; Iter   357/ 1097] train: loss: 0.1214102
[Epoch 10; Iter   387/ 1097] train: loss: 0.1642284
[Epoch 10; Iter   417/ 1097] train: loss: 0.0382779
[Epoch 10; Iter   447/ 1097] train: loss: 0.0342470
[Epoch 10; Iter   477/ 1097] train: loss: 0.0379344
[Epoch 10; Iter   507/ 1097] train: loss: 0.0856337
[Epoch 10; Iter   537/ 1097] train: loss: 0.0297374
[Epoch 10; Iter   567/ 1097] train: loss: 0.1659583
[Epoch 10; Iter   597/ 1097] train: loss: 0.1851418
[Epoch 10; Iter   627/ 1097] train: loss: 0.2038486
[Epoch 10; Iter   657/ 1097] train: loss: 0.0242643
[Epoch 10; Iter   687/ 1097] train: loss: 0.3081577
[Epoch 10; Iter   717/ 1097] train: loss: 0.1148463
[Epoch 10; Iter   747/ 1097] train: loss: 0.3689524
[Epoch 10; Iter   777/ 1097] train: loss: 0.1062921
[Epoch 10; Iter   807/ 1097] train: loss: 0.1022665
[Epoch 10; Iter   837/ 1097] train: loss: 0.1003103
[Epoch 10; Iter   867/ 1097] train: loss: 0.3570551
[Epoch 10; Iter   897/ 1097] train: loss: 0.1792646
[Epoch 10; Iter   927/ 1097] train: loss: 0.3581400
[Epoch 10; Iter   957/ 1097] train: loss: 0.2605491
[Epoch 10; Iter   987/ 1097] train: loss: 0.2655976
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0526169
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0769040
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1832066
[Epoch 10] ogbg-molhiv: 0.804488 val loss: 0.075056
[Epoch 10] ogbg-molhiv: 0.751272 test loss: 0.119533
[Epoch 11; Iter    10/ 1097] train: loss: 0.0471231
[Epoch 11; Iter    40/ 1097] train: loss: 0.0350388
[Epoch 11; Iter    70/ 1097] train: loss: 0.0505294
[Epoch 11; Iter   100/ 1097] train: loss: 0.1403562
[Epoch 11; Iter   130/ 1097] train: loss: 0.0267515
[Epoch 11; Iter   160/ 1097] train: loss: 0.0389937
[Epoch 11; Iter   190/ 1097] train: loss: 0.1261646
[Epoch 11; Iter   220/ 1097] train: loss: 0.0543555
[Epoch 11; Iter   250/ 1097] train: loss: 0.1051878
[Epoch 11; Iter   280/ 1097] train: loss: 0.1794437
[Epoch 11; Iter   310/ 1097] train: loss: 0.1025143
[Epoch 11; Iter   340/ 1097] train: loss: 0.0816949
[Epoch 11; Iter   370/ 1097] train: loss: 0.3313352
[Epoch 11; Iter   400/ 1097] train: loss: 0.0577117
[Epoch 11; Iter   430/ 1097] train: loss: 0.1077156
[Epoch 11; Iter   460/ 1097] train: loss: 0.0634963
[Epoch 11; Iter   490/ 1097] train: loss: 0.1916901
[Epoch 11; Iter   520/ 1097] train: loss: 0.5064560
[Epoch 11; Iter   550/ 1097] train: loss: 0.1431270
[Epoch 11; Iter   580/ 1097] train: loss: 0.1713896
[Epoch 11; Iter   610/ 1097] train: loss: 0.0247793
[Epoch 11; Iter   640/ 1097] train: loss: 0.0354353
[Epoch 11; Iter   670/ 1097] train: loss: 0.0498444
[Epoch 11; Iter   700/ 1097] train: loss: 0.0257424
[Epoch 11; Iter   730/ 1097] train: loss: 0.1626876
[Epoch 11; Iter   760/ 1097] train: loss: 0.0341034
[Epoch 11; Iter   790/ 1097] train: loss: 0.0517687
[Epoch 11; Iter   820/ 1097] train: loss: 0.3423786
[Epoch 11; Iter   850/ 1097] train: loss: 0.1133767
[Epoch 11; Iter   880/ 1097] train: loss: 0.0215687
[Epoch 11; Iter   910/ 1097] train: loss: 0.1585858
[Epoch 11; Iter   940/ 1097] train: loss: 0.2596038
[Epoch 11; Iter   970/ 1097] train: loss: 0.1316673
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1290363
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0590167
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2835904
[Epoch 11; Iter  1090/ 1097] train: loss: 0.2712082
[Epoch 11] ogbg-molhiv: 0.797249 val loss: 0.079845
[Epoch 11] ogbg-molhiv: 0.726242 test loss: 0.122252
[Epoch 12; Iter    23/ 1097] train: loss: 0.0841268
[Epoch 12; Iter    53/ 1097] train: loss: 0.0258648
[Epoch 12; Iter    83/ 1097] train: loss: 0.0247514
[Epoch 8; Iter     1/ 1097] train: loss: 0.0964440
[Epoch 8; Iter    31/ 1097] train: loss: 0.0315652
[Epoch 8; Iter    61/ 1097] train: loss: 0.1751736
[Epoch 8; Iter    91/ 1097] train: loss: 0.1726796
[Epoch 8; Iter   121/ 1097] train: loss: 0.0397620
[Epoch 8; Iter   151/ 1097] train: loss: 0.1786755
[Epoch 8; Iter   181/ 1097] train: loss: 0.0395690
[Epoch 8; Iter   211/ 1097] train: loss: 0.3292142
[Epoch 8; Iter   241/ 1097] train: loss: 0.1254803
[Epoch 8; Iter   271/ 1097] train: loss: 0.2039353
[Epoch 8; Iter   301/ 1097] train: loss: 0.0829055
[Epoch 8; Iter   331/ 1097] train: loss: 0.1344270
[Epoch 8; Iter   361/ 1097] train: loss: 0.0582727
[Epoch 8; Iter   391/ 1097] train: loss: 0.0589567
[Epoch 8; Iter   421/ 1097] train: loss: 0.2325278
[Epoch 8; Iter   451/ 1097] train: loss: 0.0250620
[Epoch 8; Iter   481/ 1097] train: loss: 0.1469491
[Epoch 8; Iter   511/ 1097] train: loss: 0.2040115
[Epoch 8; Iter   541/ 1097] train: loss: 0.0317694
[Epoch 8; Iter   571/ 1097] train: loss: 0.0316234
[Epoch 8; Iter   601/ 1097] train: loss: 0.0458408
[Epoch 8; Iter   631/ 1097] train: loss: 0.1056081
[Epoch 8; Iter   661/ 1097] train: loss: 0.0326044
[Epoch 8; Iter   691/ 1097] train: loss: 0.2896396
[Epoch 8; Iter   721/ 1097] train: loss: 0.0364382
[Epoch 8; Iter   751/ 1097] train: loss: 0.0660416
[Epoch 8; Iter   781/ 1097] train: loss: 0.0487119
[Epoch 8; Iter   811/ 1097] train: loss: 0.0611537
[Epoch 8; Iter   841/ 1097] train: loss: 0.1877388
[Epoch 8; Iter   871/ 1097] train: loss: 0.2553319
[Epoch 8; Iter   901/ 1097] train: loss: 0.0401920
[Epoch 8; Iter   931/ 1097] train: loss: 0.1316974
[Epoch 8; Iter   961/ 1097] train: loss: 0.0317418
[Epoch 8; Iter   991/ 1097] train: loss: 0.0586283
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0312426
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0271019
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3002952
[Epoch 8] ogbg-molhiv: 0.761047 val loss: 0.213370
[Epoch 8] ogbg-molhiv: 0.741194 test loss: 1.347312
[Epoch 9; Iter    14/ 1097] train: loss: 0.0363668
[Epoch 9; Iter    44/ 1097] train: loss: 0.0760373
[Epoch 9; Iter    74/ 1097] train: loss: 0.0498160
[Epoch 9; Iter   104/ 1097] train: loss: 0.0370254
[Epoch 9; Iter   134/ 1097] train: loss: 0.1172301
[Epoch 9; Iter   164/ 1097] train: loss: 0.0304269
[Epoch 9; Iter   194/ 1097] train: loss: 0.0298429
[Epoch 9; Iter   224/ 1097] train: loss: 0.3432674
[Epoch 9; Iter   254/ 1097] train: loss: 0.1035284
[Epoch 9; Iter   284/ 1097] train: loss: 0.1440436
[Epoch 9; Iter   314/ 1097] train: loss: 0.2658603
[Epoch 9; Iter   344/ 1097] train: loss: 0.0281920
[Epoch 9; Iter   374/ 1097] train: loss: 0.2098329
[Epoch 9; Iter   404/ 1097] train: loss: 0.1318318
[Epoch 9; Iter   434/ 1097] train: loss: 0.1523838
[Epoch 9; Iter   464/ 1097] train: loss: 0.0280379
[Epoch 9; Iter   494/ 1097] train: loss: 0.0690850
[Epoch 9; Iter   524/ 1097] train: loss: 0.0382507
[Epoch 9; Iter   554/ 1097] train: loss: 0.0573404
[Epoch 9; Iter   584/ 1097] train: loss: 0.1764148
[Epoch 9; Iter   614/ 1097] train: loss: 0.0403359
[Epoch 9; Iter   644/ 1097] train: loss: 0.2000810
[Epoch 9; Iter   674/ 1097] train: loss: 0.1908553
[Epoch 9; Iter   704/ 1097] train: loss: 0.0286318
[Epoch 9; Iter   734/ 1097] train: loss: 0.0244056
[Epoch 9; Iter   764/ 1097] train: loss: 0.0795564
[Epoch 9; Iter   794/ 1097] train: loss: 0.0487228
[Epoch 9; Iter   824/ 1097] train: loss: 0.0245277
[Epoch 9; Iter   854/ 1097] train: loss: 0.0204459
[Epoch 9; Iter   884/ 1097] train: loss: 0.3135779
[Epoch 9; Iter   914/ 1097] train: loss: 0.0557966
[Epoch 9; Iter   944/ 1097] train: loss: 0.2200490
[Epoch 9; Iter   974/ 1097] train: loss: 0.0334758
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0270077
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0283020
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2096051
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0311593
[Epoch 9] ogbg-molhiv: 0.791667 val loss: 0.750979
[Epoch 9] ogbg-molhiv: 0.753624 test loss: 1.266812
[Epoch 10; Iter    27/ 1097] train: loss: 0.2181318
[Epoch 10; Iter    57/ 1097] train: loss: 0.3563406
[Epoch 10; Iter    87/ 1097] train: loss: 0.0336187
[Epoch 10; Iter   117/ 1097] train: loss: 0.1698418
[Epoch 10; Iter   147/ 1097] train: loss: 0.0284167
[Epoch 10; Iter   177/ 1097] train: loss: 0.4759704
[Epoch 10; Iter   207/ 1097] train: loss: 0.0934578
[Epoch 10; Iter   237/ 1097] train: loss: 0.0405976
[Epoch 10; Iter   267/ 1097] train: loss: 0.0397402
[Epoch 10; Iter   297/ 1097] train: loss: 0.3032080
[Epoch 10; Iter   327/ 1097] train: loss: 0.2829197
[Epoch 10; Iter   357/ 1097] train: loss: 0.0564464
[Epoch 10; Iter   387/ 1097] train: loss: 0.0961010
[Epoch 10; Iter   417/ 1097] train: loss: 0.2571229
[Epoch 10; Iter   447/ 1097] train: loss: 0.1714614
[Epoch 10; Iter   477/ 1097] train: loss: 0.0317119
[Epoch 10; Iter   507/ 1097] train: loss: 0.0290714
[Epoch 10; Iter   537/ 1097] train: loss: 0.1151626
[Epoch 10; Iter   567/ 1097] train: loss: 0.2030229
[Epoch 10; Iter   597/ 1097] train: loss: 0.1762970
[Epoch 10; Iter   627/ 1097] train: loss: 0.0583898
[Epoch 10; Iter   657/ 1097] train: loss: 0.3142452
[Epoch 10; Iter   687/ 1097] train: loss: 0.1317405
[Epoch 10; Iter   717/ 1097] train: loss: 0.2948140
[Epoch 10; Iter   747/ 1097] train: loss: 0.0308439
[Epoch 10; Iter   777/ 1097] train: loss: 0.0188150
[Epoch 10; Iter   807/ 1097] train: loss: 0.3294209
[Epoch 10; Iter   837/ 1097] train: loss: 0.0299144
[Epoch 10; Iter   867/ 1097] train: loss: 0.0290336
[Epoch 10; Iter   897/ 1097] train: loss: 0.0329770
[Epoch 10; Iter   927/ 1097] train: loss: 0.1620424
[Epoch 10; Iter   957/ 1097] train: loss: 0.1070371
[Epoch 10; Iter   987/ 1097] train: loss: 0.4798210
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0238084
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0549543
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1868190
[Epoch 10] ogbg-molhiv: 0.779964 val loss: 2.293149
[Epoch 10] ogbg-molhiv: 0.763483 test loss: 3.721013
[Epoch 11; Iter    10/ 1097] train: loss: 0.2956929
[Epoch 11; Iter    40/ 1097] train: loss: 0.1571366
[Epoch 11; Iter    70/ 1097] train: loss: 0.1139309
[Epoch 11; Iter   100/ 1097] train: loss: 0.1169911
[Epoch 11; Iter   130/ 1097] train: loss: 0.4072315
[Epoch 11; Iter   160/ 1097] train: loss: 0.2022343
[Epoch 11; Iter   190/ 1097] train: loss: 0.0364279
[Epoch 11; Iter   220/ 1097] train: loss: 0.2186234
[Epoch 11; Iter   250/ 1097] train: loss: 0.0630226
[Epoch 11; Iter   280/ 1097] train: loss: 0.1776412
[Epoch 11; Iter   310/ 1097] train: loss: 0.2152119
[Epoch 11; Iter   340/ 1097] train: loss: 0.0361857
[Epoch 11; Iter   370/ 1097] train: loss: 0.0267948
[Epoch 11; Iter   400/ 1097] train: loss: 0.2360499
[Epoch 11; Iter   430/ 1097] train: loss: 0.0575928
[Epoch 11; Iter   460/ 1097] train: loss: 0.1179981
[Epoch 11; Iter   490/ 1097] train: loss: 0.2337285
[Epoch 11; Iter   520/ 1097] train: loss: 0.1642368
[Epoch 11; Iter   550/ 1097] train: loss: 0.0242330
[Epoch 11; Iter   580/ 1097] train: loss: 0.4534617
[Epoch 11; Iter   610/ 1097] train: loss: 0.0495912
[Epoch 11; Iter   640/ 1097] train: loss: 0.0565065
[Epoch 11; Iter   670/ 1097] train: loss: 0.0322726
[Epoch 11; Iter   700/ 1097] train: loss: 0.1881288
[Epoch 11; Iter   730/ 1097] train: loss: 0.1840668
[Epoch 11; Iter   760/ 1097] train: loss: 0.1248388
[Epoch 11; Iter   790/ 1097] train: loss: 0.1200030
[Epoch 11; Iter   820/ 1097] train: loss: 0.0428081
[Epoch 11; Iter   850/ 1097] train: loss: 0.2196039
[Epoch 11; Iter   880/ 1097] train: loss: 0.0212844
[Epoch 11; Iter   910/ 1097] train: loss: 0.0353450
[Epoch 11; Iter   940/ 1097] train: loss: 0.2243928
[Epoch 11; Iter   970/ 1097] train: loss: 0.0269908
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0756228
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1534367
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3248499
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0364642
[Epoch 11] ogbg-molhiv: 0.785978 val loss: 0.559255
[Epoch 11] ogbg-molhiv: 0.785002 test loss: 2.095334
[Epoch 12; Iter    23/ 1097] train: loss: 0.1628406
[Epoch 12; Iter    53/ 1097] train: loss: 0.0421046
[Epoch 12; Iter    83/ 1097] train: loss: 0.0564401
[Epoch 8; Iter     1/ 1097] train: loss: 0.1280925
[Epoch 8; Iter    31/ 1097] train: loss: 0.0312394
[Epoch 8; Iter    61/ 1097] train: loss: 0.1471040
[Epoch 8; Iter    91/ 1097] train: loss: 0.1638614
[Epoch 8; Iter   121/ 1097] train: loss: 0.0431026
[Epoch 8; Iter   151/ 1097] train: loss: 0.0820466
[Epoch 8; Iter   181/ 1097] train: loss: 0.0399524
[Epoch 8; Iter   211/ 1097] train: loss: 0.2740607
[Epoch 8; Iter   241/ 1097] train: loss: 0.1642393
[Epoch 8; Iter   271/ 1097] train: loss: 0.2290809
[Epoch 8; Iter   301/ 1097] train: loss: 0.0762735
[Epoch 8; Iter   331/ 1097] train: loss: 0.1230189
[Epoch 8; Iter   361/ 1097] train: loss: 0.0436846
[Epoch 8; Iter   391/ 1097] train: loss: 0.0305066
[Epoch 8; Iter   421/ 1097] train: loss: 0.2159269
[Epoch 8; Iter   451/ 1097] train: loss: 0.0270208
[Epoch 8; Iter   481/ 1097] train: loss: 0.2144332
[Epoch 8; Iter   511/ 1097] train: loss: 0.1916536
[Epoch 8; Iter   541/ 1097] train: loss: 0.0364147
[Epoch 8; Iter   571/ 1097] train: loss: 0.0305689
[Epoch 8; Iter   601/ 1097] train: loss: 0.0585884
[Epoch 8; Iter   631/ 1097] train: loss: 0.0949415
[Epoch 8; Iter   661/ 1097] train: loss: 0.0346170
[Epoch 8; Iter   691/ 1097] train: loss: 0.2741301
[Epoch 8; Iter   721/ 1097] train: loss: 0.0429166
[Epoch 8; Iter   751/ 1097] train: loss: 0.0986915
[Epoch 8; Iter   781/ 1097] train: loss: 0.0620403
[Epoch 8; Iter   811/ 1097] train: loss: 0.0544541
[Epoch 8; Iter   841/ 1097] train: loss: 0.1689097
[Epoch 8; Iter   871/ 1097] train: loss: 0.3513224
[Epoch 8; Iter   901/ 1097] train: loss: 0.0513268
[Epoch 8; Iter   931/ 1097] train: loss: 0.1017966
[Epoch 8; Iter   961/ 1097] train: loss: 0.0273706
[Epoch 8; Iter   991/ 1097] train: loss: 0.0334903
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0426869
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0335544
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3771943
[Epoch 8] ogbg-molhiv: 0.734577 val loss: 0.422311
[Epoch 8] ogbg-molhiv: 0.685301 test loss: 0.126259
[Epoch 9; Iter    14/ 1097] train: loss: 0.0397905
[Epoch 9; Iter    44/ 1097] train: loss: 0.0500555
[Epoch 9; Iter    74/ 1097] train: loss: 0.0490594
[Epoch 9; Iter   104/ 1097] train: loss: 0.0486907
[Epoch 9; Iter   134/ 1097] train: loss: 0.0319814
[Epoch 9; Iter   164/ 1097] train: loss: 0.0354596
[Epoch 9; Iter   194/ 1097] train: loss: 0.0336981
[Epoch 9; Iter   224/ 1097] train: loss: 0.3382013
[Epoch 9; Iter   254/ 1097] train: loss: 0.1123671
[Epoch 9; Iter   284/ 1097] train: loss: 0.1582694
[Epoch 9; Iter   314/ 1097] train: loss: 0.1871418
[Epoch 9; Iter   344/ 1097] train: loss: 0.0276805
[Epoch 9; Iter   374/ 1097] train: loss: 0.1593391
[Epoch 9; Iter   404/ 1097] train: loss: 0.1772344
[Epoch 9; Iter   434/ 1097] train: loss: 0.1128154
[Epoch 9; Iter   464/ 1097] train: loss: 0.0313001
[Epoch 9; Iter   494/ 1097] train: loss: 0.0942858
[Epoch 9; Iter   524/ 1097] train: loss: 0.0305861
[Epoch 9; Iter   554/ 1097] train: loss: 0.0705354
[Epoch 9; Iter   584/ 1097] train: loss: 0.1624179
[Epoch 9; Iter   614/ 1097] train: loss: 0.0609311
[Epoch 9; Iter   644/ 1097] train: loss: 0.1500042
[Epoch 9; Iter   674/ 1097] train: loss: 0.1716488
[Epoch 9; Iter   704/ 1097] train: loss: 0.0251479
[Epoch 9; Iter   734/ 1097] train: loss: 0.0284340
[Epoch 9; Iter   764/ 1097] train: loss: 0.1026327
[Epoch 9; Iter   794/ 1097] train: loss: 0.0430220
[Epoch 9; Iter   824/ 1097] train: loss: 0.0226590
[Epoch 9; Iter   854/ 1097] train: loss: 0.0231248
[Epoch 9; Iter   884/ 1097] train: loss: 0.3155065
[Epoch 9; Iter   914/ 1097] train: loss: 0.0583703
[Epoch 9; Iter   944/ 1097] train: loss: 0.1829227
[Epoch 9; Iter   974/ 1097] train: loss: 0.0281247
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0287402
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0356425
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2957742
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0443431
[Epoch 9] ogbg-molhiv: 0.748671 val loss: 0.215948
[Epoch 9] ogbg-molhiv: 0.735219 test loss: 0.175040
[Epoch 10; Iter    27/ 1097] train: loss: 0.2439832
[Epoch 10; Iter    57/ 1097] train: loss: 0.2995878
[Epoch 10; Iter    87/ 1097] train: loss: 0.0424473
[Epoch 10; Iter   117/ 1097] train: loss: 0.1633410
[Epoch 10; Iter   147/ 1097] train: loss: 0.0240384
[Epoch 10; Iter   177/ 1097] train: loss: 0.4113207
[Epoch 10; Iter   207/ 1097] train: loss: 0.0780624
[Epoch 10; Iter   237/ 1097] train: loss: 0.0318778
[Epoch 10; Iter   267/ 1097] train: loss: 0.0781463
[Epoch 10; Iter   297/ 1097] train: loss: 0.2313038
[Epoch 10; Iter   327/ 1097] train: loss: 0.2628612
[Epoch 10; Iter   357/ 1097] train: loss: 0.0291127
[Epoch 10; Iter   387/ 1097] train: loss: 0.1086521
[Epoch 10; Iter   417/ 1097] train: loss: 0.2621956
[Epoch 10; Iter   447/ 1097] train: loss: 0.1311068
[Epoch 10; Iter   477/ 1097] train: loss: 0.0314728
[Epoch 10; Iter   507/ 1097] train: loss: 0.0302762
[Epoch 10; Iter   537/ 1097] train: loss: 0.1876228
[Epoch 10; Iter   567/ 1097] train: loss: 0.2182442
[Epoch 10; Iter   597/ 1097] train: loss: 0.1895578
[Epoch 10; Iter   627/ 1097] train: loss: 0.0381942
[Epoch 10; Iter   657/ 1097] train: loss: 0.2666571
[Epoch 10; Iter   687/ 1097] train: loss: 0.1949101
[Epoch 10; Iter   717/ 1097] train: loss: 0.3082750
[Epoch 10; Iter   747/ 1097] train: loss: 0.0224669
[Epoch 10; Iter   777/ 1097] train: loss: 0.0195039
[Epoch 10; Iter   807/ 1097] train: loss: 0.3139055
[Epoch 10; Iter   837/ 1097] train: loss: 0.0360496
[Epoch 10; Iter   867/ 1097] train: loss: 0.0292367
[Epoch 10; Iter   897/ 1097] train: loss: 0.0527309
[Epoch 10; Iter   927/ 1097] train: loss: 0.1885417
[Epoch 10; Iter   957/ 1097] train: loss: 0.1083116
[Epoch 10; Iter   987/ 1097] train: loss: 0.4937294
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0250284
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0417238
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1329675
[Epoch 10] ogbg-molhiv: 0.788651 val loss: 0.076219
[Epoch 10] ogbg-molhiv: 0.737506 test loss: 0.121883
[Epoch 11; Iter    10/ 1097] train: loss: 0.2981924
[Epoch 11; Iter    40/ 1097] train: loss: 0.2032977
[Epoch 11; Iter    70/ 1097] train: loss: 0.1045654
[Epoch 11; Iter   100/ 1097] train: loss: 0.0870834
[Epoch 11; Iter   130/ 1097] train: loss: 0.2903298
[Epoch 11; Iter   160/ 1097] train: loss: 0.2159731
[Epoch 11; Iter   190/ 1097] train: loss: 0.0300051
[Epoch 11; Iter   220/ 1097] train: loss: 0.1567937
[Epoch 11; Iter   250/ 1097] train: loss: 0.0532567
[Epoch 11; Iter   280/ 1097] train: loss: 0.1698579
[Epoch 11; Iter   310/ 1097] train: loss: 0.1993513
[Epoch 11; Iter   340/ 1097] train: loss: 0.0380585
[Epoch 11; Iter   370/ 1097] train: loss: 0.0325258
[Epoch 11; Iter   400/ 1097] train: loss: 0.2435386
[Epoch 11; Iter   430/ 1097] train: loss: 0.0338341
[Epoch 11; Iter   460/ 1097] train: loss: 0.1535822
[Epoch 11; Iter   490/ 1097] train: loss: 0.2320576
[Epoch 11; Iter   520/ 1097] train: loss: 0.1310944
[Epoch 11; Iter   550/ 1097] train: loss: 0.0207747
[Epoch 11; Iter   580/ 1097] train: loss: 0.4904001
[Epoch 11; Iter   610/ 1097] train: loss: 0.0620986
[Epoch 11; Iter   640/ 1097] train: loss: 0.0770625
[Epoch 11; Iter   670/ 1097] train: loss: 0.0303313
[Epoch 11; Iter   700/ 1097] train: loss: 0.2094672
[Epoch 11; Iter   730/ 1097] train: loss: 0.0993125
[Epoch 11; Iter   760/ 1097] train: loss: 0.1583053
[Epoch 11; Iter   790/ 1097] train: loss: 0.0436162
[Epoch 11; Iter   820/ 1097] train: loss: 0.1532955
[Epoch 11; Iter   850/ 1097] train: loss: 0.2271568
[Epoch 11; Iter   880/ 1097] train: loss: 0.0284405
[Epoch 11; Iter   910/ 1097] train: loss: 0.0314669
[Epoch 11; Iter   940/ 1097] train: loss: 0.1684207
[Epoch 11; Iter   970/ 1097] train: loss: 0.0247197
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0515315
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1811597
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2255497
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0458685
[Epoch 11] ogbg-molhiv: 0.789787 val loss: 0.083467
[Epoch 11] ogbg-molhiv: 0.768101 test loss: 0.124984
[Epoch 12; Iter    23/ 1097] train: loss: 0.1324822
[Epoch 12; Iter    53/ 1097] train: loss: 0.0261783
[Epoch 12; Iter    83/ 1097] train: loss: 0.0588398
[Epoch 8; Iter     1/ 1097] train: loss: 0.1561418
[Epoch 8; Iter    31/ 1097] train: loss: 0.0571051
[Epoch 8; Iter    61/ 1097] train: loss: 0.0828051
[Epoch 8; Iter    91/ 1097] train: loss: 0.0773991
[Epoch 8; Iter   121/ 1097] train: loss: 0.1118207
[Epoch 8; Iter   151/ 1097] train: loss: 0.0310402
[Epoch 8; Iter   181/ 1097] train: loss: 0.0480170
[Epoch 8; Iter   211/ 1097] train: loss: 0.0534206
[Epoch 8; Iter   241/ 1097] train: loss: 0.0318571
[Epoch 8; Iter   271/ 1097] train: loss: 0.1881698
[Epoch 8; Iter   301/ 1097] train: loss: 0.1993176
[Epoch 8; Iter   331/ 1097] train: loss: 0.1211940
[Epoch 8; Iter   361/ 1097] train: loss: 0.1403960
[Epoch 8; Iter   391/ 1097] train: loss: 0.0295182
[Epoch 8; Iter   421/ 1097] train: loss: 0.2704999
[Epoch 8; Iter   451/ 1097] train: loss: 0.1559974
[Epoch 8; Iter   481/ 1097] train: loss: 0.0519357
[Epoch 8; Iter   511/ 1097] train: loss: 0.0691852
[Epoch 8; Iter   541/ 1097] train: loss: 0.1432652
[Epoch 8; Iter   571/ 1097] train: loss: 0.1027000
[Epoch 8; Iter   601/ 1097] train: loss: 0.3802238
[Epoch 8; Iter   631/ 1097] train: loss: 0.0264527
[Epoch 8; Iter   661/ 1097] train: loss: 0.2383596
[Epoch 8; Iter   691/ 1097] train: loss: 0.1314813
[Epoch 8; Iter   721/ 1097] train: loss: 0.0768486
[Epoch 8; Iter   751/ 1097] train: loss: 0.1266273
[Epoch 8; Iter   781/ 1097] train: loss: 0.2096641
[Epoch 8; Iter   811/ 1097] train: loss: 0.2375679
[Epoch 8; Iter   841/ 1097] train: loss: 0.4159228
[Epoch 8; Iter   871/ 1097] train: loss: 0.1874473
[Epoch 8; Iter   901/ 1097] train: loss: 0.0248687
[Epoch 8; Iter   931/ 1097] train: loss: 0.1947478
[Epoch 8; Iter   961/ 1097] train: loss: 0.0373917
[Epoch 8; Iter   991/ 1097] train: loss: 0.1880254
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2879460
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0306607
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0999968
[Epoch 8] ogbg-molhiv: 0.763123 val loss: 0.135436
[Epoch 8] ogbg-molhiv: 0.738170 test loss: 0.126798
[Epoch 9; Iter    14/ 1097] train: loss: 0.2815258
[Epoch 9; Iter    44/ 1097] train: loss: 0.0319396
[Epoch 9; Iter    74/ 1097] train: loss: 0.0276980
[Epoch 9; Iter   104/ 1097] train: loss: 0.2589598
[Epoch 9; Iter   134/ 1097] train: loss: 0.0659293
[Epoch 9; Iter   164/ 1097] train: loss: 0.1496398
[Epoch 9; Iter   194/ 1097] train: loss: 0.1313744
[Epoch 9; Iter   224/ 1097] train: loss: 0.0349307
[Epoch 9; Iter   254/ 1097] train: loss: 0.3376476
[Epoch 9; Iter   284/ 1097] train: loss: 0.1886933
[Epoch 9; Iter   314/ 1097] train: loss: 0.1465816
[Epoch 9; Iter   344/ 1097] train: loss: 0.4883933
[Epoch 9; Iter   374/ 1097] train: loss: 0.1714616
[Epoch 9; Iter   404/ 1097] train: loss: 0.1650886
[Epoch 9; Iter   434/ 1097] train: loss: 0.0579293
[Epoch 9; Iter   464/ 1097] train: loss: 0.0338924
[Epoch 9; Iter   494/ 1097] train: loss: 0.1828466
[Epoch 9; Iter   524/ 1097] train: loss: 0.0361375
[Epoch 9; Iter   554/ 1097] train: loss: 0.0324933
[Epoch 9; Iter   584/ 1097] train: loss: 0.3922772
[Epoch 9; Iter   614/ 1097] train: loss: 0.0949961
[Epoch 9; Iter   644/ 1097] train: loss: 0.2675312
[Epoch 9; Iter   674/ 1097] train: loss: 0.4284544
[Epoch 9; Iter   704/ 1097] train: loss: 0.1266760
[Epoch 9; Iter   734/ 1097] train: loss: 0.0810247
[Epoch 9; Iter   764/ 1097] train: loss: 0.3032567
[Epoch 9; Iter   794/ 1097] train: loss: 0.1556526
[Epoch 9; Iter   824/ 1097] train: loss: 0.0346294
[Epoch 9; Iter   854/ 1097] train: loss: 0.0350394
[Epoch 9; Iter   884/ 1097] train: loss: 0.0852553
[Epoch 9; Iter   914/ 1097] train: loss: 0.1789938
[Epoch 9; Iter   944/ 1097] train: loss: 0.0568841
[Epoch 9; Iter   974/ 1097] train: loss: 0.0942788
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2272757
[Epoch 9; Iter  1034/ 1097] train: loss: 0.1881647
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3389817
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2511392
[Epoch 9] ogbg-molhiv: 0.720256 val loss: 0.093533
[Epoch 9] ogbg-molhiv: 0.690863 test loss: 0.128454
[Epoch 10; Iter    27/ 1097] train: loss: 0.0244735
[Epoch 10; Iter    57/ 1097] train: loss: 0.0357972
[Epoch 10; Iter    87/ 1097] train: loss: 0.0943131
[Epoch 10; Iter   117/ 1097] train: loss: 0.0330379
[Epoch 10; Iter   147/ 1097] train: loss: 0.3420310
[Epoch 10; Iter   177/ 1097] train: loss: 0.1758150
[Epoch 10; Iter   207/ 1097] train: loss: 0.1783347
[Epoch 10; Iter   237/ 1097] train: loss: 0.0511116
[Epoch 10; Iter   267/ 1097] train: loss: 0.0263211
[Epoch 10; Iter   297/ 1097] train: loss: 0.1917821
[Epoch 10; Iter   327/ 1097] train: loss: 0.0263925
[Epoch 10; Iter   357/ 1097] train: loss: 0.1965885
[Epoch 10; Iter   387/ 1097] train: loss: 0.1195852
[Epoch 10; Iter   417/ 1097] train: loss: 0.0834169
[Epoch 10; Iter   447/ 1097] train: loss: 0.1625558
[Epoch 10; Iter   477/ 1097] train: loss: 0.1488986
[Epoch 10; Iter   507/ 1097] train: loss: 0.1191232
[Epoch 10; Iter   537/ 1097] train: loss: 0.0299240
[Epoch 10; Iter   567/ 1097] train: loss: 0.0249613
[Epoch 10; Iter   597/ 1097] train: loss: 0.0279097
[Epoch 10; Iter   627/ 1097] train: loss: 0.2079461
[Epoch 10; Iter   657/ 1097] train: loss: 0.1444889
[Epoch 10; Iter   687/ 1097] train: loss: 0.0839473
[Epoch 10; Iter   717/ 1097] train: loss: 0.1461880
[Epoch 10; Iter   747/ 1097] train: loss: 0.2313752
[Epoch 10; Iter   777/ 1097] train: loss: 0.2175891
[Epoch 10; Iter   807/ 1097] train: loss: 0.0350972
[Epoch 10; Iter   837/ 1097] train: loss: 0.0299617
[Epoch 10; Iter   867/ 1097] train: loss: 0.0616658
[Epoch 10; Iter   897/ 1097] train: loss: 0.0358836
[Epoch 10; Iter   927/ 1097] train: loss: 0.1184034
[Epoch 10; Iter   957/ 1097] train: loss: 0.0441461
[Epoch 10; Iter   987/ 1097] train: loss: 0.2128975
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2685350
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1873122
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0270876
[Epoch 10] ogbg-molhiv: 0.771143 val loss: 0.112474
[Epoch 10] ogbg-molhiv: 0.733602 test loss: 0.202768
[Epoch 11; Iter    10/ 1097] train: loss: 0.3341604
[Epoch 11; Iter    40/ 1097] train: loss: 0.0463872
[Epoch 11; Iter    70/ 1097] train: loss: 0.1737138
[Epoch 11; Iter   100/ 1097] train: loss: 0.0251179
[Epoch 11; Iter   130/ 1097] train: loss: 0.1781622
[Epoch 11; Iter   160/ 1097] train: loss: 0.0481674
[Epoch 11; Iter   190/ 1097] train: loss: 0.1790628
[Epoch 11; Iter   220/ 1097] train: loss: 0.2979914
[Epoch 11; Iter   250/ 1097] train: loss: 0.2033711
[Epoch 11; Iter   280/ 1097] train: loss: 0.0546732
[Epoch 11; Iter   310/ 1097] train: loss: 0.2717842
[Epoch 11; Iter   340/ 1097] train: loss: 0.0370147
[Epoch 11; Iter   370/ 1097] train: loss: 0.1541619
[Epoch 11; Iter   400/ 1097] train: loss: 0.0523771
[Epoch 11; Iter   430/ 1097] train: loss: 0.2466715
[Epoch 11; Iter   460/ 1097] train: loss: 0.1156172
[Epoch 11; Iter   490/ 1097] train: loss: 0.2844618
[Epoch 11; Iter   520/ 1097] train: loss: 0.1881206
[Epoch 11; Iter   550/ 1097] train: loss: 0.0361178
[Epoch 11; Iter   580/ 1097] train: loss: 0.0608937
[Epoch 11; Iter   610/ 1097] train: loss: 0.0323319
[Epoch 11; Iter   640/ 1097] train: loss: 0.0344433
[Epoch 11; Iter   670/ 1097] train: loss: 0.1544988
[Epoch 11; Iter   700/ 1097] train: loss: 0.1635472
[Epoch 11; Iter   730/ 1097] train: loss: 0.0417636
[Epoch 11; Iter   760/ 1097] train: loss: 0.2648807
[Epoch 11; Iter   790/ 1097] train: loss: 0.1938781
[Epoch 11; Iter   820/ 1097] train: loss: 0.0724886
[Epoch 11; Iter   850/ 1097] train: loss: 0.0449157
[Epoch 11; Iter   880/ 1097] train: loss: 0.2671453
[Epoch 11; Iter   910/ 1097] train: loss: 0.2579772
[Epoch 11; Iter   940/ 1097] train: loss: 0.2338247
[Epoch 11; Iter   970/ 1097] train: loss: 0.2827731
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0511059
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0310992
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2133078
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4209577
[Epoch 11] ogbg-molhiv: 0.760558 val loss: 0.243305
[Epoch 11] ogbg-molhiv: 0.744717 test loss: 0.172215
[Epoch 12; Iter    23/ 1097] train: loss: 0.2329811
[Epoch 12; Iter    53/ 1097] train: loss: 0.0210844
[Epoch 12; Iter    83/ 1097] train: loss: 0.0354344
[Epoch 8; Iter     1/ 1097] train: loss: 0.1646492
[Epoch 8; Iter    31/ 1097] train: loss: 0.1945899
[Epoch 8; Iter    61/ 1097] train: loss: 0.3211876
[Epoch 8; Iter    91/ 1097] train: loss: 0.2704385
[Epoch 8; Iter   121/ 1097] train: loss: 0.0335326
[Epoch 8; Iter   151/ 1097] train: loss: 0.4717862
[Epoch 8; Iter   181/ 1097] train: loss: 0.1953399
[Epoch 8; Iter   211/ 1097] train: loss: 0.2379706
[Epoch 8; Iter   241/ 1097] train: loss: 0.0460604
[Epoch 8; Iter   271/ 1097] train: loss: 0.1674377
[Epoch 8; Iter   301/ 1097] train: loss: 0.0282826
[Epoch 8; Iter   331/ 1097] train: loss: 0.0492111
[Epoch 8; Iter   361/ 1097] train: loss: 0.1227383
[Epoch 8; Iter   391/ 1097] train: loss: 0.0859753
[Epoch 8; Iter   421/ 1097] train: loss: 0.2808959
[Epoch 8; Iter   451/ 1097] train: loss: 0.0290515
[Epoch 8; Iter   481/ 1097] train: loss: 0.1727787
[Epoch 8; Iter   511/ 1097] train: loss: 0.1440123
[Epoch 8; Iter   541/ 1097] train: loss: 0.0374035
[Epoch 8; Iter   571/ 1097] train: loss: 0.3376544
[Epoch 8; Iter   601/ 1097] train: loss: 0.1293564
[Epoch 8; Iter   631/ 1097] train: loss: 0.0637587
[Epoch 8; Iter   661/ 1097] train: loss: 0.0378239
[Epoch 8; Iter   691/ 1097] train: loss: 0.1506433
[Epoch 8; Iter   721/ 1097] train: loss: 0.0826033
[Epoch 8; Iter   751/ 1097] train: loss: 0.0314293
[Epoch 8; Iter   781/ 1097] train: loss: 0.2677721
[Epoch 8; Iter   811/ 1097] train: loss: 0.1183493
[Epoch 8; Iter   841/ 1097] train: loss: 0.0501150
[Epoch 8; Iter   871/ 1097] train: loss: 0.1573457
[Epoch 8; Iter   901/ 1097] train: loss: 0.0266846
[Epoch 8; Iter   931/ 1097] train: loss: 0.0726533
[Epoch 8; Iter   961/ 1097] train: loss: 0.0421582
[Epoch 8; Iter   991/ 1097] train: loss: 0.0348857
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0213683
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0188463
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1053975
[Epoch 8] ogbg-molhiv: 0.787683 val loss: 0.077683
[Epoch 8] ogbg-molhiv: 0.738114 test loss: 0.119909
[Epoch 9; Iter    14/ 1097] train: loss: 0.0287755
[Epoch 9; Iter    44/ 1097] train: loss: 0.0474804
[Epoch 9; Iter    74/ 1097] train: loss: 0.1460870
[Epoch 9; Iter   104/ 1097] train: loss: 0.3589925
[Epoch 9; Iter   134/ 1097] train: loss: 0.2350814
[Epoch 9; Iter   164/ 1097] train: loss: 0.0347490
[Epoch 9; Iter   194/ 1097] train: loss: 0.0500840
[Epoch 9; Iter   224/ 1097] train: loss: 0.0260861
[Epoch 9; Iter   254/ 1097] train: loss: 0.0817019
[Epoch 9; Iter   284/ 1097] train: loss: 0.0370638
[Epoch 9; Iter   314/ 1097] train: loss: 0.0362522
[Epoch 9; Iter   344/ 1097] train: loss: 0.0515574
[Epoch 9; Iter   374/ 1097] train: loss: 0.0319114
[Epoch 9; Iter   404/ 1097] train: loss: 0.0792609
[Epoch 9; Iter   434/ 1097] train: loss: 0.1694077
[Epoch 9; Iter   464/ 1097] train: loss: 0.2446744
[Epoch 9; Iter   494/ 1097] train: loss: 0.0993657
[Epoch 9; Iter   524/ 1097] train: loss: 0.0954256
[Epoch 9; Iter   554/ 1097] train: loss: 0.0396472
[Epoch 9; Iter   584/ 1097] train: loss: 0.2073629
[Epoch 9; Iter   614/ 1097] train: loss: 0.0314599
[Epoch 9; Iter   644/ 1097] train: loss: 0.1900363
[Epoch 9; Iter   674/ 1097] train: loss: 0.0731141
[Epoch 9; Iter   704/ 1097] train: loss: 0.0313374
[Epoch 9; Iter   734/ 1097] train: loss: 0.1240491
[Epoch 9; Iter   764/ 1097] train: loss: 0.1276877
[Epoch 9; Iter   794/ 1097] train: loss: 0.0380578
[Epoch 9; Iter   824/ 1097] train: loss: 0.0421925
[Epoch 9; Iter   854/ 1097] train: loss: 0.0438569
[Epoch 9; Iter   884/ 1097] train: loss: 0.2266032
[Epoch 9; Iter   914/ 1097] train: loss: 0.0285821
[Epoch 9; Iter   944/ 1097] train: loss: 0.1573545
[Epoch 9; Iter   974/ 1097] train: loss: 0.0399750
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1564793
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0928541
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0717870
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0569099
[Epoch 9] ogbg-molhiv: 0.672689 val loss: 0.151247
[Epoch 9] ogbg-molhiv: 0.672562 test loss: 0.199459
[Epoch 10; Iter    27/ 1097] train: loss: 0.1631152
[Epoch 10; Iter    57/ 1097] train: loss: 0.0351058
[Epoch 10; Iter    87/ 1097] train: loss: 0.2157720
[Epoch 10; Iter   117/ 1097] train: loss: 0.0583571
[Epoch 10; Iter   147/ 1097] train: loss: 0.0304115
[Epoch 10; Iter   177/ 1097] train: loss: 0.0351758
[Epoch 10; Iter   207/ 1097] train: loss: 0.0336583
[Epoch 10; Iter   237/ 1097] train: loss: 0.0776523
[Epoch 10; Iter   267/ 1097] train: loss: 0.0259045
[Epoch 10; Iter   297/ 1097] train: loss: 0.0297883
[Epoch 10; Iter   327/ 1097] train: loss: 0.0427307
[Epoch 10; Iter   357/ 1097] train: loss: 0.1153639
[Epoch 10; Iter   387/ 1097] train: loss: 0.1706926
[Epoch 10; Iter   417/ 1097] train: loss: 0.0326355
[Epoch 10; Iter   447/ 1097] train: loss: 0.0409275
[Epoch 10; Iter   477/ 1097] train: loss: 0.0440390
[Epoch 10; Iter   507/ 1097] train: loss: 0.0823555
[Epoch 10; Iter   537/ 1097] train: loss: 0.0478237
[Epoch 10; Iter   567/ 1097] train: loss: 0.1407440
[Epoch 10; Iter   597/ 1097] train: loss: 0.1976954
[Epoch 10; Iter   627/ 1097] train: loss: 0.2127136
[Epoch 10; Iter   657/ 1097] train: loss: 0.0275717
[Epoch 10; Iter   687/ 1097] train: loss: 0.2451137
[Epoch 10; Iter   717/ 1097] train: loss: 0.0725348
[Epoch 10; Iter   747/ 1097] train: loss: 0.2499896
[Epoch 10; Iter   777/ 1097] train: loss: 0.0941349
[Epoch 10; Iter   807/ 1097] train: loss: 0.0520964
[Epoch 10; Iter   837/ 1097] train: loss: 0.0374742
[Epoch 10; Iter   867/ 1097] train: loss: 0.3715848
[Epoch 10; Iter   897/ 1097] train: loss: 0.2079677
[Epoch 10; Iter   927/ 1097] train: loss: 0.4606486
[Epoch 10; Iter   957/ 1097] train: loss: 0.2452941
[Epoch 10; Iter   987/ 1097] train: loss: 0.1738020
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0735807
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0998698
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1501786
[Epoch 10] ogbg-molhiv: 0.746301 val loss: 0.127984
[Epoch 10] ogbg-molhiv: 0.780282 test loss: 0.140108
[Epoch 11; Iter    10/ 1097] train: loss: 0.0506129
[Epoch 11; Iter    40/ 1097] train: loss: 0.0386810
[Epoch 11; Iter    70/ 1097] train: loss: 0.0458473
[Epoch 11; Iter   100/ 1097] train: loss: 0.1620392
[Epoch 11; Iter   130/ 1097] train: loss: 0.0574306
[Epoch 11; Iter   160/ 1097] train: loss: 0.0443382
[Epoch 11; Iter   190/ 1097] train: loss: 0.1005051
[Epoch 11; Iter   220/ 1097] train: loss: 0.0503577
[Epoch 11; Iter   250/ 1097] train: loss: 0.1615194
[Epoch 11; Iter   280/ 1097] train: loss: 0.2066409
[Epoch 11; Iter   310/ 1097] train: loss: 0.1174572
[Epoch 11; Iter   340/ 1097] train: loss: 0.0691390
[Epoch 11; Iter   370/ 1097] train: loss: 0.2569456
[Epoch 11; Iter   400/ 1097] train: loss: 0.0598129
[Epoch 11; Iter   430/ 1097] train: loss: 0.1364007
[Epoch 11; Iter   460/ 1097] train: loss: 0.1318507
[Epoch 11; Iter   490/ 1097] train: loss: 0.1855164
[Epoch 11; Iter   520/ 1097] train: loss: 0.4747731
[Epoch 11; Iter   550/ 1097] train: loss: 0.1956659
[Epoch 11; Iter   580/ 1097] train: loss: 0.1243393
[Epoch 11; Iter   610/ 1097] train: loss: 0.0284214
[Epoch 11; Iter   640/ 1097] train: loss: 0.0430645
[Epoch 11; Iter   670/ 1097] train: loss: 0.0361960
[Epoch 11; Iter   700/ 1097] train: loss: 0.0385257
[Epoch 11; Iter   730/ 1097] train: loss: 0.1801848
[Epoch 11; Iter   760/ 1097] train: loss: 0.0548382
[Epoch 11; Iter   790/ 1097] train: loss: 0.0368235
[Epoch 11; Iter   820/ 1097] train: loss: 0.3509012
[Epoch 11; Iter   850/ 1097] train: loss: 0.1771920
[Epoch 11; Iter   880/ 1097] train: loss: 0.0350476
[Epoch 11; Iter   910/ 1097] train: loss: 0.2089911
[Epoch 11; Iter   940/ 1097] train: loss: 0.2739056
[Epoch 11; Iter   970/ 1097] train: loss: 0.1452879
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0883366
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0976322
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2738219
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3284417
[Epoch 11] ogbg-molhiv: 0.777429 val loss: 0.077754
[Epoch 11] ogbg-molhiv: 0.758919 test loss: 0.116981
[Epoch 12; Iter    23/ 1097] train: loss: 0.0998096
[Epoch 12; Iter    53/ 1097] train: loss: 0.0297810
[Epoch 12; Iter    83/ 1097] train: loss: 0.0357165
[Epoch 8; Iter     1/ 1097] train: loss: 0.1798164
[Epoch 8; Iter    31/ 1097] train: loss: 0.0344340
[Epoch 8; Iter    61/ 1097] train: loss: 0.1784672
[Epoch 8; Iter    91/ 1097] train: loss: 0.1774585
[Epoch 8; Iter   121/ 1097] train: loss: 0.0443122
[Epoch 8; Iter   151/ 1097] train: loss: 0.1061374
[Epoch 8; Iter   181/ 1097] train: loss: 0.0314419
[Epoch 8; Iter   211/ 1097] train: loss: 0.3477791
[Epoch 8; Iter   241/ 1097] train: loss: 0.1277117
[Epoch 8; Iter   271/ 1097] train: loss: 0.2317816
[Epoch 8; Iter   301/ 1097] train: loss: 0.0649065
[Epoch 8; Iter   331/ 1097] train: loss: 0.1386730
[Epoch 8; Iter   361/ 1097] train: loss: 0.0543005
[Epoch 8; Iter   391/ 1097] train: loss: 0.0400410
[Epoch 8; Iter   421/ 1097] train: loss: 0.2364322
[Epoch 8; Iter   451/ 1097] train: loss: 0.0344915
[Epoch 8; Iter   481/ 1097] train: loss: 0.1887665
[Epoch 8; Iter   511/ 1097] train: loss: 0.1601187
[Epoch 8; Iter   541/ 1097] train: loss: 0.0371611
[Epoch 8; Iter   571/ 1097] train: loss: 0.0360887
[Epoch 8; Iter   601/ 1097] train: loss: 0.0361913
[Epoch 8; Iter   631/ 1097] train: loss: 0.1207055
[Epoch 8; Iter   661/ 1097] train: loss: 0.0421614
[Epoch 8; Iter   691/ 1097] train: loss: 0.3534499
[Epoch 8; Iter   721/ 1097] train: loss: 0.0386864
[Epoch 8; Iter   751/ 1097] train: loss: 0.0799913
[Epoch 8; Iter   781/ 1097] train: loss: 0.0353176
[Epoch 8; Iter   811/ 1097] train: loss: 0.0454971
[Epoch 8; Iter   841/ 1097] train: loss: 0.1441997
[Epoch 8; Iter   871/ 1097] train: loss: 0.3076995
[Epoch 8; Iter   901/ 1097] train: loss: 0.0390713
[Epoch 8; Iter   931/ 1097] train: loss: 0.1848111
[Epoch 8; Iter   961/ 1097] train: loss: 0.0314757
[Epoch 8; Iter   991/ 1097] train: loss: 0.0422675
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0361579
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0312903
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3818438
[Epoch 8] ogbg-molhiv: 0.740226 val loss: 0.094908
[Epoch 8] ogbg-molhiv: 0.724607 test loss: 0.177610
[Epoch 9; Iter    14/ 1097] train: loss: 0.0533824
[Epoch 9; Iter    44/ 1097] train: loss: 0.0617684
[Epoch 9; Iter    74/ 1097] train: loss: 0.0630009
[Epoch 9; Iter   104/ 1097] train: loss: 0.0502946
[Epoch 9; Iter   134/ 1097] train: loss: 0.0717298
[Epoch 9; Iter   164/ 1097] train: loss: 0.0320870
[Epoch 9; Iter   194/ 1097] train: loss: 0.0421603
[Epoch 9; Iter   224/ 1097] train: loss: 0.3183044
[Epoch 9; Iter   254/ 1097] train: loss: 0.1644184
[Epoch 9; Iter   284/ 1097] train: loss: 0.1474455
[Epoch 9; Iter   314/ 1097] train: loss: 0.2400805
[Epoch 9; Iter   344/ 1097] train: loss: 0.0301133
[Epoch 9; Iter   374/ 1097] train: loss: 0.1544840
[Epoch 9; Iter   404/ 1097] train: loss: 0.1423247
[Epoch 9; Iter   434/ 1097] train: loss: 0.1227746
[Epoch 9; Iter   464/ 1097] train: loss: 0.0382616
[Epoch 9; Iter   494/ 1097] train: loss: 0.1084735
[Epoch 9; Iter   524/ 1097] train: loss: 0.0337617
[Epoch 9; Iter   554/ 1097] train: loss: 0.0623910
[Epoch 9; Iter   584/ 1097] train: loss: 0.0669606
[Epoch 9; Iter   614/ 1097] train: loss: 0.0422980
[Epoch 9; Iter   644/ 1097] train: loss: 0.1228099
[Epoch 9; Iter   674/ 1097] train: loss: 0.1830495
[Epoch 9; Iter   704/ 1097] train: loss: 0.0288096
[Epoch 9; Iter   734/ 1097] train: loss: 0.0426855
[Epoch 9; Iter   764/ 1097] train: loss: 0.1126727
[Epoch 9; Iter   794/ 1097] train: loss: 0.0386020
[Epoch 9; Iter   824/ 1097] train: loss: 0.0248398
[Epoch 9; Iter   854/ 1097] train: loss: 0.0292134
[Epoch 9; Iter   884/ 1097] train: loss: 0.2818652
[Epoch 9; Iter   914/ 1097] train: loss: 0.0531269
[Epoch 9; Iter   944/ 1097] train: loss: 0.2281417
[Epoch 9; Iter   974/ 1097] train: loss: 0.0375109
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0529316
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0347271
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2638489
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0339217
[Epoch 9] ogbg-molhiv: 0.747250 val loss: 0.082507
[Epoch 9] ogbg-molhiv: 0.728345 test loss: 0.131753
[Epoch 10; Iter    27/ 1097] train: loss: 0.2332961
[Epoch 10; Iter    57/ 1097] train: loss: 0.3351637
[Epoch 10; Iter    87/ 1097] train: loss: 0.0369755
[Epoch 10; Iter   117/ 1097] train: loss: 0.1611223
[Epoch 10; Iter   147/ 1097] train: loss: 0.0405911
[Epoch 10; Iter   177/ 1097] train: loss: 0.5428764
[Epoch 10; Iter   207/ 1097] train: loss: 0.0730021
[Epoch 10; Iter   237/ 1097] train: loss: 0.0316692
[Epoch 10; Iter   267/ 1097] train: loss: 0.1129353
[Epoch 10; Iter   297/ 1097] train: loss: 0.2834984
[Epoch 10; Iter   327/ 1097] train: loss: 0.2209574
[Epoch 10; Iter   357/ 1097] train: loss: 0.0455799
[Epoch 10; Iter   387/ 1097] train: loss: 0.1197209
[Epoch 10; Iter   417/ 1097] train: loss: 0.2882269
[Epoch 10; Iter   447/ 1097] train: loss: 0.1436318
[Epoch 10; Iter   477/ 1097] train: loss: 0.0359294
[Epoch 10; Iter   507/ 1097] train: loss: 0.0261438
[Epoch 10; Iter   537/ 1097] train: loss: 0.1976416
[Epoch 10; Iter   567/ 1097] train: loss: 0.1659859
[Epoch 10; Iter   597/ 1097] train: loss: 0.1394358
[Epoch 10; Iter   627/ 1097] train: loss: 0.0690570
[Epoch 10; Iter   657/ 1097] train: loss: 0.2794583
[Epoch 10; Iter   687/ 1097] train: loss: 0.1441932
[Epoch 10; Iter   717/ 1097] train: loss: 0.2702337
[Epoch 10; Iter   747/ 1097] train: loss: 0.0293045
[Epoch 10; Iter   777/ 1097] train: loss: 0.0230924
[Epoch 10; Iter   807/ 1097] train: loss: 0.3573877
[Epoch 10; Iter   837/ 1097] train: loss: 0.0478761
[Epoch 10; Iter   867/ 1097] train: loss: 0.0362028
[Epoch 10; Iter   897/ 1097] train: loss: 0.0825283
[Epoch 10; Iter   927/ 1097] train: loss: 0.1995420
[Epoch 10; Iter   957/ 1097] train: loss: 0.1369630
[Epoch 10; Iter   987/ 1097] train: loss: 0.5812089
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0278519
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0933657
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2281477
[Epoch 10] ogbg-molhiv: 0.781192 val loss: 0.081764
[Epoch 10] ogbg-molhiv: 0.774041 test loss: 0.114478
[Epoch 11; Iter    10/ 1097] train: loss: 0.3088205
[Epoch 11; Iter    40/ 1097] train: loss: 0.1511299
[Epoch 11; Iter    70/ 1097] train: loss: 0.1292038
[Epoch 11; Iter   100/ 1097] train: loss: 0.0886885
[Epoch 11; Iter   130/ 1097] train: loss: 0.1953462
[Epoch 11; Iter   160/ 1097] train: loss: 0.1650956
[Epoch 11; Iter   190/ 1097] train: loss: 0.0245969
[Epoch 11; Iter   220/ 1097] train: loss: 0.2497959
[Epoch 11; Iter   250/ 1097] train: loss: 0.0570628
[Epoch 11; Iter   280/ 1097] train: loss: 0.1485527
[Epoch 11; Iter   310/ 1097] train: loss: 0.1750152
[Epoch 11; Iter   340/ 1097] train: loss: 0.0397995
[Epoch 11; Iter   370/ 1097] train: loss: 0.0350106
[Epoch 11; Iter   400/ 1097] train: loss: 0.2240707
[Epoch 11; Iter   430/ 1097] train: loss: 0.0585704
[Epoch 11; Iter   460/ 1097] train: loss: 0.1138005
[Epoch 11; Iter   490/ 1097] train: loss: 0.3068388
[Epoch 11; Iter   520/ 1097] train: loss: 0.1563892
[Epoch 11; Iter   550/ 1097] train: loss: 0.0253396
[Epoch 11; Iter   580/ 1097] train: loss: 0.5281323
[Epoch 11; Iter   610/ 1097] train: loss: 0.1890974
[Epoch 11; Iter   640/ 1097] train: loss: 0.0471581
[Epoch 11; Iter   670/ 1097] train: loss: 0.0282882
[Epoch 11; Iter   700/ 1097] train: loss: 0.1801572
[Epoch 11; Iter   730/ 1097] train: loss: 0.3162754
[Epoch 11; Iter   760/ 1097] train: loss: 0.1229163
[Epoch 11; Iter   790/ 1097] train: loss: 0.1554161
[Epoch 11; Iter   820/ 1097] train: loss: 0.0925605
[Epoch 11; Iter   850/ 1097] train: loss: 0.1954407
[Epoch 11; Iter   880/ 1097] train: loss: 0.0352872
[Epoch 11; Iter   910/ 1097] train: loss: 0.0437199
[Epoch 11; Iter   940/ 1097] train: loss: 0.1601559
[Epoch 11; Iter   970/ 1097] train: loss: 0.0306768
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0560400
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1995441
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1873784
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0377644
[Epoch 11] ogbg-molhiv: 0.769174 val loss: 0.081033
[Epoch 11] ogbg-molhiv: 0.764333 test loss: 0.117319
[Epoch 12; Iter    23/ 1097] train: loss: 0.2416158
[Epoch 12; Iter    53/ 1097] train: loss: 0.0360999
[Epoch 12; Iter    83/ 1097] train: loss: 0.0742641
[Epoch 8; Iter     1/ 1097] train: loss: 0.2215589
[Epoch 8; Iter    31/ 1097] train: loss: 0.0572163
[Epoch 8; Iter    61/ 1097] train: loss: 0.0721594
[Epoch 8; Iter    91/ 1097] train: loss: 0.1765530
[Epoch 8; Iter   121/ 1097] train: loss: 0.2094089
[Epoch 8; Iter   151/ 1097] train: loss: 0.0312365
[Epoch 8; Iter   181/ 1097] train: loss: 0.0364002
[Epoch 8; Iter   211/ 1097] train: loss: 0.0416203
[Epoch 8; Iter   241/ 1097] train: loss: 0.0301347
[Epoch 8; Iter   271/ 1097] train: loss: 0.1876682
[Epoch 8; Iter   301/ 1097] train: loss: 0.2167094
[Epoch 8; Iter   331/ 1097] train: loss: 0.1153228
[Epoch 8; Iter   361/ 1097] train: loss: 0.1725522
[Epoch 8; Iter   391/ 1097] train: loss: 0.0233382
[Epoch 8; Iter   421/ 1097] train: loss: 0.3269128
[Epoch 8; Iter   451/ 1097] train: loss: 0.1884172
[Epoch 8; Iter   481/ 1097] train: loss: 0.0414407
[Epoch 8; Iter   511/ 1097] train: loss: 0.1542827
[Epoch 8; Iter   541/ 1097] train: loss: 0.1424899
[Epoch 8; Iter   571/ 1097] train: loss: 0.1206814
[Epoch 8; Iter   601/ 1097] train: loss: 0.4045155
[Epoch 8; Iter   631/ 1097] train: loss: 0.0372966
[Epoch 8; Iter   661/ 1097] train: loss: 0.2564723
[Epoch 8; Iter   691/ 1097] train: loss: 0.0730486
[Epoch 8; Iter   721/ 1097] train: loss: 0.0746812
[Epoch 8; Iter   751/ 1097] train: loss: 0.1263124
[Epoch 8; Iter   781/ 1097] train: loss: 0.1931172
[Epoch 8; Iter   811/ 1097] train: loss: 0.2257978
[Epoch 8; Iter   841/ 1097] train: loss: 0.3499181
[Epoch 8; Iter   871/ 1097] train: loss: 0.2063620
[Epoch 8; Iter   901/ 1097] train: loss: 0.0290958
[Epoch 8; Iter   931/ 1097] train: loss: 0.2281671
[Epoch 8; Iter   961/ 1097] train: loss: 0.0429529
[Epoch 8; Iter   991/ 1097] train: loss: 0.1429450
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3022194
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0333290
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0964489
[Epoch 8] ogbg-molhiv: 0.791719 val loss: 0.083815
[Epoch 8] ogbg-molhiv: 0.748043 test loss: 0.124301
[Epoch 9; Iter    14/ 1097] train: loss: 0.2382515
[Epoch 9; Iter    44/ 1097] train: loss: 0.0306681
[Epoch 9; Iter    74/ 1097] train: loss: 0.0283376
[Epoch 9; Iter   104/ 1097] train: loss: 0.2747804
[Epoch 9; Iter   134/ 1097] train: loss: 0.1260818
[Epoch 9; Iter   164/ 1097] train: loss: 0.1223128
[Epoch 9; Iter   194/ 1097] train: loss: 0.0776710
[Epoch 9; Iter   224/ 1097] train: loss: 0.0301636
[Epoch 9; Iter   254/ 1097] train: loss: 0.3546416
[Epoch 9; Iter   284/ 1097] train: loss: 0.2001055
[Epoch 9; Iter   314/ 1097] train: loss: 0.1759552
[Epoch 9; Iter   344/ 1097] train: loss: 0.5016360
[Epoch 9; Iter   374/ 1097] train: loss: 0.1897971
[Epoch 9; Iter   404/ 1097] train: loss: 0.1945356
[Epoch 9; Iter   434/ 1097] train: loss: 0.0555580
[Epoch 9; Iter   464/ 1097] train: loss: 0.0464603
[Epoch 9; Iter   494/ 1097] train: loss: 0.1859778
[Epoch 9; Iter   524/ 1097] train: loss: 0.0275430
[Epoch 9; Iter   554/ 1097] train: loss: 0.0551020
[Epoch 9; Iter   584/ 1097] train: loss: 0.4976837
[Epoch 9; Iter   614/ 1097] train: loss: 0.1278297
[Epoch 9; Iter   644/ 1097] train: loss: 0.3670096
[Epoch 9; Iter   674/ 1097] train: loss: 0.4047802
[Epoch 9; Iter   704/ 1097] train: loss: 0.1225272
[Epoch 9; Iter   734/ 1097] train: loss: 0.0819243
[Epoch 9; Iter   764/ 1097] train: loss: 0.2206014
[Epoch 9; Iter   794/ 1097] train: loss: 0.1837370
[Epoch 9; Iter   824/ 1097] train: loss: 0.0371332
[Epoch 9; Iter   854/ 1097] train: loss: 0.0310238
[Epoch 9; Iter   884/ 1097] train: loss: 0.1241468
[Epoch 9; Iter   914/ 1097] train: loss: 0.1899429
[Epoch 9; Iter   944/ 1097] train: loss: 0.0498360
[Epoch 9; Iter   974/ 1097] train: loss: 0.1101533
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1870313
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2488757
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3580260
[Epoch 9; Iter  1094/ 1097] train: loss: 0.3337102
[Epoch 9] ogbg-molhiv: 0.765527 val loss: 0.227362
[Epoch 9] ogbg-molhiv: 0.728832 test loss: 0.145668
[Epoch 10; Iter    27/ 1097] train: loss: 0.0297110
[Epoch 10; Iter    57/ 1097] train: loss: 0.0310925
[Epoch 10; Iter    87/ 1097] train: loss: 0.1452676
[Epoch 10; Iter   117/ 1097] train: loss: 0.0356967
[Epoch 10; Iter   147/ 1097] train: loss: 0.4101246
[Epoch 10; Iter   177/ 1097] train: loss: 0.1862191
[Epoch 10; Iter   207/ 1097] train: loss: 0.2382160
[Epoch 10; Iter   237/ 1097] train: loss: 0.0389544
[Epoch 10; Iter   267/ 1097] train: loss: 0.0316996
[Epoch 10; Iter   297/ 1097] train: loss: 0.2103702
[Epoch 10; Iter   327/ 1097] train: loss: 0.0293919
[Epoch 10; Iter   357/ 1097] train: loss: 0.1966579
[Epoch 10; Iter   387/ 1097] train: loss: 0.1358210
[Epoch 10; Iter   417/ 1097] train: loss: 0.0624101
[Epoch 10; Iter   447/ 1097] train: loss: 0.1655365
[Epoch 10; Iter   477/ 1097] train: loss: 0.1759824
[Epoch 10; Iter   507/ 1097] train: loss: 0.1343636
[Epoch 10; Iter   537/ 1097] train: loss: 0.0278246
[Epoch 10; Iter   567/ 1097] train: loss: 0.0346745
[Epoch 10; Iter   597/ 1097] train: loss: 0.0458152
[Epoch 10; Iter   627/ 1097] train: loss: 0.2097941
[Epoch 10; Iter   657/ 1097] train: loss: 0.1697769
[Epoch 10; Iter   687/ 1097] train: loss: 0.0576880
[Epoch 10; Iter   717/ 1097] train: loss: 0.1375688
[Epoch 10; Iter   747/ 1097] train: loss: 0.2708811
[Epoch 10; Iter   777/ 1097] train: loss: 0.2282048
[Epoch 10; Iter   807/ 1097] train: loss: 0.0313945
[Epoch 10; Iter   837/ 1097] train: loss: 0.0359556
[Epoch 10; Iter   867/ 1097] train: loss: 0.0712692
[Epoch 10; Iter   897/ 1097] train: loss: 0.0344470
[Epoch 10; Iter   927/ 1097] train: loss: 0.1723312
[Epoch 10; Iter   957/ 1097] train: loss: 0.0422878
[Epoch 10; Iter   987/ 1097] train: loss: 0.2051869
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2282624
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1167630
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0471685
[Epoch 10] ogbg-molhiv: 0.772674 val loss: 0.089857
[Epoch 10] ogbg-molhiv: 0.727106 test loss: 0.124094
[Epoch 11; Iter    10/ 1097] train: loss: 0.2989167
[Epoch 11; Iter    40/ 1097] train: loss: 0.0368591
[Epoch 11; Iter    70/ 1097] train: loss: 0.1517272
[Epoch 11; Iter   100/ 1097] train: loss: 0.0250044
[Epoch 11; Iter   130/ 1097] train: loss: 0.1766720
[Epoch 11; Iter   160/ 1097] train: loss: 0.0327692
[Epoch 11; Iter   190/ 1097] train: loss: 0.2477103
[Epoch 11; Iter   220/ 1097] train: loss: 0.2837945
[Epoch 11; Iter   250/ 1097] train: loss: 0.1723079
[Epoch 11; Iter   280/ 1097] train: loss: 0.0455859
[Epoch 11; Iter   310/ 1097] train: loss: 0.2172738
[Epoch 11; Iter   340/ 1097] train: loss: 0.0354590
[Epoch 11; Iter   370/ 1097] train: loss: 0.1042388
[Epoch 11; Iter   400/ 1097] train: loss: 0.0696160
[Epoch 11; Iter   430/ 1097] train: loss: 0.2578448
[Epoch 11; Iter   460/ 1097] train: loss: 0.1414088
[Epoch 11; Iter   490/ 1097] train: loss: 0.2151434
[Epoch 11; Iter   520/ 1097] train: loss: 0.1912259
[Epoch 11; Iter   550/ 1097] train: loss: 0.0271356
[Epoch 11; Iter   580/ 1097] train: loss: 0.0617892
[Epoch 11; Iter   610/ 1097] train: loss: 0.0268368
[Epoch 11; Iter   640/ 1097] train: loss: 0.0306555
[Epoch 11; Iter   670/ 1097] train: loss: 0.1862024
[Epoch 11; Iter   700/ 1097] train: loss: 0.1130043
[Epoch 11; Iter   730/ 1097] train: loss: 0.0414475
[Epoch 11; Iter   760/ 1097] train: loss: 0.2196708
[Epoch 11; Iter   790/ 1097] train: loss: 0.1942838
[Epoch 11; Iter   820/ 1097] train: loss: 0.0724096
[Epoch 11; Iter   850/ 1097] train: loss: 0.0383129
[Epoch 11; Iter   880/ 1097] train: loss: 0.2891295
[Epoch 11; Iter   910/ 1097] train: loss: 0.2819932
[Epoch 11; Iter   940/ 1097] train: loss: 0.2796837
[Epoch 11; Iter   970/ 1097] train: loss: 0.2861341
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0440739
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0232262
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2431729
[Epoch 11; Iter  1090/ 1097] train: loss: 0.5107096
[Epoch 11] ogbg-molhiv: 0.782695 val loss: 0.403118
[Epoch 11] ogbg-molhiv: 0.711385 test loss: 0.690635
[Epoch 12; Iter    23/ 1097] train: loss: 0.1993928
[Epoch 12; Iter    53/ 1097] train: loss: 0.0402498
[Epoch 12; Iter    83/ 1097] train: loss: 0.0370722
[Epoch 8; Iter     1/ 1097] train: loss: 0.1364762
[Epoch 8; Iter    31/ 1097] train: loss: 0.1776775
[Epoch 8; Iter    61/ 1097] train: loss: 0.3404725
[Epoch 8; Iter    91/ 1097] train: loss: 0.3303644
[Epoch 8; Iter   121/ 1097] train: loss: 0.0358091
[Epoch 8; Iter   151/ 1097] train: loss: 0.4387432
[Epoch 8; Iter   181/ 1097] train: loss: 0.1892061
[Epoch 8; Iter   211/ 1097] train: loss: 0.1950769
[Epoch 8; Iter   241/ 1097] train: loss: 0.0372390
[Epoch 8; Iter   271/ 1097] train: loss: 0.1629386
[Epoch 8; Iter   301/ 1097] train: loss: 0.0274106
[Epoch 8; Iter   331/ 1097] train: loss: 0.0279619
[Epoch 8; Iter   361/ 1097] train: loss: 0.1119976
[Epoch 8; Iter   391/ 1097] train: loss: 0.0616780
[Epoch 8; Iter   421/ 1097] train: loss: 0.3238775
[Epoch 8; Iter   451/ 1097] train: loss: 0.0365059
[Epoch 8; Iter   481/ 1097] train: loss: 0.0917958
[Epoch 8; Iter   511/ 1097] train: loss: 0.1308137
[Epoch 8; Iter   541/ 1097] train: loss: 0.0372452
[Epoch 8; Iter   571/ 1097] train: loss: 0.4435521
[Epoch 8; Iter   601/ 1097] train: loss: 0.1187689
[Epoch 8; Iter   631/ 1097] train: loss: 0.1036771
[Epoch 8; Iter   661/ 1097] train: loss: 0.0395500
[Epoch 8; Iter   691/ 1097] train: loss: 0.1907076
[Epoch 8; Iter   721/ 1097] train: loss: 0.0955882
[Epoch 8; Iter   751/ 1097] train: loss: 0.0351700
[Epoch 8; Iter   781/ 1097] train: loss: 0.2071650
[Epoch 8; Iter   811/ 1097] train: loss: 0.0868537
[Epoch 8; Iter   841/ 1097] train: loss: 0.0759659
[Epoch 8; Iter   871/ 1097] train: loss: 0.1705462
[Epoch 8; Iter   901/ 1097] train: loss: 0.0289270
[Epoch 8; Iter   931/ 1097] train: loss: 0.0709453
[Epoch 8; Iter   961/ 1097] train: loss: 0.0520361
[Epoch 8; Iter   991/ 1097] train: loss: 0.0346798
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0291571
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0222432
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1208734
[Epoch 8] ogbg-molhiv: 0.768222 val loss: 0.083947
[Epoch 8] ogbg-molhiv: 0.715789 test loss: 0.166796
[Epoch 9; Iter    14/ 1097] train: loss: 0.0262758
[Epoch 9; Iter    44/ 1097] train: loss: 0.0457047
[Epoch 9; Iter    74/ 1097] train: loss: 0.1585141
[Epoch 9; Iter   104/ 1097] train: loss: 0.4299810
[Epoch 9; Iter   134/ 1097] train: loss: 0.2177251
[Epoch 9; Iter   164/ 1097] train: loss: 0.0344642
[Epoch 9; Iter   194/ 1097] train: loss: 0.0562261
[Epoch 9; Iter   224/ 1097] train: loss: 0.0283707
[Epoch 9; Iter   254/ 1097] train: loss: 0.1512624
[Epoch 9; Iter   284/ 1097] train: loss: 0.0404562
[Epoch 9; Iter   314/ 1097] train: loss: 0.0322815
[Epoch 9; Iter   344/ 1097] train: loss: 0.0597605
[Epoch 9; Iter   374/ 1097] train: loss: 0.0329651
[Epoch 9; Iter   404/ 1097] train: loss: 0.1201579
[Epoch 9; Iter   434/ 1097] train: loss: 0.1726180
[Epoch 9; Iter   464/ 1097] train: loss: 0.2197829
[Epoch 9; Iter   494/ 1097] train: loss: 0.0963400
[Epoch 9; Iter   524/ 1097] train: loss: 0.0678427
[Epoch 9; Iter   554/ 1097] train: loss: 0.0415852
[Epoch 9; Iter   584/ 1097] train: loss: 0.2086033
[Epoch 9; Iter   614/ 1097] train: loss: 0.0334998
[Epoch 9; Iter   644/ 1097] train: loss: 0.2208620
[Epoch 9; Iter   674/ 1097] train: loss: 0.0660347
[Epoch 9; Iter   704/ 1097] train: loss: 0.0253343
[Epoch 9; Iter   734/ 1097] train: loss: 0.1613187
[Epoch 9; Iter   764/ 1097] train: loss: 0.0667348
[Epoch 9; Iter   794/ 1097] train: loss: 0.0444830
[Epoch 9; Iter   824/ 1097] train: loss: 0.0419516
[Epoch 9; Iter   854/ 1097] train: loss: 0.0371245
[Epoch 9; Iter   884/ 1097] train: loss: 0.2539404
[Epoch 9; Iter   914/ 1097] train: loss: 0.0303716
[Epoch 9; Iter   944/ 1097] train: loss: 0.1637110
[Epoch 9; Iter   974/ 1097] train: loss: 0.0497220
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1489439
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0824326
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0762244
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0498376
[Epoch 9] ogbg-molhiv: 0.751007 val loss: 0.430921
[Epoch 9] ogbg-molhiv: 0.702020 test loss: 1.565656
[Epoch 10; Iter    27/ 1097] train: loss: 0.1570636
[Epoch 10; Iter    57/ 1097] train: loss: 0.0396927
[Epoch 10; Iter    87/ 1097] train: loss: 0.2271135
[Epoch 10; Iter   117/ 1097] train: loss: 0.0621861
[Epoch 10; Iter   147/ 1097] train: loss: 0.0243761
[Epoch 10; Iter   177/ 1097] train: loss: 0.0309944
[Epoch 10; Iter   207/ 1097] train: loss: 0.0353529
[Epoch 10; Iter   237/ 1097] train: loss: 0.0644747
[Epoch 10; Iter   267/ 1097] train: loss: 0.0402688
[Epoch 10; Iter   297/ 1097] train: loss: 0.0235111
[Epoch 10; Iter   327/ 1097] train: loss: 0.0438339
[Epoch 10; Iter   357/ 1097] train: loss: 0.0760952
[Epoch 10; Iter   387/ 1097] train: loss: 0.1904458
[Epoch 10; Iter   417/ 1097] train: loss: 0.0342540
[Epoch 10; Iter   447/ 1097] train: loss: 0.0491778
[Epoch 10; Iter   477/ 1097] train: loss: 0.0490922
[Epoch 10; Iter   507/ 1097] train: loss: 0.0440971
[Epoch 10; Iter   537/ 1097] train: loss: 0.0271732
[Epoch 10; Iter   567/ 1097] train: loss: 0.1271820
[Epoch 10; Iter   597/ 1097] train: loss: 0.1936387
[Epoch 10; Iter   627/ 1097] train: loss: 0.2371266
[Epoch 10; Iter   657/ 1097] train: loss: 0.0214736
[Epoch 10; Iter   687/ 1097] train: loss: 0.1917816
[Epoch 10; Iter   717/ 1097] train: loss: 0.0796039
[Epoch 10; Iter   747/ 1097] train: loss: 0.3300341
[Epoch 10; Iter   777/ 1097] train: loss: 0.0716679
[Epoch 10; Iter   807/ 1097] train: loss: 0.0696907
[Epoch 10; Iter   837/ 1097] train: loss: 0.0704925
[Epoch 10; Iter   867/ 1097] train: loss: 0.4204640
[Epoch 10; Iter   897/ 1097] train: loss: 0.1584431
[Epoch 10; Iter   927/ 1097] train: loss: 0.3668518
[Epoch 10; Iter   957/ 1097] train: loss: 0.2228448
[Epoch 10; Iter   987/ 1097] train: loss: 0.2683662
[Epoch 10; Iter  1017/ 1097] train: loss: 0.1257771
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1358060
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1802571
[Epoch 10] ogbg-molhiv: 0.767502 val loss: 0.342870
[Epoch 10] ogbg-molhiv: 0.723564 test loss: 1.170699
[Epoch 11; Iter    10/ 1097] train: loss: 0.0331550
[Epoch 11; Iter    40/ 1097] train: loss: 0.0307079
[Epoch 11; Iter    70/ 1097] train: loss: 0.0356181
[Epoch 11; Iter   100/ 1097] train: loss: 0.1481839
[Epoch 11; Iter   130/ 1097] train: loss: 0.0375966
[Epoch 11; Iter   160/ 1097] train: loss: 0.0900221
[Epoch 11; Iter   190/ 1097] train: loss: 0.1361654
[Epoch 11; Iter   220/ 1097] train: loss: 0.1104173
[Epoch 11; Iter   250/ 1097] train: loss: 0.1482875
[Epoch 11; Iter   280/ 1097] train: loss: 0.2152326
[Epoch 11; Iter   310/ 1097] train: loss: 0.1311833
[Epoch 11; Iter   340/ 1097] train: loss: 0.0323682
[Epoch 11; Iter   370/ 1097] train: loss: 0.3683304
[Epoch 11; Iter   400/ 1097] train: loss: 0.0741576
[Epoch 11; Iter   430/ 1097] train: loss: 0.1794174
[Epoch 11; Iter   460/ 1097] train: loss: 0.1630682
[Epoch 11; Iter   490/ 1097] train: loss: 0.1666866
[Epoch 11; Iter   520/ 1097] train: loss: 0.4735307
[Epoch 11; Iter   550/ 1097] train: loss: 0.1372717
[Epoch 11; Iter   580/ 1097] train: loss: 0.1618689
[Epoch 11; Iter   610/ 1097] train: loss: 0.0299316
[Epoch 11; Iter   640/ 1097] train: loss: 0.0307636
[Epoch 11; Iter   670/ 1097] train: loss: 0.0255243
[Epoch 11; Iter   700/ 1097] train: loss: 0.0258351
[Epoch 11; Iter   730/ 1097] train: loss: 0.1538544
[Epoch 11; Iter   760/ 1097] train: loss: 0.0536229
[Epoch 11; Iter   790/ 1097] train: loss: 0.0523500
[Epoch 11; Iter   820/ 1097] train: loss: 0.2567643
[Epoch 11; Iter   850/ 1097] train: loss: 0.1171635
[Epoch 11; Iter   880/ 1097] train: loss: 0.0380340
[Epoch 11; Iter   910/ 1097] train: loss: 0.2864558
[Epoch 11; Iter   940/ 1097] train: loss: 0.2848065
[Epoch 11; Iter   970/ 1097] train: loss: 0.1508147
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1540288
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0919226
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3012946
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4008943
[Epoch 11] ogbg-molhiv: 0.790234 val loss: 0.097963
[Epoch 11] ogbg-molhiv: 0.716381 test loss: 0.121323
[Epoch 12; Iter    23/ 1097] train: loss: 0.1238215
[Epoch 12; Iter    53/ 1097] train: loss: 0.0392258
[Epoch 12; Iter    83/ 1097] train: loss: 0.0368482
[Epoch 8; Iter     1/ 1097] train: loss: 0.1525391
[Epoch 8; Iter    31/ 1097] train: loss: 0.1792570
[Epoch 8; Iter    61/ 1097] train: loss: 0.3408674
[Epoch 8; Iter    91/ 1097] train: loss: 0.3284863
[Epoch 8; Iter   121/ 1097] train: loss: 0.0365687
[Epoch 8; Iter   151/ 1097] train: loss: 0.4733429
[Epoch 8; Iter   181/ 1097] train: loss: 0.2086290
[Epoch 8; Iter   211/ 1097] train: loss: 0.2119234
[Epoch 8; Iter   241/ 1097] train: loss: 0.0371697
[Epoch 8; Iter   271/ 1097] train: loss: 0.2146916
[Epoch 8; Iter   301/ 1097] train: loss: 0.0291236
[Epoch 8; Iter   331/ 1097] train: loss: 0.0345145
[Epoch 8; Iter   361/ 1097] train: loss: 0.1043702
[Epoch 8; Iter   391/ 1097] train: loss: 0.1083057
[Epoch 8; Iter   421/ 1097] train: loss: 0.2712100
[Epoch 8; Iter   451/ 1097] train: loss: 0.0303125
[Epoch 8; Iter   481/ 1097] train: loss: 0.1153359
[Epoch 8; Iter   511/ 1097] train: loss: 0.1691926
[Epoch 8; Iter   541/ 1097] train: loss: 0.0316230
[Epoch 8; Iter   571/ 1097] train: loss: 0.4538340
[Epoch 8; Iter   601/ 1097] train: loss: 0.0941250
[Epoch 8; Iter   631/ 1097] train: loss: 0.0863100
[Epoch 8; Iter   661/ 1097] train: loss: 0.0380751
[Epoch 8; Iter   691/ 1097] train: loss: 0.1986822
[Epoch 8; Iter   721/ 1097] train: loss: 0.1055372
[Epoch 8; Iter   751/ 1097] train: loss: 0.0305277
[Epoch 8; Iter   781/ 1097] train: loss: 0.1940450
[Epoch 8; Iter   811/ 1097] train: loss: 0.1152578
[Epoch 8; Iter   841/ 1097] train: loss: 0.0381697
[Epoch 8; Iter   871/ 1097] train: loss: 0.1326908
[Epoch 8; Iter   901/ 1097] train: loss: 0.0330901
[Epoch 8; Iter   931/ 1097] train: loss: 0.0659856
[Epoch 8; Iter   961/ 1097] train: loss: 0.0604334
[Epoch 8; Iter   991/ 1097] train: loss: 0.0395796
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0356155
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0222976
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1488535
[Epoch 8] ogbg-molhiv: 0.778886 val loss: 0.168022
[Epoch 8] ogbg-molhiv: 0.676771 test loss: 0.175462
[Epoch 9; Iter    14/ 1097] train: loss: 0.0319797
[Epoch 9; Iter    44/ 1097] train: loss: 0.0371451
[Epoch 9; Iter    74/ 1097] train: loss: 0.2170242
[Epoch 9; Iter   104/ 1097] train: loss: 0.3874847
[Epoch 9; Iter   134/ 1097] train: loss: 0.2347776
[Epoch 9; Iter   164/ 1097] train: loss: 0.0476376
[Epoch 9; Iter   194/ 1097] train: loss: 0.0460643
[Epoch 9; Iter   224/ 1097] train: loss: 0.0297165
[Epoch 9; Iter   254/ 1097] train: loss: 0.1337603
[Epoch 9; Iter   284/ 1097] train: loss: 0.0580115
[Epoch 9; Iter   314/ 1097] train: loss: 0.0433185
[Epoch 9; Iter   344/ 1097] train: loss: 0.0377694
[Epoch 9; Iter   374/ 1097] train: loss: 0.0407960
[Epoch 9; Iter   404/ 1097] train: loss: 0.1151314
[Epoch 9; Iter   434/ 1097] train: loss: 0.1371433
[Epoch 9; Iter   464/ 1097] train: loss: 0.1898802
[Epoch 9; Iter   494/ 1097] train: loss: 0.1273152
[Epoch 9; Iter   524/ 1097] train: loss: 0.0722692
[Epoch 9; Iter   554/ 1097] train: loss: 0.0388789
[Epoch 9; Iter   584/ 1097] train: loss: 0.2474138
[Epoch 9; Iter   614/ 1097] train: loss: 0.0462067
[Epoch 9; Iter   644/ 1097] train: loss: 0.1945076
[Epoch 9; Iter   674/ 1097] train: loss: 0.0525945
[Epoch 9; Iter   704/ 1097] train: loss: 0.0243896
[Epoch 9; Iter   734/ 1097] train: loss: 0.1641366
[Epoch 9; Iter   764/ 1097] train: loss: 0.0782866
[Epoch 9; Iter   794/ 1097] train: loss: 0.0801369
[Epoch 9; Iter   824/ 1097] train: loss: 0.0359836
[Epoch 9; Iter   854/ 1097] train: loss: 0.0407585
[Epoch 9; Iter   884/ 1097] train: loss: 0.2823227
[Epoch 9; Iter   914/ 1097] train: loss: 0.0334373
[Epoch 9; Iter   944/ 1097] train: loss: 0.1613971
[Epoch 9; Iter   974/ 1097] train: loss: 0.0409210
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1704144
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0760365
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0621264
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0419382
[Epoch 9] ogbg-molhiv: 0.668182 val loss: 0.148765
[Epoch 9] ogbg-molhiv: 0.616665 test loss: 0.152853
[Epoch 10; Iter    27/ 1097] train: loss: 0.1436508
[Epoch 10; Iter    57/ 1097] train: loss: 0.0294673
[Epoch 10; Iter    87/ 1097] train: loss: 0.1968483
[Epoch 10; Iter   117/ 1097] train: loss: 0.0410422
[Epoch 10; Iter   147/ 1097] train: loss: 0.0275119
[Epoch 10; Iter   177/ 1097] train: loss: 0.0267349
[Epoch 10; Iter   207/ 1097] train: loss: 0.0350212
[Epoch 10; Iter   237/ 1097] train: loss: 0.0252101
[Epoch 10; Iter   267/ 1097] train: loss: 0.0292976
[Epoch 10; Iter   297/ 1097] train: loss: 0.0246603
[Epoch 10; Iter   327/ 1097] train: loss: 0.0252825
[Epoch 10; Iter   357/ 1097] train: loss: 0.1939260
[Epoch 10; Iter   387/ 1097] train: loss: 0.1711847
[Epoch 10; Iter   417/ 1097] train: loss: 0.0334097
[Epoch 10; Iter   447/ 1097] train: loss: 0.0571179
[Epoch 10; Iter   477/ 1097] train: loss: 0.0382716
[Epoch 10; Iter   507/ 1097] train: loss: 0.0748873
[Epoch 10; Iter   537/ 1097] train: loss: 0.0349582
[Epoch 10; Iter   567/ 1097] train: loss: 0.1423747
[Epoch 10; Iter   597/ 1097] train: loss: 0.1772885
[Epoch 10; Iter   627/ 1097] train: loss: 0.1992941
[Epoch 10; Iter   657/ 1097] train: loss: 0.0270597
[Epoch 10; Iter   687/ 1097] train: loss: 0.1942832
[Epoch 10; Iter   717/ 1097] train: loss: 0.0377894
[Epoch 10; Iter   747/ 1097] train: loss: 0.3594900
[Epoch 10; Iter   777/ 1097] train: loss: 0.1016928
[Epoch 10; Iter   807/ 1097] train: loss: 0.0913878
[Epoch 10; Iter   837/ 1097] train: loss: 0.0368435
[Epoch 10; Iter   867/ 1097] train: loss: 0.3549034
[Epoch 10; Iter   897/ 1097] train: loss: 0.1586191
[Epoch 10; Iter   927/ 1097] train: loss: 0.3099696
[Epoch 10; Iter   957/ 1097] train: loss: 0.2234711
[Epoch 10; Iter   987/ 1097] train: loss: 0.2672331
[Epoch 10; Iter  1017/ 1097] train: loss: 0.1172686
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1126870
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1756279
[Epoch 10] ogbg-molhiv: 0.768421 val loss: 0.223496
[Epoch 10] ogbg-molhiv: 0.715974 test loss: 0.143479
[Epoch 11; Iter    10/ 1097] train: loss: 0.0284509
[Epoch 11; Iter    40/ 1097] train: loss: 0.0269870
[Epoch 11; Iter    70/ 1097] train: loss: 0.0440646
[Epoch 11; Iter   100/ 1097] train: loss: 0.1386171
[Epoch 11; Iter   130/ 1097] train: loss: 0.0382115
[Epoch 11; Iter   160/ 1097] train: loss: 0.0545690
[Epoch 11; Iter   190/ 1097] train: loss: 0.1703511
[Epoch 11; Iter   220/ 1097] train: loss: 0.0929417
[Epoch 11; Iter   250/ 1097] train: loss: 0.1767710
[Epoch 11; Iter   280/ 1097] train: loss: 0.1665664
[Epoch 11; Iter   310/ 1097] train: loss: 0.0958580
[Epoch 11; Iter   340/ 1097] train: loss: 0.0357170
[Epoch 11; Iter   370/ 1097] train: loss: 0.3456350
[Epoch 11; Iter   400/ 1097] train: loss: 0.0939363
[Epoch 11; Iter   430/ 1097] train: loss: 0.1826654
[Epoch 11; Iter   460/ 1097] train: loss: 0.1746069
[Epoch 11; Iter   490/ 1097] train: loss: 0.1701471
[Epoch 11; Iter   520/ 1097] train: loss: 0.4098203
[Epoch 11; Iter   550/ 1097] train: loss: 0.1139195
[Epoch 11; Iter   580/ 1097] train: loss: 0.1171218
[Epoch 11; Iter   610/ 1097] train: loss: 0.0316705
[Epoch 11; Iter   640/ 1097] train: loss: 0.0243010
[Epoch 11; Iter   670/ 1097] train: loss: 0.0357842
[Epoch 11; Iter   700/ 1097] train: loss: 0.0342486
[Epoch 11; Iter   730/ 1097] train: loss: 0.1540156
[Epoch 11; Iter   760/ 1097] train: loss: 0.0378769
[Epoch 11; Iter   790/ 1097] train: loss: 0.0639250
[Epoch 11; Iter   820/ 1097] train: loss: 0.2684819
[Epoch 11; Iter   850/ 1097] train: loss: 0.2112578
[Epoch 11; Iter   880/ 1097] train: loss: 0.0233309
[Epoch 11; Iter   910/ 1097] train: loss: 0.2569671
[Epoch 11; Iter   940/ 1097] train: loss: 0.3342364
[Epoch 11; Iter   970/ 1097] train: loss: 0.1600088
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1652649
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0839532
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3038779
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3432481
[Epoch 11] ogbg-molhiv: 0.783161 val loss: 0.654473
[Epoch 11] ogbg-molhiv: 0.676738 test loss: 0.136999
[Epoch 12; Iter    23/ 1097] train: loss: 0.0716050
[Epoch 12; Iter    53/ 1097] train: loss: 0.0418398
[Epoch 12; Iter    83/ 1097] train: loss: 0.0347641
[Epoch 8; Iter     1/ 1097] train: loss: 0.1728199
[Epoch 8; Iter    31/ 1097] train: loss: 0.0315900
[Epoch 8; Iter    61/ 1097] train: loss: 0.1755485
[Epoch 8; Iter    91/ 1097] train: loss: 0.1680007
[Epoch 8; Iter   121/ 1097] train: loss: 0.0344351
[Epoch 8; Iter   151/ 1097] train: loss: 0.1610552
[Epoch 8; Iter   181/ 1097] train: loss: 0.0297133
[Epoch 8; Iter   211/ 1097] train: loss: 0.3058045
[Epoch 8; Iter   241/ 1097] train: loss: 0.1575775
[Epoch 8; Iter   271/ 1097] train: loss: 0.2612197
[Epoch 8; Iter   301/ 1097] train: loss: 0.0756253
[Epoch 8; Iter   331/ 1097] train: loss: 0.1340169
[Epoch 8; Iter   361/ 1097] train: loss: 0.0418062
[Epoch 8; Iter   391/ 1097] train: loss: 0.0291962
[Epoch 8; Iter   421/ 1097] train: loss: 0.2816144
[Epoch 8; Iter   451/ 1097] train: loss: 0.0299460
[Epoch 8; Iter   481/ 1097] train: loss: 0.2013363
[Epoch 8; Iter   511/ 1097] train: loss: 0.1165354
[Epoch 8; Iter   541/ 1097] train: loss: 0.0320116
[Epoch 8; Iter   571/ 1097] train: loss: 0.0291145
[Epoch 8; Iter   601/ 1097] train: loss: 0.0329911
[Epoch 8; Iter   631/ 1097] train: loss: 0.0977280
[Epoch 8; Iter   661/ 1097] train: loss: 0.0459887
[Epoch 8; Iter   691/ 1097] train: loss: 0.3438326
[Epoch 8; Iter   721/ 1097] train: loss: 0.0364613
[Epoch 8; Iter   751/ 1097] train: loss: 0.1368756
[Epoch 8; Iter   781/ 1097] train: loss: 0.0554911
[Epoch 8; Iter   811/ 1097] train: loss: 0.0672474
[Epoch 8; Iter   841/ 1097] train: loss: 0.1556629
[Epoch 8; Iter   871/ 1097] train: loss: 0.2550051
[Epoch 8; Iter   901/ 1097] train: loss: 0.0587577
[Epoch 8; Iter   931/ 1097] train: loss: 0.0541986
[Epoch 8; Iter   961/ 1097] train: loss: 0.0257369
[Epoch 8; Iter   991/ 1097] train: loss: 0.0432599
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0439812
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0321076
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3359014
[Epoch 8] ogbg-molhiv: 0.745141 val loss: 0.084398
[Epoch 8] ogbg-molhiv: 0.672195 test loss: 0.127509
[Epoch 9; Iter    14/ 1097] train: loss: 0.0304602
[Epoch 9; Iter    44/ 1097] train: loss: 0.0399183
[Epoch 9; Iter    74/ 1097] train: loss: 0.0580248
[Epoch 9; Iter   104/ 1097] train: loss: 0.0258671
[Epoch 9; Iter   134/ 1097] train: loss: 0.0661046
[Epoch 9; Iter   164/ 1097] train: loss: 0.0424553
[Epoch 9; Iter   194/ 1097] train: loss: 0.0431026
[Epoch 9; Iter   224/ 1097] train: loss: 0.3039019
[Epoch 9; Iter   254/ 1097] train: loss: 0.0833203
[Epoch 9; Iter   284/ 1097] train: loss: 0.1824763
[Epoch 9; Iter   314/ 1097] train: loss: 0.2591160
[Epoch 9; Iter   344/ 1097] train: loss: 0.0350299
[Epoch 9; Iter   374/ 1097] train: loss: 0.1815350
[Epoch 9; Iter   404/ 1097] train: loss: 0.1662759
[Epoch 9; Iter   434/ 1097] train: loss: 0.1178309
[Epoch 9; Iter   464/ 1097] train: loss: 0.0295404
[Epoch 9; Iter   494/ 1097] train: loss: 0.1718626
[Epoch 9; Iter   524/ 1097] train: loss: 0.0268800
[Epoch 9; Iter   554/ 1097] train: loss: 0.0764622
[Epoch 9; Iter   584/ 1097] train: loss: 0.1412839
[Epoch 9; Iter   614/ 1097] train: loss: 0.0378269
[Epoch 9; Iter   644/ 1097] train: loss: 0.2049976
[Epoch 9; Iter   674/ 1097] train: loss: 0.2207750
[Epoch 9; Iter   704/ 1097] train: loss: 0.0378140
[Epoch 9; Iter   734/ 1097] train: loss: 0.0365686
[Epoch 9; Iter   764/ 1097] train: loss: 0.1402805
[Epoch 9; Iter   794/ 1097] train: loss: 0.0337235
[Epoch 9; Iter   824/ 1097] train: loss: 0.0293622
[Epoch 9; Iter   854/ 1097] train: loss: 0.0281811
[Epoch 9; Iter   884/ 1097] train: loss: 0.2395000
[Epoch 9; Iter   914/ 1097] train: loss: 0.0355193
[Epoch 9; Iter   944/ 1097] train: loss: 0.1764511
[Epoch 9; Iter   974/ 1097] train: loss: 0.0321693
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0253470
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0306486
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3106149
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0380917
[Epoch 9] ogbg-molhiv: 0.776198 val loss: 0.087288
[Epoch 9] ogbg-molhiv: 0.707169 test loss: 0.126099
[Epoch 10; Iter    27/ 1097] train: loss: 0.1970612
[Epoch 10; Iter    57/ 1097] train: loss: 0.3350683
[Epoch 10; Iter    87/ 1097] train: loss: 0.0360953
[Epoch 10; Iter   117/ 1097] train: loss: 0.1384641
[Epoch 10; Iter   147/ 1097] train: loss: 0.0513853
[Epoch 10; Iter   177/ 1097] train: loss: 0.4132558
[Epoch 10; Iter   207/ 1097] train: loss: 0.0766574
[Epoch 10; Iter   237/ 1097] train: loss: 0.0309034
[Epoch 10; Iter   267/ 1097] train: loss: 0.0777391
[Epoch 10; Iter   297/ 1097] train: loss: 0.2369404
[Epoch 10; Iter   327/ 1097] train: loss: 0.2599929
[Epoch 10; Iter   357/ 1097] train: loss: 0.0491851
[Epoch 10; Iter   387/ 1097] train: loss: 0.1065528
[Epoch 10; Iter   417/ 1097] train: loss: 0.2506793
[Epoch 10; Iter   447/ 1097] train: loss: 0.1478887
[Epoch 10; Iter   477/ 1097] train: loss: 0.0430851
[Epoch 10; Iter   507/ 1097] train: loss: 0.0342709
[Epoch 10; Iter   537/ 1097] train: loss: 0.1193876
[Epoch 10; Iter   567/ 1097] train: loss: 0.2290439
[Epoch 10; Iter   597/ 1097] train: loss: 0.1451640
[Epoch 10; Iter   627/ 1097] train: loss: 0.0930099
[Epoch 10; Iter   657/ 1097] train: loss: 0.3041534
[Epoch 10; Iter   687/ 1097] train: loss: 0.1053917
[Epoch 10; Iter   717/ 1097] train: loss: 0.3048241
[Epoch 10; Iter   747/ 1097] train: loss: 0.0402555
[Epoch 10; Iter   777/ 1097] train: loss: 0.0274352
[Epoch 10; Iter   807/ 1097] train: loss: 0.3180653
[Epoch 10; Iter   837/ 1097] train: loss: 0.0374663
[Epoch 10; Iter   867/ 1097] train: loss: 0.0516348
[Epoch 10; Iter   897/ 1097] train: loss: 0.0293728
[Epoch 10; Iter   927/ 1097] train: loss: 0.2192849
[Epoch 10; Iter   957/ 1097] train: loss: 0.1316608
[Epoch 10; Iter   987/ 1097] train: loss: 0.4908600
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0283423
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0571277
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2170980
[Epoch 10] ogbg-molhiv: 0.762205 val loss: 0.100132
[Epoch 10] ogbg-molhiv: 0.678893 test loss: 0.136870
[Epoch 11; Iter    10/ 1097] train: loss: 0.3467194
[Epoch 11; Iter    40/ 1097] train: loss: 0.1296946
[Epoch 11; Iter    70/ 1097] train: loss: 0.1309109
[Epoch 11; Iter   100/ 1097] train: loss: 0.0997818
[Epoch 11; Iter   130/ 1097] train: loss: 0.3734718
[Epoch 11; Iter   160/ 1097] train: loss: 0.1114045
[Epoch 11; Iter   190/ 1097] train: loss: 0.0315945
[Epoch 11; Iter   220/ 1097] train: loss: 0.1609574
[Epoch 11; Iter   250/ 1097] train: loss: 0.0950733
[Epoch 11; Iter   280/ 1097] train: loss: 0.2203904
[Epoch 11; Iter   310/ 1097] train: loss: 0.1374251
[Epoch 11; Iter   340/ 1097] train: loss: 0.0509677
[Epoch 11; Iter   370/ 1097] train: loss: 0.0258863
[Epoch 11; Iter   400/ 1097] train: loss: 0.2514074
[Epoch 11; Iter   430/ 1097] train: loss: 0.0250963
[Epoch 11; Iter   460/ 1097] train: loss: 0.1477395
[Epoch 11; Iter   490/ 1097] train: loss: 0.2119517
[Epoch 11; Iter   520/ 1097] train: loss: 0.1400340
[Epoch 11; Iter   550/ 1097] train: loss: 0.0247777
[Epoch 11; Iter   580/ 1097] train: loss: 0.4202435
[Epoch 11; Iter   610/ 1097] train: loss: 0.1331618
[Epoch 11; Iter   640/ 1097] train: loss: 0.1130195
[Epoch 11; Iter   670/ 1097] train: loss: 0.0279306
[Epoch 11; Iter   700/ 1097] train: loss: 0.1126505
[Epoch 11; Iter   730/ 1097] train: loss: 0.1685743
[Epoch 11; Iter   760/ 1097] train: loss: 0.1556102
[Epoch 11; Iter   790/ 1097] train: loss: 0.0821887
[Epoch 11; Iter   820/ 1097] train: loss: 0.0730612
[Epoch 11; Iter   850/ 1097] train: loss: 0.1856695
[Epoch 11; Iter   880/ 1097] train: loss: 0.0296349
[Epoch 11; Iter   910/ 1097] train: loss: 0.0474883
[Epoch 11; Iter   940/ 1097] train: loss: 0.0815938
[Epoch 11; Iter   970/ 1097] train: loss: 0.0319804
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0539544
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1414842
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2178220
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0321647
[Epoch 11] ogbg-molhiv: 0.745401 val loss: 0.088211
[Epoch 11] ogbg-molhiv: 0.695784 test loss: 0.126146
[Epoch 12; Iter    23/ 1097] train: loss: 0.1852472
[Epoch 12; Iter    53/ 1097] train: loss: 0.0358209
[Epoch 12; Iter    83/ 1097] train: loss: 0.0814033
[Epoch 8; Iter     1/ 1097] train: loss: 0.2199414
[Epoch 8; Iter    31/ 1097] train: loss: 0.0415757
[Epoch 8; Iter    61/ 1097] train: loss: 0.0870053
[Epoch 8; Iter    91/ 1097] train: loss: 0.1354131
[Epoch 8; Iter   121/ 1097] train: loss: 0.1151198
[Epoch 8; Iter   151/ 1097] train: loss: 0.0340660
[Epoch 8; Iter   181/ 1097] train: loss: 0.0502234
[Epoch 8; Iter   211/ 1097] train: loss: 0.0605189
[Epoch 8; Iter   241/ 1097] train: loss: 0.0376711
[Epoch 8; Iter   271/ 1097] train: loss: 0.2038349
[Epoch 8; Iter   301/ 1097] train: loss: 0.2473613
[Epoch 8; Iter   331/ 1097] train: loss: 0.0842873
[Epoch 8; Iter   361/ 1097] train: loss: 0.1295280
[Epoch 8; Iter   391/ 1097] train: loss: 0.0255743
[Epoch 8; Iter   421/ 1097] train: loss: 0.2919911
[Epoch 8; Iter   451/ 1097] train: loss: 0.3165987
[Epoch 8; Iter   481/ 1097] train: loss: 0.0456154
[Epoch 8; Iter   511/ 1097] train: loss: 0.1274848
[Epoch 8; Iter   541/ 1097] train: loss: 0.1776192
[Epoch 8; Iter   571/ 1097] train: loss: 0.1379372
[Epoch 8; Iter   601/ 1097] train: loss: 0.3521233
[Epoch 8; Iter   631/ 1097] train: loss: 0.0335765
[Epoch 8; Iter   661/ 1097] train: loss: 0.2568301
[Epoch 8; Iter   691/ 1097] train: loss: 0.0918433
[Epoch 8; Iter   721/ 1097] train: loss: 0.0648077
[Epoch 8; Iter   751/ 1097] train: loss: 0.1391766
[Epoch 8; Iter   781/ 1097] train: loss: 0.1720593
[Epoch 8; Iter   811/ 1097] train: loss: 0.2251786
[Epoch 8; Iter   841/ 1097] train: loss: 0.3755791
[Epoch 8; Iter   871/ 1097] train: loss: 0.1928829
[Epoch 8; Iter   901/ 1097] train: loss: 0.0331235
[Epoch 8; Iter   931/ 1097] train: loss: 0.1744835
[Epoch 8; Iter   961/ 1097] train: loss: 0.0452708
[Epoch 8; Iter   991/ 1097] train: loss: 0.1290329
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2865983
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0304164
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1007932
[Epoch 8] ogbg-molhiv: 0.697090 val loss: 0.778771
[Epoch 8] ogbg-molhiv: 0.661718 test loss: 0.668699
[Epoch 9; Iter    14/ 1097] train: loss: 0.2583400
[Epoch 9; Iter    44/ 1097] train: loss: 0.0323905
[Epoch 9; Iter    74/ 1097] train: loss: 0.0287118
[Epoch 9; Iter   104/ 1097] train: loss: 0.2479589
[Epoch 9; Iter   134/ 1097] train: loss: 0.0963074
[Epoch 9; Iter   164/ 1097] train: loss: 0.1443638
[Epoch 9; Iter   194/ 1097] train: loss: 0.0696601
[Epoch 9; Iter   224/ 1097] train: loss: 0.0364424
[Epoch 9; Iter   254/ 1097] train: loss: 0.3312468
[Epoch 9; Iter   284/ 1097] train: loss: 0.2008513
[Epoch 9; Iter   314/ 1097] train: loss: 0.1019831
[Epoch 9; Iter   344/ 1097] train: loss: 0.4479470
[Epoch 9; Iter   374/ 1097] train: loss: 0.1746782
[Epoch 9; Iter   404/ 1097] train: loss: 0.1571946
[Epoch 9; Iter   434/ 1097] train: loss: 0.0806427
[Epoch 9; Iter   464/ 1097] train: loss: 0.0390307
[Epoch 9; Iter   494/ 1097] train: loss: 0.1370909
[Epoch 9; Iter   524/ 1097] train: loss: 0.0318435
[Epoch 9; Iter   554/ 1097] train: loss: 0.0369634
[Epoch 9; Iter   584/ 1097] train: loss: 0.5313562
[Epoch 9; Iter   614/ 1097] train: loss: 0.1379613
[Epoch 9; Iter   644/ 1097] train: loss: 0.2673620
[Epoch 9; Iter   674/ 1097] train: loss: 0.4704604
[Epoch 9; Iter   704/ 1097] train: loss: 0.1416555
[Epoch 9; Iter   734/ 1097] train: loss: 0.0842399
[Epoch 9; Iter   764/ 1097] train: loss: 0.2158612
[Epoch 9; Iter   794/ 1097] train: loss: 0.1610610
[Epoch 9; Iter   824/ 1097] train: loss: 0.0389841
[Epoch 9; Iter   854/ 1097] train: loss: 0.0229280
[Epoch 9; Iter   884/ 1097] train: loss: 0.1222623
[Epoch 9; Iter   914/ 1097] train: loss: 0.1762887
[Epoch 9; Iter   944/ 1097] train: loss: 0.0440198
[Epoch 9; Iter   974/ 1097] train: loss: 0.1380025
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2454324
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2559655
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3172745
[Epoch 9; Iter  1094/ 1097] train: loss: 0.3040478
[Epoch 9] ogbg-molhiv: 0.748460 val loss: 0.553493
[Epoch 9] ogbg-molhiv: 0.666009 test loss: 0.218848
[Epoch 10; Iter    27/ 1097] train: loss: 0.0294519
[Epoch 10; Iter    57/ 1097] train: loss: 0.0329486
[Epoch 10; Iter    87/ 1097] train: loss: 0.1620478
[Epoch 10; Iter   117/ 1097] train: loss: 0.0696612
[Epoch 10; Iter   147/ 1097] train: loss: 0.3713928
[Epoch 10; Iter   177/ 1097] train: loss: 0.2630896
[Epoch 10; Iter   207/ 1097] train: loss: 0.2561781
[Epoch 10; Iter   237/ 1097] train: loss: 0.0379085
[Epoch 10; Iter   267/ 1097] train: loss: 0.0393736
[Epoch 10; Iter   297/ 1097] train: loss: 0.1740465
[Epoch 10; Iter   327/ 1097] train: loss: 0.0278929
[Epoch 10; Iter   357/ 1097] train: loss: 0.2133373
[Epoch 10; Iter   387/ 1097] train: loss: 0.1535085
[Epoch 10; Iter   417/ 1097] train: loss: 0.1579355
[Epoch 10; Iter   447/ 1097] train: loss: 0.1702306
[Epoch 10; Iter   477/ 1097] train: loss: 0.1452212
[Epoch 10; Iter   507/ 1097] train: loss: 0.1094710
[Epoch 10; Iter   537/ 1097] train: loss: 0.0303914
[Epoch 10; Iter   567/ 1097] train: loss: 0.0259748
[Epoch 10; Iter   597/ 1097] train: loss: 0.0246370
[Epoch 10; Iter   627/ 1097] train: loss: 0.1705341
[Epoch 10; Iter   657/ 1097] train: loss: 0.1793762
[Epoch 10; Iter   687/ 1097] train: loss: 0.1359818
[Epoch 10; Iter   717/ 1097] train: loss: 0.2052934
[Epoch 10; Iter   747/ 1097] train: loss: 0.1967948
[Epoch 10; Iter   777/ 1097] train: loss: 0.1569573
[Epoch 10; Iter   807/ 1097] train: loss: 0.0379049
[Epoch 10; Iter   837/ 1097] train: loss: 0.0345129
[Epoch 10; Iter   867/ 1097] train: loss: 0.1099779
[Epoch 10; Iter   897/ 1097] train: loss: 0.0374451
[Epoch 10; Iter   927/ 1097] train: loss: 0.1806505
[Epoch 10; Iter   957/ 1097] train: loss: 0.0513547
[Epoch 10; Iter   987/ 1097] train: loss: 0.2551206
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2553470
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1935686
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0312640
[Epoch 10] ogbg-molhiv: 0.731815 val loss: 2.269624
[Epoch 10] ogbg-molhiv: 0.706601 test loss: 1.922335
[Epoch 11; Iter    10/ 1097] train: loss: 0.2664647
[Epoch 11; Iter    40/ 1097] train: loss: 0.0608126
[Epoch 11; Iter    70/ 1097] train: loss: 0.1348918
[Epoch 11; Iter   100/ 1097] train: loss: 0.0247087
[Epoch 11; Iter   130/ 1097] train: loss: 0.1513356
[Epoch 11; Iter   160/ 1097] train: loss: 0.0361371
[Epoch 11; Iter   190/ 1097] train: loss: 0.2980752
[Epoch 11; Iter   220/ 1097] train: loss: 0.3120586
[Epoch 11; Iter   250/ 1097] train: loss: 0.2824020
[Epoch 11; Iter   280/ 1097] train: loss: 0.0497115
[Epoch 11; Iter   310/ 1097] train: loss: 0.2457714
[Epoch 11; Iter   340/ 1097] train: loss: 0.0406963
[Epoch 11; Iter   370/ 1097] train: loss: 0.1588529
[Epoch 11; Iter   400/ 1097] train: loss: 0.0306812
[Epoch 11; Iter   430/ 1097] train: loss: 0.2735957
[Epoch 11; Iter   460/ 1097] train: loss: 0.1298468
[Epoch 11; Iter   490/ 1097] train: loss: 0.3001621
[Epoch 11; Iter   520/ 1097] train: loss: 0.1943054
[Epoch 11; Iter   550/ 1097] train: loss: 0.0358228
[Epoch 11; Iter   580/ 1097] train: loss: 0.0740239
[Epoch 11; Iter   610/ 1097] train: loss: 0.0348344
[Epoch 11; Iter   640/ 1097] train: loss: 0.0482033
[Epoch 11; Iter   670/ 1097] train: loss: 0.1813551
[Epoch 11; Iter   700/ 1097] train: loss: 0.1459227
[Epoch 11; Iter   730/ 1097] train: loss: 0.0485809
[Epoch 11; Iter   760/ 1097] train: loss: 0.1823619
[Epoch 11; Iter   790/ 1097] train: loss: 0.1978875
[Epoch 11; Iter   820/ 1097] train: loss: 0.0708871
[Epoch 11; Iter   850/ 1097] train: loss: 0.0470271
[Epoch 11; Iter   880/ 1097] train: loss: 0.2662964
[Epoch 11; Iter   910/ 1097] train: loss: 0.2463741
[Epoch 11; Iter   940/ 1097] train: loss: 0.2993546
[Epoch 11; Iter   970/ 1097] train: loss: 0.2171760
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0506687
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0275874
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2257947
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4099365
[Epoch 11] ogbg-molhiv: 0.766381 val loss: 0.108520
[Epoch 11] ogbg-molhiv: 0.702493 test loss: 0.138951
[Epoch 12; Iter    23/ 1097] train: loss: 0.0531148
[Epoch 12; Iter    53/ 1097] train: loss: 0.0321663
[Epoch 12; Iter    83/ 1097] train: loss: 0.0355302
[Epoch 12; Iter   113/ 1097] train: loss: 0.1594750
[Epoch 12; Iter   143/ 1097] train: loss: 0.2084812
[Epoch 12; Iter   173/ 1097] train: loss: 0.0465169
[Epoch 12; Iter   203/ 1097] train: loss: 0.0284268
[Epoch 12; Iter   233/ 1097] train: loss: 0.0264327
[Epoch 12; Iter   263/ 1097] train: loss: 0.0818743
[Epoch 12; Iter   293/ 1097] train: loss: 0.1872337
[Epoch 12; Iter   323/ 1097] train: loss: 0.1103940
[Epoch 12; Iter   353/ 1097] train: loss: 0.2123251
[Epoch 12; Iter   383/ 1097] train: loss: 0.0491678
[Epoch 12; Iter   413/ 1097] train: loss: 0.2262352
[Epoch 12; Iter   443/ 1097] train: loss: 0.3069222
[Epoch 12; Iter   473/ 1097] train: loss: 0.1130872
[Epoch 12; Iter   503/ 1097] train: loss: 0.2097451
[Epoch 12; Iter   533/ 1097] train: loss: 0.1339742
[Epoch 12; Iter   563/ 1097] train: loss: 0.1193211
[Epoch 12; Iter   593/ 1097] train: loss: 0.3120738
[Epoch 12; Iter   623/ 1097] train: loss: 0.2442602
[Epoch 12; Iter   653/ 1097] train: loss: 0.0294225
[Epoch 12; Iter   683/ 1097] train: loss: 0.1918073
[Epoch 12; Iter   713/ 1097] train: loss: 0.0629105
[Epoch 12; Iter   743/ 1097] train: loss: 0.2002306
[Epoch 12; Iter   773/ 1097] train: loss: 0.0480744
[Epoch 12; Iter   803/ 1097] train: loss: 0.1638750
[Epoch 12; Iter   833/ 1097] train: loss: 0.1153855
[Epoch 12; Iter   863/ 1097] train: loss: 0.2683300
[Epoch 12; Iter   893/ 1097] train: loss: 0.0326890
[Epoch 12; Iter   923/ 1097] train: loss: 0.1662995
[Epoch 12; Iter   953/ 1097] train: loss: 0.2328745
[Epoch 12; Iter   983/ 1097] train: loss: 0.0541767
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0435597
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1282301
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0859438
[Epoch 12] ogbg-molhiv: 0.776446 val loss: 0.180450
[Epoch 12] ogbg-molhiv: 0.761000 test loss: 0.159439
[Epoch 13; Iter     6/ 1097] train: loss: 0.0607657
[Epoch 13; Iter    36/ 1097] train: loss: 0.2622051
[Epoch 13; Iter    66/ 1097] train: loss: 0.1616715
[Epoch 13; Iter    96/ 1097] train: loss: 0.0541924
[Epoch 13; Iter   126/ 1097] train: loss: 0.0246601
[Epoch 13; Iter   156/ 1097] train: loss: 0.0240053
[Epoch 13; Iter   186/ 1097] train: loss: 0.1547361
[Epoch 13; Iter   216/ 1097] train: loss: 0.2567126
[Epoch 13; Iter   246/ 1097] train: loss: 0.0232265
[Epoch 13; Iter   276/ 1097] train: loss: 0.0955623
[Epoch 13; Iter   306/ 1097] train: loss: 0.0206583
[Epoch 13; Iter   336/ 1097] train: loss: 0.1565973
[Epoch 13; Iter   366/ 1097] train: loss: 0.1000427
[Epoch 13; Iter   396/ 1097] train: loss: 0.0903412
[Epoch 13; Iter   426/ 1097] train: loss: 0.0481890
[Epoch 13; Iter   456/ 1097] train: loss: 0.0438387
[Epoch 13; Iter   486/ 1097] train: loss: 0.0380195
[Epoch 13; Iter   516/ 1097] train: loss: 0.0311094
[Epoch 13; Iter   546/ 1097] train: loss: 0.0347942
[Epoch 13; Iter   576/ 1097] train: loss: 0.1631823
[Epoch 13; Iter   606/ 1097] train: loss: 0.0625942
[Epoch 13; Iter   636/ 1097] train: loss: 0.2289898
[Epoch 13; Iter   666/ 1097] train: loss: 0.0244769
[Epoch 13; Iter   696/ 1097] train: loss: 0.0434459
[Epoch 13; Iter   726/ 1097] train: loss: 0.0841782
[Epoch 13; Iter   756/ 1097] train: loss: 0.0687264
[Epoch 13; Iter   786/ 1097] train: loss: 0.1479743
[Epoch 13; Iter   816/ 1097] train: loss: 0.0290326
[Epoch 13; Iter   846/ 1097] train: loss: 0.0208069
[Epoch 13; Iter   876/ 1097] train: loss: 0.1825717
[Epoch 13; Iter   906/ 1097] train: loss: 0.2183687
[Epoch 13; Iter   936/ 1097] train: loss: 0.2214710
[Epoch 13; Iter   966/ 1097] train: loss: 0.1132617
[Epoch 13; Iter   996/ 1097] train: loss: 0.0655394
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3934215
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1635953
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1647495
[Epoch 13] ogbg-molhiv: 0.798651 val loss: 0.427514
[Epoch 13] ogbg-molhiv: 0.768317 test loss: 0.219948
[Epoch 14; Iter    19/ 1097] train: loss: 0.0310872
[Epoch 14; Iter    49/ 1097] train: loss: 0.3053547
[Epoch 14; Iter    79/ 1097] train: loss: 0.0253206
[Epoch 14; Iter   109/ 1097] train: loss: 0.0293928
[Epoch 14; Iter   139/ 1097] train: loss: 0.0473797
[Epoch 14; Iter   169/ 1097] train: loss: 0.1595384
[Epoch 14; Iter   199/ 1097] train: loss: 0.1131948
[Epoch 14; Iter   229/ 1097] train: loss: 0.0215184
[Epoch 14; Iter   259/ 1097] train: loss: 0.0911949
[Epoch 14; Iter   289/ 1097] train: loss: 0.1154762
[Epoch 14; Iter   319/ 1097] train: loss: 0.2777298
[Epoch 14; Iter   349/ 1097] train: loss: 0.2069708
[Epoch 14; Iter   379/ 1097] train: loss: 0.1824195
[Epoch 14; Iter   409/ 1097] train: loss: 0.0715396
[Epoch 14; Iter   439/ 1097] train: loss: 0.1570803
[Epoch 14; Iter   469/ 1097] train: loss: 0.1457103
[Epoch 14; Iter   499/ 1097] train: loss: 0.0328306
[Epoch 14; Iter   529/ 1097] train: loss: 0.0278972
[Epoch 14; Iter   559/ 1097] train: loss: 0.1847831
[Epoch 14; Iter   589/ 1097] train: loss: 0.0228198
[Epoch 14; Iter   619/ 1097] train: loss: 0.0518150
[Epoch 14; Iter   649/ 1097] train: loss: 0.0316595
[Epoch 14; Iter   679/ 1097] train: loss: 0.1163970
[Epoch 14; Iter   709/ 1097] train: loss: 0.1638998
[Epoch 14; Iter   739/ 1097] train: loss: 0.0401574
[Epoch 14; Iter   769/ 1097] train: loss: 0.1373926
[Epoch 14; Iter   799/ 1097] train: loss: 0.0397227
[Epoch 14; Iter   829/ 1097] train: loss: 0.1124819
[Epoch 14; Iter   859/ 1097] train: loss: 0.0296358
[Epoch 14; Iter   889/ 1097] train: loss: 0.0358000
[Epoch 14; Iter   919/ 1097] train: loss: 0.0693568
[Epoch 14; Iter   949/ 1097] train: loss: 0.0329625
[Epoch 14; Iter   979/ 1097] train: loss: 0.1439500
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0176315
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0507924
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1129636
[Epoch 14] ogbg-molhiv: 0.737994 val loss: 0.081207
[Epoch 14] ogbg-molhiv: 0.710097 test loss: 0.131090
[Epoch 15; Iter     2/ 1097] train: loss: 0.2217816
[Epoch 15; Iter    32/ 1097] train: loss: 0.0364281
[Epoch 15; Iter    62/ 1097] train: loss: 0.1111796
[Epoch 15; Iter    92/ 1097] train: loss: 0.0343777
[Epoch 15; Iter   122/ 1097] train: loss: 0.2487049
[Epoch 15; Iter   152/ 1097] train: loss: 0.2166549
[Epoch 15; Iter   182/ 1097] train: loss: 0.2205918
[Epoch 15; Iter   212/ 1097] train: loss: 0.0272352
[Epoch 15; Iter   242/ 1097] train: loss: 0.0305506
[Epoch 15; Iter   272/ 1097] train: loss: 0.1928152
[Epoch 15; Iter   302/ 1097] train: loss: 0.1810414
[Epoch 15; Iter   332/ 1097] train: loss: 0.0438678
[Epoch 15; Iter   362/ 1097] train: loss: 0.1516408
[Epoch 15; Iter   392/ 1097] train: loss: 0.1494500
[Epoch 15; Iter   422/ 1097] train: loss: 0.2052148
[Epoch 15; Iter   452/ 1097] train: loss: 0.0624965
[Epoch 15; Iter   482/ 1097] train: loss: 0.0709406
[Epoch 15; Iter   512/ 1097] train: loss: 0.2549663
[Epoch 15; Iter   542/ 1097] train: loss: 0.0838428
[Epoch 15; Iter   572/ 1097] train: loss: 0.0302022
[Epoch 15; Iter   602/ 1097] train: loss: 0.3716102
[Epoch 15; Iter   632/ 1097] train: loss: 0.0280015
[Epoch 15; Iter   662/ 1097] train: loss: 0.2099345
[Epoch 15; Iter   692/ 1097] train: loss: 0.0288151
[Epoch 15; Iter   722/ 1097] train: loss: 0.0724255
[Epoch 15; Iter   752/ 1097] train: loss: 0.1591962
[Epoch 15; Iter   782/ 1097] train: loss: 0.1905330
[Epoch 15; Iter   812/ 1097] train: loss: 0.0596860
[Epoch 15; Iter   842/ 1097] train: loss: 0.0383633
[Epoch 15; Iter   872/ 1097] train: loss: 0.0194571
[Epoch 15; Iter   902/ 1097] train: loss: 0.2200923
[Epoch 15; Iter   932/ 1097] train: loss: 0.0784366
[Epoch 15; Iter   962/ 1097] train: loss: 0.0373842
[Epoch 15; Iter   992/ 1097] train: loss: 0.0560431
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0180624
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1597539
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0239548
[Epoch 15] ogbg-molhiv: 0.755769 val loss: 0.144779
[Epoch 15] ogbg-molhiv: 0.734865 test loss: 0.124482
[Epoch 16; Iter    15/ 1097] train: loss: 0.0941264
[Epoch 16; Iter    45/ 1097] train: loss: 0.0241158
[Epoch 16; Iter    75/ 1097] train: loss: 0.0176221
[Epoch 16; Iter   105/ 1097] train: loss: 0.0229881
[Epoch 16; Iter   135/ 1097] train: loss: 0.0301589
[Epoch 16; Iter   165/ 1097] train: loss: 0.3152574
[Epoch 12; Iter   113/ 1097] train: loss: 0.0697966
[Epoch 12; Iter   143/ 1097] train: loss: 0.1893246
[Epoch 12; Iter   173/ 1097] train: loss: 0.0269324
[Epoch 12; Iter   203/ 1097] train: loss: 0.1026488
[Epoch 12; Iter   233/ 1097] train: loss: 0.0208388
[Epoch 12; Iter   263/ 1097] train: loss: 0.0364198
[Epoch 12; Iter   293/ 1097] train: loss: 0.2024160
[Epoch 12; Iter   323/ 1097] train: loss: 0.1907149
[Epoch 12; Iter   353/ 1097] train: loss: 0.0603156
[Epoch 12; Iter   383/ 1097] train: loss: 0.0330147
[Epoch 12; Iter   413/ 1097] train: loss: 0.0291521
[Epoch 12; Iter   443/ 1097] train: loss: 0.0270228
[Epoch 12; Iter   473/ 1097] train: loss: 0.2287320
[Epoch 12; Iter   503/ 1097] train: loss: 0.1789691
[Epoch 12; Iter   533/ 1097] train: loss: 0.0283773
[Epoch 12; Iter   563/ 1097] train: loss: 0.0546055
[Epoch 12; Iter   593/ 1097] train: loss: 0.2053545
[Epoch 12; Iter   623/ 1097] train: loss: 0.0354322
[Epoch 12; Iter   653/ 1097] train: loss: 0.0856076
[Epoch 12; Iter   683/ 1097] train: loss: 0.2802557
[Epoch 12; Iter   713/ 1097] train: loss: 0.1327690
[Epoch 12; Iter   743/ 1097] train: loss: 0.0342834
[Epoch 12; Iter   773/ 1097] train: loss: 0.1702721
[Epoch 12; Iter   803/ 1097] train: loss: 0.1677788
[Epoch 12; Iter   833/ 1097] train: loss: 0.0857904
[Epoch 12; Iter   863/ 1097] train: loss: 0.0515539
[Epoch 12; Iter   893/ 1097] train: loss: 0.1703474
[Epoch 12; Iter   923/ 1097] train: loss: 0.0318148
[Epoch 12; Iter   953/ 1097] train: loss: 0.2531779
[Epoch 12; Iter   983/ 1097] train: loss: 0.2700695
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0267673
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0305184
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0349921
[Epoch 12] ogbg-molhiv: 0.803216 val loss: 0.159729
[Epoch 12] ogbg-molhiv: 0.744684 test loss: 0.128838
[Epoch 13; Iter     6/ 1097] train: loss: 0.1583008
[Epoch 13; Iter    36/ 1097] train: loss: 0.1264379
[Epoch 13; Iter    66/ 1097] train: loss: 0.1474558
[Epoch 13; Iter    96/ 1097] train: loss: 0.0173064
[Epoch 13; Iter   126/ 1097] train: loss: 0.0491824
[Epoch 13; Iter   156/ 1097] train: loss: 0.2150961
[Epoch 13; Iter   186/ 1097] train: loss: 0.2640545
[Epoch 13; Iter   216/ 1097] train: loss: 0.2026233
[Epoch 13; Iter   246/ 1097] train: loss: 0.0358883
[Epoch 13; Iter   276/ 1097] train: loss: 0.0311765
[Epoch 13; Iter   306/ 1097] train: loss: 0.3363660
[Epoch 13; Iter   336/ 1097] train: loss: 0.1690856
[Epoch 13; Iter   366/ 1097] train: loss: 0.4613255
[Epoch 13; Iter   396/ 1097] train: loss: 0.0777727
[Epoch 13; Iter   426/ 1097] train: loss: 0.0757019
[Epoch 13; Iter   456/ 1097] train: loss: 0.1701506
[Epoch 13; Iter   486/ 1097] train: loss: 0.0296013
[Epoch 13; Iter   516/ 1097] train: loss: 0.1440994
[Epoch 13; Iter   546/ 1097] train: loss: 0.0253294
[Epoch 13; Iter   576/ 1097] train: loss: 0.0463124
[Epoch 13; Iter   606/ 1097] train: loss: 0.1915630
[Epoch 13; Iter   636/ 1097] train: loss: 0.0781019
[Epoch 13; Iter   666/ 1097] train: loss: 0.1641776
[Epoch 13; Iter   696/ 1097] train: loss: 0.4126455
[Epoch 13; Iter   726/ 1097] train: loss: 0.0565561
[Epoch 13; Iter   756/ 1097] train: loss: 0.1020544
[Epoch 13; Iter   786/ 1097] train: loss: 0.2003193
[Epoch 13; Iter   816/ 1097] train: loss: 0.0589732
[Epoch 13; Iter   846/ 1097] train: loss: 0.0279427
[Epoch 13; Iter   876/ 1097] train: loss: 0.2204526
[Epoch 13; Iter   906/ 1097] train: loss: 0.3141629
[Epoch 13; Iter   936/ 1097] train: loss: 0.0421175
[Epoch 13; Iter   966/ 1097] train: loss: 0.0553249
[Epoch 13; Iter   996/ 1097] train: loss: 0.0295519
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0522671
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1805001
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0788501
[Epoch 13] ogbg-molhiv: 0.761063 val loss: 0.079854
[Epoch 13] ogbg-molhiv: 0.754217 test loss: 0.152166
[Epoch 14; Iter    19/ 1097] train: loss: 0.1700591
[Epoch 14; Iter    49/ 1097] train: loss: 0.1427427
[Epoch 14; Iter    79/ 1097] train: loss: 0.0396224
[Epoch 14; Iter   109/ 1097] train: loss: 0.1034316
[Epoch 14; Iter   139/ 1097] train: loss: 0.0406961
[Epoch 14; Iter   169/ 1097] train: loss: 0.1923285
[Epoch 14; Iter   199/ 1097] train: loss: 0.0212031
[Epoch 14; Iter   229/ 1097] train: loss: 0.2739637
[Epoch 14; Iter   259/ 1097] train: loss: 0.1846347
[Epoch 14; Iter   289/ 1097] train: loss: 0.1687728
[Epoch 14; Iter   319/ 1097] train: loss: 0.0350614
[Epoch 14; Iter   349/ 1097] train: loss: 0.0377632
[Epoch 14; Iter   379/ 1097] train: loss: 0.0356060
[Epoch 14; Iter   409/ 1097] train: loss: 0.1256749
[Epoch 14; Iter   439/ 1097] train: loss: 0.2043775
[Epoch 14; Iter   469/ 1097] train: loss: 0.1605853
[Epoch 14; Iter   499/ 1097] train: loss: 0.0171059
[Epoch 14; Iter   529/ 1097] train: loss: 0.3438204
[Epoch 14; Iter   559/ 1097] train: loss: 0.0411467
[Epoch 14; Iter   589/ 1097] train: loss: 0.1024443
[Epoch 14; Iter   619/ 1097] train: loss: 0.2571181
[Epoch 14; Iter   649/ 1097] train: loss: 0.0343009
[Epoch 14; Iter   679/ 1097] train: loss: 0.0647060
[Epoch 14; Iter   709/ 1097] train: loss: 0.2701956
[Epoch 14; Iter   739/ 1097] train: loss: 0.1513834
[Epoch 14; Iter   769/ 1097] train: loss: 0.0265023
[Epoch 14; Iter   799/ 1097] train: loss: 0.0257778
[Epoch 14; Iter   829/ 1097] train: loss: 0.1168978
[Epoch 14; Iter   859/ 1097] train: loss: 0.0316116
[Epoch 14; Iter   889/ 1097] train: loss: 0.0861031
[Epoch 14; Iter   919/ 1097] train: loss: 0.1103775
[Epoch 14; Iter   949/ 1097] train: loss: 0.1665345
[Epoch 14; Iter   979/ 1097] train: loss: 0.0580592
[Epoch 14; Iter  1009/ 1097] train: loss: 0.1476547
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0306686
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0601468
[Epoch 14] ogbg-molhiv: 0.800488 val loss: 0.073671
[Epoch 14] ogbg-molhiv: 0.762605 test loss: 0.145173
[Epoch 15; Iter     2/ 1097] train: loss: 0.1062785
[Epoch 15; Iter    32/ 1097] train: loss: 0.0824431
[Epoch 15; Iter    62/ 1097] train: loss: 0.0883059
[Epoch 15; Iter    92/ 1097] train: loss: 0.0832080
[Epoch 15; Iter   122/ 1097] train: loss: 0.0940335
[Epoch 15; Iter   152/ 1097] train: loss: 0.0308138
[Epoch 15; Iter   182/ 1097] train: loss: 0.1320496
[Epoch 15; Iter   212/ 1097] train: loss: 0.2332060
[Epoch 15; Iter   242/ 1097] train: loss: 0.0639241
[Epoch 15; Iter   272/ 1097] train: loss: 0.3313204
[Epoch 15; Iter   302/ 1097] train: loss: 0.1578430
[Epoch 15; Iter   332/ 1097] train: loss: 0.2297201
[Epoch 15; Iter   362/ 1097] train: loss: 0.1588282
[Epoch 15; Iter   392/ 1097] train: loss: 0.1141884
[Epoch 15; Iter   422/ 1097] train: loss: 0.1114944
[Epoch 15; Iter   452/ 1097] train: loss: 0.0234240
[Epoch 15; Iter   482/ 1097] train: loss: 0.0972761
[Epoch 15; Iter   512/ 1097] train: loss: 0.3604389
[Epoch 15; Iter   542/ 1097] train: loss: 0.1360697
[Epoch 15; Iter   572/ 1097] train: loss: 0.0558705
[Epoch 15; Iter   602/ 1097] train: loss: 0.0306141
[Epoch 15; Iter   632/ 1097] train: loss: 0.2303791
[Epoch 15; Iter   662/ 1097] train: loss: 0.0761325
[Epoch 15; Iter   692/ 1097] train: loss: 0.0755751
[Epoch 15; Iter   722/ 1097] train: loss: 0.0810272
[Epoch 15; Iter   752/ 1097] train: loss: 0.0599089
[Epoch 15; Iter   782/ 1097] train: loss: 0.0525332
[Epoch 15; Iter   812/ 1097] train: loss: 0.0210908
[Epoch 15; Iter   842/ 1097] train: loss: 0.0427348
[Epoch 15; Iter   872/ 1097] train: loss: 0.0277133
[Epoch 15; Iter   902/ 1097] train: loss: 0.0331799
[Epoch 15; Iter   932/ 1097] train: loss: 0.2304861
[Epoch 15; Iter   962/ 1097] train: loss: 0.2421237
[Epoch 15; Iter   992/ 1097] train: loss: 0.0345627
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1592757
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1620415
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0316937
[Epoch 15] ogbg-molhiv: 0.752388 val loss: 0.076942
[Epoch 15] ogbg-molhiv: 0.745907 test loss: 0.120128
[Epoch 16; Iter    15/ 1097] train: loss: 0.0285383
[Epoch 16; Iter    45/ 1097] train: loss: 0.0990206
[Epoch 16; Iter    75/ 1097] train: loss: 0.1586754
[Epoch 16; Iter   105/ 1097] train: loss: 0.0323147
[Epoch 16; Iter   135/ 1097] train: loss: 0.0586364
[Epoch 16; Iter   165/ 1097] train: loss: 0.0923101
[Epoch 12; Iter   113/ 1097] train: loss: 0.0288216
[Epoch 12; Iter   143/ 1097] train: loss: 0.0385078
[Epoch 12; Iter   173/ 1097] train: loss: 0.3124463
[Epoch 12; Iter   203/ 1097] train: loss: 0.1517022
[Epoch 12; Iter   233/ 1097] train: loss: 0.3224278
[Epoch 12; Iter   263/ 1097] train: loss: 0.1930139
[Epoch 12; Iter   293/ 1097] train: loss: 0.1823001
[Epoch 12; Iter   323/ 1097] train: loss: 0.1128387
[Epoch 12; Iter   353/ 1097] train: loss: 0.0384002
[Epoch 12; Iter   383/ 1097] train: loss: 0.1316475
[Epoch 12; Iter   413/ 1097] train: loss: 0.0307628
[Epoch 12; Iter   443/ 1097] train: loss: 0.1126845
[Epoch 12; Iter   473/ 1097] train: loss: 0.0225977
[Epoch 12; Iter   503/ 1097] train: loss: 0.0734110
[Epoch 12; Iter   533/ 1097] train: loss: 0.1309486
[Epoch 12; Iter   563/ 1097] train: loss: 0.1377204
[Epoch 12; Iter   593/ 1097] train: loss: 0.2249758
[Epoch 12; Iter   623/ 1097] train: loss: 0.0407221
[Epoch 12; Iter   653/ 1097] train: loss: 0.0266732
[Epoch 12; Iter   683/ 1097] train: loss: 0.0305978
[Epoch 12; Iter   713/ 1097] train: loss: 0.2851392
[Epoch 12; Iter   743/ 1097] train: loss: 0.0407901
[Epoch 12; Iter   773/ 1097] train: loss: 0.2893449
[Epoch 12; Iter   803/ 1097] train: loss: 0.0664054
[Epoch 12; Iter   833/ 1097] train: loss: 0.0370882
[Epoch 12; Iter   863/ 1097] train: loss: 0.0297536
[Epoch 12; Iter   893/ 1097] train: loss: 0.0926312
[Epoch 12; Iter   923/ 1097] train: loss: 0.0273481
[Epoch 12; Iter   953/ 1097] train: loss: 0.0655739
[Epoch 12; Iter   983/ 1097] train: loss: 0.1564176
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0283505
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2657059
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1787043
[Epoch 12] ogbg-molhiv: 0.782986 val loss: 0.078425
[Epoch 12] ogbg-molhiv: 0.755505 test loss: 0.125631
[Epoch 13; Iter     6/ 1097] train: loss: 0.0924729
[Epoch 13; Iter    36/ 1097] train: loss: 0.0522465
[Epoch 13; Iter    66/ 1097] train: loss: 0.0591281
[Epoch 13; Iter    96/ 1097] train: loss: 0.0648867
[Epoch 13; Iter   126/ 1097] train: loss: 0.0213007
[Epoch 13; Iter   156/ 1097] train: loss: 0.3421127
[Epoch 13; Iter   186/ 1097] train: loss: 0.0681725
[Epoch 13; Iter   216/ 1097] train: loss: 0.1125416
[Epoch 13; Iter   246/ 1097] train: loss: 0.1793872
[Epoch 13; Iter   276/ 1097] train: loss: 0.0304106
[Epoch 13; Iter   306/ 1097] train: loss: 0.0243371
[Epoch 13; Iter   336/ 1097] train: loss: 0.0323133
[Epoch 13; Iter   366/ 1097] train: loss: 0.0432456
[Epoch 13; Iter   396/ 1097] train: loss: 0.3337122
[Epoch 13; Iter   426/ 1097] train: loss: 0.0924941
[Epoch 13; Iter   456/ 1097] train: loss: 0.1317549
[Epoch 13; Iter   486/ 1097] train: loss: 0.0336410
[Epoch 13; Iter   516/ 1097] train: loss: 0.1121089
[Epoch 13; Iter   546/ 1097] train: loss: 0.2556277
[Epoch 13; Iter   576/ 1097] train: loss: 0.2490609
[Epoch 13; Iter   606/ 1097] train: loss: 0.0491603
[Epoch 13; Iter   636/ 1097] train: loss: 0.1525434
[Epoch 13; Iter   666/ 1097] train: loss: 0.0298127
[Epoch 13; Iter   696/ 1097] train: loss: 0.1159881
[Epoch 13; Iter   726/ 1097] train: loss: 0.2889373
[Epoch 13; Iter   756/ 1097] train: loss: 0.1927608
[Epoch 13; Iter   786/ 1097] train: loss: 0.3875396
[Epoch 13; Iter   816/ 1097] train: loss: 0.4942551
[Epoch 13; Iter   846/ 1097] train: loss: 0.0401089
[Epoch 13; Iter   876/ 1097] train: loss: 0.0396087
[Epoch 13; Iter   906/ 1097] train: loss: 0.4593658
[Epoch 13; Iter   936/ 1097] train: loss: 0.0323752
[Epoch 13; Iter   966/ 1097] train: loss: 0.0735010
[Epoch 13; Iter   996/ 1097] train: loss: 0.0430315
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1900668
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0975313
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2733902
[Epoch 13] ogbg-molhiv: 0.776339 val loss: 0.076479
[Epoch 13] ogbg-molhiv: 0.731457 test loss: 0.124899
[Epoch 14; Iter    19/ 1097] train: loss: 0.0320395
[Epoch 14; Iter    49/ 1097] train: loss: 0.0415935
[Epoch 14; Iter    79/ 1097] train: loss: 0.2175248
[Epoch 14; Iter   109/ 1097] train: loss: 0.1722325
[Epoch 14; Iter   139/ 1097] train: loss: 0.0979550
[Epoch 14; Iter   169/ 1097] train: loss: 0.1352749
[Epoch 14; Iter   199/ 1097] train: loss: 0.0287449
[Epoch 14; Iter   229/ 1097] train: loss: 0.1041257
[Epoch 14; Iter   259/ 1097] train: loss: 0.0463130
[Epoch 14; Iter   289/ 1097] train: loss: 0.0817154
[Epoch 14; Iter   319/ 1097] train: loss: 0.1558213
[Epoch 14; Iter   349/ 1097] train: loss: 0.0317431
[Epoch 14; Iter   379/ 1097] train: loss: 0.0582749
[Epoch 14; Iter   409/ 1097] train: loss: 0.0433766
[Epoch 14; Iter   439/ 1097] train: loss: 0.1686425
[Epoch 14; Iter   469/ 1097] train: loss: 0.2180997
[Epoch 14; Iter   499/ 1097] train: loss: 0.0778226
[Epoch 14; Iter   529/ 1097] train: loss: 0.0357374
[Epoch 14; Iter   559/ 1097] train: loss: 0.2700171
[Epoch 14; Iter   589/ 1097] train: loss: 0.1281740
[Epoch 14; Iter   619/ 1097] train: loss: 0.1834569
[Epoch 14; Iter   649/ 1097] train: loss: 0.1599366
[Epoch 14; Iter   679/ 1097] train: loss: 0.0236260
[Epoch 14; Iter   709/ 1097] train: loss: 0.0675882
[Epoch 14; Iter   739/ 1097] train: loss: 0.0432363
[Epoch 14; Iter   769/ 1097] train: loss: 0.0285231
[Epoch 14; Iter   799/ 1097] train: loss: 0.0522509
[Epoch 14; Iter   829/ 1097] train: loss: 0.1923525
[Epoch 14; Iter   859/ 1097] train: loss: 0.1968409
[Epoch 14; Iter   889/ 1097] train: loss: 0.0238522
[Epoch 14; Iter   919/ 1097] train: loss: 0.0211430
[Epoch 14; Iter   949/ 1097] train: loss: 0.0370077
[Epoch 14; Iter   979/ 1097] train: loss: 0.2482114
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0494466
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2520829
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0369511
[Epoch 14] ogbg-molhiv: 0.788776 val loss: 0.134921
[Epoch 14] ogbg-molhiv: 0.696417 test loss: 0.130694
[Epoch 15; Iter     2/ 1097] train: loss: 0.0570535
[Epoch 15; Iter    32/ 1097] train: loss: 0.0236665
[Epoch 15; Iter    62/ 1097] train: loss: 0.0725670
[Epoch 15; Iter    92/ 1097] train: loss: 0.1201064
[Epoch 15; Iter   122/ 1097] train: loss: 0.0298340
[Epoch 15; Iter   152/ 1097] train: loss: 0.2039250
[Epoch 15; Iter   182/ 1097] train: loss: 0.0261345
[Epoch 15; Iter   212/ 1097] train: loss: 0.2134048
[Epoch 15; Iter   242/ 1097] train: loss: 0.0260650
[Epoch 15; Iter   272/ 1097] train: loss: 0.0592333
[Epoch 15; Iter   302/ 1097] train: loss: 0.2019606
[Epoch 15; Iter   332/ 1097] train: loss: 0.1171068
[Epoch 15; Iter   362/ 1097] train: loss: 0.1972597
[Epoch 15; Iter   392/ 1097] train: loss: 0.0516815
[Epoch 15; Iter   422/ 1097] train: loss: 0.0311338
[Epoch 15; Iter   452/ 1097] train: loss: 0.2971767
[Epoch 15; Iter   482/ 1097] train: loss: 0.0324629
[Epoch 15; Iter   512/ 1097] train: loss: 0.2782127
[Epoch 15; Iter   542/ 1097] train: loss: 0.0301154
[Epoch 15; Iter   572/ 1097] train: loss: 0.0942053
[Epoch 15; Iter   602/ 1097] train: loss: 0.0252406
[Epoch 15; Iter   632/ 1097] train: loss: 0.1099447
[Epoch 15; Iter   662/ 1097] train: loss: 0.1150915
[Epoch 15; Iter   692/ 1097] train: loss: 0.0545235
[Epoch 15; Iter   722/ 1097] train: loss: 0.3251877
[Epoch 15; Iter   752/ 1097] train: loss: 0.0947955
[Epoch 15; Iter   782/ 1097] train: loss: 0.0864976
[Epoch 15; Iter   812/ 1097] train: loss: 0.0377173
[Epoch 15; Iter   842/ 1097] train: loss: 0.1607721
[Epoch 15; Iter   872/ 1097] train: loss: 0.0433025
[Epoch 15; Iter   902/ 1097] train: loss: 0.1272310
[Epoch 15; Iter   932/ 1097] train: loss: 0.0196282
[Epoch 15; Iter   962/ 1097] train: loss: 0.1017164
[Epoch 15; Iter   992/ 1097] train: loss: 0.1012743
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5984543
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0276852
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0341167
[Epoch 15] ogbg-molhiv: 0.732075 val loss: 1.564267
[Epoch 15] ogbg-molhiv: 0.742956 test loss: 1.392158
[Epoch 16; Iter    15/ 1097] train: loss: 0.1823067
[Epoch 16; Iter    45/ 1097] train: loss: 0.0591655
[Epoch 16; Iter    75/ 1097] train: loss: 0.0456112
[Epoch 16; Iter   105/ 1097] train: loss: 0.0772852
[Epoch 16; Iter   135/ 1097] train: loss: 0.0704375
[Epoch 16; Iter   165/ 1097] train: loss: 0.4633839
[Epoch 12; Iter   113/ 1097] train: loss: 0.1390093
[Epoch 12; Iter   143/ 1097] train: loss: 0.2664618
[Epoch 12; Iter   173/ 1097] train: loss: 0.0521061
[Epoch 12; Iter   203/ 1097] train: loss: 0.0345374
[Epoch 12; Iter   233/ 1097] train: loss: 0.0342719
[Epoch 12; Iter   263/ 1097] train: loss: 0.1260169
[Epoch 12; Iter   293/ 1097] train: loss: 0.1963107
[Epoch 12; Iter   323/ 1097] train: loss: 0.1497583
[Epoch 12; Iter   353/ 1097] train: loss: 0.2440143
[Epoch 12; Iter   383/ 1097] train: loss: 0.0591023
[Epoch 12; Iter   413/ 1097] train: loss: 0.2872951
[Epoch 12; Iter   443/ 1097] train: loss: 0.2842952
[Epoch 12; Iter   473/ 1097] train: loss: 0.1132414
[Epoch 12; Iter   503/ 1097] train: loss: 0.2447974
[Epoch 12; Iter   533/ 1097] train: loss: 0.2108056
[Epoch 12; Iter   563/ 1097] train: loss: 0.1866136
[Epoch 12; Iter   593/ 1097] train: loss: 0.2703069
[Epoch 12; Iter   623/ 1097] train: loss: 0.2755045
[Epoch 12; Iter   653/ 1097] train: loss: 0.0397881
[Epoch 12; Iter   683/ 1097] train: loss: 0.1726433
[Epoch 12; Iter   713/ 1097] train: loss: 0.0320636
[Epoch 12; Iter   743/ 1097] train: loss: 0.2402435
[Epoch 12; Iter   773/ 1097] train: loss: 0.0758776
[Epoch 12; Iter   803/ 1097] train: loss: 0.1940882
[Epoch 12; Iter   833/ 1097] train: loss: 0.1213446
[Epoch 12; Iter   863/ 1097] train: loss: 0.2810492
[Epoch 12; Iter   893/ 1097] train: loss: 0.0267216
[Epoch 12; Iter   923/ 1097] train: loss: 0.2084921
[Epoch 12; Iter   953/ 1097] train: loss: 0.2210421
[Epoch 12; Iter   983/ 1097] train: loss: 0.0458791
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0380307
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1460501
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0790480
[Epoch 12] ogbg-molhiv: 0.769801 val loss: 0.081798
[Epoch 12] ogbg-molhiv: 0.745561 test loss: 0.120837
[Epoch 13; Iter     6/ 1097] train: loss: 0.1286683
[Epoch 13; Iter    36/ 1097] train: loss: 0.3635961
[Epoch 13; Iter    66/ 1097] train: loss: 0.0889257
[Epoch 13; Iter    96/ 1097] train: loss: 0.0372378
[Epoch 13; Iter   126/ 1097] train: loss: 0.0255724
[Epoch 13; Iter   156/ 1097] train: loss: 0.0275775
[Epoch 13; Iter   186/ 1097] train: loss: 0.1228431
[Epoch 13; Iter   216/ 1097] train: loss: 0.3757145
[Epoch 13; Iter   246/ 1097] train: loss: 0.0290948
[Epoch 13; Iter   276/ 1097] train: loss: 0.1307929
[Epoch 13; Iter   306/ 1097] train: loss: 0.0207460
[Epoch 13; Iter   336/ 1097] train: loss: 0.1684654
[Epoch 13; Iter   366/ 1097] train: loss: 0.1593872
[Epoch 13; Iter   396/ 1097] train: loss: 0.1121930
[Epoch 13; Iter   426/ 1097] train: loss: 0.0686542
[Epoch 13; Iter   456/ 1097] train: loss: 0.0406874
[Epoch 13; Iter   486/ 1097] train: loss: 0.0369082
[Epoch 13; Iter   516/ 1097] train: loss: 0.0450442
[Epoch 13; Iter   546/ 1097] train: loss: 0.0244750
[Epoch 13; Iter   576/ 1097] train: loss: 0.1745560
[Epoch 13; Iter   606/ 1097] train: loss: 0.0423357
[Epoch 13; Iter   636/ 1097] train: loss: 0.2982296
[Epoch 13; Iter   666/ 1097] train: loss: 0.0467294
[Epoch 13; Iter   696/ 1097] train: loss: 0.0455931
[Epoch 13; Iter   726/ 1097] train: loss: 0.1246077
[Epoch 13; Iter   756/ 1097] train: loss: 0.0448496
[Epoch 13; Iter   786/ 1097] train: loss: 0.1184072
[Epoch 13; Iter   816/ 1097] train: loss: 0.0282560
[Epoch 13; Iter   846/ 1097] train: loss: 0.0261013
[Epoch 13; Iter   876/ 1097] train: loss: 0.2009711
[Epoch 13; Iter   906/ 1097] train: loss: 0.3242878
[Epoch 13; Iter   936/ 1097] train: loss: 0.1775891
[Epoch 13; Iter   966/ 1097] train: loss: 0.1309812
[Epoch 13; Iter   996/ 1097] train: loss: 0.1049325
[Epoch 13; Iter  1026/ 1097] train: loss: 0.2857097
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1874054
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1910919
[Epoch 13] ogbg-molhiv: 0.769425 val loss: 0.078389
[Epoch 13] ogbg-molhiv: 0.766940 test loss: 0.113317
[Epoch 14; Iter    19/ 1097] train: loss: 0.0329185
[Epoch 14; Iter    49/ 1097] train: loss: 0.3126525
[Epoch 14; Iter    79/ 1097] train: loss: 0.0356984
[Epoch 14; Iter   109/ 1097] train: loss: 0.0229429
[Epoch 14; Iter   139/ 1097] train: loss: 0.1167309
[Epoch 14; Iter   169/ 1097] train: loss: 0.1666368
[Epoch 14; Iter   199/ 1097] train: loss: 0.0581671
[Epoch 14; Iter   229/ 1097] train: loss: 0.0245268
[Epoch 14; Iter   259/ 1097] train: loss: 0.0618843
[Epoch 14; Iter   289/ 1097] train: loss: 0.0899300
[Epoch 14; Iter   319/ 1097] train: loss: 0.2576416
[Epoch 14; Iter   349/ 1097] train: loss: 0.2914923
[Epoch 14; Iter   379/ 1097] train: loss: 0.2254698
[Epoch 14; Iter   409/ 1097] train: loss: 0.0601165
[Epoch 14; Iter   439/ 1097] train: loss: 0.1293411
[Epoch 14; Iter   469/ 1097] train: loss: 0.1355436
[Epoch 14; Iter   499/ 1097] train: loss: 0.0233678
[Epoch 14; Iter   529/ 1097] train: loss: 0.0434277
[Epoch 14; Iter   559/ 1097] train: loss: 0.1845655
[Epoch 14; Iter   589/ 1097] train: loss: 0.0292223
[Epoch 14; Iter   619/ 1097] train: loss: 0.0825182
[Epoch 14; Iter   649/ 1097] train: loss: 0.0317494
[Epoch 14; Iter   679/ 1097] train: loss: 0.1128341
[Epoch 14; Iter   709/ 1097] train: loss: 0.1168273
[Epoch 14; Iter   739/ 1097] train: loss: 0.1033816
[Epoch 14; Iter   769/ 1097] train: loss: 0.1563627
[Epoch 14; Iter   799/ 1097] train: loss: 0.0522641
[Epoch 14; Iter   829/ 1097] train: loss: 0.1003683
[Epoch 14; Iter   859/ 1097] train: loss: 0.0332702
[Epoch 14; Iter   889/ 1097] train: loss: 0.0268513
[Epoch 14; Iter   919/ 1097] train: loss: 0.0483432
[Epoch 14; Iter   949/ 1097] train: loss: 0.0251296
[Epoch 14; Iter   979/ 1097] train: loss: 0.1808281
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0226214
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0624736
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1258877
[Epoch 14] ogbg-molhiv: 0.749654 val loss: 0.092028
[Epoch 14] ogbg-molhiv: 0.680838 test loss: 0.132401
[Epoch 15; Iter     2/ 1097] train: loss: 0.1778265
[Epoch 15; Iter    32/ 1097] train: loss: 0.0405214
[Epoch 15; Iter    62/ 1097] train: loss: 0.2150103
[Epoch 15; Iter    92/ 1097] train: loss: 0.0316323
[Epoch 15; Iter   122/ 1097] train: loss: 0.2782572
[Epoch 15; Iter   152/ 1097] train: loss: 0.1653886
[Epoch 15; Iter   182/ 1097] train: loss: 0.1117691
[Epoch 15; Iter   212/ 1097] train: loss: 0.0250739
[Epoch 15; Iter   242/ 1097] train: loss: 0.0295969
[Epoch 15; Iter   272/ 1097] train: loss: 0.1148121
[Epoch 15; Iter   302/ 1097] train: loss: 0.1697859
[Epoch 15; Iter   332/ 1097] train: loss: 0.0291846
[Epoch 15; Iter   362/ 1097] train: loss: 0.1423073
[Epoch 15; Iter   392/ 1097] train: loss: 0.1750723
[Epoch 15; Iter   422/ 1097] train: loss: 0.1866745
[Epoch 15; Iter   452/ 1097] train: loss: 0.0624604
[Epoch 15; Iter   482/ 1097] train: loss: 0.1090189
[Epoch 15; Iter   512/ 1097] train: loss: 0.2696911
[Epoch 15; Iter   542/ 1097] train: loss: 0.0953213
[Epoch 15; Iter   572/ 1097] train: loss: 0.0282847
[Epoch 15; Iter   602/ 1097] train: loss: 0.3531075
[Epoch 15; Iter   632/ 1097] train: loss: 0.0340172
[Epoch 15; Iter   662/ 1097] train: loss: 0.1510525
[Epoch 15; Iter   692/ 1097] train: loss: 0.0256332
[Epoch 15; Iter   722/ 1097] train: loss: 0.0957453
[Epoch 15; Iter   752/ 1097] train: loss: 0.2181237
[Epoch 15; Iter   782/ 1097] train: loss: 0.1212236
[Epoch 15; Iter   812/ 1097] train: loss: 0.0630862
[Epoch 15; Iter   842/ 1097] train: loss: 0.0232680
[Epoch 15; Iter   872/ 1097] train: loss: 0.0427473
[Epoch 15; Iter   902/ 1097] train: loss: 0.2451216
[Epoch 15; Iter   932/ 1097] train: loss: 0.0344876
[Epoch 15; Iter   962/ 1097] train: loss: 0.0280811
[Epoch 15; Iter   992/ 1097] train: loss: 0.0398289
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0187504
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1101844
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0359256
[Epoch 15] ogbg-molhiv: 0.755741 val loss: 1.517864
[Epoch 15] ogbg-molhiv: 0.768881 test loss: 0.532555
[Epoch 16; Iter    15/ 1097] train: loss: 0.0413479
[Epoch 16; Iter    45/ 1097] train: loss: 0.0263390
[Epoch 16; Iter    75/ 1097] train: loss: 0.0262079
[Epoch 16; Iter   105/ 1097] train: loss: 0.0175999
[Epoch 16; Iter   135/ 1097] train: loss: 0.0214874
[Epoch 16; Iter   165/ 1097] train: loss: 0.3169514
[Epoch 12; Iter   113/ 1097] train: loss: 0.0242548
[Epoch 12; Iter   143/ 1097] train: loss: 0.0798818
[Epoch 12; Iter   173/ 1097] train: loss: 0.3286276
[Epoch 12; Iter   203/ 1097] train: loss: 0.1027573
[Epoch 12; Iter   233/ 1097] train: loss: 0.3222765
[Epoch 12; Iter   263/ 1097] train: loss: 0.1844991
[Epoch 12; Iter   293/ 1097] train: loss: 0.1888041
[Epoch 12; Iter   323/ 1097] train: loss: 0.1027610
[Epoch 12; Iter   353/ 1097] train: loss: 0.0416380
[Epoch 12; Iter   383/ 1097] train: loss: 0.1251756
[Epoch 12; Iter   413/ 1097] train: loss: 0.0271198
[Epoch 12; Iter   443/ 1097] train: loss: 0.1422266
[Epoch 12; Iter   473/ 1097] train: loss: 0.0395197
[Epoch 12; Iter   503/ 1097] train: loss: 0.0747507
[Epoch 12; Iter   533/ 1097] train: loss: 0.1890976
[Epoch 12; Iter   563/ 1097] train: loss: 0.1746910
[Epoch 12; Iter   593/ 1097] train: loss: 0.3442096
[Epoch 12; Iter   623/ 1097] train: loss: 0.0509502
[Epoch 12; Iter   653/ 1097] train: loss: 0.0335362
[Epoch 12; Iter   683/ 1097] train: loss: 0.0418882
[Epoch 12; Iter   713/ 1097] train: loss: 0.2057497
[Epoch 12; Iter   743/ 1097] train: loss: 0.0348190
[Epoch 12; Iter   773/ 1097] train: loss: 0.2879215
[Epoch 12; Iter   803/ 1097] train: loss: 0.0953726
[Epoch 12; Iter   833/ 1097] train: loss: 0.0341148
[Epoch 12; Iter   863/ 1097] train: loss: 0.0375450
[Epoch 12; Iter   893/ 1097] train: loss: 0.0864281
[Epoch 12; Iter   923/ 1097] train: loss: 0.0486436
[Epoch 12; Iter   953/ 1097] train: loss: 0.0590267
[Epoch 12; Iter   983/ 1097] train: loss: 0.1638545
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0298391
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2444122
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1729128
[Epoch 12] ogbg-molhiv: 0.757324 val loss: 0.230689
[Epoch 12] ogbg-molhiv: 0.745186 test loss: 0.225619
[Epoch 13; Iter     6/ 1097] train: loss: 0.1051615
[Epoch 13; Iter    36/ 1097] train: loss: 0.0366682
[Epoch 13; Iter    66/ 1097] train: loss: 0.0478998
[Epoch 13; Iter    96/ 1097] train: loss: 0.0592393
[Epoch 13; Iter   126/ 1097] train: loss: 0.0272292
[Epoch 13; Iter   156/ 1097] train: loss: 0.2915224
[Epoch 13; Iter   186/ 1097] train: loss: 0.1128164
[Epoch 13; Iter   216/ 1097] train: loss: 0.1472225
[Epoch 13; Iter   246/ 1097] train: loss: 0.2005569
[Epoch 13; Iter   276/ 1097] train: loss: 0.0352505
[Epoch 13; Iter   306/ 1097] train: loss: 0.0242427
[Epoch 13; Iter   336/ 1097] train: loss: 0.0312186
[Epoch 13; Iter   366/ 1097] train: loss: 0.0473146
[Epoch 13; Iter   396/ 1097] train: loss: 0.2540088
[Epoch 13; Iter   426/ 1097] train: loss: 0.0403161
[Epoch 13; Iter   456/ 1097] train: loss: 0.1859384
[Epoch 13; Iter   486/ 1097] train: loss: 0.0359321
[Epoch 13; Iter   516/ 1097] train: loss: 0.1439333
[Epoch 13; Iter   546/ 1097] train: loss: 0.2411873
[Epoch 13; Iter   576/ 1097] train: loss: 0.2019230
[Epoch 13; Iter   606/ 1097] train: loss: 0.0311212
[Epoch 13; Iter   636/ 1097] train: loss: 0.1780959
[Epoch 13; Iter   666/ 1097] train: loss: 0.0379415
[Epoch 13; Iter   696/ 1097] train: loss: 0.1346246
[Epoch 13; Iter   726/ 1097] train: loss: 0.3517684
[Epoch 13; Iter   756/ 1097] train: loss: 0.1731390
[Epoch 13; Iter   786/ 1097] train: loss: 0.4638869
[Epoch 13; Iter   816/ 1097] train: loss: 0.5019176
[Epoch 13; Iter   846/ 1097] train: loss: 0.0648875
[Epoch 13; Iter   876/ 1097] train: loss: 0.0457276
[Epoch 13; Iter   906/ 1097] train: loss: 0.2683614
[Epoch 13; Iter   936/ 1097] train: loss: 0.0278859
[Epoch 13; Iter   966/ 1097] train: loss: 0.1415245
[Epoch 13; Iter   996/ 1097] train: loss: 0.1562568
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1662167
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0954095
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1928539
[Epoch 13] ogbg-molhiv: 0.785727 val loss: 0.127194
[Epoch 13] ogbg-molhiv: 0.756635 test loss: 0.134862
[Epoch 14; Iter    19/ 1097] train: loss: 0.0347542
[Epoch 14; Iter    49/ 1097] train: loss: 0.0306889
[Epoch 14; Iter    79/ 1097] train: loss: 0.2165541
[Epoch 14; Iter   109/ 1097] train: loss: 0.1620959
[Epoch 14; Iter   139/ 1097] train: loss: 0.0624134
[Epoch 14; Iter   169/ 1097] train: loss: 0.2302963
[Epoch 14; Iter   199/ 1097] train: loss: 0.0278536
[Epoch 14; Iter   229/ 1097] train: loss: 0.1675453
[Epoch 14; Iter   259/ 1097] train: loss: 0.0897274
[Epoch 14; Iter   289/ 1097] train: loss: 0.1889344
[Epoch 14; Iter   319/ 1097] train: loss: 0.1472795
[Epoch 14; Iter   349/ 1097] train: loss: 0.0306240
[Epoch 14; Iter   379/ 1097] train: loss: 0.1094518
[Epoch 14; Iter   409/ 1097] train: loss: 0.0332571
[Epoch 14; Iter   439/ 1097] train: loss: 0.1900694
[Epoch 14; Iter   469/ 1097] train: loss: 0.1868489
[Epoch 14; Iter   499/ 1097] train: loss: 0.1124845
[Epoch 14; Iter   529/ 1097] train: loss: 0.0417531
[Epoch 14; Iter   559/ 1097] train: loss: 0.3148053
[Epoch 14; Iter   589/ 1097] train: loss: 0.2065316
[Epoch 14; Iter   619/ 1097] train: loss: 0.1905410
[Epoch 14; Iter   649/ 1097] train: loss: 0.2315968
[Epoch 14; Iter   679/ 1097] train: loss: 0.0280035
[Epoch 14; Iter   709/ 1097] train: loss: 0.0949754
[Epoch 14; Iter   739/ 1097] train: loss: 0.0765615
[Epoch 14; Iter   769/ 1097] train: loss: 0.0248323
[Epoch 14; Iter   799/ 1097] train: loss: 0.0527648
[Epoch 14; Iter   829/ 1097] train: loss: 0.1042483
[Epoch 14; Iter   859/ 1097] train: loss: 0.2865192
[Epoch 14; Iter   889/ 1097] train: loss: 0.0353729
[Epoch 14; Iter   919/ 1097] train: loss: 0.0242396
[Epoch 14; Iter   949/ 1097] train: loss: 0.0212563
[Epoch 14; Iter   979/ 1097] train: loss: 0.3226410
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0614393
[Epoch 14; Iter  1039/ 1097] train: loss: 0.1920397
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0382714
[Epoch 14] ogbg-molhiv: 0.754403 val loss: 0.084495
[Epoch 14] ogbg-molhiv: 0.667921 test loss: 0.307026
[Epoch 15; Iter     2/ 1097] train: loss: 0.1039993
[Epoch 15; Iter    32/ 1097] train: loss: 0.0255620
[Epoch 15; Iter    62/ 1097] train: loss: 0.1262636
[Epoch 15; Iter    92/ 1097] train: loss: 0.0620593
[Epoch 15; Iter   122/ 1097] train: loss: 0.0224121
[Epoch 15; Iter   152/ 1097] train: loss: 0.1714097
[Epoch 15; Iter   182/ 1097] train: loss: 0.0307205
[Epoch 15; Iter   212/ 1097] train: loss: 0.2191386
[Epoch 15; Iter   242/ 1097] train: loss: 0.0587680
[Epoch 15; Iter   272/ 1097] train: loss: 0.2325326
[Epoch 15; Iter   302/ 1097] train: loss: 0.2207726
[Epoch 15; Iter   332/ 1097] train: loss: 0.0366380
[Epoch 15; Iter   362/ 1097] train: loss: 0.1874194
[Epoch 15; Iter   392/ 1097] train: loss: 0.0574730
[Epoch 15; Iter   422/ 1097] train: loss: 0.0323013
[Epoch 15; Iter   452/ 1097] train: loss: 0.2351004
[Epoch 15; Iter   482/ 1097] train: loss: 0.0593908
[Epoch 15; Iter   512/ 1097] train: loss: 0.1989561
[Epoch 15; Iter   542/ 1097] train: loss: 0.0517161
[Epoch 15; Iter   572/ 1097] train: loss: 0.1155161
[Epoch 15; Iter   602/ 1097] train: loss: 0.0262136
[Epoch 15; Iter   632/ 1097] train: loss: 0.1324843
[Epoch 15; Iter   662/ 1097] train: loss: 0.1457476
[Epoch 15; Iter   692/ 1097] train: loss: 0.0603069
[Epoch 15; Iter   722/ 1097] train: loss: 0.3346628
[Epoch 15; Iter   752/ 1097] train: loss: 0.1087519
[Epoch 15; Iter   782/ 1097] train: loss: 0.1074982
[Epoch 15; Iter   812/ 1097] train: loss: 0.0264140
[Epoch 15; Iter   842/ 1097] train: loss: 0.2349059
[Epoch 15; Iter   872/ 1097] train: loss: 0.0393774
[Epoch 15; Iter   902/ 1097] train: loss: 0.1286911
[Epoch 15; Iter   932/ 1097] train: loss: 0.0245355
[Epoch 15; Iter   962/ 1097] train: loss: 0.0709449
[Epoch 15; Iter   992/ 1097] train: loss: 0.1444917
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4764712
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0311472
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0536053
[Epoch 15] ogbg-molhiv: 0.738460 val loss: 0.082506
[Epoch 15] ogbg-molhiv: 0.743017 test loss: 0.120717
[Epoch 16; Iter    15/ 1097] train: loss: 0.1191394
[Epoch 16; Iter    45/ 1097] train: loss: 0.0399013
[Epoch 16; Iter    75/ 1097] train: loss: 0.0779965
[Epoch 16; Iter   105/ 1097] train: loss: 0.1109999
[Epoch 16; Iter   135/ 1097] train: loss: 0.1207168
[Epoch 16; Iter   165/ 1097] train: loss: 0.5092428
[Epoch 12; Iter   113/ 1097] train: loss: 0.0716917
[Epoch 12; Iter   143/ 1097] train: loss: 0.1958630
[Epoch 12; Iter   173/ 1097] train: loss: 0.0233067
[Epoch 12; Iter   203/ 1097] train: loss: 0.1104867
[Epoch 12; Iter   233/ 1097] train: loss: 0.0230110
[Epoch 12; Iter   263/ 1097] train: loss: 0.0700954
[Epoch 12; Iter   293/ 1097] train: loss: 0.2028597
[Epoch 12; Iter   323/ 1097] train: loss: 0.1930595
[Epoch 12; Iter   353/ 1097] train: loss: 0.1071412
[Epoch 12; Iter   383/ 1097] train: loss: 0.0299216
[Epoch 12; Iter   413/ 1097] train: loss: 0.1000765
[Epoch 12; Iter   443/ 1097] train: loss: 0.0362171
[Epoch 12; Iter   473/ 1097] train: loss: 0.2960454
[Epoch 12; Iter   503/ 1097] train: loss: 0.2358423
[Epoch 12; Iter   533/ 1097] train: loss: 0.0340271
[Epoch 12; Iter   563/ 1097] train: loss: 0.1158086
[Epoch 12; Iter   593/ 1097] train: loss: 0.1829818
[Epoch 12; Iter   623/ 1097] train: loss: 0.0304003
[Epoch 12; Iter   653/ 1097] train: loss: 0.1122527
[Epoch 12; Iter   683/ 1097] train: loss: 0.2645319
[Epoch 12; Iter   713/ 1097] train: loss: 0.1637701
[Epoch 12; Iter   743/ 1097] train: loss: 0.0304068
[Epoch 12; Iter   773/ 1097] train: loss: 0.1193296
[Epoch 12; Iter   803/ 1097] train: loss: 0.1967579
[Epoch 12; Iter   833/ 1097] train: loss: 0.0974241
[Epoch 12; Iter   863/ 1097] train: loss: 0.0508972
[Epoch 12; Iter   893/ 1097] train: loss: 0.1352554
[Epoch 12; Iter   923/ 1097] train: loss: 0.0448190
[Epoch 12; Iter   953/ 1097] train: loss: 0.2050647
[Epoch 12; Iter   983/ 1097] train: loss: 0.2628649
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0309532
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0273903
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0254342
[Epoch 12] ogbg-molhiv: 0.809508 val loss: 0.113138
[Epoch 12] ogbg-molhiv: 0.736795 test loss: 0.202713
[Epoch 13; Iter     6/ 1097] train: loss: 0.1688969
[Epoch 13; Iter    36/ 1097] train: loss: 0.1798908
[Epoch 13; Iter    66/ 1097] train: loss: 0.1350870
[Epoch 13; Iter    96/ 1097] train: loss: 0.0392783
[Epoch 13; Iter   126/ 1097] train: loss: 0.0589941
[Epoch 13; Iter   156/ 1097] train: loss: 0.2411194
[Epoch 13; Iter   186/ 1097] train: loss: 0.2386062
[Epoch 13; Iter   216/ 1097] train: loss: 0.1809853
[Epoch 13; Iter   246/ 1097] train: loss: 0.0272865
[Epoch 13; Iter   276/ 1097] train: loss: 0.0236424
[Epoch 13; Iter   306/ 1097] train: loss: 0.3638504
[Epoch 13; Iter   336/ 1097] train: loss: 0.1626884
[Epoch 13; Iter   366/ 1097] train: loss: 0.3471724
[Epoch 13; Iter   396/ 1097] train: loss: 0.0734034
[Epoch 13; Iter   426/ 1097] train: loss: 0.1033095
[Epoch 13; Iter   456/ 1097] train: loss: 0.1968955
[Epoch 13; Iter   486/ 1097] train: loss: 0.0362071
[Epoch 13; Iter   516/ 1097] train: loss: 0.2534140
[Epoch 13; Iter   546/ 1097] train: loss: 0.0249190
[Epoch 13; Iter   576/ 1097] train: loss: 0.1201141
[Epoch 13; Iter   606/ 1097] train: loss: 0.1988830
[Epoch 13; Iter   636/ 1097] train: loss: 0.0515130
[Epoch 13; Iter   666/ 1097] train: loss: 0.1623462
[Epoch 13; Iter   696/ 1097] train: loss: 0.3911507
[Epoch 13; Iter   726/ 1097] train: loss: 0.0627249
[Epoch 13; Iter   756/ 1097] train: loss: 0.0445738
[Epoch 13; Iter   786/ 1097] train: loss: 0.2493889
[Epoch 13; Iter   816/ 1097] train: loss: 0.0942245
[Epoch 13; Iter   846/ 1097] train: loss: 0.0340436
[Epoch 13; Iter   876/ 1097] train: loss: 0.2356714
[Epoch 13; Iter   906/ 1097] train: loss: 0.3014815
[Epoch 13; Iter   936/ 1097] train: loss: 0.0344672
[Epoch 13; Iter   966/ 1097] train: loss: 0.0377318
[Epoch 13; Iter   996/ 1097] train: loss: 0.0736433
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0451441
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2681006
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1825693
[Epoch 13] ogbg-molhiv: 0.703903 val loss: 0.100050
[Epoch 13] ogbg-molhiv: 0.711433 test loss: 0.254087
[Epoch 14; Iter    19/ 1097] train: loss: 0.2209722
[Epoch 14; Iter    49/ 1097] train: loss: 0.1723024
[Epoch 14; Iter    79/ 1097] train: loss: 0.0579011
[Epoch 14; Iter   109/ 1097] train: loss: 0.0977397
[Epoch 14; Iter   139/ 1097] train: loss: 0.0304377
[Epoch 14; Iter   169/ 1097] train: loss: 0.1480336
[Epoch 14; Iter   199/ 1097] train: loss: 0.0197630
[Epoch 14; Iter   229/ 1097] train: loss: 0.3763798
[Epoch 14; Iter   259/ 1097] train: loss: 0.3134212
[Epoch 14; Iter   289/ 1097] train: loss: 0.1722035
[Epoch 14; Iter   319/ 1097] train: loss: 0.0317732
[Epoch 14; Iter   349/ 1097] train: loss: 0.0279147
[Epoch 14; Iter   379/ 1097] train: loss: 0.0362537
[Epoch 14; Iter   409/ 1097] train: loss: 0.0633528
[Epoch 14; Iter   439/ 1097] train: loss: 0.2857481
[Epoch 14; Iter   469/ 1097] train: loss: 0.2280374
[Epoch 14; Iter   499/ 1097] train: loss: 0.0241207
[Epoch 14; Iter   529/ 1097] train: loss: 0.3056030
[Epoch 14; Iter   559/ 1097] train: loss: 0.0338999
[Epoch 14; Iter   589/ 1097] train: loss: 0.0959373
[Epoch 14; Iter   619/ 1097] train: loss: 0.1957348
[Epoch 14; Iter   649/ 1097] train: loss: 0.0615275
[Epoch 14; Iter   679/ 1097] train: loss: 0.0311209
[Epoch 14; Iter   709/ 1097] train: loss: 0.2365270
[Epoch 14; Iter   739/ 1097] train: loss: 0.2251540
[Epoch 14; Iter   769/ 1097] train: loss: 0.0246146
[Epoch 14; Iter   799/ 1097] train: loss: 0.0256802
[Epoch 14; Iter   829/ 1097] train: loss: 0.1338388
[Epoch 14; Iter   859/ 1097] train: loss: 0.0265049
[Epoch 14; Iter   889/ 1097] train: loss: 0.0857778
[Epoch 14; Iter   919/ 1097] train: loss: 0.1366073
[Epoch 14; Iter   949/ 1097] train: loss: 0.1548421
[Epoch 14; Iter   979/ 1097] train: loss: 0.0969536
[Epoch 14; Iter  1009/ 1097] train: loss: 0.1967096
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0295759
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0838841
[Epoch 14] ogbg-molhiv: 0.786259 val loss: 0.080119
[Epoch 14] ogbg-molhiv: 0.726188 test loss: 0.143750
[Epoch 15; Iter     2/ 1097] train: loss: 0.1893164
[Epoch 15; Iter    32/ 1097] train: loss: 0.0819136
[Epoch 15; Iter    62/ 1097] train: loss: 0.0653604
[Epoch 15; Iter    92/ 1097] train: loss: 0.0505921
[Epoch 15; Iter   122/ 1097] train: loss: 0.0459019
[Epoch 15; Iter   152/ 1097] train: loss: 0.0280849
[Epoch 15; Iter   182/ 1097] train: loss: 0.1490687
[Epoch 15; Iter   212/ 1097] train: loss: 0.1502144
[Epoch 15; Iter   242/ 1097] train: loss: 0.1045144
[Epoch 15; Iter   272/ 1097] train: loss: 0.3474897
[Epoch 15; Iter   302/ 1097] train: loss: 0.1789450
[Epoch 15; Iter   332/ 1097] train: loss: 0.1737378
[Epoch 15; Iter   362/ 1097] train: loss: 0.1440689
[Epoch 15; Iter   392/ 1097] train: loss: 0.1516277
[Epoch 15; Iter   422/ 1097] train: loss: 0.0493595
[Epoch 15; Iter   452/ 1097] train: loss: 0.0393675
[Epoch 15; Iter   482/ 1097] train: loss: 0.1339858
[Epoch 15; Iter   512/ 1097] train: loss: 0.3635270
[Epoch 15; Iter   542/ 1097] train: loss: 0.1303006
[Epoch 15; Iter   572/ 1097] train: loss: 0.0539669
[Epoch 15; Iter   602/ 1097] train: loss: 0.0303549
[Epoch 15; Iter   632/ 1097] train: loss: 0.2458889
[Epoch 15; Iter   662/ 1097] train: loss: 0.0931436
[Epoch 15; Iter   692/ 1097] train: loss: 0.1511692
[Epoch 15; Iter   722/ 1097] train: loss: 0.0714907
[Epoch 15; Iter   752/ 1097] train: loss: 0.0638091
[Epoch 15; Iter   782/ 1097] train: loss: 0.0497771
[Epoch 15; Iter   812/ 1097] train: loss: 0.0373175
[Epoch 15; Iter   842/ 1097] train: loss: 0.0862309
[Epoch 15; Iter   872/ 1097] train: loss: 0.0261587
[Epoch 15; Iter   902/ 1097] train: loss: 0.0318615
[Epoch 15; Iter   932/ 1097] train: loss: 0.1598459
[Epoch 15; Iter   962/ 1097] train: loss: 0.3007174
[Epoch 15; Iter   992/ 1097] train: loss: 0.0293011
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1127393
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1054168
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0225707
[Epoch 15] ogbg-molhiv: 0.759265 val loss: 0.180946
[Epoch 15] ogbg-molhiv: 0.715336 test loss: 0.141012
[Epoch 16; Iter    15/ 1097] train: loss: 0.0249492
[Epoch 16; Iter    45/ 1097] train: loss: 0.1307972
[Epoch 16; Iter    75/ 1097] train: loss: 0.3056586
[Epoch 16; Iter   105/ 1097] train: loss: 0.0282560
[Epoch 16; Iter   135/ 1097] train: loss: 0.0844119
[Epoch 16; Iter   165/ 1097] train: loss: 0.1962242
[Epoch 12; Iter   113/ 1097] train: loss: 0.0906253
[Epoch 12; Iter   143/ 1097] train: loss: 0.1622970
[Epoch 12; Iter   173/ 1097] train: loss: 0.0206781
[Epoch 12; Iter   203/ 1097] train: loss: 0.1950515
[Epoch 12; Iter   233/ 1097] train: loss: 0.0192352
[Epoch 12; Iter   263/ 1097] train: loss: 0.0360391
[Epoch 12; Iter   293/ 1097] train: loss: 0.1620037
[Epoch 12; Iter   323/ 1097] train: loss: 0.1114337
[Epoch 12; Iter   353/ 1097] train: loss: 0.0676850
[Epoch 12; Iter   383/ 1097] train: loss: 0.0237613
[Epoch 12; Iter   413/ 1097] train: loss: 0.0551662
[Epoch 12; Iter   443/ 1097] train: loss: 0.0209756
[Epoch 12; Iter   473/ 1097] train: loss: 0.2230292
[Epoch 12; Iter   503/ 1097] train: loss: 0.2342771
[Epoch 12; Iter   533/ 1097] train: loss: 0.0390513
[Epoch 12; Iter   563/ 1097] train: loss: 0.0806986
[Epoch 12; Iter   593/ 1097] train: loss: 0.1725202
[Epoch 12; Iter   623/ 1097] train: loss: 0.0352025
[Epoch 12; Iter   653/ 1097] train: loss: 0.0895063
[Epoch 12; Iter   683/ 1097] train: loss: 0.3508806
[Epoch 12; Iter   713/ 1097] train: loss: 0.0656186
[Epoch 12; Iter   743/ 1097] train: loss: 0.0269995
[Epoch 12; Iter   773/ 1097] train: loss: 0.1341986
[Epoch 12; Iter   803/ 1097] train: loss: 0.1928561
[Epoch 12; Iter   833/ 1097] train: loss: 0.1548917
[Epoch 12; Iter   863/ 1097] train: loss: 0.0783795
[Epoch 12; Iter   893/ 1097] train: loss: 0.2033621
[Epoch 12; Iter   923/ 1097] train: loss: 0.0362958
[Epoch 12; Iter   953/ 1097] train: loss: 0.2038927
[Epoch 12; Iter   983/ 1097] train: loss: 0.2036482
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0296496
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0285939
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0235388
[Epoch 12] ogbg-molhiv: 0.819493 val loss: 0.250302
[Epoch 12] ogbg-molhiv: 0.771429 test loss: 0.113424
[Epoch 13; Iter     6/ 1097] train: loss: 0.2040743
[Epoch 13; Iter    36/ 1097] train: loss: 0.1388658
[Epoch 13; Iter    66/ 1097] train: loss: 0.1403473
[Epoch 13; Iter    96/ 1097] train: loss: 0.0335456
[Epoch 13; Iter   126/ 1097] train: loss: 0.0656038
[Epoch 13; Iter   156/ 1097] train: loss: 0.2066894
[Epoch 13; Iter   186/ 1097] train: loss: 0.2319524
[Epoch 13; Iter   216/ 1097] train: loss: 0.1872715
[Epoch 13; Iter   246/ 1097] train: loss: 0.0380422
[Epoch 13; Iter   276/ 1097] train: loss: 0.0281246
[Epoch 13; Iter   306/ 1097] train: loss: 0.3419176
[Epoch 13; Iter   336/ 1097] train: loss: 0.1019693
[Epoch 13; Iter   366/ 1097] train: loss: 0.3687619
[Epoch 13; Iter   396/ 1097] train: loss: 0.0498201
[Epoch 13; Iter   426/ 1097] train: loss: 0.1312225
[Epoch 13; Iter   456/ 1097] train: loss: 0.1348459
[Epoch 13; Iter   486/ 1097] train: loss: 0.0342065
[Epoch 13; Iter   516/ 1097] train: loss: 0.1465322
[Epoch 13; Iter   546/ 1097] train: loss: 0.0422560
[Epoch 13; Iter   576/ 1097] train: loss: 0.0554603
[Epoch 13; Iter   606/ 1097] train: loss: 0.2570162
[Epoch 13; Iter   636/ 1097] train: loss: 0.0652432
[Epoch 13; Iter   666/ 1097] train: loss: 0.2029050
[Epoch 13; Iter   696/ 1097] train: loss: 0.4843506
[Epoch 13; Iter   726/ 1097] train: loss: 0.0743429
[Epoch 13; Iter   756/ 1097] train: loss: 0.0459269
[Epoch 13; Iter   786/ 1097] train: loss: 0.1280212
[Epoch 13; Iter   816/ 1097] train: loss: 0.0825811
[Epoch 13; Iter   846/ 1097] train: loss: 0.0321849
[Epoch 13; Iter   876/ 1097] train: loss: 0.1784903
[Epoch 13; Iter   906/ 1097] train: loss: 0.3104017
[Epoch 13; Iter   936/ 1097] train: loss: 0.0554002
[Epoch 13; Iter   966/ 1097] train: loss: 0.0543857
[Epoch 13; Iter   996/ 1097] train: loss: 0.0272258
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0220583
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1760949
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1581784
[Epoch 13] ogbg-molhiv: 0.816205 val loss: 0.159456
[Epoch 13] ogbg-molhiv: 0.781044 test loss: 0.116924
[Epoch 14; Iter    19/ 1097] train: loss: 0.1959428
[Epoch 14; Iter    49/ 1097] train: loss: 0.1840277
[Epoch 14; Iter    79/ 1097] train: loss: 0.0378114
[Epoch 14; Iter   109/ 1097] train: loss: 0.0920380
[Epoch 14; Iter   139/ 1097] train: loss: 0.0273346
[Epoch 14; Iter   169/ 1097] train: loss: 0.1866849
[Epoch 14; Iter   199/ 1097] train: loss: 0.0486192
[Epoch 14; Iter   229/ 1097] train: loss: 0.3128506
[Epoch 14; Iter   259/ 1097] train: loss: 0.1907983
[Epoch 14; Iter   289/ 1097] train: loss: 0.1361027
[Epoch 14; Iter   319/ 1097] train: loss: 0.0310378
[Epoch 14; Iter   349/ 1097] train: loss: 0.0776011
[Epoch 14; Iter   379/ 1097] train: loss: 0.0320988
[Epoch 14; Iter   409/ 1097] train: loss: 0.1581913
[Epoch 14; Iter   439/ 1097] train: loss: 0.2377228
[Epoch 14; Iter   469/ 1097] train: loss: 0.1817821
[Epoch 14; Iter   499/ 1097] train: loss: 0.0223499
[Epoch 14; Iter   529/ 1097] train: loss: 0.1880758
[Epoch 14; Iter   559/ 1097] train: loss: 0.0364232
[Epoch 14; Iter   589/ 1097] train: loss: 0.1237253
[Epoch 14; Iter   619/ 1097] train: loss: 0.2515815
[Epoch 14; Iter   649/ 1097] train: loss: 0.0339574
[Epoch 14; Iter   679/ 1097] train: loss: 0.0572334
[Epoch 14; Iter   709/ 1097] train: loss: 0.2811130
[Epoch 14; Iter   739/ 1097] train: loss: 0.1846337
[Epoch 14; Iter   769/ 1097] train: loss: 0.0284376
[Epoch 14; Iter   799/ 1097] train: loss: 0.0180403
[Epoch 14; Iter   829/ 1097] train: loss: 0.0920103
[Epoch 14; Iter   859/ 1097] train: loss: 0.0550459
[Epoch 14; Iter   889/ 1097] train: loss: 0.0703757
[Epoch 14; Iter   919/ 1097] train: loss: 0.1438831
[Epoch 14; Iter   949/ 1097] train: loss: 0.1253674
[Epoch 14; Iter   979/ 1097] train: loss: 0.0699150
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2062445
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0254968
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0446270
[Epoch 14] ogbg-molhiv: 0.782242 val loss: 0.329819
[Epoch 14] ogbg-molhiv: 0.797702 test loss: 0.117865
[Epoch 15; Iter     2/ 1097] train: loss: 0.1606359
[Epoch 15; Iter    32/ 1097] train: loss: 0.1172975
[Epoch 15; Iter    62/ 1097] train: loss: 0.0646335
[Epoch 15; Iter    92/ 1097] train: loss: 0.0741567
[Epoch 15; Iter   122/ 1097] train: loss: 0.1003832
[Epoch 15; Iter   152/ 1097] train: loss: 0.0221979
[Epoch 15; Iter   182/ 1097] train: loss: 0.1601055
[Epoch 15; Iter   212/ 1097] train: loss: 0.2541396
[Epoch 15; Iter   242/ 1097] train: loss: 0.1145300
[Epoch 15; Iter   272/ 1097] train: loss: 0.2641690
[Epoch 15; Iter   302/ 1097] train: loss: 0.1555787
[Epoch 15; Iter   332/ 1097] train: loss: 0.2651690
[Epoch 15; Iter   362/ 1097] train: loss: 0.1825398
[Epoch 15; Iter   392/ 1097] train: loss: 0.1765134
[Epoch 15; Iter   422/ 1097] train: loss: 0.0654145
[Epoch 15; Iter   452/ 1097] train: loss: 0.0378934
[Epoch 15; Iter   482/ 1097] train: loss: 0.0686953
[Epoch 15; Iter   512/ 1097] train: loss: 0.3526888
[Epoch 15; Iter   542/ 1097] train: loss: 0.1403777
[Epoch 15; Iter   572/ 1097] train: loss: 0.1164873
[Epoch 15; Iter   602/ 1097] train: loss: 0.0466738
[Epoch 15; Iter   632/ 1097] train: loss: 0.2591447
[Epoch 15; Iter   662/ 1097] train: loss: 0.0516365
[Epoch 15; Iter   692/ 1097] train: loss: 0.0959396
[Epoch 15; Iter   722/ 1097] train: loss: 0.0613357
[Epoch 15; Iter   752/ 1097] train: loss: 0.0381223
[Epoch 15; Iter   782/ 1097] train: loss: 0.0727034
[Epoch 15; Iter   812/ 1097] train: loss: 0.0220739
[Epoch 15; Iter   842/ 1097] train: loss: 0.0466623
[Epoch 15; Iter   872/ 1097] train: loss: 0.0221350
[Epoch 15; Iter   902/ 1097] train: loss: 0.0470742
[Epoch 15; Iter   932/ 1097] train: loss: 0.1561276
[Epoch 15; Iter   962/ 1097] train: loss: 0.2275445
[Epoch 15; Iter   992/ 1097] train: loss: 0.0226614
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1418228
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1622058
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0279792
[Epoch 15] ogbg-molhiv: 0.829959 val loss: 0.237026
[Epoch 15] ogbg-molhiv: 0.775478 test loss: 0.202369
[Epoch 16; Iter    15/ 1097] train: loss: 0.0250420
[Epoch 16; Iter    45/ 1097] train: loss: 0.1348584
[Epoch 16; Iter    75/ 1097] train: loss: 0.1864035
[Epoch 16; Iter   105/ 1097] train: loss: 0.0247285
[Epoch 16; Iter   135/ 1097] train: loss: 0.0912848
[Epoch 16; Iter   165/ 1097] train: loss: 0.1785151
[Epoch 12; Iter   113/ 1097] train: loss: 0.0434989
[Epoch 12; Iter   143/ 1097] train: loss: 0.0350283
[Epoch 12; Iter   173/ 1097] train: loss: 0.2755848
[Epoch 12; Iter   203/ 1097] train: loss: 0.0986621
[Epoch 12; Iter   233/ 1097] train: loss: 0.3443654
[Epoch 12; Iter   263/ 1097] train: loss: 0.1857793
[Epoch 12; Iter   293/ 1097] train: loss: 0.1620272
[Epoch 12; Iter   323/ 1097] train: loss: 0.0895186
[Epoch 12; Iter   353/ 1097] train: loss: 0.0295536
[Epoch 12; Iter   383/ 1097] train: loss: 0.1141891
[Epoch 12; Iter   413/ 1097] train: loss: 0.0335018
[Epoch 12; Iter   443/ 1097] train: loss: 0.0591108
[Epoch 12; Iter   473/ 1097] train: loss: 0.0247234
[Epoch 12; Iter   503/ 1097] train: loss: 0.0388007
[Epoch 12; Iter   533/ 1097] train: loss: 0.0473003
[Epoch 12; Iter   563/ 1097] train: loss: 0.1210268
[Epoch 12; Iter   593/ 1097] train: loss: 0.2440382
[Epoch 12; Iter   623/ 1097] train: loss: 0.0417695
[Epoch 12; Iter   653/ 1097] train: loss: 0.0259276
[Epoch 12; Iter   683/ 1097] train: loss: 0.0306402
[Epoch 12; Iter   713/ 1097] train: loss: 0.2971254
[Epoch 12; Iter   743/ 1097] train: loss: 0.0295432
[Epoch 12; Iter   773/ 1097] train: loss: 0.3526359
[Epoch 12; Iter   803/ 1097] train: loss: 0.0815113
[Epoch 12; Iter   833/ 1097] train: loss: 0.0344813
[Epoch 12; Iter   863/ 1097] train: loss: 0.0318116
[Epoch 12; Iter   893/ 1097] train: loss: 0.1297070
[Epoch 12; Iter   923/ 1097] train: loss: 0.0287610
[Epoch 12; Iter   953/ 1097] train: loss: 0.0512058
[Epoch 12; Iter   983/ 1097] train: loss: 0.1585947
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0287202
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1869342
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1839536
[Epoch 12] ogbg-molhiv: 0.804120 val loss: 0.075501
[Epoch 12] ogbg-molhiv: 0.744076 test loss: 0.116068
[Epoch 13; Iter     6/ 1097] train: loss: 0.0980289
[Epoch 13; Iter    36/ 1097] train: loss: 0.0642131
[Epoch 13; Iter    66/ 1097] train: loss: 0.0350581
[Epoch 13; Iter    96/ 1097] train: loss: 0.0795948
[Epoch 13; Iter   126/ 1097] train: loss: 0.0233567
[Epoch 13; Iter   156/ 1097] train: loss: 0.1839450
[Epoch 13; Iter   186/ 1097] train: loss: 0.1439076
[Epoch 13; Iter   216/ 1097] train: loss: 0.1074115
[Epoch 13; Iter   246/ 1097] train: loss: 0.0999734
[Epoch 13; Iter   276/ 1097] train: loss: 0.0292312
[Epoch 13; Iter   306/ 1097] train: loss: 0.0360188
[Epoch 13; Iter   336/ 1097] train: loss: 0.0246574
[Epoch 13; Iter   366/ 1097] train: loss: 0.0176947
[Epoch 13; Iter   396/ 1097] train: loss: 0.2603693
[Epoch 13; Iter   426/ 1097] train: loss: 0.0903718
[Epoch 13; Iter   456/ 1097] train: loss: 0.0987635
[Epoch 13; Iter   486/ 1097] train: loss: 0.0480756
[Epoch 13; Iter   516/ 1097] train: loss: 0.1497013
[Epoch 13; Iter   546/ 1097] train: loss: 0.1550209
[Epoch 13; Iter   576/ 1097] train: loss: 0.2362826
[Epoch 13; Iter   606/ 1097] train: loss: 0.0312625
[Epoch 13; Iter   636/ 1097] train: loss: 0.1544416
[Epoch 13; Iter   666/ 1097] train: loss: 0.0260388
[Epoch 13; Iter   696/ 1097] train: loss: 0.1255115
[Epoch 13; Iter   726/ 1097] train: loss: 0.2828418
[Epoch 13; Iter   756/ 1097] train: loss: 0.2062012
[Epoch 13; Iter   786/ 1097] train: loss: 0.3575896
[Epoch 13; Iter   816/ 1097] train: loss: 0.4824998
[Epoch 13; Iter   846/ 1097] train: loss: 0.0389293
[Epoch 13; Iter   876/ 1097] train: loss: 0.0486570
[Epoch 13; Iter   906/ 1097] train: loss: 0.4869894
[Epoch 13; Iter   936/ 1097] train: loss: 0.0250396
[Epoch 13; Iter   966/ 1097] train: loss: 0.0884222
[Epoch 13; Iter   996/ 1097] train: loss: 0.0538020
[Epoch 13; Iter  1026/ 1097] train: loss: 0.2407658
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1215972
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2872016
[Epoch 13] ogbg-molhiv: 0.799664 val loss: 0.074427
[Epoch 13] ogbg-molhiv: 0.736988 test loss: 0.118992
[Epoch 14; Iter    19/ 1097] train: loss: 0.0390771
[Epoch 14; Iter    49/ 1097] train: loss: 0.0229214
[Epoch 14; Iter    79/ 1097] train: loss: 0.2684006
[Epoch 14; Iter   109/ 1097] train: loss: 0.2060014
[Epoch 14; Iter   139/ 1097] train: loss: 0.1710609
[Epoch 14; Iter   169/ 1097] train: loss: 0.1144469
[Epoch 14; Iter   199/ 1097] train: loss: 0.0318527
[Epoch 14; Iter   229/ 1097] train: loss: 0.1293938
[Epoch 14; Iter   259/ 1097] train: loss: 0.0201200
[Epoch 14; Iter   289/ 1097] train: loss: 0.0938697
[Epoch 14; Iter   319/ 1097] train: loss: 0.1358570
[Epoch 14; Iter   349/ 1097] train: loss: 0.0330517
[Epoch 14; Iter   379/ 1097] train: loss: 0.0591427
[Epoch 14; Iter   409/ 1097] train: loss: 0.0250735
[Epoch 14; Iter   439/ 1097] train: loss: 0.1551157
[Epoch 14; Iter   469/ 1097] train: loss: 0.1860911
[Epoch 14; Iter   499/ 1097] train: loss: 0.1324528
[Epoch 14; Iter   529/ 1097] train: loss: 0.0410524
[Epoch 14; Iter   559/ 1097] train: loss: 0.1663669
[Epoch 14; Iter   589/ 1097] train: loss: 0.0762312
[Epoch 14; Iter   619/ 1097] train: loss: 0.1583393
[Epoch 14; Iter   649/ 1097] train: loss: 0.1878099
[Epoch 14; Iter   679/ 1097] train: loss: 0.0261141
[Epoch 14; Iter   709/ 1097] train: loss: 0.1173639
[Epoch 14; Iter   739/ 1097] train: loss: 0.0380820
[Epoch 14; Iter   769/ 1097] train: loss: 0.0212231
[Epoch 14; Iter   799/ 1097] train: loss: 0.0571731
[Epoch 14; Iter   829/ 1097] train: loss: 0.1597296
[Epoch 14; Iter   859/ 1097] train: loss: 0.1500994
[Epoch 14; Iter   889/ 1097] train: loss: 0.0288307
[Epoch 14; Iter   919/ 1097] train: loss: 0.0224366
[Epoch 14; Iter   949/ 1097] train: loss: 0.0189819
[Epoch 14; Iter   979/ 1097] train: loss: 0.2634000
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0312684
[Epoch 14; Iter  1039/ 1097] train: loss: 0.3230089
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0327122
[Epoch 14] ogbg-molhiv: 0.778066 val loss: 0.095208
[Epoch 14] ogbg-molhiv: 0.736150 test loss: 0.117682
[Epoch 15; Iter     2/ 1097] train: loss: 0.0566224
[Epoch 15; Iter    32/ 1097] train: loss: 0.0251964
[Epoch 15; Iter    62/ 1097] train: loss: 0.1141759
[Epoch 15; Iter    92/ 1097] train: loss: 0.0694852
[Epoch 15; Iter   122/ 1097] train: loss: 0.0286885
[Epoch 15; Iter   152/ 1097] train: loss: 0.1981373
[Epoch 15; Iter   182/ 1097] train: loss: 0.0274919
[Epoch 15; Iter   212/ 1097] train: loss: 0.2634660
[Epoch 15; Iter   242/ 1097] train: loss: 0.0533123
[Epoch 15; Iter   272/ 1097] train: loss: 0.0468515
[Epoch 15; Iter   302/ 1097] train: loss: 0.1533798
[Epoch 15; Iter   332/ 1097] train: loss: 0.0759255
[Epoch 15; Iter   362/ 1097] train: loss: 0.1973445
[Epoch 15; Iter   392/ 1097] train: loss: 0.0998922
[Epoch 15; Iter   422/ 1097] train: loss: 0.0285953
[Epoch 15; Iter   452/ 1097] train: loss: 0.2423288
[Epoch 15; Iter   482/ 1097] train: loss: 0.0383386
[Epoch 15; Iter   512/ 1097] train: loss: 0.1939064
[Epoch 15; Iter   542/ 1097] train: loss: 0.0393253
[Epoch 15; Iter   572/ 1097] train: loss: 0.1125653
[Epoch 15; Iter   602/ 1097] train: loss: 0.0220473
[Epoch 15; Iter   632/ 1097] train: loss: 0.1074309
[Epoch 15; Iter   662/ 1097] train: loss: 0.1011115
[Epoch 15; Iter   692/ 1097] train: loss: 0.0836988
[Epoch 15; Iter   722/ 1097] train: loss: 0.2955966
[Epoch 15; Iter   752/ 1097] train: loss: 0.1053728
[Epoch 15; Iter   782/ 1097] train: loss: 0.1799072
[Epoch 15; Iter   812/ 1097] train: loss: 0.0220616
[Epoch 15; Iter   842/ 1097] train: loss: 0.2368161
[Epoch 15; Iter   872/ 1097] train: loss: 0.0617403
[Epoch 15; Iter   902/ 1097] train: loss: 0.0861784
[Epoch 15; Iter   932/ 1097] train: loss: 0.0248713
[Epoch 15; Iter   962/ 1097] train: loss: 0.1348131
[Epoch 15; Iter   992/ 1097] train: loss: 0.1380913
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5257371
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0330111
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0518121
[Epoch 15] ogbg-molhiv: 0.789637 val loss: 0.090757
[Epoch 15] ogbg-molhiv: 0.738626 test loss: 0.133966
[Epoch 16; Iter    15/ 1097] train: loss: 0.1525160
[Epoch 16; Iter    45/ 1097] train: loss: 0.0772237
[Epoch 16; Iter    75/ 1097] train: loss: 0.0789752
[Epoch 16; Iter   105/ 1097] train: loss: 0.0839617
[Epoch 16; Iter   135/ 1097] train: loss: 0.0466368
[Epoch 16; Iter   165/ 1097] train: loss: 0.4879561
[Epoch 12; Iter   113/ 1097] train: loss: 0.1297673
[Epoch 12; Iter   143/ 1097] train: loss: 0.3458854
[Epoch 12; Iter   173/ 1097] train: loss: 0.0396053
[Epoch 12; Iter   203/ 1097] train: loss: 0.0287437
[Epoch 12; Iter   233/ 1097] train: loss: 0.0248574
[Epoch 12; Iter   263/ 1097] train: loss: 0.0443517
[Epoch 12; Iter   293/ 1097] train: loss: 0.1437746
[Epoch 12; Iter   323/ 1097] train: loss: 0.1366216
[Epoch 12; Iter   353/ 1097] train: loss: 0.2472328
[Epoch 12; Iter   383/ 1097] train: loss: 0.0516775
[Epoch 12; Iter   413/ 1097] train: loss: 0.2839785
[Epoch 12; Iter   443/ 1097] train: loss: 0.3939895
[Epoch 12; Iter   473/ 1097] train: loss: 0.1583869
[Epoch 12; Iter   503/ 1097] train: loss: 0.1708504
[Epoch 12; Iter   533/ 1097] train: loss: 0.1384032
[Epoch 12; Iter   563/ 1097] train: loss: 0.1166448
[Epoch 12; Iter   593/ 1097] train: loss: 0.3019352
[Epoch 12; Iter   623/ 1097] train: loss: 0.2592213
[Epoch 12; Iter   653/ 1097] train: loss: 0.0436505
[Epoch 12; Iter   683/ 1097] train: loss: 0.1790846
[Epoch 12; Iter   713/ 1097] train: loss: 0.0498176
[Epoch 12; Iter   743/ 1097] train: loss: 0.2061368
[Epoch 12; Iter   773/ 1097] train: loss: 0.0338754
[Epoch 12; Iter   803/ 1097] train: loss: 0.1673382
[Epoch 12; Iter   833/ 1097] train: loss: 0.1937414
[Epoch 12; Iter   863/ 1097] train: loss: 0.2538062
[Epoch 12; Iter   893/ 1097] train: loss: 0.0552980
[Epoch 12; Iter   923/ 1097] train: loss: 0.1928187
[Epoch 12; Iter   953/ 1097] train: loss: 0.2298831
[Epoch 12; Iter   983/ 1097] train: loss: 0.0774156
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0332194
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1296278
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0929294
[Epoch 12] ogbg-molhiv: 0.796008 val loss: 0.383467
[Epoch 12] ogbg-molhiv: 0.783157 test loss: 0.294955
[Epoch 13; Iter     6/ 1097] train: loss: 0.0624397
[Epoch 13; Iter    36/ 1097] train: loss: 0.3212068
[Epoch 13; Iter    66/ 1097] train: loss: 0.1441073
[Epoch 13; Iter    96/ 1097] train: loss: 0.0398011
[Epoch 13; Iter   126/ 1097] train: loss: 0.0238858
[Epoch 13; Iter   156/ 1097] train: loss: 0.0180928
[Epoch 13; Iter   186/ 1097] train: loss: 0.1765874
[Epoch 13; Iter   216/ 1097] train: loss: 0.1807935
[Epoch 13; Iter   246/ 1097] train: loss: 0.0320063
[Epoch 13; Iter   276/ 1097] train: loss: 0.1096583
[Epoch 13; Iter   306/ 1097] train: loss: 0.0234602
[Epoch 13; Iter   336/ 1097] train: loss: 0.1744352
[Epoch 13; Iter   366/ 1097] train: loss: 0.1597393
[Epoch 13; Iter   396/ 1097] train: loss: 0.0887960
[Epoch 13; Iter   426/ 1097] train: loss: 0.0580888
[Epoch 13; Iter   456/ 1097] train: loss: 0.0369397
[Epoch 13; Iter   486/ 1097] train: loss: 0.0378351
[Epoch 13; Iter   516/ 1097] train: loss: 0.0340446
[Epoch 13; Iter   546/ 1097] train: loss: 0.0233815
[Epoch 13; Iter   576/ 1097] train: loss: 0.1526826
[Epoch 13; Iter   606/ 1097] train: loss: 0.0895517
[Epoch 13; Iter   636/ 1097] train: loss: 0.3355057
[Epoch 13; Iter   666/ 1097] train: loss: 0.0373356
[Epoch 13; Iter   696/ 1097] train: loss: 0.0462606
[Epoch 13; Iter   726/ 1097] train: loss: 0.1147591
[Epoch 13; Iter   756/ 1097] train: loss: 0.0494150
[Epoch 13; Iter   786/ 1097] train: loss: 0.1270122
[Epoch 13; Iter   816/ 1097] train: loss: 0.0261434
[Epoch 13; Iter   846/ 1097] train: loss: 0.0206291
[Epoch 13; Iter   876/ 1097] train: loss: 0.1814284
[Epoch 13; Iter   906/ 1097] train: loss: 0.2989038
[Epoch 13; Iter   936/ 1097] train: loss: 0.1990265
[Epoch 13; Iter   966/ 1097] train: loss: 0.1096871
[Epoch 13; Iter   996/ 1097] train: loss: 0.0858802
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3107713
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2192893
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1621258
[Epoch 13] ogbg-molhiv: 0.794634 val loss: 0.319401
[Epoch 13] ogbg-molhiv: 0.779028 test loss: 0.108165
[Epoch 14; Iter    19/ 1097] train: loss: 0.0259621
[Epoch 14; Iter    49/ 1097] train: loss: 0.3677483
[Epoch 14; Iter    79/ 1097] train: loss: 0.0346963
[Epoch 14; Iter   109/ 1097] train: loss: 0.0331859
[Epoch 14; Iter   139/ 1097] train: loss: 0.0900217
[Epoch 14; Iter   169/ 1097] train: loss: 0.1442872
[Epoch 14; Iter   199/ 1097] train: loss: 0.0828397
[Epoch 14; Iter   229/ 1097] train: loss: 0.0239415
[Epoch 14; Iter   259/ 1097] train: loss: 0.0526889
[Epoch 14; Iter   289/ 1097] train: loss: 0.0818356
[Epoch 14; Iter   319/ 1097] train: loss: 0.2483145
[Epoch 14; Iter   349/ 1097] train: loss: 0.1441161
[Epoch 14; Iter   379/ 1097] train: loss: 0.1585103
[Epoch 14; Iter   409/ 1097] train: loss: 0.1068593
[Epoch 14; Iter   439/ 1097] train: loss: 0.1749269
[Epoch 14; Iter   469/ 1097] train: loss: 0.1365421
[Epoch 14; Iter   499/ 1097] train: loss: 0.0233780
[Epoch 14; Iter   529/ 1097] train: loss: 0.0273453
[Epoch 14; Iter   559/ 1097] train: loss: 0.2440830
[Epoch 14; Iter   589/ 1097] train: loss: 0.0299494
[Epoch 14; Iter   619/ 1097] train: loss: 0.0553161
[Epoch 14; Iter   649/ 1097] train: loss: 0.0470413
[Epoch 14; Iter   679/ 1097] train: loss: 0.1089251
[Epoch 14; Iter   709/ 1097] train: loss: 0.2036405
[Epoch 14; Iter   739/ 1097] train: loss: 0.0677655
[Epoch 14; Iter   769/ 1097] train: loss: 0.1731115
[Epoch 14; Iter   799/ 1097] train: loss: 0.0317940
[Epoch 14; Iter   829/ 1097] train: loss: 0.1105493
[Epoch 14; Iter   859/ 1097] train: loss: 0.0370420
[Epoch 14; Iter   889/ 1097] train: loss: 0.0291967
[Epoch 14; Iter   919/ 1097] train: loss: 0.0742343
[Epoch 14; Iter   949/ 1097] train: loss: 0.0378345
[Epoch 14; Iter   979/ 1097] train: loss: 0.1700593
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0229392
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0576487
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1886233
[Epoch 14] ogbg-molhiv: 0.804873 val loss: 0.358339
[Epoch 14] ogbg-molhiv: 0.788142 test loss: 0.112465
[Epoch 15; Iter     2/ 1097] train: loss: 0.1356313
[Epoch 15; Iter    32/ 1097] train: loss: 0.0357425
[Epoch 15; Iter    62/ 1097] train: loss: 0.1898621
[Epoch 15; Iter    92/ 1097] train: loss: 0.0182935
[Epoch 15; Iter   122/ 1097] train: loss: 0.1826897
[Epoch 15; Iter   152/ 1097] train: loss: 0.2001552
[Epoch 15; Iter   182/ 1097] train: loss: 0.2384049
[Epoch 15; Iter   212/ 1097] train: loss: 0.0258251
[Epoch 15; Iter   242/ 1097] train: loss: 0.0352990
[Epoch 15; Iter   272/ 1097] train: loss: 0.1647257
[Epoch 15; Iter   302/ 1097] train: loss: 0.2055202
[Epoch 15; Iter   332/ 1097] train: loss: 0.0515453
[Epoch 15; Iter   362/ 1097] train: loss: 0.1404577
[Epoch 15; Iter   392/ 1097] train: loss: 0.1913417
[Epoch 15; Iter   422/ 1097] train: loss: 0.2025922
[Epoch 15; Iter   452/ 1097] train: loss: 0.0422733
[Epoch 15; Iter   482/ 1097] train: loss: 0.0984364
[Epoch 15; Iter   512/ 1097] train: loss: 0.2821017
[Epoch 15; Iter   542/ 1097] train: loss: 0.0728659
[Epoch 15; Iter   572/ 1097] train: loss: 0.0231773
[Epoch 15; Iter   602/ 1097] train: loss: 0.4818264
[Epoch 15; Iter   632/ 1097] train: loss: 0.0251198
[Epoch 15; Iter   662/ 1097] train: loss: 0.1459223
[Epoch 15; Iter   692/ 1097] train: loss: 0.0355269
[Epoch 15; Iter   722/ 1097] train: loss: 0.0495984
[Epoch 15; Iter   752/ 1097] train: loss: 0.1603836
[Epoch 15; Iter   782/ 1097] train: loss: 0.1897371
[Epoch 15; Iter   812/ 1097] train: loss: 0.1144224
[Epoch 15; Iter   842/ 1097] train: loss: 0.0300946
[Epoch 15; Iter   872/ 1097] train: loss: 0.0328306
[Epoch 15; Iter   902/ 1097] train: loss: 0.2149000
[Epoch 15; Iter   932/ 1097] train: loss: 0.0735091
[Epoch 15; Iter   962/ 1097] train: loss: 0.0426048
[Epoch 15; Iter   992/ 1097] train: loss: 0.0381921
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0171491
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0480217
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0236741
[Epoch 15] ogbg-molhiv: 0.773908 val loss: 0.078630
[Epoch 15] ogbg-molhiv: 0.765853 test loss: 0.113803
[Epoch 16; Iter    15/ 1097] train: loss: 0.1159702
[Epoch 16; Iter    45/ 1097] train: loss: 0.0283721
[Epoch 16; Iter    75/ 1097] train: loss: 0.0179155
[Epoch 16; Iter   105/ 1097] train: loss: 0.0193085
[Epoch 16; Iter   135/ 1097] train: loss: 0.0203301
[Epoch 16; Iter   165/ 1097] train: loss: 0.2493463
[Epoch 12; Iter   113/ 1097] train: loss: 0.0570040
[Epoch 12; Iter   143/ 1097] train: loss: 0.1594424
[Epoch 12; Iter   173/ 1097] train: loss: 0.3966813
[Epoch 12; Iter   203/ 1097] train: loss: 0.0997681
[Epoch 12; Iter   233/ 1097] train: loss: 0.3101975
[Epoch 12; Iter   263/ 1097] train: loss: 0.1482430
[Epoch 12; Iter   293/ 1097] train: loss: 0.0921489
[Epoch 12; Iter   323/ 1097] train: loss: 0.0638328
[Epoch 12; Iter   353/ 1097] train: loss: 0.0282518
[Epoch 12; Iter   383/ 1097] train: loss: 0.1577452
[Epoch 12; Iter   413/ 1097] train: loss: 0.0384672
[Epoch 12; Iter   443/ 1097] train: loss: 0.1264707
[Epoch 12; Iter   473/ 1097] train: loss: 0.0349765
[Epoch 12; Iter   503/ 1097] train: loss: 0.1102511
[Epoch 12; Iter   533/ 1097] train: loss: 0.1099998
[Epoch 12; Iter   563/ 1097] train: loss: 0.1490334
[Epoch 12; Iter   593/ 1097] train: loss: 0.4122316
[Epoch 12; Iter   623/ 1097] train: loss: 0.0245391
[Epoch 12; Iter   653/ 1097] train: loss: 0.0269770
[Epoch 12; Iter   683/ 1097] train: loss: 0.0547691
[Epoch 12; Iter   713/ 1097] train: loss: 0.2140586
[Epoch 12; Iter   743/ 1097] train: loss: 0.0324761
[Epoch 12; Iter   773/ 1097] train: loss: 0.2942446
[Epoch 12; Iter   803/ 1097] train: loss: 0.0727606
[Epoch 12; Iter   833/ 1097] train: loss: 0.0493658
[Epoch 12; Iter   863/ 1097] train: loss: 0.0314813
[Epoch 12; Iter   893/ 1097] train: loss: 0.1296354
[Epoch 12; Iter   923/ 1097] train: loss: 0.0364778
[Epoch 12; Iter   953/ 1097] train: loss: 0.0611571
[Epoch 12; Iter   983/ 1097] train: loss: 0.1773597
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0322489
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2779809
[Epoch 12; Iter  1073/ 1097] train: loss: 0.2198070
[Epoch 12] ogbg-molhiv: 0.705201 val loss: 0.806138
[Epoch 12] ogbg-molhiv: 0.639935 test loss: 1.100626
[Epoch 13; Iter     6/ 1097] train: loss: 0.0816804
[Epoch 13; Iter    36/ 1097] train: loss: 0.0367393
[Epoch 13; Iter    66/ 1097] train: loss: 0.0837976
[Epoch 13; Iter    96/ 1097] train: loss: 0.0442575
[Epoch 13; Iter   126/ 1097] train: loss: 0.0316263
[Epoch 13; Iter   156/ 1097] train: loss: 0.2452122
[Epoch 13; Iter   186/ 1097] train: loss: 0.1175728
[Epoch 13; Iter   216/ 1097] train: loss: 0.1460671
[Epoch 13; Iter   246/ 1097] train: loss: 0.1375736
[Epoch 13; Iter   276/ 1097] train: loss: 0.0350768
[Epoch 13; Iter   306/ 1097] train: loss: 0.0289854
[Epoch 13; Iter   336/ 1097] train: loss: 0.0295921
[Epoch 13; Iter   366/ 1097] train: loss: 0.0230003
[Epoch 13; Iter   396/ 1097] train: loss: 0.2621998
[Epoch 13; Iter   426/ 1097] train: loss: 0.0205443
[Epoch 13; Iter   456/ 1097] train: loss: 0.1971339
[Epoch 13; Iter   486/ 1097] train: loss: 0.0357200
[Epoch 13; Iter   516/ 1097] train: loss: 0.2108491
[Epoch 13; Iter   546/ 1097] train: loss: 0.2128333
[Epoch 13; Iter   576/ 1097] train: loss: 0.2109728
[Epoch 13; Iter   606/ 1097] train: loss: 0.0336554
[Epoch 13; Iter   636/ 1097] train: loss: 0.1225473
[Epoch 13; Iter   666/ 1097] train: loss: 0.0344550
[Epoch 13; Iter   696/ 1097] train: loss: 0.1257067
[Epoch 13; Iter   726/ 1097] train: loss: 0.2683051
[Epoch 13; Iter   756/ 1097] train: loss: 0.1661045
[Epoch 13; Iter   786/ 1097] train: loss: 0.3594030
[Epoch 13; Iter   816/ 1097] train: loss: 0.5063790
[Epoch 13; Iter   846/ 1097] train: loss: 0.0571561
[Epoch 13; Iter   876/ 1097] train: loss: 0.0372182
[Epoch 13; Iter   906/ 1097] train: loss: 0.4219241
[Epoch 13; Iter   936/ 1097] train: loss: 0.0300987
[Epoch 13; Iter   966/ 1097] train: loss: 0.1900027
[Epoch 13; Iter   996/ 1097] train: loss: 0.1340146
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1203747
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1122345
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1696740
[Epoch 13] ogbg-molhiv: 0.748552 val loss: 0.086130
[Epoch 13] ogbg-molhiv: 0.731752 test loss: 0.128816
[Epoch 14; Iter    19/ 1097] train: loss: 0.0253346
[Epoch 14; Iter    49/ 1097] train: loss: 0.0345618
[Epoch 14; Iter    79/ 1097] train: loss: 0.2606000
[Epoch 14; Iter   109/ 1097] train: loss: 0.1448229
[Epoch 14; Iter   139/ 1097] train: loss: 0.0184194
[Epoch 14; Iter   169/ 1097] train: loss: 0.1012962
[Epoch 14; Iter   199/ 1097] train: loss: 0.0604595
[Epoch 14; Iter   229/ 1097] train: loss: 0.1495288
[Epoch 14; Iter   259/ 1097] train: loss: 0.0973421
[Epoch 14; Iter   289/ 1097] train: loss: 0.1394592
[Epoch 14; Iter   319/ 1097] train: loss: 0.0891629
[Epoch 14; Iter   349/ 1097] train: loss: 0.0298662
[Epoch 14; Iter   379/ 1097] train: loss: 0.0774314
[Epoch 14; Iter   409/ 1097] train: loss: 0.0395629
[Epoch 14; Iter   439/ 1097] train: loss: 0.1192477
[Epoch 14; Iter   469/ 1097] train: loss: 0.1521373
[Epoch 14; Iter   499/ 1097] train: loss: 0.0872791
[Epoch 14; Iter   529/ 1097] train: loss: 0.0883183
[Epoch 14; Iter   559/ 1097] train: loss: 0.2606839
[Epoch 14; Iter   589/ 1097] train: loss: 0.1147397
[Epoch 14; Iter   619/ 1097] train: loss: 0.1788400
[Epoch 14; Iter   649/ 1097] train: loss: 0.1253344
[Epoch 14; Iter   679/ 1097] train: loss: 0.0306015
[Epoch 14; Iter   709/ 1097] train: loss: 0.0275869
[Epoch 14; Iter   739/ 1097] train: loss: 0.0747601
[Epoch 14; Iter   769/ 1097] train: loss: 0.0204387
[Epoch 14; Iter   799/ 1097] train: loss: 0.0385890
[Epoch 14; Iter   829/ 1097] train: loss: 0.0583329
[Epoch 14; Iter   859/ 1097] train: loss: 0.3172270
[Epoch 14; Iter   889/ 1097] train: loss: 0.0275139
[Epoch 14; Iter   919/ 1097] train: loss: 0.0414375
[Epoch 14; Iter   949/ 1097] train: loss: 0.0415082
[Epoch 14; Iter   979/ 1097] train: loss: 0.2310881
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0668149
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2259447
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0637298
[Epoch 14] ogbg-molhiv: 0.681998 val loss: 0.259647
[Epoch 14] ogbg-molhiv: 0.561465 test loss: 0.186545
[Epoch 15; Iter     2/ 1097] train: loss: 0.1088164
[Epoch 15; Iter    32/ 1097] train: loss: 0.0434621
[Epoch 15; Iter    62/ 1097] train: loss: 0.0896616
[Epoch 15; Iter    92/ 1097] train: loss: 0.0311625
[Epoch 15; Iter   122/ 1097] train: loss: 0.0325489
[Epoch 15; Iter   152/ 1097] train: loss: 0.1877042
[Epoch 15; Iter   182/ 1097] train: loss: 0.0241836
[Epoch 15; Iter   212/ 1097] train: loss: 0.2058281
[Epoch 15; Iter   242/ 1097] train: loss: 0.0402091
[Epoch 15; Iter   272/ 1097] train: loss: 0.1121279
[Epoch 15; Iter   302/ 1097] train: loss: 0.1972688
[Epoch 15; Iter   332/ 1097] train: loss: 0.0565015
[Epoch 15; Iter   362/ 1097] train: loss: 0.2301279
[Epoch 15; Iter   392/ 1097] train: loss: 0.0448038
[Epoch 15; Iter   422/ 1097] train: loss: 0.0238687
[Epoch 15; Iter   452/ 1097] train: loss: 0.2074820
[Epoch 15; Iter   482/ 1097] train: loss: 0.0304154
[Epoch 15; Iter   512/ 1097] train: loss: 0.1893356
[Epoch 15; Iter   542/ 1097] train: loss: 0.0365995
[Epoch 15; Iter   572/ 1097] train: loss: 0.0520311
[Epoch 15; Iter   602/ 1097] train: loss: 0.0242105
[Epoch 15; Iter   632/ 1097] train: loss: 0.1423096
[Epoch 15; Iter   662/ 1097] train: loss: 0.1093613
[Epoch 15; Iter   692/ 1097] train: loss: 0.0359957
[Epoch 15; Iter   722/ 1097] train: loss: 0.2555593
[Epoch 15; Iter   752/ 1097] train: loss: 0.0519263
[Epoch 15; Iter   782/ 1097] train: loss: 0.1211761
[Epoch 15; Iter   812/ 1097] train: loss: 0.0376452
[Epoch 15; Iter   842/ 1097] train: loss: 0.2289744
[Epoch 15; Iter   872/ 1097] train: loss: 0.0399719
[Epoch 15; Iter   902/ 1097] train: loss: 0.1706586
[Epoch 15; Iter   932/ 1097] train: loss: 0.0283855
[Epoch 15; Iter   962/ 1097] train: loss: 0.1463002
[Epoch 15; Iter   992/ 1097] train: loss: 0.1594833
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4061910
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0284583
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0624610
[Epoch 15] ogbg-molhiv: 0.711377 val loss: 0.106964
[Epoch 15] ogbg-molhiv: 0.568418 test loss: 0.250263
[Epoch 16; Iter    15/ 1097] train: loss: 0.0502766
[Epoch 16; Iter    45/ 1097] train: loss: 0.0462517
[Epoch 16; Iter    75/ 1097] train: loss: 0.0827208
[Epoch 16; Iter   105/ 1097] train: loss: 0.1070042
[Epoch 16; Iter   135/ 1097] train: loss: 0.1250453
[Epoch 16; Iter   165/ 1097] train: loss: 0.5079370
[Epoch 12; Iter   113/ 1097] train: loss: 0.1800882
[Epoch 12; Iter   143/ 1097] train: loss: 0.2767417
[Epoch 12; Iter   173/ 1097] train: loss: 0.0450029
[Epoch 12; Iter   203/ 1097] train: loss: 0.0275066
[Epoch 12; Iter   233/ 1097] train: loss: 0.0318973
[Epoch 12; Iter   263/ 1097] train: loss: 0.1119440
[Epoch 12; Iter   293/ 1097] train: loss: 0.1671586
[Epoch 12; Iter   323/ 1097] train: loss: 0.1150803
[Epoch 12; Iter   353/ 1097] train: loss: 0.2314483
[Epoch 12; Iter   383/ 1097] train: loss: 0.0579999
[Epoch 12; Iter   413/ 1097] train: loss: 0.1716997
[Epoch 12; Iter   443/ 1097] train: loss: 0.3720330
[Epoch 12; Iter   473/ 1097] train: loss: 0.0941086
[Epoch 12; Iter   503/ 1097] train: loss: 0.2022551
[Epoch 12; Iter   533/ 1097] train: loss: 0.1528065
[Epoch 12; Iter   563/ 1097] train: loss: 0.1846519
[Epoch 12; Iter   593/ 1097] train: loss: 0.2885855
[Epoch 12; Iter   623/ 1097] train: loss: 0.3033346
[Epoch 12; Iter   653/ 1097] train: loss: 0.0981398
[Epoch 12; Iter   683/ 1097] train: loss: 0.1803191
[Epoch 12; Iter   713/ 1097] train: loss: 0.0381973
[Epoch 12; Iter   743/ 1097] train: loss: 0.1452599
[Epoch 12; Iter   773/ 1097] train: loss: 0.0399753
[Epoch 12; Iter   803/ 1097] train: loss: 0.1216307
[Epoch 12; Iter   833/ 1097] train: loss: 0.2042049
[Epoch 12; Iter   863/ 1097] train: loss: 0.2208758
[Epoch 12; Iter   893/ 1097] train: loss: 0.0353541
[Epoch 12; Iter   923/ 1097] train: loss: 0.1057827
[Epoch 12; Iter   953/ 1097] train: loss: 0.2613325
[Epoch 12; Iter   983/ 1097] train: loss: 0.0372464
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0612708
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1617166
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0635915
[Epoch 12] ogbg-molhiv: 0.771403 val loss: 0.097665
[Epoch 12] ogbg-molhiv: 0.682128 test loss: 0.139026
[Epoch 13; Iter     6/ 1097] train: loss: 0.1194711
[Epoch 13; Iter    36/ 1097] train: loss: 0.2348797
[Epoch 13; Iter    66/ 1097] train: loss: 0.1398819
[Epoch 13; Iter    96/ 1097] train: loss: 0.0890262
[Epoch 13; Iter   126/ 1097] train: loss: 0.0298110
[Epoch 13; Iter   156/ 1097] train: loss: 0.0232577
[Epoch 13; Iter   186/ 1097] train: loss: 0.1577979
[Epoch 13; Iter   216/ 1097] train: loss: 0.2237777
[Epoch 13; Iter   246/ 1097] train: loss: 0.0244277
[Epoch 13; Iter   276/ 1097] train: loss: 0.1834332
[Epoch 13; Iter   306/ 1097] train: loss: 0.0888792
[Epoch 13; Iter   336/ 1097] train: loss: 0.1148324
[Epoch 13; Iter   366/ 1097] train: loss: 0.1295346
[Epoch 13; Iter   396/ 1097] train: loss: 0.1307809
[Epoch 13; Iter   426/ 1097] train: loss: 0.1062820
[Epoch 13; Iter   456/ 1097] train: loss: 0.0443799
[Epoch 13; Iter   486/ 1097] train: loss: 0.0380081
[Epoch 13; Iter   516/ 1097] train: loss: 0.0373733
[Epoch 13; Iter   546/ 1097] train: loss: 0.0296936
[Epoch 13; Iter   576/ 1097] train: loss: 0.1528770
[Epoch 13; Iter   606/ 1097] train: loss: 0.0889626
[Epoch 13; Iter   636/ 1097] train: loss: 0.2817555
[Epoch 13; Iter   666/ 1097] train: loss: 0.0291271
[Epoch 13; Iter   696/ 1097] train: loss: 0.0640319
[Epoch 13; Iter   726/ 1097] train: loss: 0.1609488
[Epoch 13; Iter   756/ 1097] train: loss: 0.0337459
[Epoch 13; Iter   786/ 1097] train: loss: 0.1279309
[Epoch 13; Iter   816/ 1097] train: loss: 0.0266367
[Epoch 13; Iter   846/ 1097] train: loss: 0.0293114
[Epoch 13; Iter   876/ 1097] train: loss: 0.2342404
[Epoch 13; Iter   906/ 1097] train: loss: 0.4430356
[Epoch 13; Iter   936/ 1097] train: loss: 0.1911131
[Epoch 13; Iter   966/ 1097] train: loss: 0.1268188
[Epoch 13; Iter   996/ 1097] train: loss: 0.0415232
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3062696
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1640905
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1192025
[Epoch 13] ogbg-molhiv: 0.747587 val loss: 0.097580
[Epoch 13] ogbg-molhiv: 0.722814 test loss: 0.134254
[Epoch 14; Iter    19/ 1097] train: loss: 0.0332530
[Epoch 14; Iter    49/ 1097] train: loss: 0.1640180
[Epoch 14; Iter    79/ 1097] train: loss: 0.0380358
[Epoch 14; Iter   109/ 1097] train: loss: 0.0266187
[Epoch 14; Iter   139/ 1097] train: loss: 0.0653795
[Epoch 14; Iter   169/ 1097] train: loss: 0.1922718
[Epoch 14; Iter   199/ 1097] train: loss: 0.0305042
[Epoch 14; Iter   229/ 1097] train: loss: 0.0202506
[Epoch 14; Iter   259/ 1097] train: loss: 0.0618143
[Epoch 14; Iter   289/ 1097] train: loss: 0.0818420
[Epoch 14; Iter   319/ 1097] train: loss: 0.0671960
[Epoch 14; Iter   349/ 1097] train: loss: 0.3580493
[Epoch 14; Iter   379/ 1097] train: loss: 0.1055183
[Epoch 14; Iter   409/ 1097] train: loss: 0.0438045
[Epoch 14; Iter   439/ 1097] train: loss: 0.1291242
[Epoch 14; Iter   469/ 1097] train: loss: 0.1268187
[Epoch 14; Iter   499/ 1097] train: loss: 0.0286342
[Epoch 14; Iter   529/ 1097] train: loss: 0.0251095
[Epoch 14; Iter   559/ 1097] train: loss: 0.2632654
[Epoch 14; Iter   589/ 1097] train: loss: 0.0269487
[Epoch 14; Iter   619/ 1097] train: loss: 0.1103789
[Epoch 14; Iter   649/ 1097] train: loss: 0.0344403
[Epoch 14; Iter   679/ 1097] train: loss: 0.0787480
[Epoch 14; Iter   709/ 1097] train: loss: 0.1086125
[Epoch 14; Iter   739/ 1097] train: loss: 0.0711471
[Epoch 14; Iter   769/ 1097] train: loss: 0.1281912
[Epoch 14; Iter   799/ 1097] train: loss: 0.0354066
[Epoch 14; Iter   829/ 1097] train: loss: 0.0856926
[Epoch 14; Iter   859/ 1097] train: loss: 0.0287054
[Epoch 14; Iter   889/ 1097] train: loss: 0.0397279
[Epoch 14; Iter   919/ 1097] train: loss: 0.0635700
[Epoch 14; Iter   949/ 1097] train: loss: 0.0365198
[Epoch 14; Iter   979/ 1097] train: loss: 0.0815539
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0190098
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0497267
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1514545
[Epoch 14] ogbg-molhiv: 0.769443 val loss: 0.081541
[Epoch 14] ogbg-molhiv: 0.641467 test loss: 0.139515
[Epoch 15; Iter     2/ 1097] train: loss: 0.1591931
[Epoch 15; Iter    32/ 1097] train: loss: 0.0361470
[Epoch 15; Iter    62/ 1097] train: loss: 0.1340653
[Epoch 15; Iter    92/ 1097] train: loss: 0.0330608
[Epoch 15; Iter   122/ 1097] train: loss: 0.1308079
[Epoch 15; Iter   152/ 1097] train: loss: 0.1053607
[Epoch 15; Iter   182/ 1097] train: loss: 0.1864206
[Epoch 15; Iter   212/ 1097] train: loss: 0.0369725
[Epoch 15; Iter   242/ 1097] train: loss: 0.0378930
[Epoch 15; Iter   272/ 1097] train: loss: 0.0723994
[Epoch 15; Iter   302/ 1097] train: loss: 0.1764978
[Epoch 15; Iter   332/ 1097] train: loss: 0.0187920
[Epoch 15; Iter   362/ 1097] train: loss: 0.1344375
[Epoch 15; Iter   392/ 1097] train: loss: 0.1098052
[Epoch 15; Iter   422/ 1097] train: loss: 0.2249882
[Epoch 15; Iter   452/ 1097] train: loss: 0.0258927
[Epoch 15; Iter   482/ 1097] train: loss: 0.1080357
[Epoch 15; Iter   512/ 1097] train: loss: 0.3746959
[Epoch 15; Iter   542/ 1097] train: loss: 0.0263488
[Epoch 15; Iter   572/ 1097] train: loss: 0.0376851
[Epoch 15; Iter   602/ 1097] train: loss: 0.4045115
[Epoch 15; Iter   632/ 1097] train: loss: 0.0288885
[Epoch 15; Iter   662/ 1097] train: loss: 0.1352732
[Epoch 15; Iter   692/ 1097] train: loss: 0.0250065
[Epoch 15; Iter   722/ 1097] train: loss: 0.1300296
[Epoch 15; Iter   752/ 1097] train: loss: 0.1816046
[Epoch 15; Iter   782/ 1097] train: loss: 0.1756212
[Epoch 15; Iter   812/ 1097] train: loss: 0.1120944
[Epoch 15; Iter   842/ 1097] train: loss: 0.0318286
[Epoch 15; Iter   872/ 1097] train: loss: 0.0270663
[Epoch 15; Iter   902/ 1097] train: loss: 0.1698593
[Epoch 15; Iter   932/ 1097] train: loss: 0.0324590
[Epoch 15; Iter   962/ 1097] train: loss: 0.0466581
[Epoch 15; Iter   992/ 1097] train: loss: 0.0866030
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0182130
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1812629
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0280163
[Epoch 15] ogbg-molhiv: 0.794361 val loss: 0.136143
[Epoch 15] ogbg-molhiv: 0.700798 test loss: 0.133796
[Epoch 16; Iter    15/ 1097] train: loss: 0.1110721
[Epoch 16; Iter    45/ 1097] train: loss: 0.0329813
[Epoch 16; Iter    75/ 1097] train: loss: 0.0181932
[Epoch 16; Iter   105/ 1097] train: loss: 0.0322354
[Epoch 16; Iter   135/ 1097] train: loss: 0.0246746
[Epoch 16; Iter   165/ 1097] train: loss: 0.2575697
[Epoch 12; Iter   113/ 1097] train: loss: 0.0450383
[Epoch 12; Iter   143/ 1097] train: loss: 0.1778118
[Epoch 12; Iter   173/ 1097] train: loss: 0.0267386
[Epoch 12; Iter   203/ 1097] train: loss: 0.0948609
[Epoch 12; Iter   233/ 1097] train: loss: 0.0239323
[Epoch 12; Iter   263/ 1097] train: loss: 0.0529301
[Epoch 12; Iter   293/ 1097] train: loss: 0.1773189
[Epoch 12; Iter   323/ 1097] train: loss: 0.2213985
[Epoch 12; Iter   353/ 1097] train: loss: 0.1408374
[Epoch 12; Iter   383/ 1097] train: loss: 0.0395671
[Epoch 12; Iter   413/ 1097] train: loss: 0.0327149
[Epoch 12; Iter   443/ 1097] train: loss: 0.0257489
[Epoch 12; Iter   473/ 1097] train: loss: 0.2292518
[Epoch 12; Iter   503/ 1097] train: loss: 0.1549254
[Epoch 12; Iter   533/ 1097] train: loss: 0.0289622
[Epoch 12; Iter   563/ 1097] train: loss: 0.1452183
[Epoch 12; Iter   593/ 1097] train: loss: 0.1385876
[Epoch 12; Iter   623/ 1097] train: loss: 0.0340436
[Epoch 12; Iter   653/ 1097] train: loss: 0.1071204
[Epoch 12; Iter   683/ 1097] train: loss: 0.3713615
[Epoch 12; Iter   713/ 1097] train: loss: 0.1393153
[Epoch 12; Iter   743/ 1097] train: loss: 0.0215716
[Epoch 12; Iter   773/ 1097] train: loss: 0.2217527
[Epoch 12; Iter   803/ 1097] train: loss: 0.1499690
[Epoch 12; Iter   833/ 1097] train: loss: 0.0813637
[Epoch 12; Iter   863/ 1097] train: loss: 0.0536533
[Epoch 12; Iter   893/ 1097] train: loss: 0.1659314
[Epoch 12; Iter   923/ 1097] train: loss: 0.0341882
[Epoch 12; Iter   953/ 1097] train: loss: 0.2130359
[Epoch 12; Iter   983/ 1097] train: loss: 0.2968222
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0300492
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0242791
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0268590
[Epoch 12] ogbg-molhiv: 0.751320 val loss: 0.098338
[Epoch 12] ogbg-molhiv: 0.739931 test loss: 0.126321
[Epoch 13; Iter     6/ 1097] train: loss: 0.1466466
[Epoch 13; Iter    36/ 1097] train: loss: 0.1639759
[Epoch 13; Iter    66/ 1097] train: loss: 0.2437707
[Epoch 13; Iter    96/ 1097] train: loss: 0.0327839
[Epoch 13; Iter   126/ 1097] train: loss: 0.0589641
[Epoch 13; Iter   156/ 1097] train: loss: 0.2310124
[Epoch 13; Iter   186/ 1097] train: loss: 0.2517264
[Epoch 13; Iter   216/ 1097] train: loss: 0.1430513
[Epoch 13; Iter   246/ 1097] train: loss: 0.0445436
[Epoch 13; Iter   276/ 1097] train: loss: 0.0255186
[Epoch 13; Iter   306/ 1097] train: loss: 0.2882238
[Epoch 13; Iter   336/ 1097] train: loss: 0.1132547
[Epoch 13; Iter   366/ 1097] train: loss: 0.3375199
[Epoch 13; Iter   396/ 1097] train: loss: 0.0434309
[Epoch 13; Iter   426/ 1097] train: loss: 0.1298769
[Epoch 13; Iter   456/ 1097] train: loss: 0.1523434
[Epoch 13; Iter   486/ 1097] train: loss: 0.0315062
[Epoch 13; Iter   516/ 1097] train: loss: 0.1909712
[Epoch 13; Iter   546/ 1097] train: loss: 0.0232763
[Epoch 13; Iter   576/ 1097] train: loss: 0.1329808
[Epoch 13; Iter   606/ 1097] train: loss: 0.1797983
[Epoch 13; Iter   636/ 1097] train: loss: 0.0594977
[Epoch 13; Iter   666/ 1097] train: loss: 0.1680093
[Epoch 13; Iter   696/ 1097] train: loss: 0.3814094
[Epoch 13; Iter   726/ 1097] train: loss: 0.0667401
[Epoch 13; Iter   756/ 1097] train: loss: 0.0462843
[Epoch 13; Iter   786/ 1097] train: loss: 0.2181338
[Epoch 13; Iter   816/ 1097] train: loss: 0.0582273
[Epoch 13; Iter   846/ 1097] train: loss: 0.0390739
[Epoch 13; Iter   876/ 1097] train: loss: 0.2563255
[Epoch 13; Iter   906/ 1097] train: loss: 0.3106483
[Epoch 13; Iter   936/ 1097] train: loss: 0.0268958
[Epoch 13; Iter   966/ 1097] train: loss: 0.0876754
[Epoch 13; Iter   996/ 1097] train: loss: 0.0306684
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0350624
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1720634
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1673429
[Epoch 13] ogbg-molhiv: 0.733940 val loss: 0.164204
[Epoch 13] ogbg-molhiv: 0.663306 test loss: 0.155507
[Epoch 14; Iter    19/ 1097] train: loss: 0.2516912
[Epoch 14; Iter    49/ 1097] train: loss: 0.1235782
[Epoch 14; Iter    79/ 1097] train: loss: 0.0690616
[Epoch 14; Iter   109/ 1097] train: loss: 0.1344259
[Epoch 14; Iter   139/ 1097] train: loss: 0.0337073
[Epoch 14; Iter   169/ 1097] train: loss: 0.2388545
[Epoch 14; Iter   199/ 1097] train: loss: 0.0189775
[Epoch 14; Iter   229/ 1097] train: loss: 0.3794264
[Epoch 14; Iter   259/ 1097] train: loss: 0.3779158
[Epoch 14; Iter   289/ 1097] train: loss: 0.0598117
[Epoch 14; Iter   319/ 1097] train: loss: 0.0352410
[Epoch 14; Iter   349/ 1097] train: loss: 0.0535947
[Epoch 14; Iter   379/ 1097] train: loss: 0.0345164
[Epoch 14; Iter   409/ 1097] train: loss: 0.0779178
[Epoch 14; Iter   439/ 1097] train: loss: 0.2302901
[Epoch 14; Iter   469/ 1097] train: loss: 0.2466886
[Epoch 14; Iter   499/ 1097] train: loss: 0.0280686
[Epoch 14; Iter   529/ 1097] train: loss: 0.3422413
[Epoch 14; Iter   559/ 1097] train: loss: 0.0381256
[Epoch 14; Iter   589/ 1097] train: loss: 0.1751816
[Epoch 14; Iter   619/ 1097] train: loss: 0.2056190
[Epoch 14; Iter   649/ 1097] train: loss: 0.0545259
[Epoch 14; Iter   679/ 1097] train: loss: 0.0458577
[Epoch 14; Iter   709/ 1097] train: loss: 0.1575278
[Epoch 14; Iter   739/ 1097] train: loss: 0.1520590
[Epoch 14; Iter   769/ 1097] train: loss: 0.0189077
[Epoch 14; Iter   799/ 1097] train: loss: 0.0700045
[Epoch 14; Iter   829/ 1097] train: loss: 0.1392412
[Epoch 14; Iter   859/ 1097] train: loss: 0.0317811
[Epoch 14; Iter   889/ 1097] train: loss: 0.0958738
[Epoch 14; Iter   919/ 1097] train: loss: 0.1839984
[Epoch 14; Iter   949/ 1097] train: loss: 0.2199503
[Epoch 14; Iter   979/ 1097] train: loss: 0.0841629
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2678634
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0365662
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0548128
[Epoch 14] ogbg-molhiv: 0.728104 val loss: 0.107510
[Epoch 14] ogbg-molhiv: 0.702768 test loss: 0.140495
[Epoch 15; Iter     2/ 1097] train: loss: 0.0847699
[Epoch 15; Iter    32/ 1097] train: loss: 0.0762596
[Epoch 15; Iter    62/ 1097] train: loss: 0.0525654
[Epoch 15; Iter    92/ 1097] train: loss: 0.0500405
[Epoch 15; Iter   122/ 1097] train: loss: 0.1587272
[Epoch 15; Iter   152/ 1097] train: loss: 0.0229630
[Epoch 15; Iter   182/ 1097] train: loss: 0.1140600
[Epoch 15; Iter   212/ 1097] train: loss: 0.1775196
[Epoch 15; Iter   242/ 1097] train: loss: 0.1197053
[Epoch 15; Iter   272/ 1097] train: loss: 0.3284861
[Epoch 15; Iter   302/ 1097] train: loss: 0.1770988
[Epoch 15; Iter   332/ 1097] train: loss: 0.1495037
[Epoch 15; Iter   362/ 1097] train: loss: 0.1547594
[Epoch 15; Iter   392/ 1097] train: loss: 0.1967458
[Epoch 15; Iter   422/ 1097] train: loss: 0.1608159
[Epoch 15; Iter   452/ 1097] train: loss: 0.0418175
[Epoch 15; Iter   482/ 1097] train: loss: 0.1382853
[Epoch 15; Iter   512/ 1097] train: loss: 0.2822459
[Epoch 15; Iter   542/ 1097] train: loss: 0.1286837
[Epoch 15; Iter   572/ 1097] train: loss: 0.1084290
[Epoch 15; Iter   602/ 1097] train: loss: 0.0363544
[Epoch 15; Iter   632/ 1097] train: loss: 0.3491097
[Epoch 15; Iter   662/ 1097] train: loss: 0.0474288
[Epoch 15; Iter   692/ 1097] train: loss: 0.1121982
[Epoch 15; Iter   722/ 1097] train: loss: 0.0964209
[Epoch 15; Iter   752/ 1097] train: loss: 0.1168960
[Epoch 15; Iter   782/ 1097] train: loss: 0.0404918
[Epoch 15; Iter   812/ 1097] train: loss: 0.0223504
[Epoch 15; Iter   842/ 1097] train: loss: 0.0467726
[Epoch 15; Iter   872/ 1097] train: loss: 0.0235688
[Epoch 15; Iter   902/ 1097] train: loss: 0.0444430
[Epoch 15; Iter   932/ 1097] train: loss: 0.1923147
[Epoch 15; Iter   962/ 1097] train: loss: 0.2490098
[Epoch 15; Iter   992/ 1097] train: loss: 0.0374602
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1159616
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1160262
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0200637
[Epoch 15] ogbg-molhiv: 0.716484 val loss: 0.715847
[Epoch 15] ogbg-molhiv: 0.701321 test loss: 0.408725
[Epoch 16; Iter    15/ 1097] train: loss: 0.0278147
[Epoch 16; Iter    45/ 1097] train: loss: 0.0783074
[Epoch 16; Iter    75/ 1097] train: loss: 0.1624601
[Epoch 16; Iter   105/ 1097] train: loss: 0.0267519
[Epoch 16; Iter   135/ 1097] train: loss: 0.0938684
[Epoch 16; Iter   165/ 1097] train: loss: 0.1169981
[Epoch 16; Iter   195/ 1097] train: loss: 0.0834135
[Epoch 16; Iter   225/ 1097] train: loss: 0.0424897
[Epoch 16; Iter   255/ 1097] train: loss: 0.0524732
[Epoch 16; Iter   285/ 1097] train: loss: 0.1336714
[Epoch 16; Iter   315/ 1097] train: loss: 0.0734878
[Epoch 16; Iter   345/ 1097] train: loss: 0.0510215
[Epoch 16; Iter   375/ 1097] train: loss: 0.1956032
[Epoch 16; Iter   405/ 1097] train: loss: 0.2136986
[Epoch 16; Iter   435/ 1097] train: loss: 0.1074445
[Epoch 16; Iter   465/ 1097] train: loss: 0.1219115
[Epoch 16; Iter   495/ 1097] train: loss: 0.1240761
[Epoch 16; Iter   525/ 1097] train: loss: 0.0896011
[Epoch 16; Iter   555/ 1097] train: loss: 0.0261420
[Epoch 16; Iter   585/ 1097] train: loss: 0.1175992
[Epoch 16; Iter   615/ 1097] train: loss: 0.1902802
[Epoch 16; Iter   645/ 1097] train: loss: 0.0225352
[Epoch 16; Iter   675/ 1097] train: loss: 0.0672526
[Epoch 16; Iter   705/ 1097] train: loss: 0.1641947
[Epoch 16; Iter   735/ 1097] train: loss: 0.0661413
[Epoch 16; Iter   765/ 1097] train: loss: 0.0314364
[Epoch 16; Iter   795/ 1097] train: loss: 0.1295800
[Epoch 16; Iter   825/ 1097] train: loss: 0.0268828
[Epoch 16; Iter   855/ 1097] train: loss: 0.0985743
[Epoch 16; Iter   885/ 1097] train: loss: 0.1866173
[Epoch 16; Iter   915/ 1097] train: loss: 0.0235791
[Epoch 16; Iter   945/ 1097] train: loss: 0.0254358
[Epoch 16; Iter   975/ 1097] train: loss: 0.0236218
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0518658
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0347914
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0976603
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1383671
[Epoch 16] ogbg-molhiv: 0.768889 val loss: 0.078907
[Epoch 16] ogbg-molhiv: 0.752916 test loss: 0.119746
[Epoch 17; Iter    28/ 1097] train: loss: 0.0188549
[Epoch 17; Iter    58/ 1097] train: loss: 0.0344624
[Epoch 17; Iter    88/ 1097] train: loss: 0.0233626
[Epoch 17; Iter   118/ 1097] train: loss: 0.1496376
[Epoch 17; Iter   148/ 1097] train: loss: 0.1124697
[Epoch 17; Iter   178/ 1097] train: loss: 0.0314956
[Epoch 17; Iter   208/ 1097] train: loss: 0.0224744
[Epoch 17; Iter   238/ 1097] train: loss: 0.2913436
[Epoch 17; Iter   268/ 1097] train: loss: 0.0182701
[Epoch 17; Iter   298/ 1097] train: loss: 0.0366535
[Epoch 17; Iter   328/ 1097] train: loss: 0.0265793
[Epoch 17; Iter   358/ 1097] train: loss: 0.0343026
[Epoch 17; Iter   388/ 1097] train: loss: 0.0520152
[Epoch 17; Iter   418/ 1097] train: loss: 0.2955225
[Epoch 17; Iter   448/ 1097] train: loss: 0.0231950
[Epoch 17; Iter   478/ 1097] train: loss: 0.1057376
[Epoch 17; Iter   508/ 1097] train: loss: 0.0259259
[Epoch 17; Iter   538/ 1097] train: loss: 0.2812830
[Epoch 17; Iter   568/ 1097] train: loss: 0.1631351
[Epoch 17; Iter   598/ 1097] train: loss: 0.0946305
[Epoch 17; Iter   628/ 1097] train: loss: 0.0486116
[Epoch 17; Iter   658/ 1097] train: loss: 0.0315751
[Epoch 17; Iter   688/ 1097] train: loss: 0.2028709
[Epoch 17; Iter   718/ 1097] train: loss: 0.0308717
[Epoch 17; Iter   748/ 1097] train: loss: 0.1241860
[Epoch 17; Iter   778/ 1097] train: loss: 0.0543409
[Epoch 17; Iter   808/ 1097] train: loss: 0.1054367
[Epoch 17; Iter   838/ 1097] train: loss: 0.0588390
[Epoch 17; Iter   868/ 1097] train: loss: 0.0253330
[Epoch 17; Iter   898/ 1097] train: loss: 0.2260761
[Epoch 17; Iter   928/ 1097] train: loss: 0.1540064
[Epoch 17; Iter   958/ 1097] train: loss: 0.1439238
[Epoch 17; Iter   988/ 1097] train: loss: 0.0466545
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0271222
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0285277
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2038584
[Epoch 17] ogbg-molhiv: 0.762061 val loss: 0.129405
[Epoch 17] ogbg-molhiv: 0.739126 test loss: 0.123449
[Epoch 18; Iter    11/ 1097] train: loss: 0.1119691
[Epoch 18; Iter    41/ 1097] train: loss: 0.2601064
[Epoch 18; Iter    71/ 1097] train: loss: 0.0590092
[Epoch 18; Iter   101/ 1097] train: loss: 0.1351019
[Epoch 18; Iter   131/ 1097] train: loss: 0.1806298
[Epoch 18; Iter   161/ 1097] train: loss: 0.0736471
[Epoch 18; Iter   191/ 1097] train: loss: 0.2007890
[Epoch 18; Iter   221/ 1097] train: loss: 0.0837640
[Epoch 18; Iter   251/ 1097] train: loss: 0.2250067
[Epoch 18; Iter   281/ 1097] train: loss: 0.0213065
[Epoch 18; Iter   311/ 1097] train: loss: 0.0600045
[Epoch 18; Iter   341/ 1097] train: loss: 0.0433871
[Epoch 18; Iter   371/ 1097] train: loss: 0.0324061
[Epoch 18; Iter   401/ 1097] train: loss: 0.3021784
[Epoch 18; Iter   431/ 1097] train: loss: 0.2078892
[Epoch 18; Iter   461/ 1097] train: loss: 0.0364921
[Epoch 18; Iter   491/ 1097] train: loss: 0.2438582
[Epoch 18; Iter   521/ 1097] train: loss: 0.2570526
[Epoch 18; Iter   551/ 1097] train: loss: 0.0592357
[Epoch 18; Iter   581/ 1097] train: loss: 0.0714100
[Epoch 18; Iter   611/ 1097] train: loss: 0.0139613
[Epoch 18; Iter   641/ 1097] train: loss: 0.3364346
[Epoch 18; Iter   671/ 1097] train: loss: 0.0342293
[Epoch 18; Iter   701/ 1097] train: loss: 0.1783386
[Epoch 18; Iter   731/ 1097] train: loss: 0.0868927
[Epoch 18; Iter   761/ 1097] train: loss: 0.2847262
[Epoch 18; Iter   791/ 1097] train: loss: 0.0596829
[Epoch 18; Iter   821/ 1097] train: loss: 0.0661980
[Epoch 18; Iter   851/ 1097] train: loss: 0.1280299
[Epoch 18; Iter   881/ 1097] train: loss: 0.0876425
[Epoch 18; Iter   911/ 1097] train: loss: 0.1862762
[Epoch 18; Iter   941/ 1097] train: loss: 0.0206208
[Epoch 18; Iter   971/ 1097] train: loss: 0.1588256
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0357237
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0848755
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0470116
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1913428
[Epoch 18] ogbg-molhiv: 0.747284 val loss: 0.097895
[Epoch 18] ogbg-molhiv: 0.741364 test loss: 0.127089
[Epoch 19; Iter    24/ 1097] train: loss: 0.1716530
[Epoch 19; Iter    54/ 1097] train: loss: 0.0920875
[Epoch 19; Iter    84/ 1097] train: loss: 0.1575358
[Epoch 19; Iter   114/ 1097] train: loss: 0.0307237
[Epoch 19; Iter   144/ 1097] train: loss: 0.0661557
[Epoch 19; Iter   174/ 1097] train: loss: 0.0385609
[Epoch 19; Iter   204/ 1097] train: loss: 0.0611365
[Epoch 19; Iter   234/ 1097] train: loss: 0.0178118
[Epoch 19; Iter   264/ 1097] train: loss: 0.1150262
[Epoch 19; Iter   294/ 1097] train: loss: 0.0783258
[Epoch 19; Iter   324/ 1097] train: loss: 0.0465787
[Epoch 19; Iter   354/ 1097] train: loss: 0.2665694
[Epoch 19; Iter   384/ 1097] train: loss: 0.0277724
[Epoch 19; Iter   414/ 1097] train: loss: 0.0531349
[Epoch 19; Iter   444/ 1097] train: loss: 0.0591281
[Epoch 19; Iter   474/ 1097] train: loss: 0.1642380
[Epoch 19; Iter   504/ 1097] train: loss: 0.1433155
[Epoch 19; Iter   534/ 1097] train: loss: 0.1454556
[Epoch 19; Iter   564/ 1097] train: loss: 0.0195310
[Epoch 19; Iter   594/ 1097] train: loss: 0.0198105
[Epoch 19; Iter   624/ 1097] train: loss: 0.0813658
[Epoch 19; Iter   654/ 1097] train: loss: 0.1983657
[Epoch 19; Iter   684/ 1097] train: loss: 0.0301941
[Epoch 19; Iter   714/ 1097] train: loss: 0.1495751
[Epoch 19; Iter   744/ 1097] train: loss: 0.0298095
[Epoch 19; Iter   774/ 1097] train: loss: 0.1232981
[Epoch 19; Iter   804/ 1097] train: loss: 0.0694106
[Epoch 19; Iter   834/ 1097] train: loss: 0.2260387
[Epoch 19; Iter   864/ 1097] train: loss: 0.2980443
[Epoch 19; Iter   894/ 1097] train: loss: 0.2141733
[Epoch 19; Iter   924/ 1097] train: loss: 0.3557183
[Epoch 19; Iter   954/ 1097] train: loss: 0.0601726
[Epoch 19; Iter   984/ 1097] train: loss: 0.2326189
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1298092
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0354598
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0285611
[Epoch 19] ogbg-molhiv: 0.784630 val loss: 0.347188
[Epoch 19] ogbg-molhiv: 0.742873 test loss: 0.184137
[Epoch 20; Iter     7/ 1097] train: loss: 0.0396321
[Epoch 20; Iter    37/ 1097] train: loss: 0.1737513
[Epoch 20; Iter    67/ 1097] train: loss: 0.1009379
[Epoch 20; Iter    97/ 1097] train: loss: 0.0228160
[Epoch 20; Iter   127/ 1097] train: loss: 0.0728451
[Epoch 20; Iter   157/ 1097] train: loss: 0.0785340
[Epoch 20; Iter   187/ 1097] train: loss: 0.0224258
[Epoch 20; Iter   217/ 1097] train: loss: 0.0282402
[Epoch 20; Iter   247/ 1097] train: loss: 0.0254867
[Epoch 16; Iter   195/ 1097] train: loss: 0.0188207
[Epoch 16; Iter   225/ 1097] train: loss: 0.1294577
[Epoch 16; Iter   255/ 1097] train: loss: 0.0446327
[Epoch 16; Iter   285/ 1097] train: loss: 0.1759454
[Epoch 16; Iter   315/ 1097] train: loss: 0.0395108
[Epoch 16; Iter   345/ 1097] train: loss: 0.1643294
[Epoch 16; Iter   375/ 1097] train: loss: 0.1001087
[Epoch 16; Iter   405/ 1097] train: loss: 0.0551175
[Epoch 16; Iter   435/ 1097] train: loss: 0.3075148
[Epoch 16; Iter   465/ 1097] train: loss: 0.0735207
[Epoch 16; Iter   495/ 1097] train: loss: 0.0164162
[Epoch 16; Iter   525/ 1097] train: loss: 0.1804729
[Epoch 16; Iter   555/ 1097] train: loss: 0.0167891
[Epoch 16; Iter   585/ 1097] train: loss: 0.2318011
[Epoch 16; Iter   615/ 1097] train: loss: 0.0974195
[Epoch 16; Iter   645/ 1097] train: loss: 0.0398121
[Epoch 16; Iter   675/ 1097] train: loss: 0.0295431
[Epoch 16; Iter   705/ 1097] train: loss: 0.0480521
[Epoch 16; Iter   735/ 1097] train: loss: 0.2494223
[Epoch 16; Iter   765/ 1097] train: loss: 0.0474342
[Epoch 16; Iter   795/ 1097] train: loss: 0.0345776
[Epoch 16; Iter   825/ 1097] train: loss: 0.1843157
[Epoch 16; Iter   855/ 1097] train: loss: 0.1798225
[Epoch 16; Iter   885/ 1097] train: loss: 0.0240152
[Epoch 16; Iter   915/ 1097] train: loss: 0.1069932
[Epoch 16; Iter   945/ 1097] train: loss: 0.1016464
[Epoch 16; Iter   975/ 1097] train: loss: 0.1694951
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2037675
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0343184
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1424705
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0997407
[Epoch 16] ogbg-molhiv: 0.804909 val loss: 0.189636
[Epoch 16] ogbg-molhiv: 0.793148 test loss: 0.224414
[Epoch 17; Iter    28/ 1097] train: loss: 0.2725261
[Epoch 17; Iter    58/ 1097] train: loss: 0.0296810
[Epoch 17; Iter    88/ 1097] train: loss: 0.1849203
[Epoch 17; Iter   118/ 1097] train: loss: 0.1585249
[Epoch 17; Iter   148/ 1097] train: loss: 0.0458410
[Epoch 17; Iter   178/ 1097] train: loss: 0.2311696
[Epoch 17; Iter   208/ 1097] train: loss: 0.0359775
[Epoch 17; Iter   238/ 1097] train: loss: 0.2062441
[Epoch 17; Iter   268/ 1097] train: loss: 0.0446452
[Epoch 17; Iter   298/ 1097] train: loss: 0.2356565
[Epoch 17; Iter   328/ 1097] train: loss: 0.1640534
[Epoch 17; Iter   358/ 1097] train: loss: 0.0411443
[Epoch 17; Iter   388/ 1097] train: loss: 0.1438159
[Epoch 17; Iter   418/ 1097] train: loss: 0.2408105
[Epoch 17; Iter   448/ 1097] train: loss: 0.0298770
[Epoch 17; Iter   478/ 1097] train: loss: 0.0215119
[Epoch 17; Iter   508/ 1097] train: loss: 0.0836615
[Epoch 17; Iter   538/ 1097] train: loss: 0.0310350
[Epoch 17; Iter   568/ 1097] train: loss: 0.2182626
[Epoch 17; Iter   598/ 1097] train: loss: 0.0567810
[Epoch 17; Iter   628/ 1097] train: loss: 0.1821733
[Epoch 17; Iter   658/ 1097] train: loss: 0.0614497
[Epoch 17; Iter   688/ 1097] train: loss: 0.0749178
[Epoch 17; Iter   718/ 1097] train: loss: 0.2053710
[Epoch 17; Iter   748/ 1097] train: loss: 0.0197138
[Epoch 17; Iter   778/ 1097] train: loss: 0.1673985
[Epoch 17; Iter   808/ 1097] train: loss: 0.0221159
[Epoch 17; Iter   838/ 1097] train: loss: 0.0240817
[Epoch 17; Iter   868/ 1097] train: loss: 0.0191134
[Epoch 17; Iter   898/ 1097] train: loss: 0.0290028
[Epoch 17; Iter   928/ 1097] train: loss: 0.3574730
[Epoch 17; Iter   958/ 1097] train: loss: 0.1349977
[Epoch 17; Iter   988/ 1097] train: loss: 0.0572003
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0275903
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0399910
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1128122
[Epoch 17] ogbg-molhiv: 0.713903 val loss: 0.087245
[Epoch 17] ogbg-molhiv: 0.705491 test loss: 0.167952
[Epoch 18; Iter    11/ 1097] train: loss: 0.0742070
[Epoch 18; Iter    41/ 1097] train: loss: 0.0277438
[Epoch 18; Iter    71/ 1097] train: loss: 0.1301986
[Epoch 18; Iter   101/ 1097] train: loss: 0.0204931
[Epoch 18; Iter   131/ 1097] train: loss: 0.1057857
[Epoch 18; Iter   161/ 1097] train: loss: 0.1905948
[Epoch 18; Iter   191/ 1097] train: loss: 0.0193667
[Epoch 18; Iter   221/ 1097] train: loss: 0.0188033
[Epoch 18; Iter   251/ 1097] train: loss: 0.0812167
[Epoch 18; Iter   281/ 1097] train: loss: 0.0167683
[Epoch 18; Iter   311/ 1097] train: loss: 0.2644617
[Epoch 18; Iter   341/ 1097] train: loss: 0.1495997
[Epoch 18; Iter   371/ 1097] train: loss: 0.0222106
[Epoch 18; Iter   401/ 1097] train: loss: 0.0326517
[Epoch 18; Iter   431/ 1097] train: loss: 0.0247613
[Epoch 18; Iter   461/ 1097] train: loss: 0.0135081
[Epoch 18; Iter   491/ 1097] train: loss: 0.1123324
[Epoch 18; Iter   521/ 1097] train: loss: 0.0532151
[Epoch 18; Iter   551/ 1097] train: loss: 0.0483943
[Epoch 18; Iter   581/ 1097] train: loss: 0.0252406
[Epoch 18; Iter   611/ 1097] train: loss: 0.1562634
[Epoch 18; Iter   641/ 1097] train: loss: 0.0662851
[Epoch 18; Iter   671/ 1097] train: loss: 0.2369673
[Epoch 18; Iter   701/ 1097] train: loss: 0.1483395
[Epoch 18; Iter   731/ 1097] train: loss: 0.1531042
[Epoch 18; Iter   761/ 1097] train: loss: 0.0456377
[Epoch 18; Iter   791/ 1097] train: loss: 0.0435411
[Epoch 18; Iter   821/ 1097] train: loss: 0.0323094
[Epoch 18; Iter   851/ 1097] train: loss: 0.1470543
[Epoch 18; Iter   881/ 1097] train: loss: 0.0271911
[Epoch 18; Iter   911/ 1097] train: loss: 0.0314059
[Epoch 18; Iter   941/ 1097] train: loss: 0.0314736
[Epoch 18; Iter   971/ 1097] train: loss: 0.0391640
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0770030
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0258013
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0457125
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0494745
[Epoch 18] ogbg-molhiv: 0.776954 val loss: 0.111515
[Epoch 18] ogbg-molhiv: 0.762095 test loss: 0.195862
[Epoch 19; Iter    24/ 1097] train: loss: 0.0750124
[Epoch 19; Iter    54/ 1097] train: loss: 0.1215317
[Epoch 19; Iter    84/ 1097] train: loss: 0.0210183
[Epoch 19; Iter   114/ 1097] train: loss: 0.0755086
[Epoch 19; Iter   144/ 1097] train: loss: 0.1513793
[Epoch 19; Iter   174/ 1097] train: loss: 0.0940844
[Epoch 19; Iter   204/ 1097] train: loss: 0.0569376
[Epoch 19; Iter   234/ 1097] train: loss: 0.0583511
[Epoch 19; Iter   264/ 1097] train: loss: 0.2593563
[Epoch 19; Iter   294/ 1097] train: loss: 0.1857756
[Epoch 19; Iter   324/ 1097] train: loss: 0.0695587
[Epoch 19; Iter   354/ 1097] train: loss: 0.0991975
[Epoch 19; Iter   384/ 1097] train: loss: 0.2004332
[Epoch 19; Iter   414/ 1097] train: loss: 0.1630745
[Epoch 19; Iter   444/ 1097] train: loss: 0.0713017
[Epoch 19; Iter   474/ 1097] train: loss: 0.0135316
[Epoch 19; Iter   504/ 1097] train: loss: 0.2170400
[Epoch 19; Iter   534/ 1097] train: loss: 0.2308500
[Epoch 19; Iter   564/ 1097] train: loss: 0.1477256
[Epoch 19; Iter   594/ 1097] train: loss: 0.0671148
[Epoch 19; Iter   624/ 1097] train: loss: 0.0240519
[Epoch 19; Iter   654/ 1097] train: loss: 0.1845714
[Epoch 19; Iter   684/ 1097] train: loss: 0.0645774
[Epoch 19; Iter   714/ 1097] train: loss: 0.1685624
[Epoch 19; Iter   744/ 1097] train: loss: 0.1960071
[Epoch 19; Iter   774/ 1097] train: loss: 0.0925742
[Epoch 19; Iter   804/ 1097] train: loss: 0.0327382
[Epoch 19; Iter   834/ 1097] train: loss: 0.1790172
[Epoch 19; Iter   864/ 1097] train: loss: 0.1979064
[Epoch 19; Iter   894/ 1097] train: loss: 0.1003088
[Epoch 19; Iter   924/ 1097] train: loss: 0.2443701
[Epoch 19; Iter   954/ 1097] train: loss: 0.1003888
[Epoch 19; Iter   984/ 1097] train: loss: 0.0309256
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1357666
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0578798
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0201936
[Epoch 19] ogbg-molhiv: 0.705856 val loss: 0.089633
[Epoch 19] ogbg-molhiv: 0.695191 test loss: 0.171107
[Epoch 20; Iter     7/ 1097] train: loss: 0.1554365
[Epoch 20; Iter    37/ 1097] train: loss: 0.2317273
[Epoch 20; Iter    67/ 1097] train: loss: 0.0256022
[Epoch 20; Iter    97/ 1097] train: loss: 0.1313428
[Epoch 20; Iter   127/ 1097] train: loss: 0.1531161
[Epoch 20; Iter   157/ 1097] train: loss: 0.0438326
[Epoch 20; Iter   187/ 1097] train: loss: 0.0607621
[Epoch 20; Iter   217/ 1097] train: loss: 0.1650363
[Epoch 20; Iter   247/ 1097] train: loss: 0.0403036
[Epoch 16; Iter   195/ 1097] train: loss: 0.0388917
[Epoch 16; Iter   225/ 1097] train: loss: 0.0487024
[Epoch 16; Iter   255/ 1097] train: loss: 0.2483837
[Epoch 16; Iter   285/ 1097] train: loss: 0.0450258
[Epoch 16; Iter   315/ 1097] train: loss: 0.0543446
[Epoch 16; Iter   345/ 1097] train: loss: 0.0727384
[Epoch 16; Iter   375/ 1097] train: loss: 0.0282129
[Epoch 16; Iter   405/ 1097] train: loss: 0.0314456
[Epoch 16; Iter   435/ 1097] train: loss: 0.1116397
[Epoch 16; Iter   465/ 1097] train: loss: 0.1316127
[Epoch 16; Iter   495/ 1097] train: loss: 0.0338485
[Epoch 16; Iter   525/ 1097] train: loss: 0.0256013
[Epoch 16; Iter   555/ 1097] train: loss: 0.3726931
[Epoch 16; Iter   585/ 1097] train: loss: 0.0432271
[Epoch 16; Iter   615/ 1097] train: loss: 0.1240622
[Epoch 16; Iter   645/ 1097] train: loss: 0.0647057
[Epoch 16; Iter   675/ 1097] train: loss: 0.1296920
[Epoch 16; Iter   705/ 1097] train: loss: 0.0220106
[Epoch 16; Iter   735/ 1097] train: loss: 0.1837292
[Epoch 16; Iter   765/ 1097] train: loss: 0.3356697
[Epoch 16; Iter   795/ 1097] train: loss: 0.0535040
[Epoch 16; Iter   825/ 1097] train: loss: 0.0800119
[Epoch 16; Iter   855/ 1097] train: loss: 0.0290575
[Epoch 16; Iter   885/ 1097] train: loss: 0.1594512
[Epoch 16; Iter   915/ 1097] train: loss: 0.1441581
[Epoch 16; Iter   945/ 1097] train: loss: 0.0275865
[Epoch 16; Iter   975/ 1097] train: loss: 0.0296606
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1105883
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0335474
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0297682
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0318702
[Epoch 16] ogbg-molhiv: 0.783050 val loss: 0.124076
[Epoch 16] ogbg-molhiv: 0.749843 test loss: 0.173458
[Epoch 17; Iter    28/ 1097] train: loss: 0.1646971
[Epoch 17; Iter    58/ 1097] train: loss: 0.1068144
[Epoch 17; Iter    88/ 1097] train: loss: 0.1710454
[Epoch 17; Iter   118/ 1097] train: loss: 0.0268593
[Epoch 17; Iter   148/ 1097] train: loss: 0.0295759
[Epoch 17; Iter   178/ 1097] train: loss: 0.0218724
[Epoch 17; Iter   208/ 1097] train: loss: 0.0171046
[Epoch 17; Iter   238/ 1097] train: loss: 0.0630722
[Epoch 17; Iter   268/ 1097] train: loss: 0.0680278
[Epoch 17; Iter   298/ 1097] train: loss: 0.0533432
[Epoch 17; Iter   328/ 1097] train: loss: 0.1388218
[Epoch 17; Iter   358/ 1097] train: loss: 0.1926904
[Epoch 17; Iter   388/ 1097] train: loss: 0.0440352
[Epoch 17; Iter   418/ 1097] train: loss: 0.1181138
[Epoch 17; Iter   448/ 1097] train: loss: 0.1098741
[Epoch 17; Iter   478/ 1097] train: loss: 0.2301528
[Epoch 17; Iter   508/ 1097] train: loss: 0.0554144
[Epoch 17; Iter   538/ 1097] train: loss: 0.0855620
[Epoch 17; Iter   568/ 1097] train: loss: 0.0231363
[Epoch 17; Iter   598/ 1097] train: loss: 0.0832609
[Epoch 17; Iter   628/ 1097] train: loss: 0.0533865
[Epoch 17; Iter   658/ 1097] train: loss: 0.4050982
[Epoch 17; Iter   688/ 1097] train: loss: 0.0228982
[Epoch 17; Iter   718/ 1097] train: loss: 0.1347430
[Epoch 17; Iter   748/ 1097] train: loss: 0.1840640
[Epoch 17; Iter   778/ 1097] train: loss: 0.1015281
[Epoch 17; Iter   808/ 1097] train: loss: 0.1581965
[Epoch 17; Iter   838/ 1097] train: loss: 0.0583512
[Epoch 17; Iter   868/ 1097] train: loss: 0.0366200
[Epoch 17; Iter   898/ 1097] train: loss: 0.1688682
[Epoch 17; Iter   928/ 1097] train: loss: 0.1588904
[Epoch 17; Iter   958/ 1097] train: loss: 0.0258058
[Epoch 17; Iter   988/ 1097] train: loss: 0.1175710
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0213445
[Epoch 17; Iter  1048/ 1097] train: loss: 0.3162536
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2764894
[Epoch 17] ogbg-molhiv: 0.761243 val loss: 0.076598
[Epoch 17] ogbg-molhiv: 0.713704 test loss: 0.140463
[Epoch 18; Iter    11/ 1097] train: loss: 0.0203826
[Epoch 18; Iter    41/ 1097] train: loss: 0.1953063
[Epoch 18; Iter    71/ 1097] train: loss: 0.1799549
[Epoch 18; Iter   101/ 1097] train: loss: 0.0223397
[Epoch 18; Iter   131/ 1097] train: loss: 0.0760295
[Epoch 18; Iter   161/ 1097] train: loss: 0.3211816
[Epoch 18; Iter   191/ 1097] train: loss: 0.0591609
[Epoch 18; Iter   221/ 1097] train: loss: 0.0420200
[Epoch 18; Iter   251/ 1097] train: loss: 0.0228123
[Epoch 18; Iter   281/ 1097] train: loss: 0.1125327
[Epoch 18; Iter   311/ 1097] train: loss: 0.0473437
[Epoch 18; Iter   341/ 1097] train: loss: 0.0307033
[Epoch 18; Iter   371/ 1097] train: loss: 0.0370129
[Epoch 18; Iter   401/ 1097] train: loss: 0.1800585
[Epoch 18; Iter   431/ 1097] train: loss: 0.0269648
[Epoch 18; Iter   461/ 1097] train: loss: 0.0653501
[Epoch 18; Iter   491/ 1097] train: loss: 0.0255512
[Epoch 18; Iter   521/ 1097] train: loss: 0.1281077
[Epoch 18; Iter   551/ 1097] train: loss: 0.1045167
[Epoch 18; Iter   581/ 1097] train: loss: 0.0525709
[Epoch 18; Iter   611/ 1097] train: loss: 0.0200471
[Epoch 18; Iter   641/ 1097] train: loss: 0.1544901
[Epoch 18; Iter   671/ 1097] train: loss: 0.0455067
[Epoch 18; Iter   701/ 1097] train: loss: 0.0709221
[Epoch 18; Iter   731/ 1097] train: loss: 0.0416400
[Epoch 18; Iter   761/ 1097] train: loss: 0.0375429
[Epoch 18; Iter   791/ 1097] train: loss: 0.0381568
[Epoch 18; Iter   821/ 1097] train: loss: 0.1262453
[Epoch 18; Iter   851/ 1097] train: loss: 0.0744709
[Epoch 18; Iter   881/ 1097] train: loss: 0.0424749
[Epoch 18; Iter   911/ 1097] train: loss: 0.0215424
[Epoch 18; Iter   941/ 1097] train: loss: 0.0793115
[Epoch 18; Iter   971/ 1097] train: loss: 0.0328531
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0747173
[Epoch 18; Iter  1031/ 1097] train: loss: 0.1114681
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0952953
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0146766
[Epoch 18] ogbg-molhiv: 0.746332 val loss: 0.509473
[Epoch 18] ogbg-molhiv: 0.737604 test loss: 0.142878
[Epoch 19; Iter    24/ 1097] train: loss: 0.0157381
[Epoch 19; Iter    54/ 1097] train: loss: 0.0186855
[Epoch 19; Iter    84/ 1097] train: loss: 0.0234870
[Epoch 19; Iter   114/ 1097] train: loss: 0.0223753
[Epoch 19; Iter   144/ 1097] train: loss: 0.0344860
[Epoch 19; Iter   174/ 1097] train: loss: 0.0106332
[Epoch 19; Iter   204/ 1097] train: loss: 0.0345925
[Epoch 19; Iter   234/ 1097] train: loss: 0.0276788
[Epoch 19; Iter   264/ 1097] train: loss: 0.0223895
[Epoch 19; Iter   294/ 1097] train: loss: 0.0355540
[Epoch 19; Iter   324/ 1097] train: loss: 0.0435343
[Epoch 19; Iter   354/ 1097] train: loss: 0.2815456
[Epoch 19; Iter   384/ 1097] train: loss: 0.0273688
[Epoch 19; Iter   414/ 1097] train: loss: 0.1690387
[Epoch 19; Iter   444/ 1097] train: loss: 0.0444195
[Epoch 19; Iter   474/ 1097] train: loss: 0.1490897
[Epoch 19; Iter   504/ 1097] train: loss: 0.0219228
[Epoch 19; Iter   534/ 1097] train: loss: 0.0367906
[Epoch 19; Iter   564/ 1097] train: loss: 0.1870548
[Epoch 19; Iter   594/ 1097] train: loss: 0.0475238
[Epoch 19; Iter   624/ 1097] train: loss: 0.0277458
[Epoch 19; Iter   654/ 1097] train: loss: 0.0336377
[Epoch 19; Iter   684/ 1097] train: loss: 0.4526207
[Epoch 19; Iter   714/ 1097] train: loss: 0.0658214
[Epoch 19; Iter   744/ 1097] train: loss: 0.0404768
[Epoch 19; Iter   774/ 1097] train: loss: 0.0772393
[Epoch 19; Iter   804/ 1097] train: loss: 0.0360865
[Epoch 19; Iter   834/ 1097] train: loss: 0.0258088
[Epoch 19; Iter   864/ 1097] train: loss: 0.0263135
[Epoch 19; Iter   894/ 1097] train: loss: 0.3805807
[Epoch 19; Iter   924/ 1097] train: loss: 0.1499632
[Epoch 19; Iter   954/ 1097] train: loss: 0.0140716
[Epoch 19; Iter   984/ 1097] train: loss: 0.0582292
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0985843
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0549873
[Epoch 19; Iter  1074/ 1097] train: loss: 0.2062189
[Epoch 19] ogbg-molhiv: 0.813618 val loss: 0.082884
[Epoch 19] ogbg-molhiv: 0.715470 test loss: 0.177412
[Epoch 20; Iter     7/ 1097] train: loss: 0.0535687
[Epoch 20; Iter    37/ 1097] train: loss: 0.0158230
[Epoch 20; Iter    67/ 1097] train: loss: 0.0457020
[Epoch 20; Iter    97/ 1097] train: loss: 0.0887508
[Epoch 20; Iter   127/ 1097] train: loss: 0.0202455
[Epoch 20; Iter   157/ 1097] train: loss: 0.0198214
[Epoch 20; Iter   187/ 1097] train: loss: 0.1366958
[Epoch 20; Iter   217/ 1097] train: loss: 0.2462328
[Epoch 20; Iter   247/ 1097] train: loss: 0.0182089
[Epoch 16; Iter   195/ 1097] train: loss: 0.0351019
[Epoch 16; Iter   225/ 1097] train: loss: 0.1379058
[Epoch 16; Iter   255/ 1097] train: loss: 0.0295904
[Epoch 16; Iter   285/ 1097] train: loss: 0.1713566
[Epoch 16; Iter   315/ 1097] train: loss: 0.0455707
[Epoch 16; Iter   345/ 1097] train: loss: 0.2072736
[Epoch 16; Iter   375/ 1097] train: loss: 0.0640163
[Epoch 16; Iter   405/ 1097] train: loss: 0.0408707
[Epoch 16; Iter   435/ 1097] train: loss: 0.2412878
[Epoch 16; Iter   465/ 1097] train: loss: 0.0532074
[Epoch 16; Iter   495/ 1097] train: loss: 0.0177232
[Epoch 16; Iter   525/ 1097] train: loss: 0.1277327
[Epoch 16; Iter   555/ 1097] train: loss: 0.0220784
[Epoch 16; Iter   585/ 1097] train: loss: 0.2321701
[Epoch 16; Iter   615/ 1097] train: loss: 0.0827898
[Epoch 16; Iter   645/ 1097] train: loss: 0.1027541
[Epoch 16; Iter   675/ 1097] train: loss: 0.0449502
[Epoch 16; Iter   705/ 1097] train: loss: 0.0428452
[Epoch 16; Iter   735/ 1097] train: loss: 0.2314121
[Epoch 16; Iter   765/ 1097] train: loss: 0.0286816
[Epoch 16; Iter   795/ 1097] train: loss: 0.0287650
[Epoch 16; Iter   825/ 1097] train: loss: 0.2783398
[Epoch 16; Iter   855/ 1097] train: loss: 0.1767610
[Epoch 16; Iter   885/ 1097] train: loss: 0.0309563
[Epoch 16; Iter   915/ 1097] train: loss: 0.0466407
[Epoch 16; Iter   945/ 1097] train: loss: 0.0942787
[Epoch 16; Iter   975/ 1097] train: loss: 0.1742958
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2311231
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0350830
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1762041
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1656144
[Epoch 16] ogbg-molhiv: 0.735603 val loss: 0.228108
[Epoch 16] ogbg-molhiv: 0.727325 test loss: 0.204218
[Epoch 17; Iter    28/ 1097] train: loss: 0.2257987
[Epoch 17; Iter    58/ 1097] train: loss: 0.0291833
[Epoch 17; Iter    88/ 1097] train: loss: 0.2246163
[Epoch 17; Iter   118/ 1097] train: loss: 0.3257439
[Epoch 17; Iter   148/ 1097] train: loss: 0.0198237
[Epoch 17; Iter   178/ 1097] train: loss: 0.1332504
[Epoch 17; Iter   208/ 1097] train: loss: 0.0648081
[Epoch 17; Iter   238/ 1097] train: loss: 0.1347067
[Epoch 17; Iter   268/ 1097] train: loss: 0.0318934
[Epoch 17; Iter   298/ 1097] train: loss: 0.1280908
[Epoch 17; Iter   328/ 1097] train: loss: 0.1774525
[Epoch 17; Iter   358/ 1097] train: loss: 0.0254495
[Epoch 17; Iter   388/ 1097] train: loss: 0.2268147
[Epoch 17; Iter   418/ 1097] train: loss: 0.1642519
[Epoch 17; Iter   448/ 1097] train: loss: 0.0319668
[Epoch 17; Iter   478/ 1097] train: loss: 0.0805724
[Epoch 17; Iter   508/ 1097] train: loss: 0.1273696
[Epoch 17; Iter   538/ 1097] train: loss: 0.0337984
[Epoch 17; Iter   568/ 1097] train: loss: 0.1825313
[Epoch 17; Iter   598/ 1097] train: loss: 0.0293787
[Epoch 17; Iter   628/ 1097] train: loss: 0.1961902
[Epoch 17; Iter   658/ 1097] train: loss: 0.1312016
[Epoch 17; Iter   688/ 1097] train: loss: 0.0530494
[Epoch 17; Iter   718/ 1097] train: loss: 0.1498314
[Epoch 17; Iter   748/ 1097] train: loss: 0.0196702
[Epoch 17; Iter   778/ 1097] train: loss: 0.2053163
[Epoch 17; Iter   808/ 1097] train: loss: 0.0235918
[Epoch 17; Iter   838/ 1097] train: loss: 0.0223189
[Epoch 17; Iter   868/ 1097] train: loss: 0.0382272
[Epoch 17; Iter   898/ 1097] train: loss: 0.0471381
[Epoch 17; Iter   928/ 1097] train: loss: 0.2966992
[Epoch 17; Iter   958/ 1097] train: loss: 0.0559162
[Epoch 17; Iter   988/ 1097] train: loss: 0.0257594
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0295980
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0499211
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0854548
[Epoch 17] ogbg-molhiv: 0.726108 val loss: 0.280383
[Epoch 17] ogbg-molhiv: 0.675571 test loss: 0.215636
[Epoch 18; Iter    11/ 1097] train: loss: 0.1420493
[Epoch 18; Iter    41/ 1097] train: loss: 0.0205014
[Epoch 18; Iter    71/ 1097] train: loss: 0.2460446
[Epoch 18; Iter   101/ 1097] train: loss: 0.0461989
[Epoch 18; Iter   131/ 1097] train: loss: 0.1848666
[Epoch 18; Iter   161/ 1097] train: loss: 0.1465978
[Epoch 18; Iter   191/ 1097] train: loss: 0.1571368
[Epoch 18; Iter   221/ 1097] train: loss: 0.0177066
[Epoch 18; Iter   251/ 1097] train: loss: 0.1055777
[Epoch 18; Iter   281/ 1097] train: loss: 0.0244458
[Epoch 18; Iter   311/ 1097] train: loss: 0.2651658
[Epoch 18; Iter   341/ 1097] train: loss: 0.1324233
[Epoch 18; Iter   371/ 1097] train: loss: 0.0308218
[Epoch 18; Iter   401/ 1097] train: loss: 0.0335318
[Epoch 18; Iter   431/ 1097] train: loss: 0.0245505
[Epoch 18; Iter   461/ 1097] train: loss: 0.0903825
[Epoch 18; Iter   491/ 1097] train: loss: 0.0471680
[Epoch 18; Iter   521/ 1097] train: loss: 0.0395568
[Epoch 18; Iter   551/ 1097] train: loss: 0.0437638
[Epoch 18; Iter   581/ 1097] train: loss: 0.0231530
[Epoch 18; Iter   611/ 1097] train: loss: 0.1239620
[Epoch 18; Iter   641/ 1097] train: loss: 0.0889913
[Epoch 18; Iter   671/ 1097] train: loss: 0.2033844
[Epoch 18; Iter   701/ 1097] train: loss: 0.1673314
[Epoch 18; Iter   731/ 1097] train: loss: 0.0809081
[Epoch 18; Iter   761/ 1097] train: loss: 0.0717690
[Epoch 18; Iter   791/ 1097] train: loss: 0.1809592
[Epoch 18; Iter   821/ 1097] train: loss: 0.0466439
[Epoch 18; Iter   851/ 1097] train: loss: 0.2120558
[Epoch 18; Iter   881/ 1097] train: loss: 0.0243590
[Epoch 18; Iter   911/ 1097] train: loss: 0.1693109
[Epoch 18; Iter   941/ 1097] train: loss: 0.0343950
[Epoch 18; Iter   971/ 1097] train: loss: 0.0265470
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1390022
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0232241
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0334290
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0348703
[Epoch 18] ogbg-molhiv: 0.752348 val loss: 0.140538
[Epoch 18] ogbg-molhiv: 0.720885 test loss: 0.158433
[Epoch 19; Iter    24/ 1097] train: loss: 0.1084879
[Epoch 19; Iter    54/ 1097] train: loss: 0.1464922
[Epoch 19; Iter    84/ 1097] train: loss: 0.0259336
[Epoch 19; Iter   114/ 1097] train: loss: 0.0372550
[Epoch 19; Iter   144/ 1097] train: loss: 0.0918701
[Epoch 19; Iter   174/ 1097] train: loss: 0.1055290
[Epoch 19; Iter   204/ 1097] train: loss: 0.0768003
[Epoch 19; Iter   234/ 1097] train: loss: 0.2033536
[Epoch 19; Iter   264/ 1097] train: loss: 0.1108745
[Epoch 19; Iter   294/ 1097] train: loss: 0.2073696
[Epoch 19; Iter   324/ 1097] train: loss: 0.0585541
[Epoch 19; Iter   354/ 1097] train: loss: 0.0237176
[Epoch 19; Iter   384/ 1097] train: loss: 0.1080202
[Epoch 19; Iter   414/ 1097] train: loss: 0.2786475
[Epoch 19; Iter   444/ 1097] train: loss: 0.0750133
[Epoch 19; Iter   474/ 1097] train: loss: 0.0309501
[Epoch 19; Iter   504/ 1097] train: loss: 0.1685506
[Epoch 19; Iter   534/ 1097] train: loss: 0.2266393
[Epoch 19; Iter   564/ 1097] train: loss: 0.1822469
[Epoch 19; Iter   594/ 1097] train: loss: 0.0256170
[Epoch 19; Iter   624/ 1097] train: loss: 0.0247793
[Epoch 19; Iter   654/ 1097] train: loss: 0.1810058
[Epoch 19; Iter   684/ 1097] train: loss: 0.0967710
[Epoch 19; Iter   714/ 1097] train: loss: 0.1070692
[Epoch 19; Iter   744/ 1097] train: loss: 0.1750031
[Epoch 19; Iter   774/ 1097] train: loss: 0.0899417
[Epoch 19; Iter   804/ 1097] train: loss: 0.0188208
[Epoch 19; Iter   834/ 1097] train: loss: 0.1951131
[Epoch 19; Iter   864/ 1097] train: loss: 0.1413018
[Epoch 19; Iter   894/ 1097] train: loss: 0.0572264
[Epoch 19; Iter   924/ 1097] train: loss: 0.0878602
[Epoch 19; Iter   954/ 1097] train: loss: 0.0894040
[Epoch 19; Iter   984/ 1097] train: loss: 0.0539643
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1544911
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0653488
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0275775
[Epoch 19] ogbg-molhiv: 0.726181 val loss: 0.089922
[Epoch 19] ogbg-molhiv: 0.713565 test loss: 0.125467
[Epoch 20; Iter     7/ 1097] train: loss: 0.1567661
[Epoch 20; Iter    37/ 1097] train: loss: 0.1360475
[Epoch 20; Iter    67/ 1097] train: loss: 0.0264379
[Epoch 20; Iter    97/ 1097] train: loss: 0.0618149
[Epoch 20; Iter   127/ 1097] train: loss: 0.1779633
[Epoch 20; Iter   157/ 1097] train: loss: 0.0228810
[Epoch 20; Iter   187/ 1097] train: loss: 0.0497823
[Epoch 20; Iter   217/ 1097] train: loss: 0.0208671
[Epoch 20; Iter   247/ 1097] train: loss: 0.0516095
[Epoch 16; Iter   195/ 1097] train: loss: 0.0305562
[Epoch 16; Iter   225/ 1097] train: loss: 0.0679738
[Epoch 16; Iter   255/ 1097] train: loss: 0.2260914
[Epoch 16; Iter   285/ 1097] train: loss: 0.0406806
[Epoch 16; Iter   315/ 1097] train: loss: 0.1114820
[Epoch 16; Iter   345/ 1097] train: loss: 0.0666251
[Epoch 16; Iter   375/ 1097] train: loss: 0.0668980
[Epoch 16; Iter   405/ 1097] train: loss: 0.0311085
[Epoch 16; Iter   435/ 1097] train: loss: 0.0913258
[Epoch 16; Iter   465/ 1097] train: loss: 0.2405598
[Epoch 16; Iter   495/ 1097] train: loss: 0.0534803
[Epoch 16; Iter   525/ 1097] train: loss: 0.0307857
[Epoch 16; Iter   555/ 1097] train: loss: 0.4069794
[Epoch 16; Iter   585/ 1097] train: loss: 0.0401047
[Epoch 16; Iter   615/ 1097] train: loss: 0.1416222
[Epoch 16; Iter   645/ 1097] train: loss: 0.0914861
[Epoch 16; Iter   675/ 1097] train: loss: 0.1354207
[Epoch 16; Iter   705/ 1097] train: loss: 0.0242305
[Epoch 16; Iter   735/ 1097] train: loss: 0.1506857
[Epoch 16; Iter   765/ 1097] train: loss: 0.3035582
[Epoch 16; Iter   795/ 1097] train: loss: 0.0292801
[Epoch 16; Iter   825/ 1097] train: loss: 0.1368215
[Epoch 16; Iter   855/ 1097] train: loss: 0.0237467
[Epoch 16; Iter   885/ 1097] train: loss: 0.1325944
[Epoch 16; Iter   915/ 1097] train: loss: 0.1488625
[Epoch 16; Iter   945/ 1097] train: loss: 0.0320116
[Epoch 16; Iter   975/ 1097] train: loss: 0.0243146
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1123547
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0578053
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0249383
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0311484
[Epoch 16] ogbg-molhiv: 0.744599 val loss: 0.158346
[Epoch 16] ogbg-molhiv: 0.746360 test loss: 0.227507
[Epoch 17; Iter    28/ 1097] train: loss: 0.1714269
[Epoch 17; Iter    58/ 1097] train: loss: 0.0870380
[Epoch 17; Iter    88/ 1097] train: loss: 0.1024279
[Epoch 17; Iter   118/ 1097] train: loss: 0.0563956
[Epoch 17; Iter   148/ 1097] train: loss: 0.0278585
[Epoch 17; Iter   178/ 1097] train: loss: 0.0233470
[Epoch 17; Iter   208/ 1097] train: loss: 0.0197560
[Epoch 17; Iter   238/ 1097] train: loss: 0.0510492
[Epoch 17; Iter   268/ 1097] train: loss: 0.1596854
[Epoch 17; Iter   298/ 1097] train: loss: 0.0264602
[Epoch 17; Iter   328/ 1097] train: loss: 0.0399321
[Epoch 17; Iter   358/ 1097] train: loss: 0.2128698
[Epoch 17; Iter   388/ 1097] train: loss: 0.0430393
[Epoch 17; Iter   418/ 1097] train: loss: 0.1341702
[Epoch 17; Iter   448/ 1097] train: loss: 0.1029241
[Epoch 17; Iter   478/ 1097] train: loss: 0.1726073
[Epoch 17; Iter   508/ 1097] train: loss: 0.0361447
[Epoch 17; Iter   538/ 1097] train: loss: 0.0593202
[Epoch 17; Iter   568/ 1097] train: loss: 0.0235868
[Epoch 17; Iter   598/ 1097] train: loss: 0.0672181
[Epoch 17; Iter   628/ 1097] train: loss: 0.0399489
[Epoch 17; Iter   658/ 1097] train: loss: 0.0885361
[Epoch 17; Iter   688/ 1097] train: loss: 0.0262965
[Epoch 17; Iter   718/ 1097] train: loss: 0.1534154
[Epoch 17; Iter   748/ 1097] train: loss: 0.1647721
[Epoch 17; Iter   778/ 1097] train: loss: 0.1011117
[Epoch 17; Iter   808/ 1097] train: loss: 0.1897643
[Epoch 17; Iter   838/ 1097] train: loss: 0.0591352
[Epoch 17; Iter   868/ 1097] train: loss: 0.0368419
[Epoch 17; Iter   898/ 1097] train: loss: 0.2245701
[Epoch 17; Iter   928/ 1097] train: loss: 0.2523403
[Epoch 17; Iter   958/ 1097] train: loss: 0.0330509
[Epoch 17; Iter   988/ 1097] train: loss: 0.1596766
[Epoch 17; Iter  1018/ 1097] train: loss: 0.1052133
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2818747
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2848435
[Epoch 17] ogbg-molhiv: 0.755211 val loss: 0.250242
[Epoch 17] ogbg-molhiv: 0.720819 test loss: 0.126205
[Epoch 18; Iter    11/ 1097] train: loss: 0.0325108
[Epoch 18; Iter    41/ 1097] train: loss: 0.1907248
[Epoch 18; Iter    71/ 1097] train: loss: 0.1706438
[Epoch 18; Iter   101/ 1097] train: loss: 0.0159396
[Epoch 18; Iter   131/ 1097] train: loss: 0.1309086
[Epoch 18; Iter   161/ 1097] train: loss: 0.1283201
[Epoch 18; Iter   191/ 1097] train: loss: 0.0229707
[Epoch 18; Iter   221/ 1097] train: loss: 0.1207191
[Epoch 18; Iter   251/ 1097] train: loss: 0.0326932
[Epoch 18; Iter   281/ 1097] train: loss: 0.1128538
[Epoch 18; Iter   311/ 1097] train: loss: 0.0575435
[Epoch 18; Iter   341/ 1097] train: loss: 0.0204122
[Epoch 18; Iter   371/ 1097] train: loss: 0.0310960
[Epoch 18; Iter   401/ 1097] train: loss: 0.2123389
[Epoch 18; Iter   431/ 1097] train: loss: 0.0604131
[Epoch 18; Iter   461/ 1097] train: loss: 0.1676389
[Epoch 18; Iter   491/ 1097] train: loss: 0.0268677
[Epoch 18; Iter   521/ 1097] train: loss: 0.1628599
[Epoch 18; Iter   551/ 1097] train: loss: 0.0728532
[Epoch 18; Iter   581/ 1097] train: loss: 0.0295917
[Epoch 18; Iter   611/ 1097] train: loss: 0.0344897
[Epoch 18; Iter   641/ 1097] train: loss: 0.1953311
[Epoch 18; Iter   671/ 1097] train: loss: 0.0555420
[Epoch 18; Iter   701/ 1097] train: loss: 0.0732568
[Epoch 18; Iter   731/ 1097] train: loss: 0.0318050
[Epoch 18; Iter   761/ 1097] train: loss: 0.0305396
[Epoch 18; Iter   791/ 1097] train: loss: 0.0326137
[Epoch 18; Iter   821/ 1097] train: loss: 0.1428919
[Epoch 18; Iter   851/ 1097] train: loss: 0.0311459
[Epoch 18; Iter   881/ 1097] train: loss: 0.0871198
[Epoch 18; Iter   911/ 1097] train: loss: 0.0216552
[Epoch 18; Iter   941/ 1097] train: loss: 0.1301898
[Epoch 18; Iter   971/ 1097] train: loss: 0.0266564
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0719670
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0892832
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0624427
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0124123
[Epoch 18] ogbg-molhiv: 0.717792 val loss: 0.103352
[Epoch 18] ogbg-molhiv: 0.743058 test loss: 0.156226
[Epoch 19; Iter    24/ 1097] train: loss: 0.0244653
[Epoch 19; Iter    54/ 1097] train: loss: 0.1485815
[Epoch 19; Iter    84/ 1097] train: loss: 0.0421153
[Epoch 19; Iter   114/ 1097] train: loss: 0.0241530
[Epoch 19; Iter   144/ 1097] train: loss: 0.0723033
[Epoch 19; Iter   174/ 1097] train: loss: 0.0594677
[Epoch 19; Iter   204/ 1097] train: loss: 0.0506810
[Epoch 19; Iter   234/ 1097] train: loss: 0.0971799
[Epoch 19; Iter   264/ 1097] train: loss: 0.0195659
[Epoch 19; Iter   294/ 1097] train: loss: 0.0356362
[Epoch 19; Iter   324/ 1097] train: loss: 0.0283293
[Epoch 19; Iter   354/ 1097] train: loss: 0.2679659
[Epoch 19; Iter   384/ 1097] train: loss: 0.0716910
[Epoch 19; Iter   414/ 1097] train: loss: 0.1725382
[Epoch 19; Iter   444/ 1097] train: loss: 0.0443268
[Epoch 19; Iter   474/ 1097] train: loss: 0.1917246
[Epoch 19; Iter   504/ 1097] train: loss: 0.0629076
[Epoch 19; Iter   534/ 1097] train: loss: 0.0260137
[Epoch 19; Iter   564/ 1097] train: loss: 0.1084174
[Epoch 19; Iter   594/ 1097] train: loss: 0.1267846
[Epoch 19; Iter   624/ 1097] train: loss: 0.0784513
[Epoch 19; Iter   654/ 1097] train: loss: 0.0265891
[Epoch 19; Iter   684/ 1097] train: loss: 0.3781940
[Epoch 19; Iter   714/ 1097] train: loss: 0.0378025
[Epoch 19; Iter   744/ 1097] train: loss: 0.0490528
[Epoch 19; Iter   774/ 1097] train: loss: 0.0989714
[Epoch 19; Iter   804/ 1097] train: loss: 0.0141676
[Epoch 19; Iter   834/ 1097] train: loss: 0.0431670
[Epoch 19; Iter   864/ 1097] train: loss: 0.0351534
[Epoch 19; Iter   894/ 1097] train: loss: 0.4647528
[Epoch 19; Iter   924/ 1097] train: loss: 0.1346842
[Epoch 19; Iter   954/ 1097] train: loss: 0.0388963
[Epoch 19; Iter   984/ 1097] train: loss: 0.0739136
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1686864
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0315096
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3735631
[Epoch 19] ogbg-molhiv: 0.708012 val loss: 0.095758
[Epoch 19] ogbg-molhiv: 0.747828 test loss: 0.392874
[Epoch 20; Iter     7/ 1097] train: loss: 0.0233748
[Epoch 20; Iter    37/ 1097] train: loss: 0.0359070
[Epoch 20; Iter    67/ 1097] train: loss: 0.0177246
[Epoch 20; Iter    97/ 1097] train: loss: 0.0296158
[Epoch 20; Iter   127/ 1097] train: loss: 0.0235035
[Epoch 20; Iter   157/ 1097] train: loss: 0.0212314
[Epoch 20; Iter   187/ 1097] train: loss: 0.0814768
[Epoch 20; Iter   217/ 1097] train: loss: 0.1668993
[Epoch 20; Iter   247/ 1097] train: loss: 0.0283920
[Epoch 16; Iter   195/ 1097] train: loss: 0.1286149
[Epoch 16; Iter   225/ 1097] train: loss: 0.0241911
[Epoch 16; Iter   255/ 1097] train: loss: 0.0906806
[Epoch 16; Iter   285/ 1097] train: loss: 0.1235568
[Epoch 16; Iter   315/ 1097] train: loss: 0.0700166
[Epoch 16; Iter   345/ 1097] train: loss: 0.0364565
[Epoch 16; Iter   375/ 1097] train: loss: 0.1328190
[Epoch 16; Iter   405/ 1097] train: loss: 0.2742203
[Epoch 16; Iter   435/ 1097] train: loss: 0.1369682
[Epoch 16; Iter   465/ 1097] train: loss: 0.0977082
[Epoch 16; Iter   495/ 1097] train: loss: 0.1157294
[Epoch 16; Iter   525/ 1097] train: loss: 0.0844571
[Epoch 16; Iter   555/ 1097] train: loss: 0.0468926
[Epoch 16; Iter   585/ 1097] train: loss: 0.1177404
[Epoch 16; Iter   615/ 1097] train: loss: 0.0829708
[Epoch 16; Iter   645/ 1097] train: loss: 0.0459183
[Epoch 16; Iter   675/ 1097] train: loss: 0.1004887
[Epoch 16; Iter   705/ 1097] train: loss: 0.1333860
[Epoch 16; Iter   735/ 1097] train: loss: 0.0939672
[Epoch 16; Iter   765/ 1097] train: loss: 0.0508164
[Epoch 16; Iter   795/ 1097] train: loss: 0.0975962
[Epoch 16; Iter   825/ 1097] train: loss: 0.0294384
[Epoch 16; Iter   855/ 1097] train: loss: 0.1486293
[Epoch 16; Iter   885/ 1097] train: loss: 0.2989047
[Epoch 16; Iter   915/ 1097] train: loss: 0.0272195
[Epoch 16; Iter   945/ 1097] train: loss: 0.0260026
[Epoch 16; Iter   975/ 1097] train: loss: 0.0234398
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0507078
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0234055
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0597103
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1176792
[Epoch 16] ogbg-molhiv: 0.773552 val loss: 0.127714
[Epoch 16] ogbg-molhiv: 0.761189 test loss: 0.135997
[Epoch 17; Iter    28/ 1097] train: loss: 0.0355334
[Epoch 17; Iter    58/ 1097] train: loss: 0.0271560
[Epoch 17; Iter    88/ 1097] train: loss: 0.0322554
[Epoch 17; Iter   118/ 1097] train: loss: 0.1372631
[Epoch 17; Iter   148/ 1097] train: loss: 0.1935211
[Epoch 17; Iter   178/ 1097] train: loss: 0.0375713
[Epoch 17; Iter   208/ 1097] train: loss: 0.0340226
[Epoch 17; Iter   238/ 1097] train: loss: 0.2624003
[Epoch 17; Iter   268/ 1097] train: loss: 0.0184799
[Epoch 17; Iter   298/ 1097] train: loss: 0.0238491
[Epoch 17; Iter   328/ 1097] train: loss: 0.0258762
[Epoch 17; Iter   358/ 1097] train: loss: 0.0305292
[Epoch 17; Iter   388/ 1097] train: loss: 0.0330392
[Epoch 17; Iter   418/ 1097] train: loss: 0.1061352
[Epoch 17; Iter   448/ 1097] train: loss: 0.0238489
[Epoch 17; Iter   478/ 1097] train: loss: 0.0613138
[Epoch 17; Iter   508/ 1097] train: loss: 0.0482661
[Epoch 17; Iter   538/ 1097] train: loss: 0.3651131
[Epoch 17; Iter   568/ 1097] train: loss: 0.1832045
[Epoch 17; Iter   598/ 1097] train: loss: 0.1024641
[Epoch 17; Iter   628/ 1097] train: loss: 0.0276367
[Epoch 17; Iter   658/ 1097] train: loss: 0.0351568
[Epoch 17; Iter   688/ 1097] train: loss: 0.2232064
[Epoch 17; Iter   718/ 1097] train: loss: 0.0568855
[Epoch 17; Iter   748/ 1097] train: loss: 0.1072905
[Epoch 17; Iter   778/ 1097] train: loss: 0.0448783
[Epoch 17; Iter   808/ 1097] train: loss: 0.0967609
[Epoch 17; Iter   838/ 1097] train: loss: 0.0508186
[Epoch 17; Iter   868/ 1097] train: loss: 0.0218794
[Epoch 17; Iter   898/ 1097] train: loss: 0.0664926
[Epoch 17; Iter   928/ 1097] train: loss: 0.2736064
[Epoch 17; Iter   958/ 1097] train: loss: 0.1727904
[Epoch 17; Iter   988/ 1097] train: loss: 0.0409336
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0371991
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0444279
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1594032
[Epoch 17] ogbg-molhiv: 0.738046 val loss: 0.427598
[Epoch 17] ogbg-molhiv: 0.783690 test loss: 0.585760
[Epoch 18; Iter    11/ 1097] train: loss: 0.1021956
[Epoch 18; Iter    41/ 1097] train: loss: 0.2499711
[Epoch 18; Iter    71/ 1097] train: loss: 0.0749679
[Epoch 18; Iter   101/ 1097] train: loss: 0.0716928
[Epoch 18; Iter   131/ 1097] train: loss: 0.1648108
[Epoch 18; Iter   161/ 1097] train: loss: 0.0388738
[Epoch 18; Iter   191/ 1097] train: loss: 0.1754796
[Epoch 18; Iter   221/ 1097] train: loss: 0.1483734
[Epoch 18; Iter   251/ 1097] train: loss: 0.0929173
[Epoch 18; Iter   281/ 1097] train: loss: 0.0298043
[Epoch 18; Iter   311/ 1097] train: loss: 0.1683062
[Epoch 18; Iter   341/ 1097] train: loss: 0.0237900
[Epoch 18; Iter   371/ 1097] train: loss: 0.0328411
[Epoch 18; Iter   401/ 1097] train: loss: 0.2430785
[Epoch 18; Iter   431/ 1097] train: loss: 0.1871028
[Epoch 18; Iter   461/ 1097] train: loss: 0.0839646
[Epoch 18; Iter   491/ 1097] train: loss: 0.1688000
[Epoch 18; Iter   521/ 1097] train: loss: 0.3080255
[Epoch 18; Iter   551/ 1097] train: loss: 0.0366853
[Epoch 18; Iter   581/ 1097] train: loss: 0.0390469
[Epoch 18; Iter   611/ 1097] train: loss: 0.0188440
[Epoch 18; Iter   641/ 1097] train: loss: 0.1719053
[Epoch 18; Iter   671/ 1097] train: loss: 0.1271799
[Epoch 18; Iter   701/ 1097] train: loss: 0.1988070
[Epoch 18; Iter   731/ 1097] train: loss: 0.0836003
[Epoch 18; Iter   761/ 1097] train: loss: 0.3184605
[Epoch 18; Iter   791/ 1097] train: loss: 0.0612825
[Epoch 18; Iter   821/ 1097] train: loss: 0.0604926
[Epoch 18; Iter   851/ 1097] train: loss: 0.1486005
[Epoch 18; Iter   881/ 1097] train: loss: 0.0592971
[Epoch 18; Iter   911/ 1097] train: loss: 0.1774404
[Epoch 18; Iter   941/ 1097] train: loss: 0.0295628
[Epoch 18; Iter   971/ 1097] train: loss: 0.0548286
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0246733
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0826544
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0362762
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1090118
[Epoch 18] ogbg-molhiv: 0.766645 val loss: 0.479766
[Epoch 18] ogbg-molhiv: 0.739474 test loss: 0.786892
[Epoch 19; Iter    24/ 1097] train: loss: 0.2581296
[Epoch 19; Iter    54/ 1097] train: loss: 0.1419119
[Epoch 19; Iter    84/ 1097] train: loss: 0.2516275
[Epoch 19; Iter   114/ 1097] train: loss: 0.0260887
[Epoch 19; Iter   144/ 1097] train: loss: 0.0798273
[Epoch 19; Iter   174/ 1097] train: loss: 0.0908667
[Epoch 19; Iter   204/ 1097] train: loss: 0.0188125
[Epoch 19; Iter   234/ 1097] train: loss: 0.0483485
[Epoch 19; Iter   264/ 1097] train: loss: 0.0447180
[Epoch 19; Iter   294/ 1097] train: loss: 0.0621937
[Epoch 19; Iter   324/ 1097] train: loss: 0.0385960
[Epoch 19; Iter   354/ 1097] train: loss: 0.1802943
[Epoch 19; Iter   384/ 1097] train: loss: 0.0242401
[Epoch 19; Iter   414/ 1097] train: loss: 0.0352891
[Epoch 19; Iter   444/ 1097] train: loss: 0.1482277
[Epoch 19; Iter   474/ 1097] train: loss: 0.0437327
[Epoch 19; Iter   504/ 1097] train: loss: 0.1781785
[Epoch 19; Iter   534/ 1097] train: loss: 0.1363657
[Epoch 19; Iter   564/ 1097] train: loss: 0.0156890
[Epoch 19; Iter   594/ 1097] train: loss: 0.0257544
[Epoch 19; Iter   624/ 1097] train: loss: 0.0326729
[Epoch 19; Iter   654/ 1097] train: loss: 0.0534698
[Epoch 19; Iter   684/ 1097] train: loss: 0.0362145
[Epoch 19; Iter   714/ 1097] train: loss: 0.1388639
[Epoch 19; Iter   744/ 1097] train: loss: 0.0552860
[Epoch 19; Iter   774/ 1097] train: loss: 0.1152717
[Epoch 19; Iter   804/ 1097] train: loss: 0.1461459
[Epoch 19; Iter   834/ 1097] train: loss: 0.2476317
[Epoch 19; Iter   864/ 1097] train: loss: 0.3106514
[Epoch 19; Iter   894/ 1097] train: loss: 0.1427289
[Epoch 19; Iter   924/ 1097] train: loss: 0.5558621
[Epoch 19; Iter   954/ 1097] train: loss: 0.0587511
[Epoch 19; Iter   984/ 1097] train: loss: 0.3328076
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1454977
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0274135
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0394967
[Epoch 19] ogbg-molhiv: 0.739179 val loss: 1.040406
[Epoch 19] ogbg-molhiv: 0.750600 test loss: 0.491838
[Epoch 20; Iter     7/ 1097] train: loss: 0.0672046
[Epoch 20; Iter    37/ 1097] train: loss: 0.2206217
[Epoch 20; Iter    67/ 1097] train: loss: 0.0740004
[Epoch 20; Iter    97/ 1097] train: loss: 0.0234495
[Epoch 20; Iter   127/ 1097] train: loss: 0.0420781
[Epoch 20; Iter   157/ 1097] train: loss: 0.0546777
[Epoch 20; Iter   187/ 1097] train: loss: 0.0241353
[Epoch 20; Iter   217/ 1097] train: loss: 0.0387869
[Epoch 20; Iter   247/ 1097] train: loss: 0.0414078
[Epoch 16; Iter   195/ 1097] train: loss: 0.0375034
[Epoch 16; Iter   225/ 1097] train: loss: 0.0851508
[Epoch 16; Iter   255/ 1097] train: loss: 0.1864063
[Epoch 16; Iter   285/ 1097] train: loss: 0.0233065
[Epoch 16; Iter   315/ 1097] train: loss: 0.1307039
[Epoch 16; Iter   345/ 1097] train: loss: 0.1511083
[Epoch 16; Iter   375/ 1097] train: loss: 0.0374456
[Epoch 16; Iter   405/ 1097] train: loss: 0.0231782
[Epoch 16; Iter   435/ 1097] train: loss: 0.0660259
[Epoch 16; Iter   465/ 1097] train: loss: 0.0935898
[Epoch 16; Iter   495/ 1097] train: loss: 0.0554014
[Epoch 16; Iter   525/ 1097] train: loss: 0.0247231
[Epoch 16; Iter   555/ 1097] train: loss: 0.3919684
[Epoch 16; Iter   585/ 1097] train: loss: 0.0624167
[Epoch 16; Iter   615/ 1097] train: loss: 0.1356102
[Epoch 16; Iter   645/ 1097] train: loss: 0.0722962
[Epoch 16; Iter   675/ 1097] train: loss: 0.1592153
[Epoch 16; Iter   705/ 1097] train: loss: 0.0453500
[Epoch 16; Iter   735/ 1097] train: loss: 0.1787514
[Epoch 16; Iter   765/ 1097] train: loss: 0.3045436
[Epoch 16; Iter   795/ 1097] train: loss: 0.0998068
[Epoch 16; Iter   825/ 1097] train: loss: 0.1227492
[Epoch 16; Iter   855/ 1097] train: loss: 0.0284749
[Epoch 16; Iter   885/ 1097] train: loss: 0.1895730
[Epoch 16; Iter   915/ 1097] train: loss: 0.1196812
[Epoch 16; Iter   945/ 1097] train: loss: 0.0241345
[Epoch 16; Iter   975/ 1097] train: loss: 0.0228872
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1512435
[Epoch 16; Iter  1035/ 1097] train: loss: 0.1008163
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0392680
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0502119
[Epoch 16] ogbg-molhiv: 0.728870 val loss: 0.673358
[Epoch 16] ogbg-molhiv: 0.676967 test loss: 0.267643
[Epoch 17; Iter    28/ 1097] train: loss: 0.1189611
[Epoch 17; Iter    58/ 1097] train: loss: 0.0364169
[Epoch 17; Iter    88/ 1097] train: loss: 0.0346814
[Epoch 17; Iter   118/ 1097] train: loss: 0.0572790
[Epoch 17; Iter   148/ 1097] train: loss: 0.0229053
[Epoch 17; Iter   178/ 1097] train: loss: 0.0218127
[Epoch 17; Iter   208/ 1097] train: loss: 0.0274602
[Epoch 17; Iter   238/ 1097] train: loss: 0.0614840
[Epoch 17; Iter   268/ 1097] train: loss: 0.1543219
[Epoch 17; Iter   298/ 1097] train: loss: 0.0172973
[Epoch 17; Iter   328/ 1097] train: loss: 0.0448152
[Epoch 17; Iter   358/ 1097] train: loss: 0.2913904
[Epoch 17; Iter   388/ 1097] train: loss: 0.0240428
[Epoch 17; Iter   418/ 1097] train: loss: 0.0817210
[Epoch 17; Iter   448/ 1097] train: loss: 0.1439051
[Epoch 17; Iter   478/ 1097] train: loss: 0.2222356
[Epoch 17; Iter   508/ 1097] train: loss: 0.0577529
[Epoch 17; Iter   538/ 1097] train: loss: 0.1624291
[Epoch 17; Iter   568/ 1097] train: loss: 0.0225773
[Epoch 17; Iter   598/ 1097] train: loss: 0.1394427
[Epoch 17; Iter   628/ 1097] train: loss: 0.0538175
[Epoch 17; Iter   658/ 1097] train: loss: 0.0755716
[Epoch 17; Iter   688/ 1097] train: loss: 0.0411578
[Epoch 17; Iter   718/ 1097] train: loss: 0.0475456
[Epoch 17; Iter   748/ 1097] train: loss: 0.2549519
[Epoch 17; Iter   778/ 1097] train: loss: 0.0782279
[Epoch 17; Iter   808/ 1097] train: loss: 0.1155108
[Epoch 17; Iter   838/ 1097] train: loss: 0.0873927
[Epoch 17; Iter   868/ 1097] train: loss: 0.0191892
[Epoch 17; Iter   898/ 1097] train: loss: 0.1427539
[Epoch 17; Iter   928/ 1097] train: loss: 0.1763971
[Epoch 17; Iter   958/ 1097] train: loss: 0.0199066
[Epoch 17; Iter   988/ 1097] train: loss: 0.1497745
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0651237
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2151372
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1961898
[Epoch 17] ogbg-molhiv: 0.774119 val loss: 0.309646
[Epoch 17] ogbg-molhiv: 0.670343 test loss: 0.143864
[Epoch 18; Iter    11/ 1097] train: loss: 0.0381187
[Epoch 18; Iter    41/ 1097] train: loss: 0.2271218
[Epoch 18; Iter    71/ 1097] train: loss: 0.1549912
[Epoch 18; Iter   101/ 1097] train: loss: 0.0799436
[Epoch 18; Iter   131/ 1097] train: loss: 0.1042217
[Epoch 18; Iter   161/ 1097] train: loss: 0.0423780
[Epoch 18; Iter   191/ 1097] train: loss: 0.0155422
[Epoch 18; Iter   221/ 1097] train: loss: 0.0730769
[Epoch 18; Iter   251/ 1097] train: loss: 0.0286257
[Epoch 18; Iter   281/ 1097] train: loss: 0.1032887
[Epoch 18; Iter   311/ 1097] train: loss: 0.0521986
[Epoch 18; Iter   341/ 1097] train: loss: 0.0191853
[Epoch 18; Iter   371/ 1097] train: loss: 0.0393180
[Epoch 18; Iter   401/ 1097] train: loss: 0.0672564
[Epoch 18; Iter   431/ 1097] train: loss: 0.0483982
[Epoch 18; Iter   461/ 1097] train: loss: 0.1332890
[Epoch 18; Iter   491/ 1097] train: loss: 0.0267595
[Epoch 18; Iter   521/ 1097] train: loss: 0.0820606
[Epoch 18; Iter   551/ 1097] train: loss: 0.0460186
[Epoch 18; Iter   581/ 1097] train: loss: 0.0264891
[Epoch 18; Iter   611/ 1097] train: loss: 0.0274075
[Epoch 18; Iter   641/ 1097] train: loss: 0.0473162
[Epoch 18; Iter   671/ 1097] train: loss: 0.0556807
[Epoch 18; Iter   701/ 1097] train: loss: 0.0237362
[Epoch 18; Iter   731/ 1097] train: loss: 0.1072405
[Epoch 18; Iter   761/ 1097] train: loss: 0.0295370
[Epoch 18; Iter   791/ 1097] train: loss: 0.0489749
[Epoch 18; Iter   821/ 1097] train: loss: 0.1754636
[Epoch 18; Iter   851/ 1097] train: loss: 0.0324966
[Epoch 18; Iter   881/ 1097] train: loss: 0.0288988
[Epoch 18; Iter   911/ 1097] train: loss: 0.0244272
[Epoch 18; Iter   941/ 1097] train: loss: 0.1301097
[Epoch 18; Iter   971/ 1097] train: loss: 0.0207647
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1805850
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0725345
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0156074
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0121243
[Epoch 18] ogbg-molhiv: 0.742976 val loss: 0.096322
[Epoch 18] ogbg-molhiv: 0.533363 test loss: 0.235763
[Epoch 19; Iter    24/ 1097] train: loss: 0.0174477
[Epoch 19; Iter    54/ 1097] train: loss: 0.0536709
[Epoch 19; Iter    84/ 1097] train: loss: 0.0488565
[Epoch 19; Iter   114/ 1097] train: loss: 0.0196740
[Epoch 19; Iter   144/ 1097] train: loss: 0.0477306
[Epoch 19; Iter   174/ 1097] train: loss: 0.0115198
[Epoch 19; Iter   204/ 1097] train: loss: 0.0565788
[Epoch 19; Iter   234/ 1097] train: loss: 0.0236770
[Epoch 19; Iter   264/ 1097] train: loss: 0.0191220
[Epoch 19; Iter   294/ 1097] train: loss: 0.0470594
[Epoch 19; Iter   324/ 1097] train: loss: 0.0317276
[Epoch 19; Iter   354/ 1097] train: loss: 0.1717095
[Epoch 19; Iter   384/ 1097] train: loss: 0.0287001
[Epoch 19; Iter   414/ 1097] train: loss: 0.0224411
[Epoch 19; Iter   444/ 1097] train: loss: 0.0238309
[Epoch 19; Iter   474/ 1097] train: loss: 0.1649384
[Epoch 19; Iter   504/ 1097] train: loss: 0.0268742
[Epoch 19; Iter   534/ 1097] train: loss: 0.0609998
[Epoch 19; Iter   564/ 1097] train: loss: 0.1014601
[Epoch 19; Iter   594/ 1097] train: loss: 0.0670669
[Epoch 19; Iter   624/ 1097] train: loss: 0.0453854
[Epoch 19; Iter   654/ 1097] train: loss: 0.0388564
[Epoch 19; Iter   684/ 1097] train: loss: 0.2680767
[Epoch 19; Iter   714/ 1097] train: loss: 0.0118495
[Epoch 19; Iter   744/ 1097] train: loss: 0.0493599
[Epoch 19; Iter   774/ 1097] train: loss: 0.2237931
[Epoch 19; Iter   804/ 1097] train: loss: 0.0151930
[Epoch 19; Iter   834/ 1097] train: loss: 0.0413537
[Epoch 19; Iter   864/ 1097] train: loss: 0.0296385
[Epoch 19; Iter   894/ 1097] train: loss: 0.2904666
[Epoch 19; Iter   924/ 1097] train: loss: 0.0746061
[Epoch 19; Iter   954/ 1097] train: loss: 0.0227322
[Epoch 19; Iter   984/ 1097] train: loss: 0.1425942
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1319218
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1660336
[Epoch 19; Iter  1074/ 1097] train: loss: 0.2424949
[Epoch 19] ogbg-molhiv: 0.725563 val loss: 0.102443
[Epoch 19] ogbg-molhiv: 0.609301 test loss: 0.264684
[Epoch 20; Iter     7/ 1097] train: loss: 0.0147641
[Epoch 20; Iter    37/ 1097] train: loss: 0.0766545
[Epoch 20; Iter    67/ 1097] train: loss: 0.0190847
[Epoch 20; Iter    97/ 1097] train: loss: 0.0239379
[Epoch 20; Iter   127/ 1097] train: loss: 0.0392788
[Epoch 20; Iter   157/ 1097] train: loss: 0.0199417
[Epoch 20; Iter   187/ 1097] train: loss: 0.0933201
[Epoch 20; Iter   217/ 1097] train: loss: 0.1616689
[Epoch 20; Iter   247/ 1097] train: loss: 0.0230487
[Epoch 16; Iter   195/ 1097] train: loss: 0.0463369
[Epoch 16; Iter   225/ 1097] train: loss: 0.0625193
[Epoch 16; Iter   255/ 1097] train: loss: 0.0933698
[Epoch 16; Iter   285/ 1097] train: loss: 0.1535255
[Epoch 16; Iter   315/ 1097] train: loss: 0.0234534
[Epoch 16; Iter   345/ 1097] train: loss: 0.0306147
[Epoch 16; Iter   375/ 1097] train: loss: 0.1609144
[Epoch 16; Iter   405/ 1097] train: loss: 0.1860694
[Epoch 16; Iter   435/ 1097] train: loss: 0.1209783
[Epoch 16; Iter   465/ 1097] train: loss: 0.1688572
[Epoch 16; Iter   495/ 1097] train: loss: 0.1471074
[Epoch 16; Iter   525/ 1097] train: loss: 0.1332524
[Epoch 16; Iter   555/ 1097] train: loss: 0.0226254
[Epoch 16; Iter   585/ 1097] train: loss: 0.1180489
[Epoch 16; Iter   615/ 1097] train: loss: 0.0585273
[Epoch 16; Iter   645/ 1097] train: loss: 0.0287219
[Epoch 16; Iter   675/ 1097] train: loss: 0.0824281
[Epoch 16; Iter   705/ 1097] train: loss: 0.1054277
[Epoch 16; Iter   735/ 1097] train: loss: 0.0699884
[Epoch 16; Iter   765/ 1097] train: loss: 0.0539023
[Epoch 16; Iter   795/ 1097] train: loss: 0.0507590
[Epoch 16; Iter   825/ 1097] train: loss: 0.0263352
[Epoch 16; Iter   855/ 1097] train: loss: 0.0919597
[Epoch 16; Iter   885/ 1097] train: loss: 0.2814760
[Epoch 16; Iter   915/ 1097] train: loss: 0.0260838
[Epoch 16; Iter   945/ 1097] train: loss: 0.0196881
[Epoch 16; Iter   975/ 1097] train: loss: 0.0330888
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0533780
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0293174
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0310860
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0983225
[Epoch 16] ogbg-molhiv: 0.758870 val loss: 0.097062
[Epoch 16] ogbg-molhiv: 0.665013 test loss: 0.149204
[Epoch 17; Iter    28/ 1097] train: loss: 0.0183101
[Epoch 17; Iter    58/ 1097] train: loss: 0.0248406
[Epoch 17; Iter    88/ 1097] train: loss: 0.0568354
[Epoch 17; Iter   118/ 1097] train: loss: 0.1023346
[Epoch 17; Iter   148/ 1097] train: loss: 0.1719582
[Epoch 17; Iter   178/ 1097] train: loss: 0.0297763
[Epoch 17; Iter   208/ 1097] train: loss: 0.0224245
[Epoch 17; Iter   238/ 1097] train: loss: 0.2474755
[Epoch 17; Iter   268/ 1097] train: loss: 0.0166337
[Epoch 17; Iter   298/ 1097] train: loss: 0.0659921
[Epoch 17; Iter   328/ 1097] train: loss: 0.0269267
[Epoch 17; Iter   358/ 1097] train: loss: 0.0425030
[Epoch 17; Iter   388/ 1097] train: loss: 0.0444926
[Epoch 17; Iter   418/ 1097] train: loss: 0.2605773
[Epoch 17; Iter   448/ 1097] train: loss: 0.0232783
[Epoch 17; Iter   478/ 1097] train: loss: 0.0260845
[Epoch 17; Iter   508/ 1097] train: loss: 0.0455820
[Epoch 17; Iter   538/ 1097] train: loss: 0.1792871
[Epoch 17; Iter   568/ 1097] train: loss: 0.2198478
[Epoch 17; Iter   598/ 1097] train: loss: 0.1284648
[Epoch 17; Iter   628/ 1097] train: loss: 0.0975051
[Epoch 17; Iter   658/ 1097] train: loss: 0.0287964
[Epoch 17; Iter   688/ 1097] train: loss: 0.2229968
[Epoch 17; Iter   718/ 1097] train: loss: 0.0431424
[Epoch 17; Iter   748/ 1097] train: loss: 0.1176073
[Epoch 17; Iter   778/ 1097] train: loss: 0.0393111
[Epoch 17; Iter   808/ 1097] train: loss: 0.1377529
[Epoch 17; Iter   838/ 1097] train: loss: 0.1128280
[Epoch 17; Iter   868/ 1097] train: loss: 0.0264571
[Epoch 17; Iter   898/ 1097] train: loss: 0.1417463
[Epoch 17; Iter   928/ 1097] train: loss: 0.2416926
[Epoch 17; Iter   958/ 1097] train: loss: 0.1910189
[Epoch 17; Iter   988/ 1097] train: loss: 0.0165247
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0519290
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0286030
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1499024
[Epoch 17] ogbg-molhiv: 0.773500 val loss: 0.144753
[Epoch 17] ogbg-molhiv: 0.727397 test loss: 0.177403
[Epoch 18; Iter    11/ 1097] train: loss: 0.1384208
[Epoch 18; Iter    41/ 1097] train: loss: 0.2720132
[Epoch 18; Iter    71/ 1097] train: loss: 0.0662043
[Epoch 18; Iter   101/ 1097] train: loss: 0.0818949
[Epoch 18; Iter   131/ 1097] train: loss: 0.0499722
[Epoch 18; Iter   161/ 1097] train: loss: 0.0353912
[Epoch 18; Iter   191/ 1097] train: loss: 0.0635391
[Epoch 18; Iter   221/ 1097] train: loss: 0.1610649
[Epoch 18; Iter   251/ 1097] train: loss: 0.0813380
[Epoch 18; Iter   281/ 1097] train: loss: 0.0206053
[Epoch 18; Iter   311/ 1097] train: loss: 0.0748193
[Epoch 18; Iter   341/ 1097] train: loss: 0.0626596
[Epoch 18; Iter   371/ 1097] train: loss: 0.0721448
[Epoch 18; Iter   401/ 1097] train: loss: 0.2086032
[Epoch 18; Iter   431/ 1097] train: loss: 0.3060096
[Epoch 18; Iter   461/ 1097] train: loss: 0.0418810
[Epoch 18; Iter   491/ 1097] train: loss: 0.0697242
[Epoch 18; Iter   521/ 1097] train: loss: 0.1092919
[Epoch 18; Iter   551/ 1097] train: loss: 0.0312680
[Epoch 18; Iter   581/ 1097] train: loss: 0.0616981
[Epoch 18; Iter   611/ 1097] train: loss: 0.0269517
[Epoch 18; Iter   641/ 1097] train: loss: 0.1722797
[Epoch 18; Iter   671/ 1097] train: loss: 0.1809730
[Epoch 18; Iter   701/ 1097] train: loss: 0.2076194
[Epoch 18; Iter   731/ 1097] train: loss: 0.1176975
[Epoch 18; Iter   761/ 1097] train: loss: 0.2132162
[Epoch 18; Iter   791/ 1097] train: loss: 0.0166828
[Epoch 18; Iter   821/ 1097] train: loss: 0.0797581
[Epoch 18; Iter   851/ 1097] train: loss: 0.1051346
[Epoch 18; Iter   881/ 1097] train: loss: 0.0930073
[Epoch 18; Iter   911/ 1097] train: loss: 0.0785540
[Epoch 18; Iter   941/ 1097] train: loss: 0.0238318
[Epoch 18; Iter   971/ 1097] train: loss: 0.0952312
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0250386
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0269078
[Epoch 18; Iter  1061/ 1097] train: loss: 0.1323246
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1311911
[Epoch 18] ogbg-molhiv: 0.758365 val loss: 0.099464
[Epoch 18] ogbg-molhiv: 0.660795 test loss: 0.165607
[Epoch 19; Iter    24/ 1097] train: loss: 0.2567469
[Epoch 19; Iter    54/ 1097] train: loss: 0.1111066
[Epoch 19; Iter    84/ 1097] train: loss: 0.1912265
[Epoch 19; Iter   114/ 1097] train: loss: 0.0282433
[Epoch 19; Iter   144/ 1097] train: loss: 0.1306815
[Epoch 19; Iter   174/ 1097] train: loss: 0.0585686
[Epoch 19; Iter   204/ 1097] train: loss: 0.0868375
[Epoch 19; Iter   234/ 1097] train: loss: 0.0231727
[Epoch 19; Iter   264/ 1097] train: loss: 0.0888195
[Epoch 19; Iter   294/ 1097] train: loss: 0.0524552
[Epoch 19; Iter   324/ 1097] train: loss: 0.0521973
[Epoch 19; Iter   354/ 1097] train: loss: 0.1278060
[Epoch 19; Iter   384/ 1097] train: loss: 0.0231903
[Epoch 19; Iter   414/ 1097] train: loss: 0.0147715
[Epoch 19; Iter   444/ 1097] train: loss: 0.3507547
[Epoch 19; Iter   474/ 1097] train: loss: 0.1914902
[Epoch 19; Iter   504/ 1097] train: loss: 0.1187539
[Epoch 19; Iter   534/ 1097] train: loss: 0.1328149
[Epoch 19; Iter   564/ 1097] train: loss: 0.0410909
[Epoch 19; Iter   594/ 1097] train: loss: 0.0300209
[Epoch 19; Iter   624/ 1097] train: loss: 0.0551132
[Epoch 19; Iter   654/ 1097] train: loss: 0.1019056
[Epoch 19; Iter   684/ 1097] train: loss: 0.0764924
[Epoch 19; Iter   714/ 1097] train: loss: 0.1004256
[Epoch 19; Iter   744/ 1097] train: loss: 0.0817837
[Epoch 19; Iter   774/ 1097] train: loss: 0.1379566
[Epoch 19; Iter   804/ 1097] train: loss: 0.0507388
[Epoch 19; Iter   834/ 1097] train: loss: 0.1474578
[Epoch 19; Iter   864/ 1097] train: loss: 0.2452882
[Epoch 19; Iter   894/ 1097] train: loss: 0.0967797
[Epoch 19; Iter   924/ 1097] train: loss: 0.2869693
[Epoch 19; Iter   954/ 1097] train: loss: 0.1699100
[Epoch 19; Iter   984/ 1097] train: loss: 0.1679255
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0440526
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0998871
[Epoch 19; Iter  1074/ 1097] train: loss: 0.1595499
[Epoch 19] ogbg-molhiv: 0.788770 val loss: 0.090970
[Epoch 19] ogbg-molhiv: 0.681195 test loss: 0.152957
[Epoch 20; Iter     7/ 1097] train: loss: 0.0448612
[Epoch 20; Iter    37/ 1097] train: loss: 0.1494042
[Epoch 20; Iter    67/ 1097] train: loss: 0.0167510
[Epoch 20; Iter    97/ 1097] train: loss: 0.0180847
[Epoch 20; Iter   127/ 1097] train: loss: 0.0250043
[Epoch 20; Iter   157/ 1097] train: loss: 0.1186521
[Epoch 20; Iter   187/ 1097] train: loss: 0.0181742
[Epoch 20; Iter   217/ 1097] train: loss: 0.0229712
[Epoch 20; Iter   247/ 1097] train: loss: 0.0178643
[Epoch 16; Iter   195/ 1097] train: loss: 0.0454059
[Epoch 16; Iter   225/ 1097] train: loss: 0.0386491
[Epoch 16; Iter   255/ 1097] train: loss: 0.0241137
[Epoch 16; Iter   285/ 1097] train: loss: 0.2506876
[Epoch 16; Iter   315/ 1097] train: loss: 0.0398978
[Epoch 16; Iter   345/ 1097] train: loss: 0.0607298
[Epoch 16; Iter   375/ 1097] train: loss: 0.1277761
[Epoch 16; Iter   405/ 1097] train: loss: 0.0169203
[Epoch 16; Iter   435/ 1097] train: loss: 0.2484235
[Epoch 16; Iter   465/ 1097] train: loss: 0.0268882
[Epoch 16; Iter   495/ 1097] train: loss: 0.0294226
[Epoch 16; Iter   525/ 1097] train: loss: 0.1805042
[Epoch 16; Iter   555/ 1097] train: loss: 0.0410281
[Epoch 16; Iter   585/ 1097] train: loss: 0.3376302
[Epoch 16; Iter   615/ 1097] train: loss: 0.0918156
[Epoch 16; Iter   645/ 1097] train: loss: 0.0645248
[Epoch 16; Iter   675/ 1097] train: loss: 0.0470480
[Epoch 16; Iter   705/ 1097] train: loss: 0.0353316
[Epoch 16; Iter   735/ 1097] train: loss: 0.2886291
[Epoch 16; Iter   765/ 1097] train: loss: 0.0264176
[Epoch 16; Iter   795/ 1097] train: loss: 0.0324879
[Epoch 16; Iter   825/ 1097] train: loss: 0.1023302
[Epoch 16; Iter   855/ 1097] train: loss: 0.1826651
[Epoch 16; Iter   885/ 1097] train: loss: 0.0230157
[Epoch 16; Iter   915/ 1097] train: loss: 0.0296154
[Epoch 16; Iter   945/ 1097] train: loss: 0.1065522
[Epoch 16; Iter   975/ 1097] train: loss: 0.2152422
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2129761
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0271007
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1429419
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1355229
[Epoch 16] ogbg-molhiv: 0.777312 val loss: 0.334360
[Epoch 16] ogbg-molhiv: 0.703451 test loss: 0.285003
[Epoch 17; Iter    28/ 1097] train: loss: 0.1543417
[Epoch 17; Iter    58/ 1097] train: loss: 0.0378974
[Epoch 17; Iter    88/ 1097] train: loss: 0.0970686
[Epoch 17; Iter   118/ 1097] train: loss: 0.2306900
[Epoch 17; Iter   148/ 1097] train: loss: 0.0446868
[Epoch 17; Iter   178/ 1097] train: loss: 0.0966736
[Epoch 17; Iter   208/ 1097] train: loss: 0.0326278
[Epoch 17; Iter   238/ 1097] train: loss: 0.0989633
[Epoch 17; Iter   268/ 1097] train: loss: 0.0371139
[Epoch 17; Iter   298/ 1097] train: loss: 0.2486378
[Epoch 17; Iter   328/ 1097] train: loss: 0.2317724
[Epoch 17; Iter   358/ 1097] train: loss: 0.0548531
[Epoch 17; Iter   388/ 1097] train: loss: 0.1367170
[Epoch 17; Iter   418/ 1097] train: loss: 0.2153207
[Epoch 17; Iter   448/ 1097] train: loss: 0.0300925
[Epoch 17; Iter   478/ 1097] train: loss: 0.0988020
[Epoch 17; Iter   508/ 1097] train: loss: 0.2005128
[Epoch 17; Iter   538/ 1097] train: loss: 0.0237869
[Epoch 17; Iter   568/ 1097] train: loss: 0.2405195
[Epoch 17; Iter   598/ 1097] train: loss: 0.0589343
[Epoch 17; Iter   628/ 1097] train: loss: 0.0884073
[Epoch 17; Iter   658/ 1097] train: loss: 0.0925593
[Epoch 17; Iter   688/ 1097] train: loss: 0.0407565
[Epoch 17; Iter   718/ 1097] train: loss: 0.1131832
[Epoch 17; Iter   748/ 1097] train: loss: 0.0203301
[Epoch 17; Iter   778/ 1097] train: loss: 0.2695547
[Epoch 17; Iter   808/ 1097] train: loss: 0.0217891
[Epoch 17; Iter   838/ 1097] train: loss: 0.0126494
[Epoch 17; Iter   868/ 1097] train: loss: 0.0281938
[Epoch 17; Iter   898/ 1097] train: loss: 0.0512469
[Epoch 17; Iter   928/ 1097] train: loss: 0.2859973
[Epoch 17; Iter   958/ 1097] train: loss: 0.0583620
[Epoch 17; Iter   988/ 1097] train: loss: 0.0286756
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0393223
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0397764
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0425742
[Epoch 17] ogbg-molhiv: 0.722372 val loss: 0.309337
[Epoch 17] ogbg-molhiv: 0.659860 test loss: 0.332923
[Epoch 18; Iter    11/ 1097] train: loss: 0.1583024
[Epoch 18; Iter    41/ 1097] train: loss: 0.0273269
[Epoch 18; Iter    71/ 1097] train: loss: 0.0616313
[Epoch 18; Iter   101/ 1097] train: loss: 0.0379104
[Epoch 18; Iter   131/ 1097] train: loss: 0.1819662
[Epoch 18; Iter   161/ 1097] train: loss: 0.2026893
[Epoch 18; Iter   191/ 1097] train: loss: 0.0831843
[Epoch 18; Iter   221/ 1097] train: loss: 0.0206311
[Epoch 18; Iter   251/ 1097] train: loss: 0.0280792
[Epoch 18; Iter   281/ 1097] train: loss: 0.0193496
[Epoch 18; Iter   311/ 1097] train: loss: 0.2283487
[Epoch 18; Iter   341/ 1097] train: loss: 0.1595934
[Epoch 18; Iter   371/ 1097] train: loss: 0.0223583
[Epoch 18; Iter   401/ 1097] train: loss: 0.0724511
[Epoch 18; Iter   431/ 1097] train: loss: 0.0176477
[Epoch 18; Iter   461/ 1097] train: loss: 0.0535851
[Epoch 18; Iter   491/ 1097] train: loss: 0.2047714
[Epoch 18; Iter   521/ 1097] train: loss: 0.0488290
[Epoch 18; Iter   551/ 1097] train: loss: 0.0790367
[Epoch 18; Iter   581/ 1097] train: loss: 0.0335788
[Epoch 18; Iter   611/ 1097] train: loss: 0.0913332
[Epoch 18; Iter   641/ 1097] train: loss: 0.0434563
[Epoch 18; Iter   671/ 1097] train: loss: 0.1180825
[Epoch 18; Iter   701/ 1097] train: loss: 0.2071074
[Epoch 18; Iter   731/ 1097] train: loss: 0.1859605
[Epoch 18; Iter   761/ 1097] train: loss: 0.0154081
[Epoch 18; Iter   791/ 1097] train: loss: 0.0519867
[Epoch 18; Iter   821/ 1097] train: loss: 0.0472988
[Epoch 18; Iter   851/ 1097] train: loss: 0.1081593
[Epoch 18; Iter   881/ 1097] train: loss: 0.0192264
[Epoch 18; Iter   911/ 1097] train: loss: 0.0928283
[Epoch 18; Iter   941/ 1097] train: loss: 0.0652571
[Epoch 18; Iter   971/ 1097] train: loss: 0.1028656
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1040597
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0195274
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0264810
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0293896
[Epoch 18] ogbg-molhiv: 0.766721 val loss: 0.329618
[Epoch 18] ogbg-molhiv: 0.709224 test loss: 0.291005
[Epoch 19; Iter    24/ 1097] train: loss: 0.0367339
[Epoch 19; Iter    54/ 1097] train: loss: 0.1153070
[Epoch 19; Iter    84/ 1097] train: loss: 0.0250882
[Epoch 19; Iter   114/ 1097] train: loss: 0.0663525
[Epoch 19; Iter   144/ 1097] train: loss: 0.0651526
[Epoch 19; Iter   174/ 1097] train: loss: 0.0837267
[Epoch 19; Iter   204/ 1097] train: loss: 0.0525649
[Epoch 19; Iter   234/ 1097] train: loss: 0.1451169
[Epoch 19; Iter   264/ 1097] train: loss: 0.0529776
[Epoch 19; Iter   294/ 1097] train: loss: 0.0765417
[Epoch 19; Iter   324/ 1097] train: loss: 0.0393327
[Epoch 19; Iter   354/ 1097] train: loss: 0.0282104
[Epoch 19; Iter   384/ 1097] train: loss: 0.0805617
[Epoch 19; Iter   414/ 1097] train: loss: 0.2145037
[Epoch 19; Iter   444/ 1097] train: loss: 0.0288084
[Epoch 19; Iter   474/ 1097] train: loss: 0.0225515
[Epoch 19; Iter   504/ 1097] train: loss: 0.1958012
[Epoch 19; Iter   534/ 1097] train: loss: 0.3410952
[Epoch 19; Iter   564/ 1097] train: loss: 0.1830204
[Epoch 19; Iter   594/ 1097] train: loss: 0.0516266
[Epoch 19; Iter   624/ 1097] train: loss: 0.0488473
[Epoch 19; Iter   654/ 1097] train: loss: 0.1092161
[Epoch 19; Iter   684/ 1097] train: loss: 0.0604636
[Epoch 19; Iter   714/ 1097] train: loss: 0.0366660
[Epoch 19; Iter   744/ 1097] train: loss: 0.1875499
[Epoch 19; Iter   774/ 1097] train: loss: 0.0855722
[Epoch 19; Iter   804/ 1097] train: loss: 0.0186105
[Epoch 19; Iter   834/ 1097] train: loss: 0.2084542
[Epoch 19; Iter   864/ 1097] train: loss: 0.1799582
[Epoch 19; Iter   894/ 1097] train: loss: 0.0447161
[Epoch 19; Iter   924/ 1097] train: loss: 0.0367570
[Epoch 19; Iter   954/ 1097] train: loss: 0.1145125
[Epoch 19; Iter   984/ 1097] train: loss: 0.0362050
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2080773
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1086517
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0187826
[Epoch 19] ogbg-molhiv: 0.707231 val loss: 0.101744
[Epoch 19] ogbg-molhiv: 0.617743 test loss: 0.182220
[Epoch 20; Iter     7/ 1097] train: loss: 0.0730919
[Epoch 20; Iter    37/ 1097] train: loss: 0.2913192
[Epoch 20; Iter    67/ 1097] train: loss: 0.0232878
[Epoch 20; Iter    97/ 1097] train: loss: 0.0195119
[Epoch 20; Iter   127/ 1097] train: loss: 0.1790703
[Epoch 20; Iter   157/ 1097] train: loss: 0.0401898
[Epoch 20; Iter   187/ 1097] train: loss: 0.0283698
[Epoch 20; Iter   217/ 1097] train: loss: 0.0514347
[Epoch 20; Iter   247/ 1097] train: loss: 0.0630974
[Epoch 16; Iter   195/ 1097] train: loss: 0.0175211
[Epoch 16; Iter   225/ 1097] train: loss: 0.1228231
[Epoch 16; Iter   255/ 1097] train: loss: 0.0676149
[Epoch 16; Iter   285/ 1097] train: loss: 0.1897915
[Epoch 16; Iter   315/ 1097] train: loss: 0.0532158
[Epoch 16; Iter   345/ 1097] train: loss: 0.2327514
[Epoch 16; Iter   375/ 1097] train: loss: 0.1037902
[Epoch 16; Iter   405/ 1097] train: loss: 0.0200095
[Epoch 16; Iter   435/ 1097] train: loss: 0.3388332
[Epoch 16; Iter   465/ 1097] train: loss: 0.0552416
[Epoch 16; Iter   495/ 1097] train: loss: 0.0451640
[Epoch 16; Iter   525/ 1097] train: loss: 0.1588012
[Epoch 16; Iter   555/ 1097] train: loss: 0.0296139
[Epoch 16; Iter   585/ 1097] train: loss: 0.2063080
[Epoch 16; Iter   615/ 1097] train: loss: 0.0765817
[Epoch 16; Iter   645/ 1097] train: loss: 0.0513742
[Epoch 16; Iter   675/ 1097] train: loss: 0.0404734
[Epoch 16; Iter   705/ 1097] train: loss: 0.0378986
[Epoch 16; Iter   735/ 1097] train: loss: 0.3137000
[Epoch 16; Iter   765/ 1097] train: loss: 0.0309210
[Epoch 16; Iter   795/ 1097] train: loss: 0.0305200
[Epoch 16; Iter   825/ 1097] train: loss: 0.1776843
[Epoch 16; Iter   855/ 1097] train: loss: 0.1952048
[Epoch 16; Iter   885/ 1097] train: loss: 0.0207114
[Epoch 16; Iter   915/ 1097] train: loss: 0.0214893
[Epoch 16; Iter   945/ 1097] train: loss: 0.1045892
[Epoch 16; Iter   975/ 1097] train: loss: 0.1359007
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2370067
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0841363
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1451632
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1629224
[Epoch 16] ogbg-molhiv: 0.802114 val loss: 0.377345
[Epoch 16] ogbg-molhiv: 0.791807 test loss: 0.115315
[Epoch 17; Iter    28/ 1097] train: loss: 0.2305799
[Epoch 17; Iter    58/ 1097] train: loss: 0.0275923
[Epoch 17; Iter    88/ 1097] train: loss: 0.1364703
[Epoch 17; Iter   118/ 1097] train: loss: 0.1418718
[Epoch 17; Iter   148/ 1097] train: loss: 0.0203345
[Epoch 17; Iter   178/ 1097] train: loss: 0.1792091
[Epoch 17; Iter   208/ 1097] train: loss: 0.0387694
[Epoch 17; Iter   238/ 1097] train: loss: 0.2296588
[Epoch 17; Iter   268/ 1097] train: loss: 0.0265491
[Epoch 17; Iter   298/ 1097] train: loss: 0.2202344
[Epoch 17; Iter   328/ 1097] train: loss: 0.2375648
[Epoch 17; Iter   358/ 1097] train: loss: 0.0465961
[Epoch 17; Iter   388/ 1097] train: loss: 0.1669086
[Epoch 17; Iter   418/ 1097] train: loss: 0.1712440
[Epoch 17; Iter   448/ 1097] train: loss: 0.0248751
[Epoch 17; Iter   478/ 1097] train: loss: 0.0439651
[Epoch 17; Iter   508/ 1097] train: loss: 0.0210225
[Epoch 17; Iter   538/ 1097] train: loss: 0.0371569
[Epoch 17; Iter   568/ 1097] train: loss: 0.2371570
[Epoch 17; Iter   598/ 1097] train: loss: 0.0287792
[Epoch 17; Iter   628/ 1097] train: loss: 0.1401980
[Epoch 17; Iter   658/ 1097] train: loss: 0.0558225
[Epoch 17; Iter   688/ 1097] train: loss: 0.0798390
[Epoch 17; Iter   718/ 1097] train: loss: 0.1843421
[Epoch 17; Iter   748/ 1097] train: loss: 0.0236667
[Epoch 17; Iter   778/ 1097] train: loss: 0.1965834
[Epoch 17; Iter   808/ 1097] train: loss: 0.0269359
[Epoch 17; Iter   838/ 1097] train: loss: 0.0233098
[Epoch 17; Iter   868/ 1097] train: loss: 0.0361136
[Epoch 17; Iter   898/ 1097] train: loss: 0.0349869
[Epoch 17; Iter   928/ 1097] train: loss: 0.3533826
[Epoch 17; Iter   958/ 1097] train: loss: 0.0920064
[Epoch 17; Iter   988/ 1097] train: loss: 0.0486482
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0380298
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0392408
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1528326
[Epoch 17] ogbg-molhiv: 0.780760 val loss: 0.301819
[Epoch 17] ogbg-molhiv: 0.763024 test loss: 0.119211
[Epoch 18; Iter    11/ 1097] train: loss: 0.1326492
[Epoch 18; Iter    41/ 1097] train: loss: 0.0217401
[Epoch 18; Iter    71/ 1097] train: loss: 0.1974562
[Epoch 18; Iter   101/ 1097] train: loss: 0.0261707
[Epoch 18; Iter   131/ 1097] train: loss: 0.1302109
[Epoch 18; Iter   161/ 1097] train: loss: 0.1447437
[Epoch 18; Iter   191/ 1097] train: loss: 0.0722018
[Epoch 18; Iter   221/ 1097] train: loss: 0.0215740
[Epoch 18; Iter   251/ 1097] train: loss: 0.0863003
[Epoch 18; Iter   281/ 1097] train: loss: 0.0182797
[Epoch 18; Iter   311/ 1097] train: loss: 0.3141700
[Epoch 18; Iter   341/ 1097] train: loss: 0.1790174
[Epoch 18; Iter   371/ 1097] train: loss: 0.0277089
[Epoch 18; Iter   401/ 1097] train: loss: 0.0221727
[Epoch 18; Iter   431/ 1097] train: loss: 0.0309687
[Epoch 18; Iter   461/ 1097] train: loss: 0.0465542
[Epoch 18; Iter   491/ 1097] train: loss: 0.1445250
[Epoch 18; Iter   521/ 1097] train: loss: 0.0382513
[Epoch 18; Iter   551/ 1097] train: loss: 0.0961404
[Epoch 18; Iter   581/ 1097] train: loss: 0.0205479
[Epoch 18; Iter   611/ 1097] train: loss: 0.1877534
[Epoch 18; Iter   641/ 1097] train: loss: 0.0993221
[Epoch 18; Iter   671/ 1097] train: loss: 0.1561724
[Epoch 18; Iter   701/ 1097] train: loss: 0.0827701
[Epoch 18; Iter   731/ 1097] train: loss: 0.2124842
[Epoch 18; Iter   761/ 1097] train: loss: 0.0461454
[Epoch 18; Iter   791/ 1097] train: loss: 0.0721952
[Epoch 18; Iter   821/ 1097] train: loss: 0.0599534
[Epoch 18; Iter   851/ 1097] train: loss: 0.1890769
[Epoch 18; Iter   881/ 1097] train: loss: 0.0301606
[Epoch 18; Iter   911/ 1097] train: loss: 0.1225287
[Epoch 18; Iter   941/ 1097] train: loss: 0.0306965
[Epoch 18; Iter   971/ 1097] train: loss: 0.0250676
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1145544
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0197851
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0303833
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0311537
[Epoch 18] ogbg-molhiv: 0.813850 val loss: 0.195476
[Epoch 18] ogbg-molhiv: 0.760105 test loss: 0.118732
[Epoch 19; Iter    24/ 1097] train: loss: 0.1278546
[Epoch 19; Iter    54/ 1097] train: loss: 0.1456003
[Epoch 19; Iter    84/ 1097] train: loss: 0.0264975
[Epoch 19; Iter   114/ 1097] train: loss: 0.1108553
[Epoch 19; Iter   144/ 1097] train: loss: 0.2213443
[Epoch 19; Iter   174/ 1097] train: loss: 0.0995252
[Epoch 19; Iter   204/ 1097] train: loss: 0.1318345
[Epoch 19; Iter   234/ 1097] train: loss: 0.2024834
[Epoch 19; Iter   264/ 1097] train: loss: 0.2245806
[Epoch 19; Iter   294/ 1097] train: loss: 0.1863631
[Epoch 19; Iter   324/ 1097] train: loss: 0.0940858
[Epoch 19; Iter   354/ 1097] train: loss: 0.0629986
[Epoch 19; Iter   384/ 1097] train: loss: 0.2109799
[Epoch 19; Iter   414/ 1097] train: loss: 0.1626840
[Epoch 19; Iter   444/ 1097] train: loss: 0.0434689
[Epoch 19; Iter   474/ 1097] train: loss: 0.0221469
[Epoch 19; Iter   504/ 1097] train: loss: 0.0843977
[Epoch 19; Iter   534/ 1097] train: loss: 0.3007617
[Epoch 19; Iter   564/ 1097] train: loss: 0.2921522
[Epoch 19; Iter   594/ 1097] train: loss: 0.0268485
[Epoch 19; Iter   624/ 1097] train: loss: 0.0245548
[Epoch 19; Iter   654/ 1097] train: loss: 0.1709846
[Epoch 19; Iter   684/ 1097] train: loss: 0.2137431
[Epoch 19; Iter   714/ 1097] train: loss: 0.1072327
[Epoch 19; Iter   744/ 1097] train: loss: 0.1430644
[Epoch 19; Iter   774/ 1097] train: loss: 0.0799810
[Epoch 19; Iter   804/ 1097] train: loss: 0.0170031
[Epoch 19; Iter   834/ 1097] train: loss: 0.1886128
[Epoch 19; Iter   864/ 1097] train: loss: 0.1848057
[Epoch 19; Iter   894/ 1097] train: loss: 0.0444443
[Epoch 19; Iter   924/ 1097] train: loss: 0.1309975
[Epoch 19; Iter   954/ 1097] train: loss: 0.1791439
[Epoch 19; Iter   984/ 1097] train: loss: 0.0214239
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1990478
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0740681
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0198252
[Epoch 19] ogbg-molhiv: 0.774554 val loss: 0.145382
[Epoch 19] ogbg-molhiv: 0.724079 test loss: 0.130331
[Epoch 20; Iter     7/ 1097] train: loss: 0.1727504
[Epoch 20; Iter    37/ 1097] train: loss: 0.2029624
[Epoch 20; Iter    67/ 1097] train: loss: 0.0179521
[Epoch 20; Iter    97/ 1097] train: loss: 0.0589852
[Epoch 20; Iter   127/ 1097] train: loss: 0.2300526
[Epoch 20; Iter   157/ 1097] train: loss: 0.0232779
[Epoch 20; Iter   187/ 1097] train: loss: 0.0682032
[Epoch 20; Iter   217/ 1097] train: loss: 0.0333142
[Epoch 20; Iter   247/ 1097] train: loss: 0.1235240
[Epoch 16; Iter   195/ 1097] train: loss: 0.0281787
[Epoch 16; Iter   225/ 1097] train: loss: 0.0676288
[Epoch 16; Iter   255/ 1097] train: loss: 0.2467034
[Epoch 16; Iter   285/ 1097] train: loss: 0.0502532
[Epoch 16; Iter   315/ 1097] train: loss: 0.0205446
[Epoch 16; Iter   345/ 1097] train: loss: 0.1331705
[Epoch 16; Iter   375/ 1097] train: loss: 0.0454781
[Epoch 16; Iter   405/ 1097] train: loss: 0.0230454
[Epoch 16; Iter   435/ 1097] train: loss: 0.1100667
[Epoch 16; Iter   465/ 1097] train: loss: 0.1801157
[Epoch 16; Iter   495/ 1097] train: loss: 0.0379693
[Epoch 16; Iter   525/ 1097] train: loss: 0.0203044
[Epoch 16; Iter   555/ 1097] train: loss: 0.4308626
[Epoch 16; Iter   585/ 1097] train: loss: 0.0499452
[Epoch 16; Iter   615/ 1097] train: loss: 0.1394084
[Epoch 16; Iter   645/ 1097] train: loss: 0.1120294
[Epoch 16; Iter   675/ 1097] train: loss: 0.0773147
[Epoch 16; Iter   705/ 1097] train: loss: 0.0259375
[Epoch 16; Iter   735/ 1097] train: loss: 0.1803837
[Epoch 16; Iter   765/ 1097] train: loss: 0.4539680
[Epoch 16; Iter   795/ 1097] train: loss: 0.0412600
[Epoch 16; Iter   825/ 1097] train: loss: 0.0350329
[Epoch 16; Iter   855/ 1097] train: loss: 0.0386073
[Epoch 16; Iter   885/ 1097] train: loss: 0.1773188
[Epoch 16; Iter   915/ 1097] train: loss: 0.1464332
[Epoch 16; Iter   945/ 1097] train: loss: 0.0403020
[Epoch 16; Iter   975/ 1097] train: loss: 0.0218647
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1279055
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0493968
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0283957
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0215078
[Epoch 16] ogbg-molhiv: 0.814995 val loss: 0.067674
[Epoch 16] ogbg-molhiv: 0.737552 test loss: 0.119959
[Epoch 17; Iter    28/ 1097] train: loss: 0.1925481
[Epoch 17; Iter    58/ 1097] train: loss: 0.1273002
[Epoch 17; Iter    88/ 1097] train: loss: 0.1566765
[Epoch 17; Iter   118/ 1097] train: loss: 0.0151187
[Epoch 17; Iter   148/ 1097] train: loss: 0.0346071
[Epoch 17; Iter   178/ 1097] train: loss: 0.0244585
[Epoch 17; Iter   208/ 1097] train: loss: 0.0191323
[Epoch 17; Iter   238/ 1097] train: loss: 0.0350991
[Epoch 17; Iter   268/ 1097] train: loss: 0.0570824
[Epoch 17; Iter   298/ 1097] train: loss: 0.0750717
[Epoch 17; Iter   328/ 1097] train: loss: 0.1319435
[Epoch 17; Iter   358/ 1097] train: loss: 0.2829489
[Epoch 17; Iter   388/ 1097] train: loss: 0.0390072
[Epoch 17; Iter   418/ 1097] train: loss: 0.0468033
[Epoch 17; Iter   448/ 1097] train: loss: 0.0295505
[Epoch 17; Iter   478/ 1097] train: loss: 0.2182595
[Epoch 17; Iter   508/ 1097] train: loss: 0.0225329
[Epoch 17; Iter   538/ 1097] train: loss: 0.1214326
[Epoch 17; Iter   568/ 1097] train: loss: 0.0317243
[Epoch 17; Iter   598/ 1097] train: loss: 0.0828067
[Epoch 17; Iter   628/ 1097] train: loss: 0.0377480
[Epoch 17; Iter   658/ 1097] train: loss: 0.2043151
[Epoch 17; Iter   688/ 1097] train: loss: 0.0237209
[Epoch 17; Iter   718/ 1097] train: loss: 0.0824517
[Epoch 17; Iter   748/ 1097] train: loss: 0.1594870
[Epoch 17; Iter   778/ 1097] train: loss: 0.0699949
[Epoch 17; Iter   808/ 1097] train: loss: 0.1772410
[Epoch 17; Iter   838/ 1097] train: loss: 0.0628426
[Epoch 17; Iter   868/ 1097] train: loss: 0.0281925
[Epoch 17; Iter   898/ 1097] train: loss: 0.1229485
[Epoch 17; Iter   928/ 1097] train: loss: 0.2552623
[Epoch 17; Iter   958/ 1097] train: loss: 0.0225382
[Epoch 17; Iter   988/ 1097] train: loss: 0.1084323
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0367774
[Epoch 17; Iter  1048/ 1097] train: loss: 0.3257670
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2578586
[Epoch 17] ogbg-molhiv: 0.821361 val loss: 0.070523
[Epoch 17] ogbg-molhiv: 0.730825 test loss: 0.118353
[Epoch 18; Iter    11/ 1097] train: loss: 0.0246797
[Epoch 18; Iter    41/ 1097] train: loss: 0.1848543
[Epoch 18; Iter    71/ 1097] train: loss: 0.2255191
[Epoch 18; Iter   101/ 1097] train: loss: 0.0275654
[Epoch 18; Iter   131/ 1097] train: loss: 0.0988001
[Epoch 18; Iter   161/ 1097] train: loss: 0.2357624
[Epoch 18; Iter   191/ 1097] train: loss: 0.0464128
[Epoch 18; Iter   221/ 1097] train: loss: 0.0558542
[Epoch 18; Iter   251/ 1097] train: loss: 0.0284084
[Epoch 18; Iter   281/ 1097] train: loss: 0.1278112
[Epoch 18; Iter   311/ 1097] train: loss: 0.0306875
[Epoch 18; Iter   341/ 1097] train: loss: 0.0219198
[Epoch 18; Iter   371/ 1097] train: loss: 0.0254032
[Epoch 18; Iter   401/ 1097] train: loss: 0.1456588
[Epoch 18; Iter   431/ 1097] train: loss: 0.0362868
[Epoch 18; Iter   461/ 1097] train: loss: 0.1167555
[Epoch 18; Iter   491/ 1097] train: loss: 0.0213846
[Epoch 18; Iter   521/ 1097] train: loss: 0.2197783
[Epoch 18; Iter   551/ 1097] train: loss: 0.0587999
[Epoch 18; Iter   581/ 1097] train: loss: 0.0343603
[Epoch 18; Iter   611/ 1097] train: loss: 0.0239049
[Epoch 18; Iter   641/ 1097] train: loss: 0.2282618
[Epoch 18; Iter   671/ 1097] train: loss: 0.0482722
[Epoch 18; Iter   701/ 1097] train: loss: 0.0580511
[Epoch 18; Iter   731/ 1097] train: loss: 0.0307236
[Epoch 18; Iter   761/ 1097] train: loss: 0.0311434
[Epoch 18; Iter   791/ 1097] train: loss: 0.0249283
[Epoch 18; Iter   821/ 1097] train: loss: 0.0874888
[Epoch 18; Iter   851/ 1097] train: loss: 0.0494265
[Epoch 18; Iter   881/ 1097] train: loss: 0.1060682
[Epoch 18; Iter   911/ 1097] train: loss: 0.0243674
[Epoch 18; Iter   941/ 1097] train: loss: 0.1132298
[Epoch 18; Iter   971/ 1097] train: loss: 0.0301042
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1224406
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0905705
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0745644
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0167233
[Epoch 18] ogbg-molhiv: 0.816407 val loss: 0.077659
[Epoch 18] ogbg-molhiv: 0.733579 test loss: 0.121228
[Epoch 19; Iter    24/ 1097] train: loss: 0.0315885
[Epoch 19; Iter    54/ 1097] train: loss: 0.1969246
[Epoch 19; Iter    84/ 1097] train: loss: 0.0523789
[Epoch 19; Iter   114/ 1097] train: loss: 0.0206300
[Epoch 19; Iter   144/ 1097] train: loss: 0.0471384
[Epoch 19; Iter   174/ 1097] train: loss: 0.0213416
[Epoch 19; Iter   204/ 1097] train: loss: 0.0535168
[Epoch 19; Iter   234/ 1097] train: loss: 0.0693362
[Epoch 19; Iter   264/ 1097] train: loss: 0.0197062
[Epoch 19; Iter   294/ 1097] train: loss: 0.0229833
[Epoch 19; Iter   324/ 1097] train: loss: 0.0253535
[Epoch 19; Iter   354/ 1097] train: loss: 0.2058511
[Epoch 19; Iter   384/ 1097] train: loss: 0.0307533
[Epoch 19; Iter   414/ 1097] train: loss: 0.1549987
[Epoch 19; Iter   444/ 1097] train: loss: 0.0243153
[Epoch 19; Iter   474/ 1097] train: loss: 0.1776368
[Epoch 19; Iter   504/ 1097] train: loss: 0.0325893
[Epoch 19; Iter   534/ 1097] train: loss: 0.0233737
[Epoch 19; Iter   564/ 1097] train: loss: 0.1818689
[Epoch 19; Iter   594/ 1097] train: loss: 0.1342358
[Epoch 19; Iter   624/ 1097] train: loss: 0.0355897
[Epoch 19; Iter   654/ 1097] train: loss: 0.0217588
[Epoch 19; Iter   684/ 1097] train: loss: 0.4210793
[Epoch 19; Iter   714/ 1097] train: loss: 0.0311147
[Epoch 19; Iter   744/ 1097] train: loss: 0.0397803
[Epoch 19; Iter   774/ 1097] train: loss: 0.0279312
[Epoch 19; Iter   804/ 1097] train: loss: 0.0201282
[Epoch 19; Iter   834/ 1097] train: loss: 0.0233080
[Epoch 19; Iter   864/ 1097] train: loss: 0.0258171
[Epoch 19; Iter   894/ 1097] train: loss: 0.2893127
[Epoch 19; Iter   924/ 1097] train: loss: 0.0769709
[Epoch 19; Iter   954/ 1097] train: loss: 0.0192941
[Epoch 19; Iter   984/ 1097] train: loss: 0.1430388
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1077892
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0202052
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3409662
[Epoch 19] ogbg-molhiv: 0.806045 val loss: 0.073575
[Epoch 19] ogbg-molhiv: 0.736086 test loss: 0.118594
[Epoch 20; Iter     7/ 1097] train: loss: 0.0544365
[Epoch 20; Iter    37/ 1097] train: loss: 0.0534212
[Epoch 20; Iter    67/ 1097] train: loss: 0.0223417
[Epoch 20; Iter    97/ 1097] train: loss: 0.0290841
[Epoch 20; Iter   127/ 1097] train: loss: 0.0239945
[Epoch 20; Iter   157/ 1097] train: loss: 0.0177110
[Epoch 20; Iter   187/ 1097] train: loss: 0.0881034
[Epoch 20; Iter   217/ 1097] train: loss: 0.3449218
[Epoch 20; Iter   247/ 1097] train: loss: 0.0516882
[Epoch 16; Iter   195/ 1097] train: loss: 0.0364258
[Epoch 16; Iter   225/ 1097] train: loss: 0.0303799
[Epoch 16; Iter   255/ 1097] train: loss: 0.0337520
[Epoch 16; Iter   285/ 1097] train: loss: 0.1643044
[Epoch 16; Iter   315/ 1097] train: loss: 0.0804953
[Epoch 16; Iter   345/ 1097] train: loss: 0.0474280
[Epoch 16; Iter   375/ 1097] train: loss: 0.2130498
[Epoch 16; Iter   405/ 1097] train: loss: 0.1961392
[Epoch 16; Iter   435/ 1097] train: loss: 0.0943614
[Epoch 16; Iter   465/ 1097] train: loss: 0.1507691
[Epoch 16; Iter   495/ 1097] train: loss: 0.0757310
[Epoch 16; Iter   525/ 1097] train: loss: 0.1496340
[Epoch 16; Iter   555/ 1097] train: loss: 0.0296445
[Epoch 16; Iter   585/ 1097] train: loss: 0.1410613
[Epoch 16; Iter   615/ 1097] train: loss: 0.1029266
[Epoch 16; Iter   645/ 1097] train: loss: 0.0726746
[Epoch 16; Iter   675/ 1097] train: loss: 0.0998000
[Epoch 16; Iter   705/ 1097] train: loss: 0.1469236
[Epoch 16; Iter   735/ 1097] train: loss: 0.0718333
[Epoch 16; Iter   765/ 1097] train: loss: 0.0542794
[Epoch 16; Iter   795/ 1097] train: loss: 0.0903086
[Epoch 16; Iter   825/ 1097] train: loss: 0.0339225
[Epoch 16; Iter   855/ 1097] train: loss: 0.2104481
[Epoch 16; Iter   885/ 1097] train: loss: 0.2557469
[Epoch 16; Iter   915/ 1097] train: loss: 0.0264960
[Epoch 16; Iter   945/ 1097] train: loss: 0.0249523
[Epoch 16; Iter   975/ 1097] train: loss: 0.0224317
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0370136
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0281443
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1299400
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0903898
[Epoch 16] ogbg-molhiv: 0.783494 val loss: 0.083655
[Epoch 16] ogbg-molhiv: 0.787134 test loss: 0.112720
[Epoch 17; Iter    28/ 1097] train: loss: 0.0354759
[Epoch 17; Iter    58/ 1097] train: loss: 0.0307289
[Epoch 17; Iter    88/ 1097] train: loss: 0.0354249
[Epoch 17; Iter   118/ 1097] train: loss: 0.1665059
[Epoch 17; Iter   148/ 1097] train: loss: 0.2049010
[Epoch 17; Iter   178/ 1097] train: loss: 0.0349229
[Epoch 17; Iter   208/ 1097] train: loss: 0.0238054
[Epoch 17; Iter   238/ 1097] train: loss: 0.2150024
[Epoch 17; Iter   268/ 1097] train: loss: 0.0263471
[Epoch 17; Iter   298/ 1097] train: loss: 0.0271348
[Epoch 17; Iter   328/ 1097] train: loss: 0.0269831
[Epoch 17; Iter   358/ 1097] train: loss: 0.0268707
[Epoch 17; Iter   388/ 1097] train: loss: 0.0416499
[Epoch 17; Iter   418/ 1097] train: loss: 0.1562509
[Epoch 17; Iter   448/ 1097] train: loss: 0.0311755
[Epoch 17; Iter   478/ 1097] train: loss: 0.0644303
[Epoch 17; Iter   508/ 1097] train: loss: 0.0321894
[Epoch 17; Iter   538/ 1097] train: loss: 0.2476143
[Epoch 17; Iter   568/ 1097] train: loss: 0.1807446
[Epoch 17; Iter   598/ 1097] train: loss: 0.1439069
[Epoch 17; Iter   628/ 1097] train: loss: 0.0393997
[Epoch 17; Iter   658/ 1097] train: loss: 0.0267986
[Epoch 17; Iter   688/ 1097] train: loss: 0.2762033
[Epoch 17; Iter   718/ 1097] train: loss: 0.0292633
[Epoch 17; Iter   748/ 1097] train: loss: 0.1509347
[Epoch 17; Iter   778/ 1097] train: loss: 0.0600897
[Epoch 17; Iter   808/ 1097] train: loss: 0.0605020
[Epoch 17; Iter   838/ 1097] train: loss: 0.0254802
[Epoch 17; Iter   868/ 1097] train: loss: 0.0207888
[Epoch 17; Iter   898/ 1097] train: loss: 0.1216953
[Epoch 17; Iter   928/ 1097] train: loss: 0.2217854
[Epoch 17; Iter   958/ 1097] train: loss: 0.1458377
[Epoch 17; Iter   988/ 1097] train: loss: 0.0445417
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0282549
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0306945
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1966122
[Epoch 17] ogbg-molhiv: 0.789416 val loss: 0.074819
[Epoch 17] ogbg-molhiv: 0.776405 test loss: 0.115237
[Epoch 18; Iter    11/ 1097] train: loss: 0.1570874
[Epoch 18; Iter    41/ 1097] train: loss: 0.2590034
[Epoch 18; Iter    71/ 1097] train: loss: 0.1232970
[Epoch 18; Iter   101/ 1097] train: loss: 0.1254664
[Epoch 18; Iter   131/ 1097] train: loss: 0.1664504
[Epoch 18; Iter   161/ 1097] train: loss: 0.0541476
[Epoch 18; Iter   191/ 1097] train: loss: 0.1565625
[Epoch 18; Iter   221/ 1097] train: loss: 0.1661361
[Epoch 18; Iter   251/ 1097] train: loss: 0.1177194
[Epoch 18; Iter   281/ 1097] train: loss: 0.0185589
[Epoch 18; Iter   311/ 1097] train: loss: 0.1664604
[Epoch 18; Iter   341/ 1097] train: loss: 0.1051689
[Epoch 18; Iter   371/ 1097] train: loss: 0.0382390
[Epoch 18; Iter   401/ 1097] train: loss: 0.2044863
[Epoch 18; Iter   431/ 1097] train: loss: 0.0818905
[Epoch 18; Iter   461/ 1097] train: loss: 0.0370042
[Epoch 18; Iter   491/ 1097] train: loss: 0.2699587
[Epoch 18; Iter   521/ 1097] train: loss: 0.2336827
[Epoch 18; Iter   551/ 1097] train: loss: 0.0307899
[Epoch 18; Iter   581/ 1097] train: loss: 0.0403948
[Epoch 18; Iter   611/ 1097] train: loss: 0.0191498
[Epoch 18; Iter   641/ 1097] train: loss: 0.2434241
[Epoch 18; Iter   671/ 1097] train: loss: 0.0426952
[Epoch 18; Iter   701/ 1097] train: loss: 0.2795347
[Epoch 18; Iter   731/ 1097] train: loss: 0.1204787
[Epoch 18; Iter   761/ 1097] train: loss: 0.3184540
[Epoch 18; Iter   791/ 1097] train: loss: 0.0635455
[Epoch 18; Iter   821/ 1097] train: loss: 0.0728196
[Epoch 18; Iter   851/ 1097] train: loss: 0.1675167
[Epoch 18; Iter   881/ 1097] train: loss: 0.1629920
[Epoch 18; Iter   911/ 1097] train: loss: 0.2570983
[Epoch 18; Iter   941/ 1097] train: loss: 0.0264279
[Epoch 18; Iter   971/ 1097] train: loss: 0.1682097
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0433569
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0950754
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0442636
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1599591
[Epoch 18] ogbg-molhiv: 0.743962 val loss: 0.249764
[Epoch 18] ogbg-molhiv: 0.745229 test loss: 0.246771
[Epoch 19; Iter    24/ 1097] train: loss: 0.3488379
[Epoch 19; Iter    54/ 1097] train: loss: 0.1504543
[Epoch 19; Iter    84/ 1097] train: loss: 0.3183512
[Epoch 19; Iter   114/ 1097] train: loss: 0.0280795
[Epoch 19; Iter   144/ 1097] train: loss: 0.1162596
[Epoch 19; Iter   174/ 1097] train: loss: 0.0393229
[Epoch 19; Iter   204/ 1097] train: loss: 0.0265955
[Epoch 19; Iter   234/ 1097] train: loss: 0.0280992
[Epoch 19; Iter   264/ 1097] train: loss: 0.0945278
[Epoch 19; Iter   294/ 1097] train: loss: 0.1555322
[Epoch 19; Iter   324/ 1097] train: loss: 0.0466862
[Epoch 19; Iter   354/ 1097] train: loss: 0.2740051
[Epoch 19; Iter   384/ 1097] train: loss: 0.0285380
[Epoch 19; Iter   414/ 1097] train: loss: 0.0242175
[Epoch 19; Iter   444/ 1097] train: loss: 0.2263052
[Epoch 19; Iter   474/ 1097] train: loss: 0.1521443
[Epoch 19; Iter   504/ 1097] train: loss: 0.2169929
[Epoch 19; Iter   534/ 1097] train: loss: 0.1931779
[Epoch 19; Iter   564/ 1097] train: loss: 0.0196086
[Epoch 19; Iter   594/ 1097] train: loss: 0.0247291
[Epoch 19; Iter   624/ 1097] train: loss: 0.0559540
[Epoch 19; Iter   654/ 1097] train: loss: 0.0864515
[Epoch 19; Iter   684/ 1097] train: loss: 0.0273305
[Epoch 19; Iter   714/ 1097] train: loss: 0.1607516
[Epoch 19; Iter   744/ 1097] train: loss: 0.0267315
[Epoch 19; Iter   774/ 1097] train: loss: 0.2216731
[Epoch 19; Iter   804/ 1097] train: loss: 0.1351507
[Epoch 19; Iter   834/ 1097] train: loss: 0.1613371
[Epoch 19; Iter   864/ 1097] train: loss: 0.3475498
[Epoch 19; Iter   894/ 1097] train: loss: 0.2326654
[Epoch 19; Iter   924/ 1097] train: loss: 0.4393601
[Epoch 19; Iter   954/ 1097] train: loss: 0.1548948
[Epoch 19; Iter   984/ 1097] train: loss: 0.3935013
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1748861
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0220003
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0461937
[Epoch 19] ogbg-molhiv: 0.821876 val loss: 0.333735
[Epoch 19] ogbg-molhiv: 0.786566 test loss: 0.691022
[Epoch 20; Iter     7/ 1097] train: loss: 0.0669482
[Epoch 20; Iter    37/ 1097] train: loss: 0.2227908
[Epoch 20; Iter    67/ 1097] train: loss: 0.0486735
[Epoch 20; Iter    97/ 1097] train: loss: 0.0343954
[Epoch 20; Iter   127/ 1097] train: loss: 0.0590633
[Epoch 20; Iter   157/ 1097] train: loss: 0.0944111
[Epoch 20; Iter   187/ 1097] train: loss: 0.0155997
[Epoch 20; Iter   217/ 1097] train: loss: 0.0288901
[Epoch 20; Iter   247/ 1097] train: loss: 0.0280029
[Epoch 20; Iter   277/ 1097] train: loss: 0.1408841
[Epoch 20; Iter   307/ 1097] train: loss: 0.1768144
[Epoch 20; Iter   337/ 1097] train: loss: 0.1440904
[Epoch 20; Iter   367/ 1097] train: loss: 0.0397547
[Epoch 20; Iter   397/ 1097] train: loss: 0.0179827
[Epoch 20; Iter   427/ 1097] train: loss: 0.0168542
[Epoch 20; Iter   457/ 1097] train: loss: 0.0729075
[Epoch 20; Iter   487/ 1097] train: loss: 0.1261963
[Epoch 20; Iter   517/ 1097] train: loss: 0.0398484
[Epoch 20; Iter   547/ 1097] train: loss: 0.1425290
[Epoch 20; Iter   577/ 1097] train: loss: 0.0231292
[Epoch 20; Iter   607/ 1097] train: loss: 0.0260611
[Epoch 20; Iter   637/ 1097] train: loss: 0.0413688
[Epoch 20; Iter   667/ 1097] train: loss: 0.1697102
[Epoch 20; Iter   697/ 1097] train: loss: 0.1667882
[Epoch 20; Iter   727/ 1097] train: loss: 0.1216628
[Epoch 20; Iter   757/ 1097] train: loss: 0.0215375
[Epoch 20; Iter   787/ 1097] train: loss: 0.0243822
[Epoch 20; Iter   817/ 1097] train: loss: 0.0989955
[Epoch 20; Iter   847/ 1097] train: loss: 0.0404088
[Epoch 20; Iter   877/ 1097] train: loss: 0.1853520
[Epoch 20; Iter   907/ 1097] train: loss: 0.1816550
[Epoch 20; Iter   937/ 1097] train: loss: 0.0272434
[Epoch 20; Iter   967/ 1097] train: loss: 0.0939234
[Epoch 20; Iter   997/ 1097] train: loss: 0.0240946
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0320747
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1111360
[Epoch 20; Iter  1087/ 1097] train: loss: 0.1102455
[Epoch 20] ogbg-molhiv: 0.684698 val loss: 0.371754
[Epoch 20] ogbg-molhiv: 0.716426 test loss: 0.152987
[Epoch 21; Iter    20/ 1097] train: loss: 0.0564757
[Epoch 21; Iter    50/ 1097] train: loss: 0.1955733
[Epoch 21; Iter    80/ 1097] train: loss: 0.0279015
[Epoch 21; Iter   110/ 1097] train: loss: 0.0526909
[Epoch 21; Iter   140/ 1097] train: loss: 0.0704759
[Epoch 21; Iter   170/ 1097] train: loss: 0.0734129
[Epoch 21; Iter   200/ 1097] train: loss: 0.0640339
[Epoch 21; Iter   230/ 1097] train: loss: 0.2096892
[Epoch 21; Iter   260/ 1097] train: loss: 0.0776171
[Epoch 21; Iter   290/ 1097] train: loss: 0.2259144
[Epoch 21; Iter   320/ 1097] train: loss: 0.1906516
[Epoch 21; Iter   350/ 1097] train: loss: 0.0248902
[Epoch 21; Iter   380/ 1097] train: loss: 0.0493186
[Epoch 21; Iter   410/ 1097] train: loss: 0.0624106
[Epoch 21; Iter   440/ 1097] train: loss: 0.1901630
[Epoch 21; Iter   470/ 1097] train: loss: 0.1445931
[Epoch 21; Iter   500/ 1097] train: loss: 0.0277136
[Epoch 21; Iter   530/ 1097] train: loss: 0.0258197
[Epoch 21; Iter   560/ 1097] train: loss: 0.0643296
[Epoch 21; Iter   590/ 1097] train: loss: 0.0909757
[Epoch 21; Iter   620/ 1097] train: loss: 0.0870041
[Epoch 21; Iter   650/ 1097] train: loss: 0.2041037
[Epoch 21; Iter   680/ 1097] train: loss: 0.0803106
[Epoch 21; Iter   710/ 1097] train: loss: 0.0549814
[Epoch 21; Iter   740/ 1097] train: loss: 0.0437257
[Epoch 21; Iter   770/ 1097] train: loss: 0.0701193
[Epoch 21; Iter   800/ 1097] train: loss: 0.0763615
[Epoch 21; Iter   830/ 1097] train: loss: 0.2375615
[Epoch 21; Iter   860/ 1097] train: loss: 0.0599746
[Epoch 21; Iter   890/ 1097] train: loss: 0.0295222
[Epoch 21; Iter   920/ 1097] train: loss: 0.1306261
[Epoch 21; Iter   950/ 1097] train: loss: 0.0327791
[Epoch 21; Iter   980/ 1097] train: loss: 0.0161756
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0188886
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1615586
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0537981
[Epoch 21] ogbg-molhiv: 0.779808 val loss: 0.564057
[Epoch 21] ogbg-molhiv: 0.726096 test loss: 0.227051
[Epoch 22; Iter     3/ 1097] train: loss: 0.1628779
[Epoch 22; Iter    33/ 1097] train: loss: 0.0286718
[Epoch 22; Iter    63/ 1097] train: loss: 0.0360228
[Epoch 22; Iter    93/ 1097] train: loss: 0.0556144
[Epoch 22; Iter   123/ 1097] train: loss: 0.0247318
[Epoch 22; Iter   153/ 1097] train: loss: 0.0104590
[Epoch 22; Iter   183/ 1097] train: loss: 0.0504719
[Epoch 22; Iter   213/ 1097] train: loss: 0.1149054
[Epoch 22; Iter   243/ 1097] train: loss: 0.1066418
[Epoch 22; Iter   273/ 1097] train: loss: 0.1758207
[Epoch 22; Iter   303/ 1097] train: loss: 0.1996867
[Epoch 22; Iter   333/ 1097] train: loss: 0.1699677
[Epoch 22; Iter   363/ 1097] train: loss: 0.2386121
[Epoch 22; Iter   393/ 1097] train: loss: 0.0150550
[Epoch 22; Iter   423/ 1097] train: loss: 0.0252552
[Epoch 22; Iter   453/ 1097] train: loss: 0.0172097
[Epoch 22; Iter   483/ 1097] train: loss: 0.0522823
[Epoch 22; Iter   513/ 1097] train: loss: 0.2944980
[Epoch 22; Iter   543/ 1097] train: loss: 0.1945431
[Epoch 22; Iter   573/ 1097] train: loss: 0.0429112
[Epoch 22; Iter   603/ 1097] train: loss: 0.0164185
[Epoch 22; Iter   633/ 1097] train: loss: 0.0170362
[Epoch 22; Iter   663/ 1097] train: loss: 0.0403845
[Epoch 22; Iter   693/ 1097] train: loss: 0.2372960
[Epoch 22; Iter   723/ 1097] train: loss: 0.1500111
[Epoch 22; Iter   753/ 1097] train: loss: 0.2226918
[Epoch 22; Iter   783/ 1097] train: loss: 0.0537382
[Epoch 22; Iter   813/ 1097] train: loss: 0.1149597
[Epoch 22; Iter   843/ 1097] train: loss: 0.0370189
[Epoch 22; Iter   873/ 1097] train: loss: 0.0581885
[Epoch 22; Iter   903/ 1097] train: loss: 0.0708096
[Epoch 22; Iter   933/ 1097] train: loss: 0.0178654
[Epoch 22; Iter   963/ 1097] train: loss: 0.1737074
[Epoch 22; Iter   993/ 1097] train: loss: 0.0845912
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3879214
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0338340
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1587003
[Epoch 22] ogbg-molhiv: 0.711824 val loss: 0.610304
[Epoch 22] ogbg-molhiv: 0.753106 test loss: 0.207161
[Epoch 23; Iter    16/ 1097] train: loss: 0.0578152
[Epoch 23; Iter    46/ 1097] train: loss: 0.1597684
[Epoch 23; Iter    76/ 1097] train: loss: 0.1101090
[Epoch 23; Iter   106/ 1097] train: loss: 0.2327151
[Epoch 23; Iter   136/ 1097] train: loss: 0.0538526
[Epoch 23; Iter   166/ 1097] train: loss: 0.1673113
[Epoch 23; Iter   196/ 1097] train: loss: 0.0753744
[Epoch 23; Iter   226/ 1097] train: loss: 0.0596258
[Epoch 23; Iter   256/ 1097] train: loss: 0.0762093
[Epoch 23; Iter   286/ 1097] train: loss: 0.0334507
[Epoch 23; Iter   316/ 1097] train: loss: 0.0391852
[Epoch 23; Iter   346/ 1097] train: loss: 0.0382678
[Epoch 23; Iter   376/ 1097] train: loss: 0.0143036
[Epoch 23; Iter   406/ 1097] train: loss: 0.0650236
[Epoch 23; Iter   436/ 1097] train: loss: 0.1468540
[Epoch 23; Iter   466/ 1097] train: loss: 0.0413220
[Epoch 23; Iter   496/ 1097] train: loss: 0.1060203
[Epoch 23; Iter   526/ 1097] train: loss: 0.0464470
[Epoch 23; Iter   556/ 1097] train: loss: 0.1264543
[Epoch 23; Iter   586/ 1097] train: loss: 0.0875045
[Epoch 23; Iter   616/ 1097] train: loss: 0.1223684
[Epoch 23; Iter   646/ 1097] train: loss: 0.1536530
[Epoch 23; Iter   676/ 1097] train: loss: 0.0449234
[Epoch 23; Iter   706/ 1097] train: loss: 0.0311493
[Epoch 23; Iter   736/ 1097] train: loss: 0.1368511
[Epoch 23; Iter   766/ 1097] train: loss: 0.1176989
[Epoch 23; Iter   796/ 1097] train: loss: 0.0210634
[Epoch 23; Iter   826/ 1097] train: loss: 0.2595407
[Epoch 23; Iter   856/ 1097] train: loss: 0.1788985
[Epoch 23; Iter   886/ 1097] train: loss: 0.2012112
[Epoch 23; Iter   916/ 1097] train: loss: 0.3652563
[Epoch 23; Iter   946/ 1097] train: loss: 0.0249539
[Epoch 23; Iter   976/ 1097] train: loss: 0.1058011
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0428473
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0189558
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2123039
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1327568
[Epoch 23] ogbg-molhiv: 0.734228 val loss: 0.852820
[Epoch 23] ogbg-molhiv: 0.733444 test loss: 0.168167
[Epoch 24; Iter    29/ 1097] train: loss: 0.0494389
[Epoch 24; Iter    59/ 1097] train: loss: 0.2277327
[Epoch 24; Iter    89/ 1097] train: loss: 0.1523984
[Epoch 24; Iter   119/ 1097] train: loss: 0.0412336
[Epoch 24; Iter   149/ 1097] train: loss: 0.0719681
[Epoch 24; Iter   179/ 1097] train: loss: 0.0137257
[Epoch 24; Iter   209/ 1097] train: loss: 0.1812275
[Epoch 24; Iter   239/ 1097] train: loss: 0.0180739
[Epoch 24; Iter   269/ 1097] train: loss: 0.1514400
[Epoch 24; Iter   299/ 1097] train: loss: 0.0245216
[Epoch 24; Iter   329/ 1097] train: loss: 0.0314097
[Epoch 20; Iter   277/ 1097] train: loss: 0.2550956
[Epoch 20; Iter   307/ 1097] train: loss: 0.0263187
[Epoch 20; Iter   337/ 1097] train: loss: 0.0782234
[Epoch 20; Iter   367/ 1097] train: loss: 0.0848612
[Epoch 20; Iter   397/ 1097] train: loss: 0.0456056
[Epoch 20; Iter   427/ 1097] train: loss: 0.2859185
[Epoch 20; Iter   457/ 1097] train: loss: 0.0845098
[Epoch 20; Iter   487/ 1097] train: loss: 0.0483783
[Epoch 20; Iter   517/ 1097] train: loss: 0.0372957
[Epoch 20; Iter   547/ 1097] train: loss: 0.0386999
[Epoch 20; Iter   577/ 1097] train: loss: 0.0152857
[Epoch 20; Iter   607/ 1097] train: loss: 0.0321099
[Epoch 20; Iter   637/ 1097] train: loss: 0.2098096
[Epoch 20; Iter   667/ 1097] train: loss: 0.3377091
[Epoch 20; Iter   697/ 1097] train: loss: 0.0234734
[Epoch 20; Iter   727/ 1097] train: loss: 0.0384003
[Epoch 20; Iter   757/ 1097] train: loss: 0.3139077
[Epoch 20; Iter   787/ 1097] train: loss: 0.0209986
[Epoch 20; Iter   817/ 1097] train: loss: 0.0402980
[Epoch 20; Iter   847/ 1097] train: loss: 0.2009279
[Epoch 20; Iter   877/ 1097] train: loss: 0.2563362
[Epoch 20; Iter   907/ 1097] train: loss: 0.0457469
[Epoch 20; Iter   937/ 1097] train: loss: 0.0998931
[Epoch 20; Iter   967/ 1097] train: loss: 0.0814150
[Epoch 20; Iter   997/ 1097] train: loss: 0.0257808
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1051291
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1362033
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0697458
[Epoch 20] ogbg-molhiv: 0.757572 val loss: 0.282817
[Epoch 20] ogbg-molhiv: 0.753502 test loss: 0.258406
[Epoch 21; Iter    20/ 1097] train: loss: 0.0460902
[Epoch 21; Iter    50/ 1097] train: loss: 0.0174739
[Epoch 21; Iter    80/ 1097] train: loss: 0.0326826
[Epoch 21; Iter   110/ 1097] train: loss: 0.0218824
[Epoch 21; Iter   140/ 1097] train: loss: 0.2369105
[Epoch 21; Iter   170/ 1097] train: loss: 0.0893229
[Epoch 21; Iter   200/ 1097] train: loss: 0.0120692
[Epoch 21; Iter   230/ 1097] train: loss: 0.0217274
[Epoch 21; Iter   260/ 1097] train: loss: 0.0232931
[Epoch 21; Iter   290/ 1097] train: loss: 0.0414151
[Epoch 21; Iter   320/ 1097] train: loss: 0.1915417
[Epoch 21; Iter   350/ 1097] train: loss: 0.0962425
[Epoch 21; Iter   380/ 1097] train: loss: 0.0298422
[Epoch 21; Iter   410/ 1097] train: loss: 0.1763590
[Epoch 21; Iter   440/ 1097] train: loss: 0.1632528
[Epoch 21; Iter   470/ 1097] train: loss: 0.0685209
[Epoch 21; Iter   500/ 1097] train: loss: 0.1026117
[Epoch 21; Iter   530/ 1097] train: loss: 0.0524531
[Epoch 21; Iter   560/ 1097] train: loss: 0.1632183
[Epoch 21; Iter   590/ 1097] train: loss: 0.0644012
[Epoch 21; Iter   620/ 1097] train: loss: 0.3229806
[Epoch 21; Iter   650/ 1097] train: loss: 0.0266953
[Epoch 21; Iter   680/ 1097] train: loss: 0.0625179
[Epoch 21; Iter   710/ 1097] train: loss: 0.3352650
[Epoch 21; Iter   740/ 1097] train: loss: 0.1349743
[Epoch 21; Iter   770/ 1097] train: loss: 0.0255155
[Epoch 21; Iter   800/ 1097] train: loss: 0.1251183
[Epoch 21; Iter   830/ 1097] train: loss: 0.4629724
[Epoch 21; Iter   860/ 1097] train: loss: 0.0134656
[Epoch 21; Iter   890/ 1097] train: loss: 0.0390232
[Epoch 21; Iter   920/ 1097] train: loss: 0.1227202
[Epoch 21; Iter   950/ 1097] train: loss: 0.1205523
[Epoch 21; Iter   980/ 1097] train: loss: 0.1502386
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0234793
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1746692
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0200822
[Epoch 21] ogbg-molhiv: 0.749222 val loss: 0.225811
[Epoch 21] ogbg-molhiv: 0.749238 test loss: 0.337323
[Epoch 22; Iter     3/ 1097] train: loss: 0.0421029
[Epoch 22; Iter    33/ 1097] train: loss: 0.0474354
[Epoch 22; Iter    63/ 1097] train: loss: 0.1038414
[Epoch 22; Iter    93/ 1097] train: loss: 0.0237428
[Epoch 22; Iter   123/ 1097] train: loss: 0.0316837
[Epoch 22; Iter   153/ 1097] train: loss: 0.0198918
[Epoch 22; Iter   183/ 1097] train: loss: 0.0370929
[Epoch 22; Iter   213/ 1097] train: loss: 0.0123927
[Epoch 22; Iter   243/ 1097] train: loss: 0.0149073
[Epoch 22; Iter   273/ 1097] train: loss: 0.1706326
[Epoch 22; Iter   303/ 1097] train: loss: 0.0327298
[Epoch 22; Iter   333/ 1097] train: loss: 0.0252823
[Epoch 22; Iter   363/ 1097] train: loss: 0.0462705
[Epoch 22; Iter   393/ 1097] train: loss: 0.0120740
[Epoch 22; Iter   423/ 1097] train: loss: 0.0821116
[Epoch 22; Iter   453/ 1097] train: loss: 0.0410681
[Epoch 22; Iter   483/ 1097] train: loss: 0.0180788
[Epoch 22; Iter   513/ 1097] train: loss: 0.0131441
[Epoch 22; Iter   543/ 1097] train: loss: 0.1131793
[Epoch 22; Iter   573/ 1097] train: loss: 0.0474066
[Epoch 22; Iter   603/ 1097] train: loss: 0.0738391
[Epoch 22; Iter   633/ 1097] train: loss: 0.0150613
[Epoch 22; Iter   663/ 1097] train: loss: 0.0607996
[Epoch 22; Iter   693/ 1097] train: loss: 0.0160476
[Epoch 22; Iter   723/ 1097] train: loss: 0.0126198
[Epoch 22; Iter   753/ 1097] train: loss: 0.0119784
[Epoch 22; Iter   783/ 1097] train: loss: 0.2924518
[Epoch 22; Iter   813/ 1097] train: loss: 0.0665644
[Epoch 22; Iter   843/ 1097] train: loss: 0.1418877
[Epoch 22; Iter   873/ 1097] train: loss: 0.0258796
[Epoch 22; Iter   903/ 1097] train: loss: 0.0567339
[Epoch 22; Iter   933/ 1097] train: loss: 0.0154286
[Epoch 22; Iter   963/ 1097] train: loss: 0.1055948
[Epoch 22; Iter   993/ 1097] train: loss: 0.0354783
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0526099
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0163629
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0358742
[Epoch 22] ogbg-molhiv: 0.749997 val loss: 0.411714
[Epoch 22] ogbg-molhiv: 0.755443 test loss: 0.379305
[Epoch 23; Iter    16/ 1097] train: loss: 0.1263985
[Epoch 23; Iter    46/ 1097] train: loss: 0.0392978
[Epoch 23; Iter    76/ 1097] train: loss: 0.0707251
[Epoch 23; Iter   106/ 1097] train: loss: 0.0183236
[Epoch 23; Iter   136/ 1097] train: loss: 0.0721511
[Epoch 23; Iter   166/ 1097] train: loss: 0.2040803
[Epoch 23; Iter   196/ 1097] train: loss: 0.2031172
[Epoch 23; Iter   226/ 1097] train: loss: 0.0210164
[Epoch 23; Iter   256/ 1097] train: loss: 0.0357478
[Epoch 23; Iter   286/ 1097] train: loss: 0.0822755
[Epoch 23; Iter   316/ 1097] train: loss: 0.0193301
[Epoch 23; Iter   346/ 1097] train: loss: 0.1533315
[Epoch 23; Iter   376/ 1097] train: loss: 0.0391389
[Epoch 23; Iter   406/ 1097] train: loss: 0.0278971
[Epoch 23; Iter   436/ 1097] train: loss: 0.1856370
[Epoch 23; Iter   466/ 1097] train: loss: 0.0404549
[Epoch 23; Iter   496/ 1097] train: loss: 0.0667369
[Epoch 23; Iter   526/ 1097] train: loss: 0.0104964
[Epoch 23; Iter   556/ 1097] train: loss: 0.0636606
[Epoch 23; Iter   586/ 1097] train: loss: 0.0386752
[Epoch 23; Iter   616/ 1097] train: loss: 0.0181247
[Epoch 23; Iter   646/ 1097] train: loss: 0.0272362
[Epoch 23; Iter   676/ 1097] train: loss: 0.1656575
[Epoch 23; Iter   706/ 1097] train: loss: 0.0408970
[Epoch 23; Iter   736/ 1097] train: loss: 0.0454991
[Epoch 23; Iter   766/ 1097] train: loss: 0.0915963
[Epoch 23; Iter   796/ 1097] train: loss: 0.1078077
[Epoch 23; Iter   826/ 1097] train: loss: 0.0159830
[Epoch 23; Iter   856/ 1097] train: loss: 0.0183489
[Epoch 23; Iter   886/ 1097] train: loss: 0.0295088
[Epoch 23; Iter   916/ 1097] train: loss: 0.0176262
[Epoch 23; Iter   946/ 1097] train: loss: 0.0236787
[Epoch 23; Iter   976/ 1097] train: loss: 0.0523626
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1267548
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0428905
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0343596
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0182509
[Epoch 23] ogbg-molhiv: 0.772046 val loss: 0.124015
[Epoch 23] ogbg-molhiv: 0.749702 test loss: 0.204791
[Epoch 24; Iter    29/ 1097] train: loss: 0.0304692
[Epoch 24; Iter    59/ 1097] train: loss: 0.0410727
[Epoch 24; Iter    89/ 1097] train: loss: 0.3484718
[Epoch 24; Iter   119/ 1097] train: loss: 0.0299071
[Epoch 24; Iter   149/ 1097] train: loss: 0.0400012
[Epoch 24; Iter   179/ 1097] train: loss: 0.1027893
[Epoch 24; Iter   209/ 1097] train: loss: 0.0363994
[Epoch 24; Iter   239/ 1097] train: loss: 0.1725949
[Epoch 24; Iter   269/ 1097] train: loss: 0.1070790
[Epoch 24; Iter   299/ 1097] train: loss: 0.0224230
[Epoch 24; Iter   329/ 1097] train: loss: 0.1928872
[Epoch 20; Iter   277/ 1097] train: loss: 0.0292656
[Epoch 20; Iter   307/ 1097] train: loss: 0.1083706
[Epoch 20; Iter   337/ 1097] train: loss: 0.1442959
[Epoch 20; Iter   367/ 1097] train: loss: 0.3038476
[Epoch 20; Iter   397/ 1097] train: loss: 0.0698745
[Epoch 20; Iter   427/ 1097] train: loss: 0.0169929
[Epoch 20; Iter   457/ 1097] train: loss: 0.0321511
[Epoch 20; Iter   487/ 1097] train: loss: 0.1282112
[Epoch 20; Iter   517/ 1097] train: loss: 0.1667678
[Epoch 20; Iter   547/ 1097] train: loss: 0.0840419
[Epoch 20; Iter   577/ 1097] train: loss: 0.0345417
[Epoch 20; Iter   607/ 1097] train: loss: 0.2943380
[Epoch 20; Iter   637/ 1097] train: loss: 0.0751809
[Epoch 20; Iter   667/ 1097] train: loss: 0.1424103
[Epoch 20; Iter   697/ 1097] train: loss: 0.0186590
[Epoch 20; Iter   727/ 1097] train: loss: 0.0888590
[Epoch 20; Iter   757/ 1097] train: loss: 0.1367451
[Epoch 20; Iter   787/ 1097] train: loss: 0.0395691
[Epoch 20; Iter   817/ 1097] train: loss: 0.1075251
[Epoch 20; Iter   847/ 1097] train: loss: 0.0680766
[Epoch 20; Iter   877/ 1097] train: loss: 0.1414607
[Epoch 20; Iter   907/ 1097] train: loss: 0.0507341
[Epoch 20; Iter   937/ 1097] train: loss: 0.0347604
[Epoch 20; Iter   967/ 1097] train: loss: 0.1069776
[Epoch 20; Iter   997/ 1097] train: loss: 0.1517331
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0953091
[Epoch 20; Iter  1057/ 1097] train: loss: 0.2313278
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2271169
[Epoch 20] ogbg-molhiv: 0.719641 val loss: 0.090587
[Epoch 20] ogbg-molhiv: 0.741047 test loss: 0.216449
[Epoch 21; Iter    20/ 1097] train: loss: 0.0701009
[Epoch 21; Iter    50/ 1097] train: loss: 0.2087694
[Epoch 21; Iter    80/ 1097] train: loss: 0.0842966
[Epoch 21; Iter   110/ 1097] train: loss: 0.0542937
[Epoch 21; Iter   140/ 1097] train: loss: 0.1392779
[Epoch 21; Iter   170/ 1097] train: loss: 0.1256661
[Epoch 21; Iter   200/ 1097] train: loss: 0.0322502
[Epoch 21; Iter   230/ 1097] train: loss: 0.0856711
[Epoch 21; Iter   260/ 1097] train: loss: 0.1950986
[Epoch 21; Iter   290/ 1097] train: loss: 0.0316994
[Epoch 21; Iter   320/ 1097] train: loss: 0.0725810
[Epoch 21; Iter   350/ 1097] train: loss: 0.1405299
[Epoch 21; Iter   380/ 1097] train: loss: 0.0193077
[Epoch 21; Iter   410/ 1097] train: loss: 0.1048445
[Epoch 21; Iter   440/ 1097] train: loss: 0.0842594
[Epoch 21; Iter   470/ 1097] train: loss: 0.0439682
[Epoch 21; Iter   500/ 1097] train: loss: 0.0963380
[Epoch 21; Iter   530/ 1097] train: loss: 0.1507424
[Epoch 21; Iter   560/ 1097] train: loss: 0.0425021
[Epoch 21; Iter   590/ 1097] train: loss: 0.0254978
[Epoch 21; Iter   620/ 1097] train: loss: 0.1974659
[Epoch 21; Iter   650/ 1097] train: loss: 0.0369855
[Epoch 21; Iter   680/ 1097] train: loss: 0.0243010
[Epoch 21; Iter   710/ 1097] train: loss: 0.0148100
[Epoch 21; Iter   740/ 1097] train: loss: 0.0573382
[Epoch 21; Iter   770/ 1097] train: loss: 0.1149297
[Epoch 21; Iter   800/ 1097] train: loss: 0.0583829
[Epoch 21; Iter   830/ 1097] train: loss: 0.0597833
[Epoch 21; Iter   860/ 1097] train: loss: 0.0330025
[Epoch 21; Iter   890/ 1097] train: loss: 0.0435804
[Epoch 21; Iter   920/ 1097] train: loss: 0.0880505
[Epoch 21; Iter   950/ 1097] train: loss: 0.1363910
[Epoch 21; Iter   980/ 1097] train: loss: 0.1294454
[Epoch 21; Iter  1010/ 1097] train: loss: 0.2200389
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0246309
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0309124
[Epoch 21] ogbg-molhiv: 0.733123 val loss: 0.095925
[Epoch 21] ogbg-molhiv: 0.772632 test loss: 0.145145
[Epoch 22; Iter     3/ 1097] train: loss: 0.0780861
[Epoch 22; Iter    33/ 1097] train: loss: 0.2120728
[Epoch 22; Iter    63/ 1097] train: loss: 0.1782099
[Epoch 22; Iter    93/ 1097] train: loss: 0.0158152
[Epoch 22; Iter   123/ 1097] train: loss: 0.1448375
[Epoch 22; Iter   153/ 1097] train: loss: 0.1988998
[Epoch 22; Iter   183/ 1097] train: loss: 0.0930980
[Epoch 22; Iter   213/ 1097] train: loss: 0.0361415
[Epoch 22; Iter   243/ 1097] train: loss: 0.0255186
[Epoch 22; Iter   273/ 1097] train: loss: 0.0449988
[Epoch 22; Iter   303/ 1097] train: loss: 0.0567373
[Epoch 22; Iter   333/ 1097] train: loss: 0.1327587
[Epoch 22; Iter   363/ 1097] train: loss: 0.0497444
[Epoch 22; Iter   393/ 1097] train: loss: 0.1251709
[Epoch 22; Iter   423/ 1097] train: loss: 0.0253744
[Epoch 22; Iter   453/ 1097] train: loss: 0.0410696
[Epoch 22; Iter   483/ 1097] train: loss: 0.1793036
[Epoch 22; Iter   513/ 1097] train: loss: 0.0287466
[Epoch 22; Iter   543/ 1097] train: loss: 0.0301122
[Epoch 22; Iter   573/ 1097] train: loss: 0.0347919
[Epoch 22; Iter   603/ 1097] train: loss: 0.0191486
[Epoch 22; Iter   633/ 1097] train: loss: 0.0194027
[Epoch 22; Iter   663/ 1097] train: loss: 0.1071316
[Epoch 22; Iter   693/ 1097] train: loss: 0.0344667
[Epoch 22; Iter   723/ 1097] train: loss: 0.0542004
[Epoch 22; Iter   753/ 1097] train: loss: 0.2716366
[Epoch 22; Iter   783/ 1097] train: loss: 0.0620390
[Epoch 22; Iter   813/ 1097] train: loss: 0.0255675
[Epoch 22; Iter   843/ 1097] train: loss: 0.0188508
[Epoch 22; Iter   873/ 1097] train: loss: 0.0554895
[Epoch 22; Iter   903/ 1097] train: loss: 0.0422292
[Epoch 22; Iter   933/ 1097] train: loss: 0.0246408
[Epoch 22; Iter   963/ 1097] train: loss: 0.2370390
[Epoch 22; Iter   993/ 1097] train: loss: 0.0360852
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0228354
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1016095
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0194701
[Epoch 22] ogbg-molhiv: 0.735676 val loss: 0.097195
[Epoch 22] ogbg-molhiv: 0.739806 test loss: 0.536499
[Epoch 23; Iter    16/ 1097] train: loss: 0.0210665
[Epoch 23; Iter    46/ 1097] train: loss: 0.0471899
[Epoch 23; Iter    76/ 1097] train: loss: 0.0214328
[Epoch 23; Iter   106/ 1097] train: loss: 0.0235386
[Epoch 23; Iter   136/ 1097] train: loss: 0.0984119
[Epoch 23; Iter   166/ 1097] train: loss: 0.0597455
[Epoch 23; Iter   196/ 1097] train: loss: 0.2604162
[Epoch 23; Iter   226/ 1097] train: loss: 0.0317769
[Epoch 23; Iter   256/ 1097] train: loss: 0.0406760
[Epoch 23; Iter   286/ 1097] train: loss: 0.0416234
[Epoch 23; Iter   316/ 1097] train: loss: 0.2918631
[Epoch 23; Iter   346/ 1097] train: loss: 0.1411916
[Epoch 23; Iter   376/ 1097] train: loss: 0.1655682
[Epoch 23; Iter   406/ 1097] train: loss: 0.0231326
[Epoch 23; Iter   436/ 1097] train: loss: 0.1585054
[Epoch 23; Iter   466/ 1097] train: loss: 0.1304689
[Epoch 23; Iter   496/ 1097] train: loss: 0.0405331
[Epoch 23; Iter   526/ 1097] train: loss: 0.0128746
[Epoch 23; Iter   556/ 1097] train: loss: 0.0668598
[Epoch 23; Iter   586/ 1097] train: loss: 0.0335458
[Epoch 23; Iter   616/ 1097] train: loss: 0.0375247
[Epoch 23; Iter   646/ 1097] train: loss: 0.0284900
[Epoch 23; Iter   676/ 1097] train: loss: 0.0313433
[Epoch 23; Iter   706/ 1097] train: loss: 0.0154288
[Epoch 23; Iter   736/ 1097] train: loss: 0.0599958
[Epoch 23; Iter   766/ 1097] train: loss: 0.0250041
[Epoch 23; Iter   796/ 1097] train: loss: 0.2036930
[Epoch 23; Iter   826/ 1097] train: loss: 0.0895698
[Epoch 23; Iter   856/ 1097] train: loss: 0.1415398
[Epoch 23; Iter   886/ 1097] train: loss: 0.0690857
[Epoch 23; Iter   916/ 1097] train: loss: 0.0464798
[Epoch 23; Iter   946/ 1097] train: loss: 0.0593006
[Epoch 23; Iter   976/ 1097] train: loss: 0.0368701
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1737804
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0268827
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0597615
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1398310
[Epoch 23] ogbg-molhiv: 0.727394 val loss: 0.095446
[Epoch 23] ogbg-molhiv: 0.712497 test loss: 0.418304
[Epoch 24; Iter    29/ 1097] train: loss: 0.0183866
[Epoch 24; Iter    59/ 1097] train: loss: 0.0938226
[Epoch 24; Iter    89/ 1097] train: loss: 0.0643805
[Epoch 24; Iter   119/ 1097] train: loss: 0.0155396
[Epoch 24; Iter   149/ 1097] train: loss: 0.1031581
[Epoch 24; Iter   179/ 1097] train: loss: 0.0469138
[Epoch 24; Iter   209/ 1097] train: loss: 0.0151082
[Epoch 24; Iter   239/ 1097] train: loss: 0.0614211
[Epoch 24; Iter   269/ 1097] train: loss: 0.0560464
[Epoch 24; Iter   299/ 1097] train: loss: 0.0602068
[Epoch 24; Iter   329/ 1097] train: loss: 0.0375836
[Epoch 20; Iter   277/ 1097] train: loss: 0.0568073
[Epoch 20; Iter   307/ 1097] train: loss: 0.0620956
[Epoch 20; Iter   337/ 1097] train: loss: 0.0690023
[Epoch 20; Iter   367/ 1097] train: loss: 0.5654048
[Epoch 20; Iter   397/ 1097] train: loss: 0.0978571
[Epoch 20; Iter   427/ 1097] train: loss: 0.0572587
[Epoch 20; Iter   457/ 1097] train: loss: 0.0445536
[Epoch 20; Iter   487/ 1097] train: loss: 0.1238657
[Epoch 20; Iter   517/ 1097] train: loss: 0.0924366
[Epoch 20; Iter   547/ 1097] train: loss: 0.0694417
[Epoch 20; Iter   577/ 1097] train: loss: 0.0744695
[Epoch 20; Iter   607/ 1097] train: loss: 0.2454321
[Epoch 20; Iter   637/ 1097] train: loss: 0.0423235
[Epoch 20; Iter   667/ 1097] train: loss: 0.1021823
[Epoch 20; Iter   697/ 1097] train: loss: 0.0216877
[Epoch 20; Iter   727/ 1097] train: loss: 0.0780729
[Epoch 20; Iter   757/ 1097] train: loss: 0.1694149
[Epoch 20; Iter   787/ 1097] train: loss: 0.1089565
[Epoch 20; Iter   817/ 1097] train: loss: 0.1172631
[Epoch 20; Iter   847/ 1097] train: loss: 0.0384168
[Epoch 20; Iter   877/ 1097] train: loss: 0.1759598
[Epoch 20; Iter   907/ 1097] train: loss: 0.0544899
[Epoch 20; Iter   937/ 1097] train: loss: 0.0698901
[Epoch 20; Iter   967/ 1097] train: loss: 0.0557875
[Epoch 20; Iter   997/ 1097] train: loss: 0.1215267
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0749540
[Epoch 20; Iter  1057/ 1097] train: loss: 0.2980646
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2766839
[Epoch 20] ogbg-molhiv: 0.777839 val loss: 0.283926
[Epoch 20] ogbg-molhiv: 0.764204 test loss: 0.135630
[Epoch 21; Iter    20/ 1097] train: loss: 0.0168930
[Epoch 21; Iter    50/ 1097] train: loss: 0.0401247
[Epoch 21; Iter    80/ 1097] train: loss: 0.0221721
[Epoch 21; Iter   110/ 1097] train: loss: 0.0254179
[Epoch 21; Iter   140/ 1097] train: loss: 0.0423840
[Epoch 21; Iter   170/ 1097] train: loss: 0.0296367
[Epoch 21; Iter   200/ 1097] train: loss: 0.0205770
[Epoch 21; Iter   230/ 1097] train: loss: 0.0431138
[Epoch 21; Iter   260/ 1097] train: loss: 0.1009823
[Epoch 21; Iter   290/ 1097] train: loss: 0.0726093
[Epoch 21; Iter   320/ 1097] train: loss: 0.0177807
[Epoch 21; Iter   350/ 1097] train: loss: 0.0480367
[Epoch 21; Iter   380/ 1097] train: loss: 0.0278650
[Epoch 21; Iter   410/ 1097] train: loss: 0.0562356
[Epoch 21; Iter   440/ 1097] train: loss: 0.1607325
[Epoch 21; Iter   470/ 1097] train: loss: 0.1412001
[Epoch 21; Iter   500/ 1097] train: loss: 0.1771733
[Epoch 21; Iter   530/ 1097] train: loss: 0.0709068
[Epoch 21; Iter   560/ 1097] train: loss: 0.0429652
[Epoch 21; Iter   590/ 1097] train: loss: 0.0191554
[Epoch 21; Iter   620/ 1097] train: loss: 0.1501325
[Epoch 21; Iter   650/ 1097] train: loss: 0.0286539
[Epoch 21; Iter   680/ 1097] train: loss: 0.0355784
[Epoch 21; Iter   710/ 1097] train: loss: 0.0180233
[Epoch 21; Iter   740/ 1097] train: loss: 0.0503430
[Epoch 21; Iter   770/ 1097] train: loss: 0.1265464
[Epoch 21; Iter   800/ 1097] train: loss: 0.1613218
[Epoch 21; Iter   830/ 1097] train: loss: 0.0291664
[Epoch 21; Iter   860/ 1097] train: loss: 0.0174947
[Epoch 21; Iter   890/ 1097] train: loss: 0.0415668
[Epoch 21; Iter   920/ 1097] train: loss: 0.0987876
[Epoch 21; Iter   950/ 1097] train: loss: 0.0484319
[Epoch 21; Iter   980/ 1097] train: loss: 0.1894064
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1362807
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0194386
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0201506
[Epoch 21] ogbg-molhiv: 0.767082 val loss: 0.322684
[Epoch 21] ogbg-molhiv: 0.741324 test loss: 0.138491
[Epoch 22; Iter     3/ 1097] train: loss: 0.0493804
[Epoch 22; Iter    33/ 1097] train: loss: 0.2448286
[Epoch 22; Iter    63/ 1097] train: loss: 0.1478388
[Epoch 22; Iter    93/ 1097] train: loss: 0.0141249
[Epoch 22; Iter   123/ 1097] train: loss: 0.1166762
[Epoch 22; Iter   153/ 1097] train: loss: 0.1574388
[Epoch 22; Iter   183/ 1097] train: loss: 0.2205194
[Epoch 22; Iter   213/ 1097] train: loss: 0.0760568
[Epoch 22; Iter   243/ 1097] train: loss: 0.0227398
[Epoch 22; Iter   273/ 1097] train: loss: 0.0557286
[Epoch 22; Iter   303/ 1097] train: loss: 0.0587715
[Epoch 22; Iter   333/ 1097] train: loss: 0.0890928
[Epoch 22; Iter   363/ 1097] train: loss: 0.0242607
[Epoch 22; Iter   393/ 1097] train: loss: 0.0939834
[Epoch 22; Iter   423/ 1097] train: loss: 0.0394247
[Epoch 22; Iter   453/ 1097] train: loss: 0.0628230
[Epoch 22; Iter   483/ 1097] train: loss: 0.1466126
[Epoch 22; Iter   513/ 1097] train: loss: 0.1127284
[Epoch 22; Iter   543/ 1097] train: loss: 0.0384027
[Epoch 22; Iter   573/ 1097] train: loss: 0.1135085
[Epoch 22; Iter   603/ 1097] train: loss: 0.0225698
[Epoch 22; Iter   633/ 1097] train: loss: 0.0284680
[Epoch 22; Iter   663/ 1097] train: loss: 0.0380309
[Epoch 22; Iter   693/ 1097] train: loss: 0.0500627
[Epoch 22; Iter   723/ 1097] train: loss: 0.0205917
[Epoch 22; Iter   753/ 1097] train: loss: 0.1871587
[Epoch 22; Iter   783/ 1097] train: loss: 0.1810717
[Epoch 22; Iter   813/ 1097] train: loss: 0.0132631
[Epoch 22; Iter   843/ 1097] train: loss: 0.0543928
[Epoch 22; Iter   873/ 1097] train: loss: 0.1820252
[Epoch 22; Iter   903/ 1097] train: loss: 0.0193313
[Epoch 22; Iter   933/ 1097] train: loss: 0.0155814
[Epoch 22; Iter   963/ 1097] train: loss: 0.2866395
[Epoch 22; Iter   993/ 1097] train: loss: 0.0489939
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0532771
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1223229
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0318756
[Epoch 22] ogbg-molhiv: 0.738245 val loss: 0.107141
[Epoch 22] ogbg-molhiv: 0.746306 test loss: 0.130738
[Epoch 23; Iter    16/ 1097] train: loss: 0.0211196
[Epoch 23; Iter    46/ 1097] train: loss: 0.0526606
[Epoch 23; Iter    76/ 1097] train: loss: 0.0218613
[Epoch 23; Iter   106/ 1097] train: loss: 0.0298905
[Epoch 23; Iter   136/ 1097] train: loss: 0.1230804
[Epoch 23; Iter   166/ 1097] train: loss: 0.0779753
[Epoch 23; Iter   196/ 1097] train: loss: 0.2089798
[Epoch 23; Iter   226/ 1097] train: loss: 0.0636997
[Epoch 23; Iter   256/ 1097] train: loss: 0.0355088
[Epoch 23; Iter   286/ 1097] train: loss: 0.0332779
[Epoch 23; Iter   316/ 1097] train: loss: 0.2163807
[Epoch 23; Iter   346/ 1097] train: loss: 0.0818563
[Epoch 23; Iter   376/ 1097] train: loss: 0.1959589
[Epoch 23; Iter   406/ 1097] train: loss: 0.0135415
[Epoch 23; Iter   436/ 1097] train: loss: 0.1415697
[Epoch 23; Iter   466/ 1097] train: loss: 0.0324540
[Epoch 23; Iter   496/ 1097] train: loss: 0.0939121
[Epoch 23; Iter   526/ 1097] train: loss: 0.0383798
[Epoch 23; Iter   556/ 1097] train: loss: 0.1002924
[Epoch 23; Iter   586/ 1097] train: loss: 0.0130088
[Epoch 23; Iter   616/ 1097] train: loss: 0.0227667
[Epoch 23; Iter   646/ 1097] train: loss: 0.0266017
[Epoch 23; Iter   676/ 1097] train: loss: 0.0377365
[Epoch 23; Iter   706/ 1097] train: loss: 0.0281471
[Epoch 23; Iter   736/ 1097] train: loss: 0.0419491
[Epoch 23; Iter   766/ 1097] train: loss: 0.0208655
[Epoch 23; Iter   796/ 1097] train: loss: 0.1470569
[Epoch 23; Iter   826/ 1097] train: loss: 0.0327485
[Epoch 23; Iter   856/ 1097] train: loss: 0.1502692
[Epoch 23; Iter   886/ 1097] train: loss: 0.1664298
[Epoch 23; Iter   916/ 1097] train: loss: 0.0284268
[Epoch 23; Iter   946/ 1097] train: loss: 0.2453928
[Epoch 23; Iter   976/ 1097] train: loss: 0.0261496
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1655475
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0824327
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1188918
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0764241
[Epoch 23] ogbg-molhiv: 0.760117 val loss: 0.078671
[Epoch 23] ogbg-molhiv: 0.719323 test loss: 0.140827
[Epoch 24; Iter    29/ 1097] train: loss: 0.0115148
[Epoch 24; Iter    59/ 1097] train: loss: 0.0461818
[Epoch 24; Iter    89/ 1097] train: loss: 0.0143356
[Epoch 24; Iter   119/ 1097] train: loss: 0.1331584
[Epoch 24; Iter   149/ 1097] train: loss: 0.1654975
[Epoch 24; Iter   179/ 1097] train: loss: 0.0452759
[Epoch 24; Iter   209/ 1097] train: loss: 0.0156859
[Epoch 24; Iter   239/ 1097] train: loss: 0.0131226
[Epoch 24; Iter   269/ 1097] train: loss: 0.0510163
[Epoch 24; Iter   299/ 1097] train: loss: 0.1240128
[Epoch 24; Iter   329/ 1097] train: loss: 0.0253430
[Epoch 20; Iter   277/ 1097] train: loss: 0.1502385
[Epoch 20; Iter   307/ 1097] train: loss: 0.0414986
[Epoch 20; Iter   337/ 1097] train: loss: 0.1457340
[Epoch 20; Iter   367/ 1097] train: loss: 0.0292774
[Epoch 20; Iter   397/ 1097] train: loss: 0.0419858
[Epoch 20; Iter   427/ 1097] train: loss: 0.4469024
[Epoch 20; Iter   457/ 1097] train: loss: 0.1703072
[Epoch 20; Iter   487/ 1097] train: loss: 0.0839347
[Epoch 20; Iter   517/ 1097] train: loss: 0.0549996
[Epoch 20; Iter   547/ 1097] train: loss: 0.0297249
[Epoch 20; Iter   577/ 1097] train: loss: 0.0373982
[Epoch 20; Iter   607/ 1097] train: loss: 0.0160685
[Epoch 20; Iter   637/ 1097] train: loss: 0.0561044
[Epoch 20; Iter   667/ 1097] train: loss: 0.4872790
[Epoch 20; Iter   697/ 1097] train: loss: 0.0194541
[Epoch 20; Iter   727/ 1097] train: loss: 0.0254932
[Epoch 20; Iter   757/ 1097] train: loss: 0.1126333
[Epoch 20; Iter   787/ 1097] train: loss: 0.0191935
[Epoch 20; Iter   817/ 1097] train: loss: 0.0170650
[Epoch 20; Iter   847/ 1097] train: loss: 0.2430954
[Epoch 20; Iter   877/ 1097] train: loss: 0.1107830
[Epoch 20; Iter   907/ 1097] train: loss: 0.0451234
[Epoch 20; Iter   937/ 1097] train: loss: 0.0655144
[Epoch 20; Iter   967/ 1097] train: loss: 0.1092006
[Epoch 20; Iter   997/ 1097] train: loss: 0.0381430
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0689984
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0833044
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0218723
[Epoch 20] ogbg-molhiv: 0.757039 val loss: 0.244846
[Epoch 20] ogbg-molhiv: 0.724355 test loss: 0.133825
[Epoch 21; Iter    20/ 1097] train: loss: 0.0448402
[Epoch 21; Iter    50/ 1097] train: loss: 0.0640356
[Epoch 21; Iter    80/ 1097] train: loss: 0.0348035
[Epoch 21; Iter   110/ 1097] train: loss: 0.0440724
[Epoch 21; Iter   140/ 1097] train: loss: 0.2008573
[Epoch 21; Iter   170/ 1097] train: loss: 0.1950741
[Epoch 21; Iter   200/ 1097] train: loss: 0.0265536
[Epoch 21; Iter   230/ 1097] train: loss: 0.0316183
[Epoch 21; Iter   260/ 1097] train: loss: 0.0371894
[Epoch 21; Iter   290/ 1097] train: loss: 0.0580102
[Epoch 21; Iter   320/ 1097] train: loss: 0.0892413
[Epoch 21; Iter   350/ 1097] train: loss: 0.1549606
[Epoch 21; Iter   380/ 1097] train: loss: 0.0175645
[Epoch 21; Iter   410/ 1097] train: loss: 0.1971954
[Epoch 21; Iter   440/ 1097] train: loss: 0.1630361
[Epoch 21; Iter   470/ 1097] train: loss: 0.1198345
[Epoch 21; Iter   500/ 1097] train: loss: 0.1674777
[Epoch 21; Iter   530/ 1097] train: loss: 0.0361439
[Epoch 21; Iter   560/ 1097] train: loss: 0.1213239
[Epoch 21; Iter   590/ 1097] train: loss: 0.1510743
[Epoch 21; Iter   620/ 1097] train: loss: 0.2388806
[Epoch 21; Iter   650/ 1097] train: loss: 0.0256388
[Epoch 21; Iter   680/ 1097] train: loss: 0.0428579
[Epoch 21; Iter   710/ 1097] train: loss: 0.2169080
[Epoch 21; Iter   740/ 1097] train: loss: 0.1193348
[Epoch 21; Iter   770/ 1097] train: loss: 0.0222164
[Epoch 21; Iter   800/ 1097] train: loss: 0.2374048
[Epoch 21; Iter   830/ 1097] train: loss: 0.4329718
[Epoch 21; Iter   860/ 1097] train: loss: 0.0267134
[Epoch 21; Iter   890/ 1097] train: loss: 0.0361663
[Epoch 21; Iter   920/ 1097] train: loss: 0.1530530
[Epoch 21; Iter   950/ 1097] train: loss: 0.1569069
[Epoch 21; Iter   980/ 1097] train: loss: 0.1531695
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0395244
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2487326
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0197138
[Epoch 21] ogbg-molhiv: 0.740680 val loss: 0.609721
[Epoch 21] ogbg-molhiv: 0.688930 test loss: 0.379984
[Epoch 22; Iter     3/ 1097] train: loss: 0.0311604
[Epoch 22; Iter    33/ 1097] train: loss: 0.0513488
[Epoch 22; Iter    63/ 1097] train: loss: 0.1663100
[Epoch 22; Iter    93/ 1097] train: loss: 0.0404941
[Epoch 22; Iter   123/ 1097] train: loss: 0.0191024
[Epoch 22; Iter   153/ 1097] train: loss: 0.0262625
[Epoch 22; Iter   183/ 1097] train: loss: 0.0232996
[Epoch 22; Iter   213/ 1097] train: loss: 0.0319197
[Epoch 22; Iter   243/ 1097] train: loss: 0.0220403
[Epoch 22; Iter   273/ 1097] train: loss: 0.1187308
[Epoch 22; Iter   303/ 1097] train: loss: 0.0270480
[Epoch 22; Iter   333/ 1097] train: loss: 0.0142174
[Epoch 22; Iter   363/ 1097] train: loss: 0.0172460
[Epoch 22; Iter   393/ 1097] train: loss: 0.0139328
[Epoch 22; Iter   423/ 1097] train: loss: 0.0676421
[Epoch 22; Iter   453/ 1097] train: loss: 0.0656689
[Epoch 22; Iter   483/ 1097] train: loss: 0.0279581
[Epoch 22; Iter   513/ 1097] train: loss: 0.0240012
[Epoch 22; Iter   543/ 1097] train: loss: 0.1031926
[Epoch 22; Iter   573/ 1097] train: loss: 0.0559013
[Epoch 22; Iter   603/ 1097] train: loss: 0.0318933
[Epoch 22; Iter   633/ 1097] train: loss: 0.0192869
[Epoch 22; Iter   663/ 1097] train: loss: 0.0586556
[Epoch 22; Iter   693/ 1097] train: loss: 0.0224522
[Epoch 22; Iter   723/ 1097] train: loss: 0.0273201
[Epoch 22; Iter   753/ 1097] train: loss: 0.0409322
[Epoch 22; Iter   783/ 1097] train: loss: 0.2323243
[Epoch 22; Iter   813/ 1097] train: loss: 0.0425224
[Epoch 22; Iter   843/ 1097] train: loss: 0.1733339
[Epoch 22; Iter   873/ 1097] train: loss: 0.1080671
[Epoch 22; Iter   903/ 1097] train: loss: 0.0299065
[Epoch 22; Iter   933/ 1097] train: loss: 0.0356062
[Epoch 22; Iter   963/ 1097] train: loss: 0.1644973
[Epoch 22; Iter   993/ 1097] train: loss: 0.0319086
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0419140
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0469933
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0260802
[Epoch 22] ogbg-molhiv: 0.781556 val loss: 4.125459
[Epoch 22] ogbg-molhiv: 0.729199 test loss: 1.741302
[Epoch 23; Iter    16/ 1097] train: loss: 0.1194722
[Epoch 23; Iter    46/ 1097] train: loss: 0.0311664
[Epoch 23; Iter    76/ 1097] train: loss: 0.0424175
[Epoch 23; Iter   106/ 1097] train: loss: 0.0187071
[Epoch 23; Iter   136/ 1097] train: loss: 0.0611884
[Epoch 23; Iter   166/ 1097] train: loss: 0.1071512
[Epoch 23; Iter   196/ 1097] train: loss: 0.1989919
[Epoch 23; Iter   226/ 1097] train: loss: 0.1048322
[Epoch 23; Iter   256/ 1097] train: loss: 0.0246037
[Epoch 23; Iter   286/ 1097] train: loss: 0.0823926
[Epoch 23; Iter   316/ 1097] train: loss: 0.0131051
[Epoch 23; Iter   346/ 1097] train: loss: 0.1012639
[Epoch 23; Iter   376/ 1097] train: loss: 0.0383514
[Epoch 23; Iter   406/ 1097] train: loss: 0.0273793
[Epoch 23; Iter   436/ 1097] train: loss: 0.1072631
[Epoch 23; Iter   466/ 1097] train: loss: 0.0234344
[Epoch 23; Iter   496/ 1097] train: loss: 0.0554513
[Epoch 23; Iter   526/ 1097] train: loss: 0.0438377
[Epoch 23; Iter   556/ 1097] train: loss: 0.0519862
[Epoch 23; Iter   586/ 1097] train: loss: 0.0422824
[Epoch 23; Iter   616/ 1097] train: loss: 0.0171297
[Epoch 23; Iter   646/ 1097] train: loss: 0.0590974
[Epoch 23; Iter   676/ 1097] train: loss: 0.3209202
[Epoch 23; Iter   706/ 1097] train: loss: 0.0242250
[Epoch 23; Iter   736/ 1097] train: loss: 0.0244695
[Epoch 23; Iter   766/ 1097] train: loss: 0.3791932
[Epoch 23; Iter   796/ 1097] train: loss: 0.1076490
[Epoch 23; Iter   826/ 1097] train: loss: 0.0977680
[Epoch 23; Iter   856/ 1097] train: loss: 0.0184046
[Epoch 23; Iter   886/ 1097] train: loss: 0.0547003
[Epoch 23; Iter   916/ 1097] train: loss: 0.0182890
[Epoch 23; Iter   946/ 1097] train: loss: 0.0153075
[Epoch 23; Iter   976/ 1097] train: loss: 0.1161215
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1139025
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0523066
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0248052
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0338561
[Epoch 23] ogbg-molhiv: 0.730165 val loss: 2.691200
[Epoch 23] ogbg-molhiv: 0.659082 test loss: 1.264146
[Epoch 24; Iter    29/ 1097] train: loss: 0.0325420
[Epoch 24; Iter    59/ 1097] train: loss: 0.0507941
[Epoch 24; Iter    89/ 1097] train: loss: 0.1984781
[Epoch 24; Iter   119/ 1097] train: loss: 0.0715229
[Epoch 24; Iter   149/ 1097] train: loss: 0.1408789
[Epoch 24; Iter   179/ 1097] train: loss: 0.2190285
[Epoch 24; Iter   209/ 1097] train: loss: 0.0426343
[Epoch 24; Iter   239/ 1097] train: loss: 0.3862945
[Epoch 24; Iter   269/ 1097] train: loss: 0.1044946
[Epoch 24; Iter   299/ 1097] train: loss: 0.0516139
[Epoch 24; Iter   329/ 1097] train: loss: 0.4552439
[Epoch 20; Iter   277/ 1097] train: loss: 0.2217371
[Epoch 20; Iter   307/ 1097] train: loss: 0.2133238
[Epoch 20; Iter   337/ 1097] train: loss: 0.0596827
[Epoch 20; Iter   367/ 1097] train: loss: 0.0678229
[Epoch 20; Iter   397/ 1097] train: loss: 0.0159509
[Epoch 20; Iter   427/ 1097] train: loss: 0.0314694
[Epoch 20; Iter   457/ 1097] train: loss: 0.0920403
[Epoch 20; Iter   487/ 1097] train: loss: 0.2395090
[Epoch 20; Iter   517/ 1097] train: loss: 0.0321061
[Epoch 20; Iter   547/ 1097] train: loss: 0.1055596
[Epoch 20; Iter   577/ 1097] train: loss: 0.0221055
[Epoch 20; Iter   607/ 1097] train: loss: 0.0263647
[Epoch 20; Iter   637/ 1097] train: loss: 0.0594437
[Epoch 20; Iter   667/ 1097] train: loss: 0.2353546
[Epoch 20; Iter   697/ 1097] train: loss: 0.0993618
[Epoch 20; Iter   727/ 1097] train: loss: 0.1880350
[Epoch 20; Iter   757/ 1097] train: loss: 0.0205258
[Epoch 20; Iter   787/ 1097] train: loss: 0.0373965
[Epoch 20; Iter   817/ 1097] train: loss: 0.1051641
[Epoch 20; Iter   847/ 1097] train: loss: 0.0467851
[Epoch 20; Iter   877/ 1097] train: loss: 0.0756566
[Epoch 20; Iter   907/ 1097] train: loss: 0.2993332
[Epoch 20; Iter   937/ 1097] train: loss: 0.0230649
[Epoch 20; Iter   967/ 1097] train: loss: 0.1327469
[Epoch 20; Iter   997/ 1097] train: loss: 0.1698653
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0340660
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0978982
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0401356
[Epoch 20] ogbg-molhiv: 0.756932 val loss: 0.138731
[Epoch 20] ogbg-molhiv: 0.765262 test loss: 0.137700
[Epoch 21; Iter    20/ 1097] train: loss: 0.0233063
[Epoch 21; Iter    50/ 1097] train: loss: 0.1266693
[Epoch 21; Iter    80/ 1097] train: loss: 0.0149386
[Epoch 21; Iter   110/ 1097] train: loss: 0.0335725
[Epoch 21; Iter   140/ 1097] train: loss: 0.0829003
[Epoch 21; Iter   170/ 1097] train: loss: 0.1623863
[Epoch 21; Iter   200/ 1097] train: loss: 0.1569469
[Epoch 21; Iter   230/ 1097] train: loss: 0.1385216
[Epoch 21; Iter   260/ 1097] train: loss: 0.2188349
[Epoch 21; Iter   290/ 1097] train: loss: 0.1444303
[Epoch 21; Iter   320/ 1097] train: loss: 0.1598726
[Epoch 21; Iter   350/ 1097] train: loss: 0.0191966
[Epoch 21; Iter   380/ 1097] train: loss: 0.0394768
[Epoch 21; Iter   410/ 1097] train: loss: 0.0766227
[Epoch 21; Iter   440/ 1097] train: loss: 0.1632916
[Epoch 21; Iter   470/ 1097] train: loss: 0.1980266
[Epoch 21; Iter   500/ 1097] train: loss: 0.0187894
[Epoch 21; Iter   530/ 1097] train: loss: 0.0308592
[Epoch 21; Iter   560/ 1097] train: loss: 0.0378300
[Epoch 21; Iter   590/ 1097] train: loss: 0.0683515
[Epoch 21; Iter   620/ 1097] train: loss: 0.0311296
[Epoch 21; Iter   650/ 1097] train: loss: 0.2670120
[Epoch 21; Iter   680/ 1097] train: loss: 0.0883221
[Epoch 21; Iter   710/ 1097] train: loss: 0.0363957
[Epoch 21; Iter   740/ 1097] train: loss: 0.0332431
[Epoch 21; Iter   770/ 1097] train: loss: 0.0427863
[Epoch 21; Iter   800/ 1097] train: loss: 0.0754225
[Epoch 21; Iter   830/ 1097] train: loss: 0.1847115
[Epoch 21; Iter   860/ 1097] train: loss: 0.0639460
[Epoch 21; Iter   890/ 1097] train: loss: 0.0179442
[Epoch 21; Iter   920/ 1097] train: loss: 0.1609371
[Epoch 21; Iter   950/ 1097] train: loss: 0.0430584
[Epoch 21; Iter   980/ 1097] train: loss: 0.0141242
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0186662
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1036117
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0403403
[Epoch 21] ogbg-molhiv: 0.778914 val loss: 1.600790
[Epoch 21] ogbg-molhiv: 0.760822 test loss: 0.399154
[Epoch 22; Iter     3/ 1097] train: loss: 0.1284504
[Epoch 22; Iter    33/ 1097] train: loss: 0.0858532
[Epoch 22; Iter    63/ 1097] train: loss: 0.0259832
[Epoch 22; Iter    93/ 1097] train: loss: 0.0262229
[Epoch 22; Iter   123/ 1097] train: loss: 0.0318790
[Epoch 22; Iter   153/ 1097] train: loss: 0.0270279
[Epoch 22; Iter   183/ 1097] train: loss: 0.0346444
[Epoch 22; Iter   213/ 1097] train: loss: 0.1352854
[Epoch 22; Iter   243/ 1097] train: loss: 0.0844571
[Epoch 22; Iter   273/ 1097] train: loss: 0.0781094
[Epoch 22; Iter   303/ 1097] train: loss: 0.1420743
[Epoch 22; Iter   333/ 1097] train: loss: 0.0321312
[Epoch 22; Iter   363/ 1097] train: loss: 0.1740656
[Epoch 22; Iter   393/ 1097] train: loss: 0.0417486
[Epoch 22; Iter   423/ 1097] train: loss: 0.0196985
[Epoch 22; Iter   453/ 1097] train: loss: 0.0220022
[Epoch 22; Iter   483/ 1097] train: loss: 0.0269614
[Epoch 22; Iter   513/ 1097] train: loss: 0.2863157
[Epoch 22; Iter   543/ 1097] train: loss: 0.1553589
[Epoch 22; Iter   573/ 1097] train: loss: 0.0266829
[Epoch 22; Iter   603/ 1097] train: loss: 0.0257838
[Epoch 22; Iter   633/ 1097] train: loss: 0.0185397
[Epoch 22; Iter   663/ 1097] train: loss: 0.0447851
[Epoch 22; Iter   693/ 1097] train: loss: 0.1083919
[Epoch 22; Iter   723/ 1097] train: loss: 0.1605821
[Epoch 22; Iter   753/ 1097] train: loss: 0.2249666
[Epoch 22; Iter   783/ 1097] train: loss: 0.0662717
[Epoch 22; Iter   813/ 1097] train: loss: 0.1062753
[Epoch 22; Iter   843/ 1097] train: loss: 0.0302849
[Epoch 22; Iter   873/ 1097] train: loss: 0.0415674
[Epoch 22; Iter   903/ 1097] train: loss: 0.1798658
[Epoch 22; Iter   933/ 1097] train: loss: 0.0159062
[Epoch 22; Iter   963/ 1097] train: loss: 0.2049328
[Epoch 22; Iter   993/ 1097] train: loss: 0.1222063
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3614836
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0259480
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0397512
[Epoch 22] ogbg-molhiv: 0.758279 val loss: 0.825530
[Epoch 22] ogbg-molhiv: 0.779237 test loss: 0.248515
[Epoch 23; Iter    16/ 1097] train: loss: 0.0638192
[Epoch 23; Iter    46/ 1097] train: loss: 0.2488179
[Epoch 23; Iter    76/ 1097] train: loss: 0.0400739
[Epoch 23; Iter   106/ 1097] train: loss: 0.2496917
[Epoch 23; Iter   136/ 1097] train: loss: 0.0883149
[Epoch 23; Iter   166/ 1097] train: loss: 0.2317176
[Epoch 23; Iter   196/ 1097] train: loss: 0.0864385
[Epoch 23; Iter   226/ 1097] train: loss: 0.1426238
[Epoch 23; Iter   256/ 1097] train: loss: 0.1178508
[Epoch 23; Iter   286/ 1097] train: loss: 0.0156892
[Epoch 23; Iter   316/ 1097] train: loss: 0.0368269
[Epoch 23; Iter   346/ 1097] train: loss: 0.0189060
[Epoch 23; Iter   376/ 1097] train: loss: 0.0121678
[Epoch 23; Iter   406/ 1097] train: loss: 0.1050453
[Epoch 23; Iter   436/ 1097] train: loss: 0.0196035
[Epoch 23; Iter   466/ 1097] train: loss: 0.0111011
[Epoch 23; Iter   496/ 1097] train: loss: 0.2032459
[Epoch 23; Iter   526/ 1097] train: loss: 0.0747772
[Epoch 23; Iter   556/ 1097] train: loss: 0.0342200
[Epoch 23; Iter   586/ 1097] train: loss: 0.1368970
[Epoch 23; Iter   616/ 1097] train: loss: 0.1634481
[Epoch 23; Iter   646/ 1097] train: loss: 0.0769612
[Epoch 23; Iter   676/ 1097] train: loss: 0.0795588
[Epoch 23; Iter   706/ 1097] train: loss: 0.0918083
[Epoch 23; Iter   736/ 1097] train: loss: 0.2231343
[Epoch 23; Iter   766/ 1097] train: loss: 0.0470625
[Epoch 23; Iter   796/ 1097] train: loss: 0.0284996
[Epoch 23; Iter   826/ 1097] train: loss: 0.1531985
[Epoch 23; Iter   856/ 1097] train: loss: 0.2911718
[Epoch 23; Iter   886/ 1097] train: loss: 0.1102963
[Epoch 23; Iter   916/ 1097] train: loss: 0.2965092
[Epoch 23; Iter   946/ 1097] train: loss: 0.0250020
[Epoch 23; Iter   976/ 1097] train: loss: 0.1036026
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0198073
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0479543
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2299375
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0716661
[Epoch 23] ogbg-molhiv: 0.793856 val loss: 0.575073
[Epoch 23] ogbg-molhiv: 0.773340 test loss: 0.138396
[Epoch 24; Iter    29/ 1097] train: loss: 0.0149142
[Epoch 24; Iter    59/ 1097] train: loss: 0.2504549
[Epoch 24; Iter    89/ 1097] train: loss: 0.1891051
[Epoch 24; Iter   119/ 1097] train: loss: 0.0435158
[Epoch 24; Iter   149/ 1097] train: loss: 0.0236331
[Epoch 24; Iter   179/ 1097] train: loss: 0.0248955
[Epoch 24; Iter   209/ 1097] train: loss: 0.1243211
[Epoch 24; Iter   239/ 1097] train: loss: 0.0110666
[Epoch 24; Iter   269/ 1097] train: loss: 0.3882425
[Epoch 24; Iter   299/ 1097] train: loss: 0.0791158
[Epoch 24; Iter   329/ 1097] train: loss: 0.0811777
[Epoch 20; Iter   277/ 1097] train: loss: 0.0264568
[Epoch 20; Iter   307/ 1097] train: loss: 0.0696380
[Epoch 20; Iter   337/ 1097] train: loss: 0.1458367
[Epoch 20; Iter   367/ 1097] train: loss: 0.4540789
[Epoch 20; Iter   397/ 1097] train: loss: 0.0349635
[Epoch 20; Iter   427/ 1097] train: loss: 0.0329969
[Epoch 20; Iter   457/ 1097] train: loss: 0.0176794
[Epoch 20; Iter   487/ 1097] train: loss: 0.0489942
[Epoch 20; Iter   517/ 1097] train: loss: 0.0769508
[Epoch 20; Iter   547/ 1097] train: loss: 0.2338576
[Epoch 20; Iter   577/ 1097] train: loss: 0.0542347
[Epoch 20; Iter   607/ 1097] train: loss: 0.1818687
[Epoch 20; Iter   637/ 1097] train: loss: 0.0308100
[Epoch 20; Iter   667/ 1097] train: loss: 0.0631629
[Epoch 20; Iter   697/ 1097] train: loss: 0.0559135
[Epoch 20; Iter   727/ 1097] train: loss: 0.1874465
[Epoch 20; Iter   757/ 1097] train: loss: 0.0845180
[Epoch 20; Iter   787/ 1097] train: loss: 0.0306548
[Epoch 20; Iter   817/ 1097] train: loss: 0.1199493
[Epoch 20; Iter   847/ 1097] train: loss: 0.0678575
[Epoch 20; Iter   877/ 1097] train: loss: 0.1391121
[Epoch 20; Iter   907/ 1097] train: loss: 0.0574039
[Epoch 20; Iter   937/ 1097] train: loss: 0.0194902
[Epoch 20; Iter   967/ 1097] train: loss: 0.0541943
[Epoch 20; Iter   997/ 1097] train: loss: 0.0657265
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1453868
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4061785
[Epoch 20; Iter  1087/ 1097] train: loss: 0.1947447
[Epoch 20] ogbg-molhiv: 0.728524 val loss: 0.099443
[Epoch 20] ogbg-molhiv: 0.656330 test loss: 0.226370
[Epoch 21; Iter    20/ 1097] train: loss: 0.0272778
[Epoch 21; Iter    50/ 1097] train: loss: 0.1594812
[Epoch 21; Iter    80/ 1097] train: loss: 0.0666983
[Epoch 21; Iter   110/ 1097] train: loss: 0.0309788
[Epoch 21; Iter   140/ 1097] train: loss: 0.2285981
[Epoch 21; Iter   170/ 1097] train: loss: 0.1488567
[Epoch 21; Iter   200/ 1097] train: loss: 0.0180616
[Epoch 21; Iter   230/ 1097] train: loss: 0.0251273
[Epoch 21; Iter   260/ 1097] train: loss: 0.0236098
[Epoch 21; Iter   290/ 1097] train: loss: 0.0645590
[Epoch 21; Iter   320/ 1097] train: loss: 0.0382145
[Epoch 21; Iter   350/ 1097] train: loss: 0.1194856
[Epoch 21; Iter   380/ 1097] train: loss: 0.0114620
[Epoch 21; Iter   410/ 1097] train: loss: 0.0146432
[Epoch 21; Iter   440/ 1097] train: loss: 0.2115265
[Epoch 21; Iter   470/ 1097] train: loss: 0.0546942
[Epoch 21; Iter   500/ 1097] train: loss: 0.0718560
[Epoch 21; Iter   530/ 1097] train: loss: 0.0436965
[Epoch 21; Iter   560/ 1097] train: loss: 0.0704430
[Epoch 21; Iter   590/ 1097] train: loss: 0.0495190
[Epoch 21; Iter   620/ 1097] train: loss: 0.0210188
[Epoch 21; Iter   650/ 1097] train: loss: 0.0207126
[Epoch 21; Iter   680/ 1097] train: loss: 0.0163626
[Epoch 21; Iter   710/ 1097] train: loss: 0.0141430
[Epoch 21; Iter   740/ 1097] train: loss: 0.0125110
[Epoch 21; Iter   770/ 1097] train: loss: 0.2338663
[Epoch 21; Iter   800/ 1097] train: loss: 0.0470682
[Epoch 21; Iter   830/ 1097] train: loss: 0.0431122
[Epoch 21; Iter   860/ 1097] train: loss: 0.0569228
[Epoch 21; Iter   890/ 1097] train: loss: 0.0222839
[Epoch 21; Iter   920/ 1097] train: loss: 0.0882427
[Epoch 21; Iter   950/ 1097] train: loss: 0.0870628
[Epoch 21; Iter   980/ 1097] train: loss: 0.1602816
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0656367
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0235961
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0164347
[Epoch 21] ogbg-molhiv: 0.716662 val loss: 0.126762
[Epoch 21] ogbg-molhiv: 0.641602 test loss: 0.183459
[Epoch 22; Iter     3/ 1097] train: loss: 0.0292490
[Epoch 22; Iter    33/ 1097] train: loss: 0.1978212
[Epoch 22; Iter    63/ 1097] train: loss: 0.0430851
[Epoch 22; Iter    93/ 1097] train: loss: 0.0175116
[Epoch 22; Iter   123/ 1097] train: loss: 0.1220015
[Epoch 22; Iter   153/ 1097] train: loss: 0.1938410
[Epoch 22; Iter   183/ 1097] train: loss: 0.1046777
[Epoch 22; Iter   213/ 1097] train: loss: 0.0455277
[Epoch 22; Iter   243/ 1097] train: loss: 0.0147550
[Epoch 22; Iter   273/ 1097] train: loss: 0.0171017
[Epoch 22; Iter   303/ 1097] train: loss: 0.0223610
[Epoch 22; Iter   333/ 1097] train: loss: 0.0546131
[Epoch 22; Iter   363/ 1097] train: loss: 0.0575059
[Epoch 22; Iter   393/ 1097] train: loss: 0.0805441
[Epoch 22; Iter   423/ 1097] train: loss: 0.0248776
[Epoch 22; Iter   453/ 1097] train: loss: 0.0603332
[Epoch 22; Iter   483/ 1097] train: loss: 0.1384565
[Epoch 22; Iter   513/ 1097] train: loss: 0.1304336
[Epoch 22; Iter   543/ 1097] train: loss: 0.0112969
[Epoch 22; Iter   573/ 1097] train: loss: 0.0937764
[Epoch 22; Iter   603/ 1097] train: loss: 0.0235879
[Epoch 22; Iter   633/ 1097] train: loss: 0.0073704
[Epoch 22; Iter   663/ 1097] train: loss: 0.0390178
[Epoch 22; Iter   693/ 1097] train: loss: 0.0399940
[Epoch 22; Iter   723/ 1097] train: loss: 0.0193812
[Epoch 22; Iter   753/ 1097] train: loss: 0.1774309
[Epoch 22; Iter   783/ 1097] train: loss: 0.1216261
[Epoch 22; Iter   813/ 1097] train: loss: 0.0171869
[Epoch 22; Iter   843/ 1097] train: loss: 0.0412849
[Epoch 22; Iter   873/ 1097] train: loss: 0.0654884
[Epoch 22; Iter   903/ 1097] train: loss: 0.0127461
[Epoch 22; Iter   933/ 1097] train: loss: 0.0101072
[Epoch 22; Iter   963/ 1097] train: loss: 0.2014922
[Epoch 22; Iter   993/ 1097] train: loss: 0.0395826
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0406864
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0766498
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0509216
[Epoch 22] ogbg-molhiv: 0.743469 val loss: 0.172252
[Epoch 22] ogbg-molhiv: 0.630557 test loss: 0.265427
[Epoch 23; Iter    16/ 1097] train: loss: 0.0512612
[Epoch 23; Iter    46/ 1097] train: loss: 0.0641289
[Epoch 23; Iter    76/ 1097] train: loss: 0.0398829
[Epoch 23; Iter   106/ 1097] train: loss: 0.0455964
[Epoch 23; Iter   136/ 1097] train: loss: 0.0253748
[Epoch 23; Iter   166/ 1097] train: loss: 0.0178242
[Epoch 23; Iter   196/ 1097] train: loss: 0.1448601
[Epoch 23; Iter   226/ 1097] train: loss: 0.1423903
[Epoch 23; Iter   256/ 1097] train: loss: 0.0195048
[Epoch 23; Iter   286/ 1097] train: loss: 0.0397130
[Epoch 23; Iter   316/ 1097] train: loss: 0.2386991
[Epoch 23; Iter   346/ 1097] train: loss: 0.2749755
[Epoch 23; Iter   376/ 1097] train: loss: 0.2357326
[Epoch 23; Iter   406/ 1097] train: loss: 0.0158178
[Epoch 23; Iter   436/ 1097] train: loss: 0.0586844
[Epoch 23; Iter   466/ 1097] train: loss: 0.0274468
[Epoch 23; Iter   496/ 1097] train: loss: 0.0727741
[Epoch 23; Iter   526/ 1097] train: loss: 0.0181227
[Epoch 23; Iter   556/ 1097] train: loss: 0.0297455
[Epoch 23; Iter   586/ 1097] train: loss: 0.0111127
[Epoch 23; Iter   616/ 1097] train: loss: 0.0717649
[Epoch 23; Iter   646/ 1097] train: loss: 0.0086555
[Epoch 23; Iter   676/ 1097] train: loss: 0.0680773
[Epoch 23; Iter   706/ 1097] train: loss: 0.0155487
[Epoch 23; Iter   736/ 1097] train: loss: 0.1138539
[Epoch 23; Iter   766/ 1097] train: loss: 0.0254562
[Epoch 23; Iter   796/ 1097] train: loss: 0.2632290
[Epoch 23; Iter   826/ 1097] train: loss: 0.0047041
[Epoch 23; Iter   856/ 1097] train: loss: 0.1280195
[Epoch 23; Iter   886/ 1097] train: loss: 0.1661230
[Epoch 23; Iter   916/ 1097] train: loss: 0.0101461
[Epoch 23; Iter   946/ 1097] train: loss: 0.2010223
[Epoch 23; Iter   976/ 1097] train: loss: 0.0739655
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1478900
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0128645
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0591484
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0575729
[Epoch 23] ogbg-molhiv: 0.735532 val loss: 0.134498
[Epoch 23] ogbg-molhiv: 0.563717 test loss: 0.270622
[Epoch 24; Iter    29/ 1097] train: loss: 0.0099387
[Epoch 24; Iter    59/ 1097] train: loss: 0.0427756
[Epoch 24; Iter    89/ 1097] train: loss: 0.0100141
[Epoch 24; Iter   119/ 1097] train: loss: 0.0242324
[Epoch 24; Iter   149/ 1097] train: loss: 0.1288509
[Epoch 24; Iter   179/ 1097] train: loss: 0.0155081
[Epoch 24; Iter   209/ 1097] train: loss: 0.0053430
[Epoch 24; Iter   239/ 1097] train: loss: 0.0947423
[Epoch 24; Iter   269/ 1097] train: loss: 0.0131516
[Epoch 24; Iter   299/ 1097] train: loss: 0.0145609
[Epoch 24; Iter   329/ 1097] train: loss: 0.0135019
[Epoch 20; Iter   277/ 1097] train: loss: 0.1355837
[Epoch 20; Iter   307/ 1097] train: loss: 0.1024445
[Epoch 20; Iter   337/ 1097] train: loss: 0.0975761
[Epoch 20; Iter   367/ 1097] train: loss: 0.0264230
[Epoch 20; Iter   397/ 1097] train: loss: 0.0189444
[Epoch 20; Iter   427/ 1097] train: loss: 0.0522508
[Epoch 20; Iter   457/ 1097] train: loss: 0.1149921
[Epoch 20; Iter   487/ 1097] train: loss: 0.0111577
[Epoch 20; Iter   517/ 1097] train: loss: 0.0234177
[Epoch 20; Iter   547/ 1097] train: loss: 0.0821161
[Epoch 20; Iter   577/ 1097] train: loss: 0.0282123
[Epoch 20; Iter   607/ 1097] train: loss: 0.0188738
[Epoch 20; Iter   637/ 1097] train: loss: 0.0457742
[Epoch 20; Iter   667/ 1097] train: loss: 0.0756338
[Epoch 20; Iter   697/ 1097] train: loss: 0.1178069
[Epoch 20; Iter   727/ 1097] train: loss: 0.1066959
[Epoch 20; Iter   757/ 1097] train: loss: 0.0236061
[Epoch 20; Iter   787/ 1097] train: loss: 0.0247743
[Epoch 20; Iter   817/ 1097] train: loss: 0.0750248
[Epoch 20; Iter   847/ 1097] train: loss: 0.0300350
[Epoch 20; Iter   877/ 1097] train: loss: 0.0968189
[Epoch 20; Iter   907/ 1097] train: loss: 0.0525473
[Epoch 20; Iter   937/ 1097] train: loss: 0.0063138
[Epoch 20; Iter   967/ 1097] train: loss: 0.1443260
[Epoch 20; Iter   997/ 1097] train: loss: 0.0805706
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0473069
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1557018
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0327231
[Epoch 20] ogbg-molhiv: 0.800880 val loss: 0.104227
[Epoch 20] ogbg-molhiv: 0.686682 test loss: 0.161611
[Epoch 21; Iter    20/ 1097] train: loss: 0.0223908
[Epoch 21; Iter    50/ 1097] train: loss: 0.1111283
[Epoch 21; Iter    80/ 1097] train: loss: 0.0378137
[Epoch 21; Iter   110/ 1097] train: loss: 0.0255041
[Epoch 21; Iter   140/ 1097] train: loss: 0.0378605
[Epoch 21; Iter   170/ 1097] train: loss: 0.0150453
[Epoch 21; Iter   200/ 1097] train: loss: 0.0821196
[Epoch 21; Iter   230/ 1097] train: loss: 0.0192169
[Epoch 21; Iter   260/ 1097] train: loss: 0.1142802
[Epoch 21; Iter   290/ 1097] train: loss: 0.0269445
[Epoch 21; Iter   320/ 1097] train: loss: 0.3145255
[Epoch 21; Iter   350/ 1097] train: loss: 0.0184465
[Epoch 21; Iter   380/ 1097] train: loss: 0.0518333
[Epoch 21; Iter   410/ 1097] train: loss: 0.1758887
[Epoch 21; Iter   440/ 1097] train: loss: 0.0862161
[Epoch 21; Iter   470/ 1097] train: loss: 0.1013448
[Epoch 21; Iter   500/ 1097] train: loss: 0.0927372
[Epoch 21; Iter   530/ 1097] train: loss: 0.0394412
[Epoch 21; Iter   560/ 1097] train: loss: 0.0283616
[Epoch 21; Iter   590/ 1097] train: loss: 0.0350250
[Epoch 21; Iter   620/ 1097] train: loss: 0.0379643
[Epoch 21; Iter   650/ 1097] train: loss: 0.3328674
[Epoch 21; Iter   680/ 1097] train: loss: 0.0243784
[Epoch 21; Iter   710/ 1097] train: loss: 0.0414879
[Epoch 21; Iter   740/ 1097] train: loss: 0.0139186
[Epoch 21; Iter   770/ 1097] train: loss: 0.0530241
[Epoch 21; Iter   800/ 1097] train: loss: 0.1555367
[Epoch 21; Iter   830/ 1097] train: loss: 0.1086636
[Epoch 21; Iter   860/ 1097] train: loss: 0.0197821
[Epoch 21; Iter   890/ 1097] train: loss: 0.0963662
[Epoch 21; Iter   920/ 1097] train: loss: 0.0575186
[Epoch 21; Iter   950/ 1097] train: loss: 0.0451546
[Epoch 21; Iter   980/ 1097] train: loss: 0.0109956
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0606891
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1439164
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0269803
[Epoch 21] ogbg-molhiv: 0.790763 val loss: 0.095473
[Epoch 21] ogbg-molhiv: 0.694295 test loss: 0.156736
[Epoch 22; Iter     3/ 1097] train: loss: 0.0397847
[Epoch 22; Iter    33/ 1097] train: loss: 0.0451733
[Epoch 22; Iter    63/ 1097] train: loss: 0.0878061
[Epoch 22; Iter    93/ 1097] train: loss: 0.0153193
[Epoch 22; Iter   123/ 1097] train: loss: 0.0722886
[Epoch 22; Iter   153/ 1097] train: loss: 0.0119045
[Epoch 22; Iter   183/ 1097] train: loss: 0.0653943
[Epoch 22; Iter   213/ 1097] train: loss: 0.1654505
[Epoch 22; Iter   243/ 1097] train: loss: 0.0131862
[Epoch 22; Iter   273/ 1097] train: loss: 0.0836221
[Epoch 22; Iter   303/ 1097] train: loss: 0.1978957
[Epoch 22; Iter   333/ 1097] train: loss: 0.0601898
[Epoch 22; Iter   363/ 1097] train: loss: 0.0914544
[Epoch 22; Iter   393/ 1097] train: loss: 0.1206740
[Epoch 22; Iter   423/ 1097] train: loss: 0.0297593
[Epoch 22; Iter   453/ 1097] train: loss: 0.0178394
[Epoch 22; Iter   483/ 1097] train: loss: 0.0240558
[Epoch 22; Iter   513/ 1097] train: loss: 0.3564205
[Epoch 22; Iter   543/ 1097] train: loss: 0.0615223
[Epoch 22; Iter   573/ 1097] train: loss: 0.0325328
[Epoch 22; Iter   603/ 1097] train: loss: 0.0112498
[Epoch 22; Iter   633/ 1097] train: loss: 0.0204131
[Epoch 22; Iter   663/ 1097] train: loss: 0.0372083
[Epoch 22; Iter   693/ 1097] train: loss: 0.0770367
[Epoch 22; Iter   723/ 1097] train: loss: 0.0670147
[Epoch 22; Iter   753/ 1097] train: loss: 0.1404346
[Epoch 22; Iter   783/ 1097] train: loss: 0.0337454
[Epoch 22; Iter   813/ 1097] train: loss: 0.1676208
[Epoch 22; Iter   843/ 1097] train: loss: 0.0401492
[Epoch 22; Iter   873/ 1097] train: loss: 0.0395130
[Epoch 22; Iter   903/ 1097] train: loss: 0.0494911
[Epoch 22; Iter   933/ 1097] train: loss: 0.0136527
[Epoch 22; Iter   963/ 1097] train: loss: 0.0864293
[Epoch 22; Iter   993/ 1097] train: loss: 0.1826411
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3169468
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0204964
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1662636
[Epoch 22] ogbg-molhiv: 0.781976 val loss: 0.242250
[Epoch 22] ogbg-molhiv: 0.673057 test loss: 0.242002
[Epoch 23; Iter    16/ 1097] train: loss: 0.0223611
[Epoch 23; Iter    46/ 1097] train: loss: 0.1801204
[Epoch 23; Iter    76/ 1097] train: loss: 0.0456208
[Epoch 23; Iter   106/ 1097] train: loss: 0.1889987
[Epoch 23; Iter   136/ 1097] train: loss: 0.0117656
[Epoch 23; Iter   166/ 1097] train: loss: 0.1465664
[Epoch 23; Iter   196/ 1097] train: loss: 0.0064668
[Epoch 23; Iter   226/ 1097] train: loss: 0.0916529
[Epoch 23; Iter   256/ 1097] train: loss: 0.0593583
[Epoch 23; Iter   286/ 1097] train: loss: 0.0302616
[Epoch 23; Iter   316/ 1097] train: loss: 0.0333411
[Epoch 23; Iter   346/ 1097] train: loss: 0.0163687
[Epoch 23; Iter   376/ 1097] train: loss: 0.0204412
[Epoch 23; Iter   406/ 1097] train: loss: 0.1493322
[Epoch 23; Iter   436/ 1097] train: loss: 0.0926611
[Epoch 23; Iter   466/ 1097] train: loss: 0.0233777
[Epoch 23; Iter   496/ 1097] train: loss: 0.0317177
[Epoch 23; Iter   526/ 1097] train: loss: 0.0165821
[Epoch 23; Iter   556/ 1097] train: loss: 0.0113469
[Epoch 23; Iter   586/ 1097] train: loss: 0.1828986
[Epoch 23; Iter   616/ 1097] train: loss: 0.1584041
[Epoch 23; Iter   646/ 1097] train: loss: 0.1415801
[Epoch 23; Iter   676/ 1097] train: loss: 0.0910776
[Epoch 23; Iter   706/ 1097] train: loss: 0.0405104
[Epoch 23; Iter   736/ 1097] train: loss: 0.0707856
[Epoch 23; Iter   766/ 1097] train: loss: 0.1301155
[Epoch 23; Iter   796/ 1097] train: loss: 0.0207015
[Epoch 23; Iter   826/ 1097] train: loss: 0.1753543
[Epoch 23; Iter   856/ 1097] train: loss: 0.1093791
[Epoch 23; Iter   886/ 1097] train: loss: 0.1309586
[Epoch 23; Iter   916/ 1097] train: loss: 0.1383613
[Epoch 23; Iter   946/ 1097] train: loss: 0.0230417
[Epoch 23; Iter   976/ 1097] train: loss: 0.1700253
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0233565
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0447581
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2118851
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0562963
[Epoch 23] ogbg-molhiv: 0.751170 val loss: 0.619261
[Epoch 23] ogbg-molhiv: 0.691668 test loss: 0.346829
[Epoch 24; Iter    29/ 1097] train: loss: 0.0502114
[Epoch 24; Iter    59/ 1097] train: loss: 0.0675555
[Epoch 24; Iter    89/ 1097] train: loss: 0.2143469
[Epoch 24; Iter   119/ 1097] train: loss: 0.0238869
[Epoch 24; Iter   149/ 1097] train: loss: 0.0184331
[Epoch 24; Iter   179/ 1097] train: loss: 0.0095750
[Epoch 24; Iter   209/ 1097] train: loss: 0.0128791
[Epoch 24; Iter   239/ 1097] train: loss: 0.0175369
[Epoch 24; Iter   269/ 1097] train: loss: 0.3368852
[Epoch 24; Iter   299/ 1097] train: loss: 0.0278389
[Epoch 24; Iter   329/ 1097] train: loss: 0.0249676
[Epoch 20; Iter   277/ 1097] train: loss: 0.0881419
[Epoch 20; Iter   307/ 1097] train: loss: 0.0779290
[Epoch 20; Iter   337/ 1097] train: loss: 0.1063061
[Epoch 20; Iter   367/ 1097] train: loss: 0.0352607
[Epoch 20; Iter   397/ 1097] train: loss: 0.0828618
[Epoch 20; Iter   427/ 1097] train: loss: 0.2718450
[Epoch 20; Iter   457/ 1097] train: loss: 0.0690224
[Epoch 20; Iter   487/ 1097] train: loss: 0.0435237
[Epoch 20; Iter   517/ 1097] train: loss: 0.0378006
[Epoch 20; Iter   547/ 1097] train: loss: 0.0174565
[Epoch 20; Iter   577/ 1097] train: loss: 0.0226927
[Epoch 20; Iter   607/ 1097] train: loss: 0.0320962
[Epoch 20; Iter   637/ 1097] train: loss: 0.1236692
[Epoch 20; Iter   667/ 1097] train: loss: 0.2861371
[Epoch 20; Iter   697/ 1097] train: loss: 0.0187229
[Epoch 20; Iter   727/ 1097] train: loss: 0.0255745
[Epoch 20; Iter   757/ 1097] train: loss: 0.2243106
[Epoch 20; Iter   787/ 1097] train: loss: 0.0326187
[Epoch 20; Iter   817/ 1097] train: loss: 0.0371674
[Epoch 20; Iter   847/ 1097] train: loss: 0.0548816
[Epoch 20; Iter   877/ 1097] train: loss: 0.1602537
[Epoch 20; Iter   907/ 1097] train: loss: 0.0178594
[Epoch 20; Iter   937/ 1097] train: loss: 0.0214634
[Epoch 20; Iter   967/ 1097] train: loss: 0.0381759
[Epoch 20; Iter   997/ 1097] train: loss: 0.0255478
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0732469
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1937088
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0258270
[Epoch 20] ogbg-molhiv: 0.755680 val loss: 0.107285
[Epoch 20] ogbg-molhiv: 0.699739 test loss: 0.152633
[Epoch 21; Iter    20/ 1097] train: loss: 0.0168722
[Epoch 21; Iter    50/ 1097] train: loss: 0.0149332
[Epoch 21; Iter    80/ 1097] train: loss: 0.0153736
[Epoch 21; Iter   110/ 1097] train: loss: 0.0140825
[Epoch 21; Iter   140/ 1097] train: loss: 0.1845566
[Epoch 21; Iter   170/ 1097] train: loss: 0.0887104
[Epoch 21; Iter   200/ 1097] train: loss: 0.0150850
[Epoch 21; Iter   230/ 1097] train: loss: 0.0818169
[Epoch 21; Iter   260/ 1097] train: loss: 0.0229180
[Epoch 21; Iter   290/ 1097] train: loss: 0.1213184
[Epoch 21; Iter   320/ 1097] train: loss: 0.0238484
[Epoch 21; Iter   350/ 1097] train: loss: 0.2135967
[Epoch 21; Iter   380/ 1097] train: loss: 0.0139479
[Epoch 21; Iter   410/ 1097] train: loss: 0.0956802
[Epoch 21; Iter   440/ 1097] train: loss: 0.3484883
[Epoch 21; Iter   470/ 1097] train: loss: 0.1319335
[Epoch 21; Iter   500/ 1097] train: loss: 0.1346695
[Epoch 21; Iter   530/ 1097] train: loss: 0.0415285
[Epoch 21; Iter   560/ 1097] train: loss: 0.0520419
[Epoch 21; Iter   590/ 1097] train: loss: 0.0220315
[Epoch 21; Iter   620/ 1097] train: loss: 0.2459299
[Epoch 21; Iter   650/ 1097] train: loss: 0.0204912
[Epoch 21; Iter   680/ 1097] train: loss: 0.0393995
[Epoch 21; Iter   710/ 1097] train: loss: 0.2493300
[Epoch 21; Iter   740/ 1097] train: loss: 0.1110644
[Epoch 21; Iter   770/ 1097] train: loss: 0.0725671
[Epoch 21; Iter   800/ 1097] train: loss: 0.0844376
[Epoch 21; Iter   830/ 1097] train: loss: 0.3861121
[Epoch 21; Iter   860/ 1097] train: loss: 0.0160671
[Epoch 21; Iter   890/ 1097] train: loss: 0.0158822
[Epoch 21; Iter   920/ 1097] train: loss: 0.0606035
[Epoch 21; Iter   950/ 1097] train: loss: 0.1452672
[Epoch 21; Iter   980/ 1097] train: loss: 0.1979902
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0180425
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1759675
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0318038
[Epoch 21] ogbg-molhiv: 0.701380 val loss: 0.195299
[Epoch 21] ogbg-molhiv: 0.621943 test loss: 0.223163
[Epoch 22; Iter     3/ 1097] train: loss: 0.0241639
[Epoch 22; Iter    33/ 1097] train: loss: 0.0204042
[Epoch 22; Iter    63/ 1097] train: loss: 0.0127526
[Epoch 22; Iter    93/ 1097] train: loss: 0.0233955
[Epoch 22; Iter   123/ 1097] train: loss: 0.0131847
[Epoch 22; Iter   153/ 1097] train: loss: 0.0833095
[Epoch 22; Iter   183/ 1097] train: loss: 0.0132215
[Epoch 22; Iter   213/ 1097] train: loss: 0.0282473
[Epoch 22; Iter   243/ 1097] train: loss: 0.0280870
[Epoch 22; Iter   273/ 1097] train: loss: 0.1345009
[Epoch 22; Iter   303/ 1097] train: loss: 0.0636498
[Epoch 22; Iter   333/ 1097] train: loss: 0.0206740
[Epoch 22; Iter   363/ 1097] train: loss: 0.0593888
[Epoch 22; Iter   393/ 1097] train: loss: 0.0890515
[Epoch 22; Iter   423/ 1097] train: loss: 0.1383137
[Epoch 22; Iter   453/ 1097] train: loss: 0.0667085
[Epoch 22; Iter   483/ 1097] train: loss: 0.0323486
[Epoch 22; Iter   513/ 1097] train: loss: 0.0120085
[Epoch 22; Iter   543/ 1097] train: loss: 0.0220564
[Epoch 22; Iter   573/ 1097] train: loss: 0.0306426
[Epoch 22; Iter   603/ 1097] train: loss: 0.0362671
[Epoch 22; Iter   633/ 1097] train: loss: 0.0372118
[Epoch 22; Iter   663/ 1097] train: loss: 0.0189094
[Epoch 22; Iter   693/ 1097] train: loss: 0.0549700
[Epoch 22; Iter   723/ 1097] train: loss: 0.0226689
[Epoch 22; Iter   753/ 1097] train: loss: 0.0231242
[Epoch 22; Iter   783/ 1097] train: loss: 0.4865224
[Epoch 22; Iter   813/ 1097] train: loss: 0.0332321
[Epoch 22; Iter   843/ 1097] train: loss: 0.0518559
[Epoch 22; Iter   873/ 1097] train: loss: 0.0691572
[Epoch 22; Iter   903/ 1097] train: loss: 0.0239098
[Epoch 22; Iter   933/ 1097] train: loss: 0.0099641
[Epoch 22; Iter   963/ 1097] train: loss: 0.1806673
[Epoch 22; Iter   993/ 1097] train: loss: 0.0133775
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0615467
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0229832
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0134457
[Epoch 22] ogbg-molhiv: 0.714987 val loss: 0.247761
[Epoch 22] ogbg-molhiv: 0.644216 test loss: 0.176852
[Epoch 23; Iter    16/ 1097] train: loss: 0.1085739
[Epoch 23; Iter    46/ 1097] train: loss: 0.0104616
[Epoch 23; Iter    76/ 1097] train: loss: 0.0189132
[Epoch 23; Iter   106/ 1097] train: loss: 0.0295766
[Epoch 23; Iter   136/ 1097] train: loss: 0.0360319
[Epoch 23; Iter   166/ 1097] train: loss: 0.1535684
[Epoch 23; Iter   196/ 1097] train: loss: 0.1138147
[Epoch 23; Iter   226/ 1097] train: loss: 0.0158973
[Epoch 23; Iter   256/ 1097] train: loss: 0.0151004
[Epoch 23; Iter   286/ 1097] train: loss: 0.0142846
[Epoch 23; Iter   316/ 1097] train: loss: 0.0387102
[Epoch 23; Iter   346/ 1097] train: loss: 0.0484565
[Epoch 23; Iter   376/ 1097] train: loss: 0.0945508
[Epoch 23; Iter   406/ 1097] train: loss: 0.0162556
[Epoch 23; Iter   436/ 1097] train: loss: 0.2505248
[Epoch 23; Iter   466/ 1097] train: loss: 0.0391906
[Epoch 23; Iter   496/ 1097] train: loss: 0.0231173
[Epoch 23; Iter   526/ 1097] train: loss: 0.0115877
[Epoch 23; Iter   556/ 1097] train: loss: 0.0165753
[Epoch 23; Iter   586/ 1097] train: loss: 0.0221521
[Epoch 23; Iter   616/ 1097] train: loss: 0.0047423
[Epoch 23; Iter   646/ 1097] train: loss: 0.0363071
[Epoch 23; Iter   676/ 1097] train: loss: 0.1218354
[Epoch 23; Iter   706/ 1097] train: loss: 0.0359697
[Epoch 23; Iter   736/ 1097] train: loss: 0.0339883
[Epoch 23; Iter   766/ 1097] train: loss: 0.2071893
[Epoch 23; Iter   796/ 1097] train: loss: 0.0199910
[Epoch 23; Iter   826/ 1097] train: loss: 0.0755865
[Epoch 23; Iter   856/ 1097] train: loss: 0.0272862
[Epoch 23; Iter   886/ 1097] train: loss: 0.0207500
[Epoch 23; Iter   916/ 1097] train: loss: 0.0395134
[Epoch 23; Iter   946/ 1097] train: loss: 0.0439736
[Epoch 23; Iter   976/ 1097] train: loss: 0.0409965
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1342861
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1752602
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0495640
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0441563
[Epoch 23] ogbg-molhiv: 0.719194 val loss: 0.239521
[Epoch 23] ogbg-molhiv: 0.659657 test loss: 0.190359
[Epoch 24; Iter    29/ 1097] train: loss: 0.0269505
[Epoch 24; Iter    59/ 1097] train: loss: 0.0214269
[Epoch 24; Iter    89/ 1097] train: loss: 0.0239761
[Epoch 24; Iter   119/ 1097] train: loss: 0.0084036
[Epoch 24; Iter   149/ 1097] train: loss: 0.0520664
[Epoch 24; Iter   179/ 1097] train: loss: 0.1561023
[Epoch 24; Iter   209/ 1097] train: loss: 0.0412104
[Epoch 24; Iter   239/ 1097] train: loss: 0.0808094
[Epoch 24; Iter   269/ 1097] train: loss: 0.0134112
[Epoch 24; Iter   299/ 1097] train: loss: 0.1145874
[Epoch 24; Iter   329/ 1097] train: loss: 0.3412136
[Epoch 20; Iter   277/ 1097] train: loss: 0.1450890
[Epoch 20; Iter   307/ 1097] train: loss: 0.0633647
[Epoch 20; Iter   337/ 1097] train: loss: 0.0788980
[Epoch 20; Iter   367/ 1097] train: loss: 0.0656214
[Epoch 20; Iter   397/ 1097] train: loss: 0.0244540
[Epoch 20; Iter   427/ 1097] train: loss: 0.2982799
[Epoch 20; Iter   457/ 1097] train: loss: 0.1071005
[Epoch 20; Iter   487/ 1097] train: loss: 0.1091111
[Epoch 20; Iter   517/ 1097] train: loss: 0.0416246
[Epoch 20; Iter   547/ 1097] train: loss: 0.0384842
[Epoch 20; Iter   577/ 1097] train: loss: 0.0134671
[Epoch 20; Iter   607/ 1097] train: loss: 0.0327916
[Epoch 20; Iter   637/ 1097] train: loss: 0.2813907
[Epoch 20; Iter   667/ 1097] train: loss: 0.3867219
[Epoch 20; Iter   697/ 1097] train: loss: 0.0167912
[Epoch 20; Iter   727/ 1097] train: loss: 0.0226761
[Epoch 20; Iter   757/ 1097] train: loss: 0.2467027
[Epoch 20; Iter   787/ 1097] train: loss: 0.0490492
[Epoch 20; Iter   817/ 1097] train: loss: 0.0214089
[Epoch 20; Iter   847/ 1097] train: loss: 0.2054797
[Epoch 20; Iter   877/ 1097] train: loss: 0.2547610
[Epoch 20; Iter   907/ 1097] train: loss: 0.0311822
[Epoch 20; Iter   937/ 1097] train: loss: 0.1156891
[Epoch 20; Iter   967/ 1097] train: loss: 0.0387360
[Epoch 20; Iter   997/ 1097] train: loss: 0.0302716
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0420920
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1524985
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0503527
[Epoch 20] ogbg-molhiv: 0.804658 val loss: 0.125157
[Epoch 20] ogbg-molhiv: 0.764963 test loss: 0.114669
[Epoch 21; Iter    20/ 1097] train: loss: 0.0517966
[Epoch 21; Iter    50/ 1097] train: loss: 0.0230750
[Epoch 21; Iter    80/ 1097] train: loss: 0.0232741
[Epoch 21; Iter   110/ 1097] train: loss: 0.0253212
[Epoch 21; Iter   140/ 1097] train: loss: 0.1346229
[Epoch 21; Iter   170/ 1097] train: loss: 0.0873067
[Epoch 21; Iter   200/ 1097] train: loss: 0.0177653
[Epoch 21; Iter   230/ 1097] train: loss: 0.0446761
[Epoch 21; Iter   260/ 1097] train: loss: 0.0231988
[Epoch 21; Iter   290/ 1097] train: loss: 0.0534650
[Epoch 21; Iter   320/ 1097] train: loss: 0.0857529
[Epoch 21; Iter   350/ 1097] train: loss: 0.1160672
[Epoch 21; Iter   380/ 1097] train: loss: 0.0221242
[Epoch 21; Iter   410/ 1097] train: loss: 0.1940247
[Epoch 21; Iter   440/ 1097] train: loss: 0.3328891
[Epoch 21; Iter   470/ 1097] train: loss: 0.1511303
[Epoch 21; Iter   500/ 1097] train: loss: 0.1696942
[Epoch 21; Iter   530/ 1097] train: loss: 0.0576445
[Epoch 21; Iter   560/ 1097] train: loss: 0.1172257
[Epoch 21; Iter   590/ 1097] train: loss: 0.1454029
[Epoch 21; Iter   620/ 1097] train: loss: 0.1632990
[Epoch 21; Iter   650/ 1097] train: loss: 0.0236910
[Epoch 21; Iter   680/ 1097] train: loss: 0.0793407
[Epoch 21; Iter   710/ 1097] train: loss: 0.2633224
[Epoch 21; Iter   740/ 1097] train: loss: 0.1271650
[Epoch 21; Iter   770/ 1097] train: loss: 0.0441110
[Epoch 21; Iter   800/ 1097] train: loss: 0.2829461
[Epoch 21; Iter   830/ 1097] train: loss: 0.4542355
[Epoch 21; Iter   860/ 1097] train: loss: 0.0137338
[Epoch 21; Iter   890/ 1097] train: loss: 0.0354215
[Epoch 21; Iter   920/ 1097] train: loss: 0.1482017
[Epoch 21; Iter   950/ 1097] train: loss: 0.1196312
[Epoch 21; Iter   980/ 1097] train: loss: 0.2356735
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0507559
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2369918
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0251380
[Epoch 21] ogbg-molhiv: 0.767802 val loss: 0.079572
[Epoch 21] ogbg-molhiv: 0.776483 test loss: 0.119461
[Epoch 22; Iter     3/ 1097] train: loss: 0.0201618
[Epoch 22; Iter    33/ 1097] train: loss: 0.0753721
[Epoch 22; Iter    63/ 1097] train: loss: 0.1407924
[Epoch 22; Iter    93/ 1097] train: loss: 0.0249373
[Epoch 22; Iter   123/ 1097] train: loss: 0.0233336
[Epoch 22; Iter   153/ 1097] train: loss: 0.0455716
[Epoch 22; Iter   183/ 1097] train: loss: 0.0337778
[Epoch 22; Iter   213/ 1097] train: loss: 0.0218605
[Epoch 22; Iter   243/ 1097] train: loss: 0.0471113
[Epoch 22; Iter   273/ 1097] train: loss: 0.1872078
[Epoch 22; Iter   303/ 1097] train: loss: 0.0282546
[Epoch 22; Iter   333/ 1097] train: loss: 0.0264867
[Epoch 22; Iter   363/ 1097] train: loss: 0.0203695
[Epoch 22; Iter   393/ 1097] train: loss: 0.0270000
[Epoch 22; Iter   423/ 1097] train: loss: 0.0254442
[Epoch 22; Iter   453/ 1097] train: loss: 0.1344528
[Epoch 22; Iter   483/ 1097] train: loss: 0.0447369
[Epoch 22; Iter   513/ 1097] train: loss: 0.0157329
[Epoch 22; Iter   543/ 1097] train: loss: 0.1186525
[Epoch 22; Iter   573/ 1097] train: loss: 0.0592058
[Epoch 22; Iter   603/ 1097] train: loss: 0.0678297
[Epoch 22; Iter   633/ 1097] train: loss: 0.0142519
[Epoch 22; Iter   663/ 1097] train: loss: 0.0441244
[Epoch 22; Iter   693/ 1097] train: loss: 0.0177181
[Epoch 22; Iter   723/ 1097] train: loss: 0.0187614
[Epoch 22; Iter   753/ 1097] train: loss: 0.0381665
[Epoch 22; Iter   783/ 1097] train: loss: 0.2979601
[Epoch 22; Iter   813/ 1097] train: loss: 0.0361093
[Epoch 22; Iter   843/ 1097] train: loss: 0.1386504
[Epoch 22; Iter   873/ 1097] train: loss: 0.0531904
[Epoch 22; Iter   903/ 1097] train: loss: 0.0846902
[Epoch 22; Iter   933/ 1097] train: loss: 0.0270010
[Epoch 22; Iter   963/ 1097] train: loss: 0.1495285
[Epoch 22; Iter   993/ 1097] train: loss: 0.0230520
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0459497
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0904707
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0254151
[Epoch 22] ogbg-molhiv: 0.796318 val loss: 0.093534
[Epoch 22] ogbg-molhiv: 0.783789 test loss: 0.116147
[Epoch 23; Iter    16/ 1097] train: loss: 0.1020825
[Epoch 23; Iter    46/ 1097] train: loss: 0.0373610
[Epoch 23; Iter    76/ 1097] train: loss: 0.0663731
[Epoch 23; Iter   106/ 1097] train: loss: 0.0281922
[Epoch 23; Iter   136/ 1097] train: loss: 0.0877004
[Epoch 23; Iter   166/ 1097] train: loss: 0.2024935
[Epoch 23; Iter   196/ 1097] train: loss: 0.2299320
[Epoch 23; Iter   226/ 1097] train: loss: 0.0490470
[Epoch 23; Iter   256/ 1097] train: loss: 0.0452780
[Epoch 23; Iter   286/ 1097] train: loss: 0.0853603
[Epoch 23; Iter   316/ 1097] train: loss: 0.0228430
[Epoch 23; Iter   346/ 1097] train: loss: 0.0919525
[Epoch 23; Iter   376/ 1097] train: loss: 0.0710989
[Epoch 23; Iter   406/ 1097] train: loss: 0.0730277
[Epoch 23; Iter   436/ 1097] train: loss: 0.1542076
[Epoch 23; Iter   466/ 1097] train: loss: 0.0421380
[Epoch 23; Iter   496/ 1097] train: loss: 0.1392954
[Epoch 23; Iter   526/ 1097] train: loss: 0.0313915
[Epoch 23; Iter   556/ 1097] train: loss: 0.0746790
[Epoch 23; Iter   586/ 1097] train: loss: 0.0401493
[Epoch 23; Iter   616/ 1097] train: loss: 0.0169634
[Epoch 23; Iter   646/ 1097] train: loss: 0.0336811
[Epoch 23; Iter   676/ 1097] train: loss: 0.2131268
[Epoch 23; Iter   706/ 1097] train: loss: 0.0405151
[Epoch 23; Iter   736/ 1097] train: loss: 0.0355645
[Epoch 23; Iter   766/ 1097] train: loss: 0.1427865
[Epoch 23; Iter   796/ 1097] train: loss: 0.0889845
[Epoch 23; Iter   826/ 1097] train: loss: 0.1241284
[Epoch 23; Iter   856/ 1097] train: loss: 0.0165694
[Epoch 23; Iter   886/ 1097] train: loss: 0.0657275
[Epoch 23; Iter   916/ 1097] train: loss: 0.0211433
[Epoch 23; Iter   946/ 1097] train: loss: 0.0246672
[Epoch 23; Iter   976/ 1097] train: loss: 0.0230446
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0863096
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0316083
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0156049
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1733985
[Epoch 23] ogbg-molhiv: 0.774027 val loss: 0.340294
[Epoch 23] ogbg-molhiv: 0.753352 test loss: 0.257586
[Epoch 24; Iter    29/ 1097] train: loss: 0.0193237
[Epoch 24; Iter    59/ 1097] train: loss: 0.0714386
[Epoch 24; Iter    89/ 1097] train: loss: 0.2541436
[Epoch 24; Iter   119/ 1097] train: loss: 0.0781319
[Epoch 24; Iter   149/ 1097] train: loss: 0.1245480
[Epoch 24; Iter   179/ 1097] train: loss: 0.2020151
[Epoch 24; Iter   209/ 1097] train: loss: 0.1288052
[Epoch 24; Iter   239/ 1097] train: loss: 0.3873876
[Epoch 24; Iter   269/ 1097] train: loss: 0.0420820
[Epoch 24; Iter   299/ 1097] train: loss: 0.0245907
[Epoch 24; Iter   329/ 1097] train: loss: 0.2455234
[Epoch 20; Iter   277/ 1097] train: loss: 0.0166075
[Epoch 20; Iter   307/ 1097] train: loss: 0.0502194
[Epoch 20; Iter   337/ 1097] train: loss: 0.1628185
[Epoch 20; Iter   367/ 1097] train: loss: 0.3086386
[Epoch 20; Iter   397/ 1097] train: loss: 0.1422800
[Epoch 20; Iter   427/ 1097] train: loss: 0.0602264
[Epoch 20; Iter   457/ 1097] train: loss: 0.0364764
[Epoch 20; Iter   487/ 1097] train: loss: 0.1068335
[Epoch 20; Iter   517/ 1097] train: loss: 0.0638884
[Epoch 20; Iter   547/ 1097] train: loss: 0.2332961
[Epoch 20; Iter   577/ 1097] train: loss: 0.0236163
[Epoch 20; Iter   607/ 1097] train: loss: 0.2556332
[Epoch 20; Iter   637/ 1097] train: loss: 0.0632886
[Epoch 20; Iter   667/ 1097] train: loss: 0.1042935
[Epoch 20; Iter   697/ 1097] train: loss: 0.0250180
[Epoch 20; Iter   727/ 1097] train: loss: 0.0939058
[Epoch 20; Iter   757/ 1097] train: loss: 0.1452166
[Epoch 20; Iter   787/ 1097] train: loss: 0.0454057
[Epoch 20; Iter   817/ 1097] train: loss: 0.1533030
[Epoch 20; Iter   847/ 1097] train: loss: 0.0293935
[Epoch 20; Iter   877/ 1097] train: loss: 0.1690240
[Epoch 20; Iter   907/ 1097] train: loss: 0.1514347
[Epoch 20; Iter   937/ 1097] train: loss: 0.0724758
[Epoch 20; Iter   967/ 1097] train: loss: 0.0847696
[Epoch 20; Iter   997/ 1097] train: loss: 0.1293597
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0983738
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4514647
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2146770
[Epoch 20] ogbg-molhiv: 0.836809 val loss: 0.068727
[Epoch 20] ogbg-molhiv: 0.747546 test loss: 0.118273
[Epoch 21; Iter    20/ 1097] train: loss: 0.0307313
[Epoch 21; Iter    50/ 1097] train: loss: 0.2181656
[Epoch 21; Iter    80/ 1097] train: loss: 0.0538332
[Epoch 21; Iter   110/ 1097] train: loss: 0.0445262
[Epoch 21; Iter   140/ 1097] train: loss: 0.1518160
[Epoch 21; Iter   170/ 1097] train: loss: 0.1563189
[Epoch 21; Iter   200/ 1097] train: loss: 0.0391717
[Epoch 21; Iter   230/ 1097] train: loss: 0.0925114
[Epoch 21; Iter   260/ 1097] train: loss: 0.2095872
[Epoch 21; Iter   290/ 1097] train: loss: 0.0517186
[Epoch 21; Iter   320/ 1097] train: loss: 0.0605155
[Epoch 21; Iter   350/ 1097] train: loss: 0.1154897
[Epoch 21; Iter   380/ 1097] train: loss: 0.0424158
[Epoch 21; Iter   410/ 1097] train: loss: 0.0326525
[Epoch 21; Iter   440/ 1097] train: loss: 0.1488228
[Epoch 21; Iter   470/ 1097] train: loss: 0.0600246
[Epoch 21; Iter   500/ 1097] train: loss: 0.2453985
[Epoch 21; Iter   530/ 1097] train: loss: 0.0813392
[Epoch 21; Iter   560/ 1097] train: loss: 0.0445653
[Epoch 21; Iter   590/ 1097] train: loss: 0.0242505
[Epoch 21; Iter   620/ 1097] train: loss: 0.1408216
[Epoch 21; Iter   650/ 1097] train: loss: 0.0372587
[Epoch 21; Iter   680/ 1097] train: loss: 0.0199351
[Epoch 21; Iter   710/ 1097] train: loss: 0.0167044
[Epoch 21; Iter   740/ 1097] train: loss: 0.0178561
[Epoch 21; Iter   770/ 1097] train: loss: 0.1244479
[Epoch 21; Iter   800/ 1097] train: loss: 0.0399180
[Epoch 21; Iter   830/ 1097] train: loss: 0.0540177
[Epoch 21; Iter   860/ 1097] train: loss: 0.0228383
[Epoch 21; Iter   890/ 1097] train: loss: 0.0392219
[Epoch 21; Iter   920/ 1097] train: loss: 0.1411901
[Epoch 21; Iter   950/ 1097] train: loss: 0.0447890
[Epoch 21; Iter   980/ 1097] train: loss: 0.2045916
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1612371
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0228397
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0305467
[Epoch 21] ogbg-molhiv: 0.813912 val loss: 0.067267
[Epoch 21] ogbg-molhiv: 0.741720 test loss: 0.119121
[Epoch 22; Iter     3/ 1097] train: loss: 0.0567887
[Epoch 22; Iter    33/ 1097] train: loss: 0.2763295
[Epoch 22; Iter    63/ 1097] train: loss: 0.1827305
[Epoch 22; Iter    93/ 1097] train: loss: 0.0600759
[Epoch 22; Iter   123/ 1097] train: loss: 0.1090082
[Epoch 22; Iter   153/ 1097] train: loss: 0.3034986
[Epoch 22; Iter   183/ 1097] train: loss: 0.1893756
[Epoch 22; Iter   213/ 1097] train: loss: 0.0389960
[Epoch 22; Iter   243/ 1097] train: loss: 0.0387365
[Epoch 22; Iter   273/ 1097] train: loss: 0.0543631
[Epoch 22; Iter   303/ 1097] train: loss: 0.0295798
[Epoch 22; Iter   333/ 1097] train: loss: 0.1961497
[Epoch 22; Iter   363/ 1097] train: loss: 0.0679168
[Epoch 22; Iter   393/ 1097] train: loss: 0.2112759
[Epoch 22; Iter   423/ 1097] train: loss: 0.0282336
[Epoch 22; Iter   453/ 1097] train: loss: 0.0291237
[Epoch 22; Iter   483/ 1097] train: loss: 0.2079554
[Epoch 22; Iter   513/ 1097] train: loss: 0.0844674
[Epoch 22; Iter   543/ 1097] train: loss: 0.0313046
[Epoch 22; Iter   573/ 1097] train: loss: 0.0718934
[Epoch 22; Iter   603/ 1097] train: loss: 0.0174022
[Epoch 22; Iter   633/ 1097] train: loss: 0.0310732
[Epoch 22; Iter   663/ 1097] train: loss: 0.0539788
[Epoch 22; Iter   693/ 1097] train: loss: 0.0223562
[Epoch 22; Iter   723/ 1097] train: loss: 0.0229069
[Epoch 22; Iter   753/ 1097] train: loss: 0.2379072
[Epoch 22; Iter   783/ 1097] train: loss: 0.1877735
[Epoch 22; Iter   813/ 1097] train: loss: 0.0256097
[Epoch 22; Iter   843/ 1097] train: loss: 0.0271678
[Epoch 22; Iter   873/ 1097] train: loss: 0.0852363
[Epoch 22; Iter   903/ 1097] train: loss: 0.0748528
[Epoch 22; Iter   933/ 1097] train: loss: 0.0505571
[Epoch 22; Iter   963/ 1097] train: loss: 0.2408527
[Epoch 22; Iter   993/ 1097] train: loss: 0.0568871
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0239588
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1669132
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0201645
[Epoch 22] ogbg-molhiv: 0.812280 val loss: 0.080065
[Epoch 22] ogbg-molhiv: 0.761963 test loss: 0.118498
[Epoch 23; Iter    16/ 1097] train: loss: 0.0571104
[Epoch 23; Iter    46/ 1097] train: loss: 0.1049739
[Epoch 23; Iter    76/ 1097] train: loss: 0.0315443
[Epoch 23; Iter   106/ 1097] train: loss: 0.0211506
[Epoch 23; Iter   136/ 1097] train: loss: 0.1901572
[Epoch 23; Iter   166/ 1097] train: loss: 0.0667911
[Epoch 23; Iter   196/ 1097] train: loss: 0.2618167
[Epoch 23; Iter   226/ 1097] train: loss: 0.0836278
[Epoch 23; Iter   256/ 1097] train: loss: 0.0672035
[Epoch 23; Iter   286/ 1097] train: loss: 0.0271786
[Epoch 23; Iter   316/ 1097] train: loss: 0.3650983
[Epoch 23; Iter   346/ 1097] train: loss: 0.1273519
[Epoch 23; Iter   376/ 1097] train: loss: 0.2071560
[Epoch 23; Iter   406/ 1097] train: loss: 0.0755921
[Epoch 23; Iter   436/ 1097] train: loss: 0.2361277
[Epoch 23; Iter   466/ 1097] train: loss: 0.0867760
[Epoch 23; Iter   496/ 1097] train: loss: 0.0613275
[Epoch 23; Iter   526/ 1097] train: loss: 0.0167052
[Epoch 23; Iter   556/ 1097] train: loss: 0.1210525
[Epoch 23; Iter   586/ 1097] train: loss: 0.0246127
[Epoch 23; Iter   616/ 1097] train: loss: 0.0523164
[Epoch 23; Iter   646/ 1097] train: loss: 0.0329508
[Epoch 23; Iter   676/ 1097] train: loss: 0.0384442
[Epoch 23; Iter   706/ 1097] train: loss: 0.0776320
[Epoch 23; Iter   736/ 1097] train: loss: 0.1315393
[Epoch 23; Iter   766/ 1097] train: loss: 0.0434679
[Epoch 23; Iter   796/ 1097] train: loss: 0.2400987
[Epoch 23; Iter   826/ 1097] train: loss: 0.0399069
[Epoch 23; Iter   856/ 1097] train: loss: 0.1885376
[Epoch 23; Iter   886/ 1097] train: loss: 0.1839621
[Epoch 23; Iter   916/ 1097] train: loss: 0.0847414
[Epoch 23; Iter   946/ 1097] train: loss: 0.1760994
[Epoch 23; Iter   976/ 1097] train: loss: 0.0246920
[Epoch 23; Iter  1006/ 1097] train: loss: 0.2001612
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1254425
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1702693
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0292078
[Epoch 23] ogbg-molhiv: 0.824083 val loss: 0.065493
[Epoch 23] ogbg-molhiv: 0.739022 test loss: 0.119929
[Epoch 24; Iter    29/ 1097] train: loss: 0.0197423
[Epoch 24; Iter    59/ 1097] train: loss: 0.1580099
[Epoch 24; Iter    89/ 1097] train: loss: 0.0273852
[Epoch 24; Iter   119/ 1097] train: loss: 0.0458570
[Epoch 24; Iter   149/ 1097] train: loss: 0.3113641
[Epoch 24; Iter   179/ 1097] train: loss: 0.0963475
[Epoch 24; Iter   209/ 1097] train: loss: 0.0249364
[Epoch 24; Iter   239/ 1097] train: loss: 0.1303223
[Epoch 24; Iter   269/ 1097] train: loss: 0.0345514
[Epoch 24; Iter   299/ 1097] train: loss: 0.0707974
[Epoch 24; Iter   329/ 1097] train: loss: 0.0519824
[Epoch 20; Iter   277/ 1097] train: loss: 0.1588779
[Epoch 20; Iter   307/ 1097] train: loss: 0.1860467
[Epoch 20; Iter   337/ 1097] train: loss: 0.0796114
[Epoch 20; Iter   367/ 1097] train: loss: 0.0751801
[Epoch 20; Iter   397/ 1097] train: loss: 0.0290468
[Epoch 20; Iter   427/ 1097] train: loss: 0.0197049
[Epoch 20; Iter   457/ 1097] train: loss: 0.1380441
[Epoch 20; Iter   487/ 1097] train: loss: 0.1341000
[Epoch 20; Iter   517/ 1097] train: loss: 0.0370072
[Epoch 20; Iter   547/ 1097] train: loss: 0.1331650
[Epoch 20; Iter   577/ 1097] train: loss: 0.0203111
[Epoch 20; Iter   607/ 1097] train: loss: 0.0188894
[Epoch 20; Iter   637/ 1097] train: loss: 0.0216354
[Epoch 20; Iter   667/ 1097] train: loss: 0.1554403
[Epoch 20; Iter   697/ 1097] train: loss: 0.0648480
[Epoch 20; Iter   727/ 1097] train: loss: 0.1278725
[Epoch 20; Iter   757/ 1097] train: loss: 0.0214245
[Epoch 20; Iter   787/ 1097] train: loss: 0.0301146
[Epoch 20; Iter   817/ 1097] train: loss: 0.0969174
[Epoch 20; Iter   847/ 1097] train: loss: 0.0495197
[Epoch 20; Iter   877/ 1097] train: loss: 0.1520529
[Epoch 20; Iter   907/ 1097] train: loss: 0.2209145
[Epoch 20; Iter   937/ 1097] train: loss: 0.0201961
[Epoch 20; Iter   967/ 1097] train: loss: 0.0946379
[Epoch 20; Iter   997/ 1097] train: loss: 0.1367312
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0311566
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0363533
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0397778
[Epoch 20] ogbg-molhiv: 0.823103 val loss: 0.075149
[Epoch 20] ogbg-molhiv: 0.781122 test loss: 0.121395
[Epoch 21; Iter    20/ 1097] train: loss: 0.0241192
[Epoch 21; Iter    50/ 1097] train: loss: 0.1616614
[Epoch 21; Iter    80/ 1097] train: loss: 0.0388662
[Epoch 21; Iter   110/ 1097] train: loss: 0.0487976
[Epoch 21; Iter   140/ 1097] train: loss: 0.1562740
[Epoch 21; Iter   170/ 1097] train: loss: 0.1468622
[Epoch 21; Iter   200/ 1097] train: loss: 0.1778336
[Epoch 21; Iter   230/ 1097] train: loss: 0.1681204
[Epoch 21; Iter   260/ 1097] train: loss: 0.2356914
[Epoch 21; Iter   290/ 1097] train: loss: 0.1961317
[Epoch 21; Iter   320/ 1097] train: loss: 0.2116153
[Epoch 21; Iter   350/ 1097] train: loss: 0.0272715
[Epoch 21; Iter   380/ 1097] train: loss: 0.0436058
[Epoch 21; Iter   410/ 1097] train: loss: 0.0652131
[Epoch 21; Iter   440/ 1097] train: loss: 0.1558533
[Epoch 21; Iter   470/ 1097] train: loss: 0.1648207
[Epoch 21; Iter   500/ 1097] train: loss: 0.0245686
[Epoch 21; Iter   530/ 1097] train: loss: 0.0328086
[Epoch 21; Iter   560/ 1097] train: loss: 0.0203122
[Epoch 21; Iter   590/ 1097] train: loss: 0.1519257
[Epoch 21; Iter   620/ 1097] train: loss: 0.0790948
[Epoch 21; Iter   650/ 1097] train: loss: 0.2377174
[Epoch 21; Iter   680/ 1097] train: loss: 0.0748497
[Epoch 21; Iter   710/ 1097] train: loss: 0.0303713
[Epoch 21; Iter   740/ 1097] train: loss: 0.0358971
[Epoch 21; Iter   770/ 1097] train: loss: 0.0472346
[Epoch 21; Iter   800/ 1097] train: loss: 0.0714417
[Epoch 21; Iter   830/ 1097] train: loss: 0.2319302
[Epoch 21; Iter   860/ 1097] train: loss: 0.0494269
[Epoch 21; Iter   890/ 1097] train: loss: 0.0281598
[Epoch 21; Iter   920/ 1097] train: loss: 0.0789955
[Epoch 21; Iter   950/ 1097] train: loss: 0.0573499
[Epoch 21; Iter   980/ 1097] train: loss: 0.0230113
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0262024
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1669439
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0542483
[Epoch 21] ogbg-molhiv: 0.808351 val loss: 0.219503
[Epoch 21] ogbg-molhiv: 0.797180 test loss: 0.146853
[Epoch 22; Iter     3/ 1097] train: loss: 0.1620794
[Epoch 22; Iter    33/ 1097] train: loss: 0.0206446
[Epoch 22; Iter    63/ 1097] train: loss: 0.0566440
[Epoch 22; Iter    93/ 1097] train: loss: 0.0723523
[Epoch 22; Iter   123/ 1097] train: loss: 0.0374805
[Epoch 22; Iter   153/ 1097] train: loss: 0.0486311
[Epoch 22; Iter   183/ 1097] train: loss: 0.0438097
[Epoch 22; Iter   213/ 1097] train: loss: 0.1211783
[Epoch 22; Iter   243/ 1097] train: loss: 0.1613082
[Epoch 22; Iter   273/ 1097] train: loss: 0.2314117
[Epoch 22; Iter   303/ 1097] train: loss: 0.2042614
[Epoch 22; Iter   333/ 1097] train: loss: 0.0490486
[Epoch 22; Iter   363/ 1097] train: loss: 0.2597944
[Epoch 22; Iter   393/ 1097] train: loss: 0.0229455
[Epoch 22; Iter   423/ 1097] train: loss: 0.0817833
[Epoch 22; Iter   453/ 1097] train: loss: 0.0255008
[Epoch 22; Iter   483/ 1097] train: loss: 0.0739737
[Epoch 22; Iter   513/ 1097] train: loss: 0.3639046
[Epoch 22; Iter   543/ 1097] train: loss: 0.1824457
[Epoch 22; Iter   573/ 1097] train: loss: 0.0337088
[Epoch 22; Iter   603/ 1097] train: loss: 0.0306209
[Epoch 22; Iter   633/ 1097] train: loss: 0.0282728
[Epoch 22; Iter   663/ 1097] train: loss: 0.0347251
[Epoch 22; Iter   693/ 1097] train: loss: 0.1988091
[Epoch 22; Iter   723/ 1097] train: loss: 0.1420026
[Epoch 22; Iter   753/ 1097] train: loss: 0.2901906
[Epoch 22; Iter   783/ 1097] train: loss: 0.0349152
[Epoch 22; Iter   813/ 1097] train: loss: 0.1493181
[Epoch 22; Iter   843/ 1097] train: loss: 0.0345036
[Epoch 22; Iter   873/ 1097] train: loss: 0.0580409
[Epoch 22; Iter   903/ 1097] train: loss: 0.2961333
[Epoch 22; Iter   933/ 1097] train: loss: 0.0242939
[Epoch 22; Iter   963/ 1097] train: loss: 0.1898137
[Epoch 22; Iter   993/ 1097] train: loss: 0.1693206
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3711695
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0204633
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1506652
[Epoch 22] ogbg-molhiv: 0.817479 val loss: 0.282485
[Epoch 22] ogbg-molhiv: 0.787995 test loss: 0.139581
[Epoch 23; Iter    16/ 1097] train: loss: 0.0368182
[Epoch 23; Iter    46/ 1097] train: loss: 0.2848452
[Epoch 23; Iter    76/ 1097] train: loss: 0.1248685
[Epoch 23; Iter   106/ 1097] train: loss: 0.1814233
[Epoch 23; Iter   136/ 1097] train: loss: 0.0731159
[Epoch 23; Iter   166/ 1097] train: loss: 0.2232965
[Epoch 23; Iter   196/ 1097] train: loss: 0.1006002
[Epoch 23; Iter   226/ 1097] train: loss: 0.0695225
[Epoch 23; Iter   256/ 1097] train: loss: 0.1384970
[Epoch 23; Iter   286/ 1097] train: loss: 0.0269037
[Epoch 23; Iter   316/ 1097] train: loss: 0.0618117
[Epoch 23; Iter   346/ 1097] train: loss: 0.0513741
[Epoch 23; Iter   376/ 1097] train: loss: 0.0273799
[Epoch 23; Iter   406/ 1097] train: loss: 0.1713067
[Epoch 23; Iter   436/ 1097] train: loss: 0.0269278
[Epoch 23; Iter   466/ 1097] train: loss: 0.0191585
[Epoch 23; Iter   496/ 1097] train: loss: 0.2293218
[Epoch 23; Iter   526/ 1097] train: loss: 0.0771291
[Epoch 23; Iter   556/ 1097] train: loss: 0.0341179
[Epoch 23; Iter   586/ 1097] train: loss: 0.1181711
[Epoch 23; Iter   616/ 1097] train: loss: 0.1408063
[Epoch 23; Iter   646/ 1097] train: loss: 0.1508366
[Epoch 23; Iter   676/ 1097] train: loss: 0.0441046
[Epoch 23; Iter   706/ 1097] train: loss: 0.0295165
[Epoch 23; Iter   736/ 1097] train: loss: 0.2402091
[Epoch 23; Iter   766/ 1097] train: loss: 0.1735082
[Epoch 23; Iter   796/ 1097] train: loss: 0.0231108
[Epoch 23; Iter   826/ 1097] train: loss: 0.2357526
[Epoch 23; Iter   856/ 1097] train: loss: 0.2808636
[Epoch 23; Iter   886/ 1097] train: loss: 0.1426488
[Epoch 23; Iter   916/ 1097] train: loss: 0.2991890
[Epoch 23; Iter   946/ 1097] train: loss: 0.0221092
[Epoch 23; Iter   976/ 1097] train: loss: 0.2177678
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0215019
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0363057
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2301293
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0940164
[Epoch 23] ogbg-molhiv: 0.799686 val loss: 0.113949
[Epoch 23] ogbg-molhiv: 0.776512 test loss: 0.113278
[Epoch 24; Iter    29/ 1097] train: loss: 0.1118198
[Epoch 24; Iter    59/ 1097] train: loss: 0.2006258
[Epoch 24; Iter    89/ 1097] train: loss: 0.2675352
[Epoch 24; Iter   119/ 1097] train: loss: 0.0216800
[Epoch 24; Iter   149/ 1097] train: loss: 0.0532485
[Epoch 24; Iter   179/ 1097] train: loss: 0.0557682
[Epoch 24; Iter   209/ 1097] train: loss: 0.3008815
[Epoch 24; Iter   239/ 1097] train: loss: 0.0270283
[Epoch 24; Iter   269/ 1097] train: loss: 0.3610581
[Epoch 24; Iter   299/ 1097] train: loss: 0.0235767
[Epoch 24; Iter   329/ 1097] train: loss: 0.0257518
[Epoch 24; Iter   359/ 1097] train: loss: 0.0656842
[Epoch 24; Iter   389/ 1097] train: loss: 0.1195582
[Epoch 24; Iter   419/ 1097] train: loss: 0.2911288
[Epoch 24; Iter   449/ 1097] train: loss: 0.0198491
[Epoch 24; Iter   479/ 1097] train: loss: 0.0192918
[Epoch 24; Iter   509/ 1097] train: loss: 0.0288915
[Epoch 24; Iter   539/ 1097] train: loss: 0.0158013
[Epoch 24; Iter   569/ 1097] train: loss: 0.1079127
[Epoch 24; Iter   599/ 1097] train: loss: 0.2490322
[Epoch 24; Iter   629/ 1097] train: loss: 0.0126186
[Epoch 24; Iter   659/ 1097] train: loss: 0.0108061
[Epoch 24; Iter   689/ 1097] train: loss: 0.0093856
[Epoch 24; Iter   719/ 1097] train: loss: 0.0265927
[Epoch 24; Iter   749/ 1097] train: loss: 0.0531179
[Epoch 24; Iter   779/ 1097] train: loss: 0.0905985
[Epoch 24; Iter   809/ 1097] train: loss: 0.0547007
[Epoch 24; Iter   839/ 1097] train: loss: 0.1831638
[Epoch 24; Iter   869/ 1097] train: loss: 0.0938526
[Epoch 24; Iter   899/ 1097] train: loss: 0.3005301
[Epoch 24; Iter   929/ 1097] train: loss: 0.2578773
[Epoch 24; Iter   959/ 1097] train: loss: 0.0339648
[Epoch 24; Iter   989/ 1097] train: loss: 0.0466168
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1688363
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0298792
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0817630
[Epoch 24] ogbg-molhiv: 0.749014 val loss: 0.704617
[Epoch 24] ogbg-molhiv: 0.683070 test loss: 0.247458
[Epoch 25; Iter    12/ 1097] train: loss: 0.0364995
[Epoch 25; Iter    42/ 1097] train: loss: 0.0296675
[Epoch 25; Iter    72/ 1097] train: loss: 0.0190982
[Epoch 25; Iter   102/ 1097] train: loss: 0.1215291
[Epoch 25; Iter   132/ 1097] train: loss: 0.0219672
[Epoch 25; Iter   162/ 1097] train: loss: 0.0228822
[Epoch 25; Iter   192/ 1097] train: loss: 0.1466927
[Epoch 25; Iter   222/ 1097] train: loss: 0.0117392
[Epoch 25; Iter   252/ 1097] train: loss: 0.0541233
[Epoch 25; Iter   282/ 1097] train: loss: 0.1321159
[Epoch 25; Iter   312/ 1097] train: loss: 0.0253840
[Epoch 25; Iter   342/ 1097] train: loss: 0.0880375
[Epoch 25; Iter   372/ 1097] train: loss: 0.2686054
[Epoch 25; Iter   402/ 1097] train: loss: 0.0323875
[Epoch 25; Iter   432/ 1097] train: loss: 0.2645901
[Epoch 25; Iter   462/ 1097] train: loss: 0.0181304
[Epoch 25; Iter   492/ 1097] train: loss: 0.1309120
[Epoch 25; Iter   522/ 1097] train: loss: 0.0657804
[Epoch 25; Iter   552/ 1097] train: loss: 0.2201955
[Epoch 25; Iter   582/ 1097] train: loss: 0.0875154
[Epoch 25; Iter   612/ 1097] train: loss: 0.1526565
[Epoch 25; Iter   642/ 1097] train: loss: 0.1788267
[Epoch 25; Iter   672/ 1097] train: loss: 0.0144913
[Epoch 25; Iter   702/ 1097] train: loss: 0.1275643
[Epoch 25; Iter   732/ 1097] train: loss: 0.0526740
[Epoch 25; Iter   762/ 1097] train: loss: 0.1170264
[Epoch 25; Iter   792/ 1097] train: loss: 0.0150591
[Epoch 25; Iter   822/ 1097] train: loss: 0.0679048
[Epoch 25; Iter   852/ 1097] train: loss: 0.0298521
[Epoch 25; Iter   882/ 1097] train: loss: 0.0405755
[Epoch 25; Iter   912/ 1097] train: loss: 0.1399343
[Epoch 25; Iter   942/ 1097] train: loss: 0.0242768
[Epoch 25; Iter   972/ 1097] train: loss: 0.0941267
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2879366
[Epoch 25; Iter  1032/ 1097] train: loss: 0.1126788
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0931895
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1255537
[Epoch 25] ogbg-molhiv: 0.778837 val loss: 0.249951
[Epoch 25] ogbg-molhiv: 0.718909 test loss: 0.154699
[Epoch 26; Iter    25/ 1097] train: loss: 0.0564184
[Epoch 26; Iter    55/ 1097] train: loss: 0.0881875
[Epoch 26; Iter    85/ 1097] train: loss: 0.0686805
[Epoch 26; Iter   115/ 1097] train: loss: 0.1422258
[Epoch 26; Iter   145/ 1097] train: loss: 0.0578999
[Epoch 26; Iter   175/ 1097] train: loss: 0.0629489
[Epoch 26; Iter   205/ 1097] train: loss: 0.2412499
[Epoch 26; Iter   235/ 1097] train: loss: 0.0379102
[Epoch 26; Iter   265/ 1097] train: loss: 0.0483391
[Epoch 26; Iter   295/ 1097] train: loss: 0.1065008
[Epoch 26; Iter   325/ 1097] train: loss: 0.0180827
[Epoch 26; Iter   355/ 1097] train: loss: 0.0373888
[Epoch 26; Iter   385/ 1097] train: loss: 0.1071406
[Epoch 26; Iter   415/ 1097] train: loss: 0.0472675
[Epoch 26; Iter   445/ 1097] train: loss: 0.0162555
[Epoch 26; Iter   475/ 1097] train: loss: 0.1125462
[Epoch 26; Iter   505/ 1097] train: loss: 0.0756989
[Epoch 26; Iter   535/ 1097] train: loss: 0.1588925
[Epoch 26; Iter   565/ 1097] train: loss: 0.1191451
[Epoch 26; Iter   595/ 1097] train: loss: 0.0190072
[Epoch 26; Iter   625/ 1097] train: loss: 0.0666320
[Epoch 26; Iter   655/ 1097] train: loss: 0.0465377
[Epoch 26; Iter   685/ 1097] train: loss: 0.0853294
[Epoch 26; Iter   715/ 1097] train: loss: 0.0680388
[Epoch 26; Iter   745/ 1097] train: loss: 0.0200617
[Epoch 26; Iter   775/ 1097] train: loss: 0.0523963
[Epoch 26; Iter   805/ 1097] train: loss: 0.0431690
[Epoch 26; Iter   835/ 1097] train: loss: 0.1258051
[Epoch 26; Iter   865/ 1097] train: loss: 0.1778990
[Epoch 26; Iter   895/ 1097] train: loss: 0.0242165
[Epoch 26; Iter   925/ 1097] train: loss: 0.3070904
[Epoch 26; Iter   955/ 1097] train: loss: 0.0159025
[Epoch 26; Iter   985/ 1097] train: loss: 0.1241007
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0368930
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0202428
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1068907
[Epoch 26] ogbg-molhiv: 0.813223 val loss: 0.620041
[Epoch 26] ogbg-molhiv: 0.768379 test loss: 0.216701
[Epoch 27; Iter     8/ 1097] train: loss: 0.0404124
[Epoch 27; Iter    38/ 1097] train: loss: 0.0403787
[Epoch 27; Iter    68/ 1097] train: loss: 0.0106999
[Epoch 27; Iter    98/ 1097] train: loss: 0.2200765
[Epoch 27; Iter   128/ 1097] train: loss: 0.2598926
[Epoch 27; Iter   158/ 1097] train: loss: 0.0171125
[Epoch 27; Iter   188/ 1097] train: loss: 0.0421063
[Epoch 27; Iter   218/ 1097] train: loss: 0.0833440
[Epoch 27; Iter   248/ 1097] train: loss: 0.0279618
[Epoch 27; Iter   278/ 1097] train: loss: 0.0334966
[Epoch 27; Iter   308/ 1097] train: loss: 0.0735442
[Epoch 27; Iter   338/ 1097] train: loss: 0.0110270
[Epoch 27; Iter   368/ 1097] train: loss: 0.1242281
[Epoch 27; Iter   398/ 1097] train: loss: 0.0101739
[Epoch 27; Iter   428/ 1097] train: loss: 0.1639363
[Epoch 27; Iter   458/ 1097] train: loss: 0.0215042
[Epoch 27; Iter   488/ 1097] train: loss: 0.0600329
[Epoch 27; Iter   518/ 1097] train: loss: 0.0808459
[Epoch 27; Iter   548/ 1097] train: loss: 0.0631816
[Epoch 27; Iter   578/ 1097] train: loss: 0.0289248
[Epoch 27; Iter   608/ 1097] train: loss: 0.1323633
[Epoch 27; Iter   638/ 1097] train: loss: 0.0129749
[Epoch 27; Iter   668/ 1097] train: loss: 0.0339037
[Epoch 27; Iter   698/ 1097] train: loss: 0.0522567
[Epoch 27; Iter   728/ 1097] train: loss: 0.1698341
[Epoch 27; Iter   758/ 1097] train: loss: 0.0223749
[Epoch 27; Iter   788/ 1097] train: loss: 0.0237954
[Epoch 27; Iter   818/ 1097] train: loss: 0.0322646
[Epoch 27; Iter   848/ 1097] train: loss: 0.2257235
[Epoch 27; Iter   878/ 1097] train: loss: 0.0389280
[Epoch 27; Iter   908/ 1097] train: loss: 0.0130613
[Epoch 27; Iter   938/ 1097] train: loss: 0.0722629
[Epoch 27; Iter   968/ 1097] train: loss: 0.0483356
[Epoch 27; Iter   998/ 1097] train: loss: 0.0744520
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0111750
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2282802
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0913861
[Epoch 27] ogbg-molhiv: 0.783360 val loss: 0.089403
[Epoch 27] ogbg-molhiv: 0.718612 test loss: 0.145928
[Epoch 28; Iter    21/ 1097] train: loss: 0.0325874
[Epoch 28; Iter    51/ 1097] train: loss: 0.0398667
[Epoch 28; Iter    81/ 1097] train: loss: 0.0120479
[Epoch 28; Iter   111/ 1097] train: loss: 0.1521921
[Epoch 28; Iter   141/ 1097] train: loss: 0.0722430
[Epoch 28; Iter   171/ 1097] train: loss: 0.1003062
[Epoch 28; Iter   201/ 1097] train: loss: 0.1501792
[Epoch 28; Iter   231/ 1097] train: loss: 0.0470297
[Epoch 28; Iter   261/ 1097] train: loss: 0.1381638
[Epoch 28; Iter   291/ 1097] train: loss: 0.0379060
[Epoch 28; Iter   321/ 1097] train: loss: 0.0292048
[Epoch 28; Iter   351/ 1097] train: loss: 0.0131411
[Epoch 28; Iter   381/ 1097] train: loss: 0.0527095
[Epoch 28; Iter   411/ 1097] train: loss: 0.0207522
[Epoch 24; Iter   359/ 1097] train: loss: 0.1600152
[Epoch 24; Iter   389/ 1097] train: loss: 0.0262500
[Epoch 24; Iter   419/ 1097] train: loss: 0.0200608
[Epoch 24; Iter   449/ 1097] train: loss: 0.0253501
[Epoch 24; Iter   479/ 1097] train: loss: 0.2218833
[Epoch 24; Iter   509/ 1097] train: loss: 0.1406226
[Epoch 24; Iter   539/ 1097] train: loss: 0.0331794
[Epoch 24; Iter   569/ 1097] train: loss: 0.0830232
[Epoch 24; Iter   599/ 1097] train: loss: 0.1427702
[Epoch 24; Iter   629/ 1097] train: loss: 0.0207873
[Epoch 24; Iter   659/ 1097] train: loss: 0.1175787
[Epoch 24; Iter   689/ 1097] train: loss: 0.0393871
[Epoch 24; Iter   719/ 1097] train: loss: 0.0271380
[Epoch 24; Iter   749/ 1097] train: loss: 0.0265353
[Epoch 24; Iter   779/ 1097] train: loss: 0.1778207
[Epoch 24; Iter   809/ 1097] train: loss: 0.2052959
[Epoch 24; Iter   839/ 1097] train: loss: 0.0175982
[Epoch 24; Iter   869/ 1097] train: loss: 0.0204070
[Epoch 24; Iter   899/ 1097] train: loss: 0.0144545
[Epoch 24; Iter   929/ 1097] train: loss: 0.0625884
[Epoch 24; Iter   959/ 1097] train: loss: 0.0176077
[Epoch 24; Iter   989/ 1097] train: loss: 0.1134109
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3669811
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0174945
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1540827
[Epoch 24] ogbg-molhiv: 0.749130 val loss: 0.197548
[Epoch 24] ogbg-molhiv: 0.747052 test loss: 0.272813
[Epoch 25; Iter    12/ 1097] train: loss: 0.0190421
[Epoch 25; Iter    42/ 1097] train: loss: 0.0785796
[Epoch 25; Iter    72/ 1097] train: loss: 0.2579119
[Epoch 25; Iter   102/ 1097] train: loss: 0.0327240
[Epoch 25; Iter   132/ 1097] train: loss: 0.0189094
[Epoch 25; Iter   162/ 1097] train: loss: 0.0561610
[Epoch 25; Iter   192/ 1097] train: loss: 0.0460756
[Epoch 25; Iter   222/ 1097] train: loss: 0.1475510
[Epoch 25; Iter   252/ 1097] train: loss: 0.0086586
[Epoch 25; Iter   282/ 1097] train: loss: 0.0261952
[Epoch 25; Iter   312/ 1097] train: loss: 0.0120028
[Epoch 25; Iter   342/ 1097] train: loss: 0.0307608
[Epoch 25; Iter   372/ 1097] train: loss: 0.0273625
[Epoch 25; Iter   402/ 1097] train: loss: 0.0622720
[Epoch 25; Iter   432/ 1097] train: loss: 0.0539117
[Epoch 25; Iter   462/ 1097] train: loss: 0.0433138
[Epoch 25; Iter   492/ 1097] train: loss: 0.0623018
[Epoch 25; Iter   522/ 1097] train: loss: 0.0220946
[Epoch 25; Iter   552/ 1097] train: loss: 0.1155792
[Epoch 25; Iter   582/ 1097] train: loss: 0.1531578
[Epoch 25; Iter   612/ 1097] train: loss: 0.0116579
[Epoch 25; Iter   642/ 1097] train: loss: 0.2487844
[Epoch 25; Iter   672/ 1097] train: loss: 0.0217334
[Epoch 25; Iter   702/ 1097] train: loss: 0.0254504
[Epoch 25; Iter   732/ 1097] train: loss: 0.1576772
[Epoch 25; Iter   762/ 1097] train: loss: 0.1024710
[Epoch 25; Iter   792/ 1097] train: loss: 0.0582084
[Epoch 25; Iter   822/ 1097] train: loss: 0.0147855
[Epoch 25; Iter   852/ 1097] train: loss: 0.0235886
[Epoch 25; Iter   882/ 1097] train: loss: 0.0552239
[Epoch 25; Iter   912/ 1097] train: loss: 0.0309400
[Epoch 25; Iter   942/ 1097] train: loss: 0.1701831
[Epoch 25; Iter   972/ 1097] train: loss: 0.1113275
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0266758
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0530086
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1727538
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0146370
[Epoch 25] ogbg-molhiv: 0.759079 val loss: 0.124737
[Epoch 25] ogbg-molhiv: 0.782439 test loss: 0.128022
[Epoch 26; Iter    25/ 1097] train: loss: 0.1198978
[Epoch 26; Iter    55/ 1097] train: loss: 0.0763570
[Epoch 26; Iter    85/ 1097] train: loss: 0.1982664
[Epoch 26; Iter   115/ 1097] train: loss: 0.0717315
[Epoch 26; Iter   145/ 1097] train: loss: 0.0628076
[Epoch 26; Iter   175/ 1097] train: loss: 0.0707380
[Epoch 26; Iter   205/ 1097] train: loss: 0.0218279
[Epoch 26; Iter   235/ 1097] train: loss: 0.0753992
[Epoch 26; Iter   265/ 1097] train: loss: 0.0278230
[Epoch 26; Iter   295/ 1097] train: loss: 0.0552989
[Epoch 26; Iter   325/ 1097] train: loss: 0.0259987
[Epoch 26; Iter   355/ 1097] train: loss: 0.0953817
[Epoch 26; Iter   385/ 1097] train: loss: 0.0747694
[Epoch 26; Iter   415/ 1097] train: loss: 0.0181518
[Epoch 26; Iter   445/ 1097] train: loss: 0.0345550
[Epoch 26; Iter   475/ 1097] train: loss: 0.0191332
[Epoch 26; Iter   505/ 1097] train: loss: 0.0911462
[Epoch 26; Iter   535/ 1097] train: loss: 0.0118369
[Epoch 26; Iter   565/ 1097] train: loss: 0.0331740
[Epoch 26; Iter   595/ 1097] train: loss: 0.0498167
[Epoch 26; Iter   625/ 1097] train: loss: 0.0351079
[Epoch 26; Iter   655/ 1097] train: loss: 0.1388955
[Epoch 26; Iter   685/ 1097] train: loss: 0.1686085
[Epoch 26; Iter   715/ 1097] train: loss: 0.0516467
[Epoch 26; Iter   745/ 1097] train: loss: 0.0681002
[Epoch 26; Iter   775/ 1097] train: loss: 0.0843850
[Epoch 26; Iter   805/ 1097] train: loss: 0.0282076
[Epoch 26; Iter   835/ 1097] train: loss: 0.0187424
[Epoch 26; Iter   865/ 1097] train: loss: 0.0912078
[Epoch 26; Iter   895/ 1097] train: loss: 0.0244413
[Epoch 26; Iter   925/ 1097] train: loss: 0.0341030
[Epoch 26; Iter   955/ 1097] train: loss: 0.0590460
[Epoch 26; Iter   985/ 1097] train: loss: 0.0902796
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1875331
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0153799
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1697839
[Epoch 26] ogbg-molhiv: 0.770497 val loss: 0.273486
[Epoch 26] ogbg-molhiv: 0.757715 test loss: 0.421225
[Epoch 27; Iter     8/ 1097] train: loss: 0.0146822
[Epoch 27; Iter    38/ 1097] train: loss: 0.0691383
[Epoch 27; Iter    68/ 1097] train: loss: 0.0377298
[Epoch 27; Iter    98/ 1097] train: loss: 0.1033972
[Epoch 27; Iter   128/ 1097] train: loss: 0.0449016
[Epoch 27; Iter   158/ 1097] train: loss: 0.1225197
[Epoch 27; Iter   188/ 1097] train: loss: 0.0380088
[Epoch 27; Iter   218/ 1097] train: loss: 0.0409701
[Epoch 27; Iter   248/ 1097] train: loss: 0.0689968
[Epoch 27; Iter   278/ 1097] train: loss: 0.0730409
[Epoch 27; Iter   308/ 1097] train: loss: 0.0336521
[Epoch 27; Iter   338/ 1097] train: loss: 0.0765978
[Epoch 27; Iter   368/ 1097] train: loss: 0.1467565
[Epoch 27; Iter   398/ 1097] train: loss: 0.0735995
[Epoch 27; Iter   428/ 1097] train: loss: 0.0134639
[Epoch 27; Iter   458/ 1097] train: loss: 0.0256638
[Epoch 27; Iter   488/ 1097] train: loss: 0.1010309
[Epoch 27; Iter   518/ 1097] train: loss: 0.2129544
[Epoch 27; Iter   548/ 1097] train: loss: 0.1573289
[Epoch 27; Iter   578/ 1097] train: loss: 0.1520851
[Epoch 27; Iter   608/ 1097] train: loss: 0.0191075
[Epoch 27; Iter   638/ 1097] train: loss: 0.0224291
[Epoch 27; Iter   668/ 1097] train: loss: 0.0171843
[Epoch 27; Iter   698/ 1097] train: loss: 0.0244707
[Epoch 27; Iter   728/ 1097] train: loss: 0.0373070
[Epoch 27; Iter   758/ 1097] train: loss: 0.0121202
[Epoch 27; Iter   788/ 1097] train: loss: 0.1521563
[Epoch 27; Iter   818/ 1097] train: loss: 0.0403346
[Epoch 27; Iter   848/ 1097] train: loss: 0.0118208
[Epoch 27; Iter   878/ 1097] train: loss: 0.0263669
[Epoch 27; Iter   908/ 1097] train: loss: 0.1064813
[Epoch 27; Iter   938/ 1097] train: loss: 0.0421312
[Epoch 27; Iter   968/ 1097] train: loss: 0.1812013
[Epoch 27; Iter   998/ 1097] train: loss: 0.0926920
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1523992
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0363743
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0142242
[Epoch 27] ogbg-molhiv: 0.774177 val loss: 0.397629
[Epoch 27] ogbg-molhiv: 0.754538 test loss: 0.287439
[Epoch 28; Iter    21/ 1097] train: loss: 0.1527232
[Epoch 28; Iter    51/ 1097] train: loss: 0.1219814
[Epoch 28; Iter    81/ 1097] train: loss: 0.0415800
[Epoch 28; Iter   111/ 1097] train: loss: 0.0561322
[Epoch 28; Iter   141/ 1097] train: loss: 0.0208355
[Epoch 28; Iter   171/ 1097] train: loss: 0.0609946
[Epoch 28; Iter   201/ 1097] train: loss: 0.0366136
[Epoch 28; Iter   231/ 1097] train: loss: 0.0240381
[Epoch 28; Iter   261/ 1097] train: loss: 0.0090745
[Epoch 28; Iter   291/ 1097] train: loss: 0.1333352
[Epoch 28; Iter   321/ 1097] train: loss: 0.0517422
[Epoch 28; Iter   351/ 1097] train: loss: 0.0862832
[Epoch 28; Iter   381/ 1097] train: loss: 0.0302283
[Epoch 28; Iter   411/ 1097] train: loss: 0.0550071
[Epoch 24; Iter   359/ 1097] train: loss: 0.0345890
[Epoch 24; Iter   389/ 1097] train: loss: 0.0537417
[Epoch 24; Iter   419/ 1097] train: loss: 0.2392333
[Epoch 24; Iter   449/ 1097] train: loss: 0.0474281
[Epoch 24; Iter   479/ 1097] train: loss: 0.1064681
[Epoch 24; Iter   509/ 1097] train: loss: 0.1411708
[Epoch 24; Iter   539/ 1097] train: loss: 0.0240145
[Epoch 24; Iter   569/ 1097] train: loss: 0.1814860
[Epoch 24; Iter   599/ 1097] train: loss: 0.0309318
[Epoch 24; Iter   629/ 1097] train: loss: 0.0775810
[Epoch 24; Iter   659/ 1097] train: loss: 0.0236822
[Epoch 24; Iter   689/ 1097] train: loss: 0.0134822
[Epoch 24; Iter   719/ 1097] train: loss: 0.0332009
[Epoch 24; Iter   749/ 1097] train: loss: 0.1348560
[Epoch 24; Iter   779/ 1097] train: loss: 0.0186698
[Epoch 24; Iter   809/ 1097] train: loss: 0.1065094
[Epoch 24; Iter   839/ 1097] train: loss: 0.0457373
[Epoch 24; Iter   869/ 1097] train: loss: 0.0857877
[Epoch 24; Iter   899/ 1097] train: loss: 0.1132377
[Epoch 24; Iter   929/ 1097] train: loss: 0.2015867
[Epoch 24; Iter   959/ 1097] train: loss: 0.2820309
[Epoch 24; Iter   989/ 1097] train: loss: 0.0293158
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2764630
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1961485
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2501580
[Epoch 24] ogbg-molhiv: 0.714531 val loss: 0.167016
[Epoch 24] ogbg-molhiv: 0.702136 test loss: 0.168874
[Epoch 25; Iter    12/ 1097] train: loss: 0.1135518
[Epoch 25; Iter    42/ 1097] train: loss: 0.0423315
[Epoch 25; Iter    72/ 1097] train: loss: 0.0443146
[Epoch 25; Iter   102/ 1097] train: loss: 0.2434086
[Epoch 25; Iter   132/ 1097] train: loss: 0.1476808
[Epoch 25; Iter   162/ 1097] train: loss: 0.0354621
[Epoch 25; Iter   192/ 1097] train: loss: 0.0287732
[Epoch 25; Iter   222/ 1097] train: loss: 0.0663893
[Epoch 25; Iter   252/ 1097] train: loss: 0.0184330
[Epoch 25; Iter   282/ 1097] train: loss: 0.0568135
[Epoch 25; Iter   312/ 1097] train: loss: 0.0680259
[Epoch 25; Iter   342/ 1097] train: loss: 0.0215445
[Epoch 25; Iter   372/ 1097] train: loss: 0.0239249
[Epoch 25; Iter   402/ 1097] train: loss: 0.0244610
[Epoch 25; Iter   432/ 1097] train: loss: 0.0542017
[Epoch 25; Iter   462/ 1097] train: loss: 0.1270093
[Epoch 25; Iter   492/ 1097] train: loss: 0.0933141
[Epoch 25; Iter   522/ 1097] train: loss: 0.3224641
[Epoch 25; Iter   552/ 1097] train: loss: 0.1125551
[Epoch 25; Iter   582/ 1097] train: loss: 0.0624933
[Epoch 25; Iter   612/ 1097] train: loss: 0.0243441
[Epoch 25; Iter   642/ 1097] train: loss: 0.0174889
[Epoch 25; Iter   672/ 1097] train: loss: 0.0343571
[Epoch 25; Iter   702/ 1097] train: loss: 0.0759115
[Epoch 25; Iter   732/ 1097] train: loss: 0.0809247
[Epoch 25; Iter   762/ 1097] train: loss: 0.0791173
[Epoch 25; Iter   792/ 1097] train: loss: 0.0565379
[Epoch 25; Iter   822/ 1097] train: loss: 0.0238584
[Epoch 25; Iter   852/ 1097] train: loss: 0.0106762
[Epoch 25; Iter   882/ 1097] train: loss: 0.0466847
[Epoch 25; Iter   912/ 1097] train: loss: 0.0111367
[Epoch 25; Iter   942/ 1097] train: loss: 0.0866969
[Epoch 25; Iter   972/ 1097] train: loss: 0.0598889
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0697666
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0258076
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0289497
[Epoch 25; Iter  1092/ 1097] train: loss: 0.3384262
[Epoch 25] ogbg-molhiv: 0.735759 val loss: 0.121576
[Epoch 25] ogbg-molhiv: 0.751274 test loss: 0.153705
[Epoch 26; Iter    25/ 1097] train: loss: 0.0703936
[Epoch 26; Iter    55/ 1097] train: loss: 0.0123168
[Epoch 26; Iter    85/ 1097] train: loss: 0.0226551
[Epoch 26; Iter   115/ 1097] train: loss: 0.0480245
[Epoch 26; Iter   145/ 1097] train: loss: 0.2959261
[Epoch 26; Iter   175/ 1097] train: loss: 0.0388037
[Epoch 26; Iter   205/ 1097] train: loss: 0.3502905
[Epoch 26; Iter   235/ 1097] train: loss: 0.0633121
[Epoch 26; Iter   265/ 1097] train: loss: 0.0849547
[Epoch 26; Iter   295/ 1097] train: loss: 0.0523261
[Epoch 26; Iter   325/ 1097] train: loss: 0.0463745
[Epoch 26; Iter   355/ 1097] train: loss: 0.0185641
[Epoch 26; Iter   385/ 1097] train: loss: 0.0189185
[Epoch 26; Iter   415/ 1097] train: loss: 0.0181333
[Epoch 26; Iter   445/ 1097] train: loss: 0.0273831
[Epoch 26; Iter   475/ 1097] train: loss: 0.0254549
[Epoch 26; Iter   505/ 1097] train: loss: 0.0710579
[Epoch 26; Iter   535/ 1097] train: loss: 0.0258297
[Epoch 26; Iter   565/ 1097] train: loss: 0.2075762
[Epoch 26; Iter   595/ 1097] train: loss: 0.0370059
[Epoch 26; Iter   625/ 1097] train: loss: 0.0517120
[Epoch 26; Iter   655/ 1097] train: loss: 0.0895614
[Epoch 26; Iter   685/ 1097] train: loss: 0.0088738
[Epoch 26; Iter   715/ 1097] train: loss: 0.1477544
[Epoch 26; Iter   745/ 1097] train: loss: 0.0132355
[Epoch 26; Iter   775/ 1097] train: loss: 0.1524406
[Epoch 26; Iter   805/ 1097] train: loss: 0.0364766
[Epoch 26; Iter   835/ 1097] train: loss: 0.1707230
[Epoch 26; Iter   865/ 1097] train: loss: 0.0338440
[Epoch 26; Iter   895/ 1097] train: loss: 0.0180389
[Epoch 26; Iter   925/ 1097] train: loss: 0.2640837
[Epoch 26; Iter   955/ 1097] train: loss: 0.0234673
[Epoch 26; Iter   985/ 1097] train: loss: 0.0207659
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0376201
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0148311
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1208642
[Epoch 26] ogbg-molhiv: 0.703165 val loss: 0.118857
[Epoch 26] ogbg-molhiv: 0.703075 test loss: 0.300629
[Epoch 27; Iter     8/ 1097] train: loss: 0.0183569
[Epoch 27; Iter    38/ 1097] train: loss: 0.0435773
[Epoch 27; Iter    68/ 1097] train: loss: 0.3241957
[Epoch 27; Iter    98/ 1097] train: loss: 0.0111800
[Epoch 27; Iter   128/ 1097] train: loss: 0.0388923
[Epoch 27; Iter   158/ 1097] train: loss: 0.0762465
[Epoch 27; Iter   188/ 1097] train: loss: 0.0259180
[Epoch 27; Iter   218/ 1097] train: loss: 0.0199927
[Epoch 27; Iter   248/ 1097] train: loss: 0.0237739
[Epoch 27; Iter   278/ 1097] train: loss: 0.0323190
[Epoch 27; Iter   308/ 1097] train: loss: 0.0920487
[Epoch 27; Iter   338/ 1097] train: loss: 0.1040708
[Epoch 27; Iter   368/ 1097] train: loss: 0.0887070
[Epoch 27; Iter   398/ 1097] train: loss: 0.0148456
[Epoch 27; Iter   428/ 1097] train: loss: 0.0446879
[Epoch 27; Iter   458/ 1097] train: loss: 0.0162071
[Epoch 27; Iter   488/ 1097] train: loss: 0.0348014
[Epoch 27; Iter   518/ 1097] train: loss: 0.1698439
[Epoch 27; Iter   548/ 1097] train: loss: 0.0178477
[Epoch 27; Iter   578/ 1097] train: loss: 0.0420116
[Epoch 27; Iter   608/ 1097] train: loss: 0.0721994
[Epoch 27; Iter   638/ 1097] train: loss: 0.2611238
[Epoch 27; Iter   668/ 1097] train: loss: 0.1364424
[Epoch 27; Iter   698/ 1097] train: loss: 0.0340924
[Epoch 27; Iter   728/ 1097] train: loss: 0.0183897
[Epoch 27; Iter   758/ 1097] train: loss: 0.0211549
[Epoch 27; Iter   788/ 1097] train: loss: 0.0317272
[Epoch 27; Iter   818/ 1097] train: loss: 0.0106185
[Epoch 27; Iter   848/ 1097] train: loss: 0.0269756
[Epoch 27; Iter   878/ 1097] train: loss: 0.3199056
[Epoch 27; Iter   908/ 1097] train: loss: 0.1310001
[Epoch 27; Iter   938/ 1097] train: loss: 0.0947327
[Epoch 27; Iter   968/ 1097] train: loss: 0.0731611
[Epoch 27; Iter   998/ 1097] train: loss: 0.0329701
[Epoch 27; Iter  1028/ 1097] train: loss: 0.2957917
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0840539
[Epoch 27; Iter  1088/ 1097] train: loss: 0.2452347
[Epoch 27] ogbg-molhiv: 0.694849 val loss: 0.145850
[Epoch 27] ogbg-molhiv: 0.724680 test loss: 0.168182
[Epoch 28; Iter    21/ 1097] train: loss: 0.1552746
[Epoch 28; Iter    51/ 1097] train: loss: 0.1139522
[Epoch 28; Iter    81/ 1097] train: loss: 0.1318445
[Epoch 28; Iter   111/ 1097] train: loss: 0.1680706
[Epoch 28; Iter   141/ 1097] train: loss: 0.0156680
[Epoch 28; Iter   171/ 1097] train: loss: 0.0080945
[Epoch 28; Iter   201/ 1097] train: loss: 0.0281531
[Epoch 28; Iter   231/ 1097] train: loss: 0.0196841
[Epoch 28; Iter   261/ 1097] train: loss: 0.0805389
[Epoch 28; Iter   291/ 1097] train: loss: 0.0157263
[Epoch 28; Iter   321/ 1097] train: loss: 0.0104330
[Epoch 28; Iter   351/ 1097] train: loss: 0.0272790
[Epoch 28; Iter   381/ 1097] train: loss: 0.0118134
[Epoch 28; Iter   411/ 1097] train: loss: 0.2593742
[Epoch 24; Iter   359/ 1097] train: loss: 0.0492159
[Epoch 24; Iter   389/ 1097] train: loss: 0.0146697
[Epoch 24; Iter   419/ 1097] train: loss: 0.3090803
[Epoch 24; Iter   449/ 1097] train: loss: 0.0557365
[Epoch 24; Iter   479/ 1097] train: loss: 0.0548352
[Epoch 24; Iter   509/ 1097] train: loss: 0.0550530
[Epoch 24; Iter   539/ 1097] train: loss: 0.0368887
[Epoch 24; Iter   569/ 1097] train: loss: 0.1764663
[Epoch 24; Iter   599/ 1097] train: loss: 0.0527710
[Epoch 24; Iter   629/ 1097] train: loss: 0.0398218
[Epoch 24; Iter   659/ 1097] train: loss: 0.0374186
[Epoch 24; Iter   689/ 1097] train: loss: 0.0072887
[Epoch 24; Iter   719/ 1097] train: loss: 0.1448952
[Epoch 24; Iter   749/ 1097] train: loss: 0.0241546
[Epoch 24; Iter   779/ 1097] train: loss: 0.0524619
[Epoch 24; Iter   809/ 1097] train: loss: 0.0728527
[Epoch 24; Iter   839/ 1097] train: loss: 0.0792083
[Epoch 24; Iter   869/ 1097] train: loss: 0.0915218
[Epoch 24; Iter   899/ 1097] train: loss: 0.2844937
[Epoch 24; Iter   929/ 1097] train: loss: 0.0462151
[Epoch 24; Iter   959/ 1097] train: loss: 0.1385621
[Epoch 24; Iter   989/ 1097] train: loss: 0.0205804
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2380193
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1279862
[Epoch 24; Iter  1079/ 1097] train: loss: 0.3587836
[Epoch 24] ogbg-molhiv: 0.762707 val loss: 0.108063
[Epoch 24] ogbg-molhiv: 0.724821 test loss: 0.176745
[Epoch 25; Iter    12/ 1097] train: loss: 0.2589449
[Epoch 25; Iter    42/ 1097] train: loss: 0.0421384
[Epoch 25; Iter    72/ 1097] train: loss: 0.0207129
[Epoch 25; Iter   102/ 1097] train: loss: 0.3899565
[Epoch 25; Iter   132/ 1097] train: loss: 0.3202308
[Epoch 25; Iter   162/ 1097] train: loss: 0.0180048
[Epoch 25; Iter   192/ 1097] train: loss: 0.0189033
[Epoch 25; Iter   222/ 1097] train: loss: 0.0823667
[Epoch 25; Iter   252/ 1097] train: loss: 0.0568908
[Epoch 25; Iter   282/ 1097] train: loss: 0.0935385
[Epoch 25; Iter   312/ 1097] train: loss: 0.0338122
[Epoch 25; Iter   342/ 1097] train: loss: 0.0735662
[Epoch 25; Iter   372/ 1097] train: loss: 0.0345912
[Epoch 25; Iter   402/ 1097] train: loss: 0.0233758
[Epoch 25; Iter   432/ 1097] train: loss: 0.0364220
[Epoch 25; Iter   462/ 1097] train: loss: 0.0907544
[Epoch 25; Iter   492/ 1097] train: loss: 0.0650770
[Epoch 25; Iter   522/ 1097] train: loss: 0.3277328
[Epoch 25; Iter   552/ 1097] train: loss: 0.1750288
[Epoch 25; Iter   582/ 1097] train: loss: 0.1145765
[Epoch 25; Iter   612/ 1097] train: loss: 0.0221610
[Epoch 25; Iter   642/ 1097] train: loss: 0.0200205
[Epoch 25; Iter   672/ 1097] train: loss: 0.0239034
[Epoch 25; Iter   702/ 1097] train: loss: 0.0184036
[Epoch 25; Iter   732/ 1097] train: loss: 0.0836368
[Epoch 25; Iter   762/ 1097] train: loss: 0.0328809
[Epoch 25; Iter   792/ 1097] train: loss: 0.0244574
[Epoch 25; Iter   822/ 1097] train: loss: 0.0319469
[Epoch 25; Iter   852/ 1097] train: loss: 0.0179282
[Epoch 25; Iter   882/ 1097] train: loss: 0.0312272
[Epoch 25; Iter   912/ 1097] train: loss: 0.0211573
[Epoch 25; Iter   942/ 1097] train: loss: 0.1906275
[Epoch 25; Iter   972/ 1097] train: loss: 0.1379173
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0500555
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0143597
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0360259
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1741314
[Epoch 25] ogbg-molhiv: 0.794398 val loss: 0.134812
[Epoch 25] ogbg-molhiv: 0.767000 test loss: 0.148246
[Epoch 26; Iter    25/ 1097] train: loss: 0.0833850
[Epoch 26; Iter    55/ 1097] train: loss: 0.0198677
[Epoch 26; Iter    85/ 1097] train: loss: 0.0543563
[Epoch 26; Iter   115/ 1097] train: loss: 0.0417479
[Epoch 26; Iter   145/ 1097] train: loss: 0.1514589
[Epoch 26; Iter   175/ 1097] train: loss: 0.0728418
[Epoch 26; Iter   205/ 1097] train: loss: 0.2430453
[Epoch 26; Iter   235/ 1097] train: loss: 0.0946444
[Epoch 26; Iter   265/ 1097] train: loss: 0.1180935
[Epoch 26; Iter   295/ 1097] train: loss: 0.0702874
[Epoch 26; Iter   325/ 1097] train: loss: 0.0238027
[Epoch 26; Iter   355/ 1097] train: loss: 0.0228947
[Epoch 26; Iter   385/ 1097] train: loss: 0.0274313
[Epoch 26; Iter   415/ 1097] train: loss: 0.0180490
[Epoch 26; Iter   445/ 1097] train: loss: 0.0341470
[Epoch 26; Iter   475/ 1097] train: loss: 0.0312126
[Epoch 26; Iter   505/ 1097] train: loss: 0.0556966
[Epoch 26; Iter   535/ 1097] train: loss: 0.1128127
[Epoch 26; Iter   565/ 1097] train: loss: 0.3130617
[Epoch 26; Iter   595/ 1097] train: loss: 0.0340409
[Epoch 26; Iter   625/ 1097] train: loss: 0.0178025
[Epoch 26; Iter   655/ 1097] train: loss: 0.0475988
[Epoch 26; Iter   685/ 1097] train: loss: 0.0947455
[Epoch 26; Iter   715/ 1097] train: loss: 0.0818079
[Epoch 26; Iter   745/ 1097] train: loss: 0.0889628
[Epoch 26; Iter   775/ 1097] train: loss: 0.1360566
[Epoch 26; Iter   805/ 1097] train: loss: 0.0697926
[Epoch 26; Iter   835/ 1097] train: loss: 0.1699861
[Epoch 26; Iter   865/ 1097] train: loss: 0.0415439
[Epoch 26; Iter   895/ 1097] train: loss: 0.0384637
[Epoch 26; Iter   925/ 1097] train: loss: 0.1876329
[Epoch 26; Iter   955/ 1097] train: loss: 0.0221387
[Epoch 26; Iter   985/ 1097] train: loss: 0.0155123
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0624149
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0184780
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2078917
[Epoch 26] ogbg-molhiv: 0.786434 val loss: 0.126031
[Epoch 26] ogbg-molhiv: 0.727434 test loss: 0.181618
[Epoch 27; Iter     8/ 1097] train: loss: 0.0139453
[Epoch 27; Iter    38/ 1097] train: loss: 0.0612172
[Epoch 27; Iter    68/ 1097] train: loss: 0.1226574
[Epoch 27; Iter    98/ 1097] train: loss: 0.0351734
[Epoch 27; Iter   128/ 1097] train: loss: 0.0393373
[Epoch 27; Iter   158/ 1097] train: loss: 0.0108301
[Epoch 27; Iter   188/ 1097] train: loss: 0.0264322
[Epoch 27; Iter   218/ 1097] train: loss: 0.0660096
[Epoch 27; Iter   248/ 1097] train: loss: 0.0149644
[Epoch 27; Iter   278/ 1097] train: loss: 0.0114442
[Epoch 27; Iter   308/ 1097] train: loss: 0.0574343
[Epoch 27; Iter   338/ 1097] train: loss: 0.0667259
[Epoch 27; Iter   368/ 1097] train: loss: 0.1686570
[Epoch 27; Iter   398/ 1097] train: loss: 0.0164848
[Epoch 27; Iter   428/ 1097] train: loss: 0.0200433
[Epoch 27; Iter   458/ 1097] train: loss: 0.0114754
[Epoch 27; Iter   488/ 1097] train: loss: 0.0370386
[Epoch 27; Iter   518/ 1097] train: loss: 0.1198706
[Epoch 27; Iter   548/ 1097] train: loss: 0.0939941
[Epoch 27; Iter   578/ 1097] train: loss: 0.0467549
[Epoch 27; Iter   608/ 1097] train: loss: 0.0624778
[Epoch 27; Iter   638/ 1097] train: loss: 0.1584511
[Epoch 27; Iter   668/ 1097] train: loss: 0.2253661
[Epoch 27; Iter   698/ 1097] train: loss: 0.0488061
[Epoch 27; Iter   728/ 1097] train: loss: 0.0383441
[Epoch 27; Iter   758/ 1097] train: loss: 0.0348134
[Epoch 27; Iter   788/ 1097] train: loss: 0.0520881
[Epoch 27; Iter   818/ 1097] train: loss: 0.0258709
[Epoch 27; Iter   848/ 1097] train: loss: 0.0357310
[Epoch 27; Iter   878/ 1097] train: loss: 0.2748835
[Epoch 27; Iter   908/ 1097] train: loss: 0.1038085
[Epoch 27; Iter   938/ 1097] train: loss: 0.0730733
[Epoch 27; Iter   968/ 1097] train: loss: 0.0340026
[Epoch 27; Iter   998/ 1097] train: loss: 0.0242612
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1883649
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0460997
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1723748
[Epoch 27] ogbg-molhiv: 0.807233 val loss: 0.079193
[Epoch 27] ogbg-molhiv: 0.769640 test loss: 0.132253
[Epoch 28; Iter    21/ 1097] train: loss: 0.0373609
[Epoch 28; Iter    51/ 1097] train: loss: 0.0191924
[Epoch 28; Iter    81/ 1097] train: loss: 0.0143496
[Epoch 28; Iter   111/ 1097] train: loss: 0.0915302
[Epoch 28; Iter   141/ 1097] train: loss: 0.0442606
[Epoch 28; Iter   171/ 1097] train: loss: 0.0570003
[Epoch 28; Iter   201/ 1097] train: loss: 0.0102461
[Epoch 28; Iter   231/ 1097] train: loss: 0.0230082
[Epoch 28; Iter   261/ 1097] train: loss: 0.0362527
[Epoch 28; Iter   291/ 1097] train: loss: 0.0476914
[Epoch 28; Iter   321/ 1097] train: loss: 0.0270765
[Epoch 28; Iter   351/ 1097] train: loss: 0.0071714
[Epoch 28; Iter   381/ 1097] train: loss: 0.0291776
[Epoch 28; Iter   411/ 1097] train: loss: 0.1495233
[Epoch 24; Iter   359/ 1097] train: loss: 0.2864495
[Epoch 24; Iter   389/ 1097] train: loss: 0.0181599
[Epoch 24; Iter   419/ 1097] train: loss: 0.0180497
[Epoch 24; Iter   449/ 1097] train: loss: 0.0296502
[Epoch 24; Iter   479/ 1097] train: loss: 0.0663115
[Epoch 24; Iter   509/ 1097] train: loss: 0.1987914
[Epoch 24; Iter   539/ 1097] train: loss: 0.1214673
[Epoch 24; Iter   569/ 1097] train: loss: 0.0921690
[Epoch 24; Iter   599/ 1097] train: loss: 0.0852180
[Epoch 24; Iter   629/ 1097] train: loss: 0.0717198
[Epoch 24; Iter   659/ 1097] train: loss: 0.1019437
[Epoch 24; Iter   689/ 1097] train: loss: 0.0942650
[Epoch 24; Iter   719/ 1097] train: loss: 0.0582360
[Epoch 24; Iter   749/ 1097] train: loss: 0.0149150
[Epoch 24; Iter   779/ 1097] train: loss: 0.2183331
[Epoch 24; Iter   809/ 1097] train: loss: 0.0848105
[Epoch 24; Iter   839/ 1097] train: loss: 0.0552774
[Epoch 24; Iter   869/ 1097] train: loss: 0.0619621
[Epoch 24; Iter   899/ 1097] train: loss: 0.0426047
[Epoch 24; Iter   929/ 1097] train: loss: 0.0567767
[Epoch 24; Iter   959/ 1097] train: loss: 0.0131716
[Epoch 24; Iter   989/ 1097] train: loss: 0.0841102
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3775261
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0269410
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0364824
[Epoch 24] ogbg-molhiv: 0.731264 val loss: 5.605679
[Epoch 24] ogbg-molhiv: 0.703919 test loss: 3.322900
[Epoch 25; Iter    12/ 1097] train: loss: 0.0334677
[Epoch 25; Iter    42/ 1097] train: loss: 0.1428874
[Epoch 25; Iter    72/ 1097] train: loss: 0.1772482
[Epoch 25; Iter   102/ 1097] train: loss: 0.0422385
[Epoch 25; Iter   132/ 1097] train: loss: 0.0580514
[Epoch 25; Iter   162/ 1097] train: loss: 0.0290747
[Epoch 25; Iter   192/ 1097] train: loss: 0.0099017
[Epoch 25; Iter   222/ 1097] train: loss: 0.1050274
[Epoch 25; Iter   252/ 1097] train: loss: 0.0097279
[Epoch 25; Iter   282/ 1097] train: loss: 0.0299950
[Epoch 25; Iter   312/ 1097] train: loss: 0.0346470
[Epoch 25; Iter   342/ 1097] train: loss: 0.0563978
[Epoch 25; Iter   372/ 1097] train: loss: 0.0156861
[Epoch 25; Iter   402/ 1097] train: loss: 0.0209446
[Epoch 25; Iter   432/ 1097] train: loss: 0.1562761
[Epoch 25; Iter   462/ 1097] train: loss: 0.1292843
[Epoch 25; Iter   492/ 1097] train: loss: 0.0667944
[Epoch 25; Iter   522/ 1097] train: loss: 0.0314320
[Epoch 25; Iter   552/ 1097] train: loss: 0.2545423
[Epoch 25; Iter   582/ 1097] train: loss: 0.1678255
[Epoch 25; Iter   612/ 1097] train: loss: 0.0188521
[Epoch 25; Iter   642/ 1097] train: loss: 0.3780055
[Epoch 25; Iter   672/ 1097] train: loss: 0.0579596
[Epoch 25; Iter   702/ 1097] train: loss: 0.1422524
[Epoch 25; Iter   732/ 1097] train: loss: 0.1489885
[Epoch 25; Iter   762/ 1097] train: loss: 0.1003425
[Epoch 25; Iter   792/ 1097] train: loss: 0.1398415
[Epoch 25; Iter   822/ 1097] train: loss: 0.0318975
[Epoch 25; Iter   852/ 1097] train: loss: 0.1771872
[Epoch 25; Iter   882/ 1097] train: loss: 0.0383307
[Epoch 25; Iter   912/ 1097] train: loss: 0.0427956
[Epoch 25; Iter   942/ 1097] train: loss: 0.2787941
[Epoch 25; Iter   972/ 1097] train: loss: 0.1305371
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0814550
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0593202
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1356544
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0138157
[Epoch 25] ogbg-molhiv: 0.730379 val loss: 0.103671
[Epoch 25] ogbg-molhiv: 0.692816 test loss: 0.196233
[Epoch 26; Iter    25/ 1097] train: loss: 0.0912878
[Epoch 26; Iter    55/ 1097] train: loss: 0.0239375
[Epoch 26; Iter    85/ 1097] train: loss: 0.2569779
[Epoch 26; Iter   115/ 1097] train: loss: 0.0253577
[Epoch 26; Iter   145/ 1097] train: loss: 0.0312837
[Epoch 26; Iter   175/ 1097] train: loss: 0.0589344
[Epoch 26; Iter   205/ 1097] train: loss: 0.0167577
[Epoch 26; Iter   235/ 1097] train: loss: 0.0275682
[Epoch 26; Iter   265/ 1097] train: loss: 0.0630102
[Epoch 26; Iter   295/ 1097] train: loss: 0.0614978
[Epoch 26; Iter   325/ 1097] train: loss: 0.0504092
[Epoch 26; Iter   355/ 1097] train: loss: 0.0967114
[Epoch 26; Iter   385/ 1097] train: loss: 0.0650975
[Epoch 26; Iter   415/ 1097] train: loss: 0.0275999
[Epoch 26; Iter   445/ 1097] train: loss: 0.0189972
[Epoch 26; Iter   475/ 1097] train: loss: 0.0171439
[Epoch 26; Iter   505/ 1097] train: loss: 0.1047182
[Epoch 26; Iter   535/ 1097] train: loss: 0.0337363
[Epoch 26; Iter   565/ 1097] train: loss: 0.1917464
[Epoch 26; Iter   595/ 1097] train: loss: 0.0170472
[Epoch 26; Iter   625/ 1097] train: loss: 0.1929983
[Epoch 26; Iter   655/ 1097] train: loss: 0.1551031
[Epoch 26; Iter   685/ 1097] train: loss: 0.0548423
[Epoch 26; Iter   715/ 1097] train: loss: 0.0364824
[Epoch 26; Iter   745/ 1097] train: loss: 0.0412557
[Epoch 26; Iter   775/ 1097] train: loss: 0.2046323
[Epoch 26; Iter   805/ 1097] train: loss: 0.0974190
[Epoch 26; Iter   835/ 1097] train: loss: 0.0142221
[Epoch 26; Iter   865/ 1097] train: loss: 0.2862691
[Epoch 26; Iter   895/ 1097] train: loss: 0.0170387
[Epoch 26; Iter   925/ 1097] train: loss: 0.1057811
[Epoch 26; Iter   955/ 1097] train: loss: 0.0207266
[Epoch 26; Iter   985/ 1097] train: loss: 0.0364662
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1401847
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0285624
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1233002
[Epoch 26] ogbg-molhiv: 0.731534 val loss: 0.101576
[Epoch 26] ogbg-molhiv: 0.716422 test loss: 0.155874
[Epoch 27; Iter     8/ 1097] train: loss: 0.0297771
[Epoch 27; Iter    38/ 1097] train: loss: 0.1454754
[Epoch 27; Iter    68/ 1097] train: loss: 0.0246021
[Epoch 27; Iter    98/ 1097] train: loss: 0.0375884
[Epoch 27; Iter   128/ 1097] train: loss: 0.0217945
[Epoch 27; Iter   158/ 1097] train: loss: 0.0456786
[Epoch 27; Iter   188/ 1097] train: loss: 0.0170391
[Epoch 27; Iter   218/ 1097] train: loss: 0.0939108
[Epoch 27; Iter   248/ 1097] train: loss: 0.0963852
[Epoch 27; Iter   278/ 1097] train: loss: 0.0817048
[Epoch 27; Iter   308/ 1097] train: loss: 0.0256687
[Epoch 27; Iter   338/ 1097] train: loss: 0.0207985
[Epoch 27; Iter   368/ 1097] train: loss: 0.1325480
[Epoch 27; Iter   398/ 1097] train: loss: 0.1735025
[Epoch 27; Iter   428/ 1097] train: loss: 0.0130904
[Epoch 27; Iter   458/ 1097] train: loss: 0.0059060
[Epoch 27; Iter   488/ 1097] train: loss: 0.0622077
[Epoch 27; Iter   518/ 1097] train: loss: 0.1707876
[Epoch 27; Iter   548/ 1097] train: loss: 0.0994809
[Epoch 27; Iter   578/ 1097] train: loss: 0.1233990
[Epoch 27; Iter   608/ 1097] train: loss: 0.0178803
[Epoch 27; Iter   638/ 1097] train: loss: 0.0191227
[Epoch 27; Iter   668/ 1097] train: loss: 0.0857965
[Epoch 27; Iter   698/ 1097] train: loss: 0.1966283
[Epoch 27; Iter   728/ 1097] train: loss: 0.0522772
[Epoch 27; Iter   758/ 1097] train: loss: 0.0243668
[Epoch 27; Iter   788/ 1097] train: loss: 0.1076644
[Epoch 27; Iter   818/ 1097] train: loss: 0.0733273
[Epoch 27; Iter   848/ 1097] train: loss: 0.0185644
[Epoch 27; Iter   878/ 1097] train: loss: 0.0566982
[Epoch 27; Iter   908/ 1097] train: loss: 0.2294988
[Epoch 27; Iter   938/ 1097] train: loss: 0.0753743
[Epoch 27; Iter   968/ 1097] train: loss: 0.1611068
[Epoch 27; Iter   998/ 1097] train: loss: 0.0781427
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0793860
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0487166
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0390562
[Epoch 27] ogbg-molhiv: 0.774961 val loss: 0.116750
[Epoch 27] ogbg-molhiv: 0.721066 test loss: 0.190640
[Epoch 28; Iter    21/ 1097] train: loss: 0.1162777
[Epoch 28; Iter    51/ 1097] train: loss: 0.0685409
[Epoch 28; Iter    81/ 1097] train: loss: 0.0174055
[Epoch 28; Iter   111/ 1097] train: loss: 0.0305402
[Epoch 28; Iter   141/ 1097] train: loss: 0.0350793
[Epoch 28; Iter   171/ 1097] train: loss: 0.0773435
[Epoch 28; Iter   201/ 1097] train: loss: 0.0292351
[Epoch 28; Iter   231/ 1097] train: loss: 0.0141270
[Epoch 28; Iter   261/ 1097] train: loss: 0.0051820
[Epoch 28; Iter   291/ 1097] train: loss: 0.0880959
[Epoch 28; Iter   321/ 1097] train: loss: 0.0130673
[Epoch 28; Iter   351/ 1097] train: loss: 0.2265111
[Epoch 28; Iter   381/ 1097] train: loss: 0.0154155
[Epoch 28; Iter   411/ 1097] train: loss: 0.0910607
[Epoch 24; Iter   359/ 1097] train: loss: 0.1343387
[Epoch 24; Iter   389/ 1097] train: loss: 0.1991492
[Epoch 24; Iter   419/ 1097] train: loss: 0.2204582
[Epoch 24; Iter   449/ 1097] train: loss: 0.0330333
[Epoch 24; Iter   479/ 1097] train: loss: 0.0248507
[Epoch 24; Iter   509/ 1097] train: loss: 0.0286401
[Epoch 24; Iter   539/ 1097] train: loss: 0.0183008
[Epoch 24; Iter   569/ 1097] train: loss: 0.1988848
[Epoch 24; Iter   599/ 1097] train: loss: 0.1478197
[Epoch 24; Iter   629/ 1097] train: loss: 0.0142215
[Epoch 24; Iter   659/ 1097] train: loss: 0.0287547
[Epoch 24; Iter   689/ 1097] train: loss: 0.0075703
[Epoch 24; Iter   719/ 1097] train: loss: 0.0218766
[Epoch 24; Iter   749/ 1097] train: loss: 0.0491971
[Epoch 24; Iter   779/ 1097] train: loss: 0.0947890
[Epoch 24; Iter   809/ 1097] train: loss: 0.0308419
[Epoch 24; Iter   839/ 1097] train: loss: 0.2356485
[Epoch 24; Iter   869/ 1097] train: loss: 0.1335805
[Epoch 24; Iter   899/ 1097] train: loss: 0.1089687
[Epoch 24; Iter   929/ 1097] train: loss: 0.3314334
[Epoch 24; Iter   959/ 1097] train: loss: 0.0315820
[Epoch 24; Iter   989/ 1097] train: loss: 0.0157805
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1255877
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0371466
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0268639
[Epoch 24] ogbg-molhiv: 0.759388 val loss: 0.144412
[Epoch 24] ogbg-molhiv: 0.796798 test loss: 0.151652
[Epoch 25; Iter    12/ 1097] train: loss: 0.0150675
[Epoch 25; Iter    42/ 1097] train: loss: 0.1263291
[Epoch 25; Iter    72/ 1097] train: loss: 0.0183989
[Epoch 25; Iter   102/ 1097] train: loss: 0.0171655
[Epoch 25; Iter   132/ 1097] train: loss: 0.0164461
[Epoch 25; Iter   162/ 1097] train: loss: 0.0492072
[Epoch 25; Iter   192/ 1097] train: loss: 0.0441226
[Epoch 25; Iter   222/ 1097] train: loss: 0.0194369
[Epoch 25; Iter   252/ 1097] train: loss: 0.0764577
[Epoch 25; Iter   282/ 1097] train: loss: 0.1003289
[Epoch 25; Iter   312/ 1097] train: loss: 0.0235536
[Epoch 25; Iter   342/ 1097] train: loss: 0.0555292
[Epoch 25; Iter   372/ 1097] train: loss: 0.1693350
[Epoch 25; Iter   402/ 1097] train: loss: 0.0390404
[Epoch 25; Iter   432/ 1097] train: loss: 0.2465944
[Epoch 25; Iter   462/ 1097] train: loss: 0.0296719
[Epoch 25; Iter   492/ 1097] train: loss: 0.1307019
[Epoch 25; Iter   522/ 1097] train: loss: 0.0135714
[Epoch 25; Iter   552/ 1097] train: loss: 0.1252947
[Epoch 25; Iter   582/ 1097] train: loss: 0.0405208
[Epoch 25; Iter   612/ 1097] train: loss: 0.2467173
[Epoch 25; Iter   642/ 1097] train: loss: 0.1067254
[Epoch 25; Iter   672/ 1097] train: loss: 0.0242878
[Epoch 25; Iter   702/ 1097] train: loss: 0.2145158
[Epoch 25; Iter   732/ 1097] train: loss: 0.0311048
[Epoch 25; Iter   762/ 1097] train: loss: 0.0827562
[Epoch 25; Iter   792/ 1097] train: loss: 0.0225830
[Epoch 25; Iter   822/ 1097] train: loss: 0.0684966
[Epoch 25; Iter   852/ 1097] train: loss: 0.0201953
[Epoch 25; Iter   882/ 1097] train: loss: 0.0926072
[Epoch 25; Iter   912/ 1097] train: loss: 0.2090856
[Epoch 25; Iter   942/ 1097] train: loss: 0.1212003
[Epoch 25; Iter   972/ 1097] train: loss: 0.0856000
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1446115
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0950935
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0226471
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1759589
[Epoch 25] ogbg-molhiv: 0.771360 val loss: 0.327020
[Epoch 25] ogbg-molhiv: 0.765775 test loss: 0.140142
[Epoch 26; Iter    25/ 1097] train: loss: 0.0195068
[Epoch 26; Iter    55/ 1097] train: loss: 0.0552898
[Epoch 26; Iter    85/ 1097] train: loss: 0.1482977
[Epoch 26; Iter   115/ 1097] train: loss: 0.0845415
[Epoch 26; Iter   145/ 1097] train: loss: 0.0968212
[Epoch 26; Iter   175/ 1097] train: loss: 0.0875691
[Epoch 26; Iter   205/ 1097] train: loss: 0.3280583
[Epoch 26; Iter   235/ 1097] train: loss: 0.0580519
[Epoch 26; Iter   265/ 1097] train: loss: 0.0385954
[Epoch 26; Iter   295/ 1097] train: loss: 0.0935961
[Epoch 26; Iter   325/ 1097] train: loss: 0.0299321
[Epoch 26; Iter   355/ 1097] train: loss: 0.0205835
[Epoch 26; Iter   385/ 1097] train: loss: 0.0576569
[Epoch 26; Iter   415/ 1097] train: loss: 0.0351279
[Epoch 26; Iter   445/ 1097] train: loss: 0.0175116
[Epoch 26; Iter   475/ 1097] train: loss: 0.0950966
[Epoch 26; Iter   505/ 1097] train: loss: 0.0381564
[Epoch 26; Iter   535/ 1097] train: loss: 0.0725012
[Epoch 26; Iter   565/ 1097] train: loss: 0.0444830
[Epoch 26; Iter   595/ 1097] train: loss: 0.0504205
[Epoch 26; Iter   625/ 1097] train: loss: 0.0381438
[Epoch 26; Iter   655/ 1097] train: loss: 0.0297795
[Epoch 26; Iter   685/ 1097] train: loss: 0.1305439
[Epoch 26; Iter   715/ 1097] train: loss: 0.0118909
[Epoch 26; Iter   745/ 1097] train: loss: 0.0290380
[Epoch 26; Iter   775/ 1097] train: loss: 0.0116529
[Epoch 26; Iter   805/ 1097] train: loss: 0.0583660
[Epoch 26; Iter   835/ 1097] train: loss: 0.1326554
[Epoch 26; Iter   865/ 1097] train: loss: 0.0841229
[Epoch 26; Iter   895/ 1097] train: loss: 0.0404694
[Epoch 26; Iter   925/ 1097] train: loss: 0.1874070
[Epoch 26; Iter   955/ 1097] train: loss: 0.0110799
[Epoch 26; Iter   985/ 1097] train: loss: 0.1192011
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0318842
[Epoch 26; Iter  1045/ 1097] train: loss: 0.1296218
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0801443
[Epoch 26] ogbg-molhiv: 0.804612 val loss: 0.111026
[Epoch 26] ogbg-molhiv: 0.781164 test loss: 0.147155
[Epoch 27; Iter     8/ 1097] train: loss: 0.0285883
[Epoch 27; Iter    38/ 1097] train: loss: 0.0246733
[Epoch 27; Iter    68/ 1097] train: loss: 0.0348818
[Epoch 27; Iter    98/ 1097] train: loss: 0.1120712
[Epoch 27; Iter   128/ 1097] train: loss: 0.0593254
[Epoch 27; Iter   158/ 1097] train: loss: 0.0291706
[Epoch 27; Iter   188/ 1097] train: loss: 0.0137068
[Epoch 27; Iter   218/ 1097] train: loss: 0.0490709
[Epoch 27; Iter   248/ 1097] train: loss: 0.0885038
[Epoch 27; Iter   278/ 1097] train: loss: 0.0527091
[Epoch 27; Iter   308/ 1097] train: loss: 0.0265102
[Epoch 27; Iter   338/ 1097] train: loss: 0.0158612
[Epoch 27; Iter   368/ 1097] train: loss: 0.1685649
[Epoch 27; Iter   398/ 1097] train: loss: 0.0177841
[Epoch 27; Iter   428/ 1097] train: loss: 0.3060300
[Epoch 27; Iter   458/ 1097] train: loss: 0.0078814
[Epoch 27; Iter   488/ 1097] train: loss: 0.0718161
[Epoch 27; Iter   518/ 1097] train: loss: 0.1516940
[Epoch 27; Iter   548/ 1097] train: loss: 0.0608161
[Epoch 27; Iter   578/ 1097] train: loss: 0.0722415
[Epoch 27; Iter   608/ 1097] train: loss: 0.0957893
[Epoch 27; Iter   638/ 1097] train: loss: 0.0206515
[Epoch 27; Iter   668/ 1097] train: loss: 0.0266605
[Epoch 27; Iter   698/ 1097] train: loss: 0.0254684
[Epoch 27; Iter   728/ 1097] train: loss: 0.2334051
[Epoch 27; Iter   758/ 1097] train: loss: 0.0774161
[Epoch 27; Iter   788/ 1097] train: loss: 0.0142733
[Epoch 27; Iter   818/ 1097] train: loss: 0.0601071
[Epoch 27; Iter   848/ 1097] train: loss: 0.1051351
[Epoch 27; Iter   878/ 1097] train: loss: 0.0725380
[Epoch 27; Iter   908/ 1097] train: loss: 0.0189133
[Epoch 27; Iter   938/ 1097] train: loss: 0.1497322
[Epoch 27; Iter   968/ 1097] train: loss: 0.0190036
[Epoch 27; Iter   998/ 1097] train: loss: 0.0389910
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0250221
[Epoch 27; Iter  1058/ 1097] train: loss: 0.3143296
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0849402
[Epoch 27] ogbg-molhiv: 0.746479 val loss: 0.149084
[Epoch 27] ogbg-molhiv: 0.785763 test loss: 0.146805
[Epoch 28; Iter    21/ 1097] train: loss: 0.0203592
[Epoch 28; Iter    51/ 1097] train: loss: 0.0663861
[Epoch 28; Iter    81/ 1097] train: loss: 0.0082522
[Epoch 28; Iter   111/ 1097] train: loss: 0.0281522
[Epoch 28; Iter   141/ 1097] train: loss: 0.2551273
[Epoch 28; Iter   171/ 1097] train: loss: 0.0533761
[Epoch 28; Iter   201/ 1097] train: loss: 0.0555138
[Epoch 28; Iter   231/ 1097] train: loss: 0.0932227
[Epoch 28; Iter   261/ 1097] train: loss: 0.2157664
[Epoch 28; Iter   291/ 1097] train: loss: 0.0191559
[Epoch 28; Iter   321/ 1097] train: loss: 0.0100693
[Epoch 28; Iter   351/ 1097] train: loss: 0.0120559
[Epoch 28; Iter   381/ 1097] train: loss: 0.0936734
[Epoch 28; Iter   411/ 1097] train: loss: 0.0092786
[Epoch 24; Iter   359/ 1097] train: loss: 0.0682477
[Epoch 24; Iter   389/ 1097] train: loss: 0.0097854
[Epoch 24; Iter   419/ 1097] train: loss: 0.1864497
[Epoch 24; Iter   449/ 1097] train: loss: 0.0330848
[Epoch 24; Iter   479/ 1097] train: loss: 0.1842771
[Epoch 24; Iter   509/ 1097] train: loss: 0.0440745
[Epoch 24; Iter   539/ 1097] train: loss: 0.0110895
[Epoch 24; Iter   569/ 1097] train: loss: 0.1670147
[Epoch 24; Iter   599/ 1097] train: loss: 0.1605815
[Epoch 24; Iter   629/ 1097] train: loss: 0.0105046
[Epoch 24; Iter   659/ 1097] train: loss: 0.0163723
[Epoch 24; Iter   689/ 1097] train: loss: 0.0078015
[Epoch 24; Iter   719/ 1097] train: loss: 0.1131429
[Epoch 24; Iter   749/ 1097] train: loss: 0.0237086
[Epoch 24; Iter   779/ 1097] train: loss: 0.0703662
[Epoch 24; Iter   809/ 1097] train: loss: 0.0815066
[Epoch 24; Iter   839/ 1097] train: loss: 0.0594523
[Epoch 24; Iter   869/ 1097] train: loss: 0.0162821
[Epoch 24; Iter   899/ 1097] train: loss: 0.0832743
[Epoch 24; Iter   929/ 1097] train: loss: 0.0228826
[Epoch 24; Iter   959/ 1097] train: loss: 0.0758648
[Epoch 24; Iter   989/ 1097] train: loss: 0.0079622
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0819999
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1615063
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1232741
[Epoch 24] ogbg-molhiv: 0.662184 val loss: 0.219086
[Epoch 24] ogbg-molhiv: 0.494718 test loss: 0.293624
[Epoch 25; Iter    12/ 1097] train: loss: 0.0641152
[Epoch 25; Iter    42/ 1097] train: loss: 0.0137858
[Epoch 25; Iter    72/ 1097] train: loss: 0.0147368
[Epoch 25; Iter   102/ 1097] train: loss: 0.1035953
[Epoch 25; Iter   132/ 1097] train: loss: 0.2121288
[Epoch 25; Iter   162/ 1097] train: loss: 0.1016592
[Epoch 25; Iter   192/ 1097] train: loss: 0.0244151
[Epoch 25; Iter   222/ 1097] train: loss: 0.1794799
[Epoch 25; Iter   252/ 1097] train: loss: 0.0149208
[Epoch 25; Iter   282/ 1097] train: loss: 0.0804093
[Epoch 25; Iter   312/ 1097] train: loss: 0.0701710
[Epoch 25; Iter   342/ 1097] train: loss: 0.0330381
[Epoch 25; Iter   372/ 1097] train: loss: 0.0120204
[Epoch 25; Iter   402/ 1097] train: loss: 0.0408642
[Epoch 25; Iter   432/ 1097] train: loss: 0.0316169
[Epoch 25; Iter   462/ 1097] train: loss: 0.0998069
[Epoch 25; Iter   492/ 1097] train: loss: 0.0604825
[Epoch 25; Iter   522/ 1097] train: loss: 0.0497793
[Epoch 25; Iter   552/ 1097] train: loss: 0.1396840
[Epoch 25; Iter   582/ 1097] train: loss: 0.0189294
[Epoch 25; Iter   612/ 1097] train: loss: 0.0080085
[Epoch 25; Iter   642/ 1097] train: loss: 0.1692791
[Epoch 25; Iter   672/ 1097] train: loss: 0.0054407
[Epoch 25; Iter   702/ 1097] train: loss: 0.1029483
[Epoch 25; Iter   732/ 1097] train: loss: 0.0762534
[Epoch 25; Iter   762/ 1097] train: loss: 0.1226153
[Epoch 25; Iter   792/ 1097] train: loss: 0.0195651
[Epoch 25; Iter   822/ 1097] train: loss: 0.0162411
[Epoch 25; Iter   852/ 1097] train: loss: 0.0079806
[Epoch 25; Iter   882/ 1097] train: loss: 0.0219932
[Epoch 25; Iter   912/ 1097] train: loss: 0.0096974
[Epoch 25; Iter   942/ 1097] train: loss: 0.1000056
[Epoch 25; Iter   972/ 1097] train: loss: 0.0127106
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0119136
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0436967
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0375956
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1753755
[Epoch 25] ogbg-molhiv: 0.675173 val loss: 0.717546
[Epoch 25] ogbg-molhiv: 0.527104 test loss: 1.000610
[Epoch 26; Iter    25/ 1097] train: loss: 0.0167941
[Epoch 26; Iter    55/ 1097] train: loss: 0.0064722
[Epoch 26; Iter    85/ 1097] train: loss: 0.0116140
[Epoch 26; Iter   115/ 1097] train: loss: 0.0277432
[Epoch 26; Iter   145/ 1097] train: loss: 0.1941019
[Epoch 26; Iter   175/ 1097] train: loss: 0.0138979
[Epoch 26; Iter   205/ 1097] train: loss: 0.1401388
[Epoch 26; Iter   235/ 1097] train: loss: 0.0168331
[Epoch 26; Iter   265/ 1097] train: loss: 0.0131961
[Epoch 26; Iter   295/ 1097] train: loss: 0.1137875
[Epoch 26; Iter   325/ 1097] train: loss: 0.0294564
[Epoch 26; Iter   355/ 1097] train: loss: 0.0265884
[Epoch 26; Iter   385/ 1097] train: loss: 0.0182489
[Epoch 26; Iter   415/ 1097] train: loss: 0.0153239
[Epoch 26; Iter   445/ 1097] train: loss: 0.0082791
[Epoch 26; Iter   475/ 1097] train: loss: 0.0053363
[Epoch 26; Iter   505/ 1097] train: loss: 0.0133276
[Epoch 26; Iter   535/ 1097] train: loss: 0.0423744
[Epoch 26; Iter   565/ 1097] train: loss: 0.0265687
[Epoch 26; Iter   595/ 1097] train: loss: 0.0571203
[Epoch 26; Iter   625/ 1097] train: loss: 0.0098823
[Epoch 26; Iter   655/ 1097] train: loss: 0.0070950
[Epoch 26; Iter   685/ 1097] train: loss: 0.0610980
[Epoch 26; Iter   715/ 1097] train: loss: 0.0758267
[Epoch 26; Iter   745/ 1097] train: loss: 0.0415519
[Epoch 26; Iter   775/ 1097] train: loss: 0.0157284
[Epoch 26; Iter   805/ 1097] train: loss: 0.0349826
[Epoch 26; Iter   835/ 1097] train: loss: 0.1396169
[Epoch 26; Iter   865/ 1097] train: loss: 0.0162064
[Epoch 26; Iter   895/ 1097] train: loss: 0.0393391
[Epoch 26; Iter   925/ 1097] train: loss: 0.0355669
[Epoch 26; Iter   955/ 1097] train: loss: 0.0208861
[Epoch 26; Iter   985/ 1097] train: loss: 0.0262925
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0176442
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0274485
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0841982
[Epoch 26] ogbg-molhiv: 0.623515 val loss: 4.457438
[Epoch 26] ogbg-molhiv: 0.454906 test loss: 6.648118
[Epoch 27; Iter     8/ 1097] train: loss: 0.0292090
[Epoch 27; Iter    38/ 1097] train: loss: 0.0372850
[Epoch 27; Iter    68/ 1097] train: loss: 0.1519433
[Epoch 27; Iter    98/ 1097] train: loss: 0.0146483
[Epoch 27; Iter   128/ 1097] train: loss: 0.0426627
[Epoch 27; Iter   158/ 1097] train: loss: 0.0396812
[Epoch 27; Iter   188/ 1097] train: loss: 0.0262945
[Epoch 27; Iter   218/ 1097] train: loss: 0.0098621
[Epoch 27; Iter   248/ 1097] train: loss: 0.0960882
[Epoch 27; Iter   278/ 1097] train: loss: 0.0090647
[Epoch 27; Iter   308/ 1097] train: loss: 0.0119777
[Epoch 27; Iter   338/ 1097] train: loss: 0.0776943
[Epoch 27; Iter   368/ 1097] train: loss: 0.2177346
[Epoch 27; Iter   398/ 1097] train: loss: 0.0080665
[Epoch 27; Iter   428/ 1097] train: loss: 0.0222030
[Epoch 27; Iter   458/ 1097] train: loss: 0.0169176
[Epoch 27; Iter   488/ 1097] train: loss: 0.0177489
[Epoch 27; Iter   518/ 1097] train: loss: 0.1435537
[Epoch 27; Iter   548/ 1097] train: loss: 0.0216115
[Epoch 27; Iter   578/ 1097] train: loss: 0.0680906
[Epoch 27; Iter   608/ 1097] train: loss: 0.0446867
[Epoch 27; Iter   638/ 1097] train: loss: 0.0077810
[Epoch 27; Iter   668/ 1097] train: loss: 0.0842901
[Epoch 27; Iter   698/ 1097] train: loss: 0.0772793
[Epoch 27; Iter   728/ 1097] train: loss: 0.0678723
[Epoch 27; Iter   758/ 1097] train: loss: 0.0621296
[Epoch 27; Iter   788/ 1097] train: loss: 0.1035571
[Epoch 27; Iter   818/ 1097] train: loss: 0.0140789
[Epoch 27; Iter   848/ 1097] train: loss: 0.0086077
[Epoch 27; Iter   878/ 1097] train: loss: 0.2128906
[Epoch 27; Iter   908/ 1097] train: loss: 0.2496617
[Epoch 27; Iter   938/ 1097] train: loss: 0.0096118
[Epoch 27; Iter   968/ 1097] train: loss: 0.1176801
[Epoch 27; Iter   998/ 1097] train: loss: 0.0066830
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1410605
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0945591
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0574627
[Epoch 27] ogbg-molhiv: 0.686921 val loss: 48.003874
[Epoch 27] ogbg-molhiv: 0.580330 test loss: 30.642820
[Epoch 28; Iter    21/ 1097] train: loss: 0.0734274
[Epoch 28; Iter    51/ 1097] train: loss: 0.0126730
[Epoch 28; Iter    81/ 1097] train: loss: 0.0416011
[Epoch 28; Iter   111/ 1097] train: loss: 0.0232073
[Epoch 28; Iter   141/ 1097] train: loss: 0.0264972
[Epoch 28; Iter   171/ 1097] train: loss: 0.0079078
[Epoch 28; Iter   201/ 1097] train: loss: 0.0304662
[Epoch 28; Iter   231/ 1097] train: loss: 0.0076437
[Epoch 28; Iter   261/ 1097] train: loss: 0.0070476
[Epoch 28; Iter   291/ 1097] train: loss: 0.0169303
[Epoch 28; Iter   321/ 1097] train: loss: 0.0025334
[Epoch 28; Iter   351/ 1097] train: loss: 0.0295832
[Epoch 28; Iter   381/ 1097] train: loss: 0.0169874
[Epoch 28; Iter   411/ 1097] train: loss: 0.0874108
[Epoch 24; Iter   359/ 1097] train: loss: 0.1321751
[Epoch 24; Iter   389/ 1097] train: loss: 0.1518991
[Epoch 24; Iter   419/ 1097] train: loss: 0.3141508
[Epoch 24; Iter   449/ 1097] train: loss: 0.0192212
[Epoch 24; Iter   479/ 1097] train: loss: 0.1095364
[Epoch 24; Iter   509/ 1097] train: loss: 0.0523362
[Epoch 24; Iter   539/ 1097] train: loss: 0.0381213
[Epoch 24; Iter   569/ 1097] train: loss: 0.0260524
[Epoch 24; Iter   599/ 1097] train: loss: 0.2058868
[Epoch 24; Iter   629/ 1097] train: loss: 0.0180175
[Epoch 24; Iter   659/ 1097] train: loss: 0.0320344
[Epoch 24; Iter   689/ 1097] train: loss: 0.0158562
[Epoch 24; Iter   719/ 1097] train: loss: 0.0215478
[Epoch 24; Iter   749/ 1097] train: loss: 0.0451298
[Epoch 24; Iter   779/ 1097] train: loss: 0.0199084
[Epoch 24; Iter   809/ 1097] train: loss: 0.0355895
[Epoch 24; Iter   839/ 1097] train: loss: 0.0449798
[Epoch 24; Iter   869/ 1097] train: loss: 0.1331619
[Epoch 24; Iter   899/ 1097] train: loss: 0.1242172
[Epoch 24; Iter   929/ 1097] train: loss: 0.1929003
[Epoch 24; Iter   959/ 1097] train: loss: 0.0199661
[Epoch 24; Iter   989/ 1097] train: loss: 0.0203921
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0994915
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0752389
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0442117
[Epoch 24] ogbg-molhiv: 0.740337 val loss: 25.527063
[Epoch 24] ogbg-molhiv: 0.640596 test loss: 20.713570
[Epoch 25; Iter    12/ 1097] train: loss: 0.0093464
[Epoch 25; Iter    42/ 1097] train: loss: 0.0296976
[Epoch 25; Iter    72/ 1097] train: loss: 0.0197099
[Epoch 25; Iter   102/ 1097] train: loss: 0.0139255
[Epoch 25; Iter   132/ 1097] train: loss: 0.0473808
[Epoch 25; Iter   162/ 1097] train: loss: 0.0278862
[Epoch 25; Iter   192/ 1097] train: loss: 0.1224791
[Epoch 25; Iter   222/ 1097] train: loss: 0.0411623
[Epoch 25; Iter   252/ 1097] train: loss: 0.0724087
[Epoch 25; Iter   282/ 1097] train: loss: 0.0832830
[Epoch 25; Iter   312/ 1097] train: loss: 0.0094466
[Epoch 25; Iter   342/ 1097] train: loss: 0.2223527
[Epoch 25; Iter   372/ 1097] train: loss: 0.2494989
[Epoch 25; Iter   402/ 1097] train: loss: 0.0253433
[Epoch 25; Iter   432/ 1097] train: loss: 0.1771196
[Epoch 25; Iter   462/ 1097] train: loss: 0.0271098
[Epoch 25; Iter   492/ 1097] train: loss: 0.1959149
[Epoch 25; Iter   522/ 1097] train: loss: 0.0140466
[Epoch 25; Iter   552/ 1097] train: loss: 0.1577996
[Epoch 25; Iter   582/ 1097] train: loss: 0.0129939
[Epoch 25; Iter   612/ 1097] train: loss: 0.2147990
[Epoch 25; Iter   642/ 1097] train: loss: 0.0318656
[Epoch 25; Iter   672/ 1097] train: loss: 0.0197900
[Epoch 25; Iter   702/ 1097] train: loss: 0.0791687
[Epoch 25; Iter   732/ 1097] train: loss: 0.0160894
[Epoch 25; Iter   762/ 1097] train: loss: 0.0369404
[Epoch 25; Iter   792/ 1097] train: loss: 0.0204048
[Epoch 25; Iter   822/ 1097] train: loss: 0.0499257
[Epoch 25; Iter   852/ 1097] train: loss: 0.0150060
[Epoch 25; Iter   882/ 1097] train: loss: 0.0393496
[Epoch 25; Iter   912/ 1097] train: loss: 0.1144069
[Epoch 25; Iter   942/ 1097] train: loss: 0.0726372
[Epoch 25; Iter   972/ 1097] train: loss: 0.0267873
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1435173
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0549526
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0343826
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1758950
[Epoch 25] ogbg-molhiv: 0.777459 val loss: 11.775351
[Epoch 25] ogbg-molhiv: 0.696972 test loss: 7.080785
[Epoch 26; Iter    25/ 1097] train: loss: 0.0135657
[Epoch 26; Iter    55/ 1097] train: loss: 0.0159793
[Epoch 26; Iter    85/ 1097] train: loss: 0.0292494
[Epoch 26; Iter   115/ 1097] train: loss: 0.1842020
[Epoch 26; Iter   145/ 1097] train: loss: 0.0246089
[Epoch 26; Iter   175/ 1097] train: loss: 0.0731826
[Epoch 26; Iter   205/ 1097] train: loss: 0.2523252
[Epoch 26; Iter   235/ 1097] train: loss: 0.0282346
[Epoch 26; Iter   265/ 1097] train: loss: 0.0280046
[Epoch 26; Iter   295/ 1097] train: loss: 0.0421220
[Epoch 26; Iter   325/ 1097] train: loss: 0.0401791
[Epoch 26; Iter   355/ 1097] train: loss: 0.0654959
[Epoch 26; Iter   385/ 1097] train: loss: 0.0209027
[Epoch 26; Iter   415/ 1097] train: loss: 0.0283151
[Epoch 26; Iter   445/ 1097] train: loss: 0.0317163
[Epoch 26; Iter   475/ 1097] train: loss: 0.0568022
[Epoch 26; Iter   505/ 1097] train: loss: 0.0584572
[Epoch 26; Iter   535/ 1097] train: loss: 0.1720088
[Epoch 26; Iter   565/ 1097] train: loss: 0.0288544
[Epoch 26; Iter   595/ 1097] train: loss: 0.0077723
[Epoch 26; Iter   625/ 1097] train: loss: 0.0228208
[Epoch 26; Iter   655/ 1097] train: loss: 0.0713107
[Epoch 26; Iter   685/ 1097] train: loss: 0.1286129
[Epoch 26; Iter   715/ 1097] train: loss: 0.0060731
[Epoch 26; Iter   745/ 1097] train: loss: 0.0080303
[Epoch 26; Iter   775/ 1097] train: loss: 0.0120678
[Epoch 26; Iter   805/ 1097] train: loss: 0.0153909
[Epoch 26; Iter   835/ 1097] train: loss: 0.1141690
[Epoch 26; Iter   865/ 1097] train: loss: 0.1167853
[Epoch 26; Iter   895/ 1097] train: loss: 0.0530678
[Epoch 26; Iter   925/ 1097] train: loss: 0.1059923
[Epoch 26; Iter   955/ 1097] train: loss: 0.0286675
[Epoch 26; Iter   985/ 1097] train: loss: 0.0334679
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0353455
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0289035
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0779767
[Epoch 26] ogbg-molhiv: 0.777003 val loss: 1.940913
[Epoch 26] ogbg-molhiv: 0.723033 test loss: 1.252405
[Epoch 27; Iter     8/ 1097] train: loss: 0.0120955
[Epoch 27; Iter    38/ 1097] train: loss: 0.0080098
[Epoch 27; Iter    68/ 1097] train: loss: 0.0143835
[Epoch 27; Iter    98/ 1097] train: loss: 0.0323225
[Epoch 27; Iter   128/ 1097] train: loss: 0.1393858
[Epoch 27; Iter   158/ 1097] train: loss: 0.0090388
[Epoch 27; Iter   188/ 1097] train: loss: 0.0151404
[Epoch 27; Iter   218/ 1097] train: loss: 0.0234034
[Epoch 27; Iter   248/ 1097] train: loss: 0.0130933
[Epoch 27; Iter   278/ 1097] train: loss: 0.0218867
[Epoch 27; Iter   308/ 1097] train: loss: 0.0138898
[Epoch 27; Iter   338/ 1097] train: loss: 0.0039076
[Epoch 27; Iter   368/ 1097] train: loss: 0.0157609
[Epoch 27; Iter   398/ 1097] train: loss: 0.0123924
[Epoch 27; Iter   428/ 1097] train: loss: 0.1563886
[Epoch 27; Iter   458/ 1097] train: loss: 0.0244814
[Epoch 27; Iter   488/ 1097] train: loss: 0.0142678
[Epoch 27; Iter   518/ 1097] train: loss: 0.3595631
[Epoch 27; Iter   548/ 1097] train: loss: 0.0374549
[Epoch 27; Iter   578/ 1097] train: loss: 0.0326765
[Epoch 27; Iter   608/ 1097] train: loss: 0.0667362
[Epoch 27; Iter   638/ 1097] train: loss: 0.0085156
[Epoch 27; Iter   668/ 1097] train: loss: 0.0026082
[Epoch 27; Iter   698/ 1097] train: loss: 0.0798300
[Epoch 27; Iter   728/ 1097] train: loss: 0.1886369
[Epoch 27; Iter   758/ 1097] train: loss: 0.0229885
[Epoch 27; Iter   788/ 1097] train: loss: 0.0104177
[Epoch 27; Iter   818/ 1097] train: loss: 0.0236754
[Epoch 27; Iter   848/ 1097] train: loss: 0.0286707
[Epoch 27; Iter   878/ 1097] train: loss: 0.2398789
[Epoch 27; Iter   908/ 1097] train: loss: 0.0120714
[Epoch 27; Iter   938/ 1097] train: loss: 0.0660347
[Epoch 27; Iter   968/ 1097] train: loss: 0.0085535
[Epoch 27; Iter   998/ 1097] train: loss: 0.0265206
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0316569
[Epoch 27; Iter  1058/ 1097] train: loss: 0.1952187
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1274510
[Epoch 27] ogbg-molhiv: 0.752168 val loss: 0.130607
[Epoch 27] ogbg-molhiv: 0.652351 test loss: 0.207174
[Epoch 28; Iter    21/ 1097] train: loss: 0.0355528
[Epoch 28; Iter    51/ 1097] train: loss: 0.0170799
[Epoch 28; Iter    81/ 1097] train: loss: 0.0099366
[Epoch 28; Iter   111/ 1097] train: loss: 0.1312897
[Epoch 28; Iter   141/ 1097] train: loss: 0.0738554
[Epoch 28; Iter   171/ 1097] train: loss: 0.0425866
[Epoch 28; Iter   201/ 1097] train: loss: 0.0669885
[Epoch 28; Iter   231/ 1097] train: loss: 0.0132616
[Epoch 28; Iter   261/ 1097] train: loss: 0.0549597
[Epoch 28; Iter   291/ 1097] train: loss: 0.0230358
[Epoch 28; Iter   321/ 1097] train: loss: 0.0096194
[Epoch 28; Iter   351/ 1097] train: loss: 0.0124492
[Epoch 28; Iter   381/ 1097] train: loss: 0.0388874
[Epoch 28; Iter   411/ 1097] train: loss: 0.0265692
[Epoch 24; Iter   359/ 1097] train: loss: 0.0276075
[Epoch 24; Iter   389/ 1097] train: loss: 0.0167792
[Epoch 24; Iter   419/ 1097] train: loss: 0.0376867
[Epoch 24; Iter   449/ 1097] train: loss: 0.0423277
[Epoch 24; Iter   479/ 1097] train: loss: 0.1208043
[Epoch 24; Iter   509/ 1097] train: loss: 0.0109919
[Epoch 24; Iter   539/ 1097] train: loss: 0.0278809
[Epoch 24; Iter   569/ 1097] train: loss: 0.0226639
[Epoch 24; Iter   599/ 1097] train: loss: 0.1032995
[Epoch 24; Iter   629/ 1097] train: loss: 0.0356478
[Epoch 24; Iter   659/ 1097] train: loss: 0.0386656
[Epoch 24; Iter   689/ 1097] train: loss: 0.0302716
[Epoch 24; Iter   719/ 1097] train: loss: 0.0484748
[Epoch 24; Iter   749/ 1097] train: loss: 0.0107541
[Epoch 24; Iter   779/ 1097] train: loss: 0.1728403
[Epoch 24; Iter   809/ 1097] train: loss: 0.1376768
[Epoch 24; Iter   839/ 1097] train: loss: 0.1486607
[Epoch 24; Iter   869/ 1097] train: loss: 0.0055574
[Epoch 24; Iter   899/ 1097] train: loss: 0.0251009
[Epoch 24; Iter   929/ 1097] train: loss: 0.0181746
[Epoch 24; Iter   959/ 1097] train: loss: 0.0070505
[Epoch 24; Iter   989/ 1097] train: loss: 0.0343009
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3088009
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0258183
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0415113
[Epoch 24] ogbg-molhiv: 0.711610 val loss: 0.184031
[Epoch 24] ogbg-molhiv: 0.674731 test loss: 0.187407
[Epoch 25; Iter    12/ 1097] train: loss: 0.0394191
[Epoch 25; Iter    42/ 1097] train: loss: 0.0467809
[Epoch 25; Iter    72/ 1097] train: loss: 0.1575220
[Epoch 25; Iter   102/ 1097] train: loss: 0.0089097
[Epoch 25; Iter   132/ 1097] train: loss: 0.0078889
[Epoch 25; Iter   162/ 1097] train: loss: 0.0119761
[Epoch 25; Iter   192/ 1097] train: loss: 0.0106118
[Epoch 25; Iter   222/ 1097] train: loss: 0.0230655
[Epoch 25; Iter   252/ 1097] train: loss: 0.0067762
[Epoch 25; Iter   282/ 1097] train: loss: 0.0156661
[Epoch 25; Iter   312/ 1097] train: loss: 0.0596299
[Epoch 25; Iter   342/ 1097] train: loss: 0.0558891
[Epoch 25; Iter   372/ 1097] train: loss: 0.0306978
[Epoch 25; Iter   402/ 1097] train: loss: 0.0663813
[Epoch 25; Iter   432/ 1097] train: loss: 0.0935112
[Epoch 25; Iter   462/ 1097] train: loss: 0.0160032
[Epoch 25; Iter   492/ 1097] train: loss: 0.0334077
[Epoch 25; Iter   522/ 1097] train: loss: 0.0200405
[Epoch 25; Iter   552/ 1097] train: loss: 0.2068893
[Epoch 25; Iter   582/ 1097] train: loss: 0.2286072
[Epoch 25; Iter   612/ 1097] train: loss: 0.0073932
[Epoch 25; Iter   642/ 1097] train: loss: 0.1934546
[Epoch 25; Iter   672/ 1097] train: loss: 0.0455196
[Epoch 25; Iter   702/ 1097] train: loss: 0.0453951
[Epoch 25; Iter   732/ 1097] train: loss: 0.1751202
[Epoch 25; Iter   762/ 1097] train: loss: 0.0507427
[Epoch 25; Iter   792/ 1097] train: loss: 0.0567320
[Epoch 25; Iter   822/ 1097] train: loss: 0.0123145
[Epoch 25; Iter   852/ 1097] train: loss: 0.0627015
[Epoch 25; Iter   882/ 1097] train: loss: 0.0070137
[Epoch 25; Iter   912/ 1097] train: loss: 0.0218063
[Epoch 25; Iter   942/ 1097] train: loss: 0.2718816
[Epoch 25; Iter   972/ 1097] train: loss: 0.0826167
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0516513
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0450774
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0817649
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0076107
[Epoch 25] ogbg-molhiv: 0.716258 val loss: 0.151087
[Epoch 25] ogbg-molhiv: 0.696161 test loss: 0.205098
[Epoch 26; Iter    25/ 1097] train: loss: 0.0382584
[Epoch 26; Iter    55/ 1097] train: loss: 0.0630984
[Epoch 26; Iter    85/ 1097] train: loss: 0.0425692
[Epoch 26; Iter   115/ 1097] train: loss: 0.0065522
[Epoch 26; Iter   145/ 1097] train: loss: 0.0081924
[Epoch 26; Iter   175/ 1097] train: loss: 0.0401213
[Epoch 26; Iter   205/ 1097] train: loss: 0.0083727
[Epoch 26; Iter   235/ 1097] train: loss: 0.0064105
[Epoch 26; Iter   265/ 1097] train: loss: 0.0379193
[Epoch 26; Iter   295/ 1097] train: loss: 0.0472037
[Epoch 26; Iter   325/ 1097] train: loss: 0.0091335
[Epoch 26; Iter   355/ 1097] train: loss: 0.0069703
[Epoch 26; Iter   385/ 1097] train: loss: 0.1104301
[Epoch 26; Iter   415/ 1097] train: loss: 0.0062531
[Epoch 26; Iter   445/ 1097] train: loss: 0.0793972
[Epoch 26; Iter   475/ 1097] train: loss: 0.0562591
[Epoch 26; Iter   505/ 1097] train: loss: 0.1757058
[Epoch 26; Iter   535/ 1097] train: loss: 0.0266013
[Epoch 26; Iter   565/ 1097] train: loss: 0.0137601
[Epoch 26; Iter   595/ 1097] train: loss: 0.0066633
[Epoch 26; Iter   625/ 1097] train: loss: 0.0944572
[Epoch 26; Iter   655/ 1097] train: loss: 0.0194027
[Epoch 26; Iter   685/ 1097] train: loss: 0.0779367
[Epoch 26; Iter   715/ 1097] train: loss: 0.0291323
[Epoch 26; Iter   745/ 1097] train: loss: 0.0964517
[Epoch 26; Iter   775/ 1097] train: loss: 0.1316120
[Epoch 26; Iter   805/ 1097] train: loss: 0.0310169
[Epoch 26; Iter   835/ 1097] train: loss: 0.0175455
[Epoch 26; Iter   865/ 1097] train: loss: 0.2094997
[Epoch 26; Iter   895/ 1097] train: loss: 0.0165096
[Epoch 26; Iter   925/ 1097] train: loss: 0.0187916
[Epoch 26; Iter   955/ 1097] train: loss: 0.0250568
[Epoch 26; Iter   985/ 1097] train: loss: 0.0225423
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1107525
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0622486
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1012568
[Epoch 26] ogbg-molhiv: 0.752725 val loss: 0.161966
[Epoch 26] ogbg-molhiv: 0.668336 test loss: 0.224526
[Epoch 27; Iter     8/ 1097] train: loss: 0.0444251
[Epoch 27; Iter    38/ 1097] train: loss: 0.0242430
[Epoch 27; Iter    68/ 1097] train: loss: 0.0738514
[Epoch 27; Iter    98/ 1097] train: loss: 0.0463050
[Epoch 27; Iter   128/ 1097] train: loss: 0.0143768
[Epoch 27; Iter   158/ 1097] train: loss: 0.0559619
[Epoch 27; Iter   188/ 1097] train: loss: 0.0148870
[Epoch 27; Iter   218/ 1097] train: loss: 0.0159245
[Epoch 27; Iter   248/ 1097] train: loss: 0.0395353
[Epoch 27; Iter   278/ 1097] train: loss: 0.0263263
[Epoch 27; Iter   308/ 1097] train: loss: 0.0351929
[Epoch 27; Iter   338/ 1097] train: loss: 0.0129621
[Epoch 27; Iter   368/ 1097] train: loss: 0.1162093
[Epoch 27; Iter   398/ 1097] train: loss: 0.1269632
[Epoch 27; Iter   428/ 1097] train: loss: 0.0145656
[Epoch 27; Iter   458/ 1097] train: loss: 0.1073804
[Epoch 27; Iter   488/ 1097] train: loss: 0.0876717
[Epoch 27; Iter   518/ 1097] train: loss: 0.1594916
[Epoch 27; Iter   548/ 1097] train: loss: 0.0279400
[Epoch 27; Iter   578/ 1097] train: loss: 0.0210227
[Epoch 27; Iter   608/ 1097] train: loss: 0.0107679
[Epoch 27; Iter   638/ 1097] train: loss: 0.0121348
[Epoch 27; Iter   668/ 1097] train: loss: 0.0084937
[Epoch 27; Iter   698/ 1097] train: loss: 0.0525409
[Epoch 27; Iter   728/ 1097] train: loss: 0.0374580
[Epoch 27; Iter   758/ 1097] train: loss: 0.0449883
[Epoch 27; Iter   788/ 1097] train: loss: 0.1069614
[Epoch 27; Iter   818/ 1097] train: loss: 0.0056741
[Epoch 27; Iter   848/ 1097] train: loss: 0.0098671
[Epoch 27; Iter   878/ 1097] train: loss: 0.0105777
[Epoch 27; Iter   908/ 1097] train: loss: 0.0549153
[Epoch 27; Iter   938/ 1097] train: loss: 0.0110374
[Epoch 27; Iter   968/ 1097] train: loss: 0.0699701
[Epoch 27; Iter   998/ 1097] train: loss: 0.0062612
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0271725
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0061703
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0124196
[Epoch 27] ogbg-molhiv: 0.792389 val loss: 0.647977
[Epoch 27] ogbg-molhiv: 0.693563 test loss: 0.465123
[Epoch 28; Iter    21/ 1097] train: loss: 0.0638604
[Epoch 28; Iter    51/ 1097] train: loss: 0.0392520
[Epoch 28; Iter    81/ 1097] train: loss: 0.0127225
[Epoch 28; Iter   111/ 1097] train: loss: 0.0034983
[Epoch 28; Iter   141/ 1097] train: loss: 0.0293798
[Epoch 28; Iter   171/ 1097] train: loss: 0.0070439
[Epoch 28; Iter   201/ 1097] train: loss: 0.0055037
[Epoch 28; Iter   231/ 1097] train: loss: 0.0093544
[Epoch 28; Iter   261/ 1097] train: loss: 0.0086957
[Epoch 28; Iter   291/ 1097] train: loss: 0.0169818
[Epoch 28; Iter   321/ 1097] train: loss: 0.0588813
[Epoch 28; Iter   351/ 1097] train: loss: 0.0306845
[Epoch 28; Iter   381/ 1097] train: loss: 0.0155512
[Epoch 28; Iter   411/ 1097] train: loss: 0.0077398
[Epoch 28; Iter   441/ 1097] train: loss: 0.6265884
[Epoch 28; Iter   471/ 1097] train: loss: 0.0384368
[Epoch 28; Iter   501/ 1097] train: loss: 0.2326983
[Epoch 28; Iter   531/ 1097] train: loss: 0.0169645
[Epoch 28; Iter   561/ 1097] train: loss: 0.1001773
[Epoch 28; Iter   591/ 1097] train: loss: 0.1039177
[Epoch 28; Iter   621/ 1097] train: loss: 0.0530203
[Epoch 28; Iter   651/ 1097] train: loss: 0.0171236
[Epoch 28; Iter   681/ 1097] train: loss: 0.0219977
[Epoch 28; Iter   711/ 1097] train: loss: 0.0170674
[Epoch 28; Iter   741/ 1097] train: loss: 0.0073322
[Epoch 28; Iter   771/ 1097] train: loss: 0.0128112
[Epoch 28; Iter   801/ 1097] train: loss: 0.0090065
[Epoch 28; Iter   831/ 1097] train: loss: 0.0406196
[Epoch 28; Iter   861/ 1097] train: loss: 0.1411143
[Epoch 28; Iter   891/ 1097] train: loss: 0.0270514
[Epoch 28; Iter   921/ 1097] train: loss: 0.0093962
[Epoch 28; Iter   951/ 1097] train: loss: 0.0336464
[Epoch 28; Iter   981/ 1097] train: loss: 0.0161926
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0129490
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0088355
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0167305
[Epoch 28] ogbg-molhiv: 0.785074 val loss: 0.343496
[Epoch 28] ogbg-molhiv: 0.766710 test loss: 0.139371
[Epoch 29; Iter     4/ 1097] train: loss: 0.0184916
[Epoch 29; Iter    34/ 1097] train: loss: 0.0126119
[Epoch 29; Iter    64/ 1097] train: loss: 0.0467926
[Epoch 29; Iter    94/ 1097] train: loss: 0.0195261
[Epoch 29; Iter   124/ 1097] train: loss: 0.0639610
[Epoch 29; Iter   154/ 1097] train: loss: 0.0650014
[Epoch 29; Iter   184/ 1097] train: loss: 0.0126654
[Epoch 29; Iter   214/ 1097] train: loss: 0.0184524
[Epoch 29; Iter   244/ 1097] train: loss: 0.0323585
[Epoch 29; Iter   274/ 1097] train: loss: 0.0223716
[Epoch 29; Iter   304/ 1097] train: loss: 0.0124183
[Epoch 29; Iter   334/ 1097] train: loss: 0.0383202
[Epoch 29; Iter   364/ 1097] train: loss: 0.0111656
[Epoch 29; Iter   394/ 1097] train: loss: 0.0328993
[Epoch 29; Iter   424/ 1097] train: loss: 0.0751947
[Epoch 29; Iter   454/ 1097] train: loss: 0.0125064
[Epoch 29; Iter   484/ 1097] train: loss: 0.0188758
[Epoch 29; Iter   514/ 1097] train: loss: 0.0341249
[Epoch 29; Iter   544/ 1097] train: loss: 0.0089971
[Epoch 29; Iter   574/ 1097] train: loss: 0.0070322
[Epoch 29; Iter   604/ 1097] train: loss: 0.1150684
[Epoch 29; Iter   634/ 1097] train: loss: 0.2101387
[Epoch 29; Iter   664/ 1097] train: loss: 0.0179797
[Epoch 29; Iter   694/ 1097] train: loss: 0.0163438
[Epoch 29; Iter   724/ 1097] train: loss: 0.0119896
[Epoch 29; Iter   754/ 1097] train: loss: 0.0084201
[Epoch 29; Iter   784/ 1097] train: loss: 0.0259294
[Epoch 29; Iter   814/ 1097] train: loss: 0.0097011
[Epoch 29; Iter   844/ 1097] train: loss: 0.0704114
[Epoch 29; Iter   874/ 1097] train: loss: 0.3158407
[Epoch 29; Iter   904/ 1097] train: loss: 0.0111416
[Epoch 29; Iter   934/ 1097] train: loss: 0.1901556
[Epoch 29; Iter   964/ 1097] train: loss: 0.0075924
[Epoch 29; Iter   994/ 1097] train: loss: 0.0809127
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0179434
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0431340
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0759652
[Epoch 29] ogbg-molhiv: 0.721224 val loss: 0.126741
[Epoch 29] ogbg-molhiv: 0.738052 test loss: 0.149714
[Epoch 30; Iter    17/ 1097] train: loss: 0.0212332
[Epoch 30; Iter    47/ 1097] train: loss: 0.1970538
[Epoch 30; Iter    77/ 1097] train: loss: 0.0278583
[Epoch 30; Iter   107/ 1097] train: loss: 0.0090180
[Epoch 30; Iter   137/ 1097] train: loss: 0.0401639
[Epoch 30; Iter   167/ 1097] train: loss: 0.0302016
[Epoch 30; Iter   197/ 1097] train: loss: 0.0162428
[Epoch 30; Iter   227/ 1097] train: loss: 0.0140613
[Epoch 30; Iter   257/ 1097] train: loss: 0.0139697
[Epoch 30; Iter   287/ 1097] train: loss: 0.0084265
[Epoch 30; Iter   317/ 1097] train: loss: 0.0291666
[Epoch 30; Iter   347/ 1097] train: loss: 0.0255425
[Epoch 30; Iter   377/ 1097] train: loss: 0.0575228
[Epoch 30; Iter   407/ 1097] train: loss: 0.0108251
[Epoch 30; Iter   437/ 1097] train: loss: 0.0205932
[Epoch 30; Iter   467/ 1097] train: loss: 0.0128813
[Epoch 30; Iter   497/ 1097] train: loss: 0.1489433
[Epoch 30; Iter   527/ 1097] train: loss: 0.0605005
[Epoch 30; Iter   557/ 1097] train: loss: 0.2062753
[Epoch 30; Iter   587/ 1097] train: loss: 0.0181166
[Epoch 30; Iter   617/ 1097] train: loss: 0.0084765
[Epoch 30; Iter   647/ 1097] train: loss: 0.0037180
[Epoch 30; Iter   677/ 1097] train: loss: 0.0239145
[Epoch 30; Iter   707/ 1097] train: loss: 0.1722202
[Epoch 30; Iter   737/ 1097] train: loss: 0.1205940
[Epoch 30; Iter   767/ 1097] train: loss: 0.0450378
[Epoch 30; Iter   797/ 1097] train: loss: 0.1157354
[Epoch 30; Iter   827/ 1097] train: loss: 0.0723562
[Epoch 30; Iter   857/ 1097] train: loss: 0.1210222
[Epoch 30; Iter   887/ 1097] train: loss: 0.0146562
[Epoch 30; Iter   917/ 1097] train: loss: 0.0642491
[Epoch 30; Iter   947/ 1097] train: loss: 0.0591381
[Epoch 30; Iter   977/ 1097] train: loss: 0.0051272
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0627927
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0332596
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0215637
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0197594
[Epoch 30] ogbg-molhiv: 0.757591 val loss: 0.114601
[Epoch 30] ogbg-molhiv: 0.740095 test loss: 0.158854
[Epoch 31; Iter    30/ 1097] train: loss: 0.0181089
[Epoch 31; Iter    60/ 1097] train: loss: 0.0190329
[Epoch 31; Iter    90/ 1097] train: loss: 0.0809219
[Epoch 31; Iter   120/ 1097] train: loss: 0.0482264
[Epoch 31; Iter   150/ 1097] train: loss: 0.0679369
[Epoch 31; Iter   180/ 1097] train: loss: 0.0174106
[Epoch 31; Iter   210/ 1097] train: loss: 0.0259393
[Epoch 31; Iter   240/ 1097] train: loss: 0.0120504
[Epoch 31; Iter   270/ 1097] train: loss: 0.0294961
[Epoch 31; Iter   300/ 1097] train: loss: 0.0327866
[Epoch 31; Iter   330/ 1097] train: loss: 0.0645908
[Epoch 31; Iter   360/ 1097] train: loss: 0.1055895
[Epoch 31; Iter   390/ 1097] train: loss: 0.0167622
[Epoch 31; Iter   420/ 1097] train: loss: 0.0630640
[Epoch 31; Iter   450/ 1097] train: loss: 0.0255741
[Epoch 31; Iter   480/ 1097] train: loss: 0.0164524
[Epoch 31; Iter   510/ 1097] train: loss: 0.0091127
[Epoch 31; Iter   540/ 1097] train: loss: 0.0042894
[Epoch 31; Iter   570/ 1097] train: loss: 0.0335183
[Epoch 31; Iter   600/ 1097] train: loss: 0.0020761
[Epoch 31; Iter   630/ 1097] train: loss: 0.0181834
[Epoch 31; Iter   660/ 1097] train: loss: 0.0317397
[Epoch 31; Iter   690/ 1097] train: loss: 0.0135399
[Epoch 31; Iter   720/ 1097] train: loss: 0.1457312
[Epoch 31; Iter   750/ 1097] train: loss: 0.0145957
[Epoch 31; Iter   780/ 1097] train: loss: 0.0293727
[Epoch 31; Iter   810/ 1097] train: loss: 0.0155661
[Epoch 31; Iter   840/ 1097] train: loss: 0.1908383
[Epoch 31; Iter   870/ 1097] train: loss: 0.1362768
[Epoch 31; Iter   900/ 1097] train: loss: 0.0495338
[Epoch 31; Iter   930/ 1097] train: loss: 0.0126733
[Epoch 31; Iter   960/ 1097] train: loss: 0.0274771
[Epoch 31; Iter   990/ 1097] train: loss: 0.0536473
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0584851
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0762205
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0296462
[Epoch 31] ogbg-molhiv: 0.767159 val loss: 0.266399
[Epoch 31] ogbg-molhiv: 0.755607 test loss: 0.184598
[Epoch 32; Iter    13/ 1097] train: loss: 0.0069403
[Epoch 32; Iter    43/ 1097] train: loss: 0.0742338
[Epoch 32; Iter    73/ 1097] train: loss: 0.0122513
[Epoch 32; Iter   103/ 1097] train: loss: 0.0095204
[Epoch 32; Iter   133/ 1097] train: loss: 0.0669537
[Epoch 32; Iter   163/ 1097] train: loss: 0.0239669
[Epoch 32; Iter   193/ 1097] train: loss: 0.0914943
[Epoch 32; Iter   223/ 1097] train: loss: 0.0030488
[Epoch 32; Iter   253/ 1097] train: loss: 0.0033572
[Epoch 32; Iter   283/ 1097] train: loss: 0.0187166
[Epoch 32; Iter   313/ 1097] train: loss: 0.0272094
[Epoch 32; Iter   343/ 1097] train: loss: 0.0239171
[Epoch 32; Iter   373/ 1097] train: loss: 0.0550651
[Epoch 32; Iter   403/ 1097] train: loss: 0.0402690
[Epoch 32; Iter   433/ 1097] train: loss: 0.0101507
[Epoch 32; Iter   463/ 1097] train: loss: 0.0144837
[Epoch 32; Iter   493/ 1097] train: loss: 0.0413511
[Epoch 28; Iter   441/ 1097] train: loss: 0.0199647
[Epoch 28; Iter   471/ 1097] train: loss: 0.0508167
[Epoch 28; Iter   501/ 1097] train: loss: 0.0114812
[Epoch 28; Iter   531/ 1097] train: loss: 0.0991911
[Epoch 28; Iter   561/ 1097] train: loss: 0.0378905
[Epoch 28; Iter   591/ 1097] train: loss: 0.1146612
[Epoch 28; Iter   621/ 1097] train: loss: 0.0747156
[Epoch 28; Iter   651/ 1097] train: loss: 0.0421569
[Epoch 28; Iter   681/ 1097] train: loss: 0.0246861
[Epoch 28; Iter   711/ 1097] train: loss: 0.0857920
[Epoch 28; Iter   741/ 1097] train: loss: 0.1398055
[Epoch 28; Iter   771/ 1097] train: loss: 0.0675338
[Epoch 28; Iter   801/ 1097] train: loss: 0.2872815
[Epoch 28; Iter   831/ 1097] train: loss: 0.0113364
[Epoch 28; Iter   861/ 1097] train: loss: 0.0639400
[Epoch 28; Iter   891/ 1097] train: loss: 0.0404467
[Epoch 28; Iter   921/ 1097] train: loss: 0.0898408
[Epoch 28; Iter   951/ 1097] train: loss: 0.0119098
[Epoch 28; Iter   981/ 1097] train: loss: 0.0309734
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0089533
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1128374
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1210826
[Epoch 28] ogbg-molhiv: 0.772955 val loss: 0.353896
[Epoch 28] ogbg-molhiv: 0.744856 test loss: 0.210287
[Epoch 29; Iter     4/ 1097] train: loss: 0.0436118
[Epoch 29; Iter    34/ 1097] train: loss: 0.0294714
[Epoch 29; Iter    64/ 1097] train: loss: 0.3036365
[Epoch 29; Iter    94/ 1097] train: loss: 0.0286807
[Epoch 29; Iter   124/ 1097] train: loss: 0.0143003
[Epoch 29; Iter   154/ 1097] train: loss: 0.0155766
[Epoch 29; Iter   184/ 1097] train: loss: 0.0228317
[Epoch 29; Iter   214/ 1097] train: loss: 0.0727282
[Epoch 29; Iter   244/ 1097] train: loss: 0.0240921
[Epoch 29; Iter   274/ 1097] train: loss: 0.0336264
[Epoch 29; Iter   304/ 1097] train: loss: 0.0086379
[Epoch 29; Iter   334/ 1097] train: loss: 0.0482683
[Epoch 29; Iter   364/ 1097] train: loss: 0.0197473
[Epoch 29; Iter   394/ 1097] train: loss: 0.0114932
[Epoch 29; Iter   424/ 1097] train: loss: 0.0221570
[Epoch 29; Iter   454/ 1097] train: loss: 0.0162131
[Epoch 29; Iter   484/ 1097] train: loss: 0.0083966
[Epoch 29; Iter   514/ 1097] train: loss: 0.0862229
[Epoch 29; Iter   544/ 1097] train: loss: 0.0113477
[Epoch 29; Iter   574/ 1097] train: loss: 0.0091689
[Epoch 29; Iter   604/ 1097] train: loss: 0.0510630
[Epoch 29; Iter   634/ 1097] train: loss: 0.0168389
[Epoch 29; Iter   664/ 1097] train: loss: 0.0306005
[Epoch 29; Iter   694/ 1097] train: loss: 0.0975081
[Epoch 29; Iter   724/ 1097] train: loss: 0.0131211
[Epoch 29; Iter   754/ 1097] train: loss: 0.0228698
[Epoch 29; Iter   784/ 1097] train: loss: 0.0350046
[Epoch 29; Iter   814/ 1097] train: loss: 0.0809921
[Epoch 29; Iter   844/ 1097] train: loss: 0.0087862
[Epoch 29; Iter   874/ 1097] train: loss: 0.0135196
[Epoch 29; Iter   904/ 1097] train: loss: 0.0167935
[Epoch 29; Iter   934/ 1097] train: loss: 0.0454068
[Epoch 29; Iter   964/ 1097] train: loss: 0.0880615
[Epoch 29; Iter   994/ 1097] train: loss: 0.0471821
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0381844
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0607877
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1387011
[Epoch 29] ogbg-molhiv: 0.790356 val loss: 0.422809
[Epoch 29] ogbg-molhiv: 0.757985 test loss: 0.190829
[Epoch 30; Iter    17/ 1097] train: loss: 0.0402831
[Epoch 30; Iter    47/ 1097] train: loss: 0.0093337
[Epoch 30; Iter    77/ 1097] train: loss: 0.0092072
[Epoch 30; Iter   107/ 1097] train: loss: 0.0223968
[Epoch 30; Iter   137/ 1097] train: loss: 0.0141699
[Epoch 30; Iter   167/ 1097] train: loss: 0.0657040
[Epoch 30; Iter   197/ 1097] train: loss: 0.1236667
[Epoch 30; Iter   227/ 1097] train: loss: 0.0077061
[Epoch 30; Iter   257/ 1097] train: loss: 0.1550762
[Epoch 30; Iter   287/ 1097] train: loss: 0.0136853
[Epoch 30; Iter   317/ 1097] train: loss: 0.0737197
[Epoch 30; Iter   347/ 1097] train: loss: 0.0098768
[Epoch 30; Iter   377/ 1097] train: loss: 0.0877153
[Epoch 30; Iter   407/ 1097] train: loss: 0.0102389
[Epoch 30; Iter   437/ 1097] train: loss: 0.1369863
[Epoch 30; Iter   467/ 1097] train: loss: 0.0103455
[Epoch 30; Iter   497/ 1097] train: loss: 0.0956216
[Epoch 30; Iter   527/ 1097] train: loss: 0.0316989
[Epoch 30; Iter   557/ 1097] train: loss: 0.1778370
[Epoch 30; Iter   587/ 1097] train: loss: 0.1674216
[Epoch 30; Iter   617/ 1097] train: loss: 0.0078749
[Epoch 30; Iter   647/ 1097] train: loss: 0.0164280
[Epoch 30; Iter   677/ 1097] train: loss: 0.0071077
[Epoch 30; Iter   707/ 1097] train: loss: 0.0338541
[Epoch 30; Iter   737/ 1097] train: loss: 0.0043462
[Epoch 30; Iter   767/ 1097] train: loss: 0.0278331
[Epoch 30; Iter   797/ 1097] train: loss: 0.0168937
[Epoch 30; Iter   827/ 1097] train: loss: 0.0123845
[Epoch 30; Iter   857/ 1097] train: loss: 0.0208548
[Epoch 30; Iter   887/ 1097] train: loss: 0.0146482
[Epoch 30; Iter   917/ 1097] train: loss: 0.0187850
[Epoch 30; Iter   947/ 1097] train: loss: 0.0220832
[Epoch 30; Iter   977/ 1097] train: loss: 0.3170180
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0073340
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0438882
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0488512
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0047062
[Epoch 30] ogbg-molhiv: 0.783060 val loss: 0.531963
[Epoch 30] ogbg-molhiv: 0.762178 test loss: 0.282575
[Epoch 31; Iter    30/ 1097] train: loss: 0.0119267
[Epoch 31; Iter    60/ 1097] train: loss: 0.0702592
[Epoch 31; Iter    90/ 1097] train: loss: 0.0079735
[Epoch 31; Iter   120/ 1097] train: loss: 0.0237260
[Epoch 31; Iter   150/ 1097] train: loss: 0.0133992
[Epoch 31; Iter   180/ 1097] train: loss: 0.1060138
[Epoch 31; Iter   210/ 1097] train: loss: 0.0676941
[Epoch 31; Iter   240/ 1097] train: loss: 0.0653048
[Epoch 31; Iter   270/ 1097] train: loss: 0.0058994
[Epoch 31; Iter   300/ 1097] train: loss: 0.0208666
[Epoch 31; Iter   330/ 1097] train: loss: 0.0406920
[Epoch 31; Iter   360/ 1097] train: loss: 0.0021880
[Epoch 31; Iter   390/ 1097] train: loss: 0.0285567
[Epoch 31; Iter   420/ 1097] train: loss: 0.0278630
[Epoch 31; Iter   450/ 1097] train: loss: 0.0181955
[Epoch 31; Iter   480/ 1097] train: loss: 0.0770269
[Epoch 31; Iter   510/ 1097] train: loss: 0.0185299
[Epoch 31; Iter   540/ 1097] train: loss: 0.0976300
[Epoch 31; Iter   570/ 1097] train: loss: 0.0644818
[Epoch 31; Iter   600/ 1097] train: loss: 0.0080839
[Epoch 31; Iter   630/ 1097] train: loss: 0.0100815
[Epoch 31; Iter   660/ 1097] train: loss: 0.0020878
[Epoch 31; Iter   690/ 1097] train: loss: 0.0778909
[Epoch 31; Iter   720/ 1097] train: loss: 0.0601361
[Epoch 31; Iter   750/ 1097] train: loss: 0.0811293
[Epoch 31; Iter   780/ 1097] train: loss: 0.1416511
[Epoch 31; Iter   810/ 1097] train: loss: 0.0368848
[Epoch 31; Iter   840/ 1097] train: loss: 0.0032032
[Epoch 31; Iter   870/ 1097] train: loss: 0.0107413
[Epoch 31; Iter   900/ 1097] train: loss: 0.1695557
[Epoch 31; Iter   930/ 1097] train: loss: 0.1197674
[Epoch 31; Iter   960/ 1097] train: loss: 0.0325059
[Epoch 31; Iter   990/ 1097] train: loss: 0.0137472
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0623837
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0222031
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0096655
[Epoch 31] ogbg-molhiv: 0.780653 val loss: 0.339027
[Epoch 31] ogbg-molhiv: 0.755418 test loss: 0.270135
[Epoch 32; Iter    13/ 1097] train: loss: 0.2476506
[Epoch 32; Iter    43/ 1097] train: loss: 0.0143157
[Epoch 32; Iter    73/ 1097] train: loss: 0.0131699
[Epoch 32; Iter   103/ 1097] train: loss: 0.0028376
[Epoch 32; Iter   133/ 1097] train: loss: 0.0178843
[Epoch 32; Iter   163/ 1097] train: loss: 0.0180035
[Epoch 32; Iter   193/ 1097] train: loss: 0.0188342
[Epoch 32; Iter   223/ 1097] train: loss: 0.0384155
[Epoch 32; Iter   253/ 1097] train: loss: 0.0174935
[Epoch 32; Iter   283/ 1097] train: loss: 0.0442748
[Epoch 32; Iter   313/ 1097] train: loss: 0.0461972
[Epoch 32; Iter   343/ 1097] train: loss: 0.0167283
[Epoch 32; Iter   373/ 1097] train: loss: 0.0040944
[Epoch 32; Iter   403/ 1097] train: loss: 0.1237302
[Epoch 32; Iter   433/ 1097] train: loss: 0.0157207
[Epoch 32; Iter   463/ 1097] train: loss: 0.0065396
[Epoch 32; Iter   493/ 1097] train: loss: 0.0049734
[Epoch 28; Iter   441/ 1097] train: loss: 0.0631264
[Epoch 28; Iter   471/ 1097] train: loss: 0.0468298
[Epoch 28; Iter   501/ 1097] train: loss: 0.0255949
[Epoch 28; Iter   531/ 1097] train: loss: 0.0835040
[Epoch 28; Iter   561/ 1097] train: loss: 0.0904735
[Epoch 28; Iter   591/ 1097] train: loss: 0.0515593
[Epoch 28; Iter   621/ 1097] train: loss: 0.0316233
[Epoch 28; Iter   651/ 1097] train: loss: 0.1613275
[Epoch 28; Iter   681/ 1097] train: loss: 0.0580891
[Epoch 28; Iter   711/ 1097] train: loss: 0.0210140
[Epoch 28; Iter   741/ 1097] train: loss: 0.0190385
[Epoch 28; Iter   771/ 1097] train: loss: 0.0226292
[Epoch 28; Iter   801/ 1097] train: loss: 0.0073077
[Epoch 28; Iter   831/ 1097] train: loss: 0.0866194
[Epoch 28; Iter   861/ 1097] train: loss: 0.0315797
[Epoch 28; Iter   891/ 1097] train: loss: 0.0266714
[Epoch 28; Iter   921/ 1097] train: loss: 0.0102992
[Epoch 28; Iter   951/ 1097] train: loss: 0.0309213
[Epoch 28; Iter   981/ 1097] train: loss: 0.0855227
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0491160
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0312949
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0324747
[Epoch 28] ogbg-molhiv: 0.708915 val loss: 1.867822
[Epoch 28] ogbg-molhiv: 0.733741 test loss: 0.639731
[Epoch 29; Iter     4/ 1097] train: loss: 0.0177947
[Epoch 29; Iter    34/ 1097] train: loss: 0.1500006
[Epoch 29; Iter    64/ 1097] train: loss: 0.0098800
[Epoch 29; Iter    94/ 1097] train: loss: 0.0208494
[Epoch 29; Iter   124/ 1097] train: loss: 0.0208534
[Epoch 29; Iter   154/ 1097] train: loss: 0.0098475
[Epoch 29; Iter   184/ 1097] train: loss: 0.0118100
[Epoch 29; Iter   214/ 1097] train: loss: 0.0633420
[Epoch 29; Iter   244/ 1097] train: loss: 0.0694640
[Epoch 29; Iter   274/ 1097] train: loss: 0.0133435
[Epoch 29; Iter   304/ 1097] train: loss: 0.0448138
[Epoch 29; Iter   334/ 1097] train: loss: 0.1730176
[Epoch 29; Iter   364/ 1097] train: loss: 0.0280988
[Epoch 29; Iter   394/ 1097] train: loss: 0.0914165
[Epoch 29; Iter   424/ 1097] train: loss: 0.0114408
[Epoch 29; Iter   454/ 1097] train: loss: 0.0572296
[Epoch 29; Iter   484/ 1097] train: loss: 0.0696566
[Epoch 29; Iter   514/ 1097] train: loss: 0.0256478
[Epoch 29; Iter   544/ 1097] train: loss: 0.0355206
[Epoch 29; Iter   574/ 1097] train: loss: 0.0321760
[Epoch 29; Iter   604/ 1097] train: loss: 0.0235516
[Epoch 29; Iter   634/ 1097] train: loss: 0.0080313
[Epoch 29; Iter   664/ 1097] train: loss: 0.0358704
[Epoch 29; Iter   694/ 1097] train: loss: 0.1278733
[Epoch 29; Iter   724/ 1097] train: loss: 0.0181153
[Epoch 29; Iter   754/ 1097] train: loss: 0.0129583
[Epoch 29; Iter   784/ 1097] train: loss: 0.0173033
[Epoch 29; Iter   814/ 1097] train: loss: 0.0630130
[Epoch 29; Iter   844/ 1097] train: loss: 0.1041572
[Epoch 29; Iter   874/ 1097] train: loss: 0.0155700
[Epoch 29; Iter   904/ 1097] train: loss: 0.0961805
[Epoch 29; Iter   934/ 1097] train: loss: 0.0931960
[Epoch 29; Iter   964/ 1097] train: loss: 0.0461300
[Epoch 29; Iter   994/ 1097] train: loss: 0.2428983
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0562144
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0134630
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0365914
[Epoch 29] ogbg-molhiv: 0.726181 val loss: 0.127960
[Epoch 29] ogbg-molhiv: 0.703275 test loss: 0.162902
[Epoch 30; Iter    17/ 1097] train: loss: 0.0157052
[Epoch 30; Iter    47/ 1097] train: loss: 0.0325450
[Epoch 30; Iter    77/ 1097] train: loss: 0.0414051
[Epoch 30; Iter   107/ 1097] train: loss: 0.0135583
[Epoch 30; Iter   137/ 1097] train: loss: 0.0276584
[Epoch 30; Iter   167/ 1097] train: loss: 0.0087285
[Epoch 30; Iter   197/ 1097] train: loss: 0.1831149
[Epoch 30; Iter   227/ 1097] train: loss: 0.0107608
[Epoch 30; Iter   257/ 1097] train: loss: 0.0108706
[Epoch 30; Iter   287/ 1097] train: loss: 0.0214983
[Epoch 30; Iter   317/ 1097] train: loss: 0.0689080
[Epoch 30; Iter   347/ 1097] train: loss: 0.0469821
[Epoch 30; Iter   377/ 1097] train: loss: 0.0460844
[Epoch 30; Iter   407/ 1097] train: loss: 0.0747650
[Epoch 30; Iter   437/ 1097] train: loss: 0.2460223
[Epoch 30; Iter   467/ 1097] train: loss: 0.0207047
[Epoch 30; Iter   497/ 1097] train: loss: 0.0953824
[Epoch 30; Iter   527/ 1097] train: loss: 0.0247073
[Epoch 30; Iter   557/ 1097] train: loss: 0.0225308
[Epoch 30; Iter   587/ 1097] train: loss: 0.0139177
[Epoch 30; Iter   617/ 1097] train: loss: 0.0191606
[Epoch 30; Iter   647/ 1097] train: loss: 0.1181479
[Epoch 30; Iter   677/ 1097] train: loss: 0.0066891
[Epoch 30; Iter   707/ 1097] train: loss: 0.0269156
[Epoch 30; Iter   737/ 1097] train: loss: 0.1470118
[Epoch 30; Iter   767/ 1097] train: loss: 0.0099618
[Epoch 30; Iter   797/ 1097] train: loss: 0.0652918
[Epoch 30; Iter   827/ 1097] train: loss: 0.1477890
[Epoch 30; Iter   857/ 1097] train: loss: 0.0135708
[Epoch 30; Iter   887/ 1097] train: loss: 0.0394756
[Epoch 30; Iter   917/ 1097] train: loss: 0.0331716
[Epoch 30; Iter   947/ 1097] train: loss: 0.0652079
[Epoch 30; Iter   977/ 1097] train: loss: 0.0969633
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0652046
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0288982
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0331826
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0082746
[Epoch 30] ogbg-molhiv: 0.708750 val loss: 0.281691
[Epoch 30] ogbg-molhiv: 0.738518 test loss: 0.195865
[Epoch 31; Iter    30/ 1097] train: loss: 0.0212680
[Epoch 31; Iter    60/ 1097] train: loss: 0.0194451
[Epoch 31; Iter    90/ 1097] train: loss: 0.0234955
[Epoch 31; Iter   120/ 1097] train: loss: 0.0564529
[Epoch 31; Iter   150/ 1097] train: loss: 0.0923696
[Epoch 31; Iter   180/ 1097] train: loss: 0.0129528
[Epoch 31; Iter   210/ 1097] train: loss: 0.0151445
[Epoch 31; Iter   240/ 1097] train: loss: 0.0138285
[Epoch 31; Iter   270/ 1097] train: loss: 0.0078975
[Epoch 31; Iter   300/ 1097] train: loss: 0.0501861
[Epoch 31; Iter   330/ 1097] train: loss: 0.0184610
[Epoch 31; Iter   360/ 1097] train: loss: 0.0100500
[Epoch 31; Iter   390/ 1097] train: loss: 0.1345993
[Epoch 31; Iter   420/ 1097] train: loss: 0.0396266
[Epoch 31; Iter   450/ 1097] train: loss: 0.0117177
[Epoch 31; Iter   480/ 1097] train: loss: 0.0601229
[Epoch 31; Iter   510/ 1097] train: loss: 0.0419003
[Epoch 31; Iter   540/ 1097] train: loss: 0.0081479
[Epoch 31; Iter   570/ 1097] train: loss: 0.0197939
[Epoch 31; Iter   600/ 1097] train: loss: 0.0124694
[Epoch 31; Iter   630/ 1097] train: loss: 0.0610877
[Epoch 31; Iter   660/ 1097] train: loss: 0.0965598
[Epoch 31; Iter   690/ 1097] train: loss: 0.0520458
[Epoch 31; Iter   720/ 1097] train: loss: 0.0057298
[Epoch 31; Iter   750/ 1097] train: loss: 0.0496336
[Epoch 31; Iter   780/ 1097] train: loss: 0.0397093
[Epoch 31; Iter   810/ 1097] train: loss: 0.0172819
[Epoch 31; Iter   840/ 1097] train: loss: 0.0115901
[Epoch 31; Iter   870/ 1097] train: loss: 0.1489025
[Epoch 31; Iter   900/ 1097] train: loss: 0.0255065
[Epoch 31; Iter   930/ 1097] train: loss: 0.0900965
[Epoch 31; Iter   960/ 1097] train: loss: 0.0149726
[Epoch 31; Iter   990/ 1097] train: loss: 0.0251318
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0573066
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0332641
[Epoch 31; Iter  1080/ 1097] train: loss: 0.1605857
[Epoch 31] ogbg-molhiv: 0.692068 val loss: 0.208994
[Epoch 31] ogbg-molhiv: 0.698024 test loss: 0.521886
[Epoch 32; Iter    13/ 1097] train: loss: 0.0365079
[Epoch 32; Iter    43/ 1097] train: loss: 0.1508027
[Epoch 32; Iter    73/ 1097] train: loss: 0.0552592
[Epoch 32; Iter   103/ 1097] train: loss: 0.0091959
[Epoch 32; Iter   133/ 1097] train: loss: 0.0115127
[Epoch 32; Iter   163/ 1097] train: loss: 0.0298529
[Epoch 32; Iter   193/ 1097] train: loss: 0.0793307
[Epoch 32; Iter   223/ 1097] train: loss: 0.0304805
[Epoch 32; Iter   253/ 1097] train: loss: 0.0251810
[Epoch 32; Iter   283/ 1097] train: loss: 0.0054614
[Epoch 32; Iter   313/ 1097] train: loss: 0.2058748
[Epoch 32; Iter   343/ 1097] train: loss: 0.0158951
[Epoch 32; Iter   373/ 1097] train: loss: 0.0271576
[Epoch 32; Iter   403/ 1097] train: loss: 0.0291066
[Epoch 32; Iter   433/ 1097] train: loss: 0.0137314
[Epoch 32; Iter   463/ 1097] train: loss: 0.0069121
[Epoch 32; Iter   493/ 1097] train: loss: 0.0376804
[Epoch 28; Iter   441/ 1097] train: loss: 0.1528531
[Epoch 28; Iter   471/ 1097] train: loss: 0.1941673
[Epoch 28; Iter   501/ 1097] train: loss: 0.0446883
[Epoch 28; Iter   531/ 1097] train: loss: 0.0118868
[Epoch 28; Iter   561/ 1097] train: loss: 0.2018748
[Epoch 28; Iter   591/ 1097] train: loss: 0.0256491
[Epoch 28; Iter   621/ 1097] train: loss: 0.0263701
[Epoch 28; Iter   651/ 1097] train: loss: 0.0310064
[Epoch 28; Iter   681/ 1097] train: loss: 0.0315105
[Epoch 28; Iter   711/ 1097] train: loss: 0.0169620
[Epoch 28; Iter   741/ 1097] train: loss: 0.0258878
[Epoch 28; Iter   771/ 1097] train: loss: 0.0964100
[Epoch 28; Iter   801/ 1097] train: loss: 0.0141045
[Epoch 28; Iter   831/ 1097] train: loss: 0.2185619
[Epoch 28; Iter   861/ 1097] train: loss: 0.0440448
[Epoch 28; Iter   891/ 1097] train: loss: 0.0979955
[Epoch 28; Iter   921/ 1097] train: loss: 0.0192103
[Epoch 28; Iter   951/ 1097] train: loss: 0.0209148
[Epoch 28; Iter   981/ 1097] train: loss: 0.1103676
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0168900
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0531642
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0133608
[Epoch 28] ogbg-molhiv: 0.775530 val loss: 0.085603
[Epoch 28] ogbg-molhiv: 0.709065 test loss: 0.165845
[Epoch 29; Iter     4/ 1097] train: loss: 0.0256393
[Epoch 29; Iter    34/ 1097] train: loss: 0.0714960
[Epoch 29; Iter    64/ 1097] train: loss: 0.0349954
[Epoch 29; Iter    94/ 1097] train: loss: 0.0164054
[Epoch 29; Iter   124/ 1097] train: loss: 0.0245088
[Epoch 29; Iter   154/ 1097] train: loss: 0.0446308
[Epoch 29; Iter   184/ 1097] train: loss: 0.0082022
[Epoch 29; Iter   214/ 1097] train: loss: 0.0599441
[Epoch 29; Iter   244/ 1097] train: loss: 0.1376607
[Epoch 29; Iter   274/ 1097] train: loss: 0.0146771
[Epoch 29; Iter   304/ 1097] train: loss: 0.0222633
[Epoch 29; Iter   334/ 1097] train: loss: 0.1673056
[Epoch 29; Iter   364/ 1097] train: loss: 0.0840041
[Epoch 29; Iter   394/ 1097] train: loss: 0.0239058
[Epoch 29; Iter   424/ 1097] train: loss: 0.0479868
[Epoch 29; Iter   454/ 1097] train: loss: 0.0665159
[Epoch 29; Iter   484/ 1097] train: loss: 0.0130944
[Epoch 29; Iter   514/ 1097] train: loss: 0.0340086
[Epoch 29; Iter   544/ 1097] train: loss: 0.0069003
[Epoch 29; Iter   574/ 1097] train: loss: 0.0565522
[Epoch 29; Iter   604/ 1097] train: loss: 0.0122504
[Epoch 29; Iter   634/ 1097] train: loss: 0.1211328
[Epoch 29; Iter   664/ 1097] train: loss: 0.0126777
[Epoch 29; Iter   694/ 1097] train: loss: 0.3763262
[Epoch 29; Iter   724/ 1097] train: loss: 0.0123596
[Epoch 29; Iter   754/ 1097] train: loss: 0.0460583
[Epoch 29; Iter   784/ 1097] train: loss: 0.0252521
[Epoch 29; Iter   814/ 1097] train: loss: 0.0260959
[Epoch 29; Iter   844/ 1097] train: loss: 0.0798671
[Epoch 29; Iter   874/ 1097] train: loss: 0.0337494
[Epoch 29; Iter   904/ 1097] train: loss: 0.0554923
[Epoch 29; Iter   934/ 1097] train: loss: 0.0362958
[Epoch 29; Iter   964/ 1097] train: loss: 0.0517722
[Epoch 29; Iter   994/ 1097] train: loss: 0.1253644
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0753838
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0110446
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0451239
[Epoch 29] ogbg-molhiv: 0.801012 val loss: 0.095172
[Epoch 29] ogbg-molhiv: 0.715392 test loss: 0.160228
[Epoch 30; Iter    17/ 1097] train: loss: 0.0249818
[Epoch 30; Iter    47/ 1097] train: loss: 0.0342432
[Epoch 30; Iter    77/ 1097] train: loss: 0.0134405
[Epoch 30; Iter   107/ 1097] train: loss: 0.0660190
[Epoch 30; Iter   137/ 1097] train: loss: 0.0456138
[Epoch 30; Iter   167/ 1097] train: loss: 0.0142248
[Epoch 30; Iter   197/ 1097] train: loss: 0.0486100
[Epoch 30; Iter   227/ 1097] train: loss: 0.0224034
[Epoch 30; Iter   257/ 1097] train: loss: 0.0363632
[Epoch 30; Iter   287/ 1097] train: loss: 0.0216985
[Epoch 30; Iter   317/ 1097] train: loss: 0.1502345
[Epoch 30; Iter   347/ 1097] train: loss: 0.0196323
[Epoch 30; Iter   377/ 1097] train: loss: 0.0247430
[Epoch 30; Iter   407/ 1097] train: loss: 0.0406236
[Epoch 30; Iter   437/ 1097] train: loss: 0.0466604
[Epoch 30; Iter   467/ 1097] train: loss: 0.0383631
[Epoch 30; Iter   497/ 1097] train: loss: 0.0660156
[Epoch 30; Iter   527/ 1097] train: loss: 0.0605535
[Epoch 30; Iter   557/ 1097] train: loss: 0.3103545
[Epoch 30; Iter   587/ 1097] train: loss: 0.0114734
[Epoch 30; Iter   617/ 1097] train: loss: 0.0138490
[Epoch 30; Iter   647/ 1097] train: loss: 0.0437514
[Epoch 30; Iter   677/ 1097] train: loss: 0.0101615
[Epoch 30; Iter   707/ 1097] train: loss: 0.0775030
[Epoch 30; Iter   737/ 1097] train: loss: 0.0340836
[Epoch 30; Iter   767/ 1097] train: loss: 0.0093363
[Epoch 30; Iter   797/ 1097] train: loss: 0.0719401
[Epoch 30; Iter   827/ 1097] train: loss: 0.0433309
[Epoch 30; Iter   857/ 1097] train: loss: 0.0614531
[Epoch 30; Iter   887/ 1097] train: loss: 0.0777214
[Epoch 30; Iter   917/ 1097] train: loss: 0.0341352
[Epoch 30; Iter   947/ 1097] train: loss: 0.1414543
[Epoch 30; Iter   977/ 1097] train: loss: 0.0498007
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0360641
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0607529
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0560247
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0078080
[Epoch 30] ogbg-molhiv: 0.800212 val loss: 0.082159
[Epoch 30] ogbg-molhiv: 0.744580 test loss: 0.139526
[Epoch 31; Iter    30/ 1097] train: loss: 0.0142362
[Epoch 31; Iter    60/ 1097] train: loss: 0.0229417
[Epoch 31; Iter    90/ 1097] train: loss: 0.0195805
[Epoch 31; Iter   120/ 1097] train: loss: 0.0184156
[Epoch 31; Iter   150/ 1097] train: loss: 0.0812282
[Epoch 31; Iter   180/ 1097] train: loss: 0.0497888
[Epoch 31; Iter   210/ 1097] train: loss: 0.0100713
[Epoch 31; Iter   240/ 1097] train: loss: 0.0219691
[Epoch 31; Iter   270/ 1097] train: loss: 0.0437987
[Epoch 31; Iter   300/ 1097] train: loss: 0.0157147
[Epoch 31; Iter   330/ 1097] train: loss: 0.0575978
[Epoch 31; Iter   360/ 1097] train: loss: 0.0106381
[Epoch 31; Iter   390/ 1097] train: loss: 0.2023370
[Epoch 31; Iter   420/ 1097] train: loss: 0.0301199
[Epoch 31; Iter   450/ 1097] train: loss: 0.0056715
[Epoch 31; Iter   480/ 1097] train: loss: 0.0209340
[Epoch 31; Iter   510/ 1097] train: loss: 0.0118095
[Epoch 31; Iter   540/ 1097] train: loss: 0.0286841
[Epoch 31; Iter   570/ 1097] train: loss: 0.0847050
[Epoch 31; Iter   600/ 1097] train: loss: 0.0097251
[Epoch 31; Iter   630/ 1097] train: loss: 0.0414261
[Epoch 31; Iter   660/ 1097] train: loss: 0.1469877
[Epoch 31; Iter   690/ 1097] train: loss: 0.0407122
[Epoch 31; Iter   720/ 1097] train: loss: 0.0400784
[Epoch 31; Iter   750/ 1097] train: loss: 0.0656037
[Epoch 31; Iter   780/ 1097] train: loss: 0.0406114
[Epoch 31; Iter   810/ 1097] train: loss: 0.0171107
[Epoch 31; Iter   840/ 1097] train: loss: 0.0095348
[Epoch 31; Iter   870/ 1097] train: loss: 0.0071480
[Epoch 31; Iter   900/ 1097] train: loss: 0.0711518
[Epoch 31; Iter   930/ 1097] train: loss: 0.0821616
[Epoch 31; Iter   960/ 1097] train: loss: 0.0066023
[Epoch 31; Iter   990/ 1097] train: loss: 0.0479312
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0096228
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0145740
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2114097
[Epoch 31] ogbg-molhiv: 0.742109 val loss: 0.100614
[Epoch 31] ogbg-molhiv: 0.671417 test loss: 0.189008
[Epoch 32; Iter    13/ 1097] train: loss: 0.0248796
[Epoch 32; Iter    43/ 1097] train: loss: 0.2565721
[Epoch 32; Iter    73/ 1097] train: loss: 0.0195080
[Epoch 32; Iter   103/ 1097] train: loss: 0.0201042
[Epoch 32; Iter   133/ 1097] train: loss: 0.0108139
[Epoch 32; Iter   163/ 1097] train: loss: 0.0054480
[Epoch 32; Iter   193/ 1097] train: loss: 0.0278734
[Epoch 32; Iter   223/ 1097] train: loss: 0.0154869
[Epoch 32; Iter   253/ 1097] train: loss: 0.0059483
[Epoch 32; Iter   283/ 1097] train: loss: 0.1020685
[Epoch 32; Iter   313/ 1097] train: loss: 0.0548441
[Epoch 32; Iter   343/ 1097] train: loss: 0.0355185
[Epoch 32; Iter   373/ 1097] train: loss: 0.2060659
[Epoch 32; Iter   403/ 1097] train: loss: 0.0653066
[Epoch 32; Iter   433/ 1097] train: loss: 0.0418398
[Epoch 32; Iter   463/ 1097] train: loss: 0.0808264
[Epoch 32; Iter   493/ 1097] train: loss: 0.0339157
[Epoch 28; Iter   441/ 1097] train: loss: 0.0311037
[Epoch 28; Iter   471/ 1097] train: loss: 0.0152542
[Epoch 28; Iter   501/ 1097] train: loss: 0.0332816
[Epoch 28; Iter   531/ 1097] train: loss: 0.1675371
[Epoch 28; Iter   561/ 1097] train: loss: 0.0304348
[Epoch 28; Iter   591/ 1097] train: loss: 0.1108907
[Epoch 28; Iter   621/ 1097] train: loss: 0.1280780
[Epoch 28; Iter   651/ 1097] train: loss: 0.1022568
[Epoch 28; Iter   681/ 1097] train: loss: 0.0174318
[Epoch 28; Iter   711/ 1097] train: loss: 0.1208013
[Epoch 28; Iter   741/ 1097] train: loss: 0.0557637
[Epoch 28; Iter   771/ 1097] train: loss: 0.0681068
[Epoch 28; Iter   801/ 1097] train: loss: 0.2283853
[Epoch 28; Iter   831/ 1097] train: loss: 0.0222958
[Epoch 28; Iter   861/ 1097] train: loss: 0.0977275
[Epoch 28; Iter   891/ 1097] train: loss: 0.1118486
[Epoch 28; Iter   921/ 1097] train: loss: 0.0226726
[Epoch 28; Iter   951/ 1097] train: loss: 0.0349348
[Epoch 28; Iter   981/ 1097] train: loss: 0.0267020
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0358554
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0633734
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1865190
[Epoch 28] ogbg-molhiv: 0.764872 val loss: 0.211152
[Epoch 28] ogbg-molhiv: 0.681736 test loss: 0.163863
[Epoch 29; Iter     4/ 1097] train: loss: 0.0751968
[Epoch 29; Iter    34/ 1097] train: loss: 0.0337357
[Epoch 29; Iter    64/ 1097] train: loss: 0.2471998
[Epoch 29; Iter    94/ 1097] train: loss: 0.0095320
[Epoch 29; Iter   124/ 1097] train: loss: 0.0191179
[Epoch 29; Iter   154/ 1097] train: loss: 0.1327220
[Epoch 29; Iter   184/ 1097] train: loss: 0.0945955
[Epoch 29; Iter   214/ 1097] train: loss: 0.1627800
[Epoch 29; Iter   244/ 1097] train: loss: 0.0276773
[Epoch 29; Iter   274/ 1097] train: loss: 0.0381104
[Epoch 29; Iter   304/ 1097] train: loss: 0.0493174
[Epoch 29; Iter   334/ 1097] train: loss: 0.0183969
[Epoch 29; Iter   364/ 1097] train: loss: 0.1785810
[Epoch 29; Iter   394/ 1097] train: loss: 0.0395949
[Epoch 29; Iter   424/ 1097] train: loss: 0.0388633
[Epoch 29; Iter   454/ 1097] train: loss: 0.0534584
[Epoch 29; Iter   484/ 1097] train: loss: 0.0194113
[Epoch 29; Iter   514/ 1097] train: loss: 0.1427454
[Epoch 29; Iter   544/ 1097] train: loss: 0.0134542
[Epoch 29; Iter   574/ 1097] train: loss: 0.0105276
[Epoch 29; Iter   604/ 1097] train: loss: 0.0211061
[Epoch 29; Iter   634/ 1097] train: loss: 0.0063157
[Epoch 29; Iter   664/ 1097] train: loss: 0.0410909
[Epoch 29; Iter   694/ 1097] train: loss: 0.0937786
[Epoch 29; Iter   724/ 1097] train: loss: 0.0819553
[Epoch 29; Iter   754/ 1097] train: loss: 0.0236101
[Epoch 29; Iter   784/ 1097] train: loss: 0.1115371
[Epoch 29; Iter   814/ 1097] train: loss: 0.0596383
[Epoch 29; Iter   844/ 1097] train: loss: 0.0095308
[Epoch 29; Iter   874/ 1097] train: loss: 0.0062386
[Epoch 29; Iter   904/ 1097] train: loss: 0.0457706
[Epoch 29; Iter   934/ 1097] train: loss: 0.0238418
[Epoch 29; Iter   964/ 1097] train: loss: 0.0866328
[Epoch 29; Iter   994/ 1097] train: loss: 0.0069941
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0355765
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0925208
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1953135
[Epoch 29] ogbg-molhiv: 0.788501 val loss: 0.418770
[Epoch 29] ogbg-molhiv: 0.700473 test loss: 0.189629
[Epoch 30; Iter    17/ 1097] train: loss: 0.0853546
[Epoch 30; Iter    47/ 1097] train: loss: 0.0105353
[Epoch 30; Iter    77/ 1097] train: loss: 0.0054204
[Epoch 30; Iter   107/ 1097] train: loss: 0.0074167
[Epoch 30; Iter   137/ 1097] train: loss: 0.0170068
[Epoch 30; Iter   167/ 1097] train: loss: 0.1321169
[Epoch 30; Iter   197/ 1097] train: loss: 0.1012199
[Epoch 30; Iter   227/ 1097] train: loss: 0.1085512
[Epoch 30; Iter   257/ 1097] train: loss: 0.1035805
[Epoch 30; Iter   287/ 1097] train: loss: 0.0471041
[Epoch 30; Iter   317/ 1097] train: loss: 0.0575760
[Epoch 30; Iter   347/ 1097] train: loss: 0.0118483
[Epoch 30; Iter   377/ 1097] train: loss: 0.2283436
[Epoch 30; Iter   407/ 1097] train: loss: 0.0160026
[Epoch 30; Iter   437/ 1097] train: loss: 0.0344138
[Epoch 30; Iter   467/ 1097] train: loss: 0.0178246
[Epoch 30; Iter   497/ 1097] train: loss: 0.1822183
[Epoch 30; Iter   527/ 1097] train: loss: 0.0284496
[Epoch 30; Iter   557/ 1097] train: loss: 0.0561757
[Epoch 30; Iter   587/ 1097] train: loss: 0.3081013
[Epoch 30; Iter   617/ 1097] train: loss: 0.0165028
[Epoch 30; Iter   647/ 1097] train: loss: 0.2462803
[Epoch 30; Iter   677/ 1097] train: loss: 0.0109299
[Epoch 30; Iter   707/ 1097] train: loss: 0.0324874
[Epoch 30; Iter   737/ 1097] train: loss: 0.0048724
[Epoch 30; Iter   767/ 1097] train: loss: 0.0240848
[Epoch 30; Iter   797/ 1097] train: loss: 0.0161122
[Epoch 30; Iter   827/ 1097] train: loss: 0.0312403
[Epoch 30; Iter   857/ 1097] train: loss: 0.0105723
[Epoch 30; Iter   887/ 1097] train: loss: 0.0095651
[Epoch 30; Iter   917/ 1097] train: loss: 0.0230400
[Epoch 30; Iter   947/ 1097] train: loss: 0.0566395
[Epoch 30; Iter   977/ 1097] train: loss: 0.0200989
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0122206
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0309972
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0088607
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0197902
[Epoch 30] ogbg-molhiv: 0.769462 val loss: 0.108501
[Epoch 30] ogbg-molhiv: 0.719803 test loss: 0.197914
[Epoch 31; Iter    30/ 1097] train: loss: 0.0582245
[Epoch 31; Iter    60/ 1097] train: loss: 0.0272508
[Epoch 31; Iter    90/ 1097] train: loss: 0.0426604
[Epoch 31; Iter   120/ 1097] train: loss: 0.0092431
[Epoch 31; Iter   150/ 1097] train: loss: 0.0101651
[Epoch 31; Iter   180/ 1097] train: loss: 0.0201958
[Epoch 31; Iter   210/ 1097] train: loss: 0.0357883
[Epoch 31; Iter   240/ 1097] train: loss: 0.1133993
[Epoch 31; Iter   270/ 1097] train: loss: 0.0364089
[Epoch 31; Iter   300/ 1097] train: loss: 0.0199111
[Epoch 31; Iter   330/ 1097] train: loss: 0.0090635
[Epoch 31; Iter   360/ 1097] train: loss: 0.0049354
[Epoch 31; Iter   390/ 1097] train: loss: 0.0422657
[Epoch 31; Iter   420/ 1097] train: loss: 0.0057301
[Epoch 31; Iter   450/ 1097] train: loss: 0.0118508
[Epoch 31; Iter   480/ 1097] train: loss: 0.0635903
[Epoch 31; Iter   510/ 1097] train: loss: 0.0301886
[Epoch 31; Iter   540/ 1097] train: loss: 0.0251958
[Epoch 31; Iter   570/ 1097] train: loss: 0.0593724
[Epoch 31; Iter   600/ 1097] train: loss: 0.0073478
[Epoch 31; Iter   630/ 1097] train: loss: 0.0491856
[Epoch 31; Iter   660/ 1097] train: loss: 0.0035362
[Epoch 31; Iter   690/ 1097] train: loss: 0.0163091
[Epoch 31; Iter   720/ 1097] train: loss: 0.0425450
[Epoch 31; Iter   750/ 1097] train: loss: 0.1443593
[Epoch 31; Iter   780/ 1097] train: loss: 0.0617795
[Epoch 31; Iter   810/ 1097] train: loss: 0.0364635
[Epoch 31; Iter   840/ 1097] train: loss: 0.0123578
[Epoch 31; Iter   870/ 1097] train: loss: 0.0534997
[Epoch 31; Iter   900/ 1097] train: loss: 0.1082079
[Epoch 31; Iter   930/ 1097] train: loss: 0.0552418
[Epoch 31; Iter   960/ 1097] train: loss: 0.0115266
[Epoch 31; Iter   990/ 1097] train: loss: 0.0322601
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1201992
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0131601
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0823198
[Epoch 31] ogbg-molhiv: 0.732189 val loss: 0.118613
[Epoch 31] ogbg-molhiv: 0.705373 test loss: 0.222008
[Epoch 32; Iter    13/ 1097] train: loss: 0.1603585
[Epoch 32; Iter    43/ 1097] train: loss: 0.0199038
[Epoch 32; Iter    73/ 1097] train: loss: 0.0072346
[Epoch 32; Iter   103/ 1097] train: loss: 0.0323601
[Epoch 32; Iter   133/ 1097] train: loss: 0.0216806
[Epoch 32; Iter   163/ 1097] train: loss: 0.0391923
[Epoch 32; Iter   193/ 1097] train: loss: 0.0997043
[Epoch 32; Iter   223/ 1097] train: loss: 0.0223754
[Epoch 32; Iter   253/ 1097] train: loss: 0.0069892
[Epoch 32; Iter   283/ 1097] train: loss: 0.0229903
[Epoch 32; Iter   313/ 1097] train: loss: 0.0105139
[Epoch 32; Iter   343/ 1097] train: loss: 0.0168484
[Epoch 32; Iter   373/ 1097] train: loss: 0.0070669
[Epoch 32; Iter   403/ 1097] train: loss: 0.2141403
[Epoch 32; Iter   433/ 1097] train: loss: 0.0141997
[Epoch 32; Iter   463/ 1097] train: loss: 0.0063559
[Epoch 32; Iter   493/ 1097] train: loss: 0.1902413
[Epoch 28; Iter   441/ 1097] train: loss: 0.5728854
[Epoch 28; Iter   471/ 1097] train: loss: 0.0126485
[Epoch 28; Iter   501/ 1097] train: loss: 0.1137775
[Epoch 28; Iter   531/ 1097] train: loss: 0.0175486
[Epoch 28; Iter   561/ 1097] train: loss: 0.0977268
[Epoch 28; Iter   591/ 1097] train: loss: 0.0480666
[Epoch 28; Iter   621/ 1097] train: loss: 0.1469631
[Epoch 28; Iter   651/ 1097] train: loss: 0.0351074
[Epoch 28; Iter   681/ 1097] train: loss: 0.0224259
[Epoch 28; Iter   711/ 1097] train: loss: 0.0189601
[Epoch 28; Iter   741/ 1097] train: loss: 0.0150001
[Epoch 28; Iter   771/ 1097] train: loss: 0.0590282
[Epoch 28; Iter   801/ 1097] train: loss: 0.0273666
[Epoch 28; Iter   831/ 1097] train: loss: 0.0089286
[Epoch 28; Iter   861/ 1097] train: loss: 0.1609283
[Epoch 28; Iter   891/ 1097] train: loss: 0.0644427
[Epoch 28; Iter   921/ 1097] train: loss: 0.0159465
[Epoch 28; Iter   951/ 1097] train: loss: 0.0477931
[Epoch 28; Iter   981/ 1097] train: loss: 0.0405266
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0148919
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0121975
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0449893
[Epoch 28] ogbg-molhiv: 0.776519 val loss: 0.114193
[Epoch 28] ogbg-molhiv: 0.805964 test loss: 0.144079
[Epoch 29; Iter     4/ 1097] train: loss: 0.0250174
[Epoch 29; Iter    34/ 1097] train: loss: 0.0080531
[Epoch 29; Iter    64/ 1097] train: loss: 0.0158669
[Epoch 29; Iter    94/ 1097] train: loss: 0.0170388
[Epoch 29; Iter   124/ 1097] train: loss: 0.0704982
[Epoch 29; Iter   154/ 1097] train: loss: 0.0763028
[Epoch 29; Iter   184/ 1097] train: loss: 0.0140947
[Epoch 29; Iter   214/ 1097] train: loss: 0.0372660
[Epoch 29; Iter   244/ 1097] train: loss: 0.0075443
[Epoch 29; Iter   274/ 1097] train: loss: 0.0136968
[Epoch 29; Iter   304/ 1097] train: loss: 0.0987954
[Epoch 29; Iter   334/ 1097] train: loss: 0.0377175
[Epoch 29; Iter   364/ 1097] train: loss: 0.0299718
[Epoch 29; Iter   394/ 1097] train: loss: 0.0188341
[Epoch 29; Iter   424/ 1097] train: loss: 0.0340403
[Epoch 29; Iter   454/ 1097] train: loss: 0.0195496
[Epoch 29; Iter   484/ 1097] train: loss: 0.0078368
[Epoch 29; Iter   514/ 1097] train: loss: 0.0339652
[Epoch 29; Iter   544/ 1097] train: loss: 0.0113049
[Epoch 29; Iter   574/ 1097] train: loss: 0.0297198
[Epoch 29; Iter   604/ 1097] train: loss: 0.0683735
[Epoch 29; Iter   634/ 1097] train: loss: 0.1416548
[Epoch 29; Iter   664/ 1097] train: loss: 0.0075723
[Epoch 29; Iter   694/ 1097] train: loss: 0.0159559
[Epoch 29; Iter   724/ 1097] train: loss: 0.0240895
[Epoch 29; Iter   754/ 1097] train: loss: 0.0171407
[Epoch 29; Iter   784/ 1097] train: loss: 0.0087424
[Epoch 29; Iter   814/ 1097] train: loss: 0.0087483
[Epoch 29; Iter   844/ 1097] train: loss: 0.0180781
[Epoch 29; Iter   874/ 1097] train: loss: 0.3258592
[Epoch 29; Iter   904/ 1097] train: loss: 0.0072212
[Epoch 29; Iter   934/ 1097] train: loss: 0.0345488
[Epoch 29; Iter   964/ 1097] train: loss: 0.0084414
[Epoch 29; Iter   994/ 1097] train: loss: 0.0069837
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0147123
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0141052
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0042185
[Epoch 29] ogbg-molhiv: 0.747704 val loss: 0.137980
[Epoch 29] ogbg-molhiv: 0.788791 test loss: 0.161656
[Epoch 30; Iter    17/ 1097] train: loss: 0.0052791
[Epoch 30; Iter    47/ 1097] train: loss: 0.1198504
[Epoch 30; Iter    77/ 1097] train: loss: 0.0061739
[Epoch 30; Iter   107/ 1097] train: loss: 0.0123347
[Epoch 30; Iter   137/ 1097] train: loss: 0.0126290
[Epoch 30; Iter   167/ 1097] train: loss: 0.0093901
[Epoch 30; Iter   197/ 1097] train: loss: 0.0101062
[Epoch 30; Iter   227/ 1097] train: loss: 0.0248567
[Epoch 30; Iter   257/ 1097] train: loss: 0.0282032
[Epoch 30; Iter   287/ 1097] train: loss: 0.0281055
[Epoch 30; Iter   317/ 1097] train: loss: 0.0478289
[Epoch 30; Iter   347/ 1097] train: loss: 0.0103167
[Epoch 30; Iter   377/ 1097] train: loss: 0.0354977
[Epoch 30; Iter   407/ 1097] train: loss: 0.0445333
[Epoch 30; Iter   437/ 1097] train: loss: 0.0183203
[Epoch 30; Iter   467/ 1097] train: loss: 0.0075966
[Epoch 30; Iter   497/ 1097] train: loss: 0.0768059
[Epoch 30; Iter   527/ 1097] train: loss: 0.2082325
[Epoch 30; Iter   557/ 1097] train: loss: 0.0965538
[Epoch 30; Iter   587/ 1097] train: loss: 0.0095829
[Epoch 30; Iter   617/ 1097] train: loss: 0.0078906
[Epoch 30; Iter   647/ 1097] train: loss: 0.0408266
[Epoch 30; Iter   677/ 1097] train: loss: 0.0147509
[Epoch 30; Iter   707/ 1097] train: loss: 0.0743340
[Epoch 30; Iter   737/ 1097] train: loss: 0.0096307
[Epoch 30; Iter   767/ 1097] train: loss: 0.0140369
[Epoch 30; Iter   797/ 1097] train: loss: 0.0699503
[Epoch 30; Iter   827/ 1097] train: loss: 0.0276054
[Epoch 30; Iter   857/ 1097] train: loss: 0.0290040
[Epoch 30; Iter   887/ 1097] train: loss: 0.0752445
[Epoch 30; Iter   917/ 1097] train: loss: 0.0641463
[Epoch 30; Iter   947/ 1097] train: loss: 0.0358074
[Epoch 30; Iter   977/ 1097] train: loss: 0.0090168
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0180078
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0126175
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0045412
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0261559
[Epoch 30] ogbg-molhiv: 0.782306 val loss: 0.142688
[Epoch 30] ogbg-molhiv: 0.798376 test loss: 0.182478
[Epoch 31; Iter    30/ 1097] train: loss: 0.0029443
[Epoch 31; Iter    60/ 1097] train: loss: 0.1181078
[Epoch 31; Iter    90/ 1097] train: loss: 0.0102589
[Epoch 31; Iter   120/ 1097] train: loss: 0.0215471
[Epoch 31; Iter   150/ 1097] train: loss: 0.1363505
[Epoch 31; Iter   180/ 1097] train: loss: 0.0072934
[Epoch 31; Iter   210/ 1097] train: loss: 0.0071015
[Epoch 31; Iter   240/ 1097] train: loss: 0.0140494
[Epoch 31; Iter   270/ 1097] train: loss: 0.0981214
[Epoch 31; Iter   300/ 1097] train: loss: 0.0065889
[Epoch 31; Iter   330/ 1097] train: loss: 0.0114192
[Epoch 31; Iter   360/ 1097] train: loss: 0.0328152
[Epoch 31; Iter   390/ 1097] train: loss: 0.0062460
[Epoch 31; Iter   420/ 1097] train: loss: 0.0272558
[Epoch 31; Iter   450/ 1097] train: loss: 0.0473186
[Epoch 31; Iter   480/ 1097] train: loss: 0.0389007
[Epoch 31; Iter   510/ 1097] train: loss: 0.0148702
[Epoch 31; Iter   540/ 1097] train: loss: 0.0122475
[Epoch 31; Iter   570/ 1097] train: loss: 0.0511992
[Epoch 31; Iter   600/ 1097] train: loss: 0.0055266
[Epoch 31; Iter   630/ 1097] train: loss: 0.0659734
[Epoch 31; Iter   660/ 1097] train: loss: 0.0531938
[Epoch 31; Iter   690/ 1097] train: loss: 0.0072387
[Epoch 31; Iter   720/ 1097] train: loss: 0.0239650
[Epoch 31; Iter   750/ 1097] train: loss: 0.0041828
[Epoch 31; Iter   780/ 1097] train: loss: 0.0043619
[Epoch 31; Iter   810/ 1097] train: loss: 0.0055790
[Epoch 31; Iter   840/ 1097] train: loss: 0.0241573
[Epoch 31; Iter   870/ 1097] train: loss: 0.0308922
[Epoch 31; Iter   900/ 1097] train: loss: 0.0156075
[Epoch 31; Iter   930/ 1097] train: loss: 0.0115031
[Epoch 31; Iter   960/ 1097] train: loss: 0.0721467
[Epoch 31; Iter   990/ 1097] train: loss: 0.0064462
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0405531
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0718445
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0150294
[Epoch 31] ogbg-molhiv: 0.759602 val loss: 0.185310
[Epoch 31] ogbg-molhiv: 0.794053 test loss: 0.189209
[Epoch 32; Iter    13/ 1097] train: loss: 0.0378918
[Epoch 32; Iter    43/ 1097] train: loss: 0.0765243
[Epoch 32; Iter    73/ 1097] train: loss: 0.0245718
[Epoch 32; Iter   103/ 1097] train: loss: 0.0355305
[Epoch 32; Iter   133/ 1097] train: loss: 0.0240453
[Epoch 32; Iter   163/ 1097] train: loss: 0.0075469
[Epoch 32; Iter   193/ 1097] train: loss: 0.0059190
[Epoch 32; Iter   223/ 1097] train: loss: 0.0084244
[Epoch 32; Iter   253/ 1097] train: loss: 0.0013804
[Epoch 32; Iter   283/ 1097] train: loss: 0.0063807
[Epoch 32; Iter   313/ 1097] train: loss: 0.0101515
[Epoch 32; Iter   343/ 1097] train: loss: 0.0035158
[Epoch 32; Iter   373/ 1097] train: loss: 0.1366772
[Epoch 32; Iter   403/ 1097] train: loss: 0.0084836
[Epoch 32; Iter   433/ 1097] train: loss: 0.0112098
[Epoch 32; Iter   463/ 1097] train: loss: 0.0325877
[Epoch 32; Iter   493/ 1097] train: loss: 0.0347441
[Epoch 24; Iter   359/ 1097] train: loss: 0.1216990
[Epoch 24; Iter   389/ 1097] train: loss: 0.0507121
[Epoch 24; Iter   419/ 1097] train: loss: 0.0202906
[Epoch 24; Iter   449/ 1097] train: loss: 0.0372821
[Epoch 24; Iter   479/ 1097] train: loss: 0.2432768
[Epoch 24; Iter   509/ 1097] train: loss: 0.1207021
[Epoch 24; Iter   539/ 1097] train: loss: 0.0318986
[Epoch 24; Iter   569/ 1097] train: loss: 0.0702541
[Epoch 24; Iter   599/ 1097] train: loss: 0.1207584
[Epoch 24; Iter   629/ 1097] train: loss: 0.0334734
[Epoch 24; Iter   659/ 1097] train: loss: 0.1274116
[Epoch 24; Iter   689/ 1097] train: loss: 0.1028061
[Epoch 24; Iter   719/ 1097] train: loss: 0.0275774
[Epoch 24; Iter   749/ 1097] train: loss: 0.0552332
[Epoch 24; Iter   779/ 1097] train: loss: 0.2211022
[Epoch 24; Iter   809/ 1097] train: loss: 0.1656821
[Epoch 24; Iter   839/ 1097] train: loss: 0.1588445
[Epoch 24; Iter   869/ 1097] train: loss: 0.0261062
[Epoch 24; Iter   899/ 1097] train: loss: 0.0218095
[Epoch 24; Iter   929/ 1097] train: loss: 0.0309745
[Epoch 24; Iter   959/ 1097] train: loss: 0.0141561
[Epoch 24; Iter   989/ 1097] train: loss: 0.0260950
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3004429
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0276314
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0882181
[Epoch 24] ogbg-molhiv: 0.781752 val loss: 0.077493
[Epoch 24] ogbg-molhiv: 0.745949 test loss: 0.121787
[Epoch 25; Iter    12/ 1097] train: loss: 0.0755985
[Epoch 25; Iter    42/ 1097] train: loss: 0.1746873
[Epoch 25; Iter    72/ 1097] train: loss: 0.3045093
[Epoch 25; Iter   102/ 1097] train: loss: 0.0585933
[Epoch 25; Iter   132/ 1097] train: loss: 0.0297562
[Epoch 25; Iter   162/ 1097] train: loss: 0.0198201
[Epoch 25; Iter   192/ 1097] train: loss: 0.0260530
[Epoch 25; Iter   222/ 1097] train: loss: 0.1498071
[Epoch 25; Iter   252/ 1097] train: loss: 0.0177868
[Epoch 25; Iter   282/ 1097] train: loss: 0.0205835
[Epoch 25; Iter   312/ 1097] train: loss: 0.0316003
[Epoch 25; Iter   342/ 1097] train: loss: 0.0900802
[Epoch 25; Iter   372/ 1097] train: loss: 0.0165801
[Epoch 25; Iter   402/ 1097] train: loss: 0.0345748
[Epoch 25; Iter   432/ 1097] train: loss: 0.0889913
[Epoch 25; Iter   462/ 1097] train: loss: 0.1735041
[Epoch 25; Iter   492/ 1097] train: loss: 0.1177188
[Epoch 25; Iter   522/ 1097] train: loss: 0.0269348
[Epoch 25; Iter   552/ 1097] train: loss: 0.2257787
[Epoch 25; Iter   582/ 1097] train: loss: 0.2340434
[Epoch 25; Iter   612/ 1097] train: loss: 0.0147729
[Epoch 25; Iter   642/ 1097] train: loss: 0.3593193
[Epoch 25; Iter   672/ 1097] train: loss: 0.1142332
[Epoch 25; Iter   702/ 1097] train: loss: 0.0364149
[Epoch 25; Iter   732/ 1097] train: loss: 0.2392014
[Epoch 25; Iter   762/ 1097] train: loss: 0.0821654
[Epoch 25; Iter   792/ 1097] train: loss: 0.2198182
[Epoch 25; Iter   822/ 1097] train: loss: 0.0213285
[Epoch 25; Iter   852/ 1097] train: loss: 0.0256744
[Epoch 25; Iter   882/ 1097] train: loss: 0.0158094
[Epoch 25; Iter   912/ 1097] train: loss: 0.0454700
[Epoch 25; Iter   942/ 1097] train: loss: 0.2064774
[Epoch 25; Iter   972/ 1097] train: loss: 0.1091652
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1204955
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0622971
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1881690
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0226392
[Epoch 25] ogbg-molhiv: 0.814940 val loss: 0.075470
[Epoch 25] ogbg-molhiv: 0.774505 test loss: 0.117010
[Epoch 26; Iter    25/ 1097] train: loss: 0.1296652
[Epoch 26; Iter    55/ 1097] train: loss: 0.0549542
[Epoch 26; Iter    85/ 1097] train: loss: 0.4063239
[Epoch 26; Iter   115/ 1097] train: loss: 0.0693663
[Epoch 26; Iter   145/ 1097] train: loss: 0.0341441
[Epoch 26; Iter   175/ 1097] train: loss: 0.0597097
[Epoch 26; Iter   205/ 1097] train: loss: 0.0127971
[Epoch 26; Iter   235/ 1097] train: loss: 0.0219658
[Epoch 26; Iter   265/ 1097] train: loss: 0.0514005
[Epoch 26; Iter   295/ 1097] train: loss: 0.0971666
[Epoch 26; Iter   325/ 1097] train: loss: 0.0397092
[Epoch 26; Iter   355/ 1097] train: loss: 0.1034967
[Epoch 26; Iter   385/ 1097] train: loss: 0.1625956
[Epoch 26; Iter   415/ 1097] train: loss: 0.1376541
[Epoch 26; Iter   445/ 1097] train: loss: 0.0437164
[Epoch 26; Iter   475/ 1097] train: loss: 0.0438534
[Epoch 26; Iter   505/ 1097] train: loss: 0.1548398
[Epoch 26; Iter   535/ 1097] train: loss: 0.0218210
[Epoch 26; Iter   565/ 1097] train: loss: 0.0635517
[Epoch 26; Iter   595/ 1097] train: loss: 0.0225572
[Epoch 26; Iter   625/ 1097] train: loss: 0.1541908
[Epoch 26; Iter   655/ 1097] train: loss: 0.0862313
[Epoch 26; Iter   685/ 1097] train: loss: 0.1273742
[Epoch 26; Iter   715/ 1097] train: loss: 0.0401628
[Epoch 26; Iter   745/ 1097] train: loss: 0.0406721
[Epoch 26; Iter   775/ 1097] train: loss: 0.2667643
[Epoch 26; Iter   805/ 1097] train: loss: 0.0339299
[Epoch 26; Iter   835/ 1097] train: loss: 0.0176188
[Epoch 26; Iter   865/ 1097] train: loss: 0.1265669
[Epoch 26; Iter   895/ 1097] train: loss: 0.0318472
[Epoch 26; Iter   925/ 1097] train: loss: 0.1006361
[Epoch 26; Iter   955/ 1097] train: loss: 0.1191439
[Epoch 26; Iter   985/ 1097] train: loss: 0.0487311
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2589701
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0332589
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2323319
[Epoch 26] ogbg-molhiv: 0.817981 val loss: 0.167591
[Epoch 26] ogbg-molhiv: 0.801010 test loss: 0.215165
[Epoch 27; Iter     8/ 1097] train: loss: 0.0312832
[Epoch 27; Iter    38/ 1097] train: loss: 0.1540904
[Epoch 27; Iter    68/ 1097] train: loss: 0.0609234
[Epoch 27; Iter    98/ 1097] train: loss: 0.1274783
[Epoch 27; Iter   128/ 1097] train: loss: 0.0254350
[Epoch 27; Iter   158/ 1097] train: loss: 0.1843303
[Epoch 27; Iter   188/ 1097] train: loss: 0.0306381
[Epoch 27; Iter   218/ 1097] train: loss: 0.1068703
[Epoch 27; Iter   248/ 1097] train: loss: 0.0589746
[Epoch 27; Iter   278/ 1097] train: loss: 0.0799845
[Epoch 27; Iter   308/ 1097] train: loss: 0.1110671
[Epoch 27; Iter   338/ 1097] train: loss: 0.0255956
[Epoch 27; Iter   368/ 1097] train: loss: 0.0770375
[Epoch 27; Iter   398/ 1097] train: loss: 0.3045099
[Epoch 27; Iter   428/ 1097] train: loss: 0.0233639
[Epoch 27; Iter   458/ 1097] train: loss: 0.0183763
[Epoch 27; Iter   488/ 1097] train: loss: 0.1355204
[Epoch 27; Iter   518/ 1097] train: loss: 0.3784868
[Epoch 27; Iter   548/ 1097] train: loss: 0.0817380
[Epoch 27; Iter   578/ 1097] train: loss: 0.1049444
[Epoch 27; Iter   608/ 1097] train: loss: 0.0189658
[Epoch 27; Iter   638/ 1097] train: loss: 0.0434230
[Epoch 27; Iter   668/ 1097] train: loss: 0.0226421
[Epoch 27; Iter   698/ 1097] train: loss: 0.1485175
[Epoch 27; Iter   728/ 1097] train: loss: 0.1821566
[Epoch 27; Iter   758/ 1097] train: loss: 0.0748267
[Epoch 27; Iter   788/ 1097] train: loss: 0.1783112
[Epoch 27; Iter   818/ 1097] train: loss: 0.0508870
[Epoch 27; Iter   848/ 1097] train: loss: 0.0146431
[Epoch 27; Iter   878/ 1097] train: loss: 0.0268391
[Epoch 27; Iter   908/ 1097] train: loss: 0.2153386
[Epoch 27; Iter   938/ 1097] train: loss: 0.0406140
[Epoch 27; Iter   968/ 1097] train: loss: 0.1096528
[Epoch 27; Iter   998/ 1097] train: loss: 0.1108338
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1490770
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0194406
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0177469
[Epoch 27] ogbg-molhiv: 0.805902 val loss: 0.187571
[Epoch 27] ogbg-molhiv: 0.775189 test loss: 0.190272
[Epoch 28; Iter    21/ 1097] train: loss: 0.2211332
[Epoch 28; Iter    51/ 1097] train: loss: 0.0815263
[Epoch 28; Iter    81/ 1097] train: loss: 0.0553378
[Epoch 28; Iter   111/ 1097] train: loss: 0.0298638
[Epoch 28; Iter   141/ 1097] train: loss: 0.0254731
[Epoch 28; Iter   171/ 1097] train: loss: 0.1564687
[Epoch 28; Iter   201/ 1097] train: loss: 0.0354782
[Epoch 28; Iter   231/ 1097] train: loss: 0.0194049
[Epoch 28; Iter   261/ 1097] train: loss: 0.0448522
[Epoch 28; Iter   291/ 1097] train: loss: 0.1683428
[Epoch 28; Iter   321/ 1097] train: loss: 0.0952644
[Epoch 28; Iter   351/ 1097] train: loss: 0.1362511
[Epoch 28; Iter   381/ 1097] train: loss: 0.0197974
[Epoch 28; Iter   411/ 1097] train: loss: 0.0893121
[Epoch 24; Iter   359/ 1097] train: loss: 0.0770666
[Epoch 24; Iter   389/ 1097] train: loss: 0.0777457
[Epoch 24; Iter   419/ 1097] train: loss: 0.3611322
[Epoch 24; Iter   449/ 1097] train: loss: 0.0797840
[Epoch 24; Iter   479/ 1097] train: loss: 0.1158400
[Epoch 24; Iter   509/ 1097] train: loss: 0.1908422
[Epoch 24; Iter   539/ 1097] train: loss: 0.0363644
[Epoch 24; Iter   569/ 1097] train: loss: 0.1873401
[Epoch 24; Iter   599/ 1097] train: loss: 0.0973071
[Epoch 24; Iter   629/ 1097] train: loss: 0.0359896
[Epoch 24; Iter   659/ 1097] train: loss: 0.0314699
[Epoch 24; Iter   689/ 1097] train: loss: 0.0097749
[Epoch 24; Iter   719/ 1097] train: loss: 0.1229805
[Epoch 24; Iter   749/ 1097] train: loss: 0.0402785
[Epoch 24; Iter   779/ 1097] train: loss: 0.2061888
[Epoch 24; Iter   809/ 1097] train: loss: 0.0961218
[Epoch 24; Iter   839/ 1097] train: loss: 0.0999214
[Epoch 24; Iter   869/ 1097] train: loss: 0.0208650
[Epoch 24; Iter   899/ 1097] train: loss: 0.2253651
[Epoch 24; Iter   929/ 1097] train: loss: 0.1534718
[Epoch 24; Iter   959/ 1097] train: loss: 0.1850304
[Epoch 24; Iter   989/ 1097] train: loss: 0.0231185
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1399087
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0695539
[Epoch 24; Iter  1079/ 1097] train: loss: 0.3055647
[Epoch 24] ogbg-molhiv: 0.808862 val loss: 0.082635
[Epoch 24] ogbg-molhiv: 0.742446 test loss: 0.123021
[Epoch 25; Iter    12/ 1097] train: loss: 0.1865995
[Epoch 25; Iter    42/ 1097] train: loss: 0.0977635
[Epoch 25; Iter    72/ 1097] train: loss: 0.0228890
[Epoch 25; Iter   102/ 1097] train: loss: 0.2362033
[Epoch 25; Iter   132/ 1097] train: loss: 0.2984686
[Epoch 25; Iter   162/ 1097] train: loss: 0.0225747
[Epoch 25; Iter   192/ 1097] train: loss: 0.0335365
[Epoch 25; Iter   222/ 1097] train: loss: 0.1270806
[Epoch 25; Iter   252/ 1097] train: loss: 0.0457801
[Epoch 25; Iter   282/ 1097] train: loss: 0.1175575
[Epoch 25; Iter   312/ 1097] train: loss: 0.0507525
[Epoch 25; Iter   342/ 1097] train: loss: 0.0422905
[Epoch 25; Iter   372/ 1097] train: loss: 0.0304593
[Epoch 25; Iter   402/ 1097] train: loss: 0.0279190
[Epoch 25; Iter   432/ 1097] train: loss: 0.0994407
[Epoch 25; Iter   462/ 1097] train: loss: 0.1260816
[Epoch 25; Iter   492/ 1097] train: loss: 0.1657140
[Epoch 25; Iter   522/ 1097] train: loss: 0.2304270
[Epoch 25; Iter   552/ 1097] train: loss: 0.1268786
[Epoch 25; Iter   582/ 1097] train: loss: 0.1009190
[Epoch 25; Iter   612/ 1097] train: loss: 0.0459953
[Epoch 25; Iter   642/ 1097] train: loss: 0.0333410
[Epoch 25; Iter   672/ 1097] train: loss: 0.0431886
[Epoch 25; Iter   702/ 1097] train: loss: 0.1197746
[Epoch 25; Iter   732/ 1097] train: loss: 0.0730605
[Epoch 25; Iter   762/ 1097] train: loss: 0.0425408
[Epoch 25; Iter   792/ 1097] train: loss: 0.0329087
[Epoch 25; Iter   822/ 1097] train: loss: 0.0218045
[Epoch 25; Iter   852/ 1097] train: loss: 0.0182522
[Epoch 25; Iter   882/ 1097] train: loss: 0.0407320
[Epoch 25; Iter   912/ 1097] train: loss: 0.0157141
[Epoch 25; Iter   942/ 1097] train: loss: 0.1844174
[Epoch 25; Iter   972/ 1097] train: loss: 0.2158473
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0284063
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0543373
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0391512
[Epoch 25; Iter  1092/ 1097] train: loss: 0.3381592
[Epoch 25] ogbg-molhiv: 0.826695 val loss: 0.202892
[Epoch 25] ogbg-molhiv: 0.744929 test loss: 0.119051
[Epoch 26; Iter    25/ 1097] train: loss: 0.0597749
[Epoch 26; Iter    55/ 1097] train: loss: 0.0168842
[Epoch 26; Iter    85/ 1097] train: loss: 0.0316188
[Epoch 26; Iter   115/ 1097] train: loss: 0.0240865
[Epoch 26; Iter   145/ 1097] train: loss: 0.2705442
[Epoch 26; Iter   175/ 1097] train: loss: 0.1358789
[Epoch 26; Iter   205/ 1097] train: loss: 0.2435702
[Epoch 26; Iter   235/ 1097] train: loss: 0.1310011
[Epoch 26; Iter   265/ 1097] train: loss: 0.2086700
[Epoch 26; Iter   295/ 1097] train: loss: 0.0638536
[Epoch 26; Iter   325/ 1097] train: loss: 0.0398455
[Epoch 26; Iter   355/ 1097] train: loss: 0.0198968
[Epoch 26; Iter   385/ 1097] train: loss: 0.0521323
[Epoch 26; Iter   415/ 1097] train: loss: 0.0553511
[Epoch 26; Iter   445/ 1097] train: loss: 0.0303724
[Epoch 26; Iter   475/ 1097] train: loss: 0.0140365
[Epoch 26; Iter   505/ 1097] train: loss: 0.0406689
[Epoch 26; Iter   535/ 1097] train: loss: 0.1113604
[Epoch 26; Iter   565/ 1097] train: loss: 0.2757433
[Epoch 26; Iter   595/ 1097] train: loss: 0.0341061
[Epoch 26; Iter   625/ 1097] train: loss: 0.0617233
[Epoch 26; Iter   655/ 1097] train: loss: 0.0437025
[Epoch 26; Iter   685/ 1097] train: loss: 0.0794413
[Epoch 26; Iter   715/ 1097] train: loss: 0.2077034
[Epoch 26; Iter   745/ 1097] train: loss: 0.0561983
[Epoch 26; Iter   775/ 1097] train: loss: 0.0329564
[Epoch 26; Iter   805/ 1097] train: loss: 0.0685569
[Epoch 26; Iter   835/ 1097] train: loss: 0.1806130
[Epoch 26; Iter   865/ 1097] train: loss: 0.0561728
[Epoch 26; Iter   895/ 1097] train: loss: 0.0230414
[Epoch 26; Iter   925/ 1097] train: loss: 0.3339702
[Epoch 26; Iter   955/ 1097] train: loss: 0.0286491
[Epoch 26; Iter   985/ 1097] train: loss: 0.0398550
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0228659
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0192710
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1659273
[Epoch 26] ogbg-molhiv: 0.818247 val loss: 0.090984
[Epoch 26] ogbg-molhiv: 0.733937 test loss: 0.127691
[Epoch 27; Iter     8/ 1097] train: loss: 0.0207737
[Epoch 27; Iter    38/ 1097] train: loss: 0.1784379
[Epoch 27; Iter    68/ 1097] train: loss: 0.3379745
[Epoch 27; Iter    98/ 1097] train: loss: 0.0280502
[Epoch 27; Iter   128/ 1097] train: loss: 0.0236454
[Epoch 27; Iter   158/ 1097] train: loss: 0.0949530
[Epoch 27; Iter   188/ 1097] train: loss: 0.1093896
[Epoch 27; Iter   218/ 1097] train: loss: 0.0265475
[Epoch 27; Iter   248/ 1097] train: loss: 0.0285176
[Epoch 27; Iter   278/ 1097] train: loss: 0.0202585
[Epoch 27; Iter   308/ 1097] train: loss: 0.0223232
[Epoch 27; Iter   338/ 1097] train: loss: 0.2256529
[Epoch 27; Iter   368/ 1097] train: loss: 0.1783865
[Epoch 27; Iter   398/ 1097] train: loss: 0.0230304
[Epoch 27; Iter   428/ 1097] train: loss: 0.0655306
[Epoch 27; Iter   458/ 1097] train: loss: 0.0149309
[Epoch 27; Iter   488/ 1097] train: loss: 0.0263609
[Epoch 27; Iter   518/ 1097] train: loss: 0.2230462
[Epoch 27; Iter   548/ 1097] train: loss: 0.0471067
[Epoch 27; Iter   578/ 1097] train: loss: 0.1183888
[Epoch 27; Iter   608/ 1097] train: loss: 0.0712832
[Epoch 27; Iter   638/ 1097] train: loss: 0.2469423
[Epoch 27; Iter   668/ 1097] train: loss: 0.1906498
[Epoch 27; Iter   698/ 1097] train: loss: 0.0289676
[Epoch 27; Iter   728/ 1097] train: loss: 0.0534140
[Epoch 27; Iter   758/ 1097] train: loss: 0.0555853
[Epoch 27; Iter   788/ 1097] train: loss: 0.0512551
[Epoch 27; Iter   818/ 1097] train: loss: 0.0191154
[Epoch 27; Iter   848/ 1097] train: loss: 0.0510753
[Epoch 27; Iter   878/ 1097] train: loss: 0.3307345
[Epoch 27; Iter   908/ 1097] train: loss: 0.1399848
[Epoch 27; Iter   938/ 1097] train: loss: 0.0839630
[Epoch 27; Iter   968/ 1097] train: loss: 0.0505264
[Epoch 27; Iter   998/ 1097] train: loss: 0.0343701
[Epoch 27; Iter  1028/ 1097] train: loss: 0.3041393
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0774509
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1674495
[Epoch 27] ogbg-molhiv: 0.827898 val loss: 0.075285
[Epoch 27] ogbg-molhiv: 0.756900 test loss: 0.121141
[Epoch 28; Iter    21/ 1097] train: loss: 0.1330653
[Epoch 28; Iter    51/ 1097] train: loss: 0.0334359
[Epoch 28; Iter    81/ 1097] train: loss: 0.1362779
[Epoch 28; Iter   111/ 1097] train: loss: 0.1021040
[Epoch 28; Iter   141/ 1097] train: loss: 0.0160104
[Epoch 28; Iter   171/ 1097] train: loss: 0.0619591
[Epoch 28; Iter   201/ 1097] train: loss: 0.0257909
[Epoch 28; Iter   231/ 1097] train: loss: 0.0160549
[Epoch 28; Iter   261/ 1097] train: loss: 0.0251201
[Epoch 28; Iter   291/ 1097] train: loss: 0.0272642
[Epoch 28; Iter   321/ 1097] train: loss: 0.0840038
[Epoch 28; Iter   351/ 1097] train: loss: 0.0162040
[Epoch 28; Iter   381/ 1097] train: loss: 0.0235980
[Epoch 28; Iter   411/ 1097] train: loss: 0.1491520
[Epoch 24; Iter   359/ 1097] train: loss: 0.0581494
[Epoch 24; Iter   389/ 1097] train: loss: 0.1239722
[Epoch 24; Iter   419/ 1097] train: loss: 0.3515302
[Epoch 24; Iter   449/ 1097] train: loss: 0.0223075
[Epoch 24; Iter   479/ 1097] train: loss: 0.0602878
[Epoch 24; Iter   509/ 1097] train: loss: 0.0312236
[Epoch 24; Iter   539/ 1097] train: loss: 0.0235666
[Epoch 24; Iter   569/ 1097] train: loss: 0.2028353
[Epoch 24; Iter   599/ 1097] train: loss: 0.1220545
[Epoch 24; Iter   629/ 1097] train: loss: 0.0198667
[Epoch 24; Iter   659/ 1097] train: loss: 0.0204562
[Epoch 24; Iter   689/ 1097] train: loss: 0.0205225
[Epoch 24; Iter   719/ 1097] train: loss: 0.0162578
[Epoch 24; Iter   749/ 1097] train: loss: 0.0374919
[Epoch 24; Iter   779/ 1097] train: loss: 0.1819403
[Epoch 24; Iter   809/ 1097] train: loss: 0.0229866
[Epoch 24; Iter   839/ 1097] train: loss: 0.1833259
[Epoch 24; Iter   869/ 1097] train: loss: 0.1879278
[Epoch 24; Iter   899/ 1097] train: loss: 0.3589522
[Epoch 24; Iter   929/ 1097] train: loss: 0.3055644
[Epoch 24; Iter   959/ 1097] train: loss: 0.0383821
[Epoch 24; Iter   989/ 1097] train: loss: 0.0256065
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1579425
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1039236
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0250033
[Epoch 24] ogbg-molhiv: 0.805357 val loss: 0.374221
[Epoch 24] ogbg-molhiv: 0.760071 test loss: 0.144947
[Epoch 25; Iter    12/ 1097] train: loss: 0.0831089
[Epoch 25; Iter    42/ 1097] train: loss: 0.1977721
[Epoch 25; Iter    72/ 1097] train: loss: 0.0300303
[Epoch 25; Iter   102/ 1097] train: loss: 0.0600938
[Epoch 25; Iter   132/ 1097] train: loss: 0.0256962
[Epoch 25; Iter   162/ 1097] train: loss: 0.0235022
[Epoch 25; Iter   192/ 1097] train: loss: 0.1669326
[Epoch 25; Iter   222/ 1097] train: loss: 0.0346315
[Epoch 25; Iter   252/ 1097] train: loss: 0.0457153
[Epoch 25; Iter   282/ 1097] train: loss: 0.1492302
[Epoch 25; Iter   312/ 1097] train: loss: 0.0404644
[Epoch 25; Iter   342/ 1097] train: loss: 0.0419415
[Epoch 25; Iter   372/ 1097] train: loss: 0.3447842
[Epoch 25; Iter   402/ 1097] train: loss: 0.0192597
[Epoch 25; Iter   432/ 1097] train: loss: 0.2884424
[Epoch 25; Iter   462/ 1097] train: loss: 0.0201372
[Epoch 25; Iter   492/ 1097] train: loss: 0.1704046
[Epoch 25; Iter   522/ 1097] train: loss: 0.0253266
[Epoch 25; Iter   552/ 1097] train: loss: 0.1315582
[Epoch 25; Iter   582/ 1097] train: loss: 0.1404865
[Epoch 25; Iter   612/ 1097] train: loss: 0.1611602
[Epoch 25; Iter   642/ 1097] train: loss: 0.1668374
[Epoch 25; Iter   672/ 1097] train: loss: 0.0251413
[Epoch 25; Iter   702/ 1097] train: loss: 0.1375941
[Epoch 25; Iter   732/ 1097] train: loss: 0.0373215
[Epoch 25; Iter   762/ 1097] train: loss: 0.1007654
[Epoch 25; Iter   792/ 1097] train: loss: 0.0210445
[Epoch 25; Iter   822/ 1097] train: loss: 0.0776025
[Epoch 25; Iter   852/ 1097] train: loss: 0.0350784
[Epoch 25; Iter   882/ 1097] train: loss: 0.0833068
[Epoch 25; Iter   912/ 1097] train: loss: 0.1965789
[Epoch 25; Iter   942/ 1097] train: loss: 0.0283076
[Epoch 25; Iter   972/ 1097] train: loss: 0.0905690
[Epoch 25; Iter  1002/ 1097] train: loss: 0.3203076
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2439954
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0248959
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1735950
[Epoch 25] ogbg-molhiv: 0.811006 val loss: 0.443342
[Epoch 25] ogbg-molhiv: 0.759254 test loss: 0.278474
[Epoch 26; Iter    25/ 1097] train: loss: 0.0437665
[Epoch 26; Iter    55/ 1097] train: loss: 0.0626193
[Epoch 26; Iter    85/ 1097] train: loss: 0.1868846
[Epoch 26; Iter   115/ 1097] train: loss: 0.2744527
[Epoch 26; Iter   145/ 1097] train: loss: 0.1003498
[Epoch 26; Iter   175/ 1097] train: loss: 0.0727499
[Epoch 26; Iter   205/ 1097] train: loss: 0.4582817
[Epoch 26; Iter   235/ 1097] train: loss: 0.0331415
[Epoch 26; Iter   265/ 1097] train: loss: 0.0353161
[Epoch 26; Iter   295/ 1097] train: loss: 0.0763783
[Epoch 26; Iter   325/ 1097] train: loss: 0.0628148
[Epoch 26; Iter   355/ 1097] train: loss: 0.0299932
[Epoch 26; Iter   385/ 1097] train: loss: 0.0509911
[Epoch 26; Iter   415/ 1097] train: loss: 0.0483848
[Epoch 26; Iter   445/ 1097] train: loss: 0.0423750
[Epoch 26; Iter   475/ 1097] train: loss: 0.0937095
[Epoch 26; Iter   505/ 1097] train: loss: 0.1180443
[Epoch 26; Iter   535/ 1097] train: loss: 0.1832215
[Epoch 26; Iter   565/ 1097] train: loss: 0.1603634
[Epoch 26; Iter   595/ 1097] train: loss: 0.0343883
[Epoch 26; Iter   625/ 1097] train: loss: 0.1177136
[Epoch 26; Iter   655/ 1097] train: loss: 0.0329292
[Epoch 26; Iter   685/ 1097] train: loss: 0.2186702
[Epoch 26; Iter   715/ 1097] train: loss: 0.0215751
[Epoch 26; Iter   745/ 1097] train: loss: 0.0174333
[Epoch 26; Iter   775/ 1097] train: loss: 0.0623602
[Epoch 26; Iter   805/ 1097] train: loss: 0.0991147
[Epoch 26; Iter   835/ 1097] train: loss: 0.2192639
[Epoch 26; Iter   865/ 1097] train: loss: 0.2189141
[Epoch 26; Iter   895/ 1097] train: loss: 0.0336753
[Epoch 26; Iter   925/ 1097] train: loss: 0.4101583
[Epoch 26; Iter   955/ 1097] train: loss: 0.0269023
[Epoch 26; Iter   985/ 1097] train: loss: 0.0951865
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0363642
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0658748
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0750848
[Epoch 26] ogbg-molhiv: 0.820562 val loss: 0.110433
[Epoch 26] ogbg-molhiv: 0.787449 test loss: 0.258272
[Epoch 27; Iter     8/ 1097] train: loss: 0.0429685
[Epoch 27; Iter    38/ 1097] train: loss: 0.1174018
[Epoch 27; Iter    68/ 1097] train: loss: 0.0394125
[Epoch 27; Iter    98/ 1097] train: loss: 0.1882034
[Epoch 27; Iter   128/ 1097] train: loss: 0.2002073
[Epoch 27; Iter   158/ 1097] train: loss: 0.0960921
[Epoch 27; Iter   188/ 1097] train: loss: 0.0216701
[Epoch 27; Iter   218/ 1097] train: loss: 0.0862854
[Epoch 27; Iter   248/ 1097] train: loss: 0.0587363
[Epoch 27; Iter   278/ 1097] train: loss: 0.0220785
[Epoch 27; Iter   308/ 1097] train: loss: 0.0267473
[Epoch 27; Iter   338/ 1097] train: loss: 0.0405703
[Epoch 27; Iter   368/ 1097] train: loss: 0.2062221
[Epoch 27; Iter   398/ 1097] train: loss: 0.0166767
[Epoch 27; Iter   428/ 1097] train: loss: 0.1268810
[Epoch 27; Iter   458/ 1097] train: loss: 0.0338967
[Epoch 27; Iter   488/ 1097] train: loss: 0.0861186
[Epoch 27; Iter   518/ 1097] train: loss: 0.1739815
[Epoch 27; Iter   548/ 1097] train: loss: 0.1159967
[Epoch 27; Iter   578/ 1097] train: loss: 0.1371313
[Epoch 27; Iter   608/ 1097] train: loss: 0.1746561
[Epoch 27; Iter   638/ 1097] train: loss: 0.0334454
[Epoch 27; Iter   668/ 1097] train: loss: 0.0755617
[Epoch 27; Iter   698/ 1097] train: loss: 0.0322174
[Epoch 27; Iter   728/ 1097] train: loss: 0.2399371
[Epoch 27; Iter   758/ 1097] train: loss: 0.0210261
[Epoch 27; Iter   788/ 1097] train: loss: 0.0512447
[Epoch 27; Iter   818/ 1097] train: loss: 0.1217193
[Epoch 27; Iter   848/ 1097] train: loss: 0.1351848
[Epoch 27; Iter   878/ 1097] train: loss: 0.0446506
[Epoch 27; Iter   908/ 1097] train: loss: 0.0243005
[Epoch 27; Iter   938/ 1097] train: loss: 0.1894028
[Epoch 27; Iter   968/ 1097] train: loss: 0.0242706
[Epoch 27; Iter   998/ 1097] train: loss: 0.1307086
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0171564
[Epoch 27; Iter  1058/ 1097] train: loss: 0.3598230
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1537343
[Epoch 27] ogbg-molhiv: 0.828486 val loss: 0.161695
[Epoch 27] ogbg-molhiv: 0.753661 test loss: 0.189229
[Epoch 28; Iter    21/ 1097] train: loss: 0.0199056
[Epoch 28; Iter    51/ 1097] train: loss: 0.0409825
[Epoch 28; Iter    81/ 1097] train: loss: 0.0212259
[Epoch 28; Iter   111/ 1097] train: loss: 0.0937548
[Epoch 28; Iter   141/ 1097] train: loss: 0.1887158
[Epoch 28; Iter   171/ 1097] train: loss: 0.1881714
[Epoch 28; Iter   201/ 1097] train: loss: 0.1229717
[Epoch 28; Iter   231/ 1097] train: loss: 0.1017725
[Epoch 28; Iter   261/ 1097] train: loss: 0.1241851
[Epoch 28; Iter   291/ 1097] train: loss: 0.0244948
[Epoch 28; Iter   321/ 1097] train: loss: 0.0280280
[Epoch 28; Iter   351/ 1097] train: loss: 0.0234079
[Epoch 28; Iter   381/ 1097] train: loss: 0.2700150
[Epoch 28; Iter   411/ 1097] train: loss: 0.0172039
[Epoch 28; Iter   441/ 1097] train: loss: 0.0467139
[Epoch 28; Iter   471/ 1097] train: loss: 0.0362464
[Epoch 28; Iter   501/ 1097] train: loss: 0.0429080
[Epoch 28; Iter   531/ 1097] train: loss: 0.0087768
[Epoch 28; Iter   561/ 1097] train: loss: 0.0601319
[Epoch 28; Iter   591/ 1097] train: loss: 0.0373814
[Epoch 28; Iter   621/ 1097] train: loss: 0.0160189
[Epoch 28; Iter   651/ 1097] train: loss: 0.0455727
[Epoch 28; Iter   681/ 1097] train: loss: 0.0469590
[Epoch 28; Iter   711/ 1097] train: loss: 0.0407245
[Epoch 28; Iter   741/ 1097] train: loss: 0.0061179
[Epoch 28; Iter   771/ 1097] train: loss: 0.0505595
[Epoch 28; Iter   801/ 1097] train: loss: 0.0158655
[Epoch 28; Iter   831/ 1097] train: loss: 0.0523718
[Epoch 28; Iter   861/ 1097] train: loss: 0.0247399
[Epoch 28; Iter   891/ 1097] train: loss: 0.0080597
[Epoch 28; Iter   921/ 1097] train: loss: 0.0049321
[Epoch 28; Iter   951/ 1097] train: loss: 0.0084131
[Epoch 28; Iter   981/ 1097] train: loss: 0.0201105
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0858626
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0032336
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0077171
[Epoch 28] ogbg-molhiv: 0.730857 val loss: 0.617987
[Epoch 28] ogbg-molhiv: 0.581330 test loss: 0.675339
[Epoch 29; Iter     4/ 1097] train: loss: 0.0321829
[Epoch 29; Iter    34/ 1097] train: loss: 0.0312311
[Epoch 29; Iter    64/ 1097] train: loss: 0.0132241
[Epoch 29; Iter    94/ 1097] train: loss: 0.0016680
[Epoch 29; Iter   124/ 1097] train: loss: 0.0123077
[Epoch 29; Iter   154/ 1097] train: loss: 0.0077809
[Epoch 29; Iter   184/ 1097] train: loss: 0.0011127
[Epoch 29; Iter   214/ 1097] train: loss: 0.0114346
[Epoch 29; Iter   244/ 1097] train: loss: 0.0532165
[Epoch 29; Iter   274/ 1097] train: loss: 0.0423929
[Epoch 29; Iter   304/ 1097] train: loss: 0.0072545
[Epoch 29; Iter   334/ 1097] train: loss: 0.0381676
[Epoch 29; Iter   364/ 1097] train: loss: 0.0477421
[Epoch 29; Iter   394/ 1097] train: loss: 0.0375604
[Epoch 29; Iter   424/ 1097] train: loss: 0.0019081
[Epoch 29; Iter   454/ 1097] train: loss: 0.0086377
[Epoch 29; Iter   484/ 1097] train: loss: 0.0415934
[Epoch 29; Iter   514/ 1097] train: loss: 0.0127432
[Epoch 29; Iter   544/ 1097] train: loss: 0.0042168
[Epoch 29; Iter   574/ 1097] train: loss: 0.0195899
[Epoch 29; Iter   604/ 1097] train: loss: 0.0050188
[Epoch 29; Iter   634/ 1097] train: loss: 0.0028808
[Epoch 29; Iter   664/ 1097] train: loss: 0.0282952
[Epoch 29; Iter   694/ 1097] train: loss: 0.0269592
[Epoch 29; Iter   724/ 1097] train: loss: 0.0105978
[Epoch 29; Iter   754/ 1097] train: loss: 0.0457212
[Epoch 29; Iter   784/ 1097] train: loss: 0.0032786
[Epoch 29; Iter   814/ 1097] train: loss: 0.0031068
[Epoch 29; Iter   844/ 1097] train: loss: 0.0143764
[Epoch 29; Iter   874/ 1097] train: loss: 0.0080915
[Epoch 29; Iter   904/ 1097] train: loss: 0.2416672
[Epoch 29; Iter   934/ 1097] train: loss: 0.0014945
[Epoch 29; Iter   964/ 1097] train: loss: 0.0422578
[Epoch 29; Iter   994/ 1097] train: loss: 0.0743832
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0102367
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0130600
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0348756
[Epoch 29] ogbg-molhiv: 0.650108 val loss: 59.689615
[Epoch 29] ogbg-molhiv: 0.584078 test loss: 55.640243
[Epoch 30; Iter    17/ 1097] train: loss: 0.0092826
[Epoch 30; Iter    47/ 1097] train: loss: 0.1003981
[Epoch 30; Iter    77/ 1097] train: loss: 0.0130082
[Epoch 30; Iter   107/ 1097] train: loss: 0.0207210
[Epoch 30; Iter   137/ 1097] train: loss: 0.0013060
[Epoch 30; Iter   167/ 1097] train: loss: 0.0141983
[Epoch 30; Iter   197/ 1097] train: loss: 0.0194784
[Epoch 30; Iter   227/ 1097] train: loss: 0.0036400
[Epoch 30; Iter   257/ 1097] train: loss: 0.0023301
[Epoch 30; Iter   287/ 1097] train: loss: 0.0047939
[Epoch 30; Iter   317/ 1097] train: loss: 0.0129452
[Epoch 30; Iter   347/ 1097] train: loss: 0.0076446
[Epoch 30; Iter   377/ 1097] train: loss: 0.0019168
[Epoch 30; Iter   407/ 1097] train: loss: 0.0214940
[Epoch 30; Iter   437/ 1097] train: loss: 0.0637457
[Epoch 30; Iter   467/ 1097] train: loss: 0.0038914
[Epoch 30; Iter   497/ 1097] train: loss: 0.0182628
[Epoch 30; Iter   527/ 1097] train: loss: 0.0116619
[Epoch 30; Iter   557/ 1097] train: loss: 0.0049638
[Epoch 30; Iter   587/ 1097] train: loss: 0.0031505
[Epoch 30; Iter   617/ 1097] train: loss: 0.0125995
[Epoch 30; Iter   647/ 1097] train: loss: 0.0092711
[Epoch 30; Iter   677/ 1097] train: loss: 0.0008184
[Epoch 30; Iter   707/ 1097] train: loss: 0.0401054
[Epoch 30; Iter   737/ 1097] train: loss: 0.0060758
[Epoch 30; Iter   767/ 1097] train: loss: 0.0045671
[Epoch 30; Iter   797/ 1097] train: loss: 0.0034211
[Epoch 30; Iter   827/ 1097] train: loss: 0.0028307
[Epoch 30; Iter   857/ 1097] train: loss: 0.0014314
[Epoch 30; Iter   887/ 1097] train: loss: 0.1088803
[Epoch 30; Iter   917/ 1097] train: loss: 0.0174470
[Epoch 30; Iter   947/ 1097] train: loss: 0.0184508
[Epoch 30; Iter   977/ 1097] train: loss: 0.0235117
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0016413
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0036806
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0194464
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0117996
[Epoch 30] ogbg-molhiv: 0.689848 val loss: 36.917988
[Epoch 30] ogbg-molhiv: 0.558385 test loss: 40.913382
[Epoch 31; Iter    30/ 1097] train: loss: 0.0015855
[Epoch 31; Iter    60/ 1097] train: loss: 0.0007650
[Epoch 31; Iter    90/ 1097] train: loss: 0.0025850
[Epoch 31; Iter   120/ 1097] train: loss: 0.0581182
[Epoch 31; Iter   150/ 1097] train: loss: 0.0057019
[Epoch 31; Iter   180/ 1097] train: loss: 0.0038187
[Epoch 31; Iter   210/ 1097] train: loss: 0.0075616
[Epoch 31; Iter   240/ 1097] train: loss: 0.0231652
[Epoch 31; Iter   270/ 1097] train: loss: 0.0025336
[Epoch 31; Iter   300/ 1097] train: loss: 0.0108026
[Epoch 31; Iter   330/ 1097] train: loss: 0.0044566
[Epoch 31; Iter   360/ 1097] train: loss: 0.0007030
[Epoch 31; Iter   390/ 1097] train: loss: 0.0242880
[Epoch 31; Iter   420/ 1097] train: loss: 0.0030512
[Epoch 31; Iter   450/ 1097] train: loss: 0.0049290
[Epoch 31; Iter   480/ 1097] train: loss: 0.0047472
[Epoch 31; Iter   510/ 1097] train: loss: 0.0025172
[Epoch 31; Iter   540/ 1097] train: loss: 0.0730093
[Epoch 31; Iter   570/ 1097] train: loss: 0.0396592
[Epoch 31; Iter   600/ 1097] train: loss: 0.0080835
[Epoch 31; Iter   630/ 1097] train: loss: 0.0026790
[Epoch 31; Iter   660/ 1097] train: loss: 0.0018511
[Epoch 31; Iter   690/ 1097] train: loss: 0.0072292
[Epoch 31; Iter   720/ 1097] train: loss: 0.0017907
[Epoch 31; Iter   750/ 1097] train: loss: 0.0013716
[Epoch 31; Iter   780/ 1097] train: loss: 0.0499131
[Epoch 31; Iter   810/ 1097] train: loss: 0.0046437
[Epoch 31; Iter   840/ 1097] train: loss: 0.0013953
[Epoch 31; Iter   870/ 1097] train: loss: 0.0067111
[Epoch 31; Iter   900/ 1097] train: loss: 0.0335737
[Epoch 31; Iter   930/ 1097] train: loss: 0.0138374
[Epoch 31; Iter   960/ 1097] train: loss: 0.0003627
[Epoch 31; Iter   990/ 1097] train: loss: 0.0037450
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0311168
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0019445
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0101274
[Epoch 31] ogbg-molhiv: 0.649486 val loss: 0.835474
[Epoch 31] ogbg-molhiv: 0.557237 test loss: 0.990407
[Epoch 32; Iter    13/ 1097] train: loss: 0.0281808
[Epoch 32; Iter    43/ 1097] train: loss: 0.0053349
[Epoch 32; Iter    73/ 1097] train: loss: 0.0025136
[Epoch 32; Iter   103/ 1097] train: loss: 0.0009458
[Epoch 32; Iter   133/ 1097] train: loss: 0.0020783
[Epoch 32; Iter   163/ 1097] train: loss: 0.0049852
[Epoch 32; Iter   193/ 1097] train: loss: 0.0059501
[Epoch 32; Iter   223/ 1097] train: loss: 0.0023099
[Epoch 32; Iter   253/ 1097] train: loss: 0.0025150
[Epoch 32; Iter   283/ 1097] train: loss: 0.0094851
[Epoch 32; Iter   313/ 1097] train: loss: 0.0207793
[Epoch 32; Iter   343/ 1097] train: loss: 0.0073536
[Epoch 32; Iter   373/ 1097] train: loss: 0.0247199
[Epoch 32; Iter   403/ 1097] train: loss: 0.0006918
[Epoch 32; Iter   433/ 1097] train: loss: 0.0043165
[Epoch 32; Iter   463/ 1097] train: loss: 0.0188218
[Epoch 32; Iter   493/ 1097] train: loss: 0.0021828
[Epoch 28; Iter   441/ 1097] train: loss: 0.5143956
[Epoch 28; Iter   471/ 1097] train: loss: 0.0043470
[Epoch 28; Iter   501/ 1097] train: loss: 0.0439511
[Epoch 28; Iter   531/ 1097] train: loss: 0.0461329
[Epoch 28; Iter   561/ 1097] train: loss: 0.1320052
[Epoch 28; Iter   591/ 1097] train: loss: 0.0099621
[Epoch 28; Iter   621/ 1097] train: loss: 0.0423652
[Epoch 28; Iter   651/ 1097] train: loss: 0.0163372
[Epoch 28; Iter   681/ 1097] train: loss: 0.0210426
[Epoch 28; Iter   711/ 1097] train: loss: 0.0107918
[Epoch 28; Iter   741/ 1097] train: loss: 0.0216861
[Epoch 28; Iter   771/ 1097] train: loss: 0.0186969
[Epoch 28; Iter   801/ 1097] train: loss: 0.0219400
[Epoch 28; Iter   831/ 1097] train: loss: 0.0236502
[Epoch 28; Iter   861/ 1097] train: loss: 0.0651047
[Epoch 28; Iter   891/ 1097] train: loss: 0.0381378
[Epoch 28; Iter   921/ 1097] train: loss: 0.0195334
[Epoch 28; Iter   951/ 1097] train: loss: 0.0299117
[Epoch 28; Iter   981/ 1097] train: loss: 0.0131739
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0367180
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0527004
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0035471
[Epoch 28] ogbg-molhiv: 0.767168 val loss: 1.159818
[Epoch 28] ogbg-molhiv: 0.743184 test loss: 1.442300
[Epoch 29; Iter     4/ 1097] train: loss: 0.0314015
[Epoch 29; Iter    34/ 1097] train: loss: 0.0215504
[Epoch 29; Iter    64/ 1097] train: loss: 0.0685659
[Epoch 29; Iter    94/ 1097] train: loss: 0.0046336
[Epoch 29; Iter   124/ 1097] train: loss: 0.1640756
[Epoch 29; Iter   154/ 1097] train: loss: 0.2276980
[Epoch 29; Iter   184/ 1097] train: loss: 0.0081135
[Epoch 29; Iter   214/ 1097] train: loss: 0.0209386
[Epoch 29; Iter   244/ 1097] train: loss: 0.0465754
[Epoch 29; Iter   274/ 1097] train: loss: 0.0091670
[Epoch 29; Iter   304/ 1097] train: loss: 0.0709318
[Epoch 29; Iter   334/ 1097] train: loss: 0.1145207
[Epoch 29; Iter   364/ 1097] train: loss: 0.0094746
[Epoch 29; Iter   394/ 1097] train: loss: 0.0685382
[Epoch 29; Iter   424/ 1097] train: loss: 0.0511813
[Epoch 29; Iter   454/ 1097] train: loss: 0.0199461
[Epoch 29; Iter   484/ 1097] train: loss: 0.1338935
[Epoch 29; Iter   514/ 1097] train: loss: 0.0141603
[Epoch 29; Iter   544/ 1097] train: loss: 0.0328659
[Epoch 29; Iter   574/ 1097] train: loss: 0.0270189
[Epoch 29; Iter   604/ 1097] train: loss: 0.0760007
[Epoch 29; Iter   634/ 1097] train: loss: 0.1286820
[Epoch 29; Iter   664/ 1097] train: loss: 0.0208681
[Epoch 29; Iter   694/ 1097] train: loss: 0.0193626
[Epoch 29; Iter   724/ 1097] train: loss: 0.0618451
[Epoch 29; Iter   754/ 1097] train: loss: 0.0371977
[Epoch 29; Iter   784/ 1097] train: loss: 0.0182237
[Epoch 29; Iter   814/ 1097] train: loss: 0.0656947
[Epoch 29; Iter   844/ 1097] train: loss: 0.0868004
[Epoch 29; Iter   874/ 1097] train: loss: 0.3036495
[Epoch 29; Iter   904/ 1097] train: loss: 0.0344325
[Epoch 29; Iter   934/ 1097] train: loss: 0.1205635
[Epoch 29; Iter   964/ 1097] train: loss: 0.0402417
[Epoch 29; Iter   994/ 1097] train: loss: 0.0239223
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0133124
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0164351
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0066498
[Epoch 29] ogbg-molhiv: 0.696628 val loss: 1.015747
[Epoch 29] ogbg-molhiv: 0.696914 test loss: 0.531318
[Epoch 30; Iter    17/ 1097] train: loss: 0.0216850
[Epoch 30; Iter    47/ 1097] train: loss: 0.0683089
[Epoch 30; Iter    77/ 1097] train: loss: 0.0256609
[Epoch 30; Iter   107/ 1097] train: loss: 0.0494590
[Epoch 30; Iter   137/ 1097] train: loss: 0.0743841
[Epoch 30; Iter   167/ 1097] train: loss: 0.0353800
[Epoch 30; Iter   197/ 1097] train: loss: 0.0110546
[Epoch 30; Iter   227/ 1097] train: loss: 0.0295529
[Epoch 30; Iter   257/ 1097] train: loss: 0.0233643
[Epoch 30; Iter   287/ 1097] train: loss: 0.0068140
[Epoch 30; Iter   317/ 1097] train: loss: 0.1292697
[Epoch 30; Iter   347/ 1097] train: loss: 0.0129824
[Epoch 30; Iter   377/ 1097] train: loss: 0.1675406
[Epoch 30; Iter   407/ 1097] train: loss: 0.0395976
[Epoch 30; Iter   437/ 1097] train: loss: 0.0058860
[Epoch 30; Iter   467/ 1097] train: loss: 0.0193115
[Epoch 30; Iter   497/ 1097] train: loss: 0.0384262
[Epoch 30; Iter   527/ 1097] train: loss: 0.0649894
[Epoch 30; Iter   557/ 1097] train: loss: 0.1534676
[Epoch 30; Iter   587/ 1097] train: loss: 0.1222657
[Epoch 30; Iter   617/ 1097] train: loss: 0.0060803
[Epoch 30; Iter   647/ 1097] train: loss: 0.0057023
[Epoch 30; Iter   677/ 1097] train: loss: 0.1015224
[Epoch 30; Iter   707/ 1097] train: loss: 0.0061271
[Epoch 30; Iter   737/ 1097] train: loss: 0.0048131
[Epoch 30; Iter   767/ 1097] train: loss: 0.1695773
[Epoch 30; Iter   797/ 1097] train: loss: 0.1979513
[Epoch 30; Iter   827/ 1097] train: loss: 0.2320467
[Epoch 30; Iter   857/ 1097] train: loss: 0.1270124
[Epoch 30; Iter   887/ 1097] train: loss: 0.0114559
[Epoch 30; Iter   917/ 1097] train: loss: 0.0937870
[Epoch 30; Iter   947/ 1097] train: loss: 0.0256697
[Epoch 30; Iter   977/ 1097] train: loss: 0.0224580
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0366361
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0701952
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0219104
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0695806
[Epoch 30] ogbg-molhiv: 0.773614 val loss: 6.000497
[Epoch 30] ogbg-molhiv: 0.729908 test loss: 3.253111
[Epoch 31; Iter    30/ 1097] train: loss: 0.0076341
[Epoch 31; Iter    60/ 1097] train: loss: 0.0087240
[Epoch 31; Iter    90/ 1097] train: loss: 0.0021464
[Epoch 31; Iter   120/ 1097] train: loss: 0.0138810
[Epoch 31; Iter   150/ 1097] train: loss: 0.1247526
[Epoch 31; Iter   180/ 1097] train: loss: 0.0120763
[Epoch 31; Iter   210/ 1097] train: loss: 0.0138432
[Epoch 31; Iter   240/ 1097] train: loss: 0.0102548
[Epoch 31; Iter   270/ 1097] train: loss: 0.0038929
[Epoch 31; Iter   300/ 1097] train: loss: 0.1133449
[Epoch 31; Iter   330/ 1097] train: loss: 0.1642344
[Epoch 31; Iter   360/ 1097] train: loss: 0.2260329
[Epoch 31; Iter   390/ 1097] train: loss: 0.0270305
[Epoch 31; Iter   420/ 1097] train: loss: 0.2309914
[Epoch 31; Iter   450/ 1097] train: loss: 0.0132984
[Epoch 31; Iter   480/ 1097] train: loss: 0.2668864
[Epoch 31; Iter   510/ 1097] train: loss: 0.0430567
[Epoch 31; Iter   540/ 1097] train: loss: 0.1466693
[Epoch 31; Iter   570/ 1097] train: loss: 0.1129404
[Epoch 31; Iter   600/ 1097] train: loss: 0.0097794
[Epoch 31; Iter   630/ 1097] train: loss: 0.0189981
[Epoch 31; Iter   660/ 1097] train: loss: 0.0048230
[Epoch 31; Iter   690/ 1097] train: loss: 0.0081857
[Epoch 31; Iter   720/ 1097] train: loss: 0.0203627
[Epoch 31; Iter   750/ 1097] train: loss: 0.0151679
[Epoch 31; Iter   780/ 1097] train: loss: 0.0094029
[Epoch 31; Iter   810/ 1097] train: loss: 0.0420437
[Epoch 31; Iter   840/ 1097] train: loss: 0.1942806
[Epoch 31; Iter   870/ 1097] train: loss: 0.0740661
[Epoch 31; Iter   900/ 1097] train: loss: 0.0053574
[Epoch 31; Iter   930/ 1097] train: loss: 0.0076023
[Epoch 31; Iter   960/ 1097] train: loss: 0.0326044
[Epoch 31; Iter   990/ 1097] train: loss: 0.0317723
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1213836
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0168929
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0205730
[Epoch 31] ogbg-molhiv: 0.755364 val loss: 3.010541
[Epoch 31] ogbg-molhiv: 0.729663 test loss: 2.020354
[Epoch 32; Iter    13/ 1097] train: loss: 0.0263290
[Epoch 32; Iter    43/ 1097] train: loss: 0.1731129
[Epoch 32; Iter    73/ 1097] train: loss: 0.0047192
[Epoch 32; Iter   103/ 1097] train: loss: 0.0264618
[Epoch 32; Iter   133/ 1097] train: loss: 0.0036413
[Epoch 32; Iter   163/ 1097] train: loss: 0.0160140
[Epoch 32; Iter   193/ 1097] train: loss: 0.0537446
[Epoch 32; Iter   223/ 1097] train: loss: 0.0148187
[Epoch 32; Iter   253/ 1097] train: loss: 0.0425354
[Epoch 32; Iter   283/ 1097] train: loss: 0.0425824
[Epoch 32; Iter   313/ 1097] train: loss: 0.0182914
[Epoch 32; Iter   343/ 1097] train: loss: 0.0755306
[Epoch 32; Iter   373/ 1097] train: loss: 0.0495081
[Epoch 32; Iter   403/ 1097] train: loss: 0.0574493
[Epoch 32; Iter   433/ 1097] train: loss: 0.0135443
[Epoch 32; Iter   463/ 1097] train: loss: 0.1327411
[Epoch 32; Iter   493/ 1097] train: loss: 0.0500803
[Epoch 28; Iter   441/ 1097] train: loss: 0.0032701
[Epoch 28; Iter   471/ 1097] train: loss: 0.0860522
[Epoch 28; Iter   501/ 1097] train: loss: 0.0135296
[Epoch 28; Iter   531/ 1097] train: loss: 0.0678299
[Epoch 28; Iter   561/ 1097] train: loss: 0.0635752
[Epoch 28; Iter   591/ 1097] train: loss: 0.0415139
[Epoch 28; Iter   621/ 1097] train: loss: 0.1192782
[Epoch 28; Iter   651/ 1097] train: loss: 0.0061545
[Epoch 28; Iter   681/ 1097] train: loss: 0.0217796
[Epoch 28; Iter   711/ 1097] train: loss: 0.0318664
[Epoch 28; Iter   741/ 1097] train: loss: 0.0514175
[Epoch 28; Iter   771/ 1097] train: loss: 0.0225835
[Epoch 28; Iter   801/ 1097] train: loss: 0.3092381
[Epoch 28; Iter   831/ 1097] train: loss: 0.0065283
[Epoch 28; Iter   861/ 1097] train: loss: 0.0869392
[Epoch 28; Iter   891/ 1097] train: loss: 0.1401718
[Epoch 28; Iter   921/ 1097] train: loss: 0.0410252
[Epoch 28; Iter   951/ 1097] train: loss: 0.0086385
[Epoch 28; Iter   981/ 1097] train: loss: 0.0061067
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0116392
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0456835
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0251624
[Epoch 28] ogbg-molhiv: 0.741163 val loss: 0.146130
[Epoch 28] ogbg-molhiv: 0.672541 test loss: 0.211292
[Epoch 29; Iter     4/ 1097] train: loss: 0.0108999
[Epoch 29; Iter    34/ 1097] train: loss: 0.0287402
[Epoch 29; Iter    64/ 1097] train: loss: 0.2438993
[Epoch 29; Iter    94/ 1097] train: loss: 0.0092565
[Epoch 29; Iter   124/ 1097] train: loss: 0.0040495
[Epoch 29; Iter   154/ 1097] train: loss: 0.0186374
[Epoch 29; Iter   184/ 1097] train: loss: 0.0046808
[Epoch 29; Iter   214/ 1097] train: loss: 0.0179735
[Epoch 29; Iter   244/ 1097] train: loss: 0.0056363
[Epoch 29; Iter   274/ 1097] train: loss: 0.0075549
[Epoch 29; Iter   304/ 1097] train: loss: 0.0218778
[Epoch 29; Iter   334/ 1097] train: loss: 0.0086057
[Epoch 29; Iter   364/ 1097] train: loss: 0.0284783
[Epoch 29; Iter   394/ 1097] train: loss: 0.0294447
[Epoch 29; Iter   424/ 1097] train: loss: 0.0564977
[Epoch 29; Iter   454/ 1097] train: loss: 0.0071138
[Epoch 29; Iter   484/ 1097] train: loss: 0.0023320
[Epoch 29; Iter   514/ 1097] train: loss: 0.0230066
[Epoch 29; Iter   544/ 1097] train: loss: 0.0129875
[Epoch 29; Iter   574/ 1097] train: loss: 0.0278692
[Epoch 29; Iter   604/ 1097] train: loss: 0.0337876
[Epoch 29; Iter   634/ 1097] train: loss: 0.0025797
[Epoch 29; Iter   664/ 1097] train: loss: 0.0280783
[Epoch 29; Iter   694/ 1097] train: loss: 0.0265716
[Epoch 29; Iter   724/ 1097] train: loss: 0.0202056
[Epoch 29; Iter   754/ 1097] train: loss: 0.0114397
[Epoch 29; Iter   784/ 1097] train: loss: 0.0352424
[Epoch 29; Iter   814/ 1097] train: loss: 0.0800153
[Epoch 29; Iter   844/ 1097] train: loss: 0.0052729
[Epoch 29; Iter   874/ 1097] train: loss: 0.0113278
[Epoch 29; Iter   904/ 1097] train: loss: 0.0246034
[Epoch 29; Iter   934/ 1097] train: loss: 0.0581551
[Epoch 29; Iter   964/ 1097] train: loss: 0.0060691
[Epoch 29; Iter   994/ 1097] train: loss: 0.0831419
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0104344
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0044551
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0692808
[Epoch 29] ogbg-molhiv: 0.759994 val loss: 0.178678
[Epoch 29] ogbg-molhiv: 0.690243 test loss: 0.255088
[Epoch 30; Iter    17/ 1097] train: loss: 0.0162925
[Epoch 30; Iter    47/ 1097] train: loss: 0.0072429
[Epoch 30; Iter    77/ 1097] train: loss: 0.0074432
[Epoch 30; Iter   107/ 1097] train: loss: 0.0073436
[Epoch 30; Iter   137/ 1097] train: loss: 0.0085868
[Epoch 30; Iter   167/ 1097] train: loss: 0.0092433
[Epoch 30; Iter   197/ 1097] train: loss: 0.0710589
[Epoch 30; Iter   227/ 1097] train: loss: 0.0145762
[Epoch 30; Iter   257/ 1097] train: loss: 0.0625727
[Epoch 30; Iter   287/ 1097] train: loss: 0.0015590
[Epoch 30; Iter   317/ 1097] train: loss: 0.0340743
[Epoch 30; Iter   347/ 1097] train: loss: 0.0026793
[Epoch 30; Iter   377/ 1097] train: loss: 0.0385995
[Epoch 30; Iter   407/ 1097] train: loss: 0.0169563
[Epoch 30; Iter   437/ 1097] train: loss: 0.0053851
[Epoch 30; Iter   467/ 1097] train: loss: 0.0152670
[Epoch 30; Iter   497/ 1097] train: loss: 0.0068230
[Epoch 30; Iter   527/ 1097] train: loss: 0.1060857
[Epoch 30; Iter   557/ 1097] train: loss: 0.0147146
[Epoch 30; Iter   587/ 1097] train: loss: 0.0355294
[Epoch 30; Iter   617/ 1097] train: loss: 0.0008887
[Epoch 30; Iter   647/ 1097] train: loss: 0.0063745
[Epoch 30; Iter   677/ 1097] train: loss: 0.0085868
[Epoch 30; Iter   707/ 1097] train: loss: 0.0035557
[Epoch 30; Iter   737/ 1097] train: loss: 0.0352907
[Epoch 30; Iter   767/ 1097] train: loss: 0.0028171
[Epoch 30; Iter   797/ 1097] train: loss: 0.0121029
[Epoch 30; Iter   827/ 1097] train: loss: 0.0238360
[Epoch 30; Iter   857/ 1097] train: loss: 0.0032070
[Epoch 30; Iter   887/ 1097] train: loss: 0.0016571
[Epoch 30; Iter   917/ 1097] train: loss: 0.0016400
[Epoch 30; Iter   947/ 1097] train: loss: 0.0142527
[Epoch 30; Iter   977/ 1097] train: loss: 0.0044235
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0020426
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0082794
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0088370
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0014645
[Epoch 30] ogbg-molhiv: 0.780696 val loss: 1.049746
[Epoch 30] ogbg-molhiv: 0.691690 test loss: 0.705538
[Epoch 31; Iter    30/ 1097] train: loss: 0.0097701
[Epoch 31; Iter    60/ 1097] train: loss: 0.0040424
[Epoch 31; Iter    90/ 1097] train: loss: 0.0018870
[Epoch 31; Iter   120/ 1097] train: loss: 0.0058516
[Epoch 31; Iter   150/ 1097] train: loss: 0.0019274
[Epoch 31; Iter   180/ 1097] train: loss: 0.0100670
[Epoch 31; Iter   210/ 1097] train: loss: 0.0062776
[Epoch 31; Iter   240/ 1097] train: loss: 0.0004732
[Epoch 31; Iter   270/ 1097] train: loss: 0.0386603
[Epoch 31; Iter   300/ 1097] train: loss: 0.0353656
[Epoch 31; Iter   330/ 1097] train: loss: 0.0023234
[Epoch 31; Iter   360/ 1097] train: loss: 0.0027577
[Epoch 31; Iter   390/ 1097] train: loss: 0.0027223
[Epoch 31; Iter   420/ 1097] train: loss: 0.0268934
[Epoch 31; Iter   450/ 1097] train: loss: 0.0368288
[Epoch 31; Iter   480/ 1097] train: loss: 0.0007676
[Epoch 31; Iter   510/ 1097] train: loss: 0.0012467
[Epoch 31; Iter   540/ 1097] train: loss: 0.0020511
[Epoch 31; Iter   570/ 1097] train: loss: 0.0104072
[Epoch 31; Iter   600/ 1097] train: loss: 0.0269631
[Epoch 31; Iter   630/ 1097] train: loss: 0.0276243
[Epoch 31; Iter   660/ 1097] train: loss: 0.0201106
[Epoch 31; Iter   690/ 1097] train: loss: 0.0016372
[Epoch 31; Iter   720/ 1097] train: loss: 0.0007441
[Epoch 31; Iter   750/ 1097] train: loss: 0.0312488
[Epoch 31; Iter   780/ 1097] train: loss: 0.0818811
[Epoch 31; Iter   810/ 1097] train: loss: 0.0428571
[Epoch 31; Iter   840/ 1097] train: loss: 0.0021474
[Epoch 31; Iter   870/ 1097] train: loss: 0.0064766
[Epoch 31; Iter   900/ 1097] train: loss: 0.0073256
[Epoch 31; Iter   930/ 1097] train: loss: 0.0025049
[Epoch 31; Iter   960/ 1097] train: loss: 0.0036067
[Epoch 31; Iter   990/ 1097] train: loss: 0.0081166
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0402768
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0147785
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0183259
[Epoch 31] ogbg-molhiv: 0.748365 val loss: 1.395244
[Epoch 31] ogbg-molhiv: 0.640005 test loss: 1.491079
[Epoch 32; Iter    13/ 1097] train: loss: 0.0552676
[Epoch 32; Iter    43/ 1097] train: loss: 0.0138343
[Epoch 32; Iter    73/ 1097] train: loss: 0.0071487
[Epoch 32; Iter   103/ 1097] train: loss: 0.0032269
[Epoch 32; Iter   133/ 1097] train: loss: 0.0101974
[Epoch 32; Iter   163/ 1097] train: loss: 0.0008850
[Epoch 32; Iter   193/ 1097] train: loss: 0.0091108
[Epoch 32; Iter   223/ 1097] train: loss: 0.0144167
[Epoch 32; Iter   253/ 1097] train: loss: 0.0026123
[Epoch 32; Iter   283/ 1097] train: loss: 0.0179498
[Epoch 32; Iter   313/ 1097] train: loss: 0.0089468
[Epoch 32; Iter   343/ 1097] train: loss: 0.0247815
[Epoch 32; Iter   373/ 1097] train: loss: 0.0009044
[Epoch 32; Iter   403/ 1097] train: loss: 0.0212661
[Epoch 32; Iter   433/ 1097] train: loss: 0.0071028
[Epoch 32; Iter   463/ 1097] train: loss: 0.0047713
[Epoch 32; Iter   493/ 1097] train: loss: 0.0031685
[Epoch 32; Iter   523/ 1097] train: loss: 0.0293281
[Epoch 32; Iter   553/ 1097] train: loss: 0.0242742
[Epoch 32; Iter   583/ 1097] train: loss: 0.0130909
[Epoch 32; Iter   613/ 1097] train: loss: 0.1629031
[Epoch 32; Iter   643/ 1097] train: loss: 0.0048134
[Epoch 32; Iter   673/ 1097] train: loss: 0.0077155
[Epoch 32; Iter   703/ 1097] train: loss: 0.0464134
[Epoch 32; Iter   733/ 1097] train: loss: 0.0091978
[Epoch 32; Iter   763/ 1097] train: loss: 0.0040308
[Epoch 32; Iter   793/ 1097] train: loss: 0.0199731
[Epoch 32; Iter   823/ 1097] train: loss: 0.0315690
[Epoch 32; Iter   853/ 1097] train: loss: 0.0099981
[Epoch 32; Iter   883/ 1097] train: loss: 0.0111166
[Epoch 32; Iter   913/ 1097] train: loss: 0.0099883
[Epoch 32; Iter   943/ 1097] train: loss: 0.0153149
[Epoch 32; Iter   973/ 1097] train: loss: 0.0324042
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0090328
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0334026
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0354806
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0039311
[Epoch 32] ogbg-molhiv: 0.779422 val loss: 0.640631
[Epoch 32] ogbg-molhiv: 0.750877 test loss: 0.639072
[Epoch 33; Iter    26/ 1097] train: loss: 0.1205279
[Epoch 33; Iter    56/ 1097] train: loss: 0.0917836
[Epoch 33; Iter    86/ 1097] train: loss: 0.0027122
[Epoch 33; Iter   116/ 1097] train: loss: 0.0097560
[Epoch 33; Iter   146/ 1097] train: loss: 0.0167691
[Epoch 33; Iter   176/ 1097] train: loss: 0.0131257
[Epoch 33; Iter   206/ 1097] train: loss: 0.0053482
[Epoch 33; Iter   236/ 1097] train: loss: 0.0088318
[Epoch 33; Iter   266/ 1097] train: loss: 0.1438965
[Epoch 33; Iter   296/ 1097] train: loss: 0.0029508
[Epoch 33; Iter   326/ 1097] train: loss: 0.0454999
[Epoch 33; Iter   356/ 1097] train: loss: 0.0184154
[Epoch 33; Iter   386/ 1097] train: loss: 0.1208951
[Epoch 33; Iter   416/ 1097] train: loss: 0.0243586
[Epoch 33; Iter   446/ 1097] train: loss: 0.0553101
[Epoch 33; Iter   476/ 1097] train: loss: 0.0149562
[Epoch 33; Iter   506/ 1097] train: loss: 0.0158378
[Epoch 33; Iter   536/ 1097] train: loss: 0.0177552
[Epoch 33; Iter   566/ 1097] train: loss: 0.0038730
[Epoch 33; Iter   596/ 1097] train: loss: 0.0048659
[Epoch 33; Iter   626/ 1097] train: loss: 0.0017842
[Epoch 33; Iter   656/ 1097] train: loss: 0.1409539
[Epoch 33; Iter   686/ 1097] train: loss: 0.0170320
[Epoch 33; Iter   716/ 1097] train: loss: 0.0571869
[Epoch 33; Iter   746/ 1097] train: loss: 0.1637428
[Epoch 33; Iter   776/ 1097] train: loss: 0.0041710
[Epoch 33; Iter   806/ 1097] train: loss: 0.0127171
[Epoch 33; Iter   836/ 1097] train: loss: 0.0215851
[Epoch 33; Iter   866/ 1097] train: loss: 0.0065036
[Epoch 33; Iter   896/ 1097] train: loss: 0.0821096
[Epoch 33; Iter   926/ 1097] train: loss: 0.0026865
[Epoch 33; Iter   956/ 1097] train: loss: 0.0026706
[Epoch 33; Iter   986/ 1097] train: loss: 0.0876184
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0076683
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0186145
[Epoch 33; Iter  1076/ 1097] train: loss: 0.1211834
[Epoch 33] ogbg-molhiv: 0.783969 val loss: 0.523193
[Epoch 33] ogbg-molhiv: 0.747948 test loss: 0.657973
[Epoch 34; Iter     9/ 1097] train: loss: 0.0302768
[Epoch 34; Iter    39/ 1097] train: loss: 0.0112362
[Epoch 34; Iter    69/ 1097] train: loss: 0.0059122
[Epoch 34; Iter    99/ 1097] train: loss: 0.0198170
[Epoch 34; Iter   129/ 1097] train: loss: 0.0029271
[Epoch 34; Iter   159/ 1097] train: loss: 0.0084938
[Epoch 34; Iter   189/ 1097] train: loss: 0.1529577
[Epoch 34; Iter   219/ 1097] train: loss: 0.0592120
[Epoch 34; Iter   249/ 1097] train: loss: 0.0168591
[Epoch 34; Iter   279/ 1097] train: loss: 0.1388815
[Epoch 34; Iter   309/ 1097] train: loss: 0.0305147
[Epoch 34; Iter   339/ 1097] train: loss: 0.0046883
[Epoch 34; Iter   369/ 1097] train: loss: 0.0122647
[Epoch 34; Iter   399/ 1097] train: loss: 0.0024431
[Epoch 34; Iter   429/ 1097] train: loss: 0.0148994
[Epoch 34; Iter   459/ 1097] train: loss: 0.0249129
[Epoch 34; Iter   489/ 1097] train: loss: 0.0196390
[Epoch 34; Iter   519/ 1097] train: loss: 0.0289942
[Epoch 34; Iter   549/ 1097] train: loss: 0.0646959
[Epoch 34; Iter   579/ 1097] train: loss: 0.0061262
[Epoch 34; Iter   609/ 1097] train: loss: 0.0449249
[Epoch 34; Iter   639/ 1097] train: loss: 0.0144858
[Epoch 34; Iter   669/ 1097] train: loss: 0.0131038
[Epoch 34; Iter   699/ 1097] train: loss: 0.2070681
[Epoch 34; Iter   729/ 1097] train: loss: 0.1040784
[Epoch 34; Iter   759/ 1097] train: loss: 0.0294905
[Epoch 34; Iter   789/ 1097] train: loss: 0.0059791
[Epoch 34; Iter   819/ 1097] train: loss: 0.0890095
[Epoch 34; Iter   849/ 1097] train: loss: 0.0238316
[Epoch 34; Iter   879/ 1097] train: loss: 0.0036424
[Epoch 34; Iter   909/ 1097] train: loss: 0.0374294
[Epoch 34; Iter   939/ 1097] train: loss: 0.0905857
[Epoch 34; Iter   969/ 1097] train: loss: 0.0255753
[Epoch 34; Iter   999/ 1097] train: loss: 0.0063533
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0854253
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0072588
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0244053
[Epoch 34] ogbg-molhiv: 0.779205 val loss: 0.376647
[Epoch 34] ogbg-molhiv: 0.753263 test loss: 0.428399
[Epoch 35; Iter    22/ 1097] train: loss: 0.0534924
[Epoch 35; Iter    52/ 1097] train: loss: 0.0039992
[Epoch 35; Iter    82/ 1097] train: loss: 0.0127607
[Epoch 35; Iter   112/ 1097] train: loss: 0.0024695
[Epoch 35; Iter   142/ 1097] train: loss: 0.0084345
[Epoch 35; Iter   172/ 1097] train: loss: 0.0100839
[Epoch 35; Iter   202/ 1097] train: loss: 0.0722350
[Epoch 35; Iter   232/ 1097] train: loss: 0.3463408
[Epoch 35; Iter   262/ 1097] train: loss: 0.1982710
[Epoch 35; Iter   292/ 1097] train: loss: 0.0477402
[Epoch 35; Iter   322/ 1097] train: loss: 0.0481389
[Epoch 35; Iter   352/ 1097] train: loss: 0.0278801
[Epoch 35; Iter   382/ 1097] train: loss: 0.0015621
[Epoch 35; Iter   412/ 1097] train: loss: 0.0123675
[Epoch 35; Iter   442/ 1097] train: loss: 0.0197988
[Epoch 35; Iter   472/ 1097] train: loss: 0.1217092
[Epoch 35; Iter   502/ 1097] train: loss: 0.1063556
[Epoch 35; Iter   532/ 1097] train: loss: 0.0315433
[Epoch 35; Iter   562/ 1097] train: loss: 0.0152777
[Epoch 35; Iter   592/ 1097] train: loss: 0.0031960
[Epoch 35; Iter   622/ 1097] train: loss: 0.0037323
[Epoch 35; Iter   652/ 1097] train: loss: 0.0505030
[Epoch 35; Iter   682/ 1097] train: loss: 0.0064934
[Epoch 35; Iter   712/ 1097] train: loss: 0.0285603
[Epoch 35; Iter   742/ 1097] train: loss: 0.0523867
[Epoch 35; Iter   772/ 1097] train: loss: 0.0034812
[Epoch 35; Iter   802/ 1097] train: loss: 0.0027216
[Epoch 35; Iter   832/ 1097] train: loss: 0.0049182
[Epoch 35; Iter   862/ 1097] train: loss: 0.0408276
[Epoch 35; Iter   892/ 1097] train: loss: 0.0037712
[Epoch 35; Iter   922/ 1097] train: loss: 0.1328616
[Epoch 35; Iter   952/ 1097] train: loss: 0.1235756
[Epoch 35; Iter   982/ 1097] train: loss: 0.0041962
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0111373
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0039453
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0062505
[Epoch 35] ogbg-molhiv: 0.772946 val loss: 0.253470
[Epoch 35] ogbg-molhiv: 0.758389 test loss: 0.171848
[Epoch 36; Iter     5/ 1097] train: loss: 0.0096508
[Epoch 36; Iter    35/ 1097] train: loss: 0.0471878
[Epoch 36; Iter    65/ 1097] train: loss: 0.0079296
[Epoch 36; Iter    95/ 1097] train: loss: 0.0123633
[Epoch 36; Iter   125/ 1097] train: loss: 0.0043668
[Epoch 36; Iter   155/ 1097] train: loss: 0.0033993
[Epoch 36; Iter   185/ 1097] train: loss: 0.0034642
[Epoch 36; Iter   215/ 1097] train: loss: 0.0204779
[Epoch 36; Iter   245/ 1097] train: loss: 0.0113936
[Epoch 36; Iter   275/ 1097] train: loss: 0.0148975
[Epoch 36; Iter   305/ 1097] train: loss: 0.0653320
[Epoch 36; Iter   335/ 1097] train: loss: 0.0146838
[Epoch 36; Iter   365/ 1097] train: loss: 0.0047514
[Epoch 36; Iter   395/ 1097] train: loss: 0.0336500
[Epoch 36; Iter   425/ 1097] train: loss: 0.0301770
[Epoch 36; Iter   455/ 1097] train: loss: 0.0302557
[Epoch 36; Iter   485/ 1097] train: loss: 0.0052319
[Epoch 36; Iter   515/ 1097] train: loss: 0.0053840
[Epoch 36; Iter   545/ 1097] train: loss: 0.0340874
[Epoch 36; Iter   575/ 1097] train: loss: 0.0030788
[Epoch 32; Iter   523/ 1097] train: loss: 0.1335551
[Epoch 32; Iter   553/ 1097] train: loss: 0.0143752
[Epoch 32; Iter   583/ 1097] train: loss: 0.0741955
[Epoch 32; Iter   613/ 1097] train: loss: 0.0275132
[Epoch 32; Iter   643/ 1097] train: loss: 0.1656974
[Epoch 32; Iter   673/ 1097] train: loss: 0.0475335
[Epoch 32; Iter   703/ 1097] train: loss: 0.0105765
[Epoch 32; Iter   733/ 1097] train: loss: 0.0213257
[Epoch 32; Iter   763/ 1097] train: loss: 0.0114563
[Epoch 32; Iter   793/ 1097] train: loss: 0.0437391
[Epoch 32; Iter   823/ 1097] train: loss: 0.0232750
[Epoch 32; Iter   853/ 1097] train: loss: 0.0141106
[Epoch 32; Iter   883/ 1097] train: loss: 0.0144443
[Epoch 32; Iter   913/ 1097] train: loss: 0.0594942
[Epoch 32; Iter   943/ 1097] train: loss: 0.0063786
[Epoch 32; Iter   973/ 1097] train: loss: 0.0072214
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0521447
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0173611
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0279279
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0107193
[Epoch 32] ogbg-molhiv: 0.727835 val loss: 0.140642
[Epoch 32] ogbg-molhiv: 0.723859 test loss: 0.184605
[Epoch 33; Iter    26/ 1097] train: loss: 0.2313805
[Epoch 33; Iter    56/ 1097] train: loss: 0.0269255
[Epoch 33; Iter    86/ 1097] train: loss: 0.0085947
[Epoch 33; Iter   116/ 1097] train: loss: 0.0702062
[Epoch 33; Iter   146/ 1097] train: loss: 0.0236921
[Epoch 33; Iter   176/ 1097] train: loss: 0.0052031
[Epoch 33; Iter   206/ 1097] train: loss: 0.0677478
[Epoch 33; Iter   236/ 1097] train: loss: 0.0085540
[Epoch 33; Iter   266/ 1097] train: loss: 0.0180598
[Epoch 33; Iter   296/ 1097] train: loss: 0.2112289
[Epoch 33; Iter   326/ 1097] train: loss: 0.0644550
[Epoch 33; Iter   356/ 1097] train: loss: 0.1667673
[Epoch 33; Iter   386/ 1097] train: loss: 0.0093643
[Epoch 33; Iter   416/ 1097] train: loss: 0.0118874
[Epoch 33; Iter   446/ 1097] train: loss: 0.0160382
[Epoch 33; Iter   476/ 1097] train: loss: 0.0047684
[Epoch 33; Iter   506/ 1097] train: loss: 0.1212836
[Epoch 33; Iter   536/ 1097] train: loss: 0.0044915
[Epoch 33; Iter   566/ 1097] train: loss: 0.0339076
[Epoch 33; Iter   596/ 1097] train: loss: 0.0129503
[Epoch 33; Iter   626/ 1097] train: loss: 0.0210203
[Epoch 33; Iter   656/ 1097] train: loss: 0.0027049
[Epoch 33; Iter   686/ 1097] train: loss: 0.0053382
[Epoch 33; Iter   716/ 1097] train: loss: 0.2703594
[Epoch 33; Iter   746/ 1097] train: loss: 0.0117349
[Epoch 33; Iter   776/ 1097] train: loss: 0.2226006
[Epoch 33; Iter   806/ 1097] train: loss: 0.0082488
[Epoch 33; Iter   836/ 1097] train: loss: 0.1438441
[Epoch 33; Iter   866/ 1097] train: loss: 0.0507956
[Epoch 33; Iter   896/ 1097] train: loss: 0.0109317
[Epoch 33; Iter   926/ 1097] train: loss: 0.0058125
[Epoch 33; Iter   956/ 1097] train: loss: 0.0083517
[Epoch 33; Iter   986/ 1097] train: loss: 0.0299035
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0596669
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0088125
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0298771
[Epoch 33] ogbg-molhiv: 0.743466 val loss: 0.180732
[Epoch 33] ogbg-molhiv: 0.689121 test loss: 0.188833
[Epoch 34; Iter     9/ 1097] train: loss: 0.0830661
[Epoch 34; Iter    39/ 1097] train: loss: 0.1051059
[Epoch 34; Iter    69/ 1097] train: loss: 0.0069369
[Epoch 34; Iter    99/ 1097] train: loss: 0.0425076
[Epoch 34; Iter   129/ 1097] train: loss: 0.0219847
[Epoch 34; Iter   159/ 1097] train: loss: 0.0049517
[Epoch 34; Iter   189/ 1097] train: loss: 0.0097017
[Epoch 34; Iter   219/ 1097] train: loss: 0.0059825
[Epoch 34; Iter   249/ 1097] train: loss: 0.0075070
[Epoch 34; Iter   279/ 1097] train: loss: 0.0087471
[Epoch 34; Iter   309/ 1097] train: loss: 0.0075042
[Epoch 34; Iter   339/ 1097] train: loss: 0.0068801
[Epoch 34; Iter   369/ 1097] train: loss: 0.0125275
[Epoch 34; Iter   399/ 1097] train: loss: 0.0277502
[Epoch 34; Iter   429/ 1097] train: loss: 0.0097490
[Epoch 34; Iter   459/ 1097] train: loss: 0.0259015
[Epoch 34; Iter   489/ 1097] train: loss: 0.0025933
[Epoch 34; Iter   519/ 1097] train: loss: 0.0061863
[Epoch 34; Iter   549/ 1097] train: loss: 0.0034372
[Epoch 34; Iter   579/ 1097] train: loss: 0.1319745
[Epoch 34; Iter   609/ 1097] train: loss: 0.0072470
[Epoch 34; Iter   639/ 1097] train: loss: 0.0307173
[Epoch 34; Iter   669/ 1097] train: loss: 0.0336477
[Epoch 34; Iter   699/ 1097] train: loss: 0.0345469
[Epoch 34; Iter   729/ 1097] train: loss: 0.0011941
[Epoch 34; Iter   759/ 1097] train: loss: 0.2198756
[Epoch 34; Iter   789/ 1097] train: loss: 0.0305937
[Epoch 34; Iter   819/ 1097] train: loss: 0.0057951
[Epoch 34; Iter   849/ 1097] train: loss: 0.0946582
[Epoch 34; Iter   879/ 1097] train: loss: 0.0033781
[Epoch 34; Iter   909/ 1097] train: loss: 0.0594029
[Epoch 34; Iter   939/ 1097] train: loss: 0.0057775
[Epoch 34; Iter   969/ 1097] train: loss: 0.0131313
[Epoch 34; Iter   999/ 1097] train: loss: 0.0106972
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0421308
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0034361
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0430567
[Epoch 34] ogbg-molhiv: 0.725082 val loss: 0.215612
[Epoch 34] ogbg-molhiv: 0.712092 test loss: 0.203733
[Epoch 35; Iter    22/ 1097] train: loss: 0.0058683
[Epoch 35; Iter    52/ 1097] train: loss: 0.0104216
[Epoch 35; Iter    82/ 1097] train: loss: 0.0621453
[Epoch 35; Iter   112/ 1097] train: loss: 0.0010238
[Epoch 35; Iter   142/ 1097] train: loss: 0.0044518
[Epoch 35; Iter   172/ 1097] train: loss: 0.0009328
[Epoch 35; Iter   202/ 1097] train: loss: 0.0452599
[Epoch 35; Iter   232/ 1097] train: loss: 0.0035190
[Epoch 35; Iter   262/ 1097] train: loss: 0.0113526
[Epoch 35; Iter   292/ 1097] train: loss: 0.0413877
[Epoch 35; Iter   322/ 1097] train: loss: 0.0034819
[Epoch 35; Iter   352/ 1097] train: loss: 0.0123545
[Epoch 35; Iter   382/ 1097] train: loss: 0.0029208
[Epoch 35; Iter   412/ 1097] train: loss: 0.0033003
[Epoch 35; Iter   442/ 1097] train: loss: 0.0138509
[Epoch 35; Iter   472/ 1097] train: loss: 0.0013341
[Epoch 35; Iter   502/ 1097] train: loss: 0.0046096
[Epoch 35; Iter   532/ 1097] train: loss: 0.0303916
[Epoch 35; Iter   562/ 1097] train: loss: 0.0199623
[Epoch 35; Iter   592/ 1097] train: loss: 0.0032284
[Epoch 35; Iter   622/ 1097] train: loss: 0.0126877
[Epoch 35; Iter   652/ 1097] train: loss: 0.0186333
[Epoch 35; Iter   682/ 1097] train: loss: 0.0307861
[Epoch 35; Iter   712/ 1097] train: loss: 0.0553475
[Epoch 35; Iter   742/ 1097] train: loss: 0.0036928
[Epoch 35; Iter   772/ 1097] train: loss: 0.0063161
[Epoch 35; Iter   802/ 1097] train: loss: 0.0160375
[Epoch 35; Iter   832/ 1097] train: loss: 0.0146326
[Epoch 35; Iter   862/ 1097] train: loss: 0.0030631
[Epoch 35; Iter   892/ 1097] train: loss: 0.2076173
[Epoch 35; Iter   922/ 1097] train: loss: 0.0103737
[Epoch 35; Iter   952/ 1097] train: loss: 0.1087248
[Epoch 35; Iter   982/ 1097] train: loss: 0.0021510
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0384774
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0025831
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0352126
[Epoch 35] ogbg-molhiv: 0.759394 val loss: 0.529586
[Epoch 35] ogbg-molhiv: 0.721675 test loss: 0.209896
[Epoch 36; Iter     5/ 1097] train: loss: 0.0393946
[Epoch 36; Iter    35/ 1097] train: loss: 0.0071792
[Epoch 36; Iter    65/ 1097] train: loss: 0.0024407
[Epoch 36; Iter    95/ 1097] train: loss: 0.0305959
[Epoch 36; Iter   125/ 1097] train: loss: 0.0009597
[Epoch 36; Iter   155/ 1097] train: loss: 0.0386532
[Epoch 36; Iter   185/ 1097] train: loss: 0.0037680
[Epoch 36; Iter   215/ 1097] train: loss: 0.0194916
[Epoch 36; Iter   245/ 1097] train: loss: 0.2077297
[Epoch 36; Iter   275/ 1097] train: loss: 0.0022370
[Epoch 36; Iter   305/ 1097] train: loss: 0.0090714
[Epoch 36; Iter   335/ 1097] train: loss: 0.0044203
[Epoch 36; Iter   365/ 1097] train: loss: 0.0349838
[Epoch 36; Iter   395/ 1097] train: loss: 0.0087589
[Epoch 36; Iter   425/ 1097] train: loss: 0.0463720
[Epoch 36; Iter   455/ 1097] train: loss: 0.0076445
[Epoch 36; Iter   485/ 1097] train: loss: 0.0079082
[Epoch 36; Iter   515/ 1097] train: loss: 0.2186373
[Epoch 36; Iter   545/ 1097] train: loss: 0.1499759
[Epoch 36; Iter   575/ 1097] train: loss: 0.0751810
[Epoch 32; Iter   523/ 1097] train: loss: 0.0916428
[Epoch 32; Iter   553/ 1097] train: loss: 0.0382474
[Epoch 32; Iter   583/ 1097] train: loss: 0.0207296
[Epoch 32; Iter   613/ 1097] train: loss: 0.0175921
[Epoch 32; Iter   643/ 1097] train: loss: 0.0118028
[Epoch 32; Iter   673/ 1097] train: loss: 0.0985507
[Epoch 32; Iter   703/ 1097] train: loss: 0.0313652
[Epoch 32; Iter   733/ 1097] train: loss: 0.0922131
[Epoch 32; Iter   763/ 1097] train: loss: 0.0981075
[Epoch 32; Iter   793/ 1097] train: loss: 0.0221275
[Epoch 32; Iter   823/ 1097] train: loss: 0.0146649
[Epoch 32; Iter   853/ 1097] train: loss: 0.0065387
[Epoch 32; Iter   883/ 1097] train: loss: 0.0150791
[Epoch 32; Iter   913/ 1097] train: loss: 0.0651819
[Epoch 32; Iter   943/ 1097] train: loss: 0.0200099
[Epoch 32; Iter   973/ 1097] train: loss: 0.0185625
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0185357
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0315626
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0495068
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0941555
[Epoch 32] ogbg-molhiv: 0.686857 val loss: 0.564156
[Epoch 32] ogbg-molhiv: 0.717355 test loss: 0.653073
[Epoch 33; Iter    26/ 1097] train: loss: 0.0170475
[Epoch 33; Iter    56/ 1097] train: loss: 0.1323445
[Epoch 33; Iter    86/ 1097] train: loss: 0.0445849
[Epoch 33; Iter   116/ 1097] train: loss: 0.1581672
[Epoch 33; Iter   146/ 1097] train: loss: 0.0231481
[Epoch 33; Iter   176/ 1097] train: loss: 0.0126227
[Epoch 33; Iter   206/ 1097] train: loss: 0.0161841
[Epoch 33; Iter   236/ 1097] train: loss: 0.0118947
[Epoch 33; Iter   266/ 1097] train: loss: 0.0152773
[Epoch 33; Iter   296/ 1097] train: loss: 0.0532023
[Epoch 33; Iter   326/ 1097] train: loss: 0.1001768
[Epoch 33; Iter   356/ 1097] train: loss: 0.2639614
[Epoch 33; Iter   386/ 1097] train: loss: 0.0110150
[Epoch 33; Iter   416/ 1097] train: loss: 0.0191268
[Epoch 33; Iter   446/ 1097] train: loss: 0.0102271
[Epoch 33; Iter   476/ 1097] train: loss: 0.0157803
[Epoch 33; Iter   506/ 1097] train: loss: 0.1246751
[Epoch 33; Iter   536/ 1097] train: loss: 0.0327613
[Epoch 33; Iter   566/ 1097] train: loss: 0.1250719
[Epoch 33; Iter   596/ 1097] train: loss: 0.0040432
[Epoch 33; Iter   626/ 1097] train: loss: 0.0304937
[Epoch 33; Iter   656/ 1097] train: loss: 0.0174739
[Epoch 33; Iter   686/ 1097] train: loss: 0.0136704
[Epoch 33; Iter   716/ 1097] train: loss: 0.0117779
[Epoch 33; Iter   746/ 1097] train: loss: 0.0105905
[Epoch 33; Iter   776/ 1097] train: loss: 0.0801707
[Epoch 33; Iter   806/ 1097] train: loss: 0.2267605
[Epoch 33; Iter   836/ 1097] train: loss: 0.0311187
[Epoch 33; Iter   866/ 1097] train: loss: 0.0372032
[Epoch 33; Iter   896/ 1097] train: loss: 0.1954286
[Epoch 33; Iter   926/ 1097] train: loss: 0.0301587
[Epoch 33; Iter   956/ 1097] train: loss: 0.0206590
[Epoch 33; Iter   986/ 1097] train: loss: 0.0928432
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0198245
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0519944
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2259208
[Epoch 33] ogbg-molhiv: 0.741935 val loss: 0.645707
[Epoch 33] ogbg-molhiv: 0.742511 test loss: 0.264147
[Epoch 34; Iter     9/ 1097] train: loss: 0.0125999
[Epoch 34; Iter    39/ 1097] train: loss: 0.0165494
[Epoch 34; Iter    69/ 1097] train: loss: 0.0305691
[Epoch 34; Iter    99/ 1097] train: loss: 0.0425770
[Epoch 34; Iter   129/ 1097] train: loss: 0.1862095
[Epoch 34; Iter   159/ 1097] train: loss: 0.0074878
[Epoch 34; Iter   189/ 1097] train: loss: 0.0210918
[Epoch 34; Iter   219/ 1097] train: loss: 0.0096326
[Epoch 34; Iter   249/ 1097] train: loss: 0.0297185
[Epoch 34; Iter   279/ 1097] train: loss: 0.0056447
[Epoch 34; Iter   309/ 1097] train: loss: 0.0044665
[Epoch 34; Iter   339/ 1097] train: loss: 0.0177889
[Epoch 34; Iter   369/ 1097] train: loss: 0.0728780
[Epoch 34; Iter   399/ 1097] train: loss: 0.2280858
[Epoch 34; Iter   429/ 1097] train: loss: 0.0116381
[Epoch 34; Iter   459/ 1097] train: loss: 0.0340456
[Epoch 34; Iter   489/ 1097] train: loss: 0.0397743
[Epoch 34; Iter   519/ 1097] train: loss: 0.0032112
[Epoch 34; Iter   549/ 1097] train: loss: 0.0337167
[Epoch 34; Iter   579/ 1097] train: loss: 0.0208236
[Epoch 34; Iter   609/ 1097] train: loss: 0.0039037
[Epoch 34; Iter   639/ 1097] train: loss: 0.1143013
[Epoch 34; Iter   669/ 1097] train: loss: 0.0247766
[Epoch 34; Iter   699/ 1097] train: loss: 0.0165858
[Epoch 34; Iter   729/ 1097] train: loss: 0.1971912
[Epoch 34; Iter   759/ 1097] train: loss: 0.0049458
[Epoch 34; Iter   789/ 1097] train: loss: 0.0124892
[Epoch 34; Iter   819/ 1097] train: loss: 0.1750202
[Epoch 34; Iter   849/ 1097] train: loss: 0.0204971
[Epoch 34; Iter   879/ 1097] train: loss: 0.1246157
[Epoch 34; Iter   909/ 1097] train: loss: 0.0197073
[Epoch 34; Iter   939/ 1097] train: loss: 0.0301258
[Epoch 34; Iter   969/ 1097] train: loss: 0.0216903
[Epoch 34; Iter   999/ 1097] train: loss: 0.0313716
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0127038
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1000871
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0113257
[Epoch 34] ogbg-molhiv: 0.706634 val loss: 0.699694
[Epoch 34] ogbg-molhiv: 0.730053 test loss: 0.601185
[Epoch 35; Iter    22/ 1097] train: loss: 0.0087175
[Epoch 35; Iter    52/ 1097] train: loss: 0.0117814
[Epoch 35; Iter    82/ 1097] train: loss: 0.1474998
[Epoch 35; Iter   112/ 1097] train: loss: 0.0630275
[Epoch 35; Iter   142/ 1097] train: loss: 0.0111676
[Epoch 35; Iter   172/ 1097] train: loss: 0.0144922
[Epoch 35; Iter   202/ 1097] train: loss: 0.0476196
[Epoch 35; Iter   232/ 1097] train: loss: 0.0733469
[Epoch 35; Iter   262/ 1097] train: loss: 0.0044663
[Epoch 35; Iter   292/ 1097] train: loss: 0.0075462
[Epoch 35; Iter   322/ 1097] train: loss: 0.1476528
[Epoch 35; Iter   352/ 1097] train: loss: 0.0483118
[Epoch 35; Iter   382/ 1097] train: loss: 0.0979032
[Epoch 35; Iter   412/ 1097] train: loss: 0.0348268
[Epoch 35; Iter   442/ 1097] train: loss: 0.0088391
[Epoch 35; Iter   472/ 1097] train: loss: 0.0062749
[Epoch 35; Iter   502/ 1097] train: loss: 0.0177278
[Epoch 35; Iter   532/ 1097] train: loss: 0.0135381
[Epoch 35; Iter   562/ 1097] train: loss: 0.0128805
[Epoch 35; Iter   592/ 1097] train: loss: 0.0053040
[Epoch 35; Iter   622/ 1097] train: loss: 0.0357139
[Epoch 35; Iter   652/ 1097] train: loss: 0.0289282
[Epoch 35; Iter   682/ 1097] train: loss: 0.0218229
[Epoch 35; Iter   712/ 1097] train: loss: 0.1536272
[Epoch 35; Iter   742/ 1097] train: loss: 0.0453331
[Epoch 35; Iter   772/ 1097] train: loss: 0.0221042
[Epoch 35; Iter   802/ 1097] train: loss: 0.0052406
[Epoch 35; Iter   832/ 1097] train: loss: 0.0103564
[Epoch 35; Iter   862/ 1097] train: loss: 0.0063198
[Epoch 35; Iter   892/ 1097] train: loss: 0.0039695
[Epoch 35; Iter   922/ 1097] train: loss: 0.0024895
[Epoch 35; Iter   952/ 1097] train: loss: 0.0569704
[Epoch 35; Iter   982/ 1097] train: loss: 0.1780240
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0233935
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1752335
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0061307
[Epoch 35] ogbg-molhiv: 0.678525 val loss: 0.470298
[Epoch 35] ogbg-molhiv: 0.725626 test loss: 0.257667
[Epoch 36; Iter     5/ 1097] train: loss: 0.0066903
[Epoch 36; Iter    35/ 1097] train: loss: 0.0297104
[Epoch 36; Iter    65/ 1097] train: loss: 0.0332253
[Epoch 36; Iter    95/ 1097] train: loss: 0.0071106
[Epoch 36; Iter   125/ 1097] train: loss: 0.0387293
[Epoch 36; Iter   155/ 1097] train: loss: 0.0159599
[Epoch 36; Iter   185/ 1097] train: loss: 0.0032591
[Epoch 36; Iter   215/ 1097] train: loss: 0.0125469
[Epoch 36; Iter   245/ 1097] train: loss: 0.0081973
[Epoch 36; Iter   275/ 1097] train: loss: 0.1219770
[Epoch 36; Iter   305/ 1097] train: loss: 0.0373758
[Epoch 36; Iter   335/ 1097] train: loss: 0.0138130
[Epoch 36; Iter   365/ 1097] train: loss: 0.0783756
[Epoch 36; Iter   395/ 1097] train: loss: 0.0206299
[Epoch 36; Iter   425/ 1097] train: loss: 0.0085781
[Epoch 36; Iter   455/ 1097] train: loss: 0.0218611
[Epoch 36; Iter   485/ 1097] train: loss: 0.0886913
[Epoch 36; Iter   515/ 1097] train: loss: 0.0229704
[Epoch 36; Iter   545/ 1097] train: loss: 0.0322865
[Epoch 36; Iter   575/ 1097] train: loss: 0.0187155
[Epoch 32; Iter   523/ 1097] train: loss: 0.0192173
[Epoch 32; Iter   553/ 1097] train: loss: 0.0247835
[Epoch 32; Iter   583/ 1097] train: loss: 0.0206506
[Epoch 32; Iter   613/ 1097] train: loss: 0.0156182
[Epoch 32; Iter   643/ 1097] train: loss: 0.0052236
[Epoch 32; Iter   673/ 1097] train: loss: 0.3160163
[Epoch 32; Iter   703/ 1097] train: loss: 0.0104639
[Epoch 32; Iter   733/ 1097] train: loss: 0.0071285
[Epoch 32; Iter   763/ 1097] train: loss: 0.0437343
[Epoch 32; Iter   793/ 1097] train: loss: 0.0784306
[Epoch 32; Iter   823/ 1097] train: loss: 0.0798256
[Epoch 32; Iter   853/ 1097] train: loss: 0.0361715
[Epoch 32; Iter   883/ 1097] train: loss: 0.0596367
[Epoch 32; Iter   913/ 1097] train: loss: 0.0663376
[Epoch 32; Iter   943/ 1097] train: loss: 0.1405544
[Epoch 32; Iter   973/ 1097] train: loss: 0.0222954
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0460195
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0150623
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1682604
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0376670
[Epoch 32] ogbg-molhiv: 0.786676 val loss: 0.102073
[Epoch 32] ogbg-molhiv: 0.696649 test loss: 0.173602
[Epoch 33; Iter    26/ 1097] train: loss: 0.0094041
[Epoch 33; Iter    56/ 1097] train: loss: 0.0318137
[Epoch 33; Iter    86/ 1097] train: loss: 0.0070090
[Epoch 33; Iter   116/ 1097] train: loss: 0.0671741
[Epoch 33; Iter   146/ 1097] train: loss: 0.0088979
[Epoch 33; Iter   176/ 1097] train: loss: 0.0146481
[Epoch 33; Iter   206/ 1097] train: loss: 0.0091731
[Epoch 33; Iter   236/ 1097] train: loss: 0.1073197
[Epoch 33; Iter   266/ 1097] train: loss: 0.0519618
[Epoch 33; Iter   296/ 1097] train: loss: 0.0792650
[Epoch 33; Iter   326/ 1097] train: loss: 0.0465143
[Epoch 33; Iter   356/ 1097] train: loss: 0.0889533
[Epoch 33; Iter   386/ 1097] train: loss: 0.0135458
[Epoch 33; Iter   416/ 1097] train: loss: 0.0384550
[Epoch 33; Iter   446/ 1097] train: loss: 0.0615655
[Epoch 33; Iter   476/ 1097] train: loss: 0.0095773
[Epoch 33; Iter   506/ 1097] train: loss: 0.1086407
[Epoch 33; Iter   536/ 1097] train: loss: 0.0180539
[Epoch 33; Iter   566/ 1097] train: loss: 0.0395795
[Epoch 33; Iter   596/ 1097] train: loss: 0.0088031
[Epoch 33; Iter   626/ 1097] train: loss: 0.0466130
[Epoch 33; Iter   656/ 1097] train: loss: 0.0072296
[Epoch 33; Iter   686/ 1097] train: loss: 0.0714046
[Epoch 33; Iter   716/ 1097] train: loss: 0.0197749
[Epoch 33; Iter   746/ 1097] train: loss: 0.0848808
[Epoch 33; Iter   776/ 1097] train: loss: 0.0170928
[Epoch 33; Iter   806/ 1097] train: loss: 0.0269461
[Epoch 33; Iter   836/ 1097] train: loss: 0.0112716
[Epoch 33; Iter   866/ 1097] train: loss: 0.0106518
[Epoch 33; Iter   896/ 1097] train: loss: 0.2312122
[Epoch 33; Iter   926/ 1097] train: loss: 0.0962760
[Epoch 33; Iter   956/ 1097] train: loss: 0.0079675
[Epoch 33; Iter   986/ 1097] train: loss: 0.0065165
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0207002
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0678131
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2878821
[Epoch 33] ogbg-molhiv: 0.743454 val loss: 0.104825
[Epoch 33] ogbg-molhiv: 0.738968 test loss: 0.163355
[Epoch 34; Iter     9/ 1097] train: loss: 0.0147739
[Epoch 34; Iter    39/ 1097] train: loss: 0.0422408
[Epoch 34; Iter    69/ 1097] train: loss: 0.0140125
[Epoch 34; Iter    99/ 1097] train: loss: 0.0469055
[Epoch 34; Iter   129/ 1097] train: loss: 0.0628668
[Epoch 34; Iter   159/ 1097] train: loss: 0.0084242
[Epoch 34; Iter   189/ 1097] train: loss: 0.0279302
[Epoch 34; Iter   219/ 1097] train: loss: 0.0061215
[Epoch 34; Iter   249/ 1097] train: loss: 0.0485322
[Epoch 34; Iter   279/ 1097] train: loss: 0.0418718
[Epoch 34; Iter   309/ 1097] train: loss: 0.0074453
[Epoch 34; Iter   339/ 1097] train: loss: 0.0443616
[Epoch 34; Iter   369/ 1097] train: loss: 0.1535248
[Epoch 34; Iter   399/ 1097] train: loss: 0.1212188
[Epoch 34; Iter   429/ 1097] train: loss: 0.0031456
[Epoch 34; Iter   459/ 1097] train: loss: 0.0593702
[Epoch 34; Iter   489/ 1097] train: loss: 0.0213743
[Epoch 34; Iter   519/ 1097] train: loss: 0.0064361
[Epoch 34; Iter   549/ 1097] train: loss: 0.0084271
[Epoch 34; Iter   579/ 1097] train: loss: 0.0144862
[Epoch 34; Iter   609/ 1097] train: loss: 0.0065629
[Epoch 34; Iter   639/ 1097] train: loss: 0.0136176
[Epoch 34; Iter   669/ 1097] train: loss: 0.0070238
[Epoch 34; Iter   699/ 1097] train: loss: 0.0128807
[Epoch 34; Iter   729/ 1097] train: loss: 0.4106473
[Epoch 34; Iter   759/ 1097] train: loss: 0.0152868
[Epoch 34; Iter   789/ 1097] train: loss: 0.0453833
[Epoch 34; Iter   819/ 1097] train: loss: 0.1935825
[Epoch 34; Iter   849/ 1097] train: loss: 0.0232632
[Epoch 34; Iter   879/ 1097] train: loss: 0.0969246
[Epoch 34; Iter   909/ 1097] train: loss: 0.0098307
[Epoch 34; Iter   939/ 1097] train: loss: 0.2026290
[Epoch 34; Iter   969/ 1097] train: loss: 0.0516167
[Epoch 34; Iter   999/ 1097] train: loss: 0.0917985
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0133010
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0137550
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0059475
[Epoch 34] ogbg-molhiv: 0.795298 val loss: 0.100047
[Epoch 34] ogbg-molhiv: 0.738759 test loss: 0.171575
[Epoch 35; Iter    22/ 1097] train: loss: 0.0050767
[Epoch 35; Iter    52/ 1097] train: loss: 0.0029287
[Epoch 35; Iter    82/ 1097] train: loss: 0.0597045
[Epoch 35; Iter   112/ 1097] train: loss: 0.0077348
[Epoch 35; Iter   142/ 1097] train: loss: 0.0126962
[Epoch 35; Iter   172/ 1097] train: loss: 0.0020410
[Epoch 35; Iter   202/ 1097] train: loss: 0.0340107
[Epoch 35; Iter   232/ 1097] train: loss: 0.0111295
[Epoch 35; Iter   262/ 1097] train: loss: 0.0025187
[Epoch 35; Iter   292/ 1097] train: loss: 0.0098184
[Epoch 35; Iter   322/ 1097] train: loss: 0.0602475
[Epoch 35; Iter   352/ 1097] train: loss: 0.1382374
[Epoch 35; Iter   382/ 1097] train: loss: 0.1465064
[Epoch 35; Iter   412/ 1097] train: loss: 0.0236074
[Epoch 35; Iter   442/ 1097] train: loss: 0.0079529
[Epoch 35; Iter   472/ 1097] train: loss: 0.0389714
[Epoch 35; Iter   502/ 1097] train: loss: 0.0686813
[Epoch 35; Iter   532/ 1097] train: loss: 0.0307012
[Epoch 35; Iter   562/ 1097] train: loss: 0.0476766
[Epoch 35; Iter   592/ 1097] train: loss: 0.0188253
[Epoch 35; Iter   622/ 1097] train: loss: 0.0363257
[Epoch 35; Iter   652/ 1097] train: loss: 0.0201800
[Epoch 35; Iter   682/ 1097] train: loss: 0.0688694
[Epoch 35; Iter   712/ 1097] train: loss: 0.0372533
[Epoch 35; Iter   742/ 1097] train: loss: 0.0760838
[Epoch 35; Iter   772/ 1097] train: loss: 0.1240623
[Epoch 35; Iter   802/ 1097] train: loss: 0.0910636
[Epoch 35; Iter   832/ 1097] train: loss: 0.0677916
[Epoch 35; Iter   862/ 1097] train: loss: 0.0316388
[Epoch 35; Iter   892/ 1097] train: loss: 0.0069711
[Epoch 35; Iter   922/ 1097] train: loss: 0.0057380
[Epoch 35; Iter   952/ 1097] train: loss: 0.1148676
[Epoch 35; Iter   982/ 1097] train: loss: 0.0540529
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0703005
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1257044
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0227276
[Epoch 35] ogbg-molhiv: 0.780668 val loss: 0.128360
[Epoch 35] ogbg-molhiv: 0.720082 test loss: 0.178839
[Epoch 36; Iter     5/ 1097] train: loss: 0.0136609
[Epoch 36; Iter    35/ 1097] train: loss: 0.0242135
[Epoch 36; Iter    65/ 1097] train: loss: 0.0054989
[Epoch 36; Iter    95/ 1097] train: loss: 0.0482624
[Epoch 36; Iter   125/ 1097] train: loss: 0.0369924
[Epoch 36; Iter   155/ 1097] train: loss: 0.0062067
[Epoch 36; Iter   185/ 1097] train: loss: 0.0200125
[Epoch 36; Iter   215/ 1097] train: loss: 0.0243690
[Epoch 36; Iter   245/ 1097] train: loss: 0.0065672
[Epoch 36; Iter   275/ 1097] train: loss: 0.0481833
[Epoch 36; Iter   305/ 1097] train: loss: 0.0539346
[Epoch 36; Iter   335/ 1097] train: loss: 0.0139904
[Epoch 36; Iter   365/ 1097] train: loss: 0.0073420
[Epoch 36; Iter   395/ 1097] train: loss: 0.0052118
[Epoch 36; Iter   425/ 1097] train: loss: 0.0195870
[Epoch 36; Iter   455/ 1097] train: loss: 0.0354587
[Epoch 36; Iter   485/ 1097] train: loss: 0.0087449
[Epoch 36; Iter   515/ 1097] train: loss: 0.0424573
[Epoch 36; Iter   545/ 1097] train: loss: 0.0037957
[Epoch 36; Iter   575/ 1097] train: loss: 0.0025417
[Epoch 32; Iter   523/ 1097] train: loss: 0.0484034
[Epoch 32; Iter   553/ 1097] train: loss: 0.0124537
[Epoch 32; Iter   583/ 1097] train: loss: 0.0100319
[Epoch 32; Iter   613/ 1097] train: loss: 0.1654191
[Epoch 32; Iter   643/ 1097] train: loss: 0.0103549
[Epoch 32; Iter   673/ 1097] train: loss: 0.0063985
[Epoch 32; Iter   703/ 1097] train: loss: 0.0333039
[Epoch 32; Iter   733/ 1097] train: loss: 0.0070599
[Epoch 32; Iter   763/ 1097] train: loss: 0.0102328
[Epoch 32; Iter   793/ 1097] train: loss: 0.0113277
[Epoch 32; Iter   823/ 1097] train: loss: 0.0930438
[Epoch 32; Iter   853/ 1097] train: loss: 0.0094393
[Epoch 32; Iter   883/ 1097] train: loss: 0.0723936
[Epoch 32; Iter   913/ 1097] train: loss: 0.0055196
[Epoch 32; Iter   943/ 1097] train: loss: 0.0033874
[Epoch 32; Iter   973/ 1097] train: loss: 0.0441213
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0057326
[Epoch 32; Iter  1033/ 1097] train: loss: 0.1345897
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0099197
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0073824
[Epoch 32] ogbg-molhiv: 0.768626 val loss: 0.135186
[Epoch 32] ogbg-molhiv: 0.728479 test loss: 0.230939
[Epoch 33; Iter    26/ 1097] train: loss: 0.0264654
[Epoch 33; Iter    56/ 1097] train: loss: 0.0711799
[Epoch 33; Iter    86/ 1097] train: loss: 0.0057145
[Epoch 33; Iter   116/ 1097] train: loss: 0.0105199
[Epoch 33; Iter   146/ 1097] train: loss: 0.0113652
[Epoch 33; Iter   176/ 1097] train: loss: 0.0692880
[Epoch 33; Iter   206/ 1097] train: loss: 0.0177014
[Epoch 33; Iter   236/ 1097] train: loss: 0.0150589
[Epoch 33; Iter   266/ 1097] train: loss: 0.0078361
[Epoch 33; Iter   296/ 1097] train: loss: 0.0050731
[Epoch 33; Iter   326/ 1097] train: loss: 0.0926946
[Epoch 33; Iter   356/ 1097] train: loss: 0.0080616
[Epoch 33; Iter   386/ 1097] train: loss: 0.0493708
[Epoch 33; Iter   416/ 1097] train: loss: 0.1288293
[Epoch 33; Iter   446/ 1097] train: loss: 0.0819933
[Epoch 33; Iter   476/ 1097] train: loss: 0.0059934
[Epoch 33; Iter   506/ 1097] train: loss: 0.0054810
[Epoch 33; Iter   536/ 1097] train: loss: 0.0387511
[Epoch 33; Iter   566/ 1097] train: loss: 0.0136222
[Epoch 33; Iter   596/ 1097] train: loss: 0.0466704
[Epoch 33; Iter   626/ 1097] train: loss: 0.0024310
[Epoch 33; Iter   656/ 1097] train: loss: 0.0054686
[Epoch 33; Iter   686/ 1097] train: loss: 0.0189053
[Epoch 33; Iter   716/ 1097] train: loss: 0.0819792
[Epoch 33; Iter   746/ 1097] train: loss: 0.0326516
[Epoch 33; Iter   776/ 1097] train: loss: 0.0100325
[Epoch 33; Iter   806/ 1097] train: loss: 0.0399087
[Epoch 33; Iter   836/ 1097] train: loss: 0.1393930
[Epoch 33; Iter   866/ 1097] train: loss: 0.0071194
[Epoch 33; Iter   896/ 1097] train: loss: 0.0068560
[Epoch 33; Iter   926/ 1097] train: loss: 0.0369262
[Epoch 33; Iter   956/ 1097] train: loss: 0.0103270
[Epoch 33; Iter   986/ 1097] train: loss: 0.0261633
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0112032
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0271627
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0070593
[Epoch 33] ogbg-molhiv: 0.758742 val loss: 0.339387
[Epoch 33] ogbg-molhiv: 0.695902 test loss: 0.454576
[Epoch 34; Iter     9/ 1097] train: loss: 0.0064665
[Epoch 34; Iter    39/ 1097] train: loss: 0.0197537
[Epoch 34; Iter    69/ 1097] train: loss: 0.0041028
[Epoch 34; Iter    99/ 1097] train: loss: 0.0103483
[Epoch 34; Iter   129/ 1097] train: loss: 0.0190575
[Epoch 34; Iter   159/ 1097] train: loss: 0.0065290
[Epoch 34; Iter   189/ 1097] train: loss: 0.0333771
[Epoch 34; Iter   219/ 1097] train: loss: 0.0844243
[Epoch 34; Iter   249/ 1097] train: loss: 0.0086603
[Epoch 34; Iter   279/ 1097] train: loss: 0.2009676
[Epoch 34; Iter   309/ 1097] train: loss: 0.0192723
[Epoch 34; Iter   339/ 1097] train: loss: 0.0085207
[Epoch 34; Iter   369/ 1097] train: loss: 0.0076705
[Epoch 34; Iter   399/ 1097] train: loss: 0.0012582
[Epoch 34; Iter   429/ 1097] train: loss: 0.0103032
[Epoch 34; Iter   459/ 1097] train: loss: 0.0575624
[Epoch 34; Iter   489/ 1097] train: loss: 0.0116197
[Epoch 34; Iter   519/ 1097] train: loss: 0.0256527
[Epoch 34; Iter   549/ 1097] train: loss: 0.2179994
[Epoch 34; Iter   579/ 1097] train: loss: 0.0561559
[Epoch 34; Iter   609/ 1097] train: loss: 0.0022328
[Epoch 34; Iter   639/ 1097] train: loss: 0.0026080
[Epoch 34; Iter   669/ 1097] train: loss: 0.0095202
[Epoch 34; Iter   699/ 1097] train: loss: 0.0965323
[Epoch 34; Iter   729/ 1097] train: loss: 0.1461114
[Epoch 34; Iter   759/ 1097] train: loss: 0.0222808
[Epoch 34; Iter   789/ 1097] train: loss: 0.0217817
[Epoch 34; Iter   819/ 1097] train: loss: 0.0427532
[Epoch 34; Iter   849/ 1097] train: loss: 0.0055308
[Epoch 34; Iter   879/ 1097] train: loss: 0.0131324
[Epoch 34; Iter   909/ 1097] train: loss: 0.0073081
[Epoch 34; Iter   939/ 1097] train: loss: 0.0749221
[Epoch 34; Iter   969/ 1097] train: loss: 0.0260544
[Epoch 34; Iter   999/ 1097] train: loss: 0.0140044
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1606630
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0101565
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0090295
[Epoch 34] ogbg-molhiv: 0.757012 val loss: 0.150203
[Epoch 34] ogbg-molhiv: 0.694100 test loss: 0.258520
[Epoch 35; Iter    22/ 1097] train: loss: 0.0137393
[Epoch 35; Iter    52/ 1097] train: loss: 0.0099977
[Epoch 35; Iter    82/ 1097] train: loss: 0.0134560
[Epoch 35; Iter   112/ 1097] train: loss: 0.0948764
[Epoch 35; Iter   142/ 1097] train: loss: 0.0270300
[Epoch 35; Iter   172/ 1097] train: loss: 0.0148235
[Epoch 35; Iter   202/ 1097] train: loss: 0.0228754
[Epoch 35; Iter   232/ 1097] train: loss: 0.1192308
[Epoch 35; Iter   262/ 1097] train: loss: 0.0803988
[Epoch 35; Iter   292/ 1097] train: loss: 0.0538637
[Epoch 35; Iter   322/ 1097] train: loss: 0.0240322
[Epoch 35; Iter   352/ 1097] train: loss: 0.0032013
[Epoch 35; Iter   382/ 1097] train: loss: 0.0022403
[Epoch 35; Iter   412/ 1097] train: loss: 0.0118060
[Epoch 35; Iter   442/ 1097] train: loss: 0.0094275
[Epoch 35; Iter   472/ 1097] train: loss: 0.0054080
[Epoch 35; Iter   502/ 1097] train: loss: 0.0185894
[Epoch 35; Iter   532/ 1097] train: loss: 0.0083799
[Epoch 35; Iter   562/ 1097] train: loss: 0.0679523
[Epoch 35; Iter   592/ 1097] train: loss: 0.0114763
[Epoch 35; Iter   622/ 1097] train: loss: 0.0068891
[Epoch 35; Iter   652/ 1097] train: loss: 0.0074153
[Epoch 35; Iter   682/ 1097] train: loss: 0.0045606
[Epoch 35; Iter   712/ 1097] train: loss: 0.0781843
[Epoch 35; Iter   742/ 1097] train: loss: 0.0903867
[Epoch 35; Iter   772/ 1097] train: loss: 0.0170218
[Epoch 35; Iter   802/ 1097] train: loss: 0.0064858
[Epoch 35; Iter   832/ 1097] train: loss: 0.0948393
[Epoch 35; Iter   862/ 1097] train: loss: 0.0275790
[Epoch 35; Iter   892/ 1097] train: loss: 0.0162394
[Epoch 35; Iter   922/ 1097] train: loss: 0.0594023
[Epoch 35; Iter   952/ 1097] train: loss: 0.0014306
[Epoch 35; Iter   982/ 1097] train: loss: 0.0111271
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0109456
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0142369
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0136223
[Epoch 35] ogbg-molhiv: 0.720854 val loss: 0.290715
[Epoch 35] ogbg-molhiv: 0.714208 test loss: 0.335513
[Epoch 36; Iter     5/ 1097] train: loss: 0.0193571
[Epoch 36; Iter    35/ 1097] train: loss: 0.0163582
[Epoch 36; Iter    65/ 1097] train: loss: 0.0306572
[Epoch 36; Iter    95/ 1097] train: loss: 0.0367660
[Epoch 36; Iter   125/ 1097] train: loss: 0.0054763
[Epoch 36; Iter   155/ 1097] train: loss: 0.0030902
[Epoch 36; Iter   185/ 1097] train: loss: 0.0096636
[Epoch 36; Iter   215/ 1097] train: loss: 0.0538042
[Epoch 36; Iter   245/ 1097] train: loss: 0.0018625
[Epoch 36; Iter   275/ 1097] train: loss: 0.0081734
[Epoch 36; Iter   305/ 1097] train: loss: 0.1411911
[Epoch 36; Iter   335/ 1097] train: loss: 0.0077941
[Epoch 36; Iter   365/ 1097] train: loss: 0.0030187
[Epoch 36; Iter   395/ 1097] train: loss: 0.0097724
[Epoch 36; Iter   425/ 1097] train: loss: 0.0393127
[Epoch 36; Iter   455/ 1097] train: loss: 0.0186524
[Epoch 36; Iter   485/ 1097] train: loss: 0.0015683
[Epoch 36; Iter   515/ 1097] train: loss: 0.0022613
[Epoch 36; Iter   545/ 1097] train: loss: 0.0102803
[Epoch 36; Iter   575/ 1097] train: loss: 0.0017963
[Epoch 32; Iter   523/ 1097] train: loss: 0.0390742
[Epoch 32; Iter   553/ 1097] train: loss: 0.0047031
[Epoch 32; Iter   583/ 1097] train: loss: 0.1605569
[Epoch 32; Iter   613/ 1097] train: loss: 0.0090963
[Epoch 32; Iter   643/ 1097] train: loss: 0.0577251
[Epoch 32; Iter   673/ 1097] train: loss: 0.0952898
[Epoch 32; Iter   703/ 1097] train: loss: 0.0092739
[Epoch 32; Iter   733/ 1097] train: loss: 0.0135880
[Epoch 32; Iter   763/ 1097] train: loss: 0.0115559
[Epoch 32; Iter   793/ 1097] train: loss: 0.0516414
[Epoch 32; Iter   823/ 1097] train: loss: 0.0290027
[Epoch 32; Iter   853/ 1097] train: loss: 0.0026700
[Epoch 32; Iter   883/ 1097] train: loss: 0.0063502
[Epoch 32; Iter   913/ 1097] train: loss: 0.0237541
[Epoch 32; Iter   943/ 1097] train: loss: 0.0077343
[Epoch 32; Iter   973/ 1097] train: loss: 0.0298439
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0809974
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0029149
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0041643
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0313332
[Epoch 32] ogbg-molhiv: 0.760414 val loss: 0.191171
[Epoch 32] ogbg-molhiv: 0.765459 test loss: 0.209318
[Epoch 33; Iter    26/ 1097] train: loss: 0.1286610
[Epoch 33; Iter    56/ 1097] train: loss: 0.0039323
[Epoch 33; Iter    86/ 1097] train: loss: 0.0092613
[Epoch 33; Iter   116/ 1097] train: loss: 0.0509834
[Epoch 33; Iter   146/ 1097] train: loss: 0.0122949
[Epoch 33; Iter   176/ 1097] train: loss: 0.0035283
[Epoch 33; Iter   206/ 1097] train: loss: 0.0033643
[Epoch 33; Iter   236/ 1097] train: loss: 0.0383229
[Epoch 33; Iter   266/ 1097] train: loss: 0.0018118
[Epoch 33; Iter   296/ 1097] train: loss: 0.0101330
[Epoch 33; Iter   326/ 1097] train: loss: 0.0040304
[Epoch 33; Iter   356/ 1097] train: loss: 0.1658339
[Epoch 33; Iter   386/ 1097] train: loss: 0.0022533
[Epoch 33; Iter   416/ 1097] train: loss: 0.0050884
[Epoch 33; Iter   446/ 1097] train: loss: 0.0017057
[Epoch 33; Iter   476/ 1097] train: loss: 0.0032637
[Epoch 33; Iter   506/ 1097] train: loss: 0.0124711
[Epoch 33; Iter   536/ 1097] train: loss: 0.0071063
[Epoch 33; Iter   566/ 1097] train: loss: 0.0558263
[Epoch 33; Iter   596/ 1097] train: loss: 0.0026781
[Epoch 33; Iter   626/ 1097] train: loss: 0.0088434
[Epoch 33; Iter   656/ 1097] train: loss: 0.0530141
[Epoch 33; Iter   686/ 1097] train: loss: 0.0015670
[Epoch 33; Iter   716/ 1097] train: loss: 0.0690441
[Epoch 33; Iter   746/ 1097] train: loss: 0.0015557
[Epoch 33; Iter   776/ 1097] train: loss: 0.1768330
[Epoch 33; Iter   806/ 1097] train: loss: 0.0056164
[Epoch 33; Iter   836/ 1097] train: loss: 0.0017702
[Epoch 33; Iter   866/ 1097] train: loss: 0.0052388
[Epoch 33; Iter   896/ 1097] train: loss: 0.0109460
[Epoch 33; Iter   926/ 1097] train: loss: 0.0318117
[Epoch 33; Iter   956/ 1097] train: loss: 0.0099345
[Epoch 33; Iter   986/ 1097] train: loss: 0.0026548
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0398471
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0186608
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0276567
[Epoch 33] ogbg-molhiv: 0.783442 val loss: 0.164912
[Epoch 33] ogbg-molhiv: 0.792680 test loss: 0.201679
[Epoch 34; Iter     9/ 1097] train: loss: 0.0041430
[Epoch 34; Iter    39/ 1097] train: loss: 0.0743666
[Epoch 34; Iter    69/ 1097] train: loss: 0.0024225
[Epoch 34; Iter    99/ 1097] train: loss: 0.0057380
[Epoch 34; Iter   129/ 1097] train: loss: 0.0038771
[Epoch 34; Iter   159/ 1097] train: loss: 0.0069169
[Epoch 34; Iter   189/ 1097] train: loss: 0.0043207
[Epoch 34; Iter   219/ 1097] train: loss: 0.0049295
[Epoch 34; Iter   249/ 1097] train: loss: 0.0027665
[Epoch 34; Iter   279/ 1097] train: loss: 0.0292373
[Epoch 34; Iter   309/ 1097] train: loss: 0.0219252
[Epoch 34; Iter   339/ 1097] train: loss: 0.1268857
[Epoch 34; Iter   369/ 1097] train: loss: 0.0267600
[Epoch 34; Iter   399/ 1097] train: loss: 0.0151575
[Epoch 34; Iter   429/ 1097] train: loss: 0.0142286
[Epoch 34; Iter   459/ 1097] train: loss: 0.0028592
[Epoch 34; Iter   489/ 1097] train: loss: 0.0087149
[Epoch 34; Iter   519/ 1097] train: loss: 0.0029583
[Epoch 34; Iter   549/ 1097] train: loss: 0.0460754
[Epoch 34; Iter   579/ 1097] train: loss: 0.0132217
[Epoch 34; Iter   609/ 1097] train: loss: 0.0292913
[Epoch 34; Iter   639/ 1097] train: loss: 0.0106243
[Epoch 34; Iter   669/ 1097] train: loss: 0.0124073
[Epoch 34; Iter   699/ 1097] train: loss: 0.0131670
[Epoch 34; Iter   729/ 1097] train: loss: 0.0196895
[Epoch 34; Iter   759/ 1097] train: loss: 0.2978943
[Epoch 34; Iter   789/ 1097] train: loss: 0.0035132
[Epoch 34; Iter   819/ 1097] train: loss: 0.0356135
[Epoch 34; Iter   849/ 1097] train: loss: 0.2759030
[Epoch 34; Iter   879/ 1097] train: loss: 0.0199697
[Epoch 34; Iter   909/ 1097] train: loss: 0.0132554
[Epoch 34; Iter   939/ 1097] train: loss: 0.0062027
[Epoch 34; Iter   969/ 1097] train: loss: 0.0131998
[Epoch 34; Iter   999/ 1097] train: loss: 0.0617574
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0581286
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1058354
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0073767
[Epoch 34] ogbg-molhiv: 0.785258 val loss: 0.168135
[Epoch 34] ogbg-molhiv: 0.790641 test loss: 0.221977
[Epoch 35; Iter    22/ 1097] train: loss: 0.0034468
[Epoch 35; Iter    52/ 1097] train: loss: 0.0248843
[Epoch 35; Iter    82/ 1097] train: loss: 0.0312318
[Epoch 35; Iter   112/ 1097] train: loss: 0.0031657
[Epoch 35; Iter   142/ 1097] train: loss: 0.0079189
[Epoch 35; Iter   172/ 1097] train: loss: 0.0158235
[Epoch 35; Iter   202/ 1097] train: loss: 0.0124483
[Epoch 35; Iter   232/ 1097] train: loss: 0.0120658
[Epoch 35; Iter   262/ 1097] train: loss: 0.0014958
[Epoch 35; Iter   292/ 1097] train: loss: 0.0033169
[Epoch 35; Iter   322/ 1097] train: loss: 0.0054668
[Epoch 35; Iter   352/ 1097] train: loss: 0.0158828
[Epoch 35; Iter   382/ 1097] train: loss: 0.0127057
[Epoch 35; Iter   412/ 1097] train: loss: 0.0485279
[Epoch 35; Iter   442/ 1097] train: loss: 0.0113240
[Epoch 35; Iter   472/ 1097] train: loss: 0.0179397
[Epoch 35; Iter   502/ 1097] train: loss: 0.0112344
[Epoch 35; Iter   532/ 1097] train: loss: 0.0017601
[Epoch 35; Iter   562/ 1097] train: loss: 0.0688148
[Epoch 35; Iter   592/ 1097] train: loss: 0.0020873
[Epoch 35; Iter   622/ 1097] train: loss: 0.0043174
[Epoch 35; Iter   652/ 1097] train: loss: 0.0033391
[Epoch 35; Iter   682/ 1097] train: loss: 0.0046990
[Epoch 35; Iter   712/ 1097] train: loss: 0.0601976
[Epoch 35; Iter   742/ 1097] train: loss: 0.0019410
[Epoch 35; Iter   772/ 1097] train: loss: 0.0012772
[Epoch 35; Iter   802/ 1097] train: loss: 0.0038931
[Epoch 35; Iter   832/ 1097] train: loss: 0.0078414
[Epoch 35; Iter   862/ 1097] train: loss: 0.0163656
[Epoch 35; Iter   892/ 1097] train: loss: 0.1647815
[Epoch 35; Iter   922/ 1097] train: loss: 0.0014418
[Epoch 35; Iter   952/ 1097] train: loss: 0.0307421
[Epoch 35; Iter   982/ 1097] train: loss: 0.0022862
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0055701
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0070277
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0057587
[Epoch 35] ogbg-molhiv: 0.786400 val loss: 0.199499
[Epoch 35] ogbg-molhiv: 0.796164 test loss: 0.210149
[Epoch 36; Iter     5/ 1097] train: loss: 0.0037934
[Epoch 36; Iter    35/ 1097] train: loss: 0.0031581
[Epoch 36; Iter    65/ 1097] train: loss: 0.0071049
[Epoch 36; Iter    95/ 1097] train: loss: 0.0143806
[Epoch 36; Iter   125/ 1097] train: loss: 0.0018120
[Epoch 36; Iter   155/ 1097] train: loss: 0.0064685
[Epoch 36; Iter   185/ 1097] train: loss: 0.0022794
[Epoch 36; Iter   215/ 1097] train: loss: 0.0977723
[Epoch 36; Iter   245/ 1097] train: loss: 0.0017891
[Epoch 36; Iter   275/ 1097] train: loss: 0.0067762
[Epoch 36; Iter   305/ 1097] train: loss: 0.0039997
[Epoch 36; Iter   335/ 1097] train: loss: 0.0130431
[Epoch 36; Iter   365/ 1097] train: loss: 0.0055998
[Epoch 36; Iter   395/ 1097] train: loss: 0.0234075
[Epoch 36; Iter   425/ 1097] train: loss: 0.0063487
[Epoch 36; Iter   455/ 1097] train: loss: 0.0020699
[Epoch 36; Iter   485/ 1097] train: loss: 0.0077959
[Epoch 36; Iter   515/ 1097] train: loss: 0.0155358
[Epoch 36; Iter   545/ 1097] train: loss: 0.0090763
[Epoch 36; Iter   575/ 1097] train: loss: 0.0067980
[Epoch 32; Iter   523/ 1097] train: loss: 0.0013489
[Epoch 32; Iter   553/ 1097] train: loss: 0.0097123
[Epoch 32; Iter   583/ 1097] train: loss: 0.0222512
[Epoch 32; Iter   613/ 1097] train: loss: 0.0076725
[Epoch 32; Iter   643/ 1097] train: loss: 0.0016812
[Epoch 32; Iter   673/ 1097] train: loss: 0.0464785
[Epoch 32; Iter   703/ 1097] train: loss: 0.0008418
[Epoch 32; Iter   733/ 1097] train: loss: 0.0008080
[Epoch 32; Iter   763/ 1097] train: loss: 0.0013698
[Epoch 32; Iter   793/ 1097] train: loss: 0.0068561
[Epoch 32; Iter   823/ 1097] train: loss: 0.0024745
[Epoch 32; Iter   853/ 1097] train: loss: 0.0033826
[Epoch 32; Iter   883/ 1097] train: loss: 0.0118120
[Epoch 32; Iter   913/ 1097] train: loss: 0.0500451
[Epoch 32; Iter   943/ 1097] train: loss: 0.0049030
[Epoch 32; Iter   973/ 1097] train: loss: 0.0115740
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0014746
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0016094
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0218526
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0192518
[Epoch 32] ogbg-molhiv: 0.643877 val loss: 1.646138
[Epoch 32] ogbg-molhiv: 0.564376 test loss: 1.526431
[Epoch 33; Iter    26/ 1097] train: loss: 0.0035053
[Epoch 33; Iter    56/ 1097] train: loss: 0.0150135
[Epoch 33; Iter    86/ 1097] train: loss: 0.0322708
[Epoch 33; Iter   116/ 1097] train: loss: 0.0645113
[Epoch 33; Iter   146/ 1097] train: loss: 0.0025305
[Epoch 33; Iter   176/ 1097] train: loss: 0.0022337
[Epoch 33; Iter   206/ 1097] train: loss: 0.0008824
[Epoch 33; Iter   236/ 1097] train: loss: 0.0002703
[Epoch 33; Iter   266/ 1097] train: loss: 0.0021303
[Epoch 33; Iter   296/ 1097] train: loss: 0.0622901
[Epoch 33; Iter   326/ 1097] train: loss: 0.1297068
[Epoch 33; Iter   356/ 1097] train: loss: 0.0024784
[Epoch 33; Iter   386/ 1097] train: loss: 0.0144557
[Epoch 33; Iter   416/ 1097] train: loss: 0.0074851
[Epoch 33; Iter   446/ 1097] train: loss: 0.0008036
[Epoch 33; Iter   476/ 1097] train: loss: 0.1486471
[Epoch 33; Iter   506/ 1097] train: loss: 0.0318361
[Epoch 33; Iter   536/ 1097] train: loss: 0.0392315
[Epoch 33; Iter   566/ 1097] train: loss: 0.0056142
[Epoch 33; Iter   596/ 1097] train: loss: 0.0011499
[Epoch 33; Iter   626/ 1097] train: loss: 0.0018230
[Epoch 33; Iter   656/ 1097] train: loss: 0.0011981
[Epoch 33; Iter   686/ 1097] train: loss: 0.0026956
[Epoch 33; Iter   716/ 1097] train: loss: 0.0110199
[Epoch 33; Iter   746/ 1097] train: loss: 0.0065850
[Epoch 33; Iter   776/ 1097] train: loss: 0.0016956
[Epoch 33; Iter   806/ 1097] train: loss: 0.0197934
[Epoch 33; Iter   836/ 1097] train: loss: 0.0024148
[Epoch 33; Iter   866/ 1097] train: loss: 0.0049779
[Epoch 33; Iter   896/ 1097] train: loss: 0.0008592
[Epoch 33; Iter   926/ 1097] train: loss: 0.0078889
[Epoch 33; Iter   956/ 1097] train: loss: 0.0045649
[Epoch 33; Iter   986/ 1097] train: loss: 0.0017457
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0108654
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0012203
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0312945
[Epoch 33] ogbg-molhiv: 0.678219 val loss: 8.993637
[Epoch 33] ogbg-molhiv: 0.590726 test loss: 9.622485
[Epoch 34; Iter     9/ 1097] train: loss: 0.0104935
[Epoch 34; Iter    39/ 1097] train: loss: 0.0087008
[Epoch 34; Iter    69/ 1097] train: loss: 0.0062154
[Epoch 34; Iter    99/ 1097] train: loss: 0.0132369
[Epoch 34; Iter   129/ 1097] train: loss: 0.0008374
[Epoch 34; Iter   159/ 1097] train: loss: 0.0035928
[Epoch 34; Iter   189/ 1097] train: loss: 0.0086817
[Epoch 34; Iter   219/ 1097] train: loss: 0.0012144
[Epoch 34; Iter   249/ 1097] train: loss: 0.0064319
[Epoch 34; Iter   279/ 1097] train: loss: 0.0041724
[Epoch 34; Iter   309/ 1097] train: loss: 0.0174933
[Epoch 34; Iter   339/ 1097] train: loss: 0.0052198
[Epoch 34; Iter   369/ 1097] train: loss: 0.0065731
[Epoch 34; Iter   399/ 1097] train: loss: 0.0003078
[Epoch 34; Iter   429/ 1097] train: loss: 0.0572047
[Epoch 34; Iter   459/ 1097] train: loss: 0.0052416
[Epoch 34; Iter   489/ 1097] train: loss: 0.0007488
[Epoch 34; Iter   519/ 1097] train: loss: 0.0011117
[Epoch 34; Iter   549/ 1097] train: loss: 0.0029622
[Epoch 34; Iter   579/ 1097] train: loss: 0.0059234
[Epoch 34; Iter   609/ 1097] train: loss: 0.0006613
[Epoch 34; Iter   639/ 1097] train: loss: 0.0481605
[Epoch 34; Iter   669/ 1097] train: loss: 0.0001231
[Epoch 34; Iter   699/ 1097] train: loss: 0.0021914
[Epoch 34; Iter   729/ 1097] train: loss: 0.0389297
[Epoch 34; Iter   759/ 1097] train: loss: 0.0033012
[Epoch 34; Iter   789/ 1097] train: loss: 0.0059184
[Epoch 34; Iter   819/ 1097] train: loss: 0.0079487
[Epoch 34; Iter   849/ 1097] train: loss: 0.0061700
[Epoch 34; Iter   879/ 1097] train: loss: 0.0465698
[Epoch 34; Iter   909/ 1097] train: loss: 0.0007854
[Epoch 34; Iter   939/ 1097] train: loss: 0.0570816
[Epoch 34; Iter   969/ 1097] train: loss: 0.0096926
[Epoch 34; Iter   999/ 1097] train: loss: 0.0227222
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0217810
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0037782
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0114548
[Epoch 34] ogbg-molhiv: 0.650301 val loss: 12.305792
[Epoch 34] ogbg-molhiv: 0.555017 test loss: 11.179704
[Epoch 35; Iter    22/ 1097] train: loss: 0.0057855
[Epoch 35; Iter    52/ 1097] train: loss: 0.0009277
[Epoch 35; Iter    82/ 1097] train: loss: 0.0262705
[Epoch 35; Iter   112/ 1097] train: loss: 0.0048493
[Epoch 35; Iter   142/ 1097] train: loss: 0.0009639
[Epoch 35; Iter   172/ 1097] train: loss: 0.0009443
[Epoch 35; Iter   202/ 1097] train: loss: 0.0002704
[Epoch 35; Iter   232/ 1097] train: loss: 0.0016383
[Epoch 35; Iter   262/ 1097] train: loss: 0.0002392
[Epoch 35; Iter   292/ 1097] train: loss: 0.0081504
[Epoch 35; Iter   322/ 1097] train: loss: 0.0075070
[Epoch 35; Iter   352/ 1097] train: loss: 0.0627851
[Epoch 35; Iter   382/ 1097] train: loss: 0.0132947
[Epoch 35; Iter   412/ 1097] train: loss: 0.0020443
[Epoch 35; Iter   442/ 1097] train: loss: 0.0260482
[Epoch 35; Iter   472/ 1097] train: loss: 0.0078098
[Epoch 35; Iter   502/ 1097] train: loss: 0.0006953
[Epoch 35; Iter   532/ 1097] train: loss: 0.0110803
[Epoch 35; Iter   562/ 1097] train: loss: 0.0101957
[Epoch 35; Iter   592/ 1097] train: loss: 0.0004086
[Epoch 35; Iter   622/ 1097] train: loss: 0.0421442
[Epoch 35; Iter   652/ 1097] train: loss: 0.0263620
[Epoch 35; Iter   682/ 1097] train: loss: 0.0345920
[Epoch 35; Iter   712/ 1097] train: loss: 0.0196315
[Epoch 35; Iter   742/ 1097] train: loss: 0.0303568
[Epoch 35; Iter   772/ 1097] train: loss: 0.0054791
[Epoch 35; Iter   802/ 1097] train: loss: 0.0002322
[Epoch 35; Iter   832/ 1097] train: loss: 0.0002315
[Epoch 35; Iter   862/ 1097] train: loss: 0.0008477
[Epoch 35; Iter   892/ 1097] train: loss: 0.0037416
[Epoch 35; Iter   922/ 1097] train: loss: 0.0009880
[Epoch 35; Iter   952/ 1097] train: loss: 0.0038973
[Epoch 35; Iter   982/ 1097] train: loss: 0.0253091
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0376691
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1085393
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0062246
[Epoch 35] ogbg-molhiv: 0.658476 val loss: 8.754370
[Epoch 35] ogbg-molhiv: 0.622629 test loss: 10.014339
[Epoch 36; Iter     5/ 1097] train: loss: 0.0010119
[Epoch 36; Iter    35/ 1097] train: loss: 0.0013286
[Epoch 36; Iter    65/ 1097] train: loss: 0.0014517
[Epoch 36; Iter    95/ 1097] train: loss: 0.0034286
[Epoch 36; Iter   125/ 1097] train: loss: 0.0028750
[Epoch 36; Iter   155/ 1097] train: loss: 0.0756278
[Epoch 36; Iter   185/ 1097] train: loss: 0.0166194
[Epoch 36; Iter   215/ 1097] train: loss: 0.0029806
[Epoch 36; Iter   245/ 1097] train: loss: 0.0273870
[Epoch 36; Iter   275/ 1097] train: loss: 0.0000818
[Epoch 36; Iter   305/ 1097] train: loss: 0.0242770
[Epoch 36; Iter   335/ 1097] train: loss: 0.0177443
[Epoch 36; Iter   365/ 1097] train: loss: 0.0223592
[Epoch 36; Iter   395/ 1097] train: loss: 0.0005674
[Epoch 36; Iter   425/ 1097] train: loss: 0.0004279
[Epoch 36; Iter   455/ 1097] train: loss: 0.0054406
[Epoch 36; Iter   485/ 1097] train: loss: 0.0641927
[Epoch 36; Iter   515/ 1097] train: loss: 0.0004921
[Epoch 36; Iter   545/ 1097] train: loss: 0.0004066
[Epoch 36; Iter   575/ 1097] train: loss: 0.0010649
[Epoch 32; Iter   523/ 1097] train: loss: 0.0014324
[Epoch 32; Iter   553/ 1097] train: loss: 0.0077468
[Epoch 32; Iter   583/ 1097] train: loss: 0.2781034
[Epoch 32; Iter   613/ 1097] train: loss: 0.0147737
[Epoch 32; Iter   643/ 1097] train: loss: 0.1670998
[Epoch 32; Iter   673/ 1097] train: loss: 0.2448850
[Epoch 32; Iter   703/ 1097] train: loss: 0.1014803
[Epoch 32; Iter   733/ 1097] train: loss: 0.0219169
[Epoch 32; Iter   763/ 1097] train: loss: 0.0153631
[Epoch 32; Iter   793/ 1097] train: loss: 0.0378904
[Epoch 32; Iter   823/ 1097] train: loss: 0.0071444
[Epoch 32; Iter   853/ 1097] train: loss: 0.0681088
[Epoch 32; Iter   883/ 1097] train: loss: 0.0168757
[Epoch 32; Iter   913/ 1097] train: loss: 0.0496449
[Epoch 32; Iter   943/ 1097] train: loss: 0.0080369
[Epoch 32; Iter   973/ 1097] train: loss: 0.0078558
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0946463
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0079607
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0056211
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0196838
[Epoch 32] ogbg-molhiv: 0.770980 val loss: 2.487874
[Epoch 32] ogbg-molhiv: 0.707190 test loss: 1.520428
[Epoch 33; Iter    26/ 1097] train: loss: 0.0797522
[Epoch 33; Iter    56/ 1097] train: loss: 0.0064690
[Epoch 33; Iter    86/ 1097] train: loss: 0.0448815
[Epoch 33; Iter   116/ 1097] train: loss: 0.0353531
[Epoch 33; Iter   146/ 1097] train: loss: 0.0034021
[Epoch 33; Iter   176/ 1097] train: loss: 0.0091115
[Epoch 33; Iter   206/ 1097] train: loss: 0.0117611
[Epoch 33; Iter   236/ 1097] train: loss: 0.0216640
[Epoch 33; Iter   266/ 1097] train: loss: 0.0076423
[Epoch 33; Iter   296/ 1097] train: loss: 0.0035081
[Epoch 33; Iter   326/ 1097] train: loss: 0.0425523
[Epoch 33; Iter   356/ 1097] train: loss: 0.0644301
[Epoch 33; Iter   386/ 1097] train: loss: 0.0113563
[Epoch 33; Iter   416/ 1097] train: loss: 0.0135013
[Epoch 33; Iter   446/ 1097] train: loss: 0.0135818
[Epoch 33; Iter   476/ 1097] train: loss: 0.0030629
[Epoch 33; Iter   506/ 1097] train: loss: 0.0124498
[Epoch 33; Iter   536/ 1097] train: loss: 0.0021873
[Epoch 33; Iter   566/ 1097] train: loss: 0.0170616
[Epoch 33; Iter   596/ 1097] train: loss: 0.0016705
[Epoch 33; Iter   626/ 1097] train: loss: 0.0012329
[Epoch 33; Iter   656/ 1097] train: loss: 0.0021841
[Epoch 33; Iter   686/ 1097] train: loss: 0.0470652
[Epoch 33; Iter   716/ 1097] train: loss: 0.2775211
[Epoch 33; Iter   746/ 1097] train: loss: 0.0174028
[Epoch 33; Iter   776/ 1097] train: loss: 0.0855003
[Epoch 33; Iter   806/ 1097] train: loss: 0.0254139
[Epoch 33; Iter   836/ 1097] train: loss: 0.0270541
[Epoch 33; Iter   866/ 1097] train: loss: 0.0110978
[Epoch 33; Iter   896/ 1097] train: loss: 0.0285722
[Epoch 33; Iter   926/ 1097] train: loss: 0.0050991
[Epoch 33; Iter   956/ 1097] train: loss: 0.0152255
[Epoch 33; Iter   986/ 1097] train: loss: 0.0177488
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0754346
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0083752
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0163047
[Epoch 33] ogbg-molhiv: 0.766939 val loss: 1.143054
[Epoch 33] ogbg-molhiv: 0.760142 test loss: 1.227405
[Epoch 34; Iter     9/ 1097] train: loss: 0.0786469
[Epoch 34; Iter    39/ 1097] train: loss: 0.0665424
[Epoch 34; Iter    69/ 1097] train: loss: 0.0060141
[Epoch 34; Iter    99/ 1097] train: loss: 0.0177248
[Epoch 34; Iter   129/ 1097] train: loss: 0.0074167
[Epoch 34; Iter   159/ 1097] train: loss: 0.0336160
[Epoch 34; Iter   189/ 1097] train: loss: 0.0080006
[Epoch 34; Iter   219/ 1097] train: loss: 0.0523090
[Epoch 34; Iter   249/ 1097] train: loss: 0.0049165
[Epoch 34; Iter   279/ 1097] train: loss: 0.0304297
[Epoch 34; Iter   309/ 1097] train: loss: 0.0022903
[Epoch 34; Iter   339/ 1097] train: loss: 0.0197497
[Epoch 34; Iter   369/ 1097] train: loss: 0.0248028
[Epoch 34; Iter   399/ 1097] train: loss: 0.0678070
[Epoch 34; Iter   429/ 1097] train: loss: 0.0029674
[Epoch 34; Iter   459/ 1097] train: loss: 0.0025954
[Epoch 34; Iter   489/ 1097] train: loss: 0.0089860
[Epoch 34; Iter   519/ 1097] train: loss: 0.0085850
[Epoch 34; Iter   549/ 1097] train: loss: 0.0024054
[Epoch 34; Iter   579/ 1097] train: loss: 0.1743901
[Epoch 34; Iter   609/ 1097] train: loss: 0.0140567
[Epoch 34; Iter   639/ 1097] train: loss: 0.0548468
[Epoch 34; Iter   669/ 1097] train: loss: 0.0505326
[Epoch 34; Iter   699/ 1097] train: loss: 0.1100404
[Epoch 34; Iter   729/ 1097] train: loss: 0.0228801
[Epoch 34; Iter   759/ 1097] train: loss: 0.0797345
[Epoch 34; Iter   789/ 1097] train: loss: 0.2100254
[Epoch 34; Iter   819/ 1097] train: loss: 0.0104657
[Epoch 34; Iter   849/ 1097] train: loss: 0.1668448
[Epoch 34; Iter   879/ 1097] train: loss: 0.0023051
[Epoch 34; Iter   909/ 1097] train: loss: 0.0040937
[Epoch 34; Iter   939/ 1097] train: loss: 0.0519966
[Epoch 34; Iter   969/ 1097] train: loss: 0.0841630
[Epoch 34; Iter   999/ 1097] train: loss: 0.1640159
[Epoch 34; Iter  1029/ 1097] train: loss: 0.4149781
[Epoch 34; Iter  1059/ 1097] train: loss: 0.2272420
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0225380
[Epoch 34] ogbg-molhiv: 0.768656 val loss: 3.710584
[Epoch 34] ogbg-molhiv: 0.701056 test loss: 2.764122
[Epoch 35; Iter    22/ 1097] train: loss: 0.0232829
[Epoch 35; Iter    52/ 1097] train: loss: 0.0251327
[Epoch 35; Iter    82/ 1097] train: loss: 0.3904304
[Epoch 35; Iter   112/ 1097] train: loss: 0.1499266
[Epoch 35; Iter   142/ 1097] train: loss: 0.0470698
[Epoch 35; Iter   172/ 1097] train: loss: 0.0891668
[Epoch 35; Iter   202/ 1097] train: loss: 0.0569598
[Epoch 35; Iter   232/ 1097] train: loss: 0.0520717
[Epoch 35; Iter   262/ 1097] train: loss: 0.1587788
[Epoch 35; Iter   292/ 1097] train: loss: 0.0125572
[Epoch 35; Iter   322/ 1097] train: loss: 0.0875907
[Epoch 35; Iter   352/ 1097] train: loss: 0.0101352
[Epoch 35; Iter   382/ 1097] train: loss: 0.0102664
[Epoch 35; Iter   412/ 1097] train: loss: 0.0377042
[Epoch 35; Iter   442/ 1097] train: loss: 0.0368923
[Epoch 35; Iter   472/ 1097] train: loss: 0.0148260
[Epoch 35; Iter   502/ 1097] train: loss: 0.0065798
[Epoch 35; Iter   532/ 1097] train: loss: 0.0268287
[Epoch 35; Iter   562/ 1097] train: loss: 0.1664054
[Epoch 35; Iter   592/ 1097] train: loss: 0.0300571
[Epoch 35; Iter   622/ 1097] train: loss: 0.0305846
[Epoch 35; Iter   652/ 1097] train: loss: 0.0218364
[Epoch 35; Iter   682/ 1097] train: loss: 0.0686752
[Epoch 35; Iter   712/ 1097] train: loss: 0.0130705
[Epoch 35; Iter   742/ 1097] train: loss: 0.0269678
[Epoch 35; Iter   772/ 1097] train: loss: 0.0150245
[Epoch 35; Iter   802/ 1097] train: loss: 0.0075340
[Epoch 35; Iter   832/ 1097] train: loss: 0.0057100
[Epoch 35; Iter   862/ 1097] train: loss: 0.0868127
[Epoch 35; Iter   892/ 1097] train: loss: 0.0330574
[Epoch 35; Iter   922/ 1097] train: loss: 0.0267578
[Epoch 35; Iter   952/ 1097] train: loss: 0.0269213
[Epoch 35; Iter   982/ 1097] train: loss: 0.0518588
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0694310
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0150703
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0111304
[Epoch 35] ogbg-molhiv: 0.792300 val loss: 0.376273
[Epoch 35] ogbg-molhiv: 0.691336 test loss: 0.318835
[Epoch 36; Iter     5/ 1097] train: loss: 0.0345704
[Epoch 36; Iter    35/ 1097] train: loss: 0.0068200
[Epoch 36; Iter    65/ 1097] train: loss: 0.0064834
[Epoch 36; Iter    95/ 1097] train: loss: 0.1295342
[Epoch 36; Iter   125/ 1097] train: loss: 0.0261256
[Epoch 36; Iter   155/ 1097] train: loss: 0.0159367
[Epoch 36; Iter   185/ 1097] train: loss: 0.0200512
[Epoch 36; Iter   215/ 1097] train: loss: 0.0147480
[Epoch 36; Iter   245/ 1097] train: loss: 0.0675082
[Epoch 36; Iter   275/ 1097] train: loss: 0.0049872
[Epoch 36; Iter   305/ 1097] train: loss: 0.0241409
[Epoch 36; Iter   335/ 1097] train: loss: 0.0214474
[Epoch 36; Iter   365/ 1097] train: loss: 0.0334271
[Epoch 36; Iter   395/ 1097] train: loss: 0.0131229
[Epoch 36; Iter   425/ 1097] train: loss: 0.0107872
[Epoch 36; Iter   455/ 1097] train: loss: 0.0062036
[Epoch 36; Iter   485/ 1097] train: loss: 0.0102753
[Epoch 36; Iter   515/ 1097] train: loss: 0.0070714
[Epoch 36; Iter   545/ 1097] train: loss: 0.0452931
[Epoch 36; Iter   575/ 1097] train: loss: 0.0133813
[Epoch 28; Iter   441/ 1097] train: loss: 0.0213917
[Epoch 28; Iter   471/ 1097] train: loss: 0.0444239
[Epoch 28; Iter   501/ 1097] train: loss: 0.0362997
[Epoch 28; Iter   531/ 1097] train: loss: 0.1878610
[Epoch 28; Iter   561/ 1097] train: loss: 0.0258367
[Epoch 28; Iter   591/ 1097] train: loss: 0.1934286
[Epoch 28; Iter   621/ 1097] train: loss: 0.1322628
[Epoch 28; Iter   651/ 1097] train: loss: 0.1653231
[Epoch 28; Iter   681/ 1097] train: loss: 0.0377108
[Epoch 28; Iter   711/ 1097] train: loss: 0.0376546
[Epoch 28; Iter   741/ 1097] train: loss: 0.1789754
[Epoch 28; Iter   771/ 1097] train: loss: 0.0504305
[Epoch 28; Iter   801/ 1097] train: loss: 0.2021610
[Epoch 28; Iter   831/ 1097] train: loss: 0.0571156
[Epoch 28; Iter   861/ 1097] train: loss: 0.0509693
[Epoch 28; Iter   891/ 1097] train: loss: 0.3363863
[Epoch 28; Iter   921/ 1097] train: loss: 0.1384306
[Epoch 28; Iter   951/ 1097] train: loss: 0.0182004
[Epoch 28; Iter   981/ 1097] train: loss: 0.0214104
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0212406
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1962489
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1914599
[Epoch 28] ogbg-molhiv: 0.824815 val loss: 0.075292
[Epoch 28] ogbg-molhiv: 0.767738 test loss: 0.122419
[Epoch 29; Iter     4/ 1097] train: loss: 0.0402652
[Epoch 29; Iter    34/ 1097] train: loss: 0.0225835
[Epoch 29; Iter    64/ 1097] train: loss: 0.4598188
[Epoch 29; Iter    94/ 1097] train: loss: 0.0259914
[Epoch 29; Iter   124/ 1097] train: loss: 0.0437659
[Epoch 29; Iter   154/ 1097] train: loss: 0.2077233
[Epoch 29; Iter   184/ 1097] train: loss: 0.1921328
[Epoch 29; Iter   214/ 1097] train: loss: 0.1708673
[Epoch 29; Iter   244/ 1097] train: loss: 0.0160036
[Epoch 29; Iter   274/ 1097] train: loss: 0.0434383
[Epoch 29; Iter   304/ 1097] train: loss: 0.0243698
[Epoch 29; Iter   334/ 1097] train: loss: 0.0192013
[Epoch 29; Iter   364/ 1097] train: loss: 0.0482502
[Epoch 29; Iter   394/ 1097] train: loss: 0.0228342
[Epoch 29; Iter   424/ 1097] train: loss: 0.0452668
[Epoch 29; Iter   454/ 1097] train: loss: 0.0261533
[Epoch 29; Iter   484/ 1097] train: loss: 0.0265300
[Epoch 29; Iter   514/ 1097] train: loss: 0.2335619
[Epoch 29; Iter   544/ 1097] train: loss: 0.0444766
[Epoch 29; Iter   574/ 1097] train: loss: 0.0131476
[Epoch 29; Iter   604/ 1097] train: loss: 0.0443203
[Epoch 29; Iter   634/ 1097] train: loss: 0.0173171
[Epoch 29; Iter   664/ 1097] train: loss: 0.0130158
[Epoch 29; Iter   694/ 1097] train: loss: 0.1752022
[Epoch 29; Iter   724/ 1097] train: loss: 0.0259320
[Epoch 29; Iter   754/ 1097] train: loss: 0.0163493
[Epoch 29; Iter   784/ 1097] train: loss: 0.0655678
[Epoch 29; Iter   814/ 1097] train: loss: 0.1343752
[Epoch 29; Iter   844/ 1097] train: loss: 0.0396446
[Epoch 29; Iter   874/ 1097] train: loss: 0.0306584
[Epoch 29; Iter   904/ 1097] train: loss: 0.0424276
[Epoch 29; Iter   934/ 1097] train: loss: 0.0184778
[Epoch 29; Iter   964/ 1097] train: loss: 0.0217811
[Epoch 29; Iter   994/ 1097] train: loss: 0.1343291
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0223454
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1425675
[Epoch 29; Iter  1084/ 1097] train: loss: 0.2072457
[Epoch 29] ogbg-molhiv: 0.811465 val loss: 0.135868
[Epoch 29] ogbg-molhiv: 0.778142 test loss: 0.134743
[Epoch 30; Iter    17/ 1097] train: loss: 0.1915673
[Epoch 30; Iter    47/ 1097] train: loss: 0.0439117
[Epoch 30; Iter    77/ 1097] train: loss: 0.0082855
[Epoch 30; Iter   107/ 1097] train: loss: 0.1037086
[Epoch 30; Iter   137/ 1097] train: loss: 0.0344947
[Epoch 30; Iter   167/ 1097] train: loss: 0.2458523
[Epoch 30; Iter   197/ 1097] train: loss: 0.0214468
[Epoch 30; Iter   227/ 1097] train: loss: 0.0233903
[Epoch 30; Iter   257/ 1097] train: loss: 0.0898296
[Epoch 30; Iter   287/ 1097] train: loss: 0.0983436
[Epoch 30; Iter   317/ 1097] train: loss: 0.1108136
[Epoch 30; Iter   347/ 1097] train: loss: 0.0177002
[Epoch 30; Iter   377/ 1097] train: loss: 0.1245918
[Epoch 30; Iter   407/ 1097] train: loss: 0.0183360
[Epoch 30; Iter   437/ 1097] train: loss: 0.1213224
[Epoch 30; Iter   467/ 1097] train: loss: 0.0285151
[Epoch 30; Iter   497/ 1097] train: loss: 0.1000127
[Epoch 30; Iter   527/ 1097] train: loss: 0.2299844
[Epoch 30; Iter   557/ 1097] train: loss: 0.1150927
[Epoch 30; Iter   587/ 1097] train: loss: 0.0985300
[Epoch 30; Iter   617/ 1097] train: loss: 0.0221488
[Epoch 30; Iter   647/ 1097] train: loss: 0.0435428
[Epoch 30; Iter   677/ 1097] train: loss: 0.1008922
[Epoch 30; Iter   707/ 1097] train: loss: 0.0206740
[Epoch 30; Iter   737/ 1097] train: loss: 0.0121369
[Epoch 30; Iter   767/ 1097] train: loss: 0.0251083
[Epoch 30; Iter   797/ 1097] train: loss: 0.0421919
[Epoch 30; Iter   827/ 1097] train: loss: 0.0790414
[Epoch 30; Iter   857/ 1097] train: loss: 0.0738518
[Epoch 30; Iter   887/ 1097] train: loss: 0.0692733
[Epoch 30; Iter   917/ 1097] train: loss: 0.1144152
[Epoch 30; Iter   947/ 1097] train: loss: 0.0914000
[Epoch 30; Iter   977/ 1097] train: loss: 0.1420116
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0127674
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0787480
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0490449
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0355552
[Epoch 30] ogbg-molhiv: 0.806538 val loss: 0.077846
[Epoch 30] ogbg-molhiv: 0.779521 test loss: 0.132762
[Epoch 31; Iter    30/ 1097] train: loss: 0.0297448
[Epoch 31; Iter    60/ 1097] train: loss: 0.2445378
[Epoch 31; Iter    90/ 1097] train: loss: 0.0327127
[Epoch 31; Iter   120/ 1097] train: loss: 0.0140009
[Epoch 31; Iter   150/ 1097] train: loss: 0.0726227
[Epoch 31; Iter   180/ 1097] train: loss: 0.0509645
[Epoch 31; Iter   210/ 1097] train: loss: 0.1412545
[Epoch 31; Iter   240/ 1097] train: loss: 0.1845528
[Epoch 31; Iter   270/ 1097] train: loss: 0.0675739
[Epoch 31; Iter   300/ 1097] train: loss: 0.0228617
[Epoch 31; Iter   330/ 1097] train: loss: 0.0221073
[Epoch 31; Iter   360/ 1097] train: loss: 0.0246218
[Epoch 31; Iter   390/ 1097] train: loss: 0.0505868
[Epoch 31; Iter   420/ 1097] train: loss: 0.0221758
[Epoch 31; Iter   450/ 1097] train: loss: 0.0144646
[Epoch 31; Iter   480/ 1097] train: loss: 0.0516788
[Epoch 31; Iter   510/ 1097] train: loss: 0.0132633
[Epoch 31; Iter   540/ 1097] train: loss: 0.1132108
[Epoch 31; Iter   570/ 1097] train: loss: 0.0279433
[Epoch 31; Iter   600/ 1097] train: loss: 0.0384532
[Epoch 31; Iter   630/ 1097] train: loss: 0.2412226
[Epoch 31; Iter   660/ 1097] train: loss: 0.0234015
[Epoch 31; Iter   690/ 1097] train: loss: 0.1595355
[Epoch 31; Iter   720/ 1097] train: loss: 0.1310083
[Epoch 31; Iter   750/ 1097] train: loss: 0.1444689
[Epoch 31; Iter   780/ 1097] train: loss: 0.0196637
[Epoch 31; Iter   810/ 1097] train: loss: 0.0268222
[Epoch 31; Iter   840/ 1097] train: loss: 0.0209890
[Epoch 31; Iter   870/ 1097] train: loss: 0.0166538
[Epoch 31; Iter   900/ 1097] train: loss: 0.1739280
[Epoch 31; Iter   930/ 1097] train: loss: 0.0738765
[Epoch 31; Iter   960/ 1097] train: loss: 0.1353108
[Epoch 31; Iter   990/ 1097] train: loss: 0.0242887
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0665805
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0394676
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0411540
[Epoch 31] ogbg-molhiv: 0.823471 val loss: 0.094980
[Epoch 31] ogbg-molhiv: 0.762143 test loss: 0.134714
[Epoch 32; Iter    13/ 1097] train: loss: 0.5384453
[Epoch 32; Iter    43/ 1097] train: loss: 0.0458607
[Epoch 32; Iter    73/ 1097] train: loss: 0.0117075
[Epoch 32; Iter   103/ 1097] train: loss: 0.0250164
[Epoch 32; Iter   133/ 1097] train: loss: 0.0142481
[Epoch 32; Iter   163/ 1097] train: loss: 0.0459714
[Epoch 32; Iter   193/ 1097] train: loss: 0.0121843
[Epoch 32; Iter   223/ 1097] train: loss: 0.0678030
[Epoch 32; Iter   253/ 1097] train: loss: 0.0167902
[Epoch 32; Iter   283/ 1097] train: loss: 0.0221572
[Epoch 32; Iter   313/ 1097] train: loss: 0.0209097
[Epoch 32; Iter   343/ 1097] train: loss: 0.0605358
[Epoch 32; Iter   373/ 1097] train: loss: 0.0110772
[Epoch 32; Iter   403/ 1097] train: loss: 0.1787317
[Epoch 32; Iter   433/ 1097] train: loss: 0.0443315
[Epoch 32; Iter   463/ 1097] train: loss: 0.0187714
[Epoch 32; Iter   493/ 1097] train: loss: 0.0588614
[Epoch 32; Iter   523/ 1097] train: loss: 0.0055920
[Epoch 32; Iter   553/ 1097] train: loss: 0.0023776
[Epoch 32; Iter   583/ 1097] train: loss: 0.0008593
[Epoch 32; Iter   613/ 1097] train: loss: 0.0194973
[Epoch 32; Iter   643/ 1097] train: loss: 0.0109787
[Epoch 32; Iter   673/ 1097] train: loss: 0.0191685
[Epoch 32; Iter   703/ 1097] train: loss: 0.0020761
[Epoch 32; Iter   733/ 1097] train: loss: 0.0042585
[Epoch 32; Iter   763/ 1097] train: loss: 0.0011623
[Epoch 32; Iter   793/ 1097] train: loss: 0.0037168
[Epoch 32; Iter   823/ 1097] train: loss: 0.0039706
[Epoch 32; Iter   853/ 1097] train: loss: 0.0040260
[Epoch 32; Iter   883/ 1097] train: loss: 0.0188351
[Epoch 32; Iter   913/ 1097] train: loss: 0.0015350
[Epoch 32; Iter   943/ 1097] train: loss: 0.0432097
[Epoch 32; Iter   973/ 1097] train: loss: 0.0007219
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0058239
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0351411
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0070803
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0081693
[Epoch 32] ogbg-molhiv: 0.708658 val loss: 48.325489
[Epoch 32] ogbg-molhiv: 0.587311 test loss: 49.007475
[Epoch 33; Iter    26/ 1097] train: loss: 0.0024040
[Epoch 33; Iter    56/ 1097] train: loss: 0.0056525
[Epoch 33; Iter    86/ 1097] train: loss: 0.0073236
[Epoch 33; Iter   116/ 1097] train: loss: 0.0076648
[Epoch 33; Iter   146/ 1097] train: loss: 0.0007711
[Epoch 33; Iter   176/ 1097] train: loss: 0.0175193
[Epoch 33; Iter   206/ 1097] train: loss: 0.0014903
[Epoch 33; Iter   236/ 1097] train: loss: 0.0013374
[Epoch 33; Iter   266/ 1097] train: loss: 0.0016395
[Epoch 33; Iter   296/ 1097] train: loss: 0.0020283
[Epoch 33; Iter   326/ 1097] train: loss: 0.0049993
[Epoch 33; Iter   356/ 1097] train: loss: 0.0018231
[Epoch 33; Iter   386/ 1097] train: loss: 0.0010819
[Epoch 33; Iter   416/ 1097] train: loss: 0.0096473
[Epoch 33; Iter   446/ 1097] train: loss: 0.0196859
[Epoch 33; Iter   476/ 1097] train: loss: 0.0033716
[Epoch 33; Iter   506/ 1097] train: loss: 0.0156025
[Epoch 33; Iter   536/ 1097] train: loss: 0.0385941
[Epoch 33; Iter   566/ 1097] train: loss: 0.0007933
[Epoch 33; Iter   596/ 1097] train: loss: 0.0018640
[Epoch 33; Iter   626/ 1097] train: loss: 0.0042201
[Epoch 33; Iter   656/ 1097] train: loss: 0.0117217
[Epoch 33; Iter   686/ 1097] train: loss: 0.0008850
[Epoch 33; Iter   716/ 1097] train: loss: 0.0977458
[Epoch 33; Iter   746/ 1097] train: loss: 0.0438813
[Epoch 33; Iter   776/ 1097] train: loss: 0.0049442
[Epoch 33; Iter   806/ 1097] train: loss: 0.0131838
[Epoch 33; Iter   836/ 1097] train: loss: 0.0105046
[Epoch 33; Iter   866/ 1097] train: loss: 0.0023282
[Epoch 33; Iter   896/ 1097] train: loss: 0.0121783
[Epoch 33; Iter   926/ 1097] train: loss: 0.0066041
[Epoch 33; Iter   956/ 1097] train: loss: 0.0010972
[Epoch 33; Iter   986/ 1097] train: loss: 0.0048690
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0015516
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0260957
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0012953
[Epoch 33] ogbg-molhiv: 0.683128 val loss: 28.753501
[Epoch 33] ogbg-molhiv: 0.586226 test loss: 30.275717
[Epoch 34; Iter     9/ 1097] train: loss: 0.0021307
[Epoch 34; Iter    39/ 1097] train: loss: 0.0003461
[Epoch 34; Iter    69/ 1097] train: loss: 0.0055513
[Epoch 34; Iter    99/ 1097] train: loss: 0.1003093
[Epoch 34; Iter   129/ 1097] train: loss: 0.0140600
[Epoch 34; Iter   159/ 1097] train: loss: 0.0010043
[Epoch 34; Iter   189/ 1097] train: loss: 0.0010789
[Epoch 34; Iter   219/ 1097] train: loss: 0.0043912
[Epoch 34; Iter   249/ 1097] train: loss: 0.0018532
[Epoch 34; Iter   279/ 1097] train: loss: 0.0780023
[Epoch 34; Iter   309/ 1097] train: loss: 0.0030843
[Epoch 34; Iter   339/ 1097] train: loss: 0.0146636
[Epoch 34; Iter   369/ 1097] train: loss: 0.0213411
[Epoch 34; Iter   399/ 1097] train: loss: 0.0005200
[Epoch 34; Iter   429/ 1097] train: loss: 0.0019664
[Epoch 34; Iter   459/ 1097] train: loss: 0.0513293
[Epoch 34; Iter   489/ 1097] train: loss: 0.0121878
[Epoch 34; Iter   519/ 1097] train: loss: 0.0081680
[Epoch 34; Iter   549/ 1097] train: loss: 0.0047060
[Epoch 34; Iter   579/ 1097] train: loss: 0.0024793
[Epoch 34; Iter   609/ 1097] train: loss: 0.0002547
[Epoch 34; Iter   639/ 1097] train: loss: 0.0050123
[Epoch 34; Iter   669/ 1097] train: loss: 0.0006202
[Epoch 34; Iter   699/ 1097] train: loss: 0.0118890
[Epoch 34; Iter   729/ 1097] train: loss: 0.0042724
[Epoch 34; Iter   759/ 1097] train: loss: 0.0012659
[Epoch 34; Iter   789/ 1097] train: loss: 0.0441430
[Epoch 34; Iter   819/ 1097] train: loss: 0.0027689
[Epoch 34; Iter   849/ 1097] train: loss: 0.0065813
[Epoch 34; Iter   879/ 1097] train: loss: 0.0019435
[Epoch 34; Iter   909/ 1097] train: loss: 0.0619226
[Epoch 34; Iter   939/ 1097] train: loss: 0.0191882
[Epoch 34; Iter   969/ 1097] train: loss: 0.1059206
[Epoch 34; Iter   999/ 1097] train: loss: 0.0196177
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0418047
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0008217
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0045218
[Epoch 34] ogbg-molhiv: 0.697185 val loss: 35.597845
[Epoch 34] ogbg-molhiv: 0.621366 test loss: 36.057105
[Epoch 35; Iter    22/ 1097] train: loss: 0.0006502
[Epoch 35; Iter    52/ 1097] train: loss: 0.0008222
[Epoch 35; Iter    82/ 1097] train: loss: 0.0072289
[Epoch 35; Iter   112/ 1097] train: loss: 0.0023177
[Epoch 35; Iter   142/ 1097] train: loss: 0.0029273
[Epoch 35; Iter   172/ 1097] train: loss: 0.0078332
[Epoch 35; Iter   202/ 1097] train: loss: 0.0502521
[Epoch 35; Iter   232/ 1097] train: loss: 0.0435733
[Epoch 35; Iter   262/ 1097] train: loss: 0.0036071
[Epoch 35; Iter   292/ 1097] train: loss: 0.0010337
[Epoch 35; Iter   322/ 1097] train: loss: 0.0009311
[Epoch 35; Iter   352/ 1097] train: loss: 0.0007117
[Epoch 35; Iter   382/ 1097] train: loss: 0.0144864
[Epoch 35; Iter   412/ 1097] train: loss: 0.0034609
[Epoch 35; Iter   442/ 1097] train: loss: 0.0009141
[Epoch 35; Iter   472/ 1097] train: loss: 0.0067196
[Epoch 35; Iter   502/ 1097] train: loss: 0.0088203
[Epoch 35; Iter   532/ 1097] train: loss: 0.0047598
[Epoch 35; Iter   562/ 1097] train: loss: 0.0018169
[Epoch 35; Iter   592/ 1097] train: loss: 0.0072137
[Epoch 35; Iter   622/ 1097] train: loss: 0.0323903
[Epoch 35; Iter   652/ 1097] train: loss: 0.0011217
[Epoch 35; Iter   682/ 1097] train: loss: 0.0046657
[Epoch 35; Iter   712/ 1097] train: loss: 0.0001008
[Epoch 35; Iter   742/ 1097] train: loss: 0.0292721
[Epoch 35; Iter   772/ 1097] train: loss: 0.0028453
[Epoch 35; Iter   802/ 1097] train: loss: 0.0448810
[Epoch 35; Iter   832/ 1097] train: loss: 0.0008478
[Epoch 35; Iter   862/ 1097] train: loss: 0.0015269
[Epoch 35; Iter   892/ 1097] train: loss: 0.0172291
[Epoch 35; Iter   922/ 1097] train: loss: 0.0583095
[Epoch 35; Iter   952/ 1097] train: loss: 0.0006823
[Epoch 35; Iter   982/ 1097] train: loss: 0.0131953
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0005818
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0126499
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0031262
[Epoch 35] ogbg-molhiv: 0.720103 val loss: 52.864373
[Epoch 35] ogbg-molhiv: 0.610045 test loss: 52.008139
[Epoch 36; Iter     5/ 1097] train: loss: 0.0001661
[Epoch 36; Iter    35/ 1097] train: loss: 0.0011716
[Epoch 36; Iter    65/ 1097] train: loss: 0.0029551
[Epoch 36; Iter    95/ 1097] train: loss: 0.0160857
[Epoch 36; Iter   125/ 1097] train: loss: 0.0031801
[Epoch 36; Iter   155/ 1097] train: loss: 0.0008426
[Epoch 36; Iter   185/ 1097] train: loss: 0.0030783
[Epoch 36; Iter   215/ 1097] train: loss: 0.0292072
[Epoch 36; Iter   245/ 1097] train: loss: 0.0343408
[Epoch 36; Iter   275/ 1097] train: loss: 0.0107475
[Epoch 36; Iter   305/ 1097] train: loss: 0.0235311
[Epoch 36; Iter   335/ 1097] train: loss: 0.0011091
[Epoch 36; Iter   365/ 1097] train: loss: 0.0010424
[Epoch 36; Iter   395/ 1097] train: loss: 0.0093131
[Epoch 36; Iter   425/ 1097] train: loss: 0.0191794
[Epoch 36; Iter   455/ 1097] train: loss: 0.0441858
[Epoch 36; Iter   485/ 1097] train: loss: 0.0023603
[Epoch 36; Iter   515/ 1097] train: loss: 0.0019792
[Epoch 36; Iter   545/ 1097] train: loss: 0.0010919
[Epoch 36; Iter   575/ 1097] train: loss: 0.0001845
[Epoch 28; Iter   441/ 1097] train: loss: 0.0876640
[Epoch 28; Iter   471/ 1097] train: loss: 0.1951815
[Epoch 28; Iter   501/ 1097] train: loss: 0.0428718
[Epoch 28; Iter   531/ 1097] train: loss: 0.0250110
[Epoch 28; Iter   561/ 1097] train: loss: 0.1342479
[Epoch 28; Iter   591/ 1097] train: loss: 0.0669866
[Epoch 28; Iter   621/ 1097] train: loss: 0.0226419
[Epoch 28; Iter   651/ 1097] train: loss: 0.0348579
[Epoch 28; Iter   681/ 1097] train: loss: 0.0737139
[Epoch 28; Iter   711/ 1097] train: loss: 0.0386886
[Epoch 28; Iter   741/ 1097] train: loss: 0.0446690
[Epoch 28; Iter   771/ 1097] train: loss: 0.0882592
[Epoch 28; Iter   801/ 1097] train: loss: 0.0158286
[Epoch 28; Iter   831/ 1097] train: loss: 0.1427151
[Epoch 28; Iter   861/ 1097] train: loss: 0.0173117
[Epoch 28; Iter   891/ 1097] train: loss: 0.0209858
[Epoch 28; Iter   921/ 1097] train: loss: 0.0416991
[Epoch 28; Iter   951/ 1097] train: loss: 0.0148027
[Epoch 28; Iter   981/ 1097] train: loss: 0.0994945
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0186490
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0322250
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0251555
[Epoch 28] ogbg-molhiv: 0.846855 val loss: 0.066375
[Epoch 28] ogbg-molhiv: 0.739190 test loss: 0.120021
[Epoch 29; Iter     4/ 1097] train: loss: 0.0270796
[Epoch 29; Iter    34/ 1097] train: loss: 0.1965236
[Epoch 29; Iter    64/ 1097] train: loss: 0.1030262
[Epoch 29; Iter    94/ 1097] train: loss: 0.0611280
[Epoch 29; Iter   124/ 1097] train: loss: 0.1177359
[Epoch 29; Iter   154/ 1097] train: loss: 0.0235236
[Epoch 29; Iter   184/ 1097] train: loss: 0.0191434
[Epoch 29; Iter   214/ 1097] train: loss: 0.0597557
[Epoch 29; Iter   244/ 1097] train: loss: 0.1784339
[Epoch 29; Iter   274/ 1097] train: loss: 0.0164387
[Epoch 29; Iter   304/ 1097] train: loss: 0.0207565
[Epoch 29; Iter   334/ 1097] train: loss: 0.2519578
[Epoch 29; Iter   364/ 1097] train: loss: 0.0246000
[Epoch 29; Iter   394/ 1097] train: loss: 0.2833491
[Epoch 29; Iter   424/ 1097] train: loss: 0.0369335
[Epoch 29; Iter   454/ 1097] train: loss: 0.0858937
[Epoch 29; Iter   484/ 1097] train: loss: 0.0219715
[Epoch 29; Iter   514/ 1097] train: loss: 0.0360282
[Epoch 29; Iter   544/ 1097] train: loss: 0.0303916
[Epoch 29; Iter   574/ 1097] train: loss: 0.0293411
[Epoch 29; Iter   604/ 1097] train: loss: 0.0536940
[Epoch 29; Iter   634/ 1097] train: loss: 0.1312654
[Epoch 29; Iter   664/ 1097] train: loss: 0.0359138
[Epoch 29; Iter   694/ 1097] train: loss: 0.3453844
[Epoch 29; Iter   724/ 1097] train: loss: 0.0369559
[Epoch 29; Iter   754/ 1097] train: loss: 0.0200854
[Epoch 29; Iter   784/ 1097] train: loss: 0.0307926
[Epoch 29; Iter   814/ 1097] train: loss: 0.0310480
[Epoch 29; Iter   844/ 1097] train: loss: 0.1531276
[Epoch 29; Iter   874/ 1097] train: loss: 0.0244771
[Epoch 29; Iter   904/ 1097] train: loss: 0.0574696
[Epoch 29; Iter   934/ 1097] train: loss: 0.0784035
[Epoch 29; Iter   964/ 1097] train: loss: 0.0282942
[Epoch 29; Iter   994/ 1097] train: loss: 0.2594960
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0239611
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0218924
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1024200
[Epoch 29] ogbg-molhiv: 0.818979 val loss: 0.093791
[Epoch 29] ogbg-molhiv: 0.720329 test loss: 0.133710
[Epoch 30; Iter    17/ 1097] train: loss: 0.0281436
[Epoch 30; Iter    47/ 1097] train: loss: 0.0304530
[Epoch 30; Iter    77/ 1097] train: loss: 0.1695820
[Epoch 30; Iter   107/ 1097] train: loss: 0.0423382
[Epoch 30; Iter   137/ 1097] train: loss: 0.0451296
[Epoch 30; Iter   167/ 1097] train: loss: 0.0167772
[Epoch 30; Iter   197/ 1097] train: loss: 0.0917595
[Epoch 30; Iter   227/ 1097] train: loss: 0.0214488
[Epoch 30; Iter   257/ 1097] train: loss: 0.0158495
[Epoch 30; Iter   287/ 1097] train: loss: 0.0203757
[Epoch 30; Iter   317/ 1097] train: loss: 0.1838409
[Epoch 30; Iter   347/ 1097] train: loss: 0.0377469
[Epoch 30; Iter   377/ 1097] train: loss: 0.0235367
[Epoch 30; Iter   407/ 1097] train: loss: 0.0828976
[Epoch 30; Iter   437/ 1097] train: loss: 0.1733612
[Epoch 30; Iter   467/ 1097] train: loss: 0.0147525
[Epoch 30; Iter   497/ 1097] train: loss: 0.1115046
[Epoch 30; Iter   527/ 1097] train: loss: 0.0505280
[Epoch 30; Iter   557/ 1097] train: loss: 0.0755387
[Epoch 30; Iter   587/ 1097] train: loss: 0.0149357
[Epoch 30; Iter   617/ 1097] train: loss: 0.1806514
[Epoch 30; Iter   647/ 1097] train: loss: 0.0540825
[Epoch 30; Iter   677/ 1097] train: loss: 0.0252918
[Epoch 30; Iter   707/ 1097] train: loss: 0.1027405
[Epoch 30; Iter   737/ 1097] train: loss: 0.0191948
[Epoch 30; Iter   767/ 1097] train: loss: 0.0404319
[Epoch 30; Iter   797/ 1097] train: loss: 0.0527067
[Epoch 30; Iter   827/ 1097] train: loss: 0.1263796
[Epoch 30; Iter   857/ 1097] train: loss: 0.0257808
[Epoch 30; Iter   887/ 1097] train: loss: 0.0451494
[Epoch 30; Iter   917/ 1097] train: loss: 0.1411890
[Epoch 30; Iter   947/ 1097] train: loss: 0.0444672
[Epoch 30; Iter   977/ 1097] train: loss: 0.1425837
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0265037
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0704293
[Epoch 30; Iter  1067/ 1097] train: loss: 0.1505183
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0175828
[Epoch 30] ogbg-molhiv: 0.828205 val loss: 0.078155
[Epoch 30] ogbg-molhiv: 0.745802 test loss: 0.126828
[Epoch 31; Iter    30/ 1097] train: loss: 0.0562927
[Epoch 31; Iter    60/ 1097] train: loss: 0.1446920
[Epoch 31; Iter    90/ 1097] train: loss: 0.0346633
[Epoch 31; Iter   120/ 1097] train: loss: 0.0351026
[Epoch 31; Iter   150/ 1097] train: loss: 0.1257112
[Epoch 31; Iter   180/ 1097] train: loss: 0.0316216
[Epoch 31; Iter   210/ 1097] train: loss: 0.0853569
[Epoch 31; Iter   240/ 1097] train: loss: 0.0163439
[Epoch 31; Iter   270/ 1097] train: loss: 0.0872102
[Epoch 31; Iter   300/ 1097] train: loss: 0.0275867
[Epoch 31; Iter   330/ 1097] train: loss: 0.0824042
[Epoch 31; Iter   360/ 1097] train: loss: 0.0752013
[Epoch 31; Iter   390/ 1097] train: loss: 0.1043075
[Epoch 31; Iter   420/ 1097] train: loss: 0.0191708
[Epoch 31; Iter   450/ 1097] train: loss: 0.0487443
[Epoch 31; Iter   480/ 1097] train: loss: 0.0760821
[Epoch 31; Iter   510/ 1097] train: loss: 0.0151243
[Epoch 31; Iter   540/ 1097] train: loss: 0.0299938
[Epoch 31; Iter   570/ 1097] train: loss: 0.1466716
[Epoch 31; Iter   600/ 1097] train: loss: 0.0131079
[Epoch 31; Iter   630/ 1097] train: loss: 0.0580649
[Epoch 31; Iter   660/ 1097] train: loss: 0.1313187
[Epoch 31; Iter   690/ 1097] train: loss: 0.0399543
[Epoch 31; Iter   720/ 1097] train: loss: 0.0098663
[Epoch 31; Iter   750/ 1097] train: loss: 0.0618516
[Epoch 31; Iter   780/ 1097] train: loss: 0.0608430
[Epoch 31; Iter   810/ 1097] train: loss: 0.0289161
[Epoch 31; Iter   840/ 1097] train: loss: 0.0351939
[Epoch 31; Iter   870/ 1097] train: loss: 0.0707711
[Epoch 31; Iter   900/ 1097] train: loss: 0.0310262
[Epoch 31; Iter   930/ 1097] train: loss: 0.1553972
[Epoch 31; Iter   960/ 1097] train: loss: 0.0300567
[Epoch 31; Iter   990/ 1097] train: loss: 0.0362608
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0442579
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0249842
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2501367
[Epoch 31] ogbg-molhiv: 0.824500 val loss: 0.115633
[Epoch 31] ogbg-molhiv: 0.733848 test loss: 0.127506
[Epoch 32; Iter    13/ 1097] train: loss: 0.0828014
[Epoch 32; Iter    43/ 1097] train: loss: 0.2763551
[Epoch 32; Iter    73/ 1097] train: loss: 0.0943803
[Epoch 32; Iter   103/ 1097] train: loss: 0.0236457
[Epoch 32; Iter   133/ 1097] train: loss: 0.0161299
[Epoch 32; Iter   163/ 1097] train: loss: 0.0407244
[Epoch 32; Iter   193/ 1097] train: loss: 0.0427799
[Epoch 32; Iter   223/ 1097] train: loss: 0.0116697
[Epoch 32; Iter   253/ 1097] train: loss: 0.0467269
[Epoch 32; Iter   283/ 1097] train: loss: 0.0403511
[Epoch 32; Iter   313/ 1097] train: loss: 0.2755249
[Epoch 32; Iter   343/ 1097] train: loss: 0.0501366
[Epoch 32; Iter   373/ 1097] train: loss: 0.1110472
[Epoch 32; Iter   403/ 1097] train: loss: 0.0653386
[Epoch 32; Iter   433/ 1097] train: loss: 0.0193605
[Epoch 32; Iter   463/ 1097] train: loss: 0.2230724
[Epoch 32; Iter   493/ 1097] train: loss: 0.0172877
[Epoch 28; Iter   441/ 1097] train: loss: 0.7203079
[Epoch 28; Iter   471/ 1097] train: loss: 0.0355920
[Epoch 28; Iter   501/ 1097] train: loss: 0.1869803
[Epoch 28; Iter   531/ 1097] train: loss: 0.0244421
[Epoch 28; Iter   561/ 1097] train: loss: 0.1158800
[Epoch 28; Iter   591/ 1097] train: loss: 0.2447335
[Epoch 28; Iter   621/ 1097] train: loss: 0.1300695
[Epoch 28; Iter   651/ 1097] train: loss: 0.0254077
[Epoch 28; Iter   681/ 1097] train: loss: 0.0335568
[Epoch 28; Iter   711/ 1097] train: loss: 0.0530235
[Epoch 28; Iter   741/ 1097] train: loss: 0.0206735
[Epoch 28; Iter   771/ 1097] train: loss: 0.0777640
[Epoch 28; Iter   801/ 1097] train: loss: 0.0159285
[Epoch 28; Iter   831/ 1097] train: loss: 0.0477733
[Epoch 28; Iter   861/ 1097] train: loss: 0.2362985
[Epoch 28; Iter   891/ 1097] train: loss: 0.0789910
[Epoch 28; Iter   921/ 1097] train: loss: 0.0448591
[Epoch 28; Iter   951/ 1097] train: loss: 0.1109227
[Epoch 28; Iter   981/ 1097] train: loss: 0.0250921
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0158026
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0340642
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0263023
[Epoch 28] ogbg-molhiv: 0.836729 val loss: 0.107699
[Epoch 28] ogbg-molhiv: 0.779073 test loss: 0.113976
[Epoch 29; Iter     4/ 1097] train: loss: 0.0178918
[Epoch 29; Iter    34/ 1097] train: loss: 0.0608997
[Epoch 29; Iter    64/ 1097] train: loss: 0.0529034
[Epoch 29; Iter    94/ 1097] train: loss: 0.0553869
[Epoch 29; Iter   124/ 1097] train: loss: 0.1722313
[Epoch 29; Iter   154/ 1097] train: loss: 0.1702348
[Epoch 29; Iter   184/ 1097] train: loss: 0.0220811
[Epoch 29; Iter   214/ 1097] train: loss: 0.0145775
[Epoch 29; Iter   244/ 1097] train: loss: 0.0671558
[Epoch 29; Iter   274/ 1097] train: loss: 0.0199010
[Epoch 29; Iter   304/ 1097] train: loss: 0.1650157
[Epoch 29; Iter   334/ 1097] train: loss: 0.0599725
[Epoch 29; Iter   364/ 1097] train: loss: 0.0436025
[Epoch 29; Iter   394/ 1097] train: loss: 0.1068016
[Epoch 29; Iter   424/ 1097] train: loss: 0.0535335
[Epoch 29; Iter   454/ 1097] train: loss: 0.0711285
[Epoch 29; Iter   484/ 1097] train: loss: 0.0865559
[Epoch 29; Iter   514/ 1097] train: loss: 0.0566075
[Epoch 29; Iter   544/ 1097] train: loss: 0.0306416
[Epoch 29; Iter   574/ 1097] train: loss: 0.0333851
[Epoch 29; Iter   604/ 1097] train: loss: 0.1647497
[Epoch 29; Iter   634/ 1097] train: loss: 0.2665044
[Epoch 29; Iter   664/ 1097] train: loss: 0.0173186
[Epoch 29; Iter   694/ 1097] train: loss: 0.0507527
[Epoch 29; Iter   724/ 1097] train: loss: 0.0325778
[Epoch 29; Iter   754/ 1097] train: loss: 0.0647938
[Epoch 29; Iter   784/ 1097] train: loss: 0.0661759
[Epoch 29; Iter   814/ 1097] train: loss: 0.0255422
[Epoch 29; Iter   844/ 1097] train: loss: 0.0670280
[Epoch 29; Iter   874/ 1097] train: loss: 0.3227068
[Epoch 29; Iter   904/ 1097] train: loss: 0.0128257
[Epoch 29; Iter   934/ 1097] train: loss: 0.3163404
[Epoch 29; Iter   964/ 1097] train: loss: 0.0381013
[Epoch 29; Iter   994/ 1097] train: loss: 0.1260441
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0227239
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0407230
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0155404
[Epoch 29] ogbg-molhiv: 0.816578 val loss: 0.072751
[Epoch 29] ogbg-molhiv: 0.755443 test loss: 0.117237
[Epoch 30; Iter    17/ 1097] train: loss: 0.0351327
[Epoch 30; Iter    47/ 1097] train: loss: 0.1625094
[Epoch 30; Iter    77/ 1097] train: loss: 0.1328753
[Epoch 30; Iter   107/ 1097] train: loss: 0.0787084
[Epoch 30; Iter   137/ 1097] train: loss: 0.2206901
[Epoch 30; Iter   167/ 1097] train: loss: 0.0293256
[Epoch 30; Iter   197/ 1097] train: loss: 0.0332193
[Epoch 30; Iter   227/ 1097] train: loss: 0.0648400
[Epoch 30; Iter   257/ 1097] train: loss: 0.0919620
[Epoch 30; Iter   287/ 1097] train: loss: 0.0333089
[Epoch 30; Iter   317/ 1097] train: loss: 0.1147797
[Epoch 30; Iter   347/ 1097] train: loss: 0.1739240
[Epoch 30; Iter   377/ 1097] train: loss: 0.1203668
[Epoch 30; Iter   407/ 1097] train: loss: 0.0946868
[Epoch 30; Iter   437/ 1097] train: loss: 0.0731658
[Epoch 30; Iter   467/ 1097] train: loss: 0.0182873
[Epoch 30; Iter   497/ 1097] train: loss: 0.0946228
[Epoch 30; Iter   527/ 1097] train: loss: 0.1623688
[Epoch 30; Iter   557/ 1097] train: loss: 0.1587319
[Epoch 30; Iter   587/ 1097] train: loss: 0.0305025
[Epoch 30; Iter   617/ 1097] train: loss: 0.0282738
[Epoch 30; Iter   647/ 1097] train: loss: 0.0172095
[Epoch 30; Iter   677/ 1097] train: loss: 0.2229514
[Epoch 30; Iter   707/ 1097] train: loss: 0.1651538
[Epoch 30; Iter   737/ 1097] train: loss: 0.0657386
[Epoch 30; Iter   767/ 1097] train: loss: 0.2230405
[Epoch 30; Iter   797/ 1097] train: loss: 0.2327857
[Epoch 30; Iter   827/ 1097] train: loss: 0.3866867
[Epoch 30; Iter   857/ 1097] train: loss: 0.1627179
[Epoch 30; Iter   887/ 1097] train: loss: 0.0371274
[Epoch 30; Iter   917/ 1097] train: loss: 0.1255530
[Epoch 30; Iter   947/ 1097] train: loss: 0.0477637
[Epoch 30; Iter   977/ 1097] train: loss: 0.0245399
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0905554
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0686682
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0292418
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0315702
[Epoch 30] ogbg-molhiv: 0.830694 val loss: 0.111097
[Epoch 30] ogbg-molhiv: 0.761618 test loss: 0.132261
[Epoch 31; Iter    30/ 1097] train: loss: 0.1082062
[Epoch 31; Iter    60/ 1097] train: loss: 0.1620500
[Epoch 31; Iter    90/ 1097] train: loss: 0.0314668
[Epoch 31; Iter   120/ 1097] train: loss: 0.0519476
[Epoch 31; Iter   150/ 1097] train: loss: 0.2663450
[Epoch 31; Iter   180/ 1097] train: loss: 0.0312511
[Epoch 31; Iter   210/ 1097] train: loss: 0.0134788
[Epoch 31; Iter   240/ 1097] train: loss: 0.0606187
[Epoch 31; Iter   270/ 1097] train: loss: 0.1346370
[Epoch 31; Iter   300/ 1097] train: loss: 0.0982065
[Epoch 31; Iter   330/ 1097] train: loss: 0.1283832
[Epoch 31; Iter   360/ 1097] train: loss: 0.0946155
[Epoch 31; Iter   390/ 1097] train: loss: 0.0680305
[Epoch 31; Iter   420/ 1097] train: loss: 0.1760823
[Epoch 31; Iter   450/ 1097] train: loss: 0.0298165
[Epoch 31; Iter   480/ 1097] train: loss: 0.1839202
[Epoch 31; Iter   510/ 1097] train: loss: 0.0250398
[Epoch 31; Iter   540/ 1097] train: loss: 0.1066803
[Epoch 31; Iter   570/ 1097] train: loss: 0.2757200
[Epoch 31; Iter   600/ 1097] train: loss: 0.0162744
[Epoch 31; Iter   630/ 1097] train: loss: 0.0358594
[Epoch 31; Iter   660/ 1097] train: loss: 0.1427034
[Epoch 31; Iter   690/ 1097] train: loss: 0.0688428
[Epoch 31; Iter   720/ 1097] train: loss: 0.0291387
[Epoch 31; Iter   750/ 1097] train: loss: 0.0132379
[Epoch 31; Iter   780/ 1097] train: loss: 0.0987265
[Epoch 31; Iter   810/ 1097] train: loss: 0.0243962
[Epoch 31; Iter   840/ 1097] train: loss: 0.1045741
[Epoch 31; Iter   870/ 1097] train: loss: 0.2162146
[Epoch 31; Iter   900/ 1097] train: loss: 0.0457273
[Epoch 31; Iter   930/ 1097] train: loss: 0.0491702
[Epoch 31; Iter   960/ 1097] train: loss: 0.0269643
[Epoch 31; Iter   990/ 1097] train: loss: 0.1862295
[Epoch 31; Iter  1020/ 1097] train: loss: 0.2589020
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1756574
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0698873
[Epoch 31] ogbg-molhiv: 0.836640 val loss: 0.072454
[Epoch 31] ogbg-molhiv: 0.754482 test loss: 0.125070
[Epoch 32; Iter    13/ 1097] train: loss: 0.0153634
[Epoch 32; Iter    43/ 1097] train: loss: 0.1897422
[Epoch 32; Iter    73/ 1097] train: loss: 0.0140250
[Epoch 32; Iter   103/ 1097] train: loss: 0.0268869
[Epoch 32; Iter   133/ 1097] train: loss: 0.0847915
[Epoch 32; Iter   163/ 1097] train: loss: 0.1253799
[Epoch 32; Iter   193/ 1097] train: loss: 0.0852589
[Epoch 32; Iter   223/ 1097] train: loss: 0.0497854
[Epoch 32; Iter   253/ 1097] train: loss: 0.0760390
[Epoch 32; Iter   283/ 1097] train: loss: 0.0240831
[Epoch 32; Iter   313/ 1097] train: loss: 0.0373265
[Epoch 32; Iter   343/ 1097] train: loss: 0.1255607
[Epoch 32; Iter   373/ 1097] train: loss: 0.2391543
[Epoch 32; Iter   403/ 1097] train: loss: 0.0198768
[Epoch 32; Iter   433/ 1097] train: loss: 0.0159293
[Epoch 32; Iter   463/ 1097] train: loss: 0.1564917
[Epoch 32; Iter   493/ 1097] train: loss: 0.0748489
[Epoch 36; Iter   605/ 1097] train: loss: 0.0156085
[Epoch 36; Iter   635/ 1097] train: loss: 0.0076182
[Epoch 36; Iter   665/ 1097] train: loss: 0.0204300
[Epoch 36; Iter   695/ 1097] train: loss: 0.1336505
[Epoch 36; Iter   725/ 1097] train: loss: 0.0087132
[Epoch 36; Iter   755/ 1097] train: loss: 0.0027974
[Epoch 36; Iter   785/ 1097] train: loss: 0.0050053
[Epoch 36; Iter   815/ 1097] train: loss: 0.0213829
[Epoch 36; Iter   845/ 1097] train: loss: 0.0015004
[Epoch 36; Iter   875/ 1097] train: loss: 0.0270424
[Epoch 36; Iter   905/ 1097] train: loss: 0.1012846
[Epoch 36; Iter   935/ 1097] train: loss: 0.0046883
[Epoch 36; Iter   965/ 1097] train: loss: 0.0088006
[Epoch 36; Iter   995/ 1097] train: loss: 0.0082191
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0058679
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0264341
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1015632
[Epoch 36] ogbg-molhiv: 0.771694 val loss: 0.207125
[Epoch 36] ogbg-molhiv: 0.751532 test loss: 0.215240
[Epoch 37; Iter    18/ 1097] train: loss: 0.0136349
[Epoch 37; Iter    48/ 1097] train: loss: 0.0260346
[Epoch 37; Iter    78/ 1097] train: loss: 0.0018152
[Epoch 37; Iter   108/ 1097] train: loss: 0.0096097
[Epoch 37; Iter   138/ 1097] train: loss: 0.0222370
[Epoch 37; Iter   168/ 1097] train: loss: 0.0029909
[Epoch 37; Iter   198/ 1097] train: loss: 0.0057163
[Epoch 37; Iter   228/ 1097] train: loss: 0.0136990
[Epoch 37; Iter   258/ 1097] train: loss: 0.0043293
[Epoch 37; Iter   288/ 1097] train: loss: 0.0276028
[Epoch 37; Iter   318/ 1097] train: loss: 0.0062798
[Epoch 37; Iter   348/ 1097] train: loss: 0.0022955
[Epoch 37; Iter   378/ 1097] train: loss: 0.1139327
[Epoch 37; Iter   408/ 1097] train: loss: 0.1251510
[Epoch 37; Iter   438/ 1097] train: loss: 0.0275922
[Epoch 37; Iter   468/ 1097] train: loss: 0.0055356
[Epoch 37; Iter   498/ 1097] train: loss: 0.0183538
[Epoch 37; Iter   528/ 1097] train: loss: 0.0089940
[Epoch 37; Iter   558/ 1097] train: loss: 0.0075088
[Epoch 37; Iter   588/ 1097] train: loss: 0.0020180
[Epoch 37; Iter   618/ 1097] train: loss: 0.0046845
[Epoch 37; Iter   648/ 1097] train: loss: 0.0063415
[Epoch 37; Iter   678/ 1097] train: loss: 0.1355891
[Epoch 37; Iter   708/ 1097] train: loss: 0.0293108
[Epoch 37; Iter   738/ 1097] train: loss: 0.0358570
[Epoch 37; Iter   768/ 1097] train: loss: 0.0042760
[Epoch 37; Iter   798/ 1097] train: loss: 0.1787942
[Epoch 37; Iter   828/ 1097] train: loss: 0.0011417
[Epoch 37; Iter   858/ 1097] train: loss: 0.0123328
[Epoch 37; Iter   888/ 1097] train: loss: 0.0008209
[Epoch 37; Iter   918/ 1097] train: loss: 0.0628407
[Epoch 37; Iter   948/ 1097] train: loss: 0.0376104
[Epoch 37; Iter   978/ 1097] train: loss: 0.0084150
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0086857
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0073950
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0361209
[Epoch 37] ogbg-molhiv: 0.764314 val loss: 0.245126
[Epoch 37] ogbg-molhiv: 0.727445 test loss: 0.281114
[Epoch 38; Iter     1/ 1097] train: loss: 0.0035564
[Epoch 38; Iter    31/ 1097] train: loss: 0.0226895
[Epoch 38; Iter    61/ 1097] train: loss: 0.0650151
[Epoch 38; Iter    91/ 1097] train: loss: 0.0024493
[Epoch 38; Iter   121/ 1097] train: loss: 0.0031902
[Epoch 38; Iter   151/ 1097] train: loss: 0.0016027
[Epoch 38; Iter   181/ 1097] train: loss: 0.0613975
[Epoch 38; Iter   211/ 1097] train: loss: 0.0014828
[Epoch 38; Iter   241/ 1097] train: loss: 0.0141527
[Epoch 38; Iter   271/ 1097] train: loss: 0.0082303
[Epoch 38; Iter   301/ 1097] train: loss: 0.0026454
[Epoch 38; Iter   331/ 1097] train: loss: 0.0188278
[Epoch 38; Iter   361/ 1097] train: loss: 0.0040010
[Epoch 38; Iter   391/ 1097] train: loss: 0.0072137
[Epoch 38; Iter   421/ 1097] train: loss: 0.0081903
[Epoch 38; Iter   451/ 1097] train: loss: 0.0018705
[Epoch 38; Iter   481/ 1097] train: loss: 0.0941062
[Epoch 38; Iter   511/ 1097] train: loss: 0.0038484
[Epoch 38; Iter   541/ 1097] train: loss: 0.0942105
[Epoch 38; Iter   571/ 1097] train: loss: 0.0062121
[Epoch 38; Iter   601/ 1097] train: loss: 0.1657656
[Epoch 38; Iter   631/ 1097] train: loss: 0.1558613
[Epoch 38; Iter   661/ 1097] train: loss: 0.0042307
[Epoch 38; Iter   691/ 1097] train: loss: 0.0147402
[Epoch 38; Iter   721/ 1097] train: loss: 0.0633195
[Epoch 38; Iter   751/ 1097] train: loss: 0.0029942
[Epoch 38; Iter   781/ 1097] train: loss: 0.0073963
[Epoch 38; Iter   811/ 1097] train: loss: 0.0714392
[Epoch 38; Iter   841/ 1097] train: loss: 0.0251677
[Epoch 38; Iter   871/ 1097] train: loss: 0.0505005
[Epoch 38; Iter   901/ 1097] train: loss: 0.0119498
[Epoch 38; Iter   931/ 1097] train: loss: 0.0025350
[Epoch 38; Iter   961/ 1097] train: loss: 0.0067198
[Epoch 38; Iter   991/ 1097] train: loss: 0.1645689
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0412174
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0117488
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0437109
[Epoch 38] ogbg-molhiv: 0.734911 val loss: 0.579819
[Epoch 38] ogbg-molhiv: 0.738324 test loss: 0.253267
[Epoch 39; Iter    14/ 1097] train: loss: 0.1003070
[Epoch 39; Iter    44/ 1097] train: loss: 0.1365118
[Epoch 39; Iter    74/ 1097] train: loss: 0.0714090
[Epoch 39; Iter   104/ 1097] train: loss: 0.0121225
[Epoch 39; Iter   134/ 1097] train: loss: 0.0053725
[Epoch 39; Iter   164/ 1097] train: loss: 0.0414423
[Epoch 39; Iter   194/ 1097] train: loss: 0.0047215
[Epoch 39; Iter   224/ 1097] train: loss: 0.0081275
[Epoch 39; Iter   254/ 1097] train: loss: 0.0014064
[Epoch 39; Iter   284/ 1097] train: loss: 0.0094760
[Epoch 39; Iter   314/ 1097] train: loss: 0.0275277
[Epoch 39; Iter   344/ 1097] train: loss: 0.0034922
[Epoch 39; Iter   374/ 1097] train: loss: 0.0009915
[Epoch 39; Iter   404/ 1097] train: loss: 0.0125481
[Epoch 39; Iter   434/ 1097] train: loss: 0.0019662
[Epoch 39; Iter   464/ 1097] train: loss: 0.0127708
[Epoch 39; Iter   494/ 1097] train: loss: 0.0081371
[Epoch 39; Iter   524/ 1097] train: loss: 0.0145636
[Epoch 39; Iter   554/ 1097] train: loss: 0.0128977
[Epoch 39; Iter   584/ 1097] train: loss: 0.0181368
[Epoch 39; Iter   614/ 1097] train: loss: 0.0026421
[Epoch 39; Iter   644/ 1097] train: loss: 0.0184957
[Epoch 39; Iter   674/ 1097] train: loss: 0.0105347
[Epoch 39; Iter   704/ 1097] train: loss: 0.0112212
[Epoch 39; Iter   734/ 1097] train: loss: 0.0045722
[Epoch 39; Iter   764/ 1097] train: loss: 0.0760921
[Epoch 39; Iter   794/ 1097] train: loss: 0.0064866
[Epoch 39; Iter   824/ 1097] train: loss: 0.0204711
[Epoch 39; Iter   854/ 1097] train: loss: 0.0098661
[Epoch 39; Iter   884/ 1097] train: loss: 0.0017110
[Epoch 39; Iter   914/ 1097] train: loss: 0.0013932
[Epoch 39; Iter   944/ 1097] train: loss: 0.0221686
[Epoch 39; Iter   974/ 1097] train: loss: 0.0414300
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0292731
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0014827
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0061297
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1248875
[Epoch 39] ogbg-molhiv: 0.778978 val loss: 0.228508
[Epoch 39] ogbg-molhiv: 0.736306 test loss: 0.267286
[Epoch 40; Iter    27/ 1097] train: loss: 0.0031502
[Epoch 40; Iter    57/ 1097] train: loss: 0.0024791
[Epoch 40; Iter    87/ 1097] train: loss: 0.0035822
[Epoch 40; Iter   117/ 1097] train: loss: 0.0065555
[Epoch 40; Iter   147/ 1097] train: loss: 0.0054825
[Epoch 40; Iter   177/ 1097] train: loss: 0.0014226
[Epoch 40; Iter   207/ 1097] train: loss: 0.0062529
[Epoch 40; Iter   237/ 1097] train: loss: 0.0013094
[Epoch 40; Iter   267/ 1097] train: loss: 0.1247299
[Epoch 40; Iter   297/ 1097] train: loss: 0.0038810
[Epoch 40; Iter   327/ 1097] train: loss: 0.0160503
[Epoch 40; Iter   357/ 1097] train: loss: 0.0136654
[Epoch 40; Iter   387/ 1097] train: loss: 0.1062087
[Epoch 40; Iter   417/ 1097] train: loss: 0.0132519
[Epoch 40; Iter   447/ 1097] train: loss: 0.0779454
[Epoch 40; Iter   477/ 1097] train: loss: 0.0090923
[Epoch 40; Iter   507/ 1097] train: loss: 0.0230952
[Epoch 40; Iter   537/ 1097] train: loss: 0.0205312
[Epoch 40; Iter   567/ 1097] train: loss: 0.0033574
[Epoch 40; Iter   597/ 1097] train: loss: 0.0548119
[Epoch 40; Iter   627/ 1097] train: loss: 0.0012028
[Epoch 40; Iter   657/ 1097] train: loss: 0.0055080
[Epoch 36; Iter   605/ 1097] train: loss: 0.0042019
[Epoch 36; Iter   635/ 1097] train: loss: 0.0059845
[Epoch 36; Iter   665/ 1097] train: loss: 0.0177867
[Epoch 36; Iter   695/ 1097] train: loss: 0.0168639
[Epoch 36; Iter   725/ 1097] train: loss: 0.0077088
[Epoch 36; Iter   755/ 1097] train: loss: 0.2277428
[Epoch 36; Iter   785/ 1097] train: loss: 0.0059918
[Epoch 36; Iter   815/ 1097] train: loss: 0.0307200
[Epoch 36; Iter   845/ 1097] train: loss: 0.0162886
[Epoch 36; Iter   875/ 1097] train: loss: 0.0040575
[Epoch 36; Iter   905/ 1097] train: loss: 0.0345424
[Epoch 36; Iter   935/ 1097] train: loss: 0.0910263
[Epoch 36; Iter   965/ 1097] train: loss: 0.0192883
[Epoch 36; Iter   995/ 1097] train: loss: 0.0707529
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0510163
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0350682
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0087214
[Epoch 36] ogbg-molhiv: 0.762979 val loss: 0.695628
[Epoch 36] ogbg-molhiv: 0.743338 test loss: 0.592184
[Epoch 37; Iter    18/ 1097] train: loss: 0.0179198
[Epoch 37; Iter    48/ 1097] train: loss: 0.0024030
[Epoch 37; Iter    78/ 1097] train: loss: 0.0079306
[Epoch 37; Iter   108/ 1097] train: loss: 0.0818008
[Epoch 37; Iter   138/ 1097] train: loss: 0.0055005
[Epoch 37; Iter   168/ 1097] train: loss: 0.0713567
[Epoch 37; Iter   198/ 1097] train: loss: 0.0210079
[Epoch 37; Iter   228/ 1097] train: loss: 0.0011717
[Epoch 37; Iter   258/ 1097] train: loss: 0.0039965
[Epoch 37; Iter   288/ 1097] train: loss: 0.0387947
[Epoch 37; Iter   318/ 1097] train: loss: 0.0170108
[Epoch 37; Iter   348/ 1097] train: loss: 0.0324839
[Epoch 37; Iter   378/ 1097] train: loss: 0.0451220
[Epoch 37; Iter   408/ 1097] train: loss: 0.0172850
[Epoch 37; Iter   438/ 1097] train: loss: 0.0382106
[Epoch 37; Iter   468/ 1097] train: loss: 0.0118870
[Epoch 37; Iter   498/ 1097] train: loss: 0.0104084
[Epoch 37; Iter   528/ 1097] train: loss: 0.0095821
[Epoch 37; Iter   558/ 1097] train: loss: 0.0010915
[Epoch 37; Iter   588/ 1097] train: loss: 0.0061132
[Epoch 37; Iter   618/ 1097] train: loss: 0.0120238
[Epoch 37; Iter   648/ 1097] train: loss: 0.0025119
[Epoch 37; Iter   678/ 1097] train: loss: 0.0055465
[Epoch 37; Iter   708/ 1097] train: loss: 0.0038927
[Epoch 37; Iter   738/ 1097] train: loss: 0.0720993
[Epoch 37; Iter   768/ 1097] train: loss: 0.0882076
[Epoch 37; Iter   798/ 1097] train: loss: 0.0389776
[Epoch 37; Iter   828/ 1097] train: loss: 0.0061292
[Epoch 37; Iter   858/ 1097] train: loss: 0.0080351
[Epoch 37; Iter   888/ 1097] train: loss: 0.0190430
[Epoch 37; Iter   918/ 1097] train: loss: 0.0222073
[Epoch 37; Iter   948/ 1097] train: loss: 0.0022128
[Epoch 37; Iter   978/ 1097] train: loss: 0.0762529
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0020426
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0057771
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0058868
[Epoch 37] ogbg-molhiv: 0.752523 val loss: 0.155328
[Epoch 37] ogbg-molhiv: 0.727291 test loss: 0.214316
[Epoch 38; Iter     1/ 1097] train: loss: 0.0020070
[Epoch 38; Iter    31/ 1097] train: loss: 0.0121191
[Epoch 38; Iter    61/ 1097] train: loss: 0.0277711
[Epoch 38; Iter    91/ 1097] train: loss: 0.0088847
[Epoch 38; Iter   121/ 1097] train: loss: 0.1475774
[Epoch 38; Iter   151/ 1097] train: loss: 0.0023658
[Epoch 38; Iter   181/ 1097] train: loss: 0.0033234
[Epoch 38; Iter   211/ 1097] train: loss: 0.0031439
[Epoch 38; Iter   241/ 1097] train: loss: 0.0149154
[Epoch 38; Iter   271/ 1097] train: loss: 0.0125246
[Epoch 38; Iter   301/ 1097] train: loss: 0.0029845
[Epoch 38; Iter   331/ 1097] train: loss: 0.1442993
[Epoch 38; Iter   361/ 1097] train: loss: 0.3627807
[Epoch 38; Iter   391/ 1097] train: loss: 0.0031157
[Epoch 38; Iter   421/ 1097] train: loss: 0.0277675
[Epoch 38; Iter   451/ 1097] train: loss: 0.0259002
[Epoch 38; Iter   481/ 1097] train: loss: 0.0104564
[Epoch 38; Iter   511/ 1097] train: loss: 0.0150806
[Epoch 38; Iter   541/ 1097] train: loss: 0.0608503
[Epoch 38; Iter   571/ 1097] train: loss: 0.0074510
[Epoch 38; Iter   601/ 1097] train: loss: 0.0054758
[Epoch 38; Iter   631/ 1097] train: loss: 0.0250957
[Epoch 38; Iter   661/ 1097] train: loss: 0.0191469
[Epoch 38; Iter   691/ 1097] train: loss: 0.0021597
[Epoch 38; Iter   721/ 1097] train: loss: 0.0265471
[Epoch 38; Iter   751/ 1097] train: loss: 0.0062753
[Epoch 38; Iter   781/ 1097] train: loss: 0.0145400
[Epoch 38; Iter   811/ 1097] train: loss: 0.0018842
[Epoch 38; Iter   841/ 1097] train: loss: 0.0446307
[Epoch 38; Iter   871/ 1097] train: loss: 0.1649830
[Epoch 38; Iter   901/ 1097] train: loss: 0.0034510
[Epoch 38; Iter   931/ 1097] train: loss: 0.0021845
[Epoch 38; Iter   961/ 1097] train: loss: 0.0192186
[Epoch 38; Iter   991/ 1097] train: loss: 0.0152872
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0150768
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0365968
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0158449
[Epoch 38] ogbg-molhiv: 0.763975 val loss: 0.197709
[Epoch 38] ogbg-molhiv: 0.733969 test loss: 0.218271
[Epoch 39; Iter    14/ 1097] train: loss: 0.0165464
[Epoch 39; Iter    44/ 1097] train: loss: 0.0089328
[Epoch 39; Iter    74/ 1097] train: loss: 0.0087981
[Epoch 39; Iter   104/ 1097] train: loss: 0.0027222
[Epoch 39; Iter   134/ 1097] train: loss: 0.0038306
[Epoch 39; Iter   164/ 1097] train: loss: 0.0234487
[Epoch 39; Iter   194/ 1097] train: loss: 0.0006360
[Epoch 39; Iter   224/ 1097] train: loss: 0.0082335
[Epoch 39; Iter   254/ 1097] train: loss: 0.0104753
[Epoch 39; Iter   284/ 1097] train: loss: 0.0116604
[Epoch 39; Iter   314/ 1097] train: loss: 0.0095612
[Epoch 39; Iter   344/ 1097] train: loss: 0.0012478
[Epoch 39; Iter   374/ 1097] train: loss: 0.0265771
[Epoch 39; Iter   404/ 1097] train: loss: 0.0365290
[Epoch 39; Iter   434/ 1097] train: loss: 0.0106397
[Epoch 39; Iter   464/ 1097] train: loss: 0.0049826
[Epoch 39; Iter   494/ 1097] train: loss: 0.0088544
[Epoch 39; Iter   524/ 1097] train: loss: 0.0032841
[Epoch 39; Iter   554/ 1097] train: loss: 0.0032545
[Epoch 39; Iter   584/ 1097] train: loss: 0.0145089
[Epoch 39; Iter   614/ 1097] train: loss: 0.0846779
[Epoch 39; Iter   644/ 1097] train: loss: 0.0208095
[Epoch 39; Iter   674/ 1097] train: loss: 0.0092656
[Epoch 39; Iter   704/ 1097] train: loss: 0.0038914
[Epoch 39; Iter   734/ 1097] train: loss: 0.0037195
[Epoch 39; Iter   764/ 1097] train: loss: 0.0068308
[Epoch 39; Iter   794/ 1097] train: loss: 0.1150063
[Epoch 39; Iter   824/ 1097] train: loss: 0.0041314
[Epoch 39; Iter   854/ 1097] train: loss: 0.0050307
[Epoch 39; Iter   884/ 1097] train: loss: 0.0094624
[Epoch 39; Iter   914/ 1097] train: loss: 0.0618483
[Epoch 39; Iter   944/ 1097] train: loss: 0.0221133
[Epoch 39; Iter   974/ 1097] train: loss: 0.0014907
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0117237
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0072572
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0049815
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0010027
[Epoch 39] ogbg-molhiv: 0.779532 val loss: 0.129007
[Epoch 39] ogbg-molhiv: 0.750159 test loss: 0.212870
[Epoch 40; Iter    27/ 1097] train: loss: 0.0067856
[Epoch 40; Iter    57/ 1097] train: loss: 0.0091969
[Epoch 40; Iter    87/ 1097] train: loss: 0.0128573
[Epoch 40; Iter   117/ 1097] train: loss: 0.0024925
[Epoch 40; Iter   147/ 1097] train: loss: 0.0011939
[Epoch 40; Iter   177/ 1097] train: loss: 0.0055217
[Epoch 40; Iter   207/ 1097] train: loss: 0.1110092
[Epoch 40; Iter   237/ 1097] train: loss: 0.0013216
[Epoch 40; Iter   267/ 1097] train: loss: 0.0090428
[Epoch 40; Iter   297/ 1097] train: loss: 0.0115675
[Epoch 40; Iter   327/ 1097] train: loss: 0.0069463
[Epoch 40; Iter   357/ 1097] train: loss: 0.0089390
[Epoch 40; Iter   387/ 1097] train: loss: 0.0039643
[Epoch 40; Iter   417/ 1097] train: loss: 0.0083751
[Epoch 40; Iter   447/ 1097] train: loss: 0.0090231
[Epoch 40; Iter   477/ 1097] train: loss: 0.0402120
[Epoch 40; Iter   507/ 1097] train: loss: 0.0074378
[Epoch 40; Iter   537/ 1097] train: loss: 0.0011370
[Epoch 40; Iter   567/ 1097] train: loss: 0.0260534
[Epoch 40; Iter   597/ 1097] train: loss: 0.0076911
[Epoch 40; Iter   627/ 1097] train: loss: 0.0012113
[Epoch 40; Iter   657/ 1097] train: loss: 0.0087291
[Epoch 36; Iter   605/ 1097] train: loss: 0.0469692
[Epoch 36; Iter   635/ 1097] train: loss: 0.0271400
[Epoch 36; Iter   665/ 1097] train: loss: 0.0171255
[Epoch 36; Iter   695/ 1097] train: loss: 0.0137894
[Epoch 36; Iter   725/ 1097] train: loss: 0.1372671
[Epoch 36; Iter   755/ 1097] train: loss: 0.0038245
[Epoch 36; Iter   785/ 1097] train: loss: 0.0699516
[Epoch 36; Iter   815/ 1097] train: loss: 0.0449010
[Epoch 36; Iter   845/ 1097] train: loss: 0.0234094
[Epoch 36; Iter   875/ 1097] train: loss: 0.0088110
[Epoch 36; Iter   905/ 1097] train: loss: 0.0199767
[Epoch 36; Iter   935/ 1097] train: loss: 0.0035430
[Epoch 36; Iter   965/ 1097] train: loss: 0.0718951
[Epoch 36; Iter   995/ 1097] train: loss: 0.0106325
[Epoch 36; Iter  1025/ 1097] train: loss: 0.3526672
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0399161
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0068325
[Epoch 36] ogbg-molhiv: 0.695596 val loss: 1.028663
[Epoch 36] ogbg-molhiv: 0.706454 test loss: 0.210286
[Epoch 37; Iter    18/ 1097] train: loss: 0.0488503
[Epoch 37; Iter    48/ 1097] train: loss: 0.0060804
[Epoch 37; Iter    78/ 1097] train: loss: 0.0055917
[Epoch 37; Iter   108/ 1097] train: loss: 0.0125983
[Epoch 37; Iter   138/ 1097] train: loss: 0.0080192
[Epoch 37; Iter   168/ 1097] train: loss: 0.0147621
[Epoch 37; Iter   198/ 1097] train: loss: 0.0289655
[Epoch 37; Iter   228/ 1097] train: loss: 0.0095017
[Epoch 37; Iter   258/ 1097] train: loss: 0.1845492
[Epoch 37; Iter   288/ 1097] train: loss: 0.0125377
[Epoch 37; Iter   318/ 1097] train: loss: 0.1418491
[Epoch 37; Iter   348/ 1097] train: loss: 0.0421321
[Epoch 37; Iter   378/ 1097] train: loss: 0.0047561
[Epoch 37; Iter   408/ 1097] train: loss: 0.0081155
[Epoch 37; Iter   438/ 1097] train: loss: 0.0256329
[Epoch 37; Iter   468/ 1097] train: loss: 0.0063895
[Epoch 37; Iter   498/ 1097] train: loss: 0.0035604
[Epoch 37; Iter   528/ 1097] train: loss: 0.1290939
[Epoch 37; Iter   558/ 1097] train: loss: 0.2234699
[Epoch 37; Iter   588/ 1097] train: loss: 0.0080520
[Epoch 37; Iter   618/ 1097] train: loss: 0.0524575
[Epoch 37; Iter   648/ 1097] train: loss: 0.0073248
[Epoch 37; Iter   678/ 1097] train: loss: 0.0056679
[Epoch 37; Iter   708/ 1097] train: loss: 0.0796426
[Epoch 37; Iter   738/ 1097] train: loss: 0.0419050
[Epoch 37; Iter   768/ 1097] train: loss: 0.0041137
[Epoch 37; Iter   798/ 1097] train: loss: 0.0675390
[Epoch 37; Iter   828/ 1097] train: loss: 0.0218196
[Epoch 37; Iter   858/ 1097] train: loss: 0.0069657
[Epoch 37; Iter   888/ 1097] train: loss: 0.0710182
[Epoch 37; Iter   918/ 1097] train: loss: 0.2263407
[Epoch 37; Iter   948/ 1097] train: loss: 0.0132033
[Epoch 37; Iter   978/ 1097] train: loss: 0.0295494
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0545604
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0112438
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0043194
[Epoch 37] ogbg-molhiv: 0.697433 val loss: 1.530291
[Epoch 37] ogbg-molhiv: 0.742766 test loss: 0.925602
[Epoch 38; Iter     1/ 1097] train: loss: 0.0122190
[Epoch 38; Iter    31/ 1097] train: loss: 0.0057146
[Epoch 38; Iter    61/ 1097] train: loss: 0.0719822
[Epoch 38; Iter    91/ 1097] train: loss: 0.0060937
[Epoch 38; Iter   121/ 1097] train: loss: 0.0023307
[Epoch 38; Iter   151/ 1097] train: loss: 0.0062513
[Epoch 38; Iter   181/ 1097] train: loss: 0.0173112
[Epoch 38; Iter   211/ 1097] train: loss: 0.0096386
[Epoch 38; Iter   241/ 1097] train: loss: 0.0101507
[Epoch 38; Iter   271/ 1097] train: loss: 0.0133636
[Epoch 38; Iter   301/ 1097] train: loss: 0.0103245
[Epoch 38; Iter   331/ 1097] train: loss: 0.0055740
[Epoch 38; Iter   361/ 1097] train: loss: 0.0606792
[Epoch 38; Iter   391/ 1097] train: loss: 0.0811662
[Epoch 38; Iter   421/ 1097] train: loss: 0.0599277
[Epoch 38; Iter   451/ 1097] train: loss: 0.0869569
[Epoch 38; Iter   481/ 1097] train: loss: 0.1069911
[Epoch 38; Iter   511/ 1097] train: loss: 0.1751706
[Epoch 38; Iter   541/ 1097] train: loss: 0.0074981
[Epoch 38; Iter   571/ 1097] train: loss: 0.0237906
[Epoch 38; Iter   601/ 1097] train: loss: 0.3795600
[Epoch 38; Iter   631/ 1097] train: loss: 0.1274940
[Epoch 38; Iter   661/ 1097] train: loss: 0.0310532
[Epoch 38; Iter   691/ 1097] train: loss: 0.1409872
[Epoch 38; Iter   721/ 1097] train: loss: 0.0051759
[Epoch 38; Iter   751/ 1097] train: loss: 0.1146990
[Epoch 38; Iter   781/ 1097] train: loss: 0.0328790
[Epoch 38; Iter   811/ 1097] train: loss: 0.0144392
[Epoch 38; Iter   841/ 1097] train: loss: 0.0156576
[Epoch 38; Iter   871/ 1097] train: loss: 0.0027332
[Epoch 38; Iter   901/ 1097] train: loss: 0.0306649
[Epoch 38; Iter   931/ 1097] train: loss: 0.0167447
[Epoch 38; Iter   961/ 1097] train: loss: 0.0610619
[Epoch 38; Iter   991/ 1097] train: loss: 0.0820605
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0034183
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0153086
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0828929
[Epoch 38] ogbg-molhiv: 0.677607 val loss: 1.265202
[Epoch 38] ogbg-molhiv: 0.681182 test loss: 0.343543
[Epoch 39; Iter    14/ 1097] train: loss: 0.0123847
[Epoch 39; Iter    44/ 1097] train: loss: 0.0827153
[Epoch 39; Iter    74/ 1097] train: loss: 0.0033137
[Epoch 39; Iter   104/ 1097] train: loss: 0.0009155
[Epoch 39; Iter   134/ 1097] train: loss: 0.0239428
[Epoch 39; Iter   164/ 1097] train: loss: 0.0022900
[Epoch 39; Iter   194/ 1097] train: loss: 0.0204079
[Epoch 39; Iter   224/ 1097] train: loss: 0.0089415
[Epoch 39; Iter   254/ 1097] train: loss: 0.0024372
[Epoch 39; Iter   284/ 1097] train: loss: 0.0044088
[Epoch 39; Iter   314/ 1097] train: loss: 0.0202484
[Epoch 39; Iter   344/ 1097] train: loss: 0.0650463
[Epoch 39; Iter   374/ 1097] train: loss: 0.0396449
[Epoch 39; Iter   404/ 1097] train: loss: 0.0181859
[Epoch 39; Iter   434/ 1097] train: loss: 0.0043426
[Epoch 39; Iter   464/ 1097] train: loss: 0.0893112
[Epoch 39; Iter   494/ 1097] train: loss: 0.0206292
[Epoch 39; Iter   524/ 1097] train: loss: 0.0144744
[Epoch 39; Iter   554/ 1097] train: loss: 0.0151341
[Epoch 39; Iter   584/ 1097] train: loss: 0.0334100
[Epoch 39; Iter   614/ 1097] train: loss: 0.0944086
[Epoch 39; Iter   644/ 1097] train: loss: 0.0187393
[Epoch 39; Iter   674/ 1097] train: loss: 0.0465921
[Epoch 39; Iter   704/ 1097] train: loss: 0.0080056
[Epoch 39; Iter   734/ 1097] train: loss: 0.0123398
[Epoch 39; Iter   764/ 1097] train: loss: 0.0185631
[Epoch 39; Iter   794/ 1097] train: loss: 0.0212265
[Epoch 39; Iter   824/ 1097] train: loss: 0.0066699
[Epoch 39; Iter   854/ 1097] train: loss: 0.1390531
[Epoch 39; Iter   884/ 1097] train: loss: 0.0012552
[Epoch 39; Iter   914/ 1097] train: loss: 0.0099297
[Epoch 39; Iter   944/ 1097] train: loss: 0.0807052
[Epoch 39; Iter   974/ 1097] train: loss: 0.0201628
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0623582
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0350387
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0660730
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1824298
[Epoch 39] ogbg-molhiv: 0.722433 val loss: 1.035054
[Epoch 39] ogbg-molhiv: 0.732762 test loss: 0.292846
[Epoch 40; Iter    27/ 1097] train: loss: 0.0286704
[Epoch 40; Iter    57/ 1097] train: loss: 0.0053104
[Epoch 40; Iter    87/ 1097] train: loss: 0.0250743
[Epoch 40; Iter   117/ 1097] train: loss: 0.0485153
[Epoch 40; Iter   147/ 1097] train: loss: 0.0039068
[Epoch 40; Iter   177/ 1097] train: loss: 0.0157117
[Epoch 40; Iter   207/ 1097] train: loss: 0.0081655
[Epoch 40; Iter   237/ 1097] train: loss: 0.0091826
[Epoch 40; Iter   267/ 1097] train: loss: 0.0165957
[Epoch 40; Iter   297/ 1097] train: loss: 0.0492812
[Epoch 40; Iter   327/ 1097] train: loss: 0.1953170
[Epoch 40; Iter   357/ 1097] train: loss: 0.0305055
[Epoch 40; Iter   387/ 1097] train: loss: 0.0075622
[Epoch 40; Iter   417/ 1097] train: loss: 0.0034444
[Epoch 40; Iter   447/ 1097] train: loss: 0.0669186
[Epoch 40; Iter   477/ 1097] train: loss: 0.0040172
[Epoch 40; Iter   507/ 1097] train: loss: 0.0056045
[Epoch 40; Iter   537/ 1097] train: loss: 0.1384150
[Epoch 40; Iter   567/ 1097] train: loss: 0.0009236
[Epoch 40; Iter   597/ 1097] train: loss: 0.0083569
[Epoch 40; Iter   627/ 1097] train: loss: 0.0116220
[Epoch 40; Iter   657/ 1097] train: loss: 0.0240419
[Epoch 36; Iter   605/ 1097] train: loss: 0.0735448
[Epoch 36; Iter   635/ 1097] train: loss: 0.1215271
[Epoch 36; Iter   665/ 1097] train: loss: 0.0085784
[Epoch 36; Iter   695/ 1097] train: loss: 0.0235245
[Epoch 36; Iter   725/ 1097] train: loss: 0.0211932
[Epoch 36; Iter   755/ 1097] train: loss: 0.0103099
[Epoch 36; Iter   785/ 1097] train: loss: 0.0320549
[Epoch 36; Iter   815/ 1097] train: loss: 0.0167300
[Epoch 36; Iter   845/ 1097] train: loss: 0.0396909
[Epoch 36; Iter   875/ 1097] train: loss: 0.0053110
[Epoch 36; Iter   905/ 1097] train: loss: 0.0023619
[Epoch 36; Iter   935/ 1097] train: loss: 0.0263556
[Epoch 36; Iter   965/ 1097] train: loss: 0.0060810
[Epoch 36; Iter   995/ 1097] train: loss: 0.0099404
[Epoch 36; Iter  1025/ 1097] train: loss: 0.1809762
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0248478
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0029620
[Epoch 36] ogbg-molhiv: 0.770429 val loss: 0.129031
[Epoch 36] ogbg-molhiv: 0.754713 test loss: 0.178543
[Epoch 37; Iter    18/ 1097] train: loss: 0.0044757
[Epoch 37; Iter    48/ 1097] train: loss: 0.0045331
[Epoch 37; Iter    78/ 1097] train: loss: 0.0066056
[Epoch 37; Iter   108/ 1097] train: loss: 0.0776150
[Epoch 37; Iter   138/ 1097] train: loss: 0.0179351
[Epoch 37; Iter   168/ 1097] train: loss: 0.0172655
[Epoch 37; Iter   198/ 1097] train: loss: 0.0182889
[Epoch 37; Iter   228/ 1097] train: loss: 0.0034009
[Epoch 37; Iter   258/ 1097] train: loss: 0.0139536
[Epoch 37; Iter   288/ 1097] train: loss: 0.0818231
[Epoch 37; Iter   318/ 1097] train: loss: 0.0052888
[Epoch 37; Iter   348/ 1097] train: loss: 0.0187336
[Epoch 37; Iter   378/ 1097] train: loss: 0.0800235
[Epoch 37; Iter   408/ 1097] train: loss: 0.0040844
[Epoch 37; Iter   438/ 1097] train: loss: 0.0620316
[Epoch 37; Iter   468/ 1097] train: loss: 0.0122363
[Epoch 37; Iter   498/ 1097] train: loss: 0.0019224
[Epoch 37; Iter   528/ 1097] train: loss: 0.0363965
[Epoch 37; Iter   558/ 1097] train: loss: 0.0361596
[Epoch 37; Iter   588/ 1097] train: loss: 0.0046033
[Epoch 37; Iter   618/ 1097] train: loss: 0.0018636
[Epoch 37; Iter   648/ 1097] train: loss: 0.0031918
[Epoch 37; Iter   678/ 1097] train: loss: 0.0097650
[Epoch 37; Iter   708/ 1097] train: loss: 0.0179392
[Epoch 37; Iter   738/ 1097] train: loss: 0.2902109
[Epoch 37; Iter   768/ 1097] train: loss: 0.0114960
[Epoch 37; Iter   798/ 1097] train: loss: 0.0154668
[Epoch 37; Iter   828/ 1097] train: loss: 0.0079093
[Epoch 37; Iter   858/ 1097] train: loss: 0.0077435
[Epoch 37; Iter   888/ 1097] train: loss: 0.0080310
[Epoch 37; Iter   918/ 1097] train: loss: 0.0281901
[Epoch 37; Iter   948/ 1097] train: loss: 0.0063782
[Epoch 37; Iter   978/ 1097] train: loss: 0.0561996
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0052804
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0242883
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0204792
[Epoch 37] ogbg-molhiv: 0.787677 val loss: 0.169705
[Epoch 37] ogbg-molhiv: 0.728108 test loss: 0.224261
[Epoch 38; Iter     1/ 1097] train: loss: 0.0475621
[Epoch 38; Iter    31/ 1097] train: loss: 0.0052990
[Epoch 38; Iter    61/ 1097] train: loss: 0.0497782
[Epoch 38; Iter    91/ 1097] train: loss: 0.0077516
[Epoch 38; Iter   121/ 1097] train: loss: 0.0004745
[Epoch 38; Iter   151/ 1097] train: loss: 0.0017398
[Epoch 38; Iter   181/ 1097] train: loss: 0.0314710
[Epoch 38; Iter   211/ 1097] train: loss: 0.0008726
[Epoch 38; Iter   241/ 1097] train: loss: 0.0021771
[Epoch 38; Iter   271/ 1097] train: loss: 0.0028932
[Epoch 38; Iter   301/ 1097] train: loss: 0.0015371
[Epoch 38; Iter   331/ 1097] train: loss: 0.0066179
[Epoch 38; Iter   361/ 1097] train: loss: 0.0095633
[Epoch 38; Iter   391/ 1097] train: loss: 0.0044594
[Epoch 38; Iter   421/ 1097] train: loss: 0.0778641
[Epoch 38; Iter   451/ 1097] train: loss: 0.0008982
[Epoch 38; Iter   481/ 1097] train: loss: 0.0174922
[Epoch 38; Iter   511/ 1097] train: loss: 0.0011778
[Epoch 38; Iter   541/ 1097] train: loss: 0.0093727
[Epoch 38; Iter   571/ 1097] train: loss: 0.0100464
[Epoch 38; Iter   601/ 1097] train: loss: 0.0158496
[Epoch 38; Iter   631/ 1097] train: loss: 0.0021242
[Epoch 38; Iter   661/ 1097] train: loss: 0.0035409
[Epoch 38; Iter   691/ 1097] train: loss: 0.0023216
[Epoch 38; Iter   721/ 1097] train: loss: 0.0162221
[Epoch 38; Iter   751/ 1097] train: loss: 0.0006357
[Epoch 38; Iter   781/ 1097] train: loss: 0.0063443
[Epoch 38; Iter   811/ 1097] train: loss: 0.0028107
[Epoch 38; Iter   841/ 1097] train: loss: 0.0034172
[Epoch 38; Iter   871/ 1097] train: loss: 0.0045964
[Epoch 38; Iter   901/ 1097] train: loss: 0.0006161
[Epoch 38; Iter   931/ 1097] train: loss: 0.0124297
[Epoch 38; Iter   961/ 1097] train: loss: 0.0011736
[Epoch 38; Iter   991/ 1097] train: loss: 0.0319435
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0020877
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0102914
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0446997
[Epoch 38] ogbg-molhiv: 0.759715 val loss: 0.147567
[Epoch 38] ogbg-molhiv: 0.708270 test loss: 0.220520
[Epoch 39; Iter    14/ 1097] train: loss: 0.0057603
[Epoch 39; Iter    44/ 1097] train: loss: 0.0243455
[Epoch 39; Iter    74/ 1097] train: loss: 0.0039648
[Epoch 39; Iter   104/ 1097] train: loss: 0.0055259
[Epoch 39; Iter   134/ 1097] train: loss: 0.0066099
[Epoch 39; Iter   164/ 1097] train: loss: 0.0044882
[Epoch 39; Iter   194/ 1097] train: loss: 0.0138366
[Epoch 39; Iter   224/ 1097] train: loss: 0.0049005
[Epoch 39; Iter   254/ 1097] train: loss: 0.0020161
[Epoch 39; Iter   284/ 1097] train: loss: 0.0055131
[Epoch 39; Iter   314/ 1097] train: loss: 0.0044808
[Epoch 39; Iter   344/ 1097] train: loss: 0.0116044
[Epoch 39; Iter   374/ 1097] train: loss: 0.0010809
[Epoch 39; Iter   404/ 1097] train: loss: 0.0016965
[Epoch 39; Iter   434/ 1097] train: loss: 0.0060574
[Epoch 39; Iter   464/ 1097] train: loss: 0.0034715
[Epoch 39; Iter   494/ 1097] train: loss: 0.0050991
[Epoch 39; Iter   524/ 1097] train: loss: 0.0028010
[Epoch 39; Iter   554/ 1097] train: loss: 0.0018969
[Epoch 39; Iter   584/ 1097] train: loss: 0.0054896
[Epoch 39; Iter   614/ 1097] train: loss: 0.0029720
[Epoch 39; Iter   644/ 1097] train: loss: 0.0612653
[Epoch 39; Iter   674/ 1097] train: loss: 0.0019400
[Epoch 39; Iter   704/ 1097] train: loss: 0.0005260
[Epoch 39; Iter   734/ 1097] train: loss: 0.0520757
[Epoch 39; Iter   764/ 1097] train: loss: 0.0049587
[Epoch 39; Iter   794/ 1097] train: loss: 0.0213637
[Epoch 39; Iter   824/ 1097] train: loss: 0.0040648
[Epoch 39; Iter   854/ 1097] train: loss: 0.0020364
[Epoch 39; Iter   884/ 1097] train: loss: 0.0032695
[Epoch 39; Iter   914/ 1097] train: loss: 0.0052876
[Epoch 39; Iter   944/ 1097] train: loss: 0.0336123
[Epoch 39; Iter   974/ 1097] train: loss: 0.0076413
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0039607
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0079000
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0521123
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0610494
[Epoch 39] ogbg-molhiv: 0.798596 val loss: 0.202351
[Epoch 39] ogbg-molhiv: 0.732048 test loss: 0.222442
[Epoch 40; Iter    27/ 1097] train: loss: 0.0097255
[Epoch 40; Iter    57/ 1097] train: loss: 0.0018347
[Epoch 40; Iter    87/ 1097] train: loss: 0.0047317
[Epoch 40; Iter   117/ 1097] train: loss: 0.0249557
[Epoch 40; Iter   147/ 1097] train: loss: 0.0168168
[Epoch 40; Iter   177/ 1097] train: loss: 0.0082416
[Epoch 40; Iter   207/ 1097] train: loss: 0.0050930
[Epoch 40; Iter   237/ 1097] train: loss: 0.0008830
[Epoch 40; Iter   267/ 1097] train: loss: 0.0496957
[Epoch 40; Iter   297/ 1097] train: loss: 0.0231191
[Epoch 40; Iter   327/ 1097] train: loss: 0.0666160
[Epoch 40; Iter   357/ 1097] train: loss: 0.0028138
[Epoch 40; Iter   387/ 1097] train: loss: 0.0323831
[Epoch 40; Iter   417/ 1097] train: loss: 0.0003875
[Epoch 40; Iter   447/ 1097] train: loss: 0.0033480
[Epoch 40; Iter   477/ 1097] train: loss: 0.0029285
[Epoch 40; Iter   507/ 1097] train: loss: 0.0019548
[Epoch 40; Iter   537/ 1097] train: loss: 0.0005334
[Epoch 40; Iter   567/ 1097] train: loss: 0.0134750
[Epoch 40; Iter   597/ 1097] train: loss: 0.0311473
[Epoch 40; Iter   627/ 1097] train: loss: 0.0156867
[Epoch 40; Iter   657/ 1097] train: loss: 0.0025872
[Epoch 36; Iter   605/ 1097] train: loss: 0.0097637
[Epoch 36; Iter   635/ 1097] train: loss: 0.0266037
[Epoch 36; Iter   665/ 1097] train: loss: 0.0102470
[Epoch 36; Iter   695/ 1097] train: loss: 0.0138105
[Epoch 36; Iter   725/ 1097] train: loss: 0.0664869
[Epoch 36; Iter   755/ 1097] train: loss: 0.0105564
[Epoch 36; Iter   785/ 1097] train: loss: 0.0021657
[Epoch 36; Iter   815/ 1097] train: loss: 0.0080449
[Epoch 36; Iter   845/ 1097] train: loss: 0.0068582
[Epoch 36; Iter   875/ 1097] train: loss: 0.0036525
[Epoch 36; Iter   905/ 1097] train: loss: 0.0030279
[Epoch 36; Iter   935/ 1097] train: loss: 0.0496062
[Epoch 36; Iter   965/ 1097] train: loss: 0.0055778
[Epoch 36; Iter   995/ 1097] train: loss: 0.0024659
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0417589
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0211949
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0014231
[Epoch 36] ogbg-molhiv: 0.773130 val loss: 0.141921
[Epoch 36] ogbg-molhiv: 0.720163 test loss: 0.252935
[Epoch 37; Iter    18/ 1097] train: loss: 0.0056183
[Epoch 37; Iter    48/ 1097] train: loss: 0.0060821
[Epoch 37; Iter    78/ 1097] train: loss: 0.0235965
[Epoch 37; Iter   108/ 1097] train: loss: 0.1893325
[Epoch 37; Iter   138/ 1097] train: loss: 0.0099451
[Epoch 37; Iter   168/ 1097] train: loss: 0.0091398
[Epoch 37; Iter   198/ 1097] train: loss: 0.0628979
[Epoch 37; Iter   228/ 1097] train: loss: 0.1078328
[Epoch 37; Iter   258/ 1097] train: loss: 0.0055737
[Epoch 37; Iter   288/ 1097] train: loss: 0.1285395
[Epoch 37; Iter   318/ 1097] train: loss: 0.0122970
[Epoch 37; Iter   348/ 1097] train: loss: 0.0437287
[Epoch 37; Iter   378/ 1097] train: loss: 0.0009163
[Epoch 37; Iter   408/ 1097] train: loss: 0.0180004
[Epoch 37; Iter   438/ 1097] train: loss: 0.0051345
[Epoch 37; Iter   468/ 1097] train: loss: 0.0015261
[Epoch 37; Iter   498/ 1097] train: loss: 0.0516205
[Epoch 37; Iter   528/ 1097] train: loss: 0.0462968
[Epoch 37; Iter   558/ 1097] train: loss: 0.0264279
[Epoch 37; Iter   588/ 1097] train: loss: 0.0187001
[Epoch 37; Iter   618/ 1097] train: loss: 0.1076730
[Epoch 37; Iter   648/ 1097] train: loss: 0.0021018
[Epoch 37; Iter   678/ 1097] train: loss: 0.0222301
[Epoch 37; Iter   708/ 1097] train: loss: 0.0060744
[Epoch 37; Iter   738/ 1097] train: loss: 0.1266479
[Epoch 37; Iter   768/ 1097] train: loss: 0.0057670
[Epoch 37; Iter   798/ 1097] train: loss: 0.0517590
[Epoch 37; Iter   828/ 1097] train: loss: 0.0038040
[Epoch 37; Iter   858/ 1097] train: loss: 0.0086720
[Epoch 37; Iter   888/ 1097] train: loss: 0.0202101
[Epoch 37; Iter   918/ 1097] train: loss: 0.0398787
[Epoch 37; Iter   948/ 1097] train: loss: 0.0169216
[Epoch 37; Iter   978/ 1097] train: loss: 0.0543342
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0139792
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0097026
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0067974
[Epoch 37] ogbg-molhiv: 0.756323 val loss: 0.211404
[Epoch 37] ogbg-molhiv: 0.696452 test loss: 0.270988
[Epoch 38; Iter     1/ 1097] train: loss: 0.0050915
[Epoch 38; Iter    31/ 1097] train: loss: 0.0108799
[Epoch 38; Iter    61/ 1097] train: loss: 0.0090917
[Epoch 38; Iter    91/ 1097] train: loss: 0.0042651
[Epoch 38; Iter   121/ 1097] train: loss: 0.1149350
[Epoch 38; Iter   151/ 1097] train: loss: 0.0064489
[Epoch 38; Iter   181/ 1097] train: loss: 0.0122740
[Epoch 38; Iter   211/ 1097] train: loss: 0.0244392
[Epoch 38; Iter   241/ 1097] train: loss: 0.0103319
[Epoch 38; Iter   271/ 1097] train: loss: 0.0207249
[Epoch 38; Iter   301/ 1097] train: loss: 0.0102473
[Epoch 38; Iter   331/ 1097] train: loss: 0.0029560
[Epoch 38; Iter   361/ 1097] train: loss: 0.0576834
[Epoch 38; Iter   391/ 1097] train: loss: 0.1024840
[Epoch 38; Iter   421/ 1097] train: loss: 0.0012071
[Epoch 38; Iter   451/ 1097] train: loss: 0.0482117
[Epoch 38; Iter   481/ 1097] train: loss: 0.0021696
[Epoch 38; Iter   511/ 1097] train: loss: 0.0031832
[Epoch 38; Iter   541/ 1097] train: loss: 0.0163299
[Epoch 38; Iter   571/ 1097] train: loss: 0.0028001
[Epoch 38; Iter   601/ 1097] train: loss: 0.0020970
[Epoch 38; Iter   631/ 1097] train: loss: 0.0055136
[Epoch 38; Iter   661/ 1097] train: loss: 0.0055008
[Epoch 38; Iter   691/ 1097] train: loss: 0.0053447
[Epoch 38; Iter   721/ 1097] train: loss: 0.0515715
[Epoch 38; Iter   751/ 1097] train: loss: 0.0318486
[Epoch 38; Iter   781/ 1097] train: loss: 0.0219939
[Epoch 38; Iter   811/ 1097] train: loss: 0.0139943
[Epoch 38; Iter   841/ 1097] train: loss: 0.0555728
[Epoch 38; Iter   871/ 1097] train: loss: 0.0035117
[Epoch 38; Iter   901/ 1097] train: loss: 0.0046467
[Epoch 38; Iter   931/ 1097] train: loss: 0.0387930
[Epoch 38; Iter   961/ 1097] train: loss: 0.0048040
[Epoch 38; Iter   991/ 1097] train: loss: 0.0150181
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0324201
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0029698
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0252314
[Epoch 38] ogbg-molhiv: 0.756712 val loss: 0.251575
[Epoch 38] ogbg-molhiv: 0.706960 test loss: 0.325551
[Epoch 39; Iter    14/ 1097] train: loss: 0.0235868
[Epoch 39; Iter    44/ 1097] train: loss: 0.0964356
[Epoch 39; Iter    74/ 1097] train: loss: 0.0589730
[Epoch 39; Iter   104/ 1097] train: loss: 0.0048547
[Epoch 39; Iter   134/ 1097] train: loss: 0.0066592
[Epoch 39; Iter   164/ 1097] train: loss: 0.0712353
[Epoch 39; Iter   194/ 1097] train: loss: 0.0018708
[Epoch 39; Iter   224/ 1097] train: loss: 0.0215701
[Epoch 39; Iter   254/ 1097] train: loss: 0.0119968
[Epoch 39; Iter   284/ 1097] train: loss: 0.0728141
[Epoch 39; Iter   314/ 1097] train: loss: 0.0040187
[Epoch 39; Iter   344/ 1097] train: loss: 0.0129443
[Epoch 39; Iter   374/ 1097] train: loss: 0.0155717
[Epoch 39; Iter   404/ 1097] train: loss: 0.0425223
[Epoch 39; Iter   434/ 1097] train: loss: 0.0149253
[Epoch 39; Iter   464/ 1097] train: loss: 0.0153252
[Epoch 39; Iter   494/ 1097] train: loss: 0.0060368
[Epoch 39; Iter   524/ 1097] train: loss: 0.0215059
[Epoch 39; Iter   554/ 1097] train: loss: 0.0164222
[Epoch 39; Iter   584/ 1097] train: loss: 0.0376414
[Epoch 39; Iter   614/ 1097] train: loss: 0.1877840
[Epoch 39; Iter   644/ 1097] train: loss: 0.0058677
[Epoch 39; Iter   674/ 1097] train: loss: 0.0136819
[Epoch 39; Iter   704/ 1097] train: loss: 0.0037336
[Epoch 39; Iter   734/ 1097] train: loss: 0.0099761
[Epoch 39; Iter   764/ 1097] train: loss: 0.0023681
[Epoch 39; Iter   794/ 1097] train: loss: 0.0874880
[Epoch 39; Iter   824/ 1097] train: loss: 0.0032227
[Epoch 39; Iter   854/ 1097] train: loss: 0.1542397
[Epoch 39; Iter   884/ 1097] train: loss: 0.0311519
[Epoch 39; Iter   914/ 1097] train: loss: 0.0344934
[Epoch 39; Iter   944/ 1097] train: loss: 0.0994253
[Epoch 39; Iter   974/ 1097] train: loss: 0.0067380
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0015632
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0013363
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0173032
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0023789
[Epoch 39] ogbg-molhiv: 0.790831 val loss: 0.174405
[Epoch 39] ogbg-molhiv: 0.707777 test loss: 0.315235
[Epoch 40; Iter    27/ 1097] train: loss: 0.0020087
[Epoch 40; Iter    57/ 1097] train: loss: 0.0031311
[Epoch 40; Iter    87/ 1097] train: loss: 0.0103432
[Epoch 40; Iter   117/ 1097] train: loss: 0.0167995
[Epoch 40; Iter   147/ 1097] train: loss: 0.0092452
[Epoch 40; Iter   177/ 1097] train: loss: 0.0023914
[Epoch 40; Iter   207/ 1097] train: loss: 0.0157217
[Epoch 40; Iter   237/ 1097] train: loss: 0.0086774
[Epoch 40; Iter   267/ 1097] train: loss: 0.0127727
[Epoch 40; Iter   297/ 1097] train: loss: 0.0003319
[Epoch 40; Iter   327/ 1097] train: loss: 0.0495767
[Epoch 40; Iter   357/ 1097] train: loss: 0.0138606
[Epoch 40; Iter   387/ 1097] train: loss: 0.0015828
[Epoch 40; Iter   417/ 1097] train: loss: 0.0133559
[Epoch 40; Iter   447/ 1097] train: loss: 0.0062869
[Epoch 40; Iter   477/ 1097] train: loss: 0.0413848
[Epoch 40; Iter   507/ 1097] train: loss: 0.0058119
[Epoch 40; Iter   537/ 1097] train: loss: 0.0194523
[Epoch 40; Iter   567/ 1097] train: loss: 0.0175594
[Epoch 40; Iter   597/ 1097] train: loss: 0.0037151
[Epoch 40; Iter   627/ 1097] train: loss: 0.0060529
[Epoch 40; Iter   657/ 1097] train: loss: 0.0144569
[Epoch 36; Iter   605/ 1097] train: loss: 0.0080105
[Epoch 36; Iter   635/ 1097] train: loss: 0.0477032
[Epoch 36; Iter   665/ 1097] train: loss: 0.0011880
[Epoch 36; Iter   695/ 1097] train: loss: 0.0378695
[Epoch 36; Iter   725/ 1097] train: loss: 0.0013577
[Epoch 36; Iter   755/ 1097] train: loss: 0.0038873
[Epoch 36; Iter   785/ 1097] train: loss: 0.0015707
[Epoch 36; Iter   815/ 1097] train: loss: 0.0436198
[Epoch 36; Iter   845/ 1097] train: loss: 0.0029545
[Epoch 36; Iter   875/ 1097] train: loss: 0.0075020
[Epoch 36; Iter   905/ 1097] train: loss: 0.0129754
[Epoch 36; Iter   935/ 1097] train: loss: 0.0128115
[Epoch 36; Iter   965/ 1097] train: loss: 0.0022266
[Epoch 36; Iter   995/ 1097] train: loss: 0.0003407
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0451678
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1463209
[Epoch 36; Iter  1085/ 1097] train: loss: 0.2167198
[Epoch 36] ogbg-molhiv: 0.757995 val loss: 0.212065
[Epoch 36] ogbg-molhiv: 0.792634 test loss: 0.214797
[Epoch 37; Iter    18/ 1097] train: loss: 0.0107249
[Epoch 37; Iter    48/ 1097] train: loss: 0.0022319
[Epoch 37; Iter    78/ 1097] train: loss: 0.0056040
[Epoch 37; Iter   108/ 1097] train: loss: 0.0025542
[Epoch 37; Iter   138/ 1097] train: loss: 0.0096699
[Epoch 37; Iter   168/ 1097] train: loss: 0.0024405
[Epoch 37; Iter   198/ 1097] train: loss: 0.0109224
[Epoch 37; Iter   228/ 1097] train: loss: 0.0011774
[Epoch 37; Iter   258/ 1097] train: loss: 0.0008246
[Epoch 37; Iter   288/ 1097] train: loss: 0.0191409
[Epoch 37; Iter   318/ 1097] train: loss: 0.0015013
[Epoch 37; Iter   348/ 1097] train: loss: 0.0020459
[Epoch 37; Iter   378/ 1097] train: loss: 0.0155443
[Epoch 37; Iter   408/ 1097] train: loss: 0.0155796
[Epoch 37; Iter   438/ 1097] train: loss: 0.0381003
[Epoch 37; Iter   468/ 1097] train: loss: 0.0002706
[Epoch 37; Iter   498/ 1097] train: loss: 0.0025528
[Epoch 37; Iter   528/ 1097] train: loss: 0.0153973
[Epoch 37; Iter   558/ 1097] train: loss: 0.0020304
[Epoch 37; Iter   588/ 1097] train: loss: 0.0014255
[Epoch 37; Iter   618/ 1097] train: loss: 0.0238610
[Epoch 37; Iter   648/ 1097] train: loss: 0.0090894
[Epoch 37; Iter   678/ 1097] train: loss: 0.2228799
[Epoch 37; Iter   708/ 1097] train: loss: 0.0018810
[Epoch 37; Iter   738/ 1097] train: loss: 0.0504995
[Epoch 37; Iter   768/ 1097] train: loss: 0.0080451
[Epoch 37; Iter   798/ 1097] train: loss: 0.1697074
[Epoch 37; Iter   828/ 1097] train: loss: 0.0013218
[Epoch 37; Iter   858/ 1097] train: loss: 0.0009734
[Epoch 37; Iter   888/ 1097] train: loss: 0.0069415
[Epoch 37; Iter   918/ 1097] train: loss: 0.0101029
[Epoch 37; Iter   948/ 1097] train: loss: 0.0347228
[Epoch 37; Iter   978/ 1097] train: loss: 0.1187849
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0105739
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0610170
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0074393
[Epoch 37] ogbg-molhiv: 0.801094 val loss: 0.134586
[Epoch 37] ogbg-molhiv: 0.804811 test loss: 0.194525
[Epoch 38; Iter     1/ 1097] train: loss: 0.0011634
[Epoch 38; Iter    31/ 1097] train: loss: 0.0004768
[Epoch 38; Iter    61/ 1097] train: loss: 0.0415796
[Epoch 38; Iter    91/ 1097] train: loss: 0.0096589
[Epoch 38; Iter   121/ 1097] train: loss: 0.0040982
[Epoch 38; Iter   151/ 1097] train: loss: 0.0013234
[Epoch 38; Iter   181/ 1097] train: loss: 0.0205794
[Epoch 38; Iter   211/ 1097] train: loss: 0.0468731
[Epoch 38; Iter   241/ 1097] train: loss: 0.0704318
[Epoch 38; Iter   271/ 1097] train: loss: 0.0202850
[Epoch 38; Iter   301/ 1097] train: loss: 0.0426830
[Epoch 38; Iter   331/ 1097] train: loss: 0.0251824
[Epoch 38; Iter   361/ 1097] train: loss: 0.0058175
[Epoch 38; Iter   391/ 1097] train: loss: 0.0027909
[Epoch 38; Iter   421/ 1097] train: loss: 0.0314044
[Epoch 38; Iter   451/ 1097] train: loss: 0.0086826
[Epoch 38; Iter   481/ 1097] train: loss: 0.0054403
[Epoch 38; Iter   511/ 1097] train: loss: 0.0012987
[Epoch 38; Iter   541/ 1097] train: loss: 0.0024761
[Epoch 38; Iter   571/ 1097] train: loss: 0.0129219
[Epoch 38; Iter   601/ 1097] train: loss: 0.1391412
[Epoch 38; Iter   631/ 1097] train: loss: 0.2421076
[Epoch 38; Iter   661/ 1097] train: loss: 0.0010132
[Epoch 38; Iter   691/ 1097] train: loss: 0.0033866
[Epoch 38; Iter   721/ 1097] train: loss: 0.0582010
[Epoch 38; Iter   751/ 1097] train: loss: 0.0021477
[Epoch 38; Iter   781/ 1097] train: loss: 0.0247234
[Epoch 38; Iter   811/ 1097] train: loss: 0.0049459
[Epoch 38; Iter   841/ 1097] train: loss: 0.1253159
[Epoch 38; Iter   871/ 1097] train: loss: 0.0017661
[Epoch 38; Iter   901/ 1097] train: loss: 0.0019530
[Epoch 38; Iter   931/ 1097] train: loss: 0.0014138
[Epoch 38; Iter   961/ 1097] train: loss: 0.0158899
[Epoch 38; Iter   991/ 1097] train: loss: 0.0043666
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0025330
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0034072
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0007769
[Epoch 38] ogbg-molhiv: 0.790721 val loss: 0.157270
[Epoch 38] ogbg-molhiv: 0.802567 test loss: 0.210154
[Epoch 39; Iter    14/ 1097] train: loss: 0.0024962
[Epoch 39; Iter    44/ 1097] train: loss: 0.0087917
[Epoch 39; Iter    74/ 1097] train: loss: 0.0043856
[Epoch 39; Iter   104/ 1097] train: loss: 0.0049762
[Epoch 39; Iter   134/ 1097] train: loss: 0.0026567
[Epoch 39; Iter   164/ 1097] train: loss: 0.0254984
[Epoch 39; Iter   194/ 1097] train: loss: 0.0005228
[Epoch 39; Iter   224/ 1097] train: loss: 0.0126611
[Epoch 39; Iter   254/ 1097] train: loss: 0.0094543
[Epoch 39; Iter   284/ 1097] train: loss: 0.0038663
[Epoch 39; Iter   314/ 1097] train: loss: 0.0009973
[Epoch 39; Iter   344/ 1097] train: loss: 0.0042361
[Epoch 39; Iter   374/ 1097] train: loss: 0.0011032
[Epoch 39; Iter   404/ 1097] train: loss: 0.0021397
[Epoch 39; Iter   434/ 1097] train: loss: 0.0023469
[Epoch 39; Iter   464/ 1097] train: loss: 0.0106599
[Epoch 39; Iter   494/ 1097] train: loss: 0.0053495
[Epoch 39; Iter   524/ 1097] train: loss: 0.0051258
[Epoch 39; Iter   554/ 1097] train: loss: 0.0155624
[Epoch 39; Iter   584/ 1097] train: loss: 0.0412012
[Epoch 39; Iter   614/ 1097] train: loss: 0.0007825
[Epoch 39; Iter   644/ 1097] train: loss: 0.0007550
[Epoch 39; Iter   674/ 1097] train: loss: 0.0343507
[Epoch 39; Iter   704/ 1097] train: loss: 0.0054762
[Epoch 39; Iter   734/ 1097] train: loss: 0.0047924
[Epoch 39; Iter   764/ 1097] train: loss: 0.0098439
[Epoch 39; Iter   794/ 1097] train: loss: 0.0148187
[Epoch 39; Iter   824/ 1097] train: loss: 0.0046373
[Epoch 39; Iter   854/ 1097] train: loss: 0.0007536
[Epoch 39; Iter   884/ 1097] train: loss: 0.0001473
[Epoch 39; Iter   914/ 1097] train: loss: 0.0010746
[Epoch 39; Iter   944/ 1097] train: loss: 0.0351518
[Epoch 39; Iter   974/ 1097] train: loss: 0.0079063
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0285320
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0016772
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0031679
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0157078
[Epoch 39] ogbg-molhiv: 0.789214 val loss: 0.155266
[Epoch 39] ogbg-molhiv: 0.785208 test loss: 0.209105
[Epoch 40; Iter    27/ 1097] train: loss: 0.0030993
[Epoch 40; Iter    57/ 1097] train: loss: 0.0007222
[Epoch 40; Iter    87/ 1097] train: loss: 0.0067826
[Epoch 40; Iter   117/ 1097] train: loss: 0.0510079
[Epoch 40; Iter   147/ 1097] train: loss: 0.0081361
[Epoch 40; Iter   177/ 1097] train: loss: 0.0013040
[Epoch 40; Iter   207/ 1097] train: loss: 0.0297748
[Epoch 40; Iter   237/ 1097] train: loss: 0.0005066
[Epoch 40; Iter   267/ 1097] train: loss: 0.0328103
[Epoch 40; Iter   297/ 1097] train: loss: 0.0485134
[Epoch 40; Iter   327/ 1097] train: loss: 0.0030847
[Epoch 40; Iter   357/ 1097] train: loss: 0.0055310
[Epoch 40; Iter   387/ 1097] train: loss: 0.0134623
[Epoch 40; Iter   417/ 1097] train: loss: 0.0242145
[Epoch 40; Iter   447/ 1097] train: loss: 0.0609383
[Epoch 40; Iter   477/ 1097] train: loss: 0.0012384
[Epoch 40; Iter   507/ 1097] train: loss: 0.0137200
[Epoch 40; Iter   537/ 1097] train: loss: 0.0038263
[Epoch 40; Iter   567/ 1097] train: loss: 0.0007464
[Epoch 40; Iter   597/ 1097] train: loss: 0.1568562
[Epoch 40; Iter   627/ 1097] train: loss: 0.0043338
[Epoch 40; Iter   657/ 1097] train: loss: 0.0056301
[Epoch 36; Iter   605/ 1097] train: loss: 0.0338913
[Epoch 36; Iter   635/ 1097] train: loss: 0.0196582
[Epoch 36; Iter   665/ 1097] train: loss: 0.0087939
[Epoch 36; Iter   695/ 1097] train: loss: 0.0656798
[Epoch 36; Iter   725/ 1097] train: loss: 0.0287078
[Epoch 36; Iter   755/ 1097] train: loss: 0.0082903
[Epoch 36; Iter   785/ 1097] train: loss: 0.0133775
[Epoch 36; Iter   815/ 1097] train: loss: 0.0183209
[Epoch 36; Iter   845/ 1097] train: loss: 0.0227744
[Epoch 36; Iter   875/ 1097] train: loss: 0.0099427
[Epoch 36; Iter   905/ 1097] train: loss: 0.0107152
[Epoch 36; Iter   935/ 1097] train: loss: 0.0083162
[Epoch 36; Iter   965/ 1097] train: loss: 0.1059032
[Epoch 36; Iter   995/ 1097] train: loss: 0.0403497
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0199005
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0487525
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1195771
[Epoch 36] ogbg-molhiv: 0.783899 val loss: 8.608566
[Epoch 36] ogbg-molhiv: 0.720549 test loss: 5.817617
[Epoch 37; Iter    18/ 1097] train: loss: 0.0089749
[Epoch 37; Iter    48/ 1097] train: loss: 0.0069262
[Epoch 37; Iter    78/ 1097] train: loss: 0.0136768
[Epoch 37; Iter   108/ 1097] train: loss: 0.0324514
[Epoch 37; Iter   138/ 1097] train: loss: 0.0057556
[Epoch 37; Iter   168/ 1097] train: loss: 0.0434504
[Epoch 37; Iter   198/ 1097] train: loss: 0.0057895
[Epoch 37; Iter   228/ 1097] train: loss: 0.0059284
[Epoch 37; Iter   258/ 1097] train: loss: 0.0263551
[Epoch 37; Iter   288/ 1097] train: loss: 0.0039476
[Epoch 37; Iter   318/ 1097] train: loss: 0.0043670
[Epoch 37; Iter   348/ 1097] train: loss: 0.0030098
[Epoch 37; Iter   378/ 1097] train: loss: 0.1283265
[Epoch 37; Iter   408/ 1097] train: loss: 0.1316858
[Epoch 37; Iter   438/ 1097] train: loss: 0.0284160
[Epoch 37; Iter   468/ 1097] train: loss: 0.0170641
[Epoch 37; Iter   498/ 1097] train: loss: 0.0208204
[Epoch 37; Iter   528/ 1097] train: loss: 0.0173822
[Epoch 37; Iter   558/ 1097] train: loss: 0.0073988
[Epoch 37; Iter   588/ 1097] train: loss: 0.0162463
[Epoch 37; Iter   618/ 1097] train: loss: 0.0639318
[Epoch 37; Iter   648/ 1097] train: loss: 0.0917730
[Epoch 37; Iter   678/ 1097] train: loss: 0.1274523
[Epoch 37; Iter   708/ 1097] train: loss: 0.0157305
[Epoch 37; Iter   738/ 1097] train: loss: 0.0072709
[Epoch 37; Iter   768/ 1097] train: loss: 0.0243126
[Epoch 37; Iter   798/ 1097] train: loss: 0.0956988
[Epoch 37; Iter   828/ 1097] train: loss: 0.0105077
[Epoch 37; Iter   858/ 1097] train: loss: 0.0185671
[Epoch 37; Iter   888/ 1097] train: loss: 0.0117733
[Epoch 37; Iter   918/ 1097] train: loss: 0.1598549
[Epoch 37; Iter   948/ 1097] train: loss: 0.0062908
[Epoch 37; Iter   978/ 1097] train: loss: 0.1141869
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0099113
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0205504
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0075702
[Epoch 37] ogbg-molhiv: 0.789566 val loss: 0.163754
[Epoch 37] ogbg-molhiv: 0.721702 test loss: 0.235951
[Epoch 38; Iter     1/ 1097] train: loss: 0.0011124
[Epoch 38; Iter    31/ 1097] train: loss: 0.0136056
[Epoch 38; Iter    61/ 1097] train: loss: 0.1011052
[Epoch 38; Iter    91/ 1097] train: loss: 0.0117710
[Epoch 38; Iter   121/ 1097] train: loss: 0.0026757
[Epoch 38; Iter   151/ 1097] train: loss: 0.0248271
[Epoch 38; Iter   181/ 1097] train: loss: 0.0041806
[Epoch 38; Iter   211/ 1097] train: loss: 0.0022731
[Epoch 38; Iter   241/ 1097] train: loss: 0.1215050
[Epoch 38; Iter   271/ 1097] train: loss: 0.0465207
[Epoch 38; Iter   301/ 1097] train: loss: 0.0014995
[Epoch 38; Iter   331/ 1097] train: loss: 0.0644847
[Epoch 38; Iter   361/ 1097] train: loss: 0.0061035
[Epoch 38; Iter   391/ 1097] train: loss: 0.0598403
[Epoch 38; Iter   421/ 1097] train: loss: 0.0097314
[Epoch 38; Iter   451/ 1097] train: loss: 0.0052704
[Epoch 38; Iter   481/ 1097] train: loss: 0.1459353
[Epoch 38; Iter   511/ 1097] train: loss: 0.0029832
[Epoch 38; Iter   541/ 1097] train: loss: 0.0387383
[Epoch 38; Iter   571/ 1097] train: loss: 0.0035955
[Epoch 38; Iter   601/ 1097] train: loss: 0.0451943
[Epoch 38; Iter   631/ 1097] train: loss: 0.0067063
[Epoch 38; Iter   661/ 1097] train: loss: 0.0140313
[Epoch 38; Iter   691/ 1097] train: loss: 0.0241115
[Epoch 38; Iter   721/ 1097] train: loss: 0.0059241
[Epoch 38; Iter   751/ 1097] train: loss: 0.0074065
[Epoch 38; Iter   781/ 1097] train: loss: 0.0133306
[Epoch 38; Iter   811/ 1097] train: loss: 0.0077693
[Epoch 38; Iter   841/ 1097] train: loss: 0.2794856
[Epoch 38; Iter   871/ 1097] train: loss: 0.0331442
[Epoch 38; Iter   901/ 1097] train: loss: 0.0264127
[Epoch 38; Iter   931/ 1097] train: loss: 0.1365075
[Epoch 38; Iter   961/ 1097] train: loss: 0.0055329
[Epoch 38; Iter   991/ 1097] train: loss: 0.0349283
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0133950
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0129972
[Epoch 38; Iter  1081/ 1097] train: loss: 0.1127043
[Epoch 38] ogbg-molhiv: 0.782407 val loss: 0.270344
[Epoch 38] ogbg-molhiv: 0.720812 test loss: 0.338108
[Epoch 39; Iter    14/ 1097] train: loss: 0.0025792
[Epoch 39; Iter    44/ 1097] train: loss: 0.0329887
[Epoch 39; Iter    74/ 1097] train: loss: 0.0047854
[Epoch 39; Iter   104/ 1097] train: loss: 0.0032911
[Epoch 39; Iter   134/ 1097] train: loss: 0.0080193
[Epoch 39; Iter   164/ 1097] train: loss: 0.0680573
[Epoch 39; Iter   194/ 1097] train: loss: 0.1108781
[Epoch 39; Iter   224/ 1097] train: loss: 0.0053883
[Epoch 39; Iter   254/ 1097] train: loss: 0.0030194
[Epoch 39; Iter   284/ 1097] train: loss: 0.0011136
[Epoch 39; Iter   314/ 1097] train: loss: 0.0046268
[Epoch 39; Iter   344/ 1097] train: loss: 0.0995167
[Epoch 39; Iter   374/ 1097] train: loss: 0.0033544
[Epoch 39; Iter   404/ 1097] train: loss: 0.0825061
[Epoch 39; Iter   434/ 1097] train: loss: 0.0017115
[Epoch 39; Iter   464/ 1097] train: loss: 0.0117708
[Epoch 39; Iter   494/ 1097] train: loss: 0.0075536
[Epoch 39; Iter   524/ 1097] train: loss: 0.1291374
[Epoch 39; Iter   554/ 1097] train: loss: 0.0518270
[Epoch 39; Iter   584/ 1097] train: loss: 0.0031224
[Epoch 39; Iter   614/ 1097] train: loss: 0.0081270
[Epoch 39; Iter   644/ 1097] train: loss: 0.0088252
[Epoch 39; Iter   674/ 1097] train: loss: 0.0038523
[Epoch 39; Iter   704/ 1097] train: loss: 0.0085643
[Epoch 39; Iter   734/ 1097] train: loss: 0.0022394
[Epoch 39; Iter   764/ 1097] train: loss: 0.0374266
[Epoch 39; Iter   794/ 1097] train: loss: 0.0195324
[Epoch 39; Iter   824/ 1097] train: loss: 0.1395680
[Epoch 39; Iter   854/ 1097] train: loss: 0.0035130
[Epoch 39; Iter   884/ 1097] train: loss: 0.0016165
[Epoch 39; Iter   914/ 1097] train: loss: 0.0058192
[Epoch 39; Iter   944/ 1097] train: loss: 0.0167777
[Epoch 39; Iter   974/ 1097] train: loss: 0.0189336
[Epoch 39; Iter  1004/ 1097] train: loss: 0.1262895
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0269740
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0245022
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0305789
[Epoch 39] ogbg-molhiv: 0.780123 val loss: 0.303176
[Epoch 39] ogbg-molhiv: 0.742757 test loss: 0.322601
[Epoch 40; Iter    27/ 1097] train: loss: 0.0364678
[Epoch 40; Iter    57/ 1097] train: loss: 0.0020807
[Epoch 40; Iter    87/ 1097] train: loss: 0.0478212
[Epoch 40; Iter   117/ 1097] train: loss: 0.1433903
[Epoch 40; Iter   147/ 1097] train: loss: 0.0072215
[Epoch 40; Iter   177/ 1097] train: loss: 0.0184556
[Epoch 40; Iter   207/ 1097] train: loss: 0.0768869
[Epoch 40; Iter   237/ 1097] train: loss: 0.0021186
[Epoch 40; Iter   267/ 1097] train: loss: 0.1333210
[Epoch 40; Iter   297/ 1097] train: loss: 0.0045205
[Epoch 40; Iter   327/ 1097] train: loss: 0.0221059
[Epoch 40; Iter   357/ 1097] train: loss: 0.0169588
[Epoch 40; Iter   387/ 1097] train: loss: 0.0062064
[Epoch 40; Iter   417/ 1097] train: loss: 0.0206204
[Epoch 40; Iter   447/ 1097] train: loss: 0.3469684
[Epoch 40; Iter   477/ 1097] train: loss: 0.0407566
[Epoch 40; Iter   507/ 1097] train: loss: 0.0346312
[Epoch 40; Iter   537/ 1097] train: loss: 0.0884246
[Epoch 40; Iter   567/ 1097] train: loss: 0.0081041
[Epoch 40; Iter   597/ 1097] train: loss: 0.0221028
[Epoch 40; Iter   627/ 1097] train: loss: 0.0020756
[Epoch 40; Iter   657/ 1097] train: loss: 0.0093285
[Epoch 36; Iter   605/ 1097] train: loss: 0.0052348
[Epoch 36; Iter   635/ 1097] train: loss: 0.0007787
[Epoch 36; Iter   665/ 1097] train: loss: 0.0004846
[Epoch 36; Iter   695/ 1097] train: loss: 0.0024732
[Epoch 36; Iter   725/ 1097] train: loss: 0.0125355
[Epoch 36; Iter   755/ 1097] train: loss: 0.0007833
[Epoch 36; Iter   785/ 1097] train: loss: 0.0009347
[Epoch 36; Iter   815/ 1097] train: loss: 0.0750304
[Epoch 36; Iter   845/ 1097] train: loss: 0.0007949
[Epoch 36; Iter   875/ 1097] train: loss: 0.0009016
[Epoch 36; Iter   905/ 1097] train: loss: 0.0186191
[Epoch 36; Iter   935/ 1097] train: loss: 0.0353196
[Epoch 36; Iter   965/ 1097] train: loss: 0.0141217
[Epoch 36; Iter   995/ 1097] train: loss: 0.0239062
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0051922
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0074031
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0030827
[Epoch 36] ogbg-molhiv: 0.659214 val loss: 1.096645
[Epoch 36] ogbg-molhiv: 0.600386 test loss: 1.244659
[Epoch 37; Iter    18/ 1097] train: loss: 0.0055130
[Epoch 37; Iter    48/ 1097] train: loss: 0.0113057
[Epoch 37; Iter    78/ 1097] train: loss: 0.0005685
[Epoch 37; Iter   108/ 1097] train: loss: 0.0053089
[Epoch 37; Iter   138/ 1097] train: loss: 0.0004567
[Epoch 37; Iter   168/ 1097] train: loss: 0.0145332
[Epoch 37; Iter   198/ 1097] train: loss: 0.0036058
[Epoch 37; Iter   228/ 1097] train: loss: 0.0391376
[Epoch 37; Iter   258/ 1097] train: loss: 0.0350812
[Epoch 37; Iter   288/ 1097] train: loss: 0.0049822
[Epoch 37; Iter   318/ 1097] train: loss: 0.0045659
[Epoch 37; Iter   348/ 1097] train: loss: 0.0001391
[Epoch 37; Iter   378/ 1097] train: loss: 0.0003069
[Epoch 37; Iter   408/ 1097] train: loss: 0.0008532
[Epoch 37; Iter   438/ 1097] train: loss: 0.0056822
[Epoch 37; Iter   468/ 1097] train: loss: 0.0001269
[Epoch 37; Iter   498/ 1097] train: loss: 0.0003947
[Epoch 37; Iter   528/ 1097] train: loss: 0.0225820
[Epoch 37; Iter   558/ 1097] train: loss: 0.0116495
[Epoch 37; Iter   588/ 1097] train: loss: 0.0009255
[Epoch 37; Iter   618/ 1097] train: loss: 0.0082935
[Epoch 37; Iter   648/ 1097] train: loss: 0.0111690
[Epoch 37; Iter   678/ 1097] train: loss: 0.0142643
[Epoch 37; Iter   708/ 1097] train: loss: 0.0015753
[Epoch 37; Iter   738/ 1097] train: loss: 0.1439728
[Epoch 37; Iter   768/ 1097] train: loss: 0.0001434
[Epoch 37; Iter   798/ 1097] train: loss: 0.0134746
[Epoch 37; Iter   828/ 1097] train: loss: 0.0919105
[Epoch 37; Iter   858/ 1097] train: loss: 0.0002172
[Epoch 37; Iter   888/ 1097] train: loss: 0.0000638
[Epoch 37; Iter   918/ 1097] train: loss: 0.0007063
[Epoch 37; Iter   948/ 1097] train: loss: 0.0185557
[Epoch 37; Iter   978/ 1097] train: loss: 0.0235338
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0002720
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0604489
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0112107
[Epoch 37] ogbg-molhiv: 0.647882 val loss: 24.413783
[Epoch 37] ogbg-molhiv: 0.600539 test loss: 32.324021
[Epoch 38; Iter     1/ 1097] train: loss: 0.0224546
[Epoch 38; Iter    31/ 1097] train: loss: 0.0004770
[Epoch 38; Iter    61/ 1097] train: loss: 0.0574833
[Epoch 38; Iter    91/ 1097] train: loss: 0.0012246
[Epoch 38; Iter   121/ 1097] train: loss: 0.0001132
[Epoch 38; Iter   151/ 1097] train: loss: 0.0123788
[Epoch 38; Iter   181/ 1097] train: loss: 0.0036610
[Epoch 38; Iter   211/ 1097] train: loss: 0.0095273
[Epoch 38; Iter   241/ 1097] train: loss: 0.0044299
[Epoch 38; Iter   271/ 1097] train: loss: 0.0034453
[Epoch 38; Iter   301/ 1097] train: loss: 0.0004065
[Epoch 38; Iter   331/ 1097] train: loss: 0.0064041
[Epoch 38; Iter   361/ 1097] train: loss: 0.0013588
[Epoch 38; Iter   391/ 1097] train: loss: 0.0134708
[Epoch 38; Iter   421/ 1097] train: loss: 0.0039389
[Epoch 38; Iter   451/ 1097] train: loss: 0.0006365
[Epoch 38; Iter   481/ 1097] train: loss: 0.0044524
[Epoch 38; Iter   511/ 1097] train: loss: 0.0145915
[Epoch 38; Iter   541/ 1097] train: loss: 0.0022569
[Epoch 38; Iter   571/ 1097] train: loss: 0.0266155
[Epoch 38; Iter   601/ 1097] train: loss: 0.0545381
[Epoch 38; Iter   631/ 1097] train: loss: 0.0010864
[Epoch 38; Iter   661/ 1097] train: loss: 0.0162633
[Epoch 38; Iter   691/ 1097] train: loss: 0.0065750
[Epoch 38; Iter   721/ 1097] train: loss: 0.0004527
[Epoch 38; Iter   751/ 1097] train: loss: 0.0788258
[Epoch 38; Iter   781/ 1097] train: loss: 0.0674725
[Epoch 38; Iter   811/ 1097] train: loss: 0.0264071
[Epoch 38; Iter   841/ 1097] train: loss: 0.0014970
[Epoch 38; Iter   871/ 1097] train: loss: 0.0211696
[Epoch 38; Iter   901/ 1097] train: loss: 0.0007613
[Epoch 38; Iter   931/ 1097] train: loss: 0.0040859
[Epoch 38; Iter   961/ 1097] train: loss: 0.0021156
[Epoch 38; Iter   991/ 1097] train: loss: 0.0032272
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0022381
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0000854
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0301320
[Epoch 38] ogbg-molhiv: 0.726154 val loss: 5.924564
[Epoch 38] ogbg-molhiv: 0.589936 test loss: 8.604241
[Epoch 39; Iter    14/ 1097] train: loss: 0.0015169
[Epoch 39; Iter    44/ 1097] train: loss: 0.0012562
[Epoch 39; Iter    74/ 1097] train: loss: 0.0000365
[Epoch 39; Iter   104/ 1097] train: loss: 0.0024794
[Epoch 39; Iter   134/ 1097] train: loss: 0.0002179
[Epoch 39; Iter   164/ 1097] train: loss: 0.0005333
[Epoch 39; Iter   194/ 1097] train: loss: 0.0006253
[Epoch 39; Iter   224/ 1097] train: loss: 0.0001593
[Epoch 39; Iter   254/ 1097] train: loss: 0.0262806
[Epoch 39; Iter   284/ 1097] train: loss: 0.0000343
[Epoch 39; Iter   314/ 1097] train: loss: 0.0004819
[Epoch 39; Iter   344/ 1097] train: loss: 0.0118798
[Epoch 39; Iter   374/ 1097] train: loss: 0.0003372
[Epoch 39; Iter   404/ 1097] train: loss: 0.0009816
[Epoch 39; Iter   434/ 1097] train: loss: 0.0006155
[Epoch 39; Iter   464/ 1097] train: loss: 0.0017114
[Epoch 39; Iter   494/ 1097] train: loss: 0.0005370
[Epoch 39; Iter   524/ 1097] train: loss: 0.0212315
[Epoch 39; Iter   554/ 1097] train: loss: 0.0134878
[Epoch 39; Iter   584/ 1097] train: loss: 0.0067564
[Epoch 39; Iter   614/ 1097] train: loss: 0.0005580
[Epoch 39; Iter   644/ 1097] train: loss: 0.0176570
[Epoch 39; Iter   674/ 1097] train: loss: 0.0019911
[Epoch 39; Iter   704/ 1097] train: loss: 0.0001387
[Epoch 39; Iter   734/ 1097] train: loss: 0.0043891
[Epoch 39; Iter   764/ 1097] train: loss: 0.0090942
[Epoch 39; Iter   794/ 1097] train: loss: 0.0004633
[Epoch 39; Iter   824/ 1097] train: loss: 0.0051975
[Epoch 39; Iter   854/ 1097] train: loss: 0.0003608
[Epoch 39; Iter   884/ 1097] train: loss: 0.0001845
[Epoch 39; Iter   914/ 1097] train: loss: 0.0054418
[Epoch 39; Iter   944/ 1097] train: loss: 0.0430451
[Epoch 39; Iter   974/ 1097] train: loss: 0.0003130
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0005560
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0004980
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0001010
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0540875
[Epoch 39] ogbg-molhiv: 0.683250 val loss: 10.481095
[Epoch 39] ogbg-molhiv: 0.624209 test loss: 14.159949
[Epoch 40; Iter    27/ 1097] train: loss: 0.0000937
[Epoch 40; Iter    57/ 1097] train: loss: 0.0004099
[Epoch 40; Iter    87/ 1097] train: loss: 0.0038476
[Epoch 40; Iter   117/ 1097] train: loss: 0.0015303
[Epoch 40; Iter   147/ 1097] train: loss: 0.0030364
[Epoch 40; Iter   177/ 1097] train: loss: 0.0001329
[Epoch 40; Iter   207/ 1097] train: loss: 0.0015684
[Epoch 40; Iter   237/ 1097] train: loss: 0.0010143
[Epoch 40; Iter   267/ 1097] train: loss: 0.0013740
[Epoch 40; Iter   297/ 1097] train: loss: 0.0449313
[Epoch 40; Iter   327/ 1097] train: loss: 0.0555813
[Epoch 40; Iter   357/ 1097] train: loss: 0.0027195
[Epoch 40; Iter   387/ 1097] train: loss: 0.0044870
[Epoch 40; Iter   417/ 1097] train: loss: 0.0012892
[Epoch 40; Iter   447/ 1097] train: loss: 0.0096151
[Epoch 40; Iter   477/ 1097] train: loss: 0.0001448
[Epoch 40; Iter   507/ 1097] train: loss: 0.0004020
[Epoch 40; Iter   537/ 1097] train: loss: 0.0009767
[Epoch 40; Iter   567/ 1097] train: loss: 0.0065740
[Epoch 40; Iter   597/ 1097] train: loss: 0.0080976
[Epoch 40; Iter   627/ 1097] train: loss: 0.0014539
[Epoch 40; Iter   657/ 1097] train: loss: 0.0004524
[Epoch 36; Iter   605/ 1097] train: loss: 0.0003710
[Epoch 36; Iter   635/ 1097] train: loss: 0.0018225
[Epoch 36; Iter   665/ 1097] train: loss: 0.0043038
[Epoch 36; Iter   695/ 1097] train: loss: 0.0026319
[Epoch 36; Iter   725/ 1097] train: loss: 0.0001849
[Epoch 36; Iter   755/ 1097] train: loss: 0.0478305
[Epoch 36; Iter   785/ 1097] train: loss: 0.0015112
[Epoch 36; Iter   815/ 1097] train: loss: 0.0006167
[Epoch 36; Iter   845/ 1097] train: loss: 0.0014068
[Epoch 36; Iter   875/ 1097] train: loss: 0.0167166
[Epoch 36; Iter   905/ 1097] train: loss: 0.0008377
[Epoch 36; Iter   935/ 1097] train: loss: 0.1411917
[Epoch 36; Iter   965/ 1097] train: loss: 0.0050292
[Epoch 36; Iter   995/ 1097] train: loss: 0.0012624
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0252698
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0122533
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0015250
[Epoch 36] ogbg-molhiv: 0.748546 val loss: 0.837162
[Epoch 36] ogbg-molhiv: 0.652483 test loss: 0.958148
[Epoch 37; Iter    18/ 1097] train: loss: 0.0021002
[Epoch 37; Iter    48/ 1097] train: loss: 0.1482698
[Epoch 37; Iter    78/ 1097] train: loss: 0.0006590
[Epoch 37; Iter   108/ 1097] train: loss: 0.0261070
[Epoch 37; Iter   138/ 1097] train: loss: 0.0499041
[Epoch 37; Iter   168/ 1097] train: loss: 0.0009835
[Epoch 37; Iter   198/ 1097] train: loss: 0.0016878
[Epoch 37; Iter   228/ 1097] train: loss: 0.0016831
[Epoch 37; Iter   258/ 1097] train: loss: 0.0008125
[Epoch 37; Iter   288/ 1097] train: loss: 0.0007310
[Epoch 37; Iter   318/ 1097] train: loss: 0.0074716
[Epoch 37; Iter   348/ 1097] train: loss: 0.0245694
[Epoch 37; Iter   378/ 1097] train: loss: 0.0369937
[Epoch 37; Iter   408/ 1097] train: loss: 0.0004761
[Epoch 37; Iter   438/ 1097] train: loss: 0.0037478
[Epoch 37; Iter   468/ 1097] train: loss: 0.0018377
[Epoch 37; Iter   498/ 1097] train: loss: 0.0003047
[Epoch 37; Iter   528/ 1097] train: loss: 0.0008631
[Epoch 37; Iter   558/ 1097] train: loss: 0.0128840
[Epoch 37; Iter   588/ 1097] train: loss: 0.0032382
[Epoch 37; Iter   618/ 1097] train: loss: 0.1219493
[Epoch 37; Iter   648/ 1097] train: loss: 0.0011268
[Epoch 37; Iter   678/ 1097] train: loss: 0.0025011
[Epoch 37; Iter   708/ 1097] train: loss: 0.0249366
[Epoch 37; Iter   738/ 1097] train: loss: 0.0090531
[Epoch 37; Iter   768/ 1097] train: loss: 0.0016362
[Epoch 37; Iter   798/ 1097] train: loss: 0.0857093
[Epoch 37; Iter   828/ 1097] train: loss: 0.0048141
[Epoch 37; Iter   858/ 1097] train: loss: 0.0758125
[Epoch 37; Iter   888/ 1097] train: loss: 0.0019578
[Epoch 37; Iter   918/ 1097] train: loss: 0.0013523
[Epoch 37; Iter   948/ 1097] train: loss: 0.0052105
[Epoch 37; Iter   978/ 1097] train: loss: 0.0014403
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0014168
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0187290
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0009420
[Epoch 37] ogbg-molhiv: 0.695320 val loss: 36.973372
[Epoch 37] ogbg-molhiv: 0.617721 test loss: 37.093340
[Epoch 38; Iter     1/ 1097] train: loss: 0.0263327
[Epoch 38; Iter    31/ 1097] train: loss: 0.0136617
[Epoch 38; Iter    61/ 1097] train: loss: 0.0010688
[Epoch 38; Iter    91/ 1097] train: loss: 0.0109690
[Epoch 38; Iter   121/ 1097] train: loss: 0.0124992
[Epoch 38; Iter   151/ 1097] train: loss: 0.0094686
[Epoch 38; Iter   181/ 1097] train: loss: 0.0001864
[Epoch 38; Iter   211/ 1097] train: loss: 0.0024275
[Epoch 38; Iter   241/ 1097] train: loss: 0.0360806
[Epoch 38; Iter   271/ 1097] train: loss: 0.0023817
[Epoch 38; Iter   301/ 1097] train: loss: 0.0036267
[Epoch 38; Iter   331/ 1097] train: loss: 0.0038064
[Epoch 38; Iter   361/ 1097] train: loss: 0.0009990
[Epoch 38; Iter   391/ 1097] train: loss: 0.0075477
[Epoch 38; Iter   421/ 1097] train: loss: 0.0031121
[Epoch 38; Iter   451/ 1097] train: loss: 0.0016850
[Epoch 38; Iter   481/ 1097] train: loss: 0.0011027
[Epoch 38; Iter   511/ 1097] train: loss: 0.0021080
[Epoch 38; Iter   541/ 1097] train: loss: 0.0004151
[Epoch 38; Iter   571/ 1097] train: loss: 0.0012630
[Epoch 38; Iter   601/ 1097] train: loss: 0.0077964
[Epoch 38; Iter   631/ 1097] train: loss: 0.0088418
[Epoch 38; Iter   661/ 1097] train: loss: 0.0135782
[Epoch 38; Iter   691/ 1097] train: loss: 0.0001356
[Epoch 38; Iter   721/ 1097] train: loss: 0.0022524
[Epoch 38; Iter   751/ 1097] train: loss: 0.0404829
[Epoch 38; Iter   781/ 1097] train: loss: 0.0348799
[Epoch 38; Iter   811/ 1097] train: loss: 0.0071307
[Epoch 38; Iter   841/ 1097] train: loss: 0.0016973
[Epoch 38; Iter   871/ 1097] train: loss: 0.0043386
[Epoch 38; Iter   901/ 1097] train: loss: 0.0012494
[Epoch 38; Iter   931/ 1097] train: loss: 0.0013260
[Epoch 38; Iter   961/ 1097] train: loss: 0.0006546
[Epoch 38; Iter   991/ 1097] train: loss: 0.0083958
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0009259
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0010247
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0803540
[Epoch 38] ogbg-molhiv: 0.676428 val loss: 70.075378
[Epoch 38] ogbg-molhiv: 0.581296 test loss: 68.884676
[Epoch 39; Iter    14/ 1097] train: loss: 0.0145868
[Epoch 39; Iter    44/ 1097] train: loss: 0.0020564
[Epoch 39; Iter    74/ 1097] train: loss: 0.0040137
[Epoch 39; Iter   104/ 1097] train: loss: 0.0026092
[Epoch 39; Iter   134/ 1097] train: loss: 0.0047845
[Epoch 39; Iter   164/ 1097] train: loss: 0.0047030
[Epoch 39; Iter   194/ 1097] train: loss: 0.0519088
[Epoch 39; Iter   224/ 1097] train: loss: 0.0020101
[Epoch 39; Iter   254/ 1097] train: loss: 0.0058644
[Epoch 39; Iter   284/ 1097] train: loss: 0.0009895
[Epoch 39; Iter   314/ 1097] train: loss: 0.0003202
[Epoch 39; Iter   344/ 1097] train: loss: 0.0200066
[Epoch 39; Iter   374/ 1097] train: loss: 0.0089264
[Epoch 39; Iter   404/ 1097] train: loss: 0.0052214
[Epoch 39; Iter   434/ 1097] train: loss: 0.0028941
[Epoch 39; Iter   464/ 1097] train: loss: 0.0150733
[Epoch 39; Iter   494/ 1097] train: loss: 0.0032707
[Epoch 39; Iter   524/ 1097] train: loss: 0.0224209
[Epoch 39; Iter   554/ 1097] train: loss: 0.0004046
[Epoch 39; Iter   584/ 1097] train: loss: 0.0015782
[Epoch 39; Iter   614/ 1097] train: loss: 0.0491337
[Epoch 39; Iter   644/ 1097] train: loss: 0.0006249
[Epoch 39; Iter   674/ 1097] train: loss: 0.0130908
[Epoch 39; Iter   704/ 1097] train: loss: 0.0091123
[Epoch 39; Iter   734/ 1097] train: loss: 0.0049756
[Epoch 39; Iter   764/ 1097] train: loss: 0.0058602
[Epoch 39; Iter   794/ 1097] train: loss: 0.0110416
[Epoch 39; Iter   824/ 1097] train: loss: 0.0006852
[Epoch 39; Iter   854/ 1097] train: loss: 0.0075971
[Epoch 39; Iter   884/ 1097] train: loss: 0.0007191
[Epoch 39; Iter   914/ 1097] train: loss: 0.0025116
[Epoch 39; Iter   944/ 1097] train: loss: 0.0393272
[Epoch 39; Iter   974/ 1097] train: loss: 0.0024907
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0015239
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0006214
[Epoch 39; Iter  1064/ 1097] train: loss: 0.1057333
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0120101
[Epoch 39] ogbg-molhiv: 0.738677 val loss: 0.320391
[Epoch 39] ogbg-molhiv: 0.666753 test loss: 0.396010
[Epoch 40; Iter    27/ 1097] train: loss: 0.0081440
[Epoch 40; Iter    57/ 1097] train: loss: 0.0017174
[Epoch 40; Iter    87/ 1097] train: loss: 0.0263692
[Epoch 40; Iter   117/ 1097] train: loss: 0.0007879
[Epoch 40; Iter   147/ 1097] train: loss: 0.0000804
[Epoch 40; Iter   177/ 1097] train: loss: 0.0004251
[Epoch 40; Iter   207/ 1097] train: loss: 0.0712622
[Epoch 40; Iter   237/ 1097] train: loss: 0.0026981
[Epoch 40; Iter   267/ 1097] train: loss: 0.0027235
[Epoch 40; Iter   297/ 1097] train: loss: 0.0005605
[Epoch 40; Iter   327/ 1097] train: loss: 0.0284553
[Epoch 40; Iter   357/ 1097] train: loss: 0.0003092
[Epoch 40; Iter   387/ 1097] train: loss: 0.0008974
[Epoch 40; Iter   417/ 1097] train: loss: 0.0040453
[Epoch 40; Iter   447/ 1097] train: loss: 0.0105740
[Epoch 40; Iter   477/ 1097] train: loss: 0.0031673
[Epoch 40; Iter   507/ 1097] train: loss: 0.0010039
[Epoch 40; Iter   537/ 1097] train: loss: 0.0186437
[Epoch 40; Iter   567/ 1097] train: loss: 0.0008584
[Epoch 40; Iter   597/ 1097] train: loss: 0.0089209
[Epoch 40; Iter   627/ 1097] train: loss: 0.0063255
[Epoch 40; Iter   657/ 1097] train: loss: 0.0113154
[Epoch 32; Iter   523/ 1097] train: loss: 0.0312136
[Epoch 32; Iter   553/ 1097] train: loss: 0.0735450
[Epoch 32; Iter   583/ 1097] train: loss: 0.0845584
[Epoch 32; Iter   613/ 1097] train: loss: 0.2556951
[Epoch 32; Iter   643/ 1097] train: loss: 0.0310427
[Epoch 32; Iter   673/ 1097] train: loss: 0.0148550
[Epoch 32; Iter   703/ 1097] train: loss: 0.1460199
[Epoch 32; Iter   733/ 1097] train: loss: 0.0221098
[Epoch 32; Iter   763/ 1097] train: loss: 0.0205542
[Epoch 32; Iter   793/ 1097] train: loss: 0.2241954
[Epoch 32; Iter   823/ 1097] train: loss: 0.1444428
[Epoch 32; Iter   853/ 1097] train: loss: 0.0134049
[Epoch 32; Iter   883/ 1097] train: loss: 0.0126477
[Epoch 32; Iter   913/ 1097] train: loss: 0.0250732
[Epoch 32; Iter   943/ 1097] train: loss: 0.0459630
[Epoch 32; Iter   973/ 1097] train: loss: 0.1123497
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0153251
[Epoch 32; Iter  1033/ 1097] train: loss: 0.1507233
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1205691
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0140394
[Epoch 32] ogbg-molhiv: 0.835452 val loss: 0.071699
[Epoch 32] ogbg-molhiv: 0.770546 test loss: 0.146712
[Epoch 33; Iter    26/ 1097] train: loss: 0.0347877
[Epoch 33; Iter    56/ 1097] train: loss: 0.0611885
[Epoch 33; Iter    86/ 1097] train: loss: 0.0185744
[Epoch 33; Iter   116/ 1097] train: loss: 0.0223232
[Epoch 33; Iter   146/ 1097] train: loss: 0.0169788
[Epoch 33; Iter   176/ 1097] train: loss: 0.0648924
[Epoch 33; Iter   206/ 1097] train: loss: 0.2174364
[Epoch 33; Iter   236/ 1097] train: loss: 0.0267697
[Epoch 33; Iter   266/ 1097] train: loss: 0.1634810
[Epoch 33; Iter   296/ 1097] train: loss: 0.0362672
[Epoch 33; Iter   326/ 1097] train: loss: 0.0745302
[Epoch 33; Iter   356/ 1097] train: loss: 0.0378048
[Epoch 33; Iter   386/ 1097] train: loss: 0.2630277
[Epoch 33; Iter   416/ 1097] train: loss: 0.1674862
[Epoch 33; Iter   446/ 1097] train: loss: 0.0132511
[Epoch 33; Iter   476/ 1097] train: loss: 0.1162212
[Epoch 33; Iter   506/ 1097] train: loss: 0.0467611
[Epoch 33; Iter   536/ 1097] train: loss: 0.0209346
[Epoch 33; Iter   566/ 1097] train: loss: 0.0249986
[Epoch 33; Iter   596/ 1097] train: loss: 0.0189607
[Epoch 33; Iter   626/ 1097] train: loss: 0.0135328
[Epoch 33; Iter   656/ 1097] train: loss: 0.2318566
[Epoch 33; Iter   686/ 1097] train: loss: 0.0213998
[Epoch 33; Iter   716/ 1097] train: loss: 0.0689144
[Epoch 33; Iter   746/ 1097] train: loss: 0.0255289
[Epoch 33; Iter   776/ 1097] train: loss: 0.0267613
[Epoch 33; Iter   806/ 1097] train: loss: 0.0596848
[Epoch 33; Iter   836/ 1097] train: loss: 0.0278697
[Epoch 33; Iter   866/ 1097] train: loss: 0.0514735
[Epoch 33; Iter   896/ 1097] train: loss: 0.1261906
[Epoch 33; Iter   926/ 1097] train: loss: 0.0412746
[Epoch 33; Iter   956/ 1097] train: loss: 0.0103133
[Epoch 33; Iter   986/ 1097] train: loss: 0.0493805
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0150343
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1517335
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0445572
[Epoch 33] ogbg-molhiv: 0.817561 val loss: 0.075606
[Epoch 33] ogbg-molhiv: 0.749327 test loss: 0.198537
[Epoch 34; Iter     9/ 1097] train: loss: 0.0411920
[Epoch 34; Iter    39/ 1097] train: loss: 0.1513771
[Epoch 34; Iter    69/ 1097] train: loss: 0.0427619
[Epoch 34; Iter    99/ 1097] train: loss: 0.0290226
[Epoch 34; Iter   129/ 1097] train: loss: 0.1329291
[Epoch 34; Iter   159/ 1097] train: loss: 0.0154757
[Epoch 34; Iter   189/ 1097] train: loss: 0.1573637
[Epoch 34; Iter   219/ 1097] train: loss: 0.0820225
[Epoch 34; Iter   249/ 1097] train: loss: 0.0612155
[Epoch 34; Iter   279/ 1097] train: loss: 0.3524624
[Epoch 34; Iter   309/ 1097] train: loss: 0.0357213
[Epoch 34; Iter   339/ 1097] train: loss: 0.0603825
[Epoch 34; Iter   369/ 1097] train: loss: 0.0112736
[Epoch 34; Iter   399/ 1097] train: loss: 0.0235330
[Epoch 34; Iter   429/ 1097] train: loss: 0.0415339
[Epoch 34; Iter   459/ 1097] train: loss: 0.1128485
[Epoch 34; Iter   489/ 1097] train: loss: 0.0207304
[Epoch 34; Iter   519/ 1097] train: loss: 0.0160734
[Epoch 34; Iter   549/ 1097] train: loss: 0.2528614
[Epoch 34; Iter   579/ 1097] train: loss: 0.0157951
[Epoch 34; Iter   609/ 1097] train: loss: 0.0540773
[Epoch 34; Iter   639/ 1097] train: loss: 0.0159552
[Epoch 34; Iter   669/ 1097] train: loss: 0.0409124
[Epoch 34; Iter   699/ 1097] train: loss: 0.1743929
[Epoch 34; Iter   729/ 1097] train: loss: 0.2774936
[Epoch 34; Iter   759/ 1097] train: loss: 0.1041106
[Epoch 34; Iter   789/ 1097] train: loss: 0.0301114
[Epoch 34; Iter   819/ 1097] train: loss: 0.0619169
[Epoch 34; Iter   849/ 1097] train: loss: 0.0113570
[Epoch 34; Iter   879/ 1097] train: loss: 0.0541635
[Epoch 34; Iter   909/ 1097] train: loss: 0.0118441
[Epoch 34; Iter   939/ 1097] train: loss: 0.0215152
[Epoch 34; Iter   969/ 1097] train: loss: 0.0911812
[Epoch 34; Iter   999/ 1097] train: loss: 0.0260215
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1948146
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0182392
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0106496
[Epoch 34] ogbg-molhiv: 0.820060 val loss: 0.097168
[Epoch 34] ogbg-molhiv: 0.761801 test loss: 0.195836
[Epoch 35; Iter    22/ 1097] train: loss: 0.0127894
[Epoch 35; Iter    52/ 1097] train: loss: 0.0179713
[Epoch 35; Iter    82/ 1097] train: loss: 0.0502151
[Epoch 35; Iter   112/ 1097] train: loss: 0.1211134
[Epoch 35; Iter   142/ 1097] train: loss: 0.0267956
[Epoch 35; Iter   172/ 1097] train: loss: 0.0399199
[Epoch 35; Iter   202/ 1097] train: loss: 0.1326829
[Epoch 35; Iter   232/ 1097] train: loss: 0.3794033
[Epoch 35; Iter   262/ 1097] train: loss: 0.0920505
[Epoch 35; Iter   292/ 1097] train: loss: 0.0938903
[Epoch 35; Iter   322/ 1097] train: loss: 0.1181796
[Epoch 35; Iter   352/ 1097] train: loss: 0.0411587
[Epoch 35; Iter   382/ 1097] train: loss: 0.0350978
[Epoch 35; Iter   412/ 1097] train: loss: 0.0276058
[Epoch 35; Iter   442/ 1097] train: loss: 0.1283752
[Epoch 35; Iter   472/ 1097] train: loss: 0.0155967
[Epoch 35; Iter   502/ 1097] train: loss: 0.1885850
[Epoch 35; Iter   532/ 1097] train: loss: 0.0894430
[Epoch 35; Iter   562/ 1097] train: loss: 0.0350164
[Epoch 35; Iter   592/ 1097] train: loss: 0.0152147
[Epoch 35; Iter   622/ 1097] train: loss: 0.0473987
[Epoch 35; Iter   652/ 1097] train: loss: 0.0666534
[Epoch 35; Iter   682/ 1097] train: loss: 0.0432187
[Epoch 35; Iter   712/ 1097] train: loss: 0.1168531
[Epoch 35; Iter   742/ 1097] train: loss: 0.0498544
[Epoch 35; Iter   772/ 1097] train: loss: 0.0609549
[Epoch 35; Iter   802/ 1097] train: loss: 0.0465151
[Epoch 35; Iter   832/ 1097] train: loss: 0.0766298
[Epoch 35; Iter   862/ 1097] train: loss: 0.1055236
[Epoch 35; Iter   892/ 1097] train: loss: 0.0389410
[Epoch 35; Iter   922/ 1097] train: loss: 0.1368633
[Epoch 35; Iter   952/ 1097] train: loss: 0.0771165
[Epoch 35; Iter   982/ 1097] train: loss: 0.1396442
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0909305
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0146526
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0213414
[Epoch 35] ogbg-molhiv: 0.809132 val loss: 0.082565
[Epoch 35] ogbg-molhiv: 0.777906 test loss: 0.153910
[Epoch 36; Iter     5/ 1097] train: loss: 0.1416087
[Epoch 36; Iter    35/ 1097] train: loss: 0.0342615
[Epoch 36; Iter    65/ 1097] train: loss: 0.0185671
[Epoch 36; Iter    95/ 1097] train: loss: 0.0556423
[Epoch 36; Iter   125/ 1097] train: loss: 0.0335861
[Epoch 36; Iter   155/ 1097] train: loss: 0.0201360
[Epoch 36; Iter   185/ 1097] train: loss: 0.0234570
[Epoch 36; Iter   215/ 1097] train: loss: 0.3305305
[Epoch 36; Iter   245/ 1097] train: loss: 0.0658855
[Epoch 36; Iter   275/ 1097] train: loss: 0.0223014
[Epoch 36; Iter   305/ 1097] train: loss: 0.2954836
[Epoch 36; Iter   335/ 1097] train: loss: 0.0862762
[Epoch 36; Iter   365/ 1097] train: loss: 0.0232721
[Epoch 36; Iter   395/ 1097] train: loss: 0.0580374
[Epoch 36; Iter   425/ 1097] train: loss: 0.2168231
[Epoch 36; Iter   455/ 1097] train: loss: 0.1220688
[Epoch 36; Iter   485/ 1097] train: loss: 0.0197874
[Epoch 36; Iter   515/ 1097] train: loss: 0.0776137
[Epoch 36; Iter   545/ 1097] train: loss: 0.0484476
[Epoch 36; Iter   575/ 1097] train: loss: 0.0271202
[Epoch 32; Iter   523/ 1097] train: loss: 0.0244442
[Epoch 32; Iter   553/ 1097] train: loss: 0.0191407
[Epoch 32; Iter   583/ 1097] train: loss: 0.1224096
[Epoch 32; Iter   613/ 1097] train: loss: 0.0158361
[Epoch 32; Iter   643/ 1097] train: loss: 0.0256537
[Epoch 32; Iter   673/ 1097] train: loss: 0.3594406
[Epoch 32; Iter   703/ 1097] train: loss: 0.0315392
[Epoch 32; Iter   733/ 1097] train: loss: 0.0123054
[Epoch 32; Iter   763/ 1097] train: loss: 0.0882699
[Epoch 32; Iter   793/ 1097] train: loss: 0.0212097
[Epoch 32; Iter   823/ 1097] train: loss: 0.0358904
[Epoch 32; Iter   853/ 1097] train: loss: 0.0188784
[Epoch 32; Iter   883/ 1097] train: loss: 0.0248343
[Epoch 32; Iter   913/ 1097] train: loss: 0.0746880
[Epoch 32; Iter   943/ 1097] train: loss: 0.2063127
[Epoch 32; Iter   973/ 1097] train: loss: 0.0258625
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0522166
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0344134
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1706448
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0960371
[Epoch 32] ogbg-molhiv: 0.817307 val loss: 0.085004
[Epoch 32] ogbg-molhiv: 0.746169 test loss: 0.130461
[Epoch 33; Iter    26/ 1097] train: loss: 0.0333868
[Epoch 33; Iter    56/ 1097] train: loss: 0.1690388
[Epoch 33; Iter    86/ 1097] train: loss: 0.0492220
[Epoch 33; Iter   116/ 1097] train: loss: 0.2923146
[Epoch 33; Iter   146/ 1097] train: loss: 0.0320465
[Epoch 33; Iter   176/ 1097] train: loss: 0.0274465
[Epoch 33; Iter   206/ 1097] train: loss: 0.0151743
[Epoch 33; Iter   236/ 1097] train: loss: 0.2041631
[Epoch 33; Iter   266/ 1097] train: loss: 0.0251861
[Epoch 33; Iter   296/ 1097] train: loss: 0.1443231
[Epoch 33; Iter   326/ 1097] train: loss: 0.2466724
[Epoch 33; Iter   356/ 1097] train: loss: 0.2223406
[Epoch 33; Iter   386/ 1097] train: loss: 0.0342997
[Epoch 33; Iter   416/ 1097] train: loss: 0.0337444
[Epoch 33; Iter   446/ 1097] train: loss: 0.0278481
[Epoch 33; Iter   476/ 1097] train: loss: 0.1023336
[Epoch 33; Iter   506/ 1097] train: loss: 0.1757800
[Epoch 33; Iter   536/ 1097] train: loss: 0.0595613
[Epoch 33; Iter   566/ 1097] train: loss: 0.0152397
[Epoch 33; Iter   596/ 1097] train: loss: 0.0772547
[Epoch 33; Iter   626/ 1097] train: loss: 0.0658021
[Epoch 33; Iter   656/ 1097] train: loss: 0.0286530
[Epoch 33; Iter   686/ 1097] train: loss: 0.0199190
[Epoch 33; Iter   716/ 1097] train: loss: 0.0378052
[Epoch 33; Iter   746/ 1097] train: loss: 0.0121960
[Epoch 33; Iter   776/ 1097] train: loss: 0.1519718
[Epoch 33; Iter   806/ 1097] train: loss: 0.0954526
[Epoch 33; Iter   836/ 1097] train: loss: 0.0276985
[Epoch 33; Iter   866/ 1097] train: loss: 0.0613411
[Epoch 33; Iter   896/ 1097] train: loss: 0.0585024
[Epoch 33; Iter   926/ 1097] train: loss: 0.0422330
[Epoch 33; Iter   956/ 1097] train: loss: 0.0153742
[Epoch 33; Iter   986/ 1097] train: loss: 0.0308480
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0166300
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0563826
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2967094
[Epoch 33] ogbg-molhiv: 0.796110 val loss: 0.079074
[Epoch 33] ogbg-molhiv: 0.734647 test loss: 0.133528
[Epoch 34; Iter     9/ 1097] train: loss: 0.0214075
[Epoch 34; Iter    39/ 1097] train: loss: 0.0703722
[Epoch 34; Iter    69/ 1097] train: loss: 0.0217170
[Epoch 34; Iter    99/ 1097] train: loss: 0.0372777
[Epoch 34; Iter   129/ 1097] train: loss: 0.1047098
[Epoch 34; Iter   159/ 1097] train: loss: 0.0317266
[Epoch 34; Iter   189/ 1097] train: loss: 0.1441084
[Epoch 34; Iter   219/ 1097] train: loss: 0.0086118
[Epoch 34; Iter   249/ 1097] train: loss: 0.0287867
[Epoch 34; Iter   279/ 1097] train: loss: 0.0594442
[Epoch 34; Iter   309/ 1097] train: loss: 0.0275464
[Epoch 34; Iter   339/ 1097] train: loss: 0.1318319
[Epoch 34; Iter   369/ 1097] train: loss: 0.1661984
[Epoch 34; Iter   399/ 1097] train: loss: 0.1187531
[Epoch 34; Iter   429/ 1097] train: loss: 0.0166593
[Epoch 34; Iter   459/ 1097] train: loss: 0.1450536
[Epoch 34; Iter   489/ 1097] train: loss: 0.0129605
[Epoch 34; Iter   519/ 1097] train: loss: 0.0216160
[Epoch 34; Iter   549/ 1097] train: loss: 0.0535846
[Epoch 34; Iter   579/ 1097] train: loss: 0.1568360
[Epoch 34; Iter   609/ 1097] train: loss: 0.0271306
[Epoch 34; Iter   639/ 1097] train: loss: 0.2008233
[Epoch 34; Iter   669/ 1097] train: loss: 0.0161512
[Epoch 34; Iter   699/ 1097] train: loss: 0.0172579
[Epoch 34; Iter   729/ 1097] train: loss: 0.2728055
[Epoch 34; Iter   759/ 1097] train: loss: 0.0213962
[Epoch 34; Iter   789/ 1097] train: loss: 0.0351915
[Epoch 34; Iter   819/ 1097] train: loss: 0.1836495
[Epoch 34; Iter   849/ 1097] train: loss: 0.0438190
[Epoch 34; Iter   879/ 1097] train: loss: 0.2624631
[Epoch 34; Iter   909/ 1097] train: loss: 0.0719336
[Epoch 34; Iter   939/ 1097] train: loss: 0.1819040
[Epoch 34; Iter   969/ 1097] train: loss: 0.0175626
[Epoch 34; Iter   999/ 1097] train: loss: 0.0214503
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0183404
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0207153
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0193706
[Epoch 34] ogbg-molhiv: 0.822451 val loss: 0.079924
[Epoch 34] ogbg-molhiv: 0.722355 test loss: 0.133756
[Epoch 35; Iter    22/ 1097] train: loss: 0.0242092
[Epoch 35; Iter    52/ 1097] train: loss: 0.0484629
[Epoch 35; Iter    82/ 1097] train: loss: 0.1736204
[Epoch 35; Iter   112/ 1097] train: loss: 0.0617108
[Epoch 35; Iter   142/ 1097] train: loss: 0.0104443
[Epoch 35; Iter   172/ 1097] train: loss: 0.0656001
[Epoch 35; Iter   202/ 1097] train: loss: 0.0166386
[Epoch 35; Iter   232/ 1097] train: loss: 0.0435014
[Epoch 35; Iter   262/ 1097] train: loss: 0.0078539
[Epoch 35; Iter   292/ 1097] train: loss: 0.0139425
[Epoch 35; Iter   322/ 1097] train: loss: 0.1617817
[Epoch 35; Iter   352/ 1097] train: loss: 0.3621528
[Epoch 35; Iter   382/ 1097] train: loss: 0.1095566
[Epoch 35; Iter   412/ 1097] train: loss: 0.1399170
[Epoch 35; Iter   442/ 1097] train: loss: 0.0481693
[Epoch 35; Iter   472/ 1097] train: loss: 0.0341660
[Epoch 35; Iter   502/ 1097] train: loss: 0.0369878
[Epoch 35; Iter   532/ 1097] train: loss: 0.1730506
[Epoch 35; Iter   562/ 1097] train: loss: 0.1937367
[Epoch 35; Iter   592/ 1097] train: loss: 0.0204270
[Epoch 35; Iter   622/ 1097] train: loss: 0.2784890
[Epoch 35; Iter   652/ 1097] train: loss: 0.1712862
[Epoch 35; Iter   682/ 1097] train: loss: 0.0565234
[Epoch 35; Iter   712/ 1097] train: loss: 0.1163177
[Epoch 35; Iter   742/ 1097] train: loss: 0.0616391
[Epoch 35; Iter   772/ 1097] train: loss: 0.0729088
[Epoch 35; Iter   802/ 1097] train: loss: 0.0909546
[Epoch 35; Iter   832/ 1097] train: loss: 0.0847075
[Epoch 35; Iter   862/ 1097] train: loss: 0.0461214
[Epoch 35; Iter   892/ 1097] train: loss: 0.0132034
[Epoch 35; Iter   922/ 1097] train: loss: 0.0302087
[Epoch 35; Iter   952/ 1097] train: loss: 0.0775725
[Epoch 35; Iter   982/ 1097] train: loss: 0.1336696
[Epoch 35; Iter  1012/ 1097] train: loss: 0.1467990
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1123180
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0218915
[Epoch 35] ogbg-molhiv: 0.811731 val loss: 0.080903
[Epoch 35] ogbg-molhiv: 0.737370 test loss: 0.131788
[Epoch 36; Iter     5/ 1097] train: loss: 0.0115549
[Epoch 36; Iter    35/ 1097] train: loss: 0.0430178
[Epoch 36; Iter    65/ 1097] train: loss: 0.0540201
[Epoch 36; Iter    95/ 1097] train: loss: 0.0121298
[Epoch 36; Iter   125/ 1097] train: loss: 0.2352476
[Epoch 36; Iter   155/ 1097] train: loss: 0.0789571
[Epoch 36; Iter   185/ 1097] train: loss: 0.0444951
[Epoch 36; Iter   215/ 1097] train: loss: 0.1140846
[Epoch 36; Iter   245/ 1097] train: loss: 0.0990119
[Epoch 36; Iter   275/ 1097] train: loss: 0.2075300
[Epoch 36; Iter   305/ 1097] train: loss: 0.1616252
[Epoch 36; Iter   335/ 1097] train: loss: 0.0367774
[Epoch 36; Iter   365/ 1097] train: loss: 0.0532028
[Epoch 36; Iter   395/ 1097] train: loss: 0.0291137
[Epoch 36; Iter   425/ 1097] train: loss: 0.0318783
[Epoch 36; Iter   455/ 1097] train: loss: 0.0130509
[Epoch 36; Iter   485/ 1097] train: loss: 0.0973784
[Epoch 36; Iter   515/ 1097] train: loss: 0.0755134
[Epoch 36; Iter   545/ 1097] train: loss: 0.1814952
[Epoch 36; Iter   575/ 1097] train: loss: 0.0285451
[Epoch 32; Iter   523/ 1097] train: loss: 0.2657543
[Epoch 32; Iter   553/ 1097] train: loss: 0.0322970
[Epoch 32; Iter   583/ 1097] train: loss: 0.2596723
[Epoch 32; Iter   613/ 1097] train: loss: 0.0176590
[Epoch 32; Iter   643/ 1097] train: loss: 0.2988278
[Epoch 32; Iter   673/ 1097] train: loss: 0.1780448
[Epoch 32; Iter   703/ 1097] train: loss: 0.1476318
[Epoch 32; Iter   733/ 1097] train: loss: 0.0476526
[Epoch 32; Iter   763/ 1097] train: loss: 0.0384830
[Epoch 32; Iter   793/ 1097] train: loss: 0.1942885
[Epoch 32; Iter   823/ 1097] train: loss: 0.0842130
[Epoch 32; Iter   853/ 1097] train: loss: 0.0375896
[Epoch 32; Iter   883/ 1097] train: loss: 0.0727277
[Epoch 32; Iter   913/ 1097] train: loss: 0.2029255
[Epoch 32; Iter   943/ 1097] train: loss: 0.0174456
[Epoch 32; Iter   973/ 1097] train: loss: 0.0223913
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1792302
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0496578
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0521865
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0367823
[Epoch 32] ogbg-molhiv: 0.829313 val loss: 0.069363
[Epoch 32] ogbg-molhiv: 0.758854 test loss: 0.121773
[Epoch 33; Iter    26/ 1097] train: loss: 0.1160114
[Epoch 33; Iter    56/ 1097] train: loss: 0.0412840
[Epoch 33; Iter    86/ 1097] train: loss: 0.0211258
[Epoch 33; Iter   116/ 1097] train: loss: 0.1380905
[Epoch 33; Iter   146/ 1097] train: loss: 0.0538605
[Epoch 33; Iter   176/ 1097] train: loss: 0.0327321
[Epoch 33; Iter   206/ 1097] train: loss: 0.0750211
[Epoch 33; Iter   236/ 1097] train: loss: 0.1072454
[Epoch 33; Iter   266/ 1097] train: loss: 0.0142391
[Epoch 33; Iter   296/ 1097] train: loss: 0.1820681
[Epoch 33; Iter   326/ 1097] train: loss: 0.1667930
[Epoch 33; Iter   356/ 1097] train: loss: 0.3500372
[Epoch 33; Iter   386/ 1097] train: loss: 0.0404717
[Epoch 33; Iter   416/ 1097] train: loss: 0.0226553
[Epoch 33; Iter   446/ 1097] train: loss: 0.0162054
[Epoch 33; Iter   476/ 1097] train: loss: 0.0256305
[Epoch 33; Iter   506/ 1097] train: loss: 0.0441829
[Epoch 33; Iter   536/ 1097] train: loss: 0.0792694
[Epoch 33; Iter   566/ 1097] train: loss: 0.0975503
[Epoch 33; Iter   596/ 1097] train: loss: 0.1381121
[Epoch 33; Iter   626/ 1097] train: loss: 0.0883127
[Epoch 33; Iter   656/ 1097] train: loss: 0.0220381
[Epoch 33; Iter   686/ 1097] train: loss: 0.0339606
[Epoch 33; Iter   716/ 1097] train: loss: 0.5597972
[Epoch 33; Iter   746/ 1097] train: loss: 0.1280227
[Epoch 33; Iter   776/ 1097] train: loss: 0.3466153
[Epoch 33; Iter   806/ 1097] train: loss: 0.0795023
[Epoch 33; Iter   836/ 1097] train: loss: 0.0441951
[Epoch 33; Iter   866/ 1097] train: loss: 0.1085914
[Epoch 33; Iter   896/ 1097] train: loss: 0.0270950
[Epoch 33; Iter   926/ 1097] train: loss: 0.1533280
[Epoch 33; Iter   956/ 1097] train: loss: 0.0383344
[Epoch 33; Iter   986/ 1097] train: loss: 0.2386112
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0726099
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0368469
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2074537
[Epoch 33] ogbg-molhiv: 0.855309 val loss: 0.072332
[Epoch 33] ogbg-molhiv: 0.760200 test loss: 0.122799
[Epoch 34; Iter     9/ 1097] train: loss: 0.0321055
[Epoch 34; Iter    39/ 1097] train: loss: 0.1004504
[Epoch 34; Iter    69/ 1097] train: loss: 0.0293484
[Epoch 34; Iter    99/ 1097] train: loss: 0.1204840
[Epoch 34; Iter   129/ 1097] train: loss: 0.0230459
[Epoch 34; Iter   159/ 1097] train: loss: 0.0430342
[Epoch 34; Iter   189/ 1097] train: loss: 0.0232263
[Epoch 34; Iter   219/ 1097] train: loss: 0.0409227
[Epoch 34; Iter   249/ 1097] train: loss: 0.1138022
[Epoch 34; Iter   279/ 1097] train: loss: 0.1031785
[Epoch 34; Iter   309/ 1097] train: loss: 0.0385329
[Epoch 34; Iter   339/ 1097] train: loss: 0.1210148
[Epoch 34; Iter   369/ 1097] train: loss: 0.0574152
[Epoch 34; Iter   399/ 1097] train: loss: 0.0277685
[Epoch 34; Iter   429/ 1097] train: loss: 0.0234318
[Epoch 34; Iter   459/ 1097] train: loss: 0.0533051
[Epoch 34; Iter   489/ 1097] train: loss: 0.0464982
[Epoch 34; Iter   519/ 1097] train: loss: 0.0210489
[Epoch 34; Iter   549/ 1097] train: loss: 0.0197189
[Epoch 34; Iter   579/ 1097] train: loss: 0.1865606
[Epoch 34; Iter   609/ 1097] train: loss: 0.0266600
[Epoch 34; Iter   639/ 1097] train: loss: 0.1032903
[Epoch 34; Iter   669/ 1097] train: loss: 0.1199203
[Epoch 34; Iter   699/ 1097] train: loss: 0.1398147
[Epoch 34; Iter   729/ 1097] train: loss: 0.0100582
[Epoch 34; Iter   759/ 1097] train: loss: 0.3729761
[Epoch 34; Iter   789/ 1097] train: loss: 0.0378798
[Epoch 34; Iter   819/ 1097] train: loss: 0.0198067
[Epoch 34; Iter   849/ 1097] train: loss: 0.3384888
[Epoch 34; Iter   879/ 1097] train: loss: 0.0306856
[Epoch 34; Iter   909/ 1097] train: loss: 0.0380772
[Epoch 34; Iter   939/ 1097] train: loss: 0.0508652
[Epoch 34; Iter   969/ 1097] train: loss: 0.1599563
[Epoch 34; Iter   999/ 1097] train: loss: 0.1244713
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1369059
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1204962
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0262303
[Epoch 34] ogbg-molhiv: 0.840134 val loss: 0.074943
[Epoch 34] ogbg-molhiv: 0.766322 test loss: 0.125169
[Epoch 35; Iter    22/ 1097] train: loss: 0.0150996
[Epoch 35; Iter    52/ 1097] train: loss: 0.0183026
[Epoch 35; Iter    82/ 1097] train: loss: 0.2271090
[Epoch 35; Iter   112/ 1097] train: loss: 0.1014856
[Epoch 35; Iter   142/ 1097] train: loss: 0.0245236
[Epoch 35; Iter   172/ 1097] train: loss: 0.0483541
[Epoch 35; Iter   202/ 1097] train: loss: 0.0806915
[Epoch 35; Iter   232/ 1097] train: loss: 0.0398666
[Epoch 35; Iter   262/ 1097] train: loss: 0.1042428
[Epoch 35; Iter   292/ 1097] train: loss: 0.0188235
[Epoch 35; Iter   322/ 1097] train: loss: 0.0250072
[Epoch 35; Iter   352/ 1097] train: loss: 0.0191183
[Epoch 35; Iter   382/ 1097] train: loss: 0.0186189
[Epoch 35; Iter   412/ 1097] train: loss: 0.0097833
[Epoch 35; Iter   442/ 1097] train: loss: 0.0876985
[Epoch 35; Iter   472/ 1097] train: loss: 0.0327966
[Epoch 35; Iter   502/ 1097] train: loss: 0.0199270
[Epoch 35; Iter   532/ 1097] train: loss: 0.0564038
[Epoch 35; Iter   562/ 1097] train: loss: 0.1627732
[Epoch 35; Iter   592/ 1097] train: loss: 0.0207267
[Epoch 35; Iter   622/ 1097] train: loss: 0.1373235
[Epoch 35; Iter   652/ 1097] train: loss: 0.0486551
[Epoch 35; Iter   682/ 1097] train: loss: 0.2720461
[Epoch 35; Iter   712/ 1097] train: loss: 0.1554998
[Epoch 35; Iter   742/ 1097] train: loss: 0.0528925
[Epoch 35; Iter   772/ 1097] train: loss: 0.0661116
[Epoch 35; Iter   802/ 1097] train: loss: 0.0179049
[Epoch 35; Iter   832/ 1097] train: loss: 0.0219796
[Epoch 35; Iter   862/ 1097] train: loss: 0.0515559
[Epoch 35; Iter   892/ 1097] train: loss: 0.1935598
[Epoch 35; Iter   922/ 1097] train: loss: 0.0189134
[Epoch 35; Iter   952/ 1097] train: loss: 0.0770249
[Epoch 35; Iter   982/ 1097] train: loss: 0.0334665
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0181522
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0454027
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0234823
[Epoch 35] ogbg-molhiv: 0.827862 val loss: 0.072798
[Epoch 35] ogbg-molhiv: 0.742954 test loss: 0.127626
[Epoch 36; Iter     5/ 1097] train: loss: 0.0331232
[Epoch 36; Iter    35/ 1097] train: loss: 0.0348227
[Epoch 36; Iter    65/ 1097] train: loss: 0.0354898
[Epoch 36; Iter    95/ 1097] train: loss: 0.1231457
[Epoch 36; Iter   125/ 1097] train: loss: 0.0400340
[Epoch 36; Iter   155/ 1097] train: loss: 0.0511179
[Epoch 36; Iter   185/ 1097] train: loss: 0.1013116
[Epoch 36; Iter   215/ 1097] train: loss: 0.0379079
[Epoch 36; Iter   245/ 1097] train: loss: 0.2676139
[Epoch 36; Iter   275/ 1097] train: loss: 0.0572632
[Epoch 36; Iter   305/ 1097] train: loss: 0.0146171
[Epoch 36; Iter   335/ 1097] train: loss: 0.1471972
[Epoch 36; Iter   365/ 1097] train: loss: 0.3166661
[Epoch 36; Iter   395/ 1097] train: loss: 0.0175102
[Epoch 36; Iter   425/ 1097] train: loss: 0.0926669
[Epoch 36; Iter   455/ 1097] train: loss: 0.0429966
[Epoch 36; Iter   485/ 1097] train: loss: 0.0255005
[Epoch 36; Iter   515/ 1097] train: loss: 0.2910910
[Epoch 36; Iter   545/ 1097] train: loss: 0.2411643
[Epoch 36; Iter   575/ 1097] train: loss: 0.1905834
[Epoch 40; Iter   687/ 1097] train: loss: 0.0020299
[Epoch 40; Iter   717/ 1097] train: loss: 0.0094354
[Epoch 40; Iter   747/ 1097] train: loss: 0.1557576
[Epoch 40; Iter   777/ 1097] train: loss: 0.0124622
[Epoch 40; Iter   807/ 1097] train: loss: 0.0053340
[Epoch 40; Iter   837/ 1097] train: loss: 0.0249825
[Epoch 40; Iter   867/ 1097] train: loss: 0.0211964
[Epoch 40; Iter   897/ 1097] train: loss: 0.0004401
[Epoch 40; Iter   927/ 1097] train: loss: 0.1373670
[Epoch 40; Iter   957/ 1097] train: loss: 0.1978582
[Epoch 40; Iter   987/ 1097] train: loss: 0.0008811
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0065018
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0004763
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0061124
[Epoch 40] ogbg-molhiv: 0.729966 val loss: 0.239120
[Epoch 40] ogbg-molhiv: 0.693893 test loss: 0.293511
[Epoch 41; Iter    10/ 1097] train: loss: 0.0180998
[Epoch 41; Iter    40/ 1097] train: loss: 0.0006664
[Epoch 41; Iter    70/ 1097] train: loss: 0.0121772
[Epoch 41; Iter   100/ 1097] train: loss: 0.0004921
[Epoch 41; Iter   130/ 1097] train: loss: 0.0033039
[Epoch 41; Iter   160/ 1097] train: loss: 0.0005000
[Epoch 41; Iter   190/ 1097] train: loss: 0.0107096
[Epoch 41; Iter   220/ 1097] train: loss: 0.0030828
[Epoch 41; Iter   250/ 1097] train: loss: 0.0009705
[Epoch 41; Iter   280/ 1097] train: loss: 0.0009788
[Epoch 41; Iter   310/ 1097] train: loss: 0.0223475
[Epoch 41; Iter   340/ 1097] train: loss: 0.0762286
[Epoch 41; Iter   370/ 1097] train: loss: 0.0152471
[Epoch 41; Iter   400/ 1097] train: loss: 0.0066201
[Epoch 41; Iter   430/ 1097] train: loss: 0.0142381
[Epoch 41; Iter   460/ 1097] train: loss: 0.0033897
[Epoch 41; Iter   490/ 1097] train: loss: 0.0103256
[Epoch 41; Iter   520/ 1097] train: loss: 0.0030984
[Epoch 41; Iter   550/ 1097] train: loss: 0.0041841
[Epoch 41; Iter   580/ 1097] train: loss: 0.0097323
[Epoch 41; Iter   610/ 1097] train: loss: 0.0199173
[Epoch 41; Iter   640/ 1097] train: loss: 0.0035099
[Epoch 41; Iter   670/ 1097] train: loss: 0.0027945
[Epoch 41; Iter   700/ 1097] train: loss: 0.0067961
[Epoch 41; Iter   730/ 1097] train: loss: 0.0008729
[Epoch 41; Iter   760/ 1097] train: loss: 0.0038550
[Epoch 41; Iter   790/ 1097] train: loss: 0.0184475
[Epoch 41; Iter   820/ 1097] train: loss: 0.0024316
[Epoch 41; Iter   850/ 1097] train: loss: 0.0020349
[Epoch 41; Iter   880/ 1097] train: loss: 0.0017676
[Epoch 41; Iter   910/ 1097] train: loss: 0.0188325
[Epoch 41; Iter   940/ 1097] train: loss: 0.0110883
[Epoch 41; Iter   970/ 1097] train: loss: 0.0650954
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0036021
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0354080
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0066361
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0013144
[Epoch 41] ogbg-molhiv: 0.773761 val loss: 0.177083
[Epoch 41] ogbg-molhiv: 0.768912 test loss: 0.286373
[Epoch 42; Iter    23/ 1097] train: loss: 0.0999993
[Epoch 42; Iter    53/ 1097] train: loss: 0.0275441
[Epoch 42; Iter    83/ 1097] train: loss: 0.0127188
[Epoch 42; Iter   113/ 1097] train: loss: 0.0020933
[Epoch 42; Iter   143/ 1097] train: loss: 0.0214897
[Epoch 42; Iter   173/ 1097] train: loss: 0.0157526
[Epoch 42; Iter   203/ 1097] train: loss: 0.0051974
[Epoch 42; Iter   233/ 1097] train: loss: 0.0440228
[Epoch 42; Iter   263/ 1097] train: loss: 0.1059636
[Epoch 42; Iter   293/ 1097] train: loss: 0.0028480
[Epoch 42; Iter   323/ 1097] train: loss: 0.0029559
[Epoch 42; Iter   353/ 1097] train: loss: 0.0212829
[Epoch 42; Iter   383/ 1097] train: loss: 0.0055822
[Epoch 42; Iter   413/ 1097] train: loss: 0.0146400
[Epoch 42; Iter   443/ 1097] train: loss: 0.1308322
[Epoch 42; Iter   473/ 1097] train: loss: 0.0064173
[Epoch 42; Iter   503/ 1097] train: loss: 0.0067989
[Epoch 42; Iter   533/ 1097] train: loss: 0.0075121
[Epoch 42; Iter   563/ 1097] train: loss: 0.0253053
[Epoch 42; Iter   593/ 1097] train: loss: 0.0233801
[Epoch 42; Iter   623/ 1097] train: loss: 0.0053412
[Epoch 42; Iter   653/ 1097] train: loss: 0.0268108
[Epoch 42; Iter   683/ 1097] train: loss: 0.0004738
[Epoch 42; Iter   713/ 1097] train: loss: 0.0062350
[Epoch 42; Iter   743/ 1097] train: loss: 0.0426737
[Epoch 42; Iter   773/ 1097] train: loss: 0.1822705
[Epoch 42; Iter   803/ 1097] train: loss: 0.0176780
[Epoch 42; Iter   833/ 1097] train: loss: 0.0066851
[Epoch 42; Iter   863/ 1097] train: loss: 0.0047820
[Epoch 42; Iter   893/ 1097] train: loss: 0.0108526
[Epoch 42; Iter   923/ 1097] train: loss: 0.0129342
[Epoch 42; Iter   953/ 1097] train: loss: 0.0976556
[Epoch 42; Iter   983/ 1097] train: loss: 0.0068092
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1022457
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0031784
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0085787
[Epoch 42] ogbg-molhiv: 0.762416 val loss: 0.334886
[Epoch 42] ogbg-molhiv: 0.711594 test loss: 0.273576
[Epoch 43; Iter     6/ 1097] train: loss: 0.0064964
[Epoch 43; Iter    36/ 1097] train: loss: 0.0035907
[Epoch 43; Iter    66/ 1097] train: loss: 0.0592671
[Epoch 43; Iter    96/ 1097] train: loss: 0.0035659
[Epoch 43; Iter   126/ 1097] train: loss: 0.0051435
[Epoch 43; Iter   156/ 1097] train: loss: 0.1409476
[Epoch 43; Iter   186/ 1097] train: loss: 0.0116370
[Epoch 43; Iter   216/ 1097] train: loss: 0.0013237
[Epoch 43; Iter   246/ 1097] train: loss: 0.1414429
[Epoch 43; Iter   276/ 1097] train: loss: 0.0205645
[Epoch 43; Iter   306/ 1097] train: loss: 0.0010015
[Epoch 43; Iter   336/ 1097] train: loss: 0.0245481
[Epoch 43; Iter   366/ 1097] train: loss: 0.0027003
[Epoch 43; Iter   396/ 1097] train: loss: 0.0302411
[Epoch 43; Iter   426/ 1097] train: loss: 0.0006082
[Epoch 43; Iter   456/ 1097] train: loss: 0.0082664
[Epoch 43; Iter   486/ 1097] train: loss: 0.0237976
[Epoch 43; Iter   516/ 1097] train: loss: 0.0047338
[Epoch 43; Iter   546/ 1097] train: loss: 0.0018463
[Epoch 43; Iter   576/ 1097] train: loss: 0.0109220
[Epoch 43; Iter   606/ 1097] train: loss: 0.0010694
[Epoch 43; Iter   636/ 1097] train: loss: 0.0006023
[Epoch 43; Iter   666/ 1097] train: loss: 0.0014313
[Epoch 43; Iter   696/ 1097] train: loss: 0.0100439
[Epoch 43; Iter   726/ 1097] train: loss: 0.0005121
[Epoch 43; Iter   756/ 1097] train: loss: 0.0543572
[Epoch 43; Iter   786/ 1097] train: loss: 0.0041439
[Epoch 43; Iter   816/ 1097] train: loss: 0.0101829
[Epoch 43; Iter   846/ 1097] train: loss: 0.0025397
[Epoch 43; Iter   876/ 1097] train: loss: 0.0007396
[Epoch 43; Iter   906/ 1097] train: loss: 0.0006511
[Epoch 43; Iter   936/ 1097] train: loss: 0.0014563
[Epoch 43; Iter   966/ 1097] train: loss: 0.0164820
[Epoch 43; Iter   996/ 1097] train: loss: 0.0213485
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0012002
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0879811
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0015260
[Epoch 43] ogbg-molhiv: 0.754075 val loss: 0.230129
[Epoch 43] ogbg-molhiv: 0.697511 test loss: 0.334985
[Epoch 44; Iter    19/ 1097] train: loss: 0.0053949
[Epoch 44; Iter    49/ 1097] train: loss: 0.0152005
[Epoch 44; Iter    79/ 1097] train: loss: 0.0029928
[Epoch 44; Iter   109/ 1097] train: loss: 0.0047065
[Epoch 44; Iter   139/ 1097] train: loss: 0.0077579
[Epoch 44; Iter   169/ 1097] train: loss: 0.0112220
[Epoch 44; Iter   199/ 1097] train: loss: 0.0033724
[Epoch 44; Iter   229/ 1097] train: loss: 0.0012684
[Epoch 44; Iter   259/ 1097] train: loss: 0.0011650
[Epoch 44; Iter   289/ 1097] train: loss: 0.0057181
[Epoch 44; Iter   319/ 1097] train: loss: 0.0300306
[Epoch 44; Iter   349/ 1097] train: loss: 0.0012568
[Epoch 44; Iter   379/ 1097] train: loss: 0.0031209
[Epoch 44; Iter   409/ 1097] train: loss: 0.0333255
[Epoch 44; Iter   439/ 1097] train: loss: 0.0007199
[Epoch 44; Iter   469/ 1097] train: loss: 0.0035677
[Epoch 44; Iter   499/ 1097] train: loss: 0.0010945
[Epoch 44; Iter   529/ 1097] train: loss: 0.0019593
[Epoch 44; Iter   559/ 1097] train: loss: 0.0097941
[Epoch 44; Iter   589/ 1097] train: loss: 0.0028113
[Epoch 44; Iter   619/ 1097] train: loss: 0.0099929
[Epoch 44; Iter   649/ 1097] train: loss: 0.0297017
[Epoch 44; Iter   679/ 1097] train: loss: 0.0077025
[Epoch 44; Iter   709/ 1097] train: loss: 0.0065556
[Epoch 44; Iter   739/ 1097] train: loss: 0.0029956
[Epoch 40; Iter   687/ 1097] train: loss: 0.0367684
[Epoch 40; Iter   717/ 1097] train: loss: 0.0005188
[Epoch 40; Iter   747/ 1097] train: loss: 0.0098023
[Epoch 40; Iter   777/ 1097] train: loss: 0.0475162
[Epoch 40; Iter   807/ 1097] train: loss: 0.0502721
[Epoch 40; Iter   837/ 1097] train: loss: 0.0055115
[Epoch 40; Iter   867/ 1097] train: loss: 0.0019948
[Epoch 40; Iter   897/ 1097] train: loss: 0.0090431
[Epoch 40; Iter   927/ 1097] train: loss: 0.0423329
[Epoch 40; Iter   957/ 1097] train: loss: 0.0056611
[Epoch 40; Iter   987/ 1097] train: loss: 0.0019025
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0089031
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0429347
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0052103
[Epoch 40] ogbg-molhiv: 0.760355 val loss: 0.205969
[Epoch 40] ogbg-molhiv: 0.738448 test loss: 0.292805
[Epoch 41; Iter    10/ 1097] train: loss: 0.0138389
[Epoch 41; Iter    40/ 1097] train: loss: 0.0051246
[Epoch 41; Iter    70/ 1097] train: loss: 0.0101797
[Epoch 41; Iter   100/ 1097] train: loss: 0.0061862
[Epoch 41; Iter   130/ 1097] train: loss: 0.0217174
[Epoch 41; Iter   160/ 1097] train: loss: 0.0303550
[Epoch 41; Iter   190/ 1097] train: loss: 0.0121053
[Epoch 41; Iter   220/ 1097] train: loss: 0.0279576
[Epoch 41; Iter   250/ 1097] train: loss: 0.0078176
[Epoch 41; Iter   280/ 1097] train: loss: 0.0061872
[Epoch 41; Iter   310/ 1097] train: loss: 0.0722159
[Epoch 41; Iter   340/ 1097] train: loss: 0.0015549
[Epoch 41; Iter   370/ 1097] train: loss: 0.0311918
[Epoch 41; Iter   400/ 1097] train: loss: 0.0029696
[Epoch 41; Iter   430/ 1097] train: loss: 0.0378074
[Epoch 41; Iter   460/ 1097] train: loss: 0.0012669
[Epoch 41; Iter   490/ 1097] train: loss: 0.1643275
[Epoch 41; Iter   520/ 1097] train: loss: 0.0014612
[Epoch 41; Iter   550/ 1097] train: loss: 0.0043860
[Epoch 41; Iter   580/ 1097] train: loss: 0.0026939
[Epoch 41; Iter   610/ 1097] train: loss: 0.0017560
[Epoch 41; Iter   640/ 1097] train: loss: 0.0012956
[Epoch 41; Iter   670/ 1097] train: loss: 0.0459892
[Epoch 41; Iter   700/ 1097] train: loss: 0.0048301
[Epoch 41; Iter   730/ 1097] train: loss: 0.0087351
[Epoch 41; Iter   760/ 1097] train: loss: 0.0124175
[Epoch 41; Iter   790/ 1097] train: loss: 0.1939339
[Epoch 41; Iter   820/ 1097] train: loss: 0.0027634
[Epoch 41; Iter   850/ 1097] train: loss: 0.0009494
[Epoch 41; Iter   880/ 1097] train: loss: 0.0102288
[Epoch 41; Iter   910/ 1097] train: loss: 0.0048340
[Epoch 41; Iter   940/ 1097] train: loss: 0.0954153
[Epoch 41; Iter   970/ 1097] train: loss: 0.0020385
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0387982
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0213609
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0014936
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0508687
[Epoch 41] ogbg-molhiv: 0.784747 val loss: 0.181668
[Epoch 41] ogbg-molhiv: 0.737042 test loss: 0.346405
[Epoch 42; Iter    23/ 1097] train: loss: 0.0018633
[Epoch 42; Iter    53/ 1097] train: loss: 0.0142658
[Epoch 42; Iter    83/ 1097] train: loss: 0.0025830
[Epoch 42; Iter   113/ 1097] train: loss: 0.0011803
[Epoch 42; Iter   143/ 1097] train: loss: 0.0600323
[Epoch 42; Iter   173/ 1097] train: loss: 0.0499275
[Epoch 42; Iter   203/ 1097] train: loss: 0.0041582
[Epoch 42; Iter   233/ 1097] train: loss: 0.0015601
[Epoch 42; Iter   263/ 1097] train: loss: 0.0163012
[Epoch 42; Iter   293/ 1097] train: loss: 0.0004124
[Epoch 42; Iter   323/ 1097] train: loss: 0.0245518
[Epoch 42; Iter   353/ 1097] train: loss: 0.0093854
[Epoch 42; Iter   383/ 1097] train: loss: 0.0335356
[Epoch 42; Iter   413/ 1097] train: loss: 0.0259729
[Epoch 42; Iter   443/ 1097] train: loss: 0.0037607
[Epoch 42; Iter   473/ 1097] train: loss: 0.0908039
[Epoch 42; Iter   503/ 1097] train: loss: 0.0828294
[Epoch 42; Iter   533/ 1097] train: loss: 0.0044964
[Epoch 42; Iter   563/ 1097] train: loss: 0.0006483
[Epoch 42; Iter   593/ 1097] train: loss: 0.0126346
[Epoch 42; Iter   623/ 1097] train: loss: 0.0073560
[Epoch 42; Iter   653/ 1097] train: loss: 0.0655147
[Epoch 42; Iter   683/ 1097] train: loss: 0.0018784
[Epoch 42; Iter   713/ 1097] train: loss: 0.0092004
[Epoch 42; Iter   743/ 1097] train: loss: 0.0069569
[Epoch 42; Iter   773/ 1097] train: loss: 0.0027008
[Epoch 42; Iter   803/ 1097] train: loss: 0.0015162
[Epoch 42; Iter   833/ 1097] train: loss: 0.0008286
[Epoch 42; Iter   863/ 1097] train: loss: 0.0009858
[Epoch 42; Iter   893/ 1097] train: loss: 0.0065883
[Epoch 42; Iter   923/ 1097] train: loss: 0.0056715
[Epoch 42; Iter   953/ 1097] train: loss: 0.0020226
[Epoch 42; Iter   983/ 1097] train: loss: 0.0465847
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0073334
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0237684
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0111587
[Epoch 42] ogbg-molhiv: 0.784073 val loss: 0.224886
[Epoch 42] ogbg-molhiv: 0.731511 test loss: 0.281954
[Epoch 43; Iter     6/ 1097] train: loss: 0.0267476
[Epoch 43; Iter    36/ 1097] train: loss: 0.0059806
[Epoch 43; Iter    66/ 1097] train: loss: 0.0209615
[Epoch 43; Iter    96/ 1097] train: loss: 0.0038997
[Epoch 43; Iter   126/ 1097] train: loss: 0.0016937
[Epoch 43; Iter   156/ 1097] train: loss: 0.0348385
[Epoch 43; Iter   186/ 1097] train: loss: 0.0056590
[Epoch 43; Iter   216/ 1097] train: loss: 0.0654568
[Epoch 43; Iter   246/ 1097] train: loss: 0.0011548
[Epoch 43; Iter   276/ 1097] train: loss: 0.0975703
[Epoch 43; Iter   306/ 1097] train: loss: 0.0315920
[Epoch 43; Iter   336/ 1097] train: loss: 0.0797001
[Epoch 43; Iter   366/ 1097] train: loss: 0.0076682
[Epoch 43; Iter   396/ 1097] train: loss: 0.0153168
[Epoch 43; Iter   426/ 1097] train: loss: 0.0016843
[Epoch 43; Iter   456/ 1097] train: loss: 0.0536277
[Epoch 43; Iter   486/ 1097] train: loss: 0.0036742
[Epoch 43; Iter   516/ 1097] train: loss: 0.0199228
[Epoch 43; Iter   546/ 1097] train: loss: 0.0025048
[Epoch 43; Iter   576/ 1097] train: loss: 0.0075371
[Epoch 43; Iter   606/ 1097] train: loss: 0.0766320
[Epoch 43; Iter   636/ 1097] train: loss: 0.0031648
[Epoch 43; Iter   666/ 1097] train: loss: 0.0010797
[Epoch 43; Iter   696/ 1097] train: loss: 0.0123111
[Epoch 43; Iter   726/ 1097] train: loss: 0.0021438
[Epoch 43; Iter   756/ 1097] train: loss: 0.0112321
[Epoch 43; Iter   786/ 1097] train: loss: 0.0146551
[Epoch 43; Iter   816/ 1097] train: loss: 0.0003843
[Epoch 43; Iter   846/ 1097] train: loss: 0.1103449
[Epoch 43; Iter   876/ 1097] train: loss: 0.0870213
[Epoch 43; Iter   906/ 1097] train: loss: 0.0073599
[Epoch 43; Iter   936/ 1097] train: loss: 0.0260640
[Epoch 43; Iter   966/ 1097] train: loss: 0.0039244
[Epoch 43; Iter   996/ 1097] train: loss: 0.0011801
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0000804
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0558951
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0008810
[Epoch 43] ogbg-molhiv: 0.764143 val loss: 0.201234
[Epoch 43] ogbg-molhiv: 0.736781 test loss: 0.298263
[Epoch 44; Iter    19/ 1097] train: loss: 0.0014537
[Epoch 44; Iter    49/ 1097] train: loss: 0.0071670
[Epoch 44; Iter    79/ 1097] train: loss: 0.0043957
[Epoch 44; Iter   109/ 1097] train: loss: 0.0019711
[Epoch 44; Iter   139/ 1097] train: loss: 0.0005411
[Epoch 44; Iter   169/ 1097] train: loss: 0.0080701
[Epoch 44; Iter   199/ 1097] train: loss: 0.0005271
[Epoch 44; Iter   229/ 1097] train: loss: 0.0094782
[Epoch 44; Iter   259/ 1097] train: loss: 0.0012968
[Epoch 44; Iter   289/ 1097] train: loss: 0.0097657
[Epoch 44; Iter   319/ 1097] train: loss: 0.0016650
[Epoch 44; Iter   349/ 1097] train: loss: 0.0583970
[Epoch 44; Iter   379/ 1097] train: loss: 0.0043821
[Epoch 44; Iter   409/ 1097] train: loss: 0.0259144
[Epoch 44; Iter   439/ 1097] train: loss: 0.0035666
[Epoch 44; Iter   469/ 1097] train: loss: 0.0196679
[Epoch 44; Iter   499/ 1097] train: loss: 0.1121985
[Epoch 44; Iter   529/ 1097] train: loss: 0.1579777
[Epoch 44; Iter   559/ 1097] train: loss: 0.0227036
[Epoch 44; Iter   589/ 1097] train: loss: 0.0009781
[Epoch 44; Iter   619/ 1097] train: loss: 0.0117495
[Epoch 44; Iter   649/ 1097] train: loss: 0.0401800
[Epoch 44; Iter   679/ 1097] train: loss: 0.0862603
[Epoch 44; Iter   709/ 1097] train: loss: 0.0061406
[Epoch 44; Iter   739/ 1097] train: loss: 0.0012914
[Epoch 40; Iter   687/ 1097] train: loss: 0.0535013
[Epoch 40; Iter   717/ 1097] train: loss: 0.0224862
[Epoch 40; Iter   747/ 1097] train: loss: 0.0139645
[Epoch 40; Iter   777/ 1097] train: loss: 0.1420504
[Epoch 40; Iter   807/ 1097] train: loss: 0.0124551
[Epoch 40; Iter   837/ 1097] train: loss: 0.0198021
[Epoch 40; Iter   867/ 1097] train: loss: 0.0171774
[Epoch 40; Iter   897/ 1097] train: loss: 0.0075834
[Epoch 40; Iter   927/ 1097] train: loss: 0.0019019
[Epoch 40; Iter   957/ 1097] train: loss: 0.0213893
[Epoch 40; Iter   987/ 1097] train: loss: 0.0019562
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0119072
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0159737
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1350541
[Epoch 40] ogbg-molhiv: 0.713640 val loss: 1.619900
[Epoch 40] ogbg-molhiv: 0.678306 test loss: 0.750488
[Epoch 41; Iter    10/ 1097] train: loss: 0.0064248
[Epoch 41; Iter    40/ 1097] train: loss: 0.0326103
[Epoch 41; Iter    70/ 1097] train: loss: 0.0073722
[Epoch 41; Iter   100/ 1097] train: loss: 0.1472291
[Epoch 41; Iter   130/ 1097] train: loss: 0.0102062
[Epoch 41; Iter   160/ 1097] train: loss: 0.0981064
[Epoch 41; Iter   190/ 1097] train: loss: 0.0583762
[Epoch 41; Iter   220/ 1097] train: loss: 0.0026980
[Epoch 41; Iter   250/ 1097] train: loss: 0.0062563
[Epoch 41; Iter   280/ 1097] train: loss: 0.2154013
[Epoch 41; Iter   310/ 1097] train: loss: 0.0130822
[Epoch 41; Iter   340/ 1097] train: loss: 0.0455726
[Epoch 41; Iter   370/ 1097] train: loss: 0.0027877
[Epoch 41; Iter   400/ 1097] train: loss: 0.0094484
[Epoch 41; Iter   430/ 1097] train: loss: 0.0025357
[Epoch 41; Iter   460/ 1097] train: loss: 0.0043486
[Epoch 41; Iter   490/ 1097] train: loss: 0.0698348
[Epoch 41; Iter   520/ 1097] train: loss: 0.0122347
[Epoch 41; Iter   550/ 1097] train: loss: 0.0361962
[Epoch 41; Iter   580/ 1097] train: loss: 0.0130213
[Epoch 41; Iter   610/ 1097] train: loss: 0.0689146
[Epoch 41; Iter   640/ 1097] train: loss: 0.0068862
[Epoch 41; Iter   670/ 1097] train: loss: 0.0032953
[Epoch 41; Iter   700/ 1097] train: loss: 0.0098074
[Epoch 41; Iter   730/ 1097] train: loss: 0.0283773
[Epoch 41; Iter   760/ 1097] train: loss: 0.0052239
[Epoch 41; Iter   790/ 1097] train: loss: 0.0623915
[Epoch 41; Iter   820/ 1097] train: loss: 0.0057649
[Epoch 41; Iter   850/ 1097] train: loss: 0.1041486
[Epoch 41; Iter   880/ 1097] train: loss: 0.0107528
[Epoch 41; Iter   910/ 1097] train: loss: 0.0168410
[Epoch 41; Iter   940/ 1097] train: loss: 0.0056258
[Epoch 41; Iter   970/ 1097] train: loss: 0.0055729
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0108324
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0691471
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0216869
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0166780
[Epoch 41] ogbg-molhiv: 0.718352 val loss: 1.297984
[Epoch 41] ogbg-molhiv: 0.720898 test loss: 0.494835
[Epoch 42; Iter    23/ 1097] train: loss: 0.0011369
[Epoch 42; Iter    53/ 1097] train: loss: 0.0259620
[Epoch 42; Iter    83/ 1097] train: loss: 0.0042897
[Epoch 42; Iter   113/ 1097] train: loss: 0.0064595
[Epoch 42; Iter   143/ 1097] train: loss: 0.0031361
[Epoch 42; Iter   173/ 1097] train: loss: 0.0036045
[Epoch 42; Iter   203/ 1097] train: loss: 0.0566320
[Epoch 42; Iter   233/ 1097] train: loss: 0.0852967
[Epoch 42; Iter   263/ 1097] train: loss: 0.0081072
[Epoch 42; Iter   293/ 1097] train: loss: 0.0053983
[Epoch 42; Iter   323/ 1097] train: loss: 0.1259718
[Epoch 42; Iter   353/ 1097] train: loss: 0.0019489
[Epoch 42; Iter   383/ 1097] train: loss: 0.0109983
[Epoch 42; Iter   413/ 1097] train: loss: 0.0041364
[Epoch 42; Iter   443/ 1097] train: loss: 0.0058882
[Epoch 42; Iter   473/ 1097] train: loss: 0.0571048
[Epoch 42; Iter   503/ 1097] train: loss: 0.0670762
[Epoch 42; Iter   533/ 1097] train: loss: 0.0117362
[Epoch 42; Iter   563/ 1097] train: loss: 0.0035074
[Epoch 42; Iter   593/ 1097] train: loss: 0.0067535
[Epoch 42; Iter   623/ 1097] train: loss: 0.0053878
[Epoch 42; Iter   653/ 1097] train: loss: 0.0152310
[Epoch 42; Iter   683/ 1097] train: loss: 0.0242316
[Epoch 42; Iter   713/ 1097] train: loss: 0.0047621
[Epoch 42; Iter   743/ 1097] train: loss: 0.0108832
[Epoch 42; Iter   773/ 1097] train: loss: 0.0946104
[Epoch 42; Iter   803/ 1097] train: loss: 0.0109648
[Epoch 42; Iter   833/ 1097] train: loss: 0.0074165
[Epoch 42; Iter   863/ 1097] train: loss: 0.0329428
[Epoch 42; Iter   893/ 1097] train: loss: 0.0075983
[Epoch 42; Iter   923/ 1097] train: loss: 0.0321626
[Epoch 42; Iter   953/ 1097] train: loss: 0.0013198
[Epoch 42; Iter   983/ 1097] train: loss: 0.0028349
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0114436
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0209039
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0034043
[Epoch 42] ogbg-molhiv: 0.705023 val loss: 1.471724
[Epoch 42] ogbg-molhiv: 0.724373 test loss: 0.428271
[Epoch 43; Iter     6/ 1097] train: loss: 0.0087321
[Epoch 43; Iter    36/ 1097] train: loss: 0.0025348
[Epoch 43; Iter    66/ 1097] train: loss: 0.0984491
[Epoch 43; Iter    96/ 1097] train: loss: 0.0082504
[Epoch 43; Iter   126/ 1097] train: loss: 0.0097186
[Epoch 43; Iter   156/ 1097] train: loss: 0.0298775
[Epoch 43; Iter   186/ 1097] train: loss: 0.0222562
[Epoch 43; Iter   216/ 1097] train: loss: 0.0078771
[Epoch 43; Iter   246/ 1097] train: loss: 0.0131240
[Epoch 43; Iter   276/ 1097] train: loss: 0.0021799
[Epoch 43; Iter   306/ 1097] train: loss: 0.0475985
[Epoch 43; Iter   336/ 1097] train: loss: 0.0014410
[Epoch 43; Iter   366/ 1097] train: loss: 0.0141834
[Epoch 43; Iter   396/ 1097] train: loss: 0.0013756
[Epoch 43; Iter   426/ 1097] train: loss: 0.1237442
[Epoch 43; Iter   456/ 1097] train: loss: 0.0167888
[Epoch 43; Iter   486/ 1097] train: loss: 0.0167930
[Epoch 43; Iter   516/ 1097] train: loss: 0.0041854
[Epoch 43; Iter   546/ 1097] train: loss: 0.1298681
[Epoch 43; Iter   576/ 1097] train: loss: 0.0026981
[Epoch 43; Iter   606/ 1097] train: loss: 0.0126223
[Epoch 43; Iter   636/ 1097] train: loss: 0.0778132
[Epoch 43; Iter   666/ 1097] train: loss: 0.0021741
[Epoch 43; Iter   696/ 1097] train: loss: 0.0163097
[Epoch 43; Iter   726/ 1097] train: loss: 0.0019891
[Epoch 43; Iter   756/ 1097] train: loss: 0.0955666
[Epoch 43; Iter   786/ 1097] train: loss: 0.0724656
[Epoch 43; Iter   816/ 1097] train: loss: 0.0738634
[Epoch 43; Iter   846/ 1097] train: loss: 0.0984535
[Epoch 43; Iter   876/ 1097] train: loss: 0.1002776
[Epoch 43; Iter   906/ 1097] train: loss: 0.0315560
[Epoch 43; Iter   936/ 1097] train: loss: 0.0058585
[Epoch 43; Iter   966/ 1097] train: loss: 0.0474191
[Epoch 43; Iter   996/ 1097] train: loss: 0.0096978
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0940886
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0316627
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0100294
[Epoch 43] ogbg-molhiv: 0.686630 val loss: 0.359684
[Epoch 43] ogbg-molhiv: 0.717770 test loss: 0.577365
[Epoch 44; Iter    19/ 1097] train: loss: 0.0049283
[Epoch 44; Iter    49/ 1097] train: loss: 0.0037935
[Epoch 44; Iter    79/ 1097] train: loss: 0.0049041
[Epoch 44; Iter   109/ 1097] train: loss: 0.0090002
[Epoch 44; Iter   139/ 1097] train: loss: 0.0070271
[Epoch 44; Iter   169/ 1097] train: loss: 0.0474044
[Epoch 44; Iter   199/ 1097] train: loss: 0.0328979
[Epoch 44; Iter   229/ 1097] train: loss: 0.0438256
[Epoch 44; Iter   259/ 1097] train: loss: 0.0151924
[Epoch 44; Iter   289/ 1097] train: loss: 0.0340014
[Epoch 44; Iter   319/ 1097] train: loss: 0.0639348
[Epoch 44; Iter   349/ 1097] train: loss: 0.0305949
[Epoch 44; Iter   379/ 1097] train: loss: 0.0045765
[Epoch 44; Iter   409/ 1097] train: loss: 0.0016411
[Epoch 44; Iter   439/ 1097] train: loss: 0.0044643
[Epoch 44; Iter   469/ 1097] train: loss: 0.0297083
[Epoch 44; Iter   499/ 1097] train: loss: 0.0081538
[Epoch 44; Iter   529/ 1097] train: loss: 0.0012318
[Epoch 44; Iter   559/ 1097] train: loss: 0.0035301
[Epoch 44; Iter   589/ 1097] train: loss: 0.0027663
[Epoch 44; Iter   619/ 1097] train: loss: 0.0024281
[Epoch 44; Iter   649/ 1097] train: loss: 0.0030052
[Epoch 44; Iter   679/ 1097] train: loss: 0.0727629
[Epoch 44; Iter   709/ 1097] train: loss: 0.0034295
[Epoch 44; Iter   739/ 1097] train: loss: 0.0013237
[Epoch 40; Iter   687/ 1097] train: loss: 0.0078822
[Epoch 40; Iter   717/ 1097] train: loss: 0.0005994
[Epoch 40; Iter   747/ 1097] train: loss: 0.0281255
[Epoch 40; Iter   777/ 1097] train: loss: 0.1061713
[Epoch 40; Iter   807/ 1097] train: loss: 0.0214267
[Epoch 40; Iter   837/ 1097] train: loss: 0.0025033
[Epoch 40; Iter   867/ 1097] train: loss: 0.0018577
[Epoch 40; Iter   897/ 1097] train: loss: 0.0009674
[Epoch 40; Iter   927/ 1097] train: loss: 0.1548075
[Epoch 40; Iter   957/ 1097] train: loss: 0.2438392
[Epoch 40; Iter   987/ 1097] train: loss: 0.0844915
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0020832
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0024741
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0217676
[Epoch 40] ogbg-molhiv: 0.780803 val loss: 0.134811
[Epoch 40] ogbg-molhiv: 0.710216 test loss: 0.246265
[Epoch 41; Iter    10/ 1097] train: loss: 0.0007358
[Epoch 41; Iter    40/ 1097] train: loss: 0.0985848
[Epoch 41; Iter    70/ 1097] train: loss: 0.0018527
[Epoch 41; Iter   100/ 1097] train: loss: 0.0003502
[Epoch 41; Iter   130/ 1097] train: loss: 0.0046372
[Epoch 41; Iter   160/ 1097] train: loss: 0.0773222
[Epoch 41; Iter   190/ 1097] train: loss: 0.0040775
[Epoch 41; Iter   220/ 1097] train: loss: 0.0015724
[Epoch 41; Iter   250/ 1097] train: loss: 0.0193068
[Epoch 41; Iter   280/ 1097] train: loss: 0.1665142
[Epoch 41; Iter   310/ 1097] train: loss: 0.0606183
[Epoch 41; Iter   340/ 1097] train: loss: 0.0120135
[Epoch 41; Iter   370/ 1097] train: loss: 0.0012060
[Epoch 41; Iter   400/ 1097] train: loss: 0.0309999
[Epoch 41; Iter   430/ 1097] train: loss: 0.0093520
[Epoch 41; Iter   460/ 1097] train: loss: 0.0219435
[Epoch 41; Iter   490/ 1097] train: loss: 0.0034237
[Epoch 41; Iter   520/ 1097] train: loss: 0.0014950
[Epoch 41; Iter   550/ 1097] train: loss: 0.0005972
[Epoch 41; Iter   580/ 1097] train: loss: 0.0009415
[Epoch 41; Iter   610/ 1097] train: loss: 0.0077293
[Epoch 41; Iter   640/ 1097] train: loss: 0.0039238
[Epoch 41; Iter   670/ 1097] train: loss: 0.0014304
[Epoch 41; Iter   700/ 1097] train: loss: 0.0052238
[Epoch 41; Iter   730/ 1097] train: loss: 0.0005741
[Epoch 41; Iter   760/ 1097] train: loss: 0.0040614
[Epoch 41; Iter   790/ 1097] train: loss: 0.0132490
[Epoch 41; Iter   820/ 1097] train: loss: 0.0036914
[Epoch 41; Iter   850/ 1097] train: loss: 0.0318529
[Epoch 41; Iter   880/ 1097] train: loss: 0.0027464
[Epoch 41; Iter   910/ 1097] train: loss: 0.0012684
[Epoch 41; Iter   940/ 1097] train: loss: 0.0098527
[Epoch 41; Iter   970/ 1097] train: loss: 0.0025850
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0543145
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0006954
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0011006
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0159428
[Epoch 41] ogbg-molhiv: 0.791379 val loss: 0.162463
[Epoch 41] ogbg-molhiv: 0.717897 test loss: 0.266367
[Epoch 42; Iter    23/ 1097] train: loss: 0.0009176
[Epoch 42; Iter    53/ 1097] train: loss: 0.0009245
[Epoch 42; Iter    83/ 1097] train: loss: 0.0317926
[Epoch 42; Iter   113/ 1097] train: loss: 0.0066504
[Epoch 42; Iter   143/ 1097] train: loss: 0.0004474
[Epoch 42; Iter   173/ 1097] train: loss: 0.0015072
[Epoch 42; Iter   203/ 1097] train: loss: 0.0122805
[Epoch 42; Iter   233/ 1097] train: loss: 0.0013971
[Epoch 42; Iter   263/ 1097] train: loss: 0.0023108
[Epoch 42; Iter   293/ 1097] train: loss: 0.0001886
[Epoch 42; Iter   323/ 1097] train: loss: 0.0175107
[Epoch 42; Iter   353/ 1097] train: loss: 0.0003129
[Epoch 42; Iter   383/ 1097] train: loss: 0.0003723
[Epoch 42; Iter   413/ 1097] train: loss: 0.0115093
[Epoch 42; Iter   443/ 1097] train: loss: 0.0062076
[Epoch 42; Iter   473/ 1097] train: loss: 0.0347674
[Epoch 42; Iter   503/ 1097] train: loss: 0.0020692
[Epoch 42; Iter   533/ 1097] train: loss: 0.0026858
[Epoch 42; Iter   563/ 1097] train: loss: 0.0006285
[Epoch 42; Iter   593/ 1097] train: loss: 0.1356542
[Epoch 42; Iter   623/ 1097] train: loss: 0.0013814
[Epoch 42; Iter   653/ 1097] train: loss: 0.0014436
[Epoch 42; Iter   683/ 1097] train: loss: 0.0013605
[Epoch 42; Iter   713/ 1097] train: loss: 0.0047478
[Epoch 42; Iter   743/ 1097] train: loss: 0.0152051
[Epoch 42; Iter   773/ 1097] train: loss: 0.0023223
[Epoch 42; Iter   803/ 1097] train: loss: 0.0288973
[Epoch 42; Iter   833/ 1097] train: loss: 0.0014085
[Epoch 42; Iter   863/ 1097] train: loss: 0.0023421
[Epoch 42; Iter   893/ 1097] train: loss: 0.0018874
[Epoch 42; Iter   923/ 1097] train: loss: 0.0074604
[Epoch 42; Iter   953/ 1097] train: loss: 0.0057426
[Epoch 42; Iter   983/ 1097] train: loss: 0.0042454
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0344315
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0020946
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0103263
[Epoch 42] ogbg-molhiv: 0.765160 val loss: 0.155426
[Epoch 42] ogbg-molhiv: 0.721586 test loss: 0.242958
[Epoch 43; Iter     6/ 1097] train: loss: 0.0014366
[Epoch 43; Iter    36/ 1097] train: loss: 0.0003988
[Epoch 43; Iter    66/ 1097] train: loss: 0.1093037
[Epoch 43; Iter    96/ 1097] train: loss: 0.0077019
[Epoch 43; Iter   126/ 1097] train: loss: 0.0004104
[Epoch 43; Iter   156/ 1097] train: loss: 0.0057314
[Epoch 43; Iter   186/ 1097] train: loss: 0.0261056
[Epoch 43; Iter   216/ 1097] train: loss: 0.0080601
[Epoch 43; Iter   246/ 1097] train: loss: 0.0013345
[Epoch 43; Iter   276/ 1097] train: loss: 0.0025878
[Epoch 43; Iter   306/ 1097] train: loss: 0.0101998
[Epoch 43; Iter   336/ 1097] train: loss: 0.0127361
[Epoch 43; Iter   366/ 1097] train: loss: 0.0008253
[Epoch 43; Iter   396/ 1097] train: loss: 0.0018881
[Epoch 43; Iter   426/ 1097] train: loss: 0.0101843
[Epoch 43; Iter   456/ 1097] train: loss: 0.0719034
[Epoch 43; Iter   486/ 1097] train: loss: 0.0171188
[Epoch 43; Iter   516/ 1097] train: loss: 0.0108572
[Epoch 43; Iter   546/ 1097] train: loss: 0.0020973
[Epoch 43; Iter   576/ 1097] train: loss: 0.0105805
[Epoch 43; Iter   606/ 1097] train: loss: 0.0631030
[Epoch 43; Iter   636/ 1097] train: loss: 0.0035385
[Epoch 43; Iter   666/ 1097] train: loss: 0.0001493
[Epoch 43; Iter   696/ 1097] train: loss: 0.0002715
[Epoch 43; Iter   726/ 1097] train: loss: 0.0544688
[Epoch 43; Iter   756/ 1097] train: loss: 0.0122146
[Epoch 43; Iter   786/ 1097] train: loss: 0.0470214
[Epoch 43; Iter   816/ 1097] train: loss: 0.0156045
[Epoch 43; Iter   846/ 1097] train: loss: 0.0022474
[Epoch 43; Iter   876/ 1097] train: loss: 0.0416752
[Epoch 43; Iter   906/ 1097] train: loss: 0.0363469
[Epoch 43; Iter   936/ 1097] train: loss: 0.0050248
[Epoch 43; Iter   966/ 1097] train: loss: 0.0108299
[Epoch 43; Iter   996/ 1097] train: loss: 0.0004915
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0022046
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0003557
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0018199
[Epoch 43] ogbg-molhiv: 0.765781 val loss: 0.158099
[Epoch 43] ogbg-molhiv: 0.727671 test loss: 0.245839
[Epoch 44; Iter    19/ 1097] train: loss: 0.0174381
[Epoch 44; Iter    49/ 1097] train: loss: 0.0016804
[Epoch 44; Iter    79/ 1097] train: loss: 0.0538011
[Epoch 44; Iter   109/ 1097] train: loss: 0.0070502
[Epoch 44; Iter   139/ 1097] train: loss: 0.0009462
[Epoch 44; Iter   169/ 1097] train: loss: 0.0049510
[Epoch 44; Iter   199/ 1097] train: loss: 0.0873607
[Epoch 44; Iter   229/ 1097] train: loss: 0.0016226
[Epoch 44; Iter   259/ 1097] train: loss: 0.0013932
[Epoch 44; Iter   289/ 1097] train: loss: 0.0190456
[Epoch 44; Iter   319/ 1097] train: loss: 0.0006812
[Epoch 44; Iter   349/ 1097] train: loss: 0.0072657
[Epoch 44; Iter   379/ 1097] train: loss: 0.0020886
[Epoch 44; Iter   409/ 1097] train: loss: 0.0035253
[Epoch 44; Iter   439/ 1097] train: loss: 0.0002178
[Epoch 44; Iter   469/ 1097] train: loss: 0.0069752
[Epoch 44; Iter   499/ 1097] train: loss: 0.0046342
[Epoch 44; Iter   529/ 1097] train: loss: 0.0197057
[Epoch 44; Iter   559/ 1097] train: loss: 0.0012546
[Epoch 44; Iter   589/ 1097] train: loss: 0.0006838
[Epoch 44; Iter   619/ 1097] train: loss: 0.0006626
[Epoch 44; Iter   649/ 1097] train: loss: 0.0001096
[Epoch 44; Iter   679/ 1097] train: loss: 0.1275317
[Epoch 44; Iter   709/ 1097] train: loss: 0.0008413
[Epoch 44; Iter   739/ 1097] train: loss: 0.0023545
[Epoch 40; Iter   687/ 1097] train: loss: 0.1490009
[Epoch 40; Iter   717/ 1097] train: loss: 0.0041809
[Epoch 40; Iter   747/ 1097] train: loss: 0.0059531
[Epoch 40; Iter   777/ 1097] train: loss: 0.2403520
[Epoch 40; Iter   807/ 1097] train: loss: 0.0128953
[Epoch 40; Iter   837/ 1097] train: loss: 0.0061231
[Epoch 40; Iter   867/ 1097] train: loss: 0.0031769
[Epoch 40; Iter   897/ 1097] train: loss: 0.0016494
[Epoch 40; Iter   927/ 1097] train: loss: 0.0880352
[Epoch 40; Iter   957/ 1097] train: loss: 0.0113219
[Epoch 40; Iter   987/ 1097] train: loss: 0.0081841
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0037854
[Epoch 40; Iter  1047/ 1097] train: loss: 0.1421507
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0094042
[Epoch 40] ogbg-molhiv: 0.783908 val loss: 0.179701
[Epoch 40] ogbg-molhiv: 0.719730 test loss: 0.334170
[Epoch 41; Iter    10/ 1097] train: loss: 0.0512165
[Epoch 41; Iter    40/ 1097] train: loss: 0.0007550
[Epoch 41; Iter    70/ 1097] train: loss: 0.0019666
[Epoch 41; Iter   100/ 1097] train: loss: 0.0028025
[Epoch 41; Iter   130/ 1097] train: loss: 0.0505931
[Epoch 41; Iter   160/ 1097] train: loss: 0.0205990
[Epoch 41; Iter   190/ 1097] train: loss: 0.0121768
[Epoch 41; Iter   220/ 1097] train: loss: 0.1211050
[Epoch 41; Iter   250/ 1097] train: loss: 0.0103885
[Epoch 41; Iter   280/ 1097] train: loss: 0.0043109
[Epoch 41; Iter   310/ 1097] train: loss: 0.1154282
[Epoch 41; Iter   340/ 1097] train: loss: 0.0020296
[Epoch 41; Iter   370/ 1097] train: loss: 0.0942216
[Epoch 41; Iter   400/ 1097] train: loss: 0.0080430
[Epoch 41; Iter   430/ 1097] train: loss: 0.0009931
[Epoch 41; Iter   460/ 1097] train: loss: 0.0849563
[Epoch 41; Iter   490/ 1097] train: loss: 0.1606866
[Epoch 41; Iter   520/ 1097] train: loss: 0.0030023
[Epoch 41; Iter   550/ 1097] train: loss: 0.0027345
[Epoch 41; Iter   580/ 1097] train: loss: 0.1026348
[Epoch 41; Iter   610/ 1097] train: loss: 0.0051098
[Epoch 41; Iter   640/ 1097] train: loss: 0.0053540
[Epoch 41; Iter   670/ 1097] train: loss: 0.0082732
[Epoch 41; Iter   700/ 1097] train: loss: 0.0147829
[Epoch 41; Iter   730/ 1097] train: loss: 0.0043729
[Epoch 41; Iter   760/ 1097] train: loss: 0.0026077
[Epoch 41; Iter   790/ 1097] train: loss: 0.0328956
[Epoch 41; Iter   820/ 1097] train: loss: 0.0052716
[Epoch 41; Iter   850/ 1097] train: loss: 0.0005617
[Epoch 41; Iter   880/ 1097] train: loss: 0.0058826
[Epoch 41; Iter   910/ 1097] train: loss: 0.0009530
[Epoch 41; Iter   940/ 1097] train: loss: 0.0095184
[Epoch 41; Iter   970/ 1097] train: loss: 0.0008001
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0118326
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0097680
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0046675
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1665300
[Epoch 41] ogbg-molhiv: 0.804756 val loss: 0.192963
[Epoch 41] ogbg-molhiv: 0.714066 test loss: 0.367605
[Epoch 42; Iter    23/ 1097] train: loss: 0.0057135
[Epoch 42; Iter    53/ 1097] train: loss: 0.0103272
[Epoch 42; Iter    83/ 1097] train: loss: 0.0122755
[Epoch 42; Iter   113/ 1097] train: loss: 0.0083803
[Epoch 42; Iter   143/ 1097] train: loss: 0.0092961
[Epoch 42; Iter   173/ 1097] train: loss: 0.0047901
[Epoch 42; Iter   203/ 1097] train: loss: 0.0041164
[Epoch 42; Iter   233/ 1097] train: loss: 0.0098251
[Epoch 42; Iter   263/ 1097] train: loss: 0.0664669
[Epoch 42; Iter   293/ 1097] train: loss: 0.0746410
[Epoch 42; Iter   323/ 1097] train: loss: 0.0016512
[Epoch 42; Iter   353/ 1097] train: loss: 0.0042289
[Epoch 42; Iter   383/ 1097] train: loss: 0.0039797
[Epoch 42; Iter   413/ 1097] train: loss: 0.0078054
[Epoch 42; Iter   443/ 1097] train: loss: 0.0048472
[Epoch 42; Iter   473/ 1097] train: loss: 0.0993345
[Epoch 42; Iter   503/ 1097] train: loss: 0.0196876
[Epoch 42; Iter   533/ 1097] train: loss: 0.0878899
[Epoch 42; Iter   563/ 1097] train: loss: 0.0058552
[Epoch 42; Iter   593/ 1097] train: loss: 0.0013006
[Epoch 42; Iter   623/ 1097] train: loss: 0.0106731
[Epoch 42; Iter   653/ 1097] train: loss: 0.0015793
[Epoch 42; Iter   683/ 1097] train: loss: 0.0207768
[Epoch 42; Iter   713/ 1097] train: loss: 0.0376572
[Epoch 42; Iter   743/ 1097] train: loss: 0.1725034
[Epoch 42; Iter   773/ 1097] train: loss: 0.0048037
[Epoch 42; Iter   803/ 1097] train: loss: 0.0037145
[Epoch 42; Iter   833/ 1097] train: loss: 0.0520637
[Epoch 42; Iter   863/ 1097] train: loss: 0.0039512
[Epoch 42; Iter   893/ 1097] train: loss: 0.0056282
[Epoch 42; Iter   923/ 1097] train: loss: 0.0106262
[Epoch 42; Iter   953/ 1097] train: loss: 0.0036365
[Epoch 42; Iter   983/ 1097] train: loss: 0.0012008
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0561143
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1049269
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0130087
[Epoch 42] ogbg-molhiv: 0.811615 val loss: 0.152332
[Epoch 42] ogbg-molhiv: 0.720591 test loss: 0.269807
[Epoch 43; Iter     6/ 1097] train: loss: 0.0032833
[Epoch 43; Iter    36/ 1097] train: loss: 0.0211977
[Epoch 43; Iter    66/ 1097] train: loss: 0.0132322
[Epoch 43; Iter    96/ 1097] train: loss: 0.0033412
[Epoch 43; Iter   126/ 1097] train: loss: 0.0081994
[Epoch 43; Iter   156/ 1097] train: loss: 0.0111880
[Epoch 43; Iter   186/ 1097] train: loss: 0.0005025
[Epoch 43; Iter   216/ 1097] train: loss: 0.0059573
[Epoch 43; Iter   246/ 1097] train: loss: 0.0006289
[Epoch 43; Iter   276/ 1097] train: loss: 0.0605302
[Epoch 43; Iter   306/ 1097] train: loss: 0.1228390
[Epoch 43; Iter   336/ 1097] train: loss: 0.0703677
[Epoch 43; Iter   366/ 1097] train: loss: 0.0047258
[Epoch 43; Iter   396/ 1097] train: loss: 0.0016040
[Epoch 43; Iter   426/ 1097] train: loss: 0.0013458
[Epoch 43; Iter   456/ 1097] train: loss: 0.0451521
[Epoch 43; Iter   486/ 1097] train: loss: 0.0190684
[Epoch 43; Iter   516/ 1097] train: loss: 0.0006283
[Epoch 43; Iter   546/ 1097] train: loss: 0.0266503
[Epoch 43; Iter   576/ 1097] train: loss: 0.0107438
[Epoch 43; Iter   606/ 1097] train: loss: 0.1233169
[Epoch 43; Iter   636/ 1097] train: loss: 0.0162575
[Epoch 43; Iter   666/ 1097] train: loss: 0.0027957
[Epoch 43; Iter   696/ 1097] train: loss: 0.0088724
[Epoch 43; Iter   726/ 1097] train: loss: 0.0019284
[Epoch 43; Iter   756/ 1097] train: loss: 0.0060905
[Epoch 43; Iter   786/ 1097] train: loss: 0.0504067
[Epoch 43; Iter   816/ 1097] train: loss: 0.0015140
[Epoch 43; Iter   846/ 1097] train: loss: 0.0014532
[Epoch 43; Iter   876/ 1097] train: loss: 0.1068956
[Epoch 43; Iter   906/ 1097] train: loss: 0.0056930
[Epoch 43; Iter   936/ 1097] train: loss: 0.0256395
[Epoch 43; Iter   966/ 1097] train: loss: 0.0086987
[Epoch 43; Iter   996/ 1097] train: loss: 0.0531223
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0013027
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0234762
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0191526
[Epoch 43] ogbg-molhiv: 0.782297 val loss: 0.293201
[Epoch 43] ogbg-molhiv: 0.708142 test loss: 0.359816
[Epoch 44; Iter    19/ 1097] train: loss: 0.0173318
[Epoch 44; Iter    49/ 1097] train: loss: 0.0530493
[Epoch 44; Iter    79/ 1097] train: loss: 0.0043880
[Epoch 44; Iter   109/ 1097] train: loss: 0.0778234
[Epoch 44; Iter   139/ 1097] train: loss: 0.0095205
[Epoch 44; Iter   169/ 1097] train: loss: 0.0016738
[Epoch 44; Iter   199/ 1097] train: loss: 0.0050994
[Epoch 44; Iter   229/ 1097] train: loss: 0.0008350
[Epoch 44; Iter   259/ 1097] train: loss: 0.0013600
[Epoch 44; Iter   289/ 1097] train: loss: 0.0017179
[Epoch 44; Iter   319/ 1097] train: loss: 0.0020271
[Epoch 44; Iter   349/ 1097] train: loss: 0.0222215
[Epoch 44; Iter   379/ 1097] train: loss: 0.0042416
[Epoch 44; Iter   409/ 1097] train: loss: 0.0005678
[Epoch 44; Iter   439/ 1097] train: loss: 0.0022240
[Epoch 44; Iter   469/ 1097] train: loss: 0.0507864
[Epoch 44; Iter   499/ 1097] train: loss: 0.0028397
[Epoch 44; Iter   529/ 1097] train: loss: 0.0615355
[Epoch 44; Iter   559/ 1097] train: loss: 0.0020994
[Epoch 44; Iter   589/ 1097] train: loss: 0.0340844
[Epoch 44; Iter   619/ 1097] train: loss: 0.0181300
[Epoch 44; Iter   649/ 1097] train: loss: 0.0025715
[Epoch 44; Iter   679/ 1097] train: loss: 0.0909682
[Epoch 44; Iter   709/ 1097] train: loss: 0.0061639
[Epoch 44; Iter   739/ 1097] train: loss: 0.0029496
[Epoch 40; Iter   687/ 1097] train: loss: 0.0040802
[Epoch 40; Iter   717/ 1097] train: loss: 0.0699987
[Epoch 40; Iter   747/ 1097] train: loss: 0.0943493
[Epoch 40; Iter   777/ 1097] train: loss: 0.0200006
[Epoch 40; Iter   807/ 1097] train: loss: 0.0016491
[Epoch 40; Iter   837/ 1097] train: loss: 0.0074043
[Epoch 40; Iter   867/ 1097] train: loss: 0.0224602
[Epoch 40; Iter   897/ 1097] train: loss: 0.0325015
[Epoch 40; Iter   927/ 1097] train: loss: 0.0077526
[Epoch 40; Iter   957/ 1097] train: loss: 0.0076103
[Epoch 40; Iter   987/ 1097] train: loss: 0.0145525
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0031687
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0003428
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0091008
[Epoch 40] ogbg-molhiv: 0.783390 val loss: 0.219274
[Epoch 40] ogbg-molhiv: 0.762690 test loss: 0.237444
[Epoch 41; Iter    10/ 1097] train: loss: 0.0065776
[Epoch 41; Iter    40/ 1097] train: loss: 0.0002718
[Epoch 41; Iter    70/ 1097] train: loss: 0.0024625
[Epoch 41; Iter   100/ 1097] train: loss: 0.0004147
[Epoch 41; Iter   130/ 1097] train: loss: 0.0385994
[Epoch 41; Iter   160/ 1097] train: loss: 0.0028215
[Epoch 41; Iter   190/ 1097] train: loss: 0.0009721
[Epoch 41; Iter   220/ 1097] train: loss: 0.0001805
[Epoch 41; Iter   250/ 1097] train: loss: 0.0050417
[Epoch 41; Iter   280/ 1097] train: loss: 0.0024599
[Epoch 41; Iter   310/ 1097] train: loss: 0.0146666
[Epoch 41; Iter   340/ 1097] train: loss: 0.0232403
[Epoch 41; Iter   370/ 1097] train: loss: 0.0010124
[Epoch 41; Iter   400/ 1097] train: loss: 0.0125463
[Epoch 41; Iter   430/ 1097] train: loss: 0.0026323
[Epoch 41; Iter   460/ 1097] train: loss: 0.1115490
[Epoch 41; Iter   490/ 1097] train: loss: 0.0763414
[Epoch 41; Iter   520/ 1097] train: loss: 0.0001720
[Epoch 41; Iter   550/ 1097] train: loss: 0.0043767
[Epoch 41; Iter   580/ 1097] train: loss: 0.0968112
[Epoch 41; Iter   610/ 1097] train: loss: 0.0050979
[Epoch 41; Iter   640/ 1097] train: loss: 0.0346919
[Epoch 41; Iter   670/ 1097] train: loss: 0.0006225
[Epoch 41; Iter   700/ 1097] train: loss: 0.0116236
[Epoch 41; Iter   730/ 1097] train: loss: 0.0032715
[Epoch 41; Iter   760/ 1097] train: loss: 0.0264794
[Epoch 41; Iter   790/ 1097] train: loss: 0.0400242
[Epoch 41; Iter   820/ 1097] train: loss: 0.0104622
[Epoch 41; Iter   850/ 1097] train: loss: 0.0035502
[Epoch 41; Iter   880/ 1097] train: loss: 0.0044512
[Epoch 41; Iter   910/ 1097] train: loss: 0.0164393
[Epoch 41; Iter   940/ 1097] train: loss: 0.0015205
[Epoch 41; Iter   970/ 1097] train: loss: 0.1403050
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0134627
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0027212
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0176255
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0063854
[Epoch 41] ogbg-molhiv: 0.800075 val loss: 0.215125
[Epoch 41] ogbg-molhiv: 0.810825 test loss: 0.243512
[Epoch 42; Iter    23/ 1097] train: loss: 0.0169458
[Epoch 42; Iter    53/ 1097] train: loss: 0.0887122
[Epoch 42; Iter    83/ 1097] train: loss: 0.0031947
[Epoch 42; Iter   113/ 1097] train: loss: 0.0018269
[Epoch 42; Iter   143/ 1097] train: loss: 0.0043583
[Epoch 42; Iter   173/ 1097] train: loss: 0.1153930
[Epoch 42; Iter   203/ 1097] train: loss: 0.0111244
[Epoch 42; Iter   233/ 1097] train: loss: 0.0003050
[Epoch 42; Iter   263/ 1097] train: loss: 0.0166522
[Epoch 42; Iter   293/ 1097] train: loss: 0.0937162
[Epoch 42; Iter   323/ 1097] train: loss: 0.0005548
[Epoch 42; Iter   353/ 1097] train: loss: 0.0036238
[Epoch 42; Iter   383/ 1097] train: loss: 0.0038201
[Epoch 42; Iter   413/ 1097] train: loss: 0.0021939
[Epoch 42; Iter   443/ 1097] train: loss: 0.0192511
[Epoch 42; Iter   473/ 1097] train: loss: 0.0009437
[Epoch 42; Iter   503/ 1097] train: loss: 0.0048653
[Epoch 42; Iter   533/ 1097] train: loss: 0.0161267
[Epoch 42; Iter   563/ 1097] train: loss: 0.0002715
[Epoch 42; Iter   593/ 1097] train: loss: 0.0125187
[Epoch 42; Iter   623/ 1097] train: loss: 0.0020919
[Epoch 42; Iter   653/ 1097] train: loss: 0.1771599
[Epoch 42; Iter   683/ 1097] train: loss: 0.0002942
[Epoch 42; Iter   713/ 1097] train: loss: 0.0003456
[Epoch 42; Iter   743/ 1097] train: loss: 0.0092526
[Epoch 42; Iter   773/ 1097] train: loss: 0.0732636
[Epoch 42; Iter   803/ 1097] train: loss: 0.0273149
[Epoch 42; Iter   833/ 1097] train: loss: 0.0067085
[Epoch 42; Iter   863/ 1097] train: loss: 0.0232164
[Epoch 42; Iter   893/ 1097] train: loss: 0.0070617
[Epoch 42; Iter   923/ 1097] train: loss: 0.0025304
[Epoch 42; Iter   953/ 1097] train: loss: 0.0702756
[Epoch 42; Iter   983/ 1097] train: loss: 0.0196463
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0014391
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0063221
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0054111
[Epoch 42] ogbg-molhiv: 0.785754 val loss: 0.215441
[Epoch 42] ogbg-molhiv: 0.800435 test loss: 0.254008
[Epoch 43; Iter     6/ 1097] train: loss: 0.0878647
[Epoch 43; Iter    36/ 1097] train: loss: 0.0007859
[Epoch 43; Iter    66/ 1097] train: loss: 0.0166583
[Epoch 43; Iter    96/ 1097] train: loss: 0.0065321
[Epoch 43; Iter   126/ 1097] train: loss: 0.0054329
[Epoch 43; Iter   156/ 1097] train: loss: 0.0161714
[Epoch 43; Iter   186/ 1097] train: loss: 0.0057754
[Epoch 43; Iter   216/ 1097] train: loss: 0.0035405
[Epoch 43; Iter   246/ 1097] train: loss: 0.0378395
[Epoch 43; Iter   276/ 1097] train: loss: 0.0074158
[Epoch 43; Iter   306/ 1097] train: loss: 0.0022821
[Epoch 43; Iter   336/ 1097] train: loss: 0.0002358
[Epoch 43; Iter   366/ 1097] train: loss: 0.0021766
[Epoch 43; Iter   396/ 1097] train: loss: 0.1619167
[Epoch 43; Iter   426/ 1097] train: loss: 0.0007809
[Epoch 43; Iter   456/ 1097] train: loss: 0.0034949
[Epoch 43; Iter   486/ 1097] train: loss: 0.0098882
[Epoch 43; Iter   516/ 1097] train: loss: 0.0006590
[Epoch 43; Iter   546/ 1097] train: loss: 0.0205801
[Epoch 43; Iter   576/ 1097] train: loss: 0.0433399
[Epoch 43; Iter   606/ 1097] train: loss: 0.0004807
[Epoch 43; Iter   636/ 1097] train: loss: 0.0126686
[Epoch 43; Iter   666/ 1097] train: loss: 0.0935684
[Epoch 43; Iter   696/ 1097] train: loss: 0.0517917
[Epoch 43; Iter   726/ 1097] train: loss: 0.0007581
[Epoch 43; Iter   756/ 1097] train: loss: 0.0333894
[Epoch 43; Iter   786/ 1097] train: loss: 0.0059475
[Epoch 43; Iter   816/ 1097] train: loss: 0.0016955
[Epoch 43; Iter   846/ 1097] train: loss: 0.0003357
[Epoch 43; Iter   876/ 1097] train: loss: 0.0101918
[Epoch 43; Iter   906/ 1097] train: loss: 0.0017078
[Epoch 43; Iter   936/ 1097] train: loss: 0.0063034
[Epoch 43; Iter   966/ 1097] train: loss: 0.0007689
[Epoch 43; Iter   996/ 1097] train: loss: 0.0016120
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0350950
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0318104
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0008378
[Epoch 43] ogbg-molhiv: 0.776375 val loss: 0.188738
[Epoch 43] ogbg-molhiv: 0.812634 test loss: 0.217256
[Epoch 44; Iter    19/ 1097] train: loss: 0.0004218
[Epoch 44; Iter    49/ 1097] train: loss: 0.0050507
[Epoch 44; Iter    79/ 1097] train: loss: 0.0111038
[Epoch 44; Iter   109/ 1097] train: loss: 0.0010006
[Epoch 44; Iter   139/ 1097] train: loss: 0.0000476
[Epoch 44; Iter   169/ 1097] train: loss: 0.0018611
[Epoch 44; Iter   199/ 1097] train: loss: 0.0011865
[Epoch 44; Iter   229/ 1097] train: loss: 0.0003374
[Epoch 44; Iter   259/ 1097] train: loss: 0.0250568
[Epoch 44; Iter   289/ 1097] train: loss: 0.0006409
[Epoch 44; Iter   319/ 1097] train: loss: 0.1016704
[Epoch 44; Iter   349/ 1097] train: loss: 0.0026605
[Epoch 44; Iter   379/ 1097] train: loss: 0.0006008
[Epoch 44; Iter   409/ 1097] train: loss: 0.0749684
[Epoch 44; Iter   439/ 1097] train: loss: 0.0005865
[Epoch 44; Iter   469/ 1097] train: loss: 0.0017504
[Epoch 44; Iter   499/ 1097] train: loss: 0.0004920
[Epoch 44; Iter   529/ 1097] train: loss: 0.0383665
[Epoch 44; Iter   559/ 1097] train: loss: 0.0004990
[Epoch 44; Iter   589/ 1097] train: loss: 0.0020152
[Epoch 44; Iter   619/ 1097] train: loss: 0.0002728
[Epoch 44; Iter   649/ 1097] train: loss: 0.0012175
[Epoch 44; Iter   679/ 1097] train: loss: 0.0301951
[Epoch 44; Iter   709/ 1097] train: loss: 0.0033157
[Epoch 44; Iter   739/ 1097] train: loss: 0.0021181
[Epoch 40; Iter   687/ 1097] train: loss: 0.0017369
[Epoch 40; Iter   717/ 1097] train: loss: 0.0017910
[Epoch 40; Iter   747/ 1097] train: loss: 0.0022584
[Epoch 40; Iter   777/ 1097] train: loss: 0.0218170
[Epoch 40; Iter   807/ 1097] train: loss: 0.0006948
[Epoch 40; Iter   837/ 1097] train: loss: 0.0004027
[Epoch 40; Iter   867/ 1097] train: loss: 0.0001892
[Epoch 40; Iter   897/ 1097] train: loss: 0.0006330
[Epoch 40; Iter   927/ 1097] train: loss: 0.0002319
[Epoch 40; Iter   957/ 1097] train: loss: 0.0035264
[Epoch 40; Iter   987/ 1097] train: loss: 0.0076352
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0025999
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0076855
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1413012
[Epoch 40] ogbg-molhiv: 0.714745 val loss: 7.993288
[Epoch 40] ogbg-molhiv: 0.624077 test loss: 11.017086
[Epoch 41; Iter    10/ 1097] train: loss: 0.0131465
[Epoch 41; Iter    40/ 1097] train: loss: 0.0038137
[Epoch 41; Iter    70/ 1097] train: loss: 0.0024254
[Epoch 41; Iter   100/ 1097] train: loss: 0.0002446
[Epoch 41; Iter   130/ 1097] train: loss: 0.0001384
[Epoch 41; Iter   160/ 1097] train: loss: 0.0452955
[Epoch 41; Iter   190/ 1097] train: loss: 0.0034569
[Epoch 41; Iter   220/ 1097] train: loss: 0.0002339
[Epoch 41; Iter   250/ 1097] train: loss: 0.0003136
[Epoch 41; Iter   280/ 1097] train: loss: 0.0592891
[Epoch 41; Iter   310/ 1097] train: loss: 0.0007413
[Epoch 41; Iter   340/ 1097] train: loss: 0.0045741
[Epoch 41; Iter   370/ 1097] train: loss: 0.0012173
[Epoch 41; Iter   400/ 1097] train: loss: 0.0054875
[Epoch 41; Iter   430/ 1097] train: loss: 0.0004365
[Epoch 41; Iter   460/ 1097] train: loss: 0.0093695
[Epoch 41; Iter   490/ 1097] train: loss: 0.0010480
[Epoch 41; Iter   520/ 1097] train: loss: 0.0019378
[Epoch 41; Iter   550/ 1097] train: loss: 0.0039952
[Epoch 41; Iter   580/ 1097] train: loss: 0.0003831
[Epoch 41; Iter   610/ 1097] train: loss: 0.0030111
[Epoch 41; Iter   640/ 1097] train: loss: 0.0004193
[Epoch 41; Iter   670/ 1097] train: loss: 0.0015448
[Epoch 41; Iter   700/ 1097] train: loss: 0.0038202
[Epoch 41; Iter   730/ 1097] train: loss: 0.0003418
[Epoch 41; Iter   760/ 1097] train: loss: 0.0393484
[Epoch 41; Iter   790/ 1097] train: loss: 0.0014483
[Epoch 41; Iter   820/ 1097] train: loss: 0.0035914
[Epoch 41; Iter   850/ 1097] train: loss: 0.1636571
[Epoch 41; Iter   880/ 1097] train: loss: 0.0003654
[Epoch 41; Iter   910/ 1097] train: loss: 0.0001931
[Epoch 41; Iter   940/ 1097] train: loss: 0.0008298
[Epoch 41; Iter   970/ 1097] train: loss: 0.0006545
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0083494
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0002216
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0017753
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0724565
[Epoch 41] ogbg-molhiv: 0.680271 val loss: 10.882269
[Epoch 41] ogbg-molhiv: 0.580650 test loss: 15.041039
[Epoch 42; Iter    23/ 1097] train: loss: 0.0000197
[Epoch 42; Iter    53/ 1097] train: loss: 0.0004450
[Epoch 42; Iter    83/ 1097] train: loss: 0.0018281
[Epoch 42; Iter   113/ 1097] train: loss: 0.0002617
[Epoch 42; Iter   143/ 1097] train: loss: 0.0013174
[Epoch 42; Iter   173/ 1097] train: loss: 0.0078327
[Epoch 42; Iter   203/ 1097] train: loss: 0.0071380
[Epoch 42; Iter   233/ 1097] train: loss: 0.0001198
[Epoch 42; Iter   263/ 1097] train: loss: 0.0001715
[Epoch 42; Iter   293/ 1097] train: loss: 0.0003640
[Epoch 42; Iter   323/ 1097] train: loss: 0.0033816
[Epoch 42; Iter   353/ 1097] train: loss: 0.0001459
[Epoch 42; Iter   383/ 1097] train: loss: 0.0041155
[Epoch 42; Iter   413/ 1097] train: loss: 0.0003669
[Epoch 42; Iter   443/ 1097] train: loss: 0.0102421
[Epoch 42; Iter   473/ 1097] train: loss: 0.0012273
[Epoch 42; Iter   503/ 1097] train: loss: 0.0040787
[Epoch 42; Iter   533/ 1097] train: loss: 0.0473507
[Epoch 42; Iter   563/ 1097] train: loss: 0.0456576
[Epoch 42; Iter   593/ 1097] train: loss: 0.0003378
[Epoch 42; Iter   623/ 1097] train: loss: 0.0021669
[Epoch 42; Iter   653/ 1097] train: loss: 0.0000411
[Epoch 42; Iter   683/ 1097] train: loss: 0.0040902
[Epoch 42; Iter   713/ 1097] train: loss: 0.0061648
[Epoch 42; Iter   743/ 1097] train: loss: 0.0005982
[Epoch 42; Iter   773/ 1097] train: loss: 0.0387554
[Epoch 42; Iter   803/ 1097] train: loss: 0.0333723
[Epoch 42; Iter   833/ 1097] train: loss: 0.0033324
[Epoch 42; Iter   863/ 1097] train: loss: 0.0011780
[Epoch 42; Iter   893/ 1097] train: loss: 0.0078284
[Epoch 42; Iter   923/ 1097] train: loss: 0.0004812
[Epoch 42; Iter   953/ 1097] train: loss: 0.0028331
[Epoch 42; Iter   983/ 1097] train: loss: 0.0010192
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0638346
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0004810
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0015928
[Epoch 42] ogbg-molhiv: 0.653807 val loss: 28.452650
[Epoch 42] ogbg-molhiv: 0.572738 test loss: 35.482678
[Epoch 43; Iter     6/ 1097] train: loss: 0.0020128
[Epoch 43; Iter    36/ 1097] train: loss: 0.0003124
[Epoch 43; Iter    66/ 1097] train: loss: 0.0828943
[Epoch 43; Iter    96/ 1097] train: loss: 0.0008059
[Epoch 43; Iter   126/ 1097] train: loss: 0.0024463
[Epoch 43; Iter   156/ 1097] train: loss: 0.0000422
[Epoch 43; Iter   186/ 1097] train: loss: 0.0429862
[Epoch 43; Iter   216/ 1097] train: loss: 0.0054205
[Epoch 43; Iter   246/ 1097] train: loss: 0.1398627
[Epoch 43; Iter   276/ 1097] train: loss: 0.0013162
[Epoch 43; Iter   306/ 1097] train: loss: 0.0011640
[Epoch 43; Iter   336/ 1097] train: loss: 0.0000313
[Epoch 43; Iter   366/ 1097] train: loss: 0.0014477
[Epoch 43; Iter   396/ 1097] train: loss: 0.0003115
[Epoch 43; Iter   426/ 1097] train: loss: 0.0002908
[Epoch 43; Iter   456/ 1097] train: loss: 0.0002594
[Epoch 43; Iter   486/ 1097] train: loss: 0.0003383
[Epoch 43; Iter   516/ 1097] train: loss: 0.0000816
[Epoch 43; Iter   546/ 1097] train: loss: 0.0005424
[Epoch 43; Iter   576/ 1097] train: loss: 0.0480177
[Epoch 43; Iter   606/ 1097] train: loss: 0.0336923
[Epoch 43; Iter   636/ 1097] train: loss: 0.0002357
[Epoch 43; Iter   666/ 1097] train: loss: 0.0001800
[Epoch 43; Iter   696/ 1097] train: loss: 0.0003103
[Epoch 43; Iter   726/ 1097] train: loss: 0.0005858
[Epoch 43; Iter   756/ 1097] train: loss: 0.0003313
[Epoch 43; Iter   786/ 1097] train: loss: 0.0247974
[Epoch 43; Iter   816/ 1097] train: loss: 0.0015755
[Epoch 43; Iter   846/ 1097] train: loss: 0.0000688
[Epoch 43; Iter   876/ 1097] train: loss: 0.0010311
[Epoch 43; Iter   906/ 1097] train: loss: 0.0003353
[Epoch 43; Iter   936/ 1097] train: loss: 0.0007196
[Epoch 43; Iter   966/ 1097] train: loss: 0.0019303
[Epoch 43; Iter   996/ 1097] train: loss: 0.0007950
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0028139
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1195392
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0004704
[Epoch 43] ogbg-molhiv: 0.670298 val loss: 1.105657
[Epoch 43] ogbg-molhiv: 0.586991 test loss: 1.508725
[Epoch 44; Iter    19/ 1097] train: loss: 0.0039286
[Epoch 44; Iter    49/ 1097] train: loss: 0.0003981
[Epoch 44; Iter    79/ 1097] train: loss: 0.0001265
[Epoch 44; Iter   109/ 1097] train: loss: 0.0642993
[Epoch 44; Iter   139/ 1097] train: loss: 0.0034314
[Epoch 44; Iter   169/ 1097] train: loss: 0.0004649
[Epoch 44; Iter   199/ 1097] train: loss: 0.0076788
[Epoch 44; Iter   229/ 1097] train: loss: 0.0033648
[Epoch 44; Iter   259/ 1097] train: loss: 0.0011968
[Epoch 44; Iter   289/ 1097] train: loss: 0.0610937
[Epoch 44; Iter   319/ 1097] train: loss: 0.0048016
[Epoch 44; Iter   349/ 1097] train: loss: 0.0273998
[Epoch 44; Iter   379/ 1097] train: loss: 0.0006214
[Epoch 44; Iter   409/ 1097] train: loss: 0.0408310
[Epoch 44; Iter   439/ 1097] train: loss: 0.0007261
[Epoch 44; Iter   469/ 1097] train: loss: 0.0953008
[Epoch 44; Iter   499/ 1097] train: loss: 0.0089989
[Epoch 44; Iter   529/ 1097] train: loss: 0.0194352
[Epoch 44; Iter   559/ 1097] train: loss: 0.0089087
[Epoch 44; Iter   589/ 1097] train: loss: 0.0024866
[Epoch 44; Iter   619/ 1097] train: loss: 0.0016844
[Epoch 44; Iter   649/ 1097] train: loss: 0.0001387
[Epoch 44; Iter   679/ 1097] train: loss: 0.0138442
[Epoch 44; Iter   709/ 1097] train: loss: 0.0018359
[Epoch 44; Iter   739/ 1097] train: loss: 0.0015175
[Epoch 40; Iter   687/ 1097] train: loss: 0.0274868
[Epoch 40; Iter   717/ 1097] train: loss: 0.0482262
[Epoch 40; Iter   747/ 1097] train: loss: 0.2215390
[Epoch 40; Iter   777/ 1097] train: loss: 0.0045300
[Epoch 40; Iter   807/ 1097] train: loss: 0.0550260
[Epoch 40; Iter   837/ 1097] train: loss: 0.0406138
[Epoch 40; Iter   867/ 1097] train: loss: 0.0031161
[Epoch 40; Iter   897/ 1097] train: loss: 0.0007118
[Epoch 40; Iter   927/ 1097] train: loss: 0.0085866
[Epoch 40; Iter   957/ 1097] train: loss: 0.0177960
[Epoch 40; Iter   987/ 1097] train: loss: 0.0281974
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0062493
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0139096
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0638705
[Epoch 40] ogbg-molhiv: 0.764336 val loss: 0.221808
[Epoch 40] ogbg-molhiv: 0.718844 test loss: 0.309356
[Epoch 41; Iter    10/ 1097] train: loss: 0.0049178
[Epoch 41; Iter    40/ 1097] train: loss: 0.0003849
[Epoch 41; Iter    70/ 1097] train: loss: 0.0032348
[Epoch 41; Iter   100/ 1097] train: loss: 0.0022617
[Epoch 41; Iter   130/ 1097] train: loss: 0.0471406
[Epoch 41; Iter   160/ 1097] train: loss: 0.2082875
[Epoch 41; Iter   190/ 1097] train: loss: 0.0640655
[Epoch 41; Iter   220/ 1097] train: loss: 0.0010099
[Epoch 41; Iter   250/ 1097] train: loss: 0.0047068
[Epoch 41; Iter   280/ 1097] train: loss: 0.0013532
[Epoch 41; Iter   310/ 1097] train: loss: 0.0309651
[Epoch 41; Iter   340/ 1097] train: loss: 0.1191372
[Epoch 41; Iter   370/ 1097] train: loss: 0.0168853
[Epoch 41; Iter   400/ 1097] train: loss: 0.0368885
[Epoch 41; Iter   430/ 1097] train: loss: 0.0160977
[Epoch 41; Iter   460/ 1097] train: loss: 0.0149031
[Epoch 41; Iter   490/ 1097] train: loss: 0.0747990
[Epoch 41; Iter   520/ 1097] train: loss: 0.0035522
[Epoch 41; Iter   550/ 1097] train: loss: 0.1120863
[Epoch 41; Iter   580/ 1097] train: loss: 0.0189215
[Epoch 41; Iter   610/ 1097] train: loss: 0.0225731
[Epoch 41; Iter   640/ 1097] train: loss: 0.0251975
[Epoch 41; Iter   670/ 1097] train: loss: 0.0071181
[Epoch 41; Iter   700/ 1097] train: loss: 0.0213256
[Epoch 41; Iter   730/ 1097] train: loss: 0.0308894
[Epoch 41; Iter   760/ 1097] train: loss: 0.0267660
[Epoch 41; Iter   790/ 1097] train: loss: 0.1475456
[Epoch 41; Iter   820/ 1097] train: loss: 0.0066791
[Epoch 41; Iter   850/ 1097] train: loss: 0.0147107
[Epoch 41; Iter   880/ 1097] train: loss: 0.0039493
[Epoch 41; Iter   910/ 1097] train: loss: 0.0406232
[Epoch 41; Iter   940/ 1097] train: loss: 0.0038321
[Epoch 41; Iter   970/ 1097] train: loss: 0.0094482
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0110038
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0051194
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0835798
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0649747
[Epoch 41] ogbg-molhiv: 0.773653 val loss: 0.528927
[Epoch 41] ogbg-molhiv: 0.710162 test loss: 0.618522
[Epoch 42; Iter    23/ 1097] train: loss: 0.0478278
[Epoch 42; Iter    53/ 1097] train: loss: 0.0243789
[Epoch 42; Iter    83/ 1097] train: loss: 0.0155033
[Epoch 42; Iter   113/ 1097] train: loss: 0.0130055
[Epoch 42; Iter   143/ 1097] train: loss: 0.0171410
[Epoch 42; Iter   173/ 1097] train: loss: 0.0010859
[Epoch 42; Iter   203/ 1097] train: loss: 0.0343267
[Epoch 42; Iter   233/ 1097] train: loss: 0.0100136
[Epoch 42; Iter   263/ 1097] train: loss: 0.1542383
[Epoch 42; Iter   293/ 1097] train: loss: 0.0452583
[Epoch 42; Iter   323/ 1097] train: loss: 0.0034922
[Epoch 42; Iter   353/ 1097] train: loss: 0.0026201
[Epoch 42; Iter   383/ 1097] train: loss: 0.0088003
[Epoch 42; Iter   413/ 1097] train: loss: 0.0524438
[Epoch 42; Iter   443/ 1097] train: loss: 0.0322323
[Epoch 42; Iter   473/ 1097] train: loss: 0.0044111
[Epoch 42; Iter   503/ 1097] train: loss: 0.0307039
[Epoch 42; Iter   533/ 1097] train: loss: 0.0662624
[Epoch 42; Iter   563/ 1097] train: loss: 0.0041355
[Epoch 42; Iter   593/ 1097] train: loss: 0.0052465
[Epoch 42; Iter   623/ 1097] train: loss: 0.0107961
[Epoch 42; Iter   653/ 1097] train: loss: 0.1099824
[Epoch 42; Iter   683/ 1097] train: loss: 0.0200490
[Epoch 42; Iter   713/ 1097] train: loss: 0.0049280
[Epoch 42; Iter   743/ 1097] train: loss: 0.0072954
[Epoch 42; Iter   773/ 1097] train: loss: 0.1045024
[Epoch 42; Iter   803/ 1097] train: loss: 0.0442369
[Epoch 42; Iter   833/ 1097] train: loss: 0.0062322
[Epoch 42; Iter   863/ 1097] train: loss: 0.0009054
[Epoch 42; Iter   893/ 1097] train: loss: 0.0176309
[Epoch 42; Iter   923/ 1097] train: loss: 0.0149861
[Epoch 42; Iter   953/ 1097] train: loss: 0.1365877
[Epoch 42; Iter   983/ 1097] train: loss: 0.0069579
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0599785
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0242632
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0082117
[Epoch 42] ogbg-molhiv: 0.766216 val loss: 2.500461
[Epoch 42] ogbg-molhiv: 0.711039 test loss: 4.617709
[Epoch 43; Iter     6/ 1097] train: loss: 0.0211586
[Epoch 43; Iter    36/ 1097] train: loss: 0.0006929
[Epoch 43; Iter    66/ 1097] train: loss: 0.0295983
[Epoch 43; Iter    96/ 1097] train: loss: 0.0167923
[Epoch 43; Iter   126/ 1097] train: loss: 0.0017773
[Epoch 43; Iter   156/ 1097] train: loss: 0.0032288
[Epoch 43; Iter   186/ 1097] train: loss: 0.0019598
[Epoch 43; Iter   216/ 1097] train: loss: 0.0293197
[Epoch 43; Iter   246/ 1097] train: loss: 0.0777317
[Epoch 43; Iter   276/ 1097] train: loss: 0.0047493
[Epoch 43; Iter   306/ 1097] train: loss: 0.0021788
[Epoch 43; Iter   336/ 1097] train: loss: 0.0013842
[Epoch 43; Iter   366/ 1097] train: loss: 0.0049767
[Epoch 43; Iter   396/ 1097] train: loss: 0.1002419
[Epoch 43; Iter   426/ 1097] train: loss: 0.0089619
[Epoch 43; Iter   456/ 1097] train: loss: 0.0009824
[Epoch 43; Iter   486/ 1097] train: loss: 0.0003580
[Epoch 43; Iter   516/ 1097] train: loss: 0.0044827
[Epoch 43; Iter   546/ 1097] train: loss: 0.0021351
[Epoch 43; Iter   576/ 1097] train: loss: 0.0177543
[Epoch 43; Iter   606/ 1097] train: loss: 0.1154704
[Epoch 43; Iter   636/ 1097] train: loss: 0.0009264
[Epoch 43; Iter   666/ 1097] train: loss: 0.0237058
[Epoch 43; Iter   696/ 1097] train: loss: 0.0163370
[Epoch 43; Iter   726/ 1097] train: loss: 0.1027047
[Epoch 43; Iter   756/ 1097] train: loss: 0.0870698
[Epoch 43; Iter   786/ 1097] train: loss: 0.0011102
[Epoch 43; Iter   816/ 1097] train: loss: 0.0529148
[Epoch 43; Iter   846/ 1097] train: loss: 0.0012413
[Epoch 43; Iter   876/ 1097] train: loss: 0.0055740
[Epoch 43; Iter   906/ 1097] train: loss: 0.0098357
[Epoch 43; Iter   936/ 1097] train: loss: 0.0041960
[Epoch 43; Iter   966/ 1097] train: loss: 0.0197558
[Epoch 43; Iter   996/ 1097] train: loss: 0.0117253
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0060283
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0560502
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0085810
[Epoch 43] ogbg-molhiv: 0.775494 val loss: 3.073385
[Epoch 43] ogbg-molhiv: 0.696958 test loss: 5.522361
[Epoch 44; Iter    19/ 1097] train: loss: 0.0066486
[Epoch 44; Iter    49/ 1097] train: loss: 0.0072593
[Epoch 44; Iter    79/ 1097] train: loss: 0.0093888
[Epoch 44; Iter   109/ 1097] train: loss: 0.0021060
[Epoch 44; Iter   139/ 1097] train: loss: 0.0010581
[Epoch 44; Iter   169/ 1097] train: loss: 0.0539671
[Epoch 44; Iter   199/ 1097] train: loss: 0.0102563
[Epoch 44; Iter   229/ 1097] train: loss: 0.0042389
[Epoch 44; Iter   259/ 1097] train: loss: 0.0113271
[Epoch 44; Iter   289/ 1097] train: loss: 0.0006006
[Epoch 44; Iter   319/ 1097] train: loss: 0.1350856
[Epoch 44; Iter   349/ 1097] train: loss: 0.0095904
[Epoch 44; Iter   379/ 1097] train: loss: 0.0010236
[Epoch 44; Iter   409/ 1097] train: loss: 0.0382630
[Epoch 44; Iter   439/ 1097] train: loss: 0.0333128
[Epoch 44; Iter   469/ 1097] train: loss: 0.0217329
[Epoch 44; Iter   499/ 1097] train: loss: 0.0017810
[Epoch 44; Iter   529/ 1097] train: loss: 0.0029836
[Epoch 44; Iter   559/ 1097] train: loss: 0.0009888
[Epoch 44; Iter   589/ 1097] train: loss: 0.0555990
[Epoch 44; Iter   619/ 1097] train: loss: 0.0008676
[Epoch 44; Iter   649/ 1097] train: loss: 0.0049851
[Epoch 44; Iter   679/ 1097] train: loss: 0.0235557
[Epoch 44; Iter   709/ 1097] train: loss: 0.0210059
[Epoch 44; Iter   739/ 1097] train: loss: 0.0227919
[Epoch 40; Iter   687/ 1097] train: loss: 0.0562691
[Epoch 40; Iter   717/ 1097] train: loss: 0.0080944
[Epoch 40; Iter   747/ 1097] train: loss: 0.0402164
[Epoch 40; Iter   777/ 1097] train: loss: 0.2068228
[Epoch 40; Iter   807/ 1097] train: loss: 0.0014510
[Epoch 40; Iter   837/ 1097] train: loss: 0.0010031
[Epoch 40; Iter   867/ 1097] train: loss: 0.0002094
[Epoch 40; Iter   897/ 1097] train: loss: 0.0343472
[Epoch 40; Iter   927/ 1097] train: loss: 0.0094858
[Epoch 40; Iter   957/ 1097] train: loss: 0.0025054
[Epoch 40; Iter   987/ 1097] train: loss: 0.0000780
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0003990
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0248904
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0006733
[Epoch 40] ogbg-molhiv: 0.682971 val loss: 92.499385
[Epoch 40] ogbg-molhiv: 0.585569 test loss: 95.843433
[Epoch 41; Iter    10/ 1097] train: loss: 0.0008696
[Epoch 41; Iter    40/ 1097] train: loss: 0.0011000
[Epoch 41; Iter    70/ 1097] train: loss: 0.0007115
[Epoch 41; Iter   100/ 1097] train: loss: 0.0005023
[Epoch 41; Iter   130/ 1097] train: loss: 0.0007763
[Epoch 41; Iter   160/ 1097] train: loss: 0.0133120
[Epoch 41; Iter   190/ 1097] train: loss: 0.0002780
[Epoch 41; Iter   220/ 1097] train: loss: 0.0057436
[Epoch 41; Iter   250/ 1097] train: loss: 0.0029523
[Epoch 41; Iter   280/ 1097] train: loss: 0.0014346
[Epoch 41; Iter   310/ 1097] train: loss: 0.0036923
[Epoch 41; Iter   340/ 1097] train: loss: 0.0024391
[Epoch 41; Iter   370/ 1097] train: loss: 0.0604329
[Epoch 41; Iter   400/ 1097] train: loss: 0.0064141
[Epoch 41; Iter   430/ 1097] train: loss: 0.0070098
[Epoch 41; Iter   460/ 1097] train: loss: 0.0015675
[Epoch 41; Iter   490/ 1097] train: loss: 0.0346323
[Epoch 41; Iter   520/ 1097] train: loss: 0.0040322
[Epoch 41; Iter   550/ 1097] train: loss: 0.1050268
[Epoch 41; Iter   580/ 1097] train: loss: 0.0006833
[Epoch 41; Iter   610/ 1097] train: loss: 0.0046929
[Epoch 41; Iter   640/ 1097] train: loss: 0.0025898
[Epoch 41; Iter   670/ 1097] train: loss: 0.0039645
[Epoch 41; Iter   700/ 1097] train: loss: 0.0092975
[Epoch 41; Iter   730/ 1097] train: loss: 0.0021839
[Epoch 41; Iter   760/ 1097] train: loss: 0.0022863
[Epoch 41; Iter   790/ 1097] train: loss: 0.0107149
[Epoch 41; Iter   820/ 1097] train: loss: 0.0008070
[Epoch 41; Iter   850/ 1097] train: loss: 0.0028041
[Epoch 41; Iter   880/ 1097] train: loss: 0.0003978
[Epoch 41; Iter   910/ 1097] train: loss: 0.0001610
[Epoch 41; Iter   940/ 1097] train: loss: 0.0125629
[Epoch 41; Iter   970/ 1097] train: loss: 0.0003400
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0257052
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0013565
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0064713
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0058092
[Epoch 41] ogbg-molhiv: 0.701028 val loss: 72.624633
[Epoch 41] ogbg-molhiv: 0.598818 test loss: 72.068548
[Epoch 42; Iter    23/ 1097] train: loss: 0.0018970
[Epoch 42; Iter    53/ 1097] train: loss: 0.0006663
[Epoch 42; Iter    83/ 1097] train: loss: 0.0190942
[Epoch 42; Iter   113/ 1097] train: loss: 0.0006263
[Epoch 42; Iter   143/ 1097] train: loss: 0.0055753
[Epoch 42; Iter   173/ 1097] train: loss: 0.0039511
[Epoch 42; Iter   203/ 1097] train: loss: 0.0094443
[Epoch 42; Iter   233/ 1097] train: loss: 0.0067589
[Epoch 42; Iter   263/ 1097] train: loss: 0.0458645
[Epoch 42; Iter   293/ 1097] train: loss: 0.0001498
[Epoch 42; Iter   323/ 1097] train: loss: 0.0099655
[Epoch 42; Iter   353/ 1097] train: loss: 0.0015064
[Epoch 42; Iter   383/ 1097] train: loss: 0.0001610
[Epoch 42; Iter   413/ 1097] train: loss: 0.0099437
[Epoch 42; Iter   443/ 1097] train: loss: 0.0009969
[Epoch 42; Iter   473/ 1097] train: loss: 0.0035281
[Epoch 42; Iter   503/ 1097] train: loss: 0.0250186
[Epoch 42; Iter   533/ 1097] train: loss: 0.0475466
[Epoch 42; Iter   563/ 1097] train: loss: 0.0003936
[Epoch 42; Iter   593/ 1097] train: loss: 0.0060198
[Epoch 42; Iter   623/ 1097] train: loss: 0.0003658
[Epoch 42; Iter   653/ 1097] train: loss: 0.0131746
[Epoch 42; Iter   683/ 1097] train: loss: 0.0019049
[Epoch 42; Iter   713/ 1097] train: loss: 0.0148739
[Epoch 42; Iter   743/ 1097] train: loss: 0.0917503
[Epoch 42; Iter   773/ 1097] train: loss: 0.0022785
[Epoch 42; Iter   803/ 1097] train: loss: 0.0005625
[Epoch 42; Iter   833/ 1097] train: loss: 0.0261666
[Epoch 42; Iter   863/ 1097] train: loss: 0.0002133
[Epoch 42; Iter   893/ 1097] train: loss: 0.0027117
[Epoch 42; Iter   923/ 1097] train: loss: 0.0365207
[Epoch 42; Iter   953/ 1097] train: loss: 0.0051011
[Epoch 42; Iter   983/ 1097] train: loss: 0.0003133
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0007208
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1106106
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0009339
[Epoch 42] ogbg-molhiv: 0.682503 val loss: 86.312561
[Epoch 42] ogbg-molhiv: 0.589809 test loss: 85.168696
[Epoch 43; Iter     6/ 1097] train: loss: 0.0090398
[Epoch 43; Iter    36/ 1097] train: loss: 0.0031988
[Epoch 43; Iter    66/ 1097] train: loss: 0.0014603
[Epoch 43; Iter    96/ 1097] train: loss: 0.0018263
[Epoch 43; Iter   126/ 1097] train: loss: 0.0120381
[Epoch 43; Iter   156/ 1097] train: loss: 0.0011522
[Epoch 43; Iter   186/ 1097] train: loss: 0.0005757
[Epoch 43; Iter   216/ 1097] train: loss: 0.0083145
[Epoch 43; Iter   246/ 1097] train: loss: 0.0067095
[Epoch 43; Iter   276/ 1097] train: loss: 0.0080685
[Epoch 43; Iter   306/ 1097] train: loss: 0.0275467
[Epoch 43; Iter   336/ 1097] train: loss: 0.0030021
[Epoch 43; Iter   366/ 1097] train: loss: 0.0014168
[Epoch 43; Iter   396/ 1097] train: loss: 0.0016440
[Epoch 43; Iter   426/ 1097] train: loss: 0.0010026
[Epoch 43; Iter   456/ 1097] train: loss: 0.0046727
[Epoch 43; Iter   486/ 1097] train: loss: 0.0063551
[Epoch 43; Iter   516/ 1097] train: loss: 0.0002510
[Epoch 43; Iter   546/ 1097] train: loss: 0.0004747
[Epoch 43; Iter   576/ 1097] train: loss: 0.0044769
[Epoch 43; Iter   606/ 1097] train: loss: 0.0023109
[Epoch 43; Iter   636/ 1097] train: loss: 0.0059713
[Epoch 43; Iter   666/ 1097] train: loss: 0.0022761
[Epoch 43; Iter   696/ 1097] train: loss: 0.0041605
[Epoch 43; Iter   726/ 1097] train: loss: 0.0006400
[Epoch 43; Iter   756/ 1097] train: loss: 0.0004614
[Epoch 43; Iter   786/ 1097] train: loss: 0.0136414
[Epoch 43; Iter   816/ 1097] train: loss: 0.0093390
[Epoch 43; Iter   846/ 1097] train: loss: 0.0002034
[Epoch 43; Iter   876/ 1097] train: loss: 0.0023985
[Epoch 43; Iter   906/ 1097] train: loss: 0.0035860
[Epoch 43; Iter   936/ 1097] train: loss: 0.0005341
[Epoch 43; Iter   966/ 1097] train: loss: 0.0015048
[Epoch 43; Iter   996/ 1097] train: loss: 0.0006825
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0008542
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0565925
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0005398
[Epoch 43] ogbg-molhiv: 0.702136 val loss: 82.334883
[Epoch 43] ogbg-molhiv: 0.577611 test loss: 81.826391
[Epoch 44; Iter    19/ 1097] train: loss: 0.0005223
[Epoch 44; Iter    49/ 1097] train: loss: 0.0002588
[Epoch 44; Iter    79/ 1097] train: loss: 0.0015977
[Epoch 44; Iter   109/ 1097] train: loss: 0.0004665
[Epoch 44; Iter   139/ 1097] train: loss: 0.0003760
[Epoch 44; Iter   169/ 1097] train: loss: 0.0001117
[Epoch 44; Iter   199/ 1097] train: loss: 0.0009695
[Epoch 44; Iter   229/ 1097] train: loss: 0.0061420
[Epoch 44; Iter   259/ 1097] train: loss: 0.0007486
[Epoch 44; Iter   289/ 1097] train: loss: 0.0027692
[Epoch 44; Iter   319/ 1097] train: loss: 0.0000799
[Epoch 44; Iter   349/ 1097] train: loss: 0.0001634
[Epoch 44; Iter   379/ 1097] train: loss: 0.0004206
[Epoch 44; Iter   409/ 1097] train: loss: 0.0012782
[Epoch 44; Iter   439/ 1097] train: loss: 0.0001579
[Epoch 44; Iter   469/ 1097] train: loss: 0.0055455
[Epoch 44; Iter   499/ 1097] train: loss: 0.1152786
[Epoch 44; Iter   529/ 1097] train: loss: 0.0004077
[Epoch 44; Iter   559/ 1097] train: loss: 0.0009002
[Epoch 44; Iter   589/ 1097] train: loss: 0.0005849
[Epoch 44; Iter   619/ 1097] train: loss: 0.0001684
[Epoch 44; Iter   649/ 1097] train: loss: 0.0065856
[Epoch 44; Iter   679/ 1097] train: loss: 0.0255505
[Epoch 44; Iter   709/ 1097] train: loss: 0.0015235
[Epoch 44; Iter   739/ 1097] train: loss: 0.0166098
[Epoch 44; Iter   769/ 1097] train: loss: 0.0001944
[Epoch 44; Iter   799/ 1097] train: loss: 0.0343052
[Epoch 44; Iter   829/ 1097] train: loss: 0.0050607
[Epoch 44; Iter   859/ 1097] train: loss: 0.0008764
[Epoch 44; Iter   889/ 1097] train: loss: 0.0044863
[Epoch 44; Iter   919/ 1097] train: loss: 0.0069010
[Epoch 44; Iter   949/ 1097] train: loss: 0.0050275
[Epoch 44; Iter   979/ 1097] train: loss: 0.0061119
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0032096
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0027545
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0031513
[Epoch 44] ogbg-molhiv: 0.752943 val loss: 0.199518
[Epoch 44] ogbg-molhiv: 0.731634 test loss: 0.331277
[Epoch 45; Iter     2/ 1097] train: loss: 0.0059900
[Epoch 45; Iter    32/ 1097] train: loss: 0.0056394
[Epoch 45; Iter    62/ 1097] train: loss: 0.0024919
[Epoch 45; Iter    92/ 1097] train: loss: 0.0051947
[Epoch 45; Iter   122/ 1097] train: loss: 0.0035372
[Epoch 45; Iter   152/ 1097] train: loss: 0.0017753
[Epoch 45; Iter   182/ 1097] train: loss: 0.0003021
[Epoch 45; Iter   212/ 1097] train: loss: 0.0505193
[Epoch 45; Iter   242/ 1097] train: loss: 0.0004714
[Epoch 45; Iter   272/ 1097] train: loss: 0.0005010
[Epoch 45; Iter   302/ 1097] train: loss: 0.0005647
[Epoch 45; Iter   332/ 1097] train: loss: 0.0013448
[Epoch 45; Iter   362/ 1097] train: loss: 0.0328641
[Epoch 45; Iter   392/ 1097] train: loss: 0.2190443
[Epoch 45; Iter   422/ 1097] train: loss: 0.0575027
[Epoch 45; Iter   452/ 1097] train: loss: 0.0121401
[Epoch 45; Iter   482/ 1097] train: loss: 0.0029109
[Epoch 45; Iter   512/ 1097] train: loss: 0.0096632
[Epoch 45; Iter   542/ 1097] train: loss: 0.0008551
[Epoch 45; Iter   572/ 1097] train: loss: 0.0206394
[Epoch 45; Iter   602/ 1097] train: loss: 0.0060166
[Epoch 45; Iter   632/ 1097] train: loss: 0.0004805
[Epoch 45; Iter   662/ 1097] train: loss: 0.0033566
[Epoch 45; Iter   692/ 1097] train: loss: 0.0374533
[Epoch 45; Iter   722/ 1097] train: loss: 0.0076672
[Epoch 45; Iter   752/ 1097] train: loss: 0.0013906
[Epoch 45; Iter   782/ 1097] train: loss: 0.0015159
[Epoch 45; Iter   812/ 1097] train: loss: 0.0002796
[Epoch 45; Iter   842/ 1097] train: loss: 0.0028149
[Epoch 45; Iter   872/ 1097] train: loss: 0.0113605
[Epoch 45; Iter   902/ 1097] train: loss: 0.0157768
[Epoch 45; Iter   932/ 1097] train: loss: 0.1822348
[Epoch 45; Iter   962/ 1097] train: loss: 0.0005999
[Epoch 45; Iter   992/ 1097] train: loss: 0.0359046
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0240654
[Epoch 45; Iter  1052/ 1097] train: loss: 0.1903518
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0144514
[Epoch 45] ogbg-molhiv: 0.712498 val loss: 0.178648
[Epoch 45] ogbg-molhiv: 0.717758 test loss: 0.303083
[Epoch 46; Iter    15/ 1097] train: loss: 0.0106238
[Epoch 46; Iter    45/ 1097] train: loss: 0.0036501
[Epoch 46; Iter    75/ 1097] train: loss: 0.0050316
[Epoch 46; Iter   105/ 1097] train: loss: 0.0035081
[Epoch 46; Iter   135/ 1097] train: loss: 0.0017322
[Epoch 46; Iter   165/ 1097] train: loss: 0.0030738
[Epoch 46; Iter   195/ 1097] train: loss: 0.0020013
[Epoch 46; Iter   225/ 1097] train: loss: 0.0051003
[Epoch 46; Iter   255/ 1097] train: loss: 0.0004083
[Epoch 46; Iter   285/ 1097] train: loss: 0.0011104
[Epoch 46; Iter   315/ 1097] train: loss: 0.0020192
[Epoch 46; Iter   345/ 1097] train: loss: 0.0200900
[Epoch 46; Iter   375/ 1097] train: loss: 0.0127344
[Epoch 46; Iter   405/ 1097] train: loss: 0.0010262
[Epoch 46; Iter   435/ 1097] train: loss: 0.0014394
[Epoch 46; Iter   465/ 1097] train: loss: 0.0820308
[Epoch 46; Iter   495/ 1097] train: loss: 0.0003702
[Epoch 46; Iter   525/ 1097] train: loss: 0.0015355
[Epoch 46; Iter   555/ 1097] train: loss: 0.0227686
[Epoch 46; Iter   585/ 1097] train: loss: 0.0012908
[Epoch 46; Iter   615/ 1097] train: loss: 0.0560772
[Epoch 46; Iter   645/ 1097] train: loss: 0.0832742
[Epoch 46; Iter   675/ 1097] train: loss: 0.0013049
[Epoch 46; Iter   705/ 1097] train: loss: 0.0013997
[Epoch 46; Iter   735/ 1097] train: loss: 0.0037780
[Epoch 46; Iter   765/ 1097] train: loss: 0.0013448
[Epoch 46; Iter   795/ 1097] train: loss: 0.0025995
[Epoch 46; Iter   825/ 1097] train: loss: 0.0150234
[Epoch 46; Iter   855/ 1097] train: loss: 0.0024909
[Epoch 46; Iter   885/ 1097] train: loss: 0.0681166
[Epoch 46; Iter   915/ 1097] train: loss: 0.1388490
[Epoch 46; Iter   945/ 1097] train: loss: 0.0277948
[Epoch 46; Iter   975/ 1097] train: loss: 0.0111520
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0233835
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0030495
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0062891
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0032676
[Epoch 46] ogbg-molhiv: 0.683036 val loss: 0.284835
[Epoch 46] ogbg-molhiv: 0.721744 test loss: 0.301039
[Epoch 47; Iter    28/ 1097] train: loss: 0.0013736
[Epoch 47; Iter    58/ 1097] train: loss: 0.0011873
[Epoch 47; Iter    88/ 1097] train: loss: 0.0021452
[Epoch 47; Iter   118/ 1097] train: loss: 0.0015034
[Epoch 47; Iter   148/ 1097] train: loss: 0.0019958
[Epoch 47; Iter   178/ 1097] train: loss: 0.0010472
[Epoch 47; Iter   208/ 1097] train: loss: 0.0024247
[Epoch 47; Iter   238/ 1097] train: loss: 0.0004840
[Epoch 47; Iter   268/ 1097] train: loss: 0.0081528
[Epoch 47; Iter   298/ 1097] train: loss: 0.0019158
[Epoch 47; Iter   328/ 1097] train: loss: 0.0024186
[Epoch 47; Iter   358/ 1097] train: loss: 0.0249978
[Epoch 47; Iter   388/ 1097] train: loss: 0.0237331
[Epoch 47; Iter   418/ 1097] train: loss: 0.0002685
[Epoch 47; Iter   448/ 1097] train: loss: 0.0004279
[Epoch 47; Iter   478/ 1097] train: loss: 0.0011926
[Epoch 47; Iter   508/ 1097] train: loss: 0.0019797
[Epoch 47; Iter   538/ 1097] train: loss: 0.0534468
[Epoch 47; Iter   568/ 1097] train: loss: 0.0003977
[Epoch 47; Iter   598/ 1097] train: loss: 0.0011050
[Epoch 47; Iter   628/ 1097] train: loss: 0.0055972
[Epoch 47; Iter   658/ 1097] train: loss: 0.0004104
[Epoch 47; Iter   688/ 1097] train: loss: 0.0600248
[Epoch 47; Iter   718/ 1097] train: loss: 0.0033884
[Epoch 47; Iter   748/ 1097] train: loss: 0.0119582
[Epoch 47; Iter   778/ 1097] train: loss: 0.0037314
[Epoch 47; Iter   808/ 1097] train: loss: 0.0015427
[Epoch 47; Iter   838/ 1097] train: loss: 0.0771721
[Epoch 47; Iter   868/ 1097] train: loss: 0.0708086
[Epoch 47; Iter   898/ 1097] train: loss: 0.0008566
[Epoch 47; Iter   928/ 1097] train: loss: 0.0021893
[Epoch 47; Iter   958/ 1097] train: loss: 0.0011821
[Epoch 47; Iter   988/ 1097] train: loss: 0.0037296
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0020770
[Epoch 47; Iter  1048/ 1097] train: loss: 0.1230887
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0703462
[Epoch 47] ogbg-molhiv: 0.767015 val loss: 0.175459
[Epoch 47] ogbg-molhiv: 0.750130 test loss: 0.259249
[Epoch 48; Iter    11/ 1097] train: loss: 0.0082585
[Epoch 48; Iter    41/ 1097] train: loss: 0.0727339
[Epoch 48; Iter    71/ 1097] train: loss: 0.0036543
[Epoch 48; Iter   101/ 1097] train: loss: 0.0609165
[Epoch 48; Iter   131/ 1097] train: loss: 0.0009021
[Epoch 48; Iter   161/ 1097] train: loss: 0.0019767
[Epoch 48; Iter   191/ 1097] train: loss: 0.0080702
[Epoch 48; Iter   221/ 1097] train: loss: 0.0017258
[Epoch 48; Iter   251/ 1097] train: loss: 0.0038968
[Epoch 48; Iter   281/ 1097] train: loss: 0.0020813
[Epoch 48; Iter   311/ 1097] train: loss: 0.0022214
[Epoch 48; Iter   341/ 1097] train: loss: 0.0015747
[Epoch 48; Iter   371/ 1097] train: loss: 0.0017624
[Epoch 48; Iter   401/ 1097] train: loss: 0.0025631
[Epoch 48; Iter   431/ 1097] train: loss: 0.0440528
[Epoch 48; Iter   461/ 1097] train: loss: 0.0004945
[Epoch 48; Iter   491/ 1097] train: loss: 0.0006172
[Epoch 48; Iter   521/ 1097] train: loss: 0.0007833
[Epoch 48; Iter   551/ 1097] train: loss: 0.0003679
[Epoch 48; Iter   581/ 1097] train: loss: 0.0489061
[Epoch 48; Iter   611/ 1097] train: loss: 0.0014853
[Epoch 48; Iter   641/ 1097] train: loss: 0.0180778
[Epoch 48; Iter   671/ 1097] train: loss: 0.0022435
[Epoch 48; Iter   701/ 1097] train: loss: 0.0348559
[Epoch 48; Iter   731/ 1097] train: loss: 0.0052649
[Epoch 48; Iter   761/ 1097] train: loss: 0.0019485
[Epoch 48; Iter   791/ 1097] train: loss: 0.0040439
[Epoch 48; Iter   821/ 1097] train: loss: 0.0011444
[Epoch 44; Iter   769/ 1097] train: loss: 0.0084837
[Epoch 44; Iter   799/ 1097] train: loss: 0.0429283
[Epoch 44; Iter   829/ 1097] train: loss: 0.0818000
[Epoch 44; Iter   859/ 1097] train: loss: 0.0052530
[Epoch 44; Iter   889/ 1097] train: loss: 0.0773105
[Epoch 44; Iter   919/ 1097] train: loss: 0.0110730
[Epoch 44; Iter   949/ 1097] train: loss: 0.0993806
[Epoch 44; Iter   979/ 1097] train: loss: 0.0305170
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0367623
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0029937
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0984753
[Epoch 44] ogbg-molhiv: 0.694435 val loss: 0.642945
[Epoch 44] ogbg-molhiv: 0.720186 test loss: 0.379283
[Epoch 45; Iter     2/ 1097] train: loss: 0.0143148
[Epoch 45; Iter    32/ 1097] train: loss: 0.0379746
[Epoch 45; Iter    62/ 1097] train: loss: 0.0057897
[Epoch 45; Iter    92/ 1097] train: loss: 0.0226868
[Epoch 45; Iter   122/ 1097] train: loss: 0.0020934
[Epoch 45; Iter   152/ 1097] train: loss: 0.0072251
[Epoch 45; Iter   182/ 1097] train: loss: 0.0192081
[Epoch 45; Iter   212/ 1097] train: loss: 0.0135377
[Epoch 45; Iter   242/ 1097] train: loss: 0.0004541
[Epoch 45; Iter   272/ 1097] train: loss: 0.0054195
[Epoch 45; Iter   302/ 1097] train: loss: 0.0084412
[Epoch 45; Iter   332/ 1097] train: loss: 0.0048851
[Epoch 45; Iter   362/ 1097] train: loss: 0.1040369
[Epoch 45; Iter   392/ 1097] train: loss: 0.0513350
[Epoch 45; Iter   422/ 1097] train: loss: 0.0020749
[Epoch 45; Iter   452/ 1097] train: loss: 0.0125298
[Epoch 45; Iter   482/ 1097] train: loss: 0.0008196
[Epoch 45; Iter   512/ 1097] train: loss: 0.0206939
[Epoch 45; Iter   542/ 1097] train: loss: 0.0021539
[Epoch 45; Iter   572/ 1097] train: loss: 0.0029921
[Epoch 45; Iter   602/ 1097] train: loss: 0.0835483
[Epoch 45; Iter   632/ 1097] train: loss: 0.0081192
[Epoch 45; Iter   662/ 1097] train: loss: 0.0732209
[Epoch 45; Iter   692/ 1097] train: loss: 0.0045326
[Epoch 45; Iter   722/ 1097] train: loss: 0.0097921
[Epoch 45; Iter   752/ 1097] train: loss: 0.0046238
[Epoch 45; Iter   782/ 1097] train: loss: 0.1213534
[Epoch 45; Iter   812/ 1097] train: loss: 0.0819985
[Epoch 45; Iter   842/ 1097] train: loss: 0.0076729
[Epoch 45; Iter   872/ 1097] train: loss: 0.0038235
[Epoch 45; Iter   902/ 1097] train: loss: 0.0100274
[Epoch 45; Iter   932/ 1097] train: loss: 0.0028465
[Epoch 45; Iter   962/ 1097] train: loss: 0.0085848
[Epoch 45; Iter   992/ 1097] train: loss: 0.0269154
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0201024
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0156789
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0736274
[Epoch 45] ogbg-molhiv: 0.687987 val loss: 0.656292
[Epoch 45] ogbg-molhiv: 0.730485 test loss: 0.452496
[Epoch 46; Iter    15/ 1097] train: loss: 0.0034142
[Epoch 46; Iter    45/ 1097] train: loss: 0.0202934
[Epoch 46; Iter    75/ 1097] train: loss: 0.0090778
[Epoch 46; Iter   105/ 1097] train: loss: 0.0064153
[Epoch 46; Iter   135/ 1097] train: loss: 0.1185781
[Epoch 46; Iter   165/ 1097] train: loss: 0.0036621
[Epoch 46; Iter   195/ 1097] train: loss: 0.0128365
[Epoch 46; Iter   225/ 1097] train: loss: 0.0051746
[Epoch 46; Iter   255/ 1097] train: loss: 0.0249937
[Epoch 46; Iter   285/ 1097] train: loss: 0.0053131
[Epoch 46; Iter   315/ 1097] train: loss: 0.0026120
[Epoch 46; Iter   345/ 1097] train: loss: 0.0616053
[Epoch 46; Iter   375/ 1097] train: loss: 0.0094015
[Epoch 46; Iter   405/ 1097] train: loss: 0.0081098
[Epoch 46; Iter   435/ 1097] train: loss: 0.0019157
[Epoch 46; Iter   465/ 1097] train: loss: 0.0021202
[Epoch 46; Iter   495/ 1097] train: loss: 0.0615225
[Epoch 46; Iter   525/ 1097] train: loss: 0.0170246
[Epoch 46; Iter   555/ 1097] train: loss: 0.0155417
[Epoch 46; Iter   585/ 1097] train: loss: 0.0774588
[Epoch 46; Iter   615/ 1097] train: loss: 0.0082764
[Epoch 46; Iter   645/ 1097] train: loss: 0.0013043
[Epoch 46; Iter   675/ 1097] train: loss: 0.0044819
[Epoch 46; Iter   705/ 1097] train: loss: 0.0047429
[Epoch 46; Iter   735/ 1097] train: loss: 0.0231315
[Epoch 46; Iter   765/ 1097] train: loss: 0.0253569
[Epoch 46; Iter   795/ 1097] train: loss: 0.0018027
[Epoch 46; Iter   825/ 1097] train: loss: 0.0121150
[Epoch 46; Iter   855/ 1097] train: loss: 0.0062147
[Epoch 46; Iter   885/ 1097] train: loss: 0.0067004
[Epoch 46; Iter   915/ 1097] train: loss: 0.0584552
[Epoch 46; Iter   945/ 1097] train: loss: 0.0027855
[Epoch 46; Iter   975/ 1097] train: loss: 0.0031699
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0020349
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0033318
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0105642
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0032726
[Epoch 46] ogbg-molhiv: 0.685574 val loss: 11.440162
[Epoch 46] ogbg-molhiv: 0.695789 test loss: 2.965893
[Epoch 47; Iter    28/ 1097] train: loss: 0.0148259
[Epoch 47; Iter    58/ 1097] train: loss: 0.0026254
[Epoch 47; Iter    88/ 1097] train: loss: 0.0105036
[Epoch 47; Iter   118/ 1097] train: loss: 0.1128084
[Epoch 47; Iter   148/ 1097] train: loss: 0.0113600
[Epoch 47; Iter   178/ 1097] train: loss: 0.0268474
[Epoch 47; Iter   208/ 1097] train: loss: 0.0380987
[Epoch 47; Iter   238/ 1097] train: loss: 0.0958897
[Epoch 47; Iter   268/ 1097] train: loss: 0.0020184
[Epoch 47; Iter   298/ 1097] train: loss: 0.0094763
[Epoch 47; Iter   328/ 1097] train: loss: 0.0072061
[Epoch 47; Iter   358/ 1097] train: loss: 0.0056897
[Epoch 47; Iter   388/ 1097] train: loss: 0.0285495
[Epoch 47; Iter   418/ 1097] train: loss: 0.0171634
[Epoch 47; Iter   448/ 1097] train: loss: 0.0380606
[Epoch 47; Iter   478/ 1097] train: loss: 0.0272489
[Epoch 47; Iter   508/ 1097] train: loss: 0.0597246
[Epoch 47; Iter   538/ 1097] train: loss: 0.0212489
[Epoch 47; Iter   568/ 1097] train: loss: 0.0041534
[Epoch 47; Iter   598/ 1097] train: loss: 0.0713123
[Epoch 47; Iter   628/ 1097] train: loss: 0.0034832
[Epoch 47; Iter   658/ 1097] train: loss: 0.0251429
[Epoch 47; Iter   688/ 1097] train: loss: 0.0184095
[Epoch 47; Iter   718/ 1097] train: loss: 0.0090627
[Epoch 47; Iter   748/ 1097] train: loss: 0.0766404
[Epoch 47; Iter   778/ 1097] train: loss: 0.0224493
[Epoch 47; Iter   808/ 1097] train: loss: 0.1147948
[Epoch 47; Iter   838/ 1097] train: loss: 0.0011215
[Epoch 47; Iter   868/ 1097] train: loss: 0.0077368
[Epoch 47; Iter   898/ 1097] train: loss: 0.0160186
[Epoch 47; Iter   928/ 1097] train: loss: 0.0016486
[Epoch 47; Iter   958/ 1097] train: loss: 0.1880031
[Epoch 47; Iter   988/ 1097] train: loss: 0.0794701
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0069290
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0661655
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0038724
[Epoch 47] ogbg-molhiv: 0.703707 val loss: 0.731615
[Epoch 47] ogbg-molhiv: 0.713571 test loss: 0.380489
[Epoch 48; Iter    11/ 1097] train: loss: 0.0830709
[Epoch 48; Iter    41/ 1097] train: loss: 0.0102293
[Epoch 48; Iter    71/ 1097] train: loss: 0.0019833
[Epoch 48; Iter   101/ 1097] train: loss: 0.0844022
[Epoch 48; Iter   131/ 1097] train: loss: 0.0019290
[Epoch 48; Iter   161/ 1097] train: loss: 0.0034319
[Epoch 48; Iter   191/ 1097] train: loss: 0.0092529
[Epoch 48; Iter   221/ 1097] train: loss: 0.0020742
[Epoch 48; Iter   251/ 1097] train: loss: 0.0056632
[Epoch 48; Iter   281/ 1097] train: loss: 0.0055598
[Epoch 48; Iter   311/ 1097] train: loss: 0.0347841
[Epoch 48; Iter   341/ 1097] train: loss: 0.0025030
[Epoch 48; Iter   371/ 1097] train: loss: 0.0006197
[Epoch 48; Iter   401/ 1097] train: loss: 0.0077043
[Epoch 48; Iter   431/ 1097] train: loss: 0.0156800
[Epoch 48; Iter   461/ 1097] train: loss: 0.0398514
[Epoch 48; Iter   491/ 1097] train: loss: 0.0012650
[Epoch 48; Iter   521/ 1097] train: loss: 0.0007435
[Epoch 48; Iter   551/ 1097] train: loss: 0.0739302
[Epoch 48; Iter   581/ 1097] train: loss: 0.0060322
[Epoch 48; Iter   611/ 1097] train: loss: 0.0142978
[Epoch 48; Iter   641/ 1097] train: loss: 0.0277256
[Epoch 48; Iter   671/ 1097] train: loss: 0.0138609
[Epoch 48; Iter   701/ 1097] train: loss: 0.0171222
[Epoch 48; Iter   731/ 1097] train: loss: 0.0096714
[Epoch 48; Iter   761/ 1097] train: loss: 0.0026687
[Epoch 48; Iter   791/ 1097] train: loss: 0.0082827
[Epoch 48; Iter   821/ 1097] train: loss: 0.0014823
[Epoch 44; Iter   769/ 1097] train: loss: 0.0132334
[Epoch 44; Iter   799/ 1097] train: loss: 0.0239817
[Epoch 44; Iter   829/ 1097] train: loss: 0.0244536
[Epoch 44; Iter   859/ 1097] train: loss: 0.0314992
[Epoch 44; Iter   889/ 1097] train: loss: 0.1181017
[Epoch 44; Iter   919/ 1097] train: loss: 0.0163969
[Epoch 44; Iter   949/ 1097] train: loss: 0.0031749
[Epoch 44; Iter   979/ 1097] train: loss: 0.0046258
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1072516
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0026640
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0053869
[Epoch 44] ogbg-molhiv: 0.762373 val loss: 0.213510
[Epoch 44] ogbg-molhiv: 0.732411 test loss: 0.228588
[Epoch 45; Iter     2/ 1097] train: loss: 0.0192463
[Epoch 45; Iter    32/ 1097] train: loss: 0.0037367
[Epoch 45; Iter    62/ 1097] train: loss: 0.0013932
[Epoch 45; Iter    92/ 1097] train: loss: 0.0350212
[Epoch 45; Iter   122/ 1097] train: loss: 0.0838802
[Epoch 45; Iter   152/ 1097] train: loss: 0.0199454
[Epoch 45; Iter   182/ 1097] train: loss: 0.0068517
[Epoch 45; Iter   212/ 1097] train: loss: 0.2048407
[Epoch 45; Iter   242/ 1097] train: loss: 0.0003290
[Epoch 45; Iter   272/ 1097] train: loss: 0.0058354
[Epoch 45; Iter   302/ 1097] train: loss: 0.1495193
[Epoch 45; Iter   332/ 1097] train: loss: 0.0182881
[Epoch 45; Iter   362/ 1097] train: loss: 0.0006815
[Epoch 45; Iter   392/ 1097] train: loss: 0.0046657
[Epoch 45; Iter   422/ 1097] train: loss: 0.0065452
[Epoch 45; Iter   452/ 1097] train: loss: 0.0014899
[Epoch 45; Iter   482/ 1097] train: loss: 0.0200964
[Epoch 45; Iter   512/ 1097] train: loss: 0.0024458
[Epoch 45; Iter   542/ 1097] train: loss: 0.0019793
[Epoch 45; Iter   572/ 1097] train: loss: 0.0064369
[Epoch 45; Iter   602/ 1097] train: loss: 0.0021122
[Epoch 45; Iter   632/ 1097] train: loss: 0.0237100
[Epoch 45; Iter   662/ 1097] train: loss: 0.0004737
[Epoch 45; Iter   692/ 1097] train: loss: 0.0028906
[Epoch 45; Iter   722/ 1097] train: loss: 0.0784300
[Epoch 45; Iter   752/ 1097] train: loss: 0.0180582
[Epoch 45; Iter   782/ 1097] train: loss: 0.0020397
[Epoch 45; Iter   812/ 1097] train: loss: 0.0002800
[Epoch 45; Iter   842/ 1097] train: loss: 0.0006167
[Epoch 45; Iter   872/ 1097] train: loss: 0.0282467
[Epoch 45; Iter   902/ 1097] train: loss: 0.0004796
[Epoch 45; Iter   932/ 1097] train: loss: 0.0115651
[Epoch 45; Iter   962/ 1097] train: loss: 0.0009855
[Epoch 45; Iter   992/ 1097] train: loss: 0.0152879
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0515557
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0038659
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0007291
[Epoch 45] ogbg-molhiv: 0.760897 val loss: 0.211613
[Epoch 45] ogbg-molhiv: 0.741764 test loss: 0.280568
[Epoch 46; Iter    15/ 1097] train: loss: 0.0037420
[Epoch 46; Iter    45/ 1097] train: loss: 0.0048208
[Epoch 46; Iter    75/ 1097] train: loss: 0.0079644
[Epoch 46; Iter   105/ 1097] train: loss: 0.0058205
[Epoch 46; Iter   135/ 1097] train: loss: 0.0044525
[Epoch 46; Iter   165/ 1097] train: loss: 0.0017884
[Epoch 46; Iter   195/ 1097] train: loss: 0.0063698
[Epoch 46; Iter   225/ 1097] train: loss: 0.0862962
[Epoch 46; Iter   255/ 1097] train: loss: 0.0022090
[Epoch 46; Iter   285/ 1097] train: loss: 0.0061882
[Epoch 46; Iter   315/ 1097] train: loss: 0.0013995
[Epoch 46; Iter   345/ 1097] train: loss: 0.0042171
[Epoch 46; Iter   375/ 1097] train: loss: 0.0008495
[Epoch 46; Iter   405/ 1097] train: loss: 0.0119753
[Epoch 46; Iter   435/ 1097] train: loss: 0.0295873
[Epoch 46; Iter   465/ 1097] train: loss: 0.0060238
[Epoch 46; Iter   495/ 1097] train: loss: 0.0015659
[Epoch 46; Iter   525/ 1097] train: loss: 0.1043211
[Epoch 46; Iter   555/ 1097] train: loss: 0.0103282
[Epoch 46; Iter   585/ 1097] train: loss: 0.0002818
[Epoch 46; Iter   615/ 1097] train: loss: 0.0034621
[Epoch 46; Iter   645/ 1097] train: loss: 0.0026384
[Epoch 46; Iter   675/ 1097] train: loss: 0.2123370
[Epoch 46; Iter   705/ 1097] train: loss: 0.0198974
[Epoch 46; Iter   735/ 1097] train: loss: 0.0148740
[Epoch 46; Iter   765/ 1097] train: loss: 0.0969929
[Epoch 46; Iter   795/ 1097] train: loss: 0.0576406
[Epoch 46; Iter   825/ 1097] train: loss: 0.0173877
[Epoch 46; Iter   855/ 1097] train: loss: 0.0868452
[Epoch 46; Iter   885/ 1097] train: loss: 0.0025308
[Epoch 46; Iter   915/ 1097] train: loss: 0.0088684
[Epoch 46; Iter   945/ 1097] train: loss: 0.0029369
[Epoch 46; Iter   975/ 1097] train: loss: 0.0408058
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0084907
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0116332
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0005706
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0051173
[Epoch 46] ogbg-molhiv: 0.770193 val loss: 0.232206
[Epoch 46] ogbg-molhiv: 0.756197 test loss: 0.248255
[Epoch 47; Iter    28/ 1097] train: loss: 0.0374434
[Epoch 47; Iter    58/ 1097] train: loss: 0.0015958
[Epoch 47; Iter    88/ 1097] train: loss: 0.0574206
[Epoch 47; Iter   118/ 1097] train: loss: 0.0016697
[Epoch 47; Iter   148/ 1097] train: loss: 0.0054144
[Epoch 47; Iter   178/ 1097] train: loss: 0.0046236
[Epoch 47; Iter   208/ 1097] train: loss: 0.0095758
[Epoch 47; Iter   238/ 1097] train: loss: 0.0009319
[Epoch 47; Iter   268/ 1097] train: loss: 0.0051045
[Epoch 47; Iter   298/ 1097] train: loss: 0.0015581
[Epoch 47; Iter   328/ 1097] train: loss: 0.0127730
[Epoch 47; Iter   358/ 1097] train: loss: 0.0343707
[Epoch 47; Iter   388/ 1097] train: loss: 0.0340677
[Epoch 47; Iter   418/ 1097] train: loss: 0.0015456
[Epoch 47; Iter   448/ 1097] train: loss: 0.0481928
[Epoch 47; Iter   478/ 1097] train: loss: 0.0548638
[Epoch 47; Iter   508/ 1097] train: loss: 0.0478118
[Epoch 47; Iter   538/ 1097] train: loss: 0.0079391
[Epoch 47; Iter   568/ 1097] train: loss: 0.0011278
[Epoch 47; Iter   598/ 1097] train: loss: 0.0209873
[Epoch 47; Iter   628/ 1097] train: loss: 0.0007901
[Epoch 47; Iter   658/ 1097] train: loss: 0.0523890
[Epoch 47; Iter   688/ 1097] train: loss: 0.0030283
[Epoch 47; Iter   718/ 1097] train: loss: 0.0165445
[Epoch 47; Iter   748/ 1097] train: loss: 0.0002753
[Epoch 47; Iter   778/ 1097] train: loss: 0.0493618
[Epoch 47; Iter   808/ 1097] train: loss: 0.0004242
[Epoch 47; Iter   838/ 1097] train: loss: 0.0076314
[Epoch 47; Iter   868/ 1097] train: loss: 0.0015227
[Epoch 47; Iter   898/ 1097] train: loss: 0.0036809
[Epoch 47; Iter   928/ 1097] train: loss: 0.0004617
[Epoch 47; Iter   958/ 1097] train: loss: 0.0037109
[Epoch 47; Iter   988/ 1097] train: loss: 0.0016105
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0027149
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0017683
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0723464
[Epoch 47] ogbg-molhiv: 0.775944 val loss: 0.237956
[Epoch 47] ogbg-molhiv: 0.762496 test loss: 0.249005
[Epoch 48; Iter    11/ 1097] train: loss: 0.0048961
[Epoch 48; Iter    41/ 1097] train: loss: 0.0031412
[Epoch 48; Iter    71/ 1097] train: loss: 0.0010033
[Epoch 48; Iter   101/ 1097] train: loss: 0.0119197
[Epoch 48; Iter   131/ 1097] train: loss: 0.0113457
[Epoch 48; Iter   161/ 1097] train: loss: 0.0001852
[Epoch 48; Iter   191/ 1097] train: loss: 0.0226869
[Epoch 48; Iter   221/ 1097] train: loss: 0.0082463
[Epoch 48; Iter   251/ 1097] train: loss: 0.0021815
[Epoch 48; Iter   281/ 1097] train: loss: 0.0037594
[Epoch 48; Iter   311/ 1097] train: loss: 0.0237917
[Epoch 48; Iter   341/ 1097] train: loss: 0.0388981
[Epoch 48; Iter   371/ 1097] train: loss: 0.0053769
[Epoch 48; Iter   401/ 1097] train: loss: 0.0492669
[Epoch 48; Iter   431/ 1097] train: loss: 0.0007271
[Epoch 48; Iter   461/ 1097] train: loss: 0.0038076
[Epoch 48; Iter   491/ 1097] train: loss: 0.0258180
[Epoch 48; Iter   521/ 1097] train: loss: 0.0028019
[Epoch 48; Iter   551/ 1097] train: loss: 0.0005184
[Epoch 48; Iter   581/ 1097] train: loss: 0.0020658
[Epoch 48; Iter   611/ 1097] train: loss: 0.0012077
[Epoch 48; Iter   641/ 1097] train: loss: 0.0023919
[Epoch 48; Iter   671/ 1097] train: loss: 0.0019592
[Epoch 48; Iter   701/ 1097] train: loss: 0.0005237
[Epoch 48; Iter   731/ 1097] train: loss: 0.0013346
[Epoch 48; Iter   761/ 1097] train: loss: 0.0745275
[Epoch 48; Iter   791/ 1097] train: loss: 0.0148292
[Epoch 48; Iter   821/ 1097] train: loss: 0.0353043
[Epoch 36; Iter   605/ 1097] train: loss: 0.1786170
[Epoch 36; Iter   635/ 1097] train: loss: 0.2629267
[Epoch 36; Iter   665/ 1097] train: loss: 0.0497893
[Epoch 36; Iter   695/ 1097] train: loss: 0.0184152
[Epoch 36; Iter   725/ 1097] train: loss: 0.1371168
[Epoch 36; Iter   755/ 1097] train: loss: 0.0214635
[Epoch 36; Iter   785/ 1097] train: loss: 0.0806892
[Epoch 36; Iter   815/ 1097] train: loss: 0.1393802
[Epoch 36; Iter   845/ 1097] train: loss: 0.1044789
[Epoch 36; Iter   875/ 1097] train: loss: 0.0427057
[Epoch 36; Iter   905/ 1097] train: loss: 0.0426379
[Epoch 36; Iter   935/ 1097] train: loss: 0.0502420
[Epoch 36; Iter   965/ 1097] train: loss: 0.0761369
[Epoch 36; Iter   995/ 1097] train: loss: 0.0318942
[Epoch 36; Iter  1025/ 1097] train: loss: 0.2841747
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0444281
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0161586
[Epoch 36] ogbg-molhiv: 0.846031 val loss: 0.076518
[Epoch 36] ogbg-molhiv: 0.753338 test loss: 0.132270
[Epoch 37; Iter    18/ 1097] train: loss: 0.0419383
[Epoch 37; Iter    48/ 1097] train: loss: 0.0212161
[Epoch 37; Iter    78/ 1097] train: loss: 0.0610578
[Epoch 37; Iter   108/ 1097] train: loss: 0.1120768
[Epoch 37; Iter   138/ 1097] train: loss: 0.0302942
[Epoch 37; Iter   168/ 1097] train: loss: 0.1469840
[Epoch 37; Iter   198/ 1097] train: loss: 0.0455700
[Epoch 37; Iter   228/ 1097] train: loss: 0.0295229
[Epoch 37; Iter   258/ 1097] train: loss: 0.1867337
[Epoch 37; Iter   288/ 1097] train: loss: 0.0966942
[Epoch 37; Iter   318/ 1097] train: loss: 0.0307448
[Epoch 37; Iter   348/ 1097] train: loss: 0.1097034
[Epoch 37; Iter   378/ 1097] train: loss: 0.0208215
[Epoch 37; Iter   408/ 1097] train: loss: 0.0321047
[Epoch 37; Iter   438/ 1097] train: loss: 0.0096596
[Epoch 37; Iter   468/ 1097] train: loss: 0.1373528
[Epoch 37; Iter   498/ 1097] train: loss: 0.0110543
[Epoch 37; Iter   528/ 1097] train: loss: 0.3174600
[Epoch 37; Iter   558/ 1097] train: loss: 0.3279251
[Epoch 37; Iter   588/ 1097] train: loss: 0.0083895
[Epoch 37; Iter   618/ 1097] train: loss: 0.0448870
[Epoch 37; Iter   648/ 1097] train: loss: 0.0752184
[Epoch 37; Iter   678/ 1097] train: loss: 0.0141055
[Epoch 37; Iter   708/ 1097] train: loss: 0.0681039
[Epoch 37; Iter   738/ 1097] train: loss: 0.1671371
[Epoch 37; Iter   768/ 1097] train: loss: 0.0415356
[Epoch 37; Iter   798/ 1097] train: loss: 0.0814449
[Epoch 37; Iter   828/ 1097] train: loss: 0.0362685
[Epoch 37; Iter   858/ 1097] train: loss: 0.1789389
[Epoch 37; Iter   888/ 1097] train: loss: 0.0085254
[Epoch 37; Iter   918/ 1097] train: loss: 0.1470701
[Epoch 37; Iter   948/ 1097] train: loss: 0.0103839
[Epoch 37; Iter   978/ 1097] train: loss: 0.0160564
[Epoch 37; Iter  1008/ 1097] train: loss: 0.1492562
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0529022
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0624969
[Epoch 37] ogbg-molhiv: 0.830425 val loss: 0.079147
[Epoch 37] ogbg-molhiv: 0.746702 test loss: 0.136416
[Epoch 38; Iter     1/ 1097] train: loss: 0.1223586
[Epoch 38; Iter    31/ 1097] train: loss: 0.0099191
[Epoch 38; Iter    61/ 1097] train: loss: 0.1156407
[Epoch 38; Iter    91/ 1097] train: loss: 0.0521942
[Epoch 38; Iter   121/ 1097] train: loss: 0.0163668
[Epoch 38; Iter   151/ 1097] train: loss: 0.0182452
[Epoch 38; Iter   181/ 1097] train: loss: 0.0281791
[Epoch 38; Iter   211/ 1097] train: loss: 0.0115717
[Epoch 38; Iter   241/ 1097] train: loss: 0.0147641
[Epoch 38; Iter   271/ 1097] train: loss: 0.0360593
[Epoch 38; Iter   301/ 1097] train: loss: 0.0215398
[Epoch 38; Iter   331/ 1097] train: loss: 0.0440567
[Epoch 38; Iter   361/ 1097] train: loss: 0.1492504
[Epoch 38; Iter   391/ 1097] train: loss: 0.0994946
[Epoch 38; Iter   421/ 1097] train: loss: 0.1516779
[Epoch 38; Iter   451/ 1097] train: loss: 0.0328127
[Epoch 38; Iter   481/ 1097] train: loss: 0.1903128
[Epoch 38; Iter   511/ 1097] train: loss: 0.0854459
[Epoch 38; Iter   541/ 1097] train: loss: 0.1617170
[Epoch 38; Iter   571/ 1097] train: loss: 0.0088022
[Epoch 38; Iter   601/ 1097] train: loss: 0.1544884
[Epoch 38; Iter   631/ 1097] train: loss: 0.0739206
[Epoch 38; Iter   661/ 1097] train: loss: 0.0654540
[Epoch 38; Iter   691/ 1097] train: loss: 0.0187673
[Epoch 38; Iter   721/ 1097] train: loss: 0.1598186
[Epoch 38; Iter   751/ 1097] train: loss: 0.1552791
[Epoch 38; Iter   781/ 1097] train: loss: 0.0583304
[Epoch 38; Iter   811/ 1097] train: loss: 0.1449498
[Epoch 38; Iter   841/ 1097] train: loss: 0.0190906
[Epoch 38; Iter   871/ 1097] train: loss: 0.0143902
[Epoch 38; Iter   901/ 1097] train: loss: 0.0144169
[Epoch 38; Iter   931/ 1097] train: loss: 0.0399274
[Epoch 38; Iter   961/ 1097] train: loss: 0.0799575
[Epoch 38; Iter   991/ 1097] train: loss: 0.1754728
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0093376
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0487672
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0987433
[Epoch 38] ogbg-molhiv: 0.833652 val loss: 0.082116
[Epoch 38] ogbg-molhiv: 0.741370 test loss: 0.147267
[Epoch 39; Iter    14/ 1097] train: loss: 0.0914220
[Epoch 39; Iter    44/ 1097] train: loss: 0.1356660
[Epoch 39; Iter    74/ 1097] train: loss: 0.0320939
[Epoch 39; Iter   104/ 1097] train: loss: 0.0563315
[Epoch 39; Iter   134/ 1097] train: loss: 0.1413825
[Epoch 39; Iter   164/ 1097] train: loss: 0.0103496
[Epoch 39; Iter   194/ 1097] train: loss: 0.0171317
[Epoch 39; Iter   224/ 1097] train: loss: 0.0210315
[Epoch 39; Iter   254/ 1097] train: loss: 0.0262475
[Epoch 39; Iter   284/ 1097] train: loss: 0.0159003
[Epoch 39; Iter   314/ 1097] train: loss: 0.0810978
[Epoch 39; Iter   344/ 1097] train: loss: 0.0325638
[Epoch 39; Iter   374/ 1097] train: loss: 0.0345766
[Epoch 39; Iter   404/ 1097] train: loss: 0.0610637
[Epoch 39; Iter   434/ 1097] train: loss: 0.0157364
[Epoch 39; Iter   464/ 1097] train: loss: 0.0401766
[Epoch 39; Iter   494/ 1097] train: loss: 0.0188794
[Epoch 39; Iter   524/ 1097] train: loss: 0.0184480
[Epoch 39; Iter   554/ 1097] train: loss: 0.0304157
[Epoch 39; Iter   584/ 1097] train: loss: 0.0491415
[Epoch 39; Iter   614/ 1097] train: loss: 0.0444690
[Epoch 39; Iter   644/ 1097] train: loss: 0.0784593
[Epoch 39; Iter   674/ 1097] train: loss: 0.0311228
[Epoch 39; Iter   704/ 1097] train: loss: 0.0193216
[Epoch 39; Iter   734/ 1097] train: loss: 0.2690133
[Epoch 39; Iter   764/ 1097] train: loss: 0.0902033
[Epoch 39; Iter   794/ 1097] train: loss: 0.0280195
[Epoch 39; Iter   824/ 1097] train: loss: 0.0171865
[Epoch 39; Iter   854/ 1097] train: loss: 0.1188014
[Epoch 39; Iter   884/ 1097] train: loss: 0.0592343
[Epoch 39; Iter   914/ 1097] train: loss: 0.0277557
[Epoch 39; Iter   944/ 1097] train: loss: 0.0432111
[Epoch 39; Iter   974/ 1097] train: loss: 0.0093633
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0481696
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0298624
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0772080
[Epoch 39; Iter  1094/ 1097] train: loss: 0.2399216
[Epoch 39] ogbg-molhiv: 0.817332 val loss: 0.082272
[Epoch 39] ogbg-molhiv: 0.745399 test loss: 0.136724
[Epoch 40; Iter    27/ 1097] train: loss: 0.0147022
[Epoch 40; Iter    57/ 1097] train: loss: 0.0488613
[Epoch 40; Iter    87/ 1097] train: loss: 0.0266105
[Epoch 40; Iter   117/ 1097] train: loss: 0.1122191
[Epoch 40; Iter   147/ 1097] train: loss: 0.0246579
[Epoch 40; Iter   177/ 1097] train: loss: 0.0953589
[Epoch 40; Iter   207/ 1097] train: loss: 0.1020793
[Epoch 40; Iter   237/ 1097] train: loss: 0.0127117
[Epoch 40; Iter   267/ 1097] train: loss: 0.0149361
[Epoch 40; Iter   297/ 1097] train: loss: 0.1712008
[Epoch 40; Iter   327/ 1097] train: loss: 0.1409993
[Epoch 40; Iter   357/ 1097] train: loss: 0.0204564
[Epoch 40; Iter   387/ 1097] train: loss: 0.0259029
[Epoch 40; Iter   417/ 1097] train: loss: 0.0820381
[Epoch 40; Iter   447/ 1097] train: loss: 0.0980265
[Epoch 40; Iter   477/ 1097] train: loss: 0.0164675
[Epoch 40; Iter   507/ 1097] train: loss: 0.0191704
[Epoch 40; Iter   537/ 1097] train: loss: 0.1438905
[Epoch 40; Iter   567/ 1097] train: loss: 0.0112998
[Epoch 40; Iter   597/ 1097] train: loss: 0.0460348
[Epoch 40; Iter   627/ 1097] train: loss: 0.0404195
[Epoch 40; Iter   657/ 1097] train: loss: 0.0188701
[Epoch 44; Iter   769/ 1097] train: loss: 0.0035873
[Epoch 44; Iter   799/ 1097] train: loss: 0.0036948
[Epoch 44; Iter   829/ 1097] train: loss: 0.0267898
[Epoch 44; Iter   859/ 1097] train: loss: 0.0493697
[Epoch 44; Iter   889/ 1097] train: loss: 0.0005833
[Epoch 44; Iter   919/ 1097] train: loss: 0.0019587
[Epoch 44; Iter   949/ 1097] train: loss: 0.0025028
[Epoch 44; Iter   979/ 1097] train: loss: 0.0002706
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0007458
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0118788
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0476130
[Epoch 44] ogbg-molhiv: 0.760937 val loss: 0.168995
[Epoch 44] ogbg-molhiv: 0.709525 test loss: 0.279266
[Epoch 45; Iter     2/ 1097] train: loss: 0.0060100
[Epoch 45; Iter    32/ 1097] train: loss: 0.0158494
[Epoch 45; Iter    62/ 1097] train: loss: 0.0007520
[Epoch 45; Iter    92/ 1097] train: loss: 0.0010609
[Epoch 45; Iter   122/ 1097] train: loss: 0.0352010
[Epoch 45; Iter   152/ 1097] train: loss: 0.0324723
[Epoch 45; Iter   182/ 1097] train: loss: 0.0123273
[Epoch 45; Iter   212/ 1097] train: loss: 0.0076887
[Epoch 45; Iter   242/ 1097] train: loss: 0.0009041
[Epoch 45; Iter   272/ 1097] train: loss: 0.0049419
[Epoch 45; Iter   302/ 1097] train: loss: 0.0137014
[Epoch 45; Iter   332/ 1097] train: loss: 0.0041110
[Epoch 45; Iter   362/ 1097] train: loss: 0.0051372
[Epoch 45; Iter   392/ 1097] train: loss: 0.0016546
[Epoch 45; Iter   422/ 1097] train: loss: 0.1451342
[Epoch 45; Iter   452/ 1097] train: loss: 0.0001540
[Epoch 45; Iter   482/ 1097] train: loss: 0.0031557
[Epoch 45; Iter   512/ 1097] train: loss: 0.0010070
[Epoch 45; Iter   542/ 1097] train: loss: 0.0002750
[Epoch 45; Iter   572/ 1097] train: loss: 0.0026252
[Epoch 45; Iter   602/ 1097] train: loss: 0.0310602
[Epoch 45; Iter   632/ 1097] train: loss: 0.0003878
[Epoch 45; Iter   662/ 1097] train: loss: 0.0028894
[Epoch 45; Iter   692/ 1097] train: loss: 0.0006608
[Epoch 45; Iter   722/ 1097] train: loss: 0.0005940
[Epoch 45; Iter   752/ 1097] train: loss: 0.0016501
[Epoch 45; Iter   782/ 1097] train: loss: 0.1648876
[Epoch 45; Iter   812/ 1097] train: loss: 0.0061657
[Epoch 45; Iter   842/ 1097] train: loss: 0.0013980
[Epoch 45; Iter   872/ 1097] train: loss: 0.0199404
[Epoch 45; Iter   902/ 1097] train: loss: 0.0055764
[Epoch 45; Iter   932/ 1097] train: loss: 0.0031858
[Epoch 45; Iter   962/ 1097] train: loss: 0.0007950
[Epoch 45; Iter   992/ 1097] train: loss: 0.0005393
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0074762
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0017955
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0094763
[Epoch 45] ogbg-molhiv: 0.751718 val loss: 0.169887
[Epoch 45] ogbg-molhiv: 0.719664 test loss: 0.265947
[Epoch 46; Iter    15/ 1097] train: loss: 0.0231164
[Epoch 46; Iter    45/ 1097] train: loss: 0.0009328
[Epoch 46; Iter    75/ 1097] train: loss: 0.0064803
[Epoch 46; Iter   105/ 1097] train: loss: 0.0211134
[Epoch 46; Iter   135/ 1097] train: loss: 0.0060073
[Epoch 46; Iter   165/ 1097] train: loss: 0.0046845
[Epoch 46; Iter   195/ 1097] train: loss: 0.0072480
[Epoch 46; Iter   225/ 1097] train: loss: 0.0008958
[Epoch 46; Iter   255/ 1097] train: loss: 0.0010366
[Epoch 46; Iter   285/ 1097] train: loss: 0.0115301
[Epoch 46; Iter   315/ 1097] train: loss: 0.0042819
[Epoch 46; Iter   345/ 1097] train: loss: 0.0022807
[Epoch 46; Iter   375/ 1097] train: loss: 0.0056810
[Epoch 46; Iter   405/ 1097] train: loss: 0.0009131
[Epoch 46; Iter   435/ 1097] train: loss: 0.0077011
[Epoch 46; Iter   465/ 1097] train: loss: 0.0069185
[Epoch 46; Iter   495/ 1097] train: loss: 0.0021804
[Epoch 46; Iter   525/ 1097] train: loss: 0.0587519
[Epoch 46; Iter   555/ 1097] train: loss: 0.0118424
[Epoch 46; Iter   585/ 1097] train: loss: 0.0524260
[Epoch 46; Iter   615/ 1097] train: loss: 0.0007127
[Epoch 46; Iter   645/ 1097] train: loss: 0.0006092
[Epoch 46; Iter   675/ 1097] train: loss: 0.0047022
[Epoch 46; Iter   705/ 1097] train: loss: 0.0023415
[Epoch 46; Iter   735/ 1097] train: loss: 0.0034370
[Epoch 46; Iter   765/ 1097] train: loss: 0.0972661
[Epoch 46; Iter   795/ 1097] train: loss: 0.0019856
[Epoch 46; Iter   825/ 1097] train: loss: 0.0133679
[Epoch 46; Iter   855/ 1097] train: loss: 0.0003382
[Epoch 46; Iter   885/ 1097] train: loss: 0.0060709
[Epoch 46; Iter   915/ 1097] train: loss: 0.0024428
[Epoch 46; Iter   945/ 1097] train: loss: 0.0001406
[Epoch 46; Iter   975/ 1097] train: loss: 0.0010231
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0025118
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0050815
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0006167
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0028414
[Epoch 46] ogbg-molhiv: 0.798541 val loss: 0.195826
[Epoch 46] ogbg-molhiv: 0.711462 test loss: 0.289205
[Epoch 47; Iter    28/ 1097] train: loss: 0.0039071
[Epoch 47; Iter    58/ 1097] train: loss: 0.0450444
[Epoch 47; Iter    88/ 1097] train: loss: 0.0264895
[Epoch 47; Iter   118/ 1097] train: loss: 0.0438319
[Epoch 47; Iter   148/ 1097] train: loss: 0.0013610
[Epoch 47; Iter   178/ 1097] train: loss: 0.0001567
[Epoch 47; Iter   208/ 1097] train: loss: 0.0015982
[Epoch 47; Iter   238/ 1097] train: loss: 0.0011061
[Epoch 47; Iter   268/ 1097] train: loss: 0.0090936
[Epoch 47; Iter   298/ 1097] train: loss: 0.0002727
[Epoch 47; Iter   328/ 1097] train: loss: 0.0006453
[Epoch 47; Iter   358/ 1097] train: loss: 0.0013600
[Epoch 47; Iter   388/ 1097] train: loss: 0.0073464
[Epoch 47; Iter   418/ 1097] train: loss: 0.0005610
[Epoch 47; Iter   448/ 1097] train: loss: 0.0005172
[Epoch 47; Iter   478/ 1097] train: loss: 0.0002327
[Epoch 47; Iter   508/ 1097] train: loss: 0.0003279
[Epoch 47; Iter   538/ 1097] train: loss: 0.1220947
[Epoch 47; Iter   568/ 1097] train: loss: 0.0065325
[Epoch 47; Iter   598/ 1097] train: loss: 0.0506821
[Epoch 47; Iter   628/ 1097] train: loss: 0.0006755
[Epoch 47; Iter   658/ 1097] train: loss: 0.0038670
[Epoch 47; Iter   688/ 1097] train: loss: 0.0340822
[Epoch 47; Iter   718/ 1097] train: loss: 0.0705869
[Epoch 47; Iter   748/ 1097] train: loss: 0.0540651
[Epoch 47; Iter   778/ 1097] train: loss: 0.0026564
[Epoch 47; Iter   808/ 1097] train: loss: 0.0030341
[Epoch 47; Iter   838/ 1097] train: loss: 0.0018701
[Epoch 47; Iter   868/ 1097] train: loss: 0.0038701
[Epoch 47; Iter   898/ 1097] train: loss: 0.0032405
[Epoch 47; Iter   928/ 1097] train: loss: 0.0056431
[Epoch 47; Iter   958/ 1097] train: loss: 0.0817577
[Epoch 47; Iter   988/ 1097] train: loss: 0.2599474
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0016273
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0076946
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0011197
[Epoch 47] ogbg-molhiv: 0.794502 val loss: 0.191630
[Epoch 47] ogbg-molhiv: 0.733954 test loss: 0.280262
[Epoch 48; Iter    11/ 1097] train: loss: 0.0054672
[Epoch 48; Iter    41/ 1097] train: loss: 0.0009231
[Epoch 48; Iter    71/ 1097] train: loss: 0.0075971
[Epoch 48; Iter   101/ 1097] train: loss: 0.0506105
[Epoch 48; Iter   131/ 1097] train: loss: 0.0001999
[Epoch 48; Iter   161/ 1097] train: loss: 0.0007406
[Epoch 48; Iter   191/ 1097] train: loss: 0.0012438
[Epoch 48; Iter   221/ 1097] train: loss: 0.0000784
[Epoch 48; Iter   251/ 1097] train: loss: 0.0063405
[Epoch 48; Iter   281/ 1097] train: loss: 0.0087626
[Epoch 48; Iter   311/ 1097] train: loss: 0.0025181
[Epoch 48; Iter   341/ 1097] train: loss: 0.0007360
[Epoch 48; Iter   371/ 1097] train: loss: 0.0002120
[Epoch 48; Iter   401/ 1097] train: loss: 0.0022054
[Epoch 48; Iter   431/ 1097] train: loss: 0.0062187
[Epoch 48; Iter   461/ 1097] train: loss: 0.0421193
[Epoch 48; Iter   491/ 1097] train: loss: 0.0094155
[Epoch 48; Iter   521/ 1097] train: loss: 0.0138317
[Epoch 48; Iter   551/ 1097] train: loss: 0.0009140
[Epoch 48; Iter   581/ 1097] train: loss: 0.0304406
[Epoch 48; Iter   611/ 1097] train: loss: 0.0024479
[Epoch 48; Iter   641/ 1097] train: loss: 0.0027688
[Epoch 48; Iter   671/ 1097] train: loss: 0.0060202
[Epoch 48; Iter   701/ 1097] train: loss: 0.0031633
[Epoch 48; Iter   731/ 1097] train: loss: 0.0011609
[Epoch 48; Iter   761/ 1097] train: loss: 0.0527992
[Epoch 48; Iter   791/ 1097] train: loss: 0.0058683
[Epoch 48; Iter   821/ 1097] train: loss: 0.0150514
[Epoch 44; Iter   769/ 1097] train: loss: 0.0359422
[Epoch 44; Iter   799/ 1097] train: loss: 0.0562277
[Epoch 44; Iter   829/ 1097] train: loss: 0.0042446
[Epoch 44; Iter   859/ 1097] train: loss: 0.0004950
[Epoch 44; Iter   889/ 1097] train: loss: 0.0098730
[Epoch 44; Iter   919/ 1097] train: loss: 0.1591111
[Epoch 44; Iter   949/ 1097] train: loss: 0.0044506
[Epoch 44; Iter   979/ 1097] train: loss: 0.0130485
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1724478
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0048477
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0064476
[Epoch 44] ogbg-molhiv: 0.785393 val loss: 0.164251
[Epoch 44] ogbg-molhiv: 0.703268 test loss: 0.334940
[Epoch 45; Iter     2/ 1097] train: loss: 0.0017404
[Epoch 45; Iter    32/ 1097] train: loss: 0.0050149
[Epoch 45; Iter    62/ 1097] train: loss: 0.0146241
[Epoch 45; Iter    92/ 1097] train: loss: 0.0239262
[Epoch 45; Iter   122/ 1097] train: loss: 0.0408964
[Epoch 45; Iter   152/ 1097] train: loss: 0.0052663
[Epoch 45; Iter   182/ 1097] train: loss: 0.0018505
[Epoch 45; Iter   212/ 1097] train: loss: 0.0312068
[Epoch 45; Iter   242/ 1097] train: loss: 0.0009494
[Epoch 45; Iter   272/ 1097] train: loss: 0.0062029
[Epoch 45; Iter   302/ 1097] train: loss: 0.0007857
[Epoch 45; Iter   332/ 1097] train: loss: 0.0634598
[Epoch 45; Iter   362/ 1097] train: loss: 0.0036250
[Epoch 45; Iter   392/ 1097] train: loss: 0.0012954
[Epoch 45; Iter   422/ 1097] train: loss: 0.0192952
[Epoch 45; Iter   452/ 1097] train: loss: 0.0064721
[Epoch 45; Iter   482/ 1097] train: loss: 0.0079701
[Epoch 45; Iter   512/ 1097] train: loss: 0.0009115
[Epoch 45; Iter   542/ 1097] train: loss: 0.0086734
[Epoch 45; Iter   572/ 1097] train: loss: 0.0621912
[Epoch 45; Iter   602/ 1097] train: loss: 0.0776765
[Epoch 45; Iter   632/ 1097] train: loss: 0.0042866
[Epoch 45; Iter   662/ 1097] train: loss: 0.0018199
[Epoch 45; Iter   692/ 1097] train: loss: 0.0013714
[Epoch 45; Iter   722/ 1097] train: loss: 0.1525775
[Epoch 45; Iter   752/ 1097] train: loss: 0.0470230
[Epoch 45; Iter   782/ 1097] train: loss: 0.0014329
[Epoch 45; Iter   812/ 1097] train: loss: 0.0005142
[Epoch 45; Iter   842/ 1097] train: loss: 0.0001250
[Epoch 45; Iter   872/ 1097] train: loss: 0.0069392
[Epoch 45; Iter   902/ 1097] train: loss: 0.0344272
[Epoch 45; Iter   932/ 1097] train: loss: 0.0080065
[Epoch 45; Iter   962/ 1097] train: loss: 0.0355168
[Epoch 45; Iter   992/ 1097] train: loss: 0.0322690
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0030235
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0028235
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0003991
[Epoch 45] ogbg-molhiv: 0.743019 val loss: 0.193844
[Epoch 45] ogbg-molhiv: 0.701082 test loss: 0.430726
[Epoch 46; Iter    15/ 1097] train: loss: 0.0095055
[Epoch 46; Iter    45/ 1097] train: loss: 0.0096219
[Epoch 46; Iter    75/ 1097] train: loss: 0.0261906
[Epoch 46; Iter   105/ 1097] train: loss: 0.0040893
[Epoch 46; Iter   135/ 1097] train: loss: 0.0227665
[Epoch 46; Iter   165/ 1097] train: loss: 0.0011146
[Epoch 46; Iter   195/ 1097] train: loss: 0.0041239
[Epoch 46; Iter   225/ 1097] train: loss: 0.0214218
[Epoch 46; Iter   255/ 1097] train: loss: 0.0065874
[Epoch 46; Iter   285/ 1097] train: loss: 0.0091288
[Epoch 46; Iter   315/ 1097] train: loss: 0.0006809
[Epoch 46; Iter   345/ 1097] train: loss: 0.0012050
[Epoch 46; Iter   375/ 1097] train: loss: 0.0016684
[Epoch 46; Iter   405/ 1097] train: loss: 0.0031059
[Epoch 46; Iter   435/ 1097] train: loss: 0.0097545
[Epoch 46; Iter   465/ 1097] train: loss: 0.4116984
[Epoch 46; Iter   495/ 1097] train: loss: 0.0006842
[Epoch 46; Iter   525/ 1097] train: loss: 0.0123553
[Epoch 46; Iter   555/ 1097] train: loss: 0.0238781
[Epoch 46; Iter   585/ 1097] train: loss: 0.0342822
[Epoch 46; Iter   615/ 1097] train: loss: 0.0104801
[Epoch 46; Iter   645/ 1097] train: loss: 0.0037412
[Epoch 46; Iter   675/ 1097] train: loss: 0.0044482
[Epoch 46; Iter   705/ 1097] train: loss: 0.0043227
[Epoch 46; Iter   735/ 1097] train: loss: 0.0005406
[Epoch 46; Iter   765/ 1097] train: loss: 0.0061474
[Epoch 46; Iter   795/ 1097] train: loss: 0.1156624
[Epoch 46; Iter   825/ 1097] train: loss: 0.0094696
[Epoch 46; Iter   855/ 1097] train: loss: 0.0050759
[Epoch 46; Iter   885/ 1097] train: loss: 0.0130346
[Epoch 46; Iter   915/ 1097] train: loss: 0.0015338
[Epoch 46; Iter   945/ 1097] train: loss: 0.0026661
[Epoch 46; Iter   975/ 1097] train: loss: 0.0460000
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0021025
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0639224
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0039926
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0054428
[Epoch 46] ogbg-molhiv: 0.745572 val loss: 0.260598
[Epoch 46] ogbg-molhiv: 0.683138 test loss: 0.433065
[Epoch 47; Iter    28/ 1097] train: loss: 0.0013709
[Epoch 47; Iter    58/ 1097] train: loss: 0.0273976
[Epoch 47; Iter    88/ 1097] train: loss: 0.0085963
[Epoch 47; Iter   118/ 1097] train: loss: 0.0050100
[Epoch 47; Iter   148/ 1097] train: loss: 0.0046577
[Epoch 47; Iter   178/ 1097] train: loss: 0.0044548
[Epoch 47; Iter   208/ 1097] train: loss: 0.0284894
[Epoch 47; Iter   238/ 1097] train: loss: 0.0010294
[Epoch 47; Iter   268/ 1097] train: loss: 0.0007909
[Epoch 47; Iter   298/ 1097] train: loss: 0.0296562
[Epoch 47; Iter   328/ 1097] train: loss: 0.0059157
[Epoch 47; Iter   358/ 1097] train: loss: 0.0490793
[Epoch 47; Iter   388/ 1097] train: loss: 0.0512452
[Epoch 47; Iter   418/ 1097] train: loss: 0.0039625
[Epoch 47; Iter   448/ 1097] train: loss: 0.0083396
[Epoch 47; Iter   478/ 1097] train: loss: 0.1074232
[Epoch 47; Iter   508/ 1097] train: loss: 0.0230939
[Epoch 47; Iter   538/ 1097] train: loss: 0.0008094
[Epoch 47; Iter   568/ 1097] train: loss: 0.0073955
[Epoch 47; Iter   598/ 1097] train: loss: 0.0245333
[Epoch 47; Iter   628/ 1097] train: loss: 0.0116411
[Epoch 47; Iter   658/ 1097] train: loss: 0.0043780
[Epoch 47; Iter   688/ 1097] train: loss: 0.0063049
[Epoch 47; Iter   718/ 1097] train: loss: 0.0016965
[Epoch 47; Iter   748/ 1097] train: loss: 0.0002566
[Epoch 47; Iter   778/ 1097] train: loss: 0.0019595
[Epoch 47; Iter   808/ 1097] train: loss: 0.0027530
[Epoch 47; Iter   838/ 1097] train: loss: 0.0729533
[Epoch 47; Iter   868/ 1097] train: loss: 0.0809300
[Epoch 47; Iter   898/ 1097] train: loss: 0.0359079
[Epoch 47; Iter   928/ 1097] train: loss: 0.0044083
[Epoch 47; Iter   958/ 1097] train: loss: 0.0010724
[Epoch 47; Iter   988/ 1097] train: loss: 0.0065383
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0073148
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0119620
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0007142
[Epoch 47] ogbg-molhiv: 0.790154 val loss: 0.209514
[Epoch 47] ogbg-molhiv: 0.729989 test loss: 0.412235
[Epoch 48; Iter    11/ 1097] train: loss: 0.0078442
[Epoch 48; Iter    41/ 1097] train: loss: 0.0026730
[Epoch 48; Iter    71/ 1097] train: loss: 0.0577193
[Epoch 48; Iter   101/ 1097] train: loss: 0.0199898
[Epoch 48; Iter   131/ 1097] train: loss: 0.0011600
[Epoch 48; Iter   161/ 1097] train: loss: 0.0051145
[Epoch 48; Iter   191/ 1097] train: loss: 0.0098779
[Epoch 48; Iter   221/ 1097] train: loss: 0.0013558
[Epoch 48; Iter   251/ 1097] train: loss: 0.0037265
[Epoch 48; Iter   281/ 1097] train: loss: 0.0124689
[Epoch 48; Iter   311/ 1097] train: loss: 0.0016552
[Epoch 48; Iter   341/ 1097] train: loss: 0.0302231
[Epoch 48; Iter   371/ 1097] train: loss: 0.0106256
[Epoch 48; Iter   401/ 1097] train: loss: 0.0164153
[Epoch 48; Iter   431/ 1097] train: loss: 0.0033491
[Epoch 48; Iter   461/ 1097] train: loss: 0.0079244
[Epoch 48; Iter   491/ 1097] train: loss: 0.0110702
[Epoch 48; Iter   521/ 1097] train: loss: 0.0089970
[Epoch 48; Iter   551/ 1097] train: loss: 0.0200944
[Epoch 48; Iter   581/ 1097] train: loss: 0.0276185
[Epoch 48; Iter   611/ 1097] train: loss: 0.0019257
[Epoch 48; Iter   641/ 1097] train: loss: 0.0000857
[Epoch 48; Iter   671/ 1097] train: loss: 0.0065308
[Epoch 48; Iter   701/ 1097] train: loss: 0.0160365
[Epoch 48; Iter   731/ 1097] train: loss: 0.0045115
[Epoch 48; Iter   761/ 1097] train: loss: 0.0396037
[Epoch 48; Iter   791/ 1097] train: loss: 0.0003153
[Epoch 48; Iter   821/ 1097] train: loss: 0.0005449
[Epoch 36; Iter   605/ 1097] train: loss: 0.0196755
[Epoch 36; Iter   635/ 1097] train: loss: 0.0114046
[Epoch 36; Iter   665/ 1097] train: loss: 0.0155725
[Epoch 36; Iter   695/ 1097] train: loss: 0.0922083
[Epoch 36; Iter   725/ 1097] train: loss: 0.0378440
[Epoch 36; Iter   755/ 1097] train: loss: 0.1370899
[Epoch 36; Iter   785/ 1097] train: loss: 0.0147881
[Epoch 36; Iter   815/ 1097] train: loss: 0.0692418
[Epoch 36; Iter   845/ 1097] train: loss: 0.0163236
[Epoch 36; Iter   875/ 1097] train: loss: 0.0110065
[Epoch 36; Iter   905/ 1097] train: loss: 0.0106739
[Epoch 36; Iter   935/ 1097] train: loss: 0.1292349
[Epoch 36; Iter   965/ 1097] train: loss: 0.0691597
[Epoch 36; Iter   995/ 1097] train: loss: 0.0220091
[Epoch 36; Iter  1025/ 1097] train: loss: 0.1083074
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1092507
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0334783
[Epoch 36] ogbg-molhiv: 0.819227 val loss: 0.077017
[Epoch 36] ogbg-molhiv: 0.768410 test loss: 0.132478
[Epoch 37; Iter    18/ 1097] train: loss: 0.0661929
[Epoch 37; Iter    48/ 1097] train: loss: 0.1589206
[Epoch 37; Iter    78/ 1097] train: loss: 0.0277700
[Epoch 37; Iter   108/ 1097] train: loss: 0.0727648
[Epoch 37; Iter   138/ 1097] train: loss: 0.0185678
[Epoch 37; Iter   168/ 1097] train: loss: 0.0764237
[Epoch 37; Iter   198/ 1097] train: loss: 0.0831783
[Epoch 37; Iter   228/ 1097] train: loss: 0.0371205
[Epoch 37; Iter   258/ 1097] train: loss: 0.0175042
[Epoch 37; Iter   288/ 1097] train: loss: 0.0954056
[Epoch 37; Iter   318/ 1097] train: loss: 0.0283333
[Epoch 37; Iter   348/ 1097] train: loss: 0.0582550
[Epoch 37; Iter   378/ 1097] train: loss: 0.0228123
[Epoch 37; Iter   408/ 1097] train: loss: 0.0269438
[Epoch 37; Iter   438/ 1097] train: loss: 0.0195062
[Epoch 37; Iter   468/ 1097] train: loss: 0.0498244
[Epoch 37; Iter   498/ 1097] train: loss: 0.1406311
[Epoch 37; Iter   528/ 1097] train: loss: 0.0351573
[Epoch 37; Iter   558/ 1097] train: loss: 0.0095865
[Epoch 37; Iter   588/ 1097] train: loss: 0.1401646
[Epoch 37; Iter   618/ 1097] train: loss: 0.0372274
[Epoch 37; Iter   648/ 1097] train: loss: 0.0991056
[Epoch 37; Iter   678/ 1097] train: loss: 0.0551293
[Epoch 37; Iter   708/ 1097] train: loss: 0.0098811
[Epoch 37; Iter   738/ 1097] train: loss: 0.0935608
[Epoch 37; Iter   768/ 1097] train: loss: 0.0106871
[Epoch 37; Iter   798/ 1097] train: loss: 0.1440081
[Epoch 37; Iter   828/ 1097] train: loss: 0.0269690
[Epoch 37; Iter   858/ 1097] train: loss: 0.0126342
[Epoch 37; Iter   888/ 1097] train: loss: 0.0551711
[Epoch 37; Iter   918/ 1097] train: loss: 0.0731285
[Epoch 37; Iter   948/ 1097] train: loss: 0.0255593
[Epoch 37; Iter   978/ 1097] train: loss: 0.1633163
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0156501
[Epoch 37; Iter  1038/ 1097] train: loss: 0.1227146
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0407938
[Epoch 37] ogbg-molhiv: 0.828786 val loss: 0.082969
[Epoch 37] ogbg-molhiv: 0.779013 test loss: 0.139105
[Epoch 38; Iter     1/ 1097] train: loss: 0.1508579
[Epoch 38; Iter    31/ 1097] train: loss: 0.0241539
[Epoch 38; Iter    61/ 1097] train: loss: 0.0742163
[Epoch 38; Iter    91/ 1097] train: loss: 0.0202558
[Epoch 38; Iter   121/ 1097] train: loss: 0.1084657
[Epoch 38; Iter   151/ 1097] train: loss: 0.0252991
[Epoch 38; Iter   181/ 1097] train: loss: 0.1025453
[Epoch 38; Iter   211/ 1097] train: loss: 0.0581436
[Epoch 38; Iter   241/ 1097] train: loss: 0.1293885
[Epoch 38; Iter   271/ 1097] train: loss: 0.0594049
[Epoch 38; Iter   301/ 1097] train: loss: 0.1167444
[Epoch 38; Iter   331/ 1097] train: loss: 0.0527857
[Epoch 38; Iter   361/ 1097] train: loss: 0.1572176
[Epoch 38; Iter   391/ 1097] train: loss: 0.0547950
[Epoch 38; Iter   421/ 1097] train: loss: 0.0507052
[Epoch 38; Iter   451/ 1097] train: loss: 0.0582969
[Epoch 38; Iter   481/ 1097] train: loss: 0.1237295
[Epoch 38; Iter   511/ 1097] train: loss: 0.0436843
[Epoch 38; Iter   541/ 1097] train: loss: 0.0324380
[Epoch 38; Iter   571/ 1097] train: loss: 0.0211580
[Epoch 38; Iter   601/ 1097] train: loss: 0.1272858
[Epoch 38; Iter   631/ 1097] train: loss: 0.0288547
[Epoch 38; Iter   661/ 1097] train: loss: 0.0378095
[Epoch 38; Iter   691/ 1097] train: loss: 0.0332523
[Epoch 38; Iter   721/ 1097] train: loss: 0.0604758
[Epoch 38; Iter   751/ 1097] train: loss: 0.0887738
[Epoch 38; Iter   781/ 1097] train: loss: 0.0821626
[Epoch 38; Iter   811/ 1097] train: loss: 0.0587302
[Epoch 38; Iter   841/ 1097] train: loss: 0.0882249
[Epoch 38; Iter   871/ 1097] train: loss: 0.1722242
[Epoch 38; Iter   901/ 1097] train: loss: 0.0856407
[Epoch 38; Iter   931/ 1097] train: loss: 0.0221380
[Epoch 38; Iter   961/ 1097] train: loss: 0.0104824
[Epoch 38; Iter   991/ 1097] train: loss: 0.0320421
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0281531
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0236102
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0428071
[Epoch 38] ogbg-molhiv: 0.793862 val loss: 0.086655
[Epoch 38] ogbg-molhiv: 0.757626 test loss: 0.150139
[Epoch 39; Iter    14/ 1097] train: loss: 0.0214592
[Epoch 39; Iter    44/ 1097] train: loss: 0.1368810
[Epoch 39; Iter    74/ 1097] train: loss: 0.2717889
[Epoch 39; Iter   104/ 1097] train: loss: 0.0559932
[Epoch 39; Iter   134/ 1097] train: loss: 0.0555833
[Epoch 39; Iter   164/ 1097] train: loss: 0.0318712
[Epoch 39; Iter   194/ 1097] train: loss: 0.1244095
[Epoch 39; Iter   224/ 1097] train: loss: 0.0159729
[Epoch 39; Iter   254/ 1097] train: loss: 0.0150107
[Epoch 39; Iter   284/ 1097] train: loss: 0.1306655
[Epoch 39; Iter   314/ 1097] train: loss: 0.0277961
[Epoch 39; Iter   344/ 1097] train: loss: 0.0126405
[Epoch 39; Iter   374/ 1097] train: loss: 0.0230980
[Epoch 39; Iter   404/ 1097] train: loss: 0.0127764
[Epoch 39; Iter   434/ 1097] train: loss: 0.1178142
[Epoch 39; Iter   464/ 1097] train: loss: 0.0110839
[Epoch 39; Iter   494/ 1097] train: loss: 0.0720309
[Epoch 39; Iter   524/ 1097] train: loss: 0.0468530
[Epoch 39; Iter   554/ 1097] train: loss: 0.0397994
[Epoch 39; Iter   584/ 1097] train: loss: 0.0239167
[Epoch 39; Iter   614/ 1097] train: loss: 0.2350053
[Epoch 39; Iter   644/ 1097] train: loss: 0.1028256
[Epoch 39; Iter   674/ 1097] train: loss: 0.0162264
[Epoch 39; Iter   704/ 1097] train: loss: 0.0328625
[Epoch 39; Iter   734/ 1097] train: loss: 0.0077359
[Epoch 39; Iter   764/ 1097] train: loss: 0.0182302
[Epoch 39; Iter   794/ 1097] train: loss: 0.0108457
[Epoch 39; Iter   824/ 1097] train: loss: 0.0389537
[Epoch 39; Iter   854/ 1097] train: loss: 0.0169514
[Epoch 39; Iter   884/ 1097] train: loss: 0.0140336
[Epoch 39; Iter   914/ 1097] train: loss: 0.1618101
[Epoch 39; Iter   944/ 1097] train: loss: 0.1797840
[Epoch 39; Iter   974/ 1097] train: loss: 0.1510990
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0156006
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0652997
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0406775
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0151927
[Epoch 39] ogbg-molhiv: 0.820133 val loss: 0.080384
[Epoch 39] ogbg-molhiv: 0.793945 test loss: 0.169667
[Epoch 40; Iter    27/ 1097] train: loss: 0.0924669
[Epoch 40; Iter    57/ 1097] train: loss: 0.1316693
[Epoch 40; Iter    87/ 1097] train: loss: 0.1645408
[Epoch 40; Iter   117/ 1097] train: loss: 0.0196607
[Epoch 40; Iter   147/ 1097] train: loss: 0.0098700
[Epoch 40; Iter   177/ 1097] train: loss: 0.0768905
[Epoch 40; Iter   207/ 1097] train: loss: 0.3487406
[Epoch 40; Iter   237/ 1097] train: loss: 0.0207021
[Epoch 40; Iter   267/ 1097] train: loss: 0.1478448
[Epoch 40; Iter   297/ 1097] train: loss: 0.1289247
[Epoch 40; Iter   327/ 1097] train: loss: 0.2300426
[Epoch 40; Iter   357/ 1097] train: loss: 0.0136374
[Epoch 40; Iter   387/ 1097] train: loss: 0.0371859
[Epoch 40; Iter   417/ 1097] train: loss: 0.1267797
[Epoch 40; Iter   447/ 1097] train: loss: 0.0397122
[Epoch 40; Iter   477/ 1097] train: loss: 0.2034501
[Epoch 40; Iter   507/ 1097] train: loss: 0.0195871
[Epoch 40; Iter   537/ 1097] train: loss: 0.0362254
[Epoch 40; Iter   567/ 1097] train: loss: 0.0259160
[Epoch 40; Iter   597/ 1097] train: loss: 0.0187657
[Epoch 40; Iter   627/ 1097] train: loss: 0.0296699
[Epoch 40; Iter   657/ 1097] train: loss: 0.1287681
[Epoch 36; Iter   605/ 1097] train: loss: 0.0193307
[Epoch 36; Iter   635/ 1097] train: loss: 0.0179386
[Epoch 36; Iter   665/ 1097] train: loss: 0.0829485
[Epoch 36; Iter   695/ 1097] train: loss: 0.3324753
[Epoch 36; Iter   725/ 1097] train: loss: 0.0860447
[Epoch 36; Iter   755/ 1097] train: loss: 0.0171030
[Epoch 36; Iter   785/ 1097] train: loss: 0.0201649
[Epoch 36; Iter   815/ 1097] train: loss: 0.0165165
[Epoch 36; Iter   845/ 1097] train: loss: 0.0392366
[Epoch 36; Iter   875/ 1097] train: loss: 0.0116484
[Epoch 36; Iter   905/ 1097] train: loss: 0.1928364
[Epoch 36; Iter   935/ 1097] train: loss: 0.1862635
[Epoch 36; Iter   965/ 1097] train: loss: 0.0235700
[Epoch 36; Iter   995/ 1097] train: loss: 0.0153140
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0618478
[Epoch 36; Iter  1055/ 1097] train: loss: 0.2642335
[Epoch 36; Iter  1085/ 1097] train: loss: 0.3798433
[Epoch 36] ogbg-molhiv: 0.825905 val loss: 0.073977
[Epoch 36] ogbg-molhiv: 0.773364 test loss: 0.122124
[Epoch 37; Iter    18/ 1097] train: loss: 0.0179082
[Epoch 37; Iter    48/ 1097] train: loss: 0.0298071
[Epoch 37; Iter    78/ 1097] train: loss: 0.0506506
[Epoch 37; Iter   108/ 1097] train: loss: 0.0330014
[Epoch 37; Iter   138/ 1097] train: loss: 0.0733018
[Epoch 37; Iter   168/ 1097] train: loss: 0.0881540
[Epoch 37; Iter   198/ 1097] train: loss: 0.0137032
[Epoch 37; Iter   228/ 1097] train: loss: 0.0126256
[Epoch 37; Iter   258/ 1097] train: loss: 0.0380010
[Epoch 37; Iter   288/ 1097] train: loss: 0.0121222
[Epoch 37; Iter   318/ 1097] train: loss: 0.0107083
[Epoch 37; Iter   348/ 1097] train: loss: 0.0239412
[Epoch 37; Iter   378/ 1097] train: loss: 0.3042881
[Epoch 37; Iter   408/ 1097] train: loss: 0.1192521
[Epoch 37; Iter   438/ 1097] train: loss: 0.1453772
[Epoch 37; Iter   468/ 1097] train: loss: 0.0421860
[Epoch 37; Iter   498/ 1097] train: loss: 0.1376233
[Epoch 37; Iter   528/ 1097] train: loss: 0.0593226
[Epoch 37; Iter   558/ 1097] train: loss: 0.0795859
[Epoch 37; Iter   588/ 1097] train: loss: 0.0424877
[Epoch 37; Iter   618/ 1097] train: loss: 0.1863859
[Epoch 37; Iter   648/ 1097] train: loss: 0.0522584
[Epoch 37; Iter   678/ 1097] train: loss: 0.0736097
[Epoch 37; Iter   708/ 1097] train: loss: 0.0161135
[Epoch 37; Iter   738/ 1097] train: loss: 0.0235515
[Epoch 37; Iter   768/ 1097] train: loss: 0.1740284
[Epoch 37; Iter   798/ 1097] train: loss: 0.2266548
[Epoch 37; Iter   828/ 1097] train: loss: 0.0220681
[Epoch 37; Iter   858/ 1097] train: loss: 0.0615561
[Epoch 37; Iter   888/ 1097] train: loss: 0.0278483
[Epoch 37; Iter   918/ 1097] train: loss: 0.1876129
[Epoch 37; Iter   948/ 1097] train: loss: 0.0144222
[Epoch 37; Iter   978/ 1097] train: loss: 0.1554140
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0174403
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0202430
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0853849
[Epoch 37] ogbg-molhiv: 0.823979 val loss: 0.077363
[Epoch 37] ogbg-molhiv: 0.756652 test loss: 0.127910
[Epoch 38; Iter     1/ 1097] train: loss: 0.0246932
[Epoch 38; Iter    31/ 1097] train: loss: 0.0360827
[Epoch 38; Iter    61/ 1097] train: loss: 0.2069097
[Epoch 38; Iter    91/ 1097] train: loss: 0.1289821
[Epoch 38; Iter   121/ 1097] train: loss: 0.0152772
[Epoch 38; Iter   151/ 1097] train: loss: 0.0104409
[Epoch 38; Iter   181/ 1097] train: loss: 0.1333920
[Epoch 38; Iter   211/ 1097] train: loss: 0.0109589
[Epoch 38; Iter   241/ 1097] train: loss: 0.1053778
[Epoch 38; Iter   271/ 1097] train: loss: 0.0133901
[Epoch 38; Iter   301/ 1097] train: loss: 0.4555057
[Epoch 38; Iter   331/ 1097] train: loss: 0.1346455
[Epoch 38; Iter   361/ 1097] train: loss: 0.0374495
[Epoch 38; Iter   391/ 1097] train: loss: 0.0546798
[Epoch 38; Iter   421/ 1097] train: loss: 0.1631019
[Epoch 38; Iter   451/ 1097] train: loss: 0.0550589
[Epoch 38; Iter   481/ 1097] train: loss: 0.0844426
[Epoch 38; Iter   511/ 1097] train: loss: 0.1517562
[Epoch 38; Iter   541/ 1097] train: loss: 0.1791786
[Epoch 38; Iter   571/ 1097] train: loss: 0.0113378
[Epoch 38; Iter   601/ 1097] train: loss: 0.2032432
[Epoch 38; Iter   631/ 1097] train: loss: 0.1257716
[Epoch 38; Iter   661/ 1097] train: loss: 0.0215477
[Epoch 38; Iter   691/ 1097] train: loss: 0.1452011
[Epoch 38; Iter   721/ 1097] train: loss: 0.2080141
[Epoch 38; Iter   751/ 1097] train: loss: 0.0235581
[Epoch 38; Iter   781/ 1097] train: loss: 0.0908257
[Epoch 38; Iter   811/ 1097] train: loss: 0.1408636
[Epoch 38; Iter   841/ 1097] train: loss: 0.1490799
[Epoch 38; Iter   871/ 1097] train: loss: 0.0280581
[Epoch 38; Iter   901/ 1097] train: loss: 0.0290090
[Epoch 38; Iter   931/ 1097] train: loss: 0.0392913
[Epoch 38; Iter   961/ 1097] train: loss: 0.0281130
[Epoch 38; Iter   991/ 1097] train: loss: 0.0218961
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0207436
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0205616
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0399445
[Epoch 38] ogbg-molhiv: 0.855511 val loss: 0.075667
[Epoch 38] ogbg-molhiv: 0.784075 test loss: 0.130015
[Epoch 39; Iter    14/ 1097] train: loss: 0.1886567
[Epoch 39; Iter    44/ 1097] train: loss: 0.4227348
[Epoch 39; Iter    74/ 1097] train: loss: 0.0778258
[Epoch 39; Iter   104/ 1097] train: loss: 0.0194444
[Epoch 39; Iter   134/ 1097] train: loss: 0.1083252
[Epoch 39; Iter   164/ 1097] train: loss: 0.2780277
[Epoch 39; Iter   194/ 1097] train: loss: 0.0171676
[Epoch 39; Iter   224/ 1097] train: loss: 0.0831089
[Epoch 39; Iter   254/ 1097] train: loss: 0.1192978
[Epoch 39; Iter   284/ 1097] train: loss: 0.0541056
[Epoch 39; Iter   314/ 1097] train: loss: 0.1138290
[Epoch 39; Iter   344/ 1097] train: loss: 0.0488621
[Epoch 39; Iter   374/ 1097] train: loss: 0.0152529
[Epoch 39; Iter   404/ 1097] train: loss: 0.1909614
[Epoch 39; Iter   434/ 1097] train: loss: 0.0119645
[Epoch 39; Iter   464/ 1097] train: loss: 0.0318771
[Epoch 39; Iter   494/ 1097] train: loss: 0.0388490
[Epoch 39; Iter   524/ 1097] train: loss: 0.0386158
[Epoch 39; Iter   554/ 1097] train: loss: 0.0148568
[Epoch 39; Iter   584/ 1097] train: loss: 0.0204036
[Epoch 39; Iter   614/ 1097] train: loss: 0.0693128
[Epoch 39; Iter   644/ 1097] train: loss: 0.0167731
[Epoch 39; Iter   674/ 1097] train: loss: 0.1758485
[Epoch 39; Iter   704/ 1097] train: loss: 0.1424760
[Epoch 39; Iter   734/ 1097] train: loss: 0.0254421
[Epoch 39; Iter   764/ 1097] train: loss: 0.2693003
[Epoch 39; Iter   794/ 1097] train: loss: 0.1548034
[Epoch 39; Iter   824/ 1097] train: loss: 0.1240557
[Epoch 39; Iter   854/ 1097] train: loss: 0.0261873
[Epoch 39; Iter   884/ 1097] train: loss: 0.0253076
[Epoch 39; Iter   914/ 1097] train: loss: 0.0457424
[Epoch 39; Iter   944/ 1097] train: loss: 0.0387810
[Epoch 39; Iter   974/ 1097] train: loss: 0.1288561
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0718803
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0164248
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0220780
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1240178
[Epoch 39] ogbg-molhiv: 0.813079 val loss: 0.121388
[Epoch 39] ogbg-molhiv: 0.751598 test loss: 0.161218
[Epoch 40; Iter    27/ 1097] train: loss: 0.1550623
[Epoch 40; Iter    57/ 1097] train: loss: 0.0476592
[Epoch 40; Iter    87/ 1097] train: loss: 0.1015273
[Epoch 40; Iter   117/ 1097] train: loss: 0.0843580
[Epoch 40; Iter   147/ 1097] train: loss: 0.0580458
[Epoch 40; Iter   177/ 1097] train: loss: 0.0439422
[Epoch 40; Iter   207/ 1097] train: loss: 0.0525395
[Epoch 40; Iter   237/ 1097] train: loss: 0.0729375
[Epoch 40; Iter   267/ 1097] train: loss: 0.2668211
[Epoch 40; Iter   297/ 1097] train: loss: 0.0425636
[Epoch 40; Iter   327/ 1097] train: loss: 0.0228223
[Epoch 40; Iter   357/ 1097] train: loss: 0.3257677
[Epoch 40; Iter   387/ 1097] train: loss: 0.1381016
[Epoch 40; Iter   417/ 1097] train: loss: 0.1084901
[Epoch 40; Iter   447/ 1097] train: loss: 0.1337607
[Epoch 40; Iter   477/ 1097] train: loss: 0.0296393
[Epoch 40; Iter   507/ 1097] train: loss: 0.1149579
[Epoch 40; Iter   537/ 1097] train: loss: 0.0721169
[Epoch 40; Iter   567/ 1097] train: loss: 0.0528210
[Epoch 40; Iter   597/ 1097] train: loss: 0.0705335
[Epoch 40; Iter   627/ 1097] train: loss: 0.0226692
[Epoch 40; Iter   657/ 1097] train: loss: 0.1039112
[Epoch 44; Iter   769/ 1097] train: loss: 0.0017082
[Epoch 44; Iter   799/ 1097] train: loss: 0.0022885
[Epoch 44; Iter   829/ 1097] train: loss: 0.0255547
[Epoch 44; Iter   859/ 1097] train: loss: 0.0028062
[Epoch 44; Iter   889/ 1097] train: loss: 0.0003533
[Epoch 44; Iter   919/ 1097] train: loss: 0.0012985
[Epoch 44; Iter   949/ 1097] train: loss: 0.1044850
[Epoch 44; Iter   979/ 1097] train: loss: 0.0012609
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0041551
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0023598
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0148433
[Epoch 44] ogbg-molhiv: 0.789811 val loss: 0.216897
[Epoch 44] ogbg-molhiv: 0.782987 test loss: 0.234034
[Epoch 45; Iter     2/ 1097] train: loss: 0.0112448
[Epoch 45; Iter    32/ 1097] train: loss: 0.0002018
[Epoch 45; Iter    62/ 1097] train: loss: 0.0033403
[Epoch 45; Iter    92/ 1097] train: loss: 0.0052311
[Epoch 45; Iter   122/ 1097] train: loss: 0.0150941
[Epoch 45; Iter   152/ 1097] train: loss: 0.0191473
[Epoch 45; Iter   182/ 1097] train: loss: 0.0004700
[Epoch 45; Iter   212/ 1097] train: loss: 0.0259935
[Epoch 45; Iter   242/ 1097] train: loss: 0.0014846
[Epoch 45; Iter   272/ 1097] train: loss: 0.0037338
[Epoch 45; Iter   302/ 1097] train: loss: 0.0142148
[Epoch 45; Iter   332/ 1097] train: loss: 0.0108930
[Epoch 45; Iter   362/ 1097] train: loss: 0.0005910
[Epoch 45; Iter   392/ 1097] train: loss: 0.0870223
[Epoch 45; Iter   422/ 1097] train: loss: 0.0037999
[Epoch 45; Iter   452/ 1097] train: loss: 0.0023923
[Epoch 45; Iter   482/ 1097] train: loss: 0.0003130
[Epoch 45; Iter   512/ 1097] train: loss: 0.0083734
[Epoch 45; Iter   542/ 1097] train: loss: 0.0029689
[Epoch 45; Iter   572/ 1097] train: loss: 0.0052902
[Epoch 45; Iter   602/ 1097] train: loss: 0.0017154
[Epoch 45; Iter   632/ 1097] train: loss: 0.0007040
[Epoch 45; Iter   662/ 1097] train: loss: 0.0005087
[Epoch 45; Iter   692/ 1097] train: loss: 0.0037537
[Epoch 45; Iter   722/ 1097] train: loss: 0.0004479
[Epoch 45; Iter   752/ 1097] train: loss: 0.0034589
[Epoch 45; Iter   782/ 1097] train: loss: 0.0036757
[Epoch 45; Iter   812/ 1097] train: loss: 0.0005417
[Epoch 45; Iter   842/ 1097] train: loss: 0.0039005
[Epoch 45; Iter   872/ 1097] train: loss: 0.0014383
[Epoch 45; Iter   902/ 1097] train: loss: 0.0125476
[Epoch 45; Iter   932/ 1097] train: loss: 0.0093853
[Epoch 45; Iter   962/ 1097] train: loss: 0.0111661
[Epoch 45; Iter   992/ 1097] train: loss: 0.0074206
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0046105
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0046097
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0046700
[Epoch 45] ogbg-molhiv: 0.810654 val loss: 0.232265
[Epoch 45] ogbg-molhiv: 0.785110 test loss: 0.244843
[Epoch 46; Iter    15/ 1097] train: loss: 0.0089605
[Epoch 46; Iter    45/ 1097] train: loss: 0.0011916
[Epoch 46; Iter    75/ 1097] train: loss: 0.0080852
[Epoch 46; Iter   105/ 1097] train: loss: 0.0043924
[Epoch 46; Iter   135/ 1097] train: loss: 0.0194420
[Epoch 46; Iter   165/ 1097] train: loss: 0.0002899
[Epoch 46; Iter   195/ 1097] train: loss: 0.0001330
[Epoch 46; Iter   225/ 1097] train: loss: 0.0003324
[Epoch 46; Iter   255/ 1097] train: loss: 0.0027628
[Epoch 46; Iter   285/ 1097] train: loss: 0.0999691
[Epoch 46; Iter   315/ 1097] train: loss: 0.0013962
[Epoch 46; Iter   345/ 1097] train: loss: 0.0009313
[Epoch 46; Iter   375/ 1097] train: loss: 0.0022775
[Epoch 46; Iter   405/ 1097] train: loss: 0.0506389
[Epoch 46; Iter   435/ 1097] train: loss: 0.0435093
[Epoch 46; Iter   465/ 1097] train: loss: 0.0014042
[Epoch 46; Iter   495/ 1097] train: loss: 0.0002483
[Epoch 46; Iter   525/ 1097] train: loss: 0.0059938
[Epoch 46; Iter   555/ 1097] train: loss: 0.0002255
[Epoch 46; Iter   585/ 1097] train: loss: 0.0147587
[Epoch 46; Iter   615/ 1097] train: loss: 0.0009474
[Epoch 46; Iter   645/ 1097] train: loss: 0.0821896
[Epoch 46; Iter   675/ 1097] train: loss: 0.0004520
[Epoch 46; Iter   705/ 1097] train: loss: 0.0010635
[Epoch 46; Iter   735/ 1097] train: loss: 0.0047301
[Epoch 46; Iter   765/ 1097] train: loss: 0.0144658
[Epoch 46; Iter   795/ 1097] train: loss: 0.0003237
[Epoch 46; Iter   825/ 1097] train: loss: 0.0068904
[Epoch 46; Iter   855/ 1097] train: loss: 0.0017587
[Epoch 46; Iter   885/ 1097] train: loss: 0.0236276
[Epoch 46; Iter   915/ 1097] train: loss: 0.0251715
[Epoch 46; Iter   945/ 1097] train: loss: 0.0109923
[Epoch 46; Iter   975/ 1097] train: loss: 0.0394796
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0035783
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0108628
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0075086
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0005374
[Epoch 46] ogbg-molhiv: 0.768353 val loss: 0.189179
[Epoch 46] ogbg-molhiv: 0.779918 test loss: 0.246981
[Epoch 47; Iter    28/ 1097] train: loss: 0.0171949
[Epoch 47; Iter    58/ 1097] train: loss: 0.0044624
[Epoch 47; Iter    88/ 1097] train: loss: 0.0010045
[Epoch 47; Iter   118/ 1097] train: loss: 0.0006640
[Epoch 47; Iter   148/ 1097] train: loss: 0.0016118
[Epoch 47; Iter   178/ 1097] train: loss: 0.0192429
[Epoch 47; Iter   208/ 1097] train: loss: 0.0020841
[Epoch 47; Iter   238/ 1097] train: loss: 0.0017196
[Epoch 47; Iter   268/ 1097] train: loss: 0.0022089
[Epoch 47; Iter   298/ 1097] train: loss: 0.0012967
[Epoch 47; Iter   328/ 1097] train: loss: 0.0027383
[Epoch 47; Iter   358/ 1097] train: loss: 0.0168004
[Epoch 47; Iter   388/ 1097] train: loss: 0.0063636
[Epoch 47; Iter   418/ 1097] train: loss: 0.0011235
[Epoch 47; Iter   448/ 1097] train: loss: 0.0061260
[Epoch 47; Iter   478/ 1097] train: loss: 0.0013530
[Epoch 47; Iter   508/ 1097] train: loss: 0.0019109
[Epoch 47; Iter   538/ 1097] train: loss: 0.0029415
[Epoch 47; Iter   568/ 1097] train: loss: 0.0010253
[Epoch 47; Iter   598/ 1097] train: loss: 0.0053971
[Epoch 47; Iter   628/ 1097] train: loss: 0.0035191
[Epoch 47; Iter   658/ 1097] train: loss: 0.0002258
[Epoch 47; Iter   688/ 1097] train: loss: 0.0459655
[Epoch 47; Iter   718/ 1097] train: loss: 0.0031485
[Epoch 47; Iter   748/ 1097] train: loss: 0.0135035
[Epoch 47; Iter   778/ 1097] train: loss: 0.0002050
[Epoch 47; Iter   808/ 1097] train: loss: 0.0017275
[Epoch 47; Iter   838/ 1097] train: loss: 0.0003418
[Epoch 47; Iter   868/ 1097] train: loss: 0.0146221
[Epoch 47; Iter   898/ 1097] train: loss: 0.0008993
[Epoch 47; Iter   928/ 1097] train: loss: 0.0070497
[Epoch 47; Iter   958/ 1097] train: loss: 0.0045770
[Epoch 47; Iter   988/ 1097] train: loss: 0.0224265
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0022549
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0110128
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0026194
[Epoch 47] ogbg-molhiv: 0.759541 val loss: 0.215073
[Epoch 47] ogbg-molhiv: 0.772943 test loss: 0.249818
[Epoch 48; Iter    11/ 1097] train: loss: 0.0015706
[Epoch 48; Iter    41/ 1097] train: loss: 0.0776992
[Epoch 48; Iter    71/ 1097] train: loss: 0.0065759
[Epoch 48; Iter   101/ 1097] train: loss: 0.0225502
[Epoch 48; Iter   131/ 1097] train: loss: 0.0023483
[Epoch 48; Iter   161/ 1097] train: loss: 0.0007934
[Epoch 48; Iter   191/ 1097] train: loss: 0.0134930
[Epoch 48; Iter   221/ 1097] train: loss: 0.0022159
[Epoch 48; Iter   251/ 1097] train: loss: 0.0002739
[Epoch 48; Iter   281/ 1097] train: loss: 0.0009223
[Epoch 48; Iter   311/ 1097] train: loss: 0.0012506
[Epoch 48; Iter   341/ 1097] train: loss: 0.0139429
[Epoch 48; Iter   371/ 1097] train: loss: 0.0246455
[Epoch 48; Iter   401/ 1097] train: loss: 0.0027833
[Epoch 48; Iter   431/ 1097] train: loss: 0.0105817
[Epoch 48; Iter   461/ 1097] train: loss: 0.0001214
[Epoch 48; Iter   491/ 1097] train: loss: 0.0071796
[Epoch 48; Iter   521/ 1097] train: loss: 0.0114732
[Epoch 48; Iter   551/ 1097] train: loss: 0.0149478
[Epoch 48; Iter   581/ 1097] train: loss: 0.0134948
[Epoch 48; Iter   611/ 1097] train: loss: 0.0003884
[Epoch 48; Iter   641/ 1097] train: loss: 0.0037007
[Epoch 48; Iter   671/ 1097] train: loss: 0.0004233
[Epoch 48; Iter   701/ 1097] train: loss: 0.0053424
[Epoch 48; Iter   731/ 1097] train: loss: 0.0032718
[Epoch 48; Iter   761/ 1097] train: loss: 0.0058490
[Epoch 48; Iter   791/ 1097] train: loss: 0.0093262
[Epoch 48; Iter   821/ 1097] train: loss: 0.0006475
[Epoch 44; Iter   769/ 1097] train: loss: 0.0309830
[Epoch 44; Iter   799/ 1097] train: loss: 0.0023491
[Epoch 44; Iter   829/ 1097] train: loss: 0.0629110
[Epoch 44; Iter   859/ 1097] train: loss: 0.0036590
[Epoch 44; Iter   889/ 1097] train: loss: 0.0025095
[Epoch 44; Iter   919/ 1097] train: loss: 0.0000503
[Epoch 44; Iter   949/ 1097] train: loss: 0.0023103
[Epoch 44; Iter   979/ 1097] train: loss: 0.0008846
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0005121
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0073703
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0681724
[Epoch 44] ogbg-molhiv: 0.716732 val loss: 3.495970
[Epoch 44] ogbg-molhiv: 0.624068 test loss: 4.857125
[Epoch 45; Iter     2/ 1097] train: loss: 0.0001893
[Epoch 45; Iter    32/ 1097] train: loss: 0.0010854
[Epoch 45; Iter    62/ 1097] train: loss: 0.0017419
[Epoch 45; Iter    92/ 1097] train: loss: 0.0043702
[Epoch 45; Iter   122/ 1097] train: loss: 0.0052286
[Epoch 45; Iter   152/ 1097] train: loss: 0.0134822
[Epoch 45; Iter   182/ 1097] train: loss: 0.0002652
[Epoch 45; Iter   212/ 1097] train: loss: 0.0028199
[Epoch 45; Iter   242/ 1097] train: loss: 0.0297279
[Epoch 45; Iter   272/ 1097] train: loss: 0.0032166
[Epoch 45; Iter   302/ 1097] train: loss: 0.0145138
[Epoch 45; Iter   332/ 1097] train: loss: 0.0000352
[Epoch 45; Iter   362/ 1097] train: loss: 0.0000880
[Epoch 45; Iter   392/ 1097] train: loss: 0.0012476
[Epoch 45; Iter   422/ 1097] train: loss: 0.0347266
[Epoch 45; Iter   452/ 1097] train: loss: 0.0008309
[Epoch 45; Iter   482/ 1097] train: loss: 0.0038666
[Epoch 45; Iter   512/ 1097] train: loss: 0.0000402
[Epoch 45; Iter   542/ 1097] train: loss: 0.0005627
[Epoch 45; Iter   572/ 1097] train: loss: 0.0159938
[Epoch 45; Iter   602/ 1097] train: loss: 0.0001496
[Epoch 45; Iter   632/ 1097] train: loss: 0.0042059
[Epoch 45; Iter   662/ 1097] train: loss: 0.0104874
[Epoch 45; Iter   692/ 1097] train: loss: 0.0028807
[Epoch 45; Iter   722/ 1097] train: loss: 0.0014793
[Epoch 45; Iter   752/ 1097] train: loss: 0.0042402
[Epoch 45; Iter   782/ 1097] train: loss: 0.1297162
[Epoch 45; Iter   812/ 1097] train: loss: 0.0025681
[Epoch 45; Iter   842/ 1097] train: loss: 0.0000852
[Epoch 45; Iter   872/ 1097] train: loss: 0.0096093
[Epoch 45; Iter   902/ 1097] train: loss: 0.0076162
[Epoch 45; Iter   932/ 1097] train: loss: 0.0026937
[Epoch 45; Iter   962/ 1097] train: loss: 0.0008398
[Epoch 45; Iter   992/ 1097] train: loss: 0.0012403
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0514962
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0226179
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0004155
[Epoch 45] ogbg-molhiv: 0.739684 val loss: 2.531072
[Epoch 45] ogbg-molhiv: 0.620765 test loss: 2.731034
[Epoch 46; Iter    15/ 1097] train: loss: 0.0469630
[Epoch 46; Iter    45/ 1097] train: loss: 0.0003374
[Epoch 46; Iter    75/ 1097] train: loss: 0.1075102
[Epoch 46; Iter   105/ 1097] train: loss: 0.0048973
[Epoch 46; Iter   135/ 1097] train: loss: 0.0228384
[Epoch 46; Iter   165/ 1097] train: loss: 0.0051049
[Epoch 46; Iter   195/ 1097] train: loss: 0.0020759
[Epoch 46; Iter   225/ 1097] train: loss: 0.0000308
[Epoch 46; Iter   255/ 1097] train: loss: 0.0035310
[Epoch 46; Iter   285/ 1097] train: loss: 0.0002035
[Epoch 46; Iter   315/ 1097] train: loss: 0.0004250
[Epoch 46; Iter   345/ 1097] train: loss: 0.0001347
[Epoch 46; Iter   375/ 1097] train: loss: 0.0050628
[Epoch 46; Iter   405/ 1097] train: loss: 0.0001141
[Epoch 46; Iter   435/ 1097] train: loss: 0.0001602
[Epoch 46; Iter   465/ 1097] train: loss: 0.0003686
[Epoch 46; Iter   495/ 1097] train: loss: 0.0098954
[Epoch 46; Iter   525/ 1097] train: loss: 0.0005236
[Epoch 46; Iter   555/ 1097] train: loss: 0.0001667
[Epoch 46; Iter   585/ 1097] train: loss: 0.0315619
[Epoch 46; Iter   615/ 1097] train: loss: 0.0047543
[Epoch 46; Iter   645/ 1097] train: loss: 0.0000817
[Epoch 46; Iter   675/ 1097] train: loss: 0.0045882
[Epoch 46; Iter   705/ 1097] train: loss: 0.0001898
[Epoch 46; Iter   735/ 1097] train: loss: 0.0204431
[Epoch 46; Iter   765/ 1097] train: loss: 0.2833887
[Epoch 46; Iter   795/ 1097] train: loss: 0.0005775
[Epoch 46; Iter   825/ 1097] train: loss: 0.0002136
[Epoch 46; Iter   855/ 1097] train: loss: 0.0062864
[Epoch 46; Iter   885/ 1097] train: loss: 0.0030152
[Epoch 46; Iter   915/ 1097] train: loss: 0.0034241
[Epoch 46; Iter   945/ 1097] train: loss: 0.0002925
[Epoch 46; Iter   975/ 1097] train: loss: 0.0007226
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0018748
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0368826
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0009571
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0007251
[Epoch 46] ogbg-molhiv: 0.659416 val loss: 2.479036
[Epoch 46] ogbg-molhiv: 0.654651 test loss: 2.021809
[Epoch 47; Iter    28/ 1097] train: loss: 0.0010281
[Epoch 47; Iter    58/ 1097] train: loss: 0.0038162
[Epoch 47; Iter    88/ 1097] train: loss: 0.0021509
[Epoch 47; Iter   118/ 1097] train: loss: 0.0916677
[Epoch 47; Iter   148/ 1097] train: loss: 0.0399448
[Epoch 47; Iter   178/ 1097] train: loss: 0.0000247
[Epoch 47; Iter   208/ 1097] train: loss: 0.0007662
[Epoch 47; Iter   238/ 1097] train: loss: 0.0003466
[Epoch 47; Iter   268/ 1097] train: loss: 0.0286435
[Epoch 47; Iter   298/ 1097] train: loss: 0.0003479
[Epoch 47; Iter   328/ 1097] train: loss: 0.0003462
[Epoch 47; Iter   358/ 1097] train: loss: 0.0022020
[Epoch 47; Iter   388/ 1097] train: loss: 0.0007513
[Epoch 47; Iter   418/ 1097] train: loss: 0.0004144
[Epoch 47; Iter   448/ 1097] train: loss: 0.0000424
[Epoch 47; Iter   478/ 1097] train: loss: 0.0001717
[Epoch 47; Iter   508/ 1097] train: loss: 0.0013896
[Epoch 47; Iter   538/ 1097] train: loss: 0.0180606
[Epoch 47; Iter   568/ 1097] train: loss: 0.0004184
[Epoch 47; Iter   598/ 1097] train: loss: 0.0035363
[Epoch 47; Iter   628/ 1097] train: loss: 0.0002285
[Epoch 47; Iter   658/ 1097] train: loss: 0.0006996
[Epoch 47; Iter   688/ 1097] train: loss: 0.0012954
[Epoch 47; Iter   718/ 1097] train: loss: 0.0011822
[Epoch 47; Iter   748/ 1097] train: loss: 0.0005627
[Epoch 47; Iter   778/ 1097] train: loss: 0.0396485
[Epoch 47; Iter   808/ 1097] train: loss: 0.0148238
[Epoch 47; Iter   838/ 1097] train: loss: 0.0015517
[Epoch 47; Iter   868/ 1097] train: loss: 0.0040523
[Epoch 47; Iter   898/ 1097] train: loss: 0.0004867
[Epoch 47; Iter   928/ 1097] train: loss: 0.0001473
[Epoch 47; Iter   958/ 1097] train: loss: 0.0018443
[Epoch 47; Iter   988/ 1097] train: loss: 0.0778808
[Epoch 47; Iter  1018/ 1097] train: loss: 0.1154688
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0005431
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0223907
[Epoch 47] ogbg-molhiv: 0.674435 val loss: 2.554713
[Epoch 47] ogbg-molhiv: 0.592644 test loss: 2.197890
[Epoch 48; Iter    11/ 1097] train: loss: 0.0440923
[Epoch 48; Iter    41/ 1097] train: loss: 0.0003585
[Epoch 48; Iter    71/ 1097] train: loss: 0.0001306
[Epoch 48; Iter   101/ 1097] train: loss: 0.0104249
[Epoch 48; Iter   131/ 1097] train: loss: 0.0036129
[Epoch 48; Iter   161/ 1097] train: loss: 0.0002780
[Epoch 48; Iter   191/ 1097] train: loss: 0.0001949
[Epoch 48; Iter   221/ 1097] train: loss: 0.0001641
[Epoch 48; Iter   251/ 1097] train: loss: 0.0002295
[Epoch 48; Iter   281/ 1097] train: loss: 0.0044826
[Epoch 48; Iter   311/ 1097] train: loss: 0.0036812
[Epoch 48; Iter   341/ 1097] train: loss: 0.0021635
[Epoch 48; Iter   371/ 1097] train: loss: 0.0076511
[Epoch 48; Iter   401/ 1097] train: loss: 0.0006814
[Epoch 48; Iter   431/ 1097] train: loss: 0.0022379
[Epoch 48; Iter   461/ 1097] train: loss: 0.0000912
[Epoch 48; Iter   491/ 1097] train: loss: 0.0003880
[Epoch 48; Iter   521/ 1097] train: loss: 0.0003096
[Epoch 48; Iter   551/ 1097] train: loss: 0.0252306
[Epoch 48; Iter   581/ 1097] train: loss: 0.0464350
[Epoch 48; Iter   611/ 1097] train: loss: 0.0008922
[Epoch 48; Iter   641/ 1097] train: loss: 0.0036558
[Epoch 48; Iter   671/ 1097] train: loss: 0.0162520
[Epoch 48; Iter   701/ 1097] train: loss: 0.0125899
[Epoch 48; Iter   731/ 1097] train: loss: 0.0039534
[Epoch 48; Iter   761/ 1097] train: loss: 0.0099762
[Epoch 48; Iter   791/ 1097] train: loss: 0.0189189
[Epoch 48; Iter   821/ 1097] train: loss: 0.0036872
[Epoch 44; Iter   769/ 1097] train: loss: 0.0006039
[Epoch 44; Iter   799/ 1097] train: loss: 0.0357403
[Epoch 44; Iter   829/ 1097] train: loss: 0.0078533
[Epoch 44; Iter   859/ 1097] train: loss: 0.0343987
[Epoch 44; Iter   889/ 1097] train: loss: 0.0004633
[Epoch 44; Iter   919/ 1097] train: loss: 0.0208812
[Epoch 44; Iter   949/ 1097] train: loss: 0.0682172
[Epoch 44; Iter   979/ 1097] train: loss: 0.0041378
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0135555
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0082840
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0059670
[Epoch 44] ogbg-molhiv: 0.771032 val loss: 3.298801
[Epoch 44] ogbg-molhiv: 0.716615 test loss: 5.986031
[Epoch 45; Iter     2/ 1097] train: loss: 0.0002800
[Epoch 45; Iter    32/ 1097] train: loss: 0.0013831
[Epoch 45; Iter    62/ 1097] train: loss: 0.0015499
[Epoch 45; Iter    92/ 1097] train: loss: 0.0097611
[Epoch 45; Iter   122/ 1097] train: loss: 0.0073037
[Epoch 45; Iter   152/ 1097] train: loss: 0.0213869
[Epoch 45; Iter   182/ 1097] train: loss: 0.0134896
[Epoch 45; Iter   212/ 1097] train: loss: 0.0037545
[Epoch 45; Iter   242/ 1097] train: loss: 0.0025136
[Epoch 45; Iter   272/ 1097] train: loss: 0.0069960
[Epoch 45; Iter   302/ 1097] train: loss: 0.1262360
[Epoch 45; Iter   332/ 1097] train: loss: 0.0124607
[Epoch 45; Iter   362/ 1097] train: loss: 0.0009995
[Epoch 45; Iter   392/ 1097] train: loss: 0.3538225
[Epoch 45; Iter   422/ 1097] train: loss: 0.1382629
[Epoch 45; Iter   452/ 1097] train: loss: 0.0054077
[Epoch 45; Iter   482/ 1097] train: loss: 0.0006190
[Epoch 45; Iter   512/ 1097] train: loss: 0.0037469
[Epoch 45; Iter   542/ 1097] train: loss: 0.0036832
[Epoch 45; Iter   572/ 1097] train: loss: 0.0055063
[Epoch 45; Iter   602/ 1097] train: loss: 0.0018379
[Epoch 45; Iter   632/ 1097] train: loss: 0.0188405
[Epoch 45; Iter   662/ 1097] train: loss: 0.0234332
[Epoch 45; Iter   692/ 1097] train: loss: 0.0282234
[Epoch 45; Iter   722/ 1097] train: loss: 0.0103374
[Epoch 45; Iter   752/ 1097] train: loss: 0.0082695
[Epoch 45; Iter   782/ 1097] train: loss: 0.0149812
[Epoch 45; Iter   812/ 1097] train: loss: 0.0028409
[Epoch 45; Iter   842/ 1097] train: loss: 0.0021133
[Epoch 45; Iter   872/ 1097] train: loss: 0.0487354
[Epoch 45; Iter   902/ 1097] train: loss: 0.0247850
[Epoch 45; Iter   932/ 1097] train: loss: 0.0529135
[Epoch 45; Iter   962/ 1097] train: loss: 0.0008229
[Epoch 45; Iter   992/ 1097] train: loss: 0.0191214
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0044297
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0284004
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0024528
[Epoch 45] ogbg-molhiv: 0.799830 val loss: 15.250976
[Epoch 45] ogbg-molhiv: 0.702140 test loss: 12.540249
[Epoch 46; Iter    15/ 1097] train: loss: 0.0027282
[Epoch 46; Iter    45/ 1097] train: loss: 0.0019482
[Epoch 46; Iter    75/ 1097] train: loss: 0.0015659
[Epoch 46; Iter   105/ 1097] train: loss: 0.0005710
[Epoch 46; Iter   135/ 1097] train: loss: 0.0968231
[Epoch 46; Iter   165/ 1097] train: loss: 0.0024664
[Epoch 46; Iter   195/ 1097] train: loss: 0.0029512
[Epoch 46; Iter   225/ 1097] train: loss: 0.0027791
[Epoch 46; Iter   255/ 1097] train: loss: 0.0154741
[Epoch 46; Iter   285/ 1097] train: loss: 0.0080718
[Epoch 46; Iter   315/ 1097] train: loss: 0.0115064
[Epoch 46; Iter   345/ 1097] train: loss: 0.0031173
[Epoch 46; Iter   375/ 1097] train: loss: 0.0706278
[Epoch 46; Iter   405/ 1097] train: loss: 0.0028433
[Epoch 46; Iter   435/ 1097] train: loss: 0.0070213
[Epoch 46; Iter   465/ 1097] train: loss: 0.0531918
[Epoch 46; Iter   495/ 1097] train: loss: 0.0669583
[Epoch 46; Iter   525/ 1097] train: loss: 0.0020561
[Epoch 46; Iter   555/ 1097] train: loss: 0.0071571
[Epoch 46; Iter   585/ 1097] train: loss: 0.0052975
[Epoch 46; Iter   615/ 1097] train: loss: 0.3044460
[Epoch 46; Iter   645/ 1097] train: loss: 0.0033815
[Epoch 46; Iter   675/ 1097] train: loss: 0.0816555
[Epoch 46; Iter   705/ 1097] train: loss: 0.0019351
[Epoch 46; Iter   735/ 1097] train: loss: 0.0899158
[Epoch 46; Iter   765/ 1097] train: loss: 0.0037345
[Epoch 46; Iter   795/ 1097] train: loss: 0.0333361
[Epoch 46; Iter   825/ 1097] train: loss: 0.0176628
[Epoch 46; Iter   855/ 1097] train: loss: 0.0014560
[Epoch 46; Iter   885/ 1097] train: loss: 0.0233602
[Epoch 46; Iter   915/ 1097] train: loss: 0.1179043
[Epoch 46; Iter   945/ 1097] train: loss: 0.0040269
[Epoch 46; Iter   975/ 1097] train: loss: 0.0306907
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0027561
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0355811
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0026905
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0275057
[Epoch 46] ogbg-molhiv: 0.794517 val loss: 7.382792
[Epoch 46] ogbg-molhiv: 0.707182 test loss: 7.790770
[Epoch 47; Iter    28/ 1097] train: loss: 0.0039075
[Epoch 47; Iter    58/ 1097] train: loss: 0.0062184
[Epoch 47; Iter    88/ 1097] train: loss: 0.0491191
[Epoch 47; Iter   118/ 1097] train: loss: 0.0065160
[Epoch 47; Iter   148/ 1097] train: loss: 0.0015638
[Epoch 47; Iter   178/ 1097] train: loss: 0.0689468
[Epoch 47; Iter   208/ 1097] train: loss: 0.0176119
[Epoch 47; Iter   238/ 1097] train: loss: 0.0009350
[Epoch 47; Iter   268/ 1097] train: loss: 0.0039515
[Epoch 47; Iter   298/ 1097] train: loss: 0.0030232
[Epoch 47; Iter   328/ 1097] train: loss: 0.0345678
[Epoch 47; Iter   358/ 1097] train: loss: 0.0094817
[Epoch 47; Iter   388/ 1097] train: loss: 0.0027521
[Epoch 47; Iter   418/ 1097] train: loss: 0.0054620
[Epoch 47; Iter   448/ 1097] train: loss: 0.0015843
[Epoch 47; Iter   478/ 1097] train: loss: 0.0243365
[Epoch 47; Iter   508/ 1097] train: loss: 0.0066702
[Epoch 47; Iter   538/ 1097] train: loss: 0.0012069
[Epoch 47; Iter   568/ 1097] train: loss: 0.0043248
[Epoch 47; Iter   598/ 1097] train: loss: 0.0007548
[Epoch 47; Iter   628/ 1097] train: loss: 0.0005544
[Epoch 47; Iter   658/ 1097] train: loss: 0.0076818
[Epoch 47; Iter   688/ 1097] train: loss: 0.0006154
[Epoch 47; Iter   718/ 1097] train: loss: 0.0002686
[Epoch 47; Iter   748/ 1097] train: loss: 0.0027451
[Epoch 47; Iter   778/ 1097] train: loss: 0.0030660
[Epoch 47; Iter   808/ 1097] train: loss: 0.0304777
[Epoch 47; Iter   838/ 1097] train: loss: 0.0039642
[Epoch 47; Iter   868/ 1097] train: loss: 0.0752468
[Epoch 47; Iter   898/ 1097] train: loss: 0.0114206
[Epoch 47; Iter   928/ 1097] train: loss: 0.0124942
[Epoch 47; Iter   958/ 1097] train: loss: 0.0270508
[Epoch 47; Iter   988/ 1097] train: loss: 0.0954956
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0235630
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0537328
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0803659
[Epoch 47] ogbg-molhiv: 0.771969 val loss: 10.799667
[Epoch 47] ogbg-molhiv: 0.705861 test loss: 9.016849
[Epoch 48; Iter    11/ 1097] train: loss: 0.0010449
[Epoch 48; Iter    41/ 1097] train: loss: 0.1495008
[Epoch 48; Iter    71/ 1097] train: loss: 0.0217063
[Epoch 48; Iter   101/ 1097] train: loss: 0.2196602
[Epoch 48; Iter   131/ 1097] train: loss: 0.0034584
[Epoch 48; Iter   161/ 1097] train: loss: 0.0050660
[Epoch 48; Iter   191/ 1097] train: loss: 0.0064196
[Epoch 48; Iter   221/ 1097] train: loss: 0.0193035
[Epoch 48; Iter   251/ 1097] train: loss: 0.0119307
[Epoch 48; Iter   281/ 1097] train: loss: 0.0097568
[Epoch 48; Iter   311/ 1097] train: loss: 0.0004824
[Epoch 48; Iter   341/ 1097] train: loss: 0.0125217
[Epoch 48; Iter   371/ 1097] train: loss: 0.0002689
[Epoch 48; Iter   401/ 1097] train: loss: 0.0064352
[Epoch 48; Iter   431/ 1097] train: loss: 0.0102031
[Epoch 48; Iter   461/ 1097] train: loss: 0.0445318
[Epoch 48; Iter   491/ 1097] train: loss: 0.0015861
[Epoch 48; Iter   521/ 1097] train: loss: 0.0079518
[Epoch 48; Iter   551/ 1097] train: loss: 0.0012357
[Epoch 48; Iter   581/ 1097] train: loss: 0.0135772
[Epoch 48; Iter   611/ 1097] train: loss: 0.0007830
[Epoch 48; Iter   641/ 1097] train: loss: 0.0023273
[Epoch 48; Iter   671/ 1097] train: loss: 0.0027332
[Epoch 48; Iter   701/ 1097] train: loss: 0.0439240
[Epoch 48; Iter   731/ 1097] train: loss: 0.0010253
[Epoch 48; Iter   761/ 1097] train: loss: 0.0144597
[Epoch 48; Iter   791/ 1097] train: loss: 0.0095700
[Epoch 48; Iter   821/ 1097] train: loss: 0.0079750
[Epoch 44; Iter   769/ 1097] train: loss: 0.0084669
[Epoch 44; Iter   799/ 1097] train: loss: 0.0031289
[Epoch 44; Iter   829/ 1097] train: loss: 0.0003598
[Epoch 44; Iter   859/ 1097] train: loss: 0.0005777
[Epoch 44; Iter   889/ 1097] train: loss: 0.0002928
[Epoch 44; Iter   919/ 1097] train: loss: 0.0110613
[Epoch 44; Iter   949/ 1097] train: loss: 0.0007163
[Epoch 44; Iter   979/ 1097] train: loss: 0.0004930
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0018904
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0006441
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1007156
[Epoch 44] ogbg-molhiv: 0.709491 val loss: 3.379740
[Epoch 44] ogbg-molhiv: 0.676073 test loss: 2.212064
[Epoch 45; Iter     2/ 1097] train: loss: 0.0378767
[Epoch 45; Iter    32/ 1097] train: loss: 0.0009465
[Epoch 45; Iter    62/ 1097] train: loss: 0.0029263
[Epoch 45; Iter    92/ 1097] train: loss: 0.0016334
[Epoch 45; Iter   122/ 1097] train: loss: 0.0005813
[Epoch 45; Iter   152/ 1097] train: loss: 0.1119302
[Epoch 45; Iter   182/ 1097] train: loss: 0.0262913
[Epoch 45; Iter   212/ 1097] train: loss: 0.0248046
[Epoch 45; Iter   242/ 1097] train: loss: 0.0000442
[Epoch 45; Iter   272/ 1097] train: loss: 0.0019146
[Epoch 45; Iter   302/ 1097] train: loss: 0.0011858
[Epoch 45; Iter   332/ 1097] train: loss: 0.0002737
[Epoch 45; Iter   362/ 1097] train: loss: 0.0005146
[Epoch 45; Iter   392/ 1097] train: loss: 0.0009225
[Epoch 45; Iter   422/ 1097] train: loss: 0.0009700
[Epoch 45; Iter   452/ 1097] train: loss: 0.0017115
[Epoch 45; Iter   482/ 1097] train: loss: 0.1337032
[Epoch 45; Iter   512/ 1097] train: loss: 0.0042770
[Epoch 45; Iter   542/ 1097] train: loss: 0.0019684
[Epoch 45; Iter   572/ 1097] train: loss: 0.0227457
[Epoch 45; Iter   602/ 1097] train: loss: 0.0008170
[Epoch 45; Iter   632/ 1097] train: loss: 0.0039362
[Epoch 45; Iter   662/ 1097] train: loss: 0.0016989
[Epoch 45; Iter   692/ 1097] train: loss: 0.0031471
[Epoch 45; Iter   722/ 1097] train: loss: 0.0305219
[Epoch 45; Iter   752/ 1097] train: loss: 0.0008250
[Epoch 45; Iter   782/ 1097] train: loss: 0.0002867
[Epoch 45; Iter   812/ 1097] train: loss: 0.0000528
[Epoch 45; Iter   842/ 1097] train: loss: 0.0000559
[Epoch 45; Iter   872/ 1097] train: loss: 0.0729841
[Epoch 45; Iter   902/ 1097] train: loss: 0.0004489
[Epoch 45; Iter   932/ 1097] train: loss: 0.0008974
[Epoch 45; Iter   962/ 1097] train: loss: 0.0000642
[Epoch 45; Iter   992/ 1097] train: loss: 0.0052522
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0137679
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0026486
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0004339
[Epoch 45] ogbg-molhiv: 0.721910 val loss: 3.688160
[Epoch 45] ogbg-molhiv: 0.656529 test loss: 2.406682
[Epoch 46; Iter    15/ 1097] train: loss: 0.0000917
[Epoch 46; Iter    45/ 1097] train: loss: 0.0390510
[Epoch 46; Iter    75/ 1097] train: loss: 0.0005543
[Epoch 46; Iter   105/ 1097] train: loss: 0.0004444
[Epoch 46; Iter   135/ 1097] train: loss: 0.0000744
[Epoch 46; Iter   165/ 1097] train: loss: 0.0027558
[Epoch 46; Iter   195/ 1097] train: loss: 0.0057097
[Epoch 46; Iter   225/ 1097] train: loss: 0.0017792
[Epoch 46; Iter   255/ 1097] train: loss: 0.0011189
[Epoch 46; Iter   285/ 1097] train: loss: 0.0023339
[Epoch 46; Iter   315/ 1097] train: loss: 0.0008523
[Epoch 46; Iter   345/ 1097] train: loss: 0.0000561
[Epoch 46; Iter   375/ 1097] train: loss: 0.0011025
[Epoch 46; Iter   405/ 1097] train: loss: 0.0001765
[Epoch 46; Iter   435/ 1097] train: loss: 0.0690718
[Epoch 46; Iter   465/ 1097] train: loss: 0.0034678
[Epoch 46; Iter   495/ 1097] train: loss: 0.0013995
[Epoch 46; Iter   525/ 1097] train: loss: 0.0016042
[Epoch 46; Iter   555/ 1097] train: loss: 0.0040743
[Epoch 46; Iter   585/ 1097] train: loss: 0.0132136
[Epoch 46; Iter   615/ 1097] train: loss: 0.0000396
[Epoch 46; Iter   645/ 1097] train: loss: 0.0003593
[Epoch 46; Iter   675/ 1097] train: loss: 0.0012722
[Epoch 46; Iter   705/ 1097] train: loss: 0.0015175
[Epoch 46; Iter   735/ 1097] train: loss: 0.0001121
[Epoch 46; Iter   765/ 1097] train: loss: 0.0024026
[Epoch 46; Iter   795/ 1097] train: loss: 0.0000588
[Epoch 46; Iter   825/ 1097] train: loss: 0.0039535
[Epoch 46; Iter   855/ 1097] train: loss: 0.0029635
[Epoch 46; Iter   885/ 1097] train: loss: 0.0007113
[Epoch 46; Iter   915/ 1097] train: loss: 0.0002453
[Epoch 46; Iter   945/ 1097] train: loss: 0.0001827
[Epoch 46; Iter   975/ 1097] train: loss: 0.0033731
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0004308
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0026634
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0004235
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0003503
[Epoch 46] ogbg-molhiv: 0.742639 val loss: 0.335543
[Epoch 46] ogbg-molhiv: 0.673959 test loss: 0.414691
[Epoch 47; Iter    28/ 1097] train: loss: 0.0002308
[Epoch 47; Iter    58/ 1097] train: loss: 0.0012000
[Epoch 47; Iter    88/ 1097] train: loss: 0.0006947
[Epoch 47; Iter   118/ 1097] train: loss: 0.0764671
[Epoch 47; Iter   148/ 1097] train: loss: 0.0003583
[Epoch 47; Iter   178/ 1097] train: loss: 0.0124943
[Epoch 47; Iter   208/ 1097] train: loss: 0.0001650
[Epoch 47; Iter   238/ 1097] train: loss: 0.0053633
[Epoch 47; Iter   268/ 1097] train: loss: 0.0009289
[Epoch 47; Iter   298/ 1097] train: loss: 0.0357142
[Epoch 47; Iter   328/ 1097] train: loss: 0.0025918
[Epoch 47; Iter   358/ 1097] train: loss: 0.1850817
[Epoch 47; Iter   388/ 1097] train: loss: 0.0021322
[Epoch 47; Iter   418/ 1097] train: loss: 0.0022985
[Epoch 47; Iter   448/ 1097] train: loss: 0.0053042
[Epoch 47; Iter   478/ 1097] train: loss: 0.0051927
[Epoch 47; Iter   508/ 1097] train: loss: 0.0130700
[Epoch 47; Iter   538/ 1097] train: loss: 0.0001432
[Epoch 47; Iter   568/ 1097] train: loss: 0.0001871
[Epoch 47; Iter   598/ 1097] train: loss: 0.0000649
[Epoch 47; Iter   628/ 1097] train: loss: 0.0040567
[Epoch 47; Iter   658/ 1097] train: loss: 0.0049852
[Epoch 47; Iter   688/ 1097] train: loss: 0.0188017
[Epoch 47; Iter   718/ 1097] train: loss: 0.0015923
[Epoch 47; Iter   748/ 1097] train: loss: 0.0017686
[Epoch 47; Iter   778/ 1097] train: loss: 0.0009590
[Epoch 47; Iter   808/ 1097] train: loss: 0.0001029
[Epoch 47; Iter   838/ 1097] train: loss: 0.0091310
[Epoch 47; Iter   868/ 1097] train: loss: 0.0014317
[Epoch 47; Iter   898/ 1097] train: loss: 0.0648655
[Epoch 47; Iter   928/ 1097] train: loss: 0.0011395
[Epoch 47; Iter   958/ 1097] train: loss: 0.0008764
[Epoch 47; Iter   988/ 1097] train: loss: 0.0010197
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0002194
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0013600
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0025907
[Epoch 47] ogbg-molhiv: 0.760000 val loss: 1.657230
[Epoch 47] ogbg-molhiv: 0.691531 test loss: 1.177578
[Epoch 48; Iter    11/ 1097] train: loss: 0.0664848
[Epoch 48; Iter    41/ 1097] train: loss: 0.0049163
[Epoch 48; Iter    71/ 1097] train: loss: 0.0000146
[Epoch 48; Iter   101/ 1097] train: loss: 0.0542042
[Epoch 48; Iter   131/ 1097] train: loss: 0.0011413
[Epoch 48; Iter   161/ 1097] train: loss: 0.0003089
[Epoch 48; Iter   191/ 1097] train: loss: 0.0002114
[Epoch 48; Iter   221/ 1097] train: loss: 0.0001934
[Epoch 48; Iter   251/ 1097] train: loss: 0.0021537
[Epoch 48; Iter   281/ 1097] train: loss: 0.0010260
[Epoch 48; Iter   311/ 1097] train: loss: 0.0005958
[Epoch 48; Iter   341/ 1097] train: loss: 0.0005922
[Epoch 48; Iter   371/ 1097] train: loss: 0.0222838
[Epoch 48; Iter   401/ 1097] train: loss: 0.0025852
[Epoch 48; Iter   431/ 1097] train: loss: 0.0004876
[Epoch 48; Iter   461/ 1097] train: loss: 0.0050820
[Epoch 48; Iter   491/ 1097] train: loss: 0.0004778
[Epoch 48; Iter   521/ 1097] train: loss: 0.0016655
[Epoch 48; Iter   551/ 1097] train: loss: 0.0277279
[Epoch 48; Iter   581/ 1097] train: loss: 0.1260920
[Epoch 48; Iter   611/ 1097] train: loss: 0.0003795
[Epoch 48; Iter   641/ 1097] train: loss: 0.0005567
[Epoch 48; Iter   671/ 1097] train: loss: 0.0013053
[Epoch 48; Iter   701/ 1097] train: loss: 0.0002421
[Epoch 48; Iter   731/ 1097] train: loss: 0.0002424
[Epoch 48; Iter   761/ 1097] train: loss: 0.0078230
[Epoch 48; Iter   791/ 1097] train: loss: 0.0002741
[Epoch 48; Iter   821/ 1097] train: loss: 0.0061954
[Epoch 48; Iter   851/ 1097] train: loss: 0.0009649
[Epoch 48; Iter   881/ 1097] train: loss: 0.0091507
[Epoch 48; Iter   911/ 1097] train: loss: 0.0046151
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015471
[Epoch 48; Iter   971/ 1097] train: loss: 0.0257413
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0142126
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0014518
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0004474
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0238573
[Epoch 48] ogbg-molhiv: 0.690225 val loss: 0.181587
[Epoch 48] ogbg-molhiv: 0.729504 test loss: 0.311847
[Epoch 49; Iter    24/ 1097] train: loss: 0.0085438
[Epoch 49; Iter    54/ 1097] train: loss: 0.0021518
[Epoch 49; Iter    84/ 1097] train: loss: 0.0235419
[Epoch 49; Iter   114/ 1097] train: loss: 0.0062532
[Epoch 49; Iter   144/ 1097] train: loss: 0.0002234
[Epoch 49; Iter   174/ 1097] train: loss: 0.0412132
[Epoch 49; Iter   204/ 1097] train: loss: 0.0045723
[Epoch 49; Iter   234/ 1097] train: loss: 0.0249704
[Epoch 49; Iter   264/ 1097] train: loss: 0.0107949
[Epoch 49; Iter   294/ 1097] train: loss: 0.0005576
[Epoch 49; Iter   324/ 1097] train: loss: 0.1650785
[Epoch 49; Iter   354/ 1097] train: loss: 0.0065107
[Epoch 49; Iter   384/ 1097] train: loss: 0.0077058
[Epoch 49; Iter   414/ 1097] train: loss: 0.0501331
[Epoch 49; Iter   444/ 1097] train: loss: 0.0004413
[Epoch 49; Iter   474/ 1097] train: loss: 0.0557584
[Epoch 49; Iter   504/ 1097] train: loss: 0.0076071
[Epoch 49; Iter   534/ 1097] train: loss: 0.1064919
[Epoch 49; Iter   564/ 1097] train: loss: 0.0007927
[Epoch 49; Iter   594/ 1097] train: loss: 0.0004984
[Epoch 49; Iter   624/ 1097] train: loss: 0.0286167
[Epoch 49; Iter   654/ 1097] train: loss: 0.0004241
[Epoch 49; Iter   684/ 1097] train: loss: 0.0020830
[Epoch 49; Iter   714/ 1097] train: loss: 0.0008499
[Epoch 49; Iter   744/ 1097] train: loss: 0.0516430
[Epoch 49; Iter   774/ 1097] train: loss: 0.0013592
[Epoch 49; Iter   804/ 1097] train: loss: 0.0108920
[Epoch 49; Iter   834/ 1097] train: loss: 0.0057505
[Epoch 49; Iter   864/ 1097] train: loss: 0.0083662
[Epoch 49; Iter   894/ 1097] train: loss: 0.0018878
[Epoch 49; Iter   924/ 1097] train: loss: 0.0015811
[Epoch 49; Iter   954/ 1097] train: loss: 0.0343895
[Epoch 49; Iter   984/ 1097] train: loss: 0.0583544
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0129377
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0011969
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0526132
[Epoch 49] ogbg-molhiv: 0.699086 val loss: 0.662221
[Epoch 49] ogbg-molhiv: 0.728457 test loss: 0.284211
[Epoch 50; Iter     7/ 1097] train: loss: 0.0245033
[Epoch 50; Iter    37/ 1097] train: loss: 0.0010682
[Epoch 50; Iter    67/ 1097] train: loss: 0.0227308
[Epoch 50; Iter    97/ 1097] train: loss: 0.0013529
[Epoch 50; Iter   127/ 1097] train: loss: 0.0022378
[Epoch 50; Iter   157/ 1097] train: loss: 0.0040547
[Epoch 50; Iter   187/ 1097] train: loss: 0.0004512
[Epoch 50; Iter   217/ 1097] train: loss: 0.0015095
[Epoch 50; Iter   247/ 1097] train: loss: 0.0023548
[Epoch 50; Iter   277/ 1097] train: loss: 0.0062655
[Epoch 50; Iter   307/ 1097] train: loss: 0.0073311
[Epoch 50; Iter   337/ 1097] train: loss: 0.0031848
[Epoch 50; Iter   367/ 1097] train: loss: 0.0479980
[Epoch 50; Iter   397/ 1097] train: loss: 0.0014401
[Epoch 50; Iter   427/ 1097] train: loss: 0.0011972
[Epoch 50; Iter   457/ 1097] train: loss: 0.0006207
[Epoch 50; Iter   487/ 1097] train: loss: 0.0431790
[Epoch 50; Iter   517/ 1097] train: loss: 0.0034869
[Epoch 50; Iter   547/ 1097] train: loss: 0.0162764
[Epoch 50; Iter   577/ 1097] train: loss: 0.0027752
[Epoch 50; Iter   607/ 1097] train: loss: 0.0054956
[Epoch 50; Iter   637/ 1097] train: loss: 0.0037107
[Epoch 50; Iter   667/ 1097] train: loss: 0.0003518
[Epoch 50; Iter   697/ 1097] train: loss: 0.0025034
[Epoch 50; Iter   727/ 1097] train: loss: 0.0352776
[Epoch 50; Iter   757/ 1097] train: loss: 0.0016356
[Epoch 50; Iter   787/ 1097] train: loss: 0.0156907
[Epoch 50; Iter   817/ 1097] train: loss: 0.0712824
[Epoch 50; Iter   847/ 1097] train: loss: 0.0009420
[Epoch 50; Iter   877/ 1097] train: loss: 0.0097078
[Epoch 50; Iter   907/ 1097] train: loss: 0.0497974
[Epoch 50; Iter   937/ 1097] train: loss: 0.0009454
[Epoch 50; Iter   967/ 1097] train: loss: 0.0207716
[Epoch 50; Iter   997/ 1097] train: loss: 0.0041456
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0013087
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0010408
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0158509
[Epoch 50] ogbg-molhiv: 0.671985 val loss: 0.194564
[Epoch 50] ogbg-molhiv: 0.708048 test loss: 0.310492
[Epoch 51; Iter    20/ 1097] train: loss: 0.0160332
[Epoch 51; Iter    50/ 1097] train: loss: 0.0049778
[Epoch 51; Iter    80/ 1097] train: loss: 0.0000941
[Epoch 51; Iter   110/ 1097] train: loss: 0.0134620
[Epoch 51; Iter   140/ 1097] train: loss: 0.0011967
[Epoch 51; Iter   170/ 1097] train: loss: 0.0003361
[Epoch 51; Iter   200/ 1097] train: loss: 0.0119354
[Epoch 51; Iter   230/ 1097] train: loss: 0.0650090
[Epoch 51; Iter   260/ 1097] train: loss: 0.0248393
[Epoch 51; Iter   290/ 1097] train: loss: 0.0007686
[Epoch 51; Iter   320/ 1097] train: loss: 0.0406092
[Epoch 51; Iter   350/ 1097] train: loss: 0.0006057
[Epoch 51; Iter   380/ 1097] train: loss: 0.0043257
[Epoch 51; Iter   410/ 1097] train: loss: 0.0051864
[Epoch 51; Iter   440/ 1097] train: loss: 0.0080614
[Epoch 51; Iter   470/ 1097] train: loss: 0.0318935
[Epoch 51; Iter   500/ 1097] train: loss: 0.0006877
[Epoch 51; Iter   530/ 1097] train: loss: 0.0034122
[Epoch 51; Iter   560/ 1097] train: loss: 0.0004320
[Epoch 51; Iter   590/ 1097] train: loss: 0.0093498
[Epoch 51; Iter   620/ 1097] train: loss: 0.0010592
[Epoch 51; Iter   650/ 1097] train: loss: 0.0004571
[Epoch 51; Iter   680/ 1097] train: loss: 0.0001919
[Epoch 51; Iter   710/ 1097] train: loss: 0.0002570
[Epoch 51; Iter   740/ 1097] train: loss: 0.0012981
[Epoch 51; Iter   770/ 1097] train: loss: 0.0415601
[Epoch 51; Iter   800/ 1097] train: loss: 0.0633049
[Epoch 51; Iter   830/ 1097] train: loss: 0.0933048
[Epoch 51; Iter   860/ 1097] train: loss: 0.0011079
[Epoch 51; Iter   890/ 1097] train: loss: 0.0003964
[Epoch 51; Iter   920/ 1097] train: loss: 0.0111532
[Epoch 51; Iter   950/ 1097] train: loss: 0.0011175
[Epoch 51; Iter   980/ 1097] train: loss: 0.0009988
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0373405
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0014837
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0004609
[Epoch 51] ogbg-molhiv: 0.692721 val loss: 0.384390
[Epoch 51] ogbg-molhiv: 0.731870 test loss: 0.429093
[Epoch 52; Iter     3/ 1097] train: loss: 0.0225908
[Epoch 52; Iter    33/ 1097] train: loss: 0.0017828
[Epoch 52; Iter    63/ 1097] train: loss: 0.0248116
[Epoch 52; Iter    93/ 1097] train: loss: 0.0261537
[Epoch 52; Iter   123/ 1097] train: loss: 0.0020002
[Epoch 52; Iter   153/ 1097] train: loss: 0.0075480
[Epoch 52; Iter   183/ 1097] train: loss: 0.0019646
[Epoch 52; Iter   213/ 1097] train: loss: 0.0021839
[Epoch 52; Iter   243/ 1097] train: loss: 0.0000809
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002226
[Epoch 52; Iter   303/ 1097] train: loss: 0.0324536
[Epoch 52; Iter   333/ 1097] train: loss: 0.0008417
[Epoch 52; Iter   363/ 1097] train: loss: 0.0018294
[Epoch 52; Iter   393/ 1097] train: loss: 0.0077556
[Epoch 52; Iter   423/ 1097] train: loss: 0.0667897
[Epoch 52; Iter   453/ 1097] train: loss: 0.0019607
[Epoch 52; Iter   483/ 1097] train: loss: 0.0026892
[Epoch 52; Iter   513/ 1097] train: loss: 0.0011445
[Epoch 52; Iter   543/ 1097] train: loss: 0.0048944
[Epoch 52; Iter   573/ 1097] train: loss: 0.0035877
[Epoch 52; Iter   603/ 1097] train: loss: 0.0005407
[Epoch 52; Iter   633/ 1097] train: loss: 0.0007161
[Epoch 52; Iter   663/ 1097] train: loss: 0.0059544
[Epoch 52; Iter   693/ 1097] train: loss: 0.0011019
[Epoch 52; Iter   723/ 1097] train: loss: 0.0013517
[Epoch 52; Iter   753/ 1097] train: loss: 0.0051917
[Epoch 52; Iter   783/ 1097] train: loss: 0.0030722
[Epoch 52; Iter   813/ 1097] train: loss: 0.0033229
[Epoch 52; Iter   843/ 1097] train: loss: 0.0010342
[Epoch 52; Iter   873/ 1097] train: loss: 0.0005400
[Epoch 52; Iter   903/ 1097] train: loss: 0.0104738
[Epoch 48; Iter   851/ 1097] train: loss: 0.0039712
[Epoch 48; Iter   881/ 1097] train: loss: 0.0116688
[Epoch 48; Iter   911/ 1097] train: loss: 0.0369079
[Epoch 48; Iter   941/ 1097] train: loss: 0.0133091
[Epoch 48; Iter   971/ 1097] train: loss: 0.0144820
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0006554
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0038324
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0319360
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0070733
[Epoch 48] ogbg-molhiv: 0.766237 val loss: 0.201748
[Epoch 48] ogbg-molhiv: 0.748423 test loss: 0.258861
[Epoch 49; Iter    24/ 1097] train: loss: 0.0009323
[Epoch 49; Iter    54/ 1097] train: loss: 0.0276855
[Epoch 49; Iter    84/ 1097] train: loss: 0.0000703
[Epoch 49; Iter   114/ 1097] train: loss: 0.0184949
[Epoch 49; Iter   144/ 1097] train: loss: 0.0039444
[Epoch 49; Iter   174/ 1097] train: loss: 0.0223565
[Epoch 49; Iter   204/ 1097] train: loss: 0.0026127
[Epoch 49; Iter   234/ 1097] train: loss: 0.0220484
[Epoch 49; Iter   264/ 1097] train: loss: 0.0016877
[Epoch 49; Iter   294/ 1097] train: loss: 0.0001706
[Epoch 49; Iter   324/ 1097] train: loss: 0.0003652
[Epoch 49; Iter   354/ 1097] train: loss: 0.0049159
[Epoch 49; Iter   384/ 1097] train: loss: 0.0004792
[Epoch 49; Iter   414/ 1097] train: loss: 0.0199411
[Epoch 49; Iter   444/ 1097] train: loss: 0.0057238
[Epoch 49; Iter   474/ 1097] train: loss: 0.0140996
[Epoch 49; Iter   504/ 1097] train: loss: 0.0030550
[Epoch 49; Iter   534/ 1097] train: loss: 0.0002400
[Epoch 49; Iter   564/ 1097] train: loss: 0.0068735
[Epoch 49; Iter   594/ 1097] train: loss: 0.0117199
[Epoch 49; Iter   624/ 1097] train: loss: 0.0750023
[Epoch 49; Iter   654/ 1097] train: loss: 0.0022725
[Epoch 49; Iter   684/ 1097] train: loss: 0.0039636
[Epoch 49; Iter   714/ 1097] train: loss: 0.0011123
[Epoch 49; Iter   744/ 1097] train: loss: 0.0067225
[Epoch 49; Iter   774/ 1097] train: loss: 0.0072292
[Epoch 49; Iter   804/ 1097] train: loss: 0.1020195
[Epoch 49; Iter   834/ 1097] train: loss: 0.0129402
[Epoch 49; Iter   864/ 1097] train: loss: 0.0150188
[Epoch 49; Iter   894/ 1097] train: loss: 0.0004638
[Epoch 49; Iter   924/ 1097] train: loss: 0.0052845
[Epoch 49; Iter   954/ 1097] train: loss: 0.0014045
[Epoch 49; Iter   984/ 1097] train: loss: 0.0004678
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0029618
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0007834
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0018521
[Epoch 49] ogbg-molhiv: 0.776342 val loss: 0.206935
[Epoch 49] ogbg-molhiv: 0.745121 test loss: 0.330680
[Epoch 50; Iter     7/ 1097] train: loss: 0.1784326
[Epoch 50; Iter    37/ 1097] train: loss: 0.0030247
[Epoch 50; Iter    67/ 1097] train: loss: 0.0008424
[Epoch 50; Iter    97/ 1097] train: loss: 0.0098249
[Epoch 50; Iter   127/ 1097] train: loss: 0.0129865
[Epoch 50; Iter   157/ 1097] train: loss: 0.0011727
[Epoch 50; Iter   187/ 1097] train: loss: 0.0004329
[Epoch 50; Iter   217/ 1097] train: loss: 0.0123581
[Epoch 50; Iter   247/ 1097] train: loss: 0.0206209
[Epoch 50; Iter   277/ 1097] train: loss: 0.0111611
[Epoch 50; Iter   307/ 1097] train: loss: 0.0022588
[Epoch 50; Iter   337/ 1097] train: loss: 0.0028252
[Epoch 50; Iter   367/ 1097] train: loss: 0.0039460
[Epoch 50; Iter   397/ 1097] train: loss: 0.0029384
[Epoch 50; Iter   427/ 1097] train: loss: 0.1864693
[Epoch 50; Iter   457/ 1097] train: loss: 0.0004364
[Epoch 50; Iter   487/ 1097] train: loss: 0.0074504
[Epoch 50; Iter   517/ 1097] train: loss: 0.0030333
[Epoch 50; Iter   547/ 1097] train: loss: 0.0047228
[Epoch 50; Iter   577/ 1097] train: loss: 0.1066095
[Epoch 50; Iter   607/ 1097] train: loss: 0.0007549
[Epoch 50; Iter   637/ 1097] train: loss: 0.0098491
[Epoch 50; Iter   667/ 1097] train: loss: 0.0050507
[Epoch 50; Iter   697/ 1097] train: loss: 0.0036235
[Epoch 50; Iter   727/ 1097] train: loss: 0.0083998
[Epoch 50; Iter   757/ 1097] train: loss: 0.0012998
[Epoch 50; Iter   787/ 1097] train: loss: 0.0062014
[Epoch 50; Iter   817/ 1097] train: loss: 0.0035880
[Epoch 50; Iter   847/ 1097] train: loss: 0.0102278
[Epoch 50; Iter   877/ 1097] train: loss: 0.0028709
[Epoch 50; Iter   907/ 1097] train: loss: 0.0157178
[Epoch 50; Iter   937/ 1097] train: loss: 0.0052421
[Epoch 50; Iter   967/ 1097] train: loss: 0.0370210
[Epoch 50; Iter   997/ 1097] train: loss: 0.0004479
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0026813
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0008321
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0097161
[Epoch 50] ogbg-molhiv: 0.761687 val loss: 0.210938
[Epoch 50] ogbg-molhiv: 0.752394 test loss: 0.251956
[Epoch 51; Iter    20/ 1097] train: loss: 0.0014609
[Epoch 51; Iter    50/ 1097] train: loss: 0.0062612
[Epoch 51; Iter    80/ 1097] train: loss: 0.0022039
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007610
[Epoch 51; Iter   140/ 1097] train: loss: 0.0704914
[Epoch 51; Iter   170/ 1097] train: loss: 0.0026576
[Epoch 51; Iter   200/ 1097] train: loss: 0.0005268
[Epoch 51; Iter   230/ 1097] train: loss: 0.0021410
[Epoch 51; Iter   260/ 1097] train: loss: 0.0011181
[Epoch 51; Iter   290/ 1097] train: loss: 0.0086973
[Epoch 51; Iter   320/ 1097] train: loss: 0.0045904
[Epoch 51; Iter   350/ 1097] train: loss: 0.0002801
[Epoch 51; Iter   380/ 1097] train: loss: 0.0080926
[Epoch 51; Iter   410/ 1097] train: loss: 0.0108411
[Epoch 51; Iter   440/ 1097] train: loss: 0.0005963
[Epoch 51; Iter   470/ 1097] train: loss: 0.0040017
[Epoch 51; Iter   500/ 1097] train: loss: 0.1798965
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004392
[Epoch 51; Iter   560/ 1097] train: loss: 0.0047196
[Epoch 51; Iter   590/ 1097] train: loss: 0.0011806
[Epoch 51; Iter   620/ 1097] train: loss: 0.0163468
[Epoch 51; Iter   650/ 1097] train: loss: 0.0034905
[Epoch 51; Iter   680/ 1097] train: loss: 0.0157751
[Epoch 51; Iter   710/ 1097] train: loss: 0.0018564
[Epoch 51; Iter   740/ 1097] train: loss: 0.0078144
[Epoch 51; Iter   770/ 1097] train: loss: 0.1091505
[Epoch 51; Iter   800/ 1097] train: loss: 0.0089452
[Epoch 51; Iter   830/ 1097] train: loss: 0.0064265
[Epoch 51; Iter   860/ 1097] train: loss: 0.0017296
[Epoch 51; Iter   890/ 1097] train: loss: 0.0037498
[Epoch 51; Iter   920/ 1097] train: loss: 0.0002995
[Epoch 51; Iter   950/ 1097] train: loss: 0.0006508
[Epoch 51; Iter   980/ 1097] train: loss: 0.0012331
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0009581
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0024319
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0232991
[Epoch 51] ogbg-molhiv: 0.758004 val loss: 0.284595
[Epoch 51] ogbg-molhiv: 0.739750 test loss: 0.305734
[Epoch 52; Iter     3/ 1097] train: loss: 0.0047814
[Epoch 52; Iter    33/ 1097] train: loss: 0.0010717
[Epoch 52; Iter    63/ 1097] train: loss: 0.0129217
[Epoch 52; Iter    93/ 1097] train: loss: 0.0034178
[Epoch 52; Iter   123/ 1097] train: loss: 0.0004124
[Epoch 52; Iter   153/ 1097] train: loss: 0.0002945
[Epoch 52; Iter   183/ 1097] train: loss: 0.0016344
[Epoch 52; Iter   213/ 1097] train: loss: 0.0038734
[Epoch 52; Iter   243/ 1097] train: loss: 0.0009790
[Epoch 52; Iter   273/ 1097] train: loss: 0.0055452
[Epoch 52; Iter   303/ 1097] train: loss: 0.0004692
[Epoch 52; Iter   333/ 1097] train: loss: 0.0429028
[Epoch 52; Iter   363/ 1097] train: loss: 0.0026768
[Epoch 52; Iter   393/ 1097] train: loss: 0.0045657
[Epoch 52; Iter   423/ 1097] train: loss: 0.0065662
[Epoch 52; Iter   453/ 1097] train: loss: 0.0146164
[Epoch 52; Iter   483/ 1097] train: loss: 0.0003228
[Epoch 52; Iter   513/ 1097] train: loss: 0.0869479
[Epoch 52; Iter   543/ 1097] train: loss: 0.0024747
[Epoch 52; Iter   573/ 1097] train: loss: 0.0011740
[Epoch 52; Iter   603/ 1097] train: loss: 0.0030708
[Epoch 52; Iter   633/ 1097] train: loss: 0.0004966
[Epoch 52; Iter   663/ 1097] train: loss: 0.0112828
[Epoch 52; Iter   693/ 1097] train: loss: 0.0087521
[Epoch 52; Iter   723/ 1097] train: loss: 0.0018254
[Epoch 52; Iter   753/ 1097] train: loss: 0.0004672
[Epoch 52; Iter   783/ 1097] train: loss: 0.0008679
[Epoch 52; Iter   813/ 1097] train: loss: 0.0445781
[Epoch 52; Iter   843/ 1097] train: loss: 0.0043409
[Epoch 52; Iter   873/ 1097] train: loss: 0.0809680
[Epoch 52; Iter   903/ 1097] train: loss: 0.0116869
[Epoch 48; Iter   851/ 1097] train: loss: 0.0019530
[Epoch 48; Iter   881/ 1097] train: loss: 0.1251931
[Epoch 48; Iter   911/ 1097] train: loss: 0.0220912
[Epoch 48; Iter   941/ 1097] train: loss: 0.0300006
[Epoch 48; Iter   971/ 1097] train: loss: 0.0016406
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0031614
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0065017
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0630816
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0038451
[Epoch 48] ogbg-molhiv: 0.739017 val loss: 0.502854
[Epoch 48] ogbg-molhiv: 0.716043 test loss: 0.280242
[Epoch 49; Iter    24/ 1097] train: loss: 0.0036770
[Epoch 49; Iter    54/ 1097] train: loss: 0.0057704
[Epoch 49; Iter    84/ 1097] train: loss: 0.0005477
[Epoch 49; Iter   114/ 1097] train: loss: 0.0161545
[Epoch 49; Iter   144/ 1097] train: loss: 0.0103910
[Epoch 49; Iter   174/ 1097] train: loss: 0.0902699
[Epoch 49; Iter   204/ 1097] train: loss: 0.0028592
[Epoch 49; Iter   234/ 1097] train: loss: 0.0226180
[Epoch 49; Iter   264/ 1097] train: loss: 0.0437636
[Epoch 49; Iter   294/ 1097] train: loss: 0.0034683
[Epoch 49; Iter   324/ 1097] train: loss: 0.0026733
[Epoch 49; Iter   354/ 1097] train: loss: 0.0012726
[Epoch 49; Iter   384/ 1097] train: loss: 0.0502026
[Epoch 49; Iter   414/ 1097] train: loss: 0.0161753
[Epoch 49; Iter   444/ 1097] train: loss: 0.0973233
[Epoch 49; Iter   474/ 1097] train: loss: 0.0018643
[Epoch 49; Iter   504/ 1097] train: loss: 0.0517030
[Epoch 49; Iter   534/ 1097] train: loss: 0.0016988
[Epoch 49; Iter   564/ 1097] train: loss: 0.0153193
[Epoch 49; Iter   594/ 1097] train: loss: 0.0018063
[Epoch 49; Iter   624/ 1097] train: loss: 0.1175374
[Epoch 49; Iter   654/ 1097] train: loss: 0.0114482
[Epoch 49; Iter   684/ 1097] train: loss: 0.0022036
[Epoch 49; Iter   714/ 1097] train: loss: 0.0040429
[Epoch 49; Iter   744/ 1097] train: loss: 0.0010796
[Epoch 49; Iter   774/ 1097] train: loss: 0.0114854
[Epoch 49; Iter   804/ 1097] train: loss: 0.0193571
[Epoch 49; Iter   834/ 1097] train: loss: 0.0022133
[Epoch 49; Iter   864/ 1097] train: loss: 0.0088992
[Epoch 49; Iter   894/ 1097] train: loss: 0.0062423
[Epoch 49; Iter   924/ 1097] train: loss: 0.0149924
[Epoch 49; Iter   954/ 1097] train: loss: 0.0093928
[Epoch 49; Iter   984/ 1097] train: loss: 0.0126754
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0213559
[Epoch 49; Iter  1044/ 1097] train: loss: 0.1229243
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0280534
[Epoch 49] ogbg-molhiv: 0.738610 val loss: 0.487953
[Epoch 49] ogbg-molhiv: 0.711188 test loss: 0.281120
[Epoch 50; Iter     7/ 1097] train: loss: 0.0067409
[Epoch 50; Iter    37/ 1097] train: loss: 0.0156805
[Epoch 50; Iter    67/ 1097] train: loss: 0.0066330
[Epoch 50; Iter    97/ 1097] train: loss: 0.0035172
[Epoch 50; Iter   127/ 1097] train: loss: 0.0105581
[Epoch 50; Iter   157/ 1097] train: loss: 0.0029343
[Epoch 50; Iter   187/ 1097] train: loss: 0.0080497
[Epoch 50; Iter   217/ 1097] train: loss: 0.0215147
[Epoch 50; Iter   247/ 1097] train: loss: 0.0015283
[Epoch 50; Iter   277/ 1097] train: loss: 0.0011125
[Epoch 50; Iter   307/ 1097] train: loss: 0.0185148
[Epoch 50; Iter   337/ 1097] train: loss: 0.0591958
[Epoch 50; Iter   367/ 1097] train: loss: 0.0082495
[Epoch 50; Iter   397/ 1097] train: loss: 0.0154418
[Epoch 50; Iter   427/ 1097] train: loss: 0.0011455
[Epoch 50; Iter   457/ 1097] train: loss: 0.0143536
[Epoch 50; Iter   487/ 1097] train: loss: 0.0321869
[Epoch 50; Iter   517/ 1097] train: loss: 0.0023272
[Epoch 50; Iter   547/ 1097] train: loss: 0.0666045
[Epoch 50; Iter   577/ 1097] train: loss: 0.0028678
[Epoch 50; Iter   607/ 1097] train: loss: 0.0009748
[Epoch 50; Iter   637/ 1097] train: loss: 0.0150398
[Epoch 50; Iter   667/ 1097] train: loss: 0.0104855
[Epoch 50; Iter   697/ 1097] train: loss: 0.0229066
[Epoch 50; Iter   727/ 1097] train: loss: 0.0003674
[Epoch 50; Iter   757/ 1097] train: loss: 0.0016730
[Epoch 50; Iter   787/ 1097] train: loss: 0.0029454
[Epoch 50; Iter   817/ 1097] train: loss: 0.1756625
[Epoch 50; Iter   847/ 1097] train: loss: 0.0067861
[Epoch 50; Iter   877/ 1097] train: loss: 0.0016157
[Epoch 50; Iter   907/ 1097] train: loss: 0.0099428
[Epoch 50; Iter   937/ 1097] train: loss: 0.0133079
[Epoch 50; Iter   967/ 1097] train: loss: 0.0273053
[Epoch 50; Iter   997/ 1097] train: loss: 0.1588880
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0120018
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0028753
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0125882
[Epoch 50] ogbg-molhiv: 0.715440 val loss: 0.609141
[Epoch 50] ogbg-molhiv: 0.688418 test loss: 0.525526
[Epoch 51; Iter    20/ 1097] train: loss: 0.0710082
[Epoch 51; Iter    50/ 1097] train: loss: 0.0003789
[Epoch 51; Iter    80/ 1097] train: loss: 0.0385678
[Epoch 51; Iter   110/ 1097] train: loss: 0.0003569
[Epoch 51; Iter   140/ 1097] train: loss: 0.0031680
[Epoch 51; Iter   170/ 1097] train: loss: 0.0163176
[Epoch 51; Iter   200/ 1097] train: loss: 0.0596270
[Epoch 51; Iter   230/ 1097] train: loss: 0.0047136
[Epoch 51; Iter   260/ 1097] train: loss: 0.0131921
[Epoch 51; Iter   290/ 1097] train: loss: 0.0238583
[Epoch 51; Iter   320/ 1097] train: loss: 0.0171233
[Epoch 51; Iter   350/ 1097] train: loss: 0.0613584
[Epoch 51; Iter   380/ 1097] train: loss: 0.0060874
[Epoch 51; Iter   410/ 1097] train: loss: 0.0113445
[Epoch 51; Iter   440/ 1097] train: loss: 0.0014079
[Epoch 51; Iter   470/ 1097] train: loss: 0.0013036
[Epoch 51; Iter   500/ 1097] train: loss: 0.0030853
[Epoch 51; Iter   530/ 1097] train: loss: 0.0267104
[Epoch 51; Iter   560/ 1097] train: loss: 0.0012133
[Epoch 51; Iter   590/ 1097] train: loss: 0.0029994
[Epoch 51; Iter   620/ 1097] train: loss: 0.0016934
[Epoch 51; Iter   650/ 1097] train: loss: 0.0004489
[Epoch 51; Iter   680/ 1097] train: loss: 0.0099405
[Epoch 51; Iter   710/ 1097] train: loss: 0.0800382
[Epoch 51; Iter   740/ 1097] train: loss: 0.0016727
[Epoch 51; Iter   770/ 1097] train: loss: 0.0228309
[Epoch 51; Iter   800/ 1097] train: loss: 0.0006339
[Epoch 51; Iter   830/ 1097] train: loss: 0.0072577
[Epoch 51; Iter   860/ 1097] train: loss: 0.0166114
[Epoch 51; Iter   890/ 1097] train: loss: 0.0215488
[Epoch 51; Iter   920/ 1097] train: loss: 0.0003432
[Epoch 51; Iter   950/ 1097] train: loss: 0.0031351
[Epoch 51; Iter   980/ 1097] train: loss: 0.0515132
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0219115
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0177255
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0019836
[Epoch 51] ogbg-molhiv: 0.738055 val loss: 0.771066
[Epoch 51] ogbg-molhiv: 0.727067 test loss: 0.440900
[Epoch 52; Iter     3/ 1097] train: loss: 0.0124176
[Epoch 52; Iter    33/ 1097] train: loss: 0.0404835
[Epoch 52; Iter    63/ 1097] train: loss: 0.0023554
[Epoch 52; Iter    93/ 1097] train: loss: 0.0156789
[Epoch 52; Iter   123/ 1097] train: loss: 0.0049067
[Epoch 52; Iter   153/ 1097] train: loss: 0.0060523
[Epoch 52; Iter   183/ 1097] train: loss: 0.0042641
[Epoch 52; Iter   213/ 1097] train: loss: 0.0002685
[Epoch 52; Iter   243/ 1097] train: loss: 0.0036808
[Epoch 52; Iter   273/ 1097] train: loss: 0.0010410
[Epoch 52; Iter   303/ 1097] train: loss: 0.0062147
[Epoch 52; Iter   333/ 1097] train: loss: 0.0145737
[Epoch 52; Iter   363/ 1097] train: loss: 0.0041271
[Epoch 52; Iter   393/ 1097] train: loss: 0.0045505
[Epoch 52; Iter   423/ 1097] train: loss: 0.0003806
[Epoch 52; Iter   453/ 1097] train: loss: 0.0037726
[Epoch 52; Iter   483/ 1097] train: loss: 0.0010502
[Epoch 52; Iter   513/ 1097] train: loss: 0.0005129
[Epoch 52; Iter   543/ 1097] train: loss: 0.0018780
[Epoch 52; Iter   573/ 1097] train: loss: 0.0045772
[Epoch 52; Iter   603/ 1097] train: loss: 0.0542806
[Epoch 52; Iter   633/ 1097] train: loss: 0.0457925
[Epoch 52; Iter   663/ 1097] train: loss: 0.0019092
[Epoch 52; Iter   693/ 1097] train: loss: 0.0073281
[Epoch 52; Iter   723/ 1097] train: loss: 0.0088817
[Epoch 52; Iter   753/ 1097] train: loss: 0.0428028
[Epoch 52; Iter   783/ 1097] train: loss: 0.0310312
[Epoch 52; Iter   813/ 1097] train: loss: 0.0038045
[Epoch 52; Iter   843/ 1097] train: loss: 0.0088436
[Epoch 52; Iter   873/ 1097] train: loss: 0.0056772
[Epoch 52; Iter   903/ 1097] train: loss: 0.0011686
[Epoch 48; Iter   851/ 1097] train: loss: 0.0203981
[Epoch 48; Iter   881/ 1097] train: loss: 0.0060751
[Epoch 48; Iter   911/ 1097] train: loss: 0.0353526
[Epoch 48; Iter   941/ 1097] train: loss: 0.0004864
[Epoch 48; Iter   971/ 1097] train: loss: 0.0005404
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0009166
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0010190
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0012460
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0003157
[Epoch 48] ogbg-molhiv: 0.786663 val loss: 0.198629
[Epoch 48] ogbg-molhiv: 0.711595 test loss: 0.270729
[Epoch 49; Iter    24/ 1097] train: loss: 0.0063518
[Epoch 49; Iter    54/ 1097] train: loss: 0.0038026
[Epoch 49; Iter    84/ 1097] train: loss: 0.0010969
[Epoch 49; Iter   114/ 1097] train: loss: 0.0007324
[Epoch 49; Iter   144/ 1097] train: loss: 0.0019135
[Epoch 49; Iter   174/ 1097] train: loss: 0.0006719
[Epoch 49; Iter   204/ 1097] train: loss: 0.0024384
[Epoch 49; Iter   234/ 1097] train: loss: 0.0017979
[Epoch 49; Iter   264/ 1097] train: loss: 0.0015814
[Epoch 49; Iter   294/ 1097] train: loss: 0.0008002
[Epoch 49; Iter   324/ 1097] train: loss: 0.0001888
[Epoch 49; Iter   354/ 1097] train: loss: 0.0012220
[Epoch 49; Iter   384/ 1097] train: loss: 0.0352495
[Epoch 49; Iter   414/ 1097] train: loss: 0.0002796
[Epoch 49; Iter   444/ 1097] train: loss: 0.0003279
[Epoch 49; Iter   474/ 1097] train: loss: 0.0243045
[Epoch 49; Iter   504/ 1097] train: loss: 0.0004248
[Epoch 49; Iter   534/ 1097] train: loss: 0.0008217
[Epoch 49; Iter   564/ 1097] train: loss: 0.0022573
[Epoch 49; Iter   594/ 1097] train: loss: 0.0141652
[Epoch 49; Iter   624/ 1097] train: loss: 0.0060351
[Epoch 49; Iter   654/ 1097] train: loss: 0.0019270
[Epoch 49; Iter   684/ 1097] train: loss: 0.0001938
[Epoch 49; Iter   714/ 1097] train: loss: 0.0070364
[Epoch 49; Iter   744/ 1097] train: loss: 0.0011273
[Epoch 49; Iter   774/ 1097] train: loss: 0.0320051
[Epoch 49; Iter   804/ 1097] train: loss: 0.0193657
[Epoch 49; Iter   834/ 1097] train: loss: 0.0013340
[Epoch 49; Iter   864/ 1097] train: loss: 0.0065708
[Epoch 49; Iter   894/ 1097] train: loss: 0.0025312
[Epoch 49; Iter   924/ 1097] train: loss: 0.0058277
[Epoch 49; Iter   954/ 1097] train: loss: 0.0123022
[Epoch 49; Iter   984/ 1097] train: loss: 0.0006638
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0007446
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0005904
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0003516
[Epoch 49] ogbg-molhiv: 0.812402 val loss: 0.159111
[Epoch 49] ogbg-molhiv: 0.743659 test loss: 0.286664
[Epoch 50; Iter     7/ 1097] train: loss: 0.0012178
[Epoch 50; Iter    37/ 1097] train: loss: 0.0051102
[Epoch 50; Iter    67/ 1097] train: loss: 0.0895673
[Epoch 50; Iter    97/ 1097] train: loss: 0.0019781
[Epoch 50; Iter   127/ 1097] train: loss: 0.0017757
[Epoch 50; Iter   157/ 1097] train: loss: 0.0016723
[Epoch 50; Iter   187/ 1097] train: loss: 0.0099348
[Epoch 50; Iter   217/ 1097] train: loss: 0.0366179
[Epoch 50; Iter   247/ 1097] train: loss: 0.0020568
[Epoch 50; Iter   277/ 1097] train: loss: 0.0035576
[Epoch 50; Iter   307/ 1097] train: loss: 0.0104485
[Epoch 50; Iter   337/ 1097] train: loss: 0.0112259
[Epoch 50; Iter   367/ 1097] train: loss: 0.0016311
[Epoch 50; Iter   397/ 1097] train: loss: 0.0027088
[Epoch 50; Iter   427/ 1097] train: loss: 0.0001722
[Epoch 50; Iter   457/ 1097] train: loss: 0.0005134
[Epoch 50; Iter   487/ 1097] train: loss: 0.0002492
[Epoch 50; Iter   517/ 1097] train: loss: 0.0062170
[Epoch 50; Iter   547/ 1097] train: loss: 0.0003958
[Epoch 50; Iter   577/ 1097] train: loss: 0.0691874
[Epoch 50; Iter   607/ 1097] train: loss: 0.0391990
[Epoch 50; Iter   637/ 1097] train: loss: 0.0556692
[Epoch 50; Iter   667/ 1097] train: loss: 0.0005970
[Epoch 50; Iter   697/ 1097] train: loss: 0.0049689
[Epoch 50; Iter   727/ 1097] train: loss: 0.0113164
[Epoch 50; Iter   757/ 1097] train: loss: 0.0038087
[Epoch 50; Iter   787/ 1097] train: loss: 0.0006700
[Epoch 50; Iter   817/ 1097] train: loss: 0.0623594
[Epoch 50; Iter   847/ 1097] train: loss: 0.0392050
[Epoch 50; Iter   877/ 1097] train: loss: 0.0009231
[Epoch 50; Iter   907/ 1097] train: loss: 0.0038739
[Epoch 50; Iter   937/ 1097] train: loss: 0.1171181
[Epoch 50; Iter   967/ 1097] train: loss: 0.0251081
[Epoch 50; Iter   997/ 1097] train: loss: 0.0070224
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0192745
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0940813
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0514877
[Epoch 50] ogbg-molhiv: 0.772450 val loss: 0.171223
[Epoch 50] ogbg-molhiv: 0.706895 test loss: 0.307520
[Epoch 51; Iter    20/ 1097] train: loss: 0.0009768
[Epoch 51; Iter    50/ 1097] train: loss: 0.0001710
[Epoch 51; Iter    80/ 1097] train: loss: 0.0002357
[Epoch 51; Iter   110/ 1097] train: loss: 0.0003701
[Epoch 51; Iter   140/ 1097] train: loss: 0.1116370
[Epoch 51; Iter   170/ 1097] train: loss: 0.0085965
[Epoch 51; Iter   200/ 1097] train: loss: 0.0003967
[Epoch 51; Iter   230/ 1097] train: loss: 0.0189894
[Epoch 51; Iter   260/ 1097] train: loss: 0.0007159
[Epoch 51; Iter   290/ 1097] train: loss: 0.0011502
[Epoch 51; Iter   320/ 1097] train: loss: 0.0049641
[Epoch 51; Iter   350/ 1097] train: loss: 0.0182085
[Epoch 51; Iter   380/ 1097] train: loss: 0.0013487
[Epoch 51; Iter   410/ 1097] train: loss: 0.0014019
[Epoch 51; Iter   440/ 1097] train: loss: 0.0047799
[Epoch 51; Iter   470/ 1097] train: loss: 0.0006506
[Epoch 51; Iter   500/ 1097] train: loss: 0.0019994
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004158
[Epoch 51; Iter   560/ 1097] train: loss: 0.0024948
[Epoch 51; Iter   590/ 1097] train: loss: 0.0264221
[Epoch 51; Iter   620/ 1097] train: loss: 0.0175006
[Epoch 51; Iter   650/ 1097] train: loss: 0.0015790
[Epoch 51; Iter   680/ 1097] train: loss: 0.0005979
[Epoch 51; Iter   710/ 1097] train: loss: 0.0067641
[Epoch 51; Iter   740/ 1097] train: loss: 0.0519854
[Epoch 51; Iter   770/ 1097] train: loss: 0.0001906
[Epoch 51; Iter   800/ 1097] train: loss: 0.0003661
[Epoch 51; Iter   830/ 1097] train: loss: 0.0010331
[Epoch 51; Iter   860/ 1097] train: loss: 0.0033677
[Epoch 51; Iter   890/ 1097] train: loss: 0.0003890
[Epoch 51; Iter   920/ 1097] train: loss: 0.0001948
[Epoch 51; Iter   950/ 1097] train: loss: 0.0015496
[Epoch 51; Iter   980/ 1097] train: loss: 0.0044632
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0046869
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0009254
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0005064
[Epoch 51] ogbg-molhiv: 0.768292 val loss: 0.171788
[Epoch 51] ogbg-molhiv: 0.721244 test loss: 0.269345
[Epoch 52; Iter     3/ 1097] train: loss: 0.0031803
[Epoch 52; Iter    33/ 1097] train: loss: 0.0046194
[Epoch 52; Iter    63/ 1097] train: loss: 0.0026250
[Epoch 52; Iter    93/ 1097] train: loss: 0.0014289
[Epoch 52; Iter   123/ 1097] train: loss: 0.0198127
[Epoch 52; Iter   153/ 1097] train: loss: 0.0007302
[Epoch 52; Iter   183/ 1097] train: loss: 0.0012662
[Epoch 52; Iter   213/ 1097] train: loss: 0.0044327
[Epoch 52; Iter   243/ 1097] train: loss: 0.0190165
[Epoch 52; Iter   273/ 1097] train: loss: 0.0007808
[Epoch 52; Iter   303/ 1097] train: loss: 0.0041575
[Epoch 52; Iter   333/ 1097] train: loss: 0.0034092
[Epoch 52; Iter   363/ 1097] train: loss: 0.0381931
[Epoch 52; Iter   393/ 1097] train: loss: 0.0001350
[Epoch 52; Iter   423/ 1097] train: loss: 0.0004954
[Epoch 52; Iter   453/ 1097] train: loss: 0.0003088
[Epoch 52; Iter   483/ 1097] train: loss: 0.0026830
[Epoch 52; Iter   513/ 1097] train: loss: 0.0565657
[Epoch 52; Iter   543/ 1097] train: loss: 0.0001605
[Epoch 52; Iter   573/ 1097] train: loss: 0.0021001
[Epoch 52; Iter   603/ 1097] train: loss: 0.0175585
[Epoch 52; Iter   633/ 1097] train: loss: 0.0076516
[Epoch 52; Iter   663/ 1097] train: loss: 0.0251536
[Epoch 52; Iter   693/ 1097] train: loss: 0.0409206
[Epoch 52; Iter   723/ 1097] train: loss: 0.0018410
[Epoch 52; Iter   753/ 1097] train: loss: 0.0001997
[Epoch 52; Iter   783/ 1097] train: loss: 0.0255715
[Epoch 52; Iter   813/ 1097] train: loss: 0.0034238
[Epoch 52; Iter   843/ 1097] train: loss: 0.0011611
[Epoch 52; Iter   873/ 1097] train: loss: 0.0233529
[Epoch 52; Iter   903/ 1097] train: loss: 0.0056477
[Epoch 48; Iter   851/ 1097] train: loss: 0.0134609
[Epoch 48; Iter   881/ 1097] train: loss: 0.0008573
[Epoch 48; Iter   911/ 1097] train: loss: 0.0030528
[Epoch 48; Iter   941/ 1097] train: loss: 0.0023981
[Epoch 48; Iter   971/ 1097] train: loss: 0.0030757
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0037193
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0025298
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0036371
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0053265
[Epoch 48] ogbg-molhiv: 0.790114 val loss: 0.222947
[Epoch 48] ogbg-molhiv: 0.725089 test loss: 0.379480
[Epoch 49; Iter    24/ 1097] train: loss: 0.0004945
[Epoch 49; Iter    54/ 1097] train: loss: 0.0007983
[Epoch 49; Iter    84/ 1097] train: loss: 0.0009221
[Epoch 49; Iter   114/ 1097] train: loss: 0.0006337
[Epoch 49; Iter   144/ 1097] train: loss: 0.0103320
[Epoch 49; Iter   174/ 1097] train: loss: 0.0026455
[Epoch 49; Iter   204/ 1097] train: loss: 0.0008005
[Epoch 49; Iter   234/ 1097] train: loss: 0.0073154
[Epoch 49; Iter   264/ 1097] train: loss: 0.0602384
[Epoch 49; Iter   294/ 1097] train: loss: 0.0007743
[Epoch 49; Iter   324/ 1097] train: loss: 0.0020005
[Epoch 49; Iter   354/ 1097] train: loss: 0.0295687
[Epoch 49; Iter   384/ 1097] train: loss: 0.0042064
[Epoch 49; Iter   414/ 1097] train: loss: 0.0017867
[Epoch 49; Iter   444/ 1097] train: loss: 0.0042852
[Epoch 49; Iter   474/ 1097] train: loss: 0.0269379
[Epoch 49; Iter   504/ 1097] train: loss: 0.0029954
[Epoch 49; Iter   534/ 1097] train: loss: 0.0038834
[Epoch 49; Iter   564/ 1097] train: loss: 0.0027805
[Epoch 49; Iter   594/ 1097] train: loss: 0.0038121
[Epoch 49; Iter   624/ 1097] train: loss: 0.0080287
[Epoch 49; Iter   654/ 1097] train: loss: 0.0041384
[Epoch 49; Iter   684/ 1097] train: loss: 0.0320177
[Epoch 49; Iter   714/ 1097] train: loss: 0.0157570
[Epoch 49; Iter   744/ 1097] train: loss: 0.0058876
[Epoch 49; Iter   774/ 1097] train: loss: 0.0557282
[Epoch 49; Iter   804/ 1097] train: loss: 0.0044554
[Epoch 49; Iter   834/ 1097] train: loss: 0.0398357
[Epoch 49; Iter   864/ 1097] train: loss: 0.0023527
[Epoch 49; Iter   894/ 1097] train: loss: 0.0009926
[Epoch 49; Iter   924/ 1097] train: loss: 0.0003848
[Epoch 49; Iter   954/ 1097] train: loss: 0.0039912
[Epoch 49; Iter   984/ 1097] train: loss: 0.1438213
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0010552
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0021662
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0004373
[Epoch 49] ogbg-molhiv: 0.788023 val loss: 0.170984
[Epoch 49] ogbg-molhiv: 0.705780 test loss: 0.346510
[Epoch 50; Iter     7/ 1097] train: loss: 0.0842074
[Epoch 50; Iter    37/ 1097] train: loss: 0.0009050
[Epoch 50; Iter    67/ 1097] train: loss: 0.0017514
[Epoch 50; Iter    97/ 1097] train: loss: 0.0038527
[Epoch 50; Iter   127/ 1097] train: loss: 0.0208995
[Epoch 50; Iter   157/ 1097] train: loss: 0.0120942
[Epoch 50; Iter   187/ 1097] train: loss: 0.0007245
[Epoch 50; Iter   217/ 1097] train: loss: 0.0018231
[Epoch 50; Iter   247/ 1097] train: loss: 0.0014796
[Epoch 50; Iter   277/ 1097] train: loss: 0.0022051
[Epoch 50; Iter   307/ 1097] train: loss: 0.0014545
[Epoch 50; Iter   337/ 1097] train: loss: 0.0171737
[Epoch 50; Iter   367/ 1097] train: loss: 0.0100314
[Epoch 50; Iter   397/ 1097] train: loss: 0.0074392
[Epoch 50; Iter   427/ 1097] train: loss: 0.0025663
[Epoch 50; Iter   457/ 1097] train: loss: 0.0486699
[Epoch 50; Iter   487/ 1097] train: loss: 0.0254026
[Epoch 50; Iter   517/ 1097] train: loss: 0.0242546
[Epoch 50; Iter   547/ 1097] train: loss: 0.0200321
[Epoch 50; Iter   577/ 1097] train: loss: 0.0008742
[Epoch 50; Iter   607/ 1097] train: loss: 0.0020932
[Epoch 50; Iter   637/ 1097] train: loss: 0.0003158
[Epoch 50; Iter   667/ 1097] train: loss: 0.0342240
[Epoch 50; Iter   697/ 1097] train: loss: 0.0452100
[Epoch 50; Iter   727/ 1097] train: loss: 0.0758637
[Epoch 50; Iter   757/ 1097] train: loss: 0.0389125
[Epoch 50; Iter   787/ 1097] train: loss: 0.0054481
[Epoch 50; Iter   817/ 1097] train: loss: 0.0119102
[Epoch 50; Iter   847/ 1097] train: loss: 0.0451213
[Epoch 50; Iter   877/ 1097] train: loss: 0.0006439
[Epoch 50; Iter   907/ 1097] train: loss: 0.0102108
[Epoch 50; Iter   937/ 1097] train: loss: 0.0038798
[Epoch 50; Iter   967/ 1097] train: loss: 0.0002123
[Epoch 50; Iter   997/ 1097] train: loss: 0.0473917
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0004956
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0002384
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0013030
[Epoch 50] ogbg-molhiv: 0.796263 val loss: 0.178209
[Epoch 50] ogbg-molhiv: 0.732731 test loss: 0.343553
[Epoch 51; Iter    20/ 1097] train: loss: 0.0100623
[Epoch 51; Iter    50/ 1097] train: loss: 0.0095364
[Epoch 51; Iter    80/ 1097] train: loss: 0.0004477
[Epoch 51; Iter   110/ 1097] train: loss: 0.0025315
[Epoch 51; Iter   140/ 1097] train: loss: 0.0012280
[Epoch 51; Iter   170/ 1097] train: loss: 0.0015999
[Epoch 51; Iter   200/ 1097] train: loss: 0.0198020
[Epoch 51; Iter   230/ 1097] train: loss: 0.0016706
[Epoch 51; Iter   260/ 1097] train: loss: 0.0103049
[Epoch 51; Iter   290/ 1097] train: loss: 0.0077019
[Epoch 51; Iter   320/ 1097] train: loss: 0.0430117
[Epoch 51; Iter   350/ 1097] train: loss: 0.0015020
[Epoch 51; Iter   380/ 1097] train: loss: 0.0005220
[Epoch 51; Iter   410/ 1097] train: loss: 0.0616121
[Epoch 51; Iter   440/ 1097] train: loss: 0.0014750
[Epoch 51; Iter   470/ 1097] train: loss: 0.0164229
[Epoch 51; Iter   500/ 1097] train: loss: 0.0021969
[Epoch 51; Iter   530/ 1097] train: loss: 0.0381100
[Epoch 51; Iter   560/ 1097] train: loss: 0.0004289
[Epoch 51; Iter   590/ 1097] train: loss: 0.0008315
[Epoch 51; Iter   620/ 1097] train: loss: 0.0013752
[Epoch 51; Iter   650/ 1097] train: loss: 0.0076650
[Epoch 51; Iter   680/ 1097] train: loss: 0.0016776
[Epoch 51; Iter   710/ 1097] train: loss: 0.0039333
[Epoch 51; Iter   740/ 1097] train: loss: 0.0025183
[Epoch 51; Iter   770/ 1097] train: loss: 0.0006116
[Epoch 51; Iter   800/ 1097] train: loss: 0.0025984
[Epoch 51; Iter   830/ 1097] train: loss: 0.0054070
[Epoch 51; Iter   860/ 1097] train: loss: 0.0026719
[Epoch 51; Iter   890/ 1097] train: loss: 0.0090151
[Epoch 51; Iter   920/ 1097] train: loss: 0.0010784
[Epoch 51; Iter   950/ 1097] train: loss: 0.0003706
[Epoch 51; Iter   980/ 1097] train: loss: 0.0065318
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0023861
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0023723
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0164187
[Epoch 51] ogbg-molhiv: 0.769936 val loss: 0.318433
[Epoch 51] ogbg-molhiv: 0.694057 test loss: 0.361539
[Epoch 52; Iter     3/ 1097] train: loss: 0.0010156
[Epoch 52; Iter    33/ 1097] train: loss: 0.0221695
[Epoch 52; Iter    63/ 1097] train: loss: 0.0065114
[Epoch 52; Iter    93/ 1097] train: loss: 0.0028056
[Epoch 52; Iter   123/ 1097] train: loss: 0.0010633
[Epoch 52; Iter   153/ 1097] train: loss: 0.0017021
[Epoch 52; Iter   183/ 1097] train: loss: 0.0012839
[Epoch 52; Iter   213/ 1097] train: loss: 0.0264711
[Epoch 52; Iter   243/ 1097] train: loss: 0.0078230
[Epoch 52; Iter   273/ 1097] train: loss: 0.0047333
[Epoch 52; Iter   303/ 1097] train: loss: 0.0175801
[Epoch 52; Iter   333/ 1097] train: loss: 0.0037006
[Epoch 52; Iter   363/ 1097] train: loss: 0.0004737
[Epoch 52; Iter   393/ 1097] train: loss: 0.0159498
[Epoch 52; Iter   423/ 1097] train: loss: 0.0005875
[Epoch 52; Iter   453/ 1097] train: loss: 0.0452642
[Epoch 52; Iter   483/ 1097] train: loss: 0.0021962
[Epoch 52; Iter   513/ 1097] train: loss: 0.0037676
[Epoch 52; Iter   543/ 1097] train: loss: 0.0004201
[Epoch 52; Iter   573/ 1097] train: loss: 0.0023126
[Epoch 52; Iter   603/ 1097] train: loss: 0.0366520
[Epoch 52; Iter   633/ 1097] train: loss: 0.0438942
[Epoch 52; Iter   663/ 1097] train: loss: 0.0329617
[Epoch 52; Iter   693/ 1097] train: loss: 0.0015443
[Epoch 52; Iter   723/ 1097] train: loss: 0.0016861
[Epoch 52; Iter   753/ 1097] train: loss: 0.0172385
[Epoch 52; Iter   783/ 1097] train: loss: 0.0069408
[Epoch 52; Iter   813/ 1097] train: loss: 0.0437164
[Epoch 52; Iter   843/ 1097] train: loss: 0.0278750
[Epoch 52; Iter   873/ 1097] train: loss: 0.0030542
[Epoch 52; Iter   903/ 1097] train: loss: 0.0891820
[Epoch 48; Iter   851/ 1097] train: loss: 0.0004761
[Epoch 48; Iter   881/ 1097] train: loss: 0.0011481
[Epoch 48; Iter   911/ 1097] train: loss: 0.0010833
[Epoch 48; Iter   941/ 1097] train: loss: 0.0035419
[Epoch 48; Iter   971/ 1097] train: loss: 0.0655153
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0017357
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0001403
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0122485
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0276360
[Epoch 48] ogbg-molhiv: 0.806884 val loss: 0.221262
[Epoch 48] ogbg-molhiv: 0.799272 test loss: 0.274008
[Epoch 49; Iter    24/ 1097] train: loss: 0.0109505
[Epoch 49; Iter    54/ 1097] train: loss: 0.0005954
[Epoch 49; Iter    84/ 1097] train: loss: 0.0009616
[Epoch 49; Iter   114/ 1097] train: loss: 0.0017919
[Epoch 49; Iter   144/ 1097] train: loss: 0.0020278
[Epoch 49; Iter   174/ 1097] train: loss: 0.0006536
[Epoch 49; Iter   204/ 1097] train: loss: 0.0421627
[Epoch 49; Iter   234/ 1097] train: loss: 0.0035448
[Epoch 49; Iter   264/ 1097] train: loss: 0.0028381
[Epoch 49; Iter   294/ 1097] train: loss: 0.0094519
[Epoch 49; Iter   324/ 1097] train: loss: 0.0066626
[Epoch 49; Iter   354/ 1097] train: loss: 0.0004510
[Epoch 49; Iter   384/ 1097] train: loss: 0.0037442
[Epoch 49; Iter   414/ 1097] train: loss: 0.0523515
[Epoch 49; Iter   444/ 1097] train: loss: 0.0050232
[Epoch 49; Iter   474/ 1097] train: loss: 0.0125236
[Epoch 49; Iter   504/ 1097] train: loss: 0.0010925
[Epoch 49; Iter   534/ 1097] train: loss: 0.0004046
[Epoch 49; Iter   564/ 1097] train: loss: 0.0009458
[Epoch 49; Iter   594/ 1097] train: loss: 0.0032522
[Epoch 49; Iter   624/ 1097] train: loss: 0.0010405
[Epoch 49; Iter   654/ 1097] train: loss: 0.0112733
[Epoch 49; Iter   684/ 1097] train: loss: 0.0006974
[Epoch 49; Iter   714/ 1097] train: loss: 0.0064587
[Epoch 49; Iter   744/ 1097] train: loss: 0.0002672
[Epoch 49; Iter   774/ 1097] train: loss: 0.0002307
[Epoch 49; Iter   804/ 1097] train: loss: 0.0002893
[Epoch 49; Iter   834/ 1097] train: loss: 0.0057317
[Epoch 49; Iter   864/ 1097] train: loss: 0.0101591
[Epoch 49; Iter   894/ 1097] train: loss: 0.0004210
[Epoch 49; Iter   924/ 1097] train: loss: 0.0023599
[Epoch 49; Iter   954/ 1097] train: loss: 0.0002634
[Epoch 49; Iter   984/ 1097] train: loss: 0.0007695
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0032206
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0026256
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0007049
[Epoch 49] ogbg-molhiv: 0.786464 val loss: 0.230398
[Epoch 49] ogbg-molhiv: 0.789494 test loss: 0.247991
[Epoch 50; Iter     7/ 1097] train: loss: 0.1071099
[Epoch 50; Iter    37/ 1097] train: loss: 0.0011716
[Epoch 50; Iter    67/ 1097] train: loss: 0.0010985
[Epoch 50; Iter    97/ 1097] train: loss: 0.0001815
[Epoch 50; Iter   127/ 1097] train: loss: 0.0022983
[Epoch 50; Iter   157/ 1097] train: loss: 0.0047679
[Epoch 50; Iter   187/ 1097] train: loss: 0.0050492
[Epoch 50; Iter   217/ 1097] train: loss: 0.0007843
[Epoch 50; Iter   247/ 1097] train: loss: 0.0020337
[Epoch 50; Iter   277/ 1097] train: loss: 0.0067613
[Epoch 50; Iter   307/ 1097] train: loss: 0.0009177
[Epoch 50; Iter   337/ 1097] train: loss: 0.0002817
[Epoch 50; Iter   367/ 1097] train: loss: 0.0045198
[Epoch 50; Iter   397/ 1097] train: loss: 0.0009067
[Epoch 50; Iter   427/ 1097] train: loss: 0.0076076
[Epoch 50; Iter   457/ 1097] train: loss: 0.0007775
[Epoch 50; Iter   487/ 1097] train: loss: 0.1227521
[Epoch 50; Iter   517/ 1097] train: loss: 0.0084415
[Epoch 50; Iter   547/ 1097] train: loss: 0.0003363
[Epoch 50; Iter   577/ 1097] train: loss: 0.0067149
[Epoch 50; Iter   607/ 1097] train: loss: 0.0006877
[Epoch 50; Iter   637/ 1097] train: loss: 0.0003348
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002783
[Epoch 50; Iter   697/ 1097] train: loss: 0.0022855
[Epoch 50; Iter   727/ 1097] train: loss: 0.0017735
[Epoch 50; Iter   757/ 1097] train: loss: 0.0003989
[Epoch 50; Iter   787/ 1097] train: loss: 0.0014408
[Epoch 50; Iter   817/ 1097] train: loss: 0.0075077
[Epoch 50; Iter   847/ 1097] train: loss: 0.0009760
[Epoch 50; Iter   877/ 1097] train: loss: 0.0331940
[Epoch 50; Iter   907/ 1097] train: loss: 0.0973158
[Epoch 50; Iter   937/ 1097] train: loss: 0.0003068
[Epoch 50; Iter   967/ 1097] train: loss: 0.0045739
[Epoch 50; Iter   997/ 1097] train: loss: 0.0008157
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0009284
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0002356
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0029019
[Epoch 50] ogbg-molhiv: 0.818912 val loss: 0.272029
[Epoch 50] ogbg-molhiv: 0.797451 test loss: 0.246614
[Epoch 51; Iter    20/ 1097] train: loss: 0.0004938
[Epoch 51; Iter    50/ 1097] train: loss: 0.0007315
[Epoch 51; Iter    80/ 1097] train: loss: 0.0001788
[Epoch 51; Iter   110/ 1097] train: loss: 0.0005679
[Epoch 51; Iter   140/ 1097] train: loss: 0.0114256
[Epoch 51; Iter   170/ 1097] train: loss: 0.0370343
[Epoch 51; Iter   200/ 1097] train: loss: 0.0099211
[Epoch 51; Iter   230/ 1097] train: loss: 0.0030037
[Epoch 51; Iter   260/ 1097] train: loss: 0.0003038
[Epoch 51; Iter   290/ 1097] train: loss: 0.0002347
[Epoch 51; Iter   320/ 1097] train: loss: 0.0016433
[Epoch 51; Iter   350/ 1097] train: loss: 0.0013823
[Epoch 51; Iter   380/ 1097] train: loss: 0.0345247
[Epoch 51; Iter   410/ 1097] train: loss: 0.1661133
[Epoch 51; Iter   440/ 1097] train: loss: 0.0247290
[Epoch 51; Iter   470/ 1097] train: loss: 0.1090484
[Epoch 51; Iter   500/ 1097] train: loss: 0.0005680
[Epoch 51; Iter   530/ 1097] train: loss: 0.0748516
[Epoch 51; Iter   560/ 1097] train: loss: 0.0593069
[Epoch 51; Iter   590/ 1097] train: loss: 0.1047566
[Epoch 51; Iter   620/ 1097] train: loss: 0.0012729
[Epoch 51; Iter   650/ 1097] train: loss: 0.0007589
[Epoch 51; Iter   680/ 1097] train: loss: 0.1048787
[Epoch 51; Iter   710/ 1097] train: loss: 0.0421371
[Epoch 51; Iter   740/ 1097] train: loss: 0.0004153
[Epoch 51; Iter   770/ 1097] train: loss: 0.0039886
[Epoch 51; Iter   800/ 1097] train: loss: 0.0045167
[Epoch 51; Iter   830/ 1097] train: loss: 0.0771132
[Epoch 51; Iter   860/ 1097] train: loss: 0.0008429
[Epoch 51; Iter   890/ 1097] train: loss: 0.0001266
[Epoch 51; Iter   920/ 1097] train: loss: 0.0005027
[Epoch 51; Iter   950/ 1097] train: loss: 0.0010609
[Epoch 51; Iter   980/ 1097] train: loss: 0.0002535
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0122406
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0005811
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0042396
[Epoch 51] ogbg-molhiv: 0.815097 val loss: 0.263454
[Epoch 51] ogbg-molhiv: 0.799706 test loss: 0.246954
[Epoch 52; Iter     3/ 1097] train: loss: 0.0066018
[Epoch 52; Iter    33/ 1097] train: loss: 0.0004927
[Epoch 52; Iter    63/ 1097] train: loss: 0.0132807
[Epoch 52; Iter    93/ 1097] train: loss: 0.0010838
[Epoch 52; Iter   123/ 1097] train: loss: 0.0005259
[Epoch 52; Iter   153/ 1097] train: loss: 0.0006856
[Epoch 52; Iter   183/ 1097] train: loss: 0.0863783
[Epoch 52; Iter   213/ 1097] train: loss: 0.0004299
[Epoch 52; Iter   243/ 1097] train: loss: 0.0007357
[Epoch 52; Iter   273/ 1097] train: loss: 0.0043581
[Epoch 52; Iter   303/ 1097] train: loss: 0.0112621
[Epoch 52; Iter   333/ 1097] train: loss: 0.0001026
[Epoch 52; Iter   363/ 1097] train: loss: 0.0018301
[Epoch 52; Iter   393/ 1097] train: loss: 0.0017615
[Epoch 52; Iter   423/ 1097] train: loss: 0.0492588
[Epoch 52; Iter   453/ 1097] train: loss: 0.0007216
[Epoch 52; Iter   483/ 1097] train: loss: 0.0127532
[Epoch 52; Iter   513/ 1097] train: loss: 0.0491469
[Epoch 52; Iter   543/ 1097] train: loss: 0.0127175
[Epoch 52; Iter   573/ 1097] train: loss: 0.0072275
[Epoch 52; Iter   603/ 1097] train: loss: 0.0080851
[Epoch 52; Iter   633/ 1097] train: loss: 0.0010596
[Epoch 52; Iter   663/ 1097] train: loss: 0.0586627
[Epoch 52; Iter   693/ 1097] train: loss: 0.0223549
[Epoch 52; Iter   723/ 1097] train: loss: 0.0306471
[Epoch 52; Iter   753/ 1097] train: loss: 0.0011707
[Epoch 52; Iter   783/ 1097] train: loss: 0.0482489
[Epoch 52; Iter   813/ 1097] train: loss: 0.0310152
[Epoch 52; Iter   843/ 1097] train: loss: 0.0011865
[Epoch 52; Iter   873/ 1097] train: loss: 0.0018094
[Epoch 52; Iter   903/ 1097] train: loss: 0.0018569
[Epoch 48; Iter   851/ 1097] train: loss: 0.0002661
[Epoch 48; Iter   881/ 1097] train: loss: 0.0023700
[Epoch 48; Iter   911/ 1097] train: loss: 0.0008487
[Epoch 48; Iter   941/ 1097] train: loss: 0.0004133
[Epoch 48; Iter   971/ 1097] train: loss: 0.0000587
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0003192
[Epoch 48; Iter  1031/ 1097] train: loss: 0.1123308
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0000542
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0003108
[Epoch 48] ogbg-molhiv: 0.699350 val loss: 4.587149
[Epoch 48] ogbg-molhiv: 0.605187 test loss: 6.592592
[Epoch 49; Iter    24/ 1097] train: loss: 0.0000863
[Epoch 49; Iter    54/ 1097] train: loss: 0.0003013
[Epoch 49; Iter    84/ 1097] train: loss: 0.0019420
[Epoch 49; Iter   114/ 1097] train: loss: 0.0037129
[Epoch 49; Iter   144/ 1097] train: loss: 0.0002230
[Epoch 49; Iter   174/ 1097] train: loss: 0.0091924
[Epoch 49; Iter   204/ 1097] train: loss: 0.0006149
[Epoch 49; Iter   234/ 1097] train: loss: 0.0002429
[Epoch 49; Iter   264/ 1097] train: loss: 0.0001597
[Epoch 49; Iter   294/ 1097] train: loss: 0.0003378
[Epoch 49; Iter   324/ 1097] train: loss: 0.0017354
[Epoch 49; Iter   354/ 1097] train: loss: 0.0024502
[Epoch 49; Iter   384/ 1097] train: loss: 0.0002147
[Epoch 49; Iter   414/ 1097] train: loss: 0.0015608
[Epoch 49; Iter   444/ 1097] train: loss: 0.0004612
[Epoch 49; Iter   474/ 1097] train: loss: 0.0020511
[Epoch 49; Iter   504/ 1097] train: loss: 0.0001959
[Epoch 49; Iter   534/ 1097] train: loss: 0.0008582
[Epoch 49; Iter   564/ 1097] train: loss: 0.0001066
[Epoch 49; Iter   594/ 1097] train: loss: 0.0005114
[Epoch 49; Iter   624/ 1097] train: loss: 0.0006374
[Epoch 49; Iter   654/ 1097] train: loss: 0.0077368
[Epoch 49; Iter   684/ 1097] train: loss: 0.0059241
[Epoch 49; Iter   714/ 1097] train: loss: 0.0022310
[Epoch 49; Iter   744/ 1097] train: loss: 0.0000264
[Epoch 49; Iter   774/ 1097] train: loss: 0.0077891
[Epoch 49; Iter   804/ 1097] train: loss: 0.0000449
[Epoch 49; Iter   834/ 1097] train: loss: 0.0011221
[Epoch 49; Iter   864/ 1097] train: loss: 0.0012299
[Epoch 49; Iter   894/ 1097] train: loss: 0.0000579
[Epoch 49; Iter   924/ 1097] train: loss: 0.0012145
[Epoch 49; Iter   954/ 1097] train: loss: 0.0007031
[Epoch 49; Iter   984/ 1097] train: loss: 0.0052891
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0003112
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0339920
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0005158
[Epoch 49] ogbg-molhiv: 0.717960 val loss: 2.928363
[Epoch 49] ogbg-molhiv: 0.629195 test loss: 3.863181
[Epoch 50; Iter     7/ 1097] train: loss: 0.0000299
[Epoch 50; Iter    37/ 1097] train: loss: 0.0002711
[Epoch 50; Iter    67/ 1097] train: loss: 0.0045926
[Epoch 50; Iter    97/ 1097] train: loss: 0.0120786
[Epoch 50; Iter   127/ 1097] train: loss: 0.0002600
[Epoch 50; Iter   157/ 1097] train: loss: 0.0004636
[Epoch 50; Iter   187/ 1097] train: loss: 0.0522479
[Epoch 50; Iter   217/ 1097] train: loss: 0.0000549
[Epoch 50; Iter   247/ 1097] train: loss: 0.0002514
[Epoch 50; Iter   277/ 1097] train: loss: 0.0012192
[Epoch 50; Iter   307/ 1097] train: loss: 0.0003380
[Epoch 50; Iter   337/ 1097] train: loss: 0.0001363
[Epoch 50; Iter   367/ 1097] train: loss: 0.0013397
[Epoch 50; Iter   397/ 1097] train: loss: 0.0002855
[Epoch 50; Iter   427/ 1097] train: loss: 0.0003021
[Epoch 50; Iter   457/ 1097] train: loss: 0.0002444
[Epoch 50; Iter   487/ 1097] train: loss: 0.0006865
[Epoch 50; Iter   517/ 1097] train: loss: 0.0002854
[Epoch 50; Iter   547/ 1097] train: loss: 0.0668291
[Epoch 50; Iter   577/ 1097] train: loss: 0.0001748
[Epoch 50; Iter   607/ 1097] train: loss: 0.0005399
[Epoch 50; Iter   637/ 1097] train: loss: 0.0549972
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002135
[Epoch 50; Iter   697/ 1097] train: loss: 0.0002233
[Epoch 50; Iter   727/ 1097] train: loss: 0.0117268
[Epoch 50; Iter   757/ 1097] train: loss: 0.0003496
[Epoch 50; Iter   787/ 1097] train: loss: 0.0002049
[Epoch 50; Iter   817/ 1097] train: loss: 0.0100886
[Epoch 50; Iter   847/ 1097] train: loss: 0.0061001
[Epoch 50; Iter   877/ 1097] train: loss: 0.0050803
[Epoch 50; Iter   907/ 1097] train: loss: 0.0001234
[Epoch 50; Iter   937/ 1097] train: loss: 0.0001003
[Epoch 50; Iter   967/ 1097] train: loss: 0.0004439
[Epoch 50; Iter   997/ 1097] train: loss: 0.0001741
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0009542
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0101722
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0018537
[Epoch 50] ogbg-molhiv: 0.704974 val loss: 3.385139
[Epoch 50] ogbg-molhiv: 0.588198 test loss: 3.405364
[Epoch 51; Iter    20/ 1097] train: loss: 0.0001170
[Epoch 51; Iter    50/ 1097] train: loss: 0.0000903
[Epoch 51; Iter    80/ 1097] train: loss: 0.0000737
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007845
[Epoch 51; Iter   140/ 1097] train: loss: 0.0000718
[Epoch 51; Iter   170/ 1097] train: loss: 0.0046936
[Epoch 51; Iter   200/ 1097] train: loss: 0.0115211
[Epoch 51; Iter   230/ 1097] train: loss: 0.0010666
[Epoch 51; Iter   260/ 1097] train: loss: 0.0005477
[Epoch 51; Iter   290/ 1097] train: loss: 0.0653973
[Epoch 51; Iter   320/ 1097] train: loss: 0.0005934
[Epoch 51; Iter   350/ 1097] train: loss: 0.0001922
[Epoch 51; Iter   380/ 1097] train: loss: 0.0023308
[Epoch 51; Iter   410/ 1097] train: loss: 0.0035160
[Epoch 51; Iter   440/ 1097] train: loss: 0.0004055
[Epoch 51; Iter   470/ 1097] train: loss: 0.0003400
[Epoch 51; Iter   500/ 1097] train: loss: 0.0058843
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004859
[Epoch 51; Iter   560/ 1097] train: loss: 0.0029965
[Epoch 51; Iter   590/ 1097] train: loss: 0.0328920
[Epoch 51; Iter   620/ 1097] train: loss: 0.0001170
[Epoch 51; Iter   650/ 1097] train: loss: 0.0006277
[Epoch 51; Iter   680/ 1097] train: loss: 0.0040841
[Epoch 51; Iter   710/ 1097] train: loss: 0.0007437
[Epoch 51; Iter   740/ 1097] train: loss: 0.0001202
[Epoch 51; Iter   770/ 1097] train: loss: 0.0010281
[Epoch 51; Iter   800/ 1097] train: loss: 0.0002420
[Epoch 51; Iter   830/ 1097] train: loss: 0.0226614
[Epoch 51; Iter   860/ 1097] train: loss: 0.0072455
[Epoch 51; Iter   890/ 1097] train: loss: 0.0008075
[Epoch 51; Iter   920/ 1097] train: loss: 0.0016650
[Epoch 51; Iter   950/ 1097] train: loss: 0.0007179
[Epoch 51; Iter   980/ 1097] train: loss: 0.0006762
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0019585
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0003035
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0387996
[Epoch 51] ogbg-molhiv: 0.739219 val loss: 0.847070
[Epoch 51] ogbg-molhiv: 0.590641 test loss: 1.545429
[Epoch 52; Iter     3/ 1097] train: loss: 0.0001784
[Epoch 52; Iter    33/ 1097] train: loss: 0.0008262
[Epoch 52; Iter    63/ 1097] train: loss: 0.0007639
[Epoch 52; Iter    93/ 1097] train: loss: 0.0002775
[Epoch 52; Iter   123/ 1097] train: loss: 0.0024358
[Epoch 52; Iter   153/ 1097] train: loss: 0.0018901
[Epoch 52; Iter   183/ 1097] train: loss: 0.0073439
[Epoch 52; Iter   213/ 1097] train: loss: 0.0013095
[Epoch 52; Iter   243/ 1097] train: loss: 0.0013523
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002187
[Epoch 52; Iter   303/ 1097] train: loss: 0.0001146
[Epoch 52; Iter   333/ 1097] train: loss: 0.0019653
[Epoch 52; Iter   363/ 1097] train: loss: 0.0000064
[Epoch 52; Iter   393/ 1097] train: loss: 0.0005479
[Epoch 52; Iter   423/ 1097] train: loss: 0.0111710
[Epoch 52; Iter   453/ 1097] train: loss: 0.0005373
[Epoch 52; Iter   483/ 1097] train: loss: 0.0006583
[Epoch 52; Iter   513/ 1097] train: loss: 0.0009004
[Epoch 52; Iter   543/ 1097] train: loss: 0.0011187
[Epoch 52; Iter   573/ 1097] train: loss: 0.0001935
[Epoch 52; Iter   603/ 1097] train: loss: 0.0013689
[Epoch 52; Iter   633/ 1097] train: loss: 0.0031422
[Epoch 52; Iter   663/ 1097] train: loss: 0.0065371
[Epoch 52; Iter   693/ 1097] train: loss: 0.0591054
[Epoch 52; Iter   723/ 1097] train: loss: 0.0014471
[Epoch 52; Iter   753/ 1097] train: loss: 0.0114247
[Epoch 52; Iter   783/ 1097] train: loss: 0.0000977
[Epoch 52; Iter   813/ 1097] train: loss: 0.0659773
[Epoch 52; Iter   843/ 1097] train: loss: 0.0001736
[Epoch 52; Iter   873/ 1097] train: loss: 0.0001309
[Epoch 52; Iter   903/ 1097] train: loss: 0.0042933
[Epoch 40; Iter   687/ 1097] train: loss: 0.0808619
[Epoch 40; Iter   717/ 1097] train: loss: 0.0693599
[Epoch 40; Iter   747/ 1097] train: loss: 0.0670662
[Epoch 40; Iter   777/ 1097] train: loss: 0.1325265
[Epoch 40; Iter   807/ 1097] train: loss: 0.0752326
[Epoch 40; Iter   837/ 1097] train: loss: 0.0137528
[Epoch 40; Iter   867/ 1097] train: loss: 0.0328002
[Epoch 40; Iter   897/ 1097] train: loss: 0.0462498
[Epoch 40; Iter   927/ 1097] train: loss: 0.1365405
[Epoch 40; Iter   957/ 1097] train: loss: 0.2149723
[Epoch 40; Iter   987/ 1097] train: loss: 0.1109597
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0342209
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0143384
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0742930
[Epoch 40] ogbg-molhiv: 0.816888 val loss: 0.077285
[Epoch 40] ogbg-molhiv: 0.737166 test loss: 0.138215
[Epoch 41; Iter    10/ 1097] train: loss: 0.0676724
[Epoch 41; Iter    40/ 1097] train: loss: 0.0759427
[Epoch 41; Iter    70/ 1097] train: loss: 0.0722482
[Epoch 41; Iter   100/ 1097] train: loss: 0.1078370
[Epoch 41; Iter   130/ 1097] train: loss: 0.0707194
[Epoch 41; Iter   160/ 1097] train: loss: 0.1196527
[Epoch 41; Iter   190/ 1097] train: loss: 0.0207504
[Epoch 41; Iter   220/ 1097] train: loss: 0.0245215
[Epoch 41; Iter   250/ 1097] train: loss: 0.2177134
[Epoch 41; Iter   280/ 1097] train: loss: 0.2896635
[Epoch 41; Iter   310/ 1097] train: loss: 0.0093779
[Epoch 41; Iter   340/ 1097] train: loss: 0.2710432
[Epoch 41; Iter   370/ 1097] train: loss: 0.0162757
[Epoch 41; Iter   400/ 1097] train: loss: 0.0218780
[Epoch 41; Iter   430/ 1097] train: loss: 0.0223667
[Epoch 41; Iter   460/ 1097] train: loss: 0.0178509
[Epoch 41; Iter   490/ 1097] train: loss: 0.1480564
[Epoch 41; Iter   520/ 1097] train: loss: 0.0266415
[Epoch 41; Iter   550/ 1097] train: loss: 0.2325768
[Epoch 41; Iter   580/ 1097] train: loss: 0.0135309
[Epoch 41; Iter   610/ 1097] train: loss: 0.1813697
[Epoch 41; Iter   640/ 1097] train: loss: 0.0175326
[Epoch 41; Iter   670/ 1097] train: loss: 0.1866381
[Epoch 41; Iter   700/ 1097] train: loss: 0.0278205
[Epoch 41; Iter   730/ 1097] train: loss: 0.0104896
[Epoch 41; Iter   760/ 1097] train: loss: 0.0949916
[Epoch 41; Iter   790/ 1097] train: loss: 0.0549859
[Epoch 41; Iter   820/ 1097] train: loss: 0.0181176
[Epoch 41; Iter   850/ 1097] train: loss: 0.2997000
[Epoch 41; Iter   880/ 1097] train: loss: 0.0483352
[Epoch 41; Iter   910/ 1097] train: loss: 0.0137895
[Epoch 41; Iter   940/ 1097] train: loss: 0.1266274
[Epoch 41; Iter   970/ 1097] train: loss: 0.0288238
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2324993
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0216885
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0123468
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0689387
[Epoch 41] ogbg-molhiv: 0.819594 val loss: 0.087106
[Epoch 41] ogbg-molhiv: 0.770805 test loss: 0.137715
[Epoch 42; Iter    23/ 1097] train: loss: 0.0098634
[Epoch 42; Iter    53/ 1097] train: loss: 0.0134261
[Epoch 42; Iter    83/ 1097] train: loss: 0.0446528
[Epoch 42; Iter   113/ 1097] train: loss: 0.0260478
[Epoch 42; Iter   143/ 1097] train: loss: 0.0095232
[Epoch 42; Iter   173/ 1097] train: loss: 0.0089918
[Epoch 42; Iter   203/ 1097] train: loss: 0.0211514
[Epoch 42; Iter   233/ 1097] train: loss: 0.0389003
[Epoch 42; Iter   263/ 1097] train: loss: 0.0122568
[Epoch 42; Iter   293/ 1097] train: loss: 0.0380459
[Epoch 42; Iter   323/ 1097] train: loss: 0.2125954
[Epoch 42; Iter   353/ 1097] train: loss: 0.0134479
[Epoch 42; Iter   383/ 1097] train: loss: 0.0601004
[Epoch 42; Iter   413/ 1097] train: loss: 0.1576343
[Epoch 42; Iter   443/ 1097] train: loss: 0.0107980
[Epoch 42; Iter   473/ 1097] train: loss: 0.0501556
[Epoch 42; Iter   503/ 1097] train: loss: 0.1163104
[Epoch 42; Iter   533/ 1097] train: loss: 0.0339114
[Epoch 42; Iter   563/ 1097] train: loss: 0.0108929
[Epoch 42; Iter   593/ 1097] train: loss: 0.0357215
[Epoch 42; Iter   623/ 1097] train: loss: 0.0195256
[Epoch 42; Iter   653/ 1097] train: loss: 0.0704073
[Epoch 42; Iter   683/ 1097] train: loss: 0.0467270
[Epoch 42; Iter   713/ 1097] train: loss: 0.0134246
[Epoch 42; Iter   743/ 1097] train: loss: 0.1375613
[Epoch 42; Iter   773/ 1097] train: loss: 0.0179593
[Epoch 42; Iter   803/ 1097] train: loss: 0.1579271
[Epoch 42; Iter   833/ 1097] train: loss: 0.0129091
[Epoch 42; Iter   863/ 1097] train: loss: 0.0149673
[Epoch 42; Iter   893/ 1097] train: loss: 0.0359739
[Epoch 42; Iter   923/ 1097] train: loss: 0.0315225
[Epoch 42; Iter   953/ 1097] train: loss: 0.0188692
[Epoch 42; Iter   983/ 1097] train: loss: 0.0155273
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1980138
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0458059
[Epoch 42; Iter  1073/ 1097] train: loss: 0.1189456
[Epoch 42] ogbg-molhiv: 0.798412 val loss: 0.086472
[Epoch 42] ogbg-molhiv: 0.741490 test loss: 0.144618
[Epoch 43; Iter     6/ 1097] train: loss: 0.0293780
[Epoch 43; Iter    36/ 1097] train: loss: 0.0614519
[Epoch 43; Iter    66/ 1097] train: loss: 0.2986212
[Epoch 43; Iter    96/ 1097] train: loss: 0.0459513
[Epoch 43; Iter   126/ 1097] train: loss: 0.0197204
[Epoch 43; Iter   156/ 1097] train: loss: 0.0264054
[Epoch 43; Iter   186/ 1097] train: loss: 0.0557167
[Epoch 43; Iter   216/ 1097] train: loss: 0.0154191
[Epoch 43; Iter   246/ 1097] train: loss: 0.0301008
[Epoch 43; Iter   276/ 1097] train: loss: 0.0191704
[Epoch 43; Iter   306/ 1097] train: loss: 0.1666931
[Epoch 43; Iter   336/ 1097] train: loss: 0.0164319
[Epoch 43; Iter   366/ 1097] train: loss: 0.0322037
[Epoch 43; Iter   396/ 1097] train: loss: 0.0298937
[Epoch 43; Iter   426/ 1097] train: loss: 0.0724350
[Epoch 43; Iter   456/ 1097] train: loss: 0.0342456
[Epoch 43; Iter   486/ 1097] train: loss: 0.1778878
[Epoch 43; Iter   516/ 1097] train: loss: 0.2026751
[Epoch 43; Iter   546/ 1097] train: loss: 0.0610574
[Epoch 43; Iter   576/ 1097] train: loss: 0.0223556
[Epoch 43; Iter   606/ 1097] train: loss: 0.1312339
[Epoch 43; Iter   636/ 1097] train: loss: 0.0112653
[Epoch 43; Iter   666/ 1097] train: loss: 0.0110931
[Epoch 43; Iter   696/ 1097] train: loss: 0.0996459
[Epoch 43; Iter   726/ 1097] train: loss: 0.0594982
[Epoch 43; Iter   756/ 1097] train: loss: 0.0124345
[Epoch 43; Iter   786/ 1097] train: loss: 0.0103285
[Epoch 43; Iter   816/ 1097] train: loss: 0.0488917
[Epoch 43; Iter   846/ 1097] train: loss: 0.1079438
[Epoch 43; Iter   876/ 1097] train: loss: 0.1082895
[Epoch 43; Iter   906/ 1097] train: loss: 0.1341781
[Epoch 43; Iter   936/ 1097] train: loss: 0.1956100
[Epoch 43; Iter   966/ 1097] train: loss: 0.2605057
[Epoch 43; Iter   996/ 1097] train: loss: 0.0591056
[Epoch 43; Iter  1026/ 1097] train: loss: 0.1096151
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0141480
[Epoch 43; Iter  1086/ 1097] train: loss: 0.2488896
[Epoch 43] ogbg-molhiv: 0.808642 val loss: 0.097740
[Epoch 43] ogbg-molhiv: 0.740269 test loss: 0.153499
[Epoch 44; Iter    19/ 1097] train: loss: 0.0147807
[Epoch 44; Iter    49/ 1097] train: loss: 0.1158182
[Epoch 44; Iter    79/ 1097] train: loss: 0.0148445
[Epoch 44; Iter   109/ 1097] train: loss: 0.1271449
[Epoch 44; Iter   139/ 1097] train: loss: 0.0077976
[Epoch 44; Iter   169/ 1097] train: loss: 0.0791244
[Epoch 44; Iter   199/ 1097] train: loss: 0.1479550
[Epoch 44; Iter   229/ 1097] train: loss: 0.0928803
[Epoch 44; Iter   259/ 1097] train: loss: 0.0092431
[Epoch 44; Iter   289/ 1097] train: loss: 0.1544710
[Epoch 44; Iter   319/ 1097] train: loss: 0.1494798
[Epoch 44; Iter   349/ 1097] train: loss: 0.0484444
[Epoch 44; Iter   379/ 1097] train: loss: 0.0534609
[Epoch 44; Iter   409/ 1097] train: loss: 0.1080149
[Epoch 44; Iter   439/ 1097] train: loss: 0.0342600
[Epoch 44; Iter   469/ 1097] train: loss: 0.0409435
[Epoch 44; Iter   499/ 1097] train: loss: 0.0177641
[Epoch 44; Iter   529/ 1097] train: loss: 0.0140951
[Epoch 44; Iter   559/ 1097] train: loss: 0.0423747
[Epoch 44; Iter   589/ 1097] train: loss: 0.0413312
[Epoch 44; Iter   619/ 1097] train: loss: 0.0693156
[Epoch 44; Iter   649/ 1097] train: loss: 0.0164400
[Epoch 44; Iter   679/ 1097] train: loss: 0.2478355
[Epoch 44; Iter   709/ 1097] train: loss: 0.0497791
[Epoch 44; Iter   739/ 1097] train: loss: 0.0482366
[Epoch 48; Iter   851/ 1097] train: loss: 0.0021230
[Epoch 48; Iter   881/ 1097] train: loss: 0.0058270
[Epoch 48; Iter   911/ 1097] train: loss: 0.0032472
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015431
[Epoch 48; Iter   971/ 1097] train: loss: 0.0006322
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0029944
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0058725
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0053108
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0024770
[Epoch 48] ogbg-molhiv: 0.778779 val loss: 4.418376
[Epoch 48] ogbg-molhiv: 0.704351 test loss: 4.941884
[Epoch 49; Iter    24/ 1097] train: loss: 0.0087681
[Epoch 49; Iter    54/ 1097] train: loss: 0.0005326
[Epoch 49; Iter    84/ 1097] train: loss: 0.0153693
[Epoch 49; Iter   114/ 1097] train: loss: 0.0006899
[Epoch 49; Iter   144/ 1097] train: loss: 0.0077255
[Epoch 49; Iter   174/ 1097] train: loss: 0.0032910
[Epoch 49; Iter   204/ 1097] train: loss: 0.0067869
[Epoch 49; Iter   234/ 1097] train: loss: 0.0003709
[Epoch 49; Iter   264/ 1097] train: loss: 0.0424611
[Epoch 49; Iter   294/ 1097] train: loss: 0.0003275
[Epoch 49; Iter   324/ 1097] train: loss: 0.0933188
[Epoch 49; Iter   354/ 1097] train: loss: 0.0040088
[Epoch 49; Iter   384/ 1097] train: loss: 0.0161900
[Epoch 49; Iter   414/ 1097] train: loss: 0.0179425
[Epoch 49; Iter   444/ 1097] train: loss: 0.0230651
[Epoch 49; Iter   474/ 1097] train: loss: 0.0072727
[Epoch 49; Iter   504/ 1097] train: loss: 0.0015455
[Epoch 49; Iter   534/ 1097] train: loss: 0.0044531
[Epoch 49; Iter   564/ 1097] train: loss: 0.0005148
[Epoch 49; Iter   594/ 1097] train: loss: 0.0493398
[Epoch 49; Iter   624/ 1097] train: loss: 0.0144646
[Epoch 49; Iter   654/ 1097] train: loss: 0.0235888
[Epoch 49; Iter   684/ 1097] train: loss: 0.0150160
[Epoch 49; Iter   714/ 1097] train: loss: 0.0073531
[Epoch 49; Iter   744/ 1097] train: loss: 0.0034741
[Epoch 49; Iter   774/ 1097] train: loss: 0.0030129
[Epoch 49; Iter   804/ 1097] train: loss: 0.0213950
[Epoch 49; Iter   834/ 1097] train: loss: 0.0244222
[Epoch 49; Iter   864/ 1097] train: loss: 0.0024354
[Epoch 49; Iter   894/ 1097] train: loss: 0.0375521
[Epoch 49; Iter   924/ 1097] train: loss: 0.0016084
[Epoch 49; Iter   954/ 1097] train: loss: 0.1271552
[Epoch 49; Iter   984/ 1097] train: loss: 0.1859924
[Epoch 49; Iter  1014/ 1097] train: loss: 0.1257576
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0162267
[Epoch 49; Iter  1074/ 1097] train: loss: 0.1391846
[Epoch 49] ogbg-molhiv: 0.740499 val loss: 6.164430
[Epoch 49] ogbg-molhiv: 0.715232 test loss: 4.409670
[Epoch 50; Iter     7/ 1097] train: loss: 0.0843112
[Epoch 50; Iter    37/ 1097] train: loss: 0.0422791
[Epoch 50; Iter    67/ 1097] train: loss: 0.0476544
[Epoch 50; Iter    97/ 1097] train: loss: 0.0108950
[Epoch 50; Iter   127/ 1097] train: loss: 0.0057942
[Epoch 50; Iter   157/ 1097] train: loss: 0.0072713
[Epoch 50; Iter   187/ 1097] train: loss: 0.0113105
[Epoch 50; Iter   217/ 1097] train: loss: 0.0218953
[Epoch 50; Iter   247/ 1097] train: loss: 0.0074160
[Epoch 50; Iter   277/ 1097] train: loss: 0.0008386
[Epoch 50; Iter   307/ 1097] train: loss: 0.0029233
[Epoch 50; Iter   337/ 1097] train: loss: 0.0027627
[Epoch 50; Iter   367/ 1097] train: loss: 0.0012774
[Epoch 50; Iter   397/ 1097] train: loss: 0.0028234
[Epoch 50; Iter   427/ 1097] train: loss: 0.0013013
[Epoch 50; Iter   457/ 1097] train: loss: 0.0087182
[Epoch 50; Iter   487/ 1097] train: loss: 0.0668651
[Epoch 50; Iter   517/ 1097] train: loss: 0.0579471
[Epoch 50; Iter   547/ 1097] train: loss: 0.0002981
[Epoch 50; Iter   577/ 1097] train: loss: 0.0031329
[Epoch 50; Iter   607/ 1097] train: loss: 0.0555569
[Epoch 50; Iter   637/ 1097] train: loss: 0.0399288
[Epoch 50; Iter   667/ 1097] train: loss: 0.0167216
[Epoch 50; Iter   697/ 1097] train: loss: 0.0011846
[Epoch 50; Iter   727/ 1097] train: loss: 0.0025037
[Epoch 50; Iter   757/ 1097] train: loss: 0.0065839
[Epoch 50; Iter   787/ 1097] train: loss: 0.0010963
[Epoch 50; Iter   817/ 1097] train: loss: 0.0099313
[Epoch 50; Iter   847/ 1097] train: loss: 0.0265741
[Epoch 50; Iter   877/ 1097] train: loss: 0.0064720
[Epoch 50; Iter   907/ 1097] train: loss: 0.0020336
[Epoch 50; Iter   937/ 1097] train: loss: 0.0000890
[Epoch 50; Iter   967/ 1097] train: loss: 0.0013753
[Epoch 50; Iter   997/ 1097] train: loss: 0.0037501
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0010475
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0010196
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0050142
[Epoch 50] ogbg-molhiv: 0.782414 val loss: 17.592095
[Epoch 50] ogbg-molhiv: 0.686626 test loss: 16.239149
[Epoch 51; Iter    20/ 1097] train: loss: 0.0406094
[Epoch 51; Iter    50/ 1097] train: loss: 0.0109023
[Epoch 51; Iter    80/ 1097] train: loss: 0.0094095
[Epoch 51; Iter   110/ 1097] train: loss: 0.0006680
[Epoch 51; Iter   140/ 1097] train: loss: 0.0031883
[Epoch 51; Iter   170/ 1097] train: loss: 0.0053503
[Epoch 51; Iter   200/ 1097] train: loss: 0.0022489
[Epoch 51; Iter   230/ 1097] train: loss: 0.0689727
[Epoch 51; Iter   260/ 1097] train: loss: 0.0018048
[Epoch 51; Iter   290/ 1097] train: loss: 0.0079310
[Epoch 51; Iter   320/ 1097] train: loss: 0.0219216
[Epoch 51; Iter   350/ 1097] train: loss: 0.0049969
[Epoch 51; Iter   380/ 1097] train: loss: 0.0334202
[Epoch 51; Iter   410/ 1097] train: loss: 0.0042838
[Epoch 51; Iter   440/ 1097] train: loss: 0.0761693
[Epoch 51; Iter   470/ 1097] train: loss: 0.1035695
[Epoch 51; Iter   500/ 1097] train: loss: 0.0066819
[Epoch 51; Iter   530/ 1097] train: loss: 0.0430589
[Epoch 51; Iter   560/ 1097] train: loss: 0.0006360
[Epoch 51; Iter   590/ 1097] train: loss: 0.0053742
[Epoch 51; Iter   620/ 1097] train: loss: 0.0143052
[Epoch 51; Iter   650/ 1097] train: loss: 0.0026095
[Epoch 51; Iter   680/ 1097] train: loss: 0.1642186
[Epoch 51; Iter   710/ 1097] train: loss: 0.0004611
[Epoch 51; Iter   740/ 1097] train: loss: 0.0010798
[Epoch 51; Iter   770/ 1097] train: loss: 0.0169953
[Epoch 51; Iter   800/ 1097] train: loss: 0.0686945
[Epoch 51; Iter   830/ 1097] train: loss: 0.0813818
[Epoch 51; Iter   860/ 1097] train: loss: 0.0554563
[Epoch 51; Iter   890/ 1097] train: loss: 0.0398529
[Epoch 51; Iter   920/ 1097] train: loss: 0.0031680
[Epoch 51; Iter   950/ 1097] train: loss: 0.0223127
[Epoch 51; Iter   980/ 1097] train: loss: 0.0022863
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0274659
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0162968
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0171865
[Epoch 51] ogbg-molhiv: 0.792129 val loss: 11.836799
[Epoch 51] ogbg-molhiv: 0.686483 test loss: 8.035971
[Epoch 52; Iter     3/ 1097] train: loss: 0.0002310
[Epoch 52; Iter    33/ 1097] train: loss: 0.0005966
[Epoch 52; Iter    63/ 1097] train: loss: 0.0026386
[Epoch 52; Iter    93/ 1097] train: loss: 0.0023098
[Epoch 52; Iter   123/ 1097] train: loss: 0.0012379
[Epoch 52; Iter   153/ 1097] train: loss: 0.0012730
[Epoch 52; Iter   183/ 1097] train: loss: 0.0033011
[Epoch 52; Iter   213/ 1097] train: loss: 0.0113777
[Epoch 52; Iter   243/ 1097] train: loss: 0.0015505
[Epoch 52; Iter   273/ 1097] train: loss: 0.0078302
[Epoch 52; Iter   303/ 1097] train: loss: 0.0042114
[Epoch 52; Iter   333/ 1097] train: loss: 0.0001084
[Epoch 52; Iter   363/ 1097] train: loss: 0.0082079
[Epoch 52; Iter   393/ 1097] train: loss: 0.0060047
[Epoch 52; Iter   423/ 1097] train: loss: 0.0063548
[Epoch 52; Iter   453/ 1097] train: loss: 0.0024947
[Epoch 52; Iter   483/ 1097] train: loss: 0.0078720
[Epoch 52; Iter   513/ 1097] train: loss: 0.0156320
[Epoch 52; Iter   543/ 1097] train: loss: 0.0695286
[Epoch 52; Iter   573/ 1097] train: loss: 0.0372202
[Epoch 52; Iter   603/ 1097] train: loss: 0.1069059
[Epoch 52; Iter   633/ 1097] train: loss: 0.0005518
[Epoch 52; Iter   663/ 1097] train: loss: 0.0029256
[Epoch 52; Iter   693/ 1097] train: loss: 0.0008032
[Epoch 52; Iter   723/ 1097] train: loss: 0.0476195
[Epoch 52; Iter   753/ 1097] train: loss: 0.0045849
[Epoch 52; Iter   783/ 1097] train: loss: 0.0040573
[Epoch 52; Iter   813/ 1097] train: loss: 0.0946525
[Epoch 52; Iter   843/ 1097] train: loss: 0.0245637
[Epoch 52; Iter   873/ 1097] train: loss: 0.0020739
[Epoch 52; Iter   903/ 1097] train: loss: 0.0004966
[Epoch 40; Iter   687/ 1097] train: loss: 0.0415528
[Epoch 40; Iter   717/ 1097] train: loss: 0.0076603
[Epoch 40; Iter   747/ 1097] train: loss: 0.0211056
[Epoch 40; Iter   777/ 1097] train: loss: 0.2613224
[Epoch 40; Iter   807/ 1097] train: loss: 0.0145557
[Epoch 40; Iter   837/ 1097] train: loss: 0.0301693
[Epoch 40; Iter   867/ 1097] train: loss: 0.0823626
[Epoch 40; Iter   897/ 1097] train: loss: 0.0635919
[Epoch 40; Iter   927/ 1097] train: loss: 0.2291289
[Epoch 40; Iter   957/ 1097] train: loss: 0.0539131
[Epoch 40; Iter   987/ 1097] train: loss: 0.0145621
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0879032
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0860357
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0214977
[Epoch 40] ogbg-molhiv: 0.803418 val loss: 0.084083
[Epoch 40] ogbg-molhiv: 0.755588 test loss: 0.156080
[Epoch 41; Iter    10/ 1097] train: loss: 0.1055596
[Epoch 41; Iter    40/ 1097] train: loss: 0.2544296
[Epoch 41; Iter    70/ 1097] train: loss: 0.0145666
[Epoch 41; Iter   100/ 1097] train: loss: 0.0143387
[Epoch 41; Iter   130/ 1097] train: loss: 0.0762747
[Epoch 41; Iter   160/ 1097] train: loss: 0.0505378
[Epoch 41; Iter   190/ 1097] train: loss: 0.2568460
[Epoch 41; Iter   220/ 1097] train: loss: 0.2197056
[Epoch 41; Iter   250/ 1097] train: loss: 0.0333702
[Epoch 41; Iter   280/ 1097] train: loss: 0.0351626
[Epoch 41; Iter   310/ 1097] train: loss: 0.1011726
[Epoch 41; Iter   340/ 1097] train: loss: 0.0332548
[Epoch 41; Iter   370/ 1097] train: loss: 0.2371438
[Epoch 41; Iter   400/ 1097] train: loss: 0.0430637
[Epoch 41; Iter   430/ 1097] train: loss: 0.0433115
[Epoch 41; Iter   460/ 1097] train: loss: 0.1084815
[Epoch 41; Iter   490/ 1097] train: loss: 0.5896862
[Epoch 41; Iter   520/ 1097] train: loss: 0.1037524
[Epoch 41; Iter   550/ 1097] train: loss: 0.0282197
[Epoch 41; Iter   580/ 1097] train: loss: 0.0914261
[Epoch 41; Iter   610/ 1097] train: loss: 0.1124146
[Epoch 41; Iter   640/ 1097] train: loss: 0.0158837
[Epoch 41; Iter   670/ 1097] train: loss: 0.0151815
[Epoch 41; Iter   700/ 1097] train: loss: 0.0960123
[Epoch 41; Iter   730/ 1097] train: loss: 0.0164629
[Epoch 41; Iter   760/ 1097] train: loss: 0.0665213
[Epoch 41; Iter   790/ 1097] train: loss: 0.0556685
[Epoch 41; Iter   820/ 1097] train: loss: 0.0205559
[Epoch 41; Iter   850/ 1097] train: loss: 0.0186894
[Epoch 41; Iter   880/ 1097] train: loss: 0.0236783
[Epoch 41; Iter   910/ 1097] train: loss: 0.1144899
[Epoch 41; Iter   940/ 1097] train: loss: 0.0408913
[Epoch 41; Iter   970/ 1097] train: loss: 0.2297713
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2290442
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0357317
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0428749
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0883905
[Epoch 41] ogbg-molhiv: 0.818746 val loss: 0.079381
[Epoch 41] ogbg-molhiv: 0.748203 test loss: 0.157932
[Epoch 42; Iter    23/ 1097] train: loss: 0.0119974
[Epoch 42; Iter    53/ 1097] train: loss: 0.0288506
[Epoch 42; Iter    83/ 1097] train: loss: 0.1504862
[Epoch 42; Iter   113/ 1097] train: loss: 0.0286440
[Epoch 42; Iter   143/ 1097] train: loss: 0.1230987
[Epoch 42; Iter   173/ 1097] train: loss: 0.0379525
[Epoch 42; Iter   203/ 1097] train: loss: 0.0221660
[Epoch 42; Iter   233/ 1097] train: loss: 0.0246418
[Epoch 42; Iter   263/ 1097] train: loss: 0.0807485
[Epoch 42; Iter   293/ 1097] train: loss: 0.0393689
[Epoch 42; Iter   323/ 1097] train: loss: 0.1490833
[Epoch 42; Iter   353/ 1097] train: loss: 0.0133971
[Epoch 42; Iter   383/ 1097] train: loss: 0.1445475
[Epoch 42; Iter   413/ 1097] train: loss: 0.1457133
[Epoch 42; Iter   443/ 1097] train: loss: 0.0287378
[Epoch 42; Iter   473/ 1097] train: loss: 0.1487259
[Epoch 42; Iter   503/ 1097] train: loss: 0.0750417
[Epoch 42; Iter   533/ 1097] train: loss: 0.0450299
[Epoch 42; Iter   563/ 1097] train: loss: 0.0410505
[Epoch 42; Iter   593/ 1097] train: loss: 0.0206686
[Epoch 42; Iter   623/ 1097] train: loss: 0.0101218
[Epoch 42; Iter   653/ 1097] train: loss: 0.2591351
[Epoch 42; Iter   683/ 1097] train: loss: 0.0164815
[Epoch 42; Iter   713/ 1097] train: loss: 0.0566988
[Epoch 42; Iter   743/ 1097] train: loss: 0.0533098
[Epoch 42; Iter   773/ 1097] train: loss: 0.0499495
[Epoch 42; Iter   803/ 1097] train: loss: 0.0255693
[Epoch 42; Iter   833/ 1097] train: loss: 0.0203432
[Epoch 42; Iter   863/ 1097] train: loss: 0.0203500
[Epoch 42; Iter   893/ 1097] train: loss: 0.0532161
[Epoch 42; Iter   923/ 1097] train: loss: 0.2192865
[Epoch 42; Iter   953/ 1097] train: loss: 0.0087424
[Epoch 42; Iter   983/ 1097] train: loss: 0.0138455
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1111556
[Epoch 42; Iter  1043/ 1097] train: loss: 0.2353475
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0192574
[Epoch 42] ogbg-molhiv: 0.783501 val loss: 0.088224
[Epoch 42] ogbg-molhiv: 0.737840 test loss: 0.189696
[Epoch 43; Iter     6/ 1097] train: loss: 0.1482050
[Epoch 43; Iter    36/ 1097] train: loss: 0.0111595
[Epoch 43; Iter    66/ 1097] train: loss: 0.2219925
[Epoch 43; Iter    96/ 1097] train: loss: 0.0510612
[Epoch 43; Iter   126/ 1097] train: loss: 0.0871503
[Epoch 43; Iter   156/ 1097] train: loss: 0.1859501
[Epoch 43; Iter   186/ 1097] train: loss: 0.0785140
[Epoch 43; Iter   216/ 1097] train: loss: 0.0475862
[Epoch 43; Iter   246/ 1097] train: loss: 0.0484330
[Epoch 43; Iter   276/ 1097] train: loss: 0.3255461
[Epoch 43; Iter   306/ 1097] train: loss: 0.0090147
[Epoch 43; Iter   336/ 1097] train: loss: 0.1388184
[Epoch 43; Iter   366/ 1097] train: loss: 0.0227842
[Epoch 43; Iter   396/ 1097] train: loss: 0.0148467
[Epoch 43; Iter   426/ 1097] train: loss: 0.0546529
[Epoch 43; Iter   456/ 1097] train: loss: 0.1346550
[Epoch 43; Iter   486/ 1097] train: loss: 0.0467381
[Epoch 43; Iter   516/ 1097] train: loss: 0.0589655
[Epoch 43; Iter   546/ 1097] train: loss: 0.0118857
[Epoch 43; Iter   576/ 1097] train: loss: 0.2851824
[Epoch 43; Iter   606/ 1097] train: loss: 0.0304911
[Epoch 43; Iter   636/ 1097] train: loss: 0.0370201
[Epoch 43; Iter   666/ 1097] train: loss: 0.0125290
[Epoch 43; Iter   696/ 1097] train: loss: 0.2664056
[Epoch 43; Iter   726/ 1097] train: loss: 0.0511293
[Epoch 43; Iter   756/ 1097] train: loss: 0.0703626
[Epoch 43; Iter   786/ 1097] train: loss: 0.0202115
[Epoch 43; Iter   816/ 1097] train: loss: 0.0166882
[Epoch 43; Iter   846/ 1097] train: loss: 0.0545939
[Epoch 43; Iter   876/ 1097] train: loss: 0.0221042
[Epoch 43; Iter   906/ 1097] train: loss: 0.1123210
[Epoch 43; Iter   936/ 1097] train: loss: 0.0244887
[Epoch 43; Iter   966/ 1097] train: loss: 0.0479635
[Epoch 43; Iter   996/ 1097] train: loss: 0.0567128
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0228348
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1086540
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0184341
[Epoch 43] ogbg-molhiv: 0.813143 val loss: 0.080257
[Epoch 43] ogbg-molhiv: 0.767502 test loss: 0.142306
[Epoch 44; Iter    19/ 1097] train: loss: 0.0599339
[Epoch 44; Iter    49/ 1097] train: loss: 0.0106619
[Epoch 44; Iter    79/ 1097] train: loss: 0.0650093
[Epoch 44; Iter   109/ 1097] train: loss: 0.0370567
[Epoch 44; Iter   139/ 1097] train: loss: 0.0202352
[Epoch 44; Iter   169/ 1097] train: loss: 0.1123230
[Epoch 44; Iter   199/ 1097] train: loss: 0.0062156
[Epoch 44; Iter   229/ 1097] train: loss: 0.0880462
[Epoch 44; Iter   259/ 1097] train: loss: 0.0759802
[Epoch 44; Iter   289/ 1097] train: loss: 0.0241450
[Epoch 44; Iter   319/ 1097] train: loss: 0.0098423
[Epoch 44; Iter   349/ 1097] train: loss: 0.0496711
[Epoch 44; Iter   379/ 1097] train: loss: 0.0120190
[Epoch 44; Iter   409/ 1097] train: loss: 0.0193779
[Epoch 44; Iter   439/ 1097] train: loss: 0.0398518
[Epoch 44; Iter   469/ 1097] train: loss: 0.1741194
[Epoch 44; Iter   499/ 1097] train: loss: 0.0927242
[Epoch 44; Iter   529/ 1097] train: loss: 0.0677481
[Epoch 44; Iter   559/ 1097] train: loss: 0.1170463
[Epoch 44; Iter   589/ 1097] train: loss: 0.0967247
[Epoch 44; Iter   619/ 1097] train: loss: 0.0191206
[Epoch 44; Iter   649/ 1097] train: loss: 0.0243956
[Epoch 44; Iter   679/ 1097] train: loss: 0.2258555
[Epoch 44; Iter   709/ 1097] train: loss: 0.0110342
[Epoch 44; Iter   739/ 1097] train: loss: 0.0303160
[Epoch 40; Iter   687/ 1097] train: loss: 0.0130596
[Epoch 40; Iter   717/ 1097] train: loss: 0.1069354
[Epoch 40; Iter   747/ 1097] train: loss: 0.0641289
[Epoch 40; Iter   777/ 1097] train: loss: 0.0197013
[Epoch 40; Iter   807/ 1097] train: loss: 0.1102952
[Epoch 40; Iter   837/ 1097] train: loss: 0.0481654
[Epoch 40; Iter   867/ 1097] train: loss: 0.0509889
[Epoch 40; Iter   897/ 1097] train: loss: 0.0333206
[Epoch 40; Iter   927/ 1097] train: loss: 0.1462454
[Epoch 40; Iter   957/ 1097] train: loss: 0.1999992
[Epoch 40; Iter   987/ 1097] train: loss: 0.0339882
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0747102
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0451268
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0352875
[Epoch 40] ogbg-molhiv: 0.829111 val loss: 0.075109
[Epoch 40] ogbg-molhiv: 0.749889 test loss: 0.131606
[Epoch 41; Iter    10/ 1097] train: loss: 0.0954928
[Epoch 41; Iter    40/ 1097] train: loss: 0.0196972
[Epoch 41; Iter    70/ 1097] train: loss: 0.0094032
[Epoch 41; Iter   100/ 1097] train: loss: 0.0181502
[Epoch 41; Iter   130/ 1097] train: loss: 0.0534785
[Epoch 41; Iter   160/ 1097] train: loss: 0.0360724
[Epoch 41; Iter   190/ 1097] train: loss: 0.0391028
[Epoch 41; Iter   220/ 1097] train: loss: 0.0101007
[Epoch 41; Iter   250/ 1097] train: loss: 0.0557673
[Epoch 41; Iter   280/ 1097] train: loss: 0.0787777
[Epoch 41; Iter   310/ 1097] train: loss: 0.2073347
[Epoch 41; Iter   340/ 1097] train: loss: 0.2130984
[Epoch 41; Iter   370/ 1097] train: loss: 0.0128912
[Epoch 41; Iter   400/ 1097] train: loss: 0.0108458
[Epoch 41; Iter   430/ 1097] train: loss: 0.0203108
[Epoch 41; Iter   460/ 1097] train: loss: 0.0745554
[Epoch 41; Iter   490/ 1097] train: loss: 0.3443233
[Epoch 41; Iter   520/ 1097] train: loss: 0.1169426
[Epoch 41; Iter   550/ 1097] train: loss: 0.0180893
[Epoch 41; Iter   580/ 1097] train: loss: 0.1905924
[Epoch 41; Iter   610/ 1097] train: loss: 0.0165084
[Epoch 41; Iter   640/ 1097] train: loss: 0.2498351
[Epoch 41; Iter   670/ 1097] train: loss: 0.0978398
[Epoch 41; Iter   700/ 1097] train: loss: 0.0170414
[Epoch 41; Iter   730/ 1097] train: loss: 0.0205373
[Epoch 41; Iter   760/ 1097] train: loss: 0.0690459
[Epoch 41; Iter   790/ 1097] train: loss: 0.0983108
[Epoch 41; Iter   820/ 1097] train: loss: 0.0745449
[Epoch 41; Iter   850/ 1097] train: loss: 0.0519803
[Epoch 41; Iter   880/ 1097] train: loss: 0.0694908
[Epoch 41; Iter   910/ 1097] train: loss: 0.0613102
[Epoch 41; Iter   940/ 1097] train: loss: 0.0111775
[Epoch 41; Iter   970/ 1097] train: loss: 0.2316813
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0194669
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1117621
[Epoch 41; Iter  1060/ 1097] train: loss: 0.1621499
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1306845
[Epoch 41] ogbg-molhiv: 0.831793 val loss: 0.091033
[Epoch 41] ogbg-molhiv: 0.773120 test loss: 0.138054
[Epoch 42; Iter    23/ 1097] train: loss: 0.0929115
[Epoch 42; Iter    53/ 1097] train: loss: 0.1196661
[Epoch 42; Iter    83/ 1097] train: loss: 0.0479521
[Epoch 42; Iter   113/ 1097] train: loss: 0.0311482
[Epoch 42; Iter   143/ 1097] train: loss: 0.0158561
[Epoch 42; Iter   173/ 1097] train: loss: 0.0387366
[Epoch 42; Iter   203/ 1097] train: loss: 0.1409229
[Epoch 42; Iter   233/ 1097] train: loss: 0.1494912
[Epoch 42; Iter   263/ 1097] train: loss: 0.1156109
[Epoch 42; Iter   293/ 1097] train: loss: 0.1179565
[Epoch 42; Iter   323/ 1097] train: loss: 0.0584200
[Epoch 42; Iter   353/ 1097] train: loss: 0.0601764
[Epoch 42; Iter   383/ 1097] train: loss: 0.1321388
[Epoch 42; Iter   413/ 1097] train: loss: 0.0441333
[Epoch 42; Iter   443/ 1097] train: loss: 0.2933801
[Epoch 42; Iter   473/ 1097] train: loss: 0.0290574
[Epoch 42; Iter   503/ 1097] train: loss: 0.2079264
[Epoch 42; Iter   533/ 1097] train: loss: 0.1230721
[Epoch 42; Iter   563/ 1097] train: loss: 0.0216372
[Epoch 42; Iter   593/ 1097] train: loss: 0.0366630
[Epoch 42; Iter   623/ 1097] train: loss: 0.0420399
[Epoch 42; Iter   653/ 1097] train: loss: 0.1928781
[Epoch 42; Iter   683/ 1097] train: loss: 0.1763519
[Epoch 42; Iter   713/ 1097] train: loss: 0.0081712
[Epoch 42; Iter   743/ 1097] train: loss: 0.0759214
[Epoch 42; Iter   773/ 1097] train: loss: 0.2886717
[Epoch 42; Iter   803/ 1097] train: loss: 0.1221767
[Epoch 42; Iter   833/ 1097] train: loss: 0.0283842
[Epoch 42; Iter   863/ 1097] train: loss: 0.1027048
[Epoch 42; Iter   893/ 1097] train: loss: 0.1565685
[Epoch 42; Iter   923/ 1097] train: loss: 0.0366579
[Epoch 42; Iter   953/ 1097] train: loss: 0.1052875
[Epoch 42; Iter   983/ 1097] train: loss: 0.0188690
[Epoch 42; Iter  1013/ 1097] train: loss: 0.2721402
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1263507
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0175330
[Epoch 42] ogbg-molhiv: 0.837305 val loss: 0.074911
[Epoch 42] ogbg-molhiv: 0.777692 test loss: 0.130920
[Epoch 43; Iter     6/ 1097] train: loss: 0.1378729
[Epoch 43; Iter    36/ 1097] train: loss: 0.0568374
[Epoch 43; Iter    66/ 1097] train: loss: 0.1758462
[Epoch 43; Iter    96/ 1097] train: loss: 0.1599992
[Epoch 43; Iter   126/ 1097] train: loss: 0.0499493
[Epoch 43; Iter   156/ 1097] train: loss: 0.0246782
[Epoch 43; Iter   186/ 1097] train: loss: 0.2295657
[Epoch 43; Iter   216/ 1097] train: loss: 0.1463557
[Epoch 43; Iter   246/ 1097] train: loss: 0.2572462
[Epoch 43; Iter   276/ 1097] train: loss: 0.0216314
[Epoch 43; Iter   306/ 1097] train: loss: 0.0789973
[Epoch 43; Iter   336/ 1097] train: loss: 0.0215312
[Epoch 43; Iter   366/ 1097] train: loss: 0.0278420
[Epoch 43; Iter   396/ 1097] train: loss: 0.1276442
[Epoch 43; Iter   426/ 1097] train: loss: 0.0442255
[Epoch 43; Iter   456/ 1097] train: loss: 0.1127745
[Epoch 43; Iter   486/ 1097] train: loss: 0.0240509
[Epoch 43; Iter   516/ 1097] train: loss: 0.0138147
[Epoch 43; Iter   546/ 1097] train: loss: 0.0598967
[Epoch 43; Iter   576/ 1097] train: loss: 0.1826302
[Epoch 43; Iter   606/ 1097] train: loss: 0.1051801
[Epoch 43; Iter   636/ 1097] train: loss: 0.0263988
[Epoch 43; Iter   666/ 1097] train: loss: 0.0612881
[Epoch 43; Iter   696/ 1097] train: loss: 0.1196853
[Epoch 43; Iter   726/ 1097] train: loss: 0.0213013
[Epoch 43; Iter   756/ 1097] train: loss: 0.3054915
[Epoch 43; Iter   786/ 1097] train: loss: 0.0288346
[Epoch 43; Iter   816/ 1097] train: loss: 0.0121908
[Epoch 43; Iter   846/ 1097] train: loss: 0.0210840
[Epoch 43; Iter   876/ 1097] train: loss: 0.0818616
[Epoch 43; Iter   906/ 1097] train: loss: 0.0379657
[Epoch 43; Iter   936/ 1097] train: loss: 0.0302783
[Epoch 43; Iter   966/ 1097] train: loss: 0.0178661
[Epoch 43; Iter   996/ 1097] train: loss: 0.0173183
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0361661
[Epoch 43; Iter  1056/ 1097] train: loss: 0.2283701
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0233719
[Epoch 43] ogbg-molhiv: 0.821331 val loss: 0.075240
[Epoch 43] ogbg-molhiv: 0.741279 test loss: 0.142361
[Epoch 44; Iter    19/ 1097] train: loss: 0.0182873
[Epoch 44; Iter    49/ 1097] train: loss: 0.0146764
[Epoch 44; Iter    79/ 1097] train: loss: 0.1187200
[Epoch 44; Iter   109/ 1097] train: loss: 0.0378958
[Epoch 44; Iter   139/ 1097] train: loss: 0.0632560
[Epoch 44; Iter   169/ 1097] train: loss: 0.0197845
[Epoch 44; Iter   199/ 1097] train: loss: 0.0467730
[Epoch 44; Iter   229/ 1097] train: loss: 0.0200954
[Epoch 44; Iter   259/ 1097] train: loss: 0.0091252
[Epoch 44; Iter   289/ 1097] train: loss: 0.0198331
[Epoch 44; Iter   319/ 1097] train: loss: 0.2517519
[Epoch 44; Iter   349/ 1097] train: loss: 0.2805249
[Epoch 44; Iter   379/ 1097] train: loss: 0.0128282
[Epoch 44; Iter   409/ 1097] train: loss: 0.1966026
[Epoch 44; Iter   439/ 1097] train: loss: 0.0222842
[Epoch 44; Iter   469/ 1097] train: loss: 0.1776231
[Epoch 44; Iter   499/ 1097] train: loss: 0.0342918
[Epoch 44; Iter   529/ 1097] train: loss: 0.1143042
[Epoch 44; Iter   559/ 1097] train: loss: 0.0165232
[Epoch 44; Iter   589/ 1097] train: loss: 0.0553877
[Epoch 44; Iter   619/ 1097] train: loss: 0.0267845
[Epoch 44; Iter   649/ 1097] train: loss: 0.0946852
[Epoch 44; Iter   679/ 1097] train: loss: 0.1969192
[Epoch 44; Iter   709/ 1097] train: loss: 0.1385343
[Epoch 44; Iter   739/ 1097] train: loss: 0.0188612
[Epoch 48; Iter   851/ 1097] train: loss: 0.0002877
[Epoch 48; Iter   881/ 1097] train: loss: 0.0597648
[Epoch 48; Iter   911/ 1097] train: loss: 0.0014452
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015439
[Epoch 48; Iter   971/ 1097] train: loss: 0.0005341
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0007899
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0012910
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0005441
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0014284
[Epoch 48] ogbg-molhiv: 0.720113 val loss: 1.175724
[Epoch 48] ogbg-molhiv: 0.658186 test loss: 0.668772
[Epoch 49; Iter    24/ 1097] train: loss: 0.0000863
[Epoch 49; Iter    54/ 1097] train: loss: 0.0022135
[Epoch 49; Iter    84/ 1097] train: loss: 0.0006958
[Epoch 49; Iter   114/ 1097] train: loss: 0.0021945
[Epoch 49; Iter   144/ 1097] train: loss: 0.0001576
[Epoch 49; Iter   174/ 1097] train: loss: 0.0004746
[Epoch 49; Iter   204/ 1097] train: loss: 0.0001885
[Epoch 49; Iter   234/ 1097] train: loss: 0.0028014
[Epoch 49; Iter   264/ 1097] train: loss: 0.0002825
[Epoch 49; Iter   294/ 1097] train: loss: 0.0000483
[Epoch 49; Iter   324/ 1097] train: loss: 0.0000833
[Epoch 49; Iter   354/ 1097] train: loss: 0.0013838
[Epoch 49; Iter   384/ 1097] train: loss: 0.0006284
[Epoch 49; Iter   414/ 1097] train: loss: 0.0355857
[Epoch 49; Iter   444/ 1097] train: loss: 0.0001013
[Epoch 49; Iter   474/ 1097] train: loss: 0.0001206
[Epoch 49; Iter   504/ 1097] train: loss: 0.0092124
[Epoch 49; Iter   534/ 1097] train: loss: 0.0019697
[Epoch 49; Iter   564/ 1097] train: loss: 0.0323092
[Epoch 49; Iter   594/ 1097] train: loss: 0.0002443
[Epoch 49; Iter   624/ 1097] train: loss: 0.0151819
[Epoch 49; Iter   654/ 1097] train: loss: 0.0002546
[Epoch 49; Iter   684/ 1097] train: loss: 0.0029125
[Epoch 49; Iter   714/ 1097] train: loss: 0.0023291
[Epoch 49; Iter   744/ 1097] train: loss: 0.0049612
[Epoch 49; Iter   774/ 1097] train: loss: 0.0028290
[Epoch 49; Iter   804/ 1097] train: loss: 0.0030558
[Epoch 49; Iter   834/ 1097] train: loss: 0.0068372
[Epoch 49; Iter   864/ 1097] train: loss: 0.0002632
[Epoch 49; Iter   894/ 1097] train: loss: 0.0018998
[Epoch 49; Iter   924/ 1097] train: loss: 0.0003371
[Epoch 49; Iter   954/ 1097] train: loss: 0.0071995
[Epoch 49; Iter   984/ 1097] train: loss: 0.0083472
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0017734
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0006971
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0001597
[Epoch 49] ogbg-molhiv: 0.746454 val loss: 2.472744
[Epoch 49] ogbg-molhiv: 0.669999 test loss: 1.723971
[Epoch 50; Iter     7/ 1097] train: loss: 0.0873026
[Epoch 50; Iter    37/ 1097] train: loss: 0.0002201
[Epoch 50; Iter    67/ 1097] train: loss: 0.0000747
[Epoch 50; Iter    97/ 1097] train: loss: 0.0058002
[Epoch 50; Iter   127/ 1097] train: loss: 0.0003567
[Epoch 50; Iter   157/ 1097] train: loss: 0.0010718
[Epoch 50; Iter   187/ 1097] train: loss: 0.0008887
[Epoch 50; Iter   217/ 1097] train: loss: 0.0002297
[Epoch 50; Iter   247/ 1097] train: loss: 0.0290657
[Epoch 50; Iter   277/ 1097] train: loss: 0.0386963
[Epoch 50; Iter   307/ 1097] train: loss: 0.0001062
[Epoch 50; Iter   337/ 1097] train: loss: 0.0244144
[Epoch 50; Iter   367/ 1097] train: loss: 0.0001631
[Epoch 50; Iter   397/ 1097] train: loss: 0.0000646
[Epoch 50; Iter   427/ 1097] train: loss: 0.0339828
[Epoch 50; Iter   457/ 1097] train: loss: 0.0004206
[Epoch 50; Iter   487/ 1097] train: loss: 0.0050216
[Epoch 50; Iter   517/ 1097] train: loss: 0.0009805
[Epoch 50; Iter   547/ 1097] train: loss: 0.0377361
[Epoch 50; Iter   577/ 1097] train: loss: 0.0023607
[Epoch 50; Iter   607/ 1097] train: loss: 0.0001554
[Epoch 50; Iter   637/ 1097] train: loss: 0.0001004
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002262
[Epoch 50; Iter   697/ 1097] train: loss: 0.0170203
[Epoch 50; Iter   727/ 1097] train: loss: 0.0019601
[Epoch 50; Iter   757/ 1097] train: loss: 0.0243973
[Epoch 50; Iter   787/ 1097] train: loss: 0.0004660
[Epoch 50; Iter   817/ 1097] train: loss: 0.0013129
[Epoch 50; Iter   847/ 1097] train: loss: 0.0010075
[Epoch 50; Iter   877/ 1097] train: loss: 0.0028716
[Epoch 50; Iter   907/ 1097] train: loss: 0.0054191
[Epoch 50; Iter   937/ 1097] train: loss: 0.0870969
[Epoch 50; Iter   967/ 1097] train: loss: 0.0001241
[Epoch 50; Iter   997/ 1097] train: loss: 0.0023166
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0006683
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0092467
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0009061
[Epoch 50] ogbg-molhiv: 0.585345 val loss: 131.764413
[Epoch 50] ogbg-molhiv: 0.555389 test loss: 123.329884
[Epoch 51; Iter    20/ 1097] train: loss: 0.0001489
[Epoch 51; Iter    50/ 1097] train: loss: 0.0015811
[Epoch 51; Iter    80/ 1097] train: loss: 0.0001991
[Epoch 51; Iter   110/ 1097] train: loss: 0.0002991
[Epoch 51; Iter   140/ 1097] train: loss: 0.0141803
[Epoch 51; Iter   170/ 1097] train: loss: 0.0002761
[Epoch 51; Iter   200/ 1097] train: loss: 0.0045032
[Epoch 51; Iter   230/ 1097] train: loss: 0.0008090
[Epoch 51; Iter   260/ 1097] train: loss: 0.0009842
[Epoch 51; Iter   290/ 1097] train: loss: 0.0552974
[Epoch 51; Iter   320/ 1097] train: loss: 0.0055389
[Epoch 51; Iter   350/ 1097] train: loss: 0.0117080
[Epoch 51; Iter   380/ 1097] train: loss: 0.0002596
[Epoch 51; Iter   410/ 1097] train: loss: 0.0039367
[Epoch 51; Iter   440/ 1097] train: loss: 0.0008029
[Epoch 51; Iter   470/ 1097] train: loss: 0.0715559
[Epoch 51; Iter   500/ 1097] train: loss: 0.0002704
[Epoch 51; Iter   530/ 1097] train: loss: 0.0005535
[Epoch 51; Iter   560/ 1097] train: loss: 0.0001637
[Epoch 51; Iter   590/ 1097] train: loss: 0.0000440
[Epoch 51; Iter   620/ 1097] train: loss: 0.0002245
[Epoch 51; Iter   650/ 1097] train: loss: 0.0042012
[Epoch 51; Iter   680/ 1097] train: loss: 0.0000346
[Epoch 51; Iter   710/ 1097] train: loss: 0.0012009
[Epoch 51; Iter   740/ 1097] train: loss: 0.0051711
[Epoch 51; Iter   770/ 1097] train: loss: 0.0120974
[Epoch 51; Iter   800/ 1097] train: loss: 0.0000484
[Epoch 51; Iter   830/ 1097] train: loss: 0.0002138
[Epoch 51; Iter   860/ 1097] train: loss: 0.0004563
[Epoch 51; Iter   890/ 1097] train: loss: 0.0000261
[Epoch 51; Iter   920/ 1097] train: loss: 0.0003174
[Epoch 51; Iter   950/ 1097] train: loss: 0.0067373
[Epoch 51; Iter   980/ 1097] train: loss: 0.0058366
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0189234
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0067826
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0088331
[Epoch 51] ogbg-molhiv: 0.621044 val loss: 15.181062
[Epoch 51] ogbg-molhiv: 0.582968 test loss: 13.967536
[Epoch 52; Iter     3/ 1097] train: loss: 0.0001862
[Epoch 52; Iter    33/ 1097] train: loss: 0.0000876
[Epoch 52; Iter    63/ 1097] train: loss: 0.0005761
[Epoch 52; Iter    93/ 1097] train: loss: 0.0001459
[Epoch 52; Iter   123/ 1097] train: loss: 0.0000557
[Epoch 52; Iter   153/ 1097] train: loss: 0.0060452
[Epoch 52; Iter   183/ 1097] train: loss: 0.0671972
[Epoch 52; Iter   213/ 1097] train: loss: 0.0026340
[Epoch 52; Iter   243/ 1097] train: loss: 0.0004769
[Epoch 52; Iter   273/ 1097] train: loss: 0.0023132
[Epoch 52; Iter   303/ 1097] train: loss: 0.0002206
[Epoch 52; Iter   333/ 1097] train: loss: 0.0008213
[Epoch 52; Iter   363/ 1097] train: loss: 0.0007323
[Epoch 52; Iter   393/ 1097] train: loss: 0.0009742
[Epoch 52; Iter   423/ 1097] train: loss: 0.0002810
[Epoch 52; Iter   453/ 1097] train: loss: 0.0016734
[Epoch 52; Iter   483/ 1097] train: loss: 0.0008492
[Epoch 52; Iter   513/ 1097] train: loss: 0.0039947
[Epoch 52; Iter   543/ 1097] train: loss: 0.0013805
[Epoch 52; Iter   573/ 1097] train: loss: 0.0116226
[Epoch 52; Iter   603/ 1097] train: loss: 0.0001647
[Epoch 52; Iter   633/ 1097] train: loss: 0.0203394
[Epoch 52; Iter   663/ 1097] train: loss: 0.0020148
[Epoch 52; Iter   693/ 1097] train: loss: 0.0875476
[Epoch 52; Iter   723/ 1097] train: loss: 0.0016174
[Epoch 52; Iter   753/ 1097] train: loss: 0.0268663
[Epoch 52; Iter   783/ 1097] train: loss: 0.0001919
[Epoch 52; Iter   813/ 1097] train: loss: 0.0008392
[Epoch 52; Iter   843/ 1097] train: loss: 0.0031946
[Epoch 52; Iter   873/ 1097] train: loss: 0.0066819
[Epoch 52; Iter   903/ 1097] train: loss: 0.0011766
[Epoch 52; Iter   933/ 1097] train: loss: 0.0005321
[Epoch 52; Iter   963/ 1097] train: loss: 0.0042587
[Epoch 52; Iter   993/ 1097] train: loss: 0.0008436
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0035908
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0012465
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0046146
[Epoch 52] ogbg-molhiv: 0.676459 val loss: 0.560684
[Epoch 52] ogbg-molhiv: 0.727865 test loss: 0.323603
[Epoch 53; Iter    16/ 1097] train: loss: 0.0015934
[Epoch 53; Iter    46/ 1097] train: loss: 0.0277128
[Epoch 53; Iter    76/ 1097] train: loss: 0.0147115
[Epoch 53; Iter   106/ 1097] train: loss: 0.0059828
[Epoch 53; Iter   136/ 1097] train: loss: 0.0009929
[Epoch 53; Iter   166/ 1097] train: loss: 0.0019290
[Epoch 53; Iter   196/ 1097] train: loss: 0.0085160
[Epoch 53; Iter   226/ 1097] train: loss: 0.0023289
[Epoch 53; Iter   256/ 1097] train: loss: 0.0009543
[Epoch 53; Iter   286/ 1097] train: loss: 0.0015469
[Epoch 53; Iter   316/ 1097] train: loss: 0.0136114
[Epoch 53; Iter   346/ 1097] train: loss: 0.0067520
[Epoch 53; Iter   376/ 1097] train: loss: 0.0004361
[Epoch 53; Iter   406/ 1097] train: loss: 0.0216217
[Epoch 53; Iter   436/ 1097] train: loss: 0.0691118
[Epoch 53; Iter   466/ 1097] train: loss: 0.0034509
[Epoch 53; Iter   496/ 1097] train: loss: 0.0081461
[Epoch 53; Iter   526/ 1097] train: loss: 0.0079526
[Epoch 53; Iter   556/ 1097] train: loss: 0.0048980
[Epoch 53; Iter   586/ 1097] train: loss: 0.0046499
[Epoch 53; Iter   616/ 1097] train: loss: 0.0010407
[Epoch 53; Iter   646/ 1097] train: loss: 0.0092985
[Epoch 53; Iter   676/ 1097] train: loss: 0.0015185
[Epoch 53; Iter   706/ 1097] train: loss: 0.0038634
[Epoch 53; Iter   736/ 1097] train: loss: 0.0014370
[Epoch 53; Iter   766/ 1097] train: loss: 0.0223678
[Epoch 53; Iter   796/ 1097] train: loss: 0.0003036
[Epoch 53; Iter   826/ 1097] train: loss: 0.0103353
[Epoch 53; Iter   856/ 1097] train: loss: 0.0012363
[Epoch 53; Iter   886/ 1097] train: loss: 0.0009326
[Epoch 53; Iter   916/ 1097] train: loss: 0.0129922
[Epoch 53; Iter   946/ 1097] train: loss: 0.0044256
[Epoch 53; Iter   976/ 1097] train: loss: 0.0015913
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0208730
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0024430
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0258537
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0008694
[Epoch 53] ogbg-molhiv: 0.694683 val loss: 0.798214
[Epoch 53] ogbg-molhiv: 0.750764 test loss: 0.370803
[Epoch 54; Iter    29/ 1097] train: loss: 0.0000962
[Epoch 54; Iter    59/ 1097] train: loss: 0.0007711
[Epoch 54; Iter    89/ 1097] train: loss: 0.0031566
[Epoch 54; Iter   119/ 1097] train: loss: 0.0011223
[Epoch 54; Iter   149/ 1097] train: loss: 0.0069379
[Epoch 54; Iter   179/ 1097] train: loss: 0.0003965
[Epoch 54; Iter   209/ 1097] train: loss: 0.0057528
[Epoch 54; Iter   239/ 1097] train: loss: 0.0023289
[Epoch 54; Iter   269/ 1097] train: loss: 0.0079361
[Epoch 54; Iter   299/ 1097] train: loss: 0.0010217
[Epoch 54; Iter   329/ 1097] train: loss: 0.0056705
[Epoch 54; Iter   359/ 1097] train: loss: 0.0435731
[Epoch 54; Iter   389/ 1097] train: loss: 0.0011682
[Epoch 54; Iter   419/ 1097] train: loss: 0.0016788
[Epoch 54; Iter   449/ 1097] train: loss: 0.0027823
[Epoch 54; Iter   479/ 1097] train: loss: 0.0013470
[Epoch 54; Iter   509/ 1097] train: loss: 0.0162650
[Epoch 54; Iter   539/ 1097] train: loss: 0.1618676
[Epoch 54; Iter   569/ 1097] train: loss: 0.0042840
[Epoch 54; Iter   599/ 1097] train: loss: 0.0009515
[Epoch 54; Iter   629/ 1097] train: loss: 0.0028000
[Epoch 54; Iter   659/ 1097] train: loss: 0.0218193
[Epoch 54; Iter   689/ 1097] train: loss: 0.0061773
[Epoch 54; Iter   719/ 1097] train: loss: 0.0007235
[Epoch 54; Iter   749/ 1097] train: loss: 0.0037518
[Epoch 54; Iter   779/ 1097] train: loss: 0.0076406
[Epoch 54; Iter   809/ 1097] train: loss: 0.0020673
[Epoch 54; Iter   839/ 1097] train: loss: 0.0033702
[Epoch 54; Iter   869/ 1097] train: loss: 0.0120998
[Epoch 54; Iter   899/ 1097] train: loss: 0.0137402
[Epoch 54; Iter   929/ 1097] train: loss: 0.0007952
[Epoch 54; Iter   959/ 1097] train: loss: 0.0011713
[Epoch 54; Iter   989/ 1097] train: loss: 0.2226964
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0013532
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0050581
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0075384
[Epoch 54] ogbg-molhiv: 0.658366 val loss: 1.260199
[Epoch 54] ogbg-molhiv: 0.742260 test loss: 0.361766
[Epoch 55; Iter    12/ 1097] train: loss: 0.0001212
[Epoch 55; Iter    42/ 1097] train: loss: 0.0008562
[Epoch 55; Iter    72/ 1097] train: loss: 0.0010952
[Epoch 55; Iter   102/ 1097] train: loss: 0.0007943
[Epoch 55; Iter   132/ 1097] train: loss: 0.0087399
[Epoch 55; Iter   162/ 1097] train: loss: 0.0018197
[Epoch 55; Iter   192/ 1097] train: loss: 0.0184250
[Epoch 55; Iter   222/ 1097] train: loss: 0.0003603
[Epoch 55; Iter   252/ 1097] train: loss: 0.0014563
[Epoch 55; Iter   282/ 1097] train: loss: 0.0013455
[Epoch 55; Iter   312/ 1097] train: loss: 0.0027169
[Epoch 55; Iter   342/ 1097] train: loss: 0.0300517
[Epoch 55; Iter   372/ 1097] train: loss: 0.0025775
[Epoch 55; Iter   402/ 1097] train: loss: 0.0003226
[Epoch 55; Iter   432/ 1097] train: loss: 0.0004121
[Epoch 55; Iter   462/ 1097] train: loss: 0.0007910
[Epoch 55; Iter   492/ 1097] train: loss: 0.0019351
[Epoch 55; Iter   522/ 1097] train: loss: 0.0144091
[Epoch 55; Iter   552/ 1097] train: loss: 0.0076802
[Epoch 55; Iter   582/ 1097] train: loss: 0.0021924
[Epoch 55; Iter   612/ 1097] train: loss: 0.0003976
[Epoch 55; Iter   642/ 1097] train: loss: 0.0010345
[Epoch 55; Iter   672/ 1097] train: loss: 0.0026655
[Epoch 55; Iter   702/ 1097] train: loss: 0.0520292
[Epoch 55; Iter   732/ 1097] train: loss: 0.0034984
[Epoch 55; Iter   762/ 1097] train: loss: 0.0030651
[Epoch 55; Iter   792/ 1097] train: loss: 0.0003583
[Epoch 55; Iter   822/ 1097] train: loss: 0.3052980
[Epoch 55; Iter   852/ 1097] train: loss: 0.0036255
[Epoch 55; Iter   882/ 1097] train: loss: 0.0079941
[Epoch 55; Iter   912/ 1097] train: loss: 0.0128751
[Epoch 55; Iter   942/ 1097] train: loss: 0.0013715
[Epoch 55; Iter   972/ 1097] train: loss: 0.0021324
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0302208
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0046479
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0135205
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0044514
[Epoch 55] ogbg-molhiv: 0.679164 val loss: 2.134360
[Epoch 55] ogbg-molhiv: 0.744800 test loss: 0.280387
[Epoch 56; Iter    25/ 1097] train: loss: 0.0009471
[Epoch 56; Iter    55/ 1097] train: loss: 0.0206064
[Epoch 56; Iter    85/ 1097] train: loss: 0.0002187
[Epoch 56; Iter   115/ 1097] train: loss: 0.0035011
[Epoch 56; Iter   145/ 1097] train: loss: 0.0003120
[Epoch 56; Iter   175/ 1097] train: loss: 0.1284807
[Epoch 56; Iter   205/ 1097] train: loss: 0.0144248
[Epoch 56; Iter   235/ 1097] train: loss: 0.1371217
[Epoch 56; Iter   265/ 1097] train: loss: 0.0018795
[Epoch 56; Iter   295/ 1097] train: loss: 0.0642101
[Epoch 56; Iter   325/ 1097] train: loss: 0.0358888
[Epoch 56; Iter   355/ 1097] train: loss: 0.0000673
[Epoch 56; Iter   385/ 1097] train: loss: 0.0037167
[Epoch 56; Iter   415/ 1097] train: loss: 0.1248652
[Epoch 56; Iter   445/ 1097] train: loss: 0.0024049
[Epoch 56; Iter   475/ 1097] train: loss: 0.0240916
[Epoch 56; Iter   505/ 1097] train: loss: 0.0007438
[Epoch 56; Iter   535/ 1097] train: loss: 0.0045860
[Epoch 56; Iter   565/ 1097] train: loss: 0.0027883
[Epoch 56; Iter   595/ 1097] train: loss: 0.1161125
[Epoch 56; Iter   625/ 1097] train: loss: 0.0002291
[Epoch 56; Iter   655/ 1097] train: loss: 0.0013270
[Epoch 56; Iter   685/ 1097] train: loss: 0.0004434
[Epoch 56; Iter   715/ 1097] train: loss: 0.0010558
[Epoch 56; Iter   745/ 1097] train: loss: 0.0003215
[Epoch 56; Iter   775/ 1097] train: loss: 0.0160580
[Epoch 56; Iter   805/ 1097] train: loss: 0.0002822
[Epoch 56; Iter   835/ 1097] train: loss: 0.0034681
[Epoch 56; Iter   865/ 1097] train: loss: 0.0165667
[Epoch 56; Iter   895/ 1097] train: loss: 0.0555280
[Epoch 56; Iter   925/ 1097] train: loss: 0.0021944
[Epoch 56; Iter   955/ 1097] train: loss: 0.0020557
[Epoch 56; Iter   985/ 1097] train: loss: 0.0271471
[Epoch 52; Iter   933/ 1097] train: loss: 0.0024362
[Epoch 52; Iter   963/ 1097] train: loss: 0.0562207
[Epoch 52; Iter   993/ 1097] train: loss: 0.0001866
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0030147
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0038755
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0166486
[Epoch 52] ogbg-molhiv: 0.749106 val loss: 0.209342
[Epoch 52] ogbg-molhiv: 0.742241 test loss: 0.249652
[Epoch 53; Iter    16/ 1097] train: loss: 0.0023370
[Epoch 53; Iter    46/ 1097] train: loss: 0.0019037
[Epoch 53; Iter    76/ 1097] train: loss: 0.0124118
[Epoch 53; Iter   106/ 1097] train: loss: 0.0005443
[Epoch 53; Iter   136/ 1097] train: loss: 0.0009833
[Epoch 53; Iter   166/ 1097] train: loss: 0.0921281
[Epoch 53; Iter   196/ 1097] train: loss: 0.0028409
[Epoch 53; Iter   226/ 1097] train: loss: 0.0010737
[Epoch 53; Iter   256/ 1097] train: loss: 0.0102407
[Epoch 53; Iter   286/ 1097] train: loss: 0.0110048
[Epoch 53; Iter   316/ 1097] train: loss: 0.0001164
[Epoch 53; Iter   346/ 1097] train: loss: 0.0030053
[Epoch 53; Iter   376/ 1097] train: loss: 0.0071515
[Epoch 53; Iter   406/ 1097] train: loss: 0.0007890
[Epoch 53; Iter   436/ 1097] train: loss: 0.0081031
[Epoch 53; Iter   466/ 1097] train: loss: 0.0065688
[Epoch 53; Iter   496/ 1097] train: loss: 0.0051467
[Epoch 53; Iter   526/ 1097] train: loss: 0.0175627
[Epoch 53; Iter   556/ 1097] train: loss: 0.0060605
[Epoch 53; Iter   586/ 1097] train: loss: 0.0367307
[Epoch 53; Iter   616/ 1097] train: loss: 0.0439130
[Epoch 53; Iter   646/ 1097] train: loss: 0.0038166
[Epoch 53; Iter   676/ 1097] train: loss: 0.0062954
[Epoch 53; Iter   706/ 1097] train: loss: 0.0217968
[Epoch 53; Iter   736/ 1097] train: loss: 0.0057109
[Epoch 53; Iter   766/ 1097] train: loss: 0.0292737
[Epoch 53; Iter   796/ 1097] train: loss: 0.0010511
[Epoch 53; Iter   826/ 1097] train: loss: 0.0391414
[Epoch 53; Iter   856/ 1097] train: loss: 0.0145891
[Epoch 53; Iter   886/ 1097] train: loss: 0.0025627
[Epoch 53; Iter   916/ 1097] train: loss: 0.0004277
[Epoch 53; Iter   946/ 1097] train: loss: 0.0238898
[Epoch 53; Iter   976/ 1097] train: loss: 0.0022977
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0207656
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0019370
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0021626
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0017658
[Epoch 53] ogbg-molhiv: 0.768604 val loss: 0.244702
[Epoch 53] ogbg-molhiv: 0.777273 test loss: 0.254588
[Epoch 54; Iter    29/ 1097] train: loss: 0.0057674
[Epoch 54; Iter    59/ 1097] train: loss: 0.0053546
[Epoch 54; Iter    89/ 1097] train: loss: 0.0016479
[Epoch 54; Iter   119/ 1097] train: loss: 0.0032804
[Epoch 54; Iter   149/ 1097] train: loss: 0.0042510
[Epoch 54; Iter   179/ 1097] train: loss: 0.0017797
[Epoch 54; Iter   209/ 1097] train: loss: 0.0159816
[Epoch 54; Iter   239/ 1097] train: loss: 0.0011909
[Epoch 54; Iter   269/ 1097] train: loss: 0.0014179
[Epoch 54; Iter   299/ 1097] train: loss: 0.0017255
[Epoch 54; Iter   329/ 1097] train: loss: 0.1139520
[Epoch 54; Iter   359/ 1097] train: loss: 0.0021092
[Epoch 54; Iter   389/ 1097] train: loss: 0.0039196
[Epoch 54; Iter   419/ 1097] train: loss: 0.0013581
[Epoch 54; Iter   449/ 1097] train: loss: 0.0014215
[Epoch 54; Iter   479/ 1097] train: loss: 0.0069596
[Epoch 54; Iter   509/ 1097] train: loss: 0.0002645
[Epoch 54; Iter   539/ 1097] train: loss: 0.0011801
[Epoch 54; Iter   569/ 1097] train: loss: 0.0001091
[Epoch 54; Iter   599/ 1097] train: loss: 0.0006805
[Epoch 54; Iter   629/ 1097] train: loss: 0.0059607
[Epoch 54; Iter   659/ 1097] train: loss: 0.0015054
[Epoch 54; Iter   689/ 1097] train: loss: 0.0009340
[Epoch 54; Iter   719/ 1097] train: loss: 0.0007725
[Epoch 54; Iter   749/ 1097] train: loss: 0.0020285
[Epoch 54; Iter   779/ 1097] train: loss: 0.0086458
[Epoch 54; Iter   809/ 1097] train: loss: 0.0075019
[Epoch 54; Iter   839/ 1097] train: loss: 0.0023774
[Epoch 54; Iter   869/ 1097] train: loss: 0.0193660
[Epoch 54; Iter   899/ 1097] train: loss: 0.0019927
[Epoch 54; Iter   929/ 1097] train: loss: 0.0017475
[Epoch 54; Iter   959/ 1097] train: loss: 0.0036386
[Epoch 54; Iter   989/ 1097] train: loss: 0.0013971
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0478850
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0062726
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0015153
[Epoch 54] ogbg-molhiv: 0.774238 val loss: 0.304789
[Epoch 54] ogbg-molhiv: 0.737419 test loss: 0.256079
[Epoch 55; Iter    12/ 1097] train: loss: 0.0010650
[Epoch 55; Iter    42/ 1097] train: loss: 0.0106013
[Epoch 55; Iter    72/ 1097] train: loss: 0.0081057
[Epoch 55; Iter   102/ 1097] train: loss: 0.0008716
[Epoch 55; Iter   132/ 1097] train: loss: 0.0062515
[Epoch 55; Iter   162/ 1097] train: loss: 0.0002034
[Epoch 55; Iter   192/ 1097] train: loss: 0.0055641
[Epoch 55; Iter   222/ 1097] train: loss: 0.0004702
[Epoch 55; Iter   252/ 1097] train: loss: 0.0059519
[Epoch 55; Iter   282/ 1097] train: loss: 0.0005977
[Epoch 55; Iter   312/ 1097] train: loss: 0.0230309
[Epoch 55; Iter   342/ 1097] train: loss: 0.0005652
[Epoch 55; Iter   372/ 1097] train: loss: 0.0041204
[Epoch 55; Iter   402/ 1097] train: loss: 0.0202582
[Epoch 55; Iter   432/ 1097] train: loss: 0.0008852
[Epoch 55; Iter   462/ 1097] train: loss: 0.0031347
[Epoch 55; Iter   492/ 1097] train: loss: 0.0013687
[Epoch 55; Iter   522/ 1097] train: loss: 0.0023342
[Epoch 55; Iter   552/ 1097] train: loss: 0.0046966
[Epoch 55; Iter   582/ 1097] train: loss: 0.0061821
[Epoch 55; Iter   612/ 1097] train: loss: 0.0043251
[Epoch 55; Iter   642/ 1097] train: loss: 0.0007185
[Epoch 55; Iter   672/ 1097] train: loss: 0.0006369
[Epoch 55; Iter   702/ 1097] train: loss: 0.0013345
[Epoch 55; Iter   732/ 1097] train: loss: 0.0080909
[Epoch 55; Iter   762/ 1097] train: loss: 0.0069012
[Epoch 55; Iter   792/ 1097] train: loss: 0.0228698
[Epoch 55; Iter   822/ 1097] train: loss: 0.0552619
[Epoch 55; Iter   852/ 1097] train: loss: 0.0004545
[Epoch 55; Iter   882/ 1097] train: loss: 0.0003557
[Epoch 55; Iter   912/ 1097] train: loss: 0.0005673
[Epoch 55; Iter   942/ 1097] train: loss: 0.0015696
[Epoch 55; Iter   972/ 1097] train: loss: 0.0001038
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0001297
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006592
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0296888
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0053479
[Epoch 55] ogbg-molhiv: 0.778822 val loss: 0.271247
[Epoch 55] ogbg-molhiv: 0.762896 test loss: 0.256592
[Epoch 56; Iter    25/ 1097] train: loss: 0.0003449
[Epoch 56; Iter    55/ 1097] train: loss: 0.0017012
[Epoch 56; Iter    85/ 1097] train: loss: 0.0202840
[Epoch 56; Iter   115/ 1097] train: loss: 0.0016871
[Epoch 56; Iter   145/ 1097] train: loss: 0.0015505
[Epoch 56; Iter   175/ 1097] train: loss: 0.0101462
[Epoch 56; Iter   205/ 1097] train: loss: 0.0065760
[Epoch 56; Iter   235/ 1097] train: loss: 0.0028767
[Epoch 56; Iter   265/ 1097] train: loss: 0.0002173
[Epoch 56; Iter   295/ 1097] train: loss: 0.0009863
[Epoch 56; Iter   325/ 1097] train: loss: 0.0232468
[Epoch 56; Iter   355/ 1097] train: loss: 0.0014110
[Epoch 56; Iter   385/ 1097] train: loss: 0.0005038
[Epoch 56; Iter   415/ 1097] train: loss: 0.0002170
[Epoch 56; Iter   445/ 1097] train: loss: 0.0028499
[Epoch 56; Iter   475/ 1097] train: loss: 0.0000468
[Epoch 56; Iter   505/ 1097] train: loss: 0.0035380
[Epoch 56; Iter   535/ 1097] train: loss: 0.0318993
[Epoch 56; Iter   565/ 1097] train: loss: 0.0022759
[Epoch 56; Iter   595/ 1097] train: loss: 0.0746477
[Epoch 56; Iter   625/ 1097] train: loss: 0.0012083
[Epoch 56; Iter   655/ 1097] train: loss: 0.0011862
[Epoch 56; Iter   685/ 1097] train: loss: 0.0001909
[Epoch 56; Iter   715/ 1097] train: loss: 0.0005073
[Epoch 56; Iter   745/ 1097] train: loss: 0.0018626
[Epoch 56; Iter   775/ 1097] train: loss: 0.0230850
[Epoch 56; Iter   805/ 1097] train: loss: 0.0012106
[Epoch 56; Iter   835/ 1097] train: loss: 0.0116212
[Epoch 56; Iter   865/ 1097] train: loss: 0.0003283
[Epoch 56; Iter   895/ 1097] train: loss: 0.0424498
[Epoch 56; Iter   925/ 1097] train: loss: 0.0011283
[Epoch 56; Iter   955/ 1097] train: loss: 0.0039321
[Epoch 56; Iter   985/ 1097] train: loss: 0.0001265
[Epoch 52; Iter   933/ 1097] train: loss: 0.0094210
[Epoch 52; Iter   963/ 1097] train: loss: 0.0070725
[Epoch 52; Iter   993/ 1097] train: loss: 0.0060658
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0061862
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0007979
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0015376
[Epoch 52] ogbg-molhiv: 0.723689 val loss: 1.063734
[Epoch 52] ogbg-molhiv: 0.705989 test loss: 0.410674
[Epoch 53; Iter    16/ 1097] train: loss: 0.0004561
[Epoch 53; Iter    46/ 1097] train: loss: 0.0029960
[Epoch 53; Iter    76/ 1097] train: loss: 0.0055681
[Epoch 53; Iter   106/ 1097] train: loss: 0.0025457
[Epoch 53; Iter   136/ 1097] train: loss: 0.0088126
[Epoch 53; Iter   166/ 1097] train: loss: 0.0009927
[Epoch 53; Iter   196/ 1097] train: loss: 0.0080942
[Epoch 53; Iter   226/ 1097] train: loss: 0.0009383
[Epoch 53; Iter   256/ 1097] train: loss: 0.0007011
[Epoch 53; Iter   286/ 1097] train: loss: 0.0010293
[Epoch 53; Iter   316/ 1097] train: loss: 0.0007205
[Epoch 53; Iter   346/ 1097] train: loss: 0.0154837
[Epoch 53; Iter   376/ 1097] train: loss: 0.2307954
[Epoch 53; Iter   406/ 1097] train: loss: 0.1257301
[Epoch 53; Iter   436/ 1097] train: loss: 0.0350522
[Epoch 53; Iter   466/ 1097] train: loss: 0.0317223
[Epoch 53; Iter   496/ 1097] train: loss: 0.0103823
[Epoch 53; Iter   526/ 1097] train: loss: 0.0026018
[Epoch 53; Iter   556/ 1097] train: loss: 0.0128127
[Epoch 53; Iter   586/ 1097] train: loss: 0.0039061
[Epoch 53; Iter   616/ 1097] train: loss: 0.0059126
[Epoch 53; Iter   646/ 1097] train: loss: 0.1163705
[Epoch 53; Iter   676/ 1097] train: loss: 0.0437209
[Epoch 53; Iter   706/ 1097] train: loss: 0.0375542
[Epoch 53; Iter   736/ 1097] train: loss: 0.0042812
[Epoch 53; Iter   766/ 1097] train: loss: 0.0101761
[Epoch 53; Iter   796/ 1097] train: loss: 0.0170316
[Epoch 53; Iter   826/ 1097] train: loss: 0.0009226
[Epoch 53; Iter   856/ 1097] train: loss: 0.0043704
[Epoch 53; Iter   886/ 1097] train: loss: 0.0033434
[Epoch 53; Iter   916/ 1097] train: loss: 0.0304342
[Epoch 53; Iter   946/ 1097] train: loss: 0.0255320
[Epoch 53; Iter   976/ 1097] train: loss: 0.0013631
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0349512
[Epoch 53; Iter  1036/ 1097] train: loss: 0.1526782
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0042522
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0277171
[Epoch 53] ogbg-molhiv: 0.720893 val loss: 2.858687
[Epoch 53] ogbg-molhiv: 0.731646 test loss: 1.165511
[Epoch 54; Iter    29/ 1097] train: loss: 0.0261840
[Epoch 54; Iter    59/ 1097] train: loss: 0.0045184
[Epoch 54; Iter    89/ 1097] train: loss: 0.0024655
[Epoch 54; Iter   119/ 1097] train: loss: 0.0027890
[Epoch 54; Iter   149/ 1097] train: loss: 0.0007222
[Epoch 54; Iter   179/ 1097] train: loss: 0.0601393
[Epoch 54; Iter   209/ 1097] train: loss: 0.0131666
[Epoch 54; Iter   239/ 1097] train: loss: 0.0451331
[Epoch 54; Iter   269/ 1097] train: loss: 0.0029134
[Epoch 54; Iter   299/ 1097] train: loss: 0.0016871
[Epoch 54; Iter   329/ 1097] train: loss: 0.0021904
[Epoch 54; Iter   359/ 1097] train: loss: 0.0018752
[Epoch 54; Iter   389/ 1097] train: loss: 0.0096499
[Epoch 54; Iter   419/ 1097] train: loss: 0.0009702
[Epoch 54; Iter   449/ 1097] train: loss: 0.0008577
[Epoch 54; Iter   479/ 1097] train: loss: 0.0023490
[Epoch 54; Iter   509/ 1097] train: loss: 0.0364784
[Epoch 54; Iter   539/ 1097] train: loss: 0.0007421
[Epoch 54; Iter   569/ 1097] train: loss: 0.0087387
[Epoch 54; Iter   599/ 1097] train: loss: 0.0039828
[Epoch 54; Iter   629/ 1097] train: loss: 0.0135230
[Epoch 54; Iter   659/ 1097] train: loss: 0.0350145
[Epoch 54; Iter   689/ 1097] train: loss: 0.0006298
[Epoch 54; Iter   719/ 1097] train: loss: 0.0210069
[Epoch 54; Iter   749/ 1097] train: loss: 0.0099990
[Epoch 54; Iter   779/ 1097] train: loss: 0.0191053
[Epoch 54; Iter   809/ 1097] train: loss: 0.0053603
[Epoch 54; Iter   839/ 1097] train: loss: 0.1923078
[Epoch 54; Iter   869/ 1097] train: loss: 0.0018728
[Epoch 54; Iter   899/ 1097] train: loss: 0.0089489
[Epoch 54; Iter   929/ 1097] train: loss: 0.0024598
[Epoch 54; Iter   959/ 1097] train: loss: 0.0021353
[Epoch 54; Iter   989/ 1097] train: loss: 0.0016534
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0020836
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0116950
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0007503
[Epoch 54] ogbg-molhiv: 0.723514 val loss: 1.762074
[Epoch 54] ogbg-molhiv: 0.706418 test loss: 1.296844
[Epoch 55; Iter    12/ 1097] train: loss: 0.0014054
[Epoch 55; Iter    42/ 1097] train: loss: 0.0055521
[Epoch 55; Iter    72/ 1097] train: loss: 0.0001372
[Epoch 55; Iter   102/ 1097] train: loss: 0.0107604
[Epoch 55; Iter   132/ 1097] train: loss: 0.0376004
[Epoch 55; Iter   162/ 1097] train: loss: 0.0096470
[Epoch 55; Iter   192/ 1097] train: loss: 0.0011923
[Epoch 55; Iter   222/ 1097] train: loss: 0.0004220
[Epoch 55; Iter   252/ 1097] train: loss: 0.0044495
[Epoch 55; Iter   282/ 1097] train: loss: 0.0036433
[Epoch 55; Iter   312/ 1097] train: loss: 0.0017362
[Epoch 55; Iter   342/ 1097] train: loss: 0.0050372
[Epoch 55; Iter   372/ 1097] train: loss: 0.0015946
[Epoch 55; Iter   402/ 1097] train: loss: 0.0449230
[Epoch 55; Iter   432/ 1097] train: loss: 0.0058399
[Epoch 55; Iter   462/ 1097] train: loss: 0.0026377
[Epoch 55; Iter   492/ 1097] train: loss: 0.0084590
[Epoch 55; Iter   522/ 1097] train: loss: 0.0094025
[Epoch 55; Iter   552/ 1097] train: loss: 0.0237502
[Epoch 55; Iter   582/ 1097] train: loss: 0.0444272
[Epoch 55; Iter   612/ 1097] train: loss: 0.0170745
[Epoch 55; Iter   642/ 1097] train: loss: 0.0030346
[Epoch 55; Iter   672/ 1097] train: loss: 0.0096223
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010966
[Epoch 55; Iter   732/ 1097] train: loss: 0.0043541
[Epoch 55; Iter   762/ 1097] train: loss: 0.0049552
[Epoch 55; Iter   792/ 1097] train: loss: 0.0015373
[Epoch 55; Iter   822/ 1097] train: loss: 0.0348820
[Epoch 55; Iter   852/ 1097] train: loss: 0.0106475
[Epoch 55; Iter   882/ 1097] train: loss: 0.0036667
[Epoch 55; Iter   912/ 1097] train: loss: 0.0026124
[Epoch 55; Iter   942/ 1097] train: loss: 0.1249733
[Epoch 55; Iter   972/ 1097] train: loss: 0.0019575
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0771806
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0059437
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0173424
[Epoch 55; Iter  1092/ 1097] train: loss: 0.1014355
[Epoch 55] ogbg-molhiv: 0.704959 val loss: 1.239899
[Epoch 55] ogbg-molhiv: 0.742803 test loss: 0.689120
[Epoch 56; Iter    25/ 1097] train: loss: 0.0070492
[Epoch 56; Iter    55/ 1097] train: loss: 0.0038986
[Epoch 56; Iter    85/ 1097] train: loss: 0.0214379
[Epoch 56; Iter   115/ 1097] train: loss: 0.0325388
[Epoch 56; Iter   145/ 1097] train: loss: 0.0216142
[Epoch 56; Iter   175/ 1097] train: loss: 0.0741169
[Epoch 56; Iter   205/ 1097] train: loss: 0.1226633
[Epoch 56; Iter   235/ 1097] train: loss: 0.0028566
[Epoch 56; Iter   265/ 1097] train: loss: 0.0066672
[Epoch 56; Iter   295/ 1097] train: loss: 0.0062563
[Epoch 56; Iter   325/ 1097] train: loss: 0.0046778
[Epoch 56; Iter   355/ 1097] train: loss: 0.0029834
[Epoch 56; Iter   385/ 1097] train: loss: 0.0204742
[Epoch 56; Iter   415/ 1097] train: loss: 0.0273554
[Epoch 56; Iter   445/ 1097] train: loss: 0.0053890
[Epoch 56; Iter   475/ 1097] train: loss: 0.0011631
[Epoch 56; Iter   505/ 1097] train: loss: 0.0975030
[Epoch 56; Iter   535/ 1097] train: loss: 0.0272756
[Epoch 56; Iter   565/ 1097] train: loss: 0.0051189
[Epoch 56; Iter   595/ 1097] train: loss: 0.1213103
[Epoch 56; Iter   625/ 1097] train: loss: 0.0010577
[Epoch 56; Iter   655/ 1097] train: loss: 0.1234062
[Epoch 56; Iter   685/ 1097] train: loss: 0.0019581
[Epoch 56; Iter   715/ 1097] train: loss: 0.0057028
[Epoch 56; Iter   745/ 1097] train: loss: 0.0007401
[Epoch 56; Iter   775/ 1097] train: loss: 0.0071087
[Epoch 56; Iter   805/ 1097] train: loss: 0.0017323
[Epoch 56; Iter   835/ 1097] train: loss: 0.0019094
[Epoch 56; Iter   865/ 1097] train: loss: 0.0392750
[Epoch 56; Iter   895/ 1097] train: loss: 0.0550180
[Epoch 56; Iter   925/ 1097] train: loss: 0.0066529
[Epoch 56; Iter   955/ 1097] train: loss: 0.0010132
[Epoch 56; Iter   985/ 1097] train: loss: 0.0689153
[Epoch 52; Iter   933/ 1097] train: loss: 0.0006375
[Epoch 52; Iter   963/ 1097] train: loss: 0.0004579
[Epoch 52; Iter   993/ 1097] train: loss: 0.0004854
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0065521
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0011773
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0004311
[Epoch 52] ogbg-molhiv: 0.793375 val loss: 0.266469
[Epoch 52] ogbg-molhiv: 0.723123 test loss: 0.514352
[Epoch 53; Iter    16/ 1097] train: loss: 0.0049701
[Epoch 53; Iter    46/ 1097] train: loss: 0.0026256
[Epoch 53; Iter    76/ 1097] train: loss: 0.0056516
[Epoch 53; Iter   106/ 1097] train: loss: 0.0003363
[Epoch 53; Iter   136/ 1097] train: loss: 0.0010864
[Epoch 53; Iter   166/ 1097] train: loss: 0.1838544
[Epoch 53; Iter   196/ 1097] train: loss: 0.0111920
[Epoch 53; Iter   226/ 1097] train: loss: 0.0006658
[Epoch 53; Iter   256/ 1097] train: loss: 0.0023726
[Epoch 53; Iter   286/ 1097] train: loss: 0.0201318
[Epoch 53; Iter   316/ 1097] train: loss: 0.0031318
[Epoch 53; Iter   346/ 1097] train: loss: 0.0214386
[Epoch 53; Iter   376/ 1097] train: loss: 0.0026725
[Epoch 53; Iter   406/ 1097] train: loss: 0.0016993
[Epoch 53; Iter   436/ 1097] train: loss: 0.0732833
[Epoch 53; Iter   466/ 1097] train: loss: 0.0158980
[Epoch 53; Iter   496/ 1097] train: loss: 0.0244232
[Epoch 53; Iter   526/ 1097] train: loss: 0.0003656
[Epoch 53; Iter   556/ 1097] train: loss: 0.0009938
[Epoch 53; Iter   586/ 1097] train: loss: 0.1050127
[Epoch 53; Iter   616/ 1097] train: loss: 0.0002132
[Epoch 53; Iter   646/ 1097] train: loss: 0.0026796
[Epoch 53; Iter   676/ 1097] train: loss: 0.0004244
[Epoch 53; Iter   706/ 1097] train: loss: 0.1070691
[Epoch 53; Iter   736/ 1097] train: loss: 0.0076830
[Epoch 53; Iter   766/ 1097] train: loss: 0.0707520
[Epoch 53; Iter   796/ 1097] train: loss: 0.0023904
[Epoch 53; Iter   826/ 1097] train: loss: 0.0063690
[Epoch 53; Iter   856/ 1097] train: loss: 0.0160562
[Epoch 53; Iter   886/ 1097] train: loss: 0.0020888
[Epoch 53; Iter   916/ 1097] train: loss: 0.0019496
[Epoch 53; Iter   946/ 1097] train: loss: 0.0277335
[Epoch 53; Iter   976/ 1097] train: loss: 0.0004020
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0016981
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0008337
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0392847
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0243472
[Epoch 53] ogbg-molhiv: 0.786783 val loss: 0.256581
[Epoch 53] ogbg-molhiv: 0.722349 test loss: 0.511713
[Epoch 54; Iter    29/ 1097] train: loss: 0.0093253
[Epoch 54; Iter    59/ 1097] train: loss: 0.0082411
[Epoch 54; Iter    89/ 1097] train: loss: 0.0082798
[Epoch 54; Iter   119/ 1097] train: loss: 0.0025697
[Epoch 54; Iter   149/ 1097] train: loss: 0.0021209
[Epoch 54; Iter   179/ 1097] train: loss: 0.0073624
[Epoch 54; Iter   209/ 1097] train: loss: 0.0010480
[Epoch 54; Iter   239/ 1097] train: loss: 0.0026706
[Epoch 54; Iter   269/ 1097] train: loss: 0.0004132
[Epoch 54; Iter   299/ 1097] train: loss: 0.0002984
[Epoch 54; Iter   329/ 1097] train: loss: 0.0093798
[Epoch 54; Iter   359/ 1097] train: loss: 0.0022345
[Epoch 54; Iter   389/ 1097] train: loss: 0.0013348
[Epoch 54; Iter   419/ 1097] train: loss: 0.0160656
[Epoch 54; Iter   449/ 1097] train: loss: 0.0009454
[Epoch 54; Iter   479/ 1097] train: loss: 0.0146518
[Epoch 54; Iter   509/ 1097] train: loss: 0.0000871
[Epoch 54; Iter   539/ 1097] train: loss: 0.0262306
[Epoch 54; Iter   569/ 1097] train: loss: 0.0011309
[Epoch 54; Iter   599/ 1097] train: loss: 0.0144212
[Epoch 54; Iter   629/ 1097] train: loss: 0.0003058
[Epoch 54; Iter   659/ 1097] train: loss: 0.0027065
[Epoch 54; Iter   689/ 1097] train: loss: 0.0003603
[Epoch 54; Iter   719/ 1097] train: loss: 0.0010835
[Epoch 54; Iter   749/ 1097] train: loss: 0.0792133
[Epoch 54; Iter   779/ 1097] train: loss: 0.0376060
[Epoch 54; Iter   809/ 1097] train: loss: 0.0308225
[Epoch 54; Iter   839/ 1097] train: loss: 0.0056571
[Epoch 54; Iter   869/ 1097] train: loss: 0.0014144
[Epoch 54; Iter   899/ 1097] train: loss: 0.0005867
[Epoch 54; Iter   929/ 1097] train: loss: 0.0697191
[Epoch 54; Iter   959/ 1097] train: loss: 0.0014145
[Epoch 54; Iter   989/ 1097] train: loss: 0.0015050
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0089157
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0669540
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0004524
[Epoch 54] ogbg-molhiv: 0.779652 val loss: 0.299653
[Epoch 54] ogbg-molhiv: 0.689310 test loss: 0.372093
[Epoch 55; Iter    12/ 1097] train: loss: 0.0000984
[Epoch 55; Iter    42/ 1097] train: loss: 0.0002126
[Epoch 55; Iter    72/ 1097] train: loss: 0.0052038
[Epoch 55; Iter   102/ 1097] train: loss: 0.0011951
[Epoch 55; Iter   132/ 1097] train: loss: 0.0959857
[Epoch 55; Iter   162/ 1097] train: loss: 0.0649079
[Epoch 55; Iter   192/ 1097] train: loss: 0.0386491
[Epoch 55; Iter   222/ 1097] train: loss: 0.0007796
[Epoch 55; Iter   252/ 1097] train: loss: 0.0015080
[Epoch 55; Iter   282/ 1097] train: loss: 0.0495066
[Epoch 55; Iter   312/ 1097] train: loss: 0.0231787
[Epoch 55; Iter   342/ 1097] train: loss: 0.0010309
[Epoch 55; Iter   372/ 1097] train: loss: 0.0034530
[Epoch 55; Iter   402/ 1097] train: loss: 0.0282595
[Epoch 55; Iter   432/ 1097] train: loss: 0.0007857
[Epoch 55; Iter   462/ 1097] train: loss: 0.0057576
[Epoch 55; Iter   492/ 1097] train: loss: 0.0010669
[Epoch 55; Iter   522/ 1097] train: loss: 0.0800724
[Epoch 55; Iter   552/ 1097] train: loss: 0.0004935
[Epoch 55; Iter   582/ 1097] train: loss: 0.0004911
[Epoch 55; Iter   612/ 1097] train: loss: 0.0006768
[Epoch 55; Iter   642/ 1097] train: loss: 0.0012232
[Epoch 55; Iter   672/ 1097] train: loss: 0.0032382
[Epoch 55; Iter   702/ 1097] train: loss: 0.0026872
[Epoch 55; Iter   732/ 1097] train: loss: 0.0033011
[Epoch 55; Iter   762/ 1097] train: loss: 0.0052298
[Epoch 55; Iter   792/ 1097] train: loss: 0.0328434
[Epoch 55; Iter   822/ 1097] train: loss: 0.0057249
[Epoch 55; Iter   852/ 1097] train: loss: 0.0052405
[Epoch 55; Iter   882/ 1097] train: loss: 0.0002074
[Epoch 55; Iter   912/ 1097] train: loss: 0.0004451
[Epoch 55; Iter   942/ 1097] train: loss: 0.0201275
[Epoch 55; Iter   972/ 1097] train: loss: 0.0007684
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0030790
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006244
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0059307
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0011623
[Epoch 55] ogbg-molhiv: 0.787472 val loss: 0.174835
[Epoch 55] ogbg-molhiv: 0.723929 test loss: 0.284910
[Epoch 56; Iter    25/ 1097] train: loss: 0.0020790
[Epoch 56; Iter    55/ 1097] train: loss: 0.0001671
[Epoch 56; Iter    85/ 1097] train: loss: 0.0003906
[Epoch 56; Iter   115/ 1097] train: loss: 0.0001726
[Epoch 56; Iter   145/ 1097] train: loss: 0.0011200
[Epoch 56; Iter   175/ 1097] train: loss: 0.0015463
[Epoch 56; Iter   205/ 1097] train: loss: 0.0021576
[Epoch 56; Iter   235/ 1097] train: loss: 0.0006090
[Epoch 56; Iter   265/ 1097] train: loss: 0.0001436
[Epoch 56; Iter   295/ 1097] train: loss: 0.0004655
[Epoch 56; Iter   325/ 1097] train: loss: 0.0012615
[Epoch 56; Iter   355/ 1097] train: loss: 0.0005070
[Epoch 56; Iter   385/ 1097] train: loss: 0.0016046
[Epoch 56; Iter   415/ 1097] train: loss: 0.0075734
[Epoch 56; Iter   445/ 1097] train: loss: 0.0034935
[Epoch 56; Iter   475/ 1097] train: loss: 0.0007263
[Epoch 56; Iter   505/ 1097] train: loss: 0.0034982
[Epoch 56; Iter   535/ 1097] train: loss: 0.0008515
[Epoch 56; Iter   565/ 1097] train: loss: 0.0058823
[Epoch 56; Iter   595/ 1097] train: loss: 0.0042446
[Epoch 56; Iter   625/ 1097] train: loss: 0.0067577
[Epoch 56; Iter   655/ 1097] train: loss: 0.0005455
[Epoch 56; Iter   685/ 1097] train: loss: 0.0018052
[Epoch 56; Iter   715/ 1097] train: loss: 0.0091072
[Epoch 56; Iter   745/ 1097] train: loss: 0.0015978
[Epoch 56; Iter   775/ 1097] train: loss: 0.0175060
[Epoch 56; Iter   805/ 1097] train: loss: 0.0005394
[Epoch 56; Iter   835/ 1097] train: loss: 0.0008436
[Epoch 56; Iter   865/ 1097] train: loss: 0.0206987
[Epoch 56; Iter   895/ 1097] train: loss: 0.0011992
[Epoch 56; Iter   925/ 1097] train: loss: 0.0030069
[Epoch 56; Iter   955/ 1097] train: loss: 0.0010871
[Epoch 56; Iter   985/ 1097] train: loss: 0.0004671
[Epoch 52; Iter   933/ 1097] train: loss: 0.0015634
[Epoch 52; Iter   963/ 1097] train: loss: 0.0289703
[Epoch 52; Iter   993/ 1097] train: loss: 0.0012196
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0004958
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0047807
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0020922
[Epoch 52] ogbg-molhiv: 0.769673 val loss: 0.176208
[Epoch 52] ogbg-molhiv: 0.714763 test loss: 0.288069
[Epoch 53; Iter    16/ 1097] train: loss: 0.0001943
[Epoch 53; Iter    46/ 1097] train: loss: 0.0286732
[Epoch 53; Iter    76/ 1097] train: loss: 0.0001411
[Epoch 53; Iter   106/ 1097] train: loss: 0.0022504
[Epoch 53; Iter   136/ 1097] train: loss: 0.0005515
[Epoch 53; Iter   166/ 1097] train: loss: 0.0028707
[Epoch 53; Iter   196/ 1097] train: loss: 0.0006496
[Epoch 53; Iter   226/ 1097] train: loss: 0.0002089
[Epoch 53; Iter   256/ 1097] train: loss: 0.0008962
[Epoch 53; Iter   286/ 1097] train: loss: 0.0012369
[Epoch 53; Iter   316/ 1097] train: loss: 0.0005774
[Epoch 53; Iter   346/ 1097] train: loss: 0.0016516
[Epoch 53; Iter   376/ 1097] train: loss: 0.0009192
[Epoch 53; Iter   406/ 1097] train: loss: 0.0007779
[Epoch 53; Iter   436/ 1097] train: loss: 0.0039813
[Epoch 53; Iter   466/ 1097] train: loss: 0.0640969
[Epoch 53; Iter   496/ 1097] train: loss: 0.0008816
[Epoch 53; Iter   526/ 1097] train: loss: 0.1057352
[Epoch 53; Iter   556/ 1097] train: loss: 0.0049190
[Epoch 53; Iter   586/ 1097] train: loss: 0.0008117
[Epoch 53; Iter   616/ 1097] train: loss: 0.0007240
[Epoch 53; Iter   646/ 1097] train: loss: 0.0515315
[Epoch 53; Iter   676/ 1097] train: loss: 0.0218057
[Epoch 53; Iter   706/ 1097] train: loss: 0.0023673
[Epoch 53; Iter   736/ 1097] train: loss: 0.0011561
[Epoch 53; Iter   766/ 1097] train: loss: 0.0086710
[Epoch 53; Iter   796/ 1097] train: loss: 0.0225616
[Epoch 53; Iter   826/ 1097] train: loss: 0.0084014
[Epoch 53; Iter   856/ 1097] train: loss: 0.0125711
[Epoch 53; Iter   886/ 1097] train: loss: 0.0013667
[Epoch 53; Iter   916/ 1097] train: loss: 0.0332931
[Epoch 53; Iter   946/ 1097] train: loss: 0.0025011
[Epoch 53; Iter   976/ 1097] train: loss: 0.0033779
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0003153
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0800719
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0003992
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0561489
[Epoch 53] ogbg-molhiv: 0.764014 val loss: 0.190485
[Epoch 53] ogbg-molhiv: 0.749493 test loss: 0.293656
[Epoch 54; Iter    29/ 1097] train: loss: 0.0024947
[Epoch 54; Iter    59/ 1097] train: loss: 0.0071424
[Epoch 54; Iter    89/ 1097] train: loss: 0.0015860
[Epoch 54; Iter   119/ 1097] train: loss: 0.0094219
[Epoch 54; Iter   149/ 1097] train: loss: 0.0286533
[Epoch 54; Iter   179/ 1097] train: loss: 0.0004300
[Epoch 54; Iter   209/ 1097] train: loss: 0.0002060
[Epoch 54; Iter   239/ 1097] train: loss: 0.0105096
[Epoch 54; Iter   269/ 1097] train: loss: 0.0021572
[Epoch 54; Iter   299/ 1097] train: loss: 0.0001096
[Epoch 54; Iter   329/ 1097] train: loss: 0.0065776
[Epoch 54; Iter   359/ 1097] train: loss: 0.0028813
[Epoch 54; Iter   389/ 1097] train: loss: 0.0002475
[Epoch 54; Iter   419/ 1097] train: loss: 0.0000370
[Epoch 54; Iter   449/ 1097] train: loss: 0.0001535
[Epoch 54; Iter   479/ 1097] train: loss: 0.0066076
[Epoch 54; Iter   509/ 1097] train: loss: 0.0010027
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003603
[Epoch 54; Iter   569/ 1097] train: loss: 0.0008222
[Epoch 54; Iter   599/ 1097] train: loss: 0.0677770
[Epoch 54; Iter   629/ 1097] train: loss: 0.0041506
[Epoch 54; Iter   659/ 1097] train: loss: 0.0002349
[Epoch 54; Iter   689/ 1097] train: loss: 0.0003115
[Epoch 54; Iter   719/ 1097] train: loss: 0.0015540
[Epoch 54; Iter   749/ 1097] train: loss: 0.0124521
[Epoch 54; Iter   779/ 1097] train: loss: 0.0001123
[Epoch 54; Iter   809/ 1097] train: loss: 0.0033854
[Epoch 54; Iter   839/ 1097] train: loss: 0.0068595
[Epoch 54; Iter   869/ 1097] train: loss: 0.0009779
[Epoch 54; Iter   899/ 1097] train: loss: 0.0149395
[Epoch 54; Iter   929/ 1097] train: loss: 0.0009884
[Epoch 54; Iter   959/ 1097] train: loss: 0.0003477
[Epoch 54; Iter   989/ 1097] train: loss: 0.0007684
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0001690
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0046837
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0021983
[Epoch 54] ogbg-molhiv: 0.778810 val loss: 0.171470
[Epoch 54] ogbg-molhiv: 0.706541 test loss: 0.297502
[Epoch 55; Iter    12/ 1097] train: loss: 0.0049411
[Epoch 55; Iter    42/ 1097] train: loss: 0.0053384
[Epoch 55; Iter    72/ 1097] train: loss: 0.0018461
[Epoch 55; Iter   102/ 1097] train: loss: 0.0080379
[Epoch 55; Iter   132/ 1097] train: loss: 0.0350705
[Epoch 55; Iter   162/ 1097] train: loss: 0.0003802
[Epoch 55; Iter   192/ 1097] train: loss: 0.0003104
[Epoch 55; Iter   222/ 1097] train: loss: 0.0002386
[Epoch 55; Iter   252/ 1097] train: loss: 0.0001367
[Epoch 55; Iter   282/ 1097] train: loss: 0.0010998
[Epoch 55; Iter   312/ 1097] train: loss: 0.0002271
[Epoch 55; Iter   342/ 1097] train: loss: 0.0027326
[Epoch 55; Iter   372/ 1097] train: loss: 0.0024930
[Epoch 55; Iter   402/ 1097] train: loss: 0.0006037
[Epoch 55; Iter   432/ 1097] train: loss: 0.0245377
[Epoch 55; Iter   462/ 1097] train: loss: 0.0002809
[Epoch 55; Iter   492/ 1097] train: loss: 0.0207993
[Epoch 55; Iter   522/ 1097] train: loss: 0.0117656
[Epoch 55; Iter   552/ 1097] train: loss: 0.0002702
[Epoch 55; Iter   582/ 1097] train: loss: 0.0443012
[Epoch 55; Iter   612/ 1097] train: loss: 0.0364672
[Epoch 55; Iter   642/ 1097] train: loss: 0.0016898
[Epoch 55; Iter   672/ 1097] train: loss: 0.0009563
[Epoch 55; Iter   702/ 1097] train: loss: 0.0002590
[Epoch 55; Iter   732/ 1097] train: loss: 0.0001044
[Epoch 55; Iter   762/ 1097] train: loss: 0.0002072
[Epoch 55; Iter   792/ 1097] train: loss: 0.0015601
[Epoch 55; Iter   822/ 1097] train: loss: 0.0197545
[Epoch 55; Iter   852/ 1097] train: loss: 0.0002646
[Epoch 55; Iter   882/ 1097] train: loss: 0.0700714
[Epoch 55; Iter   912/ 1097] train: loss: 0.0048733
[Epoch 55; Iter   942/ 1097] train: loss: 0.0003399
[Epoch 55; Iter   972/ 1097] train: loss: 0.0000893
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0009117
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0031250
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0003874
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0015505
[Epoch 55] ogbg-molhiv: 0.761519 val loss: 0.187804
[Epoch 55] ogbg-molhiv: 0.707868 test loss: 0.313191
[Epoch 56; Iter    25/ 1097] train: loss: 0.0007692
[Epoch 56; Iter    55/ 1097] train: loss: 0.0279245
[Epoch 56; Iter    85/ 1097] train: loss: 0.0252612
[Epoch 56; Iter   115/ 1097] train: loss: 0.0007466
[Epoch 56; Iter   145/ 1097] train: loss: 0.0476725
[Epoch 56; Iter   175/ 1097] train: loss: 0.0004596
[Epoch 56; Iter   205/ 1097] train: loss: 0.1400725
[Epoch 56; Iter   235/ 1097] train: loss: 0.0002154
[Epoch 56; Iter   265/ 1097] train: loss: 0.0045345
[Epoch 56; Iter   295/ 1097] train: loss: 0.0157141
[Epoch 56; Iter   325/ 1097] train: loss: 0.0000930
[Epoch 56; Iter   355/ 1097] train: loss: 0.0052613
[Epoch 56; Iter   385/ 1097] train: loss: 0.0115916
[Epoch 56; Iter   415/ 1097] train: loss: 0.0003662
[Epoch 56; Iter   445/ 1097] train: loss: 0.0010999
[Epoch 56; Iter   475/ 1097] train: loss: 0.0167441
[Epoch 56; Iter   505/ 1097] train: loss: 0.0001458
[Epoch 56; Iter   535/ 1097] train: loss: 0.0032268
[Epoch 56; Iter   565/ 1097] train: loss: 0.0016662
[Epoch 56; Iter   595/ 1097] train: loss: 0.0155509
[Epoch 56; Iter   625/ 1097] train: loss: 0.0166186
[Epoch 56; Iter   655/ 1097] train: loss: 0.0995750
[Epoch 56; Iter   685/ 1097] train: loss: 0.0206354
[Epoch 56; Iter   715/ 1097] train: loss: 0.0009914
[Epoch 56; Iter   745/ 1097] train: loss: 0.0010898
[Epoch 56; Iter   775/ 1097] train: loss: 0.0014186
[Epoch 56; Iter   805/ 1097] train: loss: 0.0014014
[Epoch 56; Iter   835/ 1097] train: loss: 0.0421863
[Epoch 56; Iter   865/ 1097] train: loss: 0.2276533
[Epoch 56; Iter   895/ 1097] train: loss: 0.1669138
[Epoch 56; Iter   925/ 1097] train: loss: 0.0005769
[Epoch 56; Iter   955/ 1097] train: loss: 0.0076154
[Epoch 56; Iter   985/ 1097] train: loss: 0.0033693
[Epoch 52; Iter   933/ 1097] train: loss: 0.0015891
[Epoch 52; Iter   963/ 1097] train: loss: 0.0025521
[Epoch 52; Iter   993/ 1097] train: loss: 0.0006828
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0021561
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0010678
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0002328
[Epoch 52] ogbg-molhiv: 0.806894 val loss: 0.239582
[Epoch 52] ogbg-molhiv: 0.810477 test loss: 0.253745
[Epoch 53; Iter    16/ 1097] train: loss: 0.0024214
[Epoch 53; Iter    46/ 1097] train: loss: 0.0319833
[Epoch 53; Iter    76/ 1097] train: loss: 0.0009426
[Epoch 53; Iter   106/ 1097] train: loss: 0.0008821
[Epoch 53; Iter   136/ 1097] train: loss: 0.0006408
[Epoch 53; Iter   166/ 1097] train: loss: 0.0013285
[Epoch 53; Iter   196/ 1097] train: loss: 0.0062629
[Epoch 53; Iter   226/ 1097] train: loss: 0.0021044
[Epoch 53; Iter   256/ 1097] train: loss: 0.0018218
[Epoch 53; Iter   286/ 1097] train: loss: 0.0009147
[Epoch 53; Iter   316/ 1097] train: loss: 0.0008767
[Epoch 53; Iter   346/ 1097] train: loss: 0.0000724
[Epoch 53; Iter   376/ 1097] train: loss: 0.0002312
[Epoch 53; Iter   406/ 1097] train: loss: 0.0000906
[Epoch 53; Iter   436/ 1097] train: loss: 0.0396583
[Epoch 53; Iter   466/ 1097] train: loss: 0.0081111
[Epoch 53; Iter   496/ 1097] train: loss: 0.0019080
[Epoch 53; Iter   526/ 1097] train: loss: 0.0011053
[Epoch 53; Iter   556/ 1097] train: loss: 0.0003857
[Epoch 53; Iter   586/ 1097] train: loss: 0.0009657
[Epoch 53; Iter   616/ 1097] train: loss: 0.0006634
[Epoch 53; Iter   646/ 1097] train: loss: 0.0006807
[Epoch 53; Iter   676/ 1097] train: loss: 0.0043106
[Epoch 53; Iter   706/ 1097] train: loss: 0.0016820
[Epoch 53; Iter   736/ 1097] train: loss: 0.0164399
[Epoch 53; Iter   766/ 1097] train: loss: 0.0001309
[Epoch 53; Iter   796/ 1097] train: loss: 0.0005791
[Epoch 53; Iter   826/ 1097] train: loss: 0.0074077
[Epoch 53; Iter   856/ 1097] train: loss: 0.0000734
[Epoch 53; Iter   886/ 1097] train: loss: 0.0074309
[Epoch 53; Iter   916/ 1097] train: loss: 0.0026337
[Epoch 53; Iter   946/ 1097] train: loss: 0.0015037
[Epoch 53; Iter   976/ 1097] train: loss: 0.0007714
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0052245
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0005615
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0210174
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0018393
[Epoch 53] ogbg-molhiv: 0.788544 val loss: 0.231289
[Epoch 53] ogbg-molhiv: 0.795236 test loss: 0.246967
[Epoch 54; Iter    29/ 1097] train: loss: 0.0002683
[Epoch 54; Iter    59/ 1097] train: loss: 0.0004305
[Epoch 54; Iter    89/ 1097] train: loss: 0.0008942
[Epoch 54; Iter   119/ 1097] train: loss: 0.0061263
[Epoch 54; Iter   149/ 1097] train: loss: 0.0033245
[Epoch 54; Iter   179/ 1097] train: loss: 0.0028397
[Epoch 54; Iter   209/ 1097] train: loss: 0.0032648
[Epoch 54; Iter   239/ 1097] train: loss: 0.0126264
[Epoch 54; Iter   269/ 1097] train: loss: 0.0015582
[Epoch 54; Iter   299/ 1097] train: loss: 0.0049079
[Epoch 54; Iter   329/ 1097] train: loss: 0.0014331
[Epoch 54; Iter   359/ 1097] train: loss: 0.0044325
[Epoch 54; Iter   389/ 1097] train: loss: 0.0136019
[Epoch 54; Iter   419/ 1097] train: loss: 0.0077096
[Epoch 54; Iter   449/ 1097] train: loss: 0.0014941
[Epoch 54; Iter   479/ 1097] train: loss: 0.0016752
[Epoch 54; Iter   509/ 1097] train: loss: 0.0006319
[Epoch 54; Iter   539/ 1097] train: loss: 0.0742437
[Epoch 54; Iter   569/ 1097] train: loss: 0.0008861
[Epoch 54; Iter   599/ 1097] train: loss: 0.0102814
[Epoch 54; Iter   629/ 1097] train: loss: 0.0294331
[Epoch 54; Iter   659/ 1097] train: loss: 0.0110766
[Epoch 54; Iter   689/ 1097] train: loss: 0.0005752
[Epoch 54; Iter   719/ 1097] train: loss: 0.0032273
[Epoch 54; Iter   749/ 1097] train: loss: 0.0032430
[Epoch 54; Iter   779/ 1097] train: loss: 0.0007355
[Epoch 54; Iter   809/ 1097] train: loss: 0.0010885
[Epoch 54; Iter   839/ 1097] train: loss: 0.0018096
[Epoch 54; Iter   869/ 1097] train: loss: 0.0151779
[Epoch 54; Iter   899/ 1097] train: loss: 0.0001445
[Epoch 54; Iter   929/ 1097] train: loss: 0.0229026
[Epoch 54; Iter   959/ 1097] train: loss: 0.0639208
[Epoch 54; Iter   989/ 1097] train: loss: 0.0143992
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0007139
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0027010
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0008394
[Epoch 54] ogbg-molhiv: 0.758497 val loss: 0.289612
[Epoch 54] ogbg-molhiv: 0.791495 test loss: 0.302725
[Epoch 55; Iter    12/ 1097] train: loss: 0.0005438
[Epoch 55; Iter    42/ 1097] train: loss: 0.0001374
[Epoch 55; Iter    72/ 1097] train: loss: 0.0006767
[Epoch 55; Iter   102/ 1097] train: loss: 0.0001630
[Epoch 55; Iter   132/ 1097] train: loss: 0.0022818
[Epoch 55; Iter   162/ 1097] train: loss: 0.0879759
[Epoch 55; Iter   192/ 1097] train: loss: 0.0000964
[Epoch 55; Iter   222/ 1097] train: loss: 0.0008039
[Epoch 55; Iter   252/ 1097] train: loss: 0.0005113
[Epoch 55; Iter   282/ 1097] train: loss: 0.0018126
[Epoch 55; Iter   312/ 1097] train: loss: 0.0010958
[Epoch 55; Iter   342/ 1097] train: loss: 0.0001628
[Epoch 55; Iter   372/ 1097] train: loss: 0.0400668
[Epoch 55; Iter   402/ 1097] train: loss: 0.0012199
[Epoch 55; Iter   432/ 1097] train: loss: 0.0003688
[Epoch 55; Iter   462/ 1097] train: loss: 0.0015386
[Epoch 55; Iter   492/ 1097] train: loss: 0.0384678
[Epoch 55; Iter   522/ 1097] train: loss: 0.0072312
[Epoch 55; Iter   552/ 1097] train: loss: 0.0055826
[Epoch 55; Iter   582/ 1097] train: loss: 0.0008545
[Epoch 55; Iter   612/ 1097] train: loss: 0.0002229
[Epoch 55; Iter   642/ 1097] train: loss: 0.0199346
[Epoch 55; Iter   672/ 1097] train: loss: 0.0024381
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010556
[Epoch 55; Iter   732/ 1097] train: loss: 0.0020713
[Epoch 55; Iter   762/ 1097] train: loss: 0.0000792
[Epoch 55; Iter   792/ 1097] train: loss: 0.0001110
[Epoch 55; Iter   822/ 1097] train: loss: 0.0210091
[Epoch 55; Iter   852/ 1097] train: loss: 0.0007398
[Epoch 55; Iter   882/ 1097] train: loss: 0.0194704
[Epoch 55; Iter   912/ 1097] train: loss: 0.0011139
[Epoch 55; Iter   942/ 1097] train: loss: 0.0011565
[Epoch 55; Iter   972/ 1097] train: loss: 0.0001217
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0002443
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0029525
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0004683
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0047643
[Epoch 55] ogbg-molhiv: 0.769725 val loss: 0.245063
[Epoch 55] ogbg-molhiv: 0.792495 test loss: 0.274611
[Epoch 56; Iter    25/ 1097] train: loss: 0.0010662
[Epoch 56; Iter    55/ 1097] train: loss: 0.0640717
[Epoch 56; Iter    85/ 1097] train: loss: 0.0006478
[Epoch 56; Iter   115/ 1097] train: loss: 0.0001336
[Epoch 56; Iter   145/ 1097] train: loss: 0.0003461
[Epoch 56; Iter   175/ 1097] train: loss: 0.0005843
[Epoch 56; Iter   205/ 1097] train: loss: 0.0033805
[Epoch 56; Iter   235/ 1097] train: loss: 0.0001470
[Epoch 56; Iter   265/ 1097] train: loss: 0.0007074
[Epoch 56; Iter   295/ 1097] train: loss: 0.0000772
[Epoch 56; Iter   325/ 1097] train: loss: 0.0003861
[Epoch 56; Iter   355/ 1097] train: loss: 0.0009175
[Epoch 56; Iter   385/ 1097] train: loss: 0.0008107
[Epoch 56; Iter   415/ 1097] train: loss: 0.0028411
[Epoch 56; Iter   445/ 1097] train: loss: 0.0005279
[Epoch 56; Iter   475/ 1097] train: loss: 0.0028525
[Epoch 56; Iter   505/ 1097] train: loss: 0.0008560
[Epoch 56; Iter   535/ 1097] train: loss: 0.0021706
[Epoch 56; Iter   565/ 1097] train: loss: 0.0001570
[Epoch 56; Iter   595/ 1097] train: loss: 0.0013947
[Epoch 56; Iter   625/ 1097] train: loss: 0.0288570
[Epoch 56; Iter   655/ 1097] train: loss: 0.0004101
[Epoch 56; Iter   685/ 1097] train: loss: 0.0001035
[Epoch 56; Iter   715/ 1097] train: loss: 0.0002401
[Epoch 56; Iter   745/ 1097] train: loss: 0.0003077
[Epoch 56; Iter   775/ 1097] train: loss: 0.0003993
[Epoch 56; Iter   805/ 1097] train: loss: 0.0003860
[Epoch 56; Iter   835/ 1097] train: loss: 0.0058547
[Epoch 56; Iter   865/ 1097] train: loss: 0.0002302
[Epoch 56; Iter   895/ 1097] train: loss: 0.0012310
[Epoch 56; Iter   925/ 1097] train: loss: 0.0020381
[Epoch 56; Iter   955/ 1097] train: loss: 0.0163018
[Epoch 56; Iter   985/ 1097] train: loss: 0.0000150
[Epoch 52; Iter   933/ 1097] train: loss: 0.0932286
[Epoch 52; Iter   963/ 1097] train: loss: 0.0009692
[Epoch 52; Iter   993/ 1097] train: loss: 0.0003252
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0001990
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0001932
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0024029
[Epoch 52] ogbg-molhiv: 0.666596 val loss: 1.610110
[Epoch 52] ogbg-molhiv: 0.576317 test loss: 1.533130
[Epoch 53; Iter    16/ 1097] train: loss: 0.0161883
[Epoch 53; Iter    46/ 1097] train: loss: 0.0001615
[Epoch 53; Iter    76/ 1097] train: loss: 0.0000630
[Epoch 53; Iter   106/ 1097] train: loss: 0.0017181
[Epoch 53; Iter   136/ 1097] train: loss: 0.0547010
[Epoch 53; Iter   166/ 1097] train: loss: 0.0002782
[Epoch 53; Iter   196/ 1097] train: loss: 0.0003206
[Epoch 53; Iter   226/ 1097] train: loss: 0.0036314
[Epoch 53; Iter   256/ 1097] train: loss: 0.0001676
[Epoch 53; Iter   286/ 1097] train: loss: 0.0001046
[Epoch 53; Iter   316/ 1097] train: loss: 0.0011333
[Epoch 53; Iter   346/ 1097] train: loss: 0.0036653
[Epoch 53; Iter   376/ 1097] train: loss: 0.0006368
[Epoch 53; Iter   406/ 1097] train: loss: 0.0006617
[Epoch 53; Iter   436/ 1097] train: loss: 0.0137977
[Epoch 53; Iter   466/ 1097] train: loss: 0.0807830
[Epoch 53; Iter   496/ 1097] train: loss: 0.0055905
[Epoch 53; Iter   526/ 1097] train: loss: 0.0011101
[Epoch 53; Iter   556/ 1097] train: loss: 0.0604126
[Epoch 53; Iter   586/ 1097] train: loss: 0.0020566
[Epoch 53; Iter   616/ 1097] train: loss: 0.0222970
[Epoch 53; Iter   646/ 1097] train: loss: 0.0187933
[Epoch 53; Iter   676/ 1097] train: loss: 0.0696265
[Epoch 53; Iter   706/ 1097] train: loss: 0.0009746
[Epoch 53; Iter   736/ 1097] train: loss: 0.0015504
[Epoch 53; Iter   766/ 1097] train: loss: 0.0001858
[Epoch 53; Iter   796/ 1097] train: loss: 0.0062511
[Epoch 53; Iter   826/ 1097] train: loss: 0.0075927
[Epoch 53; Iter   856/ 1097] train: loss: 0.0025018
[Epoch 53; Iter   886/ 1097] train: loss: 0.0046889
[Epoch 53; Iter   916/ 1097] train: loss: 0.0003180
[Epoch 53; Iter   946/ 1097] train: loss: 0.0011796
[Epoch 53; Iter   976/ 1097] train: loss: 0.0024662
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0046970
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0019975
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0080428
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0149175
[Epoch 53] ogbg-molhiv: 0.683902 val loss: 1.977064
[Epoch 53] ogbg-molhiv: 0.620582 test loss: 2.124421
[Epoch 54; Iter    29/ 1097] train: loss: 0.0138078
[Epoch 54; Iter    59/ 1097] train: loss: 0.0001458
[Epoch 54; Iter    89/ 1097] train: loss: 0.0001011
[Epoch 54; Iter   119/ 1097] train: loss: 0.0028927
[Epoch 54; Iter   149/ 1097] train: loss: 0.0138368
[Epoch 54; Iter   179/ 1097] train: loss: 0.0000357
[Epoch 54; Iter   209/ 1097] train: loss: 0.0006584
[Epoch 54; Iter   239/ 1097] train: loss: 0.0002832
[Epoch 54; Iter   269/ 1097] train: loss: 0.0146181
[Epoch 54; Iter   299/ 1097] train: loss: 0.0047437
[Epoch 54; Iter   329/ 1097] train: loss: 0.0009858
[Epoch 54; Iter   359/ 1097] train: loss: 0.0122032
[Epoch 54; Iter   389/ 1097] train: loss: 0.0002942
[Epoch 54; Iter   419/ 1097] train: loss: 0.0013354
[Epoch 54; Iter   449/ 1097] train: loss: 0.0022954
[Epoch 54; Iter   479/ 1097] train: loss: 0.0368526
[Epoch 54; Iter   509/ 1097] train: loss: 0.0005409
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003536
[Epoch 54; Iter   569/ 1097] train: loss: 0.0015230
[Epoch 54; Iter   599/ 1097] train: loss: 0.0588159
[Epoch 54; Iter   629/ 1097] train: loss: 0.1010934
[Epoch 54; Iter   659/ 1097] train: loss: 0.0380899
[Epoch 54; Iter   689/ 1097] train: loss: 0.0007742
[Epoch 54; Iter   719/ 1097] train: loss: 0.0015494
[Epoch 54; Iter   749/ 1097] train: loss: 0.0037782
[Epoch 54; Iter   779/ 1097] train: loss: 0.0001849
[Epoch 54; Iter   809/ 1097] train: loss: 0.0019214
[Epoch 54; Iter   839/ 1097] train: loss: 0.0346177
[Epoch 54; Iter   869/ 1097] train: loss: 0.0012648
[Epoch 54; Iter   899/ 1097] train: loss: 0.0001822
[Epoch 54; Iter   929/ 1097] train: loss: 0.0004601
[Epoch 54; Iter   959/ 1097] train: loss: 0.0004666
[Epoch 54; Iter   989/ 1097] train: loss: 0.0072446
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0001183
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0056912
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0000237
[Epoch 54] ogbg-molhiv: 0.695360 val loss: 2.671744
[Epoch 54] ogbg-molhiv: 0.584592 test loss: 4.446673
[Epoch 55; Iter    12/ 1097] train: loss: 0.0009821
[Epoch 55; Iter    42/ 1097] train: loss: 0.0000338
[Epoch 55; Iter    72/ 1097] train: loss: 0.0001068
[Epoch 55; Iter   102/ 1097] train: loss: 0.0003642
[Epoch 55; Iter   132/ 1097] train: loss: 0.0006216
[Epoch 55; Iter   162/ 1097] train: loss: 0.0003711
[Epoch 55; Iter   192/ 1097] train: loss: 0.0007971
[Epoch 55; Iter   222/ 1097] train: loss: 0.0017829
[Epoch 55; Iter   252/ 1097] train: loss: 0.0008518
[Epoch 55; Iter   282/ 1097] train: loss: 0.0079717
[Epoch 55; Iter   312/ 1097] train: loss: 0.0000989
[Epoch 55; Iter   342/ 1097] train: loss: 0.0005574
[Epoch 55; Iter   372/ 1097] train: loss: 0.0047590
[Epoch 55; Iter   402/ 1097] train: loss: 0.0002145
[Epoch 55; Iter   432/ 1097] train: loss: 0.0077354
[Epoch 55; Iter   462/ 1097] train: loss: 0.0046610
[Epoch 55; Iter   492/ 1097] train: loss: 0.0062463
[Epoch 55; Iter   522/ 1097] train: loss: 0.0001739
[Epoch 55; Iter   552/ 1097] train: loss: 0.0000600
[Epoch 55; Iter   582/ 1097] train: loss: 0.0014275
[Epoch 55; Iter   612/ 1097] train: loss: 0.0000469
[Epoch 55; Iter   642/ 1097] train: loss: 0.0002230
[Epoch 55; Iter   672/ 1097] train: loss: 0.0056418
[Epoch 55; Iter   702/ 1097] train: loss: 0.0045407
[Epoch 55; Iter   732/ 1097] train: loss: 0.0005322
[Epoch 55; Iter   762/ 1097] train: loss: 0.0001261
[Epoch 55; Iter   792/ 1097] train: loss: 0.0010656
[Epoch 55; Iter   822/ 1097] train: loss: 0.0003491
[Epoch 55; Iter   852/ 1097] train: loss: 0.0017189
[Epoch 55; Iter   882/ 1097] train: loss: 0.0074907
[Epoch 55; Iter   912/ 1097] train: loss: 0.0001048
[Epoch 55; Iter   942/ 1097] train: loss: 0.0340014
[Epoch 55; Iter   972/ 1097] train: loss: 0.0043844
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0011919
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0629192
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0009870
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0022996
[Epoch 55] ogbg-molhiv: 0.707745 val loss: 5.798467
[Epoch 55] ogbg-molhiv: 0.588855 test loss: 8.305367
[Epoch 56; Iter    25/ 1097] train: loss: 0.0002214
[Epoch 56; Iter    55/ 1097] train: loss: 0.0011640
[Epoch 56; Iter    85/ 1097] train: loss: 0.0002694
[Epoch 56; Iter   115/ 1097] train: loss: 0.0000143
[Epoch 56; Iter   145/ 1097] train: loss: 0.0022471
[Epoch 56; Iter   175/ 1097] train: loss: 0.0006818
[Epoch 56; Iter   205/ 1097] train: loss: 0.0145786
[Epoch 56; Iter   235/ 1097] train: loss: 0.0151339
[Epoch 56; Iter   265/ 1097] train: loss: 0.0003763
[Epoch 56; Iter   295/ 1097] train: loss: 0.0014513
[Epoch 56; Iter   325/ 1097] train: loss: 0.0382452
[Epoch 56; Iter   355/ 1097] train: loss: 0.0003635
[Epoch 56; Iter   385/ 1097] train: loss: 0.0081653
[Epoch 56; Iter   415/ 1097] train: loss: 0.0007058
[Epoch 56; Iter   445/ 1097] train: loss: 0.0003862
[Epoch 56; Iter   475/ 1097] train: loss: 0.0004218
[Epoch 56; Iter   505/ 1097] train: loss: 0.0001398
[Epoch 56; Iter   535/ 1097] train: loss: 0.0001228
[Epoch 56; Iter   565/ 1097] train: loss: 0.0000546
[Epoch 56; Iter   595/ 1097] train: loss: 0.0064505
[Epoch 56; Iter   625/ 1097] train: loss: 0.0016691
[Epoch 56; Iter   655/ 1097] train: loss: 0.0012204
[Epoch 56; Iter   685/ 1097] train: loss: 0.0000302
[Epoch 56; Iter   715/ 1097] train: loss: 0.0032421
[Epoch 56; Iter   745/ 1097] train: loss: 0.0068574
[Epoch 56; Iter   775/ 1097] train: loss: 0.0003217
[Epoch 56; Iter   805/ 1097] train: loss: 0.0000649
[Epoch 56; Iter   835/ 1097] train: loss: 0.0000378
[Epoch 56; Iter   865/ 1097] train: loss: 0.0005735
[Epoch 56; Iter   895/ 1097] train: loss: 0.0003756
[Epoch 56; Iter   925/ 1097] train: loss: 0.0002368
[Epoch 56; Iter   955/ 1097] train: loss: 0.0000439
[Epoch 56; Iter   985/ 1097] train: loss: 0.0043377
[Epoch 52; Iter   933/ 1097] train: loss: 0.0769051
[Epoch 52; Iter   963/ 1097] train: loss: 0.0254303
[Epoch 52; Iter   993/ 1097] train: loss: 0.0081601
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0129766
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0016112
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0068517
[Epoch 52] ogbg-molhiv: 0.781489 val loss: 11.240899
[Epoch 52] ogbg-molhiv: 0.709919 test loss: 14.885870
[Epoch 53; Iter    16/ 1097] train: loss: 0.0004178
[Epoch 53; Iter    46/ 1097] train: loss: 0.0018576
[Epoch 53; Iter    76/ 1097] train: loss: 0.0024346
[Epoch 53; Iter   106/ 1097] train: loss: 0.0027868
[Epoch 53; Iter   136/ 1097] train: loss: 0.0033065
[Epoch 53; Iter   166/ 1097] train: loss: 0.0012993
[Epoch 53; Iter   196/ 1097] train: loss: 0.0027569
[Epoch 53; Iter   226/ 1097] train: loss: 0.0262946
[Epoch 53; Iter   256/ 1097] train: loss: 0.0008259
[Epoch 53; Iter   286/ 1097] train: loss: 0.0160894
[Epoch 53; Iter   316/ 1097] train: loss: 0.0140489
[Epoch 53; Iter   346/ 1097] train: loss: 0.0024376
[Epoch 53; Iter   376/ 1097] train: loss: 0.0022675
[Epoch 53; Iter   406/ 1097] train: loss: 0.0297333
[Epoch 53; Iter   436/ 1097] train: loss: 0.0014574
[Epoch 53; Iter   466/ 1097] train: loss: 0.0015632
[Epoch 53; Iter   496/ 1097] train: loss: 0.0003822
[Epoch 53; Iter   526/ 1097] train: loss: 0.0002047
[Epoch 53; Iter   556/ 1097] train: loss: 0.0096629
[Epoch 53; Iter   586/ 1097] train: loss: 0.0012058
[Epoch 53; Iter   616/ 1097] train: loss: 0.0222479
[Epoch 53; Iter   646/ 1097] train: loss: 0.0049436
[Epoch 53; Iter   676/ 1097] train: loss: 0.0052513
[Epoch 53; Iter   706/ 1097] train: loss: 0.0220315
[Epoch 53; Iter   736/ 1097] train: loss: 0.0466450
[Epoch 53; Iter   766/ 1097] train: loss: 0.0236163
[Epoch 53; Iter   796/ 1097] train: loss: 0.0010150
[Epoch 53; Iter   826/ 1097] train: loss: 0.0164654
[Epoch 53; Iter   856/ 1097] train: loss: 0.0015171
[Epoch 53; Iter   886/ 1097] train: loss: 0.0036134
[Epoch 53; Iter   916/ 1097] train: loss: 0.0251964
[Epoch 53; Iter   946/ 1097] train: loss: 0.0228266
[Epoch 53; Iter   976/ 1097] train: loss: 0.0001072
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0117672
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0016134
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0016998
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0310368
[Epoch 53] ogbg-molhiv: 0.761433 val loss: 23.633201
[Epoch 53] ogbg-molhiv: 0.675616 test loss: 17.904551
[Epoch 54; Iter    29/ 1097] train: loss: 0.0246282
[Epoch 54; Iter    59/ 1097] train: loss: 0.0010786
[Epoch 54; Iter    89/ 1097] train: loss: 0.0104839
[Epoch 54; Iter   119/ 1097] train: loss: 0.0071761
[Epoch 54; Iter   149/ 1097] train: loss: 0.0023650
[Epoch 54; Iter   179/ 1097] train: loss: 0.0184945
[Epoch 54; Iter   209/ 1097] train: loss: 0.0084463
[Epoch 54; Iter   239/ 1097] train: loss: 0.0019591
[Epoch 54; Iter   269/ 1097] train: loss: 0.0156296
[Epoch 54; Iter   299/ 1097] train: loss: 0.0027339
[Epoch 54; Iter   329/ 1097] train: loss: 0.0140579
[Epoch 54; Iter   359/ 1097] train: loss: 0.0246829
[Epoch 54; Iter   389/ 1097] train: loss: 0.0278478
[Epoch 54; Iter   419/ 1097] train: loss: 0.0159003
[Epoch 54; Iter   449/ 1097] train: loss: 0.0001085
[Epoch 54; Iter   479/ 1097] train: loss: 0.0270663
[Epoch 54; Iter   509/ 1097] train: loss: 0.0015499
[Epoch 54; Iter   539/ 1097] train: loss: 0.1676035
[Epoch 54; Iter   569/ 1097] train: loss: 0.0069084
[Epoch 54; Iter   599/ 1097] train: loss: 0.0070835
[Epoch 54; Iter   629/ 1097] train: loss: 0.0070405
[Epoch 54; Iter   659/ 1097] train: loss: 0.0426168
[Epoch 54; Iter   689/ 1097] train: loss: 0.0005524
[Epoch 54; Iter   719/ 1097] train: loss: 0.0006923
[Epoch 54; Iter   749/ 1097] train: loss: 0.0106496
[Epoch 54; Iter   779/ 1097] train: loss: 0.0410852
[Epoch 54; Iter   809/ 1097] train: loss: 0.0001856
[Epoch 54; Iter   839/ 1097] train: loss: 0.0121923
[Epoch 54; Iter   869/ 1097] train: loss: 0.0051656
[Epoch 54; Iter   899/ 1097] train: loss: 0.1022769
[Epoch 54; Iter   929/ 1097] train: loss: 0.0006206
[Epoch 54; Iter   959/ 1097] train: loss: 0.0041894
[Epoch 54; Iter   989/ 1097] train: loss: 0.0991740
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0672332
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0006992
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0017788
[Epoch 54] ogbg-molhiv: 0.744366 val loss: 16.255317
[Epoch 54] ogbg-molhiv: 0.678443 test loss: 16.657932
[Epoch 55; Iter    12/ 1097] train: loss: 0.0029243
[Epoch 55; Iter    42/ 1097] train: loss: 0.0080759
[Epoch 55; Iter    72/ 1097] train: loss: 0.0020173
[Epoch 55; Iter   102/ 1097] train: loss: 0.0015031
[Epoch 55; Iter   132/ 1097] train: loss: 0.0014576
[Epoch 55; Iter   162/ 1097] train: loss: 0.0000775
[Epoch 55; Iter   192/ 1097] train: loss: 0.0288459
[Epoch 55; Iter   222/ 1097] train: loss: 0.0538865
[Epoch 55; Iter   252/ 1097] train: loss: 0.0071889
[Epoch 55; Iter   282/ 1097] train: loss: 0.0007111
[Epoch 55; Iter   312/ 1097] train: loss: 0.0027222
[Epoch 55; Iter   342/ 1097] train: loss: 0.0053133
[Epoch 55; Iter   372/ 1097] train: loss: 0.0163098
[Epoch 55; Iter   402/ 1097] train: loss: 0.0030605
[Epoch 55; Iter   432/ 1097] train: loss: 0.0021253
[Epoch 55; Iter   462/ 1097] train: loss: 0.0011081
[Epoch 55; Iter   492/ 1097] train: loss: 0.0126013
[Epoch 55; Iter   522/ 1097] train: loss: 0.0004787
[Epoch 55; Iter   552/ 1097] train: loss: 0.0012100
[Epoch 55; Iter   582/ 1097] train: loss: 0.0024839
[Epoch 55; Iter   612/ 1097] train: loss: 0.0054339
[Epoch 55; Iter   642/ 1097] train: loss: 0.0386707
[Epoch 55; Iter   672/ 1097] train: loss: 0.0087338
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010663
[Epoch 55; Iter   732/ 1097] train: loss: 0.0006644
[Epoch 55; Iter   762/ 1097] train: loss: 0.0041387
[Epoch 55; Iter   792/ 1097] train: loss: 0.0013964
[Epoch 55; Iter   822/ 1097] train: loss: 0.1943284
[Epoch 55; Iter   852/ 1097] train: loss: 0.0003247
[Epoch 55; Iter   882/ 1097] train: loss: 0.0086901
[Epoch 55; Iter   912/ 1097] train: loss: 0.2953227
[Epoch 55; Iter   942/ 1097] train: loss: 0.0014560
[Epoch 55; Iter   972/ 1097] train: loss: 0.0018501
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0104942
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006020
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0032003
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0015956
[Epoch 55] ogbg-molhiv: 0.761987 val loss: 10.458780
[Epoch 55] ogbg-molhiv: 0.690589 test loss: 7.797542
[Epoch 56; Iter    25/ 1097] train: loss: 0.0020286
[Epoch 56; Iter    55/ 1097] train: loss: 0.0090678
[Epoch 56; Iter    85/ 1097] train: loss: 0.0019548
[Epoch 56; Iter   115/ 1097] train: loss: 0.0008164
[Epoch 56; Iter   145/ 1097] train: loss: 0.0002882
[Epoch 56; Iter   175/ 1097] train: loss: 0.0014484
[Epoch 56; Iter   205/ 1097] train: loss: 0.0045290
[Epoch 56; Iter   235/ 1097] train: loss: 0.0012022
[Epoch 56; Iter   265/ 1097] train: loss: 0.0037751
[Epoch 56; Iter   295/ 1097] train: loss: 0.0072521
[Epoch 56; Iter   325/ 1097] train: loss: 0.0459089
[Epoch 56; Iter   355/ 1097] train: loss: 0.0028603
[Epoch 56; Iter   385/ 1097] train: loss: 0.0288976
[Epoch 56; Iter   415/ 1097] train: loss: 0.0204070
[Epoch 56; Iter   445/ 1097] train: loss: 0.0008352
[Epoch 56; Iter   475/ 1097] train: loss: 0.0035400
[Epoch 56; Iter   505/ 1097] train: loss: 0.0054692
[Epoch 56; Iter   535/ 1097] train: loss: 0.0342543
[Epoch 56; Iter   565/ 1097] train: loss: 0.0006507
[Epoch 56; Iter   595/ 1097] train: loss: 0.0005846
[Epoch 56; Iter   625/ 1097] train: loss: 0.0006239
[Epoch 56; Iter   655/ 1097] train: loss: 0.0007150
[Epoch 56; Iter   685/ 1097] train: loss: 0.0009405
[Epoch 56; Iter   715/ 1097] train: loss: 0.0251389
[Epoch 56; Iter   745/ 1097] train: loss: 0.0151105
[Epoch 56; Iter   775/ 1097] train: loss: 0.0007272
[Epoch 56; Iter   805/ 1097] train: loss: 0.0200275
[Epoch 56; Iter   835/ 1097] train: loss: 0.1120442
[Epoch 56; Iter   865/ 1097] train: loss: 0.0012756
[Epoch 56; Iter   895/ 1097] train: loss: 0.0911218
[Epoch 56; Iter   925/ 1097] train: loss: 0.0005399
[Epoch 56; Iter   955/ 1097] train: loss: 0.0219454
[Epoch 56; Iter   985/ 1097] train: loss: 0.0020972
[Epoch 52; Iter   933/ 1097] train: loss: 0.0134065
[Epoch 52; Iter   963/ 1097] train: loss: 0.0004395
[Epoch 52; Iter   993/ 1097] train: loss: 0.0050863
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0005468
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0114369
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0018043
[Epoch 52] ogbg-molhiv: 0.694181 val loss: 5.538520
[Epoch 52] ogbg-molhiv: 0.630072 test loss: 5.150657
[Epoch 53; Iter    16/ 1097] train: loss: 0.0002946
[Epoch 53; Iter    46/ 1097] train: loss: 0.0006312
[Epoch 53; Iter    76/ 1097] train: loss: 0.0000964
[Epoch 53; Iter   106/ 1097] train: loss: 0.0006734
[Epoch 53; Iter   136/ 1097] train: loss: 0.0008206
[Epoch 53; Iter   166/ 1097] train: loss: 0.0427001
[Epoch 53; Iter   196/ 1097] train: loss: 0.0026697
[Epoch 53; Iter   226/ 1097] train: loss: 0.0201248
[Epoch 53; Iter   256/ 1097] train: loss: 0.0030812
[Epoch 53; Iter   286/ 1097] train: loss: 0.0024838
[Epoch 53; Iter   316/ 1097] train: loss: 0.0006766
[Epoch 53; Iter   346/ 1097] train: loss: 0.0019301
[Epoch 53; Iter   376/ 1097] train: loss: 0.0445432
[Epoch 53; Iter   406/ 1097] train: loss: 0.0023001
[Epoch 53; Iter   436/ 1097] train: loss: 0.0002129
[Epoch 53; Iter   466/ 1097] train: loss: 0.0561678
[Epoch 53; Iter   496/ 1097] train: loss: 0.0013485
[Epoch 53; Iter   526/ 1097] train: loss: 0.0001781
[Epoch 53; Iter   556/ 1097] train: loss: 0.0004561
[Epoch 53; Iter   586/ 1097] train: loss: 0.0177054
[Epoch 53; Iter   616/ 1097] train: loss: 0.0010418
[Epoch 53; Iter   646/ 1097] train: loss: 0.0164802
[Epoch 53; Iter   676/ 1097] train: loss: 0.0001694
[Epoch 53; Iter   706/ 1097] train: loss: 0.0021735
[Epoch 53; Iter   736/ 1097] train: loss: 0.0001699
[Epoch 53; Iter   766/ 1097] train: loss: 0.0011625
[Epoch 53; Iter   796/ 1097] train: loss: 0.0001050
[Epoch 53; Iter   826/ 1097] train: loss: 0.0051277
[Epoch 53; Iter   856/ 1097] train: loss: 0.0050568
[Epoch 53; Iter   886/ 1097] train: loss: 0.0017829
[Epoch 53; Iter   916/ 1097] train: loss: 0.0002857
[Epoch 53; Iter   946/ 1097] train: loss: 0.0022823
[Epoch 53; Iter   976/ 1097] train: loss: 0.0002526
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0009906
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0001630
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0254478
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0513380
[Epoch 53] ogbg-molhiv: 0.694010 val loss: 3.852416
[Epoch 53] ogbg-molhiv: 0.618044 test loss: 3.081247
[Epoch 54; Iter    29/ 1097] train: loss: 0.0000470
[Epoch 54; Iter    59/ 1097] train: loss: 0.0010189
[Epoch 54; Iter    89/ 1097] train: loss: 0.0002735
[Epoch 54; Iter   119/ 1097] train: loss: 0.0013462
[Epoch 54; Iter   149/ 1097] train: loss: 0.0010056
[Epoch 54; Iter   179/ 1097] train: loss: 0.0001575
[Epoch 54; Iter   209/ 1097] train: loss: 0.0007859
[Epoch 54; Iter   239/ 1097] train: loss: 0.0000715
[Epoch 54; Iter   269/ 1097] train: loss: 0.0001649
[Epoch 54; Iter   299/ 1097] train: loss: 0.0129911
[Epoch 54; Iter   329/ 1097] train: loss: 0.0026911
[Epoch 54; Iter   359/ 1097] train: loss: 0.0000135
[Epoch 54; Iter   389/ 1097] train: loss: 0.0032602
[Epoch 54; Iter   419/ 1097] train: loss: 0.0002406
[Epoch 54; Iter   449/ 1097] train: loss: 0.0002339
[Epoch 54; Iter   479/ 1097] train: loss: 0.0002766
[Epoch 54; Iter   509/ 1097] train: loss: 0.0008117
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003747
[Epoch 54; Iter   569/ 1097] train: loss: 0.0677749
[Epoch 54; Iter   599/ 1097] train: loss: 0.0002621
[Epoch 54; Iter   629/ 1097] train: loss: 0.0000179
[Epoch 54; Iter   659/ 1097] train: loss: 0.0003292
[Epoch 54; Iter   689/ 1097] train: loss: 0.0011911
[Epoch 54; Iter   719/ 1097] train: loss: 0.0008476
[Epoch 54; Iter   749/ 1097] train: loss: 0.0017797
[Epoch 54; Iter   779/ 1097] train: loss: 0.0817535
[Epoch 54; Iter   809/ 1097] train: loss: 0.0059913
[Epoch 54; Iter   839/ 1097] train: loss: 0.0002701
[Epoch 54; Iter   869/ 1097] train: loss: 0.0119123
[Epoch 54; Iter   899/ 1097] train: loss: 0.0118687
[Epoch 54; Iter   929/ 1097] train: loss: 0.2077952
[Epoch 54; Iter   959/ 1097] train: loss: 0.0007348
[Epoch 54; Iter   989/ 1097] train: loss: 0.0065309
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0032005
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0008437
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0229654
[Epoch 54] ogbg-molhiv: 0.709332 val loss: 5.593771
[Epoch 54] ogbg-molhiv: 0.655015 test loss: 3.461250
[Epoch 55; Iter    12/ 1097] train: loss: 0.0001764
[Epoch 55; Iter    42/ 1097] train: loss: 0.0151022
[Epoch 55; Iter    72/ 1097] train: loss: 0.0319453
[Epoch 55; Iter   102/ 1097] train: loss: 0.0001364
[Epoch 55; Iter   132/ 1097] train: loss: 0.0137613
[Epoch 55; Iter   162/ 1097] train: loss: 0.0002510
[Epoch 55; Iter   192/ 1097] train: loss: 0.0041249
[Epoch 55; Iter   222/ 1097] train: loss: 0.0015332
[Epoch 55; Iter   252/ 1097] train: loss: 0.0001407
[Epoch 55; Iter   282/ 1097] train: loss: 0.0006317
[Epoch 55; Iter   312/ 1097] train: loss: 0.0005265
[Epoch 55; Iter   342/ 1097] train: loss: 0.0006769
[Epoch 55; Iter   372/ 1097] train: loss: 0.0018251
[Epoch 55; Iter   402/ 1097] train: loss: 0.2668535
[Epoch 55; Iter   432/ 1097] train: loss: 0.0096871
[Epoch 55; Iter   462/ 1097] train: loss: 0.0067861
[Epoch 55; Iter   492/ 1097] train: loss: 0.0014994
[Epoch 55; Iter   522/ 1097] train: loss: 0.0399636
[Epoch 55; Iter   552/ 1097] train: loss: 0.0011516
[Epoch 55; Iter   582/ 1097] train: loss: 0.0039475
[Epoch 55; Iter   612/ 1097] train: loss: 0.0000610
[Epoch 55; Iter   642/ 1097] train: loss: 0.0005767
[Epoch 55; Iter   672/ 1097] train: loss: 0.0083803
[Epoch 55; Iter   702/ 1097] train: loss: 0.0472160
[Epoch 55; Iter   732/ 1097] train: loss: 0.0037543
[Epoch 55; Iter   762/ 1097] train: loss: 0.0009787
[Epoch 55; Iter   792/ 1097] train: loss: 0.0005432
[Epoch 55; Iter   822/ 1097] train: loss: 0.0028526
[Epoch 55; Iter   852/ 1097] train: loss: 0.0001438
[Epoch 55; Iter   882/ 1097] train: loss: 0.0006333
[Epoch 55; Iter   912/ 1097] train: loss: 0.0009051
[Epoch 55; Iter   942/ 1097] train: loss: 0.0821735
[Epoch 55; Iter   972/ 1097] train: loss: 0.0008008
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0000578
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0000636
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0001243
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0056709
[Epoch 55] ogbg-molhiv: 0.689812 val loss: 4.502110
[Epoch 55] ogbg-molhiv: 0.657187 test loss: 2.911564
[Epoch 56; Iter    25/ 1097] train: loss: 0.0002173
[Epoch 56; Iter    55/ 1097] train: loss: 0.0004202
[Epoch 56; Iter    85/ 1097] train: loss: 0.0099706
[Epoch 56; Iter   115/ 1097] train: loss: 0.0002069
[Epoch 56; Iter   145/ 1097] train: loss: 0.0022126
[Epoch 56; Iter   175/ 1097] train: loss: 0.0005363
[Epoch 56; Iter   205/ 1097] train: loss: 0.0721813
[Epoch 56; Iter   235/ 1097] train: loss: 0.0050414
[Epoch 56; Iter   265/ 1097] train: loss: 0.0000390
[Epoch 56; Iter   295/ 1097] train: loss: 0.0003677
[Epoch 56; Iter   325/ 1097] train: loss: 0.0028047
[Epoch 56; Iter   355/ 1097] train: loss: 0.0058219
[Epoch 56; Iter   385/ 1097] train: loss: 0.0000393
[Epoch 56; Iter   415/ 1097] train: loss: 0.0005220
[Epoch 56; Iter   445/ 1097] train: loss: 0.0216627
[Epoch 56; Iter   475/ 1097] train: loss: 0.0014791
[Epoch 56; Iter   505/ 1097] train: loss: 0.0000288
[Epoch 56; Iter   535/ 1097] train: loss: 0.0010436
[Epoch 56; Iter   565/ 1097] train: loss: 0.0050215
[Epoch 56; Iter   595/ 1097] train: loss: 0.0023714
[Epoch 56; Iter   625/ 1097] train: loss: 0.0065751
[Epoch 56; Iter   655/ 1097] train: loss: 0.0004174
[Epoch 56; Iter   685/ 1097] train: loss: 0.0004097
[Epoch 56; Iter   715/ 1097] train: loss: 0.0007614
[Epoch 56; Iter   745/ 1097] train: loss: 0.0015971
[Epoch 56; Iter   775/ 1097] train: loss: 0.0567936
[Epoch 56; Iter   805/ 1097] train: loss: 0.0013831
[Epoch 56; Iter   835/ 1097] train: loss: 0.0002290
[Epoch 56; Iter   865/ 1097] train: loss: 0.0501665
[Epoch 56; Iter   895/ 1097] train: loss: 0.0112806
[Epoch 56; Iter   925/ 1097] train: loss: 0.0035559
[Epoch 56; Iter   955/ 1097] train: loss: 0.0002849
[Epoch 56; Iter   985/ 1097] train: loss: 0.0002823
[Epoch 44; Iter   769/ 1097] train: loss: 0.0316753
[Epoch 44; Iter   799/ 1097] train: loss: 0.0180100
[Epoch 44; Iter   829/ 1097] train: loss: 0.2410753
[Epoch 44; Iter   859/ 1097] train: loss: 0.0670661
[Epoch 44; Iter   889/ 1097] train: loss: 0.0096153
[Epoch 44; Iter   919/ 1097] train: loss: 0.0102880
[Epoch 44; Iter   949/ 1097] train: loss: 0.0858494
[Epoch 44; Iter   979/ 1097] train: loss: 0.0102910
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0160408
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0647072
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1056344
[Epoch 44] ogbg-molhiv: 0.844007 val loss: 0.079402
[Epoch 44] ogbg-molhiv: 0.759341 test loss: 0.142343
[Epoch 45; Iter     2/ 1097] train: loss: 0.0133943
[Epoch 45; Iter    32/ 1097] train: loss: 0.0180026
[Epoch 45; Iter    62/ 1097] train: loss: 0.1493860
[Epoch 45; Iter    92/ 1097] train: loss: 0.0461704
[Epoch 45; Iter   122/ 1097] train: loss: 0.0250738
[Epoch 45; Iter   152/ 1097] train: loss: 0.1147294
[Epoch 45; Iter   182/ 1097] train: loss: 0.2128627
[Epoch 45; Iter   212/ 1097] train: loss: 0.1693321
[Epoch 45; Iter   242/ 1097] train: loss: 0.0979485
[Epoch 45; Iter   272/ 1097] train: loss: 0.0718728
[Epoch 45; Iter   302/ 1097] train: loss: 0.1530004
[Epoch 45; Iter   332/ 1097] train: loss: 0.0210542
[Epoch 45; Iter   362/ 1097] train: loss: 0.0235195
[Epoch 45; Iter   392/ 1097] train: loss: 0.0153309
[Epoch 45; Iter   422/ 1097] train: loss: 0.1753436
[Epoch 45; Iter   452/ 1097] train: loss: 0.0543039
[Epoch 45; Iter   482/ 1097] train: loss: 0.0962267
[Epoch 45; Iter   512/ 1097] train: loss: 0.0785824
[Epoch 45; Iter   542/ 1097] train: loss: 0.0243316
[Epoch 45; Iter   572/ 1097] train: loss: 0.0545015
[Epoch 45; Iter   602/ 1097] train: loss: 0.2895057
[Epoch 45; Iter   632/ 1097] train: loss: 0.0332986
[Epoch 45; Iter   662/ 1097] train: loss: 0.1056254
[Epoch 45; Iter   692/ 1097] train: loss: 0.0263677
[Epoch 45; Iter   722/ 1097] train: loss: 0.0188101
[Epoch 45; Iter   752/ 1097] train: loss: 0.0213567
[Epoch 45; Iter   782/ 1097] train: loss: 0.3648979
[Epoch 45; Iter   812/ 1097] train: loss: 0.0279972
[Epoch 45; Iter   842/ 1097] train: loss: 0.0146527
[Epoch 45; Iter   872/ 1097] train: loss: 0.0819942
[Epoch 45; Iter   902/ 1097] train: loss: 0.0321521
[Epoch 45; Iter   932/ 1097] train: loss: 0.0146598
[Epoch 45; Iter   962/ 1097] train: loss: 0.0546593
[Epoch 45; Iter   992/ 1097] train: loss: 0.0588496
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0259746
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0266620
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0854677
[Epoch 45] ogbg-molhiv: 0.837072 val loss: 0.084935
[Epoch 45] ogbg-molhiv: 0.735059 test loss: 0.150589
[Epoch 46; Iter    15/ 1097] train: loss: 0.1190827
[Epoch 46; Iter    45/ 1097] train: loss: 0.0149923
[Epoch 46; Iter    75/ 1097] train: loss: 0.0842589
[Epoch 46; Iter   105/ 1097] train: loss: 0.0899340
[Epoch 46; Iter   135/ 1097] train: loss: 0.1353295
[Epoch 46; Iter   165/ 1097] train: loss: 0.2533341
[Epoch 46; Iter   195/ 1097] train: loss: 0.0135181
[Epoch 46; Iter   225/ 1097] train: loss: 0.0467598
[Epoch 46; Iter   255/ 1097] train: loss: 0.0442946
[Epoch 46; Iter   285/ 1097] train: loss: 0.0212331
[Epoch 46; Iter   315/ 1097] train: loss: 0.0425531
[Epoch 46; Iter   345/ 1097] train: loss: 0.0470489
[Epoch 46; Iter   375/ 1097] train: loss: 0.0142770
[Epoch 46; Iter   405/ 1097] train: loss: 0.0927071
[Epoch 46; Iter   435/ 1097] train: loss: 0.0163989
[Epoch 46; Iter   465/ 1097] train: loss: 0.0296404
[Epoch 46; Iter   495/ 1097] train: loss: 0.1735331
[Epoch 46; Iter   525/ 1097] train: loss: 0.0419025
[Epoch 46; Iter   555/ 1097] train: loss: 0.0623634
[Epoch 46; Iter   585/ 1097] train: loss: 0.1119914
[Epoch 46; Iter   615/ 1097] train: loss: 0.0409835
[Epoch 46; Iter   645/ 1097] train: loss: 0.0759205
[Epoch 46; Iter   675/ 1097] train: loss: 0.0707870
[Epoch 46; Iter   705/ 1097] train: loss: 0.0569699
[Epoch 46; Iter   735/ 1097] train: loss: 0.0196592
[Epoch 46; Iter   765/ 1097] train: loss: 0.2060051
[Epoch 46; Iter   795/ 1097] train: loss: 0.0364163
[Epoch 46; Iter   825/ 1097] train: loss: 0.0416654
[Epoch 46; Iter   855/ 1097] train: loss: 0.0100645
[Epoch 46; Iter   885/ 1097] train: loss: 0.1898124
[Epoch 46; Iter   915/ 1097] train: loss: 0.0087697
[Epoch 46; Iter   945/ 1097] train: loss: 0.0390213
[Epoch 46; Iter   975/ 1097] train: loss: 0.0178214
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0141130
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0275800
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0523403
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0545786
[Epoch 46] ogbg-molhiv: 0.846986 val loss: 0.080884
[Epoch 46] ogbg-molhiv: 0.754012 test loss: 0.144275
[Epoch 47; Iter    28/ 1097] train: loss: 0.0367181
[Epoch 47; Iter    58/ 1097] train: loss: 0.0412033
[Epoch 47; Iter    88/ 1097] train: loss: 0.0981525
[Epoch 47; Iter   118/ 1097] train: loss: 0.0613466
[Epoch 47; Iter   148/ 1097] train: loss: 0.0261339
[Epoch 47; Iter   178/ 1097] train: loss: 0.0608794
[Epoch 47; Iter   208/ 1097] train: loss: 0.1274643
[Epoch 47; Iter   238/ 1097] train: loss: 0.0233936
[Epoch 47; Iter   268/ 1097] train: loss: 0.0084606
[Epoch 47; Iter   298/ 1097] train: loss: 0.0084107
[Epoch 47; Iter   328/ 1097] train: loss: 0.1021552
[Epoch 47; Iter   358/ 1097] train: loss: 0.1451339
[Epoch 47; Iter   388/ 1097] train: loss: 0.0103332
[Epoch 47; Iter   418/ 1097] train: loss: 0.1029433
[Epoch 47; Iter   448/ 1097] train: loss: 0.0298414
[Epoch 47; Iter   478/ 1097] train: loss: 0.0547610
[Epoch 47; Iter   508/ 1097] train: loss: 0.2002996
[Epoch 47; Iter   538/ 1097] train: loss: 0.1452052
[Epoch 47; Iter   568/ 1097] train: loss: 0.0409135
[Epoch 47; Iter   598/ 1097] train: loss: 0.0689156
[Epoch 47; Iter   628/ 1097] train: loss: 0.0089596
[Epoch 47; Iter   658/ 1097] train: loss: 0.0091183
[Epoch 47; Iter   688/ 1097] train: loss: 0.0754160
[Epoch 47; Iter   718/ 1097] train: loss: 0.0181855
[Epoch 47; Iter   748/ 1097] train: loss: 0.0374533
[Epoch 47; Iter   778/ 1097] train: loss: 0.0476861
[Epoch 47; Iter   808/ 1097] train: loss: 0.0079941
[Epoch 47; Iter   838/ 1097] train: loss: 0.0207811
[Epoch 47; Iter   868/ 1097] train: loss: 0.0194429
[Epoch 47; Iter   898/ 1097] train: loss: 0.0497207
[Epoch 47; Iter   928/ 1097] train: loss: 0.0205119
[Epoch 47; Iter   958/ 1097] train: loss: 0.2820742
[Epoch 47; Iter   988/ 1097] train: loss: 0.1971139
[Epoch 47; Iter  1018/ 1097] train: loss: 0.1123066
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0488766
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0593945
[Epoch 47] ogbg-molhiv: 0.793461 val loss: 0.091229
[Epoch 47] ogbg-molhiv: 0.719487 test loss: 0.160992
[Epoch 48; Iter    11/ 1097] train: loss: 0.0962242
[Epoch 48; Iter    41/ 1097] train: loss: 0.0463982
[Epoch 48; Iter    71/ 1097] train: loss: 0.0195115
[Epoch 48; Iter   101/ 1097] train: loss: 0.2193964
[Epoch 48; Iter   131/ 1097] train: loss: 0.0255655
[Epoch 48; Iter   161/ 1097] train: loss: 0.0111597
[Epoch 48; Iter   191/ 1097] train: loss: 0.0690384
[Epoch 48; Iter   221/ 1097] train: loss: 0.0241388
[Epoch 48; Iter   251/ 1097] train: loss: 0.0480823
[Epoch 48; Iter   281/ 1097] train: loss: 0.0209899
[Epoch 48; Iter   311/ 1097] train: loss: 0.0296860
[Epoch 48; Iter   341/ 1097] train: loss: 0.0316469
[Epoch 48; Iter   371/ 1097] train: loss: 0.0322207
[Epoch 48; Iter   401/ 1097] train: loss: 0.0355319
[Epoch 48; Iter   431/ 1097] train: loss: 0.0361485
[Epoch 48; Iter   461/ 1097] train: loss: 0.0651125
[Epoch 48; Iter   491/ 1097] train: loss: 0.0317837
[Epoch 48; Iter   521/ 1097] train: loss: 0.0493609
[Epoch 48; Iter   551/ 1097] train: loss: 0.1114459
[Epoch 48; Iter   581/ 1097] train: loss: 0.0303650
[Epoch 48; Iter   611/ 1097] train: loss: 0.0469363
[Epoch 48; Iter   641/ 1097] train: loss: 0.0632284
[Epoch 48; Iter   671/ 1097] train: loss: 0.0080079
[Epoch 48; Iter   701/ 1097] train: loss: 0.0220216
[Epoch 48; Iter   731/ 1097] train: loss: 0.0423505
[Epoch 48; Iter   761/ 1097] train: loss: 0.0592101
[Epoch 48; Iter   791/ 1097] train: loss: 0.0289946
[Epoch 48; Iter   821/ 1097] train: loss: 0.0582487
[Epoch 44; Iter   769/ 1097] train: loss: 0.0398132
[Epoch 44; Iter   799/ 1097] train: loss: 0.0551871
[Epoch 44; Iter   829/ 1097] train: loss: 0.1565332
[Epoch 44; Iter   859/ 1097] train: loss: 0.1080054
[Epoch 44; Iter   889/ 1097] train: loss: 0.0351453
[Epoch 44; Iter   919/ 1097] train: loss: 0.0101682
[Epoch 44; Iter   949/ 1097] train: loss: 0.0933685
[Epoch 44; Iter   979/ 1097] train: loss: 0.0380517
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0169115
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0239892
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0248321
[Epoch 44] ogbg-molhiv: 0.825700 val loss: 0.084981
[Epoch 44] ogbg-molhiv: 0.767767 test loss: 0.137467
[Epoch 45; Iter     2/ 1097] train: loss: 0.0545722
[Epoch 45; Iter    32/ 1097] train: loss: 0.0303429
[Epoch 45; Iter    62/ 1097] train: loss: 0.0432708
[Epoch 45; Iter    92/ 1097] train: loss: 0.0356518
[Epoch 45; Iter   122/ 1097] train: loss: 0.0228839
[Epoch 45; Iter   152/ 1097] train: loss: 0.0966998
[Epoch 45; Iter   182/ 1097] train: loss: 0.1027064
[Epoch 45; Iter   212/ 1097] train: loss: 0.0714701
[Epoch 45; Iter   242/ 1097] train: loss: 0.0220405
[Epoch 45; Iter   272/ 1097] train: loss: 0.0928966
[Epoch 45; Iter   302/ 1097] train: loss: 0.2122503
[Epoch 45; Iter   332/ 1097] train: loss: 0.0902151
[Epoch 45; Iter   362/ 1097] train: loss: 0.0244211
[Epoch 45; Iter   392/ 1097] train: loss: 0.2571641
[Epoch 45; Iter   422/ 1097] train: loss: 0.0918776
[Epoch 45; Iter   452/ 1097] train: loss: 0.1223011
[Epoch 45; Iter   482/ 1097] train: loss: 0.0152311
[Epoch 45; Iter   512/ 1097] train: loss: 0.0202396
[Epoch 45; Iter   542/ 1097] train: loss: 0.0252234
[Epoch 45; Iter   572/ 1097] train: loss: 0.1091492
[Epoch 45; Iter   602/ 1097] train: loss: 0.0159034
[Epoch 45; Iter   632/ 1097] train: loss: 0.1045633
[Epoch 45; Iter   662/ 1097] train: loss: 0.0082390
[Epoch 45; Iter   692/ 1097] train: loss: 0.0653427
[Epoch 45; Iter   722/ 1097] train: loss: 0.0334201
[Epoch 45; Iter   752/ 1097] train: loss: 0.0221303
[Epoch 45; Iter   782/ 1097] train: loss: 0.1855601
[Epoch 45; Iter   812/ 1097] train: loss: 0.0436363
[Epoch 45; Iter   842/ 1097] train: loss: 0.0119322
[Epoch 45; Iter   872/ 1097] train: loss: 0.0625632
[Epoch 45; Iter   902/ 1097] train: loss: 0.0208534
[Epoch 45; Iter   932/ 1097] train: loss: 0.2340242
[Epoch 45; Iter   962/ 1097] train: loss: 0.0242695
[Epoch 45; Iter   992/ 1097] train: loss: 0.2049873
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0099969
[Epoch 45; Iter  1052/ 1097] train: loss: 0.2422665
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0237676
[Epoch 45] ogbg-molhiv: 0.813155 val loss: 0.081779
[Epoch 45] ogbg-molhiv: 0.750341 test loss: 0.142259
[Epoch 46; Iter    15/ 1097] train: loss: 0.0197477
[Epoch 46; Iter    45/ 1097] train: loss: 0.0170976
[Epoch 46; Iter    75/ 1097] train: loss: 0.0424604
[Epoch 46; Iter   105/ 1097] train: loss: 0.0256021
[Epoch 46; Iter   135/ 1097] train: loss: 0.0558609
[Epoch 46; Iter   165/ 1097] train: loss: 0.0625113
[Epoch 46; Iter   195/ 1097] train: loss: 0.0830261
[Epoch 46; Iter   225/ 1097] train: loss: 0.0365184
[Epoch 46; Iter   255/ 1097] train: loss: 0.0182741
[Epoch 46; Iter   285/ 1097] train: loss: 0.0271548
[Epoch 46; Iter   315/ 1097] train: loss: 0.0351316
[Epoch 46; Iter   345/ 1097] train: loss: 0.0135932
[Epoch 46; Iter   375/ 1097] train: loss: 0.1454518
[Epoch 46; Iter   405/ 1097] train: loss: 0.0360928
[Epoch 46; Iter   435/ 1097] train: loss: 0.2151672
[Epoch 46; Iter   465/ 1097] train: loss: 0.0324832
[Epoch 46; Iter   495/ 1097] train: loss: 0.0233637
[Epoch 46; Iter   525/ 1097] train: loss: 0.0118221
[Epoch 46; Iter   555/ 1097] train: loss: 0.1137935
[Epoch 46; Iter   585/ 1097] train: loss: 0.0174337
[Epoch 46; Iter   615/ 1097] train: loss: 0.1275658
[Epoch 46; Iter   645/ 1097] train: loss: 0.1185744
[Epoch 46; Iter   675/ 1097] train: loss: 0.0640084
[Epoch 46; Iter   705/ 1097] train: loss: 0.0236554
[Epoch 46; Iter   735/ 1097] train: loss: 0.0276021
[Epoch 46; Iter   765/ 1097] train: loss: 0.0609168
[Epoch 46; Iter   795/ 1097] train: loss: 0.0655824
[Epoch 46; Iter   825/ 1097] train: loss: 0.0972372
[Epoch 46; Iter   855/ 1097] train: loss: 0.0226421
[Epoch 46; Iter   885/ 1097] train: loss: 0.1635137
[Epoch 46; Iter   915/ 1097] train: loss: 0.2688521
[Epoch 46; Iter   945/ 1097] train: loss: 0.1253469
[Epoch 46; Iter   975/ 1097] train: loss: 0.1805401
[Epoch 46; Iter  1005/ 1097] train: loss: 0.1396412
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0181047
[Epoch 46; Iter  1065/ 1097] train: loss: 0.2225016
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0217475
[Epoch 46] ogbg-molhiv: 0.819040 val loss: 0.075912
[Epoch 46] ogbg-molhiv: 0.754404 test loss: 0.141894
[Epoch 47; Iter    28/ 1097] train: loss: 0.0127809
[Epoch 47; Iter    58/ 1097] train: loss: 0.0262840
[Epoch 47; Iter    88/ 1097] train: loss: 0.0772617
[Epoch 47; Iter   118/ 1097] train: loss: 0.0249681
[Epoch 47; Iter   148/ 1097] train: loss: 0.0422665
[Epoch 47; Iter   178/ 1097] train: loss: 0.1463804
[Epoch 47; Iter   208/ 1097] train: loss: 0.0283061
[Epoch 47; Iter   238/ 1097] train: loss: 0.0128702
[Epoch 47; Iter   268/ 1097] train: loss: 0.0537077
[Epoch 47; Iter   298/ 1097] train: loss: 0.0446402
[Epoch 47; Iter   328/ 1097] train: loss: 0.0099005
[Epoch 47; Iter   358/ 1097] train: loss: 0.1986495
[Epoch 47; Iter   388/ 1097] train: loss: 0.1238778
[Epoch 47; Iter   418/ 1097] train: loss: 0.0778916
[Epoch 47; Iter   448/ 1097] train: loss: 0.0280965
[Epoch 47; Iter   478/ 1097] train: loss: 0.0230261
[Epoch 47; Iter   508/ 1097] train: loss: 0.0194930
[Epoch 47; Iter   538/ 1097] train: loss: 0.0177351
[Epoch 47; Iter   568/ 1097] train: loss: 0.0749424
[Epoch 47; Iter   598/ 1097] train: loss: 0.0781138
[Epoch 47; Iter   628/ 1097] train: loss: 0.0390800
[Epoch 47; Iter   658/ 1097] train: loss: 0.0096549
[Epoch 47; Iter   688/ 1097] train: loss: 0.0717301
[Epoch 47; Iter   718/ 1097] train: loss: 0.0188752
[Epoch 47; Iter   748/ 1097] train: loss: 0.0270488
[Epoch 47; Iter   778/ 1097] train: loss: 0.0148239
[Epoch 47; Iter   808/ 1097] train: loss: 0.0253389
[Epoch 47; Iter   838/ 1097] train: loss: 0.1397531
[Epoch 47; Iter   868/ 1097] train: loss: 0.1104214
[Epoch 47; Iter   898/ 1097] train: loss: 0.0394107
[Epoch 47; Iter   928/ 1097] train: loss: 0.0090835
[Epoch 47; Iter   958/ 1097] train: loss: 0.1768295
[Epoch 47; Iter   988/ 1097] train: loss: 0.0493459
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0148345
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0335197
[Epoch 47; Iter  1078/ 1097] train: loss: 0.1256849
[Epoch 47] ogbg-molhiv: 0.821554 val loss: 0.090218
[Epoch 47] ogbg-molhiv: 0.760565 test loss: 0.139202
[Epoch 48; Iter    11/ 1097] train: loss: 0.0735237
[Epoch 48; Iter    41/ 1097] train: loss: 0.1853868
[Epoch 48; Iter    71/ 1097] train: loss: 0.0203989
[Epoch 48; Iter   101/ 1097] train: loss: 0.0450238
[Epoch 48; Iter   131/ 1097] train: loss: 0.0228687
[Epoch 48; Iter   161/ 1097] train: loss: 0.0162243
[Epoch 48; Iter   191/ 1097] train: loss: 0.1054622
[Epoch 48; Iter   221/ 1097] train: loss: 0.0514731
[Epoch 48; Iter   251/ 1097] train: loss: 0.0297784
[Epoch 48; Iter   281/ 1097] train: loss: 0.0207798
[Epoch 48; Iter   311/ 1097] train: loss: 0.0179747
[Epoch 48; Iter   341/ 1097] train: loss: 0.0466546
[Epoch 48; Iter   371/ 1097] train: loss: 0.1312553
[Epoch 48; Iter   401/ 1097] train: loss: 0.0239137
[Epoch 48; Iter   431/ 1097] train: loss: 0.1814925
[Epoch 48; Iter   461/ 1097] train: loss: 0.1416994
[Epoch 48; Iter   491/ 1097] train: loss: 0.0161509
[Epoch 48; Iter   521/ 1097] train: loss: 0.0138466
[Epoch 48; Iter   551/ 1097] train: loss: 0.1838936
[Epoch 48; Iter   581/ 1097] train: loss: 0.0852370
[Epoch 48; Iter   611/ 1097] train: loss: 0.0240217
[Epoch 48; Iter   641/ 1097] train: loss: 0.1239741
[Epoch 48; Iter   671/ 1097] train: loss: 0.1119707
[Epoch 48; Iter   701/ 1097] train: loss: 0.0673407
[Epoch 48; Iter   731/ 1097] train: loss: 0.1146865
[Epoch 48; Iter   761/ 1097] train: loss: 0.0875474
[Epoch 48; Iter   791/ 1097] train: loss: 0.0385030
[Epoch 48; Iter   821/ 1097] train: loss: 0.0911577
[Epoch 44; Iter   769/ 1097] train: loss: 0.1171874
[Epoch 44; Iter   799/ 1097] train: loss: 0.0848769
[Epoch 44; Iter   829/ 1097] train: loss: 0.0200710
[Epoch 44; Iter   859/ 1097] train: loss: 0.0841216
[Epoch 44; Iter   889/ 1097] train: loss: 0.0176509
[Epoch 44; Iter   919/ 1097] train: loss: 0.0195580
[Epoch 44; Iter   949/ 1097] train: loss: 0.0107119
[Epoch 44; Iter   979/ 1097] train: loss: 0.0257289
[Epoch 44; Iter  1009/ 1097] train: loss: 0.2213516
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0040154
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0921602
[Epoch 44] ogbg-molhiv: 0.800843 val loss: 0.088851
[Epoch 44] ogbg-molhiv: 0.746594 test loss: 0.173253
[Epoch 45; Iter     2/ 1097] train: loss: 0.0221105
[Epoch 45; Iter    32/ 1097] train: loss: 0.1278934
[Epoch 45; Iter    62/ 1097] train: loss: 0.0206956
[Epoch 45; Iter    92/ 1097] train: loss: 0.0523358
[Epoch 45; Iter   122/ 1097] train: loss: 0.0292136
[Epoch 45; Iter   152/ 1097] train: loss: 0.0895032
[Epoch 45; Iter   182/ 1097] train: loss: 0.0421235
[Epoch 45; Iter   212/ 1097] train: loss: 0.0520266
[Epoch 45; Iter   242/ 1097] train: loss: 0.1178097
[Epoch 45; Iter   272/ 1097] train: loss: 0.0389902
[Epoch 45; Iter   302/ 1097] train: loss: 0.1230013
[Epoch 45; Iter   332/ 1097] train: loss: 0.1610608
[Epoch 45; Iter   362/ 1097] train: loss: 0.0688468
[Epoch 45; Iter   392/ 1097] train: loss: 0.0223134
[Epoch 45; Iter   422/ 1097] train: loss: 0.0415293
[Epoch 45; Iter   452/ 1097] train: loss: 0.0230620
[Epoch 45; Iter   482/ 1097] train: loss: 0.0460114
[Epoch 45; Iter   512/ 1097] train: loss: 0.0402674
[Epoch 45; Iter   542/ 1097] train: loss: 0.0105178
[Epoch 45; Iter   572/ 1097] train: loss: 0.3198570
[Epoch 45; Iter   602/ 1097] train: loss: 0.0535710
[Epoch 45; Iter   632/ 1097] train: loss: 0.0759286
[Epoch 45; Iter   662/ 1097] train: loss: 0.0501813
[Epoch 45; Iter   692/ 1097] train: loss: 0.0154843
[Epoch 45; Iter   722/ 1097] train: loss: 0.3071426
[Epoch 45; Iter   752/ 1097] train: loss: 0.0214953
[Epoch 45; Iter   782/ 1097] train: loss: 0.0608756
[Epoch 45; Iter   812/ 1097] train: loss: 0.0289572
[Epoch 45; Iter   842/ 1097] train: loss: 0.0105163
[Epoch 45; Iter   872/ 1097] train: loss: 0.0136177
[Epoch 45; Iter   902/ 1097] train: loss: 0.0135014
[Epoch 45; Iter   932/ 1097] train: loss: 0.1437357
[Epoch 45; Iter   962/ 1097] train: loss: 0.0594574
[Epoch 45; Iter   992/ 1097] train: loss: 0.2148544
[Epoch 45; Iter  1022/ 1097] train: loss: 0.1603006
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0534230
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0390900
[Epoch 45] ogbg-molhiv: 0.814095 val loss: 0.085564
[Epoch 45] ogbg-molhiv: 0.756788 test loss: 0.323081
[Epoch 46; Iter    15/ 1097] train: loss: 0.0150153
[Epoch 46; Iter    45/ 1097] train: loss: 0.0126417
[Epoch 46; Iter    75/ 1097] train: loss: 0.0162608
[Epoch 46; Iter   105/ 1097] train: loss: 0.0249142
[Epoch 46; Iter   135/ 1097] train: loss: 0.0356700
[Epoch 46; Iter   165/ 1097] train: loss: 0.0079874
[Epoch 46; Iter   195/ 1097] train: loss: 0.0107981
[Epoch 46; Iter   225/ 1097] train: loss: 0.0293907
[Epoch 46; Iter   255/ 1097] train: loss: 0.0444941
[Epoch 46; Iter   285/ 1097] train: loss: 0.0184849
[Epoch 46; Iter   315/ 1097] train: loss: 0.0323726
[Epoch 46; Iter   345/ 1097] train: loss: 0.0202343
[Epoch 46; Iter   375/ 1097] train: loss: 0.0234235
[Epoch 46; Iter   405/ 1097] train: loss: 0.0133541
[Epoch 46; Iter   435/ 1097] train: loss: 0.0809998
[Epoch 46; Iter   465/ 1097] train: loss: 0.0440723
[Epoch 46; Iter   495/ 1097] train: loss: 0.0139793
[Epoch 46; Iter   525/ 1097] train: loss: 0.1430716
[Epoch 46; Iter   555/ 1097] train: loss: 0.0113847
[Epoch 46; Iter   585/ 1097] train: loss: 0.0141641
[Epoch 46; Iter   615/ 1097] train: loss: 0.1180184
[Epoch 46; Iter   645/ 1097] train: loss: 0.0450474
[Epoch 46; Iter   675/ 1097] train: loss: 0.1305241
[Epoch 46; Iter   705/ 1097] train: loss: 0.0917085
[Epoch 46; Iter   735/ 1097] train: loss: 0.0125554
[Epoch 46; Iter   765/ 1097] train: loss: 0.0468924
[Epoch 46; Iter   795/ 1097] train: loss: 0.1260078
[Epoch 46; Iter   825/ 1097] train: loss: 0.0306802
[Epoch 46; Iter   855/ 1097] train: loss: 0.0127650
[Epoch 46; Iter   885/ 1097] train: loss: 0.0911983
[Epoch 46; Iter   915/ 1097] train: loss: 0.0439056
[Epoch 46; Iter   945/ 1097] train: loss: 0.0048317
[Epoch 46; Iter   975/ 1097] train: loss: 0.0473490
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0350890
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0767978
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0112629
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0290952
[Epoch 46] ogbg-molhiv: 0.805589 val loss: 0.084060
[Epoch 46] ogbg-molhiv: 0.731621 test loss: 0.252565
[Epoch 47; Iter    28/ 1097] train: loss: 0.0318369
[Epoch 47; Iter    58/ 1097] train: loss: 0.0418911
[Epoch 47; Iter    88/ 1097] train: loss: 0.0101211
[Epoch 47; Iter   118/ 1097] train: loss: 0.0246169
[Epoch 47; Iter   148/ 1097] train: loss: 0.0152452
[Epoch 47; Iter   178/ 1097] train: loss: 0.0345879
[Epoch 47; Iter   208/ 1097] train: loss: 0.0390988
[Epoch 47; Iter   238/ 1097] train: loss: 0.2160293
[Epoch 47; Iter   268/ 1097] train: loss: 0.1002846
[Epoch 47; Iter   298/ 1097] train: loss: 0.1183582
[Epoch 47; Iter   328/ 1097] train: loss: 0.1384796
[Epoch 47; Iter   358/ 1097] train: loss: 0.0566461
[Epoch 47; Iter   388/ 1097] train: loss: 0.0206350
[Epoch 47; Iter   418/ 1097] train: loss: 0.0873220
[Epoch 47; Iter   448/ 1097] train: loss: 0.0332826
[Epoch 47; Iter   478/ 1097] train: loss: 0.1774763
[Epoch 47; Iter   508/ 1097] train: loss: 0.0697319
[Epoch 47; Iter   538/ 1097] train: loss: 0.0081963
[Epoch 47; Iter   568/ 1097] train: loss: 0.1190418
[Epoch 47; Iter   598/ 1097] train: loss: 0.0904559
[Epoch 47; Iter   628/ 1097] train: loss: 0.0176818
[Epoch 47; Iter   658/ 1097] train: loss: 0.0198941
[Epoch 47; Iter   688/ 1097] train: loss: 0.0075525
[Epoch 47; Iter   718/ 1097] train: loss: 0.0196927
[Epoch 47; Iter   748/ 1097] train: loss: 0.0336716
[Epoch 47; Iter   778/ 1097] train: loss: 0.0149498
[Epoch 47; Iter   808/ 1097] train: loss: 0.0055689
[Epoch 47; Iter   838/ 1097] train: loss: 0.0072538
[Epoch 47; Iter   868/ 1097] train: loss: 0.0157442
[Epoch 47; Iter   898/ 1097] train: loss: 0.0195924
[Epoch 47; Iter   928/ 1097] train: loss: 0.0493776
[Epoch 47; Iter   958/ 1097] train: loss: 0.0365484
[Epoch 47; Iter   988/ 1097] train: loss: 0.0366301
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0449324
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0097490
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0368304
[Epoch 47] ogbg-molhiv: 0.815743 val loss: 0.084900
[Epoch 47] ogbg-molhiv: 0.767180 test loss: 0.150536
[Epoch 48; Iter    11/ 1097] train: loss: 0.0132210
[Epoch 48; Iter    41/ 1097] train: loss: 0.0080913
[Epoch 48; Iter    71/ 1097] train: loss: 0.0151493
[Epoch 48; Iter   101/ 1097] train: loss: 0.2305830
[Epoch 48; Iter   131/ 1097] train: loss: 0.0110190
[Epoch 48; Iter   161/ 1097] train: loss: 0.0285441
[Epoch 48; Iter   191/ 1097] train: loss: 0.0721202
[Epoch 48; Iter   221/ 1097] train: loss: 0.0068170
[Epoch 48; Iter   251/ 1097] train: loss: 0.0176363
[Epoch 48; Iter   281/ 1097] train: loss: 0.0096011
[Epoch 48; Iter   311/ 1097] train: loss: 0.0829297
[Epoch 48; Iter   341/ 1097] train: loss: 0.0111778
[Epoch 48; Iter   371/ 1097] train: loss: 0.0575639
[Epoch 48; Iter   401/ 1097] train: loss: 0.0348726
[Epoch 48; Iter   431/ 1097] train: loss: 0.0466102
[Epoch 48; Iter   461/ 1097] train: loss: 0.0294286
[Epoch 48; Iter   491/ 1097] train: loss: 0.0199806
[Epoch 48; Iter   521/ 1097] train: loss: 0.0187394
[Epoch 48; Iter   551/ 1097] train: loss: 0.0279306
[Epoch 48; Iter   581/ 1097] train: loss: 0.2213081
[Epoch 48; Iter   611/ 1097] train: loss: 0.0737951
[Epoch 48; Iter   641/ 1097] train: loss: 0.1235160
[Epoch 48; Iter   671/ 1097] train: loss: 0.0169245
[Epoch 48; Iter   701/ 1097] train: loss: 0.0684802
[Epoch 48; Iter   731/ 1097] train: loss: 0.0070517
[Epoch 48; Iter   761/ 1097] train: loss: 0.2257903
[Epoch 48; Iter   791/ 1097] train: loss: 0.0070248
[Epoch 48; Iter   821/ 1097] train: loss: 0.0156666
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0003286
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0039776
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0123557
[Epoch 56] ogbg-molhiv: 0.671345 val loss: 0.360460
[Epoch 56] ogbg-molhiv: 0.739207 test loss: 0.314031
[Epoch 57; Iter     8/ 1097] train: loss: 0.0024611
[Epoch 57; Iter    38/ 1097] train: loss: 0.0004104
[Epoch 57; Iter    68/ 1097] train: loss: 0.0098117
[Epoch 57; Iter    98/ 1097] train: loss: 0.0017683
[Epoch 57; Iter   128/ 1097] train: loss: 0.0116121
[Epoch 57; Iter   158/ 1097] train: loss: 0.0002995
[Epoch 57; Iter   188/ 1097] train: loss: 0.0053366
[Epoch 57; Iter   218/ 1097] train: loss: 0.0089687
[Epoch 57; Iter   248/ 1097] train: loss: 0.0107607
[Epoch 57; Iter   278/ 1097] train: loss: 0.0095594
[Epoch 57; Iter   308/ 1097] train: loss: 0.0003182
[Epoch 57; Iter   338/ 1097] train: loss: 0.0089392
[Epoch 57; Iter   368/ 1097] train: loss: 0.0004793
[Epoch 57; Iter   398/ 1097] train: loss: 0.0003452
[Epoch 57; Iter   428/ 1097] train: loss: 0.0001061
[Epoch 57; Iter   458/ 1097] train: loss: 0.0036178
[Epoch 57; Iter   488/ 1097] train: loss: 0.2718510
[Epoch 57; Iter   518/ 1097] train: loss: 0.0006327
[Epoch 57; Iter   548/ 1097] train: loss: 0.0078002
[Epoch 57; Iter   578/ 1097] train: loss: 0.0005227
[Epoch 57; Iter   608/ 1097] train: loss: 0.0000513
[Epoch 57; Iter   638/ 1097] train: loss: 0.0060679
[Epoch 57; Iter   668/ 1097] train: loss: 0.0002227
[Epoch 57; Iter   698/ 1097] train: loss: 0.0083224
[Epoch 57; Iter   728/ 1097] train: loss: 0.0003613
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007665
[Epoch 57; Iter   788/ 1097] train: loss: 0.0034774
[Epoch 57; Iter   818/ 1097] train: loss: 0.0044183
[Epoch 57; Iter   848/ 1097] train: loss: 0.0052046
[Epoch 57; Iter   878/ 1097] train: loss: 0.0074673
[Epoch 57; Iter   908/ 1097] train: loss: 0.0016150
[Epoch 57; Iter   938/ 1097] train: loss: 0.0007317
[Epoch 57; Iter   968/ 1097] train: loss: 0.0167736
[Epoch 57; Iter   998/ 1097] train: loss: 0.0999816
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0128556
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0445190
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0071110
[Epoch 57] ogbg-molhiv: 0.654848 val loss: 0.259875
[Epoch 57] ogbg-molhiv: 0.717007 test loss: 0.344799
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002054
[Epoch 58; Iter    51/ 1097] train: loss: 0.0068985
[Epoch 58; Iter    81/ 1097] train: loss: 0.0070533
[Epoch 58; Iter   111/ 1097] train: loss: 0.0001205
[Epoch 58; Iter   141/ 1097] train: loss: 0.0007272
[Epoch 58; Iter   171/ 1097] train: loss: 0.0005777
[Epoch 58; Iter   201/ 1097] train: loss: 0.0136410
[Epoch 58; Iter   231/ 1097] train: loss: 0.0072960
[Epoch 58; Iter   261/ 1097] train: loss: 0.0078941
[Epoch 58; Iter   291/ 1097] train: loss: 0.0169359
[Epoch 58; Iter   321/ 1097] train: loss: 0.0295505
[Epoch 58; Iter   351/ 1097] train: loss: 0.0013993
[Epoch 58; Iter   381/ 1097] train: loss: 0.0112703
[Epoch 58; Iter   411/ 1097] train: loss: 0.0194022
[Epoch 58; Iter   441/ 1097] train: loss: 0.0017791
[Epoch 58; Iter   471/ 1097] train: loss: 0.0010618
[Epoch 58; Iter   501/ 1097] train: loss: 0.0091071
[Epoch 58; Iter   531/ 1097] train: loss: 0.0376695
[Epoch 58; Iter   561/ 1097] train: loss: 0.0002436
[Epoch 58; Iter   591/ 1097] train: loss: 0.0025399
[Epoch 58; Iter   621/ 1097] train: loss: 0.0095745
[Epoch 58; Iter   651/ 1097] train: loss: 0.0001843
[Epoch 58; Iter   681/ 1097] train: loss: 0.0030462
[Epoch 58; Iter   711/ 1097] train: loss: 0.0041160
[Epoch 58; Iter   741/ 1097] train: loss: 0.0005583
[Epoch 58; Iter   771/ 1097] train: loss: 0.0005096
[Epoch 58; Iter   801/ 1097] train: loss: 0.0483317
[Epoch 58; Iter   831/ 1097] train: loss: 0.0052437
[Epoch 58; Iter   861/ 1097] train: loss: 0.0024305
[Epoch 58; Iter   891/ 1097] train: loss: 0.0008565
[Epoch 58; Iter   921/ 1097] train: loss: 0.0005661
[Epoch 58; Iter   951/ 1097] train: loss: 0.0801361
[Epoch 58; Iter   981/ 1097] train: loss: 0.0011634
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0002445
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0273708
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0498363
[Epoch 58] ogbg-molhiv: 0.696505 val loss: 1.198068
[Epoch 58] ogbg-molhiv: 0.739161 test loss: 0.506351
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002519
[Epoch 59; Iter    34/ 1097] train: loss: 0.0004367
[Epoch 59; Iter    64/ 1097] train: loss: 0.0033387
[Epoch 59; Iter    94/ 1097] train: loss: 0.0003597
[Epoch 59; Iter   124/ 1097] train: loss: 0.0003758
[Epoch 59; Iter   154/ 1097] train: loss: 0.0013891
[Epoch 59; Iter   184/ 1097] train: loss: 0.0000764
[Epoch 59; Iter   214/ 1097] train: loss: 0.0001023
[Epoch 59; Iter   244/ 1097] train: loss: 0.0044366
[Epoch 59; Iter   274/ 1097] train: loss: 0.0000769
[Epoch 59; Iter   304/ 1097] train: loss: 0.0315536
[Epoch 59; Iter   334/ 1097] train: loss: 0.0030622
[Epoch 59; Iter   364/ 1097] train: loss: 0.0073507
[Epoch 59; Iter   394/ 1097] train: loss: 0.0045668
[Epoch 59; Iter   424/ 1097] train: loss: 0.0018183
[Epoch 59; Iter   454/ 1097] train: loss: 0.0006826
[Epoch 59; Iter   484/ 1097] train: loss: 0.0022622
[Epoch 59; Iter   514/ 1097] train: loss: 0.0095979
[Epoch 59; Iter   544/ 1097] train: loss: 0.0005762
[Epoch 59; Iter   574/ 1097] train: loss: 0.0041436
[Epoch 59; Iter   604/ 1097] train: loss: 0.0011173
[Epoch 59; Iter   634/ 1097] train: loss: 0.0152005
[Epoch 59; Iter   664/ 1097] train: loss: 0.0119132
[Epoch 59; Iter   694/ 1097] train: loss: 0.0034717
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001987
[Epoch 59; Iter   754/ 1097] train: loss: 0.0043749
[Epoch 59; Iter   784/ 1097] train: loss: 0.0014093
[Epoch 59; Iter   814/ 1097] train: loss: 0.0002835
[Epoch 59; Iter   844/ 1097] train: loss: 0.0052753
[Epoch 59; Iter   874/ 1097] train: loss: 0.0748578
[Epoch 59; Iter   904/ 1097] train: loss: 0.0006941
[Epoch 59; Iter   934/ 1097] train: loss: 0.0421101
[Epoch 59; Iter   964/ 1097] train: loss: 0.0004427
[Epoch 59; Iter   994/ 1097] train: loss: 0.0023113
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0095397
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0025999
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0113199
[Epoch 59] ogbg-molhiv: 0.733383 val loss: 0.194301
[Epoch 59] ogbg-molhiv: 0.738448 test loss: 0.308387
[Epoch 60; Iter    17/ 1097] train: loss: 0.0224152
[Epoch 60; Iter    47/ 1097] train: loss: 0.0043935
[Epoch 60; Iter    77/ 1097] train: loss: 0.0005322
[Epoch 60; Iter   107/ 1097] train: loss: 0.0197291
[Epoch 60; Iter   137/ 1097] train: loss: 0.0064587
[Epoch 60; Iter   167/ 1097] train: loss: 0.0026241
[Epoch 60; Iter   197/ 1097] train: loss: 0.1051992
[Epoch 60; Iter   227/ 1097] train: loss: 0.0138898
[Epoch 60; Iter   257/ 1097] train: loss: 0.0031357
[Epoch 60; Iter   287/ 1097] train: loss: 0.0077376
[Epoch 60; Iter   317/ 1097] train: loss: 0.0014416
[Epoch 60; Iter   347/ 1097] train: loss: 0.0065306
[Epoch 60; Iter   377/ 1097] train: loss: 0.0040330
[Epoch 60; Iter   407/ 1097] train: loss: 0.0016877
[Epoch 60; Iter   437/ 1097] train: loss: 0.0012631
[Epoch 60; Iter   467/ 1097] train: loss: 0.0001543
[Epoch 60; Iter   497/ 1097] train: loss: 0.0000896
[Epoch 60; Iter   527/ 1097] train: loss: 0.0019864
[Epoch 60; Iter   557/ 1097] train: loss: 0.0047822
[Epoch 60; Iter   587/ 1097] train: loss: 0.0014155
[Epoch 60; Iter   617/ 1097] train: loss: 0.0018574
[Epoch 60; Iter   647/ 1097] train: loss: 0.0007508
[Epoch 60; Iter   677/ 1097] train: loss: 0.0004278
[Epoch 60; Iter   707/ 1097] train: loss: 0.0024886
[Epoch 60; Iter   737/ 1097] train: loss: 0.0002334
[Epoch 60; Iter   767/ 1097] train: loss: 0.0002004
[Epoch 60; Iter   797/ 1097] train: loss: 0.0000456
[Epoch 60; Iter   827/ 1097] train: loss: 0.0023669
[Epoch 60; Iter   857/ 1097] train: loss: 0.0019718
[Epoch 60; Iter   887/ 1097] train: loss: 0.0011000
[Epoch 60; Iter   917/ 1097] train: loss: 0.0217625
[Epoch 60; Iter   947/ 1097] train: loss: 0.0234474
[Epoch 60; Iter   977/ 1097] train: loss: 0.0003028
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0972981
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0168197
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0012016
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0014639
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0791467
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0024930
[Epoch 56] ogbg-molhiv: 0.725061 val loss: 1.529102
[Epoch 56] ogbg-molhiv: 0.730070 test loss: 0.933466
[Epoch 57; Iter     8/ 1097] train: loss: 0.0012984
[Epoch 57; Iter    38/ 1097] train: loss: 0.0003761
[Epoch 57; Iter    68/ 1097] train: loss: 0.0001632
[Epoch 57; Iter    98/ 1097] train: loss: 0.0003806
[Epoch 57; Iter   128/ 1097] train: loss: 0.0016249
[Epoch 57; Iter   158/ 1097] train: loss: 0.0002669
[Epoch 57; Iter   188/ 1097] train: loss: 0.0412782
[Epoch 57; Iter   218/ 1097] train: loss: 0.0048640
[Epoch 57; Iter   248/ 1097] train: loss: 0.0308455
[Epoch 57; Iter   278/ 1097] train: loss: 0.0004026
[Epoch 57; Iter   308/ 1097] train: loss: 0.0251498
[Epoch 57; Iter   338/ 1097] train: loss: 0.0019438
[Epoch 57; Iter   368/ 1097] train: loss: 0.0025957
[Epoch 57; Iter   398/ 1097] train: loss: 0.0021998
[Epoch 57; Iter   428/ 1097] train: loss: 0.0225105
[Epoch 57; Iter   458/ 1097] train: loss: 0.0026974
[Epoch 57; Iter   488/ 1097] train: loss: 0.0300414
[Epoch 57; Iter   518/ 1097] train: loss: 0.0028585
[Epoch 57; Iter   548/ 1097] train: loss: 0.0193771
[Epoch 57; Iter   578/ 1097] train: loss: 0.0014537
[Epoch 57; Iter   608/ 1097] train: loss: 0.1493990
[Epoch 57; Iter   638/ 1097] train: loss: 0.0244643
[Epoch 57; Iter   668/ 1097] train: loss: 0.0019984
[Epoch 57; Iter   698/ 1097] train: loss: 0.0114854
[Epoch 57; Iter   728/ 1097] train: loss: 0.0027894
[Epoch 57; Iter   758/ 1097] train: loss: 0.0098471
[Epoch 57; Iter   788/ 1097] train: loss: 0.0019862
[Epoch 57; Iter   818/ 1097] train: loss: 0.0787888
[Epoch 57; Iter   848/ 1097] train: loss: 0.0058881
[Epoch 57; Iter   878/ 1097] train: loss: 0.0052305
[Epoch 57; Iter   908/ 1097] train: loss: 0.0072854
[Epoch 57; Iter   938/ 1097] train: loss: 0.0402373
[Epoch 57; Iter   968/ 1097] train: loss: 0.0262033
[Epoch 57; Iter   998/ 1097] train: loss: 0.0160230
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0119460
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0021188
[Epoch 57; Iter  1088/ 1097] train: loss: 0.1126415
[Epoch 57] ogbg-molhiv: 0.689420 val loss: 6.000117
[Epoch 57] ogbg-molhiv: 0.673329 test loss: 2.946623
[Epoch 58; Iter    21/ 1097] train: loss: 0.1739553
[Epoch 58; Iter    51/ 1097] train: loss: 0.0042350
[Epoch 58; Iter    81/ 1097] train: loss: 0.0012920
[Epoch 58; Iter   111/ 1097] train: loss: 0.0047988
[Epoch 58; Iter   141/ 1097] train: loss: 0.0019310
[Epoch 58; Iter   171/ 1097] train: loss: 0.0005529
[Epoch 58; Iter   201/ 1097] train: loss: 0.0938668
[Epoch 58; Iter   231/ 1097] train: loss: 0.0004746
[Epoch 58; Iter   261/ 1097] train: loss: 0.0093066
[Epoch 58; Iter   291/ 1097] train: loss: 0.0159109
[Epoch 58; Iter   321/ 1097] train: loss: 0.0069939
[Epoch 58; Iter   351/ 1097] train: loss: 0.0718067
[Epoch 58; Iter   381/ 1097] train: loss: 0.0050191
[Epoch 58; Iter   411/ 1097] train: loss: 0.0211114
[Epoch 58; Iter   441/ 1097] train: loss: 0.0399153
[Epoch 58; Iter   471/ 1097] train: loss: 0.0435817
[Epoch 58; Iter   501/ 1097] train: loss: 0.0029856
[Epoch 58; Iter   531/ 1097] train: loss: 0.0027930
[Epoch 58; Iter   561/ 1097] train: loss: 0.0063565
[Epoch 58; Iter   591/ 1097] train: loss: 0.0084843
[Epoch 58; Iter   621/ 1097] train: loss: 0.0009176
[Epoch 58; Iter   651/ 1097] train: loss: 0.0083403
[Epoch 58; Iter   681/ 1097] train: loss: 0.0181148
[Epoch 58; Iter   711/ 1097] train: loss: 0.0843930
[Epoch 58; Iter   741/ 1097] train: loss: 0.0502173
[Epoch 58; Iter   771/ 1097] train: loss: 0.0012864
[Epoch 58; Iter   801/ 1097] train: loss: 0.0033355
[Epoch 58; Iter   831/ 1097] train: loss: 0.0441062
[Epoch 58; Iter   861/ 1097] train: loss: 0.0327022
[Epoch 58; Iter   891/ 1097] train: loss: 0.0170550
[Epoch 58; Iter   921/ 1097] train: loss: 0.0063270
[Epoch 58; Iter   951/ 1097] train: loss: 0.0308696
[Epoch 58; Iter   981/ 1097] train: loss: 0.0008969
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0057313
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0036877
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0505977
[Epoch 58] ogbg-molhiv: 0.716135 val loss: 2.517565
[Epoch 58] ogbg-molhiv: 0.713357 test loss: 0.848195
[Epoch 59; Iter     4/ 1097] train: loss: 0.0098575
[Epoch 59; Iter    34/ 1097] train: loss: 0.0107470
[Epoch 59; Iter    64/ 1097] train: loss: 0.0015889
[Epoch 59; Iter    94/ 1097] train: loss: 0.0396544
[Epoch 59; Iter   124/ 1097] train: loss: 0.0005957
[Epoch 59; Iter   154/ 1097] train: loss: 0.0314725
[Epoch 59; Iter   184/ 1097] train: loss: 0.0034178
[Epoch 59; Iter   214/ 1097] train: loss: 0.0064126
[Epoch 59; Iter   244/ 1097] train: loss: 0.0003032
[Epoch 59; Iter   274/ 1097] train: loss: 0.0083336
[Epoch 59; Iter   304/ 1097] train: loss: 0.0252952
[Epoch 59; Iter   334/ 1097] train: loss: 0.0021803
[Epoch 59; Iter   364/ 1097] train: loss: 0.0020659
[Epoch 59; Iter   394/ 1097] train: loss: 0.0006222
[Epoch 59; Iter   424/ 1097] train: loss: 0.0134565
[Epoch 59; Iter   454/ 1097] train: loss: 0.0127218
[Epoch 59; Iter   484/ 1097] train: loss: 0.0012401
[Epoch 59; Iter   514/ 1097] train: loss: 0.0006948
[Epoch 59; Iter   544/ 1097] train: loss: 0.0113233
[Epoch 59; Iter   574/ 1097] train: loss: 0.0040843
[Epoch 59; Iter   604/ 1097] train: loss: 0.0015680
[Epoch 59; Iter   634/ 1097] train: loss: 0.0096393
[Epoch 59; Iter   664/ 1097] train: loss: 0.0022820
[Epoch 59; Iter   694/ 1097] train: loss: 0.0179429
[Epoch 59; Iter   724/ 1097] train: loss: 0.0039870
[Epoch 59; Iter   754/ 1097] train: loss: 0.0009588
[Epoch 59; Iter   784/ 1097] train: loss: 0.0015653
[Epoch 59; Iter   814/ 1097] train: loss: 0.0013824
[Epoch 59; Iter   844/ 1097] train: loss: 0.0006899
[Epoch 59; Iter   874/ 1097] train: loss: 0.0741757
[Epoch 59; Iter   904/ 1097] train: loss: 0.0086646
[Epoch 59; Iter   934/ 1097] train: loss: 0.0016005
[Epoch 59; Iter   964/ 1097] train: loss: 0.0043849
[Epoch 59; Iter   994/ 1097] train: loss: 0.0119792
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0128838
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0006426
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0007847
[Epoch 59] ogbg-molhiv: 0.701413 val loss: 1.688973
[Epoch 59] ogbg-molhiv: 0.720051 test loss: 0.645727
[Epoch 60; Iter    17/ 1097] train: loss: 0.0747419
[Epoch 60; Iter    47/ 1097] train: loss: 0.0405551
[Epoch 60; Iter    77/ 1097] train: loss: 0.0085400
[Epoch 60; Iter   107/ 1097] train: loss: 0.0260374
[Epoch 60; Iter   137/ 1097] train: loss: 0.0002808
[Epoch 60; Iter   167/ 1097] train: loss: 0.0059802
[Epoch 60; Iter   197/ 1097] train: loss: 0.0120490
[Epoch 60; Iter   227/ 1097] train: loss: 0.0895654
[Epoch 60; Iter   257/ 1097] train: loss: 0.0081202
[Epoch 60; Iter   287/ 1097] train: loss: 0.0004383
[Epoch 60; Iter   317/ 1097] train: loss: 0.0026970
[Epoch 60; Iter   347/ 1097] train: loss: 0.0349052
[Epoch 60; Iter   377/ 1097] train: loss: 0.0008598
[Epoch 60; Iter   407/ 1097] train: loss: 0.0004478
[Epoch 60; Iter   437/ 1097] train: loss: 0.0051448
[Epoch 60; Iter   467/ 1097] train: loss: 0.0171800
[Epoch 60; Iter   497/ 1097] train: loss: 0.0004575
[Epoch 60; Iter   527/ 1097] train: loss: 0.0210918
[Epoch 60; Iter   557/ 1097] train: loss: 0.0007378
[Epoch 60; Iter   587/ 1097] train: loss: 0.0203947
[Epoch 60; Iter   617/ 1097] train: loss: 0.0010406
[Epoch 60; Iter   647/ 1097] train: loss: 0.0340191
[Epoch 60; Iter   677/ 1097] train: loss: 0.0036828
[Epoch 60; Iter   707/ 1097] train: loss: 0.0004783
[Epoch 60; Iter   737/ 1097] train: loss: 0.0010689
[Epoch 60; Iter   767/ 1097] train: loss: 0.1916140
[Epoch 60; Iter   797/ 1097] train: loss: 0.0019004
[Epoch 60; Iter   827/ 1097] train: loss: 0.0017594
[Epoch 60; Iter   857/ 1097] train: loss: 0.0001126
[Epoch 60; Iter   887/ 1097] train: loss: 0.0003049
[Epoch 60; Iter   917/ 1097] train: loss: 0.0230762
[Epoch 60; Iter   947/ 1097] train: loss: 0.0027122
[Epoch 60; Iter   977/ 1097] train: loss: 0.0274573
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0061065
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0086500
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0024059
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0047963
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0049102
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0618107
[Epoch 56] ogbg-molhiv: 0.772860 val loss: 0.279071
[Epoch 56] ogbg-molhiv: 0.752711 test loss: 0.305997
[Epoch 57; Iter     8/ 1097] train: loss: 0.0002752
[Epoch 57; Iter    38/ 1097] train: loss: 0.0002855
[Epoch 57; Iter    68/ 1097] train: loss: 0.0006532
[Epoch 57; Iter    98/ 1097] train: loss: 0.0105995
[Epoch 57; Iter   128/ 1097] train: loss: 0.0018338
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000604
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023726
[Epoch 57; Iter   218/ 1097] train: loss: 0.0001329
[Epoch 57; Iter   248/ 1097] train: loss: 0.0025123
[Epoch 57; Iter   278/ 1097] train: loss: 0.0026994
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005770
[Epoch 57; Iter   338/ 1097] train: loss: 0.0001940
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001486
[Epoch 57; Iter   398/ 1097] train: loss: 0.0009665
[Epoch 57; Iter   428/ 1097] train: loss: 0.0049412
[Epoch 57; Iter   458/ 1097] train: loss: 0.0018863
[Epoch 57; Iter   488/ 1097] train: loss: 0.0003497
[Epoch 57; Iter   518/ 1097] train: loss: 0.0148051
[Epoch 57; Iter   548/ 1097] train: loss: 0.0039035
[Epoch 57; Iter   578/ 1097] train: loss: 0.0114963
[Epoch 57; Iter   608/ 1097] train: loss: 0.0077783
[Epoch 57; Iter   638/ 1097] train: loss: 0.0040632
[Epoch 57; Iter   668/ 1097] train: loss: 0.0091001
[Epoch 57; Iter   698/ 1097] train: loss: 0.0015888
[Epoch 57; Iter   728/ 1097] train: loss: 0.0015968
[Epoch 57; Iter   758/ 1097] train: loss: 0.0001357
[Epoch 57; Iter   788/ 1097] train: loss: 0.1301500
[Epoch 57; Iter   818/ 1097] train: loss: 0.0100291
[Epoch 57; Iter   848/ 1097] train: loss: 0.0299003
[Epoch 57; Iter   878/ 1097] train: loss: 0.0031015
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005176
[Epoch 57; Iter   938/ 1097] train: loss: 0.0030745
[Epoch 57; Iter   968/ 1097] train: loss: 0.0063760
[Epoch 57; Iter   998/ 1097] train: loss: 0.0005965
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0003880
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003470
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0006665
[Epoch 57] ogbg-molhiv: 0.771455 val loss: 0.276665
[Epoch 57] ogbg-molhiv: 0.744382 test loss: 0.261859
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002006
[Epoch 58; Iter    51/ 1097] train: loss: 0.0004367
[Epoch 58; Iter    81/ 1097] train: loss: 0.0002432
[Epoch 58; Iter   111/ 1097] train: loss: 0.0002438
[Epoch 58; Iter   141/ 1097] train: loss: 0.0004795
[Epoch 58; Iter   171/ 1097] train: loss: 0.0015323
[Epoch 58; Iter   201/ 1097] train: loss: 0.0027338
[Epoch 58; Iter   231/ 1097] train: loss: 0.0223957
[Epoch 58; Iter   261/ 1097] train: loss: 0.0004112
[Epoch 58; Iter   291/ 1097] train: loss: 0.0003503
[Epoch 58; Iter   321/ 1097] train: loss: 0.0022790
[Epoch 58; Iter   351/ 1097] train: loss: 0.0070012
[Epoch 58; Iter   381/ 1097] train: loss: 0.0009999
[Epoch 58; Iter   411/ 1097] train: loss: 0.0010581
[Epoch 58; Iter   441/ 1097] train: loss: 0.0018167
[Epoch 58; Iter   471/ 1097] train: loss: 0.0163482
[Epoch 58; Iter   501/ 1097] train: loss: 0.0029094
[Epoch 58; Iter   531/ 1097] train: loss: 0.0015594
[Epoch 58; Iter   561/ 1097] train: loss: 0.0007350
[Epoch 58; Iter   591/ 1097] train: loss: 0.0012775
[Epoch 58; Iter   621/ 1097] train: loss: 0.0761527
[Epoch 58; Iter   651/ 1097] train: loss: 0.0018141
[Epoch 58; Iter   681/ 1097] train: loss: 0.0054593
[Epoch 58; Iter   711/ 1097] train: loss: 0.0118868
[Epoch 58; Iter   741/ 1097] train: loss: 0.0061091
[Epoch 58; Iter   771/ 1097] train: loss: 0.0001247
[Epoch 58; Iter   801/ 1097] train: loss: 0.0005761
[Epoch 58; Iter   831/ 1097] train: loss: 0.0014317
[Epoch 58; Iter   861/ 1097] train: loss: 0.0005867
[Epoch 58; Iter   891/ 1097] train: loss: 0.0001937
[Epoch 58; Iter   921/ 1097] train: loss: 0.0047170
[Epoch 58; Iter   951/ 1097] train: loss: 0.0001170
[Epoch 58; Iter   981/ 1097] train: loss: 0.0050159
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0001250
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0001467
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0506568
[Epoch 58] ogbg-molhiv: 0.784636 val loss: 0.293226
[Epoch 58] ogbg-molhiv: 0.741594 test loss: 0.310647
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002586
[Epoch 59; Iter    34/ 1097] train: loss: 0.0078824
[Epoch 59; Iter    64/ 1097] train: loss: 0.0388659
[Epoch 59; Iter    94/ 1097] train: loss: 0.0015580
[Epoch 59; Iter   124/ 1097] train: loss: 0.0016822
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000407
[Epoch 59; Iter   184/ 1097] train: loss: 0.0008144
[Epoch 59; Iter   214/ 1097] train: loss: 0.0003181
[Epoch 59; Iter   244/ 1097] train: loss: 0.0000570
[Epoch 59; Iter   274/ 1097] train: loss: 0.0015524
[Epoch 59; Iter   304/ 1097] train: loss: 0.0000919
[Epoch 59; Iter   334/ 1097] train: loss: 0.0051319
[Epoch 59; Iter   364/ 1097] train: loss: 0.0024547
[Epoch 59; Iter   394/ 1097] train: loss: 0.0019371
[Epoch 59; Iter   424/ 1097] train: loss: 0.0001206
[Epoch 59; Iter   454/ 1097] train: loss: 0.0009854
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007053
[Epoch 59; Iter   514/ 1097] train: loss: 0.0035710
[Epoch 59; Iter   544/ 1097] train: loss: 0.0133519
[Epoch 59; Iter   574/ 1097] train: loss: 0.0121329
[Epoch 59; Iter   604/ 1097] train: loss: 0.0037318
[Epoch 59; Iter   634/ 1097] train: loss: 0.0004775
[Epoch 59; Iter   664/ 1097] train: loss: 0.0003002
[Epoch 59; Iter   694/ 1097] train: loss: 0.0005049
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001187
[Epoch 59; Iter   754/ 1097] train: loss: 0.0229635
[Epoch 59; Iter   784/ 1097] train: loss: 0.0011126
[Epoch 59; Iter   814/ 1097] train: loss: 0.0137631
[Epoch 59; Iter   844/ 1097] train: loss: 0.0002078
[Epoch 59; Iter   874/ 1097] train: loss: 0.0082950
[Epoch 59; Iter   904/ 1097] train: loss: 0.0011618
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001831
[Epoch 59; Iter   964/ 1097] train: loss: 0.0004172
[Epoch 59; Iter   994/ 1097] train: loss: 0.0036091
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0000914
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0004729
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0011380
[Epoch 59] ogbg-molhiv: 0.763730 val loss: 0.267400
[Epoch 59] ogbg-molhiv: 0.750414 test loss: 0.300179
[Epoch 60; Iter    17/ 1097] train: loss: 0.0000653
[Epoch 60; Iter    47/ 1097] train: loss: 0.0000809
[Epoch 60; Iter    77/ 1097] train: loss: 0.0074894
[Epoch 60; Iter   107/ 1097] train: loss: 0.0002337
[Epoch 60; Iter   137/ 1097] train: loss: 0.0587191
[Epoch 60; Iter   167/ 1097] train: loss: 0.0001593
[Epoch 60; Iter   197/ 1097] train: loss: 0.0008668
[Epoch 60; Iter   227/ 1097] train: loss: 0.0055796
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001444
[Epoch 60; Iter   287/ 1097] train: loss: 0.0001021
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003889
[Epoch 60; Iter   347/ 1097] train: loss: 0.0021350
[Epoch 60; Iter   377/ 1097] train: loss: 0.0002458
[Epoch 60; Iter   407/ 1097] train: loss: 0.0000978
[Epoch 60; Iter   437/ 1097] train: loss: 0.0078508
[Epoch 60; Iter   467/ 1097] train: loss: 0.0081572
[Epoch 60; Iter   497/ 1097] train: loss: 0.0167396
[Epoch 60; Iter   527/ 1097] train: loss: 0.0010222
[Epoch 60; Iter   557/ 1097] train: loss: 0.0012075
[Epoch 60; Iter   587/ 1097] train: loss: 0.0024916
[Epoch 60; Iter   617/ 1097] train: loss: 0.0002975
[Epoch 60; Iter   647/ 1097] train: loss: 0.0004742
[Epoch 60; Iter   677/ 1097] train: loss: 0.0076788
[Epoch 60; Iter   707/ 1097] train: loss: 0.0002554
[Epoch 60; Iter   737/ 1097] train: loss: 0.0034423
[Epoch 60; Iter   767/ 1097] train: loss: 0.0006371
[Epoch 60; Iter   797/ 1097] train: loss: 0.0002117
[Epoch 60; Iter   827/ 1097] train: loss: 0.0000768
[Epoch 60; Iter   857/ 1097] train: loss: 0.0139295
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001865
[Epoch 60; Iter   917/ 1097] train: loss: 0.0069005
[Epoch 60; Iter   947/ 1097] train: loss: 0.0220749
[Epoch 60; Iter   977/ 1097] train: loss: 0.0055831
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0006070
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0002217
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0003514
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000637
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0039209
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0062842
[Epoch 56] ogbg-molhiv: 0.779107 val loss: 0.192194
[Epoch 56] ogbg-molhiv: 0.737448 test loss: 0.340016
[Epoch 57; Iter     8/ 1097] train: loss: 0.0080982
[Epoch 57; Iter    38/ 1097] train: loss: 0.0007964
[Epoch 57; Iter    68/ 1097] train: loss: 0.0004282
[Epoch 57; Iter    98/ 1097] train: loss: 0.0078138
[Epoch 57; Iter   128/ 1097] train: loss: 0.0022961
[Epoch 57; Iter   158/ 1097] train: loss: 0.0055196
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023466
[Epoch 57; Iter   218/ 1097] train: loss: 0.0026420
[Epoch 57; Iter   248/ 1097] train: loss: 0.0005948
[Epoch 57; Iter   278/ 1097] train: loss: 0.0000675
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005465
[Epoch 57; Iter   338/ 1097] train: loss: 0.0001897
[Epoch 57; Iter   368/ 1097] train: loss: 0.0397476
[Epoch 57; Iter   398/ 1097] train: loss: 0.0336130
[Epoch 57; Iter   428/ 1097] train: loss: 0.0220011
[Epoch 57; Iter   458/ 1097] train: loss: 0.0022127
[Epoch 57; Iter   488/ 1097] train: loss: 0.0032239
[Epoch 57; Iter   518/ 1097] train: loss: 0.0003963
[Epoch 57; Iter   548/ 1097] train: loss: 0.0244291
[Epoch 57; Iter   578/ 1097] train: loss: 0.0003114
[Epoch 57; Iter   608/ 1097] train: loss: 0.0274337
[Epoch 57; Iter   638/ 1097] train: loss: 0.0014323
[Epoch 57; Iter   668/ 1097] train: loss: 0.0006151
[Epoch 57; Iter   698/ 1097] train: loss: 0.0468526
[Epoch 57; Iter   728/ 1097] train: loss: 0.0005883
[Epoch 57; Iter   758/ 1097] train: loss: 0.0034618
[Epoch 57; Iter   788/ 1097] train: loss: 0.0034749
[Epoch 57; Iter   818/ 1097] train: loss: 0.0013460
[Epoch 57; Iter   848/ 1097] train: loss: 0.0000559
[Epoch 57; Iter   878/ 1097] train: loss: 0.0021468
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005819
[Epoch 57; Iter   938/ 1097] train: loss: 0.0049393
[Epoch 57; Iter   968/ 1097] train: loss: 0.0007679
[Epoch 57; Iter   998/ 1097] train: loss: 0.0008456
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0200953
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0045316
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0015841
[Epoch 57] ogbg-molhiv: 0.755502 val loss: 0.171281
[Epoch 57] ogbg-molhiv: 0.698782 test loss: 0.303118
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002392
[Epoch 58; Iter    51/ 1097] train: loss: 0.0016182
[Epoch 58; Iter    81/ 1097] train: loss: 0.0000746
[Epoch 58; Iter   111/ 1097] train: loss: 0.0005065
[Epoch 58; Iter   141/ 1097] train: loss: 0.0018523
[Epoch 58; Iter   171/ 1097] train: loss: 0.0018044
[Epoch 58; Iter   201/ 1097] train: loss: 0.0293751
[Epoch 58; Iter   231/ 1097] train: loss: 0.0467128
[Epoch 58; Iter   261/ 1097] train: loss: 0.0020168
[Epoch 58; Iter   291/ 1097] train: loss: 0.0058726
[Epoch 58; Iter   321/ 1097] train: loss: 0.0023651
[Epoch 58; Iter   351/ 1097] train: loss: 0.0000573
[Epoch 58; Iter   381/ 1097] train: loss: 0.0186978
[Epoch 58; Iter   411/ 1097] train: loss: 0.0003756
[Epoch 58; Iter   441/ 1097] train: loss: 0.0001628
[Epoch 58; Iter   471/ 1097] train: loss: 0.0012990
[Epoch 58; Iter   501/ 1097] train: loss: 0.0001565
[Epoch 58; Iter   531/ 1097] train: loss: 0.0003597
[Epoch 58; Iter   561/ 1097] train: loss: 0.0007687
[Epoch 58; Iter   591/ 1097] train: loss: 0.0004185
[Epoch 58; Iter   621/ 1097] train: loss: 0.0007356
[Epoch 58; Iter   651/ 1097] train: loss: 0.0006584
[Epoch 58; Iter   681/ 1097] train: loss: 0.0030540
[Epoch 58; Iter   711/ 1097] train: loss: 0.0031072
[Epoch 58; Iter   741/ 1097] train: loss: 0.0020601
[Epoch 58; Iter   771/ 1097] train: loss: 0.0004624
[Epoch 58; Iter   801/ 1097] train: loss: 0.0016194
[Epoch 58; Iter   831/ 1097] train: loss: 0.0182242
[Epoch 58; Iter   861/ 1097] train: loss: 0.0005509
[Epoch 58; Iter   891/ 1097] train: loss: 0.0010528
[Epoch 58; Iter   921/ 1097] train: loss: 0.0005608
[Epoch 58; Iter   951/ 1097] train: loss: 0.0034381
[Epoch 58; Iter   981/ 1097] train: loss: 0.0041989
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0005318
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0016878
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0003646
[Epoch 58] ogbg-molhiv: 0.755937 val loss: 0.209019
[Epoch 58] ogbg-molhiv: 0.685589 test loss: 0.324582
[Epoch 59; Iter     4/ 1097] train: loss: 0.0108423
[Epoch 59; Iter    34/ 1097] train: loss: 0.0003165
[Epoch 59; Iter    64/ 1097] train: loss: 0.0002424
[Epoch 59; Iter    94/ 1097] train: loss: 0.0013992
[Epoch 59; Iter   124/ 1097] train: loss: 0.0012979
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000933
[Epoch 59; Iter   184/ 1097] train: loss: 0.0015321
[Epoch 59; Iter   214/ 1097] train: loss: 0.0001738
[Epoch 59; Iter   244/ 1097] train: loss: 0.0005414
[Epoch 59; Iter   274/ 1097] train: loss: 0.0153148
[Epoch 59; Iter   304/ 1097] train: loss: 0.0286019
[Epoch 59; Iter   334/ 1097] train: loss: 0.0038318
[Epoch 59; Iter   364/ 1097] train: loss: 0.0008551
[Epoch 59; Iter   394/ 1097] train: loss: 0.0051812
[Epoch 59; Iter   424/ 1097] train: loss: 0.0039603
[Epoch 59; Iter   454/ 1097] train: loss: 0.0082870
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007878
[Epoch 59; Iter   514/ 1097] train: loss: 0.0101784
[Epoch 59; Iter   544/ 1097] train: loss: 0.0023163
[Epoch 59; Iter   574/ 1097] train: loss: 0.0004435
[Epoch 59; Iter   604/ 1097] train: loss: 0.0002632
[Epoch 59; Iter   634/ 1097] train: loss: 0.0023235
[Epoch 59; Iter   664/ 1097] train: loss: 0.0011284
[Epoch 59; Iter   694/ 1097] train: loss: 0.0009278
[Epoch 59; Iter   724/ 1097] train: loss: 0.0457641
[Epoch 59; Iter   754/ 1097] train: loss: 0.0018719
[Epoch 59; Iter   784/ 1097] train: loss: 0.0023863
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000724
[Epoch 59; Iter   844/ 1097] train: loss: 0.1542762
[Epoch 59; Iter   874/ 1097] train: loss: 0.0006984
[Epoch 59; Iter   904/ 1097] train: loss: 0.0003742
[Epoch 59; Iter   934/ 1097] train: loss: 0.0152872
[Epoch 59; Iter   964/ 1097] train: loss: 0.0023224
[Epoch 59; Iter   994/ 1097] train: loss: 0.0005077
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0006160
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0013695
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0015460
[Epoch 59] ogbg-molhiv: 0.788292 val loss: 0.192762
[Epoch 59] ogbg-molhiv: 0.743709 test loss: 0.304059
[Epoch 60; Iter    17/ 1097] train: loss: 0.0002995
[Epoch 60; Iter    47/ 1097] train: loss: 0.0001203
[Epoch 60; Iter    77/ 1097] train: loss: 0.0042175
[Epoch 60; Iter   107/ 1097] train: loss: 0.1315386
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000919
[Epoch 60; Iter   167/ 1097] train: loss: 0.0012853
[Epoch 60; Iter   197/ 1097] train: loss: 0.0018053
[Epoch 60; Iter   227/ 1097] train: loss: 0.0030160
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001401
[Epoch 60; Iter   287/ 1097] train: loss: 0.0002890
[Epoch 60; Iter   317/ 1097] train: loss: 0.0020090
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001968
[Epoch 60; Iter   377/ 1097] train: loss: 0.0301416
[Epoch 60; Iter   407/ 1097] train: loss: 0.0005065
[Epoch 60; Iter   437/ 1097] train: loss: 0.0110286
[Epoch 60; Iter   467/ 1097] train: loss: 0.0007489
[Epoch 60; Iter   497/ 1097] train: loss: 0.0002752
[Epoch 60; Iter   527/ 1097] train: loss: 0.0957194
[Epoch 60; Iter   557/ 1097] train: loss: 0.0050052
[Epoch 60; Iter   587/ 1097] train: loss: 0.0073052
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001893
[Epoch 60; Iter   647/ 1097] train: loss: 0.0022341
[Epoch 60; Iter   677/ 1097] train: loss: 0.0008038
[Epoch 60; Iter   707/ 1097] train: loss: 0.0026671
[Epoch 60; Iter   737/ 1097] train: loss: 0.0027948
[Epoch 60; Iter   767/ 1097] train: loss: 0.1048423
[Epoch 60; Iter   797/ 1097] train: loss: 0.0040392
[Epoch 60; Iter   827/ 1097] train: loss: 0.0016169
[Epoch 60; Iter   857/ 1097] train: loss: 0.0019321
[Epoch 60; Iter   887/ 1097] train: loss: 0.0003320
[Epoch 60; Iter   917/ 1097] train: loss: 0.0004599
[Epoch 60; Iter   947/ 1097] train: loss: 0.0003978
[Epoch 60; Iter   977/ 1097] train: loss: 0.0011970
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0086831
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0311290
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0023981
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0025274
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0332523
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0016420
[Epoch 56] ogbg-molhiv: 0.788522 val loss: 0.198983
[Epoch 56] ogbg-molhiv: 0.735856 test loss: 0.325227
[Epoch 57; Iter     8/ 1097] train: loss: 0.0001515
[Epoch 57; Iter    38/ 1097] train: loss: 0.0074106
[Epoch 57; Iter    68/ 1097] train: loss: 0.0296389
[Epoch 57; Iter    98/ 1097] train: loss: 0.0033440
[Epoch 57; Iter   128/ 1097] train: loss: 0.0018282
[Epoch 57; Iter   158/ 1097] train: loss: 0.0084361
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023310
[Epoch 57; Iter   218/ 1097] train: loss: 0.0047967
[Epoch 57; Iter   248/ 1097] train: loss: 0.0016970
[Epoch 57; Iter   278/ 1097] train: loss: 0.0002474
[Epoch 57; Iter   308/ 1097] train: loss: 0.0010837
[Epoch 57; Iter   338/ 1097] train: loss: 0.0005564
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001941
[Epoch 57; Iter   398/ 1097] train: loss: 0.0010750
[Epoch 57; Iter   428/ 1097] train: loss: 0.0007350
[Epoch 57; Iter   458/ 1097] train: loss: 0.0022308
[Epoch 57; Iter   488/ 1097] train: loss: 0.0010137
[Epoch 57; Iter   518/ 1097] train: loss: 0.0001194
[Epoch 57; Iter   548/ 1097] train: loss: 0.0027326
[Epoch 57; Iter   578/ 1097] train: loss: 0.0593566
[Epoch 57; Iter   608/ 1097] train: loss: 0.1062663
[Epoch 57; Iter   638/ 1097] train: loss: 0.0002109
[Epoch 57; Iter   668/ 1097] train: loss: 0.0248921
[Epoch 57; Iter   698/ 1097] train: loss: 0.0002250
[Epoch 57; Iter   728/ 1097] train: loss: 0.0012580
[Epoch 57; Iter   758/ 1097] train: loss: 0.0015936
[Epoch 57; Iter   788/ 1097] train: loss: 0.0409803
[Epoch 57; Iter   818/ 1097] train: loss: 0.0668946
[Epoch 57; Iter   848/ 1097] train: loss: 0.0021253
[Epoch 57; Iter   878/ 1097] train: loss: 0.0009592
[Epoch 57; Iter   908/ 1097] train: loss: 0.0018604
[Epoch 57; Iter   938/ 1097] train: loss: 0.0021164
[Epoch 57; Iter   968/ 1097] train: loss: 0.0004193
[Epoch 57; Iter   998/ 1097] train: loss: 0.0003296
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0001278
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0017809
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0019699
[Epoch 57] ogbg-molhiv: 0.794970 val loss: 0.196800
[Epoch 57] ogbg-molhiv: 0.721588 test loss: 0.325240
[Epoch 58; Iter    21/ 1097] train: loss: 0.0032711
[Epoch 58; Iter    51/ 1097] train: loss: 0.0080315
[Epoch 58; Iter    81/ 1097] train: loss: 0.0028268
[Epoch 58; Iter   111/ 1097] train: loss: 0.0004621
[Epoch 58; Iter   141/ 1097] train: loss: 0.0001313
[Epoch 58; Iter   171/ 1097] train: loss: 0.0000836
[Epoch 58; Iter   201/ 1097] train: loss: 0.0011993
[Epoch 58; Iter   231/ 1097] train: loss: 0.0262059
[Epoch 58; Iter   261/ 1097] train: loss: 0.0011512
[Epoch 58; Iter   291/ 1097] train: loss: 0.0022385
[Epoch 58; Iter   321/ 1097] train: loss: 0.0019591
[Epoch 58; Iter   351/ 1097] train: loss: 0.0003426
[Epoch 58; Iter   381/ 1097] train: loss: 0.0002092
[Epoch 58; Iter   411/ 1097] train: loss: 0.0010317
[Epoch 58; Iter   441/ 1097] train: loss: 0.0007181
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001692
[Epoch 58; Iter   501/ 1097] train: loss: 0.0195988
[Epoch 58; Iter   531/ 1097] train: loss: 0.0212193
[Epoch 58; Iter   561/ 1097] train: loss: 0.0018597
[Epoch 58; Iter   591/ 1097] train: loss: 0.0022081
[Epoch 58; Iter   621/ 1097] train: loss: 0.0059295
[Epoch 58; Iter   651/ 1097] train: loss: 0.0003440
[Epoch 58; Iter   681/ 1097] train: loss: 0.0003713
[Epoch 58; Iter   711/ 1097] train: loss: 0.0133038
[Epoch 58; Iter   741/ 1097] train: loss: 0.0008666
[Epoch 58; Iter   771/ 1097] train: loss: 0.0003843
[Epoch 58; Iter   801/ 1097] train: loss: 0.0022346
[Epoch 58; Iter   831/ 1097] train: loss: 0.0036370
[Epoch 58; Iter   861/ 1097] train: loss: 0.0018374
[Epoch 58; Iter   891/ 1097] train: loss: 0.0002181
[Epoch 58; Iter   921/ 1097] train: loss: 0.0019087
[Epoch 58; Iter   951/ 1097] train: loss: 0.0006631
[Epoch 58; Iter   981/ 1097] train: loss: 0.0032050
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0144613
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0070502
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0005497
[Epoch 58] ogbg-molhiv: 0.781914 val loss: 0.200816
[Epoch 58] ogbg-molhiv: 0.725700 test loss: 0.323285
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002852
[Epoch 59; Iter    34/ 1097] train: loss: 0.0007698
[Epoch 59; Iter    64/ 1097] train: loss: 0.0069804
[Epoch 59; Iter    94/ 1097] train: loss: 0.0052840
[Epoch 59; Iter   124/ 1097] train: loss: 0.0136886
[Epoch 59; Iter   154/ 1097] train: loss: 0.0008545
[Epoch 59; Iter   184/ 1097] train: loss: 0.0020626
[Epoch 59; Iter   214/ 1097] train: loss: 0.0009997
[Epoch 59; Iter   244/ 1097] train: loss: 0.0005137
[Epoch 59; Iter   274/ 1097] train: loss: 0.0463825
[Epoch 59; Iter   304/ 1097] train: loss: 0.0007290
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000816
[Epoch 59; Iter   364/ 1097] train: loss: 0.0172231
[Epoch 59; Iter   394/ 1097] train: loss: 0.0016684
[Epoch 59; Iter   424/ 1097] train: loss: 0.0013531
[Epoch 59; Iter   454/ 1097] train: loss: 0.0006390
[Epoch 59; Iter   484/ 1097] train: loss: 0.0865986
[Epoch 59; Iter   514/ 1097] train: loss: 0.0000685
[Epoch 59; Iter   544/ 1097] train: loss: 0.0304154
[Epoch 59; Iter   574/ 1097] train: loss: 0.0036882
[Epoch 59; Iter   604/ 1097] train: loss: 0.0010076
[Epoch 59; Iter   634/ 1097] train: loss: 0.0007824
[Epoch 59; Iter   664/ 1097] train: loss: 0.0090088
[Epoch 59; Iter   694/ 1097] train: loss: 0.0007214
[Epoch 59; Iter   724/ 1097] train: loss: 0.0002990
[Epoch 59; Iter   754/ 1097] train: loss: 0.0015098
[Epoch 59; Iter   784/ 1097] train: loss: 0.0001554
[Epoch 59; Iter   814/ 1097] train: loss: 0.0120840
[Epoch 59; Iter   844/ 1097] train: loss: 0.0004355
[Epoch 59; Iter   874/ 1097] train: loss: 0.1020735
[Epoch 59; Iter   904/ 1097] train: loss: 0.0026460
[Epoch 59; Iter   934/ 1097] train: loss: 0.0002497
[Epoch 59; Iter   964/ 1097] train: loss: 0.0002883
[Epoch 59; Iter   994/ 1097] train: loss: 0.0006589
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0006500
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0002849
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0012732
[Epoch 59] ogbg-molhiv: 0.762762 val loss: 0.231561
[Epoch 59] ogbg-molhiv: 0.738674 test loss: 0.327167
[Epoch 60; Iter    17/ 1097] train: loss: 0.0049811
[Epoch 60; Iter    47/ 1097] train: loss: 0.0101925
[Epoch 60; Iter    77/ 1097] train: loss: 0.0022385
[Epoch 60; Iter   107/ 1097] train: loss: 0.0066180
[Epoch 60; Iter   137/ 1097] train: loss: 0.0028321
[Epoch 60; Iter   167/ 1097] train: loss: 0.0001838
[Epoch 60; Iter   197/ 1097] train: loss: 0.0029171
[Epoch 60; Iter   227/ 1097] train: loss: 0.0002783
[Epoch 60; Iter   257/ 1097] train: loss: 0.0035022
[Epoch 60; Iter   287/ 1097] train: loss: 0.0010152
[Epoch 60; Iter   317/ 1097] train: loss: 0.0000099
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001466
[Epoch 60; Iter   377/ 1097] train: loss: 0.0010792
[Epoch 60; Iter   407/ 1097] train: loss: 0.0000787
[Epoch 60; Iter   437/ 1097] train: loss: 0.0013225
[Epoch 60; Iter   467/ 1097] train: loss: 0.0002682
[Epoch 60; Iter   497/ 1097] train: loss: 0.0016330
[Epoch 60; Iter   527/ 1097] train: loss: 0.0003150
[Epoch 60; Iter   557/ 1097] train: loss: 0.0008366
[Epoch 60; Iter   587/ 1097] train: loss: 0.0010445
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001159
[Epoch 60; Iter   647/ 1097] train: loss: 0.0014808
[Epoch 60; Iter   677/ 1097] train: loss: 0.0046279
[Epoch 60; Iter   707/ 1097] train: loss: 0.0002376
[Epoch 60; Iter   737/ 1097] train: loss: 0.0032311
[Epoch 60; Iter   767/ 1097] train: loss: 0.0856156
[Epoch 60; Iter   797/ 1097] train: loss: 0.0011027
[Epoch 60; Iter   827/ 1097] train: loss: 0.0408284
[Epoch 60; Iter   857/ 1097] train: loss: 0.0096179
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001947
[Epoch 60; Iter   917/ 1097] train: loss: 0.0002336
[Epoch 60; Iter   947/ 1097] train: loss: 0.0061834
[Epoch 60; Iter   977/ 1097] train: loss: 0.0024552
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0006467
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0002713
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0028829
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000665
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0001486
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0054883
[Epoch 56] ogbg-molhiv: 0.787322 val loss: 0.261190
[Epoch 56] ogbg-molhiv: 0.800794 test loss: 0.267329
[Epoch 57; Iter     8/ 1097] train: loss: 0.0004099
[Epoch 57; Iter    38/ 1097] train: loss: 0.0030300
[Epoch 57; Iter    68/ 1097] train: loss: 0.0020611
[Epoch 57; Iter    98/ 1097] train: loss: 0.0035147
[Epoch 57; Iter   128/ 1097] train: loss: 0.0020486
[Epoch 57; Iter   158/ 1097] train: loss: 0.0021573
[Epoch 57; Iter   188/ 1097] train: loss: 0.0010385
[Epoch 57; Iter   218/ 1097] train: loss: 0.0003785
[Epoch 57; Iter   248/ 1097] train: loss: 0.0001605
[Epoch 57; Iter   278/ 1097] train: loss: 0.0002781
[Epoch 57; Iter   308/ 1097] train: loss: 0.0012792
[Epoch 57; Iter   338/ 1097] train: loss: 0.0002838
[Epoch 57; Iter   368/ 1097] train: loss: 0.0008186
[Epoch 57; Iter   398/ 1097] train: loss: 0.0006224
[Epoch 57; Iter   428/ 1097] train: loss: 0.0009278
[Epoch 57; Iter   458/ 1097] train: loss: 0.0009734
[Epoch 57; Iter   488/ 1097] train: loss: 0.0004664
[Epoch 57; Iter   518/ 1097] train: loss: 0.0006242
[Epoch 57; Iter   548/ 1097] train: loss: 0.0008472
[Epoch 57; Iter   578/ 1097] train: loss: 0.0000289
[Epoch 57; Iter   608/ 1097] train: loss: 0.0000670
[Epoch 57; Iter   638/ 1097] train: loss: 0.0001290
[Epoch 57; Iter   668/ 1097] train: loss: 0.0048001
[Epoch 57; Iter   698/ 1097] train: loss: 0.0000885
[Epoch 57; Iter   728/ 1097] train: loss: 0.0002503
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007490
[Epoch 57; Iter   788/ 1097] train: loss: 0.0020057
[Epoch 57; Iter   818/ 1097] train: loss: 0.0002134
[Epoch 57; Iter   848/ 1097] train: loss: 0.0006156
[Epoch 57; Iter   878/ 1097] train: loss: 0.0012258
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005312
[Epoch 57; Iter   938/ 1097] train: loss: 0.0002542
[Epoch 57; Iter   968/ 1097] train: loss: 0.0004164
[Epoch 57; Iter   998/ 1097] train: loss: 0.0000286
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0084886
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0036877
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0031817
[Epoch 57] ogbg-molhiv: 0.766455 val loss: 0.271971
[Epoch 57] ogbg-molhiv: 0.800832 test loss: 0.263575
[Epoch 58; Iter    21/ 1097] train: loss: 0.0003887
[Epoch 58; Iter    51/ 1097] train: loss: 0.0069902
[Epoch 58; Iter    81/ 1097] train: loss: 0.0033071
[Epoch 58; Iter   111/ 1097] train: loss: 0.0017098
[Epoch 58; Iter   141/ 1097] train: loss: 0.0000949
[Epoch 58; Iter   171/ 1097] train: loss: 0.0003526
[Epoch 58; Iter   201/ 1097] train: loss: 0.0242150
[Epoch 58; Iter   231/ 1097] train: loss: 0.0002453
[Epoch 58; Iter   261/ 1097] train: loss: 0.0002405
[Epoch 58; Iter   291/ 1097] train: loss: 0.0005486
[Epoch 58; Iter   321/ 1097] train: loss: 0.0006464
[Epoch 58; Iter   351/ 1097] train: loss: 0.0006081
[Epoch 58; Iter   381/ 1097] train: loss: 0.0000912
[Epoch 58; Iter   411/ 1097] train: loss: 0.0117999
[Epoch 58; Iter   441/ 1097] train: loss: 0.0009449
[Epoch 58; Iter   471/ 1097] train: loss: 0.0019296
[Epoch 58; Iter   501/ 1097] train: loss: 0.0449860
[Epoch 58; Iter   531/ 1097] train: loss: 0.1650235
[Epoch 58; Iter   561/ 1097] train: loss: 0.0002027
[Epoch 58; Iter   591/ 1097] train: loss: 0.0027484
[Epoch 58; Iter   621/ 1097] train: loss: 0.0023334
[Epoch 58; Iter   651/ 1097] train: loss: 0.0000657
[Epoch 58; Iter   681/ 1097] train: loss: 0.0391931
[Epoch 58; Iter   711/ 1097] train: loss: 0.0001276
[Epoch 58; Iter   741/ 1097] train: loss: 0.0436130
[Epoch 58; Iter   771/ 1097] train: loss: 0.0021517
[Epoch 58; Iter   801/ 1097] train: loss: 0.0008695
[Epoch 58; Iter   831/ 1097] train: loss: 0.0004051
[Epoch 58; Iter   861/ 1097] train: loss: 0.0000420
[Epoch 58; Iter   891/ 1097] train: loss: 0.0010115
[Epoch 58; Iter   921/ 1097] train: loss: 0.0011884
[Epoch 58; Iter   951/ 1097] train: loss: 0.0000987
[Epoch 58; Iter   981/ 1097] train: loss: 0.0074623
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0000133
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0015965
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0001091
[Epoch 58] ogbg-molhiv: 0.801789 val loss: 0.249850
[Epoch 58] ogbg-molhiv: 0.797511 test loss: 0.273411
[Epoch 59; Iter     4/ 1097] train: loss: 0.0039365
[Epoch 59; Iter    34/ 1097] train: loss: 0.0005931
[Epoch 59; Iter    64/ 1097] train: loss: 0.0000333
[Epoch 59; Iter    94/ 1097] train: loss: 0.0001159
[Epoch 59; Iter   124/ 1097] train: loss: 0.0000632
[Epoch 59; Iter   154/ 1097] train: loss: 0.0007138
[Epoch 59; Iter   184/ 1097] train: loss: 0.0006492
[Epoch 59; Iter   214/ 1097] train: loss: 0.0000519
[Epoch 59; Iter   244/ 1097] train: loss: 0.0002716
[Epoch 59; Iter   274/ 1097] train: loss: 0.0001869
[Epoch 59; Iter   304/ 1097] train: loss: 0.0005381
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000988
[Epoch 59; Iter   364/ 1097] train: loss: 0.0048005
[Epoch 59; Iter   394/ 1097] train: loss: 0.0011935
[Epoch 59; Iter   424/ 1097] train: loss: 0.0002110
[Epoch 59; Iter   454/ 1097] train: loss: 0.0002100
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007677
[Epoch 59; Iter   514/ 1097] train: loss: 0.0000472
[Epoch 59; Iter   544/ 1097] train: loss: 0.0009448
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000983
[Epoch 59; Iter   604/ 1097] train: loss: 0.0008062
[Epoch 59; Iter   634/ 1097] train: loss: 0.0004685
[Epoch 59; Iter   664/ 1097] train: loss: 0.0029042
[Epoch 59; Iter   694/ 1097] train: loss: 0.0005020
[Epoch 59; Iter   724/ 1097] train: loss: 0.0011145
[Epoch 59; Iter   754/ 1097] train: loss: 0.0006569
[Epoch 59; Iter   784/ 1097] train: loss: 0.0005904
[Epoch 59; Iter   814/ 1097] train: loss: 0.0012554
[Epoch 59; Iter   844/ 1097] train: loss: 0.0000551
[Epoch 59; Iter   874/ 1097] train: loss: 0.0010422
[Epoch 59; Iter   904/ 1097] train: loss: 0.0002551
[Epoch 59; Iter   934/ 1097] train: loss: 0.0000740
[Epoch 59; Iter   964/ 1097] train: loss: 0.0126702
[Epoch 59; Iter   994/ 1097] train: loss: 0.0004147
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0035366
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0001053
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0007032
[Epoch 59] ogbg-molhiv: 0.762802 val loss: 0.243741
[Epoch 59] ogbg-molhiv: 0.785411 test loss: 0.288287
[Epoch 60; Iter    17/ 1097] train: loss: 0.0279160
[Epoch 60; Iter    47/ 1097] train: loss: 0.0061336
[Epoch 60; Iter    77/ 1097] train: loss: 0.0002383
[Epoch 60; Iter   107/ 1097] train: loss: 0.0118119
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000786
[Epoch 60; Iter   167/ 1097] train: loss: 0.0015495
[Epoch 60; Iter   197/ 1097] train: loss: 0.0002547
[Epoch 60; Iter   227/ 1097] train: loss: 0.0011275
[Epoch 60; Iter   257/ 1097] train: loss: 0.0013842
[Epoch 60; Iter   287/ 1097] train: loss: 0.0007145
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003631
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001528
[Epoch 60; Iter   377/ 1097] train: loss: 0.0027537
[Epoch 60; Iter   407/ 1097] train: loss: 0.0002835
[Epoch 60; Iter   437/ 1097] train: loss: 0.0015826
[Epoch 60; Iter   467/ 1097] train: loss: 0.0001101
[Epoch 60; Iter   497/ 1097] train: loss: 0.0001791
[Epoch 60; Iter   527/ 1097] train: loss: 0.0005307
[Epoch 60; Iter   557/ 1097] train: loss: 0.0002990
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001747
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001481
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000052
[Epoch 60; Iter   677/ 1097] train: loss: 0.0000533
[Epoch 60; Iter   707/ 1097] train: loss: 0.0001442
[Epoch 60; Iter   737/ 1097] train: loss: 0.0037172
[Epoch 60; Iter   767/ 1097] train: loss: 0.0019126
[Epoch 60; Iter   797/ 1097] train: loss: 0.0094614
[Epoch 60; Iter   827/ 1097] train: loss: 0.0000370
[Epoch 60; Iter   857/ 1097] train: loss: 0.0002265
[Epoch 60; Iter   887/ 1097] train: loss: 0.0012124
[Epoch 60; Iter   917/ 1097] train: loss: 0.0191042
[Epoch 60; Iter   947/ 1097] train: loss: 0.0037075
[Epoch 60; Iter   977/ 1097] train: loss: 0.0000987
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0002019
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0004378
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0007021
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0014139
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0000207
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0016160
[Epoch 56] ogbg-molhiv: 0.683002 val loss: 8.331708
[Epoch 56] ogbg-molhiv: 0.552848 test loss: 10.479410
[Epoch 57; Iter     8/ 1097] train: loss: 0.0007215
[Epoch 57; Iter    38/ 1097] train: loss: 0.0003586
[Epoch 57; Iter    68/ 1097] train: loss: 0.0000575
[Epoch 57; Iter    98/ 1097] train: loss: 0.0014171
[Epoch 57; Iter   128/ 1097] train: loss: 0.0000640
[Epoch 57; Iter   158/ 1097] train: loss: 0.0001113
[Epoch 57; Iter   188/ 1097] train: loss: 0.0001659
[Epoch 57; Iter   218/ 1097] train: loss: 0.0002039
[Epoch 57; Iter   248/ 1097] train: loss: 0.0001895
[Epoch 57; Iter   278/ 1097] train: loss: 0.0000731
[Epoch 57; Iter   308/ 1097] train: loss: 0.0009052
[Epoch 57; Iter   338/ 1097] train: loss: 0.0054883
[Epoch 57; Iter   368/ 1097] train: loss: 0.0000960
[Epoch 57; Iter   398/ 1097] train: loss: 0.0000730
[Epoch 57; Iter   428/ 1097] train: loss: 0.0003831
[Epoch 57; Iter   458/ 1097] train: loss: 0.0000570
[Epoch 57; Iter   488/ 1097] train: loss: 0.0000078
[Epoch 57; Iter   518/ 1097] train: loss: 0.0000396
[Epoch 57; Iter   548/ 1097] train: loss: 0.0009981
[Epoch 57; Iter   578/ 1097] train: loss: 0.0000349
[Epoch 57; Iter   608/ 1097] train: loss: 0.0032398
[Epoch 57; Iter   638/ 1097] train: loss: 0.0018054
[Epoch 57; Iter   668/ 1097] train: loss: 0.0000310
[Epoch 57; Iter   698/ 1097] train: loss: 0.0050346
[Epoch 57; Iter   728/ 1097] train: loss: 0.0000667
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007655
[Epoch 57; Iter   788/ 1097] train: loss: 0.0007863
[Epoch 57; Iter   818/ 1097] train: loss: 0.0044067
[Epoch 57; Iter   848/ 1097] train: loss: 0.0000345
[Epoch 57; Iter   878/ 1097] train: loss: 0.0281502
[Epoch 57; Iter   908/ 1097] train: loss: 0.0000757
[Epoch 57; Iter   938/ 1097] train: loss: 0.0000234
[Epoch 57; Iter   968/ 1097] train: loss: 0.0000181
[Epoch 57; Iter   998/ 1097] train: loss: 0.0003510
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0002044
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003756
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0000076
[Epoch 57] ogbg-molhiv: 0.712044 val loss: 1.686141
[Epoch 57] ogbg-molhiv: 0.619201 test loss: 2.510876
[Epoch 58; Iter    21/ 1097] train: loss: 0.0000577
[Epoch 58; Iter    51/ 1097] train: loss: 0.0017819
[Epoch 58; Iter    81/ 1097] train: loss: 0.0001862
[Epoch 58; Iter   111/ 1097] train: loss: 0.0006170
[Epoch 58; Iter   141/ 1097] train: loss: 0.0000980
[Epoch 58; Iter   171/ 1097] train: loss: 0.0001688
[Epoch 58; Iter   201/ 1097] train: loss: 0.0001631
[Epoch 58; Iter   231/ 1097] train: loss: 0.0000321
[Epoch 58; Iter   261/ 1097] train: loss: 0.0187724
[Epoch 58; Iter   291/ 1097] train: loss: 0.0007863
[Epoch 58; Iter   321/ 1097] train: loss: 0.0000241
[Epoch 58; Iter   351/ 1097] train: loss: 0.0115519
[Epoch 58; Iter   381/ 1097] train: loss: 0.0000231
[Epoch 58; Iter   411/ 1097] train: loss: 0.0009768
[Epoch 58; Iter   441/ 1097] train: loss: 0.0006132
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001248
[Epoch 58; Iter   501/ 1097] train: loss: 0.0001993
[Epoch 58; Iter   531/ 1097] train: loss: 0.0003279
[Epoch 58; Iter   561/ 1097] train: loss: 0.0000681
[Epoch 58; Iter   591/ 1097] train: loss: 0.0000415
[Epoch 58; Iter   621/ 1097] train: loss: 0.0000366
[Epoch 58; Iter   651/ 1097] train: loss: 0.0012000
[Epoch 58; Iter   681/ 1097] train: loss: 0.0002637
[Epoch 58; Iter   711/ 1097] train: loss: 0.0031381
[Epoch 58; Iter   741/ 1097] train: loss: 0.0034686
[Epoch 58; Iter   771/ 1097] train: loss: 0.0008493
[Epoch 58; Iter   801/ 1097] train: loss: 0.0001442
[Epoch 58; Iter   831/ 1097] train: loss: 0.0001265
[Epoch 58; Iter   861/ 1097] train: loss: 0.0001591
[Epoch 58; Iter   891/ 1097] train: loss: 0.0002075
[Epoch 58; Iter   921/ 1097] train: loss: 0.0009216
[Epoch 58; Iter   951/ 1097] train: loss: 0.0005285
[Epoch 58; Iter   981/ 1097] train: loss: 0.0001294
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0065492
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0001398
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0000194
[Epoch 58] ogbg-molhiv: 0.668816 val loss: 3.217429
[Epoch 58] ogbg-molhiv: 0.598521 test loss: 4.079403
[Epoch 59; Iter     4/ 1097] train: loss: 0.0006376
[Epoch 59; Iter    34/ 1097] train: loss: 0.0007879
[Epoch 59; Iter    64/ 1097] train: loss: 0.0001323
[Epoch 59; Iter    94/ 1097] train: loss: 0.0038820
[Epoch 59; Iter   124/ 1097] train: loss: 0.0014722
[Epoch 59; Iter   154/ 1097] train: loss: 0.0006885
[Epoch 59; Iter   184/ 1097] train: loss: 0.0105550
[Epoch 59; Iter   214/ 1097] train: loss: 0.0002417
[Epoch 59; Iter   244/ 1097] train: loss: 0.0000747
[Epoch 59; Iter   274/ 1097] train: loss: 0.0000741
[Epoch 59; Iter   304/ 1097] train: loss: 0.0002478
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000112
[Epoch 59; Iter   364/ 1097] train: loss: 0.0059059
[Epoch 59; Iter   394/ 1097] train: loss: 0.0034776
[Epoch 59; Iter   424/ 1097] train: loss: 0.0026226
[Epoch 59; Iter   454/ 1097] train: loss: 0.0069848
[Epoch 59; Iter   484/ 1097] train: loss: 0.0000249
[Epoch 59; Iter   514/ 1097] train: loss: 0.0002875
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004114
[Epoch 59; Iter   574/ 1097] train: loss: 0.0001730
[Epoch 59; Iter   604/ 1097] train: loss: 0.0006421
[Epoch 59; Iter   634/ 1097] train: loss: 0.0086397
[Epoch 59; Iter   664/ 1097] train: loss: 0.0000164
[Epoch 59; Iter   694/ 1097] train: loss: 0.0000511
[Epoch 59; Iter   724/ 1097] train: loss: 0.0008791
[Epoch 59; Iter   754/ 1097] train: loss: 0.0001143
[Epoch 59; Iter   784/ 1097] train: loss: 0.0000157
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000287
[Epoch 59; Iter   844/ 1097] train: loss: 0.0064313
[Epoch 59; Iter   874/ 1097] train: loss: 0.0002454
[Epoch 59; Iter   904/ 1097] train: loss: 0.0015884
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001621
[Epoch 59; Iter   964/ 1097] train: loss: 0.0000679
[Epoch 59; Iter   994/ 1097] train: loss: 0.0001298
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0000245
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0000296
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000814
[Epoch 59] ogbg-molhiv: 0.702234 val loss: 4.421663
[Epoch 59] ogbg-molhiv: 0.591894 test loss: 5.976201
[Epoch 60; Iter    17/ 1097] train: loss: 0.0004859
[Epoch 60; Iter    47/ 1097] train: loss: 0.0010650
[Epoch 60; Iter    77/ 1097] train: loss: 0.0008098
[Epoch 60; Iter   107/ 1097] train: loss: 0.0068155
[Epoch 60; Iter   137/ 1097] train: loss: 0.0001469
[Epoch 60; Iter   167/ 1097] train: loss: 0.0000937
[Epoch 60; Iter   197/ 1097] train: loss: 0.0113412
[Epoch 60; Iter   227/ 1097] train: loss: 0.0000358
[Epoch 60; Iter   257/ 1097] train: loss: 0.0000765
[Epoch 60; Iter   287/ 1097] train: loss: 0.0002654
[Epoch 60; Iter   317/ 1097] train: loss: 0.0004287
[Epoch 60; Iter   347/ 1097] train: loss: 0.0000879
[Epoch 60; Iter   377/ 1097] train: loss: 0.0004859
[Epoch 60; Iter   407/ 1097] train: loss: 0.0007262
[Epoch 60; Iter   437/ 1097] train: loss: 0.0003232
[Epoch 60; Iter   467/ 1097] train: loss: 0.0000204
[Epoch 60; Iter   497/ 1097] train: loss: 0.0001259
[Epoch 60; Iter   527/ 1097] train: loss: 0.0001697
[Epoch 60; Iter   557/ 1097] train: loss: 0.0052118
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001134
[Epoch 60; Iter   617/ 1097] train: loss: 0.0000379
[Epoch 60; Iter   647/ 1097] train: loss: 0.0002268
[Epoch 60; Iter   677/ 1097] train: loss: 0.0000184
[Epoch 60; Iter   707/ 1097] train: loss: 0.0014978
[Epoch 60; Iter   737/ 1097] train: loss: 0.0003413
[Epoch 60; Iter   767/ 1097] train: loss: 0.0002763
[Epoch 60; Iter   797/ 1097] train: loss: 0.0001637
[Epoch 60; Iter   827/ 1097] train: loss: 0.0016104
[Epoch 60; Iter   857/ 1097] train: loss: 0.0000222
[Epoch 60; Iter   887/ 1097] train: loss: 0.0044546
[Epoch 60; Iter   917/ 1097] train: loss: 0.0001495
[Epoch 60; Iter   947/ 1097] train: loss: 0.0002760
[Epoch 60; Iter   977/ 1097] train: loss: 0.0005549
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0000098
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0000255
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0000411
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000542
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0002693
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0003548
[Epoch 56] ogbg-molhiv: 0.786728 val loss: 20.724912
[Epoch 56] ogbg-molhiv: 0.711207 test loss: 15.966664
[Epoch 57; Iter     8/ 1097] train: loss: 0.0020186
[Epoch 57; Iter    38/ 1097] train: loss: 0.0067935
[Epoch 57; Iter    68/ 1097] train: loss: 0.0020931
[Epoch 57; Iter    98/ 1097] train: loss: 0.0005728
[Epoch 57; Iter   128/ 1097] train: loss: 0.0052075
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000688
[Epoch 57; Iter   188/ 1097] train: loss: 0.0067893
[Epoch 57; Iter   218/ 1097] train: loss: 0.0021895
[Epoch 57; Iter   248/ 1097] train: loss: 0.0002049
[Epoch 57; Iter   278/ 1097] train: loss: 0.0028128
[Epoch 57; Iter   308/ 1097] train: loss: 0.0068438
[Epoch 57; Iter   338/ 1097] train: loss: 0.0004563
[Epoch 57; Iter   368/ 1097] train: loss: 0.0015499
[Epoch 57; Iter   398/ 1097] train: loss: 0.0011066
[Epoch 57; Iter   428/ 1097] train: loss: 0.0002921
[Epoch 57; Iter   458/ 1097] train: loss: 0.0051409
[Epoch 57; Iter   488/ 1097] train: loss: 0.0202259
[Epoch 57; Iter   518/ 1097] train: loss: 0.0032412
[Epoch 57; Iter   548/ 1097] train: loss: 0.0026742
[Epoch 57; Iter   578/ 1097] train: loss: 0.0019474
[Epoch 57; Iter   608/ 1097] train: loss: 0.0010945
[Epoch 57; Iter   638/ 1097] train: loss: 0.0087602
[Epoch 57; Iter   668/ 1097] train: loss: 0.0044254
[Epoch 57; Iter   698/ 1097] train: loss: 0.0005872
[Epoch 57; Iter   728/ 1097] train: loss: 0.0050548
[Epoch 57; Iter   758/ 1097] train: loss: 0.0458506
[Epoch 57; Iter   788/ 1097] train: loss: 0.0086120
[Epoch 57; Iter   818/ 1097] train: loss: 0.0002471
[Epoch 57; Iter   848/ 1097] train: loss: 0.0012120
[Epoch 57; Iter   878/ 1097] train: loss: 0.0003404
[Epoch 57; Iter   908/ 1097] train: loss: 0.0234615
[Epoch 57; Iter   938/ 1097] train: loss: 0.0011349
[Epoch 57; Iter   968/ 1097] train: loss: 0.0002468
[Epoch 57; Iter   998/ 1097] train: loss: 0.0035655
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0225277
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0051217
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0081271
[Epoch 57] ogbg-molhiv: 0.771063 val loss: 9.929186
[Epoch 57] ogbg-molhiv: 0.694546 test loss: 9.618674
[Epoch 58; Iter    21/ 1097] train: loss: 0.0005104
[Epoch 58; Iter    51/ 1097] train: loss: 0.0016361
[Epoch 58; Iter    81/ 1097] train: loss: 0.0005098
[Epoch 58; Iter   111/ 1097] train: loss: 0.0061830
[Epoch 58; Iter   141/ 1097] train: loss: 0.0015973
[Epoch 58; Iter   171/ 1097] train: loss: 0.0004034
[Epoch 58; Iter   201/ 1097] train: loss: 0.0002150
[Epoch 58; Iter   231/ 1097] train: loss: 0.0005550
[Epoch 58; Iter   261/ 1097] train: loss: 0.0136433
[Epoch 58; Iter   291/ 1097] train: loss: 0.0004434
[Epoch 58; Iter   321/ 1097] train: loss: 0.0010227
[Epoch 58; Iter   351/ 1097] train: loss: 0.0002034
[Epoch 58; Iter   381/ 1097] train: loss: 0.0001593
[Epoch 58; Iter   411/ 1097] train: loss: 0.0040763
[Epoch 58; Iter   441/ 1097] train: loss: 0.0008170
[Epoch 58; Iter   471/ 1097] train: loss: 0.0033118
[Epoch 58; Iter   501/ 1097] train: loss: 0.0577298
[Epoch 58; Iter   531/ 1097] train: loss: 0.0393394
[Epoch 58; Iter   561/ 1097] train: loss: 0.0047600
[Epoch 58; Iter   591/ 1097] train: loss: 0.0005956
[Epoch 58; Iter   621/ 1097] train: loss: 0.0021966
[Epoch 58; Iter   651/ 1097] train: loss: 0.0522519
[Epoch 58; Iter   681/ 1097] train: loss: 0.0088557
[Epoch 58; Iter   711/ 1097] train: loss: 0.0005392
[Epoch 58; Iter   741/ 1097] train: loss: 0.0023950
[Epoch 58; Iter   771/ 1097] train: loss: 0.0001389
[Epoch 58; Iter   801/ 1097] train: loss: 0.0146188
[Epoch 58; Iter   831/ 1097] train: loss: 0.0003147
[Epoch 58; Iter   861/ 1097] train: loss: 0.0016843
[Epoch 58; Iter   891/ 1097] train: loss: 0.0006448
[Epoch 58; Iter   921/ 1097] train: loss: 0.0002142
[Epoch 58; Iter   951/ 1097] train: loss: 0.0029123
[Epoch 58; Iter   981/ 1097] train: loss: 0.0022136
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0005550
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0004992
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0081532
[Epoch 58] ogbg-molhiv: 0.735658 val loss: 9.878995
[Epoch 58] ogbg-molhiv: 0.692858 test loss: 12.233140
[Epoch 59; Iter     4/ 1097] train: loss: 0.0014489
[Epoch 59; Iter    34/ 1097] train: loss: 0.0014666
[Epoch 59; Iter    64/ 1097] train: loss: 0.0009093
[Epoch 59; Iter    94/ 1097] train: loss: 0.0011589
[Epoch 59; Iter   124/ 1097] train: loss: 0.0004185
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000942
[Epoch 59; Iter   184/ 1097] train: loss: 0.0051372
[Epoch 59; Iter   214/ 1097] train: loss: 0.0002247
[Epoch 59; Iter   244/ 1097] train: loss: 0.0012221
[Epoch 59; Iter   274/ 1097] train: loss: 0.0001176
[Epoch 59; Iter   304/ 1097] train: loss: 0.0034417
[Epoch 59; Iter   334/ 1097] train: loss: 0.0018823
[Epoch 59; Iter   364/ 1097] train: loss: 0.0015920
[Epoch 59; Iter   394/ 1097] train: loss: 0.0006458
[Epoch 59; Iter   424/ 1097] train: loss: 0.0025336
[Epoch 59; Iter   454/ 1097] train: loss: 0.0012862
[Epoch 59; Iter   484/ 1097] train: loss: 0.0068192
[Epoch 59; Iter   514/ 1097] train: loss: 0.0019693
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004480
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000445
[Epoch 59; Iter   604/ 1097] train: loss: 0.0002380
[Epoch 59; Iter   634/ 1097] train: loss: 0.0005080
[Epoch 59; Iter   664/ 1097] train: loss: 0.0048538
[Epoch 59; Iter   694/ 1097] train: loss: 0.0000532
[Epoch 59; Iter   724/ 1097] train: loss: 0.0245409
[Epoch 59; Iter   754/ 1097] train: loss: 0.0003662
[Epoch 59; Iter   784/ 1097] train: loss: 0.0000357
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000523
[Epoch 59; Iter   844/ 1097] train: loss: 0.0000360
[Epoch 59; Iter   874/ 1097] train: loss: 0.0006410
[Epoch 59; Iter   904/ 1097] train: loss: 0.0012759
[Epoch 59; Iter   934/ 1097] train: loss: 0.0125703
[Epoch 59; Iter   964/ 1097] train: loss: 0.0326750
[Epoch 59; Iter   994/ 1097] train: loss: 0.0001007
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0605469
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0006397
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000127
[Epoch 59] ogbg-molhiv: 0.786734 val loss: 7.686280
[Epoch 59] ogbg-molhiv: 0.724145 test loss: 6.924354
[Epoch 60; Iter    17/ 1097] train: loss: 0.0024132
[Epoch 60; Iter    47/ 1097] train: loss: 0.0133835
[Epoch 60; Iter    77/ 1097] train: loss: 0.0036176
[Epoch 60; Iter   107/ 1097] train: loss: 0.0050014
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000512
[Epoch 60; Iter   167/ 1097] train: loss: 0.0007421
[Epoch 60; Iter   197/ 1097] train: loss: 0.0199642
[Epoch 60; Iter   227/ 1097] train: loss: 0.0013328
[Epoch 60; Iter   257/ 1097] train: loss: 0.0004761
[Epoch 60; Iter   287/ 1097] train: loss: 0.0081408
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003015
[Epoch 60; Iter   347/ 1097] train: loss: 0.0068296
[Epoch 60; Iter   377/ 1097] train: loss: 0.0000127
[Epoch 60; Iter   407/ 1097] train: loss: 0.0002466
[Epoch 60; Iter   437/ 1097] train: loss: 0.0001973
[Epoch 60; Iter   467/ 1097] train: loss: 0.0005135
[Epoch 60; Iter   497/ 1097] train: loss: 0.0010129
[Epoch 60; Iter   527/ 1097] train: loss: 0.0002021
[Epoch 60; Iter   557/ 1097] train: loss: 0.0035389
[Epoch 60; Iter   587/ 1097] train: loss: 0.0000230
[Epoch 60; Iter   617/ 1097] train: loss: 0.0003846
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000565
[Epoch 60; Iter   677/ 1097] train: loss: 0.0004857
[Epoch 60; Iter   707/ 1097] train: loss: 0.0038905
[Epoch 60; Iter   737/ 1097] train: loss: 0.0022826
[Epoch 60; Iter   767/ 1097] train: loss: 0.0009051
[Epoch 60; Iter   797/ 1097] train: loss: 0.0000830
[Epoch 60; Iter   827/ 1097] train: loss: 0.0003203
[Epoch 60; Iter   857/ 1097] train: loss: 0.0002317
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001718
[Epoch 60; Iter   917/ 1097] train: loss: 0.0040796
[Epoch 60; Iter   947/ 1097] train: loss: 0.0027748
[Epoch 60; Iter   977/ 1097] train: loss: 0.0020037
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0065171
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0013188
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0733223
[Epoch 56; Iter  1015/ 1097] train: loss: 0.1419935
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0019177
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0051758
[Epoch 56] ogbg-molhiv: 0.615560 val loss: 59.827676
[Epoch 56] ogbg-molhiv: 0.569422 test loss: 56.540242
[Epoch 57; Iter     8/ 1097] train: loss: 0.0287202
[Epoch 57; Iter    38/ 1097] train: loss: 0.0002936
[Epoch 57; Iter    68/ 1097] train: loss: 0.0004095
[Epoch 57; Iter    98/ 1097] train: loss: 0.0011821
[Epoch 57; Iter   128/ 1097] train: loss: 0.0191494
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000982
[Epoch 57; Iter   188/ 1097] train: loss: 0.0011820
[Epoch 57; Iter   218/ 1097] train: loss: 0.0153755
[Epoch 57; Iter   248/ 1097] train: loss: 0.0025998
[Epoch 57; Iter   278/ 1097] train: loss: 0.0011838
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005500
[Epoch 57; Iter   338/ 1097] train: loss: 0.0011825
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001301
[Epoch 57; Iter   398/ 1097] train: loss: 0.0004334
[Epoch 57; Iter   428/ 1097] train: loss: 0.0004118
[Epoch 57; Iter   458/ 1097] train: loss: 0.0001147
[Epoch 57; Iter   488/ 1097] train: loss: 0.0000564
[Epoch 57; Iter   518/ 1097] train: loss: 0.0003394
[Epoch 57; Iter   548/ 1097] train: loss: 0.0000873
[Epoch 57; Iter   578/ 1097] train: loss: 0.0279936
[Epoch 57; Iter   608/ 1097] train: loss: 0.0328166
[Epoch 57; Iter   638/ 1097] train: loss: 0.0017078
[Epoch 57; Iter   668/ 1097] train: loss: 0.0006071
[Epoch 57; Iter   698/ 1097] train: loss: 0.0021816
[Epoch 57; Iter   728/ 1097] train: loss: 0.0000620
[Epoch 57; Iter   758/ 1097] train: loss: 0.0296946
[Epoch 57; Iter   788/ 1097] train: loss: 0.0172294
[Epoch 57; Iter   818/ 1097] train: loss: 0.0243032
[Epoch 57; Iter   848/ 1097] train: loss: 0.0002564
[Epoch 57; Iter   878/ 1097] train: loss: 0.0000502
[Epoch 57; Iter   908/ 1097] train: loss: 0.0009772
[Epoch 57; Iter   938/ 1097] train: loss: 0.0015493
[Epoch 57; Iter   968/ 1097] train: loss: 0.0000640
[Epoch 57; Iter   998/ 1097] train: loss: 0.0304023
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0042933
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003713
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0004510
[Epoch 57] ogbg-molhiv: 0.703238 val loss: 5.447008
[Epoch 57] ogbg-molhiv: 0.640773 test loss: 3.921848
[Epoch 58; Iter    21/ 1097] train: loss: 0.0009560
[Epoch 58; Iter    51/ 1097] train: loss: 0.0001522
[Epoch 58; Iter    81/ 1097] train: loss: 0.0079300
[Epoch 58; Iter   111/ 1097] train: loss: 0.0059356
[Epoch 58; Iter   141/ 1097] train: loss: 0.0013961
[Epoch 58; Iter   171/ 1097] train: loss: 0.0001104
[Epoch 58; Iter   201/ 1097] train: loss: 0.0000642
[Epoch 58; Iter   231/ 1097] train: loss: 0.0004957
[Epoch 58; Iter   261/ 1097] train: loss: 0.0003967
[Epoch 58; Iter   291/ 1097] train: loss: 0.0174506
[Epoch 58; Iter   321/ 1097] train: loss: 0.0005043
[Epoch 58; Iter   351/ 1097] train: loss: 0.0096898
[Epoch 58; Iter   381/ 1097] train: loss: 0.0080392
[Epoch 58; Iter   411/ 1097] train: loss: 0.0028504
[Epoch 58; Iter   441/ 1097] train: loss: 0.0002734
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001274
[Epoch 58; Iter   501/ 1097] train: loss: 0.0018120
[Epoch 58; Iter   531/ 1097] train: loss: 0.0001440
[Epoch 58; Iter   561/ 1097] train: loss: 0.0052308
[Epoch 58; Iter   591/ 1097] train: loss: 0.0082570
[Epoch 58; Iter   621/ 1097] train: loss: 0.0011967
[Epoch 58; Iter   651/ 1097] train: loss: 0.0068539
[Epoch 58; Iter   681/ 1097] train: loss: 0.0765996
[Epoch 58; Iter   711/ 1097] train: loss: 0.0128383
[Epoch 58; Iter   741/ 1097] train: loss: 0.0009138
[Epoch 58; Iter   771/ 1097] train: loss: 0.0008207
[Epoch 58; Iter   801/ 1097] train: loss: 0.0060041
[Epoch 58; Iter   831/ 1097] train: loss: 0.1253991
[Epoch 58; Iter   861/ 1097] train: loss: 0.0007247
[Epoch 58; Iter   891/ 1097] train: loss: 0.0000460
[Epoch 58; Iter   921/ 1097] train: loss: 0.0017212
[Epoch 58; Iter   951/ 1097] train: loss: 0.0044354
[Epoch 58; Iter   981/ 1097] train: loss: 0.0080897
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0004067
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0000807
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0005755
[Epoch 58] ogbg-molhiv: 0.634743 val loss: 85.054147
[Epoch 58] ogbg-molhiv: 0.604367 test loss: 76.375956
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002237
[Epoch 59; Iter    34/ 1097] train: loss: 0.0025912
[Epoch 59; Iter    64/ 1097] train: loss: 0.1995348
[Epoch 59; Iter    94/ 1097] train: loss: 0.0012630
[Epoch 59; Iter   124/ 1097] train: loss: 0.0450101
[Epoch 59; Iter   154/ 1097] train: loss: 0.0103472
[Epoch 59; Iter   184/ 1097] train: loss: 0.0021840
[Epoch 59; Iter   214/ 1097] train: loss: 0.0003221
[Epoch 59; Iter   244/ 1097] train: loss: 0.0026906
[Epoch 59; Iter   274/ 1097] train: loss: 0.0014408
[Epoch 59; Iter   304/ 1097] train: loss: 0.0016184
[Epoch 59; Iter   334/ 1097] train: loss: 0.0004559
[Epoch 59; Iter   364/ 1097] train: loss: 0.0068383
[Epoch 59; Iter   394/ 1097] train: loss: 0.0001220
[Epoch 59; Iter   424/ 1097] train: loss: 0.0003931
[Epoch 59; Iter   454/ 1097] train: loss: 0.0021441
[Epoch 59; Iter   484/ 1097] train: loss: 0.0102916
[Epoch 59; Iter   514/ 1097] train: loss: 0.0010879
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004295
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000540
[Epoch 59; Iter   604/ 1097] train: loss: 0.0008098
[Epoch 59; Iter   634/ 1097] train: loss: 0.0007702
[Epoch 59; Iter   664/ 1097] train: loss: 0.0012508
[Epoch 59; Iter   694/ 1097] train: loss: 0.0252373
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001482
[Epoch 59; Iter   754/ 1097] train: loss: 0.0010473
[Epoch 59; Iter   784/ 1097] train: loss: 0.0001742
[Epoch 59; Iter   814/ 1097] train: loss: 0.0051857
[Epoch 59; Iter   844/ 1097] train: loss: 0.0012162
[Epoch 59; Iter   874/ 1097] train: loss: 0.0480589
[Epoch 59; Iter   904/ 1097] train: loss: 0.2270273
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001999
[Epoch 59; Iter   964/ 1097] train: loss: 0.0085250
[Epoch 59; Iter   994/ 1097] train: loss: 0.0008358
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0067512
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0000606
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000301
[Epoch 59] ogbg-molhiv: 0.657606 val loss: 63.296858
[Epoch 59] ogbg-molhiv: 0.611366 test loss: 56.676261
[Epoch 60; Iter    17/ 1097] train: loss: 0.0001905
[Epoch 60; Iter    47/ 1097] train: loss: 0.0002525
[Epoch 60; Iter    77/ 1097] train: loss: 0.0075256
[Epoch 60; Iter   107/ 1097] train: loss: 0.0025436
[Epoch 60; Iter   137/ 1097] train: loss: 0.0058335
[Epoch 60; Iter   167/ 1097] train: loss: 0.0002015
[Epoch 60; Iter   197/ 1097] train: loss: 0.0001577
[Epoch 60; Iter   227/ 1097] train: loss: 0.0351634
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001799
[Epoch 60; Iter   287/ 1097] train: loss: 0.0272332
[Epoch 60; Iter   317/ 1097] train: loss: 0.0001514
[Epoch 60; Iter   347/ 1097] train: loss: 0.0006073
[Epoch 60; Iter   377/ 1097] train: loss: 0.0003742
[Epoch 60; Iter   407/ 1097] train: loss: 0.0299396
[Epoch 60; Iter   437/ 1097] train: loss: 0.0000512
[Epoch 60; Iter   467/ 1097] train: loss: 0.0081972
[Epoch 60; Iter   497/ 1097] train: loss: 0.0011462
[Epoch 60; Iter   527/ 1097] train: loss: 0.0001336
[Epoch 60; Iter   557/ 1097] train: loss: 0.0004576
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001565
[Epoch 60; Iter   617/ 1097] train: loss: 0.0026325
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000361
[Epoch 60; Iter   677/ 1097] train: loss: 0.0016328
[Epoch 60; Iter   707/ 1097] train: loss: 0.0362563
[Epoch 60; Iter   737/ 1097] train: loss: 0.0003786
[Epoch 60; Iter   767/ 1097] train: loss: 0.0006933
[Epoch 60; Iter   797/ 1097] train: loss: 0.0034115
[Epoch 60; Iter   827/ 1097] train: loss: 0.0004598
[Epoch 60; Iter   857/ 1097] train: loss: 0.0009109
[Epoch 60; Iter   887/ 1097] train: loss: 0.0004827
[Epoch 60; Iter   917/ 1097] train: loss: 0.0014962
[Epoch 60; Iter   947/ 1097] train: loss: 0.0009962
[Epoch 60; Iter   977/ 1097] train: loss: 0.0014480
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0020633
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0000751
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0005201
[Epoch 48; Iter   851/ 1097] train: loss: 0.0047389
[Epoch 48; Iter   881/ 1097] train: loss: 0.1987624
[Epoch 48; Iter   911/ 1097] train: loss: 0.2530694
[Epoch 48; Iter   941/ 1097] train: loss: 0.0432729
[Epoch 48; Iter   971/ 1097] train: loss: 0.0321711
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0790867
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0840767
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0104406
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0299013
[Epoch 48] ogbg-molhiv: 0.833505 val loss: 0.082201
[Epoch 48] ogbg-molhiv: 0.722727 test loss: 0.155492
[Epoch 49; Iter    24/ 1097] train: loss: 0.0636845
[Epoch 49; Iter    54/ 1097] train: loss: 0.1339335
[Epoch 49; Iter    84/ 1097] train: loss: 0.0322023
[Epoch 49; Iter   114/ 1097] train: loss: 0.0329137
[Epoch 49; Iter   144/ 1097] train: loss: 0.0467436
[Epoch 49; Iter   174/ 1097] train: loss: 0.0888547
[Epoch 49; Iter   204/ 1097] train: loss: 0.0115461
[Epoch 49; Iter   234/ 1097] train: loss: 0.0179924
[Epoch 49; Iter   264/ 1097] train: loss: 0.0415421
[Epoch 49; Iter   294/ 1097] train: loss: 0.0679585
[Epoch 49; Iter   324/ 1097] train: loss: 0.0083943
[Epoch 49; Iter   354/ 1097] train: loss: 0.0132644
[Epoch 49; Iter   384/ 1097] train: loss: 0.1829354
[Epoch 49; Iter   414/ 1097] train: loss: 0.0170732
[Epoch 49; Iter   444/ 1097] train: loss: 0.0137785
[Epoch 49; Iter   474/ 1097] train: loss: 0.2832489
[Epoch 49; Iter   504/ 1097] train: loss: 0.0307126
[Epoch 49; Iter   534/ 1097] train: loss: 0.0279525
[Epoch 49; Iter   564/ 1097] train: loss: 0.0344822
[Epoch 49; Iter   594/ 1097] train: loss: 0.1079337
[Epoch 49; Iter   624/ 1097] train: loss: 0.0531520
[Epoch 49; Iter   654/ 1097] train: loss: 0.1206815
[Epoch 49; Iter   684/ 1097] train: loss: 0.0286447
[Epoch 49; Iter   714/ 1097] train: loss: 0.0183857
[Epoch 49; Iter   744/ 1097] train: loss: 0.0803529
[Epoch 49; Iter   774/ 1097] train: loss: 0.0793030
[Epoch 49; Iter   804/ 1097] train: loss: 0.1147343
[Epoch 49; Iter   834/ 1097] train: loss: 0.0206862
[Epoch 49; Iter   864/ 1097] train: loss: 0.0265022
[Epoch 49; Iter   894/ 1097] train: loss: 0.0167899
[Epoch 49; Iter   924/ 1097] train: loss: 0.1534593
[Epoch 49; Iter   954/ 1097] train: loss: 0.0359800
[Epoch 49; Iter   984/ 1097] train: loss: 0.0527522
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0106937
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0472277
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0406114
[Epoch 49] ogbg-molhiv: 0.831756 val loss: 0.081551
[Epoch 49] ogbg-molhiv: 0.754377 test loss: 0.148244
[Epoch 50; Iter     7/ 1097] train: loss: 0.0328040
[Epoch 50; Iter    37/ 1097] train: loss: 0.0748252
[Epoch 50; Iter    67/ 1097] train: loss: 0.0211368
[Epoch 50; Iter    97/ 1097] train: loss: 0.0090662
[Epoch 50; Iter   127/ 1097] train: loss: 0.0161905
[Epoch 50; Iter   157/ 1097] train: loss: 0.0546115
[Epoch 50; Iter   187/ 1097] train: loss: 0.1599066
[Epoch 50; Iter   217/ 1097] train: loss: 0.0344132
[Epoch 50; Iter   247/ 1097] train: loss: 0.0265399
[Epoch 50; Iter   277/ 1097] train: loss: 0.0165963
[Epoch 50; Iter   307/ 1097] train: loss: 0.0960500
[Epoch 50; Iter   337/ 1097] train: loss: 0.0723720
[Epoch 50; Iter   367/ 1097] train: loss: 0.2197659
[Epoch 50; Iter   397/ 1097] train: loss: 0.0130971
[Epoch 50; Iter   427/ 1097] train: loss: 0.1430018
[Epoch 50; Iter   457/ 1097] train: loss: 0.1235707
[Epoch 50; Iter   487/ 1097] train: loss: 0.0550500
[Epoch 50; Iter   517/ 1097] train: loss: 0.0481967
[Epoch 50; Iter   547/ 1097] train: loss: 0.0190850
[Epoch 50; Iter   577/ 1097] train: loss: 0.0094848
[Epoch 50; Iter   607/ 1097] train: loss: 0.0107938
[Epoch 50; Iter   637/ 1097] train: loss: 0.0645011
[Epoch 50; Iter   667/ 1097] train: loss: 0.0775709
[Epoch 50; Iter   697/ 1097] train: loss: 0.0275694
[Epoch 50; Iter   727/ 1097] train: loss: 0.0646060
[Epoch 50; Iter   757/ 1097] train: loss: 0.0083658
[Epoch 50; Iter   787/ 1097] train: loss: 0.1287740
[Epoch 50; Iter   817/ 1097] train: loss: 0.0809360
[Epoch 50; Iter   847/ 1097] train: loss: 0.0212179
[Epoch 50; Iter   877/ 1097] train: loss: 0.0477371
[Epoch 50; Iter   907/ 1097] train: loss: 0.0310242
[Epoch 50; Iter   937/ 1097] train: loss: 0.0127320
[Epoch 50; Iter   967/ 1097] train: loss: 0.0790512
[Epoch 50; Iter   997/ 1097] train: loss: 0.0307110
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0218251
[Epoch 50; Iter  1057/ 1097] train: loss: 0.1515321
[Epoch 50; Iter  1087/ 1097] train: loss: 0.1979884
[Epoch 50] ogbg-molhiv: 0.835789 val loss: 0.080619
[Epoch 50] ogbg-molhiv: 0.745354 test loss: 0.151486
[Epoch 51; Iter    20/ 1097] train: loss: 0.0650939
[Epoch 51; Iter    50/ 1097] train: loss: 0.0122809
[Epoch 51; Iter    80/ 1097] train: loss: 0.0624482
[Epoch 51; Iter   110/ 1097] train: loss: 0.1498010
[Epoch 51; Iter   140/ 1097] train: loss: 0.0363845
[Epoch 51; Iter   170/ 1097] train: loss: 0.0691353
[Epoch 51; Iter   200/ 1097] train: loss: 0.0673707
[Epoch 51; Iter   230/ 1097] train: loss: 0.2366465
[Epoch 51; Iter   260/ 1097] train: loss: 0.1474856
[Epoch 51; Iter   290/ 1097] train: loss: 0.0997261
[Epoch 51; Iter   320/ 1097] train: loss: 0.0243598
[Epoch 51; Iter   350/ 1097] train: loss: 0.0124042
[Epoch 51; Iter   380/ 1097] train: loss: 0.0676965
[Epoch 51; Iter   410/ 1097] train: loss: 0.1127905
[Epoch 51; Iter   440/ 1097] train: loss: 0.0241490
[Epoch 51; Iter   470/ 1097] train: loss: 0.0850751
[Epoch 51; Iter   500/ 1097] train: loss: 0.0398145
[Epoch 51; Iter   530/ 1097] train: loss: 0.0237129
[Epoch 51; Iter   560/ 1097] train: loss: 0.0215542
[Epoch 51; Iter   590/ 1097] train: loss: 0.1524655
[Epoch 51; Iter   620/ 1097] train: loss: 0.0353142
[Epoch 51; Iter   650/ 1097] train: loss: 0.0097895
[Epoch 51; Iter   680/ 1097] train: loss: 0.0677033
[Epoch 51; Iter   710/ 1097] train: loss: 0.1025931
[Epoch 51; Iter   740/ 1097] train: loss: 0.0812194
[Epoch 51; Iter   770/ 1097] train: loss: 0.0326600
[Epoch 51; Iter   800/ 1097] train: loss: 0.0398119
[Epoch 51; Iter   830/ 1097] train: loss: 0.0079266
[Epoch 51; Iter   860/ 1097] train: loss: 0.0113521
[Epoch 51; Iter   890/ 1097] train: loss: 0.0375874
[Epoch 51; Iter   920/ 1097] train: loss: 0.0097698
[Epoch 51; Iter   950/ 1097] train: loss: 0.0950122
[Epoch 51; Iter   980/ 1097] train: loss: 0.0145326
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0316707
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0515594
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0799732
[Epoch 51] ogbg-molhiv: 0.832602 val loss: 0.079631
[Epoch 51] ogbg-molhiv: 0.734491 test loss: 0.155651
[Epoch 52; Iter     3/ 1097] train: loss: 0.1535134
[Epoch 52; Iter    33/ 1097] train: loss: 0.0171681
[Epoch 52; Iter    63/ 1097] train: loss: 0.0555152
[Epoch 52; Iter    93/ 1097] train: loss: 0.0953347
[Epoch 52; Iter   123/ 1097] train: loss: 0.0826733
[Epoch 52; Iter   153/ 1097] train: loss: 0.0320694
[Epoch 52; Iter   183/ 1097] train: loss: 0.0160241
[Epoch 52; Iter   213/ 1097] train: loss: 0.0315483
[Epoch 52; Iter   243/ 1097] train: loss: 0.0263399
[Epoch 52; Iter   273/ 1097] train: loss: 0.0172009
[Epoch 52; Iter   303/ 1097] train: loss: 0.0586685
[Epoch 52; Iter   333/ 1097] train: loss: 0.0829067
[Epoch 52; Iter   363/ 1097] train: loss: 0.0137497
[Epoch 52; Iter   393/ 1097] train: loss: 0.0717875
[Epoch 52; Iter   423/ 1097] train: loss: 0.0113635
[Epoch 52; Iter   453/ 1097] train: loss: 0.0767455
[Epoch 52; Iter   483/ 1097] train: loss: 0.0543864
[Epoch 52; Iter   513/ 1097] train: loss: 0.0159400
[Epoch 52; Iter   543/ 1097] train: loss: 0.0627891
[Epoch 52; Iter   573/ 1097] train: loss: 0.1694669
[Epoch 52; Iter   603/ 1097] train: loss: 0.0212972
[Epoch 52; Iter   633/ 1097] train: loss: 0.0496171
[Epoch 52; Iter   663/ 1097] train: loss: 0.0146047
[Epoch 52; Iter   693/ 1097] train: loss: 0.0274697
[Epoch 52; Iter   723/ 1097] train: loss: 0.0313365
[Epoch 52; Iter   753/ 1097] train: loss: 0.0603372
[Epoch 52; Iter   783/ 1097] train: loss: 0.0563696
[Epoch 52; Iter   813/ 1097] train: loss: 0.0716392
[Epoch 52; Iter   843/ 1097] train: loss: 0.0069852
[Epoch 52; Iter   873/ 1097] train: loss: 0.0508668
[Epoch 52; Iter   903/ 1097] train: loss: 0.1393601
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0046739
[Epoch 60] ogbg-molhiv: 0.625193 val loss: 0.280559
[Epoch 60] ogbg-molhiv: 0.712141 test loss: 0.320210
[Epoch 61; Iter    30/ 1097] train: loss: 0.0005795
[Epoch 61; Iter    60/ 1097] train: loss: 0.0006906
[Epoch 61; Iter    90/ 1097] train: loss: 0.0138919
[Epoch 61; Iter   120/ 1097] train: loss: 0.0039661
[Epoch 61; Iter   150/ 1097] train: loss: 0.0867226
[Epoch 61; Iter   180/ 1097] train: loss: 0.0020189
[Epoch 61; Iter   210/ 1097] train: loss: 0.0014121
[Epoch 61; Iter   240/ 1097] train: loss: 0.0002778
[Epoch 61; Iter   270/ 1097] train: loss: 0.0027918
[Epoch 61; Iter   300/ 1097] train: loss: 0.0040633
[Epoch 61; Iter   330/ 1097] train: loss: 0.0011668
[Epoch 61; Iter   360/ 1097] train: loss: 0.0047329
[Epoch 61; Iter   390/ 1097] train: loss: 0.0225375
[Epoch 61; Iter   420/ 1097] train: loss: 0.0019848
[Epoch 61; Iter   450/ 1097] train: loss: 0.0926883
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001517
[Epoch 61; Iter   510/ 1097] train: loss: 0.0014172
[Epoch 61; Iter   540/ 1097] train: loss: 0.0004512
[Epoch 61; Iter   570/ 1097] train: loss: 0.0146493
[Epoch 61; Iter   600/ 1097] train: loss: 0.0087160
[Epoch 61; Iter   630/ 1097] train: loss: 0.0361341
[Epoch 61; Iter   660/ 1097] train: loss: 0.0004343
[Epoch 61; Iter   690/ 1097] train: loss: 0.0003965
[Epoch 61; Iter   720/ 1097] train: loss: 0.0003240
[Epoch 61; Iter   750/ 1097] train: loss: 0.0007751
[Epoch 61; Iter   780/ 1097] train: loss: 0.0058532
[Epoch 61; Iter   810/ 1097] train: loss: 0.1319216
[Epoch 61; Iter   840/ 1097] train: loss: 0.0308694
[Epoch 61; Iter   870/ 1097] train: loss: 0.0010561
[Epoch 61; Iter   900/ 1097] train: loss: 0.0143928
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000666
[Epoch 61; Iter   960/ 1097] train: loss: 0.0044947
[Epoch 61; Iter   990/ 1097] train: loss: 0.1007650
[Epoch 61; Iter  1020/ 1097] train: loss: 0.2175823
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0248086
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0002268
[Epoch 61] ogbg-molhiv: 0.664021 val loss: 0.232306
[Epoch 61] ogbg-molhiv: 0.684005 test loss: 0.315478
[Epoch 62; Iter    13/ 1097] train: loss: 0.0451893
[Epoch 62; Iter    43/ 1097] train: loss: 0.0051075
[Epoch 62; Iter    73/ 1097] train: loss: 0.0124368
[Epoch 62; Iter   103/ 1097] train: loss: 0.0051815
[Epoch 62; Iter   133/ 1097] train: loss: 0.0035319
[Epoch 62; Iter   163/ 1097] train: loss: 0.0000847
[Epoch 62; Iter   193/ 1097] train: loss: 0.0011143
[Epoch 62; Iter   223/ 1097] train: loss: 0.0016729
[Epoch 62; Iter   253/ 1097] train: loss: 0.0005369
[Epoch 62; Iter   283/ 1097] train: loss: 0.0005491
[Epoch 62; Iter   313/ 1097] train: loss: 0.0016677
[Epoch 62; Iter   343/ 1097] train: loss: 0.0003737
[Epoch 62; Iter   373/ 1097] train: loss: 0.0046166
[Epoch 62; Iter   403/ 1097] train: loss: 0.0004174
[Epoch 62; Iter   433/ 1097] train: loss: 0.0070616
[Epoch 62; Iter   463/ 1097] train: loss: 0.0790522
[Epoch 62; Iter   493/ 1097] train: loss: 0.0037867
[Epoch 62; Iter   523/ 1097] train: loss: 0.0002480
[Epoch 62; Iter   553/ 1097] train: loss: 0.0006442
[Epoch 62; Iter   583/ 1097] train: loss: 0.0267663
[Epoch 62; Iter   613/ 1097] train: loss: 0.0001847
[Epoch 62; Iter   643/ 1097] train: loss: 0.0041336
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000781
[Epoch 62; Iter   703/ 1097] train: loss: 0.0011116
[Epoch 62; Iter   733/ 1097] train: loss: 0.0136223
[Epoch 62; Iter   763/ 1097] train: loss: 0.0037555
[Epoch 62; Iter   793/ 1097] train: loss: 0.0057100
[Epoch 62; Iter   823/ 1097] train: loss: 0.0006330
[Epoch 62; Iter   853/ 1097] train: loss: 0.0006183
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027678
[Epoch 62; Iter   913/ 1097] train: loss: 0.0001646
[Epoch 62; Iter   943/ 1097] train: loss: 0.0028298
[Epoch 62; Iter   973/ 1097] train: loss: 0.0003894
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0011171
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0005405
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000934
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0002443
[Epoch 62] ogbg-molhiv: 0.700360 val loss: 0.210726
[Epoch 62] ogbg-molhiv: 0.730437 test loss: 0.280914
[Epoch 63; Iter    26/ 1097] train: loss: 0.0001041
[Epoch 63; Iter    56/ 1097] train: loss: 0.0002448
[Epoch 63; Iter    86/ 1097] train: loss: 0.0127419
[Epoch 63; Iter   116/ 1097] train: loss: 0.0021373
[Epoch 63; Iter   146/ 1097] train: loss: 0.0029109
[Epoch 63; Iter   176/ 1097] train: loss: 0.0233127
[Epoch 63; Iter   206/ 1097] train: loss: 0.0010703
[Epoch 63; Iter   236/ 1097] train: loss: 0.0641593
[Epoch 63; Iter   266/ 1097] train: loss: 0.0044266
[Epoch 63; Iter   296/ 1097] train: loss: 0.0012258
[Epoch 63; Iter   326/ 1097] train: loss: 0.0561043
[Epoch 63; Iter   356/ 1097] train: loss: 0.0131931
[Epoch 63; Iter   386/ 1097] train: loss: 0.0008853
[Epoch 63; Iter   416/ 1097] train: loss: 0.0042147
[Epoch 63; Iter   446/ 1097] train: loss: 0.0001693
[Epoch 63; Iter   476/ 1097] train: loss: 0.0001355
[Epoch 63; Iter   506/ 1097] train: loss: 0.0003743
[Epoch 63; Iter   536/ 1097] train: loss: 0.0069393
[Epoch 63; Iter   566/ 1097] train: loss: 0.0002735
[Epoch 63; Iter   596/ 1097] train: loss: 0.0059836
[Epoch 63; Iter   626/ 1097] train: loss: 0.0009935
[Epoch 63; Iter   656/ 1097] train: loss: 0.0004312
[Epoch 63; Iter   686/ 1097] train: loss: 0.0001057
[Epoch 63; Iter   716/ 1097] train: loss: 0.0243852
[Epoch 63; Iter   746/ 1097] train: loss: 0.0018301
[Epoch 63; Iter   776/ 1097] train: loss: 0.0013762
[Epoch 63; Iter   806/ 1097] train: loss: 0.0007696
[Epoch 63; Iter   836/ 1097] train: loss: 0.0079877
[Epoch 63; Iter   866/ 1097] train: loss: 0.0004695
[Epoch 63; Iter   896/ 1097] train: loss: 0.0004846
[Epoch 63; Iter   926/ 1097] train: loss: 0.0014346
[Epoch 63; Iter   956/ 1097] train: loss: 0.0494487
[Epoch 63; Iter   986/ 1097] train: loss: 0.0024998
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0001280
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0034140
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0184442
[Epoch 63] ogbg-molhiv: 0.750220 val loss: 0.210280
[Epoch 63] ogbg-molhiv: 0.731318 test loss: 0.326410
[Epoch 64; Iter     9/ 1097] train: loss: 0.0004909
[Epoch 64; Iter    39/ 1097] train: loss: 0.0001792
[Epoch 64; Iter    69/ 1097] train: loss: 0.0069287
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000347
[Epoch 64; Iter   129/ 1097] train: loss: 0.0003854
[Epoch 64; Iter   159/ 1097] train: loss: 0.0031017
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002084
[Epoch 64; Iter   219/ 1097] train: loss: 0.0019127
[Epoch 64; Iter   249/ 1097] train: loss: 0.0006262
[Epoch 64; Iter   279/ 1097] train: loss: 0.0006152
[Epoch 64; Iter   309/ 1097] train: loss: 0.0007593
[Epoch 64; Iter   339/ 1097] train: loss: 0.0959073
[Epoch 64; Iter   369/ 1097] train: loss: 0.0028748
[Epoch 64; Iter   399/ 1097] train: loss: 0.0275876
[Epoch 64; Iter   429/ 1097] train: loss: 0.0020834
[Epoch 64; Iter   459/ 1097] train: loss: 0.0003305
[Epoch 64; Iter   489/ 1097] train: loss: 0.0005518
[Epoch 64; Iter   519/ 1097] train: loss: 0.0157033
[Epoch 64; Iter   549/ 1097] train: loss: 0.0008284
[Epoch 64; Iter   579/ 1097] train: loss: 0.0004595
[Epoch 64; Iter   609/ 1097] train: loss: 0.0009276
[Epoch 64; Iter   639/ 1097] train: loss: 0.0036578
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002868
[Epoch 64; Iter   699/ 1097] train: loss: 0.0127574
[Epoch 64; Iter   729/ 1097] train: loss: 0.0011118
[Epoch 64; Iter   759/ 1097] train: loss: 0.0007177
[Epoch 64; Iter   789/ 1097] train: loss: 0.0003779
[Epoch 64; Iter   819/ 1097] train: loss: 0.0004295
[Epoch 64; Iter   849/ 1097] train: loss: 0.1067576
[Epoch 64; Iter   879/ 1097] train: loss: 0.0019167
[Epoch 64; Iter   909/ 1097] train: loss: 0.0236455
[Epoch 64; Iter   939/ 1097] train: loss: 0.0001227
[Epoch 64; Iter   969/ 1097] train: loss: 0.0198451
[Epoch 64; Iter   999/ 1097] train: loss: 0.0558699
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0149809
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0004096
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0074842
[Epoch 64] ogbg-molhiv: 0.697127 val loss: 0.211933
[Epoch 64] ogbg-molhiv: 0.745725 test loss: 0.290957
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0406775
[Epoch 60] ogbg-molhiv: 0.669805 val loss: 5.514464
[Epoch 60] ogbg-molhiv: 0.699623 test loss: 2.177849
[Epoch 61; Iter    30/ 1097] train: loss: 0.0002899
[Epoch 61; Iter    60/ 1097] train: loss: 0.0019969
[Epoch 61; Iter    90/ 1097] train: loss: 0.0006908
[Epoch 61; Iter   120/ 1097] train: loss: 0.0012082
[Epoch 61; Iter   150/ 1097] train: loss: 0.0023778
[Epoch 61; Iter   180/ 1097] train: loss: 0.0033497
[Epoch 61; Iter   210/ 1097] train: loss: 0.0003624
[Epoch 61; Iter   240/ 1097] train: loss: 0.0003326
[Epoch 61; Iter   270/ 1097] train: loss: 0.0006194
[Epoch 61; Iter   300/ 1097] train: loss: 0.0012220
[Epoch 61; Iter   330/ 1097] train: loss: 0.0125597
[Epoch 61; Iter   360/ 1097] train: loss: 0.0036513
[Epoch 61; Iter   390/ 1097] train: loss: 0.0007285
[Epoch 61; Iter   420/ 1097] train: loss: 0.0160689
[Epoch 61; Iter   450/ 1097] train: loss: 0.0257441
[Epoch 61; Iter   480/ 1097] train: loss: 0.0011818
[Epoch 61; Iter   510/ 1097] train: loss: 0.0014505
[Epoch 61; Iter   540/ 1097] train: loss: 0.0154070
[Epoch 61; Iter   570/ 1097] train: loss: 0.0300529
[Epoch 61; Iter   600/ 1097] train: loss: 0.0008854
[Epoch 61; Iter   630/ 1097] train: loss: 0.0051491
[Epoch 61; Iter   660/ 1097] train: loss: 0.0047906
[Epoch 61; Iter   690/ 1097] train: loss: 0.0636925
[Epoch 61; Iter   720/ 1097] train: loss: 0.0361374
[Epoch 61; Iter   750/ 1097] train: loss: 0.0004877
[Epoch 61; Iter   780/ 1097] train: loss: 0.0105164
[Epoch 61; Iter   810/ 1097] train: loss: 0.0111788
[Epoch 61; Iter   840/ 1097] train: loss: 0.0011322
[Epoch 61; Iter   870/ 1097] train: loss: 0.0006157
[Epoch 61; Iter   900/ 1097] train: loss: 0.0101793
[Epoch 61; Iter   930/ 1097] train: loss: 0.0008646
[Epoch 61; Iter   960/ 1097] train: loss: 0.0031591
[Epoch 61; Iter   990/ 1097] train: loss: 0.0011609
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0046060
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0086116
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0033315
[Epoch 61] ogbg-molhiv: 0.705856 val loss: 1.720467
[Epoch 61] ogbg-molhiv: 0.693237 test loss: 1.048191
[Epoch 62; Iter    13/ 1097] train: loss: 0.0019478
[Epoch 62; Iter    43/ 1097] train: loss: 0.0093883
[Epoch 62; Iter    73/ 1097] train: loss: 0.0030231
[Epoch 62; Iter   103/ 1097] train: loss: 0.0001710
[Epoch 62; Iter   133/ 1097] train: loss: 0.0130297
[Epoch 62; Iter   163/ 1097] train: loss: 0.0040248
[Epoch 62; Iter   193/ 1097] train: loss: 0.0003125
[Epoch 62; Iter   223/ 1097] train: loss: 0.0407286
[Epoch 62; Iter   253/ 1097] train: loss: 0.0009981
[Epoch 62; Iter   283/ 1097] train: loss: 0.0026501
[Epoch 62; Iter   313/ 1097] train: loss: 0.0571193
[Epoch 62; Iter   343/ 1097] train: loss: 0.0007428
[Epoch 62; Iter   373/ 1097] train: loss: 0.0004107
[Epoch 62; Iter   403/ 1097] train: loss: 0.0178076
[Epoch 62; Iter   433/ 1097] train: loss: 0.0011213
[Epoch 62; Iter   463/ 1097] train: loss: 0.0023696
[Epoch 62; Iter   493/ 1097] train: loss: 0.1098500
[Epoch 62; Iter   523/ 1097] train: loss: 0.0055955
[Epoch 62; Iter   553/ 1097] train: loss: 0.0071214
[Epoch 62; Iter   583/ 1097] train: loss: 0.0215840
[Epoch 62; Iter   613/ 1097] train: loss: 0.0001426
[Epoch 62; Iter   643/ 1097] train: loss: 0.0141761
[Epoch 62; Iter   673/ 1097] train: loss: 0.0107721
[Epoch 62; Iter   703/ 1097] train: loss: 0.0007099
[Epoch 62; Iter   733/ 1097] train: loss: 0.0176091
[Epoch 62; Iter   763/ 1097] train: loss: 0.0024608
[Epoch 62; Iter   793/ 1097] train: loss: 0.0390372
[Epoch 62; Iter   823/ 1097] train: loss: 0.0046749
[Epoch 62; Iter   853/ 1097] train: loss: 0.0141396
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027121
[Epoch 62; Iter   913/ 1097] train: loss: 0.0003556
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001685
[Epoch 62; Iter   973/ 1097] train: loss: 0.0124343
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0042684
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001504
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0018185
[Epoch 62; Iter  1093/ 1097] train: loss: 0.2096782
[Epoch 62] ogbg-molhiv: 0.685703 val loss: 1.684361
[Epoch 62] ogbg-molhiv: 0.718564 test loss: 0.617230
[Epoch 63; Iter    26/ 1097] train: loss: 0.0025909
[Epoch 63; Iter    56/ 1097] train: loss: 0.0003378
[Epoch 63; Iter    86/ 1097] train: loss: 0.0071679
[Epoch 63; Iter   116/ 1097] train: loss: 0.0011766
[Epoch 63; Iter   146/ 1097] train: loss: 0.0017869
[Epoch 63; Iter   176/ 1097] train: loss: 0.0002969
[Epoch 63; Iter   206/ 1097] train: loss: 0.0166931
[Epoch 63; Iter   236/ 1097] train: loss: 0.0254598
[Epoch 63; Iter   266/ 1097] train: loss: 0.0017333
[Epoch 63; Iter   296/ 1097] train: loss: 0.0119749
[Epoch 63; Iter   326/ 1097] train: loss: 0.0068410
[Epoch 63; Iter   356/ 1097] train: loss: 0.0010443
[Epoch 63; Iter   386/ 1097] train: loss: 0.0719335
[Epoch 63; Iter   416/ 1097] train: loss: 0.0004159
[Epoch 63; Iter   446/ 1097] train: loss: 0.0058169
[Epoch 63; Iter   476/ 1097] train: loss: 0.0644456
[Epoch 63; Iter   506/ 1097] train: loss: 0.0692232
[Epoch 63; Iter   536/ 1097] train: loss: 0.0002832
[Epoch 63; Iter   566/ 1097] train: loss: 0.0164005
[Epoch 63; Iter   596/ 1097] train: loss: 0.0023258
[Epoch 63; Iter   626/ 1097] train: loss: 0.0013322
[Epoch 63; Iter   656/ 1097] train: loss: 0.0022104
[Epoch 63; Iter   686/ 1097] train: loss: 0.0038094
[Epoch 63; Iter   716/ 1097] train: loss: 0.0109156
[Epoch 63; Iter   746/ 1097] train: loss: 0.0038874
[Epoch 63; Iter   776/ 1097] train: loss: 0.0025897
[Epoch 63; Iter   806/ 1097] train: loss: 0.0003214
[Epoch 63; Iter   836/ 1097] train: loss: 0.0029312
[Epoch 63; Iter   866/ 1097] train: loss: 0.0176287
[Epoch 63; Iter   896/ 1097] train: loss: 0.0002533
[Epoch 63; Iter   926/ 1097] train: loss: 0.0139792
[Epoch 63; Iter   956/ 1097] train: loss: 0.0066725
[Epoch 63; Iter   986/ 1097] train: loss: 0.0001893
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0357350
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0008619
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0218532
[Epoch 63] ogbg-molhiv: 0.701793 val loss: 4.062165
[Epoch 63] ogbg-molhiv: 0.687132 test loss: 1.782676
[Epoch 64; Iter     9/ 1097] train: loss: 0.0085568
[Epoch 64; Iter    39/ 1097] train: loss: 0.0161962
[Epoch 64; Iter    69/ 1097] train: loss: 0.0021231
[Epoch 64; Iter    99/ 1097] train: loss: 0.0024304
[Epoch 64; Iter   129/ 1097] train: loss: 0.0092530
[Epoch 64; Iter   159/ 1097] train: loss: 0.0023866
[Epoch 64; Iter   189/ 1097] train: loss: 0.0003994
[Epoch 64; Iter   219/ 1097] train: loss: 0.0001196
[Epoch 64; Iter   249/ 1097] train: loss: 0.0002618
[Epoch 64; Iter   279/ 1097] train: loss: 0.0026410
[Epoch 64; Iter   309/ 1097] train: loss: 0.0002651
[Epoch 64; Iter   339/ 1097] train: loss: 0.0023290
[Epoch 64; Iter   369/ 1097] train: loss: 0.0008364
[Epoch 64; Iter   399/ 1097] train: loss: 0.0008063
[Epoch 64; Iter   429/ 1097] train: loss: 0.0120012
[Epoch 64; Iter   459/ 1097] train: loss: 0.0214526
[Epoch 64; Iter   489/ 1097] train: loss: 0.0047249
[Epoch 64; Iter   519/ 1097] train: loss: 0.0004178
[Epoch 64; Iter   549/ 1097] train: loss: 0.0011827
[Epoch 64; Iter   579/ 1097] train: loss: 0.0010950
[Epoch 64; Iter   609/ 1097] train: loss: 0.0006858
[Epoch 64; Iter   639/ 1097] train: loss: 0.0052525
[Epoch 64; Iter   669/ 1097] train: loss: 0.0123656
[Epoch 64; Iter   699/ 1097] train: loss: 0.0017499
[Epoch 64; Iter   729/ 1097] train: loss: 0.0357981
[Epoch 64; Iter   759/ 1097] train: loss: 0.0014802
[Epoch 64; Iter   789/ 1097] train: loss: 0.0436741
[Epoch 64; Iter   819/ 1097] train: loss: 0.0054836
[Epoch 64; Iter   849/ 1097] train: loss: 0.0156480
[Epoch 64; Iter   879/ 1097] train: loss: 0.0002039
[Epoch 64; Iter   909/ 1097] train: loss: 0.0220254
[Epoch 64; Iter   939/ 1097] train: loss: 0.0049951
[Epoch 64; Iter   969/ 1097] train: loss: 0.0698467
[Epoch 64; Iter   999/ 1097] train: loss: 0.0001692
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0148948
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0555560
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0058233
[Epoch 64] ogbg-molhiv: 0.706986 val loss: 3.056569
[Epoch 64] ogbg-molhiv: 0.713096 test loss: 1.346892
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003596
[Epoch 60] ogbg-molhiv: 0.793115 val loss: 0.172453
[Epoch 60] ogbg-molhiv: 0.726171 test loss: 0.300685
[Epoch 61; Iter    30/ 1097] train: loss: 0.0005864
[Epoch 61; Iter    60/ 1097] train: loss: 0.0135515
[Epoch 61; Iter    90/ 1097] train: loss: 0.0043921
[Epoch 61; Iter   120/ 1097] train: loss: 0.0086030
[Epoch 61; Iter   150/ 1097] train: loss: 0.0896983
[Epoch 61; Iter   180/ 1097] train: loss: 0.0002123
[Epoch 61; Iter   210/ 1097] train: loss: 0.0009627
[Epoch 61; Iter   240/ 1097] train: loss: 0.0009336
[Epoch 61; Iter   270/ 1097] train: loss: 0.0018402
[Epoch 61; Iter   300/ 1097] train: loss: 0.0004782
[Epoch 61; Iter   330/ 1097] train: loss: 0.0077008
[Epoch 61; Iter   360/ 1097] train: loss: 0.0002692
[Epoch 61; Iter   390/ 1097] train: loss: 0.0021830
[Epoch 61; Iter   420/ 1097] train: loss: 0.0018102
[Epoch 61; Iter   450/ 1097] train: loss: 0.0044784
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001549
[Epoch 61; Iter   510/ 1097] train: loss: 0.0009502
[Epoch 61; Iter   540/ 1097] train: loss: 0.0003822
[Epoch 61; Iter   570/ 1097] train: loss: 0.0055592
[Epoch 61; Iter   600/ 1097] train: loss: 0.0015460
[Epoch 61; Iter   630/ 1097] train: loss: 0.0009952
[Epoch 61; Iter   660/ 1097] train: loss: 0.0016285
[Epoch 61; Iter   690/ 1097] train: loss: 0.0107107
[Epoch 61; Iter   720/ 1097] train: loss: 0.0910162
[Epoch 61; Iter   750/ 1097] train: loss: 0.0134993
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002030
[Epoch 61; Iter   810/ 1097] train: loss: 0.0004419
[Epoch 61; Iter   840/ 1097] train: loss: 0.0104562
[Epoch 61; Iter   870/ 1097] train: loss: 0.0010745
[Epoch 61; Iter   900/ 1097] train: loss: 0.0624454
[Epoch 61; Iter   930/ 1097] train: loss: 0.0006474
[Epoch 61; Iter   960/ 1097] train: loss: 0.0018127
[Epoch 61; Iter   990/ 1097] train: loss: 0.0009271
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0031253
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0014740
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0197733
[Epoch 61] ogbg-molhiv: 0.769805 val loss: 0.187933
[Epoch 61] ogbg-molhiv: 0.738315 test loss: 0.307102
[Epoch 62; Iter    13/ 1097] train: loss: 0.0052430
[Epoch 62; Iter    43/ 1097] train: loss: 0.0021354
[Epoch 62; Iter    73/ 1097] train: loss: 0.0059230
[Epoch 62; Iter   103/ 1097] train: loss: 0.0000495
[Epoch 62; Iter   133/ 1097] train: loss: 0.0013007
[Epoch 62; Iter   163/ 1097] train: loss: 0.0508322
[Epoch 62; Iter   193/ 1097] train: loss: 0.0002098
[Epoch 62; Iter   223/ 1097] train: loss: 0.0125734
[Epoch 62; Iter   253/ 1097] train: loss: 0.0012350
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000936
[Epoch 62; Iter   313/ 1097] train: loss: 0.0045422
[Epoch 62; Iter   343/ 1097] train: loss: 0.0023255
[Epoch 62; Iter   373/ 1097] train: loss: 0.0010583
[Epoch 62; Iter   403/ 1097] train: loss: 0.0023703
[Epoch 62; Iter   433/ 1097] train: loss: 0.0001990
[Epoch 62; Iter   463/ 1097] train: loss: 0.0008546
[Epoch 62; Iter   493/ 1097] train: loss: 0.0014690
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003492
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000665
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003008
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000361
[Epoch 62; Iter   643/ 1097] train: loss: 0.0008750
[Epoch 62; Iter   673/ 1097] train: loss: 0.0007323
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001527
[Epoch 62; Iter   733/ 1097] train: loss: 0.0007597
[Epoch 62; Iter   763/ 1097] train: loss: 0.0000290
[Epoch 62; Iter   793/ 1097] train: loss: 0.0005035
[Epoch 62; Iter   823/ 1097] train: loss: 0.0007458
[Epoch 62; Iter   853/ 1097] train: loss: 0.0022275
[Epoch 62; Iter   883/ 1097] train: loss: 0.0004108
[Epoch 62; Iter   913/ 1097] train: loss: 0.0489996
[Epoch 62; Iter   943/ 1097] train: loss: 0.0005114
[Epoch 62; Iter   973/ 1097] train: loss: 0.0003430
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001831
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001162
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000504
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0006446
[Epoch 62] ogbg-molhiv: 0.761148 val loss: 0.207789
[Epoch 62] ogbg-molhiv: 0.707893 test loss: 0.310997
[Epoch 63; Iter    26/ 1097] train: loss: 0.0034885
[Epoch 63; Iter    56/ 1097] train: loss: 0.0006216
[Epoch 63; Iter    86/ 1097] train: loss: 0.0150210
[Epoch 63; Iter   116/ 1097] train: loss: 0.0003546
[Epoch 63; Iter   146/ 1097] train: loss: 0.0006145
[Epoch 63; Iter   176/ 1097] train: loss: 0.0000687
[Epoch 63; Iter   206/ 1097] train: loss: 0.0000342
[Epoch 63; Iter   236/ 1097] train: loss: 0.0007323
[Epoch 63; Iter   266/ 1097] train: loss: 0.0049521
[Epoch 63; Iter   296/ 1097] train: loss: 0.0009678
[Epoch 63; Iter   326/ 1097] train: loss: 0.0076118
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000553
[Epoch 63; Iter   386/ 1097] train: loss: 0.0258493
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000912
[Epoch 63; Iter   446/ 1097] train: loss: 0.0012887
[Epoch 63; Iter   476/ 1097] train: loss: 0.0036927
[Epoch 63; Iter   506/ 1097] train: loss: 0.0379671
[Epoch 63; Iter   536/ 1097] train: loss: 0.0001630
[Epoch 63; Iter   566/ 1097] train: loss: 0.0564113
[Epoch 63; Iter   596/ 1097] train: loss: 0.0000582
[Epoch 63; Iter   626/ 1097] train: loss: 0.0416108
[Epoch 63; Iter   656/ 1097] train: loss: 0.0002703
[Epoch 63; Iter   686/ 1097] train: loss: 0.0011964
[Epoch 63; Iter   716/ 1097] train: loss: 0.0012970
[Epoch 63; Iter   746/ 1097] train: loss: 0.0001693
[Epoch 63; Iter   776/ 1097] train: loss: 0.0206748
[Epoch 63; Iter   806/ 1097] train: loss: 0.0009531
[Epoch 63; Iter   836/ 1097] train: loss: 0.0006795
[Epoch 63; Iter   866/ 1097] train: loss: 0.0006369
[Epoch 63; Iter   896/ 1097] train: loss: 0.0048633
[Epoch 63; Iter   926/ 1097] train: loss: 0.0002251
[Epoch 63; Iter   956/ 1097] train: loss: 0.0000715
[Epoch 63; Iter   986/ 1097] train: loss: 0.0005591
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0008966
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0002413
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0065274
[Epoch 63] ogbg-molhiv: 0.767560 val loss: 0.196819
[Epoch 63] ogbg-molhiv: 0.723334 test loss: 0.310615
[Epoch 64; Iter     9/ 1097] train: loss: 0.0003123
[Epoch 64; Iter    39/ 1097] train: loss: 0.0204361
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000675
[Epoch 64; Iter    99/ 1097] train: loss: 0.0194807
[Epoch 64; Iter   129/ 1097] train: loss: 0.0000272
[Epoch 64; Iter   159/ 1097] train: loss: 0.0012966
[Epoch 64; Iter   189/ 1097] train: loss: 0.0079129
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000150
[Epoch 64; Iter   249/ 1097] train: loss: 0.0036438
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000946
[Epoch 64; Iter   309/ 1097] train: loss: 0.0012886
[Epoch 64; Iter   339/ 1097] train: loss: 0.0013215
[Epoch 64; Iter   369/ 1097] train: loss: 0.0010826
[Epoch 64; Iter   399/ 1097] train: loss: 0.0003343
[Epoch 64; Iter   429/ 1097] train: loss: 0.0020827
[Epoch 64; Iter   459/ 1097] train: loss: 0.0007235
[Epoch 64; Iter   489/ 1097] train: loss: 0.0068938
[Epoch 64; Iter   519/ 1097] train: loss: 0.0004332
[Epoch 64; Iter   549/ 1097] train: loss: 0.0004100
[Epoch 64; Iter   579/ 1097] train: loss: 0.0001179
[Epoch 64; Iter   609/ 1097] train: loss: 0.0002812
[Epoch 64; Iter   639/ 1097] train: loss: 0.0003388
[Epoch 64; Iter   669/ 1097] train: loss: 0.0801511
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001682
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002599
[Epoch 64; Iter   759/ 1097] train: loss: 0.0005371
[Epoch 64; Iter   789/ 1097] train: loss: 0.0023658
[Epoch 64; Iter   819/ 1097] train: loss: 0.0002928
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000803
[Epoch 64; Iter   879/ 1097] train: loss: 0.0003298
[Epoch 64; Iter   909/ 1097] train: loss: 0.0000395
[Epoch 64; Iter   939/ 1097] train: loss: 0.0004554
[Epoch 64; Iter   969/ 1097] train: loss: 0.0004415
[Epoch 64; Iter   999/ 1097] train: loss: 0.0067353
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0009737
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0039600
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0018828
[Epoch 64] ogbg-molhiv: 0.770637 val loss: 0.208303
[Epoch 64] ogbg-molhiv: 0.714969 test loss: 0.321924
[Epoch 48; Iter   851/ 1097] train: loss: 0.0961988
[Epoch 48; Iter   881/ 1097] train: loss: 0.0279280
[Epoch 48; Iter   911/ 1097] train: loss: 0.0698997
[Epoch 48; Iter   941/ 1097] train: loss: 0.0436805
[Epoch 48; Iter   971/ 1097] train: loss: 0.1679258
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0204187
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0421901
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0608696
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0979631
[Epoch 48] ogbg-molhiv: 0.811894 val loss: 0.080386
[Epoch 48] ogbg-molhiv: 0.758340 test loss: 0.143803
[Epoch 49; Iter    24/ 1097] train: loss: 0.0252192
[Epoch 49; Iter    54/ 1097] train: loss: 0.0189256
[Epoch 49; Iter    84/ 1097] train: loss: 0.0529459
[Epoch 49; Iter   114/ 1097] train: loss: 0.0166016
[Epoch 49; Iter   144/ 1097] train: loss: 0.0379143
[Epoch 49; Iter   174/ 1097] train: loss: 0.0147694
[Epoch 49; Iter   204/ 1097] train: loss: 0.0416996
[Epoch 49; Iter   234/ 1097] train: loss: 0.0316254
[Epoch 49; Iter   264/ 1097] train: loss: 0.0334005
[Epoch 49; Iter   294/ 1097] train: loss: 0.0185382
[Epoch 49; Iter   324/ 1097] train: loss: 0.1070679
[Epoch 49; Iter   354/ 1097] train: loss: 0.0586373
[Epoch 49; Iter   384/ 1097] train: loss: 0.0113015
[Epoch 49; Iter   414/ 1097] train: loss: 0.3352073
[Epoch 49; Iter   444/ 1097] train: loss: 0.0324332
[Epoch 49; Iter   474/ 1097] train: loss: 0.1092097
[Epoch 49; Iter   504/ 1097] train: loss: 0.0202612
[Epoch 49; Iter   534/ 1097] train: loss: 0.0357893
[Epoch 49; Iter   564/ 1097] train: loss: 0.0295613
[Epoch 49; Iter   594/ 1097] train: loss: 0.0433620
[Epoch 49; Iter   624/ 1097] train: loss: 0.0359070
[Epoch 49; Iter   654/ 1097] train: loss: 0.0215429
[Epoch 49; Iter   684/ 1097] train: loss: 0.0160596
[Epoch 49; Iter   714/ 1097] train: loss: 0.0212493
[Epoch 49; Iter   744/ 1097] train: loss: 0.0107404
[Epoch 49; Iter   774/ 1097] train: loss: 0.0457645
[Epoch 49; Iter   804/ 1097] train: loss: 0.0229503
[Epoch 49; Iter   834/ 1097] train: loss: 0.0207001
[Epoch 49; Iter   864/ 1097] train: loss: 0.0228086
[Epoch 49; Iter   894/ 1097] train: loss: 0.0665649
[Epoch 49; Iter   924/ 1097] train: loss: 0.0303924
[Epoch 49; Iter   954/ 1097] train: loss: 0.2417280
[Epoch 49; Iter   984/ 1097] train: loss: 0.0853603
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0510817
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0219311
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0117081
[Epoch 49] ogbg-molhiv: 0.773708 val loss: 0.088579
[Epoch 49] ogbg-molhiv: 0.737879 test loss: 0.153958
[Epoch 50; Iter     7/ 1097] train: loss: 0.0538041
[Epoch 50; Iter    37/ 1097] train: loss: 0.0141189
[Epoch 50; Iter    67/ 1097] train: loss: 0.1558783
[Epoch 50; Iter    97/ 1097] train: loss: 0.0207953
[Epoch 50; Iter   127/ 1097] train: loss: 0.1738478
[Epoch 50; Iter   157/ 1097] train: loss: 0.0197973
[Epoch 50; Iter   187/ 1097] train: loss: 0.0209727
[Epoch 50; Iter   217/ 1097] train: loss: 0.0239616
[Epoch 50; Iter   247/ 1097] train: loss: 0.0607687
[Epoch 50; Iter   277/ 1097] train: loss: 0.0720215
[Epoch 50; Iter   307/ 1097] train: loss: 0.0081307
[Epoch 50; Iter   337/ 1097] train: loss: 0.0134359
[Epoch 50; Iter   367/ 1097] train: loss: 0.0147738
[Epoch 50; Iter   397/ 1097] train: loss: 0.1295482
[Epoch 50; Iter   427/ 1097] train: loss: 0.0436384
[Epoch 50; Iter   457/ 1097] train: loss: 0.0184036
[Epoch 50; Iter   487/ 1097] train: loss: 0.1652537
[Epoch 50; Iter   517/ 1097] train: loss: 0.2168164
[Epoch 50; Iter   547/ 1097] train: loss: 0.0398929
[Epoch 50; Iter   577/ 1097] train: loss: 0.0797325
[Epoch 50; Iter   607/ 1097] train: loss: 0.1672455
[Epoch 50; Iter   637/ 1097] train: loss: 0.0449835
[Epoch 50; Iter   667/ 1097] train: loss: 0.0535830
[Epoch 50; Iter   697/ 1097] train: loss: 0.0173022
[Epoch 50; Iter   727/ 1097] train: loss: 0.1400758
[Epoch 50; Iter   757/ 1097] train: loss: 0.0405101
[Epoch 50; Iter   787/ 1097] train: loss: 0.0200359
[Epoch 50; Iter   817/ 1097] train: loss: 0.0105742
[Epoch 50; Iter   847/ 1097] train: loss: 0.0754779
[Epoch 50; Iter   877/ 1097] train: loss: 0.0178750
[Epoch 50; Iter   907/ 1097] train: loss: 0.0392127
[Epoch 50; Iter   937/ 1097] train: loss: 0.0237751
[Epoch 50; Iter   967/ 1097] train: loss: 0.1024811
[Epoch 50; Iter   997/ 1097] train: loss: 0.0471631
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0231826
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0257390
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0741599
[Epoch 50] ogbg-molhiv: 0.810874 val loss: 0.081557
[Epoch 50] ogbg-molhiv: 0.743881 test loss: 0.151759
[Epoch 51; Iter    20/ 1097] train: loss: 0.0383481
[Epoch 51; Iter    50/ 1097] train: loss: 0.2046150
[Epoch 51; Iter    80/ 1097] train: loss: 0.0891519
[Epoch 51; Iter   110/ 1097] train: loss: 0.0417785
[Epoch 51; Iter   140/ 1097] train: loss: 0.1250415
[Epoch 51; Iter   170/ 1097] train: loss: 0.0211324
[Epoch 51; Iter   200/ 1097] train: loss: 0.0799099
[Epoch 51; Iter   230/ 1097] train: loss: 0.0258105
[Epoch 51; Iter   260/ 1097] train: loss: 0.0105572
[Epoch 51; Iter   290/ 1097] train: loss: 0.0099878
[Epoch 51; Iter   320/ 1097] train: loss: 0.1982370
[Epoch 51; Iter   350/ 1097] train: loss: 0.0121242
[Epoch 51; Iter   380/ 1097] train: loss: 0.0872279
[Epoch 51; Iter   410/ 1097] train: loss: 0.0301291
[Epoch 51; Iter   440/ 1097] train: loss: 0.0617483
[Epoch 51; Iter   470/ 1097] train: loss: 0.1114739
[Epoch 51; Iter   500/ 1097] train: loss: 0.0120751
[Epoch 51; Iter   530/ 1097] train: loss: 0.0259058
[Epoch 51; Iter   560/ 1097] train: loss: 0.0254264
[Epoch 51; Iter   590/ 1097] train: loss: 0.1108088
[Epoch 51; Iter   620/ 1097] train: loss: 0.0145575
[Epoch 51; Iter   650/ 1097] train: loss: 0.0110405
[Epoch 51; Iter   680/ 1097] train: loss: 0.1181952
[Epoch 51; Iter   710/ 1097] train: loss: 0.0592276
[Epoch 51; Iter   740/ 1097] train: loss: 0.0061099
[Epoch 51; Iter   770/ 1097] train: loss: 0.0376430
[Epoch 51; Iter   800/ 1097] train: loss: 0.3539389
[Epoch 51; Iter   830/ 1097] train: loss: 0.0940784
[Epoch 51; Iter   860/ 1097] train: loss: 0.0551055
[Epoch 51; Iter   890/ 1097] train: loss: 0.1532081
[Epoch 51; Iter   920/ 1097] train: loss: 0.0292912
[Epoch 51; Iter   950/ 1097] train: loss: 0.0498546
[Epoch 51; Iter   980/ 1097] train: loss: 0.0417514
[Epoch 51; Iter  1010/ 1097] train: loss: 0.1732119
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1192931
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0751283
[Epoch 51] ogbg-molhiv: 0.794698 val loss: 0.081360
[Epoch 51] ogbg-molhiv: 0.750028 test loss: 0.149208
[Epoch 52; Iter     3/ 1097] train: loss: 0.1874983
[Epoch 52; Iter    33/ 1097] train: loss: 0.0455005
[Epoch 52; Iter    63/ 1097] train: loss: 0.0983351
[Epoch 52; Iter    93/ 1097] train: loss: 0.1171486
[Epoch 52; Iter   123/ 1097] train: loss: 0.0092890
[Epoch 52; Iter   153/ 1097] train: loss: 0.0087297
[Epoch 52; Iter   183/ 1097] train: loss: 0.0196064
[Epoch 52; Iter   213/ 1097] train: loss: 0.0135730
[Epoch 52; Iter   243/ 1097] train: loss: 0.0278760
[Epoch 52; Iter   273/ 1097] train: loss: 0.0802585
[Epoch 52; Iter   303/ 1097] train: loss: 0.2122773
[Epoch 52; Iter   333/ 1097] train: loss: 0.0131168
[Epoch 52; Iter   363/ 1097] train: loss: 0.0990964
[Epoch 52; Iter   393/ 1097] train: loss: 0.1142664
[Epoch 52; Iter   423/ 1097] train: loss: 0.0924171
[Epoch 52; Iter   453/ 1097] train: loss: 0.0165338
[Epoch 52; Iter   483/ 1097] train: loss: 0.1755978
[Epoch 52; Iter   513/ 1097] train: loss: 0.0209999
[Epoch 52; Iter   543/ 1097] train: loss: 0.0431990
[Epoch 52; Iter   573/ 1097] train: loss: 0.0085805
[Epoch 52; Iter   603/ 1097] train: loss: 0.0507375
[Epoch 52; Iter   633/ 1097] train: loss: 0.0925944
[Epoch 52; Iter   663/ 1097] train: loss: 0.1138075
[Epoch 52; Iter   693/ 1097] train: loss: 0.0763416
[Epoch 52; Iter   723/ 1097] train: loss: 0.1537886
[Epoch 52; Iter   753/ 1097] train: loss: 0.0244197
[Epoch 52; Iter   783/ 1097] train: loss: 0.0669417
[Epoch 52; Iter   813/ 1097] train: loss: 0.1071798
[Epoch 52; Iter   843/ 1097] train: loss: 0.2347269
[Epoch 52; Iter   873/ 1097] train: loss: 0.0168622
[Epoch 52; Iter   903/ 1097] train: loss: 0.0189516
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0013463
[Epoch 60] ogbg-molhiv: 0.772778 val loss: 0.316351
[Epoch 60] ogbg-molhiv: 0.744031 test loss: 0.310010
[Epoch 61; Iter    30/ 1097] train: loss: 0.0023381
[Epoch 61; Iter    60/ 1097] train: loss: 0.0556146
[Epoch 61; Iter    90/ 1097] train: loss: 0.0002164
[Epoch 61; Iter   120/ 1097] train: loss: 0.0001566
[Epoch 61; Iter   150/ 1097] train: loss: 0.0013863
[Epoch 61; Iter   180/ 1097] train: loss: 0.0008221
[Epoch 61; Iter   210/ 1097] train: loss: 0.0010873
[Epoch 61; Iter   240/ 1097] train: loss: 0.0156772
[Epoch 61; Iter   270/ 1097] train: loss: 0.0057003
[Epoch 61; Iter   300/ 1097] train: loss: 0.0002463
[Epoch 61; Iter   330/ 1097] train: loss: 0.0004813
[Epoch 61; Iter   360/ 1097] train: loss: 0.0064598
[Epoch 61; Iter   390/ 1097] train: loss: 0.0000917
[Epoch 61; Iter   420/ 1097] train: loss: 0.1434545
[Epoch 61; Iter   450/ 1097] train: loss: 0.0000221
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001147
[Epoch 61; Iter   510/ 1097] train: loss: 0.0006969
[Epoch 61; Iter   540/ 1097] train: loss: 0.0023553
[Epoch 61; Iter   570/ 1097] train: loss: 0.0040215
[Epoch 61; Iter   600/ 1097] train: loss: 0.0007939
[Epoch 61; Iter   630/ 1097] train: loss: 0.0009731
[Epoch 61; Iter   660/ 1097] train: loss: 0.0000525
[Epoch 61; Iter   690/ 1097] train: loss: 0.0276218
[Epoch 61; Iter   720/ 1097] train: loss: 0.0003874
[Epoch 61; Iter   750/ 1097] train: loss: 0.0026584
[Epoch 61; Iter   780/ 1097] train: loss: 0.0006085
[Epoch 61; Iter   810/ 1097] train: loss: 0.0005911
[Epoch 61; Iter   840/ 1097] train: loss: 0.0042387
[Epoch 61; Iter   870/ 1097] train: loss: 0.0002776
[Epoch 61; Iter   900/ 1097] train: loss: 0.0005715
[Epoch 61; Iter   930/ 1097] train: loss: 0.0060830
[Epoch 61; Iter   960/ 1097] train: loss: 0.0304093
[Epoch 61; Iter   990/ 1097] train: loss: 0.0001433
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0000342
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0003730
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0005121
[Epoch 61] ogbg-molhiv: 0.762633 val loss: 0.418303
[Epoch 61] ogbg-molhiv: 0.738591 test loss: 0.325683
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003327
[Epoch 62; Iter    43/ 1097] train: loss: 0.0033279
[Epoch 62; Iter    73/ 1097] train: loss: 0.0264821
[Epoch 62; Iter   103/ 1097] train: loss: 0.0006860
[Epoch 62; Iter   133/ 1097] train: loss: 0.0017516
[Epoch 62; Iter   163/ 1097] train: loss: 0.0017100
[Epoch 62; Iter   193/ 1097] train: loss: 0.0014489
[Epoch 62; Iter   223/ 1097] train: loss: 0.0004739
[Epoch 62; Iter   253/ 1097] train: loss: 0.0001855
[Epoch 62; Iter   283/ 1097] train: loss: 0.0001097
[Epoch 62; Iter   313/ 1097] train: loss: 0.0252561
[Epoch 62; Iter   343/ 1097] train: loss: 0.0013143
[Epoch 62; Iter   373/ 1097] train: loss: 0.0001259
[Epoch 62; Iter   403/ 1097] train: loss: 0.0049148
[Epoch 62; Iter   433/ 1097] train: loss: 0.0005046
[Epoch 62; Iter   463/ 1097] train: loss: 0.0003390
[Epoch 62; Iter   493/ 1097] train: loss: 0.0098081
[Epoch 62; Iter   523/ 1097] train: loss: 0.0012761
[Epoch 62; Iter   553/ 1097] train: loss: 0.1156173
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003636
[Epoch 62; Iter   613/ 1097] train: loss: 0.0005200
[Epoch 62; Iter   643/ 1097] train: loss: 0.0155621
[Epoch 62; Iter   673/ 1097] train: loss: 0.0001005
[Epoch 62; Iter   703/ 1097] train: loss: 0.0004437
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001046
[Epoch 62; Iter   763/ 1097] train: loss: 0.0002653
[Epoch 62; Iter   793/ 1097] train: loss: 0.0347438
[Epoch 62; Iter   823/ 1097] train: loss: 0.0077135
[Epoch 62; Iter   853/ 1097] train: loss: 0.0017710
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027052
[Epoch 62; Iter   913/ 1097] train: loss: 0.0003751
[Epoch 62; Iter   943/ 1097] train: loss: 0.0103923
[Epoch 62; Iter   973/ 1097] train: loss: 0.0020153
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001117
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0004904
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000906
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0001146
[Epoch 62] ogbg-molhiv: 0.771210 val loss: 0.331175
[Epoch 62] ogbg-molhiv: 0.751648 test loss: 0.302379
[Epoch 63; Iter    26/ 1097] train: loss: 0.0005892
[Epoch 63; Iter    56/ 1097] train: loss: 0.0055889
[Epoch 63; Iter    86/ 1097] train: loss: 0.0000124
[Epoch 63; Iter   116/ 1097] train: loss: 0.0017321
[Epoch 63; Iter   146/ 1097] train: loss: 0.0035063
[Epoch 63; Iter   176/ 1097] train: loss: 0.0007376
[Epoch 63; Iter   206/ 1097] train: loss: 0.0031733
[Epoch 63; Iter   236/ 1097] train: loss: 0.0003340
[Epoch 63; Iter   266/ 1097] train: loss: 0.0004894
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000476
[Epoch 63; Iter   326/ 1097] train: loss: 0.0018239
[Epoch 63; Iter   356/ 1097] train: loss: 0.0023822
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001141
[Epoch 63; Iter   416/ 1097] train: loss: 0.0021884
[Epoch 63; Iter   446/ 1097] train: loss: 0.0051229
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008028
[Epoch 63; Iter   506/ 1097] train: loss: 0.0001062
[Epoch 63; Iter   536/ 1097] train: loss: 0.0013288
[Epoch 63; Iter   566/ 1097] train: loss: 0.0002668
[Epoch 63; Iter   596/ 1097] train: loss: 0.0047355
[Epoch 63; Iter   626/ 1097] train: loss: 0.0000634
[Epoch 63; Iter   656/ 1097] train: loss: 0.0010746
[Epoch 63; Iter   686/ 1097] train: loss: 0.0001030
[Epoch 63; Iter   716/ 1097] train: loss: 0.0062347
[Epoch 63; Iter   746/ 1097] train: loss: 0.0003598
[Epoch 63; Iter   776/ 1097] train: loss: 0.0263336
[Epoch 63; Iter   806/ 1097] train: loss: 0.0026599
[Epoch 63; Iter   836/ 1097] train: loss: 0.0008773
[Epoch 63; Iter   866/ 1097] train: loss: 0.0006462
[Epoch 63; Iter   896/ 1097] train: loss: 0.0005137
[Epoch 63; Iter   926/ 1097] train: loss: 0.0062654
[Epoch 63; Iter   956/ 1097] train: loss: 0.0012152
[Epoch 63; Iter   986/ 1097] train: loss: 0.0015773
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0015908
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0008567
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0014966
[Epoch 63] ogbg-molhiv: 0.769002 val loss: 0.310021
[Epoch 63] ogbg-molhiv: 0.749294 test loss: 0.296586
[Epoch 64; Iter     9/ 1097] train: loss: 0.0006760
[Epoch 64; Iter    39/ 1097] train: loss: 0.0015223
[Epoch 64; Iter    69/ 1097] train: loss: 0.0030518
[Epoch 64; Iter    99/ 1097] train: loss: 0.0058078
[Epoch 64; Iter   129/ 1097] train: loss: 0.0023056
[Epoch 64; Iter   159/ 1097] train: loss: 0.0159403
[Epoch 64; Iter   189/ 1097] train: loss: 0.0012293
[Epoch 64; Iter   219/ 1097] train: loss: 0.0026575
[Epoch 64; Iter   249/ 1097] train: loss: 0.0000940
[Epoch 64; Iter   279/ 1097] train: loss: 0.0001246
[Epoch 64; Iter   309/ 1097] train: loss: 0.0002241
[Epoch 64; Iter   339/ 1097] train: loss: 0.0028462
[Epoch 64; Iter   369/ 1097] train: loss: 0.0036423
[Epoch 64; Iter   399/ 1097] train: loss: 0.0006920
[Epoch 64; Iter   429/ 1097] train: loss: 0.0004071
[Epoch 64; Iter   459/ 1097] train: loss: 0.0007549
[Epoch 64; Iter   489/ 1097] train: loss: 0.0001089
[Epoch 64; Iter   519/ 1097] train: loss: 0.0098427
[Epoch 64; Iter   549/ 1097] train: loss: 0.0002449
[Epoch 64; Iter   579/ 1097] train: loss: 0.0328531
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000693
[Epoch 64; Iter   639/ 1097] train: loss: 0.0019470
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002761
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001203
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002909
[Epoch 64; Iter   759/ 1097] train: loss: 0.0113044
[Epoch 64; Iter   789/ 1097] train: loss: 0.0003956
[Epoch 64; Iter   819/ 1097] train: loss: 0.0016405
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000378
[Epoch 64; Iter   879/ 1097] train: loss: 0.0007769
[Epoch 64; Iter   909/ 1097] train: loss: 0.0001543
[Epoch 64; Iter   939/ 1097] train: loss: 0.0057114
[Epoch 64; Iter   969/ 1097] train: loss: 0.0000604
[Epoch 64; Iter   999/ 1097] train: loss: 0.0000820
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0932660
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0004231
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0002751
[Epoch 64] ogbg-molhiv: 0.755089 val loss: 0.340112
[Epoch 64] ogbg-molhiv: 0.761911 test loss: 0.299921
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0002422
[Epoch 60] ogbg-molhiv: 0.800923 val loss: 0.218461
[Epoch 60] ogbg-molhiv: 0.723224 test loss: 0.364526
[Epoch 61; Iter    30/ 1097] train: loss: 0.0000279
[Epoch 61; Iter    60/ 1097] train: loss: 0.0133094
[Epoch 61; Iter    90/ 1097] train: loss: 0.0006840
[Epoch 61; Iter   120/ 1097] train: loss: 0.0000771
[Epoch 61; Iter   150/ 1097] train: loss: 0.0000541
[Epoch 61; Iter   180/ 1097] train: loss: 0.0019243
[Epoch 61; Iter   210/ 1097] train: loss: 0.0015303
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001258
[Epoch 61; Iter   270/ 1097] train: loss: 0.0022603
[Epoch 61; Iter   300/ 1097] train: loss: 0.0003220
[Epoch 61; Iter   330/ 1097] train: loss: 0.0003114
[Epoch 61; Iter   360/ 1097] train: loss: 0.0006099
[Epoch 61; Iter   390/ 1097] train: loss: 0.0011801
[Epoch 61; Iter   420/ 1097] train: loss: 0.0304503
[Epoch 61; Iter   450/ 1097] train: loss: 0.0004633
[Epoch 61; Iter   480/ 1097] train: loss: 0.0032683
[Epoch 61; Iter   510/ 1097] train: loss: 0.0001186
[Epoch 61; Iter   540/ 1097] train: loss: 0.0006350
[Epoch 61; Iter   570/ 1097] train: loss: 0.0412649
[Epoch 61; Iter   600/ 1097] train: loss: 0.0176836
[Epoch 61; Iter   630/ 1097] train: loss: 0.0034386
[Epoch 61; Iter   660/ 1097] train: loss: 0.0012412
[Epoch 61; Iter   690/ 1097] train: loss: 0.0005780
[Epoch 61; Iter   720/ 1097] train: loss: 0.0109292
[Epoch 61; Iter   750/ 1097] train: loss: 0.0005999
[Epoch 61; Iter   780/ 1097] train: loss: 0.0005156
[Epoch 61; Iter   810/ 1097] train: loss: 0.0001098
[Epoch 61; Iter   840/ 1097] train: loss: 0.0113765
[Epoch 61; Iter   870/ 1097] train: loss: 0.0051104
[Epoch 61; Iter   900/ 1097] train: loss: 0.0008709
[Epoch 61; Iter   930/ 1097] train: loss: 0.0043376
[Epoch 61; Iter   960/ 1097] train: loss: 0.0022846
[Epoch 61; Iter   990/ 1097] train: loss: 0.0000090
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0001315
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0000556
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0012407
[Epoch 61] ogbg-molhiv: 0.801762 val loss: 0.249594
[Epoch 61] ogbg-molhiv: 0.730111 test loss: 0.329257
[Epoch 62; Iter    13/ 1097] train: loss: 0.0032205
[Epoch 62; Iter    43/ 1097] train: loss: 0.0003369
[Epoch 62; Iter    73/ 1097] train: loss: 0.0047343
[Epoch 62; Iter   103/ 1097] train: loss: 0.0000446
[Epoch 62; Iter   133/ 1097] train: loss: 0.0004045
[Epoch 62; Iter   163/ 1097] train: loss: 0.0013500
[Epoch 62; Iter   193/ 1097] train: loss: 0.0023998
[Epoch 62; Iter   223/ 1097] train: loss: 0.0504993
[Epoch 62; Iter   253/ 1097] train: loss: 0.0000342
[Epoch 62; Iter   283/ 1097] train: loss: 0.0003021
[Epoch 62; Iter   313/ 1097] train: loss: 0.0019799
[Epoch 62; Iter   343/ 1097] train: loss: 0.0008593
[Epoch 62; Iter   373/ 1097] train: loss: 0.0003843
[Epoch 62; Iter   403/ 1097] train: loss: 0.0040959
[Epoch 62; Iter   433/ 1097] train: loss: 0.0033559
[Epoch 62; Iter   463/ 1097] train: loss: 0.0004541
[Epoch 62; Iter   493/ 1097] train: loss: 0.0006586
[Epoch 62; Iter   523/ 1097] train: loss: 0.0011123
[Epoch 62; Iter   553/ 1097] train: loss: 0.0100046
[Epoch 62; Iter   583/ 1097] train: loss: 0.0125293
[Epoch 62; Iter   613/ 1097] train: loss: 0.0061423
[Epoch 62; Iter   643/ 1097] train: loss: 0.0006868
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000909
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001763
[Epoch 62; Iter   733/ 1097] train: loss: 0.0009052
[Epoch 62; Iter   763/ 1097] train: loss: 0.0028860
[Epoch 62; Iter   793/ 1097] train: loss: 0.0004966
[Epoch 62; Iter   823/ 1097] train: loss: 0.0008958
[Epoch 62; Iter   853/ 1097] train: loss: 0.0175531
[Epoch 62; Iter   883/ 1097] train: loss: 0.0001305
[Epoch 62; Iter   913/ 1097] train: loss: 0.0012464
[Epoch 62; Iter   943/ 1097] train: loss: 0.0347026
[Epoch 62; Iter   973/ 1097] train: loss: 0.0062923
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0028421
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0054730
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0021654
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0000241
[Epoch 62] ogbg-molhiv: 0.807861 val loss: 0.670590
[Epoch 62] ogbg-molhiv: 0.736833 test loss: 0.358730
[Epoch 63; Iter    26/ 1097] train: loss: 0.0006495
[Epoch 63; Iter    56/ 1097] train: loss: 0.0000395
[Epoch 63; Iter    86/ 1097] train: loss: 0.0004475
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001920
[Epoch 63; Iter   146/ 1097] train: loss: 0.0089358
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001335
[Epoch 63; Iter   206/ 1097] train: loss: 0.0001097
[Epoch 63; Iter   236/ 1097] train: loss: 0.0001649
[Epoch 63; Iter   266/ 1097] train: loss: 0.0000725
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000931
[Epoch 63; Iter   326/ 1097] train: loss: 0.0009501
[Epoch 63; Iter   356/ 1097] train: loss: 0.0005025
[Epoch 63; Iter   386/ 1097] train: loss: 0.0009983
[Epoch 63; Iter   416/ 1097] train: loss: 0.0081296
[Epoch 63; Iter   446/ 1097] train: loss: 0.0018640
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008063
[Epoch 63; Iter   506/ 1097] train: loss: 0.0204077
[Epoch 63; Iter   536/ 1097] train: loss: 0.0068599
[Epoch 63; Iter   566/ 1097] train: loss: 0.0001039
[Epoch 63; Iter   596/ 1097] train: loss: 0.0057989
[Epoch 63; Iter   626/ 1097] train: loss: 0.0000428
[Epoch 63; Iter   656/ 1097] train: loss: 0.0004121
[Epoch 63; Iter   686/ 1097] train: loss: 0.0438742
[Epoch 63; Iter   716/ 1097] train: loss: 0.0001102
[Epoch 63; Iter   746/ 1097] train: loss: 0.0011007
[Epoch 63; Iter   776/ 1097] train: loss: 0.0000191
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006625
[Epoch 63; Iter   836/ 1097] train: loss: 0.0004639
[Epoch 63; Iter   866/ 1097] train: loss: 0.0030533
[Epoch 63; Iter   896/ 1097] train: loss: 0.0038987
[Epoch 63; Iter   926/ 1097] train: loss: 0.0008599
[Epoch 63; Iter   956/ 1097] train: loss: 0.0009472
[Epoch 63; Iter   986/ 1097] train: loss: 0.0242783
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0002867
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0003524
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0011030
[Epoch 63] ogbg-molhiv: 0.807322 val loss: 0.228796
[Epoch 63] ogbg-molhiv: 0.725008 test loss: 0.343276
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000180
[Epoch 64; Iter    39/ 1097] train: loss: 0.0008587
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000417
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000587
[Epoch 64; Iter   129/ 1097] train: loss: 0.0017253
[Epoch 64; Iter   159/ 1097] train: loss: 0.0001946
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002616
[Epoch 64; Iter   219/ 1097] train: loss: 0.0005908
[Epoch 64; Iter   249/ 1097] train: loss: 0.0005131
[Epoch 64; Iter   279/ 1097] train: loss: 0.0002010
[Epoch 64; Iter   309/ 1097] train: loss: 0.0007478
[Epoch 64; Iter   339/ 1097] train: loss: 0.0003219
[Epoch 64; Iter   369/ 1097] train: loss: 0.0003061
[Epoch 64; Iter   399/ 1097] train: loss: 0.0002986
[Epoch 64; Iter   429/ 1097] train: loss: 0.0014634
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001582
[Epoch 64; Iter   489/ 1097] train: loss: 0.0000788
[Epoch 64; Iter   519/ 1097] train: loss: 0.0000934
[Epoch 64; Iter   549/ 1097] train: loss: 0.0006971
[Epoch 64; Iter   579/ 1097] train: loss: 0.0002789
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000132
[Epoch 64; Iter   639/ 1097] train: loss: 0.0213699
[Epoch 64; Iter   669/ 1097] train: loss: 0.0062585
[Epoch 64; Iter   699/ 1097] train: loss: 0.0933060
[Epoch 64; Iter   729/ 1097] train: loss: 0.0004907
[Epoch 64; Iter   759/ 1097] train: loss: 0.0834665
[Epoch 64; Iter   789/ 1097] train: loss: 0.0065409
[Epoch 64; Iter   819/ 1097] train: loss: 0.0018027
[Epoch 64; Iter   849/ 1097] train: loss: 0.0002736
[Epoch 64; Iter   879/ 1097] train: loss: 0.0008970
[Epoch 64; Iter   909/ 1097] train: loss: 0.0020056
[Epoch 64; Iter   939/ 1097] train: loss: 0.0086293
[Epoch 64; Iter   969/ 1097] train: loss: 0.0055503
[Epoch 64; Iter   999/ 1097] train: loss: 0.0054587
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0127733
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0000201
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0001828
[Epoch 64] ogbg-molhiv: 0.783439 val loss: 0.270612
[Epoch 64] ogbg-molhiv: 0.726710 test loss: 0.358558
[Epoch 48; Iter   851/ 1097] train: loss: 0.0690345
[Epoch 48; Iter   881/ 1097] train: loss: 0.0297876
[Epoch 48; Iter   911/ 1097] train: loss: 0.1952441
[Epoch 48; Iter   941/ 1097] train: loss: 0.0215519
[Epoch 48; Iter   971/ 1097] train: loss: 0.0103831
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0125542
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0149491
[Epoch 48; Iter  1061/ 1097] train: loss: 0.1111146
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0102885
[Epoch 48] ogbg-molhiv: 0.813581 val loss: 0.084040
[Epoch 48] ogbg-molhiv: 0.756407 test loss: 0.178621
[Epoch 49; Iter    24/ 1097] train: loss: 0.0540316
[Epoch 49; Iter    54/ 1097] train: loss: 0.0133211
[Epoch 49; Iter    84/ 1097] train: loss: 0.0105005
[Epoch 49; Iter   114/ 1097] train: loss: 0.0053734
[Epoch 49; Iter   144/ 1097] train: loss: 0.0141985
[Epoch 49; Iter   174/ 1097] train: loss: 0.0062307
[Epoch 49; Iter   204/ 1097] train: loss: 0.0085903
[Epoch 49; Iter   234/ 1097] train: loss: 0.0067034
[Epoch 49; Iter   264/ 1097] train: loss: 0.1981740
[Epoch 49; Iter   294/ 1097] train: loss: 0.0055416
[Epoch 49; Iter   324/ 1097] train: loss: 0.0248704
[Epoch 49; Iter   354/ 1097] train: loss: 0.0725690
[Epoch 49; Iter   384/ 1097] train: loss: 0.0194268
[Epoch 49; Iter   414/ 1097] train: loss: 0.2934948
[Epoch 49; Iter   444/ 1097] train: loss: 0.0323227
[Epoch 49; Iter   474/ 1097] train: loss: 0.0292235
[Epoch 49; Iter   504/ 1097] train: loss: 0.0214007
[Epoch 49; Iter   534/ 1097] train: loss: 0.0122350
[Epoch 49; Iter   564/ 1097] train: loss: 0.0239301
[Epoch 49; Iter   594/ 1097] train: loss: 0.1434681
[Epoch 49; Iter   624/ 1097] train: loss: 0.1808376
[Epoch 49; Iter   654/ 1097] train: loss: 0.1916826
[Epoch 49; Iter   684/ 1097] train: loss: 0.0451050
[Epoch 49; Iter   714/ 1097] train: loss: 0.0041657
[Epoch 49; Iter   744/ 1097] train: loss: 0.0550566
[Epoch 49; Iter   774/ 1097] train: loss: 0.0170340
[Epoch 49; Iter   804/ 1097] train: loss: 0.0484481
[Epoch 49; Iter   834/ 1097] train: loss: 0.0323271
[Epoch 49; Iter   864/ 1097] train: loss: 0.0226942
[Epoch 49; Iter   894/ 1097] train: loss: 0.1285512
[Epoch 49; Iter   924/ 1097] train: loss: 0.0404674
[Epoch 49; Iter   954/ 1097] train: loss: 0.0259388
[Epoch 49; Iter   984/ 1097] train: loss: 0.0176965
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0267786
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0200603
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0183187
[Epoch 49] ogbg-molhiv: 0.816912 val loss: 0.092197
[Epoch 49] ogbg-molhiv: 0.761060 test loss: 0.155136
[Epoch 50; Iter     7/ 1097] train: loss: 0.2038089
[Epoch 50; Iter    37/ 1097] train: loss: 0.0162708
[Epoch 50; Iter    67/ 1097] train: loss: 0.1358978
[Epoch 50; Iter    97/ 1097] train: loss: 0.0123838
[Epoch 50; Iter   127/ 1097] train: loss: 0.0296394
[Epoch 50; Iter   157/ 1097] train: loss: 0.0183821
[Epoch 50; Iter   187/ 1097] train: loss: 0.0130969
[Epoch 50; Iter   217/ 1097] train: loss: 0.0571242
[Epoch 50; Iter   247/ 1097] train: loss: 0.0250038
[Epoch 50; Iter   277/ 1097] train: loss: 0.1185289
[Epoch 50; Iter   307/ 1097] train: loss: 0.0235438
[Epoch 50; Iter   337/ 1097] train: loss: 0.0310998
[Epoch 50; Iter   367/ 1097] train: loss: 0.0248320
[Epoch 50; Iter   397/ 1097] train: loss: 0.1083348
[Epoch 50; Iter   427/ 1097] train: loss: 0.1499744
[Epoch 50; Iter   457/ 1097] train: loss: 0.0290747
[Epoch 50; Iter   487/ 1097] train: loss: 0.0188011
[Epoch 50; Iter   517/ 1097] train: loss: 0.0131404
[Epoch 50; Iter   547/ 1097] train: loss: 0.1367545
[Epoch 50; Iter   577/ 1097] train: loss: 0.1967483
[Epoch 50; Iter   607/ 1097] train: loss: 0.0111602
[Epoch 50; Iter   637/ 1097] train: loss: 0.0924807
[Epoch 50; Iter   667/ 1097] train: loss: 0.0166337
[Epoch 50; Iter   697/ 1097] train: loss: 0.1708052
[Epoch 50; Iter   727/ 1097] train: loss: 0.1554839
[Epoch 50; Iter   757/ 1097] train: loss: 0.0061027
[Epoch 50; Iter   787/ 1097] train: loss: 0.0776882
[Epoch 50; Iter   817/ 1097] train: loss: 0.0455708
[Epoch 50; Iter   847/ 1097] train: loss: 0.0473941
[Epoch 50; Iter   877/ 1097] train: loss: 0.0256808
[Epoch 50; Iter   907/ 1097] train: loss: 0.1157253
[Epoch 50; Iter   937/ 1097] train: loss: 0.0257315
[Epoch 50; Iter   967/ 1097] train: loss: 0.0380536
[Epoch 50; Iter   997/ 1097] train: loss: 0.0066301
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0683992
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0092695
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0501810
[Epoch 50] ogbg-molhiv: 0.810436 val loss: 0.095858
[Epoch 50] ogbg-molhiv: 0.761425 test loss: 0.162265
[Epoch 51; Iter    20/ 1097] train: loss: 0.1467137
[Epoch 51; Iter    50/ 1097] train: loss: 0.0319965
[Epoch 51; Iter    80/ 1097] train: loss: 0.0242525
[Epoch 51; Iter   110/ 1097] train: loss: 0.0430033
[Epoch 51; Iter   140/ 1097] train: loss: 0.0251396
[Epoch 51; Iter   170/ 1097] train: loss: 0.0191154
[Epoch 51; Iter   200/ 1097] train: loss: 0.0403167
[Epoch 51; Iter   230/ 1097] train: loss: 0.0113074
[Epoch 51; Iter   260/ 1097] train: loss: 0.0092958
[Epoch 51; Iter   290/ 1097] train: loss: 0.0228628
[Epoch 51; Iter   320/ 1097] train: loss: 0.0122377
[Epoch 51; Iter   350/ 1097] train: loss: 0.0234666
[Epoch 51; Iter   380/ 1097] train: loss: 0.0210627
[Epoch 51; Iter   410/ 1097] train: loss: 0.0237876
[Epoch 51; Iter   440/ 1097] train: loss: 0.1342886
[Epoch 51; Iter   470/ 1097] train: loss: 0.0326115
[Epoch 51; Iter   500/ 1097] train: loss: 0.1218727
[Epoch 51; Iter   530/ 1097] train: loss: 0.0527294
[Epoch 51; Iter   560/ 1097] train: loss: 0.0060993
[Epoch 51; Iter   590/ 1097] train: loss: 0.0192801
[Epoch 51; Iter   620/ 1097] train: loss: 0.0470483
[Epoch 51; Iter   650/ 1097] train: loss: 0.0104178
[Epoch 51; Iter   680/ 1097] train: loss: 0.0549056
[Epoch 51; Iter   710/ 1097] train: loss: 0.0559986
[Epoch 51; Iter   740/ 1097] train: loss: 0.0486065
[Epoch 51; Iter   770/ 1097] train: loss: 0.2219317
[Epoch 51; Iter   800/ 1097] train: loss: 0.0578190
[Epoch 51; Iter   830/ 1097] train: loss: 0.0134142
[Epoch 51; Iter   860/ 1097] train: loss: 0.0695806
[Epoch 51; Iter   890/ 1097] train: loss: 0.0049077
[Epoch 51; Iter   920/ 1097] train: loss: 0.0703492
[Epoch 51; Iter   950/ 1097] train: loss: 0.0218737
[Epoch 51; Iter   980/ 1097] train: loss: 0.0398500
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0304991
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1292909
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0264403
[Epoch 51] ogbg-molhiv: 0.794911 val loss: 0.097958
[Epoch 51] ogbg-molhiv: 0.742193 test loss: 0.206393
[Epoch 52; Iter     3/ 1097] train: loss: 0.0208782
[Epoch 52; Iter    33/ 1097] train: loss: 0.0732696
[Epoch 52; Iter    63/ 1097] train: loss: 0.0100284
[Epoch 52; Iter    93/ 1097] train: loss: 0.0358391
[Epoch 52; Iter   123/ 1097] train: loss: 0.0562884
[Epoch 52; Iter   153/ 1097] train: loss: 0.0778058
[Epoch 52; Iter   183/ 1097] train: loss: 0.1104498
[Epoch 52; Iter   213/ 1097] train: loss: 0.0151802
[Epoch 52; Iter   243/ 1097] train: loss: 0.1600889
[Epoch 52; Iter   273/ 1097] train: loss: 0.0612284
[Epoch 52; Iter   303/ 1097] train: loss: 0.1733461
[Epoch 52; Iter   333/ 1097] train: loss: 0.0192628
[Epoch 52; Iter   363/ 1097] train: loss: 0.0325170
[Epoch 52; Iter   393/ 1097] train: loss: 0.0430702
[Epoch 52; Iter   423/ 1097] train: loss: 0.0090459
[Epoch 52; Iter   453/ 1097] train: loss: 0.0808443
[Epoch 52; Iter   483/ 1097] train: loss: 0.0052005
[Epoch 52; Iter   513/ 1097] train: loss: 0.1092525
[Epoch 52; Iter   543/ 1097] train: loss: 0.1447595
[Epoch 52; Iter   573/ 1097] train: loss: 0.1889725
[Epoch 52; Iter   603/ 1097] train: loss: 0.0101591
[Epoch 52; Iter   633/ 1097] train: loss: 0.1054244
[Epoch 52; Iter   663/ 1097] train: loss: 0.0202051
[Epoch 52; Iter   693/ 1097] train: loss: 0.0290887
[Epoch 52; Iter   723/ 1097] train: loss: 0.0260323
[Epoch 52; Iter   753/ 1097] train: loss: 0.1288410
[Epoch 52; Iter   783/ 1097] train: loss: 0.0099058
[Epoch 52; Iter   813/ 1097] train: loss: 0.0098209
[Epoch 52; Iter   843/ 1097] train: loss: 0.0264934
[Epoch 52; Iter   873/ 1097] train: loss: 0.0451123
[Epoch 52; Iter   903/ 1097] train: loss: 0.0539212
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003952
[Epoch 60] ogbg-molhiv: 0.764909 val loss: 0.276172
[Epoch 60] ogbg-molhiv: 0.800626 test loss: 0.276815
[Epoch 61; Iter    30/ 1097] train: loss: 0.0007118
[Epoch 61; Iter    60/ 1097] train: loss: 0.0002030
[Epoch 61; Iter    90/ 1097] train: loss: 0.0003418
[Epoch 61; Iter   120/ 1097] train: loss: 0.0006924
[Epoch 61; Iter   150/ 1097] train: loss: 0.0000237
[Epoch 61; Iter   180/ 1097] train: loss: 0.0183286
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002345
[Epoch 61; Iter   240/ 1097] train: loss: 0.0039420
[Epoch 61; Iter   270/ 1097] train: loss: 0.0004153
[Epoch 61; Iter   300/ 1097] train: loss: 0.0001488
[Epoch 61; Iter   330/ 1097] train: loss: 0.0002595
[Epoch 61; Iter   360/ 1097] train: loss: 0.0010786
[Epoch 61; Iter   390/ 1097] train: loss: 0.0008129
[Epoch 61; Iter   420/ 1097] train: loss: 0.0001819
[Epoch 61; Iter   450/ 1097] train: loss: 0.0002463
[Epoch 61; Iter   480/ 1097] train: loss: 0.0000436
[Epoch 61; Iter   510/ 1097] train: loss: 0.0064476
[Epoch 61; Iter   540/ 1097] train: loss: 0.0006874
[Epoch 61; Iter   570/ 1097] train: loss: 0.0006522
[Epoch 61; Iter   600/ 1097] train: loss: 0.0005349
[Epoch 61; Iter   630/ 1097] train: loss: 0.0001070
[Epoch 61; Iter   660/ 1097] train: loss: 0.0280998
[Epoch 61; Iter   690/ 1097] train: loss: 0.0006714
[Epoch 61; Iter   720/ 1097] train: loss: 0.0000998
[Epoch 61; Iter   750/ 1097] train: loss: 0.0125667
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002852
[Epoch 61; Iter   810/ 1097] train: loss: 0.0097001
[Epoch 61; Iter   840/ 1097] train: loss: 0.0072922
[Epoch 61; Iter   870/ 1097] train: loss: 0.0001940
[Epoch 61; Iter   900/ 1097] train: loss: 0.0036252
[Epoch 61; Iter   930/ 1097] train: loss: 0.0032954
[Epoch 61; Iter   960/ 1097] train: loss: 0.0006502
[Epoch 61; Iter   990/ 1097] train: loss: 0.0028367
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0008981
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0000916
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0001465
[Epoch 61] ogbg-molhiv: 0.766877 val loss: 0.222988
[Epoch 61] ogbg-molhiv: 0.796412 test loss: 0.276660
[Epoch 62; Iter    13/ 1097] train: loss: 0.0002700
[Epoch 62; Iter    43/ 1097] train: loss: 0.0040847
[Epoch 62; Iter    73/ 1097] train: loss: 0.0032944
[Epoch 62; Iter   103/ 1097] train: loss: 0.0002986
[Epoch 62; Iter   133/ 1097] train: loss: 0.0000567
[Epoch 62; Iter   163/ 1097] train: loss: 0.0015112
[Epoch 62; Iter   193/ 1097] train: loss: 0.0018630
[Epoch 62; Iter   223/ 1097] train: loss: 0.0008842
[Epoch 62; Iter   253/ 1097] train: loss: 0.0001915
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000111
[Epoch 62; Iter   313/ 1097] train: loss: 0.0254393
[Epoch 62; Iter   343/ 1097] train: loss: 0.0000234
[Epoch 62; Iter   373/ 1097] train: loss: 0.0002416
[Epoch 62; Iter   403/ 1097] train: loss: 0.0025744
[Epoch 62; Iter   433/ 1097] train: loss: 0.0002202
[Epoch 62; Iter   463/ 1097] train: loss: 0.0045392
[Epoch 62; Iter   493/ 1097] train: loss: 0.0000815
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003892
[Epoch 62; Iter   553/ 1097] train: loss: 0.0015094
[Epoch 62; Iter   583/ 1097] train: loss: 0.0813485
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000267
[Epoch 62; Iter   643/ 1097] train: loss: 0.0003231
[Epoch 62; Iter   673/ 1097] train: loss: 0.0004067
[Epoch 62; Iter   703/ 1097] train: loss: 0.0007740
[Epoch 62; Iter   733/ 1097] train: loss: 0.0000355
[Epoch 62; Iter   763/ 1097] train: loss: 0.0357923
[Epoch 62; Iter   793/ 1097] train: loss: 0.0010814
[Epoch 62; Iter   823/ 1097] train: loss: 0.0000291
[Epoch 62; Iter   853/ 1097] train: loss: 0.0017074
[Epoch 62; Iter   883/ 1097] train: loss: 0.0046427
[Epoch 62; Iter   913/ 1097] train: loss: 0.0013623
[Epoch 62; Iter   943/ 1097] train: loss: 0.0024453
[Epoch 62; Iter   973/ 1097] train: loss: 0.0002437
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0000990
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001664
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0086436
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0008117
[Epoch 62] ogbg-molhiv: 0.789441 val loss: 0.272468
[Epoch 62] ogbg-molhiv: 0.806066 test loss: 0.285754
[Epoch 63; Iter    26/ 1097] train: loss: 0.0000877
[Epoch 63; Iter    56/ 1097] train: loss: 0.0007742
[Epoch 63; Iter    86/ 1097] train: loss: 0.0006099
[Epoch 63; Iter   116/ 1097] train: loss: 0.0242904
[Epoch 63; Iter   146/ 1097] train: loss: 0.0037820
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001498
[Epoch 63; Iter   206/ 1097] train: loss: 0.0001831
[Epoch 63; Iter   236/ 1097] train: loss: 0.0014076
[Epoch 63; Iter   266/ 1097] train: loss: 0.0007457
[Epoch 63; Iter   296/ 1097] train: loss: 0.0002746
[Epoch 63; Iter   326/ 1097] train: loss: 0.0431182
[Epoch 63; Iter   356/ 1097] train: loss: 0.0019992
[Epoch 63; Iter   386/ 1097] train: loss: 0.0046574
[Epoch 63; Iter   416/ 1097] train: loss: 0.0004021
[Epoch 63; Iter   446/ 1097] train: loss: 0.0001275
[Epoch 63; Iter   476/ 1097] train: loss: 0.0000498
[Epoch 63; Iter   506/ 1097] train: loss: 0.0000166
[Epoch 63; Iter   536/ 1097] train: loss: 0.0002665
[Epoch 63; Iter   566/ 1097] train: loss: 0.0013949
[Epoch 63; Iter   596/ 1097] train: loss: 0.0005656
[Epoch 63; Iter   626/ 1097] train: loss: 0.0125141
[Epoch 63; Iter   656/ 1097] train: loss: 0.0001480
[Epoch 63; Iter   686/ 1097] train: loss: 0.0014546
[Epoch 63; Iter   716/ 1097] train: loss: 0.0000146
[Epoch 63; Iter   746/ 1097] train: loss: 0.0012400
[Epoch 63; Iter   776/ 1097] train: loss: 0.0002915
[Epoch 63; Iter   806/ 1097] train: loss: 0.0003120
[Epoch 63; Iter   836/ 1097] train: loss: 0.0000167
[Epoch 63; Iter   866/ 1097] train: loss: 0.0047146
[Epoch 63; Iter   896/ 1097] train: loss: 0.0000853
[Epoch 63; Iter   926/ 1097] train: loss: 0.0004509
[Epoch 63; Iter   956/ 1097] train: loss: 0.0036352
[Epoch 63; Iter   986/ 1097] train: loss: 0.0021236
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0000983
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0025181
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0002901
[Epoch 63] ogbg-molhiv: 0.781786 val loss: 0.313688
[Epoch 63] ogbg-molhiv: 0.779694 test loss: 0.299272
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000370
[Epoch 64; Iter    39/ 1097] train: loss: 0.0000862
[Epoch 64; Iter    69/ 1097] train: loss: 0.0004379
[Epoch 64; Iter    99/ 1097] train: loss: 0.0011847
[Epoch 64; Iter   129/ 1097] train: loss: 0.0002011
[Epoch 64; Iter   159/ 1097] train: loss: 0.0109823
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002835
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000653
[Epoch 64; Iter   249/ 1097] train: loss: 0.0004126
[Epoch 64; Iter   279/ 1097] train: loss: 0.0158182
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000299
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000133
[Epoch 64; Iter   369/ 1097] train: loss: 0.0000319
[Epoch 64; Iter   399/ 1097] train: loss: 0.0002262
[Epoch 64; Iter   429/ 1097] train: loss: 0.0006027
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001653
[Epoch 64; Iter   489/ 1097] train: loss: 0.0005271
[Epoch 64; Iter   519/ 1097] train: loss: 0.0003652
[Epoch 64; Iter   549/ 1097] train: loss: 0.0004720
[Epoch 64; Iter   579/ 1097] train: loss: 0.0012331
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000944
[Epoch 64; Iter   639/ 1097] train: loss: 0.0000083
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002011
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001596
[Epoch 64; Iter   729/ 1097] train: loss: 0.0000672
[Epoch 64; Iter   759/ 1097] train: loss: 0.0001280
[Epoch 64; Iter   789/ 1097] train: loss: 0.0001598
[Epoch 64; Iter   819/ 1097] train: loss: 0.0186871
[Epoch 64; Iter   849/ 1097] train: loss: 0.0005672
[Epoch 64; Iter   879/ 1097] train: loss: 0.0001011
[Epoch 64; Iter   909/ 1097] train: loss: 0.0003698
[Epoch 64; Iter   939/ 1097] train: loss: 0.0057486
[Epoch 64; Iter   969/ 1097] train: loss: 0.0003708
[Epoch 64; Iter   999/ 1097] train: loss: 0.0046257
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0048857
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0010226
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0391158
[Epoch 64] ogbg-molhiv: 0.794582 val loss: 0.289066
[Epoch 64] ogbg-molhiv: 0.804598 test loss: 0.304605
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0007748
[Epoch 60] ogbg-molhiv: 0.686183 val loss: 2.609524
[Epoch 60] ogbg-molhiv: 0.582257 test loss: 2.733538
[Epoch 61; Iter    30/ 1097] train: loss: 0.0010579
[Epoch 61; Iter    60/ 1097] train: loss: 0.0000128
[Epoch 61; Iter    90/ 1097] train: loss: 0.0000298
[Epoch 61; Iter   120/ 1097] train: loss: 0.0004974
[Epoch 61; Iter   150/ 1097] train: loss: 0.0005836
[Epoch 61; Iter   180/ 1097] train: loss: 0.0013831
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002251
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001683
[Epoch 61; Iter   270/ 1097] train: loss: 0.0000572
[Epoch 61; Iter   300/ 1097] train: loss: 0.0000142
[Epoch 61; Iter   330/ 1097] train: loss: 0.0004503
[Epoch 61; Iter   360/ 1097] train: loss: 0.0000965
[Epoch 61; Iter   390/ 1097] train: loss: 0.0001227
[Epoch 61; Iter   420/ 1097] train: loss: 0.0007527
[Epoch 61; Iter   450/ 1097] train: loss: 0.0036096
[Epoch 61; Iter   480/ 1097] train: loss: 0.0000768
[Epoch 61; Iter   510/ 1097] train: loss: 0.0000095
[Epoch 61; Iter   540/ 1097] train: loss: 0.0000142
[Epoch 61; Iter   570/ 1097] train: loss: 0.0000650
[Epoch 61; Iter   600/ 1097] train: loss: 0.0039914
[Epoch 61; Iter   630/ 1097] train: loss: 0.0000656
[Epoch 61; Iter   660/ 1097] train: loss: 0.0000647
[Epoch 61; Iter   690/ 1097] train: loss: 0.0003005
[Epoch 61; Iter   720/ 1097] train: loss: 0.0001355
[Epoch 61; Iter   750/ 1097] train: loss: 0.0000662
[Epoch 61; Iter   780/ 1097] train: loss: 0.0001385
[Epoch 61; Iter   810/ 1097] train: loss: 0.0417296
[Epoch 61; Iter   840/ 1097] train: loss: 0.0188916
[Epoch 61; Iter   870/ 1097] train: loss: 0.0021776
[Epoch 61; Iter   900/ 1097] train: loss: 0.0003852
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000096
[Epoch 61; Iter   960/ 1097] train: loss: 0.0000986
[Epoch 61; Iter   990/ 1097] train: loss: 0.0003236
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0008956
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0001732
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0004201
[Epoch 61] ogbg-molhiv: 0.716656 val loss: 1.103538
[Epoch 61] ogbg-molhiv: 0.627859 test loss: 2.024368
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003246
[Epoch 62; Iter    43/ 1097] train: loss: 0.0001894
[Epoch 62; Iter    73/ 1097] train: loss: 0.0000445
[Epoch 62; Iter   103/ 1097] train: loss: 0.0016657
[Epoch 62; Iter   133/ 1097] train: loss: 0.0000050
[Epoch 62; Iter   163/ 1097] train: loss: 0.0019923
[Epoch 62; Iter   193/ 1097] train: loss: 0.0054881
[Epoch 62; Iter   223/ 1097] train: loss: 0.0026084
[Epoch 62; Iter   253/ 1097] train: loss: 0.0043682
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000078
[Epoch 62; Iter   313/ 1097] train: loss: 0.0004170
[Epoch 62; Iter   343/ 1097] train: loss: 0.0000555
[Epoch 62; Iter   373/ 1097] train: loss: 0.0000261
[Epoch 62; Iter   403/ 1097] train: loss: 0.0001095
[Epoch 62; Iter   433/ 1097] train: loss: 0.0002575
[Epoch 62; Iter   463/ 1097] train: loss: 0.0000437
[Epoch 62; Iter   493/ 1097] train: loss: 0.0024944
[Epoch 62; Iter   523/ 1097] train: loss: 0.0000536
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000783
[Epoch 62; Iter   583/ 1097] train: loss: 0.0000977
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000171
[Epoch 62; Iter   643/ 1097] train: loss: 0.0000452
[Epoch 62; Iter   673/ 1097] train: loss: 0.0122459
[Epoch 62; Iter   703/ 1097] train: loss: 0.0000203
[Epoch 62; Iter   733/ 1097] train: loss: 0.0006815
[Epoch 62; Iter   763/ 1097] train: loss: 0.0000519
[Epoch 62; Iter   793/ 1097] train: loss: 0.0003355
[Epoch 62; Iter   823/ 1097] train: loss: 0.0017640
[Epoch 62; Iter   853/ 1097] train: loss: 0.0001041
[Epoch 62; Iter   883/ 1097] train: loss: 0.0000126
[Epoch 62; Iter   913/ 1097] train: loss: 0.0000167
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001066
[Epoch 62; Iter   973/ 1097] train: loss: 0.0000648
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0000067
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001126
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0030043
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0077386
[Epoch 62] ogbg-molhiv: 0.701793 val loss: 3.080653
[Epoch 62] ogbg-molhiv: 0.588376 test loss: 4.487486
[Epoch 63; Iter    26/ 1097] train: loss: 0.0000848
[Epoch 63; Iter    56/ 1097] train: loss: 0.0000721
[Epoch 63; Iter    86/ 1097] train: loss: 0.0003567
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001557
[Epoch 63; Iter   146/ 1097] train: loss: 0.0001883
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001290
[Epoch 63; Iter   206/ 1097] train: loss: 0.0000210
[Epoch 63; Iter   236/ 1097] train: loss: 0.0000311
[Epoch 63; Iter   266/ 1097] train: loss: 0.0002549
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000504
[Epoch 63; Iter   326/ 1097] train: loss: 0.0000063
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000637
[Epoch 63; Iter   386/ 1097] train: loss: 0.0005949
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000277
[Epoch 63; Iter   446/ 1097] train: loss: 0.0000110
[Epoch 63; Iter   476/ 1097] train: loss: 0.0000097
[Epoch 63; Iter   506/ 1097] train: loss: 0.0008662
[Epoch 63; Iter   536/ 1097] train: loss: 0.0000102
[Epoch 63; Iter   566/ 1097] train: loss: 0.0026474
[Epoch 63; Iter   596/ 1097] train: loss: 0.0000078
[Epoch 63; Iter   626/ 1097] train: loss: 0.0009789
[Epoch 63; Iter   656/ 1097] train: loss: 0.0000923
[Epoch 63; Iter   686/ 1097] train: loss: 0.0006403
[Epoch 63; Iter   716/ 1097] train: loss: 0.0000187
[Epoch 63; Iter   746/ 1097] train: loss: 0.0018294
[Epoch 63; Iter   776/ 1097] train: loss: 0.0000153
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006051
[Epoch 63; Iter   836/ 1097] train: loss: 0.0002334
[Epoch 63; Iter   866/ 1097] train: loss: 0.0005242
[Epoch 63; Iter   896/ 1097] train: loss: 0.0000951
[Epoch 63; Iter   926/ 1097] train: loss: 0.0000391
[Epoch 63; Iter   956/ 1097] train: loss: 0.0000399
[Epoch 63; Iter   986/ 1097] train: loss: 0.0012724
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004419
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0019764
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0001467
[Epoch 63] ogbg-molhiv: 0.709390 val loss: 4.034613
[Epoch 63] ogbg-molhiv: 0.592369 test loss: 5.400616
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000811
[Epoch 64; Iter    39/ 1097] train: loss: 0.0032032
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000134
[Epoch 64; Iter    99/ 1097] train: loss: 0.0001032
[Epoch 64; Iter   129/ 1097] train: loss: 0.0022163
[Epoch 64; Iter   159/ 1097] train: loss: 0.0003327
[Epoch 64; Iter   189/ 1097] train: loss: 0.0015390
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000280
[Epoch 64; Iter   249/ 1097] train: loss: 0.0001287
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000085
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000147
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000122
[Epoch 64; Iter   369/ 1097] train: loss: 0.0019212
[Epoch 64; Iter   399/ 1097] train: loss: 0.0003380
[Epoch 64; Iter   429/ 1097] train: loss: 0.0003048
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001946
[Epoch 64; Iter   489/ 1097] train: loss: 0.0000898
[Epoch 64; Iter   519/ 1097] train: loss: 0.0002934
[Epoch 64; Iter   549/ 1097] train: loss: 0.0014125
[Epoch 64; Iter   579/ 1097] train: loss: 0.0000093
[Epoch 64; Iter   609/ 1097] train: loss: 0.0001092
[Epoch 64; Iter   639/ 1097] train: loss: 0.0000209
[Epoch 64; Iter   669/ 1097] train: loss: 0.0007291
[Epoch 64; Iter   699/ 1097] train: loss: 0.0000037
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002367
[Epoch 64; Iter   759/ 1097] train: loss: 0.0000211
[Epoch 64; Iter   789/ 1097] train: loss: 0.0242523
[Epoch 64; Iter   819/ 1097] train: loss: 0.0000526
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000910
[Epoch 64; Iter   879/ 1097] train: loss: 0.0000658
[Epoch 64; Iter   909/ 1097] train: loss: 0.0008503
[Epoch 64; Iter   939/ 1097] train: loss: 0.0000102
[Epoch 64; Iter   969/ 1097] train: loss: 0.0004973
[Epoch 64; Iter   999/ 1097] train: loss: 0.0001471
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0001251
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0021332
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0002146
[Epoch 64] ogbg-molhiv: 0.696517 val loss: 3.432242
[Epoch 64] ogbg-molhiv: 0.646600 test loss: 3.657058
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003564
[Epoch 60] ogbg-molhiv: 0.779832 val loss: 12.775035
[Epoch 60] ogbg-molhiv: 0.714261 test loss: 12.345723
[Epoch 61; Iter    30/ 1097] train: loss: 0.0004838
[Epoch 61; Iter    60/ 1097] train: loss: 0.0008419
[Epoch 61; Iter    90/ 1097] train: loss: 0.0004366
[Epoch 61; Iter   120/ 1097] train: loss: 0.0307589
[Epoch 61; Iter   150/ 1097] train: loss: 0.0229467
[Epoch 61; Iter   180/ 1097] train: loss: 0.0005872
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002891
[Epoch 61; Iter   240/ 1097] train: loss: 0.0208309
[Epoch 61; Iter   270/ 1097] train: loss: 0.0004479
[Epoch 61; Iter   300/ 1097] train: loss: 0.0000323
[Epoch 61; Iter   330/ 1097] train: loss: 0.0010398
[Epoch 61; Iter   360/ 1097] train: loss: 0.0021703
[Epoch 61; Iter   390/ 1097] train: loss: 0.0000435
[Epoch 61; Iter   420/ 1097] train: loss: 0.0028738
[Epoch 61; Iter   450/ 1097] train: loss: 0.0016836
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001441
[Epoch 61; Iter   510/ 1097] train: loss: 0.0004742
[Epoch 61; Iter   540/ 1097] train: loss: 0.0013921
[Epoch 61; Iter   570/ 1097] train: loss: 0.0557930
[Epoch 61; Iter   600/ 1097] train: loss: 0.0311580
[Epoch 61; Iter   630/ 1097] train: loss: 0.0087516
[Epoch 61; Iter   660/ 1097] train: loss: 0.0014100
[Epoch 61; Iter   690/ 1097] train: loss: 0.0000611
[Epoch 61; Iter   720/ 1097] train: loss: 0.0010368
[Epoch 61; Iter   750/ 1097] train: loss: 0.0025330
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002754
[Epoch 61; Iter   810/ 1097] train: loss: 0.0914670
[Epoch 61; Iter   840/ 1097] train: loss: 0.0084208
[Epoch 61; Iter   870/ 1097] train: loss: 0.0003725
[Epoch 61; Iter   900/ 1097] train: loss: 0.0060805
[Epoch 61; Iter   930/ 1097] train: loss: 0.0004718
[Epoch 61; Iter   960/ 1097] train: loss: 0.0003148
[Epoch 61; Iter   990/ 1097] train: loss: 0.0089250
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0001702
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0236182
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0000254
[Epoch 61] ogbg-molhiv: 0.760512 val loss: 2.160940
[Epoch 61] ogbg-molhiv: 0.721760 test loss: 5.441449
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003270
[Epoch 62; Iter    43/ 1097] train: loss: 0.0017690
[Epoch 62; Iter    73/ 1097] train: loss: 0.0001117
[Epoch 62; Iter   103/ 1097] train: loss: 0.0001383
[Epoch 62; Iter   133/ 1097] train: loss: 0.0003480
[Epoch 62; Iter   163/ 1097] train: loss: 0.0001599
[Epoch 62; Iter   193/ 1097] train: loss: 0.0022749
[Epoch 62; Iter   223/ 1097] train: loss: 0.0038358
[Epoch 62; Iter   253/ 1097] train: loss: 0.0002181
[Epoch 62; Iter   283/ 1097] train: loss: 0.0003609
[Epoch 62; Iter   313/ 1097] train: loss: 0.0005591
[Epoch 62; Iter   343/ 1097] train: loss: 0.0006407
[Epoch 62; Iter   373/ 1097] train: loss: 0.0000268
[Epoch 62; Iter   403/ 1097] train: loss: 0.0000651
[Epoch 62; Iter   433/ 1097] train: loss: 0.1051709
[Epoch 62; Iter   463/ 1097] train: loss: 0.0439262
[Epoch 62; Iter   493/ 1097] train: loss: 0.0000634
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003292
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000419
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003951
[Epoch 62; Iter   613/ 1097] train: loss: 0.0008999
[Epoch 62; Iter   643/ 1097] train: loss: 0.0004892
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000141
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001056
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001997
[Epoch 62; Iter   763/ 1097] train: loss: 0.0024618
[Epoch 62; Iter   793/ 1097] train: loss: 0.0001938
[Epoch 62; Iter   823/ 1097] train: loss: 0.0004238
[Epoch 62; Iter   853/ 1097] train: loss: 0.0001979
[Epoch 62; Iter   883/ 1097] train: loss: 0.0000124
[Epoch 62; Iter   913/ 1097] train: loss: 0.0041715
[Epoch 62; Iter   943/ 1097] train: loss: 0.0005689
[Epoch 62; Iter   973/ 1097] train: loss: 0.0038789
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001627
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0040513
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0002601
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0001006
[Epoch 62] ogbg-molhiv: 0.764970 val loss: 9.921717
[Epoch 62] ogbg-molhiv: 0.726936 test loss: 9.285245
[Epoch 63; Iter    26/ 1097] train: loss: 0.0001697
[Epoch 63; Iter    56/ 1097] train: loss: 0.0001086
[Epoch 63; Iter    86/ 1097] train: loss: 0.0003100
[Epoch 63; Iter   116/ 1097] train: loss: 0.0004068
[Epoch 63; Iter   146/ 1097] train: loss: 0.0102345
[Epoch 63; Iter   176/ 1097] train: loss: 0.0042396
[Epoch 63; Iter   206/ 1097] train: loss: 0.0002416
[Epoch 63; Iter   236/ 1097] train: loss: 0.0000597
[Epoch 63; Iter   266/ 1097] train: loss: 0.0001115
[Epoch 63; Iter   296/ 1097] train: loss: 0.0003167
[Epoch 63; Iter   326/ 1097] train: loss: 0.0626594
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000223
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001576
[Epoch 63; Iter   416/ 1097] train: loss: 0.0009353
[Epoch 63; Iter   446/ 1097] train: loss: 0.0003275
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008379
[Epoch 63; Iter   506/ 1097] train: loss: 0.0015240
[Epoch 63; Iter   536/ 1097] train: loss: 0.0433930
[Epoch 63; Iter   566/ 1097] train: loss: 0.0019681
[Epoch 63; Iter   596/ 1097] train: loss: 0.0037475
[Epoch 63; Iter   626/ 1097] train: loss: 0.0003801
[Epoch 63; Iter   656/ 1097] train: loss: 0.0001412
[Epoch 63; Iter   686/ 1097] train: loss: 0.0169190
[Epoch 63; Iter   716/ 1097] train: loss: 0.0007622
[Epoch 63; Iter   746/ 1097] train: loss: 0.0016403
[Epoch 63; Iter   776/ 1097] train: loss: 0.0003385
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006005
[Epoch 63; Iter   836/ 1097] train: loss: 0.0009033
[Epoch 63; Iter   866/ 1097] train: loss: 0.0004839
[Epoch 63; Iter   896/ 1097] train: loss: 0.0006998
[Epoch 63; Iter   926/ 1097] train: loss: 0.0158618
[Epoch 63; Iter   956/ 1097] train: loss: 0.0072602
[Epoch 63; Iter   986/ 1097] train: loss: 0.0002437
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004843
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0036602
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0000602
[Epoch 63] ogbg-molhiv: 0.775840 val loss: 6.377900
[Epoch 63] ogbg-molhiv: 0.708502 test loss: 9.033629
[Epoch 64; Iter     9/ 1097] train: loss: 0.0003566
[Epoch 64; Iter    39/ 1097] train: loss: 0.0012031
[Epoch 64; Iter    69/ 1097] train: loss: 0.0010804
[Epoch 64; Iter    99/ 1097] train: loss: 0.0001251
[Epoch 64; Iter   129/ 1097] train: loss: 0.0000841
[Epoch 64; Iter   159/ 1097] train: loss: 0.0005776
[Epoch 64; Iter   189/ 1097] train: loss: 0.0000389
[Epoch 64; Iter   219/ 1097] train: loss: 0.0010077
[Epoch 64; Iter   249/ 1097] train: loss: 0.0002724
[Epoch 64; Iter   279/ 1097] train: loss: 0.0006985
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000432
[Epoch 64; Iter   339/ 1097] train: loss: 0.0019143
[Epoch 64; Iter   369/ 1097] train: loss: 0.0002257
[Epoch 64; Iter   399/ 1097] train: loss: 0.0001185
[Epoch 64; Iter   429/ 1097] train: loss: 0.0000271
[Epoch 64; Iter   459/ 1097] train: loss: 0.0000842
[Epoch 64; Iter   489/ 1097] train: loss: 0.0309157
[Epoch 64; Iter   519/ 1097] train: loss: 0.0042081
[Epoch 64; Iter   549/ 1097] train: loss: 0.0139428
[Epoch 64; Iter   579/ 1097] train: loss: 0.0003443
[Epoch 64; Iter   609/ 1097] train: loss: 0.0009269
[Epoch 64; Iter   639/ 1097] train: loss: 0.0222355
[Epoch 64; Iter   669/ 1097] train: loss: 0.0000973
[Epoch 64; Iter   699/ 1097] train: loss: 0.0003386
[Epoch 64; Iter   729/ 1097] train: loss: 0.0011025
[Epoch 64; Iter   759/ 1097] train: loss: 0.0001770
[Epoch 64; Iter   789/ 1097] train: loss: 0.0012588
[Epoch 64; Iter   819/ 1097] train: loss: 0.0025285
[Epoch 64; Iter   849/ 1097] train: loss: 0.0487288
[Epoch 64; Iter   879/ 1097] train: loss: 0.0002744
[Epoch 64; Iter   909/ 1097] train: loss: 0.0000388
[Epoch 64; Iter   939/ 1097] train: loss: 0.0001182
[Epoch 64; Iter   969/ 1097] train: loss: 0.0001367
[Epoch 64; Iter   999/ 1097] train: loss: 0.0034672
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0011596
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0001310
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0117984
[Epoch 64] ogbg-molhiv: 0.729507 val loss: 3.377933
[Epoch 64] ogbg-molhiv: 0.724321 test loss: 4.067614
[Epoch 60; Iter  1097/ 1097] train: loss: 0.2053896
[Epoch 60] ogbg-molhiv: 0.681979 val loss: 83.914417
[Epoch 60] ogbg-molhiv: 0.571865 test loss: 73.667704
[Epoch 61; Iter    30/ 1097] train: loss: 0.0780411
[Epoch 61; Iter    60/ 1097] train: loss: 0.0002596
[Epoch 61; Iter    90/ 1097] train: loss: 0.0017158
[Epoch 61; Iter   120/ 1097] train: loss: 0.0001561
[Epoch 61; Iter   150/ 1097] train: loss: 0.0001807
[Epoch 61; Iter   180/ 1097] train: loss: 0.0018364
[Epoch 61; Iter   210/ 1097] train: loss: 0.0019858
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001035
[Epoch 61; Iter   270/ 1097] train: loss: 0.0151094
[Epoch 61; Iter   300/ 1097] train: loss: 0.0005735
[Epoch 61; Iter   330/ 1097] train: loss: 0.0009635
[Epoch 61; Iter   360/ 1097] train: loss: 0.0002387
[Epoch 61; Iter   390/ 1097] train: loss: 0.0002311
[Epoch 61; Iter   420/ 1097] train: loss: 0.0027466
[Epoch 61; Iter   450/ 1097] train: loss: 0.0001448
[Epoch 61; Iter   480/ 1097] train: loss: 0.0090078
[Epoch 61; Iter   510/ 1097] train: loss: 0.0012644
[Epoch 61; Iter   540/ 1097] train: loss: 0.0075010
[Epoch 61; Iter   570/ 1097] train: loss: 0.0814558
[Epoch 61; Iter   600/ 1097] train: loss: 0.0076508
[Epoch 61; Iter   630/ 1097] train: loss: 0.0003329
[Epoch 61; Iter   660/ 1097] train: loss: 0.0010211
[Epoch 61; Iter   690/ 1097] train: loss: 0.0009504
[Epoch 61; Iter   720/ 1097] train: loss: 0.0000711
[Epoch 61; Iter   750/ 1097] train: loss: 0.0000473
[Epoch 61; Iter   780/ 1097] train: loss: 0.0025825
[Epoch 61; Iter   810/ 1097] train: loss: 0.0222849
[Epoch 61; Iter   840/ 1097] train: loss: 0.0002947
[Epoch 61; Iter   870/ 1097] train: loss: 0.0126887
[Epoch 61; Iter   900/ 1097] train: loss: 0.0049062
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000980
[Epoch 61; Iter   960/ 1097] train: loss: 0.0041152
[Epoch 61; Iter   990/ 1097] train: loss: 0.0007603
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0009122
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0003400
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0259348
[Epoch 61] ogbg-molhiv: 0.647955 val loss: 293.024454
[Epoch 61] ogbg-molhiv: 0.539667 test loss: 256.413319
[Epoch 62; Iter    13/ 1097] train: loss: 0.0088939
[Epoch 62; Iter    43/ 1097] train: loss: 0.0125436
[Epoch 62; Iter    73/ 1097] train: loss: 0.0013714
[Epoch 62; Iter   103/ 1097] train: loss: 0.1301192
[Epoch 62; Iter   133/ 1097] train: loss: 0.0006323
[Epoch 62; Iter   163/ 1097] train: loss: 0.0021697
[Epoch 62; Iter   193/ 1097] train: loss: 0.0000403
[Epoch 62; Iter   223/ 1097] train: loss: 0.0003744
[Epoch 62; Iter   253/ 1097] train: loss: 0.0000180
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000919
[Epoch 62; Iter   313/ 1097] train: loss: 0.0106719
[Epoch 62; Iter   343/ 1097] train: loss: 0.0255580
[Epoch 62; Iter   373/ 1097] train: loss: 0.0036721
[Epoch 62; Iter   403/ 1097] train: loss: 0.0002586
[Epoch 62; Iter   433/ 1097] train: loss: 0.0015796
[Epoch 62; Iter   463/ 1097] train: loss: 0.0053651
[Epoch 62; Iter   493/ 1097] train: loss: 0.0077436
[Epoch 62; Iter   523/ 1097] train: loss: 0.0002231
[Epoch 62; Iter   553/ 1097] train: loss: 0.0024303
[Epoch 62; Iter   583/ 1097] train: loss: 0.0013422
[Epoch 62; Iter   613/ 1097] train: loss: 0.0016687
[Epoch 62; Iter   643/ 1097] train: loss: 0.0019320
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000739
[Epoch 62; Iter   703/ 1097] train: loss: 0.0017848
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001445
[Epoch 62; Iter   763/ 1097] train: loss: 0.0007832
[Epoch 62; Iter   793/ 1097] train: loss: 0.0002208
[Epoch 62; Iter   823/ 1097] train: loss: 0.0005467
[Epoch 62; Iter   853/ 1097] train: loss: 0.0028200
[Epoch 62; Iter   883/ 1097] train: loss: 0.0038727
[Epoch 62; Iter   913/ 1097] train: loss: 0.0319293
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001109
[Epoch 62; Iter   973/ 1097] train: loss: 0.0000656
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0269900
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0021423
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0001709
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0036377
[Epoch 62] ogbg-molhiv: 0.635851 val loss: 245.948858
[Epoch 62] ogbg-molhiv: 0.559787 test loss: 207.139549
[Epoch 63; Iter    26/ 1097] train: loss: 0.0004868
[Epoch 63; Iter    56/ 1097] train: loss: 0.0766049
[Epoch 63; Iter    86/ 1097] train: loss: 0.0000304
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001551
[Epoch 63; Iter   146/ 1097] train: loss: 0.0003487
[Epoch 63; Iter   176/ 1097] train: loss: 0.0012800
[Epoch 63; Iter   206/ 1097] train: loss: 0.0016838
[Epoch 63; Iter   236/ 1097] train: loss: 0.0001754
[Epoch 63; Iter   266/ 1097] train: loss: 0.0001606
[Epoch 63; Iter   296/ 1097] train: loss: 0.0048603
[Epoch 63; Iter   326/ 1097] train: loss: 0.0118174
[Epoch 63; Iter   356/ 1097] train: loss: 0.0253176
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001244
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000327
[Epoch 63; Iter   446/ 1097] train: loss: 0.0057439
[Epoch 63; Iter   476/ 1097] train: loss: 0.0003459
[Epoch 63; Iter   506/ 1097] train: loss: 0.0000556
[Epoch 63; Iter   536/ 1097] train: loss: 0.0256801
[Epoch 63; Iter   566/ 1097] train: loss: 0.0244499
[Epoch 63; Iter   596/ 1097] train: loss: 0.0279326
[Epoch 63; Iter   626/ 1097] train: loss: 0.0003207
[Epoch 63; Iter   656/ 1097] train: loss: 0.0221120
[Epoch 63; Iter   686/ 1097] train: loss: 0.0005673
[Epoch 63; Iter   716/ 1097] train: loss: 0.0003552
[Epoch 63; Iter   746/ 1097] train: loss: 0.0003059
[Epoch 63; Iter   776/ 1097] train: loss: 0.0010636
[Epoch 63; Iter   806/ 1097] train: loss: 0.0010160
[Epoch 63; Iter   836/ 1097] train: loss: 0.0014984
[Epoch 63; Iter   866/ 1097] train: loss: 0.0147568
[Epoch 63; Iter   896/ 1097] train: loss: 0.0003477
[Epoch 63; Iter   926/ 1097] train: loss: 0.0056617
[Epoch 63; Iter   956/ 1097] train: loss: 0.0158326
[Epoch 63; Iter   986/ 1097] train: loss: 0.0002512
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004149
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0726336
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0002773
[Epoch 63] ogbg-molhiv: 0.640438 val loss: 110.360777
[Epoch 63] ogbg-molhiv: 0.562207 test loss: 104.842225
[Epoch 64; Iter     9/ 1097] train: loss: 0.0058025
[Epoch 64; Iter    39/ 1097] train: loss: 0.0000361
[Epoch 64; Iter    69/ 1097] train: loss: 0.0039808
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000240
[Epoch 64; Iter   129/ 1097] train: loss: 0.0001609
[Epoch 64; Iter   159/ 1097] train: loss: 0.0001018
[Epoch 64; Iter   189/ 1097] train: loss: 0.0001107
[Epoch 64; Iter   219/ 1097] train: loss: 0.0072185
[Epoch 64; Iter   249/ 1097] train: loss: 0.0004304
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000448
[Epoch 64; Iter   309/ 1097] train: loss: 0.0013352
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000338
[Epoch 64; Iter   369/ 1097] train: loss: 0.0107471
[Epoch 64; Iter   399/ 1097] train: loss: 0.0016517
[Epoch 64; Iter   429/ 1097] train: loss: 0.0037365
[Epoch 64; Iter   459/ 1097] train: loss: 0.0000184
[Epoch 64; Iter   489/ 1097] train: loss: 0.0003471
[Epoch 64; Iter   519/ 1097] train: loss: 0.0058583
[Epoch 64; Iter   549/ 1097] train: loss: 0.0001961
[Epoch 64; Iter   579/ 1097] train: loss: 0.0029937
[Epoch 64; Iter   609/ 1097] train: loss: 0.0006057
[Epoch 64; Iter   639/ 1097] train: loss: 0.0068171
[Epoch 64; Iter   669/ 1097] train: loss: 0.0003746
[Epoch 64; Iter   699/ 1097] train: loss: 0.0006891
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002158
[Epoch 64; Iter   759/ 1097] train: loss: 0.0002849
[Epoch 64; Iter   789/ 1097] train: loss: 0.0000207
[Epoch 64; Iter   819/ 1097] train: loss: 0.0066099
[Epoch 64; Iter   849/ 1097] train: loss: 0.0071001
[Epoch 64; Iter   879/ 1097] train: loss: 0.0004985
[Epoch 64; Iter   909/ 1097] train: loss: 0.0025770
[Epoch 64; Iter   939/ 1097] train: loss: 0.0029797
[Epoch 64; Iter   969/ 1097] train: loss: 0.0141887
[Epoch 64; Iter   999/ 1097] train: loss: 0.0361027
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0004291
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0000796
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0007862
[Epoch 64] ogbg-molhiv: 0.770867 val loss: 0.563279
[Epoch 64] ogbg-molhiv: 0.672844 test loss: 0.626775
[Epoch 65; Iter    22/ 1097] train: loss: 0.0458499
[Epoch 65; Iter    52/ 1097] train: loss: 0.0001414
[Epoch 65; Iter    82/ 1097] train: loss: 0.0017132
[Epoch 65; Iter   112/ 1097] train: loss: 0.0004679
[Epoch 65; Iter   142/ 1097] train: loss: 0.0005852
[Epoch 65; Iter   172/ 1097] train: loss: 0.0320824
[Epoch 65; Iter   202/ 1097] train: loss: 0.0015723
[Epoch 65; Iter   232/ 1097] train: loss: 0.0516097
[Epoch 65; Iter   262/ 1097] train: loss: 0.0056207
[Epoch 65; Iter   292/ 1097] train: loss: 0.0269901
[Epoch 65; Iter   322/ 1097] train: loss: 0.0117465
[Epoch 65; Iter   352/ 1097] train: loss: 0.0042934
[Epoch 65; Iter   382/ 1097] train: loss: 0.0250211
[Epoch 65; Iter   412/ 1097] train: loss: 0.0005199
[Epoch 65; Iter   442/ 1097] train: loss: 0.0002638
[Epoch 65; Iter   472/ 1097] train: loss: 0.0724705
[Epoch 65; Iter   502/ 1097] train: loss: 0.0098766
[Epoch 65; Iter   532/ 1097] train: loss: 0.0001271
[Epoch 65; Iter   562/ 1097] train: loss: 0.0116185
[Epoch 65; Iter   592/ 1097] train: loss: 0.0069169
[Epoch 65; Iter   622/ 1097] train: loss: 0.0008025
[Epoch 65; Iter   652/ 1097] train: loss: 0.0002172
[Epoch 65; Iter   682/ 1097] train: loss: 0.0001558
[Epoch 65; Iter   712/ 1097] train: loss: 0.0847249
[Epoch 65; Iter   742/ 1097] train: loss: 0.0013989
[Epoch 65; Iter   772/ 1097] train: loss: 0.0002419
[Epoch 65; Iter   802/ 1097] train: loss: 0.0752924
[Epoch 65; Iter   832/ 1097] train: loss: 0.0099174
[Epoch 65; Iter   862/ 1097] train: loss: 0.0059502
[Epoch 65; Iter   892/ 1097] train: loss: 0.0149567
[Epoch 65; Iter   922/ 1097] train: loss: 0.0131336
[Epoch 65; Iter   952/ 1097] train: loss: 0.0114648
[Epoch 65; Iter   982/ 1097] train: loss: 0.0062990
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0154117
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0005399
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0020089
[Epoch 65] ogbg-molhiv: 0.711306 val loss: 0.210244
[Epoch 65] ogbg-molhiv: 0.705238 test loss: 0.319400
[Epoch 66; Iter     5/ 1097] train: loss: 0.0078215
[Epoch 66; Iter    35/ 1097] train: loss: 0.0203636
[Epoch 66; Iter    65/ 1097] train: loss: 0.0011901
[Epoch 66; Iter    95/ 1097] train: loss: 0.0037182
[Epoch 66; Iter   125/ 1097] train: loss: 0.0009258
[Epoch 66; Iter   155/ 1097] train: loss: 0.0273324
[Epoch 66; Iter   185/ 1097] train: loss: 0.0018677
[Epoch 66; Iter   215/ 1097] train: loss: 0.0018146
[Epoch 66; Iter   245/ 1097] train: loss: 0.0075891
[Epoch 66; Iter   275/ 1097] train: loss: 0.0035610
[Epoch 66; Iter   305/ 1097] train: loss: 0.0058080
[Epoch 66; Iter   335/ 1097] train: loss: 0.0005462
[Epoch 66; Iter   365/ 1097] train: loss: 0.0295445
[Epoch 66; Iter   395/ 1097] train: loss: 0.0708682
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022615
[Epoch 66; Iter   455/ 1097] train: loss: 0.0031576
[Epoch 66; Iter   485/ 1097] train: loss: 0.0009473
[Epoch 66; Iter   515/ 1097] train: loss: 0.0001063
[Epoch 66; Iter   545/ 1097] train: loss: 0.0003098
[Epoch 66; Iter   575/ 1097] train: loss: 0.0021811
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000563
[Epoch 66; Iter   635/ 1097] train: loss: 0.0267272
[Epoch 66; Iter   665/ 1097] train: loss: 0.0050125
[Epoch 66; Iter   695/ 1097] train: loss: 0.0217094
[Epoch 66; Iter   725/ 1097] train: loss: 0.0211561
[Epoch 66; Iter   755/ 1097] train: loss: 0.0299390
[Epoch 66; Iter   785/ 1097] train: loss: 0.1398416
[Epoch 66; Iter   815/ 1097] train: loss: 0.0089880
[Epoch 66; Iter   845/ 1097] train: loss: 0.0013424
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000411
[Epoch 66; Iter   905/ 1097] train: loss: 0.0020190
[Epoch 66; Iter   935/ 1097] train: loss: 0.0023331
[Epoch 66; Iter   965/ 1097] train: loss: 0.1039859
[Epoch 66; Iter   995/ 1097] train: loss: 0.0001275
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0000616
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0000333
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0003521
[Epoch 66] ogbg-molhiv: 0.740701 val loss: 0.210285
[Epoch 66] ogbg-molhiv: 0.727069 test loss: 0.327778
[Epoch 67; Iter    18/ 1097] train: loss: 0.0011665
[Epoch 67; Iter    48/ 1097] train: loss: 0.0156937
[Epoch 67; Iter    78/ 1097] train: loss: 0.0060667
[Epoch 67; Iter   108/ 1097] train: loss: 0.0104810
[Epoch 67; Iter   138/ 1097] train: loss: 0.0061123
[Epoch 67; Iter   168/ 1097] train: loss: 0.0001030
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000232
[Epoch 67; Iter   228/ 1097] train: loss: 0.0025481
[Epoch 67; Iter   258/ 1097] train: loss: 0.0003120
[Epoch 67; Iter   288/ 1097] train: loss: 0.0032057
[Epoch 67; Iter   318/ 1097] train: loss: 0.0217312
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002696
[Epoch 67; Iter   378/ 1097] train: loss: 0.0026233
[Epoch 67; Iter   408/ 1097] train: loss: 0.0001173
[Epoch 67; Iter   438/ 1097] train: loss: 0.0000731
[Epoch 67; Iter   468/ 1097] train: loss: 0.0171757
[Epoch 67; Iter   498/ 1097] train: loss: 0.0139866
[Epoch 67; Iter   528/ 1097] train: loss: 0.0128909
[Epoch 67; Iter   558/ 1097] train: loss: 0.0001583
[Epoch 67; Iter   588/ 1097] train: loss: 0.0005100
[Epoch 67; Iter   618/ 1097] train: loss: 0.0109673
[Epoch 67; Iter   648/ 1097] train: loss: 0.0008834
[Epoch 67; Iter   678/ 1097] train: loss: 0.0023118
[Epoch 67; Iter   708/ 1097] train: loss: 0.0012901
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000316
[Epoch 67; Iter   768/ 1097] train: loss: 0.0007318
[Epoch 67; Iter   798/ 1097] train: loss: 0.0002688
[Epoch 67; Iter   828/ 1097] train: loss: 0.0356493
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004385
[Epoch 67; Iter   888/ 1097] train: loss: 0.0003713
[Epoch 67; Iter   918/ 1097] train: loss: 0.0026683
[Epoch 67; Iter   948/ 1097] train: loss: 0.0002096
[Epoch 67; Iter   978/ 1097] train: loss: 0.0001897
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0008662
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013424
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000681
[Epoch 67] ogbg-molhiv: 0.721166 val loss: 1.360581
[Epoch 67] ogbg-molhiv: 0.702513 test loss: 1.106982
[Epoch 68; Iter     1/ 1097] train: loss: 0.0096381
[Epoch 68; Iter    31/ 1097] train: loss: 0.0263228
[Epoch 68; Iter    61/ 1097] train: loss: 0.0011344
[Epoch 68; Iter    91/ 1097] train: loss: 0.0041466
[Epoch 68; Iter   121/ 1097] train: loss: 0.0084354
[Epoch 68; Iter   151/ 1097] train: loss: 0.0041448
[Epoch 68; Iter   181/ 1097] train: loss: 0.0028243
[Epoch 68; Iter   211/ 1097] train: loss: 0.0300024
[Epoch 68; Iter   241/ 1097] train: loss: 0.0016289
[Epoch 68; Iter   271/ 1097] train: loss: 0.0024348
[Epoch 68; Iter   301/ 1097] train: loss: 0.0017898
[Epoch 68; Iter   331/ 1097] train: loss: 0.0002593
[Epoch 68; Iter   361/ 1097] train: loss: 0.0023316
[Epoch 68; Iter   391/ 1097] train: loss: 0.0010838
[Epoch 68; Iter   421/ 1097] train: loss: 0.0000714
[Epoch 68; Iter   451/ 1097] train: loss: 0.0009877
[Epoch 68; Iter   481/ 1097] train: loss: 0.0003191
[Epoch 68; Iter   511/ 1097] train: loss: 0.0022090
[Epoch 68; Iter   541/ 1097] train: loss: 0.0001189
[Epoch 68; Iter   571/ 1097] train: loss: 0.0021806
[Epoch 68; Iter   601/ 1097] train: loss: 0.0093891
[Epoch 68; Iter   631/ 1097] train: loss: 0.0000297
[Epoch 68; Iter   661/ 1097] train: loss: 0.0037229
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000473
[Epoch 68; Iter   721/ 1097] train: loss: 0.0079535
[Epoch 68; Iter   751/ 1097] train: loss: 0.0006010
[Epoch 68; Iter   781/ 1097] train: loss: 0.0002445
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001593
[Epoch 68; Iter   841/ 1097] train: loss: 0.0022489
[Epoch 68; Iter   871/ 1097] train: loss: 0.0009986
[Epoch 68; Iter   901/ 1097] train: loss: 0.0158628
[Epoch 68; Iter   931/ 1097] train: loss: 0.0001045
[Epoch 68; Iter   961/ 1097] train: loss: 0.0183131
[Epoch 68; Iter   991/ 1097] train: loss: 0.0033863
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0004971
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0012450
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0004039
[Epoch 68] ogbg-molhiv: 0.778898 val loss: 0.861659
[Epoch 68] ogbg-molhiv: 0.680484 test loss: 1.154759
[Epoch 69; Iter    14/ 1097] train: loss: 0.0001578
[Epoch 69; Iter    44/ 1097] train: loss: 0.0298883
[Epoch 69; Iter    74/ 1097] train: loss: 0.0012194
[Epoch 65; Iter    22/ 1097] train: loss: 0.0000970
[Epoch 65; Iter    52/ 1097] train: loss: 0.0003434
[Epoch 65; Iter    82/ 1097] train: loss: 0.0001835
[Epoch 65; Iter   112/ 1097] train: loss: 0.0000419
[Epoch 65; Iter   142/ 1097] train: loss: 0.0006100
[Epoch 65; Iter   172/ 1097] train: loss: 0.0002770
[Epoch 65; Iter   202/ 1097] train: loss: 0.0001106
[Epoch 65; Iter   232/ 1097] train: loss: 0.0020679
[Epoch 65; Iter   262/ 1097] train: loss: 0.0000133
[Epoch 65; Iter   292/ 1097] train: loss: 0.0002288
[Epoch 65; Iter   322/ 1097] train: loss: 0.0001840
[Epoch 65; Iter   352/ 1097] train: loss: 0.0002086
[Epoch 65; Iter   382/ 1097] train: loss: 0.0023528
[Epoch 65; Iter   412/ 1097] train: loss: 0.0246181
[Epoch 65; Iter   442/ 1097] train: loss: 0.0009464
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000452
[Epoch 65; Iter   502/ 1097] train: loss: 0.0001038
[Epoch 65; Iter   532/ 1097] train: loss: 0.0002319
[Epoch 65; Iter   562/ 1097] train: loss: 0.0000931
[Epoch 65; Iter   592/ 1097] train: loss: 0.0003388
[Epoch 65; Iter   622/ 1097] train: loss: 0.0053736
[Epoch 65; Iter   652/ 1097] train: loss: 0.0005569
[Epoch 65; Iter   682/ 1097] train: loss: 0.0014046
[Epoch 65; Iter   712/ 1097] train: loss: 0.0001418
[Epoch 65; Iter   742/ 1097] train: loss: 0.0000738
[Epoch 65; Iter   772/ 1097] train: loss: 0.0007091
[Epoch 65; Iter   802/ 1097] train: loss: 0.0004094
[Epoch 65; Iter   832/ 1097] train: loss: 0.0077106
[Epoch 65; Iter   862/ 1097] train: loss: 0.0011573
[Epoch 65; Iter   892/ 1097] train: loss: 0.0011327
[Epoch 65; Iter   922/ 1097] train: loss: 0.0010465
[Epoch 65; Iter   952/ 1097] train: loss: 0.0008652
[Epoch 65; Iter   982/ 1097] train: loss: 0.0003924
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0017211
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0002751
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0016761
[Epoch 65] ogbg-molhiv: 0.756571 val loss: 0.224727
[Epoch 65] ogbg-molhiv: 0.713623 test loss: 0.330349
[Epoch 66; Iter     5/ 1097] train: loss: 0.0000316
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001819
[Epoch 66; Iter    65/ 1097] train: loss: 0.0010457
[Epoch 66; Iter    95/ 1097] train: loss: 0.0006894
[Epoch 66; Iter   125/ 1097] train: loss: 0.0053776
[Epoch 66; Iter   155/ 1097] train: loss: 0.0004512
[Epoch 66; Iter   185/ 1097] train: loss: 0.0033797
[Epoch 66; Iter   215/ 1097] train: loss: 0.0001821
[Epoch 66; Iter   245/ 1097] train: loss: 0.0016869
[Epoch 66; Iter   275/ 1097] train: loss: 0.0001603
[Epoch 66; Iter   305/ 1097] train: loss: 0.0039081
[Epoch 66; Iter   335/ 1097] train: loss: 0.0043374
[Epoch 66; Iter   365/ 1097] train: loss: 0.0003445
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002546
[Epoch 66; Iter   425/ 1097] train: loss: 0.0006111
[Epoch 66; Iter   455/ 1097] train: loss: 0.0023967
[Epoch 66; Iter   485/ 1097] train: loss: 0.0232202
[Epoch 66; Iter   515/ 1097] train: loss: 0.0002058
[Epoch 66; Iter   545/ 1097] train: loss: 0.0000920
[Epoch 66; Iter   575/ 1097] train: loss: 0.0011007
[Epoch 66; Iter   605/ 1097] train: loss: 0.0008745
[Epoch 66; Iter   635/ 1097] train: loss: 0.0049825
[Epoch 66; Iter   665/ 1097] train: loss: 0.0004526
[Epoch 66; Iter   695/ 1097] train: loss: 0.0032351
[Epoch 66; Iter   725/ 1097] train: loss: 0.0000604
[Epoch 66; Iter   755/ 1097] train: loss: 0.0000465
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000479
[Epoch 66; Iter   815/ 1097] train: loss: 0.0011926
[Epoch 66; Iter   845/ 1097] train: loss: 0.0000938
[Epoch 66; Iter   875/ 1097] train: loss: 0.0002634
[Epoch 66; Iter   905/ 1097] train: loss: 0.0001237
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001101
[Epoch 66; Iter   965/ 1097] train: loss: 0.0137203
[Epoch 66; Iter   995/ 1097] train: loss: 0.0184217
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0020627
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0000819
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0012577
[Epoch 66] ogbg-molhiv: 0.737709 val loss: 0.223274
[Epoch 66] ogbg-molhiv: 0.730008 test loss: 0.319835
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000219
[Epoch 67; Iter    48/ 1097] train: loss: 0.0009639
[Epoch 67; Iter    78/ 1097] train: loss: 0.0006599
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003301
[Epoch 67; Iter   138/ 1097] train: loss: 0.0001919
[Epoch 67; Iter   168/ 1097] train: loss: 0.0050429
[Epoch 67; Iter   198/ 1097] train: loss: 0.0010158
[Epoch 67; Iter   228/ 1097] train: loss: 0.0003312
[Epoch 67; Iter   258/ 1097] train: loss: 0.0004154
[Epoch 67; Iter   288/ 1097] train: loss: 0.0002091
[Epoch 67; Iter   318/ 1097] train: loss: 0.0032985
[Epoch 67; Iter   348/ 1097] train: loss: 0.0003539
[Epoch 67; Iter   378/ 1097] train: loss: 0.0000449
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000330
[Epoch 67; Iter   438/ 1097] train: loss: 0.0141462
[Epoch 67; Iter   468/ 1097] train: loss: 0.0000529
[Epoch 67; Iter   498/ 1097] train: loss: 0.0006391
[Epoch 67; Iter   528/ 1097] train: loss: 0.0016518
[Epoch 67; Iter   558/ 1097] train: loss: 0.0001110
[Epoch 67; Iter   588/ 1097] train: loss: 0.0020235
[Epoch 67; Iter   618/ 1097] train: loss: 0.0275111
[Epoch 67; Iter   648/ 1097] train: loss: 0.0035043
[Epoch 67; Iter   678/ 1097] train: loss: 0.0001606
[Epoch 67; Iter   708/ 1097] train: loss: 0.0054734
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000548
[Epoch 67; Iter   768/ 1097] train: loss: 0.0001531
[Epoch 67; Iter   798/ 1097] train: loss: 0.0000409
[Epoch 67; Iter   828/ 1097] train: loss: 0.0003972
[Epoch 67; Iter   858/ 1097] train: loss: 0.0097009
[Epoch 67; Iter   888/ 1097] train: loss: 0.0001065
[Epoch 67; Iter   918/ 1097] train: loss: 0.0001804
[Epoch 67; Iter   948/ 1097] train: loss: 0.0003261
[Epoch 67; Iter   978/ 1097] train: loss: 0.0005422
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0010367
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013956
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001173
[Epoch 67] ogbg-molhiv: 0.790920 val loss: 0.241966
[Epoch 67] ogbg-molhiv: 0.724746 test loss: 0.339259
[Epoch 68; Iter     1/ 1097] train: loss: 0.0170525
[Epoch 68; Iter    31/ 1097] train: loss: 0.0000716
[Epoch 68; Iter    61/ 1097] train: loss: 0.0007431
[Epoch 68; Iter    91/ 1097] train: loss: 0.0019586
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000291
[Epoch 68; Iter   151/ 1097] train: loss: 0.0060844
[Epoch 68; Iter   181/ 1097] train: loss: 0.0010048
[Epoch 68; Iter   211/ 1097] train: loss: 0.0000433
[Epoch 68; Iter   241/ 1097] train: loss: 0.0003467
[Epoch 68; Iter   271/ 1097] train: loss: 0.0003853
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000821
[Epoch 68; Iter   331/ 1097] train: loss: 0.0000278
[Epoch 68; Iter   361/ 1097] train: loss: 0.0011798
[Epoch 68; Iter   391/ 1097] train: loss: 0.0006749
[Epoch 68; Iter   421/ 1097] train: loss: 0.0010477
[Epoch 68; Iter   451/ 1097] train: loss: 0.0031421
[Epoch 68; Iter   481/ 1097] train: loss: 0.0000368
[Epoch 68; Iter   511/ 1097] train: loss: 0.0037974
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000563
[Epoch 68; Iter   571/ 1097] train: loss: 0.0000702
[Epoch 68; Iter   601/ 1097] train: loss: 0.0001101
[Epoch 68; Iter   631/ 1097] train: loss: 0.0001409
[Epoch 68; Iter   661/ 1097] train: loss: 0.0001015
[Epoch 68; Iter   691/ 1097] train: loss: 0.0026809
[Epoch 68; Iter   721/ 1097] train: loss: 0.0003301
[Epoch 68; Iter   751/ 1097] train: loss: 0.0487157
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000274
[Epoch 68; Iter   811/ 1097] train: loss: 0.0007827
[Epoch 68; Iter   841/ 1097] train: loss: 0.0135703
[Epoch 68; Iter   871/ 1097] train: loss: 0.0026055
[Epoch 68; Iter   901/ 1097] train: loss: 0.0007480
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000291
[Epoch 68; Iter   961/ 1097] train: loss: 0.0013154
[Epoch 68; Iter   991/ 1097] train: loss: 0.0220227
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0000627
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0001437
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0000798
[Epoch 68] ogbg-molhiv: 0.752638 val loss: 0.206130
[Epoch 68] ogbg-molhiv: 0.709033 test loss: 0.332724
[Epoch 69; Iter    14/ 1097] train: loss: 0.0029830
[Epoch 69; Iter    44/ 1097] train: loss: 0.0000084
[Epoch 69; Iter    74/ 1097] train: loss: 0.0007535
[Epoch 65; Iter    22/ 1097] train: loss: 0.0470107
[Epoch 65; Iter    52/ 1097] train: loss: 0.0006282
[Epoch 65; Iter    82/ 1097] train: loss: 0.1435570
[Epoch 65; Iter   112/ 1097] train: loss: 0.0022975
[Epoch 65; Iter   142/ 1097] train: loss: 0.0002128
[Epoch 65; Iter   172/ 1097] train: loss: 0.0095999
[Epoch 65; Iter   202/ 1097] train: loss: 0.0006600
[Epoch 65; Iter   232/ 1097] train: loss: 0.0470379
[Epoch 65; Iter   262/ 1097] train: loss: 0.0259030
[Epoch 65; Iter   292/ 1097] train: loss: 0.0084162
[Epoch 65; Iter   322/ 1097] train: loss: 0.0397477
[Epoch 65; Iter   352/ 1097] train: loss: 0.2309143
[Epoch 65; Iter   382/ 1097] train: loss: 0.0014246
[Epoch 65; Iter   412/ 1097] train: loss: 0.0619738
[Epoch 65; Iter   442/ 1097] train: loss: 0.0299858
[Epoch 65; Iter   472/ 1097] train: loss: 0.0104850
[Epoch 65; Iter   502/ 1097] train: loss: 0.0440871
[Epoch 65; Iter   532/ 1097] train: loss: 0.0021510
[Epoch 65; Iter   562/ 1097] train: loss: 0.0121871
[Epoch 65; Iter   592/ 1097] train: loss: 0.0004390
[Epoch 65; Iter   622/ 1097] train: loss: 0.0000711
[Epoch 65; Iter   652/ 1097] train: loss: 0.0057457
[Epoch 65; Iter   682/ 1097] train: loss: 0.0010046
[Epoch 65; Iter   712/ 1097] train: loss: 0.0038300
[Epoch 65; Iter   742/ 1097] train: loss: 0.0027048
[Epoch 65; Iter   772/ 1097] train: loss: 0.0210134
[Epoch 65; Iter   802/ 1097] train: loss: 0.0139738
[Epoch 65; Iter   832/ 1097] train: loss: 0.1747053
[Epoch 65; Iter   862/ 1097] train: loss: 0.0088429
[Epoch 65; Iter   892/ 1097] train: loss: 0.0067614
[Epoch 65; Iter   922/ 1097] train: loss: 0.0001282
[Epoch 65; Iter   952/ 1097] train: loss: 0.0026852
[Epoch 65; Iter   982/ 1097] train: loss: 0.0047266
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0239170
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0003201
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0020509
[Epoch 65] ogbg-molhiv: 0.702999 val loss: 5.432815
[Epoch 65] ogbg-molhiv: 0.715070 test loss: 1.704674
[Epoch 66; Iter     5/ 1097] train: loss: 0.0112011
[Epoch 66; Iter    35/ 1097] train: loss: 0.0003513
[Epoch 66; Iter    65/ 1097] train: loss: 0.0086806
[Epoch 66; Iter    95/ 1097] train: loss: 0.0072638
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003073
[Epoch 66; Iter   155/ 1097] train: loss: 0.0009676
[Epoch 66; Iter   185/ 1097] train: loss: 0.0151729
[Epoch 66; Iter   215/ 1097] train: loss: 0.0006797
[Epoch 66; Iter   245/ 1097] train: loss: 0.0040406
[Epoch 66; Iter   275/ 1097] train: loss: 0.0001335
[Epoch 66; Iter   305/ 1097] train: loss: 0.0004673
[Epoch 66; Iter   335/ 1097] train: loss: 0.0318179
[Epoch 66; Iter   365/ 1097] train: loss: 0.0431712
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002483
[Epoch 66; Iter   425/ 1097] train: loss: 0.0037656
[Epoch 66; Iter   455/ 1097] train: loss: 0.1346431
[Epoch 66; Iter   485/ 1097] train: loss: 0.0126779
[Epoch 66; Iter   515/ 1097] train: loss: 0.0390965
[Epoch 66; Iter   545/ 1097] train: loss: 0.0002533
[Epoch 66; Iter   575/ 1097] train: loss: 0.0021513
[Epoch 66; Iter   605/ 1097] train: loss: 0.0009815
[Epoch 66; Iter   635/ 1097] train: loss: 0.0002062
[Epoch 66; Iter   665/ 1097] train: loss: 0.0086270
[Epoch 66; Iter   695/ 1097] train: loss: 0.0002002
[Epoch 66; Iter   725/ 1097] train: loss: 0.0033026
[Epoch 66; Iter   755/ 1097] train: loss: 0.0008380
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000734
[Epoch 66; Iter   815/ 1097] train: loss: 0.0553874
[Epoch 66; Iter   845/ 1097] train: loss: 0.0004112
[Epoch 66; Iter   875/ 1097] train: loss: 0.0005774
[Epoch 66; Iter   905/ 1097] train: loss: 0.0012046
[Epoch 66; Iter   935/ 1097] train: loss: 0.0012557
[Epoch 66; Iter   965/ 1097] train: loss: 0.0010904
[Epoch 66; Iter   995/ 1097] train: loss: 0.0025643
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0021599
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0025511
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0028518
[Epoch 66] ogbg-molhiv: 0.699438 val loss: 8.497340
[Epoch 66] ogbg-molhiv: 0.717783 test loss: 2.185959
[Epoch 67; Iter    18/ 1097] train: loss: 0.0005717
[Epoch 67; Iter    48/ 1097] train: loss: 0.0012591
[Epoch 67; Iter    78/ 1097] train: loss: 0.0002442
[Epoch 67; Iter   108/ 1097] train: loss: 0.0745981
[Epoch 67; Iter   138/ 1097] train: loss: 0.0148298
[Epoch 67; Iter   168/ 1097] train: loss: 0.0176930
[Epoch 67; Iter   198/ 1097] train: loss: 0.0008566
[Epoch 67; Iter   228/ 1097] train: loss: 0.0251000
[Epoch 67; Iter   258/ 1097] train: loss: 0.0079865
[Epoch 67; Iter   288/ 1097] train: loss: 0.0017978
[Epoch 67; Iter   318/ 1097] train: loss: 0.0023910
[Epoch 67; Iter   348/ 1097] train: loss: 0.0548686
[Epoch 67; Iter   378/ 1097] train: loss: 0.0056236
[Epoch 67; Iter   408/ 1097] train: loss: 0.0068864
[Epoch 67; Iter   438/ 1097] train: loss: 0.0001847
[Epoch 67; Iter   468/ 1097] train: loss: 0.0207791
[Epoch 67; Iter   498/ 1097] train: loss: 0.0067579
[Epoch 67; Iter   528/ 1097] train: loss: 0.0026428
[Epoch 67; Iter   558/ 1097] train: loss: 0.0061373
[Epoch 67; Iter   588/ 1097] train: loss: 0.0009199
[Epoch 67; Iter   618/ 1097] train: loss: 0.0830637
[Epoch 67; Iter   648/ 1097] train: loss: 0.0226444
[Epoch 67; Iter   678/ 1097] train: loss: 0.0135663
[Epoch 67; Iter   708/ 1097] train: loss: 0.0014255
[Epoch 67; Iter   738/ 1097] train: loss: 0.0021335
[Epoch 67; Iter   768/ 1097] train: loss: 0.0093593
[Epoch 67; Iter   798/ 1097] train: loss: 0.0006395
[Epoch 67; Iter   828/ 1097] train: loss: 0.0035098
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004241
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000895
[Epoch 67; Iter   918/ 1097] train: loss: 0.0120399
[Epoch 67; Iter   948/ 1097] train: loss: 0.0005854
[Epoch 67; Iter   978/ 1097] train: loss: 0.0172572
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0024584
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0113914
[Epoch 67; Iter  1068/ 1097] train: loss: 0.1355211
[Epoch 67] ogbg-molhiv: 0.738132 val loss: 2.211960
[Epoch 67] ogbg-molhiv: 0.697312 test loss: 0.755871
[Epoch 68; Iter     1/ 1097] train: loss: 0.0838592
[Epoch 68; Iter    31/ 1097] train: loss: 0.0037387
[Epoch 68; Iter    61/ 1097] train: loss: 0.0389138
[Epoch 68; Iter    91/ 1097] train: loss: 0.0065893
[Epoch 68; Iter   121/ 1097] train: loss: 0.0009492
[Epoch 68; Iter   151/ 1097] train: loss: 0.0046475
[Epoch 68; Iter   181/ 1097] train: loss: 0.0075202
[Epoch 68; Iter   211/ 1097] train: loss: 0.0002730
[Epoch 68; Iter   241/ 1097] train: loss: 0.0098977
[Epoch 68; Iter   271/ 1097] train: loss: 0.0004715
[Epoch 68; Iter   301/ 1097] train: loss: 0.0673547
[Epoch 68; Iter   331/ 1097] train: loss: 0.0011097
[Epoch 68; Iter   361/ 1097] train: loss: 0.0041963
[Epoch 68; Iter   391/ 1097] train: loss: 0.0003094
[Epoch 68; Iter   421/ 1097] train: loss: 0.1058811
[Epoch 68; Iter   451/ 1097] train: loss: 0.0372355
[Epoch 68; Iter   481/ 1097] train: loss: 0.0050142
[Epoch 68; Iter   511/ 1097] train: loss: 0.0016367
[Epoch 68; Iter   541/ 1097] train: loss: 0.0081063
[Epoch 68; Iter   571/ 1097] train: loss: 0.0002268
[Epoch 68; Iter   601/ 1097] train: loss: 0.0008602
[Epoch 68; Iter   631/ 1097] train: loss: 0.0888578
[Epoch 68; Iter   661/ 1097] train: loss: 0.0191590
[Epoch 68; Iter   691/ 1097] train: loss: 0.0037719
[Epoch 68; Iter   721/ 1097] train: loss: 0.0008406
[Epoch 68; Iter   751/ 1097] train: loss: 0.0083663
[Epoch 68; Iter   781/ 1097] train: loss: 0.0001000
[Epoch 68; Iter   811/ 1097] train: loss: 0.0138201
[Epoch 68; Iter   841/ 1097] train: loss: 0.0143262
[Epoch 68; Iter   871/ 1097] train: loss: 0.0207979
[Epoch 68; Iter   901/ 1097] train: loss: 0.0003152
[Epoch 68; Iter   931/ 1097] train: loss: 0.0008096
[Epoch 68; Iter   961/ 1097] train: loss: 0.0023000
[Epoch 68; Iter   991/ 1097] train: loss: 0.0025458
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0029290
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003228
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0002797
[Epoch 68] ogbg-molhiv: 0.706089 val loss: 9.345147
[Epoch 68] ogbg-molhiv: 0.690834 test loss: 2.764074
[Epoch 69; Iter    14/ 1097] train: loss: 0.0053543
[Epoch 69; Iter    44/ 1097] train: loss: 0.0002877
[Epoch 69; Iter    74/ 1097] train: loss: 0.0000567
[Epoch 65; Iter    22/ 1097] train: loss: 0.0000492
[Epoch 65; Iter    52/ 1097] train: loss: 0.0009570
[Epoch 65; Iter    82/ 1097] train: loss: 0.0002935
[Epoch 65; Iter   112/ 1097] train: loss: 0.0004635
[Epoch 65; Iter   142/ 1097] train: loss: 0.0010622
[Epoch 65; Iter   172/ 1097] train: loss: 0.0000786
[Epoch 65; Iter   202/ 1097] train: loss: 0.0044144
[Epoch 65; Iter   232/ 1097] train: loss: 0.0011320
[Epoch 65; Iter   262/ 1097] train: loss: 0.0001728
[Epoch 65; Iter   292/ 1097] train: loss: 0.0000669
[Epoch 65; Iter   322/ 1097] train: loss: 0.0014805
[Epoch 65; Iter   352/ 1097] train: loss: 0.0005851
[Epoch 65; Iter   382/ 1097] train: loss: 0.0000170
[Epoch 65; Iter   412/ 1097] train: loss: 0.0002951
[Epoch 65; Iter   442/ 1097] train: loss: 0.0001237
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000239
[Epoch 65; Iter   502/ 1097] train: loss: 0.0033081
[Epoch 65; Iter   532/ 1097] train: loss: 0.0006690
[Epoch 65; Iter   562/ 1097] train: loss: 0.0006080
[Epoch 65; Iter   592/ 1097] train: loss: 0.0002202
[Epoch 65; Iter   622/ 1097] train: loss: 0.0010132
[Epoch 65; Iter   652/ 1097] train: loss: 0.0020506
[Epoch 65; Iter   682/ 1097] train: loss: 0.0002735
[Epoch 65; Iter   712/ 1097] train: loss: 0.0011484
[Epoch 65; Iter   742/ 1097] train: loss: 0.0025907
[Epoch 65; Iter   772/ 1097] train: loss: 0.0022459
[Epoch 65; Iter   802/ 1097] train: loss: 0.0001170
[Epoch 65; Iter   832/ 1097] train: loss: 0.0001500
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001911
[Epoch 65; Iter   892/ 1097] train: loss: 0.0001206
[Epoch 65; Iter   922/ 1097] train: loss: 0.0023544
[Epoch 65; Iter   952/ 1097] train: loss: 0.0171173
[Epoch 65; Iter   982/ 1097] train: loss: 0.0240842
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0008188
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0012253
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0034001
[Epoch 65] ogbg-molhiv: 0.762453 val loss: 0.318902
[Epoch 65] ogbg-molhiv: 0.753869 test loss: 0.318466
[Epoch 66; Iter     5/ 1097] train: loss: 0.0010636
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001206
[Epoch 66; Iter    65/ 1097] train: loss: 0.0002309
[Epoch 66; Iter    95/ 1097] train: loss: 0.0001860
[Epoch 66; Iter   125/ 1097] train: loss: 0.0014813
[Epoch 66; Iter   155/ 1097] train: loss: 0.0613579
[Epoch 66; Iter   185/ 1097] train: loss: 0.0012067
[Epoch 66; Iter   215/ 1097] train: loss: 0.0018905
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000616
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000621
[Epoch 66; Iter   305/ 1097] train: loss: 0.0001132
[Epoch 66; Iter   335/ 1097] train: loss: 0.0004249
[Epoch 66; Iter   365/ 1097] train: loss: 0.0000970
[Epoch 66; Iter   395/ 1097] train: loss: 0.0039090
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022481
[Epoch 66; Iter   455/ 1097] train: loss: 0.0062502
[Epoch 66; Iter   485/ 1097] train: loss: 0.0000467
[Epoch 66; Iter   515/ 1097] train: loss: 0.0014947
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001248
[Epoch 66; Iter   575/ 1097] train: loss: 0.0009787
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000370
[Epoch 66; Iter   635/ 1097] train: loss: 0.0001118
[Epoch 66; Iter   665/ 1097] train: loss: 0.0000164
[Epoch 66; Iter   695/ 1097] train: loss: 0.0001520
[Epoch 66; Iter   725/ 1097] train: loss: 0.0045892
[Epoch 66; Iter   755/ 1097] train: loss: 0.0003500
[Epoch 66; Iter   785/ 1097] train: loss: 0.0032922
[Epoch 66; Iter   815/ 1097] train: loss: 0.0162748
[Epoch 66; Iter   845/ 1097] train: loss: 0.0120124
[Epoch 66; Iter   875/ 1097] train: loss: 0.0219260
[Epoch 66; Iter   905/ 1097] train: loss: 0.0000450
[Epoch 66; Iter   935/ 1097] train: loss: 0.0002197
[Epoch 66; Iter   965/ 1097] train: loss: 0.0013709
[Epoch 66; Iter   995/ 1097] train: loss: 0.0008000
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0009843
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0061559
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0149067
[Epoch 66] ogbg-molhiv: 0.752832 val loss: 0.296899
[Epoch 66] ogbg-molhiv: 0.755974 test loss: 0.292253
[Epoch 67; Iter    18/ 1097] train: loss: 0.0001443
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000120
[Epoch 67; Iter    78/ 1097] train: loss: 0.0000938
[Epoch 67; Iter   108/ 1097] train: loss: 0.0019682
[Epoch 67; Iter   138/ 1097] train: loss: 0.0001323
[Epoch 67; Iter   168/ 1097] train: loss: 0.0546193
[Epoch 67; Iter   198/ 1097] train: loss: 0.0491535
[Epoch 67; Iter   228/ 1097] train: loss: 0.0000421
[Epoch 67; Iter   258/ 1097] train: loss: 0.0000125
[Epoch 67; Iter   288/ 1097] train: loss: 0.0174621
[Epoch 67; Iter   318/ 1097] train: loss: 0.0080734
[Epoch 67; Iter   348/ 1097] train: loss: 0.0007331
[Epoch 67; Iter   378/ 1097] train: loss: 0.0021186
[Epoch 67; Iter   408/ 1097] train: loss: 0.0104353
[Epoch 67; Iter   438/ 1097] train: loss: 0.0015467
[Epoch 67; Iter   468/ 1097] train: loss: 0.0010065
[Epoch 67; Iter   498/ 1097] train: loss: 0.0203940
[Epoch 67; Iter   528/ 1097] train: loss: 0.0051172
[Epoch 67; Iter   558/ 1097] train: loss: 0.0002251
[Epoch 67; Iter   588/ 1097] train: loss: 0.0005095
[Epoch 67; Iter   618/ 1097] train: loss: 0.0031743
[Epoch 67; Iter   648/ 1097] train: loss: 0.0002126
[Epoch 67; Iter   678/ 1097] train: loss: 0.0003284
[Epoch 67; Iter   708/ 1097] train: loss: 0.0006847
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000867
[Epoch 67; Iter   768/ 1097] train: loss: 0.0000176
[Epoch 67; Iter   798/ 1097] train: loss: 0.0033798
[Epoch 67; Iter   828/ 1097] train: loss: 0.0025728
[Epoch 67; Iter   858/ 1097] train: loss: 0.0028816
[Epoch 67; Iter   888/ 1097] train: loss: 0.0007726
[Epoch 67; Iter   918/ 1097] train: loss: 0.0000677
[Epoch 67; Iter   948/ 1097] train: loss: 0.0071209
[Epoch 67; Iter   978/ 1097] train: loss: 0.0006741
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0006008
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000270
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001918
[Epoch 67] ogbg-molhiv: 0.756053 val loss: 0.298884
[Epoch 67] ogbg-molhiv: 0.758425 test loss: 0.306313
[Epoch 68; Iter     1/ 1097] train: loss: 0.0047599
[Epoch 68; Iter    31/ 1097] train: loss: 0.0002378
[Epoch 68; Iter    61/ 1097] train: loss: 0.0105043
[Epoch 68; Iter    91/ 1097] train: loss: 0.0005623
[Epoch 68; Iter   121/ 1097] train: loss: 0.0001260
[Epoch 68; Iter   151/ 1097] train: loss: 0.0003281
[Epoch 68; Iter   181/ 1097] train: loss: 0.0008573
[Epoch 68; Iter   211/ 1097] train: loss: 0.0004565
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002200
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000967
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000368
[Epoch 68; Iter   331/ 1097] train: loss: 0.0001243
[Epoch 68; Iter   361/ 1097] train: loss: 0.0051804
[Epoch 68; Iter   391/ 1097] train: loss: 0.0064077
[Epoch 68; Iter   421/ 1097] train: loss: 0.0370611
[Epoch 68; Iter   451/ 1097] train: loss: 0.0000610
[Epoch 68; Iter   481/ 1097] train: loss: 0.0004427
[Epoch 68; Iter   511/ 1097] train: loss: 0.0171676
[Epoch 68; Iter   541/ 1097] train: loss: 0.0034634
[Epoch 68; Iter   571/ 1097] train: loss: 0.0105023
[Epoch 68; Iter   601/ 1097] train: loss: 0.0217570
[Epoch 68; Iter   631/ 1097] train: loss: 0.0207619
[Epoch 68; Iter   661/ 1097] train: loss: 0.0004625
[Epoch 68; Iter   691/ 1097] train: loss: 0.0002011
[Epoch 68; Iter   721/ 1097] train: loss: 0.0801122
[Epoch 68; Iter   751/ 1097] train: loss: 0.0001333
[Epoch 68; Iter   781/ 1097] train: loss: 0.0020628
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001935
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000745
[Epoch 68; Iter   871/ 1097] train: loss: 0.0114615
[Epoch 68; Iter   901/ 1097] train: loss: 0.0004145
[Epoch 68; Iter   931/ 1097] train: loss: 0.0006316
[Epoch 68; Iter   961/ 1097] train: loss: 0.0034835
[Epoch 68; Iter   991/ 1097] train: loss: 0.0002500
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0002647
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0011778
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0009531
[Epoch 68] ogbg-molhiv: 0.765046 val loss: 0.340312
[Epoch 68] ogbg-molhiv: 0.729054 test loss: 0.326092
[Epoch 69; Iter    14/ 1097] train: loss: 0.0577969
[Epoch 69; Iter    44/ 1097] train: loss: 0.0027400
[Epoch 69; Iter    74/ 1097] train: loss: 0.0003513
[Epoch 65; Iter    22/ 1097] train: loss: 0.0063051
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000710
[Epoch 65; Iter    82/ 1097] train: loss: 0.0007818
[Epoch 65; Iter   112/ 1097] train: loss: 0.0005497
[Epoch 65; Iter   142/ 1097] train: loss: 0.0001036
[Epoch 65; Iter   172/ 1097] train: loss: 0.0119044
[Epoch 65; Iter   202/ 1097] train: loss: 0.0075548
[Epoch 65; Iter   232/ 1097] train: loss: 0.0000231
[Epoch 65; Iter   262/ 1097] train: loss: 0.0000803
[Epoch 65; Iter   292/ 1097] train: loss: 0.0007070
[Epoch 65; Iter   322/ 1097] train: loss: 0.0063854
[Epoch 65; Iter   352/ 1097] train: loss: 0.0018846
[Epoch 65; Iter   382/ 1097] train: loss: 0.0014824
[Epoch 65; Iter   412/ 1097] train: loss: 0.0000442
[Epoch 65; Iter   442/ 1097] train: loss: 0.0110511
[Epoch 65; Iter   472/ 1097] train: loss: 0.0080721
[Epoch 65; Iter   502/ 1097] train: loss: 0.0000434
[Epoch 65; Iter   532/ 1097] train: loss: 0.0132560
[Epoch 65; Iter   562/ 1097] train: loss: 0.0001154
[Epoch 65; Iter   592/ 1097] train: loss: 0.0000506
[Epoch 65; Iter   622/ 1097] train: loss: 0.0001732
[Epoch 65; Iter   652/ 1097] train: loss: 0.0008366
[Epoch 65; Iter   682/ 1097] train: loss: 0.0016593
[Epoch 65; Iter   712/ 1097] train: loss: 0.0016110
[Epoch 65; Iter   742/ 1097] train: loss: 0.0028485
[Epoch 65; Iter   772/ 1097] train: loss: 0.0001050
[Epoch 65; Iter   802/ 1097] train: loss: 0.0002844
[Epoch 65; Iter   832/ 1097] train: loss: 0.0003418
[Epoch 65; Iter   862/ 1097] train: loss: 0.0138540
[Epoch 65; Iter   892/ 1097] train: loss: 0.0000299
[Epoch 65; Iter   922/ 1097] train: loss: 0.0017412
[Epoch 65; Iter   952/ 1097] train: loss: 0.0011339
[Epoch 65; Iter   982/ 1097] train: loss: 0.0018116
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0004476
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0004716
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0588978
[Epoch 65] ogbg-molhiv: 0.772419 val loss: 0.232163
[Epoch 65] ogbg-molhiv: 0.726457 test loss: 0.314523
[Epoch 66; Iter     5/ 1097] train: loss: 0.0005556
[Epoch 66; Iter    35/ 1097] train: loss: 0.0000363
[Epoch 66; Iter    65/ 1097] train: loss: 0.0002691
[Epoch 66; Iter    95/ 1097] train: loss: 0.0006619
[Epoch 66; Iter   125/ 1097] train: loss: 0.0034733
[Epoch 66; Iter   155/ 1097] train: loss: 0.0019491
[Epoch 66; Iter   185/ 1097] train: loss: 0.0004382
[Epoch 66; Iter   215/ 1097] train: loss: 0.0026262
[Epoch 66; Iter   245/ 1097] train: loss: 0.0118963
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000419
[Epoch 66; Iter   305/ 1097] train: loss: 0.0017222
[Epoch 66; Iter   335/ 1097] train: loss: 0.0002484
[Epoch 66; Iter   365/ 1097] train: loss: 0.0002315
[Epoch 66; Iter   395/ 1097] train: loss: 0.0012582
[Epoch 66; Iter   425/ 1097] train: loss: 0.0000795
[Epoch 66; Iter   455/ 1097] train: loss: 0.0028617
[Epoch 66; Iter   485/ 1097] train: loss: 0.0003207
[Epoch 66; Iter   515/ 1097] train: loss: 0.0015792
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001540
[Epoch 66; Iter   575/ 1097] train: loss: 0.0012906
[Epoch 66; Iter   605/ 1097] train: loss: 0.0010948
[Epoch 66; Iter   635/ 1097] train: loss: 0.0164859
[Epoch 66; Iter   665/ 1097] train: loss: 0.0010976
[Epoch 66; Iter   695/ 1097] train: loss: 0.0002169
[Epoch 66; Iter   725/ 1097] train: loss: 0.0327910
[Epoch 66; Iter   755/ 1097] train: loss: 0.0009268
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000271
[Epoch 66; Iter   815/ 1097] train: loss: 0.0000849
[Epoch 66; Iter   845/ 1097] train: loss: 0.0000441
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000993
[Epoch 66; Iter   905/ 1097] train: loss: 0.0014598
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001428
[Epoch 66; Iter   965/ 1097] train: loss: 0.0000928
[Epoch 66; Iter   995/ 1097] train: loss: 0.0014079
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0012217
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0001500
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0006688
[Epoch 66] ogbg-molhiv: 0.785062 val loss: 0.235264
[Epoch 66] ogbg-molhiv: 0.713183 test loss: 0.387722
[Epoch 67; Iter    18/ 1097] train: loss: 0.0007739
[Epoch 67; Iter    48/ 1097] train: loss: 0.0001935
[Epoch 67; Iter    78/ 1097] train: loss: 0.0039587
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003103
[Epoch 67; Iter   138/ 1097] train: loss: 0.0002004
[Epoch 67; Iter   168/ 1097] train: loss: 0.0059387
[Epoch 67; Iter   198/ 1097] train: loss: 0.0014565
[Epoch 67; Iter   228/ 1097] train: loss: 0.0001886
[Epoch 67; Iter   258/ 1097] train: loss: 0.0221459
[Epoch 67; Iter   288/ 1097] train: loss: 0.0005222
[Epoch 67; Iter   318/ 1097] train: loss: 0.0000197
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002332
[Epoch 67; Iter   378/ 1097] train: loss: 0.0001602
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000146
[Epoch 67; Iter   438/ 1097] train: loss: 0.0021919
[Epoch 67; Iter   468/ 1097] train: loss: 0.0004093
[Epoch 67; Iter   498/ 1097] train: loss: 0.0000317
[Epoch 67; Iter   528/ 1097] train: loss: 0.0000192
[Epoch 67; Iter   558/ 1097] train: loss: 0.0024132
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000791
[Epoch 67; Iter   618/ 1097] train: loss: 0.0006891
[Epoch 67; Iter   648/ 1097] train: loss: 0.0005726
[Epoch 67; Iter   678/ 1097] train: loss: 0.0005412
[Epoch 67; Iter   708/ 1097] train: loss: 0.0012026
[Epoch 67; Iter   738/ 1097] train: loss: 0.0007346
[Epoch 67; Iter   768/ 1097] train: loss: 0.0012930
[Epoch 67; Iter   798/ 1097] train: loss: 0.0000557
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000422
[Epoch 67; Iter   858/ 1097] train: loss: 0.0014934
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000309
[Epoch 67; Iter   918/ 1097] train: loss: 0.0002834
[Epoch 67; Iter   948/ 1097] train: loss: 0.0007958
[Epoch 67; Iter   978/ 1097] train: loss: 0.0057545
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0022526
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013847
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001896
[Epoch 67] ogbg-molhiv: 0.790270 val loss: 0.272167
[Epoch 67] ogbg-molhiv: 0.733244 test loss: 0.405989
[Epoch 68; Iter     1/ 1097] train: loss: 0.0009141
[Epoch 68; Iter    31/ 1097] train: loss: 0.0014241
[Epoch 68; Iter    61/ 1097] train: loss: 0.0006685
[Epoch 68; Iter    91/ 1097] train: loss: 0.0003374
[Epoch 68; Iter   121/ 1097] train: loss: 0.0002078
[Epoch 68; Iter   151/ 1097] train: loss: 0.0000607
[Epoch 68; Iter   181/ 1097] train: loss: 0.0014281
[Epoch 68; Iter   211/ 1097] train: loss: 0.0007085
[Epoch 68; Iter   241/ 1097] train: loss: 0.0003416
[Epoch 68; Iter   271/ 1097] train: loss: 0.0062670
[Epoch 68; Iter   301/ 1097] train: loss: 0.0015945
[Epoch 68; Iter   331/ 1097] train: loss: 0.0002336
[Epoch 68; Iter   361/ 1097] train: loss: 0.0023877
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000561
[Epoch 68; Iter   421/ 1097] train: loss: 0.0001311
[Epoch 68; Iter   451/ 1097] train: loss: 0.0003342
[Epoch 68; Iter   481/ 1097] train: loss: 0.0004292
[Epoch 68; Iter   511/ 1097] train: loss: 0.0001291
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000240
[Epoch 68; Iter   571/ 1097] train: loss: 0.0047011
[Epoch 68; Iter   601/ 1097] train: loss: 0.0005732
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002848
[Epoch 68; Iter   661/ 1097] train: loss: 0.0027758
[Epoch 68; Iter   691/ 1097] train: loss: 0.0003046
[Epoch 68; Iter   721/ 1097] train: loss: 0.0001764
[Epoch 68; Iter   751/ 1097] train: loss: 0.0054303
[Epoch 68; Iter   781/ 1097] train: loss: 0.0012685
[Epoch 68; Iter   811/ 1097] train: loss: 0.0009425
[Epoch 68; Iter   841/ 1097] train: loss: 0.0084438
[Epoch 68; Iter   871/ 1097] train: loss: 0.0122049
[Epoch 68; Iter   901/ 1097] train: loss: 0.0134268
[Epoch 68; Iter   931/ 1097] train: loss: 0.0023479
[Epoch 68; Iter   961/ 1097] train: loss: 0.0022811
[Epoch 68; Iter   991/ 1097] train: loss: 0.0430393
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0024305
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0001312
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0001466
[Epoch 68] ogbg-molhiv: 0.792040 val loss: 0.236461
[Epoch 68] ogbg-molhiv: 0.738552 test loss: 0.581168
[Epoch 69; Iter    14/ 1097] train: loss: 0.0002315
[Epoch 69; Iter    44/ 1097] train: loss: 0.0001275
[Epoch 69; Iter    74/ 1097] train: loss: 0.0003475
[Epoch 65; Iter    22/ 1097] train: loss: 0.0960650
[Epoch 65; Iter    52/ 1097] train: loss: 0.0007544
[Epoch 65; Iter    82/ 1097] train: loss: 0.0000422
[Epoch 65; Iter   112/ 1097] train: loss: 0.0001639
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000201
[Epoch 65; Iter   172/ 1097] train: loss: 0.0334121
[Epoch 65; Iter   202/ 1097] train: loss: 0.0000645
[Epoch 65; Iter   232/ 1097] train: loss: 0.0129337
[Epoch 65; Iter   262/ 1097] train: loss: 0.0145340
[Epoch 65; Iter   292/ 1097] train: loss: 0.0005884
[Epoch 65; Iter   322/ 1097] train: loss: 0.0042340
[Epoch 65; Iter   352/ 1097] train: loss: 0.0001527
[Epoch 65; Iter   382/ 1097] train: loss: 0.0004889
[Epoch 65; Iter   412/ 1097] train: loss: 0.0004698
[Epoch 65; Iter   442/ 1097] train: loss: 0.0000216
[Epoch 65; Iter   472/ 1097] train: loss: 0.0218516
[Epoch 65; Iter   502/ 1097] train: loss: 0.0003672
[Epoch 65; Iter   532/ 1097] train: loss: 0.0016977
[Epoch 65; Iter   562/ 1097] train: loss: 0.0033836
[Epoch 65; Iter   592/ 1097] train: loss: 0.0010214
[Epoch 65; Iter   622/ 1097] train: loss: 0.0001983
[Epoch 65; Iter   652/ 1097] train: loss: 0.0000695
[Epoch 65; Iter   682/ 1097] train: loss: 0.0014673
[Epoch 65; Iter   712/ 1097] train: loss: 0.0267931
[Epoch 65; Iter   742/ 1097] train: loss: 0.0003532
[Epoch 65; Iter   772/ 1097] train: loss: 0.0001711
[Epoch 65; Iter   802/ 1097] train: loss: 0.0000247
[Epoch 65; Iter   832/ 1097] train: loss: 0.0009002
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001759
[Epoch 65; Iter   892/ 1097] train: loss: 0.0001985
[Epoch 65; Iter   922/ 1097] train: loss: 0.0002428
[Epoch 65; Iter   952/ 1097] train: loss: 0.0000684
[Epoch 65; Iter   982/ 1097] train: loss: 0.0000118
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0006152
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0043850
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0002392
[Epoch 65] ogbg-molhiv: 0.789294 val loss: 0.427604
[Epoch 65] ogbg-molhiv: 0.793654 test loss: 0.287460
[Epoch 66; Iter     5/ 1097] train: loss: 0.0004276
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001059
[Epoch 66; Iter    65/ 1097] train: loss: 0.0286570
[Epoch 66; Iter    95/ 1097] train: loss: 0.0078604
[Epoch 66; Iter   125/ 1097] train: loss: 0.0008318
[Epoch 66; Iter   155/ 1097] train: loss: 0.0007165
[Epoch 66; Iter   185/ 1097] train: loss: 0.0020878
[Epoch 66; Iter   215/ 1097] train: loss: 0.0000698
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000283
[Epoch 66; Iter   275/ 1097] train: loss: 0.0004328
[Epoch 66; Iter   305/ 1097] train: loss: 0.0002846
[Epoch 66; Iter   335/ 1097] train: loss: 0.0038796
[Epoch 66; Iter   365/ 1097] train: loss: 0.0001797
[Epoch 66; Iter   395/ 1097] train: loss: 0.0004027
[Epoch 66; Iter   425/ 1097] train: loss: 0.0004303
[Epoch 66; Iter   455/ 1097] train: loss: 0.0179094
[Epoch 66; Iter   485/ 1097] train: loss: 0.0003071
[Epoch 66; Iter   515/ 1097] train: loss: 0.0000189
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001720
[Epoch 66; Iter   575/ 1097] train: loss: 0.0011867
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000637
[Epoch 66; Iter   635/ 1097] train: loss: 0.0000103
[Epoch 66; Iter   665/ 1097] train: loss: 0.0004386
[Epoch 66; Iter   695/ 1097] train: loss: 0.0000346
[Epoch 66; Iter   725/ 1097] train: loss: 0.0018602
[Epoch 66; Iter   755/ 1097] train: loss: 0.0001385
[Epoch 66; Iter   785/ 1097] train: loss: 0.0007738
[Epoch 66; Iter   815/ 1097] train: loss: 0.0008652
[Epoch 66; Iter   845/ 1097] train: loss: 0.0154965
[Epoch 66; Iter   875/ 1097] train: loss: 0.0004182
[Epoch 66; Iter   905/ 1097] train: loss: 0.0000299
[Epoch 66; Iter   935/ 1097] train: loss: 0.0000149
[Epoch 66; Iter   965/ 1097] train: loss: 0.0361374
[Epoch 66; Iter   995/ 1097] train: loss: 0.0014734
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0000298
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0009952
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0000817
[Epoch 66] ogbg-molhiv: 0.790868 val loss: 0.357581
[Epoch 66] ogbg-molhiv: 0.802507 test loss: 0.304715
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000108
[Epoch 67; Iter    48/ 1097] train: loss: 0.0011437
[Epoch 67; Iter    78/ 1097] train: loss: 0.0005893
[Epoch 67; Iter   108/ 1097] train: loss: 0.0001720
[Epoch 67; Iter   138/ 1097] train: loss: 0.0000486
[Epoch 67; Iter   168/ 1097] train: loss: 0.0000715
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000659
[Epoch 67; Iter   228/ 1097] train: loss: 0.0001712
[Epoch 67; Iter   258/ 1097] train: loss: 0.0004310
[Epoch 67; Iter   288/ 1097] train: loss: 0.0005475
[Epoch 67; Iter   318/ 1097] train: loss: 0.0000831
[Epoch 67; Iter   348/ 1097] train: loss: 0.0001324
[Epoch 67; Iter   378/ 1097] train: loss: 0.0001000
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000358
[Epoch 67; Iter   438/ 1097] train: loss: 0.0000372
[Epoch 67; Iter   468/ 1097] train: loss: 0.0000584
[Epoch 67; Iter   498/ 1097] train: loss: 0.0007570
[Epoch 67; Iter   528/ 1097] train: loss: 0.0000291
[Epoch 67; Iter   558/ 1097] train: loss: 0.0000333
[Epoch 67; Iter   588/ 1097] train: loss: 0.0002072
[Epoch 67; Iter   618/ 1097] train: loss: 0.0002548
[Epoch 67; Iter   648/ 1097] train: loss: 0.0025042
[Epoch 67; Iter   678/ 1097] train: loss: 0.0000174
[Epoch 67; Iter   708/ 1097] train: loss: 0.0007713
[Epoch 67; Iter   738/ 1097] train: loss: 0.0002003
[Epoch 67; Iter   768/ 1097] train: loss: 0.0017364
[Epoch 67; Iter   798/ 1097] train: loss: 0.0015412
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000379
[Epoch 67; Iter   858/ 1097] train: loss: 0.0000071
[Epoch 67; Iter   888/ 1097] train: loss: 0.0007137
[Epoch 67; Iter   918/ 1097] train: loss: 0.0011066
[Epoch 67; Iter   948/ 1097] train: loss: 0.0003916
[Epoch 67; Iter   978/ 1097] train: loss: 0.0001861
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000269
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0009870
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000040
[Epoch 67] ogbg-molhiv: 0.781299 val loss: 0.341165
[Epoch 67] ogbg-molhiv: 0.801223 test loss: 0.313650
[Epoch 68; Iter     1/ 1097] train: loss: 0.0000358
[Epoch 68; Iter    31/ 1097] train: loss: 0.0004369
[Epoch 68; Iter    61/ 1097] train: loss: 0.0000349
[Epoch 68; Iter    91/ 1097] train: loss: 0.0000709
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000200
[Epoch 68; Iter   151/ 1097] train: loss: 0.0002996
[Epoch 68; Iter   181/ 1097] train: loss: 0.0000845
[Epoch 68; Iter   211/ 1097] train: loss: 0.0000645
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002461
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000859
[Epoch 68; Iter   301/ 1097] train: loss: 0.0002069
[Epoch 68; Iter   331/ 1097] train: loss: 0.0003289
[Epoch 68; Iter   361/ 1097] train: loss: 0.0029025
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000178
[Epoch 68; Iter   421/ 1097] train: loss: 0.0044749
[Epoch 68; Iter   451/ 1097] train: loss: 0.0001889
[Epoch 68; Iter   481/ 1097] train: loss: 0.0001507
[Epoch 68; Iter   511/ 1097] train: loss: 0.0000593
[Epoch 68; Iter   541/ 1097] train: loss: 0.0003657
[Epoch 68; Iter   571/ 1097] train: loss: 0.0006542
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000873
[Epoch 68; Iter   631/ 1097] train: loss: 0.0008489
[Epoch 68; Iter   661/ 1097] train: loss: 0.0011224
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000257
[Epoch 68; Iter   721/ 1097] train: loss: 0.0000113
[Epoch 68; Iter   751/ 1097] train: loss: 0.0003009
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000528
[Epoch 68; Iter   811/ 1097] train: loss: 0.0000105
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000046
[Epoch 68; Iter   871/ 1097] train: loss: 0.0005250
[Epoch 68; Iter   901/ 1097] train: loss: 0.0000165
[Epoch 68; Iter   931/ 1097] train: loss: 0.0008402
[Epoch 68; Iter   961/ 1097] train: loss: 0.0017620
[Epoch 68; Iter   991/ 1097] train: loss: 0.0033113
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0000595
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003395
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0013392
[Epoch 68] ogbg-molhiv: 0.792447 val loss: 0.361897
[Epoch 68] ogbg-molhiv: 0.790923 test loss: 0.312593
[Epoch 69; Iter    14/ 1097] train: loss: 0.0004599
[Epoch 69; Iter    44/ 1097] train: loss: 0.0008460
[Epoch 69; Iter    74/ 1097] train: loss: 0.0027538
[Epoch 52; Iter   933/ 1097] train: loss: 0.0241091
[Epoch 52; Iter   963/ 1097] train: loss: 0.0484079
[Epoch 52; Iter   993/ 1097] train: loss: 0.0081010
[Epoch 52; Iter  1023/ 1097] train: loss: 0.1189663
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0366619
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0085936
[Epoch 52] ogbg-molhiv: 0.806287 val loss: 0.086436
[Epoch 52] ogbg-molhiv: 0.738261 test loss: 0.154983
[Epoch 53; Iter    16/ 1097] train: loss: 0.0240463
[Epoch 53; Iter    46/ 1097] train: loss: 0.0309928
[Epoch 53; Iter    76/ 1097] train: loss: 0.0066618
[Epoch 53; Iter   106/ 1097] train: loss: 0.0213130
[Epoch 53; Iter   136/ 1097] train: loss: 0.0216375
[Epoch 53; Iter   166/ 1097] train: loss: 0.0480142
[Epoch 53; Iter   196/ 1097] train: loss: 0.0131756
[Epoch 53; Iter   226/ 1097] train: loss: 0.1023088
[Epoch 53; Iter   256/ 1097] train: loss: 0.0090050
[Epoch 53; Iter   286/ 1097] train: loss: 0.0171148
[Epoch 53; Iter   316/ 1097] train: loss: 0.0289263
[Epoch 53; Iter   346/ 1097] train: loss: 0.1584013
[Epoch 53; Iter   376/ 1097] train: loss: 0.0938989
[Epoch 53; Iter   406/ 1097] train: loss: 0.0079180
[Epoch 53; Iter   436/ 1097] train: loss: 0.0189688
[Epoch 53; Iter   466/ 1097] train: loss: 0.0648226
[Epoch 53; Iter   496/ 1097] train: loss: 0.0920727
[Epoch 53; Iter   526/ 1097] train: loss: 0.0282406
[Epoch 53; Iter   556/ 1097] train: loss: 0.1851591
[Epoch 53; Iter   586/ 1097] train: loss: 0.0956128
[Epoch 53; Iter   616/ 1097] train: loss: 0.0139415
[Epoch 53; Iter   646/ 1097] train: loss: 0.2523533
[Epoch 53; Iter   676/ 1097] train: loss: 0.1120494
[Epoch 53; Iter   706/ 1097] train: loss: 0.0818857
[Epoch 53; Iter   736/ 1097] train: loss: 0.0285127
[Epoch 53; Iter   766/ 1097] train: loss: 0.0073663
[Epoch 53; Iter   796/ 1097] train: loss: 0.0168769
[Epoch 53; Iter   826/ 1097] train: loss: 0.0312876
[Epoch 53; Iter   856/ 1097] train: loss: 0.0697718
[Epoch 53; Iter   886/ 1097] train: loss: 0.0727590
[Epoch 53; Iter   916/ 1097] train: loss: 0.0576850
[Epoch 53; Iter   946/ 1097] train: loss: 0.0147041
[Epoch 53; Iter   976/ 1097] train: loss: 0.0267051
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0505628
[Epoch 53; Iter  1036/ 1097] train: loss: 0.1413947
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0140280
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0342137
[Epoch 53] ogbg-molhiv: 0.816643 val loss: 0.090886
[Epoch 53] ogbg-molhiv: 0.748354 test loss: 0.158366
[Epoch 54; Iter    29/ 1097] train: loss: 0.0076438
[Epoch 54; Iter    59/ 1097] train: loss: 0.0167474
[Epoch 54; Iter    89/ 1097] train: loss: 0.0145986
[Epoch 54; Iter   119/ 1097] train: loss: 0.0961953
[Epoch 54; Iter   149/ 1097] train: loss: 0.0498384
[Epoch 54; Iter   179/ 1097] train: loss: 0.0535181
[Epoch 54; Iter   209/ 1097] train: loss: 0.0264195
[Epoch 54; Iter   239/ 1097] train: loss: 0.0359331
[Epoch 54; Iter   269/ 1097] train: loss: 0.0092406
[Epoch 54; Iter   299/ 1097] train: loss: 0.1230084
[Epoch 54; Iter   329/ 1097] train: loss: 0.0120066
[Epoch 54; Iter   359/ 1097] train: loss: 0.0073060
[Epoch 54; Iter   389/ 1097] train: loss: 0.0740405
[Epoch 54; Iter   419/ 1097] train: loss: 0.0149973
[Epoch 54; Iter   449/ 1097] train: loss: 0.0633358
[Epoch 54; Iter   479/ 1097] train: loss: 0.0145950
[Epoch 54; Iter   509/ 1097] train: loss: 0.1367305
[Epoch 54; Iter   539/ 1097] train: loss: 0.0180959
[Epoch 54; Iter   569/ 1097] train: loss: 0.0155399
[Epoch 54; Iter   599/ 1097] train: loss: 0.0289089
[Epoch 54; Iter   629/ 1097] train: loss: 0.2551935
[Epoch 54; Iter   659/ 1097] train: loss: 0.0180168
[Epoch 54; Iter   689/ 1097] train: loss: 0.0309787
[Epoch 54; Iter   719/ 1097] train: loss: 0.1022983
[Epoch 54; Iter   749/ 1097] train: loss: 0.0204009
[Epoch 54; Iter   779/ 1097] train: loss: 0.0091593
[Epoch 54; Iter   809/ 1097] train: loss: 0.0714445
[Epoch 54; Iter   839/ 1097] train: loss: 0.2658492
[Epoch 54; Iter   869/ 1097] train: loss: 0.0112022
[Epoch 54; Iter   899/ 1097] train: loss: 0.0177689
[Epoch 54; Iter   929/ 1097] train: loss: 0.0169134
[Epoch 54; Iter   959/ 1097] train: loss: 0.0546590
[Epoch 54; Iter   989/ 1097] train: loss: 0.0211291
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0051528
[Epoch 54; Iter  1049/ 1097] train: loss: 0.1517468
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0200489
[Epoch 54] ogbg-molhiv: 0.783877 val loss: 0.098258
[Epoch 54] ogbg-molhiv: 0.723990 test loss: 0.173378
[Epoch 55; Iter    12/ 1097] train: loss: 0.0411192
[Epoch 55; Iter    42/ 1097] train: loss: 0.0319300
[Epoch 55; Iter    72/ 1097] train: loss: 0.0186271
[Epoch 55; Iter   102/ 1097] train: loss: 0.0455842
[Epoch 55; Iter   132/ 1097] train: loss: 0.2980496
[Epoch 55; Iter   162/ 1097] train: loss: 0.0718607
[Epoch 55; Iter   192/ 1097] train: loss: 0.0321738
[Epoch 55; Iter   222/ 1097] train: loss: 0.0180788
[Epoch 55; Iter   252/ 1097] train: loss: 0.0693004
[Epoch 55; Iter   282/ 1097] train: loss: 0.0940318
[Epoch 55; Iter   312/ 1097] train: loss: 0.1689150
[Epoch 55; Iter   342/ 1097] train: loss: 0.0212279
[Epoch 55; Iter   372/ 1097] train: loss: 0.0408316
[Epoch 55; Iter   402/ 1097] train: loss: 0.0093718
[Epoch 55; Iter   432/ 1097] train: loss: 0.0215589
[Epoch 55; Iter   462/ 1097] train: loss: 0.0102190
[Epoch 55; Iter   492/ 1097] train: loss: 0.0345533
[Epoch 55; Iter   522/ 1097] train: loss: 0.0275059
[Epoch 55; Iter   552/ 1097] train: loss: 0.0228982
[Epoch 55; Iter   582/ 1097] train: loss: 0.0994701
[Epoch 55; Iter   612/ 1097] train: loss: 0.0751897
[Epoch 55; Iter   642/ 1097] train: loss: 0.0072041
[Epoch 55; Iter   672/ 1097] train: loss: 0.0104602
[Epoch 55; Iter   702/ 1097] train: loss: 0.0226093
[Epoch 55; Iter   732/ 1097] train: loss: 0.0186805
[Epoch 55; Iter   762/ 1097] train: loss: 0.0066055
[Epoch 55; Iter   792/ 1097] train: loss: 0.0246917
[Epoch 55; Iter   822/ 1097] train: loss: 0.0263930
[Epoch 55; Iter   852/ 1097] train: loss: 0.0309669
[Epoch 55; Iter   882/ 1097] train: loss: 0.0837708
[Epoch 55; Iter   912/ 1097] train: loss: 0.0177210
[Epoch 55; Iter   942/ 1097] train: loss: 0.0105415
[Epoch 55; Iter   972/ 1097] train: loss: 0.0095976
[Epoch 55; Iter  1002/ 1097] train: loss: 0.1882827
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0160318
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0062180
[Epoch 55; Iter  1092/ 1097] train: loss: 0.2365794
[Epoch 55] ogbg-molhiv: 0.824238 val loss: 0.088206
[Epoch 55] ogbg-molhiv: 0.744433 test loss: 0.163670
[Epoch 56; Iter    25/ 1097] train: loss: 0.0184045
[Epoch 56; Iter    55/ 1097] train: loss: 0.0769450
[Epoch 56; Iter    85/ 1097] train: loss: 0.0143666
[Epoch 56; Iter   115/ 1097] train: loss: 0.0119001
[Epoch 56; Iter   145/ 1097] train: loss: 0.0950435
[Epoch 56; Iter   175/ 1097] train: loss: 0.1700828
[Epoch 56; Iter   205/ 1097] train: loss: 0.2389728
[Epoch 56; Iter   235/ 1097] train: loss: 0.0063513
[Epoch 56; Iter   265/ 1097] train: loss: 0.0371188
[Epoch 56; Iter   295/ 1097] train: loss: 0.1274285
[Epoch 56; Iter   325/ 1097] train: loss: 0.0206883
[Epoch 56; Iter   355/ 1097] train: loss: 0.0756028
[Epoch 56; Iter   385/ 1097] train: loss: 0.0810376
[Epoch 56; Iter   415/ 1097] train: loss: 0.0078111
[Epoch 56; Iter   445/ 1097] train: loss: 0.0748858
[Epoch 56; Iter   475/ 1097] train: loss: 0.0222721
[Epoch 56; Iter   505/ 1097] train: loss: 0.0249075
[Epoch 56; Iter   535/ 1097] train: loss: 0.0702224
[Epoch 56; Iter   565/ 1097] train: loss: 0.0088539
[Epoch 56; Iter   595/ 1097] train: loss: 0.0324088
[Epoch 56; Iter   625/ 1097] train: loss: 0.0160917
[Epoch 56; Iter   655/ 1097] train: loss: 0.0608853
[Epoch 56; Iter   685/ 1097] train: loss: 0.0168926
[Epoch 56; Iter   715/ 1097] train: loss: 0.0410502
[Epoch 56; Iter   745/ 1097] train: loss: 0.0144586
[Epoch 56; Iter   775/ 1097] train: loss: 0.1193405
[Epoch 56; Iter   805/ 1097] train: loss: 0.0244222
[Epoch 56; Iter   835/ 1097] train: loss: 0.0153377
[Epoch 56; Iter   865/ 1097] train: loss: 0.1654923
[Epoch 56; Iter   895/ 1097] train: loss: 0.1261779
[Epoch 56; Iter   925/ 1097] train: loss: 0.1044481
[Epoch 56; Iter   955/ 1097] train: loss: 0.0141115
[Epoch 56; Iter   985/ 1097] train: loss: 0.1309388
[Epoch 65; Iter    22/ 1097] train: loss: 0.0242794
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000044
[Epoch 65; Iter    82/ 1097] train: loss: 0.0000102
[Epoch 65; Iter   112/ 1097] train: loss: 0.0000128
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000682
[Epoch 65; Iter   172/ 1097] train: loss: 0.0000839
[Epoch 65; Iter   202/ 1097] train: loss: 0.0036529
[Epoch 65; Iter   232/ 1097] train: loss: 0.0094753
[Epoch 65; Iter   262/ 1097] train: loss: 0.0002396
[Epoch 65; Iter   292/ 1097] train: loss: 0.0016119
[Epoch 65; Iter   322/ 1097] train: loss: 0.0008116
[Epoch 65; Iter   352/ 1097] train: loss: 0.0000242
[Epoch 65; Iter   382/ 1097] train: loss: 0.0127334
[Epoch 65; Iter   412/ 1097] train: loss: 0.0047759
[Epoch 65; Iter   442/ 1097] train: loss: 0.0000119
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000912
[Epoch 65; Iter   502/ 1097] train: loss: 0.0001449
[Epoch 65; Iter   532/ 1097] train: loss: 0.0001090
[Epoch 65; Iter   562/ 1097] train: loss: 0.0000250
[Epoch 65; Iter   592/ 1097] train: loss: 0.0000056
[Epoch 65; Iter   622/ 1097] train: loss: 0.0000295
[Epoch 65; Iter   652/ 1097] train: loss: 0.0031707
[Epoch 65; Iter   682/ 1097] train: loss: 0.0015527
[Epoch 65; Iter   712/ 1097] train: loss: 0.0003347
[Epoch 65; Iter   742/ 1097] train: loss: 0.0002318
[Epoch 65; Iter   772/ 1097] train: loss: 0.0004500
[Epoch 65; Iter   802/ 1097] train: loss: 0.0001927
[Epoch 65; Iter   832/ 1097] train: loss: 0.0007582
[Epoch 65; Iter   862/ 1097] train: loss: 0.0000719
[Epoch 65; Iter   892/ 1097] train: loss: 0.0002829
[Epoch 65; Iter   922/ 1097] train: loss: 0.0017395
[Epoch 65; Iter   952/ 1097] train: loss: 0.0000232
[Epoch 65; Iter   982/ 1097] train: loss: 0.0002008
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0004128
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000068
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0001037
[Epoch 65] ogbg-molhiv: 0.715624 val loss: 1.041346
[Epoch 65] ogbg-molhiv: 0.637477 test loss: 2.445465
[Epoch 66; Iter     5/ 1097] train: loss: 0.0001029
[Epoch 66; Iter    35/ 1097] train: loss: 0.0044185
[Epoch 66; Iter    65/ 1097] train: loss: 0.0009901
[Epoch 66; Iter    95/ 1097] train: loss: 0.0000741
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003532
[Epoch 66; Iter   155/ 1097] train: loss: 0.0000027
[Epoch 66; Iter   185/ 1097] train: loss: 0.0000458
[Epoch 66; Iter   215/ 1097] train: loss: 0.0000731
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000073
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000034
[Epoch 66; Iter   305/ 1097] train: loss: 0.0002494
[Epoch 66; Iter   335/ 1097] train: loss: 0.0009489
[Epoch 66; Iter   365/ 1097] train: loss: 0.0000344
[Epoch 66; Iter   395/ 1097] train: loss: 0.0000333
[Epoch 66; Iter   425/ 1097] train: loss: 0.0000579
[Epoch 66; Iter   455/ 1097] train: loss: 0.0000864
[Epoch 66; Iter   485/ 1097] train: loss: 0.0001072
[Epoch 66; Iter   515/ 1097] train: loss: 0.0002773
[Epoch 66; Iter   545/ 1097] train: loss: 0.0002428
[Epoch 66; Iter   575/ 1097] train: loss: 0.0001085
[Epoch 66; Iter   605/ 1097] train: loss: 0.0001385
[Epoch 66; Iter   635/ 1097] train: loss: 0.0000624
[Epoch 66; Iter   665/ 1097] train: loss: 0.0013366
[Epoch 66; Iter   695/ 1097] train: loss: 0.0006330
[Epoch 66; Iter   725/ 1097] train: loss: 0.0000026
[Epoch 66; Iter   755/ 1097] train: loss: 0.0000359
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000739
[Epoch 66; Iter   815/ 1097] train: loss: 0.0005754
[Epoch 66; Iter   845/ 1097] train: loss: 0.0007215
[Epoch 66; Iter   875/ 1097] train: loss: 0.0012046
[Epoch 66; Iter   905/ 1097] train: loss: 0.0018030
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001027
[Epoch 66; Iter   965/ 1097] train: loss: 0.0000660
[Epoch 66; Iter   995/ 1097] train: loss: 0.0019862
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0002087
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0420928
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0025653
[Epoch 66] ogbg-molhiv: 0.685164 val loss: 2.420372
[Epoch 66] ogbg-molhiv: 0.639251 test loss: 3.116060
[Epoch 67; Iter    18/ 1097] train: loss: 0.0025277
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000758
[Epoch 67; Iter    78/ 1097] train: loss: 0.0007005
[Epoch 67; Iter   108/ 1097] train: loss: 0.0004310
[Epoch 67; Iter   138/ 1097] train: loss: 0.0000889
[Epoch 67; Iter   168/ 1097] train: loss: 0.0002563
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000248
[Epoch 67; Iter   228/ 1097] train: loss: 0.0011533
[Epoch 67; Iter   258/ 1097] train: loss: 0.0103562
[Epoch 67; Iter   288/ 1097] train: loss: 0.0001045
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001570
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002022
[Epoch 67; Iter   378/ 1097] train: loss: 0.0007909
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000272
[Epoch 67; Iter   438/ 1097] train: loss: 0.0014721
[Epoch 67; Iter   468/ 1097] train: loss: 0.0001582
[Epoch 67; Iter   498/ 1097] train: loss: 0.0009604
[Epoch 67; Iter   528/ 1097] train: loss: 0.0001391
[Epoch 67; Iter   558/ 1097] train: loss: 0.0003726
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000348
[Epoch 67; Iter   618/ 1097] train: loss: 0.0019310
[Epoch 67; Iter   648/ 1097] train: loss: 0.0017797
[Epoch 67; Iter   678/ 1097] train: loss: 0.0003324
[Epoch 67; Iter   708/ 1097] train: loss: 0.0000180
[Epoch 67; Iter   738/ 1097] train: loss: 0.0001045
[Epoch 67; Iter   768/ 1097] train: loss: 0.0000286
[Epoch 67; Iter   798/ 1097] train: loss: 0.0001128
[Epoch 67; Iter   828/ 1097] train: loss: 0.0007221
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004961
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000148
[Epoch 67; Iter   918/ 1097] train: loss: 0.0000201
[Epoch 67; Iter   948/ 1097] train: loss: 0.0001205
[Epoch 67; Iter   978/ 1097] train: loss: 0.0007512
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000247
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000063
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001089
[Epoch 67] ogbg-molhiv: 0.712730 val loss: 1.873888
[Epoch 67] ogbg-molhiv: 0.654468 test loss: 3.000572
[Epoch 68; Iter     1/ 1097] train: loss: 0.0029783
[Epoch 68; Iter    31/ 1097] train: loss: 0.0003562
[Epoch 68; Iter    61/ 1097] train: loss: 0.0974564
[Epoch 68; Iter    91/ 1097] train: loss: 0.0007104
[Epoch 68; Iter   121/ 1097] train: loss: 0.0003119
[Epoch 68; Iter   151/ 1097] train: loss: 0.0000589
[Epoch 68; Iter   181/ 1097] train: loss: 0.0003160
[Epoch 68; Iter   211/ 1097] train: loss: 0.0001238
[Epoch 68; Iter   241/ 1097] train: loss: 0.0000563
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000369
[Epoch 68; Iter   301/ 1097] train: loss: 0.0001030
[Epoch 68; Iter   331/ 1097] train: loss: 0.0005874
[Epoch 68; Iter   361/ 1097] train: loss: 0.0011497
[Epoch 68; Iter   391/ 1097] train: loss: 0.0005048
[Epoch 68; Iter   421/ 1097] train: loss: 0.0006108
[Epoch 68; Iter   451/ 1097] train: loss: 0.0280367
[Epoch 68; Iter   481/ 1097] train: loss: 0.0006634
[Epoch 68; Iter   511/ 1097] train: loss: 0.0332464
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000113
[Epoch 68; Iter   571/ 1097] train: loss: 0.0001626
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000977
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002609
[Epoch 68; Iter   661/ 1097] train: loss: 0.0314867
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000308
[Epoch 68; Iter   721/ 1097] train: loss: 0.0002370
[Epoch 68; Iter   751/ 1097] train: loss: 0.0000516
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000093
[Epoch 68; Iter   811/ 1097] train: loss: 0.0000025
[Epoch 68; Iter   841/ 1097] train: loss: 0.0055586
[Epoch 68; Iter   871/ 1097] train: loss: 0.0006074
[Epoch 68; Iter   901/ 1097] train: loss: 0.0000028
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000193
[Epoch 68; Iter   961/ 1097] train: loss: 0.0000115
[Epoch 68; Iter   991/ 1097] train: loss: 0.0029077
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0001289
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0000536
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0000919
[Epoch 68] ogbg-molhiv: 0.701560 val loss: 3.156001
[Epoch 68] ogbg-molhiv: 0.621771 test loss: 4.655309
[Epoch 69; Iter    14/ 1097] train: loss: 0.0099523
[Epoch 69; Iter    44/ 1097] train: loss: 0.0003425
[Epoch 69; Iter    74/ 1097] train: loss: 0.0000843
[Epoch 52; Iter   933/ 1097] train: loss: 0.0308502
[Epoch 52; Iter   963/ 1097] train: loss: 0.0253218
[Epoch 52; Iter   993/ 1097] train: loss: 0.0452143
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0531532
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0217514
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0917241
[Epoch 52] ogbg-molhiv: 0.798219 val loss: 0.085530
[Epoch 52] ogbg-molhiv: 0.737919 test loss: 0.159322
[Epoch 53; Iter    16/ 1097] train: loss: 0.0370972
[Epoch 53; Iter    46/ 1097] train: loss: 0.0198459
[Epoch 53; Iter    76/ 1097] train: loss: 0.0293908
[Epoch 53; Iter   106/ 1097] train: loss: 0.1309510
[Epoch 53; Iter   136/ 1097] train: loss: 0.0431872
[Epoch 53; Iter   166/ 1097] train: loss: 0.1474756
[Epoch 53; Iter   196/ 1097] train: loss: 0.0148932
[Epoch 53; Iter   226/ 1097] train: loss: 0.0810441
[Epoch 53; Iter   256/ 1097] train: loss: 0.0216553
[Epoch 53; Iter   286/ 1097] train: loss: 0.1393756
[Epoch 53; Iter   316/ 1097] train: loss: 0.0296286
[Epoch 53; Iter   346/ 1097] train: loss: 0.0232727
[Epoch 53; Iter   376/ 1097] train: loss: 0.0473384
[Epoch 53; Iter   406/ 1097] train: loss: 0.0160799
[Epoch 53; Iter   436/ 1097] train: loss: 0.0213770
[Epoch 53; Iter   466/ 1097] train: loss: 0.1608611
[Epoch 53; Iter   496/ 1097] train: loss: 0.0851922
[Epoch 53; Iter   526/ 1097] train: loss: 0.0637064
[Epoch 53; Iter   556/ 1097] train: loss: 0.0640809
[Epoch 53; Iter   586/ 1097] train: loss: 0.0430149
[Epoch 53; Iter   616/ 1097] train: loss: 0.0460576
[Epoch 53; Iter   646/ 1097] train: loss: 0.0125565
[Epoch 53; Iter   676/ 1097] train: loss: 0.3767759
[Epoch 53; Iter   706/ 1097] train: loss: 0.0414486
[Epoch 53; Iter   736/ 1097] train: loss: 0.1565778
[Epoch 53; Iter   766/ 1097] train: loss: 0.0561553
[Epoch 53; Iter   796/ 1097] train: loss: 0.0682743
[Epoch 53; Iter   826/ 1097] train: loss: 0.0253832
[Epoch 53; Iter   856/ 1097] train: loss: 0.0125790
[Epoch 53; Iter   886/ 1097] train: loss: 0.0115166
[Epoch 53; Iter   916/ 1097] train: loss: 0.0104478
[Epoch 53; Iter   946/ 1097] train: loss: 0.1768703
[Epoch 53; Iter   976/ 1097] train: loss: 0.0101848
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0215216
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0825492
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0239215
[Epoch 53; Iter  1096/ 1097] train: loss: 0.1416265
[Epoch 53] ogbg-molhiv: 0.791354 val loss: 0.096062
[Epoch 53] ogbg-molhiv: 0.760451 test loss: 0.151118
[Epoch 54; Iter    29/ 1097] train: loss: 0.0107247
[Epoch 54; Iter    59/ 1097] train: loss: 0.0092104
[Epoch 54; Iter    89/ 1097] train: loss: 0.0132687
[Epoch 54; Iter   119/ 1097] train: loss: 0.0509183
[Epoch 54; Iter   149/ 1097] train: loss: 0.0470154
[Epoch 54; Iter   179/ 1097] train: loss: 0.0182131
[Epoch 54; Iter   209/ 1097] train: loss: 0.0336821
[Epoch 54; Iter   239/ 1097] train: loss: 0.0475748
[Epoch 54; Iter   269/ 1097] train: loss: 0.0467931
[Epoch 54; Iter   299/ 1097] train: loss: 0.0768314
[Epoch 54; Iter   329/ 1097] train: loss: 0.1636388
[Epoch 54; Iter   359/ 1097] train: loss: 0.1074439
[Epoch 54; Iter   389/ 1097] train: loss: 0.1399838
[Epoch 54; Iter   419/ 1097] train: loss: 0.0095641
[Epoch 54; Iter   449/ 1097] train: loss: 0.1308812
[Epoch 54; Iter   479/ 1097] train: loss: 0.0206449
[Epoch 54; Iter   509/ 1097] train: loss: 0.0727294
[Epoch 54; Iter   539/ 1097] train: loss: 0.2201972
[Epoch 54; Iter   569/ 1097] train: loss: 0.0163401
[Epoch 54; Iter   599/ 1097] train: loss: 0.0414997
[Epoch 54; Iter   629/ 1097] train: loss: 0.0926754
[Epoch 54; Iter   659/ 1097] train: loss: 0.1502642
[Epoch 54; Iter   689/ 1097] train: loss: 0.0308825
[Epoch 54; Iter   719/ 1097] train: loss: 0.0161719
[Epoch 54; Iter   749/ 1097] train: loss: 0.0248728
[Epoch 54; Iter   779/ 1097] train: loss: 0.0209707
[Epoch 54; Iter   809/ 1097] train: loss: 0.0324352
[Epoch 54; Iter   839/ 1097] train: loss: 0.0132133
[Epoch 54; Iter   869/ 1097] train: loss: 0.0089051
[Epoch 54; Iter   899/ 1097] train: loss: 0.0150167
[Epoch 54; Iter   929/ 1097] train: loss: 0.0125872
[Epoch 54; Iter   959/ 1097] train: loss: 0.0254031
[Epoch 54; Iter   989/ 1097] train: loss: 0.0653951
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0216114
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0375945
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0096080
[Epoch 54] ogbg-molhiv: 0.808856 val loss: 0.103476
[Epoch 54] ogbg-molhiv: 0.747552 test loss: 0.159384
[Epoch 55; Iter    12/ 1097] train: loss: 0.0372129
[Epoch 55; Iter    42/ 1097] train: loss: 0.0389141
[Epoch 55; Iter    72/ 1097] train: loss: 0.0323691
[Epoch 55; Iter   102/ 1097] train: loss: 0.0104499
[Epoch 55; Iter   132/ 1097] train: loss: 0.0143972
[Epoch 55; Iter   162/ 1097] train: loss: 0.1633876
[Epoch 55; Iter   192/ 1097] train: loss: 0.0751664
[Epoch 55; Iter   222/ 1097] train: loss: 0.0117802
[Epoch 55; Iter   252/ 1097] train: loss: 0.0324246
[Epoch 55; Iter   282/ 1097] train: loss: 0.0219104
[Epoch 55; Iter   312/ 1097] train: loss: 0.0117126
[Epoch 55; Iter   342/ 1097] train: loss: 0.0126762
[Epoch 55; Iter   372/ 1097] train: loss: 0.0515536
[Epoch 55; Iter   402/ 1097] train: loss: 0.0337629
[Epoch 55; Iter   432/ 1097] train: loss: 0.0137485
[Epoch 55; Iter   462/ 1097] train: loss: 0.0234808
[Epoch 55; Iter   492/ 1097] train: loss: 0.0485286
[Epoch 55; Iter   522/ 1097] train: loss: 0.0211016
[Epoch 55; Iter   552/ 1097] train: loss: 0.0135990
[Epoch 55; Iter   582/ 1097] train: loss: 0.1034436
[Epoch 55; Iter   612/ 1097] train: loss: 0.0154565
[Epoch 55; Iter   642/ 1097] train: loss: 0.0171118
[Epoch 55; Iter   672/ 1097] train: loss: 0.1748164
[Epoch 55; Iter   702/ 1097] train: loss: 0.0747035
[Epoch 55; Iter   732/ 1097] train: loss: 0.0629763
[Epoch 55; Iter   762/ 1097] train: loss: 0.0633990
[Epoch 55; Iter   792/ 1097] train: loss: 0.0419127
[Epoch 55; Iter   822/ 1097] train: loss: 0.2365793
[Epoch 55; Iter   852/ 1097] train: loss: 0.0373694
[Epoch 55; Iter   882/ 1097] train: loss: 0.0148951
[Epoch 55; Iter   912/ 1097] train: loss: 0.0317385
[Epoch 55; Iter   942/ 1097] train: loss: 0.1646902
[Epoch 55; Iter   972/ 1097] train: loss: 0.0497468
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0440441
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0220618
[Epoch 55; Iter  1062/ 1097] train: loss: 0.1881066
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0114801
[Epoch 55] ogbg-molhiv: 0.805801 val loss: 0.086251
[Epoch 55] ogbg-molhiv: 0.744935 test loss: 0.159645
[Epoch 56; Iter    25/ 1097] train: loss: 0.0363807
[Epoch 56; Iter    55/ 1097] train: loss: 0.0620901
[Epoch 56; Iter    85/ 1097] train: loss: 0.0081633
[Epoch 56; Iter   115/ 1097] train: loss: 0.0351241
[Epoch 56; Iter   145/ 1097] train: loss: 0.0248463
[Epoch 56; Iter   175/ 1097] train: loss: 0.0658558
[Epoch 56; Iter   205/ 1097] train: loss: 0.1000359
[Epoch 56; Iter   235/ 1097] train: loss: 0.0821142
[Epoch 56; Iter   265/ 1097] train: loss: 0.0909628
[Epoch 56; Iter   295/ 1097] train: loss: 0.0637256
[Epoch 56; Iter   325/ 1097] train: loss: 0.0072261
[Epoch 56; Iter   355/ 1097] train: loss: 0.0723847
[Epoch 56; Iter   385/ 1097] train: loss: 0.0176396
[Epoch 56; Iter   415/ 1097] train: loss: 0.1362949
[Epoch 56; Iter   445/ 1097] train: loss: 0.0129445
[Epoch 56; Iter   475/ 1097] train: loss: 0.0065587
[Epoch 56; Iter   505/ 1097] train: loss: 0.0113020
[Epoch 56; Iter   535/ 1097] train: loss: 0.0093890
[Epoch 56; Iter   565/ 1097] train: loss: 0.1554945
[Epoch 56; Iter   595/ 1097] train: loss: 0.2742061
[Epoch 56; Iter   625/ 1097] train: loss: 0.0195357
[Epoch 56; Iter   655/ 1097] train: loss: 0.0707350
[Epoch 56; Iter   685/ 1097] train: loss: 0.2220442
[Epoch 56; Iter   715/ 1097] train: loss: 0.1617081
[Epoch 56; Iter   745/ 1097] train: loss: 0.0091177
[Epoch 56; Iter   775/ 1097] train: loss: 0.0182936
[Epoch 56; Iter   805/ 1097] train: loss: 0.0249070
[Epoch 56; Iter   835/ 1097] train: loss: 0.0229659
[Epoch 56; Iter   865/ 1097] train: loss: 0.0860869
[Epoch 56; Iter   895/ 1097] train: loss: 0.0784028
[Epoch 56; Iter   925/ 1097] train: loss: 0.1348729
[Epoch 56; Iter   955/ 1097] train: loss: 0.1170660
[Epoch 56; Iter   985/ 1097] train: loss: 0.0242353
[Epoch 52; Iter   933/ 1097] train: loss: 0.0107410
[Epoch 52; Iter   963/ 1097] train: loss: 0.0091081
[Epoch 52; Iter   993/ 1097] train: loss: 0.0072174
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0080198
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0126776
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0111665
[Epoch 52] ogbg-molhiv: 0.820323 val loss: 0.080238
[Epoch 52] ogbg-molhiv: 0.756556 test loss: 0.199091
[Epoch 53; Iter    16/ 1097] train: loss: 0.0105201
[Epoch 53; Iter    46/ 1097] train: loss: 0.0247120
[Epoch 53; Iter    76/ 1097] train: loss: 0.0290438
[Epoch 53; Iter   106/ 1097] train: loss: 0.0088015
[Epoch 53; Iter   136/ 1097] train: loss: 0.0144005
[Epoch 53; Iter   166/ 1097] train: loss: 0.2586915
[Epoch 53; Iter   196/ 1097] train: loss: 0.0093355
[Epoch 53; Iter   226/ 1097] train: loss: 0.0130063
[Epoch 53; Iter   256/ 1097] train: loss: 0.0149703
[Epoch 53; Iter   286/ 1097] train: loss: 0.3156807
[Epoch 53; Iter   316/ 1097] train: loss: 0.0212960
[Epoch 53; Iter   346/ 1097] train: loss: 0.1467578
[Epoch 53; Iter   376/ 1097] train: loss: 0.0117087
[Epoch 53; Iter   406/ 1097] train: loss: 0.0185728
[Epoch 53; Iter   436/ 1097] train: loss: 0.2961732
[Epoch 53; Iter   466/ 1097] train: loss: 0.1222187
[Epoch 53; Iter   496/ 1097] train: loss: 0.0138922
[Epoch 53; Iter   526/ 1097] train: loss: 0.1487768
[Epoch 53; Iter   556/ 1097] train: loss: 0.0374351
[Epoch 53; Iter   586/ 1097] train: loss: 0.0699288
[Epoch 53; Iter   616/ 1097] train: loss: 0.0763287
[Epoch 53; Iter   646/ 1097] train: loss: 0.0442474
[Epoch 53; Iter   676/ 1097] train: loss: 0.0193535
[Epoch 53; Iter   706/ 1097] train: loss: 0.0492158
[Epoch 53; Iter   736/ 1097] train: loss: 0.0536574
[Epoch 53; Iter   766/ 1097] train: loss: 0.0259385
[Epoch 53; Iter   796/ 1097] train: loss: 0.0747073
[Epoch 53; Iter   826/ 1097] train: loss: 0.1499404
[Epoch 53; Iter   856/ 1097] train: loss: 0.1342247
[Epoch 53; Iter   886/ 1097] train: loss: 0.0284953
[Epoch 53; Iter   916/ 1097] train: loss: 0.0202363
[Epoch 53; Iter   946/ 1097] train: loss: 0.0084194
[Epoch 53; Iter   976/ 1097] train: loss: 0.0416056
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0330081
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0050965
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0947565
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0110587
[Epoch 53] ogbg-molhiv: 0.802570 val loss: 0.092213
[Epoch 53] ogbg-molhiv: 0.760104 test loss: 0.226051
[Epoch 54; Iter    29/ 1097] train: loss: 0.0122027
[Epoch 54; Iter    59/ 1097] train: loss: 0.0565385
[Epoch 54; Iter    89/ 1097] train: loss: 0.0252990
[Epoch 54; Iter   119/ 1097] train: loss: 0.0101471
[Epoch 54; Iter   149/ 1097] train: loss: 0.1154791
[Epoch 54; Iter   179/ 1097] train: loss: 0.0051400
[Epoch 54; Iter   209/ 1097] train: loss: 0.0822733
[Epoch 54; Iter   239/ 1097] train: loss: 0.1566104
[Epoch 54; Iter   269/ 1097] train: loss: 0.1494794
[Epoch 54; Iter   299/ 1097] train: loss: 0.0125741
[Epoch 54; Iter   329/ 1097] train: loss: 0.0262077
[Epoch 54; Iter   359/ 1097] train: loss: 0.0220534
[Epoch 54; Iter   389/ 1097] train: loss: 0.0286279
[Epoch 54; Iter   419/ 1097] train: loss: 0.0161572
[Epoch 54; Iter   449/ 1097] train: loss: 0.0106459
[Epoch 54; Iter   479/ 1097] train: loss: 0.0088044
[Epoch 54; Iter   509/ 1097] train: loss: 0.0143211
[Epoch 54; Iter   539/ 1097] train: loss: 0.1599574
[Epoch 54; Iter   569/ 1097] train: loss: 0.0270380
[Epoch 54; Iter   599/ 1097] train: loss: 0.0196827
[Epoch 54; Iter   629/ 1097] train: loss: 0.0052391
[Epoch 54; Iter   659/ 1097] train: loss: 0.0971849
[Epoch 54; Iter   689/ 1097] train: loss: 0.0066707
[Epoch 54; Iter   719/ 1097] train: loss: 0.0155738
[Epoch 54; Iter   749/ 1097] train: loss: 0.0841458
[Epoch 54; Iter   779/ 1097] train: loss: 0.0624811
[Epoch 54; Iter   809/ 1097] train: loss: 0.2452298
[Epoch 54; Iter   839/ 1097] train: loss: 0.0592775
[Epoch 54; Iter   869/ 1097] train: loss: 0.0559854
[Epoch 54; Iter   899/ 1097] train: loss: 0.0169028
[Epoch 54; Iter   929/ 1097] train: loss: 0.0686202
[Epoch 54; Iter   959/ 1097] train: loss: 0.0172033
[Epoch 54; Iter   989/ 1097] train: loss: 0.1931911
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0689687
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0075797
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0197364
[Epoch 54] ogbg-molhiv: 0.804631 val loss: 0.093317
[Epoch 54] ogbg-molhiv: 0.744982 test loss: 0.190306
[Epoch 55; Iter    12/ 1097] train: loss: 0.0250995
[Epoch 55; Iter    42/ 1097] train: loss: 0.0767801
[Epoch 55; Iter    72/ 1097] train: loss: 0.0116885
[Epoch 55; Iter   102/ 1097] train: loss: 0.0206588
[Epoch 55; Iter   132/ 1097] train: loss: 0.3039365
[Epoch 55; Iter   162/ 1097] train: loss: 0.0092677
[Epoch 55; Iter   192/ 1097] train: loss: 0.0178467
[Epoch 55; Iter   222/ 1097] train: loss: 0.0525942
[Epoch 55; Iter   252/ 1097] train: loss: 0.0236547
[Epoch 55; Iter   282/ 1097] train: loss: 0.0197933
[Epoch 55; Iter   312/ 1097] train: loss: 0.0899530
[Epoch 55; Iter   342/ 1097] train: loss: 0.0185423
[Epoch 55; Iter   372/ 1097] train: loss: 0.0625047
[Epoch 55; Iter   402/ 1097] train: loss: 0.0946531
[Epoch 55; Iter   432/ 1097] train: loss: 0.0077021
[Epoch 55; Iter   462/ 1097] train: loss: 0.0206475
[Epoch 55; Iter   492/ 1097] train: loss: 0.0120298
[Epoch 55; Iter   522/ 1097] train: loss: 0.0934648
[Epoch 55; Iter   552/ 1097] train: loss: 0.0086872
[Epoch 55; Iter   582/ 1097] train: loss: 0.0696067
[Epoch 55; Iter   612/ 1097] train: loss: 0.0378997
[Epoch 55; Iter   642/ 1097] train: loss: 0.0078725
[Epoch 55; Iter   672/ 1097] train: loss: 0.0321634
[Epoch 55; Iter   702/ 1097] train: loss: 0.0193946
[Epoch 55; Iter   732/ 1097] train: loss: 0.0774340
[Epoch 55; Iter   762/ 1097] train: loss: 0.0348143
[Epoch 55; Iter   792/ 1097] train: loss: 0.1303917
[Epoch 55; Iter   822/ 1097] train: loss: 0.0686496
[Epoch 55; Iter   852/ 1097] train: loss: 0.0135020
[Epoch 55; Iter   882/ 1097] train: loss: 0.1377510
[Epoch 55; Iter   912/ 1097] train: loss: 0.0058270
[Epoch 55; Iter   942/ 1097] train: loss: 0.0116281
[Epoch 55; Iter   972/ 1097] train: loss: 0.0424422
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0062469
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0122183
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0585714
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0867155
[Epoch 55] ogbg-molhiv: 0.793237 val loss: 0.094767
[Epoch 55] ogbg-molhiv: 0.750424 test loss: 0.189764
[Epoch 56; Iter    25/ 1097] train: loss: 0.0125890
[Epoch 56; Iter    55/ 1097] train: loss: 0.0148540
[Epoch 56; Iter    85/ 1097] train: loss: 0.0862815
[Epoch 56; Iter   115/ 1097] train: loss: 0.0109276
[Epoch 56; Iter   145/ 1097] train: loss: 0.0144797
[Epoch 56; Iter   175/ 1097] train: loss: 0.0053068
[Epoch 56; Iter   205/ 1097] train: loss: 0.0101972
[Epoch 56; Iter   235/ 1097] train: loss: 0.0066899
[Epoch 56; Iter   265/ 1097] train: loss: 0.0125745
[Epoch 56; Iter   295/ 1097] train: loss: 0.0058806
[Epoch 56; Iter   325/ 1097] train: loss: 0.0111717
[Epoch 56; Iter   355/ 1097] train: loss: 0.0283057
[Epoch 56; Iter   385/ 1097] train: loss: 0.0367908
[Epoch 56; Iter   415/ 1097] train: loss: 0.0166217
[Epoch 56; Iter   445/ 1097] train: loss: 0.0806011
[Epoch 56; Iter   475/ 1097] train: loss: 0.0102025
[Epoch 56; Iter   505/ 1097] train: loss: 0.1472638
[Epoch 56; Iter   535/ 1097] train: loss: 0.0131782
[Epoch 56; Iter   565/ 1097] train: loss: 0.1577095
[Epoch 56; Iter   595/ 1097] train: loss: 0.1051658
[Epoch 56; Iter   625/ 1097] train: loss: 0.0227928
[Epoch 56; Iter   655/ 1097] train: loss: 0.0139231
[Epoch 56; Iter   685/ 1097] train: loss: 0.0152692
[Epoch 56; Iter   715/ 1097] train: loss: 0.0046772
[Epoch 56; Iter   745/ 1097] train: loss: 0.0622112
[Epoch 56; Iter   775/ 1097] train: loss: 0.1772674
[Epoch 56; Iter   805/ 1097] train: loss: 0.0411629
[Epoch 56; Iter   835/ 1097] train: loss: 0.0279873
[Epoch 56; Iter   865/ 1097] train: loss: 0.1333609
[Epoch 56; Iter   895/ 1097] train: loss: 0.0432230
[Epoch 56; Iter   925/ 1097] train: loss: 0.0047061
[Epoch 56; Iter   955/ 1097] train: loss: 0.0365206
[Epoch 56; Iter   985/ 1097] train: loss: 0.0061180
[Epoch 65; Iter    22/ 1097] train: loss: 0.0112965
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000336
[Epoch 65; Iter    82/ 1097] train: loss: 0.0002147
[Epoch 65; Iter   112/ 1097] train: loss: 0.0007204
[Epoch 65; Iter   142/ 1097] train: loss: 0.0161064
[Epoch 65; Iter   172/ 1097] train: loss: 0.0484706
[Epoch 65; Iter   202/ 1097] train: loss: 0.0008593
[Epoch 65; Iter   232/ 1097] train: loss: 0.0010263
[Epoch 65; Iter   262/ 1097] train: loss: 0.0040614
[Epoch 65; Iter   292/ 1097] train: loss: 0.0000384
[Epoch 65; Iter   322/ 1097] train: loss: 0.0017669
[Epoch 65; Iter   352/ 1097] train: loss: 0.0073320
[Epoch 65; Iter   382/ 1097] train: loss: 0.0020137
[Epoch 65; Iter   412/ 1097] train: loss: 0.0011137
[Epoch 65; Iter   442/ 1097] train: loss: 0.0005372
[Epoch 65; Iter   472/ 1097] train: loss: 0.0004052
[Epoch 65; Iter   502/ 1097] train: loss: 0.0105671
[Epoch 65; Iter   532/ 1097] train: loss: 0.0000115
[Epoch 65; Iter   562/ 1097] train: loss: 0.0005762
[Epoch 65; Iter   592/ 1097] train: loss: 0.0002875
[Epoch 65; Iter   622/ 1097] train: loss: 0.0049650
[Epoch 65; Iter   652/ 1097] train: loss: 0.0016585
[Epoch 65; Iter   682/ 1097] train: loss: 0.0013297
[Epoch 65; Iter   712/ 1097] train: loss: 0.0005276
[Epoch 65; Iter   742/ 1097] train: loss: 0.0001314
[Epoch 65; Iter   772/ 1097] train: loss: 0.0004642
[Epoch 65; Iter   802/ 1097] train: loss: 0.0000315
[Epoch 65; Iter   832/ 1097] train: loss: 0.0000757
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001704
[Epoch 65; Iter   892/ 1097] train: loss: 0.0029428
[Epoch 65; Iter   922/ 1097] train: loss: 0.0007188
[Epoch 65; Iter   952/ 1097] train: loss: 0.0001473
[Epoch 65; Iter   982/ 1097] train: loss: 0.0244644
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0039430
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000147
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0093797
[Epoch 65] ogbg-molhiv: 0.775230 val loss: 3.883363
[Epoch 65] ogbg-molhiv: 0.736420 test loss: 7.703512
[Epoch 66; Iter     5/ 1097] train: loss: 0.0000565
[Epoch 66; Iter    35/ 1097] train: loss: 0.0002927
[Epoch 66; Iter    65/ 1097] train: loss: 0.0001299
[Epoch 66; Iter    95/ 1097] train: loss: 0.0002723
[Epoch 66; Iter   125/ 1097] train: loss: 0.0000390
[Epoch 66; Iter   155/ 1097] train: loss: 0.0020063
[Epoch 66; Iter   185/ 1097] train: loss: 0.0006966
[Epoch 66; Iter   215/ 1097] train: loss: 0.0014056
[Epoch 66; Iter   245/ 1097] train: loss: 0.0051437
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000445
[Epoch 66; Iter   305/ 1097] train: loss: 0.0294834
[Epoch 66; Iter   335/ 1097] train: loss: 0.0059670
[Epoch 66; Iter   365/ 1097] train: loss: 0.0033834
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002331
[Epoch 66; Iter   425/ 1097] train: loss: 0.0002989
[Epoch 66; Iter   455/ 1097] train: loss: 0.0012200
[Epoch 66; Iter   485/ 1097] train: loss: 0.0001044
[Epoch 66; Iter   515/ 1097] train: loss: 0.0006096
[Epoch 66; Iter   545/ 1097] train: loss: 0.0000751
[Epoch 66; Iter   575/ 1097] train: loss: 0.0002540
[Epoch 66; Iter   605/ 1097] train: loss: 0.0025412
[Epoch 66; Iter   635/ 1097] train: loss: 0.0013113
[Epoch 66; Iter   665/ 1097] train: loss: 0.0002186
[Epoch 66; Iter   695/ 1097] train: loss: 0.0001750
[Epoch 66; Iter   725/ 1097] train: loss: 0.0019992
[Epoch 66; Iter   755/ 1097] train: loss: 0.0091990
[Epoch 66; Iter   785/ 1097] train: loss: 0.0002497
[Epoch 66; Iter   815/ 1097] train: loss: 0.0012449
[Epoch 66; Iter   845/ 1097] train: loss: 0.0018417
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000097
[Epoch 66; Iter   905/ 1097] train: loss: 0.0027277
[Epoch 66; Iter   935/ 1097] train: loss: 0.0000516
[Epoch 66; Iter   965/ 1097] train: loss: 0.0080984
[Epoch 66; Iter   995/ 1097] train: loss: 0.0000171
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0024577
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0034395
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0000087
[Epoch 66] ogbg-molhiv: 0.764832 val loss: 5.653968
[Epoch 66] ogbg-molhiv: 0.700848 test loss: 4.891059
[Epoch 67; Iter    18/ 1097] train: loss: 0.0162472
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000897
[Epoch 67; Iter    78/ 1097] train: loss: 0.0024890
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003586
[Epoch 67; Iter   138/ 1097] train: loss: 0.0002012
[Epoch 67; Iter   168/ 1097] train: loss: 0.0000275
[Epoch 67; Iter   198/ 1097] train: loss: 0.0002079
[Epoch 67; Iter   228/ 1097] train: loss: 0.0006653
[Epoch 67; Iter   258/ 1097] train: loss: 0.0002392
[Epoch 67; Iter   288/ 1097] train: loss: 0.0024040
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001717
[Epoch 67; Iter   348/ 1097] train: loss: 0.0000900
[Epoch 67; Iter   378/ 1097] train: loss: 0.0000667
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000219
[Epoch 67; Iter   438/ 1097] train: loss: 0.0018757
[Epoch 67; Iter   468/ 1097] train: loss: 0.0349594
[Epoch 67; Iter   498/ 1097] train: loss: 0.0000737
[Epoch 67; Iter   528/ 1097] train: loss: 0.0005050
[Epoch 67; Iter   558/ 1097] train: loss: 0.1065334
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000098
[Epoch 67; Iter   618/ 1097] train: loss: 0.0000265
[Epoch 67; Iter   648/ 1097] train: loss: 0.0010273
[Epoch 67; Iter   678/ 1097] train: loss: 0.0006216
[Epoch 67; Iter   708/ 1097] train: loss: 0.0047170
[Epoch 67; Iter   738/ 1097] train: loss: 0.0001779
[Epoch 67; Iter   768/ 1097] train: loss: 0.0001832
[Epoch 67; Iter   798/ 1097] train: loss: 0.0008556
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000085
[Epoch 67; Iter   858/ 1097] train: loss: 0.0001339
[Epoch 67; Iter   888/ 1097] train: loss: 0.0001474
[Epoch 67; Iter   918/ 1097] train: loss: 0.0001374
[Epoch 67; Iter   948/ 1097] train: loss: 0.0083964
[Epoch 67; Iter   978/ 1097] train: loss: 0.0002896
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0004420
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0003120
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000244
[Epoch 67] ogbg-molhiv: 0.737881 val loss: 3.363085
[Epoch 67] ogbg-molhiv: 0.725165 test loss: 4.598067
[Epoch 68; Iter     1/ 1097] train: loss: 0.0006357
[Epoch 68; Iter    31/ 1097] train: loss: 0.0000956
[Epoch 68; Iter    61/ 1097] train: loss: 0.0009101
[Epoch 68; Iter    91/ 1097] train: loss: 0.0003910
[Epoch 68; Iter   121/ 1097] train: loss: 0.0003103
[Epoch 68; Iter   151/ 1097] train: loss: 0.0001010
[Epoch 68; Iter   181/ 1097] train: loss: 0.0025338
[Epoch 68; Iter   211/ 1097] train: loss: 0.0002285
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002718
[Epoch 68; Iter   271/ 1097] train: loss: 0.0001642
[Epoch 68; Iter   301/ 1097] train: loss: 0.0014551
[Epoch 68; Iter   331/ 1097] train: loss: 0.0000144
[Epoch 68; Iter   361/ 1097] train: loss: 0.0000913
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000578
[Epoch 68; Iter   421/ 1097] train: loss: 0.0007945
[Epoch 68; Iter   451/ 1097] train: loss: 0.0005968
[Epoch 68; Iter   481/ 1097] train: loss: 0.0072760
[Epoch 68; Iter   511/ 1097] train: loss: 0.0048310
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000226
[Epoch 68; Iter   571/ 1097] train: loss: 0.0003039
[Epoch 68; Iter   601/ 1097] train: loss: 0.0006730
[Epoch 68; Iter   631/ 1097] train: loss: 0.0000009
[Epoch 68; Iter   661/ 1097] train: loss: 0.0000265
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000083
[Epoch 68; Iter   721/ 1097] train: loss: 0.0021652
[Epoch 68; Iter   751/ 1097] train: loss: 0.0004508
[Epoch 68; Iter   781/ 1097] train: loss: 0.0008390
[Epoch 68; Iter   811/ 1097] train: loss: 0.0004593
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000215
[Epoch 68; Iter   871/ 1097] train: loss: 0.0000405
[Epoch 68; Iter   901/ 1097] train: loss: 0.0042803
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000024
[Epoch 68; Iter   961/ 1097] train: loss: 0.0079138
[Epoch 68; Iter   991/ 1097] train: loss: 0.0006383
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0016454
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0041856
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0025315
[Epoch 68] ogbg-molhiv: 0.756081 val loss: 4.206703
[Epoch 68] ogbg-molhiv: 0.747716 test loss: 8.602781
[Epoch 69; Iter    14/ 1097] train: loss: 0.0001767
[Epoch 69; Iter    44/ 1097] train: loss: 0.0000022
[Epoch 69; Iter    74/ 1097] train: loss: 0.0012034
[Epoch 65; Iter    22/ 1097] train: loss: 0.0003766
[Epoch 65; Iter    52/ 1097] train: loss: 0.0002733
[Epoch 65; Iter    82/ 1097] train: loss: 0.0030551
[Epoch 65; Iter   112/ 1097] train: loss: 0.0002200
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000283
[Epoch 65; Iter   172/ 1097] train: loss: 0.0003123
[Epoch 65; Iter   202/ 1097] train: loss: 0.0001147
[Epoch 65; Iter   232/ 1097] train: loss: 0.0153291
[Epoch 65; Iter   262/ 1097] train: loss: 0.0006079
[Epoch 65; Iter   292/ 1097] train: loss: 0.0001607
[Epoch 65; Iter   322/ 1097] train: loss: 0.0032798
[Epoch 65; Iter   352/ 1097] train: loss: 0.0003319
[Epoch 65; Iter   382/ 1097] train: loss: 0.0001760
[Epoch 65; Iter   412/ 1097] train: loss: 0.0000364
[Epoch 65; Iter   442/ 1097] train: loss: 0.0003256
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000325
[Epoch 65; Iter   502/ 1097] train: loss: 0.0107720
[Epoch 65; Iter   532/ 1097] train: loss: 0.0004437
[Epoch 65; Iter   562/ 1097] train: loss: 0.0001930
[Epoch 65; Iter   592/ 1097] train: loss: 0.0023803
[Epoch 65; Iter   622/ 1097] train: loss: 0.0008265
[Epoch 65; Iter   652/ 1097] train: loss: 0.0001082
[Epoch 65; Iter   682/ 1097] train: loss: 0.0080991
[Epoch 65; Iter   712/ 1097] train: loss: 0.0015592
[Epoch 65; Iter   742/ 1097] train: loss: 0.0035605
[Epoch 65; Iter   772/ 1097] train: loss: 0.0002094
[Epoch 65; Iter   802/ 1097] train: loss: 0.0450282
[Epoch 65; Iter   832/ 1097] train: loss: 0.0046948
[Epoch 65; Iter   862/ 1097] train: loss: 0.0033257
[Epoch 65; Iter   892/ 1097] train: loss: 0.0002688
[Epoch 65; Iter   922/ 1097] train: loss: 0.0031164
[Epoch 65; Iter   952/ 1097] train: loss: 0.0003129
[Epoch 65; Iter   982/ 1097] train: loss: 0.0002465
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0102130
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000197
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0003424
[Epoch 65] ogbg-molhiv: 0.659101 val loss: 22.625723
[Epoch 65] ogbg-molhiv: 0.590960 test loss: 20.141054
[Epoch 66; Iter     5/ 1097] train: loss: 0.0011598
[Epoch 66; Iter    35/ 1097] train: loss: 0.0020645
[Epoch 66; Iter    65/ 1097] train: loss: 0.0016626
[Epoch 66; Iter    95/ 1097] train: loss: 0.0009327
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003393
[Epoch 66; Iter   155/ 1097] train: loss: 0.0279320
[Epoch 66; Iter   185/ 1097] train: loss: 0.0005296
[Epoch 66; Iter   215/ 1097] train: loss: 0.0011750
[Epoch 66; Iter   245/ 1097] train: loss: 0.0186500
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000996
[Epoch 66; Iter   305/ 1097] train: loss: 0.0026337
[Epoch 66; Iter   335/ 1097] train: loss: 0.0013849
[Epoch 66; Iter   365/ 1097] train: loss: 0.0001146
[Epoch 66; Iter   395/ 1097] train: loss: 0.0000780
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022986
[Epoch 66; Iter   455/ 1097] train: loss: 0.1176651
[Epoch 66; Iter   485/ 1097] train: loss: 0.0007257
[Epoch 66; Iter   515/ 1097] train: loss: 0.0003631
[Epoch 66; Iter   545/ 1097] train: loss: 0.0017379
[Epoch 66; Iter   575/ 1097] train: loss: 0.0124084
[Epoch 66; Iter   605/ 1097] train: loss: 0.0001834
[Epoch 66; Iter   635/ 1097] train: loss: 0.0043271
[Epoch 66; Iter   665/ 1097] train: loss: 0.0018241
[Epoch 66; Iter   695/ 1097] train: loss: 0.0055945
[Epoch 66; Iter   725/ 1097] train: loss: 0.0020299
[Epoch 66; Iter   755/ 1097] train: loss: 0.0001942
[Epoch 66; Iter   785/ 1097] train: loss: 0.0176263
[Epoch 66; Iter   815/ 1097] train: loss: 0.0006783
[Epoch 66; Iter   845/ 1097] train: loss: 0.0028294
[Epoch 66; Iter   875/ 1097] train: loss: 0.0002709
[Epoch 66; Iter   905/ 1097] train: loss: 0.0016854
[Epoch 66; Iter   935/ 1097] train: loss: 0.0028575
[Epoch 66; Iter   965/ 1097] train: loss: 0.0026175
[Epoch 66; Iter   995/ 1097] train: loss: 0.0000297
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0001451
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0013169
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0001603
[Epoch 66] ogbg-molhiv: 0.656553 val loss: 153.809215
[Epoch 66] ogbg-molhiv: 0.569793 test loss: 140.881522
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000595
[Epoch 67; Iter    48/ 1097] train: loss: 0.0011265
[Epoch 67; Iter    78/ 1097] train: loss: 0.0022108
[Epoch 67; Iter   108/ 1097] train: loss: 0.0000732
[Epoch 67; Iter   138/ 1097] train: loss: 0.0021005
[Epoch 67; Iter   168/ 1097] train: loss: 0.0824282
[Epoch 67; Iter   198/ 1097] train: loss: 0.0024527
[Epoch 67; Iter   228/ 1097] train: loss: 0.0040344
[Epoch 67; Iter   258/ 1097] train: loss: 0.0110572
[Epoch 67; Iter   288/ 1097] train: loss: 0.0000879
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001007
[Epoch 67; Iter   348/ 1097] train: loss: 0.0001738
[Epoch 67; Iter   378/ 1097] train: loss: 0.0011122
[Epoch 67; Iter   408/ 1097] train: loss: 0.0003808
[Epoch 67; Iter   438/ 1097] train: loss: 0.0001732
[Epoch 67; Iter   468/ 1097] train: loss: 0.0031580
[Epoch 67; Iter   498/ 1097] train: loss: 0.0050815
[Epoch 67; Iter   528/ 1097] train: loss: 0.0096694
[Epoch 67; Iter   558/ 1097] train: loss: 0.0034084
[Epoch 67; Iter   588/ 1097] train: loss: 0.0001113
[Epoch 67; Iter   618/ 1097] train: loss: 0.0014797
[Epoch 67; Iter   648/ 1097] train: loss: 0.0000167
[Epoch 67; Iter   678/ 1097] train: loss: 0.0009770
[Epoch 67; Iter   708/ 1097] train: loss: 0.0000670
[Epoch 67; Iter   738/ 1097] train: loss: 0.0009835
[Epoch 67; Iter   768/ 1097] train: loss: 0.0086570
[Epoch 67; Iter   798/ 1097] train: loss: 0.0058914
[Epoch 67; Iter   828/ 1097] train: loss: 0.0001595
[Epoch 67; Iter   858/ 1097] train: loss: 0.0003356
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000183
[Epoch 67; Iter   918/ 1097] train: loss: 0.0018096
[Epoch 67; Iter   948/ 1097] train: loss: 0.0009892
[Epoch 67; Iter   978/ 1097] train: loss: 0.0023168
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000860
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000757
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0003662
[Epoch 67] ogbg-molhiv: 0.709512 val loss: 13.370313
[Epoch 67] ogbg-molhiv: 0.639300 test loss: 13.987558
[Epoch 68; Iter     1/ 1097] train: loss: 0.0000520
[Epoch 68; Iter    31/ 1097] train: loss: 0.0013257
[Epoch 68; Iter    61/ 1097] train: loss: 0.0010650
[Epoch 68; Iter    91/ 1097] train: loss: 0.0004700
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000482
[Epoch 68; Iter   151/ 1097] train: loss: 0.0002078
[Epoch 68; Iter   181/ 1097] train: loss: 0.0000258
[Epoch 68; Iter   211/ 1097] train: loss: 0.0001344
[Epoch 68; Iter   241/ 1097] train: loss: 0.0052047
[Epoch 68; Iter   271/ 1097] train: loss: 0.0018003
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000519
[Epoch 68; Iter   331/ 1097] train: loss: 0.0004594
[Epoch 68; Iter   361/ 1097] train: loss: 0.0205388
[Epoch 68; Iter   391/ 1097] train: loss: 0.0033270
[Epoch 68; Iter   421/ 1097] train: loss: 0.0000630
[Epoch 68; Iter   451/ 1097] train: loss: 0.0007594
[Epoch 68; Iter   481/ 1097] train: loss: 0.0000316
[Epoch 68; Iter   511/ 1097] train: loss: 0.0057732
[Epoch 68; Iter   541/ 1097] train: loss: 0.0039651
[Epoch 68; Iter   571/ 1097] train: loss: 0.0000245
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000502
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002509
[Epoch 68; Iter   661/ 1097] train: loss: 0.0029221
[Epoch 68; Iter   691/ 1097] train: loss: 0.0001520
[Epoch 68; Iter   721/ 1097] train: loss: 0.0000753
[Epoch 68; Iter   751/ 1097] train: loss: 0.0013585
[Epoch 68; Iter   781/ 1097] train: loss: 0.0076448
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001452
[Epoch 68; Iter   841/ 1097] train: loss: 0.0012323
[Epoch 68; Iter   871/ 1097] train: loss: 0.0006464
[Epoch 68; Iter   901/ 1097] train: loss: 0.0065077
[Epoch 68; Iter   931/ 1097] train: loss: 0.0001888
[Epoch 68; Iter   961/ 1097] train: loss: 0.0006579
[Epoch 68; Iter   991/ 1097] train: loss: 0.0001360
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0003808
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003550
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0115134
[Epoch 68] ogbg-molhiv: 0.635864 val loss: 90.254602
[Epoch 68] ogbg-molhiv: 0.548508 test loss: 84.998088
[Epoch 69; Iter    14/ 1097] train: loss: 0.0010024
[Epoch 69; Iter    44/ 1097] train: loss: 0.0022517
[Epoch 69; Iter    74/ 1097] train: loss: 0.0040211
[Epoch 69; Iter   104/ 1097] train: loss: 0.0007263
[Epoch 69; Iter   134/ 1097] train: loss: 0.0035205
[Epoch 69; Iter   164/ 1097] train: loss: 0.0009192
[Epoch 69; Iter   194/ 1097] train: loss: 0.0009453
[Epoch 69; Iter   224/ 1097] train: loss: 0.0058850
[Epoch 69; Iter   254/ 1097] train: loss: 0.0057621
[Epoch 69; Iter   284/ 1097] train: loss: 0.0005302
[Epoch 69; Iter   314/ 1097] train: loss: 0.0153769
[Epoch 69; Iter   344/ 1097] train: loss: 0.0001636
[Epoch 69; Iter   374/ 1097] train: loss: 0.0156050
[Epoch 69; Iter   404/ 1097] train: loss: 0.0013450
[Epoch 69; Iter   434/ 1097] train: loss: 0.0007221
[Epoch 69; Iter   464/ 1097] train: loss: 0.0600988
[Epoch 69; Iter   494/ 1097] train: loss: 0.0015433
[Epoch 69; Iter   524/ 1097] train: loss: 0.0001606
[Epoch 69; Iter   554/ 1097] train: loss: 0.0020615
[Epoch 69; Iter   584/ 1097] train: loss: 0.0001812
[Epoch 69; Iter   614/ 1097] train: loss: 0.0012693
[Epoch 69; Iter   644/ 1097] train: loss: 0.0035859
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001430
[Epoch 69; Iter   704/ 1097] train: loss: 0.0002820
[Epoch 69; Iter   734/ 1097] train: loss: 0.0246074
[Epoch 69; Iter   764/ 1097] train: loss: 0.0002150
[Epoch 69; Iter   794/ 1097] train: loss: 0.0501385
[Epoch 69; Iter   824/ 1097] train: loss: 0.0004365
[Epoch 69; Iter   854/ 1097] train: loss: 0.0104768
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000344
[Epoch 69; Iter   914/ 1097] train: loss: 0.0016509
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001123
[Epoch 69; Iter   974/ 1097] train: loss: 0.0012190
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0002874
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0106926
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0933852
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0047052
[Epoch 69] ogbg-molhiv: 0.739455 val loss: 1.288482
[Epoch 69] ogbg-molhiv: 0.720682 test loss: 1.108166
[Epoch 70; Iter    27/ 1097] train: loss: 0.0009370
[Epoch 70; Iter    57/ 1097] train: loss: 0.0008185
[Epoch 70; Iter    87/ 1097] train: loss: 0.0115331
[Epoch 70; Iter   117/ 1097] train: loss: 0.1025309
[Epoch 70; Iter   147/ 1097] train: loss: 0.0066912
[Epoch 70; Iter   177/ 1097] train: loss: 0.0044500
[Epoch 70; Iter   207/ 1097] train: loss: 0.0005004
[Epoch 70; Iter   237/ 1097] train: loss: 0.0091454
[Epoch 70; Iter   267/ 1097] train: loss: 0.0116563
[Epoch 70; Iter   297/ 1097] train: loss: 0.0003898
[Epoch 70; Iter   327/ 1097] train: loss: 0.0010451
[Epoch 70; Iter   357/ 1097] train: loss: 0.0043861
[Epoch 70; Iter   387/ 1097] train: loss: 0.0008210
[Epoch 70; Iter   417/ 1097] train: loss: 0.0003040
[Epoch 70; Iter   447/ 1097] train: loss: 0.0017099
[Epoch 70; Iter   477/ 1097] train: loss: 0.0012634
[Epoch 70; Iter   507/ 1097] train: loss: 0.0040883
[Epoch 70; Iter   537/ 1097] train: loss: 0.0026284
[Epoch 70; Iter   567/ 1097] train: loss: 0.0008567
[Epoch 70; Iter   597/ 1097] train: loss: 0.0015793
[Epoch 70; Iter   627/ 1097] train: loss: 0.0005620
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001149
[Epoch 70; Iter   687/ 1097] train: loss: 0.0002498
[Epoch 70; Iter   717/ 1097] train: loss: 0.0021811
[Epoch 70; Iter   747/ 1097] train: loss: 0.0004124
[Epoch 70; Iter   777/ 1097] train: loss: 0.0005135
[Epoch 70; Iter   807/ 1097] train: loss: 0.0002699
[Epoch 70; Iter   837/ 1097] train: loss: 0.0007545
[Epoch 70; Iter   867/ 1097] train: loss: 0.0206099
[Epoch 70; Iter   897/ 1097] train: loss: 0.0004337
[Epoch 70; Iter   927/ 1097] train: loss: 0.0007314
[Epoch 70; Iter   957/ 1097] train: loss: 0.0007811
[Epoch 70; Iter   987/ 1097] train: loss: 0.0151008
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0003920
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0002069
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000684
[Epoch 70] ogbg-molhiv: 0.692552 val loss: 1.719021
[Epoch 70] ogbg-molhiv: 0.730870 test loss: 0.355478
[Epoch 71; Iter    10/ 1097] train: loss: 0.0014314
[Epoch 71; Iter    40/ 1097] train: loss: 0.0017522
[Epoch 71; Iter    70/ 1097] train: loss: 0.0044620
[Epoch 71; Iter   100/ 1097] train: loss: 0.1175425
[Epoch 71; Iter   130/ 1097] train: loss: 0.0061387
[Epoch 71; Iter   160/ 1097] train: loss: 0.0002214
[Epoch 71; Iter   190/ 1097] train: loss: 0.0008966
[Epoch 71; Iter   220/ 1097] train: loss: 0.0101896
[Epoch 71; Iter   250/ 1097] train: loss: 0.0002770
[Epoch 71; Iter   280/ 1097] train: loss: 0.0199207
[Epoch 71; Iter   310/ 1097] train: loss: 0.0017141
[Epoch 71; Iter   340/ 1097] train: loss: 0.0065737
[Epoch 71; Iter   370/ 1097] train: loss: 0.0006802
[Epoch 71; Iter   400/ 1097] train: loss: 0.0006638
[Epoch 71; Iter   430/ 1097] train: loss: 0.0009348
[Epoch 71; Iter   460/ 1097] train: loss: 0.0017727
[Epoch 71; Iter   490/ 1097] train: loss: 0.0023319
[Epoch 71; Iter   520/ 1097] train: loss: 0.0058213
[Epoch 71; Iter   550/ 1097] train: loss: 0.0038722
[Epoch 71; Iter   580/ 1097] train: loss: 0.0016291
[Epoch 71; Iter   610/ 1097] train: loss: 0.0002619
[Epoch 71; Iter   640/ 1097] train: loss: 0.0002986
[Epoch 71; Iter   670/ 1097] train: loss: 0.0000490
[Epoch 71; Iter   700/ 1097] train: loss: 0.0064164
[Epoch 71; Iter   730/ 1097] train: loss: 0.0011999
[Epoch 71; Iter   760/ 1097] train: loss: 0.0421643
[Epoch 71; Iter   790/ 1097] train: loss: 0.0002317
[Epoch 71; Iter   820/ 1097] train: loss: 0.0004879
[Epoch 71; Iter   850/ 1097] train: loss: 0.0007767
[Epoch 71; Iter   880/ 1097] train: loss: 0.0341415
[Epoch 71; Iter   910/ 1097] train: loss: 0.0001584
[Epoch 71; Iter   940/ 1097] train: loss: 0.0008396
[Epoch 71; Iter   970/ 1097] train: loss: 0.0134558
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0126219
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0001934
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0003389
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0032958
[Epoch 71] ogbg-molhiv: 0.724944 val loss: 1.287376
[Epoch 71] ogbg-molhiv: 0.746648 test loss: 1.067407
[Epoch 72; Iter    23/ 1097] train: loss: 0.0109095
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000613
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000577
[Epoch 72; Iter   113/ 1097] train: loss: 0.0003476
[Epoch 72; Iter   143/ 1097] train: loss: 0.0015509
[Epoch 72; Iter   173/ 1097] train: loss: 0.0004682
[Epoch 72; Iter   203/ 1097] train: loss: 0.0003133
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000581
[Epoch 72; Iter   263/ 1097] train: loss: 0.0104281
[Epoch 72; Iter   293/ 1097] train: loss: 0.0118264
[Epoch 72; Iter   323/ 1097] train: loss: 0.0002523
[Epoch 72; Iter   353/ 1097] train: loss: 0.0332795
[Epoch 72; Iter   383/ 1097] train: loss: 0.0003710
[Epoch 72; Iter   413/ 1097] train: loss: 0.0010468
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001391
[Epoch 72; Iter   473/ 1097] train: loss: 0.0038803
[Epoch 72; Iter   503/ 1097] train: loss: 0.0322665
[Epoch 72; Iter   533/ 1097] train: loss: 0.0028199
[Epoch 72; Iter   563/ 1097] train: loss: 0.0007100
[Epoch 72; Iter   593/ 1097] train: loss: 0.0002406
[Epoch 72; Iter   623/ 1097] train: loss: 0.0064564
[Epoch 72; Iter   653/ 1097] train: loss: 0.0001128
[Epoch 72; Iter   683/ 1097] train: loss: 0.0010495
[Epoch 72; Iter   713/ 1097] train: loss: 0.0067762
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000115
[Epoch 72; Iter   773/ 1097] train: loss: 0.0411503
[Epoch 72; Iter   803/ 1097] train: loss: 0.0012431
[Epoch 72; Iter   833/ 1097] train: loss: 0.0126984
[Epoch 72; Iter   863/ 1097] train: loss: 0.0048252
[Epoch 72; Iter   893/ 1097] train: loss: 0.0009480
[Epoch 72; Iter   923/ 1097] train: loss: 0.0033692
[Epoch 72; Iter   953/ 1097] train: loss: 0.0051663
[Epoch 72; Iter   983/ 1097] train: loss: 0.0007818
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000991
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0022892
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0272122
[Epoch 72] ogbg-molhiv: 0.744565 val loss: 2.595115
[Epoch 72] ogbg-molhiv: 0.721045 test loss: 1.990519
[Epoch 73; Iter     6/ 1097] train: loss: 0.0012042
[Epoch 73; Iter    36/ 1097] train: loss: 0.0255287
[Epoch 73; Iter    66/ 1097] train: loss: 0.0002008
[Epoch 73; Iter    96/ 1097] train: loss: 0.0000529
[Epoch 73; Iter   126/ 1097] train: loss: 0.0007028
[Epoch 73; Iter   156/ 1097] train: loss: 0.0052184
[Epoch 69; Iter   104/ 1097] train: loss: 0.0001673
[Epoch 69; Iter   134/ 1097] train: loss: 0.0002051
[Epoch 69; Iter   164/ 1097] train: loss: 0.0011977
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000102
[Epoch 69; Iter   224/ 1097] train: loss: 0.0003488
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000731
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001849
[Epoch 69; Iter   314/ 1097] train: loss: 0.0000364
[Epoch 69; Iter   344/ 1097] train: loss: 0.0000048
[Epoch 69; Iter   374/ 1097] train: loss: 0.0000617
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001165
[Epoch 69; Iter   434/ 1097] train: loss: 0.0004152
[Epoch 69; Iter   464/ 1097] train: loss: 0.0006867
[Epoch 69; Iter   494/ 1097] train: loss: 0.0115619
[Epoch 69; Iter   524/ 1097] train: loss: 0.0002551
[Epoch 69; Iter   554/ 1097] train: loss: 0.0184268
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000689
[Epoch 69; Iter   614/ 1097] train: loss: 0.0002222
[Epoch 69; Iter   644/ 1097] train: loss: 0.0002244
[Epoch 69; Iter   674/ 1097] train: loss: 0.0005110
[Epoch 69; Iter   704/ 1097] train: loss: 0.0005317
[Epoch 69; Iter   734/ 1097] train: loss: 0.0034322
[Epoch 69; Iter   764/ 1097] train: loss: 0.0064859
[Epoch 69; Iter   794/ 1097] train: loss: 0.0005520
[Epoch 69; Iter   824/ 1097] train: loss: 0.0008224
[Epoch 69; Iter   854/ 1097] train: loss: 0.0009687
[Epoch 69; Iter   884/ 1097] train: loss: 0.0632592
[Epoch 69; Iter   914/ 1097] train: loss: 0.0005226
[Epoch 69; Iter   944/ 1097] train: loss: 0.0272598
[Epoch 69; Iter   974/ 1097] train: loss: 0.0035855
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0002081
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0000422
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0001762
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0003767
[Epoch 69] ogbg-molhiv: 0.776568 val loss: 0.210211
[Epoch 69] ogbg-molhiv: 0.726661 test loss: 0.333000
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000931
[Epoch 70; Iter    57/ 1097] train: loss: 0.0001254
[Epoch 70; Iter    87/ 1097] train: loss: 0.0029995
[Epoch 70; Iter   117/ 1097] train: loss: 0.0002608
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000510
[Epoch 70; Iter   177/ 1097] train: loss: 0.0001136
[Epoch 70; Iter   207/ 1097] train: loss: 0.0011424
[Epoch 70; Iter   237/ 1097] train: loss: 0.0000895
[Epoch 70; Iter   267/ 1097] train: loss: 0.0005480
[Epoch 70; Iter   297/ 1097] train: loss: 0.0001101
[Epoch 70; Iter   327/ 1097] train: loss: 0.0002531
[Epoch 70; Iter   357/ 1097] train: loss: 0.0065079
[Epoch 70; Iter   387/ 1097] train: loss: 0.0005731
[Epoch 70; Iter   417/ 1097] train: loss: 0.0016818
[Epoch 70; Iter   447/ 1097] train: loss: 0.0008193
[Epoch 70; Iter   477/ 1097] train: loss: 0.0000442
[Epoch 70; Iter   507/ 1097] train: loss: 0.0006640
[Epoch 70; Iter   537/ 1097] train: loss: 0.0005551
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000227
[Epoch 70; Iter   597/ 1097] train: loss: 0.0002376
[Epoch 70; Iter   627/ 1097] train: loss: 0.0091126
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000217
[Epoch 70; Iter   687/ 1097] train: loss: 0.0009878
[Epoch 70; Iter   717/ 1097] train: loss: 0.0002123
[Epoch 70; Iter   747/ 1097] train: loss: 0.0014264
[Epoch 70; Iter   777/ 1097] train: loss: 0.0004924
[Epoch 70; Iter   807/ 1097] train: loss: 0.0555258
[Epoch 70; Iter   837/ 1097] train: loss: 0.0045243
[Epoch 70; Iter   867/ 1097] train: loss: 0.0011934
[Epoch 70; Iter   897/ 1097] train: loss: 0.0003232
[Epoch 70; Iter   927/ 1097] train: loss: 0.0011192
[Epoch 70; Iter   957/ 1097] train: loss: 0.0072558
[Epoch 70; Iter   987/ 1097] train: loss: 0.0002885
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0003539
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0003008
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000225
[Epoch 70] ogbg-molhiv: 0.775218 val loss: 0.222668
[Epoch 70] ogbg-molhiv: 0.716039 test loss: 0.359029
[Epoch 71; Iter    10/ 1097] train: loss: 0.0098242
[Epoch 71; Iter    40/ 1097] train: loss: 0.0017914
[Epoch 71; Iter    70/ 1097] train: loss: 0.0027027
[Epoch 71; Iter   100/ 1097] train: loss: 0.0013942
[Epoch 71; Iter   130/ 1097] train: loss: 0.0010562
[Epoch 71; Iter   160/ 1097] train: loss: 0.0011482
[Epoch 71; Iter   190/ 1097] train: loss: 0.0002744
[Epoch 71; Iter   220/ 1097] train: loss: 0.0001604
[Epoch 71; Iter   250/ 1097] train: loss: 0.0001685
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001426
[Epoch 71; Iter   310/ 1097] train: loss: 0.0000017
[Epoch 71; Iter   340/ 1097] train: loss: 0.0000719
[Epoch 71; Iter   370/ 1097] train: loss: 0.0002528
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000155
[Epoch 71; Iter   430/ 1097] train: loss: 0.0000451
[Epoch 71; Iter   460/ 1097] train: loss: 0.0002082
[Epoch 71; Iter   490/ 1097] train: loss: 0.0001261
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000210
[Epoch 71; Iter   550/ 1097] train: loss: 0.0075487
[Epoch 71; Iter   580/ 1097] train: loss: 0.0001031
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000654
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000159
[Epoch 71; Iter   670/ 1097] train: loss: 0.0000338
[Epoch 71; Iter   700/ 1097] train: loss: 0.0001115
[Epoch 71; Iter   730/ 1097] train: loss: 0.0067081
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000869
[Epoch 71; Iter   790/ 1097] train: loss: 0.0172743
[Epoch 71; Iter   820/ 1097] train: loss: 0.0077265
[Epoch 71; Iter   850/ 1097] train: loss: 0.0011478
[Epoch 71; Iter   880/ 1097] train: loss: 0.0001934
[Epoch 71; Iter   910/ 1097] train: loss: 0.0039354
[Epoch 71; Iter   940/ 1097] train: loss: 0.0003572
[Epoch 71; Iter   970/ 1097] train: loss: 0.0012476
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0002388
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000706
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0001416
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0064904
[Epoch 71] ogbg-molhiv: 0.759529 val loss: 0.234501
[Epoch 71] ogbg-molhiv: 0.727907 test loss: 0.341285
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000577
[Epoch 72; Iter    53/ 1097] train: loss: 0.0002629
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000899
[Epoch 72; Iter   113/ 1097] train: loss: 0.0009174
[Epoch 72; Iter   143/ 1097] train: loss: 0.0005454
[Epoch 72; Iter   173/ 1097] train: loss: 0.0001705
[Epoch 72; Iter   203/ 1097] train: loss: 0.0001802
[Epoch 72; Iter   233/ 1097] train: loss: 0.0004034
[Epoch 72; Iter   263/ 1097] train: loss: 0.0012472
[Epoch 72; Iter   293/ 1097] train: loss: 0.0008079
[Epoch 72; Iter   323/ 1097] train: loss: 0.0017449
[Epoch 72; Iter   353/ 1097] train: loss: 0.0000428
[Epoch 72; Iter   383/ 1097] train: loss: 0.0060882
[Epoch 72; Iter   413/ 1097] train: loss: 0.0000058
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001190
[Epoch 72; Iter   473/ 1097] train: loss: 0.0029878
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002014
[Epoch 72; Iter   533/ 1097] train: loss: 0.0000724
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000192
[Epoch 72; Iter   593/ 1097] train: loss: 0.0001584
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000024
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000163
[Epoch 72; Iter   683/ 1097] train: loss: 0.0000566
[Epoch 72; Iter   713/ 1097] train: loss: 0.0000904
[Epoch 72; Iter   743/ 1097] train: loss: 0.0002274
[Epoch 72; Iter   773/ 1097] train: loss: 0.0376577
[Epoch 72; Iter   803/ 1097] train: loss: 0.0008541
[Epoch 72; Iter   833/ 1097] train: loss: 0.0004568
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000580
[Epoch 72; Iter   893/ 1097] train: loss: 0.0005008
[Epoch 72; Iter   923/ 1097] train: loss: 0.0000125
[Epoch 72; Iter   953/ 1097] train: loss: 0.0013796
[Epoch 72; Iter   983/ 1097] train: loss: 0.0001616
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000651
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0006025
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0029657
[Epoch 72] ogbg-molhiv: 0.746457 val loss: 0.230450
[Epoch 72] ogbg-molhiv: 0.724682 test loss: 0.370858
[Epoch 73; Iter     6/ 1097] train: loss: 0.0275577
[Epoch 73; Iter    36/ 1097] train: loss: 0.0002524
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000839
[Epoch 73; Iter    96/ 1097] train: loss: 0.0002867
[Epoch 73; Iter   126/ 1097] train: loss: 0.0010455
[Epoch 73; Iter   156/ 1097] train: loss: 0.0009879
[Epoch 69; Iter   104/ 1097] train: loss: 0.0004938
[Epoch 69; Iter   134/ 1097] train: loss: 0.0009195
[Epoch 69; Iter   164/ 1097] train: loss: 0.0006930
[Epoch 69; Iter   194/ 1097] train: loss: 0.0632817
[Epoch 69; Iter   224/ 1097] train: loss: 0.0005212
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000592
[Epoch 69; Iter   284/ 1097] train: loss: 0.0000369
[Epoch 69; Iter   314/ 1097] train: loss: 0.0013244
[Epoch 69; Iter   344/ 1097] train: loss: 0.0082277
[Epoch 69; Iter   374/ 1097] train: loss: 0.0002009
[Epoch 69; Iter   404/ 1097] train: loss: 0.0013980
[Epoch 69; Iter   434/ 1097] train: loss: 0.0003218
[Epoch 69; Iter   464/ 1097] train: loss: 0.0051819
[Epoch 69; Iter   494/ 1097] train: loss: 0.0519868
[Epoch 69; Iter   524/ 1097] train: loss: 0.0076566
[Epoch 69; Iter   554/ 1097] train: loss: 0.0002000
[Epoch 69; Iter   584/ 1097] train: loss: 0.0007547
[Epoch 69; Iter   614/ 1097] train: loss: 0.0000286
[Epoch 69; Iter   644/ 1097] train: loss: 0.0570228
[Epoch 69; Iter   674/ 1097] train: loss: 0.0004919
[Epoch 69; Iter   704/ 1097] train: loss: 0.0000640
[Epoch 69; Iter   734/ 1097] train: loss: 0.0004383
[Epoch 69; Iter   764/ 1097] train: loss: 0.0006044
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000131
[Epoch 69; Iter   824/ 1097] train: loss: 0.0007380
[Epoch 69; Iter   854/ 1097] train: loss: 0.0003334
[Epoch 69; Iter   884/ 1097] train: loss: 0.0003891
[Epoch 69; Iter   914/ 1097] train: loss: 0.0030596
[Epoch 69; Iter   944/ 1097] train: loss: 0.0000371
[Epoch 69; Iter   974/ 1097] train: loss: 0.0001652
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000735
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001751
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0067768
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0059856
[Epoch 69] ogbg-molhiv: 0.765466 val loss: 0.343090
[Epoch 69] ogbg-molhiv: 0.740439 test loss: 0.361665
[Epoch 70; Iter    27/ 1097] train: loss: 0.0744683
[Epoch 70; Iter    57/ 1097] train: loss: 0.0001302
[Epoch 70; Iter    87/ 1097] train: loss: 0.0064479
[Epoch 70; Iter   117/ 1097] train: loss: 0.0002404
[Epoch 70; Iter   147/ 1097] train: loss: 0.0001365
[Epoch 70; Iter   177/ 1097] train: loss: 0.0007743
[Epoch 70; Iter   207/ 1097] train: loss: 0.0002217
[Epoch 70; Iter   237/ 1097] train: loss: 0.0014498
[Epoch 70; Iter   267/ 1097] train: loss: 0.0000067
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000796
[Epoch 70; Iter   327/ 1097] train: loss: 0.0259521
[Epoch 70; Iter   357/ 1097] train: loss: 0.0002454
[Epoch 70; Iter   387/ 1097] train: loss: 0.0001382
[Epoch 70; Iter   417/ 1097] train: loss: 0.0001695
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000570
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001361
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000912
[Epoch 70; Iter   537/ 1097] train: loss: 0.0000384
[Epoch 70; Iter   567/ 1097] train: loss: 0.0001778
[Epoch 70; Iter   597/ 1097] train: loss: 0.0002777
[Epoch 70; Iter   627/ 1097] train: loss: 0.0289305
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001733
[Epoch 70; Iter   687/ 1097] train: loss: 0.0078694
[Epoch 70; Iter   717/ 1097] train: loss: 0.0002205
[Epoch 70; Iter   747/ 1097] train: loss: 0.0008409
[Epoch 70; Iter   777/ 1097] train: loss: 0.0010262
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001994
[Epoch 70; Iter   837/ 1097] train: loss: 0.0008787
[Epoch 70; Iter   867/ 1097] train: loss: 0.0035781
[Epoch 70; Iter   897/ 1097] train: loss: 0.0033781
[Epoch 70; Iter   927/ 1097] train: loss: 0.0016546
[Epoch 70; Iter   957/ 1097] train: loss: 0.0097912
[Epoch 70; Iter   987/ 1097] train: loss: 0.0094293
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0001951
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000674
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0028227
[Epoch 70] ogbg-molhiv: 0.766850 val loss: 0.337536
[Epoch 70] ogbg-molhiv: 0.754366 test loss: 0.348985
[Epoch 71; Iter    10/ 1097] train: loss: 0.0000223
[Epoch 71; Iter    40/ 1097] train: loss: 0.0002374
[Epoch 71; Iter    70/ 1097] train: loss: 0.0021002
[Epoch 71; Iter   100/ 1097] train: loss: 0.0007712
[Epoch 71; Iter   130/ 1097] train: loss: 0.0034977
[Epoch 71; Iter   160/ 1097] train: loss: 0.0003431
[Epoch 71; Iter   190/ 1097] train: loss: 0.0003447
[Epoch 71; Iter   220/ 1097] train: loss: 0.0002680
[Epoch 71; Iter   250/ 1097] train: loss: 0.0079932
[Epoch 71; Iter   280/ 1097] train: loss: 0.0005639
[Epoch 71; Iter   310/ 1097] train: loss: 0.0106743
[Epoch 71; Iter   340/ 1097] train: loss: 0.0001778
[Epoch 71; Iter   370/ 1097] train: loss: 0.0072084
[Epoch 71; Iter   400/ 1097] train: loss: 0.0001568
[Epoch 71; Iter   430/ 1097] train: loss: 0.0001139
[Epoch 71; Iter   460/ 1097] train: loss: 0.0006557
[Epoch 71; Iter   490/ 1097] train: loss: 0.0002700
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000589
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000911
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000594
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000482
[Epoch 71; Iter   640/ 1097] train: loss: 0.0027854
[Epoch 71; Iter   670/ 1097] train: loss: 0.0006810
[Epoch 71; Iter   700/ 1097] train: loss: 0.0029534
[Epoch 71; Iter   730/ 1097] train: loss: 0.0005561
[Epoch 71; Iter   760/ 1097] train: loss: 0.0020689
[Epoch 71; Iter   790/ 1097] train: loss: 0.0003170
[Epoch 71; Iter   820/ 1097] train: loss: 0.0021292
[Epoch 71; Iter   850/ 1097] train: loss: 0.0139178
[Epoch 71; Iter   880/ 1097] train: loss: 0.0718949
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000327
[Epoch 71; Iter   940/ 1097] train: loss: 0.0005727
[Epoch 71; Iter   970/ 1097] train: loss: 0.0004585
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0011185
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0002351
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0002693
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0001922
[Epoch 71] ogbg-molhiv: 0.730707 val loss: 0.336968
[Epoch 71] ogbg-molhiv: 0.729892 test loss: 0.348736
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000160
[Epoch 72; Iter    53/ 1097] train: loss: 0.0010701
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000907
[Epoch 72; Iter   113/ 1097] train: loss: 0.0007918
[Epoch 72; Iter   143/ 1097] train: loss: 0.0001540
[Epoch 72; Iter   173/ 1097] train: loss: 0.0004904
[Epoch 72; Iter   203/ 1097] train: loss: 0.0266065
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000145
[Epoch 72; Iter   263/ 1097] train: loss: 0.0008637
[Epoch 72; Iter   293/ 1097] train: loss: 0.0000131
[Epoch 72; Iter   323/ 1097] train: loss: 0.0009327
[Epoch 72; Iter   353/ 1097] train: loss: 0.0001746
[Epoch 72; Iter   383/ 1097] train: loss: 0.0002939
[Epoch 72; Iter   413/ 1097] train: loss: 0.0062324
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001378
[Epoch 72; Iter   473/ 1097] train: loss: 0.0043954
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002868
[Epoch 72; Iter   533/ 1097] train: loss: 0.0000544
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001439
[Epoch 72; Iter   593/ 1097] train: loss: 0.0004291
[Epoch 72; Iter   623/ 1097] train: loss: 0.0002747
[Epoch 72; Iter   653/ 1097] train: loss: 0.0113568
[Epoch 72; Iter   683/ 1097] train: loss: 0.0001896
[Epoch 72; Iter   713/ 1097] train: loss: 0.0001209
[Epoch 72; Iter   743/ 1097] train: loss: 0.0020369
[Epoch 72; Iter   773/ 1097] train: loss: 0.0003210
[Epoch 72; Iter   803/ 1097] train: loss: 0.0002771
[Epoch 72; Iter   833/ 1097] train: loss: 0.0000586
[Epoch 72; Iter   863/ 1097] train: loss: 0.0001234
[Epoch 72; Iter   893/ 1097] train: loss: 0.0019527
[Epoch 72; Iter   923/ 1097] train: loss: 0.0039918
[Epoch 72; Iter   953/ 1097] train: loss: 0.0022865
[Epoch 72; Iter   983/ 1097] train: loss: 0.0003095
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0005244
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0059638
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0313252
[Epoch 72] ogbg-molhiv: 0.723514 val loss: 0.349307
[Epoch 72] ogbg-molhiv: 0.741986 test loss: 0.349205
[Epoch 73; Iter     6/ 1097] train: loss: 0.0000305
[Epoch 73; Iter    36/ 1097] train: loss: 0.0003199
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001778
[Epoch 73; Iter    96/ 1097] train: loss: 0.0001333
[Epoch 73; Iter   126/ 1097] train: loss: 0.0015970
[Epoch 73; Iter   156/ 1097] train: loss: 0.0000069
[Epoch 69; Iter   104/ 1097] train: loss: 0.0006648
[Epoch 69; Iter   134/ 1097] train: loss: 0.0001116
[Epoch 69; Iter   164/ 1097] train: loss: 0.0009964
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000902
[Epoch 69; Iter   224/ 1097] train: loss: 0.0004433
[Epoch 69; Iter   254/ 1097] train: loss: 0.0012721
[Epoch 69; Iter   284/ 1097] train: loss: 0.0049430
[Epoch 69; Iter   314/ 1097] train: loss: 0.0015586
[Epoch 69; Iter   344/ 1097] train: loss: 0.0228493
[Epoch 69; Iter   374/ 1097] train: loss: 0.0058963
[Epoch 69; Iter   404/ 1097] train: loss: 0.0005701
[Epoch 69; Iter   434/ 1097] train: loss: 0.0112445
[Epoch 69; Iter   464/ 1097] train: loss: 0.0024172
[Epoch 69; Iter   494/ 1097] train: loss: 0.0256937
[Epoch 69; Iter   524/ 1097] train: loss: 0.0008263
[Epoch 69; Iter   554/ 1097] train: loss: 0.0319661
[Epoch 69; Iter   584/ 1097] train: loss: 0.0026685
[Epoch 69; Iter   614/ 1097] train: loss: 0.0678381
[Epoch 69; Iter   644/ 1097] train: loss: 0.0478780
[Epoch 69; Iter   674/ 1097] train: loss: 0.0180336
[Epoch 69; Iter   704/ 1097] train: loss: 0.0032415
[Epoch 69; Iter   734/ 1097] train: loss: 0.0070612
[Epoch 69; Iter   764/ 1097] train: loss: 0.0010493
[Epoch 69; Iter   794/ 1097] train: loss: 0.0039211
[Epoch 69; Iter   824/ 1097] train: loss: 0.0004285
[Epoch 69; Iter   854/ 1097] train: loss: 0.0001417
[Epoch 69; Iter   884/ 1097] train: loss: 0.0470073
[Epoch 69; Iter   914/ 1097] train: loss: 0.0001358
[Epoch 69; Iter   944/ 1097] train: loss: 0.0021166
[Epoch 69; Iter   974/ 1097] train: loss: 0.0006314
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0517977
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0195104
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0004386
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0008817
[Epoch 69] ogbg-molhiv: 0.682298 val loss: 3.664987
[Epoch 69] ogbg-molhiv: 0.704915 test loss: 1.393299
[Epoch 70; Iter    27/ 1097] train: loss: 0.0004830
[Epoch 70; Iter    57/ 1097] train: loss: 0.0029216
[Epoch 70; Iter    87/ 1097] train: loss: 0.0514242
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000765
[Epoch 70; Iter   147/ 1097] train: loss: 0.0001155
[Epoch 70; Iter   177/ 1097] train: loss: 0.0144962
[Epoch 70; Iter   207/ 1097] train: loss: 0.0009851
[Epoch 70; Iter   237/ 1097] train: loss: 0.0474392
[Epoch 70; Iter   267/ 1097] train: loss: 0.0135286
[Epoch 70; Iter   297/ 1097] train: loss: 0.0014054
[Epoch 70; Iter   327/ 1097] train: loss: 0.0011424
[Epoch 70; Iter   357/ 1097] train: loss: 0.0097297
[Epoch 70; Iter   387/ 1097] train: loss: 0.0040197
[Epoch 70; Iter   417/ 1097] train: loss: 0.0067540
[Epoch 70; Iter   447/ 1097] train: loss: 0.0004318
[Epoch 70; Iter   477/ 1097] train: loss: 0.0056723
[Epoch 70; Iter   507/ 1097] train: loss: 0.0106516
[Epoch 70; Iter   537/ 1097] train: loss: 0.0037107
[Epoch 70; Iter   567/ 1097] train: loss: 0.0024573
[Epoch 70; Iter   597/ 1097] train: loss: 0.0247738
[Epoch 70; Iter   627/ 1097] train: loss: 0.0035375
[Epoch 70; Iter   657/ 1097] train: loss: 0.0010833
[Epoch 70; Iter   687/ 1097] train: loss: 0.0485762
[Epoch 70; Iter   717/ 1097] train: loss: 0.0022578
[Epoch 70; Iter   747/ 1097] train: loss: 0.0112259
[Epoch 70; Iter   777/ 1097] train: loss: 0.0258276
[Epoch 70; Iter   807/ 1097] train: loss: 0.0410026
[Epoch 70; Iter   837/ 1097] train: loss: 0.0003138
[Epoch 70; Iter   867/ 1097] train: loss: 0.0039345
[Epoch 70; Iter   897/ 1097] train: loss: 0.0003426
[Epoch 70; Iter   927/ 1097] train: loss: 0.0013367
[Epoch 70; Iter   957/ 1097] train: loss: 0.0008582
[Epoch 70; Iter   987/ 1097] train: loss: 0.0122012
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0019852
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0002875
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0012149
[Epoch 70] ogbg-molhiv: 0.700498 val loss: 5.385252
[Epoch 70] ogbg-molhiv: 0.681684 test loss: 2.014298
[Epoch 71; Iter    10/ 1097] train: loss: 0.0493720
[Epoch 71; Iter    40/ 1097] train: loss: 0.0007992
[Epoch 71; Iter    70/ 1097] train: loss: 0.0290334
[Epoch 71; Iter   100/ 1097] train: loss: 0.0060063
[Epoch 71; Iter   130/ 1097] train: loss: 0.0036825
[Epoch 71; Iter   160/ 1097] train: loss: 0.0132434
[Epoch 71; Iter   190/ 1097] train: loss: 0.0137512
[Epoch 71; Iter   220/ 1097] train: loss: 0.0071007
[Epoch 71; Iter   250/ 1097] train: loss: 0.0681740
[Epoch 71; Iter   280/ 1097] train: loss: 0.0065764
[Epoch 71; Iter   310/ 1097] train: loss: 0.0030413
[Epoch 71; Iter   340/ 1097] train: loss: 0.0101090
[Epoch 71; Iter   370/ 1097] train: loss: 0.0017996
[Epoch 71; Iter   400/ 1097] train: loss: 0.0021417
[Epoch 71; Iter   430/ 1097] train: loss: 0.0012601
[Epoch 71; Iter   460/ 1097] train: loss: 0.0002177
[Epoch 71; Iter   490/ 1097] train: loss: 0.0009057
[Epoch 71; Iter   520/ 1097] train: loss: 0.0013715
[Epoch 71; Iter   550/ 1097] train: loss: 0.0040556
[Epoch 71; Iter   580/ 1097] train: loss: 0.0041853
[Epoch 71; Iter   610/ 1097] train: loss: 0.0097797
[Epoch 71; Iter   640/ 1097] train: loss: 0.0047909
[Epoch 71; Iter   670/ 1097] train: loss: 0.0120450
[Epoch 71; Iter   700/ 1097] train: loss: 0.0004688
[Epoch 71; Iter   730/ 1097] train: loss: 0.3050707
[Epoch 71; Iter   760/ 1097] train: loss: 0.0027240
[Epoch 71; Iter   790/ 1097] train: loss: 0.0904477
[Epoch 71; Iter   820/ 1097] train: loss: 0.0067094
[Epoch 71; Iter   850/ 1097] train: loss: 0.0049881
[Epoch 71; Iter   880/ 1097] train: loss: 0.0001184
[Epoch 71; Iter   910/ 1097] train: loss: 0.0135507
[Epoch 71; Iter   940/ 1097] train: loss: 0.0009909
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002007
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0754116
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0976288
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0241291
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0084813
[Epoch 71] ogbg-molhiv: 0.678026 val loss: 4.416862
[Epoch 71] ogbg-molhiv: 0.682756 test loss: 1.121717
[Epoch 72; Iter    23/ 1097] train: loss: 0.0012567
[Epoch 72; Iter    53/ 1097] train: loss: 0.0235507
[Epoch 72; Iter    83/ 1097] train: loss: 0.0444950
[Epoch 72; Iter   113/ 1097] train: loss: 0.0020490
[Epoch 72; Iter   143/ 1097] train: loss: 0.0099978
[Epoch 72; Iter   173/ 1097] train: loss: 0.0042034
[Epoch 72; Iter   203/ 1097] train: loss: 0.0010597
[Epoch 72; Iter   233/ 1097] train: loss: 0.0817110
[Epoch 72; Iter   263/ 1097] train: loss: 0.0353079
[Epoch 72; Iter   293/ 1097] train: loss: 0.0010144
[Epoch 72; Iter   323/ 1097] train: loss: 0.0028712
[Epoch 72; Iter   353/ 1097] train: loss: 0.0004590
[Epoch 72; Iter   383/ 1097] train: loss: 0.0001608
[Epoch 72; Iter   413/ 1097] train: loss: 0.0001654
[Epoch 72; Iter   443/ 1097] train: loss: 0.0014202
[Epoch 72; Iter   473/ 1097] train: loss: 0.0317618
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002282
[Epoch 72; Iter   533/ 1097] train: loss: 0.0127132
[Epoch 72; Iter   563/ 1097] train: loss: 0.0053301
[Epoch 72; Iter   593/ 1097] train: loss: 0.0012016
[Epoch 72; Iter   623/ 1097] train: loss: 0.0328011
[Epoch 72; Iter   653/ 1097] train: loss: 0.0001318
[Epoch 72; Iter   683/ 1097] train: loss: 0.0014393
[Epoch 72; Iter   713/ 1097] train: loss: 0.0006283
[Epoch 72; Iter   743/ 1097] train: loss: 0.0002458
[Epoch 72; Iter   773/ 1097] train: loss: 0.0867020
[Epoch 72; Iter   803/ 1097] train: loss: 0.0346715
[Epoch 72; Iter   833/ 1097] train: loss: 0.0033607
[Epoch 72; Iter   863/ 1097] train: loss: 0.0042598
[Epoch 72; Iter   893/ 1097] train: loss: 0.0054011
[Epoch 72; Iter   923/ 1097] train: loss: 0.0060441
[Epoch 72; Iter   953/ 1097] train: loss: 0.0152313
[Epoch 72; Iter   983/ 1097] train: loss: 0.0044199
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0068781
[Epoch 72; Iter  1043/ 1097] train: loss: 0.1338633
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0454243
[Epoch 72] ogbg-molhiv: 0.714748 val loss: 2.942610
[Epoch 72] ogbg-molhiv: 0.685600 test loss: 1.543471
[Epoch 73; Iter     6/ 1097] train: loss: 0.0004201
[Epoch 73; Iter    36/ 1097] train: loss: 0.0010028
[Epoch 73; Iter    66/ 1097] train: loss: 0.0007393
[Epoch 73; Iter    96/ 1097] train: loss: 0.0006299
[Epoch 73; Iter   126/ 1097] train: loss: 0.0054398
[Epoch 73; Iter   156/ 1097] train: loss: 0.0017700
[Epoch 69; Iter   104/ 1097] train: loss: 0.0004268
[Epoch 69; Iter   134/ 1097] train: loss: 0.0003630
[Epoch 69; Iter   164/ 1097] train: loss: 0.0014231
[Epoch 69; Iter   194/ 1097] train: loss: 0.0008461
[Epoch 69; Iter   224/ 1097] train: loss: 0.0000719
[Epoch 69; Iter   254/ 1097] train: loss: 0.0002522
[Epoch 69; Iter   284/ 1097] train: loss: 0.0003313
[Epoch 69; Iter   314/ 1097] train: loss: 0.0018932
[Epoch 69; Iter   344/ 1097] train: loss: 0.0138509
[Epoch 69; Iter   374/ 1097] train: loss: 0.0038855
[Epoch 69; Iter   404/ 1097] train: loss: 0.0000224
[Epoch 69; Iter   434/ 1097] train: loss: 0.0025387
[Epoch 69; Iter   464/ 1097] train: loss: 0.0210439
[Epoch 69; Iter   494/ 1097] train: loss: 0.0027710
[Epoch 69; Iter   524/ 1097] train: loss: 0.0024180
[Epoch 69; Iter   554/ 1097] train: loss: 0.0023297
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000460
[Epoch 69; Iter   614/ 1097] train: loss: 0.0019070
[Epoch 69; Iter   644/ 1097] train: loss: 0.0123285
[Epoch 69; Iter   674/ 1097] train: loss: 0.0000273
[Epoch 69; Iter   704/ 1097] train: loss: 0.0010085
[Epoch 69; Iter   734/ 1097] train: loss: 0.0001148
[Epoch 69; Iter   764/ 1097] train: loss: 0.0001307
[Epoch 69; Iter   794/ 1097] train: loss: 0.0012451
[Epoch 69; Iter   824/ 1097] train: loss: 0.0002351
[Epoch 69; Iter   854/ 1097] train: loss: 0.0039273
[Epoch 69; Iter   884/ 1097] train: loss: 0.0005068
[Epoch 69; Iter   914/ 1097] train: loss: 0.0050450
[Epoch 69; Iter   944/ 1097] train: loss: 0.0002492
[Epoch 69; Iter   974/ 1097] train: loss: 0.0003516
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0005450
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0000129
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0005818
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0003496
[Epoch 69] ogbg-molhiv: 0.794612 val loss: 0.240345
[Epoch 69] ogbg-molhiv: 0.713420 test loss: 0.416214
[Epoch 70; Iter    27/ 1097] train: loss: 0.0008613
[Epoch 70; Iter    57/ 1097] train: loss: 0.0002096
[Epoch 70; Iter    87/ 1097] train: loss: 0.0019743
[Epoch 70; Iter   117/ 1097] train: loss: 0.0252805
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000372
[Epoch 70; Iter   177/ 1097] train: loss: 0.0000604
[Epoch 70; Iter   207/ 1097] train: loss: 0.0000240
[Epoch 70; Iter   237/ 1097] train: loss: 0.0048481
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001558
[Epoch 70; Iter   297/ 1097] train: loss: 0.0005671
[Epoch 70; Iter   327/ 1097] train: loss: 0.0010224
[Epoch 70; Iter   357/ 1097] train: loss: 0.0000526
[Epoch 70; Iter   387/ 1097] train: loss: 0.0001521
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000645
[Epoch 70; Iter   447/ 1097] train: loss: 0.0013317
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001335
[Epoch 70; Iter   507/ 1097] train: loss: 0.0004587
[Epoch 70; Iter   537/ 1097] train: loss: 0.0000517
[Epoch 70; Iter   567/ 1097] train: loss: 0.0338961
[Epoch 70; Iter   597/ 1097] train: loss: 0.0008405
[Epoch 70; Iter   627/ 1097] train: loss: 0.0005429
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001659
[Epoch 70; Iter   687/ 1097] train: loss: 0.0145602
[Epoch 70; Iter   717/ 1097] train: loss: 0.0005364
[Epoch 70; Iter   747/ 1097] train: loss: 0.0001573
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000097
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001108
[Epoch 70; Iter   837/ 1097] train: loss: 0.0013700
[Epoch 70; Iter   867/ 1097] train: loss: 0.0002030
[Epoch 70; Iter   897/ 1097] train: loss: 0.0041881
[Epoch 70; Iter   927/ 1097] train: loss: 0.0001204
[Epoch 70; Iter   957/ 1097] train: loss: 0.0488403
[Epoch 70; Iter   987/ 1097] train: loss: 0.0007948
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0006383
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0004152
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000548
[Epoch 70] ogbg-molhiv: 0.798253 val loss: 0.208112
[Epoch 70] ogbg-molhiv: 0.738689 test loss: 0.637073
[Epoch 71; Iter    10/ 1097] train: loss: 0.0000549
[Epoch 71; Iter    40/ 1097] train: loss: 0.0000847
[Epoch 71; Iter    70/ 1097] train: loss: 0.0001445
[Epoch 71; Iter   100/ 1097] train: loss: 0.0036921
[Epoch 71; Iter   130/ 1097] train: loss: 0.0004884
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000870
[Epoch 71; Iter   190/ 1097] train: loss: 0.0001579
[Epoch 71; Iter   220/ 1097] train: loss: 0.0004598
[Epoch 71; Iter   250/ 1097] train: loss: 0.0076843
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001018
[Epoch 71; Iter   310/ 1097] train: loss: 0.0061488
[Epoch 71; Iter   340/ 1097] train: loss: 0.0000767
[Epoch 71; Iter   370/ 1097] train: loss: 0.0000942
[Epoch 71; Iter   400/ 1097] train: loss: 0.0002464
[Epoch 71; Iter   430/ 1097] train: loss: 0.0007283
[Epoch 71; Iter   460/ 1097] train: loss: 0.0000817
[Epoch 71; Iter   490/ 1097] train: loss: 0.0015710
[Epoch 71; Iter   520/ 1097] train: loss: 0.0001045
[Epoch 71; Iter   550/ 1097] train: loss: 0.0092991
[Epoch 71; Iter   580/ 1097] train: loss: 0.0005114
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000052
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000160
[Epoch 71; Iter   670/ 1097] train: loss: 0.0006834
[Epoch 71; Iter   700/ 1097] train: loss: 0.0530996
[Epoch 71; Iter   730/ 1097] train: loss: 0.0113852
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000333
[Epoch 71; Iter   790/ 1097] train: loss: 0.0001522
[Epoch 71; Iter   820/ 1097] train: loss: 0.0586297
[Epoch 71; Iter   850/ 1097] train: loss: 0.0005767
[Epoch 71; Iter   880/ 1097] train: loss: 0.0003633
[Epoch 71; Iter   910/ 1097] train: loss: 0.0069573
[Epoch 71; Iter   940/ 1097] train: loss: 0.0019373
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002578
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0000367
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0002889
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0049833
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0018291
[Epoch 71] ogbg-molhiv: 0.783001 val loss: 0.239561
[Epoch 71] ogbg-molhiv: 0.727774 test loss: 0.553407
[Epoch 72; Iter    23/ 1097] train: loss: 0.0001422
[Epoch 72; Iter    53/ 1097] train: loss: 0.0001046
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000161
[Epoch 72; Iter   113/ 1097] train: loss: 0.0004743
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004850
[Epoch 72; Iter   173/ 1097] train: loss: 0.0005666
[Epoch 72; Iter   203/ 1097] train: loss: 0.0123669
[Epoch 72; Iter   233/ 1097] train: loss: 0.0002603
[Epoch 72; Iter   263/ 1097] train: loss: 0.0002513
[Epoch 72; Iter   293/ 1097] train: loss: 0.0001274
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000230
[Epoch 72; Iter   353/ 1097] train: loss: 0.0001129
[Epoch 72; Iter   383/ 1097] train: loss: 0.0052352
[Epoch 72; Iter   413/ 1097] train: loss: 0.0004573
[Epoch 72; Iter   443/ 1097] train: loss: 0.0002253
[Epoch 72; Iter   473/ 1097] train: loss: 0.0029440
[Epoch 72; Iter   503/ 1097] train: loss: 0.0065550
[Epoch 72; Iter   533/ 1097] train: loss: 0.0191258
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000432
[Epoch 72; Iter   593/ 1097] train: loss: 0.0005430
[Epoch 72; Iter   623/ 1097] train: loss: 0.0004862
[Epoch 72; Iter   653/ 1097] train: loss: 0.0014630
[Epoch 72; Iter   683/ 1097] train: loss: 0.0002617
[Epoch 72; Iter   713/ 1097] train: loss: 0.0023848
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000084
[Epoch 72; Iter   773/ 1097] train: loss: 0.0035138
[Epoch 72; Iter   803/ 1097] train: loss: 0.0008923
[Epoch 72; Iter   833/ 1097] train: loss: 0.0001561
[Epoch 72; Iter   863/ 1097] train: loss: 0.0004390
[Epoch 72; Iter   893/ 1097] train: loss: 0.0000656
[Epoch 72; Iter   923/ 1097] train: loss: 0.0083497
[Epoch 72; Iter   953/ 1097] train: loss: 0.0000294
[Epoch 72; Iter   983/ 1097] train: loss: 0.0004199
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0002855
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0191290
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0008397
[Epoch 72] ogbg-molhiv: 0.787640 val loss: 0.270358
[Epoch 72] ogbg-molhiv: 0.739406 test loss: 0.397660
[Epoch 73; Iter     6/ 1097] train: loss: 0.0066416
[Epoch 73; Iter    36/ 1097] train: loss: 0.0000718
[Epoch 73; Iter    66/ 1097] train: loss: 0.0007893
[Epoch 73; Iter    96/ 1097] train: loss: 0.0003543
[Epoch 73; Iter   126/ 1097] train: loss: 0.0006568
[Epoch 73; Iter   156/ 1097] train: loss: 0.0021305
[Epoch 69; Iter   104/ 1097] train: loss: 0.0029135
[Epoch 69; Iter   134/ 1097] train: loss: 0.0005737
[Epoch 69; Iter   164/ 1097] train: loss: 0.0005466
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000494
[Epoch 69; Iter   224/ 1097] train: loss: 0.0001488
[Epoch 69; Iter   254/ 1097] train: loss: 0.0005638
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001299
[Epoch 69; Iter   314/ 1097] train: loss: 0.0001670
[Epoch 69; Iter   344/ 1097] train: loss: 0.0006009
[Epoch 69; Iter   374/ 1097] train: loss: 0.0000569
[Epoch 69; Iter   404/ 1097] train: loss: 0.0007465
[Epoch 69; Iter   434/ 1097] train: loss: 0.0002278
[Epoch 69; Iter   464/ 1097] train: loss: 0.0000894
[Epoch 69; Iter   494/ 1097] train: loss: 0.0072749
[Epoch 69; Iter   524/ 1097] train: loss: 0.0001472
[Epoch 69; Iter   554/ 1097] train: loss: 0.0000382
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000065
[Epoch 69; Iter   614/ 1097] train: loss: 0.0109336
[Epoch 69; Iter   644/ 1097] train: loss: 0.0001892
[Epoch 69; Iter   674/ 1097] train: loss: 0.0005058
[Epoch 69; Iter   704/ 1097] train: loss: 0.0000228
[Epoch 69; Iter   734/ 1097] train: loss: 0.0077547
[Epoch 69; Iter   764/ 1097] train: loss: 0.0001018
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000206
[Epoch 69; Iter   824/ 1097] train: loss: 0.0000352
[Epoch 69; Iter   854/ 1097] train: loss: 0.0447718
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000272
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000330
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001537
[Epoch 69; Iter   974/ 1097] train: loss: 0.0005287
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000061
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0004177
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0002513
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0016782
[Epoch 69] ogbg-molhiv: 0.769293 val loss: 0.258938
[Epoch 69] ogbg-molhiv: 0.786722 test loss: 0.306357
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000034
[Epoch 70; Iter    57/ 1097] train: loss: 0.0000252
[Epoch 70; Iter    87/ 1097] train: loss: 0.0001694
[Epoch 70; Iter   117/ 1097] train: loss: 0.0043757
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000028
[Epoch 70; Iter   177/ 1097] train: loss: 0.0000375
[Epoch 70; Iter   207/ 1097] train: loss: 0.0005237
[Epoch 70; Iter   237/ 1097] train: loss: 0.0005093
[Epoch 70; Iter   267/ 1097] train: loss: 0.0004728
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000036
[Epoch 70; Iter   327/ 1097] train: loss: 0.0007905
[Epoch 70; Iter   357/ 1097] train: loss: 0.0005362
[Epoch 70; Iter   387/ 1097] train: loss: 0.0002410
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000785
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000707
[Epoch 70; Iter   477/ 1097] train: loss: 0.0096535
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000948
[Epoch 70; Iter   537/ 1097] train: loss: 0.0001501
[Epoch 70; Iter   567/ 1097] train: loss: 0.0008768
[Epoch 70; Iter   597/ 1097] train: loss: 0.0000274
[Epoch 70; Iter   627/ 1097] train: loss: 0.0015702
[Epoch 70; Iter   657/ 1097] train: loss: 0.0106356
[Epoch 70; Iter   687/ 1097] train: loss: 0.0001702
[Epoch 70; Iter   717/ 1097] train: loss: 0.0000445
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000123
[Epoch 70; Iter   777/ 1097] train: loss: 0.0074870
[Epoch 70; Iter   807/ 1097] train: loss: 0.0000085
[Epoch 70; Iter   837/ 1097] train: loss: 0.0008930
[Epoch 70; Iter   867/ 1097] train: loss: 0.0001649
[Epoch 70; Iter   897/ 1097] train: loss: 0.0001821
[Epoch 70; Iter   927/ 1097] train: loss: 0.0081811
[Epoch 70; Iter   957/ 1097] train: loss: 0.0007236
[Epoch 70; Iter   987/ 1097] train: loss: 0.0001162
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0002843
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000156
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0003430
[Epoch 70] ogbg-molhiv: 0.767346 val loss: 0.326789
[Epoch 70] ogbg-molhiv: 0.780874 test loss: 0.317737
[Epoch 71; Iter    10/ 1097] train: loss: 0.0004538
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001578
[Epoch 71; Iter    70/ 1097] train: loss: 0.0001331
[Epoch 71; Iter   100/ 1097] train: loss: 0.0230496
[Epoch 71; Iter   130/ 1097] train: loss: 0.0000320
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000599
[Epoch 71; Iter   190/ 1097] train: loss: 0.0003223
[Epoch 71; Iter   220/ 1097] train: loss: 0.0972073
[Epoch 71; Iter   250/ 1097] train: loss: 0.0003524
[Epoch 71; Iter   280/ 1097] train: loss: 0.0041652
[Epoch 71; Iter   310/ 1097] train: loss: 0.0007587
[Epoch 71; Iter   340/ 1097] train: loss: 0.0004072
[Epoch 71; Iter   370/ 1097] train: loss: 0.0006012
[Epoch 71; Iter   400/ 1097] train: loss: 0.0001323
[Epoch 71; Iter   430/ 1097] train: loss: 0.0002088
[Epoch 71; Iter   460/ 1097] train: loss: 0.0011307
[Epoch 71; Iter   490/ 1097] train: loss: 0.0175663
[Epoch 71; Iter   520/ 1097] train: loss: 0.0005367
[Epoch 71; Iter   550/ 1097] train: loss: 0.0008385
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000137
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000094
[Epoch 71; Iter   640/ 1097] train: loss: 0.0021661
[Epoch 71; Iter   670/ 1097] train: loss: 0.0003036
[Epoch 71; Iter   700/ 1097] train: loss: 0.0000657
[Epoch 71; Iter   730/ 1097] train: loss: 0.0000579
[Epoch 71; Iter   760/ 1097] train: loss: 0.0001078
[Epoch 71; Iter   790/ 1097] train: loss: 0.0005104
[Epoch 71; Iter   820/ 1097] train: loss: 0.0004228
[Epoch 71; Iter   850/ 1097] train: loss: 0.0022237
[Epoch 71; Iter   880/ 1097] train: loss: 0.0044097
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000173
[Epoch 71; Iter   940/ 1097] train: loss: 0.0007516
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002998
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0041833
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0094210
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0002035
[Epoch 71; Iter  1090/ 1097] train: loss: 0.1013557
[Epoch 71] ogbg-molhiv: 0.810029 val loss: 0.264673
[Epoch 71] ogbg-molhiv: 0.777315 test loss: 0.313073
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000569
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000479
[Epoch 72; Iter    83/ 1097] train: loss: 0.0003432
[Epoch 72; Iter   113/ 1097] train: loss: 0.0000977
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004929
[Epoch 72; Iter   173/ 1097] train: loss: 0.0008547
[Epoch 72; Iter   203/ 1097] train: loss: 0.0000027
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000630
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000805
[Epoch 72; Iter   293/ 1097] train: loss: 0.0002711
[Epoch 72; Iter   323/ 1097] train: loss: 0.0071224
[Epoch 72; Iter   353/ 1097] train: loss: 0.0324760
[Epoch 72; Iter   383/ 1097] train: loss: 0.0005926
[Epoch 72; Iter   413/ 1097] train: loss: 0.0007424
[Epoch 72; Iter   443/ 1097] train: loss: 0.0006023
[Epoch 72; Iter   473/ 1097] train: loss: 0.0246511
[Epoch 72; Iter   503/ 1097] train: loss: 0.0082529
[Epoch 72; Iter   533/ 1097] train: loss: 0.0004941
[Epoch 72; Iter   563/ 1097] train: loss: 0.0026749
[Epoch 72; Iter   593/ 1097] train: loss: 0.0000222
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000346
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000960
[Epoch 72; Iter   683/ 1097] train: loss: 0.0003305
[Epoch 72; Iter   713/ 1097] train: loss: 0.0011228
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000935
[Epoch 72; Iter   773/ 1097] train: loss: 0.0026265
[Epoch 72; Iter   803/ 1097] train: loss: 0.0003136
[Epoch 72; Iter   833/ 1097] train: loss: 0.0327321
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000386
[Epoch 72; Iter   893/ 1097] train: loss: 0.0013577
[Epoch 72; Iter   923/ 1097] train: loss: 0.0000170
[Epoch 72; Iter   953/ 1097] train: loss: 0.0072361
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000811
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0099089
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0000267
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0003184
[Epoch 72] ogbg-molhiv: 0.759492 val loss: 0.313335
[Epoch 72] ogbg-molhiv: 0.778416 test loss: 0.340840
[Epoch 73; Iter     6/ 1097] train: loss: 0.0019960
[Epoch 73; Iter    36/ 1097] train: loss: 0.0002370
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000019
[Epoch 73; Iter    96/ 1097] train: loss: 0.0004639
[Epoch 73; Iter   126/ 1097] train: loss: 0.0000333
[Epoch 73; Iter   156/ 1097] train: loss: 0.0003831
[Epoch 69; Iter   104/ 1097] train: loss: 0.0000381
[Epoch 69; Iter   134/ 1097] train: loss: 0.0000121
[Epoch 69; Iter   164/ 1097] train: loss: 0.0001456
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000134
[Epoch 69; Iter   224/ 1097] train: loss: 0.0000442
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000519
[Epoch 69; Iter   284/ 1097] train: loss: 0.0000478
[Epoch 69; Iter   314/ 1097] train: loss: 0.0000324
[Epoch 69; Iter   344/ 1097] train: loss: 0.0000070
[Epoch 69; Iter   374/ 1097] train: loss: 0.0001072
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001525
[Epoch 69; Iter   434/ 1097] train: loss: 0.0001297
[Epoch 69; Iter   464/ 1097] train: loss: 0.0000152
[Epoch 69; Iter   494/ 1097] train: loss: 0.0022664
[Epoch 69; Iter   524/ 1097] train: loss: 0.0000262
[Epoch 69; Iter   554/ 1097] train: loss: 0.0048090
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000784
[Epoch 69; Iter   614/ 1097] train: loss: 0.0044764
[Epoch 69; Iter   644/ 1097] train: loss: 0.0000341
[Epoch 69; Iter   674/ 1097] train: loss: 0.0000269
[Epoch 69; Iter   704/ 1097] train: loss: 0.0015147
[Epoch 69; Iter   734/ 1097] train: loss: 0.0044121
[Epoch 69; Iter   764/ 1097] train: loss: 0.0006212
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000995
[Epoch 69; Iter   824/ 1097] train: loss: 0.0000216
[Epoch 69; Iter   854/ 1097] train: loss: 0.0000363
[Epoch 69; Iter   884/ 1097] train: loss: 0.0004912
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000809
[Epoch 69; Iter   944/ 1097] train: loss: 0.0000884
[Epoch 69; Iter   974/ 1097] train: loss: 0.0082079
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0020063
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001196
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0000643
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0000800
[Epoch 69] ogbg-molhiv: 0.705278 val loss: 2.331071
[Epoch 69] ogbg-molhiv: 0.592881 test loss: 3.505069
[Epoch 70; Iter    27/ 1097] train: loss: 0.0001601
[Epoch 70; Iter    57/ 1097] train: loss: 0.0000313
[Epoch 70; Iter    87/ 1097] train: loss: 0.0002632
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000215
[Epoch 70; Iter   147/ 1097] train: loss: 0.0044327
[Epoch 70; Iter   177/ 1097] train: loss: 0.0004310
[Epoch 70; Iter   207/ 1097] train: loss: 0.0059137
[Epoch 70; Iter   237/ 1097] train: loss: 0.0002043
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001933
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000892
[Epoch 70; Iter   327/ 1097] train: loss: 0.0000263
[Epoch 70; Iter   357/ 1097] train: loss: 0.0001505
[Epoch 70; Iter   387/ 1097] train: loss: 0.0246061
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000058
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000225
[Epoch 70; Iter   477/ 1097] train: loss: 0.0002105
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000466
[Epoch 70; Iter   537/ 1097] train: loss: 0.0001311
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000136
[Epoch 70; Iter   597/ 1097] train: loss: 0.0012394
[Epoch 70; Iter   627/ 1097] train: loss: 0.0000039
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000888
[Epoch 70; Iter   687/ 1097] train: loss: 0.0001749
[Epoch 70; Iter   717/ 1097] train: loss: 0.0003433
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000022
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000320
[Epoch 70; Iter   807/ 1097] train: loss: 0.0005875
[Epoch 70; Iter   837/ 1097] train: loss: 0.0001935
[Epoch 70; Iter   867/ 1097] train: loss: 0.0004459
[Epoch 70; Iter   897/ 1097] train: loss: 0.0000962
[Epoch 70; Iter   927/ 1097] train: loss: 0.0000090
[Epoch 70; Iter   957/ 1097] train: loss: 0.0000027
[Epoch 70; Iter   987/ 1097] train: loss: 0.0008869
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0000462
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0011425
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0004593
[Epoch 70] ogbg-molhiv: 0.719384 val loss: 2.371061
[Epoch 70] ogbg-molhiv: 0.650613 test loss: 2.935907
[Epoch 71; Iter    10/ 1097] train: loss: 0.0001849
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001018
[Epoch 71; Iter    70/ 1097] train: loss: 0.0000077
[Epoch 71; Iter   100/ 1097] train: loss: 0.0000956
[Epoch 71; Iter   130/ 1097] train: loss: 0.0000184
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000507
[Epoch 71; Iter   190/ 1097] train: loss: 0.0120898
[Epoch 71; Iter   220/ 1097] train: loss: 0.0000605
[Epoch 71; Iter   250/ 1097] train: loss: 0.0000024
[Epoch 71; Iter   280/ 1097] train: loss: 0.0077968
[Epoch 71; Iter   310/ 1097] train: loss: 0.0010694
[Epoch 71; Iter   340/ 1097] train: loss: 0.0006109
[Epoch 71; Iter   370/ 1097] train: loss: 0.0023235
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000477
[Epoch 71; Iter   430/ 1097] train: loss: 0.0005506
[Epoch 71; Iter   460/ 1097] train: loss: 0.0001360
[Epoch 71; Iter   490/ 1097] train: loss: 0.0000019
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000088
[Epoch 71; Iter   550/ 1097] train: loss: 0.0420335
[Epoch 71; Iter   580/ 1097] train: loss: 0.0002022
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000639
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000131
[Epoch 71; Iter   670/ 1097] train: loss: 0.0001916
[Epoch 71; Iter   700/ 1097] train: loss: 0.0000040
[Epoch 71; Iter   730/ 1097] train: loss: 0.0621984
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000327
[Epoch 71; Iter   790/ 1097] train: loss: 0.0032107
[Epoch 71; Iter   820/ 1097] train: loss: 0.0021357
[Epoch 71; Iter   850/ 1097] train: loss: 0.0000112
[Epoch 71; Iter   880/ 1097] train: loss: 0.0002783
[Epoch 71; Iter   910/ 1097] train: loss: 0.0001941
[Epoch 71; Iter   940/ 1097] train: loss: 0.0004970
[Epoch 71; Iter   970/ 1097] train: loss: 0.0000385
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0003776
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000649
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0001354
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0000088
[Epoch 71] ogbg-molhiv: 0.719613 val loss: 0.461594
[Epoch 71] ogbg-molhiv: 0.596937 test loss: 0.576821
[Epoch 72; Iter    23/ 1097] train: loss: 0.0002790
[Epoch 72; Iter    53/ 1097] train: loss: 0.0001026
[Epoch 72; Iter    83/ 1097] train: loss: 0.0010432
[Epoch 72; Iter   113/ 1097] train: loss: 0.0000348
[Epoch 72; Iter   143/ 1097] train: loss: 0.0000040
[Epoch 72; Iter   173/ 1097] train: loss: 0.0000417
[Epoch 72; Iter   203/ 1097] train: loss: 0.0002128
[Epoch 72; Iter   233/ 1097] train: loss: 0.0066512
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000355
[Epoch 72; Iter   293/ 1097] train: loss: 0.0000264
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000280
[Epoch 72; Iter   353/ 1097] train: loss: 0.0000021
[Epoch 72; Iter   383/ 1097] train: loss: 0.0000031
[Epoch 72; Iter   413/ 1097] train: loss: 0.0001358
[Epoch 72; Iter   443/ 1097] train: loss: 0.0000205
[Epoch 72; Iter   473/ 1097] train: loss: 0.0002328
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002232
[Epoch 72; Iter   533/ 1097] train: loss: 0.0003186
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001613
[Epoch 72; Iter   593/ 1097] train: loss: 0.0000314
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000058
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000066
[Epoch 72; Iter   683/ 1097] train: loss: 0.0006557
[Epoch 72; Iter   713/ 1097] train: loss: 0.0009177
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000263
[Epoch 72; Iter   773/ 1097] train: loss: 0.0670469
[Epoch 72; Iter   803/ 1097] train: loss: 0.0000211
[Epoch 72; Iter   833/ 1097] train: loss: 0.0000152
[Epoch 72; Iter   863/ 1097] train: loss: 0.0001610
[Epoch 72; Iter   893/ 1097] train: loss: 0.0001022
[Epoch 72; Iter   923/ 1097] train: loss: 0.0015420
[Epoch 72; Iter   953/ 1097] train: loss: 0.0000690
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000126
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000023
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0002145
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0169106
[Epoch 72] ogbg-molhiv: 0.705679 val loss: 1.935648
[Epoch 72] ogbg-molhiv: 0.647500 test loss: 2.957284
[Epoch 73; Iter     6/ 1097] train: loss: 0.0000383
[Epoch 73; Iter    36/ 1097] train: loss: 0.0025910
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001343
[Epoch 73; Iter    96/ 1097] train: loss: 0.0000869
[Epoch 73; Iter   126/ 1097] train: loss: 0.0001404
[Epoch 73; Iter   156/ 1097] train: loss: 0.0024408
[Epoch 69; Iter   104/ 1097] train: loss: 0.0091167
[Epoch 69; Iter   134/ 1097] train: loss: 0.0015617
[Epoch 69; Iter   164/ 1097] train: loss: 0.0012560
[Epoch 69; Iter   194/ 1097] train: loss: 0.0005340
[Epoch 69; Iter   224/ 1097] train: loss: 0.0011736
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000118
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001764
[Epoch 69; Iter   314/ 1097] train: loss: 0.0015165
[Epoch 69; Iter   344/ 1097] train: loss: 0.0003471
[Epoch 69; Iter   374/ 1097] train: loss: 0.0014556
[Epoch 69; Iter   404/ 1097] train: loss: 0.0037744
[Epoch 69; Iter   434/ 1097] train: loss: 0.0292223
[Epoch 69; Iter   464/ 1097] train: loss: 0.0008172
[Epoch 69; Iter   494/ 1097] train: loss: 0.0002354
[Epoch 69; Iter   524/ 1097] train: loss: 0.0000214
[Epoch 69; Iter   554/ 1097] train: loss: 0.0005825
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000897
[Epoch 69; Iter   614/ 1097] train: loss: 0.0002427
[Epoch 69; Iter   644/ 1097] train: loss: 0.0000670
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001044
[Epoch 69; Iter   704/ 1097] train: loss: 0.0002139
[Epoch 69; Iter   734/ 1097] train: loss: 0.0028128
[Epoch 69; Iter   764/ 1097] train: loss: 0.0268212
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000228
[Epoch 69; Iter   824/ 1097] train: loss: 0.0273110
[Epoch 69; Iter   854/ 1097] train: loss: 0.0008712
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000979
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000202
[Epoch 69; Iter   944/ 1097] train: loss: 0.0011131
[Epoch 69; Iter   974/ 1097] train: loss: 0.0141176
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000113
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001198
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0014957
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0001085
[Epoch 69] ogbg-molhiv: 0.771440 val loss: 14.263231
[Epoch 69] ogbg-molhiv: 0.724303 test loss: 13.741340
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000739
[Epoch 70; Iter    57/ 1097] train: loss: 0.0008507
[Epoch 70; Iter    87/ 1097] train: loss: 0.0205051
[Epoch 70; Iter   117/ 1097] train: loss: 0.0737998
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000524
[Epoch 70; Iter   177/ 1097] train: loss: 0.0002895
[Epoch 70; Iter   207/ 1097] train: loss: 0.0001008
[Epoch 70; Iter   237/ 1097] train: loss: 0.0045046
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001503
[Epoch 70; Iter   297/ 1097] train: loss: 0.0001430
[Epoch 70; Iter   327/ 1097] train: loss: 0.0042368
[Epoch 70; Iter   357/ 1097] train: loss: 0.0020253
[Epoch 70; Iter   387/ 1097] train: loss: 0.0706834
[Epoch 70; Iter   417/ 1097] train: loss: 0.0002288
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000231
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001755
[Epoch 70; Iter   507/ 1097] train: loss: 0.0001497
[Epoch 70; Iter   537/ 1097] train: loss: 0.0034335
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000110
[Epoch 70; Iter   597/ 1097] train: loss: 0.0001390
[Epoch 70; Iter   627/ 1097] train: loss: 0.0022298
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000111
[Epoch 70; Iter   687/ 1097] train: loss: 0.0009594
[Epoch 70; Iter   717/ 1097] train: loss: 0.0055644
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000098
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000463
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001342
[Epoch 70; Iter   837/ 1097] train: loss: 0.0000347
[Epoch 70; Iter   867/ 1097] train: loss: 0.0073639
[Epoch 70; Iter   897/ 1097] train: loss: 0.0028972
[Epoch 70; Iter   927/ 1097] train: loss: 0.0042973
[Epoch 70; Iter   957/ 1097] train: loss: 0.0003895
[Epoch 70; Iter   987/ 1097] train: loss: 0.0001521
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0001485
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000458
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0025759
[Epoch 70] ogbg-molhiv: 0.776256 val loss: 1.932775
[Epoch 70] ogbg-molhiv: 0.717861 test loss: 4.149127
[Epoch 71; Iter    10/ 1097] train: loss: 0.0002526
[Epoch 71; Iter    40/ 1097] train: loss: 0.0002346
[Epoch 71; Iter    70/ 1097] train: loss: 0.0002473
[Epoch 71; Iter   100/ 1097] train: loss: 0.0073364
[Epoch 71; Iter   130/ 1097] train: loss: 0.0008833
[Epoch 71; Iter   160/ 1097] train: loss: 0.0001765
[Epoch 71; Iter   190/ 1097] train: loss: 0.0002426
[Epoch 71; Iter   220/ 1097] train: loss: 0.0002925
[Epoch 71; Iter   250/ 1097] train: loss: 0.0010195
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001090
[Epoch 71; Iter   310/ 1097] train: loss: 0.0000228
[Epoch 71; Iter   340/ 1097] train: loss: 0.0010787
[Epoch 71; Iter   370/ 1097] train: loss: 0.0000194
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000245
[Epoch 71; Iter   430/ 1097] train: loss: 0.0000807
[Epoch 71; Iter   460/ 1097] train: loss: 0.0037518
[Epoch 71; Iter   490/ 1097] train: loss: 0.0006365
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000222
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000289
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000225
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000446
[Epoch 71; Iter   640/ 1097] train: loss: 0.0229038
[Epoch 71; Iter   670/ 1097] train: loss: 0.0040990
[Epoch 71; Iter   700/ 1097] train: loss: 0.0201882
[Epoch 71; Iter   730/ 1097] train: loss: 0.0000119
[Epoch 71; Iter   760/ 1097] train: loss: 0.0001887
[Epoch 71; Iter   790/ 1097] train: loss: 0.0003902
[Epoch 71; Iter   820/ 1097] train: loss: 0.0317151
[Epoch 71; Iter   850/ 1097] train: loss: 0.0003773
[Epoch 71; Iter   880/ 1097] train: loss: 0.0050018
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000267
[Epoch 71; Iter   940/ 1097] train: loss: 0.0002053
[Epoch 71; Iter   970/ 1097] train: loss: 0.0000480
[Epoch 71; Iter  1000/ 1097] train: loss: 0.1607221
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000293
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0049620
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0454823
[Epoch 71] ogbg-molhiv: 0.764912 val loss: 6.979458
[Epoch 71] ogbg-molhiv: 0.722988 test loss: 6.300052
[Epoch 72; Iter    23/ 1097] train: loss: 0.0004355
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000019
[Epoch 72; Iter    83/ 1097] train: loss: 0.0021592
[Epoch 72; Iter   113/ 1097] train: loss: 0.0370400
[Epoch 72; Iter   143/ 1097] train: loss: 0.0001125
[Epoch 72; Iter   173/ 1097] train: loss: 0.0000243
[Epoch 72; Iter   203/ 1097] train: loss: 0.0001011
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000203
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000020
[Epoch 72; Iter   293/ 1097] train: loss: 0.0006350
[Epoch 72; Iter   323/ 1097] train: loss: 0.0217118
[Epoch 72; Iter   353/ 1097] train: loss: 0.0517958
[Epoch 72; Iter   383/ 1097] train: loss: 0.0001127
[Epoch 72; Iter   413/ 1097] train: loss: 0.0000987
[Epoch 72; Iter   443/ 1097] train: loss: 0.0000731
[Epoch 72; Iter   473/ 1097] train: loss: 0.0118782
[Epoch 72; Iter   503/ 1097] train: loss: 0.0043894
[Epoch 72; Iter   533/ 1097] train: loss: 0.0032288
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000147
[Epoch 72; Iter   593/ 1097] train: loss: 0.0001155
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000406
[Epoch 72; Iter   653/ 1097] train: loss: 0.0003388
[Epoch 72; Iter   683/ 1097] train: loss: 0.0000404
[Epoch 72; Iter   713/ 1097] train: loss: 0.0002305
[Epoch 72; Iter   743/ 1097] train: loss: 0.0016108
[Epoch 72; Iter   773/ 1097] train: loss: 0.0107803
[Epoch 72; Iter   803/ 1097] train: loss: 0.0001208
[Epoch 72; Iter   833/ 1097] train: loss: 0.0073493
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000273
[Epoch 72; Iter   893/ 1097] train: loss: 0.0013032
[Epoch 72; Iter   923/ 1097] train: loss: 0.0003526
[Epoch 72; Iter   953/ 1097] train: loss: 0.0009860
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000051
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0006640
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0003450
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0013645
[Epoch 72] ogbg-molhiv: 0.747612 val loss: 2.120755
[Epoch 72] ogbg-molhiv: 0.718737 test loss: 3.508364
[Epoch 73; Iter     6/ 1097] train: loss: 0.0010817
[Epoch 73; Iter    36/ 1097] train: loss: 0.0009260
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000972
[Epoch 73; Iter    96/ 1097] train: loss: 0.0072605
[Epoch 73; Iter   126/ 1097] train: loss: 0.0003823
[Epoch 73; Iter   156/ 1097] train: loss: 0.0144883
[Epoch 69; Iter   104/ 1097] train: loss: 0.0000173
[Epoch 69; Iter   134/ 1097] train: loss: 0.0004163
[Epoch 69; Iter   164/ 1097] train: loss: 0.0001749
[Epoch 69; Iter   194/ 1097] train: loss: 0.0046157
[Epoch 69; Iter   224/ 1097] train: loss: 0.0010822
[Epoch 69; Iter   254/ 1097] train: loss: 0.0424322
[Epoch 69; Iter   284/ 1097] train: loss: 0.0042886
[Epoch 69; Iter   314/ 1097] train: loss: 0.0017452
[Epoch 69; Iter   344/ 1097] train: loss: 0.0028204
[Epoch 69; Iter   374/ 1097] train: loss: 0.0003730
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001523
[Epoch 69; Iter   434/ 1097] train: loss: 0.0017274
[Epoch 69; Iter   464/ 1097] train: loss: 0.0021959
[Epoch 69; Iter   494/ 1097] train: loss: 0.0001695
[Epoch 69; Iter   524/ 1097] train: loss: 0.0002379
[Epoch 69; Iter   554/ 1097] train: loss: 0.0034673
[Epoch 69; Iter   584/ 1097] train: loss: 0.0008790
[Epoch 69; Iter   614/ 1097] train: loss: 0.0459512
[Epoch 69; Iter   644/ 1097] train: loss: 0.0636112
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001736
[Epoch 69; Iter   704/ 1097] train: loss: 0.0001215
[Epoch 69; Iter   734/ 1097] train: loss: 0.0003649
[Epoch 69; Iter   764/ 1097] train: loss: 0.0009591
[Epoch 69; Iter   794/ 1097] train: loss: 0.0065862
[Epoch 69; Iter   824/ 1097] train: loss: 0.0016282
[Epoch 69; Iter   854/ 1097] train: loss: 0.0001829
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000766
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000677
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001107
[Epoch 69; Iter   974/ 1097] train: loss: 0.0000211
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0015529
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0028582
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0000900
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0077027
[Epoch 69] ogbg-molhiv: 0.628065 val loss: 81.998429
[Epoch 69] ogbg-molhiv: 0.556231 test loss: 76.188471
[Epoch 70; Iter    27/ 1097] train: loss: 0.0003616
[Epoch 70; Iter    57/ 1097] train: loss: 0.0009695
[Epoch 70; Iter    87/ 1097] train: loss: 0.0350622
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000710
[Epoch 70; Iter   147/ 1097] train: loss: 0.0061953
[Epoch 70; Iter   177/ 1097] train: loss: 0.0003094
[Epoch 70; Iter   207/ 1097] train: loss: 0.0000673
[Epoch 70; Iter   237/ 1097] train: loss: 0.0014740
[Epoch 70; Iter   267/ 1097] train: loss: 0.0029674
[Epoch 70; Iter   297/ 1097] train: loss: 0.0171278
[Epoch 70; Iter   327/ 1097] train: loss: 0.0007094
[Epoch 70; Iter   357/ 1097] train: loss: 0.0040744
[Epoch 70; Iter   387/ 1097] train: loss: 0.0004221
[Epoch 70; Iter   417/ 1097] train: loss: 0.0003035
[Epoch 70; Iter   447/ 1097] train: loss: 0.0002953
[Epoch 70; Iter   477/ 1097] train: loss: 0.0023136
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000367
[Epoch 70; Iter   537/ 1097] train: loss: 0.0002206
[Epoch 70; Iter   567/ 1097] train: loss: 0.0004467
[Epoch 70; Iter   597/ 1097] train: loss: 0.0000600
[Epoch 70; Iter   627/ 1097] train: loss: 0.1293772
[Epoch 70; Iter   657/ 1097] train: loss: 0.0004562
[Epoch 70; Iter   687/ 1097] train: loss: 0.0132868
[Epoch 70; Iter   717/ 1097] train: loss: 0.0088820
[Epoch 70; Iter   747/ 1097] train: loss: 0.0169615
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000137
[Epoch 70; Iter   807/ 1097] train: loss: 0.0000215
[Epoch 70; Iter   837/ 1097] train: loss: 0.0038334
[Epoch 70; Iter   867/ 1097] train: loss: 0.0495190
[Epoch 70; Iter   897/ 1097] train: loss: 0.0004618
[Epoch 70; Iter   927/ 1097] train: loss: 0.0031693
[Epoch 70; Iter   957/ 1097] train: loss: 0.0003019
[Epoch 70; Iter   987/ 1097] train: loss: 0.0010555
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0005739
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0006035
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0012123
[Epoch 70] ogbg-molhiv: 0.595955 val loss: 280.670247
[Epoch 70] ogbg-molhiv: 0.545928 test loss: 264.721632
[Epoch 71; Iter    10/ 1097] train: loss: 0.0001871
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001829
[Epoch 71; Iter    70/ 1097] train: loss: 0.0004854
[Epoch 71; Iter   100/ 1097] train: loss: 0.1169637
[Epoch 71; Iter   130/ 1097] train: loss: 0.0007341
[Epoch 71; Iter   160/ 1097] train: loss: 0.0416297
[Epoch 71; Iter   190/ 1097] train: loss: 0.0569596
[Epoch 71; Iter   220/ 1097] train: loss: 0.0001824
[Epoch 71; Iter   250/ 1097] train: loss: 0.0004619
[Epoch 71; Iter   280/ 1097] train: loss: 0.0062335
[Epoch 71; Iter   310/ 1097] train: loss: 0.0030579
[Epoch 71; Iter   340/ 1097] train: loss: 0.0010342
[Epoch 71; Iter   370/ 1097] train: loss: 0.0011182
[Epoch 71; Iter   400/ 1097] train: loss: 0.0132507
[Epoch 71; Iter   430/ 1097] train: loss: 0.0006497
[Epoch 71; Iter   460/ 1097] train: loss: 0.2174922
[Epoch 71; Iter   490/ 1097] train: loss: 0.0011468
[Epoch 71; Iter   520/ 1097] train: loss: 0.0011252
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000808
[Epoch 71; Iter   580/ 1097] train: loss: 0.0038960
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000477
[Epoch 71; Iter   640/ 1097] train: loss: 0.0005329
[Epoch 71; Iter   670/ 1097] train: loss: 0.0001659
[Epoch 71; Iter   700/ 1097] train: loss: 0.1524809
[Epoch 71; Iter   730/ 1097] train: loss: 0.0067918
[Epoch 71; Iter   760/ 1097] train: loss: 0.0514076
[Epoch 71; Iter   790/ 1097] train: loss: 0.0014129
[Epoch 71; Iter   820/ 1097] train: loss: 0.0031792
[Epoch 71; Iter   850/ 1097] train: loss: 0.0195211
[Epoch 71; Iter   880/ 1097] train: loss: 0.0078805
[Epoch 71; Iter   910/ 1097] train: loss: 0.0018005
[Epoch 71; Iter   940/ 1097] train: loss: 0.0009195
[Epoch 71; Iter   970/ 1097] train: loss: 0.0010486
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0095622
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0050871
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0105759
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0006315
[Epoch 71] ogbg-molhiv: 0.646629 val loss: 29.903494
[Epoch 71] ogbg-molhiv: 0.564283 test loss: 28.444888
[Epoch 72; Iter    23/ 1097] train: loss: 0.0010847
[Epoch 72; Iter    53/ 1097] train: loss: 0.0021177
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000309
[Epoch 72; Iter   113/ 1097] train: loss: 0.0004853
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004385
[Epoch 72; Iter   173/ 1097] train: loss: 0.0003169
[Epoch 72; Iter   203/ 1097] train: loss: 0.0004162
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000262
[Epoch 72; Iter   263/ 1097] train: loss: 0.0750820
[Epoch 72; Iter   293/ 1097] train: loss: 0.0001001
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000889
[Epoch 72; Iter   353/ 1097] train: loss: 0.0002070
[Epoch 72; Iter   383/ 1097] train: loss: 0.0000396
[Epoch 72; Iter   413/ 1097] train: loss: 0.0345573
[Epoch 72; Iter   443/ 1097] train: loss: 0.0039971
[Epoch 72; Iter   473/ 1097] train: loss: 0.0000966
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002261
[Epoch 72; Iter   533/ 1097] train: loss: 0.0011818
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001253
[Epoch 72; Iter   593/ 1097] train: loss: 0.0072376
[Epoch 72; Iter   623/ 1097] train: loss: 0.0366509
[Epoch 72; Iter   653/ 1097] train: loss: 0.0141456
[Epoch 72; Iter   683/ 1097] train: loss: 0.0117797
[Epoch 72; Iter   713/ 1097] train: loss: 0.0001363
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000850
[Epoch 72; Iter   773/ 1097] train: loss: 0.0086044
[Epoch 72; Iter   803/ 1097] train: loss: 0.0000338
[Epoch 72; Iter   833/ 1097] train: loss: 0.0531110
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000067
[Epoch 72; Iter   893/ 1097] train: loss: 0.0199273
[Epoch 72; Iter   923/ 1097] train: loss: 0.1243393
[Epoch 72; Iter   953/ 1097] train: loss: 0.0016358
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000245
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0014200
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0780304
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0009500
[Epoch 72] ogbg-molhiv: 0.601977 val loss: 51.916261
[Epoch 72] ogbg-molhiv: 0.546712 test loss: 50.321965
[Epoch 73; Iter     6/ 1097] train: loss: 0.0001787
[Epoch 73; Iter    36/ 1097] train: loss: 0.0010909
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001175
[Epoch 73; Iter    96/ 1097] train: loss: 0.0011444
[Epoch 73; Iter   126/ 1097] train: loss: 0.0002208
[Epoch 73; Iter   156/ 1097] train: loss: 0.0013537
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0646751
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0480215
[Epoch 56; Iter  1075/ 1097] train: loss: 0.1316475
[Epoch 56] ogbg-molhiv: 0.806909 val loss: 0.096466
[Epoch 56] ogbg-molhiv: 0.749342 test loss: 0.168501
[Epoch 57; Iter     8/ 1097] train: loss: 0.0339389
[Epoch 57; Iter    38/ 1097] train: loss: 0.0372796
[Epoch 57; Iter    68/ 1097] train: loss: 0.0603657
[Epoch 57; Iter    98/ 1097] train: loss: 0.0253719
[Epoch 57; Iter   128/ 1097] train: loss: 0.0371780
[Epoch 57; Iter   158/ 1097] train: loss: 0.0975750
[Epoch 57; Iter   188/ 1097] train: loss: 0.0099545
[Epoch 57; Iter   218/ 1097] train: loss: 0.0097855
[Epoch 57; Iter   248/ 1097] train: loss: 0.0499757
[Epoch 57; Iter   278/ 1097] train: loss: 0.0152312
[Epoch 57; Iter   308/ 1097] train: loss: 0.1533651
[Epoch 57; Iter   338/ 1097] train: loss: 0.0548816
[Epoch 57; Iter   368/ 1097] train: loss: 0.0498567
[Epoch 57; Iter   398/ 1097] train: loss: 0.1236711
[Epoch 57; Iter   428/ 1097] train: loss: 0.0786215
[Epoch 57; Iter   458/ 1097] train: loss: 0.2028264
[Epoch 57; Iter   488/ 1097] train: loss: 0.0136928
[Epoch 57; Iter   518/ 1097] train: loss: 0.1625620
[Epoch 57; Iter   548/ 1097] train: loss: 0.0090235
[Epoch 57; Iter   578/ 1097] train: loss: 0.0165785
[Epoch 57; Iter   608/ 1097] train: loss: 0.2961018
[Epoch 57; Iter   638/ 1097] train: loss: 0.2127641
[Epoch 57; Iter   668/ 1097] train: loss: 0.0272493
[Epoch 57; Iter   698/ 1097] train: loss: 0.2614498
[Epoch 57; Iter   728/ 1097] train: loss: 0.0678253
[Epoch 57; Iter   758/ 1097] train: loss: 0.0714133
[Epoch 57; Iter   788/ 1097] train: loss: 0.0081145
[Epoch 57; Iter   818/ 1097] train: loss: 0.0281551
[Epoch 57; Iter   848/ 1097] train: loss: 0.0120524
[Epoch 57; Iter   878/ 1097] train: loss: 0.0098857
[Epoch 57; Iter   908/ 1097] train: loss: 0.1325600
[Epoch 57; Iter   938/ 1097] train: loss: 0.0238277
[Epoch 57; Iter   968/ 1097] train: loss: 0.1889798
[Epoch 57; Iter   998/ 1097] train: loss: 0.0083721
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0150860
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0116635
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0072997
[Epoch 57] ogbg-molhiv: 0.810449 val loss: 0.092903
[Epoch 57] ogbg-molhiv: 0.750036 test loss: 0.167489
[Epoch 58; Iter    21/ 1097] train: loss: 0.0092567
[Epoch 58; Iter    51/ 1097] train: loss: 0.0329749
[Epoch 58; Iter    81/ 1097] train: loss: 0.0445025
[Epoch 58; Iter   111/ 1097] train: loss: 0.0413188
[Epoch 58; Iter   141/ 1097] train: loss: 0.1029785
[Epoch 58; Iter   171/ 1097] train: loss: 0.0164561
[Epoch 58; Iter   201/ 1097] train: loss: 0.0441962
[Epoch 58; Iter   231/ 1097] train: loss: 0.1807076
[Epoch 58; Iter   261/ 1097] train: loss: 0.0438652
[Epoch 58; Iter   291/ 1097] train: loss: 0.0066442
[Epoch 58; Iter   321/ 1097] train: loss: 0.0263170
[Epoch 58; Iter   351/ 1097] train: loss: 0.0206694
[Epoch 58; Iter   381/ 1097] train: loss: 0.0945044
[Epoch 58; Iter   411/ 1097] train: loss: 0.0335232
[Epoch 58; Iter   441/ 1097] train: loss: 0.0192694
[Epoch 58; Iter   471/ 1097] train: loss: 0.0113879
[Epoch 58; Iter   501/ 1097] train: loss: 0.0162619
[Epoch 58; Iter   531/ 1097] train: loss: 0.0375030
[Epoch 58; Iter   561/ 1097] train: loss: 0.0104467
[Epoch 58; Iter   591/ 1097] train: loss: 0.0249188
[Epoch 58; Iter   621/ 1097] train: loss: 0.0202875
[Epoch 58; Iter   651/ 1097] train: loss: 0.0224673
[Epoch 58; Iter   681/ 1097] train: loss: 0.0476107
[Epoch 58; Iter   711/ 1097] train: loss: 0.0197380
[Epoch 58; Iter   741/ 1097] train: loss: 0.0234999
[Epoch 58; Iter   771/ 1097] train: loss: 0.0629591
[Epoch 58; Iter   801/ 1097] train: loss: 0.0045923
[Epoch 58; Iter   831/ 1097] train: loss: 0.0088216
[Epoch 58; Iter   861/ 1097] train: loss: 0.0650030
[Epoch 58; Iter   891/ 1097] train: loss: 0.0545651
[Epoch 58; Iter   921/ 1097] train: loss: 0.1624526
[Epoch 58; Iter   951/ 1097] train: loss: 0.0859139
[Epoch 58; Iter   981/ 1097] train: loss: 0.0105616
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0095978
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0081311
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0240619
[Epoch 58] ogbg-molhiv: 0.811860 val loss: 0.097801
[Epoch 58] ogbg-molhiv: 0.741741 test loss: 0.176401
[Epoch 59; Iter     4/ 1097] train: loss: 0.0128515
[Epoch 59; Iter    34/ 1097] train: loss: 0.0187807
[Epoch 59; Iter    64/ 1097] train: loss: 0.0615896
[Epoch 59; Iter    94/ 1097] train: loss: 0.1744278
[Epoch 59; Iter   124/ 1097] train: loss: 0.0030618
[Epoch 59; Iter   154/ 1097] train: loss: 0.0563165
[Epoch 59; Iter   184/ 1097] train: loss: 0.0116480
[Epoch 59; Iter   214/ 1097] train: loss: 0.0126162
[Epoch 59; Iter   244/ 1097] train: loss: 0.0304646
[Epoch 59; Iter   274/ 1097] train: loss: 0.0313288
[Epoch 59; Iter   304/ 1097] train: loss: 0.1645621
[Epoch 59; Iter   334/ 1097] train: loss: 0.0192458
[Epoch 59; Iter   364/ 1097] train: loss: 0.0099962
[Epoch 59; Iter   394/ 1097] train: loss: 0.0248091
[Epoch 59; Iter   424/ 1097] train: loss: 0.0578628
[Epoch 59; Iter   454/ 1097] train: loss: 0.0574081
[Epoch 59; Iter   484/ 1097] train: loss: 0.0060381
[Epoch 59; Iter   514/ 1097] train: loss: 0.0103523
[Epoch 59; Iter   544/ 1097] train: loss: 0.0336456
[Epoch 59; Iter   574/ 1097] train: loss: 0.0236691
[Epoch 59; Iter   604/ 1097] train: loss: 0.0364679
[Epoch 59; Iter   634/ 1097] train: loss: 0.0710812
[Epoch 59; Iter   664/ 1097] train: loss: 0.0035215
[Epoch 59; Iter   694/ 1097] train: loss: 0.0042108
[Epoch 59; Iter   724/ 1097] train: loss: 0.1009505
[Epoch 59; Iter   754/ 1097] train: loss: 0.0907407
[Epoch 59; Iter   784/ 1097] train: loss: 0.0101059
[Epoch 59; Iter   814/ 1097] train: loss: 0.0621389
[Epoch 59; Iter   844/ 1097] train: loss: 0.1114663
[Epoch 59; Iter   874/ 1097] train: loss: 0.0114983
[Epoch 59; Iter   904/ 1097] train: loss: 0.0959191
[Epoch 59; Iter   934/ 1097] train: loss: 0.1722826
[Epoch 59; Iter   964/ 1097] train: loss: 0.0589801
[Epoch 59; Iter   994/ 1097] train: loss: 0.0119553
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0059604
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0063026
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0753599
[Epoch 59] ogbg-molhiv: 0.796189 val loss: 0.100859
[Epoch 59] ogbg-molhiv: 0.745418 test loss: 0.175570
[Epoch 60; Iter    17/ 1097] train: loss: 0.0418234
[Epoch 60; Iter    47/ 1097] train: loss: 0.0116016
[Epoch 60; Iter    77/ 1097] train: loss: 0.0439185
[Epoch 60; Iter   107/ 1097] train: loss: 0.0285942
[Epoch 60; Iter   137/ 1097] train: loss: 0.0900491
[Epoch 60; Iter   167/ 1097] train: loss: 0.0052405
[Epoch 60; Iter   197/ 1097] train: loss: 0.0169892
[Epoch 60; Iter   227/ 1097] train: loss: 0.0047498
[Epoch 60; Iter   257/ 1097] train: loss: 0.0418673
[Epoch 60; Iter   287/ 1097] train: loss: 0.0200373
[Epoch 60; Iter   317/ 1097] train: loss: 0.0432592
[Epoch 60; Iter   347/ 1097] train: loss: 0.0255580
[Epoch 60; Iter   377/ 1097] train: loss: 0.1083201
[Epoch 60; Iter   407/ 1097] train: loss: 0.0110860
[Epoch 60; Iter   437/ 1097] train: loss: 0.0868942
[Epoch 60; Iter   467/ 1097] train: loss: 0.1216777
[Epoch 60; Iter   497/ 1097] train: loss: 0.0150226
[Epoch 60; Iter   527/ 1097] train: loss: 0.0121173
[Epoch 60; Iter   557/ 1097] train: loss: 0.1295907
[Epoch 60; Iter   587/ 1097] train: loss: 0.0499055
[Epoch 60; Iter   617/ 1097] train: loss: 0.0441445
[Epoch 60; Iter   647/ 1097] train: loss: 0.1112411
[Epoch 60; Iter   677/ 1097] train: loss: 0.0163760
[Epoch 60; Iter   707/ 1097] train: loss: 0.0145108
[Epoch 60; Iter   737/ 1097] train: loss: 0.0220055
[Epoch 60; Iter   767/ 1097] train: loss: 0.0327781
[Epoch 60; Iter   797/ 1097] train: loss: 0.0040244
[Epoch 60; Iter   827/ 1097] train: loss: 0.0128939
[Epoch 60; Iter   857/ 1097] train: loss: 0.0119334
[Epoch 60; Iter   887/ 1097] train: loss: 0.0694564
[Epoch 60; Iter   917/ 1097] train: loss: 0.0123322
[Epoch 60; Iter   947/ 1097] train: loss: 0.0137059
[Epoch 60; Iter   977/ 1097] train: loss: 0.0221031
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0064835
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0075448
[Epoch 60; Iter  1067/ 1097] train: loss: 0.1084183
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0872894
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0215170
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0259709
[Epoch 56] ogbg-molhiv: 0.789738 val loss: 0.157601
[Epoch 56] ogbg-molhiv: 0.735959 test loss: 0.295415
[Epoch 57; Iter     8/ 1097] train: loss: 0.0344893
[Epoch 57; Iter    38/ 1097] train: loss: 0.0040818
[Epoch 57; Iter    68/ 1097] train: loss: 0.0338953
[Epoch 57; Iter    98/ 1097] train: loss: 0.0214095
[Epoch 57; Iter   128/ 1097] train: loss: 0.1472165
[Epoch 57; Iter   158/ 1097] train: loss: 0.0096489
[Epoch 57; Iter   188/ 1097] train: loss: 0.0991813
[Epoch 57; Iter   218/ 1097] train: loss: 0.0276012
[Epoch 57; Iter   248/ 1097] train: loss: 0.1492409
[Epoch 57; Iter   278/ 1097] train: loss: 0.0345138
[Epoch 57; Iter   308/ 1097] train: loss: 0.0535603
[Epoch 57; Iter   338/ 1097] train: loss: 0.1318976
[Epoch 57; Iter   368/ 1097] train: loss: 0.0873305
[Epoch 57; Iter   398/ 1097] train: loss: 0.0077414
[Epoch 57; Iter   428/ 1097] train: loss: 0.0903218
[Epoch 57; Iter   458/ 1097] train: loss: 0.0137794
[Epoch 57; Iter   488/ 1097] train: loss: 0.2130148
[Epoch 57; Iter   518/ 1097] train: loss: 0.0623615
[Epoch 57; Iter   548/ 1097] train: loss: 0.0232496
[Epoch 57; Iter   578/ 1097] train: loss: 0.0023180
[Epoch 57; Iter   608/ 1097] train: loss: 0.0705458
[Epoch 57; Iter   638/ 1097] train: loss: 0.1139480
[Epoch 57; Iter   668/ 1097] train: loss: 0.0537937
[Epoch 57; Iter   698/ 1097] train: loss: 0.0733790
[Epoch 57; Iter   728/ 1097] train: loss: 0.0588967
[Epoch 57; Iter   758/ 1097] train: loss: 0.1161771
[Epoch 57; Iter   788/ 1097] train: loss: 0.1156986
[Epoch 57; Iter   818/ 1097] train: loss: 0.0430762
[Epoch 57; Iter   848/ 1097] train: loss: 0.1978732
[Epoch 57; Iter   878/ 1097] train: loss: 0.0800308
[Epoch 57; Iter   908/ 1097] train: loss: 0.0616638
[Epoch 57; Iter   938/ 1097] train: loss: 0.0254997
[Epoch 57; Iter   968/ 1097] train: loss: 0.0307957
[Epoch 57; Iter   998/ 1097] train: loss: 0.0545103
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0507900
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0073694
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0127601
[Epoch 57] ogbg-molhiv: 0.780809 val loss: 0.109631
[Epoch 57] ogbg-molhiv: 0.717496 test loss: 0.207125
[Epoch 58; Iter    21/ 1097] train: loss: 0.0275419
[Epoch 58; Iter    51/ 1097] train: loss: 0.0089390
[Epoch 58; Iter    81/ 1097] train: loss: 0.0310412
[Epoch 58; Iter   111/ 1097] train: loss: 0.0253173
[Epoch 58; Iter   141/ 1097] train: loss: 0.0130562
[Epoch 58; Iter   171/ 1097] train: loss: 0.0219531
[Epoch 58; Iter   201/ 1097] train: loss: 0.1705127
[Epoch 58; Iter   231/ 1097] train: loss: 0.0078070
[Epoch 58; Iter   261/ 1097] train: loss: 0.1192164
[Epoch 58; Iter   291/ 1097] train: loss: 0.0729196
[Epoch 58; Iter   321/ 1097] train: loss: 0.0697696
[Epoch 58; Iter   351/ 1097] train: loss: 0.0088624
[Epoch 58; Iter   381/ 1097] train: loss: 0.0068142
[Epoch 58; Iter   411/ 1097] train: loss: 0.0481604
[Epoch 58; Iter   441/ 1097] train: loss: 0.0167099
[Epoch 58; Iter   471/ 1097] train: loss: 0.0794031
[Epoch 58; Iter   501/ 1097] train: loss: 0.0988400
[Epoch 58; Iter   531/ 1097] train: loss: 0.1514748
[Epoch 58; Iter   561/ 1097] train: loss: 0.0334759
[Epoch 58; Iter   591/ 1097] train: loss: 0.0071100
[Epoch 58; Iter   621/ 1097] train: loss: 0.0249605
[Epoch 58; Iter   651/ 1097] train: loss: 0.0162277
[Epoch 58; Iter   681/ 1097] train: loss: 0.1831346
[Epoch 58; Iter   711/ 1097] train: loss: 0.0050989
[Epoch 58; Iter   741/ 1097] train: loss: 0.0289183
[Epoch 58; Iter   771/ 1097] train: loss: 0.0579506
[Epoch 58; Iter   801/ 1097] train: loss: 0.0095160
[Epoch 58; Iter   831/ 1097] train: loss: 0.0209693
[Epoch 58; Iter   861/ 1097] train: loss: 0.0090828
[Epoch 58; Iter   891/ 1097] train: loss: 0.0168245
[Epoch 58; Iter   921/ 1097] train: loss: 0.0105299
[Epoch 58; Iter   951/ 1097] train: loss: 0.0489018
[Epoch 58; Iter   981/ 1097] train: loss: 0.0270167
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0068067
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0078921
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0110731
[Epoch 58] ogbg-molhiv: 0.794352 val loss: 0.094756
[Epoch 58] ogbg-molhiv: 0.733021 test loss: 0.178677
[Epoch 59; Iter     4/ 1097] train: loss: 0.0030629
[Epoch 59; Iter    34/ 1097] train: loss: 0.0182011
[Epoch 59; Iter    64/ 1097] train: loss: 0.0203273
[Epoch 59; Iter    94/ 1097] train: loss: 0.0619823
[Epoch 59; Iter   124/ 1097] train: loss: 0.0135770
[Epoch 59; Iter   154/ 1097] train: loss: 0.0536823
[Epoch 59; Iter   184/ 1097] train: loss: 0.0233858
[Epoch 59; Iter   214/ 1097] train: loss: 0.0620351
[Epoch 59; Iter   244/ 1097] train: loss: 0.1583385
[Epoch 59; Iter   274/ 1097] train: loss: 0.0211355
[Epoch 59; Iter   304/ 1097] train: loss: 0.1145973
[Epoch 59; Iter   334/ 1097] train: loss: 0.0533456
[Epoch 59; Iter   364/ 1097] train: loss: 0.0175049
[Epoch 59; Iter   394/ 1097] train: loss: 0.0206648
[Epoch 59; Iter   424/ 1097] train: loss: 0.0290611
[Epoch 59; Iter   454/ 1097] train: loss: 0.0594698
[Epoch 59; Iter   484/ 1097] train: loss: 0.0078285
[Epoch 59; Iter   514/ 1097] train: loss: 0.0631186
[Epoch 59; Iter   544/ 1097] train: loss: 0.0261563
[Epoch 59; Iter   574/ 1097] train: loss: 0.2225500
[Epoch 59; Iter   604/ 1097] train: loss: 0.0144564
[Epoch 59; Iter   634/ 1097] train: loss: 0.0444791
[Epoch 59; Iter   664/ 1097] train: loss: 0.1363302
[Epoch 59; Iter   694/ 1097] train: loss: 0.0109822
[Epoch 59; Iter   724/ 1097] train: loss: 0.0161542
[Epoch 59; Iter   754/ 1097] train: loss: 0.0528832
[Epoch 59; Iter   784/ 1097] train: loss: 0.1025538
[Epoch 59; Iter   814/ 1097] train: loss: 0.0210915
[Epoch 59; Iter   844/ 1097] train: loss: 0.0829426
[Epoch 59; Iter   874/ 1097] train: loss: 0.0353822
[Epoch 59; Iter   904/ 1097] train: loss: 0.2038570
[Epoch 59; Iter   934/ 1097] train: loss: 0.0945501
[Epoch 59; Iter   964/ 1097] train: loss: 0.0227925
[Epoch 59; Iter   994/ 1097] train: loss: 0.0162646
[Epoch 59; Iter  1024/ 1097] train: loss: 0.1023480
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0120457
[Epoch 59; Iter  1084/ 1097] train: loss: 0.1238150
[Epoch 59] ogbg-molhiv: 0.805115 val loss: 0.093117
[Epoch 59] ogbg-molhiv: 0.743962 test loss: 0.175967
[Epoch 60; Iter    17/ 1097] train: loss: 0.0162448
[Epoch 60; Iter    47/ 1097] train: loss: 0.0146074
[Epoch 60; Iter    77/ 1097] train: loss: 0.0199540
[Epoch 60; Iter   107/ 1097] train: loss: 0.0144851
[Epoch 60; Iter   137/ 1097] train: loss: 0.0079584
[Epoch 60; Iter   167/ 1097] train: loss: 0.0454675
[Epoch 60; Iter   197/ 1097] train: loss: 0.0373284
[Epoch 60; Iter   227/ 1097] train: loss: 0.0963887
[Epoch 60; Iter   257/ 1097] train: loss: 0.0503750
[Epoch 60; Iter   287/ 1097] train: loss: 0.0201073
[Epoch 60; Iter   317/ 1097] train: loss: 0.0154411
[Epoch 60; Iter   347/ 1097] train: loss: 0.0138912
[Epoch 60; Iter   377/ 1097] train: loss: 0.0161627
[Epoch 60; Iter   407/ 1097] train: loss: 0.0610920
[Epoch 60; Iter   437/ 1097] train: loss: 0.0242893
[Epoch 60; Iter   467/ 1097] train: loss: 0.0093347
[Epoch 60; Iter   497/ 1097] train: loss: 0.0278669
[Epoch 60; Iter   527/ 1097] train: loss: 0.0105353
[Epoch 60; Iter   557/ 1097] train: loss: 0.0725771
[Epoch 60; Iter   587/ 1097] train: loss: 0.0255585
[Epoch 60; Iter   617/ 1097] train: loss: 0.0231405
[Epoch 60; Iter   647/ 1097] train: loss: 0.0035981
[Epoch 60; Iter   677/ 1097] train: loss: 0.0094982
[Epoch 60; Iter   707/ 1097] train: loss: 0.0792416
[Epoch 60; Iter   737/ 1097] train: loss: 0.0174109
[Epoch 60; Iter   767/ 1097] train: loss: 0.0394705
[Epoch 60; Iter   797/ 1097] train: loss: 0.0172103
[Epoch 60; Iter   827/ 1097] train: loss: 0.0378199
[Epoch 60; Iter   857/ 1097] train: loss: 0.1503452
[Epoch 60; Iter   887/ 1097] train: loss: 0.0102370
[Epoch 60; Iter   917/ 1097] train: loss: 0.2341542
[Epoch 60; Iter   947/ 1097] train: loss: 0.2127752
[Epoch 60; Iter   977/ 1097] train: loss: 0.0123662
[Epoch 60; Iter  1007/ 1097] train: loss: 0.1316673
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0148247
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0240706
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0208898
[Epoch 56; Iter  1045/ 1097] train: loss: 0.1769281
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0310669
[Epoch 56] ogbg-molhiv: 0.803749 val loss: 0.095952
[Epoch 56] ogbg-molhiv: 0.752403 test loss: 0.167980
[Epoch 57; Iter     8/ 1097] train: loss: 0.0400393
[Epoch 57; Iter    38/ 1097] train: loss: 0.0171711
[Epoch 57; Iter    68/ 1097] train: loss: 0.1012090
[Epoch 57; Iter    98/ 1097] train: loss: 0.1158598
[Epoch 57; Iter   128/ 1097] train: loss: 0.0095224
[Epoch 57; Iter   158/ 1097] train: loss: 0.0100378
[Epoch 57; Iter   188/ 1097] train: loss: 0.0030492
[Epoch 57; Iter   218/ 1097] train: loss: 0.0056475
[Epoch 57; Iter   248/ 1097] train: loss: 0.0313264
[Epoch 57; Iter   278/ 1097] train: loss: 0.0079817
[Epoch 57; Iter   308/ 1097] train: loss: 0.0264327
[Epoch 57; Iter   338/ 1097] train: loss: 0.0150385
[Epoch 57; Iter   368/ 1097] train: loss: 0.0127295
[Epoch 57; Iter   398/ 1097] train: loss: 0.0172625
[Epoch 57; Iter   428/ 1097] train: loss: 0.0090954
[Epoch 57; Iter   458/ 1097] train: loss: 0.0320685
[Epoch 57; Iter   488/ 1097] train: loss: 0.0032037
[Epoch 57; Iter   518/ 1097] train: loss: 0.0033817
[Epoch 57; Iter   548/ 1097] train: loss: 0.1065569
[Epoch 57; Iter   578/ 1097] train: loss: 0.0640620
[Epoch 57; Iter   608/ 1097] train: loss: 0.0476266
[Epoch 57; Iter   638/ 1097] train: loss: 0.0224127
[Epoch 57; Iter   668/ 1097] train: loss: 0.0282106
[Epoch 57; Iter   698/ 1097] train: loss: 0.0284457
[Epoch 57; Iter   728/ 1097] train: loss: 0.0182258
[Epoch 57; Iter   758/ 1097] train: loss: 0.0058613
[Epoch 57; Iter   788/ 1097] train: loss: 0.0943961
[Epoch 57; Iter   818/ 1097] train: loss: 0.0440877
[Epoch 57; Iter   848/ 1097] train: loss: 0.0094090
[Epoch 57; Iter   878/ 1097] train: loss: 0.0049062
[Epoch 57; Iter   908/ 1097] train: loss: 0.0261578
[Epoch 57; Iter   938/ 1097] train: loss: 0.0180835
[Epoch 57; Iter   968/ 1097] train: loss: 0.0349557
[Epoch 57; Iter   998/ 1097] train: loss: 0.0801061
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0051808
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0038230
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0034458
[Epoch 57] ogbg-molhiv: 0.795142 val loss: 0.103370
[Epoch 57] ogbg-molhiv: 0.734311 test loss: 0.197698
[Epoch 58; Iter    21/ 1097] train: loss: 0.0046634
[Epoch 58; Iter    51/ 1097] train: loss: 0.0162445
[Epoch 58; Iter    81/ 1097] train: loss: 0.0258088
[Epoch 58; Iter   111/ 1097] train: loss: 0.0110892
[Epoch 58; Iter   141/ 1097] train: loss: 0.0072721
[Epoch 58; Iter   171/ 1097] train: loss: 0.0077335
[Epoch 58; Iter   201/ 1097] train: loss: 0.0152156
[Epoch 58; Iter   231/ 1097] train: loss: 0.0347738
[Epoch 58; Iter   261/ 1097] train: loss: 0.0076510
[Epoch 58; Iter   291/ 1097] train: loss: 0.0091329
[Epoch 58; Iter   321/ 1097] train: loss: 0.0444646
[Epoch 58; Iter   351/ 1097] train: loss: 0.1047874
[Epoch 58; Iter   381/ 1097] train: loss: 0.1511738
[Epoch 58; Iter   411/ 1097] train: loss: 0.0560259
[Epoch 58; Iter   441/ 1097] train: loss: 0.0124581
[Epoch 58; Iter   471/ 1097] train: loss: 0.0141626
[Epoch 58; Iter   501/ 1097] train: loss: 0.0083223
[Epoch 58; Iter   531/ 1097] train: loss: 0.0072215
[Epoch 58; Iter   561/ 1097] train: loss: 0.0343170
[Epoch 58; Iter   591/ 1097] train: loss: 0.0428632
[Epoch 58; Iter   621/ 1097] train: loss: 0.0790895
[Epoch 58; Iter   651/ 1097] train: loss: 0.0340439
[Epoch 58; Iter   681/ 1097] train: loss: 0.0165232
[Epoch 58; Iter   711/ 1097] train: loss: 0.3055798
[Epoch 58; Iter   741/ 1097] train: loss: 0.0629857
[Epoch 58; Iter   771/ 1097] train: loss: 0.0140334
[Epoch 58; Iter   801/ 1097] train: loss: 0.0106152
[Epoch 58; Iter   831/ 1097] train: loss: 0.0644748
[Epoch 58; Iter   861/ 1097] train: loss: 0.0035829
[Epoch 58; Iter   891/ 1097] train: loss: 0.0060032
[Epoch 58; Iter   921/ 1097] train: loss: 0.0067173
[Epoch 58; Iter   951/ 1097] train: loss: 0.0159437
[Epoch 58; Iter   981/ 1097] train: loss: 0.0848527
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0071230
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0440675
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0371791
[Epoch 58] ogbg-molhiv: 0.807494 val loss: 0.114857
[Epoch 58] ogbg-molhiv: 0.753914 test loss: 0.198956
[Epoch 59; Iter     4/ 1097] train: loss: 0.0094629
[Epoch 59; Iter    34/ 1097] train: loss: 0.0138768
[Epoch 59; Iter    64/ 1097] train: loss: 0.0194466
[Epoch 59; Iter    94/ 1097] train: loss: 0.1060402
[Epoch 59; Iter   124/ 1097] train: loss: 0.0311159
[Epoch 59; Iter   154/ 1097] train: loss: 0.0069294
[Epoch 59; Iter   184/ 1097] train: loss: 0.0096790
[Epoch 59; Iter   214/ 1097] train: loss: 0.0186958
[Epoch 59; Iter   244/ 1097] train: loss: 0.0016423
[Epoch 59; Iter   274/ 1097] train: loss: 0.0068355
[Epoch 59; Iter   304/ 1097] train: loss: 0.0415103
[Epoch 59; Iter   334/ 1097] train: loss: 0.0997775
[Epoch 59; Iter   364/ 1097] train: loss: 0.0588661
[Epoch 59; Iter   394/ 1097] train: loss: 0.0050041
[Epoch 59; Iter   424/ 1097] train: loss: 0.0058392
[Epoch 59; Iter   454/ 1097] train: loss: 0.0071009
[Epoch 59; Iter   484/ 1097] train: loss: 0.1241786
[Epoch 59; Iter   514/ 1097] train: loss: 0.1167046
[Epoch 59; Iter   544/ 1097] train: loss: 0.0606954
[Epoch 59; Iter   574/ 1097] train: loss: 0.0034643
[Epoch 59; Iter   604/ 1097] train: loss: 0.0134693
[Epoch 59; Iter   634/ 1097] train: loss: 0.0174188
[Epoch 59; Iter   664/ 1097] train: loss: 0.0330385
[Epoch 59; Iter   694/ 1097] train: loss: 0.0086633
[Epoch 59; Iter   724/ 1097] train: loss: 0.0070588
[Epoch 59; Iter   754/ 1097] train: loss: 0.0132784
[Epoch 59; Iter   784/ 1097] train: loss: 0.0030006
[Epoch 59; Iter   814/ 1097] train: loss: 0.1323575
[Epoch 59; Iter   844/ 1097] train: loss: 0.0152112
[Epoch 59; Iter   874/ 1097] train: loss: 0.1597935
[Epoch 59; Iter   904/ 1097] train: loss: 0.0815689
[Epoch 59; Iter   934/ 1097] train: loss: 0.0216224
[Epoch 59; Iter   964/ 1097] train: loss: 0.0118864
[Epoch 59; Iter   994/ 1097] train: loss: 0.0115021
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0042456
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0070596
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0878662
[Epoch 59] ogbg-molhiv: 0.803593 val loss: 0.109561
[Epoch 59] ogbg-molhiv: 0.742150 test loss: 0.192775
[Epoch 60; Iter    17/ 1097] train: loss: 0.0066736
[Epoch 60; Iter    47/ 1097] train: loss: 0.0118840
[Epoch 60; Iter    77/ 1097] train: loss: 0.0125199
[Epoch 60; Iter   107/ 1097] train: loss: 0.0163499
[Epoch 60; Iter   137/ 1097] train: loss: 0.0300454
[Epoch 60; Iter   167/ 1097] train: loss: 0.0071923
[Epoch 60; Iter   197/ 1097] train: loss: 0.0079515
[Epoch 60; Iter   227/ 1097] train: loss: 0.0232932
[Epoch 60; Iter   257/ 1097] train: loss: 0.0096017
[Epoch 60; Iter   287/ 1097] train: loss: 0.0043231
[Epoch 60; Iter   317/ 1097] train: loss: 0.0232173
[Epoch 60; Iter   347/ 1097] train: loss: 0.1887882
[Epoch 60; Iter   377/ 1097] train: loss: 0.0104020
[Epoch 60; Iter   407/ 1097] train: loss: 0.0222072
[Epoch 60; Iter   437/ 1097] train: loss: 0.0186638
[Epoch 60; Iter   467/ 1097] train: loss: 0.0517258
[Epoch 60; Iter   497/ 1097] train: loss: 0.0161477
[Epoch 60; Iter   527/ 1097] train: loss: 0.0037145
[Epoch 60; Iter   557/ 1097] train: loss: 0.0078910
[Epoch 60; Iter   587/ 1097] train: loss: 0.0672101
[Epoch 60; Iter   617/ 1097] train: loss: 0.0642446
[Epoch 60; Iter   647/ 1097] train: loss: 0.0107255
[Epoch 60; Iter   677/ 1097] train: loss: 0.0100260
[Epoch 60; Iter   707/ 1097] train: loss: 0.0917077
[Epoch 60; Iter   737/ 1097] train: loss: 0.0173553
[Epoch 60; Iter   767/ 1097] train: loss: 0.0154306
[Epoch 60; Iter   797/ 1097] train: loss: 0.0049072
[Epoch 60; Iter   827/ 1097] train: loss: 0.0099966
[Epoch 60; Iter   857/ 1097] train: loss: 0.0285666
[Epoch 60; Iter   887/ 1097] train: loss: 0.0139834
[Epoch 60; Iter   917/ 1097] train: loss: 0.0376959
[Epoch 60; Iter   947/ 1097] train: loss: 0.0146557
[Epoch 60; Iter   977/ 1097] train: loss: 0.0648187
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0142958
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0842366
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0261882
[Epoch 73; Iter   186/ 1097] train: loss: 0.0001245
[Epoch 73; Iter   216/ 1097] train: loss: 0.0487431
[Epoch 73; Iter   246/ 1097] train: loss: 0.0006539
[Epoch 73; Iter   276/ 1097] train: loss: 0.0008523
[Epoch 73; Iter   306/ 1097] train: loss: 0.0001283
[Epoch 73; Iter   336/ 1097] train: loss: 0.0003906
[Epoch 73; Iter   366/ 1097] train: loss: 0.1571003
[Epoch 73; Iter   396/ 1097] train: loss: 0.0572087
[Epoch 73; Iter   426/ 1097] train: loss: 0.0016038
[Epoch 73; Iter   456/ 1097] train: loss: 0.0105762
[Epoch 73; Iter   486/ 1097] train: loss: 0.0031084
[Epoch 73; Iter   516/ 1097] train: loss: 0.0021086
[Epoch 73; Iter   546/ 1097] train: loss: 0.0026785
[Epoch 73; Iter   576/ 1097] train: loss: 0.0026949
[Epoch 73; Iter   606/ 1097] train: loss: 0.0436744
[Epoch 73; Iter   636/ 1097] train: loss: 0.0006557
[Epoch 73; Iter   666/ 1097] train: loss: 0.0038794
[Epoch 73; Iter   696/ 1097] train: loss: 0.0000859
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001476
[Epoch 73; Iter   756/ 1097] train: loss: 0.0043531
[Epoch 73; Iter   786/ 1097] train: loss: 0.0035967
[Epoch 73; Iter   816/ 1097] train: loss: 0.0000302
[Epoch 73; Iter   846/ 1097] train: loss: 0.0501572
[Epoch 73; Iter   876/ 1097] train: loss: 0.0058695
[Epoch 73; Iter   906/ 1097] train: loss: 0.0108722
[Epoch 73; Iter   936/ 1097] train: loss: 0.0007701
[Epoch 73; Iter   966/ 1097] train: loss: 0.0001158
[Epoch 73; Iter   996/ 1097] train: loss: 0.0011896
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0052690
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0002036
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0056303
[Epoch 73] ogbg-molhiv: 0.741289 val loss: 1.833760
[Epoch 73] ogbg-molhiv: 0.714342 test loss: 1.289315
[Epoch 74; Iter    19/ 1097] train: loss: 0.0017908
[Epoch 74; Iter    49/ 1097] train: loss: 0.0004202
[Epoch 74; Iter    79/ 1097] train: loss: 0.0279389
[Epoch 74; Iter   109/ 1097] train: loss: 0.0936747
[Epoch 74; Iter   139/ 1097] train: loss: 0.0004344
[Epoch 74; Iter   169/ 1097] train: loss: 0.0014849
[Epoch 74; Iter   199/ 1097] train: loss: 0.0078381
[Epoch 74; Iter   229/ 1097] train: loss: 0.0001240
[Epoch 74; Iter   259/ 1097] train: loss: 0.0028787
[Epoch 74; Iter   289/ 1097] train: loss: 0.0004169
[Epoch 74; Iter   319/ 1097] train: loss: 0.2361460
[Epoch 74; Iter   349/ 1097] train: loss: 0.0001785
[Epoch 74; Iter   379/ 1097] train: loss: 0.0020408
[Epoch 74; Iter   409/ 1097] train: loss: 0.0008466
[Epoch 74; Iter   439/ 1097] train: loss: 0.0010183
[Epoch 74; Iter   469/ 1097] train: loss: 0.0003645
[Epoch 74; Iter   499/ 1097] train: loss: 0.0002588
[Epoch 74; Iter   529/ 1097] train: loss: 0.0053256
[Epoch 74; Iter   559/ 1097] train: loss: 0.0006618
[Epoch 74; Iter   589/ 1097] train: loss: 0.0007815
[Epoch 74; Iter   619/ 1097] train: loss: 0.0031658
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001634
[Epoch 74; Iter   679/ 1097] train: loss: 0.0004813
[Epoch 74; Iter   709/ 1097] train: loss: 0.2172703
[Epoch 74; Iter   739/ 1097] train: loss: 0.0166110
[Epoch 74; Iter   769/ 1097] train: loss: 0.0009900
[Epoch 74; Iter   799/ 1097] train: loss: 0.1312601
[Epoch 74; Iter   829/ 1097] train: loss: 0.0021610
[Epoch 74; Iter   859/ 1097] train: loss: 0.0004487
[Epoch 74; Iter   889/ 1097] train: loss: 0.0012333
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000576
[Epoch 74; Iter   949/ 1097] train: loss: 0.0021115
[Epoch 74; Iter   979/ 1097] train: loss: 0.0006850
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0293225
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0048390
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0001293
[Epoch 74] ogbg-molhiv: 0.762575 val loss: 0.909353
[Epoch 74] ogbg-molhiv: 0.742585 test loss: 0.950220
[Epoch 75; Iter     2/ 1097] train: loss: 0.0177257
[Epoch 75; Iter    32/ 1097] train: loss: 0.0143599
[Epoch 75; Iter    62/ 1097] train: loss: 0.0039446
[Epoch 75; Iter    92/ 1097] train: loss: 0.0006272
[Epoch 75; Iter   122/ 1097] train: loss: 0.0008471
[Epoch 75; Iter   152/ 1097] train: loss: 0.0075265
[Epoch 75; Iter   182/ 1097] train: loss: 0.0045618
[Epoch 75; Iter   212/ 1097] train: loss: 0.0011725
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000333
[Epoch 75; Iter   272/ 1097] train: loss: 0.0003356
[Epoch 75; Iter   302/ 1097] train: loss: 0.0025029
[Epoch 75; Iter   332/ 1097] train: loss: 0.0003551
[Epoch 75; Iter   362/ 1097] train: loss: 0.0004766
[Epoch 75; Iter   392/ 1097] train: loss: 0.0810980
[Epoch 75; Iter   422/ 1097] train: loss: 0.0006927
[Epoch 75; Iter   452/ 1097] train: loss: 0.0214499
[Epoch 75; Iter   482/ 1097] train: loss: 0.0003889
[Epoch 75; Iter   512/ 1097] train: loss: 0.0002298
[Epoch 75; Iter   542/ 1097] train: loss: 0.0009333
[Epoch 75; Iter   572/ 1097] train: loss: 0.0184262
[Epoch 75; Iter   602/ 1097] train: loss: 0.0040424
[Epoch 75; Iter   632/ 1097] train: loss: 0.0003323
[Epoch 75; Iter   662/ 1097] train: loss: 0.0124364
[Epoch 75; Iter   692/ 1097] train: loss: 0.0002949
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000440
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000649
[Epoch 75; Iter   782/ 1097] train: loss: 0.0025169
[Epoch 75; Iter   812/ 1097] train: loss: 0.0016574
[Epoch 75; Iter   842/ 1097] train: loss: 0.0002587
[Epoch 75; Iter   872/ 1097] train: loss: 0.0010540
[Epoch 75; Iter   902/ 1097] train: loss: 0.0041363
[Epoch 75; Iter   932/ 1097] train: loss: 0.0171296
[Epoch 75; Iter   962/ 1097] train: loss: 0.0642206
[Epoch 75; Iter   992/ 1097] train: loss: 0.0313464
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0310573
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0043477
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0199625
[Epoch 75] ogbg-molhiv: 0.756577 val loss: 0.310987
[Epoch 75] ogbg-molhiv: 0.710863 test loss: 0.366335
[Epoch 76; Iter    15/ 1097] train: loss: 0.0031491
[Epoch 76; Iter    45/ 1097] train: loss: 0.0064090
[Epoch 76; Iter    75/ 1097] train: loss: 0.0018050
[Epoch 76; Iter   105/ 1097] train: loss: 0.0001476
[Epoch 76; Iter   135/ 1097] train: loss: 0.0022732
[Epoch 76; Iter   165/ 1097] train: loss: 0.0006518
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001792
[Epoch 76; Iter   225/ 1097] train: loss: 0.0254317
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000980
[Epoch 76; Iter   285/ 1097] train: loss: 0.0002703
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000295
[Epoch 76; Iter   345/ 1097] train: loss: 0.0054988
[Epoch 76; Iter   375/ 1097] train: loss: 0.0146256
[Epoch 76; Iter   405/ 1097] train: loss: 0.0033289
[Epoch 76; Iter   435/ 1097] train: loss: 0.0053657
[Epoch 76; Iter   465/ 1097] train: loss: 0.0009261
[Epoch 76; Iter   495/ 1097] train: loss: 0.0018038
[Epoch 76; Iter   525/ 1097] train: loss: 0.0029681
[Epoch 76; Iter   555/ 1097] train: loss: 0.0001494
[Epoch 76; Iter   585/ 1097] train: loss: 0.0000647
[Epoch 76; Iter   615/ 1097] train: loss: 0.0007799
[Epoch 76; Iter   645/ 1097] train: loss: 0.0196312
[Epoch 76; Iter   675/ 1097] train: loss: 0.0006441
[Epoch 76; Iter   705/ 1097] train: loss: 0.0014310
[Epoch 76; Iter   735/ 1097] train: loss: 0.0012282
[Epoch 76; Iter   765/ 1097] train: loss: 0.0045233
[Epoch 76; Iter   795/ 1097] train: loss: 0.0006974
[Epoch 76; Iter   825/ 1097] train: loss: 0.0029799
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000447
[Epoch 76; Iter   885/ 1097] train: loss: 0.0154462
[Epoch 76; Iter   915/ 1097] train: loss: 0.0004774
[Epoch 76; Iter   945/ 1097] train: loss: 0.0005089
[Epoch 76; Iter   975/ 1097] train: loss: 0.0007176
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0001382
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0010356
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0018546
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0879023
[Epoch 76] ogbg-molhiv: 0.771945 val loss: 1.060261
[Epoch 76] ogbg-molhiv: 0.730902 test loss: 1.179119
[Epoch 77; Iter    28/ 1097] train: loss: 0.0007797
[Epoch 77; Iter    58/ 1097] train: loss: 0.0021567
[Epoch 77; Iter    88/ 1097] train: loss: 0.0031698
[Epoch 77; Iter   118/ 1097] train: loss: 0.0293090
[Epoch 77; Iter   148/ 1097] train: loss: 0.0114487
[Epoch 77; Iter   178/ 1097] train: loss: 0.0125911
[Epoch 77; Iter   208/ 1097] train: loss: 0.0053697
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000324
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000150
[Epoch 73; Iter   216/ 1097] train: loss: 0.0000176
[Epoch 73; Iter   246/ 1097] train: loss: 0.0001552
[Epoch 73; Iter   276/ 1097] train: loss: 0.0000290
[Epoch 73; Iter   306/ 1097] train: loss: 0.0003849
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000031
[Epoch 73; Iter   366/ 1097] train: loss: 0.0003279
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000177
[Epoch 73; Iter   426/ 1097] train: loss: 0.0007426
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000079
[Epoch 73; Iter   486/ 1097] train: loss: 0.0001162
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000070
[Epoch 73; Iter   546/ 1097] train: loss: 0.0025206
[Epoch 73; Iter   576/ 1097] train: loss: 0.0000709
[Epoch 73; Iter   606/ 1097] train: loss: 0.0002038
[Epoch 73; Iter   636/ 1097] train: loss: 0.0030450
[Epoch 73; Iter   666/ 1097] train: loss: 0.0002104
[Epoch 73; Iter   696/ 1097] train: loss: 0.0034422
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001372
[Epoch 73; Iter   756/ 1097] train: loss: 0.0002917
[Epoch 73; Iter   786/ 1097] train: loss: 0.0002366
[Epoch 73; Iter   816/ 1097] train: loss: 0.0000728
[Epoch 73; Iter   846/ 1097] train: loss: 0.0000167
[Epoch 73; Iter   876/ 1097] train: loss: 0.0040190
[Epoch 73; Iter   906/ 1097] train: loss: 0.0240022
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000909
[Epoch 73; Iter   966/ 1097] train: loss: 0.0001856
[Epoch 73; Iter   996/ 1097] train: loss: 0.0149468
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0021411
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0028324
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0008331
[Epoch 73] ogbg-molhiv: 0.773225 val loss: 0.246513
[Epoch 73] ogbg-molhiv: 0.713806 test loss: 0.349686
[Epoch 74; Iter    19/ 1097] train: loss: 0.0000957
[Epoch 74; Iter    49/ 1097] train: loss: 0.0005869
[Epoch 74; Iter    79/ 1097] train: loss: 0.0011036
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000169
[Epoch 74; Iter   139/ 1097] train: loss: 0.0005405
[Epoch 74; Iter   169/ 1097] train: loss: 0.0052551
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001280
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000438
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000475
[Epoch 74; Iter   289/ 1097] train: loss: 0.0001330
[Epoch 74; Iter   319/ 1097] train: loss: 0.0006756
[Epoch 74; Iter   349/ 1097] train: loss: 0.0175473
[Epoch 74; Iter   379/ 1097] train: loss: 0.0000512
[Epoch 74; Iter   409/ 1097] train: loss: 0.0000606
[Epoch 74; Iter   439/ 1097] train: loss: 0.0000629
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001222
[Epoch 74; Iter   499/ 1097] train: loss: 0.0003304
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000098
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000124
[Epoch 74; Iter   589/ 1097] train: loss: 0.0000213
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000774
[Epoch 74; Iter   649/ 1097] train: loss: 0.0031722
[Epoch 74; Iter   679/ 1097] train: loss: 0.0014153
[Epoch 74; Iter   709/ 1097] train: loss: 0.0000259
[Epoch 74; Iter   739/ 1097] train: loss: 0.0003826
[Epoch 74; Iter   769/ 1097] train: loss: 0.0001617
[Epoch 74; Iter   799/ 1097] train: loss: 0.0000602
[Epoch 74; Iter   829/ 1097] train: loss: 0.0045312
[Epoch 74; Iter   859/ 1097] train: loss: 0.0000894
[Epoch 74; Iter   889/ 1097] train: loss: 0.0055039
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000418
[Epoch 74; Iter   949/ 1097] train: loss: 0.0032525
[Epoch 74; Iter   979/ 1097] train: loss: 0.0002710
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0100267
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0010170
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0003419
[Epoch 74] ogbg-molhiv: 0.771087 val loss: 0.239993
[Epoch 74] ogbg-molhiv: 0.716586 test loss: 0.366320
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000178
[Epoch 75; Iter    32/ 1097] train: loss: 0.0000038
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000050
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001627
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000101
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000117
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000260
[Epoch 75; Iter   212/ 1097] train: loss: 0.0001325
[Epoch 75; Iter   242/ 1097] train: loss: 0.0003812
[Epoch 75; Iter   272/ 1097] train: loss: 0.0113067
[Epoch 75; Iter   302/ 1097] train: loss: 0.0020636
[Epoch 75; Iter   332/ 1097] train: loss: 0.0007250
[Epoch 75; Iter   362/ 1097] train: loss: 0.0006102
[Epoch 75; Iter   392/ 1097] train: loss: 0.0031691
[Epoch 75; Iter   422/ 1097] train: loss: 0.0042542
[Epoch 75; Iter   452/ 1097] train: loss: 0.0013085
[Epoch 75; Iter   482/ 1097] train: loss: 0.0001785
[Epoch 75; Iter   512/ 1097] train: loss: 0.0000164
[Epoch 75; Iter   542/ 1097] train: loss: 0.0001293
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000124
[Epoch 75; Iter   602/ 1097] train: loss: 0.0008590
[Epoch 75; Iter   632/ 1097] train: loss: 0.0006042
[Epoch 75; Iter   662/ 1097] train: loss: 0.0036881
[Epoch 75; Iter   692/ 1097] train: loss: 0.0013547
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000478
[Epoch 75; Iter   752/ 1097] train: loss: 0.0001446
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000982
[Epoch 75; Iter   812/ 1097] train: loss: 0.0001672
[Epoch 75; Iter   842/ 1097] train: loss: 0.0266582
[Epoch 75; Iter   872/ 1097] train: loss: 0.0009853
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000132
[Epoch 75; Iter   932/ 1097] train: loss: 0.0000642
[Epoch 75; Iter   962/ 1097] train: loss: 0.0006976
[Epoch 75; Iter   992/ 1097] train: loss: 0.0023654
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0018996
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0089592
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0006619
[Epoch 75] ogbg-molhiv: 0.775258 val loss: 0.222890
[Epoch 75] ogbg-molhiv: 0.733981 test loss: 0.360239
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000421
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000598
[Epoch 76; Iter    75/ 1097] train: loss: 0.0000538
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000565
[Epoch 76; Iter   135/ 1097] train: loss: 0.0000215
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000139
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000145
[Epoch 76; Iter   225/ 1097] train: loss: 0.0054096
[Epoch 76; Iter   255/ 1097] train: loss: 0.0013152
[Epoch 76; Iter   285/ 1097] train: loss: 0.0030827
[Epoch 76; Iter   315/ 1097] train: loss: 0.0001042
[Epoch 76; Iter   345/ 1097] train: loss: 0.0001121
[Epoch 76; Iter   375/ 1097] train: loss: 0.0060971
[Epoch 76; Iter   405/ 1097] train: loss: 0.0001531
[Epoch 76; Iter   435/ 1097] train: loss: 0.0004934
[Epoch 76; Iter   465/ 1097] train: loss: 0.0005390
[Epoch 76; Iter   495/ 1097] train: loss: 0.0003209
[Epoch 76; Iter   525/ 1097] train: loss: 0.0002957
[Epoch 76; Iter   555/ 1097] train: loss: 0.0153815
[Epoch 76; Iter   585/ 1097] train: loss: 0.0034549
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000876
[Epoch 76; Iter   645/ 1097] train: loss: 0.0005889
[Epoch 76; Iter   675/ 1097] train: loss: 0.0000032
[Epoch 76; Iter   705/ 1097] train: loss: 0.0010701
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000362
[Epoch 76; Iter   765/ 1097] train: loss: 0.0009861
[Epoch 76; Iter   795/ 1097] train: loss: 0.0001872
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000187
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001006
[Epoch 76; Iter   885/ 1097] train: loss: 0.0001160
[Epoch 76; Iter   915/ 1097] train: loss: 0.0000516
[Epoch 76; Iter   945/ 1097] train: loss: 0.0001009
[Epoch 76; Iter   975/ 1097] train: loss: 0.0000064
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0004435
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000393
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0002749
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0000780
[Epoch 76] ogbg-molhiv: 0.775524 val loss: 0.244115
[Epoch 76] ogbg-molhiv: 0.727490 test loss: 0.383016
[Epoch 77; Iter    28/ 1097] train: loss: 0.0011340
[Epoch 77; Iter    58/ 1097] train: loss: 0.0123691
[Epoch 77; Iter    88/ 1097] train: loss: 0.0060730
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002976
[Epoch 77; Iter   148/ 1097] train: loss: 0.0086074
[Epoch 77; Iter   178/ 1097] train: loss: 0.0016820
[Epoch 77; Iter   208/ 1097] train: loss: 0.0003831
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000125
[Epoch 73; Iter   186/ 1097] train: loss: 0.0002439
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001095
[Epoch 73; Iter   246/ 1097] train: loss: 0.0005966
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001815
[Epoch 73; Iter   306/ 1097] train: loss: 0.0028576
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000908
[Epoch 73; Iter   366/ 1097] train: loss: 0.0003078
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000108
[Epoch 73; Iter   426/ 1097] train: loss: 0.0001077
[Epoch 73; Iter   456/ 1097] train: loss: 0.0002320
[Epoch 73; Iter   486/ 1097] train: loss: 0.0000157
[Epoch 73; Iter   516/ 1097] train: loss: 0.0002521
[Epoch 73; Iter   546/ 1097] train: loss: 0.0001726
[Epoch 73; Iter   576/ 1097] train: loss: 0.0000892
[Epoch 73; Iter   606/ 1097] train: loss: 0.0009328
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001081
[Epoch 73; Iter   666/ 1097] train: loss: 0.0333195
[Epoch 73; Iter   696/ 1097] train: loss: 0.0001665
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001953
[Epoch 73; Iter   756/ 1097] train: loss: 0.0008430
[Epoch 73; Iter   786/ 1097] train: loss: 0.0130361
[Epoch 73; Iter   816/ 1097] train: loss: 0.0012171
[Epoch 73; Iter   846/ 1097] train: loss: 0.0003571
[Epoch 73; Iter   876/ 1097] train: loss: 0.0005213
[Epoch 73; Iter   906/ 1097] train: loss: 0.0007427
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000508
[Epoch 73; Iter   966/ 1097] train: loss: 0.0120598
[Epoch 73; Iter   996/ 1097] train: loss: 0.0021822
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0003381
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0001320
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0063012
[Epoch 73] ogbg-molhiv: 0.744556 val loss: 0.335759
[Epoch 73] ogbg-molhiv: 0.753667 test loss: 0.351640
[Epoch 74; Iter    19/ 1097] train: loss: 0.0008089
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000474
[Epoch 74; Iter    79/ 1097] train: loss: 0.0001785
[Epoch 74; Iter   109/ 1097] train: loss: 0.0005021
[Epoch 74; Iter   139/ 1097] train: loss: 0.0005742
[Epoch 74; Iter   169/ 1097] train: loss: 0.0000432
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000482
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000313
[Epoch 74; Iter   259/ 1097] train: loss: 0.0121655
[Epoch 74; Iter   289/ 1097] train: loss: 0.0000113
[Epoch 74; Iter   319/ 1097] train: loss: 0.0009423
[Epoch 74; Iter   349/ 1097] train: loss: 0.0008431
[Epoch 74; Iter   379/ 1097] train: loss: 0.0020702
[Epoch 74; Iter   409/ 1097] train: loss: 0.0002505
[Epoch 74; Iter   439/ 1097] train: loss: 0.0002541
[Epoch 74; Iter   469/ 1097] train: loss: 0.0003951
[Epoch 74; Iter   499/ 1097] train: loss: 0.0067651
[Epoch 74; Iter   529/ 1097] train: loss: 0.0033077
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000109
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001716
[Epoch 74; Iter   619/ 1097] train: loss: 0.0027549
[Epoch 74; Iter   649/ 1097] train: loss: 0.0002142
[Epoch 74; Iter   679/ 1097] train: loss: 0.0073436
[Epoch 74; Iter   709/ 1097] train: loss: 0.0006358
[Epoch 74; Iter   739/ 1097] train: loss: 0.0463667
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000453
[Epoch 74; Iter   799/ 1097] train: loss: 0.0017686
[Epoch 74; Iter   829/ 1097] train: loss: 0.0001032
[Epoch 74; Iter   859/ 1097] train: loss: 0.0116037
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000486
[Epoch 74; Iter   919/ 1097] train: loss: 0.0031064
[Epoch 74; Iter   949/ 1097] train: loss: 0.0005506
[Epoch 74; Iter   979/ 1097] train: loss: 0.0031860
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0002412
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0003259
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0021640
[Epoch 74] ogbg-molhiv: 0.752624 val loss: 0.346504
[Epoch 74] ogbg-molhiv: 0.745377 test loss: 0.357328
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001213
[Epoch 75; Iter    32/ 1097] train: loss: 0.0011585
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000239
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001179
[Epoch 75; Iter   122/ 1097] train: loss: 0.0028977
[Epoch 75; Iter   152/ 1097] train: loss: 0.0491277
[Epoch 75; Iter   182/ 1097] train: loss: 0.0001387
[Epoch 75; Iter   212/ 1097] train: loss: 0.0009547
[Epoch 75; Iter   242/ 1097] train: loss: 0.0002592
[Epoch 75; Iter   272/ 1097] train: loss: 0.0001039
[Epoch 75; Iter   302/ 1097] train: loss: 0.0006952
[Epoch 75; Iter   332/ 1097] train: loss: 0.0088722
[Epoch 75; Iter   362/ 1097] train: loss: 0.0006884
[Epoch 75; Iter   392/ 1097] train: loss: 0.0010153
[Epoch 75; Iter   422/ 1097] train: loss: 0.0024445
[Epoch 75; Iter   452/ 1097] train: loss: 0.0000878
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000964
[Epoch 75; Iter   512/ 1097] train: loss: 0.0001849
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000255
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000053
[Epoch 75; Iter   602/ 1097] train: loss: 0.0003717
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000211
[Epoch 75; Iter   662/ 1097] train: loss: 0.0271209
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001826
[Epoch 75; Iter   722/ 1097] train: loss: 0.0003264
[Epoch 75; Iter   752/ 1097] train: loss: 0.0019135
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000800
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000792
[Epoch 75; Iter   842/ 1097] train: loss: 0.0001439
[Epoch 75; Iter   872/ 1097] train: loss: 0.0018811
[Epoch 75; Iter   902/ 1097] train: loss: 0.0004674
[Epoch 75; Iter   932/ 1097] train: loss: 0.0010216
[Epoch 75; Iter   962/ 1097] train: loss: 0.0005794
[Epoch 75; Iter   992/ 1097] train: loss: 0.0000804
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0014881
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0005735
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0016415
[Epoch 75] ogbg-molhiv: 0.746993 val loss: 0.361840
[Epoch 75] ogbg-molhiv: 0.748369 test loss: 0.361449
[Epoch 76; Iter    15/ 1097] train: loss: 0.0001354
[Epoch 76; Iter    45/ 1097] train: loss: 0.0001004
[Epoch 76; Iter    75/ 1097] train: loss: 0.0002694
[Epoch 76; Iter   105/ 1097] train: loss: 0.0008750
[Epoch 76; Iter   135/ 1097] train: loss: 0.0010051
[Epoch 76; Iter   165/ 1097] train: loss: 0.0004763
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001428
[Epoch 76; Iter   225/ 1097] train: loss: 0.0001324
[Epoch 76; Iter   255/ 1097] train: loss: 0.0007799
[Epoch 76; Iter   285/ 1097] train: loss: 0.0062634
[Epoch 76; Iter   315/ 1097] train: loss: 0.0034507
[Epoch 76; Iter   345/ 1097] train: loss: 0.0002102
[Epoch 76; Iter   375/ 1097] train: loss: 0.0017063
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000261
[Epoch 76; Iter   435/ 1097] train: loss: 0.0273927
[Epoch 76; Iter   465/ 1097] train: loss: 0.0036441
[Epoch 76; Iter   495/ 1097] train: loss: 0.0056084
[Epoch 76; Iter   525/ 1097] train: loss: 0.0000911
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000336
[Epoch 76; Iter   585/ 1097] train: loss: 0.0003395
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000272
[Epoch 76; Iter   645/ 1097] train: loss: 0.0045938
[Epoch 76; Iter   675/ 1097] train: loss: 0.0002492
[Epoch 76; Iter   705/ 1097] train: loss: 0.0003172
[Epoch 76; Iter   735/ 1097] train: loss: 0.0884001
[Epoch 76; Iter   765/ 1097] train: loss: 0.0000782
[Epoch 76; Iter   795/ 1097] train: loss: 0.0002288
[Epoch 76; Iter   825/ 1097] train: loss: 0.0005541
[Epoch 76; Iter   855/ 1097] train: loss: 0.0004155
[Epoch 76; Iter   885/ 1097] train: loss: 0.1013916
[Epoch 76; Iter   915/ 1097] train: loss: 0.0086311
[Epoch 76; Iter   945/ 1097] train: loss: 0.0019504
[Epoch 76; Iter   975/ 1097] train: loss: 0.0003604
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0013013
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000190
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0001950
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0016165
[Epoch 76] ogbg-molhiv: 0.746614 val loss: 0.309452
[Epoch 76] ogbg-molhiv: 0.743432 test loss: 0.350326
[Epoch 77; Iter    28/ 1097] train: loss: 0.0002243
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000737
[Epoch 77; Iter    88/ 1097] train: loss: 0.0001359
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002229
[Epoch 77; Iter   148/ 1097] train: loss: 0.0001210
[Epoch 77; Iter   178/ 1097] train: loss: 0.0002185
[Epoch 77; Iter   208/ 1097] train: loss: 0.0002155
[Epoch 77; Iter   238/ 1097] train: loss: 0.0053833
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000196
[Epoch 73; Iter   216/ 1097] train: loss: 0.0005739
[Epoch 73; Iter   246/ 1097] train: loss: 0.0023355
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001938
[Epoch 73; Iter   306/ 1097] train: loss: 0.0004082
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000516
[Epoch 73; Iter   366/ 1097] train: loss: 0.0000713
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000182
[Epoch 73; Iter   426/ 1097] train: loss: 0.0001791
[Epoch 73; Iter   456/ 1097] train: loss: 0.0002720
[Epoch 73; Iter   486/ 1097] train: loss: 0.0000417
[Epoch 73; Iter   516/ 1097] train: loss: 0.0002589
[Epoch 73; Iter   546/ 1097] train: loss: 0.0000954
[Epoch 73; Iter   576/ 1097] train: loss: 0.0001038
[Epoch 73; Iter   606/ 1097] train: loss: 0.0010108
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001336
[Epoch 73; Iter   666/ 1097] train: loss: 0.0109301
[Epoch 73; Iter   696/ 1097] train: loss: 0.0004068
[Epoch 73; Iter   726/ 1097] train: loss: 0.0002185
[Epoch 73; Iter   756/ 1097] train: loss: 0.0057319
[Epoch 73; Iter   786/ 1097] train: loss: 0.0070871
[Epoch 73; Iter   816/ 1097] train: loss: 0.0065679
[Epoch 73; Iter   846/ 1097] train: loss: 0.0001002
[Epoch 73; Iter   876/ 1097] train: loss: 0.0024237
[Epoch 73; Iter   906/ 1097] train: loss: 0.0004467
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000680
[Epoch 73; Iter   966/ 1097] train: loss: 0.0249963
[Epoch 73; Iter   996/ 1097] train: loss: 0.0005741
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0111313
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0002232
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0002085
[Epoch 73] ogbg-molhiv: 0.789015 val loss: 0.243760
[Epoch 73] ogbg-molhiv: 0.736571 test loss: 0.416064
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001301
[Epoch 74; Iter    49/ 1097] train: loss: 0.0001614
[Epoch 74; Iter    79/ 1097] train: loss: 0.0022239
[Epoch 74; Iter   109/ 1097] train: loss: 0.0009305
[Epoch 74; Iter   139/ 1097] train: loss: 0.0118668
[Epoch 74; Iter   169/ 1097] train: loss: 0.0000042
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000253
[Epoch 74; Iter   229/ 1097] train: loss: 0.0001088
[Epoch 74; Iter   259/ 1097] train: loss: 0.0003277
[Epoch 74; Iter   289/ 1097] train: loss: 0.0000573
[Epoch 74; Iter   319/ 1097] train: loss: 0.0000766
[Epoch 74; Iter   349/ 1097] train: loss: 0.0001908
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001573
[Epoch 74; Iter   409/ 1097] train: loss: 0.0000960
[Epoch 74; Iter   439/ 1097] train: loss: 0.0019845
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000127
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000521
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000686
[Epoch 74; Iter   559/ 1097] train: loss: 0.0006322
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001256
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000022
[Epoch 74; Iter   649/ 1097] train: loss: 0.0000061
[Epoch 74; Iter   679/ 1097] train: loss: 0.0000642
[Epoch 74; Iter   709/ 1097] train: loss: 0.0001133
[Epoch 74; Iter   739/ 1097] train: loss: 0.0001029
[Epoch 74; Iter   769/ 1097] train: loss: 0.0386109
[Epoch 74; Iter   799/ 1097] train: loss: 0.0008392
[Epoch 74; Iter   829/ 1097] train: loss: 0.0006893
[Epoch 74; Iter   859/ 1097] train: loss: 0.0053861
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000534
[Epoch 74; Iter   919/ 1097] train: loss: 0.0002557
[Epoch 74; Iter   949/ 1097] train: loss: 0.0018695
[Epoch 74; Iter   979/ 1097] train: loss: 0.0003851
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0000325
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0002603
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0013470
[Epoch 74] ogbg-molhiv: 0.793577 val loss: 0.263045
[Epoch 74] ogbg-molhiv: 0.732478 test loss: 0.416431
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001112
[Epoch 75; Iter    32/ 1097] train: loss: 0.0001055
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000515
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000551
[Epoch 75; Iter   122/ 1097] train: loss: 0.0023458
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000724
[Epoch 75; Iter   182/ 1097] train: loss: 0.0002014
[Epoch 75; Iter   212/ 1097] train: loss: 0.0002969
[Epoch 75; Iter   242/ 1097] train: loss: 0.0093382
[Epoch 75; Iter   272/ 1097] train: loss: 0.0007456
[Epoch 75; Iter   302/ 1097] train: loss: 0.0000608
[Epoch 75; Iter   332/ 1097] train: loss: 0.0054674
[Epoch 75; Iter   362/ 1097] train: loss: 0.0001492
[Epoch 75; Iter   392/ 1097] train: loss: 0.0035304
[Epoch 75; Iter   422/ 1097] train: loss: 0.0011130
[Epoch 75; Iter   452/ 1097] train: loss: 0.0027461
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000139
[Epoch 75; Iter   512/ 1097] train: loss: 0.0015564
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000254
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000074
[Epoch 75; Iter   602/ 1097] train: loss: 0.0293842
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000015
[Epoch 75; Iter   662/ 1097] train: loss: 0.0001289
[Epoch 75; Iter   692/ 1097] train: loss: 0.0010950
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000150
[Epoch 75; Iter   752/ 1097] train: loss: 0.0054390
[Epoch 75; Iter   782/ 1097] train: loss: 0.0003494
[Epoch 75; Iter   812/ 1097] train: loss: 0.0118136
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000360
[Epoch 75; Iter   872/ 1097] train: loss: 0.0001272
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000914
[Epoch 75; Iter   932/ 1097] train: loss: 0.0056699
[Epoch 75; Iter   962/ 1097] train: loss: 0.0009098
[Epoch 75; Iter   992/ 1097] train: loss: 0.0006888
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0007526
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0015166
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0000491
[Epoch 75] ogbg-molhiv: 0.816410 val loss: 0.242439
[Epoch 75] ogbg-molhiv: 0.725991 test loss: 0.444878
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000174
[Epoch 76; Iter    45/ 1097] train: loss: 0.0004504
[Epoch 76; Iter    75/ 1097] train: loss: 0.0018152
[Epoch 76; Iter   105/ 1097] train: loss: 0.0001228
[Epoch 76; Iter   135/ 1097] train: loss: 0.0031332
[Epoch 76; Iter   165/ 1097] train: loss: 0.0002475
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001761
[Epoch 76; Iter   225/ 1097] train: loss: 0.0002789
[Epoch 76; Iter   255/ 1097] train: loss: 0.0001654
[Epoch 76; Iter   285/ 1097] train: loss: 0.0015762
[Epoch 76; Iter   315/ 1097] train: loss: 0.0588955
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000091
[Epoch 76; Iter   375/ 1097] train: loss: 0.0002598
[Epoch 76; Iter   405/ 1097] train: loss: 0.0007367
[Epoch 76; Iter   435/ 1097] train: loss: 0.0000442
[Epoch 76; Iter   465/ 1097] train: loss: 0.0013037
[Epoch 76; Iter   495/ 1097] train: loss: 0.0001622
[Epoch 76; Iter   525/ 1097] train: loss: 0.0012699
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000167
[Epoch 76; Iter   585/ 1097] train: loss: 0.0001962
[Epoch 76; Iter   615/ 1097] train: loss: 0.0026432
[Epoch 76; Iter   645/ 1097] train: loss: 0.0019440
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001984
[Epoch 76; Iter   705/ 1097] train: loss: 0.0026061
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000568
[Epoch 76; Iter   765/ 1097] train: loss: 0.0087972
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000337
[Epoch 76; Iter   825/ 1097] train: loss: 0.0001568
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000033
[Epoch 76; Iter   885/ 1097] train: loss: 0.0010340
[Epoch 76; Iter   915/ 1097] train: loss: 0.0141156
[Epoch 76; Iter   945/ 1097] train: loss: 0.0351209
[Epoch 76; Iter   975/ 1097] train: loss: 0.0004630
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0000356
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0004839
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0003472
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0011978
[Epoch 76] ogbg-molhiv: 0.782962 val loss: 0.246111
[Epoch 76] ogbg-molhiv: 0.718444 test loss: 0.483896
[Epoch 77; Iter    28/ 1097] train: loss: 0.0007036
[Epoch 77; Iter    58/ 1097] train: loss: 0.0005388
[Epoch 77; Iter    88/ 1097] train: loss: 0.0005768
[Epoch 77; Iter   118/ 1097] train: loss: 0.0001594
[Epoch 77; Iter   148/ 1097] train: loss: 0.0021264
[Epoch 77; Iter   178/ 1097] train: loss: 0.0005642
[Epoch 77; Iter   208/ 1097] train: loss: 0.0094670
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000701
[Epoch 73; Iter   186/ 1097] train: loss: 0.0296606
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001466
[Epoch 73; Iter   246/ 1097] train: loss: 0.0175455
[Epoch 73; Iter   276/ 1097] train: loss: 0.0794364
[Epoch 73; Iter   306/ 1097] train: loss: 0.0123804
[Epoch 73; Iter   336/ 1097] train: loss: 0.0012168
[Epoch 73; Iter   366/ 1097] train: loss: 0.0222638
[Epoch 73; Iter   396/ 1097] train: loss: 0.0002970
[Epoch 73; Iter   426/ 1097] train: loss: 0.0016694
[Epoch 73; Iter   456/ 1097] train: loss: 0.0010691
[Epoch 73; Iter   486/ 1097] train: loss: 0.0687871
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000928
[Epoch 73; Iter   546/ 1097] train: loss: 0.0053008
[Epoch 73; Iter   576/ 1097] train: loss: 0.0003033
[Epoch 73; Iter   606/ 1097] train: loss: 0.0006023
[Epoch 73; Iter   636/ 1097] train: loss: 0.0012089
[Epoch 73; Iter   666/ 1097] train: loss: 0.0212422
[Epoch 73; Iter   696/ 1097] train: loss: 0.0104686
[Epoch 73; Iter   726/ 1097] train: loss: 0.0129643
[Epoch 73; Iter   756/ 1097] train: loss: 0.0012393
[Epoch 73; Iter   786/ 1097] train: loss: 0.0020413
[Epoch 73; Iter   816/ 1097] train: loss: 0.0203088
[Epoch 73; Iter   846/ 1097] train: loss: 0.0017680
[Epoch 73; Iter   876/ 1097] train: loss: 0.0009848
[Epoch 73; Iter   906/ 1097] train: loss: 0.0047570
[Epoch 73; Iter   936/ 1097] train: loss: 0.0082768
[Epoch 73; Iter   966/ 1097] train: loss: 0.0004757
[Epoch 73; Iter   996/ 1097] train: loss: 0.0002947
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0019811
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0012680
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0065043
[Epoch 73] ogbg-molhiv: 0.680234 val loss: 4.518130
[Epoch 73] ogbg-molhiv: 0.691875 test loss: 3.065631
[Epoch 74; Iter    19/ 1097] train: loss: 0.0535406
[Epoch 74; Iter    49/ 1097] train: loss: 0.0007069
[Epoch 74; Iter    79/ 1097] train: loss: 0.0543171
[Epoch 74; Iter   109/ 1097] train: loss: 0.0108209
[Epoch 74; Iter   139/ 1097] train: loss: 0.0122836
[Epoch 74; Iter   169/ 1097] train: loss: 0.0061116
[Epoch 74; Iter   199/ 1097] train: loss: 0.0007366
[Epoch 74; Iter   229/ 1097] train: loss: 0.0014969
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000980
[Epoch 74; Iter   289/ 1097] train: loss: 0.0312757
[Epoch 74; Iter   319/ 1097] train: loss: 0.0007532
[Epoch 74; Iter   349/ 1097] train: loss: 0.0004761
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001632
[Epoch 74; Iter   409/ 1097] train: loss: 0.0852084
[Epoch 74; Iter   439/ 1097] train: loss: 0.0250320
[Epoch 74; Iter   469/ 1097] train: loss: 0.0106746
[Epoch 74; Iter   499/ 1097] train: loss: 0.0011827
[Epoch 74; Iter   529/ 1097] train: loss: 0.0010945
[Epoch 74; Iter   559/ 1097] train: loss: 0.0001975
[Epoch 74; Iter   589/ 1097] train: loss: 0.0015294
[Epoch 74; Iter   619/ 1097] train: loss: 0.0507415
[Epoch 74; Iter   649/ 1097] train: loss: 0.0659361
[Epoch 74; Iter   679/ 1097] train: loss: 0.0048179
[Epoch 74; Iter   709/ 1097] train: loss: 0.0008907
[Epoch 74; Iter   739/ 1097] train: loss: 0.0640516
[Epoch 74; Iter   769/ 1097] train: loss: 0.0016632
[Epoch 74; Iter   799/ 1097] train: loss: 0.0010602
[Epoch 74; Iter   829/ 1097] train: loss: 0.0057539
[Epoch 74; Iter   859/ 1097] train: loss: 0.0011362
[Epoch 74; Iter   889/ 1097] train: loss: 0.0094152
[Epoch 74; Iter   919/ 1097] train: loss: 0.0005218
[Epoch 74; Iter   949/ 1097] train: loss: 0.0003716
[Epoch 74; Iter   979/ 1097] train: loss: 0.0008354
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0002220
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0011076
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0001494
[Epoch 74] ogbg-molhiv: 0.688713 val loss: 2.789869
[Epoch 74] ogbg-molhiv: 0.697064 test loss: 0.686414
[Epoch 75; Iter     2/ 1097] train: loss: 0.0008053
[Epoch 75; Iter    32/ 1097] train: loss: 0.0007502
[Epoch 75; Iter    62/ 1097] train: loss: 0.0002705
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001426
[Epoch 75; Iter   122/ 1097] train: loss: 0.0001773
[Epoch 75; Iter   152/ 1097] train: loss: 0.0014022
[Epoch 75; Iter   182/ 1097] train: loss: 0.0009061
[Epoch 75; Iter   212/ 1097] train: loss: 0.0022280
[Epoch 75; Iter   242/ 1097] train: loss: 0.0001636
[Epoch 75; Iter   272/ 1097] train: loss: 0.0062435
[Epoch 75; Iter   302/ 1097] train: loss: 0.0010198
[Epoch 75; Iter   332/ 1097] train: loss: 0.0014282
[Epoch 75; Iter   362/ 1097] train: loss: 0.0055395
[Epoch 75; Iter   392/ 1097] train: loss: 0.0105497
[Epoch 75; Iter   422/ 1097] train: loss: 0.0007167
[Epoch 75; Iter   452/ 1097] train: loss: 0.0036172
[Epoch 75; Iter   482/ 1097] train: loss: 0.0016089
[Epoch 75; Iter   512/ 1097] train: loss: 0.0006128
[Epoch 75; Iter   542/ 1097] train: loss: 0.1053536
[Epoch 75; Iter   572/ 1097] train: loss: 0.0019370
[Epoch 75; Iter   602/ 1097] train: loss: 0.0142483
[Epoch 75; Iter   632/ 1097] train: loss: 0.0043005
[Epoch 75; Iter   662/ 1097] train: loss: 0.0020826
[Epoch 75; Iter   692/ 1097] train: loss: 0.2066503
[Epoch 75; Iter   722/ 1097] train: loss: 0.0004121
[Epoch 75; Iter   752/ 1097] train: loss: 0.0001299
[Epoch 75; Iter   782/ 1097] train: loss: 0.1473681
[Epoch 75; Iter   812/ 1097] train: loss: 0.0628552
[Epoch 75; Iter   842/ 1097] train: loss: 0.1828741
[Epoch 75; Iter   872/ 1097] train: loss: 0.0020416
[Epoch 75; Iter   902/ 1097] train: loss: 0.0477821
[Epoch 75; Iter   932/ 1097] train: loss: 0.0005067
[Epoch 75; Iter   962/ 1097] train: loss: 0.0002656
[Epoch 75; Iter   992/ 1097] train: loss: 0.0010475
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0015626
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0164946
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0028214
[Epoch 75] ogbg-molhiv: 0.698024 val loss: 5.835137
[Epoch 75] ogbg-molhiv: 0.698272 test loss: 2.444622
[Epoch 76; Iter    15/ 1097] train: loss: 0.0004449
[Epoch 76; Iter    45/ 1097] train: loss: 0.0048822
[Epoch 76; Iter    75/ 1097] train: loss: 0.0003109
[Epoch 76; Iter   105/ 1097] train: loss: 0.0025699
[Epoch 76; Iter   135/ 1097] train: loss: 0.0054846
[Epoch 76; Iter   165/ 1097] train: loss: 0.0001564
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001565
[Epoch 76; Iter   225/ 1097] train: loss: 0.0046272
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000331
[Epoch 76; Iter   285/ 1097] train: loss: 0.0272581
[Epoch 76; Iter   315/ 1097] train: loss: 0.0092959
[Epoch 76; Iter   345/ 1097] train: loss: 0.0052155
[Epoch 76; Iter   375/ 1097] train: loss: 0.0000712
[Epoch 76; Iter   405/ 1097] train: loss: 0.0002389
[Epoch 76; Iter   435/ 1097] train: loss: 0.0023770
[Epoch 76; Iter   465/ 1097] train: loss: 0.0010334
[Epoch 76; Iter   495/ 1097] train: loss: 0.0031046
[Epoch 76; Iter   525/ 1097] train: loss: 0.0028148
[Epoch 76; Iter   555/ 1097] train: loss: 0.0013558
[Epoch 76; Iter   585/ 1097] train: loss: 0.0040638
[Epoch 76; Iter   615/ 1097] train: loss: 0.0007172
[Epoch 76; Iter   645/ 1097] train: loss: 0.0001039
[Epoch 76; Iter   675/ 1097] train: loss: 0.0004076
[Epoch 76; Iter   705/ 1097] train: loss: 0.0002539
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000760
[Epoch 76; Iter   765/ 1097] train: loss: 0.0000573
[Epoch 76; Iter   795/ 1097] train: loss: 0.0002597
[Epoch 76; Iter   825/ 1097] train: loss: 0.0007267
[Epoch 76; Iter   855/ 1097] train: loss: 0.0049110
[Epoch 76; Iter   885/ 1097] train: loss: 0.0018810
[Epoch 76; Iter   915/ 1097] train: loss: 0.0025361
[Epoch 76; Iter   945/ 1097] train: loss: 0.0013428
[Epoch 76; Iter   975/ 1097] train: loss: 0.0169623
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0006022
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0236596
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0009956
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0019846
[Epoch 76] ogbg-molhiv: 0.702482 val loss: 3.853508
[Epoch 76] ogbg-molhiv: 0.710128 test loss: 2.665659
[Epoch 77; Iter    28/ 1097] train: loss: 0.0767632
[Epoch 77; Iter    58/ 1097] train: loss: 0.0060594
[Epoch 77; Iter    88/ 1097] train: loss: 0.0009625
[Epoch 77; Iter   118/ 1097] train: loss: 0.0021390
[Epoch 77; Iter   148/ 1097] train: loss: 0.0003051
[Epoch 77; Iter   178/ 1097] train: loss: 0.0003839
[Epoch 77; Iter   208/ 1097] train: loss: 0.0709068
[Epoch 77; Iter   238/ 1097] train: loss: 0.1743102
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000410
[Epoch 73; Iter   216/ 1097] train: loss: 0.0075714
[Epoch 73; Iter   246/ 1097] train: loss: 0.0003515
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001313
[Epoch 73; Iter   306/ 1097] train: loss: 0.0005473
[Epoch 73; Iter   336/ 1097] train: loss: 0.0004260
[Epoch 73; Iter   366/ 1097] train: loss: 0.0701977
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000966
[Epoch 73; Iter   426/ 1097] train: loss: 0.0003230
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000137
[Epoch 73; Iter   486/ 1097] train: loss: 0.0037172
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000640
[Epoch 73; Iter   546/ 1097] train: loss: 0.0007676
[Epoch 73; Iter   576/ 1097] train: loss: 0.0001362
[Epoch 73; Iter   606/ 1097] train: loss: 0.0004269
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001945
[Epoch 73; Iter   666/ 1097] train: loss: 0.0000759
[Epoch 73; Iter   696/ 1097] train: loss: 0.0000802
[Epoch 73; Iter   726/ 1097] train: loss: 0.0000511
[Epoch 73; Iter   756/ 1097] train: loss: 0.0003307
[Epoch 73; Iter   786/ 1097] train: loss: 0.0001015
[Epoch 73; Iter   816/ 1097] train: loss: 0.0001365
[Epoch 73; Iter   846/ 1097] train: loss: 0.0002308
[Epoch 73; Iter   876/ 1097] train: loss: 0.0003395
[Epoch 73; Iter   906/ 1097] train: loss: 0.0001145
[Epoch 73; Iter   936/ 1097] train: loss: 0.0004163
[Epoch 73; Iter   966/ 1097] train: loss: 0.0000832
[Epoch 73; Iter   996/ 1097] train: loss: 0.0000821
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0000784
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0000552
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0002984
[Epoch 73] ogbg-molhiv: 0.773111 val loss: 0.355791
[Epoch 73] ogbg-molhiv: 0.777317 test loss: 0.326288
[Epoch 74; Iter    19/ 1097] train: loss: 0.0002147
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000373
[Epoch 74; Iter    79/ 1097] train: loss: 0.0003320
[Epoch 74; Iter   109/ 1097] train: loss: 0.0005208
[Epoch 74; Iter   139/ 1097] train: loss: 0.0000244
[Epoch 74; Iter   169/ 1097] train: loss: 0.0245303
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001397
[Epoch 74; Iter   229/ 1097] train: loss: 0.0002955
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000757
[Epoch 74; Iter   289/ 1097] train: loss: 0.0124265
[Epoch 74; Iter   319/ 1097] train: loss: 0.0002088
[Epoch 74; Iter   349/ 1097] train: loss: 0.0002620
[Epoch 74; Iter   379/ 1097] train: loss: 0.0002340
[Epoch 74; Iter   409/ 1097] train: loss: 0.0002932
[Epoch 74; Iter   439/ 1097] train: loss: 0.0196361
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001308
[Epoch 74; Iter   499/ 1097] train: loss: 0.0006100
[Epoch 74; Iter   529/ 1097] train: loss: 0.0004032
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000180
[Epoch 74; Iter   589/ 1097] train: loss: 0.0000375
[Epoch 74; Iter   619/ 1097] train: loss: 0.0003261
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001518
[Epoch 74; Iter   679/ 1097] train: loss: 0.0020759
[Epoch 74; Iter   709/ 1097] train: loss: 0.0063700
[Epoch 74; Iter   739/ 1097] train: loss: 0.0000049
[Epoch 74; Iter   769/ 1097] train: loss: 0.0039486
[Epoch 74; Iter   799/ 1097] train: loss: 0.0501966
[Epoch 74; Iter   829/ 1097] train: loss: 0.0040054
[Epoch 74; Iter   859/ 1097] train: loss: 0.0010466
[Epoch 74; Iter   889/ 1097] train: loss: 0.0001863
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000776
[Epoch 74; Iter   949/ 1097] train: loss: 0.0022873
[Epoch 74; Iter   979/ 1097] train: loss: 0.0018308
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0000190
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0001177
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000338
[Epoch 74] ogbg-molhiv: 0.795571 val loss: 0.321724
[Epoch 74] ogbg-molhiv: 0.812354 test loss: 0.307078
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000429
[Epoch 75; Iter    32/ 1097] train: loss: 0.0145905
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000341
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000440
[Epoch 75; Iter   122/ 1097] train: loss: 0.0011320
[Epoch 75; Iter   152/ 1097] train: loss: 0.0306173
[Epoch 75; Iter   182/ 1097] train: loss: 0.0012060
[Epoch 75; Iter   212/ 1097] train: loss: 0.0014865
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000483
[Epoch 75; Iter   272/ 1097] train: loss: 0.0001122
[Epoch 75; Iter   302/ 1097] train: loss: 0.0019002
[Epoch 75; Iter   332/ 1097] train: loss: 0.0000886
[Epoch 75; Iter   362/ 1097] train: loss: 0.0008866
[Epoch 75; Iter   392/ 1097] train: loss: 0.0281647
[Epoch 75; Iter   422/ 1097] train: loss: 0.0019688
[Epoch 75; Iter   452/ 1097] train: loss: 0.0008559
[Epoch 75; Iter   482/ 1097] train: loss: 0.0139040
[Epoch 75; Iter   512/ 1097] train: loss: 0.0005950
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000235
[Epoch 75; Iter   572/ 1097] train: loss: 0.0047670
[Epoch 75; Iter   602/ 1097] train: loss: 0.0008696
[Epoch 75; Iter   632/ 1097] train: loss: 0.0001039
[Epoch 75; Iter   662/ 1097] train: loss: 0.0004892
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001587
[Epoch 75; Iter   722/ 1097] train: loss: 0.0001017
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000805
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000625
[Epoch 75; Iter   812/ 1097] train: loss: 0.0002225
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000037
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000259
[Epoch 75; Iter   902/ 1097] train: loss: 0.0001381
[Epoch 75; Iter   932/ 1097] train: loss: 0.0311379
[Epoch 75; Iter   962/ 1097] train: loss: 0.0006230
[Epoch 75; Iter   992/ 1097] train: loss: 0.0021515
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000945
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0000316
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0010848
[Epoch 75] ogbg-molhiv: 0.786360 val loss: 0.250762
[Epoch 75] ogbg-molhiv: 0.811717 test loss: 0.319270
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000580
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000357
[Epoch 76; Iter    75/ 1097] train: loss: 0.0001228
[Epoch 76; Iter   105/ 1097] train: loss: 0.0002721
[Epoch 76; Iter   135/ 1097] train: loss: 0.0001043
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000508
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000753
[Epoch 76; Iter   225/ 1097] train: loss: 0.0001591
[Epoch 76; Iter   255/ 1097] train: loss: 0.0001181
[Epoch 76; Iter   285/ 1097] train: loss: 0.0008270
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000773
[Epoch 76; Iter   345/ 1097] train: loss: 0.0004305
[Epoch 76; Iter   375/ 1097] train: loss: 0.0002817
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000594
[Epoch 76; Iter   435/ 1097] train: loss: 0.0084562
[Epoch 76; Iter   465/ 1097] train: loss: 0.0000608
[Epoch 76; Iter   495/ 1097] train: loss: 0.0014045
[Epoch 76; Iter   525/ 1097] train: loss: 0.0002128
[Epoch 76; Iter   555/ 1097] train: loss: 0.0014974
[Epoch 76; Iter   585/ 1097] train: loss: 0.0007104
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000156
[Epoch 76; Iter   645/ 1097] train: loss: 0.0383845
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001846
[Epoch 76; Iter   705/ 1097] train: loss: 0.0000328
[Epoch 76; Iter   735/ 1097] train: loss: 0.0001558
[Epoch 76; Iter   765/ 1097] train: loss: 0.0001026
[Epoch 76; Iter   795/ 1097] train: loss: 0.0069734
[Epoch 76; Iter   825/ 1097] train: loss: 0.0018327
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000234
[Epoch 76; Iter   885/ 1097] train: loss: 0.0016034
[Epoch 76; Iter   915/ 1097] train: loss: 0.0001628
[Epoch 76; Iter   945/ 1097] train: loss: 0.0000330
[Epoch 76; Iter   975/ 1097] train: loss: 0.0009263
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0000185
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000213
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0194568
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0102147
[Epoch 76] ogbg-molhiv: 0.800234 val loss: 0.349916
[Epoch 76] ogbg-molhiv: 0.786087 test loss: 0.339582
[Epoch 77; Iter    28/ 1097] train: loss: 0.0036055
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000671
[Epoch 77; Iter    88/ 1097] train: loss: 0.0636926
[Epoch 77; Iter   118/ 1097] train: loss: 0.0000395
[Epoch 77; Iter   148/ 1097] train: loss: 0.0005120
[Epoch 77; Iter   178/ 1097] train: loss: 0.0224122
[Epoch 77; Iter   208/ 1097] train: loss: 0.0017686
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000781
[Epoch 73; Iter   186/ 1097] train: loss: 0.0018360
[Epoch 73; Iter   216/ 1097] train: loss: 0.0004090
[Epoch 73; Iter   246/ 1097] train: loss: 0.0084504
[Epoch 73; Iter   276/ 1097] train: loss: 0.0000874
[Epoch 73; Iter   306/ 1097] train: loss: 0.0002262
[Epoch 73; Iter   336/ 1097] train: loss: 0.0003474
[Epoch 73; Iter   366/ 1097] train: loss: 0.0002104
[Epoch 73; Iter   396/ 1097] train: loss: 0.0001249
[Epoch 73; Iter   426/ 1097] train: loss: 0.0048395
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000184
[Epoch 73; Iter   486/ 1097] train: loss: 0.0156417
[Epoch 73; Iter   516/ 1097] train: loss: 0.0014617
[Epoch 73; Iter   546/ 1097] train: loss: 0.0000039
[Epoch 73; Iter   576/ 1097] train: loss: 0.0004526
[Epoch 73; Iter   606/ 1097] train: loss: 0.0000121
[Epoch 73; Iter   636/ 1097] train: loss: 0.0000677
[Epoch 73; Iter   666/ 1097] train: loss: 0.0139176
[Epoch 73; Iter   696/ 1097] train: loss: 0.0009732
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001394
[Epoch 73; Iter   756/ 1097] train: loss: 0.0000143
[Epoch 73; Iter   786/ 1097] train: loss: 0.0000023
[Epoch 73; Iter   816/ 1097] train: loss: 0.0189658
[Epoch 73; Iter   846/ 1097] train: loss: 0.0094178
[Epoch 73; Iter   876/ 1097] train: loss: 0.0001876
[Epoch 73; Iter   906/ 1097] train: loss: 0.0024723
[Epoch 73; Iter   936/ 1097] train: loss: 0.0007174
[Epoch 73; Iter   966/ 1097] train: loss: 0.0002894
[Epoch 73; Iter   996/ 1097] train: loss: 0.0000945
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0000725
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0001777
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0004087
[Epoch 73] ogbg-molhiv: 0.705271 val loss: 1.355861
[Epoch 73] ogbg-molhiv: 0.627391 test loss: 2.238579
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001757
[Epoch 74; Iter    49/ 1097] train: loss: 0.0097297
[Epoch 74; Iter    79/ 1097] train: loss: 0.0002815
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000597
[Epoch 74; Iter   139/ 1097] train: loss: 0.0001039
[Epoch 74; Iter   169/ 1097] train: loss: 0.0005063
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000365
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000174
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000621
[Epoch 74; Iter   289/ 1097] train: loss: 0.0001180
[Epoch 74; Iter   319/ 1097] train: loss: 0.0001154
[Epoch 74; Iter   349/ 1097] train: loss: 0.0000200
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001937
[Epoch 74; Iter   409/ 1097] train: loss: 0.0004553
[Epoch 74; Iter   439/ 1097] train: loss: 0.0003034
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001498
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000063
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000465
[Epoch 74; Iter   559/ 1097] train: loss: 0.0004352
[Epoch 74; Iter   589/ 1097] train: loss: 0.0002544
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000385
[Epoch 74; Iter   649/ 1097] train: loss: 0.0002045
[Epoch 74; Iter   679/ 1097] train: loss: 0.0008166
[Epoch 74; Iter   709/ 1097] train: loss: 0.0000115
[Epoch 74; Iter   739/ 1097] train: loss: 0.0000275
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000291
[Epoch 74; Iter   799/ 1097] train: loss: 0.0002913
[Epoch 74; Iter   829/ 1097] train: loss: 0.0013222
[Epoch 74; Iter   859/ 1097] train: loss: 0.0019644
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000213
[Epoch 74; Iter   919/ 1097] train: loss: 0.0001152
[Epoch 74; Iter   949/ 1097] train: loss: 0.0001535
[Epoch 74; Iter   979/ 1097] train: loss: 0.0000766
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0001149
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0005463
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000700
[Epoch 74] ogbg-molhiv: 0.698422 val loss: 3.007563
[Epoch 74] ogbg-molhiv: 0.626625 test loss: 3.309936
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001004
[Epoch 75; Iter    32/ 1097] train: loss: 0.0000117
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000023
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001348
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000058
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000128
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000550
[Epoch 75; Iter   212/ 1097] train: loss: 0.0102404
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000206
[Epoch 75; Iter   272/ 1097] train: loss: 0.0038412
[Epoch 75; Iter   302/ 1097] train: loss: 0.0003772
[Epoch 75; Iter   332/ 1097] train: loss: 0.0002929
[Epoch 75; Iter   362/ 1097] train: loss: 0.1011527
[Epoch 75; Iter   392/ 1097] train: loss: 0.0000042
[Epoch 75; Iter   422/ 1097] train: loss: 0.0000123
[Epoch 75; Iter   452/ 1097] train: loss: 0.0008492
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000512
[Epoch 75; Iter   512/ 1097] train: loss: 0.0002928
[Epoch 75; Iter   542/ 1097] train: loss: 0.0002883
[Epoch 75; Iter   572/ 1097] train: loss: 0.0017546
[Epoch 75; Iter   602/ 1097] train: loss: 0.0031579
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000908
[Epoch 75; Iter   662/ 1097] train: loss: 0.0001234
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001684
[Epoch 75; Iter   722/ 1097] train: loss: 0.0003523
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000076
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000076
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000050
[Epoch 75; Iter   842/ 1097] train: loss: 0.0091247
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000080
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000174
[Epoch 75; Iter   932/ 1097] train: loss: 0.0557282
[Epoch 75; Iter   962/ 1097] train: loss: 0.0013962
[Epoch 75; Iter   992/ 1097] train: loss: 0.0000367
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000612
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0000118
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0000132
[Epoch 75] ogbg-molhiv: 0.689830 val loss: 3.275856
[Epoch 75] ogbg-molhiv: 0.634566 test loss: 2.891472
[Epoch 76; Iter    15/ 1097] train: loss: 0.0004211
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000854
[Epoch 76; Iter    75/ 1097] train: loss: 0.0000112
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000102
[Epoch 76; Iter   135/ 1097] train: loss: 0.0001064
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000066
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000912
[Epoch 76; Iter   225/ 1097] train: loss: 0.0002571
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000298
[Epoch 76; Iter   285/ 1097] train: loss: 0.0109761
[Epoch 76; Iter   315/ 1097] train: loss: 0.0027354
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000031
[Epoch 76; Iter   375/ 1097] train: loss: 0.0004475
[Epoch 76; Iter   405/ 1097] train: loss: 0.0039392
[Epoch 76; Iter   435/ 1097] train: loss: 0.0000154
[Epoch 76; Iter   465/ 1097] train: loss: 0.0000133
[Epoch 76; Iter   495/ 1097] train: loss: 0.0001652
[Epoch 76; Iter   525/ 1097] train: loss: 0.0000038
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000543
[Epoch 76; Iter   585/ 1097] train: loss: 0.0012575
[Epoch 76; Iter   615/ 1097] train: loss: 0.0001280
[Epoch 76; Iter   645/ 1097] train: loss: 0.0232959
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001301
[Epoch 76; Iter   705/ 1097] train: loss: 0.0002584
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000640
[Epoch 76; Iter   765/ 1097] train: loss: 0.0004628
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000235
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000267
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001963
[Epoch 76; Iter   885/ 1097] train: loss: 0.0000664
[Epoch 76; Iter   915/ 1097] train: loss: 0.0000339
[Epoch 76; Iter   945/ 1097] train: loss: 0.0002160
[Epoch 76; Iter   975/ 1097] train: loss: 0.0000356
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0007768
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0007636
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0000088
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0000042
[Epoch 76] ogbg-molhiv: 0.683575 val loss: 3.290067
[Epoch 76] ogbg-molhiv: 0.636119 test loss: 3.071214
[Epoch 77; Iter    28/ 1097] train: loss: 0.0003720
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000256
[Epoch 77; Iter    88/ 1097] train: loss: 0.0000352
[Epoch 77; Iter   118/ 1097] train: loss: 0.0000157
[Epoch 77; Iter   148/ 1097] train: loss: 0.0016737
[Epoch 77; Iter   178/ 1097] train: loss: 0.0143535
[Epoch 77; Iter   208/ 1097] train: loss: 0.0000059
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000059
[Epoch 73; Iter   186/ 1097] train: loss: 0.0003455
[Epoch 73; Iter   216/ 1097] train: loss: 0.0010249
[Epoch 73; Iter   246/ 1097] train: loss: 0.0001740
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001952
[Epoch 73; Iter   306/ 1097] train: loss: 0.0000381
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000893
[Epoch 73; Iter   366/ 1097] train: loss: 0.0281110
[Epoch 73; Iter   396/ 1097] train: loss: 0.0005191
[Epoch 73; Iter   426/ 1097] train: loss: 0.0000100
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000436
[Epoch 73; Iter   486/ 1097] train: loss: 0.0021968
[Epoch 73; Iter   516/ 1097] train: loss: 0.0006924
[Epoch 73; Iter   546/ 1097] train: loss: 0.0007119
[Epoch 73; Iter   576/ 1097] train: loss: 0.0004631
[Epoch 73; Iter   606/ 1097] train: loss: 0.0005854
[Epoch 73; Iter   636/ 1097] train: loss: 0.0000047
[Epoch 73; Iter   666/ 1097] train: loss: 0.0074694
[Epoch 73; Iter   696/ 1097] train: loss: 0.0003321
[Epoch 73; Iter   726/ 1097] train: loss: 0.0011637
[Epoch 73; Iter   756/ 1097] train: loss: 0.0001817
[Epoch 73; Iter   786/ 1097] train: loss: 0.0017167
[Epoch 73; Iter   816/ 1097] train: loss: 0.0002038
[Epoch 73; Iter   846/ 1097] train: loss: 0.0014466
[Epoch 73; Iter   876/ 1097] train: loss: 0.0026411
[Epoch 73; Iter   906/ 1097] train: loss: 0.0147867
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000237
[Epoch 73; Iter   966/ 1097] train: loss: 0.0007353
[Epoch 73; Iter   996/ 1097] train: loss: 0.0041301
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0008188
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0079700
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0382616
[Epoch 73] ogbg-molhiv: 0.771556 val loss: 0.755255
[Epoch 73] ogbg-molhiv: 0.742237 test loss: 1.981038
[Epoch 74; Iter    19/ 1097] train: loss: 0.0000834
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000970
[Epoch 74; Iter    79/ 1097] train: loss: 0.0000678
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000255
[Epoch 74; Iter   139/ 1097] train: loss: 0.0001014
[Epoch 74; Iter   169/ 1097] train: loss: 0.0041505
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001015
[Epoch 74; Iter   229/ 1097] train: loss: 0.0015766
[Epoch 74; Iter   259/ 1097] train: loss: 0.0013754
[Epoch 74; Iter   289/ 1097] train: loss: 0.0192950
[Epoch 74; Iter   319/ 1097] train: loss: 0.0009150
[Epoch 74; Iter   349/ 1097] train: loss: 0.0062912
[Epoch 74; Iter   379/ 1097] train: loss: 0.0000155
[Epoch 74; Iter   409/ 1097] train: loss: 0.0030186
[Epoch 74; Iter   439/ 1097] train: loss: 0.0000428
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000147
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000014
[Epoch 74; Iter   529/ 1097] train: loss: 0.0002589
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000813
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001095
[Epoch 74; Iter   619/ 1097] train: loss: 0.0007107
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001106
[Epoch 74; Iter   679/ 1097] train: loss: 0.0000771
[Epoch 74; Iter   709/ 1097] train: loss: 0.0005708
[Epoch 74; Iter   739/ 1097] train: loss: 0.0001078
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000372
[Epoch 74; Iter   799/ 1097] train: loss: 0.0005980
[Epoch 74; Iter   829/ 1097] train: loss: 0.0239678
[Epoch 74; Iter   859/ 1097] train: loss: 0.0000775
[Epoch 74; Iter   889/ 1097] train: loss: 0.0001026
[Epoch 74; Iter   919/ 1097] train: loss: 0.0001686
[Epoch 74; Iter   949/ 1097] train: loss: 0.0001202
[Epoch 74; Iter   979/ 1097] train: loss: 0.0000343
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0036151
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0000595
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000529
[Epoch 74] ogbg-molhiv: 0.775922 val loss: 2.079450
[Epoch 74] ogbg-molhiv: 0.666824 test loss: 4.632004
[Epoch 75; Iter     2/ 1097] train: loss: 0.0032208
[Epoch 75; Iter    32/ 1097] train: loss: 0.0001919
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000305
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000268
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000142
[Epoch 75; Iter   152/ 1097] train: loss: 0.0015537
[Epoch 75; Iter   182/ 1097] train: loss: 0.0027722
[Epoch 75; Iter   212/ 1097] train: loss: 0.0000523
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000073
[Epoch 75; Iter   272/ 1097] train: loss: 0.0005889
[Epoch 75; Iter   302/ 1097] train: loss: 0.0032984
[Epoch 75; Iter   332/ 1097] train: loss: 0.0000588
[Epoch 75; Iter   362/ 1097] train: loss: 0.0002115
[Epoch 75; Iter   392/ 1097] train: loss: 0.0001660
[Epoch 75; Iter   422/ 1097] train: loss: 0.0015719
[Epoch 75; Iter   452/ 1097] train: loss: 0.0000554
[Epoch 75; Iter   482/ 1097] train: loss: 0.0002457
[Epoch 75; Iter   512/ 1097] train: loss: 0.0001016
[Epoch 75; Iter   542/ 1097] train: loss: 0.0007399
[Epoch 75; Iter   572/ 1097] train: loss: 0.0017164
[Epoch 75; Iter   602/ 1097] train: loss: 0.0000067
[Epoch 75; Iter   632/ 1097] train: loss: 0.0023717
[Epoch 75; Iter   662/ 1097] train: loss: 0.0005921
[Epoch 75; Iter   692/ 1097] train: loss: 0.0000528
[Epoch 75; Iter   722/ 1097] train: loss: 0.0008180
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000801
[Epoch 75; Iter   782/ 1097] train: loss: 0.0002805
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000819
[Epoch 75; Iter   842/ 1097] train: loss: 0.0016214
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000929
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000114
[Epoch 75; Iter   932/ 1097] train: loss: 0.1140241
[Epoch 75; Iter   962/ 1097] train: loss: 0.1292765
[Epoch 75; Iter   992/ 1097] train: loss: 0.0403787
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0009797
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0003051
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0077124
[Epoch 75] ogbg-molhiv: 0.765898 val loss: 1.192391
[Epoch 75] ogbg-molhiv: 0.721107 test loss: 3.456977
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000102
[Epoch 76; Iter    45/ 1097] train: loss: 0.1688136
[Epoch 76; Iter    75/ 1097] train: loss: 0.0281216
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000148
[Epoch 76; Iter   135/ 1097] train: loss: 0.0003838
[Epoch 76; Iter   165/ 1097] train: loss: 0.0004125
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000784
[Epoch 76; Iter   225/ 1097] train: loss: 0.0000915
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000757
[Epoch 76; Iter   285/ 1097] train: loss: 0.0000121
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000617
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000182
[Epoch 76; Iter   375/ 1097] train: loss: 0.0007142
[Epoch 76; Iter   405/ 1097] train: loss: 0.0085529
[Epoch 76; Iter   435/ 1097] train: loss: 0.0001623
[Epoch 76; Iter   465/ 1097] train: loss: 0.0004641
[Epoch 76; Iter   495/ 1097] train: loss: 0.0004745
[Epoch 76; Iter   525/ 1097] train: loss: 0.0003073
[Epoch 76; Iter   555/ 1097] train: loss: 0.0003812
[Epoch 76; Iter   585/ 1097] train: loss: 0.0002729
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000662
[Epoch 76; Iter   645/ 1097] train: loss: 0.0000949
[Epoch 76; Iter   675/ 1097] train: loss: 0.0015103
[Epoch 76; Iter   705/ 1097] train: loss: 0.0000589
[Epoch 76; Iter   735/ 1097] train: loss: 0.0007162
[Epoch 76; Iter   765/ 1097] train: loss: 0.0033919
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000257
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000033
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001246
[Epoch 76; Iter   885/ 1097] train: loss: 0.0002962
[Epoch 76; Iter   915/ 1097] train: loss: 0.0002066
[Epoch 76; Iter   945/ 1097] train: loss: 0.0001193
[Epoch 76; Iter   975/ 1097] train: loss: 0.0005900
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0003230
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0001634
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0002449
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0003081
[Epoch 76] ogbg-molhiv: 0.724399 val loss: 18.396986
[Epoch 76] ogbg-molhiv: 0.678634 test loss: 13.731402
[Epoch 77; Iter    28/ 1097] train: loss: 0.0004292
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000329
[Epoch 77; Iter    88/ 1097] train: loss: 0.0012737
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002694
[Epoch 77; Iter   148/ 1097] train: loss: 0.0011993
[Epoch 77; Iter   178/ 1097] train: loss: 0.0000801
[Epoch 77; Iter   208/ 1097] train: loss: 0.0096791
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000268
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000156
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001749
[Epoch 73; Iter   246/ 1097] train: loss: 0.0000943
[Epoch 73; Iter   276/ 1097] train: loss: 0.0374361
[Epoch 73; Iter   306/ 1097] train: loss: 0.0128214
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000648
[Epoch 73; Iter   366/ 1097] train: loss: 0.0000146
[Epoch 73; Iter   396/ 1097] train: loss: 0.0005520
[Epoch 73; Iter   426/ 1097] train: loss: 0.0239583
[Epoch 73; Iter   456/ 1097] train: loss: 0.0033342
[Epoch 73; Iter   486/ 1097] train: loss: 0.0011353
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000730
[Epoch 73; Iter   546/ 1097] train: loss: 0.0086129
[Epoch 73; Iter   576/ 1097] train: loss: 0.0007920
[Epoch 73; Iter   606/ 1097] train: loss: 0.0016092
[Epoch 73; Iter   636/ 1097] train: loss: 0.0121108
[Epoch 73; Iter   666/ 1097] train: loss: 0.0004721
[Epoch 73; Iter   696/ 1097] train: loss: 0.0011188
[Epoch 73; Iter   726/ 1097] train: loss: 0.0011633
[Epoch 73; Iter   756/ 1097] train: loss: 0.0002163
[Epoch 73; Iter   786/ 1097] train: loss: 0.0001256
[Epoch 73; Iter   816/ 1097] train: loss: 0.0005441
[Epoch 73; Iter   846/ 1097] train: loss: 0.0032496
[Epoch 73; Iter   876/ 1097] train: loss: 0.0000438
[Epoch 73; Iter   906/ 1097] train: loss: 0.0001684
[Epoch 73; Iter   936/ 1097] train: loss: 0.0010200
[Epoch 73; Iter   966/ 1097] train: loss: 0.0015788
[Epoch 73; Iter   996/ 1097] train: loss: 0.0088761
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0002590
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0006555
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0001498
[Epoch 73] ogbg-molhiv: 0.594834 val loss: 49.481685
[Epoch 73] ogbg-molhiv: 0.546386 test loss: 47.034638
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001811
[Epoch 74; Iter    49/ 1097] train: loss: 0.0008405
[Epoch 74; Iter    79/ 1097] train: loss: 0.0006782
[Epoch 74; Iter   109/ 1097] train: loss: 0.0049766
[Epoch 74; Iter   139/ 1097] train: loss: 0.0000581
[Epoch 74; Iter   169/ 1097] train: loss: 0.0016344
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000395
[Epoch 74; Iter   229/ 1097] train: loss: 0.0010516
[Epoch 74; Iter   259/ 1097] train: loss: 0.0305570
[Epoch 74; Iter   289/ 1097] train: loss: 0.0002164
[Epoch 74; Iter   319/ 1097] train: loss: 0.0000840
[Epoch 74; Iter   349/ 1097] train: loss: 0.0051156
[Epoch 74; Iter   379/ 1097] train: loss: 0.0015318
[Epoch 74; Iter   409/ 1097] train: loss: 0.0050482
[Epoch 74; Iter   439/ 1097] train: loss: 0.0004186
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000533
[Epoch 74; Iter   499/ 1097] train: loss: 0.0003977
[Epoch 74; Iter   529/ 1097] train: loss: 0.0011121
[Epoch 74; Iter   559/ 1097] train: loss: 0.0001899
[Epoch 74; Iter   589/ 1097] train: loss: 0.0008705
[Epoch 74; Iter   619/ 1097] train: loss: 0.0003109
[Epoch 74; Iter   649/ 1097] train: loss: 0.0043846
[Epoch 74; Iter   679/ 1097] train: loss: 0.0041785
[Epoch 74; Iter   709/ 1097] train: loss: 0.0047775
[Epoch 74; Iter   739/ 1097] train: loss: 0.0011798
[Epoch 74; Iter   769/ 1097] train: loss: 0.0013269
[Epoch 74; Iter   799/ 1097] train: loss: 0.0001235
[Epoch 74; Iter   829/ 1097] train: loss: 0.0010203
[Epoch 74; Iter   859/ 1097] train: loss: 0.0006838
[Epoch 74; Iter   889/ 1097] train: loss: 0.0009391
[Epoch 74; Iter   919/ 1097] train: loss: 0.0004400
[Epoch 74; Iter   949/ 1097] train: loss: 0.0558944
[Epoch 74; Iter   979/ 1097] train: loss: 0.0012769
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0084366
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0000480
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000334
[Epoch 74] ogbg-molhiv: 0.584044 val loss: 100.840509
[Epoch 74] ogbg-molhiv: 0.543139 test loss: 87.736535
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000212
[Epoch 75; Iter    32/ 1097] train: loss: 0.0166806
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000526
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001037
[Epoch 75; Iter   122/ 1097] train: loss: 0.0071833
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000707
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000552
[Epoch 75; Iter   212/ 1097] train: loss: 0.0002228
[Epoch 75; Iter   242/ 1097] train: loss: 0.0013726
[Epoch 75; Iter   272/ 1097] train: loss: 0.0003815
[Epoch 75; Iter   302/ 1097] train: loss: 0.0019684
[Epoch 75; Iter   332/ 1097] train: loss: 0.0027782
[Epoch 75; Iter   362/ 1097] train: loss: 0.0000516
[Epoch 75; Iter   392/ 1097] train: loss: 0.0001943
[Epoch 75; Iter   422/ 1097] train: loss: 0.0008161
[Epoch 75; Iter   452/ 1097] train: loss: 0.0019601
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000993
[Epoch 75; Iter   512/ 1097] train: loss: 0.0156812
[Epoch 75; Iter   542/ 1097] train: loss: 0.0003698
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000532
[Epoch 75; Iter   602/ 1097] train: loss: 0.0003208
[Epoch 75; Iter   632/ 1097] train: loss: 0.0021382
[Epoch 75; Iter   662/ 1097] train: loss: 0.0000641
[Epoch 75; Iter   692/ 1097] train: loss: 0.0000683
[Epoch 75; Iter   722/ 1097] train: loss: 0.0002459
[Epoch 75; Iter   752/ 1097] train: loss: 0.0034322
[Epoch 75; Iter   782/ 1097] train: loss: 0.0002953
[Epoch 75; Iter   812/ 1097] train: loss: 0.0011695
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000119
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000613
[Epoch 75; Iter   902/ 1097] train: loss: 0.0054302
[Epoch 75; Iter   932/ 1097] train: loss: 0.0020509
[Epoch 75; Iter   962/ 1097] train: loss: 0.0001449
[Epoch 75; Iter   992/ 1097] train: loss: 0.0004820
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000041
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0008120
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0118385
[Epoch 75] ogbg-molhiv: 0.604053 val loss: 77.576757
[Epoch 75] ogbg-molhiv: 0.569005 test loss: 65.158668
[Epoch 76; Iter    15/ 1097] train: loss: 0.0896147
[Epoch 76; Iter    45/ 1097] train: loss: 0.0017606
[Epoch 76; Iter    75/ 1097] train: loss: 0.0004204
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000424
[Epoch 76; Iter   135/ 1097] train: loss: 0.0018232
[Epoch 76; Iter   165/ 1097] train: loss: 0.0001985
[Epoch 76; Iter   195/ 1097] train: loss: 0.0006155
[Epoch 76; Iter   225/ 1097] train: loss: 0.0003053
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000504
[Epoch 76; Iter   285/ 1097] train: loss: 0.0004244
[Epoch 76; Iter   315/ 1097] train: loss: 0.0024114
[Epoch 76; Iter   345/ 1097] train: loss: 0.0001702
[Epoch 76; Iter   375/ 1097] train: loss: 0.0000576
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000118
[Epoch 76; Iter   435/ 1097] train: loss: 0.0003470
[Epoch 76; Iter   465/ 1097] train: loss: 0.0004760
[Epoch 76; Iter   495/ 1097] train: loss: 0.0457441
[Epoch 76; Iter   525/ 1097] train: loss: 0.0005100
[Epoch 76; Iter   555/ 1097] train: loss: 0.0281308
[Epoch 76; Iter   585/ 1097] train: loss: 0.0000805
[Epoch 76; Iter   615/ 1097] train: loss: 0.0021197
[Epoch 76; Iter   645/ 1097] train: loss: 0.0059587
[Epoch 76; Iter   675/ 1097] train: loss: 0.0000503
[Epoch 76; Iter   705/ 1097] train: loss: 0.0007077
[Epoch 76; Iter   735/ 1097] train: loss: 0.0005477
[Epoch 76; Iter   765/ 1097] train: loss: 0.0001614
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000658
[Epoch 76; Iter   825/ 1097] train: loss: 0.0071220
[Epoch 76; Iter   855/ 1097] train: loss: 0.0026234
[Epoch 76; Iter   885/ 1097] train: loss: 0.0022076
[Epoch 76; Iter   915/ 1097] train: loss: 0.0001759
[Epoch 76; Iter   945/ 1097] train: loss: 0.0040411
[Epoch 76; Iter   975/ 1097] train: loss: 0.0003981
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0003113
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000234
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0006137
[Epoch 76; Iter  1095/ 1097] train: loss: 0.1344297
[Epoch 76] ogbg-molhiv: 0.647407 val loss: 133.496454
[Epoch 76] ogbg-molhiv: 0.553456 test loss: 109.054875
[Epoch 77; Iter    28/ 1097] train: loss: 0.0004730
[Epoch 77; Iter    58/ 1097] train: loss: 0.0051328
[Epoch 77; Iter    88/ 1097] train: loss: 0.0027240
[Epoch 77; Iter   118/ 1097] train: loss: 0.0001122
[Epoch 77; Iter   148/ 1097] train: loss: 0.0052816
[Epoch 77; Iter   178/ 1097] train: loss: 0.0000260
[Epoch 77; Iter   208/ 1097] train: loss: 0.0124878
[Epoch 77; Iter   238/ 1097] train: loss: 0.0001333
[Epoch 60; Iter  1097/ 1097] train: loss: 0.3885251
[Epoch 60] ogbg-molhiv: 0.814882 val loss: 0.100650
[Epoch 60] ogbg-molhiv: 0.740316 test loss: 0.184346
[Epoch 61; Iter    30/ 1097] train: loss: 0.0773029
[Epoch 61; Iter    60/ 1097] train: loss: 0.0022895
[Epoch 61; Iter    90/ 1097] train: loss: 0.0646777
[Epoch 61; Iter   120/ 1097] train: loss: 0.0135829
[Epoch 61; Iter   150/ 1097] train: loss: 0.2705396
[Epoch 61; Iter   180/ 1097] train: loss: 0.0473051
[Epoch 61; Iter   210/ 1097] train: loss: 0.0398792
[Epoch 61; Iter   240/ 1097] train: loss: 0.0311784
[Epoch 61; Iter   270/ 1097] train: loss: 0.1024250
[Epoch 61; Iter   300/ 1097] train: loss: 0.0240445
[Epoch 61; Iter   330/ 1097] train: loss: 0.0249364
[Epoch 61; Iter   360/ 1097] train: loss: 0.0077336
[Epoch 61; Iter   390/ 1097] train: loss: 0.0411683
[Epoch 61; Iter   420/ 1097] train: loss: 0.0393182
[Epoch 61; Iter   450/ 1097] train: loss: 0.1654736
[Epoch 61; Iter   480/ 1097] train: loss: 0.0143608
[Epoch 61; Iter   510/ 1097] train: loss: 0.2663291
[Epoch 61; Iter   540/ 1097] train: loss: 0.0230742
[Epoch 61; Iter   570/ 1097] train: loss: 0.0553451
[Epoch 61; Iter   600/ 1097] train: loss: 0.0144441
[Epoch 61; Iter   630/ 1097] train: loss: 0.1532965
[Epoch 61; Iter   660/ 1097] train: loss: 0.0504898
[Epoch 61; Iter   690/ 1097] train: loss: 0.0042049
[Epoch 61; Iter   720/ 1097] train: loss: 0.1514145
[Epoch 61; Iter   750/ 1097] train: loss: 0.1598731
[Epoch 61; Iter   780/ 1097] train: loss: 0.0045142
[Epoch 61; Iter   810/ 1097] train: loss: 0.0074924
[Epoch 61; Iter   840/ 1097] train: loss: 0.0269225
[Epoch 61; Iter   870/ 1097] train: loss: 0.1227909
[Epoch 61; Iter   900/ 1097] train: loss: 0.1498028
[Epoch 61; Iter   930/ 1097] train: loss: 0.0129781
[Epoch 61; Iter   960/ 1097] train: loss: 0.0334542
[Epoch 61; Iter   990/ 1097] train: loss: 0.0127963
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0363752
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0024300
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0181530
[Epoch 61] ogbg-molhiv: 0.827145 val loss: 0.092979
[Epoch 61] ogbg-molhiv: 0.761069 test loss: 0.176783
[Epoch 62; Iter    13/ 1097] train: loss: 0.0541316
[Epoch 62; Iter    43/ 1097] train: loss: 0.0373537
[Epoch 62; Iter    73/ 1097] train: loss: 0.0340212
[Epoch 62; Iter   103/ 1097] train: loss: 0.0335497
[Epoch 62; Iter   133/ 1097] train: loss: 0.0177857
[Epoch 62; Iter   163/ 1097] train: loss: 0.0278905
[Epoch 62; Iter   193/ 1097] train: loss: 0.0044953
[Epoch 62; Iter   223/ 1097] train: loss: 0.0066643
[Epoch 62; Iter   253/ 1097] train: loss: 0.0076748
[Epoch 62; Iter   283/ 1097] train: loss: 0.0094553
[Epoch 62; Iter   313/ 1097] train: loss: 0.0225693
[Epoch 62; Iter   343/ 1097] train: loss: 0.0019055
[Epoch 62; Iter   373/ 1097] train: loss: 0.0443105
[Epoch 62; Iter   403/ 1097] train: loss: 0.0092810
[Epoch 62; Iter   433/ 1097] train: loss: 0.0164969
[Epoch 62; Iter   463/ 1097] train: loss: 0.0201251
[Epoch 62; Iter   493/ 1097] train: loss: 0.0135362
[Epoch 62; Iter   523/ 1097] train: loss: 0.0139314
[Epoch 62; Iter   553/ 1097] train: loss: 0.0509336
[Epoch 62; Iter   583/ 1097] train: loss: 0.0127464
[Epoch 62; Iter   613/ 1097] train: loss: 0.0037065
[Epoch 62; Iter   643/ 1097] train: loss: 0.0194033
[Epoch 62; Iter   673/ 1097] train: loss: 0.1460990
[Epoch 62; Iter   703/ 1097] train: loss: 0.0631947
[Epoch 62; Iter   733/ 1097] train: loss: 0.1404565
[Epoch 62; Iter   763/ 1097] train: loss: 0.0189178
[Epoch 62; Iter   793/ 1097] train: loss: 0.2469337
[Epoch 62; Iter   823/ 1097] train: loss: 0.0644910
[Epoch 62; Iter   853/ 1097] train: loss: 0.1072463
[Epoch 62; Iter   883/ 1097] train: loss: 0.0143431
[Epoch 62; Iter   913/ 1097] train: loss: 0.0353034
[Epoch 62; Iter   943/ 1097] train: loss: 0.0310463
[Epoch 62; Iter   973/ 1097] train: loss: 0.0399600
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0108994
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0176098
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0858955
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0068243
[Epoch 62] ogbg-molhiv: 0.833952 val loss: 0.099283
[Epoch 62] ogbg-molhiv: 0.756478 test loss: 0.184782
[Epoch 63; Iter    26/ 1097] train: loss: 0.0266107
[Epoch 63; Iter    56/ 1097] train: loss: 0.0205616
[Epoch 63; Iter    86/ 1097] train: loss: 0.0867083
[Epoch 63; Iter   116/ 1097] train: loss: 0.0372327
[Epoch 63; Iter   146/ 1097] train: loss: 0.0718702
[Epoch 63; Iter   176/ 1097] train: loss: 0.0119074
[Epoch 63; Iter   206/ 1097] train: loss: 0.0679076
[Epoch 63; Iter   236/ 1097] train: loss: 0.2078877
[Epoch 63; Iter   266/ 1097] train: loss: 0.0042644
[Epoch 63; Iter   296/ 1097] train: loss: 0.0464347
[Epoch 63; Iter   326/ 1097] train: loss: 0.0053170
[Epoch 63; Iter   356/ 1097] train: loss: 0.1382150
[Epoch 63; Iter   386/ 1097] train: loss: 0.0253230
[Epoch 63; Iter   416/ 1097] train: loss: 0.0214601
[Epoch 63; Iter   446/ 1097] train: loss: 0.0049721
[Epoch 63; Iter   476/ 1097] train: loss: 0.0017894
[Epoch 63; Iter   506/ 1097] train: loss: 0.0178277
[Epoch 63; Iter   536/ 1097] train: loss: 0.0326992
[Epoch 63; Iter   566/ 1097] train: loss: 0.2662270
[Epoch 63; Iter   596/ 1097] train: loss: 0.0607934
[Epoch 63; Iter   626/ 1097] train: loss: 0.0045439
[Epoch 63; Iter   656/ 1097] train: loss: 0.0237225
[Epoch 63; Iter   686/ 1097] train: loss: 0.0086905
[Epoch 63; Iter   716/ 1097] train: loss: 0.1188430
[Epoch 63; Iter   746/ 1097] train: loss: 0.1274344
[Epoch 63; Iter   776/ 1097] train: loss: 0.0339680
[Epoch 63; Iter   806/ 1097] train: loss: 0.0947473
[Epoch 63; Iter   836/ 1097] train: loss: 0.0146626
[Epoch 63; Iter   866/ 1097] train: loss: 0.0091108
[Epoch 63; Iter   896/ 1097] train: loss: 0.0127800
[Epoch 63; Iter   926/ 1097] train: loss: 0.0034228
[Epoch 63; Iter   956/ 1097] train: loss: 0.0053372
[Epoch 63; Iter   986/ 1097] train: loss: 0.0077471
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0149802
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0416006
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0395743
[Epoch 63] ogbg-molhiv: 0.810733 val loss: 0.103652
[Epoch 63] ogbg-molhiv: 0.738249 test loss: 0.195695
[Epoch 64; Iter     9/ 1097] train: loss: 0.0052422
[Epoch 64; Iter    39/ 1097] train: loss: 0.3070163
[Epoch 64; Iter    69/ 1097] train: loss: 0.0289097
[Epoch 64; Iter    99/ 1097] train: loss: 0.0436775
[Epoch 64; Iter   129/ 1097] train: loss: 0.0277242
[Epoch 64; Iter   159/ 1097] train: loss: 0.0062036
[Epoch 64; Iter   189/ 1097] train: loss: 0.0195849
[Epoch 64; Iter   219/ 1097] train: loss: 0.0500254
[Epoch 64; Iter   249/ 1097] train: loss: 0.0030081
[Epoch 64; Iter   279/ 1097] train: loss: 0.0031349
[Epoch 64; Iter   309/ 1097] train: loss: 0.0029885
[Epoch 64; Iter   339/ 1097] train: loss: 0.0388526
[Epoch 64; Iter   369/ 1097] train: loss: 0.0530108
[Epoch 64; Iter   399/ 1097] train: loss: 0.0856700
[Epoch 64; Iter   429/ 1097] train: loss: 0.0084465
[Epoch 64; Iter   459/ 1097] train: loss: 0.0453273
[Epoch 64; Iter   489/ 1097] train: loss: 0.0040776
[Epoch 64; Iter   519/ 1097] train: loss: 0.0338322
[Epoch 64; Iter   549/ 1097] train: loss: 0.0139827
[Epoch 64; Iter   579/ 1097] train: loss: 0.0729555
[Epoch 64; Iter   609/ 1097] train: loss: 0.0595130
[Epoch 64; Iter   639/ 1097] train: loss: 0.0061554
[Epoch 64; Iter   669/ 1097] train: loss: 0.0186758
[Epoch 64; Iter   699/ 1097] train: loss: 0.0680234
[Epoch 64; Iter   729/ 1097] train: loss: 0.0078613
[Epoch 64; Iter   759/ 1097] train: loss: 0.0484951
[Epoch 64; Iter   789/ 1097] train: loss: 0.0097601
[Epoch 64; Iter   819/ 1097] train: loss: 0.0037222
[Epoch 64; Iter   849/ 1097] train: loss: 0.1942877
[Epoch 64; Iter   879/ 1097] train: loss: 0.0165318
[Epoch 64; Iter   909/ 1097] train: loss: 0.0282811
[Epoch 64; Iter   939/ 1097] train: loss: 0.0434170
[Epoch 64; Iter   969/ 1097] train: loss: 0.0722580
[Epoch 64; Iter   999/ 1097] train: loss: 0.0528670
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0461098
[Epoch 64; Iter  1059/ 1097] train: loss: 0.1421757
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0101173
[Epoch 64] ogbg-molhiv: 0.823336 val loss: 0.100196
[Epoch 64] ogbg-molhiv: 0.752633 test loss: 0.185934
[Epoch 77; Iter   268/ 1097] train: loss: 0.0003346
[Epoch 77; Iter   298/ 1097] train: loss: 0.0005654
[Epoch 77; Iter   328/ 1097] train: loss: 0.0580002
[Epoch 77; Iter   358/ 1097] train: loss: 0.0009104
[Epoch 77; Iter   388/ 1097] train: loss: 0.0031529
[Epoch 77; Iter   418/ 1097] train: loss: 0.0016120
[Epoch 77; Iter   448/ 1097] train: loss: 0.0072542
[Epoch 77; Iter   478/ 1097] train: loss: 0.0012922
[Epoch 77; Iter   508/ 1097] train: loss: 0.0002893
[Epoch 77; Iter   538/ 1097] train: loss: 0.0000317
[Epoch 77; Iter   568/ 1097] train: loss: 0.0076646
[Epoch 77; Iter   598/ 1097] train: loss: 0.0003623
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000708
[Epoch 77; Iter   658/ 1097] train: loss: 0.0024654
[Epoch 77; Iter   688/ 1097] train: loss: 0.0022549
[Epoch 77; Iter   718/ 1097] train: loss: 0.0070571
[Epoch 77; Iter   748/ 1097] train: loss: 0.0102392
[Epoch 77; Iter   778/ 1097] train: loss: 0.0037982
[Epoch 77; Iter   808/ 1097] train: loss: 0.0003125
[Epoch 77; Iter   838/ 1097] train: loss: 0.0031685
[Epoch 77; Iter   868/ 1097] train: loss: 0.0218225
[Epoch 77; Iter   898/ 1097] train: loss: 0.0018927
[Epoch 77; Iter   928/ 1097] train: loss: 0.0110899
[Epoch 77; Iter   958/ 1097] train: loss: 0.0123794
[Epoch 77; Iter   988/ 1097] train: loss: 0.0056445
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0327130
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0271714
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0059325
[Epoch 77] ogbg-molhiv: 0.744283 val loss: 0.660685
[Epoch 77] ogbg-molhiv: 0.743578 test loss: 0.730908
[Epoch 78; Iter    11/ 1097] train: loss: 0.0001162
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000462
[Epoch 78; Iter    71/ 1097] train: loss: 0.0112925
[Epoch 78; Iter   101/ 1097] train: loss: 0.0003178
[Epoch 78; Iter   131/ 1097] train: loss: 0.0005682
[Epoch 78; Iter   161/ 1097] train: loss: 0.0002234
[Epoch 78; Iter   191/ 1097] train: loss: 0.0000290
[Epoch 78; Iter   221/ 1097] train: loss: 0.0009391
[Epoch 78; Iter   251/ 1097] train: loss: 0.0032676
[Epoch 78; Iter   281/ 1097] train: loss: 0.0003722
[Epoch 78; Iter   311/ 1097] train: loss: 0.0012485
[Epoch 78; Iter   341/ 1097] train: loss: 0.0037040
[Epoch 78; Iter   371/ 1097] train: loss: 0.0000568
[Epoch 78; Iter   401/ 1097] train: loss: 0.0000779
[Epoch 78; Iter   431/ 1097] train: loss: 0.0045446
[Epoch 78; Iter   461/ 1097] train: loss: 0.0012488
[Epoch 78; Iter   491/ 1097] train: loss: 0.0015550
[Epoch 78; Iter   521/ 1097] train: loss: 0.0014202
[Epoch 78; Iter   551/ 1097] train: loss: 0.0002542
[Epoch 78; Iter   581/ 1097] train: loss: 0.0033914
[Epoch 78; Iter   611/ 1097] train: loss: 0.0366027
[Epoch 78; Iter   641/ 1097] train: loss: 0.0016761
[Epoch 78; Iter   671/ 1097] train: loss: 0.0007399
[Epoch 78; Iter   701/ 1097] train: loss: 0.0416955
[Epoch 78; Iter   731/ 1097] train: loss: 0.0001634
[Epoch 78; Iter   761/ 1097] train: loss: 0.0014133
[Epoch 78; Iter   791/ 1097] train: loss: 0.0000633
[Epoch 78; Iter   821/ 1097] train: loss: 0.0000214
[Epoch 78; Iter   851/ 1097] train: loss: 0.0003508
[Epoch 78; Iter   881/ 1097] train: loss: 0.0292026
[Epoch 78; Iter   911/ 1097] train: loss: 0.0001819
[Epoch 78; Iter   941/ 1097] train: loss: 0.0001353
[Epoch 78; Iter   971/ 1097] train: loss: 0.0000632
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0005007
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0006235
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0186541
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0006899
[Epoch 78] ogbg-molhiv: 0.770680 val loss: 1.252219
[Epoch 78] ogbg-molhiv: 0.759439 test loss: 1.858776
[Epoch 79; Iter    24/ 1097] train: loss: 0.0034271
[Epoch 79; Iter    54/ 1097] train: loss: 0.0010444
[Epoch 79; Iter    84/ 1097] train: loss: 0.0001490
[Epoch 79; Iter   114/ 1097] train: loss: 0.0002682
[Epoch 79; Iter   144/ 1097] train: loss: 0.0011989
[Epoch 79; Iter   174/ 1097] train: loss: 0.0000373
[Epoch 79; Iter   204/ 1097] train: loss: 0.0771175
[Epoch 79; Iter   234/ 1097] train: loss: 0.0000388
[Epoch 79; Iter   264/ 1097] train: loss: 0.0439550
[Epoch 79; Iter   294/ 1097] train: loss: 0.1136449
[Epoch 79; Iter   324/ 1097] train: loss: 0.0003903
[Epoch 79; Iter   354/ 1097] train: loss: 0.0003151
[Epoch 79; Iter   384/ 1097] train: loss: 0.0022690
[Epoch 79; Iter   414/ 1097] train: loss: 0.0001395
[Epoch 79; Iter   444/ 1097] train: loss: 0.0003803
[Epoch 79; Iter   474/ 1097] train: loss: 0.0025517
[Epoch 79; Iter   504/ 1097] train: loss: 0.0003446
[Epoch 79; Iter   534/ 1097] train: loss: 0.0002647
[Epoch 79; Iter   564/ 1097] train: loss: 0.0238108
[Epoch 79; Iter   594/ 1097] train: loss: 0.0038014
[Epoch 79; Iter   624/ 1097] train: loss: 0.0002973
[Epoch 79; Iter   654/ 1097] train: loss: 0.0056528
[Epoch 79; Iter   684/ 1097] train: loss: 0.0035218
[Epoch 79; Iter   714/ 1097] train: loss: 0.0585095
[Epoch 79; Iter   744/ 1097] train: loss: 0.0001889
[Epoch 79; Iter   774/ 1097] train: loss: 0.0020673
[Epoch 79; Iter   804/ 1097] train: loss: 0.0004729
[Epoch 79; Iter   834/ 1097] train: loss: 0.0081498
[Epoch 79; Iter   864/ 1097] train: loss: 0.0162277
[Epoch 79; Iter   894/ 1097] train: loss: 0.0007608
[Epoch 79; Iter   924/ 1097] train: loss: 0.0005295
[Epoch 79; Iter   954/ 1097] train: loss: 0.0012283
[Epoch 79; Iter   984/ 1097] train: loss: 0.0342936
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0005728
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0000214
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0030392
[Epoch 79] ogbg-molhiv: 0.769988 val loss: 0.650788
[Epoch 79] ogbg-molhiv: 0.718697 test loss: 0.766424
[Epoch 80; Iter     7/ 1097] train: loss: 0.0179422
[Epoch 80; Iter    37/ 1097] train: loss: 0.0031278
[Epoch 80; Iter    67/ 1097] train: loss: 0.0001741
[Epoch 80; Iter    97/ 1097] train: loss: 0.0031973
[Epoch 80; Iter   127/ 1097] train: loss: 0.0004691
[Epoch 80; Iter   157/ 1097] train: loss: 0.0001426
[Epoch 80; Iter   187/ 1097] train: loss: 0.0209609
[Epoch 80; Iter   217/ 1097] train: loss: 0.0318174
[Epoch 80; Iter   247/ 1097] train: loss: 0.0019361
[Epoch 80; Iter   277/ 1097] train: loss: 0.0000342
[Epoch 80; Iter   307/ 1097] train: loss: 0.0000223
[Epoch 80; Iter   337/ 1097] train: loss: 0.0063105
[Epoch 80; Iter   367/ 1097] train: loss: 0.0071976
[Epoch 80; Iter   397/ 1097] train: loss: 0.0011575
[Epoch 80; Iter   427/ 1097] train: loss: 0.0002779
[Epoch 80; Iter   457/ 1097] train: loss: 0.0524029
[Epoch 80; Iter   487/ 1097] train: loss: 0.0003318
[Epoch 80; Iter   517/ 1097] train: loss: 0.0012266
[Epoch 80; Iter   547/ 1097] train: loss: 0.0000697
[Epoch 80; Iter   577/ 1097] train: loss: 0.1388564
[Epoch 80; Iter   607/ 1097] train: loss: 0.0002737
[Epoch 80; Iter   637/ 1097] train: loss: 0.0004624
[Epoch 80; Iter   667/ 1097] train: loss: 0.0049275
[Epoch 80; Iter   697/ 1097] train: loss: 0.0002497
[Epoch 80; Iter   727/ 1097] train: loss: 0.0003794
[Epoch 80; Iter   757/ 1097] train: loss: 0.0957279
[Epoch 80; Iter   787/ 1097] train: loss: 0.0022985
[Epoch 80; Iter   817/ 1097] train: loss: 0.0086160
[Epoch 80; Iter   847/ 1097] train: loss: 0.0107768
[Epoch 80; Iter   877/ 1097] train: loss: 0.0172016
[Epoch 80; Iter   907/ 1097] train: loss: 0.0006154
[Epoch 80; Iter   937/ 1097] train: loss: 0.0100370
[Epoch 80; Iter   967/ 1097] train: loss: 0.0003018
[Epoch 80; Iter   997/ 1097] train: loss: 0.0066180
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0780759
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0005967
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0000536
[Epoch 80] ogbg-molhiv: 0.751926 val loss: 0.794888
[Epoch 80] ogbg-molhiv: 0.727561 test loss: 0.975489
[Epoch 81; Iter    20/ 1097] train: loss: 0.0124376
[Epoch 81; Iter    50/ 1097] train: loss: 0.0007282
[Epoch 81; Iter    80/ 1097] train: loss: 0.0016191
[Epoch 81; Iter   110/ 1097] train: loss: 0.0002944
[Epoch 81; Iter   140/ 1097] train: loss: 0.0000540
[Epoch 81; Iter   170/ 1097] train: loss: 0.0347921
[Epoch 81; Iter   200/ 1097] train: loss: 0.0045481
[Epoch 81; Iter   230/ 1097] train: loss: 0.0036391
[Epoch 81; Iter   260/ 1097] train: loss: 0.0102759
[Epoch 81; Iter   290/ 1097] train: loss: 0.0196635
[Epoch 81; Iter   320/ 1097] train: loss: 0.0056694
[Epoch 77; Iter   268/ 1097] train: loss: 0.0010084
[Epoch 77; Iter   298/ 1097] train: loss: 0.0010400
[Epoch 77; Iter   328/ 1097] train: loss: 0.0002712
[Epoch 77; Iter   358/ 1097] train: loss: 0.0004334
[Epoch 77; Iter   388/ 1097] train: loss: 0.0008916
[Epoch 77; Iter   418/ 1097] train: loss: 0.0000672
[Epoch 77; Iter   448/ 1097] train: loss: 0.0042381
[Epoch 77; Iter   478/ 1097] train: loss: 0.0010004
[Epoch 77; Iter   508/ 1097] train: loss: 0.0013915
[Epoch 77; Iter   538/ 1097] train: loss: 0.0047670
[Epoch 77; Iter   568/ 1097] train: loss: 0.0001297
[Epoch 77; Iter   598/ 1097] train: loss: 0.0002844
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000126
[Epoch 77; Iter   658/ 1097] train: loss: 0.0369568
[Epoch 77; Iter   688/ 1097] train: loss: 0.0018111
[Epoch 77; Iter   718/ 1097] train: loss: 0.0003670
[Epoch 77; Iter   748/ 1097] train: loss: 0.0000666
[Epoch 77; Iter   778/ 1097] train: loss: 0.0000511
[Epoch 77; Iter   808/ 1097] train: loss: 0.0001380
[Epoch 77; Iter   838/ 1097] train: loss: 0.0000964
[Epoch 77; Iter   868/ 1097] train: loss: 0.0006807
[Epoch 77; Iter   898/ 1097] train: loss: 0.0003670
[Epoch 77; Iter   928/ 1097] train: loss: 0.0000139
[Epoch 77; Iter   958/ 1097] train: loss: 0.0013901
[Epoch 77; Iter   988/ 1097] train: loss: 0.0000818
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0010526
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0001250
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0221752
[Epoch 77] ogbg-molhiv: 0.785595 val loss: 0.257973
[Epoch 77] ogbg-molhiv: 0.705328 test loss: 0.394316
[Epoch 78; Iter    11/ 1097] train: loss: 0.0000244
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000477
[Epoch 78; Iter    71/ 1097] train: loss: 0.0014338
[Epoch 78; Iter   101/ 1097] train: loss: 0.0004798
[Epoch 78; Iter   131/ 1097] train: loss: 0.0012760
[Epoch 78; Iter   161/ 1097] train: loss: 0.0003520
[Epoch 78; Iter   191/ 1097] train: loss: 0.0059528
[Epoch 78; Iter   221/ 1097] train: loss: 0.0773629
[Epoch 78; Iter   251/ 1097] train: loss: 0.0002595
[Epoch 78; Iter   281/ 1097] train: loss: 0.0003475
[Epoch 78; Iter   311/ 1097] train: loss: 0.0001955
[Epoch 78; Iter   341/ 1097] train: loss: 0.0022671
[Epoch 78; Iter   371/ 1097] train: loss: 0.0008238
[Epoch 78; Iter   401/ 1097] train: loss: 0.0000432
[Epoch 78; Iter   431/ 1097] train: loss: 0.0006595
[Epoch 78; Iter   461/ 1097] train: loss: 0.0003781
[Epoch 78; Iter   491/ 1097] train: loss: 0.0003297
[Epoch 78; Iter   521/ 1097] train: loss: 0.0000225
[Epoch 78; Iter   551/ 1097] train: loss: 0.0001423
[Epoch 78; Iter   581/ 1097] train: loss: 0.0544301
[Epoch 78; Iter   611/ 1097] train: loss: 0.0000340
[Epoch 78; Iter   641/ 1097] train: loss: 0.0000760
[Epoch 78; Iter   671/ 1097] train: loss: 0.0003391
[Epoch 78; Iter   701/ 1097] train: loss: 0.0054780
[Epoch 78; Iter   731/ 1097] train: loss: 0.0053874
[Epoch 78; Iter   761/ 1097] train: loss: 0.0001268
[Epoch 78; Iter   791/ 1097] train: loss: 0.0000977
[Epoch 78; Iter   821/ 1097] train: loss: 0.0013736
[Epoch 78; Iter   851/ 1097] train: loss: 0.0004120
[Epoch 78; Iter   881/ 1097] train: loss: 0.0000407
[Epoch 78; Iter   911/ 1097] train: loss: 0.0001235
[Epoch 78; Iter   941/ 1097] train: loss: 0.0000865
[Epoch 78; Iter   971/ 1097] train: loss: 0.0000028
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0000362
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0003047
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0001908
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0002732
[Epoch 78] ogbg-molhiv: 0.778231 val loss: 0.314505
[Epoch 78] ogbg-molhiv: 0.724873 test loss: 0.444326
[Epoch 79; Iter    24/ 1097] train: loss: 0.0008376
[Epoch 79; Iter    54/ 1097] train: loss: 0.0011938
[Epoch 79; Iter    84/ 1097] train: loss: 0.0002989
[Epoch 79; Iter   114/ 1097] train: loss: 0.0000404
[Epoch 79; Iter   144/ 1097] train: loss: 0.0000381
[Epoch 79; Iter   174/ 1097] train: loss: 0.0389666
[Epoch 79; Iter   204/ 1097] train: loss: 0.0002460
[Epoch 79; Iter   234/ 1097] train: loss: 0.0010910
[Epoch 79; Iter   264/ 1097] train: loss: 0.0000238
[Epoch 79; Iter   294/ 1097] train: loss: 0.0001471
[Epoch 79; Iter   324/ 1097] train: loss: 0.0034352
[Epoch 79; Iter   354/ 1097] train: loss: 0.0013009
[Epoch 79; Iter   384/ 1097] train: loss: 0.0000186
[Epoch 79; Iter   414/ 1097] train: loss: 0.0001094
[Epoch 79; Iter   444/ 1097] train: loss: 0.0000276
[Epoch 79; Iter   474/ 1097] train: loss: 0.0000179
[Epoch 79; Iter   504/ 1097] train: loss: 0.0000862
[Epoch 79; Iter   534/ 1097] train: loss: 0.0209241
[Epoch 79; Iter   564/ 1097] train: loss: 0.0002092
[Epoch 79; Iter   594/ 1097] train: loss: 0.0000400
[Epoch 79; Iter   624/ 1097] train: loss: 0.0256548
[Epoch 79; Iter   654/ 1097] train: loss: 0.0004588
[Epoch 79; Iter   684/ 1097] train: loss: 0.0000589
[Epoch 79; Iter   714/ 1097] train: loss: 0.0005970
[Epoch 79; Iter   744/ 1097] train: loss: 0.0005865
[Epoch 79; Iter   774/ 1097] train: loss: 0.0000626
[Epoch 79; Iter   804/ 1097] train: loss: 0.0001043
[Epoch 79; Iter   834/ 1097] train: loss: 0.0087951
[Epoch 79; Iter   864/ 1097] train: loss: 0.0009493
[Epoch 79; Iter   894/ 1097] train: loss: 0.0001042
[Epoch 79; Iter   924/ 1097] train: loss: 0.0000466
[Epoch 79; Iter   954/ 1097] train: loss: 0.0000836
[Epoch 79; Iter   984/ 1097] train: loss: 0.0096290
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0003486
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0001227
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0000635
[Epoch 79] ogbg-molhiv: 0.782888 val loss: 0.307484
[Epoch 79] ogbg-molhiv: 0.720945 test loss: 0.415983
[Epoch 80; Iter     7/ 1097] train: loss: 0.0001334
[Epoch 80; Iter    37/ 1097] train: loss: 0.0007513
[Epoch 80; Iter    67/ 1097] train: loss: 0.0000060
[Epoch 80; Iter    97/ 1097] train: loss: 0.0028092
[Epoch 80; Iter   127/ 1097] train: loss: 0.0002233
[Epoch 80; Iter   157/ 1097] train: loss: 0.0002028
[Epoch 80; Iter   187/ 1097] train: loss: 0.0000188
[Epoch 80; Iter   217/ 1097] train: loss: 0.0000203
[Epoch 80; Iter   247/ 1097] train: loss: 0.0000130
[Epoch 80; Iter   277/ 1097] train: loss: 0.0000292
[Epoch 80; Iter   307/ 1097] train: loss: 0.0002460
[Epoch 80; Iter   337/ 1097] train: loss: 0.0201956
[Epoch 80; Iter   367/ 1097] train: loss: 0.0003689
[Epoch 80; Iter   397/ 1097] train: loss: 0.0001381
[Epoch 80; Iter   427/ 1097] train: loss: 0.0001084
[Epoch 80; Iter   457/ 1097] train: loss: 0.0237722
[Epoch 80; Iter   487/ 1097] train: loss: 0.0002363
[Epoch 80; Iter   517/ 1097] train: loss: 0.0031399
[Epoch 80; Iter   547/ 1097] train: loss: 0.0004539
[Epoch 80; Iter   577/ 1097] train: loss: 0.0013763
[Epoch 80; Iter   607/ 1097] train: loss: 0.0010811
[Epoch 80; Iter   637/ 1097] train: loss: 0.0007730
[Epoch 80; Iter   667/ 1097] train: loss: 0.0000364
[Epoch 80; Iter   697/ 1097] train: loss: 0.0016138
[Epoch 80; Iter   727/ 1097] train: loss: 0.0033691
[Epoch 80; Iter   757/ 1097] train: loss: 0.0001017
[Epoch 80; Iter   787/ 1097] train: loss: 0.0000894
[Epoch 80; Iter   817/ 1097] train: loss: 0.0048729
[Epoch 80; Iter   847/ 1097] train: loss: 0.0001210
[Epoch 80; Iter   877/ 1097] train: loss: 0.0048096
[Epoch 80; Iter   907/ 1097] train: loss: 0.0000220
[Epoch 80; Iter   937/ 1097] train: loss: 0.0000864
[Epoch 80; Iter   967/ 1097] train: loss: 0.0000333
[Epoch 80; Iter   997/ 1097] train: loss: 0.0026742
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0004754
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0001341
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0019001
[Epoch 80] ogbg-molhiv: 0.794646 val loss: 0.377892
[Epoch 80] ogbg-molhiv: 0.728320 test loss: 0.452188
[Epoch 81; Iter    20/ 1097] train: loss: 0.0002640
[Epoch 81; Iter    50/ 1097] train: loss: 0.0002527
[Epoch 81; Iter    80/ 1097] train: loss: 0.0249580
[Epoch 81; Iter   110/ 1097] train: loss: 0.0044257
[Epoch 81; Iter   140/ 1097] train: loss: 0.0002289
[Epoch 81; Iter   170/ 1097] train: loss: 0.0000258
[Epoch 81; Iter   200/ 1097] train: loss: 0.0007011
[Epoch 81; Iter   230/ 1097] train: loss: 0.0000085
[Epoch 81; Iter   260/ 1097] train: loss: 0.0009212
[Epoch 81; Iter   290/ 1097] train: loss: 0.0000101
[Epoch 81; Iter   320/ 1097] train: loss: 0.0000050
[Epoch 60; Iter  1097/ 1097] train: loss: 0.1271469
[Epoch 60] ogbg-molhiv: 0.787778 val loss: 0.172287
[Epoch 60] ogbg-molhiv: 0.727559 test loss: 0.350919
[Epoch 61; Iter    30/ 1097] train: loss: 0.0343393
[Epoch 61; Iter    60/ 1097] train: loss: 0.0180718
[Epoch 61; Iter    90/ 1097] train: loss: 0.0771641
[Epoch 61; Iter   120/ 1097] train: loss: 0.0465603
[Epoch 61; Iter   150/ 1097] train: loss: 0.0478897
[Epoch 61; Iter   180/ 1097] train: loss: 0.0064459
[Epoch 61; Iter   210/ 1097] train: loss: 0.0438057
[Epoch 61; Iter   240/ 1097] train: loss: 0.0198989
[Epoch 61; Iter   270/ 1097] train: loss: 0.0415734
[Epoch 61; Iter   300/ 1097] train: loss: 0.0705796
[Epoch 61; Iter   330/ 1097] train: loss: 0.0187879
[Epoch 61; Iter   360/ 1097] train: loss: 0.0117729
[Epoch 61; Iter   390/ 1097] train: loss: 0.0331848
[Epoch 61; Iter   420/ 1097] train: loss: 0.0088679
[Epoch 61; Iter   450/ 1097] train: loss: 0.0083854
[Epoch 61; Iter   480/ 1097] train: loss: 0.0068465
[Epoch 61; Iter   510/ 1097] train: loss: 0.0145316
[Epoch 61; Iter   540/ 1097] train: loss: 0.0088473
[Epoch 61; Iter   570/ 1097] train: loss: 0.0578082
[Epoch 61; Iter   600/ 1097] train: loss: 0.3349873
[Epoch 61; Iter   630/ 1097] train: loss: 0.0174835
[Epoch 61; Iter   660/ 1097] train: loss: 0.0103249
[Epoch 61; Iter   690/ 1097] train: loss: 0.1154055
[Epoch 61; Iter   720/ 1097] train: loss: 0.0369196
[Epoch 61; Iter   750/ 1097] train: loss: 0.2365667
[Epoch 61; Iter   780/ 1097] train: loss: 0.0254385
[Epoch 61; Iter   810/ 1097] train: loss: 0.0800332
[Epoch 61; Iter   840/ 1097] train: loss: 0.1052458
[Epoch 61; Iter   870/ 1097] train: loss: 0.0149840
[Epoch 61; Iter   900/ 1097] train: loss: 0.1409594
[Epoch 61; Iter   930/ 1097] train: loss: 0.0263157
[Epoch 61; Iter   960/ 1097] train: loss: 0.1589579
[Epoch 61; Iter   990/ 1097] train: loss: 0.2970168
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0090784
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0210172
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0045507
[Epoch 61] ogbg-molhiv: 0.805559 val loss: 0.106438
[Epoch 61] ogbg-molhiv: 0.733224 test loss: 0.190095
[Epoch 62; Iter    13/ 1097] train: loss: 0.0210375
[Epoch 62; Iter    43/ 1097] train: loss: 0.0159917
[Epoch 62; Iter    73/ 1097] train: loss: 0.0243876
[Epoch 62; Iter   103/ 1097] train: loss: 0.0524575
[Epoch 62; Iter   133/ 1097] train: loss: 0.0188835
[Epoch 62; Iter   163/ 1097] train: loss: 0.0152920
[Epoch 62; Iter   193/ 1097] train: loss: 0.0320281
[Epoch 62; Iter   223/ 1097] train: loss: 0.0297229
[Epoch 62; Iter   253/ 1097] train: loss: 0.0202525
[Epoch 62; Iter   283/ 1097] train: loss: 0.0460087
[Epoch 62; Iter   313/ 1097] train: loss: 0.0094637
[Epoch 62; Iter   343/ 1097] train: loss: 0.0090016
[Epoch 62; Iter   373/ 1097] train: loss: 0.0075811
[Epoch 62; Iter   403/ 1097] train: loss: 0.0726270
[Epoch 62; Iter   433/ 1097] train: loss: 0.0413401
[Epoch 62; Iter   463/ 1097] train: loss: 0.0410414
[Epoch 62; Iter   493/ 1097] train: loss: 0.0834652
[Epoch 62; Iter   523/ 1097] train: loss: 0.0423053
[Epoch 62; Iter   553/ 1097] train: loss: 0.1462285
[Epoch 62; Iter   583/ 1097] train: loss: 0.0137279
[Epoch 62; Iter   613/ 1097] train: loss: 0.0230885
[Epoch 62; Iter   643/ 1097] train: loss: 0.0048671
[Epoch 62; Iter   673/ 1097] train: loss: 0.0090402
[Epoch 62; Iter   703/ 1097] train: loss: 0.0206835
[Epoch 62; Iter   733/ 1097] train: loss: 0.0653979
[Epoch 62; Iter   763/ 1097] train: loss: 0.1713724
[Epoch 62; Iter   793/ 1097] train: loss: 0.0491624
[Epoch 62; Iter   823/ 1097] train: loss: 0.0837333
[Epoch 62; Iter   853/ 1097] train: loss: 0.0125298
[Epoch 62; Iter   883/ 1097] train: loss: 0.0909849
[Epoch 62; Iter   913/ 1097] train: loss: 0.0125369
[Epoch 62; Iter   943/ 1097] train: loss: 0.0665472
[Epoch 62; Iter   973/ 1097] train: loss: 0.0085551
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0476204
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0175513
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0152192
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0067582
[Epoch 62] ogbg-molhiv: 0.818226 val loss: 0.089944
[Epoch 62] ogbg-molhiv: 0.748834 test loss: 0.181196
[Epoch 63; Iter    26/ 1097] train: loss: 0.0168644
[Epoch 63; Iter    56/ 1097] train: loss: 0.1070277
[Epoch 63; Iter    86/ 1097] train: loss: 0.0420205
[Epoch 63; Iter   116/ 1097] train: loss: 0.0087304
[Epoch 63; Iter   146/ 1097] train: loss: 0.0302651
[Epoch 63; Iter   176/ 1097] train: loss: 0.0081838
[Epoch 63; Iter   206/ 1097] train: loss: 0.0870252
[Epoch 63; Iter   236/ 1097] train: loss: 0.1081649
[Epoch 63; Iter   266/ 1097] train: loss: 0.0114259
[Epoch 63; Iter   296/ 1097] train: loss: 0.0267701
[Epoch 63; Iter   326/ 1097] train: loss: 0.2188704
[Epoch 63; Iter   356/ 1097] train: loss: 0.0335203
[Epoch 63; Iter   386/ 1097] train: loss: 0.0066316
[Epoch 63; Iter   416/ 1097] train: loss: 0.0233493
[Epoch 63; Iter   446/ 1097] train: loss: 0.0113685
[Epoch 63; Iter   476/ 1097] train: loss: 0.0024172
[Epoch 63; Iter   506/ 1097] train: loss: 0.0217202
[Epoch 63; Iter   536/ 1097] train: loss: 0.0708701
[Epoch 63; Iter   566/ 1097] train: loss: 0.0980942
[Epoch 63; Iter   596/ 1097] train: loss: 0.1395104
[Epoch 63; Iter   626/ 1097] train: loss: 0.0051652
[Epoch 63; Iter   656/ 1097] train: loss: 0.0300038
[Epoch 63; Iter   686/ 1097] train: loss: 0.0022782
[Epoch 63; Iter   716/ 1097] train: loss: 0.0164371
[Epoch 63; Iter   746/ 1097] train: loss: 0.0100182
[Epoch 63; Iter   776/ 1097] train: loss: 0.0124181
[Epoch 63; Iter   806/ 1097] train: loss: 0.0425494
[Epoch 63; Iter   836/ 1097] train: loss: 0.0331202
[Epoch 63; Iter   866/ 1097] train: loss: 0.0156963
[Epoch 63; Iter   896/ 1097] train: loss: 0.0093275
[Epoch 63; Iter   926/ 1097] train: loss: 0.0111431
[Epoch 63; Iter   956/ 1097] train: loss: 0.2689387
[Epoch 63; Iter   986/ 1097] train: loss: 0.0316324
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0139089
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0457170
[Epoch 63; Iter  1076/ 1097] train: loss: 0.1534294
[Epoch 63] ogbg-molhiv: 0.771975 val loss: 0.240445
[Epoch 63] ogbg-molhiv: 0.747784 test loss: 0.387444
[Epoch 64; Iter     9/ 1097] train: loss: 0.0102620
[Epoch 64; Iter    39/ 1097] train: loss: 0.0058091
[Epoch 64; Iter    69/ 1097] train: loss: 0.0123940
[Epoch 64; Iter    99/ 1097] train: loss: 0.0262941
[Epoch 64; Iter   129/ 1097] train: loss: 0.0167919
[Epoch 64; Iter   159/ 1097] train: loss: 0.0049059
[Epoch 64; Iter   189/ 1097] train: loss: 0.0372451
[Epoch 64; Iter   219/ 1097] train: loss: 0.0302790
[Epoch 64; Iter   249/ 1097] train: loss: 0.0085665
[Epoch 64; Iter   279/ 1097] train: loss: 0.0216935
[Epoch 64; Iter   309/ 1097] train: loss: 0.0059591
[Epoch 64; Iter   339/ 1097] train: loss: 0.0101644
[Epoch 64; Iter   369/ 1097] train: loss: 0.1030157
[Epoch 64; Iter   399/ 1097] train: loss: 0.0590950
[Epoch 64; Iter   429/ 1097] train: loss: 0.0368455
[Epoch 64; Iter   459/ 1097] train: loss: 0.1018496
[Epoch 64; Iter   489/ 1097] train: loss: 0.0166711
[Epoch 64; Iter   519/ 1097] train: loss: 0.0386320
[Epoch 64; Iter   549/ 1097] train: loss: 0.0086739
[Epoch 64; Iter   579/ 1097] train: loss: 0.0067622
[Epoch 64; Iter   609/ 1097] train: loss: 0.0448509
[Epoch 64; Iter   639/ 1097] train: loss: 0.0543537
[Epoch 64; Iter   669/ 1097] train: loss: 0.0363256
[Epoch 64; Iter   699/ 1097] train: loss: 0.0142526
[Epoch 64; Iter   729/ 1097] train: loss: 0.0115555
[Epoch 64; Iter   759/ 1097] train: loss: 0.0256653
[Epoch 64; Iter   789/ 1097] train: loss: 0.1384632
[Epoch 64; Iter   819/ 1097] train: loss: 0.0332495
[Epoch 64; Iter   849/ 1097] train: loss: 0.0223774
[Epoch 64; Iter   879/ 1097] train: loss: 0.0532123
[Epoch 64; Iter   909/ 1097] train: loss: 0.0626153
[Epoch 64; Iter   939/ 1097] train: loss: 0.0226906
[Epoch 64; Iter   969/ 1097] train: loss: 0.1141394
[Epoch 64; Iter   999/ 1097] train: loss: 0.1686820
[Epoch 64; Iter  1029/ 1097] train: loss: 0.1007475
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0725866
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0467222
[Epoch 64] ogbg-molhiv: 0.798642 val loss: 0.098304
[Epoch 64] ogbg-molhiv: 0.736086 test loss: 0.190192
[Epoch 77; Iter   268/ 1097] train: loss: 0.0021477
[Epoch 77; Iter   298/ 1097] train: loss: 0.0037723
[Epoch 77; Iter   328/ 1097] train: loss: 0.0000118
[Epoch 77; Iter   358/ 1097] train: loss: 0.0000026
[Epoch 77; Iter   388/ 1097] train: loss: 0.0187416
[Epoch 77; Iter   418/ 1097] train: loss: 0.0016254
[Epoch 77; Iter   448/ 1097] train: loss: 0.0000145
[Epoch 77; Iter   478/ 1097] train: loss: 0.0055399
[Epoch 77; Iter   508/ 1097] train: loss: 0.0029145
[Epoch 77; Iter   538/ 1097] train: loss: 0.0056071
[Epoch 77; Iter   568/ 1097] train: loss: 0.0000711
[Epoch 77; Iter   598/ 1097] train: loss: 0.0000320
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000218
[Epoch 77; Iter   658/ 1097] train: loss: 0.0000764
[Epoch 77; Iter   688/ 1097] train: loss: 0.0005899
[Epoch 77; Iter   718/ 1097] train: loss: 0.0009384
[Epoch 77; Iter   748/ 1097] train: loss: 0.0002785
[Epoch 77; Iter   778/ 1097] train: loss: 0.0006790
[Epoch 77; Iter   808/ 1097] train: loss: 0.0029151
[Epoch 77; Iter   838/ 1097] train: loss: 0.0006578
[Epoch 77; Iter   868/ 1097] train: loss: 0.0058685
[Epoch 77; Iter   898/ 1097] train: loss: 0.0001014
[Epoch 77; Iter   928/ 1097] train: loss: 0.0001095
[Epoch 77; Iter   958/ 1097] train: loss: 0.0010545
[Epoch 77; Iter   988/ 1097] train: loss: 0.0012054
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0007329
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0029965
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0049360
[Epoch 77] ogbg-molhiv: 0.784082 val loss: 0.233731
[Epoch 77] ogbg-molhiv: 0.723399 test loss: 0.379241
[Epoch 78; Iter    11/ 1097] train: loss: 0.0000872
[Epoch 78; Iter    41/ 1097] train: loss: 0.0024216
[Epoch 78; Iter    71/ 1097] train: loss: 0.0000662
[Epoch 78; Iter   101/ 1097] train: loss: 0.0003864
[Epoch 78; Iter   131/ 1097] train: loss: 0.0012032
[Epoch 78; Iter   161/ 1097] train: loss: 0.0003003
[Epoch 78; Iter   191/ 1097] train: loss: 0.0027797
[Epoch 78; Iter   221/ 1097] train: loss: 0.0000585
[Epoch 78; Iter   251/ 1097] train: loss: 0.0000241
[Epoch 78; Iter   281/ 1097] train: loss: 0.0228105
[Epoch 78; Iter   311/ 1097] train: loss: 0.0001489
[Epoch 78; Iter   341/ 1097] train: loss: 0.0015319
[Epoch 78; Iter   371/ 1097] train: loss: 0.0012691
[Epoch 78; Iter   401/ 1097] train: loss: 0.0011373
[Epoch 78; Iter   431/ 1097] train: loss: 0.0043123
[Epoch 78; Iter   461/ 1097] train: loss: 0.0000265
[Epoch 78; Iter   491/ 1097] train: loss: 0.0002293
[Epoch 78; Iter   521/ 1097] train: loss: 0.0005557
[Epoch 78; Iter   551/ 1097] train: loss: 0.0000539
[Epoch 78; Iter   581/ 1097] train: loss: 0.0005211
[Epoch 78; Iter   611/ 1097] train: loss: 0.0000305
[Epoch 78; Iter   641/ 1097] train: loss: 0.0000455
[Epoch 78; Iter   671/ 1097] train: loss: 0.0005679
[Epoch 78; Iter   701/ 1097] train: loss: 0.0006453
[Epoch 78; Iter   731/ 1097] train: loss: 0.0000958
[Epoch 78; Iter   761/ 1097] train: loss: 0.0000565
[Epoch 78; Iter   791/ 1097] train: loss: 0.0036502
[Epoch 78; Iter   821/ 1097] train: loss: 0.0021499
[Epoch 78; Iter   851/ 1097] train: loss: 0.0000264
[Epoch 78; Iter   881/ 1097] train: loss: 0.0012189
[Epoch 78; Iter   911/ 1097] train: loss: 0.0001511
[Epoch 78; Iter   941/ 1097] train: loss: 0.0082418
[Epoch 78; Iter   971/ 1097] train: loss: 0.0008581
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0002223
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0000340
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0000374
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0029501
[Epoch 78] ogbg-molhiv: 0.767300 val loss: 0.240896
[Epoch 78] ogbg-molhiv: 0.729396 test loss: 0.374131
[Epoch 79; Iter    24/ 1097] train: loss: 0.0000587
[Epoch 79; Iter    54/ 1097] train: loss: 0.0000522
[Epoch 79; Iter    84/ 1097] train: loss: 0.0001276
[Epoch 79; Iter   114/ 1097] train: loss: 0.0108547
[Epoch 79; Iter   144/ 1097] train: loss: 0.0000141
[Epoch 79; Iter   174/ 1097] train: loss: 0.0004817
[Epoch 79; Iter   204/ 1097] train: loss: 0.0006117
[Epoch 79; Iter   234/ 1097] train: loss: 0.0006917
[Epoch 79; Iter   264/ 1097] train: loss: 0.0026069
[Epoch 79; Iter   294/ 1097] train: loss: 0.0000762
[Epoch 79; Iter   324/ 1097] train: loss: 0.0000160
[Epoch 79; Iter   354/ 1097] train: loss: 0.0000717
[Epoch 79; Iter   384/ 1097] train: loss: 0.0000134
[Epoch 79; Iter   414/ 1097] train: loss: 0.0001276
[Epoch 79; Iter   444/ 1097] train: loss: 0.0016253
[Epoch 79; Iter   474/ 1097] train: loss: 0.0008475
[Epoch 79; Iter   504/ 1097] train: loss: 0.0006277
[Epoch 79; Iter   534/ 1097] train: loss: 0.0000752
[Epoch 79; Iter   564/ 1097] train: loss: 0.0000834
[Epoch 79; Iter   594/ 1097] train: loss: 0.0008206
[Epoch 79; Iter   624/ 1097] train: loss: 0.0004672
[Epoch 79; Iter   654/ 1097] train: loss: 0.0000745
[Epoch 79; Iter   684/ 1097] train: loss: 0.0681353
[Epoch 79; Iter   714/ 1097] train: loss: 0.0008263
[Epoch 79; Iter   744/ 1097] train: loss: 0.0007192
[Epoch 79; Iter   774/ 1097] train: loss: 0.0000234
[Epoch 79; Iter   804/ 1097] train: loss: 0.0000397
[Epoch 79; Iter   834/ 1097] train: loss: 0.0008382
[Epoch 79; Iter   864/ 1097] train: loss: 0.0000949
[Epoch 79; Iter   894/ 1097] train: loss: 0.0008747
[Epoch 79; Iter   924/ 1097] train: loss: 0.0011222
[Epoch 79; Iter   954/ 1097] train: loss: 0.0000097
[Epoch 79; Iter   984/ 1097] train: loss: 0.0005366
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0000681
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0000327
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0000018
[Epoch 79] ogbg-molhiv: 0.791076 val loss: 0.224881
[Epoch 79] ogbg-molhiv: 0.722521 test loss: 0.383621
[Epoch 80; Iter     7/ 1097] train: loss: 0.0002187
[Epoch 80; Iter    37/ 1097] train: loss: 0.0027661
[Epoch 80; Iter    67/ 1097] train: loss: 0.0002353
[Epoch 80; Iter    97/ 1097] train: loss: 0.0002124
[Epoch 80; Iter   127/ 1097] train: loss: 0.0000063
[Epoch 80; Iter   157/ 1097] train: loss: 0.0000025
[Epoch 80; Iter   187/ 1097] train: loss: 0.0011223
[Epoch 80; Iter   217/ 1097] train: loss: 0.0001332
[Epoch 80; Iter   247/ 1097] train: loss: 0.0321577
[Epoch 80; Iter   277/ 1097] train: loss: 0.0000147
[Epoch 80; Iter   307/ 1097] train: loss: 0.0003054
[Epoch 80; Iter   337/ 1097] train: loss: 0.0000185
[Epoch 80; Iter   367/ 1097] train: loss: 0.0032526
[Epoch 80; Iter   397/ 1097] train: loss: 0.0199588
[Epoch 80; Iter   427/ 1097] train: loss: 0.0013319
[Epoch 80; Iter   457/ 1097] train: loss: 0.0003766
[Epoch 80; Iter   487/ 1097] train: loss: 0.0014732
[Epoch 80; Iter   517/ 1097] train: loss: 0.0001933
[Epoch 80; Iter   547/ 1097] train: loss: 0.0002406
[Epoch 80; Iter   577/ 1097] train: loss: 0.0001057
[Epoch 80; Iter   607/ 1097] train: loss: 0.0002455
[Epoch 80; Iter   637/ 1097] train: loss: 0.0000201
[Epoch 80; Iter   667/ 1097] train: loss: 0.0002361
[Epoch 80; Iter   697/ 1097] train: loss: 0.0044137
[Epoch 80; Iter   727/ 1097] train: loss: 0.0001479
[Epoch 80; Iter   757/ 1097] train: loss: 0.0000549
[Epoch 80; Iter   787/ 1097] train: loss: 0.0001669
[Epoch 80; Iter   817/ 1097] train: loss: 0.0000108
[Epoch 80; Iter   847/ 1097] train: loss: 0.0000054
[Epoch 80; Iter   877/ 1097] train: loss: 0.0001374
[Epoch 80; Iter   907/ 1097] train: loss: 0.0009798
[Epoch 80; Iter   937/ 1097] train: loss: 0.0008211
[Epoch 80; Iter   967/ 1097] train: loss: 0.0001041
[Epoch 80; Iter   997/ 1097] train: loss: 0.0000209
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0001697
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0002246
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0001319
[Epoch 80] ogbg-molhiv: 0.787809 val loss: 0.235961
[Epoch 80] ogbg-molhiv: 0.734348 test loss: 0.384994
[Epoch 81; Iter    20/ 1097] train: loss: 0.0010944
[Epoch 81; Iter    50/ 1097] train: loss: 0.0006100
[Epoch 81; Iter    80/ 1097] train: loss: 0.0024189
[Epoch 81; Iter   110/ 1097] train: loss: 0.0002261
[Epoch 81; Iter   140/ 1097] train: loss: 0.0035983
[Epoch 81; Iter   170/ 1097] train: loss: 0.0002868
[Epoch 81; Iter   200/ 1097] train: loss: 0.0003564
[Epoch 81; Iter   230/ 1097] train: loss: 0.0005064
[Epoch 81; Iter   260/ 1097] train: loss: 0.0001721
[Epoch 81; Iter   290/ 1097] train: loss: 0.0004332
[Epoch 81; Iter   320/ 1097] train: loss: 0.0000262
[Epoch 77; Iter   268/ 1097] train: loss: 0.0031605
[Epoch 77; Iter   298/ 1097] train: loss: 0.0012077
[Epoch 77; Iter   328/ 1097] train: loss: 0.0000924
[Epoch 77; Iter   358/ 1097] train: loss: 0.1109900
[Epoch 77; Iter   388/ 1097] train: loss: 0.0031508
[Epoch 77; Iter   418/ 1097] train: loss: 0.0004325
[Epoch 77; Iter   448/ 1097] train: loss: 0.0003019
[Epoch 77; Iter   478/ 1097] train: loss: 0.0001962
[Epoch 77; Iter   508/ 1097] train: loss: 0.0157605
[Epoch 77; Iter   538/ 1097] train: loss: 0.0029833
[Epoch 77; Iter   568/ 1097] train: loss: 0.0182683
[Epoch 77; Iter   598/ 1097] train: loss: 0.0025031
[Epoch 77; Iter   628/ 1097] train: loss: 0.0150531
[Epoch 77; Iter   658/ 1097] train: loss: 0.0006276
[Epoch 77; Iter   688/ 1097] train: loss: 0.0238299
[Epoch 77; Iter   718/ 1097] train: loss: 0.0479059
[Epoch 77; Iter   748/ 1097] train: loss: 0.0046496
[Epoch 77; Iter   778/ 1097] train: loss: 0.0007474
[Epoch 77; Iter   808/ 1097] train: loss: 0.0022484
[Epoch 77; Iter   838/ 1097] train: loss: 0.0174194
[Epoch 77; Iter   868/ 1097] train: loss: 0.0023107
[Epoch 77; Iter   898/ 1097] train: loss: 0.0021911
[Epoch 77; Iter   928/ 1097] train: loss: 0.0043057
[Epoch 77; Iter   958/ 1097] train: loss: 0.0018203
[Epoch 77; Iter   988/ 1097] train: loss: 0.0041787
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0295411
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0078693
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0140600
[Epoch 77] ogbg-molhiv: 0.684469 val loss: 2.978166
[Epoch 77] ogbg-molhiv: 0.711779 test loss: 1.007236
[Epoch 78; Iter    11/ 1097] train: loss: 0.0031374
[Epoch 78; Iter    41/ 1097] train: loss: 0.0006773
[Epoch 78; Iter    71/ 1097] train: loss: 0.0007697
[Epoch 78; Iter   101/ 1097] train: loss: 0.0009612
[Epoch 78; Iter   131/ 1097] train: loss: 0.0003483
[Epoch 78; Iter   161/ 1097] train: loss: 0.0028166
[Epoch 78; Iter   191/ 1097] train: loss: 0.0008619
[Epoch 78; Iter   221/ 1097] train: loss: 0.0006317
[Epoch 78; Iter   251/ 1097] train: loss: 0.0000383
[Epoch 78; Iter   281/ 1097] train: loss: 0.0013087
[Epoch 78; Iter   311/ 1097] train: loss: 0.0011220
[Epoch 78; Iter   341/ 1097] train: loss: 0.0000499
[Epoch 78; Iter   371/ 1097] train: loss: 0.0007333
[Epoch 78; Iter   401/ 1097] train: loss: 0.0005490
[Epoch 78; Iter   431/ 1097] train: loss: 0.0070798
[Epoch 78; Iter   461/ 1097] train: loss: 0.0054632
[Epoch 78; Iter   491/ 1097] train: loss: 0.0059286
[Epoch 78; Iter   521/ 1097] train: loss: 0.0105181
[Epoch 78; Iter   551/ 1097] train: loss: 0.0061678
[Epoch 78; Iter   581/ 1097] train: loss: 0.0000675
[Epoch 78; Iter   611/ 1097] train: loss: 0.0053512
[Epoch 78; Iter   641/ 1097] train: loss: 0.0009664
[Epoch 78; Iter   671/ 1097] train: loss: 0.0005479
[Epoch 78; Iter   701/ 1097] train: loss: 0.0206399
[Epoch 78; Iter   731/ 1097] train: loss: 0.0023163
[Epoch 78; Iter   761/ 1097] train: loss: 0.0007173
[Epoch 78; Iter   791/ 1097] train: loss: 0.0217755
[Epoch 78; Iter   821/ 1097] train: loss: 0.0464272
[Epoch 78; Iter   851/ 1097] train: loss: 0.0001975
[Epoch 78; Iter   881/ 1097] train: loss: 0.0036586
[Epoch 78; Iter   911/ 1097] train: loss: 0.0000780
[Epoch 78; Iter   941/ 1097] train: loss: 0.0063567
[Epoch 78; Iter   971/ 1097] train: loss: 0.0000318
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0063222
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0000679
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0024618
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0363729
[Epoch 78] ogbg-molhiv: 0.717727 val loss: 6.054540
[Epoch 78] ogbg-molhiv: 0.682665 test loss: 3.311875
[Epoch 79; Iter    24/ 1097] train: loss: 0.0014137
[Epoch 79; Iter    54/ 1097] train: loss: 0.0109191
[Epoch 79; Iter    84/ 1097] train: loss: 0.0134329
[Epoch 79; Iter   114/ 1097] train: loss: 0.0004710
[Epoch 79; Iter   144/ 1097] train: loss: 0.0015643
[Epoch 79; Iter   174/ 1097] train: loss: 0.0015054
[Epoch 79; Iter   204/ 1097] train: loss: 0.0467827
[Epoch 79; Iter   234/ 1097] train: loss: 0.0251463
[Epoch 79; Iter   264/ 1097] train: loss: 0.0002886
[Epoch 79; Iter   294/ 1097] train: loss: 0.0001025
[Epoch 79; Iter   324/ 1097] train: loss: 0.0047168
[Epoch 79; Iter   354/ 1097] train: loss: 0.0017167
[Epoch 79; Iter   384/ 1097] train: loss: 0.0009735
[Epoch 79; Iter   414/ 1097] train: loss: 0.0000150
[Epoch 79; Iter   444/ 1097] train: loss: 0.0009031
[Epoch 79; Iter   474/ 1097] train: loss: 0.0000702
[Epoch 79; Iter   504/ 1097] train: loss: 0.0001850
[Epoch 79; Iter   534/ 1097] train: loss: 0.0029433
[Epoch 79; Iter   564/ 1097] train: loss: 0.0004940
[Epoch 79; Iter   594/ 1097] train: loss: 0.0797183
[Epoch 79; Iter   624/ 1097] train: loss: 0.0791405
[Epoch 79; Iter   654/ 1097] train: loss: 0.0082360
[Epoch 79; Iter   684/ 1097] train: loss: 0.1532156
[Epoch 79; Iter   714/ 1097] train: loss: 0.0026415
[Epoch 79; Iter   744/ 1097] train: loss: 0.0353601
[Epoch 79; Iter   774/ 1097] train: loss: 0.0936120
[Epoch 79; Iter   804/ 1097] train: loss: 0.0005950
[Epoch 79; Iter   834/ 1097] train: loss: 0.0004336
[Epoch 79; Iter   864/ 1097] train: loss: 0.0063335
[Epoch 79; Iter   894/ 1097] train: loss: 0.0024186
[Epoch 79; Iter   924/ 1097] train: loss: 0.0002328
[Epoch 79; Iter   954/ 1097] train: loss: 0.0001342
[Epoch 79; Iter   984/ 1097] train: loss: 0.0001323
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0000551
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0000563
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0008417
[Epoch 79] ogbg-molhiv: 0.692114 val loss: 4.927554
[Epoch 79] ogbg-molhiv: 0.689859 test loss: 1.081251
[Epoch 80; Iter     7/ 1097] train: loss: 0.0027639
[Epoch 80; Iter    37/ 1097] train: loss: 0.0000309
[Epoch 80; Iter    67/ 1097] train: loss: 0.0007252
[Epoch 80; Iter    97/ 1097] train: loss: 0.0033380
[Epoch 80; Iter   127/ 1097] train: loss: 0.0010469
[Epoch 80; Iter   157/ 1097] train: loss: 0.0003688
[Epoch 80; Iter   187/ 1097] train: loss: 0.0060955
[Epoch 80; Iter   217/ 1097] train: loss: 0.0002191
[Epoch 80; Iter   247/ 1097] train: loss: 0.0012816
[Epoch 80; Iter   277/ 1097] train: loss: 0.0005556
[Epoch 80; Iter   307/ 1097] train: loss: 0.0000984
[Epoch 80; Iter   337/ 1097] train: loss: 0.0012534
[Epoch 80; Iter   367/ 1097] train: loss: 0.0001657
[Epoch 80; Iter   397/ 1097] train: loss: 0.0006114
[Epoch 80; Iter   427/ 1097] train: loss: 0.0000625
[Epoch 80; Iter   457/ 1097] train: loss: 0.0020967
[Epoch 80; Iter   487/ 1097] train: loss: 0.0000840
[Epoch 80; Iter   517/ 1097] train: loss: 0.0078358
[Epoch 80; Iter   547/ 1097] train: loss: 0.0080077
[Epoch 80; Iter   577/ 1097] train: loss: 0.0004247
[Epoch 80; Iter   607/ 1097] train: loss: 0.0011015
[Epoch 80; Iter   637/ 1097] train: loss: 0.0182518
[Epoch 80; Iter   667/ 1097] train: loss: 0.0006500
[Epoch 80; Iter   697/ 1097] train: loss: 0.0064951
[Epoch 80; Iter   727/ 1097] train: loss: 0.0238607
[Epoch 80; Iter   757/ 1097] train: loss: 0.0640053
[Epoch 80; Iter   787/ 1097] train: loss: 0.0013248
[Epoch 80; Iter   817/ 1097] train: loss: 0.0002397
[Epoch 80; Iter   847/ 1097] train: loss: 0.0003027
[Epoch 80; Iter   877/ 1097] train: loss: 0.0592644
[Epoch 80; Iter   907/ 1097] train: loss: 0.0006417
[Epoch 80; Iter   937/ 1097] train: loss: 0.0546896
[Epoch 80; Iter   967/ 1097] train: loss: 0.0138960
[Epoch 80; Iter   997/ 1097] train: loss: 0.0010661
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0091369
[Epoch 80; Iter  1057/ 1097] train: loss: 0.1222817
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0022132
[Epoch 80] ogbg-molhiv: 0.687573 val loss: 3.625184
[Epoch 80] ogbg-molhiv: 0.674061 test loss: 2.401982
[Epoch 81; Iter    20/ 1097] train: loss: 0.0123310
[Epoch 81; Iter    50/ 1097] train: loss: 0.0001374
[Epoch 81; Iter    80/ 1097] train: loss: 0.0063722
[Epoch 81; Iter   110/ 1097] train: loss: 0.0006019
[Epoch 81; Iter   140/ 1097] train: loss: 0.0015158
[Epoch 81; Iter   170/ 1097] train: loss: 0.0059081
[Epoch 81; Iter   200/ 1097] train: loss: 0.0001141
[Epoch 81; Iter   230/ 1097] train: loss: 0.0002862
[Epoch 81; Iter   260/ 1097] train: loss: 0.0079838
[Epoch 81; Iter   290/ 1097] train: loss: 0.0090126
[Epoch 81; Iter   320/ 1097] train: loss: 0.0052559
[Epoch 77; Iter   268/ 1097] train: loss: 0.0001358
[Epoch 77; Iter   298/ 1097] train: loss: 0.0003898
[Epoch 77; Iter   328/ 1097] train: loss: 0.0006818
[Epoch 77; Iter   358/ 1097] train: loss: 0.0071961
[Epoch 77; Iter   388/ 1097] train: loss: 0.0009871
[Epoch 77; Iter   418/ 1097] train: loss: 0.0015536
[Epoch 77; Iter   448/ 1097] train: loss: 0.0000619
[Epoch 77; Iter   478/ 1097] train: loss: 0.0000897
[Epoch 77; Iter   508/ 1097] train: loss: 0.0010559
[Epoch 77; Iter   538/ 1097] train: loss: 0.0166087
[Epoch 77; Iter   568/ 1097] train: loss: 0.0030423
[Epoch 77; Iter   598/ 1097] train: loss: 0.0008149
[Epoch 77; Iter   628/ 1097] train: loss: 0.0036366
[Epoch 77; Iter   658/ 1097] train: loss: 0.0195866
[Epoch 77; Iter   688/ 1097] train: loss: 0.0000252
[Epoch 77; Iter   718/ 1097] train: loss: 0.0002862
[Epoch 77; Iter   748/ 1097] train: loss: 0.0135488
[Epoch 77; Iter   778/ 1097] train: loss: 0.0001911
[Epoch 77; Iter   808/ 1097] train: loss: 0.0001747
[Epoch 77; Iter   838/ 1097] train: loss: 0.0015194
[Epoch 77; Iter   868/ 1097] train: loss: 0.0006359
[Epoch 77; Iter   898/ 1097] train: loss: 0.0018253
[Epoch 77; Iter   928/ 1097] train: loss: 0.0005386
[Epoch 77; Iter   958/ 1097] train: loss: 0.0000152
[Epoch 77; Iter   988/ 1097] train: loss: 0.0000691
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0005707
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0000547
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0001183
[Epoch 77] ogbg-molhiv: 0.754489 val loss: 0.321725
[Epoch 77] ogbg-molhiv: 0.739800 test loss: 0.357904
[Epoch 78; Iter    11/ 1097] train: loss: 0.0001752
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000314
[Epoch 78; Iter    71/ 1097] train: loss: 0.0000390
[Epoch 78; Iter   101/ 1097] train: loss: 0.0000214
[Epoch 78; Iter   131/ 1097] train: loss: 0.0002674
[Epoch 78; Iter   161/ 1097] train: loss: 0.0004294
[Epoch 78; Iter   191/ 1097] train: loss: 0.0042062
[Epoch 78; Iter   221/ 1097] train: loss: 0.0105504
[Epoch 78; Iter   251/ 1097] train: loss: 0.0165170
[Epoch 78; Iter   281/ 1097] train: loss: 0.0007830
[Epoch 78; Iter   311/ 1097] train: loss: 0.0001841
[Epoch 78; Iter   341/ 1097] train: loss: 0.0000428
[Epoch 78; Iter   371/ 1097] train: loss: 0.0011661
[Epoch 78; Iter   401/ 1097] train: loss: 0.0000602
[Epoch 78; Iter   431/ 1097] train: loss: 0.0000477
[Epoch 78; Iter   461/ 1097] train: loss: 0.0115069
[Epoch 78; Iter   491/ 1097] train: loss: 0.0031650
[Epoch 78; Iter   521/ 1097] train: loss: 0.0014972
[Epoch 78; Iter   551/ 1097] train: loss: 0.0103539
[Epoch 78; Iter   581/ 1097] train: loss: 0.0000110
[Epoch 78; Iter   611/ 1097] train: loss: 0.0026378
[Epoch 78; Iter   641/ 1097] train: loss: 0.0038660
[Epoch 78; Iter   671/ 1097] train: loss: 0.0024785
[Epoch 78; Iter   701/ 1097] train: loss: 0.0004559
[Epoch 78; Iter   731/ 1097] train: loss: 0.0014104
[Epoch 78; Iter   761/ 1097] train: loss: 0.0000265
[Epoch 78; Iter   791/ 1097] train: loss: 0.0001151
[Epoch 78; Iter   821/ 1097] train: loss: 0.0000161
[Epoch 78; Iter   851/ 1097] train: loss: 0.0027467
[Epoch 78; Iter   881/ 1097] train: loss: 0.0001994
[Epoch 78; Iter   911/ 1097] train: loss: 0.0003521
[Epoch 78; Iter   941/ 1097] train: loss: 0.0000831
[Epoch 78; Iter   971/ 1097] train: loss: 0.0013393
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0042385
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0001455
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0002222
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0000641
[Epoch 78] ogbg-molhiv: 0.746476 val loss: 0.328294
[Epoch 78] ogbg-molhiv: 0.738174 test loss: 0.358806
[Epoch 79; Iter    24/ 1097] train: loss: 0.0039006
[Epoch 79; Iter    54/ 1097] train: loss: 0.0007221
[Epoch 79; Iter    84/ 1097] train: loss: 0.0000251
[Epoch 79; Iter   114/ 1097] train: loss: 0.0014762
[Epoch 79; Iter   144/ 1097] train: loss: 0.0000028
[Epoch 79; Iter   174/ 1097] train: loss: 0.0000354
[Epoch 79; Iter   204/ 1097] train: loss: 0.0006739
[Epoch 79; Iter   234/ 1097] train: loss: 0.0000776
[Epoch 79; Iter   264/ 1097] train: loss: 0.0005764
[Epoch 79; Iter   294/ 1097] train: loss: 0.0000134
[Epoch 79; Iter   324/ 1097] train: loss: 0.0019733
[Epoch 79; Iter   354/ 1097] train: loss: 0.0013100
[Epoch 79; Iter   384/ 1097] train: loss: 0.0001095
[Epoch 79; Iter   414/ 1097] train: loss: 0.0002451
[Epoch 79; Iter   444/ 1097] train: loss: 0.0000231
[Epoch 79; Iter   474/ 1097] train: loss: 0.0038990
[Epoch 79; Iter   504/ 1097] train: loss: 0.0000399
[Epoch 79; Iter   534/ 1097] train: loss: 0.0007193
[Epoch 79; Iter   564/ 1097] train: loss: 0.0002431
[Epoch 79; Iter   594/ 1097] train: loss: 0.0000207
[Epoch 79; Iter   624/ 1097] train: loss: 0.0008599
[Epoch 79; Iter   654/ 1097] train: loss: 0.0041036
[Epoch 79; Iter   684/ 1097] train: loss: 0.0000952
[Epoch 79; Iter   714/ 1097] train: loss: 0.0003774
[Epoch 79; Iter   744/ 1097] train: loss: 0.0011374
[Epoch 79; Iter   774/ 1097] train: loss: 0.0009642
[Epoch 79; Iter   804/ 1097] train: loss: 0.0000690
[Epoch 79; Iter   834/ 1097] train: loss: 0.0002409
[Epoch 79; Iter   864/ 1097] train: loss: 0.0000573
[Epoch 79; Iter   894/ 1097] train: loss: 0.0001947
[Epoch 79; Iter   924/ 1097] train: loss: 0.0013972
[Epoch 79; Iter   954/ 1097] train: loss: 0.0000251
[Epoch 79; Iter   984/ 1097] train: loss: 0.0000671
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0289338
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0003564
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0000158
[Epoch 79] ogbg-molhiv: 0.760374 val loss: 0.344345
[Epoch 79] ogbg-molhiv: 0.731414 test loss: 0.413308
[Epoch 80; Iter     7/ 1097] train: loss: 0.0000233
[Epoch 80; Iter    37/ 1097] train: loss: 0.0005929
[Epoch 80; Iter    67/ 1097] train: loss: 0.0000147
[Epoch 80; Iter    97/ 1097] train: loss: 0.0000132
[Epoch 80; Iter   127/ 1097] train: loss: 0.0007491
[Epoch 80; Iter   157/ 1097] train: loss: 0.0000789
[Epoch 80; Iter   187/ 1097] train: loss: 0.0130734
[Epoch 80; Iter   217/ 1097] train: loss: 0.0000601
[Epoch 80; Iter   247/ 1097] train: loss: 0.0000791
[Epoch 80; Iter   277/ 1097] train: loss: 0.0011803
[Epoch 80; Iter   307/ 1097] train: loss: 0.0003174
[Epoch 80; Iter   337/ 1097] train: loss: 0.0000933
[Epoch 80; Iter   367/ 1097] train: loss: 0.0009239
[Epoch 80; Iter   397/ 1097] train: loss: 0.0002005
[Epoch 80; Iter   427/ 1097] train: loss: 0.0000897
[Epoch 80; Iter   457/ 1097] train: loss: 0.0000182
[Epoch 80; Iter   487/ 1097] train: loss: 0.0004851
[Epoch 80; Iter   517/ 1097] train: loss: 0.0001526
[Epoch 80; Iter   547/ 1097] train: loss: 0.0983433
[Epoch 80; Iter   577/ 1097] train: loss: 0.0000075
[Epoch 80; Iter   607/ 1097] train: loss: 0.0001448
[Epoch 80; Iter   637/ 1097] train: loss: 0.0001489
[Epoch 80; Iter   667/ 1097] train: loss: 0.0007717
[Epoch 80; Iter   697/ 1097] train: loss: 0.0027405
[Epoch 80; Iter   727/ 1097] train: loss: 0.0063539
[Epoch 80; Iter   757/ 1097] train: loss: 0.0099090
[Epoch 80; Iter   787/ 1097] train: loss: 0.0012221
[Epoch 80; Iter   817/ 1097] train: loss: 0.0000352
[Epoch 80; Iter   847/ 1097] train: loss: 0.0036637
[Epoch 80; Iter   877/ 1097] train: loss: 0.0007944
[Epoch 80; Iter   907/ 1097] train: loss: 0.0001348
[Epoch 80; Iter   937/ 1097] train: loss: 0.0000954
[Epoch 80; Iter   967/ 1097] train: loss: 0.0005608
[Epoch 80; Iter   997/ 1097] train: loss: 0.0004823
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0056054
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0000587
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0159734
[Epoch 80] ogbg-molhiv: 0.774753 val loss: 0.386081
[Epoch 80] ogbg-molhiv: 0.772852 test loss: 0.376680
[Epoch 81; Iter    20/ 1097] train: loss: 0.0062130
[Epoch 81; Iter    50/ 1097] train: loss: 0.0015120
[Epoch 81; Iter    80/ 1097] train: loss: 0.0003531
[Epoch 81; Iter   110/ 1097] train: loss: 0.0000092
[Epoch 81; Iter   140/ 1097] train: loss: 0.0004771
[Epoch 81; Iter   170/ 1097] train: loss: 0.0004362
[Epoch 81; Iter   200/ 1097] train: loss: 0.0005188
[Epoch 81; Iter   230/ 1097] train: loss: 0.0000576
[Epoch 81; Iter   260/ 1097] train: loss: 0.0011448
[Epoch 81; Iter   290/ 1097] train: loss: 0.0000119
[Epoch 81; Iter   320/ 1097] train: loss: 0.0000312
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0033583
[Epoch 60] ogbg-molhiv: 0.798816 val loss: 0.132988
[Epoch 60] ogbg-molhiv: 0.731833 test loss: 0.242445
[Epoch 61; Iter    30/ 1097] train: loss: 0.0202427
[Epoch 61; Iter    60/ 1097] train: loss: 0.0135612
[Epoch 61; Iter    90/ 1097] train: loss: 0.0135602
[Epoch 61; Iter   120/ 1097] train: loss: 0.0296779
[Epoch 61; Iter   150/ 1097] train: loss: 0.0460046
[Epoch 61; Iter   180/ 1097] train: loss: 0.0043417
[Epoch 61; Iter   210/ 1097] train: loss: 0.2182981
[Epoch 61; Iter   240/ 1097] train: loss: 0.0981213
[Epoch 61; Iter   270/ 1097] train: loss: 0.0184443
[Epoch 61; Iter   300/ 1097] train: loss: 0.0360953
[Epoch 61; Iter   330/ 1097] train: loss: 0.0115127
[Epoch 61; Iter   360/ 1097] train: loss: 0.0103139
[Epoch 61; Iter   390/ 1097] train: loss: 0.0065352
[Epoch 61; Iter   420/ 1097] train: loss: 0.0098289
[Epoch 61; Iter   450/ 1097] train: loss: 0.0045699
[Epoch 61; Iter   480/ 1097] train: loss: 0.0169085
[Epoch 61; Iter   510/ 1097] train: loss: 0.0091509
[Epoch 61; Iter   540/ 1097] train: loss: 0.0411532
[Epoch 61; Iter   570/ 1097] train: loss: 0.0334456
[Epoch 61; Iter   600/ 1097] train: loss: 0.0081097
[Epoch 61; Iter   630/ 1097] train: loss: 0.0360017
[Epoch 61; Iter   660/ 1097] train: loss: 0.0197788
[Epoch 61; Iter   690/ 1097] train: loss: 0.2918943
[Epoch 61; Iter   720/ 1097] train: loss: 0.0244472
[Epoch 61; Iter   750/ 1097] train: loss: 0.0089264
[Epoch 61; Iter   780/ 1097] train: loss: 0.0229105
[Epoch 61; Iter   810/ 1097] train: loss: 0.0353153
[Epoch 61; Iter   840/ 1097] train: loss: 0.0397372
[Epoch 61; Iter   870/ 1097] train: loss: 0.0069652
[Epoch 61; Iter   900/ 1097] train: loss: 0.0804639
[Epoch 61; Iter   930/ 1097] train: loss: 0.0478716
[Epoch 61; Iter   960/ 1097] train: loss: 0.0040126
[Epoch 61; Iter   990/ 1097] train: loss: 0.0118967
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0082943
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0349387
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0813758
[Epoch 61] ogbg-molhiv: 0.808651 val loss: 0.101841
[Epoch 61] ogbg-molhiv: 0.736173 test loss: 0.240962
[Epoch 62; Iter    13/ 1097] train: loss: 0.0055697
[Epoch 62; Iter    43/ 1097] train: loss: 0.0078200
[Epoch 62; Iter    73/ 1097] train: loss: 0.0156952
[Epoch 62; Iter   103/ 1097] train: loss: 0.0102293
[Epoch 62; Iter   133/ 1097] train: loss: 0.2450817
[Epoch 62; Iter   163/ 1097] train: loss: 0.0518022
[Epoch 62; Iter   193/ 1097] train: loss: 0.0053824
[Epoch 62; Iter   223/ 1097] train: loss: 0.1771978
[Epoch 62; Iter   253/ 1097] train: loss: 0.0415663
[Epoch 62; Iter   283/ 1097] train: loss: 0.0055148
[Epoch 62; Iter   313/ 1097] train: loss: 0.1588232
[Epoch 62; Iter   343/ 1097] train: loss: 0.0103801
[Epoch 62; Iter   373/ 1097] train: loss: 0.0264571
[Epoch 62; Iter   403/ 1097] train: loss: 0.0132380
[Epoch 62; Iter   433/ 1097] train: loss: 0.0100907
[Epoch 62; Iter   463/ 1097] train: loss: 0.0361064
[Epoch 62; Iter   493/ 1097] train: loss: 0.0013112
[Epoch 62; Iter   523/ 1097] train: loss: 0.0109094
[Epoch 62; Iter   553/ 1097] train: loss: 0.0073031
[Epoch 62; Iter   583/ 1097] train: loss: 0.0219709
[Epoch 62; Iter   613/ 1097] train: loss: 0.0063735
[Epoch 62; Iter   643/ 1097] train: loss: 0.0432700
[Epoch 62; Iter   673/ 1097] train: loss: 0.0067804
[Epoch 62; Iter   703/ 1097] train: loss: 0.0056516
[Epoch 62; Iter   733/ 1097] train: loss: 0.0139714
[Epoch 62; Iter   763/ 1097] train: loss: 0.0289576
[Epoch 62; Iter   793/ 1097] train: loss: 0.1348196
[Epoch 62; Iter   823/ 1097] train: loss: 0.0108134
[Epoch 62; Iter   853/ 1097] train: loss: 0.0095531
[Epoch 62; Iter   883/ 1097] train: loss: 0.0648230
[Epoch 62; Iter   913/ 1097] train: loss: 0.0042599
[Epoch 62; Iter   943/ 1097] train: loss: 0.0054225
[Epoch 62; Iter   973/ 1097] train: loss: 0.0038212
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0383248
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0719529
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0203756
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0024077
[Epoch 62] ogbg-molhiv: 0.805142 val loss: 0.109736
[Epoch 62] ogbg-molhiv: 0.748877 test loss: 0.215618
[Epoch 63; Iter    26/ 1097] train: loss: 0.0108894
[Epoch 63; Iter    56/ 1097] train: loss: 0.0350737
[Epoch 63; Iter    86/ 1097] train: loss: 0.0327827
[Epoch 63; Iter   116/ 1097] train: loss: 0.0114062
[Epoch 63; Iter   146/ 1097] train: loss: 0.0194956
[Epoch 63; Iter   176/ 1097] train: loss: 0.0060520
[Epoch 63; Iter   206/ 1097] train: loss: 0.0914566
[Epoch 63; Iter   236/ 1097] train: loss: 0.0039256
[Epoch 63; Iter   266/ 1097] train: loss: 0.0125201
[Epoch 63; Iter   296/ 1097] train: loss: 0.0533192
[Epoch 63; Iter   326/ 1097] train: loss: 0.0346843
[Epoch 63; Iter   356/ 1097] train: loss: 0.1215486
[Epoch 63; Iter   386/ 1097] train: loss: 0.0121797
[Epoch 63; Iter   416/ 1097] train: loss: 0.0994859
[Epoch 63; Iter   446/ 1097] train: loss: 0.0106070
[Epoch 63; Iter   476/ 1097] train: loss: 0.0161367
[Epoch 63; Iter   506/ 1097] train: loss: 0.0363568
[Epoch 63; Iter   536/ 1097] train: loss: 0.1064385
[Epoch 63; Iter   566/ 1097] train: loss: 0.0060167
[Epoch 63; Iter   596/ 1097] train: loss: 0.0451881
[Epoch 63; Iter   626/ 1097] train: loss: 0.0153689
[Epoch 63; Iter   656/ 1097] train: loss: 0.0056941
[Epoch 63; Iter   686/ 1097] train: loss: 0.0038761
[Epoch 63; Iter   716/ 1097] train: loss: 0.0160876
[Epoch 63; Iter   746/ 1097] train: loss: 0.0059984
[Epoch 63; Iter   776/ 1097] train: loss: 0.0660579
[Epoch 63; Iter   806/ 1097] train: loss: 0.0184847
[Epoch 63; Iter   836/ 1097] train: loss: 0.0323970
[Epoch 63; Iter   866/ 1097] train: loss: 0.0333733
[Epoch 63; Iter   896/ 1097] train: loss: 0.2155597
[Epoch 63; Iter   926/ 1097] train: loss: 0.0588928
[Epoch 63; Iter   956/ 1097] train: loss: 0.0413407
[Epoch 63; Iter   986/ 1097] train: loss: 0.0333316
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0071167
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0086769
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0030440
[Epoch 63] ogbg-molhiv: 0.801774 val loss: 0.102567
[Epoch 63] ogbg-molhiv: 0.741167 test loss: 0.215800
[Epoch 64; Iter     9/ 1097] train: loss: 0.1147940
[Epoch 64; Iter    39/ 1097] train: loss: 0.0385983
[Epoch 64; Iter    69/ 1097] train: loss: 0.0892491
[Epoch 64; Iter    99/ 1097] train: loss: 0.0169456
[Epoch 64; Iter   129/ 1097] train: loss: 0.0270704
[Epoch 64; Iter   159/ 1097] train: loss: 0.0484061
[Epoch 64; Iter   189/ 1097] train: loss: 0.0346258
[Epoch 64; Iter   219/ 1097] train: loss: 0.0154413
[Epoch 64; Iter   249/ 1097] train: loss: 0.0088237
[Epoch 64; Iter   279/ 1097] train: loss: 0.0177144
[Epoch 64; Iter   309/ 1097] train: loss: 0.0334660
[Epoch 64; Iter   339/ 1097] train: loss: 0.0157750
[Epoch 64; Iter   369/ 1097] train: loss: 0.0105129
[Epoch 64; Iter   399/ 1097] train: loss: 0.0054931
[Epoch 64; Iter   429/ 1097] train: loss: 0.0342935
[Epoch 64; Iter   459/ 1097] train: loss: 0.0122892
[Epoch 64; Iter   489/ 1097] train: loss: 0.0407635
[Epoch 64; Iter   519/ 1097] train: loss: 0.1368458
[Epoch 64; Iter   549/ 1097] train: loss: 0.0105940
[Epoch 64; Iter   579/ 1097] train: loss: 0.0451788
[Epoch 64; Iter   609/ 1097] train: loss: 0.0211222
[Epoch 64; Iter   639/ 1097] train: loss: 0.0315023
[Epoch 64; Iter   669/ 1097] train: loss: 0.0601521
[Epoch 64; Iter   699/ 1097] train: loss: 0.1431806
[Epoch 64; Iter   729/ 1097] train: loss: 0.1716386
[Epoch 64; Iter   759/ 1097] train: loss: 0.0494299
[Epoch 64; Iter   789/ 1097] train: loss: 0.0529656
[Epoch 64; Iter   819/ 1097] train: loss: 0.0183109
[Epoch 64; Iter   849/ 1097] train: loss: 0.0016849
[Epoch 64; Iter   879/ 1097] train: loss: 0.0041575
[Epoch 64; Iter   909/ 1097] train: loss: 0.0077570
[Epoch 64; Iter   939/ 1097] train: loss: 0.0075323
[Epoch 64; Iter   969/ 1097] train: loss: 0.0982077
[Epoch 64; Iter   999/ 1097] train: loss: 0.0650004
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0870287
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0296404
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0744698
[Epoch 64] ogbg-molhiv: 0.797481 val loss: 0.113954
[Epoch 64] ogbg-molhiv: 0.745974 test loss: 0.213962
[Epoch 77; Iter   268/ 1097] train: loss: 0.0001291
[Epoch 77; Iter   298/ 1097] train: loss: 0.0001109
[Epoch 77; Iter   328/ 1097] train: loss: 0.0001052
[Epoch 77; Iter   358/ 1097] train: loss: 0.0005763
[Epoch 77; Iter   388/ 1097] train: loss: 0.0000157
[Epoch 77; Iter   418/ 1097] train: loss: 0.0001160
[Epoch 77; Iter   448/ 1097] train: loss: 0.0044193
[Epoch 77; Iter   478/ 1097] train: loss: 0.0004633
[Epoch 77; Iter   508/ 1097] train: loss: 0.0006403
[Epoch 77; Iter   538/ 1097] train: loss: 0.0005111
[Epoch 77; Iter   568/ 1097] train: loss: 0.0015736
[Epoch 77; Iter   598/ 1097] train: loss: 0.0053734
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000612
[Epoch 77; Iter   658/ 1097] train: loss: 0.0124134
[Epoch 77; Iter   688/ 1097] train: loss: 0.0023123
[Epoch 77; Iter   718/ 1097] train: loss: 0.0000810
[Epoch 77; Iter   748/ 1097] train: loss: 0.0030775
[Epoch 77; Iter   778/ 1097] train: loss: 0.0026944
[Epoch 77; Iter   808/ 1097] train: loss: 0.0000262
[Epoch 77; Iter   838/ 1097] train: loss: 0.0001927
[Epoch 77; Iter   868/ 1097] train: loss: 0.0001239
[Epoch 77; Iter   898/ 1097] train: loss: 0.0003427
[Epoch 77; Iter   928/ 1097] train: loss: 0.0010371
[Epoch 77; Iter   958/ 1097] train: loss: 0.0001912
[Epoch 77; Iter   988/ 1097] train: loss: 0.1086548
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0039696
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0013925
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0001107
[Epoch 77] ogbg-molhiv: 0.787790 val loss: 0.400229
[Epoch 77] ogbg-molhiv: 0.784115 test loss: 0.324947
[Epoch 78; Iter    11/ 1097] train: loss: 0.0000460
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000385
[Epoch 78; Iter    71/ 1097] train: loss: 0.0000242
[Epoch 78; Iter   101/ 1097] train: loss: 0.0000981
[Epoch 78; Iter   131/ 1097] train: loss: 0.0000774
[Epoch 78; Iter   161/ 1097] train: loss: 0.0000920
[Epoch 78; Iter   191/ 1097] train: loss: 0.0005029
[Epoch 78; Iter   221/ 1097] train: loss: 0.0006093
[Epoch 78; Iter   251/ 1097] train: loss: 0.0000032
[Epoch 78; Iter   281/ 1097] train: loss: 0.0002357
[Epoch 78; Iter   311/ 1097] train: loss: 0.0000058
[Epoch 78; Iter   341/ 1097] train: loss: 0.0002719
[Epoch 78; Iter   371/ 1097] train: loss: 0.0040220
[Epoch 78; Iter   401/ 1097] train: loss: 0.0001621
[Epoch 78; Iter   431/ 1097] train: loss: 0.0003603
[Epoch 78; Iter   461/ 1097] train: loss: 0.0000054
[Epoch 78; Iter   491/ 1097] train: loss: 0.0000970
[Epoch 78; Iter   521/ 1097] train: loss: 0.0014066
[Epoch 78; Iter   551/ 1097] train: loss: 0.0001525
[Epoch 78; Iter   581/ 1097] train: loss: 0.0026106
[Epoch 78; Iter   611/ 1097] train: loss: 0.0000594
[Epoch 78; Iter   641/ 1097] train: loss: 0.0000028
[Epoch 78; Iter   671/ 1097] train: loss: 0.0003258
[Epoch 78; Iter   701/ 1097] train: loss: 0.0001276
[Epoch 78; Iter   731/ 1097] train: loss: 0.0005312
[Epoch 78; Iter   761/ 1097] train: loss: 0.0001496
[Epoch 78; Iter   791/ 1097] train: loss: 0.0004248
[Epoch 78; Iter   821/ 1097] train: loss: 0.0002025
[Epoch 78; Iter   851/ 1097] train: loss: 0.0117653
[Epoch 78; Iter   881/ 1097] train: loss: 0.0001832
[Epoch 78; Iter   911/ 1097] train: loss: 0.0002977
[Epoch 78; Iter   941/ 1097] train: loss: 0.0000279
[Epoch 78; Iter   971/ 1097] train: loss: 0.0002769
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0000335
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0087872
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0001109
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0000150
[Epoch 78] ogbg-molhiv: 0.759020 val loss: 0.371079
[Epoch 78] ogbg-molhiv: 0.754754 test loss: 0.367975
[Epoch 79; Iter    24/ 1097] train: loss: 0.0084039
[Epoch 79; Iter    54/ 1097] train: loss: 0.0029046
[Epoch 79; Iter    84/ 1097] train: loss: 0.0001250
[Epoch 79; Iter   114/ 1097] train: loss: 0.0000521
[Epoch 79; Iter   144/ 1097] train: loss: 0.0005052
[Epoch 79; Iter   174/ 1097] train: loss: 0.0074161
[Epoch 79; Iter   204/ 1097] train: loss: 0.0006805
[Epoch 79; Iter   234/ 1097] train: loss: 0.0001796
[Epoch 79; Iter   264/ 1097] train: loss: 0.0001131
[Epoch 79; Iter   294/ 1097] train: loss: 0.0009727
[Epoch 79; Iter   324/ 1097] train: loss: 0.0000014
[Epoch 79; Iter   354/ 1097] train: loss: 0.0000947
[Epoch 79; Iter   384/ 1097] train: loss: 0.0057735
[Epoch 79; Iter   414/ 1097] train: loss: 0.0000988
[Epoch 79; Iter   444/ 1097] train: loss: 0.0001338
[Epoch 79; Iter   474/ 1097] train: loss: 0.0003085
[Epoch 79; Iter   504/ 1097] train: loss: 0.0002190
[Epoch 79; Iter   534/ 1097] train: loss: 0.0000188
[Epoch 79; Iter   564/ 1097] train: loss: 0.0000288
[Epoch 79; Iter   594/ 1097] train: loss: 0.0000847
[Epoch 79; Iter   624/ 1097] train: loss: 0.0002187
[Epoch 79; Iter   654/ 1097] train: loss: 0.0000473
[Epoch 79; Iter   684/ 1097] train: loss: 0.0008643
[Epoch 79; Iter   714/ 1097] train: loss: 0.0046335
[Epoch 79; Iter   744/ 1097] train: loss: 0.0000037
[Epoch 79; Iter   774/ 1097] train: loss: 0.0000176
[Epoch 79; Iter   804/ 1097] train: loss: 0.0000634
[Epoch 79; Iter   834/ 1097] train: loss: 0.0004328
[Epoch 79; Iter   864/ 1097] train: loss: 0.0002348
[Epoch 79; Iter   894/ 1097] train: loss: 0.0000101
[Epoch 79; Iter   924/ 1097] train: loss: 0.0000125
[Epoch 79; Iter   954/ 1097] train: loss: 0.0000359
[Epoch 79; Iter   984/ 1097] train: loss: 0.0134584
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0002368
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0202072
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0001144
[Epoch 79] ogbg-molhiv: 0.787389 val loss: 0.437162
[Epoch 79] ogbg-molhiv: 0.785069 test loss: 0.334732
[Epoch 80; Iter     7/ 1097] train: loss: 0.0010341
[Epoch 80; Iter    37/ 1097] train: loss: 0.0001910
[Epoch 80; Iter    67/ 1097] train: loss: 0.0001984
[Epoch 80; Iter    97/ 1097] train: loss: 0.0009361
[Epoch 80; Iter   127/ 1097] train: loss: 0.0002361
[Epoch 80; Iter   157/ 1097] train: loss: 0.0000308
[Epoch 80; Iter   187/ 1097] train: loss: 0.0004196
[Epoch 80; Iter   217/ 1097] train: loss: 0.0087743
[Epoch 80; Iter   247/ 1097] train: loss: 0.0002601
[Epoch 80; Iter   277/ 1097] train: loss: 0.0005790
[Epoch 80; Iter   307/ 1097] train: loss: 0.0001551
[Epoch 80; Iter   337/ 1097] train: loss: 0.0001417
[Epoch 80; Iter   367/ 1097] train: loss: 0.0001872
[Epoch 80; Iter   397/ 1097] train: loss: 0.0046193
[Epoch 80; Iter   427/ 1097] train: loss: 0.0004885
[Epoch 80; Iter   457/ 1097] train: loss: 0.0003178
[Epoch 80; Iter   487/ 1097] train: loss: 0.0000167
[Epoch 80; Iter   517/ 1097] train: loss: 0.0001746
[Epoch 80; Iter   547/ 1097] train: loss: 0.0001259
[Epoch 80; Iter   577/ 1097] train: loss: 0.0000340
[Epoch 80; Iter   607/ 1097] train: loss: 0.0000099
[Epoch 80; Iter   637/ 1097] train: loss: 0.0092990
[Epoch 80; Iter   667/ 1097] train: loss: 0.0001106
[Epoch 80; Iter   697/ 1097] train: loss: 0.0029084
[Epoch 80; Iter   727/ 1097] train: loss: 0.0056487
[Epoch 80; Iter   757/ 1097] train: loss: 0.0017219
[Epoch 80; Iter   787/ 1097] train: loss: 0.0000089
[Epoch 80; Iter   817/ 1097] train: loss: 0.0013461
[Epoch 80; Iter   847/ 1097] train: loss: 0.0000120
[Epoch 80; Iter   877/ 1097] train: loss: 0.0000335
[Epoch 80; Iter   907/ 1097] train: loss: 0.0000976
[Epoch 80; Iter   937/ 1097] train: loss: 0.0000195
[Epoch 80; Iter   967/ 1097] train: loss: 0.0000306
[Epoch 80; Iter   997/ 1097] train: loss: 0.0000891
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0632725
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0000649
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0005073
[Epoch 80] ogbg-molhiv: 0.767505 val loss: 0.347581
[Epoch 80] ogbg-molhiv: 0.791145 test loss: 0.347084
[Epoch 81; Iter    20/ 1097] train: loss: 0.0003849
[Epoch 81; Iter    50/ 1097] train: loss: 0.0040865
[Epoch 81; Iter    80/ 1097] train: loss: 0.0110727
[Epoch 81; Iter   110/ 1097] train: loss: 0.0002527
[Epoch 81; Iter   140/ 1097] train: loss: 0.0000364
[Epoch 81; Iter   170/ 1097] train: loss: 0.0037263
[Epoch 81; Iter   200/ 1097] train: loss: 0.0000384
[Epoch 81; Iter   230/ 1097] train: loss: 0.0000592
[Epoch 81; Iter   260/ 1097] train: loss: 0.0003114
[Epoch 81; Iter   290/ 1097] train: loss: 0.0001000
[Epoch 81; Iter   320/ 1097] train: loss: 0.0000469
[Epoch 77; Iter   268/ 1097] train: loss: 0.0046270
[Epoch 77; Iter   298/ 1097] train: loss: 0.0001096
[Epoch 77; Iter   328/ 1097] train: loss: 0.0000027
[Epoch 77; Iter   358/ 1097] train: loss: 0.0000725
[Epoch 77; Iter   388/ 1097] train: loss: 0.0000220
[Epoch 77; Iter   418/ 1097] train: loss: 0.0001237
[Epoch 77; Iter   448/ 1097] train: loss: 0.0002592
[Epoch 77; Iter   478/ 1097] train: loss: 0.0000198
[Epoch 77; Iter   508/ 1097] train: loss: 0.0000690
[Epoch 77; Iter   538/ 1097] train: loss: 0.0006039
[Epoch 77; Iter   568/ 1097] train: loss: 0.0000692
[Epoch 77; Iter   598/ 1097] train: loss: 0.0023244
[Epoch 77; Iter   628/ 1097] train: loss: 0.0003725
[Epoch 77; Iter   658/ 1097] train: loss: 0.0000390
[Epoch 77; Iter   688/ 1097] train: loss: 0.0068547
[Epoch 77; Iter   718/ 1097] train: loss: 0.0020394
[Epoch 77; Iter   748/ 1097] train: loss: 0.0002858
[Epoch 77; Iter   778/ 1097] train: loss: 0.0001833
[Epoch 77; Iter   808/ 1097] train: loss: 0.0008865
[Epoch 77; Iter   838/ 1097] train: loss: 0.0001006
[Epoch 77; Iter   868/ 1097] train: loss: 0.0043562
[Epoch 77; Iter   898/ 1097] train: loss: 0.0001358
[Epoch 77; Iter   928/ 1097] train: loss: 0.0004365
[Epoch 77; Iter   958/ 1097] train: loss: 0.0000113
[Epoch 77; Iter   988/ 1097] train: loss: 0.0000071
[Epoch 77; Iter  1018/ 1097] train: loss: 0.1189509
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0000067
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0000563
[Epoch 77] ogbg-molhiv: 0.682120 val loss: 3.870988
[Epoch 77] ogbg-molhiv: 0.610184 test loss: 3.934757
[Epoch 78; Iter    11/ 1097] train: loss: 0.0000275
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000930
[Epoch 78; Iter    71/ 1097] train: loss: 0.0000018
[Epoch 78; Iter   101/ 1097] train: loss: 0.0005628
[Epoch 78; Iter   131/ 1097] train: loss: 0.0001647
[Epoch 78; Iter   161/ 1097] train: loss: 0.0000185
[Epoch 78; Iter   191/ 1097] train: loss: 0.0000313
[Epoch 78; Iter   221/ 1097] train: loss: 0.0002171
[Epoch 78; Iter   251/ 1097] train: loss: 0.0205007
[Epoch 78; Iter   281/ 1097] train: loss: 0.0000151
[Epoch 78; Iter   311/ 1097] train: loss: 0.0000119
[Epoch 78; Iter   341/ 1097] train: loss: 0.0003231
[Epoch 78; Iter   371/ 1097] train: loss: 0.0002862
[Epoch 78; Iter   401/ 1097] train: loss: 0.0065044
[Epoch 78; Iter   431/ 1097] train: loss: 0.0000343
[Epoch 78; Iter   461/ 1097] train: loss: 0.0008247
[Epoch 78; Iter   491/ 1097] train: loss: 0.0002039
[Epoch 78; Iter   521/ 1097] train: loss: 0.0000023
[Epoch 78; Iter   551/ 1097] train: loss: 0.0000140
[Epoch 78; Iter   581/ 1097] train: loss: 0.0003556
[Epoch 78; Iter   611/ 1097] train: loss: 0.0010288
[Epoch 78; Iter   641/ 1097] train: loss: 0.0000735
[Epoch 78; Iter   671/ 1097] train: loss: 0.0008958
[Epoch 78; Iter   701/ 1097] train: loss: 0.0003336
[Epoch 78; Iter   731/ 1097] train: loss: 0.0000187
[Epoch 78; Iter   761/ 1097] train: loss: 0.0035005
[Epoch 78; Iter   791/ 1097] train: loss: 0.0000948
[Epoch 78; Iter   821/ 1097] train: loss: 0.0000038
[Epoch 78; Iter   851/ 1097] train: loss: 0.0000193
[Epoch 78; Iter   881/ 1097] train: loss: 0.0003193
[Epoch 78; Iter   911/ 1097] train: loss: 0.0000011
[Epoch 78; Iter   941/ 1097] train: loss: 0.0000358
[Epoch 78; Iter   971/ 1097] train: loss: 0.0003602
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0004701
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0000906
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0001269
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0172766
[Epoch 78] ogbg-molhiv: 0.687965 val loss: 3.110079
[Epoch 78] ogbg-molhiv: 0.590817 test loss: 3.120417
[Epoch 79; Iter    24/ 1097] train: loss: 0.0016743
[Epoch 79; Iter    54/ 1097] train: loss: 0.0000025
[Epoch 79; Iter    84/ 1097] train: loss: 0.0000358
[Epoch 79; Iter   114/ 1097] train: loss: 0.0000045
[Epoch 79; Iter   144/ 1097] train: loss: 0.0001654
[Epoch 79; Iter   174/ 1097] train: loss: 0.0012857
[Epoch 79; Iter   204/ 1097] train: loss: 0.0000304
[Epoch 79; Iter   234/ 1097] train: loss: 0.0000185
[Epoch 79; Iter   264/ 1097] train: loss: 0.0000344
[Epoch 79; Iter   294/ 1097] train: loss: 0.0003050
[Epoch 79; Iter   324/ 1097] train: loss: 0.0000134
[Epoch 79; Iter   354/ 1097] train: loss: 0.0003947
[Epoch 79; Iter   384/ 1097] train: loss: 0.0007417
[Epoch 79; Iter   414/ 1097] train: loss: 0.0000665
[Epoch 79; Iter   444/ 1097] train: loss: 0.0000485
[Epoch 79; Iter   474/ 1097] train: loss: 0.0002946
[Epoch 79; Iter   504/ 1097] train: loss: 0.0001357
[Epoch 79; Iter   534/ 1097] train: loss: 0.0000365
[Epoch 79; Iter   564/ 1097] train: loss: 0.0000503
[Epoch 79; Iter   594/ 1097] train: loss: 0.0000153
[Epoch 79; Iter   624/ 1097] train: loss: 0.0004474
[Epoch 79; Iter   654/ 1097] train: loss: 0.0152185
[Epoch 79; Iter   684/ 1097] train: loss: 0.0197065
[Epoch 79; Iter   714/ 1097] train: loss: 0.0001202
[Epoch 79; Iter   744/ 1097] train: loss: 0.0645820
[Epoch 79; Iter   774/ 1097] train: loss: 0.0312775
[Epoch 79; Iter   804/ 1097] train: loss: 0.0000585
[Epoch 79; Iter   834/ 1097] train: loss: 0.0000150
[Epoch 79; Iter   864/ 1097] train: loss: 0.0054108
[Epoch 79; Iter   894/ 1097] train: loss: 0.0000275
[Epoch 79; Iter   924/ 1097] train: loss: 0.0000225
[Epoch 79; Iter   954/ 1097] train: loss: 0.0003968
[Epoch 79; Iter   984/ 1097] train: loss: 0.0001882
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0000069
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0001054
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0000072
[Epoch 79] ogbg-molhiv: 0.672350 val loss: 2.735996
[Epoch 79] ogbg-molhiv: 0.568954 test loss: 3.156348
[Epoch 80; Iter     7/ 1097] train: loss: 0.0137707
[Epoch 80; Iter    37/ 1097] train: loss: 0.0001155
[Epoch 80; Iter    67/ 1097] train: loss: 0.0000517
[Epoch 80; Iter    97/ 1097] train: loss: 0.0001058
[Epoch 80; Iter   127/ 1097] train: loss: 0.0000157
[Epoch 80; Iter   157/ 1097] train: loss: 0.0016726
[Epoch 80; Iter   187/ 1097] train: loss: 0.0003499
[Epoch 80; Iter   217/ 1097] train: loss: 0.0005010
[Epoch 80; Iter   247/ 1097] train: loss: 0.0000006
[Epoch 80; Iter   277/ 1097] train: loss: 0.0000075
[Epoch 80; Iter   307/ 1097] train: loss: 0.0000388
[Epoch 80; Iter   337/ 1097] train: loss: 0.0000342
[Epoch 80; Iter   367/ 1097] train: loss: 0.0001385
[Epoch 80; Iter   397/ 1097] train: loss: 0.0000107
[Epoch 80; Iter   427/ 1097] train: loss: 0.0005310
[Epoch 80; Iter   457/ 1097] train: loss: 0.0013033
[Epoch 80; Iter   487/ 1097] train: loss: 0.0000034
[Epoch 80; Iter   517/ 1097] train: loss: 0.0000189
[Epoch 80; Iter   547/ 1097] train: loss: 0.0035970
[Epoch 80; Iter   577/ 1097] train: loss: 0.0000194
[Epoch 80; Iter   607/ 1097] train: loss: 0.0000045
[Epoch 80; Iter   637/ 1097] train: loss: 0.0000024
[Epoch 80; Iter   667/ 1097] train: loss: 0.0000354
[Epoch 80; Iter   697/ 1097] train: loss: 0.0000374
[Epoch 80; Iter   727/ 1097] train: loss: 0.0005970
[Epoch 80; Iter   757/ 1097] train: loss: 0.0003959
[Epoch 80; Iter   787/ 1097] train: loss: 0.0000505
[Epoch 80; Iter   817/ 1097] train: loss: 0.0000019
[Epoch 80; Iter   847/ 1097] train: loss: 0.0000126
[Epoch 80; Iter   877/ 1097] train: loss: 0.0001888
[Epoch 80; Iter   907/ 1097] train: loss: 0.0000062
[Epoch 80; Iter   937/ 1097] train: loss: 0.0000864
[Epoch 80; Iter   967/ 1097] train: loss: 0.0000476
[Epoch 80; Iter   997/ 1097] train: loss: 0.0000379
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0024448
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0013416
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0000235
[Epoch 80] ogbg-molhiv: 0.680038 val loss: 2.509828
[Epoch 80] ogbg-molhiv: 0.603971 test loss: 2.907505
[Epoch 81; Iter    20/ 1097] train: loss: 0.0000243
[Epoch 81; Iter    50/ 1097] train: loss: 0.0000099
[Epoch 81; Iter    80/ 1097] train: loss: 0.0000122
[Epoch 81; Iter   110/ 1097] train: loss: 0.0000136
[Epoch 81; Iter   140/ 1097] train: loss: 0.0005090
[Epoch 81; Iter   170/ 1097] train: loss: 0.0000089
[Epoch 81; Iter   200/ 1097] train: loss: 0.0001143
[Epoch 81; Iter   230/ 1097] train: loss: 0.0001771
[Epoch 81; Iter   260/ 1097] train: loss: 0.0000029
[Epoch 81; Iter   290/ 1097] train: loss: 0.0000846
[Epoch 81; Iter   320/ 1097] train: loss: 0.0021994
[Epoch 77; Iter   268/ 1097] train: loss: 0.0049374
[Epoch 77; Iter   298/ 1097] train: loss: 0.0000257
[Epoch 77; Iter   328/ 1097] train: loss: 0.0000603
[Epoch 77; Iter   358/ 1097] train: loss: 0.0002120
[Epoch 77; Iter   388/ 1097] train: loss: 0.0002828
[Epoch 77; Iter   418/ 1097] train: loss: 0.0043573
[Epoch 77; Iter   448/ 1097] train: loss: 0.0000227
[Epoch 77; Iter   478/ 1097] train: loss: 0.0003931
[Epoch 77; Iter   508/ 1097] train: loss: 0.0065889
[Epoch 77; Iter   538/ 1097] train: loss: 0.0030839
[Epoch 77; Iter   568/ 1097] train: loss: 0.0001537
[Epoch 77; Iter   598/ 1097] train: loss: 0.0000069
[Epoch 77; Iter   628/ 1097] train: loss: 0.0011900
[Epoch 77; Iter   658/ 1097] train: loss: 0.0008021
[Epoch 77; Iter   688/ 1097] train: loss: 0.0008532
[Epoch 77; Iter   718/ 1097] train: loss: 0.0028593
[Epoch 77; Iter   748/ 1097] train: loss: 0.0039465
[Epoch 77; Iter   778/ 1097] train: loss: 0.0002975
[Epoch 77; Iter   808/ 1097] train: loss: 0.0004090
[Epoch 77; Iter   838/ 1097] train: loss: 0.0000987
[Epoch 77; Iter   868/ 1097] train: loss: 0.0026032
[Epoch 77; Iter   898/ 1097] train: loss: 0.0001829
[Epoch 77; Iter   928/ 1097] train: loss: 0.0006976
[Epoch 77; Iter   958/ 1097] train: loss: 0.0006215
[Epoch 77; Iter   988/ 1097] train: loss: 0.0001813
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0110193
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0004117
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0030461
[Epoch 77] ogbg-molhiv: 0.662772 val loss: 189.015644
[Epoch 77] ogbg-molhiv: 0.597578 test loss: 173.803758
[Epoch 78; Iter    11/ 1097] train: loss: 0.0032022
[Epoch 78; Iter    41/ 1097] train: loss: 0.1208030
[Epoch 78; Iter    71/ 1097] train: loss: 0.0004383
[Epoch 78; Iter   101/ 1097] train: loss: 0.0011735
[Epoch 78; Iter   131/ 1097] train: loss: 0.0005067
[Epoch 78; Iter   161/ 1097] train: loss: 0.0001985
[Epoch 78; Iter   191/ 1097] train: loss: 0.0000633
[Epoch 78; Iter   221/ 1097] train: loss: 0.0000066
[Epoch 78; Iter   251/ 1097] train: loss: 0.0008950
[Epoch 78; Iter   281/ 1097] train: loss: 0.0000494
[Epoch 78; Iter   311/ 1097] train: loss: 0.0010705
[Epoch 78; Iter   341/ 1097] train: loss: 0.0000515
[Epoch 78; Iter   371/ 1097] train: loss: 0.0000077
[Epoch 78; Iter   401/ 1097] train: loss: 0.0000768
[Epoch 78; Iter   431/ 1097] train: loss: 0.0000115
[Epoch 78; Iter   461/ 1097] train: loss: 0.0015947
[Epoch 78; Iter   491/ 1097] train: loss: 0.0042930
[Epoch 78; Iter   521/ 1097] train: loss: 0.0000753
[Epoch 78; Iter   551/ 1097] train: loss: 0.0000281
[Epoch 78; Iter   581/ 1097] train: loss: 0.0009895
[Epoch 78; Iter   611/ 1097] train: loss: 0.0000745
[Epoch 78; Iter   641/ 1097] train: loss: 0.0002342
[Epoch 78; Iter   671/ 1097] train: loss: 0.0004075
[Epoch 78; Iter   701/ 1097] train: loss: 0.0247728
[Epoch 78; Iter   731/ 1097] train: loss: 0.0011345
[Epoch 78; Iter   761/ 1097] train: loss: 0.0001591
[Epoch 78; Iter   791/ 1097] train: loss: 0.0254382
[Epoch 78; Iter   821/ 1097] train: loss: 0.0000132
[Epoch 78; Iter   851/ 1097] train: loss: 0.0025984
[Epoch 78; Iter   881/ 1097] train: loss: 0.0005351
[Epoch 78; Iter   911/ 1097] train: loss: 0.0001295
[Epoch 78; Iter   941/ 1097] train: loss: 0.0047958
[Epoch 78; Iter   971/ 1097] train: loss: 0.0000392
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0031722
[Epoch 78; Iter  1031/ 1097] train: loss: 0.1049689
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0810314
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0006601
[Epoch 78] ogbg-molhiv: 0.672034 val loss: 83.565995
[Epoch 78] ogbg-molhiv: 0.576407 test loss: 68.937242
[Epoch 79; Iter    24/ 1097] train: loss: 0.0000588
[Epoch 79; Iter    54/ 1097] train: loss: 0.0389822
[Epoch 79; Iter    84/ 1097] train: loss: 0.0119630
[Epoch 79; Iter   114/ 1097] train: loss: 0.0004871
[Epoch 79; Iter   144/ 1097] train: loss: 0.0000256
[Epoch 79; Iter   174/ 1097] train: loss: 0.0005464
[Epoch 79; Iter   204/ 1097] train: loss: 0.0000258
[Epoch 79; Iter   234/ 1097] train: loss: 0.0002061
[Epoch 79; Iter   264/ 1097] train: loss: 0.0002626
[Epoch 79; Iter   294/ 1097] train: loss: 0.0002095
[Epoch 79; Iter   324/ 1097] train: loss: 0.0002175
[Epoch 79; Iter   354/ 1097] train: loss: 0.0031135
[Epoch 79; Iter   384/ 1097] train: loss: 0.0000299
[Epoch 79; Iter   414/ 1097] train: loss: 0.0001719
[Epoch 79; Iter   444/ 1097] train: loss: 0.0337972
[Epoch 79; Iter   474/ 1097] train: loss: 0.0004464
[Epoch 79; Iter   504/ 1097] train: loss: 0.0050752
[Epoch 79; Iter   534/ 1097] train: loss: 0.0031879
[Epoch 79; Iter   564/ 1097] train: loss: 0.0001482
[Epoch 79; Iter   594/ 1097] train: loss: 0.0030154
[Epoch 79; Iter   624/ 1097] train: loss: 0.0008868
[Epoch 79; Iter   654/ 1097] train: loss: 0.0000547
[Epoch 79; Iter   684/ 1097] train: loss: 0.0010942
[Epoch 79; Iter   714/ 1097] train: loss: 0.0115607
[Epoch 79; Iter   744/ 1097] train: loss: 0.0000788
[Epoch 79; Iter   774/ 1097] train: loss: 0.0003227
[Epoch 79; Iter   804/ 1097] train: loss: 0.0007402
[Epoch 79; Iter   834/ 1097] train: loss: 0.0192099
[Epoch 79; Iter   864/ 1097] train: loss: 0.0000700
[Epoch 79; Iter   894/ 1097] train: loss: 0.0029276
[Epoch 79; Iter   924/ 1097] train: loss: 0.0068654
[Epoch 79; Iter   954/ 1097] train: loss: 0.0000303
[Epoch 79; Iter   984/ 1097] train: loss: 0.0698422
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0002760
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0002430
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0016555
[Epoch 79] ogbg-molhiv: 0.673532 val loss: 8.954866
[Epoch 79] ogbg-molhiv: 0.565544 test loss: 9.107821
[Epoch 80; Iter     7/ 1097] train: loss: 0.0185547
[Epoch 80; Iter    37/ 1097] train: loss: 0.0000306
[Epoch 80; Iter    67/ 1097] train: loss: 0.0000192
[Epoch 80; Iter    97/ 1097] train: loss: 0.0002064
[Epoch 80; Iter   127/ 1097] train: loss: 0.0003144
[Epoch 80; Iter   157/ 1097] train: loss: 0.0547952
[Epoch 80; Iter   187/ 1097] train: loss: 0.0029751
[Epoch 80; Iter   217/ 1097] train: loss: 0.0002935
[Epoch 80; Iter   247/ 1097] train: loss: 0.0187909
[Epoch 80; Iter   277/ 1097] train: loss: 0.0006612
[Epoch 80; Iter   307/ 1097] train: loss: 0.0028557
[Epoch 80; Iter   337/ 1097] train: loss: 0.0002588
[Epoch 80; Iter   367/ 1097] train: loss: 0.0001950
[Epoch 80; Iter   397/ 1097] train: loss: 0.0470773
[Epoch 80; Iter   427/ 1097] train: loss: 0.0002906
[Epoch 80; Iter   457/ 1097] train: loss: 0.0007444
[Epoch 80; Iter   487/ 1097] train: loss: 0.0007447
[Epoch 80; Iter   517/ 1097] train: loss: 0.0005203
[Epoch 80; Iter   547/ 1097] train: loss: 0.0061359
[Epoch 80; Iter   577/ 1097] train: loss: 0.0361876
[Epoch 80; Iter   607/ 1097] train: loss: 0.0001799
[Epoch 80; Iter   637/ 1097] train: loss: 0.0147239
[Epoch 80; Iter   667/ 1097] train: loss: 0.0003079
[Epoch 80; Iter   697/ 1097] train: loss: 0.0045612
[Epoch 80; Iter   727/ 1097] train: loss: 0.0053397
[Epoch 80; Iter   757/ 1097] train: loss: 0.0001285
[Epoch 80; Iter   787/ 1097] train: loss: 0.0004500
[Epoch 80; Iter   817/ 1097] train: loss: 0.0005576
[Epoch 80; Iter   847/ 1097] train: loss: 0.0001223
[Epoch 80; Iter   877/ 1097] train: loss: 0.0002546
[Epoch 80; Iter   907/ 1097] train: loss: 0.0000406
[Epoch 80; Iter   937/ 1097] train: loss: 0.0000997
[Epoch 80; Iter   967/ 1097] train: loss: 0.0017762
[Epoch 80; Iter   997/ 1097] train: loss: 0.0006458
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0007684
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0196234
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0002917
[Epoch 80] ogbg-molhiv: 0.672959 val loss: 215.024687
[Epoch 80] ogbg-molhiv: 0.563379 test loss: 210.492549
[Epoch 81; Iter    20/ 1097] train: loss: 0.0005481
[Epoch 81; Iter    50/ 1097] train: loss: 0.0080549
[Epoch 81; Iter    80/ 1097] train: loss: 0.0017014
[Epoch 81; Iter   110/ 1097] train: loss: 0.0002543
[Epoch 81; Iter   140/ 1097] train: loss: 0.0017553
[Epoch 81; Iter   170/ 1097] train: loss: 0.0037884
[Epoch 81; Iter   200/ 1097] train: loss: 0.0529601
[Epoch 81; Iter   230/ 1097] train: loss: 0.0002737
[Epoch 81; Iter   260/ 1097] train: loss: 0.0758095
[Epoch 81; Iter   290/ 1097] train: loss: 0.0122672
[Epoch 81; Iter   320/ 1097] train: loss: 0.0004101
[Epoch 77; Iter   268/ 1097] train: loss: 0.0002021
[Epoch 77; Iter   298/ 1097] train: loss: 0.0003796
[Epoch 77; Iter   328/ 1097] train: loss: 0.0000131
[Epoch 77; Iter   358/ 1097] train: loss: 0.0000371
[Epoch 77; Iter   388/ 1097] train: loss: 0.0000716
[Epoch 77; Iter   418/ 1097] train: loss: 0.0000465
[Epoch 77; Iter   448/ 1097] train: loss: 0.0002785
[Epoch 77; Iter   478/ 1097] train: loss: 0.0002637
[Epoch 77; Iter   508/ 1097] train: loss: 0.0010462
[Epoch 77; Iter   538/ 1097] train: loss: 0.0000183
[Epoch 77; Iter   568/ 1097] train: loss: 0.0029443
[Epoch 77; Iter   598/ 1097] train: loss: 0.0002694
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000481
[Epoch 77; Iter   658/ 1097] train: loss: 0.0004268
[Epoch 77; Iter   688/ 1097] train: loss: 0.0000907
[Epoch 77; Iter   718/ 1097] train: loss: 0.0012294
[Epoch 77; Iter   748/ 1097] train: loss: 0.0006380
[Epoch 77; Iter   778/ 1097] train: loss: 0.0001084
[Epoch 77; Iter   808/ 1097] train: loss: 0.0000503
[Epoch 77; Iter   838/ 1097] train: loss: 0.0012769
[Epoch 77; Iter   868/ 1097] train: loss: 0.0000694
[Epoch 77; Iter   898/ 1097] train: loss: 0.0010867
[Epoch 77; Iter   928/ 1097] train: loss: 0.0000221
[Epoch 77; Iter   958/ 1097] train: loss: 0.0001726
[Epoch 77; Iter   988/ 1097] train: loss: 0.0187595
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0043443
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0003011
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0002511
[Epoch 77] ogbg-molhiv: 0.720183 val loss: 0.635953
[Epoch 77] ogbg-molhiv: 0.740370 test loss: 2.392305
[Epoch 78; Iter    11/ 1097] train: loss: 0.0005669
[Epoch 78; Iter    41/ 1097] train: loss: 0.0002458
[Epoch 78; Iter    71/ 1097] train: loss: 0.0000055
[Epoch 78; Iter   101/ 1097] train: loss: 0.0217736
[Epoch 78; Iter   131/ 1097] train: loss: 0.0047176
[Epoch 78; Iter   161/ 1097] train: loss: 0.0005025
[Epoch 78; Iter   191/ 1097] train: loss: 0.0010126
[Epoch 78; Iter   221/ 1097] train: loss: 0.0007538
[Epoch 78; Iter   251/ 1097] train: loss: 0.0002006
[Epoch 78; Iter   281/ 1097] train: loss: 0.0000679
[Epoch 78; Iter   311/ 1097] train: loss: 0.0000219
[Epoch 78; Iter   341/ 1097] train: loss: 0.0114190
[Epoch 78; Iter   371/ 1097] train: loss: 0.0004300
[Epoch 78; Iter   401/ 1097] train: loss: 0.0009401
[Epoch 78; Iter   431/ 1097] train: loss: 0.0000103
[Epoch 78; Iter   461/ 1097] train: loss: 0.0001764
[Epoch 78; Iter   491/ 1097] train: loss: 0.0013866
[Epoch 78; Iter   521/ 1097] train: loss: 0.0000442
[Epoch 78; Iter   551/ 1097] train: loss: 0.0028821
[Epoch 78; Iter   581/ 1097] train: loss: 0.0124593
[Epoch 78; Iter   611/ 1097] train: loss: 0.0000646
[Epoch 78; Iter   641/ 1097] train: loss: 0.0340844
[Epoch 78; Iter   671/ 1097] train: loss: 0.0015241
[Epoch 78; Iter   701/ 1097] train: loss: 0.0335899
[Epoch 78; Iter   731/ 1097] train: loss: 0.0002235
[Epoch 78; Iter   761/ 1097] train: loss: 0.0190435
[Epoch 78; Iter   791/ 1097] train: loss: 0.0002001
[Epoch 78; Iter   821/ 1097] train: loss: 0.0003829
[Epoch 78; Iter   851/ 1097] train: loss: 0.0000096
[Epoch 78; Iter   881/ 1097] train: loss: 0.0000132
[Epoch 78; Iter   911/ 1097] train: loss: 0.0005014
[Epoch 78; Iter   941/ 1097] train: loss: 0.0004044
[Epoch 78; Iter   971/ 1097] train: loss: 0.0011483
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0021951
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0000371
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0000026
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0000171
[Epoch 78] ogbg-molhiv: 0.745116 val loss: 0.575441
[Epoch 78] ogbg-molhiv: 0.738023 test loss: 1.097696
[Epoch 79; Iter    24/ 1097] train: loss: 0.0059195
[Epoch 79; Iter    54/ 1097] train: loss: 0.0002610
[Epoch 79; Iter    84/ 1097] train: loss: 0.0000053
[Epoch 79; Iter   114/ 1097] train: loss: 0.0000164
[Epoch 79; Iter   144/ 1097] train: loss: 0.0005189
[Epoch 79; Iter   174/ 1097] train: loss: 0.0018024
[Epoch 79; Iter   204/ 1097] train: loss: 0.0130657
[Epoch 79; Iter   234/ 1097] train: loss: 0.0000162
[Epoch 79; Iter   264/ 1097] train: loss: 0.0000435
[Epoch 79; Iter   294/ 1097] train: loss: 0.0005608
[Epoch 79; Iter   324/ 1097] train: loss: 0.0034410
[Epoch 79; Iter   354/ 1097] train: loss: 0.0000115
[Epoch 79; Iter   384/ 1097] train: loss: 0.0006059
[Epoch 79; Iter   414/ 1097] train: loss: 0.0000759
[Epoch 79; Iter   444/ 1097] train: loss: 0.0000040
[Epoch 79; Iter   474/ 1097] train: loss: 0.0000253
[Epoch 79; Iter   504/ 1097] train: loss: 0.0002993
[Epoch 79; Iter   534/ 1097] train: loss: 0.0000049
[Epoch 79; Iter   564/ 1097] train: loss: 0.0006672
[Epoch 79; Iter   594/ 1097] train: loss: 0.0003764
[Epoch 79; Iter   624/ 1097] train: loss: 0.0000110
[Epoch 79; Iter   654/ 1097] train: loss: 0.0000079
[Epoch 79; Iter   684/ 1097] train: loss: 0.0013982
[Epoch 79; Iter   714/ 1097] train: loss: 0.0020420
[Epoch 79; Iter   744/ 1097] train: loss: 0.0000429
[Epoch 79; Iter   774/ 1097] train: loss: 0.0093699
[Epoch 79; Iter   804/ 1097] train: loss: 0.0002466
[Epoch 79; Iter   834/ 1097] train: loss: 0.0004582
[Epoch 79; Iter   864/ 1097] train: loss: 0.0056935
[Epoch 79; Iter   894/ 1097] train: loss: 0.0001616
[Epoch 79; Iter   924/ 1097] train: loss: 0.0000204
[Epoch 79; Iter   954/ 1097] train: loss: 0.0113387
[Epoch 79; Iter   984/ 1097] train: loss: 0.0001229
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0006443
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0005990
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0005746
[Epoch 79] ogbg-molhiv: 0.766969 val loss: 3.560230
[Epoch 79] ogbg-molhiv: 0.718527 test loss: 5.486596
[Epoch 80; Iter     7/ 1097] train: loss: 0.0014727
[Epoch 80; Iter    37/ 1097] train: loss: 0.0000126
[Epoch 80; Iter    67/ 1097] train: loss: 0.0015041
[Epoch 80; Iter    97/ 1097] train: loss: 0.0008408
[Epoch 80; Iter   127/ 1097] train: loss: 0.0000645
[Epoch 80; Iter   157/ 1097] train: loss: 0.0005528
[Epoch 80; Iter   187/ 1097] train: loss: 0.0293932
[Epoch 80; Iter   217/ 1097] train: loss: 0.0018264
[Epoch 80; Iter   247/ 1097] train: loss: 0.0000974
[Epoch 80; Iter   277/ 1097] train: loss: 0.0121309
[Epoch 80; Iter   307/ 1097] train: loss: 0.0000849
[Epoch 80; Iter   337/ 1097] train: loss: 0.0001819
[Epoch 80; Iter   367/ 1097] train: loss: 0.0000950
[Epoch 80; Iter   397/ 1097] train: loss: 0.0000617
[Epoch 80; Iter   427/ 1097] train: loss: 0.0009258
[Epoch 80; Iter   457/ 1097] train: loss: 0.0042320
[Epoch 80; Iter   487/ 1097] train: loss: 0.0000101
[Epoch 80; Iter   517/ 1097] train: loss: 0.0016076
[Epoch 80; Iter   547/ 1097] train: loss: 0.0002180
[Epoch 80; Iter   577/ 1097] train: loss: 0.0015991
[Epoch 80; Iter   607/ 1097] train: loss: 0.0000683
[Epoch 80; Iter   637/ 1097] train: loss: 0.0014056
[Epoch 80; Iter   667/ 1097] train: loss: 0.0000071
[Epoch 80; Iter   697/ 1097] train: loss: 0.0021362
[Epoch 80; Iter   727/ 1097] train: loss: 0.0008113
[Epoch 80; Iter   757/ 1097] train: loss: 0.0049717
[Epoch 80; Iter   787/ 1097] train: loss: 0.0000414
[Epoch 80; Iter   817/ 1097] train: loss: 0.0041766
[Epoch 80; Iter   847/ 1097] train: loss: 0.0000293
[Epoch 80; Iter   877/ 1097] train: loss: 0.0001037
[Epoch 80; Iter   907/ 1097] train: loss: 0.0081104
[Epoch 80; Iter   937/ 1097] train: loss: 0.0045723
[Epoch 80; Iter   967/ 1097] train: loss: 0.1196612
[Epoch 80; Iter   997/ 1097] train: loss: 0.0039541
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0093730
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0259440
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0005316
[Epoch 80] ogbg-molhiv: 0.749288 val loss: 2.827316
[Epoch 80] ogbg-molhiv: 0.692499 test loss: 6.343741
[Epoch 81; Iter    20/ 1097] train: loss: 0.0011597
[Epoch 81; Iter    50/ 1097] train: loss: 0.0003556
[Epoch 81; Iter    80/ 1097] train: loss: 0.0000259
[Epoch 81; Iter   110/ 1097] train: loss: 0.0009828
[Epoch 81; Iter   140/ 1097] train: loss: 0.0001198
[Epoch 81; Iter   170/ 1097] train: loss: 0.0000107
[Epoch 81; Iter   200/ 1097] train: loss: 0.0000011
[Epoch 81; Iter   230/ 1097] train: loss: 0.0114915
[Epoch 81; Iter   260/ 1097] train: loss: 0.0004308
[Epoch 81; Iter   290/ 1097] train: loss: 0.0000817
[Epoch 81; Iter   320/ 1097] train: loss: 0.0003344
[Epoch 81; Iter   350/ 1097] train: loss: 0.0005114
[Epoch 81; Iter   380/ 1097] train: loss: 0.0002897
[Epoch 81; Iter   410/ 1097] train: loss: 0.0001130
[Epoch 81; Iter   440/ 1097] train: loss: 0.0010493
[Epoch 81; Iter   470/ 1097] train: loss: 0.0136594
[Epoch 81; Iter   500/ 1097] train: loss: 0.0015721
[Epoch 81; Iter   530/ 1097] train: loss: 0.0112806
[Epoch 81; Iter   560/ 1097] train: loss: 0.0004214
[Epoch 81; Iter   590/ 1097] train: loss: 0.0020851
[Epoch 81; Iter   620/ 1097] train: loss: 0.0009418
[Epoch 81; Iter   650/ 1097] train: loss: 0.0020141
[Epoch 81; Iter   680/ 1097] train: loss: 0.0003159
[Epoch 81; Iter   710/ 1097] train: loss: 0.0250051
[Epoch 81; Iter   740/ 1097] train: loss: 0.0786754
[Epoch 81; Iter   770/ 1097] train: loss: 0.0299498
[Epoch 81; Iter   800/ 1097] train: loss: 0.0002619
[Epoch 81; Iter   830/ 1097] train: loss: 0.0334058
[Epoch 81; Iter   860/ 1097] train: loss: 0.0014090
[Epoch 81; Iter   890/ 1097] train: loss: 0.0008723
[Epoch 81; Iter   920/ 1097] train: loss: 0.0497243
[Epoch 81; Iter   950/ 1097] train: loss: 0.0327188
[Epoch 81; Iter   980/ 1097] train: loss: 0.0026323
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0439349
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0036476
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0020219
[Epoch 81] ogbg-molhiv: 0.769238 val loss: 1.127185
[Epoch 81] ogbg-molhiv: 0.726397 test loss: 1.207118
[Epoch 82; Iter     3/ 1097] train: loss: 0.0050772
[Epoch 82; Iter    33/ 1097] train: loss: 0.0007501
[Epoch 82; Iter    63/ 1097] train: loss: 0.0002983
[Epoch 82; Iter    93/ 1097] train: loss: 0.0001064
[Epoch 82; Iter   123/ 1097] train: loss: 0.0001105
[Epoch 82; Iter   153/ 1097] train: loss: 0.0014351
[Epoch 82; Iter   183/ 1097] train: loss: 0.0009155
[Epoch 82; Iter   213/ 1097] train: loss: 0.0018256
[Epoch 82; Iter   243/ 1097] train: loss: 0.0055812
[Epoch 82; Iter   273/ 1097] train: loss: 0.0634073
[Epoch 82; Iter   303/ 1097] train: loss: 0.0003469
[Epoch 82; Iter   333/ 1097] train: loss: 0.0000445
[Epoch 82; Iter   363/ 1097] train: loss: 0.0003047
[Epoch 82; Iter   393/ 1097] train: loss: 0.0002259
[Epoch 82; Iter   423/ 1097] train: loss: 0.0031199
[Epoch 82; Iter   453/ 1097] train: loss: 0.0000967
[Epoch 82; Iter   483/ 1097] train: loss: 0.0000744
[Epoch 82; Iter   513/ 1097] train: loss: 0.0004134
[Epoch 82; Iter   543/ 1097] train: loss: 0.0005347
[Epoch 82; Iter   573/ 1097] train: loss: 0.1116211
[Epoch 82; Iter   603/ 1097] train: loss: 0.0005423
[Epoch 82; Iter   633/ 1097] train: loss: 0.0001155
[Epoch 82; Iter   663/ 1097] train: loss: 0.0012354
[Epoch 82; Iter   693/ 1097] train: loss: 0.0009486
[Epoch 82; Iter   723/ 1097] train: loss: 0.0542220
[Epoch 82; Iter   753/ 1097] train: loss: 0.0000466
[Epoch 82; Iter   783/ 1097] train: loss: 0.0009367
[Epoch 82; Iter   813/ 1097] train: loss: 0.0005127
[Epoch 82; Iter   843/ 1097] train: loss: 0.0309465
[Epoch 82; Iter   873/ 1097] train: loss: 0.0103635
[Epoch 82; Iter   903/ 1097] train: loss: 0.0042261
[Epoch 82; Iter   933/ 1097] train: loss: 0.0345444
[Epoch 82; Iter   963/ 1097] train: loss: 0.0061214
[Epoch 82; Iter   993/ 1097] train: loss: 0.0072573
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0003498
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0878386
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0002017
[Epoch 82] ogbg-molhiv: 0.719767 val loss: 0.927509
[Epoch 82] ogbg-molhiv: 0.718730 test loss: 1.027079
[Epoch 83; Iter    16/ 1097] train: loss: 0.0020377
[Epoch 83; Iter    46/ 1097] train: loss: 0.0180042
[Epoch 83; Iter    76/ 1097] train: loss: 0.0000313
[Epoch 83; Iter   106/ 1097] train: loss: 0.0065267
[Epoch 83; Iter   136/ 1097] train: loss: 0.0001991
[Epoch 83; Iter   166/ 1097] train: loss: 0.0067759
[Epoch 83; Iter   196/ 1097] train: loss: 0.0005107
[Epoch 83; Iter   226/ 1097] train: loss: 0.0171137
[Epoch 83; Iter   256/ 1097] train: loss: 0.0037274
[Epoch 83; Iter   286/ 1097] train: loss: 0.0000286
[Epoch 83; Iter   316/ 1097] train: loss: 0.0012650
[Epoch 83; Iter   346/ 1097] train: loss: 0.0001029
[Epoch 83; Iter   376/ 1097] train: loss: 0.0000686
[Epoch 83; Iter   406/ 1097] train: loss: 0.0028419
[Epoch 83; Iter   436/ 1097] train: loss: 0.0002936
[Epoch 83; Iter   466/ 1097] train: loss: 0.0008353
[Epoch 83; Iter   496/ 1097] train: loss: 0.0002925
[Epoch 83; Iter   526/ 1097] train: loss: 0.0015900
[Epoch 83; Iter   556/ 1097] train: loss: 0.0005803
[Epoch 83; Iter   586/ 1097] train: loss: 0.0014949
[Epoch 83; Iter   616/ 1097] train: loss: 0.0128126
[Epoch 83; Iter   646/ 1097] train: loss: 0.0001900
[Epoch 83; Iter   676/ 1097] train: loss: 0.0181495
[Epoch 83; Iter   706/ 1097] train: loss: 0.0052299
[Epoch 83; Iter   736/ 1097] train: loss: 0.0003788
[Epoch 83; Iter   766/ 1097] train: loss: 0.0018481
[Epoch 83; Iter   796/ 1097] train: loss: 0.0029443
[Epoch 83; Iter   826/ 1097] train: loss: 0.0004036
[Epoch 83; Iter   856/ 1097] train: loss: 0.0019202
[Epoch 83; Iter   886/ 1097] train: loss: 0.0000383
[Epoch 83; Iter   916/ 1097] train: loss: 0.0000740
[Epoch 83; Iter   946/ 1097] train: loss: 0.0108904
[Epoch 83; Iter   976/ 1097] train: loss: 0.0118965
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0532141
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0006071
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0018060
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0090060
[Epoch 83] ogbg-molhiv: 0.752845 val loss: 0.994769
[Epoch 83] ogbg-molhiv: 0.715087 test loss: 0.971378
[Epoch 84; Iter    29/ 1097] train: loss: 0.0055229
[Epoch 84; Iter    59/ 1097] train: loss: 0.0003246
[Epoch 84; Iter    89/ 1097] train: loss: 0.0016333
[Epoch 84; Iter   119/ 1097] train: loss: 0.0011610
[Epoch 84; Iter   149/ 1097] train: loss: 0.0163160
[Epoch 84; Iter   179/ 1097] train: loss: 0.0184564
[Epoch 84; Iter   209/ 1097] train: loss: 0.0000965
[Epoch 84; Iter   239/ 1097] train: loss: 0.0000370
[Epoch 84; Iter   269/ 1097] train: loss: 0.0001545
[Epoch 84; Iter   299/ 1097] train: loss: 0.0000906
[Epoch 84; Iter   329/ 1097] train: loss: 0.0000823
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000861
[Epoch 84; Iter   389/ 1097] train: loss: 0.0002315
[Epoch 84; Iter   419/ 1097] train: loss: 0.0000861
[Epoch 84; Iter   449/ 1097] train: loss: 0.0043650
[Epoch 84; Iter   479/ 1097] train: loss: 0.0005387
[Epoch 84; Iter   509/ 1097] train: loss: 0.0005860
[Epoch 84; Iter   539/ 1097] train: loss: 0.0001061
[Epoch 84; Iter   569/ 1097] train: loss: 0.0000691
[Epoch 84; Iter   599/ 1097] train: loss: 0.0058873
[Epoch 84; Iter   629/ 1097] train: loss: 0.0440340
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000253
[Epoch 84; Iter   689/ 1097] train: loss: 0.0021131
[Epoch 84; Iter   719/ 1097] train: loss: 0.0001269
[Epoch 84; Iter   749/ 1097] train: loss: 0.0007236
[Epoch 84; Iter   779/ 1097] train: loss: 0.0006997
[Epoch 84; Iter   809/ 1097] train: loss: 0.0026754
[Epoch 84; Iter   839/ 1097] train: loss: 0.0001089
[Epoch 84; Iter   869/ 1097] train: loss: 0.0025773
[Epoch 84; Iter   899/ 1097] train: loss: 0.0061278
[Epoch 84; Iter   929/ 1097] train: loss: 0.0000617
[Epoch 84; Iter   959/ 1097] train: loss: 0.0003583
[Epoch 84; Iter   989/ 1097] train: loss: 0.0011808
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0018804
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0016230
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0030945
[Epoch 84] ogbg-molhiv: 0.755355 val loss: 1.503521
[Epoch 84] ogbg-molhiv: 0.716202 test loss: 1.425951
[Epoch 85; Iter    12/ 1097] train: loss: 0.0004413
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000806
[Epoch 85; Iter    72/ 1097] train: loss: 0.0008571
[Epoch 85; Iter   102/ 1097] train: loss: 0.0036615
[Epoch 85; Iter   132/ 1097] train: loss: 0.0041633
[Epoch 85; Iter   162/ 1097] train: loss: 0.0029801
[Epoch 85; Iter   192/ 1097] train: loss: 0.0008116
[Epoch 85; Iter   222/ 1097] train: loss: 0.0003143
[Epoch 85; Iter   252/ 1097] train: loss: 0.0004809
[Epoch 85; Iter   282/ 1097] train: loss: 0.0003939
[Epoch 85; Iter   312/ 1097] train: loss: 0.0000148
[Epoch 85; Iter   342/ 1097] train: loss: 0.0024406
[Epoch 85; Iter   372/ 1097] train: loss: 0.0000606
[Epoch 85; Iter   402/ 1097] train: loss: 0.0010977
[Epoch 81; Iter   350/ 1097] train: loss: 0.0218428
[Epoch 81; Iter   380/ 1097] train: loss: 0.0007816
[Epoch 81; Iter   410/ 1097] train: loss: 0.0009123
[Epoch 81; Iter   440/ 1097] train: loss: 0.0000728
[Epoch 81; Iter   470/ 1097] train: loss: 0.1311089
[Epoch 81; Iter   500/ 1097] train: loss: 0.0026819
[Epoch 81; Iter   530/ 1097] train: loss: 0.0021071
[Epoch 81; Iter   560/ 1097] train: loss: 0.0017877
[Epoch 81; Iter   590/ 1097] train: loss: 0.0057794
[Epoch 81; Iter   620/ 1097] train: loss: 0.0001705
[Epoch 81; Iter   650/ 1097] train: loss: 0.2195302
[Epoch 81; Iter   680/ 1097] train: loss: 0.0092256
[Epoch 81; Iter   710/ 1097] train: loss: 0.0005707
[Epoch 81; Iter   740/ 1097] train: loss: 0.0005345
[Epoch 81; Iter   770/ 1097] train: loss: 0.0001261
[Epoch 81; Iter   800/ 1097] train: loss: 0.1318364
[Epoch 81; Iter   830/ 1097] train: loss: 0.0200712
[Epoch 81; Iter   860/ 1097] train: loss: 0.0028820
[Epoch 81; Iter   890/ 1097] train: loss: 0.0001973
[Epoch 81; Iter   920/ 1097] train: loss: 0.0026482
[Epoch 81; Iter   950/ 1097] train: loss: 0.0073417
[Epoch 81; Iter   980/ 1097] train: loss: 0.0009877
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0000843
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0009113
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0000566
[Epoch 81] ogbg-molhiv: 0.732504 val loss: 3.629547
[Epoch 81] ogbg-molhiv: 0.713214 test loss: 1.248030
[Epoch 82; Iter     3/ 1097] train: loss: 0.0000215
[Epoch 82; Iter    33/ 1097] train: loss: 0.0024893
[Epoch 82; Iter    63/ 1097] train: loss: 0.0102753
[Epoch 82; Iter    93/ 1097] train: loss: 0.0001240
[Epoch 82; Iter   123/ 1097] train: loss: 0.0113570
[Epoch 82; Iter   153/ 1097] train: loss: 0.0012541
[Epoch 82; Iter   183/ 1097] train: loss: 0.0536561
[Epoch 82; Iter   213/ 1097] train: loss: 0.0018299
[Epoch 82; Iter   243/ 1097] train: loss: 0.0002167
[Epoch 82; Iter   273/ 1097] train: loss: 0.0007522
[Epoch 82; Iter   303/ 1097] train: loss: 0.0012585
[Epoch 82; Iter   333/ 1097] train: loss: 0.0109867
[Epoch 82; Iter   363/ 1097] train: loss: 0.0005484
[Epoch 82; Iter   393/ 1097] train: loss: 0.0002759
[Epoch 82; Iter   423/ 1097] train: loss: 0.0020042
[Epoch 82; Iter   453/ 1097] train: loss: 0.0002916
[Epoch 82; Iter   483/ 1097] train: loss: 0.0001283
[Epoch 82; Iter   513/ 1097] train: loss: 0.0001395
[Epoch 82; Iter   543/ 1097] train: loss: 0.0005504
[Epoch 82; Iter   573/ 1097] train: loss: 0.0060407
[Epoch 82; Iter   603/ 1097] train: loss: 0.0003602
[Epoch 82; Iter   633/ 1097] train: loss: 0.0016551
[Epoch 82; Iter   663/ 1097] train: loss: 0.0001341
[Epoch 82; Iter   693/ 1097] train: loss: 0.1421301
[Epoch 82; Iter   723/ 1097] train: loss: 0.0048572
[Epoch 82; Iter   753/ 1097] train: loss: 0.0005654
[Epoch 82; Iter   783/ 1097] train: loss: 0.0003743
[Epoch 82; Iter   813/ 1097] train: loss: 0.0021893
[Epoch 82; Iter   843/ 1097] train: loss: 0.0028203
[Epoch 82; Iter   873/ 1097] train: loss: 0.1498940
[Epoch 82; Iter   903/ 1097] train: loss: 0.0002803
[Epoch 82; Iter   933/ 1097] train: loss: 0.0005180
[Epoch 82; Iter   963/ 1097] train: loss: 0.0075295
[Epoch 82; Iter   993/ 1097] train: loss: 0.0037918
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0094672
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0245001
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0007175
[Epoch 82] ogbg-molhiv: 0.723894 val loss: 3.869759
[Epoch 82] ogbg-molhiv: 0.709226 test loss: 1.015605
[Epoch 83; Iter    16/ 1097] train: loss: 0.0079551
[Epoch 83; Iter    46/ 1097] train: loss: 0.0092641
[Epoch 83; Iter    76/ 1097] train: loss: 0.0109522
[Epoch 83; Iter   106/ 1097] train: loss: 0.0012901
[Epoch 83; Iter   136/ 1097] train: loss: 0.0022729
[Epoch 83; Iter   166/ 1097] train: loss: 0.0002284
[Epoch 83; Iter   196/ 1097] train: loss: 0.0005289
[Epoch 83; Iter   226/ 1097] train: loss: 0.0146457
[Epoch 83; Iter   256/ 1097] train: loss: 0.0002087
[Epoch 83; Iter   286/ 1097] train: loss: 0.0102595
[Epoch 83; Iter   316/ 1097] train: loss: 0.0026302
[Epoch 83; Iter   346/ 1097] train: loss: 0.0005937
[Epoch 83; Iter   376/ 1097] train: loss: 0.0016694
[Epoch 83; Iter   406/ 1097] train: loss: 0.0116245
[Epoch 83; Iter   436/ 1097] train: loss: 0.0002544
[Epoch 83; Iter   466/ 1097] train: loss: 0.0067706
[Epoch 83; Iter   496/ 1097] train: loss: 0.0082444
[Epoch 83; Iter   526/ 1097] train: loss: 0.0027213
[Epoch 83; Iter   556/ 1097] train: loss: 0.0288210
[Epoch 83; Iter   586/ 1097] train: loss: 0.0017819
[Epoch 83; Iter   616/ 1097] train: loss: 0.0017945
[Epoch 83; Iter   646/ 1097] train: loss: 0.0006375
[Epoch 83; Iter   676/ 1097] train: loss: 0.0002261
[Epoch 83; Iter   706/ 1097] train: loss: 0.0001731
[Epoch 83; Iter   736/ 1097] train: loss: 0.0002625
[Epoch 83; Iter   766/ 1097] train: loss: 0.0010004
[Epoch 83; Iter   796/ 1097] train: loss: 0.0010953
[Epoch 83; Iter   826/ 1097] train: loss: 0.0701346
[Epoch 83; Iter   856/ 1097] train: loss: 0.0420745
[Epoch 83; Iter   886/ 1097] train: loss: 0.0005306
[Epoch 83; Iter   916/ 1097] train: loss: 0.0127333
[Epoch 83; Iter   946/ 1097] train: loss: 0.0003118
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000940
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0706271
[Epoch 83; Iter  1036/ 1097] train: loss: 0.1306162
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0002384
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0086771
[Epoch 83] ogbg-molhiv: 0.715930 val loss: 3.875791
[Epoch 83] ogbg-molhiv: 0.712963 test loss: 1.652208
[Epoch 84; Iter    29/ 1097] train: loss: 0.0000159
[Epoch 84; Iter    59/ 1097] train: loss: 0.0002816
[Epoch 84; Iter    89/ 1097] train: loss: 0.0002315
[Epoch 84; Iter   119/ 1097] train: loss: 0.0067543
[Epoch 84; Iter   149/ 1097] train: loss: 0.0040258
[Epoch 84; Iter   179/ 1097] train: loss: 0.0019143
[Epoch 84; Iter   209/ 1097] train: loss: 0.0016870
[Epoch 84; Iter   239/ 1097] train: loss: 0.0007603
[Epoch 84; Iter   269/ 1097] train: loss: 0.0056956
[Epoch 84; Iter   299/ 1097] train: loss: 0.0008323
[Epoch 84; Iter   329/ 1097] train: loss: 0.0037326
[Epoch 84; Iter   359/ 1097] train: loss: 0.0008318
[Epoch 84; Iter   389/ 1097] train: loss: 0.0000631
[Epoch 84; Iter   419/ 1097] train: loss: 0.0019050
[Epoch 84; Iter   449/ 1097] train: loss: 0.0013283
[Epoch 84; Iter   479/ 1097] train: loss: 0.0007716
[Epoch 84; Iter   509/ 1097] train: loss: 0.0009656
[Epoch 84; Iter   539/ 1097] train: loss: 0.0144264
[Epoch 84; Iter   569/ 1097] train: loss: 0.0046654
[Epoch 84; Iter   599/ 1097] train: loss: 0.0001514
[Epoch 84; Iter   629/ 1097] train: loss: 0.0036116
[Epoch 84; Iter   659/ 1097] train: loss: 0.0001451
[Epoch 84; Iter   689/ 1097] train: loss: 0.0002351
[Epoch 84; Iter   719/ 1097] train: loss: 0.0053749
[Epoch 84; Iter   749/ 1097] train: loss: 0.0092526
[Epoch 84; Iter   779/ 1097] train: loss: 0.0003358
[Epoch 84; Iter   809/ 1097] train: loss: 0.0020520
[Epoch 84; Iter   839/ 1097] train: loss: 0.0037274
[Epoch 84; Iter   869/ 1097] train: loss: 0.0006117
[Epoch 84; Iter   899/ 1097] train: loss: 0.0247778
[Epoch 84; Iter   929/ 1097] train: loss: 0.0058153
[Epoch 84; Iter   959/ 1097] train: loss: 0.0000110
[Epoch 84; Iter   989/ 1097] train: loss: 0.0004530
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0012108
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0026624
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0027714
[Epoch 84] ogbg-molhiv: 0.710235 val loss: 1.825398
[Epoch 84] ogbg-molhiv: 0.688507 test loss: 0.918504
[Epoch 85; Iter    12/ 1097] train: loss: 0.0003992
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000298
[Epoch 85; Iter    72/ 1097] train: loss: 0.1124970
[Epoch 85; Iter   102/ 1097] train: loss: 0.0038489
[Epoch 85; Iter   132/ 1097] train: loss: 0.0003487
[Epoch 85; Iter   162/ 1097] train: loss: 0.0001192
[Epoch 85; Iter   192/ 1097] train: loss: 0.0002260
[Epoch 85; Iter   222/ 1097] train: loss: 0.0007821
[Epoch 85; Iter   252/ 1097] train: loss: 0.0006348
[Epoch 85; Iter   282/ 1097] train: loss: 0.0357915
[Epoch 85; Iter   312/ 1097] train: loss: 0.0033631
[Epoch 85; Iter   342/ 1097] train: loss: 0.0105095
[Epoch 85; Iter   372/ 1097] train: loss: 0.1095427
[Epoch 85; Iter   402/ 1097] train: loss: 0.0005573
[Epoch 81; Iter   350/ 1097] train: loss: 0.0005001
[Epoch 81; Iter   380/ 1097] train: loss: 0.0000192
[Epoch 81; Iter   410/ 1097] train: loss: 0.0002461
[Epoch 81; Iter   440/ 1097] train: loss: 0.0000153
[Epoch 81; Iter   470/ 1097] train: loss: 0.0003018
[Epoch 81; Iter   500/ 1097] train: loss: 0.0000196
[Epoch 81; Iter   530/ 1097] train: loss: 0.0001152
[Epoch 81; Iter   560/ 1097] train: loss: 0.0000834
[Epoch 81; Iter   590/ 1097] train: loss: 0.0000529
[Epoch 81; Iter   620/ 1097] train: loss: 0.0007681
[Epoch 81; Iter   650/ 1097] train: loss: 0.0002410
[Epoch 81; Iter   680/ 1097] train: loss: 0.0479605
[Epoch 81; Iter   710/ 1097] train: loss: 0.0001239
[Epoch 81; Iter   740/ 1097] train: loss: 0.0000191
[Epoch 81; Iter   770/ 1097] train: loss: 0.0030045
[Epoch 81; Iter   800/ 1097] train: loss: 0.0000581
[Epoch 81; Iter   830/ 1097] train: loss: 0.0000722
[Epoch 81; Iter   860/ 1097] train: loss: 0.0000048
[Epoch 81; Iter   890/ 1097] train: loss: 0.0000096
[Epoch 81; Iter   920/ 1097] train: loss: 0.0000534
[Epoch 81; Iter   950/ 1097] train: loss: 0.0002938
[Epoch 81; Iter   980/ 1097] train: loss: 0.0000291
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0003393
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0003515
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0000946
[Epoch 81] ogbg-molhiv: 0.773699 val loss: 0.241110
[Epoch 81] ogbg-molhiv: 0.716617 test loss: 0.394079
[Epoch 82; Iter     3/ 1097] train: loss: 0.0002494
[Epoch 82; Iter    33/ 1097] train: loss: 0.0006150
[Epoch 82; Iter    63/ 1097] train: loss: 0.0006561
[Epoch 82; Iter    93/ 1097] train: loss: 0.0002943
[Epoch 82; Iter   123/ 1097] train: loss: 0.0001561
[Epoch 82; Iter   153/ 1097] train: loss: 0.0001663
[Epoch 82; Iter   183/ 1097] train: loss: 0.0031360
[Epoch 82; Iter   213/ 1097] train: loss: 0.0001452
[Epoch 82; Iter   243/ 1097] train: loss: 0.0000045
[Epoch 82; Iter   273/ 1097] train: loss: 0.0199811
[Epoch 82; Iter   303/ 1097] train: loss: 0.0033949
[Epoch 82; Iter   333/ 1097] train: loss: 0.0016347
[Epoch 82; Iter   363/ 1097] train: loss: 0.0010335
[Epoch 82; Iter   393/ 1097] train: loss: 0.0001413
[Epoch 82; Iter   423/ 1097] train: loss: 0.0003229
[Epoch 82; Iter   453/ 1097] train: loss: 0.0000552
[Epoch 82; Iter   483/ 1097] train: loss: 0.0000318
[Epoch 82; Iter   513/ 1097] train: loss: 0.0000601
[Epoch 82; Iter   543/ 1097] train: loss: 0.0398519
[Epoch 82; Iter   573/ 1097] train: loss: 0.0009580
[Epoch 82; Iter   603/ 1097] train: loss: 0.0000520
[Epoch 82; Iter   633/ 1097] train: loss: 0.0001079
[Epoch 82; Iter   663/ 1097] train: loss: 0.0008188
[Epoch 82; Iter   693/ 1097] train: loss: 0.0000462
[Epoch 82; Iter   723/ 1097] train: loss: 0.0031835
[Epoch 82; Iter   753/ 1097] train: loss: 0.0181840
[Epoch 82; Iter   783/ 1097] train: loss: 0.0015319
[Epoch 82; Iter   813/ 1097] train: loss: 0.0001064
[Epoch 82; Iter   843/ 1097] train: loss: 0.0001960
[Epoch 82; Iter   873/ 1097] train: loss: 0.0023600
[Epoch 82; Iter   903/ 1097] train: loss: 0.0176045
[Epoch 82; Iter   933/ 1097] train: loss: 0.0022082
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000148
[Epoch 82; Iter   993/ 1097] train: loss: 0.0001048
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0001819
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0004846
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0041259
[Epoch 82] ogbg-molhiv: 0.748913 val loss: 0.245979
[Epoch 82] ogbg-molhiv: 0.714929 test loss: 0.362953
[Epoch 83; Iter    16/ 1097] train: loss: 0.0000922
[Epoch 83; Iter    46/ 1097] train: loss: 0.0009125
[Epoch 83; Iter    76/ 1097] train: loss: 0.0001029
[Epoch 83; Iter   106/ 1097] train: loss: 0.0009723
[Epoch 83; Iter   136/ 1097] train: loss: 0.0002076
[Epoch 83; Iter   166/ 1097] train: loss: 0.0001086
[Epoch 83; Iter   196/ 1097] train: loss: 0.0004422
[Epoch 83; Iter   226/ 1097] train: loss: 0.0000248
[Epoch 83; Iter   256/ 1097] train: loss: 0.0080158
[Epoch 83; Iter   286/ 1097] train: loss: 0.0006452
[Epoch 83; Iter   316/ 1097] train: loss: 0.0042671
[Epoch 83; Iter   346/ 1097] train: loss: 0.0011911
[Epoch 83; Iter   376/ 1097] train: loss: 0.0012054
[Epoch 83; Iter   406/ 1097] train: loss: 0.0004082
[Epoch 83; Iter   436/ 1097] train: loss: 0.0000704
[Epoch 83; Iter   466/ 1097] train: loss: 0.0023468
[Epoch 83; Iter   496/ 1097] train: loss: 0.0000294
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000968
[Epoch 83; Iter   556/ 1097] train: loss: 0.0000069
[Epoch 83; Iter   586/ 1097] train: loss: 0.0002006
[Epoch 83; Iter   616/ 1097] train: loss: 0.0009533
[Epoch 83; Iter   646/ 1097] train: loss: 0.0054534
[Epoch 83; Iter   676/ 1097] train: loss: 0.0002124
[Epoch 83; Iter   706/ 1097] train: loss: 0.0012801
[Epoch 83; Iter   736/ 1097] train: loss: 0.0001839
[Epoch 83; Iter   766/ 1097] train: loss: 0.0000875
[Epoch 83; Iter   796/ 1097] train: loss: 0.0671771
[Epoch 83; Iter   826/ 1097] train: loss: 0.1549843
[Epoch 83; Iter   856/ 1097] train: loss: 0.0000304
[Epoch 83; Iter   886/ 1097] train: loss: 0.0007431
[Epoch 83; Iter   916/ 1097] train: loss: 0.0000338
[Epoch 83; Iter   946/ 1097] train: loss: 0.0000486
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000949
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0006354
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0000751
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0000898
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0506044
[Epoch 83] ogbg-molhiv: 0.769997 val loss: 0.232956
[Epoch 83] ogbg-molhiv: 0.710429 test loss: 0.383052
[Epoch 84; Iter    29/ 1097] train: loss: 0.0000295
[Epoch 84; Iter    59/ 1097] train: loss: 0.0001431
[Epoch 84; Iter    89/ 1097] train: loss: 0.0041795
[Epoch 84; Iter   119/ 1097] train: loss: 0.0000139
[Epoch 84; Iter   149/ 1097] train: loss: 0.0049392
[Epoch 84; Iter   179/ 1097] train: loss: 0.0001513
[Epoch 84; Iter   209/ 1097] train: loss: 0.0404262
[Epoch 84; Iter   239/ 1097] train: loss: 0.0019818
[Epoch 84; Iter   269/ 1097] train: loss: 0.0115407
[Epoch 84; Iter   299/ 1097] train: loss: 0.0000166
[Epoch 84; Iter   329/ 1097] train: loss: 0.0007370
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000231
[Epoch 84; Iter   389/ 1097] train: loss: 0.0000468
[Epoch 84; Iter   419/ 1097] train: loss: 0.0006655
[Epoch 84; Iter   449/ 1097] train: loss: 0.0000299
[Epoch 84; Iter   479/ 1097] train: loss: 0.0000170
[Epoch 84; Iter   509/ 1097] train: loss: 0.0000443
[Epoch 84; Iter   539/ 1097] train: loss: 0.0093763
[Epoch 84; Iter   569/ 1097] train: loss: 0.0013338
[Epoch 84; Iter   599/ 1097] train: loss: 0.0000779
[Epoch 84; Iter   629/ 1097] train: loss: 0.0000106
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000008
[Epoch 84; Iter   689/ 1097] train: loss: 0.0000683
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000277
[Epoch 84; Iter   749/ 1097] train: loss: 0.0000125
[Epoch 84; Iter   779/ 1097] train: loss: 0.0000172
[Epoch 84; Iter   809/ 1097] train: loss: 0.0000586
[Epoch 84; Iter   839/ 1097] train: loss: 0.0000297
[Epoch 84; Iter   869/ 1097] train: loss: 0.0000300
[Epoch 84; Iter   899/ 1097] train: loss: 0.0148834
[Epoch 84; Iter   929/ 1097] train: loss: 0.0002825
[Epoch 84; Iter   959/ 1097] train: loss: 0.0000100
[Epoch 84; Iter   989/ 1097] train: loss: 0.0004372
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0000255
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0001517
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0000932
[Epoch 84] ogbg-molhiv: 0.765518 val loss: 0.241703
[Epoch 84] ogbg-molhiv: 0.723513 test loss: 0.378728
[Epoch 85; Iter    12/ 1097] train: loss: 0.0002169
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000394
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000253
[Epoch 85; Iter   102/ 1097] train: loss: 0.0001613
[Epoch 85; Iter   132/ 1097] train: loss: 0.0000044
[Epoch 85; Iter   162/ 1097] train: loss: 0.0000019
[Epoch 85; Iter   192/ 1097] train: loss: 0.0001118
[Epoch 85; Iter   222/ 1097] train: loss: 0.1488048
[Epoch 85; Iter   252/ 1097] train: loss: 0.0009240
[Epoch 85; Iter   282/ 1097] train: loss: 0.0001030
[Epoch 85; Iter   312/ 1097] train: loss: 0.0045144
[Epoch 85; Iter   342/ 1097] train: loss: 0.0006611
[Epoch 85; Iter   372/ 1097] train: loss: 0.0002539
[Epoch 85; Iter   402/ 1097] train: loss: 0.0000706
[Epoch 81; Iter   350/ 1097] train: loss: 0.0015326
[Epoch 81; Iter   380/ 1097] train: loss: 0.0000443
[Epoch 81; Iter   410/ 1097] train: loss: 0.0000187
[Epoch 81; Iter   440/ 1097] train: loss: 0.0001089
[Epoch 81; Iter   470/ 1097] train: loss: 0.0000739
[Epoch 81; Iter   500/ 1097] train: loss: 0.0017542
[Epoch 81; Iter   530/ 1097] train: loss: 0.0030541
[Epoch 81; Iter   560/ 1097] train: loss: 0.0004717
[Epoch 81; Iter   590/ 1097] train: loss: 0.0001115
[Epoch 81; Iter   620/ 1097] train: loss: 0.0002798
[Epoch 81; Iter   650/ 1097] train: loss: 0.0000376
[Epoch 81; Iter   680/ 1097] train: loss: 0.0004873
[Epoch 81; Iter   710/ 1097] train: loss: 0.0014196
[Epoch 81; Iter   740/ 1097] train: loss: 0.0001844
[Epoch 81; Iter   770/ 1097] train: loss: 0.0395817
[Epoch 81; Iter   800/ 1097] train: loss: 0.0009134
[Epoch 81; Iter   830/ 1097] train: loss: 0.0004702
[Epoch 81; Iter   860/ 1097] train: loss: 0.0007159
[Epoch 81; Iter   890/ 1097] train: loss: 0.0000206
[Epoch 81; Iter   920/ 1097] train: loss: 0.0002255
[Epoch 81; Iter   950/ 1097] train: loss: 0.0008528
[Epoch 81; Iter   980/ 1097] train: loss: 0.0167771
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0003127
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0036106
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0000415
[Epoch 81] ogbg-molhiv: 0.796140 val loss: 0.276176
[Epoch 81] ogbg-molhiv: 0.728481 test loss: 0.402068
[Epoch 82; Iter     3/ 1097] train: loss: 0.0055406
[Epoch 82; Iter    33/ 1097] train: loss: 0.0000575
[Epoch 82; Iter    63/ 1097] train: loss: 0.0001058
[Epoch 82; Iter    93/ 1097] train: loss: 0.0000545
[Epoch 82; Iter   123/ 1097] train: loss: 0.0000441
[Epoch 82; Iter   153/ 1097] train: loss: 0.0026773
[Epoch 82; Iter   183/ 1097] train: loss: 0.0000418
[Epoch 82; Iter   213/ 1097] train: loss: 0.0010762
[Epoch 82; Iter   243/ 1097] train: loss: 0.0472448
[Epoch 82; Iter   273/ 1097] train: loss: 0.0005222
[Epoch 82; Iter   303/ 1097] train: loss: 0.0002631
[Epoch 82; Iter   333/ 1097] train: loss: 0.0011545
[Epoch 82; Iter   363/ 1097] train: loss: 0.0004008
[Epoch 82; Iter   393/ 1097] train: loss: 0.0000347
[Epoch 82; Iter   423/ 1097] train: loss: 0.0000198
[Epoch 82; Iter   453/ 1097] train: loss: 0.0000709
[Epoch 82; Iter   483/ 1097] train: loss: 0.0000099
[Epoch 82; Iter   513/ 1097] train: loss: 0.0009101
[Epoch 82; Iter   543/ 1097] train: loss: 0.0001066
[Epoch 82; Iter   573/ 1097] train: loss: 0.0000956
[Epoch 82; Iter   603/ 1097] train: loss: 0.0004063
[Epoch 82; Iter   633/ 1097] train: loss: 0.0000241
[Epoch 82; Iter   663/ 1097] train: loss: 0.0291761
[Epoch 82; Iter   693/ 1097] train: loss: 0.0000349
[Epoch 82; Iter   723/ 1097] train: loss: 0.0009859
[Epoch 82; Iter   753/ 1097] train: loss: 0.0000500
[Epoch 82; Iter   783/ 1097] train: loss: 0.0002192
[Epoch 82; Iter   813/ 1097] train: loss: 0.0000190
[Epoch 82; Iter   843/ 1097] train: loss: 0.0041970
[Epoch 82; Iter   873/ 1097] train: loss: 0.0000272
[Epoch 82; Iter   903/ 1097] train: loss: 0.0000116
[Epoch 82; Iter   933/ 1097] train: loss: 0.0003221
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000720
[Epoch 82; Iter   993/ 1097] train: loss: 0.0002155
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0000764
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0003208
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0000248
[Epoch 82] ogbg-molhiv: 0.781933 val loss: 0.299520
[Epoch 82] ogbg-molhiv: 0.725962 test loss: 0.384322
[Epoch 83; Iter    16/ 1097] train: loss: 0.0000772
[Epoch 83; Iter    46/ 1097] train: loss: 0.0000611
[Epoch 83; Iter    76/ 1097] train: loss: 0.0003244
[Epoch 83; Iter   106/ 1097] train: loss: 0.0000670
[Epoch 83; Iter   136/ 1097] train: loss: 0.0000868
[Epoch 83; Iter   166/ 1097] train: loss: 0.0008760
[Epoch 83; Iter   196/ 1097] train: loss: 0.0000499
[Epoch 83; Iter   226/ 1097] train: loss: 0.0001290
[Epoch 83; Iter   256/ 1097] train: loss: 0.0000164
[Epoch 83; Iter   286/ 1097] train: loss: 0.0001191
[Epoch 83; Iter   316/ 1097] train: loss: 0.0000241
[Epoch 83; Iter   346/ 1097] train: loss: 0.0007490
[Epoch 83; Iter   376/ 1097] train: loss: 0.0001016
[Epoch 83; Iter   406/ 1097] train: loss: 0.0000997
[Epoch 83; Iter   436/ 1097] train: loss: 0.0000760
[Epoch 83; Iter   466/ 1097] train: loss: 0.0006338
[Epoch 83; Iter   496/ 1097] train: loss: 0.0003895
[Epoch 83; Iter   526/ 1097] train: loss: 0.0034352
[Epoch 83; Iter   556/ 1097] train: loss: 0.0013720
[Epoch 83; Iter   586/ 1097] train: loss: 0.0032184
[Epoch 83; Iter   616/ 1097] train: loss: 0.0005862
[Epoch 83; Iter   646/ 1097] train: loss: 0.0000154
[Epoch 83; Iter   676/ 1097] train: loss: 0.0000042
[Epoch 83; Iter   706/ 1097] train: loss: 0.0003043
[Epoch 83; Iter   736/ 1097] train: loss: 0.0000153
[Epoch 83; Iter   766/ 1097] train: loss: 0.0009678
[Epoch 83; Iter   796/ 1097] train: loss: 0.0015917
[Epoch 83; Iter   826/ 1097] train: loss: 0.0014644
[Epoch 83; Iter   856/ 1097] train: loss: 0.0007277
[Epoch 83; Iter   886/ 1097] train: loss: 0.0235465
[Epoch 83; Iter   916/ 1097] train: loss: 0.0039892
[Epoch 83; Iter   946/ 1097] train: loss: 0.0000040
[Epoch 83; Iter   976/ 1097] train: loss: 0.0004786
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0018960
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0061279
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0000992
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0005774
[Epoch 83] ogbg-molhiv: 0.799407 val loss: 0.285572
[Epoch 83] ogbg-molhiv: 0.747295 test loss: 0.416091
[Epoch 84; Iter    29/ 1097] train: loss: 0.0005072
[Epoch 84; Iter    59/ 1097] train: loss: 0.0000183
[Epoch 84; Iter    89/ 1097] train: loss: 0.0000866
[Epoch 84; Iter   119/ 1097] train: loss: 0.0004980
[Epoch 84; Iter   149/ 1097] train: loss: 0.0000278
[Epoch 84; Iter   179/ 1097] train: loss: 0.0000290
[Epoch 84; Iter   209/ 1097] train: loss: 0.0001269
[Epoch 84; Iter   239/ 1097] train: loss: 0.0000546
[Epoch 84; Iter   269/ 1097] train: loss: 0.0006602
[Epoch 84; Iter   299/ 1097] train: loss: 0.0001965
[Epoch 84; Iter   329/ 1097] train: loss: 0.0001037
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000718
[Epoch 84; Iter   389/ 1097] train: loss: 0.0000429
[Epoch 84; Iter   419/ 1097] train: loss: 0.0003420
[Epoch 84; Iter   449/ 1097] train: loss: 0.0000236
[Epoch 84; Iter   479/ 1097] train: loss: 0.0003238
[Epoch 84; Iter   509/ 1097] train: loss: 0.0006137
[Epoch 84; Iter   539/ 1097] train: loss: 0.0026684
[Epoch 84; Iter   569/ 1097] train: loss: 0.0006277
[Epoch 84; Iter   599/ 1097] train: loss: 0.0001187
[Epoch 84; Iter   629/ 1097] train: loss: 0.0023362
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000863
[Epoch 84; Iter   689/ 1097] train: loss: 0.0000200
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000247
[Epoch 84; Iter   749/ 1097] train: loss: 0.0000225
[Epoch 84; Iter   779/ 1097] train: loss: 0.0000270
[Epoch 84; Iter   809/ 1097] train: loss: 0.0006760
[Epoch 84; Iter   839/ 1097] train: loss: 0.0000121
[Epoch 84; Iter   869/ 1097] train: loss: 0.0206273
[Epoch 84; Iter   899/ 1097] train: loss: 0.0003160
[Epoch 84; Iter   929/ 1097] train: loss: 0.0000755
[Epoch 84; Iter   959/ 1097] train: loss: 0.0010492
[Epoch 84; Iter   989/ 1097] train: loss: 0.0001426
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0000914
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0001600
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0001829
[Epoch 84] ogbg-molhiv: 0.789370 val loss: 0.270741
[Epoch 84] ogbg-molhiv: 0.726308 test loss: 0.497966
[Epoch 85; Iter    12/ 1097] train: loss: 0.0001969
[Epoch 85; Iter    42/ 1097] train: loss: 0.0002385
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000762
[Epoch 85; Iter   102/ 1097] train: loss: 0.0007203
[Epoch 85; Iter   132/ 1097] train: loss: 0.0007867
[Epoch 85; Iter   162/ 1097] train: loss: 0.0000107
[Epoch 85; Iter   192/ 1097] train: loss: 0.0000718
[Epoch 85; Iter   222/ 1097] train: loss: 0.0001997
[Epoch 85; Iter   252/ 1097] train: loss: 0.0002002
[Epoch 85; Iter   282/ 1097] train: loss: 0.0002784
[Epoch 85; Iter   312/ 1097] train: loss: 0.0006072
[Epoch 85; Iter   342/ 1097] train: loss: 0.0001307
[Epoch 85; Iter   372/ 1097] train: loss: 0.0005365
[Epoch 85; Iter   402/ 1097] train: loss: 0.0000463
[Epoch 81; Iter   350/ 1097] train: loss: 0.0002741
[Epoch 81; Iter   380/ 1097] train: loss: 0.0004019
[Epoch 81; Iter   410/ 1097] train: loss: 0.0000865
[Epoch 81; Iter   440/ 1097] train: loss: 0.0000678
[Epoch 81; Iter   470/ 1097] train: loss: 0.0007773
[Epoch 81; Iter   500/ 1097] train: loss: 0.0000690
[Epoch 81; Iter   530/ 1097] train: loss: 0.0001241
[Epoch 81; Iter   560/ 1097] train: loss: 0.0056076
[Epoch 81; Iter   590/ 1097] train: loss: 0.0000202
[Epoch 81; Iter   620/ 1097] train: loss: 0.0001327
[Epoch 81; Iter   650/ 1097] train: loss: 0.0001533
[Epoch 81; Iter   680/ 1097] train: loss: 0.0001573
[Epoch 81; Iter   710/ 1097] train: loss: 0.0009436
[Epoch 81; Iter   740/ 1097] train: loss: 0.0000580
[Epoch 81; Iter   770/ 1097] train: loss: 0.0001369
[Epoch 81; Iter   800/ 1097] train: loss: 0.0557064
[Epoch 81; Iter   830/ 1097] train: loss: 0.0000231
[Epoch 81; Iter   860/ 1097] train: loss: 0.0000605
[Epoch 81; Iter   890/ 1097] train: loss: 0.0000585
[Epoch 81; Iter   920/ 1097] train: loss: 0.0008865
[Epoch 81; Iter   950/ 1097] train: loss: 0.0004622
[Epoch 81; Iter   980/ 1097] train: loss: 0.0000585
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0017969
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0000259
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0001213
[Epoch 81] ogbg-molhiv: 0.765643 val loss: 0.370581
[Epoch 81] ogbg-molhiv: 0.761511 test loss: 0.374803
[Epoch 82; Iter     3/ 1097] train: loss: 0.0008807
[Epoch 82; Iter    33/ 1097] train: loss: 0.0000428
[Epoch 82; Iter    63/ 1097] train: loss: 0.0000293
[Epoch 82; Iter    93/ 1097] train: loss: 0.0008520
[Epoch 82; Iter   123/ 1097] train: loss: 0.0013899
[Epoch 82; Iter   153/ 1097] train: loss: 0.0036543
[Epoch 82; Iter   183/ 1097] train: loss: 0.0005282
[Epoch 82; Iter   213/ 1097] train: loss: 0.0139439
[Epoch 82; Iter   243/ 1097] train: loss: 0.0000311
[Epoch 82; Iter   273/ 1097] train: loss: 0.0004047
[Epoch 82; Iter   303/ 1097] train: loss: 0.0000795
[Epoch 82; Iter   333/ 1097] train: loss: 0.0000745
[Epoch 82; Iter   363/ 1097] train: loss: 0.0001760
[Epoch 82; Iter   393/ 1097] train: loss: 0.0001298
[Epoch 82; Iter   423/ 1097] train: loss: 0.0003340
[Epoch 82; Iter   453/ 1097] train: loss: 0.0002992
[Epoch 82; Iter   483/ 1097] train: loss: 0.0002524
[Epoch 82; Iter   513/ 1097] train: loss: 0.0000371
[Epoch 82; Iter   543/ 1097] train: loss: 0.0000650
[Epoch 82; Iter   573/ 1097] train: loss: 0.0000316
[Epoch 82; Iter   603/ 1097] train: loss: 0.0001139
[Epoch 82; Iter   633/ 1097] train: loss: 0.0000767
[Epoch 82; Iter   663/ 1097] train: loss: 0.0008395
[Epoch 82; Iter   693/ 1097] train: loss: 0.0011028
[Epoch 82; Iter   723/ 1097] train: loss: 0.0027614
[Epoch 82; Iter   753/ 1097] train: loss: 0.0001214
[Epoch 82; Iter   783/ 1097] train: loss: 0.0099821
[Epoch 82; Iter   813/ 1097] train: loss: 0.0004468
[Epoch 82; Iter   843/ 1097] train: loss: 0.0000512
[Epoch 82; Iter   873/ 1097] train: loss: 0.0000451
[Epoch 82; Iter   903/ 1097] train: loss: 0.0004049
[Epoch 82; Iter   933/ 1097] train: loss: 0.0000703
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000340
[Epoch 82; Iter   993/ 1097] train: loss: 0.0000231
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0000551
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0000586
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0014274
[Epoch 82] ogbg-molhiv: 0.762226 val loss: 0.401934
[Epoch 82] ogbg-molhiv: 0.754192 test loss: 0.363133
[Epoch 83; Iter    16/ 1097] train: loss: 0.0001971
[Epoch 83; Iter    46/ 1097] train: loss: 0.0003629
[Epoch 83; Iter    76/ 1097] train: loss: 0.0002597
[Epoch 83; Iter   106/ 1097] train: loss: 0.0002099
[Epoch 83; Iter   136/ 1097] train: loss: 0.0014911
[Epoch 83; Iter   166/ 1097] train: loss: 0.0000303
[Epoch 83; Iter   196/ 1097] train: loss: 0.0001995
[Epoch 83; Iter   226/ 1097] train: loss: 0.0009566
[Epoch 83; Iter   256/ 1097] train: loss: 0.0000896
[Epoch 83; Iter   286/ 1097] train: loss: 0.0022883
[Epoch 83; Iter   316/ 1097] train: loss: 0.0000344
[Epoch 83; Iter   346/ 1097] train: loss: 0.0004229
[Epoch 83; Iter   376/ 1097] train: loss: 0.0008247
[Epoch 83; Iter   406/ 1097] train: loss: 0.0001279
[Epoch 83; Iter   436/ 1097] train: loss: 0.0006123
[Epoch 83; Iter   466/ 1097] train: loss: 0.0003260
[Epoch 83; Iter   496/ 1097] train: loss: 0.0000035
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000108
[Epoch 83; Iter   556/ 1097] train: loss: 0.0030054
[Epoch 83; Iter   586/ 1097] train: loss: 0.0050708
[Epoch 83; Iter   616/ 1097] train: loss: 0.0000975
[Epoch 83; Iter   646/ 1097] train: loss: 0.0046210
[Epoch 83; Iter   676/ 1097] train: loss: 0.0000102
[Epoch 83; Iter   706/ 1097] train: loss: 0.0001011
[Epoch 83; Iter   736/ 1097] train: loss: 0.0000201
[Epoch 83; Iter   766/ 1097] train: loss: 0.0006136
[Epoch 83; Iter   796/ 1097] train: loss: 0.0000390
[Epoch 83; Iter   826/ 1097] train: loss: 0.0003795
[Epoch 83; Iter   856/ 1097] train: loss: 0.0000662
[Epoch 83; Iter   886/ 1097] train: loss: 0.0015841
[Epoch 83; Iter   916/ 1097] train: loss: 0.0002884
[Epoch 83; Iter   946/ 1097] train: loss: 0.0001487
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000191
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0001948
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0001544
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0008470
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0001359
[Epoch 83] ogbg-molhiv: 0.760141 val loss: 0.370234
[Epoch 83] ogbg-molhiv: 0.748877 test loss: 0.370548
[Epoch 84; Iter    29/ 1097] train: loss: 0.0008084
[Epoch 84; Iter    59/ 1097] train: loss: 0.0001033
[Epoch 84; Iter    89/ 1097] train: loss: 0.0000006
[Epoch 84; Iter   119/ 1097] train: loss: 0.0004397
[Epoch 84; Iter   149/ 1097] train: loss: 0.0000444
[Epoch 84; Iter   179/ 1097] train: loss: 0.0000054
[Epoch 84; Iter   209/ 1097] train: loss: 0.0007356
[Epoch 84; Iter   239/ 1097] train: loss: 0.0457911
[Epoch 84; Iter   269/ 1097] train: loss: 0.0001863
[Epoch 84; Iter   299/ 1097] train: loss: 0.0000053
[Epoch 84; Iter   329/ 1097] train: loss: 0.0050295
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000188
[Epoch 84; Iter   389/ 1097] train: loss: 0.0037214
[Epoch 84; Iter   419/ 1097] train: loss: 0.0001046
[Epoch 84; Iter   449/ 1097] train: loss: 0.0000602
[Epoch 84; Iter   479/ 1097] train: loss: 0.0000524
[Epoch 84; Iter   509/ 1097] train: loss: 0.0000191
[Epoch 84; Iter   539/ 1097] train: loss: 0.0022601
[Epoch 84; Iter   569/ 1097] train: loss: 0.0000183
[Epoch 84; Iter   599/ 1097] train: loss: 0.0003964
[Epoch 84; Iter   629/ 1097] train: loss: 0.0003190
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000723
[Epoch 84; Iter   689/ 1097] train: loss: 0.0001443
[Epoch 84; Iter   719/ 1097] train: loss: 0.0001380
[Epoch 84; Iter   749/ 1097] train: loss: 0.0004232
[Epoch 84; Iter   779/ 1097] train: loss: 0.0000232
[Epoch 84; Iter   809/ 1097] train: loss: 0.0000032
[Epoch 84; Iter   839/ 1097] train: loss: 0.0001684
[Epoch 84; Iter   869/ 1097] train: loss: 0.0004893
[Epoch 84; Iter   899/ 1097] train: loss: 0.0007923
[Epoch 84; Iter   929/ 1097] train: loss: 0.0012223
[Epoch 84; Iter   959/ 1097] train: loss: 0.0001382
[Epoch 84; Iter   989/ 1097] train: loss: 0.0000337
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0106565
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0006319
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0002719
[Epoch 84] ogbg-molhiv: 0.759599 val loss: 0.383779
[Epoch 84] ogbg-molhiv: 0.753276 test loss: 0.363696
[Epoch 85; Iter    12/ 1097] train: loss: 0.0001414
[Epoch 85; Iter    42/ 1097] train: loss: 0.0001251
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000678
[Epoch 85; Iter   102/ 1097] train: loss: 0.0000783
[Epoch 85; Iter   132/ 1097] train: loss: 0.0002908
[Epoch 85; Iter   162/ 1097] train: loss: 0.0000162
[Epoch 85; Iter   192/ 1097] train: loss: 0.0000219
[Epoch 85; Iter   222/ 1097] train: loss: 0.0006434
[Epoch 85; Iter   252/ 1097] train: loss: 0.0006520
[Epoch 85; Iter   282/ 1097] train: loss: 0.0000375
[Epoch 85; Iter   312/ 1097] train: loss: 0.0001463
[Epoch 85; Iter   342/ 1097] train: loss: 0.0000271
[Epoch 85; Iter   372/ 1097] train: loss: 0.0002751
[Epoch 85; Iter   402/ 1097] train: loss: 0.0030291
[Epoch 81; Iter   350/ 1097] train: loss: 0.0002293
[Epoch 81; Iter   380/ 1097] train: loss: 0.0001303
[Epoch 81; Iter   410/ 1097] train: loss: 0.0002057
[Epoch 81; Iter   440/ 1097] train: loss: 0.0003812
[Epoch 81; Iter   470/ 1097] train: loss: 0.0000034
[Epoch 81; Iter   500/ 1097] train: loss: 0.0001227
[Epoch 81; Iter   530/ 1097] train: loss: 0.0000029
[Epoch 81; Iter   560/ 1097] train: loss: 0.0000697
[Epoch 81; Iter   590/ 1097] train: loss: 0.0000239
[Epoch 81; Iter   620/ 1097] train: loss: 0.0000038
[Epoch 81; Iter   650/ 1097] train: loss: 0.0000046
[Epoch 81; Iter   680/ 1097] train: loss: 0.0000130
[Epoch 81; Iter   710/ 1097] train: loss: 0.0013563
[Epoch 81; Iter   740/ 1097] train: loss: 0.0001506
[Epoch 81; Iter   770/ 1097] train: loss: 0.0158547
[Epoch 81; Iter   800/ 1097] train: loss: 0.0015217
[Epoch 81; Iter   830/ 1097] train: loss: 0.0179206
[Epoch 81; Iter   860/ 1097] train: loss: 0.0046588
[Epoch 81; Iter   890/ 1097] train: loss: 0.0000068
[Epoch 81; Iter   920/ 1097] train: loss: 0.0002517
[Epoch 81; Iter   950/ 1097] train: loss: 0.0000303
[Epoch 81; Iter   980/ 1097] train: loss: 0.0001677
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0009382
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0000998
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0001189
[Epoch 81] ogbg-molhiv: 0.773996 val loss: 0.257274
[Epoch 81] ogbg-molhiv: 0.796933 test loss: 0.335104
[Epoch 82; Iter     3/ 1097] train: loss: 0.0000046
[Epoch 82; Iter    33/ 1097] train: loss: 0.0039461
[Epoch 82; Iter    63/ 1097] train: loss: 0.0000402
[Epoch 82; Iter    93/ 1097] train: loss: 0.0002506
[Epoch 82; Iter   123/ 1097] train: loss: 0.0000893
[Epoch 82; Iter   153/ 1097] train: loss: 0.0002686
[Epoch 82; Iter   183/ 1097] train: loss: 0.0001263
[Epoch 82; Iter   213/ 1097] train: loss: 0.0000306
[Epoch 82; Iter   243/ 1097] train: loss: 0.0000172
[Epoch 82; Iter   273/ 1097] train: loss: 0.0000269
[Epoch 82; Iter   303/ 1097] train: loss: 0.0002228
[Epoch 82; Iter   333/ 1097] train: loss: 0.0000282
[Epoch 82; Iter   363/ 1097] train: loss: 0.0002275
[Epoch 82; Iter   393/ 1097] train: loss: 0.0000059
[Epoch 82; Iter   423/ 1097] train: loss: 0.0017848
[Epoch 82; Iter   453/ 1097] train: loss: 0.0000277
[Epoch 82; Iter   483/ 1097] train: loss: 0.0011956
[Epoch 82; Iter   513/ 1097] train: loss: 0.0000067
[Epoch 82; Iter   543/ 1097] train: loss: 0.0001430
[Epoch 82; Iter   573/ 1097] train: loss: 0.0002558
[Epoch 82; Iter   603/ 1097] train: loss: 0.0009030
[Epoch 82; Iter   633/ 1097] train: loss: 0.0001342
[Epoch 82; Iter   663/ 1097] train: loss: 0.0008970
[Epoch 82; Iter   693/ 1097] train: loss: 0.0001474
[Epoch 82; Iter   723/ 1097] train: loss: 0.0000367
[Epoch 82; Iter   753/ 1097] train: loss: 0.0000643
[Epoch 82; Iter   783/ 1097] train: loss: 0.0000094
[Epoch 82; Iter   813/ 1097] train: loss: 0.0001801
[Epoch 82; Iter   843/ 1097] train: loss: 0.0000780
[Epoch 82; Iter   873/ 1097] train: loss: 0.0027436
[Epoch 82; Iter   903/ 1097] train: loss: 0.0003243
[Epoch 82; Iter   933/ 1097] train: loss: 0.0002642
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000043
[Epoch 82; Iter   993/ 1097] train: loss: 0.0025027
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0000991
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0000747
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0003322
[Epoch 82] ogbg-molhiv: 0.786406 val loss: 0.365690
[Epoch 82] ogbg-molhiv: 0.795603 test loss: 0.335255
[Epoch 83; Iter    16/ 1097] train: loss: 0.0000799
[Epoch 83; Iter    46/ 1097] train: loss: 0.0000068
[Epoch 83; Iter    76/ 1097] train: loss: 0.0000118
[Epoch 83; Iter   106/ 1097] train: loss: 0.0001782
[Epoch 83; Iter   136/ 1097] train: loss: 0.0001027
[Epoch 83; Iter   166/ 1097] train: loss: 0.0000033
[Epoch 83; Iter   196/ 1097] train: loss: 0.0003965
[Epoch 83; Iter   226/ 1097] train: loss: 0.0012139
[Epoch 83; Iter   256/ 1097] train: loss: 0.0000199
[Epoch 83; Iter   286/ 1097] train: loss: 0.0008054
[Epoch 83; Iter   316/ 1097] train: loss: 0.0001803
[Epoch 83; Iter   346/ 1097] train: loss: 0.0000011
[Epoch 83; Iter   376/ 1097] train: loss: 0.0013677
[Epoch 83; Iter   406/ 1097] train: loss: 0.0000512
[Epoch 83; Iter   436/ 1097] train: loss: 0.0006612
[Epoch 83; Iter   466/ 1097] train: loss: 0.0000230
[Epoch 83; Iter   496/ 1097] train: loss: 0.0000531
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000594
[Epoch 83; Iter   556/ 1097] train: loss: 0.0000940
[Epoch 83; Iter   586/ 1097] train: loss: 0.0000817
[Epoch 83; Iter   616/ 1097] train: loss: 0.0000838
[Epoch 83; Iter   646/ 1097] train: loss: 0.0003612
[Epoch 83; Iter   676/ 1097] train: loss: 0.0000432
[Epoch 83; Iter   706/ 1097] train: loss: 0.0022083
[Epoch 83; Iter   736/ 1097] train: loss: 0.0024521
[Epoch 83; Iter   766/ 1097] train: loss: 0.0000365
[Epoch 83; Iter   796/ 1097] train: loss: 0.0000382
[Epoch 83; Iter   826/ 1097] train: loss: 0.0002171
[Epoch 83; Iter   856/ 1097] train: loss: 0.0378446
[Epoch 83; Iter   886/ 1097] train: loss: 0.0000825
[Epoch 83; Iter   916/ 1097] train: loss: 0.0002027
[Epoch 83; Iter   946/ 1097] train: loss: 0.0000827
[Epoch 83; Iter   976/ 1097] train: loss: 0.0006746
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0010567
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0000343
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0007722
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0000059
[Epoch 83] ogbg-molhiv: 0.779511 val loss: 0.257471
[Epoch 83] ogbg-molhiv: 0.789131 test loss: 0.326605
[Epoch 84; Iter    29/ 1097] train: loss: 0.0000020
[Epoch 84; Iter    59/ 1097] train: loss: 0.0001451
[Epoch 84; Iter    89/ 1097] train: loss: 0.0002600
[Epoch 84; Iter   119/ 1097] train: loss: 0.0000608
[Epoch 84; Iter   149/ 1097] train: loss: 0.0004492
[Epoch 84; Iter   179/ 1097] train: loss: 0.0046806
[Epoch 84; Iter   209/ 1097] train: loss: 0.0000921
[Epoch 84; Iter   239/ 1097] train: loss: 0.0000432
[Epoch 84; Iter   269/ 1097] train: loss: 0.0000975
[Epoch 84; Iter   299/ 1097] train: loss: 0.0001776
[Epoch 84; Iter   329/ 1097] train: loss: 0.0013539
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000431
[Epoch 84; Iter   389/ 1097] train: loss: 0.0003634
[Epoch 84; Iter   419/ 1097] train: loss: 0.0001588
[Epoch 84; Iter   449/ 1097] train: loss: 0.0230912
[Epoch 84; Iter   479/ 1097] train: loss: 0.0000988
[Epoch 84; Iter   509/ 1097] train: loss: 0.0000428
[Epoch 84; Iter   539/ 1097] train: loss: 0.0000550
[Epoch 84; Iter   569/ 1097] train: loss: 0.0006122
[Epoch 84; Iter   599/ 1097] train: loss: 0.0004242
[Epoch 84; Iter   629/ 1097] train: loss: 0.0000183
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000584
[Epoch 84; Iter   689/ 1097] train: loss: 0.0537205
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000052
[Epoch 84; Iter   749/ 1097] train: loss: 0.0000724
[Epoch 84; Iter   779/ 1097] train: loss: 0.0000036
[Epoch 84; Iter   809/ 1097] train: loss: 0.0000306
[Epoch 84; Iter   839/ 1097] train: loss: 0.0003448
[Epoch 84; Iter   869/ 1097] train: loss: 0.0000905
[Epoch 84; Iter   899/ 1097] train: loss: 0.0004317
[Epoch 84; Iter   929/ 1097] train: loss: 0.0000282
[Epoch 84; Iter   959/ 1097] train: loss: 0.0000927
[Epoch 84; Iter   989/ 1097] train: loss: 0.0011385
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0070303
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0000845
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0000582
[Epoch 84] ogbg-molhiv: 0.785010 val loss: 0.368759
[Epoch 84] ogbg-molhiv: 0.792995 test loss: 0.332274
[Epoch 85; Iter    12/ 1097] train: loss: 0.0000682
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000260
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000398
[Epoch 85; Iter   102/ 1097] train: loss: 0.0004589
[Epoch 85; Iter   132/ 1097] train: loss: 0.0000748
[Epoch 85; Iter   162/ 1097] train: loss: 0.0002437
[Epoch 85; Iter   192/ 1097] train: loss: 0.0000601
[Epoch 85; Iter   222/ 1097] train: loss: 0.0000416
[Epoch 85; Iter   252/ 1097] train: loss: 0.0000130
[Epoch 85; Iter   282/ 1097] train: loss: 0.0000450
[Epoch 85; Iter   312/ 1097] train: loss: 0.0000447
[Epoch 85; Iter   342/ 1097] train: loss: 0.0001040
[Epoch 85; Iter   372/ 1097] train: loss: 0.0000244
[Epoch 85; Iter   402/ 1097] train: loss: 0.0003938
[Epoch 65; Iter    22/ 1097] train: loss: 0.0769576
[Epoch 65; Iter    52/ 1097] train: loss: 0.0071373
[Epoch 65; Iter    82/ 1097] train: loss: 0.0061776
[Epoch 65; Iter   112/ 1097] train: loss: 0.0515475
[Epoch 65; Iter   142/ 1097] train: loss: 0.0408873
[Epoch 65; Iter   172/ 1097] train: loss: 0.0039515
[Epoch 65; Iter   202/ 1097] train: loss: 0.0193212
[Epoch 65; Iter   232/ 1097] train: loss: 0.0388860
[Epoch 65; Iter   262/ 1097] train: loss: 0.0144977
[Epoch 65; Iter   292/ 1097] train: loss: 0.0058397
[Epoch 65; Iter   322/ 1097] train: loss: 0.0109659
[Epoch 65; Iter   352/ 1097] train: loss: 0.0193133
[Epoch 65; Iter   382/ 1097] train: loss: 0.0060214
[Epoch 65; Iter   412/ 1097] train: loss: 0.0087261
[Epoch 65; Iter   442/ 1097] train: loss: 0.0088596
[Epoch 65; Iter   472/ 1097] train: loss: 0.0148721
[Epoch 65; Iter   502/ 1097] train: loss: 0.0099188
[Epoch 65; Iter   532/ 1097] train: loss: 0.1080923
[Epoch 65; Iter   562/ 1097] train: loss: 0.0280807
[Epoch 65; Iter   592/ 1097] train: loss: 0.0221400
[Epoch 65; Iter   622/ 1097] train: loss: 0.0469991
[Epoch 65; Iter   652/ 1097] train: loss: 0.0465615
[Epoch 65; Iter   682/ 1097] train: loss: 0.0194122
[Epoch 65; Iter   712/ 1097] train: loss: 0.1157408
[Epoch 65; Iter   742/ 1097] train: loss: 0.0553588
[Epoch 65; Iter   772/ 1097] train: loss: 0.0816790
[Epoch 65; Iter   802/ 1097] train: loss: 0.0192850
[Epoch 65; Iter   832/ 1097] train: loss: 0.0681695
[Epoch 65; Iter   862/ 1097] train: loss: 0.0118246
[Epoch 65; Iter   892/ 1097] train: loss: 0.1155378
[Epoch 65; Iter   922/ 1097] train: loss: 0.0541857
[Epoch 65; Iter   952/ 1097] train: loss: 0.0209150
[Epoch 65; Iter   982/ 1097] train: loss: 0.0139847
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0078091
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0066193
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0276369
[Epoch 65] ogbg-molhiv: 0.808914 val loss: 0.109358
[Epoch 65] ogbg-molhiv: 0.745078 test loss: 0.201299
[Epoch 66; Iter     5/ 1097] train: loss: 0.0035932
[Epoch 66; Iter    35/ 1097] train: loss: 0.0293016
[Epoch 66; Iter    65/ 1097] train: loss: 0.0097030
[Epoch 66; Iter    95/ 1097] train: loss: 0.0658878
[Epoch 66; Iter   125/ 1097] train: loss: 0.0016213
[Epoch 66; Iter   155/ 1097] train: loss: 0.0214887
[Epoch 66; Iter   185/ 1097] train: loss: 0.0020995
[Epoch 66; Iter   215/ 1097] train: loss: 0.0156387
[Epoch 66; Iter   245/ 1097] train: loss: 0.1202733
[Epoch 66; Iter   275/ 1097] train: loss: 0.0265541
[Epoch 66; Iter   305/ 1097] train: loss: 0.0042156
[Epoch 66; Iter   335/ 1097] train: loss: 0.0901321
[Epoch 66; Iter   365/ 1097] train: loss: 0.0060883
[Epoch 66; Iter   395/ 1097] train: loss: 0.0027942
[Epoch 66; Iter   425/ 1097] train: loss: 0.0089498
[Epoch 66; Iter   455/ 1097] train: loss: 0.0691793
[Epoch 66; Iter   485/ 1097] train: loss: 0.0050541
[Epoch 66; Iter   515/ 1097] train: loss: 0.0757945
[Epoch 66; Iter   545/ 1097] train: loss: 0.0052997
[Epoch 66; Iter   575/ 1097] train: loss: 0.0482744
[Epoch 66; Iter   605/ 1097] train: loss: 0.0058311
[Epoch 66; Iter   635/ 1097] train: loss: 0.0079588
[Epoch 66; Iter   665/ 1097] train: loss: 0.0121556
[Epoch 66; Iter   695/ 1097] train: loss: 0.0969075
[Epoch 66; Iter   725/ 1097] train: loss: 0.2279130
[Epoch 66; Iter   755/ 1097] train: loss: 0.0584131
[Epoch 66; Iter   785/ 1097] train: loss: 0.0973265
[Epoch 66; Iter   815/ 1097] train: loss: 0.0581675
[Epoch 66; Iter   845/ 1097] train: loss: 0.0257467
[Epoch 66; Iter   875/ 1097] train: loss: 0.0403564
[Epoch 66; Iter   905/ 1097] train: loss: 0.0204223
[Epoch 66; Iter   935/ 1097] train: loss: 0.0598717
[Epoch 66; Iter   965/ 1097] train: loss: 0.0165888
[Epoch 66; Iter   995/ 1097] train: loss: 0.0585465
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0022025
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0023364
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0213945
[Epoch 66] ogbg-molhiv: 0.813416 val loss: 0.104168
[Epoch 66] ogbg-molhiv: 0.750140 test loss: 0.189739
[Epoch 67; Iter    18/ 1097] train: loss: 0.0107104
[Epoch 67; Iter    48/ 1097] train: loss: 0.0084437
[Epoch 67; Iter    78/ 1097] train: loss: 0.0158812
[Epoch 67; Iter   108/ 1097] train: loss: 0.0354132
[Epoch 67; Iter   138/ 1097] train: loss: 0.0079729
[Epoch 67; Iter   168/ 1097] train: loss: 0.0273508
[Epoch 67; Iter   198/ 1097] train: loss: 0.1078786
[Epoch 67; Iter   228/ 1097] train: loss: 0.0138563
[Epoch 67; Iter   258/ 1097] train: loss: 0.0139548
[Epoch 67; Iter   288/ 1097] train: loss: 0.0241872
[Epoch 67; Iter   318/ 1097] train: loss: 0.0119293
[Epoch 67; Iter   348/ 1097] train: loss: 0.0264801
[Epoch 67; Iter   378/ 1097] train: loss: 0.0229240
[Epoch 67; Iter   408/ 1097] train: loss: 0.0106904
[Epoch 67; Iter   438/ 1097] train: loss: 0.0046958
[Epoch 67; Iter   468/ 1097] train: loss: 0.0894212
[Epoch 67; Iter   498/ 1097] train: loss: 0.0166836
[Epoch 67; Iter   528/ 1097] train: loss: 0.0576074
[Epoch 67; Iter   558/ 1097] train: loss: 0.0269558
[Epoch 67; Iter   588/ 1097] train: loss: 0.0068705
[Epoch 67; Iter   618/ 1097] train: loss: 0.1198219
[Epoch 67; Iter   648/ 1097] train: loss: 0.0333698
[Epoch 67; Iter   678/ 1097] train: loss: 0.0267517
[Epoch 67; Iter   708/ 1097] train: loss: 0.0443689
[Epoch 67; Iter   738/ 1097] train: loss: 0.0466764
[Epoch 67; Iter   768/ 1097] train: loss: 0.0891178
[Epoch 67; Iter   798/ 1097] train: loss: 0.0501113
[Epoch 67; Iter   828/ 1097] train: loss: 0.0453306
[Epoch 67; Iter   858/ 1097] train: loss: 0.0043478
[Epoch 67; Iter   888/ 1097] train: loss: 0.1027911
[Epoch 67; Iter   918/ 1097] train: loss: 0.0185375
[Epoch 67; Iter   948/ 1097] train: loss: 0.0209322
[Epoch 67; Iter   978/ 1097] train: loss: 0.0091998
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0154242
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0079864
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0484443
[Epoch 67] ogbg-molhiv: 0.821073 val loss: 0.113403
[Epoch 67] ogbg-molhiv: 0.747334 test loss: 0.202089
[Epoch 68; Iter     1/ 1097] train: loss: 0.0822715
[Epoch 68; Iter    31/ 1097] train: loss: 0.0041971
[Epoch 68; Iter    61/ 1097] train: loss: 0.0713007
[Epoch 68; Iter    91/ 1097] train: loss: 0.0084752
[Epoch 68; Iter   121/ 1097] train: loss: 0.0241222
[Epoch 68; Iter   151/ 1097] train: loss: 0.0777141
[Epoch 68; Iter   181/ 1097] train: loss: 0.0276155
[Epoch 68; Iter   211/ 1097] train: loss: 0.0322384
[Epoch 68; Iter   241/ 1097] train: loss: 0.0205133
[Epoch 68; Iter   271/ 1097] train: loss: 0.0683732
[Epoch 68; Iter   301/ 1097] train: loss: 0.0188998
[Epoch 68; Iter   331/ 1097] train: loss: 0.0167804
[Epoch 68; Iter   361/ 1097] train: loss: 0.0054456
[Epoch 68; Iter   391/ 1097] train: loss: 0.0053659
[Epoch 68; Iter   421/ 1097] train: loss: 0.0234306
[Epoch 68; Iter   451/ 1097] train: loss: 0.1473674
[Epoch 68; Iter   481/ 1097] train: loss: 0.0143363
[Epoch 68; Iter   511/ 1097] train: loss: 0.1008012
[Epoch 68; Iter   541/ 1097] train: loss: 0.0124367
[Epoch 68; Iter   571/ 1097] train: loss: 0.0684706
[Epoch 68; Iter   601/ 1097] train: loss: 0.0075579
[Epoch 68; Iter   631/ 1097] train: loss: 0.0091170
[Epoch 68; Iter   661/ 1097] train: loss: 0.0111236
[Epoch 68; Iter   691/ 1097] train: loss: 0.0593759
[Epoch 68; Iter   721/ 1097] train: loss: 0.0102053
[Epoch 68; Iter   751/ 1097] train: loss: 0.0460528
[Epoch 68; Iter   781/ 1097] train: loss: 0.0037230
[Epoch 68; Iter   811/ 1097] train: loss: 0.0702796
[Epoch 68; Iter   841/ 1097] train: loss: 0.0330736
[Epoch 68; Iter   871/ 1097] train: loss: 0.0570523
[Epoch 68; Iter   901/ 1097] train: loss: 0.0100103
[Epoch 68; Iter   931/ 1097] train: loss: 0.0111122
[Epoch 68; Iter   961/ 1097] train: loss: 0.0099497
[Epoch 68; Iter   991/ 1097] train: loss: 0.1554262
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0068051
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0663940
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0074588
[Epoch 68] ogbg-molhiv: 0.810531 val loss: 0.112237
[Epoch 68] ogbg-molhiv: 0.745708 test loss: 0.194215
[Epoch 69; Iter    14/ 1097] train: loss: 0.0118881
[Epoch 69; Iter    44/ 1097] train: loss: 0.0257594
[Epoch 69; Iter    74/ 1097] train: loss: 0.0239347
[Epoch 81; Iter   350/ 1097] train: loss: 0.0000057
[Epoch 81; Iter   380/ 1097] train: loss: 0.0008687
[Epoch 81; Iter   410/ 1097] train: loss: 0.0003554
[Epoch 81; Iter   440/ 1097] train: loss: 0.0001028
[Epoch 81; Iter   470/ 1097] train: loss: 0.0027613
[Epoch 81; Iter   500/ 1097] train: loss: 0.0000584
[Epoch 81; Iter   530/ 1097] train: loss: 0.0000258
[Epoch 81; Iter   560/ 1097] train: loss: 0.0001449
[Epoch 81; Iter   590/ 1097] train: loss: 0.0000768
[Epoch 81; Iter   620/ 1097] train: loss: 0.0005198
[Epoch 81; Iter   650/ 1097] train: loss: 0.0000396
[Epoch 81; Iter   680/ 1097] train: loss: 0.0012923
[Epoch 81; Iter   710/ 1097] train: loss: 0.0000744
[Epoch 81; Iter   740/ 1097] train: loss: 0.0000074
[Epoch 81; Iter   770/ 1097] train: loss: 0.0005346
[Epoch 81; Iter   800/ 1097] train: loss: 0.0000633
[Epoch 81; Iter   830/ 1097] train: loss: 0.0000545
[Epoch 81; Iter   860/ 1097] train: loss: 0.0002469
[Epoch 81; Iter   890/ 1097] train: loss: 0.0001045
[Epoch 81; Iter   920/ 1097] train: loss: 0.0000134
[Epoch 81; Iter   950/ 1097] train: loss: 0.0000113
[Epoch 81; Iter   980/ 1097] train: loss: 0.0000138
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0042046
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0000199
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0000080
[Epoch 81] ogbg-molhiv: 0.671012 val loss: 2.502667
[Epoch 81] ogbg-molhiv: 0.576167 test loss: 3.506159
[Epoch 82; Iter     3/ 1097] train: loss: 0.0000380
[Epoch 82; Iter    33/ 1097] train: loss: 0.0009943
[Epoch 82; Iter    63/ 1097] train: loss: 0.0000183
[Epoch 82; Iter    93/ 1097] train: loss: 0.0000933
[Epoch 82; Iter   123/ 1097] train: loss: 0.0000201
[Epoch 82; Iter   153/ 1097] train: loss: 0.0001926
[Epoch 82; Iter   183/ 1097] train: loss: 0.0009065
[Epoch 82; Iter   213/ 1097] train: loss: 0.0000042
[Epoch 82; Iter   243/ 1097] train: loss: 0.0113376
[Epoch 82; Iter   273/ 1097] train: loss: 0.0000659
[Epoch 82; Iter   303/ 1097] train: loss: 0.0010584
[Epoch 82; Iter   333/ 1097] train: loss: 0.0000879
[Epoch 82; Iter   363/ 1097] train: loss: 0.0000583
[Epoch 82; Iter   393/ 1097] train: loss: 0.0000013
[Epoch 82; Iter   423/ 1097] train: loss: 0.0003687
[Epoch 82; Iter   453/ 1097] train: loss: 0.0001094
[Epoch 82; Iter   483/ 1097] train: loss: 0.0012151
[Epoch 82; Iter   513/ 1097] train: loss: 0.0000187
[Epoch 82; Iter   543/ 1097] train: loss: 0.0001047
[Epoch 82; Iter   573/ 1097] train: loss: 0.0009646
[Epoch 82; Iter   603/ 1097] train: loss: 0.0001092
[Epoch 82; Iter   633/ 1097] train: loss: 0.0000289
[Epoch 82; Iter   663/ 1097] train: loss: 0.0004605
[Epoch 82; Iter   693/ 1097] train: loss: 0.0000089
[Epoch 82; Iter   723/ 1097] train: loss: 0.0000227
[Epoch 82; Iter   753/ 1097] train: loss: 0.0001147
[Epoch 82; Iter   783/ 1097] train: loss: 0.0000028
[Epoch 82; Iter   813/ 1097] train: loss: 0.0003004
[Epoch 82; Iter   843/ 1097] train: loss: 0.0000568
[Epoch 82; Iter   873/ 1097] train: loss: 0.0000301
[Epoch 82; Iter   903/ 1097] train: loss: 0.0000123
[Epoch 82; Iter   933/ 1097] train: loss: 0.0000420
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000241
[Epoch 82; Iter   993/ 1097] train: loss: 0.0007613
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0000524
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0045494
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0000041
[Epoch 82] ogbg-molhiv: 0.678510 val loss: 3.332889
[Epoch 82] ogbg-molhiv: 0.610898 test loss: 3.189548
[Epoch 83; Iter    16/ 1097] train: loss: 0.0000449
[Epoch 83; Iter    46/ 1097] train: loss: 0.0003229
[Epoch 83; Iter    76/ 1097] train: loss: 0.0000697
[Epoch 83; Iter   106/ 1097] train: loss: 0.0000149
[Epoch 83; Iter   136/ 1097] train: loss: 0.0000029
[Epoch 83; Iter   166/ 1097] train: loss: 0.0000643
[Epoch 83; Iter   196/ 1097] train: loss: 0.0002114
[Epoch 83; Iter   226/ 1097] train: loss: 0.0001781
[Epoch 83; Iter   256/ 1097] train: loss: 0.0000184
[Epoch 83; Iter   286/ 1097] train: loss: 0.0000232
[Epoch 83; Iter   316/ 1097] train: loss: 0.0008170
[Epoch 83; Iter   346/ 1097] train: loss: 0.0001656
[Epoch 83; Iter   376/ 1097] train: loss: 0.0000167
[Epoch 83; Iter   406/ 1097] train: loss: 0.0000379
[Epoch 83; Iter   436/ 1097] train: loss: 0.0000573
[Epoch 83; Iter   466/ 1097] train: loss: 0.0000396
[Epoch 83; Iter   496/ 1097] train: loss: 0.0001522
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000447
[Epoch 83; Iter   556/ 1097] train: loss: 0.0000519
[Epoch 83; Iter   586/ 1097] train: loss: 0.0000884
[Epoch 83; Iter   616/ 1097] train: loss: 0.0000065
[Epoch 83; Iter   646/ 1097] train: loss: 0.0000047
[Epoch 83; Iter   676/ 1097] train: loss: 0.0000749
[Epoch 83; Iter   706/ 1097] train: loss: 0.0000020
[Epoch 83; Iter   736/ 1097] train: loss: 0.0002384
[Epoch 83; Iter   766/ 1097] train: loss: 0.0027490
[Epoch 83; Iter   796/ 1097] train: loss: 0.0000331
[Epoch 83; Iter   826/ 1097] train: loss: 0.0353947
[Epoch 83; Iter   856/ 1097] train: loss: 0.0000365
[Epoch 83; Iter   886/ 1097] train: loss: 0.0026905
[Epoch 83; Iter   916/ 1097] train: loss: 0.0000054
[Epoch 83; Iter   946/ 1097] train: loss: 0.0000104
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000008
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0034985
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0000336
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0000052
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0000676
[Epoch 83] ogbg-molhiv: 0.671419 val loss: 1.841115
[Epoch 83] ogbg-molhiv: 0.605431 test loss: 2.364659
[Epoch 84; Iter    29/ 1097] train: loss: 0.0000009
[Epoch 84; Iter    59/ 1097] train: loss: 0.0000705
[Epoch 84; Iter    89/ 1097] train: loss: 0.0000120
[Epoch 84; Iter   119/ 1097] train: loss: 0.0000052
[Epoch 84; Iter   149/ 1097] train: loss: 0.0000080
[Epoch 84; Iter   179/ 1097] train: loss: 0.0005277
[Epoch 84; Iter   209/ 1097] train: loss: 0.0005264
[Epoch 84; Iter   239/ 1097] train: loss: 0.0000162
[Epoch 84; Iter   269/ 1097] train: loss: 0.0019214
[Epoch 84; Iter   299/ 1097] train: loss: 0.0000011
[Epoch 84; Iter   329/ 1097] train: loss: 0.0000141
[Epoch 84; Iter   359/ 1097] train: loss: 0.0001123
[Epoch 84; Iter   389/ 1097] train: loss: 0.0000090
[Epoch 84; Iter   419/ 1097] train: loss: 0.0000613
[Epoch 84; Iter   449/ 1097] train: loss: 0.0000132
[Epoch 84; Iter   479/ 1097] train: loss: 0.0000460
[Epoch 84; Iter   509/ 1097] train: loss: 0.0000061
[Epoch 84; Iter   539/ 1097] train: loss: 0.0000003
[Epoch 84; Iter   569/ 1097] train: loss: 0.0000160
[Epoch 84; Iter   599/ 1097] train: loss: 0.0001937
[Epoch 84; Iter   629/ 1097] train: loss: 0.0000198
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000012
[Epoch 84; Iter   689/ 1097] train: loss: 0.0006995
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000007
[Epoch 84; Iter   749/ 1097] train: loss: 0.0000129
[Epoch 84; Iter   779/ 1097] train: loss: 0.0001395
[Epoch 84; Iter   809/ 1097] train: loss: 0.0003801
[Epoch 84; Iter   839/ 1097] train: loss: 0.0000144
[Epoch 84; Iter   869/ 1097] train: loss: 0.0001411
[Epoch 84; Iter   899/ 1097] train: loss: 0.0003647
[Epoch 84; Iter   929/ 1097] train: loss: 0.0000454
[Epoch 84; Iter   959/ 1097] train: loss: 0.0000062
[Epoch 84; Iter   989/ 1097] train: loss: 0.0000443
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0000561
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0018596
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0000383
[Epoch 84] ogbg-molhiv: 0.699484 val loss: 2.185898
[Epoch 84] ogbg-molhiv: 0.608465 test loss: 2.495953
[Epoch 85; Iter    12/ 1097] train: loss: 0.0001258
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000009
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000056
[Epoch 85; Iter   102/ 1097] train: loss: 0.0000404
[Epoch 85; Iter   132/ 1097] train: loss: 0.0000043
[Epoch 85; Iter   162/ 1097] train: loss: 0.0000621
[Epoch 85; Iter   192/ 1097] train: loss: 0.0003772
[Epoch 85; Iter   222/ 1097] train: loss: 0.0000134
[Epoch 85; Iter   252/ 1097] train: loss: 0.0000060
[Epoch 85; Iter   282/ 1097] train: loss: 0.0020769
[Epoch 85; Iter   312/ 1097] train: loss: 0.0000041
[Epoch 85; Iter   342/ 1097] train: loss: 0.0000069
[Epoch 85; Iter   372/ 1097] train: loss: 0.0000117
[Epoch 85; Iter   402/ 1097] train: loss: 0.0000206
[Epoch 65; Iter    22/ 1097] train: loss: 0.2418490
[Epoch 65; Iter    52/ 1097] train: loss: 0.0084986
[Epoch 65; Iter    82/ 1097] train: loss: 0.0568109
[Epoch 65; Iter   112/ 1097] train: loss: 0.0060655
[Epoch 65; Iter   142/ 1097] train: loss: 0.1387314
[Epoch 65; Iter   172/ 1097] train: loss: 0.2225852
[Epoch 65; Iter   202/ 1097] train: loss: 0.0165174
[Epoch 65; Iter   232/ 1097] train: loss: 0.0123613
[Epoch 65; Iter   262/ 1097] train: loss: 0.0059193
[Epoch 65; Iter   292/ 1097] train: loss: 0.0653126
[Epoch 65; Iter   322/ 1097] train: loss: 0.0739173
[Epoch 65; Iter   352/ 1097] train: loss: 0.0038612
[Epoch 65; Iter   382/ 1097] train: loss: 0.0101295
[Epoch 65; Iter   412/ 1097] train: loss: 0.0080439
[Epoch 65; Iter   442/ 1097] train: loss: 0.0061094
[Epoch 65; Iter   472/ 1097] train: loss: 0.0966645
[Epoch 65; Iter   502/ 1097] train: loss: 0.0508015
[Epoch 65; Iter   532/ 1097] train: loss: 0.1054454
[Epoch 65; Iter   562/ 1097] train: loss: 0.0821331
[Epoch 65; Iter   592/ 1097] train: loss: 0.0550149
[Epoch 65; Iter   622/ 1097] train: loss: 0.0447236
[Epoch 65; Iter   652/ 1097] train: loss: 0.0097915
[Epoch 65; Iter   682/ 1097] train: loss: 0.0173968
[Epoch 65; Iter   712/ 1097] train: loss: 0.0756016
[Epoch 65; Iter   742/ 1097] train: loss: 0.0041729
[Epoch 65; Iter   772/ 1097] train: loss: 0.0082275
[Epoch 65; Iter   802/ 1097] train: loss: 0.1502663
[Epoch 65; Iter   832/ 1097] train: loss: 0.0345045
[Epoch 65; Iter   862/ 1097] train: loss: 0.0299581
[Epoch 65; Iter   892/ 1097] train: loss: 0.0211298
[Epoch 65; Iter   922/ 1097] train: loss: 0.0165159
[Epoch 65; Iter   952/ 1097] train: loss: 0.0305599
[Epoch 65; Iter   982/ 1097] train: loss: 0.0584694
[Epoch 65; Iter  1012/ 1097] train: loss: 0.1293102
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0608007
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0296661
[Epoch 65] ogbg-molhiv: 0.784447 val loss: 0.268450
[Epoch 65] ogbg-molhiv: 0.733597 test loss: 0.269193
[Epoch 66; Iter     5/ 1097] train: loss: 0.0893432
[Epoch 66; Iter    35/ 1097] train: loss: 0.0249736
[Epoch 66; Iter    65/ 1097] train: loss: 0.0297074
[Epoch 66; Iter    95/ 1097] train: loss: 0.0049677
[Epoch 66; Iter   125/ 1097] train: loss: 0.0293958
[Epoch 66; Iter   155/ 1097] train: loss: 0.0511668
[Epoch 66; Iter   185/ 1097] train: loss: 0.0107962
[Epoch 66; Iter   215/ 1097] train: loss: 0.1064667
[Epoch 66; Iter   245/ 1097] train: loss: 0.0353788
[Epoch 66; Iter   275/ 1097] train: loss: 0.0456922
[Epoch 66; Iter   305/ 1097] train: loss: 0.0658928
[Epoch 66; Iter   335/ 1097] train: loss: 0.0107419
[Epoch 66; Iter   365/ 1097] train: loss: 0.1439238
[Epoch 66; Iter   395/ 1097] train: loss: 0.0982442
[Epoch 66; Iter   425/ 1097] train: loss: 0.0483199
[Epoch 66; Iter   455/ 1097] train: loss: 0.1760477
[Epoch 66; Iter   485/ 1097] train: loss: 0.0213963
[Epoch 66; Iter   515/ 1097] train: loss: 0.0909122
[Epoch 66; Iter   545/ 1097] train: loss: 0.0406879
[Epoch 66; Iter   575/ 1097] train: loss: 0.0613122
[Epoch 66; Iter   605/ 1097] train: loss: 0.0104860
[Epoch 66; Iter   635/ 1097] train: loss: 0.0179677
[Epoch 66; Iter   665/ 1097] train: loss: 0.0292118
[Epoch 66; Iter   695/ 1097] train: loss: 0.0373830
[Epoch 66; Iter   725/ 1097] train: loss: 0.0324038
[Epoch 66; Iter   755/ 1097] train: loss: 0.1045845
[Epoch 66; Iter   785/ 1097] train: loss: 0.0497060
[Epoch 66; Iter   815/ 1097] train: loss: 0.0375713
[Epoch 66; Iter   845/ 1097] train: loss: 0.0738680
[Epoch 66; Iter   875/ 1097] train: loss: 0.0025369
[Epoch 66; Iter   905/ 1097] train: loss: 0.0052455
[Epoch 66; Iter   935/ 1097] train: loss: 0.0069815
[Epoch 66; Iter   965/ 1097] train: loss: 0.3193606
[Epoch 66; Iter   995/ 1097] train: loss: 0.0075535
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0268800
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0620707
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0290645
[Epoch 66] ogbg-molhiv: 0.783534 val loss: 0.140721
[Epoch 66] ogbg-molhiv: 0.750466 test loss: 0.251305
[Epoch 67; Iter    18/ 1097] train: loss: 0.0405383
[Epoch 67; Iter    48/ 1097] train: loss: 0.0156383
[Epoch 67; Iter    78/ 1097] train: loss: 0.0233588
[Epoch 67; Iter   108/ 1097] train: loss: 0.0417096
[Epoch 67; Iter   138/ 1097] train: loss: 0.0060514
[Epoch 67; Iter   168/ 1097] train: loss: 0.0044295
[Epoch 67; Iter   198/ 1097] train: loss: 0.0953195
[Epoch 67; Iter   228/ 1097] train: loss: 0.0100715
[Epoch 67; Iter   258/ 1097] train: loss: 0.0031512
[Epoch 67; Iter   288/ 1097] train: loss: 0.1340017
[Epoch 67; Iter   318/ 1097] train: loss: 0.0240305
[Epoch 67; Iter   348/ 1097] train: loss: 0.0094190
[Epoch 67; Iter   378/ 1097] train: loss: 0.0048650
[Epoch 67; Iter   408/ 1097] train: loss: 0.1725003
[Epoch 67; Iter   438/ 1097] train: loss: 0.0073383
[Epoch 67; Iter   468/ 1097] train: loss: 0.0415738
[Epoch 67; Iter   498/ 1097] train: loss: 0.0238839
[Epoch 67; Iter   528/ 1097] train: loss: 0.0266377
[Epoch 67; Iter   558/ 1097] train: loss: 0.0061363
[Epoch 67; Iter   588/ 1097] train: loss: 0.0075663
[Epoch 67; Iter   618/ 1097] train: loss: 0.0023251
[Epoch 67; Iter   648/ 1097] train: loss: 0.0485916
[Epoch 67; Iter   678/ 1097] train: loss: 0.0109212
[Epoch 67; Iter   708/ 1097] train: loss: 0.0258407
[Epoch 67; Iter   738/ 1097] train: loss: 0.0144323
[Epoch 67; Iter   768/ 1097] train: loss: 0.1280960
[Epoch 67; Iter   798/ 1097] train: loss: 0.0064078
[Epoch 67; Iter   828/ 1097] train: loss: 0.0156060
[Epoch 67; Iter   858/ 1097] train: loss: 0.0090592
[Epoch 67; Iter   888/ 1097] train: loss: 0.0251035
[Epoch 67; Iter   918/ 1097] train: loss: 0.0577367
[Epoch 67; Iter   948/ 1097] train: loss: 0.0102615
[Epoch 67; Iter   978/ 1097] train: loss: 0.0461294
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0756628
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0862862
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0148638
[Epoch 67] ogbg-molhiv: 0.776997 val loss: 0.111495
[Epoch 67] ogbg-molhiv: 0.730375 test loss: 0.199749
[Epoch 68; Iter     1/ 1097] train: loss: 0.1266050
[Epoch 68; Iter    31/ 1097] train: loss: 0.1147619
[Epoch 68; Iter    61/ 1097] train: loss: 0.0798761
[Epoch 68; Iter    91/ 1097] train: loss: 0.0315941
[Epoch 68; Iter   121/ 1097] train: loss: 0.0215536
[Epoch 68; Iter   151/ 1097] train: loss: 0.0048568
[Epoch 68; Iter   181/ 1097] train: loss: 0.0158438
[Epoch 68; Iter   211/ 1097] train: loss: 0.0064261
[Epoch 68; Iter   241/ 1097] train: loss: 0.0544297
[Epoch 68; Iter   271/ 1097] train: loss: 0.0496051
[Epoch 68; Iter   301/ 1097] train: loss: 0.0287515
[Epoch 68; Iter   331/ 1097] train: loss: 0.0234919
[Epoch 68; Iter   361/ 1097] train: loss: 0.0210608
[Epoch 68; Iter   391/ 1097] train: loss: 0.0157330
[Epoch 68; Iter   421/ 1097] train: loss: 0.0196659
[Epoch 68; Iter   451/ 1097] train: loss: 0.0252529
[Epoch 68; Iter   481/ 1097] train: loss: 0.1196365
[Epoch 68; Iter   511/ 1097] train: loss: 0.0628980
[Epoch 68; Iter   541/ 1097] train: loss: 0.0143637
[Epoch 68; Iter   571/ 1097] train: loss: 0.1515795
[Epoch 68; Iter   601/ 1097] train: loss: 0.0460427
[Epoch 68; Iter   631/ 1097] train: loss: 0.0142154
[Epoch 68; Iter   661/ 1097] train: loss: 0.0963373
[Epoch 68; Iter   691/ 1097] train: loss: 0.0148265
[Epoch 68; Iter   721/ 1097] train: loss: 0.0274869
[Epoch 68; Iter   751/ 1097] train: loss: 0.0121615
[Epoch 68; Iter   781/ 1097] train: loss: 0.0258387
[Epoch 68; Iter   811/ 1097] train: loss: 0.0057536
[Epoch 68; Iter   841/ 1097] train: loss: 0.0041496
[Epoch 68; Iter   871/ 1097] train: loss: 0.0038664
[Epoch 68; Iter   901/ 1097] train: loss: 0.0285882
[Epoch 68; Iter   931/ 1097] train: loss: 0.0161028
[Epoch 68; Iter   961/ 1097] train: loss: 0.0226148
[Epoch 68; Iter   991/ 1097] train: loss: 0.2093890
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0085368
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0057191
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0077372
[Epoch 68] ogbg-molhiv: 0.800846 val loss: 0.104545
[Epoch 68] ogbg-molhiv: 0.737786 test loss: 0.200205
[Epoch 69; Iter    14/ 1097] train: loss: 0.0126492
[Epoch 69; Iter    44/ 1097] train: loss: 0.0122425
[Epoch 69; Iter    74/ 1097] train: loss: 0.0221996
[Epoch 65; Iter    22/ 1097] train: loss: 0.0042434
[Epoch 65; Iter    52/ 1097] train: loss: 0.0159775
[Epoch 65; Iter    82/ 1097] train: loss: 0.0246163
[Epoch 65; Iter   112/ 1097] train: loss: 0.0162741
[Epoch 65; Iter   142/ 1097] train: loss: 0.1600453
[Epoch 65; Iter   172/ 1097] train: loss: 0.0023067
[Epoch 65; Iter   202/ 1097] train: loss: 0.0081672
[Epoch 65; Iter   232/ 1097] train: loss: 0.0034488
[Epoch 65; Iter   262/ 1097] train: loss: 0.0436556
[Epoch 65; Iter   292/ 1097] train: loss: 0.0033399
[Epoch 65; Iter   322/ 1097] train: loss: 0.0035301
[Epoch 65; Iter   352/ 1097] train: loss: 0.0354441
[Epoch 65; Iter   382/ 1097] train: loss: 0.0110725
[Epoch 65; Iter   412/ 1097] train: loss: 0.1027004
[Epoch 65; Iter   442/ 1097] train: loss: 0.0047020
[Epoch 65; Iter   472/ 1097] train: loss: 0.0044262
[Epoch 65; Iter   502/ 1097] train: loss: 0.0881760
[Epoch 65; Iter   532/ 1097] train: loss: 0.0797853
[Epoch 65; Iter   562/ 1097] train: loss: 0.0258573
[Epoch 65; Iter   592/ 1097] train: loss: 0.0661595
[Epoch 65; Iter   622/ 1097] train: loss: 0.0443988
[Epoch 65; Iter   652/ 1097] train: loss: 0.0133385
[Epoch 65; Iter   682/ 1097] train: loss: 0.0075970
[Epoch 65; Iter   712/ 1097] train: loss: 0.0375012
[Epoch 65; Iter   742/ 1097] train: loss: 0.0077046
[Epoch 65; Iter   772/ 1097] train: loss: 0.0487044
[Epoch 65; Iter   802/ 1097] train: loss: 0.0039141
[Epoch 65; Iter   832/ 1097] train: loss: 0.0202982
[Epoch 65; Iter   862/ 1097] train: loss: 0.0178868
[Epoch 65; Iter   892/ 1097] train: loss: 0.0782331
[Epoch 65; Iter   922/ 1097] train: loss: 0.0035143
[Epoch 65; Iter   952/ 1097] train: loss: 0.0074546
[Epoch 65; Iter   982/ 1097] train: loss: 0.0016277
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0146432
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0095421
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0363619
[Epoch 65] ogbg-molhiv: 0.792380 val loss: 0.112133
[Epoch 65] ogbg-molhiv: 0.752745 test loss: 0.207189
[Epoch 66; Iter     5/ 1097] train: loss: 0.0491904
[Epoch 66; Iter    35/ 1097] train: loss: 0.0365223
[Epoch 66; Iter    65/ 1097] train: loss: 0.0080824
[Epoch 66; Iter    95/ 1097] train: loss: 0.0075705
[Epoch 66; Iter   125/ 1097] train: loss: 0.0058717
[Epoch 66; Iter   155/ 1097] train: loss: 0.1492695
[Epoch 66; Iter   185/ 1097] train: loss: 0.0769275
[Epoch 66; Iter   215/ 1097] train: loss: 0.0063842
[Epoch 66; Iter   245/ 1097] train: loss: 0.0110286
[Epoch 66; Iter   275/ 1097] train: loss: 0.0061534
[Epoch 66; Iter   305/ 1097] train: loss: 0.0621938
[Epoch 66; Iter   335/ 1097] train: loss: 0.0207069
[Epoch 66; Iter   365/ 1097] train: loss: 0.0043400
[Epoch 66; Iter   395/ 1097] train: loss: 0.0773844
[Epoch 66; Iter   425/ 1097] train: loss: 0.0216189
[Epoch 66; Iter   455/ 1097] train: loss: 0.1352464
[Epoch 66; Iter   485/ 1097] train: loss: 0.0849489
[Epoch 66; Iter   515/ 1097] train: loss: 0.0488381
[Epoch 66; Iter   545/ 1097] train: loss: 0.1195787
[Epoch 66; Iter   575/ 1097] train: loss: 0.0070382
[Epoch 66; Iter   605/ 1097] train: loss: 0.1179488
[Epoch 66; Iter   635/ 1097] train: loss: 0.0210137
[Epoch 66; Iter   665/ 1097] train: loss: 0.1323551
[Epoch 66; Iter   695/ 1097] train: loss: 0.0061638
[Epoch 66; Iter   725/ 1097] train: loss: 0.0756211
[Epoch 66; Iter   755/ 1097] train: loss: 0.0042089
[Epoch 66; Iter   785/ 1097] train: loss: 0.0045195
[Epoch 66; Iter   815/ 1097] train: loss: 0.0140065
[Epoch 66; Iter   845/ 1097] train: loss: 0.0485617
[Epoch 66; Iter   875/ 1097] train: loss: 0.0323134
[Epoch 66; Iter   905/ 1097] train: loss: 0.0063330
[Epoch 66; Iter   935/ 1097] train: loss: 0.0443569
[Epoch 66; Iter   965/ 1097] train: loss: 0.0967687
[Epoch 66; Iter   995/ 1097] train: loss: 0.0064004
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0126740
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0038534
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0087208
[Epoch 66] ogbg-molhiv: 0.802010 val loss: 0.107952
[Epoch 66] ogbg-molhiv: 0.745296 test loss: 0.196391
[Epoch 67; Iter    18/ 1097] train: loss: 0.0045599
[Epoch 67; Iter    48/ 1097] train: loss: 0.0027407
[Epoch 67; Iter    78/ 1097] train: loss: 0.0400269
[Epoch 67; Iter   108/ 1097] train: loss: 0.0030481
[Epoch 67; Iter   138/ 1097] train: loss: 0.0051334
[Epoch 67; Iter   168/ 1097] train: loss: 0.0143102
[Epoch 67; Iter   198/ 1097] train: loss: 0.0167636
[Epoch 67; Iter   228/ 1097] train: loss: 0.0111018
[Epoch 67; Iter   258/ 1097] train: loss: 0.0046752
[Epoch 67; Iter   288/ 1097] train: loss: 0.1121091
[Epoch 67; Iter   318/ 1097] train: loss: 0.0678304
[Epoch 67; Iter   348/ 1097] train: loss: 0.0157022
[Epoch 67; Iter   378/ 1097] train: loss: 0.0315749
[Epoch 67; Iter   408/ 1097] train: loss: 0.0583600
[Epoch 67; Iter   438/ 1097] train: loss: 0.0746494
[Epoch 67; Iter   468/ 1097] train: loss: 0.0091149
[Epoch 67; Iter   498/ 1097] train: loss: 0.0163960
[Epoch 67; Iter   528/ 1097] train: loss: 0.0242039
[Epoch 67; Iter   558/ 1097] train: loss: 0.0279527
[Epoch 67; Iter   588/ 1097] train: loss: 0.0691295
[Epoch 67; Iter   618/ 1097] train: loss: 0.0390794
[Epoch 67; Iter   648/ 1097] train: loss: 0.0024162
[Epoch 67; Iter   678/ 1097] train: loss: 0.0395216
[Epoch 67; Iter   708/ 1097] train: loss: 0.0784551
[Epoch 67; Iter   738/ 1097] train: loss: 0.0129404
[Epoch 67; Iter   768/ 1097] train: loss: 0.0398592
[Epoch 67; Iter   798/ 1097] train: loss: 0.0665880
[Epoch 67; Iter   828/ 1097] train: loss: 0.0058901
[Epoch 67; Iter   858/ 1097] train: loss: 0.0093408
[Epoch 67; Iter   888/ 1097] train: loss: 0.0766925
[Epoch 67; Iter   918/ 1097] train: loss: 0.0033306
[Epoch 67; Iter   948/ 1097] train: loss: 0.0451801
[Epoch 67; Iter   978/ 1097] train: loss: 0.0029948
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0122262
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0227398
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0375627
[Epoch 67] ogbg-molhiv: 0.802420 val loss: 0.112592
[Epoch 67] ogbg-molhiv: 0.740215 test loss: 0.205678
[Epoch 68; Iter     1/ 1097] train: loss: 0.0360728
[Epoch 68; Iter    31/ 1097] train: loss: 0.0140793
[Epoch 68; Iter    61/ 1097] train: loss: 0.0482960
[Epoch 68; Iter    91/ 1097] train: loss: 0.0094977
[Epoch 68; Iter   121/ 1097] train: loss: 0.0379753
[Epoch 68; Iter   151/ 1097] train: loss: 0.0008251
[Epoch 68; Iter   181/ 1097] train: loss: 0.0932477
[Epoch 68; Iter   211/ 1097] train: loss: 0.1026135
[Epoch 68; Iter   241/ 1097] train: loss: 0.0859308
[Epoch 68; Iter   271/ 1097] train: loss: 0.0063897
[Epoch 68; Iter   301/ 1097] train: loss: 0.0410751
[Epoch 68; Iter   331/ 1097] train: loss: 0.0039377
[Epoch 68; Iter   361/ 1097] train: loss: 0.0734160
[Epoch 68; Iter   391/ 1097] train: loss: 0.0082951
[Epoch 68; Iter   421/ 1097] train: loss: 0.0489565
[Epoch 68; Iter   451/ 1097] train: loss: 0.0493325
[Epoch 68; Iter   481/ 1097] train: loss: 0.0035938
[Epoch 68; Iter   511/ 1097] train: loss: 0.0288709
[Epoch 68; Iter   541/ 1097] train: loss: 0.0061857
[Epoch 68; Iter   571/ 1097] train: loss: 0.0048751
[Epoch 68; Iter   601/ 1097] train: loss: 0.0422029
[Epoch 68; Iter   631/ 1097] train: loss: 0.0027557
[Epoch 68; Iter   661/ 1097] train: loss: 0.0029938
[Epoch 68; Iter   691/ 1097] train: loss: 0.0053524
[Epoch 68; Iter   721/ 1097] train: loss: 0.0144158
[Epoch 68; Iter   751/ 1097] train: loss: 0.0652967
[Epoch 68; Iter   781/ 1097] train: loss: 0.2395107
[Epoch 68; Iter   811/ 1097] train: loss: 0.0196959
[Epoch 68; Iter   841/ 1097] train: loss: 0.0301379
[Epoch 68; Iter   871/ 1097] train: loss: 0.1918072
[Epoch 68; Iter   901/ 1097] train: loss: 0.0684740
[Epoch 68; Iter   931/ 1097] train: loss: 0.0433322
[Epoch 68; Iter   961/ 1097] train: loss: 0.0076948
[Epoch 68; Iter   991/ 1097] train: loss: 0.0240944
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0132227
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0303887
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0178271
[Epoch 68] ogbg-molhiv: 0.777876 val loss: 0.123741
[Epoch 68] ogbg-molhiv: 0.730441 test loss: 0.238687
[Epoch 69; Iter    14/ 1097] train: loss: 0.0839695
[Epoch 69; Iter    44/ 1097] train: loss: 0.0140950
[Epoch 69; Iter    74/ 1097] train: loss: 0.1087842
[Epoch 81; Iter   350/ 1097] train: loss: 0.0012555
[Epoch 81; Iter   380/ 1097] train: loss: 0.0000729
[Epoch 81; Iter   410/ 1097] train: loss: 0.0023100
[Epoch 81; Iter   440/ 1097] train: loss: 0.0001401
[Epoch 81; Iter   470/ 1097] train: loss: 0.0002300
[Epoch 81; Iter   500/ 1097] train: loss: 0.0032315
[Epoch 81; Iter   530/ 1097] train: loss: 0.0003082
[Epoch 81; Iter   560/ 1097] train: loss: 0.0001320
[Epoch 81; Iter   590/ 1097] train: loss: 0.0047971
[Epoch 81; Iter   620/ 1097] train: loss: 0.0009793
[Epoch 81; Iter   650/ 1097] train: loss: 0.0202862
[Epoch 81; Iter   680/ 1097] train: loss: 0.0004798
[Epoch 81; Iter   710/ 1097] train: loss: 0.0002321
[Epoch 81; Iter   740/ 1097] train: loss: 0.0006659
[Epoch 81; Iter   770/ 1097] train: loss: 0.0036491
[Epoch 81; Iter   800/ 1097] train: loss: 0.0007133
[Epoch 81; Iter   830/ 1097] train: loss: 0.0000866
[Epoch 81; Iter   860/ 1097] train: loss: 0.0002266
[Epoch 81; Iter   890/ 1097] train: loss: 0.0004122
[Epoch 81; Iter   920/ 1097] train: loss: 0.0001443
[Epoch 81; Iter   950/ 1097] train: loss: 0.0008119
[Epoch 81; Iter   980/ 1097] train: loss: 0.0014705
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0001503
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0005363
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0000858
[Epoch 81] ogbg-molhiv: 0.655561 val loss: 66.082702
[Epoch 81] ogbg-molhiv: 0.566349 test loss: 63.601105
[Epoch 82; Iter     3/ 1097] train: loss: 0.0007166
[Epoch 82; Iter    33/ 1097] train: loss: 0.0001760
[Epoch 82; Iter    63/ 1097] train: loss: 0.0002878
[Epoch 82; Iter    93/ 1097] train: loss: 0.0004855
[Epoch 82; Iter   123/ 1097] train: loss: 0.0000883
[Epoch 82; Iter   153/ 1097] train: loss: 0.0004624
[Epoch 82; Iter   183/ 1097] train: loss: 0.0365855
[Epoch 82; Iter   213/ 1097] train: loss: 0.0001688
[Epoch 82; Iter   243/ 1097] train: loss: 0.0000601
[Epoch 82; Iter   273/ 1097] train: loss: 0.0000086
[Epoch 82; Iter   303/ 1097] train: loss: 0.0006807
[Epoch 82; Iter   333/ 1097] train: loss: 0.0008626
[Epoch 82; Iter   363/ 1097] train: loss: 0.0000482
[Epoch 82; Iter   393/ 1097] train: loss: 0.0040151
[Epoch 82; Iter   423/ 1097] train: loss: 0.0001611
[Epoch 82; Iter   453/ 1097] train: loss: 0.0005304
[Epoch 82; Iter   483/ 1097] train: loss: 0.0012507
[Epoch 82; Iter   513/ 1097] train: loss: 0.0044763
[Epoch 82; Iter   543/ 1097] train: loss: 0.0028312
[Epoch 82; Iter   573/ 1097] train: loss: 0.0004124
[Epoch 82; Iter   603/ 1097] train: loss: 0.0005532
[Epoch 82; Iter   633/ 1097] train: loss: 0.0042633
[Epoch 82; Iter   663/ 1097] train: loss: 0.0000442
[Epoch 82; Iter   693/ 1097] train: loss: 0.0001793
[Epoch 82; Iter   723/ 1097] train: loss: 0.0000952
[Epoch 82; Iter   753/ 1097] train: loss: 0.0010908
[Epoch 82; Iter   783/ 1097] train: loss: 0.1737219
[Epoch 82; Iter   813/ 1097] train: loss: 0.0001748
[Epoch 82; Iter   843/ 1097] train: loss: 0.0003427
[Epoch 82; Iter   873/ 1097] train: loss: 0.0068219
[Epoch 82; Iter   903/ 1097] train: loss: 0.0136455
[Epoch 82; Iter   933/ 1097] train: loss: 0.0002162
[Epoch 82; Iter   963/ 1097] train: loss: 0.0854639
[Epoch 82; Iter   993/ 1097] train: loss: 0.0044557
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0003670
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0000134
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0019435
[Epoch 82] ogbg-molhiv: 0.671774 val loss: 150.869716
[Epoch 82] ogbg-molhiv: 0.573495 test loss: 141.862833
[Epoch 83; Iter    16/ 1097] train: loss: 0.0005795
[Epoch 83; Iter    46/ 1097] train: loss: 0.0005243
[Epoch 83; Iter    76/ 1097] train: loss: 0.0010346
[Epoch 83; Iter   106/ 1097] train: loss: 0.0000256
[Epoch 83; Iter   136/ 1097] train: loss: 0.0002530
[Epoch 83; Iter   166/ 1097] train: loss: 0.0000097
[Epoch 83; Iter   196/ 1097] train: loss: 0.0011807
[Epoch 83; Iter   226/ 1097] train: loss: 0.0184536
[Epoch 83; Iter   256/ 1097] train: loss: 0.0002539
[Epoch 83; Iter   286/ 1097] train: loss: 0.0000698
[Epoch 83; Iter   316/ 1097] train: loss: 0.0000055
[Epoch 83; Iter   346/ 1097] train: loss: 0.0023310
[Epoch 83; Iter   376/ 1097] train: loss: 0.0259378
[Epoch 83; Iter   406/ 1097] train: loss: 0.0013003
[Epoch 83; Iter   436/ 1097] train: loss: 0.0001232
[Epoch 83; Iter   466/ 1097] train: loss: 0.0000282
[Epoch 83; Iter   496/ 1097] train: loss: 0.0000059
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000213
[Epoch 83; Iter   556/ 1097] train: loss: 0.0001030
[Epoch 83; Iter   586/ 1097] train: loss: 0.0020365
[Epoch 83; Iter   616/ 1097] train: loss: 0.0000648
[Epoch 83; Iter   646/ 1097] train: loss: 0.0000175
[Epoch 83; Iter   676/ 1097] train: loss: 0.0076010
[Epoch 83; Iter   706/ 1097] train: loss: 0.0006861
[Epoch 83; Iter   736/ 1097] train: loss: 0.0019706
[Epoch 83; Iter   766/ 1097] train: loss: 0.0024716
[Epoch 83; Iter   796/ 1097] train: loss: 0.0074987
[Epoch 83; Iter   826/ 1097] train: loss: 0.0139815
[Epoch 83; Iter   856/ 1097] train: loss: 0.0000972
[Epoch 83; Iter   886/ 1097] train: loss: 0.0001136
[Epoch 83; Iter   916/ 1097] train: loss: 0.0003064
[Epoch 83; Iter   946/ 1097] train: loss: 0.0002792
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000868
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0000568
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0012051
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0293714
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0000621
[Epoch 83] ogbg-molhiv: 0.667236 val loss: 13.178477
[Epoch 83] ogbg-molhiv: 0.559901 test loss: 11.610795
[Epoch 84; Iter    29/ 1097] train: loss: 0.0000305
[Epoch 84; Iter    59/ 1097] train: loss: 0.0001211
[Epoch 84; Iter    89/ 1097] train: loss: 0.0001183
[Epoch 84; Iter   119/ 1097] train: loss: 0.0002711
[Epoch 84; Iter   149/ 1097] train: loss: 0.0001315
[Epoch 84; Iter   179/ 1097] train: loss: 0.0001304
[Epoch 84; Iter   209/ 1097] train: loss: 0.0007857
[Epoch 84; Iter   239/ 1097] train: loss: 0.0008139
[Epoch 84; Iter   269/ 1097] train: loss: 0.0001135
[Epoch 84; Iter   299/ 1097] train: loss: 0.0215982
[Epoch 84; Iter   329/ 1097] train: loss: 0.0000141
[Epoch 84; Iter   359/ 1097] train: loss: 0.0001645
[Epoch 84; Iter   389/ 1097] train: loss: 0.0006644
[Epoch 84; Iter   419/ 1097] train: loss: 0.0000812
[Epoch 84; Iter   449/ 1097] train: loss: 0.0061614
[Epoch 84; Iter   479/ 1097] train: loss: 0.0000461
[Epoch 84; Iter   509/ 1097] train: loss: 0.1119636
[Epoch 84; Iter   539/ 1097] train: loss: 0.0001053
[Epoch 84; Iter   569/ 1097] train: loss: 0.0000457
[Epoch 84; Iter   599/ 1097] train: loss: 0.0000918
[Epoch 84; Iter   629/ 1097] train: loss: 0.0000155
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000872
[Epoch 84; Iter   689/ 1097] train: loss: 0.0000810
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000288
[Epoch 84; Iter   749/ 1097] train: loss: 0.0003433
[Epoch 84; Iter   779/ 1097] train: loss: 0.0000335
[Epoch 84; Iter   809/ 1097] train: loss: 0.0080341
[Epoch 84; Iter   839/ 1097] train: loss: 0.0014306
[Epoch 84; Iter   869/ 1097] train: loss: 0.1086031
[Epoch 84; Iter   899/ 1097] train: loss: 0.0036576
[Epoch 84; Iter   929/ 1097] train: loss: 0.0001776
[Epoch 84; Iter   959/ 1097] train: loss: 0.0000193
[Epoch 84; Iter   989/ 1097] train: loss: 0.0000782
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0014902
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0035966
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0307826
[Epoch 84] ogbg-molhiv: 0.640313 val loss: 143.889184
[Epoch 84] ogbg-molhiv: 0.535692 test loss: 128.786750
[Epoch 85; Iter    12/ 1097] train: loss: 0.0001786
[Epoch 85; Iter    42/ 1097] train: loss: 0.0000590
[Epoch 85; Iter    72/ 1097] train: loss: 0.0280122
[Epoch 85; Iter   102/ 1097] train: loss: 0.0000909
[Epoch 85; Iter   132/ 1097] train: loss: 0.0012194
[Epoch 85; Iter   162/ 1097] train: loss: 0.0005552
[Epoch 85; Iter   192/ 1097] train: loss: 0.0000977
[Epoch 85; Iter   222/ 1097] train: loss: 0.0001688
[Epoch 85; Iter   252/ 1097] train: loss: 0.0003782
[Epoch 85; Iter   282/ 1097] train: loss: 0.0000240
[Epoch 85; Iter   312/ 1097] train: loss: 0.0044410
[Epoch 85; Iter   342/ 1097] train: loss: 0.0000466
[Epoch 85; Iter   372/ 1097] train: loss: 0.0005026
[Epoch 85; Iter   402/ 1097] train: loss: 0.0008802
[Epoch 81; Iter   350/ 1097] train: loss: 0.0008921
[Epoch 81; Iter   380/ 1097] train: loss: 0.0154063
[Epoch 81; Iter   410/ 1097] train: loss: 0.0011147
[Epoch 81; Iter   440/ 1097] train: loss: 0.0055503
[Epoch 81; Iter   470/ 1097] train: loss: 0.0000035
[Epoch 81; Iter   500/ 1097] train: loss: 0.0017107
[Epoch 81; Iter   530/ 1097] train: loss: 0.0000604
[Epoch 81; Iter   560/ 1097] train: loss: 0.0005961
[Epoch 81; Iter   590/ 1097] train: loss: 0.0000817
[Epoch 81; Iter   620/ 1097] train: loss: 0.0000585
[Epoch 81; Iter   650/ 1097] train: loss: 0.0000181
[Epoch 81; Iter   680/ 1097] train: loss: 0.0003134
[Epoch 81; Iter   710/ 1097] train: loss: 0.0001975
[Epoch 81; Iter   740/ 1097] train: loss: 0.0000065
[Epoch 81; Iter   770/ 1097] train: loss: 0.0355198
[Epoch 81; Iter   800/ 1097] train: loss: 0.0008424
[Epoch 81; Iter   830/ 1097] train: loss: 0.0000199
[Epoch 81; Iter   860/ 1097] train: loss: 0.0002335
[Epoch 81; Iter   890/ 1097] train: loss: 0.0006397
[Epoch 81; Iter   920/ 1097] train: loss: 0.0220966
[Epoch 81; Iter   950/ 1097] train: loss: 0.0001055
[Epoch 81; Iter   980/ 1097] train: loss: 0.0020489
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0000573
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0004604
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0001795
[Epoch 81] ogbg-molhiv: 0.747985 val loss: 0.527872
[Epoch 81] ogbg-molhiv: 0.733494 test loss: 2.027985
[Epoch 82; Iter     3/ 1097] train: loss: 0.0000128
[Epoch 82; Iter    33/ 1097] train: loss: 0.0003645
[Epoch 82; Iter    63/ 1097] train: loss: 0.0013651
[Epoch 82; Iter    93/ 1097] train: loss: 0.0024703
[Epoch 82; Iter   123/ 1097] train: loss: 0.0006416
[Epoch 82; Iter   153/ 1097] train: loss: 0.0000287
[Epoch 82; Iter   183/ 1097] train: loss: 0.0001997
[Epoch 82; Iter   213/ 1097] train: loss: 0.0003131
[Epoch 82; Iter   243/ 1097] train: loss: 0.0000247
[Epoch 82; Iter   273/ 1097] train: loss: 0.0001050
[Epoch 82; Iter   303/ 1097] train: loss: 0.0309187
[Epoch 82; Iter   333/ 1097] train: loss: 0.0000094
[Epoch 82; Iter   363/ 1097] train: loss: 0.0000366
[Epoch 82; Iter   393/ 1097] train: loss: 0.0000465
[Epoch 82; Iter   423/ 1097] train: loss: 0.0048923
[Epoch 82; Iter   453/ 1097] train: loss: 0.0001051
[Epoch 82; Iter   483/ 1097] train: loss: 0.0024004
[Epoch 82; Iter   513/ 1097] train: loss: 0.0000714
[Epoch 82; Iter   543/ 1097] train: loss: 0.0002558
[Epoch 82; Iter   573/ 1097] train: loss: 0.0012887
[Epoch 82; Iter   603/ 1097] train: loss: 0.0001036
[Epoch 82; Iter   633/ 1097] train: loss: 0.0035726
[Epoch 82; Iter   663/ 1097] train: loss: 0.0000258
[Epoch 82; Iter   693/ 1097] train: loss: 0.0001063
[Epoch 82; Iter   723/ 1097] train: loss: 0.0000678
[Epoch 82; Iter   753/ 1097] train: loss: 0.0004877
[Epoch 82; Iter   783/ 1097] train: loss: 0.0000243
[Epoch 82; Iter   813/ 1097] train: loss: 0.0001678
[Epoch 82; Iter   843/ 1097] train: loss: 0.0002260
[Epoch 82; Iter   873/ 1097] train: loss: 0.0000474
[Epoch 82; Iter   903/ 1097] train: loss: 0.0000863
[Epoch 82; Iter   933/ 1097] train: loss: 0.0000049
[Epoch 82; Iter   963/ 1097] train: loss: 0.0000210
[Epoch 82; Iter   993/ 1097] train: loss: 0.0420777
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0000636
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0000241
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0006968
[Epoch 82] ogbg-molhiv: 0.750034 val loss: 0.539985
[Epoch 82] ogbg-molhiv: 0.748342 test loss: 1.763198
[Epoch 83; Iter    16/ 1097] train: loss: 0.0000234
[Epoch 83; Iter    46/ 1097] train: loss: 0.0006101
[Epoch 83; Iter    76/ 1097] train: loss: 0.0000047
[Epoch 83; Iter   106/ 1097] train: loss: 0.0006495
[Epoch 83; Iter   136/ 1097] train: loss: 0.0127329
[Epoch 83; Iter   166/ 1097] train: loss: 0.0000230
[Epoch 83; Iter   196/ 1097] train: loss: 0.0001191
[Epoch 83; Iter   226/ 1097] train: loss: 0.0007458
[Epoch 83; Iter   256/ 1097] train: loss: 0.0001207
[Epoch 83; Iter   286/ 1097] train: loss: 0.0006103
[Epoch 83; Iter   316/ 1097] train: loss: 0.0000089
[Epoch 83; Iter   346/ 1097] train: loss: 0.0000129
[Epoch 83; Iter   376/ 1097] train: loss: 0.0000126
[Epoch 83; Iter   406/ 1097] train: loss: 0.0000710
[Epoch 83; Iter   436/ 1097] train: loss: 0.0002384
[Epoch 83; Iter   466/ 1097] train: loss: 0.0001131
[Epoch 83; Iter   496/ 1097] train: loss: 0.0001761
[Epoch 83; Iter   526/ 1097] train: loss: 0.0000335
[Epoch 83; Iter   556/ 1097] train: loss: 0.0000136
[Epoch 83; Iter   586/ 1097] train: loss: 0.0004963
[Epoch 83; Iter   616/ 1097] train: loss: 0.0000081
[Epoch 83; Iter   646/ 1097] train: loss: 0.0000224
[Epoch 83; Iter   676/ 1097] train: loss: 0.0022263
[Epoch 83; Iter   706/ 1097] train: loss: 0.0000159
[Epoch 83; Iter   736/ 1097] train: loss: 0.0203613
[Epoch 83; Iter   766/ 1097] train: loss: 0.0006896
[Epoch 83; Iter   796/ 1097] train: loss: 0.0000236
[Epoch 83; Iter   826/ 1097] train: loss: 0.0005415
[Epoch 83; Iter   856/ 1097] train: loss: 0.0002416
[Epoch 83; Iter   886/ 1097] train: loss: 0.0002975
[Epoch 83; Iter   916/ 1097] train: loss: 0.0002289
[Epoch 83; Iter   946/ 1097] train: loss: 0.0000567
[Epoch 83; Iter   976/ 1097] train: loss: 0.0000822
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0000108
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0000629
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0001865
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0314414
[Epoch 83] ogbg-molhiv: 0.765552 val loss: 0.821430
[Epoch 83] ogbg-molhiv: 0.735354 test loss: 2.508446
[Epoch 84; Iter    29/ 1097] train: loss: 0.0001941
[Epoch 84; Iter    59/ 1097] train: loss: 0.0000031
[Epoch 84; Iter    89/ 1097] train: loss: 0.0000495
[Epoch 84; Iter   119/ 1097] train: loss: 0.0000533
[Epoch 84; Iter   149/ 1097] train: loss: 0.0000725
[Epoch 84; Iter   179/ 1097] train: loss: 0.0000082
[Epoch 84; Iter   209/ 1097] train: loss: 0.0004562
[Epoch 84; Iter   239/ 1097] train: loss: 0.0000527
[Epoch 84; Iter   269/ 1097] train: loss: 0.0001912
[Epoch 84; Iter   299/ 1097] train: loss: 0.0000574
[Epoch 84; Iter   329/ 1097] train: loss: 0.0000105
[Epoch 84; Iter   359/ 1097] train: loss: 0.0000116
[Epoch 84; Iter   389/ 1097] train: loss: 0.0001293
[Epoch 84; Iter   419/ 1097] train: loss: 0.0001153
[Epoch 84; Iter   449/ 1097] train: loss: 0.0000481
[Epoch 84; Iter   479/ 1097] train: loss: 0.0047082
[Epoch 84; Iter   509/ 1097] train: loss: 0.0000048
[Epoch 84; Iter   539/ 1097] train: loss: 0.0000015
[Epoch 84; Iter   569/ 1097] train: loss: 0.0000109
[Epoch 84; Iter   599/ 1097] train: loss: 0.0000577
[Epoch 84; Iter   629/ 1097] train: loss: 0.0012401
[Epoch 84; Iter   659/ 1097] train: loss: 0.0000669
[Epoch 84; Iter   689/ 1097] train: loss: 0.0000277
[Epoch 84; Iter   719/ 1097] train: loss: 0.0000232
[Epoch 84; Iter   749/ 1097] train: loss: 0.0000012
[Epoch 84; Iter   779/ 1097] train: loss: 0.0001670
[Epoch 84; Iter   809/ 1097] train: loss: 0.0007318
[Epoch 84; Iter   839/ 1097] train: loss: 0.0000377
[Epoch 84; Iter   869/ 1097] train: loss: 0.0003821
[Epoch 84; Iter   899/ 1097] train: loss: 0.0001271
[Epoch 84; Iter   929/ 1097] train: loss: 0.0006014
[Epoch 84; Iter   959/ 1097] train: loss: 0.0017652
[Epoch 84; Iter   989/ 1097] train: loss: 0.0000987
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0000590
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0000032
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0000179
[Epoch 84] ogbg-molhiv: 0.749492 val loss: 0.895398
[Epoch 84] ogbg-molhiv: 0.746181 test loss: 2.501799
[Epoch 85; Iter    12/ 1097] train: loss: 0.0000279
[Epoch 85; Iter    42/ 1097] train: loss: 0.0005809
[Epoch 85; Iter    72/ 1097] train: loss: 0.0000210
[Epoch 85; Iter   102/ 1097] train: loss: 0.0000501
[Epoch 85; Iter   132/ 1097] train: loss: 0.0000213
[Epoch 85; Iter   162/ 1097] train: loss: 0.0000197
[Epoch 85; Iter   192/ 1097] train: loss: 0.0000009
[Epoch 85; Iter   222/ 1097] train: loss: 0.0000404
[Epoch 85; Iter   252/ 1097] train: loss: 0.0019849
[Epoch 85; Iter   282/ 1097] train: loss: 0.0001347
[Epoch 85; Iter   312/ 1097] train: loss: 0.0000334
[Epoch 85; Iter   342/ 1097] train: loss: 0.0000538
[Epoch 85; Iter   372/ 1097] train: loss: 0.0000361
[Epoch 85; Iter   402/ 1097] train: loss: 0.0000219
[Epoch 85; Iter   432/ 1097] train: loss: 0.0239437
[Epoch 85; Iter   462/ 1097] train: loss: 0.0001118
[Epoch 85; Iter   492/ 1097] train: loss: 0.0000344
[Epoch 85; Iter   522/ 1097] train: loss: 0.0025097
[Epoch 85; Iter   552/ 1097] train: loss: 0.0000643
[Epoch 85; Iter   582/ 1097] train: loss: 0.0064291
[Epoch 85; Iter   612/ 1097] train: loss: 0.0114016
[Epoch 85; Iter   642/ 1097] train: loss: 0.0018925
[Epoch 85; Iter   672/ 1097] train: loss: 0.0000300
[Epoch 85; Iter   702/ 1097] train: loss: 0.0005165
[Epoch 85; Iter   732/ 1097] train: loss: 0.0000931
[Epoch 85; Iter   762/ 1097] train: loss: 0.0013682
[Epoch 85; Iter   792/ 1097] train: loss: 0.0280140
[Epoch 85; Iter   822/ 1097] train: loss: 0.0158819
[Epoch 85; Iter   852/ 1097] train: loss: 0.1295982
[Epoch 85; Iter   882/ 1097] train: loss: 0.0002257
[Epoch 85; Iter   912/ 1097] train: loss: 0.0047584
[Epoch 85; Iter   942/ 1097] train: loss: 0.0162829
[Epoch 85; Iter   972/ 1097] train: loss: 0.0004941
[Epoch 85; Iter  1002/ 1097] train: loss: 0.1170926
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0001584
[Epoch 85; Iter  1062/ 1097] train: loss: 0.1516720
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0008244
[Epoch 85] ogbg-molhiv: 0.710621 val loss: 0.238828
[Epoch 85] ogbg-molhiv: 0.733969 test loss: 0.345464
[Epoch 86; Iter    25/ 1097] train: loss: 0.0001921
[Epoch 86; Iter    55/ 1097] train: loss: 0.0006355
[Epoch 86; Iter    85/ 1097] train: loss: 0.0032528
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000489
[Epoch 86; Iter   145/ 1097] train: loss: 0.0006320
[Epoch 86; Iter   175/ 1097] train: loss: 0.0002169
[Epoch 86; Iter   205/ 1097] train: loss: 0.0006062
[Epoch 86; Iter   235/ 1097] train: loss: 0.0067138
[Epoch 86; Iter   265/ 1097] train: loss: 0.1288829
[Epoch 86; Iter   295/ 1097] train: loss: 0.0052005
[Epoch 86; Iter   325/ 1097] train: loss: 0.0002676
[Epoch 86; Iter   355/ 1097] train: loss: 0.0000706
[Epoch 86; Iter   385/ 1097] train: loss: 0.0001152
[Epoch 86; Iter   415/ 1097] train: loss: 0.0109426
[Epoch 86; Iter   445/ 1097] train: loss: 0.0032998
[Epoch 86; Iter   475/ 1097] train: loss: 0.0008673
[Epoch 86; Iter   505/ 1097] train: loss: 0.0052458
[Epoch 86; Iter   535/ 1097] train: loss: 0.0019218
[Epoch 86; Iter   565/ 1097] train: loss: 0.0462185
[Epoch 86; Iter   595/ 1097] train: loss: 0.0003807
[Epoch 86; Iter   625/ 1097] train: loss: 0.0024753
[Epoch 86; Iter   655/ 1097] train: loss: 0.0000593
[Epoch 86; Iter   685/ 1097] train: loss: 0.0039528
[Epoch 86; Iter   715/ 1097] train: loss: 0.0003830
[Epoch 86; Iter   745/ 1097] train: loss: 0.0047779
[Epoch 86; Iter   775/ 1097] train: loss: 0.0008895
[Epoch 86; Iter   805/ 1097] train: loss: 0.0002077
[Epoch 86; Iter   835/ 1097] train: loss: 0.0007886
[Epoch 86; Iter   865/ 1097] train: loss: 0.0000665
[Epoch 86; Iter   895/ 1097] train: loss: 0.0002411
[Epoch 86; Iter   925/ 1097] train: loss: 0.0023359
[Epoch 86; Iter   955/ 1097] train: loss: 0.0031232
[Epoch 86; Iter   985/ 1097] train: loss: 0.0201788
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0001778
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0001278
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0019296
[Epoch 86] ogbg-molhiv: 0.707773 val loss: 1.554755
[Epoch 86] ogbg-molhiv: 0.708971 test loss: 1.631579
[Epoch 87; Iter     8/ 1097] train: loss: 0.0062009
[Epoch 87; Iter    38/ 1097] train: loss: 0.0033865
[Epoch 87; Iter    68/ 1097] train: loss: 0.0025992
[Epoch 87; Iter    98/ 1097] train: loss: 0.0000437
[Epoch 87; Iter   128/ 1097] train: loss: 0.0002388
[Epoch 87; Iter   158/ 1097] train: loss: 0.0002857
[Epoch 87; Iter   188/ 1097] train: loss: 0.0003326
[Epoch 87; Iter   218/ 1097] train: loss: 0.0006559
[Epoch 87; Iter   248/ 1097] train: loss: 0.0000936
[Epoch 87; Iter   278/ 1097] train: loss: 0.0050122
[Epoch 87; Iter   308/ 1097] train: loss: 0.0000485
[Epoch 87; Iter   338/ 1097] train: loss: 0.0002145
[Epoch 87; Iter   368/ 1097] train: loss: 0.0000850
[Epoch 87; Iter   398/ 1097] train: loss: 0.0000909
[Epoch 87; Iter   428/ 1097] train: loss: 0.0012396
[Epoch 87; Iter   458/ 1097] train: loss: 0.0001448
[Epoch 87; Iter   488/ 1097] train: loss: 0.0003010
[Epoch 87; Iter   518/ 1097] train: loss: 0.0195202
[Epoch 87; Iter   548/ 1097] train: loss: 0.0000433
[Epoch 87; Iter   578/ 1097] train: loss: 0.0015478
[Epoch 87; Iter   608/ 1097] train: loss: 0.0008090
[Epoch 87; Iter   638/ 1097] train: loss: 0.0025642
[Epoch 87; Iter   668/ 1097] train: loss: 0.0011765
[Epoch 87; Iter   698/ 1097] train: loss: 0.0001208
[Epoch 87; Iter   728/ 1097] train: loss: 0.0104863
[Epoch 87; Iter   758/ 1097] train: loss: 0.0004554
[Epoch 87; Iter   788/ 1097] train: loss: 0.0036397
[Epoch 87; Iter   818/ 1097] train: loss: 0.0000220
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000513
[Epoch 87; Iter   878/ 1097] train: loss: 0.0000829
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000571
[Epoch 87; Iter   938/ 1097] train: loss: 0.0093143
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000646
[Epoch 87; Iter   998/ 1097] train: loss: 0.0001693
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0000110
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0014496
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0001619
[Epoch 87] ogbg-molhiv: 0.719228 val loss: 2.003871
[Epoch 87] ogbg-molhiv: 0.724386 test loss: 1.095970
[Epoch 88; Iter    21/ 1097] train: loss: 0.0033241
[Epoch 88; Iter    51/ 1097] train: loss: 0.0004804
[Epoch 88; Iter    81/ 1097] train: loss: 0.0002439
[Epoch 88; Iter   111/ 1097] train: loss: 0.0010114
[Epoch 88; Iter   141/ 1097] train: loss: 0.0010785
[Epoch 88; Iter   171/ 1097] train: loss: 0.0000289
[Epoch 88; Iter   201/ 1097] train: loss: 0.0008289
[Epoch 88; Iter   231/ 1097] train: loss: 0.0043711
[Epoch 88; Iter   261/ 1097] train: loss: 0.0021224
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000533
[Epoch 88; Iter   321/ 1097] train: loss: 0.0021050
[Epoch 88; Iter   351/ 1097] train: loss: 0.0004132
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000427
[Epoch 88; Iter   411/ 1097] train: loss: 0.0001746
[Epoch 88; Iter   441/ 1097] train: loss: 0.0003021
[Epoch 88; Iter   471/ 1097] train: loss: 0.0000088
[Epoch 88; Iter   501/ 1097] train: loss: 0.0000961
[Epoch 88; Iter   531/ 1097] train: loss: 0.0006903
[Epoch 88; Iter   561/ 1097] train: loss: 0.0011003
[Epoch 88; Iter   591/ 1097] train: loss: 0.0003507
[Epoch 88; Iter   621/ 1097] train: loss: 0.0001046
[Epoch 88; Iter   651/ 1097] train: loss: 0.0004230
[Epoch 88; Iter   681/ 1097] train: loss: 0.0004654
[Epoch 88; Iter   711/ 1097] train: loss: 0.0086359
[Epoch 88; Iter   741/ 1097] train: loss: 0.0000826
[Epoch 88; Iter   771/ 1097] train: loss: 0.0001946
[Epoch 88; Iter   801/ 1097] train: loss: 0.0000279
[Epoch 88; Iter   831/ 1097] train: loss: 0.0001661
[Epoch 88; Iter   861/ 1097] train: loss: 0.0013436
[Epoch 88; Iter   891/ 1097] train: loss: 0.0002146
[Epoch 88; Iter   921/ 1097] train: loss: 0.0001063
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000689
[Epoch 88; Iter   981/ 1097] train: loss: 0.0085144
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0003619
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0005729
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0026400
[Epoch 88] ogbg-molhiv: 0.807273 val loss: 1.949777
[Epoch 88] ogbg-molhiv: 0.734331 test loss: 1.747373
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000486
[Epoch 89; Iter    34/ 1097] train: loss: 0.0001968
[Epoch 89; Iter    64/ 1097] train: loss: 0.0004742
[Epoch 89; Iter    94/ 1097] train: loss: 0.0000276
[Epoch 89; Iter   124/ 1097] train: loss: 0.0000343
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000318
[Epoch 89; Iter   184/ 1097] train: loss: 0.0003580
[Epoch 89; Iter   214/ 1097] train: loss: 0.0101186
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000332
[Epoch 89; Iter   274/ 1097] train: loss: 0.0005782
[Epoch 89; Iter   304/ 1097] train: loss: 0.0001536
[Epoch 89; Iter   334/ 1097] train: loss: 0.0001458
[Epoch 89; Iter   364/ 1097] train: loss: 0.0008216
[Epoch 89; Iter   394/ 1097] train: loss: 0.0003344
[Epoch 89; Iter   424/ 1097] train: loss: 0.0001308
[Epoch 89; Iter   454/ 1097] train: loss: 0.0026494
[Epoch 89; Iter   484/ 1097] train: loss: 0.0004811
[Epoch 85; Iter   432/ 1097] train: loss: 0.0005124
[Epoch 85; Iter   462/ 1097] train: loss: 0.0000853
[Epoch 85; Iter   492/ 1097] train: loss: 0.0884712
[Epoch 85; Iter   522/ 1097] train: loss: 0.0002283
[Epoch 85; Iter   552/ 1097] train: loss: 0.0165684
[Epoch 85; Iter   582/ 1097] train: loss: 0.0005012
[Epoch 85; Iter   612/ 1097] train: loss: 0.0000792
[Epoch 85; Iter   642/ 1097] train: loss: 0.0251682
[Epoch 85; Iter   672/ 1097] train: loss: 0.0023606
[Epoch 85; Iter   702/ 1097] train: loss: 0.0877884
[Epoch 85; Iter   732/ 1097] train: loss: 0.0012990
[Epoch 85; Iter   762/ 1097] train: loss: 0.0004141
[Epoch 85; Iter   792/ 1097] train: loss: 0.0000473
[Epoch 85; Iter   822/ 1097] train: loss: 0.0345106
[Epoch 85; Iter   852/ 1097] train: loss: 0.0007960
[Epoch 85; Iter   882/ 1097] train: loss: 0.0014110
[Epoch 85; Iter   912/ 1097] train: loss: 0.0076583
[Epoch 85; Iter   942/ 1097] train: loss: 0.0623357
[Epoch 85; Iter   972/ 1097] train: loss: 0.0002445
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0136190
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0000996
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0014352
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0250672
[Epoch 85] ogbg-molhiv: 0.718597 val loss: 0.997321
[Epoch 85] ogbg-molhiv: 0.708544 test loss: 0.787657
[Epoch 86; Iter    25/ 1097] train: loss: 0.0029592
[Epoch 86; Iter    55/ 1097] train: loss: 0.0003093
[Epoch 86; Iter    85/ 1097] train: loss: 0.0141804
[Epoch 86; Iter   115/ 1097] train: loss: 0.0002345
[Epoch 86; Iter   145/ 1097] train: loss: 0.0003679
[Epoch 86; Iter   175/ 1097] train: loss: 0.0020630
[Epoch 86; Iter   205/ 1097] train: loss: 0.0005947
[Epoch 86; Iter   235/ 1097] train: loss: 0.0000767
[Epoch 86; Iter   265/ 1097] train: loss: 0.0009085
[Epoch 86; Iter   295/ 1097] train: loss: 0.0027791
[Epoch 86; Iter   325/ 1097] train: loss: 0.0022049
[Epoch 86; Iter   355/ 1097] train: loss: 0.0020647
[Epoch 86; Iter   385/ 1097] train: loss: 0.0088330
[Epoch 86; Iter   415/ 1097] train: loss: 0.0056102
[Epoch 86; Iter   445/ 1097] train: loss: 0.0121038
[Epoch 86; Iter   475/ 1097] train: loss: 0.0023147
[Epoch 86; Iter   505/ 1097] train: loss: 0.0057032
[Epoch 86; Iter   535/ 1097] train: loss: 0.0261257
[Epoch 86; Iter   565/ 1097] train: loss: 0.0001064
[Epoch 86; Iter   595/ 1097] train: loss: 0.0018014
[Epoch 86; Iter   625/ 1097] train: loss: 0.0001125
[Epoch 86; Iter   655/ 1097] train: loss: 0.0026828
[Epoch 86; Iter   685/ 1097] train: loss: 0.0041885
[Epoch 86; Iter   715/ 1097] train: loss: 0.0002121
[Epoch 86; Iter   745/ 1097] train: loss: 0.0001496
[Epoch 86; Iter   775/ 1097] train: loss: 0.0002995
[Epoch 86; Iter   805/ 1097] train: loss: 0.0008177
[Epoch 86; Iter   835/ 1097] train: loss: 0.0005022
[Epoch 86; Iter   865/ 1097] train: loss: 0.1079910
[Epoch 86; Iter   895/ 1097] train: loss: 0.0001738
[Epoch 86; Iter   925/ 1097] train: loss: 0.0084623
[Epoch 86; Iter   955/ 1097] train: loss: 0.0003852
[Epoch 86; Iter   985/ 1097] train: loss: 0.0021383
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0003668
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0000570
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0147928
[Epoch 86] ogbg-molhiv: 0.709576 val loss: 0.948193
[Epoch 86] ogbg-molhiv: 0.705336 test loss: 0.938840
[Epoch 87; Iter     8/ 1097] train: loss: 0.0021806
[Epoch 87; Iter    38/ 1097] train: loss: 0.0008767
[Epoch 87; Iter    68/ 1097] train: loss: 0.0002480
[Epoch 87; Iter    98/ 1097] train: loss: 0.0080726
[Epoch 87; Iter   128/ 1097] train: loss: 0.0000222
[Epoch 87; Iter   158/ 1097] train: loss: 0.0002614
[Epoch 87; Iter   188/ 1097] train: loss: 0.0046216
[Epoch 87; Iter   218/ 1097] train: loss: 0.0001373
[Epoch 87; Iter   248/ 1097] train: loss: 0.0000405
[Epoch 87; Iter   278/ 1097] train: loss: 0.0022326
[Epoch 87; Iter   308/ 1097] train: loss: 0.0178502
[Epoch 87; Iter   338/ 1097] train: loss: 0.0009416
[Epoch 87; Iter   368/ 1097] train: loss: 0.0000845
[Epoch 87; Iter   398/ 1097] train: loss: 0.0010745
[Epoch 87; Iter   428/ 1097] train: loss: 0.0001834
[Epoch 87; Iter   458/ 1097] train: loss: 0.0002042
[Epoch 87; Iter   488/ 1097] train: loss: 0.0004090
[Epoch 87; Iter   518/ 1097] train: loss: 0.0004259
[Epoch 87; Iter   548/ 1097] train: loss: 0.0006678
[Epoch 87; Iter   578/ 1097] train: loss: 0.0019178
[Epoch 87; Iter   608/ 1097] train: loss: 0.0015162
[Epoch 87; Iter   638/ 1097] train: loss: 0.0001810
[Epoch 87; Iter   668/ 1097] train: loss: 0.0003014
[Epoch 87; Iter   698/ 1097] train: loss: 0.0005090
[Epoch 87; Iter   728/ 1097] train: loss: 0.0041590
[Epoch 87; Iter   758/ 1097] train: loss: 0.0000945
[Epoch 87; Iter   788/ 1097] train: loss: 0.0001249
[Epoch 87; Iter   818/ 1097] train: loss: 0.0014653
[Epoch 87; Iter   848/ 1097] train: loss: 0.0001071
[Epoch 87; Iter   878/ 1097] train: loss: 0.0000573
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000065
[Epoch 87; Iter   938/ 1097] train: loss: 0.0005685
[Epoch 87; Iter   968/ 1097] train: loss: 0.0002129
[Epoch 87; Iter   998/ 1097] train: loss: 0.0005301
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0009709
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0082954
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0053158
[Epoch 87] ogbg-molhiv: 0.710765 val loss: 0.756096
[Epoch 87] ogbg-molhiv: 0.709929 test loss: 0.630942
[Epoch 88; Iter    21/ 1097] train: loss: 0.0000285
[Epoch 88; Iter    51/ 1097] train: loss: 0.0000690
[Epoch 88; Iter    81/ 1097] train: loss: 0.0001160
[Epoch 88; Iter   111/ 1097] train: loss: 0.0023733
[Epoch 88; Iter   141/ 1097] train: loss: 0.0137076
[Epoch 88; Iter   171/ 1097] train: loss: 0.0000818
[Epoch 88; Iter   201/ 1097] train: loss: 0.0000286
[Epoch 88; Iter   231/ 1097] train: loss: 0.0006919
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000064
[Epoch 88; Iter   291/ 1097] train: loss: 0.0003206
[Epoch 88; Iter   321/ 1097] train: loss: 0.0000662
[Epoch 88; Iter   351/ 1097] train: loss: 0.0003334
[Epoch 88; Iter   381/ 1097] train: loss: 0.0002506
[Epoch 88; Iter   411/ 1097] train: loss: 0.0001266
[Epoch 88; Iter   441/ 1097] train: loss: 0.0002230
[Epoch 88; Iter   471/ 1097] train: loss: 0.0008570
[Epoch 88; Iter   501/ 1097] train: loss: 0.0084246
[Epoch 88; Iter   531/ 1097] train: loss: 0.0033337
[Epoch 88; Iter   561/ 1097] train: loss: 0.0023065
[Epoch 88; Iter   591/ 1097] train: loss: 0.0007210
[Epoch 88; Iter   621/ 1097] train: loss: 0.0000787
[Epoch 88; Iter   651/ 1097] train: loss: 0.0000325
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000576
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000625
[Epoch 88; Iter   741/ 1097] train: loss: 0.0012703
[Epoch 88; Iter   771/ 1097] train: loss: 0.0071173
[Epoch 88; Iter   801/ 1097] train: loss: 0.0003226
[Epoch 88; Iter   831/ 1097] train: loss: 0.0002646
[Epoch 88; Iter   861/ 1097] train: loss: 0.0001323
[Epoch 88; Iter   891/ 1097] train: loss: 0.0007581
[Epoch 88; Iter   921/ 1097] train: loss: 0.0002397
[Epoch 88; Iter   951/ 1097] train: loss: 0.0002228
[Epoch 88; Iter   981/ 1097] train: loss: 0.0003542
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0018692
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0000255
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0187777
[Epoch 88] ogbg-molhiv: 0.697770 val loss: 0.840784
[Epoch 88] ogbg-molhiv: 0.693497 test loss: 0.586847
[Epoch 89; Iter     4/ 1097] train: loss: 0.0003058
[Epoch 89; Iter    34/ 1097] train: loss: 0.0062387
[Epoch 89; Iter    64/ 1097] train: loss: 0.0000611
[Epoch 89; Iter    94/ 1097] train: loss: 0.0003778
[Epoch 89; Iter   124/ 1097] train: loss: 0.0009758
[Epoch 89; Iter   154/ 1097] train: loss: 0.0024030
[Epoch 89; Iter   184/ 1097] train: loss: 0.0004216
[Epoch 89; Iter   214/ 1097] train: loss: 0.0013689
[Epoch 89; Iter   244/ 1097] train: loss: 0.0016621
[Epoch 89; Iter   274/ 1097] train: loss: 0.0105659
[Epoch 89; Iter   304/ 1097] train: loss: 0.0003771
[Epoch 89; Iter   334/ 1097] train: loss: 0.0110131
[Epoch 89; Iter   364/ 1097] train: loss: 0.0011514
[Epoch 89; Iter   394/ 1097] train: loss: 0.0000626
[Epoch 89; Iter   424/ 1097] train: loss: 0.0010162
[Epoch 89; Iter   454/ 1097] train: loss: 0.0985563
[Epoch 89; Iter   484/ 1097] train: loss: 0.0012305
[Epoch 85; Iter   432/ 1097] train: loss: 0.0002873
[Epoch 85; Iter   462/ 1097] train: loss: 0.0009571
[Epoch 85; Iter   492/ 1097] train: loss: 0.0000277
[Epoch 85; Iter   522/ 1097] train: loss: 0.0024809
[Epoch 85; Iter   552/ 1097] train: loss: 0.0000977
[Epoch 85; Iter   582/ 1097] train: loss: 0.0004637
[Epoch 85; Iter   612/ 1097] train: loss: 0.0003410
[Epoch 85; Iter   642/ 1097] train: loss: 0.0000451
[Epoch 85; Iter   672/ 1097] train: loss: 0.0010559
[Epoch 85; Iter   702/ 1097] train: loss: 0.0003152
[Epoch 85; Iter   732/ 1097] train: loss: 0.0004701
[Epoch 85; Iter   762/ 1097] train: loss: 0.0000753
[Epoch 85; Iter   792/ 1097] train: loss: 0.0000418
[Epoch 85; Iter   822/ 1097] train: loss: 0.0005311
[Epoch 85; Iter   852/ 1097] train: loss: 0.0000520
[Epoch 85; Iter   882/ 1097] train: loss: 0.0001883
[Epoch 85; Iter   912/ 1097] train: loss: 0.0009749
[Epoch 85; Iter   942/ 1097] train: loss: 0.0059844
[Epoch 85; Iter   972/ 1097] train: loss: 0.0012957
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0001017
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0003363
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0024972
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0001300
[Epoch 85] ogbg-molhiv: 0.781581 val loss: 0.281522
[Epoch 85] ogbg-molhiv: 0.728906 test loss: 0.422829
[Epoch 86; Iter    25/ 1097] train: loss: 0.0000907
[Epoch 86; Iter    55/ 1097] train: loss: 0.0000259
[Epoch 86; Iter    85/ 1097] train: loss: 0.0010279
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000267
[Epoch 86; Iter   145/ 1097] train: loss: 0.0017724
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000096
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000123
[Epoch 86; Iter   235/ 1097] train: loss: 0.0000643
[Epoch 86; Iter   265/ 1097] train: loss: 0.0000097
[Epoch 86; Iter   295/ 1097] train: loss: 0.0000078
[Epoch 86; Iter   325/ 1097] train: loss: 0.0013710
[Epoch 86; Iter   355/ 1097] train: loss: 0.0000914
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000215
[Epoch 86; Iter   415/ 1097] train: loss: 0.0000986
[Epoch 86; Iter   445/ 1097] train: loss: 0.0004021
[Epoch 86; Iter   475/ 1097] train: loss: 0.0010145
[Epoch 86; Iter   505/ 1097] train: loss: 0.0008070
[Epoch 86; Iter   535/ 1097] train: loss: 0.0020189
[Epoch 86; Iter   565/ 1097] train: loss: 0.0000774
[Epoch 86; Iter   595/ 1097] train: loss: 0.0008627
[Epoch 86; Iter   625/ 1097] train: loss: 0.0000925
[Epoch 86; Iter   655/ 1097] train: loss: 0.0000136
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000362
[Epoch 86; Iter   715/ 1097] train: loss: 0.0001592
[Epoch 86; Iter   745/ 1097] train: loss: 0.0000390
[Epoch 86; Iter   775/ 1097] train: loss: 0.0000236
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000803
[Epoch 86; Iter   835/ 1097] train: loss: 0.0002212
[Epoch 86; Iter   865/ 1097] train: loss: 0.0031680
[Epoch 86; Iter   895/ 1097] train: loss: 0.0001020
[Epoch 86; Iter   925/ 1097] train: loss: 0.0000830
[Epoch 86; Iter   955/ 1097] train: loss: 0.0000412
[Epoch 86; Iter   985/ 1097] train: loss: 0.0000253
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0000285
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0000149
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0001266
[Epoch 86] ogbg-molhiv: 0.784829 val loss: 0.282234
[Epoch 86] ogbg-molhiv: 0.727050 test loss: 0.446916
[Epoch 87; Iter     8/ 1097] train: loss: 0.0002705
[Epoch 87; Iter    38/ 1097] train: loss: 0.0000484
[Epoch 87; Iter    68/ 1097] train: loss: 0.0000910
[Epoch 87; Iter    98/ 1097] train: loss: 0.0008598
[Epoch 87; Iter   128/ 1097] train: loss: 0.0001502
[Epoch 87; Iter   158/ 1097] train: loss: 0.0000831
[Epoch 87; Iter   188/ 1097] train: loss: 0.0001033
[Epoch 87; Iter   218/ 1097] train: loss: 0.0046162
[Epoch 87; Iter   248/ 1097] train: loss: 0.0000841
[Epoch 87; Iter   278/ 1097] train: loss: 0.0000093
[Epoch 87; Iter   308/ 1097] train: loss: 0.0015865
[Epoch 87; Iter   338/ 1097] train: loss: 0.0273058
[Epoch 87; Iter   368/ 1097] train: loss: 0.0232277
[Epoch 87; Iter   398/ 1097] train: loss: 0.0001041
[Epoch 87; Iter   428/ 1097] train: loss: 0.0003101
[Epoch 87; Iter   458/ 1097] train: loss: 0.0000184
[Epoch 87; Iter   488/ 1097] train: loss: 0.0000302
[Epoch 87; Iter   518/ 1097] train: loss: 0.0005641
[Epoch 87; Iter   548/ 1097] train: loss: 0.0001935
[Epoch 87; Iter   578/ 1097] train: loss: 0.0004372
[Epoch 87; Iter   608/ 1097] train: loss: 0.0000192
[Epoch 87; Iter   638/ 1097] train: loss: 0.0079375
[Epoch 87; Iter   668/ 1097] train: loss: 0.0000602
[Epoch 87; Iter   698/ 1097] train: loss: 0.0774418
[Epoch 87; Iter   728/ 1097] train: loss: 0.0004674
[Epoch 87; Iter   758/ 1097] train: loss: 0.0020106
[Epoch 87; Iter   788/ 1097] train: loss: 0.0027761
[Epoch 87; Iter   818/ 1097] train: loss: 0.0022688
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000043
[Epoch 87; Iter   878/ 1097] train: loss: 0.0004220
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000173
[Epoch 87; Iter   938/ 1097] train: loss: 0.0003457
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000473
[Epoch 87; Iter   998/ 1097] train: loss: 0.0000102
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0003434
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0000750
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0002049
[Epoch 87] ogbg-molhiv: 0.788994 val loss: 0.310632
[Epoch 87] ogbg-molhiv: 0.732546 test loss: 0.446725
[Epoch 88; Iter    21/ 1097] train: loss: 0.0024234
[Epoch 88; Iter    51/ 1097] train: loss: 0.0000376
[Epoch 88; Iter    81/ 1097] train: loss: 0.0036069
[Epoch 88; Iter   111/ 1097] train: loss: 0.0072029
[Epoch 88; Iter   141/ 1097] train: loss: 0.0000426
[Epoch 88; Iter   171/ 1097] train: loss: 0.0000241
[Epoch 88; Iter   201/ 1097] train: loss: 0.0001440
[Epoch 88; Iter   231/ 1097] train: loss: 0.0059983
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000498
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000437
[Epoch 88; Iter   321/ 1097] train: loss: 0.0006909
[Epoch 88; Iter   351/ 1097] train: loss: 0.0011245
[Epoch 88; Iter   381/ 1097] train: loss: 0.0002404
[Epoch 88; Iter   411/ 1097] train: loss: 0.0001225
[Epoch 88; Iter   441/ 1097] train: loss: 0.0000088
[Epoch 88; Iter   471/ 1097] train: loss: 0.0000428
[Epoch 88; Iter   501/ 1097] train: loss: 0.0011934
[Epoch 88; Iter   531/ 1097] train: loss: 0.0000243
[Epoch 88; Iter   561/ 1097] train: loss: 0.0001855
[Epoch 88; Iter   591/ 1097] train: loss: 0.0001677
[Epoch 88; Iter   621/ 1097] train: loss: 0.0001801
[Epoch 88; Iter   651/ 1097] train: loss: 0.0301826
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000298
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000572
[Epoch 88; Iter   741/ 1097] train: loss: 0.0000060
[Epoch 88; Iter   771/ 1097] train: loss: 0.0002334
[Epoch 88; Iter   801/ 1097] train: loss: 0.0000242
[Epoch 88; Iter   831/ 1097] train: loss: 0.0002146
[Epoch 88; Iter   861/ 1097] train: loss: 0.0000045
[Epoch 88; Iter   891/ 1097] train: loss: 0.0013014
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000195
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000012
[Epoch 88; Iter   981/ 1097] train: loss: 0.0000426
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0000123
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0140555
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0000128
[Epoch 88] ogbg-molhiv: 0.778268 val loss: 0.279729
[Epoch 88] ogbg-molhiv: 0.725557 test loss: 0.528325
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000019
[Epoch 89; Iter    34/ 1097] train: loss: 0.0000086
[Epoch 89; Iter    64/ 1097] train: loss: 0.0000111
[Epoch 89; Iter    94/ 1097] train: loss: 0.0000110
[Epoch 89; Iter   124/ 1097] train: loss: 0.0000234
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000156
[Epoch 89; Iter   184/ 1097] train: loss: 0.0018186
[Epoch 89; Iter   214/ 1097] train: loss: 0.0000256
[Epoch 89; Iter   244/ 1097] train: loss: 0.0005859
[Epoch 89; Iter   274/ 1097] train: loss: 0.0016734
[Epoch 89; Iter   304/ 1097] train: loss: 0.0000071
[Epoch 89; Iter   334/ 1097] train: loss: 0.0002208
[Epoch 89; Iter   364/ 1097] train: loss: 0.0000023
[Epoch 89; Iter   394/ 1097] train: loss: 0.0000148
[Epoch 89; Iter   424/ 1097] train: loss: 0.0013526
[Epoch 89; Iter   454/ 1097] train: loss: 0.0003266
[Epoch 89; Iter   484/ 1097] train: loss: 0.0095466
[Epoch 85; Iter   432/ 1097] train: loss: 0.0000323
[Epoch 85; Iter   462/ 1097] train: loss: 0.0019488
[Epoch 85; Iter   492/ 1097] train: loss: 0.0126744
[Epoch 85; Iter   522/ 1097] train: loss: 0.0000586
[Epoch 85; Iter   552/ 1097] train: loss: 0.0000016
[Epoch 85; Iter   582/ 1097] train: loss: 0.0428708
[Epoch 85; Iter   612/ 1097] train: loss: 0.0007886
[Epoch 85; Iter   642/ 1097] train: loss: 0.0000845
[Epoch 85; Iter   672/ 1097] train: loss: 0.0004933
[Epoch 85; Iter   702/ 1097] train: loss: 0.0338913
[Epoch 85; Iter   732/ 1097] train: loss: 0.0000081
[Epoch 85; Iter   762/ 1097] train: loss: 0.0001441
[Epoch 85; Iter   792/ 1097] train: loss: 0.0013644
[Epoch 85; Iter   822/ 1097] train: loss: 0.0003768
[Epoch 85; Iter   852/ 1097] train: loss: 0.0044288
[Epoch 85; Iter   882/ 1097] train: loss: 0.0001263
[Epoch 85; Iter   912/ 1097] train: loss: 0.0024868
[Epoch 85; Iter   942/ 1097] train: loss: 0.0002312
[Epoch 85; Iter   972/ 1097] train: loss: 0.0002524
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0006866
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0000804
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0001285
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0000109
[Epoch 85] ogbg-molhiv: 0.761344 val loss: 0.239442
[Epoch 85] ogbg-molhiv: 0.723096 test loss: 0.395568
[Epoch 86; Iter    25/ 1097] train: loss: 0.0000012
[Epoch 86; Iter    55/ 1097] train: loss: 0.0000220
[Epoch 86; Iter    85/ 1097] train: loss: 0.0001657
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000036
[Epoch 86; Iter   145/ 1097] train: loss: 0.0000176
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000352
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000544
[Epoch 86; Iter   235/ 1097] train: loss: 0.0006934
[Epoch 86; Iter   265/ 1097] train: loss: 0.0018512
[Epoch 86; Iter   295/ 1097] train: loss: 0.0079130
[Epoch 86; Iter   325/ 1097] train: loss: 0.0000265
[Epoch 86; Iter   355/ 1097] train: loss: 0.0005817
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000574
[Epoch 86; Iter   415/ 1097] train: loss: 0.0001797
[Epoch 86; Iter   445/ 1097] train: loss: 0.0000059
[Epoch 86; Iter   475/ 1097] train: loss: 0.0002802
[Epoch 86; Iter   505/ 1097] train: loss: 0.0002044
[Epoch 86; Iter   535/ 1097] train: loss: 0.0001372
[Epoch 86; Iter   565/ 1097] train: loss: 0.0000233
[Epoch 86; Iter   595/ 1097] train: loss: 0.0001081
[Epoch 86; Iter   625/ 1097] train: loss: 0.0000281
[Epoch 86; Iter   655/ 1097] train: loss: 0.0003167
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000079
[Epoch 86; Iter   715/ 1097] train: loss: 0.0000405
[Epoch 86; Iter   745/ 1097] train: loss: 0.0000536
[Epoch 86; Iter   775/ 1097] train: loss: 0.0112004
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000107
[Epoch 86; Iter   835/ 1097] train: loss: 0.0030124
[Epoch 86; Iter   865/ 1097] train: loss: 0.0000107
[Epoch 86; Iter   895/ 1097] train: loss: 0.0000132
[Epoch 86; Iter   925/ 1097] train: loss: 0.0176858
[Epoch 86; Iter   955/ 1097] train: loss: 0.0000743
[Epoch 86; Iter   985/ 1097] train: loss: 0.0000514
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0445228
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0007334
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0070868
[Epoch 86] ogbg-molhiv: 0.770714 val loss: 0.240145
[Epoch 86] ogbg-molhiv: 0.740897 test loss: 0.381308
[Epoch 87; Iter     8/ 1097] train: loss: 0.0094107
[Epoch 87; Iter    38/ 1097] train: loss: 0.0122023
[Epoch 87; Iter    68/ 1097] train: loss: 0.0013469
[Epoch 87; Iter    98/ 1097] train: loss: 0.0025325
[Epoch 87; Iter   128/ 1097] train: loss: 0.0000178
[Epoch 87; Iter   158/ 1097] train: loss: 0.0001762
[Epoch 87; Iter   188/ 1097] train: loss: 0.0000128
[Epoch 87; Iter   218/ 1097] train: loss: 0.0348290
[Epoch 87; Iter   248/ 1097] train: loss: 0.0012392
[Epoch 87; Iter   278/ 1097] train: loss: 0.0012253
[Epoch 87; Iter   308/ 1097] train: loss: 0.0002217
[Epoch 87; Iter   338/ 1097] train: loss: 0.0000216
[Epoch 87; Iter   368/ 1097] train: loss: 0.0001095
[Epoch 87; Iter   398/ 1097] train: loss: 0.0162941
[Epoch 87; Iter   428/ 1097] train: loss: 0.0000469
[Epoch 87; Iter   458/ 1097] train: loss: 0.0000577
[Epoch 87; Iter   488/ 1097] train: loss: 0.0001901
[Epoch 87; Iter   518/ 1097] train: loss: 0.0005371
[Epoch 87; Iter   548/ 1097] train: loss: 0.0000293
[Epoch 87; Iter   578/ 1097] train: loss: 0.0007435
[Epoch 87; Iter   608/ 1097] train: loss: 0.0009889
[Epoch 87; Iter   638/ 1097] train: loss: 0.0000769
[Epoch 87; Iter   668/ 1097] train: loss: 0.0004400
[Epoch 87; Iter   698/ 1097] train: loss: 0.0000605
[Epoch 87; Iter   728/ 1097] train: loss: 0.0000180
[Epoch 87; Iter   758/ 1097] train: loss: 0.0009851
[Epoch 87; Iter   788/ 1097] train: loss: 0.0000577
[Epoch 87; Iter   818/ 1097] train: loss: 0.0001775
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000578
[Epoch 87; Iter   878/ 1097] train: loss: 0.0000111
[Epoch 87; Iter   908/ 1097] train: loss: 0.0001211
[Epoch 87; Iter   938/ 1097] train: loss: 0.0000114
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000306
[Epoch 87; Iter   998/ 1097] train: loss: 0.0051049
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0000228
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0003018
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0082490
[Epoch 87] ogbg-molhiv: 0.768421 val loss: 0.248648
[Epoch 87] ogbg-molhiv: 0.729589 test loss: 0.405363
[Epoch 88; Iter    21/ 1097] train: loss: 0.0000630
[Epoch 88; Iter    51/ 1097] train: loss: 0.0099400
[Epoch 88; Iter    81/ 1097] train: loss: 0.0000306
[Epoch 88; Iter   111/ 1097] train: loss: 0.0002689
[Epoch 88; Iter   141/ 1097] train: loss: 0.0001742
[Epoch 88; Iter   171/ 1097] train: loss: 0.0000448
[Epoch 88; Iter   201/ 1097] train: loss: 0.0006605
[Epoch 88; Iter   231/ 1097] train: loss: 0.0011268
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000100
[Epoch 88; Iter   291/ 1097] train: loss: 0.0001629
[Epoch 88; Iter   321/ 1097] train: loss: 0.0000744
[Epoch 88; Iter   351/ 1097] train: loss: 0.0016258
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000030
[Epoch 88; Iter   411/ 1097] train: loss: 0.0001145
[Epoch 88; Iter   441/ 1097] train: loss: 0.0017646
[Epoch 88; Iter   471/ 1097] train: loss: 0.0002658
[Epoch 88; Iter   501/ 1097] train: loss: 0.0000075
[Epoch 88; Iter   531/ 1097] train: loss: 0.0006221
[Epoch 88; Iter   561/ 1097] train: loss: 0.0004934
[Epoch 88; Iter   591/ 1097] train: loss: 0.0001191
[Epoch 88; Iter   621/ 1097] train: loss: 0.0000740
[Epoch 88; Iter   651/ 1097] train: loss: 0.0002109
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000260
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000065
[Epoch 88; Iter   741/ 1097] train: loss: 0.0089850
[Epoch 88; Iter   771/ 1097] train: loss: 0.0003366
[Epoch 88; Iter   801/ 1097] train: loss: 0.0000210
[Epoch 88; Iter   831/ 1097] train: loss: 0.0000344
[Epoch 88; Iter   861/ 1097] train: loss: 0.0000762
[Epoch 88; Iter   891/ 1097] train: loss: 0.0000832
[Epoch 88; Iter   921/ 1097] train: loss: 0.0003355
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000802
[Epoch 88; Iter   981/ 1097] train: loss: 0.0000406
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0001341
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0007621
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0000408
[Epoch 88] ogbg-molhiv: 0.772569 val loss: 0.243604
[Epoch 88] ogbg-molhiv: 0.741528 test loss: 0.372511
[Epoch 89; Iter     4/ 1097] train: loss: 0.0011811
[Epoch 89; Iter    34/ 1097] train: loss: 0.0004821
[Epoch 89; Iter    64/ 1097] train: loss: 0.0005076
[Epoch 89; Iter    94/ 1097] train: loss: 0.0006493
[Epoch 89; Iter   124/ 1097] train: loss: 0.0001827
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000552
[Epoch 89; Iter   184/ 1097] train: loss: 0.0033620
[Epoch 89; Iter   214/ 1097] train: loss: 0.0015811
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000456
[Epoch 89; Iter   274/ 1097] train: loss: 0.0079147
[Epoch 89; Iter   304/ 1097] train: loss: 0.0004582
[Epoch 89; Iter   334/ 1097] train: loss: 0.0007609
[Epoch 89; Iter   364/ 1097] train: loss: 0.0011244
[Epoch 89; Iter   394/ 1097] train: loss: 0.0000036
[Epoch 89; Iter   424/ 1097] train: loss: 0.0001597
[Epoch 89; Iter   454/ 1097] train: loss: 0.0000236
[Epoch 89; Iter   484/ 1097] train: loss: 0.0000949
[Epoch 85; Iter   432/ 1097] train: loss: 0.0019250
[Epoch 85; Iter   462/ 1097] train: loss: 0.0000792
[Epoch 85; Iter   492/ 1097] train: loss: 0.0002858
[Epoch 85; Iter   522/ 1097] train: loss: 0.0000354
[Epoch 85; Iter   552/ 1097] train: loss: 0.0001019
[Epoch 85; Iter   582/ 1097] train: loss: 0.0007735
[Epoch 85; Iter   612/ 1097] train: loss: 0.0004463
[Epoch 85; Iter   642/ 1097] train: loss: 0.0000652
[Epoch 85; Iter   672/ 1097] train: loss: 0.0000721
[Epoch 85; Iter   702/ 1097] train: loss: 0.0000224
[Epoch 85; Iter   732/ 1097] train: loss: 0.0003323
[Epoch 85; Iter   762/ 1097] train: loss: 0.0015457
[Epoch 85; Iter   792/ 1097] train: loss: 0.0003668
[Epoch 85; Iter   822/ 1097] train: loss: 0.0000571
[Epoch 85; Iter   852/ 1097] train: loss: 0.0003797
[Epoch 85; Iter   882/ 1097] train: loss: 0.0001040
[Epoch 85; Iter   912/ 1097] train: loss: 0.0225464
[Epoch 85; Iter   942/ 1097] train: loss: 0.0006872
[Epoch 85; Iter   972/ 1097] train: loss: 0.0000904
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0001896
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0043724
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0001533
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0005725
[Epoch 85] ogbg-molhiv: 0.757860 val loss: 0.371366
[Epoch 85] ogbg-molhiv: 0.759561 test loss: 0.353187
[Epoch 86; Iter    25/ 1097] train: loss: 0.0014333
[Epoch 86; Iter    55/ 1097] train: loss: 0.0001778
[Epoch 86; Iter    85/ 1097] train: loss: 0.0035072
[Epoch 86; Iter   115/ 1097] train: loss: 0.0001050
[Epoch 86; Iter   145/ 1097] train: loss: 0.0016524
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000068
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000488
[Epoch 86; Iter   235/ 1097] train: loss: 0.0000051
[Epoch 86; Iter   265/ 1097] train: loss: 0.0000361
[Epoch 86; Iter   295/ 1097] train: loss: 0.0001318
[Epoch 86; Iter   325/ 1097] train: loss: 0.0000466
[Epoch 86; Iter   355/ 1097] train: loss: 0.0000582
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000180
[Epoch 86; Iter   415/ 1097] train: loss: 0.0000267
[Epoch 86; Iter   445/ 1097] train: loss: 0.0002669
[Epoch 86; Iter   475/ 1097] train: loss: 0.0001882
[Epoch 86; Iter   505/ 1097] train: loss: 0.0001560
[Epoch 86; Iter   535/ 1097] train: loss: 0.0000429
[Epoch 86; Iter   565/ 1097] train: loss: 0.0002026
[Epoch 86; Iter   595/ 1097] train: loss: 0.0005998
[Epoch 86; Iter   625/ 1097] train: loss: 0.0013562
[Epoch 86; Iter   655/ 1097] train: loss: 0.0002496
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000103
[Epoch 86; Iter   715/ 1097] train: loss: 0.0023599
[Epoch 86; Iter   745/ 1097] train: loss: 0.0165684
[Epoch 86; Iter   775/ 1097] train: loss: 0.0019713
[Epoch 86; Iter   805/ 1097] train: loss: 0.0054834
[Epoch 86; Iter   835/ 1097] train: loss: 0.0000402
[Epoch 86; Iter   865/ 1097] train: loss: 0.0031496
[Epoch 86; Iter   895/ 1097] train: loss: 0.0045858
[Epoch 86; Iter   925/ 1097] train: loss: 0.0000662
[Epoch 86; Iter   955/ 1097] train: loss: 0.0000546
[Epoch 86; Iter   985/ 1097] train: loss: 0.0001388
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0003422
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0002771
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0005676
[Epoch 86] ogbg-molhiv: 0.773170 val loss: 0.384954
[Epoch 86] ogbg-molhiv: 0.759397 test loss: 0.349954
[Epoch 87; Iter     8/ 1097] train: loss: 0.0000077
[Epoch 87; Iter    38/ 1097] train: loss: 0.0000064
[Epoch 87; Iter    68/ 1097] train: loss: 0.0003725
[Epoch 87; Iter    98/ 1097] train: loss: 0.0004853
[Epoch 87; Iter   128/ 1097] train: loss: 0.0002035
[Epoch 87; Iter   158/ 1097] train: loss: 0.0000129
[Epoch 87; Iter   188/ 1097] train: loss: 0.0007323
[Epoch 87; Iter   218/ 1097] train: loss: 0.0054791
[Epoch 87; Iter   248/ 1097] train: loss: 0.0005164
[Epoch 87; Iter   278/ 1097] train: loss: 0.0000364
[Epoch 87; Iter   308/ 1097] train: loss: 0.0001239
[Epoch 87; Iter   338/ 1097] train: loss: 0.0000114
[Epoch 87; Iter   368/ 1097] train: loss: 0.0022068
[Epoch 87; Iter   398/ 1097] train: loss: 0.0000135
[Epoch 87; Iter   428/ 1097] train: loss: 0.0003465
[Epoch 87; Iter   458/ 1097] train: loss: 0.0003359
[Epoch 87; Iter   488/ 1097] train: loss: 0.0004250
[Epoch 87; Iter   518/ 1097] train: loss: 0.0000279
[Epoch 87; Iter   548/ 1097] train: loss: 0.0000185
[Epoch 87; Iter   578/ 1097] train: loss: 0.0000135
[Epoch 87; Iter   608/ 1097] train: loss: 0.0000139
[Epoch 87; Iter   638/ 1097] train: loss: 0.0000175
[Epoch 87; Iter   668/ 1097] train: loss: 0.0000962
[Epoch 87; Iter   698/ 1097] train: loss: 0.0118123
[Epoch 87; Iter   728/ 1097] train: loss: 0.0010443
[Epoch 87; Iter   758/ 1097] train: loss: 0.0003664
[Epoch 87; Iter   788/ 1097] train: loss: 0.0001372
[Epoch 87; Iter   818/ 1097] train: loss: 0.0003759
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000757
[Epoch 87; Iter   878/ 1097] train: loss: 0.0075170
[Epoch 87; Iter   908/ 1097] train: loss: 0.0001411
[Epoch 87; Iter   938/ 1097] train: loss: 0.0000203
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000897
[Epoch 87; Iter   998/ 1097] train: loss: 0.0010665
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0002704
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0000048
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0000582
[Epoch 87] ogbg-molhiv: 0.763999 val loss: 0.383017
[Epoch 87] ogbg-molhiv: 0.752010 test loss: 0.366384
[Epoch 88; Iter    21/ 1097] train: loss: 0.0020519
[Epoch 88; Iter    51/ 1097] train: loss: 0.0000093
[Epoch 88; Iter    81/ 1097] train: loss: 0.0013297
[Epoch 88; Iter   111/ 1097] train: loss: 0.0001863
[Epoch 88; Iter   141/ 1097] train: loss: 0.0000118
[Epoch 88; Iter   171/ 1097] train: loss: 0.0009475
[Epoch 88; Iter   201/ 1097] train: loss: 0.0000775
[Epoch 88; Iter   231/ 1097] train: loss: 0.0000154
[Epoch 88; Iter   261/ 1097] train: loss: 0.0001066
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000153
[Epoch 88; Iter   321/ 1097] train: loss: 0.0000058
[Epoch 88; Iter   351/ 1097] train: loss: 0.0005404
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000089
[Epoch 88; Iter   411/ 1097] train: loss: 0.0030432
[Epoch 88; Iter   441/ 1097] train: loss: 0.0000054
[Epoch 88; Iter   471/ 1097] train: loss: 0.0000708
[Epoch 88; Iter   501/ 1097] train: loss: 0.0001055
[Epoch 88; Iter   531/ 1097] train: loss: 0.0003286
[Epoch 88; Iter   561/ 1097] train: loss: 0.0013236
[Epoch 88; Iter   591/ 1097] train: loss: 0.0000227
[Epoch 88; Iter   621/ 1097] train: loss: 0.0001884
[Epoch 88; Iter   651/ 1097] train: loss: 0.0011228
[Epoch 88; Iter   681/ 1097] train: loss: 0.0005064
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000416
[Epoch 88; Iter   741/ 1097] train: loss: 0.0004811
[Epoch 88; Iter   771/ 1097] train: loss: 0.0021653
[Epoch 88; Iter   801/ 1097] train: loss: 0.0102945
[Epoch 88; Iter   831/ 1097] train: loss: 0.0000082
[Epoch 88; Iter   861/ 1097] train: loss: 0.0001570
[Epoch 88; Iter   891/ 1097] train: loss: 0.0001678
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000094
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000321
[Epoch 88; Iter   981/ 1097] train: loss: 0.0000444
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0007467
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0004936
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0001303
[Epoch 88] ogbg-molhiv: 0.772024 val loss: 0.399030
[Epoch 88] ogbg-molhiv: 0.762108 test loss: 0.369246
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000040
[Epoch 89; Iter    34/ 1097] train: loss: 0.0300150
[Epoch 89; Iter    64/ 1097] train: loss: 0.0031131
[Epoch 89; Iter    94/ 1097] train: loss: 0.0001520
[Epoch 89; Iter   124/ 1097] train: loss: 0.0012009
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000289
[Epoch 89; Iter   184/ 1097] train: loss: 0.0001047
[Epoch 89; Iter   214/ 1097] train: loss: 0.0012219
[Epoch 89; Iter   244/ 1097] train: loss: 0.0016187
[Epoch 89; Iter   274/ 1097] train: loss: 0.0000104
[Epoch 89; Iter   304/ 1097] train: loss: 0.0022966
[Epoch 89; Iter   334/ 1097] train: loss: 0.0003394
[Epoch 89; Iter   364/ 1097] train: loss: 0.0000798
[Epoch 89; Iter   394/ 1097] train: loss: 0.0303236
[Epoch 89; Iter   424/ 1097] train: loss: 0.0001353
[Epoch 89; Iter   454/ 1097] train: loss: 0.0029859
[Epoch 89; Iter   484/ 1097] train: loss: 0.0002025
[Epoch 85; Iter   432/ 1097] train: loss: 0.0000335
[Epoch 85; Iter   462/ 1097] train: loss: 0.0000021
[Epoch 85; Iter   492/ 1097] train: loss: 0.0000065
[Epoch 85; Iter   522/ 1097] train: loss: 0.0000056
[Epoch 85; Iter   552/ 1097] train: loss: 0.0000622
[Epoch 85; Iter   582/ 1097] train: loss: 0.0312147
[Epoch 85; Iter   612/ 1097] train: loss: 0.0001442
[Epoch 85; Iter   642/ 1097] train: loss: 0.0001342
[Epoch 85; Iter   672/ 1097] train: loss: 0.0003313
[Epoch 85; Iter   702/ 1097] train: loss: 0.0006379
[Epoch 85; Iter   732/ 1097] train: loss: 0.0000387
[Epoch 85; Iter   762/ 1097] train: loss: 0.0000378
[Epoch 85; Iter   792/ 1097] train: loss: 0.0001134
[Epoch 85; Iter   822/ 1097] train: loss: 0.0008739
[Epoch 85; Iter   852/ 1097] train: loss: 0.0000103
[Epoch 85; Iter   882/ 1097] train: loss: 0.0009322
[Epoch 85; Iter   912/ 1097] train: loss: 0.0006318
[Epoch 85; Iter   942/ 1097] train: loss: 0.0166444
[Epoch 85; Iter   972/ 1097] train: loss: 0.0000179
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0000284
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0003853
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0509449
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0000547
[Epoch 85] ogbg-molhiv: 0.795332 val loss: 0.264886
[Epoch 85] ogbg-molhiv: 0.807405 test loss: 0.346751
[Epoch 86; Iter    25/ 1097] train: loss: 0.0000158
[Epoch 86; Iter    55/ 1097] train: loss: 0.0000170
[Epoch 86; Iter    85/ 1097] train: loss: 0.0000075
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000157
[Epoch 86; Iter   145/ 1097] train: loss: 0.0001624
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000498
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000135
[Epoch 86; Iter   235/ 1097] train: loss: 0.0000403
[Epoch 86; Iter   265/ 1097] train: loss: 0.0479092
[Epoch 86; Iter   295/ 1097] train: loss: 0.0000285
[Epoch 86; Iter   325/ 1097] train: loss: 0.0010904
[Epoch 86; Iter   355/ 1097] train: loss: 0.0000230
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000500
[Epoch 86; Iter   415/ 1097] train: loss: 0.0003345
[Epoch 86; Iter   445/ 1097] train: loss: 0.0001045
[Epoch 86; Iter   475/ 1097] train: loss: 0.0004729
[Epoch 86; Iter   505/ 1097] train: loss: 0.0001556
[Epoch 86; Iter   535/ 1097] train: loss: 0.0001934
[Epoch 86; Iter   565/ 1097] train: loss: 0.0000725
[Epoch 86; Iter   595/ 1097] train: loss: 0.0001479
[Epoch 86; Iter   625/ 1097] train: loss: 0.0001870
[Epoch 86; Iter   655/ 1097] train: loss: 0.0000213
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000175
[Epoch 86; Iter   715/ 1097] train: loss: 0.0000693
[Epoch 86; Iter   745/ 1097] train: loss: 0.0000869
[Epoch 86; Iter   775/ 1097] train: loss: 0.0005805
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000428
[Epoch 86; Iter   835/ 1097] train: loss: 0.0001975
[Epoch 86; Iter   865/ 1097] train: loss: 0.0000824
[Epoch 86; Iter   895/ 1097] train: loss: 0.0000032
[Epoch 86; Iter   925/ 1097] train: loss: 0.0000287
[Epoch 86; Iter   955/ 1097] train: loss: 0.0012779
[Epoch 86; Iter   985/ 1097] train: loss: 0.0000014
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0000073
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0000044
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0000627
[Epoch 86] ogbg-molhiv: 0.796189 val loss: 0.400593
[Epoch 86] ogbg-molhiv: 0.801379 test loss: 0.316682
[Epoch 87; Iter     8/ 1097] train: loss: 0.0000036
[Epoch 87; Iter    38/ 1097] train: loss: 0.0006641
[Epoch 87; Iter    68/ 1097] train: loss: 0.0000358
[Epoch 87; Iter    98/ 1097] train: loss: 0.0000906
[Epoch 87; Iter   128/ 1097] train: loss: 0.0000166
[Epoch 87; Iter   158/ 1097] train: loss: 0.0000234
[Epoch 87; Iter   188/ 1097] train: loss: 0.0000586
[Epoch 87; Iter   218/ 1097] train: loss: 0.0026314
[Epoch 87; Iter   248/ 1097] train: loss: 0.0005485
[Epoch 87; Iter   278/ 1097] train: loss: 0.0001879
[Epoch 87; Iter   308/ 1097] train: loss: 0.0000124
[Epoch 87; Iter   338/ 1097] train: loss: 0.0000061
[Epoch 87; Iter   368/ 1097] train: loss: 0.0000068
[Epoch 87; Iter   398/ 1097] train: loss: 0.0001914
[Epoch 87; Iter   428/ 1097] train: loss: 0.0000035
[Epoch 87; Iter   458/ 1097] train: loss: 0.0000641
[Epoch 87; Iter   488/ 1097] train: loss: 0.0001812
[Epoch 87; Iter   518/ 1097] train: loss: 0.0000113
[Epoch 87; Iter   548/ 1097] train: loss: 0.0000381
[Epoch 87; Iter   578/ 1097] train: loss: 0.0000448
[Epoch 87; Iter   608/ 1097] train: loss: 0.0000249
[Epoch 87; Iter   638/ 1097] train: loss: 0.1815849
[Epoch 87; Iter   668/ 1097] train: loss: 0.0000312
[Epoch 87; Iter   698/ 1097] train: loss: 0.0000099
[Epoch 87; Iter   728/ 1097] train: loss: 0.0000611
[Epoch 87; Iter   758/ 1097] train: loss: 0.0000088
[Epoch 87; Iter   788/ 1097] train: loss: 0.0015218
[Epoch 87; Iter   818/ 1097] train: loss: 0.0000253
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000230
[Epoch 87; Iter   878/ 1097] train: loss: 0.0007217
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000019
[Epoch 87; Iter   938/ 1097] train: loss: 0.0000565
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000119
[Epoch 87; Iter   998/ 1097] train: loss: 0.0027858
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0001474
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0000037
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0000361
[Epoch 87] ogbg-molhiv: 0.791235 val loss: 0.414909
[Epoch 87] ogbg-molhiv: 0.805898 test loss: 0.326750
[Epoch 88; Iter    21/ 1097] train: loss: 0.0001136
[Epoch 88; Iter    51/ 1097] train: loss: 0.0001109
[Epoch 88; Iter    81/ 1097] train: loss: 0.0005892
[Epoch 88; Iter   111/ 1097] train: loss: 0.0144740
[Epoch 88; Iter   141/ 1097] train: loss: 0.0020769
[Epoch 88; Iter   171/ 1097] train: loss: 0.0006668
[Epoch 88; Iter   201/ 1097] train: loss: 0.0001424
[Epoch 88; Iter   231/ 1097] train: loss: 0.0013280
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000121
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000716
[Epoch 88; Iter   321/ 1097] train: loss: 0.0127992
[Epoch 88; Iter   351/ 1097] train: loss: 0.0005747
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000786
[Epoch 88; Iter   411/ 1097] train: loss: 0.0000142
[Epoch 88; Iter   441/ 1097] train: loss: 0.0001177
[Epoch 88; Iter   471/ 1097] train: loss: 0.0000177
[Epoch 88; Iter   501/ 1097] train: loss: 0.0014033
[Epoch 88; Iter   531/ 1097] train: loss: 0.0000236
[Epoch 88; Iter   561/ 1097] train: loss: 0.0001355
[Epoch 88; Iter   591/ 1097] train: loss: 0.0002739
[Epoch 88; Iter   621/ 1097] train: loss: 0.0044633
[Epoch 88; Iter   651/ 1097] train: loss: 0.0000343
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000322
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000541
[Epoch 88; Iter   741/ 1097] train: loss: 0.0002637
[Epoch 88; Iter   771/ 1097] train: loss: 0.0000058
[Epoch 88; Iter   801/ 1097] train: loss: 0.0000159
[Epoch 88; Iter   831/ 1097] train: loss: 0.0002554
[Epoch 88; Iter   861/ 1097] train: loss: 0.0001426
[Epoch 88; Iter   891/ 1097] train: loss: 0.0000811
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000292
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000359
[Epoch 88; Iter   981/ 1097] train: loss: 0.0001790
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0000194
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0004294
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0000101
[Epoch 88] ogbg-molhiv: 0.793675 val loss: 0.261417
[Epoch 88] ogbg-molhiv: 0.800786 test loss: 0.334354
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000186
[Epoch 89; Iter    34/ 1097] train: loss: 0.0000158
[Epoch 89; Iter    64/ 1097] train: loss: 0.0002731
[Epoch 89; Iter    94/ 1097] train: loss: 0.0000314
[Epoch 89; Iter   124/ 1097] train: loss: 0.0005135
[Epoch 89; Iter   154/ 1097] train: loss: 0.0004794
[Epoch 89; Iter   184/ 1097] train: loss: 0.0000433
[Epoch 89; Iter   214/ 1097] train: loss: 0.0003159
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000037
[Epoch 89; Iter   274/ 1097] train: loss: 0.0134985
[Epoch 89; Iter   304/ 1097] train: loss: 0.0001275
[Epoch 89; Iter   334/ 1097] train: loss: 0.0000214
[Epoch 89; Iter   364/ 1097] train: loss: 0.0002267
[Epoch 89; Iter   394/ 1097] train: loss: 0.0002460
[Epoch 89; Iter   424/ 1097] train: loss: 0.0001422
[Epoch 89; Iter   454/ 1097] train: loss: 0.0009650
[Epoch 89; Iter   484/ 1097] train: loss: 0.0000398
[Epoch 85; Iter   432/ 1097] train: loss: 0.0001067
[Epoch 85; Iter   462/ 1097] train: loss: 0.0000606
[Epoch 85; Iter   492/ 1097] train: loss: 0.0000204
[Epoch 85; Iter   522/ 1097] train: loss: 0.0003269
[Epoch 85; Iter   552/ 1097] train: loss: 0.0000016
[Epoch 85; Iter   582/ 1097] train: loss: 0.0000518
[Epoch 85; Iter   612/ 1097] train: loss: 0.0004853
[Epoch 85; Iter   642/ 1097] train: loss: 0.0003014
[Epoch 85; Iter   672/ 1097] train: loss: 0.0000113
[Epoch 85; Iter   702/ 1097] train: loss: 0.0058480
[Epoch 85; Iter   732/ 1097] train: loss: 0.0000175
[Epoch 85; Iter   762/ 1097] train: loss: 0.0000007
[Epoch 85; Iter   792/ 1097] train: loss: 0.0007906
[Epoch 85; Iter   822/ 1097] train: loss: 0.0010506
[Epoch 85; Iter   852/ 1097] train: loss: 0.0001663
[Epoch 85; Iter   882/ 1097] train: loss: 0.0002930
[Epoch 85; Iter   912/ 1097] train: loss: 0.0000311
[Epoch 85; Iter   942/ 1097] train: loss: 0.0000363
[Epoch 85; Iter   972/ 1097] train: loss: 0.0000167
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0000023
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0000184
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0000590
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0000444
[Epoch 85] ogbg-molhiv: 0.691848 val loss: 2.638123
[Epoch 85] ogbg-molhiv: 0.634228 test loss: 2.710981
[Epoch 86; Iter    25/ 1097] train: loss: 0.0000025
[Epoch 86; Iter    55/ 1097] train: loss: 0.0000018
[Epoch 86; Iter    85/ 1097] train: loss: 0.0000056
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000003
[Epoch 86; Iter   145/ 1097] train: loss: 0.0004409
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000555
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000109
[Epoch 86; Iter   235/ 1097] train: loss: 0.0000018
[Epoch 86; Iter   265/ 1097] train: loss: 0.0000003
[Epoch 86; Iter   295/ 1097] train: loss: 0.0000504
[Epoch 86; Iter   325/ 1097] train: loss: 0.0000382
[Epoch 86; Iter   355/ 1097] train: loss: 0.0000548
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000608
[Epoch 86; Iter   415/ 1097] train: loss: 0.0222178
[Epoch 86; Iter   445/ 1097] train: loss: 0.0000031
[Epoch 86; Iter   475/ 1097] train: loss: 0.0000103
[Epoch 86; Iter   505/ 1097] train: loss: 0.0000015
[Epoch 86; Iter   535/ 1097] train: loss: 0.0000502
[Epoch 86; Iter   565/ 1097] train: loss: 0.0000005
[Epoch 86; Iter   595/ 1097] train: loss: 0.0006158
[Epoch 86; Iter   625/ 1097] train: loss: 0.0004462
[Epoch 86; Iter   655/ 1097] train: loss: 0.0000170
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000041
[Epoch 86; Iter   715/ 1097] train: loss: 0.0000258
[Epoch 86; Iter   745/ 1097] train: loss: 0.0006223
[Epoch 86; Iter   775/ 1097] train: loss: 0.0002393
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000070
[Epoch 86; Iter   835/ 1097] train: loss: 0.0002180
[Epoch 86; Iter   865/ 1097] train: loss: 0.0000153
[Epoch 86; Iter   895/ 1097] train: loss: 0.0001159
[Epoch 86; Iter   925/ 1097] train: loss: 0.0000568
[Epoch 86; Iter   955/ 1097] train: loss: 0.0001914
[Epoch 86; Iter   985/ 1097] train: loss: 0.0000358
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0000324
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0028396
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0009400
[Epoch 86] ogbg-molhiv: 0.686661 val loss: 1.937824
[Epoch 86] ogbg-molhiv: 0.614554 test loss: 2.610905
[Epoch 87; Iter     8/ 1097] train: loss: 0.0000202
[Epoch 87; Iter    38/ 1097] train: loss: 0.0020022
[Epoch 87; Iter    68/ 1097] train: loss: 0.0000491
[Epoch 87; Iter    98/ 1097] train: loss: 0.0002088
[Epoch 87; Iter   128/ 1097] train: loss: 0.0000102
[Epoch 87; Iter   158/ 1097] train: loss: 0.0000034
[Epoch 87; Iter   188/ 1097] train: loss: 0.0001663
[Epoch 87; Iter   218/ 1097] train: loss: 0.0000127
[Epoch 87; Iter   248/ 1097] train: loss: 0.0000226
[Epoch 87; Iter   278/ 1097] train: loss: 0.0014810
[Epoch 87; Iter   308/ 1097] train: loss: 0.0000308
[Epoch 87; Iter   338/ 1097] train: loss: 0.0000768
[Epoch 87; Iter   368/ 1097] train: loss: 0.0000845
[Epoch 87; Iter   398/ 1097] train: loss: 0.0000126
[Epoch 87; Iter   428/ 1097] train: loss: 0.0000047
[Epoch 87; Iter   458/ 1097] train: loss: 0.0006060
[Epoch 87; Iter   488/ 1097] train: loss: 0.0005678
[Epoch 87; Iter   518/ 1097] train: loss: 0.0000039
[Epoch 87; Iter   548/ 1097] train: loss: 0.0002720
[Epoch 87; Iter   578/ 1097] train: loss: 0.0003745
[Epoch 87; Iter   608/ 1097] train: loss: 0.0014588
[Epoch 87; Iter   638/ 1097] train: loss: 0.0016483
[Epoch 87; Iter   668/ 1097] train: loss: 0.0000557
[Epoch 87; Iter   698/ 1097] train: loss: 0.0018318
[Epoch 87; Iter   728/ 1097] train: loss: 0.0000385
[Epoch 87; Iter   758/ 1097] train: loss: 0.0015772
[Epoch 87; Iter   788/ 1097] train: loss: 0.0000043
[Epoch 87; Iter   818/ 1097] train: loss: 0.0000026
[Epoch 87; Iter   848/ 1097] train: loss: 0.0000005
[Epoch 87; Iter   878/ 1097] train: loss: 0.0019587
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000407
[Epoch 87; Iter   938/ 1097] train: loss: 0.0020409
[Epoch 87; Iter   968/ 1097] train: loss: 0.0001066
[Epoch 87; Iter   998/ 1097] train: loss: 0.0000028
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0003740
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0015231
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0001747
[Epoch 87] ogbg-molhiv: 0.698863 val loss: 2.049874
[Epoch 87] ogbg-molhiv: 0.631482 test loss: 2.501091
[Epoch 88; Iter    21/ 1097] train: loss: 0.0000050
[Epoch 88; Iter    51/ 1097] train: loss: 0.0001275
[Epoch 88; Iter    81/ 1097] train: loss: 0.0001807
[Epoch 88; Iter   111/ 1097] train: loss: 0.0000061
[Epoch 88; Iter   141/ 1097] train: loss: 0.0000090
[Epoch 88; Iter   171/ 1097] train: loss: 0.0001310
[Epoch 88; Iter   201/ 1097] train: loss: 0.0000803
[Epoch 88; Iter   231/ 1097] train: loss: 0.0003239
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000067
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000055
[Epoch 88; Iter   321/ 1097] train: loss: 0.0000522
[Epoch 88; Iter   351/ 1097] train: loss: 0.0105556
[Epoch 88; Iter   381/ 1097] train: loss: 0.0004389
[Epoch 88; Iter   411/ 1097] train: loss: 0.0000011
[Epoch 88; Iter   441/ 1097] train: loss: 0.0000186
[Epoch 88; Iter   471/ 1097] train: loss: 0.0000403
[Epoch 88; Iter   501/ 1097] train: loss: 0.0000024
[Epoch 88; Iter   531/ 1097] train: loss: 0.0000435
[Epoch 88; Iter   561/ 1097] train: loss: 0.0000166
[Epoch 88; Iter   591/ 1097] train: loss: 0.0001889
[Epoch 88; Iter   621/ 1097] train: loss: 0.0000141
[Epoch 88; Iter   651/ 1097] train: loss: 0.0000118
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000375
[Epoch 88; Iter   711/ 1097] train: loss: 0.0000001
[Epoch 88; Iter   741/ 1097] train: loss: 0.0055732
[Epoch 88; Iter   771/ 1097] train: loss: 0.0000228
[Epoch 88; Iter   801/ 1097] train: loss: 0.0001401
[Epoch 88; Iter   831/ 1097] train: loss: 0.0000062
[Epoch 88; Iter   861/ 1097] train: loss: 0.0000103
[Epoch 88; Iter   891/ 1097] train: loss: 0.0003881
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000181
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000028
[Epoch 88; Iter   981/ 1097] train: loss: 0.0000414
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0000114
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0000062
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0000059
[Epoch 88] ogbg-molhiv: 0.684619 val loss: 1.963957
[Epoch 88] ogbg-molhiv: 0.641258 test loss: 2.382416
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000022
[Epoch 89; Iter    34/ 1097] train: loss: 0.0007350
[Epoch 89; Iter    64/ 1097] train: loss: 0.0000886
[Epoch 89; Iter    94/ 1097] train: loss: 0.0000187
[Epoch 89; Iter   124/ 1097] train: loss: 0.0000238
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000114
[Epoch 89; Iter   184/ 1097] train: loss: 0.0000041
[Epoch 89; Iter   214/ 1097] train: loss: 0.0001897
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000495
[Epoch 89; Iter   274/ 1097] train: loss: 0.0002316
[Epoch 89; Iter   304/ 1097] train: loss: 0.0000080
[Epoch 89; Iter   334/ 1097] train: loss: 0.0000136
[Epoch 89; Iter   364/ 1097] train: loss: 0.0000144
[Epoch 89; Iter   394/ 1097] train: loss: 0.0000104
[Epoch 89; Iter   424/ 1097] train: loss: 0.0000062
[Epoch 89; Iter   454/ 1097] train: loss: 0.0001471
[Epoch 89; Iter   484/ 1097] train: loss: 0.0000012
[Epoch 85; Iter   432/ 1097] train: loss: 0.0026786
[Epoch 85; Iter   462/ 1097] train: loss: 0.0001552
[Epoch 85; Iter   492/ 1097] train: loss: 0.0092468
[Epoch 85; Iter   522/ 1097] train: loss: 0.0150703
[Epoch 85; Iter   552/ 1097] train: loss: 0.0002613
[Epoch 85; Iter   582/ 1097] train: loss: 0.0053074
[Epoch 85; Iter   612/ 1097] train: loss: 0.0068376
[Epoch 85; Iter   642/ 1097] train: loss: 0.0037375
[Epoch 85; Iter   672/ 1097] train: loss: 0.0038095
[Epoch 85; Iter   702/ 1097] train: loss: 0.0002364
[Epoch 85; Iter   732/ 1097] train: loss: 0.0013852
[Epoch 85; Iter   762/ 1097] train: loss: 0.0221695
[Epoch 85; Iter   792/ 1097] train: loss: 0.0004663
[Epoch 85; Iter   822/ 1097] train: loss: 0.0000573
[Epoch 85; Iter   852/ 1097] train: loss: 0.0000620
[Epoch 85; Iter   882/ 1097] train: loss: 0.0445020
[Epoch 85; Iter   912/ 1097] train: loss: 0.0000414
[Epoch 85; Iter   942/ 1097] train: loss: 0.0009638
[Epoch 85; Iter   972/ 1097] train: loss: 0.0005697
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0006267
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0002472
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0003601
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0005285
[Epoch 85] ogbg-molhiv: 0.718680 val loss: 3.961288
[Epoch 85] ogbg-molhiv: 0.612324 test loss: 3.667786
[Epoch 86; Iter    25/ 1097] train: loss: 0.0032676
[Epoch 86; Iter    55/ 1097] train: loss: 0.0004525
[Epoch 86; Iter    85/ 1097] train: loss: 0.0000123
[Epoch 86; Iter   115/ 1097] train: loss: 0.0015529
[Epoch 86; Iter   145/ 1097] train: loss: 0.0001601
[Epoch 86; Iter   175/ 1097] train: loss: 0.0122600
[Epoch 86; Iter   205/ 1097] train: loss: 0.0003490
[Epoch 86; Iter   235/ 1097] train: loss: 0.0002545
[Epoch 86; Iter   265/ 1097] train: loss: 0.0000050
[Epoch 86; Iter   295/ 1097] train: loss: 0.0028937
[Epoch 86; Iter   325/ 1097] train: loss: 0.0096171
[Epoch 86; Iter   355/ 1097] train: loss: 0.0001075
[Epoch 86; Iter   385/ 1097] train: loss: 0.0018242
[Epoch 86; Iter   415/ 1097] train: loss: 0.0010762
[Epoch 86; Iter   445/ 1097] train: loss: 0.0000755
[Epoch 86; Iter   475/ 1097] train: loss: 0.0010148
[Epoch 86; Iter   505/ 1097] train: loss: 0.0000659
[Epoch 86; Iter   535/ 1097] train: loss: 0.0261719
[Epoch 86; Iter   565/ 1097] train: loss: 0.0000377
[Epoch 86; Iter   595/ 1097] train: loss: 0.0159691
[Epoch 86; Iter   625/ 1097] train: loss: 0.0087271
[Epoch 86; Iter   655/ 1097] train: loss: 0.0000185
[Epoch 86; Iter   685/ 1097] train: loss: 0.0000850
[Epoch 86; Iter   715/ 1097] train: loss: 0.0003217
[Epoch 86; Iter   745/ 1097] train: loss: 0.0013534
[Epoch 86; Iter   775/ 1097] train: loss: 0.0001193
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000155
[Epoch 86; Iter   835/ 1097] train: loss: 0.0000948
[Epoch 86; Iter   865/ 1097] train: loss: 0.0030592
[Epoch 86; Iter   895/ 1097] train: loss: 0.0000656
[Epoch 86; Iter   925/ 1097] train: loss: 0.0001459
[Epoch 86; Iter   955/ 1097] train: loss: 0.0026441
[Epoch 86; Iter   985/ 1097] train: loss: 0.0002770
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0097151
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0007589
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0000883
[Epoch 86] ogbg-molhiv: 0.709335 val loss: 11.112401
[Epoch 86] ogbg-molhiv: 0.599873 test loss: 10.040713
[Epoch 87; Iter     8/ 1097] train: loss: 0.0024325
[Epoch 87; Iter    38/ 1097] train: loss: 0.0004027
[Epoch 87; Iter    68/ 1097] train: loss: 0.0001051
[Epoch 87; Iter    98/ 1097] train: loss: 0.0023263
[Epoch 87; Iter   128/ 1097] train: loss: 0.0000604
[Epoch 87; Iter   158/ 1097] train: loss: 0.0001049
[Epoch 87; Iter   188/ 1097] train: loss: 0.0031824
[Epoch 87; Iter   218/ 1097] train: loss: 0.0083798
[Epoch 87; Iter   248/ 1097] train: loss: 0.0186439
[Epoch 87; Iter   278/ 1097] train: loss: 0.0026317
[Epoch 87; Iter   308/ 1097] train: loss: 0.1108038
[Epoch 87; Iter   338/ 1097] train: loss: 0.0004907
[Epoch 87; Iter   368/ 1097] train: loss: 0.0003818
[Epoch 87; Iter   398/ 1097] train: loss: 0.0058488
[Epoch 87; Iter   428/ 1097] train: loss: 0.0215659
[Epoch 87; Iter   458/ 1097] train: loss: 0.0768699
[Epoch 87; Iter   488/ 1097] train: loss: 0.0070125
[Epoch 87; Iter   518/ 1097] train: loss: 0.0000072
[Epoch 87; Iter   548/ 1097] train: loss: 0.0011508
[Epoch 87; Iter   578/ 1097] train: loss: 0.0003001
[Epoch 87; Iter   608/ 1097] train: loss: 0.0006867
[Epoch 87; Iter   638/ 1097] train: loss: 0.0006580
[Epoch 87; Iter   668/ 1097] train: loss: 0.0007958
[Epoch 87; Iter   698/ 1097] train: loss: 0.1888085
[Epoch 87; Iter   728/ 1097] train: loss: 0.0015714
[Epoch 87; Iter   758/ 1097] train: loss: 0.0005755
[Epoch 87; Iter   788/ 1097] train: loss: 0.0007809
[Epoch 87; Iter   818/ 1097] train: loss: 0.0001525
[Epoch 87; Iter   848/ 1097] train: loss: 0.0011111
[Epoch 87; Iter   878/ 1097] train: loss: 0.0001104
[Epoch 87; Iter   908/ 1097] train: loss: 0.0007382
[Epoch 87; Iter   938/ 1097] train: loss: 0.0026884
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000152
[Epoch 87; Iter   998/ 1097] train: loss: 0.0002436
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0005306
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0037098
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0000548
[Epoch 87] ogbg-molhiv: 0.658265 val loss: 181.240185
[Epoch 87] ogbg-molhiv: 0.552011 test loss: 164.839644
[Epoch 88; Iter    21/ 1097] train: loss: 0.0021492
[Epoch 88; Iter    51/ 1097] train: loss: 0.0000846
[Epoch 88; Iter    81/ 1097] train: loss: 0.0002629
[Epoch 88; Iter   111/ 1097] train: loss: 0.0004508
[Epoch 88; Iter   141/ 1097] train: loss: 0.0000855
[Epoch 88; Iter   171/ 1097] train: loss: 0.0007329
[Epoch 88; Iter   201/ 1097] train: loss: 0.0000309
[Epoch 88; Iter   231/ 1097] train: loss: 0.0000189
[Epoch 88; Iter   261/ 1097] train: loss: 0.0044451
[Epoch 88; Iter   291/ 1097] train: loss: 0.0000321
[Epoch 88; Iter   321/ 1097] train: loss: 0.0005638
[Epoch 88; Iter   351/ 1097] train: loss: 0.0004315
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000786
[Epoch 88; Iter   411/ 1097] train: loss: 0.0000831
[Epoch 88; Iter   441/ 1097] train: loss: 0.0004065
[Epoch 88; Iter   471/ 1097] train: loss: 0.0089310
[Epoch 88; Iter   501/ 1097] train: loss: 0.0005440
[Epoch 88; Iter   531/ 1097] train: loss: 0.0000550
[Epoch 88; Iter   561/ 1097] train: loss: 0.0017933
[Epoch 88; Iter   591/ 1097] train: loss: 0.0000792
[Epoch 88; Iter   621/ 1097] train: loss: 0.0000099
[Epoch 88; Iter   651/ 1097] train: loss: 0.0117384
[Epoch 88; Iter   681/ 1097] train: loss: 0.0002899
[Epoch 88; Iter   711/ 1097] train: loss: 0.0017334
[Epoch 88; Iter   741/ 1097] train: loss: 0.0018965
[Epoch 88; Iter   771/ 1097] train: loss: 0.0078627
[Epoch 88; Iter   801/ 1097] train: loss: 0.0000758
[Epoch 88; Iter   831/ 1097] train: loss: 0.0033792
[Epoch 88; Iter   861/ 1097] train: loss: 0.0087583
[Epoch 88; Iter   891/ 1097] train: loss: 0.0014745
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000874
[Epoch 88; Iter   951/ 1097] train: loss: 0.0000447
[Epoch 88; Iter   981/ 1097] train: loss: 0.0001658
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0004288
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0000030
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0005546
[Epoch 88] ogbg-molhiv: 0.718104 val loss: 119.868033
[Epoch 88] ogbg-molhiv: 0.612551 test loss: 109.931617
[Epoch 89; Iter     4/ 1097] train: loss: 0.0007494
[Epoch 89; Iter    34/ 1097] train: loss: 0.0007277
[Epoch 89; Iter    64/ 1097] train: loss: 0.0002018
[Epoch 89; Iter    94/ 1097] train: loss: 0.0086388
[Epoch 89; Iter   124/ 1097] train: loss: 0.0032546
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000756
[Epoch 89; Iter   184/ 1097] train: loss: 0.0448975
[Epoch 89; Iter   214/ 1097] train: loss: 0.0004166
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000116
[Epoch 89; Iter   274/ 1097] train: loss: 0.0010083
[Epoch 89; Iter   304/ 1097] train: loss: 0.0000100
[Epoch 89; Iter   334/ 1097] train: loss: 0.0000156
[Epoch 89; Iter   364/ 1097] train: loss: 0.0001178
[Epoch 89; Iter   394/ 1097] train: loss: 0.0000309
[Epoch 89; Iter   424/ 1097] train: loss: 0.0000383
[Epoch 89; Iter   454/ 1097] train: loss: 0.0009503
[Epoch 89; Iter   484/ 1097] train: loss: 0.0011253
[Epoch 85; Iter   432/ 1097] train: loss: 0.0016627
[Epoch 85; Iter   462/ 1097] train: loss: 0.0000333
[Epoch 85; Iter   492/ 1097] train: loss: 0.0106347
[Epoch 85; Iter   522/ 1097] train: loss: 0.0013645
[Epoch 85; Iter   552/ 1097] train: loss: 0.0192874
[Epoch 85; Iter   582/ 1097] train: loss: 0.0000261
[Epoch 85; Iter   612/ 1097] train: loss: 0.0009723
[Epoch 85; Iter   642/ 1097] train: loss: 0.0001146
[Epoch 85; Iter   672/ 1097] train: loss: 0.0004253
[Epoch 85; Iter   702/ 1097] train: loss: 0.0000320
[Epoch 85; Iter   732/ 1097] train: loss: 0.0000474
[Epoch 85; Iter   762/ 1097] train: loss: 0.0000461
[Epoch 85; Iter   792/ 1097] train: loss: 0.0016560
[Epoch 85; Iter   822/ 1097] train: loss: 0.0026636
[Epoch 85; Iter   852/ 1097] train: loss: 0.0002379
[Epoch 85; Iter   882/ 1097] train: loss: 0.0000155
[Epoch 85; Iter   912/ 1097] train: loss: 0.0002723
[Epoch 85; Iter   942/ 1097] train: loss: 0.0000337
[Epoch 85; Iter   972/ 1097] train: loss: 0.0000062
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0000395
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0000135
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0201401
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0000148
[Epoch 85] ogbg-molhiv: 0.781966 val loss: 0.824260
[Epoch 85] ogbg-molhiv: 0.750476 test loss: 2.617093
[Epoch 86; Iter    25/ 1097] train: loss: 0.0000017
[Epoch 86; Iter    55/ 1097] train: loss: 0.0009789
[Epoch 86; Iter    85/ 1097] train: loss: 0.0055920
[Epoch 86; Iter   115/ 1097] train: loss: 0.0000624
[Epoch 86; Iter   145/ 1097] train: loss: 0.0000059
[Epoch 86; Iter   175/ 1097] train: loss: 0.0000747
[Epoch 86; Iter   205/ 1097] train: loss: 0.0000009
[Epoch 86; Iter   235/ 1097] train: loss: 0.0005204
[Epoch 86; Iter   265/ 1097] train: loss: 0.0026055
[Epoch 86; Iter   295/ 1097] train: loss: 0.0011121
[Epoch 86; Iter   325/ 1097] train: loss: 0.0000074
[Epoch 86; Iter   355/ 1097] train: loss: 0.0001093
[Epoch 86; Iter   385/ 1097] train: loss: 0.0000131
[Epoch 86; Iter   415/ 1097] train: loss: 0.0000801
[Epoch 86; Iter   445/ 1097] train: loss: 0.0000055
[Epoch 86; Iter   475/ 1097] train: loss: 0.0003032
[Epoch 86; Iter   505/ 1097] train: loss: 0.0037701
[Epoch 86; Iter   535/ 1097] train: loss: 0.0000362
[Epoch 86; Iter   565/ 1097] train: loss: 0.0015081
[Epoch 86; Iter   595/ 1097] train: loss: 0.0097845
[Epoch 86; Iter   625/ 1097] train: loss: 0.0005797
[Epoch 86; Iter   655/ 1097] train: loss: 0.0014597
[Epoch 86; Iter   685/ 1097] train: loss: 0.0003287
[Epoch 86; Iter   715/ 1097] train: loss: 0.0106318
[Epoch 86; Iter   745/ 1097] train: loss: 0.0000950
[Epoch 86; Iter   775/ 1097] train: loss: 0.0001189
[Epoch 86; Iter   805/ 1097] train: loss: 0.0000065
[Epoch 86; Iter   835/ 1097] train: loss: 0.0001319
[Epoch 86; Iter   865/ 1097] train: loss: 0.0000067
[Epoch 86; Iter   895/ 1097] train: loss: 0.0000449
[Epoch 86; Iter   925/ 1097] train: loss: 0.0000112
[Epoch 86; Iter   955/ 1097] train: loss: 0.0000083
[Epoch 86; Iter   985/ 1097] train: loss: 0.0000687
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0002313
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0000392
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0000059
[Epoch 86] ogbg-molhiv: 0.766740 val loss: 1.262826
[Epoch 86] ogbg-molhiv: 0.750385 test loss: 3.380989
[Epoch 87; Iter     8/ 1097] train: loss: 0.0000058
[Epoch 87; Iter    38/ 1097] train: loss: 0.0000342
[Epoch 87; Iter    68/ 1097] train: loss: 0.0046691
[Epoch 87; Iter    98/ 1097] train: loss: 0.0002371
[Epoch 87; Iter   128/ 1097] train: loss: 0.0007645
[Epoch 87; Iter   158/ 1097] train: loss: 0.0000059
[Epoch 87; Iter   188/ 1097] train: loss: 0.0018454
[Epoch 87; Iter   218/ 1097] train: loss: 0.0000036
[Epoch 87; Iter   248/ 1097] train: loss: 0.0001818
[Epoch 87; Iter   278/ 1097] train: loss: 0.0000203
[Epoch 87; Iter   308/ 1097] train: loss: 0.0001074
[Epoch 87; Iter   338/ 1097] train: loss: 0.0000350
[Epoch 87; Iter   368/ 1097] train: loss: 0.0000177
[Epoch 87; Iter   398/ 1097] train: loss: 0.0002142
[Epoch 87; Iter   428/ 1097] train: loss: 0.0004283
[Epoch 87; Iter   458/ 1097] train: loss: 0.0000041
[Epoch 87; Iter   488/ 1097] train: loss: 0.0003501
[Epoch 87; Iter   518/ 1097] train: loss: 0.0025091
[Epoch 87; Iter   548/ 1097] train: loss: 0.0000193
[Epoch 87; Iter   578/ 1097] train: loss: 0.0025156
[Epoch 87; Iter   608/ 1097] train: loss: 0.0003175
[Epoch 87; Iter   638/ 1097] train: loss: 0.0000047
[Epoch 87; Iter   668/ 1097] train: loss: 0.0629368
[Epoch 87; Iter   698/ 1097] train: loss: 0.0000476
[Epoch 87; Iter   728/ 1097] train: loss: 0.0430723
[Epoch 87; Iter   758/ 1097] train: loss: 0.0002289
[Epoch 87; Iter   788/ 1097] train: loss: 0.0001164
[Epoch 87; Iter   818/ 1097] train: loss: 0.0000462
[Epoch 87; Iter   848/ 1097] train: loss: 0.0001319
[Epoch 87; Iter   878/ 1097] train: loss: 0.0000487
[Epoch 87; Iter   908/ 1097] train: loss: 0.0000512
[Epoch 87; Iter   938/ 1097] train: loss: 0.0000797
[Epoch 87; Iter   968/ 1097] train: loss: 0.0000549
[Epoch 87; Iter   998/ 1097] train: loss: 0.0000264
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0000105
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0001142
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0000095
[Epoch 87] ogbg-molhiv: 0.766023 val loss: 0.911228
[Epoch 87] ogbg-molhiv: 0.732683 test loss: 2.962326
[Epoch 88; Iter    21/ 1097] train: loss: 0.0011792
[Epoch 88; Iter    51/ 1097] train: loss: 0.0000427
[Epoch 88; Iter    81/ 1097] train: loss: 0.0000038
[Epoch 88; Iter   111/ 1097] train: loss: 0.0018027
[Epoch 88; Iter   141/ 1097] train: loss: 0.0004315
[Epoch 88; Iter   171/ 1097] train: loss: 0.0000383
[Epoch 88; Iter   201/ 1097] train: loss: 0.0000289
[Epoch 88; Iter   231/ 1097] train: loss: 0.0004070
[Epoch 88; Iter   261/ 1097] train: loss: 0.0000830
[Epoch 88; Iter   291/ 1097] train: loss: 0.0004316
[Epoch 88; Iter   321/ 1097] train: loss: 0.0064449
[Epoch 88; Iter   351/ 1097] train: loss: 0.0007658
[Epoch 88; Iter   381/ 1097] train: loss: 0.0000818
[Epoch 88; Iter   411/ 1097] train: loss: 0.0002206
[Epoch 88; Iter   441/ 1097] train: loss: 0.0000050
[Epoch 88; Iter   471/ 1097] train: loss: 0.0023668
[Epoch 88; Iter   501/ 1097] train: loss: 0.0006552
[Epoch 88; Iter   531/ 1097] train: loss: 0.0006001
[Epoch 88; Iter   561/ 1097] train: loss: 0.0164424
[Epoch 88; Iter   591/ 1097] train: loss: 0.0000050
[Epoch 88; Iter   621/ 1097] train: loss: 0.0019852
[Epoch 88; Iter   651/ 1097] train: loss: 0.0000079
[Epoch 88; Iter   681/ 1097] train: loss: 0.0000495
[Epoch 88; Iter   711/ 1097] train: loss: 0.0003150
[Epoch 88; Iter   741/ 1097] train: loss: 0.0000245
[Epoch 88; Iter   771/ 1097] train: loss: 0.0000156
[Epoch 88; Iter   801/ 1097] train: loss: 0.0004044
[Epoch 88; Iter   831/ 1097] train: loss: 0.0006841
[Epoch 88; Iter   861/ 1097] train: loss: 0.0003675
[Epoch 88; Iter   891/ 1097] train: loss: 0.0007770
[Epoch 88; Iter   921/ 1097] train: loss: 0.0000405
[Epoch 88; Iter   951/ 1097] train: loss: 0.0200167
[Epoch 88; Iter   981/ 1097] train: loss: 0.0000878
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0000014
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0000111
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0000020
[Epoch 88] ogbg-molhiv: 0.737195 val loss: 0.691943
[Epoch 88] ogbg-molhiv: 0.734072 test loss: 2.762812
[Epoch 89; Iter     4/ 1097] train: loss: 0.0000952
[Epoch 89; Iter    34/ 1097] train: loss: 0.0000124
[Epoch 89; Iter    64/ 1097] train: loss: 0.0003017
[Epoch 89; Iter    94/ 1097] train: loss: 0.0000134
[Epoch 89; Iter   124/ 1097] train: loss: 0.0000558
[Epoch 89; Iter   154/ 1097] train: loss: 0.0000265
[Epoch 89; Iter   184/ 1097] train: loss: 0.0072091
[Epoch 89; Iter   214/ 1097] train: loss: 0.0000190
[Epoch 89; Iter   244/ 1097] train: loss: 0.0000295
[Epoch 89; Iter   274/ 1097] train: loss: 0.0126403
[Epoch 89; Iter   304/ 1097] train: loss: 0.0003088
[Epoch 89; Iter   334/ 1097] train: loss: 0.0000006
[Epoch 89; Iter   364/ 1097] train: loss: 0.0132202
[Epoch 89; Iter   394/ 1097] train: loss: 0.0030336
[Epoch 89; Iter   424/ 1097] train: loss: 0.0000192
[Epoch 89; Iter   454/ 1097] train: loss: 0.0003395
[Epoch 89; Iter   484/ 1097] train: loss: 0.0000342
[Epoch 69; Iter   104/ 1097] train: loss: 0.0033964
[Epoch 69; Iter   134/ 1097] train: loss: 0.0083092
[Epoch 69; Iter   164/ 1097] train: loss: 0.0174918
[Epoch 69; Iter   194/ 1097] train: loss: 0.0184299
[Epoch 69; Iter   224/ 1097] train: loss: 0.0143284
[Epoch 69; Iter   254/ 1097] train: loss: 0.0866704
[Epoch 69; Iter   284/ 1097] train: loss: 0.1089850
[Epoch 69; Iter   314/ 1097] train: loss: 0.1429203
[Epoch 69; Iter   344/ 1097] train: loss: 0.0592287
[Epoch 69; Iter   374/ 1097] train: loss: 0.0244299
[Epoch 69; Iter   404/ 1097] train: loss: 0.0140708
[Epoch 69; Iter   434/ 1097] train: loss: 0.0278364
[Epoch 69; Iter   464/ 1097] train: loss: 0.0042720
[Epoch 69; Iter   494/ 1097] train: loss: 0.0896244
[Epoch 69; Iter   524/ 1097] train: loss: 0.2001525
[Epoch 69; Iter   554/ 1097] train: loss: 0.0768586
[Epoch 69; Iter   584/ 1097] train: loss: 0.0058979
[Epoch 69; Iter   614/ 1097] train: loss: 0.0043590
[Epoch 69; Iter   644/ 1097] train: loss: 0.0170306
[Epoch 69; Iter   674/ 1097] train: loss: 0.0122851
[Epoch 69; Iter   704/ 1097] train: loss: 0.0190555
[Epoch 69; Iter   734/ 1097] train: loss: 0.0024608
[Epoch 69; Iter   764/ 1097] train: loss: 0.0232488
[Epoch 69; Iter   794/ 1097] train: loss: 0.0081372
[Epoch 69; Iter   824/ 1097] train: loss: 0.0411105
[Epoch 69; Iter   854/ 1097] train: loss: 0.0234161
[Epoch 69; Iter   884/ 1097] train: loss: 0.1345425
[Epoch 69; Iter   914/ 1097] train: loss: 0.0198287
[Epoch 69; Iter   944/ 1097] train: loss: 0.1971200
[Epoch 69; Iter   974/ 1097] train: loss: 0.0362740
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0099341
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0416614
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0049993
[Epoch 69; Iter  1094/ 1097] train: loss: 0.1015770
[Epoch 69] ogbg-molhiv: 0.814751 val loss: 0.114851
[Epoch 69] ogbg-molhiv: 0.751870 test loss: 0.203013
[Epoch 70; Iter    27/ 1097] train: loss: 0.0087893
[Epoch 70; Iter    57/ 1097] train: loss: 0.1219881
[Epoch 70; Iter    87/ 1097] train: loss: 0.0143912
[Epoch 70; Iter   117/ 1097] train: loss: 0.0044205
[Epoch 70; Iter   147/ 1097] train: loss: 0.0214725
[Epoch 70; Iter   177/ 1097] train: loss: 0.0052831
[Epoch 70; Iter   207/ 1097] train: loss: 0.0291647
[Epoch 70; Iter   237/ 1097] train: loss: 0.0304660
[Epoch 70; Iter   267/ 1097] train: loss: 0.0039427
[Epoch 70; Iter   297/ 1097] train: loss: 0.0110908
[Epoch 70; Iter   327/ 1097] train: loss: 0.0207218
[Epoch 70; Iter   357/ 1097] train: loss: 0.1116203
[Epoch 70; Iter   387/ 1097] train: loss: 0.0117820
[Epoch 70; Iter   417/ 1097] train: loss: 0.0313380
[Epoch 70; Iter   447/ 1097] train: loss: 0.0138931
[Epoch 70; Iter   477/ 1097] train: loss: 0.0386966
[Epoch 70; Iter   507/ 1097] train: loss: 0.0503023
[Epoch 70; Iter   537/ 1097] train: loss: 0.0027876
[Epoch 70; Iter   567/ 1097] train: loss: 0.1238551
[Epoch 70; Iter   597/ 1097] train: loss: 0.1510804
[Epoch 70; Iter   627/ 1097] train: loss: 0.0048556
[Epoch 70; Iter   657/ 1097] train: loss: 0.0169359
[Epoch 70; Iter   687/ 1097] train: loss: 0.0065265
[Epoch 70; Iter   717/ 1097] train: loss: 0.0082124
[Epoch 70; Iter   747/ 1097] train: loss: 0.0362107
[Epoch 70; Iter   777/ 1097] train: loss: 0.0057202
[Epoch 70; Iter   807/ 1097] train: loss: 0.0226675
[Epoch 70; Iter   837/ 1097] train: loss: 0.0134906
[Epoch 70; Iter   867/ 1097] train: loss: 0.0549290
[Epoch 70; Iter   897/ 1097] train: loss: 0.0091451
[Epoch 70; Iter   927/ 1097] train: loss: 0.0413694
[Epoch 70; Iter   957/ 1097] train: loss: 0.0640447
[Epoch 70; Iter   987/ 1097] train: loss: 0.0116131
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0048620
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0127888
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0087198
[Epoch 70] ogbg-molhiv: 0.818437 val loss: 0.105894
[Epoch 70] ogbg-molhiv: 0.755117 test loss: 0.193721
[Epoch 71; Iter    10/ 1097] train: loss: 0.0771706
[Epoch 71; Iter    40/ 1097] train: loss: 0.0014876
[Epoch 71; Iter    70/ 1097] train: loss: 0.0551116
[Epoch 71; Iter   100/ 1097] train: loss: 0.0049362
[Epoch 71; Iter   130/ 1097] train: loss: 0.0106297
[Epoch 71; Iter   160/ 1097] train: loss: 0.0464086
[Epoch 71; Iter   190/ 1097] train: loss: 0.0098158
[Epoch 71; Iter   220/ 1097] train: loss: 0.0094558
[Epoch 71; Iter   250/ 1097] train: loss: 0.0052639
[Epoch 71; Iter   280/ 1097] train: loss: 0.0098990
[Epoch 71; Iter   310/ 1097] train: loss: 0.0064451
[Epoch 71; Iter   340/ 1097] train: loss: 0.0126170
[Epoch 71; Iter   370/ 1097] train: loss: 0.1169827
[Epoch 71; Iter   400/ 1097] train: loss: 0.0152695
[Epoch 71; Iter   430/ 1097] train: loss: 0.0137900
[Epoch 71; Iter   460/ 1097] train: loss: 0.0166936
[Epoch 71; Iter   490/ 1097] train: loss: 0.0144044
[Epoch 71; Iter   520/ 1097] train: loss: 0.0451441
[Epoch 71; Iter   550/ 1097] train: loss: 0.0016208
[Epoch 71; Iter   580/ 1097] train: loss: 0.1446071
[Epoch 71; Iter   610/ 1097] train: loss: 0.0191599
[Epoch 71; Iter   640/ 1097] train: loss: 0.0138647
[Epoch 71; Iter   670/ 1097] train: loss: 0.0444618
[Epoch 71; Iter   700/ 1097] train: loss: 0.0118158
[Epoch 71; Iter   730/ 1097] train: loss: 0.1354931
[Epoch 71; Iter   760/ 1097] train: loss: 0.0181058
[Epoch 71; Iter   790/ 1097] train: loss: 0.0361873
[Epoch 71; Iter   820/ 1097] train: loss: 0.2241283
[Epoch 71; Iter   850/ 1097] train: loss: 0.0124914
[Epoch 71; Iter   880/ 1097] train: loss: 0.0162261
[Epoch 71; Iter   910/ 1097] train: loss: 0.0042179
[Epoch 71; Iter   940/ 1097] train: loss: 0.0283153
[Epoch 71; Iter   970/ 1097] train: loss: 0.0105637
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0219562
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0018557
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0378830
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0116373
[Epoch 71] ogbg-molhiv: 0.825235 val loss: 0.104110
[Epoch 71] ogbg-molhiv: 0.742983 test loss: 0.199233
[Epoch 72; Iter    23/ 1097] train: loss: 0.0103744
[Epoch 72; Iter    53/ 1097] train: loss: 0.0152704
[Epoch 72; Iter    83/ 1097] train: loss: 0.0874140
[Epoch 72; Iter   113/ 1097] train: loss: 0.0126232
[Epoch 72; Iter   143/ 1097] train: loss: 0.0745690
[Epoch 72; Iter   173/ 1097] train: loss: 0.0103926
[Epoch 72; Iter   203/ 1097] train: loss: 0.0326007
[Epoch 72; Iter   233/ 1097] train: loss: 0.0924504
[Epoch 72; Iter   263/ 1097] train: loss: 0.0207676
[Epoch 72; Iter   293/ 1097] train: loss: 0.0931514
[Epoch 72; Iter   323/ 1097] train: loss: 0.0180858
[Epoch 72; Iter   353/ 1097] train: loss: 0.0064669
[Epoch 72; Iter   383/ 1097] train: loss: 0.0049869
[Epoch 72; Iter   413/ 1097] train: loss: 0.0349322
[Epoch 72; Iter   443/ 1097] train: loss: 0.0173398
[Epoch 72; Iter   473/ 1097] train: loss: 0.2252102
[Epoch 72; Iter   503/ 1097] train: loss: 0.0061696
[Epoch 72; Iter   533/ 1097] train: loss: 0.1266612
[Epoch 72; Iter   563/ 1097] train: loss: 0.0327644
[Epoch 72; Iter   593/ 1097] train: loss: 0.0026304
[Epoch 72; Iter   623/ 1097] train: loss: 0.0119298
[Epoch 72; Iter   653/ 1097] train: loss: 0.0735527
[Epoch 72; Iter   683/ 1097] train: loss: 0.0200624
[Epoch 72; Iter   713/ 1097] train: loss: 0.0236854
[Epoch 72; Iter   743/ 1097] train: loss: 0.0168783
[Epoch 72; Iter   773/ 1097] train: loss: 0.0983326
[Epoch 72; Iter   803/ 1097] train: loss: 0.0040273
[Epoch 72; Iter   833/ 1097] train: loss: 0.0717584
[Epoch 72; Iter   863/ 1097] train: loss: 0.0560910
[Epoch 72; Iter   893/ 1097] train: loss: 0.0121489
[Epoch 72; Iter   923/ 1097] train: loss: 0.0245889
[Epoch 72; Iter   953/ 1097] train: loss: 0.0750797
[Epoch 72; Iter   983/ 1097] train: loss: 0.0259896
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0033245
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0135702
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0121576
[Epoch 72] ogbg-molhiv: 0.815029 val loss: 0.109774
[Epoch 72] ogbg-molhiv: 0.751781 test loss: 0.202383
[Epoch 73; Iter     6/ 1097] train: loss: 0.0044714
[Epoch 73; Iter    36/ 1097] train: loss: 0.0175373
[Epoch 73; Iter    66/ 1097] train: loss: 0.0153251
[Epoch 73; Iter    96/ 1097] train: loss: 0.0065916
[Epoch 73; Iter   126/ 1097] train: loss: 0.0047847
[Epoch 73; Iter   156/ 1097] train: loss: 0.0708151
[Epoch 69; Iter   104/ 1097] train: loss: 0.0615735
[Epoch 69; Iter   134/ 1097] train: loss: 0.0073784
[Epoch 69; Iter   164/ 1097] train: loss: 0.0994943
[Epoch 69; Iter   194/ 1097] train: loss: 0.0130156
[Epoch 69; Iter   224/ 1097] train: loss: 0.0536271
[Epoch 69; Iter   254/ 1097] train: loss: 0.0056261
[Epoch 69; Iter   284/ 1097] train: loss: 0.0475567
[Epoch 69; Iter   314/ 1097] train: loss: 0.0438696
[Epoch 69; Iter   344/ 1097] train: loss: 0.0183267
[Epoch 69; Iter   374/ 1097] train: loss: 0.2584374
[Epoch 69; Iter   404/ 1097] train: loss: 0.0580896
[Epoch 69; Iter   434/ 1097] train: loss: 0.1266297
[Epoch 69; Iter   464/ 1097] train: loss: 0.0440919
[Epoch 69; Iter   494/ 1097] train: loss: 0.0079142
[Epoch 69; Iter   524/ 1097] train: loss: 0.0151201
[Epoch 69; Iter   554/ 1097] train: loss: 0.0227653
[Epoch 69; Iter   584/ 1097] train: loss: 0.0163488
[Epoch 69; Iter   614/ 1097] train: loss: 0.0074335
[Epoch 69; Iter   644/ 1097] train: loss: 0.0076710
[Epoch 69; Iter   674/ 1097] train: loss: 0.0786974
[Epoch 69; Iter   704/ 1097] train: loss: 0.0299830
[Epoch 69; Iter   734/ 1097] train: loss: 0.1026106
[Epoch 69; Iter   764/ 1097] train: loss: 0.0122198
[Epoch 69; Iter   794/ 1097] train: loss: 0.0084239
[Epoch 69; Iter   824/ 1097] train: loss: 0.0202872
[Epoch 69; Iter   854/ 1097] train: loss: 0.1550150
[Epoch 69; Iter   884/ 1097] train: loss: 0.0548230
[Epoch 69; Iter   914/ 1097] train: loss: 0.0208549
[Epoch 69; Iter   944/ 1097] train: loss: 0.0038611
[Epoch 69; Iter   974/ 1097] train: loss: 0.0543761
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0028950
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0119870
[Epoch 69; Iter  1064/ 1097] train: loss: 0.2095561
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0866937
[Epoch 69] ogbg-molhiv: 0.781691 val loss: 0.105767
[Epoch 69] ogbg-molhiv: 0.738404 test loss: 0.201887
[Epoch 70; Iter    27/ 1097] train: loss: 0.0046578
[Epoch 70; Iter    57/ 1097] train: loss: 0.0054770
[Epoch 70; Iter    87/ 1097] train: loss: 0.0181078
[Epoch 70; Iter   117/ 1097] train: loss: 0.2693219
[Epoch 70; Iter   147/ 1097] train: loss: 0.0066881
[Epoch 70; Iter   177/ 1097] train: loss: 0.0628936
[Epoch 70; Iter   207/ 1097] train: loss: 0.0072834
[Epoch 70; Iter   237/ 1097] train: loss: 0.0109695
[Epoch 70; Iter   267/ 1097] train: loss: 0.1241398
[Epoch 70; Iter   297/ 1097] train: loss: 0.0313814
[Epoch 70; Iter   327/ 1097] train: loss: 0.0059981
[Epoch 70; Iter   357/ 1097] train: loss: 0.3397775
[Epoch 70; Iter   387/ 1097] train: loss: 0.0598698
[Epoch 70; Iter   417/ 1097] train: loss: 0.0384733
[Epoch 70; Iter   447/ 1097] train: loss: 0.0474716
[Epoch 70; Iter   477/ 1097] train: loss: 0.0148824
[Epoch 70; Iter   507/ 1097] train: loss: 0.0085378
[Epoch 70; Iter   537/ 1097] train: loss: 0.0898763
[Epoch 70; Iter   567/ 1097] train: loss: 0.0171608
[Epoch 70; Iter   597/ 1097] train: loss: 0.0111663
[Epoch 70; Iter   627/ 1097] train: loss: 0.0033470
[Epoch 70; Iter   657/ 1097] train: loss: 0.0152497
[Epoch 70; Iter   687/ 1097] train: loss: 0.0428119
[Epoch 70; Iter   717/ 1097] train: loss: 0.0356062
[Epoch 70; Iter   747/ 1097] train: loss: 0.0055953
[Epoch 70; Iter   777/ 1097] train: loss: 0.0106151
[Epoch 70; Iter   807/ 1097] train: loss: 0.0360236
[Epoch 70; Iter   837/ 1097] train: loss: 0.0224269
[Epoch 70; Iter   867/ 1097] train: loss: 0.0172239
[Epoch 70; Iter   897/ 1097] train: loss: 0.0709289
[Epoch 70; Iter   927/ 1097] train: loss: 0.0066280
[Epoch 70; Iter   957/ 1097] train: loss: 0.0118907
[Epoch 70; Iter   987/ 1097] train: loss: 0.1484794
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0685516
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0674301
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0820124
[Epoch 70] ogbg-molhiv: 0.803813 val loss: 0.099146
[Epoch 70] ogbg-molhiv: 0.735205 test loss: 0.191795
[Epoch 71; Iter    10/ 1097] train: loss: 0.0243116
[Epoch 71; Iter    40/ 1097] train: loss: 0.0133923
[Epoch 71; Iter    70/ 1097] train: loss: 0.0348594
[Epoch 71; Iter   100/ 1097] train: loss: 0.0648764
[Epoch 71; Iter   130/ 1097] train: loss: 0.0041731
[Epoch 71; Iter   160/ 1097] train: loss: 0.0068729
[Epoch 71; Iter   190/ 1097] train: loss: 0.1060236
[Epoch 71; Iter   220/ 1097] train: loss: 0.0271988
[Epoch 71; Iter   250/ 1097] train: loss: 0.0189400
[Epoch 71; Iter   280/ 1097] train: loss: 0.0469284
[Epoch 71; Iter   310/ 1097] train: loss: 0.0072241
[Epoch 71; Iter   340/ 1097] train: loss: 0.0572916
[Epoch 71; Iter   370/ 1097] train: loss: 0.1447652
[Epoch 71; Iter   400/ 1097] train: loss: 0.0415609
[Epoch 71; Iter   430/ 1097] train: loss: 0.0236579
[Epoch 71; Iter   460/ 1097] train: loss: 0.0147221
[Epoch 71; Iter   490/ 1097] train: loss: 0.0553353
[Epoch 71; Iter   520/ 1097] train: loss: 0.1008670
[Epoch 71; Iter   550/ 1097] train: loss: 0.0236599
[Epoch 71; Iter   580/ 1097] train: loss: 0.0109400
[Epoch 71; Iter   610/ 1097] train: loss: 0.0160538
[Epoch 71; Iter   640/ 1097] train: loss: 0.0061576
[Epoch 71; Iter   670/ 1097] train: loss: 0.0047758
[Epoch 71; Iter   700/ 1097] train: loss: 0.0889177
[Epoch 71; Iter   730/ 1097] train: loss: 0.0492046
[Epoch 71; Iter   760/ 1097] train: loss: 0.0172110
[Epoch 71; Iter   790/ 1097] train: loss: 0.0103334
[Epoch 71; Iter   820/ 1097] train: loss: 0.1568777
[Epoch 71; Iter   850/ 1097] train: loss: 0.0334433
[Epoch 71; Iter   880/ 1097] train: loss: 0.0812547
[Epoch 71; Iter   910/ 1097] train: loss: 0.0397625
[Epoch 71; Iter   940/ 1097] train: loss: 0.0045967
[Epoch 71; Iter   970/ 1097] train: loss: 0.1519012
[Epoch 71; Iter  1000/ 1097] train: loss: 0.1507392
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0277940
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0061654
[Epoch 71; Iter  1090/ 1097] train: loss: 0.1333305
[Epoch 71] ogbg-molhiv: 0.802971 val loss: 0.118325
[Epoch 71] ogbg-molhiv: 0.737901 test loss: 0.292540
[Epoch 72; Iter    23/ 1097] train: loss: 0.0720021
[Epoch 72; Iter    53/ 1097] train: loss: 0.1043127
[Epoch 72; Iter    83/ 1097] train: loss: 0.0077055
[Epoch 72; Iter   113/ 1097] train: loss: 0.0084127
[Epoch 72; Iter   143/ 1097] train: loss: 0.0065983
[Epoch 72; Iter   173/ 1097] train: loss: 0.0158625
[Epoch 72; Iter   203/ 1097] train: loss: 0.0113774
[Epoch 72; Iter   233/ 1097] train: loss: 0.0251017
[Epoch 72; Iter   263/ 1097] train: loss: 0.0234494
[Epoch 72; Iter   293/ 1097] train: loss: 0.0052305
[Epoch 72; Iter   323/ 1097] train: loss: 0.0050679
[Epoch 72; Iter   353/ 1097] train: loss: 0.3273481
[Epoch 72; Iter   383/ 1097] train: loss: 0.0077133
[Epoch 72; Iter   413/ 1097] train: loss: 0.1004356
[Epoch 72; Iter   443/ 1097] train: loss: 0.0046274
[Epoch 72; Iter   473/ 1097] train: loss: 0.1509701
[Epoch 72; Iter   503/ 1097] train: loss: 0.2722310
[Epoch 72; Iter   533/ 1097] train: loss: 0.0078412
[Epoch 72; Iter   563/ 1097] train: loss: 0.0594880
[Epoch 72; Iter   593/ 1097] train: loss: 0.0125935
[Epoch 72; Iter   623/ 1097] train: loss: 0.0424585
[Epoch 72; Iter   653/ 1097] train: loss: 0.1016722
[Epoch 72; Iter   683/ 1097] train: loss: 0.0049534
[Epoch 72; Iter   713/ 1097] train: loss: 0.0031194
[Epoch 72; Iter   743/ 1097] train: loss: 0.0262688
[Epoch 72; Iter   773/ 1097] train: loss: 0.0095283
[Epoch 72; Iter   803/ 1097] train: loss: 0.0782224
[Epoch 72; Iter   833/ 1097] train: loss: 0.3107496
[Epoch 72; Iter   863/ 1097] train: loss: 0.0288807
[Epoch 72; Iter   893/ 1097] train: loss: 0.0016517
[Epoch 72; Iter   923/ 1097] train: loss: 0.0074680
[Epoch 72; Iter   953/ 1097] train: loss: 0.0074046
[Epoch 72; Iter   983/ 1097] train: loss: 0.0139370
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0063428
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0077852
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0280811
[Epoch 72] ogbg-molhiv: 0.796838 val loss: 0.144013
[Epoch 72] ogbg-molhiv: 0.729678 test loss: 0.290744
[Epoch 73; Iter     6/ 1097] train: loss: 0.0441963
[Epoch 73; Iter    36/ 1097] train: loss: 0.0134552
[Epoch 73; Iter    66/ 1097] train: loss: 0.0200227
[Epoch 73; Iter    96/ 1097] train: loss: 0.0043907
[Epoch 73; Iter   126/ 1097] train: loss: 0.0077645
[Epoch 73; Iter   156/ 1097] train: loss: 0.0620490
[Epoch 69; Iter   104/ 1097] train: loss: 0.0286548
[Epoch 69; Iter   134/ 1097] train: loss: 0.0258543
[Epoch 69; Iter   164/ 1097] train: loss: 0.0137252
[Epoch 69; Iter   194/ 1097] train: loss: 0.0257611
[Epoch 69; Iter   224/ 1097] train: loss: 0.0399653
[Epoch 69; Iter   254/ 1097] train: loss: 0.0351633
[Epoch 69; Iter   284/ 1097] train: loss: 0.0328240
[Epoch 69; Iter   314/ 1097] train: loss: 0.0131083
[Epoch 69; Iter   344/ 1097] train: loss: 0.0091034
[Epoch 69; Iter   374/ 1097] train: loss: 0.0040939
[Epoch 69; Iter   404/ 1097] train: loss: 0.0128889
[Epoch 69; Iter   434/ 1097] train: loss: 0.0124301
[Epoch 69; Iter   464/ 1097] train: loss: 0.0175557
[Epoch 69; Iter   494/ 1097] train: loss: 0.0042696
[Epoch 69; Iter   524/ 1097] train: loss: 0.0128703
[Epoch 69; Iter   554/ 1097] train: loss: 0.0084716
[Epoch 69; Iter   584/ 1097] train: loss: 0.0151536
[Epoch 69; Iter   614/ 1097] train: loss: 0.0626325
[Epoch 69; Iter   644/ 1097] train: loss: 0.1771576
[Epoch 69; Iter   674/ 1097] train: loss: 0.0300890
[Epoch 69; Iter   704/ 1097] train: loss: 0.0040648
[Epoch 69; Iter   734/ 1097] train: loss: 0.0072584
[Epoch 69; Iter   764/ 1097] train: loss: 0.0596390
[Epoch 69; Iter   794/ 1097] train: loss: 0.0454143
[Epoch 69; Iter   824/ 1097] train: loss: 0.0385352
[Epoch 69; Iter   854/ 1097] train: loss: 0.0598374
[Epoch 69; Iter   884/ 1097] train: loss: 0.0100708
[Epoch 69; Iter   914/ 1097] train: loss: 0.0133339
[Epoch 69; Iter   944/ 1097] train: loss: 0.0027059
[Epoch 69; Iter   974/ 1097] train: loss: 0.0095345
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0275078
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0053132
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0126796
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0393787
[Epoch 69] ogbg-molhiv: 0.802775 val loss: 0.115103
[Epoch 69] ogbg-molhiv: 0.754572 test loss: 0.211904
[Epoch 70; Iter    27/ 1097] train: loss: 0.0209391
[Epoch 70; Iter    57/ 1097] train: loss: 0.0862463
[Epoch 70; Iter    87/ 1097] train: loss: 0.0637190
[Epoch 70; Iter   117/ 1097] train: loss: 0.0457745
[Epoch 70; Iter   147/ 1097] train: loss: 0.0031007
[Epoch 70; Iter   177/ 1097] train: loss: 0.0541669
[Epoch 70; Iter   207/ 1097] train: loss: 0.0678695
[Epoch 70; Iter   237/ 1097] train: loss: 0.0084657
[Epoch 70; Iter   267/ 1097] train: loss: 0.0030828
[Epoch 70; Iter   297/ 1097] train: loss: 0.0220025
[Epoch 70; Iter   327/ 1097] train: loss: 0.0067564
[Epoch 70; Iter   357/ 1097] train: loss: 0.0732788
[Epoch 70; Iter   387/ 1097] train: loss: 0.0223117
[Epoch 70; Iter   417/ 1097] train: loss: 0.1215276
[Epoch 70; Iter   447/ 1097] train: loss: 0.0378007
[Epoch 70; Iter   477/ 1097] train: loss: 0.0106405
[Epoch 70; Iter   507/ 1097] train: loss: 0.0044593
[Epoch 70; Iter   537/ 1097] train: loss: 0.0306188
[Epoch 70; Iter   567/ 1097] train: loss: 0.0098940
[Epoch 70; Iter   597/ 1097] train: loss: 0.0014593
[Epoch 70; Iter   627/ 1097] train: loss: 0.0848903
[Epoch 70; Iter   657/ 1097] train: loss: 0.0372492
[Epoch 70; Iter   687/ 1097] train: loss: 0.0552982
[Epoch 70; Iter   717/ 1097] train: loss: 0.0105740
[Epoch 70; Iter   747/ 1097] train: loss: 0.0062877
[Epoch 70; Iter   777/ 1097] train: loss: 0.0315457
[Epoch 70; Iter   807/ 1097] train: loss: 0.2365568
[Epoch 70; Iter   837/ 1097] train: loss: 0.0064461
[Epoch 70; Iter   867/ 1097] train: loss: 0.0033795
[Epoch 70; Iter   897/ 1097] train: loss: 0.0153359
[Epoch 70; Iter   927/ 1097] train: loss: 0.0071837
[Epoch 70; Iter   957/ 1097] train: loss: 0.0329799
[Epoch 70; Iter   987/ 1097] train: loss: 0.1274108
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0042899
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0069455
[Epoch 70; Iter  1077/ 1097] train: loss: 0.1789861
[Epoch 70] ogbg-molhiv: 0.810770 val loss: 0.105521
[Epoch 70] ogbg-molhiv: 0.757259 test loss: 0.209719
[Epoch 71; Iter    10/ 1097] train: loss: 0.1107737
[Epoch 71; Iter    40/ 1097] train: loss: 0.0015448
[Epoch 71; Iter    70/ 1097] train: loss: 0.0172348
[Epoch 71; Iter   100/ 1097] train: loss: 0.0770145
[Epoch 71; Iter   130/ 1097] train: loss: 0.0152031
[Epoch 71; Iter   160/ 1097] train: loss: 0.0234997
[Epoch 71; Iter   190/ 1097] train: loss: 0.1216956
[Epoch 71; Iter   220/ 1097] train: loss: 0.0095686
[Epoch 71; Iter   250/ 1097] train: loss: 0.0044066
[Epoch 71; Iter   280/ 1097] train: loss: 0.0081705
[Epoch 71; Iter   310/ 1097] train: loss: 0.0231614
[Epoch 71; Iter   340/ 1097] train: loss: 0.0478632
[Epoch 71; Iter   370/ 1097] train: loss: 0.0196776
[Epoch 71; Iter   400/ 1097] train: loss: 0.0149849
[Epoch 71; Iter   430/ 1097] train: loss: 0.0274218
[Epoch 71; Iter   460/ 1097] train: loss: 0.0144015
[Epoch 71; Iter   490/ 1097] train: loss: 0.0225527
[Epoch 71; Iter   520/ 1097] train: loss: 0.0149501
[Epoch 71; Iter   550/ 1097] train: loss: 0.0123632
[Epoch 71; Iter   580/ 1097] train: loss: 0.0379406
[Epoch 71; Iter   610/ 1097] train: loss: 0.0016592
[Epoch 71; Iter   640/ 1097] train: loss: 0.0205189
[Epoch 71; Iter   670/ 1097] train: loss: 0.0210323
[Epoch 71; Iter   700/ 1097] train: loss: 0.0539718
[Epoch 71; Iter   730/ 1097] train: loss: 0.0168927
[Epoch 71; Iter   760/ 1097] train: loss: 0.0113272
[Epoch 71; Iter   790/ 1097] train: loss: 0.0153598
[Epoch 71; Iter   820/ 1097] train: loss: 0.0309865
[Epoch 71; Iter   850/ 1097] train: loss: 0.0209230
[Epoch 71; Iter   880/ 1097] train: loss: 0.0024610
[Epoch 71; Iter   910/ 1097] train: loss: 0.0275439
[Epoch 71; Iter   940/ 1097] train: loss: 0.0417104
[Epoch 71; Iter   970/ 1097] train: loss: 0.0069298
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0983666
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0015835
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0492877
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0536926
[Epoch 71] ogbg-molhiv: 0.791214 val loss: 0.115029
[Epoch 71] ogbg-molhiv: 0.745972 test loss: 0.268330
[Epoch 72; Iter    23/ 1097] train: loss: 0.0045852
[Epoch 72; Iter    53/ 1097] train: loss: 0.0595482
[Epoch 72; Iter    83/ 1097] train: loss: 0.0019383
[Epoch 72; Iter   113/ 1097] train: loss: 0.1770377
[Epoch 72; Iter   143/ 1097] train: loss: 0.0163743
[Epoch 72; Iter   173/ 1097] train: loss: 0.0143067
[Epoch 72; Iter   203/ 1097] train: loss: 0.0386540
[Epoch 72; Iter   233/ 1097] train: loss: 0.0078127
[Epoch 72; Iter   263/ 1097] train: loss: 0.0316763
[Epoch 72; Iter   293/ 1097] train: loss: 0.1018776
[Epoch 72; Iter   323/ 1097] train: loss: 0.0759925
[Epoch 72; Iter   353/ 1097] train: loss: 0.0049416
[Epoch 72; Iter   383/ 1097] train: loss: 0.0210225
[Epoch 72; Iter   413/ 1097] train: loss: 0.0576120
[Epoch 72; Iter   443/ 1097] train: loss: 0.0365094
[Epoch 72; Iter   473/ 1097] train: loss: 0.0178346
[Epoch 72; Iter   503/ 1097] train: loss: 0.0087893
[Epoch 72; Iter   533/ 1097] train: loss: 0.0113310
[Epoch 72; Iter   563/ 1097] train: loss: 0.0107877
[Epoch 72; Iter   593/ 1097] train: loss: 0.0147644
[Epoch 72; Iter   623/ 1097] train: loss: 0.0041057
[Epoch 72; Iter   653/ 1097] train: loss: 0.1036549
[Epoch 72; Iter   683/ 1097] train: loss: 0.0203307
[Epoch 72; Iter   713/ 1097] train: loss: 0.0191242
[Epoch 72; Iter   743/ 1097] train: loss: 0.0144761
[Epoch 72; Iter   773/ 1097] train: loss: 0.0060141
[Epoch 72; Iter   803/ 1097] train: loss: 0.0088139
[Epoch 72; Iter   833/ 1097] train: loss: 0.0410557
[Epoch 72; Iter   863/ 1097] train: loss: 0.0103176
[Epoch 72; Iter   893/ 1097] train: loss: 0.0445391
[Epoch 72; Iter   923/ 1097] train: loss: 0.0121784
[Epoch 72; Iter   953/ 1097] train: loss: 0.0114990
[Epoch 72; Iter   983/ 1097] train: loss: 0.0059910
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0605598
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0468082
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0282992
[Epoch 72] ogbg-molhiv: 0.796094 val loss: 0.115986
[Epoch 72] ogbg-molhiv: 0.748968 test loss: 0.234254
[Epoch 73; Iter     6/ 1097] train: loss: 0.0168008
[Epoch 73; Iter    36/ 1097] train: loss: 0.0079401
[Epoch 73; Iter    66/ 1097] train: loss: 0.0045715
[Epoch 73; Iter    96/ 1097] train: loss: 0.1057585
[Epoch 73; Iter   126/ 1097] train: loss: 0.0152309
[Epoch 73; Iter   156/ 1097] train: loss: 0.0006640
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000605
[Epoch 89; Iter   544/ 1097] train: loss: 0.0007200
[Epoch 89; Iter   574/ 1097] train: loss: 0.0003661
[Epoch 89; Iter   604/ 1097] train: loss: 0.0458110
[Epoch 89; Iter   634/ 1097] train: loss: 0.0045599
[Epoch 89; Iter   664/ 1097] train: loss: 0.0001836
[Epoch 89; Iter   694/ 1097] train: loss: 0.0001166
[Epoch 89; Iter   724/ 1097] train: loss: 0.0016413
[Epoch 89; Iter   754/ 1097] train: loss: 0.0036872
[Epoch 89; Iter   784/ 1097] train: loss: 0.0018847
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000203
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000437
[Epoch 89; Iter   874/ 1097] train: loss: 0.0000751
[Epoch 89; Iter   904/ 1097] train: loss: 0.0003661
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000740
[Epoch 89; Iter   964/ 1097] train: loss: 0.0002121
[Epoch 89; Iter   994/ 1097] train: loss: 0.0005485
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0002721
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0005807
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0010964
[Epoch 89] ogbg-molhiv: 0.758757 val loss: 1.734459
[Epoch 89] ogbg-molhiv: 0.727660 test loss: 1.856396
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000431
[Epoch 90; Iter    47/ 1097] train: loss: 0.0019337
[Epoch 90; Iter    77/ 1097] train: loss: 0.0000234
[Epoch 90; Iter   107/ 1097] train: loss: 0.0000767
[Epoch 90; Iter   137/ 1097] train: loss: 0.0001074
[Epoch 90; Iter   167/ 1097] train: loss: 0.0002276
[Epoch 90; Iter   197/ 1097] train: loss: 0.0000639
[Epoch 90; Iter   227/ 1097] train: loss: 0.0000371
[Epoch 90; Iter   257/ 1097] train: loss: 0.0007227
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000814
[Epoch 90; Iter   317/ 1097] train: loss: 0.0000526
[Epoch 90; Iter   347/ 1097] train: loss: 0.0007894
[Epoch 90; Iter   377/ 1097] train: loss: 0.0002043
[Epoch 90; Iter   407/ 1097] train: loss: 0.0002019
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000783
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000291
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000676
[Epoch 90; Iter   527/ 1097] train: loss: 0.0002033
[Epoch 90; Iter   557/ 1097] train: loss: 0.0004288
[Epoch 90; Iter   587/ 1097] train: loss: 0.0005773
[Epoch 90; Iter   617/ 1097] train: loss: 0.0017528
[Epoch 90; Iter   647/ 1097] train: loss: 0.0001681
[Epoch 90; Iter   677/ 1097] train: loss: 0.0004314
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000118
[Epoch 90; Iter   737/ 1097] train: loss: 0.0000429
[Epoch 90; Iter   767/ 1097] train: loss: 0.0007442
[Epoch 90; Iter   797/ 1097] train: loss: 0.0015660
[Epoch 90; Iter   827/ 1097] train: loss: 0.0000386
[Epoch 90; Iter   857/ 1097] train: loss: 0.0000492
[Epoch 90; Iter   887/ 1097] train: loss: 0.0005055
[Epoch 90; Iter   917/ 1097] train: loss: 0.0002783
[Epoch 90; Iter   947/ 1097] train: loss: 0.0015090
[Epoch 90; Iter   977/ 1097] train: loss: 0.0001070
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0017083
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0017925
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0000849
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0001127
[Epoch 90] ogbg-molhiv: 0.753405 val loss: 0.226755
[Epoch 90] ogbg-molhiv: 0.717484 test loss: 0.358230
[Epoch 91; Iter    30/ 1097] train: loss: 0.0002340
[Epoch 91; Iter    60/ 1097] train: loss: 0.0000233
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000113
[Epoch 91; Iter   120/ 1097] train: loss: 0.0002203
[Epoch 91; Iter   150/ 1097] train: loss: 0.0018977
[Epoch 91; Iter   180/ 1097] train: loss: 0.0006559
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000213
[Epoch 91; Iter   240/ 1097] train: loss: 0.0426105
[Epoch 91; Iter   270/ 1097] train: loss: 0.0706036
[Epoch 91; Iter   300/ 1097] train: loss: 0.0000211
[Epoch 91; Iter   330/ 1097] train: loss: 0.0000139
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000312
[Epoch 91; Iter   390/ 1097] train: loss: 0.0001211
[Epoch 91; Iter   420/ 1097] train: loss: 0.0000557
[Epoch 91; Iter   450/ 1097] train: loss: 0.0010378
[Epoch 91; Iter   480/ 1097] train: loss: 0.0000574
[Epoch 91; Iter   510/ 1097] train: loss: 0.0010789
[Epoch 91; Iter   540/ 1097] train: loss: 0.0002253
[Epoch 91; Iter   570/ 1097] train: loss: 0.0002806
[Epoch 91; Iter   600/ 1097] train: loss: 0.0001655
[Epoch 91; Iter   630/ 1097] train: loss: 0.0005084
[Epoch 91; Iter   660/ 1097] train: loss: 0.0007739
[Epoch 91; Iter   690/ 1097] train: loss: 0.0001267
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000586
[Epoch 91; Iter   750/ 1097] train: loss: 0.0004176
[Epoch 91; Iter   780/ 1097] train: loss: 0.0004786
[Epoch 91; Iter   810/ 1097] train: loss: 0.0003215
[Epoch 91; Iter   840/ 1097] train: loss: 0.0001943
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000626
[Epoch 91; Iter   900/ 1097] train: loss: 0.0001102
[Epoch 91; Iter   930/ 1097] train: loss: 0.0023361
[Epoch 91; Iter   960/ 1097] train: loss: 0.1048505
[Epoch 91; Iter   990/ 1097] train: loss: 0.0019121
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0002185
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0001168
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0001405
[Epoch 91] ogbg-molhiv: 0.685697 val loss: 3.199563
[Epoch 91] ogbg-molhiv: 0.726001 test loss: 1.410537
[Epoch 92; Iter    13/ 1097] train: loss: 0.0001395
[Epoch 92; Iter    43/ 1097] train: loss: 0.0054624
[Epoch 92; Iter    73/ 1097] train: loss: 0.0004805
[Epoch 92; Iter   103/ 1097] train: loss: 0.0003042
[Epoch 92; Iter   133/ 1097] train: loss: 0.0000117
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000096
[Epoch 92; Iter   193/ 1097] train: loss: 0.0000419
[Epoch 92; Iter   223/ 1097] train: loss: 0.0001189
[Epoch 92; Iter   253/ 1097] train: loss: 0.0048680
[Epoch 92; Iter   283/ 1097] train: loss: 0.0008942
[Epoch 92; Iter   313/ 1097] train: loss: 0.0003112
[Epoch 92; Iter   343/ 1097] train: loss: 0.0000964
[Epoch 92; Iter   373/ 1097] train: loss: 0.0000251
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000484
[Epoch 92; Iter   433/ 1097] train: loss: 0.0032910
[Epoch 92; Iter   463/ 1097] train: loss: 0.0107373
[Epoch 92; Iter   493/ 1097] train: loss: 0.0021149
[Epoch 92; Iter   523/ 1097] train: loss: 0.0001238
[Epoch 92; Iter   553/ 1097] train: loss: 0.0079918
[Epoch 92; Iter   583/ 1097] train: loss: 0.0006073
[Epoch 92; Iter   613/ 1097] train: loss: 0.2042750
[Epoch 92; Iter   643/ 1097] train: loss: 0.0021303
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000126
[Epoch 92; Iter   703/ 1097] train: loss: 0.0003330
[Epoch 92; Iter   733/ 1097] train: loss: 0.0012427
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000723
[Epoch 92; Iter   793/ 1097] train: loss: 0.0011856
[Epoch 92; Iter   823/ 1097] train: loss: 0.0023889
[Epoch 92; Iter   853/ 1097] train: loss: 0.0000441
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000963
[Epoch 92; Iter   913/ 1097] train: loss: 0.0002075
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000561
[Epoch 92; Iter   973/ 1097] train: loss: 0.0048835
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0003187
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0005085
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0002894
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0015912
[Epoch 92] ogbg-molhiv: 0.717761 val loss: 0.932345
[Epoch 92] ogbg-molhiv: 0.724587 test loss: 0.409391
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000075
[Epoch 93; Iter    56/ 1097] train: loss: 0.0002413
[Epoch 93; Iter    86/ 1097] train: loss: 0.0000677
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000595
[Epoch 93; Iter   146/ 1097] train: loss: 0.0005474
[Epoch 93; Iter   176/ 1097] train: loss: 0.0000294
[Epoch 93; Iter   206/ 1097] train: loss: 0.0001265
[Epoch 93; Iter   236/ 1097] train: loss: 0.0000686
[Epoch 93; Iter   266/ 1097] train: loss: 0.0000670
[Epoch 93; Iter   296/ 1097] train: loss: 0.0003740
[Epoch 93; Iter   326/ 1097] train: loss: 0.0004628
[Epoch 93; Iter   356/ 1097] train: loss: 0.0003568
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000644
[Epoch 93; Iter   416/ 1097] train: loss: 0.0000415
[Epoch 93; Iter   446/ 1097] train: loss: 0.0054746
[Epoch 93; Iter   476/ 1097] train: loss: 0.0004415
[Epoch 93; Iter   506/ 1097] train: loss: 0.0001954
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000269
[Epoch 93; Iter   566/ 1097] train: loss: 0.0000792
[Epoch 89; Iter   514/ 1097] train: loss: 0.0001983
[Epoch 89; Iter   544/ 1097] train: loss: 0.0003946
[Epoch 89; Iter   574/ 1097] train: loss: 0.0008307
[Epoch 89; Iter   604/ 1097] train: loss: 0.0000894
[Epoch 89; Iter   634/ 1097] train: loss: 0.0001050
[Epoch 89; Iter   664/ 1097] train: loss: 0.0000304
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000351
[Epoch 89; Iter   724/ 1097] train: loss: 0.0017469
[Epoch 89; Iter   754/ 1097] train: loss: 0.0002149
[Epoch 89; Iter   784/ 1097] train: loss: 0.0009127
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000837
[Epoch 89; Iter   844/ 1097] train: loss: 0.0011627
[Epoch 89; Iter   874/ 1097] train: loss: 0.0016364
[Epoch 89; Iter   904/ 1097] train: loss: 0.0000767
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000326
[Epoch 89; Iter   964/ 1097] train: loss: 0.0003665
[Epoch 89; Iter   994/ 1097] train: loss: 0.0002198
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0028765
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0061063
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0000673
[Epoch 89] ogbg-molhiv: 0.702093 val loss: 1.137731
[Epoch 89] ogbg-molhiv: 0.706754 test loss: 0.853785
[Epoch 90; Iter    17/ 1097] train: loss: 0.0011788
[Epoch 90; Iter    47/ 1097] train: loss: 0.0055750
[Epoch 90; Iter    77/ 1097] train: loss: 0.0000369
[Epoch 90; Iter   107/ 1097] train: loss: 0.0003325
[Epoch 90; Iter   137/ 1097] train: loss: 0.0000433
[Epoch 90; Iter   167/ 1097] train: loss: 0.1247976
[Epoch 90; Iter   197/ 1097] train: loss: 0.0006669
[Epoch 90; Iter   227/ 1097] train: loss: 0.0003038
[Epoch 90; Iter   257/ 1097] train: loss: 0.0001800
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000110
[Epoch 90; Iter   317/ 1097] train: loss: 0.0009107
[Epoch 90; Iter   347/ 1097] train: loss: 0.0000416
[Epoch 90; Iter   377/ 1097] train: loss: 0.0002527
[Epoch 90; Iter   407/ 1097] train: loss: 0.0001853
[Epoch 90; Iter   437/ 1097] train: loss: 0.0002678
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000172
[Epoch 90; Iter   497/ 1097] train: loss: 0.0001398
[Epoch 90; Iter   527/ 1097] train: loss: 0.0004993
[Epoch 90; Iter   557/ 1097] train: loss: 0.0019520
[Epoch 90; Iter   587/ 1097] train: loss: 0.0000186
[Epoch 90; Iter   617/ 1097] train: loss: 0.0005294
[Epoch 90; Iter   647/ 1097] train: loss: 0.0001890
[Epoch 90; Iter   677/ 1097] train: loss: 0.0006811
[Epoch 90; Iter   707/ 1097] train: loss: 0.0004265
[Epoch 90; Iter   737/ 1097] train: loss: 0.0083150
[Epoch 90; Iter   767/ 1097] train: loss: 0.0362434
[Epoch 90; Iter   797/ 1097] train: loss: 0.0061882
[Epoch 90; Iter   827/ 1097] train: loss: 0.0011549
[Epoch 90; Iter   857/ 1097] train: loss: 0.0006792
[Epoch 90; Iter   887/ 1097] train: loss: 0.0001073
[Epoch 90; Iter   917/ 1097] train: loss: 0.0001300
[Epoch 90; Iter   947/ 1097] train: loss: 0.0000891
[Epoch 90; Iter   977/ 1097] train: loss: 0.0088764
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0000708
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0003248
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0027907
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0006536
[Epoch 90] ogbg-molhiv: 0.699864 val loss: 0.911965
[Epoch 90] ogbg-molhiv: 0.716460 test loss: 0.710152
[Epoch 91; Iter    30/ 1097] train: loss: 0.0000871
[Epoch 91; Iter    60/ 1097] train: loss: 0.0008993
[Epoch 91; Iter    90/ 1097] train: loss: 0.0003091
[Epoch 91; Iter   120/ 1097] train: loss: 0.0001982
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000561
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000191
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000175
[Epoch 91; Iter   240/ 1097] train: loss: 0.0000962
[Epoch 91; Iter   270/ 1097] train: loss: 0.0004814
[Epoch 91; Iter   300/ 1097] train: loss: 0.0008935
[Epoch 91; Iter   330/ 1097] train: loss: 0.0000772
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000093
[Epoch 91; Iter   390/ 1097] train: loss: 0.0001030
[Epoch 91; Iter   420/ 1097] train: loss: 0.0000104
[Epoch 91; Iter   450/ 1097] train: loss: 0.0001037
[Epoch 91; Iter   480/ 1097] train: loss: 0.0003916
[Epoch 91; Iter   510/ 1097] train: loss: 0.0001412
[Epoch 91; Iter   540/ 1097] train: loss: 0.0001422
[Epoch 91; Iter   570/ 1097] train: loss: 0.0001062
[Epoch 91; Iter   600/ 1097] train: loss: 0.0281259
[Epoch 91; Iter   630/ 1097] train: loss: 0.0003224
[Epoch 91; Iter   660/ 1097] train: loss: 0.0016789
[Epoch 91; Iter   690/ 1097] train: loss: 0.0004075
[Epoch 91; Iter   720/ 1097] train: loss: 0.0002177
[Epoch 91; Iter   750/ 1097] train: loss: 0.0002070
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000055
[Epoch 91; Iter   810/ 1097] train: loss: 0.0002446
[Epoch 91; Iter   840/ 1097] train: loss: 0.0004882
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000676
[Epoch 91; Iter   900/ 1097] train: loss: 0.0000243
[Epoch 91; Iter   930/ 1097] train: loss: 0.0055849
[Epoch 91; Iter   960/ 1097] train: loss: 0.0005180
[Epoch 91; Iter   990/ 1097] train: loss: 0.0270766
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0001021
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0000420
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0000873
[Epoch 91] ogbg-molhiv: 0.688422 val loss: 1.495507
[Epoch 91] ogbg-molhiv: 0.701292 test loss: 1.168316
[Epoch 92; Iter    13/ 1097] train: loss: 0.0007571
[Epoch 92; Iter    43/ 1097] train: loss: 0.0008020
[Epoch 92; Iter    73/ 1097] train: loss: 0.0005011
[Epoch 92; Iter   103/ 1097] train: loss: 0.0000470
[Epoch 92; Iter   133/ 1097] train: loss: 0.0000542
[Epoch 92; Iter   163/ 1097] train: loss: 0.0003675
[Epoch 92; Iter   193/ 1097] train: loss: 0.0002101
[Epoch 92; Iter   223/ 1097] train: loss: 0.0012065
[Epoch 92; Iter   253/ 1097] train: loss: 0.0000985
[Epoch 92; Iter   283/ 1097] train: loss: 0.0001458
[Epoch 92; Iter   313/ 1097] train: loss: 0.0007441
[Epoch 92; Iter   343/ 1097] train: loss: 0.0055006
[Epoch 92; Iter   373/ 1097] train: loss: 0.0001023
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000364
[Epoch 92; Iter   433/ 1097] train: loss: 0.0025528
[Epoch 92; Iter   463/ 1097] train: loss: 0.0000058
[Epoch 92; Iter   493/ 1097] train: loss: 0.0011123
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000238
[Epoch 92; Iter   553/ 1097] train: loss: 0.0000177
[Epoch 92; Iter   583/ 1097] train: loss: 0.0005624
[Epoch 92; Iter   613/ 1097] train: loss: 0.0000726
[Epoch 92; Iter   643/ 1097] train: loss: 0.0006108
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000689
[Epoch 92; Iter   703/ 1097] train: loss: 0.0004557
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000076
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000199
[Epoch 92; Iter   793/ 1097] train: loss: 0.0001531
[Epoch 92; Iter   823/ 1097] train: loss: 0.0001111
[Epoch 92; Iter   853/ 1097] train: loss: 0.0025004
[Epoch 92; Iter   883/ 1097] train: loss: 0.0004630
[Epoch 92; Iter   913/ 1097] train: loss: 0.0003273
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000867
[Epoch 92; Iter   973/ 1097] train: loss: 0.0002491
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0002559
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0000361
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000171
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0006401
[Epoch 92] ogbg-molhiv: 0.692004 val loss: 1.258939
[Epoch 92] ogbg-molhiv: 0.706632 test loss: 0.602795
[Epoch 93; Iter    26/ 1097] train: loss: 0.0147102
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000144
[Epoch 93; Iter    86/ 1097] train: loss: 0.0000245
[Epoch 93; Iter   116/ 1097] train: loss: 0.0071003
[Epoch 93; Iter   146/ 1097] train: loss: 0.0042119
[Epoch 93; Iter   176/ 1097] train: loss: 0.0615503
[Epoch 93; Iter   206/ 1097] train: loss: 0.0001042
[Epoch 93; Iter   236/ 1097] train: loss: 0.0001717
[Epoch 93; Iter   266/ 1097] train: loss: 0.0012360
[Epoch 93; Iter   296/ 1097] train: loss: 0.0000061
[Epoch 93; Iter   326/ 1097] train: loss: 0.0042672
[Epoch 93; Iter   356/ 1097] train: loss: 0.0000467
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000349
[Epoch 93; Iter   416/ 1097] train: loss: 0.0003263
[Epoch 93; Iter   446/ 1097] train: loss: 0.0000774
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000534
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000160
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000060
[Epoch 93; Iter   566/ 1097] train: loss: 0.0001140
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000158
[Epoch 89; Iter   544/ 1097] train: loss: 0.0015043
[Epoch 89; Iter   574/ 1097] train: loss: 0.0003198
[Epoch 89; Iter   604/ 1097] train: loss: 0.0000855
[Epoch 89; Iter   634/ 1097] train: loss: 0.0005302
[Epoch 89; Iter   664/ 1097] train: loss: 0.0004078
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000338
[Epoch 89; Iter   724/ 1097] train: loss: 0.0000158
[Epoch 89; Iter   754/ 1097] train: loss: 0.0000099
[Epoch 89; Iter   784/ 1097] train: loss: 0.0032088
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000148
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000594
[Epoch 89; Iter   874/ 1097] train: loss: 0.0000309
[Epoch 89; Iter   904/ 1097] train: loss: 0.0001212
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000153
[Epoch 89; Iter   964/ 1097] train: loss: 0.0000179
[Epoch 89; Iter   994/ 1097] train: loss: 0.0000954
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0000129
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0000551
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0000042
[Epoch 89] ogbg-molhiv: 0.775768 val loss: 0.242487
[Epoch 89] ogbg-molhiv: 0.737338 test loss: 0.383062
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000399
[Epoch 90; Iter    47/ 1097] train: loss: 0.0019493
[Epoch 90; Iter    77/ 1097] train: loss: 0.0000034
[Epoch 90; Iter   107/ 1097] train: loss: 0.0000198
[Epoch 90; Iter   137/ 1097] train: loss: 0.0089272
[Epoch 90; Iter   167/ 1097] train: loss: 0.0004464
[Epoch 90; Iter   197/ 1097] train: loss: 0.0000326
[Epoch 90; Iter   227/ 1097] train: loss: 0.0000039
[Epoch 90; Iter   257/ 1097] train: loss: 0.0000079
[Epoch 90; Iter   287/ 1097] train: loss: 0.0005977
[Epoch 90; Iter   317/ 1097] train: loss: 0.0005051
[Epoch 90; Iter   347/ 1097] train: loss: 0.0001242
[Epoch 90; Iter   377/ 1097] train: loss: 0.0000399
[Epoch 90; Iter   407/ 1097] train: loss: 0.0000247
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000427
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000662
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000824
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000125
[Epoch 90; Iter   557/ 1097] train: loss: 0.0000221
[Epoch 90; Iter   587/ 1097] train: loss: 0.0000392
[Epoch 90; Iter   617/ 1097] train: loss: 0.0000068
[Epoch 90; Iter   647/ 1097] train: loss: 0.0000044
[Epoch 90; Iter   677/ 1097] train: loss: 0.0000018
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000115
[Epoch 90; Iter   737/ 1097] train: loss: 0.0001911
[Epoch 90; Iter   767/ 1097] train: loss: 0.0027481
[Epoch 90; Iter   797/ 1097] train: loss: 0.0000417
[Epoch 90; Iter   827/ 1097] train: loss: 0.0000861
[Epoch 90; Iter   857/ 1097] train: loss: 0.0000083
[Epoch 90; Iter   887/ 1097] train: loss: 0.0001657
[Epoch 90; Iter   917/ 1097] train: loss: 0.0000723
[Epoch 90; Iter   947/ 1097] train: loss: 0.0005578
[Epoch 90; Iter   977/ 1097] train: loss: 0.0000351
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0003568
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0000319
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0000747
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0000160
[Epoch 90] ogbg-molhiv: 0.776795 val loss: 0.240027
[Epoch 90] ogbg-molhiv: 0.738481 test loss: 0.385720
[Epoch 91; Iter    30/ 1097] train: loss: 0.0000249
[Epoch 91; Iter    60/ 1097] train: loss: 0.0002037
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000023
[Epoch 91; Iter   120/ 1097] train: loss: 0.0000044
[Epoch 91; Iter   150/ 1097] train: loss: 0.0002412
[Epoch 91; Iter   180/ 1097] train: loss: 0.0009255
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000699
[Epoch 91; Iter   240/ 1097] train: loss: 0.0000202
[Epoch 91; Iter   270/ 1097] train: loss: 0.0184857
[Epoch 91; Iter   300/ 1097] train: loss: 0.0000017
[Epoch 91; Iter   330/ 1097] train: loss: 0.0002751
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000018
[Epoch 91; Iter   390/ 1097] train: loss: 0.0000469
[Epoch 91; Iter   420/ 1097] train: loss: 0.0000731
[Epoch 91; Iter   450/ 1097] train: loss: 0.0000812
[Epoch 91; Iter   480/ 1097] train: loss: 0.0005293
[Epoch 91; Iter   510/ 1097] train: loss: 0.0000357
[Epoch 91; Iter   540/ 1097] train: loss: 0.0000631
[Epoch 91; Iter   570/ 1097] train: loss: 0.0001141
[Epoch 91; Iter   600/ 1097] train: loss: 0.0002247
[Epoch 91; Iter   630/ 1097] train: loss: 0.0000764
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000367
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000083
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000109
[Epoch 91; Iter   750/ 1097] train: loss: 0.0126580
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000045
[Epoch 91; Iter   810/ 1097] train: loss: 0.0000339
[Epoch 91; Iter   840/ 1097] train: loss: 0.0001171
[Epoch 91; Iter   870/ 1097] train: loss: 0.0022300
[Epoch 91; Iter   900/ 1097] train: loss: 0.0012058
[Epoch 91; Iter   930/ 1097] train: loss: 0.0001239
[Epoch 91; Iter   960/ 1097] train: loss: 0.0000540
[Epoch 91; Iter   990/ 1097] train: loss: 0.0000087
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0000191
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0004406
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0025705
[Epoch 91] ogbg-molhiv: 0.775362 val loss: 0.250605
[Epoch 91] ogbg-molhiv: 0.745306 test loss: 0.386240
[Epoch 92; Iter    13/ 1097] train: loss: 0.0000490
[Epoch 92; Iter    43/ 1097] train: loss: 0.0060670
[Epoch 92; Iter    73/ 1097] train: loss: 0.0000247
[Epoch 92; Iter   103/ 1097] train: loss: 0.0000659
[Epoch 92; Iter   133/ 1097] train: loss: 0.0025195
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000068
[Epoch 92; Iter   193/ 1097] train: loss: 0.0000554
[Epoch 92; Iter   223/ 1097] train: loss: 0.0000215
[Epoch 92; Iter   253/ 1097] train: loss: 0.0010917
[Epoch 92; Iter   283/ 1097] train: loss: 0.0000080
[Epoch 92; Iter   313/ 1097] train: loss: 0.0002962
[Epoch 92; Iter   343/ 1097] train: loss: 0.0000238
[Epoch 92; Iter   373/ 1097] train: loss: 0.0066641
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000170
[Epoch 92; Iter   433/ 1097] train: loss: 0.0003818
[Epoch 92; Iter   463/ 1097] train: loss: 0.0094344
[Epoch 92; Iter   493/ 1097] train: loss: 0.0002241
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000535
[Epoch 92; Iter   553/ 1097] train: loss: 0.0000557
[Epoch 92; Iter   583/ 1097] train: loss: 0.0000703
[Epoch 92; Iter   613/ 1097] train: loss: 0.0000081
[Epoch 92; Iter   643/ 1097] train: loss: 0.0000019
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000216
[Epoch 92; Iter   703/ 1097] train: loss: 0.0001874
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000095
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000223
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000070
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000043
[Epoch 92; Iter   853/ 1097] train: loss: 0.0001745
[Epoch 92; Iter   883/ 1097] train: loss: 0.0019867
[Epoch 92; Iter   913/ 1097] train: loss: 0.0004352
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000203
[Epoch 92; Iter   973/ 1097] train: loss: 0.0000148
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0001007
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0000255
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000665
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000127
[Epoch 92] ogbg-molhiv: 0.763632 val loss: 0.259311
[Epoch 92] ogbg-molhiv: 0.738639 test loss: 0.410785
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000166
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000084
[Epoch 93; Iter    86/ 1097] train: loss: 0.0000285
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000180
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000149
[Epoch 93; Iter   176/ 1097] train: loss: 0.0130547
[Epoch 93; Iter   206/ 1097] train: loss: 0.0004438
[Epoch 93; Iter   236/ 1097] train: loss: 0.0000021
[Epoch 93; Iter   266/ 1097] train: loss: 0.0000299
[Epoch 93; Iter   296/ 1097] train: loss: 0.0000969
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000529
[Epoch 93; Iter   356/ 1097] train: loss: 0.0000075
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000598
[Epoch 93; Iter   416/ 1097] train: loss: 0.0000158
[Epoch 93; Iter   446/ 1097] train: loss: 0.0001858
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000101
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000207
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000212
[Epoch 93; Iter   566/ 1097] train: loss: 0.0001122
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000864
[Epoch 89; Iter   544/ 1097] train: loss: 0.0000911
[Epoch 89; Iter   574/ 1097] train: loss: 0.0002599
[Epoch 89; Iter   604/ 1097] train: loss: 0.0241261
[Epoch 89; Iter   634/ 1097] train: loss: 0.0008065
[Epoch 89; Iter   664/ 1097] train: loss: 0.0001377
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000090
[Epoch 89; Iter   724/ 1097] train: loss: 0.0000100
[Epoch 89; Iter   754/ 1097] train: loss: 0.0000508
[Epoch 89; Iter   784/ 1097] train: loss: 0.0003127
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000538
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000939
[Epoch 89; Iter   874/ 1097] train: loss: 0.0000529
[Epoch 89; Iter   904/ 1097] train: loss: 0.0000039
[Epoch 89; Iter   934/ 1097] train: loss: 0.1807647
[Epoch 89; Iter   964/ 1097] train: loss: 0.0000456
[Epoch 89; Iter   994/ 1097] train: loss: 0.0051224
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0006578
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0000074
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0001482
[Epoch 89] ogbg-molhiv: 0.771143 val loss: 0.380353
[Epoch 89] ogbg-molhiv: 0.750167 test loss: 0.364178
[Epoch 90; Iter    17/ 1097] train: loss: 0.0010515
[Epoch 90; Iter    47/ 1097] train: loss: 0.0036304
[Epoch 90; Iter    77/ 1097] train: loss: 0.0001173
[Epoch 90; Iter   107/ 1097] train: loss: 0.0001010
[Epoch 90; Iter   137/ 1097] train: loss: 0.0010953
[Epoch 90; Iter   167/ 1097] train: loss: 0.0004920
[Epoch 90; Iter   197/ 1097] train: loss: 0.0016524
[Epoch 90; Iter   227/ 1097] train: loss: 0.0000145
[Epoch 90; Iter   257/ 1097] train: loss: 0.0000432
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000249
[Epoch 90; Iter   317/ 1097] train: loss: 0.0002196
[Epoch 90; Iter   347/ 1097] train: loss: 0.0001376
[Epoch 90; Iter   377/ 1097] train: loss: 0.0000542
[Epoch 90; Iter   407/ 1097] train: loss: 0.0000510
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000822
[Epoch 90; Iter   467/ 1097] train: loss: 0.0025488
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000403
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000593
[Epoch 90; Iter   557/ 1097] train: loss: 0.0000110
[Epoch 90; Iter   587/ 1097] train: loss: 0.0001535
[Epoch 90; Iter   617/ 1097] train: loss: 0.0004229
[Epoch 90; Iter   647/ 1097] train: loss: 0.0098387
[Epoch 90; Iter   677/ 1097] train: loss: 0.0000106
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000097
[Epoch 90; Iter   737/ 1097] train: loss: 0.0039730
[Epoch 90; Iter   767/ 1097] train: loss: 0.0001061
[Epoch 90; Iter   797/ 1097] train: loss: 0.0000551
[Epoch 90; Iter   827/ 1097] train: loss: 0.0013418
[Epoch 90; Iter   857/ 1097] train: loss: 0.0002719
[Epoch 90; Iter   887/ 1097] train: loss: 0.0000401
[Epoch 90; Iter   917/ 1097] train: loss: 0.0069757
[Epoch 90; Iter   947/ 1097] train: loss: 0.1496035
[Epoch 90; Iter   977/ 1097] train: loss: 0.0006283
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0000179
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0001578
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0000429
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0008451
[Epoch 90] ogbg-molhiv: 0.780898 val loss: 0.385551
[Epoch 90] ogbg-molhiv: 0.761987 test loss: 0.371434
[Epoch 91; Iter    30/ 1097] train: loss: 0.0118591
[Epoch 91; Iter    60/ 1097] train: loss: 0.0002397
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000136
[Epoch 91; Iter   120/ 1097] train: loss: 0.0007727
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000337
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000619
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000269
[Epoch 91; Iter   240/ 1097] train: loss: 0.0000466
[Epoch 91; Iter   270/ 1097] train: loss: 0.0036673
[Epoch 91; Iter   300/ 1097] train: loss: 0.0002584
[Epoch 91; Iter   330/ 1097] train: loss: 0.0958335
[Epoch 91; Iter   360/ 1097] train: loss: 0.0005308
[Epoch 91; Iter   390/ 1097] train: loss: 0.0000045
[Epoch 91; Iter   420/ 1097] train: loss: 0.0145915
[Epoch 91; Iter   450/ 1097] train: loss: 0.0000107
[Epoch 91; Iter   480/ 1097] train: loss: 0.0001356
[Epoch 91; Iter   510/ 1097] train: loss: 0.0000871
[Epoch 91; Iter   540/ 1097] train: loss: 0.0003026
[Epoch 91; Iter   570/ 1097] train: loss: 0.0031389
[Epoch 91; Iter   600/ 1097] train: loss: 0.0001853
[Epoch 91; Iter   630/ 1097] train: loss: 0.0000476
[Epoch 91; Iter   660/ 1097] train: loss: 0.0003395
[Epoch 91; Iter   690/ 1097] train: loss: 0.0002504
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000053
[Epoch 91; Iter   750/ 1097] train: loss: 0.0000016
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000509
[Epoch 91; Iter   810/ 1097] train: loss: 0.0000017
[Epoch 91; Iter   840/ 1097] train: loss: 0.0087784
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000305
[Epoch 91; Iter   900/ 1097] train: loss: 0.0000032
[Epoch 91; Iter   930/ 1097] train: loss: 0.0000020
[Epoch 91; Iter   960/ 1097] train: loss: 0.0001668
[Epoch 91; Iter   990/ 1097] train: loss: 0.0002717
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0004956
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0002426
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0010700
[Epoch 91] ogbg-molhiv: 0.774753 val loss: 0.361497
[Epoch 91] ogbg-molhiv: 0.750393 test loss: 0.356360
[Epoch 92; Iter    13/ 1097] train: loss: 0.0010459
[Epoch 92; Iter    43/ 1097] train: loss: 0.0000134
[Epoch 92; Iter    73/ 1097] train: loss: 0.0000651
[Epoch 92; Iter   103/ 1097] train: loss: 0.0014849
[Epoch 92; Iter   133/ 1097] train: loss: 0.0000435
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000634
[Epoch 92; Iter   193/ 1097] train: loss: 0.0007785
[Epoch 92; Iter   223/ 1097] train: loss: 0.0002949
[Epoch 92; Iter   253/ 1097] train: loss: 0.0000068
[Epoch 92; Iter   283/ 1097] train: loss: 0.0000027
[Epoch 92; Iter   313/ 1097] train: loss: 0.0001502
[Epoch 92; Iter   343/ 1097] train: loss: 0.0005075
[Epoch 92; Iter   373/ 1097] train: loss: 0.0000044
[Epoch 92; Iter   403/ 1097] train: loss: 0.0001046
[Epoch 92; Iter   433/ 1097] train: loss: 0.0000535
[Epoch 92; Iter   463/ 1097] train: loss: 0.0003183
[Epoch 92; Iter   493/ 1097] train: loss: 0.0000263
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000365
[Epoch 92; Iter   553/ 1097] train: loss: 0.0074844
[Epoch 92; Iter   583/ 1097] train: loss: 0.0002107
[Epoch 92; Iter   613/ 1097] train: loss: 0.0000497
[Epoch 92; Iter   643/ 1097] train: loss: 0.0000567
[Epoch 92; Iter   673/ 1097] train: loss: 0.0001394
[Epoch 92; Iter   703/ 1097] train: loss: 0.0013174
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000608
[Epoch 92; Iter   763/ 1097] train: loss: 0.0074814
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000317
[Epoch 92; Iter   823/ 1097] train: loss: 0.0002294
[Epoch 92; Iter   853/ 1097] train: loss: 0.0142481
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000164
[Epoch 92; Iter   913/ 1097] train: loss: 0.0005473
[Epoch 92; Iter   943/ 1097] train: loss: 0.0001144
[Epoch 92; Iter   973/ 1097] train: loss: 0.0001346
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0002565
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0000108
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000054
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000035
[Epoch 92] ogbg-molhiv: 0.770849 val loss: 0.388115
[Epoch 92] ogbg-molhiv: 0.733819 test loss: 0.383487
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000254
[Epoch 93; Iter    56/ 1097] train: loss: 0.0005042
[Epoch 93; Iter    86/ 1097] train: loss: 0.0001287
[Epoch 93; Iter   116/ 1097] train: loss: 0.0020702
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000148
[Epoch 93; Iter   176/ 1097] train: loss: 0.0003413
[Epoch 93; Iter   206/ 1097] train: loss: 0.0000037
[Epoch 93; Iter   236/ 1097] train: loss: 0.0005724
[Epoch 93; Iter   266/ 1097] train: loss: 0.0001355
[Epoch 93; Iter   296/ 1097] train: loss: 0.0003609
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000149
[Epoch 93; Iter   356/ 1097] train: loss: 0.0000924
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000043
[Epoch 93; Iter   416/ 1097] train: loss: 0.0005953
[Epoch 93; Iter   446/ 1097] train: loss: 0.0000208
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000142
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000832
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000244
[Epoch 93; Iter   566/ 1097] train: loss: 0.0000555
[Epoch 89; Iter   514/ 1097] train: loss: 0.0001341
[Epoch 89; Iter   544/ 1097] train: loss: 0.0000639
[Epoch 89; Iter   574/ 1097] train: loss: 0.0000293
[Epoch 89; Iter   604/ 1097] train: loss: 0.0000395
[Epoch 89; Iter   634/ 1097] train: loss: 0.0001558
[Epoch 89; Iter   664/ 1097] train: loss: 0.0001382
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000535
[Epoch 89; Iter   724/ 1097] train: loss: 0.0000599
[Epoch 89; Iter   754/ 1097] train: loss: 0.0001029
[Epoch 89; Iter   784/ 1097] train: loss: 0.0936121
[Epoch 89; Iter   814/ 1097] train: loss: 0.0040912
[Epoch 89; Iter   844/ 1097] train: loss: 0.0001411
[Epoch 89; Iter   874/ 1097] train: loss: 0.0000112
[Epoch 89; Iter   904/ 1097] train: loss: 0.0000142
[Epoch 89; Iter   934/ 1097] train: loss: 0.0001137
[Epoch 89; Iter   964/ 1097] train: loss: 0.0000965
[Epoch 89; Iter   994/ 1097] train: loss: 0.0000184
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0000983
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0000183
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0009671
[Epoch 89] ogbg-molhiv: 0.790543 val loss: 0.324765
[Epoch 89] ogbg-molhiv: 0.741523 test loss: 0.484683
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000198
[Epoch 90; Iter    47/ 1097] train: loss: 0.0013035
[Epoch 90; Iter    77/ 1097] train: loss: 0.0032778
[Epoch 90; Iter   107/ 1097] train: loss: 0.0000791
[Epoch 90; Iter   137/ 1097] train: loss: 0.0000316
[Epoch 90; Iter   167/ 1097] train: loss: 0.0000534
[Epoch 90; Iter   197/ 1097] train: loss: 0.0000057
[Epoch 90; Iter   227/ 1097] train: loss: 0.0002493
[Epoch 90; Iter   257/ 1097] train: loss: 0.0001037
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000438
[Epoch 90; Iter   317/ 1097] train: loss: 0.0000043
[Epoch 90; Iter   347/ 1097] train: loss: 0.0000238
[Epoch 90; Iter   377/ 1097] train: loss: 0.0347740
[Epoch 90; Iter   407/ 1097] train: loss: 0.0000598
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000264
[Epoch 90; Iter   467/ 1097] train: loss: 0.0020133
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000080
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000136
[Epoch 90; Iter   557/ 1097] train: loss: 0.0000400
[Epoch 90; Iter   587/ 1097] train: loss: 0.0008720
[Epoch 90; Iter   617/ 1097] train: loss: 0.0000133
[Epoch 90; Iter   647/ 1097] train: loss: 0.0008494
[Epoch 90; Iter   677/ 1097] train: loss: 0.0001150
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000291
[Epoch 90; Iter   737/ 1097] train: loss: 0.0003255
[Epoch 90; Iter   767/ 1097] train: loss: 0.0001146
[Epoch 90; Iter   797/ 1097] train: loss: 0.0012235
[Epoch 90; Iter   827/ 1097] train: loss: 0.0000343
[Epoch 90; Iter   857/ 1097] train: loss: 0.0007828
[Epoch 90; Iter   887/ 1097] train: loss: 0.0000226
[Epoch 90; Iter   917/ 1097] train: loss: 0.0000402
[Epoch 90; Iter   947/ 1097] train: loss: 0.0004944
[Epoch 90; Iter   977/ 1097] train: loss: 0.0001332
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0000110
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0001120
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0003252
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0025409
[Epoch 90] ogbg-molhiv: 0.782658 val loss: 0.287595
[Epoch 90] ogbg-molhiv: 0.732708 test loss: 0.482257
[Epoch 91; Iter    30/ 1097] train: loss: 0.0001163
[Epoch 91; Iter    60/ 1097] train: loss: 0.0002841
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000086
[Epoch 91; Iter   120/ 1097] train: loss: 0.0002444
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000191
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000041
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000308
[Epoch 91; Iter   240/ 1097] train: loss: 0.0000832
[Epoch 91; Iter   270/ 1097] train: loss: 0.0003412
[Epoch 91; Iter   300/ 1097] train: loss: 0.0203122
[Epoch 91; Iter   330/ 1097] train: loss: 0.0200407
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000735
[Epoch 91; Iter   390/ 1097] train: loss: 0.0000167
[Epoch 91; Iter   420/ 1097] train: loss: 0.0028248
[Epoch 91; Iter   450/ 1097] train: loss: 0.0008187
[Epoch 91; Iter   480/ 1097] train: loss: 0.0000160
[Epoch 91; Iter   510/ 1097] train: loss: 0.0000766
[Epoch 91; Iter   540/ 1097] train: loss: 0.0018785
[Epoch 91; Iter   570/ 1097] train: loss: 0.0000711
[Epoch 91; Iter   600/ 1097] train: loss: 0.0000206
[Epoch 91; Iter   630/ 1097] train: loss: 0.0015383
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000144
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000096
[Epoch 91; Iter   720/ 1097] train: loss: 0.0001833
[Epoch 91; Iter   750/ 1097] train: loss: 0.0000428
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000539
[Epoch 91; Iter   810/ 1097] train: loss: 0.0000820
[Epoch 91; Iter   840/ 1097] train: loss: 0.0005123
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000881
[Epoch 91; Iter   900/ 1097] train: loss: 0.0011485
[Epoch 91; Iter   930/ 1097] train: loss: 0.0007758
[Epoch 91; Iter   960/ 1097] train: loss: 0.0000234
[Epoch 91; Iter   990/ 1097] train: loss: 0.0001207
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0000150
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0000185
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0020163
[Epoch 91] ogbg-molhiv: 0.788559 val loss: 0.349175
[Epoch 91] ogbg-molhiv: 0.731026 test loss: 0.458086
[Epoch 92; Iter    13/ 1097] train: loss: 0.0001495
[Epoch 92; Iter    43/ 1097] train: loss: 0.0000015
[Epoch 92; Iter    73/ 1097] train: loss: 0.0025647
[Epoch 92; Iter   103/ 1097] train: loss: 0.0001717
[Epoch 92; Iter   133/ 1097] train: loss: 0.0004666
[Epoch 92; Iter   163/ 1097] train: loss: 0.0002439
[Epoch 92; Iter   193/ 1097] train: loss: 0.0001068
[Epoch 92; Iter   223/ 1097] train: loss: 0.0001963
[Epoch 92; Iter   253/ 1097] train: loss: 0.0000081
[Epoch 92; Iter   283/ 1097] train: loss: 0.0000052
[Epoch 92; Iter   313/ 1097] train: loss: 0.0000118
[Epoch 92; Iter   343/ 1097] train: loss: 0.0023054
[Epoch 92; Iter   373/ 1097] train: loss: 0.0000762
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000517
[Epoch 92; Iter   433/ 1097] train: loss: 0.0001069
[Epoch 92; Iter   463/ 1097] train: loss: 0.0001770
[Epoch 92; Iter   493/ 1097] train: loss: 0.0006919
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000199
[Epoch 92; Iter   553/ 1097] train: loss: 0.0036669
[Epoch 92; Iter   583/ 1097] train: loss: 0.0001142
[Epoch 92; Iter   613/ 1097] train: loss: 0.0000230
[Epoch 92; Iter   643/ 1097] train: loss: 0.0003914
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000279
[Epoch 92; Iter   703/ 1097] train: loss: 0.0003521
[Epoch 92; Iter   733/ 1097] train: loss: 0.0001297
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000020
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000356
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000822
[Epoch 92; Iter   853/ 1097] train: loss: 0.0415194
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000210
[Epoch 92; Iter   913/ 1097] train: loss: 0.0019373
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000219
[Epoch 92; Iter   973/ 1097] train: loss: 0.0000073
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0000221
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0020128
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0001176
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000502
[Epoch 92] ogbg-molhiv: 0.789009 val loss: 0.299106
[Epoch 92] ogbg-molhiv: 0.737285 test loss: 0.429026
[Epoch 93; Iter    26/ 1097] train: loss: 0.0003834
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000162
[Epoch 93; Iter    86/ 1097] train: loss: 0.0006047
[Epoch 93; Iter   116/ 1097] train: loss: 0.0001418
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000296
[Epoch 93; Iter   176/ 1097] train: loss: 0.0000329
[Epoch 93; Iter   206/ 1097] train: loss: 0.0009651
[Epoch 93; Iter   236/ 1097] train: loss: 0.0000409
[Epoch 93; Iter   266/ 1097] train: loss: 0.0001255
[Epoch 93; Iter   296/ 1097] train: loss: 0.0003920
[Epoch 93; Iter   326/ 1097] train: loss: 0.0003817
[Epoch 93; Iter   356/ 1097] train: loss: 0.0002408
[Epoch 93; Iter   386/ 1097] train: loss: 0.0004264
[Epoch 93; Iter   416/ 1097] train: loss: 0.0006138
[Epoch 93; Iter   446/ 1097] train: loss: 0.0000550
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000652
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000544
[Epoch 93; Iter   536/ 1097] train: loss: 0.0002078
[Epoch 93; Iter   566/ 1097] train: loss: 0.0003558
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000091
[Epoch 89; Iter   544/ 1097] train: loss: 0.0005145
[Epoch 89; Iter   574/ 1097] train: loss: 0.0001748
[Epoch 89; Iter   604/ 1097] train: loss: 0.0012314
[Epoch 89; Iter   634/ 1097] train: loss: 0.0000034
[Epoch 89; Iter   664/ 1097] train: loss: 0.0003029
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000032
[Epoch 89; Iter   724/ 1097] train: loss: 0.0001122
[Epoch 89; Iter   754/ 1097] train: loss: 0.0000023
[Epoch 89; Iter   784/ 1097] train: loss: 0.0000937
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000116
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000970
[Epoch 89; Iter   874/ 1097] train: loss: 0.0003715
[Epoch 89; Iter   904/ 1097] train: loss: 0.0010930
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000061
[Epoch 89; Iter   964/ 1097] train: loss: 0.0003001
[Epoch 89; Iter   994/ 1097] train: loss: 0.0117179
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0000092
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0001963
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0000112
[Epoch 89] ogbg-molhiv: 0.793770 val loss: 0.263241
[Epoch 89] ogbg-molhiv: 0.787906 test loss: 0.342575
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000015
[Epoch 90; Iter    47/ 1097] train: loss: 0.0000016
[Epoch 90; Iter    77/ 1097] train: loss: 0.0000295
[Epoch 90; Iter   107/ 1097] train: loss: 0.0001896
[Epoch 90; Iter   137/ 1097] train: loss: 0.0000114
[Epoch 90; Iter   167/ 1097] train: loss: 0.0000107
[Epoch 90; Iter   197/ 1097] train: loss: 0.0000112
[Epoch 90; Iter   227/ 1097] train: loss: 0.0015281
[Epoch 90; Iter   257/ 1097] train: loss: 0.0025972
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000213
[Epoch 90; Iter   317/ 1097] train: loss: 0.0000029
[Epoch 90; Iter   347/ 1097] train: loss: 0.0000642
[Epoch 90; Iter   377/ 1097] train: loss: 0.0001703
[Epoch 90; Iter   407/ 1097] train: loss: 0.0014591
[Epoch 90; Iter   437/ 1097] train: loss: 0.0001558
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000316
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000019
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000060
[Epoch 90; Iter   557/ 1097] train: loss: 0.0000172
[Epoch 90; Iter   587/ 1097] train: loss: 0.0000183
[Epoch 90; Iter   617/ 1097] train: loss: 0.0014220
[Epoch 90; Iter   647/ 1097] train: loss: 0.0013153
[Epoch 90; Iter   677/ 1097] train: loss: 0.0000984
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000223
[Epoch 90; Iter   737/ 1097] train: loss: 0.0000014
[Epoch 90; Iter   767/ 1097] train: loss: 0.0000037
[Epoch 90; Iter   797/ 1097] train: loss: 0.0351565
[Epoch 90; Iter   827/ 1097] train: loss: 0.0000098
[Epoch 90; Iter   857/ 1097] train: loss: 0.0002438
[Epoch 90; Iter   887/ 1097] train: loss: 0.0000767
[Epoch 90; Iter   917/ 1097] train: loss: 0.0011411
[Epoch 90; Iter   947/ 1097] train: loss: 0.0000142
[Epoch 90; Iter   977/ 1097] train: loss: 0.0000032
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0007130
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0000111
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0017922
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0023146
[Epoch 90] ogbg-molhiv: 0.799885 val loss: 0.356162
[Epoch 90] ogbg-molhiv: 0.810931 test loss: 0.337323
[Epoch 91; Iter    30/ 1097] train: loss: 0.0000067
[Epoch 91; Iter    60/ 1097] train: loss: 0.0002163
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000402
[Epoch 91; Iter   120/ 1097] train: loss: 0.0215739
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000163
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000198
[Epoch 91; Iter   210/ 1097] train: loss: 0.0000595
[Epoch 91; Iter   240/ 1097] train: loss: 0.0007106
[Epoch 91; Iter   270/ 1097] train: loss: 0.0003679
[Epoch 91; Iter   300/ 1097] train: loss: 0.0002426
[Epoch 91; Iter   330/ 1097] train: loss: 0.0004987
[Epoch 91; Iter   360/ 1097] train: loss: 0.0020268
[Epoch 91; Iter   390/ 1097] train: loss: 0.0000286
[Epoch 91; Iter   420/ 1097] train: loss: 0.0002875
[Epoch 91; Iter   450/ 1097] train: loss: 0.0001878
[Epoch 91; Iter   480/ 1097] train: loss: 0.0000135
[Epoch 91; Iter   510/ 1097] train: loss: 0.0001596
[Epoch 91; Iter   540/ 1097] train: loss: 0.0000022
[Epoch 91; Iter   570/ 1097] train: loss: 0.0000510
[Epoch 91; Iter   600/ 1097] train: loss: 0.0000250
[Epoch 91; Iter   630/ 1097] train: loss: 0.0108439
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000118
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000064
[Epoch 91; Iter   720/ 1097] train: loss: 0.0154825
[Epoch 91; Iter   750/ 1097] train: loss: 0.0004286
[Epoch 91; Iter   780/ 1097] train: loss: 0.0001838
[Epoch 91; Iter   810/ 1097] train: loss: 0.0000182
[Epoch 91; Iter   840/ 1097] train: loss: 0.0000940
[Epoch 91; Iter   870/ 1097] train: loss: 0.0005673
[Epoch 91; Iter   900/ 1097] train: loss: 0.0001352
[Epoch 91; Iter   930/ 1097] train: loss: 0.0000846
[Epoch 91; Iter   960/ 1097] train: loss: 0.0215132
[Epoch 91; Iter   990/ 1097] train: loss: 0.0001250
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0000117
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0005265
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0000031
[Epoch 91] ogbg-molhiv: 0.789107 val loss: 0.424756
[Epoch 91] ogbg-molhiv: 0.802993 test loss: 0.335780
[Epoch 92; Iter    13/ 1097] train: loss: 0.0006263
[Epoch 92; Iter    43/ 1097] train: loss: 0.0000114
[Epoch 92; Iter    73/ 1097] train: loss: 0.0000202
[Epoch 92; Iter   103/ 1097] train: loss: 0.0002080
[Epoch 92; Iter   133/ 1097] train: loss: 0.0000014
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000532
[Epoch 92; Iter   193/ 1097] train: loss: 0.0000241
[Epoch 92; Iter   223/ 1097] train: loss: 0.0000574
[Epoch 92; Iter   253/ 1097] train: loss: 0.0004107
[Epoch 92; Iter   283/ 1097] train: loss: 0.0000008
[Epoch 92; Iter   313/ 1097] train: loss: 0.0002357
[Epoch 92; Iter   343/ 1097] train: loss: 0.0000297
[Epoch 92; Iter   373/ 1097] train: loss: 0.0007110
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000059
[Epoch 92; Iter   433/ 1097] train: loss: 0.0000270
[Epoch 92; Iter   463/ 1097] train: loss: 0.0023569
[Epoch 92; Iter   493/ 1097] train: loss: 0.0000565
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000138
[Epoch 92; Iter   553/ 1097] train: loss: 0.0000719
[Epoch 92; Iter   583/ 1097] train: loss: 0.0000223
[Epoch 92; Iter   613/ 1097] train: loss: 0.0012964
[Epoch 92; Iter   643/ 1097] train: loss: 0.0001795
[Epoch 92; Iter   673/ 1097] train: loss: 0.0005941
[Epoch 92; Iter   703/ 1097] train: loss: 0.0000063
[Epoch 92; Iter   733/ 1097] train: loss: 0.0001233
[Epoch 92; Iter   763/ 1097] train: loss: 0.0002041
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000343
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000106
[Epoch 92; Iter   853/ 1097] train: loss: 0.0002184
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000265
[Epoch 92; Iter   913/ 1097] train: loss: 0.0000031
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000780
[Epoch 92; Iter   973/ 1097] train: loss: 0.0002010
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0002026
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0002473
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0001057
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000170
[Epoch 92] ogbg-molhiv: 0.779615 val loss: 0.266027
[Epoch 92] ogbg-molhiv: 0.781914 test loss: 0.366559
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000070
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000136
[Epoch 93; Iter    86/ 1097] train: loss: 0.0137948
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000769
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000356
[Epoch 93; Iter   176/ 1097] train: loss: 0.0000236
[Epoch 93; Iter   206/ 1097] train: loss: 0.0002336
[Epoch 93; Iter   236/ 1097] train: loss: 0.0001084
[Epoch 93; Iter   266/ 1097] train: loss: 0.0000062
[Epoch 93; Iter   296/ 1097] train: loss: 0.0000358
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000625
[Epoch 93; Iter   356/ 1097] train: loss: 0.0001707
[Epoch 93; Iter   386/ 1097] train: loss: 0.0018718
[Epoch 93; Iter   416/ 1097] train: loss: 0.0000644
[Epoch 93; Iter   446/ 1097] train: loss: 0.0000624
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000008
[Epoch 93; Iter   506/ 1097] train: loss: 0.0001032
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000079
[Epoch 93; Iter   566/ 1097] train: loss: 0.0000327
[Epoch 89; Iter   514/ 1097] train: loss: 0.0001106
[Epoch 89; Iter   544/ 1097] train: loss: 0.0160793
[Epoch 89; Iter   574/ 1097] train: loss: 0.0000037
[Epoch 89; Iter   604/ 1097] train: loss: 0.0001977
[Epoch 89; Iter   634/ 1097] train: loss: 0.0000440
[Epoch 89; Iter   664/ 1097] train: loss: 0.0106949
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000161
[Epoch 89; Iter   724/ 1097] train: loss: 0.0008382
[Epoch 89; Iter   754/ 1097] train: loss: 0.0000038
[Epoch 89; Iter   784/ 1097] train: loss: 0.0002163
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000998
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000763
[Epoch 89; Iter   874/ 1097] train: loss: 0.0002188
[Epoch 89; Iter   904/ 1097] train: loss: 0.0000074
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000341
[Epoch 89; Iter   964/ 1097] train: loss: 0.0001292
[Epoch 89; Iter   994/ 1097] train: loss: 0.0000858
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0002038
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0000156
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0000791
[Epoch 89] ogbg-molhiv: 0.716056 val loss: 2.648061
[Epoch 89] ogbg-molhiv: 0.600915 test loss: 3.030584
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000010
[Epoch 90; Iter    47/ 1097] train: loss: 0.0022668
[Epoch 90; Iter    77/ 1097] train: loss: 0.0003401
[Epoch 90; Iter   107/ 1097] train: loss: 0.0000011
[Epoch 90; Iter   137/ 1097] train: loss: 0.0000507
[Epoch 90; Iter   167/ 1097] train: loss: 0.0000168
[Epoch 90; Iter   197/ 1097] train: loss: 0.0000056
[Epoch 90; Iter   227/ 1097] train: loss: 0.0000049
[Epoch 90; Iter   257/ 1097] train: loss: 0.0000037
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000097
[Epoch 90; Iter   317/ 1097] train: loss: 0.0003685
[Epoch 90; Iter   347/ 1097] train: loss: 0.0000014
[Epoch 90; Iter   377/ 1097] train: loss: 0.0001143
[Epoch 90; Iter   407/ 1097] train: loss: 0.0000123
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000022
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000586
[Epoch 90; Iter   497/ 1097] train: loss: 0.0002295
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000003
[Epoch 90; Iter   557/ 1097] train: loss: 0.0012384
[Epoch 90; Iter   587/ 1097] train: loss: 0.0000003
[Epoch 90; Iter   617/ 1097] train: loss: 0.0000382
[Epoch 90; Iter   647/ 1097] train: loss: 0.0000925
[Epoch 90; Iter   677/ 1097] train: loss: 0.0000704
[Epoch 90; Iter   707/ 1097] train: loss: 0.0000002
[Epoch 90; Iter   737/ 1097] train: loss: 0.0010487
[Epoch 90; Iter   767/ 1097] train: loss: 0.0047766
[Epoch 90; Iter   797/ 1097] train: loss: 0.0000256
[Epoch 90; Iter   827/ 1097] train: loss: 0.0001364
[Epoch 90; Iter   857/ 1097] train: loss: 0.0000017
[Epoch 90; Iter   887/ 1097] train: loss: 0.0001140
[Epoch 90; Iter   917/ 1097] train: loss: 0.0000059
[Epoch 90; Iter   947/ 1097] train: loss: 0.0000037
[Epoch 90; Iter   977/ 1097] train: loss: 0.0002471
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0000143
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0000147
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0015259
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0000008
[Epoch 90] ogbg-molhiv: 0.671354 val loss: 2.607439
[Epoch 90] ogbg-molhiv: 0.608028 test loss: 3.210202
[Epoch 91; Iter    30/ 1097] train: loss: 0.0000337
[Epoch 91; Iter    60/ 1097] train: loss: 0.0000535
[Epoch 91; Iter    90/ 1097] train: loss: 0.0004371
[Epoch 91; Iter   120/ 1097] train: loss: 0.0000357
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000130
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000327
[Epoch 91; Iter   210/ 1097] train: loss: 0.0009036
[Epoch 91; Iter   240/ 1097] train: loss: 0.0000137
[Epoch 91; Iter   270/ 1097] train: loss: 0.0000197
[Epoch 91; Iter   300/ 1097] train: loss: 0.0000480
[Epoch 91; Iter   330/ 1097] train: loss: 0.0000008
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000016
[Epoch 91; Iter   390/ 1097] train: loss: 0.0000811
[Epoch 91; Iter   420/ 1097] train: loss: 0.0000006
[Epoch 91; Iter   450/ 1097] train: loss: 0.0000014
[Epoch 91; Iter   480/ 1097] train: loss: 0.0000039
[Epoch 91; Iter   510/ 1097] train: loss: 0.0029501
[Epoch 91; Iter   540/ 1097] train: loss: 0.0004994
[Epoch 91; Iter   570/ 1097] train: loss: 0.0000625
[Epoch 91; Iter   600/ 1097] train: loss: 0.0000834
[Epoch 91; Iter   630/ 1097] train: loss: 0.0110821
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000539
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000046
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000201
[Epoch 91; Iter   750/ 1097] train: loss: 0.0001839
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000072
[Epoch 91; Iter   810/ 1097] train: loss: 0.0001018
[Epoch 91; Iter   840/ 1097] train: loss: 0.0000192
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000200
[Epoch 91; Iter   900/ 1097] train: loss: 0.0000520
[Epoch 91; Iter   930/ 1097] train: loss: 0.0000364
[Epoch 91; Iter   960/ 1097] train: loss: 0.0000300
[Epoch 91; Iter   990/ 1097] train: loss: 0.0000976
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0000381
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0000008
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0000101
[Epoch 91] ogbg-molhiv: 0.675675 val loss: 2.060179
[Epoch 91] ogbg-molhiv: 0.595268 test loss: 2.694546
[Epoch 92; Iter    13/ 1097] train: loss: 0.0000331
[Epoch 92; Iter    43/ 1097] train: loss: 0.0000213
[Epoch 92; Iter    73/ 1097] train: loss: 0.0000012
[Epoch 92; Iter   103/ 1097] train: loss: 0.0000089
[Epoch 92; Iter   133/ 1097] train: loss: 0.0000029
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000009
[Epoch 92; Iter   193/ 1097] train: loss: 0.0000274
[Epoch 92; Iter   223/ 1097] train: loss: 0.0000043
[Epoch 92; Iter   253/ 1097] train: loss: 0.0000091
[Epoch 92; Iter   283/ 1097] train: loss: 0.0000054
[Epoch 92; Iter   313/ 1097] train: loss: 0.0000016
[Epoch 92; Iter   343/ 1097] train: loss: 0.0000207
[Epoch 92; Iter   373/ 1097] train: loss: 0.0000338
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000095
[Epoch 92; Iter   433/ 1097] train: loss: 0.0000026
[Epoch 92; Iter   463/ 1097] train: loss: 0.0023550
[Epoch 92; Iter   493/ 1097] train: loss: 0.0000067
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000036
[Epoch 92; Iter   553/ 1097] train: loss: 0.0011629
[Epoch 92; Iter   583/ 1097] train: loss: 0.0000037
[Epoch 92; Iter   613/ 1097] train: loss: 0.0002047
[Epoch 92; Iter   643/ 1097] train: loss: 0.0000159
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000085
[Epoch 92; Iter   703/ 1097] train: loss: 0.0043400
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000186
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000892
[Epoch 92; Iter   793/ 1097] train: loss: 0.0011179
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000232
[Epoch 92; Iter   853/ 1097] train: loss: 0.0000187
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000378
[Epoch 92; Iter   913/ 1097] train: loss: 0.0000295
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000028
[Epoch 92; Iter   973/ 1097] train: loss: 0.0002757
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0001124
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0000899
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000008
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000015
[Epoch 92] ogbg-molhiv: 0.684576 val loss: 2.206215
[Epoch 92] ogbg-molhiv: 0.577732 test loss: 2.867421
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000345
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000024
[Epoch 93; Iter    86/ 1097] train: loss: 0.0001012
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000435
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000286
[Epoch 93; Iter   176/ 1097] train: loss: 0.0011342
[Epoch 93; Iter   206/ 1097] train: loss: 0.0002245
[Epoch 93; Iter   236/ 1097] train: loss: 0.0000055
[Epoch 93; Iter   266/ 1097] train: loss: 0.0002930
[Epoch 93; Iter   296/ 1097] train: loss: 0.0000018
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000001
[Epoch 93; Iter   356/ 1097] train: loss: 0.0000044
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000010
[Epoch 93; Iter   416/ 1097] train: loss: 0.0000031
[Epoch 93; Iter   446/ 1097] train: loss: 0.0001264
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000895
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000991
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000009
[Epoch 93; Iter   566/ 1097] train: loss: 0.0000637
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000492
[Epoch 89; Iter   544/ 1097] train: loss: 0.0016140
[Epoch 89; Iter   574/ 1097] train: loss: 0.0003049
[Epoch 89; Iter   604/ 1097] train: loss: 0.0000447
[Epoch 89; Iter   634/ 1097] train: loss: 0.0005021
[Epoch 89; Iter   664/ 1097] train: loss: 0.0000439
[Epoch 89; Iter   694/ 1097] train: loss: 0.0011032
[Epoch 89; Iter   724/ 1097] train: loss: 0.0000342
[Epoch 89; Iter   754/ 1097] train: loss: 0.0188515
[Epoch 89; Iter   784/ 1097] train: loss: 0.0022729
[Epoch 89; Iter   814/ 1097] train: loss: 0.0010591
[Epoch 89; Iter   844/ 1097] train: loss: 0.0004150
[Epoch 89; Iter   874/ 1097] train: loss: 0.0002809
[Epoch 89; Iter   904/ 1097] train: loss: 0.0006479
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000146
[Epoch 89; Iter   964/ 1097] train: loss: 0.0000809
[Epoch 89; Iter   994/ 1097] train: loss: 0.0012995
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0387908
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0000467
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0302869
[Epoch 89] ogbg-molhiv: 0.647704 val loss: 140.954775
[Epoch 89] ogbg-molhiv: 0.586466 test loss: 128.385170
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000163
[Epoch 90; Iter    47/ 1097] train: loss: 0.0096666
[Epoch 90; Iter    77/ 1097] train: loss: 0.0052993
[Epoch 90; Iter   107/ 1097] train: loss: 0.0009689
[Epoch 90; Iter   137/ 1097] train: loss: 0.0007079
[Epoch 90; Iter   167/ 1097] train: loss: 0.0032004
[Epoch 90; Iter   197/ 1097] train: loss: 0.0001735
[Epoch 90; Iter   227/ 1097] train: loss: 0.0050566
[Epoch 90; Iter   257/ 1097] train: loss: 0.0002049
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000128
[Epoch 90; Iter   317/ 1097] train: loss: 0.0007104
[Epoch 90; Iter   347/ 1097] train: loss: 0.0000347
[Epoch 90; Iter   377/ 1097] train: loss: 0.0139673
[Epoch 90; Iter   407/ 1097] train: loss: 0.0019099
[Epoch 90; Iter   437/ 1097] train: loss: 0.0001699
[Epoch 90; Iter   467/ 1097] train: loss: 0.0152376
[Epoch 90; Iter   497/ 1097] train: loss: 0.0001413
[Epoch 90; Iter   527/ 1097] train: loss: 0.0012371
[Epoch 90; Iter   557/ 1097] train: loss: 0.0031556
[Epoch 90; Iter   587/ 1097] train: loss: 0.1111452
[Epoch 90; Iter   617/ 1097] train: loss: 0.0002909
[Epoch 90; Iter   647/ 1097] train: loss: 0.0033783
[Epoch 90; Iter   677/ 1097] train: loss: 0.0000520
[Epoch 90; Iter   707/ 1097] train: loss: 0.0058421
[Epoch 90; Iter   737/ 1097] train: loss: 0.0001854
[Epoch 90; Iter   767/ 1097] train: loss: 0.0000434
[Epoch 90; Iter   797/ 1097] train: loss: 0.0005578
[Epoch 90; Iter   827/ 1097] train: loss: 0.0004688
[Epoch 90; Iter   857/ 1097] train: loss: 0.0013646
[Epoch 90; Iter   887/ 1097] train: loss: 0.0002716
[Epoch 90; Iter   917/ 1097] train: loss: 0.0000348
[Epoch 90; Iter   947/ 1097] train: loss: 0.0001265
[Epoch 90; Iter   977/ 1097] train: loss: 0.0007526
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0030373
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0000142
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0008707
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0000208
[Epoch 90] ogbg-molhiv: 0.688373 val loss: 95.023796
[Epoch 90] ogbg-molhiv: 0.594361 test loss: 85.998634
[Epoch 91; Iter    30/ 1097] train: loss: 0.0001665
[Epoch 91; Iter    60/ 1097] train: loss: 0.0928869
[Epoch 91; Iter    90/ 1097] train: loss: 0.0432948
[Epoch 91; Iter   120/ 1097] train: loss: 0.0003345
[Epoch 91; Iter   150/ 1097] train: loss: 0.0003373
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000610
[Epoch 91; Iter   210/ 1097] train: loss: 0.0004630
[Epoch 91; Iter   240/ 1097] train: loss: 0.0310861
[Epoch 91; Iter   270/ 1097] train: loss: 0.0001135
[Epoch 91; Iter   300/ 1097] train: loss: 0.0000391
[Epoch 91; Iter   330/ 1097] train: loss: 0.0674203
[Epoch 91; Iter   360/ 1097] train: loss: 0.0065859
[Epoch 91; Iter   390/ 1097] train: loss: 0.0368596
[Epoch 91; Iter   420/ 1097] train: loss: 0.0001929
[Epoch 91; Iter   450/ 1097] train: loss: 0.0000817
[Epoch 91; Iter   480/ 1097] train: loss: 0.0059858
[Epoch 91; Iter   510/ 1097] train: loss: 0.0003312
[Epoch 91; Iter   540/ 1097] train: loss: 0.0000368
[Epoch 91; Iter   570/ 1097] train: loss: 0.0102945
[Epoch 91; Iter   600/ 1097] train: loss: 0.0023253
[Epoch 91; Iter   630/ 1097] train: loss: 0.0031109
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000374
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000565
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000506
[Epoch 91; Iter   750/ 1097] train: loss: 0.0000048
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000146
[Epoch 91; Iter   810/ 1097] train: loss: 0.0014870
[Epoch 91; Iter   840/ 1097] train: loss: 0.0008068
[Epoch 91; Iter   870/ 1097] train: loss: 0.0003241
[Epoch 91; Iter   900/ 1097] train: loss: 0.0000357
[Epoch 91; Iter   930/ 1097] train: loss: 0.0001847
[Epoch 91; Iter   960/ 1097] train: loss: 0.0000285
[Epoch 91; Iter   990/ 1097] train: loss: 0.0011555
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0001565
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0001740
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0000544
[Epoch 91] ogbg-molhiv: 0.690194 val loss: 97.629170
[Epoch 91] ogbg-molhiv: 0.594774 test loss: 83.874038
[Epoch 92; Iter    13/ 1097] train: loss: 0.0005034
[Epoch 92; Iter    43/ 1097] train: loss: 0.0000079
[Epoch 92; Iter    73/ 1097] train: loss: 0.0019603
[Epoch 92; Iter   103/ 1097] train: loss: 0.0064404
[Epoch 92; Iter   133/ 1097] train: loss: 0.0001239
[Epoch 92; Iter   163/ 1097] train: loss: 0.0001224
[Epoch 92; Iter   193/ 1097] train: loss: 0.0001168
[Epoch 92; Iter   223/ 1097] train: loss: 0.0000765
[Epoch 92; Iter   253/ 1097] train: loss: 0.0005656
[Epoch 92; Iter   283/ 1097] train: loss: 0.0002988
[Epoch 92; Iter   313/ 1097] train: loss: 0.0001212
[Epoch 92; Iter   343/ 1097] train: loss: 0.0013900
[Epoch 92; Iter   373/ 1097] train: loss: 0.0010338
[Epoch 92; Iter   403/ 1097] train: loss: 0.0019886
[Epoch 92; Iter   433/ 1097] train: loss: 0.0000144
[Epoch 92; Iter   463/ 1097] train: loss: 0.0039844
[Epoch 92; Iter   493/ 1097] train: loss: 0.0002462
[Epoch 92; Iter   523/ 1097] train: loss: 0.0000032
[Epoch 92; Iter   553/ 1097] train: loss: 0.0001580
[Epoch 92; Iter   583/ 1097] train: loss: 0.0095280
[Epoch 92; Iter   613/ 1097] train: loss: 0.0003437
[Epoch 92; Iter   643/ 1097] train: loss: 0.0015775
[Epoch 92; Iter   673/ 1097] train: loss: 0.0033704
[Epoch 92; Iter   703/ 1097] train: loss: 0.0040589
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000268
[Epoch 92; Iter   763/ 1097] train: loss: 0.0000054
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000223
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000982
[Epoch 92; Iter   853/ 1097] train: loss: 0.0000820
[Epoch 92; Iter   883/ 1097] train: loss: 0.0001061
[Epoch 92; Iter   913/ 1097] train: loss: 0.0001032
[Epoch 92; Iter   943/ 1097] train: loss: 0.0001152
[Epoch 92; Iter   973/ 1097] train: loss: 0.0000529
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0001269
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0004031
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000432
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0003176
[Epoch 92] ogbg-molhiv: 0.708765 val loss: 51.520666
[Epoch 92] ogbg-molhiv: 0.590840 test loss: 42.649510
[Epoch 93; Iter    26/ 1097] train: loss: 0.0002846
[Epoch 93; Iter    56/ 1097] train: loss: 0.0108175
[Epoch 93; Iter    86/ 1097] train: loss: 0.0000054
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000518
[Epoch 93; Iter   146/ 1097] train: loss: 0.0019363
[Epoch 93; Iter   176/ 1097] train: loss: 0.0002650
[Epoch 93; Iter   206/ 1097] train: loss: 0.0000622
[Epoch 93; Iter   236/ 1097] train: loss: 0.0001197
[Epoch 93; Iter   266/ 1097] train: loss: 0.0001042
[Epoch 93; Iter   296/ 1097] train: loss: 0.0072364
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000109
[Epoch 93; Iter   356/ 1097] train: loss: 0.0001827
[Epoch 93; Iter   386/ 1097] train: loss: 0.0000341
[Epoch 93; Iter   416/ 1097] train: loss: 0.0779832
[Epoch 93; Iter   446/ 1097] train: loss: 0.0126990
[Epoch 93; Iter   476/ 1097] train: loss: 0.0001401
[Epoch 93; Iter   506/ 1097] train: loss: 0.0006370
[Epoch 93; Iter   536/ 1097] train: loss: 0.0090436
[Epoch 93; Iter   566/ 1097] train: loss: 0.0021522
[Epoch 89; Iter   514/ 1097] train: loss: 0.0000111
[Epoch 89; Iter   544/ 1097] train: loss: 0.0001944
[Epoch 89; Iter   574/ 1097] train: loss: 0.0010633
[Epoch 89; Iter   604/ 1097] train: loss: 0.0000474
[Epoch 89; Iter   634/ 1097] train: loss: 0.0000012
[Epoch 89; Iter   664/ 1097] train: loss: 0.0001001
[Epoch 89; Iter   694/ 1097] train: loss: 0.0000221
[Epoch 89; Iter   724/ 1097] train: loss: 0.0008332
[Epoch 89; Iter   754/ 1097] train: loss: 0.0001489
[Epoch 89; Iter   784/ 1097] train: loss: 0.0398066
[Epoch 89; Iter   814/ 1097] train: loss: 0.0000675
[Epoch 89; Iter   844/ 1097] train: loss: 0.0000058
[Epoch 89; Iter   874/ 1097] train: loss: 0.0001165
[Epoch 89; Iter   904/ 1097] train: loss: 0.0000071
[Epoch 89; Iter   934/ 1097] train: loss: 0.0000164
[Epoch 89; Iter   964/ 1097] train: loss: 0.0000253
[Epoch 89; Iter   994/ 1097] train: loss: 0.0001689
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0000121
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0001699
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0000186
[Epoch 89] ogbg-molhiv: 0.736175 val loss: 0.932631
[Epoch 89] ogbg-molhiv: 0.738363 test loss: 2.583648
[Epoch 90; Iter    17/ 1097] train: loss: 0.0000133
[Epoch 90; Iter    47/ 1097] train: loss: 0.0000337
[Epoch 90; Iter    77/ 1097] train: loss: 0.0000101
[Epoch 90; Iter   107/ 1097] train: loss: 0.0002970
[Epoch 90; Iter   137/ 1097] train: loss: 0.0000302
[Epoch 90; Iter   167/ 1097] train: loss: 0.0001261
[Epoch 90; Iter   197/ 1097] train: loss: 0.0001810
[Epoch 90; Iter   227/ 1097] train: loss: 0.0001335
[Epoch 90; Iter   257/ 1097] train: loss: 0.0000210
[Epoch 90; Iter   287/ 1097] train: loss: 0.0000174
[Epoch 90; Iter   317/ 1097] train: loss: 0.0000035
[Epoch 90; Iter   347/ 1097] train: loss: 0.0002421
[Epoch 90; Iter   377/ 1097] train: loss: 0.0000141
[Epoch 90; Iter   407/ 1097] train: loss: 0.0000200
[Epoch 90; Iter   437/ 1097] train: loss: 0.0000488
[Epoch 90; Iter   467/ 1097] train: loss: 0.0000669
[Epoch 90; Iter   497/ 1097] train: loss: 0.0000104
[Epoch 90; Iter   527/ 1097] train: loss: 0.0000433
[Epoch 90; Iter   557/ 1097] train: loss: 0.0140933
[Epoch 90; Iter   587/ 1097] train: loss: 0.0000088
[Epoch 90; Iter   617/ 1097] train: loss: 0.0047644
[Epoch 90; Iter   647/ 1097] train: loss: 0.0022693
[Epoch 90; Iter   677/ 1097] train: loss: 0.0094302
[Epoch 90; Iter   707/ 1097] train: loss: 0.0009069
[Epoch 90; Iter   737/ 1097] train: loss: 0.0000041
[Epoch 90; Iter   767/ 1097] train: loss: 0.0008681
[Epoch 90; Iter   797/ 1097] train: loss: 0.0154736
[Epoch 90; Iter   827/ 1097] train: loss: 0.0066113
[Epoch 90; Iter   857/ 1097] train: loss: 0.0000211
[Epoch 90; Iter   887/ 1097] train: loss: 0.0003892
[Epoch 90; Iter   917/ 1097] train: loss: 0.0000084
[Epoch 90; Iter   947/ 1097] train: loss: 0.0000200
[Epoch 90; Iter   977/ 1097] train: loss: 0.0000200
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0000033
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0000149
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0000547
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0000341
[Epoch 90] ogbg-molhiv: 0.744409 val loss: 0.352336
[Epoch 90] ogbg-molhiv: 0.739997 test loss: 0.483437
[Epoch 91; Iter    30/ 1097] train: loss: 0.0000435
[Epoch 91; Iter    60/ 1097] train: loss: 0.0000248
[Epoch 91; Iter    90/ 1097] train: loss: 0.0000022
[Epoch 91; Iter   120/ 1097] train: loss: 0.0000795
[Epoch 91; Iter   150/ 1097] train: loss: 0.0000928
[Epoch 91; Iter   180/ 1097] train: loss: 0.0000049
[Epoch 91; Iter   210/ 1097] train: loss: 0.0001968
[Epoch 91; Iter   240/ 1097] train: loss: 0.0001705
[Epoch 91; Iter   270/ 1097] train: loss: 0.0001457
[Epoch 91; Iter   300/ 1097] train: loss: 0.0004665
[Epoch 91; Iter   330/ 1097] train: loss: 0.0005447
[Epoch 91; Iter   360/ 1097] train: loss: 0.0000010
[Epoch 91; Iter   390/ 1097] train: loss: 0.0001189
[Epoch 91; Iter   420/ 1097] train: loss: 0.0001183
[Epoch 91; Iter   450/ 1097] train: loss: 0.0448876
[Epoch 91; Iter   480/ 1097] train: loss: 0.0000546
[Epoch 91; Iter   510/ 1097] train: loss: 0.0001561
[Epoch 91; Iter   540/ 1097] train: loss: 0.0000715
[Epoch 91; Iter   570/ 1097] train: loss: 0.0000369
[Epoch 91; Iter   600/ 1097] train: loss: 0.0002774
[Epoch 91; Iter   630/ 1097] train: loss: 0.0022954
[Epoch 91; Iter   660/ 1097] train: loss: 0.0000148
[Epoch 91; Iter   690/ 1097] train: loss: 0.0000061
[Epoch 91; Iter   720/ 1097] train: loss: 0.0000629
[Epoch 91; Iter   750/ 1097] train: loss: 0.0023396
[Epoch 91; Iter   780/ 1097] train: loss: 0.0000079
[Epoch 91; Iter   810/ 1097] train: loss: 0.0000168
[Epoch 91; Iter   840/ 1097] train: loss: 0.0000747
[Epoch 91; Iter   870/ 1097] train: loss: 0.0000071
[Epoch 91; Iter   900/ 1097] train: loss: 0.0000146
[Epoch 91; Iter   930/ 1097] train: loss: 0.0000153
[Epoch 91; Iter   960/ 1097] train: loss: 0.0095372
[Epoch 91; Iter   990/ 1097] train: loss: 0.0004178
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0002468
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0001081
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0000501
[Epoch 91] ogbg-molhiv: 0.761210 val loss: 1.576731
[Epoch 91] ogbg-molhiv: 0.737863 test loss: 3.110951
[Epoch 92; Iter    13/ 1097] train: loss: 0.0000830
[Epoch 92; Iter    43/ 1097] train: loss: 0.0001811
[Epoch 92; Iter    73/ 1097] train: loss: 0.0000182
[Epoch 92; Iter   103/ 1097] train: loss: 0.0001243
[Epoch 92; Iter   133/ 1097] train: loss: 0.0020817
[Epoch 92; Iter   163/ 1097] train: loss: 0.0000037
[Epoch 92; Iter   193/ 1097] train: loss: 0.0002212
[Epoch 92; Iter   223/ 1097] train: loss: 0.0000352
[Epoch 92; Iter   253/ 1097] train: loss: 0.0000474
[Epoch 92; Iter   283/ 1097] train: loss: 0.0019225
[Epoch 92; Iter   313/ 1097] train: loss: 0.0000195
[Epoch 92; Iter   343/ 1097] train: loss: 0.0001101
[Epoch 92; Iter   373/ 1097] train: loss: 0.0000040
[Epoch 92; Iter   403/ 1097] train: loss: 0.0000236
[Epoch 92; Iter   433/ 1097] train: loss: 0.0000069
[Epoch 92; Iter   463/ 1097] train: loss: 0.0005107
[Epoch 92; Iter   493/ 1097] train: loss: 0.0517914
[Epoch 92; Iter   523/ 1097] train: loss: 0.0008425
[Epoch 92; Iter   553/ 1097] train: loss: 0.0000423
[Epoch 92; Iter   583/ 1097] train: loss: 0.0000033
[Epoch 92; Iter   613/ 1097] train: loss: 0.0021812
[Epoch 92; Iter   643/ 1097] train: loss: 0.0004964
[Epoch 92; Iter   673/ 1097] train: loss: 0.0000020
[Epoch 92; Iter   703/ 1097] train: loss: 0.0000892
[Epoch 92; Iter   733/ 1097] train: loss: 0.0000513
[Epoch 92; Iter   763/ 1097] train: loss: 0.0018636
[Epoch 92; Iter   793/ 1097] train: loss: 0.0000318
[Epoch 92; Iter   823/ 1097] train: loss: 0.0000341
[Epoch 92; Iter   853/ 1097] train: loss: 0.0000168
[Epoch 92; Iter   883/ 1097] train: loss: 0.0000024
[Epoch 92; Iter   913/ 1097] train: loss: 0.0002607
[Epoch 92; Iter   943/ 1097] train: loss: 0.0000044
[Epoch 92; Iter   973/ 1097] train: loss: 0.0000163
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0000156
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0000065
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0000321
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0000116
[Epoch 92] ogbg-molhiv: 0.736708 val loss: 1.074259
[Epoch 92] ogbg-molhiv: 0.727471 test loss: 2.960898
[Epoch 93; Iter    26/ 1097] train: loss: 0.0000281
[Epoch 93; Iter    56/ 1097] train: loss: 0.0000186
[Epoch 93; Iter    86/ 1097] train: loss: 0.0000167
[Epoch 93; Iter   116/ 1097] train: loss: 0.0000930
[Epoch 93; Iter   146/ 1097] train: loss: 0.0000382
[Epoch 93; Iter   176/ 1097] train: loss: 0.0000097
[Epoch 93; Iter   206/ 1097] train: loss: 0.0000570
[Epoch 93; Iter   236/ 1097] train: loss: 0.0000308
[Epoch 93; Iter   266/ 1097] train: loss: 0.0001085
[Epoch 93; Iter   296/ 1097] train: loss: 0.0000017
[Epoch 93; Iter   326/ 1097] train: loss: 0.0000858
[Epoch 93; Iter   356/ 1097] train: loss: 0.0000101
[Epoch 93; Iter   386/ 1097] train: loss: 0.0002562
[Epoch 93; Iter   416/ 1097] train: loss: 0.0002568
[Epoch 93; Iter   446/ 1097] train: loss: 0.0000525
[Epoch 93; Iter   476/ 1097] train: loss: 0.0000229
[Epoch 93; Iter   506/ 1097] train: loss: 0.0000132
[Epoch 93; Iter   536/ 1097] train: loss: 0.0000048
[Epoch 93; Iter   566/ 1097] train: loss: 0.0000571
[Epoch 73; Iter   186/ 1097] train: loss: 0.0130581
[Epoch 73; Iter   216/ 1097] train: loss: 0.0095856
[Epoch 73; Iter   246/ 1097] train: loss: 0.0327065
[Epoch 73; Iter   276/ 1097] train: loss: 0.0683799
[Epoch 73; Iter   306/ 1097] train: loss: 0.0190312
[Epoch 73; Iter   336/ 1097] train: loss: 0.0164276
[Epoch 73; Iter   366/ 1097] train: loss: 0.0468223
[Epoch 73; Iter   396/ 1097] train: loss: 0.0493283
[Epoch 73; Iter   426/ 1097] train: loss: 0.0051920
[Epoch 73; Iter   456/ 1097] train: loss: 0.0348820
[Epoch 73; Iter   486/ 1097] train: loss: 0.1990836
[Epoch 73; Iter   516/ 1097] train: loss: 0.0082428
[Epoch 73; Iter   546/ 1097] train: loss: 0.0465671
[Epoch 73; Iter   576/ 1097] train: loss: 0.0215777
[Epoch 73; Iter   606/ 1097] train: loss: 0.0129661
[Epoch 73; Iter   636/ 1097] train: loss: 0.0224361
[Epoch 73; Iter   666/ 1097] train: loss: 0.0120334
[Epoch 73; Iter   696/ 1097] train: loss: 0.0072026
[Epoch 73; Iter   726/ 1097] train: loss: 0.0051700
[Epoch 73; Iter   756/ 1097] train: loss: 0.0217993
[Epoch 73; Iter   786/ 1097] train: loss: 0.0289972
[Epoch 73; Iter   816/ 1097] train: loss: 0.0242776
[Epoch 73; Iter   846/ 1097] train: loss: 0.0013218
[Epoch 73; Iter   876/ 1097] train: loss: 0.0047486
[Epoch 73; Iter   906/ 1097] train: loss: 0.0991570
[Epoch 73; Iter   936/ 1097] train: loss: 0.0043507
[Epoch 73; Iter   966/ 1097] train: loss: 0.0141667
[Epoch 73; Iter   996/ 1097] train: loss: 0.0114856
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0253251
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0227772
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0319970
[Epoch 73] ogbg-molhiv: 0.825443 val loss: 0.105370
[Epoch 73] ogbg-molhiv: 0.750957 test loss: 0.198920
[Epoch 74; Iter    19/ 1097] train: loss: 0.0062244
[Epoch 74; Iter    49/ 1097] train: loss: 0.0809588
[Epoch 74; Iter    79/ 1097] train: loss: 0.0465491
[Epoch 74; Iter   109/ 1097] train: loss: 0.0452591
[Epoch 74; Iter   139/ 1097] train: loss: 0.0052966
[Epoch 74; Iter   169/ 1097] train: loss: 0.0045243
[Epoch 74; Iter   199/ 1097] train: loss: 0.0022641
[Epoch 74; Iter   229/ 1097] train: loss: 0.0307574
[Epoch 74; Iter   259/ 1097] train: loss: 0.1420714
[Epoch 74; Iter   289/ 1097] train: loss: 0.0052929
[Epoch 74; Iter   319/ 1097] train: loss: 0.0037034
[Epoch 74; Iter   349/ 1097] train: loss: 0.0252657
[Epoch 74; Iter   379/ 1097] train: loss: 0.0323417
[Epoch 74; Iter   409/ 1097] train: loss: 0.1231856
[Epoch 74; Iter   439/ 1097] train: loss: 0.0422314
[Epoch 74; Iter   469/ 1097] train: loss: 0.0024501
[Epoch 74; Iter   499/ 1097] train: loss: 0.0212595
[Epoch 74; Iter   529/ 1097] train: loss: 0.0354630
[Epoch 74; Iter   559/ 1097] train: loss: 0.0038762
[Epoch 74; Iter   589/ 1097] train: loss: 0.0772283
[Epoch 74; Iter   619/ 1097] train: loss: 0.0471802
[Epoch 74; Iter   649/ 1097] train: loss: 0.0062693
[Epoch 74; Iter   679/ 1097] train: loss: 0.1040486
[Epoch 74; Iter   709/ 1097] train: loss: 0.0795631
[Epoch 74; Iter   739/ 1097] train: loss: 0.0543760
[Epoch 74; Iter   769/ 1097] train: loss: 0.1682371
[Epoch 74; Iter   799/ 1097] train: loss: 0.1969997
[Epoch 74; Iter   829/ 1097] train: loss: 0.0267142
[Epoch 74; Iter   859/ 1097] train: loss: 0.0117358
[Epoch 74; Iter   889/ 1097] train: loss: 0.0057563
[Epoch 74; Iter   919/ 1097] train: loss: 0.0024887
[Epoch 74; Iter   949/ 1097] train: loss: 0.0029375
[Epoch 74; Iter   979/ 1097] train: loss: 0.0334028
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0090740
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0123977
[Epoch 74; Iter  1069/ 1097] train: loss: 0.1225200
[Epoch 74] ogbg-molhiv: 0.826110 val loss: 0.111293
[Epoch 74] ogbg-molhiv: 0.754547 test loss: 0.208974
[Epoch 75; Iter     2/ 1097] train: loss: 0.0037217
[Epoch 75; Iter    32/ 1097] train: loss: 0.0020622
[Epoch 75; Iter    62/ 1097] train: loss: 0.0075788
[Epoch 75; Iter    92/ 1097] train: loss: 0.1398468
[Epoch 75; Iter   122/ 1097] train: loss: 0.0021135
[Epoch 75; Iter   152/ 1097] train: loss: 0.0182207
[Epoch 75; Iter   182/ 1097] train: loss: 0.0032008
[Epoch 75; Iter   212/ 1097] train: loss: 0.0351693
[Epoch 75; Iter   242/ 1097] train: loss: 0.0262517
[Epoch 75; Iter   272/ 1097] train: loss: 0.0028574
[Epoch 75; Iter   302/ 1097] train: loss: 0.0128255
[Epoch 75; Iter   332/ 1097] train: loss: 0.0556152
[Epoch 75; Iter   362/ 1097] train: loss: 0.0182567
[Epoch 75; Iter   392/ 1097] train: loss: 0.1034687
[Epoch 75; Iter   422/ 1097] train: loss: 0.0155918
[Epoch 75; Iter   452/ 1097] train: loss: 0.0067320
[Epoch 75; Iter   482/ 1097] train: loss: 0.0064490
[Epoch 75; Iter   512/ 1097] train: loss: 0.0267271
[Epoch 75; Iter   542/ 1097] train: loss: 0.0511588
[Epoch 75; Iter   572/ 1097] train: loss: 0.0688461
[Epoch 75; Iter   602/ 1097] train: loss: 0.0145322
[Epoch 75; Iter   632/ 1097] train: loss: 0.0523265
[Epoch 75; Iter   662/ 1097] train: loss: 0.0432500
[Epoch 75; Iter   692/ 1097] train: loss: 0.0105153
[Epoch 75; Iter   722/ 1097] train: loss: 0.0081154
[Epoch 75; Iter   752/ 1097] train: loss: 0.0026964
[Epoch 75; Iter   782/ 1097] train: loss: 0.0052349
[Epoch 75; Iter   812/ 1097] train: loss: 0.0234225
[Epoch 75; Iter   842/ 1097] train: loss: 0.1514858
[Epoch 75; Iter   872/ 1097] train: loss: 0.0718436
[Epoch 75; Iter   902/ 1097] train: loss: 0.0113770
[Epoch 75; Iter   932/ 1097] train: loss: 0.0083628
[Epoch 75; Iter   962/ 1097] train: loss: 0.0620499
[Epoch 75; Iter   992/ 1097] train: loss: 0.0115264
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0378417
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0182496
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0283068
[Epoch 75] ogbg-molhiv: 0.806257 val loss: 0.114101
[Epoch 75] ogbg-molhiv: 0.753431 test loss: 0.208781
[Epoch 76; Iter    15/ 1097] train: loss: 0.1397006
[Epoch 76; Iter    45/ 1097] train: loss: 0.0030226
[Epoch 76; Iter    75/ 1097] train: loss: 0.0263267
[Epoch 76; Iter   105/ 1097] train: loss: 0.0197467
[Epoch 76; Iter   135/ 1097] train: loss: 0.0084407
[Epoch 76; Iter   165/ 1097] train: loss: 0.0214330
[Epoch 76; Iter   195/ 1097] train: loss: 0.0111078
[Epoch 76; Iter   225/ 1097] train: loss: 0.0372575
[Epoch 76; Iter   255/ 1097] train: loss: 0.0727910
[Epoch 76; Iter   285/ 1097] train: loss: 0.0735980
[Epoch 76; Iter   315/ 1097] train: loss: 0.1074945
[Epoch 76; Iter   345/ 1097] train: loss: 0.0118802
[Epoch 76; Iter   375/ 1097] train: loss: 0.0888101
[Epoch 76; Iter   405/ 1097] train: loss: 0.0379249
[Epoch 76; Iter   435/ 1097] train: loss: 0.0275107
[Epoch 76; Iter   465/ 1097] train: loss: 0.0263554
[Epoch 76; Iter   495/ 1097] train: loss: 0.0078369
[Epoch 76; Iter   525/ 1097] train: loss: 0.0120704
[Epoch 76; Iter   555/ 1097] train: loss: 0.0372216
[Epoch 76; Iter   585/ 1097] train: loss: 0.1532413
[Epoch 76; Iter   615/ 1097] train: loss: 0.0027916
[Epoch 76; Iter   645/ 1097] train: loss: 0.0190449
[Epoch 76; Iter   675/ 1097] train: loss: 0.0189312
[Epoch 76; Iter   705/ 1097] train: loss: 0.0052925
[Epoch 76; Iter   735/ 1097] train: loss: 0.1244503
[Epoch 76; Iter   765/ 1097] train: loss: 0.0536837
[Epoch 76; Iter   795/ 1097] train: loss: 0.0058002
[Epoch 76; Iter   825/ 1097] train: loss: 0.0182565
[Epoch 76; Iter   855/ 1097] train: loss: 0.0204216
[Epoch 76; Iter   885/ 1097] train: loss: 0.0103435
[Epoch 76; Iter   915/ 1097] train: loss: 0.0345587
[Epoch 76; Iter   945/ 1097] train: loss: 0.0089529
[Epoch 76; Iter   975/ 1097] train: loss: 0.0066698
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0384262
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0174369
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0405945
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0578117
[Epoch 76] ogbg-molhiv: 0.795130 val loss: 0.119301
[Epoch 76] ogbg-molhiv: 0.738357 test loss: 0.214236
[Epoch 77; Iter    28/ 1097] train: loss: 0.0478041
[Epoch 77; Iter    58/ 1097] train: loss: 0.0210953
[Epoch 77; Iter    88/ 1097] train: loss: 0.0908166
[Epoch 77; Iter   118/ 1097] train: loss: 0.0129186
[Epoch 77; Iter   148/ 1097] train: loss: 0.0102110
[Epoch 77; Iter   178/ 1097] train: loss: 0.0421634
[Epoch 77; Iter   208/ 1097] train: loss: 0.0631694
[Epoch 77; Iter   238/ 1097] train: loss: 0.1743835
[Epoch 93; Iter   596/ 1097] train: loss: 0.0000865
[Epoch 93; Iter   626/ 1097] train: loss: 0.0003139
[Epoch 93; Iter   656/ 1097] train: loss: 0.0002795
[Epoch 93; Iter   686/ 1097] train: loss: 0.0002071
[Epoch 93; Iter   716/ 1097] train: loss: 0.0015986
[Epoch 93; Iter   746/ 1097] train: loss: 0.0026783
[Epoch 93; Iter   776/ 1097] train: loss: 0.0000757
[Epoch 93; Iter   806/ 1097] train: loss: 0.0001078
[Epoch 93; Iter   836/ 1097] train: loss: 0.0003764
[Epoch 93; Iter   866/ 1097] train: loss: 0.0002478
[Epoch 93; Iter   896/ 1097] train: loss: 0.0001519
[Epoch 93; Iter   926/ 1097] train: loss: 0.0001881
[Epoch 93; Iter   956/ 1097] train: loss: 0.0002794
[Epoch 93; Iter   986/ 1097] train: loss: 0.0002304
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000586
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0005538
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0000414
[Epoch 93] ogbg-molhiv: 0.780065 val loss: 4.453817
[Epoch 93] ogbg-molhiv: 0.729112 test loss: 2.415980
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000086
[Epoch 94; Iter    39/ 1097] train: loss: 0.0002529
[Epoch 94; Iter    69/ 1097] train: loss: 0.0039199
[Epoch 94; Iter    99/ 1097] train: loss: 0.0002409
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000583
[Epoch 94; Iter   159/ 1097] train: loss: 0.0011194
[Epoch 94; Iter   189/ 1097] train: loss: 0.0011485
[Epoch 94; Iter   219/ 1097] train: loss: 0.0000111
[Epoch 94; Iter   249/ 1097] train: loss: 0.0000514
[Epoch 94; Iter   279/ 1097] train: loss: 0.0004414
[Epoch 94; Iter   309/ 1097] train: loss: 0.0000733
[Epoch 94; Iter   339/ 1097] train: loss: 0.0002137
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000927
[Epoch 94; Iter   399/ 1097] train: loss: 0.0002293
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000493
[Epoch 94; Iter   459/ 1097] train: loss: 0.0004658
[Epoch 94; Iter   489/ 1097] train: loss: 0.0028808
[Epoch 94; Iter   519/ 1097] train: loss: 0.0002324
[Epoch 94; Iter   549/ 1097] train: loss: 0.0000202
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000279
[Epoch 94; Iter   609/ 1097] train: loss: 0.0019431
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000920
[Epoch 94; Iter   669/ 1097] train: loss: 0.0001650
[Epoch 94; Iter   699/ 1097] train: loss: 0.0007443
[Epoch 94; Iter   729/ 1097] train: loss: 0.0005096
[Epoch 94; Iter   759/ 1097] train: loss: 0.0072886
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000707
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000160
[Epoch 94; Iter   849/ 1097] train: loss: 0.0002577
[Epoch 94; Iter   879/ 1097] train: loss: 0.0004922
[Epoch 94; Iter   909/ 1097] train: loss: 0.0002711
[Epoch 94; Iter   939/ 1097] train: loss: 0.0001428
[Epoch 94; Iter   969/ 1097] train: loss: 0.0005564
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000232
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0005682
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0003888
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0000684
[Epoch 94] ogbg-molhiv: 0.780910 val loss: 1.465951
[Epoch 94] ogbg-molhiv: 0.722196 test loss: 1.442873
[Epoch 95; Iter    22/ 1097] train: loss: 0.0000261
[Epoch 95; Iter    52/ 1097] train: loss: 0.0007655
[Epoch 95; Iter    82/ 1097] train: loss: 0.0088969
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000773
[Epoch 95; Iter   142/ 1097] train: loss: 0.0001906
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000359
[Epoch 95; Iter   202/ 1097] train: loss: 0.0021564
[Epoch 95; Iter   232/ 1097] train: loss: 0.0006595
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000177
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000150
[Epoch 95; Iter   322/ 1097] train: loss: 0.0009410
[Epoch 95; Iter   352/ 1097] train: loss: 0.0002468
[Epoch 95; Iter   382/ 1097] train: loss: 0.0007612
[Epoch 95; Iter   412/ 1097] train: loss: 0.0006004
[Epoch 95; Iter   442/ 1097] train: loss: 0.0009108
[Epoch 95; Iter   472/ 1097] train: loss: 0.0005116
[Epoch 95; Iter   502/ 1097] train: loss: 0.0006985
[Epoch 95; Iter   532/ 1097] train: loss: 0.0000144
[Epoch 95; Iter   562/ 1097] train: loss: 0.0001665
[Epoch 95; Iter   592/ 1097] train: loss: 0.0005851
[Epoch 95; Iter   622/ 1097] train: loss: 0.0000723
[Epoch 95; Iter   652/ 1097] train: loss: 0.0000463
[Epoch 95; Iter   682/ 1097] train: loss: 0.0002929
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000109
[Epoch 95; Iter   742/ 1097] train: loss: 0.0014726
[Epoch 95; Iter   772/ 1097] train: loss: 0.0001662
[Epoch 95; Iter   802/ 1097] train: loss: 0.0002399
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000511
[Epoch 95; Iter   862/ 1097] train: loss: 0.0000847
[Epoch 95; Iter   892/ 1097] train: loss: 0.0004015
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000608
[Epoch 95; Iter   952/ 1097] train: loss: 0.0007027
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000203
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0001309
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0001614
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0006203
[Epoch 95] ogbg-molhiv: 0.789722 val loss: 0.577067
[Epoch 95] ogbg-molhiv: 0.731196 test loss: 0.662741
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000065
[Epoch 96; Iter    35/ 1097] train: loss: 0.0003985
[Epoch 96; Iter    65/ 1097] train: loss: 0.0002780
[Epoch 96; Iter    95/ 1097] train: loss: 0.0005464
[Epoch 96; Iter   125/ 1097] train: loss: 0.0006341
[Epoch 96; Iter   155/ 1097] train: loss: 0.0000607
[Epoch 96; Iter   185/ 1097] train: loss: 0.0000244
[Epoch 96; Iter   215/ 1097] train: loss: 0.0000925
[Epoch 96; Iter   245/ 1097] train: loss: 0.0000185
[Epoch 96; Iter   275/ 1097] train: loss: 0.0001121
[Epoch 96; Iter   305/ 1097] train: loss: 0.0003910
[Epoch 96; Iter   335/ 1097] train: loss: 0.0001786
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000083
[Epoch 96; Iter   395/ 1097] train: loss: 0.0008999
[Epoch 96; Iter   425/ 1097] train: loss: 0.0009705
[Epoch 96; Iter   455/ 1097] train: loss: 0.0008412
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000516
[Epoch 96; Iter   515/ 1097] train: loss: 0.0000858
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000562
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000103
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000398
[Epoch 96; Iter   635/ 1097] train: loss: 0.0022905
[Epoch 96; Iter   665/ 1097] train: loss: 0.0037631
[Epoch 96; Iter   695/ 1097] train: loss: 0.0009169
[Epoch 96; Iter   725/ 1097] train: loss: 0.0000732
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000210
[Epoch 96; Iter   785/ 1097] train: loss: 0.0002947
[Epoch 96; Iter   815/ 1097] train: loss: 0.0000259
[Epoch 96; Iter   845/ 1097] train: loss: 0.0005120
[Epoch 96; Iter   875/ 1097] train: loss: 0.0005621
[Epoch 96; Iter   905/ 1097] train: loss: 0.0005100
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000321
[Epoch 96; Iter   965/ 1097] train: loss: 0.0010380
[Epoch 96; Iter   995/ 1097] train: loss: 0.0001106
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0002289
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0023734
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0000772
[Epoch 96] ogbg-molhiv: 0.796679 val loss: 0.923620
[Epoch 96] ogbg-molhiv: 0.724883 test loss: 1.047077
[Epoch 97; Iter    18/ 1097] train: loss: 0.0063055
[Epoch 97; Iter    48/ 1097] train: loss: 0.0001607
[Epoch 97; Iter    78/ 1097] train: loss: 0.0002972
[Epoch 97; Iter   108/ 1097] train: loss: 0.0005847
[Epoch 97; Iter   138/ 1097] train: loss: 0.0000119
[Epoch 97; Iter   168/ 1097] train: loss: 0.0337524
[Epoch 97; Iter   198/ 1097] train: loss: 0.0000086
[Epoch 97; Iter   228/ 1097] train: loss: 0.0001331
[Epoch 97; Iter   258/ 1097] train: loss: 0.0001327
[Epoch 97; Iter   288/ 1097] train: loss: 0.0003493
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000017
[Epoch 97; Iter   348/ 1097] train: loss: 0.0002053
[Epoch 97; Iter   378/ 1097] train: loss: 0.0001339
[Epoch 97; Iter   408/ 1097] train: loss: 0.0000083
[Epoch 97; Iter   438/ 1097] train: loss: 0.0002147
[Epoch 97; Iter   468/ 1097] train: loss: 0.0021246
[Epoch 97; Iter   498/ 1097] train: loss: 0.0001679
[Epoch 97; Iter   528/ 1097] train: loss: 0.0004696
[Epoch 97; Iter   558/ 1097] train: loss: 0.0052240
[Epoch 97; Iter   588/ 1097] train: loss: 0.0002200
[Epoch 97; Iter   618/ 1097] train: loss: 0.0000759
[Epoch 97; Iter   648/ 1097] train: loss: 0.0001852
[Epoch 93; Iter   596/ 1097] train: loss: 0.0204250
[Epoch 93; Iter   626/ 1097] train: loss: 0.0002062
[Epoch 93; Iter   656/ 1097] train: loss: 0.0002318
[Epoch 93; Iter   686/ 1097] train: loss: 0.0000446
[Epoch 93; Iter   716/ 1097] train: loss: 0.0004224
[Epoch 93; Iter   746/ 1097] train: loss: 0.0000071
[Epoch 93; Iter   776/ 1097] train: loss: 0.0005495
[Epoch 93; Iter   806/ 1097] train: loss: 0.0000772
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000240
[Epoch 93; Iter   866/ 1097] train: loss: 0.0000130
[Epoch 93; Iter   896/ 1097] train: loss: 0.0015902
[Epoch 93; Iter   926/ 1097] train: loss: 0.0250069
[Epoch 93; Iter   956/ 1097] train: loss: 0.0002052
[Epoch 93; Iter   986/ 1097] train: loss: 0.0007665
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000207
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0000508
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0000796
[Epoch 93] ogbg-molhiv: 0.708385 val loss: 1.391797
[Epoch 93] ogbg-molhiv: 0.673597 test loss: 0.807103
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000200
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000078
[Epoch 94; Iter    69/ 1097] train: loss: 0.0000242
[Epoch 94; Iter    99/ 1097] train: loss: 0.0048791
[Epoch 94; Iter   129/ 1097] train: loss: 0.0004146
[Epoch 94; Iter   159/ 1097] train: loss: 0.0001741
[Epoch 94; Iter   189/ 1097] train: loss: 0.0001248
[Epoch 94; Iter   219/ 1097] train: loss: 0.0015594
[Epoch 94; Iter   249/ 1097] train: loss: 0.0019471
[Epoch 94; Iter   279/ 1097] train: loss: 0.0000645
[Epoch 94; Iter   309/ 1097] train: loss: 0.0003815
[Epoch 94; Iter   339/ 1097] train: loss: 0.0001441
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000908
[Epoch 94; Iter   399/ 1097] train: loss: 0.0003337
[Epoch 94; Iter   429/ 1097] train: loss: 0.0341335
[Epoch 94; Iter   459/ 1097] train: loss: 0.0004802
[Epoch 94; Iter   489/ 1097] train: loss: 0.0002433
[Epoch 94; Iter   519/ 1097] train: loss: 0.0000134
[Epoch 94; Iter   549/ 1097] train: loss: 0.0001290
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000141
[Epoch 94; Iter   609/ 1097] train: loss: 0.0440023
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000322
[Epoch 94; Iter   669/ 1097] train: loss: 0.0001352
[Epoch 94; Iter   699/ 1097] train: loss: 0.0002454
[Epoch 94; Iter   729/ 1097] train: loss: 0.0007572
[Epoch 94; Iter   759/ 1097] train: loss: 0.0098372
[Epoch 94; Iter   789/ 1097] train: loss: 0.0002008
[Epoch 94; Iter   819/ 1097] train: loss: 0.0001830
[Epoch 94; Iter   849/ 1097] train: loss: 0.0045076
[Epoch 94; Iter   879/ 1097] train: loss: 0.0004709
[Epoch 94; Iter   909/ 1097] train: loss: 0.0006018
[Epoch 94; Iter   939/ 1097] train: loss: 0.0000213
[Epoch 94; Iter   969/ 1097] train: loss: 0.0000280
[Epoch 94; Iter   999/ 1097] train: loss: 0.0001785
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0005292
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000692
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0000267
[Epoch 94] ogbg-molhiv: 0.709123 val loss: 1.636122
[Epoch 94] ogbg-molhiv: 0.697175 test loss: 0.673109
[Epoch 95; Iter    22/ 1097] train: loss: 0.0007870
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000314
[Epoch 95; Iter    82/ 1097] train: loss: 0.0000818
[Epoch 95; Iter   112/ 1097] train: loss: 0.0020347
[Epoch 95; Iter   142/ 1097] train: loss: 0.0010239
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000297
[Epoch 95; Iter   202/ 1097] train: loss: 0.0035330
[Epoch 95; Iter   232/ 1097] train: loss: 0.0015904
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000295
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000190
[Epoch 95; Iter   322/ 1097] train: loss: 0.0000648
[Epoch 95; Iter   352/ 1097] train: loss: 0.0000269
[Epoch 95; Iter   382/ 1097] train: loss: 0.0001710
[Epoch 95; Iter   412/ 1097] train: loss: 0.0008651
[Epoch 95; Iter   442/ 1097] train: loss: 0.0219641
[Epoch 95; Iter   472/ 1097] train: loss: 0.0000393
[Epoch 95; Iter   502/ 1097] train: loss: 0.0024272
[Epoch 95; Iter   532/ 1097] train: loss: 0.0006610
[Epoch 95; Iter   562/ 1097] train: loss: 0.0002630
[Epoch 95; Iter   592/ 1097] train: loss: 0.0078221
[Epoch 95; Iter   622/ 1097] train: loss: 0.0018726
[Epoch 95; Iter   652/ 1097] train: loss: 0.0084782
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000270
[Epoch 95; Iter   712/ 1097] train: loss: 0.0123281
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000738
[Epoch 95; Iter   772/ 1097] train: loss: 0.0002160
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000449
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000519
[Epoch 95; Iter   862/ 1097] train: loss: 0.0000091
[Epoch 95; Iter   892/ 1097] train: loss: 0.0000840
[Epoch 95; Iter   922/ 1097] train: loss: 0.0001282
[Epoch 95; Iter   952/ 1097] train: loss: 0.0020303
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000757
[Epoch 95; Iter  1012/ 1097] train: loss: 0.1137375
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0003998
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0000608
[Epoch 95] ogbg-molhiv: 0.702173 val loss: 0.692708
[Epoch 95] ogbg-molhiv: 0.701199 test loss: 0.760492
[Epoch 96; Iter     5/ 1097] train: loss: 0.0004794
[Epoch 96; Iter    35/ 1097] train: loss: 0.0000081
[Epoch 96; Iter    65/ 1097] train: loss: 0.0609964
[Epoch 96; Iter    95/ 1097] train: loss: 0.0017742
[Epoch 96; Iter   125/ 1097] train: loss: 0.0000398
[Epoch 96; Iter   155/ 1097] train: loss: 0.0002238
[Epoch 96; Iter   185/ 1097] train: loss: 0.0000854
[Epoch 96; Iter   215/ 1097] train: loss: 0.0000157
[Epoch 96; Iter   245/ 1097] train: loss: 0.0017258
[Epoch 96; Iter   275/ 1097] train: loss: 0.0001454
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000060
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000641
[Epoch 96; Iter   365/ 1097] train: loss: 0.0001500
[Epoch 96; Iter   395/ 1097] train: loss: 0.0000081
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000090
[Epoch 96; Iter   455/ 1097] train: loss: 0.0001103
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000093
[Epoch 96; Iter   515/ 1097] train: loss: 0.0019238
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000215
[Epoch 96; Iter   575/ 1097] train: loss: 0.0004269
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000314
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000463
[Epoch 96; Iter   665/ 1097] train: loss: 0.0002470
[Epoch 96; Iter   695/ 1097] train: loss: 0.0003714
[Epoch 96; Iter   725/ 1097] train: loss: 0.0002964
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000350
[Epoch 96; Iter   785/ 1097] train: loss: 0.0002888
[Epoch 96; Iter   815/ 1097] train: loss: 0.0162481
[Epoch 96; Iter   845/ 1097] train: loss: 0.0002254
[Epoch 96; Iter   875/ 1097] train: loss: 0.0029102
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000277
[Epoch 96; Iter   935/ 1097] train: loss: 0.0011031
[Epoch 96; Iter   965/ 1097] train: loss: 0.0003348
[Epoch 96; Iter   995/ 1097] train: loss: 0.0000065
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0038832
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0001667
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0028432
[Epoch 96] ogbg-molhiv: 0.712917 val loss: 0.931719
[Epoch 96] ogbg-molhiv: 0.719054 test loss: 0.656854
[Epoch 97; Iter    18/ 1097] train: loss: 0.0011083
[Epoch 97; Iter    48/ 1097] train: loss: 0.0016513
[Epoch 97; Iter    78/ 1097] train: loss: 0.0001214
[Epoch 97; Iter   108/ 1097] train: loss: 0.0016540
[Epoch 97; Iter   138/ 1097] train: loss: 0.0005589
[Epoch 97; Iter   168/ 1097] train: loss: 0.0000181
[Epoch 97; Iter   198/ 1097] train: loss: 0.0001462
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000018
[Epoch 97; Iter   258/ 1097] train: loss: 0.0000186
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000297
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000666
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000122
[Epoch 97; Iter   378/ 1097] train: loss: 0.0002259
[Epoch 97; Iter   408/ 1097] train: loss: 0.0000029
[Epoch 97; Iter   438/ 1097] train: loss: 0.0003431
[Epoch 97; Iter   468/ 1097] train: loss: 0.0061121
[Epoch 97; Iter   498/ 1097] train: loss: 0.0000056
[Epoch 97; Iter   528/ 1097] train: loss: 0.0067687
[Epoch 97; Iter   558/ 1097] train: loss: 0.0015547
[Epoch 97; Iter   588/ 1097] train: loss: 0.0005644
[Epoch 97; Iter   618/ 1097] train: loss: 0.0026752
[Epoch 97; Iter   648/ 1097] train: loss: 0.0407377
[Epoch 73; Iter   186/ 1097] train: loss: 0.1252229
[Epoch 73; Iter   216/ 1097] train: loss: 0.0094042
[Epoch 73; Iter   246/ 1097] train: loss: 0.0122602
[Epoch 73; Iter   276/ 1097] train: loss: 0.0517630
[Epoch 73; Iter   306/ 1097] train: loss: 0.0987741
[Epoch 73; Iter   336/ 1097] train: loss: 0.0169887
[Epoch 73; Iter   366/ 1097] train: loss: 0.3143888
[Epoch 73; Iter   396/ 1097] train: loss: 0.0865639
[Epoch 73; Iter   426/ 1097] train: loss: 0.0444191
[Epoch 73; Iter   456/ 1097] train: loss: 0.0169822
[Epoch 73; Iter   486/ 1097] train: loss: 0.0048553
[Epoch 73; Iter   516/ 1097] train: loss: 0.0098988
[Epoch 73; Iter   546/ 1097] train: loss: 0.0099161
[Epoch 73; Iter   576/ 1097] train: loss: 0.0282553
[Epoch 73; Iter   606/ 1097] train: loss: 0.1192490
[Epoch 73; Iter   636/ 1097] train: loss: 0.0061202
[Epoch 73; Iter   666/ 1097] train: loss: 0.0598338
[Epoch 73; Iter   696/ 1097] train: loss: 0.0045967
[Epoch 73; Iter   726/ 1097] train: loss: 0.1344391
[Epoch 73; Iter   756/ 1097] train: loss: 0.0090671
[Epoch 73; Iter   786/ 1097] train: loss: 0.0160153
[Epoch 73; Iter   816/ 1097] train: loss: 0.0229818
[Epoch 73; Iter   846/ 1097] train: loss: 0.0680386
[Epoch 73; Iter   876/ 1097] train: loss: 0.1576854
[Epoch 73; Iter   906/ 1097] train: loss: 0.1165230
[Epoch 73; Iter   936/ 1097] train: loss: 0.0088622
[Epoch 73; Iter   966/ 1097] train: loss: 0.0105323
[Epoch 73; Iter   996/ 1097] train: loss: 0.0226775
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0263235
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0025949
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0127369
[Epoch 73] ogbg-molhiv: 0.792855 val loss: 0.123870
[Epoch 73] ogbg-molhiv: 0.719357 test loss: 0.224626
[Epoch 74; Iter    19/ 1097] train: loss: 0.0043127
[Epoch 74; Iter    49/ 1097] train: loss: 0.0017403
[Epoch 74; Iter    79/ 1097] train: loss: 0.0113499
[Epoch 74; Iter   109/ 1097] train: loss: 0.0273946
[Epoch 74; Iter   139/ 1097] train: loss: 0.0127935
[Epoch 74; Iter   169/ 1097] train: loss: 0.0357218
[Epoch 74; Iter   199/ 1097] train: loss: 0.0435582
[Epoch 74; Iter   229/ 1097] train: loss: 0.0157824
[Epoch 74; Iter   259/ 1097] train: loss: 0.0571920
[Epoch 74; Iter   289/ 1097] train: loss: 0.0100752
[Epoch 74; Iter   319/ 1097] train: loss: 0.1924815
[Epoch 74; Iter   349/ 1097] train: loss: 0.1130027
[Epoch 74; Iter   379/ 1097] train: loss: 0.0963930
[Epoch 74; Iter   409/ 1097] train: loss: 0.0031916
[Epoch 74; Iter   439/ 1097] train: loss: 0.0233945
[Epoch 74; Iter   469/ 1097] train: loss: 0.0208298
[Epoch 74; Iter   499/ 1097] train: loss: 0.0178451
[Epoch 74; Iter   529/ 1097] train: loss: 0.0044815
[Epoch 74; Iter   559/ 1097] train: loss: 0.0254316
[Epoch 74; Iter   589/ 1097] train: loss: 0.0256030
[Epoch 74; Iter   619/ 1097] train: loss: 0.0054599
[Epoch 74; Iter   649/ 1097] train: loss: 0.0620859
[Epoch 74; Iter   679/ 1097] train: loss: 0.0453390
[Epoch 74; Iter   709/ 1097] train: loss: 0.2732771
[Epoch 74; Iter   739/ 1097] train: loss: 0.0140565
[Epoch 74; Iter   769/ 1097] train: loss: 0.0034469
[Epoch 74; Iter   799/ 1097] train: loss: 0.1472200
[Epoch 74; Iter   829/ 1097] train: loss: 0.0046655
[Epoch 74; Iter   859/ 1097] train: loss: 0.0426644
[Epoch 74; Iter   889/ 1097] train: loss: 0.0052866
[Epoch 74; Iter   919/ 1097] train: loss: 0.0120925
[Epoch 74; Iter   949/ 1097] train: loss: 0.0191810
[Epoch 74; Iter   979/ 1097] train: loss: 0.0079920
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0280054
[Epoch 74; Iter  1039/ 1097] train: loss: 0.2139414
[Epoch 74; Iter  1069/ 1097] train: loss: 0.1236531
[Epoch 74] ogbg-molhiv: 0.786584 val loss: 0.179951
[Epoch 74] ogbg-molhiv: 0.739085 test loss: 0.279750
[Epoch 75; Iter     2/ 1097] train: loss: 0.0157365
[Epoch 75; Iter    32/ 1097] train: loss: 0.1879231
[Epoch 75; Iter    62/ 1097] train: loss: 0.0038416
[Epoch 75; Iter    92/ 1097] train: loss: 0.0055565
[Epoch 75; Iter   122/ 1097] train: loss: 0.0132707
[Epoch 75; Iter   152/ 1097] train: loss: 0.1066613
[Epoch 75; Iter   182/ 1097] train: loss: 0.0650632
[Epoch 75; Iter   212/ 1097] train: loss: 0.0098910
[Epoch 75; Iter   242/ 1097] train: loss: 0.0188083
[Epoch 75; Iter   272/ 1097] train: loss: 0.0537115
[Epoch 75; Iter   302/ 1097] train: loss: 0.0162304
[Epoch 75; Iter   332/ 1097] train: loss: 0.0069416
[Epoch 75; Iter   362/ 1097] train: loss: 0.0192970
[Epoch 75; Iter   392/ 1097] train: loss: 0.0456468
[Epoch 75; Iter   422/ 1097] train: loss: 0.0055773
[Epoch 75; Iter   452/ 1097] train: loss: 0.0067014
[Epoch 75; Iter   482/ 1097] train: loss: 0.0461937
[Epoch 75; Iter   512/ 1097] train: loss: 0.0800188
[Epoch 75; Iter   542/ 1097] train: loss: 0.0023305
[Epoch 75; Iter   572/ 1097] train: loss: 0.1324844
[Epoch 75; Iter   602/ 1097] train: loss: 0.0389550
[Epoch 75; Iter   632/ 1097] train: loss: 0.1546744
[Epoch 75; Iter   662/ 1097] train: loss: 0.0196768
[Epoch 75; Iter   692/ 1097] train: loss: 0.0286707
[Epoch 75; Iter   722/ 1097] train: loss: 0.0320352
[Epoch 75; Iter   752/ 1097] train: loss: 0.0472329
[Epoch 75; Iter   782/ 1097] train: loss: 0.0472434
[Epoch 75; Iter   812/ 1097] train: loss: 0.0147974
[Epoch 75; Iter   842/ 1097] train: loss: 0.0354896
[Epoch 75; Iter   872/ 1097] train: loss: 0.0088481
[Epoch 75; Iter   902/ 1097] train: loss: 0.1234133
[Epoch 75; Iter   932/ 1097] train: loss: 0.0890816
[Epoch 75; Iter   962/ 1097] train: loss: 0.0759505
[Epoch 75; Iter   992/ 1097] train: loss: 0.0883899
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0680156
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0754210
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0842950
[Epoch 75] ogbg-molhiv: 0.793078 val loss: 0.157283
[Epoch 75] ogbg-molhiv: 0.750072 test loss: 0.235947
[Epoch 76; Iter    15/ 1097] train: loss: 0.0205857
[Epoch 76; Iter    45/ 1097] train: loss: 0.0563933
[Epoch 76; Iter    75/ 1097] train: loss: 0.0128324
[Epoch 76; Iter   105/ 1097] train: loss: 0.0086933
[Epoch 76; Iter   135/ 1097] train: loss: 0.0458238
[Epoch 76; Iter   165/ 1097] train: loss: 0.0020179
[Epoch 76; Iter   195/ 1097] train: loss: 0.0038344
[Epoch 76; Iter   225/ 1097] train: loss: 0.0073275
[Epoch 76; Iter   255/ 1097] train: loss: 0.0481315
[Epoch 76; Iter   285/ 1097] train: loss: 0.0102310
[Epoch 76; Iter   315/ 1097] train: loss: 0.0299767
[Epoch 76; Iter   345/ 1097] train: loss: 0.0090920
[Epoch 76; Iter   375/ 1097] train: loss: 0.0758229
[Epoch 76; Iter   405/ 1097] train: loss: 0.0449692
[Epoch 76; Iter   435/ 1097] train: loss: 0.0195897
[Epoch 76; Iter   465/ 1097] train: loss: 0.0852278
[Epoch 76; Iter   495/ 1097] train: loss: 0.0022729
[Epoch 76; Iter   525/ 1097] train: loss: 0.0519211
[Epoch 76; Iter   555/ 1097] train: loss: 0.0029939
[Epoch 76; Iter   585/ 1097] train: loss: 0.0198875
[Epoch 76; Iter   615/ 1097] train: loss: 0.0357247
[Epoch 76; Iter   645/ 1097] train: loss: 0.0093561
[Epoch 76; Iter   675/ 1097] train: loss: 0.0105208
[Epoch 76; Iter   705/ 1097] train: loss: 0.0096907
[Epoch 76; Iter   735/ 1097] train: loss: 0.0122440
[Epoch 76; Iter   765/ 1097] train: loss: 0.0316434
[Epoch 76; Iter   795/ 1097] train: loss: 0.0439382
[Epoch 76; Iter   825/ 1097] train: loss: 0.0235997
[Epoch 76; Iter   855/ 1097] train: loss: 0.0061123
[Epoch 76; Iter   885/ 1097] train: loss: 0.0286972
[Epoch 76; Iter   915/ 1097] train: loss: 0.0113663
[Epoch 76; Iter   945/ 1097] train: loss: 0.0182956
[Epoch 76; Iter   975/ 1097] train: loss: 0.0087298
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0198864
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0193064
[Epoch 76; Iter  1065/ 1097] train: loss: 0.1748917
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0690624
[Epoch 76] ogbg-molhiv: 0.784000 val loss: 0.122307
[Epoch 76] ogbg-molhiv: 0.739968 test loss: 0.218268
[Epoch 77; Iter    28/ 1097] train: loss: 0.0530258
[Epoch 77; Iter    58/ 1097] train: loss: 0.0015187
[Epoch 77; Iter    88/ 1097] train: loss: 0.2002516
[Epoch 77; Iter   118/ 1097] train: loss: 0.0082163
[Epoch 77; Iter   148/ 1097] train: loss: 0.0487439
[Epoch 77; Iter   178/ 1097] train: loss: 0.0074003
[Epoch 77; Iter   208/ 1097] train: loss: 0.0161336
[Epoch 77; Iter   238/ 1097] train: loss: 0.0027146
[Epoch 93; Iter   596/ 1097] train: loss: 0.0008057
[Epoch 93; Iter   626/ 1097] train: loss: 0.0003748
[Epoch 93; Iter   656/ 1097] train: loss: 0.0060776
[Epoch 93; Iter   686/ 1097] train: loss: 0.0000014
[Epoch 93; Iter   716/ 1097] train: loss: 0.0010959
[Epoch 93; Iter   746/ 1097] train: loss: 0.0000222
[Epoch 93; Iter   776/ 1097] train: loss: 0.0012930
[Epoch 93; Iter   806/ 1097] train: loss: 0.0000230
[Epoch 93; Iter   836/ 1097] train: loss: 0.0001153
[Epoch 93; Iter   866/ 1097] train: loss: 0.0000036
[Epoch 93; Iter   896/ 1097] train: loss: 0.0000214
[Epoch 93; Iter   926/ 1097] train: loss: 0.0008105
[Epoch 93; Iter   956/ 1097] train: loss: 0.0000113
[Epoch 93; Iter   986/ 1097] train: loss: 0.0001959
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000155
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0005624
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0005023
[Epoch 93] ogbg-molhiv: 0.778402 val loss: 0.238809
[Epoch 93] ogbg-molhiv: 0.727355 test loss: 0.392944
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000540
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000224
[Epoch 94; Iter    69/ 1097] train: loss: 0.0000687
[Epoch 94; Iter    99/ 1097] train: loss: 0.0000437
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000365
[Epoch 94; Iter   159/ 1097] train: loss: 0.0001116
[Epoch 94; Iter   189/ 1097] train: loss: 0.0009082
[Epoch 94; Iter   219/ 1097] train: loss: 0.0001280
[Epoch 94; Iter   249/ 1097] train: loss: 0.0000345
[Epoch 94; Iter   279/ 1097] train: loss: 0.0000049
[Epoch 94; Iter   309/ 1097] train: loss: 0.0008421
[Epoch 94; Iter   339/ 1097] train: loss: 0.0000161
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000525
[Epoch 94; Iter   399/ 1097] train: loss: 0.0001371
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000068
[Epoch 94; Iter   459/ 1097] train: loss: 0.0001678
[Epoch 94; Iter   489/ 1097] train: loss: 0.0000089
[Epoch 94; Iter   519/ 1097] train: loss: 0.0000113
[Epoch 94; Iter   549/ 1097] train: loss: 0.0000886
[Epoch 94; Iter   579/ 1097] train: loss: 0.0123525
[Epoch 94; Iter   609/ 1097] train: loss: 0.0048317
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000596
[Epoch 94; Iter   669/ 1097] train: loss: 0.0000081
[Epoch 94; Iter   699/ 1097] train: loss: 0.0002726
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000042
[Epoch 94; Iter   759/ 1097] train: loss: 0.0000222
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000676
[Epoch 94; Iter   819/ 1097] train: loss: 0.0005215
[Epoch 94; Iter   849/ 1097] train: loss: 0.0000185
[Epoch 94; Iter   879/ 1097] train: loss: 0.0005522
[Epoch 94; Iter   909/ 1097] train: loss: 0.0000605
[Epoch 94; Iter   939/ 1097] train: loss: 0.0003180
[Epoch 94; Iter   969/ 1097] train: loss: 0.0000436
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000069
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0004708
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0003973
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0002728
[Epoch 94] ogbg-molhiv: 0.774572 val loss: 0.244655
[Epoch 94] ogbg-molhiv: 0.729757 test loss: 0.390422
[Epoch 95; Iter    22/ 1097] train: loss: 0.0005659
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000044
[Epoch 95; Iter    82/ 1097] train: loss: 0.0000904
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000388
[Epoch 95; Iter   142/ 1097] train: loss: 0.0009525
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000143
[Epoch 95; Iter   202/ 1097] train: loss: 0.0721709
[Epoch 95; Iter   232/ 1097] train: loss: 0.0002254
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000035
[Epoch 95; Iter   292/ 1097] train: loss: 0.0004084
[Epoch 95; Iter   322/ 1097] train: loss: 0.0000393
[Epoch 95; Iter   352/ 1097] train: loss: 0.0004033
[Epoch 95; Iter   382/ 1097] train: loss: 0.0000033
[Epoch 95; Iter   412/ 1097] train: loss: 0.0036469
[Epoch 95; Iter   442/ 1097] train: loss: 0.0000049
[Epoch 95; Iter   472/ 1097] train: loss: 0.0003165
[Epoch 95; Iter   502/ 1097] train: loss: 0.0000412
[Epoch 95; Iter   532/ 1097] train: loss: 0.0000354
[Epoch 95; Iter   562/ 1097] train: loss: 0.0014089
[Epoch 95; Iter   592/ 1097] train: loss: 0.0002466
[Epoch 95; Iter   622/ 1097] train: loss: 0.0014881
[Epoch 95; Iter   652/ 1097] train: loss: 0.0049682
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000080
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000739
[Epoch 95; Iter   742/ 1097] train: loss: 0.0005186
[Epoch 95; Iter   772/ 1097] train: loss: 0.0000873
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000011
[Epoch 95; Iter   832/ 1097] train: loss: 0.0003425
[Epoch 95; Iter   862/ 1097] train: loss: 0.0002207
[Epoch 95; Iter   892/ 1097] train: loss: 0.0000161
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000378
[Epoch 95; Iter   952/ 1097] train: loss: 0.0000028
[Epoch 95; Iter   982/ 1097] train: loss: 0.0001957
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0791606
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0001028
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0000352
[Epoch 95] ogbg-molhiv: 0.774670 val loss: 0.247552
[Epoch 95] ogbg-molhiv: 0.717789 test loss: 0.393496
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000096
[Epoch 96; Iter    35/ 1097] train: loss: 0.0000028
[Epoch 96; Iter    65/ 1097] train: loss: 0.0042669
[Epoch 96; Iter    95/ 1097] train: loss: 0.0000295
[Epoch 96; Iter   125/ 1097] train: loss: 0.0000231
[Epoch 96; Iter   155/ 1097] train: loss: 0.0000653
[Epoch 96; Iter   185/ 1097] train: loss: 0.0000083
[Epoch 96; Iter   215/ 1097] train: loss: 0.0000044
[Epoch 96; Iter   245/ 1097] train: loss: 0.0001704
[Epoch 96; Iter   275/ 1097] train: loss: 0.0000012
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000049
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000865
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000087
[Epoch 96; Iter   395/ 1097] train: loss: 0.0001018
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000137
[Epoch 96; Iter   455/ 1097] train: loss: 0.0000083
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000571
[Epoch 96; Iter   515/ 1097] train: loss: 0.0000493
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000023
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000574
[Epoch 96; Iter   605/ 1097] train: loss: 0.0002101
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000136
[Epoch 96; Iter   665/ 1097] train: loss: 0.0000637
[Epoch 96; Iter   695/ 1097] train: loss: 0.0001633
[Epoch 96; Iter   725/ 1097] train: loss: 0.0003646
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000066
[Epoch 96; Iter   785/ 1097] train: loss: 0.0006397
[Epoch 96; Iter   815/ 1097] train: loss: 0.0000313
[Epoch 96; Iter   845/ 1097] train: loss: 0.0000014
[Epoch 96; Iter   875/ 1097] train: loss: 0.0002968
[Epoch 96; Iter   905/ 1097] train: loss: 0.0001343
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000785
[Epoch 96; Iter   965/ 1097] train: loss: 0.0000168
[Epoch 96; Iter   995/ 1097] train: loss: 0.0000164
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0000123
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000031
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0084963
[Epoch 96] ogbg-molhiv: 0.771492 val loss: 0.253518
[Epoch 96] ogbg-molhiv: 0.724214 test loss: 0.394592
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000777
[Epoch 97; Iter    48/ 1097] train: loss: 0.0004774
[Epoch 97; Iter    78/ 1097] train: loss: 0.0001192
[Epoch 97; Iter   108/ 1097] train: loss: 0.0000211
[Epoch 97; Iter   138/ 1097] train: loss: 0.0000244
[Epoch 97; Iter   168/ 1097] train: loss: 0.0002313
[Epoch 97; Iter   198/ 1097] train: loss: 0.0422773
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000106
[Epoch 97; Iter   258/ 1097] train: loss: 0.0001427
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000077
[Epoch 97; Iter   318/ 1097] train: loss: 0.0011862
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000386
[Epoch 97; Iter   378/ 1097] train: loss: 0.0000509
[Epoch 97; Iter   408/ 1097] train: loss: 0.0000022
[Epoch 97; Iter   438/ 1097] train: loss: 0.0000308
[Epoch 97; Iter   468/ 1097] train: loss: 0.0000035
[Epoch 97; Iter   498/ 1097] train: loss: 0.0001423
[Epoch 97; Iter   528/ 1097] train: loss: 0.0000924
[Epoch 97; Iter   558/ 1097] train: loss: 0.0017721
[Epoch 97; Iter   588/ 1097] train: loss: 0.0000459
[Epoch 97; Iter   618/ 1097] train: loss: 0.0005013
[Epoch 97; Iter   648/ 1097] train: loss: 0.0154084
[Epoch 93; Iter   596/ 1097] train: loss: 0.0000644
[Epoch 93; Iter   626/ 1097] train: loss: 0.0000229
[Epoch 93; Iter   656/ 1097] train: loss: 0.0031417
[Epoch 93; Iter   686/ 1097] train: loss: 0.0000851
[Epoch 93; Iter   716/ 1097] train: loss: 0.0003341
[Epoch 93; Iter   746/ 1097] train: loss: 0.0008927
[Epoch 93; Iter   776/ 1097] train: loss: 0.0000678
[Epoch 93; Iter   806/ 1097] train: loss: 0.0000564
[Epoch 93; Iter   836/ 1097] train: loss: 0.0006069
[Epoch 93; Iter   866/ 1097] train: loss: 0.0051161
[Epoch 93; Iter   896/ 1097] train: loss: 0.0001459
[Epoch 93; Iter   926/ 1097] train: loss: 0.0000129
[Epoch 93; Iter   956/ 1097] train: loss: 0.0000035
[Epoch 93; Iter   986/ 1097] train: loss: 0.0000140
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0392454
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0004407
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0045719
[Epoch 93] ogbg-molhiv: 0.770656 val loss: 0.373541
[Epoch 93] ogbg-molhiv: 0.731905 test loss: 0.389772
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000025
[Epoch 94; Iter    39/ 1097] train: loss: 0.0001017
[Epoch 94; Iter    69/ 1097] train: loss: 0.0019678
[Epoch 94; Iter    99/ 1097] train: loss: 0.0004163
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000087
[Epoch 94; Iter   159/ 1097] train: loss: 0.0008776
[Epoch 94; Iter   189/ 1097] train: loss: 0.0002357
[Epoch 94; Iter   219/ 1097] train: loss: 0.0003972
[Epoch 94; Iter   249/ 1097] train: loss: 0.0003123
[Epoch 94; Iter   279/ 1097] train: loss: 0.0010161
[Epoch 94; Iter   309/ 1097] train: loss: 0.0003252
[Epoch 94; Iter   339/ 1097] train: loss: 0.0000616
[Epoch 94; Iter   369/ 1097] train: loss: 0.0092596
[Epoch 94; Iter   399/ 1097] train: loss: 0.0019047
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000033
[Epoch 94; Iter   459/ 1097] train: loss: 0.0000162
[Epoch 94; Iter   489/ 1097] train: loss: 0.0000371
[Epoch 94; Iter   519/ 1097] train: loss: 0.0001839
[Epoch 94; Iter   549/ 1097] train: loss: 0.0000467
[Epoch 94; Iter   579/ 1097] train: loss: 0.0001685
[Epoch 94; Iter   609/ 1097] train: loss: 0.0003898
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000161
[Epoch 94; Iter   669/ 1097] train: loss: 0.0031923
[Epoch 94; Iter   699/ 1097] train: loss: 0.0000200
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000062
[Epoch 94; Iter   759/ 1097] train: loss: 0.0000218
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000057
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000028
[Epoch 94; Iter   849/ 1097] train: loss: 0.0000150
[Epoch 94; Iter   879/ 1097] train: loss: 0.0005065
[Epoch 94; Iter   909/ 1097] train: loss: 0.0000062
[Epoch 94; Iter   939/ 1097] train: loss: 0.0001308
[Epoch 94; Iter   969/ 1097] train: loss: 0.0000246
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000079
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0001832
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000820
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0002043
[Epoch 94] ogbg-molhiv: 0.780775 val loss: 0.371282
[Epoch 94] ogbg-molhiv: 0.766119 test loss: 0.357589
[Epoch 95; Iter    22/ 1097] train: loss: 0.0003406
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000350
[Epoch 95; Iter    82/ 1097] train: loss: 0.0001039
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000027
[Epoch 95; Iter   142/ 1097] train: loss: 0.0003503
[Epoch 95; Iter   172/ 1097] train: loss: 0.0022915
[Epoch 95; Iter   202/ 1097] train: loss: 0.0000555
[Epoch 95; Iter   232/ 1097] train: loss: 0.0000364
[Epoch 95; Iter   262/ 1097] train: loss: 0.0004984
[Epoch 95; Iter   292/ 1097] train: loss: 0.0001076
[Epoch 95; Iter   322/ 1097] train: loss: 0.0119940
[Epoch 95; Iter   352/ 1097] train: loss: 0.0001867
[Epoch 95; Iter   382/ 1097] train: loss: 0.0000755
[Epoch 95; Iter   412/ 1097] train: loss: 0.0000609
[Epoch 95; Iter   442/ 1097] train: loss: 0.0000101
[Epoch 95; Iter   472/ 1097] train: loss: 0.0006105
[Epoch 95; Iter   502/ 1097] train: loss: 0.0004739
[Epoch 95; Iter   532/ 1097] train: loss: 0.0003870
[Epoch 95; Iter   562/ 1097] train: loss: 0.0000702
[Epoch 95; Iter   592/ 1097] train: loss: 0.0000450
[Epoch 95; Iter   622/ 1097] train: loss: 0.0079270
[Epoch 95; Iter   652/ 1097] train: loss: 0.0000647
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000097
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000116
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000018
[Epoch 95; Iter   772/ 1097] train: loss: 0.0000334
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000712
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000627
[Epoch 95; Iter   862/ 1097] train: loss: 0.0002679
[Epoch 95; Iter   892/ 1097] train: loss: 0.0035931
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000021
[Epoch 95; Iter   952/ 1097] train: loss: 0.0000587
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000539
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0001436
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0000033
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0000222
[Epoch 95] ogbg-molhiv: 0.759115 val loss: 0.377010
[Epoch 95] ogbg-molhiv: 0.750289 test loss: 0.374925
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000003
[Epoch 96; Iter    35/ 1097] train: loss: 0.0001118
[Epoch 96; Iter    65/ 1097] train: loss: 0.0006275
[Epoch 96; Iter    95/ 1097] train: loss: 0.0041170
[Epoch 96; Iter   125/ 1097] train: loss: 0.0004766
[Epoch 96; Iter   155/ 1097] train: loss: 0.0002815
[Epoch 96; Iter   185/ 1097] train: loss: 0.0001316
[Epoch 96; Iter   215/ 1097] train: loss: 0.0000081
[Epoch 96; Iter   245/ 1097] train: loss: 0.0000073
[Epoch 96; Iter   275/ 1097] train: loss: 0.0000030
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000028
[Epoch 96; Iter   335/ 1097] train: loss: 0.0006638
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000252
[Epoch 96; Iter   395/ 1097] train: loss: 0.0111664
[Epoch 96; Iter   425/ 1097] train: loss: 0.0011399
[Epoch 96; Iter   455/ 1097] train: loss: 0.0004423
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000369
[Epoch 96; Iter   515/ 1097] train: loss: 0.0000833
[Epoch 96; Iter   545/ 1097] train: loss: 0.0006874
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000038
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000190
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000214
[Epoch 96; Iter   665/ 1097] train: loss: 0.0002048
[Epoch 96; Iter   695/ 1097] train: loss: 0.0000018
[Epoch 96; Iter   725/ 1097] train: loss: 0.0000148
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000955
[Epoch 96; Iter   785/ 1097] train: loss: 0.0000595
[Epoch 96; Iter   815/ 1097] train: loss: 0.0000106
[Epoch 96; Iter   845/ 1097] train: loss: 0.0000072
[Epoch 96; Iter   875/ 1097] train: loss: 0.0027839
[Epoch 96; Iter   905/ 1097] train: loss: 0.0022034
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000356
[Epoch 96; Iter   965/ 1097] train: loss: 0.0000482
[Epoch 96; Iter   995/ 1097] train: loss: 0.0004635
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0000205
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000038
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0000216
[Epoch 96] ogbg-molhiv: 0.767900 val loss: 0.393172
[Epoch 96] ogbg-molhiv: 0.748379 test loss: 0.387394
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000825
[Epoch 97; Iter    48/ 1097] train: loss: 0.0022159
[Epoch 97; Iter    78/ 1097] train: loss: 0.0000066
[Epoch 97; Iter   108/ 1097] train: loss: 0.0001087
[Epoch 97; Iter   138/ 1097] train: loss: 0.0000805
[Epoch 97; Iter   168/ 1097] train: loss: 0.0196537
[Epoch 97; Iter   198/ 1097] train: loss: 0.0001927
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000696
[Epoch 97; Iter   258/ 1097] train: loss: 0.0023512
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000288
[Epoch 97; Iter   318/ 1097] train: loss: 0.0023520
[Epoch 97; Iter   348/ 1097] train: loss: 0.0005300
[Epoch 97; Iter   378/ 1097] train: loss: 0.0004963
[Epoch 97; Iter   408/ 1097] train: loss: 0.0018153
[Epoch 97; Iter   438/ 1097] train: loss: 0.0000106
[Epoch 97; Iter   468/ 1097] train: loss: 0.0012646
[Epoch 97; Iter   498/ 1097] train: loss: 0.0000038
[Epoch 97; Iter   528/ 1097] train: loss: 0.0000160
[Epoch 97; Iter   558/ 1097] train: loss: 0.0008207
[Epoch 97; Iter   588/ 1097] train: loss: 0.0007668
[Epoch 97; Iter   618/ 1097] train: loss: 0.0000026
[Epoch 97; Iter   648/ 1097] train: loss: 0.0057821
[Epoch 93; Iter   596/ 1097] train: loss: 0.0041397
[Epoch 93; Iter   626/ 1097] train: loss: 0.0007433
[Epoch 93; Iter   656/ 1097] train: loss: 0.0001289
[Epoch 93; Iter   686/ 1097] train: loss: 0.0039456
[Epoch 93; Iter   716/ 1097] train: loss: 0.0000330
[Epoch 93; Iter   746/ 1097] train: loss: 0.0001249
[Epoch 93; Iter   776/ 1097] train: loss: 0.0000261
[Epoch 93; Iter   806/ 1097] train: loss: 0.0001064
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000277
[Epoch 93; Iter   866/ 1097] train: loss: 0.0001372
[Epoch 93; Iter   896/ 1097] train: loss: 0.0005166
[Epoch 93; Iter   926/ 1097] train: loss: 0.0003051
[Epoch 93; Iter   956/ 1097] train: loss: 0.0000834
[Epoch 93; Iter   986/ 1097] train: loss: 0.0000990
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0013373
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0004195
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0004408
[Epoch 93] ogbg-molhiv: 0.784606 val loss: 0.292383
[Epoch 93] ogbg-molhiv: 0.728500 test loss: 0.534122
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000043
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000169
[Epoch 94; Iter    69/ 1097] train: loss: 0.0000313
[Epoch 94; Iter    99/ 1097] train: loss: 0.0036991
[Epoch 94; Iter   129/ 1097] train: loss: 0.0077873
[Epoch 94; Iter   159/ 1097] train: loss: 0.0000077
[Epoch 94; Iter   189/ 1097] train: loss: 0.0000629
[Epoch 94; Iter   219/ 1097] train: loss: 0.0000086
[Epoch 94; Iter   249/ 1097] train: loss: 0.0002146
[Epoch 94; Iter   279/ 1097] train: loss: 0.0005635
[Epoch 94; Iter   309/ 1097] train: loss: 0.0000650
[Epoch 94; Iter   339/ 1097] train: loss: 0.0002183
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000577
[Epoch 94; Iter   399/ 1097] train: loss: 0.0004196
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000246
[Epoch 94; Iter   459/ 1097] train: loss: 0.0000086
[Epoch 94; Iter   489/ 1097] train: loss: 0.0000173
[Epoch 94; Iter   519/ 1097] train: loss: 0.0004083
[Epoch 94; Iter   549/ 1097] train: loss: 0.0014357
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000354
[Epoch 94; Iter   609/ 1097] train: loss: 0.0000357
[Epoch 94; Iter   639/ 1097] train: loss: 0.0004756
[Epoch 94; Iter   669/ 1097] train: loss: 0.0023855
[Epoch 94; Iter   699/ 1097] train: loss: 0.0001213
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000588
[Epoch 94; Iter   759/ 1097] train: loss: 0.0001880
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000535
[Epoch 94; Iter   819/ 1097] train: loss: 0.0003937
[Epoch 94; Iter   849/ 1097] train: loss: 0.0064061
[Epoch 94; Iter   879/ 1097] train: loss: 0.0011018
[Epoch 94; Iter   909/ 1097] train: loss: 0.0000881
[Epoch 94; Iter   939/ 1097] train: loss: 0.0063774
[Epoch 94; Iter   969/ 1097] train: loss: 0.0004788
[Epoch 94; Iter   999/ 1097] train: loss: 0.0002263
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0000440
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000902
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0003288
[Epoch 94] ogbg-molhiv: 0.787867 val loss: 0.285439
[Epoch 94] ogbg-molhiv: 0.741683 test loss: 0.458339
[Epoch 95; Iter    22/ 1097] train: loss: 0.0001230
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000054
[Epoch 95; Iter    82/ 1097] train: loss: 0.0000771
[Epoch 95; Iter   112/ 1097] train: loss: 0.0020544
[Epoch 95; Iter   142/ 1097] train: loss: 0.0001819
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000190
[Epoch 95; Iter   202/ 1097] train: loss: 0.0000951
[Epoch 95; Iter   232/ 1097] train: loss: 0.0000714
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000012
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000424
[Epoch 95; Iter   322/ 1097] train: loss: 0.0000931
[Epoch 95; Iter   352/ 1097] train: loss: 0.0000252
[Epoch 95; Iter   382/ 1097] train: loss: 0.0037977
[Epoch 95; Iter   412/ 1097] train: loss: 0.0000394
[Epoch 95; Iter   442/ 1097] train: loss: 0.0004721
[Epoch 95; Iter   472/ 1097] train: loss: 0.0110310
[Epoch 95; Iter   502/ 1097] train: loss: 0.0002973
[Epoch 95; Iter   532/ 1097] train: loss: 0.0000632
[Epoch 95; Iter   562/ 1097] train: loss: 0.0002411
[Epoch 95; Iter   592/ 1097] train: loss: 0.0020573
[Epoch 95; Iter   622/ 1097] train: loss: 0.0004559
[Epoch 95; Iter   652/ 1097] train: loss: 0.0001616
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000295
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000669
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000096
[Epoch 95; Iter   772/ 1097] train: loss: 0.0000082
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000057
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000189
[Epoch 95; Iter   862/ 1097] train: loss: 0.0000057
[Epoch 95; Iter   892/ 1097] train: loss: 0.0001005
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000121
[Epoch 95; Iter   952/ 1097] train: loss: 0.0000337
[Epoch 95; Iter   982/ 1097] train: loss: 0.0007017
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0003091
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0000111
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0009484
[Epoch 95] ogbg-molhiv: 0.779532 val loss: 0.351381
[Epoch 95] ogbg-molhiv: 0.723614 test loss: 0.564539
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000571
[Epoch 96; Iter    35/ 1097] train: loss: 0.0002853
[Epoch 96; Iter    65/ 1097] train: loss: 0.0002240
[Epoch 96; Iter    95/ 1097] train: loss: 0.0001252
[Epoch 96; Iter   125/ 1097] train: loss: 0.0001544
[Epoch 96; Iter   155/ 1097] train: loss: 0.0042293
[Epoch 96; Iter   185/ 1097] train: loss: 0.0058801
[Epoch 96; Iter   215/ 1097] train: loss: 0.0004300
[Epoch 96; Iter   245/ 1097] train: loss: 0.0000009
[Epoch 96; Iter   275/ 1097] train: loss: 0.0000020
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000024
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000182
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000058
[Epoch 96; Iter   395/ 1097] train: loss: 0.0077104
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000035
[Epoch 96; Iter   455/ 1097] train: loss: 0.0006755
[Epoch 96; Iter   485/ 1097] train: loss: 0.0002614
[Epoch 96; Iter   515/ 1097] train: loss: 0.0001233
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000118
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000021
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000040
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000054
[Epoch 96; Iter   665/ 1097] train: loss: 0.0006650
[Epoch 96; Iter   695/ 1097] train: loss: 0.0028528
[Epoch 96; Iter   725/ 1097] train: loss: 0.0000466
[Epoch 96; Iter   755/ 1097] train: loss: 0.0230289
[Epoch 96; Iter   785/ 1097] train: loss: 0.0013573
[Epoch 96; Iter   815/ 1097] train: loss: 0.0045086
[Epoch 96; Iter   845/ 1097] train: loss: 0.0007783
[Epoch 96; Iter   875/ 1097] train: loss: 0.0002465
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000066
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000803
[Epoch 96; Iter   965/ 1097] train: loss: 0.0000261
[Epoch 96; Iter   995/ 1097] train: loss: 0.0004666
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0001206
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000238
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0000130
[Epoch 96] ogbg-molhiv: 0.779737 val loss: 0.272773
[Epoch 96] ogbg-molhiv: 0.738886 test loss: 0.470249
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000028
[Epoch 97; Iter    48/ 1097] train: loss: 0.0001351
[Epoch 97; Iter    78/ 1097] train: loss: 0.0007396
[Epoch 97; Iter   108/ 1097] train: loss: 0.0000687
[Epoch 97; Iter   138/ 1097] train: loss: 0.0004547
[Epoch 97; Iter   168/ 1097] train: loss: 0.0008846
[Epoch 97; Iter   198/ 1097] train: loss: 0.0000177
[Epoch 97; Iter   228/ 1097] train: loss: 0.0002205
[Epoch 97; Iter   258/ 1097] train: loss: 0.0006900
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000253
[Epoch 97; Iter   318/ 1097] train: loss: 0.0040226
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000573
[Epoch 97; Iter   378/ 1097] train: loss: 0.0001819
[Epoch 97; Iter   408/ 1097] train: loss: 0.0020395
[Epoch 97; Iter   438/ 1097] train: loss: 0.0000112
[Epoch 97; Iter   468/ 1097] train: loss: 0.0000024
[Epoch 97; Iter   498/ 1097] train: loss: 0.0000401
[Epoch 97; Iter   528/ 1097] train: loss: 0.0510641
[Epoch 97; Iter   558/ 1097] train: loss: 0.0002881
[Epoch 97; Iter   588/ 1097] train: loss: 0.0002044
[Epoch 97; Iter   618/ 1097] train: loss: 0.0000385
[Epoch 97; Iter   648/ 1097] train: loss: 0.0000057
[Epoch 73; Iter   186/ 1097] train: loss: 0.0755454
[Epoch 73; Iter   216/ 1097] train: loss: 0.0671198
[Epoch 73; Iter   246/ 1097] train: loss: 0.0895360
[Epoch 73; Iter   276/ 1097] train: loss: 0.0027192
[Epoch 73; Iter   306/ 1097] train: loss: 0.0601362
[Epoch 73; Iter   336/ 1097] train: loss: 0.0213237
[Epoch 73; Iter   366/ 1097] train: loss: 0.0081040
[Epoch 73; Iter   396/ 1097] train: loss: 0.0339621
[Epoch 73; Iter   426/ 1097] train: loss: 0.0652249
[Epoch 73; Iter   456/ 1097] train: loss: 0.0215935
[Epoch 73; Iter   486/ 1097] train: loss: 0.1078178
[Epoch 73; Iter   516/ 1097] train: loss: 0.0152463
[Epoch 73; Iter   546/ 1097] train: loss: 0.0010557
[Epoch 73; Iter   576/ 1097] train: loss: 0.0026546
[Epoch 73; Iter   606/ 1097] train: loss: 0.1121779
[Epoch 73; Iter   636/ 1097] train: loss: 0.0031536
[Epoch 73; Iter   666/ 1097] train: loss: 0.1644537
[Epoch 73; Iter   696/ 1097] train: loss: 0.0036428
[Epoch 73; Iter   726/ 1097] train: loss: 0.0662031
[Epoch 73; Iter   756/ 1097] train: loss: 0.0033378
[Epoch 73; Iter   786/ 1097] train: loss: 0.1341432
[Epoch 73; Iter   816/ 1097] train: loss: 0.0149034
[Epoch 73; Iter   846/ 1097] train: loss: 0.0082523
[Epoch 73; Iter   876/ 1097] train: loss: 0.0028798
[Epoch 73; Iter   906/ 1097] train: loss: 0.0308109
[Epoch 73; Iter   936/ 1097] train: loss: 0.0018445
[Epoch 73; Iter   966/ 1097] train: loss: 0.0166315
[Epoch 73; Iter   996/ 1097] train: loss: 0.0090362
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0122341
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0702625
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0699336
[Epoch 73] ogbg-molhiv: 0.792052 val loss: 0.123203
[Epoch 73] ogbg-molhiv: 0.749120 test loss: 0.242657
[Epoch 74; Iter    19/ 1097] train: loss: 0.0379454
[Epoch 74; Iter    49/ 1097] train: loss: 0.0425645
[Epoch 74; Iter    79/ 1097] train: loss: 0.0645380
[Epoch 74; Iter   109/ 1097] train: loss: 0.0222067
[Epoch 74; Iter   139/ 1097] train: loss: 0.0147271
[Epoch 74; Iter   169/ 1097] train: loss: 0.0661486
[Epoch 74; Iter   199/ 1097] train: loss: 0.0257749
[Epoch 74; Iter   229/ 1097] train: loss: 0.0242385
[Epoch 74; Iter   259/ 1097] train: loss: 0.0156788
[Epoch 74; Iter   289/ 1097] train: loss: 0.0133139
[Epoch 74; Iter   319/ 1097] train: loss: 0.0060192
[Epoch 74; Iter   349/ 1097] train: loss: 0.1624041
[Epoch 74; Iter   379/ 1097] train: loss: 0.0084482
[Epoch 74; Iter   409/ 1097] train: loss: 0.0198562
[Epoch 74; Iter   439/ 1097] train: loss: 0.0070408
[Epoch 74; Iter   469/ 1097] train: loss: 0.0010419
[Epoch 74; Iter   499/ 1097] train: loss: 0.0048660
[Epoch 74; Iter   529/ 1097] train: loss: 0.1310100
[Epoch 74; Iter   559/ 1097] train: loss: 0.0015535
[Epoch 74; Iter   589/ 1097] train: loss: 0.0033479
[Epoch 74; Iter   619/ 1097] train: loss: 0.0232130
[Epoch 74; Iter   649/ 1097] train: loss: 0.0128343
[Epoch 74; Iter   679/ 1097] train: loss: 0.0035583
[Epoch 74; Iter   709/ 1097] train: loss: 0.0537903
[Epoch 74; Iter   739/ 1097] train: loss: 0.0106764
[Epoch 74; Iter   769/ 1097] train: loss: 0.0182515
[Epoch 74; Iter   799/ 1097] train: loss: 0.0073586
[Epoch 74; Iter   829/ 1097] train: loss: 0.0462825
[Epoch 74; Iter   859/ 1097] train: loss: 0.1206758
[Epoch 74; Iter   889/ 1097] train: loss: 0.0809459
[Epoch 74; Iter   919/ 1097] train: loss: 0.0060776
[Epoch 74; Iter   949/ 1097] train: loss: 0.0096968
[Epoch 74; Iter   979/ 1097] train: loss: 0.0037997
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0140943
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0058903
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0091479
[Epoch 74] ogbg-molhiv: 0.786314 val loss: 0.126199
[Epoch 74] ogbg-molhiv: 0.750470 test loss: 0.239131
[Epoch 75; Iter     2/ 1097] train: loss: 0.0022341
[Epoch 75; Iter    32/ 1097] train: loss: 0.0035731
[Epoch 75; Iter    62/ 1097] train: loss: 0.0078807
[Epoch 75; Iter    92/ 1097] train: loss: 0.0255987
[Epoch 75; Iter   122/ 1097] train: loss: 0.0504025
[Epoch 75; Iter   152/ 1097] train: loss: 0.0064257
[Epoch 75; Iter   182/ 1097] train: loss: 0.0143101
[Epoch 75; Iter   212/ 1097] train: loss: 0.0991364
[Epoch 75; Iter   242/ 1097] train: loss: 0.0249663
[Epoch 75; Iter   272/ 1097] train: loss: 0.0175265
[Epoch 75; Iter   302/ 1097] train: loss: 0.0097509
[Epoch 75; Iter   332/ 1097] train: loss: 0.1719492
[Epoch 75; Iter   362/ 1097] train: loss: 0.0156665
[Epoch 75; Iter   392/ 1097] train: loss: 0.0210808
[Epoch 75; Iter   422/ 1097] train: loss: 0.0150904
[Epoch 75; Iter   452/ 1097] train: loss: 0.0329264
[Epoch 75; Iter   482/ 1097] train: loss: 0.0777721
[Epoch 75; Iter   512/ 1097] train: loss: 0.0092786
[Epoch 75; Iter   542/ 1097] train: loss: 0.0510602
[Epoch 75; Iter   572/ 1097] train: loss: 0.0038094
[Epoch 75; Iter   602/ 1097] train: loss: 0.0083388
[Epoch 75; Iter   632/ 1097] train: loss: 0.0569840
[Epoch 75; Iter   662/ 1097] train: loss: 0.0472911
[Epoch 75; Iter   692/ 1097] train: loss: 0.0151008
[Epoch 75; Iter   722/ 1097] train: loss: 0.0884133
[Epoch 75; Iter   752/ 1097] train: loss: 0.2545704
[Epoch 75; Iter   782/ 1097] train: loss: 0.0734814
[Epoch 75; Iter   812/ 1097] train: loss: 0.0429590
[Epoch 75; Iter   842/ 1097] train: loss: 0.0028784
[Epoch 75; Iter   872/ 1097] train: loss: 0.0028402
[Epoch 75; Iter   902/ 1097] train: loss: 0.0286974
[Epoch 75; Iter   932/ 1097] train: loss: 0.0060008
[Epoch 75; Iter   962/ 1097] train: loss: 0.0763938
[Epoch 75; Iter   992/ 1097] train: loss: 0.0580939
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0113704
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0148433
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0448082
[Epoch 75] ogbg-molhiv: 0.789664 val loss: 0.115462
[Epoch 75] ogbg-molhiv: 0.739074 test loss: 0.225235
[Epoch 76; Iter    15/ 1097] train: loss: 0.0439703
[Epoch 76; Iter    45/ 1097] train: loss: 0.0276738
[Epoch 76; Iter    75/ 1097] train: loss: 0.0363623
[Epoch 76; Iter   105/ 1097] train: loss: 0.0021272
[Epoch 76; Iter   135/ 1097] train: loss: 0.0617491
[Epoch 76; Iter   165/ 1097] train: loss: 0.0129693
[Epoch 76; Iter   195/ 1097] train: loss: 0.0046096
[Epoch 76; Iter   225/ 1097] train: loss: 0.0023630
[Epoch 76; Iter   255/ 1097] train: loss: 0.0020130
[Epoch 76; Iter   285/ 1097] train: loss: 0.0078538
[Epoch 76; Iter   315/ 1097] train: loss: 0.0393257
[Epoch 76; Iter   345/ 1097] train: loss: 0.0113747
[Epoch 76; Iter   375/ 1097] train: loss: 0.0079510
[Epoch 76; Iter   405/ 1097] train: loss: 0.0201764
[Epoch 76; Iter   435/ 1097] train: loss: 0.0251097
[Epoch 76; Iter   465/ 1097] train: loss: 0.0556951
[Epoch 76; Iter   495/ 1097] train: loss: 0.0021454
[Epoch 76; Iter   525/ 1097] train: loss: 0.0652919
[Epoch 76; Iter   555/ 1097] train: loss: 0.0010317
[Epoch 76; Iter   585/ 1097] train: loss: 0.0341553
[Epoch 76; Iter   615/ 1097] train: loss: 0.0480583
[Epoch 76; Iter   645/ 1097] train: loss: 0.0148860
[Epoch 76; Iter   675/ 1097] train: loss: 0.2386933
[Epoch 76; Iter   705/ 1097] train: loss: 0.0120889
[Epoch 76; Iter   735/ 1097] train: loss: 0.0407704
[Epoch 76; Iter   765/ 1097] train: loss: 0.0544962
[Epoch 76; Iter   795/ 1097] train: loss: 0.0098721
[Epoch 76; Iter   825/ 1097] train: loss: 0.0051344
[Epoch 76; Iter   855/ 1097] train: loss: 0.0056863
[Epoch 76; Iter   885/ 1097] train: loss: 0.0709223
[Epoch 76; Iter   915/ 1097] train: loss: 0.0116261
[Epoch 76; Iter   945/ 1097] train: loss: 0.2427253
[Epoch 76; Iter   975/ 1097] train: loss: 0.0119581
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0062064
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0653855
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0915846
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0079158
[Epoch 76] ogbg-molhiv: 0.803991 val loss: 0.118378
[Epoch 76] ogbg-molhiv: 0.741401 test loss: 0.234060
[Epoch 77; Iter    28/ 1097] train: loss: 0.0217423
[Epoch 77; Iter    58/ 1097] train: loss: 0.0907131
[Epoch 77; Iter    88/ 1097] train: loss: 0.0938803
[Epoch 77; Iter   118/ 1097] train: loss: 0.0013687
[Epoch 77; Iter   148/ 1097] train: loss: 0.0149229
[Epoch 77; Iter   178/ 1097] train: loss: 0.0172267
[Epoch 77; Iter   208/ 1097] train: loss: 0.0056203
[Epoch 77; Iter   238/ 1097] train: loss: 0.0015792
[Epoch 93; Iter   596/ 1097] train: loss: 0.0000133
[Epoch 93; Iter   626/ 1097] train: loss: 0.0007074
[Epoch 93; Iter   656/ 1097] train: loss: 0.0003108
[Epoch 93; Iter   686/ 1097] train: loss: 0.0000125
[Epoch 93; Iter   716/ 1097] train: loss: 0.0000017
[Epoch 93; Iter   746/ 1097] train: loss: 0.0001297
[Epoch 93; Iter   776/ 1097] train: loss: 0.0081083
[Epoch 93; Iter   806/ 1097] train: loss: 0.0000443
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000754
[Epoch 93; Iter   866/ 1097] train: loss: 0.0000395
[Epoch 93; Iter   896/ 1097] train: loss: 0.0000080
[Epoch 93; Iter   926/ 1097] train: loss: 0.0006256
[Epoch 93; Iter   956/ 1097] train: loss: 0.0000038
[Epoch 93; Iter   986/ 1097] train: loss: 0.0011159
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000122
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0000022
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0000392
[Epoch 93] ogbg-molhiv: 0.797668 val loss: 0.407748
[Epoch 93] ogbg-molhiv: 0.811478 test loss: 0.334464
[Epoch 94; Iter     9/ 1097] train: loss: 0.0001691
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000561
[Epoch 94; Iter    69/ 1097] train: loss: 0.0008657
[Epoch 94; Iter    99/ 1097] train: loss: 0.0006640
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000361
[Epoch 94; Iter   159/ 1097] train: loss: 0.0025207
[Epoch 94; Iter   189/ 1097] train: loss: 0.0000093
[Epoch 94; Iter   219/ 1097] train: loss: 0.0000466
[Epoch 94; Iter   249/ 1097] train: loss: 0.0001874
[Epoch 94; Iter   279/ 1097] train: loss: 0.0000154
[Epoch 94; Iter   309/ 1097] train: loss: 0.0001680
[Epoch 94; Iter   339/ 1097] train: loss: 0.0013234
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000927
[Epoch 94; Iter   399/ 1097] train: loss: 0.0000452
[Epoch 94; Iter   429/ 1097] train: loss: 0.0007193
[Epoch 94; Iter   459/ 1097] train: loss: 0.0001516
[Epoch 94; Iter   489/ 1097] train: loss: 0.0001466
[Epoch 94; Iter   519/ 1097] train: loss: 0.0000429
[Epoch 94; Iter   549/ 1097] train: loss: 0.0000608
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000006
[Epoch 94; Iter   609/ 1097] train: loss: 0.0000895
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000007
[Epoch 94; Iter   669/ 1097] train: loss: 0.0007140
[Epoch 94; Iter   699/ 1097] train: loss: 0.0000207
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000336
[Epoch 94; Iter   759/ 1097] train: loss: 0.0000113
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000128
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000207
[Epoch 94; Iter   849/ 1097] train: loss: 0.0000800
[Epoch 94; Iter   879/ 1097] train: loss: 0.0000369
[Epoch 94; Iter   909/ 1097] train: loss: 0.0004842
[Epoch 94; Iter   939/ 1097] train: loss: 0.0000053
[Epoch 94; Iter   969/ 1097] train: loss: 0.0068555
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000038
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0000084
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000258
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0000642
[Epoch 94] ogbg-molhiv: 0.791905 val loss: 0.477063
[Epoch 94] ogbg-molhiv: 0.794606 test loss: 0.354101
[Epoch 95; Iter    22/ 1097] train: loss: 0.0000149
[Epoch 95; Iter    52/ 1097] train: loss: 0.0001455
[Epoch 95; Iter    82/ 1097] train: loss: 0.0013120
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000379
[Epoch 95; Iter   142/ 1097] train: loss: 0.0000196
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000846
[Epoch 95; Iter   202/ 1097] train: loss: 0.0000074
[Epoch 95; Iter   232/ 1097] train: loss: 0.0000092
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000269
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000203
[Epoch 95; Iter   322/ 1097] train: loss: 0.0008530
[Epoch 95; Iter   352/ 1097] train: loss: 0.0000384
[Epoch 95; Iter   382/ 1097] train: loss: 0.0000066
[Epoch 95; Iter   412/ 1097] train: loss: 0.0000947
[Epoch 95; Iter   442/ 1097] train: loss: 0.0002742
[Epoch 95; Iter   472/ 1097] train: loss: 0.0031330
[Epoch 95; Iter   502/ 1097] train: loss: 0.0000054
[Epoch 95; Iter   532/ 1097] train: loss: 0.0000236
[Epoch 95; Iter   562/ 1097] train: loss: 0.0000076
[Epoch 95; Iter   592/ 1097] train: loss: 0.0003355
[Epoch 95; Iter   622/ 1097] train: loss: 0.0000222
[Epoch 95; Iter   652/ 1097] train: loss: 0.0000125
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000407
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000031
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000444
[Epoch 95; Iter   772/ 1097] train: loss: 0.0000637
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000341
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000052
[Epoch 95; Iter   862/ 1097] train: loss: 0.0000384
[Epoch 95; Iter   892/ 1097] train: loss: 0.0007408
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000043
[Epoch 95; Iter   952/ 1097] train: loss: 0.0000086
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000689
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0004641
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0000884
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0000154
[Epoch 95] ogbg-molhiv: 0.794410 val loss: 0.491334
[Epoch 95] ogbg-molhiv: 0.808586 test loss: 0.341665
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000028
[Epoch 96; Iter    35/ 1097] train: loss: 0.0002089
[Epoch 96; Iter    65/ 1097] train: loss: 0.0000071
[Epoch 96; Iter    95/ 1097] train: loss: 0.0000192
[Epoch 96; Iter   125/ 1097] train: loss: 0.0088792
[Epoch 96; Iter   155/ 1097] train: loss: 0.0000125
[Epoch 96; Iter   185/ 1097] train: loss: 0.0003136
[Epoch 96; Iter   215/ 1097] train: loss: 0.0004038
[Epoch 96; Iter   245/ 1097] train: loss: 0.0000312
[Epoch 96; Iter   275/ 1097] train: loss: 0.0002584
[Epoch 96; Iter   305/ 1097] train: loss: 0.0007390
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000978
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000057
[Epoch 96; Iter   395/ 1097] train: loss: 0.0000150
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000805
[Epoch 96; Iter   455/ 1097] train: loss: 0.0000153
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000222
[Epoch 96; Iter   515/ 1097] train: loss: 0.0000071
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000054
[Epoch 96; Iter   575/ 1097] train: loss: 0.0001764
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000127
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000183
[Epoch 96; Iter   665/ 1097] train: loss: 0.0002038
[Epoch 96; Iter   695/ 1097] train: loss: 0.0000160
[Epoch 96; Iter   725/ 1097] train: loss: 0.0000107
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000052
[Epoch 96; Iter   785/ 1097] train: loss: 0.0000109
[Epoch 96; Iter   815/ 1097] train: loss: 0.0000019
[Epoch 96; Iter   845/ 1097] train: loss: 0.0001053
[Epoch 96; Iter   875/ 1097] train: loss: 0.0000415
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000189
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000017
[Epoch 96; Iter   965/ 1097] train: loss: 0.0000264
[Epoch 96; Iter   995/ 1097] train: loss: 0.0000031
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0007471
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000290
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0000797
[Epoch 96] ogbg-molhiv: 0.801064 val loss: 0.458833
[Epoch 96] ogbg-molhiv: 0.809809 test loss: 0.324944
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000510
[Epoch 97; Iter    48/ 1097] train: loss: 0.0002390
[Epoch 97; Iter    78/ 1097] train: loss: 0.0000471
[Epoch 97; Iter   108/ 1097] train: loss: 0.0001194
[Epoch 97; Iter   138/ 1097] train: loss: 0.0000172
[Epoch 97; Iter   168/ 1097] train: loss: 0.0000724
[Epoch 97; Iter   198/ 1097] train: loss: 0.0000054
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000323
[Epoch 97; Iter   258/ 1097] train: loss: 0.0000129
[Epoch 97; Iter   288/ 1097] train: loss: 0.0002118
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000055
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000052
[Epoch 97; Iter   378/ 1097] train: loss: 0.0000026
[Epoch 97; Iter   408/ 1097] train: loss: 0.0000144
[Epoch 97; Iter   438/ 1097] train: loss: 0.0000097
[Epoch 97; Iter   468/ 1097] train: loss: 0.0001083
[Epoch 97; Iter   498/ 1097] train: loss: 0.0002755
[Epoch 97; Iter   528/ 1097] train: loss: 0.0001008
[Epoch 97; Iter   558/ 1097] train: loss: 0.0000807
[Epoch 97; Iter   588/ 1097] train: loss: 0.0000150
[Epoch 97; Iter   618/ 1097] train: loss: 0.0045735
[Epoch 97; Iter   648/ 1097] train: loss: 0.0001731
[Epoch 93; Iter   596/ 1097] train: loss: 0.0164665
[Epoch 93; Iter   626/ 1097] train: loss: 0.0000393
[Epoch 93; Iter   656/ 1097] train: loss: 0.0000233
[Epoch 93; Iter   686/ 1097] train: loss: 0.0000332
[Epoch 93; Iter   716/ 1097] train: loss: 0.0008883
[Epoch 93; Iter   746/ 1097] train: loss: 0.0000695
[Epoch 93; Iter   776/ 1097] train: loss: 0.0000075
[Epoch 93; Iter   806/ 1097] train: loss: 0.0000065
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000128
[Epoch 93; Iter   866/ 1097] train: loss: 0.0000002
[Epoch 93; Iter   896/ 1097] train: loss: 0.0000160
[Epoch 93; Iter   926/ 1097] train: loss: 0.0000491
[Epoch 93; Iter   956/ 1097] train: loss: 0.0000019
[Epoch 93; Iter   986/ 1097] train: loss: 0.0000287
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000124
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0013199
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0000024
[Epoch 93] ogbg-molhiv: 0.697464 val loss: 2.891152
[Epoch 93] ogbg-molhiv: 0.594421 test loss: 3.170664
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000006
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000117
[Epoch 94; Iter    69/ 1097] train: loss: 0.0000101
[Epoch 94; Iter    99/ 1097] train: loss: 0.0000039
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000196
[Epoch 94; Iter   159/ 1097] train: loss: 0.0000591
[Epoch 94; Iter   189/ 1097] train: loss: 0.0008931
[Epoch 94; Iter   219/ 1097] train: loss: 0.0000032
[Epoch 94; Iter   249/ 1097] train: loss: 0.0000032
[Epoch 94; Iter   279/ 1097] train: loss: 0.0069249
[Epoch 94; Iter   309/ 1097] train: loss: 0.0011380
[Epoch 94; Iter   339/ 1097] train: loss: 0.0000074
[Epoch 94; Iter   369/ 1097] train: loss: 0.0000230
[Epoch 94; Iter   399/ 1097] train: loss: 0.0000123
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000977
[Epoch 94; Iter   459/ 1097] train: loss: 0.0000006
[Epoch 94; Iter   489/ 1097] train: loss: 0.0000122
[Epoch 94; Iter   519/ 1097] train: loss: 0.0000359
[Epoch 94; Iter   549/ 1097] train: loss: 0.0000067
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000124
[Epoch 94; Iter   609/ 1097] train: loss: 0.0005137
[Epoch 94; Iter   639/ 1097] train: loss: 0.0000044
[Epoch 94; Iter   669/ 1097] train: loss: 0.0000035
[Epoch 94; Iter   699/ 1097] train: loss: 0.0000032
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000472
[Epoch 94; Iter   759/ 1097] train: loss: 0.0000646
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000566
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000132
[Epoch 94; Iter   849/ 1097] train: loss: 0.0000006
[Epoch 94; Iter   879/ 1097] train: loss: 0.0000089
[Epoch 94; Iter   909/ 1097] train: loss: 0.0009015
[Epoch 94; Iter   939/ 1097] train: loss: 0.0000694
[Epoch 94; Iter   969/ 1097] train: loss: 0.0000085
[Epoch 94; Iter   999/ 1097] train: loss: 0.0001648
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0005076
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000303
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0000442
[Epoch 94] ogbg-molhiv: 0.692417 val loss: 1.558457
[Epoch 94] ogbg-molhiv: 0.621536 test loss: 2.458275
[Epoch 95; Iter    22/ 1097] train: loss: 0.0000022
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000126
[Epoch 95; Iter    82/ 1097] train: loss: 0.0019521
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000294
[Epoch 95; Iter   142/ 1097] train: loss: 0.0000409
[Epoch 95; Iter   172/ 1097] train: loss: 0.0000018
[Epoch 95; Iter   202/ 1097] train: loss: 0.0027936
[Epoch 95; Iter   232/ 1097] train: loss: 0.0001620
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000041
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000349
[Epoch 95; Iter   322/ 1097] train: loss: 0.0001609
[Epoch 95; Iter   352/ 1097] train: loss: 0.0000006
[Epoch 95; Iter   382/ 1097] train: loss: 0.0004888
[Epoch 95; Iter   412/ 1097] train: loss: 0.0005681
[Epoch 95; Iter   442/ 1097] train: loss: 0.0000050
[Epoch 95; Iter   472/ 1097] train: loss: 0.0000165
[Epoch 95; Iter   502/ 1097] train: loss: 0.0000151
[Epoch 95; Iter   532/ 1097] train: loss: 0.0000069
[Epoch 95; Iter   562/ 1097] train: loss: 0.0000060
[Epoch 95; Iter   592/ 1097] train: loss: 0.0000080
[Epoch 95; Iter   622/ 1097] train: loss: 0.0000027
[Epoch 95; Iter   652/ 1097] train: loss: 0.0002312
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000112
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000036
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000108
[Epoch 95; Iter   772/ 1097] train: loss: 0.0000082
[Epoch 95; Iter   802/ 1097] train: loss: 0.0000394
[Epoch 95; Iter   832/ 1097] train: loss: 0.0000199
[Epoch 95; Iter   862/ 1097] train: loss: 0.0004736
[Epoch 95; Iter   892/ 1097] train: loss: 0.0000236
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000105
[Epoch 95; Iter   952/ 1097] train: loss: 0.0000160
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000024
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0245671
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0000783
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0000078
[Epoch 95] ogbg-molhiv: 0.680595 val loss: 1.454769
[Epoch 95] ogbg-molhiv: 0.627532 test loss: 2.543610
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000002
[Epoch 96; Iter    35/ 1097] train: loss: 0.0000587
[Epoch 96; Iter    65/ 1097] train: loss: 0.0000274
[Epoch 96; Iter    95/ 1097] train: loss: 0.0000298
[Epoch 96; Iter   125/ 1097] train: loss: 0.0000012
[Epoch 96; Iter   155/ 1097] train: loss: 0.0000001
[Epoch 96; Iter   185/ 1097] train: loss: 0.0004943
[Epoch 96; Iter   215/ 1097] train: loss: 0.0001348
[Epoch 96; Iter   245/ 1097] train: loss: 0.0001564
[Epoch 96; Iter   275/ 1097] train: loss: 0.0000179
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000001
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000011
[Epoch 96; Iter   365/ 1097] train: loss: 0.0039428
[Epoch 96; Iter   395/ 1097] train: loss: 0.0000157
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000398
[Epoch 96; Iter   455/ 1097] train: loss: 0.0001089
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000034
[Epoch 96; Iter   515/ 1097] train: loss: 0.0001568
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000075
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000072
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000787
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000044
[Epoch 96; Iter   665/ 1097] train: loss: 0.0000005
[Epoch 96; Iter   695/ 1097] train: loss: 0.0000110
[Epoch 96; Iter   725/ 1097] train: loss: 0.0002092
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000201
[Epoch 96; Iter   785/ 1097] train: loss: 0.0000052
[Epoch 96; Iter   815/ 1097] train: loss: 0.0002710
[Epoch 96; Iter   845/ 1097] train: loss: 0.0000095
[Epoch 96; Iter   875/ 1097] train: loss: 0.0001183
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000026
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000047
[Epoch 96; Iter   965/ 1097] train: loss: 0.0000123
[Epoch 96; Iter   995/ 1097] train: loss: 0.0000030
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0015056
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0004405
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0002409
[Epoch 96] ogbg-molhiv: 0.689227 val loss: 1.906441
[Epoch 96] ogbg-molhiv: 0.604961 test loss: 2.935021
[Epoch 97; Iter    18/ 1097] train: loss: 0.0004007
[Epoch 97; Iter    48/ 1097] train: loss: 0.0000099
[Epoch 97; Iter    78/ 1097] train: loss: 0.0000461
[Epoch 97; Iter   108/ 1097] train: loss: 0.0003239
[Epoch 97; Iter   138/ 1097] train: loss: 0.0036654
[Epoch 97; Iter   168/ 1097] train: loss: 0.0048729
[Epoch 97; Iter   198/ 1097] train: loss: 0.0000044
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000026
[Epoch 97; Iter   258/ 1097] train: loss: 0.0008160
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000073
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000017
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000435
[Epoch 97; Iter   378/ 1097] train: loss: 0.0000159
[Epoch 97; Iter   408/ 1097] train: loss: 0.0001216
[Epoch 97; Iter   438/ 1097] train: loss: 0.0000038
[Epoch 97; Iter   468/ 1097] train: loss: 0.0000236
[Epoch 97; Iter   498/ 1097] train: loss: 0.0000421
[Epoch 97; Iter   528/ 1097] train: loss: 0.0000136
[Epoch 97; Iter   558/ 1097] train: loss: 0.0000053
[Epoch 97; Iter   588/ 1097] train: loss: 0.0000121
[Epoch 97; Iter   618/ 1097] train: loss: 0.0003596
[Epoch 97; Iter   648/ 1097] train: loss: 0.0000409
[Epoch 93; Iter   596/ 1097] train: loss: 0.0001163
[Epoch 93; Iter   626/ 1097] train: loss: 0.0002525
[Epoch 93; Iter   656/ 1097] train: loss: 0.0000163
[Epoch 93; Iter   686/ 1097] train: loss: 0.0358226
[Epoch 93; Iter   716/ 1097] train: loss: 0.0019570
[Epoch 93; Iter   746/ 1097] train: loss: 0.0000162
[Epoch 93; Iter   776/ 1097] train: loss: 0.0005573
[Epoch 93; Iter   806/ 1097] train: loss: 0.0003433
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000100
[Epoch 93; Iter   866/ 1097] train: loss: 0.0001625
[Epoch 93; Iter   896/ 1097] train: loss: 0.0002130
[Epoch 93; Iter   926/ 1097] train: loss: 0.0000153
[Epoch 93; Iter   956/ 1097] train: loss: 0.0002017
[Epoch 93; Iter   986/ 1097] train: loss: 0.0000007
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0000013
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0002117
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0001023
[Epoch 93] ogbg-molhiv: 0.743769 val loss: 10.599953
[Epoch 93] ogbg-molhiv: 0.705261 test loss: 8.657856
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000029
[Epoch 94; Iter    39/ 1097] train: loss: 0.0000694
[Epoch 94; Iter    69/ 1097] train: loss: 0.0002927
[Epoch 94; Iter    99/ 1097] train: loss: 0.0000248
[Epoch 94; Iter   129/ 1097] train: loss: 0.0000347
[Epoch 94; Iter   159/ 1097] train: loss: 0.0028488
[Epoch 94; Iter   189/ 1097] train: loss: 0.0000167
[Epoch 94; Iter   219/ 1097] train: loss: 0.0000469
[Epoch 94; Iter   249/ 1097] train: loss: 0.0021006
[Epoch 94; Iter   279/ 1097] train: loss: 0.0000810
[Epoch 94; Iter   309/ 1097] train: loss: 0.0000002
[Epoch 94; Iter   339/ 1097] train: loss: 0.0000096
[Epoch 94; Iter   369/ 1097] train: loss: 0.0009350
[Epoch 94; Iter   399/ 1097] train: loss: 0.0000405
[Epoch 94; Iter   429/ 1097] train: loss: 0.0000011
[Epoch 94; Iter   459/ 1097] train: loss: 0.0001920
[Epoch 94; Iter   489/ 1097] train: loss: 0.0029705
[Epoch 94; Iter   519/ 1097] train: loss: 0.0000148
[Epoch 94; Iter   549/ 1097] train: loss: 0.0040642
[Epoch 94; Iter   579/ 1097] train: loss: 0.0000018
[Epoch 94; Iter   609/ 1097] train: loss: 0.0000031
[Epoch 94; Iter   639/ 1097] train: loss: 0.0003442
[Epoch 94; Iter   669/ 1097] train: loss: 0.0000148
[Epoch 94; Iter   699/ 1097] train: loss: 0.0000279
[Epoch 94; Iter   729/ 1097] train: loss: 0.0000445
[Epoch 94; Iter   759/ 1097] train: loss: 0.0000030
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000224
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000022
[Epoch 94; Iter   849/ 1097] train: loss: 0.0002048
[Epoch 94; Iter   879/ 1097] train: loss: 0.0001574
[Epoch 94; Iter   909/ 1097] train: loss: 0.0042520
[Epoch 94; Iter   939/ 1097] train: loss: 0.0004120
[Epoch 94; Iter   969/ 1097] train: loss: 0.0000871
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000203
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0000030
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0000141
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0000179
[Epoch 94] ogbg-molhiv: 0.764709 val loss: 1.365918
[Epoch 94] ogbg-molhiv: 0.731677 test loss: 2.632342
[Epoch 95; Iter    22/ 1097] train: loss: 0.0000172
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000540
[Epoch 95; Iter    82/ 1097] train: loss: 0.0002198
[Epoch 95; Iter   112/ 1097] train: loss: 0.0000367
[Epoch 95; Iter   142/ 1097] train: loss: 0.0076026
[Epoch 95; Iter   172/ 1097] train: loss: 0.0003213
[Epoch 95; Iter   202/ 1097] train: loss: 0.0014770
[Epoch 95; Iter   232/ 1097] train: loss: 0.0000079
[Epoch 95; Iter   262/ 1097] train: loss: 0.0000157
[Epoch 95; Iter   292/ 1097] train: loss: 0.0001411
[Epoch 95; Iter   322/ 1097] train: loss: 0.0001074
[Epoch 95; Iter   352/ 1097] train: loss: 0.0000459
[Epoch 95; Iter   382/ 1097] train: loss: 0.0000109
[Epoch 95; Iter   412/ 1097] train: loss: 0.0012932
[Epoch 95; Iter   442/ 1097] train: loss: 0.0000158
[Epoch 95; Iter   472/ 1097] train: loss: 0.0056629
[Epoch 95; Iter   502/ 1097] train: loss: 0.0000427
[Epoch 95; Iter   532/ 1097] train: loss: 0.0012343
[Epoch 95; Iter   562/ 1097] train: loss: 0.0000130
[Epoch 95; Iter   592/ 1097] train: loss: 0.0000196
[Epoch 95; Iter   622/ 1097] train: loss: 0.0000086
[Epoch 95; Iter   652/ 1097] train: loss: 0.0000015
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000707
[Epoch 95; Iter   712/ 1097] train: loss: 0.0000070
[Epoch 95; Iter   742/ 1097] train: loss: 0.0000015
[Epoch 95; Iter   772/ 1097] train: loss: 0.0001546
[Epoch 95; Iter   802/ 1097] train: loss: 0.0003181
[Epoch 95; Iter   832/ 1097] train: loss: 0.0006422
[Epoch 95; Iter   862/ 1097] train: loss: 0.0002155
[Epoch 95; Iter   892/ 1097] train: loss: 0.0000767
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000209
[Epoch 95; Iter   952/ 1097] train: loss: 0.0004674
[Epoch 95; Iter   982/ 1097] train: loss: 0.0000059
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0002469
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0014094
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0002163
[Epoch 95] ogbg-molhiv: 0.771516 val loss: 1.280021
[Epoch 95] ogbg-molhiv: 0.744491 test loss: 2.068885
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000568
[Epoch 96; Iter    35/ 1097] train: loss: 0.0000339
[Epoch 96; Iter    65/ 1097] train: loss: 0.0000339
[Epoch 96; Iter    95/ 1097] train: loss: 0.0001016
[Epoch 96; Iter   125/ 1097] train: loss: 0.0000546
[Epoch 96; Iter   155/ 1097] train: loss: 0.0000045
[Epoch 96; Iter   185/ 1097] train: loss: 0.0002133
[Epoch 96; Iter   215/ 1097] train: loss: 0.0000287
[Epoch 96; Iter   245/ 1097] train: loss: 0.0000073
[Epoch 96; Iter   275/ 1097] train: loss: 0.0000705
[Epoch 96; Iter   305/ 1097] train: loss: 0.0000665
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000206
[Epoch 96; Iter   365/ 1097] train: loss: 0.0001140
[Epoch 96; Iter   395/ 1097] train: loss: 0.0000124
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000028
[Epoch 96; Iter   455/ 1097] train: loss: 0.0001647
[Epoch 96; Iter   485/ 1097] train: loss: 0.0000034
[Epoch 96; Iter   515/ 1097] train: loss: 0.0000047
[Epoch 96; Iter   545/ 1097] train: loss: 0.0000141
[Epoch 96; Iter   575/ 1097] train: loss: 0.0000042
[Epoch 96; Iter   605/ 1097] train: loss: 0.0000003
[Epoch 96; Iter   635/ 1097] train: loss: 0.0000139
[Epoch 96; Iter   665/ 1097] train: loss: 0.0000259
[Epoch 96; Iter   695/ 1097] train: loss: 0.0000027
[Epoch 96; Iter   725/ 1097] train: loss: 0.0015030
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000499
[Epoch 96; Iter   785/ 1097] train: loss: 0.0000011
[Epoch 96; Iter   815/ 1097] train: loss: 0.0000009
[Epoch 96; Iter   845/ 1097] train: loss: 0.0006078
[Epoch 96; Iter   875/ 1097] train: loss: 0.0003472
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000162
[Epoch 96; Iter   935/ 1097] train: loss: 0.0000022
[Epoch 96; Iter   965/ 1097] train: loss: 0.0023462
[Epoch 96; Iter   995/ 1097] train: loss: 0.0000223
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0000590
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000003
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0000245
[Epoch 96] ogbg-molhiv: 0.744727 val loss: 0.550564
[Epoch 96] ogbg-molhiv: 0.734029 test loss: 1.169213
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000105
[Epoch 97; Iter    48/ 1097] train: loss: 0.0001714
[Epoch 97; Iter    78/ 1097] train: loss: 0.0000031
[Epoch 97; Iter   108/ 1097] train: loss: 0.0000191
[Epoch 97; Iter   138/ 1097] train: loss: 0.0005017
[Epoch 97; Iter   168/ 1097] train: loss: 0.0013393
[Epoch 97; Iter   198/ 1097] train: loss: 0.0000678
[Epoch 97; Iter   228/ 1097] train: loss: 0.0001321
[Epoch 97; Iter   258/ 1097] train: loss: 0.0000259
[Epoch 97; Iter   288/ 1097] train: loss: 0.0017705
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000098
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000083
[Epoch 97; Iter   378/ 1097] train: loss: 0.0000468
[Epoch 97; Iter   408/ 1097] train: loss: 0.0000133
[Epoch 97; Iter   438/ 1097] train: loss: 0.0004691
[Epoch 97; Iter   468/ 1097] train: loss: 0.0000738
[Epoch 97; Iter   498/ 1097] train: loss: 0.0000017
[Epoch 97; Iter   528/ 1097] train: loss: 0.0000323
[Epoch 97; Iter   558/ 1097] train: loss: 0.0000040
[Epoch 97; Iter   588/ 1097] train: loss: 0.0000856
[Epoch 97; Iter   618/ 1097] train: loss: 0.0000060
[Epoch 97; Iter   648/ 1097] train: loss: 0.0012090
[Epoch 93; Iter   596/ 1097] train: loss: 0.0000302
[Epoch 93; Iter   626/ 1097] train: loss: 0.0006734
[Epoch 93; Iter   656/ 1097] train: loss: 0.0028210
[Epoch 93; Iter   686/ 1097] train: loss: 0.0001360
[Epoch 93; Iter   716/ 1097] train: loss: 0.0021473
[Epoch 93; Iter   746/ 1097] train: loss: 0.0009643
[Epoch 93; Iter   776/ 1097] train: loss: 0.0011984
[Epoch 93; Iter   806/ 1097] train: loss: 0.0028217
[Epoch 93; Iter   836/ 1097] train: loss: 0.0000785
[Epoch 93; Iter   866/ 1097] train: loss: 0.0000646
[Epoch 93; Iter   896/ 1097] train: loss: 0.0006411
[Epoch 93; Iter   926/ 1097] train: loss: 0.0049118
[Epoch 93; Iter   956/ 1097] train: loss: 0.0010921
[Epoch 93; Iter   986/ 1097] train: loss: 0.0001466
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0004765
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0001550
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0002634
[Epoch 93] ogbg-molhiv: 0.725606 val loss: 36.863755
[Epoch 93] ogbg-molhiv: 0.616389 test loss: 25.545649
[Epoch 94; Iter     9/ 1097] train: loss: 0.0000888
[Epoch 94; Iter    39/ 1097] train: loss: 0.0003543
[Epoch 94; Iter    69/ 1097] train: loss: 0.0000402
[Epoch 94; Iter    99/ 1097] train: loss: 0.0001399
[Epoch 94; Iter   129/ 1097] train: loss: 0.0023864
[Epoch 94; Iter   159/ 1097] train: loss: 0.0000429
[Epoch 94; Iter   189/ 1097] train: loss: 0.0006099
[Epoch 94; Iter   219/ 1097] train: loss: 0.0667904
[Epoch 94; Iter   249/ 1097] train: loss: 0.0003831
[Epoch 94; Iter   279/ 1097] train: loss: 0.0004036
[Epoch 94; Iter   309/ 1097] train: loss: 0.0008738
[Epoch 94; Iter   339/ 1097] train: loss: 0.0000589
[Epoch 94; Iter   369/ 1097] train: loss: 0.0013242
[Epoch 94; Iter   399/ 1097] train: loss: 0.0000110
[Epoch 94; Iter   429/ 1097] train: loss: 0.0002268
[Epoch 94; Iter   459/ 1097] train: loss: 0.0039777
[Epoch 94; Iter   489/ 1097] train: loss: 0.0004472
[Epoch 94; Iter   519/ 1097] train: loss: 0.0007546
[Epoch 94; Iter   549/ 1097] train: loss: 0.0451359
[Epoch 94; Iter   579/ 1097] train: loss: 0.0003140
[Epoch 94; Iter   609/ 1097] train: loss: 0.0031017
[Epoch 94; Iter   639/ 1097] train: loss: 0.0004559
[Epoch 94; Iter   669/ 1097] train: loss: 0.0003724
[Epoch 94; Iter   699/ 1097] train: loss: 0.0000782
[Epoch 94; Iter   729/ 1097] train: loss: 0.0001539
[Epoch 94; Iter   759/ 1097] train: loss: 0.0213733
[Epoch 94; Iter   789/ 1097] train: loss: 0.0000217
[Epoch 94; Iter   819/ 1097] train: loss: 0.0000052
[Epoch 94; Iter   849/ 1097] train: loss: 0.0005216
[Epoch 94; Iter   879/ 1097] train: loss: 0.0006095
[Epoch 94; Iter   909/ 1097] train: loss: 0.0024524
[Epoch 94; Iter   939/ 1097] train: loss: 0.0000776
[Epoch 94; Iter   969/ 1097] train: loss: 0.0012361
[Epoch 94; Iter   999/ 1097] train: loss: 0.0000105
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0000175
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0008373
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0227430
[Epoch 94] ogbg-molhiv: 0.730872 val loss: 68.272855
[Epoch 94] ogbg-molhiv: 0.607951 test loss: 53.442647
[Epoch 95; Iter    22/ 1097] train: loss: 0.0000278
[Epoch 95; Iter    52/ 1097] train: loss: 0.0000156
[Epoch 95; Iter    82/ 1097] train: loss: 0.0000245
[Epoch 95; Iter   112/ 1097] train: loss: 0.0118827
[Epoch 95; Iter   142/ 1097] train: loss: 0.0000290
[Epoch 95; Iter   172/ 1097] train: loss: 0.0277379
[Epoch 95; Iter   202/ 1097] train: loss: 0.0006100
[Epoch 95; Iter   232/ 1097] train: loss: 0.0009099
[Epoch 95; Iter   262/ 1097] train: loss: 0.0002991
[Epoch 95; Iter   292/ 1097] train: loss: 0.0000057
[Epoch 95; Iter   322/ 1097] train: loss: 0.0003941
[Epoch 95; Iter   352/ 1097] train: loss: 0.0006401
[Epoch 95; Iter   382/ 1097] train: loss: 0.0000655
[Epoch 95; Iter   412/ 1097] train: loss: 0.0000718
[Epoch 95; Iter   442/ 1097] train: loss: 0.0002190
[Epoch 95; Iter   472/ 1097] train: loss: 0.2292276
[Epoch 95; Iter   502/ 1097] train: loss: 0.0000765
[Epoch 95; Iter   532/ 1097] train: loss: 0.0017214
[Epoch 95; Iter   562/ 1097] train: loss: 0.0076391
[Epoch 95; Iter   592/ 1097] train: loss: 0.0012194
[Epoch 95; Iter   622/ 1097] train: loss: 0.0009284
[Epoch 95; Iter   652/ 1097] train: loss: 0.0003070
[Epoch 95; Iter   682/ 1097] train: loss: 0.0000125
[Epoch 95; Iter   712/ 1097] train: loss: 0.0005234
[Epoch 95; Iter   742/ 1097] train: loss: 0.0031965
[Epoch 95; Iter   772/ 1097] train: loss: 0.0008421
[Epoch 95; Iter   802/ 1097] train: loss: 0.0001907
[Epoch 95; Iter   832/ 1097] train: loss: 0.0003185
[Epoch 95; Iter   862/ 1097] train: loss: 0.0009631
[Epoch 95; Iter   892/ 1097] train: loss: 0.0001846
[Epoch 95; Iter   922/ 1097] train: loss: 0.0000159
[Epoch 95; Iter   952/ 1097] train: loss: 0.0003354
[Epoch 95; Iter   982/ 1097] train: loss: 0.0062228
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0000102
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0005672
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0001349
[Epoch 95] ogbg-molhiv: 0.673241 val loss: 62.948892
[Epoch 95] ogbg-molhiv: 0.583941 test loss: 47.098317
[Epoch 96; Iter     5/ 1097] train: loss: 0.0000192
[Epoch 96; Iter    35/ 1097] train: loss: 0.0001047
[Epoch 96; Iter    65/ 1097] train: loss: 0.0000673
[Epoch 96; Iter    95/ 1097] train: loss: 0.0000430
[Epoch 96; Iter   125/ 1097] train: loss: 0.0002497
[Epoch 96; Iter   155/ 1097] train: loss: 0.0211346
[Epoch 96; Iter   185/ 1097] train: loss: 0.0000389
[Epoch 96; Iter   215/ 1097] train: loss: 0.0002622
[Epoch 96; Iter   245/ 1097] train: loss: 0.0002310
[Epoch 96; Iter   275/ 1097] train: loss: 0.2004024
[Epoch 96; Iter   305/ 1097] train: loss: 0.0001968
[Epoch 96; Iter   335/ 1097] train: loss: 0.0000159
[Epoch 96; Iter   365/ 1097] train: loss: 0.0000902
[Epoch 96; Iter   395/ 1097] train: loss: 0.0006498
[Epoch 96; Iter   425/ 1097] train: loss: 0.0000917
[Epoch 96; Iter   455/ 1097] train: loss: 0.0000808
[Epoch 96; Iter   485/ 1097] train: loss: 0.0007078
[Epoch 96; Iter   515/ 1097] train: loss: 0.0001124
[Epoch 96; Iter   545/ 1097] train: loss: 0.0012820
[Epoch 96; Iter   575/ 1097] train: loss: 0.0002617
[Epoch 96; Iter   605/ 1097] train: loss: 0.0005874
[Epoch 96; Iter   635/ 1097] train: loss: 0.0003329
[Epoch 96; Iter   665/ 1097] train: loss: 0.0050048
[Epoch 96; Iter   695/ 1097] train: loss: 0.0011488
[Epoch 96; Iter   725/ 1097] train: loss: 0.0000164
[Epoch 96; Iter   755/ 1097] train: loss: 0.0000546
[Epoch 96; Iter   785/ 1097] train: loss: 0.0000693
[Epoch 96; Iter   815/ 1097] train: loss: 0.0006479
[Epoch 96; Iter   845/ 1097] train: loss: 0.0000277
[Epoch 96; Iter   875/ 1097] train: loss: 0.0004126
[Epoch 96; Iter   905/ 1097] train: loss: 0.0000576
[Epoch 96; Iter   935/ 1097] train: loss: 0.0037228
[Epoch 96; Iter   965/ 1097] train: loss: 0.0001096
[Epoch 96; Iter   995/ 1097] train: loss: 0.0001524
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0003035
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0000592
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0092219
[Epoch 96] ogbg-molhiv: 0.710532 val loss: 43.074055
[Epoch 96] ogbg-molhiv: 0.629195 test loss: 31.971237
[Epoch 97; Iter    18/ 1097] train: loss: 0.0000826
[Epoch 97; Iter    48/ 1097] train: loss: 0.0035826
[Epoch 97; Iter    78/ 1097] train: loss: 0.0480017
[Epoch 97; Iter   108/ 1097] train: loss: 0.0342534
[Epoch 97; Iter   138/ 1097] train: loss: 0.0000765
[Epoch 97; Iter   168/ 1097] train: loss: 0.0001620
[Epoch 97; Iter   198/ 1097] train: loss: 0.0022367
[Epoch 97; Iter   228/ 1097] train: loss: 0.0000679
[Epoch 97; Iter   258/ 1097] train: loss: 0.0003778
[Epoch 97; Iter   288/ 1097] train: loss: 0.0000233
[Epoch 97; Iter   318/ 1097] train: loss: 0.0000275
[Epoch 97; Iter   348/ 1097] train: loss: 0.0000928
[Epoch 97; Iter   378/ 1097] train: loss: 0.0000142
[Epoch 97; Iter   408/ 1097] train: loss: 0.0002620
[Epoch 97; Iter   438/ 1097] train: loss: 0.0036514
[Epoch 97; Iter   468/ 1097] train: loss: 0.0001392
[Epoch 97; Iter   498/ 1097] train: loss: 0.0002862
[Epoch 97; Iter   528/ 1097] train: loss: 0.0016439
[Epoch 97; Iter   558/ 1097] train: loss: 0.0006681
[Epoch 97; Iter   588/ 1097] train: loss: 0.0003583
[Epoch 97; Iter   618/ 1097] train: loss: 0.0103821
[Epoch 97; Iter   648/ 1097] train: loss: 0.0007659
[Epoch 97; Iter   678/ 1097] train: loss: 0.0000050
[Epoch 97; Iter   708/ 1097] train: loss: 0.0000276
[Epoch 97; Iter   738/ 1097] train: loss: 0.0200201
[Epoch 97; Iter   768/ 1097] train: loss: 0.0002416
[Epoch 97; Iter   798/ 1097] train: loss: 0.0013997
[Epoch 97; Iter   828/ 1097] train: loss: 0.0002729
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000290
[Epoch 97; Iter   888/ 1097] train: loss: 0.0002630
[Epoch 97; Iter   918/ 1097] train: loss: 0.0031862
[Epoch 97; Iter   948/ 1097] train: loss: 0.0008572
[Epoch 97; Iter   978/ 1097] train: loss: 0.0005580
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0073293
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0017859
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0002007
[Epoch 97] ogbg-molhiv: 0.716628 val loss: 1.834015
[Epoch 97] ogbg-molhiv: 0.725673 test loss: 1.302342
[Epoch 98; Iter     1/ 1097] train: loss: 0.0000352
[Epoch 98; Iter    31/ 1097] train: loss: 0.0017309
[Epoch 98; Iter    61/ 1097] train: loss: 0.0099864
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000306
[Epoch 98; Iter   121/ 1097] train: loss: 0.0002555
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000983
[Epoch 98; Iter   181/ 1097] train: loss: 0.0066730
[Epoch 98; Iter   211/ 1097] train: loss: 0.0001020
[Epoch 98; Iter   241/ 1097] train: loss: 0.0000328
[Epoch 98; Iter   271/ 1097] train: loss: 0.0004380
[Epoch 98; Iter   301/ 1097] train: loss: 0.0005962
[Epoch 98; Iter   331/ 1097] train: loss: 0.0002897
[Epoch 98; Iter   361/ 1097] train: loss: 0.0061905
[Epoch 98; Iter   391/ 1097] train: loss: 0.0001158
[Epoch 98; Iter   421/ 1097] train: loss: 0.0000574
[Epoch 98; Iter   451/ 1097] train: loss: 0.0001205
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000665
[Epoch 98; Iter   511/ 1097] train: loss: 0.0020287
[Epoch 98; Iter   541/ 1097] train: loss: 0.0001088
[Epoch 98; Iter   571/ 1097] train: loss: 0.0003963
[Epoch 98; Iter   601/ 1097] train: loss: 0.0002221
[Epoch 98; Iter   631/ 1097] train: loss: 0.0000223
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000548
[Epoch 98; Iter   691/ 1097] train: loss: 0.0019422
[Epoch 98; Iter   721/ 1097] train: loss: 0.0006256
[Epoch 98; Iter   751/ 1097] train: loss: 0.0000149
[Epoch 98; Iter   781/ 1097] train: loss: 0.0000329
[Epoch 98; Iter   811/ 1097] train: loss: 0.0001730
[Epoch 98; Iter   841/ 1097] train: loss: 0.0000575
[Epoch 98; Iter   871/ 1097] train: loss: 0.0000255
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000396
[Epoch 98; Iter   931/ 1097] train: loss: 0.0003242
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000200
[Epoch 98; Iter   991/ 1097] train: loss: 0.0004574
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0005890
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0004008
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0000247
[Epoch 98] ogbg-molhiv: 0.726653 val loss: 0.254560
[Epoch 98] ogbg-molhiv: 0.743871 test loss: 0.385388
[Epoch 99; Iter    14/ 1097] train: loss: 0.0031186
[Epoch 99; Iter    44/ 1097] train: loss: 0.0302374
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000275
[Epoch 99; Iter   104/ 1097] train: loss: 0.0000579
[Epoch 99; Iter   134/ 1097] train: loss: 0.0004882
[Epoch 99; Iter   164/ 1097] train: loss: 0.0001399
[Epoch 99; Iter   194/ 1097] train: loss: 0.0004605
[Epoch 99; Iter   224/ 1097] train: loss: 0.0000598
[Epoch 99; Iter   254/ 1097] train: loss: 0.0002373
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000317
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000489
[Epoch 99; Iter   344/ 1097] train: loss: 0.0001698
[Epoch 99; Iter   374/ 1097] train: loss: 0.0014639
[Epoch 99; Iter   404/ 1097] train: loss: 0.0058593
[Epoch 99; Iter   434/ 1097] train: loss: 0.0002179
[Epoch 99; Iter   464/ 1097] train: loss: 0.0002886
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000989
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000201
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000576
[Epoch 99; Iter   584/ 1097] train: loss: 0.0009414
[Epoch 99; Iter   614/ 1097] train: loss: 0.0004103
[Epoch 99; Iter   644/ 1097] train: loss: 0.0000239
[Epoch 99; Iter   674/ 1097] train: loss: 0.0052087
[Epoch 99; Iter   704/ 1097] train: loss: 0.0006384
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000532
[Epoch 99; Iter   764/ 1097] train: loss: 0.0003048
[Epoch 99; Iter   794/ 1097] train: loss: 0.0002207
[Epoch 99; Iter   824/ 1097] train: loss: 0.0252811
[Epoch 99; Iter   854/ 1097] train: loss: 0.0000217
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000561
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000672
[Epoch 99; Iter   944/ 1097] train: loss: 0.0002666
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000048
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000722
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0011449
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000318
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0003158
[Epoch 99] ogbg-molhiv: 0.745398 val loss: 1.155394
[Epoch 99] ogbg-molhiv: 0.719494 test loss: 0.907184
[Epoch 100; Iter    27/ 1097] train: loss: 0.0001733
[Epoch 100; Iter    57/ 1097] train: loss: 0.0000367
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000168
[Epoch 100; Iter   117/ 1097] train: loss: 0.0001133
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000669
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000349
[Epoch 100; Iter   207/ 1097] train: loss: 0.0000467
[Epoch 100; Iter   237/ 1097] train: loss: 0.0000649
[Epoch 100; Iter   267/ 1097] train: loss: 0.0156480
[Epoch 100; Iter   297/ 1097] train: loss: 0.0000704
[Epoch 100; Iter   327/ 1097] train: loss: 0.0146711
[Epoch 100; Iter   357/ 1097] train: loss: 0.1145357
[Epoch 100; Iter   387/ 1097] train: loss: 0.0004314
[Epoch 100; Iter   417/ 1097] train: loss: 0.0008750
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000095
[Epoch 100; Iter   477/ 1097] train: loss: 0.0003590
[Epoch 100; Iter   507/ 1097] train: loss: 0.0000172
[Epoch 100; Iter   537/ 1097] train: loss: 0.0022636
[Epoch 100; Iter   567/ 1097] train: loss: 0.0003938
[Epoch 100; Iter   597/ 1097] train: loss: 0.0003753
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000966
[Epoch 100; Iter   657/ 1097] train: loss: 0.0005331
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000945
[Epoch 100; Iter   717/ 1097] train: loss: 0.0001023
[Epoch 100; Iter   747/ 1097] train: loss: 0.0007094
[Epoch 100; Iter   777/ 1097] train: loss: 0.0000109
[Epoch 100; Iter   807/ 1097] train: loss: 0.0000498
[Epoch 100; Iter   837/ 1097] train: loss: 0.0123652
[Epoch 100; Iter   867/ 1097] train: loss: 0.0031207
[Epoch 100; Iter   897/ 1097] train: loss: 0.0000108
[Epoch 100; Iter   927/ 1097] train: loss: 0.0000432
[Epoch 100; Iter   957/ 1097] train: loss: 0.0314175
[Epoch 100; Iter   987/ 1097] train: loss: 0.0000341
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0074386
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0035259
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000651
[Epoch 100] ogbg-molhiv: 0.692512 val loss: 2.233268
[Epoch 100] ogbg-molhiv: 0.723805 test loss: 0.569750
[Epoch 101; Iter    10/ 1097] train: loss: 0.0000015
[Epoch 101; Iter    40/ 1097] train: loss: 0.0001068
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000560
[Epoch 101; Iter   100/ 1097] train: loss: 0.0096686
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000198
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000084
[Epoch 101; Iter   190/ 1097] train: loss: 0.0012432
[Epoch 101; Iter   220/ 1097] train: loss: 0.0002213
[Epoch 101; Iter   250/ 1097] train: loss: 0.0021316
[Epoch 101; Iter   280/ 1097] train: loss: 0.0000127
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000314
[Epoch 101; Iter   340/ 1097] train: loss: 0.0017357
[Epoch 101; Iter   370/ 1097] train: loss: 0.0001415
[Epoch 101; Iter   400/ 1097] train: loss: 0.0007380
[Epoch 101; Iter   430/ 1097] train: loss: 0.0002555
[Epoch 101; Iter   460/ 1097] train: loss: 0.0066762
[Epoch 101; Iter   490/ 1097] train: loss: 0.0002034
[Epoch 101; Iter   520/ 1097] train: loss: 0.0001865
[Epoch 101; Iter   550/ 1097] train: loss: 0.0000111
[Epoch 101; Iter   580/ 1097] train: loss: 0.0011450
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000313
[Epoch 101; Iter   640/ 1097] train: loss: 0.0000866
[Epoch 101; Iter   670/ 1097] train: loss: 0.0002852
[Epoch 101; Iter   700/ 1097] train: loss: 0.0245438
[Epoch 97; Iter   678/ 1097] train: loss: 0.0747548
[Epoch 97; Iter   708/ 1097] train: loss: 0.0000196
[Epoch 97; Iter   738/ 1097] train: loss: 0.0000025
[Epoch 97; Iter   768/ 1097] train: loss: 0.0000231
[Epoch 97; Iter   798/ 1097] train: loss: 0.0001478
[Epoch 97; Iter   828/ 1097] train: loss: 0.0022598
[Epoch 97; Iter   858/ 1097] train: loss: 0.0001724
[Epoch 97; Iter   888/ 1097] train: loss: 0.0004629
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000034
[Epoch 97; Iter   948/ 1097] train: loss: 0.0000519
[Epoch 97; Iter   978/ 1097] train: loss: 0.0000170
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000356
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0001987
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000586
[Epoch 97] ogbg-molhiv: 0.713079 val loss: 1.664959
[Epoch 97] ogbg-molhiv: 0.680817 test loss: 0.798627
[Epoch 98; Iter     1/ 1097] train: loss: 0.0003828
[Epoch 98; Iter    31/ 1097] train: loss: 0.0000597
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000218
[Epoch 98; Iter    91/ 1097] train: loss: 0.0006638
[Epoch 98; Iter   121/ 1097] train: loss: 0.0002200
[Epoch 98; Iter   151/ 1097] train: loss: 0.0003979
[Epoch 98; Iter   181/ 1097] train: loss: 0.0000058
[Epoch 98; Iter   211/ 1097] train: loss: 0.0000130
[Epoch 98; Iter   241/ 1097] train: loss: 0.0068025
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000426
[Epoch 98; Iter   301/ 1097] train: loss: 0.0002627
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000297
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000123
[Epoch 98; Iter   391/ 1097] train: loss: 0.0000287
[Epoch 98; Iter   421/ 1097] train: loss: 0.0011760
[Epoch 98; Iter   451/ 1097] train: loss: 0.0001129
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000914
[Epoch 98; Iter   511/ 1097] train: loss: 0.0000467
[Epoch 98; Iter   541/ 1097] train: loss: 0.0000126
[Epoch 98; Iter   571/ 1097] train: loss: 0.0009916
[Epoch 98; Iter   601/ 1097] train: loss: 0.0000391
[Epoch 98; Iter   631/ 1097] train: loss: 0.0000478
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000496
[Epoch 98; Iter   691/ 1097] train: loss: 0.0018053
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000560
[Epoch 98; Iter   751/ 1097] train: loss: 0.0000321
[Epoch 98; Iter   781/ 1097] train: loss: 0.0002274
[Epoch 98; Iter   811/ 1097] train: loss: 0.0003384
[Epoch 98; Iter   841/ 1097] train: loss: 0.0010006
[Epoch 98; Iter   871/ 1097] train: loss: 0.0488669
[Epoch 98; Iter   901/ 1097] train: loss: 0.0006372
[Epoch 98; Iter   931/ 1097] train: loss: 0.0023713
[Epoch 98; Iter   961/ 1097] train: loss: 0.0102882
[Epoch 98; Iter   991/ 1097] train: loss: 0.0016557
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0003888
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0003808
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0000135
[Epoch 98] ogbg-molhiv: 0.719460 val loss: 0.945253
[Epoch 98] ogbg-molhiv: 0.709062 test loss: 0.696157
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000203
[Epoch 99; Iter    44/ 1097] train: loss: 0.0001047
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000840
[Epoch 99; Iter   104/ 1097] train: loss: 0.0001886
[Epoch 99; Iter   134/ 1097] train: loss: 0.0000353
[Epoch 99; Iter   164/ 1097] train: loss: 0.0000535
[Epoch 99; Iter   194/ 1097] train: loss: 0.0247990
[Epoch 99; Iter   224/ 1097] train: loss: 0.0017636
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000477
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000081
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000052
[Epoch 99; Iter   344/ 1097] train: loss: 0.0008899
[Epoch 99; Iter   374/ 1097] train: loss: 0.0000780
[Epoch 99; Iter   404/ 1097] train: loss: 0.0053812
[Epoch 99; Iter   434/ 1097] train: loss: 0.0000224
[Epoch 99; Iter   464/ 1097] train: loss: 0.0001817
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000803
[Epoch 99; Iter   524/ 1097] train: loss: 0.0006699
[Epoch 99; Iter   554/ 1097] train: loss: 0.0002577
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000070
[Epoch 99; Iter   614/ 1097] train: loss: 0.0000112
[Epoch 99; Iter   644/ 1097] train: loss: 0.0002414
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000532
[Epoch 99; Iter   704/ 1097] train: loss: 0.0001994
[Epoch 99; Iter   734/ 1097] train: loss: 0.0045200
[Epoch 99; Iter   764/ 1097] train: loss: 0.0000945
[Epoch 99; Iter   794/ 1097] train: loss: 0.0010177
[Epoch 99; Iter   824/ 1097] train: loss: 0.0024089
[Epoch 99; Iter   854/ 1097] train: loss: 0.0000268
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000012
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000144
[Epoch 99; Iter   944/ 1097] train: loss: 0.0000742
[Epoch 99; Iter   974/ 1097] train: loss: 0.0001020
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000116
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0002697
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000197
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0006133
[Epoch 99] ogbg-molhiv: 0.703045 val loss: 1.016861
[Epoch 99] ogbg-molhiv: 0.669397 test loss: 0.634009
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000516
[Epoch 100; Iter    57/ 1097] train: loss: 0.0010940
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000047
[Epoch 100; Iter   117/ 1097] train: loss: 0.0001114
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000433
[Epoch 100; Iter   177/ 1097] train: loss: 0.0001771
[Epoch 100; Iter   207/ 1097] train: loss: 0.0771001
[Epoch 100; Iter   237/ 1097] train: loss: 0.0001061
[Epoch 100; Iter   267/ 1097] train: loss: 0.0000115
[Epoch 100; Iter   297/ 1097] train: loss: 0.0000325
[Epoch 100; Iter   327/ 1097] train: loss: 0.0000602
[Epoch 100; Iter   357/ 1097] train: loss: 0.0013370
[Epoch 100; Iter   387/ 1097] train: loss: 0.0008726
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000055
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000111
[Epoch 100; Iter   477/ 1097] train: loss: 0.0141606
[Epoch 100; Iter   507/ 1097] train: loss: 0.0001482
[Epoch 100; Iter   537/ 1097] train: loss: 0.0003854
[Epoch 100; Iter   567/ 1097] train: loss: 0.0007527
[Epoch 100; Iter   597/ 1097] train: loss: 0.0000837
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000623
[Epoch 100; Iter   657/ 1097] train: loss: 0.0028023
[Epoch 100; Iter   687/ 1097] train: loss: 0.0002096
[Epoch 100; Iter   717/ 1097] train: loss: 0.0000297
[Epoch 100; Iter   747/ 1097] train: loss: 0.0000207
[Epoch 100; Iter   777/ 1097] train: loss: 0.0001200
[Epoch 100; Iter   807/ 1097] train: loss: 0.0050757
[Epoch 100; Iter   837/ 1097] train: loss: 0.0029741
[Epoch 100; Iter   867/ 1097] train: loss: 0.0005300
[Epoch 100; Iter   897/ 1097] train: loss: 0.0052267
[Epoch 100; Iter   927/ 1097] train: loss: 0.0037221
[Epoch 100; Iter   957/ 1097] train: loss: 0.0000156
[Epoch 100; Iter   987/ 1097] train: loss: 0.0001964
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000252
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0000044
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000110
[Epoch 100] ogbg-molhiv: 0.692812 val loss: 1.816680
[Epoch 100] ogbg-molhiv: 0.673611 test loss: 0.963280
[Epoch 101; Iter    10/ 1097] train: loss: 0.0000482
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000187
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000109
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000046
[Epoch 101; Iter   130/ 1097] train: loss: 0.0012326
[Epoch 101; Iter   160/ 1097] train: loss: 0.0238300
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000015
[Epoch 101; Iter   220/ 1097] train: loss: 0.0038481
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000092
[Epoch 101; Iter   280/ 1097] train: loss: 0.0000679
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000901
[Epoch 101; Iter   340/ 1097] train: loss: 0.0007019
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000142
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000687
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000210
[Epoch 101; Iter   460/ 1097] train: loss: 0.0000227
[Epoch 101; Iter   490/ 1097] train: loss: 0.0000774
[Epoch 101; Iter   520/ 1097] train: loss: 0.0038954
[Epoch 101; Iter   550/ 1097] train: loss: 0.0000157
[Epoch 101; Iter   580/ 1097] train: loss: 0.0002486
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000150
[Epoch 101; Iter   640/ 1097] train: loss: 0.0385023
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000705
[Epoch 101; Iter   700/ 1097] train: loss: 0.0007612
[Epoch 97; Iter   678/ 1097] train: loss: 0.0000324
[Epoch 97; Iter   708/ 1097] train: loss: 0.0000066
[Epoch 97; Iter   738/ 1097] train: loss: 0.0006603
[Epoch 97; Iter   768/ 1097] train: loss: 0.0000425
[Epoch 97; Iter   798/ 1097] train: loss: 0.0000081
[Epoch 97; Iter   828/ 1097] train: loss: 0.0000174
[Epoch 97; Iter   858/ 1097] train: loss: 0.0293044
[Epoch 97; Iter   888/ 1097] train: loss: 0.0000052
[Epoch 97; Iter   918/ 1097] train: loss: 0.1406556
[Epoch 97; Iter   948/ 1097] train: loss: 0.0000082
[Epoch 97; Iter   978/ 1097] train: loss: 0.0000994
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000271
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000770
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000004
[Epoch 97] ogbg-molhiv: 0.778681 val loss: 0.234926
[Epoch 97] ogbg-molhiv: 0.709174 test loss: 0.404398
[Epoch 98; Iter     1/ 1097] train: loss: 0.0000584
[Epoch 98; Iter    31/ 1097] train: loss: 0.0015900
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000574
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000761
[Epoch 98; Iter   121/ 1097] train: loss: 0.0013088
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000243
[Epoch 98; Iter   181/ 1097] train: loss: 0.0008038
[Epoch 98; Iter   211/ 1097] train: loss: 0.0002832
[Epoch 98; Iter   241/ 1097] train: loss: 0.0003685
[Epoch 98; Iter   271/ 1097] train: loss: 0.0025823
[Epoch 98; Iter   301/ 1097] train: loss: 0.0000437
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000457
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000026
[Epoch 98; Iter   391/ 1097] train: loss: 0.0000256
[Epoch 98; Iter   421/ 1097] train: loss: 0.0001909
[Epoch 98; Iter   451/ 1097] train: loss: 0.0000301
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000045
[Epoch 98; Iter   511/ 1097] train: loss: 0.0000241
[Epoch 98; Iter   541/ 1097] train: loss: 0.0000010
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000093
[Epoch 98; Iter   601/ 1097] train: loss: 0.0000009
[Epoch 98; Iter   631/ 1097] train: loss: 0.0000633
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000105
[Epoch 98; Iter   691/ 1097] train: loss: 0.0000607
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000112
[Epoch 98; Iter   751/ 1097] train: loss: 0.0000335
[Epoch 98; Iter   781/ 1097] train: loss: 0.0001695
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000809
[Epoch 98; Iter   841/ 1097] train: loss: 0.0001689
[Epoch 98; Iter   871/ 1097] train: loss: 0.0002321
[Epoch 98; Iter   901/ 1097] train: loss: 0.0001276
[Epoch 98; Iter   931/ 1097] train: loss: 0.0000817
[Epoch 98; Iter   961/ 1097] train: loss: 0.0001186
[Epoch 98; Iter   991/ 1097] train: loss: 0.0000094
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0009130
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0002163
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0004639
[Epoch 98] ogbg-molhiv: 0.771985 val loss: 0.252532
[Epoch 98] ogbg-molhiv: 0.725599 test loss: 0.413779
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000398
[Epoch 99; Iter    44/ 1097] train: loss: 0.0000350
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000051
[Epoch 99; Iter   104/ 1097] train: loss: 0.0051131
[Epoch 99; Iter   134/ 1097] train: loss: 0.0000204
[Epoch 99; Iter   164/ 1097] train: loss: 0.0000099
[Epoch 99; Iter   194/ 1097] train: loss: 0.0000063
[Epoch 99; Iter   224/ 1097] train: loss: 0.1050747
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000276
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000016
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000049
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000155
[Epoch 99; Iter   374/ 1097] train: loss: 0.0000013
[Epoch 99; Iter   404/ 1097] train: loss: 0.0001025
[Epoch 99; Iter   434/ 1097] train: loss: 0.0002435
[Epoch 99; Iter   464/ 1097] train: loss: 0.0000609
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000119
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000614
[Epoch 99; Iter   554/ 1097] train: loss: 0.0002465
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000630
[Epoch 99; Iter   614/ 1097] train: loss: 0.0000158
[Epoch 99; Iter   644/ 1097] train: loss: 0.0001317
[Epoch 99; Iter   674/ 1097] train: loss: 0.0044362
[Epoch 99; Iter   704/ 1097] train: loss: 0.0000027
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000001
[Epoch 99; Iter   764/ 1097] train: loss: 0.0000457
[Epoch 99; Iter   794/ 1097] train: loss: 0.0000286
[Epoch 99; Iter   824/ 1097] train: loss: 0.0000059
[Epoch 99; Iter   854/ 1097] train: loss: 0.0000471
[Epoch 99; Iter   884/ 1097] train: loss: 0.0001152
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000032
[Epoch 99; Iter   944/ 1097] train: loss: 0.0012578
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000066
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000717
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0001610
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000029
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0002305
[Epoch 99] ogbg-molhiv: 0.784802 val loss: 0.239223
[Epoch 99] ogbg-molhiv: 0.730922 test loss: 0.397721
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000138
[Epoch 100; Iter    57/ 1097] train: loss: 0.0000334
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000026
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000727
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000563
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000004
[Epoch 100; Iter   207/ 1097] train: loss: 0.0000638
[Epoch 100; Iter   237/ 1097] train: loss: 0.0001076
[Epoch 100; Iter   267/ 1097] train: loss: 0.0000017
[Epoch 100; Iter   297/ 1097] train: loss: 0.0004317
[Epoch 100; Iter   327/ 1097] train: loss: 0.0000454
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000657
[Epoch 100; Iter   387/ 1097] train: loss: 0.0000924
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000234
[Epoch 100; Iter   447/ 1097] train: loss: 0.0012449
[Epoch 100; Iter   477/ 1097] train: loss: 0.0015064
[Epoch 100; Iter   507/ 1097] train: loss: 0.0000076
[Epoch 100; Iter   537/ 1097] train: loss: 0.0006475
[Epoch 100; Iter   567/ 1097] train: loss: 0.0007633
[Epoch 100; Iter   597/ 1097] train: loss: 0.0000009
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000053
[Epoch 100; Iter   657/ 1097] train: loss: 0.0010812
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000789
[Epoch 100; Iter   717/ 1097] train: loss: 0.0000086
[Epoch 100; Iter   747/ 1097] train: loss: 0.0000184
[Epoch 100; Iter   777/ 1097] train: loss: 0.0076867
[Epoch 100; Iter   807/ 1097] train: loss: 0.0003558
[Epoch 100; Iter   837/ 1097] train: loss: 0.0005992
[Epoch 100; Iter   867/ 1097] train: loss: 0.0000239
[Epoch 100; Iter   897/ 1097] train: loss: 0.0000269
[Epoch 100; Iter   927/ 1097] train: loss: 0.0000069
[Epoch 100; Iter   957/ 1097] train: loss: 0.0000951
[Epoch 100; Iter   987/ 1097] train: loss: 0.0148050
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0005243
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0000263
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000035
[Epoch 100] ogbg-molhiv: 0.775849 val loss: 0.257721
[Epoch 100] ogbg-molhiv: 0.727123 test loss: 0.404802
[Epoch 101; Iter    10/ 1097] train: loss: 0.0007042
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000803
[Epoch 101; Iter    70/ 1097] train: loss: 0.0003277
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000009
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000666
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000003
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000006
[Epoch 101; Iter   220/ 1097] train: loss: 0.0000166
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000138
[Epoch 101; Iter   280/ 1097] train: loss: 0.0000107
[Epoch 101; Iter   310/ 1097] train: loss: 0.0003647
[Epoch 101; Iter   340/ 1097] train: loss: 0.0000051
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000695
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000033
[Epoch 101; Iter   430/ 1097] train: loss: 0.0034619
[Epoch 101; Iter   460/ 1097] train: loss: 0.0000104
[Epoch 101; Iter   490/ 1097] train: loss: 0.0004093
[Epoch 101; Iter   520/ 1097] train: loss: 0.0000033
[Epoch 101; Iter   550/ 1097] train: loss: 0.0002984
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000036
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000052
[Epoch 101; Iter   640/ 1097] train: loss: 0.0000458
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000164
[Epoch 101; Iter   700/ 1097] train: loss: 0.0001951
[Epoch 97; Iter   678/ 1097] train: loss: 0.0007496
[Epoch 97; Iter   708/ 1097] train: loss: 0.0001664
[Epoch 97; Iter   738/ 1097] train: loss: 0.0010403
[Epoch 97; Iter   768/ 1097] train: loss: 0.0000578
[Epoch 97; Iter   798/ 1097] train: loss: 0.0001498
[Epoch 97; Iter   828/ 1097] train: loss: 0.0000435
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000269
[Epoch 97; Iter   888/ 1097] train: loss: 0.0001208
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000144
[Epoch 97; Iter   948/ 1097] train: loss: 0.0016346
[Epoch 97; Iter   978/ 1097] train: loss: 0.0005164
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0031164
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000205
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0001285
[Epoch 97] ogbg-molhiv: 0.780080 val loss: 0.408467
[Epoch 97] ogbg-molhiv: 0.754203 test loss: 0.383892
[Epoch 98; Iter     1/ 1097] train: loss: 0.0002040
[Epoch 98; Iter    31/ 1097] train: loss: 0.0178051
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000040
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000803
[Epoch 98; Iter   121/ 1097] train: loss: 0.0023687
[Epoch 98; Iter   151/ 1097] train: loss: 0.0001952
[Epoch 98; Iter   181/ 1097] train: loss: 0.0000751
[Epoch 98; Iter   211/ 1097] train: loss: 0.0001936
[Epoch 98; Iter   241/ 1097] train: loss: 0.0000210
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000230
[Epoch 98; Iter   301/ 1097] train: loss: 0.0000716
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000469
[Epoch 98; Iter   361/ 1097] train: loss: 0.0004541
[Epoch 98; Iter   391/ 1097] train: loss: 0.0005184
[Epoch 98; Iter   421/ 1097] train: loss: 0.0006054
[Epoch 98; Iter   451/ 1097] train: loss: 0.0006808
[Epoch 98; Iter   481/ 1097] train: loss: 0.0001144
[Epoch 98; Iter   511/ 1097] train: loss: 0.0174700
[Epoch 98; Iter   541/ 1097] train: loss: 0.0025616
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000078
[Epoch 98; Iter   601/ 1097] train: loss: 0.0000325
[Epoch 98; Iter   631/ 1097] train: loss: 0.0000201
[Epoch 98; Iter   661/ 1097] train: loss: 0.0006756
[Epoch 98; Iter   691/ 1097] train: loss: 0.0001782
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000824
[Epoch 98; Iter   751/ 1097] train: loss: 0.0004038
[Epoch 98; Iter   781/ 1097] train: loss: 0.0000033
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000005
[Epoch 98; Iter   841/ 1097] train: loss: 0.0000562
[Epoch 98; Iter   871/ 1097] train: loss: 0.0000702
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000222
[Epoch 98; Iter   931/ 1097] train: loss: 0.0011519
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000156
[Epoch 98; Iter   991/ 1097] train: loss: 0.0006363
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0515197
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0603514
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0017007
[Epoch 98] ogbg-molhiv: 0.775919 val loss: 0.420270
[Epoch 98] ogbg-molhiv: 0.746220 test loss: 0.377449
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000177
[Epoch 99; Iter    44/ 1097] train: loss: 0.0000049
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000495
[Epoch 99; Iter   104/ 1097] train: loss: 0.0001507
[Epoch 99; Iter   134/ 1097] train: loss: 0.0000121
[Epoch 99; Iter   164/ 1097] train: loss: 0.0060161
[Epoch 99; Iter   194/ 1097] train: loss: 0.0000109
[Epoch 99; Iter   224/ 1097] train: loss: 0.0000698
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000592
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000020
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000039
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000747
[Epoch 99; Iter   374/ 1097] train: loss: 0.0002100
[Epoch 99; Iter   404/ 1097] train: loss: 0.0000039
[Epoch 99; Iter   434/ 1097] train: loss: 0.0012029
[Epoch 99; Iter   464/ 1097] train: loss: 0.0000534
[Epoch 99; Iter   494/ 1097] train: loss: 0.0362806
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000158
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000132
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000206
[Epoch 99; Iter   614/ 1097] train: loss: 0.0000262
[Epoch 99; Iter   644/ 1097] train: loss: 0.0006819
[Epoch 99; Iter   674/ 1097] train: loss: 0.0001684
[Epoch 99; Iter   704/ 1097] train: loss: 0.0003243
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000124
[Epoch 99; Iter   764/ 1097] train: loss: 0.0001136
[Epoch 99; Iter   794/ 1097] train: loss: 0.0007681
[Epoch 99; Iter   824/ 1097] train: loss: 0.0002398
[Epoch 99; Iter   854/ 1097] train: loss: 0.0002371
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000336
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000750
[Epoch 99; Iter   944/ 1097] train: loss: 0.0000106
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000046
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000037
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0000098
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0010395
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0000251
[Epoch 99] ogbg-molhiv: 0.774495 val loss: 0.416245
[Epoch 99] ogbg-molhiv: 0.754159 test loss: 0.371783
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000112
[Epoch 100; Iter    57/ 1097] train: loss: 0.0009334
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000400
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000043
[Epoch 100; Iter   147/ 1097] train: loss: 0.0022285
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000028
[Epoch 100; Iter   207/ 1097] train: loss: 0.0001178
[Epoch 100; Iter   237/ 1097] train: loss: 0.0011750
[Epoch 100; Iter   267/ 1097] train: loss: 0.0000014
[Epoch 100; Iter   297/ 1097] train: loss: 0.0000963
[Epoch 100; Iter   327/ 1097] train: loss: 0.0007003
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000225
[Epoch 100; Iter   387/ 1097] train: loss: 0.0000425
[Epoch 100; Iter   417/ 1097] train: loss: 0.0026519
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000143
[Epoch 100; Iter   477/ 1097] train: loss: 0.0000221
[Epoch 100; Iter   507/ 1097] train: loss: 0.0025373
[Epoch 100; Iter   537/ 1097] train: loss: 0.0000093
[Epoch 100; Iter   567/ 1097] train: loss: 0.0001378
[Epoch 100; Iter   597/ 1097] train: loss: 0.0012418
[Epoch 100; Iter   627/ 1097] train: loss: 0.0001859
[Epoch 100; Iter   657/ 1097] train: loss: 0.0015470
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000035
[Epoch 100; Iter   717/ 1097] train: loss: 0.0000797
[Epoch 100; Iter   747/ 1097] train: loss: 0.0001639
[Epoch 100; Iter   777/ 1097] train: loss: 0.0136519
[Epoch 100; Iter   807/ 1097] train: loss: 0.0000103
[Epoch 100; Iter   837/ 1097] train: loss: 0.0000041
[Epoch 100; Iter   867/ 1097] train: loss: 0.0001874
[Epoch 100; Iter   897/ 1097] train: loss: 0.0004289
[Epoch 100; Iter   927/ 1097] train: loss: 0.0004185
[Epoch 100; Iter   957/ 1097] train: loss: 0.0001117
[Epoch 100; Iter   987/ 1097] train: loss: 0.0003007
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000017
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0000488
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000260
[Epoch 100] ogbg-molhiv: 0.763234 val loss: 0.427286
[Epoch 100] ogbg-molhiv: 0.748462 test loss: 0.400425
[Epoch 101; Iter    10/ 1097] train: loss: 0.0002405
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000965
[Epoch 101; Iter    70/ 1097] train: loss: 0.0006476
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000227
[Epoch 101; Iter   130/ 1097] train: loss: 0.0001224
[Epoch 101; Iter   160/ 1097] train: loss: 0.0003135
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000607
[Epoch 101; Iter   220/ 1097] train: loss: 0.0000477
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000032
[Epoch 101; Iter   280/ 1097] train: loss: 0.0115475
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000152
[Epoch 101; Iter   340/ 1097] train: loss: 0.0004727
[Epoch 101; Iter   370/ 1097] train: loss: 0.0002625
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000121
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000146
[Epoch 101; Iter   460/ 1097] train: loss: 0.0017435
[Epoch 101; Iter   490/ 1097] train: loss: 0.0000003
[Epoch 101; Iter   520/ 1097] train: loss: 0.0000551
[Epoch 101; Iter   550/ 1097] train: loss: 0.0000062
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000609
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000561
[Epoch 101; Iter   640/ 1097] train: loss: 0.0016123
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000250
[Epoch 101; Iter   700/ 1097] train: loss: 0.0000086
[Epoch 97; Iter   678/ 1097] train: loss: 0.0138082
[Epoch 97; Iter   708/ 1097] train: loss: 0.0001656
[Epoch 97; Iter   738/ 1097] train: loss: 0.0000816
[Epoch 97; Iter   768/ 1097] train: loss: 0.0002504
[Epoch 97; Iter   798/ 1097] train: loss: 0.0014041
[Epoch 97; Iter   828/ 1097] train: loss: 0.0000123
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000538
[Epoch 97; Iter   888/ 1097] train: loss: 0.0029888
[Epoch 97; Iter   918/ 1097] train: loss: 0.0001711
[Epoch 97; Iter   948/ 1097] train: loss: 0.0006950
[Epoch 97; Iter   978/ 1097] train: loss: 0.0428594
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000157
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000113
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000382
[Epoch 97] ogbg-molhiv: 0.781170 val loss: 0.288323
[Epoch 97] ogbg-molhiv: 0.743664 test loss: 0.484757
[Epoch 98; Iter     1/ 1097] train: loss: 0.0002451
[Epoch 98; Iter    31/ 1097] train: loss: 0.0001018
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000111
[Epoch 98; Iter    91/ 1097] train: loss: 0.0001144
[Epoch 98; Iter   121/ 1097] train: loss: 0.0014493
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000088
[Epoch 98; Iter   181/ 1097] train: loss: 0.0001044
[Epoch 98; Iter   211/ 1097] train: loss: 0.0002286
[Epoch 98; Iter   241/ 1097] train: loss: 0.0000139
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000047
[Epoch 98; Iter   301/ 1097] train: loss: 0.0005811
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000752
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000086
[Epoch 98; Iter   391/ 1097] train: loss: 0.0002214
[Epoch 98; Iter   421/ 1097] train: loss: 0.0000281
[Epoch 98; Iter   451/ 1097] train: loss: 0.0000146
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000086
[Epoch 98; Iter   511/ 1097] train: loss: 0.0000342
[Epoch 98; Iter   541/ 1097] train: loss: 0.0000086
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000018
[Epoch 98; Iter   601/ 1097] train: loss: 0.0005796
[Epoch 98; Iter   631/ 1097] train: loss: 0.0016216
[Epoch 98; Iter   661/ 1097] train: loss: 0.0015602
[Epoch 98; Iter   691/ 1097] train: loss: 0.0004490
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000067
[Epoch 98; Iter   751/ 1097] train: loss: 0.0008065
[Epoch 98; Iter   781/ 1097] train: loss: 0.0000957
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000466
[Epoch 98; Iter   841/ 1097] train: loss: 0.0001994
[Epoch 98; Iter   871/ 1097] train: loss: 0.0000661
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000185
[Epoch 98; Iter   931/ 1097] train: loss: 0.0000080
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000740
[Epoch 98; Iter   991/ 1097] train: loss: 0.0002857
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0112894
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0945210
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0000532
[Epoch 98] ogbg-molhiv: 0.791281 val loss: 0.346687
[Epoch 98] ogbg-molhiv: 0.755577 test loss: 0.428686
[Epoch 99; Iter    14/ 1097] train: loss: 0.0009546
[Epoch 99; Iter    44/ 1097] train: loss: 0.0000504
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000729
[Epoch 99; Iter   104/ 1097] train: loss: 0.0000225
[Epoch 99; Iter   134/ 1097] train: loss: 0.0009745
[Epoch 99; Iter   164/ 1097] train: loss: 0.0051427
[Epoch 99; Iter   194/ 1097] train: loss: 0.0000095
[Epoch 99; Iter   224/ 1097] train: loss: 0.0004590
[Epoch 99; Iter   254/ 1097] train: loss: 0.0002236
[Epoch 99; Iter   284/ 1097] train: loss: 0.0002923
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000642
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000158
[Epoch 99; Iter   374/ 1097] train: loss: 0.0001036
[Epoch 99; Iter   404/ 1097] train: loss: 0.0000101
[Epoch 99; Iter   434/ 1097] train: loss: 0.0000197
[Epoch 99; Iter   464/ 1097] train: loss: 0.0000186
[Epoch 99; Iter   494/ 1097] train: loss: 0.0003299
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000198
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000328
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000035
[Epoch 99; Iter   614/ 1097] train: loss: 0.0003992
[Epoch 99; Iter   644/ 1097] train: loss: 0.0003889
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000043
[Epoch 99; Iter   704/ 1097] train: loss: 0.0001062
[Epoch 99; Iter   734/ 1097] train: loss: 0.0001350
[Epoch 99; Iter   764/ 1097] train: loss: 0.0025167
[Epoch 99; Iter   794/ 1097] train: loss: 0.0003888
[Epoch 99; Iter   824/ 1097] train: loss: 0.0000056
[Epoch 99; Iter   854/ 1097] train: loss: 0.0000541
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000045
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000114
[Epoch 99; Iter   944/ 1097] train: loss: 0.0000016
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000205
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000339
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0018973
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000019
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0011026
[Epoch 99] ogbg-molhiv: 0.782368 val loss: 0.356740
[Epoch 99] ogbg-molhiv: 0.743699 test loss: 0.460190
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000098
[Epoch 100; Iter    57/ 1097] train: loss: 0.0004099
[Epoch 100; Iter    87/ 1097] train: loss: 0.0001361
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000068
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000384
[Epoch 100; Iter   177/ 1097] train: loss: 0.0001941
[Epoch 100; Iter   207/ 1097] train: loss: 0.0001153
[Epoch 100; Iter   237/ 1097] train: loss: 0.0002927
[Epoch 100; Iter   267/ 1097] train: loss: 0.0000026
[Epoch 100; Iter   297/ 1097] train: loss: 0.0002366
[Epoch 100; Iter   327/ 1097] train: loss: 0.0007137
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000512
[Epoch 100; Iter   387/ 1097] train: loss: 0.0001224
[Epoch 100; Iter   417/ 1097] train: loss: 0.0001170
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000157
[Epoch 100; Iter   477/ 1097] train: loss: 0.0000459
[Epoch 100; Iter   507/ 1097] train: loss: 0.0000329
[Epoch 100; Iter   537/ 1097] train: loss: 0.0000501
[Epoch 100; Iter   567/ 1097] train: loss: 0.0003464
[Epoch 100; Iter   597/ 1097] train: loss: 0.0000033
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000013
[Epoch 100; Iter   657/ 1097] train: loss: 0.0000148
[Epoch 100; Iter   687/ 1097] train: loss: 0.0004662
[Epoch 100; Iter   717/ 1097] train: loss: 0.0000239
[Epoch 100; Iter   747/ 1097] train: loss: 0.0001412
[Epoch 100; Iter   777/ 1097] train: loss: 0.0008576
[Epoch 100; Iter   807/ 1097] train: loss: 0.0000073
[Epoch 100; Iter   837/ 1097] train: loss: 0.0003889
[Epoch 100; Iter   867/ 1097] train: loss: 0.0000029
[Epoch 100; Iter   897/ 1097] train: loss: 0.0037930
[Epoch 100; Iter   927/ 1097] train: loss: 0.0001167
[Epoch 100; Iter   957/ 1097] train: loss: 0.0002250
[Epoch 100; Iter   987/ 1097] train: loss: 0.0000035
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000237
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0001240
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0044969
[Epoch 100] ogbg-molhiv: 0.782447 val loss: 0.398441
[Epoch 100] ogbg-molhiv: 0.736849 test loss: 0.430022
[Epoch 101; Iter    10/ 1097] train: loss: 0.0003429
[Epoch 101; Iter    40/ 1097] train: loss: 0.0021928
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000013
[Epoch 101; Iter   100/ 1097] train: loss: 0.0009189
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000071
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000985
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000133
[Epoch 101; Iter   220/ 1097] train: loss: 0.0000305
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000280
[Epoch 101; Iter   280/ 1097] train: loss: 0.0080367
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000363
[Epoch 101; Iter   340/ 1097] train: loss: 0.0000094
[Epoch 101; Iter   370/ 1097] train: loss: 0.0006367
[Epoch 101; Iter   400/ 1097] train: loss: 0.0002135
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000049
[Epoch 101; Iter   460/ 1097] train: loss: 0.0005424
[Epoch 101; Iter   490/ 1097] train: loss: 0.0006517
[Epoch 101; Iter   520/ 1097] train: loss: 0.0003050
[Epoch 101; Iter   550/ 1097] train: loss: 0.0004040
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000029
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000054
[Epoch 101; Iter   640/ 1097] train: loss: 0.0000848
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000076
[Epoch 101; Iter   700/ 1097] train: loss: 0.0000061
[Epoch 97; Iter   678/ 1097] train: loss: 0.0005441
[Epoch 97; Iter   708/ 1097] train: loss: 0.0000407
[Epoch 97; Iter   738/ 1097] train: loss: 0.0000462
[Epoch 97; Iter   768/ 1097] train: loss: 0.0000236
[Epoch 97; Iter   798/ 1097] train: loss: 0.0000003
[Epoch 97; Iter   828/ 1097] train: loss: 0.0000346
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000181
[Epoch 97; Iter   888/ 1097] train: loss: 0.0224662
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000231
[Epoch 97; Iter   948/ 1097] train: loss: 0.0000165
[Epoch 97; Iter   978/ 1097] train: loss: 0.0000021
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000188
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000108
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0002391
[Epoch 97] ogbg-molhiv: 0.792999 val loss: 0.455365
[Epoch 97] ogbg-molhiv: 0.808766 test loss: 0.350888
[Epoch 98; Iter     1/ 1097] train: loss: 0.0000871
[Epoch 98; Iter    31/ 1097] train: loss: 0.0000195
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000257
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000054
[Epoch 98; Iter   121/ 1097] train: loss: 0.0014094
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000045
[Epoch 98; Iter   181/ 1097] train: loss: 0.0073268
[Epoch 98; Iter   211/ 1097] train: loss: 0.0000015
[Epoch 98; Iter   241/ 1097] train: loss: 0.0000660
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000028
[Epoch 98; Iter   301/ 1097] train: loss: 0.0009329
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000512
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000111
[Epoch 98; Iter   391/ 1097] train: loss: 0.0010690
[Epoch 98; Iter   421/ 1097] train: loss: 0.0000056
[Epoch 98; Iter   451/ 1097] train: loss: 0.0000033
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000704
[Epoch 98; Iter   511/ 1097] train: loss: 0.0014911
[Epoch 98; Iter   541/ 1097] train: loss: 0.0001369
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000661
[Epoch 98; Iter   601/ 1097] train: loss: 0.0002616
[Epoch 98; Iter   631/ 1097] train: loss: 0.0003310
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000022
[Epoch 98; Iter   691/ 1097] train: loss: 0.0043025
[Epoch 98; Iter   721/ 1097] train: loss: 0.0024146
[Epoch 98; Iter   751/ 1097] train: loss: 0.0000121
[Epoch 98; Iter   781/ 1097] train: loss: 0.0009182
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000028
[Epoch 98; Iter   841/ 1097] train: loss: 0.0000048
[Epoch 98; Iter   871/ 1097] train: loss: 0.0001513
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000149
[Epoch 98; Iter   931/ 1097] train: loss: 0.0000745
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000093
[Epoch 98; Iter   991/ 1097] train: loss: 0.0001004
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0002596
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0001066
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0000186
[Epoch 98] ogbg-molhiv: 0.801991 val loss: 0.451848
[Epoch 98] ogbg-molhiv: 0.805087 test loss: 0.351830
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000780
[Epoch 99; Iter    44/ 1097] train: loss: 0.0021861
[Epoch 99; Iter    74/ 1097] train: loss: 0.0000916
[Epoch 99; Iter   104/ 1097] train: loss: 0.0000192
[Epoch 99; Iter   134/ 1097] train: loss: 0.0001115
[Epoch 99; Iter   164/ 1097] train: loss: 0.0000100
[Epoch 99; Iter   194/ 1097] train: loss: 0.0000569
[Epoch 99; Iter   224/ 1097] train: loss: 0.0000026
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000182
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000161
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000307
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000065
[Epoch 99; Iter   374/ 1097] train: loss: 0.0001505
[Epoch 99; Iter   404/ 1097] train: loss: 0.0002739
[Epoch 99; Iter   434/ 1097] train: loss: 0.0000301
[Epoch 99; Iter   464/ 1097] train: loss: 0.0000077
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000361
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000018
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000064
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000182
[Epoch 99; Iter   614/ 1097] train: loss: 0.0096976
[Epoch 99; Iter   644/ 1097] train: loss: 0.0000389
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000424
[Epoch 99; Iter   704/ 1097] train: loss: 0.0010174
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000140
[Epoch 99; Iter   764/ 1097] train: loss: 0.0000115
[Epoch 99; Iter   794/ 1097] train: loss: 0.0021664
[Epoch 99; Iter   824/ 1097] train: loss: 0.0000852
[Epoch 99; Iter   854/ 1097] train: loss: 0.0003310
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000140
[Epoch 99; Iter   914/ 1097] train: loss: 0.0001787
[Epoch 99; Iter   944/ 1097] train: loss: 0.0001210
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000003
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000104
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0000004
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000005
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0000641
[Epoch 99] ogbg-molhiv: 0.793593 val loss: 0.275989
[Epoch 99] ogbg-molhiv: 0.791610 test loss: 0.360710
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000317
[Epoch 100; Iter    57/ 1097] train: loss: 0.0000933
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000041
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000046
[Epoch 100; Iter   147/ 1097] train: loss: 0.0008085
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000144
[Epoch 100; Iter   207/ 1097] train: loss: 0.0000009
[Epoch 100; Iter   237/ 1097] train: loss: 0.0001016
[Epoch 100; Iter   267/ 1097] train: loss: 0.0013555
[Epoch 100; Iter   297/ 1097] train: loss: 0.0002572
[Epoch 100; Iter   327/ 1097] train: loss: 0.0041870
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000040
[Epoch 100; Iter   387/ 1097] train: loss: 0.0000083
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000060
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000040
[Epoch 100; Iter   477/ 1097] train: loss: 0.0000098
[Epoch 100; Iter   507/ 1097] train: loss: 0.0000003
[Epoch 100; Iter   537/ 1097] train: loss: 0.0000290
[Epoch 100; Iter   567/ 1097] train: loss: 0.0000038
[Epoch 100; Iter   597/ 1097] train: loss: 0.0055278
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000195
[Epoch 100; Iter   657/ 1097] train: loss: 0.0000270
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000182
[Epoch 100; Iter   717/ 1097] train: loss: 0.0000011
[Epoch 100; Iter   747/ 1097] train: loss: 0.0000067
[Epoch 100; Iter   777/ 1097] train: loss: 0.0000064
[Epoch 100; Iter   807/ 1097] train: loss: 0.0001193
[Epoch 100; Iter   837/ 1097] train: loss: 0.0032900
[Epoch 100; Iter   867/ 1097] train: loss: 0.0000154
[Epoch 100; Iter   897/ 1097] train: loss: 0.0005769
[Epoch 100; Iter   927/ 1097] train: loss: 0.0007525
[Epoch 100; Iter   957/ 1097] train: loss: 0.0006913
[Epoch 100; Iter   987/ 1097] train: loss: 0.0000155
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000239
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0009868
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000364
[Epoch 100] ogbg-molhiv: 0.790586 val loss: 0.568678
[Epoch 100] ogbg-molhiv: 0.802441 test loss: 0.337973
[Epoch 101; Iter    10/ 1097] train: loss: 0.0000064
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000135
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000158
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000309
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000233
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000012
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000943
[Epoch 101; Iter   220/ 1097] train: loss: 0.0000033
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000272
[Epoch 101; Iter   280/ 1097] train: loss: 0.0001152
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000067
[Epoch 101; Iter   340/ 1097] train: loss: 0.0000193
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000466
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000283
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000838
[Epoch 101; Iter   460/ 1097] train: loss: 0.0003633
[Epoch 101; Iter   490/ 1097] train: loss: 0.0000584
[Epoch 101; Iter   520/ 1097] train: loss: 0.0000099
[Epoch 101; Iter   550/ 1097] train: loss: 0.0005902
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000570
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000726
[Epoch 101; Iter   640/ 1097] train: loss: 0.0000026
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000841
[Epoch 101; Iter   700/ 1097] train: loss: 0.0003224
[Epoch 77; Iter   268/ 1097] train: loss: 0.0379980
[Epoch 77; Iter   298/ 1097] train: loss: 0.0067469
[Epoch 77; Iter   328/ 1097] train: loss: 0.0553464
[Epoch 77; Iter   358/ 1097] train: loss: 0.0032127
[Epoch 77; Iter   388/ 1097] train: loss: 0.0064932
[Epoch 77; Iter   418/ 1097] train: loss: 0.0036928
[Epoch 77; Iter   448/ 1097] train: loss: 0.0061812
[Epoch 77; Iter   478/ 1097] train: loss: 0.0082867
[Epoch 77; Iter   508/ 1097] train: loss: 0.1050316
[Epoch 77; Iter   538/ 1097] train: loss: 0.0258777
[Epoch 77; Iter   568/ 1097] train: loss: 0.0576204
[Epoch 77; Iter   598/ 1097] train: loss: 0.1310447
[Epoch 77; Iter   628/ 1097] train: loss: 0.0159049
[Epoch 77; Iter   658/ 1097] train: loss: 0.0185148
[Epoch 77; Iter   688/ 1097] train: loss: 0.0474395
[Epoch 77; Iter   718/ 1097] train: loss: 0.0123436
[Epoch 77; Iter   748/ 1097] train: loss: 0.0289832
[Epoch 77; Iter   778/ 1097] train: loss: 0.0057556
[Epoch 77; Iter   808/ 1097] train: loss: 0.0072989
[Epoch 77; Iter   838/ 1097] train: loss: 0.0152340
[Epoch 77; Iter   868/ 1097] train: loss: 0.0603262
[Epoch 77; Iter   898/ 1097] train: loss: 0.0066622
[Epoch 77; Iter   928/ 1097] train: loss: 0.0050411
[Epoch 77; Iter   958/ 1097] train: loss: 0.0299604
[Epoch 77; Iter   988/ 1097] train: loss: 0.0174128
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0101150
[Epoch 77; Iter  1048/ 1097] train: loss: 0.1489359
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0044566
[Epoch 77] ogbg-molhiv: 0.808918 val loss: 0.113068
[Epoch 77] ogbg-molhiv: 0.738454 test loss: 0.209016
[Epoch 78; Iter    11/ 1097] train: loss: 0.0024950
[Epoch 78; Iter    41/ 1097] train: loss: 0.1044731
[Epoch 78; Iter    71/ 1097] train: loss: 0.0217995
[Epoch 78; Iter   101/ 1097] train: loss: 0.0202870
[Epoch 78; Iter   131/ 1097] train: loss: 0.0215713
[Epoch 78; Iter   161/ 1097] train: loss: 0.0013827
[Epoch 78; Iter   191/ 1097] train: loss: 0.0102244
[Epoch 78; Iter   221/ 1097] train: loss: 0.0125631
[Epoch 78; Iter   251/ 1097] train: loss: 0.0020852
[Epoch 78; Iter   281/ 1097] train: loss: 0.0204976
[Epoch 78; Iter   311/ 1097] train: loss: 0.0817652
[Epoch 78; Iter   341/ 1097] train: loss: 0.0609889
[Epoch 78; Iter   371/ 1097] train: loss: 0.0201554
[Epoch 78; Iter   401/ 1097] train: loss: 0.0029954
[Epoch 78; Iter   431/ 1097] train: loss: 0.0036570
[Epoch 78; Iter   461/ 1097] train: loss: 0.1080230
[Epoch 78; Iter   491/ 1097] train: loss: 0.0199056
[Epoch 78; Iter   521/ 1097] train: loss: 0.0090208
[Epoch 78; Iter   551/ 1097] train: loss: 0.0019281
[Epoch 78; Iter   581/ 1097] train: loss: 0.0086398
[Epoch 78; Iter   611/ 1097] train: loss: 0.0125357
[Epoch 78; Iter   641/ 1097] train: loss: 0.0093108
[Epoch 78; Iter   671/ 1097] train: loss: 0.0251941
[Epoch 78; Iter   701/ 1097] train: loss: 0.0118307
[Epoch 78; Iter   731/ 1097] train: loss: 0.0388771
[Epoch 78; Iter   761/ 1097] train: loss: 0.0100379
[Epoch 78; Iter   791/ 1097] train: loss: 0.0858730
[Epoch 78; Iter   821/ 1097] train: loss: 0.0251509
[Epoch 78; Iter   851/ 1097] train: loss: 0.0710004
[Epoch 78; Iter   881/ 1097] train: loss: 0.0872150
[Epoch 78; Iter   911/ 1097] train: loss: 0.1046816
[Epoch 78; Iter   941/ 1097] train: loss: 0.0083885
[Epoch 78; Iter   971/ 1097] train: loss: 0.0030388
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0052065
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0063868
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0041876
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0660593
[Epoch 78] ogbg-molhiv: 0.817120 val loss: 0.116372
[Epoch 78] ogbg-molhiv: 0.749354 test loss: 0.206904
[Epoch 79; Iter    24/ 1097] train: loss: 0.0448116
[Epoch 79; Iter    54/ 1097] train: loss: 0.0126548
[Epoch 79; Iter    84/ 1097] train: loss: 0.0207677
[Epoch 79; Iter   114/ 1097] train: loss: 0.0358346
[Epoch 79; Iter   144/ 1097] train: loss: 0.0053110
[Epoch 79; Iter   174/ 1097] train: loss: 0.0066244
[Epoch 79; Iter   204/ 1097] train: loss: 0.0293681
[Epoch 79; Iter   234/ 1097] train: loss: 0.0035224
[Epoch 79; Iter   264/ 1097] train: loss: 0.0060073
[Epoch 79; Iter   294/ 1097] train: loss: 0.0224950
[Epoch 79; Iter   324/ 1097] train: loss: 0.0035484
[Epoch 79; Iter   354/ 1097] train: loss: 0.0101672
[Epoch 79; Iter   384/ 1097] train: loss: 0.0410526
[Epoch 79; Iter   414/ 1097] train: loss: 0.0532985
[Epoch 79; Iter   444/ 1097] train: loss: 0.0124161
[Epoch 79; Iter   474/ 1097] train: loss: 0.0102194
[Epoch 79; Iter   504/ 1097] train: loss: 0.0078347
[Epoch 79; Iter   534/ 1097] train: loss: 0.0132208
[Epoch 79; Iter   564/ 1097] train: loss: 0.0044531
[Epoch 79; Iter   594/ 1097] train: loss: 0.1156248
[Epoch 79; Iter   624/ 1097] train: loss: 0.0957590
[Epoch 79; Iter   654/ 1097] train: loss: 0.1259048
[Epoch 79; Iter   684/ 1097] train: loss: 0.2702036
[Epoch 79; Iter   714/ 1097] train: loss: 0.1242582
[Epoch 79; Iter   744/ 1097] train: loss: 0.0091549
[Epoch 79; Iter   774/ 1097] train: loss: 0.0220561
[Epoch 79; Iter   804/ 1097] train: loss: 0.0053121
[Epoch 79; Iter   834/ 1097] train: loss: 0.0082350
[Epoch 79; Iter   864/ 1097] train: loss: 0.0040116
[Epoch 79; Iter   894/ 1097] train: loss: 0.0173696
[Epoch 79; Iter   924/ 1097] train: loss: 0.0983715
[Epoch 79; Iter   954/ 1097] train: loss: 0.0054455
[Epoch 79; Iter   984/ 1097] train: loss: 0.0053383
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0385533
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0159780
[Epoch 79; Iter  1074/ 1097] train: loss: 0.1564835
[Epoch 79] ogbg-molhiv: 0.819000 val loss: 0.112941
[Epoch 79] ogbg-molhiv: 0.750026 test loss: 0.207461
[Epoch 80; Iter     7/ 1097] train: loss: 0.0353511
[Epoch 80; Iter    37/ 1097] train: loss: 0.0247781
[Epoch 80; Iter    67/ 1097] train: loss: 0.0076458
[Epoch 80; Iter    97/ 1097] train: loss: 0.0052640
[Epoch 80; Iter   127/ 1097] train: loss: 0.0272788
[Epoch 80; Iter   157/ 1097] train: loss: 0.0105206
[Epoch 80; Iter   187/ 1097] train: loss: 0.0658202
[Epoch 80; Iter   217/ 1097] train: loss: 0.0045470
[Epoch 80; Iter   247/ 1097] train: loss: 0.0495578
[Epoch 80; Iter   277/ 1097] train: loss: 0.0101223
[Epoch 80; Iter   307/ 1097] train: loss: 0.0015841
[Epoch 80; Iter   337/ 1097] train: loss: 0.0122497
[Epoch 80; Iter   367/ 1097] train: loss: 0.0082030
[Epoch 80; Iter   397/ 1097] train: loss: 0.0394321
[Epoch 80; Iter   427/ 1097] train: loss: 0.0027722
[Epoch 80; Iter   457/ 1097] train: loss: 0.0027577
[Epoch 80; Iter   487/ 1097] train: loss: 0.0017166
[Epoch 80; Iter   517/ 1097] train: loss: 0.0597388
[Epoch 80; Iter   547/ 1097] train: loss: 0.0541685
[Epoch 80; Iter   577/ 1097] train: loss: 0.0093191
[Epoch 80; Iter   607/ 1097] train: loss: 0.0409832
[Epoch 80; Iter   637/ 1097] train: loss: 0.0313417
[Epoch 80; Iter   667/ 1097] train: loss: 0.0041141
[Epoch 80; Iter   697/ 1097] train: loss: 0.0189158
[Epoch 80; Iter   727/ 1097] train: loss: 0.0085629
[Epoch 80; Iter   757/ 1097] train: loss: 0.0051439
[Epoch 80; Iter   787/ 1097] train: loss: 0.0047711
[Epoch 80; Iter   817/ 1097] train: loss: 0.0616561
[Epoch 80; Iter   847/ 1097] train: loss: 0.0037074
[Epoch 80; Iter   877/ 1097] train: loss: 0.0048291
[Epoch 80; Iter   907/ 1097] train: loss: 0.0063045
[Epoch 80; Iter   937/ 1097] train: loss: 0.0117987
[Epoch 80; Iter   967/ 1097] train: loss: 0.0242194
[Epoch 80; Iter   997/ 1097] train: loss: 0.0065160
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0172792
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0965947
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0228241
[Epoch 80] ogbg-molhiv: 0.812518 val loss: 0.116859
[Epoch 80] ogbg-molhiv: 0.748396 test loss: 0.213566
[Epoch 81; Iter    20/ 1097] train: loss: 0.1460592
[Epoch 81; Iter    50/ 1097] train: loss: 0.0018083
[Epoch 81; Iter    80/ 1097] train: loss: 0.0056329
[Epoch 81; Iter   110/ 1097] train: loss: 0.0217227
[Epoch 81; Iter   140/ 1097] train: loss: 0.1007303
[Epoch 81; Iter   170/ 1097] train: loss: 0.0858470
[Epoch 81; Iter   200/ 1097] train: loss: 0.0289019
[Epoch 81; Iter   230/ 1097] train: loss: 0.0033831
[Epoch 81; Iter   260/ 1097] train: loss: 0.1050335
[Epoch 81; Iter   290/ 1097] train: loss: 0.0150772
[Epoch 81; Iter   320/ 1097] train: loss: 0.0096862
[Epoch 97; Iter   678/ 1097] train: loss: 0.0000296
[Epoch 97; Iter   708/ 1097] train: loss: 0.0000038
[Epoch 97; Iter   738/ 1097] train: loss: 0.0000895
[Epoch 97; Iter   768/ 1097] train: loss: 0.0011577
[Epoch 97; Iter   798/ 1097] train: loss: 0.0000033
[Epoch 97; Iter   828/ 1097] train: loss: 0.0002561
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000580
[Epoch 97; Iter   888/ 1097] train: loss: 0.0000005
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000175
[Epoch 97; Iter   948/ 1097] train: loss: 0.0000007
[Epoch 97; Iter   978/ 1097] train: loss: 0.0000021
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000199
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000107
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000076
[Epoch 97] ogbg-molhiv: 0.680706 val loss: 3.621957
[Epoch 97] ogbg-molhiv: 0.579571 test loss: 4.224281
[Epoch 98; Iter     1/ 1097] train: loss: 0.0000279
[Epoch 98; Iter    31/ 1097] train: loss: 0.0025413
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000590
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000238
[Epoch 98; Iter   121/ 1097] train: loss: 0.0000124
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000004
[Epoch 98; Iter   181/ 1097] train: loss: 0.0004116
[Epoch 98; Iter   211/ 1097] train: loss: 0.0000003
[Epoch 98; Iter   241/ 1097] train: loss: 0.0001021
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000043
[Epoch 98; Iter   301/ 1097] train: loss: 0.0000174
[Epoch 98; Iter   331/ 1097] train: loss: 0.0000019
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000555
[Epoch 98; Iter   391/ 1097] train: loss: 0.0001942
[Epoch 98; Iter   421/ 1097] train: loss: 0.0030685
[Epoch 98; Iter   451/ 1097] train: loss: 0.0000032
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000637
[Epoch 98; Iter   511/ 1097] train: loss: 0.0000021
[Epoch 98; Iter   541/ 1097] train: loss: 0.0000084
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000177
[Epoch 98; Iter   601/ 1097] train: loss: 0.0003517
[Epoch 98; Iter   631/ 1097] train: loss: 0.0000030
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000109
[Epoch 98; Iter   691/ 1097] train: loss: 0.0000038
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000750
[Epoch 98; Iter   751/ 1097] train: loss: 0.0001609
[Epoch 98; Iter   781/ 1097] train: loss: 0.0000100
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000932
[Epoch 98; Iter   841/ 1097] train: loss: 0.0000087
[Epoch 98; Iter   871/ 1097] train: loss: 0.0000007
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000034
[Epoch 98; Iter   931/ 1097] train: loss: 0.0002501
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000123
[Epoch 98; Iter   991/ 1097] train: loss: 0.0000371
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0000077
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0000206
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0000179
[Epoch 98] ogbg-molhiv: 0.684267 val loss: 4.146084
[Epoch 98] ogbg-molhiv: 0.553205 test loss: 4.083846
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000144
[Epoch 99; Iter    44/ 1097] train: loss: 0.0000033
[Epoch 99; Iter    74/ 1097] train: loss: 0.0003898
[Epoch 99; Iter   104/ 1097] train: loss: 0.0030905
[Epoch 99; Iter   134/ 1097] train: loss: 0.0001605
[Epoch 99; Iter   164/ 1097] train: loss: 0.0002074
[Epoch 99; Iter   194/ 1097] train: loss: 0.0001848
[Epoch 99; Iter   224/ 1097] train: loss: 0.0000096
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000008
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000041
[Epoch 99; Iter   314/ 1097] train: loss: 0.0001214
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000124
[Epoch 99; Iter   374/ 1097] train: loss: 0.0000130
[Epoch 99; Iter   404/ 1097] train: loss: 0.0000153
[Epoch 99; Iter   434/ 1097] train: loss: 0.0000038
[Epoch 99; Iter   464/ 1097] train: loss: 0.0000046
[Epoch 99; Iter   494/ 1097] train: loss: 0.0002410
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000366
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000007
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000206
[Epoch 99; Iter   614/ 1097] train: loss: 0.0001062
[Epoch 99; Iter   644/ 1097] train: loss: 0.0000047
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000071
[Epoch 99; Iter   704/ 1097] train: loss: 0.0000556
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000723
[Epoch 99; Iter   764/ 1097] train: loss: 0.0002802
[Epoch 99; Iter   794/ 1097] train: loss: 0.0003696
[Epoch 99; Iter   824/ 1097] train: loss: 0.0000241
[Epoch 99; Iter   854/ 1097] train: loss: 0.0000034
[Epoch 99; Iter   884/ 1097] train: loss: 0.0000059
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000082
[Epoch 99; Iter   944/ 1097] train: loss: 0.0001134
[Epoch 99; Iter   974/ 1097] train: loss: 0.0000455
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0000002
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0000974
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000047
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0000151
[Epoch 99] ogbg-molhiv: 0.682785 val loss: 3.728573
[Epoch 99] ogbg-molhiv: 0.577771 test loss: 4.272293
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000672
[Epoch 100; Iter    57/ 1097] train: loss: 0.0000726
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000513
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000032
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000012
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000168
[Epoch 100; Iter   207/ 1097] train: loss: 0.0000131
[Epoch 100; Iter   237/ 1097] train: loss: 0.0000133
[Epoch 100; Iter   267/ 1097] train: loss: 0.0000081
[Epoch 100; Iter   297/ 1097] train: loss: 0.0020382
[Epoch 100; Iter   327/ 1097] train: loss: 0.0000297
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000686
[Epoch 100; Iter   387/ 1097] train: loss: 0.0000033
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000291
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000557
[Epoch 100; Iter   477/ 1097] train: loss: 0.0000079
[Epoch 100; Iter   507/ 1097] train: loss: 0.0004630
[Epoch 100; Iter   537/ 1097] train: loss: 0.0000220
[Epoch 100; Iter   567/ 1097] train: loss: 0.0000112
[Epoch 100; Iter   597/ 1097] train: loss: 0.0000075
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000744
[Epoch 100; Iter   657/ 1097] train: loss: 0.0000909
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000169
[Epoch 100; Iter   717/ 1097] train: loss: 0.0245177
[Epoch 100; Iter   747/ 1097] train: loss: 0.0361760
[Epoch 100; Iter   777/ 1097] train: loss: 0.0000029
[Epoch 100; Iter   807/ 1097] train: loss: 0.0001315
[Epoch 100; Iter   837/ 1097] train: loss: 0.0003998
[Epoch 100; Iter   867/ 1097] train: loss: 0.0000040
[Epoch 100; Iter   897/ 1097] train: loss: 0.0000037
[Epoch 100; Iter   927/ 1097] train: loss: 0.0000468
[Epoch 100; Iter   957/ 1097] train: loss: 0.0000148
[Epoch 100; Iter   987/ 1097] train: loss: 0.0000017
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000291
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0000051
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000002
[Epoch 100] ogbg-molhiv: 0.665260 val loss: 3.522577
[Epoch 100] ogbg-molhiv: 0.558692 test loss: 4.090907
[Epoch 101; Iter    10/ 1097] train: loss: 0.0000197
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000077
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000310
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000032
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000056
[Epoch 101; Iter   160/ 1097] train: loss: 0.0006737
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000509
[Epoch 101; Iter   220/ 1097] train: loss: 0.0000009
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000451
[Epoch 101; Iter   280/ 1097] train: loss: 0.0000013
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000632
[Epoch 101; Iter   340/ 1097] train: loss: 0.0533109
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000757
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000042
[Epoch 101; Iter   430/ 1097] train: loss: 0.0004779
[Epoch 101; Iter   460/ 1097] train: loss: 0.0000047
[Epoch 101; Iter   490/ 1097] train: loss: 0.0000971
[Epoch 101; Iter   520/ 1097] train: loss: 0.0003124
[Epoch 101; Iter   550/ 1097] train: loss: 0.0000009
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000011
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000439
[Epoch 101; Iter   640/ 1097] train: loss: 0.0008327
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000245
[Epoch 101; Iter   700/ 1097] train: loss: 0.0000035
[Epoch 77; Iter   268/ 1097] train: loss: 0.0267399
[Epoch 77; Iter   298/ 1097] train: loss: 0.1008945
[Epoch 77; Iter   328/ 1097] train: loss: 0.0007678
[Epoch 77; Iter   358/ 1097] train: loss: 0.0142354
[Epoch 77; Iter   388/ 1097] train: loss: 0.0141245
[Epoch 77; Iter   418/ 1097] train: loss: 0.0977076
[Epoch 77; Iter   448/ 1097] train: loss: 0.0129790
[Epoch 77; Iter   478/ 1097] train: loss: 0.0102103
[Epoch 77; Iter   508/ 1097] train: loss: 0.0104459
[Epoch 77; Iter   538/ 1097] train: loss: 0.0568537
[Epoch 77; Iter   568/ 1097] train: loss: 0.1294082
[Epoch 77; Iter   598/ 1097] train: loss: 0.0324155
[Epoch 77; Iter   628/ 1097] train: loss: 0.0074020
[Epoch 77; Iter   658/ 1097] train: loss: 0.2941950
[Epoch 77; Iter   688/ 1097] train: loss: 0.0152181
[Epoch 77; Iter   718/ 1097] train: loss: 0.0609717
[Epoch 77; Iter   748/ 1097] train: loss: 0.0105006
[Epoch 77; Iter   778/ 1097] train: loss: 0.0800830
[Epoch 77; Iter   808/ 1097] train: loss: 0.0176317
[Epoch 77; Iter   838/ 1097] train: loss: 0.0197750
[Epoch 77; Iter   868/ 1097] train: loss: 0.0197903
[Epoch 77; Iter   898/ 1097] train: loss: 0.0996794
[Epoch 77; Iter   928/ 1097] train: loss: 0.0115971
[Epoch 77; Iter   958/ 1097] train: loss: 0.0050873
[Epoch 77; Iter   988/ 1097] train: loss: 0.1853233
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0141746
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0171417
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0348029
[Epoch 77] ogbg-molhiv: 0.783865 val loss: 0.112774
[Epoch 77] ogbg-molhiv: 0.735814 test loss: 0.212095
[Epoch 78; Iter    11/ 1097] train: loss: 0.0062488
[Epoch 78; Iter    41/ 1097] train: loss: 0.0085313
[Epoch 78; Iter    71/ 1097] train: loss: 0.0522562
[Epoch 78; Iter   101/ 1097] train: loss: 0.0549297
[Epoch 78; Iter   131/ 1097] train: loss: 0.0681867
[Epoch 78; Iter   161/ 1097] train: loss: 0.0227934
[Epoch 78; Iter   191/ 1097] train: loss: 0.0098421
[Epoch 78; Iter   221/ 1097] train: loss: 0.0046811
[Epoch 78; Iter   251/ 1097] train: loss: 0.0736014
[Epoch 78; Iter   281/ 1097] train: loss: 0.0447678
[Epoch 78; Iter   311/ 1097] train: loss: 0.0047282
[Epoch 78; Iter   341/ 1097] train: loss: 0.0118180
[Epoch 78; Iter   371/ 1097] train: loss: 0.0276157
[Epoch 78; Iter   401/ 1097] train: loss: 0.0247080
[Epoch 78; Iter   431/ 1097] train: loss: 0.1033809
[Epoch 78; Iter   461/ 1097] train: loss: 0.0132832
[Epoch 78; Iter   491/ 1097] train: loss: 0.0195771
[Epoch 78; Iter   521/ 1097] train: loss: 0.0338338
[Epoch 78; Iter   551/ 1097] train: loss: 0.0536529
[Epoch 78; Iter   581/ 1097] train: loss: 0.0555205
[Epoch 78; Iter   611/ 1097] train: loss: 0.0222360
[Epoch 78; Iter   641/ 1097] train: loss: 0.0020832
[Epoch 78; Iter   671/ 1097] train: loss: 0.0085694
[Epoch 78; Iter   701/ 1097] train: loss: 0.0176872
[Epoch 78; Iter   731/ 1097] train: loss: 0.0037619
[Epoch 78; Iter   761/ 1097] train: loss: 0.1435092
[Epoch 78; Iter   791/ 1097] train: loss: 0.0197838
[Epoch 78; Iter   821/ 1097] train: loss: 0.0513831
[Epoch 78; Iter   851/ 1097] train: loss: 0.0129879
[Epoch 78; Iter   881/ 1097] train: loss: 0.0243143
[Epoch 78; Iter   911/ 1097] train: loss: 0.0100262
[Epoch 78; Iter   941/ 1097] train: loss: 0.0054830
[Epoch 78; Iter   971/ 1097] train: loss: 0.0064112
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0099112
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0592392
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0048599
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0331596
[Epoch 78] ogbg-molhiv: 0.805485 val loss: 0.104454
[Epoch 78] ogbg-molhiv: 0.739827 test loss: 0.204704
[Epoch 79; Iter    24/ 1097] train: loss: 0.0990279
[Epoch 79; Iter    54/ 1097] train: loss: 0.0956388
[Epoch 79; Iter    84/ 1097] train: loss: 0.0251383
[Epoch 79; Iter   114/ 1097] train: loss: 0.0221801
[Epoch 79; Iter   144/ 1097] train: loss: 0.0043900
[Epoch 79; Iter   174/ 1097] train: loss: 0.0166825
[Epoch 79; Iter   204/ 1097] train: loss: 0.0659167
[Epoch 79; Iter   234/ 1097] train: loss: 0.0659371
[Epoch 79; Iter   264/ 1097] train: loss: 0.0278879
[Epoch 79; Iter   294/ 1097] train: loss: 0.1213838
[Epoch 79; Iter   324/ 1097] train: loss: 0.0025737
[Epoch 79; Iter   354/ 1097] train: loss: 0.0136564
[Epoch 79; Iter   384/ 1097] train: loss: 0.0206646
[Epoch 79; Iter   414/ 1097] train: loss: 0.0135223
[Epoch 79; Iter   444/ 1097] train: loss: 0.0310680
[Epoch 79; Iter   474/ 1097] train: loss: 0.1116528
[Epoch 79; Iter   504/ 1097] train: loss: 0.0101102
[Epoch 79; Iter   534/ 1097] train: loss: 0.0474703
[Epoch 79; Iter   564/ 1097] train: loss: 0.0157549
[Epoch 79; Iter   594/ 1097] train: loss: 0.0122548
[Epoch 79; Iter   624/ 1097] train: loss: 0.0446042
[Epoch 79; Iter   654/ 1097] train: loss: 0.0073270
[Epoch 79; Iter   684/ 1097] train: loss: 0.0397616
[Epoch 79; Iter   714/ 1097] train: loss: 0.0653391
[Epoch 79; Iter   744/ 1097] train: loss: 0.0207540
[Epoch 79; Iter   774/ 1097] train: loss: 0.1587290
[Epoch 79; Iter   804/ 1097] train: loss: 0.1466188
[Epoch 79; Iter   834/ 1097] train: loss: 0.0274013
[Epoch 79; Iter   864/ 1097] train: loss: 0.1056195
[Epoch 79; Iter   894/ 1097] train: loss: 0.0369407
[Epoch 79; Iter   924/ 1097] train: loss: 0.0420896
[Epoch 79; Iter   954/ 1097] train: loss: 0.0025650
[Epoch 79; Iter   984/ 1097] train: loss: 0.0234052
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0418783
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0581613
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0045483
[Epoch 79] ogbg-molhiv: 0.806832 val loss: 0.128012
[Epoch 79] ogbg-molhiv: 0.745449 test loss: 0.218358
[Epoch 80; Iter     7/ 1097] train: loss: 0.0186486
[Epoch 80; Iter    37/ 1097] train: loss: 0.0067687
[Epoch 80; Iter    67/ 1097] train: loss: 0.0906692
[Epoch 80; Iter    97/ 1097] train: loss: 0.0367203
[Epoch 80; Iter   127/ 1097] train: loss: 0.0569312
[Epoch 80; Iter   157/ 1097] train: loss: 0.0302789
[Epoch 80; Iter   187/ 1097] train: loss: 0.1158745
[Epoch 80; Iter   217/ 1097] train: loss: 0.1432806
[Epoch 80; Iter   247/ 1097] train: loss: 0.0232117
[Epoch 80; Iter   277/ 1097] train: loss: 0.0195328
[Epoch 80; Iter   307/ 1097] train: loss: 0.0106280
[Epoch 80; Iter   337/ 1097] train: loss: 0.1049253
[Epoch 80; Iter   367/ 1097] train: loss: 0.0274507
[Epoch 80; Iter   397/ 1097] train: loss: 0.0471244
[Epoch 80; Iter   427/ 1097] train: loss: 0.0332491
[Epoch 80; Iter   457/ 1097] train: loss: 0.0938954
[Epoch 80; Iter   487/ 1097] train: loss: 0.0123930
[Epoch 80; Iter   517/ 1097] train: loss: 0.0383300
[Epoch 80; Iter   547/ 1097] train: loss: 0.0072717
[Epoch 80; Iter   577/ 1097] train: loss: 0.0261671
[Epoch 80; Iter   607/ 1097] train: loss: 0.0438515
[Epoch 80; Iter   637/ 1097] train: loss: 0.0140965
[Epoch 80; Iter   667/ 1097] train: loss: 0.0202363
[Epoch 80; Iter   697/ 1097] train: loss: 0.0286230
[Epoch 80; Iter   727/ 1097] train: loss: 0.0132547
[Epoch 80; Iter   757/ 1097] train: loss: 0.0251727
[Epoch 80; Iter   787/ 1097] train: loss: 0.0138374
[Epoch 80; Iter   817/ 1097] train: loss: 0.0091887
[Epoch 80; Iter   847/ 1097] train: loss: 0.0159922
[Epoch 80; Iter   877/ 1097] train: loss: 0.0600348
[Epoch 80; Iter   907/ 1097] train: loss: 0.0056355
[Epoch 80; Iter   937/ 1097] train: loss: 0.1495771
[Epoch 80; Iter   967/ 1097] train: loss: 0.0152006
[Epoch 80; Iter   997/ 1097] train: loss: 0.0043420
[Epoch 80; Iter  1027/ 1097] train: loss: 0.1254292
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0331291
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0114067
[Epoch 80] ogbg-molhiv: 0.798048 val loss: 0.109511
[Epoch 80] ogbg-molhiv: 0.749692 test loss: 0.217966
[Epoch 81; Iter    20/ 1097] train: loss: 0.0180564
[Epoch 81; Iter    50/ 1097] train: loss: 0.0179040
[Epoch 81; Iter    80/ 1097] train: loss: 0.0400466
[Epoch 81; Iter   110/ 1097] train: loss: 0.0069067
[Epoch 81; Iter   140/ 1097] train: loss: 0.0104358
[Epoch 81; Iter   170/ 1097] train: loss: 0.0456242
[Epoch 81; Iter   200/ 1097] train: loss: 0.0650426
[Epoch 81; Iter   230/ 1097] train: loss: 0.0509325
[Epoch 81; Iter   260/ 1097] train: loss: 0.2380765
[Epoch 81; Iter   290/ 1097] train: loss: 0.0328838
[Epoch 81; Iter   320/ 1097] train: loss: 0.0070357
[Epoch 77; Iter   268/ 1097] train: loss: 0.0072056
[Epoch 77; Iter   298/ 1097] train: loss: 0.0028422
[Epoch 77; Iter   328/ 1097] train: loss: 0.1340244
[Epoch 77; Iter   358/ 1097] train: loss: 0.0163563
[Epoch 77; Iter   388/ 1097] train: loss: 0.0326923
[Epoch 77; Iter   418/ 1097] train: loss: 0.0021839
[Epoch 77; Iter   448/ 1097] train: loss: 0.0031742
[Epoch 77; Iter   478/ 1097] train: loss: 0.0466993
[Epoch 77; Iter   508/ 1097] train: loss: 0.0208838
[Epoch 77; Iter   538/ 1097] train: loss: 0.2260501
[Epoch 77; Iter   568/ 1097] train: loss: 0.0193386
[Epoch 77; Iter   598/ 1097] train: loss: 0.0879946
[Epoch 77; Iter   628/ 1097] train: loss: 0.0059929
[Epoch 77; Iter   658/ 1097] train: loss: 0.0035135
[Epoch 77; Iter   688/ 1097] train: loss: 0.0644923
[Epoch 77; Iter   718/ 1097] train: loss: 0.0093240
[Epoch 77; Iter   748/ 1097] train: loss: 0.0389946
[Epoch 77; Iter   778/ 1097] train: loss: 0.0054658
[Epoch 77; Iter   808/ 1097] train: loss: 0.0365829
[Epoch 77; Iter   838/ 1097] train: loss: 0.0309022
[Epoch 77; Iter   868/ 1097] train: loss: 0.0033074
[Epoch 77; Iter   898/ 1097] train: loss: 0.0028750
[Epoch 77; Iter   928/ 1097] train: loss: 0.0566680
[Epoch 77; Iter   958/ 1097] train: loss: 0.0173328
[Epoch 77; Iter   988/ 1097] train: loss: 0.0037706
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0075754
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0152231
[Epoch 77; Iter  1078/ 1097] train: loss: 0.1391674
[Epoch 77] ogbg-molhiv: 0.791100 val loss: 0.115387
[Epoch 77] ogbg-molhiv: 0.748979 test loss: 0.226587
[Epoch 78; Iter    11/ 1097] train: loss: 0.0743057
[Epoch 78; Iter    41/ 1097] train: loss: 0.0076782
[Epoch 78; Iter    71/ 1097] train: loss: 0.0157375
[Epoch 78; Iter   101/ 1097] train: loss: 0.0051241
[Epoch 78; Iter   131/ 1097] train: loss: 0.0162390
[Epoch 78; Iter   161/ 1097] train: loss: 0.0209744
[Epoch 78; Iter   191/ 1097] train: loss: 0.0451403
[Epoch 78; Iter   221/ 1097] train: loss: 0.0036133
[Epoch 78; Iter   251/ 1097] train: loss: 0.0499337
[Epoch 78; Iter   281/ 1097] train: loss: 0.0421191
[Epoch 78; Iter   311/ 1097] train: loss: 0.0018832
[Epoch 78; Iter   341/ 1097] train: loss: 0.0086139
[Epoch 78; Iter   371/ 1097] train: loss: 0.1357210
[Epoch 78; Iter   401/ 1097] train: loss: 0.0044498
[Epoch 78; Iter   431/ 1097] train: loss: 0.0094715
[Epoch 78; Iter   461/ 1097] train: loss: 0.0040682
[Epoch 78; Iter   491/ 1097] train: loss: 0.0017712
[Epoch 78; Iter   521/ 1097] train: loss: 0.0082865
[Epoch 78; Iter   551/ 1097] train: loss: 0.0044848
[Epoch 78; Iter   581/ 1097] train: loss: 0.3288424
[Epoch 78; Iter   611/ 1097] train: loss: 0.0079575
[Epoch 78; Iter   641/ 1097] train: loss: 0.0049514
[Epoch 78; Iter   671/ 1097] train: loss: 0.0012086
[Epoch 78; Iter   701/ 1097] train: loss: 0.0192282
[Epoch 78; Iter   731/ 1097] train: loss: 0.0029610
[Epoch 78; Iter   761/ 1097] train: loss: 0.0099397
[Epoch 78; Iter   791/ 1097] train: loss: 0.0191540
[Epoch 78; Iter   821/ 1097] train: loss: 0.0576765
[Epoch 78; Iter   851/ 1097] train: loss: 0.1052870
[Epoch 78; Iter   881/ 1097] train: loss: 0.0057237
[Epoch 78; Iter   911/ 1097] train: loss: 0.0070033
[Epoch 78; Iter   941/ 1097] train: loss: 0.0087046
[Epoch 78; Iter   971/ 1097] train: loss: 0.0077686
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0235385
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0114150
[Epoch 78; Iter  1061/ 1097] train: loss: 0.1059705
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0047137
[Epoch 78] ogbg-molhiv: 0.784832 val loss: 0.124038
[Epoch 78] ogbg-molhiv: 0.737442 test loss: 0.222525
[Epoch 79; Iter    24/ 1097] train: loss: 0.0182111
[Epoch 79; Iter    54/ 1097] train: loss: 0.0610227
[Epoch 79; Iter    84/ 1097] train: loss: 0.0135687
[Epoch 79; Iter   114/ 1097] train: loss: 0.0081746
[Epoch 79; Iter   144/ 1097] train: loss: 0.0038248
[Epoch 79; Iter   174/ 1097] train: loss: 0.0047096
[Epoch 79; Iter   204/ 1097] train: loss: 0.0023468
[Epoch 79; Iter   234/ 1097] train: loss: 0.0066870
[Epoch 79; Iter   264/ 1097] train: loss: 0.0032529
[Epoch 79; Iter   294/ 1097] train: loss: 0.0006117
[Epoch 79; Iter   324/ 1097] train: loss: 0.0122699
[Epoch 79; Iter   354/ 1097] train: loss: 0.2035674
[Epoch 79; Iter   384/ 1097] train: loss: 0.0027577
[Epoch 79; Iter   414/ 1097] train: loss: 0.0873219
[Epoch 79; Iter   444/ 1097] train: loss: 0.0070196
[Epoch 79; Iter   474/ 1097] train: loss: 0.0861833
[Epoch 79; Iter   504/ 1097] train: loss: 0.0038981
[Epoch 79; Iter   534/ 1097] train: loss: 0.0543620
[Epoch 79; Iter   564/ 1097] train: loss: 0.0115426
[Epoch 79; Iter   594/ 1097] train: loss: 0.0049007
[Epoch 79; Iter   624/ 1097] train: loss: 0.0190067
[Epoch 79; Iter   654/ 1097] train: loss: 0.0137335
[Epoch 79; Iter   684/ 1097] train: loss: 0.0161599
[Epoch 79; Iter   714/ 1097] train: loss: 0.0217637
[Epoch 79; Iter   744/ 1097] train: loss: 0.0283771
[Epoch 79; Iter   774/ 1097] train: loss: 0.0453740
[Epoch 79; Iter   804/ 1097] train: loss: 0.0100983
[Epoch 79; Iter   834/ 1097] train: loss: 0.0596104
[Epoch 79; Iter   864/ 1097] train: loss: 0.0219497
[Epoch 79; Iter   894/ 1097] train: loss: 0.0255575
[Epoch 79; Iter   924/ 1097] train: loss: 0.0179110
[Epoch 79; Iter   954/ 1097] train: loss: 0.0210971
[Epoch 79; Iter   984/ 1097] train: loss: 0.0553537
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0190580
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0029886
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0099591
[Epoch 79] ogbg-molhiv: 0.789171 val loss: 0.122730
[Epoch 79] ogbg-molhiv: 0.744671 test loss: 0.218141
[Epoch 80; Iter     7/ 1097] train: loss: 0.0032767
[Epoch 80; Iter    37/ 1097] train: loss: 0.0522803
[Epoch 80; Iter    67/ 1097] train: loss: 0.1034553
[Epoch 80; Iter    97/ 1097] train: loss: 0.0005277
[Epoch 80; Iter   127/ 1097] train: loss: 0.0081810
[Epoch 80; Iter   157/ 1097] train: loss: 0.0066561
[Epoch 80; Iter   187/ 1097] train: loss: 0.0042306
[Epoch 80; Iter   217/ 1097] train: loss: 0.0757242
[Epoch 80; Iter   247/ 1097] train: loss: 0.0115337
[Epoch 80; Iter   277/ 1097] train: loss: 0.0012554
[Epoch 80; Iter   307/ 1097] train: loss: 0.1493388
[Epoch 80; Iter   337/ 1097] train: loss: 0.0099378
[Epoch 80; Iter   367/ 1097] train: loss: 0.0027176
[Epoch 80; Iter   397/ 1097] train: loss: 0.0063856
[Epoch 80; Iter   427/ 1097] train: loss: 0.0286456
[Epoch 80; Iter   457/ 1097] train: loss: 0.0595953
[Epoch 80; Iter   487/ 1097] train: loss: 0.0080639
[Epoch 80; Iter   517/ 1097] train: loss: 0.1535826
[Epoch 80; Iter   547/ 1097] train: loss: 0.0737342
[Epoch 80; Iter   577/ 1097] train: loss: 0.0024554
[Epoch 80; Iter   607/ 1097] train: loss: 0.0019339
[Epoch 80; Iter   637/ 1097] train: loss: 0.0034465
[Epoch 80; Iter   667/ 1097] train: loss: 0.0048321
[Epoch 80; Iter   697/ 1097] train: loss: 0.0191164
[Epoch 80; Iter   727/ 1097] train: loss: 0.0079506
[Epoch 80; Iter   757/ 1097] train: loss: 0.0268314
[Epoch 80; Iter   787/ 1097] train: loss: 0.0345317
[Epoch 80; Iter   817/ 1097] train: loss: 0.0140761
[Epoch 80; Iter   847/ 1097] train: loss: 0.0056643
[Epoch 80; Iter   877/ 1097] train: loss: 0.0653942
[Epoch 80; Iter   907/ 1097] train: loss: 0.0062026
[Epoch 80; Iter   937/ 1097] train: loss: 0.0998838
[Epoch 80; Iter   967/ 1097] train: loss: 0.0103807
[Epoch 80; Iter   997/ 1097] train: loss: 0.1196999
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0024774
[Epoch 80; Iter  1057/ 1097] train: loss: 0.1027734
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0025624
[Epoch 80] ogbg-molhiv: 0.787460 val loss: 0.118502
[Epoch 80] ogbg-molhiv: 0.730818 test loss: 0.249785
[Epoch 81; Iter    20/ 1097] train: loss: 0.0057763
[Epoch 81; Iter    50/ 1097] train: loss: 0.0142015
[Epoch 81; Iter    80/ 1097] train: loss: 0.0512170
[Epoch 81; Iter   110/ 1097] train: loss: 0.0146536
[Epoch 81; Iter   140/ 1097] train: loss: 0.0176764
[Epoch 81; Iter   170/ 1097] train: loss: 0.0062438
[Epoch 81; Iter   200/ 1097] train: loss: 0.0213483
[Epoch 81; Iter   230/ 1097] train: loss: 0.0008703
[Epoch 81; Iter   260/ 1097] train: loss: 0.0881007
[Epoch 81; Iter   290/ 1097] train: loss: 0.0098827
[Epoch 81; Iter   320/ 1097] train: loss: 0.0041872
[Epoch 97; Iter   678/ 1097] train: loss: 0.0001620
[Epoch 97; Iter   708/ 1097] train: loss: 0.0010160
[Epoch 97; Iter   738/ 1097] train: loss: 0.0004675
[Epoch 97; Iter   768/ 1097] train: loss: 0.0000083
[Epoch 97; Iter   798/ 1097] train: loss: 0.0000016
[Epoch 97; Iter   828/ 1097] train: loss: 0.0000129
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000047
[Epoch 97; Iter   888/ 1097] train: loss: 0.0001756
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000186
[Epoch 97; Iter   948/ 1097] train: loss: 0.0000727
[Epoch 97; Iter   978/ 1097] train: loss: 0.0000019
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0000095
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0000413
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000442
[Epoch 97] ogbg-molhiv: 0.729467 val loss: 0.552342
[Epoch 97] ogbg-molhiv: 0.714429 test loss: 0.956501
[Epoch 98; Iter     1/ 1097] train: loss: 0.0000007
[Epoch 98; Iter    31/ 1097] train: loss: 0.0000684
[Epoch 98; Iter    61/ 1097] train: loss: 0.0000358
[Epoch 98; Iter    91/ 1097] train: loss: 0.0000027
[Epoch 98; Iter   121/ 1097] train: loss: 0.0004173
[Epoch 98; Iter   151/ 1097] train: loss: 0.0004569
[Epoch 98; Iter   181/ 1097] train: loss: 0.0010070
[Epoch 98; Iter   211/ 1097] train: loss: 0.0000024
[Epoch 98; Iter   241/ 1097] train: loss: 0.0000138
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000005
[Epoch 98; Iter   301/ 1097] train: loss: 0.0000043
[Epoch 98; Iter   331/ 1097] train: loss: 0.0080985
[Epoch 98; Iter   361/ 1097] train: loss: 0.0002006
[Epoch 98; Iter   391/ 1097] train: loss: 0.0000053
[Epoch 98; Iter   421/ 1097] train: loss: 0.0000019
[Epoch 98; Iter   451/ 1097] train: loss: 0.0000361
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000068
[Epoch 98; Iter   511/ 1097] train: loss: 0.0000455
[Epoch 98; Iter   541/ 1097] train: loss: 0.0043935
[Epoch 98; Iter   571/ 1097] train: loss: 0.0000345
[Epoch 98; Iter   601/ 1097] train: loss: 0.0000135
[Epoch 98; Iter   631/ 1097] train: loss: 0.0001182
[Epoch 98; Iter   661/ 1097] train: loss: 0.0000057
[Epoch 98; Iter   691/ 1097] train: loss: 0.0000046
[Epoch 98; Iter   721/ 1097] train: loss: 0.0000039
[Epoch 98; Iter   751/ 1097] train: loss: 0.0000085
[Epoch 98; Iter   781/ 1097] train: loss: 0.0002804
[Epoch 98; Iter   811/ 1097] train: loss: 0.0000028
[Epoch 98; Iter   841/ 1097] train: loss: 0.0003353
[Epoch 98; Iter   871/ 1097] train: loss: 0.0000051
[Epoch 98; Iter   901/ 1097] train: loss: 0.0000097
[Epoch 98; Iter   931/ 1097] train: loss: 0.0001377
[Epoch 98; Iter   961/ 1097] train: loss: 0.0000039
[Epoch 98; Iter   991/ 1097] train: loss: 0.0000039
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0011852
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0000043
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0005887
[Epoch 98] ogbg-molhiv: 0.742452 val loss: 0.331546
[Epoch 98] ogbg-molhiv: 0.721221 test loss: 0.474878
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000091
[Epoch 99; Iter    44/ 1097] train: loss: 0.0006070
[Epoch 99; Iter    74/ 1097] train: loss: 0.0010138
[Epoch 99; Iter   104/ 1097] train: loss: 0.0000531
[Epoch 99; Iter   134/ 1097] train: loss: 0.0002897
[Epoch 99; Iter   164/ 1097] train: loss: 0.0002355
[Epoch 99; Iter   194/ 1097] train: loss: 0.0001446
[Epoch 99; Iter   224/ 1097] train: loss: 0.0000022
[Epoch 99; Iter   254/ 1097] train: loss: 0.0000418
[Epoch 99; Iter   284/ 1097] train: loss: 0.0000045
[Epoch 99; Iter   314/ 1097] train: loss: 0.0000502
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000493
[Epoch 99; Iter   374/ 1097] train: loss: 0.0000062
[Epoch 99; Iter   404/ 1097] train: loss: 0.0029745
[Epoch 99; Iter   434/ 1097] train: loss: 0.0004231
[Epoch 99; Iter   464/ 1097] train: loss: 0.0003099
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000020
[Epoch 99; Iter   524/ 1097] train: loss: 0.0006909
[Epoch 99; Iter   554/ 1097] train: loss: 0.0000311
[Epoch 99; Iter   584/ 1097] train: loss: 0.0000387
[Epoch 99; Iter   614/ 1097] train: loss: 0.0002963
[Epoch 99; Iter   644/ 1097] train: loss: 0.0000200
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000135
[Epoch 99; Iter   704/ 1097] train: loss: 0.0001577
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000053
[Epoch 99; Iter   764/ 1097] train: loss: 0.0017994
[Epoch 99; Iter   794/ 1097] train: loss: 0.0000117
[Epoch 99; Iter   824/ 1097] train: loss: 0.0001027
[Epoch 99; Iter   854/ 1097] train: loss: 0.0007958
[Epoch 99; Iter   884/ 1097] train: loss: 0.0009388
[Epoch 99; Iter   914/ 1097] train: loss: 0.0000001
[Epoch 99; Iter   944/ 1097] train: loss: 0.0000720
[Epoch 99; Iter   974/ 1097] train: loss: 0.0309030
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0023276
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0000027
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0000005
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0000746
[Epoch 99] ogbg-molhiv: 0.749461 val loss: 0.580660
[Epoch 99] ogbg-molhiv: 0.726797 test loss: 1.761153
[Epoch 100; Iter    27/ 1097] train: loss: 0.0002810
[Epoch 100; Iter    57/ 1097] train: loss: 0.0001610
[Epoch 100; Iter    87/ 1097] train: loss: 0.0000423
[Epoch 100; Iter   117/ 1097] train: loss: 0.0000204
[Epoch 100; Iter   147/ 1097] train: loss: 0.0012233
[Epoch 100; Iter   177/ 1097] train: loss: 0.0000214
[Epoch 100; Iter   207/ 1097] train: loss: 0.0000126
[Epoch 100; Iter   237/ 1097] train: loss: 0.0000061
[Epoch 100; Iter   267/ 1097] train: loss: 0.0005418
[Epoch 100; Iter   297/ 1097] train: loss: 0.0000004
[Epoch 100; Iter   327/ 1097] train: loss: 0.0000022
[Epoch 100; Iter   357/ 1097] train: loss: 0.0000078
[Epoch 100; Iter   387/ 1097] train: loss: 0.0000031
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000041
[Epoch 100; Iter   447/ 1097] train: loss: 0.0000025
[Epoch 100; Iter   477/ 1097] train: loss: 0.0004040
[Epoch 100; Iter   507/ 1097] train: loss: 0.0000015
[Epoch 100; Iter   537/ 1097] train: loss: 0.0000354
[Epoch 100; Iter   567/ 1097] train: loss: 0.0000346
[Epoch 100; Iter   597/ 1097] train: loss: 0.0054357
[Epoch 100; Iter   627/ 1097] train: loss: 0.0003933
[Epoch 100; Iter   657/ 1097] train: loss: 0.0000089
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000061
[Epoch 100; Iter   717/ 1097] train: loss: 0.0013659
[Epoch 100; Iter   747/ 1097] train: loss: 0.0000012
[Epoch 100; Iter   777/ 1097] train: loss: 0.0000050
[Epoch 100; Iter   807/ 1097] train: loss: 0.0000265
[Epoch 100; Iter   837/ 1097] train: loss: 0.0000185
[Epoch 100; Iter   867/ 1097] train: loss: 0.0000171
[Epoch 100; Iter   897/ 1097] train: loss: 0.0006098
[Epoch 100; Iter   927/ 1097] train: loss: 0.0000199
[Epoch 100; Iter   957/ 1097] train: loss: 0.0034311
[Epoch 100; Iter   987/ 1097] train: loss: 0.0000699
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000211
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0000546
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0000017
[Epoch 100] ogbg-molhiv: 0.780374 val loss: 1.262128
[Epoch 100] ogbg-molhiv: 0.724462 test loss: 2.732178
[Epoch 101; Iter    10/ 1097] train: loss: 0.0000509
[Epoch 101; Iter    40/ 1097] train: loss: 0.0000001
[Epoch 101; Iter    70/ 1097] train: loss: 0.0000319
[Epoch 101; Iter   100/ 1097] train: loss: 0.0000037
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000430
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000408
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000490
[Epoch 101; Iter   220/ 1097] train: loss: 0.0001057
[Epoch 101; Iter   250/ 1097] train: loss: 0.0000075
[Epoch 101; Iter   280/ 1097] train: loss: 0.0000168
[Epoch 101; Iter   310/ 1097] train: loss: 0.0000015
[Epoch 101; Iter   340/ 1097] train: loss: 0.0000066
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000245
[Epoch 101; Iter   400/ 1097] train: loss: 0.0000091
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000293
[Epoch 101; Iter   460/ 1097] train: loss: 0.0001442
[Epoch 101; Iter   490/ 1097] train: loss: 0.0000223
[Epoch 101; Iter   520/ 1097] train: loss: 0.0001544
[Epoch 101; Iter   550/ 1097] train: loss: 0.0000014
[Epoch 101; Iter   580/ 1097] train: loss: 0.0000599
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000307
[Epoch 101; Iter   640/ 1097] train: loss: 0.0000086
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000639
[Epoch 101; Iter   700/ 1097] train: loss: 0.0001059
[Epoch 97; Iter   678/ 1097] train: loss: 0.0016296
[Epoch 97; Iter   708/ 1097] train: loss: 0.0296288
[Epoch 97; Iter   738/ 1097] train: loss: 0.0001039
[Epoch 97; Iter   768/ 1097] train: loss: 0.0012981
[Epoch 97; Iter   798/ 1097] train: loss: 0.0000228
[Epoch 97; Iter   828/ 1097] train: loss: 0.0080510
[Epoch 97; Iter   858/ 1097] train: loss: 0.0000289
[Epoch 97; Iter   888/ 1097] train: loss: 0.0007038
[Epoch 97; Iter   918/ 1097] train: loss: 0.0000601
[Epoch 97; Iter   948/ 1097] train: loss: 0.0001384
[Epoch 97; Iter   978/ 1097] train: loss: 0.0019610
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0056026
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0131781
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0000074
[Epoch 97] ogbg-molhiv: 0.692335 val loss: 47.414531
[Epoch 97] ogbg-molhiv: 0.619305 test loss: 37.541362
[Epoch 98; Iter     1/ 1097] train: loss: 0.0104382
[Epoch 98; Iter    31/ 1097] train: loss: 0.0002074
[Epoch 98; Iter    61/ 1097] train: loss: 0.0098036
[Epoch 98; Iter    91/ 1097] train: loss: 0.0005591
[Epoch 98; Iter   121/ 1097] train: loss: 0.0158958
[Epoch 98; Iter   151/ 1097] train: loss: 0.0000075
[Epoch 98; Iter   181/ 1097] train: loss: 0.0000472
[Epoch 98; Iter   211/ 1097] train: loss: 0.0016316
[Epoch 98; Iter   241/ 1097] train: loss: 0.0016802
[Epoch 98; Iter   271/ 1097] train: loss: 0.0000164
[Epoch 98; Iter   301/ 1097] train: loss: 0.0034383
[Epoch 98; Iter   331/ 1097] train: loss: 0.0002471
[Epoch 98; Iter   361/ 1097] train: loss: 0.0000676
[Epoch 98; Iter   391/ 1097] train: loss: 0.0013128
[Epoch 98; Iter   421/ 1097] train: loss: 0.0234171
[Epoch 98; Iter   451/ 1097] train: loss: 0.0016474
[Epoch 98; Iter   481/ 1097] train: loss: 0.0000234
[Epoch 98; Iter   511/ 1097] train: loss: 0.0001524
[Epoch 98; Iter   541/ 1097] train: loss: 0.0097652
[Epoch 98; Iter   571/ 1097] train: loss: 0.0016287
[Epoch 98; Iter   601/ 1097] train: loss: 0.0001751
[Epoch 98; Iter   631/ 1097] train: loss: 0.0030828
[Epoch 98; Iter   661/ 1097] train: loss: 0.0002028
[Epoch 98; Iter   691/ 1097] train: loss: 0.0228891
[Epoch 98; Iter   721/ 1097] train: loss: 0.2292049
[Epoch 98; Iter   751/ 1097] train: loss: 0.0011709
[Epoch 98; Iter   781/ 1097] train: loss: 0.0000152
[Epoch 98; Iter   811/ 1097] train: loss: 0.0005303
[Epoch 98; Iter   841/ 1097] train: loss: 0.0000862
[Epoch 98; Iter   871/ 1097] train: loss: 0.0002198
[Epoch 98; Iter   901/ 1097] train: loss: 0.0105101
[Epoch 98; Iter   931/ 1097] train: loss: 0.0051550
[Epoch 98; Iter   961/ 1097] train: loss: 0.0834746
[Epoch 98; Iter   991/ 1097] train: loss: 0.0005524
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0010576
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0023131
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0001587
[Epoch 98] ogbg-molhiv: 0.689977 val loss: 42.240651
[Epoch 98] ogbg-molhiv: 0.603426 test loss: 32.983567
[Epoch 99; Iter    14/ 1097] train: loss: 0.0000159
[Epoch 99; Iter    44/ 1097] train: loss: 0.0019019
[Epoch 99; Iter    74/ 1097] train: loss: 0.0004715
[Epoch 99; Iter   104/ 1097] train: loss: 0.0006765
[Epoch 99; Iter   134/ 1097] train: loss: 0.0001824
[Epoch 99; Iter   164/ 1097] train: loss: 0.0252971
[Epoch 99; Iter   194/ 1097] train: loss: 0.0018653
[Epoch 99; Iter   224/ 1097] train: loss: 0.0003177
[Epoch 99; Iter   254/ 1097] train: loss: 0.0262363
[Epoch 99; Iter   284/ 1097] train: loss: 0.0397220
[Epoch 99; Iter   314/ 1097] train: loss: 0.0002972
[Epoch 99; Iter   344/ 1097] train: loss: 0.0000092
[Epoch 99; Iter   374/ 1097] train: loss: 0.0007266
[Epoch 99; Iter   404/ 1097] train: loss: 0.0000436
[Epoch 99; Iter   434/ 1097] train: loss: 0.0000603
[Epoch 99; Iter   464/ 1097] train: loss: 0.0019169
[Epoch 99; Iter   494/ 1097] train: loss: 0.0000088
[Epoch 99; Iter   524/ 1097] train: loss: 0.0000537
[Epoch 99; Iter   554/ 1097] train: loss: 0.0004039
[Epoch 99; Iter   584/ 1097] train: loss: 0.0062979
[Epoch 99; Iter   614/ 1097] train: loss: 0.0000333
[Epoch 99; Iter   644/ 1097] train: loss: 0.0057668
[Epoch 99; Iter   674/ 1097] train: loss: 0.0000623
[Epoch 99; Iter   704/ 1097] train: loss: 0.0002114
[Epoch 99; Iter   734/ 1097] train: loss: 0.0000022
[Epoch 99; Iter   764/ 1097] train: loss: 0.0006604
[Epoch 99; Iter   794/ 1097] train: loss: 0.0013639
[Epoch 99; Iter   824/ 1097] train: loss: 0.0000786
[Epoch 99; Iter   854/ 1097] train: loss: 0.0002329
[Epoch 99; Iter   884/ 1097] train: loss: 0.0001271
[Epoch 99; Iter   914/ 1097] train: loss: 0.0030312
[Epoch 99; Iter   944/ 1097] train: loss: 0.0000182
[Epoch 99; Iter   974/ 1097] train: loss: 0.0001150
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0001894
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0004401
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0250631
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0001151
[Epoch 99] ogbg-molhiv: 0.699448 val loss: 38.247293
[Epoch 99] ogbg-molhiv: 0.605099 test loss: 28.958446
[Epoch 100; Iter    27/ 1097] train: loss: 0.0000475
[Epoch 100; Iter    57/ 1097] train: loss: 0.0000270
[Epoch 100; Iter    87/ 1097] train: loss: 0.0002705
[Epoch 100; Iter   117/ 1097] train: loss: 0.0005459
[Epoch 100; Iter   147/ 1097] train: loss: 0.0000370
[Epoch 100; Iter   177/ 1097] train: loss: 0.0002300
[Epoch 100; Iter   207/ 1097] train: loss: 0.0034428
[Epoch 100; Iter   237/ 1097] train: loss: 0.0005939
[Epoch 100; Iter   267/ 1097] train: loss: 0.0001700
[Epoch 100; Iter   297/ 1097] train: loss: 0.0172329
[Epoch 100; Iter   327/ 1097] train: loss: 0.0003695
[Epoch 100; Iter   357/ 1097] train: loss: 0.0003200
[Epoch 100; Iter   387/ 1097] train: loss: 0.0025126
[Epoch 100; Iter   417/ 1097] train: loss: 0.0000333
[Epoch 100; Iter   447/ 1097] train: loss: 0.0007115
[Epoch 100; Iter   477/ 1097] train: loss: 0.0000643
[Epoch 100; Iter   507/ 1097] train: loss: 0.0007177
[Epoch 100; Iter   537/ 1097] train: loss: 0.0003053
[Epoch 100; Iter   567/ 1097] train: loss: 0.0001037
[Epoch 100; Iter   597/ 1097] train: loss: 0.0001928
[Epoch 100; Iter   627/ 1097] train: loss: 0.0000015
[Epoch 100; Iter   657/ 1097] train: loss: 0.0001488
[Epoch 100; Iter   687/ 1097] train: loss: 0.0000303
[Epoch 100; Iter   717/ 1097] train: loss: 0.0005901
[Epoch 100; Iter   747/ 1097] train: loss: 0.0000234
[Epoch 100; Iter   777/ 1097] train: loss: 0.0004321
[Epoch 100; Iter   807/ 1097] train: loss: 0.0404625
[Epoch 100; Iter   837/ 1097] train: loss: 0.0000428
[Epoch 100; Iter   867/ 1097] train: loss: 0.0002654
[Epoch 100; Iter   897/ 1097] train: loss: 0.0484827
[Epoch 100; Iter   927/ 1097] train: loss: 0.0000570
[Epoch 100; Iter   957/ 1097] train: loss: 0.0283289
[Epoch 100; Iter   987/ 1097] train: loss: 0.0449615
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0000041
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0010373
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0003732
[Epoch 100] ogbg-molhiv: 0.717801 val loss: 54.583235
[Epoch 100] ogbg-molhiv: 0.625692 test loss: 41.201760
[Epoch 101; Iter    10/ 1097] train: loss: 0.0001166
[Epoch 101; Iter    40/ 1097] train: loss: 0.0033449
[Epoch 101; Iter    70/ 1097] train: loss: 0.0035456
[Epoch 101; Iter   100/ 1097] train: loss: 0.0001823
[Epoch 101; Iter   130/ 1097] train: loss: 0.0000510
[Epoch 101; Iter   160/ 1097] train: loss: 0.0000061
[Epoch 101; Iter   190/ 1097] train: loss: 0.0000462
[Epoch 101; Iter   220/ 1097] train: loss: 0.0002687
[Epoch 101; Iter   250/ 1097] train: loss: 0.0012159
[Epoch 101; Iter   280/ 1097] train: loss: 0.0066273
[Epoch 101; Iter   310/ 1097] train: loss: 0.0003232
[Epoch 101; Iter   340/ 1097] train: loss: 0.0015298
[Epoch 101; Iter   370/ 1097] train: loss: 0.0000072
[Epoch 101; Iter   400/ 1097] train: loss: 0.0001529
[Epoch 101; Iter   430/ 1097] train: loss: 0.0000022
[Epoch 101; Iter   460/ 1097] train: loss: 0.0003706
[Epoch 101; Iter   490/ 1097] train: loss: 0.0001040
[Epoch 101; Iter   520/ 1097] train: loss: 0.0002688
[Epoch 101; Iter   550/ 1097] train: loss: 0.0001037
[Epoch 101; Iter   580/ 1097] train: loss: 0.0006281
[Epoch 101; Iter   610/ 1097] train: loss: 0.0000696
[Epoch 101; Iter   640/ 1097] train: loss: 0.0024746
[Epoch 101; Iter   670/ 1097] train: loss: 0.0000072
[Epoch 101; Iter   700/ 1097] train: loss: 0.0000892
[Epoch 101; Iter   730/ 1097] train: loss: 0.0010288
[Epoch 101; Iter   760/ 1097] train: loss: 0.0000586
[Epoch 101; Iter   790/ 1097] train: loss: 0.0001196
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000627
[Epoch 101; Iter   850/ 1097] train: loss: 0.0009224
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000658
[Epoch 101; Iter   910/ 1097] train: loss: 0.0091308
[Epoch 101; Iter   940/ 1097] train: loss: 0.0000763
[Epoch 101; Iter   970/ 1097] train: loss: 0.0001761
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0003227
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000069
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0051456
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0122609
[Epoch 101] ogbg-molhiv: 0.698606 val loss: 1.964978
[Epoch 101] ogbg-molhiv: 0.710547 test loss: 1.062699
[Epoch 102; Iter    23/ 1097] train: loss: 0.0000371
[Epoch 102; Iter    53/ 1097] train: loss: 0.0004591
[Epoch 102; Iter    83/ 1097] train: loss: 0.0063245
[Epoch 102; Iter   113/ 1097] train: loss: 0.0218283
[Epoch 102; Iter   143/ 1097] train: loss: 0.0003852
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000051
[Epoch 102; Iter   203/ 1097] train: loss: 0.0036281
[Epoch 102; Iter   233/ 1097] train: loss: 0.0000396
[Epoch 102; Iter   263/ 1097] train: loss: 0.0000307
[Epoch 102; Iter   293/ 1097] train: loss: 0.0018145
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000631
[Epoch 102; Iter   353/ 1097] train: loss: 0.0014400
[Epoch 102; Iter   383/ 1097] train: loss: 0.0003289
[Epoch 102; Iter   413/ 1097] train: loss: 0.0002051
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000302
[Epoch 102; Iter   473/ 1097] train: loss: 0.0002695
[Epoch 102; Iter   503/ 1097] train: loss: 0.0000535
[Epoch 102; Iter   533/ 1097] train: loss: 0.0000465
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000417
[Epoch 102; Iter   593/ 1097] train: loss: 0.0002779
[Epoch 102; Iter   623/ 1097] train: loss: 0.0000412
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000970
[Epoch 102; Iter   683/ 1097] train: loss: 0.0006980
[Epoch 102; Iter   713/ 1097] train: loss: 0.0038750
[Epoch 102; Iter   743/ 1097] train: loss: 0.0078862
[Epoch 102; Iter   773/ 1097] train: loss: 0.0055618
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000713
[Epoch 102; Iter   833/ 1097] train: loss: 0.0146455
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000018
[Epoch 102; Iter   893/ 1097] train: loss: 0.0002630
[Epoch 102; Iter   923/ 1097] train: loss: 0.0000055
[Epoch 102; Iter   953/ 1097] train: loss: 0.0010535
[Epoch 102; Iter   983/ 1097] train: loss: 0.0002074
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000633
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0008870
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0015130
[Epoch 102] ogbg-molhiv: 0.758387 val loss: 0.859353
[Epoch 102] ogbg-molhiv: 0.715259 test loss: 0.952715
[Epoch 103; Iter     6/ 1097] train: loss: 0.0003755
[Epoch 103; Iter    36/ 1097] train: loss: 0.0000198
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000352
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000031
[Epoch 103; Iter   126/ 1097] train: loss: 0.0001543
[Epoch 103; Iter   156/ 1097] train: loss: 0.0000536
[Epoch 103; Iter   186/ 1097] train: loss: 0.0020363
[Epoch 103; Iter   216/ 1097] train: loss: 0.0012310
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000434
[Epoch 103; Iter   276/ 1097] train: loss: 0.0000118
[Epoch 103; Iter   306/ 1097] train: loss: 0.0001752
[Epoch 103; Iter   336/ 1097] train: loss: 0.0067750
[Epoch 103; Iter   366/ 1097] train: loss: 0.0002317
[Epoch 103; Iter   396/ 1097] train: loss: 0.0001253
[Epoch 103; Iter   426/ 1097] train: loss: 0.0004137
[Epoch 103; Iter   456/ 1097] train: loss: 0.0001252
[Epoch 103; Iter   486/ 1097] train: loss: 0.0039546
[Epoch 103; Iter   516/ 1097] train: loss: 0.0187067
[Epoch 103; Iter   546/ 1097] train: loss: 0.0004210
[Epoch 103; Iter   576/ 1097] train: loss: 0.0010936
[Epoch 103; Iter   606/ 1097] train: loss: 0.0003675
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000120
[Epoch 103; Iter   666/ 1097] train: loss: 0.0653493
[Epoch 103; Iter   696/ 1097] train: loss: 0.0002104
[Epoch 103; Iter   726/ 1097] train: loss: 0.0038643
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000453
[Epoch 103; Iter   786/ 1097] train: loss: 0.0003324
[Epoch 103; Iter   816/ 1097] train: loss: 0.0011118
[Epoch 103; Iter   846/ 1097] train: loss: 0.0046380
[Epoch 103; Iter   876/ 1097] train: loss: 0.0000746
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000390
[Epoch 103; Iter   936/ 1097] train: loss: 0.0002013
[Epoch 103; Iter   966/ 1097] train: loss: 0.0009047
[Epoch 103; Iter   996/ 1097] train: loss: 0.0004222
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0011000
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0001244
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0016414
[Epoch 103] ogbg-molhiv: 0.749896 val loss: 0.805560
[Epoch 103] ogbg-molhiv: 0.704483 test loss: 1.164417
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000460
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000829
[Epoch 104; Iter    79/ 1097] train: loss: 0.0004864
[Epoch 104; Iter   109/ 1097] train: loss: 0.0000295
[Epoch 104; Iter   139/ 1097] train: loss: 0.0001097
[Epoch 104; Iter   169/ 1097] train: loss: 0.0038268
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000295
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000121
[Epoch 104; Iter   259/ 1097] train: loss: 0.0000039
[Epoch 104; Iter   289/ 1097] train: loss: 0.0000110
[Epoch 104; Iter   319/ 1097] train: loss: 0.0002165
[Epoch 104; Iter   349/ 1097] train: loss: 0.0022790
[Epoch 104; Iter   379/ 1097] train: loss: 0.0000459
[Epoch 104; Iter   409/ 1097] train: loss: 0.0008607
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000638
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000047
[Epoch 104; Iter   499/ 1097] train: loss: 0.0035627
[Epoch 104; Iter   529/ 1097] train: loss: 0.0006245
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000368
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000065
[Epoch 104; Iter   619/ 1097] train: loss: 0.0001050
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000017
[Epoch 104; Iter   679/ 1097] train: loss: 0.0003218
[Epoch 104; Iter   709/ 1097] train: loss: 0.0066145
[Epoch 104; Iter   739/ 1097] train: loss: 0.0002745
[Epoch 104; Iter   769/ 1097] train: loss: 0.0016722
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000105
[Epoch 104; Iter   829/ 1097] train: loss: 0.0002418
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000209
[Epoch 104; Iter   889/ 1097] train: loss: 0.0003467
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000312
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000507
[Epoch 104; Iter   979/ 1097] train: loss: 0.0000237
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0016894
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000013
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0000855
[Epoch 104] ogbg-molhiv: 0.785671 val loss: 0.721154
[Epoch 104] ogbg-molhiv: 0.708237 test loss: 1.173607
[Epoch 105; Iter     2/ 1097] train: loss: 0.0100438
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000319
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000120
[Epoch 105; Iter    92/ 1097] train: loss: 0.0001121
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000851
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000026
[Epoch 105; Iter   182/ 1097] train: loss: 0.0000416
[Epoch 105; Iter   212/ 1097] train: loss: 0.0011111
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000114
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000368
[Epoch 105; Iter   302/ 1097] train: loss: 0.0007528
[Epoch 105; Iter   332/ 1097] train: loss: 0.0007075
[Epoch 105; Iter   362/ 1097] train: loss: 0.0004973
[Epoch 105; Iter   392/ 1097] train: loss: 0.0039418
[Epoch 105; Iter   422/ 1097] train: loss: 0.0001496
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000015
[Epoch 105; Iter   482/ 1097] train: loss: 0.0000138
[Epoch 105; Iter   512/ 1097] train: loss: 0.0009213
[Epoch 105; Iter   542/ 1097] train: loss: 0.0002790
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000015
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000034
[Epoch 105; Iter   632/ 1097] train: loss: 0.0084096
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000527
[Epoch 105; Iter   692/ 1097] train: loss: 0.0000799
[Epoch 101; Iter   730/ 1097] train: loss: 0.0013429
[Epoch 101; Iter   760/ 1097] train: loss: 0.0005886
[Epoch 101; Iter   790/ 1097] train: loss: 0.0005411
[Epoch 101; Iter   820/ 1097] train: loss: 0.0009852
[Epoch 101; Iter   850/ 1097] train: loss: 0.0006489
[Epoch 101; Iter   880/ 1097] train: loss: 0.0006902
[Epoch 101; Iter   910/ 1097] train: loss: 0.0001425
[Epoch 101; Iter   940/ 1097] train: loss: 0.0000354
[Epoch 101; Iter   970/ 1097] train: loss: 0.0037927
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000991
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000904
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0000297
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0001637
[Epoch 101] ogbg-molhiv: 0.723067 val loss: 1.435497
[Epoch 101] ogbg-molhiv: 0.695743 test loss: 0.437432
[Epoch 102; Iter    23/ 1097] train: loss: 0.0006498
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000250
[Epoch 102; Iter    83/ 1097] train: loss: 0.0055531
[Epoch 102; Iter   113/ 1097] train: loss: 0.0000120
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000106
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000091
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000017
[Epoch 102; Iter   233/ 1097] train: loss: 0.0002096
[Epoch 102; Iter   263/ 1097] train: loss: 0.0000320
[Epoch 102; Iter   293/ 1097] train: loss: 0.0000935
[Epoch 102; Iter   323/ 1097] train: loss: 0.0004403
[Epoch 102; Iter   353/ 1097] train: loss: 0.0000122
[Epoch 102; Iter   383/ 1097] train: loss: 0.0002178
[Epoch 102; Iter   413/ 1097] train: loss: 0.0848835
[Epoch 102; Iter   443/ 1097] train: loss: 0.0001654
[Epoch 102; Iter   473/ 1097] train: loss: 0.0000247
[Epoch 102; Iter   503/ 1097] train: loss: 0.0000363
[Epoch 102; Iter   533/ 1097] train: loss: 0.0002943
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000412
[Epoch 102; Iter   593/ 1097] train: loss: 0.0009254
[Epoch 102; Iter   623/ 1097] train: loss: 0.0004456
[Epoch 102; Iter   653/ 1097] train: loss: 0.0003130
[Epoch 102; Iter   683/ 1097] train: loss: 0.0000521
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000485
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000152
[Epoch 102; Iter   773/ 1097] train: loss: 0.0265805
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000148
[Epoch 102; Iter   833/ 1097] train: loss: 0.0001711
[Epoch 102; Iter   863/ 1097] train: loss: 0.0004899
[Epoch 102; Iter   893/ 1097] train: loss: 0.0002936
[Epoch 102; Iter   923/ 1097] train: loss: 0.0000527
[Epoch 102; Iter   953/ 1097] train: loss: 0.0000377
[Epoch 102; Iter   983/ 1097] train: loss: 0.0000258
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000139
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0000309
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000101
[Epoch 102] ogbg-molhiv: 0.705571 val loss: 1.966211
[Epoch 102] ogbg-molhiv: 0.653139 test loss: 1.074358
[Epoch 103; Iter     6/ 1097] train: loss: 0.0000500
[Epoch 103; Iter    36/ 1097] train: loss: 0.0025359
[Epoch 103; Iter    66/ 1097] train: loss: 0.0010221
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000265
[Epoch 103; Iter   126/ 1097] train: loss: 0.0000037
[Epoch 103; Iter   156/ 1097] train: loss: 0.0017932
[Epoch 103; Iter   186/ 1097] train: loss: 0.0000779
[Epoch 103; Iter   216/ 1097] train: loss: 0.0014470
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000777
[Epoch 103; Iter   276/ 1097] train: loss: 0.0003526
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000104
[Epoch 103; Iter   336/ 1097] train: loss: 0.0000687
[Epoch 103; Iter   366/ 1097] train: loss: 0.0016471
[Epoch 103; Iter   396/ 1097] train: loss: 0.0000487
[Epoch 103; Iter   426/ 1097] train: loss: 0.0002234
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000357
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000044
[Epoch 103; Iter   516/ 1097] train: loss: 0.0000225
[Epoch 103; Iter   546/ 1097] train: loss: 0.0001820
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000137
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000345
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000285
[Epoch 103; Iter   666/ 1097] train: loss: 0.0004298
[Epoch 103; Iter   696/ 1097] train: loss: 0.0060228
[Epoch 103; Iter   726/ 1097] train: loss: 0.0855041
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000501
[Epoch 103; Iter   786/ 1097] train: loss: 0.0018221
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000088
[Epoch 103; Iter   846/ 1097] train: loss: 0.0000252
[Epoch 103; Iter   876/ 1097] train: loss: 0.0003773
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000764
[Epoch 103; Iter   936/ 1097] train: loss: 0.0002310
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000833
[Epoch 103; Iter   996/ 1097] train: loss: 0.0043852
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0000938
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0005020
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0002877
[Epoch 103] ogbg-molhiv: 0.707531 val loss: 1.498816
[Epoch 103] ogbg-molhiv: 0.695825 test loss: 0.781920
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000465
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000111
[Epoch 104; Iter    79/ 1097] train: loss: 0.0001744
[Epoch 104; Iter   109/ 1097] train: loss: 0.0000243
[Epoch 104; Iter   139/ 1097] train: loss: 0.0000075
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000490
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000145
[Epoch 104; Iter   229/ 1097] train: loss: 0.0033669
[Epoch 104; Iter   259/ 1097] train: loss: 0.0000489
[Epoch 104; Iter   289/ 1097] train: loss: 0.0000238
[Epoch 104; Iter   319/ 1097] train: loss: 0.0002131
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000406
[Epoch 104; Iter   379/ 1097] train: loss: 0.0000091
[Epoch 104; Iter   409/ 1097] train: loss: 0.0002379
[Epoch 104; Iter   439/ 1097] train: loss: 0.0002087
[Epoch 104; Iter   469/ 1097] train: loss: 0.0001025
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000422
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000039
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000148
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000149
[Epoch 104; Iter   619/ 1097] train: loss: 0.0004333
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000353
[Epoch 104; Iter   679/ 1097] train: loss: 0.0024684
[Epoch 104; Iter   709/ 1097] train: loss: 0.0001769
[Epoch 104; Iter   739/ 1097] train: loss: 0.0000392
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000023
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000686
[Epoch 104; Iter   829/ 1097] train: loss: 0.0000124
[Epoch 104; Iter   859/ 1097] train: loss: 0.0001018
[Epoch 104; Iter   889/ 1097] train: loss: 0.0010841
[Epoch 104; Iter   919/ 1097] train: loss: 0.0002125
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000180
[Epoch 104; Iter   979/ 1097] train: loss: 0.0004029
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0004879
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0001122
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0044633
[Epoch 104] ogbg-molhiv: 0.703398 val loss: 1.873882
[Epoch 104] ogbg-molhiv: 0.705019 test loss: 0.872377
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000011
[Epoch 105; Iter    32/ 1097] train: loss: 0.0009385
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000039
[Epoch 105; Iter    92/ 1097] train: loss: 0.0001559
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000678
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000405
[Epoch 105; Iter   182/ 1097] train: loss: 0.0017313
[Epoch 105; Iter   212/ 1097] train: loss: 0.0000018
[Epoch 105; Iter   242/ 1097] train: loss: 0.0003040
[Epoch 105; Iter   272/ 1097] train: loss: 0.0006783
[Epoch 105; Iter   302/ 1097] train: loss: 0.0000345
[Epoch 105; Iter   332/ 1097] train: loss: 0.0002589
[Epoch 105; Iter   362/ 1097] train: loss: 0.0001538
[Epoch 105; Iter   392/ 1097] train: loss: 0.0000979
[Epoch 105; Iter   422/ 1097] train: loss: 0.0002201
[Epoch 105; Iter   452/ 1097] train: loss: 0.0015325
[Epoch 105; Iter   482/ 1097] train: loss: 0.0143883
[Epoch 105; Iter   512/ 1097] train: loss: 0.0000097
[Epoch 105; Iter   542/ 1097] train: loss: 0.0023071
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000430
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000807
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000927
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000512
[Epoch 105; Iter   692/ 1097] train: loss: 0.0002322
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000172
[Epoch 101; Iter   760/ 1097] train: loss: 0.0000331
[Epoch 101; Iter   790/ 1097] train: loss: 0.0000180
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000238
[Epoch 101; Iter   850/ 1097] train: loss: 0.0000352
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000893
[Epoch 101; Iter   910/ 1097] train: loss: 0.0000155
[Epoch 101; Iter   940/ 1097] train: loss: 0.0007916
[Epoch 101; Iter   970/ 1097] train: loss: 0.0000476
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000896
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0002459
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0021881
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0000489
[Epoch 101] ogbg-molhiv: 0.772854 val loss: 0.256491
[Epoch 101] ogbg-molhiv: 0.718448 test loss: 0.400298
[Epoch 102; Iter    23/ 1097] train: loss: 0.0000012
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000066
[Epoch 102; Iter    83/ 1097] train: loss: 0.0000473
[Epoch 102; Iter   113/ 1097] train: loss: 0.0002111
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000149
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000261
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000010
[Epoch 102; Iter   233/ 1097] train: loss: 0.0003309
[Epoch 102; Iter   263/ 1097] train: loss: 0.0001319
[Epoch 102; Iter   293/ 1097] train: loss: 0.0003258
[Epoch 102; Iter   323/ 1097] train: loss: 0.0013695
[Epoch 102; Iter   353/ 1097] train: loss: 0.0000037
[Epoch 102; Iter   383/ 1097] train: loss: 0.0042964
[Epoch 102; Iter   413/ 1097] train: loss: 0.0031618
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000147
[Epoch 102; Iter   473/ 1097] train: loss: 0.0001813
[Epoch 102; Iter   503/ 1097] train: loss: 0.0000007
[Epoch 102; Iter   533/ 1097] train: loss: 0.0000304
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000687
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000038
[Epoch 102; Iter   623/ 1097] train: loss: 0.0000014
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000071
[Epoch 102; Iter   683/ 1097] train: loss: 0.0003530
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000177
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000319
[Epoch 102; Iter   773/ 1097] train: loss: 0.0000112
[Epoch 102; Iter   803/ 1097] train: loss: 0.0001029
[Epoch 102; Iter   833/ 1097] train: loss: 0.0001140
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000844
[Epoch 102; Iter   893/ 1097] train: loss: 0.0000127
[Epoch 102; Iter   923/ 1097] train: loss: 0.0001106
[Epoch 102; Iter   953/ 1097] train: loss: 0.0007770
[Epoch 102; Iter   983/ 1097] train: loss: 0.0108214
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000216
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0032617
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0005965
[Epoch 102] ogbg-molhiv: 0.771424 val loss: 0.249160
[Epoch 102] ogbg-molhiv: 0.730773 test loss: 0.406286
[Epoch 103; Iter     6/ 1097] train: loss: 0.0006219
[Epoch 103; Iter    36/ 1097] train: loss: 0.0000301
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000039
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000560
[Epoch 103; Iter   126/ 1097] train: loss: 0.0002282
[Epoch 103; Iter   156/ 1097] train: loss: 0.0000810
[Epoch 103; Iter   186/ 1097] train: loss: 0.0012834
[Epoch 103; Iter   216/ 1097] train: loss: 0.0006520
[Epoch 103; Iter   246/ 1097] train: loss: 0.0002464
[Epoch 103; Iter   276/ 1097] train: loss: 0.0000133
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000061
[Epoch 103; Iter   336/ 1097] train: loss: 0.0000037
[Epoch 103; Iter   366/ 1097] train: loss: 0.0001071
[Epoch 103; Iter   396/ 1097] train: loss: 0.0001627
[Epoch 103; Iter   426/ 1097] train: loss: 0.0002610
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000106
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000662
[Epoch 103; Iter   516/ 1097] train: loss: 0.0001234
[Epoch 103; Iter   546/ 1097] train: loss: 0.0000573
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000324
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000497
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000092
[Epoch 103; Iter   666/ 1097] train: loss: 0.0002369
[Epoch 103; Iter   696/ 1097] train: loss: 0.0000018
[Epoch 103; Iter   726/ 1097] train: loss: 0.0001517
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000352
[Epoch 103; Iter   786/ 1097] train: loss: 0.0000147
[Epoch 103; Iter   816/ 1097] train: loss: 0.0001683
[Epoch 103; Iter   846/ 1097] train: loss: 0.0000419
[Epoch 103; Iter   876/ 1097] train: loss: 0.0004948
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000018
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000172
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000063
[Epoch 103; Iter   996/ 1097] train: loss: 0.0005409
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0003872
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0000457
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000892
[Epoch 103] ogbg-molhiv: 0.779930 val loss: 0.247547
[Epoch 103] ogbg-molhiv: 0.714251 test loss: 0.415136
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000513
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000170
[Epoch 104; Iter    79/ 1097] train: loss: 0.0000145
[Epoch 104; Iter   109/ 1097] train: loss: 0.0019956
[Epoch 104; Iter   139/ 1097] train: loss: 0.0003504
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000083
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000512
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000312
[Epoch 104; Iter   259/ 1097] train: loss: 0.0002355
[Epoch 104; Iter   289/ 1097] train: loss: 0.0005055
[Epoch 104; Iter   319/ 1097] train: loss: 0.0000880
[Epoch 104; Iter   349/ 1097] train: loss: 0.0523430
[Epoch 104; Iter   379/ 1097] train: loss: 0.0000221
[Epoch 104; Iter   409/ 1097] train: loss: 0.0000283
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000024
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000158
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000764
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000193
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000218
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000095
[Epoch 104; Iter   619/ 1097] train: loss: 0.0000186
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000620
[Epoch 104; Iter   679/ 1097] train: loss: 0.0000174
[Epoch 104; Iter   709/ 1097] train: loss: 0.0003303
[Epoch 104; Iter   739/ 1097] train: loss: 0.0000224
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000114
[Epoch 104; Iter   799/ 1097] train: loss: 0.0010912
[Epoch 104; Iter   829/ 1097] train: loss: 0.0003717
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000038
[Epoch 104; Iter   889/ 1097] train: loss: 0.0003404
[Epoch 104; Iter   919/ 1097] train: loss: 0.0001932
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000105
[Epoch 104; Iter   979/ 1097] train: loss: 0.0026157
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0002079
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000134
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0000473
[Epoch 104] ogbg-molhiv: 0.783136 val loss: 0.244166
[Epoch 104] ogbg-molhiv: 0.712708 test loss: 0.424948
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000012
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000014
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000088
[Epoch 105; Iter    92/ 1097] train: loss: 0.0000468
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000297
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000680
[Epoch 105; Iter   182/ 1097] train: loss: 0.0001834
[Epoch 105; Iter   212/ 1097] train: loss: 0.0000746
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000088
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000258
[Epoch 105; Iter   302/ 1097] train: loss: 0.0000295
[Epoch 105; Iter   332/ 1097] train: loss: 0.0007952
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000005
[Epoch 105; Iter   392/ 1097] train: loss: 0.0001765
[Epoch 105; Iter   422/ 1097] train: loss: 0.0004411
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000097
[Epoch 105; Iter   482/ 1097] train: loss: 0.0000088
[Epoch 105; Iter   512/ 1097] train: loss: 0.0000238
[Epoch 105; Iter   542/ 1097] train: loss: 0.0014242
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000039
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000002
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000059
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000285
[Epoch 105; Iter   692/ 1097] train: loss: 0.0001920
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000306
[Epoch 101; Iter   760/ 1097] train: loss: 0.0004676
[Epoch 101; Iter   790/ 1097] train: loss: 0.0001076
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000644
[Epoch 101; Iter   850/ 1097] train: loss: 0.0000682
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000141
[Epoch 101; Iter   910/ 1097] train: loss: 0.0000080
[Epoch 101; Iter   940/ 1097] train: loss: 0.0005983
[Epoch 101; Iter   970/ 1097] train: loss: 0.0000063
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0003433
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000373
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0007536
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0000188
[Epoch 101] ogbg-molhiv: 0.765181 val loss: 0.400316
[Epoch 101] ogbg-molhiv: 0.755623 test loss: 0.386787
[Epoch 102; Iter    23/ 1097] train: loss: 0.0025642
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000011
[Epoch 102; Iter    83/ 1097] train: loss: 0.0000097
[Epoch 102; Iter   113/ 1097] train: loss: 0.0064151
[Epoch 102; Iter   143/ 1097] train: loss: 0.0001642
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000735
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000185
[Epoch 102; Iter   233/ 1097] train: loss: 0.0000418
[Epoch 102; Iter   263/ 1097] train: loss: 0.0000300
[Epoch 102; Iter   293/ 1097] train: loss: 0.0000129
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000235
[Epoch 102; Iter   353/ 1097] train: loss: 0.0004684
[Epoch 102; Iter   383/ 1097] train: loss: 0.0001399
[Epoch 102; Iter   413/ 1097] train: loss: 0.0006267
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000271
[Epoch 102; Iter   473/ 1097] train: loss: 0.0000128
[Epoch 102; Iter   503/ 1097] train: loss: 0.0004596
[Epoch 102; Iter   533/ 1097] train: loss: 0.0004833
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000215
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000246
[Epoch 102; Iter   623/ 1097] train: loss: 0.0000953
[Epoch 102; Iter   653/ 1097] train: loss: 0.0040587
[Epoch 102; Iter   683/ 1097] train: loss: 0.0000626
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000161
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000491
[Epoch 102; Iter   773/ 1097] train: loss: 0.0000038
[Epoch 102; Iter   803/ 1097] train: loss: 0.0002627
[Epoch 102; Iter   833/ 1097] train: loss: 0.0000272
[Epoch 102; Iter   863/ 1097] train: loss: 0.0001011
[Epoch 102; Iter   893/ 1097] train: loss: 0.0000187
[Epoch 102; Iter   923/ 1097] train: loss: 0.0000375
[Epoch 102; Iter   953/ 1097] train: loss: 0.0000029
[Epoch 102; Iter   983/ 1097] train: loss: 0.0001872
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000193
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0114792
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000037
[Epoch 102] ogbg-molhiv: 0.771130 val loss: 0.416152
[Epoch 102] ogbg-molhiv: 0.739547 test loss: 0.408916
[Epoch 103; Iter     6/ 1097] train: loss: 0.0003565
[Epoch 103; Iter    36/ 1097] train: loss: 0.0020815
[Epoch 103; Iter    66/ 1097] train: loss: 0.0001111
[Epoch 103; Iter    96/ 1097] train: loss: 0.0002334
[Epoch 103; Iter   126/ 1097] train: loss: 0.0016297
[Epoch 103; Iter   156/ 1097] train: loss: 0.0001056
[Epoch 103; Iter   186/ 1097] train: loss: 0.0000368
[Epoch 103; Iter   216/ 1097] train: loss: 0.0001338
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000014
[Epoch 103; Iter   276/ 1097] train: loss: 0.0000957
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000229
[Epoch 103; Iter   336/ 1097] train: loss: 0.0016838
[Epoch 103; Iter   366/ 1097] train: loss: 0.0001706
[Epoch 103; Iter   396/ 1097] train: loss: 0.0000122
[Epoch 103; Iter   426/ 1097] train: loss: 0.0000754
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000225
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000010
[Epoch 103; Iter   516/ 1097] train: loss: 0.0001932
[Epoch 103; Iter   546/ 1097] train: loss: 0.0010327
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000792
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000143
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000143
[Epoch 103; Iter   666/ 1097] train: loss: 0.0059347
[Epoch 103; Iter   696/ 1097] train: loss: 0.0001090
[Epoch 103; Iter   726/ 1097] train: loss: 0.0047711
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000186
[Epoch 103; Iter   786/ 1097] train: loss: 0.0000327
[Epoch 103; Iter   816/ 1097] train: loss: 0.0038810
[Epoch 103; Iter   846/ 1097] train: loss: 0.0000097
[Epoch 103; Iter   876/ 1097] train: loss: 0.0001077
[Epoch 103; Iter   906/ 1097] train: loss: 0.0017775
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000605
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000101
[Epoch 103; Iter   996/ 1097] train: loss: 0.0001184
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0000751
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0072112
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000080
[Epoch 103] ogbg-molhiv: 0.759627 val loss: 0.422916
[Epoch 103] ogbg-molhiv: 0.739802 test loss: 0.393380
[Epoch 104; Iter    19/ 1097] train: loss: 0.0001506
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000820
[Epoch 104; Iter    79/ 1097] train: loss: 0.0025367
[Epoch 104; Iter   109/ 1097] train: loss: 0.0000218
[Epoch 104; Iter   139/ 1097] train: loss: 0.0014472
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000634
[Epoch 104; Iter   199/ 1097] train: loss: 0.0001090
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000461
[Epoch 104; Iter   259/ 1097] train: loss: 0.0347341
[Epoch 104; Iter   289/ 1097] train: loss: 0.0003831
[Epoch 104; Iter   319/ 1097] train: loss: 0.0000283
[Epoch 104; Iter   349/ 1097] train: loss: 0.0004928
[Epoch 104; Iter   379/ 1097] train: loss: 0.0000287
[Epoch 104; Iter   409/ 1097] train: loss: 0.0001180
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000155
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000059
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000331
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000462
[Epoch 104; Iter   559/ 1097] train: loss: 0.0004609
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000147
[Epoch 104; Iter   619/ 1097] train: loss: 0.0004542
[Epoch 104; Iter   649/ 1097] train: loss: 0.0001011
[Epoch 104; Iter   679/ 1097] train: loss: 0.0000150
[Epoch 104; Iter   709/ 1097] train: loss: 0.0000208
[Epoch 104; Iter   739/ 1097] train: loss: 0.0005009
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000135
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000093
[Epoch 104; Iter   829/ 1097] train: loss: 0.0010513
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000262
[Epoch 104; Iter   889/ 1097] train: loss: 0.0000357
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000157
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000429
[Epoch 104; Iter   979/ 1097] train: loss: 0.0016068
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0000106
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000354
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0000879
[Epoch 104] ogbg-molhiv: 0.771262 val loss: 0.407178
[Epoch 104] ogbg-molhiv: 0.740059 test loss: 0.403614
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000782
[Epoch 105; Iter    32/ 1097] train: loss: 0.0024971
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000088
[Epoch 105; Iter    92/ 1097] train: loss: 0.0017741
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000258
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000389
[Epoch 105; Iter   182/ 1097] train: loss: 0.0001506
[Epoch 105; Iter   212/ 1097] train: loss: 0.0002343
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000196
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000475
[Epoch 105; Iter   302/ 1097] train: loss: 0.0057419
[Epoch 105; Iter   332/ 1097] train: loss: 0.0001214
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000979
[Epoch 105; Iter   392/ 1097] train: loss: 0.0000242
[Epoch 105; Iter   422/ 1097] train: loss: 0.0000945
[Epoch 105; Iter   452/ 1097] train: loss: 0.0002569
[Epoch 105; Iter   482/ 1097] train: loss: 0.0011079
[Epoch 105; Iter   512/ 1097] train: loss: 0.0006325
[Epoch 105; Iter   542/ 1097] train: loss: 0.0000300
[Epoch 105; Iter   572/ 1097] train: loss: 0.0001496
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000023
[Epoch 105; Iter   632/ 1097] train: loss: 0.0002202
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000064
[Epoch 105; Iter   692/ 1097] train: loss: 0.0004204
[Epoch 101; Iter   730/ 1097] train: loss: 0.0053929
[Epoch 101; Iter   760/ 1097] train: loss: 0.0001296
[Epoch 101; Iter   790/ 1097] train: loss: 0.0000037
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000072
[Epoch 101; Iter   850/ 1097] train: loss: 0.0000474
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000331
[Epoch 101; Iter   910/ 1097] train: loss: 0.0001089
[Epoch 101; Iter   940/ 1097] train: loss: 0.0001728
[Epoch 101; Iter   970/ 1097] train: loss: 0.0011248
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000218
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000037
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0000039
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0002919
[Epoch 101] ogbg-molhiv: 0.786991 val loss: 0.545989
[Epoch 101] ogbg-molhiv: 0.735049 test loss: 0.430074
[Epoch 102; Iter    23/ 1097] train: loss: 0.0011989
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000850
[Epoch 102; Iter    83/ 1097] train: loss: 0.0029543
[Epoch 102; Iter   113/ 1097] train: loss: 0.0001726
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000137
[Epoch 102; Iter   173/ 1097] train: loss: 0.0068888
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000041
[Epoch 102; Iter   233/ 1097] train: loss: 0.0001449
[Epoch 102; Iter   263/ 1097] train: loss: 0.0000737
[Epoch 102; Iter   293/ 1097] train: loss: 0.0000230
[Epoch 102; Iter   323/ 1097] train: loss: 0.0013731
[Epoch 102; Iter   353/ 1097] train: loss: 0.0000018
[Epoch 102; Iter   383/ 1097] train: loss: 0.0000676
[Epoch 102; Iter   413/ 1097] train: loss: 0.0003281
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000280
[Epoch 102; Iter   473/ 1097] train: loss: 0.0000043
[Epoch 102; Iter   503/ 1097] train: loss: 0.0001088
[Epoch 102; Iter   533/ 1097] train: loss: 0.0005364
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000012
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000047
[Epoch 102; Iter   623/ 1097] train: loss: 0.0000258
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000223
[Epoch 102; Iter   683/ 1097] train: loss: 0.0000523
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000096
[Epoch 102; Iter   743/ 1097] train: loss: 0.0028590
[Epoch 102; Iter   773/ 1097] train: loss: 0.0001244
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000216
[Epoch 102; Iter   833/ 1097] train: loss: 0.0000245
[Epoch 102; Iter   863/ 1097] train: loss: 0.0003140
[Epoch 102; Iter   893/ 1097] train: loss: 0.0002033
[Epoch 102; Iter   923/ 1097] train: loss: 0.0000418
[Epoch 102; Iter   953/ 1097] train: loss: 0.0049019
[Epoch 102; Iter   983/ 1097] train: loss: 0.2083964
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000977
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0001905
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000355
[Epoch 102] ogbg-molhiv: 0.772358 val loss: 0.537700
[Epoch 102] ogbg-molhiv: 0.733703 test loss: 0.398862
[Epoch 103; Iter     6/ 1097] train: loss: 0.0000186
[Epoch 103; Iter    36/ 1097] train: loss: 0.0009359
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000607
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000213
[Epoch 103; Iter   126/ 1097] train: loss: 0.0000770
[Epoch 103; Iter   156/ 1097] train: loss: 0.0001448
[Epoch 103; Iter   186/ 1097] train: loss: 0.0034322
[Epoch 103; Iter   216/ 1097] train: loss: 0.0020538
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000023
[Epoch 103; Iter   276/ 1097] train: loss: 0.0008960
[Epoch 103; Iter   306/ 1097] train: loss: 0.0018121
[Epoch 103; Iter   336/ 1097] train: loss: 0.0000306
[Epoch 103; Iter   366/ 1097] train: loss: 0.0000943
[Epoch 103; Iter   396/ 1097] train: loss: 0.0000220
[Epoch 103; Iter   426/ 1097] train: loss: 0.0006854
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000076
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000317
[Epoch 103; Iter   516/ 1097] train: loss: 0.0000163
[Epoch 103; Iter   546/ 1097] train: loss: 0.0000181
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000623
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000026
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000006
[Epoch 103; Iter   666/ 1097] train: loss: 0.0165782
[Epoch 103; Iter   696/ 1097] train: loss: 0.0061121
[Epoch 103; Iter   726/ 1097] train: loss: 0.0000852
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000022
[Epoch 103; Iter   786/ 1097] train: loss: 0.0000165
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000158
[Epoch 103; Iter   846/ 1097] train: loss: 0.0001036
[Epoch 103; Iter   876/ 1097] train: loss: 0.0001759
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000054
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000886
[Epoch 103; Iter   966/ 1097] train: loss: 0.0005550
[Epoch 103; Iter   996/ 1097] train: loss: 0.0000164
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0000452
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0000530
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000026
[Epoch 103] ogbg-molhiv: 0.789006 val loss: 0.315175
[Epoch 103] ogbg-molhiv: 0.733699 test loss: 0.434183
[Epoch 104; Iter    19/ 1097] train: loss: 0.0012372
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000194
[Epoch 104; Iter    79/ 1097] train: loss: 0.0000059
[Epoch 104; Iter   109/ 1097] train: loss: 0.0167540
[Epoch 104; Iter   139/ 1097] train: loss: 0.0000124
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000023
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000462
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000306
[Epoch 104; Iter   259/ 1097] train: loss: 0.0123736
[Epoch 104; Iter   289/ 1097] train: loss: 0.0001399
[Epoch 104; Iter   319/ 1097] train: loss: 0.0000196
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000243
[Epoch 104; Iter   379/ 1097] train: loss: 0.0000609
[Epoch 104; Iter   409/ 1097] train: loss: 0.0002934
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000577
[Epoch 104; Iter   469/ 1097] train: loss: 0.0036418
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000323
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000184
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000162
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000287
[Epoch 104; Iter   619/ 1097] train: loss: 0.0000604
[Epoch 104; Iter   649/ 1097] train: loss: 0.0004514
[Epoch 104; Iter   679/ 1097] train: loss: 0.0001128
[Epoch 104; Iter   709/ 1097] train: loss: 0.0001315
[Epoch 104; Iter   739/ 1097] train: loss: 0.0001089
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000336
[Epoch 104; Iter   799/ 1097] train: loss: 0.0002649
[Epoch 104; Iter   829/ 1097] train: loss: 0.0004552
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000339
[Epoch 104; Iter   889/ 1097] train: loss: 0.0000141
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000104
[Epoch 104; Iter   949/ 1097] train: loss: 0.0001004
[Epoch 104; Iter   979/ 1097] train: loss: 0.0007752
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0000694
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000008
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0000019
[Epoch 104] ogbg-molhiv: 0.786697 val loss: 0.393498
[Epoch 104] ogbg-molhiv: 0.733657 test loss: 0.402782
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000257
[Epoch 105; Iter    32/ 1097] train: loss: 0.0002095
[Epoch 105; Iter    62/ 1097] train: loss: 0.0002502
[Epoch 105; Iter    92/ 1097] train: loss: 0.0009397
[Epoch 105; Iter   122/ 1097] train: loss: 0.0002041
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000081
[Epoch 105; Iter   182/ 1097] train: loss: 0.0001076
[Epoch 105; Iter   212/ 1097] train: loss: 0.0000880
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000139
[Epoch 105; Iter   272/ 1097] train: loss: 0.0004722
[Epoch 105; Iter   302/ 1097] train: loss: 0.0000079
[Epoch 105; Iter   332/ 1097] train: loss: 0.0000082
[Epoch 105; Iter   362/ 1097] train: loss: 0.0003719
[Epoch 105; Iter   392/ 1097] train: loss: 0.0005728
[Epoch 105; Iter   422/ 1097] train: loss: 0.0000583
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000479
[Epoch 105; Iter   482/ 1097] train: loss: 0.0002609
[Epoch 105; Iter   512/ 1097] train: loss: 0.0317114
[Epoch 105; Iter   542/ 1097] train: loss: 0.0000344
[Epoch 105; Iter   572/ 1097] train: loss: 0.0011798
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000329
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000705
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000315
[Epoch 105; Iter   692/ 1097] train: loss: 0.0002369
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000070
[Epoch 101; Iter   760/ 1097] train: loss: 0.0005117
[Epoch 101; Iter   790/ 1097] train: loss: 0.0000031
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000103
[Epoch 101; Iter   850/ 1097] train: loss: 0.0007237
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000921
[Epoch 101; Iter   910/ 1097] train: loss: 0.0000035
[Epoch 101; Iter   940/ 1097] train: loss: 0.0000413
[Epoch 101; Iter   970/ 1097] train: loss: 0.0001528
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000059
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0001915
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0000132
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0000739
[Epoch 101] ogbg-molhiv: 0.787046 val loss: 0.520991
[Epoch 101] ogbg-molhiv: 0.800608 test loss: 0.349295
[Epoch 102; Iter    23/ 1097] train: loss: 0.0000056
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000422
[Epoch 102; Iter    83/ 1097] train: loss: 0.0000070
[Epoch 102; Iter   113/ 1097] train: loss: 0.0000379
[Epoch 102; Iter   143/ 1097] train: loss: 0.0004900
[Epoch 102; Iter   173/ 1097] train: loss: 0.0001200
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000053
[Epoch 102; Iter   233/ 1097] train: loss: 0.0001904
[Epoch 102; Iter   263/ 1097] train: loss: 0.0001399
[Epoch 102; Iter   293/ 1097] train: loss: 0.0001698
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000656
[Epoch 102; Iter   353/ 1097] train: loss: 0.0001113
[Epoch 102; Iter   383/ 1097] train: loss: 0.0000047
[Epoch 102; Iter   413/ 1097] train: loss: 0.0050310
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000005
[Epoch 102; Iter   473/ 1097] train: loss: 0.0001359
[Epoch 102; Iter   503/ 1097] train: loss: 0.0000233
[Epoch 102; Iter   533/ 1097] train: loss: 0.0000012
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000163
[Epoch 102; Iter   593/ 1097] train: loss: 0.0004987
[Epoch 102; Iter   623/ 1097] train: loss: 0.0001044
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000044
[Epoch 102; Iter   683/ 1097] train: loss: 0.0041593
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000030
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000174
[Epoch 102; Iter   773/ 1097] train: loss: 0.0168734
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000374
[Epoch 102; Iter   833/ 1097] train: loss: 0.0000484
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000017
[Epoch 102; Iter   893/ 1097] train: loss: 0.0000803
[Epoch 102; Iter   923/ 1097] train: loss: 0.0001852
[Epoch 102; Iter   953/ 1097] train: loss: 0.0001426
[Epoch 102; Iter   983/ 1097] train: loss: 0.0000088
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0013486
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0000732
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000625
[Epoch 102] ogbg-molhiv: 0.781694 val loss: 0.438469
[Epoch 102] ogbg-molhiv: 0.807712 test loss: 0.352792
[Epoch 103; Iter     6/ 1097] train: loss: 0.0000044
[Epoch 103; Iter    36/ 1097] train: loss: 0.0000040
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000022
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000264
[Epoch 103; Iter   126/ 1097] train: loss: 0.0000194
[Epoch 103; Iter   156/ 1097] train: loss: 0.0000043
[Epoch 103; Iter   186/ 1097] train: loss: 0.0000034
[Epoch 103; Iter   216/ 1097] train: loss: 0.0000414
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000066
[Epoch 103; Iter   276/ 1097] train: loss: 0.0000014
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000915
[Epoch 103; Iter   336/ 1097] train: loss: 0.0000664
[Epoch 103; Iter   366/ 1097] train: loss: 0.0001221
[Epoch 103; Iter   396/ 1097] train: loss: 0.0000311
[Epoch 103; Iter   426/ 1097] train: loss: 0.0000024
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000161
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000364
[Epoch 103; Iter   516/ 1097] train: loss: 0.0008421
[Epoch 103; Iter   546/ 1097] train: loss: 0.0246091
[Epoch 103; Iter   576/ 1097] train: loss: 0.0164203
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000601
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000074
[Epoch 103; Iter   666/ 1097] train: loss: 0.0000634
[Epoch 103; Iter   696/ 1097] train: loss: 0.0000206
[Epoch 103; Iter   726/ 1097] train: loss: 0.0003657
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000009
[Epoch 103; Iter   786/ 1097] train: loss: 0.0000294
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000926
[Epoch 103; Iter   846/ 1097] train: loss: 0.0000429
[Epoch 103; Iter   876/ 1097] train: loss: 0.0000069
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000147
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000287
[Epoch 103; Iter   966/ 1097] train: loss: 0.0002327
[Epoch 103; Iter   996/ 1097] train: loss: 0.0000555
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0005834
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0000033
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000067
[Epoch 103] ogbg-molhiv: 0.786587 val loss: 0.463902
[Epoch 103] ogbg-molhiv: 0.806902 test loss: 0.356862
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000021
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000168
[Epoch 104; Iter    79/ 1097] train: loss: 0.0000464
[Epoch 104; Iter   109/ 1097] train: loss: 0.0002120
[Epoch 104; Iter   139/ 1097] train: loss: 0.0000136
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000191
[Epoch 104; Iter   199/ 1097] train: loss: 0.0001558
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000056
[Epoch 104; Iter   259/ 1097] train: loss: 0.0000254
[Epoch 104; Iter   289/ 1097] train: loss: 0.0000040
[Epoch 104; Iter   319/ 1097] train: loss: 0.0008588
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000616
[Epoch 104; Iter   379/ 1097] train: loss: 0.0003654
[Epoch 104; Iter   409/ 1097] train: loss: 0.0000123
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000142
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000515
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000001
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000465
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000178
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000034
[Epoch 104; Iter   619/ 1097] train: loss: 0.0000541
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000020
[Epoch 104; Iter   679/ 1097] train: loss: 0.0001094
[Epoch 104; Iter   709/ 1097] train: loss: 0.0000715
[Epoch 104; Iter   739/ 1097] train: loss: 0.0002574
[Epoch 104; Iter   769/ 1097] train: loss: 0.0003376
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000137
[Epoch 104; Iter   829/ 1097] train: loss: 0.0000117
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000767
[Epoch 104; Iter   889/ 1097] train: loss: 0.0000005
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000984
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000038
[Epoch 104; Iter   979/ 1097] train: loss: 0.0000932
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0004490
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000309
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0019520
[Epoch 104] ogbg-molhiv: 0.773445 val loss: 0.483079
[Epoch 104] ogbg-molhiv: 0.786527 test loss: 0.370250
[Epoch 105; Iter     2/ 1097] train: loss: 0.0011457
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000012
[Epoch 105; Iter    62/ 1097] train: loss: 0.0013680
[Epoch 105; Iter    92/ 1097] train: loss: 0.0000212
[Epoch 105; Iter   122/ 1097] train: loss: 0.0001472
[Epoch 105; Iter   152/ 1097] train: loss: 0.0013231
[Epoch 105; Iter   182/ 1097] train: loss: 0.0000236
[Epoch 105; Iter   212/ 1097] train: loss: 0.0002691
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000146
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000019
[Epoch 105; Iter   302/ 1097] train: loss: 0.0015305
[Epoch 105; Iter   332/ 1097] train: loss: 0.0000288
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000375
[Epoch 105; Iter   392/ 1097] train: loss: 0.0002181
[Epoch 105; Iter   422/ 1097] train: loss: 0.0000448
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000008
[Epoch 105; Iter   482/ 1097] train: loss: 0.0299449
[Epoch 105; Iter   512/ 1097] train: loss: 0.0001127
[Epoch 105; Iter   542/ 1097] train: loss: 0.0002582
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000015
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000039
[Epoch 105; Iter   632/ 1097] train: loss: 0.0001042
[Epoch 105; Iter   662/ 1097] train: loss: 0.0014119
[Epoch 105; Iter   692/ 1097] train: loss: 0.0020886
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000125
[Epoch 101; Iter   760/ 1097] train: loss: 0.0001808
[Epoch 101; Iter   790/ 1097] train: loss: 0.0000013
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000357
[Epoch 101; Iter   850/ 1097] train: loss: 0.0000045
[Epoch 101; Iter   880/ 1097] train: loss: 0.0019945
[Epoch 101; Iter   910/ 1097] train: loss: 0.0000001
[Epoch 101; Iter   940/ 1097] train: loss: 0.0000251
[Epoch 101; Iter   970/ 1097] train: loss: 0.0001134
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0006949
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000507
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0000267
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0000185
[Epoch 101] ogbg-molhiv: 0.710011 val loss: 4.110566
[Epoch 101] ogbg-molhiv: 0.595585 test loss: 4.180521
[Epoch 102; Iter    23/ 1097] train: loss: 0.0000123
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000278
[Epoch 102; Iter    83/ 1097] train: loss: 0.0155827
[Epoch 102; Iter   113/ 1097] train: loss: 0.0000149
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000001
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000491
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000081
[Epoch 102; Iter   233/ 1097] train: loss: 0.0000242
[Epoch 102; Iter   263/ 1097] train: loss: 0.0008974
[Epoch 102; Iter   293/ 1097] train: loss: 0.0000109
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000016
[Epoch 102; Iter   353/ 1097] train: loss: 0.0019040
[Epoch 102; Iter   383/ 1097] train: loss: 0.0000506
[Epoch 102; Iter   413/ 1097] train: loss: 0.0047460
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000124
[Epoch 102; Iter   473/ 1097] train: loss: 0.0000134
[Epoch 102; Iter   503/ 1097] train: loss: 0.0000156
[Epoch 102; Iter   533/ 1097] train: loss: 0.0002012
[Epoch 102; Iter   563/ 1097] train: loss: 0.0001894
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000013
[Epoch 102; Iter   623/ 1097] train: loss: 0.0003457
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000017
[Epoch 102; Iter   683/ 1097] train: loss: 0.0005256
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000006
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000558
[Epoch 102; Iter   773/ 1097] train: loss: 0.0003961
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000317
[Epoch 102; Iter   833/ 1097] train: loss: 0.0000215
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000032
[Epoch 102; Iter   893/ 1097] train: loss: 0.0000044
[Epoch 102; Iter   923/ 1097] train: loss: 0.0000039
[Epoch 102; Iter   953/ 1097] train: loss: 0.0000127
[Epoch 102; Iter   983/ 1097] train: loss: 0.0000050
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000072
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0000101
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000018
[Epoch 102] ogbg-molhiv: 0.690755 val loss: 5.936074
[Epoch 102] ogbg-molhiv: 0.617105 test loss: 6.873733
[Epoch 103; Iter     6/ 1097] train: loss: 0.0000040
[Epoch 103; Iter    36/ 1097] train: loss: 0.0000315
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000389
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000066
[Epoch 103; Iter   126/ 1097] train: loss: 0.0000703
[Epoch 103; Iter   156/ 1097] train: loss: 0.0000042
[Epoch 103; Iter   186/ 1097] train: loss: 0.0010172
[Epoch 103; Iter   216/ 1097] train: loss: 0.0000069
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000008
[Epoch 103; Iter   276/ 1097] train: loss: 0.0019718
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000037
[Epoch 103; Iter   336/ 1097] train: loss: 0.0000014
[Epoch 103; Iter   366/ 1097] train: loss: 0.0000284
[Epoch 103; Iter   396/ 1097] train: loss: 0.0012613
[Epoch 103; Iter   426/ 1097] train: loss: 0.0000006
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000086
[Epoch 103; Iter   486/ 1097] train: loss: 0.0001256
[Epoch 103; Iter   516/ 1097] train: loss: 0.0000279
[Epoch 103; Iter   546/ 1097] train: loss: 0.0000008
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000068
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000163
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000671
[Epoch 103; Iter   666/ 1097] train: loss: 0.0000024
[Epoch 103; Iter   696/ 1097] train: loss: 0.0000854
[Epoch 103; Iter   726/ 1097] train: loss: 0.0011290
[Epoch 103; Iter   756/ 1097] train: loss: 0.0000027
[Epoch 103; Iter   786/ 1097] train: loss: 0.0000265
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000083
[Epoch 103; Iter   846/ 1097] train: loss: 0.0000040
[Epoch 103; Iter   876/ 1097] train: loss: 0.0000027
[Epoch 103; Iter   906/ 1097] train: loss: 0.0003560
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000018
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000433
[Epoch 103; Iter   996/ 1097] train: loss: 0.0000004
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0000002
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0000726
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000191
[Epoch 103] ogbg-molhiv: 0.686826 val loss: 8.139505
[Epoch 103] ogbg-molhiv: 0.620636 test loss: 9.022365
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000044
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000002
[Epoch 104; Iter    79/ 1097] train: loss: 0.0001102
[Epoch 104; Iter   109/ 1097] train: loss: 0.0000019
[Epoch 104; Iter   139/ 1097] train: loss: 0.0000173
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000034
[Epoch 104; Iter   199/ 1097] train: loss: 0.0002126
[Epoch 104; Iter   229/ 1097] train: loss: 0.0033075
[Epoch 104; Iter   259/ 1097] train: loss: 0.0000216
[Epoch 104; Iter   289/ 1097] train: loss: 0.0000006
[Epoch 104; Iter   319/ 1097] train: loss: 0.0000002
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000065
[Epoch 104; Iter   379/ 1097] train: loss: 0.0002840
[Epoch 104; Iter   409/ 1097] train: loss: 0.0000087
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000056
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000737
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000294
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000092
[Epoch 104; Iter   559/ 1097] train: loss: 0.0000210
[Epoch 104; Iter   589/ 1097] train: loss: 0.0001046
[Epoch 104; Iter   619/ 1097] train: loss: 0.0001622
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000015
[Epoch 104; Iter   679/ 1097] train: loss: 0.0000674
[Epoch 104; Iter   709/ 1097] train: loss: 0.0000004
[Epoch 104; Iter   739/ 1097] train: loss: 0.0000099
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000015
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000329
[Epoch 104; Iter   829/ 1097] train: loss: 0.0000767
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000059
[Epoch 104; Iter   889/ 1097] train: loss: 0.0000373
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000212
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000028
[Epoch 104; Iter   979/ 1097] train: loss: 0.0000069
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0000046
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000016
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0000036
[Epoch 104] ogbg-molhiv: 0.675568 val loss: 6.338413
[Epoch 104] ogbg-molhiv: 0.601537 test loss: 6.629783
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000005
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000035
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000179
[Epoch 105; Iter    92/ 1097] train: loss: 0.0000254
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000016
[Epoch 105; Iter   152/ 1097] train: loss: 0.0030534
[Epoch 105; Iter   182/ 1097] train: loss: 0.0000433
[Epoch 105; Iter   212/ 1097] train: loss: 0.0000010
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000308
[Epoch 105; Iter   272/ 1097] train: loss: 0.0002799
[Epoch 105; Iter   302/ 1097] train: loss: 0.0000041
[Epoch 105; Iter   332/ 1097] train: loss: 0.0000091
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000500
[Epoch 105; Iter   392/ 1097] train: loss: 0.0000088
[Epoch 105; Iter   422/ 1097] train: loss: 0.0000057
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000511
[Epoch 105; Iter   482/ 1097] train: loss: 0.0001745
[Epoch 105; Iter   512/ 1097] train: loss: 0.0000088
[Epoch 105; Iter   542/ 1097] train: loss: 0.0000610
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000788
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000214
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000057
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000010
[Epoch 105; Iter   692/ 1097] train: loss: 0.0000311
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000025
[Epoch 101; Iter   760/ 1097] train: loss: 0.0000168
[Epoch 101; Iter   790/ 1097] train: loss: 0.0000040
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000174
[Epoch 101; Iter   850/ 1097] train: loss: 0.0000454
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000033
[Epoch 101; Iter   910/ 1097] train: loss: 0.0000016
[Epoch 101; Iter   940/ 1097] train: loss: 0.0000011
[Epoch 101; Iter   970/ 1097] train: loss: 0.0004168
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000027
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000089
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0002322
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0001073
[Epoch 101] ogbg-molhiv: 0.749152 val loss: 8.952880
[Epoch 101] ogbg-molhiv: 0.706510 test loss: 8.238571
[Epoch 102; Iter    23/ 1097] train: loss: 0.0000133
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000172
[Epoch 102; Iter    83/ 1097] train: loss: 0.0018644
[Epoch 102; Iter   113/ 1097] train: loss: 0.0000031
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000613
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000484
[Epoch 102; Iter   203/ 1097] train: loss: 0.0001761
[Epoch 102; Iter   233/ 1097] train: loss: 0.0021953
[Epoch 102; Iter   263/ 1097] train: loss: 0.0001339
[Epoch 102; Iter   293/ 1097] train: loss: 0.0000079
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000118
[Epoch 102; Iter   353/ 1097] train: loss: 0.0000257
[Epoch 102; Iter   383/ 1097] train: loss: 0.0000031
[Epoch 102; Iter   413/ 1097] train: loss: 0.0096027
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000024
[Epoch 102; Iter   473/ 1097] train: loss: 0.0000089
[Epoch 102; Iter   503/ 1097] train: loss: 0.0005431
[Epoch 102; Iter   533/ 1097] train: loss: 0.0000350
[Epoch 102; Iter   563/ 1097] train: loss: 0.0000029
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000089
[Epoch 102; Iter   623/ 1097] train: loss: 0.0000003
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000112
[Epoch 102; Iter   683/ 1097] train: loss: 0.0000732
[Epoch 102; Iter   713/ 1097] train: loss: 0.0003946
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000515
[Epoch 102; Iter   773/ 1097] train: loss: 0.0067575
[Epoch 102; Iter   803/ 1097] train: loss: 0.0000178
[Epoch 102; Iter   833/ 1097] train: loss: 0.0026718
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000050
[Epoch 102; Iter   893/ 1097] train: loss: 0.0000310
[Epoch 102; Iter   923/ 1097] train: loss: 0.0066675
[Epoch 102; Iter   953/ 1097] train: loss: 0.0008967
[Epoch 102; Iter   983/ 1097] train: loss: 0.0000709
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0000443
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0004601
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0000105
[Epoch 102] ogbg-molhiv: 0.745888 val loss: 1.463300
[Epoch 102] ogbg-molhiv: 0.729413 test loss: 2.959521
[Epoch 103; Iter     6/ 1097] train: loss: 0.0000520
[Epoch 103; Iter    36/ 1097] train: loss: 0.0000081
[Epoch 103; Iter    66/ 1097] train: loss: 0.0000176
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000078
[Epoch 103; Iter   126/ 1097] train: loss: 0.0001212
[Epoch 103; Iter   156/ 1097] train: loss: 0.0000935
[Epoch 103; Iter   186/ 1097] train: loss: 0.0000520
[Epoch 103; Iter   216/ 1097] train: loss: 0.0000764
[Epoch 103; Iter   246/ 1097] train: loss: 0.0000148
[Epoch 103; Iter   276/ 1097] train: loss: 0.0000760
[Epoch 103; Iter   306/ 1097] train: loss: 0.0000414
[Epoch 103; Iter   336/ 1097] train: loss: 0.0001605
[Epoch 103; Iter   366/ 1097] train: loss: 0.0000327
[Epoch 103; Iter   396/ 1097] train: loss: 0.0256532
[Epoch 103; Iter   426/ 1097] train: loss: 0.0000042
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000015
[Epoch 103; Iter   486/ 1097] train: loss: 0.0000217
[Epoch 103; Iter   516/ 1097] train: loss: 0.0053073
[Epoch 103; Iter   546/ 1097] train: loss: 0.0018721
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000215
[Epoch 103; Iter   606/ 1097] train: loss: 0.0004686
[Epoch 103; Iter   636/ 1097] train: loss: 0.0000126
[Epoch 103; Iter   666/ 1097] train: loss: 0.0002391
[Epoch 103; Iter   696/ 1097] train: loss: 0.0000701
[Epoch 103; Iter   726/ 1097] train: loss: 0.0000008
[Epoch 103; Iter   756/ 1097] train: loss: 0.0001096
[Epoch 103; Iter   786/ 1097] train: loss: 0.0284153
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000031
[Epoch 103; Iter   846/ 1097] train: loss: 0.0002596
[Epoch 103; Iter   876/ 1097] train: loss: 0.0000060
[Epoch 103; Iter   906/ 1097] train: loss: 0.0000164
[Epoch 103; Iter   936/ 1097] train: loss: 0.0000316
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000033
[Epoch 103; Iter   996/ 1097] train: loss: 0.0009669
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0000331
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0022208
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0001359
[Epoch 103] ogbg-molhiv: 0.764762 val loss: 1.283936
[Epoch 103] ogbg-molhiv: 0.739238 test loss: 2.265389
[Epoch 104; Iter    19/ 1097] train: loss: 0.0000019
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000120
[Epoch 104; Iter    79/ 1097] train: loss: 0.0001177
[Epoch 104; Iter   109/ 1097] train: loss: 0.0002086
[Epoch 104; Iter   139/ 1097] train: loss: 0.0001282
[Epoch 104; Iter   169/ 1097] train: loss: 0.0000005
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000232
[Epoch 104; Iter   229/ 1097] train: loss: 0.0000002
[Epoch 104; Iter   259/ 1097] train: loss: 0.0000086
[Epoch 104; Iter   289/ 1097] train: loss: 0.0000071
[Epoch 104; Iter   319/ 1097] train: loss: 0.0029769
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000062
[Epoch 104; Iter   379/ 1097] train: loss: 0.0015319
[Epoch 104; Iter   409/ 1097] train: loss: 0.0000354
[Epoch 104; Iter   439/ 1097] train: loss: 0.0000676
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000282
[Epoch 104; Iter   499/ 1097] train: loss: 0.0001210
[Epoch 104; Iter   529/ 1097] train: loss: 0.0000021
[Epoch 104; Iter   559/ 1097] train: loss: 0.0002024
[Epoch 104; Iter   589/ 1097] train: loss: 0.0000092
[Epoch 104; Iter   619/ 1097] train: loss: 0.0002814
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000931
[Epoch 104; Iter   679/ 1097] train: loss: 0.0000362
[Epoch 104; Iter   709/ 1097] train: loss: 0.0000336
[Epoch 104; Iter   739/ 1097] train: loss: 0.0000102
[Epoch 104; Iter   769/ 1097] train: loss: 0.0000398
[Epoch 104; Iter   799/ 1097] train: loss: 0.0000278
[Epoch 104; Iter   829/ 1097] train: loss: 0.0000262
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000044
[Epoch 104; Iter   889/ 1097] train: loss: 0.0001478
[Epoch 104; Iter   919/ 1097] train: loss: 0.0003295
[Epoch 104; Iter   949/ 1097] train: loss: 0.0000005
[Epoch 104; Iter   979/ 1097] train: loss: 0.0000077
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0020293
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000344
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0001603
[Epoch 104] ogbg-molhiv: 0.757431 val loss: 2.320057
[Epoch 104] ogbg-molhiv: 0.727299 test loss: 3.515272
[Epoch 105; Iter     2/ 1097] train: loss: 0.0011113
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000021
[Epoch 105; Iter    62/ 1097] train: loss: 0.0000390
[Epoch 105; Iter    92/ 1097] train: loss: 0.0000113
[Epoch 105; Iter   122/ 1097] train: loss: 0.0000005
[Epoch 105; Iter   152/ 1097] train: loss: 0.0000988
[Epoch 105; Iter   182/ 1097] train: loss: 0.0000010
[Epoch 105; Iter   212/ 1097] train: loss: 0.0000328
[Epoch 105; Iter   242/ 1097] train: loss: 0.0000022
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000373
[Epoch 105; Iter   302/ 1097] train: loss: 0.0002689
[Epoch 105; Iter   332/ 1097] train: loss: 0.0000556
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000096
[Epoch 105; Iter   392/ 1097] train: loss: 0.0340086
[Epoch 105; Iter   422/ 1097] train: loss: 0.0000297
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000469
[Epoch 105; Iter   482/ 1097] train: loss: 0.0000116
[Epoch 105; Iter   512/ 1097] train: loss: 0.0000281
[Epoch 105; Iter   542/ 1097] train: loss: 0.0000032
[Epoch 105; Iter   572/ 1097] train: loss: 0.0000000
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000075
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000046
[Epoch 105; Iter   662/ 1097] train: loss: 0.0002423
[Epoch 105; Iter   692/ 1097] train: loss: 0.0000129
[Epoch 101; Iter   730/ 1097] train: loss: 0.0000092
[Epoch 101; Iter   760/ 1097] train: loss: 0.0000061
[Epoch 101; Iter   790/ 1097] train: loss: 0.0245521
[Epoch 101; Iter   820/ 1097] train: loss: 0.0000073
[Epoch 101; Iter   850/ 1097] train: loss: 0.0001333
[Epoch 101; Iter   880/ 1097] train: loss: 0.0000990
[Epoch 101; Iter   910/ 1097] train: loss: 0.0002759
[Epoch 101; Iter   940/ 1097] train: loss: 0.0001236
[Epoch 101; Iter   970/ 1097] train: loss: 0.0001475
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0000299
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0000274
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0000454
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0000563
[Epoch 101] ogbg-molhiv: 0.710529 val loss: 46.949618
[Epoch 101] ogbg-molhiv: 0.625425 test loss: 35.689438
[Epoch 102; Iter    23/ 1097] train: loss: 0.0230891
[Epoch 102; Iter    53/ 1097] train: loss: 0.0000814
[Epoch 102; Iter    83/ 1097] train: loss: 0.0000055
[Epoch 102; Iter   113/ 1097] train: loss: 0.0001459
[Epoch 102; Iter   143/ 1097] train: loss: 0.0000812
[Epoch 102; Iter   173/ 1097] train: loss: 0.0000272
[Epoch 102; Iter   203/ 1097] train: loss: 0.0000093
[Epoch 102; Iter   233/ 1097] train: loss: 0.0000688
[Epoch 102; Iter   263/ 1097] train: loss: 0.0001040
[Epoch 102; Iter   293/ 1097] train: loss: 0.0005868
[Epoch 102; Iter   323/ 1097] train: loss: 0.0000079
[Epoch 102; Iter   353/ 1097] train: loss: 0.0000355
[Epoch 102; Iter   383/ 1097] train: loss: 0.0002624
[Epoch 102; Iter   413/ 1097] train: loss: 0.0000127
[Epoch 102; Iter   443/ 1097] train: loss: 0.0000468
[Epoch 102; Iter   473/ 1097] train: loss: 0.0097756
[Epoch 102; Iter   503/ 1097] train: loss: 0.0001033
[Epoch 102; Iter   533/ 1097] train: loss: 0.0001402
[Epoch 102; Iter   563/ 1097] train: loss: 0.0002129
[Epoch 102; Iter   593/ 1097] train: loss: 0.0000194
[Epoch 102; Iter   623/ 1097] train: loss: 0.0003321
[Epoch 102; Iter   653/ 1097] train: loss: 0.0000824
[Epoch 102; Iter   683/ 1097] train: loss: 0.0001546
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000241
[Epoch 102; Iter   743/ 1097] train: loss: 0.0000811
[Epoch 102; Iter   773/ 1097] train: loss: 0.0000522
[Epoch 102; Iter   803/ 1097] train: loss: 0.0001286
[Epoch 102; Iter   833/ 1097] train: loss: 0.0017414
[Epoch 102; Iter   863/ 1097] train: loss: 0.0000825
[Epoch 102; Iter   893/ 1097] train: loss: 0.0001802
[Epoch 102; Iter   923/ 1097] train: loss: 0.0006493
[Epoch 102; Iter   953/ 1097] train: loss: 0.0000138
[Epoch 102; Iter   983/ 1097] train: loss: 0.0000425
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0033730
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0000786
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0033892
[Epoch 102] ogbg-molhiv: 0.704215 val loss: 62.602006
[Epoch 102] ogbg-molhiv: 0.623193 test loss: 49.621225
[Epoch 103; Iter     6/ 1097] train: loss: 0.0070951
[Epoch 103; Iter    36/ 1097] train: loss: 0.0001521
[Epoch 103; Iter    66/ 1097] train: loss: 0.0045839
[Epoch 103; Iter    96/ 1097] train: loss: 0.0000208
[Epoch 103; Iter   126/ 1097] train: loss: 0.0002948
[Epoch 103; Iter   156/ 1097] train: loss: 0.0003032
[Epoch 103; Iter   186/ 1097] train: loss: 0.0000023
[Epoch 103; Iter   216/ 1097] train: loss: 0.0022426
[Epoch 103; Iter   246/ 1097] train: loss: 0.0003425
[Epoch 103; Iter   276/ 1097] train: loss: 0.0001364
[Epoch 103; Iter   306/ 1097] train: loss: 0.0001097
[Epoch 103; Iter   336/ 1097] train: loss: 0.0002475
[Epoch 103; Iter   366/ 1097] train: loss: 0.0019088
[Epoch 103; Iter   396/ 1097] train: loss: 0.0000010
[Epoch 103; Iter   426/ 1097] train: loss: 0.0000786
[Epoch 103; Iter   456/ 1097] train: loss: 0.0000091
[Epoch 103; Iter   486/ 1097] train: loss: 0.0001339
[Epoch 103; Iter   516/ 1097] train: loss: 0.0000130
[Epoch 103; Iter   546/ 1097] train: loss: 0.0001421
[Epoch 103; Iter   576/ 1097] train: loss: 0.0000940
[Epoch 103; Iter   606/ 1097] train: loss: 0.0000211
[Epoch 103; Iter   636/ 1097] train: loss: 0.0005351
[Epoch 103; Iter   666/ 1097] train: loss: 0.0025455
[Epoch 103; Iter   696/ 1097] train: loss: 0.0000971
[Epoch 103; Iter   726/ 1097] train: loss: 0.0002989
[Epoch 103; Iter   756/ 1097] train: loss: 0.0003173
[Epoch 103; Iter   786/ 1097] train: loss: 0.0238542
[Epoch 103; Iter   816/ 1097] train: loss: 0.0000130
[Epoch 103; Iter   846/ 1097] train: loss: 0.0034669
[Epoch 103; Iter   876/ 1097] train: loss: 0.0030048
[Epoch 103; Iter   906/ 1097] train: loss: 0.0003139
[Epoch 103; Iter   936/ 1097] train: loss: 0.0002688
[Epoch 103; Iter   966/ 1097] train: loss: 0.0000159
[Epoch 103; Iter   996/ 1097] train: loss: 0.0000052
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0526099
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0000731
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0000579
[Epoch 103] ogbg-molhiv: 0.709693 val loss: 45.596839
[Epoch 103] ogbg-molhiv: 0.617356 test loss: 35.465416
[Epoch 104; Iter    19/ 1097] train: loss: 0.0034577
[Epoch 104; Iter    49/ 1097] train: loss: 0.0000832
[Epoch 104; Iter    79/ 1097] train: loss: 0.0000519
[Epoch 104; Iter   109/ 1097] train: loss: 0.0000384
[Epoch 104; Iter   139/ 1097] train: loss: 0.0000147
[Epoch 104; Iter   169/ 1097] train: loss: 0.0001758
[Epoch 104; Iter   199/ 1097] train: loss: 0.0000151
[Epoch 104; Iter   229/ 1097] train: loss: 0.0010365
[Epoch 104; Iter   259/ 1097] train: loss: 0.0012870
[Epoch 104; Iter   289/ 1097] train: loss: 0.0004240
[Epoch 104; Iter   319/ 1097] train: loss: 0.0000657
[Epoch 104; Iter   349/ 1097] train: loss: 0.0000277
[Epoch 104; Iter   379/ 1097] train: loss: 0.0009233
[Epoch 104; Iter   409/ 1097] train: loss: 0.0000681
[Epoch 104; Iter   439/ 1097] train: loss: 0.0001564
[Epoch 104; Iter   469/ 1097] train: loss: 0.0000078
[Epoch 104; Iter   499/ 1097] train: loss: 0.0000483
[Epoch 104; Iter   529/ 1097] train: loss: 0.0001121
[Epoch 104; Iter   559/ 1097] train: loss: 0.0003450
[Epoch 104; Iter   589/ 1097] train: loss: 0.0003239
[Epoch 104; Iter   619/ 1097] train: loss: 0.0097676
[Epoch 104; Iter   649/ 1097] train: loss: 0.0000949
[Epoch 104; Iter   679/ 1097] train: loss: 0.0000139
[Epoch 104; Iter   709/ 1097] train: loss: 0.0000054
[Epoch 104; Iter   739/ 1097] train: loss: 0.0000690
[Epoch 104; Iter   769/ 1097] train: loss: 0.0004066
[Epoch 104; Iter   799/ 1097] train: loss: 0.0029865
[Epoch 104; Iter   829/ 1097] train: loss: 0.0001183
[Epoch 104; Iter   859/ 1097] train: loss: 0.0000399
[Epoch 104; Iter   889/ 1097] train: loss: 0.0000042
[Epoch 104; Iter   919/ 1097] train: loss: 0.0000447
[Epoch 104; Iter   949/ 1097] train: loss: 0.0041411
[Epoch 104; Iter   979/ 1097] train: loss: 0.0001065
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0005778
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0000431
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0001682
[Epoch 104] ogbg-molhiv: 0.702831 val loss: 52.146137
[Epoch 104] ogbg-molhiv: 0.618811 test loss: 40.038222
[Epoch 105; Iter     2/ 1097] train: loss: 0.0000543
[Epoch 105; Iter    32/ 1097] train: loss: 0.0000831
[Epoch 105; Iter    62/ 1097] train: loss: 0.0007043
[Epoch 105; Iter    92/ 1097] train: loss: 0.0010171
[Epoch 105; Iter   122/ 1097] train: loss: 0.0001565
[Epoch 105; Iter   152/ 1097] train: loss: 0.0001231
[Epoch 105; Iter   182/ 1097] train: loss: 0.0016483
[Epoch 105; Iter   212/ 1097] train: loss: 0.0002967
[Epoch 105; Iter   242/ 1097] train: loss: 0.0069670
[Epoch 105; Iter   272/ 1097] train: loss: 0.0000215
[Epoch 105; Iter   302/ 1097] train: loss: 0.0000183
[Epoch 105; Iter   332/ 1097] train: loss: 0.0000191
[Epoch 105; Iter   362/ 1097] train: loss: 0.0000030
[Epoch 105; Iter   392/ 1097] train: loss: 0.0006274
[Epoch 105; Iter   422/ 1097] train: loss: 0.0001455
[Epoch 105; Iter   452/ 1097] train: loss: 0.0000159
[Epoch 105; Iter   482/ 1097] train: loss: 0.0001439
[Epoch 105; Iter   512/ 1097] train: loss: 0.0000278
[Epoch 105; Iter   542/ 1097] train: loss: 0.0012155
[Epoch 105; Iter   572/ 1097] train: loss: 0.0001576
[Epoch 105; Iter   602/ 1097] train: loss: 0.0000086
[Epoch 105; Iter   632/ 1097] train: loss: 0.0000107
[Epoch 105; Iter   662/ 1097] train: loss: 0.0000194
[Epoch 105; Iter   692/ 1097] train: loss: 0.0000006
[Epoch 81; Iter   350/ 1097] train: loss: 0.0035896
[Epoch 81; Iter   380/ 1097] train: loss: 0.0381612
[Epoch 81; Iter   410/ 1097] train: loss: 0.0023094
[Epoch 81; Iter   440/ 1097] train: loss: 0.0028836
[Epoch 81; Iter   470/ 1097] train: loss: 0.2067546
[Epoch 81; Iter   500/ 1097] train: loss: 0.0021488
[Epoch 81; Iter   530/ 1097] train: loss: 0.0359215
[Epoch 81; Iter   560/ 1097] train: loss: 0.0025824
[Epoch 81; Iter   590/ 1097] train: loss: 0.0084864
[Epoch 81; Iter   620/ 1097] train: loss: 0.0055247
[Epoch 81; Iter   650/ 1097] train: loss: 0.0250660
[Epoch 81; Iter   680/ 1097] train: loss: 0.0281113
[Epoch 81; Iter   710/ 1097] train: loss: 0.0223665
[Epoch 81; Iter   740/ 1097] train: loss: 0.0541292
[Epoch 81; Iter   770/ 1097] train: loss: 0.0187892
[Epoch 81; Iter   800/ 1097] train: loss: 0.0048956
[Epoch 81; Iter   830/ 1097] train: loss: 0.0013333
[Epoch 81; Iter   860/ 1097] train: loss: 0.0215557
[Epoch 81; Iter   890/ 1097] train: loss: 0.0394134
[Epoch 81; Iter   920/ 1097] train: loss: 0.0183821
[Epoch 81; Iter   950/ 1097] train: loss: 0.0100984
[Epoch 81; Iter   980/ 1097] train: loss: 0.0084126
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0037446
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0328466
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0130444
[Epoch 81] ogbg-molhiv: 0.820951 val loss: 0.112315
[Epoch 81] ogbg-molhiv: 0.746115 test loss: 0.216472
[Epoch 82; Iter     3/ 1097] train: loss: 0.1264741
[Epoch 82; Iter    33/ 1097] train: loss: 0.0160617
[Epoch 82; Iter    63/ 1097] train: loss: 0.0054130
[Epoch 82; Iter    93/ 1097] train: loss: 0.0118730
[Epoch 82; Iter   123/ 1097] train: loss: 0.0528186
[Epoch 82; Iter   153/ 1097] train: loss: 0.0577605
[Epoch 82; Iter   183/ 1097] train: loss: 0.0506468
[Epoch 82; Iter   213/ 1097] train: loss: 0.0346681
[Epoch 82; Iter   243/ 1097] train: loss: 0.0644747
[Epoch 82; Iter   273/ 1097] train: loss: 0.0401960
[Epoch 82; Iter   303/ 1097] train: loss: 0.0431493
[Epoch 82; Iter   333/ 1097] train: loss: 0.0003897
[Epoch 82; Iter   363/ 1097] train: loss: 0.0400100
[Epoch 82; Iter   393/ 1097] train: loss: 0.0047785
[Epoch 82; Iter   423/ 1097] train: loss: 0.0572069
[Epoch 82; Iter   453/ 1097] train: loss: 0.0050015
[Epoch 82; Iter   483/ 1097] train: loss: 0.0593427
[Epoch 82; Iter   513/ 1097] train: loss: 0.0261476
[Epoch 82; Iter   543/ 1097] train: loss: 0.0138461
[Epoch 82; Iter   573/ 1097] train: loss: 0.0259774
[Epoch 82; Iter   603/ 1097] train: loss: 0.0019010
[Epoch 82; Iter   633/ 1097] train: loss: 0.0196132
[Epoch 82; Iter   663/ 1097] train: loss: 0.0021686
[Epoch 82; Iter   693/ 1097] train: loss: 0.0119005
[Epoch 82; Iter   723/ 1097] train: loss: 0.0293161
[Epoch 82; Iter   753/ 1097] train: loss: 0.1692597
[Epoch 82; Iter   783/ 1097] train: loss: 0.0314083
[Epoch 82; Iter   813/ 1097] train: loss: 0.0068338
[Epoch 82; Iter   843/ 1097] train: loss: 0.0042574
[Epoch 82; Iter   873/ 1097] train: loss: 0.1397688
[Epoch 82; Iter   903/ 1097] train: loss: 0.0117380
[Epoch 82; Iter   933/ 1097] train: loss: 0.0091539
[Epoch 82; Iter   963/ 1097] train: loss: 0.0143023
[Epoch 82; Iter   993/ 1097] train: loss: 0.0177897
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0796622
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0768257
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0033075
[Epoch 82] ogbg-molhiv: 0.817102 val loss: 0.120440
[Epoch 82] ogbg-molhiv: 0.749296 test loss: 0.220302
[Epoch 83; Iter    16/ 1097] train: loss: 0.0406543
[Epoch 83; Iter    46/ 1097] train: loss: 0.0352811
[Epoch 83; Iter    76/ 1097] train: loss: 0.0058206
[Epoch 83; Iter   106/ 1097] train: loss: 0.0034241
[Epoch 83; Iter   136/ 1097] train: loss: 0.0116179
[Epoch 83; Iter   166/ 1097] train: loss: 0.0476580
[Epoch 83; Iter   196/ 1097] train: loss: 0.0011288
[Epoch 83; Iter   226/ 1097] train: loss: 0.0404238
[Epoch 83; Iter   256/ 1097] train: loss: 0.0135876
[Epoch 83; Iter   286/ 1097] train: loss: 0.0025645
[Epoch 83; Iter   316/ 1097] train: loss: 0.0362420
[Epoch 83; Iter   346/ 1097] train: loss: 0.0052798
[Epoch 83; Iter   376/ 1097] train: loss: 0.0128387
[Epoch 83; Iter   406/ 1097] train: loss: 0.0066690
[Epoch 83; Iter   436/ 1097] train: loss: 0.0206923
[Epoch 83; Iter   466/ 1097] train: loss: 0.0052793
[Epoch 83; Iter   496/ 1097] train: loss: 0.0300717
[Epoch 83; Iter   526/ 1097] train: loss: 0.0057470
[Epoch 83; Iter   556/ 1097] train: loss: 0.0101412
[Epoch 83; Iter   586/ 1097] train: loss: 0.0039143
[Epoch 83; Iter   616/ 1097] train: loss: 0.0016478
[Epoch 83; Iter   646/ 1097] train: loss: 0.0258610
[Epoch 83; Iter   676/ 1097] train: loss: 0.0363988
[Epoch 83; Iter   706/ 1097] train: loss: 0.0041169
[Epoch 83; Iter   736/ 1097] train: loss: 0.0204815
[Epoch 83; Iter   766/ 1097] train: loss: 0.0241881
[Epoch 83; Iter   796/ 1097] train: loss: 0.1298921
[Epoch 83; Iter   826/ 1097] train: loss: 0.1937282
[Epoch 83; Iter   856/ 1097] train: loss: 0.0030657
[Epoch 83; Iter   886/ 1097] train: loss: 0.0065036
[Epoch 83; Iter   916/ 1097] train: loss: 0.0121356
[Epoch 83; Iter   946/ 1097] train: loss: 0.0301811
[Epoch 83; Iter   976/ 1097] train: loss: 0.0017852
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0123256
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0015229
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0018425
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0295925
[Epoch 83] ogbg-molhiv: 0.823220 val loss: 0.118388
[Epoch 83] ogbg-molhiv: 0.748950 test loss: 0.225137
[Epoch 84; Iter    29/ 1097] train: loss: 0.0035245
[Epoch 84; Iter    59/ 1097] train: loss: 0.0060082
[Epoch 84; Iter    89/ 1097] train: loss: 0.0405873
[Epoch 84; Iter   119/ 1097] train: loss: 0.0154683
[Epoch 84; Iter   149/ 1097] train: loss: 0.0081211
[Epoch 84; Iter   179/ 1097] train: loss: 0.0093426
[Epoch 84; Iter   209/ 1097] train: loss: 0.0994182
[Epoch 84; Iter   239/ 1097] train: loss: 0.0578082
[Epoch 84; Iter   269/ 1097] train: loss: 0.0443296
[Epoch 84; Iter   299/ 1097] train: loss: 0.0299539
[Epoch 84; Iter   329/ 1097] train: loss: 0.0045455
[Epoch 84; Iter   359/ 1097] train: loss: 0.0565304
[Epoch 84; Iter   389/ 1097] train: loss: 0.0108542
[Epoch 84; Iter   419/ 1097] train: loss: 0.0063699
[Epoch 84; Iter   449/ 1097] train: loss: 0.0113829
[Epoch 84; Iter   479/ 1097] train: loss: 0.0200115
[Epoch 84; Iter   509/ 1097] train: loss: 0.0168505
[Epoch 84; Iter   539/ 1097] train: loss: 0.0202970
[Epoch 84; Iter   569/ 1097] train: loss: 0.0972412
[Epoch 84; Iter   599/ 1097] train: loss: 0.0064338
[Epoch 84; Iter   629/ 1097] train: loss: 0.0415506
[Epoch 84; Iter   659/ 1097] train: loss: 0.0211962
[Epoch 84; Iter   689/ 1097] train: loss: 0.0051734
[Epoch 84; Iter   719/ 1097] train: loss: 0.0446316
[Epoch 84; Iter   749/ 1097] train: loss: 0.0066107
[Epoch 84; Iter   779/ 1097] train: loss: 0.0026090
[Epoch 84; Iter   809/ 1097] train: loss: 0.0012993
[Epoch 84; Iter   839/ 1097] train: loss: 0.0332727
[Epoch 84; Iter   869/ 1097] train: loss: 0.0166812
[Epoch 84; Iter   899/ 1097] train: loss: 0.0447609
[Epoch 84; Iter   929/ 1097] train: loss: 0.0113853
[Epoch 84; Iter   959/ 1097] train: loss: 0.0050100
[Epoch 84; Iter   989/ 1097] train: loss: 0.0028087
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0851166
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0075847
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0024121
[Epoch 84] ogbg-molhiv: 0.815265 val loss: 0.122909
[Epoch 84] ogbg-molhiv: 0.747191 test loss: 0.230712
[Epoch 85; Iter    12/ 1097] train: loss: 0.0100270
[Epoch 85; Iter    42/ 1097] train: loss: 0.0076725
[Epoch 85; Iter    72/ 1097] train: loss: 0.0020266
[Epoch 85; Iter   102/ 1097] train: loss: 0.0451959
[Epoch 85; Iter   132/ 1097] train: loss: 0.0125691
[Epoch 85; Iter   162/ 1097] train: loss: 0.0131027
[Epoch 85; Iter   192/ 1097] train: loss: 0.0049097
[Epoch 85; Iter   222/ 1097] train: loss: 0.0073497
[Epoch 85; Iter   252/ 1097] train: loss: 0.0382292
[Epoch 85; Iter   282/ 1097] train: loss: 0.0033418
[Epoch 85; Iter   312/ 1097] train: loss: 0.0266271
[Epoch 85; Iter   342/ 1097] train: loss: 0.0493522
[Epoch 85; Iter   372/ 1097] train: loss: 0.0200016
[Epoch 85; Iter   402/ 1097] train: loss: 0.0150236
[Epoch 81; Iter   350/ 1097] train: loss: 0.0044882
[Epoch 81; Iter   380/ 1097] train: loss: 0.0035461
[Epoch 81; Iter   410/ 1097] train: loss: 0.1001673
[Epoch 81; Iter   440/ 1097] train: loss: 0.0182125
[Epoch 81; Iter   470/ 1097] train: loss: 0.0063651
[Epoch 81; Iter   500/ 1097] train: loss: 0.0370138
[Epoch 81; Iter   530/ 1097] train: loss: 0.0121095
[Epoch 81; Iter   560/ 1097] train: loss: 0.0023478
[Epoch 81; Iter   590/ 1097] train: loss: 0.0031360
[Epoch 81; Iter   620/ 1097] train: loss: 0.0343018
[Epoch 81; Iter   650/ 1097] train: loss: 0.0014741
[Epoch 81; Iter   680/ 1097] train: loss: 0.0261334
[Epoch 81; Iter   710/ 1097] train: loss: 0.0904652
[Epoch 81; Iter   740/ 1097] train: loss: 0.1583470
[Epoch 81; Iter   770/ 1097] train: loss: 0.0216624
[Epoch 81; Iter   800/ 1097] train: loss: 0.0029960
[Epoch 81; Iter   830/ 1097] train: loss: 0.0327353
[Epoch 81; Iter   860/ 1097] train: loss: 0.0050902
[Epoch 81; Iter   890/ 1097] train: loss: 0.0033380
[Epoch 81; Iter   920/ 1097] train: loss: 0.0120882
[Epoch 81; Iter   950/ 1097] train: loss: 0.0054888
[Epoch 81; Iter   980/ 1097] train: loss: 0.0040924
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0402321
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0154644
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0067673
[Epoch 81] ogbg-molhiv: 0.780408 val loss: 0.123979
[Epoch 81] ogbg-molhiv: 0.742676 test loss: 0.230896
[Epoch 82; Iter     3/ 1097] train: loss: 0.0016443
[Epoch 82; Iter    33/ 1097] train: loss: 0.0009012
[Epoch 82; Iter    63/ 1097] train: loss: 0.0456247
[Epoch 82; Iter    93/ 1097] train: loss: 0.0209224
[Epoch 82; Iter   123/ 1097] train: loss: 0.0087499
[Epoch 82; Iter   153/ 1097] train: loss: 0.0937329
[Epoch 82; Iter   183/ 1097] train: loss: 0.0841582
[Epoch 82; Iter   213/ 1097] train: loss: 0.0239897
[Epoch 82; Iter   243/ 1097] train: loss: 0.0172722
[Epoch 82; Iter   273/ 1097] train: loss: 0.0859485
[Epoch 82; Iter   303/ 1097] train: loss: 0.0086302
[Epoch 82; Iter   333/ 1097] train: loss: 0.0020109
[Epoch 82; Iter   363/ 1097] train: loss: 0.0116507
[Epoch 82; Iter   393/ 1097] train: loss: 0.0067716
[Epoch 82; Iter   423/ 1097] train: loss: 0.0040040
[Epoch 82; Iter   453/ 1097] train: loss: 0.0122201
[Epoch 82; Iter   483/ 1097] train: loss: 0.0581432
[Epoch 82; Iter   513/ 1097] train: loss: 0.0136678
[Epoch 82; Iter   543/ 1097] train: loss: 0.0042745
[Epoch 82; Iter   573/ 1097] train: loss: 0.0028725
[Epoch 82; Iter   603/ 1097] train: loss: 0.0027639
[Epoch 82; Iter   633/ 1097] train: loss: 0.0018910
[Epoch 82; Iter   663/ 1097] train: loss: 0.0015155
[Epoch 82; Iter   693/ 1097] train: loss: 0.0788052
[Epoch 82; Iter   723/ 1097] train: loss: 0.0052593
[Epoch 82; Iter   753/ 1097] train: loss: 0.0231414
[Epoch 82; Iter   783/ 1097] train: loss: 0.0595633
[Epoch 82; Iter   813/ 1097] train: loss: 0.0023386
[Epoch 82; Iter   843/ 1097] train: loss: 0.0613515
[Epoch 82; Iter   873/ 1097] train: loss: 0.0006126
[Epoch 82; Iter   903/ 1097] train: loss: 0.0155326
[Epoch 82; Iter   933/ 1097] train: loss: 0.1351843
[Epoch 82; Iter   963/ 1097] train: loss: 0.0216625
[Epoch 82; Iter   993/ 1097] train: loss: 0.0122222
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0009298
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0535983
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0012517
[Epoch 82] ogbg-molhiv: 0.785203 val loss: 0.122013
[Epoch 82] ogbg-molhiv: 0.746822 test loss: 0.239517
[Epoch 83; Iter    16/ 1097] train: loss: 0.0037835
[Epoch 83; Iter    46/ 1097] train: loss: 0.0018289
[Epoch 83; Iter    76/ 1097] train: loss: 0.0538362
[Epoch 83; Iter   106/ 1097] train: loss: 0.0017073
[Epoch 83; Iter   136/ 1097] train: loss: 0.0019272
[Epoch 83; Iter   166/ 1097] train: loss: 0.0013081
[Epoch 83; Iter   196/ 1097] train: loss: 0.0246532
[Epoch 83; Iter   226/ 1097] train: loss: 0.0083771
[Epoch 83; Iter   256/ 1097] train: loss: 0.0055991
[Epoch 83; Iter   286/ 1097] train: loss: 0.0081663
[Epoch 83; Iter   316/ 1097] train: loss: 0.0066746
[Epoch 83; Iter   346/ 1097] train: loss: 0.0126940
[Epoch 83; Iter   376/ 1097] train: loss: 0.0289544
[Epoch 83; Iter   406/ 1097] train: loss: 0.0145253
[Epoch 83; Iter   436/ 1097] train: loss: 0.0099033
[Epoch 83; Iter   466/ 1097] train: loss: 0.0359556
[Epoch 83; Iter   496/ 1097] train: loss: 0.0109644
[Epoch 83; Iter   526/ 1097] train: loss: 0.0120759
[Epoch 83; Iter   556/ 1097] train: loss: 0.0546528
[Epoch 83; Iter   586/ 1097] train: loss: 0.0019577
[Epoch 83; Iter   616/ 1097] train: loss: 0.0221026
[Epoch 83; Iter   646/ 1097] train: loss: 0.0019479
[Epoch 83; Iter   676/ 1097] train: loss: 0.0021365
[Epoch 83; Iter   706/ 1097] train: loss: 0.0014054
[Epoch 83; Iter   736/ 1097] train: loss: 0.0228249
[Epoch 83; Iter   766/ 1097] train: loss: 0.0036780
[Epoch 83; Iter   796/ 1097] train: loss: 0.0009385
[Epoch 83; Iter   826/ 1097] train: loss: 0.0172527
[Epoch 83; Iter   856/ 1097] train: loss: 0.0174145
[Epoch 83; Iter   886/ 1097] train: loss: 0.0031167
[Epoch 83; Iter   916/ 1097] train: loss: 0.1218057
[Epoch 83; Iter   946/ 1097] train: loss: 0.0031356
[Epoch 83; Iter   976/ 1097] train: loss: 0.0447277
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0050644
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0060715
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0051067
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0307319
[Epoch 83] ogbg-molhiv: 0.784866 val loss: 0.127302
[Epoch 83] ogbg-molhiv: 0.742388 test loss: 0.245060
[Epoch 84; Iter    29/ 1097] train: loss: 0.0012414
[Epoch 84; Iter    59/ 1097] train: loss: 0.0020788
[Epoch 84; Iter    89/ 1097] train: loss: 0.0068286
[Epoch 84; Iter   119/ 1097] train: loss: 0.0618712
[Epoch 84; Iter   149/ 1097] train: loss: 0.0620599
[Epoch 84; Iter   179/ 1097] train: loss: 0.0353898
[Epoch 84; Iter   209/ 1097] train: loss: 0.0038082
[Epoch 84; Iter   239/ 1097] train: loss: 0.0001428
[Epoch 84; Iter   269/ 1097] train: loss: 0.0114091
[Epoch 84; Iter   299/ 1097] train: loss: 0.0227595
[Epoch 84; Iter   329/ 1097] train: loss: 0.1088949
[Epoch 84; Iter   359/ 1097] train: loss: 0.0049237
[Epoch 84; Iter   389/ 1097] train: loss: 0.0043881
[Epoch 84; Iter   419/ 1097] train: loss: 0.0717899
[Epoch 84; Iter   449/ 1097] train: loss: 0.0193214
[Epoch 84; Iter   479/ 1097] train: loss: 0.0008729
[Epoch 84; Iter   509/ 1097] train: loss: 0.0007445
[Epoch 84; Iter   539/ 1097] train: loss: 0.0417491
[Epoch 84; Iter   569/ 1097] train: loss: 0.0104590
[Epoch 84; Iter   599/ 1097] train: loss: 0.0073287
[Epoch 84; Iter   629/ 1097] train: loss: 0.0104741
[Epoch 84; Iter   659/ 1097] train: loss: 0.0423325
[Epoch 84; Iter   689/ 1097] train: loss: 0.0031711
[Epoch 84; Iter   719/ 1097] train: loss: 0.0749869
[Epoch 84; Iter   749/ 1097] train: loss: 0.0157032
[Epoch 84; Iter   779/ 1097] train: loss: 0.0068670
[Epoch 84; Iter   809/ 1097] train: loss: 0.0028002
[Epoch 84; Iter   839/ 1097] train: loss: 0.0230327
[Epoch 84; Iter   869/ 1097] train: loss: 0.0063832
[Epoch 84; Iter   899/ 1097] train: loss: 0.0021547
[Epoch 84; Iter   929/ 1097] train: loss: 0.0034614
[Epoch 84; Iter   959/ 1097] train: loss: 0.0032798
[Epoch 84; Iter   989/ 1097] train: loss: 0.0090510
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0630723
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0232652
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0515687
[Epoch 84] ogbg-molhiv: 0.783993 val loss: 0.122160
[Epoch 84] ogbg-molhiv: 0.746230 test loss: 0.234901
[Epoch 85; Iter    12/ 1097] train: loss: 0.0013957
[Epoch 85; Iter    42/ 1097] train: loss: 0.0047755
[Epoch 85; Iter    72/ 1097] train: loss: 0.0044392
[Epoch 85; Iter   102/ 1097] train: loss: 0.0165143
[Epoch 85; Iter   132/ 1097] train: loss: 0.0443036
[Epoch 85; Iter   162/ 1097] train: loss: 0.0025277
[Epoch 85; Iter   192/ 1097] train: loss: 0.0722906
[Epoch 85; Iter   222/ 1097] train: loss: 0.0295799
[Epoch 85; Iter   252/ 1097] train: loss: 0.1341822
[Epoch 85; Iter   282/ 1097] train: loss: 0.0060962
[Epoch 85; Iter   312/ 1097] train: loss: 0.0072245
[Epoch 85; Iter   342/ 1097] train: loss: 0.0020207
[Epoch 85; Iter   372/ 1097] train: loss: 0.0154924
[Epoch 85; Iter   402/ 1097] train: loss: 0.0033283
[Epoch 81; Iter   350/ 1097] train: loss: 0.0048516
[Epoch 81; Iter   380/ 1097] train: loss: 0.0078945
[Epoch 81; Iter   410/ 1097] train: loss: 0.0569733
[Epoch 81; Iter   440/ 1097] train: loss: 0.0063860
[Epoch 81; Iter   470/ 1097] train: loss: 0.0189567
[Epoch 81; Iter   500/ 1097] train: loss: 0.0147941
[Epoch 81; Iter   530/ 1097] train: loss: 0.0093936
[Epoch 81; Iter   560/ 1097] train: loss: 0.0579145
[Epoch 81; Iter   590/ 1097] train: loss: 0.2174161
[Epoch 81; Iter   620/ 1097] train: loss: 0.0063953
[Epoch 81; Iter   650/ 1097] train: loss: 0.0022332
[Epoch 81; Iter   680/ 1097] train: loss: 0.0248732
[Epoch 81; Iter   710/ 1097] train: loss: 0.0986746
[Epoch 81; Iter   740/ 1097] train: loss: 0.0266561
[Epoch 81; Iter   770/ 1097] train: loss: 0.2246929
[Epoch 81; Iter   800/ 1097] train: loss: 0.0111972
[Epoch 81; Iter   830/ 1097] train: loss: 0.0150000
[Epoch 81; Iter   860/ 1097] train: loss: 0.0041500
[Epoch 81; Iter   890/ 1097] train: loss: 0.0040634
[Epoch 81; Iter   920/ 1097] train: loss: 0.0483492
[Epoch 81; Iter   950/ 1097] train: loss: 0.0309986
[Epoch 81; Iter   980/ 1097] train: loss: 0.0630563
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0710107
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0352770
[Epoch 81; Iter  1070/ 1097] train: loss: 0.1435674
[Epoch 81] ogbg-molhiv: 0.813988 val loss: 0.114725
[Epoch 81] ogbg-molhiv: 0.748622 test loss: 0.220855
[Epoch 82; Iter     3/ 1097] train: loss: 0.0147864
[Epoch 82; Iter    33/ 1097] train: loss: 0.0127844
[Epoch 82; Iter    63/ 1097] train: loss: 0.1303275
[Epoch 82; Iter    93/ 1097] train: loss: 0.0139509
[Epoch 82; Iter   123/ 1097] train: loss: 0.0203240
[Epoch 82; Iter   153/ 1097] train: loss: 0.1280228
[Epoch 82; Iter   183/ 1097] train: loss: 0.0056057
[Epoch 82; Iter   213/ 1097] train: loss: 0.0308735
[Epoch 82; Iter   243/ 1097] train: loss: 0.0077902
[Epoch 82; Iter   273/ 1097] train: loss: 0.0248656
[Epoch 82; Iter   303/ 1097] train: loss: 0.0473558
[Epoch 82; Iter   333/ 1097] train: loss: 0.0245986
[Epoch 82; Iter   363/ 1097] train: loss: 0.0027126
[Epoch 82; Iter   393/ 1097] train: loss: 0.0162238
[Epoch 82; Iter   423/ 1097] train: loss: 0.2127354
[Epoch 82; Iter   453/ 1097] train: loss: 0.0098531
[Epoch 82; Iter   483/ 1097] train: loss: 0.0020558
[Epoch 82; Iter   513/ 1097] train: loss: 0.0066565
[Epoch 82; Iter   543/ 1097] train: loss: 0.0034004
[Epoch 82; Iter   573/ 1097] train: loss: 0.0096773
[Epoch 82; Iter   603/ 1097] train: loss: 0.0018781
[Epoch 82; Iter   633/ 1097] train: loss: 0.0650132
[Epoch 82; Iter   663/ 1097] train: loss: 0.0156059
[Epoch 82; Iter   693/ 1097] train: loss: 0.0159987
[Epoch 82; Iter   723/ 1097] train: loss: 0.0066352
[Epoch 82; Iter   753/ 1097] train: loss: 0.0136738
[Epoch 82; Iter   783/ 1097] train: loss: 0.0162414
[Epoch 82; Iter   813/ 1097] train: loss: 0.0381884
[Epoch 82; Iter   843/ 1097] train: loss: 0.0088290
[Epoch 82; Iter   873/ 1097] train: loss: 0.0169518
[Epoch 82; Iter   903/ 1097] train: loss: 0.0225060
[Epoch 82; Iter   933/ 1097] train: loss: 0.0136602
[Epoch 82; Iter   963/ 1097] train: loss: 0.0088711
[Epoch 82; Iter   993/ 1097] train: loss: 0.1847252
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0089591
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0060173
[Epoch 82; Iter  1083/ 1097] train: loss: 0.1086883
[Epoch 82] ogbg-molhiv: 0.808422 val loss: 0.110758
[Epoch 82] ogbg-molhiv: 0.757500 test loss: 0.216379
[Epoch 83; Iter    16/ 1097] train: loss: 0.0193607
[Epoch 83; Iter    46/ 1097] train: loss: 0.0064531
[Epoch 83; Iter    76/ 1097] train: loss: 0.0115418
[Epoch 83; Iter   106/ 1097] train: loss: 0.0384425
[Epoch 83; Iter   136/ 1097] train: loss: 0.0027460
[Epoch 83; Iter   166/ 1097] train: loss: 0.0182763
[Epoch 83; Iter   196/ 1097] train: loss: 0.0163538
[Epoch 83; Iter   226/ 1097] train: loss: 0.0227539
[Epoch 83; Iter   256/ 1097] train: loss: 0.0105063
[Epoch 83; Iter   286/ 1097] train: loss: 0.0092500
[Epoch 83; Iter   316/ 1097] train: loss: 0.0205010
[Epoch 83; Iter   346/ 1097] train: loss: 0.0178604
[Epoch 83; Iter   376/ 1097] train: loss: 0.0138355
[Epoch 83; Iter   406/ 1097] train: loss: 0.0251368
[Epoch 83; Iter   436/ 1097] train: loss: 0.0678754
[Epoch 83; Iter   466/ 1097] train: loss: 0.0196952
[Epoch 83; Iter   496/ 1097] train: loss: 0.0094018
[Epoch 83; Iter   526/ 1097] train: loss: 0.0489703
[Epoch 83; Iter   556/ 1097] train: loss: 0.0084462
[Epoch 83; Iter   586/ 1097] train: loss: 0.0029020
[Epoch 83; Iter   616/ 1097] train: loss: 0.0321411
[Epoch 83; Iter   646/ 1097] train: loss: 0.0360082
[Epoch 83; Iter   676/ 1097] train: loss: 0.0299419
[Epoch 83; Iter   706/ 1097] train: loss: 0.0441777
[Epoch 83; Iter   736/ 1097] train: loss: 0.0503010
[Epoch 83; Iter   766/ 1097] train: loss: 0.0149528
[Epoch 83; Iter   796/ 1097] train: loss: 0.0167108
[Epoch 83; Iter   826/ 1097] train: loss: 0.0040377
[Epoch 83; Iter   856/ 1097] train: loss: 0.0105058
[Epoch 83; Iter   886/ 1097] train: loss: 0.1021636
[Epoch 83; Iter   916/ 1097] train: loss: 0.0679419
[Epoch 83; Iter   946/ 1097] train: loss: 0.0308673
[Epoch 83; Iter   976/ 1097] train: loss: 0.0007557
[Epoch 83; Iter  1006/ 1097] train: loss: 0.1488504
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0530157
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0050240
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0971535
[Epoch 83] ogbg-molhiv: 0.809536 val loss: 0.118628
[Epoch 83] ogbg-molhiv: 0.739277 test loss: 0.245062
[Epoch 84; Iter    29/ 1097] train: loss: 0.0180158
[Epoch 84; Iter    59/ 1097] train: loss: 0.0036963
[Epoch 84; Iter    89/ 1097] train: loss: 0.0291993
[Epoch 84; Iter   119/ 1097] train: loss: 0.0175618
[Epoch 84; Iter   149/ 1097] train: loss: 0.1137357
[Epoch 84; Iter   179/ 1097] train: loss: 0.0890071
[Epoch 84; Iter   209/ 1097] train: loss: 0.0031213
[Epoch 84; Iter   239/ 1097] train: loss: 0.0287977
[Epoch 84; Iter   269/ 1097] train: loss: 0.0044141
[Epoch 84; Iter   299/ 1097] train: loss: 0.0097081
[Epoch 84; Iter   329/ 1097] train: loss: 0.0013891
[Epoch 84; Iter   359/ 1097] train: loss: 0.0073964
[Epoch 84; Iter   389/ 1097] train: loss: 0.0056088
[Epoch 84; Iter   419/ 1097] train: loss: 0.0089115
[Epoch 84; Iter   449/ 1097] train: loss: 0.0471812
[Epoch 84; Iter   479/ 1097] train: loss: 0.0105819
[Epoch 84; Iter   509/ 1097] train: loss: 0.0049720
[Epoch 84; Iter   539/ 1097] train: loss: 0.0063602
[Epoch 84; Iter   569/ 1097] train: loss: 0.0183452
[Epoch 84; Iter   599/ 1097] train: loss: 0.0031977
[Epoch 84; Iter   629/ 1097] train: loss: 0.0453472
[Epoch 84; Iter   659/ 1097] train: loss: 0.0280891
[Epoch 84; Iter   689/ 1097] train: loss: 0.0482850
[Epoch 84; Iter   719/ 1097] train: loss: 0.0098471
[Epoch 84; Iter   749/ 1097] train: loss: 0.0076195
[Epoch 84; Iter   779/ 1097] train: loss: 0.0833194
[Epoch 84; Iter   809/ 1097] train: loss: 0.0143598
[Epoch 84; Iter   839/ 1097] train: loss: 0.0124318
[Epoch 84; Iter   869/ 1097] train: loss: 0.0245927
[Epoch 84; Iter   899/ 1097] train: loss: 0.0441017
[Epoch 84; Iter   929/ 1097] train: loss: 0.0093202
[Epoch 84; Iter   959/ 1097] train: loss: 0.0126756
[Epoch 84; Iter   989/ 1097] train: loss: 0.1255677
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0320882
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0098110
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0609027
[Epoch 84] ogbg-molhiv: 0.810727 val loss: 0.104483
[Epoch 84] ogbg-molhiv: 0.748838 test loss: 0.213082
[Epoch 85; Iter    12/ 1097] train: loss: 0.0260680
[Epoch 85; Iter    42/ 1097] train: loss: 0.0289817
[Epoch 85; Iter    72/ 1097] train: loss: 0.0016718
[Epoch 85; Iter   102/ 1097] train: loss: 0.0015855
[Epoch 85; Iter   132/ 1097] train: loss: 0.0048587
[Epoch 85; Iter   162/ 1097] train: loss: 0.0582109
[Epoch 85; Iter   192/ 1097] train: loss: 0.0247423
[Epoch 85; Iter   222/ 1097] train: loss: 0.0047620
[Epoch 85; Iter   252/ 1097] train: loss: 0.0113494
[Epoch 85; Iter   282/ 1097] train: loss: 0.0282631
[Epoch 85; Iter   312/ 1097] train: loss: 0.0499551
[Epoch 85; Iter   342/ 1097] train: loss: 0.0580046
[Epoch 85; Iter   372/ 1097] train: loss: 0.0149732
[Epoch 85; Iter   402/ 1097] train: loss: 0.0204953
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000009
[Epoch 105; Iter   752/ 1097] train: loss: 0.0008186
[Epoch 105; Iter   782/ 1097] train: loss: 0.0000057
[Epoch 105; Iter   812/ 1097] train: loss: 0.0004886
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000167
[Epoch 105; Iter   872/ 1097] train: loss: 0.0181198
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000073
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000267
[Epoch 105; Iter   962/ 1097] train: loss: 0.0003254
[Epoch 105; Iter   992/ 1097] train: loss: 0.0001156
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000433
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0000420
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000410
[Epoch 105] ogbg-molhiv: 0.772814 val loss: 0.248104
[Epoch 105] ogbg-molhiv: 0.712721 test loss: 0.467923
[Epoch 106; Iter    15/ 1097] train: loss: 0.0000042
[Epoch 106; Iter    45/ 1097] train: loss: 0.0001244
[Epoch 106; Iter    75/ 1097] train: loss: 0.0134159
[Epoch 106; Iter   105/ 1097] train: loss: 0.0001739
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000078
[Epoch 106; Iter   165/ 1097] train: loss: 0.0021318
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000444
[Epoch 106; Iter   225/ 1097] train: loss: 0.0000130
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000799
[Epoch 106; Iter   285/ 1097] train: loss: 0.0001177
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000483
[Epoch 106; Iter   345/ 1097] train: loss: 0.0004117
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000356
[Epoch 106; Iter   405/ 1097] train: loss: 0.0001974
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000198
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000203
[Epoch 106; Iter   495/ 1097] train: loss: 0.0003618
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000548
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000170
[Epoch 106; Iter   585/ 1097] train: loss: 0.0003055
[Epoch 106; Iter   615/ 1097] train: loss: 0.0004303
[Epoch 106; Iter   645/ 1097] train: loss: 0.0195512
[Epoch 106; Iter   675/ 1097] train: loss: 0.0000890
[Epoch 106; Iter   705/ 1097] train: loss: 0.0000320
[Epoch 106; Iter   735/ 1097] train: loss: 0.0000699
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000141
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000862
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000082
[Epoch 106; Iter   855/ 1097] train: loss: 0.0001353
[Epoch 106; Iter   885/ 1097] train: loss: 0.0245926
[Epoch 106; Iter   915/ 1097] train: loss: 0.0006749
[Epoch 106; Iter   945/ 1097] train: loss: 0.0000036
[Epoch 106; Iter   975/ 1097] train: loss: 0.0000129
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0003139
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0717074
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000032
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000518
[Epoch 106] ogbg-molhiv: 0.742792 val loss: 0.703588
[Epoch 106] ogbg-molhiv: 0.726379 test loss: 1.013949
[Epoch 107; Iter    28/ 1097] train: loss: 0.1348333
[Epoch 107; Iter    58/ 1097] train: loss: 0.0030809
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000343
[Epoch 107; Iter   118/ 1097] train: loss: 0.0001883
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000330
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000415
[Epoch 107; Iter   208/ 1097] train: loss: 0.0010255
[Epoch 107; Iter   238/ 1097] train: loss: 0.0001273
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000192
[Epoch 107; Iter   298/ 1097] train: loss: 0.0003181
[Epoch 107; Iter   328/ 1097] train: loss: 0.0002084
[Epoch 107; Iter   358/ 1097] train: loss: 0.0002014
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000146
[Epoch 107; Iter   418/ 1097] train: loss: 0.0001066
[Epoch 107; Iter   448/ 1097] train: loss: 0.0019310
[Epoch 107; Iter   478/ 1097] train: loss: 0.0127440
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000102
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000293
[Epoch 107; Iter   568/ 1097] train: loss: 0.0031229
[Epoch 107; Iter   598/ 1097] train: loss: 0.0000226
[Epoch 107; Iter   628/ 1097] train: loss: 0.0007685
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000388
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000171
[Epoch 107; Iter   718/ 1097] train: loss: 0.0171632
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000642
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000782
[Epoch 107; Iter   808/ 1097] train: loss: 0.0014436
[Epoch 107; Iter   838/ 1097] train: loss: 0.0008674
[Epoch 107; Iter   868/ 1097] train: loss: 0.0000048
[Epoch 107; Iter   898/ 1097] train: loss: 0.0004115
[Epoch 107; Iter   928/ 1097] train: loss: 0.0001478
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000403
[Epoch 107; Iter   988/ 1097] train: loss: 0.0000160
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000438
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0006706
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000373
[Epoch 107] ogbg-molhiv: 0.770784 val loss: 0.995928
[Epoch 107] ogbg-molhiv: 0.722847 test loss: 1.010483
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000153
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000061
[Epoch 108; Iter    71/ 1097] train: loss: 0.0009932
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000031
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000248
[Epoch 108; Iter   161/ 1097] train: loss: 0.0001112
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000041
[Epoch 108; Iter   221/ 1097] train: loss: 0.0000036
[Epoch 108; Iter   251/ 1097] train: loss: 0.0000157
[Epoch 108; Iter   281/ 1097] train: loss: 0.0000345
[Epoch 108; Iter   311/ 1097] train: loss: 0.0024523
[Epoch 108; Iter   341/ 1097] train: loss: 0.0002064
[Epoch 108; Iter   371/ 1097] train: loss: 0.0000582
[Epoch 108; Iter   401/ 1097] train: loss: 0.0000572
[Epoch 108; Iter   431/ 1097] train: loss: 0.0002721
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000109
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000157
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000653
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000395
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000051
[Epoch 108; Iter   611/ 1097] train: loss: 0.0001589
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000494
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000630
[Epoch 108; Iter   701/ 1097] train: loss: 0.0001377
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000938
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000395
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000361
[Epoch 108; Iter   821/ 1097] train: loss: 0.0007267
[Epoch 108; Iter   851/ 1097] train: loss: 0.0005354
[Epoch 108; Iter   881/ 1097] train: loss: 0.0000603
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000027
[Epoch 108; Iter   941/ 1097] train: loss: 0.0000221
[Epoch 108; Iter   971/ 1097] train: loss: 0.0001198
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0013112
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0003675
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0000313
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000033
[Epoch 108] ogbg-molhiv: 0.666201 val loss: 4.676263
[Epoch 108] ogbg-molhiv: 0.726727 test loss: 0.434932
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000438
[Epoch 109; Iter    54/ 1097] train: loss: 0.0000041
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000173
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000127
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000321
[Epoch 109; Iter   174/ 1097] train: loss: 0.0011915
[Epoch 109; Iter   204/ 1097] train: loss: 0.0001357
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000057
[Epoch 109; Iter   264/ 1097] train: loss: 0.0002516
[Epoch 109; Iter   294/ 1097] train: loss: 0.0142590
[Epoch 109; Iter   324/ 1097] train: loss: 0.0005123
[Epoch 109; Iter   354/ 1097] train: loss: 0.0004209
[Epoch 109; Iter   384/ 1097] train: loss: 0.0000019
[Epoch 109; Iter   414/ 1097] train: loss: 0.0003788
[Epoch 109; Iter   444/ 1097] train: loss: 0.0003389
[Epoch 109; Iter   474/ 1097] train: loss: 0.0010497
[Epoch 109; Iter   504/ 1097] train: loss: 0.0026800
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000011
[Epoch 109; Iter   564/ 1097] train: loss: 0.0007035
[Epoch 109; Iter   594/ 1097] train: loss: 0.0000080
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000106
[Epoch 109; Iter   654/ 1097] train: loss: 0.0008331
[Epoch 109; Iter   684/ 1097] train: loss: 0.0003672
[Epoch 105; Iter   722/ 1097] train: loss: 0.0006292
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000096
[Epoch 105; Iter   782/ 1097] train: loss: 0.0000716
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000903
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000106
[Epoch 105; Iter   872/ 1097] train: loss: 0.0000043
[Epoch 105; Iter   902/ 1097] train: loss: 0.0003034
[Epoch 105; Iter   932/ 1097] train: loss: 0.0022706
[Epoch 105; Iter   962/ 1097] train: loss: 0.0004548
[Epoch 105; Iter   992/ 1097] train: loss: 0.0005538
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000178
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0000728
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0001231
[Epoch 105] ogbg-molhiv: 0.705752 val loss: 1.623941
[Epoch 105] ogbg-molhiv: 0.700705 test loss: 0.724879
[Epoch 106; Iter    15/ 1097] train: loss: 0.0000124
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000063
[Epoch 106; Iter    75/ 1097] train: loss: 0.0003540
[Epoch 106; Iter   105/ 1097] train: loss: 0.0013702
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000133
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000150
[Epoch 106; Iter   195/ 1097] train: loss: 0.0005815
[Epoch 106; Iter   225/ 1097] train: loss: 0.0001435
[Epoch 106; Iter   255/ 1097] train: loss: 0.0004127
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000078
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000036
[Epoch 106; Iter   345/ 1097] train: loss: 0.0222376
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000732
[Epoch 106; Iter   405/ 1097] train: loss: 0.0004214
[Epoch 106; Iter   435/ 1097] train: loss: 0.0001152
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000022
[Epoch 106; Iter   495/ 1097] train: loss: 0.0007291
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000763
[Epoch 106; Iter   555/ 1097] train: loss: 0.0001487
[Epoch 106; Iter   585/ 1097] train: loss: 0.0000561
[Epoch 106; Iter   615/ 1097] train: loss: 0.0000016
[Epoch 106; Iter   645/ 1097] train: loss: 0.0000250
[Epoch 106; Iter   675/ 1097] train: loss: 0.0096850
[Epoch 106; Iter   705/ 1097] train: loss: 0.0012731
[Epoch 106; Iter   735/ 1097] train: loss: 0.0116567
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000508
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000390
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000192
[Epoch 106; Iter   855/ 1097] train: loss: 0.0001606
[Epoch 106; Iter   885/ 1097] train: loss: 0.0002578
[Epoch 106; Iter   915/ 1097] train: loss: 0.0001918
[Epoch 106; Iter   945/ 1097] train: loss: 0.0000117
[Epoch 106; Iter   975/ 1097] train: loss: 0.0000051
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000876
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0003365
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000022
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0444834
[Epoch 106] ogbg-molhiv: 0.697690 val loss: 2.022783
[Epoch 106] ogbg-molhiv: 0.678974 test loss: 1.439109
[Epoch 107; Iter    28/ 1097] train: loss: 0.0000067
[Epoch 107; Iter    58/ 1097] train: loss: 0.0001054
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000186
[Epoch 107; Iter   118/ 1097] train: loss: 0.0000087
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000686
[Epoch 107; Iter   178/ 1097] train: loss: 0.0008690
[Epoch 107; Iter   208/ 1097] train: loss: 0.0754115
[Epoch 107; Iter   238/ 1097] train: loss: 0.1311530
[Epoch 107; Iter   268/ 1097] train: loss: 0.0001427
[Epoch 107; Iter   298/ 1097] train: loss: 0.0000062
[Epoch 107; Iter   328/ 1097] train: loss: 0.0006768
[Epoch 107; Iter   358/ 1097] train: loss: 0.0002955
[Epoch 107; Iter   388/ 1097] train: loss: 0.0001647
[Epoch 107; Iter   418/ 1097] train: loss: 0.0087685
[Epoch 107; Iter   448/ 1097] train: loss: 0.0000014
[Epoch 107; Iter   478/ 1097] train: loss: 0.0001496
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000919
[Epoch 107; Iter   538/ 1097] train: loss: 0.0003300
[Epoch 107; Iter   568/ 1097] train: loss: 0.0009821
[Epoch 107; Iter   598/ 1097] train: loss: 0.0008472
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000763
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000110
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000202
[Epoch 107; Iter   718/ 1097] train: loss: 0.0002462
[Epoch 107; Iter   748/ 1097] train: loss: 0.0001068
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000062
[Epoch 107; Iter   808/ 1097] train: loss: 0.0009879
[Epoch 107; Iter   838/ 1097] train: loss: 0.0000003
[Epoch 107; Iter   868/ 1097] train: loss: 0.0002050
[Epoch 107; Iter   898/ 1097] train: loss: 0.0001323
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000767
[Epoch 107; Iter   958/ 1097] train: loss: 0.0002294
[Epoch 107; Iter   988/ 1097] train: loss: 0.0000759
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0005338
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0308161
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000299
[Epoch 107] ogbg-molhiv: 0.695066 val loss: 1.366513
[Epoch 107] ogbg-molhiv: 0.690877 test loss: 1.085208
[Epoch 108; Iter    11/ 1097] train: loss: 0.0002496
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000496
[Epoch 108; Iter    71/ 1097] train: loss: 0.0004919
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000223
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000862
[Epoch 108; Iter   161/ 1097] train: loss: 0.0003045
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000011
[Epoch 108; Iter   221/ 1097] train: loss: 0.0308224
[Epoch 108; Iter   251/ 1097] train: loss: 0.0007917
[Epoch 108; Iter   281/ 1097] train: loss: 0.0000962
[Epoch 108; Iter   311/ 1097] train: loss: 0.0000193
[Epoch 108; Iter   341/ 1097] train: loss: 0.0000071
[Epoch 108; Iter   371/ 1097] train: loss: 0.0000806
[Epoch 108; Iter   401/ 1097] train: loss: 0.0013899
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000168
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000110
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000020
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000261
[Epoch 108; Iter   551/ 1097] train: loss: 0.0001647
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000075
[Epoch 108; Iter   611/ 1097] train: loss: 0.0003931
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000172
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000147
[Epoch 108; Iter   701/ 1097] train: loss: 0.0167799
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000498
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000005
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000041
[Epoch 108; Iter   821/ 1097] train: loss: 0.0002731
[Epoch 108; Iter   851/ 1097] train: loss: 0.0137920
[Epoch 108; Iter   881/ 1097] train: loss: 0.0001032
[Epoch 108; Iter   911/ 1097] train: loss: 0.0019754
[Epoch 108; Iter   941/ 1097] train: loss: 0.0102227
[Epoch 108; Iter   971/ 1097] train: loss: 0.0002812
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0184423
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0008361
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0001426
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000432
[Epoch 108] ogbg-molhiv: 0.703235 val loss: 1.877771
[Epoch 108] ogbg-molhiv: 0.672948 test loss: 1.101842
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000372
[Epoch 109; Iter    54/ 1097] train: loss: 0.0001846
[Epoch 109; Iter    84/ 1097] train: loss: 0.0002189
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000195
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000156
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000030
[Epoch 109; Iter   204/ 1097] train: loss: 0.0014830
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000540
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000695
[Epoch 109; Iter   294/ 1097] train: loss: 0.0000038
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000220
[Epoch 109; Iter   354/ 1097] train: loss: 0.0000270
[Epoch 109; Iter   384/ 1097] train: loss: 0.0024873
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000062
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000451
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000734
[Epoch 109; Iter   504/ 1097] train: loss: 0.0006630
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000545
[Epoch 109; Iter   564/ 1097] train: loss: 0.0157746
[Epoch 109; Iter   594/ 1097] train: loss: 0.0004759
[Epoch 109; Iter   624/ 1097] train: loss: 0.0001175
[Epoch 109; Iter   654/ 1097] train: loss: 0.0007176
[Epoch 109; Iter   684/ 1097] train: loss: 0.0000060
[Epoch 105; Iter   722/ 1097] train: loss: 0.0005077
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000236
[Epoch 105; Iter   782/ 1097] train: loss: 0.0120422
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000205
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000007
[Epoch 105; Iter   872/ 1097] train: loss: 0.0000116
[Epoch 105; Iter   902/ 1097] train: loss: 0.0002963
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000301
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000516
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000082
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0001056
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0183562
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000220
[Epoch 105] ogbg-molhiv: 0.749550 val loss: 0.256292
[Epoch 105] ogbg-molhiv: 0.720224 test loss: 0.410144
[Epoch 106; Iter    15/ 1097] train: loss: 0.0000133
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000004
[Epoch 106; Iter    75/ 1097] train: loss: 0.0000585
[Epoch 106; Iter   105/ 1097] train: loss: 0.0000372
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000276
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000071
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000052
[Epoch 106; Iter   225/ 1097] train: loss: 0.0000061
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000008
[Epoch 106; Iter   285/ 1097] train: loss: 0.0029026
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000979
[Epoch 106; Iter   345/ 1097] train: loss: 0.0003593
[Epoch 106; Iter   375/ 1097] train: loss: 0.0033079
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000082
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000076
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000645
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000079
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000241
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000037
[Epoch 106; Iter   585/ 1097] train: loss: 0.0001314
[Epoch 106; Iter   615/ 1097] train: loss: 0.0000053
[Epoch 106; Iter   645/ 1097] train: loss: 0.0000104
[Epoch 106; Iter   675/ 1097] train: loss: 0.0000592
[Epoch 106; Iter   705/ 1097] train: loss: 0.0001064
[Epoch 106; Iter   735/ 1097] train: loss: 0.0000046
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000339
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000038
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000617
[Epoch 106; Iter   855/ 1097] train: loss: 0.0001598
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000041
[Epoch 106; Iter   915/ 1097] train: loss: 0.0000053
[Epoch 106; Iter   945/ 1097] train: loss: 0.0000224
[Epoch 106; Iter   975/ 1097] train: loss: 0.0018695
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000003
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0001166
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000257
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000037
[Epoch 106] ogbg-molhiv: 0.762171 val loss: 0.264953
[Epoch 106] ogbg-molhiv: 0.721462 test loss: 0.408650
[Epoch 107; Iter    28/ 1097] train: loss: 0.0000475
[Epoch 107; Iter    58/ 1097] train: loss: 0.0003061
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000221
[Epoch 107; Iter   118/ 1097] train: loss: 0.0021745
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000078
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000005
[Epoch 107; Iter   208/ 1097] train: loss: 0.1018196
[Epoch 107; Iter   238/ 1097] train: loss: 0.0000920
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000008
[Epoch 107; Iter   298/ 1097] train: loss: 0.0008761
[Epoch 107; Iter   328/ 1097] train: loss: 0.0000097
[Epoch 107; Iter   358/ 1097] train: loss: 0.0000078
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000088
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000057
[Epoch 107; Iter   448/ 1097] train: loss: 0.0000142
[Epoch 107; Iter   478/ 1097] train: loss: 0.0000026
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000069
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000180
[Epoch 107; Iter   568/ 1097] train: loss: 0.0013531
[Epoch 107; Iter   598/ 1097] train: loss: 0.0004597
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000005
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000104
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000013
[Epoch 107; Iter   718/ 1097] train: loss: 0.0000020
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000067
[Epoch 107; Iter   778/ 1097] train: loss: 0.0001393
[Epoch 107; Iter   808/ 1097] train: loss: 0.0000323
[Epoch 107; Iter   838/ 1097] train: loss: 0.0024978
[Epoch 107; Iter   868/ 1097] train: loss: 0.0003502
[Epoch 107; Iter   898/ 1097] train: loss: 0.0000025
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000031
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000635
[Epoch 107; Iter   988/ 1097] train: loss: 0.0001864
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0003651
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0042145
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000520
[Epoch 107] ogbg-molhiv: 0.775138 val loss: 0.256208
[Epoch 107] ogbg-molhiv: 0.718979 test loss: 0.409959
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000193
[Epoch 108; Iter    41/ 1097] train: loss: 0.0001897
[Epoch 108; Iter    71/ 1097] train: loss: 0.0002340
[Epoch 108; Iter   101/ 1097] train: loss: 0.0029892
[Epoch 108; Iter   131/ 1097] train: loss: 0.0007149
[Epoch 108; Iter   161/ 1097] train: loss: 0.0053153
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000002
[Epoch 108; Iter   221/ 1097] train: loss: 0.0000023
[Epoch 108; Iter   251/ 1097] train: loss: 0.0054766
[Epoch 108; Iter   281/ 1097] train: loss: 0.0005992
[Epoch 108; Iter   311/ 1097] train: loss: 0.0000022
[Epoch 108; Iter   341/ 1097] train: loss: 0.0000129
[Epoch 108; Iter   371/ 1097] train: loss: 0.0011628
[Epoch 108; Iter   401/ 1097] train: loss: 0.0000497
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000007
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000013
[Epoch 108; Iter   491/ 1097] train: loss: 0.0003356
[Epoch 108; Iter   521/ 1097] train: loss: 0.0002460
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000118
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000277
[Epoch 108; Iter   611/ 1097] train: loss: 0.0000060
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000113
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000027
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000781
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000035
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000015
[Epoch 108; Iter   791/ 1097] train: loss: 0.0016331
[Epoch 108; Iter   821/ 1097] train: loss: 0.0005079
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000086
[Epoch 108; Iter   881/ 1097] train: loss: 0.0001476
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000183
[Epoch 108; Iter   941/ 1097] train: loss: 0.0002539
[Epoch 108; Iter   971/ 1097] train: loss: 0.0000315
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000587
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000224
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0000185
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000321
[Epoch 108] ogbg-molhiv: 0.772294 val loss: 0.272655
[Epoch 108] ogbg-molhiv: 0.720087 test loss: 0.417695
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000119
[Epoch 109; Iter    54/ 1097] train: loss: 0.0000457
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000770
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000324
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000092
[Epoch 109; Iter   174/ 1097] train: loss: 0.0003071
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000075
[Epoch 109; Iter   234/ 1097] train: loss: 0.0001531
[Epoch 109; Iter   264/ 1097] train: loss: 0.0005448
[Epoch 109; Iter   294/ 1097] train: loss: 0.0000241
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000019
[Epoch 109; Iter   354/ 1097] train: loss: 0.0000046
[Epoch 109; Iter   384/ 1097] train: loss: 0.0000202
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000029
[Epoch 109; Iter   444/ 1097] train: loss: 0.0014180
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000038
[Epoch 109; Iter   504/ 1097] train: loss: 0.0001747
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000025
[Epoch 109; Iter   564/ 1097] train: loss: 0.0000421
[Epoch 109; Iter   594/ 1097] train: loss: 0.0006420
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000200
[Epoch 109; Iter   654/ 1097] train: loss: 0.0000846
[Epoch 109; Iter   684/ 1097] train: loss: 0.0000064
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000152
[Epoch 105; Iter   752/ 1097] train: loss: 0.0013580
[Epoch 105; Iter   782/ 1097] train: loss: 0.0000603
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000162
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000063
[Epoch 105; Iter   872/ 1097] train: loss: 0.0003342
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000525
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000758
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000841
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000618
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000397
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0001800
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000656
[Epoch 105] ogbg-molhiv: 0.758668 val loss: 0.410502
[Epoch 105] ogbg-molhiv: 0.747036 test loss: 0.400576
[Epoch 106; Iter    15/ 1097] train: loss: 0.0000017
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000555
[Epoch 106; Iter    75/ 1097] train: loss: 0.0000058
[Epoch 106; Iter   105/ 1097] train: loss: 0.0000419
[Epoch 106; Iter   135/ 1097] train: loss: 0.0003764
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000375
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000291
[Epoch 106; Iter   225/ 1097] train: loss: 0.0000612
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000048
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000747
[Epoch 106; Iter   315/ 1097] train: loss: 0.0026418
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000022
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000063
[Epoch 106; Iter   405/ 1097] train: loss: 0.0016151
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000223
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000140
[Epoch 106; Iter   495/ 1097] train: loss: 0.0005722
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000935
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000043
[Epoch 106; Iter   585/ 1097] train: loss: 0.0000185
[Epoch 106; Iter   615/ 1097] train: loss: 0.0000117
[Epoch 106; Iter   645/ 1097] train: loss: 0.0000118
[Epoch 106; Iter   675/ 1097] train: loss: 0.0008838
[Epoch 106; Iter   705/ 1097] train: loss: 0.0001897
[Epoch 106; Iter   735/ 1097] train: loss: 0.0000099
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000039
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000073
[Epoch 106; Iter   825/ 1097] train: loss: 0.0001107
[Epoch 106; Iter   855/ 1097] train: loss: 0.0000004
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000771
[Epoch 106; Iter   915/ 1097] train: loss: 0.0001230
[Epoch 106; Iter   945/ 1097] train: loss: 0.0002999
[Epoch 106; Iter   975/ 1097] train: loss: 0.0001212
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000045
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0000088
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0002144
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000050
[Epoch 106] ogbg-molhiv: 0.763292 val loss: 0.418116
[Epoch 106] ogbg-molhiv: 0.743887 test loss: 0.405230
[Epoch 107; Iter    28/ 1097] train: loss: 0.0002710
[Epoch 107; Iter    58/ 1097] train: loss: 0.0000176
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000076
[Epoch 107; Iter   118/ 1097] train: loss: 0.0023474
[Epoch 107; Iter   148/ 1097] train: loss: 0.0005752
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000046
[Epoch 107; Iter   208/ 1097] train: loss: 0.0001972
[Epoch 107; Iter   238/ 1097] train: loss: 0.0000192
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000108
[Epoch 107; Iter   298/ 1097] train: loss: 0.0000051
[Epoch 107; Iter   328/ 1097] train: loss: 0.0001976
[Epoch 107; Iter   358/ 1097] train: loss: 0.0000164
[Epoch 107; Iter   388/ 1097] train: loss: 0.0008462
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000549
[Epoch 107; Iter   448/ 1097] train: loss: 0.0035933
[Epoch 107; Iter   478/ 1097] train: loss: 0.0071324
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000257
[Epoch 107; Iter   538/ 1097] train: loss: 0.0002791
[Epoch 107; Iter   568/ 1097] train: loss: 0.0042055
[Epoch 107; Iter   598/ 1097] train: loss: 0.0000012
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000861
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000264
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000134
[Epoch 107; Iter   718/ 1097] train: loss: 0.0001607
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000011
[Epoch 107; Iter   778/ 1097] train: loss: 0.0001393
[Epoch 107; Iter   808/ 1097] train: loss: 0.0001041
[Epoch 107; Iter   838/ 1097] train: loss: 0.0000718
[Epoch 107; Iter   868/ 1097] train: loss: 0.0003369
[Epoch 107; Iter   898/ 1097] train: loss: 0.0003327
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000689
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000093
[Epoch 107; Iter   988/ 1097] train: loss: 0.0001764
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0020601
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0000378
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0061504
[Epoch 107] ogbg-molhiv: 0.776550 val loss: 0.410482
[Epoch 107] ogbg-molhiv: 0.761482 test loss: 0.384480
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000090
[Epoch 108; Iter    41/ 1097] train: loss: 0.0020586
[Epoch 108; Iter    71/ 1097] train: loss: 0.0000139
[Epoch 108; Iter   101/ 1097] train: loss: 0.0007107
[Epoch 108; Iter   131/ 1097] train: loss: 0.0009083
[Epoch 108; Iter   161/ 1097] train: loss: 0.0716501
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000017
[Epoch 108; Iter   221/ 1097] train: loss: 0.0002659
[Epoch 108; Iter   251/ 1097] train: loss: 0.0000009
[Epoch 108; Iter   281/ 1097] train: loss: 0.0003224
[Epoch 108; Iter   311/ 1097] train: loss: 0.0000384
[Epoch 108; Iter   341/ 1097] train: loss: 0.0000040
[Epoch 108; Iter   371/ 1097] train: loss: 0.0000302
[Epoch 108; Iter   401/ 1097] train: loss: 0.0002636
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000066
[Epoch 108; Iter   461/ 1097] train: loss: 0.0002774
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000002
[Epoch 108; Iter   521/ 1097] train: loss: 0.0004193
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000118
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000042
[Epoch 108; Iter   611/ 1097] train: loss: 0.0000376
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000663
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000046
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000409
[Epoch 108; Iter   731/ 1097] train: loss: 0.0001388
[Epoch 108; Iter   761/ 1097] train: loss: 0.0001449
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000408
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000529
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000088
[Epoch 108; Iter   881/ 1097] train: loss: 0.0000423
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000860
[Epoch 108; Iter   941/ 1097] train: loss: 0.0000023
[Epoch 108; Iter   971/ 1097] train: loss: 0.0002083
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000004
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000499
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0000142
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000888
[Epoch 108] ogbg-molhiv: 0.763632 val loss: 0.412601
[Epoch 108] ogbg-molhiv: 0.749557 test loss: 0.395636
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000186
[Epoch 109; Iter    54/ 1097] train: loss: 0.0011510
[Epoch 109; Iter    84/ 1097] train: loss: 0.0001622
[Epoch 109; Iter   114/ 1097] train: loss: 0.0002571
[Epoch 109; Iter   144/ 1097] train: loss: 0.0461675
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000069
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000096
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000432
[Epoch 109; Iter   264/ 1097] train: loss: 0.0001923
[Epoch 109; Iter   294/ 1097] train: loss: 0.0425642
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000113
[Epoch 109; Iter   354/ 1097] train: loss: 0.0002295
[Epoch 109; Iter   384/ 1097] train: loss: 0.0036349
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000311
[Epoch 109; Iter   444/ 1097] train: loss: 0.0003632
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000068
[Epoch 109; Iter   504/ 1097] train: loss: 0.0000155
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000333
[Epoch 109; Iter   564/ 1097] train: loss: 0.0000139
[Epoch 109; Iter   594/ 1097] train: loss: 0.0003165
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000114
[Epoch 109; Iter   654/ 1097] train: loss: 0.0000053
[Epoch 109; Iter   684/ 1097] train: loss: 0.0026165
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000011
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000177
[Epoch 105; Iter   782/ 1097] train: loss: 0.0000097
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000247
[Epoch 105; Iter   842/ 1097] train: loss: 0.0100732
[Epoch 105; Iter   872/ 1097] train: loss: 0.0004036
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000633
[Epoch 105; Iter   932/ 1097] train: loss: 0.0002487
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000283
[Epoch 105; Iter   992/ 1097] train: loss: 0.0005201
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000754
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0000419
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0004371
[Epoch 105] ogbg-molhiv: 0.784324 val loss: 0.334828
[Epoch 105] ogbg-molhiv: 0.727652 test loss: 0.410847
[Epoch 106; Iter    15/ 1097] train: loss: 0.0001361
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000044
[Epoch 106; Iter    75/ 1097] train: loss: 0.0006571
[Epoch 106; Iter   105/ 1097] train: loss: 0.0002813
[Epoch 106; Iter   135/ 1097] train: loss: 0.0033984
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000085
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000112
[Epoch 106; Iter   225/ 1097] train: loss: 0.0015824
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000322
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000107
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000162
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000866
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000009
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000054
[Epoch 106; Iter   435/ 1097] train: loss: 0.0013473
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000256
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000213
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000038
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000510
[Epoch 106; Iter   585/ 1097] train: loss: 0.0000327
[Epoch 106; Iter   615/ 1097] train: loss: 0.0004877
[Epoch 106; Iter   645/ 1097] train: loss: 0.0000412
[Epoch 106; Iter   675/ 1097] train: loss: 0.0005878
[Epoch 106; Iter   705/ 1097] train: loss: 0.0000026
[Epoch 106; Iter   735/ 1097] train: loss: 0.0000918
[Epoch 106; Iter   765/ 1097] train: loss: 0.0002431
[Epoch 106; Iter   795/ 1097] train: loss: 0.0002190
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000151
[Epoch 106; Iter   855/ 1097] train: loss: 0.0008015
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000407
[Epoch 106; Iter   915/ 1097] train: loss: 0.0001299
[Epoch 106; Iter   945/ 1097] train: loss: 0.0003602
[Epoch 106; Iter   975/ 1097] train: loss: 0.0056872
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000322
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0038519
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000124
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000026
[Epoch 106] ogbg-molhiv: 0.789367 val loss: 0.294168
[Epoch 106] ogbg-molhiv: 0.724749 test loss: 0.417885
[Epoch 107; Iter    28/ 1097] train: loss: 0.0000245
[Epoch 107; Iter    58/ 1097] train: loss: 0.0000032
[Epoch 107; Iter    88/ 1097] train: loss: 0.0001509
[Epoch 107; Iter   118/ 1097] train: loss: 0.0045248
[Epoch 107; Iter   148/ 1097] train: loss: 0.0002686
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000173
[Epoch 107; Iter   208/ 1097] train: loss: 0.0000609
[Epoch 107; Iter   238/ 1097] train: loss: 0.0000803
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000397
[Epoch 107; Iter   298/ 1097] train: loss: 0.0002586
[Epoch 107; Iter   328/ 1097] train: loss: 0.0000544
[Epoch 107; Iter   358/ 1097] train: loss: 0.0001868
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000076
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000037
[Epoch 107; Iter   448/ 1097] train: loss: 0.0010511
[Epoch 107; Iter   478/ 1097] train: loss: 0.0000166
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000176
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000142
[Epoch 107; Iter   568/ 1097] train: loss: 0.0000167
[Epoch 107; Iter   598/ 1097] train: loss: 0.0000331
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000275
[Epoch 107; Iter   658/ 1097] train: loss: 0.0001157
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000088
[Epoch 107; Iter   718/ 1097] train: loss: 0.0000105
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000043
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000142
[Epoch 107; Iter   808/ 1097] train: loss: 0.0000033
[Epoch 107; Iter   838/ 1097] train: loss: 0.0002255
[Epoch 107; Iter   868/ 1097] train: loss: 0.0000063
[Epoch 107; Iter   898/ 1097] train: loss: 0.0000283
[Epoch 107; Iter   928/ 1097] train: loss: 0.0001617
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000676
[Epoch 107; Iter   988/ 1097] train: loss: 0.0000745
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000089
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0000437
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000006
[Epoch 107] ogbg-molhiv: 0.784692 val loss: 0.302277
[Epoch 107] ogbg-molhiv: 0.735690 test loss: 0.424025
[Epoch 108; Iter    11/ 1097] train: loss: 0.0007201
[Epoch 108; Iter    41/ 1097] train: loss: 0.0011197
[Epoch 108; Iter    71/ 1097] train: loss: 0.0003292
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000155
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000093
[Epoch 108; Iter   161/ 1097] train: loss: 0.0000469
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000387
[Epoch 108; Iter   221/ 1097] train: loss: 0.0017124
[Epoch 108; Iter   251/ 1097] train: loss: 0.0000055
[Epoch 108; Iter   281/ 1097] train: loss: 0.0001589
[Epoch 108; Iter   311/ 1097] train: loss: 0.0001632
[Epoch 108; Iter   341/ 1097] train: loss: 0.0000068
[Epoch 108; Iter   371/ 1097] train: loss: 0.0001741
[Epoch 108; Iter   401/ 1097] train: loss: 0.0015768
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000638
[Epoch 108; Iter   461/ 1097] train: loss: 0.0007857
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000114
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000092
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000254
[Epoch 108; Iter   581/ 1097] train: loss: 0.0003726
[Epoch 108; Iter   611/ 1097] train: loss: 0.0000037
[Epoch 108; Iter   641/ 1097] train: loss: 0.0001911
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000153
[Epoch 108; Iter   701/ 1097] train: loss: 0.0001249
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000086
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000178
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000053
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000019
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000011
[Epoch 108; Iter   881/ 1097] train: loss: 0.0000058
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000387
[Epoch 108; Iter   941/ 1097] train: loss: 0.0007247
[Epoch 108; Iter   971/ 1097] train: loss: 0.0000570
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000100
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000349
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0001161
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000074
[Epoch 108] ogbg-molhiv: 0.780598 val loss: 0.289221
[Epoch 108] ogbg-molhiv: 0.734852 test loss: 0.405494
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000642
[Epoch 109; Iter    54/ 1097] train: loss: 0.0001465
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000229
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000148
[Epoch 109; Iter   144/ 1097] train: loss: 0.0001272
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000638
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000137
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000389
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000308
[Epoch 109; Iter   294/ 1097] train: loss: 0.0003471
[Epoch 109; Iter   324/ 1097] train: loss: 0.0001613
[Epoch 109; Iter   354/ 1097] train: loss: 0.0000501
[Epoch 109; Iter   384/ 1097] train: loss: 0.0021967
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000793
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000029
[Epoch 109; Iter   474/ 1097] train: loss: 0.0001357
[Epoch 109; Iter   504/ 1097] train: loss: 0.0000277
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000060
[Epoch 109; Iter   564/ 1097] train: loss: 0.0346756
[Epoch 109; Iter   594/ 1097] train: loss: 0.0000209
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000059
[Epoch 109; Iter   654/ 1097] train: loss: 0.0002055
[Epoch 109; Iter   684/ 1097] train: loss: 0.0014262
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000091
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000038
[Epoch 105; Iter   782/ 1097] train: loss: 0.0002906
[Epoch 105; Iter   812/ 1097] train: loss: 0.0001210
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000012
[Epoch 105; Iter   872/ 1097] train: loss: 0.0000567
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000900
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000180
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000030
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000355
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000264
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0000060
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0002742
[Epoch 105] ogbg-molhiv: 0.783458 val loss: 0.466736
[Epoch 105] ogbg-molhiv: 0.788007 test loss: 0.375533
[Epoch 106; Iter    15/ 1097] train: loss: 0.0019977
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000227
[Epoch 106; Iter    75/ 1097] train: loss: 0.0017707
[Epoch 106; Iter   105/ 1097] train: loss: 0.0215363
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000575
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000361
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000114
[Epoch 106; Iter   225/ 1097] train: loss: 0.0000092
[Epoch 106; Iter   255/ 1097] train: loss: 0.0016444
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000335
[Epoch 106; Iter   315/ 1097] train: loss: 0.0001397
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000487
[Epoch 106; Iter   375/ 1097] train: loss: 0.0272870
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000162
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000178
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000033
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000665
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000053
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000026
[Epoch 106; Iter   585/ 1097] train: loss: 0.0006494
[Epoch 106; Iter   615/ 1097] train: loss: 0.0006410
[Epoch 106; Iter   645/ 1097] train: loss: 0.0924516
[Epoch 106; Iter   675/ 1097] train: loss: 0.0000504
[Epoch 106; Iter   705/ 1097] train: loss: 0.0040577
[Epoch 106; Iter   735/ 1097] train: loss: 0.0008358
[Epoch 106; Iter   765/ 1097] train: loss: 0.0002510
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000060
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000668
[Epoch 106; Iter   855/ 1097] train: loss: 0.0001220
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000347
[Epoch 106; Iter   915/ 1097] train: loss: 0.0026155
[Epoch 106; Iter   945/ 1097] train: loss: 0.0000014
[Epoch 106; Iter   975/ 1097] train: loss: 0.0000224
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0001948
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0001401
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000915
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0001127
[Epoch 106] ogbg-molhiv: 0.789765 val loss: 0.438579
[Epoch 106] ogbg-molhiv: 0.793971 test loss: 0.355868
[Epoch 107; Iter    28/ 1097] train: loss: 0.0003406
[Epoch 107; Iter    58/ 1097] train: loss: 0.0000388
[Epoch 107; Iter    88/ 1097] train: loss: 0.0003007
[Epoch 107; Iter   118/ 1097] train: loss: 0.0000107
[Epoch 107; Iter   148/ 1097] train: loss: 0.0002479
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000407
[Epoch 107; Iter   208/ 1097] train: loss: 0.0000628
[Epoch 107; Iter   238/ 1097] train: loss: 0.0000027
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000166
[Epoch 107; Iter   298/ 1097] train: loss: 0.0008440
[Epoch 107; Iter   328/ 1097] train: loss: 0.0000052
[Epoch 107; Iter   358/ 1097] train: loss: 0.0000497
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000102
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000345
[Epoch 107; Iter   448/ 1097] train: loss: 0.0005471
[Epoch 107; Iter   478/ 1097] train: loss: 0.0001807
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000078
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000122
[Epoch 107; Iter   568/ 1097] train: loss: 0.0001804
[Epoch 107; Iter   598/ 1097] train: loss: 0.0000307
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000027
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000053
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000006
[Epoch 107; Iter   718/ 1097] train: loss: 0.0012112
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000246
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000189
[Epoch 107; Iter   808/ 1097] train: loss: 0.0000024
[Epoch 107; Iter   838/ 1097] train: loss: 0.0000533
[Epoch 107; Iter   868/ 1097] train: loss: 0.0002509
[Epoch 107; Iter   898/ 1097] train: loss: 0.0012023
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000037
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000021
[Epoch 107; Iter   988/ 1097] train: loss: 0.0002694
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000844
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0009210
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000818
[Epoch 107] ogbg-molhiv: 0.802255 val loss: 0.362834
[Epoch 107] ogbg-molhiv: 0.800720 test loss: 0.355609
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000063
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000026
[Epoch 108; Iter    71/ 1097] train: loss: 0.0000482
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000014
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000176
[Epoch 108; Iter   161/ 1097] train: loss: 0.0004531
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000321
[Epoch 108; Iter   221/ 1097] train: loss: 0.0001402
[Epoch 108; Iter   251/ 1097] train: loss: 0.0113430
[Epoch 108; Iter   281/ 1097] train: loss: 0.0000001
[Epoch 108; Iter   311/ 1097] train: loss: 0.0008097
[Epoch 108; Iter   341/ 1097] train: loss: 0.0169672
[Epoch 108; Iter   371/ 1097] train: loss: 0.0000374
[Epoch 108; Iter   401/ 1097] train: loss: 0.0000270
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000088
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000089
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000010
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000054
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000117
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000343
[Epoch 108; Iter   611/ 1097] train: loss: 0.0000023
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000169
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000106
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000934
[Epoch 108; Iter   731/ 1097] train: loss: 0.0030645
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000055
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000129
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000021
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000049
[Epoch 108; Iter   881/ 1097] train: loss: 0.0000017
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000038
[Epoch 108; Iter   941/ 1097] train: loss: 0.0000124
[Epoch 108; Iter   971/ 1097] train: loss: 0.0000025
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000081
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000041
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0006701
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000046
[Epoch 108] ogbg-molhiv: 0.790246 val loss: 0.257480
[Epoch 108] ogbg-molhiv: 0.785940 test loss: 0.346738
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000423
[Epoch 109; Iter    54/ 1097] train: loss: 0.0014520
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000206
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000060
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000080
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000038
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000279
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000261
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000083
[Epoch 109; Iter   294/ 1097] train: loss: 0.0000138
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000039
[Epoch 109; Iter   354/ 1097] train: loss: 0.0000455
[Epoch 109; Iter   384/ 1097] train: loss: 0.0000134
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000003
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000028
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000041
[Epoch 109; Iter   504/ 1097] train: loss: 0.0000064
[Epoch 109; Iter   534/ 1097] train: loss: 0.0003458
[Epoch 109; Iter   564/ 1097] train: loss: 0.0002720
[Epoch 109; Iter   594/ 1097] train: loss: 0.0001401
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000161
[Epoch 109; Iter   654/ 1097] train: loss: 0.0005959
[Epoch 109; Iter   684/ 1097] train: loss: 0.0000833
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000220
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000048
[Epoch 105; Iter   782/ 1097] train: loss: 0.0000068
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000001
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000014
[Epoch 105; Iter   872/ 1097] train: loss: 0.0000018
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000024
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000079
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000014
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000340
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000101
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0000025
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000858
[Epoch 105] ogbg-molhiv: 0.690651 val loss: 10.395565
[Epoch 105] ogbg-molhiv: 0.596603 test loss: 10.815588
[Epoch 106; Iter    15/ 1097] train: loss: 0.0001385
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000048
[Epoch 106; Iter    75/ 1097] train: loss: 0.0000853
[Epoch 106; Iter   105/ 1097] train: loss: 0.0005990
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000035
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000292
[Epoch 106; Iter   195/ 1097] train: loss: 0.0003179
[Epoch 106; Iter   225/ 1097] train: loss: 0.0016777
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000721
[Epoch 106; Iter   285/ 1097] train: loss: 0.0001209
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000151
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000003
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000244
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000017
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000005
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000948
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000206
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000015
[Epoch 106; Iter   555/ 1097] train: loss: 0.0001229
[Epoch 106; Iter   585/ 1097] train: loss: 0.0000035
[Epoch 106; Iter   615/ 1097] train: loss: 0.0000018
[Epoch 106; Iter   645/ 1097] train: loss: 0.0000105
[Epoch 106; Iter   675/ 1097] train: loss: 0.0000021
[Epoch 106; Iter   705/ 1097] train: loss: 0.0000067
[Epoch 106; Iter   735/ 1097] train: loss: 0.0001594
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000026
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000213
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000051
[Epoch 106; Iter   855/ 1097] train: loss: 0.0000007
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000153
[Epoch 106; Iter   915/ 1097] train: loss: 0.0000118
[Epoch 106; Iter   945/ 1097] train: loss: 0.0003396
[Epoch 106; Iter   975/ 1097] train: loss: 0.0000051
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000028
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0000171
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000004
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0317604
[Epoch 106] ogbg-molhiv: 0.684925 val loss: 10.692822
[Epoch 106] ogbg-molhiv: 0.619657 test loss: 12.053252
[Epoch 107; Iter    28/ 1097] train: loss: 0.0001771
[Epoch 107; Iter    58/ 1097] train: loss: 0.0000171
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000094
[Epoch 107; Iter   118/ 1097] train: loss: 0.0000029
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000417
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000424
[Epoch 107; Iter   208/ 1097] train: loss: 0.0136846
[Epoch 107; Iter   238/ 1097] train: loss: 0.0002030
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000051
[Epoch 107; Iter   298/ 1097] train: loss: 0.0000027
[Epoch 107; Iter   328/ 1097] train: loss: 0.0000023
[Epoch 107; Iter   358/ 1097] train: loss: 0.0098315
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000018
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000049
[Epoch 107; Iter   448/ 1097] train: loss: 0.0000086
[Epoch 107; Iter   478/ 1097] train: loss: 0.0000011
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000008
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000046
[Epoch 107; Iter   568/ 1097] train: loss: 0.0027359
[Epoch 107; Iter   598/ 1097] train: loss: 0.0001561
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000058
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000024
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000273
[Epoch 107; Iter   718/ 1097] train: loss: 0.0000291
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000248
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000138
[Epoch 107; Iter   808/ 1097] train: loss: 0.0008866
[Epoch 107; Iter   838/ 1097] train: loss: 0.0000380
[Epoch 107; Iter   868/ 1097] train: loss: 0.0000229
[Epoch 107; Iter   898/ 1097] train: loss: 0.0000087
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000175
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000005
[Epoch 107; Iter   988/ 1097] train: loss: 0.0000031
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000876
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0000053
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000004
[Epoch 107] ogbg-molhiv: 0.707332 val loss: 6.471456
[Epoch 107] ogbg-molhiv: 0.620589 test loss: 6.955090
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000005
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000127
[Epoch 108; Iter    71/ 1097] train: loss: 0.0001873
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000114
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000019
[Epoch 108; Iter   161/ 1097] train: loss: 0.0000587
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000040
[Epoch 108; Iter   221/ 1097] train: loss: 0.0000106
[Epoch 108; Iter   251/ 1097] train: loss: 0.0131315
[Epoch 108; Iter   281/ 1097] train: loss: 0.0000264
[Epoch 108; Iter   311/ 1097] train: loss: 0.0000004
[Epoch 108; Iter   341/ 1097] train: loss: 0.0002571
[Epoch 108; Iter   371/ 1097] train: loss: 0.0001503
[Epoch 108; Iter   401/ 1097] train: loss: 0.0000246
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000026
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000323
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000033
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000002
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000035
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000014
[Epoch 108; Iter   611/ 1097] train: loss: 0.0001879
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000030
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000023
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000032
[Epoch 108; Iter   731/ 1097] train: loss: 0.0003115
[Epoch 108; Iter   761/ 1097] train: loss: 0.0001779
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000009
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000061
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000008
[Epoch 108; Iter   881/ 1097] train: loss: 0.0011275
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000002
[Epoch 108; Iter   941/ 1097] train: loss: 0.0007354
[Epoch 108; Iter   971/ 1097] train: loss: 0.0000403
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0001059
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000131
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0000052
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000693
[Epoch 108] ogbg-molhiv: 0.695485 val loss: 10.549978
[Epoch 108] ogbg-molhiv: 0.587346 test loss: 10.589501
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000036
[Epoch 109; Iter    54/ 1097] train: loss: 0.0001642
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000061
[Epoch 109; Iter   114/ 1097] train: loss: 0.0001349
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000014
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000118
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000008
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000009
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000137
[Epoch 109; Iter   294/ 1097] train: loss: 0.0000261
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000011
[Epoch 109; Iter   354/ 1097] train: loss: 0.0001055
[Epoch 109; Iter   384/ 1097] train: loss: 0.0000032
[Epoch 109; Iter   414/ 1097] train: loss: 0.0000007
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000124
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000020
[Epoch 109; Iter   504/ 1097] train: loss: 0.0000054
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000029
[Epoch 109; Iter   564/ 1097] train: loss: 0.0000034
[Epoch 109; Iter   594/ 1097] train: loss: 0.0000038
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000412
[Epoch 109; Iter   654/ 1097] train: loss: 0.0000303
[Epoch 109; Iter   684/ 1097] train: loss: 0.0000040
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000031
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000023
[Epoch 105; Iter   782/ 1097] train: loss: 0.0002116
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000004
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000190
[Epoch 105; Iter   872/ 1097] train: loss: 0.0129156
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000079
[Epoch 105; Iter   932/ 1097] train: loss: 0.0004144
[Epoch 105; Iter   962/ 1097] train: loss: 0.0000318
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000004
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0001540
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0001047
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000067
[Epoch 105] ogbg-molhiv: 0.766617 val loss: 2.166703
[Epoch 105] ogbg-molhiv: 0.712279 test loss: 3.767963
[Epoch 106; Iter    15/ 1097] train: loss: 0.0003331
[Epoch 106; Iter    45/ 1097] train: loss: 0.0178021
[Epoch 106; Iter    75/ 1097] train: loss: 0.0000177
[Epoch 106; Iter   105/ 1097] train: loss: 0.0000147
[Epoch 106; Iter   135/ 1097] train: loss: 0.0000492
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000227
[Epoch 106; Iter   195/ 1097] train: loss: 0.0000689
[Epoch 106; Iter   225/ 1097] train: loss: 0.0014494
[Epoch 106; Iter   255/ 1097] train: loss: 0.0006662
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000103
[Epoch 106; Iter   315/ 1097] train: loss: 0.0000598
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000953
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000031
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000493
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000025
[Epoch 106; Iter   465/ 1097] train: loss: 0.0000578
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000081
[Epoch 106; Iter   525/ 1097] train: loss: 0.0000010
[Epoch 106; Iter   555/ 1097] train: loss: 0.0000690
[Epoch 106; Iter   585/ 1097] train: loss: 0.0034374
[Epoch 106; Iter   615/ 1097] train: loss: 0.0000100
[Epoch 106; Iter   645/ 1097] train: loss: 0.0003830
[Epoch 106; Iter   675/ 1097] train: loss: 0.0002236
[Epoch 106; Iter   705/ 1097] train: loss: 0.0000644
[Epoch 106; Iter   735/ 1097] train: loss: 0.0070762
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000171
[Epoch 106; Iter   795/ 1097] train: loss: 0.0000193
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000044
[Epoch 106; Iter   855/ 1097] train: loss: 0.0000593
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000034
[Epoch 106; Iter   915/ 1097] train: loss: 0.0002442
[Epoch 106; Iter   945/ 1097] train: loss: 0.0000030
[Epoch 106; Iter   975/ 1097] train: loss: 0.0000005
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000069
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0000893
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0000016
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000568
[Epoch 106] ogbg-molhiv: 0.784759 val loss: 2.448080
[Epoch 106] ogbg-molhiv: 0.703148 test loss: 4.750594
[Epoch 107; Iter    28/ 1097] train: loss: 0.0000169
[Epoch 107; Iter    58/ 1097] train: loss: 0.0069865
[Epoch 107; Iter    88/ 1097] train: loss: 0.0005097
[Epoch 107; Iter   118/ 1097] train: loss: 0.0000053
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000369
[Epoch 107; Iter   178/ 1097] train: loss: 0.0007015
[Epoch 107; Iter   208/ 1097] train: loss: 0.0001614
[Epoch 107; Iter   238/ 1097] train: loss: 0.0000009
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000236
[Epoch 107; Iter   298/ 1097] train: loss: 0.0002476
[Epoch 107; Iter   328/ 1097] train: loss: 0.0000610
[Epoch 107; Iter   358/ 1097] train: loss: 0.0000006
[Epoch 107; Iter   388/ 1097] train: loss: 0.0007533
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000416
[Epoch 107; Iter   448/ 1097] train: loss: 0.0000124
[Epoch 107; Iter   478/ 1097] train: loss: 0.0008548
[Epoch 107; Iter   508/ 1097] train: loss: 0.0000021
[Epoch 107; Iter   538/ 1097] train: loss: 0.0000071
[Epoch 107; Iter   568/ 1097] train: loss: 0.0053222
[Epoch 107; Iter   598/ 1097] train: loss: 0.0000004
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000049
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000024
[Epoch 107; Iter   688/ 1097] train: loss: 0.0000343
[Epoch 107; Iter   718/ 1097] train: loss: 0.0056796
[Epoch 107; Iter   748/ 1097] train: loss: 0.0000146
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000803
[Epoch 107; Iter   808/ 1097] train: loss: 0.0018228
[Epoch 107; Iter   838/ 1097] train: loss: 0.0000085
[Epoch 107; Iter   868/ 1097] train: loss: 0.0000075
[Epoch 107; Iter   898/ 1097] train: loss: 0.0000172
[Epoch 107; Iter   928/ 1097] train: loss: 0.0000071
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000053
[Epoch 107; Iter   988/ 1097] train: loss: 0.0005654
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000445
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0494090
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000702
[Epoch 107] ogbg-molhiv: 0.766341 val loss: 7.798821
[Epoch 107] ogbg-molhiv: 0.676784 test loss: 8.332455
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000011
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000175
[Epoch 108; Iter    71/ 1097] train: loss: 0.0000423
[Epoch 108; Iter   101/ 1097] train: loss: 0.0000033
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000124
[Epoch 108; Iter   161/ 1097] train: loss: 0.0021217
[Epoch 108; Iter   191/ 1097] train: loss: 0.0000039
[Epoch 108; Iter   221/ 1097] train: loss: 0.0000786
[Epoch 108; Iter   251/ 1097] train: loss: 0.0000390
[Epoch 108; Iter   281/ 1097] train: loss: 0.0000029
[Epoch 108; Iter   311/ 1097] train: loss: 0.0003566
[Epoch 108; Iter   341/ 1097] train: loss: 0.0001523
[Epoch 108; Iter   371/ 1097] train: loss: 0.0000758
[Epoch 108; Iter   401/ 1097] train: loss: 0.0000110
[Epoch 108; Iter   431/ 1097] train: loss: 0.0000071
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000195
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000355
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000063
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000732
[Epoch 108; Iter   581/ 1097] train: loss: 0.0000143
[Epoch 108; Iter   611/ 1097] train: loss: 0.0000025
[Epoch 108; Iter   641/ 1097] train: loss: 0.0000453
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000016
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000615
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000094
[Epoch 108; Iter   761/ 1097] train: loss: 0.0007228
[Epoch 108; Iter   791/ 1097] train: loss: 0.0002848
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000073
[Epoch 108; Iter   851/ 1097] train: loss: 0.0000042
[Epoch 108; Iter   881/ 1097] train: loss: 0.0000285
[Epoch 108; Iter   911/ 1097] train: loss: 0.0000398
[Epoch 108; Iter   941/ 1097] train: loss: 0.0004591
[Epoch 108; Iter   971/ 1097] train: loss: 0.0000165
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000784
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0000416
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0006960
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0005099
[Epoch 108] ogbg-molhiv: 0.747749 val loss: 1.352938
[Epoch 108] ogbg-molhiv: 0.717233 test loss: 2.415551
[Epoch 109; Iter    24/ 1097] train: loss: 0.0005205
[Epoch 109; Iter    54/ 1097] train: loss: 0.0000143
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000817
[Epoch 109; Iter   114/ 1097] train: loss: 0.0000009
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000635
[Epoch 109; Iter   174/ 1097] train: loss: 0.0000007
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000008
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000016
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000033
[Epoch 109; Iter   294/ 1097] train: loss: 0.0000038
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000540
[Epoch 109; Iter   354/ 1097] train: loss: 0.0002176
[Epoch 109; Iter   384/ 1097] train: loss: 0.0000011
[Epoch 109; Iter   414/ 1097] train: loss: 0.0001818
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000661
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000006
[Epoch 109; Iter   504/ 1097] train: loss: 0.0000295
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000005
[Epoch 109; Iter   564/ 1097] train: loss: 0.0000699
[Epoch 109; Iter   594/ 1097] train: loss: 0.0000189
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000083
[Epoch 109; Iter   654/ 1097] train: loss: 0.0001167
[Epoch 109; Iter   684/ 1097] train: loss: 0.0000106
[Epoch 105; Iter   722/ 1097] train: loss: 0.0000858
[Epoch 105; Iter   752/ 1097] train: loss: 0.0000545
[Epoch 105; Iter   782/ 1097] train: loss: 0.0019196
[Epoch 105; Iter   812/ 1097] train: loss: 0.0000177
[Epoch 105; Iter   842/ 1097] train: loss: 0.0000104
[Epoch 105; Iter   872/ 1097] train: loss: 0.0003511
[Epoch 105; Iter   902/ 1097] train: loss: 0.0000013
[Epoch 105; Iter   932/ 1097] train: loss: 0.0000932
[Epoch 105; Iter   962/ 1097] train: loss: 0.0001246
[Epoch 105; Iter   992/ 1097] train: loss: 0.0000751
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0000228
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0058042
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0000361
[Epoch 105] ogbg-molhiv: 0.692081 val loss: 30.297227
[Epoch 105] ogbg-molhiv: 0.638684 test loss: 24.163894
[Epoch 106; Iter    15/ 1097] train: loss: 0.0005075
[Epoch 106; Iter    45/ 1097] train: loss: 0.0000974
[Epoch 106; Iter    75/ 1097] train: loss: 0.0049283
[Epoch 106; Iter   105/ 1097] train: loss: 0.0000747
[Epoch 106; Iter   135/ 1097] train: loss: 0.0001381
[Epoch 106; Iter   165/ 1097] train: loss: 0.0000471
[Epoch 106; Iter   195/ 1097] train: loss: 0.0005774
[Epoch 106; Iter   225/ 1097] train: loss: 0.0006045
[Epoch 106; Iter   255/ 1097] train: loss: 0.0000072
[Epoch 106; Iter   285/ 1097] train: loss: 0.0000026
[Epoch 106; Iter   315/ 1097] train: loss: 0.0002031
[Epoch 106; Iter   345/ 1097] train: loss: 0.0000014
[Epoch 106; Iter   375/ 1097] train: loss: 0.0000813
[Epoch 106; Iter   405/ 1097] train: loss: 0.0000233
[Epoch 106; Iter   435/ 1097] train: loss: 0.0000194
[Epoch 106; Iter   465/ 1097] train: loss: 0.0003088
[Epoch 106; Iter   495/ 1097] train: loss: 0.0000073
[Epoch 106; Iter   525/ 1097] train: loss: 0.0145133
[Epoch 106; Iter   555/ 1097] train: loss: 0.0001257
[Epoch 106; Iter   585/ 1097] train: loss: 0.0006931
[Epoch 106; Iter   615/ 1097] train: loss: 0.0010985
[Epoch 106; Iter   645/ 1097] train: loss: 0.0002508
[Epoch 106; Iter   675/ 1097] train: loss: 0.0001173
[Epoch 106; Iter   705/ 1097] train: loss: 0.0000161
[Epoch 106; Iter   735/ 1097] train: loss: 0.0005222
[Epoch 106; Iter   765/ 1097] train: loss: 0.0000503
[Epoch 106; Iter   795/ 1097] train: loss: 0.0001044
[Epoch 106; Iter   825/ 1097] train: loss: 0.0000042
[Epoch 106; Iter   855/ 1097] train: loss: 0.0310641
[Epoch 106; Iter   885/ 1097] train: loss: 0.0000544
[Epoch 106; Iter   915/ 1097] train: loss: 0.0043387
[Epoch 106; Iter   945/ 1097] train: loss: 0.0001955
[Epoch 106; Iter   975/ 1097] train: loss: 0.0001560
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0000201
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0001146
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0001088
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0000639
[Epoch 106] ogbg-molhiv: 0.696073 val loss: 45.488335
[Epoch 106] ogbg-molhiv: 0.638769 test loss: 33.887747
[Epoch 107; Iter    28/ 1097] train: loss: 0.0002221
[Epoch 107; Iter    58/ 1097] train: loss: 0.0000258
[Epoch 107; Iter    88/ 1097] train: loss: 0.0000286
[Epoch 107; Iter   118/ 1097] train: loss: 0.0000439
[Epoch 107; Iter   148/ 1097] train: loss: 0.0000080
[Epoch 107; Iter   178/ 1097] train: loss: 0.0000416
[Epoch 107; Iter   208/ 1097] train: loss: 0.0001268
[Epoch 107; Iter   238/ 1097] train: loss: 0.0024060
[Epoch 107; Iter   268/ 1097] train: loss: 0.0000357
[Epoch 107; Iter   298/ 1097] train: loss: 0.0002020
[Epoch 107; Iter   328/ 1097] train: loss: 0.0198823
[Epoch 107; Iter   358/ 1097] train: loss: 0.0008686
[Epoch 107; Iter   388/ 1097] train: loss: 0.0000649
[Epoch 107; Iter   418/ 1097] train: loss: 0.0000008
[Epoch 107; Iter   448/ 1097] train: loss: 0.0004137
[Epoch 107; Iter   478/ 1097] train: loss: 0.0000494
[Epoch 107; Iter   508/ 1097] train: loss: 0.0006347
[Epoch 107; Iter   538/ 1097] train: loss: 0.0003709
[Epoch 107; Iter   568/ 1097] train: loss: 0.0000420
[Epoch 107; Iter   598/ 1097] train: loss: 0.0001391
[Epoch 107; Iter   628/ 1097] train: loss: 0.0000803
[Epoch 107; Iter   658/ 1097] train: loss: 0.0000038
[Epoch 107; Iter   688/ 1097] train: loss: 0.0001882
[Epoch 107; Iter   718/ 1097] train: loss: 0.0000069
[Epoch 107; Iter   748/ 1097] train: loss: 0.0002377
[Epoch 107; Iter   778/ 1097] train: loss: 0.0000368
[Epoch 107; Iter   808/ 1097] train: loss: 0.0000056
[Epoch 107; Iter   838/ 1097] train: loss: 0.0029312
[Epoch 107; Iter   868/ 1097] train: loss: 0.0001242
[Epoch 107; Iter   898/ 1097] train: loss: 0.0131737
[Epoch 107; Iter   928/ 1097] train: loss: 0.0001132
[Epoch 107; Iter   958/ 1097] train: loss: 0.0000134
[Epoch 107; Iter   988/ 1097] train: loss: 0.0004722
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0000433
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0002167
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0000330
[Epoch 107] ogbg-molhiv: 0.707742 val loss: 44.015969
[Epoch 107] ogbg-molhiv: 0.629122 test loss: 33.893450
[Epoch 108; Iter    11/ 1097] train: loss: 0.0000843
[Epoch 108; Iter    41/ 1097] train: loss: 0.0000023
[Epoch 108; Iter    71/ 1097] train: loss: 0.0001253
[Epoch 108; Iter   101/ 1097] train: loss: 0.0235056
[Epoch 108; Iter   131/ 1097] train: loss: 0.0000186
[Epoch 108; Iter   161/ 1097] train: loss: 0.0003850
[Epoch 108; Iter   191/ 1097] train: loss: 0.0001608
[Epoch 108; Iter   221/ 1097] train: loss: 0.0002369
[Epoch 108; Iter   251/ 1097] train: loss: 0.0000136
[Epoch 108; Iter   281/ 1097] train: loss: 0.0001006
[Epoch 108; Iter   311/ 1097] train: loss: 0.0000533
[Epoch 108; Iter   341/ 1097] train: loss: 0.0000404
[Epoch 108; Iter   371/ 1097] train: loss: 0.0019790
[Epoch 108; Iter   401/ 1097] train: loss: 0.0007000
[Epoch 108; Iter   431/ 1097] train: loss: 0.0171495
[Epoch 108; Iter   461/ 1097] train: loss: 0.0000198
[Epoch 108; Iter   491/ 1097] train: loss: 0.0000151
[Epoch 108; Iter   521/ 1097] train: loss: 0.0000345
[Epoch 108; Iter   551/ 1097] train: loss: 0.0000039
[Epoch 108; Iter   581/ 1097] train: loss: 0.0002863
[Epoch 108; Iter   611/ 1097] train: loss: 0.0012725
[Epoch 108; Iter   641/ 1097] train: loss: 0.0003859
[Epoch 108; Iter   671/ 1097] train: loss: 0.0000006
[Epoch 108; Iter   701/ 1097] train: loss: 0.0000304
[Epoch 108; Iter   731/ 1097] train: loss: 0.0000472
[Epoch 108; Iter   761/ 1097] train: loss: 0.0000014
[Epoch 108; Iter   791/ 1097] train: loss: 0.0000056
[Epoch 108; Iter   821/ 1097] train: loss: 0.0000875
[Epoch 108; Iter   851/ 1097] train: loss: 0.0009932
[Epoch 108; Iter   881/ 1097] train: loss: 0.0006400
[Epoch 108; Iter   911/ 1097] train: loss: 0.0001520
[Epoch 108; Iter   941/ 1097] train: loss: 0.0037368
[Epoch 108; Iter   971/ 1097] train: loss: 0.0054122
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0000285
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0001311
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0000088
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0000013
[Epoch 108] ogbg-molhiv: 0.710481 val loss: 35.073774
[Epoch 108] ogbg-molhiv: 0.618701 test loss: 26.085106
[Epoch 109; Iter    24/ 1097] train: loss: 0.0000476
[Epoch 109; Iter    54/ 1097] train: loss: 0.0002766
[Epoch 109; Iter    84/ 1097] train: loss: 0.0000068
[Epoch 109; Iter   114/ 1097] train: loss: 0.0007315
[Epoch 109; Iter   144/ 1097] train: loss: 0.0000456
[Epoch 109; Iter   174/ 1097] train: loss: 0.0002709
[Epoch 109; Iter   204/ 1097] train: loss: 0.0000201
[Epoch 109; Iter   234/ 1097] train: loss: 0.0000279
[Epoch 109; Iter   264/ 1097] train: loss: 0.0000801
[Epoch 109; Iter   294/ 1097] train: loss: 0.0013693
[Epoch 109; Iter   324/ 1097] train: loss: 0.0000193
[Epoch 109; Iter   354/ 1097] train: loss: 0.0000448
[Epoch 109; Iter   384/ 1097] train: loss: 0.0044805
[Epoch 109; Iter   414/ 1097] train: loss: 0.0050760
[Epoch 109; Iter   444/ 1097] train: loss: 0.0000281
[Epoch 109; Iter   474/ 1097] train: loss: 0.0000060
[Epoch 109; Iter   504/ 1097] train: loss: 0.0001841
[Epoch 109; Iter   534/ 1097] train: loss: 0.0000035
[Epoch 109; Iter   564/ 1097] train: loss: 0.0008467
[Epoch 109; Iter   594/ 1097] train: loss: 0.0000323
[Epoch 109; Iter   624/ 1097] train: loss: 0.0000080
[Epoch 109; Iter   654/ 1097] train: loss: 0.0000056
[Epoch 109; Iter   684/ 1097] train: loss: 0.0045702
[Epoch 85; Iter   432/ 1097] train: loss: 0.0581736
[Epoch 85; Iter   462/ 1097] train: loss: 0.0063191
[Epoch 85; Iter   492/ 1097] train: loss: 0.0364693
[Epoch 85; Iter   522/ 1097] train: loss: 0.0032840
[Epoch 85; Iter   552/ 1097] train: loss: 0.0034812
[Epoch 85; Iter   582/ 1097] train: loss: 0.0065942
[Epoch 85; Iter   612/ 1097] train: loss: 0.0140636
[Epoch 85; Iter   642/ 1097] train: loss: 0.0698519
[Epoch 85; Iter   672/ 1097] train: loss: 0.0022477
[Epoch 85; Iter   702/ 1097] train: loss: 0.0819393
[Epoch 85; Iter   732/ 1097] train: loss: 0.0029497
[Epoch 85; Iter   762/ 1097] train: loss: 0.0407198
[Epoch 85; Iter   792/ 1097] train: loss: 0.0206200
[Epoch 85; Iter   822/ 1097] train: loss: 0.0104216
[Epoch 85; Iter   852/ 1097] train: loss: 0.0023589
[Epoch 85; Iter   882/ 1097] train: loss: 0.0158311
[Epoch 85; Iter   912/ 1097] train: loss: 0.1220476
[Epoch 85; Iter   942/ 1097] train: loss: 0.0698921
[Epoch 85; Iter   972/ 1097] train: loss: 0.0025269
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0236455
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0197115
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0014958
[Epoch 85; Iter  1092/ 1097] train: loss: 0.1022868
[Epoch 85] ogbg-molhiv: 0.814438 val loss: 0.121953
[Epoch 85] ogbg-molhiv: 0.748819 test loss: 0.224177
[Epoch 86; Iter    25/ 1097] train: loss: 0.0022902
[Epoch 86; Iter    55/ 1097] train: loss: 0.0200915
[Epoch 86; Iter    85/ 1097] train: loss: 0.0601145
[Epoch 86; Iter   115/ 1097] train: loss: 0.0024040
[Epoch 86; Iter   145/ 1097] train: loss: 0.0019302
[Epoch 86; Iter   175/ 1097] train: loss: 0.0108123
[Epoch 86; Iter   205/ 1097] train: loss: 0.0333629
[Epoch 86; Iter   235/ 1097] train: loss: 0.0175209
[Epoch 86; Iter   265/ 1097] train: loss: 0.0068658
[Epoch 86; Iter   295/ 1097] train: loss: 0.0133970
[Epoch 86; Iter   325/ 1097] train: loss: 0.0266655
[Epoch 86; Iter   355/ 1097] train: loss: 0.0061984
[Epoch 86; Iter   385/ 1097] train: loss: 0.0521914
[Epoch 86; Iter   415/ 1097] train: loss: 0.0749895
[Epoch 86; Iter   445/ 1097] train: loss: 0.0042308
[Epoch 86; Iter   475/ 1097] train: loss: 0.0105737
[Epoch 86; Iter   505/ 1097] train: loss: 0.0420737
[Epoch 86; Iter   535/ 1097] train: loss: 0.0587655
[Epoch 86; Iter   565/ 1097] train: loss: 0.0047963
[Epoch 86; Iter   595/ 1097] train: loss: 0.0341074
[Epoch 86; Iter   625/ 1097] train: loss: 0.0015814
[Epoch 86; Iter   655/ 1097] train: loss: 0.1116117
[Epoch 86; Iter   685/ 1097] train: loss: 0.0164609
[Epoch 86; Iter   715/ 1097] train: loss: 0.0582744
[Epoch 86; Iter   745/ 1097] train: loss: 0.0121546
[Epoch 86; Iter   775/ 1097] train: loss: 0.0217380
[Epoch 86; Iter   805/ 1097] train: loss: 0.0058404
[Epoch 86; Iter   835/ 1097] train: loss: 0.0178398
[Epoch 86; Iter   865/ 1097] train: loss: 0.0087877
[Epoch 86; Iter   895/ 1097] train: loss: 0.0200318
[Epoch 86; Iter   925/ 1097] train: loss: 0.0120260
[Epoch 86; Iter   955/ 1097] train: loss: 0.0180333
[Epoch 86; Iter   985/ 1097] train: loss: 0.0084854
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0018682
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0068965
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0434313
[Epoch 86] ogbg-molhiv: 0.808259 val loss: 0.125506
[Epoch 86] ogbg-molhiv: 0.744562 test loss: 0.232393
[Epoch 87; Iter     8/ 1097] train: loss: 0.0172914
[Epoch 87; Iter    38/ 1097] train: loss: 0.0077808
[Epoch 87; Iter    68/ 1097] train: loss: 0.0100423
[Epoch 87; Iter    98/ 1097] train: loss: 0.0239426
[Epoch 87; Iter   128/ 1097] train: loss: 0.0076405
[Epoch 87; Iter   158/ 1097] train: loss: 0.0160667
[Epoch 87; Iter   188/ 1097] train: loss: 0.0039106
[Epoch 87; Iter   218/ 1097] train: loss: 0.0118636
[Epoch 87; Iter   248/ 1097] train: loss: 0.0287703
[Epoch 87; Iter   278/ 1097] train: loss: 0.0238992
[Epoch 87; Iter   308/ 1097] train: loss: 0.0291496
[Epoch 87; Iter   338/ 1097] train: loss: 0.0066471
[Epoch 87; Iter   368/ 1097] train: loss: 0.0043379
[Epoch 87; Iter   398/ 1097] train: loss: 0.0033841
[Epoch 87; Iter   428/ 1097] train: loss: 0.0584391
[Epoch 87; Iter   458/ 1097] train: loss: 0.0005537
[Epoch 87; Iter   488/ 1097] train: loss: 0.1094099
[Epoch 87; Iter   518/ 1097] train: loss: 0.0556391
[Epoch 87; Iter   548/ 1097] train: loss: 0.0610745
[Epoch 87; Iter   578/ 1097] train: loss: 0.0157984
[Epoch 87; Iter   608/ 1097] train: loss: 0.0286415
[Epoch 87; Iter   638/ 1097] train: loss: 0.0529606
[Epoch 87; Iter   668/ 1097] train: loss: 0.0066224
[Epoch 87; Iter   698/ 1097] train: loss: 0.0097898
[Epoch 87; Iter   728/ 1097] train: loss: 0.0665891
[Epoch 87; Iter   758/ 1097] train: loss: 0.0162210
[Epoch 87; Iter   788/ 1097] train: loss: 0.0242816
[Epoch 87; Iter   818/ 1097] train: loss: 0.0223819
[Epoch 87; Iter   848/ 1097] train: loss: 0.0011206
[Epoch 87; Iter   878/ 1097] train: loss: 0.0079972
[Epoch 87; Iter   908/ 1097] train: loss: 0.0013434
[Epoch 87; Iter   938/ 1097] train: loss: 0.0193080
[Epoch 87; Iter   968/ 1097] train: loss: 0.0813536
[Epoch 87; Iter   998/ 1097] train: loss: 0.0064228
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0030494
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0031312
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0065679
[Epoch 87] ogbg-molhiv: 0.822586 val loss: 0.117696
[Epoch 87] ogbg-molhiv: 0.745868 test loss: 0.233074
[Epoch 88; Iter    21/ 1097] train: loss: 0.0213438
[Epoch 88; Iter    51/ 1097] train: loss: 0.0019729
[Epoch 88; Iter    81/ 1097] train: loss: 0.0662514
[Epoch 88; Iter   111/ 1097] train: loss: 0.0068316
[Epoch 88; Iter   141/ 1097] train: loss: 0.0460459
[Epoch 88; Iter   171/ 1097] train: loss: 0.0012363
[Epoch 88; Iter   201/ 1097] train: loss: 0.0026097
[Epoch 88; Iter   231/ 1097] train: loss: 0.1379113
[Epoch 88; Iter   261/ 1097] train: loss: 0.0127930
[Epoch 88; Iter   291/ 1097] train: loss: 0.0183763
[Epoch 88; Iter   321/ 1097] train: loss: 0.0041606
[Epoch 88; Iter   351/ 1097] train: loss: 0.0159493
[Epoch 88; Iter   381/ 1097] train: loss: 0.0075730
[Epoch 88; Iter   411/ 1097] train: loss: 0.0579286
[Epoch 88; Iter   441/ 1097] train: loss: 0.0041770
[Epoch 88; Iter   471/ 1097] train: loss: 0.0030439
[Epoch 88; Iter   501/ 1097] train: loss: 0.0066265
[Epoch 88; Iter   531/ 1097] train: loss: 0.0228414
[Epoch 88; Iter   561/ 1097] train: loss: 0.0750836
[Epoch 88; Iter   591/ 1097] train: loss: 0.1122411
[Epoch 88; Iter   621/ 1097] train: loss: 0.0011009
[Epoch 88; Iter   651/ 1097] train: loss: 0.0130501
[Epoch 88; Iter   681/ 1097] train: loss: 0.0020594
[Epoch 88; Iter   711/ 1097] train: loss: 0.0398660
[Epoch 88; Iter   741/ 1097] train: loss: 0.0692720
[Epoch 88; Iter   771/ 1097] train: loss: 0.0044074
[Epoch 88; Iter   801/ 1097] train: loss: 0.0009788
[Epoch 88; Iter   831/ 1097] train: loss: 0.0064696
[Epoch 88; Iter   861/ 1097] train: loss: 0.0010633
[Epoch 88; Iter   891/ 1097] train: loss: 0.0193802
[Epoch 88; Iter   921/ 1097] train: loss: 0.0365508
[Epoch 88; Iter   951/ 1097] train: loss: 0.0016930
[Epoch 88; Iter   981/ 1097] train: loss: 0.0029587
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0380088
[Epoch 88; Iter  1041/ 1097] train: loss: 0.1680198
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0649612
[Epoch 88] ogbg-molhiv: 0.812953 val loss: 0.125261
[Epoch 88] ogbg-molhiv: 0.742413 test loss: 0.234525
[Epoch 89; Iter     4/ 1097] train: loss: 0.0808340
[Epoch 89; Iter    34/ 1097] train: loss: 0.0143768
[Epoch 89; Iter    64/ 1097] train: loss: 0.0037050
[Epoch 89; Iter    94/ 1097] train: loss: 0.0020648
[Epoch 89; Iter   124/ 1097] train: loss: 0.0166097
[Epoch 89; Iter   154/ 1097] train: loss: 0.0357477
[Epoch 89; Iter   184/ 1097] train: loss: 0.0062177
[Epoch 89; Iter   214/ 1097] train: loss: 0.0088506
[Epoch 89; Iter   244/ 1097] train: loss: 0.0268092
[Epoch 89; Iter   274/ 1097] train: loss: 0.0837823
[Epoch 89; Iter   304/ 1097] train: loss: 0.0075609
[Epoch 89; Iter   334/ 1097] train: loss: 0.0187285
[Epoch 89; Iter   364/ 1097] train: loss: 0.0614119
[Epoch 89; Iter   394/ 1097] train: loss: 0.0054717
[Epoch 89; Iter   424/ 1097] train: loss: 0.0275252
[Epoch 89; Iter   454/ 1097] train: loss: 0.0030818
[Epoch 89; Iter   484/ 1097] train: loss: 0.0211055
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000136
[Epoch 109; Iter   744/ 1097] train: loss: 0.0000216
[Epoch 109; Iter   774/ 1097] train: loss: 0.0001325
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000213
[Epoch 109; Iter   834/ 1097] train: loss: 0.0069272
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000056
[Epoch 109; Iter   894/ 1097] train: loss: 0.0000215
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000623
[Epoch 109; Iter   954/ 1097] train: loss: 0.0000321
[Epoch 109; Iter   984/ 1097] train: loss: 0.0009325
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000879
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0002445
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000138
[Epoch 109] ogbg-molhiv: 0.695593 val loss: 3.604747
[Epoch 109] ogbg-molhiv: 0.718434 test loss: 0.965001
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000158
[Epoch 110; Iter    37/ 1097] train: loss: 0.0000361
[Epoch 110; Iter    67/ 1097] train: loss: 0.0000009
[Epoch 110; Iter    97/ 1097] train: loss: 0.0000904
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000867
[Epoch 110; Iter   157/ 1097] train: loss: 0.0000285
[Epoch 110; Iter   187/ 1097] train: loss: 0.0001654
[Epoch 110; Iter   217/ 1097] train: loss: 0.0004007
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000129
[Epoch 110; Iter   277/ 1097] train: loss: 0.0003753
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000289
[Epoch 110; Iter   337/ 1097] train: loss: 0.0021893
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000490
[Epoch 110; Iter   397/ 1097] train: loss: 0.0001369
[Epoch 110; Iter   427/ 1097] train: loss: 0.0319121
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000275
[Epoch 110; Iter   487/ 1097] train: loss: 0.0001443
[Epoch 110; Iter   517/ 1097] train: loss: 0.0002521
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000183
[Epoch 110; Iter   577/ 1097] train: loss: 0.0034637
[Epoch 110; Iter   607/ 1097] train: loss: 0.0014088
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000406
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000362
[Epoch 110; Iter   697/ 1097] train: loss: 0.0033037
[Epoch 110; Iter   727/ 1097] train: loss: 0.0000279
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000018
[Epoch 110; Iter   787/ 1097] train: loss: 0.0001830
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000408
[Epoch 110; Iter   847/ 1097] train: loss: 0.0043867
[Epoch 110; Iter   877/ 1097] train: loss: 0.0151721
[Epoch 110; Iter   907/ 1097] train: loss: 0.0010988
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000059
[Epoch 110; Iter   967/ 1097] train: loss: 0.0004989
[Epoch 110; Iter   997/ 1097] train: loss: 0.0022213
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000092
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0001881
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0033369
[Epoch 110] ogbg-molhiv: 0.786755 val loss: 0.582046
[Epoch 110] ogbg-molhiv: 0.726486 test loss: 1.025484
[Epoch 111; Iter    20/ 1097] train: loss: 0.0006346
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000066
[Epoch 111; Iter    80/ 1097] train: loss: 0.0001245
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000515
[Epoch 111; Iter   140/ 1097] train: loss: 0.0000386
[Epoch 111; Iter   170/ 1097] train: loss: 0.0123622
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000472
[Epoch 111; Iter   230/ 1097] train: loss: 0.0002010
[Epoch 111; Iter   260/ 1097] train: loss: 0.0023912
[Epoch 111; Iter   290/ 1097] train: loss: 0.0007144
[Epoch 111; Iter   320/ 1097] train: loss: 0.0001817
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000065
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000021
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000611
[Epoch 111; Iter   440/ 1097] train: loss: 0.0003751
[Epoch 111; Iter   470/ 1097] train: loss: 0.0065948
[Epoch 111; Iter   500/ 1097] train: loss: 0.0003930
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000111
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000317
[Epoch 111; Iter   590/ 1097] train: loss: 0.0003327
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000743
[Epoch 111; Iter   650/ 1097] train: loss: 0.0125801
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000978
[Epoch 111; Iter   710/ 1097] train: loss: 0.0006364
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000099
[Epoch 111; Iter   770/ 1097] train: loss: 0.0026284
[Epoch 111; Iter   800/ 1097] train: loss: 0.0002839
[Epoch 111; Iter   830/ 1097] train: loss: 0.0001002
[Epoch 111; Iter   860/ 1097] train: loss: 0.0000094
[Epoch 111; Iter   890/ 1097] train: loss: 0.0054455
[Epoch 111; Iter   920/ 1097] train: loss: 0.0016125
[Epoch 111; Iter   950/ 1097] train: loss: 0.0010358
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000098
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000400
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000174
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0001650
[Epoch 111] ogbg-molhiv: 0.759682 val loss: 1.357979
[Epoch 111] ogbg-molhiv: 0.711284 test loss: 1.170664
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000859
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000236
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000026
[Epoch 112; Iter    93/ 1097] train: loss: 0.0009030
[Epoch 112; Iter   123/ 1097] train: loss: 0.0018948
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000631
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000355
[Epoch 112; Iter   213/ 1097] train: loss: 0.0000987
[Epoch 112; Iter   243/ 1097] train: loss: 0.0017208
[Epoch 112; Iter   273/ 1097] train: loss: 0.0033034
[Epoch 112; Iter   303/ 1097] train: loss: 0.0003410
[Epoch 112; Iter   333/ 1097] train: loss: 0.0001408
[Epoch 112; Iter   363/ 1097] train: loss: 0.0001974
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000177
[Epoch 112; Iter   423/ 1097] train: loss: 0.0001052
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000216
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000253
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000550
[Epoch 112; Iter   543/ 1097] train: loss: 0.0000016
[Epoch 112; Iter   573/ 1097] train: loss: 0.0014019
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000252
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000759
[Epoch 112; Iter   663/ 1097] train: loss: 0.0002606
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000071
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000268
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000367
[Epoch 112; Iter   783/ 1097] train: loss: 0.0005149
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000034
[Epoch 112; Iter   843/ 1097] train: loss: 0.0073935
[Epoch 112; Iter   873/ 1097] train: loss: 0.0000561
[Epoch 112; Iter   903/ 1097] train: loss: 0.0002851
[Epoch 112; Iter   933/ 1097] train: loss: 0.0000101
[Epoch 112; Iter   963/ 1097] train: loss: 0.0001686
[Epoch 112; Iter   993/ 1097] train: loss: 0.0010530
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000491
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0000810
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0000227
[Epoch 112] ogbg-molhiv: 0.741659 val loss: 0.707097
[Epoch 112] ogbg-molhiv: 0.722306 test loss: 0.958038
[Epoch 113; Iter    16/ 1097] train: loss: 0.0004556
[Epoch 113; Iter    46/ 1097] train: loss: 0.0001430
[Epoch 113; Iter    76/ 1097] train: loss: 0.0019996
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000123
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000518
[Epoch 113; Iter   166/ 1097] train: loss: 0.0003668
[Epoch 113; Iter   196/ 1097] train: loss: 0.0013236
[Epoch 113; Iter   226/ 1097] train: loss: 0.0002030
[Epoch 113; Iter   256/ 1097] train: loss: 0.0086343
[Epoch 113; Iter   286/ 1097] train: loss: 0.0000340
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000371
[Epoch 113; Iter   346/ 1097] train: loss: 0.0002383
[Epoch 113; Iter   376/ 1097] train: loss: 0.0000529
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000696
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000761
[Epoch 113; Iter   466/ 1097] train: loss: 0.0000334
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000055
[Epoch 113; Iter   526/ 1097] train: loss: 0.0005400
[Epoch 113; Iter   556/ 1097] train: loss: 0.0000073
[Epoch 113; Iter   586/ 1097] train: loss: 0.0011199
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000707
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000533
[Epoch 113; Iter   676/ 1097] train: loss: 0.0016075
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000345
[Epoch 109; Iter   744/ 1097] train: loss: 0.0017558
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000730
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000430
[Epoch 109; Iter   834/ 1097] train: loss: 0.0002966
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000878
[Epoch 109; Iter   894/ 1097] train: loss: 0.0004288
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000184
[Epoch 109; Iter   954/ 1097] train: loss: 0.0003988
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000299
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000111
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000046
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000424
[Epoch 109] ogbg-molhiv: 0.703281 val loss: 1.311014
[Epoch 109] ogbg-molhiv: 0.692140 test loss: 0.619496
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000855
[Epoch 110; Iter    37/ 1097] train: loss: 0.0000249
[Epoch 110; Iter    67/ 1097] train: loss: 0.0000285
[Epoch 110; Iter    97/ 1097] train: loss: 0.0006384
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000538
[Epoch 110; Iter   157/ 1097] train: loss: 0.0379899
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000033
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000697
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000080
[Epoch 110; Iter   277/ 1097] train: loss: 0.0001927
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000054
[Epoch 110; Iter   337/ 1097] train: loss: 0.0004253
[Epoch 110; Iter   367/ 1097] train: loss: 0.0003576
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000076
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000453
[Epoch 110; Iter   457/ 1097] train: loss: 0.0002862
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000425
[Epoch 110; Iter   517/ 1097] train: loss: 0.0005241
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000012
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000033
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000009
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000258
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000299
[Epoch 110; Iter   697/ 1097] train: loss: 0.0000597
[Epoch 110; Iter   727/ 1097] train: loss: 0.0030604
[Epoch 110; Iter   757/ 1097] train: loss: 0.0002559
[Epoch 110; Iter   787/ 1097] train: loss: 0.0013281
[Epoch 110; Iter   817/ 1097] train: loss: 0.0003026
[Epoch 110; Iter   847/ 1097] train: loss: 0.0000091
[Epoch 110; Iter   877/ 1097] train: loss: 0.0193685
[Epoch 110; Iter   907/ 1097] train: loss: 0.0001523
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000697
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000046
[Epoch 110; Iter   997/ 1097] train: loss: 0.0266571
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0048322
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0087650
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000190
[Epoch 110] ogbg-molhiv: 0.708762 val loss: 1.542158
[Epoch 110] ogbg-molhiv: 0.703584 test loss: 1.534676
[Epoch 111; Iter    20/ 1097] train: loss: 0.0000069
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000196
[Epoch 111; Iter    80/ 1097] train: loss: 0.0011462
[Epoch 111; Iter   110/ 1097] train: loss: 0.0020271
[Epoch 111; Iter   140/ 1097] train: loss: 0.0598199
[Epoch 111; Iter   170/ 1097] train: loss: 0.0000025
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000583
[Epoch 111; Iter   230/ 1097] train: loss: 0.0001111
[Epoch 111; Iter   260/ 1097] train: loss: 0.0060981
[Epoch 111; Iter   290/ 1097] train: loss: 0.0001674
[Epoch 111; Iter   320/ 1097] train: loss: 0.0000181
[Epoch 111; Iter   350/ 1097] train: loss: 0.0387506
[Epoch 111; Iter   380/ 1097] train: loss: 0.0023014
[Epoch 111; Iter   410/ 1097] train: loss: 0.0002227
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000140
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000338
[Epoch 111; Iter   500/ 1097] train: loss: 0.0001749
[Epoch 111; Iter   530/ 1097] train: loss: 0.0007753
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000300
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000143
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000095
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000964
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000661
[Epoch 111; Iter   710/ 1097] train: loss: 0.0000743
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000450
[Epoch 111; Iter   770/ 1097] train: loss: 0.0000043
[Epoch 111; Iter   800/ 1097] train: loss: 0.0019498
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000547
[Epoch 111; Iter   860/ 1097] train: loss: 0.0097290
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000888
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000931
[Epoch 111; Iter   950/ 1097] train: loss: 0.0002715
[Epoch 111; Iter   980/ 1097] train: loss: 0.0152058
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000129
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0002317
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0362556
[Epoch 111] ogbg-molhiv: 0.706521 val loss: 1.342145
[Epoch 111] ogbg-molhiv: 0.704934 test loss: 1.333752
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000484
[Epoch 112; Iter    33/ 1097] train: loss: 0.0003430
[Epoch 112; Iter    63/ 1097] train: loss: 0.0001752
[Epoch 112; Iter    93/ 1097] train: loss: 0.0003679
[Epoch 112; Iter   123/ 1097] train: loss: 0.0006365
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000636
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000129
[Epoch 112; Iter   213/ 1097] train: loss: 0.0000239
[Epoch 112; Iter   243/ 1097] train: loss: 0.0001142
[Epoch 112; Iter   273/ 1097] train: loss: 0.0000546
[Epoch 112; Iter   303/ 1097] train: loss: 0.0001227
[Epoch 112; Iter   333/ 1097] train: loss: 0.0000059
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000291
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000598
[Epoch 112; Iter   423/ 1097] train: loss: 0.0000068
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000080
[Epoch 112; Iter   483/ 1097] train: loss: 0.0019194
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000584
[Epoch 112; Iter   543/ 1097] train: loss: 0.0057203
[Epoch 112; Iter   573/ 1097] train: loss: 0.0000002
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000065
[Epoch 112; Iter   633/ 1097] train: loss: 0.0001077
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000188
[Epoch 112; Iter   693/ 1097] train: loss: 0.0002842
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000157
[Epoch 112; Iter   753/ 1097] train: loss: 0.0010272
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000087
[Epoch 112; Iter   813/ 1097] train: loss: 0.0005300
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000007
[Epoch 112; Iter   873/ 1097] train: loss: 0.0001052
[Epoch 112; Iter   903/ 1097] train: loss: 0.0002217
[Epoch 112; Iter   933/ 1097] train: loss: 0.0001032
[Epoch 112; Iter   963/ 1097] train: loss: 0.0001173
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000033
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0228333
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0101863
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0002088
[Epoch 112] ogbg-molhiv: 0.706919 val loss: 2.425475
[Epoch 112] ogbg-molhiv: 0.700290 test loss: 1.479576
[Epoch 113; Iter    16/ 1097] train: loss: 0.0001587
[Epoch 113; Iter    46/ 1097] train: loss: 0.0001071
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000226
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000925
[Epoch 113; Iter   136/ 1097] train: loss: 0.0002324
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000263
[Epoch 113; Iter   196/ 1097] train: loss: 0.0012790
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000053
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000040
[Epoch 113; Iter   286/ 1097] train: loss: 0.0006804
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000914
[Epoch 113; Iter   346/ 1097] train: loss: 0.0001642
[Epoch 113; Iter   376/ 1097] train: loss: 0.0004839
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000055
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000003
[Epoch 113; Iter   466/ 1097] train: loss: 0.0000230
[Epoch 113; Iter   496/ 1097] train: loss: 0.0002398
[Epoch 113; Iter   526/ 1097] train: loss: 0.0001362
[Epoch 113; Iter   556/ 1097] train: loss: 0.0010500
[Epoch 113; Iter   586/ 1097] train: loss: 0.0022070
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000186
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000009
[Epoch 113; Iter   676/ 1097] train: loss: 0.0000921
[Epoch 85; Iter   432/ 1097] train: loss: 0.0045980
[Epoch 85; Iter   462/ 1097] train: loss: 0.0025121
[Epoch 85; Iter   492/ 1097] train: loss: 0.0471632
[Epoch 85; Iter   522/ 1097] train: loss: 0.0047465
[Epoch 85; Iter   552/ 1097] train: loss: 0.0329837
[Epoch 85; Iter   582/ 1097] train: loss: 0.1302053
[Epoch 85; Iter   612/ 1097] train: loss: 0.0125556
[Epoch 85; Iter   642/ 1097] train: loss: 0.0704913
[Epoch 85; Iter   672/ 1097] train: loss: 0.0218226
[Epoch 85; Iter   702/ 1097] train: loss: 0.0638565
[Epoch 85; Iter   732/ 1097] train: loss: 0.0321685
[Epoch 85; Iter   762/ 1097] train: loss: 0.0334431
[Epoch 85; Iter   792/ 1097] train: loss: 0.0272532
[Epoch 85; Iter   822/ 1097] train: loss: 0.0272622
[Epoch 85; Iter   852/ 1097] train: loss: 0.0307498
[Epoch 85; Iter   882/ 1097] train: loss: 0.0317575
[Epoch 85; Iter   912/ 1097] train: loss: 0.0710681
[Epoch 85; Iter   942/ 1097] train: loss: 0.0088186
[Epoch 85; Iter   972/ 1097] train: loss: 0.0124222
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0721012
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0456879
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0275826
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0188571
[Epoch 85] ogbg-molhiv: 0.803728 val loss: 0.109430
[Epoch 85] ogbg-molhiv: 0.748309 test loss: 0.237083
[Epoch 86; Iter    25/ 1097] train: loss: 0.0173024
[Epoch 86; Iter    55/ 1097] train: loss: 0.0242173
[Epoch 86; Iter    85/ 1097] train: loss: 0.0296007
[Epoch 86; Iter   115/ 1097] train: loss: 0.0031609
[Epoch 86; Iter   145/ 1097] train: loss: 0.0470904
[Epoch 86; Iter   175/ 1097] train: loss: 0.0058570
[Epoch 86; Iter   205/ 1097] train: loss: 0.0764002
[Epoch 86; Iter   235/ 1097] train: loss: 0.0394091
[Epoch 86; Iter   265/ 1097] train: loss: 0.1225218
[Epoch 86; Iter   295/ 1097] train: loss: 0.0077945
[Epoch 86; Iter   325/ 1097] train: loss: 0.0021660
[Epoch 86; Iter   355/ 1097] train: loss: 0.0328851
[Epoch 86; Iter   385/ 1097] train: loss: 0.0307422
[Epoch 86; Iter   415/ 1097] train: loss: 0.0087114
[Epoch 86; Iter   445/ 1097] train: loss: 0.0213123
[Epoch 86; Iter   475/ 1097] train: loss: 0.0125362
[Epoch 86; Iter   505/ 1097] train: loss: 0.0402489
[Epoch 86; Iter   535/ 1097] train: loss: 0.0056058
[Epoch 86; Iter   565/ 1097] train: loss: 0.0509914
[Epoch 86; Iter   595/ 1097] train: loss: 0.1119767
[Epoch 86; Iter   625/ 1097] train: loss: 0.0292895
[Epoch 86; Iter   655/ 1097] train: loss: 0.0064445
[Epoch 86; Iter   685/ 1097] train: loss: 0.0651592
[Epoch 86; Iter   715/ 1097] train: loss: 0.0286332
[Epoch 86; Iter   745/ 1097] train: loss: 0.1156409
[Epoch 86; Iter   775/ 1097] train: loss: 0.0525294
[Epoch 86; Iter   805/ 1097] train: loss: 0.0357423
[Epoch 86; Iter   835/ 1097] train: loss: 0.0012887
[Epoch 86; Iter   865/ 1097] train: loss: 0.0964504
[Epoch 86; Iter   895/ 1097] train: loss: 0.0070604
[Epoch 86; Iter   925/ 1097] train: loss: 0.0264602
[Epoch 86; Iter   955/ 1097] train: loss: 0.0187889
[Epoch 86; Iter   985/ 1097] train: loss: 0.0055728
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0174008
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0027712
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0031561
[Epoch 86] ogbg-molhiv: 0.803238 val loss: 0.110682
[Epoch 86] ogbg-molhiv: 0.746895 test loss: 0.228504
[Epoch 87; Iter     8/ 1097] train: loss: 0.0107702
[Epoch 87; Iter    38/ 1097] train: loss: 0.0099041
[Epoch 87; Iter    68/ 1097] train: loss: 0.0019916
[Epoch 87; Iter    98/ 1097] train: loss: 0.0068649
[Epoch 87; Iter   128/ 1097] train: loss: 0.0329747
[Epoch 87; Iter   158/ 1097] train: loss: 0.0068583
[Epoch 87; Iter   188/ 1097] train: loss: 0.0066769
[Epoch 87; Iter   218/ 1097] train: loss: 0.0181882
[Epoch 87; Iter   248/ 1097] train: loss: 0.0229595
[Epoch 87; Iter   278/ 1097] train: loss: 0.0150528
[Epoch 87; Iter   308/ 1097] train: loss: 0.0012701
[Epoch 87; Iter   338/ 1097] train: loss: 0.0123880
[Epoch 87; Iter   368/ 1097] train: loss: 0.0096353
[Epoch 87; Iter   398/ 1097] train: loss: 0.0087180
[Epoch 87; Iter   428/ 1097] train: loss: 0.0147076
[Epoch 87; Iter   458/ 1097] train: loss: 0.0177738
[Epoch 87; Iter   488/ 1097] train: loss: 0.0193165
[Epoch 87; Iter   518/ 1097] train: loss: 0.0223251
[Epoch 87; Iter   548/ 1097] train: loss: 0.0047265
[Epoch 87; Iter   578/ 1097] train: loss: 0.0387739
[Epoch 87; Iter   608/ 1097] train: loss: 0.0044639
[Epoch 87; Iter   638/ 1097] train: loss: 0.0249050
[Epoch 87; Iter   668/ 1097] train: loss: 0.0426199
[Epoch 87; Iter   698/ 1097] train: loss: 0.0208996
[Epoch 87; Iter   728/ 1097] train: loss: 0.0076771
[Epoch 87; Iter   758/ 1097] train: loss: 0.0377422
[Epoch 87; Iter   788/ 1097] train: loss: 0.0052929
[Epoch 87; Iter   818/ 1097] train: loss: 0.0388464
[Epoch 87; Iter   848/ 1097] train: loss: 0.0094954
[Epoch 87; Iter   878/ 1097] train: loss: 0.0051523
[Epoch 87; Iter   908/ 1097] train: loss: 0.0310971
[Epoch 87; Iter   938/ 1097] train: loss: 0.0295603
[Epoch 87; Iter   968/ 1097] train: loss: 0.0502355
[Epoch 87; Iter   998/ 1097] train: loss: 0.0419513
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0178854
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0029010
[Epoch 87; Iter  1088/ 1097] train: loss: 0.1216494
[Epoch 87] ogbg-molhiv: 0.813795 val loss: 0.112924
[Epoch 87] ogbg-molhiv: 0.755505 test loss: 0.228808
[Epoch 88; Iter    21/ 1097] train: loss: 0.0082351
[Epoch 88; Iter    51/ 1097] train: loss: 0.1198256
[Epoch 88; Iter    81/ 1097] train: loss: 0.0096190
[Epoch 88; Iter   111/ 1097] train: loss: 0.0004801
[Epoch 88; Iter   141/ 1097] train: loss: 0.0278915
[Epoch 88; Iter   171/ 1097] train: loss: 0.0409031
[Epoch 88; Iter   201/ 1097] train: loss: 0.0150253
[Epoch 88; Iter   231/ 1097] train: loss: 0.0360488
[Epoch 88; Iter   261/ 1097] train: loss: 0.0314379
[Epoch 88; Iter   291/ 1097] train: loss: 0.0338707
[Epoch 88; Iter   321/ 1097] train: loss: 0.0546886
[Epoch 88; Iter   351/ 1097] train: loss: 0.1094446
[Epoch 88; Iter   381/ 1097] train: loss: 0.0676794
[Epoch 88; Iter   411/ 1097] train: loss: 0.0061984
[Epoch 88; Iter   441/ 1097] train: loss: 0.0040165
[Epoch 88; Iter   471/ 1097] train: loss: 0.0102700
[Epoch 88; Iter   501/ 1097] train: loss: 0.0617879
[Epoch 88; Iter   531/ 1097] train: loss: 0.0039047
[Epoch 88; Iter   561/ 1097] train: loss: 0.0320289
[Epoch 88; Iter   591/ 1097] train: loss: 0.0037547
[Epoch 88; Iter   621/ 1097] train: loss: 0.0115523
[Epoch 88; Iter   651/ 1097] train: loss: 0.0845159
[Epoch 88; Iter   681/ 1097] train: loss: 0.0145004
[Epoch 88; Iter   711/ 1097] train: loss: 0.0048290
[Epoch 88; Iter   741/ 1097] train: loss: 0.0079078
[Epoch 88; Iter   771/ 1097] train: loss: 0.0115767
[Epoch 88; Iter   801/ 1097] train: loss: 0.1514844
[Epoch 88; Iter   831/ 1097] train: loss: 0.0059822
[Epoch 88; Iter   861/ 1097] train: loss: 0.0486537
[Epoch 88; Iter   891/ 1097] train: loss: 0.0028140
[Epoch 88; Iter   921/ 1097] train: loss: 0.0188721
[Epoch 88; Iter   951/ 1097] train: loss: 0.0293360
[Epoch 88; Iter   981/ 1097] train: loss: 0.0024224
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0037551
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0621648
[Epoch 88; Iter  1071/ 1097] train: loss: 0.1052454
[Epoch 88] ogbg-molhiv: 0.806979 val loss: 0.108869
[Epoch 88] ogbg-molhiv: 0.740700 test loss: 0.225685
[Epoch 89; Iter     4/ 1097] train: loss: 0.0269664
[Epoch 89; Iter    34/ 1097] train: loss: 0.0084289
[Epoch 89; Iter    64/ 1097] train: loss: 0.0211957
[Epoch 89; Iter    94/ 1097] train: loss: 0.0022593
[Epoch 89; Iter   124/ 1097] train: loss: 0.0031324
[Epoch 89; Iter   154/ 1097] train: loss: 0.1390884
[Epoch 89; Iter   184/ 1097] train: loss: 0.1137060
[Epoch 89; Iter   214/ 1097] train: loss: 0.0060531
[Epoch 89; Iter   244/ 1097] train: loss: 0.0154280
[Epoch 89; Iter   274/ 1097] train: loss: 0.0089761
[Epoch 89; Iter   304/ 1097] train: loss: 0.0040065
[Epoch 89; Iter   334/ 1097] train: loss: 0.0159706
[Epoch 89; Iter   364/ 1097] train: loss: 0.0015788
[Epoch 89; Iter   394/ 1097] train: loss: 0.0461570
[Epoch 89; Iter   424/ 1097] train: loss: 0.0005534
[Epoch 89; Iter   454/ 1097] train: loss: 0.2033438
[Epoch 89; Iter   484/ 1097] train: loss: 0.0939924
[Epoch 109; Iter   714/ 1097] train: loss: 0.0001280
[Epoch 109; Iter   744/ 1097] train: loss: 0.0000351
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000611
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000178
[Epoch 109; Iter   834/ 1097] train: loss: 0.0001527
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000010
[Epoch 109; Iter   894/ 1097] train: loss: 0.0001638
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000060
[Epoch 109; Iter   954/ 1097] train: loss: 0.0000070
[Epoch 109; Iter   984/ 1097] train: loss: 0.0016445
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000009
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000096
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000125
[Epoch 109] ogbg-molhiv: 0.786663 val loss: 0.254670
[Epoch 109] ogbg-molhiv: 0.718797 test loss: 0.433329
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000203
[Epoch 110; Iter    37/ 1097] train: loss: 0.0000177
[Epoch 110; Iter    67/ 1097] train: loss: 0.0000476
[Epoch 110; Iter    97/ 1097] train: loss: 0.0000014
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000535
[Epoch 110; Iter   157/ 1097] train: loss: 0.0055205
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000108
[Epoch 110; Iter   217/ 1097] train: loss: 0.0004982
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000251
[Epoch 110; Iter   277/ 1097] train: loss: 0.0216715
[Epoch 110; Iter   307/ 1097] train: loss: 0.0016355
[Epoch 110; Iter   337/ 1097] train: loss: 0.0057754
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000042
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000041
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000211
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000746
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000015
[Epoch 110; Iter   517/ 1097] train: loss: 0.0001258
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000078
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000091
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000006
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000031
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000395
[Epoch 110; Iter   697/ 1097] train: loss: 0.0001263
[Epoch 110; Iter   727/ 1097] train: loss: 0.0000467
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000052
[Epoch 110; Iter   787/ 1097] train: loss: 0.0000009
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000019
[Epoch 110; Iter   847/ 1097] train: loss: 0.0000791
[Epoch 110; Iter   877/ 1097] train: loss: 0.0000024
[Epoch 110; Iter   907/ 1097] train: loss: 0.0000015
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000025
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000034
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000004
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000269
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0000030
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000009
[Epoch 110] ogbg-molhiv: 0.792313 val loss: 0.233938
[Epoch 110] ogbg-molhiv: 0.724352 test loss: 0.418347
[Epoch 111; Iter    20/ 1097] train: loss: 0.0000005
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000016
[Epoch 111; Iter    80/ 1097] train: loss: 0.0000003
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000035
[Epoch 111; Iter   140/ 1097] train: loss: 0.0000200
[Epoch 111; Iter   170/ 1097] train: loss: 0.0000130
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000395
[Epoch 111; Iter   230/ 1097] train: loss: 0.0008270
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000006
[Epoch 111; Iter   290/ 1097] train: loss: 0.0000099
[Epoch 111; Iter   320/ 1097] train: loss: 0.0001245
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000355
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000379
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000034
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000016
[Epoch 111; Iter   470/ 1097] train: loss: 0.0004349
[Epoch 111; Iter   500/ 1097] train: loss: 0.0003483
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000002
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000068
[Epoch 111; Iter   590/ 1097] train: loss: 0.0001199
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000230
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000413
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000241
[Epoch 111; Iter   710/ 1097] train: loss: 0.0000055
[Epoch 111; Iter   740/ 1097] train: loss: 0.0002645
[Epoch 111; Iter   770/ 1097] train: loss: 0.0000084
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000092
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000098
[Epoch 111; Iter   860/ 1097] train: loss: 0.0058491
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000124
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000006
[Epoch 111; Iter   950/ 1097] train: loss: 0.0000169
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000035
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000004
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0006545
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000059
[Epoch 111] ogbg-molhiv: 0.786357 val loss: 0.231152
[Epoch 111] ogbg-molhiv: 0.712758 test loss: 0.413228
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000007
[Epoch 112; Iter    33/ 1097] train: loss: 0.0031124
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000075
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000008
[Epoch 112; Iter   123/ 1097] train: loss: 0.0002308
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000033
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000016
[Epoch 112; Iter   213/ 1097] train: loss: 0.0007202
[Epoch 112; Iter   243/ 1097] train: loss: 0.0000772
[Epoch 112; Iter   273/ 1097] train: loss: 0.0000539
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000153
[Epoch 112; Iter   333/ 1097] train: loss: 0.0005826
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000624
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000014
[Epoch 112; Iter   423/ 1097] train: loss: 0.0000252
[Epoch 112; Iter   453/ 1097] train: loss: 0.0004166
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000003
[Epoch 112; Iter   513/ 1097] train: loss: 0.0001217
[Epoch 112; Iter   543/ 1097] train: loss: 0.0123197
[Epoch 112; Iter   573/ 1097] train: loss: 0.0005522
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000547
[Epoch 112; Iter   633/ 1097] train: loss: 0.0015403
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000000
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000103
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000015
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000039
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000002
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000036
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000239
[Epoch 112; Iter   873/ 1097] train: loss: 0.0001114
[Epoch 112; Iter   903/ 1097] train: loss: 0.0007934
[Epoch 112; Iter   933/ 1097] train: loss: 0.0000284
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000007
[Epoch 112; Iter   993/ 1097] train: loss: 0.0003548
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000208
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0002651
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0005184
[Epoch 112] ogbg-molhiv: 0.781856 val loss: 0.274570
[Epoch 112] ogbg-molhiv: 0.729684 test loss: 0.420632
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000646
[Epoch 113; Iter    46/ 1097] train: loss: 0.0000230
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000323
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000982
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000201
[Epoch 113; Iter   166/ 1097] train: loss: 0.0001449
[Epoch 113; Iter   196/ 1097] train: loss: 0.0001159
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000009
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000477
[Epoch 113; Iter   286/ 1097] train: loss: 0.0098934
[Epoch 113; Iter   316/ 1097] train: loss: 0.0010629
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000405
[Epoch 113; Iter   376/ 1097] train: loss: 0.0000518
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000054
[Epoch 113; Iter   436/ 1097] train: loss: 0.0002875
[Epoch 113; Iter   466/ 1097] train: loss: 0.0002158
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000694
[Epoch 113; Iter   526/ 1097] train: loss: 0.0001538
[Epoch 113; Iter   556/ 1097] train: loss: 0.0002780
[Epoch 113; Iter   586/ 1097] train: loss: 0.0001616
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000021
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000263
[Epoch 113; Iter   676/ 1097] train: loss: 0.0000205
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000393
[Epoch 109; Iter   744/ 1097] train: loss: 0.0001167
[Epoch 109; Iter   774/ 1097] train: loss: 0.0001006
[Epoch 109; Iter   804/ 1097] train: loss: 0.0006144
[Epoch 109; Iter   834/ 1097] train: loss: 0.0000214
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000255
[Epoch 109; Iter   894/ 1097] train: loss: 0.0000386
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000050
[Epoch 109; Iter   954/ 1097] train: loss: 0.0000116
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000350
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0003774
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0012784
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0005820
[Epoch 109] ogbg-molhiv: 0.765398 val loss: 0.411751
[Epoch 109] ogbg-molhiv: 0.746314 test loss: 0.387777
[Epoch 110; Iter     7/ 1097] train: loss: 0.0654728
[Epoch 110; Iter    37/ 1097] train: loss: 0.0005574
[Epoch 110; Iter    67/ 1097] train: loss: 0.0001831
[Epoch 110; Iter    97/ 1097] train: loss: 0.0029775
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000515
[Epoch 110; Iter   157/ 1097] train: loss: 0.0005129
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000528
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000012
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000448
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000085
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000052
[Epoch 110; Iter   337/ 1097] train: loss: 0.0000109
[Epoch 110; Iter   367/ 1097] train: loss: 0.0017600
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000075
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000091
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000202
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000245
[Epoch 110; Iter   517/ 1097] train: loss: 0.0003693
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000302
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000367
[Epoch 110; Iter   607/ 1097] train: loss: 0.0005422
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000200
[Epoch 110; Iter   667/ 1097] train: loss: 0.0001668
[Epoch 110; Iter   697/ 1097] train: loss: 0.0006149
[Epoch 110; Iter   727/ 1097] train: loss: 0.0000012
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000341
[Epoch 110; Iter   787/ 1097] train: loss: 0.0000104
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000125
[Epoch 110; Iter   847/ 1097] train: loss: 0.0000048
[Epoch 110; Iter   877/ 1097] train: loss: 0.0001173
[Epoch 110; Iter   907/ 1097] train: loss: 0.0009110
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000239
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000289
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000073
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000204
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0006160
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000045
[Epoch 110] ogbg-molhiv: 0.770438 val loss: 0.416889
[Epoch 110] ogbg-molhiv: 0.760957 test loss: 0.385518
[Epoch 111; Iter    20/ 1097] train: loss: 0.0000760
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000108
[Epoch 111; Iter    80/ 1097] train: loss: 0.0000074
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000503
[Epoch 111; Iter   140/ 1097] train: loss: 0.0000035
[Epoch 111; Iter   170/ 1097] train: loss: 0.0000148
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000602
[Epoch 111; Iter   230/ 1097] train: loss: 0.0013327
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000116
[Epoch 111; Iter   290/ 1097] train: loss: 0.0000007
[Epoch 111; Iter   320/ 1097] train: loss: 0.0144010
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000064
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000257
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000489
[Epoch 111; Iter   440/ 1097] train: loss: 0.0001943
[Epoch 111; Iter   470/ 1097] train: loss: 0.0010432
[Epoch 111; Iter   500/ 1097] train: loss: 0.0000271
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000007
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000005
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000046
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000875
[Epoch 111; Iter   650/ 1097] train: loss: 0.0008835
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000739
[Epoch 111; Iter   710/ 1097] train: loss: 0.0008827
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000061
[Epoch 111; Iter   770/ 1097] train: loss: 0.0000269
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000118
[Epoch 111; Iter   830/ 1097] train: loss: 0.0001845
[Epoch 111; Iter   860/ 1097] train: loss: 0.0029781
[Epoch 111; Iter   890/ 1097] train: loss: 0.0001580
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000106
[Epoch 111; Iter   950/ 1097] train: loss: 0.0000617
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000100
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000080
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000192
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0001006
[Epoch 111] ogbg-molhiv: 0.762612 val loss: 0.413765
[Epoch 111] ogbg-molhiv: 0.750683 test loss: 0.386951
[Epoch 112; Iter     3/ 1097] train: loss: 0.0003340
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000490
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000057
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000311
[Epoch 112; Iter   123/ 1097] train: loss: 0.0000125
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000340
[Epoch 112; Iter   183/ 1097] train: loss: 0.0029595
[Epoch 112; Iter   213/ 1097] train: loss: 0.0002740
[Epoch 112; Iter   243/ 1097] train: loss: 0.0001196
[Epoch 112; Iter   273/ 1097] train: loss: 0.0016568
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000543
[Epoch 112; Iter   333/ 1097] train: loss: 0.0001469
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000929
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000079
[Epoch 112; Iter   423/ 1097] train: loss: 0.0002910
[Epoch 112; Iter   453/ 1097] train: loss: 0.0001493
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000039
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000690
[Epoch 112; Iter   543/ 1097] train: loss: 0.0000148
[Epoch 112; Iter   573/ 1097] train: loss: 0.0000091
[Epoch 112; Iter   603/ 1097] train: loss: 0.0001187
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000454
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000570
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000171
[Epoch 112; Iter   723/ 1097] train: loss: 0.0002036
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000063
[Epoch 112; Iter   783/ 1097] train: loss: 0.0010907
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000012
[Epoch 112; Iter   843/ 1097] train: loss: 0.0005160
[Epoch 112; Iter   873/ 1097] train: loss: 0.0006942
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000317
[Epoch 112; Iter   933/ 1097] train: loss: 0.0001146
[Epoch 112; Iter   963/ 1097] train: loss: 0.0022240
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000122
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000545
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0006100
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0000063
[Epoch 112] ogbg-molhiv: 0.762284 val loss: 0.424106
[Epoch 112] ogbg-molhiv: 0.747994 test loss: 0.388175
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000039
[Epoch 113; Iter    46/ 1097] train: loss: 0.0002568
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000219
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000209
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000059
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000036
[Epoch 113; Iter   196/ 1097] train: loss: 0.0000195
[Epoch 113; Iter   226/ 1097] train: loss: 0.0001457
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000438
[Epoch 113; Iter   286/ 1097] train: loss: 0.0002973
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000392
[Epoch 113; Iter   346/ 1097] train: loss: 0.0031494
[Epoch 113; Iter   376/ 1097] train: loss: 0.0001332
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000027
[Epoch 113; Iter   436/ 1097] train: loss: 0.0002293
[Epoch 113; Iter   466/ 1097] train: loss: 0.0004236
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000109
[Epoch 113; Iter   526/ 1097] train: loss: 0.0000245
[Epoch 113; Iter   556/ 1097] train: loss: 0.0000014
[Epoch 113; Iter   586/ 1097] train: loss: 0.0001679
[Epoch 113; Iter   616/ 1097] train: loss: 0.0001150
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000006
[Epoch 113; Iter   676/ 1097] train: loss: 0.0060613
[Epoch 85; Iter   432/ 1097] train: loss: 0.0236619
[Epoch 85; Iter   462/ 1097] train: loss: 0.0012437
[Epoch 85; Iter   492/ 1097] train: loss: 0.0109745
[Epoch 85; Iter   522/ 1097] train: loss: 0.0006599
[Epoch 85; Iter   552/ 1097] train: loss: 0.0112999
[Epoch 85; Iter   582/ 1097] train: loss: 0.0788221
[Epoch 85; Iter   612/ 1097] train: loss: 0.0012935
[Epoch 85; Iter   642/ 1097] train: loss: 0.0062105
[Epoch 85; Iter   672/ 1097] train: loss: 0.0123294
[Epoch 85; Iter   702/ 1097] train: loss: 0.0115126
[Epoch 85; Iter   732/ 1097] train: loss: 0.0018758
[Epoch 85; Iter   762/ 1097] train: loss: 0.0254312
[Epoch 85; Iter   792/ 1097] train: loss: 0.0011608
[Epoch 85; Iter   822/ 1097] train: loss: 0.0148692
[Epoch 85; Iter   852/ 1097] train: loss: 0.0041260
[Epoch 85; Iter   882/ 1097] train: loss: 0.1089097
[Epoch 85; Iter   912/ 1097] train: loss: 0.0487300
[Epoch 85; Iter   942/ 1097] train: loss: 0.0021213
[Epoch 85; Iter   972/ 1097] train: loss: 0.0027561
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0004801
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0083079
[Epoch 85; Iter  1062/ 1097] train: loss: 0.1665200
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0050725
[Epoch 85] ogbg-molhiv: 0.781826 val loss: 0.129448
[Epoch 85] ogbg-molhiv: 0.739025 test loss: 0.234516
[Epoch 86; Iter    25/ 1097] train: loss: 0.0062078
[Epoch 86; Iter    55/ 1097] train: loss: 0.0033021
[Epoch 86; Iter    85/ 1097] train: loss: 0.0375412
[Epoch 86; Iter   115/ 1097] train: loss: 0.0019145
[Epoch 86; Iter   145/ 1097] train: loss: 0.0047374
[Epoch 86; Iter   175/ 1097] train: loss: 0.0074817
[Epoch 86; Iter   205/ 1097] train: loss: 0.0718026
[Epoch 86; Iter   235/ 1097] train: loss: 0.0280466
[Epoch 86; Iter   265/ 1097] train: loss: 0.0038916
[Epoch 86; Iter   295/ 1097] train: loss: 0.0045187
[Epoch 86; Iter   325/ 1097] train: loss: 0.0072577
[Epoch 86; Iter   355/ 1097] train: loss: 0.0053674
[Epoch 86; Iter   385/ 1097] train: loss: 0.0017643
[Epoch 86; Iter   415/ 1097] train: loss: 0.0008553
[Epoch 86; Iter   445/ 1097] train: loss: 0.0076515
[Epoch 86; Iter   475/ 1097] train: loss: 0.0208173
[Epoch 86; Iter   505/ 1097] train: loss: 0.0052112
[Epoch 86; Iter   535/ 1097] train: loss: 0.0035549
[Epoch 86; Iter   565/ 1097] train: loss: 0.0261272
[Epoch 86; Iter   595/ 1097] train: loss: 0.0013915
[Epoch 86; Iter   625/ 1097] train: loss: 0.0103793
[Epoch 86; Iter   655/ 1097] train: loss: 0.0245017
[Epoch 86; Iter   685/ 1097] train: loss: 0.0150338
[Epoch 86; Iter   715/ 1097] train: loss: 0.0045029
[Epoch 86; Iter   745/ 1097] train: loss: 0.0211459
[Epoch 86; Iter   775/ 1097] train: loss: 0.0148645
[Epoch 86; Iter   805/ 1097] train: loss: 0.1096803
[Epoch 86; Iter   835/ 1097] train: loss: 0.0660720
[Epoch 86; Iter   865/ 1097] train: loss: 0.0053807
[Epoch 86; Iter   895/ 1097] train: loss: 0.0053582
[Epoch 86; Iter   925/ 1097] train: loss: 0.0034361
[Epoch 86; Iter   955/ 1097] train: loss: 0.0884403
[Epoch 86; Iter   985/ 1097] train: loss: 0.0071231
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0745009
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0457357
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0067151
[Epoch 86] ogbg-molhiv: 0.778216 val loss: 0.135343
[Epoch 86] ogbg-molhiv: 0.740642 test loss: 0.237175
[Epoch 87; Iter     8/ 1097] train: loss: 0.0090547
[Epoch 87; Iter    38/ 1097] train: loss: 0.0031019
[Epoch 87; Iter    68/ 1097] train: loss: 0.0031912
[Epoch 87; Iter    98/ 1097] train: loss: 0.0061210
[Epoch 87; Iter   128/ 1097] train: loss: 0.0129935
[Epoch 87; Iter   158/ 1097] train: loss: 0.0033133
[Epoch 87; Iter   188/ 1097] train: loss: 0.0508516
[Epoch 87; Iter   218/ 1097] train: loss: 0.0272787
[Epoch 87; Iter   248/ 1097] train: loss: 0.1354185
[Epoch 87; Iter   278/ 1097] train: loss: 0.0225618
[Epoch 87; Iter   308/ 1097] train: loss: 0.0019500
[Epoch 87; Iter   338/ 1097] train: loss: 0.0045509
[Epoch 87; Iter   368/ 1097] train: loss: 0.2522382
[Epoch 87; Iter   398/ 1097] train: loss: 0.0026505
[Epoch 87; Iter   428/ 1097] train: loss: 0.0022362
[Epoch 87; Iter   458/ 1097] train: loss: 0.0017207
[Epoch 87; Iter   488/ 1097] train: loss: 0.0096110
[Epoch 87; Iter   518/ 1097] train: loss: 0.0163135
[Epoch 87; Iter   548/ 1097] train: loss: 0.0068566
[Epoch 87; Iter   578/ 1097] train: loss: 0.0176595
[Epoch 87; Iter   608/ 1097] train: loss: 0.0012194
[Epoch 87; Iter   638/ 1097] train: loss: 0.0278234
[Epoch 87; Iter   668/ 1097] train: loss: 0.0040889
[Epoch 87; Iter   698/ 1097] train: loss: 0.1966231
[Epoch 87; Iter   728/ 1097] train: loss: 0.0218598
[Epoch 87; Iter   758/ 1097] train: loss: 0.0079118
[Epoch 87; Iter   788/ 1097] train: loss: 0.0113239
[Epoch 87; Iter   818/ 1097] train: loss: 0.0041807
[Epoch 87; Iter   848/ 1097] train: loss: 0.0081385
[Epoch 87; Iter   878/ 1097] train: loss: 0.0037171
[Epoch 87; Iter   908/ 1097] train: loss: 0.0117682
[Epoch 87; Iter   938/ 1097] train: loss: 0.0087133
[Epoch 87; Iter   968/ 1097] train: loss: 0.0174154
[Epoch 87; Iter   998/ 1097] train: loss: 0.0052775
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0144736
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0023141
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0141418
[Epoch 87] ogbg-molhiv: 0.784808 val loss: 0.138006
[Epoch 87] ogbg-molhiv: 0.744192 test loss: 0.236362
[Epoch 88; Iter    21/ 1097] train: loss: 0.0019767
[Epoch 88; Iter    51/ 1097] train: loss: 0.0038501
[Epoch 88; Iter    81/ 1097] train: loss: 0.1675847
[Epoch 88; Iter   111/ 1097] train: loss: 0.0041282
[Epoch 88; Iter   141/ 1097] train: loss: 0.0127758
[Epoch 88; Iter   171/ 1097] train: loss: 0.0214777
[Epoch 88; Iter   201/ 1097] train: loss: 0.0139334
[Epoch 88; Iter   231/ 1097] train: loss: 0.0073129
[Epoch 88; Iter   261/ 1097] train: loss: 0.0032888
[Epoch 88; Iter   291/ 1097] train: loss: 0.0051254
[Epoch 88; Iter   321/ 1097] train: loss: 0.0093395
[Epoch 88; Iter   351/ 1097] train: loss: 0.0028441
[Epoch 88; Iter   381/ 1097] train: loss: 0.0079530
[Epoch 88; Iter   411/ 1097] train: loss: 0.0259633
[Epoch 88; Iter   441/ 1097] train: loss: 0.0015802
[Epoch 88; Iter   471/ 1097] train: loss: 0.1110268
[Epoch 88; Iter   501/ 1097] train: loss: 0.0106582
[Epoch 88; Iter   531/ 1097] train: loss: 0.0008414
[Epoch 88; Iter   561/ 1097] train: loss: 0.0026836
[Epoch 88; Iter   591/ 1097] train: loss: 0.0022273
[Epoch 88; Iter   621/ 1097] train: loss: 0.0016766
[Epoch 88; Iter   651/ 1097] train: loss: 0.0914454
[Epoch 88; Iter   681/ 1097] train: loss: 0.0177922
[Epoch 88; Iter   711/ 1097] train: loss: 0.0012861
[Epoch 88; Iter   741/ 1097] train: loss: 0.0102000
[Epoch 88; Iter   771/ 1097] train: loss: 0.0850211
[Epoch 88; Iter   801/ 1097] train: loss: 0.0384956
[Epoch 88; Iter   831/ 1097] train: loss: 0.0634772
[Epoch 88; Iter   861/ 1097] train: loss: 0.0091681
[Epoch 88; Iter   891/ 1097] train: loss: 0.0114646
[Epoch 88; Iter   921/ 1097] train: loss: 0.0006099
[Epoch 88; Iter   951/ 1097] train: loss: 0.0011257
[Epoch 88; Iter   981/ 1097] train: loss: 0.0279583
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0068500
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0543166
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0082224
[Epoch 88] ogbg-molhiv: 0.777818 val loss: 0.135380
[Epoch 88] ogbg-molhiv: 0.752388 test loss: 0.266400
[Epoch 89; Iter     4/ 1097] train: loss: 0.0039509
[Epoch 89; Iter    34/ 1097] train: loss: 0.0046467
[Epoch 89; Iter    64/ 1097] train: loss: 0.0021864
[Epoch 89; Iter    94/ 1097] train: loss: 0.0013196
[Epoch 89; Iter   124/ 1097] train: loss: 0.0012389
[Epoch 89; Iter   154/ 1097] train: loss: 0.0187426
[Epoch 89; Iter   184/ 1097] train: loss: 0.0212489
[Epoch 89; Iter   214/ 1097] train: loss: 0.0098773
[Epoch 89; Iter   244/ 1097] train: loss: 0.0103529
[Epoch 89; Iter   274/ 1097] train: loss: 0.0090983
[Epoch 89; Iter   304/ 1097] train: loss: 0.0132839
[Epoch 89; Iter   334/ 1097] train: loss: 0.0101667
[Epoch 89; Iter   364/ 1097] train: loss: 0.1662594
[Epoch 89; Iter   394/ 1097] train: loss: 0.0544654
[Epoch 89; Iter   424/ 1097] train: loss: 0.0121345
[Epoch 89; Iter   454/ 1097] train: loss: 0.0010152
[Epoch 89; Iter   484/ 1097] train: loss: 0.0046116
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000029
[Epoch 109; Iter   744/ 1097] train: loss: 0.0000798
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000068
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000024
[Epoch 109; Iter   834/ 1097] train: loss: 0.0014252
[Epoch 109; Iter   864/ 1097] train: loss: 0.0011519
[Epoch 109; Iter   894/ 1097] train: loss: 0.0000467
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000066
[Epoch 109; Iter   954/ 1097] train: loss: 0.0001408
[Epoch 109; Iter   984/ 1097] train: loss: 0.0005481
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000652
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000008
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000347
[Epoch 109] ogbg-molhiv: 0.775438 val loss: 0.301292
[Epoch 109] ogbg-molhiv: 0.732251 test loss: 0.454573
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000132
[Epoch 110; Iter    37/ 1097] train: loss: 0.0002591
[Epoch 110; Iter    67/ 1097] train: loss: 0.0001109
[Epoch 110; Iter    97/ 1097] train: loss: 0.0000153
[Epoch 110; Iter   127/ 1097] train: loss: 0.0001034
[Epoch 110; Iter   157/ 1097] train: loss: 0.0007725
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000136
[Epoch 110; Iter   217/ 1097] train: loss: 0.0001277
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000199
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000172
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000331
[Epoch 110; Iter   337/ 1097] train: loss: 0.0019391
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000295
[Epoch 110; Iter   397/ 1097] train: loss: 0.0047569
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000238
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000116
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000312
[Epoch 110; Iter   517/ 1097] train: loss: 0.0032968
[Epoch 110; Iter   547/ 1097] train: loss: 0.0009636
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000244
[Epoch 110; Iter   607/ 1097] train: loss: 0.0001623
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000989
[Epoch 110; Iter   667/ 1097] train: loss: 0.0001570
[Epoch 110; Iter   697/ 1097] train: loss: 0.0515619
[Epoch 110; Iter   727/ 1097] train: loss: 0.0001390
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000422
[Epoch 110; Iter   787/ 1097] train: loss: 0.0036450
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000063
[Epoch 110; Iter   847/ 1097] train: loss: 0.0000597
[Epoch 110; Iter   877/ 1097] train: loss: 0.0010039
[Epoch 110; Iter   907/ 1097] train: loss: 0.0000367
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000394
[Epoch 110; Iter   967/ 1097] train: loss: 0.0001005
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000378
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000074
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0000019
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0001442
[Epoch 110] ogbg-molhiv: 0.780977 val loss: 0.277940
[Epoch 110] ogbg-molhiv: 0.728127 test loss: 0.428770
[Epoch 111; Iter    20/ 1097] train: loss: 0.0001952
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000997
[Epoch 111; Iter    80/ 1097] train: loss: 0.0001076
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000185
[Epoch 111; Iter   140/ 1097] train: loss: 0.0000018
[Epoch 111; Iter   170/ 1097] train: loss: 0.0001093
[Epoch 111; Iter   200/ 1097] train: loss: 0.0009574
[Epoch 111; Iter   230/ 1097] train: loss: 0.0000106
[Epoch 111; Iter   260/ 1097] train: loss: 0.0002105
[Epoch 111; Iter   290/ 1097] train: loss: 0.0000012
[Epoch 111; Iter   320/ 1097] train: loss: 0.0000234
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000106
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000733
[Epoch 111; Iter   410/ 1097] train: loss: 0.0004846
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000632
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000254
[Epoch 111; Iter   500/ 1097] train: loss: 0.0001370
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000209
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000069
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000016
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000062
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000646
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000042
[Epoch 111; Iter   710/ 1097] train: loss: 0.0000404
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000186
[Epoch 111; Iter   770/ 1097] train: loss: 0.0000045
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000005
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000525
[Epoch 111; Iter   860/ 1097] train: loss: 0.0024214
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000476
[Epoch 111; Iter   920/ 1097] train: loss: 0.0002700
[Epoch 111; Iter   950/ 1097] train: loss: 0.0002273
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000080
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0028721
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000026
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000269
[Epoch 111] ogbg-molhiv: 0.785344 val loss: 0.320211
[Epoch 111] ogbg-molhiv: 0.722845 test loss: 0.431736
[Epoch 112; Iter     3/ 1097] train: loss: 0.0002362
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000436
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000043
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000216
[Epoch 112; Iter   123/ 1097] train: loss: 0.0000055
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000024
[Epoch 112; Iter   183/ 1097] train: loss: 0.0028991
[Epoch 112; Iter   213/ 1097] train: loss: 0.0077880
[Epoch 112; Iter   243/ 1097] train: loss: 0.0000079
[Epoch 112; Iter   273/ 1097] train: loss: 0.0000145
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000616
[Epoch 112; Iter   333/ 1097] train: loss: 0.0000962
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000529
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000158
[Epoch 112; Iter   423/ 1097] train: loss: 0.0064292
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000113
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000004
[Epoch 112; Iter   513/ 1097] train: loss: 0.0009911
[Epoch 112; Iter   543/ 1097] train: loss: 0.0002369
[Epoch 112; Iter   573/ 1097] train: loss: 0.0002128
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000175
[Epoch 112; Iter   633/ 1097] train: loss: 0.0001272
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000020
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000496
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000564
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000977
[Epoch 112; Iter   783/ 1097] train: loss: 0.0005105
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000038
[Epoch 112; Iter   843/ 1097] train: loss: 0.0004381
[Epoch 112; Iter   873/ 1097] train: loss: 0.0001582
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000021
[Epoch 112; Iter   933/ 1097] train: loss: 0.0007821
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000898
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000379
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000747
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0073545
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0004875
[Epoch 112] ogbg-molhiv: 0.791296 val loss: 0.272001
[Epoch 112] ogbg-molhiv: 0.731994 test loss: 0.439149
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000150
[Epoch 113; Iter    46/ 1097] train: loss: 0.0000065
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000060
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000663
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000014
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000124
[Epoch 113; Iter   196/ 1097] train: loss: 0.0000220
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000008
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000030
[Epoch 113; Iter   286/ 1097] train: loss: 0.0000392
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000500
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000446
[Epoch 113; Iter   376/ 1097] train: loss: 0.0002705
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000013
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000064
[Epoch 113; Iter   466/ 1097] train: loss: 0.0001102
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000873
[Epoch 113; Iter   526/ 1097] train: loss: 0.0002172
[Epoch 113; Iter   556/ 1097] train: loss: 0.0004237
[Epoch 113; Iter   586/ 1097] train: loss: 0.0000985
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000008
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000051
[Epoch 113; Iter   676/ 1097] train: loss: 0.0083728
[Epoch 109; Iter   714/ 1097] train: loss: 0.0002415
[Epoch 109; Iter   744/ 1097] train: loss: 0.0004129
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000005
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000080
[Epoch 109; Iter   834/ 1097] train: loss: 0.0000027
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000276
[Epoch 109; Iter   894/ 1097] train: loss: 0.0007484
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000044
[Epoch 109; Iter   954/ 1097] train: loss: 0.0002617
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000201
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000071
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000108
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0001945
[Epoch 109] ogbg-molhiv: 0.799184 val loss: 0.403902
[Epoch 109] ogbg-molhiv: 0.793190 test loss: 0.357253
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000031
[Epoch 110; Iter    37/ 1097] train: loss: 0.0001063
[Epoch 110; Iter    67/ 1097] train: loss: 0.0001318
[Epoch 110; Iter    97/ 1097] train: loss: 0.0001209
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000187
[Epoch 110; Iter   157/ 1097] train: loss: 0.0000040
[Epoch 110; Iter   187/ 1097] train: loss: 0.0040769
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000666
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000069
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000817
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000009
[Epoch 110; Iter   337/ 1097] train: loss: 0.0001134
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000044
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000148
[Epoch 110; Iter   427/ 1097] train: loss: 0.0034320
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000417
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000385
[Epoch 110; Iter   517/ 1097] train: loss: 0.0000365
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000260
[Epoch 110; Iter   577/ 1097] train: loss: 0.0002325
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000861
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000004
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000119
[Epoch 110; Iter   697/ 1097] train: loss: 0.0000168
[Epoch 110; Iter   727/ 1097] train: loss: 0.0000137
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000008
[Epoch 110; Iter   787/ 1097] train: loss: 0.0000005
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000095
[Epoch 110; Iter   847/ 1097] train: loss: 0.0066482
[Epoch 110; Iter   877/ 1097] train: loss: 0.0005561
[Epoch 110; Iter   907/ 1097] train: loss: 0.0000316
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000082
[Epoch 110; Iter   967/ 1097] train: loss: 0.0009033
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000356
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000054
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0000002
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0004778
[Epoch 110] ogbg-molhiv: 0.803605 val loss: 0.297257
[Epoch 110] ogbg-molhiv: 0.789940 test loss: 0.359793
[Epoch 111; Iter    20/ 1097] train: loss: 0.0000014
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000056
[Epoch 111; Iter    80/ 1097] train: loss: 0.0000037
[Epoch 111; Iter   110/ 1097] train: loss: 0.0003183
[Epoch 111; Iter   140/ 1097] train: loss: 0.0010593
[Epoch 111; Iter   170/ 1097] train: loss: 0.0002148
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000709
[Epoch 111; Iter   230/ 1097] train: loss: 0.0000169
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000060
[Epoch 111; Iter   290/ 1097] train: loss: 0.0001841
[Epoch 111; Iter   320/ 1097] train: loss: 0.0000012
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000813
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000040
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000002
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000349
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000099
[Epoch 111; Iter   500/ 1097] train: loss: 0.0000012
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000353
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000445
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000341
[Epoch 111; Iter   620/ 1097] train: loss: 0.0000280
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000004
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000211
[Epoch 111; Iter   710/ 1097] train: loss: 0.0000648
[Epoch 111; Iter   740/ 1097] train: loss: 0.0001149
[Epoch 111; Iter   770/ 1097] train: loss: 0.0000417
[Epoch 111; Iter   800/ 1097] train: loss: 0.0005023
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000639
[Epoch 111; Iter   860/ 1097] train: loss: 0.0000005
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000341
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000676
[Epoch 111; Iter   950/ 1097] train: loss: 0.0000083
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000022
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0004749
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000059
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000477
[Epoch 111] ogbg-molhiv: 0.799478 val loss: 0.309771
[Epoch 111] ogbg-molhiv: 0.790865 test loss: 0.372027
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000171
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000441
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000625
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000505
[Epoch 112; Iter   123/ 1097] train: loss: 0.0000226
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000205
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000170
[Epoch 112; Iter   213/ 1097] train: loss: 0.0006883
[Epoch 112; Iter   243/ 1097] train: loss: 0.0009871
[Epoch 112; Iter   273/ 1097] train: loss: 0.0000317
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000162
[Epoch 112; Iter   333/ 1097] train: loss: 0.0000649
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000058
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000013
[Epoch 112; Iter   423/ 1097] train: loss: 0.0000326
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000037
[Epoch 112; Iter   483/ 1097] train: loss: 0.0002122
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000074
[Epoch 112; Iter   543/ 1097] train: loss: 0.0000081
[Epoch 112; Iter   573/ 1097] train: loss: 0.0000091
[Epoch 112; Iter   603/ 1097] train: loss: 0.0009248
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000012
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000018
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000082
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000019
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000070
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000463
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000460
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000881
[Epoch 112; Iter   873/ 1097] train: loss: 0.0000659
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000528
[Epoch 112; Iter   933/ 1097] train: loss: 0.0000146
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000040
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000057
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000036
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0002546
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0000040
[Epoch 112] ogbg-molhiv: 0.810892 val loss: 0.449598
[Epoch 112] ogbg-molhiv: 0.804218 test loss: 0.359267
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000056
[Epoch 113; Iter    46/ 1097] train: loss: 0.0000024
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000780
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000034
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000216
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000034
[Epoch 113; Iter   196/ 1097] train: loss: 0.0004182
[Epoch 113; Iter   226/ 1097] train: loss: 0.0001387
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000049
[Epoch 113; Iter   286/ 1097] train: loss: 0.0000401
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000009
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000062
[Epoch 113; Iter   376/ 1097] train: loss: 0.0000293
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000023
[Epoch 113; Iter   436/ 1097] train: loss: 0.0023092
[Epoch 113; Iter   466/ 1097] train: loss: 0.0000026
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000021
[Epoch 113; Iter   526/ 1097] train: loss: 0.0001319
[Epoch 113; Iter   556/ 1097] train: loss: 0.0000223
[Epoch 113; Iter   586/ 1097] train: loss: 0.0006277
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000098
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000076
[Epoch 113; Iter   676/ 1097] train: loss: 0.0001687
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000093
[Epoch 109; Iter   744/ 1097] train: loss: 0.0010741
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000424
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000036
[Epoch 109; Iter   834/ 1097] train: loss: 0.0000104
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000002
[Epoch 109; Iter   894/ 1097] train: loss: 0.0011706
[Epoch 109; Iter   924/ 1097] train: loss: 0.0001034
[Epoch 109; Iter   954/ 1097] train: loss: 0.0000564
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000677
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0000421
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000010
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000841
[Epoch 109] ogbg-molhiv: 0.697617 val loss: 7.852546
[Epoch 109] ogbg-molhiv: 0.618789 test loss: 8.014004
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000032
[Epoch 110; Iter    37/ 1097] train: loss: 0.0000092
[Epoch 110; Iter    67/ 1097] train: loss: 0.0000021
[Epoch 110; Iter    97/ 1097] train: loss: 0.0000103
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000359
[Epoch 110; Iter   157/ 1097] train: loss: 0.0031393
[Epoch 110; Iter   187/ 1097] train: loss: 0.0003096
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000078
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000177
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000278
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000347
[Epoch 110; Iter   337/ 1097] train: loss: 0.0000109
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000020
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000015
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000004
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000006
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000015
[Epoch 110; Iter   517/ 1097] train: loss: 0.0001616
[Epoch 110; Iter   547/ 1097] train: loss: 0.0000005
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000194
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000042
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000003
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000598
[Epoch 110; Iter   697/ 1097] train: loss: 0.0000021
[Epoch 110; Iter   727/ 1097] train: loss: 0.0000096
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000053
[Epoch 110; Iter   787/ 1097] train: loss: 0.0000476
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000029
[Epoch 110; Iter   847/ 1097] train: loss: 0.0000048
[Epoch 110; Iter   877/ 1097] train: loss: 0.0000027
[Epoch 110; Iter   907/ 1097] train: loss: 0.0000453
[Epoch 110; Iter   937/ 1097] train: loss: 0.0002904
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000006
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000026
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000095
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0000870
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000013
[Epoch 110] ogbg-molhiv: 0.680078 val loss: 6.400290
[Epoch 110] ogbg-molhiv: 0.607414 test loss: 6.806200
[Epoch 111; Iter    20/ 1097] train: loss: 0.0000017
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000683
[Epoch 111; Iter    80/ 1097] train: loss: 0.0000156
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000001
[Epoch 111; Iter   140/ 1097] train: loss: 0.0000048
[Epoch 111; Iter   170/ 1097] train: loss: 0.0000058
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000309
[Epoch 111; Iter   230/ 1097] train: loss: 0.0000172
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000995
[Epoch 111; Iter   290/ 1097] train: loss: 0.0001943
[Epoch 111; Iter   320/ 1097] train: loss: 0.0005911
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000880
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000041
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000016
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000038
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000010
[Epoch 111; Iter   500/ 1097] train: loss: 0.0000018
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000083
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000039
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000161
[Epoch 111; Iter   620/ 1097] train: loss: 0.0004283
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000787
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000184
[Epoch 111; Iter   710/ 1097] train: loss: 0.0000053
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000015
[Epoch 111; Iter   770/ 1097] train: loss: 0.0001424
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000111
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000094
[Epoch 111; Iter   860/ 1097] train: loss: 0.0000543
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000001
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000073
[Epoch 111; Iter   950/ 1097] train: loss: 0.0002212
[Epoch 111; Iter   980/ 1097] train: loss: 0.0002442
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000016
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000412
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000051
[Epoch 111] ogbg-molhiv: 0.701499 val loss: 5.730036
[Epoch 111] ogbg-molhiv: 0.610124 test loss: 6.529858
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000041
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000022
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000225
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000081
[Epoch 112; Iter   123/ 1097] train: loss: 0.0001195
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000040
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000074
[Epoch 112; Iter   213/ 1097] train: loss: 0.0000439
[Epoch 112; Iter   243/ 1097] train: loss: 0.0000622
[Epoch 112; Iter   273/ 1097] train: loss: 0.0000085
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000009
[Epoch 112; Iter   333/ 1097] train: loss: 0.0000153
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000037
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000037
[Epoch 112; Iter   423/ 1097] train: loss: 0.0000008
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000001
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000242
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000041
[Epoch 112; Iter   543/ 1097] train: loss: 0.0006464
[Epoch 112; Iter   573/ 1097] train: loss: 0.0000794
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000045
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000151
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000437
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000002
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000015
[Epoch 112; Iter   753/ 1097] train: loss: 0.0001270
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000078
[Epoch 112; Iter   813/ 1097] train: loss: 0.0002058
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000017
[Epoch 112; Iter   873/ 1097] train: loss: 0.0007997
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000208
[Epoch 112; Iter   933/ 1097] train: loss: 0.0000117
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000032
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000018
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000328
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0002349
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0000068
[Epoch 112] ogbg-molhiv: 0.723713 val loss: 4.105597
[Epoch 112] ogbg-molhiv: 0.630684 test loss: 5.148112
[Epoch 113; Iter    16/ 1097] train: loss: 0.0005160
[Epoch 113; Iter    46/ 1097] train: loss: 0.0000299
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000160
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000474
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000067
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000018
[Epoch 113; Iter   196/ 1097] train: loss: 0.0000218
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000005
[Epoch 113; Iter   286/ 1097] train: loss: 0.0000048
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000545
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000147
[Epoch 113; Iter   376/ 1097] train: loss: 0.0000087
[Epoch 113; Iter   406/ 1097] train: loss: 0.0002436
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000016
[Epoch 113; Iter   466/ 1097] train: loss: 0.0000107
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000146
[Epoch 113; Iter   526/ 1097] train: loss: 0.0000016
[Epoch 113; Iter   556/ 1097] train: loss: 0.0001284
[Epoch 113; Iter   586/ 1097] train: loss: 0.0000724
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000583
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000133
[Epoch 113; Iter   676/ 1097] train: loss: 0.0000032
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000629
[Epoch 109; Iter   744/ 1097] train: loss: 0.0000135
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000025
[Epoch 109; Iter   804/ 1097] train: loss: 0.0003528
[Epoch 109; Iter   834/ 1097] train: loss: 0.0004987
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000223
[Epoch 109; Iter   894/ 1097] train: loss: 0.0000061
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000067
[Epoch 109; Iter   954/ 1097] train: loss: 0.0003023
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000487
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0003550
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0000119
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000392
[Epoch 109] ogbg-molhiv: 0.711221 val loss: 28.956716
[Epoch 109] ogbg-molhiv: 0.644883 test loss: 20.546344
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000254
[Epoch 110; Iter    37/ 1097] train: loss: 0.0034783
[Epoch 110; Iter    67/ 1097] train: loss: 0.0001819
[Epoch 110; Iter    97/ 1097] train: loss: 0.0004816
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000023
[Epoch 110; Iter   157/ 1097] train: loss: 0.0829512
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000083
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000155
[Epoch 110; Iter   247/ 1097] train: loss: 0.0000110
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000018
[Epoch 110; Iter   307/ 1097] train: loss: 0.0013608
[Epoch 110; Iter   337/ 1097] train: loss: 0.0002056
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000324
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000949
[Epoch 110; Iter   427/ 1097] train: loss: 0.0000038
[Epoch 110; Iter   457/ 1097] train: loss: 0.0001106
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000933
[Epoch 110; Iter   517/ 1097] train: loss: 0.0000184
[Epoch 110; Iter   547/ 1097] train: loss: 0.0001428
[Epoch 110; Iter   577/ 1097] train: loss: 0.0000149
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000090
[Epoch 110; Iter   637/ 1097] train: loss: 0.0002897
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000093
[Epoch 110; Iter   697/ 1097] train: loss: 0.0000331
[Epoch 110; Iter   727/ 1097] train: loss: 0.0026619
[Epoch 110; Iter   757/ 1097] train: loss: 0.0001675
[Epoch 110; Iter   787/ 1097] train: loss: 0.0009993
[Epoch 110; Iter   817/ 1097] train: loss: 0.0005333
[Epoch 110; Iter   847/ 1097] train: loss: 0.0004563
[Epoch 110; Iter   877/ 1097] train: loss: 0.0000343
[Epoch 110; Iter   907/ 1097] train: loss: 0.0001924
[Epoch 110; Iter   937/ 1097] train: loss: 0.0001259
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000819
[Epoch 110; Iter   997/ 1097] train: loss: 0.0005328
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000267
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0002132
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000051
[Epoch 110] ogbg-molhiv: 0.708104 val loss: 28.155880
[Epoch 110] ogbg-molhiv: 0.607951 test loss: 20.875770
[Epoch 111; Iter    20/ 1097] train: loss: 0.0020171
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000120
[Epoch 111; Iter    80/ 1097] train: loss: 0.0001473
[Epoch 111; Iter   110/ 1097] train: loss: 0.0000109
[Epoch 111; Iter   140/ 1097] train: loss: 0.0002557
[Epoch 111; Iter   170/ 1097] train: loss: 0.0003434
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000485
[Epoch 111; Iter   230/ 1097] train: loss: 0.0000036
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000146
[Epoch 111; Iter   290/ 1097] train: loss: 0.0037456
[Epoch 111; Iter   320/ 1097] train: loss: 0.0000073
[Epoch 111; Iter   350/ 1097] train: loss: 0.0002930
[Epoch 111; Iter   380/ 1097] train: loss: 0.0001225
[Epoch 111; Iter   410/ 1097] train: loss: 0.0000253
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000255
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000849
[Epoch 111; Iter   500/ 1097] train: loss: 0.0000690
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000056
[Epoch 111; Iter   560/ 1097] train: loss: 0.0043108
[Epoch 111; Iter   590/ 1097] train: loss: 0.0000068
[Epoch 111; Iter   620/ 1097] train: loss: 0.0014638
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000291
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000375
[Epoch 111; Iter   710/ 1097] train: loss: 0.0018394
[Epoch 111; Iter   740/ 1097] train: loss: 0.0068715
[Epoch 111; Iter   770/ 1097] train: loss: 0.0001985
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000149
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000353
[Epoch 111; Iter   860/ 1097] train: loss: 0.0005070
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000056
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000093
[Epoch 111; Iter   950/ 1097] train: loss: 0.0000026
[Epoch 111; Iter   980/ 1097] train: loss: 0.0009046
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000220
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0009322
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000886
[Epoch 111] ogbg-molhiv: 0.702797 val loss: 44.363863
[Epoch 111] ogbg-molhiv: 0.629045 test loss: 33.308130
[Epoch 112; Iter     3/ 1097] train: loss: 0.0001536
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000028
[Epoch 112; Iter    63/ 1097] train: loss: 0.0007193
[Epoch 112; Iter    93/ 1097] train: loss: 0.0001440
[Epoch 112; Iter   123/ 1097] train: loss: 0.0000279
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000017
[Epoch 112; Iter   183/ 1097] train: loss: 0.0047466
[Epoch 112; Iter   213/ 1097] train: loss: 0.0007656
[Epoch 112; Iter   243/ 1097] train: loss: 0.0017490
[Epoch 112; Iter   273/ 1097] train: loss: 0.0006114
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000717
[Epoch 112; Iter   333/ 1097] train: loss: 0.0750660
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000727
[Epoch 112; Iter   393/ 1097] train: loss: 0.0002866
[Epoch 112; Iter   423/ 1097] train: loss: 0.0000041
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000028
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000013
[Epoch 112; Iter   513/ 1097] train: loss: 0.0011851
[Epoch 112; Iter   543/ 1097] train: loss: 0.0719922
[Epoch 112; Iter   573/ 1097] train: loss: 0.0004932
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000185
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000015
[Epoch 112; Iter   663/ 1097] train: loss: 0.0001192
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000042
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000295
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000012
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000188
[Epoch 112; Iter   813/ 1097] train: loss: 0.0451472
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000091
[Epoch 112; Iter   873/ 1097] train: loss: 0.0719312
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000767
[Epoch 112; Iter   933/ 1097] train: loss: 0.0002493
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000354
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000259
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000046
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0000996
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0000183
[Epoch 112] ogbg-molhiv: 0.720700 val loss: 24.910009
[Epoch 112] ogbg-molhiv: 0.624444 test loss: 18.304122
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000049
[Epoch 113; Iter    46/ 1097] train: loss: 0.0268354
[Epoch 113; Iter    76/ 1097] train: loss: 0.0001207
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000915
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000082
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000137
[Epoch 113; Iter   196/ 1097] train: loss: 0.0017074
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000600
[Epoch 113; Iter   256/ 1097] train: loss: 0.0001479
[Epoch 113; Iter   286/ 1097] train: loss: 0.0000385
[Epoch 113; Iter   316/ 1097] train: loss: 0.0001085
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000017
[Epoch 113; Iter   376/ 1097] train: loss: 0.0235863
[Epoch 113; Iter   406/ 1097] train: loss: 0.0000060
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000116
[Epoch 113; Iter   466/ 1097] train: loss: 0.0024655
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000258
[Epoch 113; Iter   526/ 1097] train: loss: 0.0001913
[Epoch 113; Iter   556/ 1097] train: loss: 0.0009420
[Epoch 113; Iter   586/ 1097] train: loss: 0.0000266
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000239
[Epoch 113; Iter   646/ 1097] train: loss: 0.0006681
[Epoch 113; Iter   676/ 1097] train: loss: 0.0006069
[Epoch 109; Iter   714/ 1097] train: loss: 0.0000203
[Epoch 109; Iter   744/ 1097] train: loss: 0.0000468
[Epoch 109; Iter   774/ 1097] train: loss: 0.0000092
[Epoch 109; Iter   804/ 1097] train: loss: 0.0000002
[Epoch 109; Iter   834/ 1097] train: loss: 0.0001082
[Epoch 109; Iter   864/ 1097] train: loss: 0.0000921
[Epoch 109; Iter   894/ 1097] train: loss: 0.0000644
[Epoch 109; Iter   924/ 1097] train: loss: 0.0000003
[Epoch 109; Iter   954/ 1097] train: loss: 0.0000395
[Epoch 109; Iter   984/ 1097] train: loss: 0.0000039
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0314011
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0005370
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0000154
[Epoch 109] ogbg-molhiv: 0.731289 val loss: 0.897043
[Epoch 109] ogbg-molhiv: 0.713600 test loss: 1.739747
[Epoch 110; Iter     7/ 1097] train: loss: 0.0000184
[Epoch 110; Iter    37/ 1097] train: loss: 0.0000322
[Epoch 110; Iter    67/ 1097] train: loss: 0.0001745
[Epoch 110; Iter    97/ 1097] train: loss: 0.0331769
[Epoch 110; Iter   127/ 1097] train: loss: 0.0000048
[Epoch 110; Iter   157/ 1097] train: loss: 0.0000070
[Epoch 110; Iter   187/ 1097] train: loss: 0.0000167
[Epoch 110; Iter   217/ 1097] train: loss: 0.0000299
[Epoch 110; Iter   247/ 1097] train: loss: 0.0001195
[Epoch 110; Iter   277/ 1097] train: loss: 0.0000025
[Epoch 110; Iter   307/ 1097] train: loss: 0.0000024
[Epoch 110; Iter   337/ 1097] train: loss: 0.0000169
[Epoch 110; Iter   367/ 1097] train: loss: 0.0000003
[Epoch 110; Iter   397/ 1097] train: loss: 0.0000004
[Epoch 110; Iter   427/ 1097] train: loss: 0.0008631
[Epoch 110; Iter   457/ 1097] train: loss: 0.0000285
[Epoch 110; Iter   487/ 1097] train: loss: 0.0000038
[Epoch 110; Iter   517/ 1097] train: loss: 0.0000039
[Epoch 110; Iter   547/ 1097] train: loss: 0.0052066
[Epoch 110; Iter   577/ 1097] train: loss: 0.0001381
[Epoch 110; Iter   607/ 1097] train: loss: 0.0000100
[Epoch 110; Iter   637/ 1097] train: loss: 0.0000004
[Epoch 110; Iter   667/ 1097] train: loss: 0.0000267
[Epoch 110; Iter   697/ 1097] train: loss: 0.0000236
[Epoch 110; Iter   727/ 1097] train: loss: 0.0002240
[Epoch 110; Iter   757/ 1097] train: loss: 0.0000014
[Epoch 110; Iter   787/ 1097] train: loss: 0.0002724
[Epoch 110; Iter   817/ 1097] train: loss: 0.0000143
[Epoch 110; Iter   847/ 1097] train: loss: 0.0152278
[Epoch 110; Iter   877/ 1097] train: loss: 0.0003173
[Epoch 110; Iter   907/ 1097] train: loss: 0.0000343
[Epoch 110; Iter   937/ 1097] train: loss: 0.0000003
[Epoch 110; Iter   967/ 1097] train: loss: 0.0000520
[Epoch 110; Iter   997/ 1097] train: loss: 0.0000558
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0000031
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0000001
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0000006
[Epoch 110] ogbg-molhiv: 0.737592 val loss: 0.989948
[Epoch 110] ogbg-molhiv: 0.720209 test loss: 1.571477
[Epoch 111; Iter    20/ 1097] train: loss: 0.0002177
[Epoch 111; Iter    50/ 1097] train: loss: 0.0000015
[Epoch 111; Iter    80/ 1097] train: loss: 0.0000096
[Epoch 111; Iter   110/ 1097] train: loss: 0.0003058
[Epoch 111; Iter   140/ 1097] train: loss: 0.0001368
[Epoch 111; Iter   170/ 1097] train: loss: 0.0001435
[Epoch 111; Iter   200/ 1097] train: loss: 0.0000908
[Epoch 111; Iter   230/ 1097] train: loss: 0.0000041
[Epoch 111; Iter   260/ 1097] train: loss: 0.0000120
[Epoch 111; Iter   290/ 1097] train: loss: 0.0000980
[Epoch 111; Iter   320/ 1097] train: loss: 0.0000390
[Epoch 111; Iter   350/ 1097] train: loss: 0.0000084
[Epoch 111; Iter   380/ 1097] train: loss: 0.0000012
[Epoch 111; Iter   410/ 1097] train: loss: 0.0003988
[Epoch 111; Iter   440/ 1097] train: loss: 0.0000144
[Epoch 111; Iter   470/ 1097] train: loss: 0.0000105
[Epoch 111; Iter   500/ 1097] train: loss: 0.0000028
[Epoch 111; Iter   530/ 1097] train: loss: 0.0000044
[Epoch 111; Iter   560/ 1097] train: loss: 0.0000018
[Epoch 111; Iter   590/ 1097] train: loss: 0.0001096
[Epoch 111; Iter   620/ 1097] train: loss: 0.0002160
[Epoch 111; Iter   650/ 1097] train: loss: 0.0000138
[Epoch 111; Iter   680/ 1097] train: loss: 0.0000028
[Epoch 111; Iter   710/ 1097] train: loss: 0.0001182
[Epoch 111; Iter   740/ 1097] train: loss: 0.0000040
[Epoch 111; Iter   770/ 1097] train: loss: 0.0022936
[Epoch 111; Iter   800/ 1097] train: loss: 0.0000599
[Epoch 111; Iter   830/ 1097] train: loss: 0.0000021
[Epoch 111; Iter   860/ 1097] train: loss: 0.0001778
[Epoch 111; Iter   890/ 1097] train: loss: 0.0000003
[Epoch 111; Iter   920/ 1097] train: loss: 0.0000001
[Epoch 111; Iter   950/ 1097] train: loss: 0.0000121
[Epoch 111; Iter   980/ 1097] train: loss: 0.0000008
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0000040
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0000466
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0000205
[Epoch 111] ogbg-molhiv: 0.784333 val loss: 1.062460
[Epoch 111] ogbg-molhiv: 0.720522 test loss: 1.917303
[Epoch 112; Iter     3/ 1097] train: loss: 0.0000091
[Epoch 112; Iter    33/ 1097] train: loss: 0.0000129
[Epoch 112; Iter    63/ 1097] train: loss: 0.0000246
[Epoch 112; Iter    93/ 1097] train: loss: 0.0000065
[Epoch 112; Iter   123/ 1097] train: loss: 0.0000043
[Epoch 112; Iter   153/ 1097] train: loss: 0.0000029
[Epoch 112; Iter   183/ 1097] train: loss: 0.0000188
[Epoch 112; Iter   213/ 1097] train: loss: 0.0003932
[Epoch 112; Iter   243/ 1097] train: loss: 0.0341294
[Epoch 112; Iter   273/ 1097] train: loss: 0.0001452
[Epoch 112; Iter   303/ 1097] train: loss: 0.0000002
[Epoch 112; Iter   333/ 1097] train: loss: 0.0001498
[Epoch 112; Iter   363/ 1097] train: loss: 0.0000033
[Epoch 112; Iter   393/ 1097] train: loss: 0.0000070
[Epoch 112; Iter   423/ 1097] train: loss: 0.0003398
[Epoch 112; Iter   453/ 1097] train: loss: 0.0000012
[Epoch 112; Iter   483/ 1097] train: loss: 0.0000168
[Epoch 112; Iter   513/ 1097] train: loss: 0.0000002
[Epoch 112; Iter   543/ 1097] train: loss: 0.0000131
[Epoch 112; Iter   573/ 1097] train: loss: 0.0000063
[Epoch 112; Iter   603/ 1097] train: loss: 0.0000306
[Epoch 112; Iter   633/ 1097] train: loss: 0.0000035
[Epoch 112; Iter   663/ 1097] train: loss: 0.0000020
[Epoch 112; Iter   693/ 1097] train: loss: 0.0000196
[Epoch 112; Iter   723/ 1097] train: loss: 0.0000025
[Epoch 112; Iter   753/ 1097] train: loss: 0.0000078
[Epoch 112; Iter   783/ 1097] train: loss: 0.0000141
[Epoch 112; Iter   813/ 1097] train: loss: 0.0000147
[Epoch 112; Iter   843/ 1097] train: loss: 0.0000787
[Epoch 112; Iter   873/ 1097] train: loss: 0.0010650
[Epoch 112; Iter   903/ 1097] train: loss: 0.0000089
[Epoch 112; Iter   933/ 1097] train: loss: 0.0000409
[Epoch 112; Iter   963/ 1097] train: loss: 0.0000018
[Epoch 112; Iter   993/ 1097] train: loss: 0.0000111
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0000002
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0000435
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0001353
[Epoch 112] ogbg-molhiv: 0.735355 val loss: 8.807009
[Epoch 112] ogbg-molhiv: 0.671873 test loss: 7.353919
[Epoch 113; Iter    16/ 1097] train: loss: 0.0000741
[Epoch 113; Iter    46/ 1097] train: loss: 0.0000290
[Epoch 113; Iter    76/ 1097] train: loss: 0.0000053
[Epoch 113; Iter   106/ 1097] train: loss: 0.0000240
[Epoch 113; Iter   136/ 1097] train: loss: 0.0000151
[Epoch 113; Iter   166/ 1097] train: loss: 0.0000209
[Epoch 113; Iter   196/ 1097] train: loss: 0.0000086
[Epoch 113; Iter   226/ 1097] train: loss: 0.0000073
[Epoch 113; Iter   256/ 1097] train: loss: 0.0000004
[Epoch 113; Iter   286/ 1097] train: loss: 0.0003780
[Epoch 113; Iter   316/ 1097] train: loss: 0.0000002
[Epoch 113; Iter   346/ 1097] train: loss: 0.0000286
[Epoch 113; Iter   376/ 1097] train: loss: 0.0000087
[Epoch 113; Iter   406/ 1097] train: loss: 0.0069219
[Epoch 113; Iter   436/ 1097] train: loss: 0.0000853
[Epoch 113; Iter   466/ 1097] train: loss: 0.0000469
[Epoch 113; Iter   496/ 1097] train: loss: 0.0000184
[Epoch 113; Iter   526/ 1097] train: loss: 0.0000544
[Epoch 113; Iter   556/ 1097] train: loss: 0.0000420
[Epoch 113; Iter   586/ 1097] train: loss: 0.0000007
[Epoch 113; Iter   616/ 1097] train: loss: 0.0000658
[Epoch 113; Iter   646/ 1097] train: loss: 0.0000045
[Epoch 113; Iter   676/ 1097] train: loss: 0.0000034
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000320
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000961
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000164
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000115
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000586
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000427
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000506
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000004
[Epoch 113; Iter   946/ 1097] train: loss: 0.0000258
[Epoch 113; Iter   976/ 1097] train: loss: 0.0066822
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000221
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000628
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0035373
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000269
[Epoch 113] ogbg-molhiv: 0.752097 val loss: 0.711951
[Epoch 113] ogbg-molhiv: 0.719332 test loss: 1.014316
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000275
[Epoch 114; Iter    59/ 1097] train: loss: 0.0001035
[Epoch 114; Iter    89/ 1097] train: loss: 0.0005990
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000819
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000122
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000038
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000767
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000567
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000019
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000491
[Epoch 114; Iter   329/ 1097] train: loss: 0.0012255
[Epoch 114; Iter   359/ 1097] train: loss: 0.0002438
[Epoch 114; Iter   389/ 1097] train: loss: 0.0011440
[Epoch 114; Iter   419/ 1097] train: loss: 0.0012655
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000149
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000332
[Epoch 114; Iter   509/ 1097] train: loss: 0.0000187
[Epoch 114; Iter   539/ 1097] train: loss: 0.0001105
[Epoch 114; Iter   569/ 1097] train: loss: 0.0000062
[Epoch 114; Iter   599/ 1097] train: loss: 0.0066504
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000427
[Epoch 114; Iter   659/ 1097] train: loss: 0.0001014
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000245
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000088
[Epoch 114; Iter   749/ 1097] train: loss: 0.0002979
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000600
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000243
[Epoch 114; Iter   839/ 1097] train: loss: 0.0064155
[Epoch 114; Iter   869/ 1097] train: loss: 0.0015056
[Epoch 114; Iter   899/ 1097] train: loss: 0.0009377
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000484
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000032
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000078
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000013
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000033
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000039
[Epoch 114] ogbg-molhiv: 0.768959 val loss: 0.758849
[Epoch 114] ogbg-molhiv: 0.722098 test loss: 1.222740
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000087
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000011
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000453
[Epoch 115; Iter   102/ 1097] train: loss: 0.0030165
[Epoch 115; Iter   132/ 1097] train: loss: 0.0000200
[Epoch 115; Iter   162/ 1097] train: loss: 0.0013777
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000190
[Epoch 115; Iter   222/ 1097] train: loss: 0.0001056
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000859
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000006
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000192
[Epoch 115; Iter   342/ 1097] train: loss: 0.0003689
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000447
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000503
[Epoch 115; Iter   432/ 1097] train: loss: 0.0004284
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000018
[Epoch 115; Iter   492/ 1097] train: loss: 0.0000049
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000058
[Epoch 115; Iter   552/ 1097] train: loss: 0.0000096
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000003
[Epoch 115; Iter   612/ 1097] train: loss: 0.0029362
[Epoch 115; Iter   642/ 1097] train: loss: 0.0001165
[Epoch 115; Iter   672/ 1097] train: loss: 0.0000153
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000099
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000051
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000418
[Epoch 115; Iter   792/ 1097] train: loss: 0.0005770
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000919
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000781
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000028
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000246
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000217
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000248
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000023
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0000897
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0001238
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000225
[Epoch 115] ogbg-molhiv: 0.771611 val loss: 0.647077
[Epoch 115] ogbg-molhiv: 0.735134 test loss: 1.129066
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000011
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000048
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000005
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000070
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000247
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000896
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000110
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000206
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000067
[Epoch 116; Iter   295/ 1097] train: loss: 0.0003570
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000128
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000301
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000149
[Epoch 116; Iter   415/ 1097] train: loss: 0.0002840
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000036
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000276
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000035
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000389
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000004
[Epoch 116; Iter   595/ 1097] train: loss: 0.0000116
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000031
[Epoch 116; Iter   655/ 1097] train: loss: 0.0004566
[Epoch 116; Iter   685/ 1097] train: loss: 0.0001848
[Epoch 116; Iter   715/ 1097] train: loss: 0.0002956
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000282
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000998
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000115
[Epoch 116; Iter   835/ 1097] train: loss: 0.0014072
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000039
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000096
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000217
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000047
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000788
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0001330
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000266
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0001906
[Epoch 116] ogbg-molhiv: 0.758763 val loss: 0.759364
[Epoch 116] ogbg-molhiv: 0.724017 test loss: 1.125381
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000802
[Epoch 117; Iter    38/ 1097] train: loss: 0.0021202
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000153
[Epoch 117; Iter    98/ 1097] train: loss: 0.0016567
[Epoch 117; Iter   128/ 1097] train: loss: 0.0003572
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000371
[Epoch 117; Iter   188/ 1097] train: loss: 0.0002283
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000381
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000241
[Epoch 117; Iter   278/ 1097] train: loss: 0.0003308
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000842
[Epoch 117; Iter   338/ 1097] train: loss: 0.0000013
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000635
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000261
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000092
[Epoch 117; Iter   458/ 1097] train: loss: 0.0001688
[Epoch 117; Iter   488/ 1097] train: loss: 0.0006736
[Epoch 117; Iter   518/ 1097] train: loss: 0.0002088
[Epoch 117; Iter   548/ 1097] train: loss: 0.0011162
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000227
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000922
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000332
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000085
[Epoch 113; Iter   706/ 1097] train: loss: 0.0012359
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   766/ 1097] train: loss: 0.0006231
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000050
[Epoch 113; Iter   826/ 1097] train: loss: 0.0001177
[Epoch 113; Iter   856/ 1097] train: loss: 0.0018088
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000036
[Epoch 113; Iter   916/ 1097] train: loss: 0.0004912
[Epoch 113; Iter   946/ 1097] train: loss: 0.0001424
[Epoch 113; Iter   976/ 1097] train: loss: 0.0001396
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0002944
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000047
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0000006
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000009
[Epoch 113] ogbg-molhiv: 0.782634 val loss: 0.255588
[Epoch 113] ogbg-molhiv: 0.724307 test loss: 0.427368
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000088
[Epoch 114; Iter    59/ 1097] train: loss: 0.0000017
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000236
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000087
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000006
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000007
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000589
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000038
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000097
[Epoch 114; Iter   299/ 1097] train: loss: 0.0001270
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000083
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000502
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000084
[Epoch 114; Iter   419/ 1097] train: loss: 0.0003024
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000190
[Epoch 114; Iter   479/ 1097] train: loss: 0.0001203
[Epoch 114; Iter   509/ 1097] train: loss: 0.0083045
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000170
[Epoch 114; Iter   569/ 1097] train: loss: 0.0000060
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000024
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000035
[Epoch 114; Iter   659/ 1097] train: loss: 0.0000692
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000481
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000952
[Epoch 114; Iter   749/ 1097] train: loss: 0.0000344
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000900
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000037
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000010
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000074
[Epoch 114; Iter   899/ 1097] train: loss: 0.0008438
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000229
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000454
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000332
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000024
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000029
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0001214
[Epoch 114] ogbg-molhiv: 0.777453 val loss: 0.248547
[Epoch 114] ogbg-molhiv: 0.720790 test loss: 0.423778
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000184
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000012
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000007
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000727
[Epoch 115; Iter   132/ 1097] train: loss: 0.0002950
[Epoch 115; Iter   162/ 1097] train: loss: 0.0001006
[Epoch 115; Iter   192/ 1097] train: loss: 0.0005583
[Epoch 115; Iter   222/ 1097] train: loss: 0.0000122
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000016
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000027
[Epoch 115; Iter   312/ 1097] train: loss: 0.0002553
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000150
[Epoch 115; Iter   372/ 1097] train: loss: 0.0008456
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000049
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000397
[Epoch 115; Iter   462/ 1097] train: loss: 0.0007656
[Epoch 115; Iter   492/ 1097] train: loss: 0.0004629
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000167
[Epoch 115; Iter   552/ 1097] train: loss: 0.0000063
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000569
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000242
[Epoch 115; Iter   642/ 1097] train: loss: 0.0025491
[Epoch 115; Iter   672/ 1097] train: loss: 0.0000135
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000106
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000082
[Epoch 115; Iter   762/ 1097] train: loss: 0.0054329
[Epoch 115; Iter   792/ 1097] train: loss: 0.0000002
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000030
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000018
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000434
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000123
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000639
[Epoch 115; Iter   972/ 1097] train: loss: 0.0002167
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000035
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0000054
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0001308
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000953
[Epoch 115] ogbg-molhiv: 0.772202 val loss: 0.258753
[Epoch 115] ogbg-molhiv: 0.712302 test loss: 0.435095
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000033
[Epoch 116; Iter    55/ 1097] train: loss: 0.0013593
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000873
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000384
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000255
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000486
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000011
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000260
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000001
[Epoch 116; Iter   295/ 1097] train: loss: 0.0004092
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000902
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000010
[Epoch 116; Iter   385/ 1097] train: loss: 0.0005518
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000132
[Epoch 116; Iter   445/ 1097] train: loss: 0.0001505
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000027
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000082
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000972
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000207
[Epoch 116; Iter   595/ 1097] train: loss: 0.0011569
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000054
[Epoch 116; Iter   655/ 1097] train: loss: 0.0411224
[Epoch 116; Iter   685/ 1097] train: loss: 0.0003748
[Epoch 116; Iter   715/ 1097] train: loss: 0.0005549
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000470
[Epoch 116; Iter   775/ 1097] train: loss: 0.0002191
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000123
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000176
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000023
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000381
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000815
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000016
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000860
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0001210
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000184
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000567
[Epoch 116] ogbg-molhiv: 0.777000 val loss: 0.251935
[Epoch 116] ogbg-molhiv: 0.715161 test loss: 0.421836
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000016
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000519
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000079
[Epoch 117; Iter    98/ 1097] train: loss: 0.0003412
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000222
[Epoch 117; Iter   158/ 1097] train: loss: 0.0001802
[Epoch 117; Iter   188/ 1097] train: loss: 0.0010778
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000061
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000838
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000346
[Epoch 117; Iter   308/ 1097] train: loss: 0.0022055
[Epoch 117; Iter   338/ 1097] train: loss: 0.0003925
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000477
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000358
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000167
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000021
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000064
[Epoch 117; Iter   518/ 1097] train: loss: 0.0000047
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000213
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000476
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000156
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000046
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000053
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000296
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000285
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000205
[Epoch 113; Iter   796/ 1097] train: loss: 0.0128038
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000110
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000014
[Epoch 113; Iter   886/ 1097] train: loss: 0.0002391
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000302
[Epoch 113; Iter   946/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   976/ 1097] train: loss: 0.0004864
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000218
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0005587
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0000106
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000426
[Epoch 113] ogbg-molhiv: 0.696683 val loss: 1.789963
[Epoch 113] ogbg-molhiv: 0.716470 test loss: 0.990700
[Epoch 114; Iter    29/ 1097] train: loss: 0.0004671
[Epoch 114; Iter    59/ 1097] train: loss: 0.0007981
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000468
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000025
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000529
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000069
[Epoch 114; Iter   209/ 1097] train: loss: 0.0001318
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000604
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000083
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000138
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000177
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000167
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000016
[Epoch 114; Iter   419/ 1097] train: loss: 0.0072994
[Epoch 114; Iter   449/ 1097] train: loss: 0.0273517
[Epoch 114; Iter   479/ 1097] train: loss: 0.0001061
[Epoch 114; Iter   509/ 1097] train: loss: 0.0000033
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000213
[Epoch 114; Iter   569/ 1097] train: loss: 0.0000734
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000860
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000029
[Epoch 114; Iter   659/ 1097] train: loss: 0.0000132
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000054
[Epoch 114; Iter   719/ 1097] train: loss: 0.0009392
[Epoch 114; Iter   749/ 1097] train: loss: 0.0001011
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000019
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000025
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000417
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000026
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000237
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000016
[Epoch 114; Iter   959/ 1097] train: loss: 0.0002328
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000131
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000401
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000188
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000147
[Epoch 114] ogbg-molhiv: 0.695743 val loss: 1.877474
[Epoch 114] ogbg-molhiv: 0.705004 test loss: 0.746881
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000814
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000090
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000082
[Epoch 115; Iter   102/ 1097] train: loss: 0.0011941
[Epoch 115; Iter   132/ 1097] train: loss: 0.0000194
[Epoch 115; Iter   162/ 1097] train: loss: 0.0011061
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000068
[Epoch 115; Iter   222/ 1097] train: loss: 0.0001154
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000289
[Epoch 115; Iter   282/ 1097] train: loss: 0.0001735
[Epoch 115; Iter   312/ 1097] train: loss: 0.0014645
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000201
[Epoch 115; Iter   372/ 1097] train: loss: 0.0001445
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000938
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000035
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000160
[Epoch 115; Iter   492/ 1097] train: loss: 0.0001000
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000588
[Epoch 115; Iter   552/ 1097] train: loss: 0.0002365
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000142
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000013
[Epoch 115; Iter   642/ 1097] train: loss: 0.0005518
[Epoch 115; Iter   672/ 1097] train: loss: 0.0017681
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000011
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000013
[Epoch 115; Iter   762/ 1097] train: loss: 0.0006652
[Epoch 115; Iter   792/ 1097] train: loss: 0.0000585
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000244
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000182
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000330
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000505
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000628
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000008
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000059
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0011903
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0002684
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0001087
[Epoch 115] ogbg-molhiv: 0.694190 val loss: 1.910803
[Epoch 115] ogbg-molhiv: 0.685052 test loss: 0.923589
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000839
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000035
[Epoch 116; Iter    85/ 1097] train: loss: 0.0115713
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000879
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000007
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000036
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000178
[Epoch 116; Iter   235/ 1097] train: loss: 0.0008403
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000008
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000511
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000274
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000066
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000035
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000296
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000281
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000053
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000189
[Epoch 116; Iter   535/ 1097] train: loss: 0.0001217
[Epoch 116; Iter   565/ 1097] train: loss: 0.0003741
[Epoch 116; Iter   595/ 1097] train: loss: 0.0000701
[Epoch 116; Iter   625/ 1097] train: loss: 0.0023906
[Epoch 116; Iter   655/ 1097] train: loss: 0.0197552
[Epoch 116; Iter   685/ 1097] train: loss: 0.0005643
[Epoch 116; Iter   715/ 1097] train: loss: 0.0001012
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000012
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000709
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000018
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000285
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000921
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000288
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000305
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000286
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000158
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0001008
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000121
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000085
[Epoch 116] ogbg-molhiv: 0.698125 val loss: 2.181480
[Epoch 116] ogbg-molhiv: 0.670133 test loss: 1.042480
[Epoch 117; Iter     8/ 1097] train: loss: 0.0016436
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000038
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000060
[Epoch 117; Iter    98/ 1097] train: loss: 0.0001142
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000591
[Epoch 117; Iter   158/ 1097] train: loss: 0.0007395
[Epoch 117; Iter   188/ 1097] train: loss: 0.0000903
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000172
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000548
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000116
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000320
[Epoch 117; Iter   338/ 1097] train: loss: 0.0001977
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000006
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000103
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000825
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000019
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000036
[Epoch 117; Iter   518/ 1097] train: loss: 0.0000080
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000066
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000371
[Epoch 117; Iter   608/ 1097] train: loss: 0.0001167
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000058
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000031
[Epoch 113; Iter   706/ 1097] train: loss: 0.0001601
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000138
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000041
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000102
[Epoch 113; Iter   826/ 1097] train: loss: 0.0001952
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000718
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000065
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000475
[Epoch 113; Iter   946/ 1097] train: loss: 0.0000009
[Epoch 113; Iter   976/ 1097] train: loss: 0.0000851
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000713
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000267
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0000154
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000480
[Epoch 113] ogbg-molhiv: 0.763984 val loss: 0.429644
[Epoch 113] ogbg-molhiv: 0.746940 test loss: 0.399252
[Epoch 114; Iter    29/ 1097] train: loss: 0.0005355
[Epoch 114; Iter    59/ 1097] train: loss: 0.0001161
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000002
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000825
[Epoch 114; Iter   149/ 1097] train: loss: 0.0001138
[Epoch 114; Iter   179/ 1097] train: loss: 0.0001462
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000060
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000154
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000031
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000576
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000153
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000068
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000685
[Epoch 114; Iter   419/ 1097] train: loss: 0.0000298
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000432
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000188
[Epoch 114; Iter   509/ 1097] train: loss: 0.0001144
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000109
[Epoch 114; Iter   569/ 1097] train: loss: 0.0005692
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000064
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000444
[Epoch 114; Iter   659/ 1097] train: loss: 0.0005015
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000662
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000002
[Epoch 114; Iter   749/ 1097] train: loss: 0.0000550
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000553
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000043
[Epoch 114; Iter   839/ 1097] train: loss: 0.0004879
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000079
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000169
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000071
[Epoch 114; Iter   959/ 1097] train: loss: 0.0001251
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000193
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000097
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0069284
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000106
[Epoch 114] ogbg-molhiv: 0.772689 val loss: 0.437551
[Epoch 114] ogbg-molhiv: 0.753871 test loss: 0.406592
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000045
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000251
[Epoch 115; Iter    72/ 1097] train: loss: 0.0007828
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000602
[Epoch 115; Iter   132/ 1097] train: loss: 0.0001006
[Epoch 115; Iter   162/ 1097] train: loss: 0.0000070
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000082
[Epoch 115; Iter   222/ 1097] train: loss: 0.0002904
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000006
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000474
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000052
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000032
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000061
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000058
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000174
[Epoch 115; Iter   462/ 1097] train: loss: 0.0017536
[Epoch 115; Iter   492/ 1097] train: loss: 0.0000163
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000071
[Epoch 115; Iter   552/ 1097] train: loss: 0.0001923
[Epoch 115; Iter   582/ 1097] train: loss: 0.0008362
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000049
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000171
[Epoch 115; Iter   672/ 1097] train: loss: 0.0689010
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000020
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000139
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000089
[Epoch 115; Iter   792/ 1097] train: loss: 0.0000040
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000109
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000129
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000238
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000040
[Epoch 115; Iter   942/ 1097] train: loss: 0.0001097
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000768
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000003
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0000765
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0000419
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000372
[Epoch 115] ogbg-molhiv: 0.767676 val loss: 0.421707
[Epoch 115] ogbg-molhiv: 0.743216 test loss: 0.407803
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000210
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000840
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000273
[Epoch 116; Iter   115/ 1097] train: loss: 0.0003142
[Epoch 116; Iter   145/ 1097] train: loss: 0.0058471
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000986
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000822
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000859
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000468
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000831
[Epoch 116; Iter   325/ 1097] train: loss: 0.0003819
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000078
[Epoch 116; Iter   385/ 1097] train: loss: 0.0011815
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000009
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000030
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000502
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000116
[Epoch 116; Iter   535/ 1097] train: loss: 0.0004621
[Epoch 116; Iter   565/ 1097] train: loss: 0.0001122
[Epoch 116; Iter   595/ 1097] train: loss: 0.0039191
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000885
[Epoch 116; Iter   655/ 1097] train: loss: 0.0007761
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000073
[Epoch 116; Iter   715/ 1097] train: loss: 0.0001288
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000284
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000099
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000062
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000813
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000105
[Epoch 116; Iter   895/ 1097] train: loss: 0.0003094
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000005
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000948
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000223
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0000016
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000065
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000102
[Epoch 116] ogbg-molhiv: 0.768280 val loss: 0.417598
[Epoch 116] ogbg-molhiv: 0.745588 test loss: 0.399955
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000522
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000510
[Epoch 117; Iter    68/ 1097] train: loss: 0.0003859
[Epoch 117; Iter    98/ 1097] train: loss: 0.0000108
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000121
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000928
[Epoch 117; Iter   188/ 1097] train: loss: 0.0000086
[Epoch 117; Iter   218/ 1097] train: loss: 0.0004428
[Epoch 117; Iter   248/ 1097] train: loss: 0.0002198
[Epoch 117; Iter   278/ 1097] train: loss: 0.0006532
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000761
[Epoch 117; Iter   338/ 1097] train: loss: 0.0009655
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000207
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000095
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000692
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000433
[Epoch 117; Iter   488/ 1097] train: loss: 0.0001266
[Epoch 117; Iter   518/ 1097] train: loss: 0.0001159
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000015
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000188
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000191
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000539
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000024
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000047
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000102
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000521
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000012
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000045
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000137
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000066
[Epoch 113; Iter   916/ 1097] train: loss: 0.0001657
[Epoch 113; Iter   946/ 1097] train: loss: 0.0001158
[Epoch 113; Iter   976/ 1097] train: loss: 0.0000051
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000075
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000255
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0002428
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000245
[Epoch 113] ogbg-molhiv: 0.784845 val loss: 0.284841
[Epoch 113] ogbg-molhiv: 0.735549 test loss: 0.424171
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000288
[Epoch 114; Iter    59/ 1097] train: loss: 0.0000059
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000026
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000094
[Epoch 114; Iter   149/ 1097] train: loss: 0.0017081
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000696
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000050
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000003
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000043
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000099
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000084
[Epoch 114; Iter   359/ 1097] train: loss: 0.0002193
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000577
[Epoch 114; Iter   419/ 1097] train: loss: 0.0000020
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000071
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000307
[Epoch 114; Iter   509/ 1097] train: loss: 0.0000079
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000084
[Epoch 114; Iter   569/ 1097] train: loss: 0.0001800
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000128
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000849
[Epoch 114; Iter   659/ 1097] train: loss: 0.0000084
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000594
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000303
[Epoch 114; Iter   749/ 1097] train: loss: 0.0026274
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000709
[Epoch 114; Iter   809/ 1097] train: loss: 0.0001721
[Epoch 114; Iter   839/ 1097] train: loss: 0.0063486
[Epoch 114; Iter   869/ 1097] train: loss: 0.0017616
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000205
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000410
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000607
[Epoch 114; Iter   989/ 1097] train: loss: 0.0001491
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000265
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000312
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000046
[Epoch 114] ogbg-molhiv: 0.792426 val loss: 0.288004
[Epoch 114] ogbg-molhiv: 0.742087 test loss: 0.427728
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000186
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000008
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000496
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000330
[Epoch 115; Iter   132/ 1097] train: loss: 0.0001313
[Epoch 115; Iter   162/ 1097] train: loss: 0.0017948
[Epoch 115; Iter   192/ 1097] train: loss: 0.0003684
[Epoch 115; Iter   222/ 1097] train: loss: 0.0000180
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000743
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000014
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000019
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000043
[Epoch 115; Iter   372/ 1097] train: loss: 0.0001876
[Epoch 115; Iter   402/ 1097] train: loss: 0.0002603
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000246
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000051
[Epoch 115; Iter   492/ 1097] train: loss: 0.0000181
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000075
[Epoch 115; Iter   552/ 1097] train: loss: 0.0009511
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000382
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000306
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000036
[Epoch 115; Iter   672/ 1097] train: loss: 0.0000016
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000022
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000724
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000160
[Epoch 115; Iter   792/ 1097] train: loss: 0.0000598
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000346
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000009
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000289
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000166
[Epoch 115; Iter   942/ 1097] train: loss: 0.0004474
[Epoch 115; Iter   972/ 1097] train: loss: 0.0008702
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000644
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0001319
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0000719
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000129
[Epoch 115] ogbg-molhiv: 0.784355 val loss: 0.263879
[Epoch 115] ogbg-molhiv: 0.729180 test loss: 0.446478
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000064
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000135
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000065
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000175
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000831
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000033
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000025
[Epoch 116; Iter   235/ 1097] train: loss: 0.0001158
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000610
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000025
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000012
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000126
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000792
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000353
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000610
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000701
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000230
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000831
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000016
[Epoch 116; Iter   595/ 1097] train: loss: 0.0001251
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000009
[Epoch 116; Iter   655/ 1097] train: loss: 0.0000718
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000071
[Epoch 116; Iter   715/ 1097] train: loss: 0.0000322
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000114
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000221
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000013
[Epoch 116; Iter   835/ 1097] train: loss: 0.0001247
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000449
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000056
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000221
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000053
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000482
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0000892
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000022
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0006813
[Epoch 116] ogbg-molhiv: 0.797010 val loss: 0.292147
[Epoch 116] ogbg-molhiv: 0.738031 test loss: 0.476366
[Epoch 117; Iter     8/ 1097] train: loss: 0.0073992
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000092
[Epoch 117; Iter    68/ 1097] train: loss: 0.0008835
[Epoch 117; Iter    98/ 1097] train: loss: 0.0000640
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000092
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000071
[Epoch 117; Iter   188/ 1097] train: loss: 0.0000109
[Epoch 117; Iter   218/ 1097] train: loss: 0.0001236
[Epoch 117; Iter   248/ 1097] train: loss: 0.0002666
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000116
[Epoch 117; Iter   308/ 1097] train: loss: 0.0004141
[Epoch 117; Iter   338/ 1097] train: loss: 0.0000074
[Epoch 117; Iter   368/ 1097] train: loss: 0.0001424
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000023
[Epoch 117; Iter   428/ 1097] train: loss: 0.0002387
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000784
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000093
[Epoch 117; Iter   518/ 1097] train: loss: 0.0001142
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000020
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000033
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000729
[Epoch 117; Iter   638/ 1097] train: loss: 0.0005429
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000015
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000084
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000897
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000126
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000012
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000081
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000002
[Epoch 113; Iter   886/ 1097] train: loss: 0.0001065
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000084
[Epoch 113; Iter   946/ 1097] train: loss: 0.0000073
[Epoch 113; Iter   976/ 1097] train: loss: 0.0000298
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000010
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000014
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0002349
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000012
[Epoch 113] ogbg-molhiv: 0.793605 val loss: 0.439774
[Epoch 113] ogbg-molhiv: 0.803430 test loss: 0.352533
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000528
[Epoch 114; Iter    59/ 1097] train: loss: 0.0000950
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000010
[Epoch 114; Iter   119/ 1097] train: loss: 0.0002836
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000076
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000289
[Epoch 114; Iter   209/ 1097] train: loss: 0.0002213
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000054
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000006
[Epoch 114; Iter   299/ 1097] train: loss: 0.0001321
[Epoch 114; Iter   329/ 1097] train: loss: 0.0004670
[Epoch 114; Iter   359/ 1097] train: loss: 0.0001217
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000160
[Epoch 114; Iter   419/ 1097] train: loss: 0.0000860
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000370
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000733
[Epoch 114; Iter   509/ 1097] train: loss: 0.0000004
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000142
[Epoch 114; Iter   569/ 1097] train: loss: 0.0000061
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000035
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000238
[Epoch 114; Iter   659/ 1097] train: loss: 0.0000201
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000708
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000392
[Epoch 114; Iter   749/ 1097] train: loss: 0.0000055
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000015
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000043
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000088
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000030
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000115
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000707
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000262
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000919
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000019
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000106
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000085
[Epoch 114] ogbg-molhiv: 0.794135 val loss: 0.334108
[Epoch 114] ogbg-molhiv: 0.797675 test loss: 0.362864
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000010
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000087
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000163
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000278
[Epoch 115; Iter   132/ 1097] train: loss: 0.0000147
[Epoch 115; Iter   162/ 1097] train: loss: 0.0000064
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000039
[Epoch 115; Iter   222/ 1097] train: loss: 0.0000589
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000266
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000087
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000005
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000172
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000292
[Epoch 115; Iter   402/ 1097] train: loss: 0.0008429
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000182
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000004
[Epoch 115; Iter   492/ 1097] train: loss: 0.0000067
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000219
[Epoch 115; Iter   552/ 1097] train: loss: 0.0000027
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000030
[Epoch 115; Iter   612/ 1097] train: loss: 0.0002560
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000014
[Epoch 115; Iter   672/ 1097] train: loss: 0.0000536
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000024
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000049
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000345
[Epoch 115; Iter   792/ 1097] train: loss: 0.0007318
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000091
[Epoch 115; Iter   852/ 1097] train: loss: 0.0070815
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000022
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000014
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000006
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000679
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000003
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0001827
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0001407
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000068
[Epoch 115] ogbg-molhiv: 0.798675 val loss: 0.283779
[Epoch 115] ogbg-molhiv: 0.808729 test loss: 0.354273
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000217
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000671
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000159
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000902
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000137
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000051
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000103
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000013
[Epoch 116; Iter   265/ 1097] train: loss: 0.0001441
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000120
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000210
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000015
[Epoch 116; Iter   385/ 1097] train: loss: 0.0004109
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000326
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000012
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000503
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000241
[Epoch 116; Iter   535/ 1097] train: loss: 0.0005284
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000100
[Epoch 116; Iter   595/ 1097] train: loss: 0.0000020
[Epoch 116; Iter   625/ 1097] train: loss: 0.0002928
[Epoch 116; Iter   655/ 1097] train: loss: 0.0000037
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000950
[Epoch 116; Iter   715/ 1097] train: loss: 0.0000148
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000043
[Epoch 116; Iter   775/ 1097] train: loss: 0.0004808
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000026
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000178
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000013
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000305
[Epoch 116; Iter   925/ 1097] train: loss: 0.0002059
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000035
[Epoch 116; Iter   985/ 1097] train: loss: 0.0001270
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0000082
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000145
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000053
[Epoch 116] ogbg-molhiv: 0.793400 val loss: 0.404418
[Epoch 116] ogbg-molhiv: 0.801132 test loss: 0.366371
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000277
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000902
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000010
[Epoch 117; Iter    98/ 1097] train: loss: 0.0000719
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000380
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000208
[Epoch 117; Iter   188/ 1097] train: loss: 0.0000240
[Epoch 117; Iter   218/ 1097] train: loss: 0.0002148
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000601
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000069
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000048
[Epoch 117; Iter   338/ 1097] train: loss: 0.0002382
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000077
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000708
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000019
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000001
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000020
[Epoch 117; Iter   518/ 1097] train: loss: 0.0000036
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000011
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000008
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000018
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000068
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000234
[Epoch 89; Iter   514/ 1097] train: loss: 0.0011129
[Epoch 89; Iter   544/ 1097] train: loss: 0.0003474
[Epoch 89; Iter   574/ 1097] train: loss: 0.0054506
[Epoch 89; Iter   604/ 1097] train: loss: 0.0272631
[Epoch 89; Iter   634/ 1097] train: loss: 0.0046868
[Epoch 89; Iter   664/ 1097] train: loss: 0.0093821
[Epoch 89; Iter   694/ 1097] train: loss: 0.0100187
[Epoch 89; Iter   724/ 1097] train: loss: 0.0026287
[Epoch 89; Iter   754/ 1097] train: loss: 0.0060087
[Epoch 89; Iter   784/ 1097] train: loss: 0.0395618
[Epoch 89; Iter   814/ 1097] train: loss: 0.0446479
[Epoch 89; Iter   844/ 1097] train: loss: 0.0070563
[Epoch 89; Iter   874/ 1097] train: loss: 0.0014778
[Epoch 89; Iter   904/ 1097] train: loss: 0.0078986
[Epoch 89; Iter   934/ 1097] train: loss: 0.0130946
[Epoch 89; Iter   964/ 1097] train: loss: 0.0119892
[Epoch 89; Iter   994/ 1097] train: loss: 0.0695309
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0384609
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0027826
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0048867
[Epoch 89] ogbg-molhiv: 0.825207 val loss: 0.118370
[Epoch 89] ogbg-molhiv: 0.746563 test loss: 0.231223
[Epoch 90; Iter    17/ 1097] train: loss: 0.0153068
[Epoch 90; Iter    47/ 1097] train: loss: 0.0495432
[Epoch 90; Iter    77/ 1097] train: loss: 0.0268594
[Epoch 90; Iter   107/ 1097] train: loss: 0.0038339
[Epoch 90; Iter   137/ 1097] train: loss: 0.0036286
[Epoch 90; Iter   167/ 1097] train: loss: 0.1426344
[Epoch 90; Iter   197/ 1097] train: loss: 0.0042559
[Epoch 90; Iter   227/ 1097] train: loss: 0.0004008
[Epoch 90; Iter   257/ 1097] train: loss: 0.0051180
[Epoch 90; Iter   287/ 1097] train: loss: 0.0051852
[Epoch 90; Iter   317/ 1097] train: loss: 0.0079152
[Epoch 90; Iter   347/ 1097] train: loss: 0.0444548
[Epoch 90; Iter   377/ 1097] train: loss: 0.0055221
[Epoch 90; Iter   407/ 1097] train: loss: 0.0540100
[Epoch 90; Iter   437/ 1097] train: loss: 0.0024696
[Epoch 90; Iter   467/ 1097] train: loss: 0.0093513
[Epoch 90; Iter   497/ 1097] train: loss: 0.0120955
[Epoch 90; Iter   527/ 1097] train: loss: 0.0135241
[Epoch 90; Iter   557/ 1097] train: loss: 0.0758835
[Epoch 90; Iter   587/ 1097] train: loss: 0.0083297
[Epoch 90; Iter   617/ 1097] train: loss: 0.0019580
[Epoch 90; Iter   647/ 1097] train: loss: 0.0009068
[Epoch 90; Iter   677/ 1097] train: loss: 0.0120542
[Epoch 90; Iter   707/ 1097] train: loss: 0.0035961
[Epoch 90; Iter   737/ 1097] train: loss: 0.0104185
[Epoch 90; Iter   767/ 1097] train: loss: 0.1216689
[Epoch 90; Iter   797/ 1097] train: loss: 0.0030950
[Epoch 90; Iter   827/ 1097] train: loss: 0.0844858
[Epoch 90; Iter   857/ 1097] train: loss: 0.0090436
[Epoch 90; Iter   887/ 1097] train: loss: 0.0229319
[Epoch 90; Iter   917/ 1097] train: loss: 0.0092706
[Epoch 90; Iter   947/ 1097] train: loss: 0.0448417
[Epoch 90; Iter   977/ 1097] train: loss: 0.0063961
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0407356
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0355377
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0081235
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0742901
[Epoch 90] ogbg-molhiv: 0.824261 val loss: 0.122872
[Epoch 90] ogbg-molhiv: 0.756210 test loss: 0.236149
[Epoch 91; Iter    30/ 1097] train: loss: 0.0016157
[Epoch 91; Iter    60/ 1097] train: loss: 0.0485781
[Epoch 91; Iter    90/ 1097] train: loss: 0.0227352
[Epoch 91; Iter   120/ 1097] train: loss: 0.0126531
[Epoch 91; Iter   150/ 1097] train: loss: 0.0011255
[Epoch 91; Iter   180/ 1097] train: loss: 0.0153155
[Epoch 91; Iter   210/ 1097] train: loss: 0.0021442
[Epoch 91; Iter   240/ 1097] train: loss: 0.0057421
[Epoch 91; Iter   270/ 1097] train: loss: 0.0218751
[Epoch 91; Iter   300/ 1097] train: loss: 0.0046929
[Epoch 91; Iter   330/ 1097] train: loss: 0.0137587
[Epoch 91; Iter   360/ 1097] train: loss: 0.0743332
[Epoch 91; Iter   390/ 1097] train: loss: 0.0024468
[Epoch 91; Iter   420/ 1097] train: loss: 0.0194502
[Epoch 91; Iter   450/ 1097] train: loss: 0.0042938
[Epoch 91; Iter   480/ 1097] train: loss: 0.0075354
[Epoch 91; Iter   510/ 1097] train: loss: 0.0026833
[Epoch 91; Iter   540/ 1097] train: loss: 0.0378218
[Epoch 91; Iter   570/ 1097] train: loss: 0.0036957
[Epoch 91; Iter   600/ 1097] train: loss: 0.0118296
[Epoch 91; Iter   630/ 1097] train: loss: 0.0059561
[Epoch 91; Iter   660/ 1097] train: loss: 0.0108980
[Epoch 91; Iter   690/ 1097] train: loss: 0.1493021
[Epoch 91; Iter   720/ 1097] train: loss: 0.0473667
[Epoch 91; Iter   750/ 1097] train: loss: 0.0461344
[Epoch 91; Iter   780/ 1097] train: loss: 0.0067989
[Epoch 91; Iter   810/ 1097] train: loss: 0.0103087
[Epoch 91; Iter   840/ 1097] train: loss: 0.0011179
[Epoch 91; Iter   870/ 1097] train: loss: 0.0056219
[Epoch 91; Iter   900/ 1097] train: loss: 0.0036930
[Epoch 91; Iter   930/ 1097] train: loss: 0.0055068
[Epoch 91; Iter   960/ 1097] train: loss: 0.0106117
[Epoch 91; Iter   990/ 1097] train: loss: 0.0075596
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0285170
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0092985
[Epoch 91; Iter  1080/ 1097] train: loss: 0.1382969
[Epoch 91] ogbg-molhiv: 0.824010 val loss: 0.126765
[Epoch 91] ogbg-molhiv: 0.750573 test loss: 0.238224
[Epoch 92; Iter    13/ 1097] train: loss: 0.0171973
[Epoch 92; Iter    43/ 1097] train: loss: 0.0044936
[Epoch 92; Iter    73/ 1097] train: loss: 0.0050219
[Epoch 92; Iter   103/ 1097] train: loss: 0.0344615
[Epoch 92; Iter   133/ 1097] train: loss: 0.0026809
[Epoch 92; Iter   163/ 1097] train: loss: 0.0070707
[Epoch 92; Iter   193/ 1097] train: loss: 0.0020014
[Epoch 92; Iter   223/ 1097] train: loss: 0.0168185
[Epoch 92; Iter   253/ 1097] train: loss: 0.0015337
[Epoch 92; Iter   283/ 1097] train: loss: 0.0031893
[Epoch 92; Iter   313/ 1097] train: loss: 0.0735323
[Epoch 92; Iter   343/ 1097] train: loss: 0.0050810
[Epoch 92; Iter   373/ 1097] train: loss: 0.0518374
[Epoch 92; Iter   403/ 1097] train: loss: 0.0039426
[Epoch 92; Iter   433/ 1097] train: loss: 0.0085011
[Epoch 92; Iter   463/ 1097] train: loss: 0.0174916
[Epoch 92; Iter   493/ 1097] train: loss: 0.0072809
[Epoch 92; Iter   523/ 1097] train: loss: 0.0726275
[Epoch 92; Iter   553/ 1097] train: loss: 0.0145877
[Epoch 92; Iter   583/ 1097] train: loss: 0.0039795
[Epoch 92; Iter   613/ 1097] train: loss: 0.0147409
[Epoch 92; Iter   643/ 1097] train: loss: 0.0012334
[Epoch 92; Iter   673/ 1097] train: loss: 0.0027774
[Epoch 92; Iter   703/ 1097] train: loss: 0.0451689
[Epoch 92; Iter   733/ 1097] train: loss: 0.0011970
[Epoch 92; Iter   763/ 1097] train: loss: 0.0416558
[Epoch 92; Iter   793/ 1097] train: loss: 0.0108656
[Epoch 92; Iter   823/ 1097] train: loss: 0.0020991
[Epoch 92; Iter   853/ 1097] train: loss: 0.0031777
[Epoch 92; Iter   883/ 1097] train: loss: 0.0016982
[Epoch 92; Iter   913/ 1097] train: loss: 0.0036489
[Epoch 92; Iter   943/ 1097] train: loss: 0.0027427
[Epoch 92; Iter   973/ 1097] train: loss: 0.0061679
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0133577
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0212801
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0020192
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0043404
[Epoch 92] ogbg-molhiv: 0.826420 val loss: 0.125378
[Epoch 92] ogbg-molhiv: 0.757471 test loss: 0.239685
[Epoch 93; Iter    26/ 1097] train: loss: 0.0025740
[Epoch 93; Iter    56/ 1097] train: loss: 0.0045889
[Epoch 93; Iter    86/ 1097] train: loss: 0.0063200
[Epoch 93; Iter   116/ 1097] train: loss: 0.0009640
[Epoch 93; Iter   146/ 1097] train: loss: 0.0896317
[Epoch 93; Iter   176/ 1097] train: loss: 0.0599742
[Epoch 93; Iter   206/ 1097] train: loss: 0.0013400
[Epoch 93; Iter   236/ 1097] train: loss: 0.0049711
[Epoch 93; Iter   266/ 1097] train: loss: 0.0497157
[Epoch 93; Iter   296/ 1097] train: loss: 0.0002322
[Epoch 93; Iter   326/ 1097] train: loss: 0.0026943
[Epoch 93; Iter   356/ 1097] train: loss: 0.0040839
[Epoch 93; Iter   386/ 1097] train: loss: 0.0181338
[Epoch 93; Iter   416/ 1097] train: loss: 0.0086321
[Epoch 93; Iter   446/ 1097] train: loss: 0.0710697
[Epoch 93; Iter   476/ 1097] train: loss: 0.0523482
[Epoch 93; Iter   506/ 1097] train: loss: 0.0045334
[Epoch 93; Iter   536/ 1097] train: loss: 0.0174615
[Epoch 93; Iter   566/ 1097] train: loss: 0.0345598
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000002
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000225
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000039
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000066
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000058
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000235
[Epoch 113; Iter   946/ 1097] train: loss: 0.0000016
[Epoch 113; Iter   976/ 1097] train: loss: 0.0000174
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000141
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000029
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0000028
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000009
[Epoch 113] ogbg-molhiv: 0.714231 val loss: 4.214698
[Epoch 113] ogbg-molhiv: 0.624419 test loss: 4.741210
[Epoch 114; Iter    29/ 1097] train: loss: 0.0003741
[Epoch 114; Iter    59/ 1097] train: loss: 0.0000013
[Epoch 114; Iter    89/ 1097] train: loss: 0.0694535
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000005
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000071
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000020
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000006
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000014
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000001
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000075
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000082
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000045
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000014
[Epoch 114; Iter   419/ 1097] train: loss: 0.0000218
[Epoch 114; Iter   449/ 1097] train: loss: 0.0001538
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000049
[Epoch 114; Iter   509/ 1097] train: loss: 0.0001556
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000023
[Epoch 114; Iter   569/ 1097] train: loss: 0.0000216
[Epoch 114; Iter   599/ 1097] train: loss: 0.0001241
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000013
[Epoch 114; Iter   659/ 1097] train: loss: 0.0000015
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000311
[Epoch 114; Iter   719/ 1097] train: loss: 0.0001741
[Epoch 114; Iter   749/ 1097] train: loss: 0.0001807
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000009
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000001
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000130
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000127
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000052
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000394
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000011
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000014
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000017
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0005159
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000046
[Epoch 114] ogbg-molhiv: 0.707602 val loss: 1.403816
[Epoch 114] ogbg-molhiv: 0.624048 test loss: 1.093367
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000116
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000001
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000010
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000013
[Epoch 115; Iter   132/ 1097] train: loss: 0.0044863
[Epoch 115; Iter   162/ 1097] train: loss: 0.0000062
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000019
[Epoch 115; Iter   222/ 1097] train: loss: 0.0000959
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000156
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000008
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000095
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000403
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000053
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000276
[Epoch 115; Iter   432/ 1097] train: loss: 0.0015196
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000038
[Epoch 115; Iter   492/ 1097] train: loss: 0.0008203
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000163
[Epoch 115; Iter   552/ 1097] train: loss: 0.0000321
[Epoch 115; Iter   582/ 1097] train: loss: 0.0117831
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000039
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000573
[Epoch 115; Iter   672/ 1097] train: loss: 0.0000009
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000008
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000240
[Epoch 115; Iter   762/ 1097] train: loss: 0.0011553
[Epoch 115; Iter   792/ 1097] train: loss: 0.0000002
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000007
[Epoch 115; Iter   852/ 1097] train: loss: 0.0000010
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000019
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000151
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000110
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000004
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000725
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0000034
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0000034
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000071
[Epoch 115] ogbg-molhiv: 0.696370 val loss: 4.444334
[Epoch 115] ogbg-molhiv: 0.620746 test loss: 4.907374
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000000
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000061
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000073
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000008
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000765
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000007
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000065
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000014
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000006
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000035
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000027
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000141
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000221
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000548
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000121
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000207
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000344
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000102
[Epoch 116; Iter   565/ 1097] train: loss: 0.0001720
[Epoch 116; Iter   595/ 1097] train: loss: 0.0001004
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000117
[Epoch 116; Iter   655/ 1097] train: loss: 0.0212891
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000363
[Epoch 116; Iter   715/ 1097] train: loss: 0.0035163
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000037
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000361
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000012
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000116
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000065
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000407
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000064
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000017
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000979
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0331686
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000018
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000829
[Epoch 116] ogbg-molhiv: 0.705127 val loss: 5.435340
[Epoch 116] ogbg-molhiv: 0.602416 test loss: 5.360809
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000007
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000111
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000026
[Epoch 117; Iter    98/ 1097] train: loss: 0.0000121
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000041
[Epoch 117; Iter   158/ 1097] train: loss: 0.0007464
[Epoch 117; Iter   188/ 1097] train: loss: 0.0024161
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000075
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000054
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000026
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000014
[Epoch 117; Iter   338/ 1097] train: loss: 0.0008022
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000515
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000025
[Epoch 117; Iter   428/ 1097] train: loss: 0.0002493
[Epoch 117; Iter   458/ 1097] train: loss: 0.0001328
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000015
[Epoch 117; Iter   518/ 1097] train: loss: 0.0002339
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000222
[Epoch 117; Iter   578/ 1097] train: loss: 0.0001544
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000008
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000047
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000009
[Epoch 89; Iter   514/ 1097] train: loss: 0.0175249
[Epoch 89; Iter   544/ 1097] train: loss: 0.0101555
[Epoch 89; Iter   574/ 1097] train: loss: 0.0032670
[Epoch 89; Iter   604/ 1097] train: loss: 0.0523913
[Epoch 89; Iter   634/ 1097] train: loss: 0.0009051
[Epoch 89; Iter   664/ 1097] train: loss: 0.0056068
[Epoch 89; Iter   694/ 1097] train: loss: 0.0175209
[Epoch 89; Iter   724/ 1097] train: loss: 0.0463685
[Epoch 89; Iter   754/ 1097] train: loss: 0.0536724
[Epoch 89; Iter   784/ 1097] train: loss: 0.0498745
[Epoch 89; Iter   814/ 1097] train: loss: 0.0006823
[Epoch 89; Iter   844/ 1097] train: loss: 0.0014832
[Epoch 89; Iter   874/ 1097] train: loss: 0.0018909
[Epoch 89; Iter   904/ 1097] train: loss: 0.0015010
[Epoch 89; Iter   934/ 1097] train: loss: 0.0055828
[Epoch 89; Iter   964/ 1097] train: loss: 0.0314433
[Epoch 89; Iter   994/ 1097] train: loss: 0.1187390
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0611436
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0199513
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0245224
[Epoch 89] ogbg-molhiv: 0.804888 val loss: 0.117203
[Epoch 89] ogbg-molhiv: 0.745721 test loss: 0.230430
[Epoch 90; Iter    17/ 1097] train: loss: 0.0121949
[Epoch 90; Iter    47/ 1097] train: loss: 0.0127568
[Epoch 90; Iter    77/ 1097] train: loss: 0.0090411
[Epoch 90; Iter   107/ 1097] train: loss: 0.0256747
[Epoch 90; Iter   137/ 1097] train: loss: 0.0242882
[Epoch 90; Iter   167/ 1097] train: loss: 0.0023540
[Epoch 90; Iter   197/ 1097] train: loss: 0.0054333
[Epoch 90; Iter   227/ 1097] train: loss: 0.0174432
[Epoch 90; Iter   257/ 1097] train: loss: 0.0485105
[Epoch 90; Iter   287/ 1097] train: loss: 0.0023271
[Epoch 90; Iter   317/ 1097] train: loss: 0.0045760
[Epoch 90; Iter   347/ 1097] train: loss: 0.0173236
[Epoch 90; Iter   377/ 1097] train: loss: 0.0021875
[Epoch 90; Iter   407/ 1097] train: loss: 0.1031295
[Epoch 90; Iter   437/ 1097] train: loss: 0.0018332
[Epoch 90; Iter   467/ 1097] train: loss: 0.0033912
[Epoch 90; Iter   497/ 1097] train: loss: 0.0025038
[Epoch 90; Iter   527/ 1097] train: loss: 0.0126572
[Epoch 90; Iter   557/ 1097] train: loss: 0.0060549
[Epoch 90; Iter   587/ 1097] train: loss: 0.0291717
[Epoch 90; Iter   617/ 1097] train: loss: 0.0164281
[Epoch 90; Iter   647/ 1097] train: loss: 0.0092082
[Epoch 90; Iter   677/ 1097] train: loss: 0.0711621
[Epoch 90; Iter   707/ 1097] train: loss: 0.0056940
[Epoch 90; Iter   737/ 1097] train: loss: 0.0302624
[Epoch 90; Iter   767/ 1097] train: loss: 0.0058678
[Epoch 90; Iter   797/ 1097] train: loss: 0.0069131
[Epoch 90; Iter   827/ 1097] train: loss: 0.0229868
[Epoch 90; Iter   857/ 1097] train: loss: 0.0126717
[Epoch 90; Iter   887/ 1097] train: loss: 0.0078980
[Epoch 90; Iter   917/ 1097] train: loss: 0.0757046
[Epoch 90; Iter   947/ 1097] train: loss: 0.0188766
[Epoch 90; Iter   977/ 1097] train: loss: 0.0376274
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0225593
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0280685
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0199474
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0621246
[Epoch 90] ogbg-molhiv: 0.802726 val loss: 0.114924
[Epoch 90] ogbg-molhiv: 0.747674 test loss: 0.247061
[Epoch 91; Iter    30/ 1097] train: loss: 0.0187729
[Epoch 91; Iter    60/ 1097] train: loss: 0.0272350
[Epoch 91; Iter    90/ 1097] train: loss: 0.0254169
[Epoch 91; Iter   120/ 1097] train: loss: 0.0090779
[Epoch 91; Iter   150/ 1097] train: loss: 0.0063618
[Epoch 91; Iter   180/ 1097] train: loss: 0.0165411
[Epoch 91; Iter   210/ 1097] train: loss: 0.0036689
[Epoch 91; Iter   240/ 1097] train: loss: 0.0757037
[Epoch 91; Iter   270/ 1097] train: loss: 0.0132588
[Epoch 91; Iter   300/ 1097] train: loss: 0.0312061
[Epoch 91; Iter   330/ 1097] train: loss: 0.0127697
[Epoch 91; Iter   360/ 1097] train: loss: 0.0006278
[Epoch 91; Iter   390/ 1097] train: loss: 0.0012301
[Epoch 91; Iter   420/ 1097] train: loss: 0.0152059
[Epoch 91; Iter   450/ 1097] train: loss: 0.0095745
[Epoch 91; Iter   480/ 1097] train: loss: 0.0112602
[Epoch 91; Iter   510/ 1097] train: loss: 0.0657341
[Epoch 91; Iter   540/ 1097] train: loss: 0.0094501
[Epoch 91; Iter   570/ 1097] train: loss: 0.0015484
[Epoch 91; Iter   600/ 1097] train: loss: 0.0237157
[Epoch 91; Iter   630/ 1097] train: loss: 0.0439512
[Epoch 91; Iter   660/ 1097] train: loss: 0.0071058
[Epoch 91; Iter   690/ 1097] train: loss: 0.0612946
[Epoch 91; Iter   720/ 1097] train: loss: 0.0282193
[Epoch 91; Iter   750/ 1097] train: loss: 0.0145852
[Epoch 91; Iter   780/ 1097] train: loss: 0.1270358
[Epoch 91; Iter   810/ 1097] train: loss: 0.0324225
[Epoch 91; Iter   840/ 1097] train: loss: 0.0092997
[Epoch 91; Iter   870/ 1097] train: loss: 0.0117031
[Epoch 91; Iter   900/ 1097] train: loss: 0.0351588
[Epoch 91; Iter   930/ 1097] train: loss: 0.0396791
[Epoch 91; Iter   960/ 1097] train: loss: 0.2174699
[Epoch 91; Iter   990/ 1097] train: loss: 0.0258417
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0300554
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0080259
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0063505
[Epoch 91] ogbg-molhiv: 0.792398 val loss: 0.122960
[Epoch 91] ogbg-molhiv: 0.749657 test loss: 0.277794
[Epoch 92; Iter    13/ 1097] train: loss: 0.0259606
[Epoch 92; Iter    43/ 1097] train: loss: 0.0865977
[Epoch 92; Iter    73/ 1097] train: loss: 0.0248642
[Epoch 92; Iter   103/ 1097] train: loss: 0.0247003
[Epoch 92; Iter   133/ 1097] train: loss: 0.0057676
[Epoch 92; Iter   163/ 1097] train: loss: 0.0062095
[Epoch 92; Iter   193/ 1097] train: loss: 0.1154447
[Epoch 92; Iter   223/ 1097] train: loss: 0.0228509
[Epoch 92; Iter   253/ 1097] train: loss: 0.0103192
[Epoch 92; Iter   283/ 1097] train: loss: 0.0247612
[Epoch 92; Iter   313/ 1097] train: loss: 0.0053408
[Epoch 92; Iter   343/ 1097] train: loss: 0.0045105
[Epoch 92; Iter   373/ 1097] train: loss: 0.0304229
[Epoch 92; Iter   403/ 1097] train: loss: 0.0252161
[Epoch 92; Iter   433/ 1097] train: loss: 0.0091320
[Epoch 92; Iter   463/ 1097] train: loss: 0.0128459
[Epoch 92; Iter   493/ 1097] train: loss: 0.0143092
[Epoch 92; Iter   523/ 1097] train: loss: 0.0788116
[Epoch 92; Iter   553/ 1097] train: loss: 0.0141129
[Epoch 92; Iter   583/ 1097] train: loss: 0.0110428
[Epoch 92; Iter   613/ 1097] train: loss: 0.2698447
[Epoch 92; Iter   643/ 1097] train: loss: 0.0101673
[Epoch 92; Iter   673/ 1097] train: loss: 0.1075864
[Epoch 92; Iter   703/ 1097] train: loss: 0.1229426
[Epoch 92; Iter   733/ 1097] train: loss: 0.0183098
[Epoch 92; Iter   763/ 1097] train: loss: 0.0880412
[Epoch 92; Iter   793/ 1097] train: loss: 0.0176002
[Epoch 92; Iter   823/ 1097] train: loss: 0.0027077
[Epoch 92; Iter   853/ 1097] train: loss: 0.0524963
[Epoch 92; Iter   883/ 1097] train: loss: 0.0429971
[Epoch 92; Iter   913/ 1097] train: loss: 0.0019779
[Epoch 92; Iter   943/ 1097] train: loss: 0.0077535
[Epoch 92; Iter   973/ 1097] train: loss: 0.0115508
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0291466
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0495471
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0014651
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0048067
[Epoch 92] ogbg-molhiv: 0.800105 val loss: 0.120979
[Epoch 92] ogbg-molhiv: 0.740507 test loss: 0.231649
[Epoch 93; Iter    26/ 1097] train: loss: 0.0021829
[Epoch 93; Iter    56/ 1097] train: loss: 0.0187661
[Epoch 93; Iter    86/ 1097] train: loss: 0.0176796
[Epoch 93; Iter   116/ 1097] train: loss: 0.0241098
[Epoch 93; Iter   146/ 1097] train: loss: 0.0250146
[Epoch 93; Iter   176/ 1097] train: loss: 0.0013378
[Epoch 93; Iter   206/ 1097] train: loss: 0.0140279
[Epoch 93; Iter   236/ 1097] train: loss: 0.1730040
[Epoch 93; Iter   266/ 1097] train: loss: 0.0750860
[Epoch 93; Iter   296/ 1097] train: loss: 0.0013699
[Epoch 93; Iter   326/ 1097] train: loss: 0.0152988
[Epoch 93; Iter   356/ 1097] train: loss: 0.0094530
[Epoch 93; Iter   386/ 1097] train: loss: 0.0382096
[Epoch 93; Iter   416/ 1097] train: loss: 0.0101964
[Epoch 93; Iter   446/ 1097] train: loss: 0.0040442
[Epoch 93; Iter   476/ 1097] train: loss: 0.0023965
[Epoch 93; Iter   506/ 1097] train: loss: 0.0204463
[Epoch 93; Iter   536/ 1097] train: loss: 0.0100577
[Epoch 93; Iter   566/ 1097] train: loss: 0.0117062
[Epoch 89; Iter   514/ 1097] train: loss: 0.0094980
[Epoch 89; Iter   544/ 1097] train: loss: 0.0116925
[Epoch 89; Iter   574/ 1097] train: loss: 0.0113837
[Epoch 89; Iter   604/ 1097] train: loss: 0.0194001
[Epoch 89; Iter   634/ 1097] train: loss: 0.0156583
[Epoch 89; Iter   664/ 1097] train: loss: 0.0025429
[Epoch 89; Iter   694/ 1097] train: loss: 0.0205948
[Epoch 89; Iter   724/ 1097] train: loss: 0.0986582
[Epoch 89; Iter   754/ 1097] train: loss: 0.0120156
[Epoch 89; Iter   784/ 1097] train: loss: 0.1269042
[Epoch 89; Iter   814/ 1097] train: loss: 0.0169536
[Epoch 89; Iter   844/ 1097] train: loss: 0.0437372
[Epoch 89; Iter   874/ 1097] train: loss: 0.0225487
[Epoch 89; Iter   904/ 1097] train: loss: 0.0204852
[Epoch 89; Iter   934/ 1097] train: loss: 0.0086346
[Epoch 89; Iter   964/ 1097] train: loss: 0.0040568
[Epoch 89; Iter   994/ 1097] train: loss: 0.0064296
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0027863
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0507673
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0088185
[Epoch 89] ogbg-molhiv: 0.764388 val loss: 0.146304
[Epoch 89] ogbg-molhiv: 0.753354 test loss: 0.244114
[Epoch 90; Iter    17/ 1097] train: loss: 0.1018781
[Epoch 90; Iter    47/ 1097] train: loss: 0.1097764
[Epoch 90; Iter    77/ 1097] train: loss: 0.0244063
[Epoch 90; Iter   107/ 1097] train: loss: 0.0003857
[Epoch 90; Iter   137/ 1097] train: loss: 0.0026982
[Epoch 90; Iter   167/ 1097] train: loss: 0.0017953
[Epoch 90; Iter   197/ 1097] train: loss: 0.0204724
[Epoch 90; Iter   227/ 1097] train: loss: 0.0029037
[Epoch 90; Iter   257/ 1097] train: loss: 0.0017807
[Epoch 90; Iter   287/ 1097] train: loss: 0.0003158
[Epoch 90; Iter   317/ 1097] train: loss: 0.0612191
[Epoch 90; Iter   347/ 1097] train: loss: 0.0190186
[Epoch 90; Iter   377/ 1097] train: loss: 0.0021564
[Epoch 90; Iter   407/ 1097] train: loss: 0.0421210
[Epoch 90; Iter   437/ 1097] train: loss: 0.0057914
[Epoch 90; Iter   467/ 1097] train: loss: 0.0883931
[Epoch 90; Iter   497/ 1097] train: loss: 0.0010415
[Epoch 90; Iter   527/ 1097] train: loss: 0.0472213
[Epoch 90; Iter   557/ 1097] train: loss: 0.0091788
[Epoch 90; Iter   587/ 1097] train: loss: 0.0246196
[Epoch 90; Iter   617/ 1097] train: loss: 0.0035007
[Epoch 90; Iter   647/ 1097] train: loss: 0.0081386
[Epoch 90; Iter   677/ 1097] train: loss: 0.0041732
[Epoch 90; Iter   707/ 1097] train: loss: 0.0173779
[Epoch 90; Iter   737/ 1097] train: loss: 0.0051378
[Epoch 90; Iter   767/ 1097] train: loss: 0.0024745
[Epoch 90; Iter   797/ 1097] train: loss: 0.0594247
[Epoch 90; Iter   827/ 1097] train: loss: 0.1495919
[Epoch 90; Iter   857/ 1097] train: loss: 0.0014805
[Epoch 90; Iter   887/ 1097] train: loss: 0.0784379
[Epoch 90; Iter   917/ 1097] train: loss: 0.0614867
[Epoch 90; Iter   947/ 1097] train: loss: 0.0493059
[Epoch 90; Iter   977/ 1097] train: loss: 0.0103734
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0284606
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0654928
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0708933
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0097596
[Epoch 90] ogbg-molhiv: 0.775484 val loss: 0.144083
[Epoch 90] ogbg-molhiv: 0.745744 test loss: 0.257940
[Epoch 91; Iter    30/ 1097] train: loss: 0.0262647
[Epoch 91; Iter    60/ 1097] train: loss: 0.0128333
[Epoch 91; Iter    90/ 1097] train: loss: 0.0014377
[Epoch 91; Iter   120/ 1097] train: loss: 0.0073995
[Epoch 91; Iter   150/ 1097] train: loss: 0.1011438
[Epoch 91; Iter   180/ 1097] train: loss: 0.0264617
[Epoch 91; Iter   210/ 1097] train: loss: 0.0057219
[Epoch 91; Iter   240/ 1097] train: loss: 0.0821603
[Epoch 91; Iter   270/ 1097] train: loss: 0.0073101
[Epoch 91; Iter   300/ 1097] train: loss: 0.0046302
[Epoch 91; Iter   330/ 1097] train: loss: 0.1477604
[Epoch 91; Iter   360/ 1097] train: loss: 0.0415617
[Epoch 91; Iter   390/ 1097] train: loss: 0.0015593
[Epoch 91; Iter   420/ 1097] train: loss: 0.0943820
[Epoch 91; Iter   450/ 1097] train: loss: 0.0021690
[Epoch 91; Iter   480/ 1097] train: loss: 0.0029164
[Epoch 91; Iter   510/ 1097] train: loss: 0.0723216
[Epoch 91; Iter   540/ 1097] train: loss: 0.0176932
[Epoch 91; Iter   570/ 1097] train: loss: 0.0059266
[Epoch 91; Iter   600/ 1097] train: loss: 0.0031779
[Epoch 91; Iter   630/ 1097] train: loss: 0.0012271
[Epoch 91; Iter   660/ 1097] train: loss: 0.0485094
[Epoch 91; Iter   690/ 1097] train: loss: 0.0217493
[Epoch 91; Iter   720/ 1097] train: loss: 0.0051853
[Epoch 91; Iter   750/ 1097] train: loss: 0.0103226
[Epoch 91; Iter   780/ 1097] train: loss: 0.0052346
[Epoch 91; Iter   810/ 1097] train: loss: 0.0117072
[Epoch 91; Iter   840/ 1097] train: loss: 0.0086613
[Epoch 91; Iter   870/ 1097] train: loss: 0.0652915
[Epoch 91; Iter   900/ 1097] train: loss: 0.0013000
[Epoch 91; Iter   930/ 1097] train: loss: 0.0026298
[Epoch 91; Iter   960/ 1097] train: loss: 0.0025871
[Epoch 91; Iter   990/ 1097] train: loss: 0.0076334
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0237798
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0009003
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0046581
[Epoch 91] ogbg-molhiv: 0.778445 val loss: 0.137074
[Epoch 91] ogbg-molhiv: 0.749984 test loss: 0.255548
[Epoch 92; Iter    13/ 1097] train: loss: 0.0030922
[Epoch 92; Iter    43/ 1097] train: loss: 0.0045262
[Epoch 92; Iter    73/ 1097] train: loss: 0.0134482
[Epoch 92; Iter   103/ 1097] train: loss: 0.0379253
[Epoch 92; Iter   133/ 1097] train: loss: 0.0565427
[Epoch 92; Iter   163/ 1097] train: loss: 0.0015345
[Epoch 92; Iter   193/ 1097] train: loss: 0.0093697
[Epoch 92; Iter   223/ 1097] train: loss: 0.0046664
[Epoch 92; Iter   253/ 1097] train: loss: 0.0004052
[Epoch 92; Iter   283/ 1097] train: loss: 0.0079371
[Epoch 92; Iter   313/ 1097] train: loss: 0.0663226
[Epoch 92; Iter   343/ 1097] train: loss: 0.0025825
[Epoch 92; Iter   373/ 1097] train: loss: 0.1120760
[Epoch 92; Iter   403/ 1097] train: loss: 0.0355652
[Epoch 92; Iter   433/ 1097] train: loss: 0.0026689
[Epoch 92; Iter   463/ 1097] train: loss: 0.0019188
[Epoch 92; Iter   493/ 1097] train: loss: 0.0235266
[Epoch 92; Iter   523/ 1097] train: loss: 0.0072161
[Epoch 92; Iter   553/ 1097] train: loss: 0.0130111
[Epoch 92; Iter   583/ 1097] train: loss: 0.0061892
[Epoch 92; Iter   613/ 1097] train: loss: 0.2439046
[Epoch 92; Iter   643/ 1097] train: loss: 0.0056500
[Epoch 92; Iter   673/ 1097] train: loss: 0.0031168
[Epoch 92; Iter   703/ 1097] train: loss: 0.0677256
[Epoch 92; Iter   733/ 1097] train: loss: 0.0641994
[Epoch 92; Iter   763/ 1097] train: loss: 0.0344042
[Epoch 92; Iter   793/ 1097] train: loss: 0.0019847
[Epoch 92; Iter   823/ 1097] train: loss: 0.0674961
[Epoch 92; Iter   853/ 1097] train: loss: 0.0271850
[Epoch 92; Iter   883/ 1097] train: loss: 0.0166668
[Epoch 92; Iter   913/ 1097] train: loss: 0.0690180
[Epoch 92; Iter   943/ 1097] train: loss: 0.0034190
[Epoch 92; Iter   973/ 1097] train: loss: 0.0288212
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0458628
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0029741
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0852823
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0010161
[Epoch 92] ogbg-molhiv: 0.781856 val loss: 0.148172
[Epoch 92] ogbg-molhiv: 0.742042 test loss: 0.249748
[Epoch 93; Iter    26/ 1097] train: loss: 0.0120104
[Epoch 93; Iter    56/ 1097] train: loss: 0.0072220
[Epoch 93; Iter    86/ 1097] train: loss: 0.0046926
[Epoch 93; Iter   116/ 1097] train: loss: 0.0057395
[Epoch 93; Iter   146/ 1097] train: loss: 0.0041472
[Epoch 93; Iter   176/ 1097] train: loss: 0.0174740
[Epoch 93; Iter   206/ 1097] train: loss: 0.0029099
[Epoch 93; Iter   236/ 1097] train: loss: 0.0147296
[Epoch 93; Iter   266/ 1097] train: loss: 0.0022249
[Epoch 93; Iter   296/ 1097] train: loss: 0.0010805
[Epoch 93; Iter   326/ 1097] train: loss: 0.0077931
[Epoch 93; Iter   356/ 1097] train: loss: 0.0170350
[Epoch 93; Iter   386/ 1097] train: loss: 0.0365107
[Epoch 93; Iter   416/ 1097] train: loss: 0.0450739
[Epoch 93; Iter   446/ 1097] train: loss: 0.0039461
[Epoch 93; Iter   476/ 1097] train: loss: 0.0075483
[Epoch 93; Iter   506/ 1097] train: loss: 0.0010447
[Epoch 93; Iter   536/ 1097] train: loss: 0.0030023
[Epoch 93; Iter   566/ 1097] train: loss: 0.0065076
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000010
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000154
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000067
[Epoch 113; Iter   796/ 1097] train: loss: 0.0002122
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000367
[Epoch 113; Iter   856/ 1097] train: loss: 0.0001922
[Epoch 113; Iter   886/ 1097] train: loss: 0.0002247
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000093
[Epoch 113; Iter   946/ 1097] train: loss: 0.0004799
[Epoch 113; Iter   976/ 1097] train: loss: 0.0001318
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000047
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000169
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0004349
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000182
[Epoch 113] ogbg-molhiv: 0.704191 val loss: 33.072711
[Epoch 113] ogbg-molhiv: 0.625111 test loss: 24.219829
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000711
[Epoch 114; Iter    59/ 1097] train: loss: 0.0000212
[Epoch 114; Iter    89/ 1097] train: loss: 0.0006440
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000037
[Epoch 114; Iter   149/ 1097] train: loss: 0.0006606
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000066
[Epoch 114; Iter   209/ 1097] train: loss: 0.0003998
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000019
[Epoch 114; Iter   269/ 1097] train: loss: 0.0000047
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000743
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000030
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000016
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000529
[Epoch 114; Iter   419/ 1097] train: loss: 0.0000011
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000047
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000024
[Epoch 114; Iter   509/ 1097] train: loss: 0.0004837
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000017
[Epoch 114; Iter   569/ 1097] train: loss: 0.0008234
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000053
[Epoch 114; Iter   629/ 1097] train: loss: 0.0000237
[Epoch 114; Iter   659/ 1097] train: loss: 0.0013241
[Epoch 114; Iter   689/ 1097] train: loss: 0.0001865
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000725
[Epoch 114; Iter   749/ 1097] train: loss: 0.0000083
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000024
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000026
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000514
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000117
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000178
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000204
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000583
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000199
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000003
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000626
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000115
[Epoch 114] ogbg-molhiv: 0.732030 val loss: 37.736626
[Epoch 114] ogbg-molhiv: 0.635536 test loss: 27.879482
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000128
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000086
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000557
[Epoch 115; Iter   102/ 1097] train: loss: 0.0002285
[Epoch 115; Iter   132/ 1097] train: loss: 0.0000154
[Epoch 115; Iter   162/ 1097] train: loss: 0.0002089
[Epoch 115; Iter   192/ 1097] train: loss: 0.0001909
[Epoch 115; Iter   222/ 1097] train: loss: 0.0009631
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000033
[Epoch 115; Iter   282/ 1097] train: loss: 0.0004613
[Epoch 115; Iter   312/ 1097] train: loss: 0.0008222
[Epoch 115; Iter   342/ 1097] train: loss: 0.0003584
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000375
[Epoch 115; Iter   402/ 1097] train: loss: 0.0008942
[Epoch 115; Iter   432/ 1097] train: loss: 0.0000071
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000022
[Epoch 115; Iter   492/ 1097] train: loss: 0.0002492
[Epoch 115; Iter   522/ 1097] train: loss: 0.0001785
[Epoch 115; Iter   552/ 1097] train: loss: 0.0025220
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000325
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000003
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000012
[Epoch 115; Iter   672/ 1097] train: loss: 0.0001031
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000132
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000303
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000134
[Epoch 115; Iter   792/ 1097] train: loss: 0.0014231
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000127
[Epoch 115; Iter   852/ 1097] train: loss: 0.0154970
[Epoch 115; Iter   882/ 1097] train: loss: 0.0005095
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000042
[Epoch 115; Iter   942/ 1097] train: loss: 0.0004991
[Epoch 115; Iter   972/ 1097] train: loss: 0.0006728
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000373
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0017508
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0000091
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000188
[Epoch 115] ogbg-molhiv: 0.690516 val loss: 53.910139
[Epoch 115] ogbg-molhiv: 0.590546 test loss: 41.419858
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000024
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000212
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000638
[Epoch 116; Iter   115/ 1097] train: loss: 0.0028542
[Epoch 116; Iter   145/ 1097] train: loss: 0.0006864
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000313
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000160
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000349
[Epoch 116; Iter   265/ 1097] train: loss: 0.0011382
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000033
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000021
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000028
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000368
[Epoch 116; Iter   415/ 1097] train: loss: 0.0000275
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000014
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000734
[Epoch 116; Iter   505/ 1097] train: loss: 0.0001435
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000494
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000059
[Epoch 116; Iter   595/ 1097] train: loss: 0.0002470
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000380
[Epoch 116; Iter   655/ 1097] train: loss: 0.0000048
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000053
[Epoch 116; Iter   715/ 1097] train: loss: 0.0001384
[Epoch 116; Iter   745/ 1097] train: loss: 0.0000042
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000597
[Epoch 116; Iter   805/ 1097] train: loss: 0.0001380
[Epoch 116; Iter   835/ 1097] train: loss: 0.0006825
[Epoch 116; Iter   865/ 1097] train: loss: 0.0000062
[Epoch 116; Iter   895/ 1097] train: loss: 0.0079343
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000057
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000117
[Epoch 116; Iter   985/ 1097] train: loss: 0.0009474
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0000200
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0000564
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0000082
[Epoch 116] ogbg-molhiv: 0.706906 val loss: 40.363115
[Epoch 116] ogbg-molhiv: 0.598847 test loss: 29.505234
[Epoch 117; Iter     8/ 1097] train: loss: 0.0021697
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000144
[Epoch 117; Iter    68/ 1097] train: loss: 0.0001056
[Epoch 117; Iter    98/ 1097] train: loss: 0.0001808
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000167
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000713
[Epoch 117; Iter   188/ 1097] train: loss: 0.0001206
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000199
[Epoch 117; Iter   248/ 1097] train: loss: 0.0004374
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000084
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000642
[Epoch 117; Iter   338/ 1097] train: loss: 0.0000206
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000010
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000959
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000033
[Epoch 117; Iter   458/ 1097] train: loss: 0.0001023
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000557
[Epoch 117; Iter   518/ 1097] train: loss: 0.0008185
[Epoch 117; Iter   548/ 1097] train: loss: 0.0000065
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000578
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000380
[Epoch 117; Iter   638/ 1097] train: loss: 0.0000072
[Epoch 117; Iter   668/ 1097] train: loss: 0.0018843
[Epoch 113; Iter   706/ 1097] train: loss: 0.0000009
[Epoch 113; Iter   736/ 1097] train: loss: 0.0000681
[Epoch 113; Iter   766/ 1097] train: loss: 0.0000120
[Epoch 113; Iter   796/ 1097] train: loss: 0.0000141
[Epoch 113; Iter   826/ 1097] train: loss: 0.0000178
[Epoch 113; Iter   856/ 1097] train: loss: 0.0000030
[Epoch 113; Iter   886/ 1097] train: loss: 0.0000350
[Epoch 113; Iter   916/ 1097] train: loss: 0.0000333
[Epoch 113; Iter   946/ 1097] train: loss: 0.0001044
[Epoch 113; Iter   976/ 1097] train: loss: 0.0000026
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0000009
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0000160
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0000616
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0000002
[Epoch 113] ogbg-molhiv: 0.754617 val loss: 1.356321
[Epoch 113] ogbg-molhiv: 0.708677 test loss: 2.838336
[Epoch 114; Iter    29/ 1097] train: loss: 0.0000025
[Epoch 114; Iter    59/ 1097] train: loss: 0.0001235
[Epoch 114; Iter    89/ 1097] train: loss: 0.0000454
[Epoch 114; Iter   119/ 1097] train: loss: 0.0000012
[Epoch 114; Iter   149/ 1097] train: loss: 0.0000018
[Epoch 114; Iter   179/ 1097] train: loss: 0.0000005
[Epoch 114; Iter   209/ 1097] train: loss: 0.0000194
[Epoch 114; Iter   239/ 1097] train: loss: 0.0000001
[Epoch 114; Iter   269/ 1097] train: loss: 0.0002864
[Epoch 114; Iter   299/ 1097] train: loss: 0.0000063
[Epoch 114; Iter   329/ 1097] train: loss: 0.0000258
[Epoch 114; Iter   359/ 1097] train: loss: 0.0000122
[Epoch 114; Iter   389/ 1097] train: loss: 0.0000597
[Epoch 114; Iter   419/ 1097] train: loss: 0.0003939
[Epoch 114; Iter   449/ 1097] train: loss: 0.0000008
[Epoch 114; Iter   479/ 1097] train: loss: 0.0000300
[Epoch 114; Iter   509/ 1097] train: loss: 0.0000154
[Epoch 114; Iter   539/ 1097] train: loss: 0.0000048
[Epoch 114; Iter   569/ 1097] train: loss: 0.0001160
[Epoch 114; Iter   599/ 1097] train: loss: 0.0000102
[Epoch 114; Iter   629/ 1097] train: loss: 0.0009411
[Epoch 114; Iter   659/ 1097] train: loss: 0.0001215
[Epoch 114; Iter   689/ 1097] train: loss: 0.0000354
[Epoch 114; Iter   719/ 1097] train: loss: 0.0000260
[Epoch 114; Iter   749/ 1097] train: loss: 0.0000040
[Epoch 114; Iter   779/ 1097] train: loss: 0.0000077
[Epoch 114; Iter   809/ 1097] train: loss: 0.0000004
[Epoch 114; Iter   839/ 1097] train: loss: 0.0000337
[Epoch 114; Iter   869/ 1097] train: loss: 0.0000134
[Epoch 114; Iter   899/ 1097] train: loss: 0.0000859
[Epoch 114; Iter   929/ 1097] train: loss: 0.0000056
[Epoch 114; Iter   959/ 1097] train: loss: 0.0000920
[Epoch 114; Iter   989/ 1097] train: loss: 0.0000329
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0000006
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0000073
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0000045
[Epoch 114] ogbg-molhiv: 0.760527 val loss: 1.060803
[Epoch 114] ogbg-molhiv: 0.705948 test loss: 2.349213
[Epoch 115; Iter    12/ 1097] train: loss: 0.0000033
[Epoch 115; Iter    42/ 1097] train: loss: 0.0000131
[Epoch 115; Iter    72/ 1097] train: loss: 0.0000053
[Epoch 115; Iter   102/ 1097] train: loss: 0.0000128
[Epoch 115; Iter   132/ 1097] train: loss: 0.0000166
[Epoch 115; Iter   162/ 1097] train: loss: 0.0000011
[Epoch 115; Iter   192/ 1097] train: loss: 0.0000035
[Epoch 115; Iter   222/ 1097] train: loss: 0.0000030
[Epoch 115; Iter   252/ 1097] train: loss: 0.0000017
[Epoch 115; Iter   282/ 1097] train: loss: 0.0000053
[Epoch 115; Iter   312/ 1097] train: loss: 0.0000061
[Epoch 115; Iter   342/ 1097] train: loss: 0.0000788
[Epoch 115; Iter   372/ 1097] train: loss: 0.0000033
[Epoch 115; Iter   402/ 1097] train: loss: 0.0000360
[Epoch 115; Iter   432/ 1097] train: loss: 0.0006699
[Epoch 115; Iter   462/ 1097] train: loss: 0.0000029
[Epoch 115; Iter   492/ 1097] train: loss: 0.0000251
[Epoch 115; Iter   522/ 1097] train: loss: 0.0000088
[Epoch 115; Iter   552/ 1097] train: loss: 0.0000014
[Epoch 115; Iter   582/ 1097] train: loss: 0.0000002
[Epoch 115; Iter   612/ 1097] train: loss: 0.0000592
[Epoch 115; Iter   642/ 1097] train: loss: 0.0000014
[Epoch 115; Iter   672/ 1097] train: loss: 0.0005837
[Epoch 115; Iter   702/ 1097] train: loss: 0.0000021
[Epoch 115; Iter   732/ 1097] train: loss: 0.0000023
[Epoch 115; Iter   762/ 1097] train: loss: 0.0000132
[Epoch 115; Iter   792/ 1097] train: loss: 0.0021202
[Epoch 115; Iter   822/ 1097] train: loss: 0.0000010
[Epoch 115; Iter   852/ 1097] train: loss: 0.0001159
[Epoch 115; Iter   882/ 1097] train: loss: 0.0000017
[Epoch 115; Iter   912/ 1097] train: loss: 0.0000453
[Epoch 115; Iter   942/ 1097] train: loss: 0.0000004
[Epoch 115; Iter   972/ 1097] train: loss: 0.0000575
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0000274
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0003159
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0000001
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0000009
[Epoch 115] ogbg-molhiv: 0.744363 val loss: 0.880648
[Epoch 115] ogbg-molhiv: 0.709038 test loss: 2.205941
[Epoch 116; Iter    25/ 1097] train: loss: 0.0000013
[Epoch 116; Iter    55/ 1097] train: loss: 0.0000030
[Epoch 116; Iter    85/ 1097] train: loss: 0.0000267
[Epoch 116; Iter   115/ 1097] train: loss: 0.0000066
[Epoch 116; Iter   145/ 1097] train: loss: 0.0000177
[Epoch 116; Iter   175/ 1097] train: loss: 0.0000135
[Epoch 116; Iter   205/ 1097] train: loss: 0.0000239
[Epoch 116; Iter   235/ 1097] train: loss: 0.0000019
[Epoch 116; Iter   265/ 1097] train: loss: 0.0000021
[Epoch 116; Iter   295/ 1097] train: loss: 0.0000022
[Epoch 116; Iter   325/ 1097] train: loss: 0.0000329
[Epoch 116; Iter   355/ 1097] train: loss: 0.0000024
[Epoch 116; Iter   385/ 1097] train: loss: 0.0000014
[Epoch 116; Iter   415/ 1097] train: loss: 0.0008710
[Epoch 116; Iter   445/ 1097] train: loss: 0.0000022
[Epoch 116; Iter   475/ 1097] train: loss: 0.0000109
[Epoch 116; Iter   505/ 1097] train: loss: 0.0000081
[Epoch 116; Iter   535/ 1097] train: loss: 0.0000055
[Epoch 116; Iter   565/ 1097] train: loss: 0.0000000
[Epoch 116; Iter   595/ 1097] train: loss: 0.0000388
[Epoch 116; Iter   625/ 1097] train: loss: 0.0000093
[Epoch 116; Iter   655/ 1097] train: loss: 0.0000256
[Epoch 116; Iter   685/ 1097] train: loss: 0.0000041
[Epoch 116; Iter   715/ 1097] train: loss: 0.0002211
[Epoch 116; Iter   745/ 1097] train: loss: 0.0003885
[Epoch 116; Iter   775/ 1097] train: loss: 0.0000404
[Epoch 116; Iter   805/ 1097] train: loss: 0.0000254
[Epoch 116; Iter   835/ 1097] train: loss: 0.0000074
[Epoch 116; Iter   865/ 1097] train: loss: 0.0001288
[Epoch 116; Iter   895/ 1097] train: loss: 0.0000321
[Epoch 116; Iter   925/ 1097] train: loss: 0.0000009
[Epoch 116; Iter   955/ 1097] train: loss: 0.0000072
[Epoch 116; Iter   985/ 1097] train: loss: 0.0000377
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0001346
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0001348
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0002039
[Epoch 116] ogbg-molhiv: 0.750297 val loss: 1.120701
[Epoch 116] ogbg-molhiv: 0.717650 test loss: 2.242435
[Epoch 117; Iter     8/ 1097] train: loss: 0.0000163
[Epoch 117; Iter    38/ 1097] train: loss: 0.0000079
[Epoch 117; Iter    68/ 1097] train: loss: 0.0000076
[Epoch 117; Iter    98/ 1097] train: loss: 0.0000703
[Epoch 117; Iter   128/ 1097] train: loss: 0.0000006
[Epoch 117; Iter   158/ 1097] train: loss: 0.0000000
[Epoch 117; Iter   188/ 1097] train: loss: 0.0000035
[Epoch 117; Iter   218/ 1097] train: loss: 0.0000209
[Epoch 117; Iter   248/ 1097] train: loss: 0.0000005
[Epoch 117; Iter   278/ 1097] train: loss: 0.0000984
[Epoch 117; Iter   308/ 1097] train: loss: 0.0000011
[Epoch 117; Iter   338/ 1097] train: loss: 0.0000206
[Epoch 117; Iter   368/ 1097] train: loss: 0.0000006
[Epoch 117; Iter   398/ 1097] train: loss: 0.0000007
[Epoch 117; Iter   428/ 1097] train: loss: 0.0000145
[Epoch 117; Iter   458/ 1097] train: loss: 0.0000873
[Epoch 117; Iter   488/ 1097] train: loss: 0.0000564
[Epoch 117; Iter   518/ 1097] train: loss: 0.0001601
[Epoch 117; Iter   548/ 1097] train: loss: 0.0004533
[Epoch 117; Iter   578/ 1097] train: loss: 0.0000074
[Epoch 117; Iter   608/ 1097] train: loss: 0.0000025
[Epoch 117; Iter   638/ 1097] train: loss: 0.0001133
[Epoch 117; Iter   668/ 1097] train: loss: 0.0000080
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000311
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000453
[Epoch 117; Iter   758/ 1097] train: loss: 0.0007363
[Epoch 117; Iter   788/ 1097] train: loss: 0.0001512
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000072
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000022
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000178
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000829
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000332
[Epoch 117; Iter   968/ 1097] train: loss: 0.0000520
[Epoch 117; Iter   998/ 1097] train: loss: 0.0009443
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000241
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000036
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000346
[Epoch 117] ogbg-molhiv: 0.794686 val loss: 0.275630
[Epoch 117] ogbg-molhiv: 0.739371 test loss: 0.424326
[Epoch 118; Iter    21/ 1097] train: loss: 0.0011817
[Epoch 118; Iter    51/ 1097] train: loss: 0.0003935
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000041
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000091
[Epoch 118; Iter   141/ 1097] train: loss: 0.0000054
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000884
[Epoch 118; Iter   201/ 1097] train: loss: 0.0000297
[Epoch 118; Iter   231/ 1097] train: loss: 0.0024220
[Epoch 118; Iter   261/ 1097] train: loss: 0.0012442
[Epoch 118; Iter   291/ 1097] train: loss: 0.0000002
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000032
[Epoch 118; Iter   351/ 1097] train: loss: 0.0000117
[Epoch 118; Iter   381/ 1097] train: loss: 0.0015688
[Epoch 118; Iter   411/ 1097] train: loss: 0.0001861
[Epoch 118; Iter   441/ 1097] train: loss: 0.0003779
[Epoch 118; Iter   471/ 1097] train: loss: 0.0006154
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000125
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000451
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000152
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000451
[Epoch 118; Iter   621/ 1097] train: loss: 0.0001890
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000259
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000106
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000136
[Epoch 118; Iter   741/ 1097] train: loss: 0.0006518
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000101
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000040
[Epoch 118; Iter   831/ 1097] train: loss: 0.0033594
[Epoch 118; Iter   861/ 1097] train: loss: 0.0015260
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000872
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000077
[Epoch 118; Iter   951/ 1097] train: loss: 0.0001109
[Epoch 118; Iter   981/ 1097] train: loss: 0.1086980
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0001335
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0054652
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000030
[Epoch 118] ogbg-molhiv: 0.796070 val loss: 0.268301
[Epoch 118] ogbg-molhiv: 0.737056 test loss: 0.436850
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000792
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000076
[Epoch 119; Iter    64/ 1097] train: loss: 0.0004586
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000093
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000558
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000265
[Epoch 119; Iter   184/ 1097] train: loss: 0.0009168
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000182
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000092
[Epoch 119; Iter   274/ 1097] train: loss: 0.0005828
[Epoch 119; Iter   304/ 1097] train: loss: 0.0004124
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000326
[Epoch 119; Iter   364/ 1097] train: loss: 0.0001192
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000217
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000155
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000038
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000054
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000493
[Epoch 119; Iter   544/ 1097] train: loss: 0.0042843
[Epoch 119; Iter   574/ 1097] train: loss: 0.0001655
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000143
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000768
[Epoch 119; Iter   664/ 1097] train: loss: 0.0001153
[Epoch 119; Iter   694/ 1097] train: loss: 0.0000304
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000111
[Epoch 119; Iter   754/ 1097] train: loss: 0.0000579
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000078
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000234
[Epoch 119; Iter   844/ 1097] train: loss: 0.0001608
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000280
[Epoch 119; Iter   904/ 1097] train: loss: 0.0014408
[Epoch 119; Iter   934/ 1097] train: loss: 0.0002000
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000637
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000924
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0005708
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000622
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000108
[Epoch 119] ogbg-molhiv: 0.788121 val loss: 0.300126
[Epoch 119] ogbg-molhiv: 0.735538 test loss: 0.444887
[Epoch 120; Iter    17/ 1097] train: loss: 0.0002211
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000023
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000134
[Epoch 120; Iter   107/ 1097] train: loss: 0.0001036
[Epoch 120; Iter   137/ 1097] train: loss: 0.0002444
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000303
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000239
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000173
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000036
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000600
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000029
[Epoch 120; Iter   347/ 1097] train: loss: 0.0002712
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000031
[Epoch 120; Iter   407/ 1097] train: loss: 0.0001928
[Epoch 120; Iter   437/ 1097] train: loss: 0.0001072
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000945
[Epoch 120; Iter   497/ 1097] train: loss: 0.0042409
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000091
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000216
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000055
[Epoch 120; Iter   617/ 1097] train: loss: 0.0001486
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000021
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000117
[Epoch 120; Iter   707/ 1097] train: loss: 0.0008583
[Epoch 120; Iter   737/ 1097] train: loss: 0.0000549
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000789
[Epoch 120; Iter   797/ 1097] train: loss: 0.0002453
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000114
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000986
[Epoch 120; Iter   887/ 1097] train: loss: 0.0000014
[Epoch 120; Iter   917/ 1097] train: loss: 0.0000036
[Epoch 120; Iter   947/ 1097] train: loss: 0.0000013
[Epoch 120; Iter   977/ 1097] train: loss: 0.0001188
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000605
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000066
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000004
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0019038
[Epoch 120] ogbg-molhiv: 0.793400 val loss: 0.297687
[Epoch 120] ogbg-molhiv: 0.742922 test loss: 0.449383
[Epoch 121; Iter    30/ 1097] train: loss: 0.0000008
[Epoch 121; Iter    60/ 1097] train: loss: 0.0004617
[Epoch 121; Iter    90/ 1097] train: loss: 0.0000028
[Epoch 121; Iter   120/ 1097] train: loss: 0.0002349
[Epoch 121; Iter   150/ 1097] train: loss: 0.0020222
[Epoch 121; Iter   180/ 1097] train: loss: 0.0000138
[Epoch 121; Iter   210/ 1097] train: loss: 0.0000206
[Epoch 121; Iter   240/ 1097] train: loss: 0.0000071
[Epoch 121; Iter   270/ 1097] train: loss: 0.0000022
[Epoch 121; Iter   300/ 1097] train: loss: 0.0027767
[Epoch 121; Iter   330/ 1097] train: loss: 0.0000086
[Epoch 121; Iter   360/ 1097] train: loss: 0.0000252
[Epoch 121; Iter   390/ 1097] train: loss: 0.0000048
[Epoch 121; Iter   420/ 1097] train: loss: 0.0001871
[Epoch 121; Iter   450/ 1097] train: loss: 0.0008548
[Epoch 121; Iter   480/ 1097] train: loss: 0.0000291
[Epoch 121; Iter   510/ 1097] train: loss: 0.0000019
[Epoch 121; Iter   540/ 1097] train: loss: 0.0002236
[Epoch 121; Iter   570/ 1097] train: loss: 0.0005257
[Epoch 121; Iter   600/ 1097] train: loss: 0.0000867
[Epoch 121; Iter   630/ 1097] train: loss: 0.0000164
[Epoch 121; Iter   660/ 1097] train: loss: 0.0000025
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000072
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000461
[Epoch 117; Iter   758/ 1097] train: loss: 0.0013237
[Epoch 117; Iter   788/ 1097] train: loss: 0.0000533
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000222
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000327
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000457
[Epoch 117; Iter   908/ 1097] train: loss: 0.0003382
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000006
[Epoch 117; Iter   968/ 1097] train: loss: 0.0001795
[Epoch 117; Iter   998/ 1097] train: loss: 0.0000076
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0099146
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000144
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000040
[Epoch 117] ogbg-molhiv: 0.755903 val loss: 0.687264
[Epoch 117] ogbg-molhiv: 0.717662 test loss: 1.046503
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000032
[Epoch 118; Iter    51/ 1097] train: loss: 0.0004484
[Epoch 118; Iter    81/ 1097] train: loss: 0.0003348
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000127
[Epoch 118; Iter   141/ 1097] train: loss: 0.0000010
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000153
[Epoch 118; Iter   201/ 1097] train: loss: 0.0002087
[Epoch 118; Iter   231/ 1097] train: loss: 0.0000395
[Epoch 118; Iter   261/ 1097] train: loss: 0.0011170
[Epoch 118; Iter   291/ 1097] train: loss: 0.0005051
[Epoch 118; Iter   321/ 1097] train: loss: 0.0022968
[Epoch 118; Iter   351/ 1097] train: loss: 0.0001267
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000139
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000952
[Epoch 118; Iter   441/ 1097] train: loss: 0.0006542
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000094
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000008
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000129
[Epoch 118; Iter   561/ 1097] train: loss: 0.0173866
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000015
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000042
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000105
[Epoch 118; Iter   681/ 1097] train: loss: 0.0617328
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000282
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000127
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000259
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000952
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000050
[Epoch 118; Iter   861/ 1097] train: loss: 0.0000990
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000879
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000049
[Epoch 118; Iter   951/ 1097] train: loss: 0.0001609
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000254
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0022371
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000152
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0007081
[Epoch 118] ogbg-molhiv: 0.754302 val loss: 0.744505
[Epoch 118] ogbg-molhiv: 0.720922 test loss: 1.012916
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000034
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000074
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000391
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000166
[Epoch 119; Iter   124/ 1097] train: loss: 0.0003576
[Epoch 119; Iter   154/ 1097] train: loss: 0.0001116
[Epoch 119; Iter   184/ 1097] train: loss: 0.0002247
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000030
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000141
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000660
[Epoch 119; Iter   304/ 1097] train: loss: 0.0043574
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000024
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000020
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000123
[Epoch 119; Iter   424/ 1097] train: loss: 0.0755541
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000068
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000058
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000815
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000168
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000313
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000205
[Epoch 119; Iter   634/ 1097] train: loss: 0.0243724
[Epoch 119; Iter   664/ 1097] train: loss: 0.0041135
[Epoch 119; Iter   694/ 1097] train: loss: 0.0001812
[Epoch 119; Iter   724/ 1097] train: loss: 0.0003666
[Epoch 119; Iter   754/ 1097] train: loss: 0.0000008
[Epoch 119; Iter   784/ 1097] train: loss: 0.0007325
[Epoch 119; Iter   814/ 1097] train: loss: 0.0002520
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000373
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000842
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000198
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000020
[Epoch 119; Iter   964/ 1097] train: loss: 0.0025990
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000023
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000069
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0013179
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000108
[Epoch 119] ogbg-molhiv: 0.794542 val loss: 0.546146
[Epoch 119] ogbg-molhiv: 0.729021 test loss: 1.016615
[Epoch 120; Iter    17/ 1097] train: loss: 0.0000161
[Epoch 120; Iter    47/ 1097] train: loss: 0.0045865
[Epoch 120; Iter    77/ 1097] train: loss: 0.0002232
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000189
[Epoch 120; Iter   137/ 1097] train: loss: 0.0011331
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000385
[Epoch 120; Iter   197/ 1097] train: loss: 0.0001035
[Epoch 120; Iter   227/ 1097] train: loss: 0.0002618
[Epoch 120; Iter   257/ 1097] train: loss: 0.0005360
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000189
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000067
[Epoch 120; Iter   347/ 1097] train: loss: 0.0018803
[Epoch 120; Iter   377/ 1097] train: loss: 0.0001282
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000521
[Epoch 120; Iter   437/ 1097] train: loss: 0.0007657
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000131
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000037
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000134
[Epoch 120; Iter   557/ 1097] train: loss: 0.0001565
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000641
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000030
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000044
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000084
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000868
[Epoch 120; Iter   737/ 1097] train: loss: 0.0000156
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000393
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000124
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000022
[Epoch 120; Iter   857/ 1097] train: loss: 0.0001461
[Epoch 120; Iter   887/ 1097] train: loss: 0.0000065
[Epoch 120; Iter   917/ 1097] train: loss: 0.0000077
[Epoch 120; Iter   947/ 1097] train: loss: 0.0000162
[Epoch 120; Iter   977/ 1097] train: loss: 0.0001848
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000183
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000048
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000194
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0000579
[Epoch 120] ogbg-molhiv: 0.773883 val loss: 0.689241
[Epoch 120] ogbg-molhiv: 0.728419 test loss: 1.158576
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 26.
Statistics on  val_best_checkpoint
mean_pred: -4.3189167976379395
std_pred: 18.263601303100586
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.20879514855386164
rocauc: 0.81322261414854
ogbg-molhiv: 0.81322261414854
BCEWithLogitsLoss: 0.620041250094326
Statistics on  test
mean_pred: -4.695979118347168
std_pred: 4.11740255355835
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2570147383029411
rocauc: 0.7683790725969988
ogbg-molhiv: 0.7683790725969988
BCEWithLogitsLoss: 0.21670147528925884
Statistics on  train
mean_pred: -4.780355930328369
std_pred: 2.121992588043213
mean_targets: 0.03744566813111305
std_targets: 0.18985413014888763
prcauc: 0.7404626966226588
rocauc: 0.9631334751957443
ogbg-molhiv: 0.9631334751957443
BCEWithLogitsLoss: 0.06903221695823977
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000177
[Epoch 117; Iter   728/ 1097] train: loss: 0.0004791
[Epoch 117; Iter   758/ 1097] train: loss: 0.0002095
[Epoch 117; Iter   788/ 1097] train: loss: 0.0008992
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000573
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000540
[Epoch 117; Iter   878/ 1097] train: loss: 0.0002318
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000053
[Epoch 117; Iter   938/ 1097] train: loss: 0.0008581
[Epoch 117; Iter   968/ 1097] train: loss: 0.0001236
[Epoch 117; Iter   998/ 1097] train: loss: 0.0005024
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000041
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000115
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000074
[Epoch 117] ogbg-molhiv: 0.769305 val loss: 0.431587
[Epoch 117] ogbg-molhiv: 0.758197 test loss: 0.390607
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000380
[Epoch 118; Iter    51/ 1097] train: loss: 0.0013603
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000007
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000188
[Epoch 118; Iter   141/ 1097] train: loss: 0.0009722
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000030
[Epoch 118; Iter   201/ 1097] train: loss: 0.0000337
[Epoch 118; Iter   231/ 1097] train: loss: 0.0064710
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000009
[Epoch 118; Iter   291/ 1097] train: loss: 0.0000321
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000007
[Epoch 118; Iter   351/ 1097] train: loss: 0.0000033
[Epoch 118; Iter   381/ 1097] train: loss: 0.0005071
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000018
[Epoch 118; Iter   441/ 1097] train: loss: 0.0008756
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000671
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000147
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000907
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000015
[Epoch 118; Iter   591/ 1097] train: loss: 0.0022417
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000852
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000265
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000400
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000346
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000229
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000129
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000050
[Epoch 118; Iter   831/ 1097] train: loss: 0.0047361
[Epoch 118; Iter   861/ 1097] train: loss: 0.0034128
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000164
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000031
[Epoch 118; Iter   951/ 1097] train: loss: 0.0003583
[Epoch 118; Iter   981/ 1097] train: loss: 0.0124578
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000030
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0001172
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000041
[Epoch 118] ogbg-molhiv: 0.767153 val loss: 0.438853
[Epoch 118] ogbg-molhiv: 0.746868 test loss: 0.412108
[Epoch 119; Iter     4/ 1097] train: loss: 0.0002498
[Epoch 119; Iter    34/ 1097] train: loss: 0.0002056
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000122
[Epoch 119; Iter    94/ 1097] train: loss: 0.0039817
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000004
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000337
[Epoch 119; Iter   184/ 1097] train: loss: 0.0000051
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000139
[Epoch 119; Iter   244/ 1097] train: loss: 0.0004427
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000591
[Epoch 119; Iter   304/ 1097] train: loss: 0.0001174
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000013
[Epoch 119; Iter   364/ 1097] train: loss: 0.0009577
[Epoch 119; Iter   394/ 1097] train: loss: 0.0003502
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000254
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000085
[Epoch 119; Iter   484/ 1097] train: loss: 0.0003490
[Epoch 119; Iter   514/ 1097] train: loss: 0.0006725
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000196
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000976
[Epoch 119; Iter   604/ 1097] train: loss: 0.0020466
[Epoch 119; Iter   634/ 1097] train: loss: 0.0003280
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000380
[Epoch 119; Iter   694/ 1097] train: loss: 0.0005179
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000580
[Epoch 119; Iter   754/ 1097] train: loss: 0.0000632
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000251
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000448
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000077
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000148
[Epoch 119; Iter   904/ 1097] train: loss: 0.0002440
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000120
[Epoch 119; Iter   964/ 1097] train: loss: 0.0001577
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000009
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000011
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000053
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000980
[Epoch 119] ogbg-molhiv: 0.769452 val loss: 0.419638
[Epoch 119] ogbg-molhiv: 0.759074 test loss: 0.385389
[Epoch 120; Iter    17/ 1097] train: loss: 0.0000150
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000091
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000046
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000521
[Epoch 120; Iter   137/ 1097] train: loss: 0.0000055
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000449
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   227/ 1097] train: loss: 0.0001070
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000040
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000632
[Epoch 120; Iter   317/ 1097] train: loss: 0.0002189
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000253
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000572
[Epoch 120; Iter   407/ 1097] train: loss: 0.0009443
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000013
[Epoch 120; Iter   467/ 1097] train: loss: 0.0007244
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000243
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000199
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000155
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000083
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000018
[Epoch 120; Iter   677/ 1097] train: loss: 0.0001835
[Epoch 120; Iter   707/ 1097] train: loss: 0.0440064
[Epoch 120; Iter   737/ 1097] train: loss: 0.0000449
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000095
[Epoch 120; Iter   797/ 1097] train: loss: 0.0054793
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000176
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000041
[Epoch 120; Iter   887/ 1097] train: loss: 0.0020126
[Epoch 120; Iter   917/ 1097] train: loss: 0.0006347
[Epoch 120; Iter   947/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000469
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000024
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000298
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0001809
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0000403
[Epoch 120] ogbg-molhiv: 0.767676 val loss: 0.430975
[Epoch 120] ogbg-molhiv: 0.752025 test loss: 0.412334
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 16.
Statistics on  val_best_checkpoint
mean_pred: -5.303859710693359
std_pred: 20.694595336914062
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.2606722350049871
rocauc: 0.8049094895159711
ogbg-molhiv: 0.8049094895159711
BCEWithLogitsLoss: 0.1896364759903509
Statistics on  test
mean_pred: -4.340088844299316
std_pred: 4.24788236618042
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.25050285748370005
rocauc: 0.7931478012321598
ogbg-molhiv: 0.7931478012321598
BCEWithLogitsLoss: 0.22441372703558402
Statistics on  train
mean_pred: -4.031152725219727
std_pred: 4.097704887390137
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.5225738694530336
rocauc: 0.9021185503214458
ogbg-molhiv: 0.9021185503214458
BCEWithLogitsLoss: 0.10771457136777605
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000057
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000008
[Epoch 117; Iter   758/ 1097] train: loss: 0.0000141
[Epoch 117; Iter   788/ 1097] train: loss: 0.0008835
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000002
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000113
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000764
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000474
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000103
[Epoch 117; Iter   968/ 1097] train: loss: 0.0000002
[Epoch 117; Iter   998/ 1097] train: loss: 0.0000093
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000317
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000108
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000079
[Epoch 117] ogbg-molhiv: 0.775699 val loss: 0.257394
[Epoch 117] ogbg-molhiv: 0.711634 test loss: 0.431521
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000028
[Epoch 118; Iter    51/ 1097] train: loss: 0.0000343
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000004
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000063
[Epoch 118; Iter   141/ 1097] train: loss: 0.0005118
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000363
[Epoch 118; Iter   201/ 1097] train: loss: 0.0001384
[Epoch 118; Iter   231/ 1097] train: loss: 0.0000022
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000128
[Epoch 118; Iter   291/ 1097] train: loss: 0.0007232
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000599
[Epoch 118; Iter   351/ 1097] train: loss: 0.0000163
[Epoch 118; Iter   381/ 1097] train: loss: 0.0002359
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000233
[Epoch 118; Iter   441/ 1097] train: loss: 0.0001523
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000614
[Epoch 118; Iter   501/ 1097] train: loss: 0.0004983
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000039
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000824
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000027
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000063
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000200
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000130
[Epoch 118; Iter   711/ 1097] train: loss: 0.0009973
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000054
[Epoch 118; Iter   771/ 1097] train: loss: 0.0001758
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000006
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000013
[Epoch 118; Iter   861/ 1097] train: loss: 0.0000374
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000567
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000039
[Epoch 118; Iter   951/ 1097] train: loss: 0.0002705
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000181
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000063
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000107
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000037
[Epoch 118] ogbg-molhiv: 0.775910 val loss: 0.250256
[Epoch 118] ogbg-molhiv: 0.711453 test loss: 0.420097
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000160
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000030
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000749
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000699
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000368
[Epoch 119; Iter   154/ 1097] train: loss: 0.0012329
[Epoch 119; Iter   184/ 1097] train: loss: 0.0000062
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000017
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000123
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000101
[Epoch 119; Iter   304/ 1097] train: loss: 0.0000085
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000172
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000036
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000063
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000109
[Epoch 119; Iter   454/ 1097] train: loss: 0.0001050
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000075
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000095
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000060
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000037
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000016
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000145
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000174
[Epoch 119; Iter   694/ 1097] train: loss: 0.0000019
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000310
[Epoch 119; Iter   754/ 1097] train: loss: 0.0000321
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000044
[Epoch 119; Iter   814/ 1097] train: loss: 0.0001158
[Epoch 119; Iter   844/ 1097] train: loss: 0.0052287
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000049
[Epoch 119; Iter   904/ 1097] train: loss: 0.0001210
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000660
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000224
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000307
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000388
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000455
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0002948
[Epoch 119] ogbg-molhiv: 0.777162 val loss: 0.255058
[Epoch 119] ogbg-molhiv: 0.722258 test loss: 0.417913
[Epoch 120; Iter    17/ 1097] train: loss: 0.0001628
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000113
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000021
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000009
[Epoch 120; Iter   137/ 1097] train: loss: 0.0008915
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000013
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000002
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000055
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000636
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000011
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000113
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000062
[Epoch 120; Iter   437/ 1097] train: loss: 0.0001665
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000002
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000124
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000047
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000048
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000112
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000019
[Epoch 120; Iter   647/ 1097] train: loss: 0.0002408
[Epoch 120; Iter   677/ 1097] train: loss: 0.0001249
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000331
[Epoch 120; Iter   737/ 1097] train: loss: 0.0001383
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000080
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000035
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000034
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000095
[Epoch 120; Iter   887/ 1097] train: loss: 0.0000030
[Epoch 120; Iter   917/ 1097] train: loss: 0.0000345
[Epoch 120; Iter   947/ 1097] train: loss: 0.0004353
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000025
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000038
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000102
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000413
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0000003
[Epoch 120] ogbg-molhiv: 0.779768 val loss: 0.259871
[Epoch 120] ogbg-molhiv: 0.717895 test loss: 0.434074
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 19.
Statistics on  val_best_checkpoint
mean_pred: -5.028994560241699
std_pred: 1.6470361948013306
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.23910153520251867
rocauc: 0.8136176023907504
ogbg-molhiv: 0.8136176023907504
BCEWithLogitsLoss: 0.08288439873781434
Statistics on  test
mean_pred: -5.052440643310547
std_pred: 2.300644874572754
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.13431072713343398
rocauc: 0.7154695919195041
ogbg-molhiv: 0.7154695919195041
BCEWithLogitsLoss: 0.17741240353485488
Statistics on  train
mean_pred: -4.726787567138672
std_pred: 1.440312147140503
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.5849228493867404
rocauc: 0.9274225983211901
ogbg-molhiv: 0.9274225983211901
BCEWithLogitsLoss: 0.0902084889401467
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000016
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000023
[Epoch 117; Iter   758/ 1097] train: loss: 0.0000032
[Epoch 117; Iter   788/ 1097] train: loss: 0.0042763
[Epoch 117; Iter   818/ 1097] train: loss: 0.0008210
[Epoch 117; Iter   848/ 1097] train: loss: 0.0051361
[Epoch 117; Iter   878/ 1097] train: loss: 0.0005674
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000014
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000014
[Epoch 117; Iter   968/ 1097] train: loss: 0.0000299
[Epoch 117; Iter   998/ 1097] train: loss: 0.0002235
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000211
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000194
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000125
[Epoch 117] ogbg-molhiv: 0.696732 val loss: 1.357141
[Epoch 117] ogbg-molhiv: 0.685786 test loss: 1.278968
[Epoch 118; Iter    21/ 1097] train: loss: 0.0013935
[Epoch 118; Iter    51/ 1097] train: loss: 0.0006860
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000125
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000165
[Epoch 118; Iter   141/ 1097] train: loss: 0.0017162
[Epoch 118; Iter   171/ 1097] train: loss: 0.0003078
[Epoch 118; Iter   201/ 1097] train: loss: 0.0000022
[Epoch 118; Iter   231/ 1097] train: loss: 0.0000087
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000105
[Epoch 118; Iter   291/ 1097] train: loss: 0.0000183
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000003
[Epoch 118; Iter   351/ 1097] train: loss: 0.0001286
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000026
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000128
[Epoch 118; Iter   441/ 1097] train: loss: 0.0000061
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000208
[Epoch 118; Iter   501/ 1097] train: loss: 0.0016286
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000151
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000837
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000105
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000096
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000008
[Epoch 118; Iter   681/ 1097] train: loss: 0.0001161
[Epoch 118; Iter   711/ 1097] train: loss: 0.0001373
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000169
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000577
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000166
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000010
[Epoch 118; Iter   861/ 1097] train: loss: 0.0000162
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000059
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000017
[Epoch 118; Iter   951/ 1097] train: loss: 0.0000092
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000100
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000003
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000012
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000005
[Epoch 118] ogbg-molhiv: 0.708881 val loss: 1.324778
[Epoch 118] ogbg-molhiv: 0.686593 test loss: 1.047327
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000074
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000090
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000110
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000575
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000034
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000069
[Epoch 119; Iter   184/ 1097] train: loss: 0.0012385
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000142
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000045
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000439
[Epoch 119; Iter   304/ 1097] train: loss: 0.0008168
[Epoch 119; Iter   334/ 1097] train: loss: 0.0028647
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000667
[Epoch 119; Iter   394/ 1097] train: loss: 0.0009443
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000624
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000216
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000766
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000004
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000285
[Epoch 119; Iter   574/ 1097] train: loss: 0.0001224
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000324
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000176
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000188
[Epoch 119; Iter   694/ 1097] train: loss: 0.0000037
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000154
[Epoch 119; Iter   754/ 1097] train: loss: 0.0001746
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000094
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000210
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000026
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000624
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000944
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000126
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000271
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000028
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000116
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000045
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000460
[Epoch 119] ogbg-molhiv: 0.696098 val loss: 2.178275
[Epoch 119] ogbg-molhiv: 0.692976 test loss: 0.924646
[Epoch 120; Iter    17/ 1097] train: loss: 0.0002491
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000027
[Epoch 120; Iter    77/ 1097] train: loss: 0.0001127
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000293
[Epoch 120; Iter   137/ 1097] train: loss: 0.0000481
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000193
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000298
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000147
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000542
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   317/ 1097] train: loss: 0.0015770
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000362
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000196
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000006
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000259
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000009
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000121
[Epoch 120; Iter   527/ 1097] train: loss: 0.0016697
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000024
[Epoch 120; Iter   587/ 1097] train: loss: 0.0011088
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000055
[Epoch 120; Iter   647/ 1097] train: loss: 0.0418905
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000073
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000426
[Epoch 120; Iter   737/ 1097] train: loss: 0.0027428
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000124
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000122
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000223
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000028
[Epoch 120; Iter   887/ 1097] train: loss: 0.0186987
[Epoch 120; Iter   917/ 1097] train: loss: 0.0018496
[Epoch 120; Iter   947/ 1097] train: loss: 0.0000378
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000038
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000031
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000582
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000077
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0011264
[Epoch 120] ogbg-molhiv: 0.692084 val loss: 1.535841
[Epoch 120] ogbg-molhiv: 0.686224 test loss: 0.754195
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 6.
Statistics on  val_best_checkpoint
mean_pred: -3.8028743267059326
std_pred: 1.7596282958984375
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.1650940183615259
rocauc: 0.797040343915344
ogbg-molhiv: 0.797040343915344
BCEWithLogitsLoss: 0.1210841014576347
Statistics on  test
mean_pred: -3.8030760288238525
std_pred: 1.797494649887085
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.1996323994597254
rocauc: 0.7330384905077348
ogbg-molhiv: 0.7330384905077348
BCEWithLogitsLoss: 0.1452294091788539
Statistics on  train
mean_pred: -3.8100337982177734
std_pred: 2.068009614944458
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.24472076109988525
rocauc: 0.7841464244808208
ogbg-molhiv: 0.7841464244808208
BCEWithLogitsLoss: 0.15003982607577482
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000510
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000923
[Epoch 117; Iter   758/ 1097] train: loss: 0.0000028
[Epoch 117; Iter   788/ 1097] train: loss: 0.0000540
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000341
[Epoch 117; Iter   848/ 1097] train: loss: 0.0012836
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000055
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000097
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000747
[Epoch 117; Iter   968/ 1097] train: loss: 0.0057494
[Epoch 117; Iter   998/ 1097] train: loss: 0.0007409
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000036
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0007524
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000100
[Epoch 117] ogbg-molhiv: 0.796468 val loss: 0.471006
[Epoch 117] ogbg-molhiv: 0.804181 test loss: 0.356471
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000408
[Epoch 118; Iter    51/ 1097] train: loss: 0.0071436
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000045
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000003
[Epoch 118; Iter   141/ 1097] train: loss: 0.0000192
[Epoch 118; Iter   171/ 1097] train: loss: 0.0007568
[Epoch 118; Iter   201/ 1097] train: loss: 0.0007905
[Epoch 118; Iter   231/ 1097] train: loss: 0.0000044
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000250
[Epoch 118; Iter   291/ 1097] train: loss: 0.0001076
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000044
[Epoch 118; Iter   351/ 1097] train: loss: 0.0001041
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000103
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000009
[Epoch 118; Iter   441/ 1097] train: loss: 0.0000139
[Epoch 118; Iter   471/ 1097] train: loss: 0.0001030
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000868
[Epoch 118; Iter   531/ 1097] train: loss: 0.0001110
[Epoch 118; Iter   561/ 1097] train: loss: 0.0004215
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000026
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000074
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000198
[Epoch 118; Iter   681/ 1097] train: loss: 0.0001747
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000072
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000265
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000438
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000541
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000012
[Epoch 118; Iter   861/ 1097] train: loss: 0.0000084
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000238
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000032
[Epoch 118; Iter   951/ 1097] train: loss: 0.0001556
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000011
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000475
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000028
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0006235
[Epoch 118] ogbg-molhiv: 0.795032 val loss: 0.319294
[Epoch 118] ogbg-molhiv: 0.811277 test loss: 0.353917
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000343
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000042
[Epoch 119; Iter    64/ 1097] train: loss: 0.0001839
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000112
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000712
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000128
[Epoch 119; Iter   184/ 1097] train: loss: 0.0000529
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000009
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000017
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000050
[Epoch 119; Iter   304/ 1097] train: loss: 0.0000157
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000022
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000066
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000043
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000857
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000141
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000339
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000570
[Epoch 119; Iter   544/ 1097] train: loss: 0.0001688
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000140
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000185
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000117
[Epoch 119; Iter   664/ 1097] train: loss: 0.0001628
[Epoch 119; Iter   694/ 1097] train: loss: 0.0001045
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000106
[Epoch 119; Iter   754/ 1097] train: loss: 0.0001164
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000148
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000038
[Epoch 119; Iter   844/ 1097] train: loss: 0.0001060
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000021
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000036
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000025
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000910
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000146
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000006
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000228
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000095
[Epoch 119] ogbg-molhiv: 0.786504 val loss: 0.492320
[Epoch 119] ogbg-molhiv: 0.805715 test loss: 0.368725
[Epoch 120; Iter    17/ 1097] train: loss: 0.0003220
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000202
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000019
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000303
[Epoch 120; Iter   137/ 1097] train: loss: 0.0000346
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000048
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000046
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000021
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000734
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000078
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000002
[Epoch 120; Iter   347/ 1097] train: loss: 0.0001934
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000474
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000015
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000545
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000002
[Epoch 120; Iter   497/ 1097] train: loss: 0.0001967
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000079
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000009
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000016
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000229
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000104
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000210
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000092
[Epoch 120; Iter   737/ 1097] train: loss: 0.0015732
[Epoch 120; Iter   767/ 1097] train: loss: 0.0106024
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000432
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000015
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000388
[Epoch 120; Iter   887/ 1097] train: loss: 0.0009030
[Epoch 120; Iter   917/ 1097] train: loss: 0.0000064
[Epoch 120; Iter   947/ 1097] train: loss: 0.0002151
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000728
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000182
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0008432
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000193
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0000135
[Epoch 120] ogbg-molhiv: 0.791443 val loss: 0.522737
[Epoch 120] ogbg-molhiv: 0.804934 test loss: 0.362902
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 50.
Statistics on  val_best_checkpoint
mean_pred: -11.963529586791992
std_pred: 10.257389068603516
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.19325237708144993
rocauc: 0.8189116696061141
ogbg-molhiv: 0.8189116696061141
BCEWithLogitsLoss: 0.2720294197615263
Statistics on  test
mean_pred: -11.264447212219238
std_pred: 6.511988162994385
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2607250980108466
rocauc: 0.7974507039533402
ogbg-molhiv: 0.7974507039533402
BCEWithLogitsLoss: 0.24661363571905656
Statistics on  train
mean_pred: -13.09591293334961
std_pred: 11.629701614379883
mean_targets: 0.03744566813111305
std_targets: 0.18985413014888763
prcauc: 0.9461856841047305
rocauc: 0.9994187800106048
ogbg-molhiv: 0.9994187800106048
BCEWithLogitsLoss: 0.030595404166938282
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000003
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000008
[Epoch 117; Iter   758/ 1097] train: loss: 0.0000138
[Epoch 117; Iter   788/ 1097] train: loss: 0.0000088
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000008
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000079
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000142
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000031
[Epoch 117; Iter   938/ 1097] train: loss: 0.0012282
[Epoch 117; Iter   968/ 1097] train: loss: 0.0000065
[Epoch 117; Iter   998/ 1097] train: loss: 0.0000203
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0001429
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000005
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000001
[Epoch 117] ogbg-molhiv: 0.710020 val loss: 4.754043
[Epoch 117] ogbg-molhiv: 0.623181 test loss: 4.227611
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000064
[Epoch 118; Iter    51/ 1097] train: loss: 0.0000875
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000014
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000023
[Epoch 118; Iter   141/ 1097] train: loss: 0.0000387
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000142
[Epoch 118; Iter   201/ 1097] train: loss: 0.0000067
[Epoch 118; Iter   231/ 1097] train: loss: 0.0000054
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000406
[Epoch 118; Iter   291/ 1097] train: loss: 0.0000048
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000036
[Epoch 118; Iter   351/ 1097] train: loss: 0.0003520
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000087
[Epoch 118; Iter   411/ 1097] train: loss: 0.0002832
[Epoch 118; Iter   441/ 1097] train: loss: 0.0003013
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000007
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000033
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000001
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000612
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000714
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000016
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000150
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000146
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000100
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000014
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000033
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000004
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000002
[Epoch 118; Iter   861/ 1097] train: loss: 0.0000076
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000012
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000489
[Epoch 118; Iter   951/ 1097] train: loss: 0.0000242
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000285
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0005653
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000002
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0011547
[Epoch 118] ogbg-molhiv: 0.718542 val loss: 4.347415
[Epoch 118] ogbg-molhiv: 0.609741 test loss: 3.839644
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000006
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000021
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000026
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000059
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000121
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000195
[Epoch 119; Iter   184/ 1097] train: loss: 0.0000007
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000083
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000898
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000012
[Epoch 119; Iter   304/ 1097] train: loss: 0.0000031
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000573
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000119
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000294
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000037
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000044
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000096
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000001
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000065
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000041
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000015
[Epoch 119; Iter   634/ 1097] train: loss: 0.0001076
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000101
[Epoch 119; Iter   694/ 1097] train: loss: 0.0000033
[Epoch 119; Iter   724/ 1097] train: loss: 0.0003432
[Epoch 119; Iter   754/ 1097] train: loss: 0.0001143
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000099
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000086
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000080
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000668
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000217
[Epoch 119; Iter   934/ 1097] train: loss: 0.0002139
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000009
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000011
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000037
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0004614
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0001322
[Epoch 119] ogbg-molhiv: 0.723355 val loss: 3.360380
[Epoch 119] ogbg-molhiv: 0.603772 test loss: 3.514884
[Epoch 120; Iter    17/ 1097] train: loss: 0.0000127
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000096
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000007
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000025
[Epoch 120; Iter   137/ 1097] train: loss: 0.0000012
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000002
[Epoch 120; Iter   197/ 1097] train: loss: 0.0000289
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000001
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000032
[Epoch 120; Iter   287/ 1097] train: loss: 0.0001513
[Epoch 120; Iter   317/ 1097] train: loss: 0.0001099
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000008
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000072
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000034
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000599
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000479
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000170
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000005
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000021
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000027
[Epoch 120; Iter   617/ 1097] train: loss: 0.0001171
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000494
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000163
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000016
[Epoch 120; Iter   737/ 1097] train: loss: 0.0000003
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000023
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000060
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000318
[Epoch 120; Iter   857/ 1097] train: loss: 0.0000038
[Epoch 120; Iter   887/ 1097] train: loss: 0.0000010
[Epoch 120; Iter   917/ 1097] train: loss: 0.0000020
[Epoch 120; Iter   947/ 1097] train: loss: 0.0003564
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000004
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000007
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000011
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000617
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0000782
[Epoch 120] ogbg-molhiv: 0.723817 val loss: 3.161293
[Epoch 120] ogbg-molhiv: 0.608536 test loss: 3.443814
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 11.
Statistics on  val_best_checkpoint
mean_pred: -3.8019020557403564
std_pred: 14.150893211364746
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.19532398029739384
rocauc: 0.7831606407995296
ogbg-molhiv: 0.7831606407995296
BCEWithLogitsLoss: 0.6544726677711351
Statistics on  test
mean_pred: -4.334819793701172
std_pred: 0.9397552609443665
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.14319774156137208
rocauc: 0.676737673574229
ogbg-molhiv: 0.676737673574229
BCEWithLogitsLoss: 0.13699872378070932
Statistics on  train
mean_pred: -3.983348846435547
std_pred: 0.9280576705932617
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.38846112525494164
rocauc: 0.8654826732521008
ogbg-molhiv: 0.8654826732521008
BCEWithLogitsLoss: 0.11846022511626116
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000045
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000286
[Epoch 117; Iter   758/ 1097] train: loss: 0.0016389
[Epoch 117; Iter   788/ 1097] train: loss: 0.0002874
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000009
[Epoch 117; Iter   848/ 1097] train: loss: 0.0002462
[Epoch 117; Iter   878/ 1097] train: loss: 0.0002428
[Epoch 117; Iter   908/ 1097] train: loss: 0.0002400
[Epoch 117; Iter   938/ 1097] train: loss: 0.0000058
[Epoch 117; Iter   968/ 1097] train: loss: 0.0005837
[Epoch 117; Iter   998/ 1097] train: loss: 0.0000200
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0001127
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0007786
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000030
[Epoch 117] ogbg-molhiv: 0.693526 val loss: 47.863115
[Epoch 117] ogbg-molhiv: 0.581296 test loss: 34.368522
[Epoch 118; Iter    21/ 1097] train: loss: 0.0001988
[Epoch 118; Iter    51/ 1097] train: loss: 0.0000014
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000310
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000180
[Epoch 118; Iter   141/ 1097] train: loss: 0.0000071
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000091
[Epoch 118; Iter   201/ 1097] train: loss: 0.0002775
[Epoch 118; Iter   231/ 1097] train: loss: 0.0094941
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000014
[Epoch 118; Iter   291/ 1097] train: loss: 0.0000103
[Epoch 118; Iter   321/ 1097] train: loss: 0.0024382
[Epoch 118; Iter   351/ 1097] train: loss: 0.0020477
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000504
[Epoch 118; Iter   411/ 1097] train: loss: 0.0001226
[Epoch 118; Iter   441/ 1097] train: loss: 0.0001553
[Epoch 118; Iter   471/ 1097] train: loss: 0.0006318
[Epoch 118; Iter   501/ 1097] train: loss: 0.0010521
[Epoch 118; Iter   531/ 1097] train: loss: 0.0001597
[Epoch 118; Iter   561/ 1097] train: loss: 0.0000194
[Epoch 118; Iter   591/ 1097] train: loss: 0.0131894
[Epoch 118; Iter   621/ 1097] train: loss: 0.0058480
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000440
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000099
[Epoch 118; Iter   711/ 1097] train: loss: 0.0000324
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000086
[Epoch 118; Iter   771/ 1097] train: loss: 0.0006011
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000237
[Epoch 118; Iter   831/ 1097] train: loss: 0.0333852
[Epoch 118; Iter   861/ 1097] train: loss: 0.0003075
[Epoch 118; Iter   891/ 1097] train: loss: 0.0000359
[Epoch 118; Iter   921/ 1097] train: loss: 0.0006961
[Epoch 118; Iter   951/ 1097] train: loss: 0.0000649
[Epoch 118; Iter   981/ 1097] train: loss: 0.1242569
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000928
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000344
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000493
[Epoch 118] ogbg-molhiv: 0.691563 val loss: 38.543346
[Epoch 118] ogbg-molhiv: 0.615775 test loss: 27.905339
[Epoch 119; Iter     4/ 1097] train: loss: 0.0006950
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000315
[Epoch 119; Iter    64/ 1097] train: loss: 0.0000535
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000775
[Epoch 119; Iter   124/ 1097] train: loss: 0.0000420
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000383
[Epoch 119; Iter   184/ 1097] train: loss: 0.0001267
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000036
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000194
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000631
[Epoch 119; Iter   304/ 1097] train: loss: 0.0000440
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000131
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000120
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000191
[Epoch 119; Iter   424/ 1097] train: loss: 0.0010259
[Epoch 119; Iter   454/ 1097] train: loss: 0.0002234
[Epoch 119; Iter   484/ 1097] train: loss: 0.0004736
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000507
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000316
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000101
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000009
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000355
[Epoch 119; Iter   664/ 1097] train: loss: 0.0096486
[Epoch 119; Iter   694/ 1097] train: loss: 0.0003325
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000087
[Epoch 119; Iter   754/ 1097] train: loss: 0.0002097
[Epoch 119; Iter   784/ 1097] train: loss: 0.0000053
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000284
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000053
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000954
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000113
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000024
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000849
[Epoch 119; Iter   994/ 1097] train: loss: 0.0000486
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000379
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0021057
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000402
[Epoch 119] ogbg-molhiv: 0.692996 val loss: 49.307426
[Epoch 119] ogbg-molhiv: 0.589117 test loss: 35.866998
[Epoch 120; Iter    17/ 1097] train: loss: 0.0008488
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000240
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000075
[Epoch 120; Iter   107/ 1097] train: loss: 0.0000092
[Epoch 120; Iter   137/ 1097] train: loss: 0.0001186
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000457
[Epoch 120; Iter   197/ 1097] train: loss: 0.0001528
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000107
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000713
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000446
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000034
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000044
[Epoch 120; Iter   377/ 1097] train: loss: 0.0000360
[Epoch 120; Iter   407/ 1097] train: loss: 0.0001460
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000009
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000232
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000284
[Epoch 120; Iter   527/ 1097] train: loss: 0.0000141
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000449
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000057
[Epoch 120; Iter   617/ 1097] train: loss: 0.0001081
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000016
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000143
[Epoch 120; Iter   707/ 1097] train: loss: 0.0004861
[Epoch 120; Iter   737/ 1097] train: loss: 0.0000134
[Epoch 120; Iter   767/ 1097] train: loss: 0.0004832
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000678
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000056
[Epoch 120; Iter   857/ 1097] train: loss: 0.0001041
[Epoch 120; Iter   887/ 1097] train: loss: 0.0014262
[Epoch 120; Iter   917/ 1097] train: loss: 0.0014282
[Epoch 120; Iter   947/ 1097] train: loss: 0.0004854
[Epoch 120; Iter   977/ 1097] train: loss: 0.0021528
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000120
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0000075
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000054
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0006562
[Epoch 120] ogbg-molhiv: 0.703440 val loss: 29.366339
[Epoch 120] ogbg-molhiv: 0.625404 test loss: 22.028365
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 27.
Statistics on  val_best_checkpoint
mean_pred: -6.8346147537231445
std_pred: 14.956586837768555
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.19554544461119924
rocauc: 0.7923892808152069
ogbg-molhiv: 0.7923892808152069
BCEWithLogitsLoss: 0.6479766993830656
Statistics on  test
mean_pred: -6.727200984954834
std_pred: 10.81020450592041
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2456696882253973
rocauc: 0.6935630274821839
ogbg-molhiv: 0.6935630274821839
BCEWithLogitsLoss: 0.4651227291929451
Statistics on  train
mean_pred: -7.240929126739502
std_pred: 12.425176620483398
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.8657689587233222
rocauc: 0.9906244861110028
ogbg-molhiv: 0.9906244861110028
BCEWithLogitsLoss: 0.1667451603475709
[Epoch 117; Iter   698/ 1097] train: loss: 0.0000003
[Epoch 117; Iter   728/ 1097] train: loss: 0.0000015
[Epoch 117; Iter   758/ 1097] train: loss: 0.0000018
[Epoch 117; Iter   788/ 1097] train: loss: 0.0000538
[Epoch 117; Iter   818/ 1097] train: loss: 0.0000065
[Epoch 117; Iter   848/ 1097] train: loss: 0.0000109
[Epoch 117; Iter   878/ 1097] train: loss: 0.0000020
[Epoch 117; Iter   908/ 1097] train: loss: 0.0000026
[Epoch 117; Iter   938/ 1097] train: loss: 0.0003628
[Epoch 117; Iter   968/ 1097] train: loss: 0.0000299
[Epoch 117; Iter   998/ 1097] train: loss: 0.0000151
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0000098
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0000010
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0000074
[Epoch 117] ogbg-molhiv: 0.756161 val loss: 5.666450
[Epoch 117] ogbg-molhiv: 0.665799 test loss: 5.204791
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000136
[Epoch 118; Iter    51/ 1097] train: loss: 0.0000012
[Epoch 118; Iter    81/ 1097] train: loss: 0.0000009
[Epoch 118; Iter   111/ 1097] train: loss: 0.0000003
[Epoch 118; Iter   141/ 1097] train: loss: 0.0001389
[Epoch 118; Iter   171/ 1097] train: loss: 0.0000066
[Epoch 118; Iter   201/ 1097] train: loss: 0.0000265
[Epoch 118; Iter   231/ 1097] train: loss: 0.0001053
[Epoch 118; Iter   261/ 1097] train: loss: 0.0000021
[Epoch 118; Iter   291/ 1097] train: loss: 0.0001394
[Epoch 118; Iter   321/ 1097] train: loss: 0.0000029
[Epoch 118; Iter   351/ 1097] train: loss: 0.0000124
[Epoch 118; Iter   381/ 1097] train: loss: 0.0000492
[Epoch 118; Iter   411/ 1097] train: loss: 0.0000008
[Epoch 118; Iter   441/ 1097] train: loss: 0.0000035
[Epoch 118; Iter   471/ 1097] train: loss: 0.0000010
[Epoch 118; Iter   501/ 1097] train: loss: 0.0000928
[Epoch 118; Iter   531/ 1097] train: loss: 0.0000957
[Epoch 118; Iter   561/ 1097] train: loss: 0.0002876
[Epoch 118; Iter   591/ 1097] train: loss: 0.0000281
[Epoch 118; Iter   621/ 1097] train: loss: 0.0000494
[Epoch 118; Iter   651/ 1097] train: loss: 0.0000123
[Epoch 118; Iter   681/ 1097] train: loss: 0.0000172
[Epoch 118; Iter   711/ 1097] train: loss: 0.0324223
[Epoch 118; Iter   741/ 1097] train: loss: 0.0000019
[Epoch 118; Iter   771/ 1097] train: loss: 0.0000076
[Epoch 118; Iter   801/ 1097] train: loss: 0.0000007
[Epoch 118; Iter   831/ 1097] train: loss: 0.0000013
[Epoch 118; Iter   861/ 1097] train: loss: 0.0003991
[Epoch 118; Iter   891/ 1097] train: loss: 0.0001849
[Epoch 118; Iter   921/ 1097] train: loss: 0.0000241
[Epoch 118; Iter   951/ 1097] train: loss: 0.0001623
[Epoch 118; Iter   981/ 1097] train: loss: 0.0000070
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0000037
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0000068
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000026
[Epoch 118] ogbg-molhiv: 0.774915 val loss: 6.430114
[Epoch 118] ogbg-molhiv: 0.704919 test loss: 7.034357
[Epoch 119; Iter     4/ 1097] train: loss: 0.0000391
[Epoch 119; Iter    34/ 1097] train: loss: 0.0000137
[Epoch 119; Iter    64/ 1097] train: loss: 0.0030393
[Epoch 119; Iter    94/ 1097] train: loss: 0.0000296
[Epoch 119; Iter   124/ 1097] train: loss: 0.0001180
[Epoch 119; Iter   154/ 1097] train: loss: 0.0000021
[Epoch 119; Iter   184/ 1097] train: loss: 0.0001879
[Epoch 119; Iter   214/ 1097] train: loss: 0.0000026
[Epoch 119; Iter   244/ 1097] train: loss: 0.0000004
[Epoch 119; Iter   274/ 1097] train: loss: 0.0000023
[Epoch 119; Iter   304/ 1097] train: loss: 0.0000221
[Epoch 119; Iter   334/ 1097] train: loss: 0.0000173
[Epoch 119; Iter   364/ 1097] train: loss: 0.0000078
[Epoch 119; Iter   394/ 1097] train: loss: 0.0000010
[Epoch 119; Iter   424/ 1097] train: loss: 0.0000171
[Epoch 119; Iter   454/ 1097] train: loss: 0.0000259
[Epoch 119; Iter   484/ 1097] train: loss: 0.0000209
[Epoch 119; Iter   514/ 1097] train: loss: 0.0000066
[Epoch 119; Iter   544/ 1097] train: loss: 0.0000172
[Epoch 119; Iter   574/ 1097] train: loss: 0.0000012
[Epoch 119; Iter   604/ 1097] train: loss: 0.0000027
[Epoch 119; Iter   634/ 1097] train: loss: 0.0000477
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000479
[Epoch 119; Iter   694/ 1097] train: loss: 0.0000603
[Epoch 119; Iter   724/ 1097] train: loss: 0.0000002
[Epoch 119; Iter   754/ 1097] train: loss: 0.0000019
[Epoch 119; Iter   784/ 1097] train: loss: 0.0006466
[Epoch 119; Iter   814/ 1097] train: loss: 0.0000076
[Epoch 119; Iter   844/ 1097] train: loss: 0.0000008
[Epoch 119; Iter   874/ 1097] train: loss: 0.0000026
[Epoch 119; Iter   904/ 1097] train: loss: 0.0000040
[Epoch 119; Iter   934/ 1097] train: loss: 0.0000007
[Epoch 119; Iter   964/ 1097] train: loss: 0.0000017
[Epoch 119; Iter   994/ 1097] train: loss: 0.0004429
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0000036
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0000618
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0000042
[Epoch 119] ogbg-molhiv: 0.759428 val loss: 7.169951
[Epoch 119] ogbg-molhiv: 0.688561 test loss: 7.550997
[Epoch 120; Iter    17/ 1097] train: loss: 0.0006886
[Epoch 120; Iter    47/ 1097] train: loss: 0.0000029
[Epoch 120; Iter    77/ 1097] train: loss: 0.0000034
[Epoch 120; Iter   107/ 1097] train: loss: 0.0006539
[Epoch 120; Iter   137/ 1097] train: loss: 0.0010550
[Epoch 120; Iter   167/ 1097] train: loss: 0.0000005
[Epoch 120; Iter   197/ 1097] train: loss: 0.0061499
[Epoch 120; Iter   227/ 1097] train: loss: 0.0000028
[Epoch 120; Iter   257/ 1097] train: loss: 0.0000009
[Epoch 120; Iter   287/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   317/ 1097] train: loss: 0.0000890
[Epoch 120; Iter   347/ 1097] train: loss: 0.0000011
[Epoch 120; Iter   377/ 1097] train: loss: 0.0004844
[Epoch 120; Iter   407/ 1097] train: loss: 0.0000057
[Epoch 120; Iter   437/ 1097] train: loss: 0.0000121
[Epoch 120; Iter   467/ 1097] train: loss: 0.0000018
[Epoch 120; Iter   497/ 1097] train: loss: 0.0000031
[Epoch 120; Iter   527/ 1097] train: loss: 0.0008576
[Epoch 120; Iter   557/ 1097] train: loss: 0.0000004
[Epoch 120; Iter   587/ 1097] train: loss: 0.0000007
[Epoch 120; Iter   617/ 1097] train: loss: 0.0000069
[Epoch 120; Iter   647/ 1097] train: loss: 0.0000339
[Epoch 120; Iter   677/ 1097] train: loss: 0.0000011
[Epoch 120; Iter   707/ 1097] train: loss: 0.0000053
[Epoch 120; Iter   737/ 1097] train: loss: 0.0026769
[Epoch 120; Iter   767/ 1097] train: loss: 0.0000404
[Epoch 120; Iter   797/ 1097] train: loss: 0.0000577
[Epoch 120; Iter   827/ 1097] train: loss: 0.0000003
[Epoch 120; Iter   857/ 1097] train: loss: 0.0002328
[Epoch 120; Iter   887/ 1097] train: loss: 0.0000032
[Epoch 120; Iter   917/ 1097] train: loss: 0.0037863
[Epoch 120; Iter   947/ 1097] train: loss: 0.0019703
[Epoch 120; Iter   977/ 1097] train: loss: 0.0000876
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0000011
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0002677
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0000627
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0001052
[Epoch 120] ogbg-molhiv: 0.749066 val loss: 1.736983
[Epoch 120] ogbg-molhiv: 0.692250 test loss: 3.707315
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 20.
Statistics on  val_best_checkpoint
mean_pred: -4.839085102081299
std_pred: 2.3898184299468994
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.2637627511882468
rocauc: 0.8008799970605527
ogbg-molhiv: 0.8008799970605527
BCEWithLogitsLoss: 0.10422745936133045
Statistics on  test
mean_pred: -4.569527626037598
std_pred: 2.0754494667053223
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.15439852465995973
rocauc: 0.6866818594410863
ogbg-molhiv: 0.6866818594410863
BCEWithLogitsLoss: 0.16161147065703635
Statistics on  train
mean_pred: -4.3045654296875
std_pred: 2.0817439556121826
mean_targets: 0.03744566813111305
std_targets: 0.18985413014888763
prcauc: 0.7263206430762086
rocauc: 0.9649057130308513
ogbg-molhiv: 0.9649057130308513
BCEWithLogitsLoss: 0.07647606131001804
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 93; Iter   596/ 1097] train: loss: 0.0059494
[Epoch 93; Iter   626/ 1097] train: loss: 0.0110368
[Epoch 93; Iter   656/ 1097] train: loss: 0.0069641
[Epoch 93; Iter   686/ 1097] train: loss: 0.0015319
[Epoch 93; Iter   716/ 1097] train: loss: 0.0358246
[Epoch 93; Iter   746/ 1097] train: loss: 0.0047407
[Epoch 93; Iter   776/ 1097] train: loss: 0.0022463
[Epoch 93; Iter   806/ 1097] train: loss: 0.0042680
[Epoch 93; Iter   836/ 1097] train: loss: 0.0042921
[Epoch 93; Iter   866/ 1097] train: loss: 0.0030517
[Epoch 93; Iter   896/ 1097] train: loss: 0.0140515
[Epoch 93; Iter   926/ 1097] train: loss: 0.0098841
[Epoch 93; Iter   956/ 1097] train: loss: 0.0027835
[Epoch 93; Iter   986/ 1097] train: loss: 0.0090204
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0342877
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0017198
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0640292
[Epoch 93] ogbg-molhiv: 0.813994 val loss: 0.125460
[Epoch 93] ogbg-molhiv: 0.752589 test loss: 0.239383
[Epoch 94; Iter     9/ 1097] train: loss: 0.0410862
[Epoch 94; Iter    39/ 1097] train: loss: 0.0182250
[Epoch 94; Iter    69/ 1097] train: loss: 0.0102223
[Epoch 94; Iter    99/ 1097] train: loss: 0.0259284
[Epoch 94; Iter   129/ 1097] train: loss: 0.0006877
[Epoch 94; Iter   159/ 1097] train: loss: 0.0074370
[Epoch 94; Iter   189/ 1097] train: loss: 0.0027642
[Epoch 94; Iter   219/ 1097] train: loss: 0.0402553
[Epoch 94; Iter   249/ 1097] train: loss: 0.0156555
[Epoch 94; Iter   279/ 1097] train: loss: 0.0012148
[Epoch 94; Iter   309/ 1097] train: loss: 0.0080883
[Epoch 94; Iter   339/ 1097] train: loss: 0.0045863
[Epoch 94; Iter   369/ 1097] train: loss: 0.0696051
[Epoch 94; Iter   399/ 1097] train: loss: 0.0603066
[Epoch 94; Iter   429/ 1097] train: loss: 0.0203108
[Epoch 94; Iter   459/ 1097] train: loss: 0.0134634
[Epoch 94; Iter   489/ 1097] train: loss: 0.0094072
[Epoch 94; Iter   519/ 1097] train: loss: 0.0022248
[Epoch 94; Iter   549/ 1097] train: loss: 0.0057331
[Epoch 94; Iter   579/ 1097] train: loss: 0.0065071
[Epoch 94; Iter   609/ 1097] train: loss: 0.0535655
[Epoch 94; Iter   639/ 1097] train: loss: 0.0124586
[Epoch 94; Iter   669/ 1097] train: loss: 0.0156879
[Epoch 94; Iter   699/ 1097] train: loss: 0.0080084
[Epoch 94; Iter   729/ 1097] train: loss: 0.0029990
[Epoch 94; Iter   759/ 1097] train: loss: 0.0178253
[Epoch 94; Iter   789/ 1097] train: loss: 0.0840441
[Epoch 94; Iter   819/ 1097] train: loss: 0.0026208
[Epoch 94; Iter   849/ 1097] train: loss: 0.0112185
[Epoch 94; Iter   879/ 1097] train: loss: 0.0278889
[Epoch 94; Iter   909/ 1097] train: loss: 0.0115111
[Epoch 94; Iter   939/ 1097] train: loss: 0.0618902
[Epoch 94; Iter   969/ 1097] train: loss: 0.0025452
[Epoch 94; Iter   999/ 1097] train: loss: 0.0181215
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0043955
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0080193
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0345699
[Epoch 94] ogbg-molhiv: 0.818817 val loss: 0.129996
[Epoch 94] ogbg-molhiv: 0.750619 test loss: 0.248189
[Epoch 95; Iter    22/ 1097] train: loss: 0.0120130
[Epoch 95; Iter    52/ 1097] train: loss: 0.0006401
[Epoch 95; Iter    82/ 1097] train: loss: 0.0104741
[Epoch 95; Iter   112/ 1097] train: loss: 0.0018563
[Epoch 95; Iter   142/ 1097] train: loss: 0.0530173
[Epoch 95; Iter   172/ 1097] train: loss: 0.0041727
[Epoch 95; Iter   202/ 1097] train: loss: 0.0026942
[Epoch 95; Iter   232/ 1097] train: loss: 0.0099659
[Epoch 95; Iter   262/ 1097] train: loss: 0.0070828
[Epoch 95; Iter   292/ 1097] train: loss: 0.0069152
[Epoch 95; Iter   322/ 1097] train: loss: 0.0019143
[Epoch 95; Iter   352/ 1097] train: loss: 0.0686402
[Epoch 95; Iter   382/ 1097] train: loss: 0.0183693
[Epoch 95; Iter   412/ 1097] train: loss: 0.0085638
[Epoch 95; Iter   442/ 1097] train: loss: 0.0022442
[Epoch 95; Iter   472/ 1097] train: loss: 0.0071830
[Epoch 95; Iter   502/ 1097] train: loss: 0.0144853
[Epoch 95; Iter   532/ 1097] train: loss: 0.0106690
[Epoch 95; Iter   562/ 1097] train: loss: 0.0251337
[Epoch 95; Iter   592/ 1097] train: loss: 0.0019055
[Epoch 95; Iter   622/ 1097] train: loss: 0.1943763
[Epoch 95; Iter   652/ 1097] train: loss: 0.2767270
[Epoch 95; Iter   682/ 1097] train: loss: 0.0272462
[Epoch 95; Iter   712/ 1097] train: loss: 0.0064701
[Epoch 95; Iter   742/ 1097] train: loss: 0.0061574
[Epoch 95; Iter   772/ 1097] train: loss: 0.0117260
[Epoch 95; Iter   802/ 1097] train: loss: 0.0015967
[Epoch 95; Iter   832/ 1097] train: loss: 0.0046397
[Epoch 95; Iter   862/ 1097] train: loss: 0.0023303
[Epoch 95; Iter   892/ 1097] train: loss: 0.0037430
[Epoch 95; Iter   922/ 1097] train: loss: 0.0140268
[Epoch 95; Iter   952/ 1097] train: loss: 0.0425749
[Epoch 95; Iter   982/ 1097] train: loss: 0.0087453
[Epoch 95; Iter  1012/ 1097] train: loss: 0.4013788
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0032146
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0050220
[Epoch 95] ogbg-molhiv: 0.816487 val loss: 0.131856
[Epoch 95] ogbg-molhiv: 0.747488 test loss: 0.256565
[Epoch 96; Iter     5/ 1097] train: loss: 0.0014941
[Epoch 96; Iter    35/ 1097] train: loss: 0.0555005
[Epoch 96; Iter    65/ 1097] train: loss: 0.0028433
[Epoch 96; Iter    95/ 1097] train: loss: 0.0014917
[Epoch 96; Iter   125/ 1097] train: loss: 0.0025235
[Epoch 96; Iter   155/ 1097] train: loss: 0.0140403
[Epoch 96; Iter   185/ 1097] train: loss: 0.0044888
[Epoch 96; Iter   215/ 1097] train: loss: 0.0026645
[Epoch 96; Iter   245/ 1097] train: loss: 0.0232962
[Epoch 96; Iter   275/ 1097] train: loss: 0.0314912
[Epoch 96; Iter   305/ 1097] train: loss: 0.0023914
[Epoch 96; Iter   335/ 1097] train: loss: 0.0050181
[Epoch 96; Iter   365/ 1097] train: loss: 0.0830226
[Epoch 96; Iter   395/ 1097] train: loss: 0.0172034
[Epoch 96; Iter   425/ 1097] train: loss: 0.0058796
[Epoch 96; Iter   455/ 1097] train: loss: 0.0034409
[Epoch 96; Iter   485/ 1097] train: loss: 0.0582411
[Epoch 96; Iter   515/ 1097] train: loss: 0.0532079
[Epoch 96; Iter   545/ 1097] train: loss: 0.0069362
[Epoch 96; Iter   575/ 1097] train: loss: 0.1354866
[Epoch 96; Iter   605/ 1097] train: loss: 0.0013223
[Epoch 96; Iter   635/ 1097] train: loss: 0.0432323
[Epoch 96; Iter   665/ 1097] train: loss: 0.0331625
[Epoch 96; Iter   695/ 1097] train: loss: 0.0433784
[Epoch 96; Iter   725/ 1097] train: loss: 0.1681048
[Epoch 96; Iter   755/ 1097] train: loss: 0.0048296
[Epoch 96; Iter   785/ 1097] train: loss: 0.0416473
[Epoch 96; Iter   815/ 1097] train: loss: 0.0015403
[Epoch 96; Iter   845/ 1097] train: loss: 0.0006437
[Epoch 96; Iter   875/ 1097] train: loss: 0.0122382
[Epoch 96; Iter   905/ 1097] train: loss: 0.0561212
[Epoch 96; Iter   935/ 1097] train: loss: 0.0053685
[Epoch 96; Iter   965/ 1097] train: loss: 0.0106686
[Epoch 96; Iter   995/ 1097] train: loss: 0.0074287
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0207676
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0210193
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0213258
[Epoch 96] ogbg-molhiv: 0.821643 val loss: 0.128756
[Epoch 96] ogbg-molhiv: 0.752602 test loss: 0.245324
[Epoch 97; Iter    18/ 1097] train: loss: 0.0351434
[Epoch 97; Iter    48/ 1097] train: loss: 0.0053297
[Epoch 97; Iter    78/ 1097] train: loss: 0.0260712
[Epoch 97; Iter   108/ 1097] train: loss: 0.0404705
[Epoch 97; Iter   138/ 1097] train: loss: 0.0042802
[Epoch 97; Iter   168/ 1097] train: loss: 0.0269815
[Epoch 97; Iter   198/ 1097] train: loss: 0.0230238
[Epoch 97; Iter   228/ 1097] train: loss: 0.0074992
[Epoch 97; Iter   258/ 1097] train: loss: 0.0017482
[Epoch 97; Iter   288/ 1097] train: loss: 0.0191610
[Epoch 97; Iter   318/ 1097] train: loss: 0.0113589
[Epoch 97; Iter   348/ 1097] train: loss: 0.0189641
[Epoch 97; Iter   378/ 1097] train: loss: 0.0104316
[Epoch 97; Iter   408/ 1097] train: loss: 0.0054797
[Epoch 97; Iter   438/ 1097] train: loss: 0.0008527
[Epoch 97; Iter   468/ 1097] train: loss: 0.0096848
[Epoch 97; Iter   498/ 1097] train: loss: 0.0562471
[Epoch 97; Iter   528/ 1097] train: loss: 0.0155193
[Epoch 97; Iter   558/ 1097] train: loss: 0.0388091
[Epoch 97; Iter   588/ 1097] train: loss: 0.0037699
[Epoch 97; Iter   618/ 1097] train: loss: 0.0028654
[Epoch 97; Iter   648/ 1097] train: loss: 0.0987970
[Epoch 121; Iter   690/ 1097] train: loss: 0.0000046
[Epoch 121; Iter   720/ 1097] train: loss: 0.0158308
[Epoch 121; Iter   750/ 1097] train: loss: 0.0000084
[Epoch 121; Iter   780/ 1097] train: loss: 0.0001125
[Epoch 121; Iter   810/ 1097] train: loss: 0.0002029
[Epoch 121; Iter   840/ 1097] train: loss: 0.0000362
[Epoch 121; Iter   870/ 1097] train: loss: 0.0000560
[Epoch 121; Iter   900/ 1097] train: loss: 0.0000033
[Epoch 121; Iter   930/ 1097] train: loss: 0.0000086
[Epoch 121; Iter   960/ 1097] train: loss: 0.0000692
[Epoch 121; Iter   990/ 1097] train: loss: 0.0000425
[Epoch 121; Iter  1020/ 1097] train: loss: 0.0000056
[Epoch 121; Iter  1050/ 1097] train: loss: 0.0000073
[Epoch 121; Iter  1080/ 1097] train: loss: 0.0000195
[Epoch 121] ogbg-molhiv: 0.791103 val loss: 0.283620
[Epoch 121] ogbg-molhiv: 0.740321 test loss: 0.437082
[Epoch 122; Iter    13/ 1097] train: loss: 0.0000152
[Epoch 122; Iter    43/ 1097] train: loss: 0.0000588
[Epoch 122; Iter    73/ 1097] train: loss: 0.0016449
[Epoch 122; Iter   103/ 1097] train: loss: 0.0000149
[Epoch 122; Iter   133/ 1097] train: loss: 0.0000009
[Epoch 122; Iter   163/ 1097] train: loss: 0.0007586
[Epoch 122; Iter   193/ 1097] train: loss: 0.0008254
[Epoch 122; Iter   223/ 1097] train: loss: 0.0000069
[Epoch 122; Iter   253/ 1097] train: loss: 0.0001778
[Epoch 122; Iter   283/ 1097] train: loss: 0.0000090
[Epoch 122; Iter   313/ 1097] train: loss: 0.0000117
[Epoch 122; Iter   343/ 1097] train: loss: 0.0000126
[Epoch 122; Iter   373/ 1097] train: loss: 0.0000456
[Epoch 122; Iter   403/ 1097] train: loss: 0.0009803
[Epoch 122; Iter   433/ 1097] train: loss: 0.0000040
[Epoch 122; Iter   463/ 1097] train: loss: 0.0000383
[Epoch 122; Iter   493/ 1097] train: loss: 0.0000236
[Epoch 122; Iter   523/ 1097] train: loss: 0.0640211
[Epoch 122; Iter   553/ 1097] train: loss: 0.0000055
[Epoch 122; Iter   583/ 1097] train: loss: 0.0000170
[Epoch 122; Iter   613/ 1097] train: loss: 0.0000041
[Epoch 122; Iter   643/ 1097] train: loss: 0.0000028
[Epoch 122; Iter   673/ 1097] train: loss: 0.0000051
[Epoch 122; Iter   703/ 1097] train: loss: 0.0000236
[Epoch 122; Iter   733/ 1097] train: loss: 0.0001628
[Epoch 122; Iter   763/ 1097] train: loss: 0.0000739
[Epoch 122; Iter   793/ 1097] train: loss: 0.0000092
[Epoch 122; Iter   823/ 1097] train: loss: 0.0000684
[Epoch 122; Iter   853/ 1097] train: loss: 0.0000131
[Epoch 122; Iter   883/ 1097] train: loss: 0.0000125
[Epoch 122; Iter   913/ 1097] train: loss: 0.0000041
[Epoch 122; Iter   943/ 1097] train: loss: 0.0011041
[Epoch 122; Iter   973/ 1097] train: loss: 0.0002124
[Epoch 122; Iter  1003/ 1097] train: loss: 0.0000089
[Epoch 122; Iter  1033/ 1097] train: loss: 0.0002639
[Epoch 122; Iter  1063/ 1097] train: loss: 0.0000048
[Epoch 122; Iter  1093/ 1097] train: loss: 0.0000051
[Epoch 122] ogbg-molhiv: 0.782282 val loss: 0.310161
[Epoch 122] ogbg-molhiv: 0.736046 test loss: 0.476387
[Epoch 123; Iter    26/ 1097] train: loss: 0.0000123
[Epoch 123; Iter    56/ 1097] train: loss: 0.0000596
[Epoch 123; Iter    86/ 1097] train: loss: 0.0000330
[Epoch 123; Iter   116/ 1097] train: loss: 0.0000124
[Epoch 123; Iter   146/ 1097] train: loss: 0.0000047
[Epoch 123; Iter   176/ 1097] train: loss: 0.0000151
[Epoch 123; Iter   206/ 1097] train: loss: 0.0000398
[Epoch 123; Iter   236/ 1097] train: loss: 0.0003138
[Epoch 123; Iter   266/ 1097] train: loss: 0.0000029
[Epoch 123; Iter   296/ 1097] train: loss: 0.0000019
[Epoch 123; Iter   326/ 1097] train: loss: 0.0007817
[Epoch 123; Iter   356/ 1097] train: loss: 0.0001430
[Epoch 123; Iter   386/ 1097] train: loss: 0.0000118
[Epoch 123; Iter   416/ 1097] train: loss: 0.0000534
[Epoch 123; Iter   446/ 1097] train: loss: 0.0012800
[Epoch 123; Iter   476/ 1097] train: loss: 0.0000091
[Epoch 123; Iter   506/ 1097] train: loss: 0.0000352
[Epoch 123; Iter   536/ 1097] train: loss: 0.0000262
[Epoch 123; Iter   566/ 1097] train: loss: 0.0000188
[Epoch 123; Iter   596/ 1097] train: loss: 0.0000023
[Epoch 123; Iter   626/ 1097] train: loss: 0.0008634
[Epoch 123; Iter   656/ 1097] train: loss: 0.0002782
[Epoch 123; Iter   686/ 1097] train: loss: 0.0000014
[Epoch 123; Iter   716/ 1097] train: loss: 0.0077572
[Epoch 123; Iter   746/ 1097] train: loss: 0.0000818
[Epoch 123; Iter   776/ 1097] train: loss: 0.0008994
[Epoch 123; Iter   806/ 1097] train: loss: 0.0000086
[Epoch 123; Iter   836/ 1097] train: loss: 0.0008172
[Epoch 123; Iter   866/ 1097] train: loss: 0.0000209
[Epoch 123; Iter   896/ 1097] train: loss: 0.0000639
[Epoch 123; Iter   926/ 1097] train: loss: 0.0001085
[Epoch 123; Iter   956/ 1097] train: loss: 0.0000199
[Epoch 123; Iter   986/ 1097] train: loss: 0.0000787
[Epoch 123; Iter  1016/ 1097] train: loss: 0.0000068
[Epoch 123; Iter  1046/ 1097] train: loss: 0.0000416
[Epoch 123; Iter  1076/ 1097] train: loss: 0.0000287
[Epoch 123] ogbg-molhiv: 0.792279 val loss: 0.310393
[Epoch 123] ogbg-molhiv: 0.741078 test loss: 0.435123
[Epoch 124; Iter     9/ 1097] train: loss: 0.0000023
[Epoch 124; Iter    39/ 1097] train: loss: 0.0001536
[Epoch 124; Iter    69/ 1097] train: loss: 0.0000054
[Epoch 124; Iter    99/ 1097] train: loss: 0.0000755
[Epoch 124; Iter   129/ 1097] train: loss: 0.0000080
[Epoch 124; Iter   159/ 1097] train: loss: 0.0001393
[Epoch 124; Iter   189/ 1097] train: loss: 0.0012943
[Epoch 124; Iter   219/ 1097] train: loss: 0.0000919
[Epoch 124; Iter   249/ 1097] train: loss: 0.0000047
[Epoch 124; Iter   279/ 1097] train: loss: 0.0016759
[Epoch 124; Iter   309/ 1097] train: loss: 0.0000560
[Epoch 124; Iter   339/ 1097] train: loss: 0.0000268
[Epoch 124; Iter   369/ 1097] train: loss: 0.0000082
[Epoch 124; Iter   399/ 1097] train: loss: 0.0000026
[Epoch 124; Iter   429/ 1097] train: loss: 0.0000254
[Epoch 124; Iter   459/ 1097] train: loss: 0.0000059
[Epoch 124; Iter   489/ 1097] train: loss: 0.0000033
[Epoch 124; Iter   519/ 1097] train: loss: 0.0000733
[Epoch 124; Iter   549/ 1097] train: loss: 0.0778731
[Epoch 124; Iter   579/ 1097] train: loss: 0.0000070
[Epoch 124; Iter   609/ 1097] train: loss: 0.0000473
[Epoch 124; Iter   639/ 1097] train: loss: 0.0000728
[Epoch 124; Iter   669/ 1097] train: loss: 0.0001491
[Epoch 124; Iter   699/ 1097] train: loss: 0.0000017
[Epoch 124; Iter   729/ 1097] train: loss: 0.0001894
[Epoch 124; Iter   759/ 1097] train: loss: 0.0000075
[Epoch 124; Iter   789/ 1097] train: loss: 0.0000082
[Epoch 124; Iter   819/ 1097] train: loss: 0.0000433
[Epoch 124; Iter   849/ 1097] train: loss: 0.0000598
[Epoch 124; Iter   879/ 1097] train: loss: 0.0000328
[Epoch 124; Iter   909/ 1097] train: loss: 0.0000195
[Epoch 124; Iter   939/ 1097] train: loss: 0.0000008
[Epoch 124; Iter   969/ 1097] train: loss: 0.0000037
[Epoch 124; Iter   999/ 1097] train: loss: 0.0001676
[Epoch 124; Iter  1029/ 1097] train: loss: 0.0000530
[Epoch 124; Iter  1059/ 1097] train: loss: 0.0000025
[Epoch 124; Iter  1089/ 1097] train: loss: 0.0000201
[Epoch 124] ogbg-molhiv: 0.790093 val loss: 0.339804
[Epoch 124] ogbg-molhiv: 0.732353 test loss: 0.428339
[Epoch 125; Iter    22/ 1097] train: loss: 0.0000147
[Epoch 125; Iter    52/ 1097] train: loss: 0.0000104
[Epoch 125; Iter    82/ 1097] train: loss: 0.0000584
[Epoch 125; Iter   112/ 1097] train: loss: 0.0000254
[Epoch 125; Iter   142/ 1097] train: loss: 0.0000028
[Epoch 125; Iter   172/ 1097] train: loss: 0.0000049
[Epoch 125; Iter   202/ 1097] train: loss: 0.0000012
[Epoch 125; Iter   232/ 1097] train: loss: 0.0000108
[Epoch 125; Iter   262/ 1097] train: loss: 0.0000038
[Epoch 125; Iter   292/ 1097] train: loss: 0.0000292
[Epoch 125; Iter   322/ 1097] train: loss: 0.0000246
[Epoch 125; Iter   352/ 1097] train: loss: 0.0000124
[Epoch 125; Iter   382/ 1097] train: loss: 0.0002473
[Epoch 125; Iter   412/ 1097] train: loss: 0.0000871
[Epoch 125; Iter   442/ 1097] train: loss: 0.0000085
[Epoch 125; Iter   472/ 1097] train: loss: 0.0000091
[Epoch 125; Iter   502/ 1097] train: loss: 0.0001363
[Epoch 125; Iter   532/ 1097] train: loss: 0.0000355
[Epoch 125; Iter   562/ 1097] train: loss: 0.0000787
[Epoch 125; Iter   592/ 1097] train: loss: 0.0000028
[Epoch 125; Iter   622/ 1097] train: loss: 0.0000478
[Epoch 125; Iter   652/ 1097] train: loss: 0.0000552
[Epoch 93; Iter   596/ 1097] train: loss: 0.0016210
[Epoch 93; Iter   626/ 1097] train: loss: 0.0026462
[Epoch 93; Iter   656/ 1097] train: loss: 0.0085388
[Epoch 93; Iter   686/ 1097] train: loss: 0.0574857
[Epoch 93; Iter   716/ 1097] train: loss: 0.0192725
[Epoch 93; Iter   746/ 1097] train: loss: 0.0469350
[Epoch 93; Iter   776/ 1097] train: loss: 0.0309341
[Epoch 93; Iter   806/ 1097] train: loss: 0.0563111
[Epoch 93; Iter   836/ 1097] train: loss: 0.0028600
[Epoch 93; Iter   866/ 1097] train: loss: 0.0355238
[Epoch 93; Iter   896/ 1097] train: loss: 0.0044566
[Epoch 93; Iter   926/ 1097] train: loss: 0.0113833
[Epoch 93; Iter   956/ 1097] train: loss: 0.0045687
[Epoch 93; Iter   986/ 1097] train: loss: 0.0081037
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0085850
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0153454
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0168614
[Epoch 93] ogbg-molhiv: 0.801639 val loss: 0.129328
[Epoch 93] ogbg-molhiv: 0.738230 test loss: 0.274441
[Epoch 94; Iter     9/ 1097] train: loss: 0.0285089
[Epoch 94; Iter    39/ 1097] train: loss: 0.0219734
[Epoch 94; Iter    69/ 1097] train: loss: 0.0402159
[Epoch 94; Iter    99/ 1097] train: loss: 0.0087909
[Epoch 94; Iter   129/ 1097] train: loss: 0.1379867
[Epoch 94; Iter   159/ 1097] train: loss: 0.0243847
[Epoch 94; Iter   189/ 1097] train: loss: 0.0710538
[Epoch 94; Iter   219/ 1097] train: loss: 0.0034752
[Epoch 94; Iter   249/ 1097] train: loss: 0.0983137
[Epoch 94; Iter   279/ 1097] train: loss: 0.0070455
[Epoch 94; Iter   309/ 1097] train: loss: 0.0478800
[Epoch 94; Iter   339/ 1097] train: loss: 0.0217028
[Epoch 94; Iter   369/ 1097] train: loss: 0.0330877
[Epoch 94; Iter   399/ 1097] train: loss: 0.0063840
[Epoch 94; Iter   429/ 1097] train: loss: 0.0065611
[Epoch 94; Iter   459/ 1097] train: loss: 0.0080189
[Epoch 94; Iter   489/ 1097] train: loss: 0.0807680
[Epoch 94; Iter   519/ 1097] train: loss: 0.0860400
[Epoch 94; Iter   549/ 1097] train: loss: 0.0766143
[Epoch 94; Iter   579/ 1097] train: loss: 0.0046446
[Epoch 94; Iter   609/ 1097] train: loss: 0.0035063
[Epoch 94; Iter   639/ 1097] train: loss: 0.0042297
[Epoch 94; Iter   669/ 1097] train: loss: 0.0767904
[Epoch 94; Iter   699/ 1097] train: loss: 0.0166150
[Epoch 94; Iter   729/ 1097] train: loss: 0.1330715
[Epoch 94; Iter   759/ 1097] train: loss: 0.0019453
[Epoch 94; Iter   789/ 1097] train: loss: 0.1580023
[Epoch 94; Iter   819/ 1097] train: loss: 0.0085742
[Epoch 94; Iter   849/ 1097] train: loss: 0.0459943
[Epoch 94; Iter   879/ 1097] train: loss: 0.0072107
[Epoch 94; Iter   909/ 1097] train: loss: 0.0104930
[Epoch 94; Iter   939/ 1097] train: loss: 0.0127336
[Epoch 94; Iter   969/ 1097] train: loss: 0.0026337
[Epoch 94; Iter   999/ 1097] train: loss: 0.0043781
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0093114
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0044694
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0018687
[Epoch 94] ogbg-molhiv: 0.791214 val loss: 0.134715
[Epoch 94] ogbg-molhiv: 0.747457 test loss: 0.254912
[Epoch 95; Iter    22/ 1097] train: loss: 0.0052946
[Epoch 95; Iter    52/ 1097] train: loss: 0.0087700
[Epoch 95; Iter    82/ 1097] train: loss: 0.1579172
[Epoch 95; Iter   112/ 1097] train: loss: 0.0016397
[Epoch 95; Iter   142/ 1097] train: loss: 0.0076066
[Epoch 95; Iter   172/ 1097] train: loss: 0.0043908
[Epoch 95; Iter   202/ 1097] train: loss: 0.1179531
[Epoch 95; Iter   232/ 1097] train: loss: 0.0890248
[Epoch 95; Iter   262/ 1097] train: loss: 0.0300327
[Epoch 95; Iter   292/ 1097] train: loss: 0.0149352
[Epoch 95; Iter   322/ 1097] train: loss: 0.0022751
[Epoch 95; Iter   352/ 1097] train: loss: 0.0821990
[Epoch 95; Iter   382/ 1097] train: loss: 0.1577123
[Epoch 95; Iter   412/ 1097] train: loss: 0.0059433
[Epoch 95; Iter   442/ 1097] train: loss: 0.0013006
[Epoch 95; Iter   472/ 1097] train: loss: 0.0177233
[Epoch 95; Iter   502/ 1097] train: loss: 0.0369042
[Epoch 95; Iter   532/ 1097] train: loss: 0.0162438
[Epoch 95; Iter   562/ 1097] train: loss: 0.0008752
[Epoch 95; Iter   592/ 1097] train: loss: 0.0551333
[Epoch 95; Iter   622/ 1097] train: loss: 0.0109289
[Epoch 95; Iter   652/ 1097] train: loss: 0.0042593
[Epoch 95; Iter   682/ 1097] train: loss: 0.0025959
[Epoch 95; Iter   712/ 1097] train: loss: 0.0133624
[Epoch 95; Iter   742/ 1097] train: loss: 0.0064100
[Epoch 95; Iter   772/ 1097] train: loss: 0.0195248
[Epoch 95; Iter   802/ 1097] train: loss: 0.0267287
[Epoch 95; Iter   832/ 1097] train: loss: 0.0216606
[Epoch 95; Iter   862/ 1097] train: loss: 0.0138209
[Epoch 95; Iter   892/ 1097] train: loss: 0.0256581
[Epoch 95; Iter   922/ 1097] train: loss: 0.0225569
[Epoch 95; Iter   952/ 1097] train: loss: 0.0161307
[Epoch 95; Iter   982/ 1097] train: loss: 0.0047173
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0144576
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0010235
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0093417
[Epoch 95] ogbg-molhiv: 0.802971 val loss: 0.124780
[Epoch 95] ogbg-molhiv: 0.747106 test loss: 0.261893
[Epoch 96; Iter     5/ 1097] train: loss: 0.0271056
[Epoch 96; Iter    35/ 1097] train: loss: 0.1086737
[Epoch 96; Iter    65/ 1097] train: loss: 0.0092733
[Epoch 96; Iter    95/ 1097] train: loss: 0.0210926
[Epoch 96; Iter   125/ 1097] train: loss: 0.0328073
[Epoch 96; Iter   155/ 1097] train: loss: 0.0209970
[Epoch 96; Iter   185/ 1097] train: loss: 0.0104133
[Epoch 96; Iter   215/ 1097] train: loss: 0.0209864
[Epoch 96; Iter   245/ 1097] train: loss: 0.0066941
[Epoch 96; Iter   275/ 1097] train: loss: 0.0009014
[Epoch 96; Iter   305/ 1097] train: loss: 0.0587087
[Epoch 96; Iter   335/ 1097] train: loss: 0.0055606
[Epoch 96; Iter   365/ 1097] train: loss: 0.0260558
[Epoch 96; Iter   395/ 1097] train: loss: 0.0017288
[Epoch 96; Iter   425/ 1097] train: loss: 0.0475618
[Epoch 96; Iter   455/ 1097] train: loss: 0.0417758
[Epoch 96; Iter   485/ 1097] train: loss: 0.0054075
[Epoch 96; Iter   515/ 1097] train: loss: 0.0158297
[Epoch 96; Iter   545/ 1097] train: loss: 0.0490180
[Epoch 96; Iter   575/ 1097] train: loss: 0.0065997
[Epoch 96; Iter   605/ 1097] train: loss: 0.0111229
[Epoch 96; Iter   635/ 1097] train: loss: 0.0282057
[Epoch 96; Iter   665/ 1097] train: loss: 0.0123414
[Epoch 96; Iter   695/ 1097] train: loss: 0.1068975
[Epoch 96; Iter   725/ 1097] train: loss: 0.1006207
[Epoch 96; Iter   755/ 1097] train: loss: 0.0575941
[Epoch 96; Iter   785/ 1097] train: loss: 0.0231889
[Epoch 96; Iter   815/ 1097] train: loss: 0.0188106
[Epoch 96; Iter   845/ 1097] train: loss: 0.0267283
[Epoch 96; Iter   875/ 1097] train: loss: 0.0025781
[Epoch 96; Iter   905/ 1097] train: loss: 0.0049250
[Epoch 96; Iter   935/ 1097] train: loss: 0.0624735
[Epoch 96; Iter   965/ 1097] train: loss: 0.0693889
[Epoch 96; Iter   995/ 1097] train: loss: 0.0085247
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0210985
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0075589
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0075524
[Epoch 96] ogbg-molhiv: 0.793323 val loss: 0.120479
[Epoch 96] ogbg-molhiv: 0.744624 test loss: 0.269032
[Epoch 97; Iter    18/ 1097] train: loss: 0.0414566
[Epoch 97; Iter    48/ 1097] train: loss: 0.0067784
[Epoch 97; Iter    78/ 1097] train: loss: 0.0029595
[Epoch 97; Iter   108/ 1097] train: loss: 0.0378946
[Epoch 97; Iter   138/ 1097] train: loss: 0.0037097
[Epoch 97; Iter   168/ 1097] train: loss: 0.1516795
[Epoch 97; Iter   198/ 1097] train: loss: 0.0031262
[Epoch 97; Iter   228/ 1097] train: loss: 0.0044924
[Epoch 97; Iter   258/ 1097] train: loss: 0.0159971
[Epoch 97; Iter   288/ 1097] train: loss: 0.0108025
[Epoch 97; Iter   318/ 1097] train: loss: 0.0101653
[Epoch 97; Iter   348/ 1097] train: loss: 0.0034922
[Epoch 97; Iter   378/ 1097] train: loss: 0.0136864
[Epoch 97; Iter   408/ 1097] train: loss: 0.0029290
[Epoch 97; Iter   438/ 1097] train: loss: 0.0483933
[Epoch 97; Iter   468/ 1097] train: loss: 0.0665405
[Epoch 97; Iter   498/ 1097] train: loss: 0.0182647
[Epoch 97; Iter   528/ 1097] train: loss: 0.0057172
[Epoch 97; Iter   558/ 1097] train: loss: 0.0047049
[Epoch 97; Iter   588/ 1097] train: loss: 0.0063249
[Epoch 97; Iter   618/ 1097] train: loss: 0.0116424
[Epoch 97; Iter   648/ 1097] train: loss: 0.0961263
[Epoch 93; Iter   596/ 1097] train: loss: 0.0067169
[Epoch 93; Iter   626/ 1097] train: loss: 0.0009644
[Epoch 93; Iter   656/ 1097] train: loss: 0.0074503
[Epoch 93; Iter   686/ 1097] train: loss: 0.0042215
[Epoch 93; Iter   716/ 1097] train: loss: 0.0014360
[Epoch 93; Iter   746/ 1097] train: loss: 0.0031801
[Epoch 93; Iter   776/ 1097] train: loss: 0.0027312
[Epoch 93; Iter   806/ 1097] train: loss: 0.0126361
[Epoch 93; Iter   836/ 1097] train: loss: 0.0012844
[Epoch 93; Iter   866/ 1097] train: loss: 0.0018955
[Epoch 93; Iter   896/ 1097] train: loss: 0.0045275
[Epoch 93; Iter   926/ 1097] train: loss: 0.0016397
[Epoch 93; Iter   956/ 1097] train: loss: 0.0030673
[Epoch 93; Iter   986/ 1097] train: loss: 0.0106678
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0077118
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0004352
[Epoch 93; Iter  1076/ 1097] train: loss: 0.2303124
[Epoch 93] ogbg-molhiv: 0.783360 val loss: 0.141456
[Epoch 93] ogbg-molhiv: 0.748850 test loss: 0.252479
[Epoch 94; Iter     9/ 1097] train: loss: 0.0068453
[Epoch 94; Iter    39/ 1097] train: loss: 0.0024348
[Epoch 94; Iter    69/ 1097] train: loss: 0.0237141
[Epoch 94; Iter    99/ 1097] train: loss: 0.0037130
[Epoch 94; Iter   129/ 1097] train: loss: 0.0027824
[Epoch 94; Iter   159/ 1097] train: loss: 0.0029187
[Epoch 94; Iter   189/ 1097] train: loss: 0.0029147
[Epoch 94; Iter   219/ 1097] train: loss: 0.0103828
[Epoch 94; Iter   249/ 1097] train: loss: 0.0015860
[Epoch 94; Iter   279/ 1097] train: loss: 0.0127106
[Epoch 94; Iter   309/ 1097] train: loss: 0.0035421
[Epoch 94; Iter   339/ 1097] train: loss: 0.0005597
[Epoch 94; Iter   369/ 1097] train: loss: 0.0401272
[Epoch 94; Iter   399/ 1097] train: loss: 0.0039365
[Epoch 94; Iter   429/ 1097] train: loss: 0.0070283
[Epoch 94; Iter   459/ 1097] train: loss: 0.0035266
[Epoch 94; Iter   489/ 1097] train: loss: 0.0162103
[Epoch 94; Iter   519/ 1097] train: loss: 0.0275914
[Epoch 94; Iter   549/ 1097] train: loss: 0.0090036
[Epoch 94; Iter   579/ 1097] train: loss: 0.0098866
[Epoch 94; Iter   609/ 1097] train: loss: 0.0010907
[Epoch 94; Iter   639/ 1097] train: loss: 0.0121873
[Epoch 94; Iter   669/ 1097] train: loss: 0.0366625
[Epoch 94; Iter   699/ 1097] train: loss: 0.0053989
[Epoch 94; Iter   729/ 1097] train: loss: 0.0548204
[Epoch 94; Iter   759/ 1097] train: loss: 0.0056324
[Epoch 94; Iter   789/ 1097] train: loss: 0.1021047
[Epoch 94; Iter   819/ 1097] train: loss: 0.0078313
[Epoch 94; Iter   849/ 1097] train: loss: 0.0073021
[Epoch 94; Iter   879/ 1097] train: loss: 0.0055931
[Epoch 94; Iter   909/ 1097] train: loss: 0.0655678
[Epoch 94; Iter   939/ 1097] train: loss: 0.0107392
[Epoch 94; Iter   969/ 1097] train: loss: 0.0060987
[Epoch 94; Iter   999/ 1097] train: loss: 0.0108827
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0056586
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0392283
[Epoch 94; Iter  1089/ 1097] train: loss: 0.1398349
[Epoch 94] ogbg-molhiv: 0.786498 val loss: 0.147369
[Epoch 94] ogbg-molhiv: 0.745860 test loss: 0.251596
[Epoch 95; Iter    22/ 1097] train: loss: 0.0017487
[Epoch 95; Iter    52/ 1097] train: loss: 0.0327648
[Epoch 95; Iter    82/ 1097] train: loss: 0.0071744
[Epoch 95; Iter   112/ 1097] train: loss: 0.0195946
[Epoch 95; Iter   142/ 1097] train: loss: 0.0013647
[Epoch 95; Iter   172/ 1097] train: loss: 0.0011102
[Epoch 95; Iter   202/ 1097] train: loss: 0.0034303
[Epoch 95; Iter   232/ 1097] train: loss: 0.0030611
[Epoch 95; Iter   262/ 1097] train: loss: 0.0007492
[Epoch 95; Iter   292/ 1097] train: loss: 0.0005458
[Epoch 95; Iter   322/ 1097] train: loss: 0.0301675
[Epoch 95; Iter   352/ 1097] train: loss: 0.0598288
[Epoch 95; Iter   382/ 1097] train: loss: 0.0188525
[Epoch 95; Iter   412/ 1097] train: loss: 0.0037551
[Epoch 95; Iter   442/ 1097] train: loss: 0.0101098
[Epoch 95; Iter   472/ 1097] train: loss: 0.0105731
[Epoch 95; Iter   502/ 1097] train: loss: 0.0756530
[Epoch 95; Iter   532/ 1097] train: loss: 0.0034076
[Epoch 95; Iter   562/ 1097] train: loss: 0.0053417
[Epoch 95; Iter   592/ 1097] train: loss: 0.0064053
[Epoch 95; Iter   622/ 1097] train: loss: 0.0100381
[Epoch 95; Iter   652/ 1097] train: loss: 0.0075745
[Epoch 95; Iter   682/ 1097] train: loss: 0.0070175
[Epoch 95; Iter   712/ 1097] train: loss: 0.0039395
[Epoch 95; Iter   742/ 1097] train: loss: 0.0220970
[Epoch 95; Iter   772/ 1097] train: loss: 0.0026072
[Epoch 95; Iter   802/ 1097] train: loss: 0.0065324
[Epoch 95; Iter   832/ 1097] train: loss: 0.0055353
[Epoch 95; Iter   862/ 1097] train: loss: 0.0872795
[Epoch 95; Iter   892/ 1097] train: loss: 0.0129413
[Epoch 95; Iter   922/ 1097] train: loss: 0.0079233
[Epoch 95; Iter   952/ 1097] train: loss: 0.2970373
[Epoch 95; Iter   982/ 1097] train: loss: 0.0053740
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0058819
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0005582
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0383126
[Epoch 95] ogbg-molhiv: 0.783038 val loss: 0.143337
[Epoch 95] ogbg-molhiv: 0.746857 test loss: 0.251136
[Epoch 96; Iter     5/ 1097] train: loss: 0.0027456
[Epoch 96; Iter    35/ 1097] train: loss: 0.0105602
[Epoch 96; Iter    65/ 1097] train: loss: 0.0058358
[Epoch 96; Iter    95/ 1097] train: loss: 0.0140688
[Epoch 96; Iter   125/ 1097] train: loss: 0.0920339
[Epoch 96; Iter   155/ 1097] train: loss: 0.0012188
[Epoch 96; Iter   185/ 1097] train: loss: 0.0005879
[Epoch 96; Iter   215/ 1097] train: loss: 0.0103345
[Epoch 96; Iter   245/ 1097] train: loss: 0.0020908
[Epoch 96; Iter   275/ 1097] train: loss: 0.0273158
[Epoch 96; Iter   305/ 1097] train: loss: 0.0269418
[Epoch 96; Iter   335/ 1097] train: loss: 0.0005122
[Epoch 96; Iter   365/ 1097] train: loss: 0.0031932
[Epoch 96; Iter   395/ 1097] train: loss: 0.0037042
[Epoch 96; Iter   425/ 1097] train: loss: 0.0152257
[Epoch 96; Iter   455/ 1097] train: loss: 0.0033559
[Epoch 96; Iter   485/ 1097] train: loss: 0.0005386
[Epoch 96; Iter   515/ 1097] train: loss: 0.0267395
[Epoch 96; Iter   545/ 1097] train: loss: 0.0461300
[Epoch 96; Iter   575/ 1097] train: loss: 0.0017216
[Epoch 96; Iter   605/ 1097] train: loss: 0.0139531
[Epoch 96; Iter   635/ 1097] train: loss: 0.0034027
[Epoch 96; Iter   665/ 1097] train: loss: 0.0016555
[Epoch 96; Iter   695/ 1097] train: loss: 0.1085859
[Epoch 96; Iter   725/ 1097] train: loss: 0.0005355
[Epoch 96; Iter   755/ 1097] train: loss: 0.0224042
[Epoch 96; Iter   785/ 1097] train: loss: 0.0825355
[Epoch 96; Iter   815/ 1097] train: loss: 0.0389153
[Epoch 96; Iter   845/ 1097] train: loss: 0.0020369
[Epoch 96; Iter   875/ 1097] train: loss: 0.0324714
[Epoch 96; Iter   905/ 1097] train: loss: 0.0432498
[Epoch 96; Iter   935/ 1097] train: loss: 0.0010624
[Epoch 96; Iter   965/ 1097] train: loss: 0.0337955
[Epoch 96; Iter   995/ 1097] train: loss: 0.0686666
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0068218
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0160922
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0057037
[Epoch 96] ogbg-molhiv: 0.789205 val loss: 0.142272
[Epoch 96] ogbg-molhiv: 0.752500 test loss: 0.248136
[Epoch 97; Iter    18/ 1097] train: loss: 0.0163672
[Epoch 97; Iter    48/ 1097] train: loss: 0.0019639
[Epoch 97; Iter    78/ 1097] train: loss: 0.0244572
[Epoch 97; Iter   108/ 1097] train: loss: 0.0126298
[Epoch 97; Iter   138/ 1097] train: loss: 0.0258394
[Epoch 97; Iter   168/ 1097] train: loss: 0.0903227
[Epoch 97; Iter   198/ 1097] train: loss: 0.0025677
[Epoch 97; Iter   228/ 1097] train: loss: 0.0229223
[Epoch 97; Iter   258/ 1097] train: loss: 0.0306277
[Epoch 97; Iter   288/ 1097] train: loss: 0.0019254
[Epoch 97; Iter   318/ 1097] train: loss: 0.0100568
[Epoch 97; Iter   348/ 1097] train: loss: 0.0737510
[Epoch 97; Iter   378/ 1097] train: loss: 0.0033612
[Epoch 97; Iter   408/ 1097] train: loss: 0.0094158
[Epoch 97; Iter   438/ 1097] train: loss: 0.0010761
[Epoch 97; Iter   468/ 1097] train: loss: 0.0149452
[Epoch 97; Iter   498/ 1097] train: loss: 0.0037450
[Epoch 97; Iter   528/ 1097] train: loss: 0.0014874
[Epoch 97; Iter   558/ 1097] train: loss: 0.0018173
[Epoch 97; Iter   588/ 1097] train: loss: 0.0041157
[Epoch 97; Iter   618/ 1097] train: loss: 0.0021155
[Epoch 97; Iter   648/ 1097] train: loss: 0.0018383
[Epoch 125; Iter   682/ 1097] train: loss: 0.0000518
[Epoch 125; Iter   712/ 1097] train: loss: 0.0000028
[Epoch 125; Iter   742/ 1097] train: loss: 0.0000491
[Epoch 125; Iter   772/ 1097] train: loss: 0.0004992
[Epoch 125; Iter   802/ 1097] train: loss: 0.0000114
[Epoch 125; Iter   832/ 1097] train: loss: 0.0000076
[Epoch 125; Iter   862/ 1097] train: loss: 0.0004770
[Epoch 125; Iter   892/ 1097] train: loss: 0.0000836
[Epoch 125; Iter   922/ 1097] train: loss: 0.0000124
[Epoch 125; Iter   952/ 1097] train: loss: 0.0000222
[Epoch 125; Iter   982/ 1097] train: loss: 0.0000020
[Epoch 125; Iter  1012/ 1097] train: loss: 0.0000032
[Epoch 125; Iter  1042/ 1097] train: loss: 0.0001484
[Epoch 125; Iter  1072/ 1097] train: loss: 0.0000607
[Epoch 125] ogbg-molhiv: 0.785990 val loss: 0.341821
[Epoch 125] ogbg-molhiv: 0.741704 test loss: 0.423105
[Epoch 126; Iter     5/ 1097] train: loss: 0.0001709
[Epoch 126; Iter    35/ 1097] train: loss: 0.0000131
[Epoch 126; Iter    65/ 1097] train: loss: 0.0000005
[Epoch 126; Iter    95/ 1097] train: loss: 0.0000005
[Epoch 126; Iter   125/ 1097] train: loss: 0.0000019
[Epoch 126; Iter   155/ 1097] train: loss: 0.0003356
[Epoch 126; Iter   185/ 1097] train: loss: 0.0000024
[Epoch 126; Iter   215/ 1097] train: loss: 0.0000051
[Epoch 126; Iter   245/ 1097] train: loss: 0.0002669
[Epoch 126; Iter   275/ 1097] train: loss: 0.0032776
[Epoch 126; Iter   305/ 1097] train: loss: 0.0000405
[Epoch 126; Iter   335/ 1097] train: loss: 0.0000034
[Epoch 126; Iter   365/ 1097] train: loss: 0.0000067
[Epoch 126; Iter   395/ 1097] train: loss: 0.0000034
[Epoch 126; Iter   425/ 1097] train: loss: 0.0000075
[Epoch 126; Iter   455/ 1097] train: loss: 0.0003956
[Epoch 126; Iter   485/ 1097] train: loss: 0.0000057
[Epoch 126; Iter   515/ 1097] train: loss: 0.0000500
[Epoch 126; Iter   545/ 1097] train: loss: 0.0000010
[Epoch 126; Iter   575/ 1097] train: loss: 0.0000332
[Epoch 126; Iter   605/ 1097] train: loss: 0.0041003
[Epoch 126; Iter   635/ 1097] train: loss: 0.0000307
[Epoch 126; Iter   665/ 1097] train: loss: 0.0000064
[Epoch 126; Iter   695/ 1097] train: loss: 0.0000102
[Epoch 126; Iter   725/ 1097] train: loss: 0.0001218
[Epoch 126; Iter   755/ 1097] train: loss: 0.0000151
[Epoch 126; Iter   785/ 1097] train: loss: 0.0001008
[Epoch 126; Iter   815/ 1097] train: loss: 0.0000042
[Epoch 126; Iter   845/ 1097] train: loss: 0.0011596
[Epoch 126; Iter   875/ 1097] train: loss: 0.0411247
[Epoch 126; Iter   905/ 1097] train: loss: 0.0000127
[Epoch 126; Iter   935/ 1097] train: loss: 0.0000060
[Epoch 126; Iter   965/ 1097] train: loss: 0.0000063
[Epoch 126; Iter   995/ 1097] train: loss: 0.0000031
[Epoch 126; Iter  1025/ 1097] train: loss: 0.0000256
[Epoch 126; Iter  1055/ 1097] train: loss: 0.0000039
[Epoch 126; Iter  1085/ 1097] train: loss: 0.0000142
[Epoch 126] ogbg-molhiv: 0.779545 val loss: 0.415167
[Epoch 126] ogbg-molhiv: 0.733042 test loss: 0.425546
[Epoch 127; Iter    18/ 1097] train: loss: 0.0000048
[Epoch 127; Iter    48/ 1097] train: loss: 0.0000056
[Epoch 127; Iter    78/ 1097] train: loss: 0.0000215
[Epoch 127; Iter   108/ 1097] train: loss: 0.0001287
[Epoch 127; Iter   138/ 1097] train: loss: 0.0000146
[Epoch 127; Iter   168/ 1097] train: loss: 0.0000147
[Epoch 127; Iter   198/ 1097] train: loss: 0.0000988
[Epoch 127; Iter   228/ 1097] train: loss: 0.0000017
[Epoch 127; Iter   258/ 1097] train: loss: 0.0000009
[Epoch 127; Iter   288/ 1097] train: loss: 0.0007255
[Epoch 127; Iter   318/ 1097] train: loss: 0.0001360
[Epoch 127; Iter   348/ 1097] train: loss: 0.0011223
[Epoch 127; Iter   378/ 1097] train: loss: 0.0000474
[Epoch 127; Iter   408/ 1097] train: loss: 0.0004466
[Epoch 127; Iter   438/ 1097] train: loss: 0.0003499
[Epoch 127; Iter   468/ 1097] train: loss: 0.0000038
[Epoch 127; Iter   498/ 1097] train: loss: 0.0003677
[Epoch 127; Iter   528/ 1097] train: loss: 0.0000929
[Epoch 127; Iter   558/ 1097] train: loss: 0.0000054
[Epoch 127; Iter   588/ 1097] train: loss: 0.0001468
[Epoch 127; Iter   618/ 1097] train: loss: 0.0000952
[Epoch 127; Iter   648/ 1097] train: loss: 0.0000945
[Epoch 127; Iter   678/ 1097] train: loss: 0.0000100
[Epoch 127; Iter   708/ 1097] train: loss: 0.0000545
[Epoch 127; Iter   738/ 1097] train: loss: 0.0003090
[Epoch 127; Iter   768/ 1097] train: loss: 0.0000116
[Epoch 127; Iter   798/ 1097] train: loss: 0.0000189
[Epoch 127; Iter   828/ 1097] train: loss: 0.0000366
[Epoch 127; Iter   858/ 1097] train: loss: 0.0001159
[Epoch 127; Iter   888/ 1097] train: loss: 0.0001020
[Epoch 127; Iter   918/ 1097] train: loss: 0.0000006
[Epoch 127; Iter   948/ 1097] train: loss: 0.0000003
[Epoch 127; Iter   978/ 1097] train: loss: 0.0000200
[Epoch 127; Iter  1008/ 1097] train: loss: 0.0000015
[Epoch 127; Iter  1038/ 1097] train: loss: 0.0000040
[Epoch 127; Iter  1068/ 1097] train: loss: 0.0001370
[Epoch 127] ogbg-molhiv: 0.785224 val loss: 0.305393
[Epoch 127] ogbg-molhiv: 0.735333 test loss: 0.452950
[Epoch 128; Iter     1/ 1097] train: loss: 0.0000119
[Epoch 128; Iter    31/ 1097] train: loss: 0.0000091
[Epoch 128; Iter    61/ 1097] train: loss: 0.0000161
[Epoch 128; Iter    91/ 1097] train: loss: 0.0000130
[Epoch 128; Iter   121/ 1097] train: loss: 0.0000047
[Epoch 128; Iter   151/ 1097] train: loss: 0.0000005
[Epoch 128; Iter   181/ 1097] train: loss: 0.0000001
[Epoch 128; Iter   211/ 1097] train: loss: 0.0001337
[Epoch 128; Iter   241/ 1097] train: loss: 0.0010313
[Epoch 128; Iter   271/ 1097] train: loss: 0.0000371
[Epoch 128; Iter   301/ 1097] train: loss: 0.0005453
[Epoch 128; Iter   331/ 1097] train: loss: 0.0001963
[Epoch 128; Iter   361/ 1097] train: loss: 0.0000279
[Epoch 128; Iter   391/ 1097] train: loss: 0.0000231
[Epoch 128; Iter   421/ 1097] train: loss: 0.0000202
[Epoch 128; Iter   451/ 1097] train: loss: 0.0000506
[Epoch 128; Iter   481/ 1097] train: loss: 0.0000326
[Epoch 128; Iter   511/ 1097] train: loss: 0.0000157
[Epoch 128; Iter   541/ 1097] train: loss: 0.0001030
[Epoch 128; Iter   571/ 1097] train: loss: 0.0000295
[Epoch 128; Iter   601/ 1097] train: loss: 0.0000043
[Epoch 128; Iter   631/ 1097] train: loss: 0.0000433
[Epoch 128; Iter   661/ 1097] train: loss: 0.0000026
[Epoch 128; Iter   691/ 1097] train: loss: 0.0003002
[Epoch 128; Iter   721/ 1097] train: loss: 0.0000104
[Epoch 128; Iter   751/ 1097] train: loss: 0.0000316
[Epoch 128; Iter   781/ 1097] train: loss: 0.0000098
[Epoch 128; Iter   811/ 1097] train: loss: 0.0000152
[Epoch 128; Iter   841/ 1097] train: loss: 0.0003102
[Epoch 128; Iter   871/ 1097] train: loss: 0.0007054
[Epoch 128; Iter   901/ 1097] train: loss: 0.0000192
[Epoch 128; Iter   931/ 1097] train: loss: 0.0000113
[Epoch 128; Iter   961/ 1097] train: loss: 0.0000058
[Epoch 128; Iter   991/ 1097] train: loss: 0.0000044
[Epoch 128; Iter  1021/ 1097] train: loss: 0.0019971
[Epoch 128; Iter  1051/ 1097] train: loss: 0.0054374
[Epoch 128; Iter  1081/ 1097] train: loss: 0.0000192
[Epoch 128] ogbg-molhiv: 0.773898 val loss: 0.369403
[Epoch 128] ogbg-molhiv: 0.723768 test loss: 0.453939
[Epoch 129; Iter    14/ 1097] train: loss: 0.0000081
[Epoch 129; Iter    44/ 1097] train: loss: 0.0000041
[Epoch 129; Iter    74/ 1097] train: loss: 0.0000057
[Epoch 129; Iter   104/ 1097] train: loss: 0.0000320
[Epoch 129; Iter   134/ 1097] train: loss: 0.0001160
[Epoch 129; Iter   164/ 1097] train: loss: 0.0000093
[Epoch 129; Iter   194/ 1097] train: loss: 0.0001030
[Epoch 129; Iter   224/ 1097] train: loss: 0.0000047
[Epoch 129; Iter   254/ 1097] train: loss: 0.0001619
[Epoch 129; Iter   284/ 1097] train: loss: 0.0000225
[Epoch 129; Iter   314/ 1097] train: loss: 0.0001822
[Epoch 129; Iter   344/ 1097] train: loss: 0.0000050
[Epoch 129; Iter   374/ 1097] train: loss: 0.0000090
[Epoch 129; Iter   404/ 1097] train: loss: 0.0000008
[Epoch 129; Iter   434/ 1097] train: loss: 0.0000003
[Epoch 129; Iter   464/ 1097] train: loss: 0.0001481
[Epoch 129; Iter   494/ 1097] train: loss: 0.0004749
[Epoch 129; Iter   524/ 1097] train: loss: 0.0000020
[Epoch 129; Iter   554/ 1097] train: loss: 0.0000071
[Epoch 129; Iter   584/ 1097] train: loss: 0.0000167
[Epoch 129; Iter   614/ 1097] train: loss: 0.0000015
[Epoch 129; Iter   644/ 1097] train: loss: 0.0000136
[Epoch 129; Iter   674/ 1097] train: loss: 0.0000274
[Epoch 129; Iter   704/ 1097] train: loss: 0.0000119
[Epoch 129; Iter   734/ 1097] train: loss: 0.0000062
[Epoch 129; Iter   764/ 1097] train: loss: 0.0000616
[Epoch 129; Iter   794/ 1097] train: loss: 0.0002671
[Epoch 129; Iter   824/ 1097] train: loss: 0.0000145
[Epoch 129; Iter   854/ 1097] train: loss: 0.0000062
[Epoch 129; Iter   884/ 1097] train: loss: 0.0000158
[Epoch 129; Iter   914/ 1097] train: loss: 0.0000059
[Epoch 129; Iter   944/ 1097] train: loss: 0.0000357
[Epoch 129; Iter   974/ 1097] train: loss: 0.0000185
[Epoch 129; Iter  1004/ 1097] train: loss: 0.0000005
[Epoch 129; Iter  1034/ 1097] train: loss: 0.0000121
[Epoch 129; Iter  1064/ 1097] train: loss: 0.0000013
[Epoch 129; Iter  1094/ 1097] train: loss: 0.0000003
[Epoch 129] ogbg-molhiv: 0.785503 val loss: 0.331791
[Epoch 129] ogbg-molhiv: 0.734734 test loss: 0.459625
[Epoch 130; Iter    27/ 1097] train: loss: 0.0001502
[Epoch 130; Iter    57/ 1097] train: loss: 0.0000393
[Epoch 130; Iter    87/ 1097] train: loss: 0.0000049
[Epoch 130; Iter   117/ 1097] train: loss: 0.0000178
[Epoch 130; Iter   147/ 1097] train: loss: 0.0000808
[Epoch 130; Iter   177/ 1097] train: loss: 0.0000043
[Epoch 130; Iter   207/ 1097] train: loss: 0.0000492
[Epoch 130; Iter   237/ 1097] train: loss: 0.0000116
[Epoch 130; Iter   267/ 1097] train: loss: 0.0000102
[Epoch 130; Iter   297/ 1097] train: loss: 0.0000982
[Epoch 130; Iter   327/ 1097] train: loss: 0.0000011
[Epoch 130; Iter   357/ 1097] train: loss: 0.0000223
[Epoch 130; Iter   387/ 1097] train: loss: 0.0000229
[Epoch 130; Iter   417/ 1097] train: loss: 0.0000395
[Epoch 130; Iter   447/ 1097] train: loss: 0.0005476
[Epoch 130; Iter   477/ 1097] train: loss: 0.0027496
[Epoch 130; Iter   507/ 1097] train: loss: 0.0000850
[Epoch 130; Iter   537/ 1097] train: loss: 0.0000039
[Epoch 130; Iter   567/ 1097] train: loss: 0.0000584
[Epoch 130; Iter   597/ 1097] train: loss: 0.0004939
[Epoch 130; Iter   627/ 1097] train: loss: 0.0000566
[Epoch 130; Iter   657/ 1097] train: loss: 0.0000083
[Epoch 130; Iter   687/ 1097] train: loss: 0.0000071
[Epoch 130; Iter   717/ 1097] train: loss: 0.0000697
[Epoch 130; Iter   747/ 1097] train: loss: 0.0000097
[Epoch 130; Iter   777/ 1097] train: loss: 0.0000918
[Epoch 130; Iter   807/ 1097] train: loss: 0.0000544
[Epoch 130; Iter   837/ 1097] train: loss: 0.0000003
[Epoch 130; Iter   867/ 1097] train: loss: 0.0000093
[Epoch 130; Iter   897/ 1097] train: loss: 0.0001314
[Epoch 130; Iter   927/ 1097] train: loss: 0.0000010
[Epoch 130; Iter   957/ 1097] train: loss: 0.0000088
[Epoch 130; Iter   987/ 1097] train: loss: 0.0000004
[Epoch 130; Iter  1017/ 1097] train: loss: 0.0000127
[Epoch 130; Iter  1047/ 1097] train: loss: 0.0000019
[Epoch 130; Iter  1077/ 1097] train: loss: 0.0002654
[Epoch 130] ogbg-molhiv: 0.788329 val loss: 0.367997
[Epoch 130] ogbg-molhiv: 0.731408 test loss: 0.564690
[Epoch 131; Iter    10/ 1097] train: loss: 0.0000380
[Epoch 131; Iter    40/ 1097] train: loss: 0.0000039
[Epoch 131; Iter    70/ 1097] train: loss: 0.0000053
[Epoch 131; Iter   100/ 1097] train: loss: 0.0000100
[Epoch 131; Iter   130/ 1097] train: loss: 0.0000405
[Epoch 131; Iter   160/ 1097] train: loss: 0.0000512
[Epoch 131; Iter   190/ 1097] train: loss: 0.0001171
[Epoch 131; Iter   220/ 1097] train: loss: 0.0000783
[Epoch 131; Iter   250/ 1097] train: loss: 0.0000433
[Epoch 131; Iter   280/ 1097] train: loss: 0.0000015
[Epoch 131; Iter   310/ 1097] train: loss: 0.0000298
[Epoch 131; Iter   340/ 1097] train: loss: 0.0000765
[Epoch 131; Iter   370/ 1097] train: loss: 0.0000022
[Epoch 131; Iter   400/ 1097] train: loss: 0.0000215
[Epoch 131; Iter   430/ 1097] train: loss: 0.0000007
[Epoch 131; Iter   460/ 1097] train: loss: 0.0000013
[Epoch 131; Iter   490/ 1097] train: loss: 0.0000025
[Epoch 131; Iter   520/ 1097] train: loss: 0.0000014
[Epoch 131; Iter   550/ 1097] train: loss: 0.0000930
[Epoch 131; Iter   580/ 1097] train: loss: 0.0000013
[Epoch 131; Iter   610/ 1097] train: loss: 0.0000040
[Epoch 131; Iter   640/ 1097] train: loss: 0.0000111
[Epoch 131; Iter   670/ 1097] train: loss: 0.0000047
[Epoch 131; Iter   700/ 1097] train: loss: 0.0000230
[Epoch 131; Iter   730/ 1097] train: loss: 0.0000134
[Epoch 131; Iter   760/ 1097] train: loss: 0.0000373
[Epoch 131; Iter   790/ 1097] train: loss: 0.0201821
[Epoch 131; Iter   820/ 1097] train: loss: 0.0000005
[Epoch 131; Iter   850/ 1097] train: loss: 0.0000010
[Epoch 131; Iter   880/ 1097] train: loss: 0.0000040
[Epoch 131; Iter   910/ 1097] train: loss: 0.0000387
[Epoch 131; Iter   940/ 1097] train: loss: 0.0000037
[Epoch 131; Iter   970/ 1097] train: loss: 0.0000255
[Epoch 131; Iter  1000/ 1097] train: loss: 0.0000033
[Epoch 131; Iter  1030/ 1097] train: loss: 0.0000052
[Epoch 131; Iter  1060/ 1097] train: loss: 0.0000075
[Epoch 131; Iter  1090/ 1097] train: loss: 0.0000138
[Epoch 131] ogbg-molhiv: 0.784921 val loss: 0.320159
[Epoch 131] ogbg-molhiv: 0.744109 test loss: 0.697832
[Epoch 132; Iter    23/ 1097] train: loss: 0.0001019
[Epoch 132; Iter    53/ 1097] train: loss: 0.0000749
[Epoch 132; Iter    83/ 1097] train: loss: 0.0000220
[Epoch 132; Iter   113/ 1097] train: loss: 0.0061403
[Epoch 132; Iter   143/ 1097] train: loss: 0.0000078
[Epoch 132; Iter   173/ 1097] train: loss: 0.0000821
[Epoch 132; Iter   203/ 1097] train: loss: 0.0000078
[Epoch 132; Iter   233/ 1097] train: loss: 0.0003929
[Epoch 132; Iter   263/ 1097] train: loss: 0.0000060
[Epoch 132; Iter   293/ 1097] train: loss: 0.0000012
[Epoch 132; Iter   323/ 1097] train: loss: 0.0001138
[Epoch 132; Iter   353/ 1097] train: loss: 0.0205658
[Epoch 132; Iter   383/ 1097] train: loss: 0.0000041
[Epoch 132; Iter   413/ 1097] train: loss: 0.0000090
[Epoch 132; Iter   443/ 1097] train: loss: 0.0000242
[Epoch 132; Iter   473/ 1097] train: loss: 0.0000022
[Epoch 132; Iter   503/ 1097] train: loss: 0.0000050
[Epoch 132; Iter   533/ 1097] train: loss: 0.0000253
[Epoch 132; Iter   563/ 1097] train: loss: 0.0000505
[Epoch 132; Iter   593/ 1097] train: loss: 0.0002555
[Epoch 132; Iter   623/ 1097] train: loss: 0.0000070
[Epoch 132; Iter   653/ 1097] train: loss: 0.0000279
[Epoch 132; Iter   683/ 1097] train: loss: 0.0000199
[Epoch 132; Iter   713/ 1097] train: loss: 0.0000759
[Epoch 132; Iter   743/ 1097] train: loss: 0.0000008
[Epoch 132; Iter   773/ 1097] train: loss: 0.0000001
[Epoch 132; Iter   803/ 1097] train: loss: 0.0000042
[Epoch 132; Iter   833/ 1097] train: loss: 0.0000339
[Epoch 132; Iter   863/ 1097] train: loss: 0.0000726
[Epoch 132; Iter   893/ 1097] train: loss: 0.0000141
[Epoch 132; Iter   923/ 1097] train: loss: 0.0000354
[Epoch 132; Iter   953/ 1097] train: loss: 0.0000119
[Epoch 132; Iter   983/ 1097] train: loss: 0.0000185
[Epoch 132; Iter  1013/ 1097] train: loss: 0.0000091
[Epoch 132; Iter  1043/ 1097] train: loss: 0.0000014
[Epoch 132; Iter  1073/ 1097] train: loss: 0.0000482
[Epoch 132] ogbg-molhiv: 0.791278 val loss: 0.327688
[Epoch 132] ogbg-molhiv: 0.733693 test loss: 0.442983
[Epoch 133; Iter     6/ 1097] train: loss: 0.0000020
[Epoch 133; Iter    36/ 1097] train: loss: 0.0000099
[Epoch 133; Iter    66/ 1097] train: loss: 0.0000020
[Epoch 133; Iter    96/ 1097] train: loss: 0.0000475
[Epoch 133; Iter   126/ 1097] train: loss: 0.0000024
[Epoch 133; Iter   156/ 1097] train: loss: 0.0004283
[Epoch 133; Iter   186/ 1097] train: loss: 0.0000006
[Epoch 133; Iter   216/ 1097] train: loss: 0.0000319
[Epoch 133; Iter   246/ 1097] train: loss: 0.0000264
[Epoch 133; Iter   276/ 1097] train: loss: 0.0000087
[Epoch 133; Iter   306/ 1097] train: loss: 0.0000067
[Epoch 133; Iter   336/ 1097] train: loss: 0.0000368
[Epoch 133; Iter   366/ 1097] train: loss: 0.0000023
[Epoch 133; Iter   396/ 1097] train: loss: 0.0000198
[Epoch 133; Iter   426/ 1097] train: loss: 0.0000266
[Epoch 133; Iter   456/ 1097] train: loss: 0.0014169
[Epoch 133; Iter   486/ 1097] train: loss: 0.0006713
[Epoch 133; Iter   516/ 1097] train: loss: 0.0000025
[Epoch 133; Iter   546/ 1097] train: loss: 0.0002750
[Epoch 133; Iter   576/ 1097] train: loss: 0.0000015
[Epoch 133; Iter   606/ 1097] train: loss: 0.0000199
[Epoch 133; Iter   636/ 1097] train: loss: 0.0000030
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 133; Iter   666/ 1097] train: loss: 0.0000093
[Epoch 133; Iter   696/ 1097] train: loss: 0.0000003
[Epoch 133; Iter   726/ 1097] train: loss: 0.0000373
[Epoch 133; Iter   756/ 1097] train: loss: 0.0001193
[Epoch 133; Iter   786/ 1097] train: loss: 0.0002715
[Epoch 133; Iter   816/ 1097] train: loss: 0.0003043
[Epoch 133; Iter   846/ 1097] train: loss: 0.0000017
[Epoch 133; Iter   876/ 1097] train: loss: 0.0000190
[Epoch 133; Iter   906/ 1097] train: loss: 0.0000133
[Epoch 133; Iter   936/ 1097] train: loss: 0.0004401
[Epoch 133; Iter   966/ 1097] train: loss: 0.0018898
[Epoch 133; Iter   996/ 1097] train: loss: 0.0000826
[Epoch 133; Iter  1026/ 1097] train: loss: 0.0015822
[Epoch 133; Iter  1056/ 1097] train: loss: 0.0000003
[Epoch 133; Iter  1086/ 1097] train: loss: 0.0000007
[Epoch 133] ogbg-molhiv: 0.776274 val loss: 0.356761
[Epoch 133] ogbg-molhiv: 0.727905 test loss: 0.464983
[Epoch 134; Iter    19/ 1097] train: loss: 0.0001923
[Epoch 134; Iter    49/ 1097] train: loss: 0.0012700
[Epoch 134; Iter    79/ 1097] train: loss: 0.0000388
[Epoch 134; Iter   109/ 1097] train: loss: 0.0000013
[Epoch 134; Iter   139/ 1097] train: loss: 0.0000121
[Epoch 134; Iter   169/ 1097] train: loss: 0.0000773
[Epoch 134; Iter   199/ 1097] train: loss: 0.0000046
[Epoch 134; Iter   229/ 1097] train: loss: 0.0000065
[Epoch 134; Iter   259/ 1097] train: loss: 0.0012543
[Epoch 134; Iter   289/ 1097] train: loss: 0.0000601
[Epoch 134; Iter   319/ 1097] train: loss: 0.0000120
[Epoch 134; Iter   349/ 1097] train: loss: 0.0000064
[Epoch 134; Iter   379/ 1097] train: loss: 0.0000887
[Epoch 134; Iter   409/ 1097] train: loss: 0.0000614
[Epoch 134; Iter   439/ 1097] train: loss: 0.0000026
[Epoch 134; Iter   469/ 1097] train: loss: 0.0021729
[Epoch 134; Iter   499/ 1097] train: loss: 0.0000087
[Epoch 134; Iter   529/ 1097] train: loss: 0.0000019
[Epoch 134; Iter   559/ 1097] train: loss: 0.0000490
[Epoch 134; Iter   589/ 1097] train: loss: 0.0022236
[Epoch 134; Iter   619/ 1097] train: loss: 0.0000281
[Epoch 134; Iter   649/ 1097] train: loss: 0.0000893
[Epoch 134; Iter   679/ 1097] train: loss: 0.0000033
[Epoch 134; Iter   709/ 1097] train: loss: 0.0000098
[Epoch 134; Iter   739/ 1097] train: loss: 0.0000408
[Epoch 134; Iter   769/ 1097] train: loss: 0.0000069
[Epoch 134; Iter   799/ 1097] train: loss: 0.0000154
[Epoch 134; Iter   829/ 1097] train: loss: 0.0000087
[Epoch 134; Iter   859/ 1097] train: loss: 0.0000156
[Epoch 134; Iter   889/ 1097] train: loss: 0.0000444
[Epoch 134; Iter   919/ 1097] train: loss: 0.0001434
[Epoch 134; Iter   949/ 1097] train: loss: 0.0001712
[Epoch 134; Iter   979/ 1097] train: loss: 0.0000751
[Epoch 134; Iter  1009/ 1097] train: loss: 0.0000113
[Epoch 134; Iter  1039/ 1097] train: loss: 0.0000175
[Epoch 134; Iter  1069/ 1097] train: loss: 0.0000224
[Epoch 134] ogbg-molhiv: 0.785332 val loss: 0.356919
[Epoch 134] ogbg-molhiv: 0.738950 test loss: 0.451683
[Epoch 135; Iter     2/ 1097] train: loss: 0.0000007
[Epoch 135; Iter    32/ 1097] train: loss: 0.0000155
[Epoch 135; Iter    62/ 1097] train: loss: 0.0000014
[Epoch 135; Iter    92/ 1097] train: loss: 0.0001033
[Epoch 135; Iter   122/ 1097] train: loss: 0.0004137
[Epoch 135; Iter   152/ 1097] train: loss: 0.0000024
[Epoch 135; Iter   182/ 1097] train: loss: 0.0004791
[Epoch 135; Iter   212/ 1097] train: loss: 0.0000530
[Epoch 135; Iter   242/ 1097] train: loss: 0.0001390
[Epoch 135; Iter   272/ 1097] train: loss: 0.0000019
[Epoch 135; Iter   302/ 1097] train: loss: 0.0000004
[Epoch 135; Iter   332/ 1097] train: loss: 0.0000042
[Epoch 135; Iter   362/ 1097] train: loss: 0.0000133
[Epoch 135; Iter   392/ 1097] train: loss: 0.0000559
[Epoch 135; Iter   422/ 1097] train: loss: 0.0000028
[Epoch 135; Iter   452/ 1097] train: loss: 0.0012437
[Epoch 135; Iter   482/ 1097] train: loss: 0.0000461
[Epoch 135; Iter   512/ 1097] train: loss: 0.0000150
[Epoch 135; Iter   542/ 1097] train: loss: 0.0002747
[Epoch 135; Iter   572/ 1097] train: loss: 0.0003193
[Epoch 135; Iter   602/ 1097] train: loss: 0.0000321
[Epoch 135; Iter   632/ 1097] train: loss: 0.0001000
[Epoch 135; Iter   662/ 1097] train: loss: 0.0000008
[Epoch 135; Iter   692/ 1097] train: loss: 0.0028437
[Epoch 135; Iter   722/ 1097] train: loss: 0.0001526
[Epoch 135; Iter   752/ 1097] train: loss: 0.0001182
[Epoch 135; Iter   782/ 1097] train: loss: 0.0000003
[Epoch 135; Iter   812/ 1097] train: loss: 0.0000129
[Epoch 135; Iter   842/ 1097] train: loss: 0.0000678
[Epoch 135; Iter   872/ 1097] train: loss: 0.0000752
[Epoch 135; Iter   902/ 1097] train: loss: 0.0000003
[Epoch 135; Iter   932/ 1097] train: loss: 0.0012527
[Epoch 135; Iter   962/ 1097] train: loss: 0.0000284
[Epoch 135; Iter   992/ 1097] train: loss: 0.0000079
[Epoch 135; Iter  1022/ 1097] train: loss: 0.0000160
[Epoch 135; Iter  1052/ 1097] train: loss: 0.0000061
[Epoch 135; Iter  1082/ 1097] train: loss: 0.0000031
[Epoch 135] ogbg-molhiv: 0.779946 val loss: 0.382963
[Epoch 135] ogbg-molhiv: 0.740113 test loss: 0.571816
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 135 epochs. Best model checkpoint was in epoch 75.
Statistics on  val_best_checkpoint
mean_pred: -15.776670455932617
std_pred: 21.532154083251953
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.25519813318688817
rocauc: 0.8164100774054477
ogbg-molhiv: 0.8164100774054477
BCEWithLogitsLoss: 0.24243882747828469
Statistics on  test
mean_pred: -15.150544166564941
std_pred: 13.06601333618164
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.23913992278375812
rocauc: 0.7259912319666274
ogbg-molhiv: 0.7259912319666274
BCEWithLogitsLoss: 0.4448783476817076
Statistics on  train
mean_pred: -17.821521759033203
std_pred: 8.719805717468262
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.9998279379464329
rocauc: 0.9999934129939024
ogbg-molhiv: 0.9999934129939024
BCEWithLogitsLoss: 0.0014432206305034867
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
[Epoch 97; Iter   678/ 1097] train: loss: 0.0152125
[Epoch 97; Iter   708/ 1097] train: loss: 0.0019525
[Epoch 97; Iter   738/ 1097] train: loss: 0.0079548
[Epoch 97; Iter   768/ 1097] train: loss: 0.0131681
[Epoch 97; Iter   798/ 1097] train: loss: 0.0578635
[Epoch 97; Iter   828/ 1097] train: loss: 0.0083266
[Epoch 97; Iter   858/ 1097] train: loss: 0.0027692
[Epoch 97; Iter   888/ 1097] train: loss: 0.0899615
[Epoch 97; Iter   918/ 1097] train: loss: 0.0095415
[Epoch 97; Iter   948/ 1097] train: loss: 0.0114396
[Epoch 97; Iter   978/ 1097] train: loss: 0.0180117
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0444170
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0018121
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0059516
[Epoch 97] ogbg-molhiv: 0.819971 val loss: 0.131683
[Epoch 97] ogbg-molhiv: 0.741548 test loss: 0.253911
[Epoch 98; Iter     1/ 1097] train: loss: 0.0351861
[Epoch 98; Iter    31/ 1097] train: loss: 0.0150921
[Epoch 98; Iter    61/ 1097] train: loss: 0.0863011
[Epoch 98; Iter    91/ 1097] train: loss: 0.0232863
[Epoch 98; Iter   121/ 1097] train: loss: 0.0214999
[Epoch 98; Iter   151/ 1097] train: loss: 0.0173345
[Epoch 98; Iter   181/ 1097] train: loss: 0.0029886
[Epoch 98; Iter   211/ 1097] train: loss: 0.0012411
[Epoch 98; Iter   241/ 1097] train: loss: 0.0044980
[Epoch 98; Iter   271/ 1097] train: loss: 0.0009841
[Epoch 98; Iter   301/ 1097] train: loss: 0.0074904
[Epoch 98; Iter   331/ 1097] train: loss: 0.1247162
[Epoch 98; Iter   361/ 1097] train: loss: 0.0165430
[Epoch 98; Iter   391/ 1097] train: loss: 0.0026446
[Epoch 98; Iter   421/ 1097] train: loss: 0.1416284
[Epoch 98; Iter   451/ 1097] train: loss: 0.0065682
[Epoch 98; Iter   481/ 1097] train: loss: 0.0042287
[Epoch 98; Iter   511/ 1097] train: loss: 0.0109576
[Epoch 98; Iter   541/ 1097] train: loss: 0.0275983
[Epoch 98; Iter   571/ 1097] train: loss: 0.0190677
[Epoch 98; Iter   601/ 1097] train: loss: 0.0102791
[Epoch 98; Iter   631/ 1097] train: loss: 0.0807727
[Epoch 98; Iter   661/ 1097] train: loss: 0.0205402
[Epoch 98; Iter   691/ 1097] train: loss: 0.0099140
[Epoch 98; Iter   721/ 1097] train: loss: 0.0028300
[Epoch 98; Iter   751/ 1097] train: loss: 0.0023678
[Epoch 98; Iter   781/ 1097] train: loss: 0.0034247
[Epoch 98; Iter   811/ 1097] train: loss: 0.0031797
[Epoch 98; Iter   841/ 1097] train: loss: 0.0037593
[Epoch 98; Iter   871/ 1097] train: loss: 0.0045163
[Epoch 98; Iter   901/ 1097] train: loss: 0.0379684
[Epoch 98; Iter   931/ 1097] train: loss: 0.0096655
[Epoch 98; Iter   961/ 1097] train: loss: 0.0909241
[Epoch 98; Iter   991/ 1097] train: loss: 0.0031413
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0351027
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0014646
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0654916
[Epoch 98] ogbg-molhiv: 0.826622 val loss: 0.132957
[Epoch 98] ogbg-molhiv: 0.745389 test loss: 0.254175
[Epoch 99; Iter    14/ 1097] train: loss: 0.0014565
[Epoch 99; Iter    44/ 1097] train: loss: 0.0032172
[Epoch 99; Iter    74/ 1097] train: loss: 0.0015784
[Epoch 99; Iter   104/ 1097] train: loss: 0.0077768
[Epoch 99; Iter   134/ 1097] train: loss: 0.0173925
[Epoch 99; Iter   164/ 1097] train: loss: 0.0098766
[Epoch 99; Iter   194/ 1097] train: loss: 0.0399414
[Epoch 99; Iter   224/ 1097] train: loss: 0.0008376
[Epoch 99; Iter   254/ 1097] train: loss: 0.0026803
[Epoch 99; Iter   284/ 1097] train: loss: 0.0310276
[Epoch 99; Iter   314/ 1097] train: loss: 0.0040843
[Epoch 99; Iter   344/ 1097] train: loss: 0.0252656
[Epoch 99; Iter   374/ 1097] train: loss: 0.0304225
[Epoch 99; Iter   404/ 1097] train: loss: 0.0495999
[Epoch 99; Iter   434/ 1097] train: loss: 0.0128814
[Epoch 99; Iter   464/ 1097] train: loss: 0.0026319
[Epoch 99; Iter   494/ 1097] train: loss: 0.0284473
[Epoch 99; Iter   524/ 1097] train: loss: 0.0020747
[Epoch 99; Iter   554/ 1097] train: loss: 0.0034511
[Epoch 99; Iter   584/ 1097] train: loss: 0.0061793
[Epoch 99; Iter   614/ 1097] train: loss: 0.0014395
[Epoch 99; Iter   644/ 1097] train: loss: 0.0235616
[Epoch 99; Iter   674/ 1097] train: loss: 0.0518126
[Epoch 99; Iter   704/ 1097] train: loss: 0.0283907
[Epoch 99; Iter   734/ 1097] train: loss: 0.0027884
[Epoch 99; Iter   764/ 1097] train: loss: 0.0720972
[Epoch 99; Iter   794/ 1097] train: loss: 0.0720443
[Epoch 99; Iter   824/ 1097] train: loss: 0.0617309
[Epoch 99; Iter   854/ 1097] train: loss: 0.0138829
[Epoch 99; Iter   884/ 1097] train: loss: 0.0144929
[Epoch 99; Iter   914/ 1097] train: loss: 0.0011158
[Epoch 99; Iter   944/ 1097] train: loss: 0.0402879
[Epoch 99; Iter   974/ 1097] train: loss: 0.0056623
[Epoch 99; Iter  1004/ 1097] train: loss: 0.1602089
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0119648
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0079128
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0013816
[Epoch 99] ogbg-molhiv: 0.814276 val loss: 0.135164
[Epoch 99] ogbg-molhiv: 0.745184 test loss: 0.260010
[Epoch 100; Iter    27/ 1097] train: loss: 0.0024809
[Epoch 100; Iter    57/ 1097] train: loss: 0.0046294
[Epoch 100; Iter    87/ 1097] train: loss: 0.0131582
[Epoch 100; Iter   117/ 1097] train: loss: 0.0149463
[Epoch 100; Iter   147/ 1097] train: loss: 0.0163033
[Epoch 100; Iter   177/ 1097] train: loss: 0.0116830
[Epoch 100; Iter   207/ 1097] train: loss: 0.0028269
[Epoch 100; Iter   237/ 1097] train: loss: 0.0176234
[Epoch 100; Iter   267/ 1097] train: loss: 0.0216611
[Epoch 100; Iter   297/ 1097] train: loss: 0.0036385
[Epoch 100; Iter   327/ 1097] train: loss: 0.0477372
[Epoch 100; Iter   357/ 1097] train: loss: 0.0150462
[Epoch 100; Iter   387/ 1097] train: loss: 0.0289476
[Epoch 100; Iter   417/ 1097] train: loss: 0.0008772
[Epoch 100; Iter   447/ 1097] train: loss: 0.0023140
[Epoch 100; Iter   477/ 1097] train: loss: 0.0582757
[Epoch 100; Iter   507/ 1097] train: loss: 0.0093768
[Epoch 100; Iter   537/ 1097] train: loss: 0.0117745
[Epoch 100; Iter   567/ 1097] train: loss: 0.0115452
[Epoch 100; Iter   597/ 1097] train: loss: 0.0210115
[Epoch 100; Iter   627/ 1097] train: loss: 0.0449364
[Epoch 100; Iter   657/ 1097] train: loss: 0.0041115
[Epoch 100; Iter   687/ 1097] train: loss: 0.0168966
[Epoch 100; Iter   717/ 1097] train: loss: 0.0126899
[Epoch 100; Iter   747/ 1097] train: loss: 0.0190862
[Epoch 100; Iter   777/ 1097] train: loss: 0.0529879
[Epoch 100; Iter   807/ 1097] train: loss: 0.0490128
[Epoch 100; Iter   837/ 1097] train: loss: 0.0017635
[Epoch 100; Iter   867/ 1097] train: loss: 0.0957989
[Epoch 100; Iter   897/ 1097] train: loss: 0.0857948
[Epoch 100; Iter   927/ 1097] train: loss: 0.0071009
[Epoch 100; Iter   957/ 1097] train: loss: 0.0729614
[Epoch 100; Iter   987/ 1097] train: loss: 0.0249088
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0379178
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0062149
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0028217
[Epoch 100] ogbg-molhiv: 0.814392 val loss: 0.133373
[Epoch 100] ogbg-molhiv: 0.745065 test loss: 0.257206
[Epoch 101; Iter    10/ 1097] train: loss: 0.0170249
[Epoch 101; Iter    40/ 1097] train: loss: 0.0044953
[Epoch 101; Iter    70/ 1097] train: loss: 0.0276560
[Epoch 101; Iter   100/ 1097] train: loss: 0.0064260
[Epoch 101; Iter   130/ 1097] train: loss: 0.0105926
[Epoch 101; Iter   160/ 1097] train: loss: 0.0026320
[Epoch 101; Iter   190/ 1097] train: loss: 0.0767820
[Epoch 101; Iter   220/ 1097] train: loss: 0.0127482
[Epoch 101; Iter   250/ 1097] train: loss: 0.0057142
[Epoch 101; Iter   280/ 1097] train: loss: 0.0323191
[Epoch 101; Iter   310/ 1097] train: loss: 0.0764170
[Epoch 101; Iter   340/ 1097] train: loss: 0.1014504
[Epoch 101; Iter   370/ 1097] train: loss: 0.0594880
[Epoch 101; Iter   400/ 1097] train: loss: 0.0011911
[Epoch 101; Iter   430/ 1097] train: loss: 0.0025015
[Epoch 101; Iter   460/ 1097] train: loss: 0.0043738
[Epoch 101; Iter   490/ 1097] train: loss: 0.0006178
[Epoch 101; Iter   520/ 1097] train: loss: 0.0278980
[Epoch 101; Iter   550/ 1097] train: loss: 0.0013591
[Epoch 101; Iter   580/ 1097] train: loss: 0.0025265
[Epoch 101; Iter   610/ 1097] train: loss: 0.0154490
[Epoch 101; Iter   640/ 1097] train: loss: 0.0463495
[Epoch 101; Iter   670/ 1097] train: loss: 0.0039315
[Epoch 101; Iter   700/ 1097] train: loss: 0.0136803
[Epoch 97; Iter   678/ 1097] train: loss: 0.0035043
[Epoch 97; Iter   708/ 1097] train: loss: 0.0254882
[Epoch 97; Iter   738/ 1097] train: loss: 0.0127931
[Epoch 97; Iter   768/ 1097] train: loss: 0.0799494
[Epoch 97; Iter   798/ 1097] train: loss: 0.0325374
[Epoch 97; Iter   828/ 1097] train: loss: 0.0044842
[Epoch 97; Iter   858/ 1097] train: loss: 0.0099918
[Epoch 97; Iter   888/ 1097] train: loss: 0.0096044
[Epoch 97; Iter   918/ 1097] train: loss: 0.0019097
[Epoch 97; Iter   948/ 1097] train: loss: 0.0222461
[Epoch 97; Iter   978/ 1097] train: loss: 0.0089035
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0177080
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0139806
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0255043
[Epoch 97] ogbg-molhiv: 0.794511 val loss: 0.121418
[Epoch 97] ogbg-molhiv: 0.753483 test loss: 0.235010
[Epoch 98; Iter     1/ 1097] train: loss: 0.0063506
[Epoch 98; Iter    31/ 1097] train: loss: 0.0739214
[Epoch 98; Iter    61/ 1097] train: loss: 0.0054075
[Epoch 98; Iter    91/ 1097] train: loss: 0.0008591
[Epoch 98; Iter   121/ 1097] train: loss: 0.0066437
[Epoch 98; Iter   151/ 1097] train: loss: 0.0049769
[Epoch 98; Iter   181/ 1097] train: loss: 0.0058521
[Epoch 98; Iter   211/ 1097] train: loss: 0.0043247
[Epoch 98; Iter   241/ 1097] train: loss: 0.0070546
[Epoch 98; Iter   271/ 1097] train: loss: 0.0049009
[Epoch 98; Iter   301/ 1097] train: loss: 0.0196723
[Epoch 98; Iter   331/ 1097] train: loss: 0.0513892
[Epoch 98; Iter   361/ 1097] train: loss: 0.0128288
[Epoch 98; Iter   391/ 1097] train: loss: 0.0093288
[Epoch 98; Iter   421/ 1097] train: loss: 0.0073427
[Epoch 98; Iter   451/ 1097] train: loss: 0.0123210
[Epoch 98; Iter   481/ 1097] train: loss: 0.0057442
[Epoch 98; Iter   511/ 1097] train: loss: 0.1696657
[Epoch 98; Iter   541/ 1097] train: loss: 0.0040643
[Epoch 98; Iter   571/ 1097] train: loss: 0.0034578
[Epoch 98; Iter   601/ 1097] train: loss: 0.0131355
[Epoch 98; Iter   631/ 1097] train: loss: 0.0036872
[Epoch 98; Iter   661/ 1097] train: loss: 0.0034798
[Epoch 98; Iter   691/ 1097] train: loss: 0.0057795
[Epoch 98; Iter   721/ 1097] train: loss: 0.1289925
[Epoch 98; Iter   751/ 1097] train: loss: 0.1240984
[Epoch 98; Iter   781/ 1097] train: loss: 0.0043774
[Epoch 98; Iter   811/ 1097] train: loss: 0.0040993
[Epoch 98; Iter   841/ 1097] train: loss: 0.0249292
[Epoch 98; Iter   871/ 1097] train: loss: 0.0078558
[Epoch 98; Iter   901/ 1097] train: loss: 0.0993858
[Epoch 98; Iter   931/ 1097] train: loss: 0.0209755
[Epoch 98; Iter   961/ 1097] train: loss: 0.0108730
[Epoch 98; Iter   991/ 1097] train: loss: 0.0014849
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0064289
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0017388
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0029104
[Epoch 98] ogbg-molhiv: 0.816147 val loss: 0.113985
[Epoch 98] ogbg-molhiv: 0.755727 test loss: 0.232012
[Epoch 99; Iter    14/ 1097] train: loss: 0.0103666
[Epoch 99; Iter    44/ 1097] train: loss: 0.0238005
[Epoch 99; Iter    74/ 1097] train: loss: 0.0458487
[Epoch 99; Iter   104/ 1097] train: loss: 0.0085529
[Epoch 99; Iter   134/ 1097] train: loss: 0.0060298
[Epoch 99; Iter   164/ 1097] train: loss: 0.1327258
[Epoch 99; Iter   194/ 1097] train: loss: 0.0143630
[Epoch 99; Iter   224/ 1097] train: loss: 0.0086604
[Epoch 99; Iter   254/ 1097] train: loss: 0.1464364
[Epoch 99; Iter   284/ 1097] train: loss: 0.0041338
[Epoch 99; Iter   314/ 1097] train: loss: 0.0378818
[Epoch 99; Iter   344/ 1097] train: loss: 0.0022723
[Epoch 99; Iter   374/ 1097] train: loss: 0.0011630
[Epoch 99; Iter   404/ 1097] train: loss: 0.0399434
[Epoch 99; Iter   434/ 1097] train: loss: 0.0296474
[Epoch 99; Iter   464/ 1097] train: loss: 0.0029616
[Epoch 99; Iter   494/ 1097] train: loss: 0.0118524
[Epoch 99; Iter   524/ 1097] train: loss: 0.0275043
[Epoch 99; Iter   554/ 1097] train: loss: 0.0051958
[Epoch 99; Iter   584/ 1097] train: loss: 0.0043614
[Epoch 99; Iter   614/ 1097] train: loss: 0.0327079
[Epoch 99; Iter   644/ 1097] train: loss: 0.0012489
[Epoch 99; Iter   674/ 1097] train: loss: 0.0075847
[Epoch 99; Iter   704/ 1097] train: loss: 0.0108665
[Epoch 99; Iter   734/ 1097] train: loss: 0.0155758
[Epoch 99; Iter   764/ 1097] train: loss: 0.0044623
[Epoch 99; Iter   794/ 1097] train: loss: 0.2965311
[Epoch 99; Iter   824/ 1097] train: loss: 0.0207262
[Epoch 99; Iter   854/ 1097] train: loss: 0.0053949
[Epoch 99; Iter   884/ 1097] train: loss: 0.0138818
[Epoch 99; Iter   914/ 1097] train: loss: 0.0225308
[Epoch 99; Iter   944/ 1097] train: loss: 0.0346009
[Epoch 99; Iter   974/ 1097] train: loss: 0.0040256
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0015090
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0230600
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0118120
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0251417
[Epoch 99] ogbg-molhiv: 0.804977 val loss: 0.119606
[Epoch 99] ogbg-molhiv: 0.741161 test loss: 0.235972
[Epoch 100; Iter    27/ 1097] train: loss: 0.0064030
[Epoch 100; Iter    57/ 1097] train: loss: 0.0181957
[Epoch 100; Iter    87/ 1097] train: loss: 0.0034004
[Epoch 100; Iter   117/ 1097] train: loss: 0.0986857
[Epoch 100; Iter   147/ 1097] train: loss: 0.0027391
[Epoch 100; Iter   177/ 1097] train: loss: 0.0376315
[Epoch 100; Iter   207/ 1097] train: loss: 0.0475612
[Epoch 100; Iter   237/ 1097] train: loss: 0.0361758
[Epoch 100; Iter   267/ 1097] train: loss: 0.0042138
[Epoch 100; Iter   297/ 1097] train: loss: 0.0016347
[Epoch 100; Iter   327/ 1097] train: loss: 0.0292373
[Epoch 100; Iter   357/ 1097] train: loss: 0.0027958
[Epoch 100; Iter   387/ 1097] train: loss: 0.0388487
[Epoch 100; Iter   417/ 1097] train: loss: 0.0302736
[Epoch 100; Iter   447/ 1097] train: loss: 0.0148875
[Epoch 100; Iter   477/ 1097] train: loss: 0.0294171
[Epoch 100; Iter   507/ 1097] train: loss: 0.0228276
[Epoch 100; Iter   537/ 1097] train: loss: 0.0063862
[Epoch 100; Iter   567/ 1097] train: loss: 0.0059600
[Epoch 100; Iter   597/ 1097] train: loss: 0.0124135
[Epoch 100; Iter   627/ 1097] train: loss: 0.0710682
[Epoch 100; Iter   657/ 1097] train: loss: 0.0055533
[Epoch 100; Iter   687/ 1097] train: loss: 0.0053968
[Epoch 100; Iter   717/ 1097] train: loss: 0.1061515
[Epoch 100; Iter   747/ 1097] train: loss: 0.0020792
[Epoch 100; Iter   777/ 1097] train: loss: 0.0051158
[Epoch 100; Iter   807/ 1097] train: loss: 0.0629119
[Epoch 100; Iter   837/ 1097] train: loss: 0.1156024
[Epoch 100; Iter   867/ 1097] train: loss: 0.0316520
[Epoch 100; Iter   897/ 1097] train: loss: 0.0118361
[Epoch 100; Iter   927/ 1097] train: loss: 0.0038591
[Epoch 100; Iter   957/ 1097] train: loss: 0.0252618
[Epoch 100; Iter   987/ 1097] train: loss: 0.0223537
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0473365
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0112769
[Epoch 100; Iter  1077/ 1097] train: loss: 0.1134386
[Epoch 100] ogbg-molhiv: 0.807273 val loss: 0.116911
[Epoch 100] ogbg-molhiv: 0.743110 test loss: 0.240514
[Epoch 101; Iter    10/ 1097] train: loss: 0.0033223
[Epoch 101; Iter    40/ 1097] train: loss: 0.0022601
[Epoch 101; Iter    70/ 1097] train: loss: 0.0199233
[Epoch 101; Iter   100/ 1097] train: loss: 0.0551323
[Epoch 101; Iter   130/ 1097] train: loss: 0.0069505
[Epoch 101; Iter   160/ 1097] train: loss: 0.0051220
[Epoch 101; Iter   190/ 1097] train: loss: 0.0215947
[Epoch 101; Iter   220/ 1097] train: loss: 0.0119024
[Epoch 101; Iter   250/ 1097] train: loss: 0.0040493
[Epoch 101; Iter   280/ 1097] train: loss: 0.0066941
[Epoch 101; Iter   310/ 1097] train: loss: 0.0048100
[Epoch 101; Iter   340/ 1097] train: loss: 0.0030505
[Epoch 101; Iter   370/ 1097] train: loss: 0.0093622
[Epoch 101; Iter   400/ 1097] train: loss: 0.0447506
[Epoch 101; Iter   430/ 1097] train: loss: 0.0128443
[Epoch 101; Iter   460/ 1097] train: loss: 0.0077718
[Epoch 101; Iter   490/ 1097] train: loss: 0.0029307
[Epoch 101; Iter   520/ 1097] train: loss: 0.0007435
[Epoch 101; Iter   550/ 1097] train: loss: 0.0349167
[Epoch 101; Iter   580/ 1097] train: loss: 0.0008370
[Epoch 101; Iter   610/ 1097] train: loss: 0.0234041
[Epoch 101; Iter   640/ 1097] train: loss: 0.0015699
[Epoch 101; Iter   670/ 1097] train: loss: 0.0018682
[Epoch 101; Iter   700/ 1097] train: loss: 0.0035826
[Epoch 97; Iter   678/ 1097] train: loss: 0.0154781
[Epoch 97; Iter   708/ 1097] train: loss: 0.0156134
[Epoch 97; Iter   738/ 1097] train: loss: 0.0702375
[Epoch 97; Iter   768/ 1097] train: loss: 0.0241123
[Epoch 97; Iter   798/ 1097] train: loss: 0.0147856
[Epoch 97; Iter   828/ 1097] train: loss: 0.0004046
[Epoch 97; Iter   858/ 1097] train: loss: 0.0192085
[Epoch 97; Iter   888/ 1097] train: loss: 0.1071463
[Epoch 97; Iter   918/ 1097] train: loss: 0.0462633
[Epoch 97; Iter   948/ 1097] train: loss: 0.0020893
[Epoch 97; Iter   978/ 1097] train: loss: 0.0250141
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0450480
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0091721
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0009395
[Epoch 97] ogbg-molhiv: 0.777064 val loss: 0.152212
[Epoch 97] ogbg-molhiv: 0.741235 test loss: 0.265610
[Epoch 98; Iter     1/ 1097] train: loss: 0.0354570
[Epoch 98; Iter    31/ 1097] train: loss: 0.0035335
[Epoch 98; Iter    61/ 1097] train: loss: 0.0012766
[Epoch 98; Iter    91/ 1097] train: loss: 0.0372945
[Epoch 98; Iter   121/ 1097] train: loss: 0.0464971
[Epoch 98; Iter   151/ 1097] train: loss: 0.0325732
[Epoch 98; Iter   181/ 1097] train: loss: 0.0018901
[Epoch 98; Iter   211/ 1097] train: loss: 0.0179714
[Epoch 98; Iter   241/ 1097] train: loss: 0.0014962
[Epoch 98; Iter   271/ 1097] train: loss: 0.0123054
[Epoch 98; Iter   301/ 1097] train: loss: 0.0113706
[Epoch 98; Iter   331/ 1097] train: loss: 0.0130873
[Epoch 98; Iter   361/ 1097] train: loss: 0.0146914
[Epoch 98; Iter   391/ 1097] train: loss: 0.0630963
[Epoch 98; Iter   421/ 1097] train: loss: 0.0027707
[Epoch 98; Iter   451/ 1097] train: loss: 0.0094894
[Epoch 98; Iter   481/ 1097] train: loss: 0.0023282
[Epoch 98; Iter   511/ 1097] train: loss: 0.0008590
[Epoch 98; Iter   541/ 1097] train: loss: 0.0039739
[Epoch 98; Iter   571/ 1097] train: loss: 0.0374374
[Epoch 98; Iter   601/ 1097] train: loss: 0.0038244
[Epoch 98; Iter   631/ 1097] train: loss: 0.0012012
[Epoch 98; Iter   661/ 1097] train: loss: 0.0020150
[Epoch 98; Iter   691/ 1097] train: loss: 0.0317724
[Epoch 98; Iter   721/ 1097] train: loss: 0.0121167
[Epoch 98; Iter   751/ 1097] train: loss: 0.0047119
[Epoch 98; Iter   781/ 1097] train: loss: 0.0008019
[Epoch 98; Iter   811/ 1097] train: loss: 0.0005586
[Epoch 98; Iter   841/ 1097] train: loss: 0.0179715
[Epoch 98; Iter   871/ 1097] train: loss: 0.0020368
[Epoch 98; Iter   901/ 1097] train: loss: 0.0039873
[Epoch 98; Iter   931/ 1097] train: loss: 0.0136690
[Epoch 98; Iter   961/ 1097] train: loss: 0.0045781
[Epoch 98; Iter   991/ 1097] train: loss: 0.0026588
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0972600
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0322959
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0839433
[Epoch 98] ogbg-molhiv: 0.786131 val loss: 0.144687
[Epoch 98] ogbg-molhiv: 0.759516 test loss: 0.257639
[Epoch 99; Iter    14/ 1097] train: loss: 0.0053090
[Epoch 99; Iter    44/ 1097] train: loss: 0.0073168
[Epoch 99; Iter    74/ 1097] train: loss: 0.0008940
[Epoch 99; Iter   104/ 1097] train: loss: 0.0123949
[Epoch 99; Iter   134/ 1097] train: loss: 0.0554172
[Epoch 99; Iter   164/ 1097] train: loss: 0.0045266
[Epoch 99; Iter   194/ 1097] train: loss: 0.0006568
[Epoch 99; Iter   224/ 1097] train: loss: 0.0305075
[Epoch 99; Iter   254/ 1097] train: loss: 0.0223256
[Epoch 99; Iter   284/ 1097] train: loss: 0.0027701
[Epoch 99; Iter   314/ 1097] train: loss: 0.0486798
[Epoch 99; Iter   344/ 1097] train: loss: 0.0029603
[Epoch 99; Iter   374/ 1097] train: loss: 0.0004984
[Epoch 99; Iter   404/ 1097] train: loss: 0.0315782
[Epoch 99; Iter   434/ 1097] train: loss: 0.0260843
[Epoch 99; Iter   464/ 1097] train: loss: 0.0203797
[Epoch 99; Iter   494/ 1097] train: loss: 0.0087006
[Epoch 99; Iter   524/ 1097] train: loss: 0.0014836
[Epoch 99; Iter   554/ 1097] train: loss: 0.0035432
[Epoch 99; Iter   584/ 1097] train: loss: 0.0058850
[Epoch 99; Iter   614/ 1097] train: loss: 0.0022923
[Epoch 99; Iter   644/ 1097] train: loss: 0.0039003
[Epoch 99; Iter   674/ 1097] train: loss: 0.0022457
[Epoch 99; Iter   704/ 1097] train: loss: 0.1068520
[Epoch 99; Iter   734/ 1097] train: loss: 0.0015178
[Epoch 99; Iter   764/ 1097] train: loss: 0.0140149
[Epoch 99; Iter   794/ 1097] train: loss: 0.0064355
[Epoch 99; Iter   824/ 1097] train: loss: 0.0039604
[Epoch 99; Iter   854/ 1097] train: loss: 0.0512016
[Epoch 99; Iter   884/ 1097] train: loss: 0.0015320
[Epoch 99; Iter   914/ 1097] train: loss: 0.0033093
[Epoch 99; Iter   944/ 1097] train: loss: 0.0134377
[Epoch 99; Iter   974/ 1097] train: loss: 0.0012359
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0044355
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0085940
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0137167
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0005799
[Epoch 99] ogbg-molhiv: 0.785133 val loss: 0.148901
[Epoch 99] ogbg-molhiv: 0.748682 test loss: 0.268092
[Epoch 100; Iter    27/ 1097] train: loss: 0.0065132
[Epoch 100; Iter    57/ 1097] train: loss: 0.0022887
[Epoch 100; Iter    87/ 1097] train: loss: 0.0022637
[Epoch 100; Iter   117/ 1097] train: loss: 0.0139918
[Epoch 100; Iter   147/ 1097] train: loss: 0.0004372
[Epoch 100; Iter   177/ 1097] train: loss: 0.0012093
[Epoch 100; Iter   207/ 1097] train: loss: 0.0018161
[Epoch 100; Iter   237/ 1097] train: loss: 0.0291140
[Epoch 100; Iter   267/ 1097] train: loss: 0.0163515
[Epoch 100; Iter   297/ 1097] train: loss: 0.0034166
[Epoch 100; Iter   327/ 1097] train: loss: 0.0127080
[Epoch 100; Iter   357/ 1097] train: loss: 0.0004612
[Epoch 100; Iter   387/ 1097] train: loss: 0.0250700
[Epoch 100; Iter   417/ 1097] train: loss: 0.0155721
[Epoch 100; Iter   447/ 1097] train: loss: 0.0234832
[Epoch 100; Iter   477/ 1097] train: loss: 0.0317586
[Epoch 100; Iter   507/ 1097] train: loss: 0.0003892
[Epoch 100; Iter   537/ 1097] train: loss: 0.0235230
[Epoch 100; Iter   567/ 1097] train: loss: 0.0390089
[Epoch 100; Iter   597/ 1097] train: loss: 0.0008008
[Epoch 100; Iter   627/ 1097] train: loss: 0.0031696
[Epoch 100; Iter   657/ 1097] train: loss: 0.0304494
[Epoch 100; Iter   687/ 1097] train: loss: 0.0018536
[Epoch 100; Iter   717/ 1097] train: loss: 0.0062504
[Epoch 100; Iter   747/ 1097] train: loss: 0.0182123
[Epoch 100; Iter   777/ 1097] train: loss: 0.0013067
[Epoch 100; Iter   807/ 1097] train: loss: 0.0027267
[Epoch 100; Iter   837/ 1097] train: loss: 0.0077192
[Epoch 100; Iter   867/ 1097] train: loss: 0.0057533
[Epoch 100; Iter   897/ 1097] train: loss: 0.0168725
[Epoch 100; Iter   927/ 1097] train: loss: 0.0019486
[Epoch 100; Iter   957/ 1097] train: loss: 0.0022255
[Epoch 100; Iter   987/ 1097] train: loss: 0.0362636
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0242954
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0013982
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0702221
[Epoch 100] ogbg-molhiv: 0.769557 val loss: 0.150089
[Epoch 100] ogbg-molhiv: 0.745814 test loss: 0.277666
[Epoch 101; Iter    10/ 1097] train: loss: 0.0468224
[Epoch 101; Iter    40/ 1097] train: loss: 0.1198144
[Epoch 101; Iter    70/ 1097] train: loss: 0.0568429
[Epoch 101; Iter   100/ 1097] train: loss: 0.0559486
[Epoch 101; Iter   130/ 1097] train: loss: 0.0064269
[Epoch 101; Iter   160/ 1097] train: loss: 0.0032039
[Epoch 101; Iter   190/ 1097] train: loss: 0.0775908
[Epoch 101; Iter   220/ 1097] train: loss: 0.0539791
[Epoch 101; Iter   250/ 1097] train: loss: 0.0027666
[Epoch 101; Iter   280/ 1097] train: loss: 0.1858135
[Epoch 101; Iter   310/ 1097] train: loss: 0.0090241
[Epoch 101; Iter   340/ 1097] train: loss: 0.0152619
[Epoch 101; Iter   370/ 1097] train: loss: 0.0019879
[Epoch 101; Iter   400/ 1097] train: loss: 0.0363168
[Epoch 101; Iter   430/ 1097] train: loss: 0.0729098
[Epoch 101; Iter   460/ 1097] train: loss: 0.0718842
[Epoch 101; Iter   490/ 1097] train: loss: 0.0021115
[Epoch 101; Iter   520/ 1097] train: loss: 0.0005767
[Epoch 101; Iter   550/ 1097] train: loss: 0.0034550
[Epoch 101; Iter   580/ 1097] train: loss: 0.1485440
[Epoch 101; Iter   610/ 1097] train: loss: 0.0308183
[Epoch 101; Iter   640/ 1097] train: loss: 0.0229850
[Epoch 101; Iter   670/ 1097] train: loss: 0.0047477
[Epoch 101; Iter   700/ 1097] train: loss: 0.0257521
[Epoch 101; Iter   730/ 1097] train: loss: 0.0021128
[Epoch 101; Iter   760/ 1097] train: loss: 0.0222218
[Epoch 101; Iter   790/ 1097] train: loss: 0.0053155
[Epoch 101; Iter   820/ 1097] train: loss: 0.0027552
[Epoch 101; Iter   850/ 1097] train: loss: 0.0013366
[Epoch 101; Iter   880/ 1097] train: loss: 0.0103794
[Epoch 101; Iter   910/ 1097] train: loss: 0.0033332
[Epoch 101; Iter   940/ 1097] train: loss: 0.0255107
[Epoch 101; Iter   970/ 1097] train: loss: 0.0168241
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0545344
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0029335
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0015970
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0096872
[Epoch 101] ogbg-molhiv: 0.820317 val loss: 0.133782
[Epoch 101] ogbg-molhiv: 0.750293 test loss: 0.249214
[Epoch 102; Iter    23/ 1097] train: loss: 0.0020352
[Epoch 102; Iter    53/ 1097] train: loss: 0.0011136
[Epoch 102; Iter    83/ 1097] train: loss: 0.0753912
[Epoch 102; Iter   113/ 1097] train: loss: 0.0079664
[Epoch 102; Iter   143/ 1097] train: loss: 0.0305798
[Epoch 102; Iter   173/ 1097] train: loss: 0.0087831
[Epoch 102; Iter   203/ 1097] train: loss: 0.0031028
[Epoch 102; Iter   233/ 1097] train: loss: 0.0383488
[Epoch 102; Iter   263/ 1097] train: loss: 0.0019669
[Epoch 102; Iter   293/ 1097] train: loss: 0.0004997
[Epoch 102; Iter   323/ 1097] train: loss: 0.0074893
[Epoch 102; Iter   353/ 1097] train: loss: 0.0476718
[Epoch 102; Iter   383/ 1097] train: loss: 0.0488544
[Epoch 102; Iter   413/ 1097] train: loss: 0.0782116
[Epoch 102; Iter   443/ 1097] train: loss: 0.0086795
[Epoch 102; Iter   473/ 1097] train: loss: 0.0197652
[Epoch 102; Iter   503/ 1097] train: loss: 0.0351707
[Epoch 102; Iter   533/ 1097] train: loss: 0.0161885
[Epoch 102; Iter   563/ 1097] train: loss: 0.0060909
[Epoch 102; Iter   593/ 1097] train: loss: 0.0069131
[Epoch 102; Iter   623/ 1097] train: loss: 0.0157229
[Epoch 102; Iter   653/ 1097] train: loss: 0.0145280
[Epoch 102; Iter   683/ 1097] train: loss: 0.0042419
[Epoch 102; Iter   713/ 1097] train: loss: 0.0125330
[Epoch 102; Iter   743/ 1097] train: loss: 0.0022416
[Epoch 102; Iter   773/ 1097] train: loss: 0.0083327
[Epoch 102; Iter   803/ 1097] train: loss: 0.0175097
[Epoch 102; Iter   833/ 1097] train: loss: 0.0076334
[Epoch 102; Iter   863/ 1097] train: loss: 0.0080612
[Epoch 102; Iter   893/ 1097] train: loss: 0.0049440
[Epoch 102; Iter   923/ 1097] train: loss: 0.0551872
[Epoch 102; Iter   953/ 1097] train: loss: 0.0045362
[Epoch 102; Iter   983/ 1097] train: loss: 0.0028154
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0267822
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0037031
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0009750
[Epoch 102] ogbg-molhiv: 0.809496 val loss: 0.132170
[Epoch 102] ogbg-molhiv: 0.748394 test loss: 0.248552
[Epoch 103; Iter     6/ 1097] train: loss: 0.0061999
[Epoch 103; Iter    36/ 1097] train: loss: 0.0169988
[Epoch 103; Iter    66/ 1097] train: loss: 0.0073103
[Epoch 103; Iter    96/ 1097] train: loss: 0.0082630
[Epoch 103; Iter   126/ 1097] train: loss: 0.0366569
[Epoch 103; Iter   156/ 1097] train: loss: 0.0205696
[Epoch 103; Iter   186/ 1097] train: loss: 0.0779687
[Epoch 103; Iter   216/ 1097] train: loss: 0.0166855
[Epoch 103; Iter   246/ 1097] train: loss: 0.0538290
[Epoch 103; Iter   276/ 1097] train: loss: 0.0068039
[Epoch 103; Iter   306/ 1097] train: loss: 0.0148746
[Epoch 103; Iter   336/ 1097] train: loss: 0.0103810
[Epoch 103; Iter   366/ 1097] train: loss: 0.0040650
[Epoch 103; Iter   396/ 1097] train: loss: 0.0007434
[Epoch 103; Iter   426/ 1097] train: loss: 0.0208953
[Epoch 103; Iter   456/ 1097] train: loss: 0.0115110
[Epoch 103; Iter   486/ 1097] train: loss: 0.0115247
[Epoch 103; Iter   516/ 1097] train: loss: 0.0287367
[Epoch 103; Iter   546/ 1097] train: loss: 0.0032956
[Epoch 103; Iter   576/ 1097] train: loss: 0.0065505
[Epoch 103; Iter   606/ 1097] train: loss: 0.0227544
[Epoch 103; Iter   636/ 1097] train: loss: 0.0073847
[Epoch 103; Iter   666/ 1097] train: loss: 0.0020244
[Epoch 103; Iter   696/ 1097] train: loss: 0.0242165
[Epoch 103; Iter   726/ 1097] train: loss: 0.0929534
[Epoch 103; Iter   756/ 1097] train: loss: 0.0822108
[Epoch 103; Iter   786/ 1097] train: loss: 0.0017671
[Epoch 103; Iter   816/ 1097] train: loss: 0.0731248
[Epoch 103; Iter   846/ 1097] train: loss: 0.1089786
[Epoch 103; Iter   876/ 1097] train: loss: 0.0018528
[Epoch 103; Iter   906/ 1097] train: loss: 0.0195944
[Epoch 103; Iter   936/ 1097] train: loss: 0.0013185
[Epoch 103; Iter   966/ 1097] train: loss: 0.0011057
[Epoch 103; Iter   996/ 1097] train: loss: 0.0100300
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0839719
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0074435
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0029792
[Epoch 103] ogbg-molhiv: 0.808627 val loss: 0.140553
[Epoch 103] ogbg-molhiv: 0.743724 test loss: 0.260149
[Epoch 104; Iter    19/ 1097] train: loss: 0.0024563
[Epoch 104; Iter    49/ 1097] train: loss: 0.0010568
[Epoch 104; Iter    79/ 1097] train: loss: 0.0028195
[Epoch 104; Iter   109/ 1097] train: loss: 0.0070722
[Epoch 104; Iter   139/ 1097] train: loss: 0.0241189
[Epoch 104; Iter   169/ 1097] train: loss: 0.0342006
[Epoch 104; Iter   199/ 1097] train: loss: 0.0179723
[Epoch 104; Iter   229/ 1097] train: loss: 0.0296611
[Epoch 104; Iter   259/ 1097] train: loss: 0.0082620
[Epoch 104; Iter   289/ 1097] train: loss: 0.0014620
[Epoch 104; Iter   319/ 1097] train: loss: 0.0008650
[Epoch 104; Iter   349/ 1097] train: loss: 0.0001427
[Epoch 104; Iter   379/ 1097] train: loss: 0.0005506
[Epoch 104; Iter   409/ 1097] train: loss: 0.0188916
[Epoch 104; Iter   439/ 1097] train: loss: 0.1205439
[Epoch 104; Iter   469/ 1097] train: loss: 0.0255167
[Epoch 104; Iter   499/ 1097] train: loss: 0.0009053
[Epoch 104; Iter   529/ 1097] train: loss: 0.0253530
[Epoch 104; Iter   559/ 1097] train: loss: 0.0164074
[Epoch 104; Iter   589/ 1097] train: loss: 0.0040391
[Epoch 104; Iter   619/ 1097] train: loss: 0.0013728
[Epoch 104; Iter   649/ 1097] train: loss: 0.0999231
[Epoch 104; Iter   679/ 1097] train: loss: 0.0150997
[Epoch 104; Iter   709/ 1097] train: loss: 0.0022673
[Epoch 104; Iter   739/ 1097] train: loss: 0.0018471
[Epoch 104; Iter   769/ 1097] train: loss: 0.0152905
[Epoch 104; Iter   799/ 1097] train: loss: 0.0051681
[Epoch 104; Iter   829/ 1097] train: loss: 0.0216391
[Epoch 104; Iter   859/ 1097] train: loss: 0.0008936
[Epoch 104; Iter   889/ 1097] train: loss: 0.0299329
[Epoch 104; Iter   919/ 1097] train: loss: 0.0009904
[Epoch 104; Iter   949/ 1097] train: loss: 0.1098024
[Epoch 104; Iter   979/ 1097] train: loss: 0.0584911
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0162726
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0090631
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0550999
[Epoch 104] ogbg-molhiv: 0.818713 val loss: 0.137803
[Epoch 104] ogbg-molhiv: 0.748334 test loss: 0.261556
[Epoch 105; Iter     2/ 1097] train: loss: 0.0077588
[Epoch 105; Iter    32/ 1097] train: loss: 0.0016503
[Epoch 105; Iter    62/ 1097] train: loss: 0.0007722
[Epoch 105; Iter    92/ 1097] train: loss: 0.0118400
[Epoch 105; Iter   122/ 1097] train: loss: 0.0091013
[Epoch 105; Iter   152/ 1097] train: loss: 0.0530453
[Epoch 105; Iter   182/ 1097] train: loss: 0.0061992
[Epoch 105; Iter   212/ 1097] train: loss: 0.0005853
[Epoch 105; Iter   242/ 1097] train: loss: 0.0758415
[Epoch 105; Iter   272/ 1097] train: loss: 0.0015922
[Epoch 105; Iter   302/ 1097] train: loss: 0.0220934
[Epoch 105; Iter   332/ 1097] train: loss: 0.0999994
[Epoch 105; Iter   362/ 1097] train: loss: 0.0022728
[Epoch 105; Iter   392/ 1097] train: loss: 0.0089291
[Epoch 105; Iter   422/ 1097] train: loss: 0.0179555
[Epoch 105; Iter   452/ 1097] train: loss: 0.0132543
[Epoch 105; Iter   482/ 1097] train: loss: 0.0706799
[Epoch 105; Iter   512/ 1097] train: loss: 0.0007668
[Epoch 105; Iter   542/ 1097] train: loss: 0.0289137
[Epoch 105; Iter   572/ 1097] train: loss: 0.0075300
[Epoch 105; Iter   602/ 1097] train: loss: 0.0341750
[Epoch 105; Iter   632/ 1097] train: loss: 0.0018714
[Epoch 105; Iter   662/ 1097] train: loss: 0.0161393
[Epoch 105; Iter   692/ 1097] train: loss: 0.0225940
[Epoch 101; Iter   730/ 1097] train: loss: 0.0137761
[Epoch 101; Iter   760/ 1097] train: loss: 0.0941603
[Epoch 101; Iter   790/ 1097] train: loss: 0.0347178
[Epoch 101; Iter   820/ 1097] train: loss: 0.0003427
[Epoch 101; Iter   850/ 1097] train: loss: 0.0029007
[Epoch 101; Iter   880/ 1097] train: loss: 0.0122495
[Epoch 101; Iter   910/ 1097] train: loss: 0.0051102
[Epoch 101; Iter   940/ 1097] train: loss: 0.0130156
[Epoch 101; Iter   970/ 1097] train: loss: 0.0027740
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0017471
[Epoch 101; Iter  1030/ 1097] train: loss: 0.1181587
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0945099
[Epoch 101; Iter  1090/ 1097] train: loss: 0.1624453
[Epoch 101] ogbg-molhiv: 0.806832 val loss: 0.120265
[Epoch 101] ogbg-molhiv: 0.744887 test loss: 0.257365
[Epoch 102; Iter    23/ 1097] train: loss: 0.0127633
[Epoch 102; Iter    53/ 1097] train: loss: 0.0060106
[Epoch 102; Iter    83/ 1097] train: loss: 0.0013796
[Epoch 102; Iter   113/ 1097] train: loss: 0.0057724
[Epoch 102; Iter   143/ 1097] train: loss: 0.0986584
[Epoch 102; Iter   173/ 1097] train: loss: 0.0120662
[Epoch 102; Iter   203/ 1097] train: loss: 0.0004990
[Epoch 102; Iter   233/ 1097] train: loss: 0.0029618
[Epoch 102; Iter   263/ 1097] train: loss: 0.0122716
[Epoch 102; Iter   293/ 1097] train: loss: 0.0031739
[Epoch 102; Iter   323/ 1097] train: loss: 0.0215934
[Epoch 102; Iter   353/ 1097] train: loss: 0.0069593
[Epoch 102; Iter   383/ 1097] train: loss: 0.0080752
[Epoch 102; Iter   413/ 1097] train: loss: 0.0197479
[Epoch 102; Iter   443/ 1097] train: loss: 0.0309866
[Epoch 102; Iter   473/ 1097] train: loss: 0.0034357
[Epoch 102; Iter   503/ 1097] train: loss: 0.0480439
[Epoch 102; Iter   533/ 1097] train: loss: 0.0034511
[Epoch 102; Iter   563/ 1097] train: loss: 0.0648544
[Epoch 102; Iter   593/ 1097] train: loss: 0.0034691
[Epoch 102; Iter   623/ 1097] train: loss: 0.0045330
[Epoch 102; Iter   653/ 1097] train: loss: 0.0723497
[Epoch 102; Iter   683/ 1097] train: loss: 0.0017139
[Epoch 102; Iter   713/ 1097] train: loss: 0.1483906
[Epoch 102; Iter   743/ 1097] train: loss: 0.1862871
[Epoch 102; Iter   773/ 1097] train: loss: 0.1285752
[Epoch 102; Iter   803/ 1097] train: loss: 0.0046242
[Epoch 102; Iter   833/ 1097] train: loss: 0.0373784
[Epoch 102; Iter   863/ 1097] train: loss: 0.0031018
[Epoch 102; Iter   893/ 1097] train: loss: 0.1297693
[Epoch 102; Iter   923/ 1097] train: loss: 0.0081863
[Epoch 102; Iter   953/ 1097] train: loss: 0.0226249
[Epoch 102; Iter   983/ 1097] train: loss: 0.0278933
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0107377
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0536116
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0044556
[Epoch 102] ogbg-molhiv: 0.807570 val loss: 0.116037
[Epoch 102] ogbg-molhiv: 0.757902 test loss: 0.230934
[Epoch 103; Iter     6/ 1097] train: loss: 0.0136323
[Epoch 103; Iter    36/ 1097] train: loss: 0.0312858
[Epoch 103; Iter    66/ 1097] train: loss: 0.0015172
[Epoch 103; Iter    96/ 1097] train: loss: 0.0133986
[Epoch 103; Iter   126/ 1097] train: loss: 0.0170952
[Epoch 103; Iter   156/ 1097] train: loss: 0.0006750
[Epoch 103; Iter   186/ 1097] train: loss: 0.0011416
[Epoch 103; Iter   216/ 1097] train: loss: 0.0424868
[Epoch 103; Iter   246/ 1097] train: loss: 0.0018447
[Epoch 103; Iter   276/ 1097] train: loss: 0.0358228
[Epoch 103; Iter   306/ 1097] train: loss: 0.0299132
[Epoch 103; Iter   336/ 1097] train: loss: 0.0390640
[Epoch 103; Iter   366/ 1097] train: loss: 0.0576753
[Epoch 103; Iter   396/ 1097] train: loss: 0.0243345
[Epoch 103; Iter   426/ 1097] train: loss: 0.0013357
[Epoch 103; Iter   456/ 1097] train: loss: 0.0075803
[Epoch 103; Iter   486/ 1097] train: loss: 0.0918117
[Epoch 103; Iter   516/ 1097] train: loss: 0.1774398
[Epoch 103; Iter   546/ 1097] train: loss: 0.0530523
[Epoch 103; Iter   576/ 1097] train: loss: 0.0326180
[Epoch 103; Iter   606/ 1097] train: loss: 0.0240656
[Epoch 103; Iter   636/ 1097] train: loss: 0.0014121
[Epoch 103; Iter   666/ 1097] train: loss: 0.0047190
[Epoch 103; Iter   696/ 1097] train: loss: 0.0013788
[Epoch 103; Iter   726/ 1097] train: loss: 0.0061963
[Epoch 103; Iter   756/ 1097] train: loss: 0.0275754
[Epoch 103; Iter   786/ 1097] train: loss: 0.0922869
[Epoch 103; Iter   816/ 1097] train: loss: 0.0031476
[Epoch 103; Iter   846/ 1097] train: loss: 0.0461177
[Epoch 103; Iter   876/ 1097] train: loss: 0.0214181
[Epoch 103; Iter   906/ 1097] train: loss: 0.0025321
[Epoch 103; Iter   936/ 1097] train: loss: 0.0604911
[Epoch 103; Iter   966/ 1097] train: loss: 0.0120310
[Epoch 103; Iter   996/ 1097] train: loss: 0.1068632
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0022720
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0241323
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0293032
[Epoch 103] ogbg-molhiv: 0.806538 val loss: 0.128868
[Epoch 103] ogbg-molhiv: 0.744665 test loss: 0.255250
[Epoch 104; Iter    19/ 1097] train: loss: 0.0382177
[Epoch 104; Iter    49/ 1097] train: loss: 0.0179726
[Epoch 104; Iter    79/ 1097] train: loss: 0.0994952
[Epoch 104; Iter   109/ 1097] train: loss: 0.0063857
[Epoch 104; Iter   139/ 1097] train: loss: 0.0045515
[Epoch 104; Iter   169/ 1097] train: loss: 0.0041531
[Epoch 104; Iter   199/ 1097] train: loss: 0.0039937
[Epoch 104; Iter   229/ 1097] train: loss: 0.0712446
[Epoch 104; Iter   259/ 1097] train: loss: 0.0484218
[Epoch 104; Iter   289/ 1097] train: loss: 0.0109729
[Epoch 104; Iter   319/ 1097] train: loss: 0.0019132
[Epoch 104; Iter   349/ 1097] train: loss: 0.0038139
[Epoch 104; Iter   379/ 1097] train: loss: 0.0020120
[Epoch 104; Iter   409/ 1097] train: loss: 0.0074058
[Epoch 104; Iter   439/ 1097] train: loss: 0.0068000
[Epoch 104; Iter   469/ 1097] train: loss: 0.0481379
[Epoch 104; Iter   499/ 1097] train: loss: 0.0019290
[Epoch 104; Iter   529/ 1097] train: loss: 0.0157923
[Epoch 104; Iter   559/ 1097] train: loss: 0.0199198
[Epoch 104; Iter   589/ 1097] train: loss: 0.0591332
[Epoch 104; Iter   619/ 1097] train: loss: 0.0070855
[Epoch 104; Iter   649/ 1097] train: loss: 0.0071684
[Epoch 104; Iter   679/ 1097] train: loss: 0.0025012
[Epoch 104; Iter   709/ 1097] train: loss: 0.0064118
[Epoch 104; Iter   739/ 1097] train: loss: 0.0306657
[Epoch 104; Iter   769/ 1097] train: loss: 0.0037902
[Epoch 104; Iter   799/ 1097] train: loss: 0.0449085
[Epoch 104; Iter   829/ 1097] train: loss: 0.0052523
[Epoch 104; Iter   859/ 1097] train: loss: 0.0197552
[Epoch 104; Iter   889/ 1097] train: loss: 0.0184771
[Epoch 104; Iter   919/ 1097] train: loss: 0.0018984
[Epoch 104; Iter   949/ 1097] train: loss: 0.0018177
[Epoch 104; Iter   979/ 1097] train: loss: 0.0240715
[Epoch 104; Iter  1009/ 1097] train: loss: 0.4103391
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0080928
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0011096
[Epoch 104] ogbg-molhiv: 0.804882 val loss: 0.117064
[Epoch 104] ogbg-molhiv: 0.754601 test loss: 0.239675
[Epoch 105; Iter     2/ 1097] train: loss: 0.0889039
[Epoch 105; Iter    32/ 1097] train: loss: 0.0048033
[Epoch 105; Iter    62/ 1097] train: loss: 0.0145934
[Epoch 105; Iter    92/ 1097] train: loss: 0.1043041
[Epoch 105; Iter   122/ 1097] train: loss: 0.0412752
[Epoch 105; Iter   152/ 1097] train: loss: 0.0899531
[Epoch 105; Iter   182/ 1097] train: loss: 0.0015849
[Epoch 105; Iter   212/ 1097] train: loss: 0.0032171
[Epoch 105; Iter   242/ 1097] train: loss: 0.0048364
[Epoch 105; Iter   272/ 1097] train: loss: 0.0022628
[Epoch 105; Iter   302/ 1097] train: loss: 0.0892521
[Epoch 105; Iter   332/ 1097] train: loss: 0.0026653
[Epoch 105; Iter   362/ 1097] train: loss: 0.0076874
[Epoch 105; Iter   392/ 1097] train: loss: 0.0063429
[Epoch 105; Iter   422/ 1097] train: loss: 0.0012029
[Epoch 105; Iter   452/ 1097] train: loss: 0.0069758
[Epoch 105; Iter   482/ 1097] train: loss: 0.0012918
[Epoch 105; Iter   512/ 1097] train: loss: 0.0021987
[Epoch 105; Iter   542/ 1097] train: loss: 0.0548297
[Epoch 105; Iter   572/ 1097] train: loss: 0.0277883
[Epoch 105; Iter   602/ 1097] train: loss: 0.0259025
[Epoch 105; Iter   632/ 1097] train: loss: 0.0009103
[Epoch 105; Iter   662/ 1097] train: loss: 0.0217450
[Epoch 105; Iter   692/ 1097] train: loss: 0.0055482
[Epoch 101; Iter   730/ 1097] train: loss: 0.0120785
[Epoch 101; Iter   760/ 1097] train: loss: 0.0380971
[Epoch 101; Iter   790/ 1097] train: loss: 0.0015805
[Epoch 101; Iter   820/ 1097] train: loss: 0.0032609
[Epoch 101; Iter   850/ 1097] train: loss: 0.0084789
[Epoch 101; Iter   880/ 1097] train: loss: 0.0025814
[Epoch 101; Iter   910/ 1097] train: loss: 0.0012400
[Epoch 101; Iter   940/ 1097] train: loss: 0.0046862
[Epoch 101; Iter   970/ 1097] train: loss: 0.0163462
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0480780
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0017753
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0008604
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0015709
[Epoch 101] ogbg-molhiv: 0.781654 val loss: 0.148428
[Epoch 101] ogbg-molhiv: 0.745994 test loss: 0.278969
[Epoch 102; Iter    23/ 1097] train: loss: 0.0054329
[Epoch 102; Iter    53/ 1097] train: loss: 0.0213266
[Epoch 102; Iter    83/ 1097] train: loss: 0.0159736
[Epoch 102; Iter   113/ 1097] train: loss: 0.1473678
[Epoch 102; Iter   143/ 1097] train: loss: 0.0027549
[Epoch 102; Iter   173/ 1097] train: loss: 0.0021650
[Epoch 102; Iter   203/ 1097] train: loss: 0.0027801
[Epoch 102; Iter   233/ 1097] train: loss: 0.0024458
[Epoch 102; Iter   263/ 1097] train: loss: 0.0013499
[Epoch 102; Iter   293/ 1097] train: loss: 0.0028285
[Epoch 102; Iter   323/ 1097] train: loss: 0.0062500
[Epoch 102; Iter   353/ 1097] train: loss: 0.0101670
[Epoch 102; Iter   383/ 1097] train: loss: 0.0063678
[Epoch 102; Iter   413/ 1097] train: loss: 0.0052370
[Epoch 102; Iter   443/ 1097] train: loss: 0.0004386
[Epoch 102; Iter   473/ 1097] train: loss: 0.0038302
[Epoch 102; Iter   503/ 1097] train: loss: 0.0031656
[Epoch 102; Iter   533/ 1097] train: loss: 0.0021723
[Epoch 102; Iter   563/ 1097] train: loss: 0.0162618
[Epoch 102; Iter   593/ 1097] train: loss: 0.0043779
[Epoch 102; Iter   623/ 1097] train: loss: 0.0103663
[Epoch 102; Iter   653/ 1097] train: loss: 0.0481986
[Epoch 102; Iter   683/ 1097] train: loss: 0.0012112
[Epoch 102; Iter   713/ 1097] train: loss: 0.0000823
[Epoch 102; Iter   743/ 1097] train: loss: 0.0245590
[Epoch 102; Iter   773/ 1097] train: loss: 0.0024784
[Epoch 102; Iter   803/ 1097] train: loss: 0.0010276
[Epoch 102; Iter   833/ 1097] train: loss: 0.0008283
[Epoch 102; Iter   863/ 1097] train: loss: 0.0003014
[Epoch 102; Iter   893/ 1097] train: loss: 0.0106353
[Epoch 102; Iter   923/ 1097] train: loss: 0.0132410
[Epoch 102; Iter   953/ 1097] train: loss: 0.0086325
[Epoch 102; Iter   983/ 1097] train: loss: 0.0135255
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0006207
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0134362
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0203248
[Epoch 102] ogbg-molhiv: 0.769703 val loss: 0.146597
[Epoch 102] ogbg-molhiv: 0.740462 test loss: 0.279473
[Epoch 103; Iter     6/ 1097] train: loss: 0.0007769
[Epoch 103; Iter    36/ 1097] train: loss: 0.0161949
[Epoch 103; Iter    66/ 1097] train: loss: 0.0009095
[Epoch 103; Iter    96/ 1097] train: loss: 0.0005685
[Epoch 103; Iter   126/ 1097] train: loss: 0.0042124
[Epoch 103; Iter   156/ 1097] train: loss: 0.0115215
[Epoch 103; Iter   186/ 1097] train: loss: 0.0013183
[Epoch 103; Iter   216/ 1097] train: loss: 0.0676760
[Epoch 103; Iter   246/ 1097] train: loss: 0.0004459
[Epoch 103; Iter   276/ 1097] train: loss: 0.0184389
[Epoch 103; Iter   306/ 1097] train: loss: 0.0223259
[Epoch 103; Iter   336/ 1097] train: loss: 0.0964358
[Epoch 103; Iter   366/ 1097] train: loss: 0.0237318
[Epoch 103; Iter   396/ 1097] train: loss: 0.0173112
[Epoch 103; Iter   426/ 1097] train: loss: 0.0021012
[Epoch 103; Iter   456/ 1097] train: loss: 0.0044110
[Epoch 103; Iter   486/ 1097] train: loss: 0.0022345
[Epoch 103; Iter   516/ 1097] train: loss: 0.0287203
[Epoch 103; Iter   546/ 1097] train: loss: 0.0010463
[Epoch 103; Iter   576/ 1097] train: loss: 0.0010394
[Epoch 103; Iter   606/ 1097] train: loss: 0.0053636
[Epoch 103; Iter   636/ 1097] train: loss: 0.0073859
[Epoch 103; Iter   666/ 1097] train: loss: 0.0055048
[Epoch 103; Iter   696/ 1097] train: loss: 0.0043255
[Epoch 103; Iter   726/ 1097] train: loss: 0.0056515
[Epoch 103; Iter   756/ 1097] train: loss: 0.0003066
[Epoch 103; Iter   786/ 1097] train: loss: 0.0023102
[Epoch 103; Iter   816/ 1097] train: loss: 0.0020676
[Epoch 103; Iter   846/ 1097] train: loss: 0.0040955
[Epoch 103; Iter   876/ 1097] train: loss: 0.0090491
[Epoch 103; Iter   906/ 1097] train: loss: 0.0034346
[Epoch 103; Iter   936/ 1097] train: loss: 0.0298380
[Epoch 103; Iter   966/ 1097] train: loss: 0.0837001
[Epoch 103; Iter   996/ 1097] train: loss: 0.0018716
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0054247
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0035850
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0824934
[Epoch 103] ogbg-molhiv: 0.769685 val loss: 0.153093
[Epoch 103] ogbg-molhiv: 0.746104 test loss: 0.260907
[Epoch 104; Iter    19/ 1097] train: loss: 0.0187100
[Epoch 104; Iter    49/ 1097] train: loss: 0.0036781
[Epoch 104; Iter    79/ 1097] train: loss: 0.0134359
[Epoch 104; Iter   109/ 1097] train: loss: 0.0057530
[Epoch 104; Iter   139/ 1097] train: loss: 0.0010188
[Epoch 104; Iter   169/ 1097] train: loss: 0.0199816
[Epoch 104; Iter   199/ 1097] train: loss: 0.0010972
[Epoch 104; Iter   229/ 1097] train: loss: 0.0431619
[Epoch 104; Iter   259/ 1097] train: loss: 0.1067533
[Epoch 104; Iter   289/ 1097] train: loss: 0.0317098
[Epoch 104; Iter   319/ 1097] train: loss: 0.0080906
[Epoch 104; Iter   349/ 1097] train: loss: 0.0033749
[Epoch 104; Iter   379/ 1097] train: loss: 0.0002645
[Epoch 104; Iter   409/ 1097] train: loss: 0.0179089
[Epoch 104; Iter   439/ 1097] train: loss: 0.0028117
[Epoch 104; Iter   469/ 1097] train: loss: 0.0089768
[Epoch 104; Iter   499/ 1097] train: loss: 0.0060757
[Epoch 104; Iter   529/ 1097] train: loss: 0.0035604
[Epoch 104; Iter   559/ 1097] train: loss: 0.0189687
[Epoch 104; Iter   589/ 1097] train: loss: 0.0007638
[Epoch 104; Iter   619/ 1097] train: loss: 0.0641622
[Epoch 104; Iter   649/ 1097] train: loss: 0.0392608
[Epoch 104; Iter   679/ 1097] train: loss: 0.0040972
[Epoch 104; Iter   709/ 1097] train: loss: 0.0016700
[Epoch 104; Iter   739/ 1097] train: loss: 0.0001244
[Epoch 104; Iter   769/ 1097] train: loss: 0.0081427
[Epoch 104; Iter   799/ 1097] train: loss: 0.0097454
[Epoch 104; Iter   829/ 1097] train: loss: 0.0063776
[Epoch 104; Iter   859/ 1097] train: loss: 0.0002435
[Epoch 104; Iter   889/ 1097] train: loss: 0.0179784
[Epoch 104; Iter   919/ 1097] train: loss: 0.0009598
[Epoch 104; Iter   949/ 1097] train: loss: 0.0004695
[Epoch 104; Iter   979/ 1097] train: loss: 0.0039880
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0020089
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0082860
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0020588
[Epoch 104] ogbg-molhiv: 0.775720 val loss: 0.153863
[Epoch 104] ogbg-molhiv: 0.750022 test loss: 0.267197
[Epoch 105; Iter     2/ 1097] train: loss: 0.0297333
[Epoch 105; Iter    32/ 1097] train: loss: 0.0052835
[Epoch 105; Iter    62/ 1097] train: loss: 0.0020003
[Epoch 105; Iter    92/ 1097] train: loss: 0.0066615
[Epoch 105; Iter   122/ 1097] train: loss: 0.0008704
[Epoch 105; Iter   152/ 1097] train: loss: 0.0011498
[Epoch 105; Iter   182/ 1097] train: loss: 0.0021724
[Epoch 105; Iter   212/ 1097] train: loss: 0.0351699
[Epoch 105; Iter   242/ 1097] train: loss: 0.0027687
[Epoch 105; Iter   272/ 1097] train: loss: 0.0008942
[Epoch 105; Iter   302/ 1097] train: loss: 0.0104782
[Epoch 105; Iter   332/ 1097] train: loss: 0.0236434
[Epoch 105; Iter   362/ 1097] train: loss: 0.0007274
[Epoch 105; Iter   392/ 1097] train: loss: 0.0009418
[Epoch 105; Iter   422/ 1097] train: loss: 0.0019157
[Epoch 105; Iter   452/ 1097] train: loss: 0.0004961
[Epoch 105; Iter   482/ 1097] train: loss: 0.0977263
[Epoch 105; Iter   512/ 1097] train: loss: 0.0067217
[Epoch 105; Iter   542/ 1097] train: loss: 0.0226319
[Epoch 105; Iter   572/ 1097] train: loss: 0.0005221
[Epoch 105; Iter   602/ 1097] train: loss: 0.0130939
[Epoch 105; Iter   632/ 1097] train: loss: 0.0582845
[Epoch 105; Iter   662/ 1097] train: loss: 0.0411920
[Epoch 105; Iter   692/ 1097] train: loss: 0.0069775
[Epoch 105; Iter   722/ 1097] train: loss: 0.0056164
[Epoch 105; Iter   752/ 1097] train: loss: 0.0043396
[Epoch 105; Iter   782/ 1097] train: loss: 0.0099696
[Epoch 105; Iter   812/ 1097] train: loss: 0.0016362
[Epoch 105; Iter   842/ 1097] train: loss: 0.0011898
[Epoch 105; Iter   872/ 1097] train: loss: 0.0122348
[Epoch 105; Iter   902/ 1097] train: loss: 0.0022973
[Epoch 105; Iter   932/ 1097] train: loss: 0.1335115
[Epoch 105; Iter   962/ 1097] train: loss: 0.0154639
[Epoch 105; Iter   992/ 1097] train: loss: 0.0412837
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0200124
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0113443
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0029371
[Epoch 105] ogbg-molhiv: 0.811419 val loss: 0.138336
[Epoch 105] ogbg-molhiv: 0.751689 test loss: 0.257496
[Epoch 106; Iter    15/ 1097] train: loss: 0.0028758
[Epoch 106; Iter    45/ 1097] train: loss: 0.0069060
[Epoch 106; Iter    75/ 1097] train: loss: 0.0005166
[Epoch 106; Iter   105/ 1097] train: loss: 0.0025706
[Epoch 106; Iter   135/ 1097] train: loss: 0.0072664
[Epoch 106; Iter   165/ 1097] train: loss: 0.0046787
[Epoch 106; Iter   195/ 1097] train: loss: 0.0112752
[Epoch 106; Iter   225/ 1097] train: loss: 0.0100754
[Epoch 106; Iter   255/ 1097] train: loss: 0.0046853
[Epoch 106; Iter   285/ 1097] train: loss: 0.0046102
[Epoch 106; Iter   315/ 1097] train: loss: 0.0725177
[Epoch 106; Iter   345/ 1097] train: loss: 0.0010872
[Epoch 106; Iter   375/ 1097] train: loss: 0.0119139
[Epoch 106; Iter   405/ 1097] train: loss: 0.0402081
[Epoch 106; Iter   435/ 1097] train: loss: 0.0011298
[Epoch 106; Iter   465/ 1097] train: loss: 0.0059348
[Epoch 106; Iter   495/ 1097] train: loss: 0.1223495
[Epoch 106; Iter   525/ 1097] train: loss: 0.0166023
[Epoch 106; Iter   555/ 1097] train: loss: 0.0275223
[Epoch 106; Iter   585/ 1097] train: loss: 0.0228488
[Epoch 106; Iter   615/ 1097] train: loss: 0.0337665
[Epoch 106; Iter   645/ 1097] train: loss: 0.0010900
[Epoch 106; Iter   675/ 1097] train: loss: 0.0139186
[Epoch 106; Iter   705/ 1097] train: loss: 0.0044134
[Epoch 106; Iter   735/ 1097] train: loss: 0.0036913
[Epoch 106; Iter   765/ 1097] train: loss: 0.0023777
[Epoch 106; Iter   795/ 1097] train: loss: 0.0158090
[Epoch 106; Iter   825/ 1097] train: loss: 0.0023510
[Epoch 106; Iter   855/ 1097] train: loss: 0.0274969
[Epoch 106; Iter   885/ 1097] train: loss: 0.0242636
[Epoch 106; Iter   915/ 1097] train: loss: 0.0006019
[Epoch 106; Iter   945/ 1097] train: loss: 0.0014729
[Epoch 106; Iter   975/ 1097] train: loss: 0.0112048
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0227294
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0040520
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0016937
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0033382
[Epoch 106] ogbg-molhiv: 0.811863 val loss: 0.137835
[Epoch 106] ogbg-molhiv: 0.749433 test loss: 0.260974
[Epoch 107; Iter    28/ 1097] train: loss: 0.0456849
[Epoch 107; Iter    58/ 1097] train: loss: 0.0070835
[Epoch 107; Iter    88/ 1097] train: loss: 0.0250008
[Epoch 107; Iter   118/ 1097] train: loss: 0.0007691
[Epoch 107; Iter   148/ 1097] train: loss: 0.0381305
[Epoch 107; Iter   178/ 1097] train: loss: 0.0101604
[Epoch 107; Iter   208/ 1097] train: loss: 0.1888786
[Epoch 107; Iter   238/ 1097] train: loss: 0.0083902
[Epoch 107; Iter   268/ 1097] train: loss: 0.0298155
[Epoch 107; Iter   298/ 1097] train: loss: 0.0020197
[Epoch 107; Iter   328/ 1097] train: loss: 0.0702976
[Epoch 107; Iter   358/ 1097] train: loss: 0.0194700
[Epoch 107; Iter   388/ 1097] train: loss: 0.0043140
[Epoch 107; Iter   418/ 1097] train: loss: 0.0462009
[Epoch 107; Iter   448/ 1097] train: loss: 0.0400915
[Epoch 107; Iter   478/ 1097] train: loss: 0.0728399
[Epoch 107; Iter   508/ 1097] train: loss: 0.0025352
[Epoch 107; Iter   538/ 1097] train: loss: 0.0035641
[Epoch 107; Iter   568/ 1097] train: loss: 0.0117996
[Epoch 107; Iter   598/ 1097] train: loss: 0.0170841
[Epoch 107; Iter   628/ 1097] train: loss: 0.0018066
[Epoch 107; Iter   658/ 1097] train: loss: 0.0019471
[Epoch 107; Iter   688/ 1097] train: loss: 0.0040055
[Epoch 107; Iter   718/ 1097] train: loss: 0.0025013
[Epoch 107; Iter   748/ 1097] train: loss: 0.0060002
[Epoch 107; Iter   778/ 1097] train: loss: 0.0141397
[Epoch 107; Iter   808/ 1097] train: loss: 0.0071251
[Epoch 107; Iter   838/ 1097] train: loss: 0.0026079
[Epoch 107; Iter   868/ 1097] train: loss: 0.0249618
[Epoch 107; Iter   898/ 1097] train: loss: 0.0039642
[Epoch 107; Iter   928/ 1097] train: loss: 0.0057378
[Epoch 107; Iter   958/ 1097] train: loss: 0.0057879
[Epoch 107; Iter   988/ 1097] train: loss: 0.0449283
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0019900
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0026093
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0235295
[Epoch 107] ogbg-molhiv: 0.812727 val loss: 0.139716
[Epoch 107] ogbg-molhiv: 0.752062 test loss: 0.259810
[Epoch 108; Iter    11/ 1097] train: loss: 0.0070354
[Epoch 108; Iter    41/ 1097] train: loss: 0.0157993
[Epoch 108; Iter    71/ 1097] train: loss: 0.0033335
[Epoch 108; Iter   101/ 1097] train: loss: 0.0183169
[Epoch 108; Iter   131/ 1097] train: loss: 0.0021813
[Epoch 108; Iter   161/ 1097] train: loss: 0.0610682
[Epoch 108; Iter   191/ 1097] train: loss: 0.0009347
[Epoch 108; Iter   221/ 1097] train: loss: 0.0319324
[Epoch 108; Iter   251/ 1097] train: loss: 0.0482937
[Epoch 108; Iter   281/ 1097] train: loss: 0.1319950
[Epoch 108; Iter   311/ 1097] train: loss: 0.0160966
[Epoch 108; Iter   341/ 1097] train: loss: 0.0122805
[Epoch 108; Iter   371/ 1097] train: loss: 0.0035740
[Epoch 108; Iter   401/ 1097] train: loss: 0.0105286
[Epoch 108; Iter   431/ 1097] train: loss: 0.0059529
[Epoch 108; Iter   461/ 1097] train: loss: 0.0032937
[Epoch 108; Iter   491/ 1097] train: loss: 0.0516004
[Epoch 108; Iter   521/ 1097] train: loss: 0.0020707
[Epoch 108; Iter   551/ 1097] train: loss: 0.0036858
[Epoch 108; Iter   581/ 1097] train: loss: 0.0039757
[Epoch 108; Iter   611/ 1097] train: loss: 0.0043390
[Epoch 108; Iter   641/ 1097] train: loss: 0.0139458
[Epoch 108; Iter   671/ 1097] train: loss: 0.0069506
[Epoch 108; Iter   701/ 1097] train: loss: 0.0088407
[Epoch 108; Iter   731/ 1097] train: loss: 0.0537619
[Epoch 108; Iter   761/ 1097] train: loss: 0.0004188
[Epoch 108; Iter   791/ 1097] train: loss: 0.0081288
[Epoch 108; Iter   821/ 1097] train: loss: 0.0011510
[Epoch 108; Iter   851/ 1097] train: loss: 0.0075231
[Epoch 108; Iter   881/ 1097] train: loss: 0.0212522
[Epoch 108; Iter   911/ 1097] train: loss: 0.0050475
[Epoch 108; Iter   941/ 1097] train: loss: 0.0129393
[Epoch 108; Iter   971/ 1097] train: loss: 0.0032154
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0280544
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0072672
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0073491
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0597868
[Epoch 108] ogbg-molhiv: 0.816263 val loss: 0.134784
[Epoch 108] ogbg-molhiv: 0.746206 test loss: 0.259686
[Epoch 109; Iter    24/ 1097] train: loss: 0.0056603
[Epoch 109; Iter    54/ 1097] train: loss: 0.0017383
[Epoch 109; Iter    84/ 1097] train: loss: 0.0899196
[Epoch 109; Iter   114/ 1097] train: loss: 0.0024940
[Epoch 109; Iter   144/ 1097] train: loss: 0.0049758
[Epoch 109; Iter   174/ 1097] train: loss: 0.0009335
[Epoch 109; Iter   204/ 1097] train: loss: 0.0675658
[Epoch 109; Iter   234/ 1097] train: loss: 0.0034783
[Epoch 109; Iter   264/ 1097] train: loss: 0.0022177
[Epoch 109; Iter   294/ 1097] train: loss: 0.0145374
[Epoch 109; Iter   324/ 1097] train: loss: 0.0274301
[Epoch 109; Iter   354/ 1097] train: loss: 0.0017369
[Epoch 109; Iter   384/ 1097] train: loss: 0.0286282
[Epoch 109; Iter   414/ 1097] train: loss: 0.0031098
[Epoch 109; Iter   444/ 1097] train: loss: 0.0010801
[Epoch 109; Iter   474/ 1097] train: loss: 0.0008123
[Epoch 109; Iter   504/ 1097] train: loss: 0.0166211
[Epoch 109; Iter   534/ 1097] train: loss: 0.0190356
[Epoch 109; Iter   564/ 1097] train: loss: 0.0064090
[Epoch 109; Iter   594/ 1097] train: loss: 0.0268324
[Epoch 109; Iter   624/ 1097] train: loss: 0.0003291
[Epoch 109; Iter   654/ 1097] train: loss: 0.0166507
[Epoch 109; Iter   684/ 1097] train: loss: 0.0009978
[Epoch 105; Iter   722/ 1097] train: loss: 0.0143849
[Epoch 105; Iter   752/ 1097] train: loss: 0.0131116
[Epoch 105; Iter   782/ 1097] train: loss: 0.0973022
[Epoch 105; Iter   812/ 1097] train: loss: 0.0418831
[Epoch 105; Iter   842/ 1097] train: loss: 0.0098026
[Epoch 105; Iter   872/ 1097] train: loss: 0.0118517
[Epoch 105; Iter   902/ 1097] train: loss: 0.0128186
[Epoch 105; Iter   932/ 1097] train: loss: 0.0054369
[Epoch 105; Iter   962/ 1097] train: loss: 0.1051091
[Epoch 105; Iter   992/ 1097] train: loss: 0.0326836
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0023673
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0079580
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0114638
[Epoch 105] ogbg-molhiv: 0.805084 val loss: 0.126829
[Epoch 105] ogbg-molhiv: 0.748975 test loss: 0.247254
[Epoch 106; Iter    15/ 1097] train: loss: 0.0021819
[Epoch 106; Iter    45/ 1097] train: loss: 0.0051676
[Epoch 106; Iter    75/ 1097] train: loss: 0.0026866
[Epoch 106; Iter   105/ 1097] train: loss: 0.0562669
[Epoch 106; Iter   135/ 1097] train: loss: 0.0521937
[Epoch 106; Iter   165/ 1097] train: loss: 0.0018471
[Epoch 106; Iter   195/ 1097] train: loss: 0.0030354
[Epoch 106; Iter   225/ 1097] train: loss: 0.0020691
[Epoch 106; Iter   255/ 1097] train: loss: 0.0324840
[Epoch 106; Iter   285/ 1097] train: loss: 0.0013063
[Epoch 106; Iter   315/ 1097] train: loss: 0.0073340
[Epoch 106; Iter   345/ 1097] train: loss: 0.0552014
[Epoch 106; Iter   375/ 1097] train: loss: 0.0120934
[Epoch 106; Iter   405/ 1097] train: loss: 0.0062789
[Epoch 106; Iter   435/ 1097] train: loss: 0.0199149
[Epoch 106; Iter   465/ 1097] train: loss: 0.0055558
[Epoch 106; Iter   495/ 1097] train: loss: 0.0050937
[Epoch 106; Iter   525/ 1097] train: loss: 0.0050091
[Epoch 106; Iter   555/ 1097] train: loss: 0.0107870
[Epoch 106; Iter   585/ 1097] train: loss: 0.0242306
[Epoch 106; Iter   615/ 1097] train: loss: 0.1230718
[Epoch 106; Iter   645/ 1097] train: loss: 0.0634788
[Epoch 106; Iter   675/ 1097] train: loss: 0.0039069
[Epoch 106; Iter   705/ 1097] train: loss: 0.0197719
[Epoch 106; Iter   735/ 1097] train: loss: 0.1213781
[Epoch 106; Iter   765/ 1097] train: loss: 0.0178141
[Epoch 106; Iter   795/ 1097] train: loss: 0.0376663
[Epoch 106; Iter   825/ 1097] train: loss: 0.0194266
[Epoch 106; Iter   855/ 1097] train: loss: 0.0128645
[Epoch 106; Iter   885/ 1097] train: loss: 0.0025821
[Epoch 106; Iter   915/ 1097] train: loss: 0.0034970
[Epoch 106; Iter   945/ 1097] train: loss: 0.0178290
[Epoch 106; Iter   975/ 1097] train: loss: 0.0117875
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0263426
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0114499
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0086655
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0148232
[Epoch 106] ogbg-molhiv: 0.800335 val loss: 0.122751
[Epoch 106] ogbg-molhiv: 0.764831 test loss: 0.236692
[Epoch 107; Iter    28/ 1097] train: loss: 0.0701227
[Epoch 107; Iter    58/ 1097] train: loss: 0.0030191
[Epoch 107; Iter    88/ 1097] train: loss: 0.0086316
[Epoch 107; Iter   118/ 1097] train: loss: 0.0150822
[Epoch 107; Iter   148/ 1097] train: loss: 0.0200492
[Epoch 107; Iter   178/ 1097] train: loss: 0.0040708
[Epoch 107; Iter   208/ 1097] train: loss: 0.0056808
[Epoch 107; Iter   238/ 1097] train: loss: 0.0034021
[Epoch 107; Iter   268/ 1097] train: loss: 0.0155370
[Epoch 107; Iter   298/ 1097] train: loss: 0.0031198
[Epoch 107; Iter   328/ 1097] train: loss: 0.0146222
[Epoch 107; Iter   358/ 1097] train: loss: 0.0045768
[Epoch 107; Iter   388/ 1097] train: loss: 0.0136905
[Epoch 107; Iter   418/ 1097] train: loss: 0.0499041
[Epoch 107; Iter   448/ 1097] train: loss: 0.0067657
[Epoch 107; Iter   478/ 1097] train: loss: 0.0040114
[Epoch 107; Iter   508/ 1097] train: loss: 0.0029272
[Epoch 107; Iter   538/ 1097] train: loss: 0.0081060
[Epoch 107; Iter   568/ 1097] train: loss: 0.0108775
[Epoch 107; Iter   598/ 1097] train: loss: 0.0176942
[Epoch 107; Iter   628/ 1097] train: loss: 0.0016400
[Epoch 107; Iter   658/ 1097] train: loss: 0.0146786
[Epoch 107; Iter   688/ 1097] train: loss: 0.0087786
[Epoch 107; Iter   718/ 1097] train: loss: 0.2861870
[Epoch 107; Iter   748/ 1097] train: loss: 0.0186020
[Epoch 107; Iter   778/ 1097] train: loss: 0.0016369
[Epoch 107; Iter   808/ 1097] train: loss: 0.0348367
[Epoch 107; Iter   838/ 1097] train: loss: 0.0092897
[Epoch 107; Iter   868/ 1097] train: loss: 0.0051362
[Epoch 107; Iter   898/ 1097] train: loss: 0.0077034
[Epoch 107; Iter   928/ 1097] train: loss: 0.0835680
[Epoch 107; Iter   958/ 1097] train: loss: 0.0111797
[Epoch 107; Iter   988/ 1097] train: loss: 0.0242030
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0326291
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0265581
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0029333
[Epoch 107] ogbg-molhiv: 0.803085 val loss: 0.121395
[Epoch 107] ogbg-molhiv: 0.756403 test loss: 0.249633
[Epoch 108; Iter    11/ 1097] train: loss: 0.0381238
[Epoch 108; Iter    41/ 1097] train: loss: 0.0594624
[Epoch 108; Iter    71/ 1097] train: loss: 0.0082806
[Epoch 108; Iter   101/ 1097] train: loss: 0.0506632
[Epoch 108; Iter   131/ 1097] train: loss: 0.0035514
[Epoch 108; Iter   161/ 1097] train: loss: 0.0131270
[Epoch 108; Iter   191/ 1097] train: loss: 0.0404495
[Epoch 108; Iter   221/ 1097] train: loss: 0.0508150
[Epoch 108; Iter   251/ 1097] train: loss: 0.0159709
[Epoch 108; Iter   281/ 1097] train: loss: 0.0039379
[Epoch 108; Iter   311/ 1097] train: loss: 0.0254163
[Epoch 108; Iter   341/ 1097] train: loss: 0.0108563
[Epoch 108; Iter   371/ 1097] train: loss: 0.0120962
[Epoch 108; Iter   401/ 1097] train: loss: 0.0116894
[Epoch 108; Iter   431/ 1097] train: loss: 0.0139719
[Epoch 108; Iter   461/ 1097] train: loss: 0.0097849
[Epoch 108; Iter   491/ 1097] train: loss: 0.0088000
[Epoch 108; Iter   521/ 1097] train: loss: 0.0047662
[Epoch 108; Iter   551/ 1097] train: loss: 0.0145045
[Epoch 108; Iter   581/ 1097] train: loss: 0.0076083
[Epoch 108; Iter   611/ 1097] train: loss: 0.0005083
[Epoch 108; Iter   641/ 1097] train: loss: 0.0104652
[Epoch 108; Iter   671/ 1097] train: loss: 0.0015075
[Epoch 108; Iter   701/ 1097] train: loss: 0.1029102
[Epoch 108; Iter   731/ 1097] train: loss: 0.0107592
[Epoch 108; Iter   761/ 1097] train: loss: 0.0003725
[Epoch 108; Iter   791/ 1097] train: loss: 0.0007445
[Epoch 108; Iter   821/ 1097] train: loss: 0.0014202
[Epoch 108; Iter   851/ 1097] train: loss: 0.0028578
[Epoch 108; Iter   881/ 1097] train: loss: 0.0118508
[Epoch 108; Iter   911/ 1097] train: loss: 0.0143149
[Epoch 108; Iter   941/ 1097] train: loss: 0.0030448
[Epoch 108; Iter   971/ 1097] train: loss: 0.0025040
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0104630
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0548676
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0761513
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0171911
[Epoch 108] ogbg-molhiv: 0.807053 val loss: 0.119492
[Epoch 108] ogbg-molhiv: 0.752554 test loss: 0.259085
[Epoch 109; Iter    24/ 1097] train: loss: 0.0376105
[Epoch 109; Iter    54/ 1097] train: loss: 0.0006501
[Epoch 109; Iter    84/ 1097] train: loss: 0.0073464
[Epoch 109; Iter   114/ 1097] train: loss: 0.0007864
[Epoch 109; Iter   144/ 1097] train: loss: 0.0011540
[Epoch 109; Iter   174/ 1097] train: loss: 0.0007337
[Epoch 109; Iter   204/ 1097] train: loss: 0.0219815
[Epoch 109; Iter   234/ 1097] train: loss: 0.0065063
[Epoch 109; Iter   264/ 1097] train: loss: 0.0034953
[Epoch 109; Iter   294/ 1097] train: loss: 0.0022719
[Epoch 109; Iter   324/ 1097] train: loss: 0.0085134
[Epoch 109; Iter   354/ 1097] train: loss: 0.0082493
[Epoch 109; Iter   384/ 1097] train: loss: 0.0006819
[Epoch 109; Iter   414/ 1097] train: loss: 0.0124435
[Epoch 109; Iter   444/ 1097] train: loss: 0.0091474
[Epoch 109; Iter   474/ 1097] train: loss: 0.0074825
[Epoch 109; Iter   504/ 1097] train: loss: 0.0187209
[Epoch 109; Iter   534/ 1097] train: loss: 0.0296695
[Epoch 109; Iter   564/ 1097] train: loss: 0.0004477
[Epoch 109; Iter   594/ 1097] train: loss: 0.0899717
[Epoch 109; Iter   624/ 1097] train: loss: 0.0047212
[Epoch 109; Iter   654/ 1097] train: loss: 0.0228825
[Epoch 109; Iter   684/ 1097] train: loss: 0.0058238
[Epoch 105; Iter   722/ 1097] train: loss: 0.0120415
[Epoch 105; Iter   752/ 1097] train: loss: 0.0135156
[Epoch 105; Iter   782/ 1097] train: loss: 0.0098215
[Epoch 105; Iter   812/ 1097] train: loss: 0.0006143
[Epoch 105; Iter   842/ 1097] train: loss: 0.0040467
[Epoch 105; Iter   872/ 1097] train: loss: 0.0192395
[Epoch 105; Iter   902/ 1097] train: loss: 0.0012628
[Epoch 105; Iter   932/ 1097] train: loss: 0.1118499
[Epoch 105; Iter   962/ 1097] train: loss: 0.0104512
[Epoch 105; Iter   992/ 1097] train: loss: 0.0068833
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0111387
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0158489
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0004706
[Epoch 105] ogbg-molhiv: 0.777570 val loss: 0.159525
[Epoch 105] ogbg-molhiv: 0.738888 test loss: 0.285920
[Epoch 106; Iter    15/ 1097] train: loss: 0.0020293
[Epoch 106; Iter    45/ 1097] train: loss: 0.0047133
[Epoch 106; Iter    75/ 1097] train: loss: 0.0607932
[Epoch 106; Iter   105/ 1097] train: loss: 0.0018884
[Epoch 106; Iter   135/ 1097] train: loss: 0.0098984
[Epoch 106; Iter   165/ 1097] train: loss: 0.0015843
[Epoch 106; Iter   195/ 1097] train: loss: 0.0296800
[Epoch 106; Iter   225/ 1097] train: loss: 0.0107192
[Epoch 106; Iter   255/ 1097] train: loss: 0.0086482
[Epoch 106; Iter   285/ 1097] train: loss: 0.0104712
[Epoch 106; Iter   315/ 1097] train: loss: 0.0046802
[Epoch 106; Iter   345/ 1097] train: loss: 0.0034561
[Epoch 106; Iter   375/ 1097] train: loss: 0.0008848
[Epoch 106; Iter   405/ 1097] train: loss: 0.0150459
[Epoch 106; Iter   435/ 1097] train: loss: 0.0337631
[Epoch 106; Iter   465/ 1097] train: loss: 0.0241907
[Epoch 106; Iter   495/ 1097] train: loss: 0.0006291
[Epoch 106; Iter   525/ 1097] train: loss: 0.0005538
[Epoch 106; Iter   555/ 1097] train: loss: 0.0011264
[Epoch 106; Iter   585/ 1097] train: loss: 0.0011665
[Epoch 106; Iter   615/ 1097] train: loss: 0.0013347
[Epoch 106; Iter   645/ 1097] train: loss: 0.0026782
[Epoch 106; Iter   675/ 1097] train: loss: 0.0023775
[Epoch 106; Iter   705/ 1097] train: loss: 0.0010123
[Epoch 106; Iter   735/ 1097] train: loss: 0.0010779
[Epoch 106; Iter   765/ 1097] train: loss: 0.0536249
[Epoch 106; Iter   795/ 1097] train: loss: 0.0923004
[Epoch 106; Iter   825/ 1097] train: loss: 0.0047771
[Epoch 106; Iter   855/ 1097] train: loss: 0.1671821
[Epoch 106; Iter   885/ 1097] train: loss: 0.0134500
[Epoch 106; Iter   915/ 1097] train: loss: 0.0008032
[Epoch 106; Iter   945/ 1097] train: loss: 0.0030786
[Epoch 106; Iter   975/ 1097] train: loss: 0.0113960
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0008065
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0062781
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0048697
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0019591
[Epoch 106] ogbg-molhiv: 0.776565 val loss: 0.151706
[Epoch 106] ogbg-molhiv: 0.748576 test loss: 0.272308
[Epoch 107; Iter    28/ 1097] train: loss: 0.0271082
[Epoch 107; Iter    58/ 1097] train: loss: 0.0290261
[Epoch 107; Iter    88/ 1097] train: loss: 0.0311373
[Epoch 107; Iter   118/ 1097] train: loss: 0.0105314
[Epoch 107; Iter   148/ 1097] train: loss: 0.0091154
[Epoch 107; Iter   178/ 1097] train: loss: 0.0017458
[Epoch 107; Iter   208/ 1097] train: loss: 0.0020140
[Epoch 107; Iter   238/ 1097] train: loss: 0.1135318
[Epoch 107; Iter   268/ 1097] train: loss: 0.0107524
[Epoch 107; Iter   298/ 1097] train: loss: 0.0003208
[Epoch 107; Iter   328/ 1097] train: loss: 0.0006761
[Epoch 107; Iter   358/ 1097] train: loss: 0.0041182
[Epoch 107; Iter   388/ 1097] train: loss: 0.0077180
[Epoch 107; Iter   418/ 1097] train: loss: 0.0056557
[Epoch 107; Iter   448/ 1097] train: loss: 0.0363478
[Epoch 107; Iter   478/ 1097] train: loss: 0.0019391
[Epoch 107; Iter   508/ 1097] train: loss: 0.0016833
[Epoch 107; Iter   538/ 1097] train: loss: 0.0033376
[Epoch 107; Iter   568/ 1097] train: loss: 0.0002134
[Epoch 107; Iter   598/ 1097] train: loss: 0.0101870
[Epoch 107; Iter   628/ 1097] train: loss: 0.0005945
[Epoch 107; Iter   658/ 1097] train: loss: 0.0225043
[Epoch 107; Iter   688/ 1097] train: loss: 0.0015075
[Epoch 107; Iter   718/ 1097] train: loss: 0.0072285
[Epoch 107; Iter   748/ 1097] train: loss: 0.0259429
[Epoch 107; Iter   778/ 1097] train: loss: 0.0435896
[Epoch 107; Iter   808/ 1097] train: loss: 0.0287689
[Epoch 107; Iter   838/ 1097] train: loss: 0.0147968
[Epoch 107; Iter   868/ 1097] train: loss: 0.0027958
[Epoch 107; Iter   898/ 1097] train: loss: 0.0112088
[Epoch 107; Iter   928/ 1097] train: loss: 0.0224683
[Epoch 107; Iter   958/ 1097] train: loss: 0.0016884
[Epoch 107; Iter   988/ 1097] train: loss: 0.0021253
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0003692
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0350267
[Epoch 107; Iter  1078/ 1097] train: loss: 0.1437403
[Epoch 107] ogbg-molhiv: 0.784704 val loss: 0.153943
[Epoch 107] ogbg-molhiv: 0.748159 test loss: 0.269443
[Epoch 108; Iter    11/ 1097] train: loss: 0.0034157
[Epoch 108; Iter    41/ 1097] train: loss: 0.0022830
[Epoch 108; Iter    71/ 1097] train: loss: 0.0225142
[Epoch 108; Iter   101/ 1097] train: loss: 0.0061805
[Epoch 108; Iter   131/ 1097] train: loss: 0.0064223
[Epoch 108; Iter   161/ 1097] train: loss: 0.0328459
[Epoch 108; Iter   191/ 1097] train: loss: 0.0005730
[Epoch 108; Iter   221/ 1097] train: loss: 0.0122007
[Epoch 108; Iter   251/ 1097] train: loss: 0.0019334
[Epoch 108; Iter   281/ 1097] train: loss: 0.0010404
[Epoch 108; Iter   311/ 1097] train: loss: 0.0094627
[Epoch 108; Iter   341/ 1097] train: loss: 0.0042269
[Epoch 108; Iter   371/ 1097] train: loss: 0.0010085
[Epoch 108; Iter   401/ 1097] train: loss: 0.0029258
[Epoch 108; Iter   431/ 1097] train: loss: 0.0029951
[Epoch 108; Iter   461/ 1097] train: loss: 0.0020568
[Epoch 108; Iter   491/ 1097] train: loss: 0.0010578
[Epoch 108; Iter   521/ 1097] train: loss: 0.0026637
[Epoch 108; Iter   551/ 1097] train: loss: 0.0888594
[Epoch 108; Iter   581/ 1097] train: loss: 0.0166093
[Epoch 108; Iter   611/ 1097] train: loss: 0.0002746
[Epoch 108; Iter   641/ 1097] train: loss: 0.0034370
[Epoch 108; Iter   671/ 1097] train: loss: 0.0022940
[Epoch 108; Iter   701/ 1097] train: loss: 0.0607942
[Epoch 108; Iter   731/ 1097] train: loss: 0.0015271
[Epoch 108; Iter   761/ 1097] train: loss: 0.0025847
[Epoch 108; Iter   791/ 1097] train: loss: 0.0028401
[Epoch 108; Iter   821/ 1097] train: loss: 0.0017424
[Epoch 108; Iter   851/ 1097] train: loss: 0.0006436
[Epoch 108; Iter   881/ 1097] train: loss: 0.0020806
[Epoch 108; Iter   911/ 1097] train: loss: 0.0020223
[Epoch 108; Iter   941/ 1097] train: loss: 0.0116127
[Epoch 108; Iter   971/ 1097] train: loss: 0.0237689
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0014634
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0061489
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0114314
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0004771
[Epoch 108] ogbg-molhiv: 0.782551 val loss: 0.155212
[Epoch 108] ogbg-molhiv: 0.750557 test loss: 0.259978
[Epoch 109; Iter    24/ 1097] train: loss: 0.0076519
[Epoch 109; Iter    54/ 1097] train: loss: 0.0023870
[Epoch 109; Iter    84/ 1097] train: loss: 0.0061809
[Epoch 109; Iter   114/ 1097] train: loss: 0.0004313
[Epoch 109; Iter   144/ 1097] train: loss: 0.0118339
[Epoch 109; Iter   174/ 1097] train: loss: 0.0012622
[Epoch 109; Iter   204/ 1097] train: loss: 0.0077967
[Epoch 109; Iter   234/ 1097] train: loss: 0.0038835
[Epoch 109; Iter   264/ 1097] train: loss: 0.0069018
[Epoch 109; Iter   294/ 1097] train: loss: 0.0400903
[Epoch 109; Iter   324/ 1097] train: loss: 0.0191277
[Epoch 109; Iter   354/ 1097] train: loss: 0.0005966
[Epoch 109; Iter   384/ 1097] train: loss: 0.0038665
[Epoch 109; Iter   414/ 1097] train: loss: 0.0364332
[Epoch 109; Iter   444/ 1097] train: loss: 0.0336087
[Epoch 109; Iter   474/ 1097] train: loss: 0.0041151
[Epoch 109; Iter   504/ 1097] train: loss: 0.1299200
[Epoch 109; Iter   534/ 1097] train: loss: 0.0040617
[Epoch 109; Iter   564/ 1097] train: loss: 0.0052064
[Epoch 109; Iter   594/ 1097] train: loss: 0.0166627
[Epoch 109; Iter   624/ 1097] train: loss: 0.0003057
[Epoch 109; Iter   654/ 1097] train: loss: 0.0016968
[Epoch 109; Iter   684/ 1097] train: loss: 0.0290837
[Epoch 109; Iter   714/ 1097] train: loss: 0.0185568
[Epoch 109; Iter   744/ 1097] train: loss: 0.0342231
[Epoch 109; Iter   774/ 1097] train: loss: 0.0200355
[Epoch 109; Iter   804/ 1097] train: loss: 0.0237450
[Epoch 109; Iter   834/ 1097] train: loss: 0.0777580
[Epoch 109; Iter   864/ 1097] train: loss: 0.0054059
[Epoch 109; Iter   894/ 1097] train: loss: 0.0029167
[Epoch 109; Iter   924/ 1097] train: loss: 0.0013798
[Epoch 109; Iter   954/ 1097] train: loss: 0.0139235
[Epoch 109; Iter   984/ 1097] train: loss: 0.0088180
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0004977
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0355541
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0261475
[Epoch 109] ogbg-molhiv: 0.814288 val loss: 0.143565
[Epoch 109] ogbg-molhiv: 0.743888 test loss: 0.271048
[Epoch 110; Iter     7/ 1097] train: loss: 0.0038214
[Epoch 110; Iter    37/ 1097] train: loss: 0.0069027
[Epoch 110; Iter    67/ 1097] train: loss: 0.0051797
[Epoch 110; Iter    97/ 1097] train: loss: 0.0094926
[Epoch 110; Iter   127/ 1097] train: loss: 0.0084231
[Epoch 110; Iter   157/ 1097] train: loss: 0.0411094
[Epoch 110; Iter   187/ 1097] train: loss: 0.0032552
[Epoch 110; Iter   217/ 1097] train: loss: 0.0046341
[Epoch 110; Iter   247/ 1097] train: loss: 0.0769203
[Epoch 110; Iter   277/ 1097] train: loss: 0.0039584
[Epoch 110; Iter   307/ 1097] train: loss: 0.0096877
[Epoch 110; Iter   337/ 1097] train: loss: 0.0162004
[Epoch 110; Iter   367/ 1097] train: loss: 0.0018641
[Epoch 110; Iter   397/ 1097] train: loss: 0.0150911
[Epoch 110; Iter   427/ 1097] train: loss: 0.0396800
[Epoch 110; Iter   457/ 1097] train: loss: 0.0009019
[Epoch 110; Iter   487/ 1097] train: loss: 0.0023697
[Epoch 110; Iter   517/ 1097] train: loss: 0.0463536
[Epoch 110; Iter   547/ 1097] train: loss: 0.0016583
[Epoch 110; Iter   577/ 1097] train: loss: 0.0010127
[Epoch 110; Iter   607/ 1097] train: loss: 0.0004821
[Epoch 110; Iter   637/ 1097] train: loss: 0.0032719
[Epoch 110; Iter   667/ 1097] train: loss: 0.0011358
[Epoch 110; Iter   697/ 1097] train: loss: 0.0006952
[Epoch 110; Iter   727/ 1097] train: loss: 0.0003072
[Epoch 110; Iter   757/ 1097] train: loss: 0.0014653
[Epoch 110; Iter   787/ 1097] train: loss: 0.0060038
[Epoch 110; Iter   817/ 1097] train: loss: 0.0088279
[Epoch 110; Iter   847/ 1097] train: loss: 0.0053824
[Epoch 110; Iter   877/ 1097] train: loss: 0.0066825
[Epoch 110; Iter   907/ 1097] train: loss: 0.0006114
[Epoch 110; Iter   937/ 1097] train: loss: 0.0968393
[Epoch 110; Iter   967/ 1097] train: loss: 0.0151793
[Epoch 110; Iter   997/ 1097] train: loss: 0.0041927
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0017147
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0063291
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0006022
[Epoch 110] ogbg-molhiv: 0.821349 val loss: 0.135858
[Epoch 110] ogbg-molhiv: 0.750687 test loss: 0.264320
[Epoch 111; Iter    20/ 1097] train: loss: 0.0050084
[Epoch 111; Iter    50/ 1097] train: loss: 0.0219679
[Epoch 111; Iter    80/ 1097] train: loss: 0.0075425
[Epoch 111; Iter   110/ 1097] train: loss: 0.0359639
[Epoch 111; Iter   140/ 1097] train: loss: 0.0024951
[Epoch 111; Iter   170/ 1097] train: loss: 0.0015024
[Epoch 111; Iter   200/ 1097] train: loss: 0.0270360
[Epoch 111; Iter   230/ 1097] train: loss: 0.0237961
[Epoch 111; Iter   260/ 1097] train: loss: 0.0030878
[Epoch 111; Iter   290/ 1097] train: loss: 0.0152022
[Epoch 111; Iter   320/ 1097] train: loss: 0.0463325
[Epoch 111; Iter   350/ 1097] train: loss: 0.0008085
[Epoch 111; Iter   380/ 1097] train: loss: 0.0300309
[Epoch 111; Iter   410/ 1097] train: loss: 0.0030679
[Epoch 111; Iter   440/ 1097] train: loss: 0.0003861
[Epoch 111; Iter   470/ 1097] train: loss: 0.0036245
[Epoch 111; Iter   500/ 1097] train: loss: 0.0107699
[Epoch 111; Iter   530/ 1097] train: loss: 0.0415507
[Epoch 111; Iter   560/ 1097] train: loss: 0.0126581
[Epoch 111; Iter   590/ 1097] train: loss: 0.0057091
[Epoch 111; Iter   620/ 1097] train: loss: 0.0003356
[Epoch 111; Iter   650/ 1097] train: loss: 0.0010079
[Epoch 111; Iter   680/ 1097] train: loss: 0.0148515
[Epoch 111; Iter   710/ 1097] train: loss: 0.0040962
[Epoch 111; Iter   740/ 1097] train: loss: 0.0120528
[Epoch 111; Iter   770/ 1097] train: loss: 0.0086553
[Epoch 111; Iter   800/ 1097] train: loss: 0.0370326
[Epoch 111; Iter   830/ 1097] train: loss: 0.0008610
[Epoch 111; Iter   860/ 1097] train: loss: 0.0027248
[Epoch 111; Iter   890/ 1097] train: loss: 0.0045772
[Epoch 111; Iter   920/ 1097] train: loss: 0.0012357
[Epoch 111; Iter   950/ 1097] train: loss: 0.0191348
[Epoch 111; Iter   980/ 1097] train: loss: 0.0010457
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0081065
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0134413
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0203288
[Epoch 111] ogbg-molhiv: 0.824417 val loss: 0.133665
[Epoch 111] ogbg-molhiv: 0.751081 test loss: 0.259322
[Epoch 112; Iter     3/ 1097] train: loss: 0.0029373
[Epoch 112; Iter    33/ 1097] train: loss: 0.0698782
[Epoch 112; Iter    63/ 1097] train: loss: 0.0122909
[Epoch 112; Iter    93/ 1097] train: loss: 0.0348129
[Epoch 112; Iter   123/ 1097] train: loss: 0.0215800
[Epoch 112; Iter   153/ 1097] train: loss: 0.0081603
[Epoch 112; Iter   183/ 1097] train: loss: 0.0119534
[Epoch 112; Iter   213/ 1097] train: loss: 0.0056737
[Epoch 112; Iter   243/ 1097] train: loss: 0.0106626
[Epoch 112; Iter   273/ 1097] train: loss: 0.0058272
[Epoch 112; Iter   303/ 1097] train: loss: 0.0004538
[Epoch 112; Iter   333/ 1097] train: loss: 0.0004837
[Epoch 112; Iter   363/ 1097] train: loss: 0.0006492
[Epoch 112; Iter   393/ 1097] train: loss: 0.0005770
[Epoch 112; Iter   423/ 1097] train: loss: 0.0287384
[Epoch 112; Iter   453/ 1097] train: loss: 0.0994606
[Epoch 112; Iter   483/ 1097] train: loss: 0.0010864
[Epoch 112; Iter   513/ 1097] train: loss: 0.0278706
[Epoch 112; Iter   543/ 1097] train: loss: 0.1579524
[Epoch 112; Iter   573/ 1097] train: loss: 0.0015705
[Epoch 112; Iter   603/ 1097] train: loss: 0.0017254
[Epoch 112; Iter   633/ 1097] train: loss: 0.0291252
[Epoch 112; Iter   663/ 1097] train: loss: 0.0027468
[Epoch 112; Iter   693/ 1097] train: loss: 0.0299269
[Epoch 112; Iter   723/ 1097] train: loss: 0.0007469
[Epoch 112; Iter   753/ 1097] train: loss: 0.0004485
[Epoch 112; Iter   783/ 1097] train: loss: 0.0016541
[Epoch 112; Iter   813/ 1097] train: loss: 0.0127598
[Epoch 112; Iter   843/ 1097] train: loss: 0.0076154
[Epoch 112; Iter   873/ 1097] train: loss: 0.0094605
[Epoch 112; Iter   903/ 1097] train: loss: 0.0015188
[Epoch 112; Iter   933/ 1097] train: loss: 0.0050504
[Epoch 112; Iter   963/ 1097] train: loss: 0.0049156
[Epoch 112; Iter   993/ 1097] train: loss: 0.0193905
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0094803
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0242998
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0013475
[Epoch 112] ogbg-molhiv: 0.820838 val loss: 0.137283
[Epoch 112] ogbg-molhiv: 0.750524 test loss: 0.268363
[Epoch 113; Iter    16/ 1097] train: loss: 0.0013605
[Epoch 113; Iter    46/ 1097] train: loss: 0.0099707
[Epoch 113; Iter    76/ 1097] train: loss: 0.0247919
[Epoch 113; Iter   106/ 1097] train: loss: 0.0050889
[Epoch 113; Iter   136/ 1097] train: loss: 0.0365392
[Epoch 113; Iter   166/ 1097] train: loss: 0.0030612
[Epoch 113; Iter   196/ 1097] train: loss: 0.0482557
[Epoch 113; Iter   226/ 1097] train: loss: 0.0012198
[Epoch 113; Iter   256/ 1097] train: loss: 0.0010161
[Epoch 113; Iter   286/ 1097] train: loss: 0.0868792
[Epoch 113; Iter   316/ 1097] train: loss: 0.0032190
[Epoch 113; Iter   346/ 1097] train: loss: 0.0020016
[Epoch 113; Iter   376/ 1097] train: loss: 0.0176970
[Epoch 113; Iter   406/ 1097] train: loss: 0.0064636
[Epoch 113; Iter   436/ 1097] train: loss: 0.0094608
[Epoch 113; Iter   466/ 1097] train: loss: 0.0061827
[Epoch 113; Iter   496/ 1097] train: loss: 0.0200568
[Epoch 113; Iter   526/ 1097] train: loss: 0.0034290
[Epoch 113; Iter   556/ 1097] train: loss: 0.0050158
[Epoch 113; Iter   586/ 1097] train: loss: 0.0004322
[Epoch 113; Iter   616/ 1097] train: loss: 0.0004683
[Epoch 113; Iter   646/ 1097] train: loss: 0.0029211
[Epoch 113; Iter   676/ 1097] train: loss: 0.0051992
[Epoch 109; Iter   714/ 1097] train: loss: 0.0084292
[Epoch 109; Iter   744/ 1097] train: loss: 0.0073831
[Epoch 109; Iter   774/ 1097] train: loss: 0.0268331
[Epoch 109; Iter   804/ 1097] train: loss: 0.0168126
[Epoch 109; Iter   834/ 1097] train: loss: 0.0560552
[Epoch 109; Iter   864/ 1097] train: loss: 0.0188680
[Epoch 109; Iter   894/ 1097] train: loss: 0.0026927
[Epoch 109; Iter   924/ 1097] train: loss: 0.0171069
[Epoch 109; Iter   954/ 1097] train: loss: 0.0028790
[Epoch 109; Iter   984/ 1097] train: loss: 0.0133282
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0008233
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0068982
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0230023
[Epoch 109] ogbg-molhiv: 0.804735 val loss: 0.123323
[Epoch 109] ogbg-molhiv: 0.759482 test loss: 0.246778
[Epoch 110; Iter     7/ 1097] train: loss: 0.0024298
[Epoch 110; Iter    37/ 1097] train: loss: 0.0064446
[Epoch 110; Iter    67/ 1097] train: loss: 0.0230804
[Epoch 110; Iter    97/ 1097] train: loss: 0.0005882
[Epoch 110; Iter   127/ 1097] train: loss: 0.0270968
[Epoch 110; Iter   157/ 1097] train: loss: 0.0003619
[Epoch 110; Iter   187/ 1097] train: loss: 0.0040042
[Epoch 110; Iter   217/ 1097] train: loss: 0.0074070
[Epoch 110; Iter   247/ 1097] train: loss: 0.0065732
[Epoch 110; Iter   277/ 1097] train: loss: 0.0023029
[Epoch 110; Iter   307/ 1097] train: loss: 0.0197295
[Epoch 110; Iter   337/ 1097] train: loss: 0.0033987
[Epoch 110; Iter   367/ 1097] train: loss: 0.0297431
[Epoch 110; Iter   397/ 1097] train: loss: 0.0434318
[Epoch 110; Iter   427/ 1097] train: loss: 0.3173898
[Epoch 110; Iter   457/ 1097] train: loss: 0.0014037
[Epoch 110; Iter   487/ 1097] train: loss: 0.0160452
[Epoch 110; Iter   517/ 1097] train: loss: 0.0023311
[Epoch 110; Iter   547/ 1097] train: loss: 0.0106110
[Epoch 110; Iter   577/ 1097] train: loss: 0.0471848
[Epoch 110; Iter   607/ 1097] train: loss: 0.0020830
[Epoch 110; Iter   637/ 1097] train: loss: 0.0100786
[Epoch 110; Iter   667/ 1097] train: loss: 0.0331787
[Epoch 110; Iter   697/ 1097] train: loss: 0.0261273
[Epoch 110; Iter   727/ 1097] train: loss: 0.0282942
[Epoch 110; Iter   757/ 1097] train: loss: 0.0229560
[Epoch 110; Iter   787/ 1097] train: loss: 0.0033663
[Epoch 110; Iter   817/ 1097] train: loss: 0.0129107
[Epoch 110; Iter   847/ 1097] train: loss: 0.0868019
[Epoch 110; Iter   877/ 1097] train: loss: 0.1047901
[Epoch 110; Iter   907/ 1097] train: loss: 0.0271296
[Epoch 110; Iter   937/ 1097] train: loss: 0.0029782
[Epoch 110; Iter   967/ 1097] train: loss: 0.0061392
[Epoch 110; Iter   997/ 1097] train: loss: 0.0148239
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0028252
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0179235
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0047345
[Epoch 110] ogbg-molhiv: 0.805908 val loss: 0.124223
[Epoch 110] ogbg-molhiv: 0.758767 test loss: 0.249573
[Epoch 111; Iter    20/ 1097] train: loss: 0.0038760
[Epoch 111; Iter    50/ 1097] train: loss: 0.0120477
[Epoch 111; Iter    80/ 1097] train: loss: 0.0294818
[Epoch 111; Iter   110/ 1097] train: loss: 0.0030292
[Epoch 111; Iter   140/ 1097] train: loss: 0.0054658
[Epoch 111; Iter   170/ 1097] train: loss: 0.0552720
[Epoch 111; Iter   200/ 1097] train: loss: 0.0008220
[Epoch 111; Iter   230/ 1097] train: loss: 0.0173981
[Epoch 111; Iter   260/ 1097] train: loss: 0.0172820
[Epoch 111; Iter   290/ 1097] train: loss: 0.0447443
[Epoch 111; Iter   320/ 1097] train: loss: 0.0038480
[Epoch 111; Iter   350/ 1097] train: loss: 0.0005675
[Epoch 111; Iter   380/ 1097] train: loss: 0.0346231
[Epoch 111; Iter   410/ 1097] train: loss: 0.0091455
[Epoch 111; Iter   440/ 1097] train: loss: 0.0095310
[Epoch 111; Iter   470/ 1097] train: loss: 0.0157507
[Epoch 111; Iter   500/ 1097] train: loss: 0.0027614
[Epoch 111; Iter   530/ 1097] train: loss: 0.1639315
[Epoch 111; Iter   560/ 1097] train: loss: 0.0064395
[Epoch 111; Iter   590/ 1097] train: loss: 0.0031557
[Epoch 111; Iter   620/ 1097] train: loss: 0.0903870
[Epoch 111; Iter   650/ 1097] train: loss: 0.0071498
[Epoch 111; Iter   680/ 1097] train: loss: 0.0060680
[Epoch 111; Iter   710/ 1097] train: loss: 0.0209981
[Epoch 111; Iter   740/ 1097] train: loss: 0.0096190
[Epoch 111; Iter   770/ 1097] train: loss: 0.0033141
[Epoch 111; Iter   800/ 1097] train: loss: 0.0584177
[Epoch 111; Iter   830/ 1097] train: loss: 0.0237182
[Epoch 111; Iter   860/ 1097] train: loss: 0.0287923
[Epoch 111; Iter   890/ 1097] train: loss: 0.0017972
[Epoch 111; Iter   920/ 1097] train: loss: 0.0007064
[Epoch 111; Iter   950/ 1097] train: loss: 0.0308887
[Epoch 111; Iter   980/ 1097] train: loss: 0.0065978
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0556763
[Epoch 111; Iter  1040/ 1097] train: loss: 0.1392028
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0099458
[Epoch 111] ogbg-molhiv: 0.802699 val loss: 0.125392
[Epoch 111] ogbg-molhiv: 0.754449 test loss: 0.248918
[Epoch 112; Iter     3/ 1097] train: loss: 0.0345764
[Epoch 112; Iter    33/ 1097] train: loss: 0.0161845
[Epoch 112; Iter    63/ 1097] train: loss: 0.0192658
[Epoch 112; Iter    93/ 1097] train: loss: 0.0021457
[Epoch 112; Iter   123/ 1097] train: loss: 0.0221632
[Epoch 112; Iter   153/ 1097] train: loss: 0.0239958
[Epoch 112; Iter   183/ 1097] train: loss: 0.0016327
[Epoch 112; Iter   213/ 1097] train: loss: 0.0129977
[Epoch 112; Iter   243/ 1097] train: loss: 0.0228975
[Epoch 112; Iter   273/ 1097] train: loss: 0.0071360
[Epoch 112; Iter   303/ 1097] train: loss: 0.0030448
[Epoch 112; Iter   333/ 1097] train: loss: 0.0131052
[Epoch 112; Iter   363/ 1097] train: loss: 0.0017535
[Epoch 112; Iter   393/ 1097] train: loss: 0.0156374
[Epoch 112; Iter   423/ 1097] train: loss: 0.0072353
[Epoch 112; Iter   453/ 1097] train: loss: 0.0041234
[Epoch 112; Iter   483/ 1097] train: loss: 0.0078806
[Epoch 112; Iter   513/ 1097] train: loss: 0.0146649
[Epoch 112; Iter   543/ 1097] train: loss: 0.0016423
[Epoch 112; Iter   573/ 1097] train: loss: 0.0042094
[Epoch 112; Iter   603/ 1097] train: loss: 0.0070010
[Epoch 112; Iter   633/ 1097] train: loss: 0.0011672
[Epoch 112; Iter   663/ 1097] train: loss: 0.0068125
[Epoch 112; Iter   693/ 1097] train: loss: 0.0120946
[Epoch 112; Iter   723/ 1097] train: loss: 0.1088876
[Epoch 112; Iter   753/ 1097] train: loss: 0.0026728
[Epoch 112; Iter   783/ 1097] train: loss: 0.0003822
[Epoch 112; Iter   813/ 1097] train: loss: 0.0356371
[Epoch 112; Iter   843/ 1097] train: loss: 0.0156615
[Epoch 112; Iter   873/ 1097] train: loss: 0.0057915
[Epoch 112; Iter   903/ 1097] train: loss: 0.0931700
[Epoch 112; Iter   933/ 1097] train: loss: 0.0063622
[Epoch 112; Iter   963/ 1097] train: loss: 0.0355077
[Epoch 112; Iter   993/ 1097] train: loss: 0.0177241
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0018513
[Epoch 112; Iter  1053/ 1097] train: loss: 0.1342201
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0019637
[Epoch 112] ogbg-molhiv: 0.811410 val loss: 0.128653
[Epoch 112] ogbg-molhiv: 0.755604 test loss: 0.262114
[Epoch 113; Iter    16/ 1097] train: loss: 0.0352985
[Epoch 113; Iter    46/ 1097] train: loss: 0.0086891
[Epoch 113; Iter    76/ 1097] train: loss: 0.0019977
[Epoch 113; Iter   106/ 1097] train: loss: 0.0163017
[Epoch 113; Iter   136/ 1097] train: loss: 0.0156072
[Epoch 113; Iter   166/ 1097] train: loss: 0.0260805
[Epoch 113; Iter   196/ 1097] train: loss: 0.0122399
[Epoch 113; Iter   226/ 1097] train: loss: 0.0161060
[Epoch 113; Iter   256/ 1097] train: loss: 0.0300476
[Epoch 113; Iter   286/ 1097] train: loss: 0.0011346
[Epoch 113; Iter   316/ 1097] train: loss: 0.0077403
[Epoch 113; Iter   346/ 1097] train: loss: 0.0151301
[Epoch 113; Iter   376/ 1097] train: loss: 0.0180956
[Epoch 113; Iter   406/ 1097] train: loss: 0.0675468
[Epoch 113; Iter   436/ 1097] train: loss: 0.0090556
[Epoch 113; Iter   466/ 1097] train: loss: 0.1562150
[Epoch 113; Iter   496/ 1097] train: loss: 0.0056338
[Epoch 113; Iter   526/ 1097] train: loss: 0.0670280
[Epoch 113; Iter   556/ 1097] train: loss: 0.0003906
[Epoch 113; Iter   586/ 1097] train: loss: 0.1140437
[Epoch 113; Iter   616/ 1097] train: loss: 0.0458856
[Epoch 113; Iter   646/ 1097] train: loss: 0.0699635
[Epoch 113; Iter   676/ 1097] train: loss: 0.1392446
[Epoch 109; Iter   714/ 1097] train: loss: 0.0031910
[Epoch 109; Iter   744/ 1097] train: loss: 0.0011707
[Epoch 109; Iter   774/ 1097] train: loss: 0.0155043
[Epoch 109; Iter   804/ 1097] train: loss: 0.1525989
[Epoch 109; Iter   834/ 1097] train: loss: 0.0011893
[Epoch 109; Iter   864/ 1097] train: loss: 0.0013234
[Epoch 109; Iter   894/ 1097] train: loss: 0.0027339
[Epoch 109; Iter   924/ 1097] train: loss: 0.0036267
[Epoch 109; Iter   954/ 1097] train: loss: 0.0006092
[Epoch 109; Iter   984/ 1097] train: loss: 0.0003456
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0037235
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0084323
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0004701
[Epoch 109] ogbg-molhiv: 0.780198 val loss: 0.155162
[Epoch 109] ogbg-molhiv: 0.752726 test loss: 0.265671
[Epoch 110; Iter     7/ 1097] train: loss: 0.0401307
[Epoch 110; Iter    37/ 1097] train: loss: 0.0020998
[Epoch 110; Iter    67/ 1097] train: loss: 0.0251978
[Epoch 110; Iter    97/ 1097] train: loss: 0.0469457
[Epoch 110; Iter   127/ 1097] train: loss: 0.0196914
[Epoch 110; Iter   157/ 1097] train: loss: 0.0174284
[Epoch 110; Iter   187/ 1097] train: loss: 0.0046279
[Epoch 110; Iter   217/ 1097] train: loss: 0.0048463
[Epoch 110; Iter   247/ 1097] train: loss: 0.0057541
[Epoch 110; Iter   277/ 1097] train: loss: 0.0017986
[Epoch 110; Iter   307/ 1097] train: loss: 0.0124053
[Epoch 110; Iter   337/ 1097] train: loss: 0.0093287
[Epoch 110; Iter   367/ 1097] train: loss: 0.0002714
[Epoch 110; Iter   397/ 1097] train: loss: 0.0017715
[Epoch 110; Iter   427/ 1097] train: loss: 0.0132974
[Epoch 110; Iter   457/ 1097] train: loss: 0.0015874
[Epoch 110; Iter   487/ 1097] train: loss: 0.0031256
[Epoch 110; Iter   517/ 1097] train: loss: 0.0018285
[Epoch 110; Iter   547/ 1097] train: loss: 0.0043099
[Epoch 110; Iter   577/ 1097] train: loss: 0.0072833
[Epoch 110; Iter   607/ 1097] train: loss: 0.0010940
[Epoch 110; Iter   637/ 1097] train: loss: 0.0388063
[Epoch 110; Iter   667/ 1097] train: loss: 0.0054660
[Epoch 110; Iter   697/ 1097] train: loss: 0.0085751
[Epoch 110; Iter   727/ 1097] train: loss: 0.0013559
[Epoch 110; Iter   757/ 1097] train: loss: 0.0016224
[Epoch 110; Iter   787/ 1097] train: loss: 0.0105193
[Epoch 110; Iter   817/ 1097] train: loss: 0.0027239
[Epoch 110; Iter   847/ 1097] train: loss: 0.0293243
[Epoch 110; Iter   877/ 1097] train: loss: 0.0048345
[Epoch 110; Iter   907/ 1097] train: loss: 0.0005867
[Epoch 110; Iter   937/ 1097] train: loss: 0.0338370
[Epoch 110; Iter   967/ 1097] train: loss: 0.0095490
[Epoch 110; Iter   997/ 1097] train: loss: 0.0008019
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0017353
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0003347
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0571190
[Epoch 110] ogbg-molhiv: 0.788954 val loss: 0.156145
[Epoch 110] ogbg-molhiv: 0.752454 test loss: 0.266524
[Epoch 111; Iter    20/ 1097] train: loss: 0.0007441
[Epoch 111; Iter    50/ 1097] train: loss: 0.0124128
[Epoch 111; Iter    80/ 1097] train: loss: 0.0040875
[Epoch 111; Iter   110/ 1097] train: loss: 0.0019847
[Epoch 111; Iter   140/ 1097] train: loss: 0.0060808
[Epoch 111; Iter   170/ 1097] train: loss: 0.0647308
[Epoch 111; Iter   200/ 1097] train: loss: 0.0041548
[Epoch 111; Iter   230/ 1097] train: loss: 0.0047461
[Epoch 111; Iter   260/ 1097] train: loss: 0.0049000
[Epoch 111; Iter   290/ 1097] train: loss: 0.0067730
[Epoch 111; Iter   320/ 1097] train: loss: 0.0011821
[Epoch 111; Iter   350/ 1097] train: loss: 0.0005515
[Epoch 111; Iter   380/ 1097] train: loss: 0.0148339
[Epoch 111; Iter   410/ 1097] train: loss: 0.0382479
[Epoch 111; Iter   440/ 1097] train: loss: 0.0024253
[Epoch 111; Iter   470/ 1097] train: loss: 0.0027786
[Epoch 111; Iter   500/ 1097] train: loss: 0.0352990
[Epoch 111; Iter   530/ 1097] train: loss: 0.0006157
[Epoch 111; Iter   560/ 1097] train: loss: 0.0002425
[Epoch 111; Iter   590/ 1097] train: loss: 0.0008638
[Epoch 111; Iter   620/ 1097] train: loss: 0.0055656
[Epoch 111; Iter   650/ 1097] train: loss: 0.0046725
[Epoch 111; Iter   680/ 1097] train: loss: 0.0026022
[Epoch 111; Iter   710/ 1097] train: loss: 0.0084686
[Epoch 111; Iter   740/ 1097] train: loss: 0.0375161
[Epoch 111; Iter   770/ 1097] train: loss: 0.0483530
[Epoch 111; Iter   800/ 1097] train: loss: 0.0497338
[Epoch 111; Iter   830/ 1097] train: loss: 0.0739797
[Epoch 111; Iter   860/ 1097] train: loss: 0.0668413
[Epoch 111; Iter   890/ 1097] train: loss: 0.0041872
[Epoch 111; Iter   920/ 1097] train: loss: 0.0232888
[Epoch 111; Iter   950/ 1097] train: loss: 0.0028579
[Epoch 111; Iter   980/ 1097] train: loss: 0.0043253
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0138046
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0005599
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0014996
[Epoch 111] ogbg-molhiv: 0.783014 val loss: 0.152948
[Epoch 111] ogbg-molhiv: 0.747031 test loss: 0.267381
[Epoch 112; Iter     3/ 1097] train: loss: 0.0040949
[Epoch 112; Iter    33/ 1097] train: loss: 0.0217644
[Epoch 112; Iter    63/ 1097] train: loss: 0.0049491
[Epoch 112; Iter    93/ 1097] train: loss: 0.0069421
[Epoch 112; Iter   123/ 1097] train: loss: 0.0982253
[Epoch 112; Iter   153/ 1097] train: loss: 0.0104840
[Epoch 112; Iter   183/ 1097] train: loss: 0.0071302
[Epoch 112; Iter   213/ 1097] train: loss: 0.0896737
[Epoch 112; Iter   243/ 1097] train: loss: 0.0016449
[Epoch 112; Iter   273/ 1097] train: loss: 0.0008731
[Epoch 112; Iter   303/ 1097] train: loss: 0.0019418
[Epoch 112; Iter   333/ 1097] train: loss: 0.0026610
[Epoch 112; Iter   363/ 1097] train: loss: 0.0024647
[Epoch 112; Iter   393/ 1097] train: loss: 0.0068542
[Epoch 112; Iter   423/ 1097] train: loss: 0.0159184
[Epoch 112; Iter   453/ 1097] train: loss: 0.0082738
[Epoch 112; Iter   483/ 1097] train: loss: 0.0005958
[Epoch 112; Iter   513/ 1097] train: loss: 0.0012231
[Epoch 112; Iter   543/ 1097] train: loss: 0.0012026
[Epoch 112; Iter   573/ 1097] train: loss: 0.0095023
[Epoch 112; Iter   603/ 1097] train: loss: 0.0054462
[Epoch 112; Iter   633/ 1097] train: loss: 0.0005918
[Epoch 112; Iter   663/ 1097] train: loss: 0.0602510
[Epoch 112; Iter   693/ 1097] train: loss: 0.0031893
[Epoch 112; Iter   723/ 1097] train: loss: 0.0011248
[Epoch 112; Iter   753/ 1097] train: loss: 0.0289989
[Epoch 112; Iter   783/ 1097] train: loss: 0.0051442
[Epoch 112; Iter   813/ 1097] train: loss: 0.0005528
[Epoch 112; Iter   843/ 1097] train: loss: 0.0219222
[Epoch 112; Iter   873/ 1097] train: loss: 0.0201961
[Epoch 112; Iter   903/ 1097] train: loss: 0.0004200
[Epoch 112; Iter   933/ 1097] train: loss: 0.0169584
[Epoch 112; Iter   963/ 1097] train: loss: 0.0020544
[Epoch 112; Iter   993/ 1097] train: loss: 0.0037385
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0022154
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0015315
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0003112
[Epoch 112] ogbg-molhiv: 0.773044 val loss: 0.158584
[Epoch 112] ogbg-molhiv: 0.745435 test loss: 0.268493
[Epoch 113; Iter    16/ 1097] train: loss: 0.0113803
[Epoch 113; Iter    46/ 1097] train: loss: 0.0015039
[Epoch 113; Iter    76/ 1097] train: loss: 0.0018213
[Epoch 113; Iter   106/ 1097] train: loss: 0.0066567
[Epoch 113; Iter   136/ 1097] train: loss: 0.0006282
[Epoch 113; Iter   166/ 1097] train: loss: 0.0138793
[Epoch 113; Iter   196/ 1097] train: loss: 0.0033261
[Epoch 113; Iter   226/ 1097] train: loss: 0.0264604
[Epoch 113; Iter   256/ 1097] train: loss: 0.0707720
[Epoch 113; Iter   286/ 1097] train: loss: 0.0439330
[Epoch 113; Iter   316/ 1097] train: loss: 0.0040910
[Epoch 113; Iter   346/ 1097] train: loss: 0.0009819
[Epoch 113; Iter   376/ 1097] train: loss: 0.0393182
[Epoch 113; Iter   406/ 1097] train: loss: 0.0007122
[Epoch 113; Iter   436/ 1097] train: loss: 0.0104604
[Epoch 113; Iter   466/ 1097] train: loss: 0.0030393
[Epoch 113; Iter   496/ 1097] train: loss: 0.0052622
[Epoch 113; Iter   526/ 1097] train: loss: 0.0002049
[Epoch 113; Iter   556/ 1097] train: loss: 0.0023086
[Epoch 113; Iter   586/ 1097] train: loss: 0.0055240
[Epoch 113; Iter   616/ 1097] train: loss: 0.0075569
[Epoch 113; Iter   646/ 1097] train: loss: 0.0008785
[Epoch 113; Iter   676/ 1097] train: loss: 0.1269243
[Epoch 113; Iter   706/ 1097] train: loss: 0.0009862
[Epoch 113; Iter   736/ 1097] train: loss: 0.0027723
[Epoch 113; Iter   766/ 1097] train: loss: 0.0008309
[Epoch 113; Iter   796/ 1097] train: loss: 0.0022579
[Epoch 113; Iter   826/ 1097] train: loss: 0.0003994
[Epoch 113; Iter   856/ 1097] train: loss: 0.0134658
[Epoch 113; Iter   886/ 1097] train: loss: 0.0020912
[Epoch 113; Iter   916/ 1097] train: loss: 0.0256224
[Epoch 113; Iter   946/ 1097] train: loss: 0.0012700
[Epoch 113; Iter   976/ 1097] train: loss: 0.0081468
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0009920
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0274900
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0001216
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0476908
[Epoch 113] ogbg-molhiv: 0.822096 val loss: 0.141591
[Epoch 113] ogbg-molhiv: 0.744738 test loss: 0.280794
[Epoch 114; Iter    29/ 1097] train: loss: 0.0010079
[Epoch 114; Iter    59/ 1097] train: loss: 0.0065586
[Epoch 114; Iter    89/ 1097] train: loss: 0.0021007
[Epoch 114; Iter   119/ 1097] train: loss: 0.0251732
[Epoch 114; Iter   149/ 1097] train: loss: 0.0048155
[Epoch 114; Iter   179/ 1097] train: loss: 0.0863432
[Epoch 114; Iter   209/ 1097] train: loss: 0.0106744
[Epoch 114; Iter   239/ 1097] train: loss: 0.0038405
[Epoch 114; Iter   269/ 1097] train: loss: 0.0096023
[Epoch 114; Iter   299/ 1097] train: loss: 0.0009874
[Epoch 114; Iter   329/ 1097] train: loss: 0.0003655
[Epoch 114; Iter   359/ 1097] train: loss: 0.0015163
[Epoch 114; Iter   389/ 1097] train: loss: 0.0037016
[Epoch 114; Iter   419/ 1097] train: loss: 0.0011592
[Epoch 114; Iter   449/ 1097] train: loss: 0.0337814
[Epoch 114; Iter   479/ 1097] train: loss: 0.0363340
[Epoch 114; Iter   509/ 1097] train: loss: 0.0192018
[Epoch 114; Iter   539/ 1097] train: loss: 0.0065164
[Epoch 114; Iter   569/ 1097] train: loss: 0.0331604
[Epoch 114; Iter   599/ 1097] train: loss: 0.0192407
[Epoch 114; Iter   629/ 1097] train: loss: 0.0010895
[Epoch 114; Iter   659/ 1097] train: loss: 0.0038881
[Epoch 114; Iter   689/ 1097] train: loss: 0.0116524
[Epoch 114; Iter   719/ 1097] train: loss: 0.0368028
[Epoch 114; Iter   749/ 1097] train: loss: 0.0075249
[Epoch 114; Iter   779/ 1097] train: loss: 0.0685384
[Epoch 114; Iter   809/ 1097] train: loss: 0.0106136
[Epoch 114; Iter   839/ 1097] train: loss: 0.0018002
[Epoch 114; Iter   869/ 1097] train: loss: 0.0046612
[Epoch 114; Iter   899/ 1097] train: loss: 0.0013181
[Epoch 114; Iter   929/ 1097] train: loss: 0.0209867
[Epoch 114; Iter   959/ 1097] train: loss: 0.0002071
[Epoch 114; Iter   989/ 1097] train: loss: 0.0167446
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0023563
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0004889
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0192940
[Epoch 114] ogbg-molhiv: 0.823524 val loss: 0.140545
[Epoch 114] ogbg-molhiv: 0.743576 test loss: 0.272052
[Epoch 115; Iter    12/ 1097] train: loss: 0.0813523
[Epoch 115; Iter    42/ 1097] train: loss: 0.0015661
[Epoch 115; Iter    72/ 1097] train: loss: 0.0005096
[Epoch 115; Iter   102/ 1097] train: loss: 0.0032400
[Epoch 115; Iter   132/ 1097] train: loss: 0.0049453
[Epoch 115; Iter   162/ 1097] train: loss: 0.0028132
[Epoch 115; Iter   192/ 1097] train: loss: 0.0009382
[Epoch 115; Iter   222/ 1097] train: loss: 0.0013215
[Epoch 115; Iter   252/ 1097] train: loss: 0.0389670
[Epoch 115; Iter   282/ 1097] train: loss: 0.0036452
[Epoch 115; Iter   312/ 1097] train: loss: 0.0086198
[Epoch 115; Iter   342/ 1097] train: loss: 0.0031375
[Epoch 115; Iter   372/ 1097] train: loss: 0.0026465
[Epoch 115; Iter   402/ 1097] train: loss: 0.0023566
[Epoch 115; Iter   432/ 1097] train: loss: 0.0102417
[Epoch 115; Iter   462/ 1097] train: loss: 0.0033720
[Epoch 115; Iter   492/ 1097] train: loss: 0.0512356
[Epoch 115; Iter   522/ 1097] train: loss: 0.0087228
[Epoch 115; Iter   552/ 1097] train: loss: 0.0843661
[Epoch 115; Iter   582/ 1097] train: loss: 0.0042398
[Epoch 115; Iter   612/ 1097] train: loss: 0.0013341
[Epoch 115; Iter   642/ 1097] train: loss: 0.1861154
[Epoch 115; Iter   672/ 1097] train: loss: 0.0007919
[Epoch 115; Iter   702/ 1097] train: loss: 0.0022470
[Epoch 115; Iter   732/ 1097] train: loss: 0.0774806
[Epoch 115; Iter   762/ 1097] train: loss: 0.0095967
[Epoch 115; Iter   792/ 1097] train: loss: 0.0011650
[Epoch 115; Iter   822/ 1097] train: loss: 0.0004941
[Epoch 115; Iter   852/ 1097] train: loss: 0.0417859
[Epoch 115; Iter   882/ 1097] train: loss: 0.0039534
[Epoch 115; Iter   912/ 1097] train: loss: 0.0015934
[Epoch 115; Iter   942/ 1097] train: loss: 0.0029032
[Epoch 115; Iter   972/ 1097] train: loss: 0.0009526
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0034578
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0013220
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0364957
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0085007
[Epoch 115] ogbg-molhiv: 0.819441 val loss: 0.140934
[Epoch 115] ogbg-molhiv: 0.742631 test loss: 0.274724
[Epoch 116; Iter    25/ 1097] train: loss: 0.0004426
[Epoch 116; Iter    55/ 1097] train: loss: 0.0120725
[Epoch 116; Iter    85/ 1097] train: loss: 0.0239516
[Epoch 116; Iter   115/ 1097] train: loss: 0.0038887
[Epoch 116; Iter   145/ 1097] train: loss: 0.0038343
[Epoch 116; Iter   175/ 1097] train: loss: 0.0178440
[Epoch 116; Iter   205/ 1097] train: loss: 0.0011915
[Epoch 116; Iter   235/ 1097] train: loss: 0.0193909
[Epoch 116; Iter   265/ 1097] train: loss: 0.0377189
[Epoch 116; Iter   295/ 1097] train: loss: 0.0067517
[Epoch 116; Iter   325/ 1097] train: loss: 0.0026155
[Epoch 116; Iter   355/ 1097] train: loss: 0.0833572
[Epoch 116; Iter   385/ 1097] train: loss: 0.0001714
[Epoch 116; Iter   415/ 1097] train: loss: 0.0024477
[Epoch 116; Iter   445/ 1097] train: loss: 0.0166676
[Epoch 116; Iter   475/ 1097] train: loss: 0.0026809
[Epoch 116; Iter   505/ 1097] train: loss: 0.0005631
[Epoch 116; Iter   535/ 1097] train: loss: 0.0546240
[Epoch 116; Iter   565/ 1097] train: loss: 0.0402680
[Epoch 116; Iter   595/ 1097] train: loss: 0.0075595
[Epoch 116; Iter   625/ 1097] train: loss: 0.0044860
[Epoch 116; Iter   655/ 1097] train: loss: 0.2576677
[Epoch 116; Iter   685/ 1097] train: loss: 0.0386243
[Epoch 116; Iter   715/ 1097] train: loss: 0.0491908
[Epoch 116; Iter   745/ 1097] train: loss: 0.0088173
[Epoch 116; Iter   775/ 1097] train: loss: 0.0343040
[Epoch 116; Iter   805/ 1097] train: loss: 0.0163116
[Epoch 116; Iter   835/ 1097] train: loss: 0.0047663
[Epoch 116; Iter   865/ 1097] train: loss: 0.0057111
[Epoch 116; Iter   895/ 1097] train: loss: 0.0049528
[Epoch 116; Iter   925/ 1097] train: loss: 0.0106824
[Epoch 116; Iter   955/ 1097] train: loss: 0.0025447
[Epoch 116; Iter   985/ 1097] train: loss: 0.0263259
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0008641
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0021259
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0009202
[Epoch 116] ogbg-molhiv: 0.818214 val loss: 0.140272
[Epoch 116] ogbg-molhiv: 0.750434 test loss: 0.266923
[Epoch 117; Iter     8/ 1097] train: loss: 0.0048019
[Epoch 117; Iter    38/ 1097] train: loss: 0.0077781
[Epoch 117; Iter    68/ 1097] train: loss: 0.0021718
[Epoch 117; Iter    98/ 1097] train: loss: 0.0176233
[Epoch 117; Iter   128/ 1097] train: loss: 0.0856418
[Epoch 117; Iter   158/ 1097] train: loss: 0.0018020
[Epoch 117; Iter   188/ 1097] train: loss: 0.0102429
[Epoch 117; Iter   218/ 1097] train: loss: 0.0043565
[Epoch 117; Iter   248/ 1097] train: loss: 0.0068911
[Epoch 117; Iter   278/ 1097] train: loss: 0.0470255
[Epoch 117; Iter   308/ 1097] train: loss: 0.0021615
[Epoch 117; Iter   338/ 1097] train: loss: 0.0250658
[Epoch 117; Iter   368/ 1097] train: loss: 0.0050633
[Epoch 117; Iter   398/ 1097] train: loss: 0.0022613
[Epoch 117; Iter   428/ 1097] train: loss: 0.0084001
[Epoch 117; Iter   458/ 1097] train: loss: 0.0003144
[Epoch 117; Iter   488/ 1097] train: loss: 0.0103968
[Epoch 117; Iter   518/ 1097] train: loss: 0.0010604
[Epoch 117; Iter   548/ 1097] train: loss: 0.0101450
[Epoch 117; Iter   578/ 1097] train: loss: 0.0006310
[Epoch 117; Iter   608/ 1097] train: loss: 0.0280077
[Epoch 117; Iter   638/ 1097] train: loss: 0.0006873
[Epoch 117; Iter   668/ 1097] train: loss: 0.0029948
[Epoch 113; Iter   706/ 1097] train: loss: 0.0078128
[Epoch 113; Iter   736/ 1097] train: loss: 0.0117947
[Epoch 113; Iter   766/ 1097] train: loss: 0.0016617
[Epoch 113; Iter   796/ 1097] train: loss: 0.0129267
[Epoch 113; Iter   826/ 1097] train: loss: 0.0154868
[Epoch 113; Iter   856/ 1097] train: loss: 0.0020831
[Epoch 113; Iter   886/ 1097] train: loss: 0.0043027
[Epoch 113; Iter   916/ 1097] train: loss: 0.0019305
[Epoch 113; Iter   946/ 1097] train: loss: 0.0066423
[Epoch 113; Iter   976/ 1097] train: loss: 0.0013606
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0258759
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0101152
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0027455
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0005744
[Epoch 113] ogbg-molhiv: 0.813651 val loss: 0.124508
[Epoch 113] ogbg-molhiv: 0.753582 test loss: 0.254364
[Epoch 114; Iter    29/ 1097] train: loss: 0.0137666
[Epoch 114; Iter    59/ 1097] train: loss: 0.0200768
[Epoch 114; Iter    89/ 1097] train: loss: 0.0419396
[Epoch 114; Iter   119/ 1097] train: loss: 0.0058148
[Epoch 114; Iter   149/ 1097] train: loss: 0.0043842
[Epoch 114; Iter   179/ 1097] train: loss: 0.0045795
[Epoch 114; Iter   209/ 1097] train: loss: 0.0022730
[Epoch 114; Iter   239/ 1097] train: loss: 0.0265300
[Epoch 114; Iter   269/ 1097] train: loss: 0.0091241
[Epoch 114; Iter   299/ 1097] train: loss: 0.0857336
[Epoch 114; Iter   329/ 1097] train: loss: 0.0101983
[Epoch 114; Iter   359/ 1097] train: loss: 0.0739174
[Epoch 114; Iter   389/ 1097] train: loss: 0.0072487
[Epoch 114; Iter   419/ 1097] train: loss: 0.0043291
[Epoch 114; Iter   449/ 1097] train: loss: 0.0435502
[Epoch 114; Iter   479/ 1097] train: loss: 0.0306026
[Epoch 114; Iter   509/ 1097] train: loss: 0.0335103
[Epoch 114; Iter   539/ 1097] train: loss: 0.0012115
[Epoch 114; Iter   569/ 1097] train: loss: 0.0027752
[Epoch 114; Iter   599/ 1097] train: loss: 0.0032233
[Epoch 114; Iter   629/ 1097] train: loss: 0.0011831
[Epoch 114; Iter   659/ 1097] train: loss: 0.0025259
[Epoch 114; Iter   689/ 1097] train: loss: 0.0066676
[Epoch 114; Iter   719/ 1097] train: loss: 0.0023808
[Epoch 114; Iter   749/ 1097] train: loss: 0.0381876
[Epoch 114; Iter   779/ 1097] train: loss: 0.0318033
[Epoch 114; Iter   809/ 1097] train: loss: 0.0170320
[Epoch 114; Iter   839/ 1097] train: loss: 0.0053879
[Epoch 114; Iter   869/ 1097] train: loss: 0.0007227
[Epoch 114; Iter   899/ 1097] train: loss: 0.0643116
[Epoch 114; Iter   929/ 1097] train: loss: 0.0498992
[Epoch 114; Iter   959/ 1097] train: loss: 0.0203636
[Epoch 114; Iter   989/ 1097] train: loss: 0.0042027
[Epoch 114; Iter  1019/ 1097] train: loss: 0.2298121
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0094226
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0279935
[Epoch 114] ogbg-molhiv: 0.808963 val loss: 0.124704
[Epoch 114] ogbg-molhiv: 0.758502 test loss: 0.254840
[Epoch 115; Iter    12/ 1097] train: loss: 0.0018941
[Epoch 115; Iter    42/ 1097] train: loss: 0.1617299
[Epoch 115; Iter    72/ 1097] train: loss: 0.0104115
[Epoch 115; Iter   102/ 1097] train: loss: 0.0480625
[Epoch 115; Iter   132/ 1097] train: loss: 0.0088676
[Epoch 115; Iter   162/ 1097] train: loss: 0.0286446
[Epoch 115; Iter   192/ 1097] train: loss: 0.0109902
[Epoch 115; Iter   222/ 1097] train: loss: 0.0026816
[Epoch 115; Iter   252/ 1097] train: loss: 0.0101675
[Epoch 115; Iter   282/ 1097] train: loss: 0.0307530
[Epoch 115; Iter   312/ 1097] train: loss: 0.0016109
[Epoch 115; Iter   342/ 1097] train: loss: 0.0187027
[Epoch 115; Iter   372/ 1097] train: loss: 0.0031049
[Epoch 115; Iter   402/ 1097] train: loss: 0.0018870
[Epoch 115; Iter   432/ 1097] train: loss: 0.0639330
[Epoch 115; Iter   462/ 1097] train: loss: 0.0010880
[Epoch 115; Iter   492/ 1097] train: loss: 0.0186328
[Epoch 115; Iter   522/ 1097] train: loss: 0.0757971
[Epoch 115; Iter   552/ 1097] train: loss: 0.0211266
[Epoch 115; Iter   582/ 1097] train: loss: 0.0013462
[Epoch 115; Iter   612/ 1097] train: loss: 0.1132284
[Epoch 115; Iter   642/ 1097] train: loss: 0.0084588
[Epoch 115; Iter   672/ 1097] train: loss: 0.0294630
[Epoch 115; Iter   702/ 1097] train: loss: 0.0144076
[Epoch 115; Iter   732/ 1097] train: loss: 0.0015948
[Epoch 115; Iter   762/ 1097] train: loss: 0.0089557
[Epoch 115; Iter   792/ 1097] train: loss: 0.0232159
[Epoch 115; Iter   822/ 1097] train: loss: 0.0098866
[Epoch 115; Iter   852/ 1097] train: loss: 0.0462635
[Epoch 115; Iter   882/ 1097] train: loss: 0.0121308
[Epoch 115; Iter   912/ 1097] train: loss: 0.0055353
[Epoch 115; Iter   942/ 1097] train: loss: 0.0639217
[Epoch 115; Iter   972/ 1097] train: loss: 0.0116691
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0251752
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0110936
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0850240
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0556093
[Epoch 115] ogbg-molhiv: 0.807353 val loss: 0.128957
[Epoch 115] ogbg-molhiv: 0.756343 test loss: 0.258785
[Epoch 116; Iter    25/ 1097] train: loss: 0.0068809
[Epoch 116; Iter    55/ 1097] train: loss: 0.0087569
[Epoch 116; Iter    85/ 1097] train: loss: 0.0043373
[Epoch 116; Iter   115/ 1097] train: loss: 0.0020524
[Epoch 116; Iter   145/ 1097] train: loss: 0.0280564
[Epoch 116; Iter   175/ 1097] train: loss: 0.0199819
[Epoch 116; Iter   205/ 1097] train: loss: 0.1092475
[Epoch 116; Iter   235/ 1097] train: loss: 0.0029351
[Epoch 116; Iter   265/ 1097] train: loss: 0.0128429
[Epoch 116; Iter   295/ 1097] train: loss: 0.2557722
[Epoch 116; Iter   325/ 1097] train: loss: 0.0220891
[Epoch 116; Iter   355/ 1097] train: loss: 0.0030283
[Epoch 116; Iter   385/ 1097] train: loss: 0.0168887
[Epoch 116; Iter   415/ 1097] train: loss: 0.0019831
[Epoch 116; Iter   445/ 1097] train: loss: 0.0004644
[Epoch 116; Iter   475/ 1097] train: loss: 0.0033856
[Epoch 116; Iter   505/ 1097] train: loss: 0.0014903
[Epoch 116; Iter   535/ 1097] train: loss: 0.0015309
[Epoch 116; Iter   565/ 1097] train: loss: 0.0011129
[Epoch 116; Iter   595/ 1097] train: loss: 0.0204715
[Epoch 116; Iter   625/ 1097] train: loss: 0.0019042
[Epoch 116; Iter   655/ 1097] train: loss: 0.0021249
[Epoch 116; Iter   685/ 1097] train: loss: 0.0018672
[Epoch 116; Iter   715/ 1097] train: loss: 0.0041180
[Epoch 116; Iter   745/ 1097] train: loss: 0.1972420
[Epoch 116; Iter   775/ 1097] train: loss: 0.0750792
[Epoch 116; Iter   805/ 1097] train: loss: 0.0386982
[Epoch 116; Iter   835/ 1097] train: loss: 0.0083324
[Epoch 116; Iter   865/ 1097] train: loss: 0.0134986
[Epoch 116; Iter   895/ 1097] train: loss: 0.0020004
[Epoch 116; Iter   925/ 1097] train: loss: 0.0042924
[Epoch 116; Iter   955/ 1097] train: loss: 0.0076137
[Epoch 116; Iter   985/ 1097] train: loss: 0.0010191
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0477505
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0006893
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0025561
[Epoch 116] ogbg-molhiv: 0.816643 val loss: 0.121626
[Epoch 116] ogbg-molhiv: 0.755349 test loss: 0.252813
[Epoch 117; Iter     8/ 1097] train: loss: 0.1032066
[Epoch 117; Iter    38/ 1097] train: loss: 0.0265436
[Epoch 117; Iter    68/ 1097] train: loss: 0.0005741
[Epoch 117; Iter    98/ 1097] train: loss: 0.0760259
[Epoch 117; Iter   128/ 1097] train: loss: 0.0754994
[Epoch 117; Iter   158/ 1097] train: loss: 0.0247982
[Epoch 117; Iter   188/ 1097] train: loss: 0.0038786
[Epoch 117; Iter   218/ 1097] train: loss: 0.0133671
[Epoch 117; Iter   248/ 1097] train: loss: 0.0080307
[Epoch 117; Iter   278/ 1097] train: loss: 0.0479515
[Epoch 117; Iter   308/ 1097] train: loss: 0.0042391
[Epoch 117; Iter   338/ 1097] train: loss: 0.0006060
[Epoch 117; Iter   368/ 1097] train: loss: 0.0240367
[Epoch 117; Iter   398/ 1097] train: loss: 0.0023156
[Epoch 117; Iter   428/ 1097] train: loss: 0.0017538
[Epoch 117; Iter   458/ 1097] train: loss: 0.0064967
[Epoch 117; Iter   488/ 1097] train: loss: 0.0643255
[Epoch 117; Iter   518/ 1097] train: loss: 0.0411351
[Epoch 117; Iter   548/ 1097] train: loss: 0.0119799
[Epoch 117; Iter   578/ 1097] train: loss: 0.0652401
[Epoch 117; Iter   608/ 1097] train: loss: 0.0515792
[Epoch 117; Iter   638/ 1097] train: loss: 0.0097082
[Epoch 117; Iter   668/ 1097] train: loss: 0.0064359
[Epoch 113; Iter   706/ 1097] train: loss: 0.0015246
[Epoch 113; Iter   736/ 1097] train: loss: 0.0354875
[Epoch 113; Iter   766/ 1097] train: loss: 0.0008663
[Epoch 113; Iter   796/ 1097] train: loss: 0.0720425
[Epoch 113; Iter   826/ 1097] train: loss: 0.0181087
[Epoch 113; Iter   856/ 1097] train: loss: 0.0017100
[Epoch 113; Iter   886/ 1097] train: loss: 0.0175808
[Epoch 113; Iter   916/ 1097] train: loss: 0.0063673
[Epoch 113; Iter   946/ 1097] train: loss: 0.0079686
[Epoch 113; Iter   976/ 1097] train: loss: 0.0746047
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0009724
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0054050
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0002052
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0358837
[Epoch 113] ogbg-molhiv: 0.772943 val loss: 0.159077
[Epoch 113] ogbg-molhiv: 0.746905 test loss: 0.274797
[Epoch 114; Iter    29/ 1097] train: loss: 0.0044882
[Epoch 114; Iter    59/ 1097] train: loss: 0.0102481
[Epoch 114; Iter    89/ 1097] train: loss: 0.0257949
[Epoch 114; Iter   119/ 1097] train: loss: 0.0012636
[Epoch 114; Iter   149/ 1097] train: loss: 0.0532906
[Epoch 114; Iter   179/ 1097] train: loss: 0.0024666
[Epoch 114; Iter   209/ 1097] train: loss: 0.0242420
[Epoch 114; Iter   239/ 1097] train: loss: 0.0005228
[Epoch 114; Iter   269/ 1097] train: loss: 0.0005965
[Epoch 114; Iter   299/ 1097] train: loss: 0.0047628
[Epoch 114; Iter   329/ 1097] train: loss: 0.0012181
[Epoch 114; Iter   359/ 1097] train: loss: 0.0024697
[Epoch 114; Iter   389/ 1097] train: loss: 0.0014395
[Epoch 114; Iter   419/ 1097] train: loss: 0.0062871
[Epoch 114; Iter   449/ 1097] train: loss: 0.0198068
[Epoch 114; Iter   479/ 1097] train: loss: 0.0178917
[Epoch 114; Iter   509/ 1097] train: loss: 0.0184867
[Epoch 114; Iter   539/ 1097] train: loss: 0.0088820
[Epoch 114; Iter   569/ 1097] train: loss: 0.0119239
[Epoch 114; Iter   599/ 1097] train: loss: 0.0494370
[Epoch 114; Iter   629/ 1097] train: loss: 0.0308019
[Epoch 114; Iter   659/ 1097] train: loss: 0.0213326
[Epoch 114; Iter   689/ 1097] train: loss: 0.0082671
[Epoch 114; Iter   719/ 1097] train: loss: 0.0005520
[Epoch 114; Iter   749/ 1097] train: loss: 0.0015561
[Epoch 114; Iter   779/ 1097] train: loss: 0.0064550
[Epoch 114; Iter   809/ 1097] train: loss: 0.0011057
[Epoch 114; Iter   839/ 1097] train: loss: 0.1733100
[Epoch 114; Iter   869/ 1097] train: loss: 0.0568379
[Epoch 114; Iter   899/ 1097] train: loss: 0.0087807
[Epoch 114; Iter   929/ 1097] train: loss: 0.0008162
[Epoch 114; Iter   959/ 1097] train: loss: 0.0284769
[Epoch 114; Iter   989/ 1097] train: loss: 0.0101812
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0017230
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0013420
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0181208
[Epoch 114] ogbg-molhiv: 0.774961 val loss: 0.158931
[Epoch 114] ogbg-molhiv: 0.747896 test loss: 0.270680
[Epoch 115; Iter    12/ 1097] train: loss: 0.0029910
[Epoch 115; Iter    42/ 1097] train: loss: 0.0006033
[Epoch 115; Iter    72/ 1097] train: loss: 0.0027267
[Epoch 115; Iter   102/ 1097] train: loss: 0.0008046
[Epoch 115; Iter   132/ 1097] train: loss: 0.0059579
[Epoch 115; Iter   162/ 1097] train: loss: 0.0033266
[Epoch 115; Iter   192/ 1097] train: loss: 0.0019361
[Epoch 115; Iter   222/ 1097] train: loss: 0.0009616
[Epoch 115; Iter   252/ 1097] train: loss: 0.0143906
[Epoch 115; Iter   282/ 1097] train: loss: 0.0045671
[Epoch 115; Iter   312/ 1097] train: loss: 0.0032553
[Epoch 115; Iter   342/ 1097] train: loss: 0.0034918
[Epoch 115; Iter   372/ 1097] train: loss: 0.0021249
[Epoch 115; Iter   402/ 1097] train: loss: 0.0010056
[Epoch 115; Iter   432/ 1097] train: loss: 0.0220822
[Epoch 115; Iter   462/ 1097] train: loss: 0.0023794
[Epoch 115; Iter   492/ 1097] train: loss: 0.0061973
[Epoch 115; Iter   522/ 1097] train: loss: 0.0156565
[Epoch 115; Iter   552/ 1097] train: loss: 0.0033264
[Epoch 115; Iter   582/ 1097] train: loss: 0.0164074
[Epoch 115; Iter   612/ 1097] train: loss: 0.0009314
[Epoch 115; Iter   642/ 1097] train: loss: 0.0019726
[Epoch 115; Iter   672/ 1097] train: loss: 0.0702487
[Epoch 115; Iter   702/ 1097] train: loss: 0.0007432
[Epoch 115; Iter   732/ 1097] train: loss: 0.0011663
[Epoch 115; Iter   762/ 1097] train: loss: 0.0005367
[Epoch 115; Iter   792/ 1097] train: loss: 0.0017224
[Epoch 115; Iter   822/ 1097] train: loss: 0.0486938
[Epoch 115; Iter   852/ 1097] train: loss: 0.0012111
[Epoch 115; Iter   882/ 1097] train: loss: 0.0013103
[Epoch 115; Iter   912/ 1097] train: loss: 0.0018874
[Epoch 115; Iter   942/ 1097] train: loss: 0.0027772
[Epoch 115; Iter   972/ 1097] train: loss: 0.0247280
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0281707
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0236275
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0268462
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0039720
[Epoch 115] ogbg-molhiv: 0.773963 val loss: 0.161327
[Epoch 115] ogbg-molhiv: 0.744978 test loss: 0.278473
[Epoch 116; Iter    25/ 1097] train: loss: 0.0002902
[Epoch 116; Iter    55/ 1097] train: loss: 0.0037871
[Epoch 116; Iter    85/ 1097] train: loss: 0.0019467
[Epoch 116; Iter   115/ 1097] train: loss: 0.0009517
[Epoch 116; Iter   145/ 1097] train: loss: 0.0588870
[Epoch 116; Iter   175/ 1097] train: loss: 0.0047460
[Epoch 116; Iter   205/ 1097] train: loss: 0.0006079
[Epoch 116; Iter   235/ 1097] train: loss: 0.0013324
[Epoch 116; Iter   265/ 1097] train: loss: 0.0008559
[Epoch 116; Iter   295/ 1097] train: loss: 0.0044425
[Epoch 116; Iter   325/ 1097] train: loss: 0.0142018
[Epoch 116; Iter   355/ 1097] train: loss: 0.0010875
[Epoch 116; Iter   385/ 1097] train: loss: 0.0164929
[Epoch 116; Iter   415/ 1097] train: loss: 0.0025465
[Epoch 116; Iter   445/ 1097] train: loss: 0.0019965
[Epoch 116; Iter   475/ 1097] train: loss: 0.0087027
[Epoch 116; Iter   505/ 1097] train: loss: 0.0268239
[Epoch 116; Iter   535/ 1097] train: loss: 0.0024724
[Epoch 116; Iter   565/ 1097] train: loss: 0.0022815
[Epoch 116; Iter   595/ 1097] train: loss: 0.0016831
[Epoch 116; Iter   625/ 1097] train: loss: 0.0012433
[Epoch 116; Iter   655/ 1097] train: loss: 0.0031764
[Epoch 116; Iter   685/ 1097] train: loss: 0.0004461
[Epoch 116; Iter   715/ 1097] train: loss: 0.0109929
[Epoch 116; Iter   745/ 1097] train: loss: 0.0020489
[Epoch 116; Iter   775/ 1097] train: loss: 0.0008983
[Epoch 116; Iter   805/ 1097] train: loss: 0.0030926
[Epoch 116; Iter   835/ 1097] train: loss: 0.0008042
[Epoch 116; Iter   865/ 1097] train: loss: 0.0032663
[Epoch 116; Iter   895/ 1097] train: loss: 0.0296737
[Epoch 116; Iter   925/ 1097] train: loss: 0.0153929
[Epoch 116; Iter   955/ 1097] train: loss: 0.0079610
[Epoch 116; Iter   985/ 1097] train: loss: 0.1318215
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0079653
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0010486
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0898787
[Epoch 116] ogbg-molhiv: 0.771094 val loss: 0.167086
[Epoch 116] ogbg-molhiv: 0.742430 test loss: 0.278892
[Epoch 117; Iter     8/ 1097] train: loss: 0.0018328
[Epoch 117; Iter    38/ 1097] train: loss: 0.0056758
[Epoch 117; Iter    68/ 1097] train: loss: 0.0050871
[Epoch 117; Iter    98/ 1097] train: loss: 0.1312319
[Epoch 117; Iter   128/ 1097] train: loss: 0.0213731
[Epoch 117; Iter   158/ 1097] train: loss: 0.0655659
[Epoch 117; Iter   188/ 1097] train: loss: 0.0011220
[Epoch 117; Iter   218/ 1097] train: loss: 0.0479034
[Epoch 117; Iter   248/ 1097] train: loss: 0.0140584
[Epoch 117; Iter   278/ 1097] train: loss: 0.0127532
[Epoch 117; Iter   308/ 1097] train: loss: 0.0057072
[Epoch 117; Iter   338/ 1097] train: loss: 0.1110065
[Epoch 117; Iter   368/ 1097] train: loss: 0.0015498
[Epoch 117; Iter   398/ 1097] train: loss: 0.0029049
[Epoch 117; Iter   428/ 1097] train: loss: 0.0026118
[Epoch 117; Iter   458/ 1097] train: loss: 0.0285608
[Epoch 117; Iter   488/ 1097] train: loss: 0.0007157
[Epoch 117; Iter   518/ 1097] train: loss: 0.0859729
[Epoch 117; Iter   548/ 1097] train: loss: 0.0078737
[Epoch 117; Iter   578/ 1097] train: loss: 0.0305383
[Epoch 117; Iter   608/ 1097] train: loss: 0.0049454
[Epoch 117; Iter   638/ 1097] train: loss: 0.0242025
[Epoch 117; Iter   668/ 1097] train: loss: 0.0020573
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   698/ 1097] train: loss: 0.0069483
[Epoch 117; Iter   728/ 1097] train: loss: 0.0116139
[Epoch 117; Iter   758/ 1097] train: loss: 0.0068317
[Epoch 117; Iter   788/ 1097] train: loss: 0.0081444
[Epoch 117; Iter   818/ 1097] train: loss: 0.0066440
[Epoch 117; Iter   848/ 1097] train: loss: 0.1460915
[Epoch 117; Iter   878/ 1097] train: loss: 0.0021943
[Epoch 117; Iter   908/ 1097] train: loss: 0.0210456
[Epoch 117; Iter   938/ 1097] train: loss: 0.0035791
[Epoch 117; Iter   968/ 1097] train: loss: 0.0014458
[Epoch 117; Iter   998/ 1097] train: loss: 0.0196918
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0347994
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0332821
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0053692
[Epoch 117] ogbg-molhiv: 0.816970 val loss: 0.141891
[Epoch 117] ogbg-molhiv: 0.748520 test loss: 0.271559
[Epoch 118; Iter    21/ 1097] train: loss: 0.0214214
[Epoch 118; Iter    51/ 1097] train: loss: 0.0008218
[Epoch 118; Iter    81/ 1097] train: loss: 0.0257259
[Epoch 118; Iter   111/ 1097] train: loss: 0.0034828
[Epoch 118; Iter   141/ 1097] train: loss: 0.0740932
[Epoch 118; Iter   171/ 1097] train: loss: 0.0012817
[Epoch 118; Iter   201/ 1097] train: loss: 0.0023546
[Epoch 118; Iter   231/ 1097] train: loss: 0.0200550
[Epoch 118; Iter   261/ 1097] train: loss: 0.0007305
[Epoch 118; Iter   291/ 1097] train: loss: 0.0257373
[Epoch 118; Iter   321/ 1097] train: loss: 0.0027193
[Epoch 118; Iter   351/ 1097] train: loss: 0.0044039
[Epoch 118; Iter   381/ 1097] train: loss: 0.0011479
[Epoch 118; Iter   411/ 1097] train: loss: 0.0065287
[Epoch 118; Iter   441/ 1097] train: loss: 0.0133646
[Epoch 118; Iter   471/ 1097] train: loss: 0.0087988
[Epoch 118; Iter   501/ 1097] train: loss: 0.0013159
[Epoch 118; Iter   531/ 1097] train: loss: 0.0012845
[Epoch 118; Iter   561/ 1097] train: loss: 0.0864987
[Epoch 118; Iter   591/ 1097] train: loss: 0.0018302
[Epoch 118; Iter   621/ 1097] train: loss: 0.0771786
[Epoch 118; Iter   651/ 1097] train: loss: 0.0684294
[Epoch 118; Iter   681/ 1097] train: loss: 0.0025302
[Epoch 118; Iter   711/ 1097] train: loss: 0.0099362
[Epoch 118; Iter   741/ 1097] train: loss: 0.0005633
[Epoch 118; Iter   771/ 1097] train: loss: 0.0050398
[Epoch 118; Iter   801/ 1097] train: loss: 0.0011267
[Epoch 118; Iter   831/ 1097] train: loss: 0.0246265
[Epoch 118; Iter   861/ 1097] train: loss: 0.0011672
[Epoch 118; Iter   891/ 1097] train: loss: 0.0047752
[Epoch 118; Iter   921/ 1097] train: loss: 0.0020004
[Epoch 118; Iter   951/ 1097] train: loss: 0.0040198
[Epoch 118; Iter   981/ 1097] train: loss: 0.0005840
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0485963
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0005190
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0005198
[Epoch 118] ogbg-molhiv: 0.823453 val loss: 0.141896
[Epoch 118] ogbg-molhiv: 0.747144 test loss: 0.272572
[Epoch 119; Iter     4/ 1097] train: loss: 0.0019769
[Epoch 119; Iter    34/ 1097] train: loss: 0.0057202
[Epoch 119; Iter    64/ 1097] train: loss: 0.0258223
[Epoch 119; Iter    94/ 1097] train: loss: 0.0034554
[Epoch 119; Iter   124/ 1097] train: loss: 0.0010369
[Epoch 119; Iter   154/ 1097] train: loss: 0.0460875
[Epoch 119; Iter   184/ 1097] train: loss: 0.0308128
[Epoch 119; Iter   214/ 1097] train: loss: 0.0006822
[Epoch 119; Iter   244/ 1097] train: loss: 0.0049258
[Epoch 119; Iter   274/ 1097] train: loss: 0.0276655
[Epoch 119; Iter   304/ 1097] train: loss: 0.0081909
[Epoch 119; Iter   334/ 1097] train: loss: 0.0003719
[Epoch 119; Iter   364/ 1097] train: loss: 0.0007606
[Epoch 119; Iter   394/ 1097] train: loss: 0.0012021
[Epoch 119; Iter   424/ 1097] train: loss: 0.0146518
[Epoch 119; Iter   454/ 1097] train: loss: 0.0004163
[Epoch 119; Iter   484/ 1097] train: loss: 0.0115081
[Epoch 119; Iter   514/ 1097] train: loss: 0.0047418
[Epoch 119; Iter   544/ 1097] train: loss: 0.0006571
[Epoch 119; Iter   574/ 1097] train: loss: 0.0227866
[Epoch 119; Iter   604/ 1097] train: loss: 0.0006712
[Epoch 119; Iter   634/ 1097] train: loss: 0.0185553
[Epoch 119; Iter   664/ 1097] train: loss: 0.0000794
[Epoch 119; Iter   694/ 1097] train: loss: 0.0042276
[Epoch 119; Iter   724/ 1097] train: loss: 0.0689484
[Epoch 119; Iter   754/ 1097] train: loss: 0.0285035
[Epoch 119; Iter   784/ 1097] train: loss: 0.1071374
[Epoch 119; Iter   814/ 1097] train: loss: 0.0007815
[Epoch 119; Iter   844/ 1097] train: loss: 0.0079480
[Epoch 119; Iter   874/ 1097] train: loss: 0.0380236
[Epoch 119; Iter   904/ 1097] train: loss: 0.0008413
[Epoch 119; Iter   934/ 1097] train: loss: 0.0390025
[Epoch 119; Iter   964/ 1097] train: loss: 0.0143705
[Epoch 119; Iter   994/ 1097] train: loss: 0.0337296
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0136609
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0140481
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0142830
[Epoch 119] ogbg-molhiv: 0.817665 val loss: 0.144331
[Epoch 119] ogbg-molhiv: 0.748935 test loss: 0.276531
[Epoch 120; Iter    17/ 1097] train: loss: 0.0002680
[Epoch 120; Iter    47/ 1097] train: loss: 0.0021658
[Epoch 120; Iter    77/ 1097] train: loss: 0.0099355
[Epoch 120; Iter   107/ 1097] train: loss: 0.0011538
[Epoch 120; Iter   137/ 1097] train: loss: 0.0018391
[Epoch 120; Iter   167/ 1097] train: loss: 0.0042291
[Epoch 120; Iter   197/ 1097] train: loss: 0.0559616
[Epoch 120; Iter   227/ 1097] train: loss: 0.0345233
[Epoch 120; Iter   257/ 1097] train: loss: 0.0038587
[Epoch 120; Iter   287/ 1097] train: loss: 0.0036306
[Epoch 120; Iter   317/ 1097] train: loss: 0.0028405
[Epoch 120; Iter   347/ 1097] train: loss: 0.0009365
[Epoch 120; Iter   377/ 1097] train: loss: 0.0078281
[Epoch 120; Iter   407/ 1097] train: loss: 0.0140805
[Epoch 120; Iter   437/ 1097] train: loss: 0.0112143
[Epoch 120; Iter   467/ 1097] train: loss: 0.0009561
[Epoch 120; Iter   497/ 1097] train: loss: 0.0001848
[Epoch 120; Iter   527/ 1097] train: loss: 0.0028512
[Epoch 120; Iter   557/ 1097] train: loss: 0.0019202
[Epoch 120; Iter   587/ 1097] train: loss: 0.0118061
[Epoch 120; Iter   617/ 1097] train: loss: 0.0026815
[Epoch 120; Iter   647/ 1097] train: loss: 0.0013761
[Epoch 120; Iter   677/ 1097] train: loss: 0.0046423
[Epoch 120; Iter   707/ 1097] train: loss: 0.0165737
[Epoch 120; Iter   737/ 1097] train: loss: 0.0031250
[Epoch 120; Iter   767/ 1097] train: loss: 0.0021559
[Epoch 120; Iter   797/ 1097] train: loss: 0.0007633
[Epoch 120; Iter   827/ 1097] train: loss: 0.0150182
[Epoch 120; Iter   857/ 1097] train: loss: 0.0067184
[Epoch 120; Iter   887/ 1097] train: loss: 0.0026714
[Epoch 120; Iter   917/ 1097] train: loss: 0.0016909
[Epoch 120; Iter   947/ 1097] train: loss: 0.1105981
[Epoch 120; Iter   977/ 1097] train: loss: 0.0017715
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0001556
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0015957
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0003552
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0053742
[Epoch 120] ogbg-molhiv: 0.815167 val loss: 0.144669
[Epoch 120] ogbg-molhiv: 0.741254 test loss: 0.280913
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: -6.222320079803467
std_pred: 2.772284746170044
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.3154579043165451
rocauc: 0.8469864540466393
ogbg-molhiv: 0.8469864540466393
BCEWithLogitsLoss: 0.08088434121885296
Statistics on  test
mean_pred: -6.207989692687988
std_pred: 8.33714485168457
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2417898012475858
rocauc: 0.7540122443461635
ogbg-molhiv: 0.7540122443461635
BCEWithLogitsLoss: 0.14427473818532366
Statistics on  train
mean_pred: -6.135516166687012
std_pred: 2.5519304275512695
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.7219494756787904
rocauc: 0.9784928868535866
ogbg-molhiv: 0.9784928868535866
BCEWithLogitsLoss: 0.06379485102442543
[Epoch 117; Iter   698/ 1097] train: loss: 0.0518596
[Epoch 117; Iter   728/ 1097] train: loss: 0.0043614
[Epoch 117; Iter   758/ 1097] train: loss: 0.0013466
[Epoch 117; Iter   788/ 1097] train: loss: 0.0158264
[Epoch 117; Iter   818/ 1097] train: loss: 0.0079006
[Epoch 117; Iter   848/ 1097] train: loss: 0.0087839
[Epoch 117; Iter   878/ 1097] train: loss: 0.0031024
[Epoch 117; Iter   908/ 1097] train: loss: 0.0043990
[Epoch 117; Iter   938/ 1097] train: loss: 0.0063577
[Epoch 117; Iter   968/ 1097] train: loss: 0.1531341
[Epoch 117; Iter   998/ 1097] train: loss: 0.0037781
[Epoch 117; Iter  1028/ 1097] train: loss: 0.1222296
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0287643
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0101915
[Epoch 117] ogbg-molhiv: 0.811177 val loss: 0.129654
[Epoch 117] ogbg-molhiv: 0.758740 test loss: 0.254253
[Epoch 118; Iter    21/ 1097] train: loss: 0.0008624
[Epoch 118; Iter    51/ 1097] train: loss: 0.0706424
[Epoch 118; Iter    81/ 1097] train: loss: 0.0107808
[Epoch 118; Iter   111/ 1097] train: loss: 0.0149768
[Epoch 118; Iter   141/ 1097] train: loss: 0.0025345
[Epoch 118; Iter   171/ 1097] train: loss: 0.0022841
[Epoch 118; Iter   201/ 1097] train: loss: 0.0222642
[Epoch 118; Iter   231/ 1097] train: loss: 0.0165173
[Epoch 118; Iter   261/ 1097] train: loss: 0.0304933
[Epoch 118; Iter   291/ 1097] train: loss: 0.0478996
[Epoch 118; Iter   321/ 1097] train: loss: 0.0281984
[Epoch 118; Iter   351/ 1097] train: loss: 0.0104254
[Epoch 118; Iter   381/ 1097] train: loss: 0.1521017
[Epoch 118; Iter   411/ 1097] train: loss: 0.0147835
[Epoch 118; Iter   441/ 1097] train: loss: 0.0075115
[Epoch 118; Iter   471/ 1097] train: loss: 0.0347128
[Epoch 118; Iter   501/ 1097] train: loss: 0.0231512
[Epoch 118; Iter   531/ 1097] train: loss: 0.0047477
[Epoch 118; Iter   561/ 1097] train: loss: 0.1400605
[Epoch 118; Iter   591/ 1097] train: loss: 0.0084650
[Epoch 118; Iter   621/ 1097] train: loss: 0.0085871
[Epoch 118; Iter   651/ 1097] train: loss: 0.0177423
[Epoch 118; Iter   681/ 1097] train: loss: 0.0327569
[Epoch 118; Iter   711/ 1097] train: loss: 0.0031730
[Epoch 118; Iter   741/ 1097] train: loss: 0.0057461
[Epoch 118; Iter   771/ 1097] train: loss: 0.0084673
[Epoch 118; Iter   801/ 1097] train: loss: 0.1260741
[Epoch 118; Iter   831/ 1097] train: loss: 0.0339851
[Epoch 118; Iter   861/ 1097] train: loss: 0.0082488
[Epoch 118; Iter   891/ 1097] train: loss: 0.0090120
[Epoch 118; Iter   921/ 1097] train: loss: 0.0002864
[Epoch 118; Iter   951/ 1097] train: loss: 0.0031077
[Epoch 118; Iter   981/ 1097] train: loss: 0.0117709
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0018504
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0044562
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0096073
[Epoch 118] ogbg-molhiv: 0.808761 val loss: 0.126446
[Epoch 118] ogbg-molhiv: 0.753313 test loss: 0.258247
[Epoch 119; Iter     4/ 1097] train: loss: 0.0056224
[Epoch 119; Iter    34/ 1097] train: loss: 0.0008715
[Epoch 119; Iter    64/ 1097] train: loss: 0.1170216
[Epoch 119; Iter    94/ 1097] train: loss: 0.0165626
[Epoch 119; Iter   124/ 1097] train: loss: 0.0102662
[Epoch 119; Iter   154/ 1097] train: loss: 0.0007939
[Epoch 119; Iter   184/ 1097] train: loss: 0.0018876
[Epoch 119; Iter   214/ 1097] train: loss: 0.0563530
[Epoch 119; Iter   244/ 1097] train: loss: 0.0084369
[Epoch 119; Iter   274/ 1097] train: loss: 0.0773049
[Epoch 119; Iter   304/ 1097] train: loss: 0.0172899
[Epoch 119; Iter   334/ 1097] train: loss: 0.0049126
[Epoch 119; Iter   364/ 1097] train: loss: 0.0409217
[Epoch 119; Iter   394/ 1097] train: loss: 0.0104452
[Epoch 119; Iter   424/ 1097] train: loss: 0.0334297
[Epoch 119; Iter   454/ 1097] train: loss: 0.0030034
[Epoch 119; Iter   484/ 1097] train: loss: 0.0170321
[Epoch 119; Iter   514/ 1097] train: loss: 0.0015197
[Epoch 119; Iter   544/ 1097] train: loss: 0.1044889
[Epoch 119; Iter   574/ 1097] train: loss: 0.0218778
[Epoch 119; Iter   604/ 1097] train: loss: 0.0122635
[Epoch 119; Iter   634/ 1097] train: loss: 0.1145229
[Epoch 119; Iter   664/ 1097] train: loss: 0.0160945
[Epoch 119; Iter   694/ 1097] train: loss: 0.0018714
[Epoch 119; Iter   724/ 1097] train: loss: 0.0031465
[Epoch 119; Iter   754/ 1097] train: loss: 0.0157021
[Epoch 119; Iter   784/ 1097] train: loss: 0.0255922
[Epoch 119; Iter   814/ 1097] train: loss: 0.0153527
[Epoch 119; Iter   844/ 1097] train: loss: 0.0022738
[Epoch 119; Iter   874/ 1097] train: loss: 0.0016420
[Epoch 119; Iter   904/ 1097] train: loss: 0.0899669
[Epoch 119; Iter   934/ 1097] train: loss: 0.0122984
[Epoch 119; Iter   964/ 1097] train: loss: 0.0286413
[Epoch 119; Iter   994/ 1097] train: loss: 0.0174933
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0026269
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0801449
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0008295
[Epoch 119] ogbg-molhiv: 0.807723 val loss: 0.128354
[Epoch 119] ogbg-molhiv: 0.751585 test loss: 0.262863
[Epoch 120; Iter    17/ 1097] train: loss: 0.0027335
[Epoch 120; Iter    47/ 1097] train: loss: 0.0251467
[Epoch 120; Iter    77/ 1097] train: loss: 0.0126843
[Epoch 120; Iter   107/ 1097] train: loss: 0.0101886
[Epoch 120; Iter   137/ 1097] train: loss: 0.0086560
[Epoch 120; Iter   167/ 1097] train: loss: 0.1283187
[Epoch 120; Iter   197/ 1097] train: loss: 0.0388971
[Epoch 120; Iter   227/ 1097] train: loss: 0.0014356
[Epoch 120; Iter   257/ 1097] train: loss: 0.0022419
[Epoch 120; Iter   287/ 1097] train: loss: 0.0258677
[Epoch 120; Iter   317/ 1097] train: loss: 0.0206906
[Epoch 120; Iter   347/ 1097] train: loss: 0.0582055
[Epoch 120; Iter   377/ 1097] train: loss: 0.0179682
[Epoch 120; Iter   407/ 1097] train: loss: 0.0014238
[Epoch 120; Iter   437/ 1097] train: loss: 0.1310880
[Epoch 120; Iter   467/ 1097] train: loss: 0.0077958
[Epoch 120; Iter   497/ 1097] train: loss: 0.0052712
[Epoch 120; Iter   527/ 1097] train: loss: 0.0097492
[Epoch 120; Iter   557/ 1097] train: loss: 0.0118243
[Epoch 120; Iter   587/ 1097] train: loss: 0.0607203
[Epoch 120; Iter   617/ 1097] train: loss: 0.0102276
[Epoch 120; Iter   647/ 1097] train: loss: 0.0287420
[Epoch 120; Iter   677/ 1097] train: loss: 0.0098633
[Epoch 120; Iter   707/ 1097] train: loss: 0.0012319
[Epoch 120; Iter   737/ 1097] train: loss: 0.0649315
[Epoch 120; Iter   767/ 1097] train: loss: 0.1023776
[Epoch 120; Iter   797/ 1097] train: loss: 0.0666817
[Epoch 120; Iter   827/ 1097] train: loss: 0.0061986
[Epoch 120; Iter   857/ 1097] train: loss: 0.0100244
[Epoch 120; Iter   887/ 1097] train: loss: 0.0044094
[Epoch 120; Iter   917/ 1097] train: loss: 0.0048445
[Epoch 120; Iter   947/ 1097] train: loss: 0.0559856
[Epoch 120; Iter   977/ 1097] train: loss: 0.0190663
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0096548
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0008121
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0576062
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0052611
[Epoch 120] ogbg-molhiv: 0.813143 val loss: 0.127218
[Epoch 120] ogbg-molhiv: 0.760254 test loss: 0.259853
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 38.
Statistics on  val_best_checkpoint
mean_pred: -5.422186374664307
std_pred: 2.425560235977173
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.4153911534589403
rocauc: 0.8555108514599254
ogbg-molhiv: 0.8555108514599254
BCEWithLogitsLoss: 0.07566740775845297
Statistics on  test
mean_pred: -5.560190200805664
std_pred: 15.950389862060547
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.31495912145095545
rocauc: 0.7840746248479114
ogbg-molhiv: 0.7840746248479114
BCEWithLogitsLoss: 0.13001511935009688
Statistics on  train
mean_pred: -5.322820663452148
std_pred: 2.348346710205078
mean_targets: 0.03744566813111305
std_targets: 0.18985413014888763
prcauc: 0.6939479529894911
rocauc: 0.9614132926500698
ogbg-molhiv: 0.9614132926500698
BCEWithLogitsLoss: 0.07128966442473171
[Epoch 117; Iter   698/ 1097] train: loss: 0.0098487
[Epoch 117; Iter   728/ 1097] train: loss: 0.0983502
[Epoch 117; Iter   758/ 1097] train: loss: 0.0019733
[Epoch 117; Iter   788/ 1097] train: loss: 0.0131218
[Epoch 117; Iter   818/ 1097] train: loss: 0.0117493
[Epoch 117; Iter   848/ 1097] train: loss: 0.0089678
[Epoch 117; Iter   878/ 1097] train: loss: 0.0019340
[Epoch 117; Iter   908/ 1097] train: loss: 0.0025168
[Epoch 117; Iter   938/ 1097] train: loss: 0.0393679
[Epoch 117; Iter   968/ 1097] train: loss: 0.0035559
[Epoch 117; Iter   998/ 1097] train: loss: 0.0006300
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0011617
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0009570
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0007414
[Epoch 117] ogbg-molhiv: 0.784300 val loss: 0.151014
[Epoch 117] ogbg-molhiv: 0.749690 test loss: 0.265001
[Epoch 118; Iter    21/ 1097] train: loss: 0.0003609
[Epoch 118; Iter    51/ 1097] train: loss: 0.0029500
[Epoch 118; Iter    81/ 1097] train: loss: 0.0111760
[Epoch 118; Iter   111/ 1097] train: loss: 0.0007992
[Epoch 118; Iter   141/ 1097] train: loss: 0.0148468
[Epoch 118; Iter   171/ 1097] train: loss: 0.0028663
[Epoch 118; Iter   201/ 1097] train: loss: 0.0041874
[Epoch 118; Iter   231/ 1097] train: loss: 0.0840144
[Epoch 118; Iter   261/ 1097] train: loss: 0.0347483
[Epoch 118; Iter   291/ 1097] train: loss: 0.0189507
[Epoch 118; Iter   321/ 1097] train: loss: 0.0155793
[Epoch 118; Iter   351/ 1097] train: loss: 0.0107148
[Epoch 118; Iter   381/ 1097] train: loss: 0.0020936
[Epoch 118; Iter   411/ 1097] train: loss: 0.0669549
[Epoch 118; Iter   441/ 1097] train: loss: 0.0006479
[Epoch 118; Iter   471/ 1097] train: loss: 0.0134401
[Epoch 118; Iter   501/ 1097] train: loss: 0.0009671
[Epoch 118; Iter   531/ 1097] train: loss: 0.0131458
[Epoch 118; Iter   561/ 1097] train: loss: 0.0006621
[Epoch 118; Iter   591/ 1097] train: loss: 0.0046496
[Epoch 118; Iter   621/ 1097] train: loss: 0.0038023
[Epoch 118; Iter   651/ 1097] train: loss: 0.0587445
[Epoch 118; Iter   681/ 1097] train: loss: 0.0008314
[Epoch 118; Iter   711/ 1097] train: loss: 0.0190252
[Epoch 118; Iter   741/ 1097] train: loss: 0.0022419
[Epoch 118; Iter   771/ 1097] train: loss: 0.0062990
[Epoch 118; Iter   801/ 1097] train: loss: 0.0108243
[Epoch 118; Iter   831/ 1097] train: loss: 0.0413127
[Epoch 118; Iter   861/ 1097] train: loss: 0.0900934
[Epoch 118; Iter   891/ 1097] train: loss: 0.0365713
[Epoch 118; Iter   921/ 1097] train: loss: 0.0070339
[Epoch 118; Iter   951/ 1097] train: loss: 0.0002101
[Epoch 118; Iter   981/ 1097] train: loss: 0.1529707
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0024653
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0003898
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0000976
[Epoch 118] ogbg-molhiv: 0.776314 val loss: 0.158886
[Epoch 118] ogbg-molhiv: 0.750001 test loss: 0.274446
[Epoch 119; Iter     4/ 1097] train: loss: 0.0111771
[Epoch 119; Iter    34/ 1097] train: loss: 0.0005530
[Epoch 119; Iter    64/ 1097] train: loss: 0.0145757
[Epoch 119; Iter    94/ 1097] train: loss: 0.0029898
[Epoch 119; Iter   124/ 1097] train: loss: 0.0027549
[Epoch 119; Iter   154/ 1097] train: loss: 0.0206690
[Epoch 119; Iter   184/ 1097] train: loss: 0.0034830
[Epoch 119; Iter   214/ 1097] train: loss: 0.0015098
[Epoch 119; Iter   244/ 1097] train: loss: 0.0034957
[Epoch 119; Iter   274/ 1097] train: loss: 0.0013927
[Epoch 119; Iter   304/ 1097] train: loss: 0.1059380
[Epoch 119; Iter   334/ 1097] train: loss: 0.0097611
[Epoch 119; Iter   364/ 1097] train: loss: 0.0050163
[Epoch 119; Iter   394/ 1097] train: loss: 0.0601573
[Epoch 119; Iter   424/ 1097] train: loss: 0.0022558
[Epoch 119; Iter   454/ 1097] train: loss: 0.0025680
[Epoch 119; Iter   484/ 1097] train: loss: 0.0172658
[Epoch 119; Iter   514/ 1097] train: loss: 0.0320653
[Epoch 119; Iter   544/ 1097] train: loss: 0.0046391
[Epoch 119; Iter   574/ 1097] train: loss: 0.0065920
[Epoch 119; Iter   604/ 1097] train: loss: 0.0123519
[Epoch 119; Iter   634/ 1097] train: loss: 0.0103990
[Epoch 119; Iter   664/ 1097] train: loss: 0.0033692
[Epoch 119; Iter   694/ 1097] train: loss: 0.0038228
[Epoch 119; Iter   724/ 1097] train: loss: 0.0034645
[Epoch 119; Iter   754/ 1097] train: loss: 0.0354006
[Epoch 119; Iter   784/ 1097] train: loss: 0.0020561
[Epoch 119; Iter   814/ 1097] train: loss: 0.0568850
[Epoch 119; Iter   844/ 1097] train: loss: 0.0007058
[Epoch 119; Iter   874/ 1097] train: loss: 0.0049328
[Epoch 119; Iter   904/ 1097] train: loss: 0.0500081
[Epoch 119; Iter   934/ 1097] train: loss: 0.0083723
[Epoch 119; Iter   964/ 1097] train: loss: 0.0039520
[Epoch 119; Iter   994/ 1097] train: loss: 0.0003679
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0002185
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0009646
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0007003
[Epoch 119] ogbg-molhiv: 0.775797 val loss: 0.163410
[Epoch 119] ogbg-molhiv: 0.754744 test loss: 0.274225
[Epoch 120; Iter    17/ 1097] train: loss: 0.0085092
[Epoch 120; Iter    47/ 1097] train: loss: 0.0008179
[Epoch 120; Iter    77/ 1097] train: loss: 0.0026324
[Epoch 120; Iter   107/ 1097] train: loss: 0.0096220
[Epoch 120; Iter   137/ 1097] train: loss: 0.0432851
[Epoch 120; Iter   167/ 1097] train: loss: 0.0003894
[Epoch 120; Iter   197/ 1097] train: loss: 0.0038380
[Epoch 120; Iter   227/ 1097] train: loss: 0.0089948
[Epoch 120; Iter   257/ 1097] train: loss: 0.0051523
[Epoch 120; Iter   287/ 1097] train: loss: 0.0162727
[Epoch 120; Iter   317/ 1097] train: loss: 0.0016658
[Epoch 120; Iter   347/ 1097] train: loss: 0.0008785
[Epoch 120; Iter   377/ 1097] train: loss: 0.0063889
[Epoch 120; Iter   407/ 1097] train: loss: 0.0016339
[Epoch 120; Iter   437/ 1097] train: loss: 0.0026469
[Epoch 120; Iter   467/ 1097] train: loss: 0.0038867
[Epoch 120; Iter   497/ 1097] train: loss: 0.0051057
[Epoch 120; Iter   527/ 1097] train: loss: 0.0741288
[Epoch 120; Iter   557/ 1097] train: loss: 0.0032721
[Epoch 120; Iter   587/ 1097] train: loss: 0.0006765
[Epoch 120; Iter   617/ 1097] train: loss: 0.0036497
[Epoch 120; Iter   647/ 1097] train: loss: 0.0149442
[Epoch 120; Iter   677/ 1097] train: loss: 0.0070672
[Epoch 120; Iter   707/ 1097] train: loss: 0.2046953
[Epoch 120; Iter   737/ 1097] train: loss: 0.0058620
[Epoch 120; Iter   767/ 1097] train: loss: 0.0209954
[Epoch 120; Iter   797/ 1097] train: loss: 0.0030306
[Epoch 120; Iter   827/ 1097] train: loss: 0.0021318
[Epoch 120; Iter   857/ 1097] train: loss: 0.0011614
[Epoch 120; Iter   887/ 1097] train: loss: 0.0036304
[Epoch 120; Iter   917/ 1097] train: loss: 0.0499360
[Epoch 120; Iter   947/ 1097] train: loss: 0.0128861
[Epoch 120; Iter   977/ 1097] train: loss: 0.0995944
[Epoch 120; Iter  1007/ 1097] train: loss: 0.1296164
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0700898
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0285823
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0113231
[Epoch 120] ogbg-molhiv: 0.773274 val loss: 0.171606
[Epoch 120] ogbg-molhiv: 0.751297 test loss: 0.293618
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -5.624048709869385
std_pred: 1.9912219047546387
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.39764297315094876
rocauc: 0.8354521849892221
ogbg-molhiv: 0.8354521849892221
BCEWithLogitsLoss: 0.0716990622340877
Statistics on  test
mean_pred: -5.407254695892334
std_pred: 2.367912769317627
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2539279012561904
rocauc: 0.7705459742366596
ogbg-molhiv: 0.7705459742366596
BCEWithLogitsLoss: 0.14671248750106525
Statistics on  train
mean_pred: -5.50274133682251
std_pred: 2.4005751609802246
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.7033627464143378
rocauc: 0.9623868880338142
ogbg-molhiv: 0.9623868880338142
BCEWithLogitsLoss: 0.0792521635472007
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
