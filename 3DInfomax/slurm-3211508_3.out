>>> Starting run for dataset: hiv
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_6_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6937668
[Epoch 1; Iter    60/ 1097] train: loss: 0.6939044
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928584
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924998
[Epoch 1; Iter   150/ 1097] train: loss: 0.6920872
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913102
[Epoch 1; Iter   210/ 1097] train: loss: 0.6897854
[Epoch 1; Iter   240/ 1097] train: loss: 0.6905884
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889262
[Epoch 1; Iter   300/ 1097] train: loss: 0.6895396
[Epoch 1; Iter   330/ 1097] train: loss: 0.6865795
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856121
[Epoch 1; Iter   390/ 1097] train: loss: 0.6907162
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829181
[Epoch 1; Iter   450/ 1097] train: loss: 0.6838868
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798050
[Epoch 1; Iter   510/ 1097] train: loss: 0.6780493
[Epoch 1; Iter   540/ 1097] train: loss: 0.6819426
[Epoch 1; Iter   570/ 1097] train: loss: 0.6786606
[Epoch 1; Iter   600/ 1097] train: loss: 0.6738160
[Epoch 1; Iter   630/ 1097] train: loss: 0.6756099
[Epoch 1; Iter   660/ 1097] train: loss: 0.6737949
[Epoch 1; Iter   690/ 1097] train: loss: 0.6669567
[Epoch 1; Iter   720/ 1097] train: loss: 0.6616233
[Epoch 1; Iter   750/ 1097] train: loss: 0.6409676
[Epoch 1; Iter   780/ 1097] train: loss: 0.6047168
[Epoch 1; Iter   810/ 1097] train: loss: 0.5800083
[Epoch 1; Iter   840/ 1097] train: loss: 0.5072190
[Epoch 1; Iter   870/ 1097] train: loss: 0.4275191
[Epoch 1; Iter   900/ 1097] train: loss: 0.3589137
[Epoch 1; Iter   930/ 1097] train: loss: 0.3826609
[Epoch 1; Iter   960/ 1097] train: loss: 0.2654501
[Epoch 1; Iter   990/ 1097] train: loss: 0.2422700
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2026439
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1209590
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1284503
[Epoch 1] ogbg-molhiv: 0.683345 val loss: 0.122340
[Epoch 1] ogbg-molhiv: 0.626416 test loss: 0.161164
[Epoch 2; Iter    13/ 1097] train: loss: 0.1709080
[Epoch 2; Iter    43/ 1097] train: loss: 0.2325415
[Epoch 2; Iter    73/ 1097] train: loss: 0.0640178
[Epoch 2; Iter   103/ 1097] train: loss: 0.1025014
[Epoch 2; Iter   133/ 1097] train: loss: 0.1965415
[Epoch 2; Iter   163/ 1097] train: loss: 0.1328741
[Epoch 2; Iter   193/ 1097] train: loss: 0.3725084
[Epoch 2; Iter   223/ 1097] train: loss: 0.1569706
[Epoch 2; Iter   253/ 1097] train: loss: 0.2157560
[Epoch 2; Iter   283/ 1097] train: loss: 0.1199250
[Epoch 2; Iter   313/ 1097] train: loss: 0.1219997
[Epoch 2; Iter   343/ 1097] train: loss: 0.1812509
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392434
[Epoch 2; Iter   403/ 1097] train: loss: 0.0581722
[Epoch 2; Iter   433/ 1097] train: loss: 0.1854296
[Epoch 2; Iter   463/ 1097] train: loss: 0.2185357
[Epoch 2; Iter   493/ 1097] train: loss: 0.1547657
[Epoch 2; Iter   523/ 1097] train: loss: 0.2514716
[Epoch 2; Iter   553/ 1097] train: loss: 0.1495342
[Epoch 2; Iter   583/ 1097] train: loss: 0.0567325
[Epoch 2; Iter   613/ 1097] train: loss: 0.2791170
[Epoch 2; Iter   643/ 1097] train: loss: 0.3426515
[Epoch 2; Iter   673/ 1097] train: loss: 0.1526512
[Epoch 2; Iter   703/ 1097] train: loss: 0.1294780
[Epoch 2; Iter   733/ 1097] train: loss: 0.1744879
[Epoch 2; Iter   763/ 1097] train: loss: 0.0292907
[Epoch 2; Iter   793/ 1097] train: loss: 0.1117580
[Epoch 2; Iter   823/ 1097] train: loss: 0.0342074
[Epoch 2; Iter   853/ 1097] train: loss: 0.6452128
[Epoch 2; Iter   883/ 1097] train: loss: 0.1483165
[Epoch 2; Iter   913/ 1097] train: loss: 0.4022065
[Epoch 2; Iter   943/ 1097] train: loss: 0.2681246
[Epoch 2; Iter   973/ 1097] train: loss: 0.0439654
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0956736
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0326561
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0539700
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1552485
[Epoch 2] ogbg-molhiv: 0.644786 val loss: 0.167645
[Epoch 2] ogbg-molhiv: 0.605900 test loss: 0.328189
[Epoch 3; Iter    26/ 1097] train: loss: 0.3072164
[Epoch 3; Iter    56/ 1097] train: loss: 0.1478072
[Epoch 3; Iter    86/ 1097] train: loss: 0.6036936
[Epoch 3; Iter   116/ 1097] train: loss: 0.1262593
[Epoch 3; Iter   146/ 1097] train: loss: 0.1854799
[Epoch 3; Iter   176/ 1097] train: loss: 0.1605697
[Epoch 3; Iter   206/ 1097] train: loss: 0.0526321
[Epoch 3; Iter   236/ 1097] train: loss: 0.4109465
[Epoch 3; Iter   266/ 1097] train: loss: 0.2954975
[Epoch 3; Iter   296/ 1097] train: loss: 0.1546505
[Epoch 3; Iter   326/ 1097] train: loss: 0.1557683
[Epoch 3; Iter   356/ 1097] train: loss: 0.0528993
[Epoch 3; Iter   386/ 1097] train: loss: 0.1050146
[Epoch 3; Iter   416/ 1097] train: loss: 0.1610736
[Epoch 3; Iter   446/ 1097] train: loss: 0.0469070
[Epoch 3; Iter   476/ 1097] train: loss: 0.1886211
[Epoch 3; Iter   506/ 1097] train: loss: 0.0405367
[Epoch 3; Iter   536/ 1097] train: loss: 0.1105667
[Epoch 3; Iter   566/ 1097] train: loss: 0.5293685
[Epoch 3; Iter   596/ 1097] train: loss: 0.4582130
[Epoch 3; Iter   626/ 1097] train: loss: 0.0315163
[Epoch 3; Iter   656/ 1097] train: loss: 0.0314612
[Epoch 3; Iter   686/ 1097] train: loss: 0.3966296
[Epoch 3; Iter   716/ 1097] train: loss: 0.1154893
[Epoch 3; Iter   746/ 1097] train: loss: 0.0979433
[Epoch 3; Iter   776/ 1097] train: loss: 0.2825401
[Epoch 3; Iter   806/ 1097] train: loss: 0.0403301
[Epoch 3; Iter   836/ 1097] train: loss: 0.2633204
[Epoch 3; Iter   866/ 1097] train: loss: 0.0756838
[Epoch 3; Iter   896/ 1097] train: loss: 0.0554950
[Epoch 3; Iter   926/ 1097] train: loss: 0.0302920
[Epoch 3; Iter   956/ 1097] train: loss: 0.0333490
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_4_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931346
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929677
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928356
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923388
[Epoch 1; Iter   150/ 1097] train: loss: 0.6921138
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912631
[Epoch 1; Iter   210/ 1097] train: loss: 0.6896061
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897142
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887900
[Epoch 1; Iter   300/ 1097] train: loss: 0.6884043
[Epoch 1; Iter   330/ 1097] train: loss: 0.6880339
[Epoch 1; Iter   360/ 1097] train: loss: 0.6864935
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840698
[Epoch 1; Iter   420/ 1097] train: loss: 0.6852891
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810420
[Epoch 1; Iter   480/ 1097] train: loss: 0.6808093
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776120
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757873
[Epoch 1; Iter   570/ 1097] train: loss: 0.6737893
[Epoch 1; Iter   600/ 1097] train: loss: 0.6730399
[Epoch 1; Iter   630/ 1097] train: loss: 0.6717930
[Epoch 1; Iter   660/ 1097] train: loss: 0.6726711
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649538
[Epoch 1; Iter   720/ 1097] train: loss: 0.6651986
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408582
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051825
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563256
[Epoch 1; Iter   840/ 1097] train: loss: 0.5016583
[Epoch 1; Iter   870/ 1097] train: loss: 0.4438245
[Epoch 1; Iter   900/ 1097] train: loss: 0.4231094
[Epoch 1; Iter   930/ 1097] train: loss: 0.3857171
[Epoch 1; Iter   960/ 1097] train: loss: 0.3341602
[Epoch 1; Iter   990/ 1097] train: loss: 0.1871833
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1537901
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1230242
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2189800
[Epoch 1] ogbg-molhiv: 0.720299 val loss: 0.172504
[Epoch 1] ogbg-molhiv: 0.711230 test loss: 0.170583
[Epoch 2; Iter    13/ 1097] train: loss: 0.0861137
[Epoch 2; Iter    43/ 1097] train: loss: 0.0948735
[Epoch 2; Iter    73/ 1097] train: loss: 0.0622638
[Epoch 2; Iter   103/ 1097] train: loss: 0.0574091
[Epoch 2; Iter   133/ 1097] train: loss: 0.0480283
[Epoch 2; Iter   163/ 1097] train: loss: 0.0783543
[Epoch 2; Iter   193/ 1097] train: loss: 0.3029076
[Epoch 2; Iter   223/ 1097] train: loss: 0.1551666
[Epoch 2; Iter   253/ 1097] train: loss: 0.3983891
[Epoch 2; Iter   283/ 1097] train: loss: 0.1213823
[Epoch 2; Iter   313/ 1097] train: loss: 0.5697960
[Epoch 2; Iter   343/ 1097] train: loss: 0.1524801
[Epoch 2; Iter   373/ 1097] train: loss: 0.0588810
[Epoch 2; Iter   403/ 1097] train: loss: 0.1114528
[Epoch 2; Iter   433/ 1097] train: loss: 0.4664555
[Epoch 2; Iter   463/ 1097] train: loss: 0.3379234
[Epoch 2; Iter   493/ 1097] train: loss: 0.2027093
[Epoch 2; Iter   523/ 1097] train: loss: 0.0425251
[Epoch 2; Iter   553/ 1097] train: loss: 0.0928934
[Epoch 2; Iter   583/ 1097] train: loss: 0.0939735
[Epoch 2; Iter   613/ 1097] train: loss: 0.0322746
[Epoch 2; Iter   643/ 1097] train: loss: 0.1662632
[Epoch 2; Iter   673/ 1097] train: loss: 0.1568309
[Epoch 2; Iter   703/ 1097] train: loss: 0.1269201
[Epoch 2; Iter   733/ 1097] train: loss: 0.0430935
[Epoch 2; Iter   763/ 1097] train: loss: 0.1391044
[Epoch 2; Iter   793/ 1097] train: loss: 0.2231126
[Epoch 2; Iter   823/ 1097] train: loss: 0.1579557
[Epoch 2; Iter   853/ 1097] train: loss: 0.0359026
[Epoch 2; Iter   883/ 1097] train: loss: 0.1542671
[Epoch 2; Iter   913/ 1097] train: loss: 0.0361512
[Epoch 2; Iter   943/ 1097] train: loss: 0.2724829
[Epoch 2; Iter   973/ 1097] train: loss: 0.2716890
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0300674
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1244579
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1935484
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3339556
[Epoch 2] ogbg-molhiv: 0.729497 val loss: 0.117593
[Epoch 2] ogbg-molhiv: 0.737461 test loss: 0.134207
[Epoch 3; Iter    26/ 1097] train: loss: 0.0394057
[Epoch 3; Iter    56/ 1097] train: loss: 0.2930873
[Epoch 3; Iter    86/ 1097] train: loss: 0.0392348
[Epoch 3; Iter   116/ 1097] train: loss: 0.1432494
[Epoch 3; Iter   146/ 1097] train: loss: 0.0324685
[Epoch 3; Iter   176/ 1097] train: loss: 0.1723433
[Epoch 3; Iter   206/ 1097] train: loss: 0.2110601
[Epoch 3; Iter   236/ 1097] train: loss: 0.2497403
[Epoch 3; Iter   266/ 1097] train: loss: 0.2259473
[Epoch 3; Iter   296/ 1097] train: loss: 0.1610407
[Epoch 3; Iter   326/ 1097] train: loss: 0.0349553
[Epoch 3; Iter   356/ 1097] train: loss: 0.0357124
[Epoch 3; Iter   386/ 1097] train: loss: 0.0289367
[Epoch 3; Iter   416/ 1097] train: loss: 0.0759966
[Epoch 3; Iter   446/ 1097] train: loss: 0.0414723
[Epoch 3; Iter   476/ 1097] train: loss: 0.0351631
[Epoch 3; Iter   506/ 1097] train: loss: 0.2180444
[Epoch 3; Iter   536/ 1097] train: loss: 0.0606583
[Epoch 3; Iter   566/ 1097] train: loss: 0.0396227
[Epoch 3; Iter   596/ 1097] train: loss: 0.3374815
[Epoch 3; Iter   626/ 1097] train: loss: 0.0436380
[Epoch 3; Iter   656/ 1097] train: loss: 0.0377473
[Epoch 3; Iter   686/ 1097] train: loss: 0.1186695
[Epoch 3; Iter   716/ 1097] train: loss: 0.0972105
[Epoch 3; Iter   746/ 1097] train: loss: 0.0324873
[Epoch 3; Iter   776/ 1097] train: loss: 0.1526893
[Epoch 3; Iter   806/ 1097] train: loss: 0.1873743
[Epoch 3; Iter   836/ 1097] train: loss: 0.0265471
[Epoch 3; Iter   866/ 1097] train: loss: 0.3116834
[Epoch 3; Iter   896/ 1097] train: loss: 0.1462387
[Epoch 3; Iter   926/ 1097] train: loss: 0.0288572
[Epoch 3; Iter   956/ 1097] train: loss: 0.1284564
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.0/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.0_5_26-05_09-18-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.0
logdir: runs/static_noise/3DInfomax/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931635
[Epoch 1; Iter    60/ 1097] train: loss: 0.6943821
[Epoch 1; Iter    90/ 1097] train: loss: 0.6928144
[Epoch 1; Iter   120/ 1097] train: loss: 0.6937405
[Epoch 1; Iter   150/ 1097] train: loss: 0.6921297
[Epoch 1; Iter   180/ 1097] train: loss: 0.6903898
[Epoch 1; Iter   210/ 1097] train: loss: 0.6910319
[Epoch 1; Iter   240/ 1097] train: loss: 0.6910415
[Epoch 1; Iter   270/ 1097] train: loss: 0.6894438
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879163
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868501
[Epoch 1; Iter   360/ 1097] train: loss: 0.6855925
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843225
[Epoch 1; Iter   420/ 1097] train: loss: 0.6839861
[Epoch 1; Iter   450/ 1097] train: loss: 0.6840432
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796545
[Epoch 1; Iter   510/ 1097] train: loss: 0.6790964
[Epoch 1; Iter   540/ 1097] train: loss: 0.6776018
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742067
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721647
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721866
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678065
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654619
[Epoch 1; Iter   720/ 1097] train: loss: 0.6653349
[Epoch 1; Iter   750/ 1097] train: loss: 0.6415719
[Epoch 1; Iter   780/ 1097] train: loss: 0.6056225
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560692
[Epoch 1; Iter   840/ 1097] train: loss: 0.5041943
[Epoch 1; Iter   870/ 1097] train: loss: 0.4662044
[Epoch 1; Iter   900/ 1097] train: loss: 0.3574550
[Epoch 1; Iter   930/ 1097] train: loss: 0.3155825
[Epoch 1; Iter   960/ 1097] train: loss: 0.2272441
[Epoch 1; Iter   990/ 1097] train: loss: 0.3934979
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2029752
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2275120
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1924295
[Epoch 1] ogbg-molhiv: 0.691940 val loss: 0.126629
[Epoch 1] ogbg-molhiv: 0.692145 test loss: 0.154837
[Epoch 2; Iter    13/ 1097] train: loss: 0.0789248
[Epoch 2; Iter    43/ 1097] train: loss: 0.0685123
[Epoch 2; Iter    73/ 1097] train: loss: 0.0625626
[Epoch 2; Iter   103/ 1097] train: loss: 0.0525911
[Epoch 2; Iter   133/ 1097] train: loss: 0.1263950
[Epoch 2; Iter   163/ 1097] train: loss: 0.0552342
[Epoch 2; Iter   193/ 1097] train: loss: 0.3032627
[Epoch 2; Iter   223/ 1097] train: loss: 0.0485250
[Epoch 2; Iter   253/ 1097] train: loss: 0.1484368
[Epoch 2; Iter   283/ 1097] train: loss: 0.1334209
[Epoch 2; Iter   313/ 1097] train: loss: 0.1288157
[Epoch 2; Iter   343/ 1097] train: loss: 0.0589589
[Epoch 2; Iter   373/ 1097] train: loss: 0.2574062
[Epoch 2; Iter   403/ 1097] train: loss: 0.2180674
[Epoch 2; Iter   433/ 1097] train: loss: 0.1386117
[Epoch 2; Iter   463/ 1097] train: loss: 0.2462260
[Epoch 2; Iter   493/ 1097] train: loss: 0.0344995
[Epoch 2; Iter   523/ 1097] train: loss: 0.0671465
[Epoch 2; Iter   553/ 1097] train: loss: 0.1343661
[Epoch 2; Iter   583/ 1097] train: loss: 0.2688271
[Epoch 2; Iter   613/ 1097] train: loss: 0.1813639
[Epoch 2; Iter   643/ 1097] train: loss: 0.2214275
[Epoch 2; Iter   673/ 1097] train: loss: 0.0330908
[Epoch 2; Iter   703/ 1097] train: loss: 0.0374413
[Epoch 2; Iter   733/ 1097] train: loss: 0.2649907
[Epoch 2; Iter   763/ 1097] train: loss: 0.2200102
[Epoch 2; Iter   793/ 1097] train: loss: 0.1252292
[Epoch 2; Iter   823/ 1097] train: loss: 0.2465561
[Epoch 2; Iter   853/ 1097] train: loss: 0.1091126
[Epoch 2; Iter   883/ 1097] train: loss: 0.0272574
[Epoch 2; Iter   913/ 1097] train: loss: 0.0792237
[Epoch 2; Iter   943/ 1097] train: loss: 0.2070734
[Epoch 2; Iter   973/ 1097] train: loss: 0.2671638
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0758897
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2053843
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1811784
[Epoch 2; Iter  1093/ 1097] train: loss: 0.2158341
[Epoch 2] ogbg-molhiv: 0.717366 val loss: 0.106629
[Epoch 2] ogbg-molhiv: 0.710935 test loss: 0.138890
[Epoch 3; Iter    26/ 1097] train: loss: 0.1504164
[Epoch 3; Iter    56/ 1097] train: loss: 0.1882711
[Epoch 3; Iter    86/ 1097] train: loss: 0.4658043
[Epoch 3; Iter   116/ 1097] train: loss: 0.0496515
[Epoch 3; Iter   146/ 1097] train: loss: 0.0443499
[Epoch 3; Iter   176/ 1097] train: loss: 0.2963053
[Epoch 3; Iter   206/ 1097] train: loss: 0.0286840
[Epoch 3; Iter   236/ 1097] train: loss: 0.0291369
[Epoch 3; Iter   266/ 1097] train: loss: 0.0604880
[Epoch 3; Iter   296/ 1097] train: loss: 0.0315745
[Epoch 3; Iter   326/ 1097] train: loss: 0.4512549
[Epoch 3; Iter   356/ 1097] train: loss: 0.0350233
[Epoch 3; Iter   386/ 1097] train: loss: 0.2961130
[Epoch 3; Iter   416/ 1097] train: loss: 0.0337601
[Epoch 3; Iter   446/ 1097] train: loss: 0.0312754
[Epoch 3; Iter   476/ 1097] train: loss: 0.1170048
[Epoch 3; Iter   506/ 1097] train: loss: 0.0273464
[Epoch 3; Iter   536/ 1097] train: loss: 0.1505006
[Epoch 3; Iter   566/ 1097] train: loss: 0.1069295
[Epoch 3; Iter   596/ 1097] train: loss: 0.1252228
[Epoch 3; Iter   626/ 1097] train: loss: 0.0304097
[Epoch 3; Iter   656/ 1097] train: loss: 0.2188051
[Epoch 3; Iter   686/ 1097] train: loss: 0.0366320
[Epoch 3; Iter   716/ 1097] train: loss: 0.2232785
[Epoch 3; Iter   746/ 1097] train: loss: 0.1409516
[Epoch 3; Iter   776/ 1097] train: loss: 0.2458416
[Epoch 3; Iter   806/ 1097] train: loss: 0.2989621
[Epoch 3; Iter   836/ 1097] train: loss: 0.1077523
[Epoch 3; Iter   866/ 1097] train: loss: 0.0360493
[Epoch 3; Iter   896/ 1097] train: loss: 0.0446668
[Epoch 3; Iter   926/ 1097] train: loss: 0.4754883
[Epoch 3; Iter   956/ 1097] train: loss: 0.0711523
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_6_26-05_09-28-20
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932432
[Epoch 1; Iter    60/ 1097] train: loss: 0.6939290
[Epoch 1; Iter    90/ 1097] train: loss: 0.6914838
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923213
[Epoch 1; Iter   150/ 1097] train: loss: 0.6920445
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913080
[Epoch 1; Iter   210/ 1097] train: loss: 0.6906900
[Epoch 1; Iter   240/ 1097] train: loss: 0.6905314
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889268
[Epoch 1; Iter   300/ 1097] train: loss: 0.6889197
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868726
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856242
[Epoch 1; Iter   390/ 1097] train: loss: 0.6903708
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829060
[Epoch 1; Iter   450/ 1097] train: loss: 0.6847395
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798209
[Epoch 1; Iter   510/ 1097] train: loss: 0.6792711
[Epoch 1; Iter   540/ 1097] train: loss: 0.6814792
[Epoch 1; Iter   570/ 1097] train: loss: 0.6773018
[Epoch 1; Iter   600/ 1097] train: loss: 0.6734499
[Epoch 1; Iter   630/ 1097] train: loss: 0.6762406
[Epoch 1; Iter   660/ 1097] train: loss: 0.6727275
[Epoch 1; Iter   690/ 1097] train: loss: 0.6670963
[Epoch 1; Iter   720/ 1097] train: loss: 0.6615651
[Epoch 1; Iter   750/ 1097] train: loss: 0.6422089
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051424
[Epoch 1; Iter   810/ 1097] train: loss: 0.5802650
[Epoch 1; Iter   840/ 1097] train: loss: 0.5032439
[Epoch 1; Iter   870/ 1097] train: loss: 0.4280176
[Epoch 1; Iter   900/ 1097] train: loss: 0.3599989
[Epoch 1; Iter   930/ 1097] train: loss: 0.3674774
[Epoch 1; Iter   960/ 1097] train: loss: 0.2830441
[Epoch 1; Iter   990/ 1097] train: loss: 0.2396472
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2010991
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1206949
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1279451
[Epoch 1] ogbg-molhiv: 0.637235 val loss: 0.153657
[Epoch 1] ogbg-molhiv: 0.631933 test loss: 0.178002
[Epoch 2; Iter    13/ 1097] train: loss: 0.1706529
[Epoch 2; Iter    43/ 1097] train: loss: 0.2356830
[Epoch 2; Iter    73/ 1097] train: loss: 0.0606494
[Epoch 2; Iter   103/ 1097] train: loss: 0.1062194
[Epoch 2; Iter   133/ 1097] train: loss: 0.1630833
[Epoch 2; Iter   163/ 1097] train: loss: 0.1414899
[Epoch 2; Iter   193/ 1097] train: loss: 0.3648979
[Epoch 2; Iter   223/ 1097] train: loss: 0.1554362
[Epoch 2; Iter   253/ 1097] train: loss: 0.1841890
[Epoch 2; Iter   283/ 1097] train: loss: 0.1376374
[Epoch 2; Iter   313/ 1097] train: loss: 0.0950456
[Epoch 2; Iter   343/ 1097] train: loss: 0.1349215
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392550
[Epoch 2; Iter   403/ 1097] train: loss: 0.0499223
[Epoch 2; Iter   433/ 1097] train: loss: 0.2350298
[Epoch 2; Iter   463/ 1097] train: loss: 0.2222069
[Epoch 2; Iter   493/ 1097] train: loss: 0.1350555
[Epoch 2; Iter   523/ 1097] train: loss: 0.2541783
[Epoch 2; Iter   553/ 1097] train: loss: 0.1546148
[Epoch 2; Iter   583/ 1097] train: loss: 0.0385363
[Epoch 2; Iter   613/ 1097] train: loss: 0.3054174
[Epoch 2; Iter   643/ 1097] train: loss: 0.3608449
[Epoch 2; Iter   673/ 1097] train: loss: 0.1625567
[Epoch 2; Iter   703/ 1097] train: loss: 0.1245665
[Epoch 2; Iter   733/ 1097] train: loss: 0.1451025
[Epoch 2; Iter   763/ 1097] train: loss: 0.0330422
[Epoch 2; Iter   793/ 1097] train: loss: 0.1633166
[Epoch 2; Iter   823/ 1097] train: loss: 0.0318237
[Epoch 2; Iter   853/ 1097] train: loss: 0.5722354
[Epoch 2; Iter   883/ 1097] train: loss: 0.1502224
[Epoch 2; Iter   913/ 1097] train: loss: 0.4341837
[Epoch 2; Iter   943/ 1097] train: loss: 0.2482204
[Epoch 2; Iter   973/ 1097] train: loss: 0.0386981
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1034337
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0347455
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0510309
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1241023
[Epoch 2] ogbg-molhiv: 0.684567 val loss: 0.289732
[Epoch 2] ogbg-molhiv: 0.598088 test loss: 0.226493
[Epoch 3; Iter    26/ 1097] train: loss: 0.2343116
[Epoch 3; Iter    56/ 1097] train: loss: 0.1350639
[Epoch 3; Iter    86/ 1097] train: loss: 0.5363858
[Epoch 3; Iter   116/ 1097] train: loss: 0.1190775
[Epoch 3; Iter   146/ 1097] train: loss: 0.1322823
[Epoch 3; Iter   176/ 1097] train: loss: 0.1425277
[Epoch 3; Iter   206/ 1097] train: loss: 0.0376282
[Epoch 3; Iter   236/ 1097] train: loss: 0.4188837
[Epoch 3; Iter   266/ 1097] train: loss: 0.2666330
[Epoch 3; Iter   296/ 1097] train: loss: 0.1347002
[Epoch 3; Iter   326/ 1097] train: loss: 0.1509339
[Epoch 3; Iter   356/ 1097] train: loss: 0.0385170
[Epoch 3; Iter   386/ 1097] train: loss: 0.1048046
[Epoch 3; Iter   416/ 1097] train: loss: 0.1189069
[Epoch 3; Iter   446/ 1097] train: loss: 0.0344469
[Epoch 3; Iter   476/ 1097] train: loss: 0.0876047
[Epoch 3; Iter   506/ 1097] train: loss: 0.0429656
[Epoch 3; Iter   536/ 1097] train: loss: 0.1771127
[Epoch 3; Iter   566/ 1097] train: loss: 0.4387774
[Epoch 3; Iter   596/ 1097] train: loss: 0.4252828
[Epoch 3; Iter   626/ 1097] train: loss: 0.0311531
[Epoch 3; Iter   656/ 1097] train: loss: 0.0306774
[Epoch 3; Iter   686/ 1097] train: loss: 0.3786686
[Epoch 3; Iter   716/ 1097] train: loss: 0.1332466
[Epoch 3; Iter   746/ 1097] train: loss: 0.0877934
[Epoch 3; Iter   776/ 1097] train: loss: 0.2336310
[Epoch 3; Iter   806/ 1097] train: loss: 0.0343912
[Epoch 3; Iter   836/ 1097] train: loss: 0.2575179
[Epoch 3; Iter   866/ 1097] train: loss: 0.0697722
[Epoch 3; Iter   896/ 1097] train: loss: 0.0596176
[Epoch 3; Iter   926/ 1097] train: loss: 0.0359687
[Epoch 3; Iter   956/ 1097] train: loss: 0.0307245
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_4_26-05_09-28-30
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931373
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929594
[Epoch 1; Iter    90/ 1097] train: loss: 0.6924442
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923314
[Epoch 1; Iter   150/ 1097] train: loss: 0.6916901
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912597
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902300
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897208
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887908
[Epoch 1; Iter   300/ 1097] train: loss: 0.6882349
[Epoch 1; Iter   330/ 1097] train: loss: 0.6878585
[Epoch 1; Iter   360/ 1097] train: loss: 0.6860540
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840680
[Epoch 1; Iter   420/ 1097] train: loss: 0.6862881
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810322
[Epoch 1; Iter   480/ 1097] train: loss: 0.6809990
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776155
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757461
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738144
[Epoch 1; Iter   600/ 1097] train: loss: 0.6735436
[Epoch 1; Iter   630/ 1097] train: loss: 0.6717408
[Epoch 1; Iter   660/ 1097] train: loss: 0.6733069
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649680
[Epoch 1; Iter   720/ 1097] train: loss: 0.6651436
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412953
[Epoch 1; Iter   780/ 1097] train: loss: 0.6057239
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563064
[Epoch 1; Iter   840/ 1097] train: loss: 0.4962647
[Epoch 1; Iter   870/ 1097] train: loss: 0.4470668
[Epoch 1; Iter   900/ 1097] train: loss: 0.4199249
[Epoch 1; Iter   930/ 1097] train: loss: 0.3861295
[Epoch 1; Iter   960/ 1097] train: loss: 0.3739844
[Epoch 1; Iter   990/ 1097] train: loss: 0.1842961
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1506150
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1228141
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2116449
[Epoch 1] ogbg-molhiv: 0.666615 val loss: 0.184878
[Epoch 1] ogbg-molhiv: 0.660963 test loss: 0.203441
[Epoch 2; Iter    13/ 1097] train: loss: 0.0841611
[Epoch 2; Iter    43/ 1097] train: loss: 0.1074128
[Epoch 2; Iter    73/ 1097] train: loss: 0.0629483
[Epoch 2; Iter   103/ 1097] train: loss: 0.0526482
[Epoch 2; Iter   133/ 1097] train: loss: 0.0518376
[Epoch 2; Iter   163/ 1097] train: loss: 0.0909466
[Epoch 2; Iter   193/ 1097] train: loss: 0.2856707
[Epoch 2; Iter   223/ 1097] train: loss: 0.1613456
[Epoch 2; Iter   253/ 1097] train: loss: 0.3831520
[Epoch 2; Iter   283/ 1097] train: loss: 0.1302580
[Epoch 2; Iter   313/ 1097] train: loss: 0.6042686
[Epoch 2; Iter   343/ 1097] train: loss: 0.1643408
[Epoch 2; Iter   373/ 1097] train: loss: 0.0439370
[Epoch 2; Iter   403/ 1097] train: loss: 0.0856008
[Epoch 2; Iter   433/ 1097] train: loss: 0.4476657
[Epoch 2; Iter   463/ 1097] train: loss: 0.2724691
[Epoch 2; Iter   493/ 1097] train: loss: 0.1919468
[Epoch 2; Iter   523/ 1097] train: loss: 0.0400255
[Epoch 2; Iter   553/ 1097] train: loss: 0.1035608
[Epoch 2; Iter   583/ 1097] train: loss: 0.1135345
[Epoch 2; Iter   613/ 1097] train: loss: 0.0336483
[Epoch 2; Iter   643/ 1097] train: loss: 0.1978025
[Epoch 2; Iter   673/ 1097] train: loss: 0.1620965
[Epoch 2; Iter   703/ 1097] train: loss: 0.1487167
[Epoch 2; Iter   733/ 1097] train: loss: 0.0369898
[Epoch 2; Iter   763/ 1097] train: loss: 0.1625061
[Epoch 2; Iter   793/ 1097] train: loss: 0.2485707
[Epoch 2; Iter   823/ 1097] train: loss: 0.1236592
[Epoch 2; Iter   853/ 1097] train: loss: 0.0396668
[Epoch 2; Iter   883/ 1097] train: loss: 0.1686805
[Epoch 2; Iter   913/ 1097] train: loss: 0.0345151
[Epoch 2; Iter   943/ 1097] train: loss: 0.2474559
[Epoch 2; Iter   973/ 1097] train: loss: 0.2855329
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0361307
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1404776
[Epoch 2; Iter  1063/ 1097] train: loss: 0.2046086
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3412097
[Epoch 2] ogbg-molhiv: 0.756231 val loss: 0.236613
[Epoch 2] ogbg-molhiv: 0.731275 test loss: 0.119510
[Epoch 3; Iter    26/ 1097] train: loss: 0.0295216
[Epoch 3; Iter    56/ 1097] train: loss: 0.2764919
[Epoch 3; Iter    86/ 1097] train: loss: 0.0557747
[Epoch 3; Iter   116/ 1097] train: loss: 0.1215474
[Epoch 3; Iter   146/ 1097] train: loss: 0.0310938
[Epoch 3; Iter   176/ 1097] train: loss: 0.1985100
[Epoch 3; Iter   206/ 1097] train: loss: 0.1799899
[Epoch 3; Iter   236/ 1097] train: loss: 0.2863598
[Epoch 3; Iter   266/ 1097] train: loss: 0.2808373
[Epoch 3; Iter   296/ 1097] train: loss: 0.1724082
[Epoch 3; Iter   326/ 1097] train: loss: 0.0490591
[Epoch 3; Iter   356/ 1097] train: loss: 0.0355233
[Epoch 3; Iter   386/ 1097] train: loss: 0.0301529
[Epoch 3; Iter   416/ 1097] train: loss: 0.0718467
[Epoch 3; Iter   446/ 1097] train: loss: 0.0452822
[Epoch 3; Iter   476/ 1097] train: loss: 0.0412344
[Epoch 3; Iter   506/ 1097] train: loss: 0.1672350
[Epoch 3; Iter   536/ 1097] train: loss: 0.0709313
[Epoch 3; Iter   566/ 1097] train: loss: 0.0465850
[Epoch 3; Iter   596/ 1097] train: loss: 0.3363628
[Epoch 3; Iter   626/ 1097] train: loss: 0.0409829
[Epoch 3; Iter   656/ 1097] train: loss: 0.0327030
[Epoch 3; Iter   686/ 1097] train: loss: 0.1284012
[Epoch 3; Iter   716/ 1097] train: loss: 0.1074150
[Epoch 3; Iter   746/ 1097] train: loss: 0.0350878
[Epoch 3; Iter   776/ 1097] train: loss: 0.1774615
[Epoch 3; Iter   806/ 1097] train: loss: 0.2814780
[Epoch 3; Iter   836/ 1097] train: loss: 0.0257683
[Epoch 3; Iter   866/ 1097] train: loss: 0.3488612
[Epoch 3; Iter   896/ 1097] train: loss: 0.0891858
[Epoch 3; Iter   926/ 1097] train: loss: 0.0280591
[Epoch 3; Iter   956/ 1097] train: loss: 0.1226069
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.05/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.05_5_26-05_09-28-25
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.05
logdir: runs/static_noise/3DInfomax/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931785
[Epoch 1; Iter    60/ 1097] train: loss: 0.6948265
[Epoch 1; Iter    90/ 1097] train: loss: 0.6934670
[Epoch 1; Iter   120/ 1097] train: loss: 0.6941205
[Epoch 1; Iter   150/ 1097] train: loss: 0.6912769
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912782
[Epoch 1; Iter   210/ 1097] train: loss: 0.6920481
[Epoch 1; Iter   240/ 1097] train: loss: 0.6910456
[Epoch 1; Iter   270/ 1097] train: loss: 0.6900606
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879135
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868602
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856139
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843088
[Epoch 1; Iter   420/ 1097] train: loss: 0.6847886
[Epoch 1; Iter   450/ 1097] train: loss: 0.6833422
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796653
[Epoch 1; Iter   510/ 1097] train: loss: 0.6785768
[Epoch 1; Iter   540/ 1097] train: loss: 0.6775469
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742100
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721722
[Epoch 1; Iter   630/ 1097] train: loss: 0.6730629
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678073
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654837
[Epoch 1; Iter   720/ 1097] train: loss: 0.6621163
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412005
[Epoch 1; Iter   780/ 1097] train: loss: 0.6062028
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560594
[Epoch 1; Iter   840/ 1097] train: loss: 0.5052131
[Epoch 1; Iter   870/ 1097] train: loss: 0.4543979
[Epoch 1; Iter   900/ 1097] train: loss: 0.3542163
[Epoch 1; Iter   930/ 1097] train: loss: 0.3129459
[Epoch 1; Iter   960/ 1097] train: loss: 0.2264456
[Epoch 1; Iter   990/ 1097] train: loss: 0.4024276
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1870816
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2368086
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1746044
[Epoch 1] ogbg-molhiv: 0.708070 val loss: 0.388386
[Epoch 1] ogbg-molhiv: 0.675353 test loss: 0.312025
[Epoch 2; Iter    13/ 1097] train: loss: 0.0792859
[Epoch 2; Iter    43/ 1097] train: loss: 0.0677284
[Epoch 2; Iter    73/ 1097] train: loss: 0.0674210
[Epoch 2; Iter   103/ 1097] train: loss: 0.0529831
[Epoch 2; Iter   133/ 1097] train: loss: 0.1198220
[Epoch 2; Iter   163/ 1097] train: loss: 0.0595043
[Epoch 2; Iter   193/ 1097] train: loss: 0.2607442
[Epoch 2; Iter   223/ 1097] train: loss: 0.0508029
[Epoch 2; Iter   253/ 1097] train: loss: 0.1402999
[Epoch 2; Iter   283/ 1097] train: loss: 0.1223001
[Epoch 2; Iter   313/ 1097] train: loss: 0.1292439
[Epoch 2; Iter   343/ 1097] train: loss: 0.0456348
[Epoch 2; Iter   373/ 1097] train: loss: 0.2860563
[Epoch 2; Iter   403/ 1097] train: loss: 0.2087779
[Epoch 2; Iter   433/ 1097] train: loss: 0.1507108
[Epoch 2; Iter   463/ 1097] train: loss: 0.2708758
[Epoch 2; Iter   493/ 1097] train: loss: 0.0359442
[Epoch 2; Iter   523/ 1097] train: loss: 0.0762366
[Epoch 2; Iter   553/ 1097] train: loss: 0.1807282
[Epoch 2; Iter   583/ 1097] train: loss: 0.2589084
[Epoch 2; Iter   613/ 1097] train: loss: 0.1752664
[Epoch 2; Iter   643/ 1097] train: loss: 0.2469854
[Epoch 2; Iter   673/ 1097] train: loss: 0.0368632
[Epoch 2; Iter   703/ 1097] train: loss: 0.0594749
[Epoch 2; Iter   733/ 1097] train: loss: 0.3044374
[Epoch 2; Iter   763/ 1097] train: loss: 0.2400610
[Epoch 2; Iter   793/ 1097] train: loss: 0.1478913
[Epoch 2; Iter   823/ 1097] train: loss: 0.2342046
[Epoch 2; Iter   853/ 1097] train: loss: 0.0825151
[Epoch 2; Iter   883/ 1097] train: loss: 0.0283627
[Epoch 2; Iter   913/ 1097] train: loss: 0.1078677
[Epoch 2; Iter   943/ 1097] train: loss: 0.2064964
[Epoch 2; Iter   973/ 1097] train: loss: 0.2188837
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1100979
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1824153
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1950909
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1691184
[Epoch 2] ogbg-molhiv: 0.672218 val loss: 0.136803
[Epoch 2] ogbg-molhiv: 0.649062 test loss: 0.164896
[Epoch 3; Iter    26/ 1097] train: loss: 0.1608400
[Epoch 3; Iter    56/ 1097] train: loss: 0.1564238
[Epoch 3; Iter    86/ 1097] train: loss: 0.4379459
[Epoch 3; Iter   116/ 1097] train: loss: 0.0528683
[Epoch 3; Iter   146/ 1097] train: loss: 0.0578167
[Epoch 3; Iter   176/ 1097] train: loss: 0.2727444
[Epoch 3; Iter   206/ 1097] train: loss: 0.0264654
[Epoch 3; Iter   236/ 1097] train: loss: 0.0280471
[Epoch 3; Iter   266/ 1097] train: loss: 0.0531700
[Epoch 3; Iter   296/ 1097] train: loss: 0.0339660
[Epoch 3; Iter   326/ 1097] train: loss: 0.4452779
[Epoch 3; Iter   356/ 1097] train: loss: 0.0303025
[Epoch 3; Iter   386/ 1097] train: loss: 0.2544396
[Epoch 3; Iter   416/ 1097] train: loss: 0.0325215
[Epoch 3; Iter   446/ 1097] train: loss: 0.0427426
[Epoch 3; Iter   476/ 1097] train: loss: 0.1288070
[Epoch 3; Iter   506/ 1097] train: loss: 0.0707854
[Epoch 3; Iter   536/ 1097] train: loss: 0.0883872
[Epoch 3; Iter   566/ 1097] train: loss: 0.1181134
[Epoch 3; Iter   596/ 1097] train: loss: 0.1265635
[Epoch 3; Iter   626/ 1097] train: loss: 0.0286428
[Epoch 3; Iter   656/ 1097] train: loss: 0.1909503
[Epoch 3; Iter   686/ 1097] train: loss: 0.0316796
[Epoch 3; Iter   716/ 1097] train: loss: 0.1973134
[Epoch 3; Iter   746/ 1097] train: loss: 0.1367811
[Epoch 3; Iter   776/ 1097] train: loss: 0.2843744
[Epoch 3; Iter   806/ 1097] train: loss: 0.2710490
[Epoch 3; Iter   836/ 1097] train: loss: 0.1369301
[Epoch 3; Iter   866/ 1097] train: loss: 0.0345709
[Epoch 3; Iter   896/ 1097] train: loss: 0.0558556
[Epoch 3; Iter   926/ 1097] train: loss: 0.4522243
[Epoch 3; Iter   956/ 1097] train: loss: 0.1674959
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_6_26-05_09-30-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6929836
[Epoch 1; Iter    60/ 1097] train: loss: 0.6941025
[Epoch 1; Iter    90/ 1097] train: loss: 0.6909129
[Epoch 1; Iter   120/ 1097] train: loss: 0.6925658
[Epoch 1; Iter   150/ 1097] train: loss: 0.6940382
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913170
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902380
[Epoch 1; Iter   240/ 1097] train: loss: 0.6902057
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889209
[Epoch 1; Iter   300/ 1097] train: loss: 0.6900887
[Epoch 1; Iter   330/ 1097] train: loss: 0.6863169
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856021
[Epoch 1; Iter   390/ 1097] train: loss: 0.6893879
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829016
[Epoch 1; Iter   450/ 1097] train: loss: 0.6838576
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798173
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798958
[Epoch 1; Iter   540/ 1097] train: loss: 0.6822278
[Epoch 1; Iter   570/ 1097] train: loss: 0.6780481
[Epoch 1; Iter   600/ 1097] train: loss: 0.6736544
[Epoch 1; Iter   630/ 1097] train: loss: 0.6747472
[Epoch 1; Iter   660/ 1097] train: loss: 0.6725076
[Epoch 1; Iter   690/ 1097] train: loss: 0.6671120
[Epoch 1; Iter   720/ 1097] train: loss: 0.6615101
[Epoch 1; Iter   750/ 1097] train: loss: 0.6417219
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051620
[Epoch 1; Iter   810/ 1097] train: loss: 0.5754365
[Epoch 1; Iter   840/ 1097] train: loss: 0.5005482
[Epoch 1; Iter   870/ 1097] train: loss: 0.4291634
[Epoch 1; Iter   900/ 1097] train: loss: 0.3573335
[Epoch 1; Iter   930/ 1097] train: loss: 0.3568260
[Epoch 1; Iter   960/ 1097] train: loss: 0.2872902
[Epoch 1; Iter   990/ 1097] train: loss: 0.2169419
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1991145
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1210284
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1407672
[Epoch 1] ogbg-molhiv: 0.611065 val loss: 0.114873
[Epoch 1] ogbg-molhiv: 0.547674 test loss: 0.164474
[Epoch 2; Iter    13/ 1097] train: loss: 0.1682212
[Epoch 2; Iter    43/ 1097] train: loss: 0.2544574
[Epoch 2; Iter    73/ 1097] train: loss: 0.0649388
[Epoch 2; Iter   103/ 1097] train: loss: 0.0898721
[Epoch 2; Iter   133/ 1097] train: loss: 0.1712982
[Epoch 2; Iter   163/ 1097] train: loss: 0.1481421
[Epoch 2; Iter   193/ 1097] train: loss: 0.3215616
[Epoch 2; Iter   223/ 1097] train: loss: 0.1389889
[Epoch 2; Iter   253/ 1097] train: loss: 0.1748610
[Epoch 2; Iter   283/ 1097] train: loss: 0.1393055
[Epoch 2; Iter   313/ 1097] train: loss: 0.0988677
[Epoch 2; Iter   343/ 1097] train: loss: 0.1516018
[Epoch 2; Iter   373/ 1097] train: loss: 0.0369817
[Epoch 2; Iter   403/ 1097] train: loss: 0.0419134
[Epoch 2; Iter   433/ 1097] train: loss: 0.2668642
[Epoch 2; Iter   463/ 1097] train: loss: 0.2545271
[Epoch 2; Iter   493/ 1097] train: loss: 0.1589954
[Epoch 2; Iter   523/ 1097] train: loss: 0.2604822
[Epoch 2; Iter   553/ 1097] train: loss: 0.1434582
[Epoch 2; Iter   583/ 1097] train: loss: 0.0417999
[Epoch 2; Iter   613/ 1097] train: loss: 0.2745323
[Epoch 2; Iter   643/ 1097] train: loss: 0.4027928
[Epoch 2; Iter   673/ 1097] train: loss: 0.1712343
[Epoch 2; Iter   703/ 1097] train: loss: 0.1434799
[Epoch 2; Iter   733/ 1097] train: loss: 0.1766362
[Epoch 2; Iter   763/ 1097] train: loss: 0.0326984
[Epoch 2; Iter   793/ 1097] train: loss: 0.1259614
[Epoch 2; Iter   823/ 1097] train: loss: 0.0333604
[Epoch 2; Iter   853/ 1097] train: loss: 0.6245289
[Epoch 2; Iter   883/ 1097] train: loss: 0.1614318
[Epoch 2; Iter   913/ 1097] train: loss: 0.3921075
[Epoch 2; Iter   943/ 1097] train: loss: 0.3408529
[Epoch 2; Iter   973/ 1097] train: loss: 0.0412324
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1086370
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0350552
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0842710
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1206857
[Epoch 2] ogbg-molhiv: 0.675209 val loss: 1.320481
[Epoch 2] ogbg-molhiv: 0.639680 test loss: 0.600041
[Epoch 3; Iter    26/ 1097] train: loss: 0.3640716
[Epoch 3; Iter    56/ 1097] train: loss: 0.1596842
[Epoch 3; Iter    86/ 1097] train: loss: 0.5422960
[Epoch 3; Iter   116/ 1097] train: loss: 0.1622857
[Epoch 3; Iter   146/ 1097] train: loss: 0.1481326
[Epoch 3; Iter   176/ 1097] train: loss: 0.1736616
[Epoch 3; Iter   206/ 1097] train: loss: 0.0374339
[Epoch 3; Iter   236/ 1097] train: loss: 0.4047903
[Epoch 3; Iter   266/ 1097] train: loss: 0.2826456
[Epoch 3; Iter   296/ 1097] train: loss: 0.2166936
[Epoch 3; Iter   326/ 1097] train: loss: 0.1230475
[Epoch 3; Iter   356/ 1097] train: loss: 0.0432957
[Epoch 3; Iter   386/ 1097] train: loss: 0.0980850
[Epoch 3; Iter   416/ 1097] train: loss: 0.1439592
[Epoch 3; Iter   446/ 1097] train: loss: 0.0383229
[Epoch 3; Iter   476/ 1097] train: loss: 0.1582338
[Epoch 3; Iter   506/ 1097] train: loss: 0.0368052
[Epoch 3; Iter   536/ 1097] train: loss: 0.1418716
[Epoch 3; Iter   566/ 1097] train: loss: 0.4526532
[Epoch 3; Iter   596/ 1097] train: loss: 0.3834665
[Epoch 3; Iter   626/ 1097] train: loss: 0.0383066
[Epoch 3; Iter   656/ 1097] train: loss: 0.0319603
[Epoch 3; Iter   686/ 1097] train: loss: 0.3947338
[Epoch 3; Iter   716/ 1097] train: loss: 0.1290038
[Epoch 3; Iter   746/ 1097] train: loss: 0.0817962
[Epoch 3; Iter   776/ 1097] train: loss: 0.2143720
[Epoch 3; Iter   806/ 1097] train: loss: 0.0402961
[Epoch 3; Iter   836/ 1097] train: loss: 0.2599047
[Epoch 3; Iter   866/ 1097] train: loss: 0.0716714
[Epoch 3; Iter   896/ 1097] train: loss: 0.0683235
[Epoch 3; Iter   926/ 1097] train: loss: 0.0379202
[Epoch 3; Iter   956/ 1097] train: loss: 0.0304895
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_5_26-05_09-30-00
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931735
[Epoch 1; Iter    60/ 1097] train: loss: 0.6927472
[Epoch 1; Iter    90/ 1097] train: loss: 0.6932407
[Epoch 1; Iter   120/ 1097] train: loss: 0.6946480
[Epoch 1; Iter   150/ 1097] train: loss: 0.6913855
[Epoch 1; Iter   180/ 1097] train: loss: 0.6914127
[Epoch 1; Iter   210/ 1097] train: loss: 0.6922070
[Epoch 1; Iter   240/ 1097] train: loss: 0.6907763
[Epoch 1; Iter   270/ 1097] train: loss: 0.6896634
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879555
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868681
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856108
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843241
[Epoch 1; Iter   420/ 1097] train: loss: 0.6849182
[Epoch 1; Iter   450/ 1097] train: loss: 0.6824472
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796967
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798174
[Epoch 1; Iter   540/ 1097] train: loss: 0.6775867
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742340
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721607
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721516
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678197
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654792
[Epoch 1; Iter   720/ 1097] train: loss: 0.6628169
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408572
[Epoch 1; Iter   780/ 1097] train: loss: 0.6057367
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563859
[Epoch 1; Iter   840/ 1097] train: loss: 0.5076789
[Epoch 1; Iter   870/ 1097] train: loss: 0.4625482
[Epoch 1; Iter   900/ 1097] train: loss: 0.3582475
[Epoch 1; Iter   930/ 1097] train: loss: 0.3329992
[Epoch 1; Iter   960/ 1097] train: loss: 0.2285669
[Epoch 1; Iter   990/ 1097] train: loss: 0.3873539
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1721659
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2393439
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1820941
[Epoch 1] ogbg-molhiv: 0.579322 val loss: 0.904185
[Epoch 1] ogbg-molhiv: 0.597464 test loss: 0.890505
[Epoch 2; Iter    13/ 1097] train: loss: 0.0863161
[Epoch 2; Iter    43/ 1097] train: loss: 0.0710981
[Epoch 2; Iter    73/ 1097] train: loss: 0.0607391
[Epoch 2; Iter   103/ 1097] train: loss: 0.0534483
[Epoch 2; Iter   133/ 1097] train: loss: 0.1161448
[Epoch 2; Iter   163/ 1097] train: loss: 0.0528869
[Epoch 2; Iter   193/ 1097] train: loss: 0.2620347
[Epoch 2; Iter   223/ 1097] train: loss: 0.0488281
[Epoch 2; Iter   253/ 1097] train: loss: 0.1629804
[Epoch 2; Iter   283/ 1097] train: loss: 0.0969135
[Epoch 2; Iter   313/ 1097] train: loss: 0.1407329
[Epoch 2; Iter   343/ 1097] train: loss: 0.0473019
[Epoch 2; Iter   373/ 1097] train: loss: 0.2496783
[Epoch 2; Iter   403/ 1097] train: loss: 0.2591560
[Epoch 2; Iter   433/ 1097] train: loss: 0.2132138
[Epoch 2; Iter   463/ 1097] train: loss: 0.2599362
[Epoch 2; Iter   493/ 1097] train: loss: 0.0378436
[Epoch 2; Iter   523/ 1097] train: loss: 0.1050996
[Epoch 2; Iter   553/ 1097] train: loss: 0.1703805
[Epoch 2; Iter   583/ 1097] train: loss: 0.2549338
[Epoch 2; Iter   613/ 1097] train: loss: 0.1954471
[Epoch 2; Iter   643/ 1097] train: loss: 0.2307229
[Epoch 2; Iter   673/ 1097] train: loss: 0.0356227
[Epoch 2; Iter   703/ 1097] train: loss: 0.0640479
[Epoch 2; Iter   733/ 1097] train: loss: 0.3182336
[Epoch 2; Iter   763/ 1097] train: loss: 0.2369656
[Epoch 2; Iter   793/ 1097] train: loss: 0.1366294
[Epoch 2; Iter   823/ 1097] train: loss: 0.2269734
[Epoch 2; Iter   853/ 1097] train: loss: 0.0533149
[Epoch 2; Iter   883/ 1097] train: loss: 0.0252673
[Epoch 2; Iter   913/ 1097] train: loss: 0.1330355
[Epoch 2; Iter   943/ 1097] train: loss: 0.1993576
[Epoch 2; Iter   973/ 1097] train: loss: 0.2452305
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1459549
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2633027
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1826296
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1639793
[Epoch 2] ogbg-molhiv: 0.604185 val loss: 0.194704
[Epoch 2] ogbg-molhiv: 0.647060 test loss: 0.143550
[Epoch 3; Iter    26/ 1097] train: loss: 0.1545944
[Epoch 3; Iter    56/ 1097] train: loss: 0.1685915
[Epoch 3; Iter    86/ 1097] train: loss: 0.4683888
[Epoch 3; Iter   116/ 1097] train: loss: 0.0767848
[Epoch 3; Iter   146/ 1097] train: loss: 0.0560289
[Epoch 3; Iter   176/ 1097] train: loss: 0.2620152
[Epoch 3; Iter   206/ 1097] train: loss: 0.0284102
[Epoch 3; Iter   236/ 1097] train: loss: 0.0353672
[Epoch 3; Iter   266/ 1097] train: loss: 0.0352875
[Epoch 3; Iter   296/ 1097] train: loss: 0.0314970
[Epoch 3; Iter   326/ 1097] train: loss: 0.4153710
[Epoch 3; Iter   356/ 1097] train: loss: 0.0352653
[Epoch 3; Iter   386/ 1097] train: loss: 0.2938995
[Epoch 3; Iter   416/ 1097] train: loss: 0.0388118
[Epoch 3; Iter   446/ 1097] train: loss: 0.0446090
[Epoch 3; Iter   476/ 1097] train: loss: 0.1375611
[Epoch 3; Iter   506/ 1097] train: loss: 0.0995236
[Epoch 3; Iter   536/ 1097] train: loss: 0.1387353
[Epoch 3; Iter   566/ 1097] train: loss: 0.0879917
[Epoch 3; Iter   596/ 1097] train: loss: 0.1269473
[Epoch 3; Iter   626/ 1097] train: loss: 0.0330659
[Epoch 3; Iter   656/ 1097] train: loss: 0.1699641
[Epoch 3; Iter   686/ 1097] train: loss: 0.0339214
[Epoch 3; Iter   716/ 1097] train: loss: 0.2382849
[Epoch 3; Iter   746/ 1097] train: loss: 0.1477767
[Epoch 3; Iter   776/ 1097] train: loss: 0.2887600
[Epoch 3; Iter   806/ 1097] train: loss: 0.2693481
[Epoch 3; Iter   836/ 1097] train: loss: 0.1266815
[Epoch 3; Iter   866/ 1097] train: loss: 0.0339850
[Epoch 3; Iter   896/ 1097] train: loss: 0.0409843
[Epoch 3; Iter   926/ 1097] train: loss: 0.5396878
[Epoch 3; Iter   956/ 1097] train: loss: 0.1827231
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.1/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.1_4_26-05_09-30-34
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.1
logdir: runs/static_noise/3DInfomax/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931368
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929709
[Epoch 1; Iter    90/ 1097] train: loss: 0.6921951
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923326
[Epoch 1; Iter   150/ 1097] train: loss: 0.6924561
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912559
[Epoch 1; Iter   210/ 1097] train: loss: 0.6903683
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897203
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887889
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879462
[Epoch 1; Iter   330/ 1097] train: loss: 0.6872656
[Epoch 1; Iter   360/ 1097] train: loss: 0.6859931
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840538
[Epoch 1; Iter   420/ 1097] train: loss: 0.6865224
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810458
[Epoch 1; Iter   480/ 1097] train: loss: 0.6797777
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776138
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757590
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738002
[Epoch 1; Iter   600/ 1097] train: loss: 0.6727681
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721697
[Epoch 1; Iter   660/ 1097] train: loss: 0.6720569
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649595
[Epoch 1; Iter   720/ 1097] train: loss: 0.6618397
[Epoch 1; Iter   750/ 1097] train: loss: 0.6412876
[Epoch 1; Iter   780/ 1097] train: loss: 0.6051318
[Epoch 1; Iter   810/ 1097] train: loss: 0.5557635
[Epoch 1; Iter   840/ 1097] train: loss: 0.4978102
[Epoch 1; Iter   870/ 1097] train: loss: 0.4444568
[Epoch 1; Iter   900/ 1097] train: loss: 0.4249702
[Epoch 1; Iter   930/ 1097] train: loss: 0.3860976
[Epoch 1; Iter   960/ 1097] train: loss: 0.3881784
[Epoch 1; Iter   990/ 1097] train: loss: 0.1850768
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1512061
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1249333
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2290296
[Epoch 1] ogbg-molhiv: 0.668510 val loss: 0.962422
[Epoch 1] ogbg-molhiv: 0.708693 test loss: 0.843575
[Epoch 2; Iter    13/ 1097] train: loss: 0.0813834
[Epoch 2; Iter    43/ 1097] train: loss: 0.1422385
[Epoch 2; Iter    73/ 1097] train: loss: 0.0608678
[Epoch 2; Iter   103/ 1097] train: loss: 0.0544351
[Epoch 2; Iter   133/ 1097] train: loss: 0.0508846
[Epoch 2; Iter   163/ 1097] train: loss: 0.0940736
[Epoch 2; Iter   193/ 1097] train: loss: 0.2558503
[Epoch 2; Iter   223/ 1097] train: loss: 0.1687566
[Epoch 2; Iter   253/ 1097] train: loss: 0.4089078
[Epoch 2; Iter   283/ 1097] train: loss: 0.1424836
[Epoch 2; Iter   313/ 1097] train: loss: 0.6187941
[Epoch 2; Iter   343/ 1097] train: loss: 0.1622789
[Epoch 2; Iter   373/ 1097] train: loss: 0.0396460
[Epoch 2; Iter   403/ 1097] train: loss: 0.1034128
[Epoch 2; Iter   433/ 1097] train: loss: 0.4745893
[Epoch 2; Iter   463/ 1097] train: loss: 0.3170354
[Epoch 2; Iter   493/ 1097] train: loss: 0.2088373
[Epoch 2; Iter   523/ 1097] train: loss: 0.0399883
[Epoch 2; Iter   553/ 1097] train: loss: 0.1261013
[Epoch 2; Iter   583/ 1097] train: loss: 0.0928304
[Epoch 2; Iter   613/ 1097] train: loss: 0.0338833
[Epoch 2; Iter   643/ 1097] train: loss: 0.1355947
[Epoch 2; Iter   673/ 1097] train: loss: 0.1780350
[Epoch 2; Iter   703/ 1097] train: loss: 0.1735401
[Epoch 2; Iter   733/ 1097] train: loss: 0.0366093
[Epoch 2; Iter   763/ 1097] train: loss: 0.1586913
[Epoch 2; Iter   793/ 1097] train: loss: 0.2537750
[Epoch 2; Iter   823/ 1097] train: loss: 0.1363024
[Epoch 2; Iter   853/ 1097] train: loss: 0.0433283
[Epoch 2; Iter   883/ 1097] train: loss: 0.1658334
[Epoch 2; Iter   913/ 1097] train: loss: 0.0342669
[Epoch 2; Iter   943/ 1097] train: loss: 0.2782497
[Epoch 2; Iter   973/ 1097] train: loss: 0.2791530
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0388291
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1508513
[Epoch 2; Iter  1063/ 1097] train: loss: 0.2103899
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3468712
[Epoch 2] ogbg-molhiv: 0.697506 val loss: 0.239992
[Epoch 2] ogbg-molhiv: 0.672796 test loss: 0.406400
[Epoch 3; Iter    26/ 1097] train: loss: 0.0318270
[Epoch 3; Iter    56/ 1097] train: loss: 0.2424784
[Epoch 3; Iter    86/ 1097] train: loss: 0.0406910
[Epoch 3; Iter   116/ 1097] train: loss: 0.0989473
[Epoch 3; Iter   146/ 1097] train: loss: 0.0291102
[Epoch 3; Iter   176/ 1097] train: loss: 0.1688637
[Epoch 3; Iter   206/ 1097] train: loss: 0.1768174
[Epoch 3; Iter   236/ 1097] train: loss: 0.2737676
[Epoch 3; Iter   266/ 1097] train: loss: 0.2849944
[Epoch 3; Iter   296/ 1097] train: loss: 0.1379984
[Epoch 3; Iter   326/ 1097] train: loss: 0.0386315
[Epoch 3; Iter   356/ 1097] train: loss: 0.0369947
[Epoch 3; Iter   386/ 1097] train: loss: 0.0297865
[Epoch 3; Iter   416/ 1097] train: loss: 0.1046156
[Epoch 3; Iter   446/ 1097] train: loss: 0.0396550
[Epoch 3; Iter   476/ 1097] train: loss: 0.0393035
[Epoch 3; Iter   506/ 1097] train: loss: 0.2003157
[Epoch 3; Iter   536/ 1097] train: loss: 0.0616733
[Epoch 3; Iter   566/ 1097] train: loss: 0.0409020
[Epoch 3; Iter   596/ 1097] train: loss: 0.3268175
[Epoch 3; Iter   626/ 1097] train: loss: 0.0404561
[Epoch 3; Iter   656/ 1097] train: loss: 0.0324846
[Epoch 3; Iter   686/ 1097] train: loss: 0.1212288
[Epoch 3; Iter   716/ 1097] train: loss: 0.1185104
[Epoch 3; Iter   746/ 1097] train: loss: 0.0445538
[Epoch 3; Iter   776/ 1097] train: loss: 0.2562331
[Epoch 3; Iter   806/ 1097] train: loss: 0.2927710
[Epoch 3; Iter   836/ 1097] train: loss: 0.0329278
[Epoch 3; Iter   866/ 1097] train: loss: 0.3419058
[Epoch 3; Iter   896/ 1097] train: loss: 0.1320621
[Epoch 3; Iter   926/ 1097] train: loss: 0.0306758
[Epoch 3; Iter   956/ 1097] train: loss: 0.1958516
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_4_26-05_09-32-45
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931365
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929717
[Epoch 1; Iter    90/ 1097] train: loss: 0.6925332
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923445
[Epoch 1; Iter   150/ 1097] train: loss: 0.6922008
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912544
[Epoch 1; Iter   210/ 1097] train: loss: 0.6902406
[Epoch 1; Iter   240/ 1097] train: loss: 0.6897295
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888016
[Epoch 1; Iter   300/ 1097] train: loss: 0.6880606
[Epoch 1; Iter   330/ 1097] train: loss: 0.6877014
[Epoch 1; Iter   360/ 1097] train: loss: 0.6865961
[Epoch 1; Iter   390/ 1097] train: loss: 0.6840554
[Epoch 1; Iter   420/ 1097] train: loss: 0.6844548
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810336
[Epoch 1; Iter   480/ 1097] train: loss: 0.6812363
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776235
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757724
[Epoch 1; Iter   570/ 1097] train: loss: 0.6737962
[Epoch 1; Iter   600/ 1097] train: loss: 0.6731701
[Epoch 1; Iter   630/ 1097] train: loss: 0.6713842
[Epoch 1; Iter   660/ 1097] train: loss: 0.6718303
[Epoch 1; Iter   690/ 1097] train: loss: 0.6649736
[Epoch 1; Iter   720/ 1097] train: loss: 0.6601234
[Epoch 1; Iter   750/ 1097] train: loss: 0.6413683
[Epoch 1; Iter   780/ 1097] train: loss: 0.6055655
[Epoch 1; Iter   810/ 1097] train: loss: 0.5560836
[Epoch 1; Iter   840/ 1097] train: loss: 0.4966683
[Epoch 1; Iter   870/ 1097] train: loss: 0.4463083
[Epoch 1; Iter   900/ 1097] train: loss: 0.4176069
[Epoch 1; Iter   930/ 1097] train: loss: 0.3774824
[Epoch 1; Iter   960/ 1097] train: loss: 0.3627125
[Epoch 1; Iter   990/ 1097] train: loss: 0.1836723
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1522245
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1206530
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1951133
[Epoch 1] ogbg-molhiv: 0.527239 val loss: 0.964277
[Epoch 1] ogbg-molhiv: 0.496891 test loss: 0.754892
[Epoch 2; Iter    13/ 1097] train: loss: 0.0837421
[Epoch 2; Iter    43/ 1097] train: loss: 0.1314277
[Epoch 2; Iter    73/ 1097] train: loss: 0.0651473
[Epoch 2; Iter   103/ 1097] train: loss: 0.0536544
[Epoch 2; Iter   133/ 1097] train: loss: 0.0517237
[Epoch 2; Iter   163/ 1097] train: loss: 0.1006457
[Epoch 2; Iter   193/ 1097] train: loss: 0.2584257
[Epoch 2; Iter   223/ 1097] train: loss: 0.1707698
[Epoch 2; Iter   253/ 1097] train: loss: 0.3604334
[Epoch 2; Iter   283/ 1097] train: loss: 0.1446003
[Epoch 2; Iter   313/ 1097] train: loss: 0.6028736
[Epoch 2; Iter   343/ 1097] train: loss: 0.1458236
[Epoch 2; Iter   373/ 1097] train: loss: 0.0405429
[Epoch 2; Iter   403/ 1097] train: loss: 0.1430929
[Epoch 2; Iter   433/ 1097] train: loss: 0.4698869
[Epoch 2; Iter   463/ 1097] train: loss: 0.2960469
[Epoch 2; Iter   493/ 1097] train: loss: 0.2025238
[Epoch 2; Iter   523/ 1097] train: loss: 0.0436559
[Epoch 2; Iter   553/ 1097] train: loss: 0.1625743
[Epoch 2; Iter   583/ 1097] train: loss: 0.0845846
[Epoch 2; Iter   613/ 1097] train: loss: 0.0421091
[Epoch 2; Iter   643/ 1097] train: loss: 0.1485837
[Epoch 2; Iter   673/ 1097] train: loss: 0.1550736
[Epoch 2; Iter   703/ 1097] train: loss: 0.1406142
[Epoch 2; Iter   733/ 1097] train: loss: 0.0380667
[Epoch 2; Iter   763/ 1097] train: loss: 0.1437217
[Epoch 2; Iter   793/ 1097] train: loss: 0.2453011
[Epoch 2; Iter   823/ 1097] train: loss: 0.1193583
[Epoch 2; Iter   853/ 1097] train: loss: 0.0359242
[Epoch 2; Iter   883/ 1097] train: loss: 0.1593412
[Epoch 2; Iter   913/ 1097] train: loss: 0.0368956
[Epoch 2; Iter   943/ 1097] train: loss: 0.3388153
[Epoch 2; Iter   973/ 1097] train: loss: 0.2746463
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0395248
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1526794
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1688400
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3757368
[Epoch 2] ogbg-molhiv: 0.585685 val loss: 0.251218
[Epoch 2] ogbg-molhiv: 0.693399 test loss: 0.201268
[Epoch 3; Iter    26/ 1097] train: loss: 0.0330952
[Epoch 3; Iter    56/ 1097] train: loss: 0.2713681
[Epoch 3; Iter    86/ 1097] train: loss: 0.0444755
[Epoch 3; Iter   116/ 1097] train: loss: 0.0972757
[Epoch 3; Iter   146/ 1097] train: loss: 0.0334551
[Epoch 3; Iter   176/ 1097] train: loss: 0.2253328
[Epoch 3; Iter   206/ 1097] train: loss: 0.1790286
[Epoch 3; Iter   236/ 1097] train: loss: 0.2630368
[Epoch 3; Iter   266/ 1097] train: loss: 0.3240950
[Epoch 3; Iter   296/ 1097] train: loss: 0.1577314
[Epoch 3; Iter   326/ 1097] train: loss: 0.0373941
[Epoch 3; Iter   356/ 1097] train: loss: 0.0432459
[Epoch 3; Iter   386/ 1097] train: loss: 0.0329121
[Epoch 3; Iter   416/ 1097] train: loss: 0.1047323
[Epoch 3; Iter   446/ 1097] train: loss: 0.0396207
[Epoch 3; Iter   476/ 1097] train: loss: 0.0390049
[Epoch 3; Iter   506/ 1097] train: loss: 0.2104333
[Epoch 3; Iter   536/ 1097] train: loss: 0.0449768
[Epoch 3; Iter   566/ 1097] train: loss: 0.0386696
[Epoch 3; Iter   596/ 1097] train: loss: 0.3466753
[Epoch 3; Iter   626/ 1097] train: loss: 0.0400860
[Epoch 3; Iter   656/ 1097] train: loss: 0.0911650
[Epoch 3; Iter   686/ 1097] train: loss: 0.1456177
[Epoch 3; Iter   716/ 1097] train: loss: 0.1158544
[Epoch 3; Iter   746/ 1097] train: loss: 0.0418216
[Epoch 3; Iter   776/ 1097] train: loss: 0.2688819
[Epoch 3; Iter   806/ 1097] train: loss: 0.2873384
[Epoch 3; Iter   836/ 1097] train: loss: 0.0301793
[Epoch 3; Iter   866/ 1097] train: loss: 0.3430785
[Epoch 3; Iter   896/ 1097] train: loss: 0.1227246
[Epoch 3; Iter   926/ 1097] train: loss: 0.0297805
[Epoch 3; Iter   956/ 1097] train: loss: 0.1949116
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_6_26-05_09-33-26
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6929076
[Epoch 1; Iter    60/ 1097] train: loss: 0.6943719
[Epoch 1; Iter    90/ 1097] train: loss: 0.6909936
[Epoch 1; Iter   120/ 1097] train: loss: 0.6927298
[Epoch 1; Iter   150/ 1097] train: loss: 0.6934567
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913093
[Epoch 1; Iter   210/ 1097] train: loss: 0.6906065
[Epoch 1; Iter   240/ 1097] train: loss: 0.6901342
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889318
[Epoch 1; Iter   300/ 1097] train: loss: 0.6887952
[Epoch 1; Iter   330/ 1097] train: loss: 0.6873167
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856077
[Epoch 1; Iter   390/ 1097] train: loss: 0.6883816
[Epoch 1; Iter   420/ 1097] train: loss: 0.6828962
[Epoch 1; Iter   450/ 1097] train: loss: 0.6848150
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798326
[Epoch 1; Iter   510/ 1097] train: loss: 0.6806523
[Epoch 1; Iter   540/ 1097] train: loss: 0.6818473
[Epoch 1; Iter   570/ 1097] train: loss: 0.6758271
[Epoch 1; Iter   600/ 1097] train: loss: 0.6737152
[Epoch 1; Iter   630/ 1097] train: loss: 0.6753734
[Epoch 1; Iter   660/ 1097] train: loss: 0.6725132
[Epoch 1; Iter   690/ 1097] train: loss: 0.6671481
[Epoch 1; Iter   720/ 1097] train: loss: 0.6616332
[Epoch 1; Iter   750/ 1097] train: loss: 0.6407339
[Epoch 1; Iter   780/ 1097] train: loss: 0.6062188
[Epoch 1; Iter   810/ 1097] train: loss: 0.5685943
[Epoch 1; Iter   840/ 1097] train: loss: 0.4981526
[Epoch 1; Iter   870/ 1097] train: loss: 0.4334599
[Epoch 1; Iter   900/ 1097] train: loss: 0.3582071
[Epoch 1; Iter   930/ 1097] train: loss: 0.3604268
[Epoch 1; Iter   960/ 1097] train: loss: 0.2831786
[Epoch 1; Iter   990/ 1097] train: loss: 0.2171583
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2123185
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1205899
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1563296
[Epoch 1] ogbg-molhiv: 0.571732 val loss: 3.365988
[Epoch 1] ogbg-molhiv: 0.653068 test loss: 2.940663
[Epoch 2; Iter    13/ 1097] train: loss: 0.1670976
[Epoch 2; Iter    43/ 1097] train: loss: 0.2432278
[Epoch 2; Iter    73/ 1097] train: loss: 0.0659655
[Epoch 2; Iter   103/ 1097] train: loss: 0.1397842
[Epoch 2; Iter   133/ 1097] train: loss: 0.1733047
[Epoch 2; Iter   163/ 1097] train: loss: 0.1317779
[Epoch 2; Iter   193/ 1097] train: loss: 0.3234878
[Epoch 2; Iter   223/ 1097] train: loss: 0.1640767
[Epoch 2; Iter   253/ 1097] train: loss: 0.1953322
[Epoch 2; Iter   283/ 1097] train: loss: 0.1585866
[Epoch 2; Iter   313/ 1097] train: loss: 0.1526300
[Epoch 2; Iter   343/ 1097] train: loss: 0.1529338
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392933
[Epoch 2; Iter   403/ 1097] train: loss: 0.0455188
[Epoch 2; Iter   433/ 1097] train: loss: 0.2457446
[Epoch 2; Iter   463/ 1097] train: loss: 0.2615652
[Epoch 2; Iter   493/ 1097] train: loss: 0.1453463
[Epoch 2; Iter   523/ 1097] train: loss: 0.2656473
[Epoch 2; Iter   553/ 1097] train: loss: 0.1439067
[Epoch 2; Iter   583/ 1097] train: loss: 0.0444642
[Epoch 2; Iter   613/ 1097] train: loss: 0.3202035
[Epoch 2; Iter   643/ 1097] train: loss: 0.3320878
[Epoch 2; Iter   673/ 1097] train: loss: 0.1526702
[Epoch 2; Iter   703/ 1097] train: loss: 0.1369638
[Epoch 2; Iter   733/ 1097] train: loss: 0.1499363
[Epoch 2; Iter   763/ 1097] train: loss: 0.0297759
[Epoch 2; Iter   793/ 1097] train: loss: 0.0911944
[Epoch 2; Iter   823/ 1097] train: loss: 0.0352725
[Epoch 2; Iter   853/ 1097] train: loss: 0.6154681
[Epoch 2; Iter   883/ 1097] train: loss: 0.1432603
[Epoch 2; Iter   913/ 1097] train: loss: 0.3783899
[Epoch 2; Iter   943/ 1097] train: loss: 0.3094657
[Epoch 2; Iter   973/ 1097] train: loss: 0.0376488
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1098767
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0353085
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0585102
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1278707
[Epoch 2] ogbg-molhiv: 0.742266 val loss: 0.459066
[Epoch 2] ogbg-molhiv: 0.695355 test loss: 0.379510
[Epoch 3; Iter    26/ 1097] train: loss: 0.3206243
[Epoch 3; Iter    56/ 1097] train: loss: 0.1729149
[Epoch 3; Iter    86/ 1097] train: loss: 0.5109643
[Epoch 3; Iter   116/ 1097] train: loss: 0.1526941
[Epoch 3; Iter   146/ 1097] train: loss: 0.1482736
[Epoch 3; Iter   176/ 1097] train: loss: 0.1502327
[Epoch 3; Iter   206/ 1097] train: loss: 0.0463639
[Epoch 3; Iter   236/ 1097] train: loss: 0.3496789
[Epoch 3; Iter   266/ 1097] train: loss: 0.2713533
[Epoch 3; Iter   296/ 1097] train: loss: 0.2279667
[Epoch 3; Iter   326/ 1097] train: loss: 0.1550128
[Epoch 3; Iter   356/ 1097] train: loss: 0.0490428
[Epoch 3; Iter   386/ 1097] train: loss: 0.0990162
[Epoch 3; Iter   416/ 1097] train: loss: 0.1184859
[Epoch 3; Iter   446/ 1097] train: loss: 0.0390869
[Epoch 3; Iter   476/ 1097] train: loss: 0.1411483
[Epoch 3; Iter   506/ 1097] train: loss: 0.0576435
[Epoch 3; Iter   536/ 1097] train: loss: 0.1768101
[Epoch 3; Iter   566/ 1097] train: loss: 0.4586182
[Epoch 3; Iter   596/ 1097] train: loss: 0.4284237
[Epoch 3; Iter   626/ 1097] train: loss: 0.0316731
[Epoch 3; Iter   656/ 1097] train: loss: 0.0377493
[Epoch 3; Iter   686/ 1097] train: loss: 0.3669298
[Epoch 3; Iter   716/ 1097] train: loss: 0.1561018
[Epoch 3; Iter   746/ 1097] train: loss: 0.0724760
[Epoch 3; Iter   776/ 1097] train: loss: 0.2057848
[Epoch 3; Iter   806/ 1097] train: loss: 0.0363598
[Epoch 3; Iter   836/ 1097] train: loss: 0.2481459
[Epoch 3; Iter   866/ 1097] train: loss: 0.0889583
[Epoch 3; Iter   896/ 1097] train: loss: 0.0911096
[Epoch 3; Iter   926/ 1097] train: loss: 0.0372682
[Epoch 3; Iter   956/ 1097] train: loss: 0.0376592
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/hiv/noise=0.2/PNA_ogbg-molhiv_3DInfomax_hiv_static_noise=0.2_5_26-05_09-33-40
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_hiv_static_noise=0.2
logdir: runs/static_noise/3DInfomax/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932184
[Epoch 1; Iter    60/ 1097] train: loss: 0.6934208
[Epoch 1; Iter    90/ 1097] train: loss: 0.6932592
[Epoch 1; Iter   120/ 1097] train: loss: 0.6940998
[Epoch 1; Iter   150/ 1097] train: loss: 0.6910717
[Epoch 1; Iter   180/ 1097] train: loss: 0.6923596
[Epoch 1; Iter   210/ 1097] train: loss: 0.6912225
[Epoch 1; Iter   240/ 1097] train: loss: 0.6914445
[Epoch 1; Iter   270/ 1097] train: loss: 0.6893069
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879395
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868614
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856220
[Epoch 1; Iter   390/ 1097] train: loss: 0.6843571
[Epoch 1; Iter   420/ 1097] train: loss: 0.6847388
[Epoch 1; Iter   450/ 1097] train: loss: 0.6814957
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796837
[Epoch 1; Iter   510/ 1097] train: loss: 0.6798881
[Epoch 1; Iter   540/ 1097] train: loss: 0.6777537
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742346
[Epoch 1; Iter   600/ 1097] train: loss: 0.6722220
[Epoch 1; Iter   630/ 1097] train: loss: 0.6726218
[Epoch 1; Iter   660/ 1097] train: loss: 0.6678224
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654813
[Epoch 1; Iter   720/ 1097] train: loss: 0.6637139
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411246
[Epoch 1; Iter   780/ 1097] train: loss: 0.6055752
[Epoch 1; Iter   810/ 1097] train: loss: 0.5590557
[Epoch 1; Iter   840/ 1097] train: loss: 0.5135453
[Epoch 1; Iter   870/ 1097] train: loss: 0.4590991
[Epoch 1; Iter   900/ 1097] train: loss: 0.3545045
[Epoch 1; Iter   930/ 1097] train: loss: 0.3150695
[Epoch 1; Iter   960/ 1097] train: loss: 0.2291997
[Epoch 1; Iter   990/ 1097] train: loss: 0.4136755
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1929751
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2346991
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1597579
[Epoch 1] ogbg-molhiv: 0.575106 val loss: 2.128527
[Epoch 1] ogbg-molhiv: 0.632310 test loss: 2.225780
[Epoch 2; Iter    13/ 1097] train: loss: 0.0853576
[Epoch 2; Iter    43/ 1097] train: loss: 0.0733735
[Epoch 2; Iter    73/ 1097] train: loss: 0.0624894
[Epoch 2; Iter   103/ 1097] train: loss: 0.0520319
[Epoch 2; Iter   133/ 1097] train: loss: 0.1176817
[Epoch 2; Iter   163/ 1097] train: loss: 0.0451668
[Epoch 2; Iter   193/ 1097] train: loss: 0.2665616
[Epoch 2; Iter   223/ 1097] train: loss: 0.0567489
[Epoch 2; Iter   253/ 1097] train: loss: 0.1378037
[Epoch 2; Iter   283/ 1097] train: loss: 0.1255347
[Epoch 2; Iter   313/ 1097] train: loss: 0.1347343
[Epoch 2; Iter   343/ 1097] train: loss: 0.0416700
[Epoch 2; Iter   373/ 1097] train: loss: 0.2797507
[Epoch 2; Iter   403/ 1097] train: loss: 0.3361592
[Epoch 2; Iter   433/ 1097] train: loss: 0.1545866
[Epoch 2; Iter   463/ 1097] train: loss: 0.3348128
[Epoch 2; Iter   493/ 1097] train: loss: 0.0387688
[Epoch 2; Iter   523/ 1097] train: loss: 0.1085647
[Epoch 2; Iter   553/ 1097] train: loss: 0.1660825
[Epoch 2; Iter   583/ 1097] train: loss: 0.2653221
[Epoch 2; Iter   613/ 1097] train: loss: 0.1587391
[Epoch 2; Iter   643/ 1097] train: loss: 0.2408033
[Epoch 2; Iter   673/ 1097] train: loss: 0.0366160
[Epoch 2; Iter   703/ 1097] train: loss: 0.0553145
[Epoch 2; Iter   733/ 1097] train: loss: 0.3160486
[Epoch 2; Iter   763/ 1097] train: loss: 0.2420189
[Epoch 2; Iter   793/ 1097] train: loss: 0.1353994
[Epoch 2; Iter   823/ 1097] train: loss: 0.2453550
[Epoch 2; Iter   853/ 1097] train: loss: 0.0531550
[Epoch 2; Iter   883/ 1097] train: loss: 0.0285382
[Epoch 2; Iter   913/ 1097] train: loss: 0.1519428
[Epoch 2; Iter   943/ 1097] train: loss: 0.2186966
[Epoch 2; Iter   973/ 1097] train: loss: 0.2420268
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1567087
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2242238
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1949356
[Epoch 2; Iter  1093/ 1097] train: loss: 0.2040605
[Epoch 2] ogbg-molhiv: 0.602516 val loss: 0.192561
[Epoch 2] ogbg-molhiv: 0.610865 test loss: 0.141726
[Epoch 3; Iter    26/ 1097] train: loss: 0.1750682
[Epoch 3; Iter    56/ 1097] train: loss: 0.1670675
[Epoch 3; Iter    86/ 1097] train: loss: 0.4728419
[Epoch 3; Iter   116/ 1097] train: loss: 0.0864117
[Epoch 3; Iter   146/ 1097] train: loss: 0.0407306
[Epoch 3; Iter   176/ 1097] train: loss: 0.2890295
[Epoch 3; Iter   206/ 1097] train: loss: 0.0292564
[Epoch 3; Iter   236/ 1097] train: loss: 0.0313833
[Epoch 3; Iter   266/ 1097] train: loss: 0.0351988
[Epoch 3; Iter   296/ 1097] train: loss: 0.0296929
[Epoch 3; Iter   326/ 1097] train: loss: 0.4992990
[Epoch 3; Iter   356/ 1097] train: loss: 0.0359404
[Epoch 3; Iter   386/ 1097] train: loss: 0.3157001
[Epoch 3; Iter   416/ 1097] train: loss: 0.0382424
[Epoch 3; Iter   446/ 1097] train: loss: 0.0336950
[Epoch 3; Iter   476/ 1097] train: loss: 0.1524684
[Epoch 3; Iter   506/ 1097] train: loss: 0.1119888
[Epoch 3; Iter   536/ 1097] train: loss: 0.1261919
[Epoch 3; Iter   566/ 1097] train: loss: 0.1206426
[Epoch 3; Iter   596/ 1097] train: loss: 0.1215178
[Epoch 3; Iter   626/ 1097] train: loss: 0.0319174
[Epoch 3; Iter   656/ 1097] train: loss: 0.1802052
[Epoch 3; Iter   686/ 1097] train: loss: 0.0340474
[Epoch 3; Iter   716/ 1097] train: loss: 0.1928474
[Epoch 3; Iter   746/ 1097] train: loss: 0.1293730
[Epoch 3; Iter   776/ 1097] train: loss: 0.3070218
[Epoch 3; Iter   806/ 1097] train: loss: 0.2599915
[Epoch 3; Iter   836/ 1097] train: loss: 0.1411177
[Epoch 3; Iter   866/ 1097] train: loss: 0.0383503
[Epoch 3; Iter   896/ 1097] train: loss: 0.0518845
[Epoch 3; Iter   926/ 1097] train: loss: 0.4366487
[Epoch 3; Iter   956/ 1097] train: loss: 0.1832013
[Epoch 3; Iter   986/ 1097] train: loss: 0.2205703
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0886187
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0879364
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0320302
[Epoch 3] ogbg-molhiv: 0.757578 val loss: 0.313727
[Epoch 3] ogbg-molhiv: 0.758151 test loss: 0.153195
[Epoch 4; Iter     9/ 1097] train: loss: 0.3862506
[Epoch 4; Iter    39/ 1097] train: loss: 0.0940491
[Epoch 4; Iter    69/ 1097] train: loss: 0.1128955
[Epoch 4; Iter    99/ 1097] train: loss: 0.0301854
[Epoch 4; Iter   129/ 1097] train: loss: 0.1329330
[Epoch 4; Iter   159/ 1097] train: loss: 0.4407690
[Epoch 4; Iter   189/ 1097] train: loss: 0.0301290
[Epoch 4; Iter   219/ 1097] train: loss: 0.4241340
[Epoch 4; Iter   249/ 1097] train: loss: 0.0316447
[Epoch 4; Iter   279/ 1097] train: loss: 0.1424044
[Epoch 4; Iter   309/ 1097] train: loss: 0.1523537
[Epoch 4; Iter   339/ 1097] train: loss: 0.0987377
[Epoch 4; Iter   369/ 1097] train: loss: 0.1538679
[Epoch 4; Iter   399/ 1097] train: loss: 0.1536854
[Epoch 4; Iter   429/ 1097] train: loss: 0.0583904
[Epoch 4; Iter   459/ 1097] train: loss: 0.0439027
[Epoch 4; Iter   489/ 1097] train: loss: 0.0319988
[Epoch 4; Iter   519/ 1097] train: loss: 0.0958421
[Epoch 4; Iter   549/ 1097] train: loss: 0.0371313
[Epoch 4; Iter   579/ 1097] train: loss: 0.0381169
[Epoch 4; Iter   609/ 1097] train: loss: 0.2247833
[Epoch 4; Iter   639/ 1097] train: loss: 0.0283901
[Epoch 4; Iter   669/ 1097] train: loss: 0.2152619
[Epoch 4; Iter   699/ 1097] train: loss: 0.0659621
[Epoch 4; Iter   729/ 1097] train: loss: 0.4267885
[Epoch 4; Iter   759/ 1097] train: loss: 0.0380219
[Epoch 4; Iter   789/ 1097] train: loss: 0.3399914
[Epoch 4; Iter   819/ 1097] train: loss: 0.0382286
[Epoch 4; Iter   849/ 1097] train: loss: 0.2287235
[Epoch 4; Iter   879/ 1097] train: loss: 0.1495612
[Epoch 4; Iter   909/ 1097] train: loss: 0.5450599
[Epoch 4; Iter   939/ 1097] train: loss: 0.0446360
[Epoch 4; Iter   969/ 1097] train: loss: 0.0549401
[Epoch 4; Iter   999/ 1097] train: loss: 0.2826192
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2589925
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2007585
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1057084
[Epoch 4] ogbg-molhiv: 0.753503 val loss: 0.541002
[Epoch 4] ogbg-molhiv: 0.745880 test loss: 0.195344
[Epoch 5; Iter    22/ 1097] train: loss: 0.0558346
[Epoch 5; Iter    52/ 1097] train: loss: 0.1292382
[Epoch 5; Iter    82/ 1097] train: loss: 0.4445356
[Epoch 5; Iter   112/ 1097] train: loss: 0.0455009
[Epoch 5; Iter   142/ 1097] train: loss: 0.3113189
[Epoch 5; Iter   172/ 1097] train: loss: 0.1829826
[Epoch 5; Iter   202/ 1097] train: loss: 0.0308545
[Epoch 5; Iter   232/ 1097] train: loss: 0.1733088
[Epoch 5; Iter   262/ 1097] train: loss: 0.1656406
[Epoch 5; Iter   292/ 1097] train: loss: 0.2914168
[Epoch 5; Iter   322/ 1097] train: loss: 0.1638188
[Epoch 5; Iter   352/ 1097] train: loss: 0.1895342
[Epoch 5; Iter   382/ 1097] train: loss: 0.2347591
[Epoch 5; Iter   412/ 1097] train: loss: 0.0395082
[Epoch 5; Iter   442/ 1097] train: loss: 0.1374638
[Epoch 5; Iter   472/ 1097] train: loss: 0.1984218
[Epoch 5; Iter   502/ 1097] train: loss: 0.1259231
[Epoch 5; Iter   532/ 1097] train: loss: 0.0623806
[Epoch 5; Iter   562/ 1097] train: loss: 0.2355453
[Epoch 5; Iter   592/ 1097] train: loss: 0.0595894
[Epoch 5; Iter   622/ 1097] train: loss: 0.1284231
[Epoch 5; Iter   652/ 1097] train: loss: 0.2545489
[Epoch 5; Iter   682/ 1097] train: loss: 0.0264256
[Epoch 5; Iter   712/ 1097] train: loss: 0.2070368
[Epoch 5; Iter   742/ 1097] train: loss: 0.0286681
[Epoch 5; Iter   772/ 1097] train: loss: 0.0341048
[Epoch 5; Iter   802/ 1097] train: loss: 0.1418808
[Epoch 5; Iter   832/ 1097] train: loss: 0.2601145
[Epoch 5; Iter   862/ 1097] train: loss: 0.0614216
[Epoch 5; Iter   892/ 1097] train: loss: 0.0854601
[Epoch 5; Iter   922/ 1097] train: loss: 0.1194702
[Epoch 5; Iter   952/ 1097] train: loss: 0.2429848
[Epoch 5; Iter   982/ 1097] train: loss: 0.0781350
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2686147
[Epoch 5; Iter  1042/ 1097] train: loss: 0.3344289
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0461535
[Epoch 5] ogbg-molhiv: 0.761145 val loss: 0.285643
[Epoch 5] ogbg-molhiv: 0.743307 test loss: 0.139910
[Epoch 6; Iter     5/ 1097] train: loss: 0.2487565
[Epoch 6; Iter    35/ 1097] train: loss: 0.3780073
[Epoch 6; Iter    65/ 1097] train: loss: 0.0406270
[Epoch 6; Iter    95/ 1097] train: loss: 0.1741670
[Epoch 6; Iter   125/ 1097] train: loss: 0.2486059
[Epoch 6; Iter   155/ 1097] train: loss: 0.0601383
[Epoch 6; Iter   185/ 1097] train: loss: 0.1265327
[Epoch 6; Iter   215/ 1097] train: loss: 0.1250868
[Epoch 6; Iter   245/ 1097] train: loss: 0.0492995
[Epoch 6; Iter   275/ 1097] train: loss: 0.1324993
[Epoch 6; Iter   305/ 1097] train: loss: 0.0269651
[Epoch 6; Iter   335/ 1097] train: loss: 0.0301244
[Epoch 6; Iter   365/ 1097] train: loss: 0.0458334
[Epoch 6; Iter   395/ 1097] train: loss: 0.1940893
[Epoch 6; Iter   425/ 1097] train: loss: 0.0446853
[Epoch 6; Iter   455/ 1097] train: loss: 0.2462755
[Epoch 6; Iter   485/ 1097] train: loss: 0.0335216
[Epoch 6; Iter   515/ 1097] train: loss: 0.0417761
[Epoch 6; Iter   545/ 1097] train: loss: 0.1228545
[Epoch 6; Iter   575/ 1097] train: loss: 0.0339848
[Epoch 6; Iter   605/ 1097] train: loss: 0.0607069
[Epoch 6; Iter   635/ 1097] train: loss: 0.1835238
[Epoch 6; Iter   665/ 1097] train: loss: 0.1969190
[Epoch 6; Iter   695/ 1097] train: loss: 0.1616464
[Epoch 6; Iter   725/ 1097] train: loss: 0.3584448
[Epoch 6; Iter   755/ 1097] train: loss: 0.1862202
[Epoch 6; Iter   785/ 1097] train: loss: 0.4218531
[Epoch 6; Iter   815/ 1097] train: loss: 0.0554623
[Epoch 6; Iter   845/ 1097] train: loss: 0.0426868
[Epoch 6; Iter   875/ 1097] train: loss: 0.0762885
[Epoch 6; Iter   905/ 1097] train: loss: 0.1171706
[Epoch 6; Iter   935/ 1097] train: loss: 0.0446465
[Epoch 6; Iter   965/ 1097] train: loss: 0.0438413
[Epoch 6; Iter   995/ 1097] train: loss: 0.0311334
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0844441
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1893203
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2086624
[Epoch 6] ogbg-molhiv: 0.785831 val loss: 0.274933
[Epoch 6] ogbg-molhiv: 0.762357 test loss: 0.192724
[Epoch 7; Iter    18/ 1097] train: loss: 0.0534633
[Epoch 7; Iter    48/ 1097] train: loss: 0.0281291
[Epoch 7; Iter    78/ 1097] train: loss: 0.2001503
[Epoch 7; Iter   108/ 1097] train: loss: 0.2656524
[Epoch 7; Iter   138/ 1097] train: loss: 0.1167167
[Epoch 7; Iter   168/ 1097] train: loss: 0.0270427
[Epoch 7; Iter   198/ 1097] train: loss: 0.2150328
[Epoch 7; Iter   228/ 1097] train: loss: 0.2002728
[Epoch 7; Iter   258/ 1097] train: loss: 0.0215896
[Epoch 7; Iter   288/ 1097] train: loss: 0.0234574
[Epoch 7; Iter   318/ 1097] train: loss: 0.1130865
[Epoch 7; Iter   348/ 1097] train: loss: 0.0268732
[Epoch 7; Iter   378/ 1097] train: loss: 0.2115813
[Epoch 7; Iter   408/ 1097] train: loss: 0.2899941
[Epoch 7; Iter   438/ 1097] train: loss: 0.0580353
[Epoch 7; Iter   468/ 1097] train: loss: 0.0319844
[Epoch 7; Iter   498/ 1097] train: loss: 0.1857526
[Epoch 7; Iter   528/ 1097] train: loss: 0.1006899
[Epoch 7; Iter   558/ 1097] train: loss: 0.0336502
[Epoch 7; Iter   588/ 1097] train: loss: 0.2019135
[Epoch 7; Iter   618/ 1097] train: loss: 0.1662533
[Epoch 7; Iter   648/ 1097] train: loss: 0.0528177
[Epoch 7; Iter   678/ 1097] train: loss: 0.0266896
[Epoch 7; Iter   708/ 1097] train: loss: 0.1899735
[Epoch 7; Iter   738/ 1097] train: loss: 0.1856323
[Epoch 7; Iter   768/ 1097] train: loss: 0.1578502
[Epoch 7; Iter   798/ 1097] train: loss: 0.1147507
[Epoch 7; Iter   828/ 1097] train: loss: 0.0596141
[Epoch 7; Iter   858/ 1097] train: loss: 0.2467908
[Epoch 7; Iter   888/ 1097] train: loss: 0.0410166
[Epoch 7; Iter   918/ 1097] train: loss: 0.1005322
[Epoch 7; Iter   948/ 1097] train: loss: 0.0359729
[Epoch 7; Iter   978/ 1097] train: loss: 0.0599979
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0590355
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0415240
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1798152
[Epoch 7] ogbg-molhiv: 0.762064 val loss: 0.945647
[Epoch 7] ogbg-molhiv: 0.740455 test loss: 0.198696
[Epoch 3; Iter   986/ 1097] train: loss: 0.0334403
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2816857
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0332691
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0889156
[Epoch 3] ogbg-molhiv: 0.733377 val loss: 0.102514
[Epoch 3] ogbg-molhiv: 0.749261 test loss: 0.120978
[Epoch 4; Iter     9/ 1097] train: loss: 0.0625326
[Epoch 4; Iter    39/ 1097] train: loss: 0.0392040
[Epoch 4; Iter    69/ 1097] train: loss: 0.0266443
[Epoch 4; Iter    99/ 1097] train: loss: 0.0287808
[Epoch 4; Iter   129/ 1097] train: loss: 0.2150482
[Epoch 4; Iter   159/ 1097] train: loss: 0.1265253
[Epoch 4; Iter   189/ 1097] train: loss: 0.0445650
[Epoch 4; Iter   219/ 1097] train: loss: 0.0337708
[Epoch 4; Iter   249/ 1097] train: loss: 0.1435616
[Epoch 4; Iter   279/ 1097] train: loss: 0.2212927
[Epoch 4; Iter   309/ 1097] train: loss: 0.0514884
[Epoch 4; Iter   339/ 1097] train: loss: 0.0382258
[Epoch 4; Iter   369/ 1097] train: loss: 0.0742991
[Epoch 4; Iter   399/ 1097] train: loss: 0.2264995
[Epoch 4; Iter   429/ 1097] train: loss: 0.0336091
[Epoch 4; Iter   459/ 1097] train: loss: 0.1530077
[Epoch 4; Iter   489/ 1097] train: loss: 0.0260193
[Epoch 4; Iter   519/ 1097] train: loss: 0.1848639
[Epoch 4; Iter   549/ 1097] train: loss: 0.0461229
[Epoch 4; Iter   579/ 1097] train: loss: 0.0999072
[Epoch 4; Iter   609/ 1097] train: loss: 0.1107781
[Epoch 4; Iter   639/ 1097] train: loss: 0.0916584
[Epoch 4; Iter   669/ 1097] train: loss: 0.2328306
[Epoch 4; Iter   699/ 1097] train: loss: 0.1164729
[Epoch 4; Iter   729/ 1097] train: loss: 0.0367736
[Epoch 4; Iter   759/ 1097] train: loss: 0.0282643
[Epoch 4; Iter   789/ 1097] train: loss: 0.0257932
[Epoch 4; Iter   819/ 1097] train: loss: 0.1436810
[Epoch 4; Iter   849/ 1097] train: loss: 0.0309274
[Epoch 4; Iter   879/ 1097] train: loss: 0.0369829
[Epoch 4; Iter   909/ 1097] train: loss: 0.0344897
[Epoch 4; Iter   939/ 1097] train: loss: 0.3399282
[Epoch 4; Iter   969/ 1097] train: loss: 0.0965298
[Epoch 4; Iter   999/ 1097] train: loss: 0.0337958
[Epoch 4; Iter  1029/ 1097] train: loss: 0.1810039
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1708509
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1691096
[Epoch 4] ogbg-molhiv: 0.788678 val loss: 0.089593
[Epoch 4] ogbg-molhiv: 0.752270 test loss: 0.123006
[Epoch 5; Iter    22/ 1097] train: loss: 0.1017998
[Epoch 5; Iter    52/ 1097] train: loss: 0.1585031
[Epoch 5; Iter    82/ 1097] train: loss: 0.1581564
[Epoch 5; Iter   112/ 1097] train: loss: 0.3935542
[Epoch 5; Iter   142/ 1097] train: loss: 0.3374801
[Epoch 5; Iter   172/ 1097] train: loss: 0.0286852
[Epoch 5; Iter   202/ 1097] train: loss: 0.1790243
[Epoch 5; Iter   232/ 1097] train: loss: 0.2382348
[Epoch 5; Iter   262/ 1097] train: loss: 0.0672089
[Epoch 5; Iter   292/ 1097] train: loss: 0.1880651
[Epoch 5; Iter   322/ 1097] train: loss: 0.0276958
[Epoch 5; Iter   352/ 1097] train: loss: 0.0911542
[Epoch 5; Iter   382/ 1097] train: loss: 0.1440066
[Epoch 5; Iter   412/ 1097] train: loss: 0.2987715
[Epoch 5; Iter   442/ 1097] train: loss: 0.1503921
[Epoch 5; Iter   472/ 1097] train: loss: 0.1059308
[Epoch 5; Iter   502/ 1097] train: loss: 0.1785484
[Epoch 5; Iter   532/ 1097] train: loss: 0.2348067
[Epoch 5; Iter   562/ 1097] train: loss: 0.2835404
[Epoch 5; Iter   592/ 1097] train: loss: 0.0520223
[Epoch 5; Iter   622/ 1097] train: loss: 0.0334840
[Epoch 5; Iter   652/ 1097] train: loss: 0.1035742
[Epoch 5; Iter   682/ 1097] train: loss: 0.1440582
[Epoch 5; Iter   712/ 1097] train: loss: 0.0332348
[Epoch 5; Iter   742/ 1097] train: loss: 0.1492053
[Epoch 5; Iter   772/ 1097] train: loss: 0.2562872
[Epoch 5; Iter   802/ 1097] train: loss: 0.0811073
[Epoch 5; Iter   832/ 1097] train: loss: 0.0551403
[Epoch 5; Iter   862/ 1097] train: loss: 0.0846138
[Epoch 5; Iter   892/ 1097] train: loss: 0.0418323
[Epoch 5; Iter   922/ 1097] train: loss: 0.0363182
[Epoch 5; Iter   952/ 1097] train: loss: 0.0291976
[Epoch 5; Iter   982/ 1097] train: loss: 0.0672113
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0314474
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2210091
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0454108
[Epoch 5] ogbg-molhiv: 0.784952 val loss: 0.080784
[Epoch 5] ogbg-molhiv: 0.752434 test loss: 0.119351
[Epoch 6; Iter     5/ 1097] train: loss: 0.0560403
[Epoch 6; Iter    35/ 1097] train: loss: 0.2648273
[Epoch 6; Iter    65/ 1097] train: loss: 0.0272992
[Epoch 6; Iter    95/ 1097] train: loss: 0.0632152
[Epoch 6; Iter   125/ 1097] train: loss: 0.3728862
[Epoch 6; Iter   155/ 1097] train: loss: 0.2970348
[Epoch 6; Iter   185/ 1097] train: loss: 0.0290284
[Epoch 6; Iter   215/ 1097] train: loss: 0.1500181
[Epoch 6; Iter   245/ 1097] train: loss: 0.2366405
[Epoch 6; Iter   275/ 1097] train: loss: 0.0339964
[Epoch 6; Iter   305/ 1097] train: loss: 0.1649607
[Epoch 6; Iter   335/ 1097] train: loss: 0.0700073
[Epoch 6; Iter   365/ 1097] train: loss: 0.2808619
[Epoch 6; Iter   395/ 1097] train: loss: 0.2559066
[Epoch 6; Iter   425/ 1097] train: loss: 0.0358790
[Epoch 6; Iter   455/ 1097] train: loss: 0.3285229
[Epoch 6; Iter   485/ 1097] train: loss: 0.0331989
[Epoch 6; Iter   515/ 1097] train: loss: 0.1091538
[Epoch 6; Iter   545/ 1097] train: loss: 0.1765362
[Epoch 6; Iter   575/ 1097] train: loss: 0.2344788
[Epoch 6; Iter   605/ 1097] train: loss: 0.0399570
[Epoch 6; Iter   635/ 1097] train: loss: 0.0284712
[Epoch 6; Iter   665/ 1097] train: loss: 0.1988348
[Epoch 6; Iter   695/ 1097] train: loss: 0.1798907
[Epoch 6; Iter   725/ 1097] train: loss: 0.1893843
[Epoch 6; Iter   755/ 1097] train: loss: 0.0517567
[Epoch 6; Iter   785/ 1097] train: loss: 0.1217272
[Epoch 6; Iter   815/ 1097] train: loss: 0.0334541
[Epoch 6; Iter   845/ 1097] train: loss: 0.1261224
[Epoch 6; Iter   875/ 1097] train: loss: 0.1294841
[Epoch 6; Iter   905/ 1097] train: loss: 0.2772962
[Epoch 6; Iter   935/ 1097] train: loss: 0.0320842
[Epoch 6; Iter   965/ 1097] train: loss: 0.0268462
[Epoch 6; Iter   995/ 1097] train: loss: 0.1733303
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1933911
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0262354
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2481316
[Epoch 6] ogbg-molhiv: 0.795234 val loss: 0.082889
[Epoch 6] ogbg-molhiv: 0.765905 test loss: 0.117285
[Epoch 7; Iter    18/ 1097] train: loss: 0.2094202
[Epoch 7; Iter    48/ 1097] train: loss: 0.6607606
[Epoch 7; Iter    78/ 1097] train: loss: 0.3751817
[Epoch 7; Iter   108/ 1097] train: loss: 0.0362693
[Epoch 7; Iter   138/ 1097] train: loss: 0.0213531
[Epoch 7; Iter   168/ 1097] train: loss: 0.0250317
[Epoch 7; Iter   198/ 1097] train: loss: 0.1689922
[Epoch 7; Iter   228/ 1097] train: loss: 0.1529447
[Epoch 7; Iter   258/ 1097] train: loss: 0.1192316
[Epoch 7; Iter   288/ 1097] train: loss: 0.1659409
[Epoch 7; Iter   318/ 1097] train: loss: 0.0359066
[Epoch 7; Iter   348/ 1097] train: loss: 0.0520900
[Epoch 7; Iter   378/ 1097] train: loss: 0.0277319
[Epoch 7; Iter   408/ 1097] train: loss: 0.0405685
[Epoch 7; Iter   438/ 1097] train: loss: 0.0295523
[Epoch 7; Iter   468/ 1097] train: loss: 0.2983337
[Epoch 7; Iter   498/ 1097] train: loss: 0.0432448
[Epoch 7; Iter   528/ 1097] train: loss: 0.0274986
[Epoch 7; Iter   558/ 1097] train: loss: 0.2506319
[Epoch 7; Iter   588/ 1097] train: loss: 0.1014445
[Epoch 7; Iter   618/ 1097] train: loss: 0.1974692
[Epoch 7; Iter   648/ 1097] train: loss: 0.1952559
[Epoch 7; Iter   678/ 1097] train: loss: 0.0832726
[Epoch 7; Iter   708/ 1097] train: loss: 0.0970567
[Epoch 7; Iter   738/ 1097] train: loss: 0.0391584
[Epoch 7; Iter   768/ 1097] train: loss: 0.0797382
[Epoch 7; Iter   798/ 1097] train: loss: 0.1986228
[Epoch 7; Iter   828/ 1097] train: loss: 0.1551442
[Epoch 7; Iter   858/ 1097] train: loss: 0.1001639
[Epoch 7; Iter   888/ 1097] train: loss: 0.0855650
[Epoch 7; Iter   918/ 1097] train: loss: 0.1713616
[Epoch 7; Iter   948/ 1097] train: loss: 0.1584620
[Epoch 7; Iter   978/ 1097] train: loss: 0.0853422
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0253295
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2684586
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0490948
[Epoch 7] ogbg-molhiv: 0.789609 val loss: 0.080140
[Epoch 7] ogbg-molhiv: 0.756424 test loss: 0.115676
[Epoch 3; Iter   986/ 1097] train: loss: 0.0282360
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0251230
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1375426
[Epoch 3; Iter  1076/ 1097] train: loss: 0.3087243
[Epoch 3] ogbg-molhiv: 0.780809 val loss: 0.085807
[Epoch 3] ogbg-molhiv: 0.728340 test loss: 0.124471
[Epoch 4; Iter     9/ 1097] train: loss: 0.1793579
[Epoch 4; Iter    39/ 1097] train: loss: 0.1933269
[Epoch 4; Iter    69/ 1097] train: loss: 0.0416244
[Epoch 4; Iter    99/ 1097] train: loss: 0.2838563
[Epoch 4; Iter   129/ 1097] train: loss: 0.1681812
[Epoch 4; Iter   159/ 1097] train: loss: 0.0876937
[Epoch 4; Iter   189/ 1097] train: loss: 0.2740844
[Epoch 4; Iter   219/ 1097] train: loss: 0.1503020
[Epoch 4; Iter   249/ 1097] train: loss: 0.1641322
[Epoch 4; Iter   279/ 1097] train: loss: 0.1056998
[Epoch 4; Iter   309/ 1097] train: loss: 0.1141609
[Epoch 4; Iter   339/ 1097] train: loss: 0.0290574
[Epoch 4; Iter   369/ 1097] train: loss: 0.1055802
[Epoch 4; Iter   399/ 1097] train: loss: 0.0813220
[Epoch 4; Iter   429/ 1097] train: loss: 0.1767343
[Epoch 4; Iter   459/ 1097] train: loss: 0.0278169
[Epoch 4; Iter   489/ 1097] train: loss: 0.1620589
[Epoch 4; Iter   519/ 1097] train: loss: 0.3038638
[Epoch 4; Iter   549/ 1097] train: loss: 0.1808390
[Epoch 4; Iter   579/ 1097] train: loss: 0.0377782
[Epoch 4; Iter   609/ 1097] train: loss: 0.3103428
[Epoch 4; Iter   639/ 1097] train: loss: 0.3241965
[Epoch 4; Iter   669/ 1097] train: loss: 0.2732227
[Epoch 4; Iter   699/ 1097] train: loss: 0.0324874
[Epoch 4; Iter   729/ 1097] train: loss: 0.1988593
[Epoch 4; Iter   759/ 1097] train: loss: 0.2838763
[Epoch 4; Iter   789/ 1097] train: loss: 0.3708489
[Epoch 4; Iter   819/ 1097] train: loss: 0.1664826
[Epoch 4; Iter   849/ 1097] train: loss: 0.0461646
[Epoch 4; Iter   879/ 1097] train: loss: 0.0283495
[Epoch 4; Iter   909/ 1097] train: loss: 0.3773086
[Epoch 4; Iter   939/ 1097] train: loss: 0.1106164
[Epoch 4; Iter   969/ 1097] train: loss: 0.0392601
[Epoch 4; Iter   999/ 1097] train: loss: 0.1785551
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3615532
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2774177
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0428436
[Epoch 4] ogbg-molhiv: 0.791186 val loss: 0.995821
[Epoch 4] ogbg-molhiv: 0.752809 test loss: 2.248495
[Epoch 5; Iter    22/ 1097] train: loss: 0.3628150
[Epoch 5; Iter    52/ 1097] train: loss: 0.1770769
[Epoch 5; Iter    82/ 1097] train: loss: 0.1046427
[Epoch 5; Iter   112/ 1097] train: loss: 0.0619117
[Epoch 5; Iter   142/ 1097] train: loss: 0.0823573
[Epoch 5; Iter   172/ 1097] train: loss: 0.0394503
[Epoch 5; Iter   202/ 1097] train: loss: 0.0962179
[Epoch 5; Iter   232/ 1097] train: loss: 0.0322781
[Epoch 5; Iter   262/ 1097] train: loss: 0.0416876
[Epoch 5; Iter   292/ 1097] train: loss: 0.1828185
[Epoch 5; Iter   322/ 1097] train: loss: 0.1555110
[Epoch 5; Iter   352/ 1097] train: loss: 0.0612446
[Epoch 5; Iter   382/ 1097] train: loss: 0.2787651
[Epoch 5; Iter   412/ 1097] train: loss: 0.2453213
[Epoch 5; Iter   442/ 1097] train: loss: 0.3473075
[Epoch 5; Iter   472/ 1097] train: loss: 0.1383016
[Epoch 5; Iter   502/ 1097] train: loss: 0.2078004
[Epoch 5; Iter   532/ 1097] train: loss: 0.0572092
[Epoch 5; Iter   562/ 1097] train: loss: 0.0399320
[Epoch 5; Iter   592/ 1097] train: loss: 0.0467700
[Epoch 5; Iter   622/ 1097] train: loss: 0.1230353
[Epoch 5; Iter   652/ 1097] train: loss: 0.1108723
[Epoch 5; Iter   682/ 1097] train: loss: 0.1714260
[Epoch 5; Iter   712/ 1097] train: loss: 0.0279052
[Epoch 5; Iter   742/ 1097] train: loss: 0.1695771
[Epoch 5; Iter   772/ 1097] train: loss: 0.1883430
[Epoch 5; Iter   802/ 1097] train: loss: 0.1392522
[Epoch 5; Iter   832/ 1097] train: loss: 0.0312133
[Epoch 5; Iter   862/ 1097] train: loss: 0.1972554
[Epoch 5; Iter   892/ 1097] train: loss: 0.0477886
[Epoch 5; Iter   922/ 1097] train: loss: 0.3172630
[Epoch 5; Iter   952/ 1097] train: loss: 0.0270963
[Epoch 5; Iter   982/ 1097] train: loss: 0.2813166
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2407015
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2031515
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0477861
[Epoch 5] ogbg-molhiv: 0.775249 val loss: 0.168750
[Epoch 5] ogbg-molhiv: 0.708465 test loss: 0.470078
[Epoch 6; Iter     5/ 1097] train: loss: 0.0795436
[Epoch 6; Iter    35/ 1097] train: loss: 0.0801857
[Epoch 6; Iter    65/ 1097] train: loss: 0.1095342
[Epoch 6; Iter    95/ 1097] train: loss: 0.0432816
[Epoch 6; Iter   125/ 1097] train: loss: 0.1137734
[Epoch 6; Iter   155/ 1097] train: loss: 0.0243676
[Epoch 6; Iter   185/ 1097] train: loss: 0.0214766
[Epoch 6; Iter   215/ 1097] train: loss: 0.3203340
[Epoch 6; Iter   245/ 1097] train: loss: 0.2106807
[Epoch 6; Iter   275/ 1097] train: loss: 0.0273914
[Epoch 6; Iter   305/ 1097] train: loss: 0.0564857
[Epoch 6; Iter   335/ 1097] train: loss: 0.1792855
[Epoch 6; Iter   365/ 1097] train: loss: 0.0571385
[Epoch 6; Iter   395/ 1097] train: loss: 0.2826931
[Epoch 6; Iter   425/ 1097] train: loss: 0.1838132
[Epoch 6; Iter   455/ 1097] train: loss: 0.1162785
[Epoch 6; Iter   485/ 1097] train: loss: 0.1684032
[Epoch 6; Iter   515/ 1097] train: loss: 0.0237380
[Epoch 6; Iter   545/ 1097] train: loss: 0.1557406
[Epoch 6; Iter   575/ 1097] train: loss: 0.0307919
[Epoch 6; Iter   605/ 1097] train: loss: 0.0225101
[Epoch 6; Iter   635/ 1097] train: loss: 0.0260817
[Epoch 6; Iter   665/ 1097] train: loss: 0.0343102
[Epoch 6; Iter   695/ 1097] train: loss: 0.1565851
[Epoch 6; Iter   725/ 1097] train: loss: 0.0273359
[Epoch 6; Iter   755/ 1097] train: loss: 0.0940512
[Epoch 6; Iter   785/ 1097] train: loss: 0.0303421
[Epoch 6; Iter   815/ 1097] train: loss: 0.1251956
[Epoch 6; Iter   845/ 1097] train: loss: 0.0881405
[Epoch 6; Iter   875/ 1097] train: loss: 0.1331940
[Epoch 6; Iter   905/ 1097] train: loss: 0.2804132
[Epoch 6; Iter   935/ 1097] train: loss: 0.1540164
[Epoch 6; Iter   965/ 1097] train: loss: 0.1250805
[Epoch 6; Iter   995/ 1097] train: loss: 0.0432384
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0314520
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0977266
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2258459
[Epoch 6] ogbg-molhiv: 0.782698 val loss: 0.256795
[Epoch 6] ogbg-molhiv: 0.760299 test loss: 0.193640
[Epoch 7; Iter    18/ 1097] train: loss: 0.0343331
[Epoch 7; Iter    48/ 1097] train: loss: 0.0666533
[Epoch 7; Iter    78/ 1097] train: loss: 0.0903987
[Epoch 7; Iter   108/ 1097] train: loss: 0.0292703
[Epoch 7; Iter   138/ 1097] train: loss: 0.0389261
[Epoch 7; Iter   168/ 1097] train: loss: 0.0894292
[Epoch 7; Iter   198/ 1097] train: loss: 0.1024997
[Epoch 7; Iter   228/ 1097] train: loss: 0.0253330
[Epoch 7; Iter   258/ 1097] train: loss: 0.0373037
[Epoch 7; Iter   288/ 1097] train: loss: 0.1046116
[Epoch 7; Iter   318/ 1097] train: loss: 0.0326404
[Epoch 7; Iter   348/ 1097] train: loss: 0.1220612
[Epoch 7; Iter   378/ 1097] train: loss: 0.1155298
[Epoch 7; Iter   408/ 1097] train: loss: 0.1545603
[Epoch 7; Iter   438/ 1097] train: loss: 0.2179063
[Epoch 7; Iter   468/ 1097] train: loss: 0.0271091
[Epoch 7; Iter   498/ 1097] train: loss: 0.0419517
[Epoch 7; Iter   528/ 1097] train: loss: 0.0295699
[Epoch 7; Iter   558/ 1097] train: loss: 0.0617017
[Epoch 7; Iter   588/ 1097] train: loss: 0.3139835
[Epoch 7; Iter   618/ 1097] train: loss: 0.3225848
[Epoch 7; Iter   648/ 1097] train: loss: 0.3361341
[Epoch 7; Iter   678/ 1097] train: loss: 0.0378796
[Epoch 7; Iter   708/ 1097] train: loss: 0.1699160
[Epoch 7; Iter   738/ 1097] train: loss: 0.1672797
[Epoch 7; Iter   768/ 1097] train: loss: 0.0356392
[Epoch 7; Iter   798/ 1097] train: loss: 0.0909415
[Epoch 7; Iter   828/ 1097] train: loss: 0.1040464
[Epoch 7; Iter   858/ 1097] train: loss: 0.0639427
[Epoch 7; Iter   888/ 1097] train: loss: 0.0226229
[Epoch 7; Iter   918/ 1097] train: loss: 0.0698384
[Epoch 7; Iter   948/ 1097] train: loss: 0.1667140
[Epoch 7; Iter   978/ 1097] train: loss: 0.0401243
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1198902
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0252935
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1334026
[Epoch 7] ogbg-molhiv: 0.741280 val loss: 0.163774
[Epoch 7] ogbg-molhiv: 0.748153 test loss: 0.816276
[Epoch 3; Iter   986/ 1097] train: loss: 0.0283640
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0451896
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1504346
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2835383
[Epoch 3] ogbg-molhiv: 0.703866 val loss: 0.366123
[Epoch 3] ogbg-molhiv: 0.648160 test loss: 0.346178
[Epoch 4; Iter     9/ 1097] train: loss: 0.2265087
[Epoch 4; Iter    39/ 1097] train: loss: 0.1892236
[Epoch 4; Iter    69/ 1097] train: loss: 0.0388921
[Epoch 4; Iter    99/ 1097] train: loss: 0.2982976
[Epoch 4; Iter   129/ 1097] train: loss: 0.1387441
[Epoch 4; Iter   159/ 1097] train: loss: 0.1244502
[Epoch 4; Iter   189/ 1097] train: loss: 0.2465242
[Epoch 4; Iter   219/ 1097] train: loss: 0.1757037
[Epoch 4; Iter   249/ 1097] train: loss: 0.2060755
[Epoch 4; Iter   279/ 1097] train: loss: 0.1169213
[Epoch 4; Iter   309/ 1097] train: loss: 0.1231243
[Epoch 4; Iter   339/ 1097] train: loss: 0.0285114
[Epoch 4; Iter   369/ 1097] train: loss: 0.1085049
[Epoch 4; Iter   399/ 1097] train: loss: 0.1209011
[Epoch 4; Iter   429/ 1097] train: loss: 0.1938841
[Epoch 4; Iter   459/ 1097] train: loss: 0.0398241
[Epoch 4; Iter   489/ 1097] train: loss: 0.1440448
[Epoch 4; Iter   519/ 1097] train: loss: 0.2882139
[Epoch 4; Iter   549/ 1097] train: loss: 0.1845179
[Epoch 4; Iter   579/ 1097] train: loss: 0.0372745
[Epoch 4; Iter   609/ 1097] train: loss: 0.3392540
[Epoch 4; Iter   639/ 1097] train: loss: 0.3596972
[Epoch 4; Iter   669/ 1097] train: loss: 0.2883170
[Epoch 4; Iter   699/ 1097] train: loss: 0.0345864
[Epoch 4; Iter   729/ 1097] train: loss: 0.1981062
[Epoch 4; Iter   759/ 1097] train: loss: 0.1974571
[Epoch 4; Iter   789/ 1097] train: loss: 0.3790152
[Epoch 4; Iter   819/ 1097] train: loss: 0.1587109
[Epoch 4; Iter   849/ 1097] train: loss: 0.0375297
[Epoch 4; Iter   879/ 1097] train: loss: 0.0330463
[Epoch 4; Iter   909/ 1097] train: loss: 0.4404026
[Epoch 4; Iter   939/ 1097] train: loss: 0.0984799
[Epoch 4; Iter   969/ 1097] train: loss: 0.0746762
[Epoch 4; Iter   999/ 1097] train: loss: 0.2036873
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3352933
[Epoch 4; Iter  1059/ 1097] train: loss: 0.3010400
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0578674
[Epoch 4] ogbg-molhiv: 0.786869 val loss: 0.086602
[Epoch 4] ogbg-molhiv: 0.715450 test loss: 0.173828
[Epoch 5; Iter    22/ 1097] train: loss: 0.2850050
[Epoch 5; Iter    52/ 1097] train: loss: 0.1523645
[Epoch 5; Iter    82/ 1097] train: loss: 0.1196165
[Epoch 5; Iter   112/ 1097] train: loss: 0.0726450
[Epoch 5; Iter   142/ 1097] train: loss: 0.0827916
[Epoch 5; Iter   172/ 1097] train: loss: 0.0426908
[Epoch 5; Iter   202/ 1097] train: loss: 0.1323755
[Epoch 5; Iter   232/ 1097] train: loss: 0.0324733
[Epoch 5; Iter   262/ 1097] train: loss: 0.0722121
[Epoch 5; Iter   292/ 1097] train: loss: 0.1877317
[Epoch 5; Iter   322/ 1097] train: loss: 0.1645608
[Epoch 5; Iter   352/ 1097] train: loss: 0.0643752
[Epoch 5; Iter   382/ 1097] train: loss: 0.2297062
[Epoch 5; Iter   412/ 1097] train: loss: 0.2552999
[Epoch 5; Iter   442/ 1097] train: loss: 0.2226172
[Epoch 5; Iter   472/ 1097] train: loss: 0.1215040
[Epoch 5; Iter   502/ 1097] train: loss: 0.1776294
[Epoch 5; Iter   532/ 1097] train: loss: 0.0489626
[Epoch 5; Iter   562/ 1097] train: loss: 0.0489366
[Epoch 5; Iter   592/ 1097] train: loss: 0.0451985
[Epoch 5; Iter   622/ 1097] train: loss: 0.1214935
[Epoch 5; Iter   652/ 1097] train: loss: 0.1291384
[Epoch 5; Iter   682/ 1097] train: loss: 0.1482025
[Epoch 5; Iter   712/ 1097] train: loss: 0.0273421
[Epoch 5; Iter   742/ 1097] train: loss: 0.1933614
[Epoch 5; Iter   772/ 1097] train: loss: 0.1684140
[Epoch 5; Iter   802/ 1097] train: loss: 0.2214386
[Epoch 5; Iter   832/ 1097] train: loss: 0.0297836
[Epoch 5; Iter   862/ 1097] train: loss: 0.2351234
[Epoch 5; Iter   892/ 1097] train: loss: 0.0450333
[Epoch 5; Iter   922/ 1097] train: loss: 0.3013011
[Epoch 5; Iter   952/ 1097] train: loss: 0.0260718
[Epoch 5; Iter   982/ 1097] train: loss: 0.2725291
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2571575
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2010105
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0375889
[Epoch 5] ogbg-molhiv: 0.773552 val loss: 0.911158
[Epoch 5] ogbg-molhiv: 0.716972 test loss: 0.233473
[Epoch 6; Iter     5/ 1097] train: loss: 0.0873405
[Epoch 6; Iter    35/ 1097] train: loss: 0.0691587
[Epoch 6; Iter    65/ 1097] train: loss: 0.1052037
[Epoch 6; Iter    95/ 1097] train: loss: 0.0428178
[Epoch 6; Iter   125/ 1097] train: loss: 0.1198641
[Epoch 6; Iter   155/ 1097] train: loss: 0.0322850
[Epoch 6; Iter   185/ 1097] train: loss: 0.0250854
[Epoch 6; Iter   215/ 1097] train: loss: 0.3091985
[Epoch 6; Iter   245/ 1097] train: loss: 0.2341661
[Epoch 6; Iter   275/ 1097] train: loss: 0.0316402
[Epoch 6; Iter   305/ 1097] train: loss: 0.0563984
[Epoch 6; Iter   335/ 1097] train: loss: 0.1495206
[Epoch 6; Iter   365/ 1097] train: loss: 0.0528075
[Epoch 6; Iter   395/ 1097] train: loss: 0.2858846
[Epoch 6; Iter   425/ 1097] train: loss: 0.1543691
[Epoch 6; Iter   455/ 1097] train: loss: 0.1173209
[Epoch 6; Iter   485/ 1097] train: loss: 0.1981760
[Epoch 6; Iter   515/ 1097] train: loss: 0.0296516
[Epoch 6; Iter   545/ 1097] train: loss: 0.1812292
[Epoch 6; Iter   575/ 1097] train: loss: 0.0394771
[Epoch 6; Iter   605/ 1097] train: loss: 0.0274890
[Epoch 6; Iter   635/ 1097] train: loss: 0.0302526
[Epoch 6; Iter   665/ 1097] train: loss: 0.0406996
[Epoch 6; Iter   695/ 1097] train: loss: 0.1673735
[Epoch 6; Iter   725/ 1097] train: loss: 0.0343991
[Epoch 6; Iter   755/ 1097] train: loss: 0.1195533
[Epoch 6; Iter   785/ 1097] train: loss: 0.0288465
[Epoch 6; Iter   815/ 1097] train: loss: 0.1274101
[Epoch 6; Iter   845/ 1097] train: loss: 0.0916761
[Epoch 6; Iter   875/ 1097] train: loss: 0.2002153
[Epoch 6; Iter   905/ 1097] train: loss: 0.3511195
[Epoch 6; Iter   935/ 1097] train: loss: 0.1626410
[Epoch 6; Iter   965/ 1097] train: loss: 0.1149354
[Epoch 6; Iter   995/ 1097] train: loss: 0.0429809
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0288834
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0798804
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2003340
[Epoch 6] ogbg-molhiv: 0.793097 val loss: 0.161958
[Epoch 6] ogbg-molhiv: 0.727102 test loss: 0.144263
[Epoch 7; Iter    18/ 1097] train: loss: 0.0373406
[Epoch 7; Iter    48/ 1097] train: loss: 0.0516720
[Epoch 7; Iter    78/ 1097] train: loss: 0.1097961
[Epoch 7; Iter   108/ 1097] train: loss: 0.0325947
[Epoch 7; Iter   138/ 1097] train: loss: 0.0339512
[Epoch 7; Iter   168/ 1097] train: loss: 0.0982116
[Epoch 7; Iter   198/ 1097] train: loss: 0.0888513
[Epoch 7; Iter   228/ 1097] train: loss: 0.0267363
[Epoch 7; Iter   258/ 1097] train: loss: 0.0850997
[Epoch 7; Iter   288/ 1097] train: loss: 0.1247840
[Epoch 7; Iter   318/ 1097] train: loss: 0.0461689
[Epoch 7; Iter   348/ 1097] train: loss: 0.1891029
[Epoch 7; Iter   378/ 1097] train: loss: 0.1510383
[Epoch 7; Iter   408/ 1097] train: loss: 0.1551450
[Epoch 7; Iter   438/ 1097] train: loss: 0.1745912
[Epoch 7; Iter   468/ 1097] train: loss: 0.0256190
[Epoch 7; Iter   498/ 1097] train: loss: 0.0348264
[Epoch 7; Iter   528/ 1097] train: loss: 0.0260574
[Epoch 7; Iter   558/ 1097] train: loss: 0.0260182
[Epoch 7; Iter   588/ 1097] train: loss: 0.2602385
[Epoch 7; Iter   618/ 1097] train: loss: 0.3208720
[Epoch 7; Iter   648/ 1097] train: loss: 0.2982784
[Epoch 7; Iter   678/ 1097] train: loss: 0.0446695
[Epoch 7; Iter   708/ 1097] train: loss: 0.1991067
[Epoch 7; Iter   738/ 1097] train: loss: 0.1849531
[Epoch 7; Iter   768/ 1097] train: loss: 0.0393251
[Epoch 7; Iter   798/ 1097] train: loss: 0.1773253
[Epoch 7; Iter   828/ 1097] train: loss: 0.1417066
[Epoch 7; Iter   858/ 1097] train: loss: 0.0832942
[Epoch 7; Iter   888/ 1097] train: loss: 0.0245139
[Epoch 7; Iter   918/ 1097] train: loss: 0.0573495
[Epoch 7; Iter   948/ 1097] train: loss: 0.1580923
[Epoch 7; Iter   978/ 1097] train: loss: 0.0320360
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1297985
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0331663
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1645668
[Epoch 7] ogbg-molhiv: 0.771280 val loss: 0.119184
[Epoch 7] ogbg-molhiv: 0.770438 test loss: 0.117549
[Epoch 3; Iter   986/ 1097] train: loss: 0.2905274
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0559927
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0618265
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0321973
[Epoch 3] ogbg-molhiv: 0.746644 val loss: 0.108831
[Epoch 3] ogbg-molhiv: 0.758178 test loss: 0.137749
[Epoch 4; Iter     9/ 1097] train: loss: 0.4417065
[Epoch 4; Iter    39/ 1097] train: loss: 0.1247925
[Epoch 4; Iter    69/ 1097] train: loss: 0.0852927
[Epoch 4; Iter    99/ 1097] train: loss: 0.0559261
[Epoch 4; Iter   129/ 1097] train: loss: 0.1678598
[Epoch 4; Iter   159/ 1097] train: loss: 0.4097250
[Epoch 4; Iter   189/ 1097] train: loss: 0.0329427
[Epoch 4; Iter   219/ 1097] train: loss: 0.3979858
[Epoch 4; Iter   249/ 1097] train: loss: 0.0450365
[Epoch 4; Iter   279/ 1097] train: loss: 0.1126383
[Epoch 4; Iter   309/ 1097] train: loss: 0.1528314
[Epoch 4; Iter   339/ 1097] train: loss: 0.1183206
[Epoch 4; Iter   369/ 1097] train: loss: 0.1149544
[Epoch 4; Iter   399/ 1097] train: loss: 0.1545167
[Epoch 4; Iter   429/ 1097] train: loss: 0.0709186
[Epoch 4; Iter   459/ 1097] train: loss: 0.0320858
[Epoch 4; Iter   489/ 1097] train: loss: 0.0323178
[Epoch 4; Iter   519/ 1097] train: loss: 0.0958915
[Epoch 4; Iter   549/ 1097] train: loss: 0.0394110
[Epoch 4; Iter   579/ 1097] train: loss: 0.0334877
[Epoch 4; Iter   609/ 1097] train: loss: 0.2452286
[Epoch 4; Iter   639/ 1097] train: loss: 0.0294124
[Epoch 4; Iter   669/ 1097] train: loss: 0.2427543
[Epoch 4; Iter   699/ 1097] train: loss: 0.0781523
[Epoch 4; Iter   729/ 1097] train: loss: 0.3726355
[Epoch 4; Iter   759/ 1097] train: loss: 0.0565226
[Epoch 4; Iter   789/ 1097] train: loss: 0.3241040
[Epoch 4; Iter   819/ 1097] train: loss: 0.0350830
[Epoch 4; Iter   849/ 1097] train: loss: 0.2276465
[Epoch 4; Iter   879/ 1097] train: loss: 0.1236598
[Epoch 4; Iter   909/ 1097] train: loss: 0.5095119
[Epoch 4; Iter   939/ 1097] train: loss: 0.0333912
[Epoch 4; Iter   969/ 1097] train: loss: 0.0432123
[Epoch 4; Iter   999/ 1097] train: loss: 0.3333614
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3029038
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2056342
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0775999
[Epoch 4] ogbg-molhiv: 0.745490 val loss: 0.149005
[Epoch 4] ogbg-molhiv: 0.755109 test loss: 0.126339
[Epoch 5; Iter    22/ 1097] train: loss: 0.0529736
[Epoch 5; Iter    52/ 1097] train: loss: 0.1217709
[Epoch 5; Iter    82/ 1097] train: loss: 0.3420508
[Epoch 5; Iter   112/ 1097] train: loss: 0.0722291
[Epoch 5; Iter   142/ 1097] train: loss: 0.3269139
[Epoch 5; Iter   172/ 1097] train: loss: 0.1897464
[Epoch 5; Iter   202/ 1097] train: loss: 0.0287114
[Epoch 5; Iter   232/ 1097] train: loss: 0.1420245
[Epoch 5; Iter   262/ 1097] train: loss: 0.1670668
[Epoch 5; Iter   292/ 1097] train: loss: 0.2727235
[Epoch 5; Iter   322/ 1097] train: loss: 0.1852581
[Epoch 5; Iter   352/ 1097] train: loss: 0.2050150
[Epoch 5; Iter   382/ 1097] train: loss: 0.2636809
[Epoch 5; Iter   412/ 1097] train: loss: 0.0417911
[Epoch 5; Iter   442/ 1097] train: loss: 0.1505007
[Epoch 5; Iter   472/ 1097] train: loss: 0.1981138
[Epoch 5; Iter   502/ 1097] train: loss: 0.1148048
[Epoch 5; Iter   532/ 1097] train: loss: 0.0377183
[Epoch 5; Iter   562/ 1097] train: loss: 0.2504078
[Epoch 5; Iter   592/ 1097] train: loss: 0.0597884
[Epoch 5; Iter   622/ 1097] train: loss: 0.1923855
[Epoch 5; Iter   652/ 1097] train: loss: 0.2356024
[Epoch 5; Iter   682/ 1097] train: loss: 0.0292396
[Epoch 5; Iter   712/ 1097] train: loss: 0.1967008
[Epoch 5; Iter   742/ 1097] train: loss: 0.0270579
[Epoch 5; Iter   772/ 1097] train: loss: 0.0355080
[Epoch 5; Iter   802/ 1097] train: loss: 0.1825928
[Epoch 5; Iter   832/ 1097] train: loss: 0.2760696
[Epoch 5; Iter   862/ 1097] train: loss: 0.0381925
[Epoch 5; Iter   892/ 1097] train: loss: 0.1159165
[Epoch 5; Iter   922/ 1097] train: loss: 0.0956143
[Epoch 5; Iter   952/ 1097] train: loss: 0.2390369
[Epoch 5; Iter   982/ 1097] train: loss: 0.1339480
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2474696
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2840645
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0376699
[Epoch 5] ogbg-molhiv: 0.762845 val loss: 0.120159
[Epoch 5] ogbg-molhiv: 0.760882 test loss: 0.135722
[Epoch 6; Iter     5/ 1097] train: loss: 0.2057441
[Epoch 6; Iter    35/ 1097] train: loss: 0.4103926
[Epoch 6; Iter    65/ 1097] train: loss: 0.0342279
[Epoch 6; Iter    95/ 1097] train: loss: 0.1487509
[Epoch 6; Iter   125/ 1097] train: loss: 0.3048868
[Epoch 6; Iter   155/ 1097] train: loss: 0.0595735
[Epoch 6; Iter   185/ 1097] train: loss: 0.1375965
[Epoch 6; Iter   215/ 1097] train: loss: 0.1408213
[Epoch 6; Iter   245/ 1097] train: loss: 0.0640058
[Epoch 6; Iter   275/ 1097] train: loss: 0.1542104
[Epoch 6; Iter   305/ 1097] train: loss: 0.0315308
[Epoch 6; Iter   335/ 1097] train: loss: 0.0421937
[Epoch 6; Iter   365/ 1097] train: loss: 0.0429180
[Epoch 6; Iter   395/ 1097] train: loss: 0.1290672
[Epoch 6; Iter   425/ 1097] train: loss: 0.0565437
[Epoch 6; Iter   455/ 1097] train: loss: 0.2992877
[Epoch 6; Iter   485/ 1097] train: loss: 0.0345900
[Epoch 6; Iter   515/ 1097] train: loss: 0.1219256
[Epoch 6; Iter   545/ 1097] train: loss: 0.1588985
[Epoch 6; Iter   575/ 1097] train: loss: 0.0370428
[Epoch 6; Iter   605/ 1097] train: loss: 0.0597582
[Epoch 6; Iter   635/ 1097] train: loss: 0.2071685
[Epoch 6; Iter   665/ 1097] train: loss: 0.2152157
[Epoch 6; Iter   695/ 1097] train: loss: 0.2903106
[Epoch 6; Iter   725/ 1097] train: loss: 0.2937962
[Epoch 6; Iter   755/ 1097] train: loss: 0.2917462
[Epoch 6; Iter   785/ 1097] train: loss: 0.4055764
[Epoch 6; Iter   815/ 1097] train: loss: 0.0772801
[Epoch 6; Iter   845/ 1097] train: loss: 0.0329663
[Epoch 6; Iter   875/ 1097] train: loss: 0.0771308
[Epoch 6; Iter   905/ 1097] train: loss: 0.1810951
[Epoch 6; Iter   935/ 1097] train: loss: 0.0642448
[Epoch 6; Iter   965/ 1097] train: loss: 0.0631300
[Epoch 6; Iter   995/ 1097] train: loss: 0.1089511
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1461481
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1508006
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1860052
[Epoch 6] ogbg-molhiv: 0.760873 val loss: 0.089703
[Epoch 6] ogbg-molhiv: 0.714556 test loss: 0.122489
[Epoch 7; Iter    18/ 1097] train: loss: 0.0378814
[Epoch 7; Iter    48/ 1097] train: loss: 0.0337637
[Epoch 7; Iter    78/ 1097] train: loss: 0.1514811
[Epoch 7; Iter   108/ 1097] train: loss: 0.2840567
[Epoch 7; Iter   138/ 1097] train: loss: 0.1753304
[Epoch 7; Iter   168/ 1097] train: loss: 0.0258293
[Epoch 7; Iter   198/ 1097] train: loss: 0.2917140
[Epoch 7; Iter   228/ 1097] train: loss: 0.1693724
[Epoch 7; Iter   258/ 1097] train: loss: 0.0211240
[Epoch 7; Iter   288/ 1097] train: loss: 0.0251979
[Epoch 7; Iter   318/ 1097] train: loss: 0.1860716
[Epoch 7; Iter   348/ 1097] train: loss: 0.0280033
[Epoch 7; Iter   378/ 1097] train: loss: 0.1871184
[Epoch 7; Iter   408/ 1097] train: loss: 0.2652086
[Epoch 7; Iter   438/ 1097] train: loss: 0.0608163
[Epoch 7; Iter   468/ 1097] train: loss: 0.0300380
[Epoch 7; Iter   498/ 1097] train: loss: 0.1876845
[Epoch 7; Iter   528/ 1097] train: loss: 0.1276302
[Epoch 7; Iter   558/ 1097] train: loss: 0.0330069
[Epoch 7; Iter   588/ 1097] train: loss: 0.2155078
[Epoch 7; Iter   618/ 1097] train: loss: 0.1136957
[Epoch 7; Iter   648/ 1097] train: loss: 0.0917897
[Epoch 7; Iter   678/ 1097] train: loss: 0.0328571
[Epoch 7; Iter   708/ 1097] train: loss: 0.2244739
[Epoch 7; Iter   738/ 1097] train: loss: 0.1691525
[Epoch 7; Iter   768/ 1097] train: loss: 0.1755500
[Epoch 7; Iter   798/ 1097] train: loss: 0.1507523
[Epoch 7; Iter   828/ 1097] train: loss: 0.0409944
[Epoch 7; Iter   858/ 1097] train: loss: 0.2149813
[Epoch 7; Iter   888/ 1097] train: loss: 0.0353574
[Epoch 7; Iter   918/ 1097] train: loss: 0.1571153
[Epoch 7; Iter   948/ 1097] train: loss: 0.0419187
[Epoch 7; Iter   978/ 1097] train: loss: 0.0536406
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0472635
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0272671
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1696731
[Epoch 7] ogbg-molhiv: 0.730796 val loss: 0.094357
[Epoch 7] ogbg-molhiv: 0.755625 test loss: 0.117037
[Epoch 3; Iter   986/ 1097] train: loss: 0.0402389
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2848434
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0293655
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1123367
[Epoch 3] ogbg-molhiv: 0.722354 val loss: 0.094730
[Epoch 3] ogbg-molhiv: 0.738336 test loss: 0.120471
[Epoch 4; Iter     9/ 1097] train: loss: 0.0716765
[Epoch 4; Iter    39/ 1097] train: loss: 0.0402382
[Epoch 4; Iter    69/ 1097] train: loss: 0.0274996
[Epoch 4; Iter    99/ 1097] train: loss: 0.0275412
[Epoch 4; Iter   129/ 1097] train: loss: 0.2416076
[Epoch 4; Iter   159/ 1097] train: loss: 0.1403160
[Epoch 4; Iter   189/ 1097] train: loss: 0.0399601
[Epoch 4; Iter   219/ 1097] train: loss: 0.0379655
[Epoch 4; Iter   249/ 1097] train: loss: 0.1415080
[Epoch 4; Iter   279/ 1097] train: loss: 0.2587893
[Epoch 4; Iter   309/ 1097] train: loss: 0.0435335
[Epoch 4; Iter   339/ 1097] train: loss: 0.0502607
[Epoch 4; Iter   369/ 1097] train: loss: 0.0682988
[Epoch 4; Iter   399/ 1097] train: loss: 0.2290367
[Epoch 4; Iter   429/ 1097] train: loss: 0.0314051
[Epoch 4; Iter   459/ 1097] train: loss: 0.1303432
[Epoch 4; Iter   489/ 1097] train: loss: 0.0271264
[Epoch 4; Iter   519/ 1097] train: loss: 0.1694873
[Epoch 4; Iter   549/ 1097] train: loss: 0.0331580
[Epoch 4; Iter   579/ 1097] train: loss: 0.0827491
[Epoch 4; Iter   609/ 1097] train: loss: 0.1352046
[Epoch 4; Iter   639/ 1097] train: loss: 0.1063055
[Epoch 4; Iter   669/ 1097] train: loss: 0.1912109
[Epoch 4; Iter   699/ 1097] train: loss: 0.1060150
[Epoch 4; Iter   729/ 1097] train: loss: 0.0331690
[Epoch 4; Iter   759/ 1097] train: loss: 0.0288598
[Epoch 4; Iter   789/ 1097] train: loss: 0.0356122
[Epoch 4; Iter   819/ 1097] train: loss: 0.1298797
[Epoch 4; Iter   849/ 1097] train: loss: 0.0278236
[Epoch 4; Iter   879/ 1097] train: loss: 0.0559625
[Epoch 4; Iter   909/ 1097] train: loss: 0.0339558
[Epoch 4; Iter   939/ 1097] train: loss: 0.2755828
[Epoch 4; Iter   969/ 1097] train: loss: 0.0715254
[Epoch 4; Iter   999/ 1097] train: loss: 0.0380698
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2156438
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1539651
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1753961
[Epoch 4] ogbg-molhiv: 0.767122 val loss: 1.745616
[Epoch 4] ogbg-molhiv: 0.757089 test loss: 1.434390
[Epoch 5; Iter    22/ 1097] train: loss: 0.1264097
[Epoch 5; Iter    52/ 1097] train: loss: 0.1468964
[Epoch 5; Iter    82/ 1097] train: loss: 0.1487200
[Epoch 5; Iter   112/ 1097] train: loss: 0.3842149
[Epoch 5; Iter   142/ 1097] train: loss: 0.3378121
[Epoch 5; Iter   172/ 1097] train: loss: 0.0288749
[Epoch 5; Iter   202/ 1097] train: loss: 0.1860803
[Epoch 5; Iter   232/ 1097] train: loss: 0.1989372
[Epoch 5; Iter   262/ 1097] train: loss: 0.0453815
[Epoch 5; Iter   292/ 1097] train: loss: 0.1961270
[Epoch 5; Iter   322/ 1097] train: loss: 0.0292777
[Epoch 5; Iter   352/ 1097] train: loss: 0.1206229
[Epoch 5; Iter   382/ 1097] train: loss: 0.1368031
[Epoch 5; Iter   412/ 1097] train: loss: 0.3521530
[Epoch 5; Iter   442/ 1097] train: loss: 0.1300432
[Epoch 5; Iter   472/ 1097] train: loss: 0.1133007
[Epoch 5; Iter   502/ 1097] train: loss: 0.1734112
[Epoch 5; Iter   532/ 1097] train: loss: 0.2326766
[Epoch 5; Iter   562/ 1097] train: loss: 0.2981706
[Epoch 5; Iter   592/ 1097] train: loss: 0.0635704
[Epoch 5; Iter   622/ 1097] train: loss: 0.0378841
[Epoch 5; Iter   652/ 1097] train: loss: 0.1139393
[Epoch 5; Iter   682/ 1097] train: loss: 0.1472413
[Epoch 5; Iter   712/ 1097] train: loss: 0.0294318
[Epoch 5; Iter   742/ 1097] train: loss: 0.1528986
[Epoch 5; Iter   772/ 1097] train: loss: 0.2523045
[Epoch 5; Iter   802/ 1097] train: loss: 0.0655187
[Epoch 5; Iter   832/ 1097] train: loss: 0.0637336
[Epoch 5; Iter   862/ 1097] train: loss: 0.0803326
[Epoch 5; Iter   892/ 1097] train: loss: 0.0444311
[Epoch 5; Iter   922/ 1097] train: loss: 0.0464348
[Epoch 5; Iter   952/ 1097] train: loss: 0.0301758
[Epoch 5; Iter   982/ 1097] train: loss: 0.0714626
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0385877
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2262325
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0399756
[Epoch 5] ogbg-molhiv: 0.743717 val loss: 0.086670
[Epoch 5] ogbg-molhiv: 0.743506 test loss: 0.117916
[Epoch 6; Iter     5/ 1097] train: loss: 0.1132366
[Epoch 6; Iter    35/ 1097] train: loss: 0.3223284
[Epoch 6; Iter    65/ 1097] train: loss: 0.0248737
[Epoch 6; Iter    95/ 1097] train: loss: 0.0730143
[Epoch 6; Iter   125/ 1097] train: loss: 0.4557749
[Epoch 6; Iter   155/ 1097] train: loss: 0.3925524
[Epoch 6; Iter   185/ 1097] train: loss: 0.0335986
[Epoch 6; Iter   215/ 1097] train: loss: 0.1372171
[Epoch 6; Iter   245/ 1097] train: loss: 0.2936650
[Epoch 6; Iter   275/ 1097] train: loss: 0.0416813
[Epoch 6; Iter   305/ 1097] train: loss: 0.1709053
[Epoch 6; Iter   335/ 1097] train: loss: 0.0655553
[Epoch 6; Iter   365/ 1097] train: loss: 0.2568775
[Epoch 6; Iter   395/ 1097] train: loss: 0.2604904
[Epoch 6; Iter   425/ 1097] train: loss: 0.0401213
[Epoch 6; Iter   455/ 1097] train: loss: 0.3579696
[Epoch 6; Iter   485/ 1097] train: loss: 0.0336310
[Epoch 6; Iter   515/ 1097] train: loss: 0.1067733
[Epoch 6; Iter   545/ 1097] train: loss: 0.1879311
[Epoch 6; Iter   575/ 1097] train: loss: 0.1646165
[Epoch 6; Iter   605/ 1097] train: loss: 0.0370105
[Epoch 6; Iter   635/ 1097] train: loss: 0.0301534
[Epoch 6; Iter   665/ 1097] train: loss: 0.2060930
[Epoch 6; Iter   695/ 1097] train: loss: 0.2303516
[Epoch 6; Iter   725/ 1097] train: loss: 0.2158252
[Epoch 6; Iter   755/ 1097] train: loss: 0.0503003
[Epoch 6; Iter   785/ 1097] train: loss: 0.1075529
[Epoch 6; Iter   815/ 1097] train: loss: 0.0375725
[Epoch 6; Iter   845/ 1097] train: loss: 0.0815333
[Epoch 6; Iter   875/ 1097] train: loss: 0.1295419
[Epoch 6; Iter   905/ 1097] train: loss: 0.3315040
[Epoch 6; Iter   935/ 1097] train: loss: 0.0351581
[Epoch 6; Iter   965/ 1097] train: loss: 0.0277897
[Epoch 6; Iter   995/ 1097] train: loss: 0.1570939
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1782520
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0282782
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2087982
[Epoch 6] ogbg-molhiv: 0.786106 val loss: 0.526001
[Epoch 6] ogbg-molhiv: 0.758193 test loss: 0.472797
[Epoch 7; Iter    18/ 1097] train: loss: 0.2018957
[Epoch 7; Iter    48/ 1097] train: loss: 0.7581927
[Epoch 7; Iter    78/ 1097] train: loss: 0.3893885
[Epoch 7; Iter   108/ 1097] train: loss: 0.0415448
[Epoch 7; Iter   138/ 1097] train: loss: 0.0246942
[Epoch 7; Iter   168/ 1097] train: loss: 0.0413201
[Epoch 7; Iter   198/ 1097] train: loss: 0.1655759
[Epoch 7; Iter   228/ 1097] train: loss: 0.1698209
[Epoch 7; Iter   258/ 1097] train: loss: 0.1450005
[Epoch 7; Iter   288/ 1097] train: loss: 0.1799158
[Epoch 7; Iter   318/ 1097] train: loss: 0.0354495
[Epoch 7; Iter   348/ 1097] train: loss: 0.0633124
[Epoch 7; Iter   378/ 1097] train: loss: 0.0262950
[Epoch 7; Iter   408/ 1097] train: loss: 0.0373653
[Epoch 7; Iter   438/ 1097] train: loss: 0.0441235
[Epoch 7; Iter   468/ 1097] train: loss: 0.2351826
[Epoch 7; Iter   498/ 1097] train: loss: 0.0423153
[Epoch 7; Iter   528/ 1097] train: loss: 0.0354523
[Epoch 7; Iter   558/ 1097] train: loss: 0.2802237
[Epoch 7; Iter   588/ 1097] train: loss: 0.2004071
[Epoch 7; Iter   618/ 1097] train: loss: 0.1984669
[Epoch 7; Iter   648/ 1097] train: loss: 0.2031716
[Epoch 7; Iter   678/ 1097] train: loss: 0.0937091
[Epoch 7; Iter   708/ 1097] train: loss: 0.0881533
[Epoch 7; Iter   738/ 1097] train: loss: 0.0470825
[Epoch 7; Iter   768/ 1097] train: loss: 0.1144359
[Epoch 7; Iter   798/ 1097] train: loss: 0.2544943
[Epoch 7; Iter   828/ 1097] train: loss: 0.1675421
[Epoch 7; Iter   858/ 1097] train: loss: 0.2540489
[Epoch 7; Iter   888/ 1097] train: loss: 0.1950087
[Epoch 7; Iter   918/ 1097] train: loss: 0.1477308
[Epoch 7; Iter   948/ 1097] train: loss: 0.1790949
[Epoch 7; Iter   978/ 1097] train: loss: 0.1177387
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0243919
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2719889
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0458244
[Epoch 7] ogbg-molhiv: 0.801575 val loss: 0.360221
[Epoch 7] ogbg-molhiv: 0.760086 test loss: 0.216804
[Epoch 3; Iter   986/ 1097] train: loss: 0.0373331
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0356869
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1268832
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2864563
[Epoch 3] ogbg-molhiv: 0.748864 val loss: 0.085303
[Epoch 3] ogbg-molhiv: 0.711960 test loss: 0.127330
[Epoch 4; Iter     9/ 1097] train: loss: 0.2362702
[Epoch 4; Iter    39/ 1097] train: loss: 0.1745079
[Epoch 4; Iter    69/ 1097] train: loss: 0.0409605
[Epoch 4; Iter    99/ 1097] train: loss: 0.3177418
[Epoch 4; Iter   129/ 1097] train: loss: 0.1685742
[Epoch 4; Iter   159/ 1097] train: loss: 0.0813761
[Epoch 4; Iter   189/ 1097] train: loss: 0.2767805
[Epoch 4; Iter   219/ 1097] train: loss: 0.1920360
[Epoch 4; Iter   249/ 1097] train: loss: 0.1891868
[Epoch 4; Iter   279/ 1097] train: loss: 0.1896883
[Epoch 4; Iter   309/ 1097] train: loss: 0.0829339
[Epoch 4; Iter   339/ 1097] train: loss: 0.0309429
[Epoch 4; Iter   369/ 1097] train: loss: 0.1289713
[Epoch 4; Iter   399/ 1097] train: loss: 0.1495779
[Epoch 4; Iter   429/ 1097] train: loss: 0.1636134
[Epoch 4; Iter   459/ 1097] train: loss: 0.0354055
[Epoch 4; Iter   489/ 1097] train: loss: 0.1608938
[Epoch 4; Iter   519/ 1097] train: loss: 0.3333410
[Epoch 4; Iter   549/ 1097] train: loss: 0.1822280
[Epoch 4; Iter   579/ 1097] train: loss: 0.0322922
[Epoch 4; Iter   609/ 1097] train: loss: 0.3248037
[Epoch 4; Iter   639/ 1097] train: loss: 0.3052079
[Epoch 4; Iter   669/ 1097] train: loss: 0.2690468
[Epoch 4; Iter   699/ 1097] train: loss: 0.0369887
[Epoch 4; Iter   729/ 1097] train: loss: 0.2004274
[Epoch 4; Iter   759/ 1097] train: loss: 0.2209348
[Epoch 4; Iter   789/ 1097] train: loss: 0.3950561
[Epoch 4; Iter   819/ 1097] train: loss: 0.1623002
[Epoch 4; Iter   849/ 1097] train: loss: 0.0435971
[Epoch 4; Iter   879/ 1097] train: loss: 0.0477462
[Epoch 4; Iter   909/ 1097] train: loss: 0.4011831
[Epoch 4; Iter   939/ 1097] train: loss: 0.1252858
[Epoch 4; Iter   969/ 1097] train: loss: 0.0482200
[Epoch 4; Iter   999/ 1097] train: loss: 0.1923167
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2956424
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2839550
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0435120
[Epoch 4] ogbg-molhiv: 0.729647 val loss: 0.092891
[Epoch 4] ogbg-molhiv: 0.721346 test loss: 0.124574
[Epoch 5; Iter    22/ 1097] train: loss: 0.3640666
[Epoch 5; Iter    52/ 1097] train: loss: 0.1750354
[Epoch 5; Iter    82/ 1097] train: loss: 0.0883983
[Epoch 5; Iter   112/ 1097] train: loss: 0.1073708
[Epoch 5; Iter   142/ 1097] train: loss: 0.0944470
[Epoch 5; Iter   172/ 1097] train: loss: 0.0424969
[Epoch 5; Iter   202/ 1097] train: loss: 0.1702759
[Epoch 5; Iter   232/ 1097] train: loss: 0.0441159
[Epoch 5; Iter   262/ 1097] train: loss: 0.0545216
[Epoch 5; Iter   292/ 1097] train: loss: 0.1942616
[Epoch 5; Iter   322/ 1097] train: loss: 0.1562640
[Epoch 5; Iter   352/ 1097] train: loss: 0.0658403
[Epoch 5; Iter   382/ 1097] train: loss: 0.2250571
[Epoch 5; Iter   412/ 1097] train: loss: 0.2956498
[Epoch 5; Iter   442/ 1097] train: loss: 0.2759835
[Epoch 5; Iter   472/ 1097] train: loss: 0.1320210
[Epoch 5; Iter   502/ 1097] train: loss: 0.2041512
[Epoch 5; Iter   532/ 1097] train: loss: 0.0654482
[Epoch 5; Iter   562/ 1097] train: loss: 0.0672940
[Epoch 5; Iter   592/ 1097] train: loss: 0.0427228
[Epoch 5; Iter   622/ 1097] train: loss: 0.1128422
[Epoch 5; Iter   652/ 1097] train: loss: 0.1235450
[Epoch 5; Iter   682/ 1097] train: loss: 0.1547800
[Epoch 5; Iter   712/ 1097] train: loss: 0.0265521
[Epoch 5; Iter   742/ 1097] train: loss: 0.1714000
[Epoch 5; Iter   772/ 1097] train: loss: 0.1614653
[Epoch 5; Iter   802/ 1097] train: loss: 0.2408893
[Epoch 5; Iter   832/ 1097] train: loss: 0.0332110
[Epoch 5; Iter   862/ 1097] train: loss: 0.1855578
[Epoch 5; Iter   892/ 1097] train: loss: 0.0335048
[Epoch 5; Iter   922/ 1097] train: loss: 0.3080989
[Epoch 5; Iter   952/ 1097] train: loss: 0.0263538
[Epoch 5; Iter   982/ 1097] train: loss: 0.2433462
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2497921
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2310732
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0430953
[Epoch 5] ogbg-molhiv: 0.684894 val loss: 0.091072
[Epoch 5] ogbg-molhiv: 0.648068 test loss: 0.128457
[Epoch 6; Iter     5/ 1097] train: loss: 0.0571793
[Epoch 6; Iter    35/ 1097] train: loss: 0.1266349
[Epoch 6; Iter    65/ 1097] train: loss: 0.1352690
[Epoch 6; Iter    95/ 1097] train: loss: 0.0586114
[Epoch 6; Iter   125/ 1097] train: loss: 0.1281729
[Epoch 6; Iter   155/ 1097] train: loss: 0.0261283
[Epoch 6; Iter   185/ 1097] train: loss: 0.0316020
[Epoch 6; Iter   215/ 1097] train: loss: 0.2702404
[Epoch 6; Iter   245/ 1097] train: loss: 0.2473444
[Epoch 6; Iter   275/ 1097] train: loss: 0.0297718
[Epoch 6; Iter   305/ 1097] train: loss: 0.0395327
[Epoch 6; Iter   335/ 1097] train: loss: 0.1986402
[Epoch 6; Iter   365/ 1097] train: loss: 0.0593424
[Epoch 6; Iter   395/ 1097] train: loss: 0.2518321
[Epoch 6; Iter   425/ 1097] train: loss: 0.1684129
[Epoch 6; Iter   455/ 1097] train: loss: 0.1350211
[Epoch 6; Iter   485/ 1097] train: loss: 0.1847183
[Epoch 6; Iter   515/ 1097] train: loss: 0.0275544
[Epoch 6; Iter   545/ 1097] train: loss: 0.1536637
[Epoch 6; Iter   575/ 1097] train: loss: 0.0520446
[Epoch 6; Iter   605/ 1097] train: loss: 0.0321875
[Epoch 6; Iter   635/ 1097] train: loss: 0.0319677
[Epoch 6; Iter   665/ 1097] train: loss: 0.0314188
[Epoch 6; Iter   695/ 1097] train: loss: 0.1688179
[Epoch 6; Iter   725/ 1097] train: loss: 0.0360350
[Epoch 6; Iter   755/ 1097] train: loss: 0.1024447
[Epoch 6; Iter   785/ 1097] train: loss: 0.0283458
[Epoch 6; Iter   815/ 1097] train: loss: 0.1667157
[Epoch 6; Iter   845/ 1097] train: loss: 0.1213594
[Epoch 6; Iter   875/ 1097] train: loss: 0.2057215
[Epoch 6; Iter   905/ 1097] train: loss: 0.3754759
[Epoch 6; Iter   935/ 1097] train: loss: 0.1645745
[Epoch 6; Iter   965/ 1097] train: loss: 0.1070340
[Epoch 6; Iter   995/ 1097] train: loss: 0.0371296
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0312065
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0615083
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1850264
[Epoch 6] ogbg-molhiv: 0.762727 val loss: 0.088627
[Epoch 6] ogbg-molhiv: 0.728394 test loss: 0.129921
[Epoch 7; Iter    18/ 1097] train: loss: 0.0385172
[Epoch 7; Iter    48/ 1097] train: loss: 0.0585165
[Epoch 7; Iter    78/ 1097] train: loss: 0.0919393
[Epoch 7; Iter   108/ 1097] train: loss: 0.0331464
[Epoch 7; Iter   138/ 1097] train: loss: 0.0426962
[Epoch 7; Iter   168/ 1097] train: loss: 0.1020237
[Epoch 7; Iter   198/ 1097] train: loss: 0.1245475
[Epoch 7; Iter   228/ 1097] train: loss: 0.0312672
[Epoch 7; Iter   258/ 1097] train: loss: 0.1021374
[Epoch 7; Iter   288/ 1097] train: loss: 0.0630741
[Epoch 7; Iter   318/ 1097] train: loss: 0.0755437
[Epoch 7; Iter   348/ 1097] train: loss: 0.1918534
[Epoch 7; Iter   378/ 1097] train: loss: 0.1449483
[Epoch 7; Iter   408/ 1097] train: loss: 0.1580382
[Epoch 7; Iter   438/ 1097] train: loss: 0.1354812
[Epoch 7; Iter   468/ 1097] train: loss: 0.0322908
[Epoch 7; Iter   498/ 1097] train: loss: 0.0275233
[Epoch 7; Iter   528/ 1097] train: loss: 0.0384626
[Epoch 7; Iter   558/ 1097] train: loss: 0.1122813
[Epoch 7; Iter   588/ 1097] train: loss: 0.2846960
[Epoch 7; Iter   618/ 1097] train: loss: 0.3174838
[Epoch 7; Iter   648/ 1097] train: loss: 0.3293266
[Epoch 7; Iter   678/ 1097] train: loss: 0.0453388
[Epoch 7; Iter   708/ 1097] train: loss: 0.1777005
[Epoch 7; Iter   738/ 1097] train: loss: 0.1645868
[Epoch 7; Iter   768/ 1097] train: loss: 0.0487111
[Epoch 7; Iter   798/ 1097] train: loss: 0.1017667
[Epoch 7; Iter   828/ 1097] train: loss: 0.1360462
[Epoch 7; Iter   858/ 1097] train: loss: 0.0980123
[Epoch 7; Iter   888/ 1097] train: loss: 0.0305052
[Epoch 7; Iter   918/ 1097] train: loss: 0.0543947
[Epoch 7; Iter   948/ 1097] train: loss: 0.1824752
[Epoch 7; Iter   978/ 1097] train: loss: 0.0497425
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1302514
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0308372
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1799725
[Epoch 7] ogbg-molhiv: 0.735658 val loss: 0.142998
[Epoch 7] ogbg-molhiv: 0.731381 test loss: 0.163597
[Epoch 3; Iter   986/ 1097] train: loss: 0.3365250
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1123506
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0768172
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0396913
[Epoch 3] ogbg-molhiv: 0.730924 val loss: 0.370734
[Epoch 3] ogbg-molhiv: 0.756986 test loss: 0.143026
[Epoch 4; Iter     9/ 1097] train: loss: 0.3844759
[Epoch 4; Iter    39/ 1097] train: loss: 0.0887933
[Epoch 4; Iter    69/ 1097] train: loss: 0.0886767
[Epoch 4; Iter    99/ 1097] train: loss: 0.0318544
[Epoch 4; Iter   129/ 1097] train: loss: 0.1248133
[Epoch 4; Iter   159/ 1097] train: loss: 0.4617574
[Epoch 4; Iter   189/ 1097] train: loss: 0.0310984
[Epoch 4; Iter   219/ 1097] train: loss: 0.3558963
[Epoch 4; Iter   249/ 1097] train: loss: 0.0792551
[Epoch 4; Iter   279/ 1097] train: loss: 0.1374473
[Epoch 4; Iter   309/ 1097] train: loss: 0.1331553
[Epoch 4; Iter   339/ 1097] train: loss: 0.1191280
[Epoch 4; Iter   369/ 1097] train: loss: 0.1433942
[Epoch 4; Iter   399/ 1097] train: loss: 0.1578159
[Epoch 4; Iter   429/ 1097] train: loss: 0.0696245
[Epoch 4; Iter   459/ 1097] train: loss: 0.0335810
[Epoch 4; Iter   489/ 1097] train: loss: 0.0319473
[Epoch 4; Iter   519/ 1097] train: loss: 0.1096160
[Epoch 4; Iter   549/ 1097] train: loss: 0.0422161
[Epoch 4; Iter   579/ 1097] train: loss: 0.0386669
[Epoch 4; Iter   609/ 1097] train: loss: 0.2625175
[Epoch 4; Iter   639/ 1097] train: loss: 0.0292065
[Epoch 4; Iter   669/ 1097] train: loss: 0.2663087
[Epoch 4; Iter   699/ 1097] train: loss: 0.0721233
[Epoch 4; Iter   729/ 1097] train: loss: 0.4040570
[Epoch 4; Iter   759/ 1097] train: loss: 0.0640595
[Epoch 4; Iter   789/ 1097] train: loss: 0.3173824
[Epoch 4; Iter   819/ 1097] train: loss: 0.0364141
[Epoch 4; Iter   849/ 1097] train: loss: 0.2240529
[Epoch 4; Iter   879/ 1097] train: loss: 0.1286203
[Epoch 4; Iter   909/ 1097] train: loss: 0.5274184
[Epoch 4; Iter   939/ 1097] train: loss: 0.0362592
[Epoch 4; Iter   969/ 1097] train: loss: 0.0598000
[Epoch 4; Iter   999/ 1097] train: loss: 0.3020751
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2863901
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2064826
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1034844
[Epoch 4] ogbg-molhiv: 0.699588 val loss: 0.099314
[Epoch 4] ogbg-molhiv: 0.732270 test loss: 0.118723
[Epoch 5; Iter    22/ 1097] train: loss: 0.0487141
[Epoch 5; Iter    52/ 1097] train: loss: 0.1368908
[Epoch 5; Iter    82/ 1097] train: loss: 0.3155103
[Epoch 5; Iter   112/ 1097] train: loss: 0.0389275
[Epoch 5; Iter   142/ 1097] train: loss: 0.3295372
[Epoch 5; Iter   172/ 1097] train: loss: 0.1945859
[Epoch 5; Iter   202/ 1097] train: loss: 0.0315634
[Epoch 5; Iter   232/ 1097] train: loss: 0.1339311
[Epoch 5; Iter   262/ 1097] train: loss: 0.1693380
[Epoch 5; Iter   292/ 1097] train: loss: 0.2871182
[Epoch 5; Iter   322/ 1097] train: loss: 0.1705631
[Epoch 5; Iter   352/ 1097] train: loss: 0.1738982
[Epoch 5; Iter   382/ 1097] train: loss: 0.2773618
[Epoch 5; Iter   412/ 1097] train: loss: 0.0349828
[Epoch 5; Iter   442/ 1097] train: loss: 0.1485834
[Epoch 5; Iter   472/ 1097] train: loss: 0.1524831
[Epoch 5; Iter   502/ 1097] train: loss: 0.1692186
[Epoch 5; Iter   532/ 1097] train: loss: 0.0417467
[Epoch 5; Iter   562/ 1097] train: loss: 0.2402173
[Epoch 5; Iter   592/ 1097] train: loss: 0.0739587
[Epoch 5; Iter   622/ 1097] train: loss: 0.2360783
[Epoch 5; Iter   652/ 1097] train: loss: 0.2486371
[Epoch 5; Iter   682/ 1097] train: loss: 0.0331888
[Epoch 5; Iter   712/ 1097] train: loss: 0.1881034
[Epoch 5; Iter   742/ 1097] train: loss: 0.0270426
[Epoch 5; Iter   772/ 1097] train: loss: 0.0343921
[Epoch 5; Iter   802/ 1097] train: loss: 0.2415675
[Epoch 5; Iter   832/ 1097] train: loss: 0.3323216
[Epoch 5; Iter   862/ 1097] train: loss: 0.1174756
[Epoch 5; Iter   892/ 1097] train: loss: 0.1395807
[Epoch 5; Iter   922/ 1097] train: loss: 0.1295484
[Epoch 5; Iter   952/ 1097] train: loss: 0.2455558
[Epoch 5; Iter   982/ 1097] train: loss: 0.1312424
[Epoch 5; Iter  1012/ 1097] train: loss: 0.3092671
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2475354
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0394581
[Epoch 5] ogbg-molhiv: 0.761516 val loss: 0.232264
[Epoch 5] ogbg-molhiv: 0.726685 test loss: 0.195500
[Epoch 6; Iter     5/ 1097] train: loss: 0.2515711
[Epoch 6; Iter    35/ 1097] train: loss: 0.3801737
[Epoch 6; Iter    65/ 1097] train: loss: 0.0342441
[Epoch 6; Iter    95/ 1097] train: loss: 0.1592343
[Epoch 6; Iter   125/ 1097] train: loss: 0.3053620
[Epoch 6; Iter   155/ 1097] train: loss: 0.1028740
[Epoch 6; Iter   185/ 1097] train: loss: 0.1995301
[Epoch 6; Iter   215/ 1097] train: loss: 0.1603895
[Epoch 6; Iter   245/ 1097] train: loss: 0.1295104
[Epoch 6; Iter   275/ 1097] train: loss: 0.1429764
[Epoch 6; Iter   305/ 1097] train: loss: 0.0385702
[Epoch 6; Iter   335/ 1097] train: loss: 0.0272829
[Epoch 6; Iter   365/ 1097] train: loss: 0.0343525
[Epoch 6; Iter   395/ 1097] train: loss: 0.1788604
[Epoch 6; Iter   425/ 1097] train: loss: 0.0915341
[Epoch 6; Iter   455/ 1097] train: loss: 0.2203111
[Epoch 6; Iter   485/ 1097] train: loss: 0.0377958
[Epoch 6; Iter   515/ 1097] train: loss: 0.1075350
[Epoch 6; Iter   545/ 1097] train: loss: 0.1876995
[Epoch 6; Iter   575/ 1097] train: loss: 0.0433656
[Epoch 6; Iter   605/ 1097] train: loss: 0.0450262
[Epoch 6; Iter   635/ 1097] train: loss: 0.2254285
[Epoch 6; Iter   665/ 1097] train: loss: 0.2256741
[Epoch 6; Iter   695/ 1097] train: loss: 0.3041197
[Epoch 6; Iter   725/ 1097] train: loss: 0.3270655
[Epoch 6; Iter   755/ 1097] train: loss: 0.2705874
[Epoch 6; Iter   785/ 1097] train: loss: 0.4615142
[Epoch 6; Iter   815/ 1097] train: loss: 0.0585661
[Epoch 6; Iter   845/ 1097] train: loss: 0.0384482
[Epoch 6; Iter   875/ 1097] train: loss: 0.1096744
[Epoch 6; Iter   905/ 1097] train: loss: 0.2441870
[Epoch 6; Iter   935/ 1097] train: loss: 0.0752479
[Epoch 6; Iter   965/ 1097] train: loss: 0.1205390
[Epoch 6; Iter   995/ 1097] train: loss: 0.0892472
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0997947
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1570691
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2138163
[Epoch 6] ogbg-molhiv: 0.746561 val loss: 0.379729
[Epoch 6] ogbg-molhiv: 0.693304 test loss: 0.124961
[Epoch 7; Iter    18/ 1097] train: loss: 0.0447183
[Epoch 7; Iter    48/ 1097] train: loss: 0.0407595
[Epoch 7; Iter    78/ 1097] train: loss: 0.2168897
[Epoch 7; Iter   108/ 1097] train: loss: 0.2878288
[Epoch 7; Iter   138/ 1097] train: loss: 0.1540874
[Epoch 7; Iter   168/ 1097] train: loss: 0.0314391
[Epoch 7; Iter   198/ 1097] train: loss: 0.2530770
[Epoch 7; Iter   228/ 1097] train: loss: 0.2154964
[Epoch 7; Iter   258/ 1097] train: loss: 0.0259440
[Epoch 7; Iter   288/ 1097] train: loss: 0.0244835
[Epoch 7; Iter   318/ 1097] train: loss: 0.1861915
[Epoch 7; Iter   348/ 1097] train: loss: 0.0260316
[Epoch 7; Iter   378/ 1097] train: loss: 0.2061692
[Epoch 7; Iter   408/ 1097] train: loss: 0.2805832
[Epoch 7; Iter   438/ 1097] train: loss: 0.0900479
[Epoch 7; Iter   468/ 1097] train: loss: 0.0365434
[Epoch 7; Iter   498/ 1097] train: loss: 0.1603906
[Epoch 7; Iter   528/ 1097] train: loss: 0.0912593
[Epoch 7; Iter   558/ 1097] train: loss: 0.0524116
[Epoch 7; Iter   588/ 1097] train: loss: 0.2752670
[Epoch 7; Iter   618/ 1097] train: loss: 0.1401393
[Epoch 7; Iter   648/ 1097] train: loss: 0.0722877
[Epoch 7; Iter   678/ 1097] train: loss: 0.0290450
[Epoch 7; Iter   708/ 1097] train: loss: 0.1798880
[Epoch 7; Iter   738/ 1097] train: loss: 0.1873007
[Epoch 7; Iter   768/ 1097] train: loss: 0.1648105
[Epoch 7; Iter   798/ 1097] train: loss: 0.1438460
[Epoch 7; Iter   828/ 1097] train: loss: 0.0515512
[Epoch 7; Iter   858/ 1097] train: loss: 0.1375771
[Epoch 7; Iter   888/ 1097] train: loss: 0.0369838
[Epoch 7; Iter   918/ 1097] train: loss: 0.1224357
[Epoch 7; Iter   948/ 1097] train: loss: 0.0406807
[Epoch 7; Iter   978/ 1097] train: loss: 0.0674922
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0563703
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0342370
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1742991
[Epoch 7] ogbg-molhiv: 0.764339 val loss: 1.790693
[Epoch 7] ogbg-molhiv: 0.722107 test loss: 0.427034
[Epoch 3; Iter   986/ 1097] train: loss: 0.0410486
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2790177
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0355560
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2179766
[Epoch 3] ogbg-molhiv: 0.721549 val loss: 2.639211
[Epoch 3] ogbg-molhiv: 0.661302 test loss: 2.754992
[Epoch 4; Iter     9/ 1097] train: loss: 0.0797744
[Epoch 4; Iter    39/ 1097] train: loss: 0.0323590
[Epoch 4; Iter    69/ 1097] train: loss: 0.0396721
[Epoch 4; Iter    99/ 1097] train: loss: 0.0286382
[Epoch 4; Iter   129/ 1097] train: loss: 0.2783708
[Epoch 4; Iter   159/ 1097] train: loss: 0.1076135
[Epoch 4; Iter   189/ 1097] train: loss: 0.0428794
[Epoch 4; Iter   219/ 1097] train: loss: 0.0335013
[Epoch 4; Iter   249/ 1097] train: loss: 0.1612534
[Epoch 4; Iter   279/ 1097] train: loss: 0.2314476
[Epoch 4; Iter   309/ 1097] train: loss: 0.0758952
[Epoch 4; Iter   339/ 1097] train: loss: 0.0548254
[Epoch 4; Iter   369/ 1097] train: loss: 0.0533326
[Epoch 4; Iter   399/ 1097] train: loss: 0.2540210
[Epoch 4; Iter   429/ 1097] train: loss: 0.0364915
[Epoch 4; Iter   459/ 1097] train: loss: 0.1061232
[Epoch 4; Iter   489/ 1097] train: loss: 0.0318247
[Epoch 4; Iter   519/ 1097] train: loss: 0.1682184
[Epoch 4; Iter   549/ 1097] train: loss: 0.0552936
[Epoch 4; Iter   579/ 1097] train: loss: 0.2101338
[Epoch 4; Iter   609/ 1097] train: loss: 0.1684206
[Epoch 4; Iter   639/ 1097] train: loss: 0.1037712
[Epoch 4; Iter   669/ 1097] train: loss: 0.2280868
[Epoch 4; Iter   699/ 1097] train: loss: 0.0891454
[Epoch 4; Iter   729/ 1097] train: loss: 0.0414603
[Epoch 4; Iter   759/ 1097] train: loss: 0.0308827
[Epoch 4; Iter   789/ 1097] train: loss: 0.0280537
[Epoch 4; Iter   819/ 1097] train: loss: 0.1293168
[Epoch 4; Iter   849/ 1097] train: loss: 0.0326686
[Epoch 4; Iter   879/ 1097] train: loss: 0.0311214
[Epoch 4; Iter   909/ 1097] train: loss: 0.0349105
[Epoch 4; Iter   939/ 1097] train: loss: 0.3018297
[Epoch 4; Iter   969/ 1097] train: loss: 0.1138216
[Epoch 4; Iter   999/ 1097] train: loss: 0.0358889
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2179867
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1244476
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1836326
[Epoch 4] ogbg-molhiv: 0.758362 val loss: 0.160406
[Epoch 4] ogbg-molhiv: 0.732706 test loss: 0.158195
[Epoch 5; Iter    22/ 1097] train: loss: 0.0959418
[Epoch 5; Iter    52/ 1097] train: loss: 0.1560661
[Epoch 5; Iter    82/ 1097] train: loss: 0.1529485
[Epoch 5; Iter   112/ 1097] train: loss: 0.4429121
[Epoch 5; Iter   142/ 1097] train: loss: 0.3776709
[Epoch 5; Iter   172/ 1097] train: loss: 0.0287249
[Epoch 5; Iter   202/ 1097] train: loss: 0.1737260
[Epoch 5; Iter   232/ 1097] train: loss: 0.2356901
[Epoch 5; Iter   262/ 1097] train: loss: 0.0394134
[Epoch 5; Iter   292/ 1097] train: loss: 0.1864086
[Epoch 5; Iter   322/ 1097] train: loss: 0.0312141
[Epoch 5; Iter   352/ 1097] train: loss: 0.1086430
[Epoch 5; Iter   382/ 1097] train: loss: 0.0911891
[Epoch 5; Iter   412/ 1097] train: loss: 0.3654018
[Epoch 5; Iter   442/ 1097] train: loss: 0.1296985
[Epoch 5; Iter   472/ 1097] train: loss: 0.1454974
[Epoch 5; Iter   502/ 1097] train: loss: 0.2277371
[Epoch 5; Iter   532/ 1097] train: loss: 0.2806416
[Epoch 5; Iter   562/ 1097] train: loss: 0.2127278
[Epoch 5; Iter   592/ 1097] train: loss: 0.0483484
[Epoch 5; Iter   622/ 1097] train: loss: 0.0296467
[Epoch 5; Iter   652/ 1097] train: loss: 0.1055278
[Epoch 5; Iter   682/ 1097] train: loss: 0.1459078
[Epoch 5; Iter   712/ 1097] train: loss: 0.0260042
[Epoch 5; Iter   742/ 1097] train: loss: 0.1777742
[Epoch 5; Iter   772/ 1097] train: loss: 0.2783319
[Epoch 5; Iter   802/ 1097] train: loss: 0.0790767
[Epoch 5; Iter   832/ 1097] train: loss: 0.0599283
[Epoch 5; Iter   862/ 1097] train: loss: 0.1040501
[Epoch 5; Iter   892/ 1097] train: loss: 0.0461364
[Epoch 5; Iter   922/ 1097] train: loss: 0.0414774
[Epoch 5; Iter   952/ 1097] train: loss: 0.0455184
[Epoch 5; Iter   982/ 1097] train: loss: 0.0773790
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0338111
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2274840
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0419099
[Epoch 5] ogbg-molhiv: 0.742553 val loss: 0.978381
[Epoch 5] ogbg-molhiv: 0.707461 test loss: 0.124300
[Epoch 6; Iter     5/ 1097] train: loss: 0.0834019
[Epoch 6; Iter    35/ 1097] train: loss: 0.2547201
[Epoch 6; Iter    65/ 1097] train: loss: 0.0321470
[Epoch 6; Iter    95/ 1097] train: loss: 0.0549024
[Epoch 6; Iter   125/ 1097] train: loss: 0.3924046
[Epoch 6; Iter   155/ 1097] train: loss: 0.3585001
[Epoch 6; Iter   185/ 1097] train: loss: 0.0492055
[Epoch 6; Iter   215/ 1097] train: loss: 0.1162302
[Epoch 6; Iter   245/ 1097] train: loss: 0.2686239
[Epoch 6; Iter   275/ 1097] train: loss: 0.0474501
[Epoch 6; Iter   305/ 1097] train: loss: 0.2203697
[Epoch 6; Iter   335/ 1097] train: loss: 0.1120291
[Epoch 6; Iter   365/ 1097] train: loss: 0.3313215
[Epoch 6; Iter   395/ 1097] train: loss: 0.3236884
[Epoch 6; Iter   425/ 1097] train: loss: 0.0416144
[Epoch 6; Iter   455/ 1097] train: loss: 0.3547055
[Epoch 6; Iter   485/ 1097] train: loss: 0.0356956
[Epoch 6; Iter   515/ 1097] train: loss: 0.1057721
[Epoch 6; Iter   545/ 1097] train: loss: 0.1677232
[Epoch 6; Iter   575/ 1097] train: loss: 0.1760471
[Epoch 6; Iter   605/ 1097] train: loss: 0.0396971
[Epoch 6; Iter   635/ 1097] train: loss: 0.0306348
[Epoch 6; Iter   665/ 1097] train: loss: 0.2011208
[Epoch 6; Iter   695/ 1097] train: loss: 0.1989948
[Epoch 6; Iter   725/ 1097] train: loss: 0.1825849
[Epoch 6; Iter   755/ 1097] train: loss: 0.0547298
[Epoch 6; Iter   785/ 1097] train: loss: 0.1574384
[Epoch 6; Iter   815/ 1097] train: loss: 0.0338905
[Epoch 6; Iter   845/ 1097] train: loss: 0.1039131
[Epoch 6; Iter   875/ 1097] train: loss: 0.1146834
[Epoch 6; Iter   905/ 1097] train: loss: 0.3011773
[Epoch 6; Iter   935/ 1097] train: loss: 0.0378485
[Epoch 6; Iter   965/ 1097] train: loss: 0.0274277
[Epoch 6; Iter   995/ 1097] train: loss: 0.1879856
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1462979
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0237515
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2142339
[Epoch 6] ogbg-molhiv: 0.797040 val loss: 0.121084
[Epoch 6] ogbg-molhiv: 0.733038 test loss: 0.145229
[Epoch 7; Iter    18/ 1097] train: loss: 0.1757695
[Epoch 7; Iter    48/ 1097] train: loss: 0.7122025
[Epoch 7; Iter    78/ 1097] train: loss: 0.3593976
[Epoch 7; Iter   108/ 1097] train: loss: 0.0423557
[Epoch 7; Iter   138/ 1097] train: loss: 0.0236205
[Epoch 7; Iter   168/ 1097] train: loss: 0.0685648
[Epoch 7; Iter   198/ 1097] train: loss: 0.1810025
[Epoch 7; Iter   228/ 1097] train: loss: 0.1588395
[Epoch 7; Iter   258/ 1097] train: loss: 0.1560326
[Epoch 7; Iter   288/ 1097] train: loss: 0.2173720
[Epoch 7; Iter   318/ 1097] train: loss: 0.0393329
[Epoch 7; Iter   348/ 1097] train: loss: 0.0394360
[Epoch 7; Iter   378/ 1097] train: loss: 0.0302544
[Epoch 7; Iter   408/ 1097] train: loss: 0.0504077
[Epoch 7; Iter   438/ 1097] train: loss: 0.0277809
[Epoch 7; Iter   468/ 1097] train: loss: 0.2929067
[Epoch 7; Iter   498/ 1097] train: loss: 0.0349649
[Epoch 7; Iter   528/ 1097] train: loss: 0.0323624
[Epoch 7; Iter   558/ 1097] train: loss: 0.2662968
[Epoch 7; Iter   588/ 1097] train: loss: 0.1507832
[Epoch 7; Iter   618/ 1097] train: loss: 0.2687093
[Epoch 7; Iter   648/ 1097] train: loss: 0.2240829
[Epoch 7; Iter   678/ 1097] train: loss: 0.1444466
[Epoch 7; Iter   708/ 1097] train: loss: 0.0604306
[Epoch 7; Iter   738/ 1097] train: loss: 0.0275829
[Epoch 7; Iter   768/ 1097] train: loss: 0.0977368
[Epoch 7; Iter   798/ 1097] train: loss: 0.2720194
[Epoch 7; Iter   828/ 1097] train: loss: 0.1719365
[Epoch 7; Iter   858/ 1097] train: loss: 0.2243342
[Epoch 7; Iter   888/ 1097] train: loss: 0.1256495
[Epoch 7; Iter   918/ 1097] train: loss: 0.1775793
[Epoch 7; Iter   948/ 1097] train: loss: 0.1920861
[Epoch 7; Iter   978/ 1097] train: loss: 0.1335107
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0284862
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2390229
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0471142
[Epoch 7] ogbg-molhiv: 0.774263 val loss: 0.132223
[Epoch 7] ogbg-molhiv: 0.753981 test loss: 0.230969
[Epoch 3; Iter   986/ 1097] train: loss: 0.0359927
[Epoch 3; Iter  1016/ 1097] train: loss: 0.3100647
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0309220
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2070954
[Epoch 3] ogbg-molhiv: 0.705798 val loss: 0.130434
[Epoch 3] ogbg-molhiv: 0.679988 test loss: 0.138460
[Epoch 4; Iter     9/ 1097] train: loss: 0.0636878
[Epoch 4; Iter    39/ 1097] train: loss: 0.0280388
[Epoch 4; Iter    69/ 1097] train: loss: 0.0333813
[Epoch 4; Iter    99/ 1097] train: loss: 0.0293691
[Epoch 4; Iter   129/ 1097] train: loss: 0.3063587
[Epoch 4; Iter   159/ 1097] train: loss: 0.0990110
[Epoch 4; Iter   189/ 1097] train: loss: 0.0440284
[Epoch 4; Iter   219/ 1097] train: loss: 0.0362409
[Epoch 4; Iter   249/ 1097] train: loss: 0.1564735
[Epoch 4; Iter   279/ 1097] train: loss: 0.2572688
[Epoch 4; Iter   309/ 1097] train: loss: 0.1022605
[Epoch 4; Iter   339/ 1097] train: loss: 0.0453708
[Epoch 4; Iter   369/ 1097] train: loss: 0.0670187
[Epoch 4; Iter   399/ 1097] train: loss: 0.2313479
[Epoch 4; Iter   429/ 1097] train: loss: 0.0347411
[Epoch 4; Iter   459/ 1097] train: loss: 0.1198970
[Epoch 4; Iter   489/ 1097] train: loss: 0.0366508
[Epoch 4; Iter   519/ 1097] train: loss: 0.1685977
[Epoch 4; Iter   549/ 1097] train: loss: 0.0624159
[Epoch 4; Iter   579/ 1097] train: loss: 0.1197032
[Epoch 4; Iter   609/ 1097] train: loss: 0.1555074
[Epoch 4; Iter   639/ 1097] train: loss: 0.1213029
[Epoch 4; Iter   669/ 1097] train: loss: 0.2154283
[Epoch 4; Iter   699/ 1097] train: loss: 0.0880335
[Epoch 4; Iter   729/ 1097] train: loss: 0.0461941
[Epoch 4; Iter   759/ 1097] train: loss: 0.0319531
[Epoch 4; Iter   789/ 1097] train: loss: 0.0449286
[Epoch 4; Iter   819/ 1097] train: loss: 0.1336993
[Epoch 4; Iter   849/ 1097] train: loss: 0.0318310
[Epoch 4; Iter   879/ 1097] train: loss: 0.0343988
[Epoch 4; Iter   909/ 1097] train: loss: 0.0317009
[Epoch 4; Iter   939/ 1097] train: loss: 0.3200218
[Epoch 4; Iter   969/ 1097] train: loss: 0.1225062
[Epoch 4; Iter   999/ 1097] train: loss: 0.0526695
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2285517
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1145827
[Epoch 4; Iter  1089/ 1097] train: loss: 0.2008596
[Epoch 4] ogbg-molhiv: 0.735165 val loss: 0.137081
[Epoch 4] ogbg-molhiv: 0.707698 test loss: 0.141720
[Epoch 5; Iter    22/ 1097] train: loss: 0.1032033
[Epoch 5; Iter    52/ 1097] train: loss: 0.1558913
[Epoch 5; Iter    82/ 1097] train: loss: 0.1550408
[Epoch 5; Iter   112/ 1097] train: loss: 0.4613813
[Epoch 5; Iter   142/ 1097] train: loss: 0.4068990
[Epoch 5; Iter   172/ 1097] train: loss: 0.0291537
[Epoch 5; Iter   202/ 1097] train: loss: 0.1594773
[Epoch 5; Iter   232/ 1097] train: loss: 0.1674919
[Epoch 5; Iter   262/ 1097] train: loss: 0.0459241
[Epoch 5; Iter   292/ 1097] train: loss: 0.1871843
[Epoch 5; Iter   322/ 1097] train: loss: 0.0319345
[Epoch 5; Iter   352/ 1097] train: loss: 0.1408583
[Epoch 5; Iter   382/ 1097] train: loss: 0.1395566
[Epoch 5; Iter   412/ 1097] train: loss: 0.4101946
[Epoch 5; Iter   442/ 1097] train: loss: 0.1492130
[Epoch 5; Iter   472/ 1097] train: loss: 0.1715486
[Epoch 5; Iter   502/ 1097] train: loss: 0.2102829
[Epoch 5; Iter   532/ 1097] train: loss: 0.2819003
[Epoch 5; Iter   562/ 1097] train: loss: 0.2329600
[Epoch 5; Iter   592/ 1097] train: loss: 0.0379220
[Epoch 5; Iter   622/ 1097] train: loss: 0.0313606
[Epoch 5; Iter   652/ 1097] train: loss: 0.0954616
[Epoch 5; Iter   682/ 1097] train: loss: 0.1621038
[Epoch 5; Iter   712/ 1097] train: loss: 0.0329442
[Epoch 5; Iter   742/ 1097] train: loss: 0.1195375
[Epoch 5; Iter   772/ 1097] train: loss: 0.2788783
[Epoch 5; Iter   802/ 1097] train: loss: 0.0839707
[Epoch 5; Iter   832/ 1097] train: loss: 0.0639494
[Epoch 5; Iter   862/ 1097] train: loss: 0.0929305
[Epoch 5; Iter   892/ 1097] train: loss: 0.0419164
[Epoch 5; Iter   922/ 1097] train: loss: 0.0352938
[Epoch 5; Iter   952/ 1097] train: loss: 0.0841797
[Epoch 5; Iter   982/ 1097] train: loss: 0.0746177
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0353072
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2266345
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0451584
[Epoch 5] ogbg-molhiv: 0.707384 val loss: 0.095988
[Epoch 5] ogbg-molhiv: 0.672641 test loss: 0.134870
[Epoch 6; Iter     5/ 1097] train: loss: 0.1493189
[Epoch 6; Iter    35/ 1097] train: loss: 0.2202974
[Epoch 6; Iter    65/ 1097] train: loss: 0.0310512
[Epoch 6; Iter    95/ 1097] train: loss: 0.0559431
[Epoch 6; Iter   125/ 1097] train: loss: 0.4895004
[Epoch 6; Iter   155/ 1097] train: loss: 0.3973104
[Epoch 6; Iter   185/ 1097] train: loss: 0.0574154
[Epoch 6; Iter   215/ 1097] train: loss: 0.1384877
[Epoch 6; Iter   245/ 1097] train: loss: 0.2663252
[Epoch 6; Iter   275/ 1097] train: loss: 0.0341348
[Epoch 6; Iter   305/ 1097] train: loss: 0.2096530
[Epoch 6; Iter   335/ 1097] train: loss: 0.0442739
[Epoch 6; Iter   365/ 1097] train: loss: 0.2843259
[Epoch 6; Iter   395/ 1097] train: loss: 0.3323900
[Epoch 6; Iter   425/ 1097] train: loss: 0.0429591
[Epoch 6; Iter   455/ 1097] train: loss: 0.2817334
[Epoch 6; Iter   485/ 1097] train: loss: 0.0327411
[Epoch 6; Iter   515/ 1097] train: loss: 0.1409761
[Epoch 6; Iter   545/ 1097] train: loss: 0.1639481
[Epoch 6; Iter   575/ 1097] train: loss: 0.1545591
[Epoch 6; Iter   605/ 1097] train: loss: 0.0374862
[Epoch 6; Iter   635/ 1097] train: loss: 0.0354587
[Epoch 6; Iter   665/ 1097] train: loss: 0.2465180
[Epoch 6; Iter   695/ 1097] train: loss: 0.1702292
[Epoch 6; Iter   725/ 1097] train: loss: 0.1918207
[Epoch 6; Iter   755/ 1097] train: loss: 0.0807910
[Epoch 6; Iter   785/ 1097] train: loss: 0.1064925
[Epoch 6; Iter   815/ 1097] train: loss: 0.0385614
[Epoch 6; Iter   845/ 1097] train: loss: 0.1528793
[Epoch 6; Iter   875/ 1097] train: loss: 0.2091575
[Epoch 6; Iter   905/ 1097] train: loss: 0.3635964
[Epoch 6; Iter   935/ 1097] train: loss: 0.0343956
[Epoch 6; Iter   965/ 1097] train: loss: 0.0322946
[Epoch 6; Iter   995/ 1097] train: loss: 0.2081545
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1548148
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0333147
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2522733
[Epoch 6] ogbg-molhiv: 0.757033 val loss: 0.715085
[Epoch 6] ogbg-molhiv: 0.711505 test loss: 0.608248
[Epoch 7; Iter    18/ 1097] train: loss: 0.1519535
[Epoch 7; Iter    48/ 1097] train: loss: 0.6587597
[Epoch 7; Iter    78/ 1097] train: loss: 0.3820221
[Epoch 7; Iter   108/ 1097] train: loss: 0.0649510
[Epoch 7; Iter   138/ 1097] train: loss: 0.0271894
[Epoch 7; Iter   168/ 1097] train: loss: 0.0942412
[Epoch 7; Iter   198/ 1097] train: loss: 0.1675455
[Epoch 7; Iter   228/ 1097] train: loss: 0.1678394
[Epoch 7; Iter   258/ 1097] train: loss: 0.1115241
[Epoch 7; Iter   288/ 1097] train: loss: 0.1711006
[Epoch 7; Iter   318/ 1097] train: loss: 0.0398547
[Epoch 7; Iter   348/ 1097] train: loss: 0.0402758
[Epoch 7; Iter   378/ 1097] train: loss: 0.0302145
[Epoch 7; Iter   408/ 1097] train: loss: 0.0434565
[Epoch 7; Iter   438/ 1097] train: loss: 0.0331911
[Epoch 7; Iter   468/ 1097] train: loss: 0.2859995
[Epoch 7; Iter   498/ 1097] train: loss: 0.0468171
[Epoch 7; Iter   528/ 1097] train: loss: 0.0380921
[Epoch 7; Iter   558/ 1097] train: loss: 0.2622288
[Epoch 7; Iter   588/ 1097] train: loss: 0.2315157
[Epoch 7; Iter   618/ 1097] train: loss: 0.2726247
[Epoch 7; Iter   648/ 1097] train: loss: 0.1965149
[Epoch 7; Iter   678/ 1097] train: loss: 0.1408885
[Epoch 7; Iter   708/ 1097] train: loss: 0.0768982
[Epoch 7; Iter   738/ 1097] train: loss: 0.0306587
[Epoch 7; Iter   768/ 1097] train: loss: 0.1341723
[Epoch 7; Iter   798/ 1097] train: loss: 0.2406615
[Epoch 7; Iter   828/ 1097] train: loss: 0.1733050
[Epoch 7; Iter   858/ 1097] train: loss: 0.2259731
[Epoch 7; Iter   888/ 1097] train: loss: 0.0882836
[Epoch 7; Iter   918/ 1097] train: loss: 0.1928046
[Epoch 7; Iter   948/ 1097] train: loss: 0.1684493
[Epoch 7; Iter   978/ 1097] train: loss: 0.1287266
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0320245
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2729793
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1005302
[Epoch 7] ogbg-molhiv: 0.729090 val loss: 0.491204
[Epoch 7] ogbg-molhiv: 0.720280 test loss: 0.408296
[Epoch 3; Iter   986/ 1097] train: loss: 0.0502775
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0440162
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1431390
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2528138
[Epoch 3] ogbg-molhiv: 0.744709 val loss: 0.084393
[Epoch 3] ogbg-molhiv: 0.646293 test loss: 0.130488
[Epoch 4; Iter     9/ 1097] train: loss: 0.2339975
[Epoch 4; Iter    39/ 1097] train: loss: 0.1457818
[Epoch 4; Iter    69/ 1097] train: loss: 0.0415489
[Epoch 4; Iter    99/ 1097] train: loss: 0.2986434
[Epoch 4; Iter   129/ 1097] train: loss: 0.1420779
[Epoch 4; Iter   159/ 1097] train: loss: 0.1437110
[Epoch 4; Iter   189/ 1097] train: loss: 0.2553277
[Epoch 4; Iter   219/ 1097] train: loss: 0.1630752
[Epoch 4; Iter   249/ 1097] train: loss: 0.1500432
[Epoch 4; Iter   279/ 1097] train: loss: 0.1914483
[Epoch 4; Iter   309/ 1097] train: loss: 0.1732532
[Epoch 4; Iter   339/ 1097] train: loss: 0.0276571
[Epoch 4; Iter   369/ 1097] train: loss: 0.1185307
[Epoch 4; Iter   399/ 1097] train: loss: 0.1504886
[Epoch 4; Iter   429/ 1097] train: loss: 0.1608883
[Epoch 4; Iter   459/ 1097] train: loss: 0.0360222
[Epoch 4; Iter   489/ 1097] train: loss: 0.1555683
[Epoch 4; Iter   519/ 1097] train: loss: 0.2821422
[Epoch 4; Iter   549/ 1097] train: loss: 0.1950644
[Epoch 4; Iter   579/ 1097] train: loss: 0.0350526
[Epoch 4; Iter   609/ 1097] train: loss: 0.3619588
[Epoch 4; Iter   639/ 1097] train: loss: 0.2655330
[Epoch 4; Iter   669/ 1097] train: loss: 0.3308237
[Epoch 4; Iter   699/ 1097] train: loss: 0.0310095
[Epoch 4; Iter   729/ 1097] train: loss: 0.2447812
[Epoch 4; Iter   759/ 1097] train: loss: 0.1603294
[Epoch 4; Iter   789/ 1097] train: loss: 0.3329460
[Epoch 4; Iter   819/ 1097] train: loss: 0.1557906
[Epoch 4; Iter   849/ 1097] train: loss: 0.0386887
[Epoch 4; Iter   879/ 1097] train: loss: 0.0379283
[Epoch 4; Iter   909/ 1097] train: loss: 0.4138343
[Epoch 4; Iter   939/ 1097] train: loss: 0.1688469
[Epoch 4; Iter   969/ 1097] train: loss: 0.0785184
[Epoch 4; Iter   999/ 1097] train: loss: 0.1911690
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3690318
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2694008
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0433233
[Epoch 4] ogbg-molhiv: 0.721126 val loss: 0.393620
[Epoch 4] ogbg-molhiv: 0.676299 test loss: 0.171978
[Epoch 5; Iter    22/ 1097] train: loss: 0.3460790
[Epoch 5; Iter    52/ 1097] train: loss: 0.1938466
[Epoch 5; Iter    82/ 1097] train: loss: 0.1464570
[Epoch 5; Iter   112/ 1097] train: loss: 0.1208723
[Epoch 5; Iter   142/ 1097] train: loss: 0.1052075
[Epoch 5; Iter   172/ 1097] train: loss: 0.0320265
[Epoch 5; Iter   202/ 1097] train: loss: 0.1417087
[Epoch 5; Iter   232/ 1097] train: loss: 0.0329273
[Epoch 5; Iter   262/ 1097] train: loss: 0.0431856
[Epoch 5; Iter   292/ 1097] train: loss: 0.1780982
[Epoch 5; Iter   322/ 1097] train: loss: 0.1902919
[Epoch 5; Iter   352/ 1097] train: loss: 0.0684270
[Epoch 5; Iter   382/ 1097] train: loss: 0.2236522
[Epoch 5; Iter   412/ 1097] train: loss: 0.2878880
[Epoch 5; Iter   442/ 1097] train: loss: 0.2677917
[Epoch 5; Iter   472/ 1097] train: loss: 0.1432267
[Epoch 5; Iter   502/ 1097] train: loss: 0.1836055
[Epoch 5; Iter   532/ 1097] train: loss: 0.0579187
[Epoch 5; Iter   562/ 1097] train: loss: 0.0499386
[Epoch 5; Iter   592/ 1097] train: loss: 0.0430882
[Epoch 5; Iter   622/ 1097] train: loss: 0.1120597
[Epoch 5; Iter   652/ 1097] train: loss: 0.1275105
[Epoch 5; Iter   682/ 1097] train: loss: 0.1756175
[Epoch 5; Iter   712/ 1097] train: loss: 0.0363245
[Epoch 5; Iter   742/ 1097] train: loss: 0.1930504
[Epoch 5; Iter   772/ 1097] train: loss: 0.1780619
[Epoch 5; Iter   802/ 1097] train: loss: 0.2015474
[Epoch 5; Iter   832/ 1097] train: loss: 0.0341611
[Epoch 5; Iter   862/ 1097] train: loss: 0.1962200
[Epoch 5; Iter   892/ 1097] train: loss: 0.0373979
[Epoch 5; Iter   922/ 1097] train: loss: 0.3401219
[Epoch 5; Iter   952/ 1097] train: loss: 0.0374047
[Epoch 5; Iter   982/ 1097] train: loss: 0.2413543
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2754318
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2129082
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0416918
[Epoch 5] ogbg-molhiv: 0.715002 val loss: 0.105779
[Epoch 5] ogbg-molhiv: 0.722418 test loss: 0.135334
[Epoch 6; Iter     5/ 1097] train: loss: 0.0806309
[Epoch 6; Iter    35/ 1097] train: loss: 0.1101119
[Epoch 6; Iter    65/ 1097] train: loss: 0.1227349
[Epoch 6; Iter    95/ 1097] train: loss: 0.0354514
[Epoch 6; Iter   125/ 1097] train: loss: 0.0915851
[Epoch 6; Iter   155/ 1097] train: loss: 0.0271156
[Epoch 6; Iter   185/ 1097] train: loss: 0.0443488
[Epoch 6; Iter   215/ 1097] train: loss: 0.3659958
[Epoch 6; Iter   245/ 1097] train: loss: 0.2500742
[Epoch 6; Iter   275/ 1097] train: loss: 0.0320694
[Epoch 6; Iter   305/ 1097] train: loss: 0.0367433
[Epoch 6; Iter   335/ 1097] train: loss: 0.1561384
[Epoch 6; Iter   365/ 1097] train: loss: 0.0423906
[Epoch 6; Iter   395/ 1097] train: loss: 0.2852698
[Epoch 6; Iter   425/ 1097] train: loss: 0.1341053
[Epoch 6; Iter   455/ 1097] train: loss: 0.1048153
[Epoch 6; Iter   485/ 1097] train: loss: 0.2235628
[Epoch 6; Iter   515/ 1097] train: loss: 0.0529896
[Epoch 6; Iter   545/ 1097] train: loss: 0.1538440
[Epoch 6; Iter   575/ 1097] train: loss: 0.0411407
[Epoch 6; Iter   605/ 1097] train: loss: 0.0337644
[Epoch 6; Iter   635/ 1097] train: loss: 0.0309545
[Epoch 6; Iter   665/ 1097] train: loss: 0.0326534
[Epoch 6; Iter   695/ 1097] train: loss: 0.1295006
[Epoch 6; Iter   725/ 1097] train: loss: 0.0338547
[Epoch 6; Iter   755/ 1097] train: loss: 0.1521670
[Epoch 6; Iter   785/ 1097] train: loss: 0.0286032
[Epoch 6; Iter   815/ 1097] train: loss: 0.1918889
[Epoch 6; Iter   845/ 1097] train: loss: 0.1374297
[Epoch 6; Iter   875/ 1097] train: loss: 0.1933141
[Epoch 6; Iter   905/ 1097] train: loss: 0.3534327
[Epoch 6; Iter   935/ 1097] train: loss: 0.1865942
[Epoch 6; Iter   965/ 1097] train: loss: 0.1570746
[Epoch 6; Iter   995/ 1097] train: loss: 0.0307005
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0354469
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1014147
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1749303
[Epoch 6] ogbg-molhiv: 0.754960 val loss: 0.221641
[Epoch 6] ogbg-molhiv: 0.633848 test loss: 0.156970
[Epoch 7; Iter    18/ 1097] train: loss: 0.0353350
[Epoch 7; Iter    48/ 1097] train: loss: 0.0840010
[Epoch 7; Iter    78/ 1097] train: loss: 0.1757929
[Epoch 7; Iter   108/ 1097] train: loss: 0.0376583
[Epoch 7; Iter   138/ 1097] train: loss: 0.0390644
[Epoch 7; Iter   168/ 1097] train: loss: 0.1323147
[Epoch 7; Iter   198/ 1097] train: loss: 0.1236171
[Epoch 7; Iter   228/ 1097] train: loss: 0.0297699
[Epoch 7; Iter   258/ 1097] train: loss: 0.0700737
[Epoch 7; Iter   288/ 1097] train: loss: 0.0886423
[Epoch 7; Iter   318/ 1097] train: loss: 0.0548601
[Epoch 7; Iter   348/ 1097] train: loss: 0.1793767
[Epoch 7; Iter   378/ 1097] train: loss: 0.1583338
[Epoch 7; Iter   408/ 1097] train: loss: 0.1395700
[Epoch 7; Iter   438/ 1097] train: loss: 0.1697556
[Epoch 7; Iter   468/ 1097] train: loss: 0.0344396
[Epoch 7; Iter   498/ 1097] train: loss: 0.0510505
[Epoch 7; Iter   528/ 1097] train: loss: 0.0328569
[Epoch 7; Iter   558/ 1097] train: loss: 0.0288855
[Epoch 7; Iter   588/ 1097] train: loss: 0.3005762
[Epoch 7; Iter   618/ 1097] train: loss: 0.3523949
[Epoch 7; Iter   648/ 1097] train: loss: 0.3660401
[Epoch 7; Iter   678/ 1097] train: loss: 0.0490780
[Epoch 7; Iter   708/ 1097] train: loss: 0.1674462
[Epoch 7; Iter   738/ 1097] train: loss: 0.2241179
[Epoch 7; Iter   768/ 1097] train: loss: 0.0401722
[Epoch 7; Iter   798/ 1097] train: loss: 0.1146020
[Epoch 7; Iter   828/ 1097] train: loss: 0.1471719
[Epoch 7; Iter   858/ 1097] train: loss: 0.0863836
[Epoch 7; Iter   888/ 1097] train: loss: 0.0281072
[Epoch 7; Iter   918/ 1097] train: loss: 0.0625190
[Epoch 7; Iter   948/ 1097] train: loss: 0.1575990
[Epoch 7; Iter   978/ 1097] train: loss: 0.0369141
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1497228
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0327089
[Epoch 7; Iter  1068/ 1097] train: loss: 0.2292146
[Epoch 7] ogbg-molhiv: 0.793192 val loss: 0.107208
[Epoch 7] ogbg-molhiv: 0.717573 test loss: 0.124387
[Epoch 3; Iter   986/ 1097] train: loss: 0.2946983
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1213567
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1018091
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0351751
[Epoch 3] ogbg-molhiv: 0.669568 val loss: 0.122216
[Epoch 3] ogbg-molhiv: 0.680181 test loss: 0.121575
[Epoch 4; Iter     9/ 1097] train: loss: 0.3661390
[Epoch 4; Iter    39/ 1097] train: loss: 0.0761309
[Epoch 4; Iter    69/ 1097] train: loss: 0.1034560
[Epoch 4; Iter    99/ 1097] train: loss: 0.0408800
[Epoch 4; Iter   129/ 1097] train: loss: 0.1732273
[Epoch 4; Iter   159/ 1097] train: loss: 0.4526177
[Epoch 4; Iter   189/ 1097] train: loss: 0.0329580
[Epoch 4; Iter   219/ 1097] train: loss: 0.2816765
[Epoch 4; Iter   249/ 1097] train: loss: 0.0366518
[Epoch 4; Iter   279/ 1097] train: loss: 0.1392097
[Epoch 4; Iter   309/ 1097] train: loss: 0.1672503
[Epoch 4; Iter   339/ 1097] train: loss: 0.1039066
[Epoch 4; Iter   369/ 1097] train: loss: 0.1211772
[Epoch 4; Iter   399/ 1097] train: loss: 0.1417351
[Epoch 4; Iter   429/ 1097] train: loss: 0.0570516
[Epoch 4; Iter   459/ 1097] train: loss: 0.0308363
[Epoch 4; Iter   489/ 1097] train: loss: 0.0367110
[Epoch 4; Iter   519/ 1097] train: loss: 0.0994941
[Epoch 4; Iter   549/ 1097] train: loss: 0.0362386
[Epoch 4; Iter   579/ 1097] train: loss: 0.0376377
[Epoch 4; Iter   609/ 1097] train: loss: 0.2373871
[Epoch 4; Iter   639/ 1097] train: loss: 0.0348652
[Epoch 4; Iter   669/ 1097] train: loss: 0.2581359
[Epoch 4; Iter   699/ 1097] train: loss: 0.0952320
[Epoch 4; Iter   729/ 1097] train: loss: 0.3997200
[Epoch 4; Iter   759/ 1097] train: loss: 0.0622685
[Epoch 4; Iter   789/ 1097] train: loss: 0.3477027
[Epoch 4; Iter   819/ 1097] train: loss: 0.0358207
[Epoch 4; Iter   849/ 1097] train: loss: 0.2507594
[Epoch 4; Iter   879/ 1097] train: loss: 0.0986099
[Epoch 4; Iter   909/ 1097] train: loss: 0.5418154
[Epoch 4; Iter   939/ 1097] train: loss: 0.0340471
[Epoch 4; Iter   969/ 1097] train: loss: 0.0384696
[Epoch 4; Iter   999/ 1097] train: loss: 0.2973799
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2841059
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1849109
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0932626
[Epoch 4] ogbg-molhiv: 0.713557 val loss: 0.669104
[Epoch 4] ogbg-molhiv: 0.721279 test loss: 0.168402
[Epoch 5; Iter    22/ 1097] train: loss: 0.0421535
[Epoch 5; Iter    52/ 1097] train: loss: 0.1108779
[Epoch 5; Iter    82/ 1097] train: loss: 0.2925562
[Epoch 5; Iter   112/ 1097] train: loss: 0.0594480
[Epoch 5; Iter   142/ 1097] train: loss: 0.3241306
[Epoch 5; Iter   172/ 1097] train: loss: 0.1872702
[Epoch 5; Iter   202/ 1097] train: loss: 0.0331887
[Epoch 5; Iter   232/ 1097] train: loss: 0.1464081
[Epoch 5; Iter   262/ 1097] train: loss: 0.1713413
[Epoch 5; Iter   292/ 1097] train: loss: 0.2537605
[Epoch 5; Iter   322/ 1097] train: loss: 0.1619978
[Epoch 5; Iter   352/ 1097] train: loss: 0.1622149
[Epoch 5; Iter   382/ 1097] train: loss: 0.3595554
[Epoch 5; Iter   412/ 1097] train: loss: 0.0381502
[Epoch 5; Iter   442/ 1097] train: loss: 0.1532241
[Epoch 5; Iter   472/ 1097] train: loss: 0.1406157
[Epoch 5; Iter   502/ 1097] train: loss: 0.1328222
[Epoch 5; Iter   532/ 1097] train: loss: 0.0361338
[Epoch 5; Iter   562/ 1097] train: loss: 0.3006622
[Epoch 5; Iter   592/ 1097] train: loss: 0.0573516
[Epoch 5; Iter   622/ 1097] train: loss: 0.1686462
[Epoch 5; Iter   652/ 1097] train: loss: 0.2360047
[Epoch 5; Iter   682/ 1097] train: loss: 0.0315504
[Epoch 5; Iter   712/ 1097] train: loss: 0.1896886
[Epoch 5; Iter   742/ 1097] train: loss: 0.0287524
[Epoch 5; Iter   772/ 1097] train: loss: 0.0315712
[Epoch 5; Iter   802/ 1097] train: loss: 0.2669654
[Epoch 5; Iter   832/ 1097] train: loss: 0.2907204
[Epoch 5; Iter   862/ 1097] train: loss: 0.0375308
[Epoch 5; Iter   892/ 1097] train: loss: 0.1104143
[Epoch 5; Iter   922/ 1097] train: loss: 0.1301461
[Epoch 5; Iter   952/ 1097] train: loss: 0.2381973
[Epoch 5; Iter   982/ 1097] train: loss: 0.1506154
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2547122
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2780887
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0370311
[Epoch 5] ogbg-molhiv: 0.720731 val loss: 0.234207
[Epoch 5] ogbg-molhiv: 0.703515 test loss: 0.179939
[Epoch 6; Iter     5/ 1097] train: loss: 0.2043655
[Epoch 6; Iter    35/ 1097] train: loss: 0.4058796
[Epoch 6; Iter    65/ 1097] train: loss: 0.0379888
[Epoch 6; Iter    95/ 1097] train: loss: 0.1626355
[Epoch 6; Iter   125/ 1097] train: loss: 0.2524695
[Epoch 6; Iter   155/ 1097] train: loss: 0.0921844
[Epoch 6; Iter   185/ 1097] train: loss: 0.1747732
[Epoch 6; Iter   215/ 1097] train: loss: 0.1533220
[Epoch 6; Iter   245/ 1097] train: loss: 0.1418210
[Epoch 6; Iter   275/ 1097] train: loss: 0.1520307
[Epoch 6; Iter   305/ 1097] train: loss: 0.0812799
[Epoch 6; Iter   335/ 1097] train: loss: 0.0496767
[Epoch 6; Iter   365/ 1097] train: loss: 0.0365870
[Epoch 6; Iter   395/ 1097] train: loss: 0.1536437
[Epoch 6; Iter   425/ 1097] train: loss: 0.0941528
[Epoch 6; Iter   455/ 1097] train: loss: 0.2729970
[Epoch 6; Iter   485/ 1097] train: loss: 0.0409341
[Epoch 6; Iter   515/ 1097] train: loss: 0.0984968
[Epoch 6; Iter   545/ 1097] train: loss: 0.2087337
[Epoch 6; Iter   575/ 1097] train: loss: 0.0369995
[Epoch 6; Iter   605/ 1097] train: loss: 0.0622087
[Epoch 6; Iter   635/ 1097] train: loss: 0.2079559
[Epoch 6; Iter   665/ 1097] train: loss: 0.2101109
[Epoch 6; Iter   695/ 1097] train: loss: 0.2952775
[Epoch 6; Iter   725/ 1097] train: loss: 0.3059063
[Epoch 6; Iter   755/ 1097] train: loss: 0.3185104
[Epoch 6; Iter   785/ 1097] train: loss: 0.4085800
[Epoch 6; Iter   815/ 1097] train: loss: 0.0944324
[Epoch 6; Iter   845/ 1097] train: loss: 0.0348173
[Epoch 6; Iter   875/ 1097] train: loss: 0.1018428
[Epoch 6; Iter   905/ 1097] train: loss: 0.2692855
[Epoch 6; Iter   935/ 1097] train: loss: 0.1147563
[Epoch 6; Iter   965/ 1097] train: loss: 0.1614725
[Epoch 6; Iter   995/ 1097] train: loss: 0.1438393
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1239319
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1729015
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2406671
[Epoch 6] ogbg-molhiv: 0.743760 val loss: 0.436083
[Epoch 6] ogbg-molhiv: 0.660984 test loss: 0.244996
[Epoch 7; Iter    18/ 1097] train: loss: 0.0445606
[Epoch 7; Iter    48/ 1097] train: loss: 0.0288408
[Epoch 7; Iter    78/ 1097] train: loss: 0.2123108
[Epoch 7; Iter   108/ 1097] train: loss: 0.2516825
[Epoch 7; Iter   138/ 1097] train: loss: 0.2066410
[Epoch 7; Iter   168/ 1097] train: loss: 0.0374994
[Epoch 7; Iter   198/ 1097] train: loss: 0.2608893
[Epoch 7; Iter   228/ 1097] train: loss: 0.1453845
[Epoch 7; Iter   258/ 1097] train: loss: 0.0287275
[Epoch 7; Iter   288/ 1097] train: loss: 0.0214247
[Epoch 7; Iter   318/ 1097] train: loss: 0.2006557
[Epoch 7; Iter   348/ 1097] train: loss: 0.0333788
[Epoch 7; Iter   378/ 1097] train: loss: 0.1798528
[Epoch 7; Iter   408/ 1097] train: loss: 0.2661132
[Epoch 7; Iter   438/ 1097] train: loss: 0.1066520
[Epoch 7; Iter   468/ 1097] train: loss: 0.0394006
[Epoch 7; Iter   498/ 1097] train: loss: 0.1416970
[Epoch 7; Iter   528/ 1097] train: loss: 0.1164803
[Epoch 7; Iter   558/ 1097] train: loss: 0.0471204
[Epoch 7; Iter   588/ 1097] train: loss: 0.2475600
[Epoch 7; Iter   618/ 1097] train: loss: 0.1277410
[Epoch 7; Iter   648/ 1097] train: loss: 0.0806516
[Epoch 7; Iter   678/ 1097] train: loss: 0.0394815
[Epoch 7; Iter   708/ 1097] train: loss: 0.1729860
[Epoch 7; Iter   738/ 1097] train: loss: 0.1607609
[Epoch 7; Iter   768/ 1097] train: loss: 0.1713520
[Epoch 7; Iter   798/ 1097] train: loss: 0.1114551
[Epoch 7; Iter   828/ 1097] train: loss: 0.0333830
[Epoch 7; Iter   858/ 1097] train: loss: 0.1514786
[Epoch 7; Iter   888/ 1097] train: loss: 0.0346992
[Epoch 7; Iter   918/ 1097] train: loss: 0.1597569
[Epoch 7; Iter   948/ 1097] train: loss: 0.0365681
[Epoch 7; Iter   978/ 1097] train: loss: 0.0796567
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0352595
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0328938
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1608969
[Epoch 7] ogbg-molhiv: 0.730597 val loss: 0.264583
[Epoch 7] ogbg-molhiv: 0.698712 test loss: 0.488764
[Epoch 8; Iter     1/ 1097] train: loss: 0.1945917
[Epoch 8; Iter    31/ 1097] train: loss: 0.0727073
[Epoch 8; Iter    61/ 1097] train: loss: 0.1195573
[Epoch 8; Iter    91/ 1097] train: loss: 0.0939687
[Epoch 8; Iter   121/ 1097] train: loss: 0.1344930
[Epoch 8; Iter   151/ 1097] train: loss: 0.0367417
[Epoch 8; Iter   181/ 1097] train: loss: 0.0696283
[Epoch 8; Iter   211/ 1097] train: loss: 0.0454369
[Epoch 8; Iter   241/ 1097] train: loss: 0.0232401
[Epoch 8; Iter   271/ 1097] train: loss: 0.1593257
[Epoch 8; Iter   301/ 1097] train: loss: 0.1780965
[Epoch 8; Iter   331/ 1097] train: loss: 0.1065315
[Epoch 8; Iter   361/ 1097] train: loss: 0.2112280
[Epoch 8; Iter   391/ 1097] train: loss: 0.0267729
[Epoch 8; Iter   421/ 1097] train: loss: 0.2647122
[Epoch 8; Iter   451/ 1097] train: loss: 0.1275585
[Epoch 8; Iter   481/ 1097] train: loss: 0.0418066
[Epoch 8; Iter   511/ 1097] train: loss: 0.0957204
[Epoch 8; Iter   541/ 1097] train: loss: 0.1189667
[Epoch 8; Iter   571/ 1097] train: loss: 0.0998995
[Epoch 8; Iter   601/ 1097] train: loss: 0.3303177
[Epoch 8; Iter   631/ 1097] train: loss: 0.0310095
[Epoch 8; Iter   661/ 1097] train: loss: 0.1801521
[Epoch 8; Iter   691/ 1097] train: loss: 0.1048008
[Epoch 8; Iter   721/ 1097] train: loss: 0.0758374
[Epoch 8; Iter   751/ 1097] train: loss: 0.0703027
[Epoch 8; Iter   781/ 1097] train: loss: 0.1543463
[Epoch 8; Iter   811/ 1097] train: loss: 0.2530167
[Epoch 8; Iter   841/ 1097] train: loss: 0.3154508
[Epoch 8; Iter   871/ 1097] train: loss: 0.2041283
[Epoch 8; Iter   901/ 1097] train: loss: 0.0312549
[Epoch 8; Iter   931/ 1097] train: loss: 0.2006349
[Epoch 8; Iter   961/ 1097] train: loss: 0.0409233
[Epoch 8; Iter   991/ 1097] train: loss: 0.1234868
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3016484
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0306904
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0578443
[Epoch 8] ogbg-molhiv: 0.779244 val loss: 0.671757
[Epoch 8] ogbg-molhiv: 0.759976 test loss: 0.119894
[Epoch 9; Iter    14/ 1097] train: loss: 0.2403185
[Epoch 9; Iter    44/ 1097] train: loss: 0.0299525
[Epoch 9; Iter    74/ 1097] train: loss: 0.0256858
[Epoch 9; Iter   104/ 1097] train: loss: 0.2564633
[Epoch 9; Iter   134/ 1097] train: loss: 0.1032123
[Epoch 9; Iter   164/ 1097] train: loss: 0.1568605
[Epoch 9; Iter   194/ 1097] train: loss: 0.1223111
[Epoch 9; Iter   224/ 1097] train: loss: 0.0305767
[Epoch 9; Iter   254/ 1097] train: loss: 0.3825535
[Epoch 9; Iter   284/ 1097] train: loss: 0.1921297
[Epoch 9; Iter   314/ 1097] train: loss: 0.0978604
[Epoch 9; Iter   344/ 1097] train: loss: 0.5142171
[Epoch 9; Iter   374/ 1097] train: loss: 0.1919185
[Epoch 9; Iter   404/ 1097] train: loss: 0.2299384
[Epoch 9; Iter   434/ 1097] train: loss: 0.0773537
[Epoch 9; Iter   464/ 1097] train: loss: 0.0349489
[Epoch 9; Iter   494/ 1097] train: loss: 0.1719939
[Epoch 9; Iter   524/ 1097] train: loss: 0.0276421
[Epoch 9; Iter   554/ 1097] train: loss: 0.0329216
[Epoch 9; Iter   584/ 1097] train: loss: 0.4431015
[Epoch 9; Iter   614/ 1097] train: loss: 0.1105108
[Epoch 9; Iter   644/ 1097] train: loss: 0.2322015
[Epoch 9; Iter   674/ 1097] train: loss: 0.4547201
[Epoch 9; Iter   704/ 1097] train: loss: 0.1050041
[Epoch 9; Iter   734/ 1097] train: loss: 0.0699706
[Epoch 9; Iter   764/ 1097] train: loss: 0.2975236
[Epoch 9; Iter   794/ 1097] train: loss: 0.1467012
[Epoch 9; Iter   824/ 1097] train: loss: 0.0350336
[Epoch 9; Iter   854/ 1097] train: loss: 0.0422545
[Epoch 9; Iter   884/ 1097] train: loss: 0.0620510
[Epoch 9; Iter   914/ 1097] train: loss: 0.1945322
[Epoch 9; Iter   944/ 1097] train: loss: 0.0361587
[Epoch 9; Iter   974/ 1097] train: loss: 0.0715132
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1349018
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2263684
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3410498
[Epoch 9; Iter  1094/ 1097] train: loss: 0.1878447
[Epoch 9] ogbg-molhiv: 0.745266 val loss: 0.578469
[Epoch 9] ogbg-molhiv: 0.742654 test loss: 0.128810
[Epoch 10; Iter    27/ 1097] train: loss: 0.0352965
[Epoch 10; Iter    57/ 1097] train: loss: 0.0368477
[Epoch 10; Iter    87/ 1097] train: loss: 0.1236647
[Epoch 10; Iter   117/ 1097] train: loss: 0.0476149
[Epoch 10; Iter   147/ 1097] train: loss: 0.3716370
[Epoch 10; Iter   177/ 1097] train: loss: 0.2125832
[Epoch 10; Iter   207/ 1097] train: loss: 0.1863647
[Epoch 10; Iter   237/ 1097] train: loss: 0.0541468
[Epoch 10; Iter   267/ 1097] train: loss: 0.0237589
[Epoch 10; Iter   297/ 1097] train: loss: 0.1759709
[Epoch 10; Iter   327/ 1097] train: loss: 0.0241955
[Epoch 10; Iter   357/ 1097] train: loss: 0.1669231
[Epoch 10; Iter   387/ 1097] train: loss: 0.0850859
[Epoch 10; Iter   417/ 1097] train: loss: 0.0707641
[Epoch 10; Iter   447/ 1097] train: loss: 0.1739303
[Epoch 10; Iter   477/ 1097] train: loss: 0.1413859
[Epoch 10; Iter   507/ 1097] train: loss: 0.1072810
[Epoch 10; Iter   537/ 1097] train: loss: 0.0280099
[Epoch 10; Iter   567/ 1097] train: loss: 0.0305976
[Epoch 10; Iter   597/ 1097] train: loss: 0.0353247
[Epoch 10; Iter   627/ 1097] train: loss: 0.2083713
[Epoch 10; Iter   657/ 1097] train: loss: 0.1533252
[Epoch 10; Iter   687/ 1097] train: loss: 0.0916299
[Epoch 10; Iter   717/ 1097] train: loss: 0.0576490
[Epoch 10; Iter   747/ 1097] train: loss: 0.2076538
[Epoch 10; Iter   777/ 1097] train: loss: 0.2621039
[Epoch 10; Iter   807/ 1097] train: loss: 0.0331510
[Epoch 10; Iter   837/ 1097] train: loss: 0.0320794
[Epoch 10; Iter   867/ 1097] train: loss: 0.0535227
[Epoch 10; Iter   897/ 1097] train: loss: 0.0406101
[Epoch 10; Iter   927/ 1097] train: loss: 0.1577231
[Epoch 10; Iter   957/ 1097] train: loss: 0.0430963
[Epoch 10; Iter   987/ 1097] train: loss: 0.2339614
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2012222
[Epoch 10; Iter  1047/ 1097] train: loss: 0.2016564
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0563500
[Epoch 10] ogbg-molhiv: 0.797515 val loss: 0.077999
[Epoch 10] ogbg-molhiv: 0.766624 test loss: 0.114474
[Epoch 11; Iter    10/ 1097] train: loss: 0.3506870
[Epoch 11; Iter    40/ 1097] train: loss: 0.0376470
[Epoch 11; Iter    70/ 1097] train: loss: 0.1502343
[Epoch 11; Iter   100/ 1097] train: loss: 0.0456301
[Epoch 11; Iter   130/ 1097] train: loss: 0.2449499
[Epoch 11; Iter   160/ 1097] train: loss: 0.0295144
[Epoch 11; Iter   190/ 1097] train: loss: 0.2293213
[Epoch 11; Iter   220/ 1097] train: loss: 0.2712800
[Epoch 11; Iter   250/ 1097] train: loss: 0.1443451
[Epoch 11; Iter   280/ 1097] train: loss: 0.0597012
[Epoch 11; Iter   310/ 1097] train: loss: 0.2124710
[Epoch 11; Iter   340/ 1097] train: loss: 0.0312304
[Epoch 11; Iter   370/ 1097] train: loss: 0.0814343
[Epoch 11; Iter   400/ 1097] train: loss: 0.0759665
[Epoch 11; Iter   430/ 1097] train: loss: 0.2481728
[Epoch 11; Iter   460/ 1097] train: loss: 0.1836489
[Epoch 11; Iter   490/ 1097] train: loss: 0.3219131
[Epoch 11; Iter   520/ 1097] train: loss: 0.1439928
[Epoch 11; Iter   550/ 1097] train: loss: 0.0272868
[Epoch 11; Iter   580/ 1097] train: loss: 0.0539454
[Epoch 11; Iter   610/ 1097] train: loss: 0.0325887
[Epoch 11; Iter   640/ 1097] train: loss: 0.0230350
[Epoch 11; Iter   670/ 1097] train: loss: 0.1446281
[Epoch 11; Iter   700/ 1097] train: loss: 0.1639042
[Epoch 11; Iter   730/ 1097] train: loss: 0.0417376
[Epoch 11; Iter   760/ 1097] train: loss: 0.2919047
[Epoch 11; Iter   790/ 1097] train: loss: 0.2021000
[Epoch 11; Iter   820/ 1097] train: loss: 0.0595884
[Epoch 11; Iter   850/ 1097] train: loss: 0.0476376
[Epoch 11; Iter   880/ 1097] train: loss: 0.2064870
[Epoch 11; Iter   910/ 1097] train: loss: 0.3138567
[Epoch 11; Iter   940/ 1097] train: loss: 0.2765197
[Epoch 11; Iter   970/ 1097] train: loss: 0.2122778
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0473454
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0225152
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1450137
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4248309
[Epoch 11] ogbg-molhiv: 0.788868 val loss: 0.618435
[Epoch 11] ogbg-molhiv: 0.756749 test loss: 0.160967
[Epoch 12; Iter    23/ 1097] train: loss: 0.2384025
[Epoch 12; Iter    53/ 1097] train: loss: 0.0284068
[Epoch 12; Iter    83/ 1097] train: loss: 0.0270755
[Epoch 8; Iter     1/ 1097] train: loss: 0.0800055
[Epoch 8; Iter    31/ 1097] train: loss: 0.1383152
[Epoch 8; Iter    61/ 1097] train: loss: 0.1970050
[Epoch 8; Iter    91/ 1097] train: loss: 0.2479877
[Epoch 8; Iter   121/ 1097] train: loss: 0.0490774
[Epoch 8; Iter   151/ 1097] train: loss: 0.3047006
[Epoch 8; Iter   181/ 1097] train: loss: 0.1974319
[Epoch 8; Iter   211/ 1097] train: loss: 0.2411373
[Epoch 8; Iter   241/ 1097] train: loss: 0.0685265
[Epoch 8; Iter   271/ 1097] train: loss: 0.1375281
[Epoch 8; Iter   301/ 1097] train: loss: 0.0362562
[Epoch 8; Iter   331/ 1097] train: loss: 0.0623049
[Epoch 8; Iter   361/ 1097] train: loss: 0.1525261
[Epoch 8; Iter   391/ 1097] train: loss: 0.0381483
[Epoch 8; Iter   421/ 1097] train: loss: 0.2997779
[Epoch 8; Iter   451/ 1097] train: loss: 0.0239563
[Epoch 8; Iter   481/ 1097] train: loss: 0.1019263
[Epoch 8; Iter   511/ 1097] train: loss: 0.0927716
[Epoch 8; Iter   541/ 1097] train: loss: 0.0306920
[Epoch 8; Iter   571/ 1097] train: loss: 0.4495329
[Epoch 8; Iter   601/ 1097] train: loss: 0.1407524
[Epoch 8; Iter   631/ 1097] train: loss: 0.1151959
[Epoch 8; Iter   661/ 1097] train: loss: 0.0380338
[Epoch 8; Iter   691/ 1097] train: loss: 0.1954107
[Epoch 8; Iter   721/ 1097] train: loss: 0.0961834
[Epoch 8; Iter   751/ 1097] train: loss: 0.0400890
[Epoch 8; Iter   781/ 1097] train: loss: 0.2289031
[Epoch 8; Iter   811/ 1097] train: loss: 0.1078938
[Epoch 8; Iter   841/ 1097] train: loss: 0.0432504
[Epoch 8; Iter   871/ 1097] train: loss: 0.1704151
[Epoch 8; Iter   901/ 1097] train: loss: 0.0280962
[Epoch 8; Iter   931/ 1097] train: loss: 0.0700259
[Epoch 8; Iter   961/ 1097] train: loss: 0.0475876
[Epoch 8; Iter   991/ 1097] train: loss: 0.0291468
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0246657
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0259578
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1700482
[Epoch 8] ogbg-molhiv: 0.788874 val loss: 0.359871
[Epoch 8] ogbg-molhiv: 0.751355 test loss: 0.180199
[Epoch 9; Iter    14/ 1097] train: loss: 0.0238587
[Epoch 9; Iter    44/ 1097] train: loss: 0.0493612
[Epoch 9; Iter    74/ 1097] train: loss: 0.1822755
[Epoch 9; Iter   104/ 1097] train: loss: 0.2875412
[Epoch 9; Iter   134/ 1097] train: loss: 0.2347015
[Epoch 9; Iter   164/ 1097] train: loss: 0.0400261
[Epoch 9; Iter   194/ 1097] train: loss: 0.0519775
[Epoch 9; Iter   224/ 1097] train: loss: 0.0321852
[Epoch 9; Iter   254/ 1097] train: loss: 0.0963700
[Epoch 9; Iter   284/ 1097] train: loss: 0.0497458
[Epoch 9; Iter   314/ 1097] train: loss: 0.0526771
[Epoch 9; Iter   344/ 1097] train: loss: 0.0246982
[Epoch 9; Iter   374/ 1097] train: loss: 0.0462584
[Epoch 9; Iter   404/ 1097] train: loss: 0.1110510
[Epoch 9; Iter   434/ 1097] train: loss: 0.1763365
[Epoch 9; Iter   464/ 1097] train: loss: 0.2027364
[Epoch 9; Iter   494/ 1097] train: loss: 0.0695681
[Epoch 9; Iter   524/ 1097] train: loss: 0.1013659
[Epoch 9; Iter   554/ 1097] train: loss: 0.0375851
[Epoch 9; Iter   584/ 1097] train: loss: 0.1845132
[Epoch 9; Iter   614/ 1097] train: loss: 0.0238297
[Epoch 9; Iter   644/ 1097] train: loss: 0.1894010
[Epoch 9; Iter   674/ 1097] train: loss: 0.0796513
[Epoch 9; Iter   704/ 1097] train: loss: 0.0244650
[Epoch 9; Iter   734/ 1097] train: loss: 0.1068511
[Epoch 9; Iter   764/ 1097] train: loss: 0.1029402
[Epoch 9; Iter   794/ 1097] train: loss: 0.0283454
[Epoch 9; Iter   824/ 1097] train: loss: 0.0315418
[Epoch 9; Iter   854/ 1097] train: loss: 0.0355296
[Epoch 9; Iter   884/ 1097] train: loss: 0.2384610
[Epoch 9; Iter   914/ 1097] train: loss: 0.0249426
[Epoch 9; Iter   944/ 1097] train: loss: 0.1520984
[Epoch 9; Iter   974/ 1097] train: loss: 0.0409314
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1425993
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0961943
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0683542
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0710594
[Epoch 9] ogbg-molhiv: 0.751724 val loss: 0.367996
[Epoch 9] ogbg-molhiv: 0.720607 test loss: 0.144749
[Epoch 10; Iter    27/ 1097] train: loss: 0.1681528
[Epoch 10; Iter    57/ 1097] train: loss: 0.0271261
[Epoch 10; Iter    87/ 1097] train: loss: 0.1984989
[Epoch 10; Iter   117/ 1097] train: loss: 0.0450680
[Epoch 10; Iter   147/ 1097] train: loss: 0.0284273
[Epoch 10; Iter   177/ 1097] train: loss: 0.0243294
[Epoch 10; Iter   207/ 1097] train: loss: 0.0257276
[Epoch 10; Iter   237/ 1097] train: loss: 0.0926022
[Epoch 10; Iter   267/ 1097] train: loss: 0.0210233
[Epoch 10; Iter   297/ 1097] train: loss: 0.0250650
[Epoch 10; Iter   327/ 1097] train: loss: 0.0743994
[Epoch 10; Iter   357/ 1097] train: loss: 0.1214102
[Epoch 10; Iter   387/ 1097] train: loss: 0.1642284
[Epoch 10; Iter   417/ 1097] train: loss: 0.0382779
[Epoch 10; Iter   447/ 1097] train: loss: 0.0342470
[Epoch 10; Iter   477/ 1097] train: loss: 0.0379344
[Epoch 10; Iter   507/ 1097] train: loss: 0.0856337
[Epoch 10; Iter   537/ 1097] train: loss: 0.0297374
[Epoch 10; Iter   567/ 1097] train: loss: 0.1659583
[Epoch 10; Iter   597/ 1097] train: loss: 0.1851418
[Epoch 10; Iter   627/ 1097] train: loss: 0.2038486
[Epoch 10; Iter   657/ 1097] train: loss: 0.0242643
[Epoch 10; Iter   687/ 1097] train: loss: 0.3081577
[Epoch 10; Iter   717/ 1097] train: loss: 0.1148463
[Epoch 10; Iter   747/ 1097] train: loss: 0.3689524
[Epoch 10; Iter   777/ 1097] train: loss: 0.1062921
[Epoch 10; Iter   807/ 1097] train: loss: 0.1022665
[Epoch 10; Iter   837/ 1097] train: loss: 0.1003103
[Epoch 10; Iter   867/ 1097] train: loss: 0.3570551
[Epoch 10; Iter   897/ 1097] train: loss: 0.1792646
[Epoch 10; Iter   927/ 1097] train: loss: 0.3581400
[Epoch 10; Iter   957/ 1097] train: loss: 0.2605491
[Epoch 10; Iter   987/ 1097] train: loss: 0.2655976
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0526169
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0769040
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1832066
[Epoch 10] ogbg-molhiv: 0.804488 val loss: 0.075056
[Epoch 10] ogbg-molhiv: 0.751272 test loss: 0.119533
[Epoch 11; Iter    10/ 1097] train: loss: 0.0471231
[Epoch 11; Iter    40/ 1097] train: loss: 0.0350388
[Epoch 11; Iter    70/ 1097] train: loss: 0.0505294
[Epoch 11; Iter   100/ 1097] train: loss: 0.1403562
[Epoch 11; Iter   130/ 1097] train: loss: 0.0267515
[Epoch 11; Iter   160/ 1097] train: loss: 0.0389937
[Epoch 11; Iter   190/ 1097] train: loss: 0.1261646
[Epoch 11; Iter   220/ 1097] train: loss: 0.0543555
[Epoch 11; Iter   250/ 1097] train: loss: 0.1051878
[Epoch 11; Iter   280/ 1097] train: loss: 0.1794437
[Epoch 11; Iter   310/ 1097] train: loss: 0.1025143
[Epoch 11; Iter   340/ 1097] train: loss: 0.0816949
[Epoch 11; Iter   370/ 1097] train: loss: 0.3313352
[Epoch 11; Iter   400/ 1097] train: loss: 0.0577117
[Epoch 11; Iter   430/ 1097] train: loss: 0.1077156
[Epoch 11; Iter   460/ 1097] train: loss: 0.0634963
[Epoch 11; Iter   490/ 1097] train: loss: 0.1916901
[Epoch 11; Iter   520/ 1097] train: loss: 0.5064560
[Epoch 11; Iter   550/ 1097] train: loss: 0.1431270
[Epoch 11; Iter   580/ 1097] train: loss: 0.1713896
[Epoch 11; Iter   610/ 1097] train: loss: 0.0247793
[Epoch 11; Iter   640/ 1097] train: loss: 0.0354353
[Epoch 11; Iter   670/ 1097] train: loss: 0.0498444
[Epoch 11; Iter   700/ 1097] train: loss: 0.0257424
[Epoch 11; Iter   730/ 1097] train: loss: 0.1626876
[Epoch 11; Iter   760/ 1097] train: loss: 0.0341034
[Epoch 11; Iter   790/ 1097] train: loss: 0.0517687
[Epoch 11; Iter   820/ 1097] train: loss: 0.3423786
[Epoch 11; Iter   850/ 1097] train: loss: 0.1133767
[Epoch 11; Iter   880/ 1097] train: loss: 0.0215687
[Epoch 11; Iter   910/ 1097] train: loss: 0.1585858
[Epoch 11; Iter   940/ 1097] train: loss: 0.2596038
[Epoch 11; Iter   970/ 1097] train: loss: 0.1316673
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1290363
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0590167
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2835904
[Epoch 11; Iter  1090/ 1097] train: loss: 0.2712082
[Epoch 11] ogbg-molhiv: 0.797249 val loss: 0.079845
[Epoch 11] ogbg-molhiv: 0.726242 test loss: 0.122252
[Epoch 12; Iter    23/ 1097] train: loss: 0.0841268
[Epoch 12; Iter    53/ 1097] train: loss: 0.0258648
[Epoch 12; Iter    83/ 1097] train: loss: 0.0247514
[Epoch 8; Iter     1/ 1097] train: loss: 0.0964440
[Epoch 8; Iter    31/ 1097] train: loss: 0.0315652
[Epoch 8; Iter    61/ 1097] train: loss: 0.1751736
[Epoch 8; Iter    91/ 1097] train: loss: 0.1726796
[Epoch 8; Iter   121/ 1097] train: loss: 0.0397620
[Epoch 8; Iter   151/ 1097] train: loss: 0.1786755
[Epoch 8; Iter   181/ 1097] train: loss: 0.0395690
[Epoch 8; Iter   211/ 1097] train: loss: 0.3292142
[Epoch 8; Iter   241/ 1097] train: loss: 0.1254803
[Epoch 8; Iter   271/ 1097] train: loss: 0.2039353
[Epoch 8; Iter   301/ 1097] train: loss: 0.0829055
[Epoch 8; Iter   331/ 1097] train: loss: 0.1344270
[Epoch 8; Iter   361/ 1097] train: loss: 0.0582727
[Epoch 8; Iter   391/ 1097] train: loss: 0.0589567
[Epoch 8; Iter   421/ 1097] train: loss: 0.2325278
[Epoch 8; Iter   451/ 1097] train: loss: 0.0250620
[Epoch 8; Iter   481/ 1097] train: loss: 0.1469491
[Epoch 8; Iter   511/ 1097] train: loss: 0.2040115
[Epoch 8; Iter   541/ 1097] train: loss: 0.0317694
[Epoch 8; Iter   571/ 1097] train: loss: 0.0316234
[Epoch 8; Iter   601/ 1097] train: loss: 0.0458408
[Epoch 8; Iter   631/ 1097] train: loss: 0.1056081
[Epoch 8; Iter   661/ 1097] train: loss: 0.0326044
[Epoch 8; Iter   691/ 1097] train: loss: 0.2896396
[Epoch 8; Iter   721/ 1097] train: loss: 0.0364382
[Epoch 8; Iter   751/ 1097] train: loss: 0.0660416
[Epoch 8; Iter   781/ 1097] train: loss: 0.0487119
[Epoch 8; Iter   811/ 1097] train: loss: 0.0611537
[Epoch 8; Iter   841/ 1097] train: loss: 0.1877388
[Epoch 8; Iter   871/ 1097] train: loss: 0.2553319
[Epoch 8; Iter   901/ 1097] train: loss: 0.0401920
[Epoch 8; Iter   931/ 1097] train: loss: 0.1316974
[Epoch 8; Iter   961/ 1097] train: loss: 0.0317418
[Epoch 8; Iter   991/ 1097] train: loss: 0.0586283
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0312426
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0271019
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3002952
[Epoch 8] ogbg-molhiv: 0.761047 val loss: 0.213370
[Epoch 8] ogbg-molhiv: 0.741194 test loss: 1.347312
[Epoch 9; Iter    14/ 1097] train: loss: 0.0363668
[Epoch 9; Iter    44/ 1097] train: loss: 0.0760373
[Epoch 9; Iter    74/ 1097] train: loss: 0.0498160
[Epoch 9; Iter   104/ 1097] train: loss: 0.0370254
[Epoch 9; Iter   134/ 1097] train: loss: 0.1172301
[Epoch 9; Iter   164/ 1097] train: loss: 0.0304269
[Epoch 9; Iter   194/ 1097] train: loss: 0.0298429
[Epoch 9; Iter   224/ 1097] train: loss: 0.3432674
[Epoch 9; Iter   254/ 1097] train: loss: 0.1035284
[Epoch 9; Iter   284/ 1097] train: loss: 0.1440436
[Epoch 9; Iter   314/ 1097] train: loss: 0.2658603
[Epoch 9; Iter   344/ 1097] train: loss: 0.0281920
[Epoch 9; Iter   374/ 1097] train: loss: 0.2098329
[Epoch 9; Iter   404/ 1097] train: loss: 0.1318318
[Epoch 9; Iter   434/ 1097] train: loss: 0.1523838
[Epoch 9; Iter   464/ 1097] train: loss: 0.0280379
[Epoch 9; Iter   494/ 1097] train: loss: 0.0690850
[Epoch 9; Iter   524/ 1097] train: loss: 0.0382507
[Epoch 9; Iter   554/ 1097] train: loss: 0.0573404
[Epoch 9; Iter   584/ 1097] train: loss: 0.1764148
[Epoch 9; Iter   614/ 1097] train: loss: 0.0403359
[Epoch 9; Iter   644/ 1097] train: loss: 0.2000810
[Epoch 9; Iter   674/ 1097] train: loss: 0.1908553
[Epoch 9; Iter   704/ 1097] train: loss: 0.0286318
[Epoch 9; Iter   734/ 1097] train: loss: 0.0244056
[Epoch 9; Iter   764/ 1097] train: loss: 0.0795564
[Epoch 9; Iter   794/ 1097] train: loss: 0.0487228
[Epoch 9; Iter   824/ 1097] train: loss: 0.0245277
[Epoch 9; Iter   854/ 1097] train: loss: 0.0204459
[Epoch 9; Iter   884/ 1097] train: loss: 0.3135779
[Epoch 9; Iter   914/ 1097] train: loss: 0.0557966
[Epoch 9; Iter   944/ 1097] train: loss: 0.2200490
[Epoch 9; Iter   974/ 1097] train: loss: 0.0334758
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0270077
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0283020
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2096051
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0311593
[Epoch 9] ogbg-molhiv: 0.791667 val loss: 0.750979
[Epoch 9] ogbg-molhiv: 0.753624 test loss: 1.266812
[Epoch 10; Iter    27/ 1097] train: loss: 0.2181318
[Epoch 10; Iter    57/ 1097] train: loss: 0.3563406
[Epoch 10; Iter    87/ 1097] train: loss: 0.0336187
[Epoch 10; Iter   117/ 1097] train: loss: 0.1698418
[Epoch 10; Iter   147/ 1097] train: loss: 0.0284167
[Epoch 10; Iter   177/ 1097] train: loss: 0.4759704
[Epoch 10; Iter   207/ 1097] train: loss: 0.0934578
[Epoch 10; Iter   237/ 1097] train: loss: 0.0405976
[Epoch 10; Iter   267/ 1097] train: loss: 0.0397402
[Epoch 10; Iter   297/ 1097] train: loss: 0.3032080
[Epoch 10; Iter   327/ 1097] train: loss: 0.2829197
[Epoch 10; Iter   357/ 1097] train: loss: 0.0564464
[Epoch 10; Iter   387/ 1097] train: loss: 0.0961010
[Epoch 10; Iter   417/ 1097] train: loss: 0.2571229
[Epoch 10; Iter   447/ 1097] train: loss: 0.1714614
[Epoch 10; Iter   477/ 1097] train: loss: 0.0317119
[Epoch 10; Iter   507/ 1097] train: loss: 0.0290714
[Epoch 10; Iter   537/ 1097] train: loss: 0.1151626
[Epoch 10; Iter   567/ 1097] train: loss: 0.2030229
[Epoch 10; Iter   597/ 1097] train: loss: 0.1762970
[Epoch 10; Iter   627/ 1097] train: loss: 0.0583898
[Epoch 10; Iter   657/ 1097] train: loss: 0.3142452
[Epoch 10; Iter   687/ 1097] train: loss: 0.1317405
[Epoch 10; Iter   717/ 1097] train: loss: 0.2948140
[Epoch 10; Iter   747/ 1097] train: loss: 0.0308439
[Epoch 10; Iter   777/ 1097] train: loss: 0.0188150
[Epoch 10; Iter   807/ 1097] train: loss: 0.3294209
[Epoch 10; Iter   837/ 1097] train: loss: 0.0299144
[Epoch 10; Iter   867/ 1097] train: loss: 0.0290336
[Epoch 10; Iter   897/ 1097] train: loss: 0.0329770
[Epoch 10; Iter   927/ 1097] train: loss: 0.1620424
[Epoch 10; Iter   957/ 1097] train: loss: 0.1070371
[Epoch 10; Iter   987/ 1097] train: loss: 0.4798210
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0238084
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0549543
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1868190
[Epoch 10] ogbg-molhiv: 0.779964 val loss: 2.293149
[Epoch 10] ogbg-molhiv: 0.763483 test loss: 3.721013
[Epoch 11; Iter    10/ 1097] train: loss: 0.2956929
[Epoch 11; Iter    40/ 1097] train: loss: 0.1571366
[Epoch 11; Iter    70/ 1097] train: loss: 0.1139309
[Epoch 11; Iter   100/ 1097] train: loss: 0.1169911
[Epoch 11; Iter   130/ 1097] train: loss: 0.4072315
[Epoch 11; Iter   160/ 1097] train: loss: 0.2022343
[Epoch 11; Iter   190/ 1097] train: loss: 0.0364279
[Epoch 11; Iter   220/ 1097] train: loss: 0.2186234
[Epoch 11; Iter   250/ 1097] train: loss: 0.0630226
[Epoch 11; Iter   280/ 1097] train: loss: 0.1776412
[Epoch 11; Iter   310/ 1097] train: loss: 0.2152119
[Epoch 11; Iter   340/ 1097] train: loss: 0.0361857
[Epoch 11; Iter   370/ 1097] train: loss: 0.0267948
[Epoch 11; Iter   400/ 1097] train: loss: 0.2360499
[Epoch 11; Iter   430/ 1097] train: loss: 0.0575928
[Epoch 11; Iter   460/ 1097] train: loss: 0.1179981
[Epoch 11; Iter   490/ 1097] train: loss: 0.2337285
[Epoch 11; Iter   520/ 1097] train: loss: 0.1642368
[Epoch 11; Iter   550/ 1097] train: loss: 0.0242330
[Epoch 11; Iter   580/ 1097] train: loss: 0.4534617
[Epoch 11; Iter   610/ 1097] train: loss: 0.0495912
[Epoch 11; Iter   640/ 1097] train: loss: 0.0565065
[Epoch 11; Iter   670/ 1097] train: loss: 0.0322726
[Epoch 11; Iter   700/ 1097] train: loss: 0.1881288
[Epoch 11; Iter   730/ 1097] train: loss: 0.1840668
[Epoch 11; Iter   760/ 1097] train: loss: 0.1248388
[Epoch 11; Iter   790/ 1097] train: loss: 0.1200030
[Epoch 11; Iter   820/ 1097] train: loss: 0.0428081
[Epoch 11; Iter   850/ 1097] train: loss: 0.2196039
[Epoch 11; Iter   880/ 1097] train: loss: 0.0212844
[Epoch 11; Iter   910/ 1097] train: loss: 0.0353450
[Epoch 11; Iter   940/ 1097] train: loss: 0.2243928
[Epoch 11; Iter   970/ 1097] train: loss: 0.0269908
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0756228
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1534367
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3248499
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0364642
[Epoch 11] ogbg-molhiv: 0.785978 val loss: 0.559255
[Epoch 11] ogbg-molhiv: 0.785002 test loss: 2.095334
[Epoch 12; Iter    23/ 1097] train: loss: 0.1628406
[Epoch 12; Iter    53/ 1097] train: loss: 0.0421046
[Epoch 12; Iter    83/ 1097] train: loss: 0.0564401
[Epoch 8; Iter     1/ 1097] train: loss: 0.1280925
[Epoch 8; Iter    31/ 1097] train: loss: 0.0312394
[Epoch 8; Iter    61/ 1097] train: loss: 0.1471040
[Epoch 8; Iter    91/ 1097] train: loss: 0.1638614
[Epoch 8; Iter   121/ 1097] train: loss: 0.0431026
[Epoch 8; Iter   151/ 1097] train: loss: 0.0820466
[Epoch 8; Iter   181/ 1097] train: loss: 0.0399524
[Epoch 8; Iter   211/ 1097] train: loss: 0.2740607
[Epoch 8; Iter   241/ 1097] train: loss: 0.1642393
[Epoch 8; Iter   271/ 1097] train: loss: 0.2290809
[Epoch 8; Iter   301/ 1097] train: loss: 0.0762735
[Epoch 8; Iter   331/ 1097] train: loss: 0.1230189
[Epoch 8; Iter   361/ 1097] train: loss: 0.0436846
[Epoch 8; Iter   391/ 1097] train: loss: 0.0305066
[Epoch 8; Iter   421/ 1097] train: loss: 0.2159269
[Epoch 8; Iter   451/ 1097] train: loss: 0.0270208
[Epoch 8; Iter   481/ 1097] train: loss: 0.2144332
[Epoch 8; Iter   511/ 1097] train: loss: 0.1916536
[Epoch 8; Iter   541/ 1097] train: loss: 0.0364147
[Epoch 8; Iter   571/ 1097] train: loss: 0.0305689
[Epoch 8; Iter   601/ 1097] train: loss: 0.0585884
[Epoch 8; Iter   631/ 1097] train: loss: 0.0949415
[Epoch 8; Iter   661/ 1097] train: loss: 0.0346170
[Epoch 8; Iter   691/ 1097] train: loss: 0.2741301
[Epoch 8; Iter   721/ 1097] train: loss: 0.0429166
[Epoch 8; Iter   751/ 1097] train: loss: 0.0986915
[Epoch 8; Iter   781/ 1097] train: loss: 0.0620403
[Epoch 8; Iter   811/ 1097] train: loss: 0.0544541
[Epoch 8; Iter   841/ 1097] train: loss: 0.1689097
[Epoch 8; Iter   871/ 1097] train: loss: 0.3513224
[Epoch 8; Iter   901/ 1097] train: loss: 0.0513268
[Epoch 8; Iter   931/ 1097] train: loss: 0.1017966
[Epoch 8; Iter   961/ 1097] train: loss: 0.0273706
[Epoch 8; Iter   991/ 1097] train: loss: 0.0334903
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0426869
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0335544
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3771943
[Epoch 8] ogbg-molhiv: 0.734577 val loss: 0.422311
[Epoch 8] ogbg-molhiv: 0.685301 test loss: 0.126259
[Epoch 9; Iter    14/ 1097] train: loss: 0.0397905
[Epoch 9; Iter    44/ 1097] train: loss: 0.0500555
[Epoch 9; Iter    74/ 1097] train: loss: 0.0490594
[Epoch 9; Iter   104/ 1097] train: loss: 0.0486907
[Epoch 9; Iter   134/ 1097] train: loss: 0.0319814
[Epoch 9; Iter   164/ 1097] train: loss: 0.0354596
[Epoch 9; Iter   194/ 1097] train: loss: 0.0336981
[Epoch 9; Iter   224/ 1097] train: loss: 0.3382013
[Epoch 9; Iter   254/ 1097] train: loss: 0.1123671
[Epoch 9; Iter   284/ 1097] train: loss: 0.1582694
[Epoch 9; Iter   314/ 1097] train: loss: 0.1871418
[Epoch 9; Iter   344/ 1097] train: loss: 0.0276805
[Epoch 9; Iter   374/ 1097] train: loss: 0.1593391
[Epoch 9; Iter   404/ 1097] train: loss: 0.1772344
[Epoch 9; Iter   434/ 1097] train: loss: 0.1128154
[Epoch 9; Iter   464/ 1097] train: loss: 0.0313001
[Epoch 9; Iter   494/ 1097] train: loss: 0.0942858
[Epoch 9; Iter   524/ 1097] train: loss: 0.0305861
[Epoch 9; Iter   554/ 1097] train: loss: 0.0705354
[Epoch 9; Iter   584/ 1097] train: loss: 0.1624179
[Epoch 9; Iter   614/ 1097] train: loss: 0.0609311
[Epoch 9; Iter   644/ 1097] train: loss: 0.1500042
[Epoch 9; Iter   674/ 1097] train: loss: 0.1716488
[Epoch 9; Iter   704/ 1097] train: loss: 0.0251479
[Epoch 9; Iter   734/ 1097] train: loss: 0.0284340
[Epoch 9; Iter   764/ 1097] train: loss: 0.1026327
[Epoch 9; Iter   794/ 1097] train: loss: 0.0430220
[Epoch 9; Iter   824/ 1097] train: loss: 0.0226590
[Epoch 9; Iter   854/ 1097] train: loss: 0.0231248
[Epoch 9; Iter   884/ 1097] train: loss: 0.3155065
[Epoch 9; Iter   914/ 1097] train: loss: 0.0583703
[Epoch 9; Iter   944/ 1097] train: loss: 0.1829227
[Epoch 9; Iter   974/ 1097] train: loss: 0.0281247
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0287402
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0356425
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2957742
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0443431
[Epoch 9] ogbg-molhiv: 0.748671 val loss: 0.215948
[Epoch 9] ogbg-molhiv: 0.735219 test loss: 0.175040
[Epoch 10; Iter    27/ 1097] train: loss: 0.2439832
[Epoch 10; Iter    57/ 1097] train: loss: 0.2995878
[Epoch 10; Iter    87/ 1097] train: loss: 0.0424473
[Epoch 10; Iter   117/ 1097] train: loss: 0.1633410
[Epoch 10; Iter   147/ 1097] train: loss: 0.0240384
[Epoch 10; Iter   177/ 1097] train: loss: 0.4113207
[Epoch 10; Iter   207/ 1097] train: loss: 0.0780624
[Epoch 10; Iter   237/ 1097] train: loss: 0.0318778
[Epoch 10; Iter   267/ 1097] train: loss: 0.0781463
[Epoch 10; Iter   297/ 1097] train: loss: 0.2313038
[Epoch 10; Iter   327/ 1097] train: loss: 0.2628612
[Epoch 10; Iter   357/ 1097] train: loss: 0.0291127
[Epoch 10; Iter   387/ 1097] train: loss: 0.1086521
[Epoch 10; Iter   417/ 1097] train: loss: 0.2621956
[Epoch 10; Iter   447/ 1097] train: loss: 0.1311068
[Epoch 10; Iter   477/ 1097] train: loss: 0.0314728
[Epoch 10; Iter   507/ 1097] train: loss: 0.0302762
[Epoch 10; Iter   537/ 1097] train: loss: 0.1876228
[Epoch 10; Iter   567/ 1097] train: loss: 0.2182442
[Epoch 10; Iter   597/ 1097] train: loss: 0.1895578
[Epoch 10; Iter   627/ 1097] train: loss: 0.0381942
[Epoch 10; Iter   657/ 1097] train: loss: 0.2666571
[Epoch 10; Iter   687/ 1097] train: loss: 0.1949101
[Epoch 10; Iter   717/ 1097] train: loss: 0.3082750
[Epoch 10; Iter   747/ 1097] train: loss: 0.0224669
[Epoch 10; Iter   777/ 1097] train: loss: 0.0195039
[Epoch 10; Iter   807/ 1097] train: loss: 0.3139055
[Epoch 10; Iter   837/ 1097] train: loss: 0.0360496
[Epoch 10; Iter   867/ 1097] train: loss: 0.0292367
[Epoch 10; Iter   897/ 1097] train: loss: 0.0527309
[Epoch 10; Iter   927/ 1097] train: loss: 0.1885417
[Epoch 10; Iter   957/ 1097] train: loss: 0.1083116
[Epoch 10; Iter   987/ 1097] train: loss: 0.4937294
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0250284
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0417238
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1329675
[Epoch 10] ogbg-molhiv: 0.788651 val loss: 0.076219
[Epoch 10] ogbg-molhiv: 0.737506 test loss: 0.121883
[Epoch 11; Iter    10/ 1097] train: loss: 0.2981924
[Epoch 11; Iter    40/ 1097] train: loss: 0.2032977
[Epoch 11; Iter    70/ 1097] train: loss: 0.1045654
[Epoch 11; Iter   100/ 1097] train: loss: 0.0870834
[Epoch 11; Iter   130/ 1097] train: loss: 0.2903298
[Epoch 11; Iter   160/ 1097] train: loss: 0.2159731
[Epoch 11; Iter   190/ 1097] train: loss: 0.0300051
[Epoch 11; Iter   220/ 1097] train: loss: 0.1567937
[Epoch 11; Iter   250/ 1097] train: loss: 0.0532567
[Epoch 11; Iter   280/ 1097] train: loss: 0.1698579
[Epoch 11; Iter   310/ 1097] train: loss: 0.1993513
[Epoch 11; Iter   340/ 1097] train: loss: 0.0380585
[Epoch 11; Iter   370/ 1097] train: loss: 0.0325258
[Epoch 11; Iter   400/ 1097] train: loss: 0.2435386
[Epoch 11; Iter   430/ 1097] train: loss: 0.0338341
[Epoch 11; Iter   460/ 1097] train: loss: 0.1535822
[Epoch 11; Iter   490/ 1097] train: loss: 0.2320576
[Epoch 11; Iter   520/ 1097] train: loss: 0.1310944
[Epoch 11; Iter   550/ 1097] train: loss: 0.0207747
[Epoch 11; Iter   580/ 1097] train: loss: 0.4904001
[Epoch 11; Iter   610/ 1097] train: loss: 0.0620986
[Epoch 11; Iter   640/ 1097] train: loss: 0.0770625
[Epoch 11; Iter   670/ 1097] train: loss: 0.0303313
[Epoch 11; Iter   700/ 1097] train: loss: 0.2094672
[Epoch 11; Iter   730/ 1097] train: loss: 0.0993125
[Epoch 11; Iter   760/ 1097] train: loss: 0.1583053
[Epoch 11; Iter   790/ 1097] train: loss: 0.0436162
[Epoch 11; Iter   820/ 1097] train: loss: 0.1532955
[Epoch 11; Iter   850/ 1097] train: loss: 0.2271568
[Epoch 11; Iter   880/ 1097] train: loss: 0.0284405
[Epoch 11; Iter   910/ 1097] train: loss: 0.0314669
[Epoch 11; Iter   940/ 1097] train: loss: 0.1684207
[Epoch 11; Iter   970/ 1097] train: loss: 0.0247197
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0515315
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1811597
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2255497
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0458685
[Epoch 11] ogbg-molhiv: 0.789787 val loss: 0.083467
[Epoch 11] ogbg-molhiv: 0.768101 test loss: 0.124984
[Epoch 12; Iter    23/ 1097] train: loss: 0.1324822
[Epoch 12; Iter    53/ 1097] train: loss: 0.0261783
[Epoch 12; Iter    83/ 1097] train: loss: 0.0588398
[Epoch 8; Iter     1/ 1097] train: loss: 0.1561418
[Epoch 8; Iter    31/ 1097] train: loss: 0.0571051
[Epoch 8; Iter    61/ 1097] train: loss: 0.0828051
[Epoch 8; Iter    91/ 1097] train: loss: 0.0773991
[Epoch 8; Iter   121/ 1097] train: loss: 0.1118207
[Epoch 8; Iter   151/ 1097] train: loss: 0.0310402
[Epoch 8; Iter   181/ 1097] train: loss: 0.0480170
[Epoch 8; Iter   211/ 1097] train: loss: 0.0534206
[Epoch 8; Iter   241/ 1097] train: loss: 0.0318571
[Epoch 8; Iter   271/ 1097] train: loss: 0.1881698
[Epoch 8; Iter   301/ 1097] train: loss: 0.1993176
[Epoch 8; Iter   331/ 1097] train: loss: 0.1211940
[Epoch 8; Iter   361/ 1097] train: loss: 0.1403960
[Epoch 8; Iter   391/ 1097] train: loss: 0.0295182
[Epoch 8; Iter   421/ 1097] train: loss: 0.2704999
[Epoch 8; Iter   451/ 1097] train: loss: 0.1559974
[Epoch 8; Iter   481/ 1097] train: loss: 0.0519357
[Epoch 8; Iter   511/ 1097] train: loss: 0.0691852
[Epoch 8; Iter   541/ 1097] train: loss: 0.1432652
[Epoch 8; Iter   571/ 1097] train: loss: 0.1027000
[Epoch 8; Iter   601/ 1097] train: loss: 0.3802238
[Epoch 8; Iter   631/ 1097] train: loss: 0.0264527
[Epoch 8; Iter   661/ 1097] train: loss: 0.2383596
[Epoch 8; Iter   691/ 1097] train: loss: 0.1314813
[Epoch 8; Iter   721/ 1097] train: loss: 0.0768486
[Epoch 8; Iter   751/ 1097] train: loss: 0.1266273
[Epoch 8; Iter   781/ 1097] train: loss: 0.2096641
[Epoch 8; Iter   811/ 1097] train: loss: 0.2375679
[Epoch 8; Iter   841/ 1097] train: loss: 0.4159228
[Epoch 8; Iter   871/ 1097] train: loss: 0.1874473
[Epoch 8; Iter   901/ 1097] train: loss: 0.0248687
[Epoch 8; Iter   931/ 1097] train: loss: 0.1947478
[Epoch 8; Iter   961/ 1097] train: loss: 0.0373917
[Epoch 8; Iter   991/ 1097] train: loss: 0.1880254
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2879460
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0306607
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0999968
[Epoch 8] ogbg-molhiv: 0.763123 val loss: 0.135436
[Epoch 8] ogbg-molhiv: 0.738170 test loss: 0.126798
[Epoch 9; Iter    14/ 1097] train: loss: 0.2815258
[Epoch 9; Iter    44/ 1097] train: loss: 0.0319396
[Epoch 9; Iter    74/ 1097] train: loss: 0.0276980
[Epoch 9; Iter   104/ 1097] train: loss: 0.2589598
[Epoch 9; Iter   134/ 1097] train: loss: 0.0659293
[Epoch 9; Iter   164/ 1097] train: loss: 0.1496398
[Epoch 9; Iter   194/ 1097] train: loss: 0.1313744
[Epoch 9; Iter   224/ 1097] train: loss: 0.0349307
[Epoch 9; Iter   254/ 1097] train: loss: 0.3376476
[Epoch 9; Iter   284/ 1097] train: loss: 0.1886933
[Epoch 9; Iter   314/ 1097] train: loss: 0.1465816
[Epoch 9; Iter   344/ 1097] train: loss: 0.4883933
[Epoch 9; Iter   374/ 1097] train: loss: 0.1714616
[Epoch 9; Iter   404/ 1097] train: loss: 0.1650886
[Epoch 9; Iter   434/ 1097] train: loss: 0.0579293
[Epoch 9; Iter   464/ 1097] train: loss: 0.0338924
[Epoch 9; Iter   494/ 1097] train: loss: 0.1828466
[Epoch 9; Iter   524/ 1097] train: loss: 0.0361375
[Epoch 9; Iter   554/ 1097] train: loss: 0.0324933
[Epoch 9; Iter   584/ 1097] train: loss: 0.3922772
[Epoch 9; Iter   614/ 1097] train: loss: 0.0949961
[Epoch 9; Iter   644/ 1097] train: loss: 0.2675312
[Epoch 9; Iter   674/ 1097] train: loss: 0.4284544
[Epoch 9; Iter   704/ 1097] train: loss: 0.1266760
[Epoch 9; Iter   734/ 1097] train: loss: 0.0810247
[Epoch 9; Iter   764/ 1097] train: loss: 0.3032567
[Epoch 9; Iter   794/ 1097] train: loss: 0.1556526
[Epoch 9; Iter   824/ 1097] train: loss: 0.0346294
[Epoch 9; Iter   854/ 1097] train: loss: 0.0350394
[Epoch 9; Iter   884/ 1097] train: loss: 0.0852553
[Epoch 9; Iter   914/ 1097] train: loss: 0.1789938
[Epoch 9; Iter   944/ 1097] train: loss: 0.0568841
[Epoch 9; Iter   974/ 1097] train: loss: 0.0942788
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2272757
[Epoch 9; Iter  1034/ 1097] train: loss: 0.1881647
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3389817
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2511392
[Epoch 9] ogbg-molhiv: 0.720256 val loss: 0.093533
[Epoch 9] ogbg-molhiv: 0.690863 test loss: 0.128454
[Epoch 10; Iter    27/ 1097] train: loss: 0.0244735
[Epoch 10; Iter    57/ 1097] train: loss: 0.0357972
[Epoch 10; Iter    87/ 1097] train: loss: 0.0943131
[Epoch 10; Iter   117/ 1097] train: loss: 0.0330379
[Epoch 10; Iter   147/ 1097] train: loss: 0.3420310
[Epoch 10; Iter   177/ 1097] train: loss: 0.1758150
[Epoch 10; Iter   207/ 1097] train: loss: 0.1783347
[Epoch 10; Iter   237/ 1097] train: loss: 0.0511116
[Epoch 10; Iter   267/ 1097] train: loss: 0.0263211
[Epoch 10; Iter   297/ 1097] train: loss: 0.1917821
[Epoch 10; Iter   327/ 1097] train: loss: 0.0263925
[Epoch 10; Iter   357/ 1097] train: loss: 0.1965885
[Epoch 10; Iter   387/ 1097] train: loss: 0.1195852
[Epoch 10; Iter   417/ 1097] train: loss: 0.0834169
[Epoch 10; Iter   447/ 1097] train: loss: 0.1625558
[Epoch 10; Iter   477/ 1097] train: loss: 0.1488986
[Epoch 10; Iter   507/ 1097] train: loss: 0.1191232
[Epoch 10; Iter   537/ 1097] train: loss: 0.0299240
[Epoch 10; Iter   567/ 1097] train: loss: 0.0249613
[Epoch 10; Iter   597/ 1097] train: loss: 0.0279097
[Epoch 10; Iter   627/ 1097] train: loss: 0.2079461
[Epoch 10; Iter   657/ 1097] train: loss: 0.1444889
[Epoch 10; Iter   687/ 1097] train: loss: 0.0839473
[Epoch 10; Iter   717/ 1097] train: loss: 0.1461880
[Epoch 10; Iter   747/ 1097] train: loss: 0.2313752
[Epoch 10; Iter   777/ 1097] train: loss: 0.2175891
[Epoch 10; Iter   807/ 1097] train: loss: 0.0350972
[Epoch 10; Iter   837/ 1097] train: loss: 0.0299617
[Epoch 10; Iter   867/ 1097] train: loss: 0.0616658
[Epoch 10; Iter   897/ 1097] train: loss: 0.0358836
[Epoch 10; Iter   927/ 1097] train: loss: 0.1184034
[Epoch 10; Iter   957/ 1097] train: loss: 0.0441461
[Epoch 10; Iter   987/ 1097] train: loss: 0.2128975
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2685350
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1873122
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0270876
[Epoch 10] ogbg-molhiv: 0.771143 val loss: 0.112474
[Epoch 10] ogbg-molhiv: 0.733602 test loss: 0.202768
[Epoch 11; Iter    10/ 1097] train: loss: 0.3341604
[Epoch 11; Iter    40/ 1097] train: loss: 0.0463872
[Epoch 11; Iter    70/ 1097] train: loss: 0.1737138
[Epoch 11; Iter   100/ 1097] train: loss: 0.0251179
[Epoch 11; Iter   130/ 1097] train: loss: 0.1781622
[Epoch 11; Iter   160/ 1097] train: loss: 0.0481674
[Epoch 11; Iter   190/ 1097] train: loss: 0.1790628
[Epoch 11; Iter   220/ 1097] train: loss: 0.2979914
[Epoch 11; Iter   250/ 1097] train: loss: 0.2033711
[Epoch 11; Iter   280/ 1097] train: loss: 0.0546732
[Epoch 11; Iter   310/ 1097] train: loss: 0.2717842
[Epoch 11; Iter   340/ 1097] train: loss: 0.0370147
[Epoch 11; Iter   370/ 1097] train: loss: 0.1541619
[Epoch 11; Iter   400/ 1097] train: loss: 0.0523771
[Epoch 11; Iter   430/ 1097] train: loss: 0.2466715
[Epoch 11; Iter   460/ 1097] train: loss: 0.1156172
[Epoch 11; Iter   490/ 1097] train: loss: 0.2844618
[Epoch 11; Iter   520/ 1097] train: loss: 0.1881206
[Epoch 11; Iter   550/ 1097] train: loss: 0.0361178
[Epoch 11; Iter   580/ 1097] train: loss: 0.0608937
[Epoch 11; Iter   610/ 1097] train: loss: 0.0323319
[Epoch 11; Iter   640/ 1097] train: loss: 0.0344433
[Epoch 11; Iter   670/ 1097] train: loss: 0.1544988
[Epoch 11; Iter   700/ 1097] train: loss: 0.1635472
[Epoch 11; Iter   730/ 1097] train: loss: 0.0417636
[Epoch 11; Iter   760/ 1097] train: loss: 0.2648807
[Epoch 11; Iter   790/ 1097] train: loss: 0.1938781
[Epoch 11; Iter   820/ 1097] train: loss: 0.0724886
[Epoch 11; Iter   850/ 1097] train: loss: 0.0449157
[Epoch 11; Iter   880/ 1097] train: loss: 0.2671453
[Epoch 11; Iter   910/ 1097] train: loss: 0.2579772
[Epoch 11; Iter   940/ 1097] train: loss: 0.2338247
[Epoch 11; Iter   970/ 1097] train: loss: 0.2827731
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0511059
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0310992
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2133078
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4209577
[Epoch 11] ogbg-molhiv: 0.760558 val loss: 0.243305
[Epoch 11] ogbg-molhiv: 0.744717 test loss: 0.172215
[Epoch 12; Iter    23/ 1097] train: loss: 0.2329811
[Epoch 12; Iter    53/ 1097] train: loss: 0.0210844
[Epoch 12; Iter    83/ 1097] train: loss: 0.0354344
[Epoch 8; Iter     1/ 1097] train: loss: 0.1646492
[Epoch 8; Iter    31/ 1097] train: loss: 0.1945899
[Epoch 8; Iter    61/ 1097] train: loss: 0.3211876
[Epoch 8; Iter    91/ 1097] train: loss: 0.2704385
[Epoch 8; Iter   121/ 1097] train: loss: 0.0335326
[Epoch 8; Iter   151/ 1097] train: loss: 0.4717862
[Epoch 8; Iter   181/ 1097] train: loss: 0.1953399
[Epoch 8; Iter   211/ 1097] train: loss: 0.2379706
[Epoch 8; Iter   241/ 1097] train: loss: 0.0460604
[Epoch 8; Iter   271/ 1097] train: loss: 0.1674377
[Epoch 8; Iter   301/ 1097] train: loss: 0.0282826
[Epoch 8; Iter   331/ 1097] train: loss: 0.0492111
[Epoch 8; Iter   361/ 1097] train: loss: 0.1227383
[Epoch 8; Iter   391/ 1097] train: loss: 0.0859753
[Epoch 8; Iter   421/ 1097] train: loss: 0.2808959
[Epoch 8; Iter   451/ 1097] train: loss: 0.0290515
[Epoch 8; Iter   481/ 1097] train: loss: 0.1727787
[Epoch 8; Iter   511/ 1097] train: loss: 0.1440123
[Epoch 8; Iter   541/ 1097] train: loss: 0.0374035
[Epoch 8; Iter   571/ 1097] train: loss: 0.3376544
[Epoch 8; Iter   601/ 1097] train: loss: 0.1293564
[Epoch 8; Iter   631/ 1097] train: loss: 0.0637587
[Epoch 8; Iter   661/ 1097] train: loss: 0.0378239
[Epoch 8; Iter   691/ 1097] train: loss: 0.1506433
[Epoch 8; Iter   721/ 1097] train: loss: 0.0826033
[Epoch 8; Iter   751/ 1097] train: loss: 0.0314293
[Epoch 8; Iter   781/ 1097] train: loss: 0.2677721
[Epoch 8; Iter   811/ 1097] train: loss: 0.1183493
[Epoch 8; Iter   841/ 1097] train: loss: 0.0501150
[Epoch 8; Iter   871/ 1097] train: loss: 0.1573457
[Epoch 8; Iter   901/ 1097] train: loss: 0.0266846
[Epoch 8; Iter   931/ 1097] train: loss: 0.0726533
[Epoch 8; Iter   961/ 1097] train: loss: 0.0421582
[Epoch 8; Iter   991/ 1097] train: loss: 0.0348857
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0213683
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0188463
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1053975
[Epoch 8] ogbg-molhiv: 0.787683 val loss: 0.077683
[Epoch 8] ogbg-molhiv: 0.738114 test loss: 0.119909
[Epoch 9; Iter    14/ 1097] train: loss: 0.0287755
[Epoch 9; Iter    44/ 1097] train: loss: 0.0474804
[Epoch 9; Iter    74/ 1097] train: loss: 0.1460870
[Epoch 9; Iter   104/ 1097] train: loss: 0.3589925
[Epoch 9; Iter   134/ 1097] train: loss: 0.2350814
[Epoch 9; Iter   164/ 1097] train: loss: 0.0347490
[Epoch 9; Iter   194/ 1097] train: loss: 0.0500840
[Epoch 9; Iter   224/ 1097] train: loss: 0.0260861
[Epoch 9; Iter   254/ 1097] train: loss: 0.0817019
[Epoch 9; Iter   284/ 1097] train: loss: 0.0370638
[Epoch 9; Iter   314/ 1097] train: loss: 0.0362522
[Epoch 9; Iter   344/ 1097] train: loss: 0.0515574
[Epoch 9; Iter   374/ 1097] train: loss: 0.0319114
[Epoch 9; Iter   404/ 1097] train: loss: 0.0792609
[Epoch 9; Iter   434/ 1097] train: loss: 0.1694077
[Epoch 9; Iter   464/ 1097] train: loss: 0.2446744
[Epoch 9; Iter   494/ 1097] train: loss: 0.0993657
[Epoch 9; Iter   524/ 1097] train: loss: 0.0954256
[Epoch 9; Iter   554/ 1097] train: loss: 0.0396472
[Epoch 9; Iter   584/ 1097] train: loss: 0.2073629
[Epoch 9; Iter   614/ 1097] train: loss: 0.0314599
[Epoch 9; Iter   644/ 1097] train: loss: 0.1900363
[Epoch 9; Iter   674/ 1097] train: loss: 0.0731141
[Epoch 9; Iter   704/ 1097] train: loss: 0.0313374
[Epoch 9; Iter   734/ 1097] train: loss: 0.1240491
[Epoch 9; Iter   764/ 1097] train: loss: 0.1276877
[Epoch 9; Iter   794/ 1097] train: loss: 0.0380578
[Epoch 9; Iter   824/ 1097] train: loss: 0.0421925
[Epoch 9; Iter   854/ 1097] train: loss: 0.0438569
[Epoch 9; Iter   884/ 1097] train: loss: 0.2266032
[Epoch 9; Iter   914/ 1097] train: loss: 0.0285821
[Epoch 9; Iter   944/ 1097] train: loss: 0.1573545
[Epoch 9; Iter   974/ 1097] train: loss: 0.0399750
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1564793
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0928541
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0717870
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0569099
[Epoch 9] ogbg-molhiv: 0.672689 val loss: 0.151247
[Epoch 9] ogbg-molhiv: 0.672562 test loss: 0.199459
[Epoch 10; Iter    27/ 1097] train: loss: 0.1631152
[Epoch 10; Iter    57/ 1097] train: loss: 0.0351058
[Epoch 10; Iter    87/ 1097] train: loss: 0.2157720
[Epoch 10; Iter   117/ 1097] train: loss: 0.0583571
[Epoch 10; Iter   147/ 1097] train: loss: 0.0304115
[Epoch 10; Iter   177/ 1097] train: loss: 0.0351758
[Epoch 10; Iter   207/ 1097] train: loss: 0.0336583
[Epoch 10; Iter   237/ 1097] train: loss: 0.0776523
[Epoch 10; Iter   267/ 1097] train: loss: 0.0259045
[Epoch 10; Iter   297/ 1097] train: loss: 0.0297883
[Epoch 10; Iter   327/ 1097] train: loss: 0.0427307
[Epoch 10; Iter   357/ 1097] train: loss: 0.1153639
[Epoch 10; Iter   387/ 1097] train: loss: 0.1706926
[Epoch 10; Iter   417/ 1097] train: loss: 0.0326355
[Epoch 10; Iter   447/ 1097] train: loss: 0.0409275
[Epoch 10; Iter   477/ 1097] train: loss: 0.0440390
[Epoch 10; Iter   507/ 1097] train: loss: 0.0823555
[Epoch 10; Iter   537/ 1097] train: loss: 0.0478237
[Epoch 10; Iter   567/ 1097] train: loss: 0.1407440
[Epoch 10; Iter   597/ 1097] train: loss: 0.1976954
[Epoch 10; Iter   627/ 1097] train: loss: 0.2127136
[Epoch 10; Iter   657/ 1097] train: loss: 0.0275717
[Epoch 10; Iter   687/ 1097] train: loss: 0.2451137
[Epoch 10; Iter   717/ 1097] train: loss: 0.0725348
[Epoch 10; Iter   747/ 1097] train: loss: 0.2499896
[Epoch 10; Iter   777/ 1097] train: loss: 0.0941349
[Epoch 10; Iter   807/ 1097] train: loss: 0.0520964
[Epoch 10; Iter   837/ 1097] train: loss: 0.0374742
[Epoch 10; Iter   867/ 1097] train: loss: 0.3715848
[Epoch 10; Iter   897/ 1097] train: loss: 0.2079677
[Epoch 10; Iter   927/ 1097] train: loss: 0.4606486
[Epoch 10; Iter   957/ 1097] train: loss: 0.2452941
[Epoch 10; Iter   987/ 1097] train: loss: 0.1738020
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0735807
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0998698
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1501786
[Epoch 10] ogbg-molhiv: 0.746301 val loss: 0.127984
[Epoch 10] ogbg-molhiv: 0.780282 test loss: 0.140108
[Epoch 11; Iter    10/ 1097] train: loss: 0.0506129
[Epoch 11; Iter    40/ 1097] train: loss: 0.0386810
[Epoch 11; Iter    70/ 1097] train: loss: 0.0458473
[Epoch 11; Iter   100/ 1097] train: loss: 0.1620392
[Epoch 11; Iter   130/ 1097] train: loss: 0.0574306
[Epoch 11; Iter   160/ 1097] train: loss: 0.0443382
[Epoch 11; Iter   190/ 1097] train: loss: 0.1005051
[Epoch 11; Iter   220/ 1097] train: loss: 0.0503577
[Epoch 11; Iter   250/ 1097] train: loss: 0.1615194
[Epoch 11; Iter   280/ 1097] train: loss: 0.2066409
[Epoch 11; Iter   310/ 1097] train: loss: 0.1174572
[Epoch 11; Iter   340/ 1097] train: loss: 0.0691390
[Epoch 11; Iter   370/ 1097] train: loss: 0.2569456
[Epoch 11; Iter   400/ 1097] train: loss: 0.0598129
[Epoch 11; Iter   430/ 1097] train: loss: 0.1364007
[Epoch 11; Iter   460/ 1097] train: loss: 0.1318507
[Epoch 11; Iter   490/ 1097] train: loss: 0.1855164
[Epoch 11; Iter   520/ 1097] train: loss: 0.4747731
[Epoch 11; Iter   550/ 1097] train: loss: 0.1956659
[Epoch 11; Iter   580/ 1097] train: loss: 0.1243393
[Epoch 11; Iter   610/ 1097] train: loss: 0.0284214
[Epoch 11; Iter   640/ 1097] train: loss: 0.0430645
[Epoch 11; Iter   670/ 1097] train: loss: 0.0361960
[Epoch 11; Iter   700/ 1097] train: loss: 0.0385257
[Epoch 11; Iter   730/ 1097] train: loss: 0.1801848
[Epoch 11; Iter   760/ 1097] train: loss: 0.0548382
[Epoch 11; Iter   790/ 1097] train: loss: 0.0368235
[Epoch 11; Iter   820/ 1097] train: loss: 0.3509012
[Epoch 11; Iter   850/ 1097] train: loss: 0.1771920
[Epoch 11; Iter   880/ 1097] train: loss: 0.0350476
[Epoch 11; Iter   910/ 1097] train: loss: 0.2089911
[Epoch 11; Iter   940/ 1097] train: loss: 0.2739056
[Epoch 11; Iter   970/ 1097] train: loss: 0.1452879
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0883366
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0976322
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2738219
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3284417
[Epoch 11] ogbg-molhiv: 0.777429 val loss: 0.077754
[Epoch 11] ogbg-molhiv: 0.758919 test loss: 0.116981
[Epoch 12; Iter    23/ 1097] train: loss: 0.0998096
[Epoch 12; Iter    53/ 1097] train: loss: 0.0297810
[Epoch 12; Iter    83/ 1097] train: loss: 0.0357165
[Epoch 8; Iter     1/ 1097] train: loss: 0.1798164
[Epoch 8; Iter    31/ 1097] train: loss: 0.0344340
[Epoch 8; Iter    61/ 1097] train: loss: 0.1784672
[Epoch 8; Iter    91/ 1097] train: loss: 0.1774585
[Epoch 8; Iter   121/ 1097] train: loss: 0.0443122
[Epoch 8; Iter   151/ 1097] train: loss: 0.1061374
[Epoch 8; Iter   181/ 1097] train: loss: 0.0314419
[Epoch 8; Iter   211/ 1097] train: loss: 0.3477791
[Epoch 8; Iter   241/ 1097] train: loss: 0.1277117
[Epoch 8; Iter   271/ 1097] train: loss: 0.2317816
[Epoch 8; Iter   301/ 1097] train: loss: 0.0649065
[Epoch 8; Iter   331/ 1097] train: loss: 0.1386730
[Epoch 8; Iter   361/ 1097] train: loss: 0.0543005
[Epoch 8; Iter   391/ 1097] train: loss: 0.0400410
[Epoch 8; Iter   421/ 1097] train: loss: 0.2364322
[Epoch 8; Iter   451/ 1097] train: loss: 0.0344915
[Epoch 8; Iter   481/ 1097] train: loss: 0.1887665
[Epoch 8; Iter   511/ 1097] train: loss: 0.1601187
[Epoch 8; Iter   541/ 1097] train: loss: 0.0371611
[Epoch 8; Iter   571/ 1097] train: loss: 0.0360887
[Epoch 8; Iter   601/ 1097] train: loss: 0.0361913
[Epoch 8; Iter   631/ 1097] train: loss: 0.1207055
[Epoch 8; Iter   661/ 1097] train: loss: 0.0421614
[Epoch 8; Iter   691/ 1097] train: loss: 0.3534499
[Epoch 8; Iter   721/ 1097] train: loss: 0.0386864
[Epoch 8; Iter   751/ 1097] train: loss: 0.0799913
[Epoch 8; Iter   781/ 1097] train: loss: 0.0353176
[Epoch 8; Iter   811/ 1097] train: loss: 0.0454971
[Epoch 8; Iter   841/ 1097] train: loss: 0.1441997
[Epoch 8; Iter   871/ 1097] train: loss: 0.3076995
[Epoch 8; Iter   901/ 1097] train: loss: 0.0390713
[Epoch 8; Iter   931/ 1097] train: loss: 0.1848111
[Epoch 8; Iter   961/ 1097] train: loss: 0.0314757
[Epoch 8; Iter   991/ 1097] train: loss: 0.0422675
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0361579
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0312903
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3818438
[Epoch 8] ogbg-molhiv: 0.740226 val loss: 0.094908
[Epoch 8] ogbg-molhiv: 0.724607 test loss: 0.177610
[Epoch 9; Iter    14/ 1097] train: loss: 0.0533824
[Epoch 9; Iter    44/ 1097] train: loss: 0.0617684
[Epoch 9; Iter    74/ 1097] train: loss: 0.0630009
[Epoch 9; Iter   104/ 1097] train: loss: 0.0502946
[Epoch 9; Iter   134/ 1097] train: loss: 0.0717298
[Epoch 9; Iter   164/ 1097] train: loss: 0.0320870
[Epoch 9; Iter   194/ 1097] train: loss: 0.0421603
[Epoch 9; Iter   224/ 1097] train: loss: 0.3183044
[Epoch 9; Iter   254/ 1097] train: loss: 0.1644184
[Epoch 9; Iter   284/ 1097] train: loss: 0.1474455
[Epoch 9; Iter   314/ 1097] train: loss: 0.2400805
[Epoch 9; Iter   344/ 1097] train: loss: 0.0301133
[Epoch 9; Iter   374/ 1097] train: loss: 0.1544840
[Epoch 9; Iter   404/ 1097] train: loss: 0.1423247
[Epoch 9; Iter   434/ 1097] train: loss: 0.1227746
[Epoch 9; Iter   464/ 1097] train: loss: 0.0382616
[Epoch 9; Iter   494/ 1097] train: loss: 0.1084735
[Epoch 9; Iter   524/ 1097] train: loss: 0.0337617
[Epoch 9; Iter   554/ 1097] train: loss: 0.0623910
[Epoch 9; Iter   584/ 1097] train: loss: 0.0669606
[Epoch 9; Iter   614/ 1097] train: loss: 0.0422980
[Epoch 9; Iter   644/ 1097] train: loss: 0.1228099
[Epoch 9; Iter   674/ 1097] train: loss: 0.1830495
[Epoch 9; Iter   704/ 1097] train: loss: 0.0288096
[Epoch 9; Iter   734/ 1097] train: loss: 0.0426855
[Epoch 9; Iter   764/ 1097] train: loss: 0.1126727
[Epoch 9; Iter   794/ 1097] train: loss: 0.0386020
[Epoch 9; Iter   824/ 1097] train: loss: 0.0248398
[Epoch 9; Iter   854/ 1097] train: loss: 0.0292134
[Epoch 9; Iter   884/ 1097] train: loss: 0.2818652
[Epoch 9; Iter   914/ 1097] train: loss: 0.0531269
[Epoch 9; Iter   944/ 1097] train: loss: 0.2281417
[Epoch 9; Iter   974/ 1097] train: loss: 0.0375109
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0529316
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0347271
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2638489
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0339217
[Epoch 9] ogbg-molhiv: 0.747250 val loss: 0.082507
[Epoch 9] ogbg-molhiv: 0.728345 test loss: 0.131753
[Epoch 10; Iter    27/ 1097] train: loss: 0.2332961
[Epoch 10; Iter    57/ 1097] train: loss: 0.3351637
[Epoch 10; Iter    87/ 1097] train: loss: 0.0369755
[Epoch 10; Iter   117/ 1097] train: loss: 0.1611223
[Epoch 10; Iter   147/ 1097] train: loss: 0.0405911
[Epoch 10; Iter   177/ 1097] train: loss: 0.5428764
[Epoch 10; Iter   207/ 1097] train: loss: 0.0730021
[Epoch 10; Iter   237/ 1097] train: loss: 0.0316692
[Epoch 10; Iter   267/ 1097] train: loss: 0.1129353
[Epoch 10; Iter   297/ 1097] train: loss: 0.2834984
[Epoch 10; Iter   327/ 1097] train: loss: 0.2209574
[Epoch 10; Iter   357/ 1097] train: loss: 0.0455799
[Epoch 10; Iter   387/ 1097] train: loss: 0.1197209
[Epoch 10; Iter   417/ 1097] train: loss: 0.2882269
[Epoch 10; Iter   447/ 1097] train: loss: 0.1436318
[Epoch 10; Iter   477/ 1097] train: loss: 0.0359294
[Epoch 10; Iter   507/ 1097] train: loss: 0.0261438
[Epoch 10; Iter   537/ 1097] train: loss: 0.1976416
[Epoch 10; Iter   567/ 1097] train: loss: 0.1659859
[Epoch 10; Iter   597/ 1097] train: loss: 0.1394358
[Epoch 10; Iter   627/ 1097] train: loss: 0.0690570
[Epoch 10; Iter   657/ 1097] train: loss: 0.2794583
[Epoch 10; Iter   687/ 1097] train: loss: 0.1441932
[Epoch 10; Iter   717/ 1097] train: loss: 0.2702337
[Epoch 10; Iter   747/ 1097] train: loss: 0.0293045
[Epoch 10; Iter   777/ 1097] train: loss: 0.0230924
[Epoch 10; Iter   807/ 1097] train: loss: 0.3573877
[Epoch 10; Iter   837/ 1097] train: loss: 0.0478761
[Epoch 10; Iter   867/ 1097] train: loss: 0.0362028
[Epoch 10; Iter   897/ 1097] train: loss: 0.0825283
[Epoch 10; Iter   927/ 1097] train: loss: 0.1995420
[Epoch 10; Iter   957/ 1097] train: loss: 0.1369630
[Epoch 10; Iter   987/ 1097] train: loss: 0.5812089
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0278519
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0933657
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2281477
[Epoch 10] ogbg-molhiv: 0.781192 val loss: 0.081764
[Epoch 10] ogbg-molhiv: 0.774041 test loss: 0.114478
[Epoch 11; Iter    10/ 1097] train: loss: 0.3088205
[Epoch 11; Iter    40/ 1097] train: loss: 0.1511299
[Epoch 11; Iter    70/ 1097] train: loss: 0.1292038
[Epoch 11; Iter   100/ 1097] train: loss: 0.0886885
[Epoch 11; Iter   130/ 1097] train: loss: 0.1953462
[Epoch 11; Iter   160/ 1097] train: loss: 0.1650956
[Epoch 11; Iter   190/ 1097] train: loss: 0.0245969
[Epoch 11; Iter   220/ 1097] train: loss: 0.2497959
[Epoch 11; Iter   250/ 1097] train: loss: 0.0570628
[Epoch 11; Iter   280/ 1097] train: loss: 0.1485527
[Epoch 11; Iter   310/ 1097] train: loss: 0.1750152
[Epoch 11; Iter   340/ 1097] train: loss: 0.0397995
[Epoch 11; Iter   370/ 1097] train: loss: 0.0350106
[Epoch 11; Iter   400/ 1097] train: loss: 0.2240707
[Epoch 11; Iter   430/ 1097] train: loss: 0.0585704
[Epoch 11; Iter   460/ 1097] train: loss: 0.1138005
[Epoch 11; Iter   490/ 1097] train: loss: 0.3068388
[Epoch 11; Iter   520/ 1097] train: loss: 0.1563892
[Epoch 11; Iter   550/ 1097] train: loss: 0.0253396
[Epoch 11; Iter   580/ 1097] train: loss: 0.5281323
[Epoch 11; Iter   610/ 1097] train: loss: 0.1890974
[Epoch 11; Iter   640/ 1097] train: loss: 0.0471581
[Epoch 11; Iter   670/ 1097] train: loss: 0.0282882
[Epoch 11; Iter   700/ 1097] train: loss: 0.1801572
[Epoch 11; Iter   730/ 1097] train: loss: 0.3162754
[Epoch 11; Iter   760/ 1097] train: loss: 0.1229163
[Epoch 11; Iter   790/ 1097] train: loss: 0.1554161
[Epoch 11; Iter   820/ 1097] train: loss: 0.0925605
[Epoch 11; Iter   850/ 1097] train: loss: 0.1954407
[Epoch 11; Iter   880/ 1097] train: loss: 0.0352872
[Epoch 11; Iter   910/ 1097] train: loss: 0.0437199
[Epoch 11; Iter   940/ 1097] train: loss: 0.1601559
[Epoch 11; Iter   970/ 1097] train: loss: 0.0306768
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0560400
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1995441
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1873784
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0377644
[Epoch 11] ogbg-molhiv: 0.769174 val loss: 0.081033
[Epoch 11] ogbg-molhiv: 0.764333 test loss: 0.117319
[Epoch 12; Iter    23/ 1097] train: loss: 0.2416158
[Epoch 12; Iter    53/ 1097] train: loss: 0.0360999
[Epoch 12; Iter    83/ 1097] train: loss: 0.0742641
[Epoch 8; Iter     1/ 1097] train: loss: 0.2215589
[Epoch 8; Iter    31/ 1097] train: loss: 0.0572163
[Epoch 8; Iter    61/ 1097] train: loss: 0.0721594
[Epoch 8; Iter    91/ 1097] train: loss: 0.1765530
[Epoch 8; Iter   121/ 1097] train: loss: 0.2094089
[Epoch 8; Iter   151/ 1097] train: loss: 0.0312365
[Epoch 8; Iter   181/ 1097] train: loss: 0.0364002
[Epoch 8; Iter   211/ 1097] train: loss: 0.0416203
[Epoch 8; Iter   241/ 1097] train: loss: 0.0301347
[Epoch 8; Iter   271/ 1097] train: loss: 0.1876682
[Epoch 8; Iter   301/ 1097] train: loss: 0.2167094
[Epoch 8; Iter   331/ 1097] train: loss: 0.1153228
[Epoch 8; Iter   361/ 1097] train: loss: 0.1725522
[Epoch 8; Iter   391/ 1097] train: loss: 0.0233382
[Epoch 8; Iter   421/ 1097] train: loss: 0.3269128
[Epoch 8; Iter   451/ 1097] train: loss: 0.1884172
[Epoch 8; Iter   481/ 1097] train: loss: 0.0414407
[Epoch 8; Iter   511/ 1097] train: loss: 0.1542827
[Epoch 8; Iter   541/ 1097] train: loss: 0.1424899
[Epoch 8; Iter   571/ 1097] train: loss: 0.1206814
[Epoch 8; Iter   601/ 1097] train: loss: 0.4045155
[Epoch 8; Iter   631/ 1097] train: loss: 0.0372966
[Epoch 8; Iter   661/ 1097] train: loss: 0.2564723
[Epoch 8; Iter   691/ 1097] train: loss: 0.0730486
[Epoch 8; Iter   721/ 1097] train: loss: 0.0746812
[Epoch 8; Iter   751/ 1097] train: loss: 0.1263124
[Epoch 8; Iter   781/ 1097] train: loss: 0.1931172
[Epoch 8; Iter   811/ 1097] train: loss: 0.2257978
[Epoch 8; Iter   841/ 1097] train: loss: 0.3499181
[Epoch 8; Iter   871/ 1097] train: loss: 0.2063620
[Epoch 8; Iter   901/ 1097] train: loss: 0.0290958
[Epoch 8; Iter   931/ 1097] train: loss: 0.2281671
[Epoch 8; Iter   961/ 1097] train: loss: 0.0429529
[Epoch 8; Iter   991/ 1097] train: loss: 0.1429450
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3022194
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0333290
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0964489
[Epoch 8] ogbg-molhiv: 0.791719 val loss: 0.083815
[Epoch 8] ogbg-molhiv: 0.748043 test loss: 0.124301
[Epoch 9; Iter    14/ 1097] train: loss: 0.2382515
[Epoch 9; Iter    44/ 1097] train: loss: 0.0306681
[Epoch 9; Iter    74/ 1097] train: loss: 0.0283376
[Epoch 9; Iter   104/ 1097] train: loss: 0.2747804
[Epoch 9; Iter   134/ 1097] train: loss: 0.1260818
[Epoch 9; Iter   164/ 1097] train: loss: 0.1223128
[Epoch 9; Iter   194/ 1097] train: loss: 0.0776710
[Epoch 9; Iter   224/ 1097] train: loss: 0.0301636
[Epoch 9; Iter   254/ 1097] train: loss: 0.3546416
[Epoch 9; Iter   284/ 1097] train: loss: 0.2001055
[Epoch 9; Iter   314/ 1097] train: loss: 0.1759552
[Epoch 9; Iter   344/ 1097] train: loss: 0.5016360
[Epoch 9; Iter   374/ 1097] train: loss: 0.1897971
[Epoch 9; Iter   404/ 1097] train: loss: 0.1945356
[Epoch 9; Iter   434/ 1097] train: loss: 0.0555580
[Epoch 9; Iter   464/ 1097] train: loss: 0.0464603
[Epoch 9; Iter   494/ 1097] train: loss: 0.1859778
[Epoch 9; Iter   524/ 1097] train: loss: 0.0275430
[Epoch 9; Iter   554/ 1097] train: loss: 0.0551020
[Epoch 9; Iter   584/ 1097] train: loss: 0.4976837
[Epoch 9; Iter   614/ 1097] train: loss: 0.1278297
[Epoch 9; Iter   644/ 1097] train: loss: 0.3670096
[Epoch 9; Iter   674/ 1097] train: loss: 0.4047802
[Epoch 9; Iter   704/ 1097] train: loss: 0.1225272
[Epoch 9; Iter   734/ 1097] train: loss: 0.0819243
[Epoch 9; Iter   764/ 1097] train: loss: 0.2206014
[Epoch 9; Iter   794/ 1097] train: loss: 0.1837370
[Epoch 9; Iter   824/ 1097] train: loss: 0.0371332
[Epoch 9; Iter   854/ 1097] train: loss: 0.0310238
[Epoch 9; Iter   884/ 1097] train: loss: 0.1241468
[Epoch 9; Iter   914/ 1097] train: loss: 0.1899429
[Epoch 9; Iter   944/ 1097] train: loss: 0.0498360
[Epoch 9; Iter   974/ 1097] train: loss: 0.1101533
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1870313
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2488757
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3580260
[Epoch 9; Iter  1094/ 1097] train: loss: 0.3337102
[Epoch 9] ogbg-molhiv: 0.765527 val loss: 0.227362
[Epoch 9] ogbg-molhiv: 0.728832 test loss: 0.145668
[Epoch 10; Iter    27/ 1097] train: loss: 0.0297110
[Epoch 10; Iter    57/ 1097] train: loss: 0.0310925
[Epoch 10; Iter    87/ 1097] train: loss: 0.1452676
[Epoch 10; Iter   117/ 1097] train: loss: 0.0356967
[Epoch 10; Iter   147/ 1097] train: loss: 0.4101246
[Epoch 10; Iter   177/ 1097] train: loss: 0.1862191
[Epoch 10; Iter   207/ 1097] train: loss: 0.2382160
[Epoch 10; Iter   237/ 1097] train: loss: 0.0389544
[Epoch 10; Iter   267/ 1097] train: loss: 0.0316996
[Epoch 10; Iter   297/ 1097] train: loss: 0.2103702
[Epoch 10; Iter   327/ 1097] train: loss: 0.0293919
[Epoch 10; Iter   357/ 1097] train: loss: 0.1966579
[Epoch 10; Iter   387/ 1097] train: loss: 0.1358210
[Epoch 10; Iter   417/ 1097] train: loss: 0.0624101
[Epoch 10; Iter   447/ 1097] train: loss: 0.1655365
[Epoch 10; Iter   477/ 1097] train: loss: 0.1759824
[Epoch 10; Iter   507/ 1097] train: loss: 0.1343636
[Epoch 10; Iter   537/ 1097] train: loss: 0.0278246
[Epoch 10; Iter   567/ 1097] train: loss: 0.0346745
[Epoch 10; Iter   597/ 1097] train: loss: 0.0458152
[Epoch 10; Iter   627/ 1097] train: loss: 0.2097941
[Epoch 10; Iter   657/ 1097] train: loss: 0.1697769
[Epoch 10; Iter   687/ 1097] train: loss: 0.0576880
[Epoch 10; Iter   717/ 1097] train: loss: 0.1375688
[Epoch 10; Iter   747/ 1097] train: loss: 0.2708811
[Epoch 10; Iter   777/ 1097] train: loss: 0.2282048
[Epoch 10; Iter   807/ 1097] train: loss: 0.0313945
[Epoch 10; Iter   837/ 1097] train: loss: 0.0359556
[Epoch 10; Iter   867/ 1097] train: loss: 0.0712692
[Epoch 10; Iter   897/ 1097] train: loss: 0.0344470
[Epoch 10; Iter   927/ 1097] train: loss: 0.1723312
[Epoch 10; Iter   957/ 1097] train: loss: 0.0422878
[Epoch 10; Iter   987/ 1097] train: loss: 0.2051869
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2282624
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1167630
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0471685
[Epoch 10] ogbg-molhiv: 0.772674 val loss: 0.089857
[Epoch 10] ogbg-molhiv: 0.727106 test loss: 0.124094
[Epoch 11; Iter    10/ 1097] train: loss: 0.2989167
[Epoch 11; Iter    40/ 1097] train: loss: 0.0368591
[Epoch 11; Iter    70/ 1097] train: loss: 0.1517272
[Epoch 11; Iter   100/ 1097] train: loss: 0.0250044
[Epoch 11; Iter   130/ 1097] train: loss: 0.1766720
[Epoch 11; Iter   160/ 1097] train: loss: 0.0327692
[Epoch 11; Iter   190/ 1097] train: loss: 0.2477103
[Epoch 11; Iter   220/ 1097] train: loss: 0.2837945
[Epoch 11; Iter   250/ 1097] train: loss: 0.1723079
[Epoch 11; Iter   280/ 1097] train: loss: 0.0455859
[Epoch 11; Iter   310/ 1097] train: loss: 0.2172738
[Epoch 11; Iter   340/ 1097] train: loss: 0.0354590
[Epoch 11; Iter   370/ 1097] train: loss: 0.1042388
[Epoch 11; Iter   400/ 1097] train: loss: 0.0696160
[Epoch 11; Iter   430/ 1097] train: loss: 0.2578448
[Epoch 11; Iter   460/ 1097] train: loss: 0.1414088
[Epoch 11; Iter   490/ 1097] train: loss: 0.2151434
[Epoch 11; Iter   520/ 1097] train: loss: 0.1912259
[Epoch 11; Iter   550/ 1097] train: loss: 0.0271356
[Epoch 11; Iter   580/ 1097] train: loss: 0.0617892
[Epoch 11; Iter   610/ 1097] train: loss: 0.0268368
[Epoch 11; Iter   640/ 1097] train: loss: 0.0306555
[Epoch 11; Iter   670/ 1097] train: loss: 0.1862024
[Epoch 11; Iter   700/ 1097] train: loss: 0.1130043
[Epoch 11; Iter   730/ 1097] train: loss: 0.0414475
[Epoch 11; Iter   760/ 1097] train: loss: 0.2196708
[Epoch 11; Iter   790/ 1097] train: loss: 0.1942838
[Epoch 11; Iter   820/ 1097] train: loss: 0.0724096
[Epoch 11; Iter   850/ 1097] train: loss: 0.0383129
[Epoch 11; Iter   880/ 1097] train: loss: 0.2891295
[Epoch 11; Iter   910/ 1097] train: loss: 0.2819932
[Epoch 11; Iter   940/ 1097] train: loss: 0.2796837
[Epoch 11; Iter   970/ 1097] train: loss: 0.2861341
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0440739
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0232262
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2431729
[Epoch 11; Iter  1090/ 1097] train: loss: 0.5107096
[Epoch 11] ogbg-molhiv: 0.782695 val loss: 0.403118
[Epoch 11] ogbg-molhiv: 0.711385 test loss: 0.690635
[Epoch 12; Iter    23/ 1097] train: loss: 0.1993928
[Epoch 12; Iter    53/ 1097] train: loss: 0.0402498
[Epoch 12; Iter    83/ 1097] train: loss: 0.0370722
[Epoch 8; Iter     1/ 1097] train: loss: 0.1364762
[Epoch 8; Iter    31/ 1097] train: loss: 0.1776775
[Epoch 8; Iter    61/ 1097] train: loss: 0.3404725
[Epoch 8; Iter    91/ 1097] train: loss: 0.3303644
[Epoch 8; Iter   121/ 1097] train: loss: 0.0358091
[Epoch 8; Iter   151/ 1097] train: loss: 0.4387432
[Epoch 8; Iter   181/ 1097] train: loss: 0.1892061
[Epoch 8; Iter   211/ 1097] train: loss: 0.1950769
[Epoch 8; Iter   241/ 1097] train: loss: 0.0372390
[Epoch 8; Iter   271/ 1097] train: loss: 0.1629386
[Epoch 8; Iter   301/ 1097] train: loss: 0.0274106
[Epoch 8; Iter   331/ 1097] train: loss: 0.0279619
[Epoch 8; Iter   361/ 1097] train: loss: 0.1119976
[Epoch 8; Iter   391/ 1097] train: loss: 0.0616780
[Epoch 8; Iter   421/ 1097] train: loss: 0.3238775
[Epoch 8; Iter   451/ 1097] train: loss: 0.0365059
[Epoch 8; Iter   481/ 1097] train: loss: 0.0917958
[Epoch 8; Iter   511/ 1097] train: loss: 0.1308137
[Epoch 8; Iter   541/ 1097] train: loss: 0.0372452
[Epoch 8; Iter   571/ 1097] train: loss: 0.4435521
[Epoch 8; Iter   601/ 1097] train: loss: 0.1187689
[Epoch 8; Iter   631/ 1097] train: loss: 0.1036771
[Epoch 8; Iter   661/ 1097] train: loss: 0.0395500
[Epoch 8; Iter   691/ 1097] train: loss: 0.1907076
[Epoch 8; Iter   721/ 1097] train: loss: 0.0955882
[Epoch 8; Iter   751/ 1097] train: loss: 0.0351700
[Epoch 8; Iter   781/ 1097] train: loss: 0.2071650
[Epoch 8; Iter   811/ 1097] train: loss: 0.0868537
[Epoch 8; Iter   841/ 1097] train: loss: 0.0759659
[Epoch 8; Iter   871/ 1097] train: loss: 0.1705462
[Epoch 8; Iter   901/ 1097] train: loss: 0.0289270
[Epoch 8; Iter   931/ 1097] train: loss: 0.0709453
[Epoch 8; Iter   961/ 1097] train: loss: 0.0520361
[Epoch 8; Iter   991/ 1097] train: loss: 0.0346798
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0291571
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0222432
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1208734
[Epoch 8] ogbg-molhiv: 0.768222 val loss: 0.083947
[Epoch 8] ogbg-molhiv: 0.715789 test loss: 0.166796
[Epoch 9; Iter    14/ 1097] train: loss: 0.0262758
[Epoch 9; Iter    44/ 1097] train: loss: 0.0457047
[Epoch 9; Iter    74/ 1097] train: loss: 0.1585141
[Epoch 9; Iter   104/ 1097] train: loss: 0.4299810
[Epoch 9; Iter   134/ 1097] train: loss: 0.2177251
[Epoch 9; Iter   164/ 1097] train: loss: 0.0344642
[Epoch 9; Iter   194/ 1097] train: loss: 0.0562261
[Epoch 9; Iter   224/ 1097] train: loss: 0.0283707
[Epoch 9; Iter   254/ 1097] train: loss: 0.1512624
[Epoch 9; Iter   284/ 1097] train: loss: 0.0404562
[Epoch 9; Iter   314/ 1097] train: loss: 0.0322815
[Epoch 9; Iter   344/ 1097] train: loss: 0.0597605
[Epoch 9; Iter   374/ 1097] train: loss: 0.0329651
[Epoch 9; Iter   404/ 1097] train: loss: 0.1201579
[Epoch 9; Iter   434/ 1097] train: loss: 0.1726180
[Epoch 9; Iter   464/ 1097] train: loss: 0.2197829
[Epoch 9; Iter   494/ 1097] train: loss: 0.0963400
[Epoch 9; Iter   524/ 1097] train: loss: 0.0678427
[Epoch 9; Iter   554/ 1097] train: loss: 0.0415852
[Epoch 9; Iter   584/ 1097] train: loss: 0.2086033
[Epoch 9; Iter   614/ 1097] train: loss: 0.0334998
[Epoch 9; Iter   644/ 1097] train: loss: 0.2208620
[Epoch 9; Iter   674/ 1097] train: loss: 0.0660347
[Epoch 9; Iter   704/ 1097] train: loss: 0.0253343
[Epoch 9; Iter   734/ 1097] train: loss: 0.1613187
[Epoch 9; Iter   764/ 1097] train: loss: 0.0667348
[Epoch 9; Iter   794/ 1097] train: loss: 0.0444830
[Epoch 9; Iter   824/ 1097] train: loss: 0.0419516
[Epoch 9; Iter   854/ 1097] train: loss: 0.0371245
[Epoch 9; Iter   884/ 1097] train: loss: 0.2539404
[Epoch 9; Iter   914/ 1097] train: loss: 0.0303716
[Epoch 9; Iter   944/ 1097] train: loss: 0.1637110
[Epoch 9; Iter   974/ 1097] train: loss: 0.0497220
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1489439
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0824326
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0762244
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0498376
[Epoch 9] ogbg-molhiv: 0.751007 val loss: 0.430921
[Epoch 9] ogbg-molhiv: 0.702020 test loss: 1.565656
[Epoch 10; Iter    27/ 1097] train: loss: 0.1570636
[Epoch 10; Iter    57/ 1097] train: loss: 0.0396927
[Epoch 10; Iter    87/ 1097] train: loss: 0.2271135
[Epoch 10; Iter   117/ 1097] train: loss: 0.0621861
[Epoch 10; Iter   147/ 1097] train: loss: 0.0243761
[Epoch 10; Iter   177/ 1097] train: loss: 0.0309944
[Epoch 10; Iter   207/ 1097] train: loss: 0.0353529
[Epoch 10; Iter   237/ 1097] train: loss: 0.0644747
[Epoch 10; Iter   267/ 1097] train: loss: 0.0402688
[Epoch 10; Iter   297/ 1097] train: loss: 0.0235111
[Epoch 10; Iter   327/ 1097] train: loss: 0.0438339
[Epoch 10; Iter   357/ 1097] train: loss: 0.0760952
[Epoch 10; Iter   387/ 1097] train: loss: 0.1904458
[Epoch 10; Iter   417/ 1097] train: loss: 0.0342540
[Epoch 10; Iter   447/ 1097] train: loss: 0.0491778
[Epoch 10; Iter   477/ 1097] train: loss: 0.0490922
[Epoch 10; Iter   507/ 1097] train: loss: 0.0440971
[Epoch 10; Iter   537/ 1097] train: loss: 0.0271732
[Epoch 10; Iter   567/ 1097] train: loss: 0.1271820
[Epoch 10; Iter   597/ 1097] train: loss: 0.1936387
[Epoch 10; Iter   627/ 1097] train: loss: 0.2371266
[Epoch 10; Iter   657/ 1097] train: loss: 0.0214736
[Epoch 10; Iter   687/ 1097] train: loss: 0.1917816
[Epoch 10; Iter   717/ 1097] train: loss: 0.0796039
[Epoch 10; Iter   747/ 1097] train: loss: 0.3300341
[Epoch 10; Iter   777/ 1097] train: loss: 0.0716679
[Epoch 10; Iter   807/ 1097] train: loss: 0.0696907
[Epoch 10; Iter   837/ 1097] train: loss: 0.0704925
[Epoch 10; Iter   867/ 1097] train: loss: 0.4204640
[Epoch 10; Iter   897/ 1097] train: loss: 0.1584431
[Epoch 10; Iter   927/ 1097] train: loss: 0.3668518
[Epoch 10; Iter   957/ 1097] train: loss: 0.2228448
[Epoch 10; Iter   987/ 1097] train: loss: 0.2683662
[Epoch 10; Iter  1017/ 1097] train: loss: 0.1257771
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1358060
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1802571
[Epoch 10] ogbg-molhiv: 0.767502 val loss: 0.342870
[Epoch 10] ogbg-molhiv: 0.723564 test loss: 1.170699
[Epoch 11; Iter    10/ 1097] train: loss: 0.0331550
[Epoch 11; Iter    40/ 1097] train: loss: 0.0307079
[Epoch 11; Iter    70/ 1097] train: loss: 0.0356181
[Epoch 11; Iter   100/ 1097] train: loss: 0.1481839
[Epoch 11; Iter   130/ 1097] train: loss: 0.0375966
[Epoch 11; Iter   160/ 1097] train: loss: 0.0900221
[Epoch 11; Iter   190/ 1097] train: loss: 0.1361654
[Epoch 11; Iter   220/ 1097] train: loss: 0.1104173
[Epoch 11; Iter   250/ 1097] train: loss: 0.1482875
[Epoch 11; Iter   280/ 1097] train: loss: 0.2152326
[Epoch 11; Iter   310/ 1097] train: loss: 0.1311833
[Epoch 11; Iter   340/ 1097] train: loss: 0.0323682
[Epoch 11; Iter   370/ 1097] train: loss: 0.3683304
[Epoch 11; Iter   400/ 1097] train: loss: 0.0741576
[Epoch 11; Iter   430/ 1097] train: loss: 0.1794174
[Epoch 11; Iter   460/ 1097] train: loss: 0.1630682
[Epoch 11; Iter   490/ 1097] train: loss: 0.1666866
[Epoch 11; Iter   520/ 1097] train: loss: 0.4735307
[Epoch 11; Iter   550/ 1097] train: loss: 0.1372717
[Epoch 11; Iter   580/ 1097] train: loss: 0.1618689
[Epoch 11; Iter   610/ 1097] train: loss: 0.0299316
[Epoch 11; Iter   640/ 1097] train: loss: 0.0307636
[Epoch 11; Iter   670/ 1097] train: loss: 0.0255243
[Epoch 11; Iter   700/ 1097] train: loss: 0.0258351
[Epoch 11; Iter   730/ 1097] train: loss: 0.1538544
[Epoch 11; Iter   760/ 1097] train: loss: 0.0536229
[Epoch 11; Iter   790/ 1097] train: loss: 0.0523500
[Epoch 11; Iter   820/ 1097] train: loss: 0.2567643
[Epoch 11; Iter   850/ 1097] train: loss: 0.1171635
[Epoch 11; Iter   880/ 1097] train: loss: 0.0380340
[Epoch 11; Iter   910/ 1097] train: loss: 0.2864558
[Epoch 11; Iter   940/ 1097] train: loss: 0.2848065
[Epoch 11; Iter   970/ 1097] train: loss: 0.1508147
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1540288
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0919226
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3012946
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4008943
[Epoch 11] ogbg-molhiv: 0.790234 val loss: 0.097963
[Epoch 11] ogbg-molhiv: 0.716381 test loss: 0.121323
[Epoch 12; Iter    23/ 1097] train: loss: 0.1238215
[Epoch 12; Iter    53/ 1097] train: loss: 0.0392258
[Epoch 12; Iter    83/ 1097] train: loss: 0.0368482
[Epoch 8; Iter     1/ 1097] train: loss: 0.1525391
[Epoch 8; Iter    31/ 1097] train: loss: 0.1792570
[Epoch 8; Iter    61/ 1097] train: loss: 0.3408674
[Epoch 8; Iter    91/ 1097] train: loss: 0.3284863
[Epoch 8; Iter   121/ 1097] train: loss: 0.0365687
[Epoch 8; Iter   151/ 1097] train: loss: 0.4733429
[Epoch 8; Iter   181/ 1097] train: loss: 0.2086290
[Epoch 8; Iter   211/ 1097] train: loss: 0.2119234
[Epoch 8; Iter   241/ 1097] train: loss: 0.0371697
[Epoch 8; Iter   271/ 1097] train: loss: 0.2146916
[Epoch 8; Iter   301/ 1097] train: loss: 0.0291236
[Epoch 8; Iter   331/ 1097] train: loss: 0.0345145
[Epoch 8; Iter   361/ 1097] train: loss: 0.1043702
[Epoch 8; Iter   391/ 1097] train: loss: 0.1083057
[Epoch 8; Iter   421/ 1097] train: loss: 0.2712100
[Epoch 8; Iter   451/ 1097] train: loss: 0.0303125
[Epoch 8; Iter   481/ 1097] train: loss: 0.1153359
[Epoch 8; Iter   511/ 1097] train: loss: 0.1691926
[Epoch 8; Iter   541/ 1097] train: loss: 0.0316230
[Epoch 8; Iter   571/ 1097] train: loss: 0.4538340
[Epoch 8; Iter   601/ 1097] train: loss: 0.0941250
[Epoch 8; Iter   631/ 1097] train: loss: 0.0863100
[Epoch 8; Iter   661/ 1097] train: loss: 0.0380751
[Epoch 8; Iter   691/ 1097] train: loss: 0.1986822
[Epoch 8; Iter   721/ 1097] train: loss: 0.1055372
[Epoch 8; Iter   751/ 1097] train: loss: 0.0305277
[Epoch 8; Iter   781/ 1097] train: loss: 0.1940450
[Epoch 8; Iter   811/ 1097] train: loss: 0.1152578
[Epoch 8; Iter   841/ 1097] train: loss: 0.0381697
[Epoch 8; Iter   871/ 1097] train: loss: 0.1326908
[Epoch 8; Iter   901/ 1097] train: loss: 0.0330901
[Epoch 8; Iter   931/ 1097] train: loss: 0.0659856
[Epoch 8; Iter   961/ 1097] train: loss: 0.0604334
[Epoch 8; Iter   991/ 1097] train: loss: 0.0395796
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0356155
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0222976
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1488535
[Epoch 8] ogbg-molhiv: 0.778886 val loss: 0.168022
[Epoch 8] ogbg-molhiv: 0.676771 test loss: 0.175462
[Epoch 9; Iter    14/ 1097] train: loss: 0.0319797
[Epoch 9; Iter    44/ 1097] train: loss: 0.0371451
[Epoch 9; Iter    74/ 1097] train: loss: 0.2170242
[Epoch 9; Iter   104/ 1097] train: loss: 0.3874847
[Epoch 9; Iter   134/ 1097] train: loss: 0.2347776
[Epoch 9; Iter   164/ 1097] train: loss: 0.0476376
[Epoch 9; Iter   194/ 1097] train: loss: 0.0460643
[Epoch 9; Iter   224/ 1097] train: loss: 0.0297165
[Epoch 9; Iter   254/ 1097] train: loss: 0.1337603
[Epoch 9; Iter   284/ 1097] train: loss: 0.0580115
[Epoch 9; Iter   314/ 1097] train: loss: 0.0433185
[Epoch 9; Iter   344/ 1097] train: loss: 0.0377694
[Epoch 9; Iter   374/ 1097] train: loss: 0.0407960
[Epoch 9; Iter   404/ 1097] train: loss: 0.1151314
[Epoch 9; Iter   434/ 1097] train: loss: 0.1371433
[Epoch 9; Iter   464/ 1097] train: loss: 0.1898802
[Epoch 9; Iter   494/ 1097] train: loss: 0.1273152
[Epoch 9; Iter   524/ 1097] train: loss: 0.0722692
[Epoch 9; Iter   554/ 1097] train: loss: 0.0388789
[Epoch 9; Iter   584/ 1097] train: loss: 0.2474138
[Epoch 9; Iter   614/ 1097] train: loss: 0.0462067
[Epoch 9; Iter   644/ 1097] train: loss: 0.1945076
[Epoch 9; Iter   674/ 1097] train: loss: 0.0525945
[Epoch 9; Iter   704/ 1097] train: loss: 0.0243896
[Epoch 9; Iter   734/ 1097] train: loss: 0.1641366
[Epoch 9; Iter   764/ 1097] train: loss: 0.0782866
[Epoch 9; Iter   794/ 1097] train: loss: 0.0801369
[Epoch 9; Iter   824/ 1097] train: loss: 0.0359836
[Epoch 9; Iter   854/ 1097] train: loss: 0.0407585
[Epoch 9; Iter   884/ 1097] train: loss: 0.2823227
[Epoch 9; Iter   914/ 1097] train: loss: 0.0334373
[Epoch 9; Iter   944/ 1097] train: loss: 0.1613971
[Epoch 9; Iter   974/ 1097] train: loss: 0.0409210
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1704144
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0760365
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0621264
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0419382
[Epoch 9] ogbg-molhiv: 0.668182 val loss: 0.148765
[Epoch 9] ogbg-molhiv: 0.616665 test loss: 0.152853
[Epoch 10; Iter    27/ 1097] train: loss: 0.1436508
[Epoch 10; Iter    57/ 1097] train: loss: 0.0294673
[Epoch 10; Iter    87/ 1097] train: loss: 0.1968483
[Epoch 10; Iter   117/ 1097] train: loss: 0.0410422
[Epoch 10; Iter   147/ 1097] train: loss: 0.0275119
[Epoch 10; Iter   177/ 1097] train: loss: 0.0267349
[Epoch 10; Iter   207/ 1097] train: loss: 0.0350212
[Epoch 10; Iter   237/ 1097] train: loss: 0.0252101
[Epoch 10; Iter   267/ 1097] train: loss: 0.0292976
[Epoch 10; Iter   297/ 1097] train: loss: 0.0246603
[Epoch 10; Iter   327/ 1097] train: loss: 0.0252825
[Epoch 10; Iter   357/ 1097] train: loss: 0.1939260
[Epoch 10; Iter   387/ 1097] train: loss: 0.1711847
[Epoch 10; Iter   417/ 1097] train: loss: 0.0334097
[Epoch 10; Iter   447/ 1097] train: loss: 0.0571179
[Epoch 10; Iter   477/ 1097] train: loss: 0.0382716
[Epoch 10; Iter   507/ 1097] train: loss: 0.0748873
[Epoch 10; Iter   537/ 1097] train: loss: 0.0349582
[Epoch 10; Iter   567/ 1097] train: loss: 0.1423747
[Epoch 10; Iter   597/ 1097] train: loss: 0.1772885
[Epoch 10; Iter   627/ 1097] train: loss: 0.1992941
[Epoch 10; Iter   657/ 1097] train: loss: 0.0270597
[Epoch 10; Iter   687/ 1097] train: loss: 0.1942832
[Epoch 10; Iter   717/ 1097] train: loss: 0.0377894
[Epoch 10; Iter   747/ 1097] train: loss: 0.3594900
[Epoch 10; Iter   777/ 1097] train: loss: 0.1016928
[Epoch 10; Iter   807/ 1097] train: loss: 0.0913878
[Epoch 10; Iter   837/ 1097] train: loss: 0.0368435
[Epoch 10; Iter   867/ 1097] train: loss: 0.3549034
[Epoch 10; Iter   897/ 1097] train: loss: 0.1586191
[Epoch 10; Iter   927/ 1097] train: loss: 0.3099696
[Epoch 10; Iter   957/ 1097] train: loss: 0.2234711
[Epoch 10; Iter   987/ 1097] train: loss: 0.2672331
[Epoch 10; Iter  1017/ 1097] train: loss: 0.1172686
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1126870
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1756279
[Epoch 10] ogbg-molhiv: 0.768421 val loss: 0.223496
[Epoch 10] ogbg-molhiv: 0.715974 test loss: 0.143479
[Epoch 11; Iter    10/ 1097] train: loss: 0.0284509
[Epoch 11; Iter    40/ 1097] train: loss: 0.0269870
[Epoch 11; Iter    70/ 1097] train: loss: 0.0440646
[Epoch 11; Iter   100/ 1097] train: loss: 0.1386171
[Epoch 11; Iter   130/ 1097] train: loss: 0.0382115
[Epoch 11; Iter   160/ 1097] train: loss: 0.0545690
[Epoch 11; Iter   190/ 1097] train: loss: 0.1703511
[Epoch 11; Iter   220/ 1097] train: loss: 0.0929417
[Epoch 11; Iter   250/ 1097] train: loss: 0.1767710
[Epoch 11; Iter   280/ 1097] train: loss: 0.1665664
[Epoch 11; Iter   310/ 1097] train: loss: 0.0958580
[Epoch 11; Iter   340/ 1097] train: loss: 0.0357170
[Epoch 11; Iter   370/ 1097] train: loss: 0.3456350
[Epoch 11; Iter   400/ 1097] train: loss: 0.0939363
[Epoch 11; Iter   430/ 1097] train: loss: 0.1826654
[Epoch 11; Iter   460/ 1097] train: loss: 0.1746069
[Epoch 11; Iter   490/ 1097] train: loss: 0.1701471
[Epoch 11; Iter   520/ 1097] train: loss: 0.4098203
[Epoch 11; Iter   550/ 1097] train: loss: 0.1139195
[Epoch 11; Iter   580/ 1097] train: loss: 0.1171218
[Epoch 11; Iter   610/ 1097] train: loss: 0.0316705
[Epoch 11; Iter   640/ 1097] train: loss: 0.0243010
[Epoch 11; Iter   670/ 1097] train: loss: 0.0357842
[Epoch 11; Iter   700/ 1097] train: loss: 0.0342486
[Epoch 11; Iter   730/ 1097] train: loss: 0.1540156
[Epoch 11; Iter   760/ 1097] train: loss: 0.0378769
[Epoch 11; Iter   790/ 1097] train: loss: 0.0639250
[Epoch 11; Iter   820/ 1097] train: loss: 0.2684819
[Epoch 11; Iter   850/ 1097] train: loss: 0.2112578
[Epoch 11; Iter   880/ 1097] train: loss: 0.0233309
[Epoch 11; Iter   910/ 1097] train: loss: 0.2569671
[Epoch 11; Iter   940/ 1097] train: loss: 0.3342364
[Epoch 11; Iter   970/ 1097] train: loss: 0.1600088
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1652649
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0839532
[Epoch 11; Iter  1060/ 1097] train: loss: 0.3038779
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3432481
[Epoch 11] ogbg-molhiv: 0.783161 val loss: 0.654473
[Epoch 11] ogbg-molhiv: 0.676738 test loss: 0.136999
[Epoch 12; Iter    23/ 1097] train: loss: 0.0716050
[Epoch 12; Iter    53/ 1097] train: loss: 0.0418398
[Epoch 12; Iter    83/ 1097] train: loss: 0.0347641
[Epoch 8; Iter     1/ 1097] train: loss: 0.1728199
[Epoch 8; Iter    31/ 1097] train: loss: 0.0315900
[Epoch 8; Iter    61/ 1097] train: loss: 0.1755485
[Epoch 8; Iter    91/ 1097] train: loss: 0.1680007
[Epoch 8; Iter   121/ 1097] train: loss: 0.0344351
[Epoch 8; Iter   151/ 1097] train: loss: 0.1610552
[Epoch 8; Iter   181/ 1097] train: loss: 0.0297133
[Epoch 8; Iter   211/ 1097] train: loss: 0.3058045
[Epoch 8; Iter   241/ 1097] train: loss: 0.1575775
[Epoch 8; Iter   271/ 1097] train: loss: 0.2612197
[Epoch 8; Iter   301/ 1097] train: loss: 0.0756253
[Epoch 8; Iter   331/ 1097] train: loss: 0.1340169
[Epoch 8; Iter   361/ 1097] train: loss: 0.0418062
[Epoch 8; Iter   391/ 1097] train: loss: 0.0291962
[Epoch 8; Iter   421/ 1097] train: loss: 0.2816144
[Epoch 8; Iter   451/ 1097] train: loss: 0.0299460
[Epoch 8; Iter   481/ 1097] train: loss: 0.2013363
[Epoch 8; Iter   511/ 1097] train: loss: 0.1165354
[Epoch 8; Iter   541/ 1097] train: loss: 0.0320116
[Epoch 8; Iter   571/ 1097] train: loss: 0.0291145
[Epoch 8; Iter   601/ 1097] train: loss: 0.0329911
[Epoch 8; Iter   631/ 1097] train: loss: 0.0977280
[Epoch 8; Iter   661/ 1097] train: loss: 0.0459887
[Epoch 8; Iter   691/ 1097] train: loss: 0.3438326
[Epoch 8; Iter   721/ 1097] train: loss: 0.0364613
[Epoch 8; Iter   751/ 1097] train: loss: 0.1368756
[Epoch 8; Iter   781/ 1097] train: loss: 0.0554911
[Epoch 8; Iter   811/ 1097] train: loss: 0.0672474
[Epoch 8; Iter   841/ 1097] train: loss: 0.1556629
[Epoch 8; Iter   871/ 1097] train: loss: 0.2550051
[Epoch 8; Iter   901/ 1097] train: loss: 0.0587577
[Epoch 8; Iter   931/ 1097] train: loss: 0.0541986
[Epoch 8; Iter   961/ 1097] train: loss: 0.0257369
[Epoch 8; Iter   991/ 1097] train: loss: 0.0432599
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0439812
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0321076
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3359014
[Epoch 8] ogbg-molhiv: 0.745141 val loss: 0.084398
[Epoch 8] ogbg-molhiv: 0.672195 test loss: 0.127509
[Epoch 9; Iter    14/ 1097] train: loss: 0.0304602
[Epoch 9; Iter    44/ 1097] train: loss: 0.0399183
[Epoch 9; Iter    74/ 1097] train: loss: 0.0580248
[Epoch 9; Iter   104/ 1097] train: loss: 0.0258671
[Epoch 9; Iter   134/ 1097] train: loss: 0.0661046
[Epoch 9; Iter   164/ 1097] train: loss: 0.0424553
[Epoch 9; Iter   194/ 1097] train: loss: 0.0431026
[Epoch 9; Iter   224/ 1097] train: loss: 0.3039019
[Epoch 9; Iter   254/ 1097] train: loss: 0.0833203
[Epoch 9; Iter   284/ 1097] train: loss: 0.1824763
[Epoch 9; Iter   314/ 1097] train: loss: 0.2591160
[Epoch 9; Iter   344/ 1097] train: loss: 0.0350299
[Epoch 9; Iter   374/ 1097] train: loss: 0.1815350
[Epoch 9; Iter   404/ 1097] train: loss: 0.1662759
[Epoch 9; Iter   434/ 1097] train: loss: 0.1178309
[Epoch 9; Iter   464/ 1097] train: loss: 0.0295404
[Epoch 9; Iter   494/ 1097] train: loss: 0.1718626
[Epoch 9; Iter   524/ 1097] train: loss: 0.0268800
[Epoch 9; Iter   554/ 1097] train: loss: 0.0764622
[Epoch 9; Iter   584/ 1097] train: loss: 0.1412839
[Epoch 9; Iter   614/ 1097] train: loss: 0.0378269
[Epoch 9; Iter   644/ 1097] train: loss: 0.2049976
[Epoch 9; Iter   674/ 1097] train: loss: 0.2207750
[Epoch 9; Iter   704/ 1097] train: loss: 0.0378140
[Epoch 9; Iter   734/ 1097] train: loss: 0.0365686
[Epoch 9; Iter   764/ 1097] train: loss: 0.1402805
[Epoch 9; Iter   794/ 1097] train: loss: 0.0337235
[Epoch 9; Iter   824/ 1097] train: loss: 0.0293622
[Epoch 9; Iter   854/ 1097] train: loss: 0.0281811
[Epoch 9; Iter   884/ 1097] train: loss: 0.2395000
[Epoch 9; Iter   914/ 1097] train: loss: 0.0355193
[Epoch 9; Iter   944/ 1097] train: loss: 0.1764511
[Epoch 9; Iter   974/ 1097] train: loss: 0.0321693
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0253470
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0306486
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3106149
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0380917
[Epoch 9] ogbg-molhiv: 0.776198 val loss: 0.087288
[Epoch 9] ogbg-molhiv: 0.707169 test loss: 0.126099
[Epoch 10; Iter    27/ 1097] train: loss: 0.1970612
[Epoch 10; Iter    57/ 1097] train: loss: 0.3350683
[Epoch 10; Iter    87/ 1097] train: loss: 0.0360953
[Epoch 10; Iter   117/ 1097] train: loss: 0.1384641
[Epoch 10; Iter   147/ 1097] train: loss: 0.0513853
[Epoch 10; Iter   177/ 1097] train: loss: 0.4132558
[Epoch 10; Iter   207/ 1097] train: loss: 0.0766574
[Epoch 10; Iter   237/ 1097] train: loss: 0.0309034
[Epoch 10; Iter   267/ 1097] train: loss: 0.0777391
[Epoch 10; Iter   297/ 1097] train: loss: 0.2369404
[Epoch 10; Iter   327/ 1097] train: loss: 0.2599929
[Epoch 10; Iter   357/ 1097] train: loss: 0.0491851
[Epoch 10; Iter   387/ 1097] train: loss: 0.1065528
[Epoch 10; Iter   417/ 1097] train: loss: 0.2506793
[Epoch 10; Iter   447/ 1097] train: loss: 0.1478887
[Epoch 10; Iter   477/ 1097] train: loss: 0.0430851
[Epoch 10; Iter   507/ 1097] train: loss: 0.0342709
[Epoch 10; Iter   537/ 1097] train: loss: 0.1193876
[Epoch 10; Iter   567/ 1097] train: loss: 0.2290439
[Epoch 10; Iter   597/ 1097] train: loss: 0.1451640
[Epoch 10; Iter   627/ 1097] train: loss: 0.0930099
[Epoch 10; Iter   657/ 1097] train: loss: 0.3041534
[Epoch 10; Iter   687/ 1097] train: loss: 0.1053917
[Epoch 10; Iter   717/ 1097] train: loss: 0.3048241
[Epoch 10; Iter   747/ 1097] train: loss: 0.0402555
[Epoch 10; Iter   777/ 1097] train: loss: 0.0274352
[Epoch 10; Iter   807/ 1097] train: loss: 0.3180653
[Epoch 10; Iter   837/ 1097] train: loss: 0.0374663
[Epoch 10; Iter   867/ 1097] train: loss: 0.0516348
[Epoch 10; Iter   897/ 1097] train: loss: 0.0293728
[Epoch 10; Iter   927/ 1097] train: loss: 0.2192849
[Epoch 10; Iter   957/ 1097] train: loss: 0.1316608
[Epoch 10; Iter   987/ 1097] train: loss: 0.4908600
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0283423
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0571277
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2170980
[Epoch 10] ogbg-molhiv: 0.762205 val loss: 0.100132
[Epoch 10] ogbg-molhiv: 0.678893 test loss: 0.136870
[Epoch 11; Iter    10/ 1097] train: loss: 0.3467194
[Epoch 11; Iter    40/ 1097] train: loss: 0.1296946
[Epoch 11; Iter    70/ 1097] train: loss: 0.1309109
[Epoch 11; Iter   100/ 1097] train: loss: 0.0997818
[Epoch 11; Iter   130/ 1097] train: loss: 0.3734718
[Epoch 11; Iter   160/ 1097] train: loss: 0.1114045
[Epoch 11; Iter   190/ 1097] train: loss: 0.0315945
[Epoch 11; Iter   220/ 1097] train: loss: 0.1609574
[Epoch 11; Iter   250/ 1097] train: loss: 0.0950733
[Epoch 11; Iter   280/ 1097] train: loss: 0.2203904
[Epoch 11; Iter   310/ 1097] train: loss: 0.1374251
[Epoch 11; Iter   340/ 1097] train: loss: 0.0509677
[Epoch 11; Iter   370/ 1097] train: loss: 0.0258863
[Epoch 11; Iter   400/ 1097] train: loss: 0.2514074
[Epoch 11; Iter   430/ 1097] train: loss: 0.0250963
[Epoch 11; Iter   460/ 1097] train: loss: 0.1477395
[Epoch 11; Iter   490/ 1097] train: loss: 0.2119517
[Epoch 11; Iter   520/ 1097] train: loss: 0.1400340
[Epoch 11; Iter   550/ 1097] train: loss: 0.0247777
[Epoch 11; Iter   580/ 1097] train: loss: 0.4202435
[Epoch 11; Iter   610/ 1097] train: loss: 0.1331618
[Epoch 11; Iter   640/ 1097] train: loss: 0.1130195
[Epoch 11; Iter   670/ 1097] train: loss: 0.0279306
[Epoch 11; Iter   700/ 1097] train: loss: 0.1126505
[Epoch 11; Iter   730/ 1097] train: loss: 0.1685743
[Epoch 11; Iter   760/ 1097] train: loss: 0.1556102
[Epoch 11; Iter   790/ 1097] train: loss: 0.0821887
[Epoch 11; Iter   820/ 1097] train: loss: 0.0730612
[Epoch 11; Iter   850/ 1097] train: loss: 0.1856695
[Epoch 11; Iter   880/ 1097] train: loss: 0.0296349
[Epoch 11; Iter   910/ 1097] train: loss: 0.0474883
[Epoch 11; Iter   940/ 1097] train: loss: 0.0815938
[Epoch 11; Iter   970/ 1097] train: loss: 0.0319804
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0539544
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1414842
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2178220
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0321647
[Epoch 11] ogbg-molhiv: 0.745401 val loss: 0.088211
[Epoch 11] ogbg-molhiv: 0.695784 test loss: 0.126146
[Epoch 12; Iter    23/ 1097] train: loss: 0.1852472
[Epoch 12; Iter    53/ 1097] train: loss: 0.0358209
[Epoch 12; Iter    83/ 1097] train: loss: 0.0814033
[Epoch 8; Iter     1/ 1097] train: loss: 0.2199414
[Epoch 8; Iter    31/ 1097] train: loss: 0.0415757
[Epoch 8; Iter    61/ 1097] train: loss: 0.0870053
[Epoch 8; Iter    91/ 1097] train: loss: 0.1354131
[Epoch 8; Iter   121/ 1097] train: loss: 0.1151198
[Epoch 8; Iter   151/ 1097] train: loss: 0.0340660
[Epoch 8; Iter   181/ 1097] train: loss: 0.0502234
[Epoch 8; Iter   211/ 1097] train: loss: 0.0605189
[Epoch 8; Iter   241/ 1097] train: loss: 0.0376711
[Epoch 8; Iter   271/ 1097] train: loss: 0.2038349
[Epoch 8; Iter   301/ 1097] train: loss: 0.2473613
[Epoch 8; Iter   331/ 1097] train: loss: 0.0842873
[Epoch 8; Iter   361/ 1097] train: loss: 0.1295280
[Epoch 8; Iter   391/ 1097] train: loss: 0.0255743
[Epoch 8; Iter   421/ 1097] train: loss: 0.2919911
[Epoch 8; Iter   451/ 1097] train: loss: 0.3165987
[Epoch 8; Iter   481/ 1097] train: loss: 0.0456154
[Epoch 8; Iter   511/ 1097] train: loss: 0.1274848
[Epoch 8; Iter   541/ 1097] train: loss: 0.1776192
[Epoch 8; Iter   571/ 1097] train: loss: 0.1379372
[Epoch 8; Iter   601/ 1097] train: loss: 0.3521233
[Epoch 8; Iter   631/ 1097] train: loss: 0.0335765
[Epoch 8; Iter   661/ 1097] train: loss: 0.2568301
[Epoch 8; Iter   691/ 1097] train: loss: 0.0918433
[Epoch 8; Iter   721/ 1097] train: loss: 0.0648077
[Epoch 8; Iter   751/ 1097] train: loss: 0.1391766
[Epoch 8; Iter   781/ 1097] train: loss: 0.1720593
[Epoch 8; Iter   811/ 1097] train: loss: 0.2251786
[Epoch 8; Iter   841/ 1097] train: loss: 0.3755791
[Epoch 8; Iter   871/ 1097] train: loss: 0.1928829
[Epoch 8; Iter   901/ 1097] train: loss: 0.0331235
[Epoch 8; Iter   931/ 1097] train: loss: 0.1744835
[Epoch 8; Iter   961/ 1097] train: loss: 0.0452708
[Epoch 8; Iter   991/ 1097] train: loss: 0.1290329
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2865983
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0304164
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1007932
[Epoch 8] ogbg-molhiv: 0.697090 val loss: 0.778771
[Epoch 8] ogbg-molhiv: 0.661718 test loss: 0.668699
[Epoch 9; Iter    14/ 1097] train: loss: 0.2583400
[Epoch 9; Iter    44/ 1097] train: loss: 0.0323905
[Epoch 9; Iter    74/ 1097] train: loss: 0.0287118
[Epoch 9; Iter   104/ 1097] train: loss: 0.2479589
[Epoch 9; Iter   134/ 1097] train: loss: 0.0963074
[Epoch 9; Iter   164/ 1097] train: loss: 0.1443638
[Epoch 9; Iter   194/ 1097] train: loss: 0.0696601
[Epoch 9; Iter   224/ 1097] train: loss: 0.0364424
[Epoch 9; Iter   254/ 1097] train: loss: 0.3312468
[Epoch 9; Iter   284/ 1097] train: loss: 0.2008513
[Epoch 9; Iter   314/ 1097] train: loss: 0.1019831
[Epoch 9; Iter   344/ 1097] train: loss: 0.4479470
[Epoch 9; Iter   374/ 1097] train: loss: 0.1746782
[Epoch 9; Iter   404/ 1097] train: loss: 0.1571946
[Epoch 9; Iter   434/ 1097] train: loss: 0.0806427
[Epoch 9; Iter   464/ 1097] train: loss: 0.0390307
[Epoch 9; Iter   494/ 1097] train: loss: 0.1370909
[Epoch 9; Iter   524/ 1097] train: loss: 0.0318435
[Epoch 9; Iter   554/ 1097] train: loss: 0.0369634
[Epoch 9; Iter   584/ 1097] train: loss: 0.5313562
[Epoch 9; Iter   614/ 1097] train: loss: 0.1379613
[Epoch 9; Iter   644/ 1097] train: loss: 0.2673620
[Epoch 9; Iter   674/ 1097] train: loss: 0.4704604
[Epoch 9; Iter   704/ 1097] train: loss: 0.1416555
[Epoch 9; Iter   734/ 1097] train: loss: 0.0842399
[Epoch 9; Iter   764/ 1097] train: loss: 0.2158612
[Epoch 9; Iter   794/ 1097] train: loss: 0.1610610
[Epoch 9; Iter   824/ 1097] train: loss: 0.0389841
[Epoch 9; Iter   854/ 1097] train: loss: 0.0229280
[Epoch 9; Iter   884/ 1097] train: loss: 0.1222623
[Epoch 9; Iter   914/ 1097] train: loss: 0.1762887
[Epoch 9; Iter   944/ 1097] train: loss: 0.0440198
[Epoch 9; Iter   974/ 1097] train: loss: 0.1380025
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2454324
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2559655
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3172745
[Epoch 9; Iter  1094/ 1097] train: loss: 0.3040478
[Epoch 9] ogbg-molhiv: 0.748460 val loss: 0.553493
[Epoch 9] ogbg-molhiv: 0.666009 test loss: 0.218848
[Epoch 10; Iter    27/ 1097] train: loss: 0.0294519
[Epoch 10; Iter    57/ 1097] train: loss: 0.0329486
[Epoch 10; Iter    87/ 1097] train: loss: 0.1620478
[Epoch 10; Iter   117/ 1097] train: loss: 0.0696612
[Epoch 10; Iter   147/ 1097] train: loss: 0.3713928
[Epoch 10; Iter   177/ 1097] train: loss: 0.2630896
[Epoch 10; Iter   207/ 1097] train: loss: 0.2561781
[Epoch 10; Iter   237/ 1097] train: loss: 0.0379085
[Epoch 10; Iter   267/ 1097] train: loss: 0.0393736
[Epoch 10; Iter   297/ 1097] train: loss: 0.1740465
[Epoch 10; Iter   327/ 1097] train: loss: 0.0278929
[Epoch 10; Iter   357/ 1097] train: loss: 0.2133373
[Epoch 10; Iter   387/ 1097] train: loss: 0.1535085
[Epoch 10; Iter   417/ 1097] train: loss: 0.1579355
[Epoch 10; Iter   447/ 1097] train: loss: 0.1702306
[Epoch 10; Iter   477/ 1097] train: loss: 0.1452212
[Epoch 10; Iter   507/ 1097] train: loss: 0.1094710
[Epoch 10; Iter   537/ 1097] train: loss: 0.0303914
[Epoch 10; Iter   567/ 1097] train: loss: 0.0259748
[Epoch 10; Iter   597/ 1097] train: loss: 0.0246370
[Epoch 10; Iter   627/ 1097] train: loss: 0.1705341
[Epoch 10; Iter   657/ 1097] train: loss: 0.1793762
[Epoch 10; Iter   687/ 1097] train: loss: 0.1359818
[Epoch 10; Iter   717/ 1097] train: loss: 0.2052934
[Epoch 10; Iter   747/ 1097] train: loss: 0.1967948
[Epoch 10; Iter   777/ 1097] train: loss: 0.1569573
[Epoch 10; Iter   807/ 1097] train: loss: 0.0379049
[Epoch 10; Iter   837/ 1097] train: loss: 0.0345129
[Epoch 10; Iter   867/ 1097] train: loss: 0.1099779
[Epoch 10; Iter   897/ 1097] train: loss: 0.0374451
[Epoch 10; Iter   927/ 1097] train: loss: 0.1806505
[Epoch 10; Iter   957/ 1097] train: loss: 0.0513547
[Epoch 10; Iter   987/ 1097] train: loss: 0.2551206
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2553470
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1935686
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0312640
[Epoch 10] ogbg-molhiv: 0.731815 val loss: 2.269624
[Epoch 10] ogbg-molhiv: 0.706601 test loss: 1.922335
[Epoch 11; Iter    10/ 1097] train: loss: 0.2664647
[Epoch 11; Iter    40/ 1097] train: loss: 0.0608126
[Epoch 11; Iter    70/ 1097] train: loss: 0.1348918
[Epoch 11; Iter   100/ 1097] train: loss: 0.0247087
[Epoch 11; Iter   130/ 1097] train: loss: 0.1513356
[Epoch 11; Iter   160/ 1097] train: loss: 0.0361371
[Epoch 11; Iter   190/ 1097] train: loss: 0.2980752
[Epoch 11; Iter   220/ 1097] train: loss: 0.3120586
[Epoch 11; Iter   250/ 1097] train: loss: 0.2824020
[Epoch 11; Iter   280/ 1097] train: loss: 0.0497115
[Epoch 11; Iter   310/ 1097] train: loss: 0.2457714
[Epoch 11; Iter   340/ 1097] train: loss: 0.0406963
[Epoch 11; Iter   370/ 1097] train: loss: 0.1588529
[Epoch 11; Iter   400/ 1097] train: loss: 0.0306812
[Epoch 11; Iter   430/ 1097] train: loss: 0.2735957
[Epoch 11; Iter   460/ 1097] train: loss: 0.1298468
[Epoch 11; Iter   490/ 1097] train: loss: 0.3001621
[Epoch 11; Iter   520/ 1097] train: loss: 0.1943054
[Epoch 11; Iter   550/ 1097] train: loss: 0.0358228
[Epoch 11; Iter   580/ 1097] train: loss: 0.0740239
[Epoch 11; Iter   610/ 1097] train: loss: 0.0348344
[Epoch 11; Iter   640/ 1097] train: loss: 0.0482033
[Epoch 11; Iter   670/ 1097] train: loss: 0.1813551
[Epoch 11; Iter   700/ 1097] train: loss: 0.1459227
[Epoch 11; Iter   730/ 1097] train: loss: 0.0485809
[Epoch 11; Iter   760/ 1097] train: loss: 0.1823619
[Epoch 11; Iter   790/ 1097] train: loss: 0.1978875
[Epoch 11; Iter   820/ 1097] train: loss: 0.0708871
[Epoch 11; Iter   850/ 1097] train: loss: 0.0470271
[Epoch 11; Iter   880/ 1097] train: loss: 0.2662964
[Epoch 11; Iter   910/ 1097] train: loss: 0.2463741
[Epoch 11; Iter   940/ 1097] train: loss: 0.2993546
[Epoch 11; Iter   970/ 1097] train: loss: 0.2171760
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0506687
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0275874
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2257947
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4099365
[Epoch 11] ogbg-molhiv: 0.766381 val loss: 0.108520
[Epoch 11] ogbg-molhiv: 0.702493 test loss: 0.138951
[Epoch 12; Iter    23/ 1097] train: loss: 0.0531148
[Epoch 12; Iter    53/ 1097] train: loss: 0.0321663
[Epoch 12; Iter    83/ 1097] train: loss: 0.0355302
[Epoch 12; Iter   113/ 1097] train: loss: 0.1594750
[Epoch 12; Iter   143/ 1097] train: loss: 0.2084812
[Epoch 12; Iter   173/ 1097] train: loss: 0.0465169
[Epoch 12; Iter   203/ 1097] train: loss: 0.0284268
[Epoch 12; Iter   233/ 1097] train: loss: 0.0264327
[Epoch 12; Iter   263/ 1097] train: loss: 0.0818743
[Epoch 12; Iter   293/ 1097] train: loss: 0.1872337
[Epoch 12; Iter   323/ 1097] train: loss: 0.1103940
[Epoch 12; Iter   353/ 1097] train: loss: 0.2123251
[Epoch 12; Iter   383/ 1097] train: loss: 0.0491678
[Epoch 12; Iter   413/ 1097] train: loss: 0.2262352
[Epoch 12; Iter   443/ 1097] train: loss: 0.3069222
[Epoch 12; Iter   473/ 1097] train: loss: 0.1130872
[Epoch 12; Iter   503/ 1097] train: loss: 0.2097451
[Epoch 12; Iter   533/ 1097] train: loss: 0.1339742
[Epoch 12; Iter   563/ 1097] train: loss: 0.1193211
[Epoch 12; Iter   593/ 1097] train: loss: 0.3120738
[Epoch 12; Iter   623/ 1097] train: loss: 0.2442602
[Epoch 12; Iter   653/ 1097] train: loss: 0.0294225
[Epoch 12; Iter   683/ 1097] train: loss: 0.1918073
[Epoch 12; Iter   713/ 1097] train: loss: 0.0629105
[Epoch 12; Iter   743/ 1097] train: loss: 0.2002306
[Epoch 12; Iter   773/ 1097] train: loss: 0.0480744
[Epoch 12; Iter   803/ 1097] train: loss: 0.1638750
[Epoch 12; Iter   833/ 1097] train: loss: 0.1153855
[Epoch 12; Iter   863/ 1097] train: loss: 0.2683300
[Epoch 12; Iter   893/ 1097] train: loss: 0.0326890
[Epoch 12; Iter   923/ 1097] train: loss: 0.1662995
[Epoch 12; Iter   953/ 1097] train: loss: 0.2328745
[Epoch 12; Iter   983/ 1097] train: loss: 0.0541767
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0435597
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1282301
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0859438
[Epoch 12] ogbg-molhiv: 0.776446 val loss: 0.180450
[Epoch 12] ogbg-molhiv: 0.761000 test loss: 0.159439
[Epoch 13; Iter     6/ 1097] train: loss: 0.0607657
[Epoch 13; Iter    36/ 1097] train: loss: 0.2622051
[Epoch 13; Iter    66/ 1097] train: loss: 0.1616715
[Epoch 13; Iter    96/ 1097] train: loss: 0.0541924
[Epoch 13; Iter   126/ 1097] train: loss: 0.0246601
[Epoch 13; Iter   156/ 1097] train: loss: 0.0240053
[Epoch 13; Iter   186/ 1097] train: loss: 0.1547361
[Epoch 13; Iter   216/ 1097] train: loss: 0.2567126
[Epoch 13; Iter   246/ 1097] train: loss: 0.0232265
[Epoch 13; Iter   276/ 1097] train: loss: 0.0955623
[Epoch 13; Iter   306/ 1097] train: loss: 0.0206583
[Epoch 13; Iter   336/ 1097] train: loss: 0.1565973
[Epoch 13; Iter   366/ 1097] train: loss: 0.1000427
[Epoch 13; Iter   396/ 1097] train: loss: 0.0903412
[Epoch 13; Iter   426/ 1097] train: loss: 0.0481890
[Epoch 13; Iter   456/ 1097] train: loss: 0.0438387
[Epoch 13; Iter   486/ 1097] train: loss: 0.0380195
[Epoch 13; Iter   516/ 1097] train: loss: 0.0311094
[Epoch 13; Iter   546/ 1097] train: loss: 0.0347942
[Epoch 13; Iter   576/ 1097] train: loss: 0.1631823
[Epoch 13; Iter   606/ 1097] train: loss: 0.0625942
[Epoch 13; Iter   636/ 1097] train: loss: 0.2289898
[Epoch 13; Iter   666/ 1097] train: loss: 0.0244769
[Epoch 13; Iter   696/ 1097] train: loss: 0.0434459
[Epoch 13; Iter   726/ 1097] train: loss: 0.0841782
[Epoch 13; Iter   756/ 1097] train: loss: 0.0687264
[Epoch 13; Iter   786/ 1097] train: loss: 0.1479743
[Epoch 13; Iter   816/ 1097] train: loss: 0.0290326
[Epoch 13; Iter   846/ 1097] train: loss: 0.0208069
[Epoch 13; Iter   876/ 1097] train: loss: 0.1825717
[Epoch 13; Iter   906/ 1097] train: loss: 0.2183687
[Epoch 13; Iter   936/ 1097] train: loss: 0.2214710
[Epoch 13; Iter   966/ 1097] train: loss: 0.1132617
[Epoch 13; Iter   996/ 1097] train: loss: 0.0655394
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3934215
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1635953
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1647495
[Epoch 13] ogbg-molhiv: 0.798651 val loss: 0.427514
[Epoch 13] ogbg-molhiv: 0.768317 test loss: 0.219948
[Epoch 14; Iter    19/ 1097] train: loss: 0.0310872
[Epoch 14; Iter    49/ 1097] train: loss: 0.3053547
[Epoch 14; Iter    79/ 1097] train: loss: 0.0253206
[Epoch 14; Iter   109/ 1097] train: loss: 0.0293928
[Epoch 14; Iter   139/ 1097] train: loss: 0.0473797
[Epoch 14; Iter   169/ 1097] train: loss: 0.1595384
[Epoch 14; Iter   199/ 1097] train: loss: 0.1131948
[Epoch 14; Iter   229/ 1097] train: loss: 0.0215184
[Epoch 14; Iter   259/ 1097] train: loss: 0.0911949
[Epoch 14; Iter   289/ 1097] train: loss: 0.1154762
[Epoch 14; Iter   319/ 1097] train: loss: 0.2777298
[Epoch 14; Iter   349/ 1097] train: loss: 0.2069708
[Epoch 14; Iter   379/ 1097] train: loss: 0.1824195
[Epoch 14; Iter   409/ 1097] train: loss: 0.0715396
[Epoch 14; Iter   439/ 1097] train: loss: 0.1570803
[Epoch 14; Iter   469/ 1097] train: loss: 0.1457103
[Epoch 14; Iter   499/ 1097] train: loss: 0.0328306
[Epoch 14; Iter   529/ 1097] train: loss: 0.0278972
[Epoch 14; Iter   559/ 1097] train: loss: 0.1847831
[Epoch 14; Iter   589/ 1097] train: loss: 0.0228198
[Epoch 14; Iter   619/ 1097] train: loss: 0.0518150
[Epoch 14; Iter   649/ 1097] train: loss: 0.0316595
[Epoch 14; Iter   679/ 1097] train: loss: 0.1163970
[Epoch 14; Iter   709/ 1097] train: loss: 0.1638998
[Epoch 14; Iter   739/ 1097] train: loss: 0.0401574
[Epoch 14; Iter   769/ 1097] train: loss: 0.1373926
[Epoch 14; Iter   799/ 1097] train: loss: 0.0397227
[Epoch 14; Iter   829/ 1097] train: loss: 0.1124819
[Epoch 14; Iter   859/ 1097] train: loss: 0.0296358
[Epoch 14; Iter   889/ 1097] train: loss: 0.0358000
[Epoch 14; Iter   919/ 1097] train: loss: 0.0693568
[Epoch 14; Iter   949/ 1097] train: loss: 0.0329625
[Epoch 14; Iter   979/ 1097] train: loss: 0.1439500
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0176315
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0507924
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1129636
[Epoch 14] ogbg-molhiv: 0.737994 val loss: 0.081207
[Epoch 14] ogbg-molhiv: 0.710097 test loss: 0.131090
[Epoch 15; Iter     2/ 1097] train: loss: 0.2217816
[Epoch 15; Iter    32/ 1097] train: loss: 0.0364281
[Epoch 15; Iter    62/ 1097] train: loss: 0.1111796
[Epoch 15; Iter    92/ 1097] train: loss: 0.0343777
[Epoch 15; Iter   122/ 1097] train: loss: 0.2487049
[Epoch 15; Iter   152/ 1097] train: loss: 0.2166549
[Epoch 15; Iter   182/ 1097] train: loss: 0.2205918
[Epoch 15; Iter   212/ 1097] train: loss: 0.0272352
[Epoch 15; Iter   242/ 1097] train: loss: 0.0305506
[Epoch 15; Iter   272/ 1097] train: loss: 0.1928152
[Epoch 15; Iter   302/ 1097] train: loss: 0.1810414
[Epoch 15; Iter   332/ 1097] train: loss: 0.0438678
[Epoch 15; Iter   362/ 1097] train: loss: 0.1516408
[Epoch 15; Iter   392/ 1097] train: loss: 0.1494500
[Epoch 15; Iter   422/ 1097] train: loss: 0.2052148
[Epoch 15; Iter   452/ 1097] train: loss: 0.0624965
[Epoch 15; Iter   482/ 1097] train: loss: 0.0709406
[Epoch 15; Iter   512/ 1097] train: loss: 0.2549663
[Epoch 15; Iter   542/ 1097] train: loss: 0.0838428
[Epoch 15; Iter   572/ 1097] train: loss: 0.0302022
[Epoch 15; Iter   602/ 1097] train: loss: 0.3716102
[Epoch 15; Iter   632/ 1097] train: loss: 0.0280015
[Epoch 15; Iter   662/ 1097] train: loss: 0.2099345
[Epoch 15; Iter   692/ 1097] train: loss: 0.0288151
[Epoch 15; Iter   722/ 1097] train: loss: 0.0724255
[Epoch 15; Iter   752/ 1097] train: loss: 0.1591962
[Epoch 15; Iter   782/ 1097] train: loss: 0.1905330
[Epoch 15; Iter   812/ 1097] train: loss: 0.0596860
[Epoch 15; Iter   842/ 1097] train: loss: 0.0383633
[Epoch 15; Iter   872/ 1097] train: loss: 0.0194571
[Epoch 15; Iter   902/ 1097] train: loss: 0.2200923
[Epoch 15; Iter   932/ 1097] train: loss: 0.0784366
[Epoch 15; Iter   962/ 1097] train: loss: 0.0373842
[Epoch 15; Iter   992/ 1097] train: loss: 0.0560431
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0180624
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1597539
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0239548
[Epoch 15] ogbg-molhiv: 0.755769 val loss: 0.144779
[Epoch 15] ogbg-molhiv: 0.734865 test loss: 0.124482
[Epoch 16; Iter    15/ 1097] train: loss: 0.0941264
[Epoch 16; Iter    45/ 1097] train: loss: 0.0241158
[Epoch 16; Iter    75/ 1097] train: loss: 0.0176221
[Epoch 16; Iter   105/ 1097] train: loss: 0.0229881
[Epoch 16; Iter   135/ 1097] train: loss: 0.0301589
[Epoch 16; Iter   165/ 1097] train: loss: 0.3152574
[Epoch 12; Iter   113/ 1097] train: loss: 0.0697966
[Epoch 12; Iter   143/ 1097] train: loss: 0.1893246
[Epoch 12; Iter   173/ 1097] train: loss: 0.0269324
[Epoch 12; Iter   203/ 1097] train: loss: 0.1026488
[Epoch 12; Iter   233/ 1097] train: loss: 0.0208388
[Epoch 12; Iter   263/ 1097] train: loss: 0.0364198
[Epoch 12; Iter   293/ 1097] train: loss: 0.2024160
[Epoch 12; Iter   323/ 1097] train: loss: 0.1907149
[Epoch 12; Iter   353/ 1097] train: loss: 0.0603156
[Epoch 12; Iter   383/ 1097] train: loss: 0.0330147
[Epoch 12; Iter   413/ 1097] train: loss: 0.0291521
[Epoch 12; Iter   443/ 1097] train: loss: 0.0270228
[Epoch 12; Iter   473/ 1097] train: loss: 0.2287320
[Epoch 12; Iter   503/ 1097] train: loss: 0.1789691
[Epoch 12; Iter   533/ 1097] train: loss: 0.0283773
[Epoch 12; Iter   563/ 1097] train: loss: 0.0546055
[Epoch 12; Iter   593/ 1097] train: loss: 0.2053545
[Epoch 12; Iter   623/ 1097] train: loss: 0.0354322
[Epoch 12; Iter   653/ 1097] train: loss: 0.0856076
[Epoch 12; Iter   683/ 1097] train: loss: 0.2802557
[Epoch 12; Iter   713/ 1097] train: loss: 0.1327690
[Epoch 12; Iter   743/ 1097] train: loss: 0.0342834
[Epoch 12; Iter   773/ 1097] train: loss: 0.1702721
[Epoch 12; Iter   803/ 1097] train: loss: 0.1677788
[Epoch 12; Iter   833/ 1097] train: loss: 0.0857904
[Epoch 12; Iter   863/ 1097] train: loss: 0.0515539
[Epoch 12; Iter   893/ 1097] train: loss: 0.1703474
[Epoch 12; Iter   923/ 1097] train: loss: 0.0318148
[Epoch 12; Iter   953/ 1097] train: loss: 0.2531779
[Epoch 12; Iter   983/ 1097] train: loss: 0.2700695
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0267673
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0305184
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0349921
[Epoch 12] ogbg-molhiv: 0.803216 val loss: 0.159729
[Epoch 12] ogbg-molhiv: 0.744684 test loss: 0.128838
[Epoch 13; Iter     6/ 1097] train: loss: 0.1583008
[Epoch 13; Iter    36/ 1097] train: loss: 0.1264379
[Epoch 13; Iter    66/ 1097] train: loss: 0.1474558
[Epoch 13; Iter    96/ 1097] train: loss: 0.0173064
[Epoch 13; Iter   126/ 1097] train: loss: 0.0491824
[Epoch 13; Iter   156/ 1097] train: loss: 0.2150961
[Epoch 13; Iter   186/ 1097] train: loss: 0.2640545
[Epoch 13; Iter   216/ 1097] train: loss: 0.2026233
[Epoch 13; Iter   246/ 1097] train: loss: 0.0358883
[Epoch 13; Iter   276/ 1097] train: loss: 0.0311765
[Epoch 13; Iter   306/ 1097] train: loss: 0.3363660
[Epoch 13; Iter   336/ 1097] train: loss: 0.1690856
[Epoch 13; Iter   366/ 1097] train: loss: 0.4613255
[Epoch 13; Iter   396/ 1097] train: loss: 0.0777727
[Epoch 13; Iter   426/ 1097] train: loss: 0.0757019
[Epoch 13; Iter   456/ 1097] train: loss: 0.1701506
[Epoch 13; Iter   486/ 1097] train: loss: 0.0296013
[Epoch 13; Iter   516/ 1097] train: loss: 0.1440994
[Epoch 13; Iter   546/ 1097] train: loss: 0.0253294
[Epoch 13; Iter   576/ 1097] train: loss: 0.0463124
[Epoch 13; Iter   606/ 1097] train: loss: 0.1915630
[Epoch 13; Iter   636/ 1097] train: loss: 0.0781019
[Epoch 13; Iter   666/ 1097] train: loss: 0.1641776
[Epoch 13; Iter   696/ 1097] train: loss: 0.4126455
[Epoch 13; Iter   726/ 1097] train: loss: 0.0565561
[Epoch 13; Iter   756/ 1097] train: loss: 0.1020544
[Epoch 13; Iter   786/ 1097] train: loss: 0.2003193
[Epoch 13; Iter   816/ 1097] train: loss: 0.0589732
[Epoch 13; Iter   846/ 1097] train: loss: 0.0279427
[Epoch 13; Iter   876/ 1097] train: loss: 0.2204526
[Epoch 13; Iter   906/ 1097] train: loss: 0.3141629
[Epoch 13; Iter   936/ 1097] train: loss: 0.0421175
[Epoch 13; Iter   966/ 1097] train: loss: 0.0553249
[Epoch 13; Iter   996/ 1097] train: loss: 0.0295519
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0522671
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1805001
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0788501
[Epoch 13] ogbg-molhiv: 0.761063 val loss: 0.079854
[Epoch 13] ogbg-molhiv: 0.754217 test loss: 0.152166
[Epoch 14; Iter    19/ 1097] train: loss: 0.1700591
[Epoch 14; Iter    49/ 1097] train: loss: 0.1427427
[Epoch 14; Iter    79/ 1097] train: loss: 0.0396224
[Epoch 14; Iter   109/ 1097] train: loss: 0.1034316
[Epoch 14; Iter   139/ 1097] train: loss: 0.0406961
[Epoch 14; Iter   169/ 1097] train: loss: 0.1923285
[Epoch 14; Iter   199/ 1097] train: loss: 0.0212031
[Epoch 14; Iter   229/ 1097] train: loss: 0.2739637
[Epoch 14; Iter   259/ 1097] train: loss: 0.1846347
[Epoch 14; Iter   289/ 1097] train: loss: 0.1687728
[Epoch 14; Iter   319/ 1097] train: loss: 0.0350614
[Epoch 14; Iter   349/ 1097] train: loss: 0.0377632
[Epoch 14; Iter   379/ 1097] train: loss: 0.0356060
[Epoch 14; Iter   409/ 1097] train: loss: 0.1256749
[Epoch 14; Iter   439/ 1097] train: loss: 0.2043775
[Epoch 14; Iter   469/ 1097] train: loss: 0.1605853
[Epoch 14; Iter   499/ 1097] train: loss: 0.0171059
[Epoch 14; Iter   529/ 1097] train: loss: 0.3438204
[Epoch 14; Iter   559/ 1097] train: loss: 0.0411467
[Epoch 14; Iter   589/ 1097] train: loss: 0.1024443
[Epoch 14; Iter   619/ 1097] train: loss: 0.2571181
[Epoch 14; Iter   649/ 1097] train: loss: 0.0343009
[Epoch 14; Iter   679/ 1097] train: loss: 0.0647060
[Epoch 14; Iter   709/ 1097] train: loss: 0.2701956
[Epoch 14; Iter   739/ 1097] train: loss: 0.1513834
[Epoch 14; Iter   769/ 1097] train: loss: 0.0265023
[Epoch 14; Iter   799/ 1097] train: loss: 0.0257778
[Epoch 14; Iter   829/ 1097] train: loss: 0.1168978
[Epoch 14; Iter   859/ 1097] train: loss: 0.0316116
[Epoch 14; Iter   889/ 1097] train: loss: 0.0861031
[Epoch 14; Iter   919/ 1097] train: loss: 0.1103775
[Epoch 14; Iter   949/ 1097] train: loss: 0.1665345
[Epoch 14; Iter   979/ 1097] train: loss: 0.0580592
[Epoch 14; Iter  1009/ 1097] train: loss: 0.1476547
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0306686
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0601468
[Epoch 14] ogbg-molhiv: 0.800488 val loss: 0.073671
[Epoch 14] ogbg-molhiv: 0.762605 test loss: 0.145173
[Epoch 15; Iter     2/ 1097] train: loss: 0.1062785
[Epoch 15; Iter    32/ 1097] train: loss: 0.0824431
[Epoch 15; Iter    62/ 1097] train: loss: 0.0883059
[Epoch 15; Iter    92/ 1097] train: loss: 0.0832080
[Epoch 15; Iter   122/ 1097] train: loss: 0.0940335
[Epoch 15; Iter   152/ 1097] train: loss: 0.0308138
[Epoch 15; Iter   182/ 1097] train: loss: 0.1320496
[Epoch 15; Iter   212/ 1097] train: loss: 0.2332060
[Epoch 15; Iter   242/ 1097] train: loss: 0.0639241
[Epoch 15; Iter   272/ 1097] train: loss: 0.3313204
[Epoch 15; Iter   302/ 1097] train: loss: 0.1578430
[Epoch 15; Iter   332/ 1097] train: loss: 0.2297201
[Epoch 15; Iter   362/ 1097] train: loss: 0.1588282
[Epoch 15; Iter   392/ 1097] train: loss: 0.1141884
[Epoch 15; Iter   422/ 1097] train: loss: 0.1114944
[Epoch 15; Iter   452/ 1097] train: loss: 0.0234240
[Epoch 15; Iter   482/ 1097] train: loss: 0.0972761
[Epoch 15; Iter   512/ 1097] train: loss: 0.3604389
[Epoch 15; Iter   542/ 1097] train: loss: 0.1360697
[Epoch 15; Iter   572/ 1097] train: loss: 0.0558705
[Epoch 15; Iter   602/ 1097] train: loss: 0.0306141
[Epoch 15; Iter   632/ 1097] train: loss: 0.2303791
[Epoch 15; Iter   662/ 1097] train: loss: 0.0761325
[Epoch 15; Iter   692/ 1097] train: loss: 0.0755751
[Epoch 15; Iter   722/ 1097] train: loss: 0.0810272
[Epoch 15; Iter   752/ 1097] train: loss: 0.0599089
[Epoch 15; Iter   782/ 1097] train: loss: 0.0525332
[Epoch 15; Iter   812/ 1097] train: loss: 0.0210908
[Epoch 15; Iter   842/ 1097] train: loss: 0.0427348
[Epoch 15; Iter   872/ 1097] train: loss: 0.0277133
[Epoch 15; Iter   902/ 1097] train: loss: 0.0331799
[Epoch 15; Iter   932/ 1097] train: loss: 0.2304861
[Epoch 15; Iter   962/ 1097] train: loss: 0.2421237
[Epoch 15; Iter   992/ 1097] train: loss: 0.0345627
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1592757
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1620415
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0316937
[Epoch 15] ogbg-molhiv: 0.752388 val loss: 0.076942
[Epoch 15] ogbg-molhiv: 0.745907 test loss: 0.120128
[Epoch 16; Iter    15/ 1097] train: loss: 0.0285383
[Epoch 16; Iter    45/ 1097] train: loss: 0.0990206
[Epoch 16; Iter    75/ 1097] train: loss: 0.1586754
[Epoch 16; Iter   105/ 1097] train: loss: 0.0323147
[Epoch 16; Iter   135/ 1097] train: loss: 0.0586364
[Epoch 16; Iter   165/ 1097] train: loss: 0.0923101
[Epoch 12; Iter   113/ 1097] train: loss: 0.0288216
[Epoch 12; Iter   143/ 1097] train: loss: 0.0385078
[Epoch 12; Iter   173/ 1097] train: loss: 0.3124463
[Epoch 12; Iter   203/ 1097] train: loss: 0.1517022
[Epoch 12; Iter   233/ 1097] train: loss: 0.3224278
[Epoch 12; Iter   263/ 1097] train: loss: 0.1930139
[Epoch 12; Iter   293/ 1097] train: loss: 0.1823001
[Epoch 12; Iter   323/ 1097] train: loss: 0.1128387
[Epoch 12; Iter   353/ 1097] train: loss: 0.0384002
[Epoch 12; Iter   383/ 1097] train: loss: 0.1316475
[Epoch 12; Iter   413/ 1097] train: loss: 0.0307628
[Epoch 12; Iter   443/ 1097] train: loss: 0.1126845
[Epoch 12; Iter   473/ 1097] train: loss: 0.0225977
[Epoch 12; Iter   503/ 1097] train: loss: 0.0734110
[Epoch 12; Iter   533/ 1097] train: loss: 0.1309486
[Epoch 12; Iter   563/ 1097] train: loss: 0.1377204
[Epoch 12; Iter   593/ 1097] train: loss: 0.2249758
[Epoch 12; Iter   623/ 1097] train: loss: 0.0407221
[Epoch 12; Iter   653/ 1097] train: loss: 0.0266732
[Epoch 12; Iter   683/ 1097] train: loss: 0.0305978
[Epoch 12; Iter   713/ 1097] train: loss: 0.2851392
[Epoch 12; Iter   743/ 1097] train: loss: 0.0407901
[Epoch 12; Iter   773/ 1097] train: loss: 0.2893449
[Epoch 12; Iter   803/ 1097] train: loss: 0.0664054
[Epoch 12; Iter   833/ 1097] train: loss: 0.0370882
[Epoch 12; Iter   863/ 1097] train: loss: 0.0297536
[Epoch 12; Iter   893/ 1097] train: loss: 0.0926312
[Epoch 12; Iter   923/ 1097] train: loss: 0.0273481
[Epoch 12; Iter   953/ 1097] train: loss: 0.0655739
[Epoch 12; Iter   983/ 1097] train: loss: 0.1564176
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0283505
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2657059
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1787043
[Epoch 12] ogbg-molhiv: 0.782986 val loss: 0.078425
[Epoch 12] ogbg-molhiv: 0.755505 test loss: 0.125631
[Epoch 13; Iter     6/ 1097] train: loss: 0.0924729
[Epoch 13; Iter    36/ 1097] train: loss: 0.0522465
[Epoch 13; Iter    66/ 1097] train: loss: 0.0591281
[Epoch 13; Iter    96/ 1097] train: loss: 0.0648867
[Epoch 13; Iter   126/ 1097] train: loss: 0.0213007
[Epoch 13; Iter   156/ 1097] train: loss: 0.3421127
[Epoch 13; Iter   186/ 1097] train: loss: 0.0681725
[Epoch 13; Iter   216/ 1097] train: loss: 0.1125416
[Epoch 13; Iter   246/ 1097] train: loss: 0.1793872
[Epoch 13; Iter   276/ 1097] train: loss: 0.0304106
[Epoch 13; Iter   306/ 1097] train: loss: 0.0243371
[Epoch 13; Iter   336/ 1097] train: loss: 0.0323133
[Epoch 13; Iter   366/ 1097] train: loss: 0.0432456
[Epoch 13; Iter   396/ 1097] train: loss: 0.3337122
[Epoch 13; Iter   426/ 1097] train: loss: 0.0924941
[Epoch 13; Iter   456/ 1097] train: loss: 0.1317549
[Epoch 13; Iter   486/ 1097] train: loss: 0.0336410
[Epoch 13; Iter   516/ 1097] train: loss: 0.1121089
[Epoch 13; Iter   546/ 1097] train: loss: 0.2556277
[Epoch 13; Iter   576/ 1097] train: loss: 0.2490609
[Epoch 13; Iter   606/ 1097] train: loss: 0.0491603
[Epoch 13; Iter   636/ 1097] train: loss: 0.1525434
[Epoch 13; Iter   666/ 1097] train: loss: 0.0298127
[Epoch 13; Iter   696/ 1097] train: loss: 0.1159881
[Epoch 13; Iter   726/ 1097] train: loss: 0.2889373
[Epoch 13; Iter   756/ 1097] train: loss: 0.1927608
[Epoch 13; Iter   786/ 1097] train: loss: 0.3875396
[Epoch 13; Iter   816/ 1097] train: loss: 0.4942551
[Epoch 13; Iter   846/ 1097] train: loss: 0.0401089
[Epoch 13; Iter   876/ 1097] train: loss: 0.0396087
[Epoch 13; Iter   906/ 1097] train: loss: 0.4593658
[Epoch 13; Iter   936/ 1097] train: loss: 0.0323752
[Epoch 13; Iter   966/ 1097] train: loss: 0.0735010
[Epoch 13; Iter   996/ 1097] train: loss: 0.0430315
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1900668
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0975313
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2733902
[Epoch 13] ogbg-molhiv: 0.776339 val loss: 0.076479
[Epoch 13] ogbg-molhiv: 0.731457 test loss: 0.124899
[Epoch 14; Iter    19/ 1097] train: loss: 0.0320395
[Epoch 14; Iter    49/ 1097] train: loss: 0.0415935
[Epoch 14; Iter    79/ 1097] train: loss: 0.2175248
[Epoch 14; Iter   109/ 1097] train: loss: 0.1722325
[Epoch 14; Iter   139/ 1097] train: loss: 0.0979550
[Epoch 14; Iter   169/ 1097] train: loss: 0.1352749
[Epoch 14; Iter   199/ 1097] train: loss: 0.0287449
[Epoch 14; Iter   229/ 1097] train: loss: 0.1041257
[Epoch 14; Iter   259/ 1097] train: loss: 0.0463130
[Epoch 14; Iter   289/ 1097] train: loss: 0.0817154
[Epoch 14; Iter   319/ 1097] train: loss: 0.1558213
[Epoch 14; Iter   349/ 1097] train: loss: 0.0317431
[Epoch 14; Iter   379/ 1097] train: loss: 0.0582749
[Epoch 14; Iter   409/ 1097] train: loss: 0.0433766
[Epoch 14; Iter   439/ 1097] train: loss: 0.1686425
[Epoch 14; Iter   469/ 1097] train: loss: 0.2180997
[Epoch 14; Iter   499/ 1097] train: loss: 0.0778226
[Epoch 14; Iter   529/ 1097] train: loss: 0.0357374
[Epoch 14; Iter   559/ 1097] train: loss: 0.2700171
[Epoch 14; Iter   589/ 1097] train: loss: 0.1281740
[Epoch 14; Iter   619/ 1097] train: loss: 0.1834569
[Epoch 14; Iter   649/ 1097] train: loss: 0.1599366
[Epoch 14; Iter   679/ 1097] train: loss: 0.0236260
[Epoch 14; Iter   709/ 1097] train: loss: 0.0675882
[Epoch 14; Iter   739/ 1097] train: loss: 0.0432363
[Epoch 14; Iter   769/ 1097] train: loss: 0.0285231
[Epoch 14; Iter   799/ 1097] train: loss: 0.0522509
[Epoch 14; Iter   829/ 1097] train: loss: 0.1923525
[Epoch 14; Iter   859/ 1097] train: loss: 0.1968409
[Epoch 14; Iter   889/ 1097] train: loss: 0.0238522
[Epoch 14; Iter   919/ 1097] train: loss: 0.0211430
[Epoch 14; Iter   949/ 1097] train: loss: 0.0370077
[Epoch 14; Iter   979/ 1097] train: loss: 0.2482114
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0494466
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2520829
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0369511
[Epoch 14] ogbg-molhiv: 0.788776 val loss: 0.134921
[Epoch 14] ogbg-molhiv: 0.696417 test loss: 0.130694
[Epoch 15; Iter     2/ 1097] train: loss: 0.0570535
[Epoch 15; Iter    32/ 1097] train: loss: 0.0236665
[Epoch 15; Iter    62/ 1097] train: loss: 0.0725670
[Epoch 15; Iter    92/ 1097] train: loss: 0.1201064
[Epoch 15; Iter   122/ 1097] train: loss: 0.0298340
[Epoch 15; Iter   152/ 1097] train: loss: 0.2039250
[Epoch 15; Iter   182/ 1097] train: loss: 0.0261345
[Epoch 15; Iter   212/ 1097] train: loss: 0.2134048
[Epoch 15; Iter   242/ 1097] train: loss: 0.0260650
[Epoch 15; Iter   272/ 1097] train: loss: 0.0592333
[Epoch 15; Iter   302/ 1097] train: loss: 0.2019606
[Epoch 15; Iter   332/ 1097] train: loss: 0.1171068
[Epoch 15; Iter   362/ 1097] train: loss: 0.1972597
[Epoch 15; Iter   392/ 1097] train: loss: 0.0516815
[Epoch 15; Iter   422/ 1097] train: loss: 0.0311338
[Epoch 15; Iter   452/ 1097] train: loss: 0.2971767
[Epoch 15; Iter   482/ 1097] train: loss: 0.0324629
[Epoch 15; Iter   512/ 1097] train: loss: 0.2782127
[Epoch 15; Iter   542/ 1097] train: loss: 0.0301154
[Epoch 15; Iter   572/ 1097] train: loss: 0.0942053
[Epoch 15; Iter   602/ 1097] train: loss: 0.0252406
[Epoch 15; Iter   632/ 1097] train: loss: 0.1099447
[Epoch 15; Iter   662/ 1097] train: loss: 0.1150915
[Epoch 15; Iter   692/ 1097] train: loss: 0.0545235
[Epoch 15; Iter   722/ 1097] train: loss: 0.3251877
[Epoch 15; Iter   752/ 1097] train: loss: 0.0947955
[Epoch 15; Iter   782/ 1097] train: loss: 0.0864976
[Epoch 15; Iter   812/ 1097] train: loss: 0.0377173
[Epoch 15; Iter   842/ 1097] train: loss: 0.1607721
[Epoch 15; Iter   872/ 1097] train: loss: 0.0433025
[Epoch 15; Iter   902/ 1097] train: loss: 0.1272310
[Epoch 15; Iter   932/ 1097] train: loss: 0.0196282
[Epoch 15; Iter   962/ 1097] train: loss: 0.1017164
[Epoch 15; Iter   992/ 1097] train: loss: 0.1012743
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5984543
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0276852
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0341167
[Epoch 15] ogbg-molhiv: 0.732075 val loss: 1.564267
[Epoch 15] ogbg-molhiv: 0.742956 test loss: 1.392158
[Epoch 16; Iter    15/ 1097] train: loss: 0.1823067
[Epoch 16; Iter    45/ 1097] train: loss: 0.0591655
[Epoch 16; Iter    75/ 1097] train: loss: 0.0456112
[Epoch 16; Iter   105/ 1097] train: loss: 0.0772852
[Epoch 16; Iter   135/ 1097] train: loss: 0.0704375
[Epoch 16; Iter   165/ 1097] train: loss: 0.4633839
[Epoch 12; Iter   113/ 1097] train: loss: 0.1390093
[Epoch 12; Iter   143/ 1097] train: loss: 0.2664618
[Epoch 12; Iter   173/ 1097] train: loss: 0.0521061
[Epoch 12; Iter   203/ 1097] train: loss: 0.0345374
[Epoch 12; Iter   233/ 1097] train: loss: 0.0342719
[Epoch 12; Iter   263/ 1097] train: loss: 0.1260169
[Epoch 12; Iter   293/ 1097] train: loss: 0.1963107
[Epoch 12; Iter   323/ 1097] train: loss: 0.1497583
[Epoch 12; Iter   353/ 1097] train: loss: 0.2440143
[Epoch 12; Iter   383/ 1097] train: loss: 0.0591023
[Epoch 12; Iter   413/ 1097] train: loss: 0.2872951
[Epoch 12; Iter   443/ 1097] train: loss: 0.2842952
[Epoch 12; Iter   473/ 1097] train: loss: 0.1132414
[Epoch 12; Iter   503/ 1097] train: loss: 0.2447974
[Epoch 12; Iter   533/ 1097] train: loss: 0.2108056
[Epoch 12; Iter   563/ 1097] train: loss: 0.1866136
[Epoch 12; Iter   593/ 1097] train: loss: 0.2703069
[Epoch 12; Iter   623/ 1097] train: loss: 0.2755045
[Epoch 12; Iter   653/ 1097] train: loss: 0.0397881
[Epoch 12; Iter   683/ 1097] train: loss: 0.1726433
[Epoch 12; Iter   713/ 1097] train: loss: 0.0320636
[Epoch 12; Iter   743/ 1097] train: loss: 0.2402435
[Epoch 12; Iter   773/ 1097] train: loss: 0.0758776
[Epoch 12; Iter   803/ 1097] train: loss: 0.1940882
[Epoch 12; Iter   833/ 1097] train: loss: 0.1213446
[Epoch 12; Iter   863/ 1097] train: loss: 0.2810492
[Epoch 12; Iter   893/ 1097] train: loss: 0.0267216
[Epoch 12; Iter   923/ 1097] train: loss: 0.2084921
[Epoch 12; Iter   953/ 1097] train: loss: 0.2210421
[Epoch 12; Iter   983/ 1097] train: loss: 0.0458791
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0380307
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1460501
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0790480
[Epoch 12] ogbg-molhiv: 0.769801 val loss: 0.081798
[Epoch 12] ogbg-molhiv: 0.745561 test loss: 0.120837
[Epoch 13; Iter     6/ 1097] train: loss: 0.1286683
[Epoch 13; Iter    36/ 1097] train: loss: 0.3635961
[Epoch 13; Iter    66/ 1097] train: loss: 0.0889257
[Epoch 13; Iter    96/ 1097] train: loss: 0.0372378
[Epoch 13; Iter   126/ 1097] train: loss: 0.0255724
[Epoch 13; Iter   156/ 1097] train: loss: 0.0275775
[Epoch 13; Iter   186/ 1097] train: loss: 0.1228431
[Epoch 13; Iter   216/ 1097] train: loss: 0.3757145
[Epoch 13; Iter   246/ 1097] train: loss: 0.0290948
[Epoch 13; Iter   276/ 1097] train: loss: 0.1307929
[Epoch 13; Iter   306/ 1097] train: loss: 0.0207460
[Epoch 13; Iter   336/ 1097] train: loss: 0.1684654
[Epoch 13; Iter   366/ 1097] train: loss: 0.1593872
[Epoch 13; Iter   396/ 1097] train: loss: 0.1121930
[Epoch 13; Iter   426/ 1097] train: loss: 0.0686542
[Epoch 13; Iter   456/ 1097] train: loss: 0.0406874
[Epoch 13; Iter   486/ 1097] train: loss: 0.0369082
[Epoch 13; Iter   516/ 1097] train: loss: 0.0450442
[Epoch 13; Iter   546/ 1097] train: loss: 0.0244750
[Epoch 13; Iter   576/ 1097] train: loss: 0.1745560
[Epoch 13; Iter   606/ 1097] train: loss: 0.0423357
[Epoch 13; Iter   636/ 1097] train: loss: 0.2982296
[Epoch 13; Iter   666/ 1097] train: loss: 0.0467294
[Epoch 13; Iter   696/ 1097] train: loss: 0.0455931
[Epoch 13; Iter   726/ 1097] train: loss: 0.1246077
[Epoch 13; Iter   756/ 1097] train: loss: 0.0448496
[Epoch 13; Iter   786/ 1097] train: loss: 0.1184072
[Epoch 13; Iter   816/ 1097] train: loss: 0.0282560
[Epoch 13; Iter   846/ 1097] train: loss: 0.0261013
[Epoch 13; Iter   876/ 1097] train: loss: 0.2009711
[Epoch 13; Iter   906/ 1097] train: loss: 0.3242878
[Epoch 13; Iter   936/ 1097] train: loss: 0.1775891
[Epoch 13; Iter   966/ 1097] train: loss: 0.1309812
[Epoch 13; Iter   996/ 1097] train: loss: 0.1049325
[Epoch 13; Iter  1026/ 1097] train: loss: 0.2857097
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1874054
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1910919
[Epoch 13] ogbg-molhiv: 0.769425 val loss: 0.078389
[Epoch 13] ogbg-molhiv: 0.766940 test loss: 0.113317
[Epoch 14; Iter    19/ 1097] train: loss: 0.0329185
[Epoch 14; Iter    49/ 1097] train: loss: 0.3126525
[Epoch 14; Iter    79/ 1097] train: loss: 0.0356984
[Epoch 14; Iter   109/ 1097] train: loss: 0.0229429
[Epoch 14; Iter   139/ 1097] train: loss: 0.1167309
[Epoch 14; Iter   169/ 1097] train: loss: 0.1666368
[Epoch 14; Iter   199/ 1097] train: loss: 0.0581671
[Epoch 14; Iter   229/ 1097] train: loss: 0.0245268
[Epoch 14; Iter   259/ 1097] train: loss: 0.0618843
[Epoch 14; Iter   289/ 1097] train: loss: 0.0899300
[Epoch 14; Iter   319/ 1097] train: loss: 0.2576416
[Epoch 14; Iter   349/ 1097] train: loss: 0.2914923
[Epoch 14; Iter   379/ 1097] train: loss: 0.2254698
[Epoch 14; Iter   409/ 1097] train: loss: 0.0601165
[Epoch 14; Iter   439/ 1097] train: loss: 0.1293411
[Epoch 14; Iter   469/ 1097] train: loss: 0.1355436
[Epoch 14; Iter   499/ 1097] train: loss: 0.0233678
[Epoch 14; Iter   529/ 1097] train: loss: 0.0434277
[Epoch 14; Iter   559/ 1097] train: loss: 0.1845655
[Epoch 14; Iter   589/ 1097] train: loss: 0.0292223
[Epoch 14; Iter   619/ 1097] train: loss: 0.0825182
[Epoch 14; Iter   649/ 1097] train: loss: 0.0317494
[Epoch 14; Iter   679/ 1097] train: loss: 0.1128341
[Epoch 14; Iter   709/ 1097] train: loss: 0.1168273
[Epoch 14; Iter   739/ 1097] train: loss: 0.1033816
[Epoch 14; Iter   769/ 1097] train: loss: 0.1563627
[Epoch 14; Iter   799/ 1097] train: loss: 0.0522641
[Epoch 14; Iter   829/ 1097] train: loss: 0.1003683
[Epoch 14; Iter   859/ 1097] train: loss: 0.0332702
[Epoch 14; Iter   889/ 1097] train: loss: 0.0268513
[Epoch 14; Iter   919/ 1097] train: loss: 0.0483432
[Epoch 14; Iter   949/ 1097] train: loss: 0.0251296
[Epoch 14; Iter   979/ 1097] train: loss: 0.1808281
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0226214
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0624736
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1258877
[Epoch 14] ogbg-molhiv: 0.749654 val loss: 0.092028
[Epoch 14] ogbg-molhiv: 0.680838 test loss: 0.132401
[Epoch 15; Iter     2/ 1097] train: loss: 0.1778265
[Epoch 15; Iter    32/ 1097] train: loss: 0.0405214
[Epoch 15; Iter    62/ 1097] train: loss: 0.2150103
[Epoch 15; Iter    92/ 1097] train: loss: 0.0316323
[Epoch 15; Iter   122/ 1097] train: loss: 0.2782572
[Epoch 15; Iter   152/ 1097] train: loss: 0.1653886
[Epoch 15; Iter   182/ 1097] train: loss: 0.1117691
[Epoch 15; Iter   212/ 1097] train: loss: 0.0250739
[Epoch 15; Iter   242/ 1097] train: loss: 0.0295969
[Epoch 15; Iter   272/ 1097] train: loss: 0.1148121
[Epoch 15; Iter   302/ 1097] train: loss: 0.1697859
[Epoch 15; Iter   332/ 1097] train: loss: 0.0291846
[Epoch 15; Iter   362/ 1097] train: loss: 0.1423073
[Epoch 15; Iter   392/ 1097] train: loss: 0.1750723
[Epoch 15; Iter   422/ 1097] train: loss: 0.1866745
[Epoch 15; Iter   452/ 1097] train: loss: 0.0624604
[Epoch 15; Iter   482/ 1097] train: loss: 0.1090189
[Epoch 15; Iter   512/ 1097] train: loss: 0.2696911
[Epoch 15; Iter   542/ 1097] train: loss: 0.0953213
[Epoch 15; Iter   572/ 1097] train: loss: 0.0282847
[Epoch 15; Iter   602/ 1097] train: loss: 0.3531075
[Epoch 15; Iter   632/ 1097] train: loss: 0.0340172
[Epoch 15; Iter   662/ 1097] train: loss: 0.1510525
[Epoch 15; Iter   692/ 1097] train: loss: 0.0256332
[Epoch 15; Iter   722/ 1097] train: loss: 0.0957453
[Epoch 15; Iter   752/ 1097] train: loss: 0.2181237
[Epoch 15; Iter   782/ 1097] train: loss: 0.1212236
[Epoch 15; Iter   812/ 1097] train: loss: 0.0630862
[Epoch 15; Iter   842/ 1097] train: loss: 0.0232680
[Epoch 15; Iter   872/ 1097] train: loss: 0.0427473
[Epoch 15; Iter   902/ 1097] train: loss: 0.2451216
[Epoch 15; Iter   932/ 1097] train: loss: 0.0344876
[Epoch 15; Iter   962/ 1097] train: loss: 0.0280811
[Epoch 15; Iter   992/ 1097] train: loss: 0.0398289
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0187504
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1101844
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0359256
[Epoch 15] ogbg-molhiv: 0.755741 val loss: 1.517864
[Epoch 15] ogbg-molhiv: 0.768881 test loss: 0.532555
[Epoch 16; Iter    15/ 1097] train: loss: 0.0413479
[Epoch 16; Iter    45/ 1097] train: loss: 0.0263390
[Epoch 16; Iter    75/ 1097] train: loss: 0.0262079
[Epoch 16; Iter   105/ 1097] train: loss: 0.0175999
[Epoch 16; Iter   135/ 1097] train: loss: 0.0214874
[Epoch 16; Iter   165/ 1097] train: loss: 0.3169514
[Epoch 12; Iter   113/ 1097] train: loss: 0.0242548
[Epoch 12; Iter   143/ 1097] train: loss: 0.0798818
[Epoch 12; Iter   173/ 1097] train: loss: 0.3286276
[Epoch 12; Iter   203/ 1097] train: loss: 0.1027573
[Epoch 12; Iter   233/ 1097] train: loss: 0.3222765
[Epoch 12; Iter   263/ 1097] train: loss: 0.1844991
[Epoch 12; Iter   293/ 1097] train: loss: 0.1888041
[Epoch 12; Iter   323/ 1097] train: loss: 0.1027610
[Epoch 12; Iter   353/ 1097] train: loss: 0.0416380
[Epoch 12; Iter   383/ 1097] train: loss: 0.1251756
[Epoch 12; Iter   413/ 1097] train: loss: 0.0271198
[Epoch 12; Iter   443/ 1097] train: loss: 0.1422266
[Epoch 12; Iter   473/ 1097] train: loss: 0.0395197
[Epoch 12; Iter   503/ 1097] train: loss: 0.0747507
[Epoch 12; Iter   533/ 1097] train: loss: 0.1890976
[Epoch 12; Iter   563/ 1097] train: loss: 0.1746910
[Epoch 12; Iter   593/ 1097] train: loss: 0.3442096
[Epoch 12; Iter   623/ 1097] train: loss: 0.0509502
[Epoch 12; Iter   653/ 1097] train: loss: 0.0335362
[Epoch 12; Iter   683/ 1097] train: loss: 0.0418882
[Epoch 12; Iter   713/ 1097] train: loss: 0.2057497
[Epoch 12; Iter   743/ 1097] train: loss: 0.0348190
[Epoch 12; Iter   773/ 1097] train: loss: 0.2879215
[Epoch 12; Iter   803/ 1097] train: loss: 0.0953726
[Epoch 12; Iter   833/ 1097] train: loss: 0.0341148
[Epoch 12; Iter   863/ 1097] train: loss: 0.0375450
[Epoch 12; Iter   893/ 1097] train: loss: 0.0864281
[Epoch 12; Iter   923/ 1097] train: loss: 0.0486436
[Epoch 12; Iter   953/ 1097] train: loss: 0.0590267
[Epoch 12; Iter   983/ 1097] train: loss: 0.1638545
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0298391
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2444122
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1729128
[Epoch 12] ogbg-molhiv: 0.757324 val loss: 0.230689
[Epoch 12] ogbg-molhiv: 0.745186 test loss: 0.225619
[Epoch 13; Iter     6/ 1097] train: loss: 0.1051615
[Epoch 13; Iter    36/ 1097] train: loss: 0.0366682
[Epoch 13; Iter    66/ 1097] train: loss: 0.0478998
[Epoch 13; Iter    96/ 1097] train: loss: 0.0592393
[Epoch 13; Iter   126/ 1097] train: loss: 0.0272292
[Epoch 13; Iter   156/ 1097] train: loss: 0.2915224
[Epoch 13; Iter   186/ 1097] train: loss: 0.1128164
[Epoch 13; Iter   216/ 1097] train: loss: 0.1472225
[Epoch 13; Iter   246/ 1097] train: loss: 0.2005569
[Epoch 13; Iter   276/ 1097] train: loss: 0.0352505
[Epoch 13; Iter   306/ 1097] train: loss: 0.0242427
[Epoch 13; Iter   336/ 1097] train: loss: 0.0312186
[Epoch 13; Iter   366/ 1097] train: loss: 0.0473146
[Epoch 13; Iter   396/ 1097] train: loss: 0.2540088
[Epoch 13; Iter   426/ 1097] train: loss: 0.0403161
[Epoch 13; Iter   456/ 1097] train: loss: 0.1859384
[Epoch 13; Iter   486/ 1097] train: loss: 0.0359321
[Epoch 13; Iter   516/ 1097] train: loss: 0.1439333
[Epoch 13; Iter   546/ 1097] train: loss: 0.2411873
[Epoch 13; Iter   576/ 1097] train: loss: 0.2019230
[Epoch 13; Iter   606/ 1097] train: loss: 0.0311212
[Epoch 13; Iter   636/ 1097] train: loss: 0.1780959
[Epoch 13; Iter   666/ 1097] train: loss: 0.0379415
[Epoch 13; Iter   696/ 1097] train: loss: 0.1346246
[Epoch 13; Iter   726/ 1097] train: loss: 0.3517684
[Epoch 13; Iter   756/ 1097] train: loss: 0.1731390
[Epoch 13; Iter   786/ 1097] train: loss: 0.4638869
[Epoch 13; Iter   816/ 1097] train: loss: 0.5019176
[Epoch 13; Iter   846/ 1097] train: loss: 0.0648875
[Epoch 13; Iter   876/ 1097] train: loss: 0.0457276
[Epoch 13; Iter   906/ 1097] train: loss: 0.2683614
[Epoch 13; Iter   936/ 1097] train: loss: 0.0278859
[Epoch 13; Iter   966/ 1097] train: loss: 0.1415245
[Epoch 13; Iter   996/ 1097] train: loss: 0.1562568
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1662167
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0954095
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1928539
[Epoch 13] ogbg-molhiv: 0.785727 val loss: 0.127194
[Epoch 13] ogbg-molhiv: 0.756635 test loss: 0.134862
[Epoch 14; Iter    19/ 1097] train: loss: 0.0347542
[Epoch 14; Iter    49/ 1097] train: loss: 0.0306889
[Epoch 14; Iter    79/ 1097] train: loss: 0.2165541
[Epoch 14; Iter   109/ 1097] train: loss: 0.1620959
[Epoch 14; Iter   139/ 1097] train: loss: 0.0624134
[Epoch 14; Iter   169/ 1097] train: loss: 0.2302963
[Epoch 14; Iter   199/ 1097] train: loss: 0.0278536
[Epoch 14; Iter   229/ 1097] train: loss: 0.1675453
[Epoch 14; Iter   259/ 1097] train: loss: 0.0897274
[Epoch 14; Iter   289/ 1097] train: loss: 0.1889344
[Epoch 14; Iter   319/ 1097] train: loss: 0.1472795
[Epoch 14; Iter   349/ 1097] train: loss: 0.0306240
[Epoch 14; Iter   379/ 1097] train: loss: 0.1094518
[Epoch 14; Iter   409/ 1097] train: loss: 0.0332571
[Epoch 14; Iter   439/ 1097] train: loss: 0.1900694
[Epoch 14; Iter   469/ 1097] train: loss: 0.1868489
[Epoch 14; Iter   499/ 1097] train: loss: 0.1124845
[Epoch 14; Iter   529/ 1097] train: loss: 0.0417531
[Epoch 14; Iter   559/ 1097] train: loss: 0.3148053
[Epoch 14; Iter   589/ 1097] train: loss: 0.2065316
[Epoch 14; Iter   619/ 1097] train: loss: 0.1905410
[Epoch 14; Iter   649/ 1097] train: loss: 0.2315968
[Epoch 14; Iter   679/ 1097] train: loss: 0.0280035
[Epoch 14; Iter   709/ 1097] train: loss: 0.0949754
[Epoch 14; Iter   739/ 1097] train: loss: 0.0765615
[Epoch 14; Iter   769/ 1097] train: loss: 0.0248323
[Epoch 14; Iter   799/ 1097] train: loss: 0.0527648
[Epoch 14; Iter   829/ 1097] train: loss: 0.1042483
[Epoch 14; Iter   859/ 1097] train: loss: 0.2865192
[Epoch 14; Iter   889/ 1097] train: loss: 0.0353729
[Epoch 14; Iter   919/ 1097] train: loss: 0.0242396
[Epoch 14; Iter   949/ 1097] train: loss: 0.0212563
[Epoch 14; Iter   979/ 1097] train: loss: 0.3226410
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0614393
[Epoch 14; Iter  1039/ 1097] train: loss: 0.1920397
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0382714
[Epoch 14] ogbg-molhiv: 0.754403 val loss: 0.084495
[Epoch 14] ogbg-molhiv: 0.667921 test loss: 0.307026
[Epoch 15; Iter     2/ 1097] train: loss: 0.1039993
[Epoch 15; Iter    32/ 1097] train: loss: 0.0255620
[Epoch 15; Iter    62/ 1097] train: loss: 0.1262636
[Epoch 15; Iter    92/ 1097] train: loss: 0.0620593
[Epoch 15; Iter   122/ 1097] train: loss: 0.0224121
[Epoch 15; Iter   152/ 1097] train: loss: 0.1714097
[Epoch 15; Iter   182/ 1097] train: loss: 0.0307205
[Epoch 15; Iter   212/ 1097] train: loss: 0.2191386
[Epoch 15; Iter   242/ 1097] train: loss: 0.0587680
[Epoch 15; Iter   272/ 1097] train: loss: 0.2325326
[Epoch 15; Iter   302/ 1097] train: loss: 0.2207726
[Epoch 15; Iter   332/ 1097] train: loss: 0.0366380
[Epoch 15; Iter   362/ 1097] train: loss: 0.1874194
[Epoch 15; Iter   392/ 1097] train: loss: 0.0574730
[Epoch 15; Iter   422/ 1097] train: loss: 0.0323013
[Epoch 15; Iter   452/ 1097] train: loss: 0.2351004
[Epoch 15; Iter   482/ 1097] train: loss: 0.0593908
[Epoch 15; Iter   512/ 1097] train: loss: 0.1989561
[Epoch 15; Iter   542/ 1097] train: loss: 0.0517161
[Epoch 15; Iter   572/ 1097] train: loss: 0.1155161
[Epoch 15; Iter   602/ 1097] train: loss: 0.0262136
[Epoch 15; Iter   632/ 1097] train: loss: 0.1324843
[Epoch 15; Iter   662/ 1097] train: loss: 0.1457476
[Epoch 15; Iter   692/ 1097] train: loss: 0.0603069
[Epoch 15; Iter   722/ 1097] train: loss: 0.3346628
[Epoch 15; Iter   752/ 1097] train: loss: 0.1087519
[Epoch 15; Iter   782/ 1097] train: loss: 0.1074982
[Epoch 15; Iter   812/ 1097] train: loss: 0.0264140
[Epoch 15; Iter   842/ 1097] train: loss: 0.2349059
[Epoch 15; Iter   872/ 1097] train: loss: 0.0393774
[Epoch 15; Iter   902/ 1097] train: loss: 0.1286911
[Epoch 15; Iter   932/ 1097] train: loss: 0.0245355
[Epoch 15; Iter   962/ 1097] train: loss: 0.0709449
[Epoch 15; Iter   992/ 1097] train: loss: 0.1444917
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4764712
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0311472
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0536053
[Epoch 15] ogbg-molhiv: 0.738460 val loss: 0.082506
[Epoch 15] ogbg-molhiv: 0.743017 test loss: 0.120717
[Epoch 16; Iter    15/ 1097] train: loss: 0.1191394
[Epoch 16; Iter    45/ 1097] train: loss: 0.0399013
[Epoch 16; Iter    75/ 1097] train: loss: 0.0779965
[Epoch 16; Iter   105/ 1097] train: loss: 0.1109999
[Epoch 16; Iter   135/ 1097] train: loss: 0.1207168
[Epoch 16; Iter   165/ 1097] train: loss: 0.5092428
[Epoch 12; Iter   113/ 1097] train: loss: 0.0716917
[Epoch 12; Iter   143/ 1097] train: loss: 0.1958630
[Epoch 12; Iter   173/ 1097] train: loss: 0.0233067
[Epoch 12; Iter   203/ 1097] train: loss: 0.1104867
[Epoch 12; Iter   233/ 1097] train: loss: 0.0230110
[Epoch 12; Iter   263/ 1097] train: loss: 0.0700954
[Epoch 12; Iter   293/ 1097] train: loss: 0.2028597
[Epoch 12; Iter   323/ 1097] train: loss: 0.1930595
[Epoch 12; Iter   353/ 1097] train: loss: 0.1071412
[Epoch 12; Iter   383/ 1097] train: loss: 0.0299216
[Epoch 12; Iter   413/ 1097] train: loss: 0.1000765
[Epoch 12; Iter   443/ 1097] train: loss: 0.0362171
[Epoch 12; Iter   473/ 1097] train: loss: 0.2960454
[Epoch 12; Iter   503/ 1097] train: loss: 0.2358423
[Epoch 12; Iter   533/ 1097] train: loss: 0.0340271
[Epoch 12; Iter   563/ 1097] train: loss: 0.1158086
[Epoch 12; Iter   593/ 1097] train: loss: 0.1829818
[Epoch 12; Iter   623/ 1097] train: loss: 0.0304003
[Epoch 12; Iter   653/ 1097] train: loss: 0.1122527
[Epoch 12; Iter   683/ 1097] train: loss: 0.2645319
[Epoch 12; Iter   713/ 1097] train: loss: 0.1637701
[Epoch 12; Iter   743/ 1097] train: loss: 0.0304068
[Epoch 12; Iter   773/ 1097] train: loss: 0.1193296
[Epoch 12; Iter   803/ 1097] train: loss: 0.1967579
[Epoch 12; Iter   833/ 1097] train: loss: 0.0974241
[Epoch 12; Iter   863/ 1097] train: loss: 0.0508972
[Epoch 12; Iter   893/ 1097] train: loss: 0.1352554
[Epoch 12; Iter   923/ 1097] train: loss: 0.0448190
[Epoch 12; Iter   953/ 1097] train: loss: 0.2050647
[Epoch 12; Iter   983/ 1097] train: loss: 0.2628649
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0309532
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0273903
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0254342
[Epoch 12] ogbg-molhiv: 0.809508 val loss: 0.113138
[Epoch 12] ogbg-molhiv: 0.736795 test loss: 0.202713
[Epoch 13; Iter     6/ 1097] train: loss: 0.1688969
[Epoch 13; Iter    36/ 1097] train: loss: 0.1798908
[Epoch 13; Iter    66/ 1097] train: loss: 0.1350870
[Epoch 13; Iter    96/ 1097] train: loss: 0.0392783
[Epoch 13; Iter   126/ 1097] train: loss: 0.0589941
[Epoch 13; Iter   156/ 1097] train: loss: 0.2411194
[Epoch 13; Iter   186/ 1097] train: loss: 0.2386062
[Epoch 13; Iter   216/ 1097] train: loss: 0.1809853
[Epoch 13; Iter   246/ 1097] train: loss: 0.0272865
[Epoch 13; Iter   276/ 1097] train: loss: 0.0236424
[Epoch 13; Iter   306/ 1097] train: loss: 0.3638504
[Epoch 13; Iter   336/ 1097] train: loss: 0.1626884
[Epoch 13; Iter   366/ 1097] train: loss: 0.3471724
[Epoch 13; Iter   396/ 1097] train: loss: 0.0734034
[Epoch 13; Iter   426/ 1097] train: loss: 0.1033095
[Epoch 13; Iter   456/ 1097] train: loss: 0.1968955
[Epoch 13; Iter   486/ 1097] train: loss: 0.0362071
[Epoch 13; Iter   516/ 1097] train: loss: 0.2534140
[Epoch 13; Iter   546/ 1097] train: loss: 0.0249190
[Epoch 13; Iter   576/ 1097] train: loss: 0.1201141
[Epoch 13; Iter   606/ 1097] train: loss: 0.1988830
[Epoch 13; Iter   636/ 1097] train: loss: 0.0515130
[Epoch 13; Iter   666/ 1097] train: loss: 0.1623462
[Epoch 13; Iter   696/ 1097] train: loss: 0.3911507
[Epoch 13; Iter   726/ 1097] train: loss: 0.0627249
[Epoch 13; Iter   756/ 1097] train: loss: 0.0445738
[Epoch 13; Iter   786/ 1097] train: loss: 0.2493889
[Epoch 13; Iter   816/ 1097] train: loss: 0.0942245
[Epoch 13; Iter   846/ 1097] train: loss: 0.0340436
[Epoch 13; Iter   876/ 1097] train: loss: 0.2356714
[Epoch 13; Iter   906/ 1097] train: loss: 0.3014815
[Epoch 13; Iter   936/ 1097] train: loss: 0.0344672
[Epoch 13; Iter   966/ 1097] train: loss: 0.0377318
[Epoch 13; Iter   996/ 1097] train: loss: 0.0736433
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0451441
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2681006
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1825693
[Epoch 13] ogbg-molhiv: 0.703903 val loss: 0.100050
[Epoch 13] ogbg-molhiv: 0.711433 test loss: 0.254087
[Epoch 14; Iter    19/ 1097] train: loss: 0.2209722
[Epoch 14; Iter    49/ 1097] train: loss: 0.1723024
[Epoch 14; Iter    79/ 1097] train: loss: 0.0579011
[Epoch 14; Iter   109/ 1097] train: loss: 0.0977397
[Epoch 14; Iter   139/ 1097] train: loss: 0.0304377
[Epoch 14; Iter   169/ 1097] train: loss: 0.1480336
[Epoch 14; Iter   199/ 1097] train: loss: 0.0197630
[Epoch 14; Iter   229/ 1097] train: loss: 0.3763798
[Epoch 14; Iter   259/ 1097] train: loss: 0.3134212
[Epoch 14; Iter   289/ 1097] train: loss: 0.1722035
[Epoch 14; Iter   319/ 1097] train: loss: 0.0317732
[Epoch 14; Iter   349/ 1097] train: loss: 0.0279147
[Epoch 14; Iter   379/ 1097] train: loss: 0.0362537
[Epoch 14; Iter   409/ 1097] train: loss: 0.0633528
[Epoch 14; Iter   439/ 1097] train: loss: 0.2857481
[Epoch 14; Iter   469/ 1097] train: loss: 0.2280374
[Epoch 14; Iter   499/ 1097] train: loss: 0.0241207
[Epoch 14; Iter   529/ 1097] train: loss: 0.3056030
[Epoch 14; Iter   559/ 1097] train: loss: 0.0338999
[Epoch 14; Iter   589/ 1097] train: loss: 0.0959373
[Epoch 14; Iter   619/ 1097] train: loss: 0.1957348
[Epoch 14; Iter   649/ 1097] train: loss: 0.0615275
[Epoch 14; Iter   679/ 1097] train: loss: 0.0311209
[Epoch 14; Iter   709/ 1097] train: loss: 0.2365270
[Epoch 14; Iter   739/ 1097] train: loss: 0.2251540
[Epoch 14; Iter   769/ 1097] train: loss: 0.0246146
[Epoch 14; Iter   799/ 1097] train: loss: 0.0256802
[Epoch 14; Iter   829/ 1097] train: loss: 0.1338388
[Epoch 14; Iter   859/ 1097] train: loss: 0.0265049
[Epoch 14; Iter   889/ 1097] train: loss: 0.0857778
[Epoch 14; Iter   919/ 1097] train: loss: 0.1366073
[Epoch 14; Iter   949/ 1097] train: loss: 0.1548421
[Epoch 14; Iter   979/ 1097] train: loss: 0.0969536
[Epoch 14; Iter  1009/ 1097] train: loss: 0.1967096
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0295759
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0838841
[Epoch 14] ogbg-molhiv: 0.786259 val loss: 0.080119
[Epoch 14] ogbg-molhiv: 0.726188 test loss: 0.143750
[Epoch 15; Iter     2/ 1097] train: loss: 0.1893164
[Epoch 15; Iter    32/ 1097] train: loss: 0.0819136
[Epoch 15; Iter    62/ 1097] train: loss: 0.0653604
[Epoch 15; Iter    92/ 1097] train: loss: 0.0505921
[Epoch 15; Iter   122/ 1097] train: loss: 0.0459019
[Epoch 15; Iter   152/ 1097] train: loss: 0.0280849
[Epoch 15; Iter   182/ 1097] train: loss: 0.1490687
[Epoch 15; Iter   212/ 1097] train: loss: 0.1502144
[Epoch 15; Iter   242/ 1097] train: loss: 0.1045144
[Epoch 15; Iter   272/ 1097] train: loss: 0.3474897
[Epoch 15; Iter   302/ 1097] train: loss: 0.1789450
[Epoch 15; Iter   332/ 1097] train: loss: 0.1737378
[Epoch 15; Iter   362/ 1097] train: loss: 0.1440689
[Epoch 15; Iter   392/ 1097] train: loss: 0.1516277
[Epoch 15; Iter   422/ 1097] train: loss: 0.0493595
[Epoch 15; Iter   452/ 1097] train: loss: 0.0393675
[Epoch 15; Iter   482/ 1097] train: loss: 0.1339858
[Epoch 15; Iter   512/ 1097] train: loss: 0.3635270
[Epoch 15; Iter   542/ 1097] train: loss: 0.1303006
[Epoch 15; Iter   572/ 1097] train: loss: 0.0539669
[Epoch 15; Iter   602/ 1097] train: loss: 0.0303549
[Epoch 15; Iter   632/ 1097] train: loss: 0.2458889
[Epoch 15; Iter   662/ 1097] train: loss: 0.0931436
[Epoch 15; Iter   692/ 1097] train: loss: 0.1511692
[Epoch 15; Iter   722/ 1097] train: loss: 0.0714907
[Epoch 15; Iter   752/ 1097] train: loss: 0.0638091
[Epoch 15; Iter   782/ 1097] train: loss: 0.0497771
[Epoch 15; Iter   812/ 1097] train: loss: 0.0373175
[Epoch 15; Iter   842/ 1097] train: loss: 0.0862309
[Epoch 15; Iter   872/ 1097] train: loss: 0.0261587
[Epoch 15; Iter   902/ 1097] train: loss: 0.0318615
[Epoch 15; Iter   932/ 1097] train: loss: 0.1598459
[Epoch 15; Iter   962/ 1097] train: loss: 0.3007174
[Epoch 15; Iter   992/ 1097] train: loss: 0.0293011
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1127393
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1054168
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0225707
[Epoch 15] ogbg-molhiv: 0.759265 val loss: 0.180946
[Epoch 15] ogbg-molhiv: 0.715336 test loss: 0.141012
[Epoch 16; Iter    15/ 1097] train: loss: 0.0249492
[Epoch 16; Iter    45/ 1097] train: loss: 0.1307972
[Epoch 16; Iter    75/ 1097] train: loss: 0.3056586
[Epoch 16; Iter   105/ 1097] train: loss: 0.0282560
[Epoch 16; Iter   135/ 1097] train: loss: 0.0844119
[Epoch 16; Iter   165/ 1097] train: loss: 0.1962242
[Epoch 12; Iter   113/ 1097] train: loss: 0.0906253
[Epoch 12; Iter   143/ 1097] train: loss: 0.1622970
[Epoch 12; Iter   173/ 1097] train: loss: 0.0206781
[Epoch 12; Iter   203/ 1097] train: loss: 0.1950515
[Epoch 12; Iter   233/ 1097] train: loss: 0.0192352
[Epoch 12; Iter   263/ 1097] train: loss: 0.0360391
[Epoch 12; Iter   293/ 1097] train: loss: 0.1620037
[Epoch 12; Iter   323/ 1097] train: loss: 0.1114337
[Epoch 12; Iter   353/ 1097] train: loss: 0.0676850
[Epoch 12; Iter   383/ 1097] train: loss: 0.0237613
[Epoch 12; Iter   413/ 1097] train: loss: 0.0551662
[Epoch 12; Iter   443/ 1097] train: loss: 0.0209756
[Epoch 12; Iter   473/ 1097] train: loss: 0.2230292
[Epoch 12; Iter   503/ 1097] train: loss: 0.2342771
[Epoch 12; Iter   533/ 1097] train: loss: 0.0390513
[Epoch 12; Iter   563/ 1097] train: loss: 0.0806986
[Epoch 12; Iter   593/ 1097] train: loss: 0.1725202
[Epoch 12; Iter   623/ 1097] train: loss: 0.0352025
[Epoch 12; Iter   653/ 1097] train: loss: 0.0895063
[Epoch 12; Iter   683/ 1097] train: loss: 0.3508806
[Epoch 12; Iter   713/ 1097] train: loss: 0.0656186
[Epoch 12; Iter   743/ 1097] train: loss: 0.0269995
[Epoch 12; Iter   773/ 1097] train: loss: 0.1341986
[Epoch 12; Iter   803/ 1097] train: loss: 0.1928561
[Epoch 12; Iter   833/ 1097] train: loss: 0.1548917
[Epoch 12; Iter   863/ 1097] train: loss: 0.0783795
[Epoch 12; Iter   893/ 1097] train: loss: 0.2033621
[Epoch 12; Iter   923/ 1097] train: loss: 0.0362958
[Epoch 12; Iter   953/ 1097] train: loss: 0.2038927
[Epoch 12; Iter   983/ 1097] train: loss: 0.2036482
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0296496
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0285939
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0235388
[Epoch 12] ogbg-molhiv: 0.819493 val loss: 0.250302
[Epoch 12] ogbg-molhiv: 0.771429 test loss: 0.113424
[Epoch 13; Iter     6/ 1097] train: loss: 0.2040743
[Epoch 13; Iter    36/ 1097] train: loss: 0.1388658
[Epoch 13; Iter    66/ 1097] train: loss: 0.1403473
[Epoch 13; Iter    96/ 1097] train: loss: 0.0335456
[Epoch 13; Iter   126/ 1097] train: loss: 0.0656038
[Epoch 13; Iter   156/ 1097] train: loss: 0.2066894
[Epoch 13; Iter   186/ 1097] train: loss: 0.2319524
[Epoch 13; Iter   216/ 1097] train: loss: 0.1872715
[Epoch 13; Iter   246/ 1097] train: loss: 0.0380422
[Epoch 13; Iter   276/ 1097] train: loss: 0.0281246
[Epoch 13; Iter   306/ 1097] train: loss: 0.3419176
[Epoch 13; Iter   336/ 1097] train: loss: 0.1019693
[Epoch 13; Iter   366/ 1097] train: loss: 0.3687619
[Epoch 13; Iter   396/ 1097] train: loss: 0.0498201
[Epoch 13; Iter   426/ 1097] train: loss: 0.1312225
[Epoch 13; Iter   456/ 1097] train: loss: 0.1348459
[Epoch 13; Iter   486/ 1097] train: loss: 0.0342065
[Epoch 13; Iter   516/ 1097] train: loss: 0.1465322
[Epoch 13; Iter   546/ 1097] train: loss: 0.0422560
[Epoch 13; Iter   576/ 1097] train: loss: 0.0554603
[Epoch 13; Iter   606/ 1097] train: loss: 0.2570162
[Epoch 13; Iter   636/ 1097] train: loss: 0.0652432
[Epoch 13; Iter   666/ 1097] train: loss: 0.2029050
[Epoch 13; Iter   696/ 1097] train: loss: 0.4843506
[Epoch 13; Iter   726/ 1097] train: loss: 0.0743429
[Epoch 13; Iter   756/ 1097] train: loss: 0.0459269
[Epoch 13; Iter   786/ 1097] train: loss: 0.1280212
[Epoch 13; Iter   816/ 1097] train: loss: 0.0825811
[Epoch 13; Iter   846/ 1097] train: loss: 0.0321849
[Epoch 13; Iter   876/ 1097] train: loss: 0.1784903
[Epoch 13; Iter   906/ 1097] train: loss: 0.3104017
[Epoch 13; Iter   936/ 1097] train: loss: 0.0554002
[Epoch 13; Iter   966/ 1097] train: loss: 0.0543857
[Epoch 13; Iter   996/ 1097] train: loss: 0.0272258
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0220583
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1760949
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1581784
[Epoch 13] ogbg-molhiv: 0.816205 val loss: 0.159456
[Epoch 13] ogbg-molhiv: 0.781044 test loss: 0.116924
[Epoch 14; Iter    19/ 1097] train: loss: 0.1959428
[Epoch 14; Iter    49/ 1097] train: loss: 0.1840277
[Epoch 14; Iter    79/ 1097] train: loss: 0.0378114
[Epoch 14; Iter   109/ 1097] train: loss: 0.0920380
[Epoch 14; Iter   139/ 1097] train: loss: 0.0273346
[Epoch 14; Iter   169/ 1097] train: loss: 0.1866849
[Epoch 14; Iter   199/ 1097] train: loss: 0.0486192
[Epoch 14; Iter   229/ 1097] train: loss: 0.3128506
[Epoch 14; Iter   259/ 1097] train: loss: 0.1907983
[Epoch 14; Iter   289/ 1097] train: loss: 0.1361027
[Epoch 14; Iter   319/ 1097] train: loss: 0.0310378
[Epoch 14; Iter   349/ 1097] train: loss: 0.0776011
[Epoch 14; Iter   379/ 1097] train: loss: 0.0320988
[Epoch 14; Iter   409/ 1097] train: loss: 0.1581913
[Epoch 14; Iter   439/ 1097] train: loss: 0.2377228
[Epoch 14; Iter   469/ 1097] train: loss: 0.1817821
[Epoch 14; Iter   499/ 1097] train: loss: 0.0223499
[Epoch 14; Iter   529/ 1097] train: loss: 0.1880758
[Epoch 14; Iter   559/ 1097] train: loss: 0.0364232
[Epoch 14; Iter   589/ 1097] train: loss: 0.1237253
[Epoch 14; Iter   619/ 1097] train: loss: 0.2515815
[Epoch 14; Iter   649/ 1097] train: loss: 0.0339574
[Epoch 14; Iter   679/ 1097] train: loss: 0.0572334
[Epoch 14; Iter   709/ 1097] train: loss: 0.2811130
[Epoch 14; Iter   739/ 1097] train: loss: 0.1846337
[Epoch 14; Iter   769/ 1097] train: loss: 0.0284376
[Epoch 14; Iter   799/ 1097] train: loss: 0.0180403
[Epoch 14; Iter   829/ 1097] train: loss: 0.0920103
[Epoch 14; Iter   859/ 1097] train: loss: 0.0550459
[Epoch 14; Iter   889/ 1097] train: loss: 0.0703757
[Epoch 14; Iter   919/ 1097] train: loss: 0.1438831
[Epoch 14; Iter   949/ 1097] train: loss: 0.1253674
[Epoch 14; Iter   979/ 1097] train: loss: 0.0699150
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2062445
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0254968
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0446270
[Epoch 14] ogbg-molhiv: 0.782242 val loss: 0.329819
[Epoch 14] ogbg-molhiv: 0.797702 test loss: 0.117865
[Epoch 15; Iter     2/ 1097] train: loss: 0.1606359
[Epoch 15; Iter    32/ 1097] train: loss: 0.1172975
[Epoch 15; Iter    62/ 1097] train: loss: 0.0646335
[Epoch 15; Iter    92/ 1097] train: loss: 0.0741567
[Epoch 15; Iter   122/ 1097] train: loss: 0.1003832
[Epoch 15; Iter   152/ 1097] train: loss: 0.0221979
[Epoch 15; Iter   182/ 1097] train: loss: 0.1601055
[Epoch 15; Iter   212/ 1097] train: loss: 0.2541396
[Epoch 15; Iter   242/ 1097] train: loss: 0.1145300
[Epoch 15; Iter   272/ 1097] train: loss: 0.2641690
[Epoch 15; Iter   302/ 1097] train: loss: 0.1555787
[Epoch 15; Iter   332/ 1097] train: loss: 0.2651690
[Epoch 15; Iter   362/ 1097] train: loss: 0.1825398
[Epoch 15; Iter   392/ 1097] train: loss: 0.1765134
[Epoch 15; Iter   422/ 1097] train: loss: 0.0654145
[Epoch 15; Iter   452/ 1097] train: loss: 0.0378934
[Epoch 15; Iter   482/ 1097] train: loss: 0.0686953
[Epoch 15; Iter   512/ 1097] train: loss: 0.3526888
[Epoch 15; Iter   542/ 1097] train: loss: 0.1403777
[Epoch 15; Iter   572/ 1097] train: loss: 0.1164873
[Epoch 15; Iter   602/ 1097] train: loss: 0.0466738
[Epoch 15; Iter   632/ 1097] train: loss: 0.2591447
[Epoch 15; Iter   662/ 1097] train: loss: 0.0516365
[Epoch 15; Iter   692/ 1097] train: loss: 0.0959396
[Epoch 15; Iter   722/ 1097] train: loss: 0.0613357
[Epoch 15; Iter   752/ 1097] train: loss: 0.0381223
[Epoch 15; Iter   782/ 1097] train: loss: 0.0727034
[Epoch 15; Iter   812/ 1097] train: loss: 0.0220739
[Epoch 15; Iter   842/ 1097] train: loss: 0.0466623
[Epoch 15; Iter   872/ 1097] train: loss: 0.0221350
[Epoch 15; Iter   902/ 1097] train: loss: 0.0470742
[Epoch 15; Iter   932/ 1097] train: loss: 0.1561276
[Epoch 15; Iter   962/ 1097] train: loss: 0.2275445
[Epoch 15; Iter   992/ 1097] train: loss: 0.0226614
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1418228
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1622058
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0279792
[Epoch 15] ogbg-molhiv: 0.829959 val loss: 0.237026
[Epoch 15] ogbg-molhiv: 0.775478 test loss: 0.202369
[Epoch 16; Iter    15/ 1097] train: loss: 0.0250420
[Epoch 16; Iter    45/ 1097] train: loss: 0.1348584
[Epoch 16; Iter    75/ 1097] train: loss: 0.1864035
[Epoch 16; Iter   105/ 1097] train: loss: 0.0247285
[Epoch 16; Iter   135/ 1097] train: loss: 0.0912848
[Epoch 16; Iter   165/ 1097] train: loss: 0.1785151
[Epoch 12; Iter   113/ 1097] train: loss: 0.0434989
[Epoch 12; Iter   143/ 1097] train: loss: 0.0350283
[Epoch 12; Iter   173/ 1097] train: loss: 0.2755848
[Epoch 12; Iter   203/ 1097] train: loss: 0.0986621
[Epoch 12; Iter   233/ 1097] train: loss: 0.3443654
[Epoch 12; Iter   263/ 1097] train: loss: 0.1857793
[Epoch 12; Iter   293/ 1097] train: loss: 0.1620272
[Epoch 12; Iter   323/ 1097] train: loss: 0.0895186
[Epoch 12; Iter   353/ 1097] train: loss: 0.0295536
[Epoch 12; Iter   383/ 1097] train: loss: 0.1141891
[Epoch 12; Iter   413/ 1097] train: loss: 0.0335018
[Epoch 12; Iter   443/ 1097] train: loss: 0.0591108
[Epoch 12; Iter   473/ 1097] train: loss: 0.0247234
[Epoch 12; Iter   503/ 1097] train: loss: 0.0388007
[Epoch 12; Iter   533/ 1097] train: loss: 0.0473003
[Epoch 12; Iter   563/ 1097] train: loss: 0.1210268
[Epoch 12; Iter   593/ 1097] train: loss: 0.2440382
[Epoch 12; Iter   623/ 1097] train: loss: 0.0417695
[Epoch 12; Iter   653/ 1097] train: loss: 0.0259276
[Epoch 12; Iter   683/ 1097] train: loss: 0.0306402
[Epoch 12; Iter   713/ 1097] train: loss: 0.2971254
[Epoch 12; Iter   743/ 1097] train: loss: 0.0295432
[Epoch 12; Iter   773/ 1097] train: loss: 0.3526359
[Epoch 12; Iter   803/ 1097] train: loss: 0.0815113
[Epoch 12; Iter   833/ 1097] train: loss: 0.0344813
[Epoch 12; Iter   863/ 1097] train: loss: 0.0318116
[Epoch 12; Iter   893/ 1097] train: loss: 0.1297070
[Epoch 12; Iter   923/ 1097] train: loss: 0.0287610
[Epoch 12; Iter   953/ 1097] train: loss: 0.0512058
[Epoch 12; Iter   983/ 1097] train: loss: 0.1585947
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0287202
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1869342
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1839536
[Epoch 12] ogbg-molhiv: 0.804120 val loss: 0.075501
[Epoch 12] ogbg-molhiv: 0.744076 test loss: 0.116068
[Epoch 13; Iter     6/ 1097] train: loss: 0.0980289
[Epoch 13; Iter    36/ 1097] train: loss: 0.0642131
[Epoch 13; Iter    66/ 1097] train: loss: 0.0350581
[Epoch 13; Iter    96/ 1097] train: loss: 0.0795948
[Epoch 13; Iter   126/ 1097] train: loss: 0.0233567
[Epoch 13; Iter   156/ 1097] train: loss: 0.1839450
[Epoch 13; Iter   186/ 1097] train: loss: 0.1439076
[Epoch 13; Iter   216/ 1097] train: loss: 0.1074115
[Epoch 13; Iter   246/ 1097] train: loss: 0.0999734
[Epoch 13; Iter   276/ 1097] train: loss: 0.0292312
[Epoch 13; Iter   306/ 1097] train: loss: 0.0360188
[Epoch 13; Iter   336/ 1097] train: loss: 0.0246574
[Epoch 13; Iter   366/ 1097] train: loss: 0.0176947
[Epoch 13; Iter   396/ 1097] train: loss: 0.2603693
[Epoch 13; Iter   426/ 1097] train: loss: 0.0903718
[Epoch 13; Iter   456/ 1097] train: loss: 0.0987635
[Epoch 13; Iter   486/ 1097] train: loss: 0.0480756
[Epoch 13; Iter   516/ 1097] train: loss: 0.1497013
[Epoch 13; Iter   546/ 1097] train: loss: 0.1550209
[Epoch 13; Iter   576/ 1097] train: loss: 0.2362826
[Epoch 13; Iter   606/ 1097] train: loss: 0.0312625
[Epoch 13; Iter   636/ 1097] train: loss: 0.1544416
[Epoch 13; Iter   666/ 1097] train: loss: 0.0260388
[Epoch 13; Iter   696/ 1097] train: loss: 0.1255115
[Epoch 13; Iter   726/ 1097] train: loss: 0.2828418
[Epoch 13; Iter   756/ 1097] train: loss: 0.2062012
[Epoch 13; Iter   786/ 1097] train: loss: 0.3575896
[Epoch 13; Iter   816/ 1097] train: loss: 0.4824998
[Epoch 13; Iter   846/ 1097] train: loss: 0.0389293
[Epoch 13; Iter   876/ 1097] train: loss: 0.0486570
[Epoch 13; Iter   906/ 1097] train: loss: 0.4869894
[Epoch 13; Iter   936/ 1097] train: loss: 0.0250396
[Epoch 13; Iter   966/ 1097] train: loss: 0.0884222
[Epoch 13; Iter   996/ 1097] train: loss: 0.0538020
[Epoch 13; Iter  1026/ 1097] train: loss: 0.2407658
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1215972
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2872016
[Epoch 13] ogbg-molhiv: 0.799664 val loss: 0.074427
[Epoch 13] ogbg-molhiv: 0.736988 test loss: 0.118992
[Epoch 14; Iter    19/ 1097] train: loss: 0.0390771
[Epoch 14; Iter    49/ 1097] train: loss: 0.0229214
[Epoch 14; Iter    79/ 1097] train: loss: 0.2684006
[Epoch 14; Iter   109/ 1097] train: loss: 0.2060014
[Epoch 14; Iter   139/ 1097] train: loss: 0.1710609
[Epoch 14; Iter   169/ 1097] train: loss: 0.1144469
[Epoch 14; Iter   199/ 1097] train: loss: 0.0318527
[Epoch 14; Iter   229/ 1097] train: loss: 0.1293938
[Epoch 14; Iter   259/ 1097] train: loss: 0.0201200
[Epoch 14; Iter   289/ 1097] train: loss: 0.0938697
[Epoch 14; Iter   319/ 1097] train: loss: 0.1358570
[Epoch 14; Iter   349/ 1097] train: loss: 0.0330517
[Epoch 14; Iter   379/ 1097] train: loss: 0.0591427
[Epoch 14; Iter   409/ 1097] train: loss: 0.0250735
[Epoch 14; Iter   439/ 1097] train: loss: 0.1551157
[Epoch 14; Iter   469/ 1097] train: loss: 0.1860911
[Epoch 14; Iter   499/ 1097] train: loss: 0.1324528
[Epoch 14; Iter   529/ 1097] train: loss: 0.0410524
[Epoch 14; Iter   559/ 1097] train: loss: 0.1663669
[Epoch 14; Iter   589/ 1097] train: loss: 0.0762312
[Epoch 14; Iter   619/ 1097] train: loss: 0.1583393
[Epoch 14; Iter   649/ 1097] train: loss: 0.1878099
[Epoch 14; Iter   679/ 1097] train: loss: 0.0261141
[Epoch 14; Iter   709/ 1097] train: loss: 0.1173639
[Epoch 14; Iter   739/ 1097] train: loss: 0.0380820
[Epoch 14; Iter   769/ 1097] train: loss: 0.0212231
[Epoch 14; Iter   799/ 1097] train: loss: 0.0571731
[Epoch 14; Iter   829/ 1097] train: loss: 0.1597296
[Epoch 14; Iter   859/ 1097] train: loss: 0.1500994
[Epoch 14; Iter   889/ 1097] train: loss: 0.0288307
[Epoch 14; Iter   919/ 1097] train: loss: 0.0224366
[Epoch 14; Iter   949/ 1097] train: loss: 0.0189819
[Epoch 14; Iter   979/ 1097] train: loss: 0.2634000
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0312684
[Epoch 14; Iter  1039/ 1097] train: loss: 0.3230089
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0327122
[Epoch 14] ogbg-molhiv: 0.778066 val loss: 0.095208
[Epoch 14] ogbg-molhiv: 0.736150 test loss: 0.117682
[Epoch 15; Iter     2/ 1097] train: loss: 0.0566224
[Epoch 15; Iter    32/ 1097] train: loss: 0.0251964
[Epoch 15; Iter    62/ 1097] train: loss: 0.1141759
[Epoch 15; Iter    92/ 1097] train: loss: 0.0694852
[Epoch 15; Iter   122/ 1097] train: loss: 0.0286885
[Epoch 15; Iter   152/ 1097] train: loss: 0.1981373
[Epoch 15; Iter   182/ 1097] train: loss: 0.0274919
[Epoch 15; Iter   212/ 1097] train: loss: 0.2634660
[Epoch 15; Iter   242/ 1097] train: loss: 0.0533123
[Epoch 15; Iter   272/ 1097] train: loss: 0.0468515
[Epoch 15; Iter   302/ 1097] train: loss: 0.1533798
[Epoch 15; Iter   332/ 1097] train: loss: 0.0759255
[Epoch 15; Iter   362/ 1097] train: loss: 0.1973445
[Epoch 15; Iter   392/ 1097] train: loss: 0.0998922
[Epoch 15; Iter   422/ 1097] train: loss: 0.0285953
[Epoch 15; Iter   452/ 1097] train: loss: 0.2423288
[Epoch 15; Iter   482/ 1097] train: loss: 0.0383386
[Epoch 15; Iter   512/ 1097] train: loss: 0.1939064
[Epoch 15; Iter   542/ 1097] train: loss: 0.0393253
[Epoch 15; Iter   572/ 1097] train: loss: 0.1125653
[Epoch 15; Iter   602/ 1097] train: loss: 0.0220473
[Epoch 15; Iter   632/ 1097] train: loss: 0.1074309
[Epoch 15; Iter   662/ 1097] train: loss: 0.1011115
[Epoch 15; Iter   692/ 1097] train: loss: 0.0836988
[Epoch 15; Iter   722/ 1097] train: loss: 0.2955966
[Epoch 15; Iter   752/ 1097] train: loss: 0.1053728
[Epoch 15; Iter   782/ 1097] train: loss: 0.1799072
[Epoch 15; Iter   812/ 1097] train: loss: 0.0220616
[Epoch 15; Iter   842/ 1097] train: loss: 0.2368161
[Epoch 15; Iter   872/ 1097] train: loss: 0.0617403
[Epoch 15; Iter   902/ 1097] train: loss: 0.0861784
[Epoch 15; Iter   932/ 1097] train: loss: 0.0248713
[Epoch 15; Iter   962/ 1097] train: loss: 0.1348131
[Epoch 15; Iter   992/ 1097] train: loss: 0.1380913
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5257371
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0330111
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0518121
[Epoch 15] ogbg-molhiv: 0.789637 val loss: 0.090757
[Epoch 15] ogbg-molhiv: 0.738626 test loss: 0.133966
[Epoch 16; Iter    15/ 1097] train: loss: 0.1525160
[Epoch 16; Iter    45/ 1097] train: loss: 0.0772237
[Epoch 16; Iter    75/ 1097] train: loss: 0.0789752
[Epoch 16; Iter   105/ 1097] train: loss: 0.0839617
[Epoch 16; Iter   135/ 1097] train: loss: 0.0466368
[Epoch 16; Iter   165/ 1097] train: loss: 0.4879561
[Epoch 12; Iter   113/ 1097] train: loss: 0.1297673
[Epoch 12; Iter   143/ 1097] train: loss: 0.3458854
[Epoch 12; Iter   173/ 1097] train: loss: 0.0396053
[Epoch 12; Iter   203/ 1097] train: loss: 0.0287437
[Epoch 12; Iter   233/ 1097] train: loss: 0.0248574
[Epoch 12; Iter   263/ 1097] train: loss: 0.0443517
[Epoch 12; Iter   293/ 1097] train: loss: 0.1437746
[Epoch 12; Iter   323/ 1097] train: loss: 0.1366216
[Epoch 12; Iter   353/ 1097] train: loss: 0.2472328
[Epoch 12; Iter   383/ 1097] train: loss: 0.0516775
[Epoch 12; Iter   413/ 1097] train: loss: 0.2839785
[Epoch 12; Iter   443/ 1097] train: loss: 0.3939895
[Epoch 12; Iter   473/ 1097] train: loss: 0.1583869
[Epoch 12; Iter   503/ 1097] train: loss: 0.1708504
[Epoch 12; Iter   533/ 1097] train: loss: 0.1384032
[Epoch 12; Iter   563/ 1097] train: loss: 0.1166448
[Epoch 12; Iter   593/ 1097] train: loss: 0.3019352
[Epoch 12; Iter   623/ 1097] train: loss: 0.2592213
[Epoch 12; Iter   653/ 1097] train: loss: 0.0436505
[Epoch 12; Iter   683/ 1097] train: loss: 0.1790846
[Epoch 12; Iter   713/ 1097] train: loss: 0.0498176
[Epoch 12; Iter   743/ 1097] train: loss: 0.2061368
[Epoch 12; Iter   773/ 1097] train: loss: 0.0338754
[Epoch 12; Iter   803/ 1097] train: loss: 0.1673382
[Epoch 12; Iter   833/ 1097] train: loss: 0.1937414
[Epoch 12; Iter   863/ 1097] train: loss: 0.2538062
[Epoch 12; Iter   893/ 1097] train: loss: 0.0552980
[Epoch 12; Iter   923/ 1097] train: loss: 0.1928187
[Epoch 12; Iter   953/ 1097] train: loss: 0.2298831
[Epoch 12; Iter   983/ 1097] train: loss: 0.0774156
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0332194
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1296278
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0929294
[Epoch 12] ogbg-molhiv: 0.796008 val loss: 0.383467
[Epoch 12] ogbg-molhiv: 0.783157 test loss: 0.294955
[Epoch 13; Iter     6/ 1097] train: loss: 0.0624397
[Epoch 13; Iter    36/ 1097] train: loss: 0.3212068
[Epoch 13; Iter    66/ 1097] train: loss: 0.1441073
[Epoch 13; Iter    96/ 1097] train: loss: 0.0398011
[Epoch 13; Iter   126/ 1097] train: loss: 0.0238858
[Epoch 13; Iter   156/ 1097] train: loss: 0.0180928
[Epoch 13; Iter   186/ 1097] train: loss: 0.1765874
[Epoch 13; Iter   216/ 1097] train: loss: 0.1807935
[Epoch 13; Iter   246/ 1097] train: loss: 0.0320063
[Epoch 13; Iter   276/ 1097] train: loss: 0.1096583
[Epoch 13; Iter   306/ 1097] train: loss: 0.0234602
[Epoch 13; Iter   336/ 1097] train: loss: 0.1744352
[Epoch 13; Iter   366/ 1097] train: loss: 0.1597393
[Epoch 13; Iter   396/ 1097] train: loss: 0.0887960
[Epoch 13; Iter   426/ 1097] train: loss: 0.0580888
[Epoch 13; Iter   456/ 1097] train: loss: 0.0369397
[Epoch 13; Iter   486/ 1097] train: loss: 0.0378351
[Epoch 13; Iter   516/ 1097] train: loss: 0.0340446
[Epoch 13; Iter   546/ 1097] train: loss: 0.0233815
[Epoch 13; Iter   576/ 1097] train: loss: 0.1526826
[Epoch 13; Iter   606/ 1097] train: loss: 0.0895517
[Epoch 13; Iter   636/ 1097] train: loss: 0.3355057
[Epoch 13; Iter   666/ 1097] train: loss: 0.0373356
[Epoch 13; Iter   696/ 1097] train: loss: 0.0462606
[Epoch 13; Iter   726/ 1097] train: loss: 0.1147591
[Epoch 13; Iter   756/ 1097] train: loss: 0.0494150
[Epoch 13; Iter   786/ 1097] train: loss: 0.1270122
[Epoch 13; Iter   816/ 1097] train: loss: 0.0261434
[Epoch 13; Iter   846/ 1097] train: loss: 0.0206291
[Epoch 13; Iter   876/ 1097] train: loss: 0.1814284
[Epoch 13; Iter   906/ 1097] train: loss: 0.2989038
[Epoch 13; Iter   936/ 1097] train: loss: 0.1990265
[Epoch 13; Iter   966/ 1097] train: loss: 0.1096871
[Epoch 13; Iter   996/ 1097] train: loss: 0.0858802
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3107713
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2192893
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1621258
[Epoch 13] ogbg-molhiv: 0.794634 val loss: 0.319401
[Epoch 13] ogbg-molhiv: 0.779028 test loss: 0.108165
[Epoch 14; Iter    19/ 1097] train: loss: 0.0259621
[Epoch 14; Iter    49/ 1097] train: loss: 0.3677483
[Epoch 14; Iter    79/ 1097] train: loss: 0.0346963
[Epoch 14; Iter   109/ 1097] train: loss: 0.0331859
[Epoch 14; Iter   139/ 1097] train: loss: 0.0900217
[Epoch 14; Iter   169/ 1097] train: loss: 0.1442872
[Epoch 14; Iter   199/ 1097] train: loss: 0.0828397
[Epoch 14; Iter   229/ 1097] train: loss: 0.0239415
[Epoch 14; Iter   259/ 1097] train: loss: 0.0526889
[Epoch 14; Iter   289/ 1097] train: loss: 0.0818356
[Epoch 14; Iter   319/ 1097] train: loss: 0.2483145
[Epoch 14; Iter   349/ 1097] train: loss: 0.1441161
[Epoch 14; Iter   379/ 1097] train: loss: 0.1585103
[Epoch 14; Iter   409/ 1097] train: loss: 0.1068593
[Epoch 14; Iter   439/ 1097] train: loss: 0.1749269
[Epoch 14; Iter   469/ 1097] train: loss: 0.1365421
[Epoch 14; Iter   499/ 1097] train: loss: 0.0233780
[Epoch 14; Iter   529/ 1097] train: loss: 0.0273453
[Epoch 14; Iter   559/ 1097] train: loss: 0.2440830
[Epoch 14; Iter   589/ 1097] train: loss: 0.0299494
[Epoch 14; Iter   619/ 1097] train: loss: 0.0553161
[Epoch 14; Iter   649/ 1097] train: loss: 0.0470413
[Epoch 14; Iter   679/ 1097] train: loss: 0.1089251
[Epoch 14; Iter   709/ 1097] train: loss: 0.2036405
[Epoch 14; Iter   739/ 1097] train: loss: 0.0677655
[Epoch 14; Iter   769/ 1097] train: loss: 0.1731115
[Epoch 14; Iter   799/ 1097] train: loss: 0.0317940
[Epoch 14; Iter   829/ 1097] train: loss: 0.1105493
[Epoch 14; Iter   859/ 1097] train: loss: 0.0370420
[Epoch 14; Iter   889/ 1097] train: loss: 0.0291967
[Epoch 14; Iter   919/ 1097] train: loss: 0.0742343
[Epoch 14; Iter   949/ 1097] train: loss: 0.0378345
[Epoch 14; Iter   979/ 1097] train: loss: 0.1700593
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0229392
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0576487
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1886233
[Epoch 14] ogbg-molhiv: 0.804873 val loss: 0.358339
[Epoch 14] ogbg-molhiv: 0.788142 test loss: 0.112465
[Epoch 15; Iter     2/ 1097] train: loss: 0.1356313
[Epoch 15; Iter    32/ 1097] train: loss: 0.0357425
[Epoch 15; Iter    62/ 1097] train: loss: 0.1898621
[Epoch 15; Iter    92/ 1097] train: loss: 0.0182935
[Epoch 15; Iter   122/ 1097] train: loss: 0.1826897
[Epoch 15; Iter   152/ 1097] train: loss: 0.2001552
[Epoch 15; Iter   182/ 1097] train: loss: 0.2384049
[Epoch 15; Iter   212/ 1097] train: loss: 0.0258251
[Epoch 15; Iter   242/ 1097] train: loss: 0.0352990
[Epoch 15; Iter   272/ 1097] train: loss: 0.1647257
[Epoch 15; Iter   302/ 1097] train: loss: 0.2055202
[Epoch 15; Iter   332/ 1097] train: loss: 0.0515453
[Epoch 15; Iter   362/ 1097] train: loss: 0.1404577
[Epoch 15; Iter   392/ 1097] train: loss: 0.1913417
[Epoch 15; Iter   422/ 1097] train: loss: 0.2025922
[Epoch 15; Iter   452/ 1097] train: loss: 0.0422733
[Epoch 15; Iter   482/ 1097] train: loss: 0.0984364
[Epoch 15; Iter   512/ 1097] train: loss: 0.2821017
[Epoch 15; Iter   542/ 1097] train: loss: 0.0728659
[Epoch 15; Iter   572/ 1097] train: loss: 0.0231773
[Epoch 15; Iter   602/ 1097] train: loss: 0.4818264
[Epoch 15; Iter   632/ 1097] train: loss: 0.0251198
[Epoch 15; Iter   662/ 1097] train: loss: 0.1459223
[Epoch 15; Iter   692/ 1097] train: loss: 0.0355269
[Epoch 15; Iter   722/ 1097] train: loss: 0.0495984
[Epoch 15; Iter   752/ 1097] train: loss: 0.1603836
[Epoch 15; Iter   782/ 1097] train: loss: 0.1897371
[Epoch 15; Iter   812/ 1097] train: loss: 0.1144224
[Epoch 15; Iter   842/ 1097] train: loss: 0.0300946
[Epoch 15; Iter   872/ 1097] train: loss: 0.0328306
[Epoch 15; Iter   902/ 1097] train: loss: 0.2149000
[Epoch 15; Iter   932/ 1097] train: loss: 0.0735091
[Epoch 15; Iter   962/ 1097] train: loss: 0.0426048
[Epoch 15; Iter   992/ 1097] train: loss: 0.0381921
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0171491
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0480217
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0236741
[Epoch 15] ogbg-molhiv: 0.773908 val loss: 0.078630
[Epoch 15] ogbg-molhiv: 0.765853 test loss: 0.113803
[Epoch 16; Iter    15/ 1097] train: loss: 0.1159702
[Epoch 16; Iter    45/ 1097] train: loss: 0.0283721
[Epoch 16; Iter    75/ 1097] train: loss: 0.0179155
[Epoch 16; Iter   105/ 1097] train: loss: 0.0193085
[Epoch 16; Iter   135/ 1097] train: loss: 0.0203301
[Epoch 16; Iter   165/ 1097] train: loss: 0.2493463
[Epoch 12; Iter   113/ 1097] train: loss: 0.0570040
[Epoch 12; Iter   143/ 1097] train: loss: 0.1594424
[Epoch 12; Iter   173/ 1097] train: loss: 0.3966813
[Epoch 12; Iter   203/ 1097] train: loss: 0.0997681
[Epoch 12; Iter   233/ 1097] train: loss: 0.3101975
[Epoch 12; Iter   263/ 1097] train: loss: 0.1482430
[Epoch 12; Iter   293/ 1097] train: loss: 0.0921489
[Epoch 12; Iter   323/ 1097] train: loss: 0.0638328
[Epoch 12; Iter   353/ 1097] train: loss: 0.0282518
[Epoch 12; Iter   383/ 1097] train: loss: 0.1577452
[Epoch 12; Iter   413/ 1097] train: loss: 0.0384672
[Epoch 12; Iter   443/ 1097] train: loss: 0.1264707
[Epoch 12; Iter   473/ 1097] train: loss: 0.0349765
[Epoch 12; Iter   503/ 1097] train: loss: 0.1102511
[Epoch 12; Iter   533/ 1097] train: loss: 0.1099998
[Epoch 12; Iter   563/ 1097] train: loss: 0.1490334
[Epoch 12; Iter   593/ 1097] train: loss: 0.4122316
[Epoch 12; Iter   623/ 1097] train: loss: 0.0245391
[Epoch 12; Iter   653/ 1097] train: loss: 0.0269770
[Epoch 12; Iter   683/ 1097] train: loss: 0.0547691
[Epoch 12; Iter   713/ 1097] train: loss: 0.2140586
[Epoch 12; Iter   743/ 1097] train: loss: 0.0324761
[Epoch 12; Iter   773/ 1097] train: loss: 0.2942446
[Epoch 12; Iter   803/ 1097] train: loss: 0.0727606
[Epoch 12; Iter   833/ 1097] train: loss: 0.0493658
[Epoch 12; Iter   863/ 1097] train: loss: 0.0314813
[Epoch 12; Iter   893/ 1097] train: loss: 0.1296354
[Epoch 12; Iter   923/ 1097] train: loss: 0.0364778
[Epoch 12; Iter   953/ 1097] train: loss: 0.0611571
[Epoch 12; Iter   983/ 1097] train: loss: 0.1773597
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0322489
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2779809
[Epoch 12; Iter  1073/ 1097] train: loss: 0.2198070
[Epoch 12] ogbg-molhiv: 0.705201 val loss: 0.806138
[Epoch 12] ogbg-molhiv: 0.639935 test loss: 1.100626
[Epoch 13; Iter     6/ 1097] train: loss: 0.0816804
[Epoch 13; Iter    36/ 1097] train: loss: 0.0367393
[Epoch 13; Iter    66/ 1097] train: loss: 0.0837976
[Epoch 13; Iter    96/ 1097] train: loss: 0.0442575
[Epoch 13; Iter   126/ 1097] train: loss: 0.0316263
[Epoch 13; Iter   156/ 1097] train: loss: 0.2452122
[Epoch 13; Iter   186/ 1097] train: loss: 0.1175728
[Epoch 13; Iter   216/ 1097] train: loss: 0.1460671
[Epoch 13; Iter   246/ 1097] train: loss: 0.1375736
[Epoch 13; Iter   276/ 1097] train: loss: 0.0350768
[Epoch 13; Iter   306/ 1097] train: loss: 0.0289854
[Epoch 13; Iter   336/ 1097] train: loss: 0.0295921
[Epoch 13; Iter   366/ 1097] train: loss: 0.0230003
[Epoch 13; Iter   396/ 1097] train: loss: 0.2621998
[Epoch 13; Iter   426/ 1097] train: loss: 0.0205443
[Epoch 13; Iter   456/ 1097] train: loss: 0.1971339
[Epoch 13; Iter   486/ 1097] train: loss: 0.0357200
[Epoch 13; Iter   516/ 1097] train: loss: 0.2108491
[Epoch 13; Iter   546/ 1097] train: loss: 0.2128333
[Epoch 13; Iter   576/ 1097] train: loss: 0.2109728
[Epoch 13; Iter   606/ 1097] train: loss: 0.0336554
[Epoch 13; Iter   636/ 1097] train: loss: 0.1225473
[Epoch 13; Iter   666/ 1097] train: loss: 0.0344550
[Epoch 13; Iter   696/ 1097] train: loss: 0.1257067
[Epoch 13; Iter   726/ 1097] train: loss: 0.2683051
[Epoch 13; Iter   756/ 1097] train: loss: 0.1661045
[Epoch 13; Iter   786/ 1097] train: loss: 0.3594030
[Epoch 13; Iter   816/ 1097] train: loss: 0.5063790
[Epoch 13; Iter   846/ 1097] train: loss: 0.0571561
[Epoch 13; Iter   876/ 1097] train: loss: 0.0372182
[Epoch 13; Iter   906/ 1097] train: loss: 0.4219241
[Epoch 13; Iter   936/ 1097] train: loss: 0.0300987
[Epoch 13; Iter   966/ 1097] train: loss: 0.1900027
[Epoch 13; Iter   996/ 1097] train: loss: 0.1340146
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1203747
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1122345
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1696740
[Epoch 13] ogbg-molhiv: 0.748552 val loss: 0.086130
[Epoch 13] ogbg-molhiv: 0.731752 test loss: 0.128816
[Epoch 14; Iter    19/ 1097] train: loss: 0.0253346
[Epoch 14; Iter    49/ 1097] train: loss: 0.0345618
[Epoch 14; Iter    79/ 1097] train: loss: 0.2606000
[Epoch 14; Iter   109/ 1097] train: loss: 0.1448229
[Epoch 14; Iter   139/ 1097] train: loss: 0.0184194
[Epoch 14; Iter   169/ 1097] train: loss: 0.1012962
[Epoch 14; Iter   199/ 1097] train: loss: 0.0604595
[Epoch 14; Iter   229/ 1097] train: loss: 0.1495288
[Epoch 14; Iter   259/ 1097] train: loss: 0.0973421
[Epoch 14; Iter   289/ 1097] train: loss: 0.1394592
[Epoch 14; Iter   319/ 1097] train: loss: 0.0891629
[Epoch 14; Iter   349/ 1097] train: loss: 0.0298662
[Epoch 14; Iter   379/ 1097] train: loss: 0.0774314
[Epoch 14; Iter   409/ 1097] train: loss: 0.0395629
[Epoch 14; Iter   439/ 1097] train: loss: 0.1192477
[Epoch 14; Iter   469/ 1097] train: loss: 0.1521373
[Epoch 14; Iter   499/ 1097] train: loss: 0.0872791
[Epoch 14; Iter   529/ 1097] train: loss: 0.0883183
[Epoch 14; Iter   559/ 1097] train: loss: 0.2606839
[Epoch 14; Iter   589/ 1097] train: loss: 0.1147397
[Epoch 14; Iter   619/ 1097] train: loss: 0.1788400
[Epoch 14; Iter   649/ 1097] train: loss: 0.1253344
[Epoch 14; Iter   679/ 1097] train: loss: 0.0306015
[Epoch 14; Iter   709/ 1097] train: loss: 0.0275869
[Epoch 14; Iter   739/ 1097] train: loss: 0.0747601
[Epoch 14; Iter   769/ 1097] train: loss: 0.0204387
[Epoch 14; Iter   799/ 1097] train: loss: 0.0385890
[Epoch 14; Iter   829/ 1097] train: loss: 0.0583329
[Epoch 14; Iter   859/ 1097] train: loss: 0.3172270
[Epoch 14; Iter   889/ 1097] train: loss: 0.0275139
[Epoch 14; Iter   919/ 1097] train: loss: 0.0414375
[Epoch 14; Iter   949/ 1097] train: loss: 0.0415082
[Epoch 14; Iter   979/ 1097] train: loss: 0.2310881
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0668149
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2259447
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0637298
[Epoch 14] ogbg-molhiv: 0.681998 val loss: 0.259647
[Epoch 14] ogbg-molhiv: 0.561465 test loss: 0.186545
[Epoch 15; Iter     2/ 1097] train: loss: 0.1088164
[Epoch 15; Iter    32/ 1097] train: loss: 0.0434621
[Epoch 15; Iter    62/ 1097] train: loss: 0.0896616
[Epoch 15; Iter    92/ 1097] train: loss: 0.0311625
[Epoch 15; Iter   122/ 1097] train: loss: 0.0325489
[Epoch 15; Iter   152/ 1097] train: loss: 0.1877042
[Epoch 15; Iter   182/ 1097] train: loss: 0.0241836
[Epoch 15; Iter   212/ 1097] train: loss: 0.2058281
[Epoch 15; Iter   242/ 1097] train: loss: 0.0402091
[Epoch 15; Iter   272/ 1097] train: loss: 0.1121279
[Epoch 15; Iter   302/ 1097] train: loss: 0.1972688
[Epoch 15; Iter   332/ 1097] train: loss: 0.0565015
[Epoch 15; Iter   362/ 1097] train: loss: 0.2301279
[Epoch 15; Iter   392/ 1097] train: loss: 0.0448038
[Epoch 15; Iter   422/ 1097] train: loss: 0.0238687
[Epoch 15; Iter   452/ 1097] train: loss: 0.2074820
[Epoch 15; Iter   482/ 1097] train: loss: 0.0304154
[Epoch 15; Iter   512/ 1097] train: loss: 0.1893356
[Epoch 15; Iter   542/ 1097] train: loss: 0.0365995
[Epoch 15; Iter   572/ 1097] train: loss: 0.0520311
[Epoch 15; Iter   602/ 1097] train: loss: 0.0242105
[Epoch 15; Iter   632/ 1097] train: loss: 0.1423096
[Epoch 15; Iter   662/ 1097] train: loss: 0.1093613
[Epoch 15; Iter   692/ 1097] train: loss: 0.0359957
[Epoch 15; Iter   722/ 1097] train: loss: 0.2555593
[Epoch 15; Iter   752/ 1097] train: loss: 0.0519263
[Epoch 15; Iter   782/ 1097] train: loss: 0.1211761
[Epoch 15; Iter   812/ 1097] train: loss: 0.0376452
[Epoch 15; Iter   842/ 1097] train: loss: 0.2289744
[Epoch 15; Iter   872/ 1097] train: loss: 0.0399719
[Epoch 15; Iter   902/ 1097] train: loss: 0.1706586
[Epoch 15; Iter   932/ 1097] train: loss: 0.0283855
[Epoch 15; Iter   962/ 1097] train: loss: 0.1463002
[Epoch 15; Iter   992/ 1097] train: loss: 0.1594833
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4061910
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0284583
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0624610
[Epoch 15] ogbg-molhiv: 0.711377 val loss: 0.106964
[Epoch 15] ogbg-molhiv: 0.568418 test loss: 0.250263
[Epoch 16; Iter    15/ 1097] train: loss: 0.0502766
[Epoch 16; Iter    45/ 1097] train: loss: 0.0462517
[Epoch 16; Iter    75/ 1097] train: loss: 0.0827208
[Epoch 16; Iter   105/ 1097] train: loss: 0.1070042
[Epoch 16; Iter   135/ 1097] train: loss: 0.1250453
[Epoch 16; Iter   165/ 1097] train: loss: 0.5079370
[Epoch 12; Iter   113/ 1097] train: loss: 0.1800882
[Epoch 12; Iter   143/ 1097] train: loss: 0.2767417
[Epoch 12; Iter   173/ 1097] train: loss: 0.0450029
[Epoch 12; Iter   203/ 1097] train: loss: 0.0275066
[Epoch 12; Iter   233/ 1097] train: loss: 0.0318973
[Epoch 12; Iter   263/ 1097] train: loss: 0.1119440
[Epoch 12; Iter   293/ 1097] train: loss: 0.1671586
[Epoch 12; Iter   323/ 1097] train: loss: 0.1150803
[Epoch 12; Iter   353/ 1097] train: loss: 0.2314483
[Epoch 12; Iter   383/ 1097] train: loss: 0.0579999
[Epoch 12; Iter   413/ 1097] train: loss: 0.1716997
[Epoch 12; Iter   443/ 1097] train: loss: 0.3720330
[Epoch 12; Iter   473/ 1097] train: loss: 0.0941086
[Epoch 12; Iter   503/ 1097] train: loss: 0.2022551
[Epoch 12; Iter   533/ 1097] train: loss: 0.1528065
[Epoch 12; Iter   563/ 1097] train: loss: 0.1846519
[Epoch 12; Iter   593/ 1097] train: loss: 0.2885855
[Epoch 12; Iter   623/ 1097] train: loss: 0.3033346
[Epoch 12; Iter   653/ 1097] train: loss: 0.0981398
[Epoch 12; Iter   683/ 1097] train: loss: 0.1803191
[Epoch 12; Iter   713/ 1097] train: loss: 0.0381973
[Epoch 12; Iter   743/ 1097] train: loss: 0.1452599
[Epoch 12; Iter   773/ 1097] train: loss: 0.0399753
[Epoch 12; Iter   803/ 1097] train: loss: 0.1216307
[Epoch 12; Iter   833/ 1097] train: loss: 0.2042049
[Epoch 12; Iter   863/ 1097] train: loss: 0.2208758
[Epoch 12; Iter   893/ 1097] train: loss: 0.0353541
[Epoch 12; Iter   923/ 1097] train: loss: 0.1057827
[Epoch 12; Iter   953/ 1097] train: loss: 0.2613325
[Epoch 12; Iter   983/ 1097] train: loss: 0.0372464
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0612708
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1617166
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0635915
[Epoch 12] ogbg-molhiv: 0.771403 val loss: 0.097665
[Epoch 12] ogbg-molhiv: 0.682128 test loss: 0.139026
[Epoch 13; Iter     6/ 1097] train: loss: 0.1194711
[Epoch 13; Iter    36/ 1097] train: loss: 0.2348797
[Epoch 13; Iter    66/ 1097] train: loss: 0.1398819
[Epoch 13; Iter    96/ 1097] train: loss: 0.0890262
[Epoch 13; Iter   126/ 1097] train: loss: 0.0298110
[Epoch 13; Iter   156/ 1097] train: loss: 0.0232577
[Epoch 13; Iter   186/ 1097] train: loss: 0.1577979
[Epoch 13; Iter   216/ 1097] train: loss: 0.2237777
[Epoch 13; Iter   246/ 1097] train: loss: 0.0244277
[Epoch 13; Iter   276/ 1097] train: loss: 0.1834332
[Epoch 13; Iter   306/ 1097] train: loss: 0.0888792
[Epoch 13; Iter   336/ 1097] train: loss: 0.1148324
[Epoch 13; Iter   366/ 1097] train: loss: 0.1295346
[Epoch 13; Iter   396/ 1097] train: loss: 0.1307809
[Epoch 13; Iter   426/ 1097] train: loss: 0.1062820
[Epoch 13; Iter   456/ 1097] train: loss: 0.0443799
[Epoch 13; Iter   486/ 1097] train: loss: 0.0380081
[Epoch 13; Iter   516/ 1097] train: loss: 0.0373733
[Epoch 13; Iter   546/ 1097] train: loss: 0.0296936
[Epoch 13; Iter   576/ 1097] train: loss: 0.1528770
[Epoch 13; Iter   606/ 1097] train: loss: 0.0889626
[Epoch 13; Iter   636/ 1097] train: loss: 0.2817555
[Epoch 13; Iter   666/ 1097] train: loss: 0.0291271
[Epoch 13; Iter   696/ 1097] train: loss: 0.0640319
[Epoch 13; Iter   726/ 1097] train: loss: 0.1609488
[Epoch 13; Iter   756/ 1097] train: loss: 0.0337459
[Epoch 13; Iter   786/ 1097] train: loss: 0.1279309
[Epoch 13; Iter   816/ 1097] train: loss: 0.0266367
[Epoch 13; Iter   846/ 1097] train: loss: 0.0293114
[Epoch 13; Iter   876/ 1097] train: loss: 0.2342404
[Epoch 13; Iter   906/ 1097] train: loss: 0.4430356
[Epoch 13; Iter   936/ 1097] train: loss: 0.1911131
[Epoch 13; Iter   966/ 1097] train: loss: 0.1268188
[Epoch 13; Iter   996/ 1097] train: loss: 0.0415232
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3062696
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1640905
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1192025
[Epoch 13] ogbg-molhiv: 0.747587 val loss: 0.097580
[Epoch 13] ogbg-molhiv: 0.722814 test loss: 0.134254
[Epoch 14; Iter    19/ 1097] train: loss: 0.0332530
[Epoch 14; Iter    49/ 1097] train: loss: 0.1640180
[Epoch 14; Iter    79/ 1097] train: loss: 0.0380358
[Epoch 14; Iter   109/ 1097] train: loss: 0.0266187
[Epoch 14; Iter   139/ 1097] train: loss: 0.0653795
[Epoch 14; Iter   169/ 1097] train: loss: 0.1922718
[Epoch 14; Iter   199/ 1097] train: loss: 0.0305042
[Epoch 14; Iter   229/ 1097] train: loss: 0.0202506
[Epoch 14; Iter   259/ 1097] train: loss: 0.0618143
[Epoch 14; Iter   289/ 1097] train: loss: 0.0818420
[Epoch 14; Iter   319/ 1097] train: loss: 0.0671960
[Epoch 14; Iter   349/ 1097] train: loss: 0.3580493
[Epoch 14; Iter   379/ 1097] train: loss: 0.1055183
[Epoch 14; Iter   409/ 1097] train: loss: 0.0438045
[Epoch 14; Iter   439/ 1097] train: loss: 0.1291242
[Epoch 14; Iter   469/ 1097] train: loss: 0.1268187
[Epoch 14; Iter   499/ 1097] train: loss: 0.0286342
[Epoch 14; Iter   529/ 1097] train: loss: 0.0251095
[Epoch 14; Iter   559/ 1097] train: loss: 0.2632654
[Epoch 14; Iter   589/ 1097] train: loss: 0.0269487
[Epoch 14; Iter   619/ 1097] train: loss: 0.1103789
[Epoch 14; Iter   649/ 1097] train: loss: 0.0344403
[Epoch 14; Iter   679/ 1097] train: loss: 0.0787480
[Epoch 14; Iter   709/ 1097] train: loss: 0.1086125
[Epoch 14; Iter   739/ 1097] train: loss: 0.0711471
[Epoch 14; Iter   769/ 1097] train: loss: 0.1281912
[Epoch 14; Iter   799/ 1097] train: loss: 0.0354066
[Epoch 14; Iter   829/ 1097] train: loss: 0.0856926
[Epoch 14; Iter   859/ 1097] train: loss: 0.0287054
[Epoch 14; Iter   889/ 1097] train: loss: 0.0397279
[Epoch 14; Iter   919/ 1097] train: loss: 0.0635700
[Epoch 14; Iter   949/ 1097] train: loss: 0.0365198
[Epoch 14; Iter   979/ 1097] train: loss: 0.0815539
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0190098
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0497267
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1514545
[Epoch 14] ogbg-molhiv: 0.769443 val loss: 0.081541
[Epoch 14] ogbg-molhiv: 0.641467 test loss: 0.139515
[Epoch 15; Iter     2/ 1097] train: loss: 0.1591931
[Epoch 15; Iter    32/ 1097] train: loss: 0.0361470
[Epoch 15; Iter    62/ 1097] train: loss: 0.1340653
[Epoch 15; Iter    92/ 1097] train: loss: 0.0330608
[Epoch 15; Iter   122/ 1097] train: loss: 0.1308079
[Epoch 15; Iter   152/ 1097] train: loss: 0.1053607
[Epoch 15; Iter   182/ 1097] train: loss: 0.1864206
[Epoch 15; Iter   212/ 1097] train: loss: 0.0369725
[Epoch 15; Iter   242/ 1097] train: loss: 0.0378930
[Epoch 15; Iter   272/ 1097] train: loss: 0.0723994
[Epoch 15; Iter   302/ 1097] train: loss: 0.1764978
[Epoch 15; Iter   332/ 1097] train: loss: 0.0187920
[Epoch 15; Iter   362/ 1097] train: loss: 0.1344375
[Epoch 15; Iter   392/ 1097] train: loss: 0.1098052
[Epoch 15; Iter   422/ 1097] train: loss: 0.2249882
[Epoch 15; Iter   452/ 1097] train: loss: 0.0258927
[Epoch 15; Iter   482/ 1097] train: loss: 0.1080357
[Epoch 15; Iter   512/ 1097] train: loss: 0.3746959
[Epoch 15; Iter   542/ 1097] train: loss: 0.0263488
[Epoch 15; Iter   572/ 1097] train: loss: 0.0376851
[Epoch 15; Iter   602/ 1097] train: loss: 0.4045115
[Epoch 15; Iter   632/ 1097] train: loss: 0.0288885
[Epoch 15; Iter   662/ 1097] train: loss: 0.1352732
[Epoch 15; Iter   692/ 1097] train: loss: 0.0250065
[Epoch 15; Iter   722/ 1097] train: loss: 0.1300296
[Epoch 15; Iter   752/ 1097] train: loss: 0.1816046
[Epoch 15; Iter   782/ 1097] train: loss: 0.1756212
[Epoch 15; Iter   812/ 1097] train: loss: 0.1120944
[Epoch 15; Iter   842/ 1097] train: loss: 0.0318286
[Epoch 15; Iter   872/ 1097] train: loss: 0.0270663
[Epoch 15; Iter   902/ 1097] train: loss: 0.1698593
[Epoch 15; Iter   932/ 1097] train: loss: 0.0324590
[Epoch 15; Iter   962/ 1097] train: loss: 0.0466581
[Epoch 15; Iter   992/ 1097] train: loss: 0.0866030
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0182130
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1812629
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0280163
[Epoch 15] ogbg-molhiv: 0.794361 val loss: 0.136143
[Epoch 15] ogbg-molhiv: 0.700798 test loss: 0.133796
[Epoch 16; Iter    15/ 1097] train: loss: 0.1110721
[Epoch 16; Iter    45/ 1097] train: loss: 0.0329813
[Epoch 16; Iter    75/ 1097] train: loss: 0.0181932
[Epoch 16; Iter   105/ 1097] train: loss: 0.0322354
[Epoch 16; Iter   135/ 1097] train: loss: 0.0246746
[Epoch 16; Iter   165/ 1097] train: loss: 0.2575697
[Epoch 12; Iter   113/ 1097] train: loss: 0.0450383
[Epoch 12; Iter   143/ 1097] train: loss: 0.1778118
[Epoch 12; Iter   173/ 1097] train: loss: 0.0267386
[Epoch 12; Iter   203/ 1097] train: loss: 0.0948609
[Epoch 12; Iter   233/ 1097] train: loss: 0.0239323
[Epoch 12; Iter   263/ 1097] train: loss: 0.0529301
[Epoch 12; Iter   293/ 1097] train: loss: 0.1773189
[Epoch 12; Iter   323/ 1097] train: loss: 0.2213985
[Epoch 12; Iter   353/ 1097] train: loss: 0.1408374
[Epoch 12; Iter   383/ 1097] train: loss: 0.0395671
[Epoch 12; Iter   413/ 1097] train: loss: 0.0327149
[Epoch 12; Iter   443/ 1097] train: loss: 0.0257489
[Epoch 12; Iter   473/ 1097] train: loss: 0.2292518
[Epoch 12; Iter   503/ 1097] train: loss: 0.1549254
[Epoch 12; Iter   533/ 1097] train: loss: 0.0289622
[Epoch 12; Iter   563/ 1097] train: loss: 0.1452183
[Epoch 12; Iter   593/ 1097] train: loss: 0.1385876
[Epoch 12; Iter   623/ 1097] train: loss: 0.0340436
[Epoch 12; Iter   653/ 1097] train: loss: 0.1071204
[Epoch 12; Iter   683/ 1097] train: loss: 0.3713615
[Epoch 12; Iter   713/ 1097] train: loss: 0.1393153
[Epoch 12; Iter   743/ 1097] train: loss: 0.0215716
[Epoch 12; Iter   773/ 1097] train: loss: 0.2217527
[Epoch 12; Iter   803/ 1097] train: loss: 0.1499690
[Epoch 12; Iter   833/ 1097] train: loss: 0.0813637
[Epoch 12; Iter   863/ 1097] train: loss: 0.0536533
[Epoch 12; Iter   893/ 1097] train: loss: 0.1659314
[Epoch 12; Iter   923/ 1097] train: loss: 0.0341882
[Epoch 12; Iter   953/ 1097] train: loss: 0.2130359
[Epoch 12; Iter   983/ 1097] train: loss: 0.2968222
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0300492
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0242791
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0268590
[Epoch 12] ogbg-molhiv: 0.751320 val loss: 0.098338
[Epoch 12] ogbg-molhiv: 0.739931 test loss: 0.126321
[Epoch 13; Iter     6/ 1097] train: loss: 0.1466466
[Epoch 13; Iter    36/ 1097] train: loss: 0.1639759
[Epoch 13; Iter    66/ 1097] train: loss: 0.2437707
[Epoch 13; Iter    96/ 1097] train: loss: 0.0327839
[Epoch 13; Iter   126/ 1097] train: loss: 0.0589641
[Epoch 13; Iter   156/ 1097] train: loss: 0.2310124
[Epoch 13; Iter   186/ 1097] train: loss: 0.2517264
[Epoch 13; Iter   216/ 1097] train: loss: 0.1430513
[Epoch 13; Iter   246/ 1097] train: loss: 0.0445436
[Epoch 13; Iter   276/ 1097] train: loss: 0.0255186
[Epoch 13; Iter   306/ 1097] train: loss: 0.2882238
[Epoch 13; Iter   336/ 1097] train: loss: 0.1132547
[Epoch 13; Iter   366/ 1097] train: loss: 0.3375199
[Epoch 13; Iter   396/ 1097] train: loss: 0.0434309
[Epoch 13; Iter   426/ 1097] train: loss: 0.1298769
[Epoch 13; Iter   456/ 1097] train: loss: 0.1523434
[Epoch 13; Iter   486/ 1097] train: loss: 0.0315062
[Epoch 13; Iter   516/ 1097] train: loss: 0.1909712
[Epoch 13; Iter   546/ 1097] train: loss: 0.0232763
[Epoch 13; Iter   576/ 1097] train: loss: 0.1329808
[Epoch 13; Iter   606/ 1097] train: loss: 0.1797983
[Epoch 13; Iter   636/ 1097] train: loss: 0.0594977
[Epoch 13; Iter   666/ 1097] train: loss: 0.1680093
[Epoch 13; Iter   696/ 1097] train: loss: 0.3814094
[Epoch 13; Iter   726/ 1097] train: loss: 0.0667401
[Epoch 13; Iter   756/ 1097] train: loss: 0.0462843
[Epoch 13; Iter   786/ 1097] train: loss: 0.2181338
[Epoch 13; Iter   816/ 1097] train: loss: 0.0582273
[Epoch 13; Iter   846/ 1097] train: loss: 0.0390739
[Epoch 13; Iter   876/ 1097] train: loss: 0.2563255
[Epoch 13; Iter   906/ 1097] train: loss: 0.3106483
[Epoch 13; Iter   936/ 1097] train: loss: 0.0268958
[Epoch 13; Iter   966/ 1097] train: loss: 0.0876754
[Epoch 13; Iter   996/ 1097] train: loss: 0.0306684
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0350624
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1720634
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1673429
[Epoch 13] ogbg-molhiv: 0.733940 val loss: 0.164204
[Epoch 13] ogbg-molhiv: 0.663306 test loss: 0.155507
[Epoch 14; Iter    19/ 1097] train: loss: 0.2516912
[Epoch 14; Iter    49/ 1097] train: loss: 0.1235782
[Epoch 14; Iter    79/ 1097] train: loss: 0.0690616
[Epoch 14; Iter   109/ 1097] train: loss: 0.1344259
[Epoch 14; Iter   139/ 1097] train: loss: 0.0337073
[Epoch 14; Iter   169/ 1097] train: loss: 0.2388545
[Epoch 14; Iter   199/ 1097] train: loss: 0.0189775
[Epoch 14; Iter   229/ 1097] train: loss: 0.3794264
[Epoch 14; Iter   259/ 1097] train: loss: 0.3779158
[Epoch 14; Iter   289/ 1097] train: loss: 0.0598117
[Epoch 14; Iter   319/ 1097] train: loss: 0.0352410
[Epoch 14; Iter   349/ 1097] train: loss: 0.0535947
[Epoch 14; Iter   379/ 1097] train: loss: 0.0345164
[Epoch 14; Iter   409/ 1097] train: loss: 0.0779178
[Epoch 14; Iter   439/ 1097] train: loss: 0.2302901
[Epoch 14; Iter   469/ 1097] train: loss: 0.2466886
[Epoch 14; Iter   499/ 1097] train: loss: 0.0280686
[Epoch 14; Iter   529/ 1097] train: loss: 0.3422413
[Epoch 14; Iter   559/ 1097] train: loss: 0.0381256
[Epoch 14; Iter   589/ 1097] train: loss: 0.1751816
[Epoch 14; Iter   619/ 1097] train: loss: 0.2056190
[Epoch 14; Iter   649/ 1097] train: loss: 0.0545259
[Epoch 14; Iter   679/ 1097] train: loss: 0.0458577
[Epoch 14; Iter   709/ 1097] train: loss: 0.1575278
[Epoch 14; Iter   739/ 1097] train: loss: 0.1520590
[Epoch 14; Iter   769/ 1097] train: loss: 0.0189077
[Epoch 14; Iter   799/ 1097] train: loss: 0.0700045
[Epoch 14; Iter   829/ 1097] train: loss: 0.1392412
[Epoch 14; Iter   859/ 1097] train: loss: 0.0317811
[Epoch 14; Iter   889/ 1097] train: loss: 0.0958738
[Epoch 14; Iter   919/ 1097] train: loss: 0.1839984
[Epoch 14; Iter   949/ 1097] train: loss: 0.2199503
[Epoch 14; Iter   979/ 1097] train: loss: 0.0841629
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2678634
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0365662
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0548128
[Epoch 14] ogbg-molhiv: 0.728104 val loss: 0.107510
[Epoch 14] ogbg-molhiv: 0.702768 test loss: 0.140495
[Epoch 15; Iter     2/ 1097] train: loss: 0.0847699
[Epoch 15; Iter    32/ 1097] train: loss: 0.0762596
[Epoch 15; Iter    62/ 1097] train: loss: 0.0525654
[Epoch 15; Iter    92/ 1097] train: loss: 0.0500405
[Epoch 15; Iter   122/ 1097] train: loss: 0.1587272
[Epoch 15; Iter   152/ 1097] train: loss: 0.0229630
[Epoch 15; Iter   182/ 1097] train: loss: 0.1140600
[Epoch 15; Iter   212/ 1097] train: loss: 0.1775196
[Epoch 15; Iter   242/ 1097] train: loss: 0.1197053
[Epoch 15; Iter   272/ 1097] train: loss: 0.3284861
[Epoch 15; Iter   302/ 1097] train: loss: 0.1770988
[Epoch 15; Iter   332/ 1097] train: loss: 0.1495037
[Epoch 15; Iter   362/ 1097] train: loss: 0.1547594
[Epoch 15; Iter   392/ 1097] train: loss: 0.1967458
[Epoch 15; Iter   422/ 1097] train: loss: 0.1608159
[Epoch 15; Iter   452/ 1097] train: loss: 0.0418175
[Epoch 15; Iter   482/ 1097] train: loss: 0.1382853
[Epoch 15; Iter   512/ 1097] train: loss: 0.2822459
[Epoch 15; Iter   542/ 1097] train: loss: 0.1286837
[Epoch 15; Iter   572/ 1097] train: loss: 0.1084290
[Epoch 15; Iter   602/ 1097] train: loss: 0.0363544
[Epoch 15; Iter   632/ 1097] train: loss: 0.3491097
[Epoch 15; Iter   662/ 1097] train: loss: 0.0474288
[Epoch 15; Iter   692/ 1097] train: loss: 0.1121982
[Epoch 15; Iter   722/ 1097] train: loss: 0.0964209
[Epoch 15; Iter   752/ 1097] train: loss: 0.1168960
[Epoch 15; Iter   782/ 1097] train: loss: 0.0404918
[Epoch 15; Iter   812/ 1097] train: loss: 0.0223504
[Epoch 15; Iter   842/ 1097] train: loss: 0.0467726
[Epoch 15; Iter   872/ 1097] train: loss: 0.0235688
[Epoch 15; Iter   902/ 1097] train: loss: 0.0444430
[Epoch 15; Iter   932/ 1097] train: loss: 0.1923147
[Epoch 15; Iter   962/ 1097] train: loss: 0.2490098
[Epoch 15; Iter   992/ 1097] train: loss: 0.0374602
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1159616
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1160262
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0200637
[Epoch 15] ogbg-molhiv: 0.716484 val loss: 0.715847
[Epoch 15] ogbg-molhiv: 0.701321 test loss: 0.408725
[Epoch 16; Iter    15/ 1097] train: loss: 0.0278147
[Epoch 16; Iter    45/ 1097] train: loss: 0.0783074
[Epoch 16; Iter    75/ 1097] train: loss: 0.1624601
[Epoch 16; Iter   105/ 1097] train: loss: 0.0267519
[Epoch 16; Iter   135/ 1097] train: loss: 0.0938684
[Epoch 16; Iter   165/ 1097] train: loss: 0.1169981
[Epoch 16; Iter   195/ 1097] train: loss: 0.0834135
[Epoch 16; Iter   225/ 1097] train: loss: 0.0424897
[Epoch 16; Iter   255/ 1097] train: loss: 0.0524732
[Epoch 16; Iter   285/ 1097] train: loss: 0.1336714
[Epoch 16; Iter   315/ 1097] train: loss: 0.0734878
[Epoch 16; Iter   345/ 1097] train: loss: 0.0510215
[Epoch 16; Iter   375/ 1097] train: loss: 0.1956032
[Epoch 16; Iter   405/ 1097] train: loss: 0.2136986
[Epoch 16; Iter   435/ 1097] train: loss: 0.1074445
[Epoch 16; Iter   465/ 1097] train: loss: 0.1219115
[Epoch 16; Iter   495/ 1097] train: loss: 0.1240761
[Epoch 16; Iter   525/ 1097] train: loss: 0.0896011
[Epoch 16; Iter   555/ 1097] train: loss: 0.0261420
[Epoch 16; Iter   585/ 1097] train: loss: 0.1175992
[Epoch 16; Iter   615/ 1097] train: loss: 0.1902802
[Epoch 16; Iter   645/ 1097] train: loss: 0.0225352
[Epoch 16; Iter   675/ 1097] train: loss: 0.0672526
[Epoch 16; Iter   705/ 1097] train: loss: 0.1641947
[Epoch 16; Iter   735/ 1097] train: loss: 0.0661413
[Epoch 16; Iter   765/ 1097] train: loss: 0.0314364
[Epoch 16; Iter   795/ 1097] train: loss: 0.1295800
[Epoch 16; Iter   825/ 1097] train: loss: 0.0268828
[Epoch 16; Iter   855/ 1097] train: loss: 0.0985743
[Epoch 16; Iter   885/ 1097] train: loss: 0.1866173
[Epoch 16; Iter   915/ 1097] train: loss: 0.0235791
[Epoch 16; Iter   945/ 1097] train: loss: 0.0254358
[Epoch 16; Iter   975/ 1097] train: loss: 0.0236218
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0518658
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0347914
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0976603
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1383671
[Epoch 16] ogbg-molhiv: 0.768889 val loss: 0.078907
[Epoch 16] ogbg-molhiv: 0.752916 test loss: 0.119746
[Epoch 17; Iter    28/ 1097] train: loss: 0.0188549
[Epoch 17; Iter    58/ 1097] train: loss: 0.0344624
[Epoch 17; Iter    88/ 1097] train: loss: 0.0233626
[Epoch 17; Iter   118/ 1097] train: loss: 0.1496376
[Epoch 17; Iter   148/ 1097] train: loss: 0.1124697
[Epoch 17; Iter   178/ 1097] train: loss: 0.0314956
[Epoch 17; Iter   208/ 1097] train: loss: 0.0224744
[Epoch 17; Iter   238/ 1097] train: loss: 0.2913436
[Epoch 17; Iter   268/ 1097] train: loss: 0.0182701
[Epoch 17; Iter   298/ 1097] train: loss: 0.0366535
[Epoch 17; Iter   328/ 1097] train: loss: 0.0265793
[Epoch 17; Iter   358/ 1097] train: loss: 0.0343026
[Epoch 17; Iter   388/ 1097] train: loss: 0.0520152
[Epoch 17; Iter   418/ 1097] train: loss: 0.2955225
[Epoch 17; Iter   448/ 1097] train: loss: 0.0231950
[Epoch 17; Iter   478/ 1097] train: loss: 0.1057376
[Epoch 17; Iter   508/ 1097] train: loss: 0.0259259
[Epoch 17; Iter   538/ 1097] train: loss: 0.2812830
[Epoch 17; Iter   568/ 1097] train: loss: 0.1631351
[Epoch 17; Iter   598/ 1097] train: loss: 0.0946305
[Epoch 17; Iter   628/ 1097] train: loss: 0.0486116
[Epoch 17; Iter   658/ 1097] train: loss: 0.0315751
[Epoch 17; Iter   688/ 1097] train: loss: 0.2028709
[Epoch 17; Iter   718/ 1097] train: loss: 0.0308717
[Epoch 17; Iter   748/ 1097] train: loss: 0.1241860
[Epoch 17; Iter   778/ 1097] train: loss: 0.0543409
[Epoch 17; Iter   808/ 1097] train: loss: 0.1054367
[Epoch 17; Iter   838/ 1097] train: loss: 0.0588390
[Epoch 17; Iter   868/ 1097] train: loss: 0.0253330
[Epoch 17; Iter   898/ 1097] train: loss: 0.2260761
[Epoch 17; Iter   928/ 1097] train: loss: 0.1540064
[Epoch 17; Iter   958/ 1097] train: loss: 0.1439238
[Epoch 17; Iter   988/ 1097] train: loss: 0.0466545
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0271222
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0285277
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2038584
[Epoch 17] ogbg-molhiv: 0.762061 val loss: 0.129405
[Epoch 17] ogbg-molhiv: 0.739126 test loss: 0.123449
[Epoch 18; Iter    11/ 1097] train: loss: 0.1119691
[Epoch 18; Iter    41/ 1097] train: loss: 0.2601064
[Epoch 18; Iter    71/ 1097] train: loss: 0.0590092
[Epoch 18; Iter   101/ 1097] train: loss: 0.1351019
[Epoch 18; Iter   131/ 1097] train: loss: 0.1806298
[Epoch 18; Iter   161/ 1097] train: loss: 0.0736471
[Epoch 18; Iter   191/ 1097] train: loss: 0.2007890
[Epoch 18; Iter   221/ 1097] train: loss: 0.0837640
[Epoch 18; Iter   251/ 1097] train: loss: 0.2250067
[Epoch 18; Iter   281/ 1097] train: loss: 0.0213065
[Epoch 18; Iter   311/ 1097] train: loss: 0.0600045
[Epoch 18; Iter   341/ 1097] train: loss: 0.0433871
[Epoch 18; Iter   371/ 1097] train: loss: 0.0324061
[Epoch 18; Iter   401/ 1097] train: loss: 0.3021784
[Epoch 18; Iter   431/ 1097] train: loss: 0.2078892
[Epoch 18; Iter   461/ 1097] train: loss: 0.0364921
[Epoch 18; Iter   491/ 1097] train: loss: 0.2438582
[Epoch 18; Iter   521/ 1097] train: loss: 0.2570526
[Epoch 18; Iter   551/ 1097] train: loss: 0.0592357
[Epoch 18; Iter   581/ 1097] train: loss: 0.0714100
[Epoch 18; Iter   611/ 1097] train: loss: 0.0139613
[Epoch 18; Iter   641/ 1097] train: loss: 0.3364346
[Epoch 18; Iter   671/ 1097] train: loss: 0.0342293
[Epoch 18; Iter   701/ 1097] train: loss: 0.1783386
[Epoch 18; Iter   731/ 1097] train: loss: 0.0868927
[Epoch 18; Iter   761/ 1097] train: loss: 0.2847262
[Epoch 18; Iter   791/ 1097] train: loss: 0.0596829
[Epoch 18; Iter   821/ 1097] train: loss: 0.0661980
[Epoch 18; Iter   851/ 1097] train: loss: 0.1280299
[Epoch 18; Iter   881/ 1097] train: loss: 0.0876425
[Epoch 18; Iter   911/ 1097] train: loss: 0.1862762
[Epoch 18; Iter   941/ 1097] train: loss: 0.0206208
[Epoch 18; Iter   971/ 1097] train: loss: 0.1588256
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0357237
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0848755
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0470116
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1913428
[Epoch 18] ogbg-molhiv: 0.747284 val loss: 0.097895
[Epoch 18] ogbg-molhiv: 0.741364 test loss: 0.127089
[Epoch 19; Iter    24/ 1097] train: loss: 0.1716530
[Epoch 19; Iter    54/ 1097] train: loss: 0.0920875
[Epoch 19; Iter    84/ 1097] train: loss: 0.1575358
[Epoch 19; Iter   114/ 1097] train: loss: 0.0307237
[Epoch 19; Iter   144/ 1097] train: loss: 0.0661557
[Epoch 19; Iter   174/ 1097] train: loss: 0.0385609
[Epoch 19; Iter   204/ 1097] train: loss: 0.0611365
[Epoch 19; Iter   234/ 1097] train: loss: 0.0178118
[Epoch 19; Iter   264/ 1097] train: loss: 0.1150262
[Epoch 19; Iter   294/ 1097] train: loss: 0.0783258
[Epoch 19; Iter   324/ 1097] train: loss: 0.0465787
[Epoch 19; Iter   354/ 1097] train: loss: 0.2665694
[Epoch 19; Iter   384/ 1097] train: loss: 0.0277724
[Epoch 19; Iter   414/ 1097] train: loss: 0.0531349
[Epoch 19; Iter   444/ 1097] train: loss: 0.0591281
[Epoch 19; Iter   474/ 1097] train: loss: 0.1642380
[Epoch 19; Iter   504/ 1097] train: loss: 0.1433155
[Epoch 19; Iter   534/ 1097] train: loss: 0.1454556
[Epoch 19; Iter   564/ 1097] train: loss: 0.0195310
[Epoch 19; Iter   594/ 1097] train: loss: 0.0198105
[Epoch 19; Iter   624/ 1097] train: loss: 0.0813658
[Epoch 19; Iter   654/ 1097] train: loss: 0.1983657
[Epoch 19; Iter   684/ 1097] train: loss: 0.0301941
[Epoch 19; Iter   714/ 1097] train: loss: 0.1495751
[Epoch 19; Iter   744/ 1097] train: loss: 0.0298095
[Epoch 19; Iter   774/ 1097] train: loss: 0.1232981
[Epoch 19; Iter   804/ 1097] train: loss: 0.0694106
[Epoch 19; Iter   834/ 1097] train: loss: 0.2260387
[Epoch 19; Iter   864/ 1097] train: loss: 0.2980443
[Epoch 19; Iter   894/ 1097] train: loss: 0.2141733
[Epoch 19; Iter   924/ 1097] train: loss: 0.3557183
[Epoch 19; Iter   954/ 1097] train: loss: 0.0601726
[Epoch 19; Iter   984/ 1097] train: loss: 0.2326189
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1298092
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0354598
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0285611
[Epoch 19] ogbg-molhiv: 0.784630 val loss: 0.347188
[Epoch 19] ogbg-molhiv: 0.742873 test loss: 0.184137
[Epoch 20; Iter     7/ 1097] train: loss: 0.0396321
[Epoch 20; Iter    37/ 1097] train: loss: 0.1737513
[Epoch 20; Iter    67/ 1097] train: loss: 0.1009379
[Epoch 20; Iter    97/ 1097] train: loss: 0.0228160
[Epoch 20; Iter   127/ 1097] train: loss: 0.0728451
[Epoch 20; Iter   157/ 1097] train: loss: 0.0785340
[Epoch 20; Iter   187/ 1097] train: loss: 0.0224258
[Epoch 20; Iter   217/ 1097] train: loss: 0.0282402
[Epoch 20; Iter   247/ 1097] train: loss: 0.0254867
[Epoch 16; Iter   195/ 1097] train: loss: 0.0188207
[Epoch 16; Iter   225/ 1097] train: loss: 0.1294577
[Epoch 16; Iter   255/ 1097] train: loss: 0.0446327
[Epoch 16; Iter   285/ 1097] train: loss: 0.1759454
[Epoch 16; Iter   315/ 1097] train: loss: 0.0395108
[Epoch 16; Iter   345/ 1097] train: loss: 0.1643294
[Epoch 16; Iter   375/ 1097] train: loss: 0.1001087
[Epoch 16; Iter   405/ 1097] train: loss: 0.0551175
[Epoch 16; Iter   435/ 1097] train: loss: 0.3075148
[Epoch 16; Iter   465/ 1097] train: loss: 0.0735207
[Epoch 16; Iter   495/ 1097] train: loss: 0.0164162
[Epoch 16; Iter   525/ 1097] train: loss: 0.1804729
[Epoch 16; Iter   555/ 1097] train: loss: 0.0167891
[Epoch 16; Iter   585/ 1097] train: loss: 0.2318011
[Epoch 16; Iter   615/ 1097] train: loss: 0.0974195
[Epoch 16; Iter   645/ 1097] train: loss: 0.0398121
[Epoch 16; Iter   675/ 1097] train: loss: 0.0295431
[Epoch 16; Iter   705/ 1097] train: loss: 0.0480521
[Epoch 16; Iter   735/ 1097] train: loss: 0.2494223
[Epoch 16; Iter   765/ 1097] train: loss: 0.0474342
[Epoch 16; Iter   795/ 1097] train: loss: 0.0345776
[Epoch 16; Iter   825/ 1097] train: loss: 0.1843157
[Epoch 16; Iter   855/ 1097] train: loss: 0.1798225
[Epoch 16; Iter   885/ 1097] train: loss: 0.0240152
[Epoch 16; Iter   915/ 1097] train: loss: 0.1069932
[Epoch 16; Iter   945/ 1097] train: loss: 0.1016464
[Epoch 16; Iter   975/ 1097] train: loss: 0.1694951
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2037675
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0343184
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1424705
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0997407
[Epoch 16] ogbg-molhiv: 0.804909 val loss: 0.189636
[Epoch 16] ogbg-molhiv: 0.793148 test loss: 0.224414
[Epoch 17; Iter    28/ 1097] train: loss: 0.2725261
[Epoch 17; Iter    58/ 1097] train: loss: 0.0296810
[Epoch 17; Iter    88/ 1097] train: loss: 0.1849203
[Epoch 17; Iter   118/ 1097] train: loss: 0.1585249
[Epoch 17; Iter   148/ 1097] train: loss: 0.0458410
[Epoch 17; Iter   178/ 1097] train: loss: 0.2311696
[Epoch 17; Iter   208/ 1097] train: loss: 0.0359775
[Epoch 17; Iter   238/ 1097] train: loss: 0.2062441
[Epoch 17; Iter   268/ 1097] train: loss: 0.0446452
[Epoch 17; Iter   298/ 1097] train: loss: 0.2356565
[Epoch 17; Iter   328/ 1097] train: loss: 0.1640534
[Epoch 17; Iter   358/ 1097] train: loss: 0.0411443
[Epoch 17; Iter   388/ 1097] train: loss: 0.1438159
[Epoch 17; Iter   418/ 1097] train: loss: 0.2408105
[Epoch 17; Iter   448/ 1097] train: loss: 0.0298770
[Epoch 17; Iter   478/ 1097] train: loss: 0.0215119
[Epoch 17; Iter   508/ 1097] train: loss: 0.0836615
[Epoch 17; Iter   538/ 1097] train: loss: 0.0310350
[Epoch 17; Iter   568/ 1097] train: loss: 0.2182626
[Epoch 17; Iter   598/ 1097] train: loss: 0.0567810
[Epoch 17; Iter   628/ 1097] train: loss: 0.1821733
[Epoch 17; Iter   658/ 1097] train: loss: 0.0614497
[Epoch 17; Iter   688/ 1097] train: loss: 0.0749178
[Epoch 17; Iter   718/ 1097] train: loss: 0.2053710
[Epoch 17; Iter   748/ 1097] train: loss: 0.0197138
[Epoch 17; Iter   778/ 1097] train: loss: 0.1673985
[Epoch 17; Iter   808/ 1097] train: loss: 0.0221159
[Epoch 17; Iter   838/ 1097] train: loss: 0.0240817
[Epoch 17; Iter   868/ 1097] train: loss: 0.0191134
[Epoch 17; Iter   898/ 1097] train: loss: 0.0290028
[Epoch 17; Iter   928/ 1097] train: loss: 0.3574730
[Epoch 17; Iter   958/ 1097] train: loss: 0.1349977
[Epoch 17; Iter   988/ 1097] train: loss: 0.0572003
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0275903
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0399910
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1128122
[Epoch 17] ogbg-molhiv: 0.713903 val loss: 0.087245
[Epoch 17] ogbg-molhiv: 0.705491 test loss: 0.167952
[Epoch 18; Iter    11/ 1097] train: loss: 0.0742070
[Epoch 18; Iter    41/ 1097] train: loss: 0.0277438
[Epoch 18; Iter    71/ 1097] train: loss: 0.1301986
[Epoch 18; Iter   101/ 1097] train: loss: 0.0204931
[Epoch 18; Iter   131/ 1097] train: loss: 0.1057857
[Epoch 18; Iter   161/ 1097] train: loss: 0.1905948
[Epoch 18; Iter   191/ 1097] train: loss: 0.0193667
[Epoch 18; Iter   221/ 1097] train: loss: 0.0188033
[Epoch 18; Iter   251/ 1097] train: loss: 0.0812167
[Epoch 18; Iter   281/ 1097] train: loss: 0.0167683
[Epoch 18; Iter   311/ 1097] train: loss: 0.2644617
[Epoch 18; Iter   341/ 1097] train: loss: 0.1495997
[Epoch 18; Iter   371/ 1097] train: loss: 0.0222106
[Epoch 18; Iter   401/ 1097] train: loss: 0.0326517
[Epoch 18; Iter   431/ 1097] train: loss: 0.0247613
[Epoch 18; Iter   461/ 1097] train: loss: 0.0135081
[Epoch 18; Iter   491/ 1097] train: loss: 0.1123324
[Epoch 18; Iter   521/ 1097] train: loss: 0.0532151
[Epoch 18; Iter   551/ 1097] train: loss: 0.0483943
[Epoch 18; Iter   581/ 1097] train: loss: 0.0252406
[Epoch 18; Iter   611/ 1097] train: loss: 0.1562634
[Epoch 18; Iter   641/ 1097] train: loss: 0.0662851
[Epoch 18; Iter   671/ 1097] train: loss: 0.2369673
[Epoch 18; Iter   701/ 1097] train: loss: 0.1483395
[Epoch 18; Iter   731/ 1097] train: loss: 0.1531042
[Epoch 18; Iter   761/ 1097] train: loss: 0.0456377
[Epoch 18; Iter   791/ 1097] train: loss: 0.0435411
[Epoch 18; Iter   821/ 1097] train: loss: 0.0323094
[Epoch 18; Iter   851/ 1097] train: loss: 0.1470543
[Epoch 18; Iter   881/ 1097] train: loss: 0.0271911
[Epoch 18; Iter   911/ 1097] train: loss: 0.0314059
[Epoch 18; Iter   941/ 1097] train: loss: 0.0314736
[Epoch 18; Iter   971/ 1097] train: loss: 0.0391640
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0770030
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0258013
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0457125
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0494745
[Epoch 18] ogbg-molhiv: 0.776954 val loss: 0.111515
[Epoch 18] ogbg-molhiv: 0.762095 test loss: 0.195862
[Epoch 19; Iter    24/ 1097] train: loss: 0.0750124
[Epoch 19; Iter    54/ 1097] train: loss: 0.1215317
[Epoch 19; Iter    84/ 1097] train: loss: 0.0210183
[Epoch 19; Iter   114/ 1097] train: loss: 0.0755086
[Epoch 19; Iter   144/ 1097] train: loss: 0.1513793
[Epoch 19; Iter   174/ 1097] train: loss: 0.0940844
[Epoch 19; Iter   204/ 1097] train: loss: 0.0569376
[Epoch 19; Iter   234/ 1097] train: loss: 0.0583511
[Epoch 19; Iter   264/ 1097] train: loss: 0.2593563
[Epoch 19; Iter   294/ 1097] train: loss: 0.1857756
[Epoch 19; Iter   324/ 1097] train: loss: 0.0695587
[Epoch 19; Iter   354/ 1097] train: loss: 0.0991975
[Epoch 19; Iter   384/ 1097] train: loss: 0.2004332
[Epoch 19; Iter   414/ 1097] train: loss: 0.1630745
[Epoch 19; Iter   444/ 1097] train: loss: 0.0713017
[Epoch 19; Iter   474/ 1097] train: loss: 0.0135316
[Epoch 19; Iter   504/ 1097] train: loss: 0.2170400
[Epoch 19; Iter   534/ 1097] train: loss: 0.2308500
[Epoch 19; Iter   564/ 1097] train: loss: 0.1477256
[Epoch 19; Iter   594/ 1097] train: loss: 0.0671148
[Epoch 19; Iter   624/ 1097] train: loss: 0.0240519
[Epoch 19; Iter   654/ 1097] train: loss: 0.1845714
[Epoch 19; Iter   684/ 1097] train: loss: 0.0645774
[Epoch 19; Iter   714/ 1097] train: loss: 0.1685624
[Epoch 19; Iter   744/ 1097] train: loss: 0.1960071
[Epoch 19; Iter   774/ 1097] train: loss: 0.0925742
[Epoch 19; Iter   804/ 1097] train: loss: 0.0327382
[Epoch 19; Iter   834/ 1097] train: loss: 0.1790172
[Epoch 19; Iter   864/ 1097] train: loss: 0.1979064
[Epoch 19; Iter   894/ 1097] train: loss: 0.1003088
[Epoch 19; Iter   924/ 1097] train: loss: 0.2443701
[Epoch 19; Iter   954/ 1097] train: loss: 0.1003888
[Epoch 19; Iter   984/ 1097] train: loss: 0.0309256
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1357666
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0578798
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0201936
[Epoch 19] ogbg-molhiv: 0.705856 val loss: 0.089633
[Epoch 19] ogbg-molhiv: 0.695191 test loss: 0.171107
[Epoch 20; Iter     7/ 1097] train: loss: 0.1554365
[Epoch 20; Iter    37/ 1097] train: loss: 0.2317273
[Epoch 20; Iter    67/ 1097] train: loss: 0.0256022
[Epoch 20; Iter    97/ 1097] train: loss: 0.1313428
[Epoch 20; Iter   127/ 1097] train: loss: 0.1531161
[Epoch 20; Iter   157/ 1097] train: loss: 0.0438326
[Epoch 20; Iter   187/ 1097] train: loss: 0.0607621
[Epoch 20; Iter   217/ 1097] train: loss: 0.1650363
[Epoch 20; Iter   247/ 1097] train: loss: 0.0403036
[Epoch 16; Iter   195/ 1097] train: loss: 0.0388917
[Epoch 16; Iter   225/ 1097] train: loss: 0.0487024
[Epoch 16; Iter   255/ 1097] train: loss: 0.2483837
[Epoch 16; Iter   285/ 1097] train: loss: 0.0450258
[Epoch 16; Iter   315/ 1097] train: loss: 0.0543446
[Epoch 16; Iter   345/ 1097] train: loss: 0.0727384
[Epoch 16; Iter   375/ 1097] train: loss: 0.0282129
[Epoch 16; Iter   405/ 1097] train: loss: 0.0314456
[Epoch 16; Iter   435/ 1097] train: loss: 0.1116397
[Epoch 16; Iter   465/ 1097] train: loss: 0.1316127
[Epoch 16; Iter   495/ 1097] train: loss: 0.0338485
[Epoch 16; Iter   525/ 1097] train: loss: 0.0256013
[Epoch 16; Iter   555/ 1097] train: loss: 0.3726931
[Epoch 16; Iter   585/ 1097] train: loss: 0.0432271
[Epoch 16; Iter   615/ 1097] train: loss: 0.1240622
[Epoch 16; Iter   645/ 1097] train: loss: 0.0647057
[Epoch 16; Iter   675/ 1097] train: loss: 0.1296920
[Epoch 16; Iter   705/ 1097] train: loss: 0.0220106
[Epoch 16; Iter   735/ 1097] train: loss: 0.1837292
[Epoch 16; Iter   765/ 1097] train: loss: 0.3356697
[Epoch 16; Iter   795/ 1097] train: loss: 0.0535040
[Epoch 16; Iter   825/ 1097] train: loss: 0.0800119
[Epoch 16; Iter   855/ 1097] train: loss: 0.0290575
[Epoch 16; Iter   885/ 1097] train: loss: 0.1594512
[Epoch 16; Iter   915/ 1097] train: loss: 0.1441581
[Epoch 16; Iter   945/ 1097] train: loss: 0.0275865
[Epoch 16; Iter   975/ 1097] train: loss: 0.0296606
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1105883
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0335474
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0297682
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0318702
[Epoch 16] ogbg-molhiv: 0.783050 val loss: 0.124076
[Epoch 16] ogbg-molhiv: 0.749843 test loss: 0.173458
[Epoch 17; Iter    28/ 1097] train: loss: 0.1646971
[Epoch 17; Iter    58/ 1097] train: loss: 0.1068144
[Epoch 17; Iter    88/ 1097] train: loss: 0.1710454
[Epoch 17; Iter   118/ 1097] train: loss: 0.0268593
[Epoch 17; Iter   148/ 1097] train: loss: 0.0295759
[Epoch 17; Iter   178/ 1097] train: loss: 0.0218724
[Epoch 17; Iter   208/ 1097] train: loss: 0.0171046
[Epoch 17; Iter   238/ 1097] train: loss: 0.0630722
[Epoch 17; Iter   268/ 1097] train: loss: 0.0680278
[Epoch 17; Iter   298/ 1097] train: loss: 0.0533432
[Epoch 17; Iter   328/ 1097] train: loss: 0.1388218
[Epoch 17; Iter   358/ 1097] train: loss: 0.1926904
[Epoch 17; Iter   388/ 1097] train: loss: 0.0440352
[Epoch 17; Iter   418/ 1097] train: loss: 0.1181138
[Epoch 17; Iter   448/ 1097] train: loss: 0.1098741
[Epoch 17; Iter   478/ 1097] train: loss: 0.2301528
[Epoch 17; Iter   508/ 1097] train: loss: 0.0554144
[Epoch 17; Iter   538/ 1097] train: loss: 0.0855620
[Epoch 17; Iter   568/ 1097] train: loss: 0.0231363
[Epoch 17; Iter   598/ 1097] train: loss: 0.0832609
[Epoch 17; Iter   628/ 1097] train: loss: 0.0533865
[Epoch 17; Iter   658/ 1097] train: loss: 0.4050982
[Epoch 17; Iter   688/ 1097] train: loss: 0.0228982
[Epoch 17; Iter   718/ 1097] train: loss: 0.1347430
[Epoch 17; Iter   748/ 1097] train: loss: 0.1840640
[Epoch 17; Iter   778/ 1097] train: loss: 0.1015281
[Epoch 17; Iter   808/ 1097] train: loss: 0.1581965
[Epoch 17; Iter   838/ 1097] train: loss: 0.0583512
[Epoch 17; Iter   868/ 1097] train: loss: 0.0366200
[Epoch 17; Iter   898/ 1097] train: loss: 0.1688682
[Epoch 17; Iter   928/ 1097] train: loss: 0.1588904
[Epoch 17; Iter   958/ 1097] train: loss: 0.0258058
[Epoch 17; Iter   988/ 1097] train: loss: 0.1175710
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0213445
[Epoch 17; Iter  1048/ 1097] train: loss: 0.3162536
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2764894
[Epoch 17] ogbg-molhiv: 0.761243 val loss: 0.076598
[Epoch 17] ogbg-molhiv: 0.713704 test loss: 0.140463
[Epoch 18; Iter    11/ 1097] train: loss: 0.0203826
[Epoch 18; Iter    41/ 1097] train: loss: 0.1953063
[Epoch 18; Iter    71/ 1097] train: loss: 0.1799549
[Epoch 18; Iter   101/ 1097] train: loss: 0.0223397
[Epoch 18; Iter   131/ 1097] train: loss: 0.0760295
[Epoch 18; Iter   161/ 1097] train: loss: 0.3211816
[Epoch 18; Iter   191/ 1097] train: loss: 0.0591609
[Epoch 18; Iter   221/ 1097] train: loss: 0.0420200
[Epoch 18; Iter   251/ 1097] train: loss: 0.0228123
[Epoch 18; Iter   281/ 1097] train: loss: 0.1125327
[Epoch 18; Iter   311/ 1097] train: loss: 0.0473437
[Epoch 18; Iter   341/ 1097] train: loss: 0.0307033
[Epoch 18; Iter   371/ 1097] train: loss: 0.0370129
[Epoch 18; Iter   401/ 1097] train: loss: 0.1800585
[Epoch 18; Iter   431/ 1097] train: loss: 0.0269648
[Epoch 18; Iter   461/ 1097] train: loss: 0.0653501
[Epoch 18; Iter   491/ 1097] train: loss: 0.0255512
[Epoch 18; Iter   521/ 1097] train: loss: 0.1281077
[Epoch 18; Iter   551/ 1097] train: loss: 0.1045167
[Epoch 18; Iter   581/ 1097] train: loss: 0.0525709
[Epoch 18; Iter   611/ 1097] train: loss: 0.0200471
[Epoch 18; Iter   641/ 1097] train: loss: 0.1544901
[Epoch 18; Iter   671/ 1097] train: loss: 0.0455067
[Epoch 18; Iter   701/ 1097] train: loss: 0.0709221
[Epoch 18; Iter   731/ 1097] train: loss: 0.0416400
[Epoch 18; Iter   761/ 1097] train: loss: 0.0375429
[Epoch 18; Iter   791/ 1097] train: loss: 0.0381568
[Epoch 18; Iter   821/ 1097] train: loss: 0.1262453
[Epoch 18; Iter   851/ 1097] train: loss: 0.0744709
[Epoch 18; Iter   881/ 1097] train: loss: 0.0424749
[Epoch 18; Iter   911/ 1097] train: loss: 0.0215424
[Epoch 18; Iter   941/ 1097] train: loss: 0.0793115
[Epoch 18; Iter   971/ 1097] train: loss: 0.0328531
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0747173
[Epoch 18; Iter  1031/ 1097] train: loss: 0.1114681
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0952953
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0146766
[Epoch 18] ogbg-molhiv: 0.746332 val loss: 0.509473
[Epoch 18] ogbg-molhiv: 0.737604 test loss: 0.142878
[Epoch 19; Iter    24/ 1097] train: loss: 0.0157381
[Epoch 19; Iter    54/ 1097] train: loss: 0.0186855
[Epoch 19; Iter    84/ 1097] train: loss: 0.0234870
[Epoch 19; Iter   114/ 1097] train: loss: 0.0223753
[Epoch 19; Iter   144/ 1097] train: loss: 0.0344860
[Epoch 19; Iter   174/ 1097] train: loss: 0.0106332
[Epoch 19; Iter   204/ 1097] train: loss: 0.0345925
[Epoch 19; Iter   234/ 1097] train: loss: 0.0276788
[Epoch 19; Iter   264/ 1097] train: loss: 0.0223895
[Epoch 19; Iter   294/ 1097] train: loss: 0.0355540
[Epoch 19; Iter   324/ 1097] train: loss: 0.0435343
[Epoch 19; Iter   354/ 1097] train: loss: 0.2815456
[Epoch 19; Iter   384/ 1097] train: loss: 0.0273688
[Epoch 19; Iter   414/ 1097] train: loss: 0.1690387
[Epoch 19; Iter   444/ 1097] train: loss: 0.0444195
[Epoch 19; Iter   474/ 1097] train: loss: 0.1490897
[Epoch 19; Iter   504/ 1097] train: loss: 0.0219228
[Epoch 19; Iter   534/ 1097] train: loss: 0.0367906
[Epoch 19; Iter   564/ 1097] train: loss: 0.1870548
[Epoch 19; Iter   594/ 1097] train: loss: 0.0475238
[Epoch 19; Iter   624/ 1097] train: loss: 0.0277458
[Epoch 19; Iter   654/ 1097] train: loss: 0.0336377
[Epoch 19; Iter   684/ 1097] train: loss: 0.4526207
[Epoch 19; Iter   714/ 1097] train: loss: 0.0658214
[Epoch 19; Iter   744/ 1097] train: loss: 0.0404768
[Epoch 19; Iter   774/ 1097] train: loss: 0.0772393
[Epoch 19; Iter   804/ 1097] train: loss: 0.0360865
[Epoch 19; Iter   834/ 1097] train: loss: 0.0258088
[Epoch 19; Iter   864/ 1097] train: loss: 0.0263135
[Epoch 19; Iter   894/ 1097] train: loss: 0.3805807
[Epoch 19; Iter   924/ 1097] train: loss: 0.1499632
[Epoch 19; Iter   954/ 1097] train: loss: 0.0140716
[Epoch 19; Iter   984/ 1097] train: loss: 0.0582292
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0985843
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0549873
[Epoch 19; Iter  1074/ 1097] train: loss: 0.2062189
[Epoch 19] ogbg-molhiv: 0.813618 val loss: 0.082884
[Epoch 19] ogbg-molhiv: 0.715470 test loss: 0.177412
[Epoch 20; Iter     7/ 1097] train: loss: 0.0535687
[Epoch 20; Iter    37/ 1097] train: loss: 0.0158230
[Epoch 20; Iter    67/ 1097] train: loss: 0.0457020
[Epoch 20; Iter    97/ 1097] train: loss: 0.0887508
[Epoch 20; Iter   127/ 1097] train: loss: 0.0202455
[Epoch 20; Iter   157/ 1097] train: loss: 0.0198214
[Epoch 20; Iter   187/ 1097] train: loss: 0.1366958
[Epoch 20; Iter   217/ 1097] train: loss: 0.2462328
[Epoch 20; Iter   247/ 1097] train: loss: 0.0182089
[Epoch 16; Iter   195/ 1097] train: loss: 0.0351019
[Epoch 16; Iter   225/ 1097] train: loss: 0.1379058
[Epoch 16; Iter   255/ 1097] train: loss: 0.0295904
[Epoch 16; Iter   285/ 1097] train: loss: 0.1713566
[Epoch 16; Iter   315/ 1097] train: loss: 0.0455707
[Epoch 16; Iter   345/ 1097] train: loss: 0.2072736
[Epoch 16; Iter   375/ 1097] train: loss: 0.0640163
[Epoch 16; Iter   405/ 1097] train: loss: 0.0408707
[Epoch 16; Iter   435/ 1097] train: loss: 0.2412878
[Epoch 16; Iter   465/ 1097] train: loss: 0.0532074
[Epoch 16; Iter   495/ 1097] train: loss: 0.0177232
[Epoch 16; Iter   525/ 1097] train: loss: 0.1277327
[Epoch 16; Iter   555/ 1097] train: loss: 0.0220784
[Epoch 16; Iter   585/ 1097] train: loss: 0.2321701
[Epoch 16; Iter   615/ 1097] train: loss: 0.0827898
[Epoch 16; Iter   645/ 1097] train: loss: 0.1027541
[Epoch 16; Iter   675/ 1097] train: loss: 0.0449502
[Epoch 16; Iter   705/ 1097] train: loss: 0.0428452
[Epoch 16; Iter   735/ 1097] train: loss: 0.2314121
[Epoch 16; Iter   765/ 1097] train: loss: 0.0286816
[Epoch 16; Iter   795/ 1097] train: loss: 0.0287650
[Epoch 16; Iter   825/ 1097] train: loss: 0.2783398
[Epoch 16; Iter   855/ 1097] train: loss: 0.1767610
[Epoch 16; Iter   885/ 1097] train: loss: 0.0309563
[Epoch 16; Iter   915/ 1097] train: loss: 0.0466407
[Epoch 16; Iter   945/ 1097] train: loss: 0.0942787
[Epoch 16; Iter   975/ 1097] train: loss: 0.1742958
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2311231
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0350830
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1762041
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1656144
[Epoch 16] ogbg-molhiv: 0.735603 val loss: 0.228108
[Epoch 16] ogbg-molhiv: 0.727325 test loss: 0.204218
[Epoch 17; Iter    28/ 1097] train: loss: 0.2257987
[Epoch 17; Iter    58/ 1097] train: loss: 0.0291833
[Epoch 17; Iter    88/ 1097] train: loss: 0.2246163
[Epoch 17; Iter   118/ 1097] train: loss: 0.3257439
[Epoch 17; Iter   148/ 1097] train: loss: 0.0198237
[Epoch 17; Iter   178/ 1097] train: loss: 0.1332504
[Epoch 17; Iter   208/ 1097] train: loss: 0.0648081
[Epoch 17; Iter   238/ 1097] train: loss: 0.1347067
[Epoch 17; Iter   268/ 1097] train: loss: 0.0318934
[Epoch 17; Iter   298/ 1097] train: loss: 0.1280908
[Epoch 17; Iter   328/ 1097] train: loss: 0.1774525
[Epoch 17; Iter   358/ 1097] train: loss: 0.0254495
[Epoch 17; Iter   388/ 1097] train: loss: 0.2268147
[Epoch 17; Iter   418/ 1097] train: loss: 0.1642519
[Epoch 17; Iter   448/ 1097] train: loss: 0.0319668
[Epoch 17; Iter   478/ 1097] train: loss: 0.0805724
[Epoch 17; Iter   508/ 1097] train: loss: 0.1273696
[Epoch 17; Iter   538/ 1097] train: loss: 0.0337984
[Epoch 17; Iter   568/ 1097] train: loss: 0.1825313
[Epoch 17; Iter   598/ 1097] train: loss: 0.0293787
[Epoch 17; Iter   628/ 1097] train: loss: 0.1961902
[Epoch 17; Iter   658/ 1097] train: loss: 0.1312016
[Epoch 17; Iter   688/ 1097] train: loss: 0.0530494
[Epoch 17; Iter   718/ 1097] train: loss: 0.1498314
[Epoch 17; Iter   748/ 1097] train: loss: 0.0196702
[Epoch 17; Iter   778/ 1097] train: loss: 0.2053163
[Epoch 17; Iter   808/ 1097] train: loss: 0.0235918
[Epoch 17; Iter   838/ 1097] train: loss: 0.0223189
[Epoch 17; Iter   868/ 1097] train: loss: 0.0382272
[Epoch 17; Iter   898/ 1097] train: loss: 0.0471381
[Epoch 17; Iter   928/ 1097] train: loss: 0.2966992
[Epoch 17; Iter   958/ 1097] train: loss: 0.0559162
[Epoch 17; Iter   988/ 1097] train: loss: 0.0257594
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0295980
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0499211
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0854548
[Epoch 17] ogbg-molhiv: 0.726108 val loss: 0.280383
[Epoch 17] ogbg-molhiv: 0.675571 test loss: 0.215636
[Epoch 18; Iter    11/ 1097] train: loss: 0.1420493
[Epoch 18; Iter    41/ 1097] train: loss: 0.0205014
[Epoch 18; Iter    71/ 1097] train: loss: 0.2460446
[Epoch 18; Iter   101/ 1097] train: loss: 0.0461989
[Epoch 18; Iter   131/ 1097] train: loss: 0.1848666
[Epoch 18; Iter   161/ 1097] train: loss: 0.1465978
[Epoch 18; Iter   191/ 1097] train: loss: 0.1571368
[Epoch 18; Iter   221/ 1097] train: loss: 0.0177066
[Epoch 18; Iter   251/ 1097] train: loss: 0.1055777
[Epoch 18; Iter   281/ 1097] train: loss: 0.0244458
[Epoch 18; Iter   311/ 1097] train: loss: 0.2651658
[Epoch 18; Iter   341/ 1097] train: loss: 0.1324233
[Epoch 18; Iter   371/ 1097] train: loss: 0.0308218
[Epoch 18; Iter   401/ 1097] train: loss: 0.0335318
[Epoch 18; Iter   431/ 1097] train: loss: 0.0245505
[Epoch 18; Iter   461/ 1097] train: loss: 0.0903825
[Epoch 18; Iter   491/ 1097] train: loss: 0.0471680
[Epoch 18; Iter   521/ 1097] train: loss: 0.0395568
[Epoch 18; Iter   551/ 1097] train: loss: 0.0437638
[Epoch 18; Iter   581/ 1097] train: loss: 0.0231530
[Epoch 18; Iter   611/ 1097] train: loss: 0.1239620
[Epoch 18; Iter   641/ 1097] train: loss: 0.0889913
[Epoch 18; Iter   671/ 1097] train: loss: 0.2033844
[Epoch 18; Iter   701/ 1097] train: loss: 0.1673314
[Epoch 18; Iter   731/ 1097] train: loss: 0.0809081
[Epoch 18; Iter   761/ 1097] train: loss: 0.0717690
[Epoch 18; Iter   791/ 1097] train: loss: 0.1809592
[Epoch 18; Iter   821/ 1097] train: loss: 0.0466439
[Epoch 18; Iter   851/ 1097] train: loss: 0.2120558
[Epoch 18; Iter   881/ 1097] train: loss: 0.0243590
[Epoch 18; Iter   911/ 1097] train: loss: 0.1693109
[Epoch 18; Iter   941/ 1097] train: loss: 0.0343950
[Epoch 18; Iter   971/ 1097] train: loss: 0.0265470
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1390022
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0232241
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0334290
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0348703
[Epoch 18] ogbg-molhiv: 0.752348 val loss: 0.140538
[Epoch 18] ogbg-molhiv: 0.720885 test loss: 0.158433
[Epoch 19; Iter    24/ 1097] train: loss: 0.1084879
[Epoch 19; Iter    54/ 1097] train: loss: 0.1464922
[Epoch 19; Iter    84/ 1097] train: loss: 0.0259336
[Epoch 19; Iter   114/ 1097] train: loss: 0.0372550
[Epoch 19; Iter   144/ 1097] train: loss: 0.0918701
[Epoch 19; Iter   174/ 1097] train: loss: 0.1055290
[Epoch 19; Iter   204/ 1097] train: loss: 0.0768003
[Epoch 19; Iter   234/ 1097] train: loss: 0.2033536
[Epoch 19; Iter   264/ 1097] train: loss: 0.1108745
[Epoch 19; Iter   294/ 1097] train: loss: 0.2073696
[Epoch 19; Iter   324/ 1097] train: loss: 0.0585541
[Epoch 19; Iter   354/ 1097] train: loss: 0.0237176
[Epoch 19; Iter   384/ 1097] train: loss: 0.1080202
[Epoch 19; Iter   414/ 1097] train: loss: 0.2786475
[Epoch 19; Iter   444/ 1097] train: loss: 0.0750133
[Epoch 19; Iter   474/ 1097] train: loss: 0.0309501
[Epoch 19; Iter   504/ 1097] train: loss: 0.1685506
[Epoch 19; Iter   534/ 1097] train: loss: 0.2266393
[Epoch 19; Iter   564/ 1097] train: loss: 0.1822469
[Epoch 19; Iter   594/ 1097] train: loss: 0.0256170
[Epoch 19; Iter   624/ 1097] train: loss: 0.0247793
[Epoch 19; Iter   654/ 1097] train: loss: 0.1810058
[Epoch 19; Iter   684/ 1097] train: loss: 0.0967710
[Epoch 19; Iter   714/ 1097] train: loss: 0.1070692
[Epoch 19; Iter   744/ 1097] train: loss: 0.1750031
[Epoch 19; Iter   774/ 1097] train: loss: 0.0899417
[Epoch 19; Iter   804/ 1097] train: loss: 0.0188208
[Epoch 19; Iter   834/ 1097] train: loss: 0.1951131
[Epoch 19; Iter   864/ 1097] train: loss: 0.1413018
[Epoch 19; Iter   894/ 1097] train: loss: 0.0572264
[Epoch 19; Iter   924/ 1097] train: loss: 0.0878602
[Epoch 19; Iter   954/ 1097] train: loss: 0.0894040
[Epoch 19; Iter   984/ 1097] train: loss: 0.0539643
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1544911
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0653488
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0275775
[Epoch 19] ogbg-molhiv: 0.726181 val loss: 0.089922
[Epoch 19] ogbg-molhiv: 0.713565 test loss: 0.125467
[Epoch 20; Iter     7/ 1097] train: loss: 0.1567661
[Epoch 20; Iter    37/ 1097] train: loss: 0.1360475
[Epoch 20; Iter    67/ 1097] train: loss: 0.0264379
[Epoch 20; Iter    97/ 1097] train: loss: 0.0618149
[Epoch 20; Iter   127/ 1097] train: loss: 0.1779633
[Epoch 20; Iter   157/ 1097] train: loss: 0.0228810
[Epoch 20; Iter   187/ 1097] train: loss: 0.0497823
[Epoch 20; Iter   217/ 1097] train: loss: 0.0208671
[Epoch 20; Iter   247/ 1097] train: loss: 0.0516095
[Epoch 16; Iter   195/ 1097] train: loss: 0.0305562
[Epoch 16; Iter   225/ 1097] train: loss: 0.0679738
[Epoch 16; Iter   255/ 1097] train: loss: 0.2260914
[Epoch 16; Iter   285/ 1097] train: loss: 0.0406806
[Epoch 16; Iter   315/ 1097] train: loss: 0.1114820
[Epoch 16; Iter   345/ 1097] train: loss: 0.0666251
[Epoch 16; Iter   375/ 1097] train: loss: 0.0668980
[Epoch 16; Iter   405/ 1097] train: loss: 0.0311085
[Epoch 16; Iter   435/ 1097] train: loss: 0.0913258
[Epoch 16; Iter   465/ 1097] train: loss: 0.2405598
[Epoch 16; Iter   495/ 1097] train: loss: 0.0534803
[Epoch 16; Iter   525/ 1097] train: loss: 0.0307857
[Epoch 16; Iter   555/ 1097] train: loss: 0.4069794
[Epoch 16; Iter   585/ 1097] train: loss: 0.0401047
[Epoch 16; Iter   615/ 1097] train: loss: 0.1416222
[Epoch 16; Iter   645/ 1097] train: loss: 0.0914861
[Epoch 16; Iter   675/ 1097] train: loss: 0.1354207
[Epoch 16; Iter   705/ 1097] train: loss: 0.0242305
[Epoch 16; Iter   735/ 1097] train: loss: 0.1506857
[Epoch 16; Iter   765/ 1097] train: loss: 0.3035582
[Epoch 16; Iter   795/ 1097] train: loss: 0.0292801
[Epoch 16; Iter   825/ 1097] train: loss: 0.1368215
[Epoch 16; Iter   855/ 1097] train: loss: 0.0237467
[Epoch 16; Iter   885/ 1097] train: loss: 0.1325944
[Epoch 16; Iter   915/ 1097] train: loss: 0.1488625
[Epoch 16; Iter   945/ 1097] train: loss: 0.0320116
[Epoch 16; Iter   975/ 1097] train: loss: 0.0243146
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1123547
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0578053
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0249383
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0311484
[Epoch 16] ogbg-molhiv: 0.744599 val loss: 0.158346
[Epoch 16] ogbg-molhiv: 0.746360 test loss: 0.227507
[Epoch 17; Iter    28/ 1097] train: loss: 0.1714269
[Epoch 17; Iter    58/ 1097] train: loss: 0.0870380
[Epoch 17; Iter    88/ 1097] train: loss: 0.1024279
[Epoch 17; Iter   118/ 1097] train: loss: 0.0563956
[Epoch 17; Iter   148/ 1097] train: loss: 0.0278585
[Epoch 17; Iter   178/ 1097] train: loss: 0.0233470
[Epoch 17; Iter   208/ 1097] train: loss: 0.0197560
[Epoch 17; Iter   238/ 1097] train: loss: 0.0510492
[Epoch 17; Iter   268/ 1097] train: loss: 0.1596854
[Epoch 17; Iter   298/ 1097] train: loss: 0.0264602
[Epoch 17; Iter   328/ 1097] train: loss: 0.0399321
[Epoch 17; Iter   358/ 1097] train: loss: 0.2128698
[Epoch 17; Iter   388/ 1097] train: loss: 0.0430393
[Epoch 17; Iter   418/ 1097] train: loss: 0.1341702
[Epoch 17; Iter   448/ 1097] train: loss: 0.1029241
[Epoch 17; Iter   478/ 1097] train: loss: 0.1726073
[Epoch 17; Iter   508/ 1097] train: loss: 0.0361447
[Epoch 17; Iter   538/ 1097] train: loss: 0.0593202
[Epoch 17; Iter   568/ 1097] train: loss: 0.0235868
[Epoch 17; Iter   598/ 1097] train: loss: 0.0672181
[Epoch 17; Iter   628/ 1097] train: loss: 0.0399489
[Epoch 17; Iter   658/ 1097] train: loss: 0.0885361
[Epoch 17; Iter   688/ 1097] train: loss: 0.0262965
[Epoch 17; Iter   718/ 1097] train: loss: 0.1534154
[Epoch 17; Iter   748/ 1097] train: loss: 0.1647721
[Epoch 17; Iter   778/ 1097] train: loss: 0.1011117
[Epoch 17; Iter   808/ 1097] train: loss: 0.1897643
[Epoch 17; Iter   838/ 1097] train: loss: 0.0591352
[Epoch 17; Iter   868/ 1097] train: loss: 0.0368419
[Epoch 17; Iter   898/ 1097] train: loss: 0.2245701
[Epoch 17; Iter   928/ 1097] train: loss: 0.2523403
[Epoch 17; Iter   958/ 1097] train: loss: 0.0330509
[Epoch 17; Iter   988/ 1097] train: loss: 0.1596766
[Epoch 17; Iter  1018/ 1097] train: loss: 0.1052133
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2818747
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2848435
[Epoch 17] ogbg-molhiv: 0.755211 val loss: 0.250242
[Epoch 17] ogbg-molhiv: 0.720819 test loss: 0.126205
[Epoch 18; Iter    11/ 1097] train: loss: 0.0325108
[Epoch 18; Iter    41/ 1097] train: loss: 0.1907248
[Epoch 18; Iter    71/ 1097] train: loss: 0.1706438
[Epoch 18; Iter   101/ 1097] train: loss: 0.0159396
[Epoch 18; Iter   131/ 1097] train: loss: 0.1309086
[Epoch 18; Iter   161/ 1097] train: loss: 0.1283201
[Epoch 18; Iter   191/ 1097] train: loss: 0.0229707
[Epoch 18; Iter   221/ 1097] train: loss: 0.1207191
[Epoch 18; Iter   251/ 1097] train: loss: 0.0326932
[Epoch 18; Iter   281/ 1097] train: loss: 0.1128538
[Epoch 18; Iter   311/ 1097] train: loss: 0.0575435
[Epoch 18; Iter   341/ 1097] train: loss: 0.0204122
[Epoch 18; Iter   371/ 1097] train: loss: 0.0310960
[Epoch 18; Iter   401/ 1097] train: loss: 0.2123389
[Epoch 18; Iter   431/ 1097] train: loss: 0.0604131
[Epoch 18; Iter   461/ 1097] train: loss: 0.1676389
[Epoch 18; Iter   491/ 1097] train: loss: 0.0268677
[Epoch 18; Iter   521/ 1097] train: loss: 0.1628599
[Epoch 18; Iter   551/ 1097] train: loss: 0.0728532
[Epoch 18; Iter   581/ 1097] train: loss: 0.0295917
[Epoch 18; Iter   611/ 1097] train: loss: 0.0344897
[Epoch 18; Iter   641/ 1097] train: loss: 0.1953311
[Epoch 18; Iter   671/ 1097] train: loss: 0.0555420
[Epoch 18; Iter   701/ 1097] train: loss: 0.0732568
[Epoch 18; Iter   731/ 1097] train: loss: 0.0318050
[Epoch 18; Iter   761/ 1097] train: loss: 0.0305396
[Epoch 18; Iter   791/ 1097] train: loss: 0.0326137
[Epoch 18; Iter   821/ 1097] train: loss: 0.1428919
[Epoch 18; Iter   851/ 1097] train: loss: 0.0311459
[Epoch 18; Iter   881/ 1097] train: loss: 0.0871198
[Epoch 18; Iter   911/ 1097] train: loss: 0.0216552
[Epoch 18; Iter   941/ 1097] train: loss: 0.1301898
[Epoch 18; Iter   971/ 1097] train: loss: 0.0266564
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0719670
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0892832
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0624427
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0124123
[Epoch 18] ogbg-molhiv: 0.717792 val loss: 0.103352
[Epoch 18] ogbg-molhiv: 0.743058 test loss: 0.156226
[Epoch 19; Iter    24/ 1097] train: loss: 0.0244653
[Epoch 19; Iter    54/ 1097] train: loss: 0.1485815
[Epoch 19; Iter    84/ 1097] train: loss: 0.0421153
[Epoch 19; Iter   114/ 1097] train: loss: 0.0241530
[Epoch 19; Iter   144/ 1097] train: loss: 0.0723033
[Epoch 19; Iter   174/ 1097] train: loss: 0.0594677
[Epoch 19; Iter   204/ 1097] train: loss: 0.0506810
[Epoch 19; Iter   234/ 1097] train: loss: 0.0971799
[Epoch 19; Iter   264/ 1097] train: loss: 0.0195659
[Epoch 19; Iter   294/ 1097] train: loss: 0.0356362
[Epoch 19; Iter   324/ 1097] train: loss: 0.0283293
[Epoch 19; Iter   354/ 1097] train: loss: 0.2679659
[Epoch 19; Iter   384/ 1097] train: loss: 0.0716910
[Epoch 19; Iter   414/ 1097] train: loss: 0.1725382
[Epoch 19; Iter   444/ 1097] train: loss: 0.0443268
[Epoch 19; Iter   474/ 1097] train: loss: 0.1917246
[Epoch 19; Iter   504/ 1097] train: loss: 0.0629076
[Epoch 19; Iter   534/ 1097] train: loss: 0.0260137
[Epoch 19; Iter   564/ 1097] train: loss: 0.1084174
[Epoch 19; Iter   594/ 1097] train: loss: 0.1267846
[Epoch 19; Iter   624/ 1097] train: loss: 0.0784513
[Epoch 19; Iter   654/ 1097] train: loss: 0.0265891
[Epoch 19; Iter   684/ 1097] train: loss: 0.3781940
[Epoch 19; Iter   714/ 1097] train: loss: 0.0378025
[Epoch 19; Iter   744/ 1097] train: loss: 0.0490528
[Epoch 19; Iter   774/ 1097] train: loss: 0.0989714
[Epoch 19; Iter   804/ 1097] train: loss: 0.0141676
[Epoch 19; Iter   834/ 1097] train: loss: 0.0431670
[Epoch 19; Iter   864/ 1097] train: loss: 0.0351534
[Epoch 19; Iter   894/ 1097] train: loss: 0.4647528
[Epoch 19; Iter   924/ 1097] train: loss: 0.1346842
[Epoch 19; Iter   954/ 1097] train: loss: 0.0388963
[Epoch 19; Iter   984/ 1097] train: loss: 0.0739136
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1686864
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0315096
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3735631
[Epoch 19] ogbg-molhiv: 0.708012 val loss: 0.095758
[Epoch 19] ogbg-molhiv: 0.747828 test loss: 0.392874
[Epoch 20; Iter     7/ 1097] train: loss: 0.0233748
[Epoch 20; Iter    37/ 1097] train: loss: 0.0359070
[Epoch 20; Iter    67/ 1097] train: loss: 0.0177246
[Epoch 20; Iter    97/ 1097] train: loss: 0.0296158
[Epoch 20; Iter   127/ 1097] train: loss: 0.0235035
[Epoch 20; Iter   157/ 1097] train: loss: 0.0212314
[Epoch 20; Iter   187/ 1097] train: loss: 0.0814768
[Epoch 20; Iter   217/ 1097] train: loss: 0.1668993
[Epoch 20; Iter   247/ 1097] train: loss: 0.0283920
[Epoch 16; Iter   195/ 1097] train: loss: 0.1286149
[Epoch 16; Iter   225/ 1097] train: loss: 0.0241911
[Epoch 16; Iter   255/ 1097] train: loss: 0.0906806
[Epoch 16; Iter   285/ 1097] train: loss: 0.1235568
[Epoch 16; Iter   315/ 1097] train: loss: 0.0700166
[Epoch 16; Iter   345/ 1097] train: loss: 0.0364565
[Epoch 16; Iter   375/ 1097] train: loss: 0.1328190
[Epoch 16; Iter   405/ 1097] train: loss: 0.2742203
[Epoch 16; Iter   435/ 1097] train: loss: 0.1369682
[Epoch 16; Iter   465/ 1097] train: loss: 0.0977082
[Epoch 16; Iter   495/ 1097] train: loss: 0.1157294
[Epoch 16; Iter   525/ 1097] train: loss: 0.0844571
[Epoch 16; Iter   555/ 1097] train: loss: 0.0468926
[Epoch 16; Iter   585/ 1097] train: loss: 0.1177404
[Epoch 16; Iter   615/ 1097] train: loss: 0.0829708
[Epoch 16; Iter   645/ 1097] train: loss: 0.0459183
[Epoch 16; Iter   675/ 1097] train: loss: 0.1004887
[Epoch 16; Iter   705/ 1097] train: loss: 0.1333860
[Epoch 16; Iter   735/ 1097] train: loss: 0.0939672
[Epoch 16; Iter   765/ 1097] train: loss: 0.0508164
[Epoch 16; Iter   795/ 1097] train: loss: 0.0975962
[Epoch 16; Iter   825/ 1097] train: loss: 0.0294384
[Epoch 16; Iter   855/ 1097] train: loss: 0.1486293
[Epoch 16; Iter   885/ 1097] train: loss: 0.2989047
[Epoch 16; Iter   915/ 1097] train: loss: 0.0272195
[Epoch 16; Iter   945/ 1097] train: loss: 0.0260026
[Epoch 16; Iter   975/ 1097] train: loss: 0.0234398
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0507078
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0234055
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0597103
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1176792
[Epoch 16] ogbg-molhiv: 0.773552 val loss: 0.127714
[Epoch 16] ogbg-molhiv: 0.761189 test loss: 0.135997
[Epoch 17; Iter    28/ 1097] train: loss: 0.0355334
[Epoch 17; Iter    58/ 1097] train: loss: 0.0271560
[Epoch 17; Iter    88/ 1097] train: loss: 0.0322554
[Epoch 17; Iter   118/ 1097] train: loss: 0.1372631
[Epoch 17; Iter   148/ 1097] train: loss: 0.1935211
[Epoch 17; Iter   178/ 1097] train: loss: 0.0375713
[Epoch 17; Iter   208/ 1097] train: loss: 0.0340226
[Epoch 17; Iter   238/ 1097] train: loss: 0.2624003
[Epoch 17; Iter   268/ 1097] train: loss: 0.0184799
[Epoch 17; Iter   298/ 1097] train: loss: 0.0238491
[Epoch 17; Iter   328/ 1097] train: loss: 0.0258762
[Epoch 17; Iter   358/ 1097] train: loss: 0.0305292
[Epoch 17; Iter   388/ 1097] train: loss: 0.0330392
[Epoch 17; Iter   418/ 1097] train: loss: 0.1061352
[Epoch 17; Iter   448/ 1097] train: loss: 0.0238489
[Epoch 17; Iter   478/ 1097] train: loss: 0.0613138
[Epoch 17; Iter   508/ 1097] train: loss: 0.0482661
[Epoch 17; Iter   538/ 1097] train: loss: 0.3651131
[Epoch 17; Iter   568/ 1097] train: loss: 0.1832045
[Epoch 17; Iter   598/ 1097] train: loss: 0.1024641
[Epoch 17; Iter   628/ 1097] train: loss: 0.0276367
[Epoch 17; Iter   658/ 1097] train: loss: 0.0351568
[Epoch 17; Iter   688/ 1097] train: loss: 0.2232064
[Epoch 17; Iter   718/ 1097] train: loss: 0.0568855
[Epoch 17; Iter   748/ 1097] train: loss: 0.1072905
[Epoch 17; Iter   778/ 1097] train: loss: 0.0448783
[Epoch 17; Iter   808/ 1097] train: loss: 0.0967609
[Epoch 17; Iter   838/ 1097] train: loss: 0.0508186
[Epoch 17; Iter   868/ 1097] train: loss: 0.0218794
[Epoch 17; Iter   898/ 1097] train: loss: 0.0664926
[Epoch 17; Iter   928/ 1097] train: loss: 0.2736064
[Epoch 17; Iter   958/ 1097] train: loss: 0.1727904
[Epoch 17; Iter   988/ 1097] train: loss: 0.0409336
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0371991
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0444279
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1594032
[Epoch 17] ogbg-molhiv: 0.738046 val loss: 0.427598
[Epoch 17] ogbg-molhiv: 0.783690 test loss: 0.585760
[Epoch 18; Iter    11/ 1097] train: loss: 0.1021956
[Epoch 18; Iter    41/ 1097] train: loss: 0.2499711
[Epoch 18; Iter    71/ 1097] train: loss: 0.0749679
[Epoch 18; Iter   101/ 1097] train: loss: 0.0716928
[Epoch 18; Iter   131/ 1097] train: loss: 0.1648108
[Epoch 18; Iter   161/ 1097] train: loss: 0.0388738
[Epoch 18; Iter   191/ 1097] train: loss: 0.1754796
[Epoch 18; Iter   221/ 1097] train: loss: 0.1483734
[Epoch 18; Iter   251/ 1097] train: loss: 0.0929173
[Epoch 18; Iter   281/ 1097] train: loss: 0.0298043
[Epoch 18; Iter   311/ 1097] train: loss: 0.1683062
[Epoch 18; Iter   341/ 1097] train: loss: 0.0237900
[Epoch 18; Iter   371/ 1097] train: loss: 0.0328411
[Epoch 18; Iter   401/ 1097] train: loss: 0.2430785
[Epoch 18; Iter   431/ 1097] train: loss: 0.1871028
[Epoch 18; Iter   461/ 1097] train: loss: 0.0839646
[Epoch 18; Iter   491/ 1097] train: loss: 0.1688000
[Epoch 18; Iter   521/ 1097] train: loss: 0.3080255
[Epoch 18; Iter   551/ 1097] train: loss: 0.0366853
[Epoch 18; Iter   581/ 1097] train: loss: 0.0390469
[Epoch 18; Iter   611/ 1097] train: loss: 0.0188440
[Epoch 18; Iter   641/ 1097] train: loss: 0.1719053
[Epoch 18; Iter   671/ 1097] train: loss: 0.1271799
[Epoch 18; Iter   701/ 1097] train: loss: 0.1988070
[Epoch 18; Iter   731/ 1097] train: loss: 0.0836003
[Epoch 18; Iter   761/ 1097] train: loss: 0.3184605
[Epoch 18; Iter   791/ 1097] train: loss: 0.0612825
[Epoch 18; Iter   821/ 1097] train: loss: 0.0604926
[Epoch 18; Iter   851/ 1097] train: loss: 0.1486005
[Epoch 18; Iter   881/ 1097] train: loss: 0.0592971
[Epoch 18; Iter   911/ 1097] train: loss: 0.1774404
[Epoch 18; Iter   941/ 1097] train: loss: 0.0295628
[Epoch 18; Iter   971/ 1097] train: loss: 0.0548286
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0246733
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0826544
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0362762
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1090118
[Epoch 18] ogbg-molhiv: 0.766645 val loss: 0.479766
[Epoch 18] ogbg-molhiv: 0.739474 test loss: 0.786892
[Epoch 19; Iter    24/ 1097] train: loss: 0.2581296
[Epoch 19; Iter    54/ 1097] train: loss: 0.1419119
[Epoch 19; Iter    84/ 1097] train: loss: 0.2516275
[Epoch 19; Iter   114/ 1097] train: loss: 0.0260887
[Epoch 19; Iter   144/ 1097] train: loss: 0.0798273
[Epoch 19; Iter   174/ 1097] train: loss: 0.0908667
[Epoch 19; Iter   204/ 1097] train: loss: 0.0188125
[Epoch 19; Iter   234/ 1097] train: loss: 0.0483485
[Epoch 19; Iter   264/ 1097] train: loss: 0.0447180
[Epoch 19; Iter   294/ 1097] train: loss: 0.0621937
[Epoch 19; Iter   324/ 1097] train: loss: 0.0385960
[Epoch 19; Iter   354/ 1097] train: loss: 0.1802943
[Epoch 19; Iter   384/ 1097] train: loss: 0.0242401
[Epoch 19; Iter   414/ 1097] train: loss: 0.0352891
[Epoch 19; Iter   444/ 1097] train: loss: 0.1482277
[Epoch 19; Iter   474/ 1097] train: loss: 0.0437327
[Epoch 19; Iter   504/ 1097] train: loss: 0.1781785
[Epoch 19; Iter   534/ 1097] train: loss: 0.1363657
[Epoch 19; Iter   564/ 1097] train: loss: 0.0156890
[Epoch 19; Iter   594/ 1097] train: loss: 0.0257544
[Epoch 19; Iter   624/ 1097] train: loss: 0.0326729
[Epoch 19; Iter   654/ 1097] train: loss: 0.0534698
[Epoch 19; Iter   684/ 1097] train: loss: 0.0362145
[Epoch 19; Iter   714/ 1097] train: loss: 0.1388639
[Epoch 19; Iter   744/ 1097] train: loss: 0.0552860
[Epoch 19; Iter   774/ 1097] train: loss: 0.1152717
[Epoch 19; Iter   804/ 1097] train: loss: 0.1461459
[Epoch 19; Iter   834/ 1097] train: loss: 0.2476317
[Epoch 19; Iter   864/ 1097] train: loss: 0.3106514
[Epoch 19; Iter   894/ 1097] train: loss: 0.1427289
[Epoch 19; Iter   924/ 1097] train: loss: 0.5558621
[Epoch 19; Iter   954/ 1097] train: loss: 0.0587511
[Epoch 19; Iter   984/ 1097] train: loss: 0.3328076
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1454977
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0274135
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0394967
[Epoch 19] ogbg-molhiv: 0.739179 val loss: 1.040406
[Epoch 19] ogbg-molhiv: 0.750600 test loss: 0.491838
[Epoch 20; Iter     7/ 1097] train: loss: 0.0672046
[Epoch 20; Iter    37/ 1097] train: loss: 0.2206217
[Epoch 20; Iter    67/ 1097] train: loss: 0.0740004
[Epoch 20; Iter    97/ 1097] train: loss: 0.0234495
[Epoch 20; Iter   127/ 1097] train: loss: 0.0420781
[Epoch 20; Iter   157/ 1097] train: loss: 0.0546777
[Epoch 20; Iter   187/ 1097] train: loss: 0.0241353
[Epoch 20; Iter   217/ 1097] train: loss: 0.0387869
[Epoch 20; Iter   247/ 1097] train: loss: 0.0414078
[Epoch 16; Iter   195/ 1097] train: loss: 0.0375034
[Epoch 16; Iter   225/ 1097] train: loss: 0.0851508
[Epoch 16; Iter   255/ 1097] train: loss: 0.1864063
[Epoch 16; Iter   285/ 1097] train: loss: 0.0233065
[Epoch 16; Iter   315/ 1097] train: loss: 0.1307039
[Epoch 16; Iter   345/ 1097] train: loss: 0.1511083
[Epoch 16; Iter   375/ 1097] train: loss: 0.0374456
[Epoch 16; Iter   405/ 1097] train: loss: 0.0231782
[Epoch 16; Iter   435/ 1097] train: loss: 0.0660259
[Epoch 16; Iter   465/ 1097] train: loss: 0.0935898
[Epoch 16; Iter   495/ 1097] train: loss: 0.0554014
[Epoch 16; Iter   525/ 1097] train: loss: 0.0247231
[Epoch 16; Iter   555/ 1097] train: loss: 0.3919684
[Epoch 16; Iter   585/ 1097] train: loss: 0.0624167
[Epoch 16; Iter   615/ 1097] train: loss: 0.1356102
[Epoch 16; Iter   645/ 1097] train: loss: 0.0722962
[Epoch 16; Iter   675/ 1097] train: loss: 0.1592153
[Epoch 16; Iter   705/ 1097] train: loss: 0.0453500
[Epoch 16; Iter   735/ 1097] train: loss: 0.1787514
[Epoch 16; Iter   765/ 1097] train: loss: 0.3045436
[Epoch 16; Iter   795/ 1097] train: loss: 0.0998068
[Epoch 16; Iter   825/ 1097] train: loss: 0.1227492
[Epoch 16; Iter   855/ 1097] train: loss: 0.0284749
[Epoch 16; Iter   885/ 1097] train: loss: 0.1895730
[Epoch 16; Iter   915/ 1097] train: loss: 0.1196812
[Epoch 16; Iter   945/ 1097] train: loss: 0.0241345
[Epoch 16; Iter   975/ 1097] train: loss: 0.0228872
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1512435
[Epoch 16; Iter  1035/ 1097] train: loss: 0.1008163
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0392680
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0502119
[Epoch 16] ogbg-molhiv: 0.728870 val loss: 0.673358
[Epoch 16] ogbg-molhiv: 0.676967 test loss: 0.267643
[Epoch 17; Iter    28/ 1097] train: loss: 0.1189611
[Epoch 17; Iter    58/ 1097] train: loss: 0.0364169
[Epoch 17; Iter    88/ 1097] train: loss: 0.0346814
[Epoch 17; Iter   118/ 1097] train: loss: 0.0572790
[Epoch 17; Iter   148/ 1097] train: loss: 0.0229053
[Epoch 17; Iter   178/ 1097] train: loss: 0.0218127
[Epoch 17; Iter   208/ 1097] train: loss: 0.0274602
[Epoch 17; Iter   238/ 1097] train: loss: 0.0614840
[Epoch 17; Iter   268/ 1097] train: loss: 0.1543219
[Epoch 17; Iter   298/ 1097] train: loss: 0.0172973
[Epoch 17; Iter   328/ 1097] train: loss: 0.0448152
[Epoch 17; Iter   358/ 1097] train: loss: 0.2913904
[Epoch 17; Iter   388/ 1097] train: loss: 0.0240428
[Epoch 17; Iter   418/ 1097] train: loss: 0.0817210
[Epoch 17; Iter   448/ 1097] train: loss: 0.1439051
[Epoch 17; Iter   478/ 1097] train: loss: 0.2222356
[Epoch 17; Iter   508/ 1097] train: loss: 0.0577529
[Epoch 17; Iter   538/ 1097] train: loss: 0.1624291
[Epoch 17; Iter   568/ 1097] train: loss: 0.0225773
[Epoch 17; Iter   598/ 1097] train: loss: 0.1394427
[Epoch 17; Iter   628/ 1097] train: loss: 0.0538175
[Epoch 17; Iter   658/ 1097] train: loss: 0.0755716
[Epoch 17; Iter   688/ 1097] train: loss: 0.0411578
[Epoch 17; Iter   718/ 1097] train: loss: 0.0475456
[Epoch 17; Iter   748/ 1097] train: loss: 0.2549519
[Epoch 17; Iter   778/ 1097] train: loss: 0.0782279
[Epoch 17; Iter   808/ 1097] train: loss: 0.1155108
[Epoch 17; Iter   838/ 1097] train: loss: 0.0873927
[Epoch 17; Iter   868/ 1097] train: loss: 0.0191892
[Epoch 17; Iter   898/ 1097] train: loss: 0.1427539
[Epoch 17; Iter   928/ 1097] train: loss: 0.1763971
[Epoch 17; Iter   958/ 1097] train: loss: 0.0199066
[Epoch 17; Iter   988/ 1097] train: loss: 0.1497745
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0651237
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2151372
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1961898
[Epoch 17] ogbg-molhiv: 0.774119 val loss: 0.309646
[Epoch 17] ogbg-molhiv: 0.670343 test loss: 0.143864
[Epoch 18; Iter    11/ 1097] train: loss: 0.0381187
[Epoch 18; Iter    41/ 1097] train: loss: 0.2271218
[Epoch 18; Iter    71/ 1097] train: loss: 0.1549912
[Epoch 18; Iter   101/ 1097] train: loss: 0.0799436
[Epoch 18; Iter   131/ 1097] train: loss: 0.1042217
[Epoch 18; Iter   161/ 1097] train: loss: 0.0423780
[Epoch 18; Iter   191/ 1097] train: loss: 0.0155422
[Epoch 18; Iter   221/ 1097] train: loss: 0.0730769
[Epoch 18; Iter   251/ 1097] train: loss: 0.0286257
[Epoch 18; Iter   281/ 1097] train: loss: 0.1032887
[Epoch 18; Iter   311/ 1097] train: loss: 0.0521986
[Epoch 18; Iter   341/ 1097] train: loss: 0.0191853
[Epoch 18; Iter   371/ 1097] train: loss: 0.0393180
[Epoch 18; Iter   401/ 1097] train: loss: 0.0672564
[Epoch 18; Iter   431/ 1097] train: loss: 0.0483982
[Epoch 18; Iter   461/ 1097] train: loss: 0.1332890
[Epoch 18; Iter   491/ 1097] train: loss: 0.0267595
[Epoch 18; Iter   521/ 1097] train: loss: 0.0820606
[Epoch 18; Iter   551/ 1097] train: loss: 0.0460186
[Epoch 18; Iter   581/ 1097] train: loss: 0.0264891
[Epoch 18; Iter   611/ 1097] train: loss: 0.0274075
[Epoch 18; Iter   641/ 1097] train: loss: 0.0473162
[Epoch 18; Iter   671/ 1097] train: loss: 0.0556807
[Epoch 18; Iter   701/ 1097] train: loss: 0.0237362
[Epoch 18; Iter   731/ 1097] train: loss: 0.1072405
[Epoch 18; Iter   761/ 1097] train: loss: 0.0295370
[Epoch 18; Iter   791/ 1097] train: loss: 0.0489749
[Epoch 18; Iter   821/ 1097] train: loss: 0.1754636
[Epoch 18; Iter   851/ 1097] train: loss: 0.0324966
[Epoch 18; Iter   881/ 1097] train: loss: 0.0288988
[Epoch 18; Iter   911/ 1097] train: loss: 0.0244272
[Epoch 18; Iter   941/ 1097] train: loss: 0.1301097
[Epoch 18; Iter   971/ 1097] train: loss: 0.0207647
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1805850
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0725345
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0156074
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0121243
[Epoch 18] ogbg-molhiv: 0.742976 val loss: 0.096322
[Epoch 18] ogbg-molhiv: 0.533363 test loss: 0.235763
[Epoch 19; Iter    24/ 1097] train: loss: 0.0174477
[Epoch 19; Iter    54/ 1097] train: loss: 0.0536709
[Epoch 19; Iter    84/ 1097] train: loss: 0.0488565
[Epoch 19; Iter   114/ 1097] train: loss: 0.0196740
[Epoch 19; Iter   144/ 1097] train: loss: 0.0477306
[Epoch 19; Iter   174/ 1097] train: loss: 0.0115198
[Epoch 19; Iter   204/ 1097] train: loss: 0.0565788
[Epoch 19; Iter   234/ 1097] train: loss: 0.0236770
[Epoch 19; Iter   264/ 1097] train: loss: 0.0191220
[Epoch 19; Iter   294/ 1097] train: loss: 0.0470594
[Epoch 19; Iter   324/ 1097] train: loss: 0.0317276
[Epoch 19; Iter   354/ 1097] train: loss: 0.1717095
[Epoch 19; Iter   384/ 1097] train: loss: 0.0287001
[Epoch 19; Iter   414/ 1097] train: loss: 0.0224411
[Epoch 19; Iter   444/ 1097] train: loss: 0.0238309
[Epoch 19; Iter   474/ 1097] train: loss: 0.1649384
[Epoch 19; Iter   504/ 1097] train: loss: 0.0268742
[Epoch 19; Iter   534/ 1097] train: loss: 0.0609998
[Epoch 19; Iter   564/ 1097] train: loss: 0.1014601
[Epoch 19; Iter   594/ 1097] train: loss: 0.0670669
[Epoch 19; Iter   624/ 1097] train: loss: 0.0453854
[Epoch 19; Iter   654/ 1097] train: loss: 0.0388564
[Epoch 19; Iter   684/ 1097] train: loss: 0.2680767
[Epoch 19; Iter   714/ 1097] train: loss: 0.0118495
[Epoch 19; Iter   744/ 1097] train: loss: 0.0493599
[Epoch 19; Iter   774/ 1097] train: loss: 0.2237931
[Epoch 19; Iter   804/ 1097] train: loss: 0.0151930
[Epoch 19; Iter   834/ 1097] train: loss: 0.0413537
[Epoch 19; Iter   864/ 1097] train: loss: 0.0296385
[Epoch 19; Iter   894/ 1097] train: loss: 0.2904666
[Epoch 19; Iter   924/ 1097] train: loss: 0.0746061
[Epoch 19; Iter   954/ 1097] train: loss: 0.0227322
[Epoch 19; Iter   984/ 1097] train: loss: 0.1425942
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1319218
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1660336
[Epoch 19; Iter  1074/ 1097] train: loss: 0.2424949
[Epoch 19] ogbg-molhiv: 0.725563 val loss: 0.102443
[Epoch 19] ogbg-molhiv: 0.609301 test loss: 0.264684
[Epoch 20; Iter     7/ 1097] train: loss: 0.0147641
[Epoch 20; Iter    37/ 1097] train: loss: 0.0766545
[Epoch 20; Iter    67/ 1097] train: loss: 0.0190847
[Epoch 20; Iter    97/ 1097] train: loss: 0.0239379
[Epoch 20; Iter   127/ 1097] train: loss: 0.0392788
[Epoch 20; Iter   157/ 1097] train: loss: 0.0199417
[Epoch 20; Iter   187/ 1097] train: loss: 0.0933201
[Epoch 20; Iter   217/ 1097] train: loss: 0.1616689
[Epoch 20; Iter   247/ 1097] train: loss: 0.0230487
[Epoch 16; Iter   195/ 1097] train: loss: 0.0463369
[Epoch 16; Iter   225/ 1097] train: loss: 0.0625193
[Epoch 16; Iter   255/ 1097] train: loss: 0.0933698
[Epoch 16; Iter   285/ 1097] train: loss: 0.1535255
[Epoch 16; Iter   315/ 1097] train: loss: 0.0234534
[Epoch 16; Iter   345/ 1097] train: loss: 0.0306147
[Epoch 16; Iter   375/ 1097] train: loss: 0.1609144
[Epoch 16; Iter   405/ 1097] train: loss: 0.1860694
[Epoch 16; Iter   435/ 1097] train: loss: 0.1209783
[Epoch 16; Iter   465/ 1097] train: loss: 0.1688572
[Epoch 16; Iter   495/ 1097] train: loss: 0.1471074
[Epoch 16; Iter   525/ 1097] train: loss: 0.1332524
[Epoch 16; Iter   555/ 1097] train: loss: 0.0226254
[Epoch 16; Iter   585/ 1097] train: loss: 0.1180489
[Epoch 16; Iter   615/ 1097] train: loss: 0.0585273
[Epoch 16; Iter   645/ 1097] train: loss: 0.0287219
[Epoch 16; Iter   675/ 1097] train: loss: 0.0824281
[Epoch 16; Iter   705/ 1097] train: loss: 0.1054277
[Epoch 16; Iter   735/ 1097] train: loss: 0.0699884
[Epoch 16; Iter   765/ 1097] train: loss: 0.0539023
[Epoch 16; Iter   795/ 1097] train: loss: 0.0507590
[Epoch 16; Iter   825/ 1097] train: loss: 0.0263352
[Epoch 16; Iter   855/ 1097] train: loss: 0.0919597
[Epoch 16; Iter   885/ 1097] train: loss: 0.2814760
[Epoch 16; Iter   915/ 1097] train: loss: 0.0260838
[Epoch 16; Iter   945/ 1097] train: loss: 0.0196881
[Epoch 16; Iter   975/ 1097] train: loss: 0.0330888
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0533780
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0293174
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0310860
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0983225
[Epoch 16] ogbg-molhiv: 0.758870 val loss: 0.097062
[Epoch 16] ogbg-molhiv: 0.665013 test loss: 0.149204
[Epoch 17; Iter    28/ 1097] train: loss: 0.0183101
[Epoch 17; Iter    58/ 1097] train: loss: 0.0248406
[Epoch 17; Iter    88/ 1097] train: loss: 0.0568354
[Epoch 17; Iter   118/ 1097] train: loss: 0.1023346
[Epoch 17; Iter   148/ 1097] train: loss: 0.1719582
[Epoch 17; Iter   178/ 1097] train: loss: 0.0297763
[Epoch 17; Iter   208/ 1097] train: loss: 0.0224245
[Epoch 17; Iter   238/ 1097] train: loss: 0.2474755
[Epoch 17; Iter   268/ 1097] train: loss: 0.0166337
[Epoch 17; Iter   298/ 1097] train: loss: 0.0659921
[Epoch 17; Iter   328/ 1097] train: loss: 0.0269267
[Epoch 17; Iter   358/ 1097] train: loss: 0.0425030
[Epoch 17; Iter   388/ 1097] train: loss: 0.0444926
[Epoch 17; Iter   418/ 1097] train: loss: 0.2605773
[Epoch 17; Iter   448/ 1097] train: loss: 0.0232783
[Epoch 17; Iter   478/ 1097] train: loss: 0.0260845
[Epoch 17; Iter   508/ 1097] train: loss: 0.0455820
[Epoch 17; Iter   538/ 1097] train: loss: 0.1792871
[Epoch 17; Iter   568/ 1097] train: loss: 0.2198478
[Epoch 17; Iter   598/ 1097] train: loss: 0.1284648
[Epoch 17; Iter   628/ 1097] train: loss: 0.0975051
[Epoch 17; Iter   658/ 1097] train: loss: 0.0287964
[Epoch 17; Iter   688/ 1097] train: loss: 0.2229968
[Epoch 17; Iter   718/ 1097] train: loss: 0.0431424
[Epoch 17; Iter   748/ 1097] train: loss: 0.1176073
[Epoch 17; Iter   778/ 1097] train: loss: 0.0393111
[Epoch 17; Iter   808/ 1097] train: loss: 0.1377529
[Epoch 17; Iter   838/ 1097] train: loss: 0.1128280
[Epoch 17; Iter   868/ 1097] train: loss: 0.0264571
[Epoch 17; Iter   898/ 1097] train: loss: 0.1417463
[Epoch 17; Iter   928/ 1097] train: loss: 0.2416926
[Epoch 17; Iter   958/ 1097] train: loss: 0.1910189
[Epoch 17; Iter   988/ 1097] train: loss: 0.0165247
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0519290
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0286030
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1499024
[Epoch 17] ogbg-molhiv: 0.773500 val loss: 0.144753
[Epoch 17] ogbg-molhiv: 0.727397 test loss: 0.177403
[Epoch 18; Iter    11/ 1097] train: loss: 0.1384208
[Epoch 18; Iter    41/ 1097] train: loss: 0.2720132
[Epoch 18; Iter    71/ 1097] train: loss: 0.0662043
[Epoch 18; Iter   101/ 1097] train: loss: 0.0818949
[Epoch 18; Iter   131/ 1097] train: loss: 0.0499722
[Epoch 18; Iter   161/ 1097] train: loss: 0.0353912
[Epoch 18; Iter   191/ 1097] train: loss: 0.0635391
[Epoch 18; Iter   221/ 1097] train: loss: 0.1610649
[Epoch 18; Iter   251/ 1097] train: loss: 0.0813380
[Epoch 18; Iter   281/ 1097] train: loss: 0.0206053
[Epoch 18; Iter   311/ 1097] train: loss: 0.0748193
[Epoch 18; Iter   341/ 1097] train: loss: 0.0626596
[Epoch 18; Iter   371/ 1097] train: loss: 0.0721448
[Epoch 18; Iter   401/ 1097] train: loss: 0.2086032
[Epoch 18; Iter   431/ 1097] train: loss: 0.3060096
[Epoch 18; Iter   461/ 1097] train: loss: 0.0418810
[Epoch 18; Iter   491/ 1097] train: loss: 0.0697242
[Epoch 18; Iter   521/ 1097] train: loss: 0.1092919
[Epoch 18; Iter   551/ 1097] train: loss: 0.0312680
[Epoch 18; Iter   581/ 1097] train: loss: 0.0616981
[Epoch 18; Iter   611/ 1097] train: loss: 0.0269517
[Epoch 18; Iter   641/ 1097] train: loss: 0.1722797
[Epoch 18; Iter   671/ 1097] train: loss: 0.1809730
[Epoch 18; Iter   701/ 1097] train: loss: 0.2076194
[Epoch 18; Iter   731/ 1097] train: loss: 0.1176975
[Epoch 18; Iter   761/ 1097] train: loss: 0.2132162
[Epoch 18; Iter   791/ 1097] train: loss: 0.0166828
[Epoch 18; Iter   821/ 1097] train: loss: 0.0797581
[Epoch 18; Iter   851/ 1097] train: loss: 0.1051346
[Epoch 18; Iter   881/ 1097] train: loss: 0.0930073
[Epoch 18; Iter   911/ 1097] train: loss: 0.0785540
[Epoch 18; Iter   941/ 1097] train: loss: 0.0238318
[Epoch 18; Iter   971/ 1097] train: loss: 0.0952312
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0250386
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0269078
[Epoch 18; Iter  1061/ 1097] train: loss: 0.1323246
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1311911
[Epoch 18] ogbg-molhiv: 0.758365 val loss: 0.099464
[Epoch 18] ogbg-molhiv: 0.660795 test loss: 0.165607
[Epoch 19; Iter    24/ 1097] train: loss: 0.2567469
[Epoch 19; Iter    54/ 1097] train: loss: 0.1111066
[Epoch 19; Iter    84/ 1097] train: loss: 0.1912265
[Epoch 19; Iter   114/ 1097] train: loss: 0.0282433
[Epoch 19; Iter   144/ 1097] train: loss: 0.1306815
[Epoch 19; Iter   174/ 1097] train: loss: 0.0585686
[Epoch 19; Iter   204/ 1097] train: loss: 0.0868375
[Epoch 19; Iter   234/ 1097] train: loss: 0.0231727
[Epoch 19; Iter   264/ 1097] train: loss: 0.0888195
[Epoch 19; Iter   294/ 1097] train: loss: 0.0524552
[Epoch 19; Iter   324/ 1097] train: loss: 0.0521973
[Epoch 19; Iter   354/ 1097] train: loss: 0.1278060
[Epoch 19; Iter   384/ 1097] train: loss: 0.0231903
[Epoch 19; Iter   414/ 1097] train: loss: 0.0147715
[Epoch 19; Iter   444/ 1097] train: loss: 0.3507547
[Epoch 19; Iter   474/ 1097] train: loss: 0.1914902
[Epoch 19; Iter   504/ 1097] train: loss: 0.1187539
[Epoch 19; Iter   534/ 1097] train: loss: 0.1328149
[Epoch 19; Iter   564/ 1097] train: loss: 0.0410909
[Epoch 19; Iter   594/ 1097] train: loss: 0.0300209
[Epoch 19; Iter   624/ 1097] train: loss: 0.0551132
[Epoch 19; Iter   654/ 1097] train: loss: 0.1019056
[Epoch 19; Iter   684/ 1097] train: loss: 0.0764924
[Epoch 19; Iter   714/ 1097] train: loss: 0.1004256
[Epoch 19; Iter   744/ 1097] train: loss: 0.0817837
[Epoch 19; Iter   774/ 1097] train: loss: 0.1379566
[Epoch 19; Iter   804/ 1097] train: loss: 0.0507388
[Epoch 19; Iter   834/ 1097] train: loss: 0.1474578
[Epoch 19; Iter   864/ 1097] train: loss: 0.2452882
[Epoch 19; Iter   894/ 1097] train: loss: 0.0967797
[Epoch 19; Iter   924/ 1097] train: loss: 0.2869693
[Epoch 19; Iter   954/ 1097] train: loss: 0.1699100
[Epoch 19; Iter   984/ 1097] train: loss: 0.1679255
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0440526
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0998871
[Epoch 19; Iter  1074/ 1097] train: loss: 0.1595499
[Epoch 19] ogbg-molhiv: 0.788770 val loss: 0.090970
[Epoch 19] ogbg-molhiv: 0.681195 test loss: 0.152957
[Epoch 20; Iter     7/ 1097] train: loss: 0.0448612
[Epoch 20; Iter    37/ 1097] train: loss: 0.1494042
[Epoch 20; Iter    67/ 1097] train: loss: 0.0167510
[Epoch 20; Iter    97/ 1097] train: loss: 0.0180847
[Epoch 20; Iter   127/ 1097] train: loss: 0.0250043
[Epoch 20; Iter   157/ 1097] train: loss: 0.1186521
[Epoch 20; Iter   187/ 1097] train: loss: 0.0181742
[Epoch 20; Iter   217/ 1097] train: loss: 0.0229712
[Epoch 20; Iter   247/ 1097] train: loss: 0.0178643
[Epoch 16; Iter   195/ 1097] train: loss: 0.0454059
[Epoch 16; Iter   225/ 1097] train: loss: 0.0386491
[Epoch 16; Iter   255/ 1097] train: loss: 0.0241137
[Epoch 16; Iter   285/ 1097] train: loss: 0.2506876
[Epoch 16; Iter   315/ 1097] train: loss: 0.0398978
[Epoch 16; Iter   345/ 1097] train: loss: 0.0607298
[Epoch 16; Iter   375/ 1097] train: loss: 0.1277761
[Epoch 16; Iter   405/ 1097] train: loss: 0.0169203
[Epoch 16; Iter   435/ 1097] train: loss: 0.2484235
[Epoch 16; Iter   465/ 1097] train: loss: 0.0268882
[Epoch 16; Iter   495/ 1097] train: loss: 0.0294226
[Epoch 16; Iter   525/ 1097] train: loss: 0.1805042
[Epoch 16; Iter   555/ 1097] train: loss: 0.0410281
[Epoch 16; Iter   585/ 1097] train: loss: 0.3376302
[Epoch 16; Iter   615/ 1097] train: loss: 0.0918156
[Epoch 16; Iter   645/ 1097] train: loss: 0.0645248
[Epoch 16; Iter   675/ 1097] train: loss: 0.0470480
[Epoch 16; Iter   705/ 1097] train: loss: 0.0353316
[Epoch 16; Iter   735/ 1097] train: loss: 0.2886291
[Epoch 16; Iter   765/ 1097] train: loss: 0.0264176
[Epoch 16; Iter   795/ 1097] train: loss: 0.0324879
[Epoch 16; Iter   825/ 1097] train: loss: 0.1023302
[Epoch 16; Iter   855/ 1097] train: loss: 0.1826651
[Epoch 16; Iter   885/ 1097] train: loss: 0.0230157
[Epoch 16; Iter   915/ 1097] train: loss: 0.0296154
[Epoch 16; Iter   945/ 1097] train: loss: 0.1065522
[Epoch 16; Iter   975/ 1097] train: loss: 0.2152422
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2129761
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0271007
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1429419
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1355229
[Epoch 16] ogbg-molhiv: 0.777312 val loss: 0.334360
[Epoch 16] ogbg-molhiv: 0.703451 test loss: 0.285003
[Epoch 17; Iter    28/ 1097] train: loss: 0.1543417
[Epoch 17; Iter    58/ 1097] train: loss: 0.0378974
[Epoch 17; Iter    88/ 1097] train: loss: 0.0970686
[Epoch 17; Iter   118/ 1097] train: loss: 0.2306900
[Epoch 17; Iter   148/ 1097] train: loss: 0.0446868
[Epoch 17; Iter   178/ 1097] train: loss: 0.0966736
[Epoch 17; Iter   208/ 1097] train: loss: 0.0326278
[Epoch 17; Iter   238/ 1097] train: loss: 0.0989633
[Epoch 17; Iter   268/ 1097] train: loss: 0.0371139
[Epoch 17; Iter   298/ 1097] train: loss: 0.2486378
[Epoch 17; Iter   328/ 1097] train: loss: 0.2317724
[Epoch 17; Iter   358/ 1097] train: loss: 0.0548531
[Epoch 17; Iter   388/ 1097] train: loss: 0.1367170
[Epoch 17; Iter   418/ 1097] train: loss: 0.2153207
[Epoch 17; Iter   448/ 1097] train: loss: 0.0300925
[Epoch 17; Iter   478/ 1097] train: loss: 0.0988020
[Epoch 17; Iter   508/ 1097] train: loss: 0.2005128
[Epoch 17; Iter   538/ 1097] train: loss: 0.0237869
[Epoch 17; Iter   568/ 1097] train: loss: 0.2405195
[Epoch 17; Iter   598/ 1097] train: loss: 0.0589343
[Epoch 17; Iter   628/ 1097] train: loss: 0.0884073
[Epoch 17; Iter   658/ 1097] train: loss: 0.0925593
[Epoch 17; Iter   688/ 1097] train: loss: 0.0407565
[Epoch 17; Iter   718/ 1097] train: loss: 0.1131832
[Epoch 17; Iter   748/ 1097] train: loss: 0.0203301
[Epoch 17; Iter   778/ 1097] train: loss: 0.2695547
[Epoch 17; Iter   808/ 1097] train: loss: 0.0217891
[Epoch 17; Iter   838/ 1097] train: loss: 0.0126494
[Epoch 17; Iter   868/ 1097] train: loss: 0.0281938
[Epoch 17; Iter   898/ 1097] train: loss: 0.0512469
[Epoch 17; Iter   928/ 1097] train: loss: 0.2859973
[Epoch 17; Iter   958/ 1097] train: loss: 0.0583620
[Epoch 17; Iter   988/ 1097] train: loss: 0.0286756
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0393223
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0397764
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0425742
[Epoch 17] ogbg-molhiv: 0.722372 val loss: 0.309337
[Epoch 17] ogbg-molhiv: 0.659860 test loss: 0.332923
[Epoch 18; Iter    11/ 1097] train: loss: 0.1583024
[Epoch 18; Iter    41/ 1097] train: loss: 0.0273269
[Epoch 18; Iter    71/ 1097] train: loss: 0.0616313
[Epoch 18; Iter   101/ 1097] train: loss: 0.0379104
[Epoch 18; Iter   131/ 1097] train: loss: 0.1819662
[Epoch 18; Iter   161/ 1097] train: loss: 0.2026893
[Epoch 18; Iter   191/ 1097] train: loss: 0.0831843
[Epoch 18; Iter   221/ 1097] train: loss: 0.0206311
[Epoch 18; Iter   251/ 1097] train: loss: 0.0280792
[Epoch 18; Iter   281/ 1097] train: loss: 0.0193496
[Epoch 18; Iter   311/ 1097] train: loss: 0.2283487
[Epoch 18; Iter   341/ 1097] train: loss: 0.1595934
[Epoch 18; Iter   371/ 1097] train: loss: 0.0223583
[Epoch 18; Iter   401/ 1097] train: loss: 0.0724511
[Epoch 18; Iter   431/ 1097] train: loss: 0.0176477
[Epoch 18; Iter   461/ 1097] train: loss: 0.0535851
[Epoch 18; Iter   491/ 1097] train: loss: 0.2047714
[Epoch 18; Iter   521/ 1097] train: loss: 0.0488290
[Epoch 18; Iter   551/ 1097] train: loss: 0.0790367
[Epoch 18; Iter   581/ 1097] train: loss: 0.0335788
[Epoch 18; Iter   611/ 1097] train: loss: 0.0913332
[Epoch 18; Iter   641/ 1097] train: loss: 0.0434563
[Epoch 18; Iter   671/ 1097] train: loss: 0.1180825
[Epoch 18; Iter   701/ 1097] train: loss: 0.2071074
[Epoch 18; Iter   731/ 1097] train: loss: 0.1859605
[Epoch 18; Iter   761/ 1097] train: loss: 0.0154081
[Epoch 18; Iter   791/ 1097] train: loss: 0.0519867
[Epoch 18; Iter   821/ 1097] train: loss: 0.0472988
[Epoch 18; Iter   851/ 1097] train: loss: 0.1081593
[Epoch 18; Iter   881/ 1097] train: loss: 0.0192264
[Epoch 18; Iter   911/ 1097] train: loss: 0.0928283
[Epoch 18; Iter   941/ 1097] train: loss: 0.0652571
[Epoch 18; Iter   971/ 1097] train: loss: 0.1028656
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1040597
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0195274
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0264810
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0293896
[Epoch 18] ogbg-molhiv: 0.766721 val loss: 0.329618
[Epoch 18] ogbg-molhiv: 0.709224 test loss: 0.291005
[Epoch 19; Iter    24/ 1097] train: loss: 0.0367339
[Epoch 19; Iter    54/ 1097] train: loss: 0.1153070
[Epoch 19; Iter    84/ 1097] train: loss: 0.0250882
[Epoch 19; Iter   114/ 1097] train: loss: 0.0663525
[Epoch 19; Iter   144/ 1097] train: loss: 0.0651526
[Epoch 19; Iter   174/ 1097] train: loss: 0.0837267
[Epoch 19; Iter   204/ 1097] train: loss: 0.0525649
[Epoch 19; Iter   234/ 1097] train: loss: 0.1451169
[Epoch 19; Iter   264/ 1097] train: loss: 0.0529776
[Epoch 19; Iter   294/ 1097] train: loss: 0.0765417
[Epoch 19; Iter   324/ 1097] train: loss: 0.0393327
[Epoch 19; Iter   354/ 1097] train: loss: 0.0282104
[Epoch 19; Iter   384/ 1097] train: loss: 0.0805617
[Epoch 19; Iter   414/ 1097] train: loss: 0.2145037
[Epoch 19; Iter   444/ 1097] train: loss: 0.0288084
[Epoch 19; Iter   474/ 1097] train: loss: 0.0225515
[Epoch 19; Iter   504/ 1097] train: loss: 0.1958012
[Epoch 19; Iter   534/ 1097] train: loss: 0.3410952
[Epoch 19; Iter   564/ 1097] train: loss: 0.1830204
[Epoch 19; Iter   594/ 1097] train: loss: 0.0516266
[Epoch 19; Iter   624/ 1097] train: loss: 0.0488473
[Epoch 19; Iter   654/ 1097] train: loss: 0.1092161
[Epoch 19; Iter   684/ 1097] train: loss: 0.0604636
[Epoch 19; Iter   714/ 1097] train: loss: 0.0366660
[Epoch 19; Iter   744/ 1097] train: loss: 0.1875499
[Epoch 19; Iter   774/ 1097] train: loss: 0.0855722
[Epoch 19; Iter   804/ 1097] train: loss: 0.0186105
[Epoch 19; Iter   834/ 1097] train: loss: 0.2084542
[Epoch 19; Iter   864/ 1097] train: loss: 0.1799582
[Epoch 19; Iter   894/ 1097] train: loss: 0.0447161
[Epoch 19; Iter   924/ 1097] train: loss: 0.0367570
[Epoch 19; Iter   954/ 1097] train: loss: 0.1145125
[Epoch 19; Iter   984/ 1097] train: loss: 0.0362050
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2080773
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1086517
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0187826
[Epoch 19] ogbg-molhiv: 0.707231 val loss: 0.101744
[Epoch 19] ogbg-molhiv: 0.617743 test loss: 0.182220
[Epoch 20; Iter     7/ 1097] train: loss: 0.0730919
[Epoch 20; Iter    37/ 1097] train: loss: 0.2913192
[Epoch 20; Iter    67/ 1097] train: loss: 0.0232878
[Epoch 20; Iter    97/ 1097] train: loss: 0.0195119
[Epoch 20; Iter   127/ 1097] train: loss: 0.1790703
[Epoch 20; Iter   157/ 1097] train: loss: 0.0401898
[Epoch 20; Iter   187/ 1097] train: loss: 0.0283698
[Epoch 20; Iter   217/ 1097] train: loss: 0.0514347
[Epoch 20; Iter   247/ 1097] train: loss: 0.0630974
[Epoch 16; Iter   195/ 1097] train: loss: 0.0175211
[Epoch 16; Iter   225/ 1097] train: loss: 0.1228231
[Epoch 16; Iter   255/ 1097] train: loss: 0.0676149
[Epoch 16; Iter   285/ 1097] train: loss: 0.1897915
[Epoch 16; Iter   315/ 1097] train: loss: 0.0532158
[Epoch 16; Iter   345/ 1097] train: loss: 0.2327514
[Epoch 16; Iter   375/ 1097] train: loss: 0.1037902
[Epoch 16; Iter   405/ 1097] train: loss: 0.0200095
[Epoch 16; Iter   435/ 1097] train: loss: 0.3388332
[Epoch 16; Iter   465/ 1097] train: loss: 0.0552416
[Epoch 16; Iter   495/ 1097] train: loss: 0.0451640
[Epoch 16; Iter   525/ 1097] train: loss: 0.1588012
[Epoch 16; Iter   555/ 1097] train: loss: 0.0296139
[Epoch 16; Iter   585/ 1097] train: loss: 0.2063080
[Epoch 16; Iter   615/ 1097] train: loss: 0.0765817
[Epoch 16; Iter   645/ 1097] train: loss: 0.0513742
[Epoch 16; Iter   675/ 1097] train: loss: 0.0404734
[Epoch 16; Iter   705/ 1097] train: loss: 0.0378986
[Epoch 16; Iter   735/ 1097] train: loss: 0.3137000
[Epoch 16; Iter   765/ 1097] train: loss: 0.0309210
[Epoch 16; Iter   795/ 1097] train: loss: 0.0305200
[Epoch 16; Iter   825/ 1097] train: loss: 0.1776843
[Epoch 16; Iter   855/ 1097] train: loss: 0.1952048
[Epoch 16; Iter   885/ 1097] train: loss: 0.0207114
[Epoch 16; Iter   915/ 1097] train: loss: 0.0214893
[Epoch 16; Iter   945/ 1097] train: loss: 0.1045892
[Epoch 16; Iter   975/ 1097] train: loss: 0.1359007
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2370067
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0841363
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1451632
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1629224
[Epoch 16] ogbg-molhiv: 0.802114 val loss: 0.377345
[Epoch 16] ogbg-molhiv: 0.791807 test loss: 0.115315
[Epoch 17; Iter    28/ 1097] train: loss: 0.2305799
[Epoch 17; Iter    58/ 1097] train: loss: 0.0275923
[Epoch 17; Iter    88/ 1097] train: loss: 0.1364703
[Epoch 17; Iter   118/ 1097] train: loss: 0.1418718
[Epoch 17; Iter   148/ 1097] train: loss: 0.0203345
[Epoch 17; Iter   178/ 1097] train: loss: 0.1792091
[Epoch 17; Iter   208/ 1097] train: loss: 0.0387694
[Epoch 17; Iter   238/ 1097] train: loss: 0.2296588
[Epoch 17; Iter   268/ 1097] train: loss: 0.0265491
[Epoch 17; Iter   298/ 1097] train: loss: 0.2202344
[Epoch 17; Iter   328/ 1097] train: loss: 0.2375648
[Epoch 17; Iter   358/ 1097] train: loss: 0.0465961
[Epoch 17; Iter   388/ 1097] train: loss: 0.1669086
[Epoch 17; Iter   418/ 1097] train: loss: 0.1712440
[Epoch 17; Iter   448/ 1097] train: loss: 0.0248751
[Epoch 17; Iter   478/ 1097] train: loss: 0.0439651
[Epoch 17; Iter   508/ 1097] train: loss: 0.0210225
[Epoch 17; Iter   538/ 1097] train: loss: 0.0371569
[Epoch 17; Iter   568/ 1097] train: loss: 0.2371570
[Epoch 17; Iter   598/ 1097] train: loss: 0.0287792
[Epoch 17; Iter   628/ 1097] train: loss: 0.1401980
[Epoch 17; Iter   658/ 1097] train: loss: 0.0558225
[Epoch 17; Iter   688/ 1097] train: loss: 0.0798390
[Epoch 17; Iter   718/ 1097] train: loss: 0.1843421
[Epoch 17; Iter   748/ 1097] train: loss: 0.0236667
[Epoch 17; Iter   778/ 1097] train: loss: 0.1965834
[Epoch 17; Iter   808/ 1097] train: loss: 0.0269359
[Epoch 17; Iter   838/ 1097] train: loss: 0.0233098
[Epoch 17; Iter   868/ 1097] train: loss: 0.0361136
[Epoch 17; Iter   898/ 1097] train: loss: 0.0349869
[Epoch 17; Iter   928/ 1097] train: loss: 0.3533826
[Epoch 17; Iter   958/ 1097] train: loss: 0.0920064
[Epoch 17; Iter   988/ 1097] train: loss: 0.0486482
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0380298
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0392408
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1528326
[Epoch 17] ogbg-molhiv: 0.780760 val loss: 0.301819
[Epoch 17] ogbg-molhiv: 0.763024 test loss: 0.119211
[Epoch 18; Iter    11/ 1097] train: loss: 0.1326492
[Epoch 18; Iter    41/ 1097] train: loss: 0.0217401
[Epoch 18; Iter    71/ 1097] train: loss: 0.1974562
[Epoch 18; Iter   101/ 1097] train: loss: 0.0261707
[Epoch 18; Iter   131/ 1097] train: loss: 0.1302109
[Epoch 18; Iter   161/ 1097] train: loss: 0.1447437
[Epoch 18; Iter   191/ 1097] train: loss: 0.0722018
[Epoch 18; Iter   221/ 1097] train: loss: 0.0215740
[Epoch 18; Iter   251/ 1097] train: loss: 0.0863003
[Epoch 18; Iter   281/ 1097] train: loss: 0.0182797
[Epoch 18; Iter   311/ 1097] train: loss: 0.3141700
[Epoch 18; Iter   341/ 1097] train: loss: 0.1790174
[Epoch 18; Iter   371/ 1097] train: loss: 0.0277089
[Epoch 18; Iter   401/ 1097] train: loss: 0.0221727
[Epoch 18; Iter   431/ 1097] train: loss: 0.0309687
[Epoch 18; Iter   461/ 1097] train: loss: 0.0465542
[Epoch 18; Iter   491/ 1097] train: loss: 0.1445250
[Epoch 18; Iter   521/ 1097] train: loss: 0.0382513
[Epoch 18; Iter   551/ 1097] train: loss: 0.0961404
[Epoch 18; Iter   581/ 1097] train: loss: 0.0205479
[Epoch 18; Iter   611/ 1097] train: loss: 0.1877534
[Epoch 18; Iter   641/ 1097] train: loss: 0.0993221
[Epoch 18; Iter   671/ 1097] train: loss: 0.1561724
[Epoch 18; Iter   701/ 1097] train: loss: 0.0827701
[Epoch 18; Iter   731/ 1097] train: loss: 0.2124842
[Epoch 18; Iter   761/ 1097] train: loss: 0.0461454
[Epoch 18; Iter   791/ 1097] train: loss: 0.0721952
[Epoch 18; Iter   821/ 1097] train: loss: 0.0599534
[Epoch 18; Iter   851/ 1097] train: loss: 0.1890769
[Epoch 18; Iter   881/ 1097] train: loss: 0.0301606
[Epoch 18; Iter   911/ 1097] train: loss: 0.1225287
[Epoch 18; Iter   941/ 1097] train: loss: 0.0306965
[Epoch 18; Iter   971/ 1097] train: loss: 0.0250676
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1145544
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0197851
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0303833
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0311537
[Epoch 18] ogbg-molhiv: 0.813850 val loss: 0.195476
[Epoch 18] ogbg-molhiv: 0.760105 test loss: 0.118732
[Epoch 19; Iter    24/ 1097] train: loss: 0.1278546
[Epoch 19; Iter    54/ 1097] train: loss: 0.1456003
[Epoch 19; Iter    84/ 1097] train: loss: 0.0264975
[Epoch 19; Iter   114/ 1097] train: loss: 0.1108553
[Epoch 19; Iter   144/ 1097] train: loss: 0.2213443
[Epoch 19; Iter   174/ 1097] train: loss: 0.0995252
[Epoch 19; Iter   204/ 1097] train: loss: 0.1318345
[Epoch 19; Iter   234/ 1097] train: loss: 0.2024834
[Epoch 19; Iter   264/ 1097] train: loss: 0.2245806
[Epoch 19; Iter   294/ 1097] train: loss: 0.1863631
[Epoch 19; Iter   324/ 1097] train: loss: 0.0940858
[Epoch 19; Iter   354/ 1097] train: loss: 0.0629986
[Epoch 19; Iter   384/ 1097] train: loss: 0.2109799
[Epoch 19; Iter   414/ 1097] train: loss: 0.1626840
[Epoch 19; Iter   444/ 1097] train: loss: 0.0434689
[Epoch 19; Iter   474/ 1097] train: loss: 0.0221469
[Epoch 19; Iter   504/ 1097] train: loss: 0.0843977
[Epoch 19; Iter   534/ 1097] train: loss: 0.3007617
[Epoch 19; Iter   564/ 1097] train: loss: 0.2921522
[Epoch 19; Iter   594/ 1097] train: loss: 0.0268485
[Epoch 19; Iter   624/ 1097] train: loss: 0.0245548
[Epoch 19; Iter   654/ 1097] train: loss: 0.1709846
[Epoch 19; Iter   684/ 1097] train: loss: 0.2137431
[Epoch 19; Iter   714/ 1097] train: loss: 0.1072327
[Epoch 19; Iter   744/ 1097] train: loss: 0.1430644
[Epoch 19; Iter   774/ 1097] train: loss: 0.0799810
[Epoch 19; Iter   804/ 1097] train: loss: 0.0170031
[Epoch 19; Iter   834/ 1097] train: loss: 0.1886128
[Epoch 19; Iter   864/ 1097] train: loss: 0.1848057
[Epoch 19; Iter   894/ 1097] train: loss: 0.0444443
[Epoch 19; Iter   924/ 1097] train: loss: 0.1309975
[Epoch 19; Iter   954/ 1097] train: loss: 0.1791439
[Epoch 19; Iter   984/ 1097] train: loss: 0.0214239
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1990478
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0740681
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0198252
[Epoch 19] ogbg-molhiv: 0.774554 val loss: 0.145382
[Epoch 19] ogbg-molhiv: 0.724079 test loss: 0.130331
[Epoch 20; Iter     7/ 1097] train: loss: 0.1727504
[Epoch 20; Iter    37/ 1097] train: loss: 0.2029624
[Epoch 20; Iter    67/ 1097] train: loss: 0.0179521
[Epoch 20; Iter    97/ 1097] train: loss: 0.0589852
[Epoch 20; Iter   127/ 1097] train: loss: 0.2300526
[Epoch 20; Iter   157/ 1097] train: loss: 0.0232779
[Epoch 20; Iter   187/ 1097] train: loss: 0.0682032
[Epoch 20; Iter   217/ 1097] train: loss: 0.0333142
[Epoch 20; Iter   247/ 1097] train: loss: 0.1235240
[Epoch 16; Iter   195/ 1097] train: loss: 0.0281787
[Epoch 16; Iter   225/ 1097] train: loss: 0.0676288
[Epoch 16; Iter   255/ 1097] train: loss: 0.2467034
[Epoch 16; Iter   285/ 1097] train: loss: 0.0502532
[Epoch 16; Iter   315/ 1097] train: loss: 0.0205446
[Epoch 16; Iter   345/ 1097] train: loss: 0.1331705
[Epoch 16; Iter   375/ 1097] train: loss: 0.0454781
[Epoch 16; Iter   405/ 1097] train: loss: 0.0230454
[Epoch 16; Iter   435/ 1097] train: loss: 0.1100667
[Epoch 16; Iter   465/ 1097] train: loss: 0.1801157
[Epoch 16; Iter   495/ 1097] train: loss: 0.0379693
[Epoch 16; Iter   525/ 1097] train: loss: 0.0203044
[Epoch 16; Iter   555/ 1097] train: loss: 0.4308626
[Epoch 16; Iter   585/ 1097] train: loss: 0.0499452
[Epoch 16; Iter   615/ 1097] train: loss: 0.1394084
[Epoch 16; Iter   645/ 1097] train: loss: 0.1120294
[Epoch 16; Iter   675/ 1097] train: loss: 0.0773147
[Epoch 16; Iter   705/ 1097] train: loss: 0.0259375
[Epoch 16; Iter   735/ 1097] train: loss: 0.1803837
[Epoch 16; Iter   765/ 1097] train: loss: 0.4539680
[Epoch 16; Iter   795/ 1097] train: loss: 0.0412600
[Epoch 16; Iter   825/ 1097] train: loss: 0.0350329
[Epoch 16; Iter   855/ 1097] train: loss: 0.0386073
[Epoch 16; Iter   885/ 1097] train: loss: 0.1773188
[Epoch 16; Iter   915/ 1097] train: loss: 0.1464332
[Epoch 16; Iter   945/ 1097] train: loss: 0.0403020
[Epoch 16; Iter   975/ 1097] train: loss: 0.0218647
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1279055
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0493968
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0283957
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0215078
[Epoch 16] ogbg-molhiv: 0.814995 val loss: 0.067674
[Epoch 16] ogbg-molhiv: 0.737552 test loss: 0.119959
[Epoch 17; Iter    28/ 1097] train: loss: 0.1925481
[Epoch 17; Iter    58/ 1097] train: loss: 0.1273002
[Epoch 17; Iter    88/ 1097] train: loss: 0.1566765
[Epoch 17; Iter   118/ 1097] train: loss: 0.0151187
[Epoch 17; Iter   148/ 1097] train: loss: 0.0346071
[Epoch 17; Iter   178/ 1097] train: loss: 0.0244585
[Epoch 17; Iter   208/ 1097] train: loss: 0.0191323
[Epoch 17; Iter   238/ 1097] train: loss: 0.0350991
[Epoch 17; Iter   268/ 1097] train: loss: 0.0570824
[Epoch 17; Iter   298/ 1097] train: loss: 0.0750717
[Epoch 17; Iter   328/ 1097] train: loss: 0.1319435
[Epoch 17; Iter   358/ 1097] train: loss: 0.2829489
[Epoch 17; Iter   388/ 1097] train: loss: 0.0390072
[Epoch 17; Iter   418/ 1097] train: loss: 0.0468033
[Epoch 17; Iter   448/ 1097] train: loss: 0.0295505
[Epoch 17; Iter   478/ 1097] train: loss: 0.2182595
[Epoch 17; Iter   508/ 1097] train: loss: 0.0225329
[Epoch 17; Iter   538/ 1097] train: loss: 0.1214326
[Epoch 17; Iter   568/ 1097] train: loss: 0.0317243
[Epoch 17; Iter   598/ 1097] train: loss: 0.0828067
[Epoch 17; Iter   628/ 1097] train: loss: 0.0377480
[Epoch 17; Iter   658/ 1097] train: loss: 0.2043151
[Epoch 17; Iter   688/ 1097] train: loss: 0.0237209
[Epoch 17; Iter   718/ 1097] train: loss: 0.0824517
[Epoch 17; Iter   748/ 1097] train: loss: 0.1594870
[Epoch 17; Iter   778/ 1097] train: loss: 0.0699949
[Epoch 17; Iter   808/ 1097] train: loss: 0.1772410
[Epoch 17; Iter   838/ 1097] train: loss: 0.0628426
[Epoch 17; Iter   868/ 1097] train: loss: 0.0281925
[Epoch 17; Iter   898/ 1097] train: loss: 0.1229485
[Epoch 17; Iter   928/ 1097] train: loss: 0.2552623
[Epoch 17; Iter   958/ 1097] train: loss: 0.0225382
[Epoch 17; Iter   988/ 1097] train: loss: 0.1084323
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0367774
[Epoch 17; Iter  1048/ 1097] train: loss: 0.3257670
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2578586
[Epoch 17] ogbg-molhiv: 0.821361 val loss: 0.070523
[Epoch 17] ogbg-molhiv: 0.730825 test loss: 0.118353
[Epoch 18; Iter    11/ 1097] train: loss: 0.0246797
[Epoch 18; Iter    41/ 1097] train: loss: 0.1848543
[Epoch 18; Iter    71/ 1097] train: loss: 0.2255191
[Epoch 18; Iter   101/ 1097] train: loss: 0.0275654
[Epoch 18; Iter   131/ 1097] train: loss: 0.0988001
[Epoch 18; Iter   161/ 1097] train: loss: 0.2357624
[Epoch 18; Iter   191/ 1097] train: loss: 0.0464128
[Epoch 18; Iter   221/ 1097] train: loss: 0.0558542
[Epoch 18; Iter   251/ 1097] train: loss: 0.0284084
[Epoch 18; Iter   281/ 1097] train: loss: 0.1278112
[Epoch 18; Iter   311/ 1097] train: loss: 0.0306875
[Epoch 18; Iter   341/ 1097] train: loss: 0.0219198
[Epoch 18; Iter   371/ 1097] train: loss: 0.0254032
[Epoch 18; Iter   401/ 1097] train: loss: 0.1456588
[Epoch 18; Iter   431/ 1097] train: loss: 0.0362868
[Epoch 18; Iter   461/ 1097] train: loss: 0.1167555
[Epoch 18; Iter   491/ 1097] train: loss: 0.0213846
[Epoch 18; Iter   521/ 1097] train: loss: 0.2197783
[Epoch 18; Iter   551/ 1097] train: loss: 0.0587999
[Epoch 18; Iter   581/ 1097] train: loss: 0.0343603
[Epoch 18; Iter   611/ 1097] train: loss: 0.0239049
[Epoch 18; Iter   641/ 1097] train: loss: 0.2282618
[Epoch 18; Iter   671/ 1097] train: loss: 0.0482722
[Epoch 18; Iter   701/ 1097] train: loss: 0.0580511
[Epoch 18; Iter   731/ 1097] train: loss: 0.0307236
[Epoch 18; Iter   761/ 1097] train: loss: 0.0311434
[Epoch 18; Iter   791/ 1097] train: loss: 0.0249283
[Epoch 18; Iter   821/ 1097] train: loss: 0.0874888
[Epoch 18; Iter   851/ 1097] train: loss: 0.0494265
[Epoch 18; Iter   881/ 1097] train: loss: 0.1060682
[Epoch 18; Iter   911/ 1097] train: loss: 0.0243674
[Epoch 18; Iter   941/ 1097] train: loss: 0.1132298
[Epoch 18; Iter   971/ 1097] train: loss: 0.0301042
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1224406
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0905705
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0745644
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0167233
[Epoch 18] ogbg-molhiv: 0.816407 val loss: 0.077659
[Epoch 18] ogbg-molhiv: 0.733579 test loss: 0.121228
[Epoch 19; Iter    24/ 1097] train: loss: 0.0315885
[Epoch 19; Iter    54/ 1097] train: loss: 0.1969246
[Epoch 19; Iter    84/ 1097] train: loss: 0.0523789
[Epoch 19; Iter   114/ 1097] train: loss: 0.0206300
[Epoch 19; Iter   144/ 1097] train: loss: 0.0471384
[Epoch 19; Iter   174/ 1097] train: loss: 0.0213416
[Epoch 19; Iter   204/ 1097] train: loss: 0.0535168
[Epoch 19; Iter   234/ 1097] train: loss: 0.0693362
[Epoch 19; Iter   264/ 1097] train: loss: 0.0197062
[Epoch 19; Iter   294/ 1097] train: loss: 0.0229833
[Epoch 19; Iter   324/ 1097] train: loss: 0.0253535
[Epoch 19; Iter   354/ 1097] train: loss: 0.2058511
[Epoch 19; Iter   384/ 1097] train: loss: 0.0307533
[Epoch 19; Iter   414/ 1097] train: loss: 0.1549987
[Epoch 19; Iter   444/ 1097] train: loss: 0.0243153
[Epoch 19; Iter   474/ 1097] train: loss: 0.1776368
[Epoch 19; Iter   504/ 1097] train: loss: 0.0325893
[Epoch 19; Iter   534/ 1097] train: loss: 0.0233737
[Epoch 19; Iter   564/ 1097] train: loss: 0.1818689
[Epoch 19; Iter   594/ 1097] train: loss: 0.1342358
[Epoch 19; Iter   624/ 1097] train: loss: 0.0355897
[Epoch 19; Iter   654/ 1097] train: loss: 0.0217588
[Epoch 19; Iter   684/ 1097] train: loss: 0.4210793
[Epoch 19; Iter   714/ 1097] train: loss: 0.0311147
[Epoch 19; Iter   744/ 1097] train: loss: 0.0397803
[Epoch 19; Iter   774/ 1097] train: loss: 0.0279312
[Epoch 19; Iter   804/ 1097] train: loss: 0.0201282
[Epoch 19; Iter   834/ 1097] train: loss: 0.0233080
[Epoch 19; Iter   864/ 1097] train: loss: 0.0258171
[Epoch 19; Iter   894/ 1097] train: loss: 0.2893127
[Epoch 19; Iter   924/ 1097] train: loss: 0.0769709
[Epoch 19; Iter   954/ 1097] train: loss: 0.0192941
[Epoch 19; Iter   984/ 1097] train: loss: 0.1430388
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1077892
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0202052
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3409662
[Epoch 19] ogbg-molhiv: 0.806045 val loss: 0.073575
[Epoch 19] ogbg-molhiv: 0.736086 test loss: 0.118594
[Epoch 20; Iter     7/ 1097] train: loss: 0.0544365
[Epoch 20; Iter    37/ 1097] train: loss: 0.0534212
[Epoch 20; Iter    67/ 1097] train: loss: 0.0223417
[Epoch 20; Iter    97/ 1097] train: loss: 0.0290841
[Epoch 20; Iter   127/ 1097] train: loss: 0.0239945
[Epoch 20; Iter   157/ 1097] train: loss: 0.0177110
[Epoch 20; Iter   187/ 1097] train: loss: 0.0881034
[Epoch 20; Iter   217/ 1097] train: loss: 0.3449218
[Epoch 20; Iter   247/ 1097] train: loss: 0.0516882
[Epoch 16; Iter   195/ 1097] train: loss: 0.0364258
[Epoch 16; Iter   225/ 1097] train: loss: 0.0303799
[Epoch 16; Iter   255/ 1097] train: loss: 0.0337520
[Epoch 16; Iter   285/ 1097] train: loss: 0.1643044
[Epoch 16; Iter   315/ 1097] train: loss: 0.0804953
[Epoch 16; Iter   345/ 1097] train: loss: 0.0474280
[Epoch 16; Iter   375/ 1097] train: loss: 0.2130498
[Epoch 16; Iter   405/ 1097] train: loss: 0.1961392
[Epoch 16; Iter   435/ 1097] train: loss: 0.0943614
[Epoch 16; Iter   465/ 1097] train: loss: 0.1507691
[Epoch 16; Iter   495/ 1097] train: loss: 0.0757310
[Epoch 16; Iter   525/ 1097] train: loss: 0.1496340
[Epoch 16; Iter   555/ 1097] train: loss: 0.0296445
[Epoch 16; Iter   585/ 1097] train: loss: 0.1410613
[Epoch 16; Iter   615/ 1097] train: loss: 0.1029266
[Epoch 16; Iter   645/ 1097] train: loss: 0.0726746
[Epoch 16; Iter   675/ 1097] train: loss: 0.0998000
[Epoch 16; Iter   705/ 1097] train: loss: 0.1469236
[Epoch 16; Iter   735/ 1097] train: loss: 0.0718333
[Epoch 16; Iter   765/ 1097] train: loss: 0.0542794
[Epoch 16; Iter   795/ 1097] train: loss: 0.0903086
[Epoch 16; Iter   825/ 1097] train: loss: 0.0339225
[Epoch 16; Iter   855/ 1097] train: loss: 0.2104481
[Epoch 16; Iter   885/ 1097] train: loss: 0.2557469
[Epoch 16; Iter   915/ 1097] train: loss: 0.0264960
[Epoch 16; Iter   945/ 1097] train: loss: 0.0249523
[Epoch 16; Iter   975/ 1097] train: loss: 0.0224317
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0370136
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0281443
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1299400
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0903898
[Epoch 16] ogbg-molhiv: 0.783494 val loss: 0.083655
[Epoch 16] ogbg-molhiv: 0.787134 test loss: 0.112720
[Epoch 17; Iter    28/ 1097] train: loss: 0.0354759
[Epoch 17; Iter    58/ 1097] train: loss: 0.0307289
[Epoch 17; Iter    88/ 1097] train: loss: 0.0354249
[Epoch 17; Iter   118/ 1097] train: loss: 0.1665059
[Epoch 17; Iter   148/ 1097] train: loss: 0.2049010
[Epoch 17; Iter   178/ 1097] train: loss: 0.0349229
[Epoch 17; Iter   208/ 1097] train: loss: 0.0238054
[Epoch 17; Iter   238/ 1097] train: loss: 0.2150024
[Epoch 17; Iter   268/ 1097] train: loss: 0.0263471
[Epoch 17; Iter   298/ 1097] train: loss: 0.0271348
[Epoch 17; Iter   328/ 1097] train: loss: 0.0269831
[Epoch 17; Iter   358/ 1097] train: loss: 0.0268707
[Epoch 17; Iter   388/ 1097] train: loss: 0.0416499
[Epoch 17; Iter   418/ 1097] train: loss: 0.1562509
[Epoch 17; Iter   448/ 1097] train: loss: 0.0311755
[Epoch 17; Iter   478/ 1097] train: loss: 0.0644303
[Epoch 17; Iter   508/ 1097] train: loss: 0.0321894
[Epoch 17; Iter   538/ 1097] train: loss: 0.2476143
[Epoch 17; Iter   568/ 1097] train: loss: 0.1807446
[Epoch 17; Iter   598/ 1097] train: loss: 0.1439069
[Epoch 17; Iter   628/ 1097] train: loss: 0.0393997
[Epoch 17; Iter   658/ 1097] train: loss: 0.0267986
[Epoch 17; Iter   688/ 1097] train: loss: 0.2762033
[Epoch 17; Iter   718/ 1097] train: loss: 0.0292633
[Epoch 17; Iter   748/ 1097] train: loss: 0.1509347
[Epoch 17; Iter   778/ 1097] train: loss: 0.0600897
[Epoch 17; Iter   808/ 1097] train: loss: 0.0605020
[Epoch 17; Iter   838/ 1097] train: loss: 0.0254802
[Epoch 17; Iter   868/ 1097] train: loss: 0.0207888
[Epoch 17; Iter   898/ 1097] train: loss: 0.1216953
[Epoch 17; Iter   928/ 1097] train: loss: 0.2217854
[Epoch 17; Iter   958/ 1097] train: loss: 0.1458377
[Epoch 17; Iter   988/ 1097] train: loss: 0.0445417
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0282549
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0306945
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1966122
[Epoch 17] ogbg-molhiv: 0.789416 val loss: 0.074819
[Epoch 17] ogbg-molhiv: 0.776405 test loss: 0.115237
[Epoch 18; Iter    11/ 1097] train: loss: 0.1570874
[Epoch 18; Iter    41/ 1097] train: loss: 0.2590034
[Epoch 18; Iter    71/ 1097] train: loss: 0.1232970
[Epoch 18; Iter   101/ 1097] train: loss: 0.1254664
[Epoch 18; Iter   131/ 1097] train: loss: 0.1664504
[Epoch 18; Iter   161/ 1097] train: loss: 0.0541476
[Epoch 18; Iter   191/ 1097] train: loss: 0.1565625
[Epoch 18; Iter   221/ 1097] train: loss: 0.1661361
[Epoch 18; Iter   251/ 1097] train: loss: 0.1177194
[Epoch 18; Iter   281/ 1097] train: loss: 0.0185589
[Epoch 18; Iter   311/ 1097] train: loss: 0.1664604
[Epoch 18; Iter   341/ 1097] train: loss: 0.1051689
[Epoch 18; Iter   371/ 1097] train: loss: 0.0382390
[Epoch 18; Iter   401/ 1097] train: loss: 0.2044863
[Epoch 18; Iter   431/ 1097] train: loss: 0.0818905
[Epoch 18; Iter   461/ 1097] train: loss: 0.0370042
[Epoch 18; Iter   491/ 1097] train: loss: 0.2699587
[Epoch 18; Iter   521/ 1097] train: loss: 0.2336827
[Epoch 18; Iter   551/ 1097] train: loss: 0.0307899
[Epoch 18; Iter   581/ 1097] train: loss: 0.0403948
[Epoch 18; Iter   611/ 1097] train: loss: 0.0191498
[Epoch 18; Iter   641/ 1097] train: loss: 0.2434241
[Epoch 18; Iter   671/ 1097] train: loss: 0.0426952
[Epoch 18; Iter   701/ 1097] train: loss: 0.2795347
[Epoch 18; Iter   731/ 1097] train: loss: 0.1204787
[Epoch 18; Iter   761/ 1097] train: loss: 0.3184540
[Epoch 18; Iter   791/ 1097] train: loss: 0.0635455
[Epoch 18; Iter   821/ 1097] train: loss: 0.0728196
[Epoch 18; Iter   851/ 1097] train: loss: 0.1675167
[Epoch 18; Iter   881/ 1097] train: loss: 0.1629920
[Epoch 18; Iter   911/ 1097] train: loss: 0.2570983
[Epoch 18; Iter   941/ 1097] train: loss: 0.0264279
[Epoch 18; Iter   971/ 1097] train: loss: 0.1682097
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0433569
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0950754
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0442636
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1599591
[Epoch 18] ogbg-molhiv: 0.743962 val loss: 0.249764
[Epoch 18] ogbg-molhiv: 0.745229 test loss: 0.246771
[Epoch 19; Iter    24/ 1097] train: loss: 0.3488379
[Epoch 19; Iter    54/ 1097] train: loss: 0.1504543
[Epoch 19; Iter    84/ 1097] train: loss: 0.3183512
[Epoch 19; Iter   114/ 1097] train: loss: 0.0280795
[Epoch 19; Iter   144/ 1097] train: loss: 0.1162596
[Epoch 19; Iter   174/ 1097] train: loss: 0.0393229
[Epoch 19; Iter   204/ 1097] train: loss: 0.0265955
[Epoch 19; Iter   234/ 1097] train: loss: 0.0280992
[Epoch 19; Iter   264/ 1097] train: loss: 0.0945278
[Epoch 19; Iter   294/ 1097] train: loss: 0.1555322
[Epoch 19; Iter   324/ 1097] train: loss: 0.0466862
[Epoch 19; Iter   354/ 1097] train: loss: 0.2740051
[Epoch 19; Iter   384/ 1097] train: loss: 0.0285380
[Epoch 19; Iter   414/ 1097] train: loss: 0.0242175
[Epoch 19; Iter   444/ 1097] train: loss: 0.2263052
[Epoch 19; Iter   474/ 1097] train: loss: 0.1521443
[Epoch 19; Iter   504/ 1097] train: loss: 0.2169929
[Epoch 19; Iter   534/ 1097] train: loss: 0.1931779
[Epoch 19; Iter   564/ 1097] train: loss: 0.0196086
[Epoch 19; Iter   594/ 1097] train: loss: 0.0247291
[Epoch 19; Iter   624/ 1097] train: loss: 0.0559540
[Epoch 19; Iter   654/ 1097] train: loss: 0.0864515
[Epoch 19; Iter   684/ 1097] train: loss: 0.0273305
[Epoch 19; Iter   714/ 1097] train: loss: 0.1607516
[Epoch 19; Iter   744/ 1097] train: loss: 0.0267315
[Epoch 19; Iter   774/ 1097] train: loss: 0.2216731
[Epoch 19; Iter   804/ 1097] train: loss: 0.1351507
[Epoch 19; Iter   834/ 1097] train: loss: 0.1613371
[Epoch 19; Iter   864/ 1097] train: loss: 0.3475498
[Epoch 19; Iter   894/ 1097] train: loss: 0.2326654
[Epoch 19; Iter   924/ 1097] train: loss: 0.4393601
[Epoch 19; Iter   954/ 1097] train: loss: 0.1548948
[Epoch 19; Iter   984/ 1097] train: loss: 0.3935013
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1748861
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0220003
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0461937
[Epoch 19] ogbg-molhiv: 0.821876 val loss: 0.333735
[Epoch 19] ogbg-molhiv: 0.786566 test loss: 0.691022
[Epoch 20; Iter     7/ 1097] train: loss: 0.0669482
[Epoch 20; Iter    37/ 1097] train: loss: 0.2227908
[Epoch 20; Iter    67/ 1097] train: loss: 0.0486735
[Epoch 20; Iter    97/ 1097] train: loss: 0.0343954
[Epoch 20; Iter   127/ 1097] train: loss: 0.0590633
[Epoch 20; Iter   157/ 1097] train: loss: 0.0944111
[Epoch 20; Iter   187/ 1097] train: loss: 0.0155997
[Epoch 20; Iter   217/ 1097] train: loss: 0.0288901
[Epoch 20; Iter   247/ 1097] train: loss: 0.0280029
[Epoch 20; Iter   277/ 1097] train: loss: 0.1408841
[Epoch 20; Iter   307/ 1097] train: loss: 0.1768144
[Epoch 20; Iter   337/ 1097] train: loss: 0.1440904
[Epoch 20; Iter   367/ 1097] train: loss: 0.0397547
[Epoch 20; Iter   397/ 1097] train: loss: 0.0179827
[Epoch 20; Iter   427/ 1097] train: loss: 0.0168542
[Epoch 20; Iter   457/ 1097] train: loss: 0.0729075
[Epoch 20; Iter   487/ 1097] train: loss: 0.1261963
[Epoch 20; Iter   517/ 1097] train: loss: 0.0398484
[Epoch 20; Iter   547/ 1097] train: loss: 0.1425290
[Epoch 20; Iter   577/ 1097] train: loss: 0.0231292
[Epoch 20; Iter   607/ 1097] train: loss: 0.0260611
[Epoch 20; Iter   637/ 1097] train: loss: 0.0413688
[Epoch 20; Iter   667/ 1097] train: loss: 0.1697102
[Epoch 20; Iter   697/ 1097] train: loss: 0.1667882
[Epoch 20; Iter   727/ 1097] train: loss: 0.1216628
[Epoch 20; Iter   757/ 1097] train: loss: 0.0215375
[Epoch 20; Iter   787/ 1097] train: loss: 0.0243822
[Epoch 20; Iter   817/ 1097] train: loss: 0.0989955
[Epoch 20; Iter   847/ 1097] train: loss: 0.0404088
[Epoch 20; Iter   877/ 1097] train: loss: 0.1853520
[Epoch 20; Iter   907/ 1097] train: loss: 0.1816550
[Epoch 20; Iter   937/ 1097] train: loss: 0.0272434
[Epoch 20; Iter   967/ 1097] train: loss: 0.0939234
[Epoch 20; Iter   997/ 1097] train: loss: 0.0240946
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0320747
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1111360
[Epoch 20; Iter  1087/ 1097] train: loss: 0.1102455
[Epoch 20] ogbg-molhiv: 0.684698 val loss: 0.371754
[Epoch 20] ogbg-molhiv: 0.716426 test loss: 0.152987
[Epoch 21; Iter    20/ 1097] train: loss: 0.0564757
[Epoch 21; Iter    50/ 1097] train: loss: 0.1955733
[Epoch 21; Iter    80/ 1097] train: loss: 0.0279015
[Epoch 21; Iter   110/ 1097] train: loss: 0.0526909
[Epoch 21; Iter   140/ 1097] train: loss: 0.0704759
[Epoch 21; Iter   170/ 1097] train: loss: 0.0734129
[Epoch 21; Iter   200/ 1097] train: loss: 0.0640339
[Epoch 21; Iter   230/ 1097] train: loss: 0.2096892
[Epoch 21; Iter   260/ 1097] train: loss: 0.0776171
[Epoch 21; Iter   290/ 1097] train: loss: 0.2259144
[Epoch 21; Iter   320/ 1097] train: loss: 0.1906516
[Epoch 21; Iter   350/ 1097] train: loss: 0.0248902
[Epoch 21; Iter   380/ 1097] train: loss: 0.0493186
[Epoch 21; Iter   410/ 1097] train: loss: 0.0624106
[Epoch 21; Iter   440/ 1097] train: loss: 0.1901630
[Epoch 21; Iter   470/ 1097] train: loss: 0.1445931
[Epoch 21; Iter   500/ 1097] train: loss: 0.0277136
[Epoch 21; Iter   530/ 1097] train: loss: 0.0258197
[Epoch 21; Iter   560/ 1097] train: loss: 0.0643296
[Epoch 21; Iter   590/ 1097] train: loss: 0.0909757
[Epoch 21; Iter   620/ 1097] train: loss: 0.0870041
[Epoch 21; Iter   650/ 1097] train: loss: 0.2041037
[Epoch 21; Iter   680/ 1097] train: loss: 0.0803106
[Epoch 21; Iter   710/ 1097] train: loss: 0.0549814
[Epoch 21; Iter   740/ 1097] train: loss: 0.0437257
[Epoch 21; Iter   770/ 1097] train: loss: 0.0701193
[Epoch 21; Iter   800/ 1097] train: loss: 0.0763615
[Epoch 21; Iter   830/ 1097] train: loss: 0.2375615
[Epoch 21; Iter   860/ 1097] train: loss: 0.0599746
[Epoch 21; Iter   890/ 1097] train: loss: 0.0295222
[Epoch 21; Iter   920/ 1097] train: loss: 0.1306261
[Epoch 21; Iter   950/ 1097] train: loss: 0.0327791
[Epoch 21; Iter   980/ 1097] train: loss: 0.0161756
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0188886
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1615586
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0537981
[Epoch 21] ogbg-molhiv: 0.779808 val loss: 0.564057
[Epoch 21] ogbg-molhiv: 0.726096 test loss: 0.227051
[Epoch 22; Iter     3/ 1097] train: loss: 0.1628779
[Epoch 22; Iter    33/ 1097] train: loss: 0.0286718
[Epoch 22; Iter    63/ 1097] train: loss: 0.0360228
[Epoch 22; Iter    93/ 1097] train: loss: 0.0556144
[Epoch 22; Iter   123/ 1097] train: loss: 0.0247318
[Epoch 22; Iter   153/ 1097] train: loss: 0.0104590
[Epoch 22; Iter   183/ 1097] train: loss: 0.0504719
[Epoch 22; Iter   213/ 1097] train: loss: 0.1149054
[Epoch 22; Iter   243/ 1097] train: loss: 0.1066418
[Epoch 22; Iter   273/ 1097] train: loss: 0.1758207
[Epoch 22; Iter   303/ 1097] train: loss: 0.1996867
[Epoch 22; Iter   333/ 1097] train: loss: 0.1699677
[Epoch 22; Iter   363/ 1097] train: loss: 0.2386121
[Epoch 22; Iter   393/ 1097] train: loss: 0.0150550
[Epoch 22; Iter   423/ 1097] train: loss: 0.0252552
[Epoch 22; Iter   453/ 1097] train: loss: 0.0172097
[Epoch 22; Iter   483/ 1097] train: loss: 0.0522823
[Epoch 22; Iter   513/ 1097] train: loss: 0.2944980
[Epoch 22; Iter   543/ 1097] train: loss: 0.1945431
[Epoch 22; Iter   573/ 1097] train: loss: 0.0429112
[Epoch 22; Iter   603/ 1097] train: loss: 0.0164185
[Epoch 22; Iter   633/ 1097] train: loss: 0.0170362
[Epoch 22; Iter   663/ 1097] train: loss: 0.0403845
[Epoch 22; Iter   693/ 1097] train: loss: 0.2372960
[Epoch 22; Iter   723/ 1097] train: loss: 0.1500111
[Epoch 22; Iter   753/ 1097] train: loss: 0.2226918
[Epoch 22; Iter   783/ 1097] train: loss: 0.0537382
[Epoch 22; Iter   813/ 1097] train: loss: 0.1149597
[Epoch 22; Iter   843/ 1097] train: loss: 0.0370189
[Epoch 22; Iter   873/ 1097] train: loss: 0.0581885
[Epoch 22; Iter   903/ 1097] train: loss: 0.0708096
[Epoch 22; Iter   933/ 1097] train: loss: 0.0178654
[Epoch 22; Iter   963/ 1097] train: loss: 0.1737074
[Epoch 22; Iter   993/ 1097] train: loss: 0.0845912
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3879214
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0338340
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1587003
[Epoch 22] ogbg-molhiv: 0.711824 val loss: 0.610304
[Epoch 22] ogbg-molhiv: 0.753106 test loss: 0.207161
[Epoch 23; Iter    16/ 1097] train: loss: 0.0578152
[Epoch 23; Iter    46/ 1097] train: loss: 0.1597684
[Epoch 23; Iter    76/ 1097] train: loss: 0.1101090
[Epoch 23; Iter   106/ 1097] train: loss: 0.2327151
[Epoch 23; Iter   136/ 1097] train: loss: 0.0538526
[Epoch 23; Iter   166/ 1097] train: loss: 0.1673113
[Epoch 23; Iter   196/ 1097] train: loss: 0.0753744
[Epoch 23; Iter   226/ 1097] train: loss: 0.0596258
[Epoch 23; Iter   256/ 1097] train: loss: 0.0762093
[Epoch 23; Iter   286/ 1097] train: loss: 0.0334507
[Epoch 23; Iter   316/ 1097] train: loss: 0.0391852
[Epoch 23; Iter   346/ 1097] train: loss: 0.0382678
[Epoch 23; Iter   376/ 1097] train: loss: 0.0143036
[Epoch 23; Iter   406/ 1097] train: loss: 0.0650236
[Epoch 23; Iter   436/ 1097] train: loss: 0.1468540
[Epoch 23; Iter   466/ 1097] train: loss: 0.0413220
[Epoch 23; Iter   496/ 1097] train: loss: 0.1060203
[Epoch 23; Iter   526/ 1097] train: loss: 0.0464470
[Epoch 23; Iter   556/ 1097] train: loss: 0.1264543
[Epoch 23; Iter   586/ 1097] train: loss: 0.0875045
[Epoch 23; Iter   616/ 1097] train: loss: 0.1223684
[Epoch 23; Iter   646/ 1097] train: loss: 0.1536530
[Epoch 23; Iter   676/ 1097] train: loss: 0.0449234
[Epoch 23; Iter   706/ 1097] train: loss: 0.0311493
[Epoch 23; Iter   736/ 1097] train: loss: 0.1368511
[Epoch 23; Iter   766/ 1097] train: loss: 0.1176989
[Epoch 23; Iter   796/ 1097] train: loss: 0.0210634
[Epoch 23; Iter   826/ 1097] train: loss: 0.2595407
[Epoch 23; Iter   856/ 1097] train: loss: 0.1788985
[Epoch 23; Iter   886/ 1097] train: loss: 0.2012112
[Epoch 23; Iter   916/ 1097] train: loss: 0.3652563
[Epoch 23; Iter   946/ 1097] train: loss: 0.0249539
[Epoch 23; Iter   976/ 1097] train: loss: 0.1058011
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0428473
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0189558
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2123039
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1327568
[Epoch 23] ogbg-molhiv: 0.734228 val loss: 0.852820
[Epoch 23] ogbg-molhiv: 0.733444 test loss: 0.168167
[Epoch 24; Iter    29/ 1097] train: loss: 0.0494389
[Epoch 24; Iter    59/ 1097] train: loss: 0.2277327
[Epoch 24; Iter    89/ 1097] train: loss: 0.1523984
[Epoch 24; Iter   119/ 1097] train: loss: 0.0412336
[Epoch 24; Iter   149/ 1097] train: loss: 0.0719681
[Epoch 24; Iter   179/ 1097] train: loss: 0.0137257
[Epoch 24; Iter   209/ 1097] train: loss: 0.1812275
[Epoch 24; Iter   239/ 1097] train: loss: 0.0180739
[Epoch 24; Iter   269/ 1097] train: loss: 0.1514400
[Epoch 24; Iter   299/ 1097] train: loss: 0.0245216
[Epoch 24; Iter   329/ 1097] train: loss: 0.0314097
[Epoch 20; Iter   277/ 1097] train: loss: 0.2550956
[Epoch 20; Iter   307/ 1097] train: loss: 0.0263187
[Epoch 20; Iter   337/ 1097] train: loss: 0.0782234
[Epoch 20; Iter   367/ 1097] train: loss: 0.0848612
[Epoch 20; Iter   397/ 1097] train: loss: 0.0456056
[Epoch 20; Iter   427/ 1097] train: loss: 0.2859185
[Epoch 20; Iter   457/ 1097] train: loss: 0.0845098
[Epoch 20; Iter   487/ 1097] train: loss: 0.0483783
[Epoch 20; Iter   517/ 1097] train: loss: 0.0372957
[Epoch 20; Iter   547/ 1097] train: loss: 0.0386999
[Epoch 20; Iter   577/ 1097] train: loss: 0.0152857
[Epoch 20; Iter   607/ 1097] train: loss: 0.0321099
[Epoch 20; Iter   637/ 1097] train: loss: 0.2098096
[Epoch 20; Iter   667/ 1097] train: loss: 0.3377091
[Epoch 20; Iter   697/ 1097] train: loss: 0.0234734
[Epoch 20; Iter   727/ 1097] train: loss: 0.0384003
[Epoch 20; Iter   757/ 1097] train: loss: 0.3139077
[Epoch 20; Iter   787/ 1097] train: loss: 0.0209986
[Epoch 20; Iter   817/ 1097] train: loss: 0.0402980
[Epoch 20; Iter   847/ 1097] train: loss: 0.2009279
[Epoch 20; Iter   877/ 1097] train: loss: 0.2563362
[Epoch 20; Iter   907/ 1097] train: loss: 0.0457469
[Epoch 20; Iter   937/ 1097] train: loss: 0.0998931
[Epoch 20; Iter   967/ 1097] train: loss: 0.0814150
[Epoch 20; Iter   997/ 1097] train: loss: 0.0257808
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1051291
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1362033
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0697458
[Epoch 20] ogbg-molhiv: 0.757572 val loss: 0.282817
[Epoch 20] ogbg-molhiv: 0.753502 test loss: 0.258406
[Epoch 21; Iter    20/ 1097] train: loss: 0.0460902
[Epoch 21; Iter    50/ 1097] train: loss: 0.0174739
[Epoch 21; Iter    80/ 1097] train: loss: 0.0326826
[Epoch 21; Iter   110/ 1097] train: loss: 0.0218824
[Epoch 21; Iter   140/ 1097] train: loss: 0.2369105
[Epoch 21; Iter   170/ 1097] train: loss: 0.0893229
[Epoch 21; Iter   200/ 1097] train: loss: 0.0120692
[Epoch 21; Iter   230/ 1097] train: loss: 0.0217274
[Epoch 21; Iter   260/ 1097] train: loss: 0.0232931
[Epoch 21; Iter   290/ 1097] train: loss: 0.0414151
[Epoch 21; Iter   320/ 1097] train: loss: 0.1915417
[Epoch 21; Iter   350/ 1097] train: loss: 0.0962425
[Epoch 21; Iter   380/ 1097] train: loss: 0.0298422
[Epoch 21; Iter   410/ 1097] train: loss: 0.1763590
[Epoch 21; Iter   440/ 1097] train: loss: 0.1632528
[Epoch 21; Iter   470/ 1097] train: loss: 0.0685209
[Epoch 21; Iter   500/ 1097] train: loss: 0.1026117
[Epoch 21; Iter   530/ 1097] train: loss: 0.0524531
[Epoch 21; Iter   560/ 1097] train: loss: 0.1632183
[Epoch 21; Iter   590/ 1097] train: loss: 0.0644012
[Epoch 21; Iter   620/ 1097] train: loss: 0.3229806
[Epoch 21; Iter   650/ 1097] train: loss: 0.0266953
[Epoch 21; Iter   680/ 1097] train: loss: 0.0625179
[Epoch 21; Iter   710/ 1097] train: loss: 0.3352650
[Epoch 21; Iter   740/ 1097] train: loss: 0.1349743
[Epoch 21; Iter   770/ 1097] train: loss: 0.0255155
[Epoch 21; Iter   800/ 1097] train: loss: 0.1251183
[Epoch 21; Iter   830/ 1097] train: loss: 0.4629724
[Epoch 21; Iter   860/ 1097] train: loss: 0.0134656
[Epoch 21; Iter   890/ 1097] train: loss: 0.0390232
[Epoch 21; Iter   920/ 1097] train: loss: 0.1227202
[Epoch 21; Iter   950/ 1097] train: loss: 0.1205523
[Epoch 21; Iter   980/ 1097] train: loss: 0.1502386
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0234793
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1746692
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0200822
[Epoch 21] ogbg-molhiv: 0.749222 val loss: 0.225811
[Epoch 21] ogbg-molhiv: 0.749238 test loss: 0.337323
[Epoch 22; Iter     3/ 1097] train: loss: 0.0421029
[Epoch 22; Iter    33/ 1097] train: loss: 0.0474354
[Epoch 22; Iter    63/ 1097] train: loss: 0.1038414
[Epoch 22; Iter    93/ 1097] train: loss: 0.0237428
[Epoch 22; Iter   123/ 1097] train: loss: 0.0316837
[Epoch 22; Iter   153/ 1097] train: loss: 0.0198918
[Epoch 22; Iter   183/ 1097] train: loss: 0.0370929
[Epoch 22; Iter   213/ 1097] train: loss: 0.0123927
[Epoch 22; Iter   243/ 1097] train: loss: 0.0149073
[Epoch 22; Iter   273/ 1097] train: loss: 0.1706326
[Epoch 22; Iter   303/ 1097] train: loss: 0.0327298
[Epoch 22; Iter   333/ 1097] train: loss: 0.0252823
[Epoch 22; Iter   363/ 1097] train: loss: 0.0462705
[Epoch 22; Iter   393/ 1097] train: loss: 0.0120740
[Epoch 22; Iter   423/ 1097] train: loss: 0.0821116
[Epoch 22; Iter   453/ 1097] train: loss: 0.0410681
[Epoch 22; Iter   483/ 1097] train: loss: 0.0180788
[Epoch 22; Iter   513/ 1097] train: loss: 0.0131441
[Epoch 22; Iter   543/ 1097] train: loss: 0.1131793
[Epoch 22; Iter   573/ 1097] train: loss: 0.0474066
[Epoch 22; Iter   603/ 1097] train: loss: 0.0738391
[Epoch 22; Iter   633/ 1097] train: loss: 0.0150613
[Epoch 22; Iter   663/ 1097] train: loss: 0.0607996
[Epoch 22; Iter   693/ 1097] train: loss: 0.0160476
[Epoch 22; Iter   723/ 1097] train: loss: 0.0126198
[Epoch 22; Iter   753/ 1097] train: loss: 0.0119784
[Epoch 22; Iter   783/ 1097] train: loss: 0.2924518
[Epoch 22; Iter   813/ 1097] train: loss: 0.0665644
[Epoch 22; Iter   843/ 1097] train: loss: 0.1418877
[Epoch 22; Iter   873/ 1097] train: loss: 0.0258796
[Epoch 22; Iter   903/ 1097] train: loss: 0.0567339
[Epoch 22; Iter   933/ 1097] train: loss: 0.0154286
[Epoch 22; Iter   963/ 1097] train: loss: 0.1055948
[Epoch 22; Iter   993/ 1097] train: loss: 0.0354783
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0526099
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0163629
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0358742
[Epoch 22] ogbg-molhiv: 0.749997 val loss: 0.411714
[Epoch 22] ogbg-molhiv: 0.755443 test loss: 0.379305
[Epoch 23; Iter    16/ 1097] train: loss: 0.1263985
[Epoch 23; Iter    46/ 1097] train: loss: 0.0392978
[Epoch 23; Iter    76/ 1097] train: loss: 0.0707251
[Epoch 23; Iter   106/ 1097] train: loss: 0.0183236
[Epoch 23; Iter   136/ 1097] train: loss: 0.0721511
[Epoch 23; Iter   166/ 1097] train: loss: 0.2040803
[Epoch 23; Iter   196/ 1097] train: loss: 0.2031172
[Epoch 23; Iter   226/ 1097] train: loss: 0.0210164
[Epoch 23; Iter   256/ 1097] train: loss: 0.0357478
[Epoch 23; Iter   286/ 1097] train: loss: 0.0822755
[Epoch 23; Iter   316/ 1097] train: loss: 0.0193301
[Epoch 23; Iter   346/ 1097] train: loss: 0.1533315
[Epoch 23; Iter   376/ 1097] train: loss: 0.0391389
[Epoch 23; Iter   406/ 1097] train: loss: 0.0278971
[Epoch 23; Iter   436/ 1097] train: loss: 0.1856370
[Epoch 23; Iter   466/ 1097] train: loss: 0.0404549
[Epoch 23; Iter   496/ 1097] train: loss: 0.0667369
[Epoch 23; Iter   526/ 1097] train: loss: 0.0104964
[Epoch 23; Iter   556/ 1097] train: loss: 0.0636606
[Epoch 23; Iter   586/ 1097] train: loss: 0.0386752
[Epoch 23; Iter   616/ 1097] train: loss: 0.0181247
[Epoch 23; Iter   646/ 1097] train: loss: 0.0272362
[Epoch 23; Iter   676/ 1097] train: loss: 0.1656575
[Epoch 23; Iter   706/ 1097] train: loss: 0.0408970
[Epoch 23; Iter   736/ 1097] train: loss: 0.0454991
[Epoch 23; Iter   766/ 1097] train: loss: 0.0915963
[Epoch 23; Iter   796/ 1097] train: loss: 0.1078077
[Epoch 23; Iter   826/ 1097] train: loss: 0.0159830
[Epoch 23; Iter   856/ 1097] train: loss: 0.0183489
[Epoch 23; Iter   886/ 1097] train: loss: 0.0295088
[Epoch 23; Iter   916/ 1097] train: loss: 0.0176262
[Epoch 23; Iter   946/ 1097] train: loss: 0.0236787
[Epoch 23; Iter   976/ 1097] train: loss: 0.0523626
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1267548
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0428905
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0343596
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0182509
[Epoch 23] ogbg-molhiv: 0.772046 val loss: 0.124015
[Epoch 23] ogbg-molhiv: 0.749702 test loss: 0.204791
[Epoch 24; Iter    29/ 1097] train: loss: 0.0304692
[Epoch 24; Iter    59/ 1097] train: loss: 0.0410727
[Epoch 24; Iter    89/ 1097] train: loss: 0.3484718
[Epoch 24; Iter   119/ 1097] train: loss: 0.0299071
[Epoch 24; Iter   149/ 1097] train: loss: 0.0400012
[Epoch 24; Iter   179/ 1097] train: loss: 0.1027893
[Epoch 24; Iter   209/ 1097] train: loss: 0.0363994
[Epoch 24; Iter   239/ 1097] train: loss: 0.1725949
[Epoch 24; Iter   269/ 1097] train: loss: 0.1070790
[Epoch 24; Iter   299/ 1097] train: loss: 0.0224230
[Epoch 24; Iter   329/ 1097] train: loss: 0.1928872
[Epoch 20; Iter   277/ 1097] train: loss: 0.0292656
[Epoch 20; Iter   307/ 1097] train: loss: 0.1083706
[Epoch 20; Iter   337/ 1097] train: loss: 0.1442959
[Epoch 20; Iter   367/ 1097] train: loss: 0.3038476
[Epoch 20; Iter   397/ 1097] train: loss: 0.0698745
[Epoch 20; Iter   427/ 1097] train: loss: 0.0169929
[Epoch 20; Iter   457/ 1097] train: loss: 0.0321511
[Epoch 20; Iter   487/ 1097] train: loss: 0.1282112
[Epoch 20; Iter   517/ 1097] train: loss: 0.1667678
[Epoch 20; Iter   547/ 1097] train: loss: 0.0840419
[Epoch 20; Iter   577/ 1097] train: loss: 0.0345417
[Epoch 20; Iter   607/ 1097] train: loss: 0.2943380
[Epoch 20; Iter   637/ 1097] train: loss: 0.0751809
[Epoch 20; Iter   667/ 1097] train: loss: 0.1424103
[Epoch 20; Iter   697/ 1097] train: loss: 0.0186590
[Epoch 20; Iter   727/ 1097] train: loss: 0.0888590
[Epoch 20; Iter   757/ 1097] train: loss: 0.1367451
[Epoch 20; Iter   787/ 1097] train: loss: 0.0395691
[Epoch 20; Iter   817/ 1097] train: loss: 0.1075251
[Epoch 20; Iter   847/ 1097] train: loss: 0.0680766
[Epoch 20; Iter   877/ 1097] train: loss: 0.1414607
[Epoch 20; Iter   907/ 1097] train: loss: 0.0507341
[Epoch 20; Iter   937/ 1097] train: loss: 0.0347604
[Epoch 20; Iter   967/ 1097] train: loss: 0.1069776
[Epoch 20; Iter   997/ 1097] train: loss: 0.1517331
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0953091
[Epoch 20; Iter  1057/ 1097] train: loss: 0.2313278
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2271169
[Epoch 20] ogbg-molhiv: 0.719641 val loss: 0.090587
[Epoch 20] ogbg-molhiv: 0.741047 test loss: 0.216449
[Epoch 21; Iter    20/ 1097] train: loss: 0.0701009
[Epoch 21; Iter    50/ 1097] train: loss: 0.2087694
[Epoch 21; Iter    80/ 1097] train: loss: 0.0842966
[Epoch 21; Iter   110/ 1097] train: loss: 0.0542937
[Epoch 21; Iter   140/ 1097] train: loss: 0.1392779
[Epoch 21; Iter   170/ 1097] train: loss: 0.1256661
[Epoch 21; Iter   200/ 1097] train: loss: 0.0322502
[Epoch 21; Iter   230/ 1097] train: loss: 0.0856711
[Epoch 21; Iter   260/ 1097] train: loss: 0.1950986
[Epoch 21; Iter   290/ 1097] train: loss: 0.0316994
[Epoch 21; Iter   320/ 1097] train: loss: 0.0725810
[Epoch 21; Iter   350/ 1097] train: loss: 0.1405299
[Epoch 21; Iter   380/ 1097] train: loss: 0.0193077
[Epoch 21; Iter   410/ 1097] train: loss: 0.1048445
[Epoch 21; Iter   440/ 1097] train: loss: 0.0842594
[Epoch 21; Iter   470/ 1097] train: loss: 0.0439682
[Epoch 21; Iter   500/ 1097] train: loss: 0.0963380
[Epoch 21; Iter   530/ 1097] train: loss: 0.1507424
[Epoch 21; Iter   560/ 1097] train: loss: 0.0425021
[Epoch 21; Iter   590/ 1097] train: loss: 0.0254978
[Epoch 21; Iter   620/ 1097] train: loss: 0.1974659
[Epoch 21; Iter   650/ 1097] train: loss: 0.0369855
[Epoch 21; Iter   680/ 1097] train: loss: 0.0243010
[Epoch 21; Iter   710/ 1097] train: loss: 0.0148100
[Epoch 21; Iter   740/ 1097] train: loss: 0.0573382
[Epoch 21; Iter   770/ 1097] train: loss: 0.1149297
[Epoch 21; Iter   800/ 1097] train: loss: 0.0583829
[Epoch 21; Iter   830/ 1097] train: loss: 0.0597833
[Epoch 21; Iter   860/ 1097] train: loss: 0.0330025
[Epoch 21; Iter   890/ 1097] train: loss: 0.0435804
[Epoch 21; Iter   920/ 1097] train: loss: 0.0880505
[Epoch 21; Iter   950/ 1097] train: loss: 0.1363910
[Epoch 21; Iter   980/ 1097] train: loss: 0.1294454
[Epoch 21; Iter  1010/ 1097] train: loss: 0.2200389
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0246309
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0309124
[Epoch 21] ogbg-molhiv: 0.733123 val loss: 0.095925
[Epoch 21] ogbg-molhiv: 0.772632 test loss: 0.145145
[Epoch 22; Iter     3/ 1097] train: loss: 0.0780861
[Epoch 22; Iter    33/ 1097] train: loss: 0.2120728
[Epoch 22; Iter    63/ 1097] train: loss: 0.1782099
[Epoch 22; Iter    93/ 1097] train: loss: 0.0158152
[Epoch 22; Iter   123/ 1097] train: loss: 0.1448375
[Epoch 22; Iter   153/ 1097] train: loss: 0.1988998
[Epoch 22; Iter   183/ 1097] train: loss: 0.0930980
[Epoch 22; Iter   213/ 1097] train: loss: 0.0361415
[Epoch 22; Iter   243/ 1097] train: loss: 0.0255186
[Epoch 22; Iter   273/ 1097] train: loss: 0.0449988
[Epoch 22; Iter   303/ 1097] train: loss: 0.0567373
[Epoch 22; Iter   333/ 1097] train: loss: 0.1327587
[Epoch 22; Iter   363/ 1097] train: loss: 0.0497444
[Epoch 22; Iter   393/ 1097] train: loss: 0.1251709
[Epoch 22; Iter   423/ 1097] train: loss: 0.0253744
[Epoch 22; Iter   453/ 1097] train: loss: 0.0410696
[Epoch 22; Iter   483/ 1097] train: loss: 0.1793036
[Epoch 22; Iter   513/ 1097] train: loss: 0.0287466
[Epoch 22; Iter   543/ 1097] train: loss: 0.0301122
[Epoch 22; Iter   573/ 1097] train: loss: 0.0347919
[Epoch 22; Iter   603/ 1097] train: loss: 0.0191486
[Epoch 22; Iter   633/ 1097] train: loss: 0.0194027
[Epoch 22; Iter   663/ 1097] train: loss: 0.1071316
[Epoch 22; Iter   693/ 1097] train: loss: 0.0344667
[Epoch 22; Iter   723/ 1097] train: loss: 0.0542004
[Epoch 22; Iter   753/ 1097] train: loss: 0.2716366
[Epoch 22; Iter   783/ 1097] train: loss: 0.0620390
[Epoch 22; Iter   813/ 1097] train: loss: 0.0255675
[Epoch 22; Iter   843/ 1097] train: loss: 0.0188508
[Epoch 22; Iter   873/ 1097] train: loss: 0.0554895
[Epoch 22; Iter   903/ 1097] train: loss: 0.0422292
[Epoch 22; Iter   933/ 1097] train: loss: 0.0246408
[Epoch 22; Iter   963/ 1097] train: loss: 0.2370390
[Epoch 22; Iter   993/ 1097] train: loss: 0.0360852
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0228354
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1016095
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0194701
[Epoch 22] ogbg-molhiv: 0.735676 val loss: 0.097195
[Epoch 22] ogbg-molhiv: 0.739806 test loss: 0.536499
[Epoch 23; Iter    16/ 1097] train: loss: 0.0210665
[Epoch 23; Iter    46/ 1097] train: loss: 0.0471899
[Epoch 23; Iter    76/ 1097] train: loss: 0.0214328
[Epoch 23; Iter   106/ 1097] train: loss: 0.0235386
[Epoch 23; Iter   136/ 1097] train: loss: 0.0984119
[Epoch 23; Iter   166/ 1097] train: loss: 0.0597455
[Epoch 23; Iter   196/ 1097] train: loss: 0.2604162
[Epoch 23; Iter   226/ 1097] train: loss: 0.0317769
[Epoch 23; Iter   256/ 1097] train: loss: 0.0406760
[Epoch 23; Iter   286/ 1097] train: loss: 0.0416234
[Epoch 23; Iter   316/ 1097] train: loss: 0.2918631
[Epoch 23; Iter   346/ 1097] train: loss: 0.1411916
[Epoch 23; Iter   376/ 1097] train: loss: 0.1655682
[Epoch 23; Iter   406/ 1097] train: loss: 0.0231326
[Epoch 23; Iter   436/ 1097] train: loss: 0.1585054
[Epoch 23; Iter   466/ 1097] train: loss: 0.1304689
[Epoch 23; Iter   496/ 1097] train: loss: 0.0405331
[Epoch 23; Iter   526/ 1097] train: loss: 0.0128746
[Epoch 23; Iter   556/ 1097] train: loss: 0.0668598
[Epoch 23; Iter   586/ 1097] train: loss: 0.0335458
[Epoch 23; Iter   616/ 1097] train: loss: 0.0375247
[Epoch 23; Iter   646/ 1097] train: loss: 0.0284900
[Epoch 23; Iter   676/ 1097] train: loss: 0.0313433
[Epoch 23; Iter   706/ 1097] train: loss: 0.0154288
[Epoch 23; Iter   736/ 1097] train: loss: 0.0599958
[Epoch 23; Iter   766/ 1097] train: loss: 0.0250041
[Epoch 23; Iter   796/ 1097] train: loss: 0.2036930
[Epoch 23; Iter   826/ 1097] train: loss: 0.0895698
[Epoch 23; Iter   856/ 1097] train: loss: 0.1415398
[Epoch 23; Iter   886/ 1097] train: loss: 0.0690857
[Epoch 23; Iter   916/ 1097] train: loss: 0.0464798
[Epoch 23; Iter   946/ 1097] train: loss: 0.0593006
[Epoch 23; Iter   976/ 1097] train: loss: 0.0368701
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1737804
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0268827
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0597615
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1398310
[Epoch 23] ogbg-molhiv: 0.727394 val loss: 0.095446
[Epoch 23] ogbg-molhiv: 0.712497 test loss: 0.418304
[Epoch 24; Iter    29/ 1097] train: loss: 0.0183866
[Epoch 24; Iter    59/ 1097] train: loss: 0.0938226
[Epoch 24; Iter    89/ 1097] train: loss: 0.0643805
[Epoch 24; Iter   119/ 1097] train: loss: 0.0155396
[Epoch 24; Iter   149/ 1097] train: loss: 0.1031581
[Epoch 24; Iter   179/ 1097] train: loss: 0.0469138
[Epoch 24; Iter   209/ 1097] train: loss: 0.0151082
[Epoch 24; Iter   239/ 1097] train: loss: 0.0614211
[Epoch 24; Iter   269/ 1097] train: loss: 0.0560464
[Epoch 24; Iter   299/ 1097] train: loss: 0.0602068
[Epoch 24; Iter   329/ 1097] train: loss: 0.0375836
[Epoch 20; Iter   277/ 1097] train: loss: 0.0568073
[Epoch 20; Iter   307/ 1097] train: loss: 0.0620956
[Epoch 20; Iter   337/ 1097] train: loss: 0.0690023
[Epoch 20; Iter   367/ 1097] train: loss: 0.5654048
[Epoch 20; Iter   397/ 1097] train: loss: 0.0978571
[Epoch 20; Iter   427/ 1097] train: loss: 0.0572587
[Epoch 20; Iter   457/ 1097] train: loss: 0.0445536
[Epoch 20; Iter   487/ 1097] train: loss: 0.1238657
[Epoch 20; Iter   517/ 1097] train: loss: 0.0924366
[Epoch 20; Iter   547/ 1097] train: loss: 0.0694417
[Epoch 20; Iter   577/ 1097] train: loss: 0.0744695
[Epoch 20; Iter   607/ 1097] train: loss: 0.2454321
[Epoch 20; Iter   637/ 1097] train: loss: 0.0423235
[Epoch 20; Iter   667/ 1097] train: loss: 0.1021823
[Epoch 20; Iter   697/ 1097] train: loss: 0.0216877
[Epoch 20; Iter   727/ 1097] train: loss: 0.0780729
[Epoch 20; Iter   757/ 1097] train: loss: 0.1694149
[Epoch 20; Iter   787/ 1097] train: loss: 0.1089565
[Epoch 20; Iter   817/ 1097] train: loss: 0.1172631
[Epoch 20; Iter   847/ 1097] train: loss: 0.0384168
[Epoch 20; Iter   877/ 1097] train: loss: 0.1759598
[Epoch 20; Iter   907/ 1097] train: loss: 0.0544899
[Epoch 20; Iter   937/ 1097] train: loss: 0.0698901
[Epoch 20; Iter   967/ 1097] train: loss: 0.0557875
[Epoch 20; Iter   997/ 1097] train: loss: 0.1215267
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0749540
[Epoch 20; Iter  1057/ 1097] train: loss: 0.2980646
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2766839
[Epoch 20] ogbg-molhiv: 0.777839 val loss: 0.283926
[Epoch 20] ogbg-molhiv: 0.764204 test loss: 0.135630
[Epoch 21; Iter    20/ 1097] train: loss: 0.0168930
[Epoch 21; Iter    50/ 1097] train: loss: 0.0401247
[Epoch 21; Iter    80/ 1097] train: loss: 0.0221721
[Epoch 21; Iter   110/ 1097] train: loss: 0.0254179
[Epoch 21; Iter   140/ 1097] train: loss: 0.0423840
[Epoch 21; Iter   170/ 1097] train: loss: 0.0296367
[Epoch 21; Iter   200/ 1097] train: loss: 0.0205770
[Epoch 21; Iter   230/ 1097] train: loss: 0.0431138
[Epoch 21; Iter   260/ 1097] train: loss: 0.1009823
[Epoch 21; Iter   290/ 1097] train: loss: 0.0726093
[Epoch 21; Iter   320/ 1097] train: loss: 0.0177807
[Epoch 21; Iter   350/ 1097] train: loss: 0.0480367
[Epoch 21; Iter   380/ 1097] train: loss: 0.0278650
[Epoch 21; Iter   410/ 1097] train: loss: 0.0562356
[Epoch 21; Iter   440/ 1097] train: loss: 0.1607325
[Epoch 21; Iter   470/ 1097] train: loss: 0.1412001
[Epoch 21; Iter   500/ 1097] train: loss: 0.1771733
[Epoch 21; Iter   530/ 1097] train: loss: 0.0709068
[Epoch 21; Iter   560/ 1097] train: loss: 0.0429652
[Epoch 21; Iter   590/ 1097] train: loss: 0.0191554
[Epoch 21; Iter   620/ 1097] train: loss: 0.1501325
[Epoch 21; Iter   650/ 1097] train: loss: 0.0286539
[Epoch 21; Iter   680/ 1097] train: loss: 0.0355784
[Epoch 21; Iter   710/ 1097] train: loss: 0.0180233
[Epoch 21; Iter   740/ 1097] train: loss: 0.0503430
[Epoch 21; Iter   770/ 1097] train: loss: 0.1265464
[Epoch 21; Iter   800/ 1097] train: loss: 0.1613218
[Epoch 21; Iter   830/ 1097] train: loss: 0.0291664
[Epoch 21; Iter   860/ 1097] train: loss: 0.0174947
[Epoch 21; Iter   890/ 1097] train: loss: 0.0415668
[Epoch 21; Iter   920/ 1097] train: loss: 0.0987876
[Epoch 21; Iter   950/ 1097] train: loss: 0.0484319
[Epoch 21; Iter   980/ 1097] train: loss: 0.1894064
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1362807
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0194386
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0201506
[Epoch 21] ogbg-molhiv: 0.767082 val loss: 0.322684
[Epoch 21] ogbg-molhiv: 0.741324 test loss: 0.138491
[Epoch 22; Iter     3/ 1097] train: loss: 0.0493804
[Epoch 22; Iter    33/ 1097] train: loss: 0.2448286
[Epoch 22; Iter    63/ 1097] train: loss: 0.1478388
[Epoch 22; Iter    93/ 1097] train: loss: 0.0141249
[Epoch 22; Iter   123/ 1097] train: loss: 0.1166762
[Epoch 22; Iter   153/ 1097] train: loss: 0.1574388
[Epoch 22; Iter   183/ 1097] train: loss: 0.2205194
[Epoch 22; Iter   213/ 1097] train: loss: 0.0760568
[Epoch 22; Iter   243/ 1097] train: loss: 0.0227398
[Epoch 22; Iter   273/ 1097] train: loss: 0.0557286
[Epoch 22; Iter   303/ 1097] train: loss: 0.0587715
[Epoch 22; Iter   333/ 1097] train: loss: 0.0890928
[Epoch 22; Iter   363/ 1097] train: loss: 0.0242607
[Epoch 22; Iter   393/ 1097] train: loss: 0.0939834
[Epoch 22; Iter   423/ 1097] train: loss: 0.0394247
[Epoch 22; Iter   453/ 1097] train: loss: 0.0628230
[Epoch 22; Iter   483/ 1097] train: loss: 0.1466126
[Epoch 22; Iter   513/ 1097] train: loss: 0.1127284
[Epoch 22; Iter   543/ 1097] train: loss: 0.0384027
[Epoch 22; Iter   573/ 1097] train: loss: 0.1135085
[Epoch 22; Iter   603/ 1097] train: loss: 0.0225698
[Epoch 22; Iter   633/ 1097] train: loss: 0.0284680
[Epoch 22; Iter   663/ 1097] train: loss: 0.0380309
[Epoch 22; Iter   693/ 1097] train: loss: 0.0500627
[Epoch 22; Iter   723/ 1097] train: loss: 0.0205917
[Epoch 22; Iter   753/ 1097] train: loss: 0.1871587
[Epoch 22; Iter   783/ 1097] train: loss: 0.1810717
[Epoch 22; Iter   813/ 1097] train: loss: 0.0132631
[Epoch 22; Iter   843/ 1097] train: loss: 0.0543928
[Epoch 22; Iter   873/ 1097] train: loss: 0.1820252
[Epoch 22; Iter   903/ 1097] train: loss: 0.0193313
[Epoch 22; Iter   933/ 1097] train: loss: 0.0155814
[Epoch 22; Iter   963/ 1097] train: loss: 0.2866395
[Epoch 22; Iter   993/ 1097] train: loss: 0.0489939
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0532771
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1223229
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0318756
[Epoch 22] ogbg-molhiv: 0.738245 val loss: 0.107141
[Epoch 22] ogbg-molhiv: 0.746306 test loss: 0.130738
[Epoch 23; Iter    16/ 1097] train: loss: 0.0211196
[Epoch 23; Iter    46/ 1097] train: loss: 0.0526606
[Epoch 23; Iter    76/ 1097] train: loss: 0.0218613
[Epoch 23; Iter   106/ 1097] train: loss: 0.0298905
[Epoch 23; Iter   136/ 1097] train: loss: 0.1230804
[Epoch 23; Iter   166/ 1097] train: loss: 0.0779753
[Epoch 23; Iter   196/ 1097] train: loss: 0.2089798
[Epoch 23; Iter   226/ 1097] train: loss: 0.0636997
[Epoch 23; Iter   256/ 1097] train: loss: 0.0355088
[Epoch 23; Iter   286/ 1097] train: loss: 0.0332779
[Epoch 23; Iter   316/ 1097] train: loss: 0.2163807
[Epoch 23; Iter   346/ 1097] train: loss: 0.0818563
[Epoch 23; Iter   376/ 1097] train: loss: 0.1959589
[Epoch 23; Iter   406/ 1097] train: loss: 0.0135415
[Epoch 23; Iter   436/ 1097] train: loss: 0.1415697
[Epoch 23; Iter   466/ 1097] train: loss: 0.0324540
[Epoch 23; Iter   496/ 1097] train: loss: 0.0939121
[Epoch 23; Iter   526/ 1097] train: loss: 0.0383798
[Epoch 23; Iter   556/ 1097] train: loss: 0.1002924
[Epoch 23; Iter   586/ 1097] train: loss: 0.0130088
[Epoch 23; Iter   616/ 1097] train: loss: 0.0227667
[Epoch 23; Iter   646/ 1097] train: loss: 0.0266017
[Epoch 23; Iter   676/ 1097] train: loss: 0.0377365
[Epoch 23; Iter   706/ 1097] train: loss: 0.0281471
[Epoch 23; Iter   736/ 1097] train: loss: 0.0419491
[Epoch 23; Iter   766/ 1097] train: loss: 0.0208655
[Epoch 23; Iter   796/ 1097] train: loss: 0.1470569
[Epoch 23; Iter   826/ 1097] train: loss: 0.0327485
[Epoch 23; Iter   856/ 1097] train: loss: 0.1502692
[Epoch 23; Iter   886/ 1097] train: loss: 0.1664298
[Epoch 23; Iter   916/ 1097] train: loss: 0.0284268
[Epoch 23; Iter   946/ 1097] train: loss: 0.2453928
[Epoch 23; Iter   976/ 1097] train: loss: 0.0261496
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1655475
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0824327
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1188918
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0764241
[Epoch 23] ogbg-molhiv: 0.760117 val loss: 0.078671
[Epoch 23] ogbg-molhiv: 0.719323 test loss: 0.140827
[Epoch 24; Iter    29/ 1097] train: loss: 0.0115148
[Epoch 24; Iter    59/ 1097] train: loss: 0.0461818
[Epoch 24; Iter    89/ 1097] train: loss: 0.0143356
[Epoch 24; Iter   119/ 1097] train: loss: 0.1331584
[Epoch 24; Iter   149/ 1097] train: loss: 0.1654975
[Epoch 24; Iter   179/ 1097] train: loss: 0.0452759
[Epoch 24; Iter   209/ 1097] train: loss: 0.0156859
[Epoch 24; Iter   239/ 1097] train: loss: 0.0131226
[Epoch 24; Iter   269/ 1097] train: loss: 0.0510163
[Epoch 24; Iter   299/ 1097] train: loss: 0.1240128
[Epoch 24; Iter   329/ 1097] train: loss: 0.0253430
[Epoch 20; Iter   277/ 1097] train: loss: 0.1502385
[Epoch 20; Iter   307/ 1097] train: loss: 0.0414986
[Epoch 20; Iter   337/ 1097] train: loss: 0.1457340
[Epoch 20; Iter   367/ 1097] train: loss: 0.0292774
[Epoch 20; Iter   397/ 1097] train: loss: 0.0419858
[Epoch 20; Iter   427/ 1097] train: loss: 0.4469024
[Epoch 20; Iter   457/ 1097] train: loss: 0.1703072
[Epoch 20; Iter   487/ 1097] train: loss: 0.0839347
[Epoch 20; Iter   517/ 1097] train: loss: 0.0549996
[Epoch 20; Iter   547/ 1097] train: loss: 0.0297249
[Epoch 20; Iter   577/ 1097] train: loss: 0.0373982
[Epoch 20; Iter   607/ 1097] train: loss: 0.0160685
[Epoch 20; Iter   637/ 1097] train: loss: 0.0561044
[Epoch 20; Iter   667/ 1097] train: loss: 0.4872790
[Epoch 20; Iter   697/ 1097] train: loss: 0.0194541
[Epoch 20; Iter   727/ 1097] train: loss: 0.0254932
[Epoch 20; Iter   757/ 1097] train: loss: 0.1126333
[Epoch 20; Iter   787/ 1097] train: loss: 0.0191935
[Epoch 20; Iter   817/ 1097] train: loss: 0.0170650
[Epoch 20; Iter   847/ 1097] train: loss: 0.2430954
[Epoch 20; Iter   877/ 1097] train: loss: 0.1107830
[Epoch 20; Iter   907/ 1097] train: loss: 0.0451234
[Epoch 20; Iter   937/ 1097] train: loss: 0.0655144
[Epoch 20; Iter   967/ 1097] train: loss: 0.1092006
[Epoch 20; Iter   997/ 1097] train: loss: 0.0381430
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0689984
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0833044
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0218723
[Epoch 20] ogbg-molhiv: 0.757039 val loss: 0.244846
[Epoch 20] ogbg-molhiv: 0.724355 test loss: 0.133825
[Epoch 21; Iter    20/ 1097] train: loss: 0.0448402
[Epoch 21; Iter    50/ 1097] train: loss: 0.0640356
[Epoch 21; Iter    80/ 1097] train: loss: 0.0348035
[Epoch 21; Iter   110/ 1097] train: loss: 0.0440724
[Epoch 21; Iter   140/ 1097] train: loss: 0.2008573
[Epoch 21; Iter   170/ 1097] train: loss: 0.1950741
[Epoch 21; Iter   200/ 1097] train: loss: 0.0265536
[Epoch 21; Iter   230/ 1097] train: loss: 0.0316183
[Epoch 21; Iter   260/ 1097] train: loss: 0.0371894
[Epoch 21; Iter   290/ 1097] train: loss: 0.0580102
[Epoch 21; Iter   320/ 1097] train: loss: 0.0892413
[Epoch 21; Iter   350/ 1097] train: loss: 0.1549606
[Epoch 21; Iter   380/ 1097] train: loss: 0.0175645
[Epoch 21; Iter   410/ 1097] train: loss: 0.1971954
[Epoch 21; Iter   440/ 1097] train: loss: 0.1630361
[Epoch 21; Iter   470/ 1097] train: loss: 0.1198345
[Epoch 21; Iter   500/ 1097] train: loss: 0.1674777
[Epoch 21; Iter   530/ 1097] train: loss: 0.0361439
[Epoch 21; Iter   560/ 1097] train: loss: 0.1213239
[Epoch 21; Iter   590/ 1097] train: loss: 0.1510743
[Epoch 21; Iter   620/ 1097] train: loss: 0.2388806
[Epoch 21; Iter   650/ 1097] train: loss: 0.0256388
[Epoch 21; Iter   680/ 1097] train: loss: 0.0428579
[Epoch 21; Iter   710/ 1097] train: loss: 0.2169080
[Epoch 21; Iter   740/ 1097] train: loss: 0.1193348
[Epoch 21; Iter   770/ 1097] train: loss: 0.0222164
[Epoch 21; Iter   800/ 1097] train: loss: 0.2374048
[Epoch 21; Iter   830/ 1097] train: loss: 0.4329718
[Epoch 21; Iter   860/ 1097] train: loss: 0.0267134
[Epoch 21; Iter   890/ 1097] train: loss: 0.0361663
[Epoch 21; Iter   920/ 1097] train: loss: 0.1530530
[Epoch 21; Iter   950/ 1097] train: loss: 0.1569069
[Epoch 21; Iter   980/ 1097] train: loss: 0.1531695
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0395244
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2487326
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0197138
[Epoch 21] ogbg-molhiv: 0.740680 val loss: 0.609721
[Epoch 21] ogbg-molhiv: 0.688930 test loss: 0.379984
[Epoch 22; Iter     3/ 1097] train: loss: 0.0311604
[Epoch 22; Iter    33/ 1097] train: loss: 0.0513488
[Epoch 22; Iter    63/ 1097] train: loss: 0.1663100
[Epoch 22; Iter    93/ 1097] train: loss: 0.0404941
[Epoch 22; Iter   123/ 1097] train: loss: 0.0191024
[Epoch 22; Iter   153/ 1097] train: loss: 0.0262625
[Epoch 22; Iter   183/ 1097] train: loss: 0.0232996
[Epoch 22; Iter   213/ 1097] train: loss: 0.0319197
[Epoch 22; Iter   243/ 1097] train: loss: 0.0220403
[Epoch 22; Iter   273/ 1097] train: loss: 0.1187308
[Epoch 22; Iter   303/ 1097] train: loss: 0.0270480
[Epoch 22; Iter   333/ 1097] train: loss: 0.0142174
[Epoch 22; Iter   363/ 1097] train: loss: 0.0172460
[Epoch 22; Iter   393/ 1097] train: loss: 0.0139328
[Epoch 22; Iter   423/ 1097] train: loss: 0.0676421
[Epoch 22; Iter   453/ 1097] train: loss: 0.0656689
[Epoch 22; Iter   483/ 1097] train: loss: 0.0279581
[Epoch 22; Iter   513/ 1097] train: loss: 0.0240012
[Epoch 22; Iter   543/ 1097] train: loss: 0.1031926
[Epoch 22; Iter   573/ 1097] train: loss: 0.0559013
[Epoch 22; Iter   603/ 1097] train: loss: 0.0318933
[Epoch 22; Iter   633/ 1097] train: loss: 0.0192869
[Epoch 22; Iter   663/ 1097] train: loss: 0.0586556
[Epoch 22; Iter   693/ 1097] train: loss: 0.0224522
[Epoch 22; Iter   723/ 1097] train: loss: 0.0273201
[Epoch 22; Iter   753/ 1097] train: loss: 0.0409322
[Epoch 22; Iter   783/ 1097] train: loss: 0.2323243
[Epoch 22; Iter   813/ 1097] train: loss: 0.0425224
[Epoch 22; Iter   843/ 1097] train: loss: 0.1733339
[Epoch 22; Iter   873/ 1097] train: loss: 0.1080671
[Epoch 22; Iter   903/ 1097] train: loss: 0.0299065
[Epoch 22; Iter   933/ 1097] train: loss: 0.0356062
[Epoch 22; Iter   963/ 1097] train: loss: 0.1644973
[Epoch 22; Iter   993/ 1097] train: loss: 0.0319086
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0419140
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0469933
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0260802
[Epoch 22] ogbg-molhiv: 0.781556 val loss: 4.125459
[Epoch 22] ogbg-molhiv: 0.729199 test loss: 1.741302
[Epoch 23; Iter    16/ 1097] train: loss: 0.1194722
[Epoch 23; Iter    46/ 1097] train: loss: 0.0311664
[Epoch 23; Iter    76/ 1097] train: loss: 0.0424175
[Epoch 23; Iter   106/ 1097] train: loss: 0.0187071
[Epoch 23; Iter   136/ 1097] train: loss: 0.0611884
[Epoch 23; Iter   166/ 1097] train: loss: 0.1071512
[Epoch 23; Iter   196/ 1097] train: loss: 0.1989919
[Epoch 23; Iter   226/ 1097] train: loss: 0.1048322
[Epoch 23; Iter   256/ 1097] train: loss: 0.0246037
[Epoch 23; Iter   286/ 1097] train: loss: 0.0823926
[Epoch 23; Iter   316/ 1097] train: loss: 0.0131051
[Epoch 23; Iter   346/ 1097] train: loss: 0.1012639
[Epoch 23; Iter   376/ 1097] train: loss: 0.0383514
[Epoch 23; Iter   406/ 1097] train: loss: 0.0273793
[Epoch 23; Iter   436/ 1097] train: loss: 0.1072631
[Epoch 23; Iter   466/ 1097] train: loss: 0.0234344
[Epoch 23; Iter   496/ 1097] train: loss: 0.0554513
[Epoch 23; Iter   526/ 1097] train: loss: 0.0438377
[Epoch 23; Iter   556/ 1097] train: loss: 0.0519862
[Epoch 23; Iter   586/ 1097] train: loss: 0.0422824
[Epoch 23; Iter   616/ 1097] train: loss: 0.0171297
[Epoch 23; Iter   646/ 1097] train: loss: 0.0590974
[Epoch 23; Iter   676/ 1097] train: loss: 0.3209202
[Epoch 23; Iter   706/ 1097] train: loss: 0.0242250
[Epoch 23; Iter   736/ 1097] train: loss: 0.0244695
[Epoch 23; Iter   766/ 1097] train: loss: 0.3791932
[Epoch 23; Iter   796/ 1097] train: loss: 0.1076490
[Epoch 23; Iter   826/ 1097] train: loss: 0.0977680
[Epoch 23; Iter   856/ 1097] train: loss: 0.0184046
[Epoch 23; Iter   886/ 1097] train: loss: 0.0547003
[Epoch 23; Iter   916/ 1097] train: loss: 0.0182890
[Epoch 23; Iter   946/ 1097] train: loss: 0.0153075
[Epoch 23; Iter   976/ 1097] train: loss: 0.1161215
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1139025
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0523066
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0248052
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0338561
[Epoch 23] ogbg-molhiv: 0.730165 val loss: 2.691200
[Epoch 23] ogbg-molhiv: 0.659082 test loss: 1.264146
[Epoch 24; Iter    29/ 1097] train: loss: 0.0325420
[Epoch 24; Iter    59/ 1097] train: loss: 0.0507941
[Epoch 24; Iter    89/ 1097] train: loss: 0.1984781
[Epoch 24; Iter   119/ 1097] train: loss: 0.0715229
[Epoch 24; Iter   149/ 1097] train: loss: 0.1408789
[Epoch 24; Iter   179/ 1097] train: loss: 0.2190285
[Epoch 24; Iter   209/ 1097] train: loss: 0.0426343
[Epoch 24; Iter   239/ 1097] train: loss: 0.3862945
[Epoch 24; Iter   269/ 1097] train: loss: 0.1044946
[Epoch 24; Iter   299/ 1097] train: loss: 0.0516139
[Epoch 24; Iter   329/ 1097] train: loss: 0.4552439
[Epoch 20; Iter   277/ 1097] train: loss: 0.2217371
[Epoch 20; Iter   307/ 1097] train: loss: 0.2133238
[Epoch 20; Iter   337/ 1097] train: loss: 0.0596827
[Epoch 20; Iter   367/ 1097] train: loss: 0.0678229
[Epoch 20; Iter   397/ 1097] train: loss: 0.0159509
[Epoch 20; Iter   427/ 1097] train: loss: 0.0314694
[Epoch 20; Iter   457/ 1097] train: loss: 0.0920403
[Epoch 20; Iter   487/ 1097] train: loss: 0.2395090
[Epoch 20; Iter   517/ 1097] train: loss: 0.0321061
[Epoch 20; Iter   547/ 1097] train: loss: 0.1055596
[Epoch 20; Iter   577/ 1097] train: loss: 0.0221055
[Epoch 20; Iter   607/ 1097] train: loss: 0.0263647
[Epoch 20; Iter   637/ 1097] train: loss: 0.0594437
[Epoch 20; Iter   667/ 1097] train: loss: 0.2353546
[Epoch 20; Iter   697/ 1097] train: loss: 0.0993618
[Epoch 20; Iter   727/ 1097] train: loss: 0.1880350
[Epoch 20; Iter   757/ 1097] train: loss: 0.0205258
[Epoch 20; Iter   787/ 1097] train: loss: 0.0373965
[Epoch 20; Iter   817/ 1097] train: loss: 0.1051641
[Epoch 20; Iter   847/ 1097] train: loss: 0.0467851
[Epoch 20; Iter   877/ 1097] train: loss: 0.0756566
[Epoch 20; Iter   907/ 1097] train: loss: 0.2993332
[Epoch 20; Iter   937/ 1097] train: loss: 0.0230649
[Epoch 20; Iter   967/ 1097] train: loss: 0.1327469
[Epoch 20; Iter   997/ 1097] train: loss: 0.1698653
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0340660
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0978982
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0401356
[Epoch 20] ogbg-molhiv: 0.756932 val loss: 0.138731
[Epoch 20] ogbg-molhiv: 0.765262 test loss: 0.137700
[Epoch 21; Iter    20/ 1097] train: loss: 0.0233063
[Epoch 21; Iter    50/ 1097] train: loss: 0.1266693
[Epoch 21; Iter    80/ 1097] train: loss: 0.0149386
[Epoch 21; Iter   110/ 1097] train: loss: 0.0335725
[Epoch 21; Iter   140/ 1097] train: loss: 0.0829003
[Epoch 21; Iter   170/ 1097] train: loss: 0.1623863
[Epoch 21; Iter   200/ 1097] train: loss: 0.1569469
[Epoch 21; Iter   230/ 1097] train: loss: 0.1385216
[Epoch 21; Iter   260/ 1097] train: loss: 0.2188349
[Epoch 21; Iter   290/ 1097] train: loss: 0.1444303
[Epoch 21; Iter   320/ 1097] train: loss: 0.1598726
[Epoch 21; Iter   350/ 1097] train: loss: 0.0191966
[Epoch 21; Iter   380/ 1097] train: loss: 0.0394768
[Epoch 21; Iter   410/ 1097] train: loss: 0.0766227
[Epoch 21; Iter   440/ 1097] train: loss: 0.1632916
[Epoch 21; Iter   470/ 1097] train: loss: 0.1980266
[Epoch 21; Iter   500/ 1097] train: loss: 0.0187894
[Epoch 21; Iter   530/ 1097] train: loss: 0.0308592
[Epoch 21; Iter   560/ 1097] train: loss: 0.0378300
[Epoch 21; Iter   590/ 1097] train: loss: 0.0683515
[Epoch 21; Iter   620/ 1097] train: loss: 0.0311296
[Epoch 21; Iter   650/ 1097] train: loss: 0.2670120
[Epoch 21; Iter   680/ 1097] train: loss: 0.0883221
[Epoch 21; Iter   710/ 1097] train: loss: 0.0363957
[Epoch 21; Iter   740/ 1097] train: loss: 0.0332431
[Epoch 21; Iter   770/ 1097] train: loss: 0.0427863
[Epoch 21; Iter   800/ 1097] train: loss: 0.0754225
[Epoch 21; Iter   830/ 1097] train: loss: 0.1847115
[Epoch 21; Iter   860/ 1097] train: loss: 0.0639460
[Epoch 21; Iter   890/ 1097] train: loss: 0.0179442
[Epoch 21; Iter   920/ 1097] train: loss: 0.1609371
[Epoch 21; Iter   950/ 1097] train: loss: 0.0430584
[Epoch 21; Iter   980/ 1097] train: loss: 0.0141242
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0186662
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1036117
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0403403
[Epoch 21] ogbg-molhiv: 0.778914 val loss: 1.600790
[Epoch 21] ogbg-molhiv: 0.760822 test loss: 0.399154
[Epoch 22; Iter     3/ 1097] train: loss: 0.1284504
[Epoch 22; Iter    33/ 1097] train: loss: 0.0858532
[Epoch 22; Iter    63/ 1097] train: loss: 0.0259832
[Epoch 22; Iter    93/ 1097] train: loss: 0.0262229
[Epoch 22; Iter   123/ 1097] train: loss: 0.0318790
[Epoch 22; Iter   153/ 1097] train: loss: 0.0270279
[Epoch 22; Iter   183/ 1097] train: loss: 0.0346444
[Epoch 22; Iter   213/ 1097] train: loss: 0.1352854
[Epoch 22; Iter   243/ 1097] train: loss: 0.0844571
[Epoch 22; Iter   273/ 1097] train: loss: 0.0781094
[Epoch 22; Iter   303/ 1097] train: loss: 0.1420743
[Epoch 22; Iter   333/ 1097] train: loss: 0.0321312
[Epoch 22; Iter   363/ 1097] train: loss: 0.1740656
[Epoch 22; Iter   393/ 1097] train: loss: 0.0417486
[Epoch 22; Iter   423/ 1097] train: loss: 0.0196985
[Epoch 22; Iter   453/ 1097] train: loss: 0.0220022
[Epoch 22; Iter   483/ 1097] train: loss: 0.0269614
[Epoch 22; Iter   513/ 1097] train: loss: 0.2863157
[Epoch 22; Iter   543/ 1097] train: loss: 0.1553589
[Epoch 22; Iter   573/ 1097] train: loss: 0.0266829
[Epoch 22; Iter   603/ 1097] train: loss: 0.0257838
[Epoch 22; Iter   633/ 1097] train: loss: 0.0185397
[Epoch 22; Iter   663/ 1097] train: loss: 0.0447851
[Epoch 22; Iter   693/ 1097] train: loss: 0.1083919
[Epoch 22; Iter   723/ 1097] train: loss: 0.1605821
[Epoch 22; Iter   753/ 1097] train: loss: 0.2249666
[Epoch 22; Iter   783/ 1097] train: loss: 0.0662717
[Epoch 22; Iter   813/ 1097] train: loss: 0.1062753
[Epoch 22; Iter   843/ 1097] train: loss: 0.0302849
[Epoch 22; Iter   873/ 1097] train: loss: 0.0415674
[Epoch 22; Iter   903/ 1097] train: loss: 0.1798658
[Epoch 22; Iter   933/ 1097] train: loss: 0.0159062
[Epoch 22; Iter   963/ 1097] train: loss: 0.2049328
[Epoch 22; Iter   993/ 1097] train: loss: 0.1222063
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3614836
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0259480
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0397512
[Epoch 22] ogbg-molhiv: 0.758279 val loss: 0.825530
[Epoch 22] ogbg-molhiv: 0.779237 test loss: 0.248515
[Epoch 23; Iter    16/ 1097] train: loss: 0.0638192
[Epoch 23; Iter    46/ 1097] train: loss: 0.2488179
[Epoch 23; Iter    76/ 1097] train: loss: 0.0400739
[Epoch 23; Iter   106/ 1097] train: loss: 0.2496917
[Epoch 23; Iter   136/ 1097] train: loss: 0.0883149
[Epoch 23; Iter   166/ 1097] train: loss: 0.2317176
[Epoch 23; Iter   196/ 1097] train: loss: 0.0864385
[Epoch 23; Iter   226/ 1097] train: loss: 0.1426238
[Epoch 23; Iter   256/ 1097] train: loss: 0.1178508
[Epoch 23; Iter   286/ 1097] train: loss: 0.0156892
[Epoch 23; Iter   316/ 1097] train: loss: 0.0368269
[Epoch 23; Iter   346/ 1097] train: loss: 0.0189060
[Epoch 23; Iter   376/ 1097] train: loss: 0.0121678
[Epoch 23; Iter   406/ 1097] train: loss: 0.1050453
[Epoch 23; Iter   436/ 1097] train: loss: 0.0196035
[Epoch 23; Iter   466/ 1097] train: loss: 0.0111011
[Epoch 23; Iter   496/ 1097] train: loss: 0.2032459
[Epoch 23; Iter   526/ 1097] train: loss: 0.0747772
[Epoch 23; Iter   556/ 1097] train: loss: 0.0342200
[Epoch 23; Iter   586/ 1097] train: loss: 0.1368970
[Epoch 23; Iter   616/ 1097] train: loss: 0.1634481
[Epoch 23; Iter   646/ 1097] train: loss: 0.0769612
[Epoch 23; Iter   676/ 1097] train: loss: 0.0795588
[Epoch 23; Iter   706/ 1097] train: loss: 0.0918083
[Epoch 23; Iter   736/ 1097] train: loss: 0.2231343
[Epoch 23; Iter   766/ 1097] train: loss: 0.0470625
[Epoch 23; Iter   796/ 1097] train: loss: 0.0284996
[Epoch 23; Iter   826/ 1097] train: loss: 0.1531985
[Epoch 23; Iter   856/ 1097] train: loss: 0.2911718
[Epoch 23; Iter   886/ 1097] train: loss: 0.1102963
[Epoch 23; Iter   916/ 1097] train: loss: 0.2965092
[Epoch 23; Iter   946/ 1097] train: loss: 0.0250020
[Epoch 23; Iter   976/ 1097] train: loss: 0.1036026
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0198073
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0479543
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2299375
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0716661
[Epoch 23] ogbg-molhiv: 0.793856 val loss: 0.575073
[Epoch 23] ogbg-molhiv: 0.773340 test loss: 0.138396
[Epoch 24; Iter    29/ 1097] train: loss: 0.0149142
[Epoch 24; Iter    59/ 1097] train: loss: 0.2504549
[Epoch 24; Iter    89/ 1097] train: loss: 0.1891051
[Epoch 24; Iter   119/ 1097] train: loss: 0.0435158
[Epoch 24; Iter   149/ 1097] train: loss: 0.0236331
[Epoch 24; Iter   179/ 1097] train: loss: 0.0248955
[Epoch 24; Iter   209/ 1097] train: loss: 0.1243211
[Epoch 24; Iter   239/ 1097] train: loss: 0.0110666
[Epoch 24; Iter   269/ 1097] train: loss: 0.3882425
[Epoch 24; Iter   299/ 1097] train: loss: 0.0791158
[Epoch 24; Iter   329/ 1097] train: loss: 0.0811777
[Epoch 20; Iter   277/ 1097] train: loss: 0.0264568
[Epoch 20; Iter   307/ 1097] train: loss: 0.0696380
[Epoch 20; Iter   337/ 1097] train: loss: 0.1458367
[Epoch 20; Iter   367/ 1097] train: loss: 0.4540789
[Epoch 20; Iter   397/ 1097] train: loss: 0.0349635
[Epoch 20; Iter   427/ 1097] train: loss: 0.0329969
[Epoch 20; Iter   457/ 1097] train: loss: 0.0176794
[Epoch 20; Iter   487/ 1097] train: loss: 0.0489942
[Epoch 20; Iter   517/ 1097] train: loss: 0.0769508
[Epoch 20; Iter   547/ 1097] train: loss: 0.2338576
[Epoch 20; Iter   577/ 1097] train: loss: 0.0542347
[Epoch 20; Iter   607/ 1097] train: loss: 0.1818687
[Epoch 20; Iter   637/ 1097] train: loss: 0.0308100
[Epoch 20; Iter   667/ 1097] train: loss: 0.0631629
[Epoch 20; Iter   697/ 1097] train: loss: 0.0559135
[Epoch 20; Iter   727/ 1097] train: loss: 0.1874465
[Epoch 20; Iter   757/ 1097] train: loss: 0.0845180
[Epoch 20; Iter   787/ 1097] train: loss: 0.0306548
[Epoch 20; Iter   817/ 1097] train: loss: 0.1199493
[Epoch 20; Iter   847/ 1097] train: loss: 0.0678575
[Epoch 20; Iter   877/ 1097] train: loss: 0.1391121
[Epoch 20; Iter   907/ 1097] train: loss: 0.0574039
[Epoch 20; Iter   937/ 1097] train: loss: 0.0194902
[Epoch 20; Iter   967/ 1097] train: loss: 0.0541943
[Epoch 20; Iter   997/ 1097] train: loss: 0.0657265
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1453868
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4061785
[Epoch 20; Iter  1087/ 1097] train: loss: 0.1947447
[Epoch 20] ogbg-molhiv: 0.728524 val loss: 0.099443
[Epoch 20] ogbg-molhiv: 0.656330 test loss: 0.226370
[Epoch 21; Iter    20/ 1097] train: loss: 0.0272778
[Epoch 21; Iter    50/ 1097] train: loss: 0.1594812
[Epoch 21; Iter    80/ 1097] train: loss: 0.0666983
[Epoch 21; Iter   110/ 1097] train: loss: 0.0309788
[Epoch 21; Iter   140/ 1097] train: loss: 0.2285981
[Epoch 21; Iter   170/ 1097] train: loss: 0.1488567
[Epoch 21; Iter   200/ 1097] train: loss: 0.0180616
[Epoch 21; Iter   230/ 1097] train: loss: 0.0251273
[Epoch 21; Iter   260/ 1097] train: loss: 0.0236098
[Epoch 21; Iter   290/ 1097] train: loss: 0.0645590
[Epoch 21; Iter   320/ 1097] train: loss: 0.0382145
[Epoch 21; Iter   350/ 1097] train: loss: 0.1194856
[Epoch 21; Iter   380/ 1097] train: loss: 0.0114620
[Epoch 21; Iter   410/ 1097] train: loss: 0.0146432
[Epoch 21; Iter   440/ 1097] train: loss: 0.2115265
[Epoch 21; Iter   470/ 1097] train: loss: 0.0546942
[Epoch 21; Iter   500/ 1097] train: loss: 0.0718560
[Epoch 21; Iter   530/ 1097] train: loss: 0.0436965
[Epoch 21; Iter   560/ 1097] train: loss: 0.0704430
[Epoch 21; Iter   590/ 1097] train: loss: 0.0495190
[Epoch 21; Iter   620/ 1097] train: loss: 0.0210188
[Epoch 21; Iter   650/ 1097] train: loss: 0.0207126
[Epoch 21; Iter   680/ 1097] train: loss: 0.0163626
[Epoch 21; Iter   710/ 1097] train: loss: 0.0141430
[Epoch 21; Iter   740/ 1097] train: loss: 0.0125110
[Epoch 21; Iter   770/ 1097] train: loss: 0.2338663
[Epoch 21; Iter   800/ 1097] train: loss: 0.0470682
[Epoch 21; Iter   830/ 1097] train: loss: 0.0431122
[Epoch 21; Iter   860/ 1097] train: loss: 0.0569228
[Epoch 21; Iter   890/ 1097] train: loss: 0.0222839
[Epoch 21; Iter   920/ 1097] train: loss: 0.0882427
[Epoch 21; Iter   950/ 1097] train: loss: 0.0870628
[Epoch 21; Iter   980/ 1097] train: loss: 0.1602816
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0656367
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0235961
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0164347
[Epoch 21] ogbg-molhiv: 0.716662 val loss: 0.126762
[Epoch 21] ogbg-molhiv: 0.641602 test loss: 0.183459
[Epoch 22; Iter     3/ 1097] train: loss: 0.0292490
[Epoch 22; Iter    33/ 1097] train: loss: 0.1978212
[Epoch 22; Iter    63/ 1097] train: loss: 0.0430851
[Epoch 22; Iter    93/ 1097] train: loss: 0.0175116
[Epoch 22; Iter   123/ 1097] train: loss: 0.1220015
[Epoch 22; Iter   153/ 1097] train: loss: 0.1938410
[Epoch 22; Iter   183/ 1097] train: loss: 0.1046777
[Epoch 22; Iter   213/ 1097] train: loss: 0.0455277
[Epoch 22; Iter   243/ 1097] train: loss: 0.0147550
[Epoch 22; Iter   273/ 1097] train: loss: 0.0171017
[Epoch 22; Iter   303/ 1097] train: loss: 0.0223610
[Epoch 22; Iter   333/ 1097] train: loss: 0.0546131
[Epoch 22; Iter   363/ 1097] train: loss: 0.0575059
[Epoch 22; Iter   393/ 1097] train: loss: 0.0805441
[Epoch 22; Iter   423/ 1097] train: loss: 0.0248776
[Epoch 22; Iter   453/ 1097] train: loss: 0.0603332
[Epoch 22; Iter   483/ 1097] train: loss: 0.1384565
[Epoch 22; Iter   513/ 1097] train: loss: 0.1304336
[Epoch 22; Iter   543/ 1097] train: loss: 0.0112969
[Epoch 22; Iter   573/ 1097] train: loss: 0.0937764
[Epoch 22; Iter   603/ 1097] train: loss: 0.0235879
[Epoch 22; Iter   633/ 1097] train: loss: 0.0073704
[Epoch 22; Iter   663/ 1097] train: loss: 0.0390178
[Epoch 22; Iter   693/ 1097] train: loss: 0.0399940
[Epoch 22; Iter   723/ 1097] train: loss: 0.0193812
[Epoch 22; Iter   753/ 1097] train: loss: 0.1774309
[Epoch 22; Iter   783/ 1097] train: loss: 0.1216261
[Epoch 22; Iter   813/ 1097] train: loss: 0.0171869
[Epoch 22; Iter   843/ 1097] train: loss: 0.0412849
[Epoch 22; Iter   873/ 1097] train: loss: 0.0654884
[Epoch 22; Iter   903/ 1097] train: loss: 0.0127461
[Epoch 22; Iter   933/ 1097] train: loss: 0.0101072
[Epoch 22; Iter   963/ 1097] train: loss: 0.2014922
[Epoch 22; Iter   993/ 1097] train: loss: 0.0395826
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0406864
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0766498
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0509216
[Epoch 22] ogbg-molhiv: 0.743469 val loss: 0.172252
[Epoch 22] ogbg-molhiv: 0.630557 test loss: 0.265427
[Epoch 23; Iter    16/ 1097] train: loss: 0.0512612
[Epoch 23; Iter    46/ 1097] train: loss: 0.0641289
[Epoch 23; Iter    76/ 1097] train: loss: 0.0398829
[Epoch 23; Iter   106/ 1097] train: loss: 0.0455964
[Epoch 23; Iter   136/ 1097] train: loss: 0.0253748
[Epoch 23; Iter   166/ 1097] train: loss: 0.0178242
[Epoch 23; Iter   196/ 1097] train: loss: 0.1448601
[Epoch 23; Iter   226/ 1097] train: loss: 0.1423903
[Epoch 23; Iter   256/ 1097] train: loss: 0.0195048
[Epoch 23; Iter   286/ 1097] train: loss: 0.0397130
[Epoch 23; Iter   316/ 1097] train: loss: 0.2386991
[Epoch 23; Iter   346/ 1097] train: loss: 0.2749755
[Epoch 23; Iter   376/ 1097] train: loss: 0.2357326
[Epoch 23; Iter   406/ 1097] train: loss: 0.0158178
[Epoch 23; Iter   436/ 1097] train: loss: 0.0586844
[Epoch 23; Iter   466/ 1097] train: loss: 0.0274468
[Epoch 23; Iter   496/ 1097] train: loss: 0.0727741
[Epoch 23; Iter   526/ 1097] train: loss: 0.0181227
[Epoch 23; Iter   556/ 1097] train: loss: 0.0297455
[Epoch 23; Iter   586/ 1097] train: loss: 0.0111127
[Epoch 23; Iter   616/ 1097] train: loss: 0.0717649
[Epoch 23; Iter   646/ 1097] train: loss: 0.0086555
[Epoch 23; Iter   676/ 1097] train: loss: 0.0680773
[Epoch 23; Iter   706/ 1097] train: loss: 0.0155487
[Epoch 23; Iter   736/ 1097] train: loss: 0.1138539
[Epoch 23; Iter   766/ 1097] train: loss: 0.0254562
[Epoch 23; Iter   796/ 1097] train: loss: 0.2632290
[Epoch 23; Iter   826/ 1097] train: loss: 0.0047041
[Epoch 23; Iter   856/ 1097] train: loss: 0.1280195
[Epoch 23; Iter   886/ 1097] train: loss: 0.1661230
[Epoch 23; Iter   916/ 1097] train: loss: 0.0101461
[Epoch 23; Iter   946/ 1097] train: loss: 0.2010223
[Epoch 23; Iter   976/ 1097] train: loss: 0.0739655
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1478900
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0128645
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0591484
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0575729
[Epoch 23] ogbg-molhiv: 0.735532 val loss: 0.134498
[Epoch 23] ogbg-molhiv: 0.563717 test loss: 0.270622
[Epoch 24; Iter    29/ 1097] train: loss: 0.0099387
[Epoch 24; Iter    59/ 1097] train: loss: 0.0427756
[Epoch 24; Iter    89/ 1097] train: loss: 0.0100141
[Epoch 24; Iter   119/ 1097] train: loss: 0.0242324
[Epoch 24; Iter   149/ 1097] train: loss: 0.1288509
[Epoch 24; Iter   179/ 1097] train: loss: 0.0155081
[Epoch 24; Iter   209/ 1097] train: loss: 0.0053430
[Epoch 24; Iter   239/ 1097] train: loss: 0.0947423
[Epoch 24; Iter   269/ 1097] train: loss: 0.0131516
[Epoch 24; Iter   299/ 1097] train: loss: 0.0145609
[Epoch 24; Iter   329/ 1097] train: loss: 0.0135019
[Epoch 20; Iter   277/ 1097] train: loss: 0.1355837
[Epoch 20; Iter   307/ 1097] train: loss: 0.1024445
[Epoch 20; Iter   337/ 1097] train: loss: 0.0975761
[Epoch 20; Iter   367/ 1097] train: loss: 0.0264230
[Epoch 20; Iter   397/ 1097] train: loss: 0.0189444
[Epoch 20; Iter   427/ 1097] train: loss: 0.0522508
[Epoch 20; Iter   457/ 1097] train: loss: 0.1149921
[Epoch 20; Iter   487/ 1097] train: loss: 0.0111577
[Epoch 20; Iter   517/ 1097] train: loss: 0.0234177
[Epoch 20; Iter   547/ 1097] train: loss: 0.0821161
[Epoch 20; Iter   577/ 1097] train: loss: 0.0282123
[Epoch 20; Iter   607/ 1097] train: loss: 0.0188738
[Epoch 20; Iter   637/ 1097] train: loss: 0.0457742
[Epoch 20; Iter   667/ 1097] train: loss: 0.0756338
[Epoch 20; Iter   697/ 1097] train: loss: 0.1178069
[Epoch 20; Iter   727/ 1097] train: loss: 0.1066959
[Epoch 20; Iter   757/ 1097] train: loss: 0.0236061
[Epoch 20; Iter   787/ 1097] train: loss: 0.0247743
[Epoch 20; Iter   817/ 1097] train: loss: 0.0750248
[Epoch 20; Iter   847/ 1097] train: loss: 0.0300350
[Epoch 20; Iter   877/ 1097] train: loss: 0.0968189
[Epoch 20; Iter   907/ 1097] train: loss: 0.0525473
[Epoch 20; Iter   937/ 1097] train: loss: 0.0063138
[Epoch 20; Iter   967/ 1097] train: loss: 0.1443260
[Epoch 20; Iter   997/ 1097] train: loss: 0.0805706
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0473069
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1557018
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0327231
[Epoch 20] ogbg-molhiv: 0.800880 val loss: 0.104227
[Epoch 20] ogbg-molhiv: 0.686682 test loss: 0.161611
[Epoch 21; Iter    20/ 1097] train: loss: 0.0223908
[Epoch 21; Iter    50/ 1097] train: loss: 0.1111283
[Epoch 21; Iter    80/ 1097] train: loss: 0.0378137
[Epoch 21; Iter   110/ 1097] train: loss: 0.0255041
[Epoch 21; Iter   140/ 1097] train: loss: 0.0378605
[Epoch 21; Iter   170/ 1097] train: loss: 0.0150453
[Epoch 21; Iter   200/ 1097] train: loss: 0.0821196
[Epoch 21; Iter   230/ 1097] train: loss: 0.0192169
[Epoch 21; Iter   260/ 1097] train: loss: 0.1142802
[Epoch 21; Iter   290/ 1097] train: loss: 0.0269445
[Epoch 21; Iter   320/ 1097] train: loss: 0.3145255
[Epoch 21; Iter   350/ 1097] train: loss: 0.0184465
[Epoch 21; Iter   380/ 1097] train: loss: 0.0518333
[Epoch 21; Iter   410/ 1097] train: loss: 0.1758887
[Epoch 21; Iter   440/ 1097] train: loss: 0.0862161
[Epoch 21; Iter   470/ 1097] train: loss: 0.1013448
[Epoch 21; Iter   500/ 1097] train: loss: 0.0927372
[Epoch 21; Iter   530/ 1097] train: loss: 0.0394412
[Epoch 21; Iter   560/ 1097] train: loss: 0.0283616
[Epoch 21; Iter   590/ 1097] train: loss: 0.0350250
[Epoch 21; Iter   620/ 1097] train: loss: 0.0379643
[Epoch 21; Iter   650/ 1097] train: loss: 0.3328674
[Epoch 21; Iter   680/ 1097] train: loss: 0.0243784
[Epoch 21; Iter   710/ 1097] train: loss: 0.0414879
[Epoch 21; Iter   740/ 1097] train: loss: 0.0139186
[Epoch 21; Iter   770/ 1097] train: loss: 0.0530241
[Epoch 21; Iter   800/ 1097] train: loss: 0.1555367
[Epoch 21; Iter   830/ 1097] train: loss: 0.1086636
[Epoch 21; Iter   860/ 1097] train: loss: 0.0197821
[Epoch 21; Iter   890/ 1097] train: loss: 0.0963662
[Epoch 21; Iter   920/ 1097] train: loss: 0.0575186
[Epoch 21; Iter   950/ 1097] train: loss: 0.0451546
[Epoch 21; Iter   980/ 1097] train: loss: 0.0109956
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0606891
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1439164
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0269803
[Epoch 21] ogbg-molhiv: 0.790763 val loss: 0.095473
[Epoch 21] ogbg-molhiv: 0.694295 test loss: 0.156736
[Epoch 22; Iter     3/ 1097] train: loss: 0.0397847
[Epoch 22; Iter    33/ 1097] train: loss: 0.0451733
[Epoch 22; Iter    63/ 1097] train: loss: 0.0878061
[Epoch 22; Iter    93/ 1097] train: loss: 0.0153193
[Epoch 22; Iter   123/ 1097] train: loss: 0.0722886
[Epoch 22; Iter   153/ 1097] train: loss: 0.0119045
[Epoch 22; Iter   183/ 1097] train: loss: 0.0653943
[Epoch 22; Iter   213/ 1097] train: loss: 0.1654505
[Epoch 22; Iter   243/ 1097] train: loss: 0.0131862
[Epoch 22; Iter   273/ 1097] train: loss: 0.0836221
[Epoch 22; Iter   303/ 1097] train: loss: 0.1978957
[Epoch 22; Iter   333/ 1097] train: loss: 0.0601898
[Epoch 22; Iter   363/ 1097] train: loss: 0.0914544
[Epoch 22; Iter   393/ 1097] train: loss: 0.1206740
[Epoch 22; Iter   423/ 1097] train: loss: 0.0297593
[Epoch 22; Iter   453/ 1097] train: loss: 0.0178394
[Epoch 22; Iter   483/ 1097] train: loss: 0.0240558
[Epoch 22; Iter   513/ 1097] train: loss: 0.3564205
[Epoch 22; Iter   543/ 1097] train: loss: 0.0615223
[Epoch 22; Iter   573/ 1097] train: loss: 0.0325328
[Epoch 22; Iter   603/ 1097] train: loss: 0.0112498
[Epoch 22; Iter   633/ 1097] train: loss: 0.0204131
[Epoch 22; Iter   663/ 1097] train: loss: 0.0372083
[Epoch 22; Iter   693/ 1097] train: loss: 0.0770367
[Epoch 22; Iter   723/ 1097] train: loss: 0.0670147
[Epoch 22; Iter   753/ 1097] train: loss: 0.1404346
[Epoch 22; Iter   783/ 1097] train: loss: 0.0337454
[Epoch 22; Iter   813/ 1097] train: loss: 0.1676208
[Epoch 22; Iter   843/ 1097] train: loss: 0.0401492
[Epoch 22; Iter   873/ 1097] train: loss: 0.0395130
[Epoch 22; Iter   903/ 1097] train: loss: 0.0494911
[Epoch 22; Iter   933/ 1097] train: loss: 0.0136527
[Epoch 22; Iter   963/ 1097] train: loss: 0.0864293
[Epoch 22; Iter   993/ 1097] train: loss: 0.1826411
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3169468
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0204964
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1662636
[Epoch 22] ogbg-molhiv: 0.781976 val loss: 0.242250
[Epoch 22] ogbg-molhiv: 0.673057 test loss: 0.242002
[Epoch 23; Iter    16/ 1097] train: loss: 0.0223611
[Epoch 23; Iter    46/ 1097] train: loss: 0.1801204
[Epoch 23; Iter    76/ 1097] train: loss: 0.0456208
[Epoch 23; Iter   106/ 1097] train: loss: 0.1889987
[Epoch 23; Iter   136/ 1097] train: loss: 0.0117656
[Epoch 23; Iter   166/ 1097] train: loss: 0.1465664
[Epoch 23; Iter   196/ 1097] train: loss: 0.0064668
[Epoch 23; Iter   226/ 1097] train: loss: 0.0916529
[Epoch 23; Iter   256/ 1097] train: loss: 0.0593583
[Epoch 23; Iter   286/ 1097] train: loss: 0.0302616
[Epoch 23; Iter   316/ 1097] train: loss: 0.0333411
[Epoch 23; Iter   346/ 1097] train: loss: 0.0163687
[Epoch 23; Iter   376/ 1097] train: loss: 0.0204412
[Epoch 23; Iter   406/ 1097] train: loss: 0.1493322
[Epoch 23; Iter   436/ 1097] train: loss: 0.0926611
[Epoch 23; Iter   466/ 1097] train: loss: 0.0233777
[Epoch 23; Iter   496/ 1097] train: loss: 0.0317177
[Epoch 23; Iter   526/ 1097] train: loss: 0.0165821
[Epoch 23; Iter   556/ 1097] train: loss: 0.0113469
[Epoch 23; Iter   586/ 1097] train: loss: 0.1828986
[Epoch 23; Iter   616/ 1097] train: loss: 0.1584041
[Epoch 23; Iter   646/ 1097] train: loss: 0.1415801
[Epoch 23; Iter   676/ 1097] train: loss: 0.0910776
[Epoch 23; Iter   706/ 1097] train: loss: 0.0405104
[Epoch 23; Iter   736/ 1097] train: loss: 0.0707856
[Epoch 23; Iter   766/ 1097] train: loss: 0.1301155
[Epoch 23; Iter   796/ 1097] train: loss: 0.0207015
[Epoch 23; Iter   826/ 1097] train: loss: 0.1753543
[Epoch 23; Iter   856/ 1097] train: loss: 0.1093791
[Epoch 23; Iter   886/ 1097] train: loss: 0.1309586
[Epoch 23; Iter   916/ 1097] train: loss: 0.1383613
[Epoch 23; Iter   946/ 1097] train: loss: 0.0230417
[Epoch 23; Iter   976/ 1097] train: loss: 0.1700253
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0233565
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0447581
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2118851
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0562963
[Epoch 23] ogbg-molhiv: 0.751170 val loss: 0.619261
[Epoch 23] ogbg-molhiv: 0.691668 test loss: 0.346829
[Epoch 24; Iter    29/ 1097] train: loss: 0.0502114
[Epoch 24; Iter    59/ 1097] train: loss: 0.0675555
[Epoch 24; Iter    89/ 1097] train: loss: 0.2143469
[Epoch 24; Iter   119/ 1097] train: loss: 0.0238869
[Epoch 24; Iter   149/ 1097] train: loss: 0.0184331
[Epoch 24; Iter   179/ 1097] train: loss: 0.0095750
[Epoch 24; Iter   209/ 1097] train: loss: 0.0128791
[Epoch 24; Iter   239/ 1097] train: loss: 0.0175369
[Epoch 24; Iter   269/ 1097] train: loss: 0.3368852
[Epoch 24; Iter   299/ 1097] train: loss: 0.0278389
[Epoch 24; Iter   329/ 1097] train: loss: 0.0249676
[Epoch 20; Iter   277/ 1097] train: loss: 0.0881419
[Epoch 20; Iter   307/ 1097] train: loss: 0.0779290
[Epoch 20; Iter   337/ 1097] train: loss: 0.1063061
[Epoch 20; Iter   367/ 1097] train: loss: 0.0352607
[Epoch 20; Iter   397/ 1097] train: loss: 0.0828618
[Epoch 20; Iter   427/ 1097] train: loss: 0.2718450
[Epoch 20; Iter   457/ 1097] train: loss: 0.0690224
[Epoch 20; Iter   487/ 1097] train: loss: 0.0435237
[Epoch 20; Iter   517/ 1097] train: loss: 0.0378006
[Epoch 20; Iter   547/ 1097] train: loss: 0.0174565
[Epoch 20; Iter   577/ 1097] train: loss: 0.0226927
[Epoch 20; Iter   607/ 1097] train: loss: 0.0320962
[Epoch 20; Iter   637/ 1097] train: loss: 0.1236692
[Epoch 20; Iter   667/ 1097] train: loss: 0.2861371
[Epoch 20; Iter   697/ 1097] train: loss: 0.0187229
[Epoch 20; Iter   727/ 1097] train: loss: 0.0255745
[Epoch 20; Iter   757/ 1097] train: loss: 0.2243106
[Epoch 20; Iter   787/ 1097] train: loss: 0.0326187
[Epoch 20; Iter   817/ 1097] train: loss: 0.0371674
[Epoch 20; Iter   847/ 1097] train: loss: 0.0548816
[Epoch 20; Iter   877/ 1097] train: loss: 0.1602537
[Epoch 20; Iter   907/ 1097] train: loss: 0.0178594
[Epoch 20; Iter   937/ 1097] train: loss: 0.0214634
[Epoch 20; Iter   967/ 1097] train: loss: 0.0381759
[Epoch 20; Iter   997/ 1097] train: loss: 0.0255478
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0732469
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1937088
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0258270
[Epoch 20] ogbg-molhiv: 0.755680 val loss: 0.107285
[Epoch 20] ogbg-molhiv: 0.699739 test loss: 0.152633
[Epoch 21; Iter    20/ 1097] train: loss: 0.0168722
[Epoch 21; Iter    50/ 1097] train: loss: 0.0149332
[Epoch 21; Iter    80/ 1097] train: loss: 0.0153736
[Epoch 21; Iter   110/ 1097] train: loss: 0.0140825
[Epoch 21; Iter   140/ 1097] train: loss: 0.1845566
[Epoch 21; Iter   170/ 1097] train: loss: 0.0887104
[Epoch 21; Iter   200/ 1097] train: loss: 0.0150850
[Epoch 21; Iter   230/ 1097] train: loss: 0.0818169
[Epoch 21; Iter   260/ 1097] train: loss: 0.0229180
[Epoch 21; Iter   290/ 1097] train: loss: 0.1213184
[Epoch 21; Iter   320/ 1097] train: loss: 0.0238484
[Epoch 21; Iter   350/ 1097] train: loss: 0.2135967
[Epoch 21; Iter   380/ 1097] train: loss: 0.0139479
[Epoch 21; Iter   410/ 1097] train: loss: 0.0956802
[Epoch 21; Iter   440/ 1097] train: loss: 0.3484883
[Epoch 21; Iter   470/ 1097] train: loss: 0.1319335
[Epoch 21; Iter   500/ 1097] train: loss: 0.1346695
[Epoch 21; Iter   530/ 1097] train: loss: 0.0415285
[Epoch 21; Iter   560/ 1097] train: loss: 0.0520419
[Epoch 21; Iter   590/ 1097] train: loss: 0.0220315
[Epoch 21; Iter   620/ 1097] train: loss: 0.2459299
[Epoch 21; Iter   650/ 1097] train: loss: 0.0204912
[Epoch 21; Iter   680/ 1097] train: loss: 0.0393995
[Epoch 21; Iter   710/ 1097] train: loss: 0.2493300
[Epoch 21; Iter   740/ 1097] train: loss: 0.1110644
[Epoch 21; Iter   770/ 1097] train: loss: 0.0725671
[Epoch 21; Iter   800/ 1097] train: loss: 0.0844376
[Epoch 21; Iter   830/ 1097] train: loss: 0.3861121
[Epoch 21; Iter   860/ 1097] train: loss: 0.0160671
[Epoch 21; Iter   890/ 1097] train: loss: 0.0158822
[Epoch 21; Iter   920/ 1097] train: loss: 0.0606035
[Epoch 21; Iter   950/ 1097] train: loss: 0.1452672
[Epoch 21; Iter   980/ 1097] train: loss: 0.1979902
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0180425
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1759675
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0318038
[Epoch 21] ogbg-molhiv: 0.701380 val loss: 0.195299
[Epoch 21] ogbg-molhiv: 0.621943 test loss: 0.223163
[Epoch 22; Iter     3/ 1097] train: loss: 0.0241639
[Epoch 22; Iter    33/ 1097] train: loss: 0.0204042
[Epoch 22; Iter    63/ 1097] train: loss: 0.0127526
[Epoch 22; Iter    93/ 1097] train: loss: 0.0233955
[Epoch 22; Iter   123/ 1097] train: loss: 0.0131847
[Epoch 22; Iter   153/ 1097] train: loss: 0.0833095
[Epoch 22; Iter   183/ 1097] train: loss: 0.0132215
[Epoch 22; Iter   213/ 1097] train: loss: 0.0282473
[Epoch 22; Iter   243/ 1097] train: loss: 0.0280870
[Epoch 22; Iter   273/ 1097] train: loss: 0.1345009
[Epoch 22; Iter   303/ 1097] train: loss: 0.0636498
[Epoch 22; Iter   333/ 1097] train: loss: 0.0206740
[Epoch 22; Iter   363/ 1097] train: loss: 0.0593888
[Epoch 22; Iter   393/ 1097] train: loss: 0.0890515
[Epoch 22; Iter   423/ 1097] train: loss: 0.1383137
[Epoch 22; Iter   453/ 1097] train: loss: 0.0667085
[Epoch 22; Iter   483/ 1097] train: loss: 0.0323486
[Epoch 22; Iter   513/ 1097] train: loss: 0.0120085
[Epoch 22; Iter   543/ 1097] train: loss: 0.0220564
[Epoch 22; Iter   573/ 1097] train: loss: 0.0306426
[Epoch 22; Iter   603/ 1097] train: loss: 0.0362671
[Epoch 22; Iter   633/ 1097] train: loss: 0.0372118
[Epoch 22; Iter   663/ 1097] train: loss: 0.0189094
[Epoch 22; Iter   693/ 1097] train: loss: 0.0549700
[Epoch 22; Iter   723/ 1097] train: loss: 0.0226689
[Epoch 22; Iter   753/ 1097] train: loss: 0.0231242
[Epoch 22; Iter   783/ 1097] train: loss: 0.4865224
[Epoch 22; Iter   813/ 1097] train: loss: 0.0332321
[Epoch 22; Iter   843/ 1097] train: loss: 0.0518559
[Epoch 22; Iter   873/ 1097] train: loss: 0.0691572
[Epoch 22; Iter   903/ 1097] train: loss: 0.0239098
[Epoch 22; Iter   933/ 1097] train: loss: 0.0099641
[Epoch 22; Iter   963/ 1097] train: loss: 0.1806673
[Epoch 22; Iter   993/ 1097] train: loss: 0.0133775
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0615467
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0229832
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0134457
[Epoch 22] ogbg-molhiv: 0.714987 val loss: 0.247761
[Epoch 22] ogbg-molhiv: 0.644216 test loss: 0.176852
[Epoch 23; Iter    16/ 1097] train: loss: 0.1085739
[Epoch 23; Iter    46/ 1097] train: loss: 0.0104616
[Epoch 23; Iter    76/ 1097] train: loss: 0.0189132
[Epoch 23; Iter   106/ 1097] train: loss: 0.0295766
[Epoch 23; Iter   136/ 1097] train: loss: 0.0360319
[Epoch 23; Iter   166/ 1097] train: loss: 0.1535684
[Epoch 23; Iter   196/ 1097] train: loss: 0.1138147
[Epoch 23; Iter   226/ 1097] train: loss: 0.0158973
[Epoch 23; Iter   256/ 1097] train: loss: 0.0151004
[Epoch 23; Iter   286/ 1097] train: loss: 0.0142846
[Epoch 23; Iter   316/ 1097] train: loss: 0.0387102
[Epoch 23; Iter   346/ 1097] train: loss: 0.0484565
[Epoch 23; Iter   376/ 1097] train: loss: 0.0945508
[Epoch 23; Iter   406/ 1097] train: loss: 0.0162556
[Epoch 23; Iter   436/ 1097] train: loss: 0.2505248
[Epoch 23; Iter   466/ 1097] train: loss: 0.0391906
[Epoch 23; Iter   496/ 1097] train: loss: 0.0231173
[Epoch 23; Iter   526/ 1097] train: loss: 0.0115877
[Epoch 23; Iter   556/ 1097] train: loss: 0.0165753
[Epoch 23; Iter   586/ 1097] train: loss: 0.0221521
[Epoch 23; Iter   616/ 1097] train: loss: 0.0047423
[Epoch 23; Iter   646/ 1097] train: loss: 0.0363071
[Epoch 23; Iter   676/ 1097] train: loss: 0.1218354
[Epoch 23; Iter   706/ 1097] train: loss: 0.0359697
[Epoch 23; Iter   736/ 1097] train: loss: 0.0339883
[Epoch 23; Iter   766/ 1097] train: loss: 0.2071893
[Epoch 23; Iter   796/ 1097] train: loss: 0.0199910
[Epoch 23; Iter   826/ 1097] train: loss: 0.0755865
[Epoch 23; Iter   856/ 1097] train: loss: 0.0272862
[Epoch 23; Iter   886/ 1097] train: loss: 0.0207500
[Epoch 23; Iter   916/ 1097] train: loss: 0.0395134
[Epoch 23; Iter   946/ 1097] train: loss: 0.0439736
[Epoch 23; Iter   976/ 1097] train: loss: 0.0409965
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1342861
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1752602
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0495640
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0441563
[Epoch 23] ogbg-molhiv: 0.719194 val loss: 0.239521
[Epoch 23] ogbg-molhiv: 0.659657 test loss: 0.190359
[Epoch 24; Iter    29/ 1097] train: loss: 0.0269505
[Epoch 24; Iter    59/ 1097] train: loss: 0.0214269
[Epoch 24; Iter    89/ 1097] train: loss: 0.0239761
[Epoch 24; Iter   119/ 1097] train: loss: 0.0084036
[Epoch 24; Iter   149/ 1097] train: loss: 0.0520664
[Epoch 24; Iter   179/ 1097] train: loss: 0.1561023
[Epoch 24; Iter   209/ 1097] train: loss: 0.0412104
[Epoch 24; Iter   239/ 1097] train: loss: 0.0808094
[Epoch 24; Iter   269/ 1097] train: loss: 0.0134112
[Epoch 24; Iter   299/ 1097] train: loss: 0.1145874
[Epoch 24; Iter   329/ 1097] train: loss: 0.3412136
[Epoch 20; Iter   277/ 1097] train: loss: 0.1450890
[Epoch 20; Iter   307/ 1097] train: loss: 0.0633647
[Epoch 20; Iter   337/ 1097] train: loss: 0.0788980
[Epoch 20; Iter   367/ 1097] train: loss: 0.0656214
[Epoch 20; Iter   397/ 1097] train: loss: 0.0244540
[Epoch 20; Iter   427/ 1097] train: loss: 0.2982799
[Epoch 20; Iter   457/ 1097] train: loss: 0.1071005
[Epoch 20; Iter   487/ 1097] train: loss: 0.1091111
[Epoch 20; Iter   517/ 1097] train: loss: 0.0416246
[Epoch 20; Iter   547/ 1097] train: loss: 0.0384842
[Epoch 20; Iter   577/ 1097] train: loss: 0.0134671
[Epoch 20; Iter   607/ 1097] train: loss: 0.0327916
[Epoch 20; Iter   637/ 1097] train: loss: 0.2813907
[Epoch 20; Iter   667/ 1097] train: loss: 0.3867219
[Epoch 20; Iter   697/ 1097] train: loss: 0.0167912
[Epoch 20; Iter   727/ 1097] train: loss: 0.0226761
[Epoch 20; Iter   757/ 1097] train: loss: 0.2467027
[Epoch 20; Iter   787/ 1097] train: loss: 0.0490492
[Epoch 20; Iter   817/ 1097] train: loss: 0.0214089
[Epoch 20; Iter   847/ 1097] train: loss: 0.2054797
[Epoch 20; Iter   877/ 1097] train: loss: 0.2547610
[Epoch 20; Iter   907/ 1097] train: loss: 0.0311822
[Epoch 20; Iter   937/ 1097] train: loss: 0.1156891
[Epoch 20; Iter   967/ 1097] train: loss: 0.0387360
[Epoch 20; Iter   997/ 1097] train: loss: 0.0302716
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0420920
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1524985
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0503527
[Epoch 20] ogbg-molhiv: 0.804658 val loss: 0.125157
[Epoch 20] ogbg-molhiv: 0.764963 test loss: 0.114669
[Epoch 21; Iter    20/ 1097] train: loss: 0.0517966
[Epoch 21; Iter    50/ 1097] train: loss: 0.0230750
[Epoch 21; Iter    80/ 1097] train: loss: 0.0232741
[Epoch 21; Iter   110/ 1097] train: loss: 0.0253212
[Epoch 21; Iter   140/ 1097] train: loss: 0.1346229
[Epoch 21; Iter   170/ 1097] train: loss: 0.0873067
[Epoch 21; Iter   200/ 1097] train: loss: 0.0177653
[Epoch 21; Iter   230/ 1097] train: loss: 0.0446761
[Epoch 21; Iter   260/ 1097] train: loss: 0.0231988
[Epoch 21; Iter   290/ 1097] train: loss: 0.0534650
[Epoch 21; Iter   320/ 1097] train: loss: 0.0857529
[Epoch 21; Iter   350/ 1097] train: loss: 0.1160672
[Epoch 21; Iter   380/ 1097] train: loss: 0.0221242
[Epoch 21; Iter   410/ 1097] train: loss: 0.1940247
[Epoch 21; Iter   440/ 1097] train: loss: 0.3328891
[Epoch 21; Iter   470/ 1097] train: loss: 0.1511303
[Epoch 21; Iter   500/ 1097] train: loss: 0.1696942
[Epoch 21; Iter   530/ 1097] train: loss: 0.0576445
[Epoch 21; Iter   560/ 1097] train: loss: 0.1172257
[Epoch 21; Iter   590/ 1097] train: loss: 0.1454029
[Epoch 21; Iter   620/ 1097] train: loss: 0.1632990
[Epoch 21; Iter   650/ 1097] train: loss: 0.0236910
[Epoch 21; Iter   680/ 1097] train: loss: 0.0793407
[Epoch 21; Iter   710/ 1097] train: loss: 0.2633224
[Epoch 21; Iter   740/ 1097] train: loss: 0.1271650
[Epoch 21; Iter   770/ 1097] train: loss: 0.0441110
[Epoch 21; Iter   800/ 1097] train: loss: 0.2829461
[Epoch 21; Iter   830/ 1097] train: loss: 0.4542355
[Epoch 21; Iter   860/ 1097] train: loss: 0.0137338
[Epoch 21; Iter   890/ 1097] train: loss: 0.0354215
[Epoch 21; Iter   920/ 1097] train: loss: 0.1482017
[Epoch 21; Iter   950/ 1097] train: loss: 0.1196312
[Epoch 21; Iter   980/ 1097] train: loss: 0.2356735
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0507559
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2369918
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0251380
[Epoch 21] ogbg-molhiv: 0.767802 val loss: 0.079572
[Epoch 21] ogbg-molhiv: 0.776483 test loss: 0.119461
[Epoch 22; Iter     3/ 1097] train: loss: 0.0201618
[Epoch 22; Iter    33/ 1097] train: loss: 0.0753721
[Epoch 22; Iter    63/ 1097] train: loss: 0.1407924
[Epoch 22; Iter    93/ 1097] train: loss: 0.0249373
[Epoch 22; Iter   123/ 1097] train: loss: 0.0233336
[Epoch 22; Iter   153/ 1097] train: loss: 0.0455716
[Epoch 22; Iter   183/ 1097] train: loss: 0.0337778
[Epoch 22; Iter   213/ 1097] train: loss: 0.0218605
[Epoch 22; Iter   243/ 1097] train: loss: 0.0471113
[Epoch 22; Iter   273/ 1097] train: loss: 0.1872078
[Epoch 22; Iter   303/ 1097] train: loss: 0.0282546
[Epoch 22; Iter   333/ 1097] train: loss: 0.0264867
[Epoch 22; Iter   363/ 1097] train: loss: 0.0203695
[Epoch 22; Iter   393/ 1097] train: loss: 0.0270000
[Epoch 22; Iter   423/ 1097] train: loss: 0.0254442
[Epoch 22; Iter   453/ 1097] train: loss: 0.1344528
[Epoch 22; Iter   483/ 1097] train: loss: 0.0447369
[Epoch 22; Iter   513/ 1097] train: loss: 0.0157329
[Epoch 22; Iter   543/ 1097] train: loss: 0.1186525
[Epoch 22; Iter   573/ 1097] train: loss: 0.0592058
[Epoch 22; Iter   603/ 1097] train: loss: 0.0678297
[Epoch 22; Iter   633/ 1097] train: loss: 0.0142519
[Epoch 22; Iter   663/ 1097] train: loss: 0.0441244
[Epoch 22; Iter   693/ 1097] train: loss: 0.0177181
[Epoch 22; Iter   723/ 1097] train: loss: 0.0187614
[Epoch 22; Iter   753/ 1097] train: loss: 0.0381665
[Epoch 22; Iter   783/ 1097] train: loss: 0.2979601
[Epoch 22; Iter   813/ 1097] train: loss: 0.0361093
[Epoch 22; Iter   843/ 1097] train: loss: 0.1386504
[Epoch 22; Iter   873/ 1097] train: loss: 0.0531904
[Epoch 22; Iter   903/ 1097] train: loss: 0.0846902
[Epoch 22; Iter   933/ 1097] train: loss: 0.0270010
[Epoch 22; Iter   963/ 1097] train: loss: 0.1495285
[Epoch 22; Iter   993/ 1097] train: loss: 0.0230520
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0459497
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0904707
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0254151
[Epoch 22] ogbg-molhiv: 0.796318 val loss: 0.093534
[Epoch 22] ogbg-molhiv: 0.783789 test loss: 0.116147
[Epoch 23; Iter    16/ 1097] train: loss: 0.1020825
[Epoch 23; Iter    46/ 1097] train: loss: 0.0373610
[Epoch 23; Iter    76/ 1097] train: loss: 0.0663731
[Epoch 23; Iter   106/ 1097] train: loss: 0.0281922
[Epoch 23; Iter   136/ 1097] train: loss: 0.0877004
[Epoch 23; Iter   166/ 1097] train: loss: 0.2024935
[Epoch 23; Iter   196/ 1097] train: loss: 0.2299320
[Epoch 23; Iter   226/ 1097] train: loss: 0.0490470
[Epoch 23; Iter   256/ 1097] train: loss: 0.0452780
[Epoch 23; Iter   286/ 1097] train: loss: 0.0853603
[Epoch 23; Iter   316/ 1097] train: loss: 0.0228430
[Epoch 23; Iter   346/ 1097] train: loss: 0.0919525
[Epoch 23; Iter   376/ 1097] train: loss: 0.0710989
[Epoch 23; Iter   406/ 1097] train: loss: 0.0730277
[Epoch 23; Iter   436/ 1097] train: loss: 0.1542076
[Epoch 23; Iter   466/ 1097] train: loss: 0.0421380
[Epoch 23; Iter   496/ 1097] train: loss: 0.1392954
[Epoch 23; Iter   526/ 1097] train: loss: 0.0313915
[Epoch 23; Iter   556/ 1097] train: loss: 0.0746790
[Epoch 23; Iter   586/ 1097] train: loss: 0.0401493
[Epoch 23; Iter   616/ 1097] train: loss: 0.0169634
[Epoch 23; Iter   646/ 1097] train: loss: 0.0336811
[Epoch 23; Iter   676/ 1097] train: loss: 0.2131268
[Epoch 23; Iter   706/ 1097] train: loss: 0.0405151
[Epoch 23; Iter   736/ 1097] train: loss: 0.0355645
[Epoch 23; Iter   766/ 1097] train: loss: 0.1427865
[Epoch 23; Iter   796/ 1097] train: loss: 0.0889845
[Epoch 23; Iter   826/ 1097] train: loss: 0.1241284
[Epoch 23; Iter   856/ 1097] train: loss: 0.0165694
[Epoch 23; Iter   886/ 1097] train: loss: 0.0657275
[Epoch 23; Iter   916/ 1097] train: loss: 0.0211433
[Epoch 23; Iter   946/ 1097] train: loss: 0.0246672
[Epoch 23; Iter   976/ 1097] train: loss: 0.0230446
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0863096
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0316083
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0156049
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1733985
[Epoch 23] ogbg-molhiv: 0.774027 val loss: 0.340294
[Epoch 23] ogbg-molhiv: 0.753352 test loss: 0.257586
[Epoch 24; Iter    29/ 1097] train: loss: 0.0193237
[Epoch 24; Iter    59/ 1097] train: loss: 0.0714386
[Epoch 24; Iter    89/ 1097] train: loss: 0.2541436
[Epoch 24; Iter   119/ 1097] train: loss: 0.0781319
[Epoch 24; Iter   149/ 1097] train: loss: 0.1245480
[Epoch 24; Iter   179/ 1097] train: loss: 0.2020151
[Epoch 24; Iter   209/ 1097] train: loss: 0.1288052
[Epoch 24; Iter   239/ 1097] train: loss: 0.3873876
[Epoch 24; Iter   269/ 1097] train: loss: 0.0420820
[Epoch 24; Iter   299/ 1097] train: loss: 0.0245907
[Epoch 24; Iter   329/ 1097] train: loss: 0.2455234
[Epoch 20; Iter   277/ 1097] train: loss: 0.0166075
[Epoch 20; Iter   307/ 1097] train: loss: 0.0502194
[Epoch 20; Iter   337/ 1097] train: loss: 0.1628185
[Epoch 20; Iter   367/ 1097] train: loss: 0.3086386
[Epoch 20; Iter   397/ 1097] train: loss: 0.1422800
[Epoch 20; Iter   427/ 1097] train: loss: 0.0602264
[Epoch 20; Iter   457/ 1097] train: loss: 0.0364764
[Epoch 20; Iter   487/ 1097] train: loss: 0.1068335
[Epoch 20; Iter   517/ 1097] train: loss: 0.0638884
[Epoch 20; Iter   547/ 1097] train: loss: 0.2332961
[Epoch 20; Iter   577/ 1097] train: loss: 0.0236163
[Epoch 20; Iter   607/ 1097] train: loss: 0.2556332
[Epoch 20; Iter   637/ 1097] train: loss: 0.0632886
[Epoch 20; Iter   667/ 1097] train: loss: 0.1042935
[Epoch 20; Iter   697/ 1097] train: loss: 0.0250180
[Epoch 20; Iter   727/ 1097] train: loss: 0.0939058
[Epoch 20; Iter   757/ 1097] train: loss: 0.1452166
[Epoch 20; Iter   787/ 1097] train: loss: 0.0454057
[Epoch 20; Iter   817/ 1097] train: loss: 0.1533030
[Epoch 20; Iter   847/ 1097] train: loss: 0.0293935
[Epoch 20; Iter   877/ 1097] train: loss: 0.1690240
[Epoch 20; Iter   907/ 1097] train: loss: 0.1514347
[Epoch 20; Iter   937/ 1097] train: loss: 0.0724758
[Epoch 20; Iter   967/ 1097] train: loss: 0.0847696
[Epoch 20; Iter   997/ 1097] train: loss: 0.1293597
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0983738
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4514647
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2146770
[Epoch 20] ogbg-molhiv: 0.836809 val loss: 0.068727
[Epoch 20] ogbg-molhiv: 0.747546 test loss: 0.118273
[Epoch 21; Iter    20/ 1097] train: loss: 0.0307313
[Epoch 21; Iter    50/ 1097] train: loss: 0.2181656
[Epoch 21; Iter    80/ 1097] train: loss: 0.0538332
[Epoch 21; Iter   110/ 1097] train: loss: 0.0445262
[Epoch 21; Iter   140/ 1097] train: loss: 0.1518160
[Epoch 21; Iter   170/ 1097] train: loss: 0.1563189
[Epoch 21; Iter   200/ 1097] train: loss: 0.0391717
[Epoch 21; Iter   230/ 1097] train: loss: 0.0925114
[Epoch 21; Iter   260/ 1097] train: loss: 0.2095872
[Epoch 21; Iter   290/ 1097] train: loss: 0.0517186
[Epoch 21; Iter   320/ 1097] train: loss: 0.0605155
[Epoch 21; Iter   350/ 1097] train: loss: 0.1154897
[Epoch 21; Iter   380/ 1097] train: loss: 0.0424158
[Epoch 21; Iter   410/ 1097] train: loss: 0.0326525
[Epoch 21; Iter   440/ 1097] train: loss: 0.1488228
[Epoch 21; Iter   470/ 1097] train: loss: 0.0600246
[Epoch 21; Iter   500/ 1097] train: loss: 0.2453985
[Epoch 21; Iter   530/ 1097] train: loss: 0.0813392
[Epoch 21; Iter   560/ 1097] train: loss: 0.0445653
[Epoch 21; Iter   590/ 1097] train: loss: 0.0242505
[Epoch 21; Iter   620/ 1097] train: loss: 0.1408216
[Epoch 21; Iter   650/ 1097] train: loss: 0.0372587
[Epoch 21; Iter   680/ 1097] train: loss: 0.0199351
[Epoch 21; Iter   710/ 1097] train: loss: 0.0167044
[Epoch 21; Iter   740/ 1097] train: loss: 0.0178561
[Epoch 21; Iter   770/ 1097] train: loss: 0.1244479
[Epoch 21; Iter   800/ 1097] train: loss: 0.0399180
[Epoch 21; Iter   830/ 1097] train: loss: 0.0540177
[Epoch 21; Iter   860/ 1097] train: loss: 0.0228383
[Epoch 21; Iter   890/ 1097] train: loss: 0.0392219
[Epoch 21; Iter   920/ 1097] train: loss: 0.1411901
[Epoch 21; Iter   950/ 1097] train: loss: 0.0447890
[Epoch 21; Iter   980/ 1097] train: loss: 0.2045916
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1612371
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0228397
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0305467
[Epoch 21] ogbg-molhiv: 0.813912 val loss: 0.067267
[Epoch 21] ogbg-molhiv: 0.741720 test loss: 0.119121
[Epoch 22; Iter     3/ 1097] train: loss: 0.0567887
[Epoch 22; Iter    33/ 1097] train: loss: 0.2763295
[Epoch 22; Iter    63/ 1097] train: loss: 0.1827305
[Epoch 22; Iter    93/ 1097] train: loss: 0.0600759
[Epoch 22; Iter   123/ 1097] train: loss: 0.1090082
[Epoch 22; Iter   153/ 1097] train: loss: 0.3034986
[Epoch 22; Iter   183/ 1097] train: loss: 0.1893756
[Epoch 22; Iter   213/ 1097] train: loss: 0.0389960
[Epoch 22; Iter   243/ 1097] train: loss: 0.0387365
[Epoch 22; Iter   273/ 1097] train: loss: 0.0543631
[Epoch 22; Iter   303/ 1097] train: loss: 0.0295798
[Epoch 22; Iter   333/ 1097] train: loss: 0.1961497
[Epoch 22; Iter   363/ 1097] train: loss: 0.0679168
[Epoch 22; Iter   393/ 1097] train: loss: 0.2112759
[Epoch 22; Iter   423/ 1097] train: loss: 0.0282336
[Epoch 22; Iter   453/ 1097] train: loss: 0.0291237
[Epoch 22; Iter   483/ 1097] train: loss: 0.2079554
[Epoch 22; Iter   513/ 1097] train: loss: 0.0844674
[Epoch 22; Iter   543/ 1097] train: loss: 0.0313046
[Epoch 22; Iter   573/ 1097] train: loss: 0.0718934
[Epoch 22; Iter   603/ 1097] train: loss: 0.0174022
[Epoch 22; Iter   633/ 1097] train: loss: 0.0310732
[Epoch 22; Iter   663/ 1097] train: loss: 0.0539788
[Epoch 22; Iter   693/ 1097] train: loss: 0.0223562
[Epoch 22; Iter   723/ 1097] train: loss: 0.0229069
[Epoch 22; Iter   753/ 1097] train: loss: 0.2379072
[Epoch 22; Iter   783/ 1097] train: loss: 0.1877735
[Epoch 22; Iter   813/ 1097] train: loss: 0.0256097
[Epoch 22; Iter   843/ 1097] train: loss: 0.0271678
[Epoch 22; Iter   873/ 1097] train: loss: 0.0852363
[Epoch 22; Iter   903/ 1097] train: loss: 0.0748528
[Epoch 22; Iter   933/ 1097] train: loss: 0.0505571
[Epoch 22; Iter   963/ 1097] train: loss: 0.2408527
[Epoch 22; Iter   993/ 1097] train: loss: 0.0568871
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0239588
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1669132
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0201645
[Epoch 22] ogbg-molhiv: 0.812280 val loss: 0.080065
[Epoch 22] ogbg-molhiv: 0.761963 test loss: 0.118498
[Epoch 23; Iter    16/ 1097] train: loss: 0.0571104
[Epoch 23; Iter    46/ 1097] train: loss: 0.1049739
[Epoch 23; Iter    76/ 1097] train: loss: 0.0315443
[Epoch 23; Iter   106/ 1097] train: loss: 0.0211506
[Epoch 23; Iter   136/ 1097] train: loss: 0.1901572
[Epoch 23; Iter   166/ 1097] train: loss: 0.0667911
[Epoch 23; Iter   196/ 1097] train: loss: 0.2618167
[Epoch 23; Iter   226/ 1097] train: loss: 0.0836278
[Epoch 23; Iter   256/ 1097] train: loss: 0.0672035
[Epoch 23; Iter   286/ 1097] train: loss: 0.0271786
[Epoch 23; Iter   316/ 1097] train: loss: 0.3650983
[Epoch 23; Iter   346/ 1097] train: loss: 0.1273519
[Epoch 23; Iter   376/ 1097] train: loss: 0.2071560
[Epoch 23; Iter   406/ 1097] train: loss: 0.0755921
[Epoch 23; Iter   436/ 1097] train: loss: 0.2361277
[Epoch 23; Iter   466/ 1097] train: loss: 0.0867760
[Epoch 23; Iter   496/ 1097] train: loss: 0.0613275
[Epoch 23; Iter   526/ 1097] train: loss: 0.0167052
[Epoch 23; Iter   556/ 1097] train: loss: 0.1210525
[Epoch 23; Iter   586/ 1097] train: loss: 0.0246127
[Epoch 23; Iter   616/ 1097] train: loss: 0.0523164
[Epoch 23; Iter   646/ 1097] train: loss: 0.0329508
[Epoch 23; Iter   676/ 1097] train: loss: 0.0384442
[Epoch 23; Iter   706/ 1097] train: loss: 0.0776320
[Epoch 23; Iter   736/ 1097] train: loss: 0.1315393
[Epoch 23; Iter   766/ 1097] train: loss: 0.0434679
[Epoch 23; Iter   796/ 1097] train: loss: 0.2400987
[Epoch 23; Iter   826/ 1097] train: loss: 0.0399069
[Epoch 23; Iter   856/ 1097] train: loss: 0.1885376
[Epoch 23; Iter   886/ 1097] train: loss: 0.1839621
[Epoch 23; Iter   916/ 1097] train: loss: 0.0847414
[Epoch 23; Iter   946/ 1097] train: loss: 0.1760994
[Epoch 23; Iter   976/ 1097] train: loss: 0.0246920
[Epoch 23; Iter  1006/ 1097] train: loss: 0.2001612
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1254425
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1702693
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0292078
[Epoch 23] ogbg-molhiv: 0.824083 val loss: 0.065493
[Epoch 23] ogbg-molhiv: 0.739022 test loss: 0.119929
[Epoch 24; Iter    29/ 1097] train: loss: 0.0197423
[Epoch 24; Iter    59/ 1097] train: loss: 0.1580099
[Epoch 24; Iter    89/ 1097] train: loss: 0.0273852
[Epoch 24; Iter   119/ 1097] train: loss: 0.0458570
[Epoch 24; Iter   149/ 1097] train: loss: 0.3113641
[Epoch 24; Iter   179/ 1097] train: loss: 0.0963475
[Epoch 24; Iter   209/ 1097] train: loss: 0.0249364
[Epoch 24; Iter   239/ 1097] train: loss: 0.1303223
[Epoch 24; Iter   269/ 1097] train: loss: 0.0345514
[Epoch 24; Iter   299/ 1097] train: loss: 0.0707974
[Epoch 24; Iter   329/ 1097] train: loss: 0.0519824
[Epoch 20; Iter   277/ 1097] train: loss: 0.1588779
[Epoch 20; Iter   307/ 1097] train: loss: 0.1860467
[Epoch 20; Iter   337/ 1097] train: loss: 0.0796114
[Epoch 20; Iter   367/ 1097] train: loss: 0.0751801
[Epoch 20; Iter   397/ 1097] train: loss: 0.0290468
[Epoch 20; Iter   427/ 1097] train: loss: 0.0197049
[Epoch 20; Iter   457/ 1097] train: loss: 0.1380441
[Epoch 20; Iter   487/ 1097] train: loss: 0.1341000
[Epoch 20; Iter   517/ 1097] train: loss: 0.0370072
[Epoch 20; Iter   547/ 1097] train: loss: 0.1331650
[Epoch 20; Iter   577/ 1097] train: loss: 0.0203111
[Epoch 20; Iter   607/ 1097] train: loss: 0.0188894
[Epoch 20; Iter   637/ 1097] train: loss: 0.0216354
[Epoch 20; Iter   667/ 1097] train: loss: 0.1554403
[Epoch 20; Iter   697/ 1097] train: loss: 0.0648480
[Epoch 20; Iter   727/ 1097] train: loss: 0.1278725
[Epoch 20; Iter   757/ 1097] train: loss: 0.0214245
[Epoch 20; Iter   787/ 1097] train: loss: 0.0301146
[Epoch 20; Iter   817/ 1097] train: loss: 0.0969174
[Epoch 20; Iter   847/ 1097] train: loss: 0.0495197
[Epoch 20; Iter   877/ 1097] train: loss: 0.1520529
[Epoch 20; Iter   907/ 1097] train: loss: 0.2209145
[Epoch 20; Iter   937/ 1097] train: loss: 0.0201961
[Epoch 20; Iter   967/ 1097] train: loss: 0.0946379
[Epoch 20; Iter   997/ 1097] train: loss: 0.1367312
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0311566
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0363533
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0397778
[Epoch 20] ogbg-molhiv: 0.823103 val loss: 0.075149
[Epoch 20] ogbg-molhiv: 0.781122 test loss: 0.121395
[Epoch 21; Iter    20/ 1097] train: loss: 0.0241192
[Epoch 21; Iter    50/ 1097] train: loss: 0.1616614
[Epoch 21; Iter    80/ 1097] train: loss: 0.0388662
[Epoch 21; Iter   110/ 1097] train: loss: 0.0487976
[Epoch 21; Iter   140/ 1097] train: loss: 0.1562740
[Epoch 21; Iter   170/ 1097] train: loss: 0.1468622
[Epoch 21; Iter   200/ 1097] train: loss: 0.1778336
[Epoch 21; Iter   230/ 1097] train: loss: 0.1681204
[Epoch 21; Iter   260/ 1097] train: loss: 0.2356914
[Epoch 21; Iter   290/ 1097] train: loss: 0.1961317
[Epoch 21; Iter   320/ 1097] train: loss: 0.2116153
[Epoch 21; Iter   350/ 1097] train: loss: 0.0272715
[Epoch 21; Iter   380/ 1097] train: loss: 0.0436058
[Epoch 21; Iter   410/ 1097] train: loss: 0.0652131
[Epoch 21; Iter   440/ 1097] train: loss: 0.1558533
[Epoch 21; Iter   470/ 1097] train: loss: 0.1648207
[Epoch 21; Iter   500/ 1097] train: loss: 0.0245686
[Epoch 21; Iter   530/ 1097] train: loss: 0.0328086
[Epoch 21; Iter   560/ 1097] train: loss: 0.0203122
[Epoch 21; Iter   590/ 1097] train: loss: 0.1519257
[Epoch 21; Iter   620/ 1097] train: loss: 0.0790948
[Epoch 21; Iter   650/ 1097] train: loss: 0.2377174
[Epoch 21; Iter   680/ 1097] train: loss: 0.0748497
[Epoch 21; Iter   710/ 1097] train: loss: 0.0303713
[Epoch 21; Iter   740/ 1097] train: loss: 0.0358971
[Epoch 21; Iter   770/ 1097] train: loss: 0.0472346
[Epoch 21; Iter   800/ 1097] train: loss: 0.0714417
[Epoch 21; Iter   830/ 1097] train: loss: 0.2319302
[Epoch 21; Iter   860/ 1097] train: loss: 0.0494269
[Epoch 21; Iter   890/ 1097] train: loss: 0.0281598
[Epoch 21; Iter   920/ 1097] train: loss: 0.0789955
[Epoch 21; Iter   950/ 1097] train: loss: 0.0573499
[Epoch 21; Iter   980/ 1097] train: loss: 0.0230113
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0262024
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1669439
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0542483
[Epoch 21] ogbg-molhiv: 0.808351 val loss: 0.219503
[Epoch 21] ogbg-molhiv: 0.797180 test loss: 0.146853
[Epoch 22; Iter     3/ 1097] train: loss: 0.1620794
[Epoch 22; Iter    33/ 1097] train: loss: 0.0206446
[Epoch 22; Iter    63/ 1097] train: loss: 0.0566440
[Epoch 22; Iter    93/ 1097] train: loss: 0.0723523
[Epoch 22; Iter   123/ 1097] train: loss: 0.0374805
[Epoch 22; Iter   153/ 1097] train: loss: 0.0486311
[Epoch 22; Iter   183/ 1097] train: loss: 0.0438097
[Epoch 22; Iter   213/ 1097] train: loss: 0.1211783
[Epoch 22; Iter   243/ 1097] train: loss: 0.1613082
[Epoch 22; Iter   273/ 1097] train: loss: 0.2314117
[Epoch 22; Iter   303/ 1097] train: loss: 0.2042614
[Epoch 22; Iter   333/ 1097] train: loss: 0.0490486
[Epoch 22; Iter   363/ 1097] train: loss: 0.2597944
[Epoch 22; Iter   393/ 1097] train: loss: 0.0229455
[Epoch 22; Iter   423/ 1097] train: loss: 0.0817833
[Epoch 22; Iter   453/ 1097] train: loss: 0.0255008
[Epoch 22; Iter   483/ 1097] train: loss: 0.0739737
[Epoch 22; Iter   513/ 1097] train: loss: 0.3639046
[Epoch 22; Iter   543/ 1097] train: loss: 0.1824457
[Epoch 22; Iter   573/ 1097] train: loss: 0.0337088
[Epoch 22; Iter   603/ 1097] train: loss: 0.0306209
[Epoch 22; Iter   633/ 1097] train: loss: 0.0282728
[Epoch 22; Iter   663/ 1097] train: loss: 0.0347251
[Epoch 22; Iter   693/ 1097] train: loss: 0.1988091
[Epoch 22; Iter   723/ 1097] train: loss: 0.1420026
[Epoch 22; Iter   753/ 1097] train: loss: 0.2901906
[Epoch 22; Iter   783/ 1097] train: loss: 0.0349152
[Epoch 22; Iter   813/ 1097] train: loss: 0.1493181
[Epoch 22; Iter   843/ 1097] train: loss: 0.0345036
[Epoch 22; Iter   873/ 1097] train: loss: 0.0580409
[Epoch 22; Iter   903/ 1097] train: loss: 0.2961333
[Epoch 22; Iter   933/ 1097] train: loss: 0.0242939
[Epoch 22; Iter   963/ 1097] train: loss: 0.1898137
[Epoch 22; Iter   993/ 1097] train: loss: 0.1693206
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3711695
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0204633
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1506652
[Epoch 22] ogbg-molhiv: 0.817479 val loss: 0.282485
[Epoch 22] ogbg-molhiv: 0.787995 test loss: 0.139581
[Epoch 23; Iter    16/ 1097] train: loss: 0.0368182
[Epoch 23; Iter    46/ 1097] train: loss: 0.2848452
[Epoch 23; Iter    76/ 1097] train: loss: 0.1248685
[Epoch 23; Iter   106/ 1097] train: loss: 0.1814233
[Epoch 23; Iter   136/ 1097] train: loss: 0.0731159
[Epoch 23; Iter   166/ 1097] train: loss: 0.2232965
[Epoch 23; Iter   196/ 1097] train: loss: 0.1006002
[Epoch 23; Iter   226/ 1097] train: loss: 0.0695225
[Epoch 23; Iter   256/ 1097] train: loss: 0.1384970
[Epoch 23; Iter   286/ 1097] train: loss: 0.0269037
[Epoch 23; Iter   316/ 1097] train: loss: 0.0618117
[Epoch 23; Iter   346/ 1097] train: loss: 0.0513741
[Epoch 23; Iter   376/ 1097] train: loss: 0.0273799
[Epoch 23; Iter   406/ 1097] train: loss: 0.1713067
[Epoch 23; Iter   436/ 1097] train: loss: 0.0269278
[Epoch 23; Iter   466/ 1097] train: loss: 0.0191585
[Epoch 23; Iter   496/ 1097] train: loss: 0.2293218
[Epoch 23; Iter   526/ 1097] train: loss: 0.0771291
[Epoch 23; Iter   556/ 1097] train: loss: 0.0341179
[Epoch 23; Iter   586/ 1097] train: loss: 0.1181711
[Epoch 23; Iter   616/ 1097] train: loss: 0.1408063
[Epoch 23; Iter   646/ 1097] train: loss: 0.1508366
[Epoch 23; Iter   676/ 1097] train: loss: 0.0441046
[Epoch 23; Iter   706/ 1097] train: loss: 0.0295165
[Epoch 23; Iter   736/ 1097] train: loss: 0.2402091
[Epoch 23; Iter   766/ 1097] train: loss: 0.1735082
[Epoch 23; Iter   796/ 1097] train: loss: 0.0231108
[Epoch 23; Iter   826/ 1097] train: loss: 0.2357526
[Epoch 23; Iter   856/ 1097] train: loss: 0.2808636
[Epoch 23; Iter   886/ 1097] train: loss: 0.1426488
[Epoch 23; Iter   916/ 1097] train: loss: 0.2991890
[Epoch 23; Iter   946/ 1097] train: loss: 0.0221092
[Epoch 23; Iter   976/ 1097] train: loss: 0.2177678
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0215019
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0363057
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2301293
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0940164
[Epoch 23] ogbg-molhiv: 0.799686 val loss: 0.113949
[Epoch 23] ogbg-molhiv: 0.776512 test loss: 0.113278
[Epoch 24; Iter    29/ 1097] train: loss: 0.1118198
[Epoch 24; Iter    59/ 1097] train: loss: 0.2006258
[Epoch 24; Iter    89/ 1097] train: loss: 0.2675352
[Epoch 24; Iter   119/ 1097] train: loss: 0.0216800
[Epoch 24; Iter   149/ 1097] train: loss: 0.0532485
[Epoch 24; Iter   179/ 1097] train: loss: 0.0557682
[Epoch 24; Iter   209/ 1097] train: loss: 0.3008815
[Epoch 24; Iter   239/ 1097] train: loss: 0.0270283
[Epoch 24; Iter   269/ 1097] train: loss: 0.3610581
[Epoch 24; Iter   299/ 1097] train: loss: 0.0235767
[Epoch 24; Iter   329/ 1097] train: loss: 0.0257518
[Epoch 24; Iter   359/ 1097] train: loss: 0.0656842
[Epoch 24; Iter   389/ 1097] train: loss: 0.1195582
[Epoch 24; Iter   419/ 1097] train: loss: 0.2911288
[Epoch 24; Iter   449/ 1097] train: loss: 0.0198491
[Epoch 24; Iter   479/ 1097] train: loss: 0.0192918
[Epoch 24; Iter   509/ 1097] train: loss: 0.0288915
[Epoch 24; Iter   539/ 1097] train: loss: 0.0158013
[Epoch 24; Iter   569/ 1097] train: loss: 0.1079127
[Epoch 24; Iter   599/ 1097] train: loss: 0.2490322
[Epoch 24; Iter   629/ 1097] train: loss: 0.0126186
[Epoch 24; Iter   659/ 1097] train: loss: 0.0108061
[Epoch 24; Iter   689/ 1097] train: loss: 0.0093856
[Epoch 24; Iter   719/ 1097] train: loss: 0.0265927
[Epoch 24; Iter   749/ 1097] train: loss: 0.0531179
[Epoch 24; Iter   779/ 1097] train: loss: 0.0905985
[Epoch 24; Iter   809/ 1097] train: loss: 0.0547007
[Epoch 24; Iter   839/ 1097] train: loss: 0.1831638
[Epoch 24; Iter   869/ 1097] train: loss: 0.0938526
[Epoch 24; Iter   899/ 1097] train: loss: 0.3005301
[Epoch 24; Iter   929/ 1097] train: loss: 0.2578773
[Epoch 24; Iter   959/ 1097] train: loss: 0.0339648
[Epoch 24; Iter   989/ 1097] train: loss: 0.0466168
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1688363
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0298792
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0817630
[Epoch 24] ogbg-molhiv: 0.749014 val loss: 0.704617
[Epoch 24] ogbg-molhiv: 0.683070 test loss: 0.247458
[Epoch 25; Iter    12/ 1097] train: loss: 0.0364995
[Epoch 25; Iter    42/ 1097] train: loss: 0.0296675
[Epoch 25; Iter    72/ 1097] train: loss: 0.0190982
[Epoch 25; Iter   102/ 1097] train: loss: 0.1215291
[Epoch 25; Iter   132/ 1097] train: loss: 0.0219672
[Epoch 25; Iter   162/ 1097] train: loss: 0.0228822
[Epoch 25; Iter   192/ 1097] train: loss: 0.1466927
[Epoch 25; Iter   222/ 1097] train: loss: 0.0117392
[Epoch 25; Iter   252/ 1097] train: loss: 0.0541233
[Epoch 25; Iter   282/ 1097] train: loss: 0.1321159
[Epoch 25; Iter   312/ 1097] train: loss: 0.0253840
[Epoch 25; Iter   342/ 1097] train: loss: 0.0880375
[Epoch 25; Iter   372/ 1097] train: loss: 0.2686054
[Epoch 25; Iter   402/ 1097] train: loss: 0.0323875
[Epoch 25; Iter   432/ 1097] train: loss: 0.2645901
[Epoch 25; Iter   462/ 1097] train: loss: 0.0181304
[Epoch 25; Iter   492/ 1097] train: loss: 0.1309120
[Epoch 25; Iter   522/ 1097] train: loss: 0.0657804
[Epoch 25; Iter   552/ 1097] train: loss: 0.2201955
[Epoch 25; Iter   582/ 1097] train: loss: 0.0875154
[Epoch 25; Iter   612/ 1097] train: loss: 0.1526565
[Epoch 25; Iter   642/ 1097] train: loss: 0.1788267
[Epoch 25; Iter   672/ 1097] train: loss: 0.0144913
[Epoch 25; Iter   702/ 1097] train: loss: 0.1275643
[Epoch 25; Iter   732/ 1097] train: loss: 0.0526740
[Epoch 25; Iter   762/ 1097] train: loss: 0.1170264
[Epoch 25; Iter   792/ 1097] train: loss: 0.0150591
[Epoch 25; Iter   822/ 1097] train: loss: 0.0679048
[Epoch 25; Iter   852/ 1097] train: loss: 0.0298521
[Epoch 25; Iter   882/ 1097] train: loss: 0.0405755
[Epoch 25; Iter   912/ 1097] train: loss: 0.1399343
[Epoch 25; Iter   942/ 1097] train: loss: 0.0242768
[Epoch 25; Iter   972/ 1097] train: loss: 0.0941267
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2879366
[Epoch 25; Iter  1032/ 1097] train: loss: 0.1126788
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0931895
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1255537
[Epoch 25] ogbg-molhiv: 0.778837 val loss: 0.249951
[Epoch 25] ogbg-molhiv: 0.718909 test loss: 0.154699
[Epoch 26; Iter    25/ 1097] train: loss: 0.0564184
[Epoch 26; Iter    55/ 1097] train: loss: 0.0881875
[Epoch 26; Iter    85/ 1097] train: loss: 0.0686805
[Epoch 26; Iter   115/ 1097] train: loss: 0.1422258
[Epoch 26; Iter   145/ 1097] train: loss: 0.0578999
[Epoch 26; Iter   175/ 1097] train: loss: 0.0629489
[Epoch 26; Iter   205/ 1097] train: loss: 0.2412499
[Epoch 26; Iter   235/ 1097] train: loss: 0.0379102
[Epoch 26; Iter   265/ 1097] train: loss: 0.0483391
[Epoch 26; Iter   295/ 1097] train: loss: 0.1065008
[Epoch 26; Iter   325/ 1097] train: loss: 0.0180827
[Epoch 26; Iter   355/ 1097] train: loss: 0.0373888
[Epoch 26; Iter   385/ 1097] train: loss: 0.1071406
[Epoch 26; Iter   415/ 1097] train: loss: 0.0472675
[Epoch 26; Iter   445/ 1097] train: loss: 0.0162555
[Epoch 26; Iter   475/ 1097] train: loss: 0.1125462
[Epoch 26; Iter   505/ 1097] train: loss: 0.0756989
[Epoch 26; Iter   535/ 1097] train: loss: 0.1588925
[Epoch 26; Iter   565/ 1097] train: loss: 0.1191451
[Epoch 26; Iter   595/ 1097] train: loss: 0.0190072
[Epoch 26; Iter   625/ 1097] train: loss: 0.0666320
[Epoch 26; Iter   655/ 1097] train: loss: 0.0465377
[Epoch 26; Iter   685/ 1097] train: loss: 0.0853294
[Epoch 26; Iter   715/ 1097] train: loss: 0.0680388
[Epoch 26; Iter   745/ 1097] train: loss: 0.0200617
[Epoch 26; Iter   775/ 1097] train: loss: 0.0523963
[Epoch 26; Iter   805/ 1097] train: loss: 0.0431690
[Epoch 26; Iter   835/ 1097] train: loss: 0.1258051
[Epoch 26; Iter   865/ 1097] train: loss: 0.1778990
[Epoch 26; Iter   895/ 1097] train: loss: 0.0242165
[Epoch 26; Iter   925/ 1097] train: loss: 0.3070904
[Epoch 26; Iter   955/ 1097] train: loss: 0.0159025
[Epoch 26; Iter   985/ 1097] train: loss: 0.1241007
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0368930
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0202428
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1068907
[Epoch 26] ogbg-molhiv: 0.813223 val loss: 0.620041
[Epoch 26] ogbg-molhiv: 0.768379 test loss: 0.216701
[Epoch 27; Iter     8/ 1097] train: loss: 0.0404124
[Epoch 27; Iter    38/ 1097] train: loss: 0.0403787
[Epoch 27; Iter    68/ 1097] train: loss: 0.0106999
[Epoch 27; Iter    98/ 1097] train: loss: 0.2200765
[Epoch 27; Iter   128/ 1097] train: loss: 0.2598926
[Epoch 27; Iter   158/ 1097] train: loss: 0.0171125
[Epoch 27; Iter   188/ 1097] train: loss: 0.0421063
[Epoch 27; Iter   218/ 1097] train: loss: 0.0833440
[Epoch 27; Iter   248/ 1097] train: loss: 0.0279618
[Epoch 27; Iter   278/ 1097] train: loss: 0.0334966
[Epoch 27; Iter   308/ 1097] train: loss: 0.0735442
[Epoch 27; Iter   338/ 1097] train: loss: 0.0110270
[Epoch 27; Iter   368/ 1097] train: loss: 0.1242281
[Epoch 27; Iter   398/ 1097] train: loss: 0.0101739
[Epoch 27; Iter   428/ 1097] train: loss: 0.1639363
[Epoch 27; Iter   458/ 1097] train: loss: 0.0215042
[Epoch 27; Iter   488/ 1097] train: loss: 0.0600329
[Epoch 27; Iter   518/ 1097] train: loss: 0.0808459
[Epoch 27; Iter   548/ 1097] train: loss: 0.0631816
[Epoch 27; Iter   578/ 1097] train: loss: 0.0289248
[Epoch 27; Iter   608/ 1097] train: loss: 0.1323633
[Epoch 27; Iter   638/ 1097] train: loss: 0.0129749
[Epoch 27; Iter   668/ 1097] train: loss: 0.0339037
[Epoch 27; Iter   698/ 1097] train: loss: 0.0522567
[Epoch 27; Iter   728/ 1097] train: loss: 0.1698341
[Epoch 27; Iter   758/ 1097] train: loss: 0.0223749
[Epoch 27; Iter   788/ 1097] train: loss: 0.0237954
[Epoch 27; Iter   818/ 1097] train: loss: 0.0322646
[Epoch 27; Iter   848/ 1097] train: loss: 0.2257235
[Epoch 27; Iter   878/ 1097] train: loss: 0.0389280
[Epoch 27; Iter   908/ 1097] train: loss: 0.0130613
[Epoch 27; Iter   938/ 1097] train: loss: 0.0722629
[Epoch 27; Iter   968/ 1097] train: loss: 0.0483356
[Epoch 27; Iter   998/ 1097] train: loss: 0.0744520
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0111750
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2282802
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0913861
[Epoch 27] ogbg-molhiv: 0.783360 val loss: 0.089403
[Epoch 27] ogbg-molhiv: 0.718612 test loss: 0.145928
[Epoch 28; Iter    21/ 1097] train: loss: 0.0325874
[Epoch 28; Iter    51/ 1097] train: loss: 0.0398667
[Epoch 28; Iter    81/ 1097] train: loss: 0.0120479
[Epoch 28; Iter   111/ 1097] train: loss: 0.1521921
[Epoch 28; Iter   141/ 1097] train: loss: 0.0722430
[Epoch 28; Iter   171/ 1097] train: loss: 0.1003062
[Epoch 28; Iter   201/ 1097] train: loss: 0.1501792
[Epoch 28; Iter   231/ 1097] train: loss: 0.0470297
[Epoch 28; Iter   261/ 1097] train: loss: 0.1381638
[Epoch 28; Iter   291/ 1097] train: loss: 0.0379060
[Epoch 28; Iter   321/ 1097] train: loss: 0.0292048
[Epoch 28; Iter   351/ 1097] train: loss: 0.0131411
[Epoch 28; Iter   381/ 1097] train: loss: 0.0527095
[Epoch 28; Iter   411/ 1097] train: loss: 0.0207522
[Epoch 24; Iter   359/ 1097] train: loss: 0.1600152
[Epoch 24; Iter   389/ 1097] train: loss: 0.0262500
[Epoch 24; Iter   419/ 1097] train: loss: 0.0200608
[Epoch 24; Iter   449/ 1097] train: loss: 0.0253501
[Epoch 24; Iter   479/ 1097] train: loss: 0.2218833
[Epoch 24; Iter   509/ 1097] train: loss: 0.1406226
[Epoch 24; Iter   539/ 1097] train: loss: 0.0331794
[Epoch 24; Iter   569/ 1097] train: loss: 0.0830232
[Epoch 24; Iter   599/ 1097] train: loss: 0.1427702
[Epoch 24; Iter   629/ 1097] train: loss: 0.0207873
[Epoch 24; Iter   659/ 1097] train: loss: 0.1175787
[Epoch 24; Iter   689/ 1097] train: loss: 0.0393871
[Epoch 24; Iter   719/ 1097] train: loss: 0.0271380
[Epoch 24; Iter   749/ 1097] train: loss: 0.0265353
[Epoch 24; Iter   779/ 1097] train: loss: 0.1778207
[Epoch 24; Iter   809/ 1097] train: loss: 0.2052959
[Epoch 24; Iter   839/ 1097] train: loss: 0.0175982
[Epoch 24; Iter   869/ 1097] train: loss: 0.0204070
[Epoch 24; Iter   899/ 1097] train: loss: 0.0144545
[Epoch 24; Iter   929/ 1097] train: loss: 0.0625884
[Epoch 24; Iter   959/ 1097] train: loss: 0.0176077
[Epoch 24; Iter   989/ 1097] train: loss: 0.1134109
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3669811
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0174945
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1540827
[Epoch 24] ogbg-molhiv: 0.749130 val loss: 0.197548
[Epoch 24] ogbg-molhiv: 0.747052 test loss: 0.272813
[Epoch 25; Iter    12/ 1097] train: loss: 0.0190421
[Epoch 25; Iter    42/ 1097] train: loss: 0.0785796
[Epoch 25; Iter    72/ 1097] train: loss: 0.2579119
[Epoch 25; Iter   102/ 1097] train: loss: 0.0327240
[Epoch 25; Iter   132/ 1097] train: loss: 0.0189094
[Epoch 25; Iter   162/ 1097] train: loss: 0.0561610
[Epoch 25; Iter   192/ 1097] train: loss: 0.0460756
[Epoch 25; Iter   222/ 1097] train: loss: 0.1475510
[Epoch 25; Iter   252/ 1097] train: loss: 0.0086586
[Epoch 25; Iter   282/ 1097] train: loss: 0.0261952
[Epoch 25; Iter   312/ 1097] train: loss: 0.0120028
[Epoch 25; Iter   342/ 1097] train: loss: 0.0307608
[Epoch 25; Iter   372/ 1097] train: loss: 0.0273625
[Epoch 25; Iter   402/ 1097] train: loss: 0.0622720
[Epoch 25; Iter   432/ 1097] train: loss: 0.0539117
[Epoch 25; Iter   462/ 1097] train: loss: 0.0433138
[Epoch 25; Iter   492/ 1097] train: loss: 0.0623018
[Epoch 25; Iter   522/ 1097] train: loss: 0.0220946
[Epoch 25; Iter   552/ 1097] train: loss: 0.1155792
[Epoch 25; Iter   582/ 1097] train: loss: 0.1531578
[Epoch 25; Iter   612/ 1097] train: loss: 0.0116579
[Epoch 25; Iter   642/ 1097] train: loss: 0.2487844
[Epoch 25; Iter   672/ 1097] train: loss: 0.0217334
[Epoch 25; Iter   702/ 1097] train: loss: 0.0254504
[Epoch 25; Iter   732/ 1097] train: loss: 0.1576772
[Epoch 25; Iter   762/ 1097] train: loss: 0.1024710
[Epoch 25; Iter   792/ 1097] train: loss: 0.0582084
[Epoch 25; Iter   822/ 1097] train: loss: 0.0147855
[Epoch 25; Iter   852/ 1097] train: loss: 0.0235886
[Epoch 25; Iter   882/ 1097] train: loss: 0.0552239
[Epoch 25; Iter   912/ 1097] train: loss: 0.0309400
[Epoch 25; Iter   942/ 1097] train: loss: 0.1701831
[Epoch 25; Iter   972/ 1097] train: loss: 0.1113275
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0266758
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0530086
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1727538
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0146370
[Epoch 25] ogbg-molhiv: 0.759079 val loss: 0.124737
[Epoch 25] ogbg-molhiv: 0.782439 test loss: 0.128022
[Epoch 26; Iter    25/ 1097] train: loss: 0.1198978
[Epoch 26; Iter    55/ 1097] train: loss: 0.0763570
[Epoch 26; Iter    85/ 1097] train: loss: 0.1982664
[Epoch 26; Iter   115/ 1097] train: loss: 0.0717315
[Epoch 26; Iter   145/ 1097] train: loss: 0.0628076
[Epoch 26; Iter   175/ 1097] train: loss: 0.0707380
[Epoch 26; Iter   205/ 1097] train: loss: 0.0218279
[Epoch 26; Iter   235/ 1097] train: loss: 0.0753992
[Epoch 26; Iter   265/ 1097] train: loss: 0.0278230
[Epoch 26; Iter   295/ 1097] train: loss: 0.0552989
[Epoch 26; Iter   325/ 1097] train: loss: 0.0259987
[Epoch 26; Iter   355/ 1097] train: loss: 0.0953817
[Epoch 26; Iter   385/ 1097] train: loss: 0.0747694
[Epoch 26; Iter   415/ 1097] train: loss: 0.0181518
[Epoch 26; Iter   445/ 1097] train: loss: 0.0345550
[Epoch 26; Iter   475/ 1097] train: loss: 0.0191332
[Epoch 26; Iter   505/ 1097] train: loss: 0.0911462
[Epoch 26; Iter   535/ 1097] train: loss: 0.0118369
[Epoch 26; Iter   565/ 1097] train: loss: 0.0331740
[Epoch 26; Iter   595/ 1097] train: loss: 0.0498167
[Epoch 26; Iter   625/ 1097] train: loss: 0.0351079
[Epoch 26; Iter   655/ 1097] train: loss: 0.1388955
[Epoch 26; Iter   685/ 1097] train: loss: 0.1686085
[Epoch 26; Iter   715/ 1097] train: loss: 0.0516467
[Epoch 26; Iter   745/ 1097] train: loss: 0.0681002
[Epoch 26; Iter   775/ 1097] train: loss: 0.0843850
[Epoch 26; Iter   805/ 1097] train: loss: 0.0282076
[Epoch 26; Iter   835/ 1097] train: loss: 0.0187424
[Epoch 26; Iter   865/ 1097] train: loss: 0.0912078
[Epoch 26; Iter   895/ 1097] train: loss: 0.0244413
[Epoch 26; Iter   925/ 1097] train: loss: 0.0341030
[Epoch 26; Iter   955/ 1097] train: loss: 0.0590460
[Epoch 26; Iter   985/ 1097] train: loss: 0.0902796
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1875331
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0153799
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1697839
[Epoch 26] ogbg-molhiv: 0.770497 val loss: 0.273486
[Epoch 26] ogbg-molhiv: 0.757715 test loss: 0.421225
[Epoch 27; Iter     8/ 1097] train: loss: 0.0146822
[Epoch 27; Iter    38/ 1097] train: loss: 0.0691383
[Epoch 27; Iter    68/ 1097] train: loss: 0.0377298
[Epoch 27; Iter    98/ 1097] train: loss: 0.1033972
[Epoch 27; Iter   128/ 1097] train: loss: 0.0449016
[Epoch 27; Iter   158/ 1097] train: loss: 0.1225197
[Epoch 27; Iter   188/ 1097] train: loss: 0.0380088
[Epoch 27; Iter   218/ 1097] train: loss: 0.0409701
[Epoch 27; Iter   248/ 1097] train: loss: 0.0689968
[Epoch 27; Iter   278/ 1097] train: loss: 0.0730409
[Epoch 27; Iter   308/ 1097] train: loss: 0.0336521
[Epoch 27; Iter   338/ 1097] train: loss: 0.0765978
[Epoch 27; Iter   368/ 1097] train: loss: 0.1467565
[Epoch 27; Iter   398/ 1097] train: loss: 0.0735995
[Epoch 27; Iter   428/ 1097] train: loss: 0.0134639
[Epoch 27; Iter   458/ 1097] train: loss: 0.0256638
[Epoch 27; Iter   488/ 1097] train: loss: 0.1010309
[Epoch 27; Iter   518/ 1097] train: loss: 0.2129544
[Epoch 27; Iter   548/ 1097] train: loss: 0.1573289
[Epoch 27; Iter   578/ 1097] train: loss: 0.1520851
[Epoch 27; Iter   608/ 1097] train: loss: 0.0191075
[Epoch 27; Iter   638/ 1097] train: loss: 0.0224291
[Epoch 27; Iter   668/ 1097] train: loss: 0.0171843
[Epoch 27; Iter   698/ 1097] train: loss: 0.0244707
[Epoch 27; Iter   728/ 1097] train: loss: 0.0373070
[Epoch 27; Iter   758/ 1097] train: loss: 0.0121202
[Epoch 27; Iter   788/ 1097] train: loss: 0.1521563
[Epoch 27; Iter   818/ 1097] train: loss: 0.0403346
[Epoch 27; Iter   848/ 1097] train: loss: 0.0118208
[Epoch 27; Iter   878/ 1097] train: loss: 0.0263669
[Epoch 27; Iter   908/ 1097] train: loss: 0.1064813
[Epoch 27; Iter   938/ 1097] train: loss: 0.0421312
[Epoch 27; Iter   968/ 1097] train: loss: 0.1812013
[Epoch 27; Iter   998/ 1097] train: loss: 0.0926920
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1523992
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0363743
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0142242
[Epoch 27] ogbg-molhiv: 0.774177 val loss: 0.397629
[Epoch 27] ogbg-molhiv: 0.754538 test loss: 0.287439
[Epoch 28; Iter    21/ 1097] train: loss: 0.1527232
[Epoch 28; Iter    51/ 1097] train: loss: 0.1219814
[Epoch 28; Iter    81/ 1097] train: loss: 0.0415800
[Epoch 28; Iter   111/ 1097] train: loss: 0.0561322
[Epoch 28; Iter   141/ 1097] train: loss: 0.0208355
[Epoch 28; Iter   171/ 1097] train: loss: 0.0609946
[Epoch 28; Iter   201/ 1097] train: loss: 0.0366136
[Epoch 28; Iter   231/ 1097] train: loss: 0.0240381
[Epoch 28; Iter   261/ 1097] train: loss: 0.0090745
[Epoch 28; Iter   291/ 1097] train: loss: 0.1333352
[Epoch 28; Iter   321/ 1097] train: loss: 0.0517422
[Epoch 28; Iter   351/ 1097] train: loss: 0.0862832
[Epoch 28; Iter   381/ 1097] train: loss: 0.0302283
[Epoch 28; Iter   411/ 1097] train: loss: 0.0550071
[Epoch 24; Iter   359/ 1097] train: loss: 0.0345890
[Epoch 24; Iter   389/ 1097] train: loss: 0.0537417
[Epoch 24; Iter   419/ 1097] train: loss: 0.2392333
[Epoch 24; Iter   449/ 1097] train: loss: 0.0474281
[Epoch 24; Iter   479/ 1097] train: loss: 0.1064681
[Epoch 24; Iter   509/ 1097] train: loss: 0.1411708
[Epoch 24; Iter   539/ 1097] train: loss: 0.0240145
[Epoch 24; Iter   569/ 1097] train: loss: 0.1814860
[Epoch 24; Iter   599/ 1097] train: loss: 0.0309318
[Epoch 24; Iter   629/ 1097] train: loss: 0.0775810
[Epoch 24; Iter   659/ 1097] train: loss: 0.0236822
[Epoch 24; Iter   689/ 1097] train: loss: 0.0134822
[Epoch 24; Iter   719/ 1097] train: loss: 0.0332009
[Epoch 24; Iter   749/ 1097] train: loss: 0.1348560
[Epoch 24; Iter   779/ 1097] train: loss: 0.0186698
[Epoch 24; Iter   809/ 1097] train: loss: 0.1065094
[Epoch 24; Iter   839/ 1097] train: loss: 0.0457373
[Epoch 24; Iter   869/ 1097] train: loss: 0.0857877
[Epoch 24; Iter   899/ 1097] train: loss: 0.1132377
[Epoch 24; Iter   929/ 1097] train: loss: 0.2015867
[Epoch 24; Iter   959/ 1097] train: loss: 0.2820309
[Epoch 24; Iter   989/ 1097] train: loss: 0.0293158
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2764630
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1961485
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2501580
[Epoch 24] ogbg-molhiv: 0.714531 val loss: 0.167016
[Epoch 24] ogbg-molhiv: 0.702136 test loss: 0.168874
[Epoch 25; Iter    12/ 1097] train: loss: 0.1135518
[Epoch 25; Iter    42/ 1097] train: loss: 0.0423315
[Epoch 25; Iter    72/ 1097] train: loss: 0.0443146
[Epoch 25; Iter   102/ 1097] train: loss: 0.2434086
[Epoch 25; Iter   132/ 1097] train: loss: 0.1476808
[Epoch 25; Iter   162/ 1097] train: loss: 0.0354621
[Epoch 25; Iter   192/ 1097] train: loss: 0.0287732
[Epoch 25; Iter   222/ 1097] train: loss: 0.0663893
[Epoch 25; Iter   252/ 1097] train: loss: 0.0184330
[Epoch 25; Iter   282/ 1097] train: loss: 0.0568135
[Epoch 25; Iter   312/ 1097] train: loss: 0.0680259
[Epoch 25; Iter   342/ 1097] train: loss: 0.0215445
[Epoch 25; Iter   372/ 1097] train: loss: 0.0239249
[Epoch 25; Iter   402/ 1097] train: loss: 0.0244610
[Epoch 25; Iter   432/ 1097] train: loss: 0.0542017
[Epoch 25; Iter   462/ 1097] train: loss: 0.1270093
[Epoch 25; Iter   492/ 1097] train: loss: 0.0933141
[Epoch 25; Iter   522/ 1097] train: loss: 0.3224641
[Epoch 25; Iter   552/ 1097] train: loss: 0.1125551
[Epoch 25; Iter   582/ 1097] train: loss: 0.0624933
[Epoch 25; Iter   612/ 1097] train: loss: 0.0243441
[Epoch 25; Iter   642/ 1097] train: loss: 0.0174889
[Epoch 25; Iter   672/ 1097] train: loss: 0.0343571
[Epoch 25; Iter   702/ 1097] train: loss: 0.0759115
[Epoch 25; Iter   732/ 1097] train: loss: 0.0809247
[Epoch 25; Iter   762/ 1097] train: loss: 0.0791173
[Epoch 25; Iter   792/ 1097] train: loss: 0.0565379
[Epoch 25; Iter   822/ 1097] train: loss: 0.0238584
[Epoch 25; Iter   852/ 1097] train: loss: 0.0106762
[Epoch 25; Iter   882/ 1097] train: loss: 0.0466847
[Epoch 25; Iter   912/ 1097] train: loss: 0.0111367
[Epoch 25; Iter   942/ 1097] train: loss: 0.0866969
[Epoch 25; Iter   972/ 1097] train: loss: 0.0598889
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0697666
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0258076
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0289497
[Epoch 25; Iter  1092/ 1097] train: loss: 0.3384262
[Epoch 25] ogbg-molhiv: 0.735759 val loss: 0.121576
[Epoch 25] ogbg-molhiv: 0.751274 test loss: 0.153705
[Epoch 26; Iter    25/ 1097] train: loss: 0.0703936
[Epoch 26; Iter    55/ 1097] train: loss: 0.0123168
[Epoch 26; Iter    85/ 1097] train: loss: 0.0226551
[Epoch 26; Iter   115/ 1097] train: loss: 0.0480245
[Epoch 26; Iter   145/ 1097] train: loss: 0.2959261
[Epoch 26; Iter   175/ 1097] train: loss: 0.0388037
[Epoch 26; Iter   205/ 1097] train: loss: 0.3502905
[Epoch 26; Iter   235/ 1097] train: loss: 0.0633121
[Epoch 26; Iter   265/ 1097] train: loss: 0.0849547
[Epoch 26; Iter   295/ 1097] train: loss: 0.0523261
[Epoch 26; Iter   325/ 1097] train: loss: 0.0463745
[Epoch 26; Iter   355/ 1097] train: loss: 0.0185641
[Epoch 26; Iter   385/ 1097] train: loss: 0.0189185
[Epoch 26; Iter   415/ 1097] train: loss: 0.0181333
[Epoch 26; Iter   445/ 1097] train: loss: 0.0273831
[Epoch 26; Iter   475/ 1097] train: loss: 0.0254549
[Epoch 26; Iter   505/ 1097] train: loss: 0.0710579
[Epoch 26; Iter   535/ 1097] train: loss: 0.0258297
[Epoch 26; Iter   565/ 1097] train: loss: 0.2075762
[Epoch 26; Iter   595/ 1097] train: loss: 0.0370059
[Epoch 26; Iter   625/ 1097] train: loss: 0.0517120
[Epoch 26; Iter   655/ 1097] train: loss: 0.0895614
[Epoch 26; Iter   685/ 1097] train: loss: 0.0088738
[Epoch 26; Iter   715/ 1097] train: loss: 0.1477544
[Epoch 26; Iter   745/ 1097] train: loss: 0.0132355
[Epoch 26; Iter   775/ 1097] train: loss: 0.1524406
[Epoch 26; Iter   805/ 1097] train: loss: 0.0364766
[Epoch 26; Iter   835/ 1097] train: loss: 0.1707230
[Epoch 26; Iter   865/ 1097] train: loss: 0.0338440
[Epoch 26; Iter   895/ 1097] train: loss: 0.0180389
[Epoch 26; Iter   925/ 1097] train: loss: 0.2640837
[Epoch 26; Iter   955/ 1097] train: loss: 0.0234673
[Epoch 26; Iter   985/ 1097] train: loss: 0.0207659
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0376201
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0148311
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1208642
[Epoch 26] ogbg-molhiv: 0.703165 val loss: 0.118857
[Epoch 26] ogbg-molhiv: 0.703075 test loss: 0.300629
[Epoch 27; Iter     8/ 1097] train: loss: 0.0183569
[Epoch 27; Iter    38/ 1097] train: loss: 0.0435773
[Epoch 27; Iter    68/ 1097] train: loss: 0.3241957
[Epoch 27; Iter    98/ 1097] train: loss: 0.0111800
[Epoch 27; Iter   128/ 1097] train: loss: 0.0388923
[Epoch 27; Iter   158/ 1097] train: loss: 0.0762465
[Epoch 27; Iter   188/ 1097] train: loss: 0.0259180
[Epoch 27; Iter   218/ 1097] train: loss: 0.0199927
[Epoch 27; Iter   248/ 1097] train: loss: 0.0237739
[Epoch 27; Iter   278/ 1097] train: loss: 0.0323190
[Epoch 27; Iter   308/ 1097] train: loss: 0.0920487
[Epoch 27; Iter   338/ 1097] train: loss: 0.1040708
[Epoch 27; Iter   368/ 1097] train: loss: 0.0887070
[Epoch 27; Iter   398/ 1097] train: loss: 0.0148456
[Epoch 27; Iter   428/ 1097] train: loss: 0.0446879
[Epoch 27; Iter   458/ 1097] train: loss: 0.0162071
[Epoch 27; Iter   488/ 1097] train: loss: 0.0348014
[Epoch 27; Iter   518/ 1097] train: loss: 0.1698439
[Epoch 27; Iter   548/ 1097] train: loss: 0.0178477
[Epoch 27; Iter   578/ 1097] train: loss: 0.0420116
[Epoch 27; Iter   608/ 1097] train: loss: 0.0721994
[Epoch 27; Iter   638/ 1097] train: loss: 0.2611238
[Epoch 27; Iter   668/ 1097] train: loss: 0.1364424
[Epoch 27; Iter   698/ 1097] train: loss: 0.0340924
[Epoch 27; Iter   728/ 1097] train: loss: 0.0183897
[Epoch 27; Iter   758/ 1097] train: loss: 0.0211549
[Epoch 27; Iter   788/ 1097] train: loss: 0.0317272
[Epoch 27; Iter   818/ 1097] train: loss: 0.0106185
[Epoch 27; Iter   848/ 1097] train: loss: 0.0269756
[Epoch 27; Iter   878/ 1097] train: loss: 0.3199056
[Epoch 27; Iter   908/ 1097] train: loss: 0.1310001
[Epoch 27; Iter   938/ 1097] train: loss: 0.0947327
[Epoch 27; Iter   968/ 1097] train: loss: 0.0731611
[Epoch 27; Iter   998/ 1097] train: loss: 0.0329701
[Epoch 27; Iter  1028/ 1097] train: loss: 0.2957917
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0840539
[Epoch 27; Iter  1088/ 1097] train: loss: 0.2452347
[Epoch 27] ogbg-molhiv: 0.694849 val loss: 0.145850
[Epoch 27] ogbg-molhiv: 0.724680 test loss: 0.168182
[Epoch 28; Iter    21/ 1097] train: loss: 0.1552746
[Epoch 28; Iter    51/ 1097] train: loss: 0.1139522
[Epoch 28; Iter    81/ 1097] train: loss: 0.1318445
[Epoch 28; Iter   111/ 1097] train: loss: 0.1680706
[Epoch 28; Iter   141/ 1097] train: loss: 0.0156680
[Epoch 28; Iter   171/ 1097] train: loss: 0.0080945
[Epoch 28; Iter   201/ 1097] train: loss: 0.0281531
[Epoch 28; Iter   231/ 1097] train: loss: 0.0196841
[Epoch 28; Iter   261/ 1097] train: loss: 0.0805389
[Epoch 28; Iter   291/ 1097] train: loss: 0.0157263
[Epoch 28; Iter   321/ 1097] train: loss: 0.0104330
[Epoch 28; Iter   351/ 1097] train: loss: 0.0272790
[Epoch 28; Iter   381/ 1097] train: loss: 0.0118134
[Epoch 28; Iter   411/ 1097] train: loss: 0.2593742
[Epoch 24; Iter   359/ 1097] train: loss: 0.0492159
[Epoch 24; Iter   389/ 1097] train: loss: 0.0146697
[Epoch 24; Iter   419/ 1097] train: loss: 0.3090803
[Epoch 24; Iter   449/ 1097] train: loss: 0.0557365
[Epoch 24; Iter   479/ 1097] train: loss: 0.0548352
[Epoch 24; Iter   509/ 1097] train: loss: 0.0550530
[Epoch 24; Iter   539/ 1097] train: loss: 0.0368887
[Epoch 24; Iter   569/ 1097] train: loss: 0.1764663
[Epoch 24; Iter   599/ 1097] train: loss: 0.0527710
[Epoch 24; Iter   629/ 1097] train: loss: 0.0398218
[Epoch 24; Iter   659/ 1097] train: loss: 0.0374186
[Epoch 24; Iter   689/ 1097] train: loss: 0.0072887
[Epoch 24; Iter   719/ 1097] train: loss: 0.1448952
[Epoch 24; Iter   749/ 1097] train: loss: 0.0241546
[Epoch 24; Iter   779/ 1097] train: loss: 0.0524619
[Epoch 24; Iter   809/ 1097] train: loss: 0.0728527
[Epoch 24; Iter   839/ 1097] train: loss: 0.0792083
[Epoch 24; Iter   869/ 1097] train: loss: 0.0915218
[Epoch 24; Iter   899/ 1097] train: loss: 0.2844937
[Epoch 24; Iter   929/ 1097] train: loss: 0.0462151
[Epoch 24; Iter   959/ 1097] train: loss: 0.1385621
[Epoch 24; Iter   989/ 1097] train: loss: 0.0205804
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2380193
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1279862
[Epoch 24; Iter  1079/ 1097] train: loss: 0.3587836
[Epoch 24] ogbg-molhiv: 0.762707 val loss: 0.108063
[Epoch 24] ogbg-molhiv: 0.724821 test loss: 0.176745
[Epoch 25; Iter    12/ 1097] train: loss: 0.2589449
[Epoch 25; Iter    42/ 1097] train: loss: 0.0421384
[Epoch 25; Iter    72/ 1097] train: loss: 0.0207129
[Epoch 25; Iter   102/ 1097] train: loss: 0.3899565
[Epoch 25; Iter   132/ 1097] train: loss: 0.3202308
[Epoch 25; Iter   162/ 1097] train: loss: 0.0180048
[Epoch 25; Iter   192/ 1097] train: loss: 0.0189033
[Epoch 25; Iter   222/ 1097] train: loss: 0.0823667
[Epoch 25; Iter   252/ 1097] train: loss: 0.0568908
[Epoch 25; Iter   282/ 1097] train: loss: 0.0935385
[Epoch 25; Iter   312/ 1097] train: loss: 0.0338122
[Epoch 25; Iter   342/ 1097] train: loss: 0.0735662
[Epoch 25; Iter   372/ 1097] train: loss: 0.0345912
[Epoch 25; Iter   402/ 1097] train: loss: 0.0233758
[Epoch 25; Iter   432/ 1097] train: loss: 0.0364220
[Epoch 25; Iter   462/ 1097] train: loss: 0.0907544
[Epoch 25; Iter   492/ 1097] train: loss: 0.0650770
[Epoch 25; Iter   522/ 1097] train: loss: 0.3277328
[Epoch 25; Iter   552/ 1097] train: loss: 0.1750288
[Epoch 25; Iter   582/ 1097] train: loss: 0.1145765
[Epoch 25; Iter   612/ 1097] train: loss: 0.0221610
[Epoch 25; Iter   642/ 1097] train: loss: 0.0200205
[Epoch 25; Iter   672/ 1097] train: loss: 0.0239034
[Epoch 25; Iter   702/ 1097] train: loss: 0.0184036
[Epoch 25; Iter   732/ 1097] train: loss: 0.0836368
[Epoch 25; Iter   762/ 1097] train: loss: 0.0328809
[Epoch 25; Iter   792/ 1097] train: loss: 0.0244574
[Epoch 25; Iter   822/ 1097] train: loss: 0.0319469
[Epoch 25; Iter   852/ 1097] train: loss: 0.0179282
[Epoch 25; Iter   882/ 1097] train: loss: 0.0312272
[Epoch 25; Iter   912/ 1097] train: loss: 0.0211573
[Epoch 25; Iter   942/ 1097] train: loss: 0.1906275
[Epoch 25; Iter   972/ 1097] train: loss: 0.1379173
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0500555
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0143597
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0360259
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1741314
[Epoch 25] ogbg-molhiv: 0.794398 val loss: 0.134812
[Epoch 25] ogbg-molhiv: 0.767000 test loss: 0.148246
[Epoch 26; Iter    25/ 1097] train: loss: 0.0833850
[Epoch 26; Iter    55/ 1097] train: loss: 0.0198677
[Epoch 26; Iter    85/ 1097] train: loss: 0.0543563
[Epoch 26; Iter   115/ 1097] train: loss: 0.0417479
[Epoch 26; Iter   145/ 1097] train: loss: 0.1514589
[Epoch 26; Iter   175/ 1097] train: loss: 0.0728418
[Epoch 26; Iter   205/ 1097] train: loss: 0.2430453
[Epoch 26; Iter   235/ 1097] train: loss: 0.0946444
[Epoch 26; Iter   265/ 1097] train: loss: 0.1180935
[Epoch 26; Iter   295/ 1097] train: loss: 0.0702874
[Epoch 26; Iter   325/ 1097] train: loss: 0.0238027
[Epoch 26; Iter   355/ 1097] train: loss: 0.0228947
[Epoch 26; Iter   385/ 1097] train: loss: 0.0274313
[Epoch 26; Iter   415/ 1097] train: loss: 0.0180490
[Epoch 26; Iter   445/ 1097] train: loss: 0.0341470
[Epoch 26; Iter   475/ 1097] train: loss: 0.0312126
[Epoch 26; Iter   505/ 1097] train: loss: 0.0556966
[Epoch 26; Iter   535/ 1097] train: loss: 0.1128127
[Epoch 26; Iter   565/ 1097] train: loss: 0.3130617
[Epoch 26; Iter   595/ 1097] train: loss: 0.0340409
[Epoch 26; Iter   625/ 1097] train: loss: 0.0178025
[Epoch 26; Iter   655/ 1097] train: loss: 0.0475988
[Epoch 26; Iter   685/ 1097] train: loss: 0.0947455
[Epoch 26; Iter   715/ 1097] train: loss: 0.0818079
[Epoch 26; Iter   745/ 1097] train: loss: 0.0889628
[Epoch 26; Iter   775/ 1097] train: loss: 0.1360566
[Epoch 26; Iter   805/ 1097] train: loss: 0.0697926
[Epoch 26; Iter   835/ 1097] train: loss: 0.1699861
[Epoch 26; Iter   865/ 1097] train: loss: 0.0415439
[Epoch 26; Iter   895/ 1097] train: loss: 0.0384637
[Epoch 26; Iter   925/ 1097] train: loss: 0.1876329
[Epoch 26; Iter   955/ 1097] train: loss: 0.0221387
[Epoch 26; Iter   985/ 1097] train: loss: 0.0155123
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0624149
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0184780
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2078917
[Epoch 26] ogbg-molhiv: 0.786434 val loss: 0.126031
[Epoch 26] ogbg-molhiv: 0.727434 test loss: 0.181618
[Epoch 27; Iter     8/ 1097] train: loss: 0.0139453
[Epoch 27; Iter    38/ 1097] train: loss: 0.0612172
[Epoch 27; Iter    68/ 1097] train: loss: 0.1226574
[Epoch 27; Iter    98/ 1097] train: loss: 0.0351734
[Epoch 27; Iter   128/ 1097] train: loss: 0.0393373
[Epoch 27; Iter   158/ 1097] train: loss: 0.0108301
[Epoch 27; Iter   188/ 1097] train: loss: 0.0264322
[Epoch 27; Iter   218/ 1097] train: loss: 0.0660096
[Epoch 27; Iter   248/ 1097] train: loss: 0.0149644
[Epoch 27; Iter   278/ 1097] train: loss: 0.0114442
[Epoch 27; Iter   308/ 1097] train: loss: 0.0574343
[Epoch 27; Iter   338/ 1097] train: loss: 0.0667259
[Epoch 27; Iter   368/ 1097] train: loss: 0.1686570
[Epoch 27; Iter   398/ 1097] train: loss: 0.0164848
[Epoch 27; Iter   428/ 1097] train: loss: 0.0200433
[Epoch 27; Iter   458/ 1097] train: loss: 0.0114754
[Epoch 27; Iter   488/ 1097] train: loss: 0.0370386
[Epoch 27; Iter   518/ 1097] train: loss: 0.1198706
[Epoch 27; Iter   548/ 1097] train: loss: 0.0939941
[Epoch 27; Iter   578/ 1097] train: loss: 0.0467549
[Epoch 27; Iter   608/ 1097] train: loss: 0.0624778
[Epoch 27; Iter   638/ 1097] train: loss: 0.1584511
[Epoch 27; Iter   668/ 1097] train: loss: 0.2253661
[Epoch 27; Iter   698/ 1097] train: loss: 0.0488061
[Epoch 27; Iter   728/ 1097] train: loss: 0.0383441
[Epoch 27; Iter   758/ 1097] train: loss: 0.0348134
[Epoch 27; Iter   788/ 1097] train: loss: 0.0520881
[Epoch 27; Iter   818/ 1097] train: loss: 0.0258709
[Epoch 27; Iter   848/ 1097] train: loss: 0.0357310
[Epoch 27; Iter   878/ 1097] train: loss: 0.2748835
[Epoch 27; Iter   908/ 1097] train: loss: 0.1038085
[Epoch 27; Iter   938/ 1097] train: loss: 0.0730733
[Epoch 27; Iter   968/ 1097] train: loss: 0.0340026
[Epoch 27; Iter   998/ 1097] train: loss: 0.0242612
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1883649
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0460997
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1723748
[Epoch 27] ogbg-molhiv: 0.807233 val loss: 0.079193
[Epoch 27] ogbg-molhiv: 0.769640 test loss: 0.132253
[Epoch 28; Iter    21/ 1097] train: loss: 0.0373609
[Epoch 28; Iter    51/ 1097] train: loss: 0.0191924
[Epoch 28; Iter    81/ 1097] train: loss: 0.0143496
[Epoch 28; Iter   111/ 1097] train: loss: 0.0915302
[Epoch 28; Iter   141/ 1097] train: loss: 0.0442606
[Epoch 28; Iter   171/ 1097] train: loss: 0.0570003
[Epoch 28; Iter   201/ 1097] train: loss: 0.0102461
[Epoch 28; Iter   231/ 1097] train: loss: 0.0230082
[Epoch 28; Iter   261/ 1097] train: loss: 0.0362527
[Epoch 28; Iter   291/ 1097] train: loss: 0.0476914
[Epoch 28; Iter   321/ 1097] train: loss: 0.0270765
[Epoch 28; Iter   351/ 1097] train: loss: 0.0071714
[Epoch 28; Iter   381/ 1097] train: loss: 0.0291776
[Epoch 28; Iter   411/ 1097] train: loss: 0.1495233
[Epoch 24; Iter   359/ 1097] train: loss: 0.2864495
[Epoch 24; Iter   389/ 1097] train: loss: 0.0181599
[Epoch 24; Iter   419/ 1097] train: loss: 0.0180497
[Epoch 24; Iter   449/ 1097] train: loss: 0.0296502
[Epoch 24; Iter   479/ 1097] train: loss: 0.0663115
[Epoch 24; Iter   509/ 1097] train: loss: 0.1987914
[Epoch 24; Iter   539/ 1097] train: loss: 0.1214673
[Epoch 24; Iter   569/ 1097] train: loss: 0.0921690
[Epoch 24; Iter   599/ 1097] train: loss: 0.0852180
[Epoch 24; Iter   629/ 1097] train: loss: 0.0717198
[Epoch 24; Iter   659/ 1097] train: loss: 0.1019437
[Epoch 24; Iter   689/ 1097] train: loss: 0.0942650
[Epoch 24; Iter   719/ 1097] train: loss: 0.0582360
[Epoch 24; Iter   749/ 1097] train: loss: 0.0149150
[Epoch 24; Iter   779/ 1097] train: loss: 0.2183331
[Epoch 24; Iter   809/ 1097] train: loss: 0.0848105
[Epoch 24; Iter   839/ 1097] train: loss: 0.0552774
[Epoch 24; Iter   869/ 1097] train: loss: 0.0619621
[Epoch 24; Iter   899/ 1097] train: loss: 0.0426047
[Epoch 24; Iter   929/ 1097] train: loss: 0.0567767
[Epoch 24; Iter   959/ 1097] train: loss: 0.0131716
[Epoch 24; Iter   989/ 1097] train: loss: 0.0841102
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3775261
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0269410
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0364824
[Epoch 24] ogbg-molhiv: 0.731264 val loss: 5.605679
[Epoch 24] ogbg-molhiv: 0.703919 test loss: 3.322900
[Epoch 25; Iter    12/ 1097] train: loss: 0.0334677
[Epoch 25; Iter    42/ 1097] train: loss: 0.1428874
[Epoch 25; Iter    72/ 1097] train: loss: 0.1772482
[Epoch 25; Iter   102/ 1097] train: loss: 0.0422385
[Epoch 25; Iter   132/ 1097] train: loss: 0.0580514
[Epoch 25; Iter   162/ 1097] train: loss: 0.0290747
[Epoch 25; Iter   192/ 1097] train: loss: 0.0099017
[Epoch 25; Iter   222/ 1097] train: loss: 0.1050274
[Epoch 25; Iter   252/ 1097] train: loss: 0.0097279
[Epoch 25; Iter   282/ 1097] train: loss: 0.0299950
[Epoch 25; Iter   312/ 1097] train: loss: 0.0346470
[Epoch 25; Iter   342/ 1097] train: loss: 0.0563978
[Epoch 25; Iter   372/ 1097] train: loss: 0.0156861
[Epoch 25; Iter   402/ 1097] train: loss: 0.0209446
[Epoch 25; Iter   432/ 1097] train: loss: 0.1562761
[Epoch 25; Iter   462/ 1097] train: loss: 0.1292843
[Epoch 25; Iter   492/ 1097] train: loss: 0.0667944
[Epoch 25; Iter   522/ 1097] train: loss: 0.0314320
[Epoch 25; Iter   552/ 1097] train: loss: 0.2545423
[Epoch 25; Iter   582/ 1097] train: loss: 0.1678255
[Epoch 25; Iter   612/ 1097] train: loss: 0.0188521
[Epoch 25; Iter   642/ 1097] train: loss: 0.3780055
[Epoch 25; Iter   672/ 1097] train: loss: 0.0579596
[Epoch 25; Iter   702/ 1097] train: loss: 0.1422524
[Epoch 25; Iter   732/ 1097] train: loss: 0.1489885
[Epoch 25; Iter   762/ 1097] train: loss: 0.1003425
[Epoch 25; Iter   792/ 1097] train: loss: 0.1398415
[Epoch 25; Iter   822/ 1097] train: loss: 0.0318975
[Epoch 25; Iter   852/ 1097] train: loss: 0.1771872
[Epoch 25; Iter   882/ 1097] train: loss: 0.0383307
[Epoch 25; Iter   912/ 1097] train: loss: 0.0427956
[Epoch 25; Iter   942/ 1097] train: loss: 0.2787941
[Epoch 25; Iter   972/ 1097] train: loss: 0.1305371
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0814550
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0593202
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1356544
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0138157
[Epoch 25] ogbg-molhiv: 0.730379 val loss: 0.103671
[Epoch 25] ogbg-molhiv: 0.692816 test loss: 0.196233
[Epoch 26; Iter    25/ 1097] train: loss: 0.0912878
[Epoch 26; Iter    55/ 1097] train: loss: 0.0239375
[Epoch 26; Iter    85/ 1097] train: loss: 0.2569779
[Epoch 26; Iter   115/ 1097] train: loss: 0.0253577
[Epoch 26; Iter   145/ 1097] train: loss: 0.0312837
[Epoch 26; Iter   175/ 1097] train: loss: 0.0589344
[Epoch 26; Iter   205/ 1097] train: loss: 0.0167577
[Epoch 26; Iter   235/ 1097] train: loss: 0.0275682
[Epoch 26; Iter   265/ 1097] train: loss: 0.0630102
[Epoch 26; Iter   295/ 1097] train: loss: 0.0614978
[Epoch 26; Iter   325/ 1097] train: loss: 0.0504092
[Epoch 26; Iter   355/ 1097] train: loss: 0.0967114
[Epoch 26; Iter   385/ 1097] train: loss: 0.0650975
[Epoch 26; Iter   415/ 1097] train: loss: 0.0275999
[Epoch 26; Iter   445/ 1097] train: loss: 0.0189972
[Epoch 26; Iter   475/ 1097] train: loss: 0.0171439
[Epoch 26; Iter   505/ 1097] train: loss: 0.1047182
[Epoch 26; Iter   535/ 1097] train: loss: 0.0337363
[Epoch 26; Iter   565/ 1097] train: loss: 0.1917464
[Epoch 26; Iter   595/ 1097] train: loss: 0.0170472
[Epoch 26; Iter   625/ 1097] train: loss: 0.1929983
[Epoch 26; Iter   655/ 1097] train: loss: 0.1551031
[Epoch 26; Iter   685/ 1097] train: loss: 0.0548423
[Epoch 26; Iter   715/ 1097] train: loss: 0.0364824
[Epoch 26; Iter   745/ 1097] train: loss: 0.0412557
[Epoch 26; Iter   775/ 1097] train: loss: 0.2046323
[Epoch 26; Iter   805/ 1097] train: loss: 0.0974190
[Epoch 26; Iter   835/ 1097] train: loss: 0.0142221
[Epoch 26; Iter   865/ 1097] train: loss: 0.2862691
[Epoch 26; Iter   895/ 1097] train: loss: 0.0170387
[Epoch 26; Iter   925/ 1097] train: loss: 0.1057811
[Epoch 26; Iter   955/ 1097] train: loss: 0.0207266
[Epoch 26; Iter   985/ 1097] train: loss: 0.0364662
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1401847
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0285624
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1233002
[Epoch 26] ogbg-molhiv: 0.731534 val loss: 0.101576
[Epoch 26] ogbg-molhiv: 0.716422 test loss: 0.155874
[Epoch 27; Iter     8/ 1097] train: loss: 0.0297771
[Epoch 27; Iter    38/ 1097] train: loss: 0.1454754
[Epoch 27; Iter    68/ 1097] train: loss: 0.0246021
[Epoch 27; Iter    98/ 1097] train: loss: 0.0375884
[Epoch 27; Iter   128/ 1097] train: loss: 0.0217945
[Epoch 27; Iter   158/ 1097] train: loss: 0.0456786
[Epoch 27; Iter   188/ 1097] train: loss: 0.0170391
[Epoch 27; Iter   218/ 1097] train: loss: 0.0939108
[Epoch 27; Iter   248/ 1097] train: loss: 0.0963852
[Epoch 27; Iter   278/ 1097] train: loss: 0.0817048
[Epoch 27; Iter   308/ 1097] train: loss: 0.0256687
[Epoch 27; Iter   338/ 1097] train: loss: 0.0207985
[Epoch 27; Iter   368/ 1097] train: loss: 0.1325480
[Epoch 27; Iter   398/ 1097] train: loss: 0.1735025
[Epoch 27; Iter   428/ 1097] train: loss: 0.0130904
[Epoch 27; Iter   458/ 1097] train: loss: 0.0059060
[Epoch 27; Iter   488/ 1097] train: loss: 0.0622077
[Epoch 27; Iter   518/ 1097] train: loss: 0.1707876
[Epoch 27; Iter   548/ 1097] train: loss: 0.0994809
[Epoch 27; Iter   578/ 1097] train: loss: 0.1233990
[Epoch 27; Iter   608/ 1097] train: loss: 0.0178803
[Epoch 27; Iter   638/ 1097] train: loss: 0.0191227
[Epoch 27; Iter   668/ 1097] train: loss: 0.0857965
[Epoch 27; Iter   698/ 1097] train: loss: 0.1966283
[Epoch 27; Iter   728/ 1097] train: loss: 0.0522772
[Epoch 27; Iter   758/ 1097] train: loss: 0.0243668
[Epoch 27; Iter   788/ 1097] train: loss: 0.1076644
[Epoch 27; Iter   818/ 1097] train: loss: 0.0733273
[Epoch 27; Iter   848/ 1097] train: loss: 0.0185644
[Epoch 27; Iter   878/ 1097] train: loss: 0.0566982
[Epoch 27; Iter   908/ 1097] train: loss: 0.2294988
[Epoch 27; Iter   938/ 1097] train: loss: 0.0753743
[Epoch 27; Iter   968/ 1097] train: loss: 0.1611068
[Epoch 27; Iter   998/ 1097] train: loss: 0.0781427
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0793860
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0487166
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0390562
[Epoch 27] ogbg-molhiv: 0.774961 val loss: 0.116750
[Epoch 27] ogbg-molhiv: 0.721066 test loss: 0.190640
[Epoch 28; Iter    21/ 1097] train: loss: 0.1162777
[Epoch 28; Iter    51/ 1097] train: loss: 0.0685409
[Epoch 28; Iter    81/ 1097] train: loss: 0.0174055
[Epoch 28; Iter   111/ 1097] train: loss: 0.0305402
[Epoch 28; Iter   141/ 1097] train: loss: 0.0350793
[Epoch 28; Iter   171/ 1097] train: loss: 0.0773435
[Epoch 28; Iter   201/ 1097] train: loss: 0.0292351
[Epoch 28; Iter   231/ 1097] train: loss: 0.0141270
[Epoch 28; Iter   261/ 1097] train: loss: 0.0051820
[Epoch 28; Iter   291/ 1097] train: loss: 0.0880959
[Epoch 28; Iter   321/ 1097] train: loss: 0.0130673
[Epoch 28; Iter   351/ 1097] train: loss: 0.2265111
[Epoch 28; Iter   381/ 1097] train: loss: 0.0154155
[Epoch 28; Iter   411/ 1097] train: loss: 0.0910607
[Epoch 24; Iter   359/ 1097] train: loss: 0.1343387
[Epoch 24; Iter   389/ 1097] train: loss: 0.1991492
[Epoch 24; Iter   419/ 1097] train: loss: 0.2204582
[Epoch 24; Iter   449/ 1097] train: loss: 0.0330333
[Epoch 24; Iter   479/ 1097] train: loss: 0.0248507
[Epoch 24; Iter   509/ 1097] train: loss: 0.0286401
[Epoch 24; Iter   539/ 1097] train: loss: 0.0183008
[Epoch 24; Iter   569/ 1097] train: loss: 0.1988848
[Epoch 24; Iter   599/ 1097] train: loss: 0.1478197
[Epoch 24; Iter   629/ 1097] train: loss: 0.0142215
[Epoch 24; Iter   659/ 1097] train: loss: 0.0287547
[Epoch 24; Iter   689/ 1097] train: loss: 0.0075703
[Epoch 24; Iter   719/ 1097] train: loss: 0.0218766
[Epoch 24; Iter   749/ 1097] train: loss: 0.0491971
[Epoch 24; Iter   779/ 1097] train: loss: 0.0947890
[Epoch 24; Iter   809/ 1097] train: loss: 0.0308419
[Epoch 24; Iter   839/ 1097] train: loss: 0.2356485
[Epoch 24; Iter   869/ 1097] train: loss: 0.1335805
[Epoch 24; Iter   899/ 1097] train: loss: 0.1089687
[Epoch 24; Iter   929/ 1097] train: loss: 0.3314334
[Epoch 24; Iter   959/ 1097] train: loss: 0.0315820
[Epoch 24; Iter   989/ 1097] train: loss: 0.0157805
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1255877
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0371466
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0268639
[Epoch 24] ogbg-molhiv: 0.759388 val loss: 0.144412
[Epoch 24] ogbg-molhiv: 0.796798 test loss: 0.151652
[Epoch 25; Iter    12/ 1097] train: loss: 0.0150675
[Epoch 25; Iter    42/ 1097] train: loss: 0.1263291
[Epoch 25; Iter    72/ 1097] train: loss: 0.0183989
[Epoch 25; Iter   102/ 1097] train: loss: 0.0171655
[Epoch 25; Iter   132/ 1097] train: loss: 0.0164461
[Epoch 25; Iter   162/ 1097] train: loss: 0.0492072
[Epoch 25; Iter   192/ 1097] train: loss: 0.0441226
[Epoch 25; Iter   222/ 1097] train: loss: 0.0194369
[Epoch 25; Iter   252/ 1097] train: loss: 0.0764577
[Epoch 25; Iter   282/ 1097] train: loss: 0.1003289
[Epoch 25; Iter   312/ 1097] train: loss: 0.0235536
[Epoch 25; Iter   342/ 1097] train: loss: 0.0555292
[Epoch 25; Iter   372/ 1097] train: loss: 0.1693350
[Epoch 25; Iter   402/ 1097] train: loss: 0.0390404
[Epoch 25; Iter   432/ 1097] train: loss: 0.2465944
[Epoch 25; Iter   462/ 1097] train: loss: 0.0296719
[Epoch 25; Iter   492/ 1097] train: loss: 0.1307019
[Epoch 25; Iter   522/ 1097] train: loss: 0.0135714
[Epoch 25; Iter   552/ 1097] train: loss: 0.1252947
[Epoch 25; Iter   582/ 1097] train: loss: 0.0405208
[Epoch 25; Iter   612/ 1097] train: loss: 0.2467173
[Epoch 25; Iter   642/ 1097] train: loss: 0.1067254
[Epoch 25; Iter   672/ 1097] train: loss: 0.0242878
[Epoch 25; Iter   702/ 1097] train: loss: 0.2145158
[Epoch 25; Iter   732/ 1097] train: loss: 0.0311048
[Epoch 25; Iter   762/ 1097] train: loss: 0.0827562
[Epoch 25; Iter   792/ 1097] train: loss: 0.0225830
[Epoch 25; Iter   822/ 1097] train: loss: 0.0684966
[Epoch 25; Iter   852/ 1097] train: loss: 0.0201953
[Epoch 25; Iter   882/ 1097] train: loss: 0.0926072
[Epoch 25; Iter   912/ 1097] train: loss: 0.2090856
[Epoch 25; Iter   942/ 1097] train: loss: 0.1212003
[Epoch 25; Iter   972/ 1097] train: loss: 0.0856000
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1446115
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0950935
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0226471
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1759589
[Epoch 25] ogbg-molhiv: 0.771360 val loss: 0.327020
[Epoch 25] ogbg-molhiv: 0.765775 test loss: 0.140142
[Epoch 26; Iter    25/ 1097] train: loss: 0.0195068
[Epoch 26; Iter    55/ 1097] train: loss: 0.0552898
[Epoch 26; Iter    85/ 1097] train: loss: 0.1482977
[Epoch 26; Iter   115/ 1097] train: loss: 0.0845415
[Epoch 26; Iter   145/ 1097] train: loss: 0.0968212
[Epoch 26; Iter   175/ 1097] train: loss: 0.0875691
[Epoch 26; Iter   205/ 1097] train: loss: 0.3280583
[Epoch 26; Iter   235/ 1097] train: loss: 0.0580519
[Epoch 26; Iter   265/ 1097] train: loss: 0.0385954
[Epoch 26; Iter   295/ 1097] train: loss: 0.0935961
[Epoch 26; Iter   325/ 1097] train: loss: 0.0299321
[Epoch 26; Iter   355/ 1097] train: loss: 0.0205835
[Epoch 26; Iter   385/ 1097] train: loss: 0.0576569
[Epoch 26; Iter   415/ 1097] train: loss: 0.0351279
[Epoch 26; Iter   445/ 1097] train: loss: 0.0175116
[Epoch 26; Iter   475/ 1097] train: loss: 0.0950966
[Epoch 26; Iter   505/ 1097] train: loss: 0.0381564
[Epoch 26; Iter   535/ 1097] train: loss: 0.0725012
[Epoch 26; Iter   565/ 1097] train: loss: 0.0444830
[Epoch 26; Iter   595/ 1097] train: loss: 0.0504205
[Epoch 26; Iter   625/ 1097] train: loss: 0.0381438
[Epoch 26; Iter   655/ 1097] train: loss: 0.0297795
[Epoch 26; Iter   685/ 1097] train: loss: 0.1305439
[Epoch 26; Iter   715/ 1097] train: loss: 0.0118909
[Epoch 26; Iter   745/ 1097] train: loss: 0.0290380
[Epoch 26; Iter   775/ 1097] train: loss: 0.0116529
[Epoch 26; Iter   805/ 1097] train: loss: 0.0583660
[Epoch 26; Iter   835/ 1097] train: loss: 0.1326554
[Epoch 26; Iter   865/ 1097] train: loss: 0.0841229
[Epoch 26; Iter   895/ 1097] train: loss: 0.0404694
[Epoch 26; Iter   925/ 1097] train: loss: 0.1874070
[Epoch 26; Iter   955/ 1097] train: loss: 0.0110799
[Epoch 26; Iter   985/ 1097] train: loss: 0.1192011
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0318842
[Epoch 26; Iter  1045/ 1097] train: loss: 0.1296218
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0801443
[Epoch 26] ogbg-molhiv: 0.804612 val loss: 0.111026
[Epoch 26] ogbg-molhiv: 0.781164 test loss: 0.147155
[Epoch 27; Iter     8/ 1097] train: loss: 0.0285883
[Epoch 27; Iter    38/ 1097] train: loss: 0.0246733
[Epoch 27; Iter    68/ 1097] train: loss: 0.0348818
[Epoch 27; Iter    98/ 1097] train: loss: 0.1120712
[Epoch 27; Iter   128/ 1097] train: loss: 0.0593254
[Epoch 27; Iter   158/ 1097] train: loss: 0.0291706
[Epoch 27; Iter   188/ 1097] train: loss: 0.0137068
[Epoch 27; Iter   218/ 1097] train: loss: 0.0490709
[Epoch 27; Iter   248/ 1097] train: loss: 0.0885038
[Epoch 27; Iter   278/ 1097] train: loss: 0.0527091
[Epoch 27; Iter   308/ 1097] train: loss: 0.0265102
[Epoch 27; Iter   338/ 1097] train: loss: 0.0158612
[Epoch 27; Iter   368/ 1097] train: loss: 0.1685649
[Epoch 27; Iter   398/ 1097] train: loss: 0.0177841
[Epoch 27; Iter   428/ 1097] train: loss: 0.3060300
[Epoch 27; Iter   458/ 1097] train: loss: 0.0078814
[Epoch 27; Iter   488/ 1097] train: loss: 0.0718161
[Epoch 27; Iter   518/ 1097] train: loss: 0.1516940
[Epoch 27; Iter   548/ 1097] train: loss: 0.0608161
[Epoch 27; Iter   578/ 1097] train: loss: 0.0722415
[Epoch 27; Iter   608/ 1097] train: loss: 0.0957893
[Epoch 27; Iter   638/ 1097] train: loss: 0.0206515
[Epoch 27; Iter   668/ 1097] train: loss: 0.0266605
[Epoch 27; Iter   698/ 1097] train: loss: 0.0254684
[Epoch 27; Iter   728/ 1097] train: loss: 0.2334051
[Epoch 27; Iter   758/ 1097] train: loss: 0.0774161
[Epoch 27; Iter   788/ 1097] train: loss: 0.0142733
[Epoch 27; Iter   818/ 1097] train: loss: 0.0601071
[Epoch 27; Iter   848/ 1097] train: loss: 0.1051351
[Epoch 27; Iter   878/ 1097] train: loss: 0.0725380
[Epoch 27; Iter   908/ 1097] train: loss: 0.0189133
[Epoch 27; Iter   938/ 1097] train: loss: 0.1497322
[Epoch 27; Iter   968/ 1097] train: loss: 0.0190036
[Epoch 27; Iter   998/ 1097] train: loss: 0.0389910
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0250221
[Epoch 27; Iter  1058/ 1097] train: loss: 0.3143296
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0849402
[Epoch 27] ogbg-molhiv: 0.746479 val loss: 0.149084
[Epoch 27] ogbg-molhiv: 0.785763 test loss: 0.146805
[Epoch 28; Iter    21/ 1097] train: loss: 0.0203592
[Epoch 28; Iter    51/ 1097] train: loss: 0.0663861
[Epoch 28; Iter    81/ 1097] train: loss: 0.0082522
[Epoch 28; Iter   111/ 1097] train: loss: 0.0281522
[Epoch 28; Iter   141/ 1097] train: loss: 0.2551273
[Epoch 28; Iter   171/ 1097] train: loss: 0.0533761
[Epoch 28; Iter   201/ 1097] train: loss: 0.0555138
[Epoch 28; Iter   231/ 1097] train: loss: 0.0932227
[Epoch 28; Iter   261/ 1097] train: loss: 0.2157664
[Epoch 28; Iter   291/ 1097] train: loss: 0.0191559
[Epoch 28; Iter   321/ 1097] train: loss: 0.0100693
[Epoch 28; Iter   351/ 1097] train: loss: 0.0120559
[Epoch 28; Iter   381/ 1097] train: loss: 0.0936734
[Epoch 28; Iter   411/ 1097] train: loss: 0.0092786
[Epoch 24; Iter   359/ 1097] train: loss: 0.0682477
[Epoch 24; Iter   389/ 1097] train: loss: 0.0097854
[Epoch 24; Iter   419/ 1097] train: loss: 0.1864497
[Epoch 24; Iter   449/ 1097] train: loss: 0.0330848
[Epoch 24; Iter   479/ 1097] train: loss: 0.1842771
[Epoch 24; Iter   509/ 1097] train: loss: 0.0440745
[Epoch 24; Iter   539/ 1097] train: loss: 0.0110895
[Epoch 24; Iter   569/ 1097] train: loss: 0.1670147
[Epoch 24; Iter   599/ 1097] train: loss: 0.1605815
[Epoch 24; Iter   629/ 1097] train: loss: 0.0105046
[Epoch 24; Iter   659/ 1097] train: loss: 0.0163723
[Epoch 24; Iter   689/ 1097] train: loss: 0.0078015
[Epoch 24; Iter   719/ 1097] train: loss: 0.1131429
[Epoch 24; Iter   749/ 1097] train: loss: 0.0237086
[Epoch 24; Iter   779/ 1097] train: loss: 0.0703662
[Epoch 24; Iter   809/ 1097] train: loss: 0.0815066
[Epoch 24; Iter   839/ 1097] train: loss: 0.0594523
[Epoch 24; Iter   869/ 1097] train: loss: 0.0162821
[Epoch 24; Iter   899/ 1097] train: loss: 0.0832743
[Epoch 24; Iter   929/ 1097] train: loss: 0.0228826
[Epoch 24; Iter   959/ 1097] train: loss: 0.0758648
[Epoch 24; Iter   989/ 1097] train: loss: 0.0079622
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0819999
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1615063
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1232741
[Epoch 24] ogbg-molhiv: 0.662184 val loss: 0.219086
[Epoch 24] ogbg-molhiv: 0.494718 test loss: 0.293624
[Epoch 25; Iter    12/ 1097] train: loss: 0.0641152
[Epoch 25; Iter    42/ 1097] train: loss: 0.0137858
[Epoch 25; Iter    72/ 1097] train: loss: 0.0147368
[Epoch 25; Iter   102/ 1097] train: loss: 0.1035953
[Epoch 25; Iter   132/ 1097] train: loss: 0.2121288
[Epoch 25; Iter   162/ 1097] train: loss: 0.1016592
[Epoch 25; Iter   192/ 1097] train: loss: 0.0244151
[Epoch 25; Iter   222/ 1097] train: loss: 0.1794799
[Epoch 25; Iter   252/ 1097] train: loss: 0.0149208
[Epoch 25; Iter   282/ 1097] train: loss: 0.0804093
[Epoch 25; Iter   312/ 1097] train: loss: 0.0701710
[Epoch 25; Iter   342/ 1097] train: loss: 0.0330381
[Epoch 25; Iter   372/ 1097] train: loss: 0.0120204
[Epoch 25; Iter   402/ 1097] train: loss: 0.0408642
[Epoch 25; Iter   432/ 1097] train: loss: 0.0316169
[Epoch 25; Iter   462/ 1097] train: loss: 0.0998069
[Epoch 25; Iter   492/ 1097] train: loss: 0.0604825
[Epoch 25; Iter   522/ 1097] train: loss: 0.0497793
[Epoch 25; Iter   552/ 1097] train: loss: 0.1396840
[Epoch 25; Iter   582/ 1097] train: loss: 0.0189294
[Epoch 25; Iter   612/ 1097] train: loss: 0.0080085
[Epoch 25; Iter   642/ 1097] train: loss: 0.1692791
[Epoch 25; Iter   672/ 1097] train: loss: 0.0054407
[Epoch 25; Iter   702/ 1097] train: loss: 0.1029483
[Epoch 25; Iter   732/ 1097] train: loss: 0.0762534
[Epoch 25; Iter   762/ 1097] train: loss: 0.1226153
[Epoch 25; Iter   792/ 1097] train: loss: 0.0195651
[Epoch 25; Iter   822/ 1097] train: loss: 0.0162411
[Epoch 25; Iter   852/ 1097] train: loss: 0.0079806
[Epoch 25; Iter   882/ 1097] train: loss: 0.0219932
[Epoch 25; Iter   912/ 1097] train: loss: 0.0096974
[Epoch 25; Iter   942/ 1097] train: loss: 0.1000056
[Epoch 25; Iter   972/ 1097] train: loss: 0.0127106
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0119136
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0436967
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0375956
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1753755
[Epoch 25] ogbg-molhiv: 0.675173 val loss: 0.717546
[Epoch 25] ogbg-molhiv: 0.527104 test loss: 1.000610
[Epoch 26; Iter    25/ 1097] train: loss: 0.0167941
[Epoch 26; Iter    55/ 1097] train: loss: 0.0064722
[Epoch 26; Iter    85/ 1097] train: loss: 0.0116140
[Epoch 26; Iter   115/ 1097] train: loss: 0.0277432
[Epoch 26; Iter   145/ 1097] train: loss: 0.1941019
[Epoch 26; Iter   175/ 1097] train: loss: 0.0138979
[Epoch 26; Iter   205/ 1097] train: loss: 0.1401388
[Epoch 26; Iter   235/ 1097] train: loss: 0.0168331
[Epoch 26; Iter   265/ 1097] train: loss: 0.0131961
[Epoch 26; Iter   295/ 1097] train: loss: 0.1137875
[Epoch 26; Iter   325/ 1097] train: loss: 0.0294564
[Epoch 26; Iter   355/ 1097] train: loss: 0.0265884
[Epoch 26; Iter   385/ 1097] train: loss: 0.0182489
[Epoch 26; Iter   415/ 1097] train: loss: 0.0153239
[Epoch 26; Iter   445/ 1097] train: loss: 0.0082791
[Epoch 26; Iter   475/ 1097] train: loss: 0.0053363
[Epoch 26; Iter   505/ 1097] train: loss: 0.0133276
[Epoch 26; Iter   535/ 1097] train: loss: 0.0423744
[Epoch 26; Iter   565/ 1097] train: loss: 0.0265687
[Epoch 26; Iter   595/ 1097] train: loss: 0.0571203
[Epoch 26; Iter   625/ 1097] train: loss: 0.0098823
[Epoch 26; Iter   655/ 1097] train: loss: 0.0070950
[Epoch 26; Iter   685/ 1097] train: loss: 0.0610980
[Epoch 26; Iter   715/ 1097] train: loss: 0.0758267
[Epoch 26; Iter   745/ 1097] train: loss: 0.0415519
[Epoch 26; Iter   775/ 1097] train: loss: 0.0157284
[Epoch 26; Iter   805/ 1097] train: loss: 0.0349826
[Epoch 26; Iter   835/ 1097] train: loss: 0.1396169
[Epoch 26; Iter   865/ 1097] train: loss: 0.0162064
[Epoch 26; Iter   895/ 1097] train: loss: 0.0393391
[Epoch 26; Iter   925/ 1097] train: loss: 0.0355669
[Epoch 26; Iter   955/ 1097] train: loss: 0.0208861
[Epoch 26; Iter   985/ 1097] train: loss: 0.0262925
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0176442
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0274485
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0841982
[Epoch 26] ogbg-molhiv: 0.623515 val loss: 4.457438
[Epoch 26] ogbg-molhiv: 0.454906 test loss: 6.648118
[Epoch 27; Iter     8/ 1097] train: loss: 0.0292090
[Epoch 27; Iter    38/ 1097] train: loss: 0.0372850
[Epoch 27; Iter    68/ 1097] train: loss: 0.1519433
[Epoch 27; Iter    98/ 1097] train: loss: 0.0146483
[Epoch 27; Iter   128/ 1097] train: loss: 0.0426627
[Epoch 27; Iter   158/ 1097] train: loss: 0.0396812
[Epoch 27; Iter   188/ 1097] train: loss: 0.0262945
[Epoch 27; Iter   218/ 1097] train: loss: 0.0098621
[Epoch 27; Iter   248/ 1097] train: loss: 0.0960882
[Epoch 27; Iter   278/ 1097] train: loss: 0.0090647
[Epoch 27; Iter   308/ 1097] train: loss: 0.0119777
[Epoch 27; Iter   338/ 1097] train: loss: 0.0776943
[Epoch 27; Iter   368/ 1097] train: loss: 0.2177346
[Epoch 27; Iter   398/ 1097] train: loss: 0.0080665
[Epoch 27; Iter   428/ 1097] train: loss: 0.0222030
[Epoch 27; Iter   458/ 1097] train: loss: 0.0169176
[Epoch 27; Iter   488/ 1097] train: loss: 0.0177489
[Epoch 27; Iter   518/ 1097] train: loss: 0.1435537
[Epoch 27; Iter   548/ 1097] train: loss: 0.0216115
[Epoch 27; Iter   578/ 1097] train: loss: 0.0680906
[Epoch 27; Iter   608/ 1097] train: loss: 0.0446867
[Epoch 27; Iter   638/ 1097] train: loss: 0.0077810
[Epoch 27; Iter   668/ 1097] train: loss: 0.0842901
[Epoch 27; Iter   698/ 1097] train: loss: 0.0772793
[Epoch 27; Iter   728/ 1097] train: loss: 0.0678723
[Epoch 27; Iter   758/ 1097] train: loss: 0.0621296
[Epoch 27; Iter   788/ 1097] train: loss: 0.1035571
[Epoch 27; Iter   818/ 1097] train: loss: 0.0140789
[Epoch 27; Iter   848/ 1097] train: loss: 0.0086077
[Epoch 27; Iter   878/ 1097] train: loss: 0.2128906
[Epoch 27; Iter   908/ 1097] train: loss: 0.2496617
[Epoch 27; Iter   938/ 1097] train: loss: 0.0096118
[Epoch 27; Iter   968/ 1097] train: loss: 0.1176801
[Epoch 27; Iter   998/ 1097] train: loss: 0.0066830
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1410605
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0945591
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0574627
[Epoch 27] ogbg-molhiv: 0.686921 val loss: 48.003874
[Epoch 27] ogbg-molhiv: 0.580330 test loss: 30.642820
[Epoch 28; Iter    21/ 1097] train: loss: 0.0734274
[Epoch 28; Iter    51/ 1097] train: loss: 0.0126730
[Epoch 28; Iter    81/ 1097] train: loss: 0.0416011
[Epoch 28; Iter   111/ 1097] train: loss: 0.0232073
[Epoch 28; Iter   141/ 1097] train: loss: 0.0264972
[Epoch 28; Iter   171/ 1097] train: loss: 0.0079078
[Epoch 28; Iter   201/ 1097] train: loss: 0.0304662
[Epoch 28; Iter   231/ 1097] train: loss: 0.0076437
[Epoch 28; Iter   261/ 1097] train: loss: 0.0070476
[Epoch 28; Iter   291/ 1097] train: loss: 0.0169303
[Epoch 28; Iter   321/ 1097] train: loss: 0.0025334
[Epoch 28; Iter   351/ 1097] train: loss: 0.0295832
[Epoch 28; Iter   381/ 1097] train: loss: 0.0169874
[Epoch 28; Iter   411/ 1097] train: loss: 0.0874108
[Epoch 24; Iter   359/ 1097] train: loss: 0.1321751
[Epoch 24; Iter   389/ 1097] train: loss: 0.1518991
[Epoch 24; Iter   419/ 1097] train: loss: 0.3141508
[Epoch 24; Iter   449/ 1097] train: loss: 0.0192212
[Epoch 24; Iter   479/ 1097] train: loss: 0.1095364
[Epoch 24; Iter   509/ 1097] train: loss: 0.0523362
[Epoch 24; Iter   539/ 1097] train: loss: 0.0381213
[Epoch 24; Iter   569/ 1097] train: loss: 0.0260524
[Epoch 24; Iter   599/ 1097] train: loss: 0.2058868
[Epoch 24; Iter   629/ 1097] train: loss: 0.0180175
[Epoch 24; Iter   659/ 1097] train: loss: 0.0320344
[Epoch 24; Iter   689/ 1097] train: loss: 0.0158562
[Epoch 24; Iter   719/ 1097] train: loss: 0.0215478
[Epoch 24; Iter   749/ 1097] train: loss: 0.0451298
[Epoch 24; Iter   779/ 1097] train: loss: 0.0199084
[Epoch 24; Iter   809/ 1097] train: loss: 0.0355895
[Epoch 24; Iter   839/ 1097] train: loss: 0.0449798
[Epoch 24; Iter   869/ 1097] train: loss: 0.1331619
[Epoch 24; Iter   899/ 1097] train: loss: 0.1242172
[Epoch 24; Iter   929/ 1097] train: loss: 0.1929003
[Epoch 24; Iter   959/ 1097] train: loss: 0.0199661
[Epoch 24; Iter   989/ 1097] train: loss: 0.0203921
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0994915
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0752389
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0442117
[Epoch 24] ogbg-molhiv: 0.740337 val loss: 25.527063
[Epoch 24] ogbg-molhiv: 0.640596 test loss: 20.713570
[Epoch 25; Iter    12/ 1097] train: loss: 0.0093464
[Epoch 25; Iter    42/ 1097] train: loss: 0.0296976
[Epoch 25; Iter    72/ 1097] train: loss: 0.0197099
[Epoch 25; Iter   102/ 1097] train: loss: 0.0139255
[Epoch 25; Iter   132/ 1097] train: loss: 0.0473808
[Epoch 25; Iter   162/ 1097] train: loss: 0.0278862
[Epoch 25; Iter   192/ 1097] train: loss: 0.1224791
[Epoch 25; Iter   222/ 1097] train: loss: 0.0411623
[Epoch 25; Iter   252/ 1097] train: loss: 0.0724087
[Epoch 25; Iter   282/ 1097] train: loss: 0.0832830
[Epoch 25; Iter   312/ 1097] train: loss: 0.0094466
[Epoch 25; Iter   342/ 1097] train: loss: 0.2223527
[Epoch 25; Iter   372/ 1097] train: loss: 0.2494989
[Epoch 25; Iter   402/ 1097] train: loss: 0.0253433
[Epoch 25; Iter   432/ 1097] train: loss: 0.1771196
[Epoch 25; Iter   462/ 1097] train: loss: 0.0271098
[Epoch 25; Iter   492/ 1097] train: loss: 0.1959149
[Epoch 25; Iter   522/ 1097] train: loss: 0.0140466
[Epoch 25; Iter   552/ 1097] train: loss: 0.1577996
[Epoch 25; Iter   582/ 1097] train: loss: 0.0129939
[Epoch 25; Iter   612/ 1097] train: loss: 0.2147990
[Epoch 25; Iter   642/ 1097] train: loss: 0.0318656
[Epoch 25; Iter   672/ 1097] train: loss: 0.0197900
[Epoch 25; Iter   702/ 1097] train: loss: 0.0791687
[Epoch 25; Iter   732/ 1097] train: loss: 0.0160894
[Epoch 25; Iter   762/ 1097] train: loss: 0.0369404
[Epoch 25; Iter   792/ 1097] train: loss: 0.0204048
[Epoch 25; Iter   822/ 1097] train: loss: 0.0499257
[Epoch 25; Iter   852/ 1097] train: loss: 0.0150060
[Epoch 25; Iter   882/ 1097] train: loss: 0.0393496
[Epoch 25; Iter   912/ 1097] train: loss: 0.1144069
[Epoch 25; Iter   942/ 1097] train: loss: 0.0726372
[Epoch 25; Iter   972/ 1097] train: loss: 0.0267873
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1435173
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0549526
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0343826
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1758950
[Epoch 25] ogbg-molhiv: 0.777459 val loss: 11.775351
[Epoch 25] ogbg-molhiv: 0.696972 test loss: 7.080785
[Epoch 26; Iter    25/ 1097] train: loss: 0.0135657
[Epoch 26; Iter    55/ 1097] train: loss: 0.0159793
[Epoch 26; Iter    85/ 1097] train: loss: 0.0292494
[Epoch 26; Iter   115/ 1097] train: loss: 0.1842020
[Epoch 26; Iter   145/ 1097] train: loss: 0.0246089
[Epoch 26; Iter   175/ 1097] train: loss: 0.0731826
[Epoch 26; Iter   205/ 1097] train: loss: 0.2523252
[Epoch 26; Iter   235/ 1097] train: loss: 0.0282346
[Epoch 26; Iter   265/ 1097] train: loss: 0.0280046
[Epoch 26; Iter   295/ 1097] train: loss: 0.0421220
[Epoch 26; Iter   325/ 1097] train: loss: 0.0401791
[Epoch 26; Iter   355/ 1097] train: loss: 0.0654959
[Epoch 26; Iter   385/ 1097] train: loss: 0.0209027
[Epoch 26; Iter   415/ 1097] train: loss: 0.0283151
[Epoch 26; Iter   445/ 1097] train: loss: 0.0317163
[Epoch 26; Iter   475/ 1097] train: loss: 0.0568022
[Epoch 26; Iter   505/ 1097] train: loss: 0.0584572
[Epoch 26; Iter   535/ 1097] train: loss: 0.1720088
[Epoch 26; Iter   565/ 1097] train: loss: 0.0288544
[Epoch 26; Iter   595/ 1097] train: loss: 0.0077723
[Epoch 26; Iter   625/ 1097] train: loss: 0.0228208
[Epoch 26; Iter   655/ 1097] train: loss: 0.0713107
[Epoch 26; Iter   685/ 1097] train: loss: 0.1286129
[Epoch 26; Iter   715/ 1097] train: loss: 0.0060731
[Epoch 26; Iter   745/ 1097] train: loss: 0.0080303
[Epoch 26; Iter   775/ 1097] train: loss: 0.0120678
[Epoch 26; Iter   805/ 1097] train: loss: 0.0153909
[Epoch 26; Iter   835/ 1097] train: loss: 0.1141690
[Epoch 26; Iter   865/ 1097] train: loss: 0.1167853
[Epoch 26; Iter   895/ 1097] train: loss: 0.0530678
[Epoch 26; Iter   925/ 1097] train: loss: 0.1059923
[Epoch 26; Iter   955/ 1097] train: loss: 0.0286675
[Epoch 26; Iter   985/ 1097] train: loss: 0.0334679
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0353455
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0289035
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0779767
[Epoch 26] ogbg-molhiv: 0.777003 val loss: 1.940913
[Epoch 26] ogbg-molhiv: 0.723033 test loss: 1.252405
[Epoch 27; Iter     8/ 1097] train: loss: 0.0120955
[Epoch 27; Iter    38/ 1097] train: loss: 0.0080098
[Epoch 27; Iter    68/ 1097] train: loss: 0.0143835
[Epoch 27; Iter    98/ 1097] train: loss: 0.0323225
[Epoch 27; Iter   128/ 1097] train: loss: 0.1393858
[Epoch 27; Iter   158/ 1097] train: loss: 0.0090388
[Epoch 27; Iter   188/ 1097] train: loss: 0.0151404
[Epoch 27; Iter   218/ 1097] train: loss: 0.0234034
[Epoch 27; Iter   248/ 1097] train: loss: 0.0130933
[Epoch 27; Iter   278/ 1097] train: loss: 0.0218867
[Epoch 27; Iter   308/ 1097] train: loss: 0.0138898
[Epoch 27; Iter   338/ 1097] train: loss: 0.0039076
[Epoch 27; Iter   368/ 1097] train: loss: 0.0157609
[Epoch 27; Iter   398/ 1097] train: loss: 0.0123924
[Epoch 27; Iter   428/ 1097] train: loss: 0.1563886
[Epoch 27; Iter   458/ 1097] train: loss: 0.0244814
[Epoch 27; Iter   488/ 1097] train: loss: 0.0142678
[Epoch 27; Iter   518/ 1097] train: loss: 0.3595631
[Epoch 27; Iter   548/ 1097] train: loss: 0.0374549
[Epoch 27; Iter   578/ 1097] train: loss: 0.0326765
[Epoch 27; Iter   608/ 1097] train: loss: 0.0667362
[Epoch 27; Iter   638/ 1097] train: loss: 0.0085156
[Epoch 27; Iter   668/ 1097] train: loss: 0.0026082
[Epoch 27; Iter   698/ 1097] train: loss: 0.0798300
[Epoch 27; Iter   728/ 1097] train: loss: 0.1886369
[Epoch 27; Iter   758/ 1097] train: loss: 0.0229885
[Epoch 27; Iter   788/ 1097] train: loss: 0.0104177
[Epoch 27; Iter   818/ 1097] train: loss: 0.0236754
[Epoch 27; Iter   848/ 1097] train: loss: 0.0286707
[Epoch 27; Iter   878/ 1097] train: loss: 0.2398789
[Epoch 27; Iter   908/ 1097] train: loss: 0.0120714
[Epoch 27; Iter   938/ 1097] train: loss: 0.0660347
[Epoch 27; Iter   968/ 1097] train: loss: 0.0085535
[Epoch 27; Iter   998/ 1097] train: loss: 0.0265206
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0316569
[Epoch 27; Iter  1058/ 1097] train: loss: 0.1952187
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1274510
[Epoch 27] ogbg-molhiv: 0.752168 val loss: 0.130607
[Epoch 27] ogbg-molhiv: 0.652351 test loss: 0.207174
[Epoch 28; Iter    21/ 1097] train: loss: 0.0355528
[Epoch 28; Iter    51/ 1097] train: loss: 0.0170799
[Epoch 28; Iter    81/ 1097] train: loss: 0.0099366
[Epoch 28; Iter   111/ 1097] train: loss: 0.1312897
[Epoch 28; Iter   141/ 1097] train: loss: 0.0738554
[Epoch 28; Iter   171/ 1097] train: loss: 0.0425866
[Epoch 28; Iter   201/ 1097] train: loss: 0.0669885
[Epoch 28; Iter   231/ 1097] train: loss: 0.0132616
[Epoch 28; Iter   261/ 1097] train: loss: 0.0549597
[Epoch 28; Iter   291/ 1097] train: loss: 0.0230358
[Epoch 28; Iter   321/ 1097] train: loss: 0.0096194
[Epoch 28; Iter   351/ 1097] train: loss: 0.0124492
[Epoch 28; Iter   381/ 1097] train: loss: 0.0388874
[Epoch 28; Iter   411/ 1097] train: loss: 0.0265692
[Epoch 24; Iter   359/ 1097] train: loss: 0.0276075
[Epoch 24; Iter   389/ 1097] train: loss: 0.0167792
[Epoch 24; Iter   419/ 1097] train: loss: 0.0376867
[Epoch 24; Iter   449/ 1097] train: loss: 0.0423277
[Epoch 24; Iter   479/ 1097] train: loss: 0.1208043
[Epoch 24; Iter   509/ 1097] train: loss: 0.0109919
[Epoch 24; Iter   539/ 1097] train: loss: 0.0278809
[Epoch 24; Iter   569/ 1097] train: loss: 0.0226639
[Epoch 24; Iter   599/ 1097] train: loss: 0.1032995
[Epoch 24; Iter   629/ 1097] train: loss: 0.0356478
[Epoch 24; Iter   659/ 1097] train: loss: 0.0386656
[Epoch 24; Iter   689/ 1097] train: loss: 0.0302716
[Epoch 24; Iter   719/ 1097] train: loss: 0.0484748
[Epoch 24; Iter   749/ 1097] train: loss: 0.0107541
[Epoch 24; Iter   779/ 1097] train: loss: 0.1728403
[Epoch 24; Iter   809/ 1097] train: loss: 0.1376768
[Epoch 24; Iter   839/ 1097] train: loss: 0.1486607
[Epoch 24; Iter   869/ 1097] train: loss: 0.0055574
[Epoch 24; Iter   899/ 1097] train: loss: 0.0251009
[Epoch 24; Iter   929/ 1097] train: loss: 0.0181746
[Epoch 24; Iter   959/ 1097] train: loss: 0.0070505
[Epoch 24; Iter   989/ 1097] train: loss: 0.0343009
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3088009
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0258183
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0415113
[Epoch 24] ogbg-molhiv: 0.711610 val loss: 0.184031
[Epoch 24] ogbg-molhiv: 0.674731 test loss: 0.187407
[Epoch 25; Iter    12/ 1097] train: loss: 0.0394191
[Epoch 25; Iter    42/ 1097] train: loss: 0.0467809
[Epoch 25; Iter    72/ 1097] train: loss: 0.1575220
[Epoch 25; Iter   102/ 1097] train: loss: 0.0089097
[Epoch 25; Iter   132/ 1097] train: loss: 0.0078889
[Epoch 25; Iter   162/ 1097] train: loss: 0.0119761
[Epoch 25; Iter   192/ 1097] train: loss: 0.0106118
[Epoch 25; Iter   222/ 1097] train: loss: 0.0230655
[Epoch 25; Iter   252/ 1097] train: loss: 0.0067762
[Epoch 25; Iter   282/ 1097] train: loss: 0.0156661
[Epoch 25; Iter   312/ 1097] train: loss: 0.0596299
[Epoch 25; Iter   342/ 1097] train: loss: 0.0558891
[Epoch 25; Iter   372/ 1097] train: loss: 0.0306978
[Epoch 25; Iter   402/ 1097] train: loss: 0.0663813
[Epoch 25; Iter   432/ 1097] train: loss: 0.0935112
[Epoch 25; Iter   462/ 1097] train: loss: 0.0160032
[Epoch 25; Iter   492/ 1097] train: loss: 0.0334077
[Epoch 25; Iter   522/ 1097] train: loss: 0.0200405
[Epoch 25; Iter   552/ 1097] train: loss: 0.2068893
[Epoch 25; Iter   582/ 1097] train: loss: 0.2286072
[Epoch 25; Iter   612/ 1097] train: loss: 0.0073932
[Epoch 25; Iter   642/ 1097] train: loss: 0.1934546
[Epoch 25; Iter   672/ 1097] train: loss: 0.0455196
[Epoch 25; Iter   702/ 1097] train: loss: 0.0453951
[Epoch 25; Iter   732/ 1097] train: loss: 0.1751202
[Epoch 25; Iter   762/ 1097] train: loss: 0.0507427
[Epoch 25; Iter   792/ 1097] train: loss: 0.0567320
[Epoch 25; Iter   822/ 1097] train: loss: 0.0123145
[Epoch 25; Iter   852/ 1097] train: loss: 0.0627015
[Epoch 25; Iter   882/ 1097] train: loss: 0.0070137
[Epoch 25; Iter   912/ 1097] train: loss: 0.0218063
[Epoch 25; Iter   942/ 1097] train: loss: 0.2718816
[Epoch 25; Iter   972/ 1097] train: loss: 0.0826167
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0516513
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0450774
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0817649
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0076107
[Epoch 25] ogbg-molhiv: 0.716258 val loss: 0.151087
[Epoch 25] ogbg-molhiv: 0.696161 test loss: 0.205098
[Epoch 26; Iter    25/ 1097] train: loss: 0.0382584
[Epoch 26; Iter    55/ 1097] train: loss: 0.0630984
[Epoch 26; Iter    85/ 1097] train: loss: 0.0425692
[Epoch 26; Iter   115/ 1097] train: loss: 0.0065522
[Epoch 26; Iter   145/ 1097] train: loss: 0.0081924
[Epoch 26; Iter   175/ 1097] train: loss: 0.0401213
[Epoch 26; Iter   205/ 1097] train: loss: 0.0083727
[Epoch 26; Iter   235/ 1097] train: loss: 0.0064105
[Epoch 26; Iter   265/ 1097] train: loss: 0.0379193
[Epoch 26; Iter   295/ 1097] train: loss: 0.0472037
[Epoch 26; Iter   325/ 1097] train: loss: 0.0091335
[Epoch 26; Iter   355/ 1097] train: loss: 0.0069703
[Epoch 26; Iter   385/ 1097] train: loss: 0.1104301
[Epoch 26; Iter   415/ 1097] train: loss: 0.0062531
[Epoch 26; Iter   445/ 1097] train: loss: 0.0793972
[Epoch 26; Iter   475/ 1097] train: loss: 0.0562591
[Epoch 26; Iter   505/ 1097] train: loss: 0.1757058
[Epoch 26; Iter   535/ 1097] train: loss: 0.0266013
[Epoch 26; Iter   565/ 1097] train: loss: 0.0137601
[Epoch 26; Iter   595/ 1097] train: loss: 0.0066633
[Epoch 26; Iter   625/ 1097] train: loss: 0.0944572
[Epoch 26; Iter   655/ 1097] train: loss: 0.0194027
[Epoch 26; Iter   685/ 1097] train: loss: 0.0779367
[Epoch 26; Iter   715/ 1097] train: loss: 0.0291323
[Epoch 26; Iter   745/ 1097] train: loss: 0.0964517
[Epoch 26; Iter   775/ 1097] train: loss: 0.1316120
[Epoch 26; Iter   805/ 1097] train: loss: 0.0310169
[Epoch 26; Iter   835/ 1097] train: loss: 0.0175455
[Epoch 26; Iter   865/ 1097] train: loss: 0.2094997
[Epoch 26; Iter   895/ 1097] train: loss: 0.0165096
[Epoch 26; Iter   925/ 1097] train: loss: 0.0187916
[Epoch 26; Iter   955/ 1097] train: loss: 0.0250568
[Epoch 26; Iter   985/ 1097] train: loss: 0.0225423
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1107525
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0622486
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1012568
[Epoch 26] ogbg-molhiv: 0.752725 val loss: 0.161966
[Epoch 26] ogbg-molhiv: 0.668336 test loss: 0.224526
[Epoch 27; Iter     8/ 1097] train: loss: 0.0444251
[Epoch 27; Iter    38/ 1097] train: loss: 0.0242430
[Epoch 27; Iter    68/ 1097] train: loss: 0.0738514
[Epoch 27; Iter    98/ 1097] train: loss: 0.0463050
[Epoch 27; Iter   128/ 1097] train: loss: 0.0143768
[Epoch 27; Iter   158/ 1097] train: loss: 0.0559619
[Epoch 27; Iter   188/ 1097] train: loss: 0.0148870
[Epoch 27; Iter   218/ 1097] train: loss: 0.0159245
[Epoch 27; Iter   248/ 1097] train: loss: 0.0395353
[Epoch 27; Iter   278/ 1097] train: loss: 0.0263263
[Epoch 27; Iter   308/ 1097] train: loss: 0.0351929
[Epoch 27; Iter   338/ 1097] train: loss: 0.0129621
[Epoch 27; Iter   368/ 1097] train: loss: 0.1162093
[Epoch 27; Iter   398/ 1097] train: loss: 0.1269632
[Epoch 27; Iter   428/ 1097] train: loss: 0.0145656
[Epoch 27; Iter   458/ 1097] train: loss: 0.1073804
[Epoch 27; Iter   488/ 1097] train: loss: 0.0876717
[Epoch 27; Iter   518/ 1097] train: loss: 0.1594916
[Epoch 27; Iter   548/ 1097] train: loss: 0.0279400
[Epoch 27; Iter   578/ 1097] train: loss: 0.0210227
[Epoch 27; Iter   608/ 1097] train: loss: 0.0107679
[Epoch 27; Iter   638/ 1097] train: loss: 0.0121348
[Epoch 27; Iter   668/ 1097] train: loss: 0.0084937
[Epoch 27; Iter   698/ 1097] train: loss: 0.0525409
[Epoch 27; Iter   728/ 1097] train: loss: 0.0374580
[Epoch 27; Iter   758/ 1097] train: loss: 0.0449883
[Epoch 27; Iter   788/ 1097] train: loss: 0.1069614
[Epoch 27; Iter   818/ 1097] train: loss: 0.0056741
[Epoch 27; Iter   848/ 1097] train: loss: 0.0098671
[Epoch 27; Iter   878/ 1097] train: loss: 0.0105777
[Epoch 27; Iter   908/ 1097] train: loss: 0.0549153
[Epoch 27; Iter   938/ 1097] train: loss: 0.0110374
[Epoch 27; Iter   968/ 1097] train: loss: 0.0699701
[Epoch 27; Iter   998/ 1097] train: loss: 0.0062612
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0271725
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0061703
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0124196
[Epoch 27] ogbg-molhiv: 0.792389 val loss: 0.647977
[Epoch 27] ogbg-molhiv: 0.693563 test loss: 0.465123
[Epoch 28; Iter    21/ 1097] train: loss: 0.0638604
[Epoch 28; Iter    51/ 1097] train: loss: 0.0392520
[Epoch 28; Iter    81/ 1097] train: loss: 0.0127225
[Epoch 28; Iter   111/ 1097] train: loss: 0.0034983
[Epoch 28; Iter   141/ 1097] train: loss: 0.0293798
[Epoch 28; Iter   171/ 1097] train: loss: 0.0070439
[Epoch 28; Iter   201/ 1097] train: loss: 0.0055037
[Epoch 28; Iter   231/ 1097] train: loss: 0.0093544
[Epoch 28; Iter   261/ 1097] train: loss: 0.0086957
[Epoch 28; Iter   291/ 1097] train: loss: 0.0169818
[Epoch 28; Iter   321/ 1097] train: loss: 0.0588813
[Epoch 28; Iter   351/ 1097] train: loss: 0.0306845
[Epoch 28; Iter   381/ 1097] train: loss: 0.0155512
[Epoch 28; Iter   411/ 1097] train: loss: 0.0077398
[Epoch 28; Iter   441/ 1097] train: loss: 0.6265884
[Epoch 28; Iter   471/ 1097] train: loss: 0.0384368
[Epoch 28; Iter   501/ 1097] train: loss: 0.2326983
[Epoch 28; Iter   531/ 1097] train: loss: 0.0169645
[Epoch 28; Iter   561/ 1097] train: loss: 0.1001773
[Epoch 28; Iter   591/ 1097] train: loss: 0.1039177
[Epoch 28; Iter   621/ 1097] train: loss: 0.0530203
[Epoch 28; Iter   651/ 1097] train: loss: 0.0171236
[Epoch 28; Iter   681/ 1097] train: loss: 0.0219977
[Epoch 28; Iter   711/ 1097] train: loss: 0.0170674
[Epoch 28; Iter   741/ 1097] train: loss: 0.0073322
[Epoch 28; Iter   771/ 1097] train: loss: 0.0128112
[Epoch 28; Iter   801/ 1097] train: loss: 0.0090065
[Epoch 28; Iter   831/ 1097] train: loss: 0.0406196
[Epoch 28; Iter   861/ 1097] train: loss: 0.1411143
[Epoch 28; Iter   891/ 1097] train: loss: 0.0270514
[Epoch 28; Iter   921/ 1097] train: loss: 0.0093962
[Epoch 28; Iter   951/ 1097] train: loss: 0.0336464
[Epoch 28; Iter   981/ 1097] train: loss: 0.0161926
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0129490
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0088355
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0167305
[Epoch 28] ogbg-molhiv: 0.785074 val loss: 0.343496
[Epoch 28] ogbg-molhiv: 0.766710 test loss: 0.139371
[Epoch 29; Iter     4/ 1097] train: loss: 0.0184916
[Epoch 29; Iter    34/ 1097] train: loss: 0.0126119
[Epoch 29; Iter    64/ 1097] train: loss: 0.0467926
[Epoch 29; Iter    94/ 1097] train: loss: 0.0195261
[Epoch 29; Iter   124/ 1097] train: loss: 0.0639610
[Epoch 29; Iter   154/ 1097] train: loss: 0.0650014
[Epoch 29; Iter   184/ 1097] train: loss: 0.0126654
[Epoch 29; Iter   214/ 1097] train: loss: 0.0184524
[Epoch 29; Iter   244/ 1097] train: loss: 0.0323585
[Epoch 29; Iter   274/ 1097] train: loss: 0.0223716
[Epoch 29; Iter   304/ 1097] train: loss: 0.0124183
[Epoch 29; Iter   334/ 1097] train: loss: 0.0383202
[Epoch 29; Iter   364/ 1097] train: loss: 0.0111656
[Epoch 29; Iter   394/ 1097] train: loss: 0.0328993
[Epoch 29; Iter   424/ 1097] train: loss: 0.0751947
[Epoch 29; Iter   454/ 1097] train: loss: 0.0125064
[Epoch 29; Iter   484/ 1097] train: loss: 0.0188758
[Epoch 29; Iter   514/ 1097] train: loss: 0.0341249
[Epoch 29; Iter   544/ 1097] train: loss: 0.0089971
[Epoch 29; Iter   574/ 1097] train: loss: 0.0070322
[Epoch 29; Iter   604/ 1097] train: loss: 0.1150684
[Epoch 29; Iter   634/ 1097] train: loss: 0.2101387
[Epoch 29; Iter   664/ 1097] train: loss: 0.0179797
[Epoch 29; Iter   694/ 1097] train: loss: 0.0163438
[Epoch 29; Iter   724/ 1097] train: loss: 0.0119896
[Epoch 29; Iter   754/ 1097] train: loss: 0.0084201
[Epoch 29; Iter   784/ 1097] train: loss: 0.0259294
[Epoch 29; Iter   814/ 1097] train: loss: 0.0097011
[Epoch 29; Iter   844/ 1097] train: loss: 0.0704114
[Epoch 29; Iter   874/ 1097] train: loss: 0.3158407
[Epoch 29; Iter   904/ 1097] train: loss: 0.0111416
[Epoch 29; Iter   934/ 1097] train: loss: 0.1901556
[Epoch 29; Iter   964/ 1097] train: loss: 0.0075924
[Epoch 29; Iter   994/ 1097] train: loss: 0.0809127
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0179434
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0431340
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0759652
[Epoch 29] ogbg-molhiv: 0.721224 val loss: 0.126741
[Epoch 29] ogbg-molhiv: 0.738052 test loss: 0.149714
[Epoch 30; Iter    17/ 1097] train: loss: 0.0212332
[Epoch 30; Iter    47/ 1097] train: loss: 0.1970538
[Epoch 30; Iter    77/ 1097] train: loss: 0.0278583
[Epoch 30; Iter   107/ 1097] train: loss: 0.0090180
[Epoch 30; Iter   137/ 1097] train: loss: 0.0401639
[Epoch 30; Iter   167/ 1097] train: loss: 0.0302016
[Epoch 30; Iter   197/ 1097] train: loss: 0.0162428
[Epoch 30; Iter   227/ 1097] train: loss: 0.0140613
[Epoch 30; Iter   257/ 1097] train: loss: 0.0139697
[Epoch 30; Iter   287/ 1097] train: loss: 0.0084265
[Epoch 30; Iter   317/ 1097] train: loss: 0.0291666
[Epoch 30; Iter   347/ 1097] train: loss: 0.0255425
[Epoch 30; Iter   377/ 1097] train: loss: 0.0575228
[Epoch 30; Iter   407/ 1097] train: loss: 0.0108251
[Epoch 30; Iter   437/ 1097] train: loss: 0.0205932
[Epoch 30; Iter   467/ 1097] train: loss: 0.0128813
[Epoch 30; Iter   497/ 1097] train: loss: 0.1489433
[Epoch 30; Iter   527/ 1097] train: loss: 0.0605005
[Epoch 30; Iter   557/ 1097] train: loss: 0.2062753
[Epoch 30; Iter   587/ 1097] train: loss: 0.0181166
[Epoch 30; Iter   617/ 1097] train: loss: 0.0084765
[Epoch 30; Iter   647/ 1097] train: loss: 0.0037180
[Epoch 30; Iter   677/ 1097] train: loss: 0.0239145
[Epoch 30; Iter   707/ 1097] train: loss: 0.1722202
[Epoch 30; Iter   737/ 1097] train: loss: 0.1205940
[Epoch 30; Iter   767/ 1097] train: loss: 0.0450378
[Epoch 30; Iter   797/ 1097] train: loss: 0.1157354
[Epoch 30; Iter   827/ 1097] train: loss: 0.0723562
[Epoch 30; Iter   857/ 1097] train: loss: 0.1210222
[Epoch 30; Iter   887/ 1097] train: loss: 0.0146562
[Epoch 30; Iter   917/ 1097] train: loss: 0.0642491
[Epoch 30; Iter   947/ 1097] train: loss: 0.0591381
[Epoch 30; Iter   977/ 1097] train: loss: 0.0051272
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0627927
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0332596
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0215637
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0197594
[Epoch 30] ogbg-molhiv: 0.757591 val loss: 0.114601
[Epoch 30] ogbg-molhiv: 0.740095 test loss: 0.158854
[Epoch 31; Iter    30/ 1097] train: loss: 0.0181089
[Epoch 31; Iter    60/ 1097] train: loss: 0.0190329
[Epoch 31; Iter    90/ 1097] train: loss: 0.0809219
[Epoch 31; Iter   120/ 1097] train: loss: 0.0482264
[Epoch 31; Iter   150/ 1097] train: loss: 0.0679369
[Epoch 31; Iter   180/ 1097] train: loss: 0.0174106
[Epoch 31; Iter   210/ 1097] train: loss: 0.0259393
[Epoch 31; Iter   240/ 1097] train: loss: 0.0120504
[Epoch 31; Iter   270/ 1097] train: loss: 0.0294961
[Epoch 31; Iter   300/ 1097] train: loss: 0.0327866
[Epoch 31; Iter   330/ 1097] train: loss: 0.0645908
[Epoch 31; Iter   360/ 1097] train: loss: 0.1055895
[Epoch 31; Iter   390/ 1097] train: loss: 0.0167622
[Epoch 31; Iter   420/ 1097] train: loss: 0.0630640
[Epoch 31; Iter   450/ 1097] train: loss: 0.0255741
[Epoch 31; Iter   480/ 1097] train: loss: 0.0164524
[Epoch 31; Iter   510/ 1097] train: loss: 0.0091127
[Epoch 31; Iter   540/ 1097] train: loss: 0.0042894
[Epoch 31; Iter   570/ 1097] train: loss: 0.0335183
[Epoch 31; Iter   600/ 1097] train: loss: 0.0020761
[Epoch 31; Iter   630/ 1097] train: loss: 0.0181834
[Epoch 31; Iter   660/ 1097] train: loss: 0.0317397
[Epoch 31; Iter   690/ 1097] train: loss: 0.0135399
[Epoch 31; Iter   720/ 1097] train: loss: 0.1457312
[Epoch 31; Iter   750/ 1097] train: loss: 0.0145957
[Epoch 31; Iter   780/ 1097] train: loss: 0.0293727
[Epoch 31; Iter   810/ 1097] train: loss: 0.0155661
[Epoch 31; Iter   840/ 1097] train: loss: 0.1908383
[Epoch 31; Iter   870/ 1097] train: loss: 0.1362768
[Epoch 31; Iter   900/ 1097] train: loss: 0.0495338
[Epoch 31; Iter   930/ 1097] train: loss: 0.0126733
[Epoch 31; Iter   960/ 1097] train: loss: 0.0274771
[Epoch 31; Iter   990/ 1097] train: loss: 0.0536473
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0584851
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0762205
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0296462
[Epoch 31] ogbg-molhiv: 0.767159 val loss: 0.266399
[Epoch 31] ogbg-molhiv: 0.755607 test loss: 0.184598
[Epoch 32; Iter    13/ 1097] train: loss: 0.0069403
[Epoch 32; Iter    43/ 1097] train: loss: 0.0742338
[Epoch 32; Iter    73/ 1097] train: loss: 0.0122513
[Epoch 32; Iter   103/ 1097] train: loss: 0.0095204
[Epoch 32; Iter   133/ 1097] train: loss: 0.0669537
[Epoch 32; Iter   163/ 1097] train: loss: 0.0239669
[Epoch 32; Iter   193/ 1097] train: loss: 0.0914943
[Epoch 32; Iter   223/ 1097] train: loss: 0.0030488
[Epoch 32; Iter   253/ 1097] train: loss: 0.0033572
[Epoch 32; Iter   283/ 1097] train: loss: 0.0187166
[Epoch 32; Iter   313/ 1097] train: loss: 0.0272094
[Epoch 32; Iter   343/ 1097] train: loss: 0.0239171
[Epoch 32; Iter   373/ 1097] train: loss: 0.0550651
[Epoch 32; Iter   403/ 1097] train: loss: 0.0402690
[Epoch 32; Iter   433/ 1097] train: loss: 0.0101507
[Epoch 32; Iter   463/ 1097] train: loss: 0.0144837
[Epoch 32; Iter   493/ 1097] train: loss: 0.0413511
[Epoch 28; Iter   441/ 1097] train: loss: 0.0199647
[Epoch 28; Iter   471/ 1097] train: loss: 0.0508167
[Epoch 28; Iter   501/ 1097] train: loss: 0.0114812
[Epoch 28; Iter   531/ 1097] train: loss: 0.0991911
[Epoch 28; Iter   561/ 1097] train: loss: 0.0378905
[Epoch 28; Iter   591/ 1097] train: loss: 0.1146612
[Epoch 28; Iter   621/ 1097] train: loss: 0.0747156
[Epoch 28; Iter   651/ 1097] train: loss: 0.0421569
[Epoch 28; Iter   681/ 1097] train: loss: 0.0246861
[Epoch 28; Iter   711/ 1097] train: loss: 0.0857920
[Epoch 28; Iter   741/ 1097] train: loss: 0.1398055
[Epoch 28; Iter   771/ 1097] train: loss: 0.0675338
[Epoch 28; Iter   801/ 1097] train: loss: 0.2872815
[Epoch 28; Iter   831/ 1097] train: loss: 0.0113364
[Epoch 28; Iter   861/ 1097] train: loss: 0.0639400
[Epoch 28; Iter   891/ 1097] train: loss: 0.0404467
[Epoch 28; Iter   921/ 1097] train: loss: 0.0898408
[Epoch 28; Iter   951/ 1097] train: loss: 0.0119098
[Epoch 28; Iter   981/ 1097] train: loss: 0.0309734
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0089533
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1128374
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1210826
[Epoch 28] ogbg-molhiv: 0.772955 val loss: 0.353896
[Epoch 28] ogbg-molhiv: 0.744856 test loss: 0.210287
[Epoch 29; Iter     4/ 1097] train: loss: 0.0436118
[Epoch 29; Iter    34/ 1097] train: loss: 0.0294714
[Epoch 29; Iter    64/ 1097] train: loss: 0.3036365
[Epoch 29; Iter    94/ 1097] train: loss: 0.0286807
[Epoch 29; Iter   124/ 1097] train: loss: 0.0143003
[Epoch 29; Iter   154/ 1097] train: loss: 0.0155766
[Epoch 29; Iter   184/ 1097] train: loss: 0.0228317
[Epoch 29; Iter   214/ 1097] train: loss: 0.0727282
[Epoch 29; Iter   244/ 1097] train: loss: 0.0240921
[Epoch 29; Iter   274/ 1097] train: loss: 0.0336264
[Epoch 29; Iter   304/ 1097] train: loss: 0.0086379
[Epoch 29; Iter   334/ 1097] train: loss: 0.0482683
[Epoch 29; Iter   364/ 1097] train: loss: 0.0197473
[Epoch 29; Iter   394/ 1097] train: loss: 0.0114932
[Epoch 29; Iter   424/ 1097] train: loss: 0.0221570
[Epoch 29; Iter   454/ 1097] train: loss: 0.0162131
[Epoch 29; Iter   484/ 1097] train: loss: 0.0083966
[Epoch 29; Iter   514/ 1097] train: loss: 0.0862229
[Epoch 29; Iter   544/ 1097] train: loss: 0.0113477
[Epoch 29; Iter   574/ 1097] train: loss: 0.0091689
[Epoch 29; Iter   604/ 1097] train: loss: 0.0510630
[Epoch 29; Iter   634/ 1097] train: loss: 0.0168389
[Epoch 29; Iter   664/ 1097] train: loss: 0.0306005
[Epoch 29; Iter   694/ 1097] train: loss: 0.0975081
[Epoch 29; Iter   724/ 1097] train: loss: 0.0131211
[Epoch 29; Iter   754/ 1097] train: loss: 0.0228698
[Epoch 29; Iter   784/ 1097] train: loss: 0.0350046
[Epoch 29; Iter   814/ 1097] train: loss: 0.0809921
[Epoch 29; Iter   844/ 1097] train: loss: 0.0087862
[Epoch 29; Iter   874/ 1097] train: loss: 0.0135196
[Epoch 29; Iter   904/ 1097] train: loss: 0.0167935
[Epoch 29; Iter   934/ 1097] train: loss: 0.0454068
[Epoch 29; Iter   964/ 1097] train: loss: 0.0880615
[Epoch 29; Iter   994/ 1097] train: loss: 0.0471821
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0381844
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0607877
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1387011
[Epoch 29] ogbg-molhiv: 0.790356 val loss: 0.422809
[Epoch 29] ogbg-molhiv: 0.757985 test loss: 0.190829
[Epoch 30; Iter    17/ 1097] train: loss: 0.0402831
[Epoch 30; Iter    47/ 1097] train: loss: 0.0093337
[Epoch 30; Iter    77/ 1097] train: loss: 0.0092072
[Epoch 30; Iter   107/ 1097] train: loss: 0.0223968
[Epoch 30; Iter   137/ 1097] train: loss: 0.0141699
[Epoch 30; Iter   167/ 1097] train: loss: 0.0657040
[Epoch 30; Iter   197/ 1097] train: loss: 0.1236667
[Epoch 30; Iter   227/ 1097] train: loss: 0.0077061
[Epoch 30; Iter   257/ 1097] train: loss: 0.1550762
[Epoch 30; Iter   287/ 1097] train: loss: 0.0136853
[Epoch 30; Iter   317/ 1097] train: loss: 0.0737197
[Epoch 30; Iter   347/ 1097] train: loss: 0.0098768
[Epoch 30; Iter   377/ 1097] train: loss: 0.0877153
[Epoch 30; Iter   407/ 1097] train: loss: 0.0102389
[Epoch 30; Iter   437/ 1097] train: loss: 0.1369863
[Epoch 30; Iter   467/ 1097] train: loss: 0.0103455
[Epoch 30; Iter   497/ 1097] train: loss: 0.0956216
[Epoch 30; Iter   527/ 1097] train: loss: 0.0316989
[Epoch 30; Iter   557/ 1097] train: loss: 0.1778370
[Epoch 30; Iter   587/ 1097] train: loss: 0.1674216
[Epoch 30; Iter   617/ 1097] train: loss: 0.0078749
[Epoch 30; Iter   647/ 1097] train: loss: 0.0164280
[Epoch 30; Iter   677/ 1097] train: loss: 0.0071077
[Epoch 30; Iter   707/ 1097] train: loss: 0.0338541
[Epoch 30; Iter   737/ 1097] train: loss: 0.0043462
[Epoch 30; Iter   767/ 1097] train: loss: 0.0278331
[Epoch 30; Iter   797/ 1097] train: loss: 0.0168937
[Epoch 30; Iter   827/ 1097] train: loss: 0.0123845
[Epoch 30; Iter   857/ 1097] train: loss: 0.0208548
[Epoch 30; Iter   887/ 1097] train: loss: 0.0146482
[Epoch 30; Iter   917/ 1097] train: loss: 0.0187850
[Epoch 30; Iter   947/ 1097] train: loss: 0.0220832
[Epoch 30; Iter   977/ 1097] train: loss: 0.3170180
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0073340
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0438882
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0488512
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0047062
[Epoch 30] ogbg-molhiv: 0.783060 val loss: 0.531963
[Epoch 30] ogbg-molhiv: 0.762178 test loss: 0.282575
[Epoch 31; Iter    30/ 1097] train: loss: 0.0119267
[Epoch 31; Iter    60/ 1097] train: loss: 0.0702592
[Epoch 31; Iter    90/ 1097] train: loss: 0.0079735
[Epoch 31; Iter   120/ 1097] train: loss: 0.0237260
[Epoch 31; Iter   150/ 1097] train: loss: 0.0133992
[Epoch 31; Iter   180/ 1097] train: loss: 0.1060138
[Epoch 31; Iter   210/ 1097] train: loss: 0.0676941
[Epoch 31; Iter   240/ 1097] train: loss: 0.0653048
[Epoch 31; Iter   270/ 1097] train: loss: 0.0058994
[Epoch 31; Iter   300/ 1097] train: loss: 0.0208666
[Epoch 31; Iter   330/ 1097] train: loss: 0.0406920
[Epoch 31; Iter   360/ 1097] train: loss: 0.0021880
[Epoch 31; Iter   390/ 1097] train: loss: 0.0285567
[Epoch 31; Iter   420/ 1097] train: loss: 0.0278630
[Epoch 31; Iter   450/ 1097] train: loss: 0.0181955
[Epoch 31; Iter   480/ 1097] train: loss: 0.0770269
[Epoch 31; Iter   510/ 1097] train: loss: 0.0185299
[Epoch 31; Iter   540/ 1097] train: loss: 0.0976300
[Epoch 31; Iter   570/ 1097] train: loss: 0.0644818
[Epoch 31; Iter   600/ 1097] train: loss: 0.0080839
[Epoch 31; Iter   630/ 1097] train: loss: 0.0100815
[Epoch 31; Iter   660/ 1097] train: loss: 0.0020878
[Epoch 31; Iter   690/ 1097] train: loss: 0.0778909
[Epoch 31; Iter   720/ 1097] train: loss: 0.0601361
[Epoch 31; Iter   750/ 1097] train: loss: 0.0811293
[Epoch 31; Iter   780/ 1097] train: loss: 0.1416511
[Epoch 31; Iter   810/ 1097] train: loss: 0.0368848
[Epoch 31; Iter   840/ 1097] train: loss: 0.0032032
[Epoch 31; Iter   870/ 1097] train: loss: 0.0107413
[Epoch 31; Iter   900/ 1097] train: loss: 0.1695557
[Epoch 31; Iter   930/ 1097] train: loss: 0.1197674
[Epoch 31; Iter   960/ 1097] train: loss: 0.0325059
[Epoch 31; Iter   990/ 1097] train: loss: 0.0137472
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0623837
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0222031
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0096655
[Epoch 31] ogbg-molhiv: 0.780653 val loss: 0.339027
[Epoch 31] ogbg-molhiv: 0.755418 test loss: 0.270135
[Epoch 32; Iter    13/ 1097] train: loss: 0.2476506
[Epoch 32; Iter    43/ 1097] train: loss: 0.0143157
[Epoch 32; Iter    73/ 1097] train: loss: 0.0131699
[Epoch 32; Iter   103/ 1097] train: loss: 0.0028376
[Epoch 32; Iter   133/ 1097] train: loss: 0.0178843
[Epoch 32; Iter   163/ 1097] train: loss: 0.0180035
[Epoch 32; Iter   193/ 1097] train: loss: 0.0188342
[Epoch 32; Iter   223/ 1097] train: loss: 0.0384155
[Epoch 32; Iter   253/ 1097] train: loss: 0.0174935
[Epoch 32; Iter   283/ 1097] train: loss: 0.0442748
[Epoch 32; Iter   313/ 1097] train: loss: 0.0461972
[Epoch 32; Iter   343/ 1097] train: loss: 0.0167283
[Epoch 32; Iter   373/ 1097] train: loss: 0.0040944
[Epoch 32; Iter   403/ 1097] train: loss: 0.1237302
[Epoch 32; Iter   433/ 1097] train: loss: 0.0157207
[Epoch 32; Iter   463/ 1097] train: loss: 0.0065396
[Epoch 32; Iter   493/ 1097] train: loss: 0.0049734
[Epoch 28; Iter   441/ 1097] train: loss: 0.0631264
[Epoch 28; Iter   471/ 1097] train: loss: 0.0468298
[Epoch 28; Iter   501/ 1097] train: loss: 0.0255949
[Epoch 28; Iter   531/ 1097] train: loss: 0.0835040
[Epoch 28; Iter   561/ 1097] train: loss: 0.0904735
[Epoch 28; Iter   591/ 1097] train: loss: 0.0515593
[Epoch 28; Iter   621/ 1097] train: loss: 0.0316233
[Epoch 28; Iter   651/ 1097] train: loss: 0.1613275
[Epoch 28; Iter   681/ 1097] train: loss: 0.0580891
[Epoch 28; Iter   711/ 1097] train: loss: 0.0210140
[Epoch 28; Iter   741/ 1097] train: loss: 0.0190385
[Epoch 28; Iter   771/ 1097] train: loss: 0.0226292
[Epoch 28; Iter   801/ 1097] train: loss: 0.0073077
[Epoch 28; Iter   831/ 1097] train: loss: 0.0866194
[Epoch 28; Iter   861/ 1097] train: loss: 0.0315797
[Epoch 28; Iter   891/ 1097] train: loss: 0.0266714
[Epoch 28; Iter   921/ 1097] train: loss: 0.0102992
[Epoch 28; Iter   951/ 1097] train: loss: 0.0309213
[Epoch 28; Iter   981/ 1097] train: loss: 0.0855227
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0491160
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0312949
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0324747
[Epoch 28] ogbg-molhiv: 0.708915 val loss: 1.867822
[Epoch 28] ogbg-molhiv: 0.733741 test loss: 0.639731
[Epoch 29; Iter     4/ 1097] train: loss: 0.0177947
[Epoch 29; Iter    34/ 1097] train: loss: 0.1500006
[Epoch 29; Iter    64/ 1097] train: loss: 0.0098800
[Epoch 29; Iter    94/ 1097] train: loss: 0.0208494
[Epoch 29; Iter   124/ 1097] train: loss: 0.0208534
[Epoch 29; Iter   154/ 1097] train: loss: 0.0098475
[Epoch 29; Iter   184/ 1097] train: loss: 0.0118100
[Epoch 29; Iter   214/ 1097] train: loss: 0.0633420
[Epoch 29; Iter   244/ 1097] train: loss: 0.0694640
[Epoch 29; Iter   274/ 1097] train: loss: 0.0133435
[Epoch 29; Iter   304/ 1097] train: loss: 0.0448138
[Epoch 29; Iter   334/ 1097] train: loss: 0.1730176
[Epoch 29; Iter   364/ 1097] train: loss: 0.0280988
[Epoch 29; Iter   394/ 1097] train: loss: 0.0914165
[Epoch 29; Iter   424/ 1097] train: loss: 0.0114408
[Epoch 29; Iter   454/ 1097] train: loss: 0.0572296
[Epoch 29; Iter   484/ 1097] train: loss: 0.0696566
[Epoch 29; Iter   514/ 1097] train: loss: 0.0256478
[Epoch 29; Iter   544/ 1097] train: loss: 0.0355206
[Epoch 29; Iter   574/ 1097] train: loss: 0.0321760
[Epoch 29; Iter   604/ 1097] train: loss: 0.0235516
[Epoch 29; Iter   634/ 1097] train: loss: 0.0080313
[Epoch 29; Iter   664/ 1097] train: loss: 0.0358704
[Epoch 29; Iter   694/ 1097] train: loss: 0.1278733
[Epoch 29; Iter   724/ 1097] train: loss: 0.0181153
[Epoch 29; Iter   754/ 1097] train: loss: 0.0129583
[Epoch 29; Iter   784/ 1097] train: loss: 0.0173033
[Epoch 29; Iter   814/ 1097] train: loss: 0.0630130
[Epoch 29; Iter   844/ 1097] train: loss: 0.1041572
[Epoch 29; Iter   874/ 1097] train: loss: 0.0155700
[Epoch 29; Iter   904/ 1097] train: loss: 0.0961805
[Epoch 29; Iter   934/ 1097] train: loss: 0.0931960
[Epoch 29; Iter   964/ 1097] train: loss: 0.0461300
[Epoch 29; Iter   994/ 1097] train: loss: 0.2428983
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0562144
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0134630
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0365914
[Epoch 29] ogbg-molhiv: 0.726181 val loss: 0.127960
[Epoch 29] ogbg-molhiv: 0.703275 test loss: 0.162902
[Epoch 30; Iter    17/ 1097] train: loss: 0.0157052
[Epoch 30; Iter    47/ 1097] train: loss: 0.0325450
[Epoch 30; Iter    77/ 1097] train: loss: 0.0414051
[Epoch 30; Iter   107/ 1097] train: loss: 0.0135583
[Epoch 30; Iter   137/ 1097] train: loss: 0.0276584
[Epoch 30; Iter   167/ 1097] train: loss: 0.0087285
[Epoch 30; Iter   197/ 1097] train: loss: 0.1831149
[Epoch 30; Iter   227/ 1097] train: loss: 0.0107608
[Epoch 30; Iter   257/ 1097] train: loss: 0.0108706
[Epoch 30; Iter   287/ 1097] train: loss: 0.0214983
[Epoch 30; Iter   317/ 1097] train: loss: 0.0689080
[Epoch 30; Iter   347/ 1097] train: loss: 0.0469821
[Epoch 30; Iter   377/ 1097] train: loss: 0.0460844
[Epoch 30; Iter   407/ 1097] train: loss: 0.0747650
[Epoch 30; Iter   437/ 1097] train: loss: 0.2460223
[Epoch 30; Iter   467/ 1097] train: loss: 0.0207047
[Epoch 30; Iter   497/ 1097] train: loss: 0.0953824
[Epoch 30; Iter   527/ 1097] train: loss: 0.0247073
[Epoch 30; Iter   557/ 1097] train: loss: 0.0225308
[Epoch 30; Iter   587/ 1097] train: loss: 0.0139177
[Epoch 30; Iter   617/ 1097] train: loss: 0.0191606
[Epoch 30; Iter   647/ 1097] train: loss: 0.1181479
[Epoch 30; Iter   677/ 1097] train: loss: 0.0066891
[Epoch 30; Iter   707/ 1097] train: loss: 0.0269156
[Epoch 30; Iter   737/ 1097] train: loss: 0.1470118
[Epoch 30; Iter   767/ 1097] train: loss: 0.0099618
[Epoch 30; Iter   797/ 1097] train: loss: 0.0652918
[Epoch 30; Iter   827/ 1097] train: loss: 0.1477890
[Epoch 30; Iter   857/ 1097] train: loss: 0.0135708
[Epoch 30; Iter   887/ 1097] train: loss: 0.0394756
[Epoch 30; Iter   917/ 1097] train: loss: 0.0331716
[Epoch 30; Iter   947/ 1097] train: loss: 0.0652079
[Epoch 30; Iter   977/ 1097] train: loss: 0.0969633
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0652046
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0288982
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0331826
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0082746
[Epoch 30] ogbg-molhiv: 0.708750 val loss: 0.281691
[Epoch 30] ogbg-molhiv: 0.738518 test loss: 0.195865
[Epoch 31; Iter    30/ 1097] train: loss: 0.0212680
[Epoch 31; Iter    60/ 1097] train: loss: 0.0194451
[Epoch 31; Iter    90/ 1097] train: loss: 0.0234955
[Epoch 31; Iter   120/ 1097] train: loss: 0.0564529
[Epoch 31; Iter   150/ 1097] train: loss: 0.0923696
[Epoch 31; Iter   180/ 1097] train: loss: 0.0129528
[Epoch 31; Iter   210/ 1097] train: loss: 0.0151445
[Epoch 31; Iter   240/ 1097] train: loss: 0.0138285
[Epoch 31; Iter   270/ 1097] train: loss: 0.0078975
[Epoch 31; Iter   300/ 1097] train: loss: 0.0501861
[Epoch 31; Iter   330/ 1097] train: loss: 0.0184610
[Epoch 31; Iter   360/ 1097] train: loss: 0.0100500
[Epoch 31; Iter   390/ 1097] train: loss: 0.1345993
[Epoch 31; Iter   420/ 1097] train: loss: 0.0396266
[Epoch 31; Iter   450/ 1097] train: loss: 0.0117177
[Epoch 31; Iter   480/ 1097] train: loss: 0.0601229
[Epoch 31; Iter   510/ 1097] train: loss: 0.0419003
[Epoch 31; Iter   540/ 1097] train: loss: 0.0081479
[Epoch 31; Iter   570/ 1097] train: loss: 0.0197939
[Epoch 31; Iter   600/ 1097] train: loss: 0.0124694
[Epoch 31; Iter   630/ 1097] train: loss: 0.0610877
[Epoch 31; Iter   660/ 1097] train: loss: 0.0965598
[Epoch 31; Iter   690/ 1097] train: loss: 0.0520458
[Epoch 31; Iter   720/ 1097] train: loss: 0.0057298
[Epoch 31; Iter   750/ 1097] train: loss: 0.0496336
[Epoch 31; Iter   780/ 1097] train: loss: 0.0397093
[Epoch 31; Iter   810/ 1097] train: loss: 0.0172819
[Epoch 31; Iter   840/ 1097] train: loss: 0.0115901
[Epoch 31; Iter   870/ 1097] train: loss: 0.1489025
[Epoch 31; Iter   900/ 1097] train: loss: 0.0255065
[Epoch 31; Iter   930/ 1097] train: loss: 0.0900965
[Epoch 31; Iter   960/ 1097] train: loss: 0.0149726
[Epoch 31; Iter   990/ 1097] train: loss: 0.0251318
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0573066
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0332641
[Epoch 31; Iter  1080/ 1097] train: loss: 0.1605857
[Epoch 31] ogbg-molhiv: 0.692068 val loss: 0.208994
[Epoch 31] ogbg-molhiv: 0.698024 test loss: 0.521886
[Epoch 32; Iter    13/ 1097] train: loss: 0.0365079
[Epoch 32; Iter    43/ 1097] train: loss: 0.1508027
[Epoch 32; Iter    73/ 1097] train: loss: 0.0552592
[Epoch 32; Iter   103/ 1097] train: loss: 0.0091959
[Epoch 32; Iter   133/ 1097] train: loss: 0.0115127
[Epoch 32; Iter   163/ 1097] train: loss: 0.0298529
[Epoch 32; Iter   193/ 1097] train: loss: 0.0793307
[Epoch 32; Iter   223/ 1097] train: loss: 0.0304805
[Epoch 32; Iter   253/ 1097] train: loss: 0.0251810
[Epoch 32; Iter   283/ 1097] train: loss: 0.0054614
[Epoch 32; Iter   313/ 1097] train: loss: 0.2058748
[Epoch 32; Iter   343/ 1097] train: loss: 0.0158951
[Epoch 32; Iter   373/ 1097] train: loss: 0.0271576
[Epoch 32; Iter   403/ 1097] train: loss: 0.0291066
[Epoch 32; Iter   433/ 1097] train: loss: 0.0137314
[Epoch 32; Iter   463/ 1097] train: loss: 0.0069121
[Epoch 32; Iter   493/ 1097] train: loss: 0.0376804
[Epoch 28; Iter   441/ 1097] train: loss: 0.1528531
[Epoch 28; Iter   471/ 1097] train: loss: 0.1941673
[Epoch 28; Iter   501/ 1097] train: loss: 0.0446883
[Epoch 28; Iter   531/ 1097] train: loss: 0.0118868
[Epoch 28; Iter   561/ 1097] train: loss: 0.2018748
[Epoch 28; Iter   591/ 1097] train: loss: 0.0256491
[Epoch 28; Iter   621/ 1097] train: loss: 0.0263701
[Epoch 28; Iter   651/ 1097] train: loss: 0.0310064
[Epoch 28; Iter   681/ 1097] train: loss: 0.0315105
[Epoch 28; Iter   711/ 1097] train: loss: 0.0169620
[Epoch 28; Iter   741/ 1097] train: loss: 0.0258878
[Epoch 28; Iter   771/ 1097] train: loss: 0.0964100
[Epoch 28; Iter   801/ 1097] train: loss: 0.0141045
[Epoch 28; Iter   831/ 1097] train: loss: 0.2185619
[Epoch 28; Iter   861/ 1097] train: loss: 0.0440448
[Epoch 28; Iter   891/ 1097] train: loss: 0.0979955
[Epoch 28; Iter   921/ 1097] train: loss: 0.0192103
[Epoch 28; Iter   951/ 1097] train: loss: 0.0209148
[Epoch 28; Iter   981/ 1097] train: loss: 0.1103676
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0168900
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0531642
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0133608
[Epoch 28] ogbg-molhiv: 0.775530 val loss: 0.085603
[Epoch 28] ogbg-molhiv: 0.709065 test loss: 0.165845
[Epoch 29; Iter     4/ 1097] train: loss: 0.0256393
[Epoch 29; Iter    34/ 1097] train: loss: 0.0714960
[Epoch 29; Iter    64/ 1097] train: loss: 0.0349954
[Epoch 29; Iter    94/ 1097] train: loss: 0.0164054
[Epoch 29; Iter   124/ 1097] train: loss: 0.0245088
[Epoch 29; Iter   154/ 1097] train: loss: 0.0446308
[Epoch 29; Iter   184/ 1097] train: loss: 0.0082022
[Epoch 29; Iter   214/ 1097] train: loss: 0.0599441
[Epoch 29; Iter   244/ 1097] train: loss: 0.1376607
[Epoch 29; Iter   274/ 1097] train: loss: 0.0146771
[Epoch 29; Iter   304/ 1097] train: loss: 0.0222633
[Epoch 29; Iter   334/ 1097] train: loss: 0.1673056
[Epoch 29; Iter   364/ 1097] train: loss: 0.0840041
[Epoch 29; Iter   394/ 1097] train: loss: 0.0239058
[Epoch 29; Iter   424/ 1097] train: loss: 0.0479868
[Epoch 29; Iter   454/ 1097] train: loss: 0.0665159
[Epoch 29; Iter   484/ 1097] train: loss: 0.0130944
[Epoch 29; Iter   514/ 1097] train: loss: 0.0340086
[Epoch 29; Iter   544/ 1097] train: loss: 0.0069003
[Epoch 29; Iter   574/ 1097] train: loss: 0.0565522
[Epoch 29; Iter   604/ 1097] train: loss: 0.0122504
[Epoch 29; Iter   634/ 1097] train: loss: 0.1211328
[Epoch 29; Iter   664/ 1097] train: loss: 0.0126777
[Epoch 29; Iter   694/ 1097] train: loss: 0.3763262
[Epoch 29; Iter   724/ 1097] train: loss: 0.0123596
[Epoch 29; Iter   754/ 1097] train: loss: 0.0460583
[Epoch 29; Iter   784/ 1097] train: loss: 0.0252521
[Epoch 29; Iter   814/ 1097] train: loss: 0.0260959
[Epoch 29; Iter   844/ 1097] train: loss: 0.0798671
[Epoch 29; Iter   874/ 1097] train: loss: 0.0337494
[Epoch 29; Iter   904/ 1097] train: loss: 0.0554923
[Epoch 29; Iter   934/ 1097] train: loss: 0.0362958
[Epoch 29; Iter   964/ 1097] train: loss: 0.0517722
[Epoch 29; Iter   994/ 1097] train: loss: 0.1253644
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0753838
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0110446
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0451239
[Epoch 29] ogbg-molhiv: 0.801012 val loss: 0.095172
[Epoch 29] ogbg-molhiv: 0.715392 test loss: 0.160228
[Epoch 30; Iter    17/ 1097] train: loss: 0.0249818
[Epoch 30; Iter    47/ 1097] train: loss: 0.0342432
[Epoch 30; Iter    77/ 1097] train: loss: 0.0134405
[Epoch 30; Iter   107/ 1097] train: loss: 0.0660190
[Epoch 30; Iter   137/ 1097] train: loss: 0.0456138
[Epoch 30; Iter   167/ 1097] train: loss: 0.0142248
[Epoch 30; Iter   197/ 1097] train: loss: 0.0486100
[Epoch 30; Iter   227/ 1097] train: loss: 0.0224034
[Epoch 30; Iter   257/ 1097] train: loss: 0.0363632
[Epoch 30; Iter   287/ 1097] train: loss: 0.0216985
[Epoch 30; Iter   317/ 1097] train: loss: 0.1502345
[Epoch 30; Iter   347/ 1097] train: loss: 0.0196323
[Epoch 30; Iter   377/ 1097] train: loss: 0.0247430
[Epoch 30; Iter   407/ 1097] train: loss: 0.0406236
[Epoch 30; Iter   437/ 1097] train: loss: 0.0466604
[Epoch 30; Iter   467/ 1097] train: loss: 0.0383631
[Epoch 30; Iter   497/ 1097] train: loss: 0.0660156
[Epoch 30; Iter   527/ 1097] train: loss: 0.0605535
[Epoch 30; Iter   557/ 1097] train: loss: 0.3103545
[Epoch 30; Iter   587/ 1097] train: loss: 0.0114734
[Epoch 30; Iter   617/ 1097] train: loss: 0.0138490
[Epoch 30; Iter   647/ 1097] train: loss: 0.0437514
[Epoch 30; Iter   677/ 1097] train: loss: 0.0101615
[Epoch 30; Iter   707/ 1097] train: loss: 0.0775030
[Epoch 30; Iter   737/ 1097] train: loss: 0.0340836
[Epoch 30; Iter   767/ 1097] train: loss: 0.0093363
[Epoch 30; Iter   797/ 1097] train: loss: 0.0719401
[Epoch 30; Iter   827/ 1097] train: loss: 0.0433309
[Epoch 30; Iter   857/ 1097] train: loss: 0.0614531
[Epoch 30; Iter   887/ 1097] train: loss: 0.0777214
[Epoch 30; Iter   917/ 1097] train: loss: 0.0341352
[Epoch 30; Iter   947/ 1097] train: loss: 0.1414543
[Epoch 30; Iter   977/ 1097] train: loss: 0.0498007
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0360641
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0607529
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0560247
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0078080
[Epoch 30] ogbg-molhiv: 0.800212 val loss: 0.082159
[Epoch 30] ogbg-molhiv: 0.744580 test loss: 0.139526
[Epoch 31; Iter    30/ 1097] train: loss: 0.0142362
[Epoch 31; Iter    60/ 1097] train: loss: 0.0229417
[Epoch 31; Iter    90/ 1097] train: loss: 0.0195805
[Epoch 31; Iter   120/ 1097] train: loss: 0.0184156
[Epoch 31; Iter   150/ 1097] train: loss: 0.0812282
[Epoch 31; Iter   180/ 1097] train: loss: 0.0497888
[Epoch 31; Iter   210/ 1097] train: loss: 0.0100713
[Epoch 31; Iter   240/ 1097] train: loss: 0.0219691
[Epoch 31; Iter   270/ 1097] train: loss: 0.0437987
[Epoch 31; Iter   300/ 1097] train: loss: 0.0157147
[Epoch 31; Iter   330/ 1097] train: loss: 0.0575978
[Epoch 31; Iter   360/ 1097] train: loss: 0.0106381
[Epoch 31; Iter   390/ 1097] train: loss: 0.2023370
[Epoch 31; Iter   420/ 1097] train: loss: 0.0301199
[Epoch 31; Iter   450/ 1097] train: loss: 0.0056715
[Epoch 31; Iter   480/ 1097] train: loss: 0.0209340
[Epoch 31; Iter   510/ 1097] train: loss: 0.0118095
[Epoch 31; Iter   540/ 1097] train: loss: 0.0286841
[Epoch 31; Iter   570/ 1097] train: loss: 0.0847050
[Epoch 31; Iter   600/ 1097] train: loss: 0.0097251
[Epoch 31; Iter   630/ 1097] train: loss: 0.0414261
[Epoch 31; Iter   660/ 1097] train: loss: 0.1469877
[Epoch 31; Iter   690/ 1097] train: loss: 0.0407122
[Epoch 31; Iter   720/ 1097] train: loss: 0.0400784
[Epoch 31; Iter   750/ 1097] train: loss: 0.0656037
[Epoch 31; Iter   780/ 1097] train: loss: 0.0406114
[Epoch 31; Iter   810/ 1097] train: loss: 0.0171107
[Epoch 31; Iter   840/ 1097] train: loss: 0.0095348
[Epoch 31; Iter   870/ 1097] train: loss: 0.0071480
[Epoch 31; Iter   900/ 1097] train: loss: 0.0711518
[Epoch 31; Iter   930/ 1097] train: loss: 0.0821616
[Epoch 31; Iter   960/ 1097] train: loss: 0.0066023
[Epoch 31; Iter   990/ 1097] train: loss: 0.0479312
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0096228
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0145740
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2114097
[Epoch 31] ogbg-molhiv: 0.742109 val loss: 0.100614
[Epoch 31] ogbg-molhiv: 0.671417 test loss: 0.189008
[Epoch 32; Iter    13/ 1097] train: loss: 0.0248796
[Epoch 32; Iter    43/ 1097] train: loss: 0.2565721
[Epoch 32; Iter    73/ 1097] train: loss: 0.0195080
[Epoch 32; Iter   103/ 1097] train: loss: 0.0201042
[Epoch 32; Iter   133/ 1097] train: loss: 0.0108139
[Epoch 32; Iter   163/ 1097] train: loss: 0.0054480
[Epoch 32; Iter   193/ 1097] train: loss: 0.0278734
[Epoch 32; Iter   223/ 1097] train: loss: 0.0154869
[Epoch 32; Iter   253/ 1097] train: loss: 0.0059483
[Epoch 32; Iter   283/ 1097] train: loss: 0.1020685
[Epoch 32; Iter   313/ 1097] train: loss: 0.0548441
[Epoch 32; Iter   343/ 1097] train: loss: 0.0355185
[Epoch 32; Iter   373/ 1097] train: loss: 0.2060659
[Epoch 32; Iter   403/ 1097] train: loss: 0.0653066
[Epoch 32; Iter   433/ 1097] train: loss: 0.0418398
[Epoch 32; Iter   463/ 1097] train: loss: 0.0808264
[Epoch 32; Iter   493/ 1097] train: loss: 0.0339157
[Epoch 28; Iter   441/ 1097] train: loss: 0.0311037
[Epoch 28; Iter   471/ 1097] train: loss: 0.0152542
[Epoch 28; Iter   501/ 1097] train: loss: 0.0332816
[Epoch 28; Iter   531/ 1097] train: loss: 0.1675371
[Epoch 28; Iter   561/ 1097] train: loss: 0.0304348
[Epoch 28; Iter   591/ 1097] train: loss: 0.1108907
[Epoch 28; Iter   621/ 1097] train: loss: 0.1280780
[Epoch 28; Iter   651/ 1097] train: loss: 0.1022568
[Epoch 28; Iter   681/ 1097] train: loss: 0.0174318
[Epoch 28; Iter   711/ 1097] train: loss: 0.1208013
[Epoch 28; Iter   741/ 1097] train: loss: 0.0557637
[Epoch 28; Iter   771/ 1097] train: loss: 0.0681068
[Epoch 28; Iter   801/ 1097] train: loss: 0.2283853
[Epoch 28; Iter   831/ 1097] train: loss: 0.0222958
[Epoch 28; Iter   861/ 1097] train: loss: 0.0977275
[Epoch 28; Iter   891/ 1097] train: loss: 0.1118486
[Epoch 28; Iter   921/ 1097] train: loss: 0.0226726
[Epoch 28; Iter   951/ 1097] train: loss: 0.0349348
[Epoch 28; Iter   981/ 1097] train: loss: 0.0267020
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0358554
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0633734
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1865190
[Epoch 28] ogbg-molhiv: 0.764872 val loss: 0.211152
[Epoch 28] ogbg-molhiv: 0.681736 test loss: 0.163863
[Epoch 29; Iter     4/ 1097] train: loss: 0.0751968
[Epoch 29; Iter    34/ 1097] train: loss: 0.0337357
[Epoch 29; Iter    64/ 1097] train: loss: 0.2471998
[Epoch 29; Iter    94/ 1097] train: loss: 0.0095320
[Epoch 29; Iter   124/ 1097] train: loss: 0.0191179
[Epoch 29; Iter   154/ 1097] train: loss: 0.1327220
[Epoch 29; Iter   184/ 1097] train: loss: 0.0945955
[Epoch 29; Iter   214/ 1097] train: loss: 0.1627800
[Epoch 29; Iter   244/ 1097] train: loss: 0.0276773
[Epoch 29; Iter   274/ 1097] train: loss: 0.0381104
[Epoch 29; Iter   304/ 1097] train: loss: 0.0493174
[Epoch 29; Iter   334/ 1097] train: loss: 0.0183969
[Epoch 29; Iter   364/ 1097] train: loss: 0.1785810
[Epoch 29; Iter   394/ 1097] train: loss: 0.0395949
[Epoch 29; Iter   424/ 1097] train: loss: 0.0388633
[Epoch 29; Iter   454/ 1097] train: loss: 0.0534584
[Epoch 29; Iter   484/ 1097] train: loss: 0.0194113
[Epoch 29; Iter   514/ 1097] train: loss: 0.1427454
[Epoch 29; Iter   544/ 1097] train: loss: 0.0134542
[Epoch 29; Iter   574/ 1097] train: loss: 0.0105276
[Epoch 29; Iter   604/ 1097] train: loss: 0.0211061
[Epoch 29; Iter   634/ 1097] train: loss: 0.0063157
[Epoch 29; Iter   664/ 1097] train: loss: 0.0410909
[Epoch 29; Iter   694/ 1097] train: loss: 0.0937786
[Epoch 29; Iter   724/ 1097] train: loss: 0.0819553
[Epoch 29; Iter   754/ 1097] train: loss: 0.0236101
[Epoch 29; Iter   784/ 1097] train: loss: 0.1115371
[Epoch 29; Iter   814/ 1097] train: loss: 0.0596383
[Epoch 29; Iter   844/ 1097] train: loss: 0.0095308
[Epoch 29; Iter   874/ 1097] train: loss: 0.0062386
[Epoch 29; Iter   904/ 1097] train: loss: 0.0457706
[Epoch 29; Iter   934/ 1097] train: loss: 0.0238418
[Epoch 29; Iter   964/ 1097] train: loss: 0.0866328
[Epoch 29; Iter   994/ 1097] train: loss: 0.0069941
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0355765
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0925208
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1953135
[Epoch 29] ogbg-molhiv: 0.788501 val loss: 0.418770
[Epoch 29] ogbg-molhiv: 0.700473 test loss: 0.189629
[Epoch 30; Iter    17/ 1097] train: loss: 0.0853546
[Epoch 30; Iter    47/ 1097] train: loss: 0.0105353
[Epoch 30; Iter    77/ 1097] train: loss: 0.0054204
[Epoch 30; Iter   107/ 1097] train: loss: 0.0074167
[Epoch 30; Iter   137/ 1097] train: loss: 0.0170068
[Epoch 30; Iter   167/ 1097] train: loss: 0.1321169
[Epoch 30; Iter   197/ 1097] train: loss: 0.1012199
[Epoch 30; Iter   227/ 1097] train: loss: 0.1085512
[Epoch 30; Iter   257/ 1097] train: loss: 0.1035805
[Epoch 30; Iter   287/ 1097] train: loss: 0.0471041
[Epoch 30; Iter   317/ 1097] train: loss: 0.0575760
[Epoch 30; Iter   347/ 1097] train: loss: 0.0118483
[Epoch 30; Iter   377/ 1097] train: loss: 0.2283436
[Epoch 30; Iter   407/ 1097] train: loss: 0.0160026
[Epoch 30; Iter   437/ 1097] train: loss: 0.0344138
[Epoch 30; Iter   467/ 1097] train: loss: 0.0178246
[Epoch 30; Iter   497/ 1097] train: loss: 0.1822183
[Epoch 30; Iter   527/ 1097] train: loss: 0.0284496
[Epoch 30; Iter   557/ 1097] train: loss: 0.0561757
[Epoch 30; Iter   587/ 1097] train: loss: 0.3081013
[Epoch 30; Iter   617/ 1097] train: loss: 0.0165028
[Epoch 30; Iter   647/ 1097] train: loss: 0.2462803
[Epoch 30; Iter   677/ 1097] train: loss: 0.0109299
[Epoch 30; Iter   707/ 1097] train: loss: 0.0324874
[Epoch 30; Iter   737/ 1097] train: loss: 0.0048724
[Epoch 30; Iter   767/ 1097] train: loss: 0.0240848
[Epoch 30; Iter   797/ 1097] train: loss: 0.0161122
[Epoch 30; Iter   827/ 1097] train: loss: 0.0312403
[Epoch 30; Iter   857/ 1097] train: loss: 0.0105723
[Epoch 30; Iter   887/ 1097] train: loss: 0.0095651
[Epoch 30; Iter   917/ 1097] train: loss: 0.0230400
[Epoch 30; Iter   947/ 1097] train: loss: 0.0566395
[Epoch 30; Iter   977/ 1097] train: loss: 0.0200989
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0122206
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0309972
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0088607
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0197902
[Epoch 30] ogbg-molhiv: 0.769462 val loss: 0.108501
[Epoch 30] ogbg-molhiv: 0.719803 test loss: 0.197914
[Epoch 31; Iter    30/ 1097] train: loss: 0.0582245
[Epoch 31; Iter    60/ 1097] train: loss: 0.0272508
[Epoch 31; Iter    90/ 1097] train: loss: 0.0426604
[Epoch 31; Iter   120/ 1097] train: loss: 0.0092431
[Epoch 31; Iter   150/ 1097] train: loss: 0.0101651
[Epoch 31; Iter   180/ 1097] train: loss: 0.0201958
[Epoch 31; Iter   210/ 1097] train: loss: 0.0357883
[Epoch 31; Iter   240/ 1097] train: loss: 0.1133993
[Epoch 31; Iter   270/ 1097] train: loss: 0.0364089
[Epoch 31; Iter   300/ 1097] train: loss: 0.0199111
[Epoch 31; Iter   330/ 1097] train: loss: 0.0090635
[Epoch 31; Iter   360/ 1097] train: loss: 0.0049354
[Epoch 31; Iter   390/ 1097] train: loss: 0.0422657
[Epoch 31; Iter   420/ 1097] train: loss: 0.0057301
[Epoch 31; Iter   450/ 1097] train: loss: 0.0118508
[Epoch 31; Iter   480/ 1097] train: loss: 0.0635903
[Epoch 31; Iter   510/ 1097] train: loss: 0.0301886
[Epoch 31; Iter   540/ 1097] train: loss: 0.0251958
[Epoch 31; Iter   570/ 1097] train: loss: 0.0593724
[Epoch 31; Iter   600/ 1097] train: loss: 0.0073478
[Epoch 31; Iter   630/ 1097] train: loss: 0.0491856
[Epoch 31; Iter   660/ 1097] train: loss: 0.0035362
[Epoch 31; Iter   690/ 1097] train: loss: 0.0163091
[Epoch 31; Iter   720/ 1097] train: loss: 0.0425450
[Epoch 31; Iter   750/ 1097] train: loss: 0.1443593
[Epoch 31; Iter   780/ 1097] train: loss: 0.0617795
[Epoch 31; Iter   810/ 1097] train: loss: 0.0364635
[Epoch 31; Iter   840/ 1097] train: loss: 0.0123578
[Epoch 31; Iter   870/ 1097] train: loss: 0.0534997
[Epoch 31; Iter   900/ 1097] train: loss: 0.1082079
[Epoch 31; Iter   930/ 1097] train: loss: 0.0552418
[Epoch 31; Iter   960/ 1097] train: loss: 0.0115266
[Epoch 31; Iter   990/ 1097] train: loss: 0.0322601
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1201992
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0131601
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0823198
[Epoch 31] ogbg-molhiv: 0.732189 val loss: 0.118613
[Epoch 31] ogbg-molhiv: 0.705373 test loss: 0.222008
[Epoch 32; Iter    13/ 1097] train: loss: 0.1603585
[Epoch 32; Iter    43/ 1097] train: loss: 0.0199038
[Epoch 32; Iter    73/ 1097] train: loss: 0.0072346
[Epoch 32; Iter   103/ 1097] train: loss: 0.0323601
[Epoch 32; Iter   133/ 1097] train: loss: 0.0216806
[Epoch 32; Iter   163/ 1097] train: loss: 0.0391923
[Epoch 32; Iter   193/ 1097] train: loss: 0.0997043
[Epoch 32; Iter   223/ 1097] train: loss: 0.0223754
[Epoch 32; Iter   253/ 1097] train: loss: 0.0069892
[Epoch 32; Iter   283/ 1097] train: loss: 0.0229903
[Epoch 32; Iter   313/ 1097] train: loss: 0.0105139
[Epoch 32; Iter   343/ 1097] train: loss: 0.0168484
[Epoch 32; Iter   373/ 1097] train: loss: 0.0070669
[Epoch 32; Iter   403/ 1097] train: loss: 0.2141403
[Epoch 32; Iter   433/ 1097] train: loss: 0.0141997
[Epoch 32; Iter   463/ 1097] train: loss: 0.0063559
[Epoch 32; Iter   493/ 1097] train: loss: 0.1902413
[Epoch 28; Iter   441/ 1097] train: loss: 0.5728854
[Epoch 28; Iter   471/ 1097] train: loss: 0.0126485
[Epoch 28; Iter   501/ 1097] train: loss: 0.1137775
[Epoch 28; Iter   531/ 1097] train: loss: 0.0175486
[Epoch 28; Iter   561/ 1097] train: loss: 0.0977268
[Epoch 28; Iter   591/ 1097] train: loss: 0.0480666
[Epoch 28; Iter   621/ 1097] train: loss: 0.1469631
[Epoch 28; Iter   651/ 1097] train: loss: 0.0351074
[Epoch 28; Iter   681/ 1097] train: loss: 0.0224259
[Epoch 28; Iter   711/ 1097] train: loss: 0.0189601
[Epoch 28; Iter   741/ 1097] train: loss: 0.0150001
[Epoch 28; Iter   771/ 1097] train: loss: 0.0590282
[Epoch 28; Iter   801/ 1097] train: loss: 0.0273666
[Epoch 28; Iter   831/ 1097] train: loss: 0.0089286
[Epoch 28; Iter   861/ 1097] train: loss: 0.1609283
[Epoch 28; Iter   891/ 1097] train: loss: 0.0644427
[Epoch 28; Iter   921/ 1097] train: loss: 0.0159465
[Epoch 28; Iter   951/ 1097] train: loss: 0.0477931
[Epoch 28; Iter   981/ 1097] train: loss: 0.0405266
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0148919
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0121975
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0449893
[Epoch 28] ogbg-molhiv: 0.776519 val loss: 0.114193
[Epoch 28] ogbg-molhiv: 0.805964 test loss: 0.144079
[Epoch 29; Iter     4/ 1097] train: loss: 0.0250174
[Epoch 29; Iter    34/ 1097] train: loss: 0.0080531
[Epoch 29; Iter    64/ 1097] train: loss: 0.0158669
[Epoch 29; Iter    94/ 1097] train: loss: 0.0170388
[Epoch 29; Iter   124/ 1097] train: loss: 0.0704982
[Epoch 29; Iter   154/ 1097] train: loss: 0.0763028
[Epoch 29; Iter   184/ 1097] train: loss: 0.0140947
[Epoch 29; Iter   214/ 1097] train: loss: 0.0372660
[Epoch 29; Iter   244/ 1097] train: loss: 0.0075443
[Epoch 29; Iter   274/ 1097] train: loss: 0.0136968
[Epoch 29; Iter   304/ 1097] train: loss: 0.0987954
[Epoch 29; Iter   334/ 1097] train: loss: 0.0377175
[Epoch 29; Iter   364/ 1097] train: loss: 0.0299718
[Epoch 29; Iter   394/ 1097] train: loss: 0.0188341
[Epoch 29; Iter   424/ 1097] train: loss: 0.0340403
[Epoch 29; Iter   454/ 1097] train: loss: 0.0195496
[Epoch 29; Iter   484/ 1097] train: loss: 0.0078368
[Epoch 29; Iter   514/ 1097] train: loss: 0.0339652
[Epoch 29; Iter   544/ 1097] train: loss: 0.0113049
[Epoch 29; Iter   574/ 1097] train: loss: 0.0297198
[Epoch 29; Iter   604/ 1097] train: loss: 0.0683735
[Epoch 29; Iter   634/ 1097] train: loss: 0.1416548
[Epoch 29; Iter   664/ 1097] train: loss: 0.0075723
[Epoch 29; Iter   694/ 1097] train: loss: 0.0159559
[Epoch 29; Iter   724/ 1097] train: loss: 0.0240895
[Epoch 29; Iter   754/ 1097] train: loss: 0.0171407
[Epoch 29; Iter   784/ 1097] train: loss: 0.0087424
[Epoch 29; Iter   814/ 1097] train: loss: 0.0087483
[Epoch 29; Iter   844/ 1097] train: loss: 0.0180781
[Epoch 29; Iter   874/ 1097] train: loss: 0.3258592
[Epoch 29; Iter   904/ 1097] train: loss: 0.0072212
[Epoch 29; Iter   934/ 1097] train: loss: 0.0345488
[Epoch 29; Iter   964/ 1097] train: loss: 0.0084414
[Epoch 29; Iter   994/ 1097] train: loss: 0.0069837
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0147123
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0141052
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0042185
[Epoch 29] ogbg-molhiv: 0.747704 val loss: 0.137980
[Epoch 29] ogbg-molhiv: 0.788791 test loss: 0.161656
[Epoch 30; Iter    17/ 1097] train: loss: 0.0052791
[Epoch 30; Iter    47/ 1097] train: loss: 0.1198504
[Epoch 30; Iter    77/ 1097] train: loss: 0.0061739
[Epoch 30; Iter   107/ 1097] train: loss: 0.0123347
[Epoch 30; Iter   137/ 1097] train: loss: 0.0126290
[Epoch 30; Iter   167/ 1097] train: loss: 0.0093901
[Epoch 30; Iter   197/ 1097] train: loss: 0.0101062
[Epoch 30; Iter   227/ 1097] train: loss: 0.0248567
[Epoch 30; Iter   257/ 1097] train: loss: 0.0282032
[Epoch 30; Iter   287/ 1097] train: loss: 0.0281055
[Epoch 30; Iter   317/ 1097] train: loss: 0.0478289
[Epoch 30; Iter   347/ 1097] train: loss: 0.0103167
[Epoch 30; Iter   377/ 1097] train: loss: 0.0354977
[Epoch 30; Iter   407/ 1097] train: loss: 0.0445333
[Epoch 30; Iter   437/ 1097] train: loss: 0.0183203
[Epoch 30; Iter   467/ 1097] train: loss: 0.0075966
[Epoch 30; Iter   497/ 1097] train: loss: 0.0768059
[Epoch 30; Iter   527/ 1097] train: loss: 0.2082325
[Epoch 30; Iter   557/ 1097] train: loss: 0.0965538
[Epoch 30; Iter   587/ 1097] train: loss: 0.0095829
[Epoch 30; Iter   617/ 1097] train: loss: 0.0078906
[Epoch 30; Iter   647/ 1097] train: loss: 0.0408266
[Epoch 30; Iter   677/ 1097] train: loss: 0.0147509
[Epoch 30; Iter   707/ 1097] train: loss: 0.0743340
[Epoch 30; Iter   737/ 1097] train: loss: 0.0096307
[Epoch 30; Iter   767/ 1097] train: loss: 0.0140369
[Epoch 30; Iter   797/ 1097] train: loss: 0.0699503
[Epoch 30; Iter   827/ 1097] train: loss: 0.0276054
[Epoch 30; Iter   857/ 1097] train: loss: 0.0290040
[Epoch 30; Iter   887/ 1097] train: loss: 0.0752445
[Epoch 30; Iter   917/ 1097] train: loss: 0.0641463
[Epoch 30; Iter   947/ 1097] train: loss: 0.0358074
[Epoch 30; Iter   977/ 1097] train: loss: 0.0090168
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0180078
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0126175
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0045412
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0261559
[Epoch 30] ogbg-molhiv: 0.782306 val loss: 0.142688
[Epoch 30] ogbg-molhiv: 0.798376 test loss: 0.182478
[Epoch 31; Iter    30/ 1097] train: loss: 0.0029443
[Epoch 31; Iter    60/ 1097] train: loss: 0.1181078
[Epoch 31; Iter    90/ 1097] train: loss: 0.0102589
[Epoch 31; Iter   120/ 1097] train: loss: 0.0215471
[Epoch 31; Iter   150/ 1097] train: loss: 0.1363505
[Epoch 31; Iter   180/ 1097] train: loss: 0.0072934
[Epoch 31; Iter   210/ 1097] train: loss: 0.0071015
[Epoch 31; Iter   240/ 1097] train: loss: 0.0140494
[Epoch 31; Iter   270/ 1097] train: loss: 0.0981214
[Epoch 31; Iter   300/ 1097] train: loss: 0.0065889
[Epoch 31; Iter   330/ 1097] train: loss: 0.0114192
[Epoch 31; Iter   360/ 1097] train: loss: 0.0328152
[Epoch 31; Iter   390/ 1097] train: loss: 0.0062460
[Epoch 31; Iter   420/ 1097] train: loss: 0.0272558
[Epoch 31; Iter   450/ 1097] train: loss: 0.0473186
[Epoch 31; Iter   480/ 1097] train: loss: 0.0389007
[Epoch 31; Iter   510/ 1097] train: loss: 0.0148702
[Epoch 31; Iter   540/ 1097] train: loss: 0.0122475
[Epoch 31; Iter   570/ 1097] train: loss: 0.0511992
[Epoch 31; Iter   600/ 1097] train: loss: 0.0055266
[Epoch 31; Iter   630/ 1097] train: loss: 0.0659734
[Epoch 31; Iter   660/ 1097] train: loss: 0.0531938
[Epoch 31; Iter   690/ 1097] train: loss: 0.0072387
[Epoch 31; Iter   720/ 1097] train: loss: 0.0239650
[Epoch 31; Iter   750/ 1097] train: loss: 0.0041828
[Epoch 31; Iter   780/ 1097] train: loss: 0.0043619
[Epoch 31; Iter   810/ 1097] train: loss: 0.0055790
[Epoch 31; Iter   840/ 1097] train: loss: 0.0241573
[Epoch 31; Iter   870/ 1097] train: loss: 0.0308922
[Epoch 31; Iter   900/ 1097] train: loss: 0.0156075
[Epoch 31; Iter   930/ 1097] train: loss: 0.0115031
[Epoch 31; Iter   960/ 1097] train: loss: 0.0721467
[Epoch 31; Iter   990/ 1097] train: loss: 0.0064462
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0405531
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0718445
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0150294
[Epoch 31] ogbg-molhiv: 0.759602 val loss: 0.185310
[Epoch 31] ogbg-molhiv: 0.794053 test loss: 0.189209
[Epoch 32; Iter    13/ 1097] train: loss: 0.0378918
[Epoch 32; Iter    43/ 1097] train: loss: 0.0765243
[Epoch 32; Iter    73/ 1097] train: loss: 0.0245718
[Epoch 32; Iter   103/ 1097] train: loss: 0.0355305
[Epoch 32; Iter   133/ 1097] train: loss: 0.0240453
[Epoch 32; Iter   163/ 1097] train: loss: 0.0075469
[Epoch 32; Iter   193/ 1097] train: loss: 0.0059190
[Epoch 32; Iter   223/ 1097] train: loss: 0.0084244
[Epoch 32; Iter   253/ 1097] train: loss: 0.0013804
[Epoch 32; Iter   283/ 1097] train: loss: 0.0063807
[Epoch 32; Iter   313/ 1097] train: loss: 0.0101515
[Epoch 32; Iter   343/ 1097] train: loss: 0.0035158
[Epoch 32; Iter   373/ 1097] train: loss: 0.1366772
[Epoch 32; Iter   403/ 1097] train: loss: 0.0084836
[Epoch 32; Iter   433/ 1097] train: loss: 0.0112098
[Epoch 32; Iter   463/ 1097] train: loss: 0.0325877
[Epoch 32; Iter   493/ 1097] train: loss: 0.0347441
[Epoch 24; Iter   359/ 1097] train: loss: 0.1216990
[Epoch 24; Iter   389/ 1097] train: loss: 0.0507121
[Epoch 24; Iter   419/ 1097] train: loss: 0.0202906
[Epoch 24; Iter   449/ 1097] train: loss: 0.0372821
[Epoch 24; Iter   479/ 1097] train: loss: 0.2432768
[Epoch 24; Iter   509/ 1097] train: loss: 0.1207021
[Epoch 24; Iter   539/ 1097] train: loss: 0.0318986
[Epoch 24; Iter   569/ 1097] train: loss: 0.0702541
[Epoch 24; Iter   599/ 1097] train: loss: 0.1207584
[Epoch 24; Iter   629/ 1097] train: loss: 0.0334734
[Epoch 24; Iter   659/ 1097] train: loss: 0.1274116
[Epoch 24; Iter   689/ 1097] train: loss: 0.1028061
[Epoch 24; Iter   719/ 1097] train: loss: 0.0275774
[Epoch 24; Iter   749/ 1097] train: loss: 0.0552332
[Epoch 24; Iter   779/ 1097] train: loss: 0.2211022
[Epoch 24; Iter   809/ 1097] train: loss: 0.1656821
[Epoch 24; Iter   839/ 1097] train: loss: 0.1588445
[Epoch 24; Iter   869/ 1097] train: loss: 0.0261062
[Epoch 24; Iter   899/ 1097] train: loss: 0.0218095
[Epoch 24; Iter   929/ 1097] train: loss: 0.0309745
[Epoch 24; Iter   959/ 1097] train: loss: 0.0141561
[Epoch 24; Iter   989/ 1097] train: loss: 0.0260950
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3004429
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0276314
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0882181
[Epoch 24] ogbg-molhiv: 0.781752 val loss: 0.077493
[Epoch 24] ogbg-molhiv: 0.745949 test loss: 0.121787
[Epoch 25; Iter    12/ 1097] train: loss: 0.0755985
[Epoch 25; Iter    42/ 1097] train: loss: 0.1746873
[Epoch 25; Iter    72/ 1097] train: loss: 0.3045093
[Epoch 25; Iter   102/ 1097] train: loss: 0.0585933
[Epoch 25; Iter   132/ 1097] train: loss: 0.0297562
[Epoch 25; Iter   162/ 1097] train: loss: 0.0198201
[Epoch 25; Iter   192/ 1097] train: loss: 0.0260530
[Epoch 25; Iter   222/ 1097] train: loss: 0.1498071
[Epoch 25; Iter   252/ 1097] train: loss: 0.0177868
[Epoch 25; Iter   282/ 1097] train: loss: 0.0205835
[Epoch 25; Iter   312/ 1097] train: loss: 0.0316003
[Epoch 25; Iter   342/ 1097] train: loss: 0.0900802
[Epoch 25; Iter   372/ 1097] train: loss: 0.0165801
[Epoch 25; Iter   402/ 1097] train: loss: 0.0345748
[Epoch 25; Iter   432/ 1097] train: loss: 0.0889913
[Epoch 25; Iter   462/ 1097] train: loss: 0.1735041
[Epoch 25; Iter   492/ 1097] train: loss: 0.1177188
[Epoch 25; Iter   522/ 1097] train: loss: 0.0269348
[Epoch 25; Iter   552/ 1097] train: loss: 0.2257787
[Epoch 25; Iter   582/ 1097] train: loss: 0.2340434
[Epoch 25; Iter   612/ 1097] train: loss: 0.0147729
[Epoch 25; Iter   642/ 1097] train: loss: 0.3593193
[Epoch 25; Iter   672/ 1097] train: loss: 0.1142332
[Epoch 25; Iter   702/ 1097] train: loss: 0.0364149
[Epoch 25; Iter   732/ 1097] train: loss: 0.2392014
[Epoch 25; Iter   762/ 1097] train: loss: 0.0821654
[Epoch 25; Iter   792/ 1097] train: loss: 0.2198182
[Epoch 25; Iter   822/ 1097] train: loss: 0.0213285
[Epoch 25; Iter   852/ 1097] train: loss: 0.0256744
[Epoch 25; Iter   882/ 1097] train: loss: 0.0158094
[Epoch 25; Iter   912/ 1097] train: loss: 0.0454700
[Epoch 25; Iter   942/ 1097] train: loss: 0.2064774
[Epoch 25; Iter   972/ 1097] train: loss: 0.1091652
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1204955
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0622971
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1881690
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0226392
[Epoch 25] ogbg-molhiv: 0.814940 val loss: 0.075470
[Epoch 25] ogbg-molhiv: 0.774505 test loss: 0.117010
[Epoch 26; Iter    25/ 1097] train: loss: 0.1296652
[Epoch 26; Iter    55/ 1097] train: loss: 0.0549542
[Epoch 26; Iter    85/ 1097] train: loss: 0.4063239
[Epoch 26; Iter   115/ 1097] train: loss: 0.0693663
[Epoch 26; Iter   145/ 1097] train: loss: 0.0341441
[Epoch 26; Iter   175/ 1097] train: loss: 0.0597097
[Epoch 26; Iter   205/ 1097] train: loss: 0.0127971
[Epoch 26; Iter   235/ 1097] train: loss: 0.0219658
[Epoch 26; Iter   265/ 1097] train: loss: 0.0514005
[Epoch 26; Iter   295/ 1097] train: loss: 0.0971666
[Epoch 26; Iter   325/ 1097] train: loss: 0.0397092
[Epoch 26; Iter   355/ 1097] train: loss: 0.1034967
[Epoch 26; Iter   385/ 1097] train: loss: 0.1625956
[Epoch 26; Iter   415/ 1097] train: loss: 0.1376541
[Epoch 26; Iter   445/ 1097] train: loss: 0.0437164
[Epoch 26; Iter   475/ 1097] train: loss: 0.0438534
[Epoch 26; Iter   505/ 1097] train: loss: 0.1548398
[Epoch 26; Iter   535/ 1097] train: loss: 0.0218210
[Epoch 26; Iter   565/ 1097] train: loss: 0.0635517
[Epoch 26; Iter   595/ 1097] train: loss: 0.0225572
[Epoch 26; Iter   625/ 1097] train: loss: 0.1541908
[Epoch 26; Iter   655/ 1097] train: loss: 0.0862313
[Epoch 26; Iter   685/ 1097] train: loss: 0.1273742
[Epoch 26; Iter   715/ 1097] train: loss: 0.0401628
[Epoch 26; Iter   745/ 1097] train: loss: 0.0406721
[Epoch 26; Iter   775/ 1097] train: loss: 0.2667643
[Epoch 26; Iter   805/ 1097] train: loss: 0.0339299
[Epoch 26; Iter   835/ 1097] train: loss: 0.0176188
[Epoch 26; Iter   865/ 1097] train: loss: 0.1265669
[Epoch 26; Iter   895/ 1097] train: loss: 0.0318472
[Epoch 26; Iter   925/ 1097] train: loss: 0.1006361
[Epoch 26; Iter   955/ 1097] train: loss: 0.1191439
[Epoch 26; Iter   985/ 1097] train: loss: 0.0487311
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2589701
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0332589
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2323319
[Epoch 26] ogbg-molhiv: 0.817981 val loss: 0.167591
[Epoch 26] ogbg-molhiv: 0.801010 test loss: 0.215165
[Epoch 27; Iter     8/ 1097] train: loss: 0.0312832
[Epoch 27; Iter    38/ 1097] train: loss: 0.1540904
[Epoch 27; Iter    68/ 1097] train: loss: 0.0609234
[Epoch 27; Iter    98/ 1097] train: loss: 0.1274783
[Epoch 27; Iter   128/ 1097] train: loss: 0.0254350
[Epoch 27; Iter   158/ 1097] train: loss: 0.1843303
[Epoch 27; Iter   188/ 1097] train: loss: 0.0306381
[Epoch 27; Iter   218/ 1097] train: loss: 0.1068703
[Epoch 27; Iter   248/ 1097] train: loss: 0.0589746
[Epoch 27; Iter   278/ 1097] train: loss: 0.0799845
[Epoch 27; Iter   308/ 1097] train: loss: 0.1110671
[Epoch 27; Iter   338/ 1097] train: loss: 0.0255956
[Epoch 27; Iter   368/ 1097] train: loss: 0.0770375
[Epoch 27; Iter   398/ 1097] train: loss: 0.3045099
[Epoch 27; Iter   428/ 1097] train: loss: 0.0233639
[Epoch 27; Iter   458/ 1097] train: loss: 0.0183763
[Epoch 27; Iter   488/ 1097] train: loss: 0.1355204
[Epoch 27; Iter   518/ 1097] train: loss: 0.3784868
[Epoch 27; Iter   548/ 1097] train: loss: 0.0817380
[Epoch 27; Iter   578/ 1097] train: loss: 0.1049444
[Epoch 27; Iter   608/ 1097] train: loss: 0.0189658
[Epoch 27; Iter   638/ 1097] train: loss: 0.0434230
[Epoch 27; Iter   668/ 1097] train: loss: 0.0226421
[Epoch 27; Iter   698/ 1097] train: loss: 0.1485175
[Epoch 27; Iter   728/ 1097] train: loss: 0.1821566
[Epoch 27; Iter   758/ 1097] train: loss: 0.0748267
[Epoch 27; Iter   788/ 1097] train: loss: 0.1783112
[Epoch 27; Iter   818/ 1097] train: loss: 0.0508870
[Epoch 27; Iter   848/ 1097] train: loss: 0.0146431
[Epoch 27; Iter   878/ 1097] train: loss: 0.0268391
[Epoch 27; Iter   908/ 1097] train: loss: 0.2153386
[Epoch 27; Iter   938/ 1097] train: loss: 0.0406140
[Epoch 27; Iter   968/ 1097] train: loss: 0.1096528
[Epoch 27; Iter   998/ 1097] train: loss: 0.1108338
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1490770
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0194406
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0177469
[Epoch 27] ogbg-molhiv: 0.805902 val loss: 0.187571
[Epoch 27] ogbg-molhiv: 0.775189 test loss: 0.190272
[Epoch 28; Iter    21/ 1097] train: loss: 0.2211332
[Epoch 28; Iter    51/ 1097] train: loss: 0.0815263
[Epoch 28; Iter    81/ 1097] train: loss: 0.0553378
[Epoch 28; Iter   111/ 1097] train: loss: 0.0298638
[Epoch 28; Iter   141/ 1097] train: loss: 0.0254731
[Epoch 28; Iter   171/ 1097] train: loss: 0.1564687
[Epoch 28; Iter   201/ 1097] train: loss: 0.0354782
[Epoch 28; Iter   231/ 1097] train: loss: 0.0194049
[Epoch 28; Iter   261/ 1097] train: loss: 0.0448522
[Epoch 28; Iter   291/ 1097] train: loss: 0.1683428
[Epoch 28; Iter   321/ 1097] train: loss: 0.0952644
[Epoch 28; Iter   351/ 1097] train: loss: 0.1362511
[Epoch 28; Iter   381/ 1097] train: loss: 0.0197974
[Epoch 28; Iter   411/ 1097] train: loss: 0.0893121
[Epoch 24; Iter   359/ 1097] train: loss: 0.0770666
[Epoch 24; Iter   389/ 1097] train: loss: 0.0777457
[Epoch 24; Iter   419/ 1097] train: loss: 0.3611322
[Epoch 24; Iter   449/ 1097] train: loss: 0.0797840
[Epoch 24; Iter   479/ 1097] train: loss: 0.1158400
[Epoch 24; Iter   509/ 1097] train: loss: 0.1908422
[Epoch 24; Iter   539/ 1097] train: loss: 0.0363644
[Epoch 24; Iter   569/ 1097] train: loss: 0.1873401
[Epoch 24; Iter   599/ 1097] train: loss: 0.0973071
[Epoch 24; Iter   629/ 1097] train: loss: 0.0359896
[Epoch 24; Iter   659/ 1097] train: loss: 0.0314699
[Epoch 24; Iter   689/ 1097] train: loss: 0.0097749
[Epoch 24; Iter   719/ 1097] train: loss: 0.1229805
[Epoch 24; Iter   749/ 1097] train: loss: 0.0402785
[Epoch 24; Iter   779/ 1097] train: loss: 0.2061888
[Epoch 24; Iter   809/ 1097] train: loss: 0.0961218
[Epoch 24; Iter   839/ 1097] train: loss: 0.0999214
[Epoch 24; Iter   869/ 1097] train: loss: 0.0208650
[Epoch 24; Iter   899/ 1097] train: loss: 0.2253651
[Epoch 24; Iter   929/ 1097] train: loss: 0.1534718
[Epoch 24; Iter   959/ 1097] train: loss: 0.1850304
[Epoch 24; Iter   989/ 1097] train: loss: 0.0231185
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1399087
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0695539
[Epoch 24; Iter  1079/ 1097] train: loss: 0.3055647
[Epoch 24] ogbg-molhiv: 0.808862 val loss: 0.082635
[Epoch 24] ogbg-molhiv: 0.742446 test loss: 0.123021
[Epoch 25; Iter    12/ 1097] train: loss: 0.1865995
[Epoch 25; Iter    42/ 1097] train: loss: 0.0977635
[Epoch 25; Iter    72/ 1097] train: loss: 0.0228890
[Epoch 25; Iter   102/ 1097] train: loss: 0.2362033
[Epoch 25; Iter   132/ 1097] train: loss: 0.2984686
[Epoch 25; Iter   162/ 1097] train: loss: 0.0225747
[Epoch 25; Iter   192/ 1097] train: loss: 0.0335365
[Epoch 25; Iter   222/ 1097] train: loss: 0.1270806
[Epoch 25; Iter   252/ 1097] train: loss: 0.0457801
[Epoch 25; Iter   282/ 1097] train: loss: 0.1175575
[Epoch 25; Iter   312/ 1097] train: loss: 0.0507525
[Epoch 25; Iter   342/ 1097] train: loss: 0.0422905
[Epoch 25; Iter   372/ 1097] train: loss: 0.0304593
[Epoch 25; Iter   402/ 1097] train: loss: 0.0279190
[Epoch 25; Iter   432/ 1097] train: loss: 0.0994407
[Epoch 25; Iter   462/ 1097] train: loss: 0.1260816
[Epoch 25; Iter   492/ 1097] train: loss: 0.1657140
[Epoch 25; Iter   522/ 1097] train: loss: 0.2304270
[Epoch 25; Iter   552/ 1097] train: loss: 0.1268786
[Epoch 25; Iter   582/ 1097] train: loss: 0.1009190
[Epoch 25; Iter   612/ 1097] train: loss: 0.0459953
[Epoch 25; Iter   642/ 1097] train: loss: 0.0333410
[Epoch 25; Iter   672/ 1097] train: loss: 0.0431886
[Epoch 25; Iter   702/ 1097] train: loss: 0.1197746
[Epoch 25; Iter   732/ 1097] train: loss: 0.0730605
[Epoch 25; Iter   762/ 1097] train: loss: 0.0425408
[Epoch 25; Iter   792/ 1097] train: loss: 0.0329087
[Epoch 25; Iter   822/ 1097] train: loss: 0.0218045
[Epoch 25; Iter   852/ 1097] train: loss: 0.0182522
[Epoch 25; Iter   882/ 1097] train: loss: 0.0407320
[Epoch 25; Iter   912/ 1097] train: loss: 0.0157141
[Epoch 25; Iter   942/ 1097] train: loss: 0.1844174
[Epoch 25; Iter   972/ 1097] train: loss: 0.2158473
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0284063
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0543373
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0391512
[Epoch 25; Iter  1092/ 1097] train: loss: 0.3381592
[Epoch 25] ogbg-molhiv: 0.826695 val loss: 0.202892
[Epoch 25] ogbg-molhiv: 0.744929 test loss: 0.119051
[Epoch 26; Iter    25/ 1097] train: loss: 0.0597749
[Epoch 26; Iter    55/ 1097] train: loss: 0.0168842
[Epoch 26; Iter    85/ 1097] train: loss: 0.0316188
[Epoch 26; Iter   115/ 1097] train: loss: 0.0240865
[Epoch 26; Iter   145/ 1097] train: loss: 0.2705442
[Epoch 26; Iter   175/ 1097] train: loss: 0.1358789
[Epoch 26; Iter   205/ 1097] train: loss: 0.2435702
[Epoch 26; Iter   235/ 1097] train: loss: 0.1310011
[Epoch 26; Iter   265/ 1097] train: loss: 0.2086700
[Epoch 26; Iter   295/ 1097] train: loss: 0.0638536
[Epoch 26; Iter   325/ 1097] train: loss: 0.0398455
[Epoch 26; Iter   355/ 1097] train: loss: 0.0198968
[Epoch 26; Iter   385/ 1097] train: loss: 0.0521323
[Epoch 26; Iter   415/ 1097] train: loss: 0.0553511
[Epoch 26; Iter   445/ 1097] train: loss: 0.0303724
[Epoch 26; Iter   475/ 1097] train: loss: 0.0140365
[Epoch 26; Iter   505/ 1097] train: loss: 0.0406689
[Epoch 26; Iter   535/ 1097] train: loss: 0.1113604
[Epoch 26; Iter   565/ 1097] train: loss: 0.2757433
[Epoch 26; Iter   595/ 1097] train: loss: 0.0341061
[Epoch 26; Iter   625/ 1097] train: loss: 0.0617233
[Epoch 26; Iter   655/ 1097] train: loss: 0.0437025
[Epoch 26; Iter   685/ 1097] train: loss: 0.0794413
[Epoch 26; Iter   715/ 1097] train: loss: 0.2077034
[Epoch 26; Iter   745/ 1097] train: loss: 0.0561983
[Epoch 26; Iter   775/ 1097] train: loss: 0.0329564
[Epoch 26; Iter   805/ 1097] train: loss: 0.0685569
[Epoch 26; Iter   835/ 1097] train: loss: 0.1806130
[Epoch 26; Iter   865/ 1097] train: loss: 0.0561728
[Epoch 26; Iter   895/ 1097] train: loss: 0.0230414
[Epoch 26; Iter   925/ 1097] train: loss: 0.3339702
[Epoch 26; Iter   955/ 1097] train: loss: 0.0286491
[Epoch 26; Iter   985/ 1097] train: loss: 0.0398550
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0228659
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0192710
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1659273
[Epoch 26] ogbg-molhiv: 0.818247 val loss: 0.090984
[Epoch 26] ogbg-molhiv: 0.733937 test loss: 0.127691
[Epoch 27; Iter     8/ 1097] train: loss: 0.0207737
[Epoch 27; Iter    38/ 1097] train: loss: 0.1784379
[Epoch 27; Iter    68/ 1097] train: loss: 0.3379745
[Epoch 27; Iter    98/ 1097] train: loss: 0.0280502
[Epoch 27; Iter   128/ 1097] train: loss: 0.0236454
[Epoch 27; Iter   158/ 1097] train: loss: 0.0949530
[Epoch 27; Iter   188/ 1097] train: loss: 0.1093896
[Epoch 27; Iter   218/ 1097] train: loss: 0.0265475
[Epoch 27; Iter   248/ 1097] train: loss: 0.0285176
[Epoch 27; Iter   278/ 1097] train: loss: 0.0202585
[Epoch 27; Iter   308/ 1097] train: loss: 0.0223232
[Epoch 27; Iter   338/ 1097] train: loss: 0.2256529
[Epoch 27; Iter   368/ 1097] train: loss: 0.1783865
[Epoch 27; Iter   398/ 1097] train: loss: 0.0230304
[Epoch 27; Iter   428/ 1097] train: loss: 0.0655306
[Epoch 27; Iter   458/ 1097] train: loss: 0.0149309
[Epoch 27; Iter   488/ 1097] train: loss: 0.0263609
[Epoch 27; Iter   518/ 1097] train: loss: 0.2230462
[Epoch 27; Iter   548/ 1097] train: loss: 0.0471067
[Epoch 27; Iter   578/ 1097] train: loss: 0.1183888
[Epoch 27; Iter   608/ 1097] train: loss: 0.0712832
[Epoch 27; Iter   638/ 1097] train: loss: 0.2469423
[Epoch 27; Iter   668/ 1097] train: loss: 0.1906498
[Epoch 27; Iter   698/ 1097] train: loss: 0.0289676
[Epoch 27; Iter   728/ 1097] train: loss: 0.0534140
[Epoch 27; Iter   758/ 1097] train: loss: 0.0555853
[Epoch 27; Iter   788/ 1097] train: loss: 0.0512551
[Epoch 27; Iter   818/ 1097] train: loss: 0.0191154
[Epoch 27; Iter   848/ 1097] train: loss: 0.0510753
[Epoch 27; Iter   878/ 1097] train: loss: 0.3307345
[Epoch 27; Iter   908/ 1097] train: loss: 0.1399848
[Epoch 27; Iter   938/ 1097] train: loss: 0.0839630
[Epoch 27; Iter   968/ 1097] train: loss: 0.0505264
[Epoch 27; Iter   998/ 1097] train: loss: 0.0343701
[Epoch 27; Iter  1028/ 1097] train: loss: 0.3041393
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0774509
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1674495
[Epoch 27] ogbg-molhiv: 0.827898 val loss: 0.075285
[Epoch 27] ogbg-molhiv: 0.756900 test loss: 0.121141
[Epoch 28; Iter    21/ 1097] train: loss: 0.1330653
[Epoch 28; Iter    51/ 1097] train: loss: 0.0334359
[Epoch 28; Iter    81/ 1097] train: loss: 0.1362779
[Epoch 28; Iter   111/ 1097] train: loss: 0.1021040
[Epoch 28; Iter   141/ 1097] train: loss: 0.0160104
[Epoch 28; Iter   171/ 1097] train: loss: 0.0619591
[Epoch 28; Iter   201/ 1097] train: loss: 0.0257909
[Epoch 28; Iter   231/ 1097] train: loss: 0.0160549
[Epoch 28; Iter   261/ 1097] train: loss: 0.0251201
[Epoch 28; Iter   291/ 1097] train: loss: 0.0272642
[Epoch 28; Iter   321/ 1097] train: loss: 0.0840038
[Epoch 28; Iter   351/ 1097] train: loss: 0.0162040
[Epoch 28; Iter   381/ 1097] train: loss: 0.0235980
[Epoch 28; Iter   411/ 1097] train: loss: 0.1491520
[Epoch 24; Iter   359/ 1097] train: loss: 0.0581494
[Epoch 24; Iter   389/ 1097] train: loss: 0.1239722
[Epoch 24; Iter   419/ 1097] train: loss: 0.3515302
[Epoch 24; Iter   449/ 1097] train: loss: 0.0223075
[Epoch 24; Iter   479/ 1097] train: loss: 0.0602878
[Epoch 24; Iter   509/ 1097] train: loss: 0.0312236
[Epoch 24; Iter   539/ 1097] train: loss: 0.0235666
[Epoch 24; Iter   569/ 1097] train: loss: 0.2028353
[Epoch 24; Iter   599/ 1097] train: loss: 0.1220545
[Epoch 24; Iter   629/ 1097] train: loss: 0.0198667
[Epoch 24; Iter   659/ 1097] train: loss: 0.0204562
[Epoch 24; Iter   689/ 1097] train: loss: 0.0205225
[Epoch 24; Iter   719/ 1097] train: loss: 0.0162578
[Epoch 24; Iter   749/ 1097] train: loss: 0.0374919
[Epoch 24; Iter   779/ 1097] train: loss: 0.1819403
[Epoch 24; Iter   809/ 1097] train: loss: 0.0229866
[Epoch 24; Iter   839/ 1097] train: loss: 0.1833259
[Epoch 24; Iter   869/ 1097] train: loss: 0.1879278
[Epoch 24; Iter   899/ 1097] train: loss: 0.3589522
[Epoch 24; Iter   929/ 1097] train: loss: 0.3055644
[Epoch 24; Iter   959/ 1097] train: loss: 0.0383821
[Epoch 24; Iter   989/ 1097] train: loss: 0.0256065
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1579425
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1039236
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0250033
[Epoch 24] ogbg-molhiv: 0.805357 val loss: 0.374221
[Epoch 24] ogbg-molhiv: 0.760071 test loss: 0.144947
[Epoch 25; Iter    12/ 1097] train: loss: 0.0831089
[Epoch 25; Iter    42/ 1097] train: loss: 0.1977721
[Epoch 25; Iter    72/ 1097] train: loss: 0.0300303
[Epoch 25; Iter   102/ 1097] train: loss: 0.0600938
[Epoch 25; Iter   132/ 1097] train: loss: 0.0256962
[Epoch 25; Iter   162/ 1097] train: loss: 0.0235022
[Epoch 25; Iter   192/ 1097] train: loss: 0.1669326
[Epoch 25; Iter   222/ 1097] train: loss: 0.0346315
[Epoch 25; Iter   252/ 1097] train: loss: 0.0457153
[Epoch 25; Iter   282/ 1097] train: loss: 0.1492302
[Epoch 25; Iter   312/ 1097] train: loss: 0.0404644
[Epoch 25; Iter   342/ 1097] train: loss: 0.0419415
[Epoch 25; Iter   372/ 1097] train: loss: 0.3447842
[Epoch 25; Iter   402/ 1097] train: loss: 0.0192597
[Epoch 25; Iter   432/ 1097] train: loss: 0.2884424
[Epoch 25; Iter   462/ 1097] train: loss: 0.0201372
[Epoch 25; Iter   492/ 1097] train: loss: 0.1704046
[Epoch 25; Iter   522/ 1097] train: loss: 0.0253266
[Epoch 25; Iter   552/ 1097] train: loss: 0.1315582
[Epoch 25; Iter   582/ 1097] train: loss: 0.1404865
[Epoch 25; Iter   612/ 1097] train: loss: 0.1611602
[Epoch 25; Iter   642/ 1097] train: loss: 0.1668374
[Epoch 25; Iter   672/ 1097] train: loss: 0.0251413
[Epoch 25; Iter   702/ 1097] train: loss: 0.1375941
[Epoch 25; Iter   732/ 1097] train: loss: 0.0373215
[Epoch 25; Iter   762/ 1097] train: loss: 0.1007654
[Epoch 25; Iter   792/ 1097] train: loss: 0.0210445
[Epoch 25; Iter   822/ 1097] train: loss: 0.0776025
[Epoch 25; Iter   852/ 1097] train: loss: 0.0350784
[Epoch 25; Iter   882/ 1097] train: loss: 0.0833068
[Epoch 25; Iter   912/ 1097] train: loss: 0.1965789
[Epoch 25; Iter   942/ 1097] train: loss: 0.0283076
[Epoch 25; Iter   972/ 1097] train: loss: 0.0905690
[Epoch 25; Iter  1002/ 1097] train: loss: 0.3203076
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2439954
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0248959
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1735950
[Epoch 25] ogbg-molhiv: 0.811006 val loss: 0.443342
[Epoch 25] ogbg-molhiv: 0.759254 test loss: 0.278474
[Epoch 26; Iter    25/ 1097] train: loss: 0.0437665
[Epoch 26; Iter    55/ 1097] train: loss: 0.0626193
[Epoch 26; Iter    85/ 1097] train: loss: 0.1868846
[Epoch 26; Iter   115/ 1097] train: loss: 0.2744527
[Epoch 26; Iter   145/ 1097] train: loss: 0.1003498
[Epoch 26; Iter   175/ 1097] train: loss: 0.0727499
[Epoch 26; Iter   205/ 1097] train: loss: 0.4582817
[Epoch 26; Iter   235/ 1097] train: loss: 0.0331415
[Epoch 26; Iter   265/ 1097] train: loss: 0.0353161
[Epoch 26; Iter   295/ 1097] train: loss: 0.0763783
[Epoch 26; Iter   325/ 1097] train: loss: 0.0628148
[Epoch 26; Iter   355/ 1097] train: loss: 0.0299932
[Epoch 26; Iter   385/ 1097] train: loss: 0.0509911
[Epoch 26; Iter   415/ 1097] train: loss: 0.0483848
[Epoch 26; Iter   445/ 1097] train: loss: 0.0423750
[Epoch 26; Iter   475/ 1097] train: loss: 0.0937095
[Epoch 26; Iter   505/ 1097] train: loss: 0.1180443
[Epoch 26; Iter   535/ 1097] train: loss: 0.1832215
[Epoch 26; Iter   565/ 1097] train: loss: 0.1603634
[Epoch 26; Iter   595/ 1097] train: loss: 0.0343883
[Epoch 26; Iter   625/ 1097] train: loss: 0.1177136
[Epoch 26; Iter   655/ 1097] train: loss: 0.0329292
[Epoch 26; Iter   685/ 1097] train: loss: 0.2186702
[Epoch 26; Iter   715/ 1097] train: loss: 0.0215751
[Epoch 26; Iter   745/ 1097] train: loss: 0.0174333
[Epoch 26; Iter   775/ 1097] train: loss: 0.0623602
[Epoch 26; Iter   805/ 1097] train: loss: 0.0991147
[Epoch 26; Iter   835/ 1097] train: loss: 0.2192639
[Epoch 26; Iter   865/ 1097] train: loss: 0.2189141
[Epoch 26; Iter   895/ 1097] train: loss: 0.0336753
[Epoch 26; Iter   925/ 1097] train: loss: 0.4101583
[Epoch 26; Iter   955/ 1097] train: loss: 0.0269023
[Epoch 26; Iter   985/ 1097] train: loss: 0.0951865
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0363642
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0658748
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0750848
[Epoch 26] ogbg-molhiv: 0.820562 val loss: 0.110433
[Epoch 26] ogbg-molhiv: 0.787449 test loss: 0.258272
[Epoch 27; Iter     8/ 1097] train: loss: 0.0429685
[Epoch 27; Iter    38/ 1097] train: loss: 0.1174018
[Epoch 27; Iter    68/ 1097] train: loss: 0.0394125
[Epoch 27; Iter    98/ 1097] train: loss: 0.1882034
[Epoch 27; Iter   128/ 1097] train: loss: 0.2002073
[Epoch 27; Iter   158/ 1097] train: loss: 0.0960921
[Epoch 27; Iter   188/ 1097] train: loss: 0.0216701
[Epoch 27; Iter   218/ 1097] train: loss: 0.0862854
[Epoch 27; Iter   248/ 1097] train: loss: 0.0587363
[Epoch 27; Iter   278/ 1097] train: loss: 0.0220785
[Epoch 27; Iter   308/ 1097] train: loss: 0.0267473
[Epoch 27; Iter   338/ 1097] train: loss: 0.0405703
[Epoch 27; Iter   368/ 1097] train: loss: 0.2062221
[Epoch 27; Iter   398/ 1097] train: loss: 0.0166767
[Epoch 27; Iter   428/ 1097] train: loss: 0.1268810
[Epoch 27; Iter   458/ 1097] train: loss: 0.0338967
[Epoch 27; Iter   488/ 1097] train: loss: 0.0861186
[Epoch 27; Iter   518/ 1097] train: loss: 0.1739815
[Epoch 27; Iter   548/ 1097] train: loss: 0.1159967
[Epoch 27; Iter   578/ 1097] train: loss: 0.1371313
[Epoch 27; Iter   608/ 1097] train: loss: 0.1746561
[Epoch 27; Iter   638/ 1097] train: loss: 0.0334454
[Epoch 27; Iter   668/ 1097] train: loss: 0.0755617
[Epoch 27; Iter   698/ 1097] train: loss: 0.0322174
[Epoch 27; Iter   728/ 1097] train: loss: 0.2399371
[Epoch 27; Iter   758/ 1097] train: loss: 0.0210261
[Epoch 27; Iter   788/ 1097] train: loss: 0.0512447
[Epoch 27; Iter   818/ 1097] train: loss: 0.1217193
[Epoch 27; Iter   848/ 1097] train: loss: 0.1351848
[Epoch 27; Iter   878/ 1097] train: loss: 0.0446506
[Epoch 27; Iter   908/ 1097] train: loss: 0.0243005
[Epoch 27; Iter   938/ 1097] train: loss: 0.1894028
[Epoch 27; Iter   968/ 1097] train: loss: 0.0242706
[Epoch 27; Iter   998/ 1097] train: loss: 0.1307086
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0171564
[Epoch 27; Iter  1058/ 1097] train: loss: 0.3598230
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1537343
[Epoch 27] ogbg-molhiv: 0.828486 val loss: 0.161695
[Epoch 27] ogbg-molhiv: 0.753661 test loss: 0.189229
[Epoch 28; Iter    21/ 1097] train: loss: 0.0199056
[Epoch 28; Iter    51/ 1097] train: loss: 0.0409825
[Epoch 28; Iter    81/ 1097] train: loss: 0.0212259
[Epoch 28; Iter   111/ 1097] train: loss: 0.0937548
[Epoch 28; Iter   141/ 1097] train: loss: 0.1887158
[Epoch 28; Iter   171/ 1097] train: loss: 0.1881714
[Epoch 28; Iter   201/ 1097] train: loss: 0.1229717
[Epoch 28; Iter   231/ 1097] train: loss: 0.1017725
[Epoch 28; Iter   261/ 1097] train: loss: 0.1241851
[Epoch 28; Iter   291/ 1097] train: loss: 0.0244948
[Epoch 28; Iter   321/ 1097] train: loss: 0.0280280
[Epoch 28; Iter   351/ 1097] train: loss: 0.0234079
[Epoch 28; Iter   381/ 1097] train: loss: 0.2700150
[Epoch 28; Iter   411/ 1097] train: loss: 0.0172039
[Epoch 28; Iter   441/ 1097] train: loss: 0.0467139
[Epoch 28; Iter   471/ 1097] train: loss: 0.0362464
[Epoch 28; Iter   501/ 1097] train: loss: 0.0429080
[Epoch 28; Iter   531/ 1097] train: loss: 0.0087768
[Epoch 28; Iter   561/ 1097] train: loss: 0.0601319
[Epoch 28; Iter   591/ 1097] train: loss: 0.0373814
[Epoch 28; Iter   621/ 1097] train: loss: 0.0160189
[Epoch 28; Iter   651/ 1097] train: loss: 0.0455727
[Epoch 28; Iter   681/ 1097] train: loss: 0.0469590
[Epoch 28; Iter   711/ 1097] train: loss: 0.0407245
[Epoch 28; Iter   741/ 1097] train: loss: 0.0061179
[Epoch 28; Iter   771/ 1097] train: loss: 0.0505595
[Epoch 28; Iter   801/ 1097] train: loss: 0.0158655
[Epoch 28; Iter   831/ 1097] train: loss: 0.0523718
[Epoch 28; Iter   861/ 1097] train: loss: 0.0247399
[Epoch 28; Iter   891/ 1097] train: loss: 0.0080597
[Epoch 28; Iter   921/ 1097] train: loss: 0.0049321
[Epoch 28; Iter   951/ 1097] train: loss: 0.0084131
[Epoch 28; Iter   981/ 1097] train: loss: 0.0201105
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0858626
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0032336
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0077171
[Epoch 28] ogbg-molhiv: 0.730857 val loss: 0.617987
[Epoch 28] ogbg-molhiv: 0.581330 test loss: 0.675339
[Epoch 29; Iter     4/ 1097] train: loss: 0.0321829
[Epoch 29; Iter    34/ 1097] train: loss: 0.0312311
[Epoch 29; Iter    64/ 1097] train: loss: 0.0132241
[Epoch 29; Iter    94/ 1097] train: loss: 0.0016680
[Epoch 29; Iter   124/ 1097] train: loss: 0.0123077
[Epoch 29; Iter   154/ 1097] train: loss: 0.0077809
[Epoch 29; Iter   184/ 1097] train: loss: 0.0011127
[Epoch 29; Iter   214/ 1097] train: loss: 0.0114346
[Epoch 29; Iter   244/ 1097] train: loss: 0.0532165
[Epoch 29; Iter   274/ 1097] train: loss: 0.0423929
[Epoch 29; Iter   304/ 1097] train: loss: 0.0072545
[Epoch 29; Iter   334/ 1097] train: loss: 0.0381676
[Epoch 29; Iter   364/ 1097] train: loss: 0.0477421
[Epoch 29; Iter   394/ 1097] train: loss: 0.0375604
[Epoch 29; Iter   424/ 1097] train: loss: 0.0019081
[Epoch 29; Iter   454/ 1097] train: loss: 0.0086377
[Epoch 29; Iter   484/ 1097] train: loss: 0.0415934
[Epoch 29; Iter   514/ 1097] train: loss: 0.0127432
[Epoch 29; Iter   544/ 1097] train: loss: 0.0042168
[Epoch 29; Iter   574/ 1097] train: loss: 0.0195899
[Epoch 29; Iter   604/ 1097] train: loss: 0.0050188
[Epoch 29; Iter   634/ 1097] train: loss: 0.0028808
[Epoch 29; Iter   664/ 1097] train: loss: 0.0282952
[Epoch 29; Iter   694/ 1097] train: loss: 0.0269592
[Epoch 29; Iter   724/ 1097] train: loss: 0.0105978
[Epoch 29; Iter   754/ 1097] train: loss: 0.0457212
[Epoch 29; Iter   784/ 1097] train: loss: 0.0032786
[Epoch 29; Iter   814/ 1097] train: loss: 0.0031068
[Epoch 29; Iter   844/ 1097] train: loss: 0.0143764
[Epoch 29; Iter   874/ 1097] train: loss: 0.0080915
[Epoch 29; Iter   904/ 1097] train: loss: 0.2416672
[Epoch 29; Iter   934/ 1097] train: loss: 0.0014945
[Epoch 29; Iter   964/ 1097] train: loss: 0.0422578
[Epoch 29; Iter   994/ 1097] train: loss: 0.0743832
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0102367
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0130600
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0348756
[Epoch 29] ogbg-molhiv: 0.650108 val loss: 59.689615
[Epoch 29] ogbg-molhiv: 0.584078 test loss: 55.640243
[Epoch 30; Iter    17/ 1097] train: loss: 0.0092826
[Epoch 30; Iter    47/ 1097] train: loss: 0.1003981
[Epoch 30; Iter    77/ 1097] train: loss: 0.0130082
[Epoch 30; Iter   107/ 1097] train: loss: 0.0207210
[Epoch 30; Iter   137/ 1097] train: loss: 0.0013060
[Epoch 30; Iter   167/ 1097] train: loss: 0.0141983
[Epoch 30; Iter   197/ 1097] train: loss: 0.0194784
[Epoch 30; Iter   227/ 1097] train: loss: 0.0036400
[Epoch 30; Iter   257/ 1097] train: loss: 0.0023301
[Epoch 30; Iter   287/ 1097] train: loss: 0.0047939
[Epoch 30; Iter   317/ 1097] train: loss: 0.0129452
[Epoch 30; Iter   347/ 1097] train: loss: 0.0076446
[Epoch 30; Iter   377/ 1097] train: loss: 0.0019168
[Epoch 30; Iter   407/ 1097] train: loss: 0.0214940
[Epoch 30; Iter   437/ 1097] train: loss: 0.0637457
[Epoch 30; Iter   467/ 1097] train: loss: 0.0038914
[Epoch 30; Iter   497/ 1097] train: loss: 0.0182628
[Epoch 30; Iter   527/ 1097] train: loss: 0.0116619
[Epoch 30; Iter   557/ 1097] train: loss: 0.0049638
[Epoch 30; Iter   587/ 1097] train: loss: 0.0031505
[Epoch 30; Iter   617/ 1097] train: loss: 0.0125995
[Epoch 30; Iter   647/ 1097] train: loss: 0.0092711
[Epoch 30; Iter   677/ 1097] train: loss: 0.0008184
[Epoch 30; Iter   707/ 1097] train: loss: 0.0401054
[Epoch 30; Iter   737/ 1097] train: loss: 0.0060758
[Epoch 30; Iter   767/ 1097] train: loss: 0.0045671
[Epoch 30; Iter   797/ 1097] train: loss: 0.0034211
[Epoch 30; Iter   827/ 1097] train: loss: 0.0028307
[Epoch 30; Iter   857/ 1097] train: loss: 0.0014314
[Epoch 30; Iter   887/ 1097] train: loss: 0.1088803
[Epoch 30; Iter   917/ 1097] train: loss: 0.0174470
[Epoch 30; Iter   947/ 1097] train: loss: 0.0184508
[Epoch 30; Iter   977/ 1097] train: loss: 0.0235117
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0016413
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0036806
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0194464
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0117996
[Epoch 30] ogbg-molhiv: 0.689848 val loss: 36.917988
[Epoch 30] ogbg-molhiv: 0.558385 test loss: 40.913382
[Epoch 31; Iter    30/ 1097] train: loss: 0.0015855
[Epoch 31; Iter    60/ 1097] train: loss: 0.0007650
[Epoch 31; Iter    90/ 1097] train: loss: 0.0025850
[Epoch 31; Iter   120/ 1097] train: loss: 0.0581182
[Epoch 31; Iter   150/ 1097] train: loss: 0.0057019
[Epoch 31; Iter   180/ 1097] train: loss: 0.0038187
[Epoch 31; Iter   210/ 1097] train: loss: 0.0075616
[Epoch 31; Iter   240/ 1097] train: loss: 0.0231652
[Epoch 31; Iter   270/ 1097] train: loss: 0.0025336
[Epoch 31; Iter   300/ 1097] train: loss: 0.0108026
[Epoch 31; Iter   330/ 1097] train: loss: 0.0044566
[Epoch 31; Iter   360/ 1097] train: loss: 0.0007030
[Epoch 31; Iter   390/ 1097] train: loss: 0.0242880
[Epoch 31; Iter   420/ 1097] train: loss: 0.0030512
[Epoch 31; Iter   450/ 1097] train: loss: 0.0049290
[Epoch 31; Iter   480/ 1097] train: loss: 0.0047472
[Epoch 31; Iter   510/ 1097] train: loss: 0.0025172
[Epoch 31; Iter   540/ 1097] train: loss: 0.0730093
[Epoch 31; Iter   570/ 1097] train: loss: 0.0396592
[Epoch 31; Iter   600/ 1097] train: loss: 0.0080835
[Epoch 31; Iter   630/ 1097] train: loss: 0.0026790
[Epoch 31; Iter   660/ 1097] train: loss: 0.0018511
[Epoch 31; Iter   690/ 1097] train: loss: 0.0072292
[Epoch 31; Iter   720/ 1097] train: loss: 0.0017907
[Epoch 31; Iter   750/ 1097] train: loss: 0.0013716
[Epoch 31; Iter   780/ 1097] train: loss: 0.0499131
[Epoch 31; Iter   810/ 1097] train: loss: 0.0046437
[Epoch 31; Iter   840/ 1097] train: loss: 0.0013953
[Epoch 31; Iter   870/ 1097] train: loss: 0.0067111
[Epoch 31; Iter   900/ 1097] train: loss: 0.0335737
[Epoch 31; Iter   930/ 1097] train: loss: 0.0138374
[Epoch 31; Iter   960/ 1097] train: loss: 0.0003627
[Epoch 31; Iter   990/ 1097] train: loss: 0.0037450
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0311168
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0019445
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0101274
[Epoch 31] ogbg-molhiv: 0.649486 val loss: 0.835474
[Epoch 31] ogbg-molhiv: 0.557237 test loss: 0.990407
[Epoch 32; Iter    13/ 1097] train: loss: 0.0281808
[Epoch 32; Iter    43/ 1097] train: loss: 0.0053349
[Epoch 32; Iter    73/ 1097] train: loss: 0.0025136
[Epoch 32; Iter   103/ 1097] train: loss: 0.0009458
[Epoch 32; Iter   133/ 1097] train: loss: 0.0020783
[Epoch 32; Iter   163/ 1097] train: loss: 0.0049852
[Epoch 32; Iter   193/ 1097] train: loss: 0.0059501
[Epoch 32; Iter   223/ 1097] train: loss: 0.0023099
[Epoch 32; Iter   253/ 1097] train: loss: 0.0025150
[Epoch 32; Iter   283/ 1097] train: loss: 0.0094851
[Epoch 32; Iter   313/ 1097] train: loss: 0.0207793
[Epoch 32; Iter   343/ 1097] train: loss: 0.0073536
[Epoch 32; Iter   373/ 1097] train: loss: 0.0247199
[Epoch 32; Iter   403/ 1097] train: loss: 0.0006918
[Epoch 32; Iter   433/ 1097] train: loss: 0.0043165
[Epoch 32; Iter   463/ 1097] train: loss: 0.0188218
[Epoch 32; Iter   493/ 1097] train: loss: 0.0021828
[Epoch 28; Iter   441/ 1097] train: loss: 0.5143956
[Epoch 28; Iter   471/ 1097] train: loss: 0.0043470
[Epoch 28; Iter   501/ 1097] train: loss: 0.0439511
[Epoch 28; Iter   531/ 1097] train: loss: 0.0461329
[Epoch 28; Iter   561/ 1097] train: loss: 0.1320052
[Epoch 28; Iter   591/ 1097] train: loss: 0.0099621
[Epoch 28; Iter   621/ 1097] train: loss: 0.0423652
[Epoch 28; Iter   651/ 1097] train: loss: 0.0163372
[Epoch 28; Iter   681/ 1097] train: loss: 0.0210426
[Epoch 28; Iter   711/ 1097] train: loss: 0.0107918
[Epoch 28; Iter   741/ 1097] train: loss: 0.0216861
[Epoch 28; Iter   771/ 1097] train: loss: 0.0186969
[Epoch 28; Iter   801/ 1097] train: loss: 0.0219400
[Epoch 28; Iter   831/ 1097] train: loss: 0.0236502
[Epoch 28; Iter   861/ 1097] train: loss: 0.0651047
[Epoch 28; Iter   891/ 1097] train: loss: 0.0381378
[Epoch 28; Iter   921/ 1097] train: loss: 0.0195334
[Epoch 28; Iter   951/ 1097] train: loss: 0.0299117
[Epoch 28; Iter   981/ 1097] train: loss: 0.0131739
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0367180
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0527004
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0035471
[Epoch 28] ogbg-molhiv: 0.767168 val loss: 1.159818
[Epoch 28] ogbg-molhiv: 0.743184 test loss: 1.442300
[Epoch 29; Iter     4/ 1097] train: loss: 0.0314015
[Epoch 29; Iter    34/ 1097] train: loss: 0.0215504
[Epoch 29; Iter    64/ 1097] train: loss: 0.0685659
[Epoch 29; Iter    94/ 1097] train: loss: 0.0046336
[Epoch 29; Iter   124/ 1097] train: loss: 0.1640756
[Epoch 29; Iter   154/ 1097] train: loss: 0.2276980
[Epoch 29; Iter   184/ 1097] train: loss: 0.0081135
[Epoch 29; Iter   214/ 1097] train: loss: 0.0209386
[Epoch 29; Iter   244/ 1097] train: loss: 0.0465754
[Epoch 29; Iter   274/ 1097] train: loss: 0.0091670
[Epoch 29; Iter   304/ 1097] train: loss: 0.0709318
[Epoch 29; Iter   334/ 1097] train: loss: 0.1145207
[Epoch 29; Iter   364/ 1097] train: loss: 0.0094746
[Epoch 29; Iter   394/ 1097] train: loss: 0.0685382
[Epoch 29; Iter   424/ 1097] train: loss: 0.0511813
[Epoch 29; Iter   454/ 1097] train: loss: 0.0199461
[Epoch 29; Iter   484/ 1097] train: loss: 0.1338935
[Epoch 29; Iter   514/ 1097] train: loss: 0.0141603
[Epoch 29; Iter   544/ 1097] train: loss: 0.0328659
[Epoch 29; Iter   574/ 1097] train: loss: 0.0270189
[Epoch 29; Iter   604/ 1097] train: loss: 0.0760007
[Epoch 29; Iter   634/ 1097] train: loss: 0.1286820
[Epoch 29; Iter   664/ 1097] train: loss: 0.0208681
[Epoch 29; Iter   694/ 1097] train: loss: 0.0193626
[Epoch 29; Iter   724/ 1097] train: loss: 0.0618451
[Epoch 29; Iter   754/ 1097] train: loss: 0.0371977
[Epoch 29; Iter   784/ 1097] train: loss: 0.0182237
[Epoch 29; Iter   814/ 1097] train: loss: 0.0656947
[Epoch 29; Iter   844/ 1097] train: loss: 0.0868004
[Epoch 29; Iter   874/ 1097] train: loss: 0.3036495
[Epoch 29; Iter   904/ 1097] train: loss: 0.0344325
[Epoch 29; Iter   934/ 1097] train: loss: 0.1205635
[Epoch 29; Iter   964/ 1097] train: loss: 0.0402417
[Epoch 29; Iter   994/ 1097] train: loss: 0.0239223
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0133124
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0164351
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0066498
[Epoch 29] ogbg-molhiv: 0.696628 val loss: 1.015747
[Epoch 29] ogbg-molhiv: 0.696914 test loss: 0.531318
[Epoch 30; Iter    17/ 1097] train: loss: 0.0216850
[Epoch 30; Iter    47/ 1097] train: loss: 0.0683089
[Epoch 30; Iter    77/ 1097] train: loss: 0.0256609
[Epoch 30; Iter   107/ 1097] train: loss: 0.0494590
[Epoch 30; Iter   137/ 1097] train: loss: 0.0743841
[Epoch 30; Iter   167/ 1097] train: loss: 0.0353800
[Epoch 30; Iter   197/ 1097] train: loss: 0.0110546
[Epoch 30; Iter   227/ 1097] train: loss: 0.0295529
[Epoch 30; Iter   257/ 1097] train: loss: 0.0233643
[Epoch 30; Iter   287/ 1097] train: loss: 0.0068140
[Epoch 30; Iter   317/ 1097] train: loss: 0.1292697
[Epoch 30; Iter   347/ 1097] train: loss: 0.0129824
[Epoch 30; Iter   377/ 1097] train: loss: 0.1675406
[Epoch 30; Iter   407/ 1097] train: loss: 0.0395976
[Epoch 30; Iter   437/ 1097] train: loss: 0.0058860
[Epoch 30; Iter   467/ 1097] train: loss: 0.0193115
[Epoch 30; Iter   497/ 1097] train: loss: 0.0384262
[Epoch 30; Iter   527/ 1097] train: loss: 0.0649894
[Epoch 30; Iter   557/ 1097] train: loss: 0.1534676
[Epoch 30; Iter   587/ 1097] train: loss: 0.1222657
[Epoch 30; Iter   617/ 1097] train: loss: 0.0060803
[Epoch 30; Iter   647/ 1097] train: loss: 0.0057023
[Epoch 30; Iter   677/ 1097] train: loss: 0.1015224
[Epoch 30; Iter   707/ 1097] train: loss: 0.0061271
[Epoch 30; Iter   737/ 1097] train: loss: 0.0048131
[Epoch 30; Iter   767/ 1097] train: loss: 0.1695773
[Epoch 30; Iter   797/ 1097] train: loss: 0.1979513
[Epoch 30; Iter   827/ 1097] train: loss: 0.2320467
[Epoch 30; Iter   857/ 1097] train: loss: 0.1270124
[Epoch 30; Iter   887/ 1097] train: loss: 0.0114559
[Epoch 30; Iter   917/ 1097] train: loss: 0.0937870
[Epoch 30; Iter   947/ 1097] train: loss: 0.0256697
[Epoch 30; Iter   977/ 1097] train: loss: 0.0224580
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0366361
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0701952
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0219104
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0695806
[Epoch 30] ogbg-molhiv: 0.773614 val loss: 6.000497
[Epoch 30] ogbg-molhiv: 0.729908 test loss: 3.253111
[Epoch 31; Iter    30/ 1097] train: loss: 0.0076341
[Epoch 31; Iter    60/ 1097] train: loss: 0.0087240
[Epoch 31; Iter    90/ 1097] train: loss: 0.0021464
[Epoch 31; Iter   120/ 1097] train: loss: 0.0138810
[Epoch 31; Iter   150/ 1097] train: loss: 0.1247526
[Epoch 31; Iter   180/ 1097] train: loss: 0.0120763
[Epoch 31; Iter   210/ 1097] train: loss: 0.0138432
[Epoch 31; Iter   240/ 1097] train: loss: 0.0102548
[Epoch 31; Iter   270/ 1097] train: loss: 0.0038929
[Epoch 31; Iter   300/ 1097] train: loss: 0.1133449
[Epoch 31; Iter   330/ 1097] train: loss: 0.1642344
[Epoch 31; Iter   360/ 1097] train: loss: 0.2260329
[Epoch 31; Iter   390/ 1097] train: loss: 0.0270305
[Epoch 31; Iter   420/ 1097] train: loss: 0.2309914
[Epoch 31; Iter   450/ 1097] train: loss: 0.0132984
[Epoch 31; Iter   480/ 1097] train: loss: 0.2668864
[Epoch 31; Iter   510/ 1097] train: loss: 0.0430567
[Epoch 31; Iter   540/ 1097] train: loss: 0.1466693
[Epoch 31; Iter   570/ 1097] train: loss: 0.1129404
[Epoch 31; Iter   600/ 1097] train: loss: 0.0097794
[Epoch 31; Iter   630/ 1097] train: loss: 0.0189981
[Epoch 31; Iter   660/ 1097] train: loss: 0.0048230
[Epoch 31; Iter   690/ 1097] train: loss: 0.0081857
[Epoch 31; Iter   720/ 1097] train: loss: 0.0203627
[Epoch 31; Iter   750/ 1097] train: loss: 0.0151679
[Epoch 31; Iter   780/ 1097] train: loss: 0.0094029
[Epoch 31; Iter   810/ 1097] train: loss: 0.0420437
[Epoch 31; Iter   840/ 1097] train: loss: 0.1942806
[Epoch 31; Iter   870/ 1097] train: loss: 0.0740661
[Epoch 31; Iter   900/ 1097] train: loss: 0.0053574
[Epoch 31; Iter   930/ 1097] train: loss: 0.0076023
[Epoch 31; Iter   960/ 1097] train: loss: 0.0326044
[Epoch 31; Iter   990/ 1097] train: loss: 0.0317723
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1213836
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0168929
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0205730
[Epoch 31] ogbg-molhiv: 0.755364 val loss: 3.010541
[Epoch 31] ogbg-molhiv: 0.729663 test loss: 2.020354
[Epoch 32; Iter    13/ 1097] train: loss: 0.0263290
[Epoch 32; Iter    43/ 1097] train: loss: 0.1731129
[Epoch 32; Iter    73/ 1097] train: loss: 0.0047192
[Epoch 32; Iter   103/ 1097] train: loss: 0.0264618
[Epoch 32; Iter   133/ 1097] train: loss: 0.0036413
[Epoch 32; Iter   163/ 1097] train: loss: 0.0160140
[Epoch 32; Iter   193/ 1097] train: loss: 0.0537446
[Epoch 32; Iter   223/ 1097] train: loss: 0.0148187
[Epoch 32; Iter   253/ 1097] train: loss: 0.0425354
[Epoch 32; Iter   283/ 1097] train: loss: 0.0425824
[Epoch 32; Iter   313/ 1097] train: loss: 0.0182914
[Epoch 32; Iter   343/ 1097] train: loss: 0.0755306
[Epoch 32; Iter   373/ 1097] train: loss: 0.0495081
[Epoch 32; Iter   403/ 1097] train: loss: 0.0574493
[Epoch 32; Iter   433/ 1097] train: loss: 0.0135443
[Epoch 32; Iter   463/ 1097] train: loss: 0.1327411
[Epoch 32; Iter   493/ 1097] train: loss: 0.0500803
[Epoch 28; Iter   441/ 1097] train: loss: 0.0032701
[Epoch 28; Iter   471/ 1097] train: loss: 0.0860522
[Epoch 28; Iter   501/ 1097] train: loss: 0.0135296
[Epoch 28; Iter   531/ 1097] train: loss: 0.0678299
[Epoch 28; Iter   561/ 1097] train: loss: 0.0635752
[Epoch 28; Iter   591/ 1097] train: loss: 0.0415139
[Epoch 28; Iter   621/ 1097] train: loss: 0.1192782
[Epoch 28; Iter   651/ 1097] train: loss: 0.0061545
[Epoch 28; Iter   681/ 1097] train: loss: 0.0217796
[Epoch 28; Iter   711/ 1097] train: loss: 0.0318664
[Epoch 28; Iter   741/ 1097] train: loss: 0.0514175
[Epoch 28; Iter   771/ 1097] train: loss: 0.0225835
[Epoch 28; Iter   801/ 1097] train: loss: 0.3092381
[Epoch 28; Iter   831/ 1097] train: loss: 0.0065283
[Epoch 28; Iter   861/ 1097] train: loss: 0.0869392
[Epoch 28; Iter   891/ 1097] train: loss: 0.1401718
[Epoch 28; Iter   921/ 1097] train: loss: 0.0410252
[Epoch 28; Iter   951/ 1097] train: loss: 0.0086385
[Epoch 28; Iter   981/ 1097] train: loss: 0.0061067
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0116392
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0456835
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0251624
[Epoch 28] ogbg-molhiv: 0.741163 val loss: 0.146130
[Epoch 28] ogbg-molhiv: 0.672541 test loss: 0.211292
[Epoch 29; Iter     4/ 1097] train: loss: 0.0108999
[Epoch 29; Iter    34/ 1097] train: loss: 0.0287402
[Epoch 29; Iter    64/ 1097] train: loss: 0.2438993
[Epoch 29; Iter    94/ 1097] train: loss: 0.0092565
[Epoch 29; Iter   124/ 1097] train: loss: 0.0040495
[Epoch 29; Iter   154/ 1097] train: loss: 0.0186374
[Epoch 29; Iter   184/ 1097] train: loss: 0.0046808
[Epoch 29; Iter   214/ 1097] train: loss: 0.0179735
[Epoch 29; Iter   244/ 1097] train: loss: 0.0056363
[Epoch 29; Iter   274/ 1097] train: loss: 0.0075549
[Epoch 29; Iter   304/ 1097] train: loss: 0.0218778
[Epoch 29; Iter   334/ 1097] train: loss: 0.0086057
[Epoch 29; Iter   364/ 1097] train: loss: 0.0284783
[Epoch 29; Iter   394/ 1097] train: loss: 0.0294447
[Epoch 29; Iter   424/ 1097] train: loss: 0.0564977
[Epoch 29; Iter   454/ 1097] train: loss: 0.0071138
[Epoch 29; Iter   484/ 1097] train: loss: 0.0023320
[Epoch 29; Iter   514/ 1097] train: loss: 0.0230066
[Epoch 29; Iter   544/ 1097] train: loss: 0.0129875
[Epoch 29; Iter   574/ 1097] train: loss: 0.0278692
[Epoch 29; Iter   604/ 1097] train: loss: 0.0337876
[Epoch 29; Iter   634/ 1097] train: loss: 0.0025797
[Epoch 29; Iter   664/ 1097] train: loss: 0.0280783
[Epoch 29; Iter   694/ 1097] train: loss: 0.0265716
[Epoch 29; Iter   724/ 1097] train: loss: 0.0202056
[Epoch 29; Iter   754/ 1097] train: loss: 0.0114397
[Epoch 29; Iter   784/ 1097] train: loss: 0.0352424
[Epoch 29; Iter   814/ 1097] train: loss: 0.0800153
[Epoch 29; Iter   844/ 1097] train: loss: 0.0052729
[Epoch 29; Iter   874/ 1097] train: loss: 0.0113278
[Epoch 29; Iter   904/ 1097] train: loss: 0.0246034
[Epoch 29; Iter   934/ 1097] train: loss: 0.0581551
[Epoch 29; Iter   964/ 1097] train: loss: 0.0060691
[Epoch 29; Iter   994/ 1097] train: loss: 0.0831419
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0104344
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0044551
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0692808
[Epoch 29] ogbg-molhiv: 0.759994 val loss: 0.178678
[Epoch 29] ogbg-molhiv: 0.690243 test loss: 0.255088
[Epoch 30; Iter    17/ 1097] train: loss: 0.0162925
[Epoch 30; Iter    47/ 1097] train: loss: 0.0072429
[Epoch 30; Iter    77/ 1097] train: loss: 0.0074432
[Epoch 30; Iter   107/ 1097] train: loss: 0.0073436
[Epoch 30; Iter   137/ 1097] train: loss: 0.0085868
[Epoch 30; Iter   167/ 1097] train: loss: 0.0092433
[Epoch 30; Iter   197/ 1097] train: loss: 0.0710589
[Epoch 30; Iter   227/ 1097] train: loss: 0.0145762
[Epoch 30; Iter   257/ 1097] train: loss: 0.0625727
[Epoch 30; Iter   287/ 1097] train: loss: 0.0015590
[Epoch 30; Iter   317/ 1097] train: loss: 0.0340743
[Epoch 30; Iter   347/ 1097] train: loss: 0.0026793
[Epoch 30; Iter   377/ 1097] train: loss: 0.0385995
[Epoch 30; Iter   407/ 1097] train: loss: 0.0169563
[Epoch 30; Iter   437/ 1097] train: loss: 0.0053851
[Epoch 30; Iter   467/ 1097] train: loss: 0.0152670
[Epoch 30; Iter   497/ 1097] train: loss: 0.0068230
[Epoch 30; Iter   527/ 1097] train: loss: 0.1060857
[Epoch 30; Iter   557/ 1097] train: loss: 0.0147146
[Epoch 30; Iter   587/ 1097] train: loss: 0.0355294
[Epoch 30; Iter   617/ 1097] train: loss: 0.0008887
[Epoch 30; Iter   647/ 1097] train: loss: 0.0063745
[Epoch 30; Iter   677/ 1097] train: loss: 0.0085868
[Epoch 30; Iter   707/ 1097] train: loss: 0.0035557
[Epoch 30; Iter   737/ 1097] train: loss: 0.0352907
[Epoch 30; Iter   767/ 1097] train: loss: 0.0028171
[Epoch 30; Iter   797/ 1097] train: loss: 0.0121029
[Epoch 30; Iter   827/ 1097] train: loss: 0.0238360
[Epoch 30; Iter   857/ 1097] train: loss: 0.0032070
[Epoch 30; Iter   887/ 1097] train: loss: 0.0016571
[Epoch 30; Iter   917/ 1097] train: loss: 0.0016400
[Epoch 30; Iter   947/ 1097] train: loss: 0.0142527
[Epoch 30; Iter   977/ 1097] train: loss: 0.0044235
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0020426
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0082794
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0088370
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0014645
[Epoch 30] ogbg-molhiv: 0.780696 val loss: 1.049746
[Epoch 30] ogbg-molhiv: 0.691690 test loss: 0.705538
[Epoch 31; Iter    30/ 1097] train: loss: 0.0097701
[Epoch 31; Iter    60/ 1097] train: loss: 0.0040424
[Epoch 31; Iter    90/ 1097] train: loss: 0.0018870
[Epoch 31; Iter   120/ 1097] train: loss: 0.0058516
[Epoch 31; Iter   150/ 1097] train: loss: 0.0019274
[Epoch 31; Iter   180/ 1097] train: loss: 0.0100670
[Epoch 31; Iter   210/ 1097] train: loss: 0.0062776
[Epoch 31; Iter   240/ 1097] train: loss: 0.0004732
[Epoch 31; Iter   270/ 1097] train: loss: 0.0386603
[Epoch 31; Iter   300/ 1097] train: loss: 0.0353656
[Epoch 31; Iter   330/ 1097] train: loss: 0.0023234
[Epoch 31; Iter   360/ 1097] train: loss: 0.0027577
[Epoch 31; Iter   390/ 1097] train: loss: 0.0027223
[Epoch 31; Iter   420/ 1097] train: loss: 0.0268934
[Epoch 31; Iter   450/ 1097] train: loss: 0.0368288
[Epoch 31; Iter   480/ 1097] train: loss: 0.0007676
[Epoch 31; Iter   510/ 1097] train: loss: 0.0012467
[Epoch 31; Iter   540/ 1097] train: loss: 0.0020511
[Epoch 31; Iter   570/ 1097] train: loss: 0.0104072
[Epoch 31; Iter   600/ 1097] train: loss: 0.0269631
[Epoch 31; Iter   630/ 1097] train: loss: 0.0276243
[Epoch 31; Iter   660/ 1097] train: loss: 0.0201106
[Epoch 31; Iter   690/ 1097] train: loss: 0.0016372
[Epoch 31; Iter   720/ 1097] train: loss: 0.0007441
[Epoch 31; Iter   750/ 1097] train: loss: 0.0312488
[Epoch 31; Iter   780/ 1097] train: loss: 0.0818811
[Epoch 31; Iter   810/ 1097] train: loss: 0.0428571
[Epoch 31; Iter   840/ 1097] train: loss: 0.0021474
[Epoch 31; Iter   870/ 1097] train: loss: 0.0064766
[Epoch 31; Iter   900/ 1097] train: loss: 0.0073256
[Epoch 31; Iter   930/ 1097] train: loss: 0.0025049
[Epoch 31; Iter   960/ 1097] train: loss: 0.0036067
[Epoch 31; Iter   990/ 1097] train: loss: 0.0081166
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0402768
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0147785
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0183259
[Epoch 31] ogbg-molhiv: 0.748365 val loss: 1.395244
[Epoch 31] ogbg-molhiv: 0.640005 test loss: 1.491079
[Epoch 32; Iter    13/ 1097] train: loss: 0.0552676
[Epoch 32; Iter    43/ 1097] train: loss: 0.0138343
[Epoch 32; Iter    73/ 1097] train: loss: 0.0071487
[Epoch 32; Iter   103/ 1097] train: loss: 0.0032269
[Epoch 32; Iter   133/ 1097] train: loss: 0.0101974
[Epoch 32; Iter   163/ 1097] train: loss: 0.0008850
[Epoch 32; Iter   193/ 1097] train: loss: 0.0091108
[Epoch 32; Iter   223/ 1097] train: loss: 0.0144167
[Epoch 32; Iter   253/ 1097] train: loss: 0.0026123
[Epoch 32; Iter   283/ 1097] train: loss: 0.0179498
[Epoch 32; Iter   313/ 1097] train: loss: 0.0089468
[Epoch 32; Iter   343/ 1097] train: loss: 0.0247815
[Epoch 32; Iter   373/ 1097] train: loss: 0.0009044
[Epoch 32; Iter   403/ 1097] train: loss: 0.0212661
[Epoch 32; Iter   433/ 1097] train: loss: 0.0071028
[Epoch 32; Iter   463/ 1097] train: loss: 0.0047713
[Epoch 32; Iter   493/ 1097] train: loss: 0.0031685
[Epoch 32; Iter   523/ 1097] train: loss: 0.0293281
[Epoch 32; Iter   553/ 1097] train: loss: 0.0242742
[Epoch 32; Iter   583/ 1097] train: loss: 0.0130909
[Epoch 32; Iter   613/ 1097] train: loss: 0.1629031
[Epoch 32; Iter   643/ 1097] train: loss: 0.0048134
[Epoch 32; Iter   673/ 1097] train: loss: 0.0077155
[Epoch 32; Iter   703/ 1097] train: loss: 0.0464134
[Epoch 32; Iter   733/ 1097] train: loss: 0.0091978
[Epoch 32; Iter   763/ 1097] train: loss: 0.0040308
[Epoch 32; Iter   793/ 1097] train: loss: 0.0199731
[Epoch 32; Iter   823/ 1097] train: loss: 0.0315690
[Epoch 32; Iter   853/ 1097] train: loss: 0.0099981
[Epoch 32; Iter   883/ 1097] train: loss: 0.0111166
[Epoch 32; Iter   913/ 1097] train: loss: 0.0099883
[Epoch 32; Iter   943/ 1097] train: loss: 0.0153149
[Epoch 32; Iter   973/ 1097] train: loss: 0.0324042
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0090328
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0334026
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0354806
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0039311
[Epoch 32] ogbg-molhiv: 0.779422 val loss: 0.640631
[Epoch 32] ogbg-molhiv: 0.750877 test loss: 0.639072
[Epoch 33; Iter    26/ 1097] train: loss: 0.1205279
[Epoch 33; Iter    56/ 1097] train: loss: 0.0917836
[Epoch 33; Iter    86/ 1097] train: loss: 0.0027122
[Epoch 33; Iter   116/ 1097] train: loss: 0.0097560
[Epoch 33; Iter   146/ 1097] train: loss: 0.0167691
[Epoch 33; Iter   176/ 1097] train: loss: 0.0131257
[Epoch 33; Iter   206/ 1097] train: loss: 0.0053482
[Epoch 33; Iter   236/ 1097] train: loss: 0.0088318
[Epoch 33; Iter   266/ 1097] train: loss: 0.1438965
[Epoch 33; Iter   296/ 1097] train: loss: 0.0029508
[Epoch 33; Iter   326/ 1097] train: loss: 0.0454999
[Epoch 33; Iter   356/ 1097] train: loss: 0.0184154
[Epoch 33; Iter   386/ 1097] train: loss: 0.1208951
[Epoch 33; Iter   416/ 1097] train: loss: 0.0243586
[Epoch 33; Iter   446/ 1097] train: loss: 0.0553101
[Epoch 33; Iter   476/ 1097] train: loss: 0.0149562
[Epoch 33; Iter   506/ 1097] train: loss: 0.0158378
[Epoch 33; Iter   536/ 1097] train: loss: 0.0177552
[Epoch 33; Iter   566/ 1097] train: loss: 0.0038730
[Epoch 33; Iter   596/ 1097] train: loss: 0.0048659
[Epoch 33; Iter   626/ 1097] train: loss: 0.0017842
[Epoch 33; Iter   656/ 1097] train: loss: 0.1409539
[Epoch 33; Iter   686/ 1097] train: loss: 0.0170320
[Epoch 33; Iter   716/ 1097] train: loss: 0.0571869
[Epoch 33; Iter   746/ 1097] train: loss: 0.1637428
[Epoch 33; Iter   776/ 1097] train: loss: 0.0041710
[Epoch 33; Iter   806/ 1097] train: loss: 0.0127171
[Epoch 33; Iter   836/ 1097] train: loss: 0.0215851
[Epoch 33; Iter   866/ 1097] train: loss: 0.0065036
[Epoch 33; Iter   896/ 1097] train: loss: 0.0821096
[Epoch 33; Iter   926/ 1097] train: loss: 0.0026865
[Epoch 33; Iter   956/ 1097] train: loss: 0.0026706
[Epoch 33; Iter   986/ 1097] train: loss: 0.0876184
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0076683
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0186145
[Epoch 33; Iter  1076/ 1097] train: loss: 0.1211834
[Epoch 33] ogbg-molhiv: 0.783969 val loss: 0.523193
[Epoch 33] ogbg-molhiv: 0.747948 test loss: 0.657973
[Epoch 34; Iter     9/ 1097] train: loss: 0.0302768
[Epoch 34; Iter    39/ 1097] train: loss: 0.0112362
[Epoch 34; Iter    69/ 1097] train: loss: 0.0059122
[Epoch 34; Iter    99/ 1097] train: loss: 0.0198170
[Epoch 34; Iter   129/ 1097] train: loss: 0.0029271
[Epoch 34; Iter   159/ 1097] train: loss: 0.0084938
[Epoch 34; Iter   189/ 1097] train: loss: 0.1529577
[Epoch 34; Iter   219/ 1097] train: loss: 0.0592120
[Epoch 34; Iter   249/ 1097] train: loss: 0.0168591
[Epoch 34; Iter   279/ 1097] train: loss: 0.1388815
[Epoch 34; Iter   309/ 1097] train: loss: 0.0305147
[Epoch 34; Iter   339/ 1097] train: loss: 0.0046883
[Epoch 34; Iter   369/ 1097] train: loss: 0.0122647
[Epoch 34; Iter   399/ 1097] train: loss: 0.0024431
[Epoch 34; Iter   429/ 1097] train: loss: 0.0148994
[Epoch 34; Iter   459/ 1097] train: loss: 0.0249129
[Epoch 34; Iter   489/ 1097] train: loss: 0.0196390
[Epoch 34; Iter   519/ 1097] train: loss: 0.0289942
[Epoch 34; Iter   549/ 1097] train: loss: 0.0646959
[Epoch 34; Iter   579/ 1097] train: loss: 0.0061262
[Epoch 34; Iter   609/ 1097] train: loss: 0.0449249
[Epoch 34; Iter   639/ 1097] train: loss: 0.0144858
[Epoch 34; Iter   669/ 1097] train: loss: 0.0131038
[Epoch 34; Iter   699/ 1097] train: loss: 0.2070681
[Epoch 34; Iter   729/ 1097] train: loss: 0.1040784
[Epoch 34; Iter   759/ 1097] train: loss: 0.0294905
[Epoch 34; Iter   789/ 1097] train: loss: 0.0059791
[Epoch 34; Iter   819/ 1097] train: loss: 0.0890095
[Epoch 34; Iter   849/ 1097] train: loss: 0.0238316
[Epoch 34; Iter   879/ 1097] train: loss: 0.0036424
[Epoch 34; Iter   909/ 1097] train: loss: 0.0374294
[Epoch 34; Iter   939/ 1097] train: loss: 0.0905857
[Epoch 34; Iter   969/ 1097] train: loss: 0.0255753
[Epoch 34; Iter   999/ 1097] train: loss: 0.0063533
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0854253
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0072588
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0244053
[Epoch 34] ogbg-molhiv: 0.779205 val loss: 0.376647
[Epoch 34] ogbg-molhiv: 0.753263 test loss: 0.428399
[Epoch 35; Iter    22/ 1097] train: loss: 0.0534924
[Epoch 35; Iter    52/ 1097] train: loss: 0.0039992
[Epoch 35; Iter    82/ 1097] train: loss: 0.0127607
[Epoch 35; Iter   112/ 1097] train: loss: 0.0024695
[Epoch 35; Iter   142/ 1097] train: loss: 0.0084345
[Epoch 35; Iter   172/ 1097] train: loss: 0.0100839
[Epoch 35; Iter   202/ 1097] train: loss: 0.0722350
[Epoch 35; Iter   232/ 1097] train: loss: 0.3463408
[Epoch 35; Iter   262/ 1097] train: loss: 0.1982710
[Epoch 35; Iter   292/ 1097] train: loss: 0.0477402
[Epoch 35; Iter   322/ 1097] train: loss: 0.0481389
[Epoch 35; Iter   352/ 1097] train: loss: 0.0278801
[Epoch 35; Iter   382/ 1097] train: loss: 0.0015621
[Epoch 35; Iter   412/ 1097] train: loss: 0.0123675
[Epoch 35; Iter   442/ 1097] train: loss: 0.0197988
[Epoch 35; Iter   472/ 1097] train: loss: 0.1217092
[Epoch 35; Iter   502/ 1097] train: loss: 0.1063556
[Epoch 35; Iter   532/ 1097] train: loss: 0.0315433
[Epoch 35; Iter   562/ 1097] train: loss: 0.0152777
[Epoch 35; Iter   592/ 1097] train: loss: 0.0031960
[Epoch 35; Iter   622/ 1097] train: loss: 0.0037323
[Epoch 35; Iter   652/ 1097] train: loss: 0.0505030
[Epoch 35; Iter   682/ 1097] train: loss: 0.0064934
[Epoch 35; Iter   712/ 1097] train: loss: 0.0285603
[Epoch 35; Iter   742/ 1097] train: loss: 0.0523867
[Epoch 35; Iter   772/ 1097] train: loss: 0.0034812
[Epoch 35; Iter   802/ 1097] train: loss: 0.0027216
[Epoch 35; Iter   832/ 1097] train: loss: 0.0049182
[Epoch 35; Iter   862/ 1097] train: loss: 0.0408276
[Epoch 35; Iter   892/ 1097] train: loss: 0.0037712
[Epoch 35; Iter   922/ 1097] train: loss: 0.1328616
[Epoch 35; Iter   952/ 1097] train: loss: 0.1235756
[Epoch 35; Iter   982/ 1097] train: loss: 0.0041962
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0111373
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0039453
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0062505
[Epoch 35] ogbg-molhiv: 0.772946 val loss: 0.253470
[Epoch 35] ogbg-molhiv: 0.758389 test loss: 0.171848
[Epoch 36; Iter     5/ 1097] train: loss: 0.0096508
[Epoch 36; Iter    35/ 1097] train: loss: 0.0471878
[Epoch 36; Iter    65/ 1097] train: loss: 0.0079296
[Epoch 36; Iter    95/ 1097] train: loss: 0.0123633
[Epoch 36; Iter   125/ 1097] train: loss: 0.0043668
[Epoch 36; Iter   155/ 1097] train: loss: 0.0033993
[Epoch 36; Iter   185/ 1097] train: loss: 0.0034642
[Epoch 36; Iter   215/ 1097] train: loss: 0.0204779
[Epoch 36; Iter   245/ 1097] train: loss: 0.0113936
[Epoch 36; Iter   275/ 1097] train: loss: 0.0148975
[Epoch 36; Iter   305/ 1097] train: loss: 0.0653320
[Epoch 36; Iter   335/ 1097] train: loss: 0.0146838
[Epoch 36; Iter   365/ 1097] train: loss: 0.0047514
[Epoch 36; Iter   395/ 1097] train: loss: 0.0336500
[Epoch 36; Iter   425/ 1097] train: loss: 0.0301770
[Epoch 36; Iter   455/ 1097] train: loss: 0.0302557
[Epoch 36; Iter   485/ 1097] train: loss: 0.0052319
[Epoch 36; Iter   515/ 1097] train: loss: 0.0053840
[Epoch 36; Iter   545/ 1097] train: loss: 0.0340874
[Epoch 36; Iter   575/ 1097] train: loss: 0.0030788
[Epoch 32; Iter   523/ 1097] train: loss: 0.1335551
[Epoch 32; Iter   553/ 1097] train: loss: 0.0143752
[Epoch 32; Iter   583/ 1097] train: loss: 0.0741955
[Epoch 32; Iter   613/ 1097] train: loss: 0.0275132
[Epoch 32; Iter   643/ 1097] train: loss: 0.1656974
[Epoch 32; Iter   673/ 1097] train: loss: 0.0475335
[Epoch 32; Iter   703/ 1097] train: loss: 0.0105765
[Epoch 32; Iter   733/ 1097] train: loss: 0.0213257
[Epoch 32; Iter   763/ 1097] train: loss: 0.0114563
[Epoch 32; Iter   793/ 1097] train: loss: 0.0437391
[Epoch 32; Iter   823/ 1097] train: loss: 0.0232750
[Epoch 32; Iter   853/ 1097] train: loss: 0.0141106
[Epoch 32; Iter   883/ 1097] train: loss: 0.0144443
[Epoch 32; Iter   913/ 1097] train: loss: 0.0594942
[Epoch 32; Iter   943/ 1097] train: loss: 0.0063786
[Epoch 32; Iter   973/ 1097] train: loss: 0.0072214
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0521447
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0173611
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0279279
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0107193
[Epoch 32] ogbg-molhiv: 0.727835 val loss: 0.140642
[Epoch 32] ogbg-molhiv: 0.723859 test loss: 0.184605
[Epoch 33; Iter    26/ 1097] train: loss: 0.2313805
[Epoch 33; Iter    56/ 1097] train: loss: 0.0269255
[Epoch 33; Iter    86/ 1097] train: loss: 0.0085947
[Epoch 33; Iter   116/ 1097] train: loss: 0.0702062
[Epoch 33; Iter   146/ 1097] train: loss: 0.0236921
[Epoch 33; Iter   176/ 1097] train: loss: 0.0052031
[Epoch 33; Iter   206/ 1097] train: loss: 0.0677478
[Epoch 33; Iter   236/ 1097] train: loss: 0.0085540
[Epoch 33; Iter   266/ 1097] train: loss: 0.0180598
[Epoch 33; Iter   296/ 1097] train: loss: 0.2112289
[Epoch 33; Iter   326/ 1097] train: loss: 0.0644550
[Epoch 33; Iter   356/ 1097] train: loss: 0.1667673
[Epoch 33; Iter   386/ 1097] train: loss: 0.0093643
[Epoch 33; Iter   416/ 1097] train: loss: 0.0118874
[Epoch 33; Iter   446/ 1097] train: loss: 0.0160382
[Epoch 33; Iter   476/ 1097] train: loss: 0.0047684
[Epoch 33; Iter   506/ 1097] train: loss: 0.1212836
[Epoch 33; Iter   536/ 1097] train: loss: 0.0044915
[Epoch 33; Iter   566/ 1097] train: loss: 0.0339076
[Epoch 33; Iter   596/ 1097] train: loss: 0.0129503
[Epoch 33; Iter   626/ 1097] train: loss: 0.0210203
[Epoch 33; Iter   656/ 1097] train: loss: 0.0027049
[Epoch 33; Iter   686/ 1097] train: loss: 0.0053382
[Epoch 33; Iter   716/ 1097] train: loss: 0.2703594
[Epoch 33; Iter   746/ 1097] train: loss: 0.0117349
[Epoch 33; Iter   776/ 1097] train: loss: 0.2226006
[Epoch 33; Iter   806/ 1097] train: loss: 0.0082488
[Epoch 33; Iter   836/ 1097] train: loss: 0.1438441
[Epoch 33; Iter   866/ 1097] train: loss: 0.0507956
[Epoch 33; Iter   896/ 1097] train: loss: 0.0109317
[Epoch 33; Iter   926/ 1097] train: loss: 0.0058125
[Epoch 33; Iter   956/ 1097] train: loss: 0.0083517
[Epoch 33; Iter   986/ 1097] train: loss: 0.0299035
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0596669
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0088125
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0298771
[Epoch 33] ogbg-molhiv: 0.743466 val loss: 0.180732
[Epoch 33] ogbg-molhiv: 0.689121 test loss: 0.188833
[Epoch 34; Iter     9/ 1097] train: loss: 0.0830661
[Epoch 34; Iter    39/ 1097] train: loss: 0.1051059
[Epoch 34; Iter    69/ 1097] train: loss: 0.0069369
[Epoch 34; Iter    99/ 1097] train: loss: 0.0425076
[Epoch 34; Iter   129/ 1097] train: loss: 0.0219847
[Epoch 34; Iter   159/ 1097] train: loss: 0.0049517
[Epoch 34; Iter   189/ 1097] train: loss: 0.0097017
[Epoch 34; Iter   219/ 1097] train: loss: 0.0059825
[Epoch 34; Iter   249/ 1097] train: loss: 0.0075070
[Epoch 34; Iter   279/ 1097] train: loss: 0.0087471
[Epoch 34; Iter   309/ 1097] train: loss: 0.0075042
[Epoch 34; Iter   339/ 1097] train: loss: 0.0068801
[Epoch 34; Iter   369/ 1097] train: loss: 0.0125275
[Epoch 34; Iter   399/ 1097] train: loss: 0.0277502
[Epoch 34; Iter   429/ 1097] train: loss: 0.0097490
[Epoch 34; Iter   459/ 1097] train: loss: 0.0259015
[Epoch 34; Iter   489/ 1097] train: loss: 0.0025933
[Epoch 34; Iter   519/ 1097] train: loss: 0.0061863
[Epoch 34; Iter   549/ 1097] train: loss: 0.0034372
[Epoch 34; Iter   579/ 1097] train: loss: 0.1319745
[Epoch 34; Iter   609/ 1097] train: loss: 0.0072470
[Epoch 34; Iter   639/ 1097] train: loss: 0.0307173
[Epoch 34; Iter   669/ 1097] train: loss: 0.0336477
[Epoch 34; Iter   699/ 1097] train: loss: 0.0345469
[Epoch 34; Iter   729/ 1097] train: loss: 0.0011941
[Epoch 34; Iter   759/ 1097] train: loss: 0.2198756
[Epoch 34; Iter   789/ 1097] train: loss: 0.0305937
[Epoch 34; Iter   819/ 1097] train: loss: 0.0057951
[Epoch 34; Iter   849/ 1097] train: loss: 0.0946582
[Epoch 34; Iter   879/ 1097] train: loss: 0.0033781
[Epoch 34; Iter   909/ 1097] train: loss: 0.0594029
[Epoch 34; Iter   939/ 1097] train: loss: 0.0057775
[Epoch 34; Iter   969/ 1097] train: loss: 0.0131313
[Epoch 34; Iter   999/ 1097] train: loss: 0.0106972
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0421308
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0034361
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0430567
[Epoch 34] ogbg-molhiv: 0.725082 val loss: 0.215612
[Epoch 34] ogbg-molhiv: 0.712092 test loss: 0.203733
[Epoch 35; Iter    22/ 1097] train: loss: 0.0058683
[Epoch 35; Iter    52/ 1097] train: loss: 0.0104216
[Epoch 35; Iter    82/ 1097] train: loss: 0.0621453
[Epoch 35; Iter   112/ 1097] train: loss: 0.0010238
[Epoch 35; Iter   142/ 1097] train: loss: 0.0044518
[Epoch 35; Iter   172/ 1097] train: loss: 0.0009328
[Epoch 35; Iter   202/ 1097] train: loss: 0.0452599
[Epoch 35; Iter   232/ 1097] train: loss: 0.0035190
[Epoch 35; Iter   262/ 1097] train: loss: 0.0113526
[Epoch 35; Iter   292/ 1097] train: loss: 0.0413877
[Epoch 35; Iter   322/ 1097] train: loss: 0.0034819
[Epoch 35; Iter   352/ 1097] train: loss: 0.0123545
[Epoch 35; Iter   382/ 1097] train: loss: 0.0029208
[Epoch 35; Iter   412/ 1097] train: loss: 0.0033003
[Epoch 35; Iter   442/ 1097] train: loss: 0.0138509
[Epoch 35; Iter   472/ 1097] train: loss: 0.0013341
[Epoch 35; Iter   502/ 1097] train: loss: 0.0046096
[Epoch 35; Iter   532/ 1097] train: loss: 0.0303916
[Epoch 35; Iter   562/ 1097] train: loss: 0.0199623
[Epoch 35; Iter   592/ 1097] train: loss: 0.0032284
[Epoch 35; Iter   622/ 1097] train: loss: 0.0126877
[Epoch 35; Iter   652/ 1097] train: loss: 0.0186333
[Epoch 35; Iter   682/ 1097] train: loss: 0.0307861
[Epoch 35; Iter   712/ 1097] train: loss: 0.0553475
[Epoch 35; Iter   742/ 1097] train: loss: 0.0036928
[Epoch 35; Iter   772/ 1097] train: loss: 0.0063161
[Epoch 35; Iter   802/ 1097] train: loss: 0.0160375
[Epoch 35; Iter   832/ 1097] train: loss: 0.0146326
[Epoch 35; Iter   862/ 1097] train: loss: 0.0030631
[Epoch 35; Iter   892/ 1097] train: loss: 0.2076173
[Epoch 35; Iter   922/ 1097] train: loss: 0.0103737
[Epoch 35; Iter   952/ 1097] train: loss: 0.1087248
[Epoch 35; Iter   982/ 1097] train: loss: 0.0021510
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0384774
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0025831
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0352126
[Epoch 35] ogbg-molhiv: 0.759394 val loss: 0.529586
[Epoch 35] ogbg-molhiv: 0.721675 test loss: 0.209896
[Epoch 36; Iter     5/ 1097] train: loss: 0.0393946
[Epoch 36; Iter    35/ 1097] train: loss: 0.0071792
[Epoch 36; Iter    65/ 1097] train: loss: 0.0024407
[Epoch 36; Iter    95/ 1097] train: loss: 0.0305959
[Epoch 36; Iter   125/ 1097] train: loss: 0.0009597
[Epoch 36; Iter   155/ 1097] train: loss: 0.0386532
[Epoch 36; Iter   185/ 1097] train: loss: 0.0037680
[Epoch 36; Iter   215/ 1097] train: loss: 0.0194916
[Epoch 36; Iter   245/ 1097] train: loss: 0.2077297
[Epoch 36; Iter   275/ 1097] train: loss: 0.0022370
[Epoch 36; Iter   305/ 1097] train: loss: 0.0090714
[Epoch 36; Iter   335/ 1097] train: loss: 0.0044203
[Epoch 36; Iter   365/ 1097] train: loss: 0.0349838
[Epoch 36; Iter   395/ 1097] train: loss: 0.0087589
[Epoch 36; Iter   425/ 1097] train: loss: 0.0463720
[Epoch 36; Iter   455/ 1097] train: loss: 0.0076445
[Epoch 36; Iter   485/ 1097] train: loss: 0.0079082
[Epoch 36; Iter   515/ 1097] train: loss: 0.2186373
[Epoch 36; Iter   545/ 1097] train: loss: 0.1499759
[Epoch 36; Iter   575/ 1097] train: loss: 0.0751810
[Epoch 32; Iter   523/ 1097] train: loss: 0.0916428
[Epoch 32; Iter   553/ 1097] train: loss: 0.0382474
[Epoch 32; Iter   583/ 1097] train: loss: 0.0207296
[Epoch 32; Iter   613/ 1097] train: loss: 0.0175921
[Epoch 32; Iter   643/ 1097] train: loss: 0.0118028
[Epoch 32; Iter   673/ 1097] train: loss: 0.0985507
[Epoch 32; Iter   703/ 1097] train: loss: 0.0313652
[Epoch 32; Iter   733/ 1097] train: loss: 0.0922131
[Epoch 32; Iter   763/ 1097] train: loss: 0.0981075
[Epoch 32; Iter   793/ 1097] train: loss: 0.0221275
[Epoch 32; Iter   823/ 1097] train: loss: 0.0146649
[Epoch 32; Iter   853/ 1097] train: loss: 0.0065387
[Epoch 32; Iter   883/ 1097] train: loss: 0.0150791
[Epoch 32; Iter   913/ 1097] train: loss: 0.0651819
[Epoch 32; Iter   943/ 1097] train: loss: 0.0200099
[Epoch 32; Iter   973/ 1097] train: loss: 0.0185625
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0185357
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0315626
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0495068
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0941555
[Epoch 32] ogbg-molhiv: 0.686857 val loss: 0.564156
[Epoch 32] ogbg-molhiv: 0.717355 test loss: 0.653073
[Epoch 33; Iter    26/ 1097] train: loss: 0.0170475
[Epoch 33; Iter    56/ 1097] train: loss: 0.1323445
[Epoch 33; Iter    86/ 1097] train: loss: 0.0445849
[Epoch 33; Iter   116/ 1097] train: loss: 0.1581672
[Epoch 33; Iter   146/ 1097] train: loss: 0.0231481
[Epoch 33; Iter   176/ 1097] train: loss: 0.0126227
[Epoch 33; Iter   206/ 1097] train: loss: 0.0161841
[Epoch 33; Iter   236/ 1097] train: loss: 0.0118947
[Epoch 33; Iter   266/ 1097] train: loss: 0.0152773
[Epoch 33; Iter   296/ 1097] train: loss: 0.0532023
[Epoch 33; Iter   326/ 1097] train: loss: 0.1001768
[Epoch 33; Iter   356/ 1097] train: loss: 0.2639614
[Epoch 33; Iter   386/ 1097] train: loss: 0.0110150
[Epoch 33; Iter   416/ 1097] train: loss: 0.0191268
[Epoch 33; Iter   446/ 1097] train: loss: 0.0102271
[Epoch 33; Iter   476/ 1097] train: loss: 0.0157803
[Epoch 33; Iter   506/ 1097] train: loss: 0.1246751
[Epoch 33; Iter   536/ 1097] train: loss: 0.0327613
[Epoch 33; Iter   566/ 1097] train: loss: 0.1250719
[Epoch 33; Iter   596/ 1097] train: loss: 0.0040432
[Epoch 33; Iter   626/ 1097] train: loss: 0.0304937
[Epoch 33; Iter   656/ 1097] train: loss: 0.0174739
[Epoch 33; Iter   686/ 1097] train: loss: 0.0136704
[Epoch 33; Iter   716/ 1097] train: loss: 0.0117779
[Epoch 33; Iter   746/ 1097] train: loss: 0.0105905
[Epoch 33; Iter   776/ 1097] train: loss: 0.0801707
[Epoch 33; Iter   806/ 1097] train: loss: 0.2267605
[Epoch 33; Iter   836/ 1097] train: loss: 0.0311187
[Epoch 33; Iter   866/ 1097] train: loss: 0.0372032
[Epoch 33; Iter   896/ 1097] train: loss: 0.1954286
[Epoch 33; Iter   926/ 1097] train: loss: 0.0301587
[Epoch 33; Iter   956/ 1097] train: loss: 0.0206590
[Epoch 33; Iter   986/ 1097] train: loss: 0.0928432
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0198245
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0519944
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2259208
[Epoch 33] ogbg-molhiv: 0.741935 val loss: 0.645707
[Epoch 33] ogbg-molhiv: 0.742511 test loss: 0.264147
[Epoch 34; Iter     9/ 1097] train: loss: 0.0125999
[Epoch 34; Iter    39/ 1097] train: loss: 0.0165494
[Epoch 34; Iter    69/ 1097] train: loss: 0.0305691
[Epoch 34; Iter    99/ 1097] train: loss: 0.0425770
[Epoch 34; Iter   129/ 1097] train: loss: 0.1862095
[Epoch 34; Iter   159/ 1097] train: loss: 0.0074878
[Epoch 34; Iter   189/ 1097] train: loss: 0.0210918
[Epoch 34; Iter   219/ 1097] train: loss: 0.0096326
[Epoch 34; Iter   249/ 1097] train: loss: 0.0297185
[Epoch 34; Iter   279/ 1097] train: loss: 0.0056447
[Epoch 34; Iter   309/ 1097] train: loss: 0.0044665
[Epoch 34; Iter   339/ 1097] train: loss: 0.0177889
[Epoch 34; Iter   369/ 1097] train: loss: 0.0728780
[Epoch 34; Iter   399/ 1097] train: loss: 0.2280858
[Epoch 34; Iter   429/ 1097] train: loss: 0.0116381
[Epoch 34; Iter   459/ 1097] train: loss: 0.0340456
[Epoch 34; Iter   489/ 1097] train: loss: 0.0397743
[Epoch 34; Iter   519/ 1097] train: loss: 0.0032112
[Epoch 34; Iter   549/ 1097] train: loss: 0.0337167
[Epoch 34; Iter   579/ 1097] train: loss: 0.0208236
[Epoch 34; Iter   609/ 1097] train: loss: 0.0039037
[Epoch 34; Iter   639/ 1097] train: loss: 0.1143013
[Epoch 34; Iter   669/ 1097] train: loss: 0.0247766
[Epoch 34; Iter   699/ 1097] train: loss: 0.0165858
[Epoch 34; Iter   729/ 1097] train: loss: 0.1971912
[Epoch 34; Iter   759/ 1097] train: loss: 0.0049458
[Epoch 34; Iter   789/ 1097] train: loss: 0.0124892
[Epoch 34; Iter   819/ 1097] train: loss: 0.1750202
[Epoch 34; Iter   849/ 1097] train: loss: 0.0204971
[Epoch 34; Iter   879/ 1097] train: loss: 0.1246157
[Epoch 34; Iter   909/ 1097] train: loss: 0.0197073
[Epoch 34; Iter   939/ 1097] train: loss: 0.0301258
[Epoch 34; Iter   969/ 1097] train: loss: 0.0216903
[Epoch 34; Iter   999/ 1097] train: loss: 0.0313716
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0127038
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1000871
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0113257
[Epoch 34] ogbg-molhiv: 0.706634 val loss: 0.699694
[Epoch 34] ogbg-molhiv: 0.730053 test loss: 0.601185
[Epoch 35; Iter    22/ 1097] train: loss: 0.0087175
[Epoch 35; Iter    52/ 1097] train: loss: 0.0117814
[Epoch 35; Iter    82/ 1097] train: loss: 0.1474998
[Epoch 35; Iter   112/ 1097] train: loss: 0.0630275
[Epoch 35; Iter   142/ 1097] train: loss: 0.0111676
[Epoch 35; Iter   172/ 1097] train: loss: 0.0144922
[Epoch 35; Iter   202/ 1097] train: loss: 0.0476196
[Epoch 35; Iter   232/ 1097] train: loss: 0.0733469
[Epoch 35; Iter   262/ 1097] train: loss: 0.0044663
[Epoch 35; Iter   292/ 1097] train: loss: 0.0075462
[Epoch 35; Iter   322/ 1097] train: loss: 0.1476528
[Epoch 35; Iter   352/ 1097] train: loss: 0.0483118
[Epoch 35; Iter   382/ 1097] train: loss: 0.0979032
[Epoch 35; Iter   412/ 1097] train: loss: 0.0348268
[Epoch 35; Iter   442/ 1097] train: loss: 0.0088391
[Epoch 35; Iter   472/ 1097] train: loss: 0.0062749
[Epoch 35; Iter   502/ 1097] train: loss: 0.0177278
[Epoch 35; Iter   532/ 1097] train: loss: 0.0135381
[Epoch 35; Iter   562/ 1097] train: loss: 0.0128805
[Epoch 35; Iter   592/ 1097] train: loss: 0.0053040
[Epoch 35; Iter   622/ 1097] train: loss: 0.0357139
[Epoch 35; Iter   652/ 1097] train: loss: 0.0289282
[Epoch 35; Iter   682/ 1097] train: loss: 0.0218229
[Epoch 35; Iter   712/ 1097] train: loss: 0.1536272
[Epoch 35; Iter   742/ 1097] train: loss: 0.0453331
[Epoch 35; Iter   772/ 1097] train: loss: 0.0221042
[Epoch 35; Iter   802/ 1097] train: loss: 0.0052406
[Epoch 35; Iter   832/ 1097] train: loss: 0.0103564
[Epoch 35; Iter   862/ 1097] train: loss: 0.0063198
[Epoch 35; Iter   892/ 1097] train: loss: 0.0039695
[Epoch 35; Iter   922/ 1097] train: loss: 0.0024895
[Epoch 35; Iter   952/ 1097] train: loss: 0.0569704
[Epoch 35; Iter   982/ 1097] train: loss: 0.1780240
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0233935
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1752335
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0061307
[Epoch 35] ogbg-molhiv: 0.678525 val loss: 0.470298
[Epoch 35] ogbg-molhiv: 0.725626 test loss: 0.257667
[Epoch 36; Iter     5/ 1097] train: loss: 0.0066903
[Epoch 36; Iter    35/ 1097] train: loss: 0.0297104
[Epoch 36; Iter    65/ 1097] train: loss: 0.0332253
[Epoch 36; Iter    95/ 1097] train: loss: 0.0071106
[Epoch 36; Iter   125/ 1097] train: loss: 0.0387293
[Epoch 36; Iter   155/ 1097] train: loss: 0.0159599
[Epoch 36; Iter   185/ 1097] train: loss: 0.0032591
[Epoch 36; Iter   215/ 1097] train: loss: 0.0125469
[Epoch 36; Iter   245/ 1097] train: loss: 0.0081973
[Epoch 36; Iter   275/ 1097] train: loss: 0.1219770
[Epoch 36; Iter   305/ 1097] train: loss: 0.0373758
[Epoch 36; Iter   335/ 1097] train: loss: 0.0138130
[Epoch 36; Iter   365/ 1097] train: loss: 0.0783756
[Epoch 36; Iter   395/ 1097] train: loss: 0.0206299
[Epoch 36; Iter   425/ 1097] train: loss: 0.0085781
[Epoch 36; Iter   455/ 1097] train: loss: 0.0218611
[Epoch 36; Iter   485/ 1097] train: loss: 0.0886913
[Epoch 36; Iter   515/ 1097] train: loss: 0.0229704
[Epoch 36; Iter   545/ 1097] train: loss: 0.0322865
[Epoch 36; Iter   575/ 1097] train: loss: 0.0187155
[Epoch 32; Iter   523/ 1097] train: loss: 0.0192173
[Epoch 32; Iter   553/ 1097] train: loss: 0.0247835
[Epoch 32; Iter   583/ 1097] train: loss: 0.0206506
[Epoch 32; Iter   613/ 1097] train: loss: 0.0156182
[Epoch 32; Iter   643/ 1097] train: loss: 0.0052236
[Epoch 32; Iter   673/ 1097] train: loss: 0.3160163
[Epoch 32; Iter   703/ 1097] train: loss: 0.0104639
[Epoch 32; Iter   733/ 1097] train: loss: 0.0071285
[Epoch 32; Iter   763/ 1097] train: loss: 0.0437343
[Epoch 32; Iter   793/ 1097] train: loss: 0.0784306
[Epoch 32; Iter   823/ 1097] train: loss: 0.0798256
[Epoch 32; Iter   853/ 1097] train: loss: 0.0361715
[Epoch 32; Iter   883/ 1097] train: loss: 0.0596367
[Epoch 32; Iter   913/ 1097] train: loss: 0.0663376
[Epoch 32; Iter   943/ 1097] train: loss: 0.1405544
[Epoch 32; Iter   973/ 1097] train: loss: 0.0222954
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0460195
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0150623
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1682604
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0376670
[Epoch 32] ogbg-molhiv: 0.786676 val loss: 0.102073
[Epoch 32] ogbg-molhiv: 0.696649 test loss: 0.173602
[Epoch 33; Iter    26/ 1097] train: loss: 0.0094041
[Epoch 33; Iter    56/ 1097] train: loss: 0.0318137
[Epoch 33; Iter    86/ 1097] train: loss: 0.0070090
[Epoch 33; Iter   116/ 1097] train: loss: 0.0671741
[Epoch 33; Iter   146/ 1097] train: loss: 0.0088979
[Epoch 33; Iter   176/ 1097] train: loss: 0.0146481
[Epoch 33; Iter   206/ 1097] train: loss: 0.0091731
[Epoch 33; Iter   236/ 1097] train: loss: 0.1073197
[Epoch 33; Iter   266/ 1097] train: loss: 0.0519618
[Epoch 33; Iter   296/ 1097] train: loss: 0.0792650
[Epoch 33; Iter   326/ 1097] train: loss: 0.0465143
[Epoch 33; Iter   356/ 1097] train: loss: 0.0889533
[Epoch 33; Iter   386/ 1097] train: loss: 0.0135458
[Epoch 33; Iter   416/ 1097] train: loss: 0.0384550
[Epoch 33; Iter   446/ 1097] train: loss: 0.0615655
[Epoch 33; Iter   476/ 1097] train: loss: 0.0095773
[Epoch 33; Iter   506/ 1097] train: loss: 0.1086407
[Epoch 33; Iter   536/ 1097] train: loss: 0.0180539
[Epoch 33; Iter   566/ 1097] train: loss: 0.0395795
[Epoch 33; Iter   596/ 1097] train: loss: 0.0088031
[Epoch 33; Iter   626/ 1097] train: loss: 0.0466130
[Epoch 33; Iter   656/ 1097] train: loss: 0.0072296
[Epoch 33; Iter   686/ 1097] train: loss: 0.0714046
[Epoch 33; Iter   716/ 1097] train: loss: 0.0197749
[Epoch 33; Iter   746/ 1097] train: loss: 0.0848808
[Epoch 33; Iter   776/ 1097] train: loss: 0.0170928
[Epoch 33; Iter   806/ 1097] train: loss: 0.0269461
[Epoch 33; Iter   836/ 1097] train: loss: 0.0112716
[Epoch 33; Iter   866/ 1097] train: loss: 0.0106518
[Epoch 33; Iter   896/ 1097] train: loss: 0.2312122
[Epoch 33; Iter   926/ 1097] train: loss: 0.0962760
[Epoch 33; Iter   956/ 1097] train: loss: 0.0079675
[Epoch 33; Iter   986/ 1097] train: loss: 0.0065165
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0207002
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0678131
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2878821
[Epoch 33] ogbg-molhiv: 0.743454 val loss: 0.104825
[Epoch 33] ogbg-molhiv: 0.738968 test loss: 0.163355
[Epoch 34; Iter     9/ 1097] train: loss: 0.0147739
[Epoch 34; Iter    39/ 1097] train: loss: 0.0422408
[Epoch 34; Iter    69/ 1097] train: loss: 0.0140125
[Epoch 34; Iter    99/ 1097] train: loss: 0.0469055
[Epoch 34; Iter   129/ 1097] train: loss: 0.0628668
[Epoch 34; Iter   159/ 1097] train: loss: 0.0084242
[Epoch 34; Iter   189/ 1097] train: loss: 0.0279302
[Epoch 34; Iter   219/ 1097] train: loss: 0.0061215
[Epoch 34; Iter   249/ 1097] train: loss: 0.0485322
[Epoch 34; Iter   279/ 1097] train: loss: 0.0418718
[Epoch 34; Iter   309/ 1097] train: loss: 0.0074453
[Epoch 34; Iter   339/ 1097] train: loss: 0.0443616
[Epoch 34; Iter   369/ 1097] train: loss: 0.1535248
[Epoch 34; Iter   399/ 1097] train: loss: 0.1212188
[Epoch 34; Iter   429/ 1097] train: loss: 0.0031456
[Epoch 34; Iter   459/ 1097] train: loss: 0.0593702
[Epoch 34; Iter   489/ 1097] train: loss: 0.0213743
[Epoch 34; Iter   519/ 1097] train: loss: 0.0064361
[Epoch 34; Iter   549/ 1097] train: loss: 0.0084271
[Epoch 34; Iter   579/ 1097] train: loss: 0.0144862
[Epoch 34; Iter   609/ 1097] train: loss: 0.0065629
[Epoch 34; Iter   639/ 1097] train: loss: 0.0136176
[Epoch 34; Iter   669/ 1097] train: loss: 0.0070238
[Epoch 34; Iter   699/ 1097] train: loss: 0.0128807
[Epoch 34; Iter   729/ 1097] train: loss: 0.4106473
[Epoch 34; Iter   759/ 1097] train: loss: 0.0152868
[Epoch 34; Iter   789/ 1097] train: loss: 0.0453833
[Epoch 34; Iter   819/ 1097] train: loss: 0.1935825
[Epoch 34; Iter   849/ 1097] train: loss: 0.0232632
[Epoch 34; Iter   879/ 1097] train: loss: 0.0969246
[Epoch 34; Iter   909/ 1097] train: loss: 0.0098307
[Epoch 34; Iter   939/ 1097] train: loss: 0.2026290
[Epoch 34; Iter   969/ 1097] train: loss: 0.0516167
[Epoch 34; Iter   999/ 1097] train: loss: 0.0917985
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0133010
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0137550
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0059475
[Epoch 34] ogbg-molhiv: 0.795298 val loss: 0.100047
[Epoch 34] ogbg-molhiv: 0.738759 test loss: 0.171575
[Epoch 35; Iter    22/ 1097] train: loss: 0.0050767
[Epoch 35; Iter    52/ 1097] train: loss: 0.0029287
[Epoch 35; Iter    82/ 1097] train: loss: 0.0597045
[Epoch 35; Iter   112/ 1097] train: loss: 0.0077348
[Epoch 35; Iter   142/ 1097] train: loss: 0.0126962
[Epoch 35; Iter   172/ 1097] train: loss: 0.0020410
[Epoch 35; Iter   202/ 1097] train: loss: 0.0340107
[Epoch 35; Iter   232/ 1097] train: loss: 0.0111295
[Epoch 35; Iter   262/ 1097] train: loss: 0.0025187
[Epoch 35; Iter   292/ 1097] train: loss: 0.0098184
[Epoch 35; Iter   322/ 1097] train: loss: 0.0602475
[Epoch 35; Iter   352/ 1097] train: loss: 0.1382374
[Epoch 35; Iter   382/ 1097] train: loss: 0.1465064
[Epoch 35; Iter   412/ 1097] train: loss: 0.0236074
[Epoch 35; Iter   442/ 1097] train: loss: 0.0079529
[Epoch 35; Iter   472/ 1097] train: loss: 0.0389714
[Epoch 35; Iter   502/ 1097] train: loss: 0.0686813
[Epoch 35; Iter   532/ 1097] train: loss: 0.0307012
[Epoch 35; Iter   562/ 1097] train: loss: 0.0476766
[Epoch 35; Iter   592/ 1097] train: loss: 0.0188253
[Epoch 35; Iter   622/ 1097] train: loss: 0.0363257
[Epoch 35; Iter   652/ 1097] train: loss: 0.0201800
[Epoch 35; Iter   682/ 1097] train: loss: 0.0688694
[Epoch 35; Iter   712/ 1097] train: loss: 0.0372533
[Epoch 35; Iter   742/ 1097] train: loss: 0.0760838
[Epoch 35; Iter   772/ 1097] train: loss: 0.1240623
[Epoch 35; Iter   802/ 1097] train: loss: 0.0910636
[Epoch 35; Iter   832/ 1097] train: loss: 0.0677916
[Epoch 35; Iter   862/ 1097] train: loss: 0.0316388
[Epoch 35; Iter   892/ 1097] train: loss: 0.0069711
[Epoch 35; Iter   922/ 1097] train: loss: 0.0057380
[Epoch 35; Iter   952/ 1097] train: loss: 0.1148676
[Epoch 35; Iter   982/ 1097] train: loss: 0.0540529
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0703005
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1257044
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0227276
[Epoch 35] ogbg-molhiv: 0.780668 val loss: 0.128360
[Epoch 35] ogbg-molhiv: 0.720082 test loss: 0.178839
[Epoch 36; Iter     5/ 1097] train: loss: 0.0136609
[Epoch 36; Iter    35/ 1097] train: loss: 0.0242135
[Epoch 36; Iter    65/ 1097] train: loss: 0.0054989
[Epoch 36; Iter    95/ 1097] train: loss: 0.0482624
[Epoch 36; Iter   125/ 1097] train: loss: 0.0369924
[Epoch 36; Iter   155/ 1097] train: loss: 0.0062067
[Epoch 36; Iter   185/ 1097] train: loss: 0.0200125
[Epoch 36; Iter   215/ 1097] train: loss: 0.0243690
[Epoch 36; Iter   245/ 1097] train: loss: 0.0065672
[Epoch 36; Iter   275/ 1097] train: loss: 0.0481833
[Epoch 36; Iter   305/ 1097] train: loss: 0.0539346
[Epoch 36; Iter   335/ 1097] train: loss: 0.0139904
[Epoch 36; Iter   365/ 1097] train: loss: 0.0073420
[Epoch 36; Iter   395/ 1097] train: loss: 0.0052118
[Epoch 36; Iter   425/ 1097] train: loss: 0.0195870
[Epoch 36; Iter   455/ 1097] train: loss: 0.0354587
[Epoch 36; Iter   485/ 1097] train: loss: 0.0087449
[Epoch 36; Iter   515/ 1097] train: loss: 0.0424573
[Epoch 36; Iter   545/ 1097] train: loss: 0.0037957
[Epoch 36; Iter   575/ 1097] train: loss: 0.0025417
[Epoch 32; Iter   523/ 1097] train: loss: 0.0484034
[Epoch 32; Iter   553/ 1097] train: loss: 0.0124537
[Epoch 32; Iter   583/ 1097] train: loss: 0.0100319
[Epoch 32; Iter   613/ 1097] train: loss: 0.1654191
[Epoch 32; Iter   643/ 1097] train: loss: 0.0103549
[Epoch 32; Iter   673/ 1097] train: loss: 0.0063985
[Epoch 32; Iter   703/ 1097] train: loss: 0.0333039
[Epoch 32; Iter   733/ 1097] train: loss: 0.0070599
[Epoch 32; Iter   763/ 1097] train: loss: 0.0102328
[Epoch 32; Iter   793/ 1097] train: loss: 0.0113277
[Epoch 32; Iter   823/ 1097] train: loss: 0.0930438
[Epoch 32; Iter   853/ 1097] train: loss: 0.0094393
[Epoch 32; Iter   883/ 1097] train: loss: 0.0723936
[Epoch 32; Iter   913/ 1097] train: loss: 0.0055196
[Epoch 32; Iter   943/ 1097] train: loss: 0.0033874
[Epoch 32; Iter   973/ 1097] train: loss: 0.0441213
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0057326
[Epoch 32; Iter  1033/ 1097] train: loss: 0.1345897
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0099197
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0073824
[Epoch 32] ogbg-molhiv: 0.768626 val loss: 0.135186
[Epoch 32] ogbg-molhiv: 0.728479 test loss: 0.230939
[Epoch 33; Iter    26/ 1097] train: loss: 0.0264654
[Epoch 33; Iter    56/ 1097] train: loss: 0.0711799
[Epoch 33; Iter    86/ 1097] train: loss: 0.0057145
[Epoch 33; Iter   116/ 1097] train: loss: 0.0105199
[Epoch 33; Iter   146/ 1097] train: loss: 0.0113652
[Epoch 33; Iter   176/ 1097] train: loss: 0.0692880
[Epoch 33; Iter   206/ 1097] train: loss: 0.0177014
[Epoch 33; Iter   236/ 1097] train: loss: 0.0150589
[Epoch 33; Iter   266/ 1097] train: loss: 0.0078361
[Epoch 33; Iter   296/ 1097] train: loss: 0.0050731
[Epoch 33; Iter   326/ 1097] train: loss: 0.0926946
[Epoch 33; Iter   356/ 1097] train: loss: 0.0080616
[Epoch 33; Iter   386/ 1097] train: loss: 0.0493708
[Epoch 33; Iter   416/ 1097] train: loss: 0.1288293
[Epoch 33; Iter   446/ 1097] train: loss: 0.0819933
[Epoch 33; Iter   476/ 1097] train: loss: 0.0059934
[Epoch 33; Iter   506/ 1097] train: loss: 0.0054810
[Epoch 33; Iter   536/ 1097] train: loss: 0.0387511
[Epoch 33; Iter   566/ 1097] train: loss: 0.0136222
[Epoch 33; Iter   596/ 1097] train: loss: 0.0466704
[Epoch 33; Iter   626/ 1097] train: loss: 0.0024310
[Epoch 33; Iter   656/ 1097] train: loss: 0.0054686
[Epoch 33; Iter   686/ 1097] train: loss: 0.0189053
[Epoch 33; Iter   716/ 1097] train: loss: 0.0819792
[Epoch 33; Iter   746/ 1097] train: loss: 0.0326516
[Epoch 33; Iter   776/ 1097] train: loss: 0.0100325
[Epoch 33; Iter   806/ 1097] train: loss: 0.0399087
[Epoch 33; Iter   836/ 1097] train: loss: 0.1393930
[Epoch 33; Iter   866/ 1097] train: loss: 0.0071194
[Epoch 33; Iter   896/ 1097] train: loss: 0.0068560
[Epoch 33; Iter   926/ 1097] train: loss: 0.0369262
[Epoch 33; Iter   956/ 1097] train: loss: 0.0103270
[Epoch 33; Iter   986/ 1097] train: loss: 0.0261633
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0112032
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0271627
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0070593
[Epoch 33] ogbg-molhiv: 0.758742 val loss: 0.339387
[Epoch 33] ogbg-molhiv: 0.695902 test loss: 0.454576
[Epoch 34; Iter     9/ 1097] train: loss: 0.0064665
[Epoch 34; Iter    39/ 1097] train: loss: 0.0197537
[Epoch 34; Iter    69/ 1097] train: loss: 0.0041028
[Epoch 34; Iter    99/ 1097] train: loss: 0.0103483
[Epoch 34; Iter   129/ 1097] train: loss: 0.0190575
[Epoch 34; Iter   159/ 1097] train: loss: 0.0065290
[Epoch 34; Iter   189/ 1097] train: loss: 0.0333771
[Epoch 34; Iter   219/ 1097] train: loss: 0.0844243
[Epoch 34; Iter   249/ 1097] train: loss: 0.0086603
[Epoch 34; Iter   279/ 1097] train: loss: 0.2009676
[Epoch 34; Iter   309/ 1097] train: loss: 0.0192723
[Epoch 34; Iter   339/ 1097] train: loss: 0.0085207
[Epoch 34; Iter   369/ 1097] train: loss: 0.0076705
[Epoch 34; Iter   399/ 1097] train: loss: 0.0012582
[Epoch 34; Iter   429/ 1097] train: loss: 0.0103032
[Epoch 34; Iter   459/ 1097] train: loss: 0.0575624
[Epoch 34; Iter   489/ 1097] train: loss: 0.0116197
[Epoch 34; Iter   519/ 1097] train: loss: 0.0256527
[Epoch 34; Iter   549/ 1097] train: loss: 0.2179994
[Epoch 34; Iter   579/ 1097] train: loss: 0.0561559
[Epoch 34; Iter   609/ 1097] train: loss: 0.0022328
[Epoch 34; Iter   639/ 1097] train: loss: 0.0026080
[Epoch 34; Iter   669/ 1097] train: loss: 0.0095202
[Epoch 34; Iter   699/ 1097] train: loss: 0.0965323
[Epoch 34; Iter   729/ 1097] train: loss: 0.1461114
[Epoch 34; Iter   759/ 1097] train: loss: 0.0222808
[Epoch 34; Iter   789/ 1097] train: loss: 0.0217817
[Epoch 34; Iter   819/ 1097] train: loss: 0.0427532
[Epoch 34; Iter   849/ 1097] train: loss: 0.0055308
[Epoch 34; Iter   879/ 1097] train: loss: 0.0131324
[Epoch 34; Iter   909/ 1097] train: loss: 0.0073081
[Epoch 34; Iter   939/ 1097] train: loss: 0.0749221
[Epoch 34; Iter   969/ 1097] train: loss: 0.0260544
[Epoch 34; Iter   999/ 1097] train: loss: 0.0140044
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1606630
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0101565
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0090295
[Epoch 34] ogbg-molhiv: 0.757012 val loss: 0.150203
[Epoch 34] ogbg-molhiv: 0.694100 test loss: 0.258520
[Epoch 35; Iter    22/ 1097] train: loss: 0.0137393
[Epoch 35; Iter    52/ 1097] train: loss: 0.0099977
[Epoch 35; Iter    82/ 1097] train: loss: 0.0134560
[Epoch 35; Iter   112/ 1097] train: loss: 0.0948764
[Epoch 35; Iter   142/ 1097] train: loss: 0.0270300
[Epoch 35; Iter   172/ 1097] train: loss: 0.0148235
[Epoch 35; Iter   202/ 1097] train: loss: 0.0228754
[Epoch 35; Iter   232/ 1097] train: loss: 0.1192308
[Epoch 35; Iter   262/ 1097] train: loss: 0.0803988
[Epoch 35; Iter   292/ 1097] train: loss: 0.0538637
[Epoch 35; Iter   322/ 1097] train: loss: 0.0240322
[Epoch 35; Iter   352/ 1097] train: loss: 0.0032013
[Epoch 35; Iter   382/ 1097] train: loss: 0.0022403
[Epoch 35; Iter   412/ 1097] train: loss: 0.0118060
[Epoch 35; Iter   442/ 1097] train: loss: 0.0094275
[Epoch 35; Iter   472/ 1097] train: loss: 0.0054080
[Epoch 35; Iter   502/ 1097] train: loss: 0.0185894
[Epoch 35; Iter   532/ 1097] train: loss: 0.0083799
[Epoch 35; Iter   562/ 1097] train: loss: 0.0679523
[Epoch 35; Iter   592/ 1097] train: loss: 0.0114763
[Epoch 35; Iter   622/ 1097] train: loss: 0.0068891
[Epoch 35; Iter   652/ 1097] train: loss: 0.0074153
[Epoch 35; Iter   682/ 1097] train: loss: 0.0045606
[Epoch 35; Iter   712/ 1097] train: loss: 0.0781843
[Epoch 35; Iter   742/ 1097] train: loss: 0.0903867
[Epoch 35; Iter   772/ 1097] train: loss: 0.0170218
[Epoch 35; Iter   802/ 1097] train: loss: 0.0064858
[Epoch 35; Iter   832/ 1097] train: loss: 0.0948393
[Epoch 35; Iter   862/ 1097] train: loss: 0.0275790
[Epoch 35; Iter   892/ 1097] train: loss: 0.0162394
[Epoch 35; Iter   922/ 1097] train: loss: 0.0594023
[Epoch 35; Iter   952/ 1097] train: loss: 0.0014306
[Epoch 35; Iter   982/ 1097] train: loss: 0.0111271
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0109456
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0142369
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0136223
[Epoch 35] ogbg-molhiv: 0.720854 val loss: 0.290715
[Epoch 35] ogbg-molhiv: 0.714208 test loss: 0.335513
[Epoch 36; Iter     5/ 1097] train: loss: 0.0193571
[Epoch 36; Iter    35/ 1097] train: loss: 0.0163582
[Epoch 36; Iter    65/ 1097] train: loss: 0.0306572
[Epoch 36; Iter    95/ 1097] train: loss: 0.0367660
[Epoch 36; Iter   125/ 1097] train: loss: 0.0054763
[Epoch 36; Iter   155/ 1097] train: loss: 0.0030902
[Epoch 36; Iter   185/ 1097] train: loss: 0.0096636
[Epoch 36; Iter   215/ 1097] train: loss: 0.0538042
[Epoch 36; Iter   245/ 1097] train: loss: 0.0018625
[Epoch 36; Iter   275/ 1097] train: loss: 0.0081734
[Epoch 36; Iter   305/ 1097] train: loss: 0.1411911
[Epoch 36; Iter   335/ 1097] train: loss: 0.0077941
[Epoch 36; Iter   365/ 1097] train: loss: 0.0030187
[Epoch 36; Iter   395/ 1097] train: loss: 0.0097724
[Epoch 36; Iter   425/ 1097] train: loss: 0.0393127
[Epoch 36; Iter   455/ 1097] train: loss: 0.0186524
[Epoch 36; Iter   485/ 1097] train: loss: 0.0015683
[Epoch 36; Iter   515/ 1097] train: loss: 0.0022613
[Epoch 36; Iter   545/ 1097] train: loss: 0.0102803
[Epoch 36; Iter   575/ 1097] train: loss: 0.0017963
[Epoch 32; Iter   523/ 1097] train: loss: 0.0390742
[Epoch 32; Iter   553/ 1097] train: loss: 0.0047031
[Epoch 32; Iter   583/ 1097] train: loss: 0.1605569
[Epoch 32; Iter   613/ 1097] train: loss: 0.0090963
[Epoch 32; Iter   643/ 1097] train: loss: 0.0577251
[Epoch 32; Iter   673/ 1097] train: loss: 0.0952898
[Epoch 32; Iter   703/ 1097] train: loss: 0.0092739
[Epoch 32; Iter   733/ 1097] train: loss: 0.0135880
[Epoch 32; Iter   763/ 1097] train: loss: 0.0115559
[Epoch 32; Iter   793/ 1097] train: loss: 0.0516414
[Epoch 32; Iter   823/ 1097] train: loss: 0.0290027
[Epoch 32; Iter   853/ 1097] train: loss: 0.0026700
[Epoch 32; Iter   883/ 1097] train: loss: 0.0063502
[Epoch 32; Iter   913/ 1097] train: loss: 0.0237541
[Epoch 32; Iter   943/ 1097] train: loss: 0.0077343
[Epoch 32; Iter   973/ 1097] train: loss: 0.0298439
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0809974
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0029149
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0041643
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0313332
[Epoch 32] ogbg-molhiv: 0.760414 val loss: 0.191171
[Epoch 32] ogbg-molhiv: 0.765459 test loss: 0.209318
[Epoch 33; Iter    26/ 1097] train: loss: 0.1286610
[Epoch 33; Iter    56/ 1097] train: loss: 0.0039323
[Epoch 33; Iter    86/ 1097] train: loss: 0.0092613
[Epoch 33; Iter   116/ 1097] train: loss: 0.0509834
[Epoch 33; Iter   146/ 1097] train: loss: 0.0122949
[Epoch 33; Iter   176/ 1097] train: loss: 0.0035283
[Epoch 33; Iter   206/ 1097] train: loss: 0.0033643
[Epoch 33; Iter   236/ 1097] train: loss: 0.0383229
[Epoch 33; Iter   266/ 1097] train: loss: 0.0018118
[Epoch 33; Iter   296/ 1097] train: loss: 0.0101330
[Epoch 33; Iter   326/ 1097] train: loss: 0.0040304
[Epoch 33; Iter   356/ 1097] train: loss: 0.1658339
[Epoch 33; Iter   386/ 1097] train: loss: 0.0022533
[Epoch 33; Iter   416/ 1097] train: loss: 0.0050884
[Epoch 33; Iter   446/ 1097] train: loss: 0.0017057
[Epoch 33; Iter   476/ 1097] train: loss: 0.0032637
[Epoch 33; Iter   506/ 1097] train: loss: 0.0124711
[Epoch 33; Iter   536/ 1097] train: loss: 0.0071063
[Epoch 33; Iter   566/ 1097] train: loss: 0.0558263
[Epoch 33; Iter   596/ 1097] train: loss: 0.0026781
[Epoch 33; Iter   626/ 1097] train: loss: 0.0088434
[Epoch 33; Iter   656/ 1097] train: loss: 0.0530141
[Epoch 33; Iter   686/ 1097] train: loss: 0.0015670
[Epoch 33; Iter   716/ 1097] train: loss: 0.0690441
[Epoch 33; Iter   746/ 1097] train: loss: 0.0015557
[Epoch 33; Iter   776/ 1097] train: loss: 0.1768330
[Epoch 33; Iter   806/ 1097] train: loss: 0.0056164
[Epoch 33; Iter   836/ 1097] train: loss: 0.0017702
[Epoch 33; Iter   866/ 1097] train: loss: 0.0052388
[Epoch 33; Iter   896/ 1097] train: loss: 0.0109460
[Epoch 33; Iter   926/ 1097] train: loss: 0.0318117
[Epoch 33; Iter   956/ 1097] train: loss: 0.0099345
[Epoch 33; Iter   986/ 1097] train: loss: 0.0026548
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0398471
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0186608
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0276567
[Epoch 33] ogbg-molhiv: 0.783442 val loss: 0.164912
[Epoch 33] ogbg-molhiv: 0.792680 test loss: 0.201679
[Epoch 34; Iter     9/ 1097] train: loss: 0.0041430
[Epoch 34; Iter    39/ 1097] train: loss: 0.0743666
[Epoch 34; Iter    69/ 1097] train: loss: 0.0024225
[Epoch 34; Iter    99/ 1097] train: loss: 0.0057380
[Epoch 34; Iter   129/ 1097] train: loss: 0.0038771
[Epoch 34; Iter   159/ 1097] train: loss: 0.0069169
[Epoch 34; Iter   189/ 1097] train: loss: 0.0043207
[Epoch 34; Iter   219/ 1097] train: loss: 0.0049295
[Epoch 34; Iter   249/ 1097] train: loss: 0.0027665
[Epoch 34; Iter   279/ 1097] train: loss: 0.0292373
[Epoch 34; Iter   309/ 1097] train: loss: 0.0219252
[Epoch 34; Iter   339/ 1097] train: loss: 0.1268857
[Epoch 34; Iter   369/ 1097] train: loss: 0.0267600
[Epoch 34; Iter   399/ 1097] train: loss: 0.0151575
[Epoch 34; Iter   429/ 1097] train: loss: 0.0142286
[Epoch 34; Iter   459/ 1097] train: loss: 0.0028592
[Epoch 34; Iter   489/ 1097] train: loss: 0.0087149
[Epoch 34; Iter   519/ 1097] train: loss: 0.0029583
[Epoch 34; Iter   549/ 1097] train: loss: 0.0460754
[Epoch 34; Iter   579/ 1097] train: loss: 0.0132217
[Epoch 34; Iter   609/ 1097] train: loss: 0.0292913
[Epoch 34; Iter   639/ 1097] train: loss: 0.0106243
[Epoch 34; Iter   669/ 1097] train: loss: 0.0124073
[Epoch 34; Iter   699/ 1097] train: loss: 0.0131670
[Epoch 34; Iter   729/ 1097] train: loss: 0.0196895
[Epoch 34; Iter   759/ 1097] train: loss: 0.2978943
[Epoch 34; Iter   789/ 1097] train: loss: 0.0035132
[Epoch 34; Iter   819/ 1097] train: loss: 0.0356135
[Epoch 34; Iter   849/ 1097] train: loss: 0.2759030
[Epoch 34; Iter   879/ 1097] train: loss: 0.0199697
[Epoch 34; Iter   909/ 1097] train: loss: 0.0132554
[Epoch 34; Iter   939/ 1097] train: loss: 0.0062027
[Epoch 34; Iter   969/ 1097] train: loss: 0.0131998
[Epoch 34; Iter   999/ 1097] train: loss: 0.0617574
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0581286
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1058354
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0073767
[Epoch 34] ogbg-molhiv: 0.785258 val loss: 0.168135
[Epoch 34] ogbg-molhiv: 0.790641 test loss: 0.221977
[Epoch 35; Iter    22/ 1097] train: loss: 0.0034468
[Epoch 35; Iter    52/ 1097] train: loss: 0.0248843
[Epoch 35; Iter    82/ 1097] train: loss: 0.0312318
[Epoch 35; Iter   112/ 1097] train: loss: 0.0031657
[Epoch 35; Iter   142/ 1097] train: loss: 0.0079189
[Epoch 35; Iter   172/ 1097] train: loss: 0.0158235
[Epoch 35; Iter   202/ 1097] train: loss: 0.0124483
[Epoch 35; Iter   232/ 1097] train: loss: 0.0120658
[Epoch 35; Iter   262/ 1097] train: loss: 0.0014958
[Epoch 35; Iter   292/ 1097] train: loss: 0.0033169
[Epoch 35; Iter   322/ 1097] train: loss: 0.0054668
[Epoch 35; Iter   352/ 1097] train: loss: 0.0158828
[Epoch 35; Iter   382/ 1097] train: loss: 0.0127057
[Epoch 35; Iter   412/ 1097] train: loss: 0.0485279
[Epoch 35; Iter   442/ 1097] train: loss: 0.0113240
[Epoch 35; Iter   472/ 1097] train: loss: 0.0179397
[Epoch 35; Iter   502/ 1097] train: loss: 0.0112344
[Epoch 35; Iter   532/ 1097] train: loss: 0.0017601
[Epoch 35; Iter   562/ 1097] train: loss: 0.0688148
[Epoch 35; Iter   592/ 1097] train: loss: 0.0020873
[Epoch 35; Iter   622/ 1097] train: loss: 0.0043174
[Epoch 35; Iter   652/ 1097] train: loss: 0.0033391
[Epoch 35; Iter   682/ 1097] train: loss: 0.0046990
[Epoch 35; Iter   712/ 1097] train: loss: 0.0601976
[Epoch 35; Iter   742/ 1097] train: loss: 0.0019410
[Epoch 35; Iter   772/ 1097] train: loss: 0.0012772
[Epoch 35; Iter   802/ 1097] train: loss: 0.0038931
[Epoch 35; Iter   832/ 1097] train: loss: 0.0078414
[Epoch 35; Iter   862/ 1097] train: loss: 0.0163656
[Epoch 35; Iter   892/ 1097] train: loss: 0.1647815
[Epoch 35; Iter   922/ 1097] train: loss: 0.0014418
[Epoch 35; Iter   952/ 1097] train: loss: 0.0307421
[Epoch 35; Iter   982/ 1097] train: loss: 0.0022862
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0055701
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0070277
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0057587
[Epoch 35] ogbg-molhiv: 0.786400 val loss: 0.199499
[Epoch 35] ogbg-molhiv: 0.796164 test loss: 0.210149
[Epoch 36; Iter     5/ 1097] train: loss: 0.0037934
[Epoch 36; Iter    35/ 1097] train: loss: 0.0031581
[Epoch 36; Iter    65/ 1097] train: loss: 0.0071049
[Epoch 36; Iter    95/ 1097] train: loss: 0.0143806
[Epoch 36; Iter   125/ 1097] train: loss: 0.0018120
[Epoch 36; Iter   155/ 1097] train: loss: 0.0064685
[Epoch 36; Iter   185/ 1097] train: loss: 0.0022794
[Epoch 36; Iter   215/ 1097] train: loss: 0.0977723
[Epoch 36; Iter   245/ 1097] train: loss: 0.0017891
[Epoch 36; Iter   275/ 1097] train: loss: 0.0067762
[Epoch 36; Iter   305/ 1097] train: loss: 0.0039997
[Epoch 36; Iter   335/ 1097] train: loss: 0.0130431
[Epoch 36; Iter   365/ 1097] train: loss: 0.0055998
[Epoch 36; Iter   395/ 1097] train: loss: 0.0234075
[Epoch 36; Iter   425/ 1097] train: loss: 0.0063487
[Epoch 36; Iter   455/ 1097] train: loss: 0.0020699
[Epoch 36; Iter   485/ 1097] train: loss: 0.0077959
[Epoch 36; Iter   515/ 1097] train: loss: 0.0155358
[Epoch 36; Iter   545/ 1097] train: loss: 0.0090763
[Epoch 36; Iter   575/ 1097] train: loss: 0.0067980
[Epoch 32; Iter   523/ 1097] train: loss: 0.0013489
[Epoch 32; Iter   553/ 1097] train: loss: 0.0097123
[Epoch 32; Iter   583/ 1097] train: loss: 0.0222512
[Epoch 32; Iter   613/ 1097] train: loss: 0.0076725
[Epoch 32; Iter   643/ 1097] train: loss: 0.0016812
[Epoch 32; Iter   673/ 1097] train: loss: 0.0464785
[Epoch 32; Iter   703/ 1097] train: loss: 0.0008418
[Epoch 32; Iter   733/ 1097] train: loss: 0.0008080
[Epoch 32; Iter   763/ 1097] train: loss: 0.0013698
[Epoch 32; Iter   793/ 1097] train: loss: 0.0068561
[Epoch 32; Iter   823/ 1097] train: loss: 0.0024745
[Epoch 32; Iter   853/ 1097] train: loss: 0.0033826
[Epoch 32; Iter   883/ 1097] train: loss: 0.0118120
[Epoch 32; Iter   913/ 1097] train: loss: 0.0500451
[Epoch 32; Iter   943/ 1097] train: loss: 0.0049030
[Epoch 32; Iter   973/ 1097] train: loss: 0.0115740
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0014746
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0016094
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0218526
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0192518
[Epoch 32] ogbg-molhiv: 0.643877 val loss: 1.646138
[Epoch 32] ogbg-molhiv: 0.564376 test loss: 1.526431
[Epoch 33; Iter    26/ 1097] train: loss: 0.0035053
[Epoch 33; Iter    56/ 1097] train: loss: 0.0150135
[Epoch 33; Iter    86/ 1097] train: loss: 0.0322708
[Epoch 33; Iter   116/ 1097] train: loss: 0.0645113
[Epoch 33; Iter   146/ 1097] train: loss: 0.0025305
[Epoch 33; Iter   176/ 1097] train: loss: 0.0022337
[Epoch 33; Iter   206/ 1097] train: loss: 0.0008824
[Epoch 33; Iter   236/ 1097] train: loss: 0.0002703
[Epoch 33; Iter   266/ 1097] train: loss: 0.0021303
[Epoch 33; Iter   296/ 1097] train: loss: 0.0622901
[Epoch 33; Iter   326/ 1097] train: loss: 0.1297068
[Epoch 33; Iter   356/ 1097] train: loss: 0.0024784
[Epoch 33; Iter   386/ 1097] train: loss: 0.0144557
[Epoch 33; Iter   416/ 1097] train: loss: 0.0074851
[Epoch 33; Iter   446/ 1097] train: loss: 0.0008036
[Epoch 33; Iter   476/ 1097] train: loss: 0.1486471
[Epoch 33; Iter   506/ 1097] train: loss: 0.0318361
[Epoch 33; Iter   536/ 1097] train: loss: 0.0392315
[Epoch 33; Iter   566/ 1097] train: loss: 0.0056142
[Epoch 33; Iter   596/ 1097] train: loss: 0.0011499
[Epoch 33; Iter   626/ 1097] train: loss: 0.0018230
[Epoch 33; Iter   656/ 1097] train: loss: 0.0011981
[Epoch 33; Iter   686/ 1097] train: loss: 0.0026956
[Epoch 33; Iter   716/ 1097] train: loss: 0.0110199
[Epoch 33; Iter   746/ 1097] train: loss: 0.0065850
[Epoch 33; Iter   776/ 1097] train: loss: 0.0016956
[Epoch 33; Iter   806/ 1097] train: loss: 0.0197934
[Epoch 33; Iter   836/ 1097] train: loss: 0.0024148
[Epoch 33; Iter   866/ 1097] train: loss: 0.0049779
[Epoch 33; Iter   896/ 1097] train: loss: 0.0008592
[Epoch 33; Iter   926/ 1097] train: loss: 0.0078889
[Epoch 33; Iter   956/ 1097] train: loss: 0.0045649
[Epoch 33; Iter   986/ 1097] train: loss: 0.0017457
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0108654
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0012203
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0312945
[Epoch 33] ogbg-molhiv: 0.678219 val loss: 8.993637
[Epoch 33] ogbg-molhiv: 0.590726 test loss: 9.622485
[Epoch 34; Iter     9/ 1097] train: loss: 0.0104935
[Epoch 34; Iter    39/ 1097] train: loss: 0.0087008
[Epoch 34; Iter    69/ 1097] train: loss: 0.0062154
[Epoch 34; Iter    99/ 1097] train: loss: 0.0132369
[Epoch 34; Iter   129/ 1097] train: loss: 0.0008374
[Epoch 34; Iter   159/ 1097] train: loss: 0.0035928
[Epoch 34; Iter   189/ 1097] train: loss: 0.0086817
[Epoch 34; Iter   219/ 1097] train: loss: 0.0012144
[Epoch 34; Iter   249/ 1097] train: loss: 0.0064319
[Epoch 34; Iter   279/ 1097] train: loss: 0.0041724
[Epoch 34; Iter   309/ 1097] train: loss: 0.0174933
[Epoch 34; Iter   339/ 1097] train: loss: 0.0052198
[Epoch 34; Iter   369/ 1097] train: loss: 0.0065731
[Epoch 34; Iter   399/ 1097] train: loss: 0.0003078
[Epoch 34; Iter   429/ 1097] train: loss: 0.0572047
[Epoch 34; Iter   459/ 1097] train: loss: 0.0052416
[Epoch 34; Iter   489/ 1097] train: loss: 0.0007488
[Epoch 34; Iter   519/ 1097] train: loss: 0.0011117
[Epoch 34; Iter   549/ 1097] train: loss: 0.0029622
[Epoch 34; Iter   579/ 1097] train: loss: 0.0059234
[Epoch 34; Iter   609/ 1097] train: loss: 0.0006613
[Epoch 34; Iter   639/ 1097] train: loss: 0.0481605
[Epoch 34; Iter   669/ 1097] train: loss: 0.0001231
[Epoch 34; Iter   699/ 1097] train: loss: 0.0021914
[Epoch 34; Iter   729/ 1097] train: loss: 0.0389297
[Epoch 34; Iter   759/ 1097] train: loss: 0.0033012
[Epoch 34; Iter   789/ 1097] train: loss: 0.0059184
[Epoch 34; Iter   819/ 1097] train: loss: 0.0079487
[Epoch 34; Iter   849/ 1097] train: loss: 0.0061700
[Epoch 34; Iter   879/ 1097] train: loss: 0.0465698
[Epoch 34; Iter   909/ 1097] train: loss: 0.0007854
[Epoch 34; Iter   939/ 1097] train: loss: 0.0570816
[Epoch 34; Iter   969/ 1097] train: loss: 0.0096926
[Epoch 34; Iter   999/ 1097] train: loss: 0.0227222
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0217810
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0037782
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0114548
[Epoch 34] ogbg-molhiv: 0.650301 val loss: 12.305792
[Epoch 34] ogbg-molhiv: 0.555017 test loss: 11.179704
[Epoch 35; Iter    22/ 1097] train: loss: 0.0057855
[Epoch 35; Iter    52/ 1097] train: loss: 0.0009277
[Epoch 35; Iter    82/ 1097] train: loss: 0.0262705
[Epoch 35; Iter   112/ 1097] train: loss: 0.0048493
[Epoch 35; Iter   142/ 1097] train: loss: 0.0009639
[Epoch 35; Iter   172/ 1097] train: loss: 0.0009443
[Epoch 35; Iter   202/ 1097] train: loss: 0.0002704
[Epoch 35; Iter   232/ 1097] train: loss: 0.0016383
[Epoch 35; Iter   262/ 1097] train: loss: 0.0002392
[Epoch 35; Iter   292/ 1097] train: loss: 0.0081504
[Epoch 35; Iter   322/ 1097] train: loss: 0.0075070
[Epoch 35; Iter   352/ 1097] train: loss: 0.0627851
[Epoch 35; Iter   382/ 1097] train: loss: 0.0132947
[Epoch 35; Iter   412/ 1097] train: loss: 0.0020443
[Epoch 35; Iter   442/ 1097] train: loss: 0.0260482
[Epoch 35; Iter   472/ 1097] train: loss: 0.0078098
[Epoch 35; Iter   502/ 1097] train: loss: 0.0006953
[Epoch 35; Iter   532/ 1097] train: loss: 0.0110803
[Epoch 35; Iter   562/ 1097] train: loss: 0.0101957
[Epoch 35; Iter   592/ 1097] train: loss: 0.0004086
[Epoch 35; Iter   622/ 1097] train: loss: 0.0421442
[Epoch 35; Iter   652/ 1097] train: loss: 0.0263620
[Epoch 35; Iter   682/ 1097] train: loss: 0.0345920
[Epoch 35; Iter   712/ 1097] train: loss: 0.0196315
[Epoch 35; Iter   742/ 1097] train: loss: 0.0303568
[Epoch 35; Iter   772/ 1097] train: loss: 0.0054791
[Epoch 35; Iter   802/ 1097] train: loss: 0.0002322
[Epoch 35; Iter   832/ 1097] train: loss: 0.0002315
[Epoch 35; Iter   862/ 1097] train: loss: 0.0008477
[Epoch 35; Iter   892/ 1097] train: loss: 0.0037416
[Epoch 35; Iter   922/ 1097] train: loss: 0.0009880
[Epoch 35; Iter   952/ 1097] train: loss: 0.0038973
[Epoch 35; Iter   982/ 1097] train: loss: 0.0253091
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0376691
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1085393
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0062246
[Epoch 35] ogbg-molhiv: 0.658476 val loss: 8.754370
[Epoch 35] ogbg-molhiv: 0.622629 test loss: 10.014339
[Epoch 36; Iter     5/ 1097] train: loss: 0.0010119
[Epoch 36; Iter    35/ 1097] train: loss: 0.0013286
[Epoch 36; Iter    65/ 1097] train: loss: 0.0014517
[Epoch 36; Iter    95/ 1097] train: loss: 0.0034286
[Epoch 36; Iter   125/ 1097] train: loss: 0.0028750
[Epoch 36; Iter   155/ 1097] train: loss: 0.0756278
[Epoch 36; Iter   185/ 1097] train: loss: 0.0166194
[Epoch 36; Iter   215/ 1097] train: loss: 0.0029806
[Epoch 36; Iter   245/ 1097] train: loss: 0.0273870
[Epoch 36; Iter   275/ 1097] train: loss: 0.0000818
[Epoch 36; Iter   305/ 1097] train: loss: 0.0242770
[Epoch 36; Iter   335/ 1097] train: loss: 0.0177443
[Epoch 36; Iter   365/ 1097] train: loss: 0.0223592
[Epoch 36; Iter   395/ 1097] train: loss: 0.0005674
[Epoch 36; Iter   425/ 1097] train: loss: 0.0004279
[Epoch 36; Iter   455/ 1097] train: loss: 0.0054406
[Epoch 36; Iter   485/ 1097] train: loss: 0.0641927
[Epoch 36; Iter   515/ 1097] train: loss: 0.0004921
[Epoch 36; Iter   545/ 1097] train: loss: 0.0004066
[Epoch 36; Iter   575/ 1097] train: loss: 0.0010649
[Epoch 32; Iter   523/ 1097] train: loss: 0.0014324
[Epoch 32; Iter   553/ 1097] train: loss: 0.0077468
[Epoch 32; Iter   583/ 1097] train: loss: 0.2781034
[Epoch 32; Iter   613/ 1097] train: loss: 0.0147737
[Epoch 32; Iter   643/ 1097] train: loss: 0.1670998
[Epoch 32; Iter   673/ 1097] train: loss: 0.2448850
[Epoch 32; Iter   703/ 1097] train: loss: 0.1014803
[Epoch 32; Iter   733/ 1097] train: loss: 0.0219169
[Epoch 32; Iter   763/ 1097] train: loss: 0.0153631
[Epoch 32; Iter   793/ 1097] train: loss: 0.0378904
[Epoch 32; Iter   823/ 1097] train: loss: 0.0071444
[Epoch 32; Iter   853/ 1097] train: loss: 0.0681088
[Epoch 32; Iter   883/ 1097] train: loss: 0.0168757
[Epoch 32; Iter   913/ 1097] train: loss: 0.0496449
[Epoch 32; Iter   943/ 1097] train: loss: 0.0080369
[Epoch 32; Iter   973/ 1097] train: loss: 0.0078558
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0946463
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0079607
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0056211
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0196838
[Epoch 32] ogbg-molhiv: 0.770980 val loss: 2.487874
[Epoch 32] ogbg-molhiv: 0.707190 test loss: 1.520428
[Epoch 33; Iter    26/ 1097] train: loss: 0.0797522
[Epoch 33; Iter    56/ 1097] train: loss: 0.0064690
[Epoch 33; Iter    86/ 1097] train: loss: 0.0448815
[Epoch 33; Iter   116/ 1097] train: loss: 0.0353531
[Epoch 33; Iter   146/ 1097] train: loss: 0.0034021
[Epoch 33; Iter   176/ 1097] train: loss: 0.0091115
[Epoch 33; Iter   206/ 1097] train: loss: 0.0117611
[Epoch 33; Iter   236/ 1097] train: loss: 0.0216640
[Epoch 33; Iter   266/ 1097] train: loss: 0.0076423
[Epoch 33; Iter   296/ 1097] train: loss: 0.0035081
[Epoch 33; Iter   326/ 1097] train: loss: 0.0425523
[Epoch 33; Iter   356/ 1097] train: loss: 0.0644301
[Epoch 33; Iter   386/ 1097] train: loss: 0.0113563
[Epoch 33; Iter   416/ 1097] train: loss: 0.0135013
[Epoch 33; Iter   446/ 1097] train: loss: 0.0135818
[Epoch 33; Iter   476/ 1097] train: loss: 0.0030629
[Epoch 33; Iter   506/ 1097] train: loss: 0.0124498
[Epoch 33; Iter   536/ 1097] train: loss: 0.0021873
[Epoch 33; Iter   566/ 1097] train: loss: 0.0170616
[Epoch 33; Iter   596/ 1097] train: loss: 0.0016705
[Epoch 33; Iter   626/ 1097] train: loss: 0.0012329
[Epoch 33; Iter   656/ 1097] train: loss: 0.0021841
[Epoch 33; Iter   686/ 1097] train: loss: 0.0470652
[Epoch 33; Iter   716/ 1097] train: loss: 0.2775211
[Epoch 33; Iter   746/ 1097] train: loss: 0.0174028
[Epoch 33; Iter   776/ 1097] train: loss: 0.0855003
[Epoch 33; Iter   806/ 1097] train: loss: 0.0254139
[Epoch 33; Iter   836/ 1097] train: loss: 0.0270541
[Epoch 33; Iter   866/ 1097] train: loss: 0.0110978
[Epoch 33; Iter   896/ 1097] train: loss: 0.0285722
[Epoch 33; Iter   926/ 1097] train: loss: 0.0050991
[Epoch 33; Iter   956/ 1097] train: loss: 0.0152255
[Epoch 33; Iter   986/ 1097] train: loss: 0.0177488
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0754346
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0083752
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0163047
[Epoch 33] ogbg-molhiv: 0.766939 val loss: 1.143054
[Epoch 33] ogbg-molhiv: 0.760142 test loss: 1.227405
[Epoch 34; Iter     9/ 1097] train: loss: 0.0786469
[Epoch 34; Iter    39/ 1097] train: loss: 0.0665424
[Epoch 34; Iter    69/ 1097] train: loss: 0.0060141
[Epoch 34; Iter    99/ 1097] train: loss: 0.0177248
[Epoch 34; Iter   129/ 1097] train: loss: 0.0074167
[Epoch 34; Iter   159/ 1097] train: loss: 0.0336160
[Epoch 34; Iter   189/ 1097] train: loss: 0.0080006
[Epoch 34; Iter   219/ 1097] train: loss: 0.0523090
[Epoch 34; Iter   249/ 1097] train: loss: 0.0049165
[Epoch 34; Iter   279/ 1097] train: loss: 0.0304297
[Epoch 34; Iter   309/ 1097] train: loss: 0.0022903
[Epoch 34; Iter   339/ 1097] train: loss: 0.0197497
[Epoch 34; Iter   369/ 1097] train: loss: 0.0248028
[Epoch 34; Iter   399/ 1097] train: loss: 0.0678070
[Epoch 34; Iter   429/ 1097] train: loss: 0.0029674
[Epoch 34; Iter   459/ 1097] train: loss: 0.0025954
[Epoch 34; Iter   489/ 1097] train: loss: 0.0089860
[Epoch 34; Iter   519/ 1097] train: loss: 0.0085850
[Epoch 34; Iter   549/ 1097] train: loss: 0.0024054
[Epoch 34; Iter   579/ 1097] train: loss: 0.1743901
[Epoch 34; Iter   609/ 1097] train: loss: 0.0140567
[Epoch 34; Iter   639/ 1097] train: loss: 0.0548468
[Epoch 34; Iter   669/ 1097] train: loss: 0.0505326
[Epoch 34; Iter   699/ 1097] train: loss: 0.1100404
[Epoch 34; Iter   729/ 1097] train: loss: 0.0228801
[Epoch 34; Iter   759/ 1097] train: loss: 0.0797345
[Epoch 34; Iter   789/ 1097] train: loss: 0.2100254
[Epoch 34; Iter   819/ 1097] train: loss: 0.0104657
[Epoch 34; Iter   849/ 1097] train: loss: 0.1668448
[Epoch 34; Iter   879/ 1097] train: loss: 0.0023051
[Epoch 34; Iter   909/ 1097] train: loss: 0.0040937
[Epoch 34; Iter   939/ 1097] train: loss: 0.0519966
[Epoch 34; Iter   969/ 1097] train: loss: 0.0841630
[Epoch 34; Iter   999/ 1097] train: loss: 0.1640159
[Epoch 34; Iter  1029/ 1097] train: loss: 0.4149781
[Epoch 34; Iter  1059/ 1097] train: loss: 0.2272420
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0225380
[Epoch 34] ogbg-molhiv: 0.768656 val loss: 3.710584
[Epoch 34] ogbg-molhiv: 0.701056 test loss: 2.764122
[Epoch 35; Iter    22/ 1097] train: loss: 0.0232829
[Epoch 35; Iter    52/ 1097] train: loss: 0.0251327
[Epoch 35; Iter    82/ 1097] train: loss: 0.3904304
[Epoch 35; Iter   112/ 1097] train: loss: 0.1499266
[Epoch 35; Iter   142/ 1097] train: loss: 0.0470698
[Epoch 35; Iter   172/ 1097] train: loss: 0.0891668
[Epoch 35; Iter   202/ 1097] train: loss: 0.0569598
[Epoch 35; Iter   232/ 1097] train: loss: 0.0520717
[Epoch 35; Iter   262/ 1097] train: loss: 0.1587788
[Epoch 35; Iter   292/ 1097] train: loss: 0.0125572
[Epoch 35; Iter   322/ 1097] train: loss: 0.0875907
[Epoch 35; Iter   352/ 1097] train: loss: 0.0101352
[Epoch 35; Iter   382/ 1097] train: loss: 0.0102664
[Epoch 35; Iter   412/ 1097] train: loss: 0.0377042
[Epoch 35; Iter   442/ 1097] train: loss: 0.0368923
[Epoch 35; Iter   472/ 1097] train: loss: 0.0148260
[Epoch 35; Iter   502/ 1097] train: loss: 0.0065798
[Epoch 35; Iter   532/ 1097] train: loss: 0.0268287
[Epoch 35; Iter   562/ 1097] train: loss: 0.1664054
[Epoch 35; Iter   592/ 1097] train: loss: 0.0300571
[Epoch 35; Iter   622/ 1097] train: loss: 0.0305846
[Epoch 35; Iter   652/ 1097] train: loss: 0.0218364
[Epoch 35; Iter   682/ 1097] train: loss: 0.0686752
[Epoch 35; Iter   712/ 1097] train: loss: 0.0130705
[Epoch 35; Iter   742/ 1097] train: loss: 0.0269678
[Epoch 35; Iter   772/ 1097] train: loss: 0.0150245
[Epoch 35; Iter   802/ 1097] train: loss: 0.0075340
[Epoch 35; Iter   832/ 1097] train: loss: 0.0057100
[Epoch 35; Iter   862/ 1097] train: loss: 0.0868127
[Epoch 35; Iter   892/ 1097] train: loss: 0.0330574
[Epoch 35; Iter   922/ 1097] train: loss: 0.0267578
[Epoch 35; Iter   952/ 1097] train: loss: 0.0269213
[Epoch 35; Iter   982/ 1097] train: loss: 0.0518588
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0694310
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0150703
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0111304
[Epoch 35] ogbg-molhiv: 0.792300 val loss: 0.376273
[Epoch 35] ogbg-molhiv: 0.691336 test loss: 0.318835
[Epoch 36; Iter     5/ 1097] train: loss: 0.0345704
[Epoch 36; Iter    35/ 1097] train: loss: 0.0068200
[Epoch 36; Iter    65/ 1097] train: loss: 0.0064834
[Epoch 36; Iter    95/ 1097] train: loss: 0.1295342
[Epoch 36; Iter   125/ 1097] train: loss: 0.0261256
[Epoch 36; Iter   155/ 1097] train: loss: 0.0159367
[Epoch 36; Iter   185/ 1097] train: loss: 0.0200512
[Epoch 36; Iter   215/ 1097] train: loss: 0.0147480
[Epoch 36; Iter   245/ 1097] train: loss: 0.0675082
[Epoch 36; Iter   275/ 1097] train: loss: 0.0049872
[Epoch 36; Iter   305/ 1097] train: loss: 0.0241409
[Epoch 36; Iter   335/ 1097] train: loss: 0.0214474
[Epoch 36; Iter   365/ 1097] train: loss: 0.0334271
[Epoch 36; Iter   395/ 1097] train: loss: 0.0131229
[Epoch 36; Iter   425/ 1097] train: loss: 0.0107872
[Epoch 36; Iter   455/ 1097] train: loss: 0.0062036
[Epoch 36; Iter   485/ 1097] train: loss: 0.0102753
[Epoch 36; Iter   515/ 1097] train: loss: 0.0070714
[Epoch 36; Iter   545/ 1097] train: loss: 0.0452931
[Epoch 36; Iter   575/ 1097] train: loss: 0.0133813
[Epoch 28; Iter   441/ 1097] train: loss: 0.0213917
[Epoch 28; Iter   471/ 1097] train: loss: 0.0444239
[Epoch 28; Iter   501/ 1097] train: loss: 0.0362997
[Epoch 28; Iter   531/ 1097] train: loss: 0.1878610
[Epoch 28; Iter   561/ 1097] train: loss: 0.0258367
[Epoch 28; Iter   591/ 1097] train: loss: 0.1934286
[Epoch 28; Iter   621/ 1097] train: loss: 0.1322628
[Epoch 28; Iter   651/ 1097] train: loss: 0.1653231
[Epoch 28; Iter   681/ 1097] train: loss: 0.0377108
[Epoch 28; Iter   711/ 1097] train: loss: 0.0376546
[Epoch 28; Iter   741/ 1097] train: loss: 0.1789754
[Epoch 28; Iter   771/ 1097] train: loss: 0.0504305
[Epoch 28; Iter   801/ 1097] train: loss: 0.2021610
[Epoch 28; Iter   831/ 1097] train: loss: 0.0571156
[Epoch 28; Iter   861/ 1097] train: loss: 0.0509693
[Epoch 28; Iter   891/ 1097] train: loss: 0.3363863
[Epoch 28; Iter   921/ 1097] train: loss: 0.1384306
[Epoch 28; Iter   951/ 1097] train: loss: 0.0182004
[Epoch 28; Iter   981/ 1097] train: loss: 0.0214104
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0212406
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1962489
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1914599
[Epoch 28] ogbg-molhiv: 0.824815 val loss: 0.075292
[Epoch 28] ogbg-molhiv: 0.767738 test loss: 0.122419
[Epoch 29; Iter     4/ 1097] train: loss: 0.0402652
[Epoch 29; Iter    34/ 1097] train: loss: 0.0225835
[Epoch 29; Iter    64/ 1097] train: loss: 0.4598188
[Epoch 29; Iter    94/ 1097] train: loss: 0.0259914
[Epoch 29; Iter   124/ 1097] train: loss: 0.0437659
[Epoch 29; Iter   154/ 1097] train: loss: 0.2077233
[Epoch 29; Iter   184/ 1097] train: loss: 0.1921328
[Epoch 29; Iter   214/ 1097] train: loss: 0.1708673
[Epoch 29; Iter   244/ 1097] train: loss: 0.0160036
[Epoch 29; Iter   274/ 1097] train: loss: 0.0434383
[Epoch 29; Iter   304/ 1097] train: loss: 0.0243698
[Epoch 29; Iter   334/ 1097] train: loss: 0.0192013
[Epoch 29; Iter   364/ 1097] train: loss: 0.0482502
[Epoch 29; Iter   394/ 1097] train: loss: 0.0228342
[Epoch 29; Iter   424/ 1097] train: loss: 0.0452668
[Epoch 29; Iter   454/ 1097] train: loss: 0.0261533
[Epoch 29; Iter   484/ 1097] train: loss: 0.0265300
[Epoch 29; Iter   514/ 1097] train: loss: 0.2335619
[Epoch 29; Iter   544/ 1097] train: loss: 0.0444766
[Epoch 29; Iter   574/ 1097] train: loss: 0.0131476
[Epoch 29; Iter   604/ 1097] train: loss: 0.0443203
[Epoch 29; Iter   634/ 1097] train: loss: 0.0173171
[Epoch 29; Iter   664/ 1097] train: loss: 0.0130158
[Epoch 29; Iter   694/ 1097] train: loss: 0.1752022
[Epoch 29; Iter   724/ 1097] train: loss: 0.0259320
[Epoch 29; Iter   754/ 1097] train: loss: 0.0163493
[Epoch 29; Iter   784/ 1097] train: loss: 0.0655678
[Epoch 29; Iter   814/ 1097] train: loss: 0.1343752
[Epoch 29; Iter   844/ 1097] train: loss: 0.0396446
[Epoch 29; Iter   874/ 1097] train: loss: 0.0306584
[Epoch 29; Iter   904/ 1097] train: loss: 0.0424276
[Epoch 29; Iter   934/ 1097] train: loss: 0.0184778
[Epoch 29; Iter   964/ 1097] train: loss: 0.0217811
[Epoch 29; Iter   994/ 1097] train: loss: 0.1343291
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0223454
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1425675
[Epoch 29; Iter  1084/ 1097] train: loss: 0.2072457
[Epoch 29] ogbg-molhiv: 0.811465 val loss: 0.135868
[Epoch 29] ogbg-molhiv: 0.778142 test loss: 0.134743
[Epoch 30; Iter    17/ 1097] train: loss: 0.1915673
[Epoch 30; Iter    47/ 1097] train: loss: 0.0439117
[Epoch 30; Iter    77/ 1097] train: loss: 0.0082855
[Epoch 30; Iter   107/ 1097] train: loss: 0.1037086
[Epoch 30; Iter   137/ 1097] train: loss: 0.0344947
[Epoch 30; Iter   167/ 1097] train: loss: 0.2458523
[Epoch 30; Iter   197/ 1097] train: loss: 0.0214468
[Epoch 30; Iter   227/ 1097] train: loss: 0.0233903
[Epoch 30; Iter   257/ 1097] train: loss: 0.0898296
[Epoch 30; Iter   287/ 1097] train: loss: 0.0983436
[Epoch 30; Iter   317/ 1097] train: loss: 0.1108136
[Epoch 30; Iter   347/ 1097] train: loss: 0.0177002
[Epoch 30; Iter   377/ 1097] train: loss: 0.1245918
[Epoch 30; Iter   407/ 1097] train: loss: 0.0183360
[Epoch 30; Iter   437/ 1097] train: loss: 0.1213224
[Epoch 30; Iter   467/ 1097] train: loss: 0.0285151
[Epoch 30; Iter   497/ 1097] train: loss: 0.1000127
[Epoch 30; Iter   527/ 1097] train: loss: 0.2299844
[Epoch 30; Iter   557/ 1097] train: loss: 0.1150927
[Epoch 30; Iter   587/ 1097] train: loss: 0.0985300
[Epoch 30; Iter   617/ 1097] train: loss: 0.0221488
[Epoch 30; Iter   647/ 1097] train: loss: 0.0435428
[Epoch 30; Iter   677/ 1097] train: loss: 0.1008922
[Epoch 30; Iter   707/ 1097] train: loss: 0.0206740
[Epoch 30; Iter   737/ 1097] train: loss: 0.0121369
[Epoch 30; Iter   767/ 1097] train: loss: 0.0251083
[Epoch 30; Iter   797/ 1097] train: loss: 0.0421919
[Epoch 30; Iter   827/ 1097] train: loss: 0.0790414
[Epoch 30; Iter   857/ 1097] train: loss: 0.0738518
[Epoch 30; Iter   887/ 1097] train: loss: 0.0692733
[Epoch 30; Iter   917/ 1097] train: loss: 0.1144152
[Epoch 30; Iter   947/ 1097] train: loss: 0.0914000
[Epoch 30; Iter   977/ 1097] train: loss: 0.1420116
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0127674
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0787480
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0490449
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0355552
[Epoch 30] ogbg-molhiv: 0.806538 val loss: 0.077846
[Epoch 30] ogbg-molhiv: 0.779521 test loss: 0.132762
[Epoch 31; Iter    30/ 1097] train: loss: 0.0297448
[Epoch 31; Iter    60/ 1097] train: loss: 0.2445378
[Epoch 31; Iter    90/ 1097] train: loss: 0.0327127
[Epoch 31; Iter   120/ 1097] train: loss: 0.0140009
[Epoch 31; Iter   150/ 1097] train: loss: 0.0726227
[Epoch 31; Iter   180/ 1097] train: loss: 0.0509645
[Epoch 31; Iter   210/ 1097] train: loss: 0.1412545
[Epoch 31; Iter   240/ 1097] train: loss: 0.1845528
[Epoch 31; Iter   270/ 1097] train: loss: 0.0675739
[Epoch 31; Iter   300/ 1097] train: loss: 0.0228617
[Epoch 31; Iter   330/ 1097] train: loss: 0.0221073
[Epoch 31; Iter   360/ 1097] train: loss: 0.0246218
[Epoch 31; Iter   390/ 1097] train: loss: 0.0505868
[Epoch 31; Iter   420/ 1097] train: loss: 0.0221758
[Epoch 31; Iter   450/ 1097] train: loss: 0.0144646
[Epoch 31; Iter   480/ 1097] train: loss: 0.0516788
[Epoch 31; Iter   510/ 1097] train: loss: 0.0132633
[Epoch 31; Iter   540/ 1097] train: loss: 0.1132108
[Epoch 31; Iter   570/ 1097] train: loss: 0.0279433
[Epoch 31; Iter   600/ 1097] train: loss: 0.0384532
[Epoch 31; Iter   630/ 1097] train: loss: 0.2412226
[Epoch 31; Iter   660/ 1097] train: loss: 0.0234015
[Epoch 31; Iter   690/ 1097] train: loss: 0.1595355
[Epoch 31; Iter   720/ 1097] train: loss: 0.1310083
[Epoch 31; Iter   750/ 1097] train: loss: 0.1444689
[Epoch 31; Iter   780/ 1097] train: loss: 0.0196637
[Epoch 31; Iter   810/ 1097] train: loss: 0.0268222
[Epoch 31; Iter   840/ 1097] train: loss: 0.0209890
[Epoch 31; Iter   870/ 1097] train: loss: 0.0166538
[Epoch 31; Iter   900/ 1097] train: loss: 0.1739280
[Epoch 31; Iter   930/ 1097] train: loss: 0.0738765
[Epoch 31; Iter   960/ 1097] train: loss: 0.1353108
[Epoch 31; Iter   990/ 1097] train: loss: 0.0242887
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0665805
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0394676
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0411540
[Epoch 31] ogbg-molhiv: 0.823471 val loss: 0.094980
[Epoch 31] ogbg-molhiv: 0.762143 test loss: 0.134714
[Epoch 32; Iter    13/ 1097] train: loss: 0.5384453
[Epoch 32; Iter    43/ 1097] train: loss: 0.0458607
[Epoch 32; Iter    73/ 1097] train: loss: 0.0117075
[Epoch 32; Iter   103/ 1097] train: loss: 0.0250164
[Epoch 32; Iter   133/ 1097] train: loss: 0.0142481
[Epoch 32; Iter   163/ 1097] train: loss: 0.0459714
[Epoch 32; Iter   193/ 1097] train: loss: 0.0121843
[Epoch 32; Iter   223/ 1097] train: loss: 0.0678030
[Epoch 32; Iter   253/ 1097] train: loss: 0.0167902
[Epoch 32; Iter   283/ 1097] train: loss: 0.0221572
[Epoch 32; Iter   313/ 1097] train: loss: 0.0209097
[Epoch 32; Iter   343/ 1097] train: loss: 0.0605358
[Epoch 32; Iter   373/ 1097] train: loss: 0.0110772
[Epoch 32; Iter   403/ 1097] train: loss: 0.1787317
[Epoch 32; Iter   433/ 1097] train: loss: 0.0443315
[Epoch 32; Iter   463/ 1097] train: loss: 0.0187714
[Epoch 32; Iter   493/ 1097] train: loss: 0.0588614
[Epoch 32; Iter   523/ 1097] train: loss: 0.0055920
[Epoch 32; Iter   553/ 1097] train: loss: 0.0023776
[Epoch 32; Iter   583/ 1097] train: loss: 0.0008593
[Epoch 32; Iter   613/ 1097] train: loss: 0.0194973
[Epoch 32; Iter   643/ 1097] train: loss: 0.0109787
[Epoch 32; Iter   673/ 1097] train: loss: 0.0191685
[Epoch 32; Iter   703/ 1097] train: loss: 0.0020761
[Epoch 32; Iter   733/ 1097] train: loss: 0.0042585
[Epoch 32; Iter   763/ 1097] train: loss: 0.0011623
[Epoch 32; Iter   793/ 1097] train: loss: 0.0037168
[Epoch 32; Iter   823/ 1097] train: loss: 0.0039706
[Epoch 32; Iter   853/ 1097] train: loss: 0.0040260
[Epoch 32; Iter   883/ 1097] train: loss: 0.0188351
[Epoch 32; Iter   913/ 1097] train: loss: 0.0015350
[Epoch 32; Iter   943/ 1097] train: loss: 0.0432097
[Epoch 32; Iter   973/ 1097] train: loss: 0.0007219
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0058239
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0351411
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0070803
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0081693
[Epoch 32] ogbg-molhiv: 0.708658 val loss: 48.325489
[Epoch 32] ogbg-molhiv: 0.587311 test loss: 49.007475
[Epoch 33; Iter    26/ 1097] train: loss: 0.0024040
[Epoch 33; Iter    56/ 1097] train: loss: 0.0056525
[Epoch 33; Iter    86/ 1097] train: loss: 0.0073236
[Epoch 33; Iter   116/ 1097] train: loss: 0.0076648
[Epoch 33; Iter   146/ 1097] train: loss: 0.0007711
[Epoch 33; Iter   176/ 1097] train: loss: 0.0175193
[Epoch 33; Iter   206/ 1097] train: loss: 0.0014903
[Epoch 33; Iter   236/ 1097] train: loss: 0.0013374
[Epoch 33; Iter   266/ 1097] train: loss: 0.0016395
[Epoch 33; Iter   296/ 1097] train: loss: 0.0020283
[Epoch 33; Iter   326/ 1097] train: loss: 0.0049993
[Epoch 33; Iter   356/ 1097] train: loss: 0.0018231
[Epoch 33; Iter   386/ 1097] train: loss: 0.0010819
[Epoch 33; Iter   416/ 1097] train: loss: 0.0096473
[Epoch 33; Iter   446/ 1097] train: loss: 0.0196859
[Epoch 33; Iter   476/ 1097] train: loss: 0.0033716
[Epoch 33; Iter   506/ 1097] train: loss: 0.0156025
[Epoch 33; Iter   536/ 1097] train: loss: 0.0385941
[Epoch 33; Iter   566/ 1097] train: loss: 0.0007933
[Epoch 33; Iter   596/ 1097] train: loss: 0.0018640
[Epoch 33; Iter   626/ 1097] train: loss: 0.0042201
[Epoch 33; Iter   656/ 1097] train: loss: 0.0117217
[Epoch 33; Iter   686/ 1097] train: loss: 0.0008850
[Epoch 33; Iter   716/ 1097] train: loss: 0.0977458
[Epoch 33; Iter   746/ 1097] train: loss: 0.0438813
[Epoch 33; Iter   776/ 1097] train: loss: 0.0049442
[Epoch 33; Iter   806/ 1097] train: loss: 0.0131838
[Epoch 33; Iter   836/ 1097] train: loss: 0.0105046
[Epoch 33; Iter   866/ 1097] train: loss: 0.0023282
[Epoch 33; Iter   896/ 1097] train: loss: 0.0121783
[Epoch 33; Iter   926/ 1097] train: loss: 0.0066041
[Epoch 33; Iter   956/ 1097] train: loss: 0.0010972
[Epoch 33; Iter   986/ 1097] train: loss: 0.0048690
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0015516
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0260957
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0012953
[Epoch 33] ogbg-molhiv: 0.683128 val loss: 28.753501
[Epoch 33] ogbg-molhiv: 0.586226 test loss: 30.275717
[Epoch 34; Iter     9/ 1097] train: loss: 0.0021307
[Epoch 34; Iter    39/ 1097] train: loss: 0.0003461
[Epoch 34; Iter    69/ 1097] train: loss: 0.0055513
[Epoch 34; Iter    99/ 1097] train: loss: 0.1003093
[Epoch 34; Iter   129/ 1097] train: loss: 0.0140600
[Epoch 34; Iter   159/ 1097] train: loss: 0.0010043
[Epoch 34; Iter   189/ 1097] train: loss: 0.0010789
[Epoch 34; Iter   219/ 1097] train: loss: 0.0043912
[Epoch 34; Iter   249/ 1097] train: loss: 0.0018532
[Epoch 34; Iter   279/ 1097] train: loss: 0.0780023
[Epoch 34; Iter   309/ 1097] train: loss: 0.0030843
[Epoch 34; Iter   339/ 1097] train: loss: 0.0146636
[Epoch 34; Iter   369/ 1097] train: loss: 0.0213411
[Epoch 34; Iter   399/ 1097] train: loss: 0.0005200
[Epoch 34; Iter   429/ 1097] train: loss: 0.0019664
[Epoch 34; Iter   459/ 1097] train: loss: 0.0513293
[Epoch 34; Iter   489/ 1097] train: loss: 0.0121878
[Epoch 34; Iter   519/ 1097] train: loss: 0.0081680
[Epoch 34; Iter   549/ 1097] train: loss: 0.0047060
[Epoch 34; Iter   579/ 1097] train: loss: 0.0024793
[Epoch 34; Iter   609/ 1097] train: loss: 0.0002547
[Epoch 34; Iter   639/ 1097] train: loss: 0.0050123
[Epoch 34; Iter   669/ 1097] train: loss: 0.0006202
[Epoch 34; Iter   699/ 1097] train: loss: 0.0118890
[Epoch 34; Iter   729/ 1097] train: loss: 0.0042724
[Epoch 34; Iter   759/ 1097] train: loss: 0.0012659
[Epoch 34; Iter   789/ 1097] train: loss: 0.0441430
[Epoch 34; Iter   819/ 1097] train: loss: 0.0027689
[Epoch 34; Iter   849/ 1097] train: loss: 0.0065813
[Epoch 34; Iter   879/ 1097] train: loss: 0.0019435
[Epoch 34; Iter   909/ 1097] train: loss: 0.0619226
[Epoch 34; Iter   939/ 1097] train: loss: 0.0191882
[Epoch 34; Iter   969/ 1097] train: loss: 0.1059206
[Epoch 34; Iter   999/ 1097] train: loss: 0.0196177
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0418047
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0008217
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0045218
[Epoch 34] ogbg-molhiv: 0.697185 val loss: 35.597845
[Epoch 34] ogbg-molhiv: 0.621366 test loss: 36.057105
[Epoch 35; Iter    22/ 1097] train: loss: 0.0006502
[Epoch 35; Iter    52/ 1097] train: loss: 0.0008222
[Epoch 35; Iter    82/ 1097] train: loss: 0.0072289
[Epoch 35; Iter   112/ 1097] train: loss: 0.0023177
[Epoch 35; Iter   142/ 1097] train: loss: 0.0029273
[Epoch 35; Iter   172/ 1097] train: loss: 0.0078332
[Epoch 35; Iter   202/ 1097] train: loss: 0.0502521
[Epoch 35; Iter   232/ 1097] train: loss: 0.0435733
[Epoch 35; Iter   262/ 1097] train: loss: 0.0036071
[Epoch 35; Iter   292/ 1097] train: loss: 0.0010337
[Epoch 35; Iter   322/ 1097] train: loss: 0.0009311
[Epoch 35; Iter   352/ 1097] train: loss: 0.0007117
[Epoch 35; Iter   382/ 1097] train: loss: 0.0144864
[Epoch 35; Iter   412/ 1097] train: loss: 0.0034609
[Epoch 35; Iter   442/ 1097] train: loss: 0.0009141
[Epoch 35; Iter   472/ 1097] train: loss: 0.0067196
[Epoch 35; Iter   502/ 1097] train: loss: 0.0088203
[Epoch 35; Iter   532/ 1097] train: loss: 0.0047598
[Epoch 35; Iter   562/ 1097] train: loss: 0.0018169
[Epoch 35; Iter   592/ 1097] train: loss: 0.0072137
[Epoch 35; Iter   622/ 1097] train: loss: 0.0323903
[Epoch 35; Iter   652/ 1097] train: loss: 0.0011217
[Epoch 35; Iter   682/ 1097] train: loss: 0.0046657
[Epoch 35; Iter   712/ 1097] train: loss: 0.0001008
[Epoch 35; Iter   742/ 1097] train: loss: 0.0292721
[Epoch 35; Iter   772/ 1097] train: loss: 0.0028453
[Epoch 35; Iter   802/ 1097] train: loss: 0.0448810
[Epoch 35; Iter   832/ 1097] train: loss: 0.0008478
[Epoch 35; Iter   862/ 1097] train: loss: 0.0015269
[Epoch 35; Iter   892/ 1097] train: loss: 0.0172291
[Epoch 35; Iter   922/ 1097] train: loss: 0.0583095
[Epoch 35; Iter   952/ 1097] train: loss: 0.0006823
[Epoch 35; Iter   982/ 1097] train: loss: 0.0131953
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0005818
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0126499
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0031262
[Epoch 35] ogbg-molhiv: 0.720103 val loss: 52.864373
[Epoch 35] ogbg-molhiv: 0.610045 test loss: 52.008139
[Epoch 36; Iter     5/ 1097] train: loss: 0.0001661
[Epoch 36; Iter    35/ 1097] train: loss: 0.0011716
[Epoch 36; Iter    65/ 1097] train: loss: 0.0029551
[Epoch 36; Iter    95/ 1097] train: loss: 0.0160857
[Epoch 36; Iter   125/ 1097] train: loss: 0.0031801
[Epoch 36; Iter   155/ 1097] train: loss: 0.0008426
[Epoch 36; Iter   185/ 1097] train: loss: 0.0030783
[Epoch 36; Iter   215/ 1097] train: loss: 0.0292072
[Epoch 36; Iter   245/ 1097] train: loss: 0.0343408
[Epoch 36; Iter   275/ 1097] train: loss: 0.0107475
[Epoch 36; Iter   305/ 1097] train: loss: 0.0235311
[Epoch 36; Iter   335/ 1097] train: loss: 0.0011091
[Epoch 36; Iter   365/ 1097] train: loss: 0.0010424
[Epoch 36; Iter   395/ 1097] train: loss: 0.0093131
[Epoch 36; Iter   425/ 1097] train: loss: 0.0191794
[Epoch 36; Iter   455/ 1097] train: loss: 0.0441858
[Epoch 36; Iter   485/ 1097] train: loss: 0.0023603
[Epoch 36; Iter   515/ 1097] train: loss: 0.0019792
[Epoch 36; Iter   545/ 1097] train: loss: 0.0010919
[Epoch 36; Iter   575/ 1097] train: loss: 0.0001845
[Epoch 28; Iter   441/ 1097] train: loss: 0.0876640
[Epoch 28; Iter   471/ 1097] train: loss: 0.1951815
[Epoch 28; Iter   501/ 1097] train: loss: 0.0428718
[Epoch 28; Iter   531/ 1097] train: loss: 0.0250110
[Epoch 28; Iter   561/ 1097] train: loss: 0.1342479
[Epoch 28; Iter   591/ 1097] train: loss: 0.0669866
[Epoch 28; Iter   621/ 1097] train: loss: 0.0226419
[Epoch 28; Iter   651/ 1097] train: loss: 0.0348579
[Epoch 28; Iter   681/ 1097] train: loss: 0.0737139
[Epoch 28; Iter   711/ 1097] train: loss: 0.0386886
[Epoch 28; Iter   741/ 1097] train: loss: 0.0446690
[Epoch 28; Iter   771/ 1097] train: loss: 0.0882592
[Epoch 28; Iter   801/ 1097] train: loss: 0.0158286
[Epoch 28; Iter   831/ 1097] train: loss: 0.1427151
[Epoch 28; Iter   861/ 1097] train: loss: 0.0173117
[Epoch 28; Iter   891/ 1097] train: loss: 0.0209858
[Epoch 28; Iter   921/ 1097] train: loss: 0.0416991
[Epoch 28; Iter   951/ 1097] train: loss: 0.0148027
[Epoch 28; Iter   981/ 1097] train: loss: 0.0994945
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0186490
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0322250
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0251555
[Epoch 28] ogbg-molhiv: 0.846855 val loss: 0.066375
[Epoch 28] ogbg-molhiv: 0.739190 test loss: 0.120021
[Epoch 29; Iter     4/ 1097] train: loss: 0.0270796
[Epoch 29; Iter    34/ 1097] train: loss: 0.1965236
[Epoch 29; Iter    64/ 1097] train: loss: 0.1030262
[Epoch 29; Iter    94/ 1097] train: loss: 0.0611280
[Epoch 29; Iter   124/ 1097] train: loss: 0.1177359
[Epoch 29; Iter   154/ 1097] train: loss: 0.0235236
[Epoch 29; Iter   184/ 1097] train: loss: 0.0191434
[Epoch 29; Iter   214/ 1097] train: loss: 0.0597557
[Epoch 29; Iter   244/ 1097] train: loss: 0.1784339
[Epoch 29; Iter   274/ 1097] train: loss: 0.0164387
[Epoch 29; Iter   304/ 1097] train: loss: 0.0207565
[Epoch 29; Iter   334/ 1097] train: loss: 0.2519578
[Epoch 29; Iter   364/ 1097] train: loss: 0.0246000
[Epoch 29; Iter   394/ 1097] train: loss: 0.2833491
[Epoch 29; Iter   424/ 1097] train: loss: 0.0369335
[Epoch 29; Iter   454/ 1097] train: loss: 0.0858937
[Epoch 29; Iter   484/ 1097] train: loss: 0.0219715
[Epoch 29; Iter   514/ 1097] train: loss: 0.0360282
[Epoch 29; Iter   544/ 1097] train: loss: 0.0303916
[Epoch 29; Iter   574/ 1097] train: loss: 0.0293411
[Epoch 29; Iter   604/ 1097] train: loss: 0.0536940
[Epoch 29; Iter   634/ 1097] train: loss: 0.1312654
[Epoch 29; Iter   664/ 1097] train: loss: 0.0359138
[Epoch 29; Iter   694/ 1097] train: loss: 0.3453844
[Epoch 29; Iter   724/ 1097] train: loss: 0.0369559
[Epoch 29; Iter   754/ 1097] train: loss: 0.0200854
[Epoch 29; Iter   784/ 1097] train: loss: 0.0307926
[Epoch 29; Iter   814/ 1097] train: loss: 0.0310480
[Epoch 29; Iter   844/ 1097] train: loss: 0.1531276
[Epoch 29; Iter   874/ 1097] train: loss: 0.0244771
[Epoch 29; Iter   904/ 1097] train: loss: 0.0574696
[Epoch 29; Iter   934/ 1097] train: loss: 0.0784035
[Epoch 29; Iter   964/ 1097] train: loss: 0.0282942
[Epoch 29; Iter   994/ 1097] train: loss: 0.2594960
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0239611
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0218924
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1024200
[Epoch 29] ogbg-molhiv: 0.818979 val loss: 0.093791
[Epoch 29] ogbg-molhiv: 0.720329 test loss: 0.133710
[Epoch 30; Iter    17/ 1097] train: loss: 0.0281436
[Epoch 30; Iter    47/ 1097] train: loss: 0.0304530
[Epoch 30; Iter    77/ 1097] train: loss: 0.1695820
[Epoch 30; Iter   107/ 1097] train: loss: 0.0423382
[Epoch 30; Iter   137/ 1097] train: loss: 0.0451296
[Epoch 30; Iter   167/ 1097] train: loss: 0.0167772
[Epoch 30; Iter   197/ 1097] train: loss: 0.0917595
[Epoch 30; Iter   227/ 1097] train: loss: 0.0214488
[Epoch 30; Iter   257/ 1097] train: loss: 0.0158495
[Epoch 30; Iter   287/ 1097] train: loss: 0.0203757
[Epoch 30; Iter   317/ 1097] train: loss: 0.1838409
[Epoch 30; Iter   347/ 1097] train: loss: 0.0377469
[Epoch 30; Iter   377/ 1097] train: loss: 0.0235367
[Epoch 30; Iter   407/ 1097] train: loss: 0.0828976
[Epoch 30; Iter   437/ 1097] train: loss: 0.1733612
[Epoch 30; Iter   467/ 1097] train: loss: 0.0147525
[Epoch 30; Iter   497/ 1097] train: loss: 0.1115046
[Epoch 30; Iter   527/ 1097] train: loss: 0.0505280
[Epoch 30; Iter   557/ 1097] train: loss: 0.0755387
[Epoch 30; Iter   587/ 1097] train: loss: 0.0149357
[Epoch 30; Iter   617/ 1097] train: loss: 0.1806514
[Epoch 30; Iter   647/ 1097] train: loss: 0.0540825
[Epoch 30; Iter   677/ 1097] train: loss: 0.0252918
[Epoch 30; Iter   707/ 1097] train: loss: 0.1027405
[Epoch 30; Iter   737/ 1097] train: loss: 0.0191948
[Epoch 30; Iter   767/ 1097] train: loss: 0.0404319
[Epoch 30; Iter   797/ 1097] train: loss: 0.0527067
[Epoch 30; Iter   827/ 1097] train: loss: 0.1263796
[Epoch 30; Iter   857/ 1097] train: loss: 0.0257808
[Epoch 30; Iter   887/ 1097] train: loss: 0.0451494
[Epoch 30; Iter   917/ 1097] train: loss: 0.1411890
[Epoch 30; Iter   947/ 1097] train: loss: 0.0444672
[Epoch 30; Iter   977/ 1097] train: loss: 0.1425837
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0265037
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0704293
[Epoch 30; Iter  1067/ 1097] train: loss: 0.1505183
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0175828
[Epoch 30] ogbg-molhiv: 0.828205 val loss: 0.078155
[Epoch 30] ogbg-molhiv: 0.745802 test loss: 0.126828
[Epoch 31; Iter    30/ 1097] train: loss: 0.0562927
[Epoch 31; Iter    60/ 1097] train: loss: 0.1446920
[Epoch 31; Iter    90/ 1097] train: loss: 0.0346633
[Epoch 31; Iter   120/ 1097] train: loss: 0.0351026
[Epoch 31; Iter   150/ 1097] train: loss: 0.1257112
[Epoch 31; Iter   180/ 1097] train: loss: 0.0316216
[Epoch 31; Iter   210/ 1097] train: loss: 0.0853569
[Epoch 31; Iter   240/ 1097] train: loss: 0.0163439
[Epoch 31; Iter   270/ 1097] train: loss: 0.0872102
[Epoch 31; Iter   300/ 1097] train: loss: 0.0275867
[Epoch 31; Iter   330/ 1097] train: loss: 0.0824042
[Epoch 31; Iter   360/ 1097] train: loss: 0.0752013
[Epoch 31; Iter   390/ 1097] train: loss: 0.1043075
[Epoch 31; Iter   420/ 1097] train: loss: 0.0191708
[Epoch 31; Iter   450/ 1097] train: loss: 0.0487443
[Epoch 31; Iter   480/ 1097] train: loss: 0.0760821
[Epoch 31; Iter   510/ 1097] train: loss: 0.0151243
[Epoch 31; Iter   540/ 1097] train: loss: 0.0299938
[Epoch 31; Iter   570/ 1097] train: loss: 0.1466716
[Epoch 31; Iter   600/ 1097] train: loss: 0.0131079
[Epoch 31; Iter   630/ 1097] train: loss: 0.0580649
[Epoch 31; Iter   660/ 1097] train: loss: 0.1313187
[Epoch 31; Iter   690/ 1097] train: loss: 0.0399543
[Epoch 31; Iter   720/ 1097] train: loss: 0.0098663
[Epoch 31; Iter   750/ 1097] train: loss: 0.0618516
[Epoch 31; Iter   780/ 1097] train: loss: 0.0608430
[Epoch 31; Iter   810/ 1097] train: loss: 0.0289161
[Epoch 31; Iter   840/ 1097] train: loss: 0.0351939
[Epoch 31; Iter   870/ 1097] train: loss: 0.0707711
[Epoch 31; Iter   900/ 1097] train: loss: 0.0310262
[Epoch 31; Iter   930/ 1097] train: loss: 0.1553972
[Epoch 31; Iter   960/ 1097] train: loss: 0.0300567
[Epoch 31; Iter   990/ 1097] train: loss: 0.0362608
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0442579
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0249842
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2501367
[Epoch 31] ogbg-molhiv: 0.824500 val loss: 0.115633
[Epoch 31] ogbg-molhiv: 0.733848 test loss: 0.127506
[Epoch 32; Iter    13/ 1097] train: loss: 0.0828014
[Epoch 32; Iter    43/ 1097] train: loss: 0.2763551
[Epoch 32; Iter    73/ 1097] train: loss: 0.0943803
[Epoch 32; Iter   103/ 1097] train: loss: 0.0236457
[Epoch 32; Iter   133/ 1097] train: loss: 0.0161299
[Epoch 32; Iter   163/ 1097] train: loss: 0.0407244
[Epoch 32; Iter   193/ 1097] train: loss: 0.0427799
[Epoch 32; Iter   223/ 1097] train: loss: 0.0116697
[Epoch 32; Iter   253/ 1097] train: loss: 0.0467269
[Epoch 32; Iter   283/ 1097] train: loss: 0.0403511
[Epoch 32; Iter   313/ 1097] train: loss: 0.2755249
[Epoch 32; Iter   343/ 1097] train: loss: 0.0501366
[Epoch 32; Iter   373/ 1097] train: loss: 0.1110472
[Epoch 32; Iter   403/ 1097] train: loss: 0.0653386
[Epoch 32; Iter   433/ 1097] train: loss: 0.0193605
[Epoch 32; Iter   463/ 1097] train: loss: 0.2230724
[Epoch 32; Iter   493/ 1097] train: loss: 0.0172877
[Epoch 28; Iter   441/ 1097] train: loss: 0.7203079
[Epoch 28; Iter   471/ 1097] train: loss: 0.0355920
[Epoch 28; Iter   501/ 1097] train: loss: 0.1869803
[Epoch 28; Iter   531/ 1097] train: loss: 0.0244421
[Epoch 28; Iter   561/ 1097] train: loss: 0.1158800
[Epoch 28; Iter   591/ 1097] train: loss: 0.2447335
[Epoch 28; Iter   621/ 1097] train: loss: 0.1300695
[Epoch 28; Iter   651/ 1097] train: loss: 0.0254077
[Epoch 28; Iter   681/ 1097] train: loss: 0.0335568
[Epoch 28; Iter   711/ 1097] train: loss: 0.0530235
[Epoch 28; Iter   741/ 1097] train: loss: 0.0206735
[Epoch 28; Iter   771/ 1097] train: loss: 0.0777640
[Epoch 28; Iter   801/ 1097] train: loss: 0.0159285
[Epoch 28; Iter   831/ 1097] train: loss: 0.0477733
[Epoch 28; Iter   861/ 1097] train: loss: 0.2362985
[Epoch 28; Iter   891/ 1097] train: loss: 0.0789910
[Epoch 28; Iter   921/ 1097] train: loss: 0.0448591
[Epoch 28; Iter   951/ 1097] train: loss: 0.1109227
[Epoch 28; Iter   981/ 1097] train: loss: 0.0250921
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0158026
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0340642
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0263023
[Epoch 28] ogbg-molhiv: 0.836729 val loss: 0.107699
[Epoch 28] ogbg-molhiv: 0.779073 test loss: 0.113976
[Epoch 29; Iter     4/ 1097] train: loss: 0.0178918
[Epoch 29; Iter    34/ 1097] train: loss: 0.0608997
[Epoch 29; Iter    64/ 1097] train: loss: 0.0529034
[Epoch 29; Iter    94/ 1097] train: loss: 0.0553869
[Epoch 29; Iter   124/ 1097] train: loss: 0.1722313
[Epoch 29; Iter   154/ 1097] train: loss: 0.1702348
[Epoch 29; Iter   184/ 1097] train: loss: 0.0220811
[Epoch 29; Iter   214/ 1097] train: loss: 0.0145775
[Epoch 29; Iter   244/ 1097] train: loss: 0.0671558
[Epoch 29; Iter   274/ 1097] train: loss: 0.0199010
[Epoch 29; Iter   304/ 1097] train: loss: 0.1650157
[Epoch 29; Iter   334/ 1097] train: loss: 0.0599725
[Epoch 29; Iter   364/ 1097] train: loss: 0.0436025
[Epoch 29; Iter   394/ 1097] train: loss: 0.1068016
[Epoch 29; Iter   424/ 1097] train: loss: 0.0535335
[Epoch 29; Iter   454/ 1097] train: loss: 0.0711285
[Epoch 29; Iter   484/ 1097] train: loss: 0.0865559
[Epoch 29; Iter   514/ 1097] train: loss: 0.0566075
[Epoch 29; Iter   544/ 1097] train: loss: 0.0306416
[Epoch 29; Iter   574/ 1097] train: loss: 0.0333851
[Epoch 29; Iter   604/ 1097] train: loss: 0.1647497
[Epoch 29; Iter   634/ 1097] train: loss: 0.2665044
[Epoch 29; Iter   664/ 1097] train: loss: 0.0173186
[Epoch 29; Iter   694/ 1097] train: loss: 0.0507527
[Epoch 29; Iter   724/ 1097] train: loss: 0.0325778
[Epoch 29; Iter   754/ 1097] train: loss: 0.0647938
[Epoch 29; Iter   784/ 1097] train: loss: 0.0661759
[Epoch 29; Iter   814/ 1097] train: loss: 0.0255422
[Epoch 29; Iter   844/ 1097] train: loss: 0.0670280
[Epoch 29; Iter   874/ 1097] train: loss: 0.3227068
[Epoch 29; Iter   904/ 1097] train: loss: 0.0128257
[Epoch 29; Iter   934/ 1097] train: loss: 0.3163404
[Epoch 29; Iter   964/ 1097] train: loss: 0.0381013
[Epoch 29; Iter   994/ 1097] train: loss: 0.1260441
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0227239
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0407230
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0155404
[Epoch 29] ogbg-molhiv: 0.816578 val loss: 0.072751
[Epoch 29] ogbg-molhiv: 0.755443 test loss: 0.117237
[Epoch 30; Iter    17/ 1097] train: loss: 0.0351327
[Epoch 30; Iter    47/ 1097] train: loss: 0.1625094
[Epoch 30; Iter    77/ 1097] train: loss: 0.1328753
[Epoch 30; Iter   107/ 1097] train: loss: 0.0787084
[Epoch 30; Iter   137/ 1097] train: loss: 0.2206901
[Epoch 30; Iter   167/ 1097] train: loss: 0.0293256
[Epoch 30; Iter   197/ 1097] train: loss: 0.0332193
[Epoch 30; Iter   227/ 1097] train: loss: 0.0648400
[Epoch 30; Iter   257/ 1097] train: loss: 0.0919620
[Epoch 30; Iter   287/ 1097] train: loss: 0.0333089
[Epoch 30; Iter   317/ 1097] train: loss: 0.1147797
[Epoch 30; Iter   347/ 1097] train: loss: 0.1739240
[Epoch 30; Iter   377/ 1097] train: loss: 0.1203668
[Epoch 30; Iter   407/ 1097] train: loss: 0.0946868
[Epoch 30; Iter   437/ 1097] train: loss: 0.0731658
[Epoch 30; Iter   467/ 1097] train: loss: 0.0182873
[Epoch 30; Iter   497/ 1097] train: loss: 0.0946228
[Epoch 30; Iter   527/ 1097] train: loss: 0.1623688
[Epoch 30; Iter   557/ 1097] train: loss: 0.1587319
[Epoch 30; Iter   587/ 1097] train: loss: 0.0305025
[Epoch 30; Iter   617/ 1097] train: loss: 0.0282738
[Epoch 30; Iter   647/ 1097] train: loss: 0.0172095
[Epoch 30; Iter   677/ 1097] train: loss: 0.2229514
[Epoch 30; Iter   707/ 1097] train: loss: 0.1651538
[Epoch 30; Iter   737/ 1097] train: loss: 0.0657386
[Epoch 30; Iter   767/ 1097] train: loss: 0.2230405
[Epoch 30; Iter   797/ 1097] train: loss: 0.2327857
[Epoch 30; Iter   827/ 1097] train: loss: 0.3866867
[Epoch 30; Iter   857/ 1097] train: loss: 0.1627179
[Epoch 30; Iter   887/ 1097] train: loss: 0.0371274
[Epoch 30; Iter   917/ 1097] train: loss: 0.1255530
[Epoch 30; Iter   947/ 1097] train: loss: 0.0477637
[Epoch 30; Iter   977/ 1097] train: loss: 0.0245399
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0905554
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0686682
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0292418
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0315702
[Epoch 30] ogbg-molhiv: 0.830694 val loss: 0.111097
[Epoch 30] ogbg-molhiv: 0.761618 test loss: 0.132261
[Epoch 31; Iter    30/ 1097] train: loss: 0.1082062
[Epoch 31; Iter    60/ 1097] train: loss: 0.1620500
[Epoch 31; Iter    90/ 1097] train: loss: 0.0314668
[Epoch 31; Iter   120/ 1097] train: loss: 0.0519476
[Epoch 31; Iter   150/ 1097] train: loss: 0.2663450
[Epoch 31; Iter   180/ 1097] train: loss: 0.0312511
[Epoch 31; Iter   210/ 1097] train: loss: 0.0134788
[Epoch 31; Iter   240/ 1097] train: loss: 0.0606187
[Epoch 31; Iter   270/ 1097] train: loss: 0.1346370
[Epoch 31; Iter   300/ 1097] train: loss: 0.0982065
[Epoch 31; Iter   330/ 1097] train: loss: 0.1283832
[Epoch 31; Iter   360/ 1097] train: loss: 0.0946155
[Epoch 31; Iter   390/ 1097] train: loss: 0.0680305
[Epoch 31; Iter   420/ 1097] train: loss: 0.1760823
[Epoch 31; Iter   450/ 1097] train: loss: 0.0298165
[Epoch 31; Iter   480/ 1097] train: loss: 0.1839202
[Epoch 31; Iter   510/ 1097] train: loss: 0.0250398
[Epoch 31; Iter   540/ 1097] train: loss: 0.1066803
[Epoch 31; Iter   570/ 1097] train: loss: 0.2757200
[Epoch 31; Iter   600/ 1097] train: loss: 0.0162744
[Epoch 31; Iter   630/ 1097] train: loss: 0.0358594
[Epoch 31; Iter   660/ 1097] train: loss: 0.1427034
[Epoch 31; Iter   690/ 1097] train: loss: 0.0688428
[Epoch 31; Iter   720/ 1097] train: loss: 0.0291387
[Epoch 31; Iter   750/ 1097] train: loss: 0.0132379
[Epoch 31; Iter   780/ 1097] train: loss: 0.0987265
[Epoch 31; Iter   810/ 1097] train: loss: 0.0243962
[Epoch 31; Iter   840/ 1097] train: loss: 0.1045741
[Epoch 31; Iter   870/ 1097] train: loss: 0.2162146
[Epoch 31; Iter   900/ 1097] train: loss: 0.0457273
[Epoch 31; Iter   930/ 1097] train: loss: 0.0491702
[Epoch 31; Iter   960/ 1097] train: loss: 0.0269643
[Epoch 31; Iter   990/ 1097] train: loss: 0.1862295
[Epoch 31; Iter  1020/ 1097] train: loss: 0.2589020
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1756574
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0698873
[Epoch 31] ogbg-molhiv: 0.836640 val loss: 0.072454
[Epoch 31] ogbg-molhiv: 0.754482 test loss: 0.125070
[Epoch 32; Iter    13/ 1097] train: loss: 0.0153634
[Epoch 32; Iter    43/ 1097] train: loss: 0.1897422
[Epoch 32; Iter    73/ 1097] train: loss: 0.0140250
[Epoch 32; Iter   103/ 1097] train: loss: 0.0268869
[Epoch 32; Iter   133/ 1097] train: loss: 0.0847915
[Epoch 32; Iter   163/ 1097] train: loss: 0.1253799
[Epoch 32; Iter   193/ 1097] train: loss: 0.0852589
[Epoch 32; Iter   223/ 1097] train: loss: 0.0497854
[Epoch 32; Iter   253/ 1097] train: loss: 0.0760390
[Epoch 32; Iter   283/ 1097] train: loss: 0.0240831
[Epoch 32; Iter   313/ 1097] train: loss: 0.0373265
[Epoch 32; Iter   343/ 1097] train: loss: 0.1255607
[Epoch 32; Iter   373/ 1097] train: loss: 0.2391543
[Epoch 32; Iter   403/ 1097] train: loss: 0.0198768
[Epoch 32; Iter   433/ 1097] train: loss: 0.0159293
[Epoch 32; Iter   463/ 1097] train: loss: 0.1564917
[Epoch 32; Iter   493/ 1097] train: loss: 0.0748489
[Epoch 36; Iter   605/ 1097] train: loss: 0.0156085
[Epoch 36; Iter   635/ 1097] train: loss: 0.0076182
[Epoch 36; Iter   665/ 1097] train: loss: 0.0204300
[Epoch 36; Iter   695/ 1097] train: loss: 0.1336505
[Epoch 36; Iter   725/ 1097] train: loss: 0.0087132
[Epoch 36; Iter   755/ 1097] train: loss: 0.0027974
[Epoch 36; Iter   785/ 1097] train: loss: 0.0050053
[Epoch 36; Iter   815/ 1097] train: loss: 0.0213829
[Epoch 36; Iter   845/ 1097] train: loss: 0.0015004
[Epoch 36; Iter   875/ 1097] train: loss: 0.0270424
[Epoch 36; Iter   905/ 1097] train: loss: 0.1012846
[Epoch 36; Iter   935/ 1097] train: loss: 0.0046883
[Epoch 36; Iter   965/ 1097] train: loss: 0.0088006
[Epoch 36; Iter   995/ 1097] train: loss: 0.0082191
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0058679
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0264341
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1015632
[Epoch 36] ogbg-molhiv: 0.771694 val loss: 0.207125
[Epoch 36] ogbg-molhiv: 0.751532 test loss: 0.215240
[Epoch 37; Iter    18/ 1097] train: loss: 0.0136349
[Epoch 37; Iter    48/ 1097] train: loss: 0.0260346
[Epoch 37; Iter    78/ 1097] train: loss: 0.0018152
[Epoch 37; Iter   108/ 1097] train: loss: 0.0096097
[Epoch 37; Iter   138/ 1097] train: loss: 0.0222370
[Epoch 37; Iter   168/ 1097] train: loss: 0.0029909
[Epoch 37; Iter   198/ 1097] train: loss: 0.0057163
[Epoch 37; Iter   228/ 1097] train: loss: 0.0136990
[Epoch 37; Iter   258/ 1097] train: loss: 0.0043293
[Epoch 37; Iter   288/ 1097] train: loss: 0.0276028
[Epoch 37; Iter   318/ 1097] train: loss: 0.0062798
[Epoch 37; Iter   348/ 1097] train: loss: 0.0022955
[Epoch 37; Iter   378/ 1097] train: loss: 0.1139327
[Epoch 37; Iter   408/ 1097] train: loss: 0.1251510
[Epoch 37; Iter   438/ 1097] train: loss: 0.0275922
[Epoch 37; Iter   468/ 1097] train: loss: 0.0055356
[Epoch 37; Iter   498/ 1097] train: loss: 0.0183538
[Epoch 37; Iter   528/ 1097] train: loss: 0.0089940
[Epoch 37; Iter   558/ 1097] train: loss: 0.0075088
[Epoch 37; Iter   588/ 1097] train: loss: 0.0020180
[Epoch 37; Iter   618/ 1097] train: loss: 0.0046845
[Epoch 37; Iter   648/ 1097] train: loss: 0.0063415
[Epoch 37; Iter   678/ 1097] train: loss: 0.1355891
[Epoch 37; Iter   708/ 1097] train: loss: 0.0293108
[Epoch 37; Iter   738/ 1097] train: loss: 0.0358570
[Epoch 37; Iter   768/ 1097] train: loss: 0.0042760
[Epoch 37; Iter   798/ 1097] train: loss: 0.1787942
[Epoch 37; Iter   828/ 1097] train: loss: 0.0011417
[Epoch 37; Iter   858/ 1097] train: loss: 0.0123328
[Epoch 37; Iter   888/ 1097] train: loss: 0.0008209
[Epoch 37; Iter   918/ 1097] train: loss: 0.0628407
[Epoch 37; Iter   948/ 1097] train: loss: 0.0376104
[Epoch 37; Iter   978/ 1097] train: loss: 0.0084150
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0086857
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0073950
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0361209
[Epoch 37] ogbg-molhiv: 0.764314 val loss: 0.245126
[Epoch 37] ogbg-molhiv: 0.727445 test loss: 0.281114
[Epoch 38; Iter     1/ 1097] train: loss: 0.0035564
[Epoch 38; Iter    31/ 1097] train: loss: 0.0226895
[Epoch 38; Iter    61/ 1097] train: loss: 0.0650151
[Epoch 38; Iter    91/ 1097] train: loss: 0.0024493
[Epoch 38; Iter   121/ 1097] train: loss: 0.0031902
[Epoch 38; Iter   151/ 1097] train: loss: 0.0016027
[Epoch 38; Iter   181/ 1097] train: loss: 0.0613975
[Epoch 38; Iter   211/ 1097] train: loss: 0.0014828
[Epoch 38; Iter   241/ 1097] train: loss: 0.0141527
[Epoch 38; Iter   271/ 1097] train: loss: 0.0082303
[Epoch 38; Iter   301/ 1097] train: loss: 0.0026454
[Epoch 38; Iter   331/ 1097] train: loss: 0.0188278
[Epoch 38; Iter   361/ 1097] train: loss: 0.0040010
[Epoch 38; Iter   391/ 1097] train: loss: 0.0072137
[Epoch 38; Iter   421/ 1097] train: loss: 0.0081903
[Epoch 38; Iter   451/ 1097] train: loss: 0.0018705
[Epoch 38; Iter   481/ 1097] train: loss: 0.0941062
[Epoch 38; Iter   511/ 1097] train: loss: 0.0038484
[Epoch 38; Iter   541/ 1097] train: loss: 0.0942105
[Epoch 38; Iter   571/ 1097] train: loss: 0.0062121
[Epoch 38; Iter   601/ 1097] train: loss: 0.1657656
[Epoch 38; Iter   631/ 1097] train: loss: 0.1558613
[Epoch 38; Iter   661/ 1097] train: loss: 0.0042307
[Epoch 38; Iter   691/ 1097] train: loss: 0.0147402
[Epoch 38; Iter   721/ 1097] train: loss: 0.0633195
[Epoch 38; Iter   751/ 1097] train: loss: 0.0029942
[Epoch 38; Iter   781/ 1097] train: loss: 0.0073963
[Epoch 38; Iter   811/ 1097] train: loss: 0.0714392
[Epoch 38; Iter   841/ 1097] train: loss: 0.0251677
[Epoch 38; Iter   871/ 1097] train: loss: 0.0505005
[Epoch 38; Iter   901/ 1097] train: loss: 0.0119498
[Epoch 38; Iter   931/ 1097] train: loss: 0.0025350
[Epoch 38; Iter   961/ 1097] train: loss: 0.0067198
[Epoch 38; Iter   991/ 1097] train: loss: 0.1645689
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0412174
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0117488
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0437109
[Epoch 38] ogbg-molhiv: 0.734911 val loss: 0.579819
[Epoch 38] ogbg-molhiv: 0.738324 test loss: 0.253267
[Epoch 39; Iter    14/ 1097] train: loss: 0.1003070
[Epoch 39; Iter    44/ 1097] train: loss: 0.1365118
[Epoch 39; Iter    74/ 1097] train: loss: 0.0714090
[Epoch 39; Iter   104/ 1097] train: loss: 0.0121225
[Epoch 39; Iter   134/ 1097] train: loss: 0.0053725
[Epoch 39; Iter   164/ 1097] train: loss: 0.0414423
[Epoch 39; Iter   194/ 1097] train: loss: 0.0047215
[Epoch 39; Iter   224/ 1097] train: loss: 0.0081275
[Epoch 39; Iter   254/ 1097] train: loss: 0.0014064
[Epoch 39; Iter   284/ 1097] train: loss: 0.0094760
[Epoch 39; Iter   314/ 1097] train: loss: 0.0275277
[Epoch 39; Iter   344/ 1097] train: loss: 0.0034922
[Epoch 39; Iter   374/ 1097] train: loss: 0.0009915
[Epoch 39; Iter   404/ 1097] train: loss: 0.0125481
[Epoch 39; Iter   434/ 1097] train: loss: 0.0019662
[Epoch 39; Iter   464/ 1097] train: loss: 0.0127708
[Epoch 39; Iter   494/ 1097] train: loss: 0.0081371
[Epoch 39; Iter   524/ 1097] train: loss: 0.0145636
[Epoch 39; Iter   554/ 1097] train: loss: 0.0128977
[Epoch 39; Iter   584/ 1097] train: loss: 0.0181368
[Epoch 39; Iter   614/ 1097] train: loss: 0.0026421
[Epoch 39; Iter   644/ 1097] train: loss: 0.0184957
[Epoch 39; Iter   674/ 1097] train: loss: 0.0105347
[Epoch 39; Iter   704/ 1097] train: loss: 0.0112212
[Epoch 39; Iter   734/ 1097] train: loss: 0.0045722
[Epoch 39; Iter   764/ 1097] train: loss: 0.0760921
[Epoch 39; Iter   794/ 1097] train: loss: 0.0064866
[Epoch 39; Iter   824/ 1097] train: loss: 0.0204711
[Epoch 39; Iter   854/ 1097] train: loss: 0.0098661
[Epoch 39; Iter   884/ 1097] train: loss: 0.0017110
[Epoch 39; Iter   914/ 1097] train: loss: 0.0013932
[Epoch 39; Iter   944/ 1097] train: loss: 0.0221686
[Epoch 39; Iter   974/ 1097] train: loss: 0.0414300
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0292731
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0014827
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0061297
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1248875
[Epoch 39] ogbg-molhiv: 0.778978 val loss: 0.228508
[Epoch 39] ogbg-molhiv: 0.736306 test loss: 0.267286
[Epoch 40; Iter    27/ 1097] train: loss: 0.0031502
[Epoch 40; Iter    57/ 1097] train: loss: 0.0024791
[Epoch 40; Iter    87/ 1097] train: loss: 0.0035822
[Epoch 40; Iter   117/ 1097] train: loss: 0.0065555
[Epoch 40; Iter   147/ 1097] train: loss: 0.0054825
[Epoch 40; Iter   177/ 1097] train: loss: 0.0014226
[Epoch 40; Iter   207/ 1097] train: loss: 0.0062529
[Epoch 40; Iter   237/ 1097] train: loss: 0.0013094
[Epoch 40; Iter   267/ 1097] train: loss: 0.1247299
[Epoch 40; Iter   297/ 1097] train: loss: 0.0038810
[Epoch 40; Iter   327/ 1097] train: loss: 0.0160503
[Epoch 40; Iter   357/ 1097] train: loss: 0.0136654
[Epoch 40; Iter   387/ 1097] train: loss: 0.1062087
[Epoch 40; Iter   417/ 1097] train: loss: 0.0132519
[Epoch 40; Iter   447/ 1097] train: loss: 0.0779454
[Epoch 40; Iter   477/ 1097] train: loss: 0.0090923
[Epoch 40; Iter   507/ 1097] train: loss: 0.0230952
[Epoch 40; Iter   537/ 1097] train: loss: 0.0205312
[Epoch 40; Iter   567/ 1097] train: loss: 0.0033574
[Epoch 40; Iter   597/ 1097] train: loss: 0.0548119
[Epoch 40; Iter   627/ 1097] train: loss: 0.0012028
[Epoch 40; Iter   657/ 1097] train: loss: 0.0055080
[Epoch 36; Iter   605/ 1097] train: loss: 0.0042019
[Epoch 36; Iter   635/ 1097] train: loss: 0.0059845
[Epoch 36; Iter   665/ 1097] train: loss: 0.0177867
[Epoch 36; Iter   695/ 1097] train: loss: 0.0168639
[Epoch 36; Iter   725/ 1097] train: loss: 0.0077088
[Epoch 36; Iter   755/ 1097] train: loss: 0.2277428
[Epoch 36; Iter   785/ 1097] train: loss: 0.0059918
[Epoch 36; Iter   815/ 1097] train: loss: 0.0307200
[Epoch 36; Iter   845/ 1097] train: loss: 0.0162886
[Epoch 36; Iter   875/ 1097] train: loss: 0.0040575
[Epoch 36; Iter   905/ 1097] train: loss: 0.0345424
[Epoch 36; Iter   935/ 1097] train: loss: 0.0910263
[Epoch 36; Iter   965/ 1097] train: loss: 0.0192883
[Epoch 36; Iter   995/ 1097] train: loss: 0.0707529
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0510163
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0350682
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0087214
[Epoch 36] ogbg-molhiv: 0.762979 val loss: 0.695628
[Epoch 36] ogbg-molhiv: 0.743338 test loss: 0.592184
[Epoch 37; Iter    18/ 1097] train: loss: 0.0179198
[Epoch 37; Iter    48/ 1097] train: loss: 0.0024030
[Epoch 37; Iter    78/ 1097] train: loss: 0.0079306
[Epoch 37; Iter   108/ 1097] train: loss: 0.0818008
[Epoch 37; Iter   138/ 1097] train: loss: 0.0055005
[Epoch 37; Iter   168/ 1097] train: loss: 0.0713567
[Epoch 37; Iter   198/ 1097] train: loss: 0.0210079
[Epoch 37; Iter   228/ 1097] train: loss: 0.0011717
[Epoch 37; Iter   258/ 1097] train: loss: 0.0039965
[Epoch 37; Iter   288/ 1097] train: loss: 0.0387947
[Epoch 37; Iter   318/ 1097] train: loss: 0.0170108
[Epoch 37; Iter   348/ 1097] train: loss: 0.0324839
[Epoch 37; Iter   378/ 1097] train: loss: 0.0451220
[Epoch 37; Iter   408/ 1097] train: loss: 0.0172850
[Epoch 37; Iter   438/ 1097] train: loss: 0.0382106
[Epoch 37; Iter   468/ 1097] train: loss: 0.0118870
[Epoch 37; Iter   498/ 1097] train: loss: 0.0104084
[Epoch 37; Iter   528/ 1097] train: loss: 0.0095821
[Epoch 37; Iter   558/ 1097] train: loss: 0.0010915
[Epoch 37; Iter   588/ 1097] train: loss: 0.0061132
[Epoch 37; Iter   618/ 1097] train: loss: 0.0120238
[Epoch 37; Iter   648/ 1097] train: loss: 0.0025119
[Epoch 37; Iter   678/ 1097] train: loss: 0.0055465
[Epoch 37; Iter   708/ 1097] train: loss: 0.0038927
[Epoch 37; Iter   738/ 1097] train: loss: 0.0720993
[Epoch 37; Iter   768/ 1097] train: loss: 0.0882076
[Epoch 37; Iter   798/ 1097] train: loss: 0.0389776
[Epoch 37; Iter   828/ 1097] train: loss: 0.0061292
[Epoch 37; Iter   858/ 1097] train: loss: 0.0080351
[Epoch 37; Iter   888/ 1097] train: loss: 0.0190430
[Epoch 37; Iter   918/ 1097] train: loss: 0.0222073
[Epoch 37; Iter   948/ 1097] train: loss: 0.0022128
[Epoch 37; Iter   978/ 1097] train: loss: 0.0762529
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0020426
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0057771
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0058868
[Epoch 37] ogbg-molhiv: 0.752523 val loss: 0.155328
[Epoch 37] ogbg-molhiv: 0.727291 test loss: 0.214316
[Epoch 38; Iter     1/ 1097] train: loss: 0.0020070
[Epoch 38; Iter    31/ 1097] train: loss: 0.0121191
[Epoch 38; Iter    61/ 1097] train: loss: 0.0277711
[Epoch 38; Iter    91/ 1097] train: loss: 0.0088847
[Epoch 38; Iter   121/ 1097] train: loss: 0.1475774
[Epoch 38; Iter   151/ 1097] train: loss: 0.0023658
[Epoch 38; Iter   181/ 1097] train: loss: 0.0033234
[Epoch 38; Iter   211/ 1097] train: loss: 0.0031439
[Epoch 38; Iter   241/ 1097] train: loss: 0.0149154
[Epoch 38; Iter   271/ 1097] train: loss: 0.0125246
[Epoch 38; Iter   301/ 1097] train: loss: 0.0029845
[Epoch 38; Iter   331/ 1097] train: loss: 0.1442993
[Epoch 38; Iter   361/ 1097] train: loss: 0.3627807
[Epoch 38; Iter   391/ 1097] train: loss: 0.0031157
[Epoch 38; Iter   421/ 1097] train: loss: 0.0277675
[Epoch 38; Iter   451/ 1097] train: loss: 0.0259002
[Epoch 38; Iter   481/ 1097] train: loss: 0.0104564
[Epoch 38; Iter   511/ 1097] train: loss: 0.0150806
[Epoch 38; Iter   541/ 1097] train: loss: 0.0608503
[Epoch 38; Iter   571/ 1097] train: loss: 0.0074510
[Epoch 38; Iter   601/ 1097] train: loss: 0.0054758
[Epoch 38; Iter   631/ 1097] train: loss: 0.0250957
[Epoch 38; Iter   661/ 1097] train: loss: 0.0191469
[Epoch 38; Iter   691/ 1097] train: loss: 0.0021597
[Epoch 38; Iter   721/ 1097] train: loss: 0.0265471
[Epoch 38; Iter   751/ 1097] train: loss: 0.0062753
[Epoch 38; Iter   781/ 1097] train: loss: 0.0145400
[Epoch 38; Iter   811/ 1097] train: loss: 0.0018842
[Epoch 38; Iter   841/ 1097] train: loss: 0.0446307
[Epoch 38; Iter   871/ 1097] train: loss: 0.1649830
[Epoch 38; Iter   901/ 1097] train: loss: 0.0034510
[Epoch 38; Iter   931/ 1097] train: loss: 0.0021845
[Epoch 38; Iter   961/ 1097] train: loss: 0.0192186
[Epoch 38; Iter   991/ 1097] train: loss: 0.0152872
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0150768
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0365968
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0158449
[Epoch 38] ogbg-molhiv: 0.763975 val loss: 0.197709
[Epoch 38] ogbg-molhiv: 0.733969 test loss: 0.218271
[Epoch 39; Iter    14/ 1097] train: loss: 0.0165464
[Epoch 39; Iter    44/ 1097] train: loss: 0.0089328
[Epoch 39; Iter    74/ 1097] train: loss: 0.0087981
[Epoch 39; Iter   104/ 1097] train: loss: 0.0027222
[Epoch 39; Iter   134/ 1097] train: loss: 0.0038306
[Epoch 39; Iter   164/ 1097] train: loss: 0.0234487
[Epoch 39; Iter   194/ 1097] train: loss: 0.0006360
[Epoch 39; Iter   224/ 1097] train: loss: 0.0082335
[Epoch 39; Iter   254/ 1097] train: loss: 0.0104753
[Epoch 39; Iter   284/ 1097] train: loss: 0.0116604
[Epoch 39; Iter   314/ 1097] train: loss: 0.0095612
[Epoch 39; Iter   344/ 1097] train: loss: 0.0012478
[Epoch 39; Iter   374/ 1097] train: loss: 0.0265771
[Epoch 39; Iter   404/ 1097] train: loss: 0.0365290
[Epoch 39; Iter   434/ 1097] train: loss: 0.0106397
[Epoch 39; Iter   464/ 1097] train: loss: 0.0049826
[Epoch 39; Iter   494/ 1097] train: loss: 0.0088544
[Epoch 39; Iter   524/ 1097] train: loss: 0.0032841
[Epoch 39; Iter   554/ 1097] train: loss: 0.0032545
[Epoch 39; Iter   584/ 1097] train: loss: 0.0145089
[Epoch 39; Iter   614/ 1097] train: loss: 0.0846779
[Epoch 39; Iter   644/ 1097] train: loss: 0.0208095
[Epoch 39; Iter   674/ 1097] train: loss: 0.0092656
[Epoch 39; Iter   704/ 1097] train: loss: 0.0038914
[Epoch 39; Iter   734/ 1097] train: loss: 0.0037195
[Epoch 39; Iter   764/ 1097] train: loss: 0.0068308
[Epoch 39; Iter   794/ 1097] train: loss: 0.1150063
[Epoch 39; Iter   824/ 1097] train: loss: 0.0041314
[Epoch 39; Iter   854/ 1097] train: loss: 0.0050307
[Epoch 39; Iter   884/ 1097] train: loss: 0.0094624
[Epoch 39; Iter   914/ 1097] train: loss: 0.0618483
[Epoch 39; Iter   944/ 1097] train: loss: 0.0221133
[Epoch 39; Iter   974/ 1097] train: loss: 0.0014907
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0117237
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0072572
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0049815
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0010027
[Epoch 39] ogbg-molhiv: 0.779532 val loss: 0.129007
[Epoch 39] ogbg-molhiv: 0.750159 test loss: 0.212870
[Epoch 40; Iter    27/ 1097] train: loss: 0.0067856
[Epoch 40; Iter    57/ 1097] train: loss: 0.0091969
[Epoch 40; Iter    87/ 1097] train: loss: 0.0128573
[Epoch 40; Iter   117/ 1097] train: loss: 0.0024925
[Epoch 40; Iter   147/ 1097] train: loss: 0.0011939
[Epoch 40; Iter   177/ 1097] train: loss: 0.0055217
[Epoch 40; Iter   207/ 1097] train: loss: 0.1110092
[Epoch 40; Iter   237/ 1097] train: loss: 0.0013216
[Epoch 40; Iter   267/ 1097] train: loss: 0.0090428
[Epoch 40; Iter   297/ 1097] train: loss: 0.0115675
[Epoch 40; Iter   327/ 1097] train: loss: 0.0069463
[Epoch 40; Iter   357/ 1097] train: loss: 0.0089390
[Epoch 40; Iter   387/ 1097] train: loss: 0.0039643
[Epoch 40; Iter   417/ 1097] train: loss: 0.0083751
[Epoch 40; Iter   447/ 1097] train: loss: 0.0090231
[Epoch 40; Iter   477/ 1097] train: loss: 0.0402120
[Epoch 40; Iter   507/ 1097] train: loss: 0.0074378
[Epoch 40; Iter   537/ 1097] train: loss: 0.0011370
[Epoch 40; Iter   567/ 1097] train: loss: 0.0260534
[Epoch 40; Iter   597/ 1097] train: loss: 0.0076911
[Epoch 40; Iter   627/ 1097] train: loss: 0.0012113
[Epoch 40; Iter   657/ 1097] train: loss: 0.0087291
[Epoch 36; Iter   605/ 1097] train: loss: 0.0469692
[Epoch 36; Iter   635/ 1097] train: loss: 0.0271400
[Epoch 36; Iter   665/ 1097] train: loss: 0.0171255
[Epoch 36; Iter   695/ 1097] train: loss: 0.0137894
[Epoch 36; Iter   725/ 1097] train: loss: 0.1372671
[Epoch 36; Iter   755/ 1097] train: loss: 0.0038245
[Epoch 36; Iter   785/ 1097] train: loss: 0.0699516
[Epoch 36; Iter   815/ 1097] train: loss: 0.0449010
[Epoch 36; Iter   845/ 1097] train: loss: 0.0234094
[Epoch 36; Iter   875/ 1097] train: loss: 0.0088110
[Epoch 36; Iter   905/ 1097] train: loss: 0.0199767
[Epoch 36; Iter   935/ 1097] train: loss: 0.0035430
[Epoch 36; Iter   965/ 1097] train: loss: 0.0718951
[Epoch 36; Iter   995/ 1097] train: loss: 0.0106325
[Epoch 36; Iter  1025/ 1097] train: loss: 0.3526672
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0399161
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0068325
[Epoch 36] ogbg-molhiv: 0.695596 val loss: 1.028663
[Epoch 36] ogbg-molhiv: 0.706454 test loss: 0.210286
[Epoch 37; Iter    18/ 1097] train: loss: 0.0488503
[Epoch 37; Iter    48/ 1097] train: loss: 0.0060804
[Epoch 37; Iter    78/ 1097] train: loss: 0.0055917
[Epoch 37; Iter   108/ 1097] train: loss: 0.0125983
[Epoch 37; Iter   138/ 1097] train: loss: 0.0080192
[Epoch 37; Iter   168/ 1097] train: loss: 0.0147621
[Epoch 37; Iter   198/ 1097] train: loss: 0.0289655
[Epoch 37; Iter   228/ 1097] train: loss: 0.0095017
[Epoch 37; Iter   258/ 1097] train: loss: 0.1845492
[Epoch 37; Iter   288/ 1097] train: loss: 0.0125377
[Epoch 37; Iter   318/ 1097] train: loss: 0.1418491
[Epoch 37; Iter   348/ 1097] train: loss: 0.0421321
[Epoch 37; Iter   378/ 1097] train: loss: 0.0047561
[Epoch 37; Iter   408/ 1097] train: loss: 0.0081155
[Epoch 37; Iter   438/ 1097] train: loss: 0.0256329
[Epoch 37; Iter   468/ 1097] train: loss: 0.0063895
[Epoch 37; Iter   498/ 1097] train: loss: 0.0035604
[Epoch 37; Iter   528/ 1097] train: loss: 0.1290939
[Epoch 37; Iter   558/ 1097] train: loss: 0.2234699
[Epoch 37; Iter   588/ 1097] train: loss: 0.0080520
[Epoch 37; Iter   618/ 1097] train: loss: 0.0524575
[Epoch 37; Iter   648/ 1097] train: loss: 0.0073248
[Epoch 37; Iter   678/ 1097] train: loss: 0.0056679
[Epoch 37; Iter   708/ 1097] train: loss: 0.0796426
[Epoch 37; Iter   738/ 1097] train: loss: 0.0419050
[Epoch 37; Iter   768/ 1097] train: loss: 0.0041137
[Epoch 37; Iter   798/ 1097] train: loss: 0.0675390
[Epoch 37; Iter   828/ 1097] train: loss: 0.0218196
[Epoch 37; Iter   858/ 1097] train: loss: 0.0069657
[Epoch 37; Iter   888/ 1097] train: loss: 0.0710182
[Epoch 37; Iter   918/ 1097] train: loss: 0.2263407
[Epoch 37; Iter   948/ 1097] train: loss: 0.0132033
[Epoch 37; Iter   978/ 1097] train: loss: 0.0295494
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0545604
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0112438
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0043194
[Epoch 37] ogbg-molhiv: 0.697433 val loss: 1.530291
[Epoch 37] ogbg-molhiv: 0.742766 test loss: 0.925602
[Epoch 38; Iter     1/ 1097] train: loss: 0.0122190
[Epoch 38; Iter    31/ 1097] train: loss: 0.0057146
[Epoch 38; Iter    61/ 1097] train: loss: 0.0719822
[Epoch 38; Iter    91/ 1097] train: loss: 0.0060937
[Epoch 38; Iter   121/ 1097] train: loss: 0.0023307
[Epoch 38; Iter   151/ 1097] train: loss: 0.0062513
[Epoch 38; Iter   181/ 1097] train: loss: 0.0173112
[Epoch 38; Iter   211/ 1097] train: loss: 0.0096386
[Epoch 38; Iter   241/ 1097] train: loss: 0.0101507
[Epoch 38; Iter   271/ 1097] train: loss: 0.0133636
[Epoch 38; Iter   301/ 1097] train: loss: 0.0103245
[Epoch 38; Iter   331/ 1097] train: loss: 0.0055740
[Epoch 38; Iter   361/ 1097] train: loss: 0.0606792
[Epoch 38; Iter   391/ 1097] train: loss: 0.0811662
[Epoch 38; Iter   421/ 1097] train: loss: 0.0599277
[Epoch 38; Iter   451/ 1097] train: loss: 0.0869569
[Epoch 38; Iter   481/ 1097] train: loss: 0.1069911
[Epoch 38; Iter   511/ 1097] train: loss: 0.1751706
[Epoch 38; Iter   541/ 1097] train: loss: 0.0074981
[Epoch 38; Iter   571/ 1097] train: loss: 0.0237906
[Epoch 38; Iter   601/ 1097] train: loss: 0.3795600
[Epoch 38; Iter   631/ 1097] train: loss: 0.1274940
[Epoch 38; Iter   661/ 1097] train: loss: 0.0310532
[Epoch 38; Iter   691/ 1097] train: loss: 0.1409872
[Epoch 38; Iter   721/ 1097] train: loss: 0.0051759
[Epoch 38; Iter   751/ 1097] train: loss: 0.1146990
[Epoch 38; Iter   781/ 1097] train: loss: 0.0328790
[Epoch 38; Iter   811/ 1097] train: loss: 0.0144392
[Epoch 38; Iter   841/ 1097] train: loss: 0.0156576
[Epoch 38; Iter   871/ 1097] train: loss: 0.0027332
[Epoch 38; Iter   901/ 1097] train: loss: 0.0306649
[Epoch 38; Iter   931/ 1097] train: loss: 0.0167447
[Epoch 38; Iter   961/ 1097] train: loss: 0.0610619
[Epoch 38; Iter   991/ 1097] train: loss: 0.0820605
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0034183
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0153086
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0828929
[Epoch 38] ogbg-molhiv: 0.677607 val loss: 1.265202
[Epoch 38] ogbg-molhiv: 0.681182 test loss: 0.343543
[Epoch 39; Iter    14/ 1097] train: loss: 0.0123847
[Epoch 39; Iter    44/ 1097] train: loss: 0.0827153
[Epoch 39; Iter    74/ 1097] train: loss: 0.0033137
[Epoch 39; Iter   104/ 1097] train: loss: 0.0009155
[Epoch 39; Iter   134/ 1097] train: loss: 0.0239428
[Epoch 39; Iter   164/ 1097] train: loss: 0.0022900
[Epoch 39; Iter   194/ 1097] train: loss: 0.0204079
[Epoch 39; Iter   224/ 1097] train: loss: 0.0089415
[Epoch 39; Iter   254/ 1097] train: loss: 0.0024372
[Epoch 39; Iter   284/ 1097] train: loss: 0.0044088
[Epoch 39; Iter   314/ 1097] train: loss: 0.0202484
[Epoch 39; Iter   344/ 1097] train: loss: 0.0650463
[Epoch 39; Iter   374/ 1097] train: loss: 0.0396449
[Epoch 39; Iter   404/ 1097] train: loss: 0.0181859
[Epoch 39; Iter   434/ 1097] train: loss: 0.0043426
[Epoch 39; Iter   464/ 1097] train: loss: 0.0893112
[Epoch 39; Iter   494/ 1097] train: loss: 0.0206292
[Epoch 39; Iter   524/ 1097] train: loss: 0.0144744
[Epoch 39; Iter   554/ 1097] train: loss: 0.0151341
[Epoch 39; Iter   584/ 1097] train: loss: 0.0334100
[Epoch 39; Iter   614/ 1097] train: loss: 0.0944086
[Epoch 39; Iter   644/ 1097] train: loss: 0.0187393
[Epoch 39; Iter   674/ 1097] train: loss: 0.0465921
[Epoch 39; Iter   704/ 1097] train: loss: 0.0080056
[Epoch 39; Iter   734/ 1097] train: loss: 0.0123398
[Epoch 39; Iter   764/ 1097] train: loss: 0.0185631
[Epoch 39; Iter   794/ 1097] train: loss: 0.0212265
[Epoch 39; Iter   824/ 1097] train: loss: 0.0066699
[Epoch 39; Iter   854/ 1097] train: loss: 0.1390531
[Epoch 39; Iter   884/ 1097] train: loss: 0.0012552
[Epoch 39; Iter   914/ 1097] train: loss: 0.0099297
[Epoch 39; Iter   944/ 1097] train: loss: 0.0807052
[Epoch 39; Iter   974/ 1097] train: loss: 0.0201628
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0623582
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0350387
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0660730
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1824298
[Epoch 39] ogbg-molhiv: 0.722433 val loss: 1.035054
[Epoch 39] ogbg-molhiv: 0.732762 test loss: 0.292846
[Epoch 40; Iter    27/ 1097] train: loss: 0.0286704
[Epoch 40; Iter    57/ 1097] train: loss: 0.0053104
[Epoch 40; Iter    87/ 1097] train: loss: 0.0250743
[Epoch 40; Iter   117/ 1097] train: loss: 0.0485153
[Epoch 40; Iter   147/ 1097] train: loss: 0.0039068
[Epoch 40; Iter   177/ 1097] train: loss: 0.0157117
[Epoch 40; Iter   207/ 1097] train: loss: 0.0081655
[Epoch 40; Iter   237/ 1097] train: loss: 0.0091826
[Epoch 40; Iter   267/ 1097] train: loss: 0.0165957
[Epoch 40; Iter   297/ 1097] train: loss: 0.0492812
[Epoch 40; Iter   327/ 1097] train: loss: 0.1953170
[Epoch 40; Iter   357/ 1097] train: loss: 0.0305055
[Epoch 40; Iter   387/ 1097] train: loss: 0.0075622
[Epoch 40; Iter   417/ 1097] train: loss: 0.0034444
[Epoch 40; Iter   447/ 1097] train: loss: 0.0669186
[Epoch 40; Iter   477/ 1097] train: loss: 0.0040172
[Epoch 40; Iter   507/ 1097] train: loss: 0.0056045
[Epoch 40; Iter   537/ 1097] train: loss: 0.1384150
[Epoch 40; Iter   567/ 1097] train: loss: 0.0009236
[Epoch 40; Iter   597/ 1097] train: loss: 0.0083569
[Epoch 40; Iter   627/ 1097] train: loss: 0.0116220
[Epoch 40; Iter   657/ 1097] train: loss: 0.0240419
[Epoch 36; Iter   605/ 1097] train: loss: 0.0735448
[Epoch 36; Iter   635/ 1097] train: loss: 0.1215271
[Epoch 36; Iter   665/ 1097] train: loss: 0.0085784
[Epoch 36; Iter   695/ 1097] train: loss: 0.0235245
[Epoch 36; Iter   725/ 1097] train: loss: 0.0211932
[Epoch 36; Iter   755/ 1097] train: loss: 0.0103099
[Epoch 36; Iter   785/ 1097] train: loss: 0.0320549
[Epoch 36; Iter   815/ 1097] train: loss: 0.0167300
[Epoch 36; Iter   845/ 1097] train: loss: 0.0396909
[Epoch 36; Iter   875/ 1097] train: loss: 0.0053110
[Epoch 36; Iter   905/ 1097] train: loss: 0.0023619
[Epoch 36; Iter   935/ 1097] train: loss: 0.0263556
[Epoch 36; Iter   965/ 1097] train: loss: 0.0060810
[Epoch 36; Iter   995/ 1097] train: loss: 0.0099404
[Epoch 36; Iter  1025/ 1097] train: loss: 0.1809762
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0248478
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0029620
[Epoch 36] ogbg-molhiv: 0.770429 val loss: 0.129031
[Epoch 36] ogbg-molhiv: 0.754713 test loss: 0.178543
[Epoch 37; Iter    18/ 1097] train: loss: 0.0044757
[Epoch 37; Iter    48/ 1097] train: loss: 0.0045331
[Epoch 37; Iter    78/ 1097] train: loss: 0.0066056
[Epoch 37; Iter   108/ 1097] train: loss: 0.0776150
[Epoch 37; Iter   138/ 1097] train: loss: 0.0179351
[Epoch 37; Iter   168/ 1097] train: loss: 0.0172655
[Epoch 37; Iter   198/ 1097] train: loss: 0.0182889
[Epoch 37; Iter   228/ 1097] train: loss: 0.0034009
[Epoch 37; Iter   258/ 1097] train: loss: 0.0139536
[Epoch 37; Iter   288/ 1097] train: loss: 0.0818231
[Epoch 37; Iter   318/ 1097] train: loss: 0.0052888
[Epoch 37; Iter   348/ 1097] train: loss: 0.0187336
[Epoch 37; Iter   378/ 1097] train: loss: 0.0800235
[Epoch 37; Iter   408/ 1097] train: loss: 0.0040844
[Epoch 37; Iter   438/ 1097] train: loss: 0.0620316
[Epoch 37; Iter   468/ 1097] train: loss: 0.0122363
[Epoch 37; Iter   498/ 1097] train: loss: 0.0019224
[Epoch 37; Iter   528/ 1097] train: loss: 0.0363965
[Epoch 37; Iter   558/ 1097] train: loss: 0.0361596
[Epoch 37; Iter   588/ 1097] train: loss: 0.0046033
[Epoch 37; Iter   618/ 1097] train: loss: 0.0018636
[Epoch 37; Iter   648/ 1097] train: loss: 0.0031918
[Epoch 37; Iter   678/ 1097] train: loss: 0.0097650
[Epoch 37; Iter   708/ 1097] train: loss: 0.0179392
[Epoch 37; Iter   738/ 1097] train: loss: 0.2902109
[Epoch 37; Iter   768/ 1097] train: loss: 0.0114960
[Epoch 37; Iter   798/ 1097] train: loss: 0.0154668
[Epoch 37; Iter   828/ 1097] train: loss: 0.0079093
[Epoch 37; Iter   858/ 1097] train: loss: 0.0077435
[Epoch 37; Iter   888/ 1097] train: loss: 0.0080310
[Epoch 37; Iter   918/ 1097] train: loss: 0.0281901
[Epoch 37; Iter   948/ 1097] train: loss: 0.0063782
[Epoch 37; Iter   978/ 1097] train: loss: 0.0561996
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0052804
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0242883
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0204792
[Epoch 37] ogbg-molhiv: 0.787677 val loss: 0.169705
[Epoch 37] ogbg-molhiv: 0.728108 test loss: 0.224261
[Epoch 38; Iter     1/ 1097] train: loss: 0.0475621
[Epoch 38; Iter    31/ 1097] train: loss: 0.0052990
[Epoch 38; Iter    61/ 1097] train: loss: 0.0497782
[Epoch 38; Iter    91/ 1097] train: loss: 0.0077516
[Epoch 38; Iter   121/ 1097] train: loss: 0.0004745
[Epoch 38; Iter   151/ 1097] train: loss: 0.0017398
[Epoch 38; Iter   181/ 1097] train: loss: 0.0314710
[Epoch 38; Iter   211/ 1097] train: loss: 0.0008726
[Epoch 38; Iter   241/ 1097] train: loss: 0.0021771
[Epoch 38; Iter   271/ 1097] train: loss: 0.0028932
[Epoch 38; Iter   301/ 1097] train: loss: 0.0015371
[Epoch 38; Iter   331/ 1097] train: loss: 0.0066179
[Epoch 38; Iter   361/ 1097] train: loss: 0.0095633
[Epoch 38; Iter   391/ 1097] train: loss: 0.0044594
[Epoch 38; Iter   421/ 1097] train: loss: 0.0778641
[Epoch 38; Iter   451/ 1097] train: loss: 0.0008982
[Epoch 38; Iter   481/ 1097] train: loss: 0.0174922
[Epoch 38; Iter   511/ 1097] train: loss: 0.0011778
[Epoch 38; Iter   541/ 1097] train: loss: 0.0093727
[Epoch 38; Iter   571/ 1097] train: loss: 0.0100464
[Epoch 38; Iter   601/ 1097] train: loss: 0.0158496
[Epoch 38; Iter   631/ 1097] train: loss: 0.0021242
[Epoch 38; Iter   661/ 1097] train: loss: 0.0035409
[Epoch 38; Iter   691/ 1097] train: loss: 0.0023216
[Epoch 38; Iter   721/ 1097] train: loss: 0.0162221
[Epoch 38; Iter   751/ 1097] train: loss: 0.0006357
[Epoch 38; Iter   781/ 1097] train: loss: 0.0063443
[Epoch 38; Iter   811/ 1097] train: loss: 0.0028107
[Epoch 38; Iter   841/ 1097] train: loss: 0.0034172
[Epoch 38; Iter   871/ 1097] train: loss: 0.0045964
[Epoch 38; Iter   901/ 1097] train: loss: 0.0006161
[Epoch 38; Iter   931/ 1097] train: loss: 0.0124297
[Epoch 38; Iter   961/ 1097] train: loss: 0.0011736
[Epoch 38; Iter   991/ 1097] train: loss: 0.0319435
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0020877
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0102914
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0446997
[Epoch 38] ogbg-molhiv: 0.759715 val loss: 0.147567
[Epoch 38] ogbg-molhiv: 0.708270 test loss: 0.220520
[Epoch 39; Iter    14/ 1097] train: loss: 0.0057603
[Epoch 39; Iter    44/ 1097] train: loss: 0.0243455
[Epoch 39; Iter    74/ 1097] train: loss: 0.0039648
[Epoch 39; Iter   104/ 1097] train: loss: 0.0055259
[Epoch 39; Iter   134/ 1097] train: loss: 0.0066099
[Epoch 39; Iter   164/ 1097] train: loss: 0.0044882
[Epoch 39; Iter   194/ 1097] train: loss: 0.0138366
[Epoch 39; Iter   224/ 1097] train: loss: 0.0049005
[Epoch 39; Iter   254/ 1097] train: loss: 0.0020161
[Epoch 39; Iter   284/ 1097] train: loss: 0.0055131
[Epoch 39; Iter   314/ 1097] train: loss: 0.0044808
[Epoch 39; Iter   344/ 1097] train: loss: 0.0116044
[Epoch 39; Iter   374/ 1097] train: loss: 0.0010809
[Epoch 39; Iter   404/ 1097] train: loss: 0.0016965
[Epoch 39; Iter   434/ 1097] train: loss: 0.0060574
[Epoch 39; Iter   464/ 1097] train: loss: 0.0034715
[Epoch 39; Iter   494/ 1097] train: loss: 0.0050991
[Epoch 39; Iter   524/ 1097] train: loss: 0.0028010
[Epoch 39; Iter   554/ 1097] train: loss: 0.0018969
[Epoch 39; Iter   584/ 1097] train: loss: 0.0054896
[Epoch 39; Iter   614/ 1097] train: loss: 0.0029720
[Epoch 39; Iter   644/ 1097] train: loss: 0.0612653
[Epoch 39; Iter   674/ 1097] train: loss: 0.0019400
[Epoch 39; Iter   704/ 1097] train: loss: 0.0005260
[Epoch 39; Iter   734/ 1097] train: loss: 0.0520757
[Epoch 39; Iter   764/ 1097] train: loss: 0.0049587
[Epoch 39; Iter   794/ 1097] train: loss: 0.0213637
[Epoch 39; Iter   824/ 1097] train: loss: 0.0040648
[Epoch 39; Iter   854/ 1097] train: loss: 0.0020364
[Epoch 39; Iter   884/ 1097] train: loss: 0.0032695
[Epoch 39; Iter   914/ 1097] train: loss: 0.0052876
[Epoch 39; Iter   944/ 1097] train: loss: 0.0336123
[Epoch 39; Iter   974/ 1097] train: loss: 0.0076413
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0039607
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0079000
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0521123
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0610494
[Epoch 39] ogbg-molhiv: 0.798596 val loss: 0.202351
[Epoch 39] ogbg-molhiv: 0.732048 test loss: 0.222442
[Epoch 40; Iter    27/ 1097] train: loss: 0.0097255
[Epoch 40; Iter    57/ 1097] train: loss: 0.0018347
[Epoch 40; Iter    87/ 1097] train: loss: 0.0047317
[Epoch 40; Iter   117/ 1097] train: loss: 0.0249557
[Epoch 40; Iter   147/ 1097] train: loss: 0.0168168
[Epoch 40; Iter   177/ 1097] train: loss: 0.0082416
[Epoch 40; Iter   207/ 1097] train: loss: 0.0050930
[Epoch 40; Iter   237/ 1097] train: loss: 0.0008830
[Epoch 40; Iter   267/ 1097] train: loss: 0.0496957
[Epoch 40; Iter   297/ 1097] train: loss: 0.0231191
[Epoch 40; Iter   327/ 1097] train: loss: 0.0666160
[Epoch 40; Iter   357/ 1097] train: loss: 0.0028138
[Epoch 40; Iter   387/ 1097] train: loss: 0.0323831
[Epoch 40; Iter   417/ 1097] train: loss: 0.0003875
[Epoch 40; Iter   447/ 1097] train: loss: 0.0033480
[Epoch 40; Iter   477/ 1097] train: loss: 0.0029285
[Epoch 40; Iter   507/ 1097] train: loss: 0.0019548
[Epoch 40; Iter   537/ 1097] train: loss: 0.0005334
[Epoch 40; Iter   567/ 1097] train: loss: 0.0134750
[Epoch 40; Iter   597/ 1097] train: loss: 0.0311473
[Epoch 40; Iter   627/ 1097] train: loss: 0.0156867
[Epoch 40; Iter   657/ 1097] train: loss: 0.0025872
[Epoch 36; Iter   605/ 1097] train: loss: 0.0097637
[Epoch 36; Iter   635/ 1097] train: loss: 0.0266037
[Epoch 36; Iter   665/ 1097] train: loss: 0.0102470
[Epoch 36; Iter   695/ 1097] train: loss: 0.0138105
[Epoch 36; Iter   725/ 1097] train: loss: 0.0664869
[Epoch 36; Iter   755/ 1097] train: loss: 0.0105564
[Epoch 36; Iter   785/ 1097] train: loss: 0.0021657
[Epoch 36; Iter   815/ 1097] train: loss: 0.0080449
[Epoch 36; Iter   845/ 1097] train: loss: 0.0068582
[Epoch 36; Iter   875/ 1097] train: loss: 0.0036525
[Epoch 36; Iter   905/ 1097] train: loss: 0.0030279
[Epoch 36; Iter   935/ 1097] train: loss: 0.0496062
[Epoch 36; Iter   965/ 1097] train: loss: 0.0055778
[Epoch 36; Iter   995/ 1097] train: loss: 0.0024659
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0417589
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0211949
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0014231
[Epoch 36] ogbg-molhiv: 0.773130 val loss: 0.141921
[Epoch 36] ogbg-molhiv: 0.720163 test loss: 0.252935
[Epoch 37; Iter    18/ 1097] train: loss: 0.0056183
[Epoch 37; Iter    48/ 1097] train: loss: 0.0060821
[Epoch 37; Iter    78/ 1097] train: loss: 0.0235965
[Epoch 37; Iter   108/ 1097] train: loss: 0.1893325
[Epoch 37; Iter   138/ 1097] train: loss: 0.0099451
[Epoch 37; Iter   168/ 1097] train: loss: 0.0091398
[Epoch 37; Iter   198/ 1097] train: loss: 0.0628979
[Epoch 37; Iter   228/ 1097] train: loss: 0.1078328
[Epoch 37; Iter   258/ 1097] train: loss: 0.0055737
[Epoch 37; Iter   288/ 1097] train: loss: 0.1285395
[Epoch 37; Iter   318/ 1097] train: loss: 0.0122970
[Epoch 37; Iter   348/ 1097] train: loss: 0.0437287
[Epoch 37; Iter   378/ 1097] train: loss: 0.0009163
[Epoch 37; Iter   408/ 1097] train: loss: 0.0180004
[Epoch 37; Iter   438/ 1097] train: loss: 0.0051345
[Epoch 37; Iter   468/ 1097] train: loss: 0.0015261
[Epoch 37; Iter   498/ 1097] train: loss: 0.0516205
[Epoch 37; Iter   528/ 1097] train: loss: 0.0462968
[Epoch 37; Iter   558/ 1097] train: loss: 0.0264279
[Epoch 37; Iter   588/ 1097] train: loss: 0.0187001
[Epoch 37; Iter   618/ 1097] train: loss: 0.1076730
[Epoch 37; Iter   648/ 1097] train: loss: 0.0021018
[Epoch 37; Iter   678/ 1097] train: loss: 0.0222301
[Epoch 37; Iter   708/ 1097] train: loss: 0.0060744
[Epoch 37; Iter   738/ 1097] train: loss: 0.1266479
[Epoch 37; Iter   768/ 1097] train: loss: 0.0057670
[Epoch 37; Iter   798/ 1097] train: loss: 0.0517590
[Epoch 37; Iter   828/ 1097] train: loss: 0.0038040
[Epoch 37; Iter   858/ 1097] train: loss: 0.0086720
[Epoch 37; Iter   888/ 1097] train: loss: 0.0202101
[Epoch 37; Iter   918/ 1097] train: loss: 0.0398787
[Epoch 37; Iter   948/ 1097] train: loss: 0.0169216
[Epoch 37; Iter   978/ 1097] train: loss: 0.0543342
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0139792
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0097026
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0067974
[Epoch 37] ogbg-molhiv: 0.756323 val loss: 0.211404
[Epoch 37] ogbg-molhiv: 0.696452 test loss: 0.270988
[Epoch 38; Iter     1/ 1097] train: loss: 0.0050915
[Epoch 38; Iter    31/ 1097] train: loss: 0.0108799
[Epoch 38; Iter    61/ 1097] train: loss: 0.0090917
[Epoch 38; Iter    91/ 1097] train: loss: 0.0042651
[Epoch 38; Iter   121/ 1097] train: loss: 0.1149350
[Epoch 38; Iter   151/ 1097] train: loss: 0.0064489
[Epoch 38; Iter   181/ 1097] train: loss: 0.0122740
[Epoch 38; Iter   211/ 1097] train: loss: 0.0244392
[Epoch 38; Iter   241/ 1097] train: loss: 0.0103319
[Epoch 38; Iter   271/ 1097] train: loss: 0.0207249
[Epoch 38; Iter   301/ 1097] train: loss: 0.0102473
[Epoch 38; Iter   331/ 1097] train: loss: 0.0029560
[Epoch 38; Iter   361/ 1097] train: loss: 0.0576834
[Epoch 38; Iter   391/ 1097] train: loss: 0.1024840
[Epoch 38; Iter   421/ 1097] train: loss: 0.0012071
[Epoch 38; Iter   451/ 1097] train: loss: 0.0482117
[Epoch 38; Iter   481/ 1097] train: loss: 0.0021696
[Epoch 38; Iter   511/ 1097] train: loss: 0.0031832
[Epoch 38; Iter   541/ 1097] train: loss: 0.0163299
[Epoch 38; Iter   571/ 1097] train: loss: 0.0028001
[Epoch 38; Iter   601/ 1097] train: loss: 0.0020970
[Epoch 38; Iter   631/ 1097] train: loss: 0.0055136
[Epoch 38; Iter   661/ 1097] train: loss: 0.0055008
[Epoch 38; Iter   691/ 1097] train: loss: 0.0053447
[Epoch 38; Iter   721/ 1097] train: loss: 0.0515715
[Epoch 38; Iter   751/ 1097] train: loss: 0.0318486
[Epoch 38; Iter   781/ 1097] train: loss: 0.0219939
[Epoch 38; Iter   811/ 1097] train: loss: 0.0139943
[Epoch 38; Iter   841/ 1097] train: loss: 0.0555728
[Epoch 38; Iter   871/ 1097] train: loss: 0.0035117
[Epoch 38; Iter   901/ 1097] train: loss: 0.0046467
[Epoch 38; Iter   931/ 1097] train: loss: 0.0387930
[Epoch 38; Iter   961/ 1097] train: loss: 0.0048040
[Epoch 38; Iter   991/ 1097] train: loss: 0.0150181
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0324201
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0029698
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0252314
[Epoch 38] ogbg-molhiv: 0.756712 val loss: 0.251575
[Epoch 38] ogbg-molhiv: 0.706960 test loss: 0.325551
[Epoch 39; Iter    14/ 1097] train: loss: 0.0235868
[Epoch 39; Iter    44/ 1097] train: loss: 0.0964356
[Epoch 39; Iter    74/ 1097] train: loss: 0.0589730
[Epoch 39; Iter   104/ 1097] train: loss: 0.0048547
[Epoch 39; Iter   134/ 1097] train: loss: 0.0066592
[Epoch 39; Iter   164/ 1097] train: loss: 0.0712353
[Epoch 39; Iter   194/ 1097] train: loss: 0.0018708
[Epoch 39; Iter   224/ 1097] train: loss: 0.0215701
[Epoch 39; Iter   254/ 1097] train: loss: 0.0119968
[Epoch 39; Iter   284/ 1097] train: loss: 0.0728141
[Epoch 39; Iter   314/ 1097] train: loss: 0.0040187
[Epoch 39; Iter   344/ 1097] train: loss: 0.0129443
[Epoch 39; Iter   374/ 1097] train: loss: 0.0155717
[Epoch 39; Iter   404/ 1097] train: loss: 0.0425223
[Epoch 39; Iter   434/ 1097] train: loss: 0.0149253
[Epoch 39; Iter   464/ 1097] train: loss: 0.0153252
[Epoch 39; Iter   494/ 1097] train: loss: 0.0060368
[Epoch 39; Iter   524/ 1097] train: loss: 0.0215059
[Epoch 39; Iter   554/ 1097] train: loss: 0.0164222
[Epoch 39; Iter   584/ 1097] train: loss: 0.0376414
[Epoch 39; Iter   614/ 1097] train: loss: 0.1877840
[Epoch 39; Iter   644/ 1097] train: loss: 0.0058677
[Epoch 39; Iter   674/ 1097] train: loss: 0.0136819
[Epoch 39; Iter   704/ 1097] train: loss: 0.0037336
[Epoch 39; Iter   734/ 1097] train: loss: 0.0099761
[Epoch 39; Iter   764/ 1097] train: loss: 0.0023681
[Epoch 39; Iter   794/ 1097] train: loss: 0.0874880
[Epoch 39; Iter   824/ 1097] train: loss: 0.0032227
[Epoch 39; Iter   854/ 1097] train: loss: 0.1542397
[Epoch 39; Iter   884/ 1097] train: loss: 0.0311519
[Epoch 39; Iter   914/ 1097] train: loss: 0.0344934
[Epoch 39; Iter   944/ 1097] train: loss: 0.0994253
[Epoch 39; Iter   974/ 1097] train: loss: 0.0067380
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0015632
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0013363
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0173032
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0023789
[Epoch 39] ogbg-molhiv: 0.790831 val loss: 0.174405
[Epoch 39] ogbg-molhiv: 0.707777 test loss: 0.315235
[Epoch 40; Iter    27/ 1097] train: loss: 0.0020087
[Epoch 40; Iter    57/ 1097] train: loss: 0.0031311
[Epoch 40; Iter    87/ 1097] train: loss: 0.0103432
[Epoch 40; Iter   117/ 1097] train: loss: 0.0167995
[Epoch 40; Iter   147/ 1097] train: loss: 0.0092452
[Epoch 40; Iter   177/ 1097] train: loss: 0.0023914
[Epoch 40; Iter   207/ 1097] train: loss: 0.0157217
[Epoch 40; Iter   237/ 1097] train: loss: 0.0086774
[Epoch 40; Iter   267/ 1097] train: loss: 0.0127727
[Epoch 40; Iter   297/ 1097] train: loss: 0.0003319
[Epoch 40; Iter   327/ 1097] train: loss: 0.0495767
[Epoch 40; Iter   357/ 1097] train: loss: 0.0138606
[Epoch 40; Iter   387/ 1097] train: loss: 0.0015828
[Epoch 40; Iter   417/ 1097] train: loss: 0.0133559
[Epoch 40; Iter   447/ 1097] train: loss: 0.0062869
[Epoch 40; Iter   477/ 1097] train: loss: 0.0413848
[Epoch 40; Iter   507/ 1097] train: loss: 0.0058119
[Epoch 40; Iter   537/ 1097] train: loss: 0.0194523
[Epoch 40; Iter   567/ 1097] train: loss: 0.0175594
[Epoch 40; Iter   597/ 1097] train: loss: 0.0037151
[Epoch 40; Iter   627/ 1097] train: loss: 0.0060529
[Epoch 40; Iter   657/ 1097] train: loss: 0.0144569
[Epoch 36; Iter   605/ 1097] train: loss: 0.0080105
[Epoch 36; Iter   635/ 1097] train: loss: 0.0477032
[Epoch 36; Iter   665/ 1097] train: loss: 0.0011880
[Epoch 36; Iter   695/ 1097] train: loss: 0.0378695
[Epoch 36; Iter   725/ 1097] train: loss: 0.0013577
[Epoch 36; Iter   755/ 1097] train: loss: 0.0038873
[Epoch 36; Iter   785/ 1097] train: loss: 0.0015707
[Epoch 36; Iter   815/ 1097] train: loss: 0.0436198
[Epoch 36; Iter   845/ 1097] train: loss: 0.0029545
[Epoch 36; Iter   875/ 1097] train: loss: 0.0075020
[Epoch 36; Iter   905/ 1097] train: loss: 0.0129754
[Epoch 36; Iter   935/ 1097] train: loss: 0.0128115
[Epoch 36; Iter   965/ 1097] train: loss: 0.0022266
[Epoch 36; Iter   995/ 1097] train: loss: 0.0003407
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0451678
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1463209
[Epoch 36; Iter  1085/ 1097] train: loss: 0.2167198
[Epoch 36] ogbg-molhiv: 0.757995 val loss: 0.212065
[Epoch 36] ogbg-molhiv: 0.792634 test loss: 0.214797
[Epoch 37; Iter    18/ 1097] train: loss: 0.0107249
[Epoch 37; Iter    48/ 1097] train: loss: 0.0022319
[Epoch 37; Iter    78/ 1097] train: loss: 0.0056040
[Epoch 37; Iter   108/ 1097] train: loss: 0.0025542
[Epoch 37; Iter   138/ 1097] train: loss: 0.0096699
[Epoch 37; Iter   168/ 1097] train: loss: 0.0024405
[Epoch 37; Iter   198/ 1097] train: loss: 0.0109224
[Epoch 37; Iter   228/ 1097] train: loss: 0.0011774
[Epoch 37; Iter   258/ 1097] train: loss: 0.0008246
[Epoch 37; Iter   288/ 1097] train: loss: 0.0191409
[Epoch 37; Iter   318/ 1097] train: loss: 0.0015013
[Epoch 37; Iter   348/ 1097] train: loss: 0.0020459
[Epoch 37; Iter   378/ 1097] train: loss: 0.0155443
[Epoch 37; Iter   408/ 1097] train: loss: 0.0155796
[Epoch 37; Iter   438/ 1097] train: loss: 0.0381003
[Epoch 37; Iter   468/ 1097] train: loss: 0.0002706
[Epoch 37; Iter   498/ 1097] train: loss: 0.0025528
[Epoch 37; Iter   528/ 1097] train: loss: 0.0153973
[Epoch 37; Iter   558/ 1097] train: loss: 0.0020304
[Epoch 37; Iter   588/ 1097] train: loss: 0.0014255
[Epoch 37; Iter   618/ 1097] train: loss: 0.0238610
[Epoch 37; Iter   648/ 1097] train: loss: 0.0090894
[Epoch 37; Iter   678/ 1097] train: loss: 0.2228799
[Epoch 37; Iter   708/ 1097] train: loss: 0.0018810
[Epoch 37; Iter   738/ 1097] train: loss: 0.0504995
[Epoch 37; Iter   768/ 1097] train: loss: 0.0080451
[Epoch 37; Iter   798/ 1097] train: loss: 0.1697074
[Epoch 37; Iter   828/ 1097] train: loss: 0.0013218
[Epoch 37; Iter   858/ 1097] train: loss: 0.0009734
[Epoch 37; Iter   888/ 1097] train: loss: 0.0069415
[Epoch 37; Iter   918/ 1097] train: loss: 0.0101029
[Epoch 37; Iter   948/ 1097] train: loss: 0.0347228
[Epoch 37; Iter   978/ 1097] train: loss: 0.1187849
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0105739
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0610170
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0074393
[Epoch 37] ogbg-molhiv: 0.801094 val loss: 0.134586
[Epoch 37] ogbg-molhiv: 0.804811 test loss: 0.194525
[Epoch 38; Iter     1/ 1097] train: loss: 0.0011634
[Epoch 38; Iter    31/ 1097] train: loss: 0.0004768
[Epoch 38; Iter    61/ 1097] train: loss: 0.0415796
[Epoch 38; Iter    91/ 1097] train: loss: 0.0096589
[Epoch 38; Iter   121/ 1097] train: loss: 0.0040982
[Epoch 38; Iter   151/ 1097] train: loss: 0.0013234
[Epoch 38; Iter   181/ 1097] train: loss: 0.0205794
[Epoch 38; Iter   211/ 1097] train: loss: 0.0468731
[Epoch 38; Iter   241/ 1097] train: loss: 0.0704318
[Epoch 38; Iter   271/ 1097] train: loss: 0.0202850
[Epoch 38; Iter   301/ 1097] train: loss: 0.0426830
[Epoch 38; Iter   331/ 1097] train: loss: 0.0251824
[Epoch 38; Iter   361/ 1097] train: loss: 0.0058175
[Epoch 38; Iter   391/ 1097] train: loss: 0.0027909
[Epoch 38; Iter   421/ 1097] train: loss: 0.0314044
[Epoch 38; Iter   451/ 1097] train: loss: 0.0086826
[Epoch 38; Iter   481/ 1097] train: loss: 0.0054403
[Epoch 38; Iter   511/ 1097] train: loss: 0.0012987
[Epoch 38; Iter   541/ 1097] train: loss: 0.0024761
[Epoch 38; Iter   571/ 1097] train: loss: 0.0129219
[Epoch 38; Iter   601/ 1097] train: loss: 0.1391412
[Epoch 38; Iter   631/ 1097] train: loss: 0.2421076
[Epoch 38; Iter   661/ 1097] train: loss: 0.0010132
[Epoch 38; Iter   691/ 1097] train: loss: 0.0033866
[Epoch 38; Iter   721/ 1097] train: loss: 0.0582010
[Epoch 38; Iter   751/ 1097] train: loss: 0.0021477
[Epoch 38; Iter   781/ 1097] train: loss: 0.0247234
[Epoch 38; Iter   811/ 1097] train: loss: 0.0049459
[Epoch 38; Iter   841/ 1097] train: loss: 0.1253159
[Epoch 38; Iter   871/ 1097] train: loss: 0.0017661
[Epoch 38; Iter   901/ 1097] train: loss: 0.0019530
[Epoch 38; Iter   931/ 1097] train: loss: 0.0014138
[Epoch 38; Iter   961/ 1097] train: loss: 0.0158899
[Epoch 38; Iter   991/ 1097] train: loss: 0.0043666
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0025330
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0034072
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0007769
[Epoch 38] ogbg-molhiv: 0.790721 val loss: 0.157270
[Epoch 38] ogbg-molhiv: 0.802567 test loss: 0.210154
[Epoch 39; Iter    14/ 1097] train: loss: 0.0024962
[Epoch 39; Iter    44/ 1097] train: loss: 0.0087917
[Epoch 39; Iter    74/ 1097] train: loss: 0.0043856
[Epoch 39; Iter   104/ 1097] train: loss: 0.0049762
[Epoch 39; Iter   134/ 1097] train: loss: 0.0026567
[Epoch 39; Iter   164/ 1097] train: loss: 0.0254984
[Epoch 39; Iter   194/ 1097] train: loss: 0.0005228
[Epoch 39; Iter   224/ 1097] train: loss: 0.0126611
[Epoch 39; Iter   254/ 1097] train: loss: 0.0094543
[Epoch 39; Iter   284/ 1097] train: loss: 0.0038663
[Epoch 39; Iter   314/ 1097] train: loss: 0.0009973
[Epoch 39; Iter   344/ 1097] train: loss: 0.0042361
[Epoch 39; Iter   374/ 1097] train: loss: 0.0011032
[Epoch 39; Iter   404/ 1097] train: loss: 0.0021397
[Epoch 39; Iter   434/ 1097] train: loss: 0.0023469
[Epoch 39; Iter   464/ 1097] train: loss: 0.0106599
[Epoch 39; Iter   494/ 1097] train: loss: 0.0053495
[Epoch 39; Iter   524/ 1097] train: loss: 0.0051258
[Epoch 39; Iter   554/ 1097] train: loss: 0.0155624
[Epoch 39; Iter   584/ 1097] train: loss: 0.0412012
[Epoch 39; Iter   614/ 1097] train: loss: 0.0007825
[Epoch 39; Iter   644/ 1097] train: loss: 0.0007550
[Epoch 39; Iter   674/ 1097] train: loss: 0.0343507
[Epoch 39; Iter   704/ 1097] train: loss: 0.0054762
[Epoch 39; Iter   734/ 1097] train: loss: 0.0047924
[Epoch 39; Iter   764/ 1097] train: loss: 0.0098439
[Epoch 39; Iter   794/ 1097] train: loss: 0.0148187
[Epoch 39; Iter   824/ 1097] train: loss: 0.0046373
[Epoch 39; Iter   854/ 1097] train: loss: 0.0007536
[Epoch 39; Iter   884/ 1097] train: loss: 0.0001473
[Epoch 39; Iter   914/ 1097] train: loss: 0.0010746
[Epoch 39; Iter   944/ 1097] train: loss: 0.0351518
[Epoch 39; Iter   974/ 1097] train: loss: 0.0079063
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0285320
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0016772
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0031679
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0157078
[Epoch 39] ogbg-molhiv: 0.789214 val loss: 0.155266
[Epoch 39] ogbg-molhiv: 0.785208 test loss: 0.209105
[Epoch 40; Iter    27/ 1097] train: loss: 0.0030993
[Epoch 40; Iter    57/ 1097] train: loss: 0.0007222
[Epoch 40; Iter    87/ 1097] train: loss: 0.0067826
[Epoch 40; Iter   117/ 1097] train: loss: 0.0510079
[Epoch 40; Iter   147/ 1097] train: loss: 0.0081361
[Epoch 40; Iter   177/ 1097] train: loss: 0.0013040
[Epoch 40; Iter   207/ 1097] train: loss: 0.0297748
[Epoch 40; Iter   237/ 1097] train: loss: 0.0005066
[Epoch 40; Iter   267/ 1097] train: loss: 0.0328103
[Epoch 40; Iter   297/ 1097] train: loss: 0.0485134
[Epoch 40; Iter   327/ 1097] train: loss: 0.0030847
[Epoch 40; Iter   357/ 1097] train: loss: 0.0055310
[Epoch 40; Iter   387/ 1097] train: loss: 0.0134623
[Epoch 40; Iter   417/ 1097] train: loss: 0.0242145
[Epoch 40; Iter   447/ 1097] train: loss: 0.0609383
[Epoch 40; Iter   477/ 1097] train: loss: 0.0012384
[Epoch 40; Iter   507/ 1097] train: loss: 0.0137200
[Epoch 40; Iter   537/ 1097] train: loss: 0.0038263
[Epoch 40; Iter   567/ 1097] train: loss: 0.0007464
[Epoch 40; Iter   597/ 1097] train: loss: 0.1568562
[Epoch 40; Iter   627/ 1097] train: loss: 0.0043338
[Epoch 40; Iter   657/ 1097] train: loss: 0.0056301
[Epoch 36; Iter   605/ 1097] train: loss: 0.0338913
[Epoch 36; Iter   635/ 1097] train: loss: 0.0196582
[Epoch 36; Iter   665/ 1097] train: loss: 0.0087939
[Epoch 36; Iter   695/ 1097] train: loss: 0.0656798
[Epoch 36; Iter   725/ 1097] train: loss: 0.0287078
[Epoch 36; Iter   755/ 1097] train: loss: 0.0082903
[Epoch 36; Iter   785/ 1097] train: loss: 0.0133775
[Epoch 36; Iter   815/ 1097] train: loss: 0.0183209
[Epoch 36; Iter   845/ 1097] train: loss: 0.0227744
[Epoch 36; Iter   875/ 1097] train: loss: 0.0099427
[Epoch 36; Iter   905/ 1097] train: loss: 0.0107152
[Epoch 36; Iter   935/ 1097] train: loss: 0.0083162
[Epoch 36; Iter   965/ 1097] train: loss: 0.1059032
[Epoch 36; Iter   995/ 1097] train: loss: 0.0403497
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0199005
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0487525
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1195771
[Epoch 36] ogbg-molhiv: 0.783899 val loss: 8.608566
[Epoch 36] ogbg-molhiv: 0.720549 test loss: 5.817617
[Epoch 37; Iter    18/ 1097] train: loss: 0.0089749
[Epoch 37; Iter    48/ 1097] train: loss: 0.0069262
[Epoch 37; Iter    78/ 1097] train: loss: 0.0136768
[Epoch 37; Iter   108/ 1097] train: loss: 0.0324514
[Epoch 37; Iter   138/ 1097] train: loss: 0.0057556
[Epoch 37; Iter   168/ 1097] train: loss: 0.0434504
[Epoch 37; Iter   198/ 1097] train: loss: 0.0057895
[Epoch 37; Iter   228/ 1097] train: loss: 0.0059284
[Epoch 37; Iter   258/ 1097] train: loss: 0.0263551
[Epoch 37; Iter   288/ 1097] train: loss: 0.0039476
[Epoch 37; Iter   318/ 1097] train: loss: 0.0043670
[Epoch 37; Iter   348/ 1097] train: loss: 0.0030098
[Epoch 37; Iter   378/ 1097] train: loss: 0.1283265
[Epoch 37; Iter   408/ 1097] train: loss: 0.1316858
[Epoch 37; Iter   438/ 1097] train: loss: 0.0284160
[Epoch 37; Iter   468/ 1097] train: loss: 0.0170641
[Epoch 37; Iter   498/ 1097] train: loss: 0.0208204
[Epoch 37; Iter   528/ 1097] train: loss: 0.0173822
[Epoch 37; Iter   558/ 1097] train: loss: 0.0073988
[Epoch 37; Iter   588/ 1097] train: loss: 0.0162463
[Epoch 37; Iter   618/ 1097] train: loss: 0.0639318
[Epoch 37; Iter   648/ 1097] train: loss: 0.0917730
[Epoch 37; Iter   678/ 1097] train: loss: 0.1274523
[Epoch 37; Iter   708/ 1097] train: loss: 0.0157305
[Epoch 37; Iter   738/ 1097] train: loss: 0.0072709
[Epoch 37; Iter   768/ 1097] train: loss: 0.0243126
[Epoch 37; Iter   798/ 1097] train: loss: 0.0956988
[Epoch 37; Iter   828/ 1097] train: loss: 0.0105077
[Epoch 37; Iter   858/ 1097] train: loss: 0.0185671
[Epoch 37; Iter   888/ 1097] train: loss: 0.0117733
[Epoch 37; Iter   918/ 1097] train: loss: 0.1598549
[Epoch 37; Iter   948/ 1097] train: loss: 0.0062908
[Epoch 37; Iter   978/ 1097] train: loss: 0.1141869
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0099113
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0205504
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0075702
[Epoch 37] ogbg-molhiv: 0.789566 val loss: 0.163754
[Epoch 37] ogbg-molhiv: 0.721702 test loss: 0.235951
[Epoch 38; Iter     1/ 1097] train: loss: 0.0011124
[Epoch 38; Iter    31/ 1097] train: loss: 0.0136056
[Epoch 38; Iter    61/ 1097] train: loss: 0.1011052
[Epoch 38; Iter    91/ 1097] train: loss: 0.0117710
[Epoch 38; Iter   121/ 1097] train: loss: 0.0026757
[Epoch 38; Iter   151/ 1097] train: loss: 0.0248271
[Epoch 38; Iter   181/ 1097] train: loss: 0.0041806
[Epoch 38; Iter   211/ 1097] train: loss: 0.0022731
[Epoch 38; Iter   241/ 1097] train: loss: 0.1215050
[Epoch 38; Iter   271/ 1097] train: loss: 0.0465207
[Epoch 38; Iter   301/ 1097] train: loss: 0.0014995
[Epoch 38; Iter   331/ 1097] train: loss: 0.0644847
[Epoch 38; Iter   361/ 1097] train: loss: 0.0061035
[Epoch 38; Iter   391/ 1097] train: loss: 0.0598403
[Epoch 38; Iter   421/ 1097] train: loss: 0.0097314
[Epoch 38; Iter   451/ 1097] train: loss: 0.0052704
[Epoch 38; Iter   481/ 1097] train: loss: 0.1459353
[Epoch 38; Iter   511/ 1097] train: loss: 0.0029832
[Epoch 38; Iter   541/ 1097] train: loss: 0.0387383
[Epoch 38; Iter   571/ 1097] train: loss: 0.0035955
[Epoch 38; Iter   601/ 1097] train: loss: 0.0451943
[Epoch 38; Iter   631/ 1097] train: loss: 0.0067063
[Epoch 38; Iter   661/ 1097] train: loss: 0.0140313
[Epoch 38; Iter   691/ 1097] train: loss: 0.0241115
[Epoch 38; Iter   721/ 1097] train: loss: 0.0059241
[Epoch 38; Iter   751/ 1097] train: loss: 0.0074065
[Epoch 38; Iter   781/ 1097] train: loss: 0.0133306
[Epoch 38; Iter   811/ 1097] train: loss: 0.0077693
[Epoch 38; Iter   841/ 1097] train: loss: 0.2794856
[Epoch 38; Iter   871/ 1097] train: loss: 0.0331442
[Epoch 38; Iter   901/ 1097] train: loss: 0.0264127
[Epoch 38; Iter   931/ 1097] train: loss: 0.1365075
[Epoch 38; Iter   961/ 1097] train: loss: 0.0055329
[Epoch 38; Iter   991/ 1097] train: loss: 0.0349283
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0133950
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0129972
[Epoch 38; Iter  1081/ 1097] train: loss: 0.1127043
[Epoch 38] ogbg-molhiv: 0.782407 val loss: 0.270344
[Epoch 38] ogbg-molhiv: 0.720812 test loss: 0.338108
[Epoch 39; Iter    14/ 1097] train: loss: 0.0025792
[Epoch 39; Iter    44/ 1097] train: loss: 0.0329887
[Epoch 39; Iter    74/ 1097] train: loss: 0.0047854
[Epoch 39; Iter   104/ 1097] train: loss: 0.0032911
[Epoch 39; Iter   134/ 1097] train: loss: 0.0080193
[Epoch 39; Iter   164/ 1097] train: loss: 0.0680573
[Epoch 39; Iter   194/ 1097] train: loss: 0.1108781
[Epoch 39; Iter   224/ 1097] train: loss: 0.0053883
[Epoch 39; Iter   254/ 1097] train: loss: 0.0030194
[Epoch 39; Iter   284/ 1097] train: loss: 0.0011136
[Epoch 39; Iter   314/ 1097] train: loss: 0.0046268
[Epoch 39; Iter   344/ 1097] train: loss: 0.0995167
[Epoch 39; Iter   374/ 1097] train: loss: 0.0033544
[Epoch 39; Iter   404/ 1097] train: loss: 0.0825061
[Epoch 39; Iter   434/ 1097] train: loss: 0.0017115
[Epoch 39; Iter   464/ 1097] train: loss: 0.0117708
[Epoch 39; Iter   494/ 1097] train: loss: 0.0075536
[Epoch 39; Iter   524/ 1097] train: loss: 0.1291374
[Epoch 39; Iter   554/ 1097] train: loss: 0.0518270
[Epoch 39; Iter   584/ 1097] train: loss: 0.0031224
[Epoch 39; Iter   614/ 1097] train: loss: 0.0081270
[Epoch 39; Iter   644/ 1097] train: loss: 0.0088252
[Epoch 39; Iter   674/ 1097] train: loss: 0.0038523
[Epoch 39; Iter   704/ 1097] train: loss: 0.0085643
[Epoch 39; Iter   734/ 1097] train: loss: 0.0022394
[Epoch 39; Iter   764/ 1097] train: loss: 0.0374266
[Epoch 39; Iter   794/ 1097] train: loss: 0.0195324
[Epoch 39; Iter   824/ 1097] train: loss: 0.1395680
[Epoch 39; Iter   854/ 1097] train: loss: 0.0035130
[Epoch 39; Iter   884/ 1097] train: loss: 0.0016165
[Epoch 39; Iter   914/ 1097] train: loss: 0.0058192
[Epoch 39; Iter   944/ 1097] train: loss: 0.0167777
[Epoch 39; Iter   974/ 1097] train: loss: 0.0189336
[Epoch 39; Iter  1004/ 1097] train: loss: 0.1262895
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0269740
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0245022
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0305789
[Epoch 39] ogbg-molhiv: 0.780123 val loss: 0.303176
[Epoch 39] ogbg-molhiv: 0.742757 test loss: 0.322601
[Epoch 40; Iter    27/ 1097] train: loss: 0.0364678
[Epoch 40; Iter    57/ 1097] train: loss: 0.0020807
[Epoch 40; Iter    87/ 1097] train: loss: 0.0478212
[Epoch 40; Iter   117/ 1097] train: loss: 0.1433903
[Epoch 40; Iter   147/ 1097] train: loss: 0.0072215
[Epoch 40; Iter   177/ 1097] train: loss: 0.0184556
[Epoch 40; Iter   207/ 1097] train: loss: 0.0768869
[Epoch 40; Iter   237/ 1097] train: loss: 0.0021186
[Epoch 40; Iter   267/ 1097] train: loss: 0.1333210
[Epoch 40; Iter   297/ 1097] train: loss: 0.0045205
[Epoch 40; Iter   327/ 1097] train: loss: 0.0221059
[Epoch 40; Iter   357/ 1097] train: loss: 0.0169588
[Epoch 40; Iter   387/ 1097] train: loss: 0.0062064
[Epoch 40; Iter   417/ 1097] train: loss: 0.0206204
[Epoch 40; Iter   447/ 1097] train: loss: 0.3469684
[Epoch 40; Iter   477/ 1097] train: loss: 0.0407566
[Epoch 40; Iter   507/ 1097] train: loss: 0.0346312
[Epoch 40; Iter   537/ 1097] train: loss: 0.0884246
[Epoch 40; Iter   567/ 1097] train: loss: 0.0081041
[Epoch 40; Iter   597/ 1097] train: loss: 0.0221028
[Epoch 40; Iter   627/ 1097] train: loss: 0.0020756
[Epoch 40; Iter   657/ 1097] train: loss: 0.0093285
[Epoch 36; Iter   605/ 1097] train: loss: 0.0052348
[Epoch 36; Iter   635/ 1097] train: loss: 0.0007787
[Epoch 36; Iter   665/ 1097] train: loss: 0.0004846
[Epoch 36; Iter   695/ 1097] train: loss: 0.0024732
[Epoch 36; Iter   725/ 1097] train: loss: 0.0125355
[Epoch 36; Iter   755/ 1097] train: loss: 0.0007833
[Epoch 36; Iter   785/ 1097] train: loss: 0.0009347
[Epoch 36; Iter   815/ 1097] train: loss: 0.0750304
[Epoch 36; Iter   845/ 1097] train: loss: 0.0007949
[Epoch 36; Iter   875/ 1097] train: loss: 0.0009016
[Epoch 36; Iter   905/ 1097] train: loss: 0.0186191
[Epoch 36; Iter   935/ 1097] train: loss: 0.0353196
[Epoch 36; Iter   965/ 1097] train: loss: 0.0141217
[Epoch 36; Iter   995/ 1097] train: loss: 0.0239062
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0051922
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0074031
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0030827
[Epoch 36] ogbg-molhiv: 0.659214 val loss: 1.096645
[Epoch 36] ogbg-molhiv: 0.600386 test loss: 1.244659
[Epoch 37; Iter    18/ 1097] train: loss: 0.0055130
[Epoch 37; Iter    48/ 1097] train: loss: 0.0113057
[Epoch 37; Iter    78/ 1097] train: loss: 0.0005685
[Epoch 37; Iter   108/ 1097] train: loss: 0.0053089
[Epoch 37; Iter   138/ 1097] train: loss: 0.0004567
[Epoch 37; Iter   168/ 1097] train: loss: 0.0145332
[Epoch 37; Iter   198/ 1097] train: loss: 0.0036058
[Epoch 37; Iter   228/ 1097] train: loss: 0.0391376
[Epoch 37; Iter   258/ 1097] train: loss: 0.0350812
[Epoch 37; Iter   288/ 1097] train: loss: 0.0049822
[Epoch 37; Iter   318/ 1097] train: loss: 0.0045659
[Epoch 37; Iter   348/ 1097] train: loss: 0.0001391
[Epoch 37; Iter   378/ 1097] train: loss: 0.0003069
[Epoch 37; Iter   408/ 1097] train: loss: 0.0008532
[Epoch 37; Iter   438/ 1097] train: loss: 0.0056822
[Epoch 37; Iter   468/ 1097] train: loss: 0.0001269
[Epoch 37; Iter   498/ 1097] train: loss: 0.0003947
[Epoch 37; Iter   528/ 1097] train: loss: 0.0225820
[Epoch 37; Iter   558/ 1097] train: loss: 0.0116495
[Epoch 37; Iter   588/ 1097] train: loss: 0.0009255
[Epoch 37; Iter   618/ 1097] train: loss: 0.0082935
[Epoch 37; Iter   648/ 1097] train: loss: 0.0111690
[Epoch 37; Iter   678/ 1097] train: loss: 0.0142643
[Epoch 37; Iter   708/ 1097] train: loss: 0.0015753
[Epoch 37; Iter   738/ 1097] train: loss: 0.1439728
[Epoch 37; Iter   768/ 1097] train: loss: 0.0001434
[Epoch 37; Iter   798/ 1097] train: loss: 0.0134746
[Epoch 37; Iter   828/ 1097] train: loss: 0.0919105
[Epoch 37; Iter   858/ 1097] train: loss: 0.0002172
[Epoch 37; Iter   888/ 1097] train: loss: 0.0000638
[Epoch 37; Iter   918/ 1097] train: loss: 0.0007063
[Epoch 37; Iter   948/ 1097] train: loss: 0.0185557
[Epoch 37; Iter   978/ 1097] train: loss: 0.0235338
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0002720
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0604489
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0112107
[Epoch 37] ogbg-molhiv: 0.647882 val loss: 24.413783
[Epoch 37] ogbg-molhiv: 0.600539 test loss: 32.324021
[Epoch 38; Iter     1/ 1097] train: loss: 0.0224546
[Epoch 38; Iter    31/ 1097] train: loss: 0.0004770
[Epoch 38; Iter    61/ 1097] train: loss: 0.0574833
[Epoch 38; Iter    91/ 1097] train: loss: 0.0012246
[Epoch 38; Iter   121/ 1097] train: loss: 0.0001132
[Epoch 38; Iter   151/ 1097] train: loss: 0.0123788
[Epoch 38; Iter   181/ 1097] train: loss: 0.0036610
[Epoch 38; Iter   211/ 1097] train: loss: 0.0095273
[Epoch 38; Iter   241/ 1097] train: loss: 0.0044299
[Epoch 38; Iter   271/ 1097] train: loss: 0.0034453
[Epoch 38; Iter   301/ 1097] train: loss: 0.0004065
[Epoch 38; Iter   331/ 1097] train: loss: 0.0064041
[Epoch 38; Iter   361/ 1097] train: loss: 0.0013588
[Epoch 38; Iter   391/ 1097] train: loss: 0.0134708
[Epoch 38; Iter   421/ 1097] train: loss: 0.0039389
[Epoch 38; Iter   451/ 1097] train: loss: 0.0006365
[Epoch 38; Iter   481/ 1097] train: loss: 0.0044524
[Epoch 38; Iter   511/ 1097] train: loss: 0.0145915
[Epoch 38; Iter   541/ 1097] train: loss: 0.0022569
[Epoch 38; Iter   571/ 1097] train: loss: 0.0266155
[Epoch 38; Iter   601/ 1097] train: loss: 0.0545381
[Epoch 38; Iter   631/ 1097] train: loss: 0.0010864
[Epoch 38; Iter   661/ 1097] train: loss: 0.0162633
[Epoch 38; Iter   691/ 1097] train: loss: 0.0065750
[Epoch 38; Iter   721/ 1097] train: loss: 0.0004527
[Epoch 38; Iter   751/ 1097] train: loss: 0.0788258
[Epoch 38; Iter   781/ 1097] train: loss: 0.0674725
[Epoch 38; Iter   811/ 1097] train: loss: 0.0264071
[Epoch 38; Iter   841/ 1097] train: loss: 0.0014970
[Epoch 38; Iter   871/ 1097] train: loss: 0.0211696
[Epoch 38; Iter   901/ 1097] train: loss: 0.0007613
[Epoch 38; Iter   931/ 1097] train: loss: 0.0040859
[Epoch 38; Iter   961/ 1097] train: loss: 0.0021156
[Epoch 38; Iter   991/ 1097] train: loss: 0.0032272
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0022381
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0000854
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0301320
[Epoch 38] ogbg-molhiv: 0.726154 val loss: 5.924564
[Epoch 38] ogbg-molhiv: 0.589936 test loss: 8.604241
[Epoch 39; Iter    14/ 1097] train: loss: 0.0015169
[Epoch 39; Iter    44/ 1097] train: loss: 0.0012562
[Epoch 39; Iter    74/ 1097] train: loss: 0.0000365
[Epoch 39; Iter   104/ 1097] train: loss: 0.0024794
[Epoch 39; Iter   134/ 1097] train: loss: 0.0002179
[Epoch 39; Iter   164/ 1097] train: loss: 0.0005333
[Epoch 39; Iter   194/ 1097] train: loss: 0.0006253
[Epoch 39; Iter   224/ 1097] train: loss: 0.0001593
[Epoch 39; Iter   254/ 1097] train: loss: 0.0262806
[Epoch 39; Iter   284/ 1097] train: loss: 0.0000343
[Epoch 39; Iter   314/ 1097] train: loss: 0.0004819
[Epoch 39; Iter   344/ 1097] train: loss: 0.0118798
[Epoch 39; Iter   374/ 1097] train: loss: 0.0003372
[Epoch 39; Iter   404/ 1097] train: loss: 0.0009816
[Epoch 39; Iter   434/ 1097] train: loss: 0.0006155
[Epoch 39; Iter   464/ 1097] train: loss: 0.0017114
[Epoch 39; Iter   494/ 1097] train: loss: 0.0005370
[Epoch 39; Iter   524/ 1097] train: loss: 0.0212315
[Epoch 39; Iter   554/ 1097] train: loss: 0.0134878
[Epoch 39; Iter   584/ 1097] train: loss: 0.0067564
[Epoch 39; Iter   614/ 1097] train: loss: 0.0005580
[Epoch 39; Iter   644/ 1097] train: loss: 0.0176570
[Epoch 39; Iter   674/ 1097] train: loss: 0.0019911
[Epoch 39; Iter   704/ 1097] train: loss: 0.0001387
[Epoch 39; Iter   734/ 1097] train: loss: 0.0043891
[Epoch 39; Iter   764/ 1097] train: loss: 0.0090942
[Epoch 39; Iter   794/ 1097] train: loss: 0.0004633
[Epoch 39; Iter   824/ 1097] train: loss: 0.0051975
[Epoch 39; Iter   854/ 1097] train: loss: 0.0003608
[Epoch 39; Iter   884/ 1097] train: loss: 0.0001845
[Epoch 39; Iter   914/ 1097] train: loss: 0.0054418
[Epoch 39; Iter   944/ 1097] train: loss: 0.0430451
[Epoch 39; Iter   974/ 1097] train: loss: 0.0003130
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0005560
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0004980
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0001010
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0540875
[Epoch 39] ogbg-molhiv: 0.683250 val loss: 10.481095
[Epoch 39] ogbg-molhiv: 0.624209 test loss: 14.159949
[Epoch 40; Iter    27/ 1097] train: loss: 0.0000937
[Epoch 40; Iter    57/ 1097] train: loss: 0.0004099
[Epoch 40; Iter    87/ 1097] train: loss: 0.0038476
[Epoch 40; Iter   117/ 1097] train: loss: 0.0015303
[Epoch 40; Iter   147/ 1097] train: loss: 0.0030364
[Epoch 40; Iter   177/ 1097] train: loss: 0.0001329
[Epoch 40; Iter   207/ 1097] train: loss: 0.0015684
[Epoch 40; Iter   237/ 1097] train: loss: 0.0010143
[Epoch 40; Iter   267/ 1097] train: loss: 0.0013740
[Epoch 40; Iter   297/ 1097] train: loss: 0.0449313
[Epoch 40; Iter   327/ 1097] train: loss: 0.0555813
[Epoch 40; Iter   357/ 1097] train: loss: 0.0027195
[Epoch 40; Iter   387/ 1097] train: loss: 0.0044870
[Epoch 40; Iter   417/ 1097] train: loss: 0.0012892
[Epoch 40; Iter   447/ 1097] train: loss: 0.0096151
[Epoch 40; Iter   477/ 1097] train: loss: 0.0001448
[Epoch 40; Iter   507/ 1097] train: loss: 0.0004020
[Epoch 40; Iter   537/ 1097] train: loss: 0.0009767
[Epoch 40; Iter   567/ 1097] train: loss: 0.0065740
[Epoch 40; Iter   597/ 1097] train: loss: 0.0080976
[Epoch 40; Iter   627/ 1097] train: loss: 0.0014539
[Epoch 40; Iter   657/ 1097] train: loss: 0.0004524
[Epoch 36; Iter   605/ 1097] train: loss: 0.0003710
[Epoch 36; Iter   635/ 1097] train: loss: 0.0018225
[Epoch 36; Iter   665/ 1097] train: loss: 0.0043038
[Epoch 36; Iter   695/ 1097] train: loss: 0.0026319
[Epoch 36; Iter   725/ 1097] train: loss: 0.0001849
[Epoch 36; Iter   755/ 1097] train: loss: 0.0478305
[Epoch 36; Iter   785/ 1097] train: loss: 0.0015112
[Epoch 36; Iter   815/ 1097] train: loss: 0.0006167
[Epoch 36; Iter   845/ 1097] train: loss: 0.0014068
[Epoch 36; Iter   875/ 1097] train: loss: 0.0167166
[Epoch 36; Iter   905/ 1097] train: loss: 0.0008377
[Epoch 36; Iter   935/ 1097] train: loss: 0.1411917
[Epoch 36; Iter   965/ 1097] train: loss: 0.0050292
[Epoch 36; Iter   995/ 1097] train: loss: 0.0012624
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0252698
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0122533
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0015250
[Epoch 36] ogbg-molhiv: 0.748546 val loss: 0.837162
[Epoch 36] ogbg-molhiv: 0.652483 test loss: 0.958148
[Epoch 37; Iter    18/ 1097] train: loss: 0.0021002
[Epoch 37; Iter    48/ 1097] train: loss: 0.1482698
[Epoch 37; Iter    78/ 1097] train: loss: 0.0006590
[Epoch 37; Iter   108/ 1097] train: loss: 0.0261070
[Epoch 37; Iter   138/ 1097] train: loss: 0.0499041
[Epoch 37; Iter   168/ 1097] train: loss: 0.0009835
[Epoch 37; Iter   198/ 1097] train: loss: 0.0016878
[Epoch 37; Iter   228/ 1097] train: loss: 0.0016831
[Epoch 37; Iter   258/ 1097] train: loss: 0.0008125
[Epoch 37; Iter   288/ 1097] train: loss: 0.0007310
[Epoch 37; Iter   318/ 1097] train: loss: 0.0074716
[Epoch 37; Iter   348/ 1097] train: loss: 0.0245694
[Epoch 37; Iter   378/ 1097] train: loss: 0.0369937
[Epoch 37; Iter   408/ 1097] train: loss: 0.0004761
[Epoch 37; Iter   438/ 1097] train: loss: 0.0037478
[Epoch 37; Iter   468/ 1097] train: loss: 0.0018377
[Epoch 37; Iter   498/ 1097] train: loss: 0.0003047
[Epoch 37; Iter   528/ 1097] train: loss: 0.0008631
[Epoch 37; Iter   558/ 1097] train: loss: 0.0128840
[Epoch 37; Iter   588/ 1097] train: loss: 0.0032382
[Epoch 37; Iter   618/ 1097] train: loss: 0.1219493
[Epoch 37; Iter   648/ 1097] train: loss: 0.0011268
[Epoch 37; Iter   678/ 1097] train: loss: 0.0025011
[Epoch 37; Iter   708/ 1097] train: loss: 0.0249366
[Epoch 37; Iter   738/ 1097] train: loss: 0.0090531
[Epoch 37; Iter   768/ 1097] train: loss: 0.0016362
[Epoch 37; Iter   798/ 1097] train: loss: 0.0857093
[Epoch 37; Iter   828/ 1097] train: loss: 0.0048141
[Epoch 37; Iter   858/ 1097] train: loss: 0.0758125
[Epoch 37; Iter   888/ 1097] train: loss: 0.0019578
[Epoch 37; Iter   918/ 1097] train: loss: 0.0013523
[Epoch 37; Iter   948/ 1097] train: loss: 0.0052105
[Epoch 37; Iter   978/ 1097] train: loss: 0.0014403
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0014168
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0187290
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0009420
[Epoch 37] ogbg-molhiv: 0.695320 val loss: 36.973372
[Epoch 37] ogbg-molhiv: 0.617721 test loss: 37.093340
[Epoch 38; Iter     1/ 1097] train: loss: 0.0263327
[Epoch 38; Iter    31/ 1097] train: loss: 0.0136617
[Epoch 38; Iter    61/ 1097] train: loss: 0.0010688
[Epoch 38; Iter    91/ 1097] train: loss: 0.0109690
[Epoch 38; Iter   121/ 1097] train: loss: 0.0124992
[Epoch 38; Iter   151/ 1097] train: loss: 0.0094686
[Epoch 38; Iter   181/ 1097] train: loss: 0.0001864
[Epoch 38; Iter   211/ 1097] train: loss: 0.0024275
[Epoch 38; Iter   241/ 1097] train: loss: 0.0360806
[Epoch 38; Iter   271/ 1097] train: loss: 0.0023817
[Epoch 38; Iter   301/ 1097] train: loss: 0.0036267
[Epoch 38; Iter   331/ 1097] train: loss: 0.0038064
[Epoch 38; Iter   361/ 1097] train: loss: 0.0009990
[Epoch 38; Iter   391/ 1097] train: loss: 0.0075477
[Epoch 38; Iter   421/ 1097] train: loss: 0.0031121
[Epoch 38; Iter   451/ 1097] train: loss: 0.0016850
[Epoch 38; Iter   481/ 1097] train: loss: 0.0011027
[Epoch 38; Iter   511/ 1097] train: loss: 0.0021080
[Epoch 38; Iter   541/ 1097] train: loss: 0.0004151
[Epoch 38; Iter   571/ 1097] train: loss: 0.0012630
[Epoch 38; Iter   601/ 1097] train: loss: 0.0077964
[Epoch 38; Iter   631/ 1097] train: loss: 0.0088418
[Epoch 38; Iter   661/ 1097] train: loss: 0.0135782
[Epoch 38; Iter   691/ 1097] train: loss: 0.0001356
[Epoch 38; Iter   721/ 1097] train: loss: 0.0022524
[Epoch 38; Iter   751/ 1097] train: loss: 0.0404829
[Epoch 38; Iter   781/ 1097] train: loss: 0.0348799
[Epoch 38; Iter   811/ 1097] train: loss: 0.0071307
[Epoch 38; Iter   841/ 1097] train: loss: 0.0016973
[Epoch 38; Iter   871/ 1097] train: loss: 0.0043386
[Epoch 38; Iter   901/ 1097] train: loss: 0.0012494
[Epoch 38; Iter   931/ 1097] train: loss: 0.0013260
[Epoch 38; Iter   961/ 1097] train: loss: 0.0006546
[Epoch 38; Iter   991/ 1097] train: loss: 0.0083958
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0009259
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0010247
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0803540
[Epoch 38] ogbg-molhiv: 0.676428 val loss: 70.075378
[Epoch 38] ogbg-molhiv: 0.581296 test loss: 68.884676
[Epoch 39; Iter    14/ 1097] train: loss: 0.0145868
[Epoch 39; Iter    44/ 1097] train: loss: 0.0020564
[Epoch 39; Iter    74/ 1097] train: loss: 0.0040137
[Epoch 39; Iter   104/ 1097] train: loss: 0.0026092
[Epoch 39; Iter   134/ 1097] train: loss: 0.0047845
[Epoch 39; Iter   164/ 1097] train: loss: 0.0047030
[Epoch 39; Iter   194/ 1097] train: loss: 0.0519088
[Epoch 39; Iter   224/ 1097] train: loss: 0.0020101
[Epoch 39; Iter   254/ 1097] train: loss: 0.0058644
[Epoch 39; Iter   284/ 1097] train: loss: 0.0009895
[Epoch 39; Iter   314/ 1097] train: loss: 0.0003202
[Epoch 39; Iter   344/ 1097] train: loss: 0.0200066
[Epoch 39; Iter   374/ 1097] train: loss: 0.0089264
[Epoch 39; Iter   404/ 1097] train: loss: 0.0052214
[Epoch 39; Iter   434/ 1097] train: loss: 0.0028941
[Epoch 39; Iter   464/ 1097] train: loss: 0.0150733
[Epoch 39; Iter   494/ 1097] train: loss: 0.0032707
[Epoch 39; Iter   524/ 1097] train: loss: 0.0224209
[Epoch 39; Iter   554/ 1097] train: loss: 0.0004046
[Epoch 39; Iter   584/ 1097] train: loss: 0.0015782
[Epoch 39; Iter   614/ 1097] train: loss: 0.0491337
[Epoch 39; Iter   644/ 1097] train: loss: 0.0006249
[Epoch 39; Iter   674/ 1097] train: loss: 0.0130908
[Epoch 39; Iter   704/ 1097] train: loss: 0.0091123
[Epoch 39; Iter   734/ 1097] train: loss: 0.0049756
[Epoch 39; Iter   764/ 1097] train: loss: 0.0058602
[Epoch 39; Iter   794/ 1097] train: loss: 0.0110416
[Epoch 39; Iter   824/ 1097] train: loss: 0.0006852
[Epoch 39; Iter   854/ 1097] train: loss: 0.0075971
[Epoch 39; Iter   884/ 1097] train: loss: 0.0007191
[Epoch 39; Iter   914/ 1097] train: loss: 0.0025116
[Epoch 39; Iter   944/ 1097] train: loss: 0.0393272
[Epoch 39; Iter   974/ 1097] train: loss: 0.0024907
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0015239
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0006214
[Epoch 39; Iter  1064/ 1097] train: loss: 0.1057333
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0120101
[Epoch 39] ogbg-molhiv: 0.738677 val loss: 0.320391
[Epoch 39] ogbg-molhiv: 0.666753 test loss: 0.396010
[Epoch 40; Iter    27/ 1097] train: loss: 0.0081440
[Epoch 40; Iter    57/ 1097] train: loss: 0.0017174
[Epoch 40; Iter    87/ 1097] train: loss: 0.0263692
[Epoch 40; Iter   117/ 1097] train: loss: 0.0007879
[Epoch 40; Iter   147/ 1097] train: loss: 0.0000804
[Epoch 40; Iter   177/ 1097] train: loss: 0.0004251
[Epoch 40; Iter   207/ 1097] train: loss: 0.0712622
[Epoch 40; Iter   237/ 1097] train: loss: 0.0026981
[Epoch 40; Iter   267/ 1097] train: loss: 0.0027235
[Epoch 40; Iter   297/ 1097] train: loss: 0.0005605
[Epoch 40; Iter   327/ 1097] train: loss: 0.0284553
[Epoch 40; Iter   357/ 1097] train: loss: 0.0003092
[Epoch 40; Iter   387/ 1097] train: loss: 0.0008974
[Epoch 40; Iter   417/ 1097] train: loss: 0.0040453
[Epoch 40; Iter   447/ 1097] train: loss: 0.0105740
[Epoch 40; Iter   477/ 1097] train: loss: 0.0031673
[Epoch 40; Iter   507/ 1097] train: loss: 0.0010039
[Epoch 40; Iter   537/ 1097] train: loss: 0.0186437
[Epoch 40; Iter   567/ 1097] train: loss: 0.0008584
[Epoch 40; Iter   597/ 1097] train: loss: 0.0089209
[Epoch 40; Iter   627/ 1097] train: loss: 0.0063255
[Epoch 40; Iter   657/ 1097] train: loss: 0.0113154
[Epoch 32; Iter   523/ 1097] train: loss: 0.0312136
[Epoch 32; Iter   553/ 1097] train: loss: 0.0735450
[Epoch 32; Iter   583/ 1097] train: loss: 0.0845584
[Epoch 32; Iter   613/ 1097] train: loss: 0.2556951
[Epoch 32; Iter   643/ 1097] train: loss: 0.0310427
[Epoch 32; Iter   673/ 1097] train: loss: 0.0148550
[Epoch 32; Iter   703/ 1097] train: loss: 0.1460199
[Epoch 32; Iter   733/ 1097] train: loss: 0.0221098
[Epoch 32; Iter   763/ 1097] train: loss: 0.0205542
[Epoch 32; Iter   793/ 1097] train: loss: 0.2241954
[Epoch 32; Iter   823/ 1097] train: loss: 0.1444428
[Epoch 32; Iter   853/ 1097] train: loss: 0.0134049
[Epoch 32; Iter   883/ 1097] train: loss: 0.0126477
[Epoch 32; Iter   913/ 1097] train: loss: 0.0250732
[Epoch 32; Iter   943/ 1097] train: loss: 0.0459630
[Epoch 32; Iter   973/ 1097] train: loss: 0.1123497
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0153251
[Epoch 32; Iter  1033/ 1097] train: loss: 0.1507233
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1205691
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0140394
[Epoch 32] ogbg-molhiv: 0.835452 val loss: 0.071699
[Epoch 32] ogbg-molhiv: 0.770546 test loss: 0.146712
[Epoch 33; Iter    26/ 1097] train: loss: 0.0347877
[Epoch 33; Iter    56/ 1097] train: loss: 0.0611885
[Epoch 33; Iter    86/ 1097] train: loss: 0.0185744
[Epoch 33; Iter   116/ 1097] train: loss: 0.0223232
[Epoch 33; Iter   146/ 1097] train: loss: 0.0169788
[Epoch 33; Iter   176/ 1097] train: loss: 0.0648924
[Epoch 33; Iter   206/ 1097] train: loss: 0.2174364
[Epoch 33; Iter   236/ 1097] train: loss: 0.0267697
[Epoch 33; Iter   266/ 1097] train: loss: 0.1634810
[Epoch 33; Iter   296/ 1097] train: loss: 0.0362672
[Epoch 33; Iter   326/ 1097] train: loss: 0.0745302
[Epoch 33; Iter   356/ 1097] train: loss: 0.0378048
[Epoch 33; Iter   386/ 1097] train: loss: 0.2630277
[Epoch 33; Iter   416/ 1097] train: loss: 0.1674862
[Epoch 33; Iter   446/ 1097] train: loss: 0.0132511
[Epoch 33; Iter   476/ 1097] train: loss: 0.1162212
[Epoch 33; Iter   506/ 1097] train: loss: 0.0467611
[Epoch 33; Iter   536/ 1097] train: loss: 0.0209346
[Epoch 33; Iter   566/ 1097] train: loss: 0.0249986
[Epoch 33; Iter   596/ 1097] train: loss: 0.0189607
[Epoch 33; Iter   626/ 1097] train: loss: 0.0135328
[Epoch 33; Iter   656/ 1097] train: loss: 0.2318566
[Epoch 33; Iter   686/ 1097] train: loss: 0.0213998
[Epoch 33; Iter   716/ 1097] train: loss: 0.0689144
[Epoch 33; Iter   746/ 1097] train: loss: 0.0255289
[Epoch 33; Iter   776/ 1097] train: loss: 0.0267613
[Epoch 33; Iter   806/ 1097] train: loss: 0.0596848
[Epoch 33; Iter   836/ 1097] train: loss: 0.0278697
[Epoch 33; Iter   866/ 1097] train: loss: 0.0514735
[Epoch 33; Iter   896/ 1097] train: loss: 0.1261906
[Epoch 33; Iter   926/ 1097] train: loss: 0.0412746
[Epoch 33; Iter   956/ 1097] train: loss: 0.0103133
[Epoch 33; Iter   986/ 1097] train: loss: 0.0493805
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0150343
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1517335
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0445572
[Epoch 33] ogbg-molhiv: 0.817561 val loss: 0.075606
[Epoch 33] ogbg-molhiv: 0.749327 test loss: 0.198537
[Epoch 34; Iter     9/ 1097] train: loss: 0.0411920
[Epoch 34; Iter    39/ 1097] train: loss: 0.1513771
[Epoch 34; Iter    69/ 1097] train: loss: 0.0427619
[Epoch 34; Iter    99/ 1097] train: loss: 0.0290226
[Epoch 34; Iter   129/ 1097] train: loss: 0.1329291
[Epoch 34; Iter   159/ 1097] train: loss: 0.0154757
[Epoch 34; Iter   189/ 1097] train: loss: 0.1573637
[Epoch 34; Iter   219/ 1097] train: loss: 0.0820225
[Epoch 34; Iter   249/ 1097] train: loss: 0.0612155
[Epoch 34; Iter   279/ 1097] train: loss: 0.3524624
[Epoch 34; Iter   309/ 1097] train: loss: 0.0357213
[Epoch 34; Iter   339/ 1097] train: loss: 0.0603825
[Epoch 34; Iter   369/ 1097] train: loss: 0.0112736
[Epoch 34; Iter   399/ 1097] train: loss: 0.0235330
[Epoch 34; Iter   429/ 1097] train: loss: 0.0415339
[Epoch 34; Iter   459/ 1097] train: loss: 0.1128485
[Epoch 34; Iter   489/ 1097] train: loss: 0.0207304
[Epoch 34; Iter   519/ 1097] train: loss: 0.0160734
[Epoch 34; Iter   549/ 1097] train: loss: 0.2528614
[Epoch 34; Iter   579/ 1097] train: loss: 0.0157951
[Epoch 34; Iter   609/ 1097] train: loss: 0.0540773
[Epoch 34; Iter   639/ 1097] train: loss: 0.0159552
[Epoch 34; Iter   669/ 1097] train: loss: 0.0409124
[Epoch 34; Iter   699/ 1097] train: loss: 0.1743929
[Epoch 34; Iter   729/ 1097] train: loss: 0.2774936
[Epoch 34; Iter   759/ 1097] train: loss: 0.1041106
[Epoch 34; Iter   789/ 1097] train: loss: 0.0301114
[Epoch 34; Iter   819/ 1097] train: loss: 0.0619169
[Epoch 34; Iter   849/ 1097] train: loss: 0.0113570
[Epoch 34; Iter   879/ 1097] train: loss: 0.0541635
[Epoch 34; Iter   909/ 1097] train: loss: 0.0118441
[Epoch 34; Iter   939/ 1097] train: loss: 0.0215152
[Epoch 34; Iter   969/ 1097] train: loss: 0.0911812
[Epoch 34; Iter   999/ 1097] train: loss: 0.0260215
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1948146
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0182392
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0106496
[Epoch 34] ogbg-molhiv: 0.820060 val loss: 0.097168
[Epoch 34] ogbg-molhiv: 0.761801 test loss: 0.195836
[Epoch 35; Iter    22/ 1097] train: loss: 0.0127894
[Epoch 35; Iter    52/ 1097] train: loss: 0.0179713
[Epoch 35; Iter    82/ 1097] train: loss: 0.0502151
[Epoch 35; Iter   112/ 1097] train: loss: 0.1211134
[Epoch 35; Iter   142/ 1097] train: loss: 0.0267956
[Epoch 35; Iter   172/ 1097] train: loss: 0.0399199
[Epoch 35; Iter   202/ 1097] train: loss: 0.1326829
[Epoch 35; Iter   232/ 1097] train: loss: 0.3794033
[Epoch 35; Iter   262/ 1097] train: loss: 0.0920505
[Epoch 35; Iter   292/ 1097] train: loss: 0.0938903
[Epoch 35; Iter   322/ 1097] train: loss: 0.1181796
[Epoch 35; Iter   352/ 1097] train: loss: 0.0411587
[Epoch 35; Iter   382/ 1097] train: loss: 0.0350978
[Epoch 35; Iter   412/ 1097] train: loss: 0.0276058
[Epoch 35; Iter   442/ 1097] train: loss: 0.1283752
[Epoch 35; Iter   472/ 1097] train: loss: 0.0155967
[Epoch 35; Iter   502/ 1097] train: loss: 0.1885850
[Epoch 35; Iter   532/ 1097] train: loss: 0.0894430
[Epoch 35; Iter   562/ 1097] train: loss: 0.0350164
[Epoch 35; Iter   592/ 1097] train: loss: 0.0152147
[Epoch 35; Iter   622/ 1097] train: loss: 0.0473987
[Epoch 35; Iter   652/ 1097] train: loss: 0.0666534
[Epoch 35; Iter   682/ 1097] train: loss: 0.0432187
[Epoch 35; Iter   712/ 1097] train: loss: 0.1168531
[Epoch 35; Iter   742/ 1097] train: loss: 0.0498544
[Epoch 35; Iter   772/ 1097] train: loss: 0.0609549
[Epoch 35; Iter   802/ 1097] train: loss: 0.0465151
[Epoch 35; Iter   832/ 1097] train: loss: 0.0766298
[Epoch 35; Iter   862/ 1097] train: loss: 0.1055236
[Epoch 35; Iter   892/ 1097] train: loss: 0.0389410
[Epoch 35; Iter   922/ 1097] train: loss: 0.1368633
[Epoch 35; Iter   952/ 1097] train: loss: 0.0771165
[Epoch 35; Iter   982/ 1097] train: loss: 0.1396442
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0909305
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0146526
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0213414
[Epoch 35] ogbg-molhiv: 0.809132 val loss: 0.082565
[Epoch 35] ogbg-molhiv: 0.777906 test loss: 0.153910
[Epoch 36; Iter     5/ 1097] train: loss: 0.1416087
[Epoch 36; Iter    35/ 1097] train: loss: 0.0342615
[Epoch 36; Iter    65/ 1097] train: loss: 0.0185671
[Epoch 36; Iter    95/ 1097] train: loss: 0.0556423
[Epoch 36; Iter   125/ 1097] train: loss: 0.0335861
[Epoch 36; Iter   155/ 1097] train: loss: 0.0201360
[Epoch 36; Iter   185/ 1097] train: loss: 0.0234570
[Epoch 36; Iter   215/ 1097] train: loss: 0.3305305
[Epoch 36; Iter   245/ 1097] train: loss: 0.0658855
[Epoch 36; Iter   275/ 1097] train: loss: 0.0223014
[Epoch 36; Iter   305/ 1097] train: loss: 0.2954836
[Epoch 36; Iter   335/ 1097] train: loss: 0.0862762
[Epoch 36; Iter   365/ 1097] train: loss: 0.0232721
[Epoch 36; Iter   395/ 1097] train: loss: 0.0580374
[Epoch 36; Iter   425/ 1097] train: loss: 0.2168231
[Epoch 36; Iter   455/ 1097] train: loss: 0.1220688
[Epoch 36; Iter   485/ 1097] train: loss: 0.0197874
[Epoch 36; Iter   515/ 1097] train: loss: 0.0776137
[Epoch 36; Iter   545/ 1097] train: loss: 0.0484476
[Epoch 36; Iter   575/ 1097] train: loss: 0.0271202
[Epoch 32; Iter   523/ 1097] train: loss: 0.0244442
[Epoch 32; Iter   553/ 1097] train: loss: 0.0191407
[Epoch 32; Iter   583/ 1097] train: loss: 0.1224096
[Epoch 32; Iter   613/ 1097] train: loss: 0.0158361
[Epoch 32; Iter   643/ 1097] train: loss: 0.0256537
[Epoch 32; Iter   673/ 1097] train: loss: 0.3594406
[Epoch 32; Iter   703/ 1097] train: loss: 0.0315392
[Epoch 32; Iter   733/ 1097] train: loss: 0.0123054
[Epoch 32; Iter   763/ 1097] train: loss: 0.0882699
[Epoch 32; Iter   793/ 1097] train: loss: 0.0212097
[Epoch 32; Iter   823/ 1097] train: loss: 0.0358904
[Epoch 32; Iter   853/ 1097] train: loss: 0.0188784
[Epoch 32; Iter   883/ 1097] train: loss: 0.0248343
[Epoch 32; Iter   913/ 1097] train: loss: 0.0746880
[Epoch 32; Iter   943/ 1097] train: loss: 0.2063127
[Epoch 32; Iter   973/ 1097] train: loss: 0.0258625
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0522166
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0344134
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1706448
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0960371
[Epoch 32] ogbg-molhiv: 0.817307 val loss: 0.085004
[Epoch 32] ogbg-molhiv: 0.746169 test loss: 0.130461
[Epoch 33; Iter    26/ 1097] train: loss: 0.0333868
[Epoch 33; Iter    56/ 1097] train: loss: 0.1690388
[Epoch 33; Iter    86/ 1097] train: loss: 0.0492220
[Epoch 33; Iter   116/ 1097] train: loss: 0.2923146
[Epoch 33; Iter   146/ 1097] train: loss: 0.0320465
[Epoch 33; Iter   176/ 1097] train: loss: 0.0274465
[Epoch 33; Iter   206/ 1097] train: loss: 0.0151743
[Epoch 33; Iter   236/ 1097] train: loss: 0.2041631
[Epoch 33; Iter   266/ 1097] train: loss: 0.0251861
[Epoch 33; Iter   296/ 1097] train: loss: 0.1443231
[Epoch 33; Iter   326/ 1097] train: loss: 0.2466724
[Epoch 33; Iter   356/ 1097] train: loss: 0.2223406
[Epoch 33; Iter   386/ 1097] train: loss: 0.0342997
[Epoch 33; Iter   416/ 1097] train: loss: 0.0337444
[Epoch 33; Iter   446/ 1097] train: loss: 0.0278481
[Epoch 33; Iter   476/ 1097] train: loss: 0.1023336
[Epoch 33; Iter   506/ 1097] train: loss: 0.1757800
[Epoch 33; Iter   536/ 1097] train: loss: 0.0595613
[Epoch 33; Iter   566/ 1097] train: loss: 0.0152397
[Epoch 33; Iter   596/ 1097] train: loss: 0.0772547
[Epoch 33; Iter   626/ 1097] train: loss: 0.0658021
[Epoch 33; Iter   656/ 1097] train: loss: 0.0286530
[Epoch 33; Iter   686/ 1097] train: loss: 0.0199190
[Epoch 33; Iter   716/ 1097] train: loss: 0.0378052
[Epoch 33; Iter   746/ 1097] train: loss: 0.0121960
[Epoch 33; Iter   776/ 1097] train: loss: 0.1519718
[Epoch 33; Iter   806/ 1097] train: loss: 0.0954526
[Epoch 33; Iter   836/ 1097] train: loss: 0.0276985
[Epoch 33; Iter   866/ 1097] train: loss: 0.0613411
[Epoch 33; Iter   896/ 1097] train: loss: 0.0585024
[Epoch 33; Iter   926/ 1097] train: loss: 0.0422330
[Epoch 33; Iter   956/ 1097] train: loss: 0.0153742
[Epoch 33; Iter   986/ 1097] train: loss: 0.0308480
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0166300
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0563826
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2967094
[Epoch 33] ogbg-molhiv: 0.796110 val loss: 0.079074
[Epoch 33] ogbg-molhiv: 0.734647 test loss: 0.133528
[Epoch 34; Iter     9/ 1097] train: loss: 0.0214075
[Epoch 34; Iter    39/ 1097] train: loss: 0.0703722
[Epoch 34; Iter    69/ 1097] train: loss: 0.0217170
[Epoch 34; Iter    99/ 1097] train: loss: 0.0372777
[Epoch 34; Iter   129/ 1097] train: loss: 0.1047098
[Epoch 34; Iter   159/ 1097] train: loss: 0.0317266
[Epoch 34; Iter   189/ 1097] train: loss: 0.1441084
[Epoch 34; Iter   219/ 1097] train: loss: 0.0086118
[Epoch 34; Iter   249/ 1097] train: loss: 0.0287867
[Epoch 34; Iter   279/ 1097] train: loss: 0.0594442
[Epoch 34; Iter   309/ 1097] train: loss: 0.0275464
[Epoch 34; Iter   339/ 1097] train: loss: 0.1318319
[Epoch 34; Iter   369/ 1097] train: loss: 0.1661984
[Epoch 34; Iter   399/ 1097] train: loss: 0.1187531
[Epoch 34; Iter   429/ 1097] train: loss: 0.0166593
[Epoch 34; Iter   459/ 1097] train: loss: 0.1450536
[Epoch 34; Iter   489/ 1097] train: loss: 0.0129605
[Epoch 34; Iter   519/ 1097] train: loss: 0.0216160
[Epoch 34; Iter   549/ 1097] train: loss: 0.0535846
[Epoch 34; Iter   579/ 1097] train: loss: 0.1568360
[Epoch 34; Iter   609/ 1097] train: loss: 0.0271306
[Epoch 34; Iter   639/ 1097] train: loss: 0.2008233
[Epoch 34; Iter   669/ 1097] train: loss: 0.0161512
[Epoch 34; Iter   699/ 1097] train: loss: 0.0172579
[Epoch 34; Iter   729/ 1097] train: loss: 0.2728055
[Epoch 34; Iter   759/ 1097] train: loss: 0.0213962
[Epoch 34; Iter   789/ 1097] train: loss: 0.0351915
[Epoch 34; Iter   819/ 1097] train: loss: 0.1836495
[Epoch 34; Iter   849/ 1097] train: loss: 0.0438190
[Epoch 34; Iter   879/ 1097] train: loss: 0.2624631
[Epoch 34; Iter   909/ 1097] train: loss: 0.0719336
[Epoch 34; Iter   939/ 1097] train: loss: 0.1819040
[Epoch 34; Iter   969/ 1097] train: loss: 0.0175626
[Epoch 34; Iter   999/ 1097] train: loss: 0.0214503
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0183404
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0207153
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0193706
[Epoch 34] ogbg-molhiv: 0.822451 val loss: 0.079924
[Epoch 34] ogbg-molhiv: 0.722355 test loss: 0.133756
[Epoch 35; Iter    22/ 1097] train: loss: 0.0242092
[Epoch 35; Iter    52/ 1097] train: loss: 0.0484629
[Epoch 35; Iter    82/ 1097] train: loss: 0.1736204
[Epoch 35; Iter   112/ 1097] train: loss: 0.0617108
[Epoch 35; Iter   142/ 1097] train: loss: 0.0104443
[Epoch 35; Iter   172/ 1097] train: loss: 0.0656001
[Epoch 35; Iter   202/ 1097] train: loss: 0.0166386
[Epoch 35; Iter   232/ 1097] train: loss: 0.0435014
[Epoch 35; Iter   262/ 1097] train: loss: 0.0078539
[Epoch 35; Iter   292/ 1097] train: loss: 0.0139425
[Epoch 35; Iter   322/ 1097] train: loss: 0.1617817
[Epoch 35; Iter   352/ 1097] train: loss: 0.3621528
[Epoch 35; Iter   382/ 1097] train: loss: 0.1095566
[Epoch 35; Iter   412/ 1097] train: loss: 0.1399170
[Epoch 35; Iter   442/ 1097] train: loss: 0.0481693
[Epoch 35; Iter   472/ 1097] train: loss: 0.0341660
[Epoch 35; Iter   502/ 1097] train: loss: 0.0369878
[Epoch 35; Iter   532/ 1097] train: loss: 0.1730506
[Epoch 35; Iter   562/ 1097] train: loss: 0.1937367
[Epoch 35; Iter   592/ 1097] train: loss: 0.0204270
[Epoch 35; Iter   622/ 1097] train: loss: 0.2784890
[Epoch 35; Iter   652/ 1097] train: loss: 0.1712862
[Epoch 35; Iter   682/ 1097] train: loss: 0.0565234
[Epoch 35; Iter   712/ 1097] train: loss: 0.1163177
[Epoch 35; Iter   742/ 1097] train: loss: 0.0616391
[Epoch 35; Iter   772/ 1097] train: loss: 0.0729088
[Epoch 35; Iter   802/ 1097] train: loss: 0.0909546
[Epoch 35; Iter   832/ 1097] train: loss: 0.0847075
[Epoch 35; Iter   862/ 1097] train: loss: 0.0461214
[Epoch 35; Iter   892/ 1097] train: loss: 0.0132034
[Epoch 35; Iter   922/ 1097] train: loss: 0.0302087
[Epoch 35; Iter   952/ 1097] train: loss: 0.0775725
[Epoch 35; Iter   982/ 1097] train: loss: 0.1336696
[Epoch 35; Iter  1012/ 1097] train: loss: 0.1467990
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1123180
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0218915
[Epoch 35] ogbg-molhiv: 0.811731 val loss: 0.080903
[Epoch 35] ogbg-molhiv: 0.737370 test loss: 0.131788
[Epoch 36; Iter     5/ 1097] train: loss: 0.0115549
[Epoch 36; Iter    35/ 1097] train: loss: 0.0430178
[Epoch 36; Iter    65/ 1097] train: loss: 0.0540201
[Epoch 36; Iter    95/ 1097] train: loss: 0.0121298
[Epoch 36; Iter   125/ 1097] train: loss: 0.2352476
[Epoch 36; Iter   155/ 1097] train: loss: 0.0789571
[Epoch 36; Iter   185/ 1097] train: loss: 0.0444951
[Epoch 36; Iter   215/ 1097] train: loss: 0.1140846
[Epoch 36; Iter   245/ 1097] train: loss: 0.0990119
[Epoch 36; Iter   275/ 1097] train: loss: 0.2075300
[Epoch 36; Iter   305/ 1097] train: loss: 0.1616252
[Epoch 36; Iter   335/ 1097] train: loss: 0.0367774
[Epoch 36; Iter   365/ 1097] train: loss: 0.0532028
[Epoch 36; Iter   395/ 1097] train: loss: 0.0291137
[Epoch 36; Iter   425/ 1097] train: loss: 0.0318783
[Epoch 36; Iter   455/ 1097] train: loss: 0.0130509
[Epoch 36; Iter   485/ 1097] train: loss: 0.0973784
[Epoch 36; Iter   515/ 1097] train: loss: 0.0755134
[Epoch 36; Iter   545/ 1097] train: loss: 0.1814952
[Epoch 36; Iter   575/ 1097] train: loss: 0.0285451
[Epoch 32; Iter   523/ 1097] train: loss: 0.2657543
[Epoch 32; Iter   553/ 1097] train: loss: 0.0322970
[Epoch 32; Iter   583/ 1097] train: loss: 0.2596723
[Epoch 32; Iter   613/ 1097] train: loss: 0.0176590
[Epoch 32; Iter   643/ 1097] train: loss: 0.2988278
[Epoch 32; Iter   673/ 1097] train: loss: 0.1780448
[Epoch 32; Iter   703/ 1097] train: loss: 0.1476318
[Epoch 32; Iter   733/ 1097] train: loss: 0.0476526
[Epoch 32; Iter   763/ 1097] train: loss: 0.0384830
[Epoch 32; Iter   793/ 1097] train: loss: 0.1942885
[Epoch 32; Iter   823/ 1097] train: loss: 0.0842130
[Epoch 32; Iter   853/ 1097] train: loss: 0.0375896
[Epoch 32; Iter   883/ 1097] train: loss: 0.0727277
[Epoch 32; Iter   913/ 1097] train: loss: 0.2029255
[Epoch 32; Iter   943/ 1097] train: loss: 0.0174456
[Epoch 32; Iter   973/ 1097] train: loss: 0.0223913
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1792302
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0496578
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0521865
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0367823
[Epoch 32] ogbg-molhiv: 0.829313 val loss: 0.069363
[Epoch 32] ogbg-molhiv: 0.758854 test loss: 0.121773
[Epoch 33; Iter    26/ 1097] train: loss: 0.1160114
[Epoch 33; Iter    56/ 1097] train: loss: 0.0412840
[Epoch 33; Iter    86/ 1097] train: loss: 0.0211258
[Epoch 33; Iter   116/ 1097] train: loss: 0.1380905
[Epoch 33; Iter   146/ 1097] train: loss: 0.0538605
[Epoch 33; Iter   176/ 1097] train: loss: 0.0327321
[Epoch 33; Iter   206/ 1097] train: loss: 0.0750211
[Epoch 33; Iter   236/ 1097] train: loss: 0.1072454
[Epoch 33; Iter   266/ 1097] train: loss: 0.0142391
[Epoch 33; Iter   296/ 1097] train: loss: 0.1820681
[Epoch 33; Iter   326/ 1097] train: loss: 0.1667930
[Epoch 33; Iter   356/ 1097] train: loss: 0.3500372
[Epoch 33; Iter   386/ 1097] train: loss: 0.0404717
[Epoch 33; Iter   416/ 1097] train: loss: 0.0226553
[Epoch 33; Iter   446/ 1097] train: loss: 0.0162054
[Epoch 33; Iter   476/ 1097] train: loss: 0.0256305
[Epoch 33; Iter   506/ 1097] train: loss: 0.0441829
[Epoch 33; Iter   536/ 1097] train: loss: 0.0792694
[Epoch 33; Iter   566/ 1097] train: loss: 0.0975503
[Epoch 33; Iter   596/ 1097] train: loss: 0.1381121
[Epoch 33; Iter   626/ 1097] train: loss: 0.0883127
[Epoch 33; Iter   656/ 1097] train: loss: 0.0220381
[Epoch 33; Iter   686/ 1097] train: loss: 0.0339606
[Epoch 33; Iter   716/ 1097] train: loss: 0.5597972
[Epoch 33; Iter   746/ 1097] train: loss: 0.1280227
[Epoch 33; Iter   776/ 1097] train: loss: 0.3466153
[Epoch 33; Iter   806/ 1097] train: loss: 0.0795023
[Epoch 33; Iter   836/ 1097] train: loss: 0.0441951
[Epoch 33; Iter   866/ 1097] train: loss: 0.1085914
[Epoch 33; Iter   896/ 1097] train: loss: 0.0270950
[Epoch 33; Iter   926/ 1097] train: loss: 0.1533280
[Epoch 33; Iter   956/ 1097] train: loss: 0.0383344
[Epoch 33; Iter   986/ 1097] train: loss: 0.2386112
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0726099
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0368469
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2074537
[Epoch 33] ogbg-molhiv: 0.855309 val loss: 0.072332
[Epoch 33] ogbg-molhiv: 0.760200 test loss: 0.122799
[Epoch 34; Iter     9/ 1097] train: loss: 0.0321055
[Epoch 34; Iter    39/ 1097] train: loss: 0.1004504
[Epoch 34; Iter    69/ 1097] train: loss: 0.0293484
[Epoch 34; Iter    99/ 1097] train: loss: 0.1204840
[Epoch 34; Iter   129/ 1097] train: loss: 0.0230459
[Epoch 34; Iter   159/ 1097] train: loss: 0.0430342
[Epoch 34; Iter   189/ 1097] train: loss: 0.0232263
[Epoch 34; Iter   219/ 1097] train: loss: 0.0409227
[Epoch 34; Iter   249/ 1097] train: loss: 0.1138022
[Epoch 34; Iter   279/ 1097] train: loss: 0.1031785
[Epoch 34; Iter   309/ 1097] train: loss: 0.0385329
[Epoch 34; Iter   339/ 1097] train: loss: 0.1210148
[Epoch 34; Iter   369/ 1097] train: loss: 0.0574152
[Epoch 34; Iter   399/ 1097] train: loss: 0.0277685
[Epoch 34; Iter   429/ 1097] train: loss: 0.0234318
[Epoch 34; Iter   459/ 1097] train: loss: 0.0533051
[Epoch 34; Iter   489/ 1097] train: loss: 0.0464982
[Epoch 34; Iter   519/ 1097] train: loss: 0.0210489
[Epoch 34; Iter   549/ 1097] train: loss: 0.0197189
[Epoch 34; Iter   579/ 1097] train: loss: 0.1865606
[Epoch 34; Iter   609/ 1097] train: loss: 0.0266600
[Epoch 34; Iter   639/ 1097] train: loss: 0.1032903
[Epoch 34; Iter   669/ 1097] train: loss: 0.1199203
[Epoch 34; Iter   699/ 1097] train: loss: 0.1398147
[Epoch 34; Iter   729/ 1097] train: loss: 0.0100582
[Epoch 34; Iter   759/ 1097] train: loss: 0.3729761
[Epoch 34; Iter   789/ 1097] train: loss: 0.0378798
[Epoch 34; Iter   819/ 1097] train: loss: 0.0198067
[Epoch 34; Iter   849/ 1097] train: loss: 0.3384888
[Epoch 34; Iter   879/ 1097] train: loss: 0.0306856
[Epoch 34; Iter   909/ 1097] train: loss: 0.0380772
[Epoch 34; Iter   939/ 1097] train: loss: 0.0508652
[Epoch 34; Iter   969/ 1097] train: loss: 0.1599563
[Epoch 34; Iter   999/ 1097] train: loss: 0.1244713
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1369059
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1204962
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0262303
[Epoch 34] ogbg-molhiv: 0.840134 val loss: 0.074943
[Epoch 34] ogbg-molhiv: 0.766322 test loss: 0.125169
[Epoch 35; Iter    22/ 1097] train: loss: 0.0150996
[Epoch 35; Iter    52/ 1097] train: loss: 0.0183026
[Epoch 35; Iter    82/ 1097] train: loss: 0.2271090
[Epoch 35; Iter   112/ 1097] train: loss: 0.1014856
[Epoch 35; Iter   142/ 1097] train: loss: 0.0245236
[Epoch 35; Iter   172/ 1097] train: loss: 0.0483541
[Epoch 35; Iter   202/ 1097] train: loss: 0.0806915
[Epoch 35; Iter   232/ 1097] train: loss: 0.0398666
[Epoch 35; Iter   262/ 1097] train: loss: 0.1042428
[Epoch 35; Iter   292/ 1097] train: loss: 0.0188235
[Epoch 35; Iter   322/ 1097] train: loss: 0.0250072
[Epoch 35; Iter   352/ 1097] train: loss: 0.0191183
[Epoch 35; Iter   382/ 1097] train: loss: 0.0186189
[Epoch 35; Iter   412/ 1097] train: loss: 0.0097833
[Epoch 35; Iter   442/ 1097] train: loss: 0.0876985
[Epoch 35; Iter   472/ 1097] train: loss: 0.0327966
[Epoch 35; Iter   502/ 1097] train: loss: 0.0199270
[Epoch 35; Iter   532/ 1097] train: loss: 0.0564038
[Epoch 35; Iter   562/ 1097] train: loss: 0.1627732
[Epoch 35; Iter   592/ 1097] train: loss: 0.0207267
[Epoch 35; Iter   622/ 1097] train: loss: 0.1373235
[Epoch 35; Iter   652/ 1097] train: loss: 0.0486551
[Epoch 35; Iter   682/ 1097] train: loss: 0.2720461
[Epoch 35; Iter   712/ 1097] train: loss: 0.1554998
[Epoch 35; Iter   742/ 1097] train: loss: 0.0528925
[Epoch 35; Iter   772/ 1097] train: loss: 0.0661116
[Epoch 35; Iter   802/ 1097] train: loss: 0.0179049
[Epoch 35; Iter   832/ 1097] train: loss: 0.0219796
[Epoch 35; Iter   862/ 1097] train: loss: 0.0515559
[Epoch 35; Iter   892/ 1097] train: loss: 0.1935598
[Epoch 35; Iter   922/ 1097] train: loss: 0.0189134
[Epoch 35; Iter   952/ 1097] train: loss: 0.0770249
[Epoch 35; Iter   982/ 1097] train: loss: 0.0334665
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0181522
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0454027
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0234823
[Epoch 35] ogbg-molhiv: 0.827862 val loss: 0.072798
[Epoch 35] ogbg-molhiv: 0.742954 test loss: 0.127626
[Epoch 36; Iter     5/ 1097] train: loss: 0.0331232
[Epoch 36; Iter    35/ 1097] train: loss: 0.0348227
[Epoch 36; Iter    65/ 1097] train: loss: 0.0354898
[Epoch 36; Iter    95/ 1097] train: loss: 0.1231457
[Epoch 36; Iter   125/ 1097] train: loss: 0.0400340
[Epoch 36; Iter   155/ 1097] train: loss: 0.0511179
[Epoch 36; Iter   185/ 1097] train: loss: 0.1013116
[Epoch 36; Iter   215/ 1097] train: loss: 0.0379079
[Epoch 36; Iter   245/ 1097] train: loss: 0.2676139
[Epoch 36; Iter   275/ 1097] train: loss: 0.0572632
[Epoch 36; Iter   305/ 1097] train: loss: 0.0146171
[Epoch 36; Iter   335/ 1097] train: loss: 0.1471972
[Epoch 36; Iter   365/ 1097] train: loss: 0.3166661
[Epoch 36; Iter   395/ 1097] train: loss: 0.0175102
[Epoch 36; Iter   425/ 1097] train: loss: 0.0926669
[Epoch 36; Iter   455/ 1097] train: loss: 0.0429966
[Epoch 36; Iter   485/ 1097] train: loss: 0.0255005
[Epoch 36; Iter   515/ 1097] train: loss: 0.2910910
[Epoch 36; Iter   545/ 1097] train: loss: 0.2411643
[Epoch 36; Iter   575/ 1097] train: loss: 0.1905834
[Epoch 40; Iter   687/ 1097] train: loss: 0.0020299
[Epoch 40; Iter   717/ 1097] train: loss: 0.0094354
[Epoch 40; Iter   747/ 1097] train: loss: 0.1557576
[Epoch 40; Iter   777/ 1097] train: loss: 0.0124622
[Epoch 40; Iter   807/ 1097] train: loss: 0.0053340
[Epoch 40; Iter   837/ 1097] train: loss: 0.0249825
[Epoch 40; Iter   867/ 1097] train: loss: 0.0211964
[Epoch 40; Iter   897/ 1097] train: loss: 0.0004401
[Epoch 40; Iter   927/ 1097] train: loss: 0.1373670
[Epoch 40; Iter   957/ 1097] train: loss: 0.1978582
[Epoch 40; Iter   987/ 1097] train: loss: 0.0008811
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0065018
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0004763
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0061124
[Epoch 40] ogbg-molhiv: 0.729966 val loss: 0.239120
[Epoch 40] ogbg-molhiv: 0.693893 test loss: 0.293511
[Epoch 41; Iter    10/ 1097] train: loss: 0.0180998
[Epoch 41; Iter    40/ 1097] train: loss: 0.0006664
[Epoch 41; Iter    70/ 1097] train: loss: 0.0121772
[Epoch 41; Iter   100/ 1097] train: loss: 0.0004921
[Epoch 41; Iter   130/ 1097] train: loss: 0.0033039
[Epoch 41; Iter   160/ 1097] train: loss: 0.0005000
[Epoch 41; Iter   190/ 1097] train: loss: 0.0107096
[Epoch 41; Iter   220/ 1097] train: loss: 0.0030828
[Epoch 41; Iter   250/ 1097] train: loss: 0.0009705
[Epoch 41; Iter   280/ 1097] train: loss: 0.0009788
[Epoch 41; Iter   310/ 1097] train: loss: 0.0223475
[Epoch 41; Iter   340/ 1097] train: loss: 0.0762286
[Epoch 41; Iter   370/ 1097] train: loss: 0.0152471
[Epoch 41; Iter   400/ 1097] train: loss: 0.0066201
[Epoch 41; Iter   430/ 1097] train: loss: 0.0142381
[Epoch 41; Iter   460/ 1097] train: loss: 0.0033897
[Epoch 41; Iter   490/ 1097] train: loss: 0.0103256
[Epoch 41; Iter   520/ 1097] train: loss: 0.0030984
[Epoch 41; Iter   550/ 1097] train: loss: 0.0041841
[Epoch 41; Iter   580/ 1097] train: loss: 0.0097323
[Epoch 41; Iter   610/ 1097] train: loss: 0.0199173
[Epoch 41; Iter   640/ 1097] train: loss: 0.0035099
[Epoch 41; Iter   670/ 1097] train: loss: 0.0027945
[Epoch 41; Iter   700/ 1097] train: loss: 0.0067961
[Epoch 41; Iter   730/ 1097] train: loss: 0.0008729
[Epoch 41; Iter   760/ 1097] train: loss: 0.0038550
[Epoch 41; Iter   790/ 1097] train: loss: 0.0184475
[Epoch 41; Iter   820/ 1097] train: loss: 0.0024316
[Epoch 41; Iter   850/ 1097] train: loss: 0.0020349
[Epoch 41; Iter   880/ 1097] train: loss: 0.0017676
[Epoch 41; Iter   910/ 1097] train: loss: 0.0188325
[Epoch 41; Iter   940/ 1097] train: loss: 0.0110883
[Epoch 41; Iter   970/ 1097] train: loss: 0.0650954
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0036021
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0354080
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0066361
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0013144
[Epoch 41] ogbg-molhiv: 0.773761 val loss: 0.177083
[Epoch 41] ogbg-molhiv: 0.768912 test loss: 0.286373
[Epoch 42; Iter    23/ 1097] train: loss: 0.0999993
[Epoch 42; Iter    53/ 1097] train: loss: 0.0275441
[Epoch 42; Iter    83/ 1097] train: loss: 0.0127188
[Epoch 42; Iter   113/ 1097] train: loss: 0.0020933
[Epoch 42; Iter   143/ 1097] train: loss: 0.0214897
[Epoch 42; Iter   173/ 1097] train: loss: 0.0157526
[Epoch 42; Iter   203/ 1097] train: loss: 0.0051974
[Epoch 42; Iter   233/ 1097] train: loss: 0.0440228
[Epoch 42; Iter   263/ 1097] train: loss: 0.1059636
[Epoch 42; Iter   293/ 1097] train: loss: 0.0028480
[Epoch 42; Iter   323/ 1097] train: loss: 0.0029559
[Epoch 42; Iter   353/ 1097] train: loss: 0.0212829
[Epoch 42; Iter   383/ 1097] train: loss: 0.0055822
[Epoch 42; Iter   413/ 1097] train: loss: 0.0146400
[Epoch 42; Iter   443/ 1097] train: loss: 0.1308322
[Epoch 42; Iter   473/ 1097] train: loss: 0.0064173
[Epoch 42; Iter   503/ 1097] train: loss: 0.0067989
[Epoch 42; Iter   533/ 1097] train: loss: 0.0075121
[Epoch 42; Iter   563/ 1097] train: loss: 0.0253053
[Epoch 42; Iter   593/ 1097] train: loss: 0.0233801
[Epoch 42; Iter   623/ 1097] train: loss: 0.0053412
[Epoch 42; Iter   653/ 1097] train: loss: 0.0268108
[Epoch 42; Iter   683/ 1097] train: loss: 0.0004738
[Epoch 42; Iter   713/ 1097] train: loss: 0.0062350
[Epoch 42; Iter   743/ 1097] train: loss: 0.0426737
[Epoch 42; Iter   773/ 1097] train: loss: 0.1822705
[Epoch 42; Iter   803/ 1097] train: loss: 0.0176780
[Epoch 42; Iter   833/ 1097] train: loss: 0.0066851
[Epoch 42; Iter   863/ 1097] train: loss: 0.0047820
[Epoch 42; Iter   893/ 1097] train: loss: 0.0108526
[Epoch 42; Iter   923/ 1097] train: loss: 0.0129342
[Epoch 42; Iter   953/ 1097] train: loss: 0.0976556
[Epoch 42; Iter   983/ 1097] train: loss: 0.0068092
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1022457
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0031784
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0085787
[Epoch 42] ogbg-molhiv: 0.762416 val loss: 0.334886
[Epoch 42] ogbg-molhiv: 0.711594 test loss: 0.273576
[Epoch 43; Iter     6/ 1097] train: loss: 0.0064964
[Epoch 43; Iter    36/ 1097] train: loss: 0.0035907
[Epoch 43; Iter    66/ 1097] train: loss: 0.0592671
[Epoch 43; Iter    96/ 1097] train: loss: 0.0035659
[Epoch 43; Iter   126/ 1097] train: loss: 0.0051435
[Epoch 43; Iter   156/ 1097] train: loss: 0.1409476
[Epoch 43; Iter   186/ 1097] train: loss: 0.0116370
[Epoch 43; Iter   216/ 1097] train: loss: 0.0013237
[Epoch 43; Iter   246/ 1097] train: loss: 0.1414429
[Epoch 43; Iter   276/ 1097] train: loss: 0.0205645
[Epoch 43; Iter   306/ 1097] train: loss: 0.0010015
[Epoch 43; Iter   336/ 1097] train: loss: 0.0245481
[Epoch 43; Iter   366/ 1097] train: loss: 0.0027003
[Epoch 43; Iter   396/ 1097] train: loss: 0.0302411
[Epoch 43; Iter   426/ 1097] train: loss: 0.0006082
[Epoch 43; Iter   456/ 1097] train: loss: 0.0082664
[Epoch 43; Iter   486/ 1097] train: loss: 0.0237976
[Epoch 43; Iter   516/ 1097] train: loss: 0.0047338
[Epoch 43; Iter   546/ 1097] train: loss: 0.0018463
[Epoch 43; Iter   576/ 1097] train: loss: 0.0109220
[Epoch 43; Iter   606/ 1097] train: loss: 0.0010694
[Epoch 43; Iter   636/ 1097] train: loss: 0.0006023
[Epoch 43; Iter   666/ 1097] train: loss: 0.0014313
[Epoch 43; Iter   696/ 1097] train: loss: 0.0100439
[Epoch 43; Iter   726/ 1097] train: loss: 0.0005121
[Epoch 43; Iter   756/ 1097] train: loss: 0.0543572
[Epoch 43; Iter   786/ 1097] train: loss: 0.0041439
[Epoch 43; Iter   816/ 1097] train: loss: 0.0101829
[Epoch 43; Iter   846/ 1097] train: loss: 0.0025397
[Epoch 43; Iter   876/ 1097] train: loss: 0.0007396
[Epoch 43; Iter   906/ 1097] train: loss: 0.0006511
[Epoch 43; Iter   936/ 1097] train: loss: 0.0014563
[Epoch 43; Iter   966/ 1097] train: loss: 0.0164820
[Epoch 43; Iter   996/ 1097] train: loss: 0.0213485
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0012002
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0879811
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0015260
[Epoch 43] ogbg-molhiv: 0.754075 val loss: 0.230129
[Epoch 43] ogbg-molhiv: 0.697511 test loss: 0.334985
[Epoch 44; Iter    19/ 1097] train: loss: 0.0053949
[Epoch 44; Iter    49/ 1097] train: loss: 0.0152005
[Epoch 44; Iter    79/ 1097] train: loss: 0.0029928
[Epoch 44; Iter   109/ 1097] train: loss: 0.0047065
[Epoch 44; Iter   139/ 1097] train: loss: 0.0077579
[Epoch 44; Iter   169/ 1097] train: loss: 0.0112220
[Epoch 44; Iter   199/ 1097] train: loss: 0.0033724
[Epoch 44; Iter   229/ 1097] train: loss: 0.0012684
[Epoch 44; Iter   259/ 1097] train: loss: 0.0011650
[Epoch 44; Iter   289/ 1097] train: loss: 0.0057181
[Epoch 44; Iter   319/ 1097] train: loss: 0.0300306
[Epoch 44; Iter   349/ 1097] train: loss: 0.0012568
[Epoch 44; Iter   379/ 1097] train: loss: 0.0031209
[Epoch 44; Iter   409/ 1097] train: loss: 0.0333255
[Epoch 44; Iter   439/ 1097] train: loss: 0.0007199
[Epoch 44; Iter   469/ 1097] train: loss: 0.0035677
[Epoch 44; Iter   499/ 1097] train: loss: 0.0010945
[Epoch 44; Iter   529/ 1097] train: loss: 0.0019593
[Epoch 44; Iter   559/ 1097] train: loss: 0.0097941
[Epoch 44; Iter   589/ 1097] train: loss: 0.0028113
[Epoch 44; Iter   619/ 1097] train: loss: 0.0099929
[Epoch 44; Iter   649/ 1097] train: loss: 0.0297017
[Epoch 44; Iter   679/ 1097] train: loss: 0.0077025
[Epoch 44; Iter   709/ 1097] train: loss: 0.0065556
[Epoch 44; Iter   739/ 1097] train: loss: 0.0029956
[Epoch 40; Iter   687/ 1097] train: loss: 0.0367684
[Epoch 40; Iter   717/ 1097] train: loss: 0.0005188
[Epoch 40; Iter   747/ 1097] train: loss: 0.0098023
[Epoch 40; Iter   777/ 1097] train: loss: 0.0475162
[Epoch 40; Iter   807/ 1097] train: loss: 0.0502721
[Epoch 40; Iter   837/ 1097] train: loss: 0.0055115
[Epoch 40; Iter   867/ 1097] train: loss: 0.0019948
[Epoch 40; Iter   897/ 1097] train: loss: 0.0090431
[Epoch 40; Iter   927/ 1097] train: loss: 0.0423329
[Epoch 40; Iter   957/ 1097] train: loss: 0.0056611
[Epoch 40; Iter   987/ 1097] train: loss: 0.0019025
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0089031
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0429347
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0052103
[Epoch 40] ogbg-molhiv: 0.760355 val loss: 0.205969
[Epoch 40] ogbg-molhiv: 0.738448 test loss: 0.292805
[Epoch 41; Iter    10/ 1097] train: loss: 0.0138389
[Epoch 41; Iter    40/ 1097] train: loss: 0.0051246
[Epoch 41; Iter    70/ 1097] train: loss: 0.0101797
[Epoch 41; Iter   100/ 1097] train: loss: 0.0061862
[Epoch 41; Iter   130/ 1097] train: loss: 0.0217174
[Epoch 41; Iter   160/ 1097] train: loss: 0.0303550
[Epoch 41; Iter   190/ 1097] train: loss: 0.0121053
[Epoch 41; Iter   220/ 1097] train: loss: 0.0279576
[Epoch 41; Iter   250/ 1097] train: loss: 0.0078176
[Epoch 41; Iter   280/ 1097] train: loss: 0.0061872
[Epoch 41; Iter   310/ 1097] train: loss: 0.0722159
[Epoch 41; Iter   340/ 1097] train: loss: 0.0015549
[Epoch 41; Iter   370/ 1097] train: loss: 0.0311918
[Epoch 41; Iter   400/ 1097] train: loss: 0.0029696
[Epoch 41; Iter   430/ 1097] train: loss: 0.0378074
[Epoch 41; Iter   460/ 1097] train: loss: 0.0012669
[Epoch 41; Iter   490/ 1097] train: loss: 0.1643275
[Epoch 41; Iter   520/ 1097] train: loss: 0.0014612
[Epoch 41; Iter   550/ 1097] train: loss: 0.0043860
[Epoch 41; Iter   580/ 1097] train: loss: 0.0026939
[Epoch 41; Iter   610/ 1097] train: loss: 0.0017560
[Epoch 41; Iter   640/ 1097] train: loss: 0.0012956
[Epoch 41; Iter   670/ 1097] train: loss: 0.0459892
[Epoch 41; Iter   700/ 1097] train: loss: 0.0048301
[Epoch 41; Iter   730/ 1097] train: loss: 0.0087351
[Epoch 41; Iter   760/ 1097] train: loss: 0.0124175
[Epoch 41; Iter   790/ 1097] train: loss: 0.1939339
[Epoch 41; Iter   820/ 1097] train: loss: 0.0027634
[Epoch 41; Iter   850/ 1097] train: loss: 0.0009494
[Epoch 41; Iter   880/ 1097] train: loss: 0.0102288
[Epoch 41; Iter   910/ 1097] train: loss: 0.0048340
[Epoch 41; Iter   940/ 1097] train: loss: 0.0954153
[Epoch 41; Iter   970/ 1097] train: loss: 0.0020385
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0387982
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0213609
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0014936
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0508687
[Epoch 41] ogbg-molhiv: 0.784747 val loss: 0.181668
[Epoch 41] ogbg-molhiv: 0.737042 test loss: 0.346405
[Epoch 42; Iter    23/ 1097] train: loss: 0.0018633
[Epoch 42; Iter    53/ 1097] train: loss: 0.0142658
[Epoch 42; Iter    83/ 1097] train: loss: 0.0025830
[Epoch 42; Iter   113/ 1097] train: loss: 0.0011803
[Epoch 42; Iter   143/ 1097] train: loss: 0.0600323
[Epoch 42; Iter   173/ 1097] train: loss: 0.0499275
[Epoch 42; Iter   203/ 1097] train: loss: 0.0041582
[Epoch 42; Iter   233/ 1097] train: loss: 0.0015601
[Epoch 42; Iter   263/ 1097] train: loss: 0.0163012
[Epoch 42; Iter   293/ 1097] train: loss: 0.0004124
[Epoch 42; Iter   323/ 1097] train: loss: 0.0245518
[Epoch 42; Iter   353/ 1097] train: loss: 0.0093854
[Epoch 42; Iter   383/ 1097] train: loss: 0.0335356
[Epoch 42; Iter   413/ 1097] train: loss: 0.0259729
[Epoch 42; Iter   443/ 1097] train: loss: 0.0037607
[Epoch 42; Iter   473/ 1097] train: loss: 0.0908039
[Epoch 42; Iter   503/ 1097] train: loss: 0.0828294
[Epoch 42; Iter   533/ 1097] train: loss: 0.0044964
[Epoch 42; Iter   563/ 1097] train: loss: 0.0006483
[Epoch 42; Iter   593/ 1097] train: loss: 0.0126346
[Epoch 42; Iter   623/ 1097] train: loss: 0.0073560
[Epoch 42; Iter   653/ 1097] train: loss: 0.0655147
[Epoch 42; Iter   683/ 1097] train: loss: 0.0018784
[Epoch 42; Iter   713/ 1097] train: loss: 0.0092004
[Epoch 42; Iter   743/ 1097] train: loss: 0.0069569
[Epoch 42; Iter   773/ 1097] train: loss: 0.0027008
[Epoch 42; Iter   803/ 1097] train: loss: 0.0015162
[Epoch 42; Iter   833/ 1097] train: loss: 0.0008286
[Epoch 42; Iter   863/ 1097] train: loss: 0.0009858
[Epoch 42; Iter   893/ 1097] train: loss: 0.0065883
[Epoch 42; Iter   923/ 1097] train: loss: 0.0056715
[Epoch 42; Iter   953/ 1097] train: loss: 0.0020226
[Epoch 42; Iter   983/ 1097] train: loss: 0.0465847
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0073334
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0237684
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0111587
[Epoch 42] ogbg-molhiv: 0.784073 val loss: 0.224886
[Epoch 42] ogbg-molhiv: 0.731511 test loss: 0.281954
[Epoch 43; Iter     6/ 1097] train: loss: 0.0267476
[Epoch 43; Iter    36/ 1097] train: loss: 0.0059806
[Epoch 43; Iter    66/ 1097] train: loss: 0.0209615
[Epoch 43; Iter    96/ 1097] train: loss: 0.0038997
[Epoch 43; Iter   126/ 1097] train: loss: 0.0016937
[Epoch 43; Iter   156/ 1097] train: loss: 0.0348385
[Epoch 43; Iter   186/ 1097] train: loss: 0.0056590
[Epoch 43; Iter   216/ 1097] train: loss: 0.0654568
[Epoch 43; Iter   246/ 1097] train: loss: 0.0011548
[Epoch 43; Iter   276/ 1097] train: loss: 0.0975703
[Epoch 43; Iter   306/ 1097] train: loss: 0.0315920
[Epoch 43; Iter   336/ 1097] train: loss: 0.0797001
[Epoch 43; Iter   366/ 1097] train: loss: 0.0076682
[Epoch 43; Iter   396/ 1097] train: loss: 0.0153168
[Epoch 43; Iter   426/ 1097] train: loss: 0.0016843
[Epoch 43; Iter   456/ 1097] train: loss: 0.0536277
[Epoch 43; Iter   486/ 1097] train: loss: 0.0036742
[Epoch 43; Iter   516/ 1097] train: loss: 0.0199228
[Epoch 43; Iter   546/ 1097] train: loss: 0.0025048
[Epoch 43; Iter   576/ 1097] train: loss: 0.0075371
[Epoch 43; Iter   606/ 1097] train: loss: 0.0766320
[Epoch 43; Iter   636/ 1097] train: loss: 0.0031648
[Epoch 43; Iter   666/ 1097] train: loss: 0.0010797
[Epoch 43; Iter   696/ 1097] train: loss: 0.0123111
[Epoch 43; Iter   726/ 1097] train: loss: 0.0021438
[Epoch 43; Iter   756/ 1097] train: loss: 0.0112321
[Epoch 43; Iter   786/ 1097] train: loss: 0.0146551
[Epoch 43; Iter   816/ 1097] train: loss: 0.0003843
[Epoch 43; Iter   846/ 1097] train: loss: 0.1103449
[Epoch 43; Iter   876/ 1097] train: loss: 0.0870213
[Epoch 43; Iter   906/ 1097] train: loss: 0.0073599
[Epoch 43; Iter   936/ 1097] train: loss: 0.0260640
[Epoch 43; Iter   966/ 1097] train: loss: 0.0039244
[Epoch 43; Iter   996/ 1097] train: loss: 0.0011801
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0000804
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0558951
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0008810
[Epoch 43] ogbg-molhiv: 0.764143 val loss: 0.201234
[Epoch 43] ogbg-molhiv: 0.736781 test loss: 0.298263
[Epoch 44; Iter    19/ 1097] train: loss: 0.0014537
[Epoch 44; Iter    49/ 1097] train: loss: 0.0071670
[Epoch 44; Iter    79/ 1097] train: loss: 0.0043957
[Epoch 44; Iter   109/ 1097] train: loss: 0.0019711
[Epoch 44; Iter   139/ 1097] train: loss: 0.0005411
[Epoch 44; Iter   169/ 1097] train: loss: 0.0080701
[Epoch 44; Iter   199/ 1097] train: loss: 0.0005271
[Epoch 44; Iter   229/ 1097] train: loss: 0.0094782
[Epoch 44; Iter   259/ 1097] train: loss: 0.0012968
[Epoch 44; Iter   289/ 1097] train: loss: 0.0097657
[Epoch 44; Iter   319/ 1097] train: loss: 0.0016650
[Epoch 44; Iter   349/ 1097] train: loss: 0.0583970
[Epoch 44; Iter   379/ 1097] train: loss: 0.0043821
[Epoch 44; Iter   409/ 1097] train: loss: 0.0259144
[Epoch 44; Iter   439/ 1097] train: loss: 0.0035666
[Epoch 44; Iter   469/ 1097] train: loss: 0.0196679
[Epoch 44; Iter   499/ 1097] train: loss: 0.1121985
[Epoch 44; Iter   529/ 1097] train: loss: 0.1579777
[Epoch 44; Iter   559/ 1097] train: loss: 0.0227036
[Epoch 44; Iter   589/ 1097] train: loss: 0.0009781
[Epoch 44; Iter   619/ 1097] train: loss: 0.0117495
[Epoch 44; Iter   649/ 1097] train: loss: 0.0401800
[Epoch 44; Iter   679/ 1097] train: loss: 0.0862603
[Epoch 44; Iter   709/ 1097] train: loss: 0.0061406
[Epoch 44; Iter   739/ 1097] train: loss: 0.0012914
[Epoch 40; Iter   687/ 1097] train: loss: 0.0535013
[Epoch 40; Iter   717/ 1097] train: loss: 0.0224862
[Epoch 40; Iter   747/ 1097] train: loss: 0.0139645
[Epoch 40; Iter   777/ 1097] train: loss: 0.1420504
[Epoch 40; Iter   807/ 1097] train: loss: 0.0124551
[Epoch 40; Iter   837/ 1097] train: loss: 0.0198021
[Epoch 40; Iter   867/ 1097] train: loss: 0.0171774
[Epoch 40; Iter   897/ 1097] train: loss: 0.0075834
[Epoch 40; Iter   927/ 1097] train: loss: 0.0019019
[Epoch 40; Iter   957/ 1097] train: loss: 0.0213893
[Epoch 40; Iter   987/ 1097] train: loss: 0.0019562
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0119072
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0159737
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1350541
[Epoch 40] ogbg-molhiv: 0.713640 val loss: 1.619900
[Epoch 40] ogbg-molhiv: 0.678306 test loss: 0.750488
[Epoch 41; Iter    10/ 1097] train: loss: 0.0064248
[Epoch 41; Iter    40/ 1097] train: loss: 0.0326103
[Epoch 41; Iter    70/ 1097] train: loss: 0.0073722
[Epoch 41; Iter   100/ 1097] train: loss: 0.1472291
[Epoch 41; Iter   130/ 1097] train: loss: 0.0102062
[Epoch 41; Iter   160/ 1097] train: loss: 0.0981064
[Epoch 41; Iter   190/ 1097] train: loss: 0.0583762
[Epoch 41; Iter   220/ 1097] train: loss: 0.0026980
[Epoch 41; Iter   250/ 1097] train: loss: 0.0062563
[Epoch 41; Iter   280/ 1097] train: loss: 0.2154013
[Epoch 41; Iter   310/ 1097] train: loss: 0.0130822
[Epoch 41; Iter   340/ 1097] train: loss: 0.0455726
[Epoch 41; Iter   370/ 1097] train: loss: 0.0027877
[Epoch 41; Iter   400/ 1097] train: loss: 0.0094484
[Epoch 41; Iter   430/ 1097] train: loss: 0.0025357
[Epoch 41; Iter   460/ 1097] train: loss: 0.0043486
[Epoch 41; Iter   490/ 1097] train: loss: 0.0698348
[Epoch 41; Iter   520/ 1097] train: loss: 0.0122347
[Epoch 41; Iter   550/ 1097] train: loss: 0.0361962
[Epoch 41; Iter   580/ 1097] train: loss: 0.0130213
[Epoch 41; Iter   610/ 1097] train: loss: 0.0689146
[Epoch 41; Iter   640/ 1097] train: loss: 0.0068862
[Epoch 41; Iter   670/ 1097] train: loss: 0.0032953
[Epoch 41; Iter   700/ 1097] train: loss: 0.0098074
[Epoch 41; Iter   730/ 1097] train: loss: 0.0283773
[Epoch 41; Iter   760/ 1097] train: loss: 0.0052239
[Epoch 41; Iter   790/ 1097] train: loss: 0.0623915
[Epoch 41; Iter   820/ 1097] train: loss: 0.0057649
[Epoch 41; Iter   850/ 1097] train: loss: 0.1041486
[Epoch 41; Iter   880/ 1097] train: loss: 0.0107528
[Epoch 41; Iter   910/ 1097] train: loss: 0.0168410
[Epoch 41; Iter   940/ 1097] train: loss: 0.0056258
[Epoch 41; Iter   970/ 1097] train: loss: 0.0055729
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0108324
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0691471
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0216869
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0166780
[Epoch 41] ogbg-molhiv: 0.718352 val loss: 1.297984
[Epoch 41] ogbg-molhiv: 0.720898 test loss: 0.494835
[Epoch 42; Iter    23/ 1097] train: loss: 0.0011369
[Epoch 42; Iter    53/ 1097] train: loss: 0.0259620
[Epoch 42; Iter    83/ 1097] train: loss: 0.0042897
[Epoch 42; Iter   113/ 1097] train: loss: 0.0064595
[Epoch 42; Iter   143/ 1097] train: loss: 0.0031361
[Epoch 42; Iter   173/ 1097] train: loss: 0.0036045
[Epoch 42; Iter   203/ 1097] train: loss: 0.0566320
[Epoch 42; Iter   233/ 1097] train: loss: 0.0852967
[Epoch 42; Iter   263/ 1097] train: loss: 0.0081072
[Epoch 42; Iter   293/ 1097] train: loss: 0.0053983
[Epoch 42; Iter   323/ 1097] train: loss: 0.1259718
[Epoch 42; Iter   353/ 1097] train: loss: 0.0019489
[Epoch 42; Iter   383/ 1097] train: loss: 0.0109983
[Epoch 42; Iter   413/ 1097] train: loss: 0.0041364
[Epoch 42; Iter   443/ 1097] train: loss: 0.0058882
[Epoch 42; Iter   473/ 1097] train: loss: 0.0571048
[Epoch 42; Iter   503/ 1097] train: loss: 0.0670762
[Epoch 42; Iter   533/ 1097] train: loss: 0.0117362
[Epoch 42; Iter   563/ 1097] train: loss: 0.0035074
[Epoch 42; Iter   593/ 1097] train: loss: 0.0067535
[Epoch 42; Iter   623/ 1097] train: loss: 0.0053878
[Epoch 42; Iter   653/ 1097] train: loss: 0.0152310
[Epoch 42; Iter   683/ 1097] train: loss: 0.0242316
[Epoch 42; Iter   713/ 1097] train: loss: 0.0047621
[Epoch 42; Iter   743/ 1097] train: loss: 0.0108832
[Epoch 42; Iter   773/ 1097] train: loss: 0.0946104
[Epoch 42; Iter   803/ 1097] train: loss: 0.0109648
[Epoch 42; Iter   833/ 1097] train: loss: 0.0074165
[Epoch 42; Iter   863/ 1097] train: loss: 0.0329428
[Epoch 42; Iter   893/ 1097] train: loss: 0.0075983
[Epoch 42; Iter   923/ 1097] train: loss: 0.0321626
[Epoch 42; Iter   953/ 1097] train: loss: 0.0013198
[Epoch 42; Iter   983/ 1097] train: loss: 0.0028349
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0114436
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0209039
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0034043
[Epoch 42] ogbg-molhiv: 0.705023 val loss: 1.471724
[Epoch 42] ogbg-molhiv: 0.724373 test loss: 0.428271
[Epoch 43; Iter     6/ 1097] train: loss: 0.0087321
[Epoch 43; Iter    36/ 1097] train: loss: 0.0025348
[Epoch 43; Iter    66/ 1097] train: loss: 0.0984491
[Epoch 43; Iter    96/ 1097] train: loss: 0.0082504
[Epoch 43; Iter   126/ 1097] train: loss: 0.0097186
[Epoch 43; Iter   156/ 1097] train: loss: 0.0298775
[Epoch 43; Iter   186/ 1097] train: loss: 0.0222562
[Epoch 43; Iter   216/ 1097] train: loss: 0.0078771
[Epoch 43; Iter   246/ 1097] train: loss: 0.0131240
[Epoch 43; Iter   276/ 1097] train: loss: 0.0021799
[Epoch 43; Iter   306/ 1097] train: loss: 0.0475985
[Epoch 43; Iter   336/ 1097] train: loss: 0.0014410
[Epoch 43; Iter   366/ 1097] train: loss: 0.0141834
[Epoch 43; Iter   396/ 1097] train: loss: 0.0013756
[Epoch 43; Iter   426/ 1097] train: loss: 0.1237442
[Epoch 43; Iter   456/ 1097] train: loss: 0.0167888
[Epoch 43; Iter   486/ 1097] train: loss: 0.0167930
[Epoch 43; Iter   516/ 1097] train: loss: 0.0041854
[Epoch 43; Iter   546/ 1097] train: loss: 0.1298681
[Epoch 43; Iter   576/ 1097] train: loss: 0.0026981
[Epoch 43; Iter   606/ 1097] train: loss: 0.0126223
[Epoch 43; Iter   636/ 1097] train: loss: 0.0778132
[Epoch 43; Iter   666/ 1097] train: loss: 0.0021741
[Epoch 43; Iter   696/ 1097] train: loss: 0.0163097
[Epoch 43; Iter   726/ 1097] train: loss: 0.0019891
[Epoch 43; Iter   756/ 1097] train: loss: 0.0955666
[Epoch 43; Iter   786/ 1097] train: loss: 0.0724656
[Epoch 43; Iter   816/ 1097] train: loss: 0.0738634
[Epoch 43; Iter   846/ 1097] train: loss: 0.0984535
[Epoch 43; Iter   876/ 1097] train: loss: 0.1002776
[Epoch 43; Iter   906/ 1097] train: loss: 0.0315560
[Epoch 43; Iter   936/ 1097] train: loss: 0.0058585
[Epoch 43; Iter   966/ 1097] train: loss: 0.0474191
[Epoch 43; Iter   996/ 1097] train: loss: 0.0096978
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0940886
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0316627
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0100294
[Epoch 43] ogbg-molhiv: 0.686630 val loss: 0.359684
[Epoch 43] ogbg-molhiv: 0.717770 test loss: 0.577365
[Epoch 44; Iter    19/ 1097] train: loss: 0.0049283
[Epoch 44; Iter    49/ 1097] train: loss: 0.0037935
[Epoch 44; Iter    79/ 1097] train: loss: 0.0049041
[Epoch 44; Iter   109/ 1097] train: loss: 0.0090002
[Epoch 44; Iter   139/ 1097] train: loss: 0.0070271
[Epoch 44; Iter   169/ 1097] train: loss: 0.0474044
[Epoch 44; Iter   199/ 1097] train: loss: 0.0328979
[Epoch 44; Iter   229/ 1097] train: loss: 0.0438256
[Epoch 44; Iter   259/ 1097] train: loss: 0.0151924
[Epoch 44; Iter   289/ 1097] train: loss: 0.0340014
[Epoch 44; Iter   319/ 1097] train: loss: 0.0639348
[Epoch 44; Iter   349/ 1097] train: loss: 0.0305949
[Epoch 44; Iter   379/ 1097] train: loss: 0.0045765
[Epoch 44; Iter   409/ 1097] train: loss: 0.0016411
[Epoch 44; Iter   439/ 1097] train: loss: 0.0044643
[Epoch 44; Iter   469/ 1097] train: loss: 0.0297083
[Epoch 44; Iter   499/ 1097] train: loss: 0.0081538
[Epoch 44; Iter   529/ 1097] train: loss: 0.0012318
[Epoch 44; Iter   559/ 1097] train: loss: 0.0035301
[Epoch 44; Iter   589/ 1097] train: loss: 0.0027663
[Epoch 44; Iter   619/ 1097] train: loss: 0.0024281
[Epoch 44; Iter   649/ 1097] train: loss: 0.0030052
[Epoch 44; Iter   679/ 1097] train: loss: 0.0727629
[Epoch 44; Iter   709/ 1097] train: loss: 0.0034295
[Epoch 44; Iter   739/ 1097] train: loss: 0.0013237
[Epoch 40; Iter   687/ 1097] train: loss: 0.0078822
[Epoch 40; Iter   717/ 1097] train: loss: 0.0005994
[Epoch 40; Iter   747/ 1097] train: loss: 0.0281255
[Epoch 40; Iter   777/ 1097] train: loss: 0.1061713
[Epoch 40; Iter   807/ 1097] train: loss: 0.0214267
[Epoch 40; Iter   837/ 1097] train: loss: 0.0025033
[Epoch 40; Iter   867/ 1097] train: loss: 0.0018577
[Epoch 40; Iter   897/ 1097] train: loss: 0.0009674
[Epoch 40; Iter   927/ 1097] train: loss: 0.1548075
[Epoch 40; Iter   957/ 1097] train: loss: 0.2438392
[Epoch 40; Iter   987/ 1097] train: loss: 0.0844915
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0020832
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0024741
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0217676
[Epoch 40] ogbg-molhiv: 0.780803 val loss: 0.134811
[Epoch 40] ogbg-molhiv: 0.710216 test loss: 0.246265
[Epoch 41; Iter    10/ 1097] train: loss: 0.0007358
[Epoch 41; Iter    40/ 1097] train: loss: 0.0985848
[Epoch 41; Iter    70/ 1097] train: loss: 0.0018527
[Epoch 41; Iter   100/ 1097] train: loss: 0.0003502
[Epoch 41; Iter   130/ 1097] train: loss: 0.0046372
[Epoch 41; Iter   160/ 1097] train: loss: 0.0773222
[Epoch 41; Iter   190/ 1097] train: loss: 0.0040775
[Epoch 41; Iter   220/ 1097] train: loss: 0.0015724
[Epoch 41; Iter   250/ 1097] train: loss: 0.0193068
[Epoch 41; Iter   280/ 1097] train: loss: 0.1665142
[Epoch 41; Iter   310/ 1097] train: loss: 0.0606183
[Epoch 41; Iter   340/ 1097] train: loss: 0.0120135
[Epoch 41; Iter   370/ 1097] train: loss: 0.0012060
[Epoch 41; Iter   400/ 1097] train: loss: 0.0309999
[Epoch 41; Iter   430/ 1097] train: loss: 0.0093520
[Epoch 41; Iter   460/ 1097] train: loss: 0.0219435
[Epoch 41; Iter   490/ 1097] train: loss: 0.0034237
[Epoch 41; Iter   520/ 1097] train: loss: 0.0014950
[Epoch 41; Iter   550/ 1097] train: loss: 0.0005972
[Epoch 41; Iter   580/ 1097] train: loss: 0.0009415
[Epoch 41; Iter   610/ 1097] train: loss: 0.0077293
[Epoch 41; Iter   640/ 1097] train: loss: 0.0039238
[Epoch 41; Iter   670/ 1097] train: loss: 0.0014304
[Epoch 41; Iter   700/ 1097] train: loss: 0.0052238
[Epoch 41; Iter   730/ 1097] train: loss: 0.0005741
[Epoch 41; Iter   760/ 1097] train: loss: 0.0040614
[Epoch 41; Iter   790/ 1097] train: loss: 0.0132490
[Epoch 41; Iter   820/ 1097] train: loss: 0.0036914
[Epoch 41; Iter   850/ 1097] train: loss: 0.0318529
[Epoch 41; Iter   880/ 1097] train: loss: 0.0027464
[Epoch 41; Iter   910/ 1097] train: loss: 0.0012684
[Epoch 41; Iter   940/ 1097] train: loss: 0.0098527
[Epoch 41; Iter   970/ 1097] train: loss: 0.0025850
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0543145
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0006954
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0011006
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0159428
[Epoch 41] ogbg-molhiv: 0.791379 val loss: 0.162463
[Epoch 41] ogbg-molhiv: 0.717897 test loss: 0.266367
[Epoch 42; Iter    23/ 1097] train: loss: 0.0009176
[Epoch 42; Iter    53/ 1097] train: loss: 0.0009245
[Epoch 42; Iter    83/ 1097] train: loss: 0.0317926
[Epoch 42; Iter   113/ 1097] train: loss: 0.0066504
[Epoch 42; Iter   143/ 1097] train: loss: 0.0004474
[Epoch 42; Iter   173/ 1097] train: loss: 0.0015072
[Epoch 42; Iter   203/ 1097] train: loss: 0.0122805
[Epoch 42; Iter   233/ 1097] train: loss: 0.0013971
[Epoch 42; Iter   263/ 1097] train: loss: 0.0023108
[Epoch 42; Iter   293/ 1097] train: loss: 0.0001886
[Epoch 42; Iter   323/ 1097] train: loss: 0.0175107
[Epoch 42; Iter   353/ 1097] train: loss: 0.0003129
[Epoch 42; Iter   383/ 1097] train: loss: 0.0003723
[Epoch 42; Iter   413/ 1097] train: loss: 0.0115093
[Epoch 42; Iter   443/ 1097] train: loss: 0.0062076
[Epoch 42; Iter   473/ 1097] train: loss: 0.0347674
[Epoch 42; Iter   503/ 1097] train: loss: 0.0020692
[Epoch 42; Iter   533/ 1097] train: loss: 0.0026858
[Epoch 42; Iter   563/ 1097] train: loss: 0.0006285
[Epoch 42; Iter   593/ 1097] train: loss: 0.1356542
[Epoch 42; Iter   623/ 1097] train: loss: 0.0013814
[Epoch 42; Iter   653/ 1097] train: loss: 0.0014436
[Epoch 42; Iter   683/ 1097] train: loss: 0.0013605
[Epoch 42; Iter   713/ 1097] train: loss: 0.0047478
[Epoch 42; Iter   743/ 1097] train: loss: 0.0152051
[Epoch 42; Iter   773/ 1097] train: loss: 0.0023223
[Epoch 42; Iter   803/ 1097] train: loss: 0.0288973
[Epoch 42; Iter   833/ 1097] train: loss: 0.0014085
[Epoch 42; Iter   863/ 1097] train: loss: 0.0023421
[Epoch 42; Iter   893/ 1097] train: loss: 0.0018874
[Epoch 42; Iter   923/ 1097] train: loss: 0.0074604
[Epoch 42; Iter   953/ 1097] train: loss: 0.0057426
[Epoch 42; Iter   983/ 1097] train: loss: 0.0042454
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0344315
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0020946
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0103263
[Epoch 42] ogbg-molhiv: 0.765160 val loss: 0.155426
[Epoch 42] ogbg-molhiv: 0.721586 test loss: 0.242958
[Epoch 43; Iter     6/ 1097] train: loss: 0.0014366
[Epoch 43; Iter    36/ 1097] train: loss: 0.0003988
[Epoch 43; Iter    66/ 1097] train: loss: 0.1093037
[Epoch 43; Iter    96/ 1097] train: loss: 0.0077019
[Epoch 43; Iter   126/ 1097] train: loss: 0.0004104
[Epoch 43; Iter   156/ 1097] train: loss: 0.0057314
[Epoch 43; Iter   186/ 1097] train: loss: 0.0261056
[Epoch 43; Iter   216/ 1097] train: loss: 0.0080601
[Epoch 43; Iter   246/ 1097] train: loss: 0.0013345
[Epoch 43; Iter   276/ 1097] train: loss: 0.0025878
[Epoch 43; Iter   306/ 1097] train: loss: 0.0101998
[Epoch 43; Iter   336/ 1097] train: loss: 0.0127361
[Epoch 43; Iter   366/ 1097] train: loss: 0.0008253
[Epoch 43; Iter   396/ 1097] train: loss: 0.0018881
[Epoch 43; Iter   426/ 1097] train: loss: 0.0101843
[Epoch 43; Iter   456/ 1097] train: loss: 0.0719034
[Epoch 43; Iter   486/ 1097] train: loss: 0.0171188
[Epoch 43; Iter   516/ 1097] train: loss: 0.0108572
[Epoch 43; Iter   546/ 1097] train: loss: 0.0020973
[Epoch 43; Iter   576/ 1097] train: loss: 0.0105805
[Epoch 43; Iter   606/ 1097] train: loss: 0.0631030
[Epoch 43; Iter   636/ 1097] train: loss: 0.0035385
[Epoch 43; Iter   666/ 1097] train: loss: 0.0001493
[Epoch 43; Iter   696/ 1097] train: loss: 0.0002715
[Epoch 43; Iter   726/ 1097] train: loss: 0.0544688
[Epoch 43; Iter   756/ 1097] train: loss: 0.0122146
[Epoch 43; Iter   786/ 1097] train: loss: 0.0470214
[Epoch 43; Iter   816/ 1097] train: loss: 0.0156045
[Epoch 43; Iter   846/ 1097] train: loss: 0.0022474
[Epoch 43; Iter   876/ 1097] train: loss: 0.0416752
[Epoch 43; Iter   906/ 1097] train: loss: 0.0363469
[Epoch 43; Iter   936/ 1097] train: loss: 0.0050248
[Epoch 43; Iter   966/ 1097] train: loss: 0.0108299
[Epoch 43; Iter   996/ 1097] train: loss: 0.0004915
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0022046
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0003557
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0018199
[Epoch 43] ogbg-molhiv: 0.765781 val loss: 0.158099
[Epoch 43] ogbg-molhiv: 0.727671 test loss: 0.245839
[Epoch 44; Iter    19/ 1097] train: loss: 0.0174381
[Epoch 44; Iter    49/ 1097] train: loss: 0.0016804
[Epoch 44; Iter    79/ 1097] train: loss: 0.0538011
[Epoch 44; Iter   109/ 1097] train: loss: 0.0070502
[Epoch 44; Iter   139/ 1097] train: loss: 0.0009462
[Epoch 44; Iter   169/ 1097] train: loss: 0.0049510
[Epoch 44; Iter   199/ 1097] train: loss: 0.0873607
[Epoch 44; Iter   229/ 1097] train: loss: 0.0016226
[Epoch 44; Iter   259/ 1097] train: loss: 0.0013932
[Epoch 44; Iter   289/ 1097] train: loss: 0.0190456
[Epoch 44; Iter   319/ 1097] train: loss: 0.0006812
[Epoch 44; Iter   349/ 1097] train: loss: 0.0072657
[Epoch 44; Iter   379/ 1097] train: loss: 0.0020886
[Epoch 44; Iter   409/ 1097] train: loss: 0.0035253
[Epoch 44; Iter   439/ 1097] train: loss: 0.0002178
[Epoch 44; Iter   469/ 1097] train: loss: 0.0069752
[Epoch 44; Iter   499/ 1097] train: loss: 0.0046342
[Epoch 44; Iter   529/ 1097] train: loss: 0.0197057
[Epoch 44; Iter   559/ 1097] train: loss: 0.0012546
[Epoch 44; Iter   589/ 1097] train: loss: 0.0006838
[Epoch 44; Iter   619/ 1097] train: loss: 0.0006626
[Epoch 44; Iter   649/ 1097] train: loss: 0.0001096
[Epoch 44; Iter   679/ 1097] train: loss: 0.1275317
[Epoch 44; Iter   709/ 1097] train: loss: 0.0008413
[Epoch 44; Iter   739/ 1097] train: loss: 0.0023545
[Epoch 40; Iter   687/ 1097] train: loss: 0.1490009
[Epoch 40; Iter   717/ 1097] train: loss: 0.0041809
[Epoch 40; Iter   747/ 1097] train: loss: 0.0059531
[Epoch 40; Iter   777/ 1097] train: loss: 0.2403520
[Epoch 40; Iter   807/ 1097] train: loss: 0.0128953
[Epoch 40; Iter   837/ 1097] train: loss: 0.0061231
[Epoch 40; Iter   867/ 1097] train: loss: 0.0031769
[Epoch 40; Iter   897/ 1097] train: loss: 0.0016494
[Epoch 40; Iter   927/ 1097] train: loss: 0.0880352
[Epoch 40; Iter   957/ 1097] train: loss: 0.0113219
[Epoch 40; Iter   987/ 1097] train: loss: 0.0081841
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0037854
[Epoch 40; Iter  1047/ 1097] train: loss: 0.1421507
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0094042
[Epoch 40] ogbg-molhiv: 0.783908 val loss: 0.179701
[Epoch 40] ogbg-molhiv: 0.719730 test loss: 0.334170
[Epoch 41; Iter    10/ 1097] train: loss: 0.0512165
[Epoch 41; Iter    40/ 1097] train: loss: 0.0007550
[Epoch 41; Iter    70/ 1097] train: loss: 0.0019666
[Epoch 41; Iter   100/ 1097] train: loss: 0.0028025
[Epoch 41; Iter   130/ 1097] train: loss: 0.0505931
[Epoch 41; Iter   160/ 1097] train: loss: 0.0205990
[Epoch 41; Iter   190/ 1097] train: loss: 0.0121768
[Epoch 41; Iter   220/ 1097] train: loss: 0.1211050
[Epoch 41; Iter   250/ 1097] train: loss: 0.0103885
[Epoch 41; Iter   280/ 1097] train: loss: 0.0043109
[Epoch 41; Iter   310/ 1097] train: loss: 0.1154282
[Epoch 41; Iter   340/ 1097] train: loss: 0.0020296
[Epoch 41; Iter   370/ 1097] train: loss: 0.0942216
[Epoch 41; Iter   400/ 1097] train: loss: 0.0080430
[Epoch 41; Iter   430/ 1097] train: loss: 0.0009931
[Epoch 41; Iter   460/ 1097] train: loss: 0.0849563
[Epoch 41; Iter   490/ 1097] train: loss: 0.1606866
[Epoch 41; Iter   520/ 1097] train: loss: 0.0030023
[Epoch 41; Iter   550/ 1097] train: loss: 0.0027345
[Epoch 41; Iter   580/ 1097] train: loss: 0.1026348
[Epoch 41; Iter   610/ 1097] train: loss: 0.0051098
[Epoch 41; Iter   640/ 1097] train: loss: 0.0053540
[Epoch 41; Iter   670/ 1097] train: loss: 0.0082732
[Epoch 41; Iter   700/ 1097] train: loss: 0.0147829
[Epoch 41; Iter   730/ 1097] train: loss: 0.0043729
[Epoch 41; Iter   760/ 1097] train: loss: 0.0026077
[Epoch 41; Iter   790/ 1097] train: loss: 0.0328956
[Epoch 41; Iter   820/ 1097] train: loss: 0.0052716
[Epoch 41; Iter   850/ 1097] train: loss: 0.0005617
[Epoch 41; Iter   880/ 1097] train: loss: 0.0058826
[Epoch 41; Iter   910/ 1097] train: loss: 0.0009530
[Epoch 41; Iter   940/ 1097] train: loss: 0.0095184
[Epoch 41; Iter   970/ 1097] train: loss: 0.0008001
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0118326
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0097680
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0046675
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1665300
[Epoch 41] ogbg-molhiv: 0.804756 val loss: 0.192963
[Epoch 41] ogbg-molhiv: 0.714066 test loss: 0.367605
[Epoch 42; Iter    23/ 1097] train: loss: 0.0057135
[Epoch 42; Iter    53/ 1097] train: loss: 0.0103272
[Epoch 42; Iter    83/ 1097] train: loss: 0.0122755
[Epoch 42; Iter   113/ 1097] train: loss: 0.0083803
[Epoch 42; Iter   143/ 1097] train: loss: 0.0092961
[Epoch 42; Iter   173/ 1097] train: loss: 0.0047901
[Epoch 42; Iter   203/ 1097] train: loss: 0.0041164
[Epoch 42; Iter   233/ 1097] train: loss: 0.0098251
[Epoch 42; Iter   263/ 1097] train: loss: 0.0664669
[Epoch 42; Iter   293/ 1097] train: loss: 0.0746410
[Epoch 42; Iter   323/ 1097] train: loss: 0.0016512
[Epoch 42; Iter   353/ 1097] train: loss: 0.0042289
[Epoch 42; Iter   383/ 1097] train: loss: 0.0039797
[Epoch 42; Iter   413/ 1097] train: loss: 0.0078054
[Epoch 42; Iter   443/ 1097] train: loss: 0.0048472
[Epoch 42; Iter   473/ 1097] train: loss: 0.0993345
[Epoch 42; Iter   503/ 1097] train: loss: 0.0196876
[Epoch 42; Iter   533/ 1097] train: loss: 0.0878899
[Epoch 42; Iter   563/ 1097] train: loss: 0.0058552
[Epoch 42; Iter   593/ 1097] train: loss: 0.0013006
[Epoch 42; Iter   623/ 1097] train: loss: 0.0106731
[Epoch 42; Iter   653/ 1097] train: loss: 0.0015793
[Epoch 42; Iter   683/ 1097] train: loss: 0.0207768
[Epoch 42; Iter   713/ 1097] train: loss: 0.0376572
[Epoch 42; Iter   743/ 1097] train: loss: 0.1725034
[Epoch 42; Iter   773/ 1097] train: loss: 0.0048037
[Epoch 42; Iter   803/ 1097] train: loss: 0.0037145
[Epoch 42; Iter   833/ 1097] train: loss: 0.0520637
[Epoch 42; Iter   863/ 1097] train: loss: 0.0039512
[Epoch 42; Iter   893/ 1097] train: loss: 0.0056282
[Epoch 42; Iter   923/ 1097] train: loss: 0.0106262
[Epoch 42; Iter   953/ 1097] train: loss: 0.0036365
[Epoch 42; Iter   983/ 1097] train: loss: 0.0012008
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0561143
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1049269
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0130087
[Epoch 42] ogbg-molhiv: 0.811615 val loss: 0.152332
[Epoch 42] ogbg-molhiv: 0.720591 test loss: 0.269807
[Epoch 43; Iter     6/ 1097] train: loss: 0.0032833
[Epoch 43; Iter    36/ 1097] train: loss: 0.0211977
[Epoch 43; Iter    66/ 1097] train: loss: 0.0132322
[Epoch 43; Iter    96/ 1097] train: loss: 0.0033412
[Epoch 43; Iter   126/ 1097] train: loss: 0.0081994
[Epoch 43; Iter   156/ 1097] train: loss: 0.0111880
[Epoch 43; Iter   186/ 1097] train: loss: 0.0005025
[Epoch 43; Iter   216/ 1097] train: loss: 0.0059573
[Epoch 43; Iter   246/ 1097] train: loss: 0.0006289
[Epoch 43; Iter   276/ 1097] train: loss: 0.0605302
[Epoch 43; Iter   306/ 1097] train: loss: 0.1228390
[Epoch 43; Iter   336/ 1097] train: loss: 0.0703677
[Epoch 43; Iter   366/ 1097] train: loss: 0.0047258
[Epoch 43; Iter   396/ 1097] train: loss: 0.0016040
[Epoch 43; Iter   426/ 1097] train: loss: 0.0013458
[Epoch 43; Iter   456/ 1097] train: loss: 0.0451521
[Epoch 43; Iter   486/ 1097] train: loss: 0.0190684
[Epoch 43; Iter   516/ 1097] train: loss: 0.0006283
[Epoch 43; Iter   546/ 1097] train: loss: 0.0266503
[Epoch 43; Iter   576/ 1097] train: loss: 0.0107438
[Epoch 43; Iter   606/ 1097] train: loss: 0.1233169
[Epoch 43; Iter   636/ 1097] train: loss: 0.0162575
[Epoch 43; Iter   666/ 1097] train: loss: 0.0027957
[Epoch 43; Iter   696/ 1097] train: loss: 0.0088724
[Epoch 43; Iter   726/ 1097] train: loss: 0.0019284
[Epoch 43; Iter   756/ 1097] train: loss: 0.0060905
[Epoch 43; Iter   786/ 1097] train: loss: 0.0504067
[Epoch 43; Iter   816/ 1097] train: loss: 0.0015140
[Epoch 43; Iter   846/ 1097] train: loss: 0.0014532
[Epoch 43; Iter   876/ 1097] train: loss: 0.1068956
[Epoch 43; Iter   906/ 1097] train: loss: 0.0056930
[Epoch 43; Iter   936/ 1097] train: loss: 0.0256395
[Epoch 43; Iter   966/ 1097] train: loss: 0.0086987
[Epoch 43; Iter   996/ 1097] train: loss: 0.0531223
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0013027
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0234762
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0191526
[Epoch 43] ogbg-molhiv: 0.782297 val loss: 0.293201
[Epoch 43] ogbg-molhiv: 0.708142 test loss: 0.359816
[Epoch 44; Iter    19/ 1097] train: loss: 0.0173318
[Epoch 44; Iter    49/ 1097] train: loss: 0.0530493
[Epoch 44; Iter    79/ 1097] train: loss: 0.0043880
[Epoch 44; Iter   109/ 1097] train: loss: 0.0778234
[Epoch 44; Iter   139/ 1097] train: loss: 0.0095205
[Epoch 44; Iter   169/ 1097] train: loss: 0.0016738
[Epoch 44; Iter   199/ 1097] train: loss: 0.0050994
[Epoch 44; Iter   229/ 1097] train: loss: 0.0008350
[Epoch 44; Iter   259/ 1097] train: loss: 0.0013600
[Epoch 44; Iter   289/ 1097] train: loss: 0.0017179
[Epoch 44; Iter   319/ 1097] train: loss: 0.0020271
[Epoch 44; Iter   349/ 1097] train: loss: 0.0222215
[Epoch 44; Iter   379/ 1097] train: loss: 0.0042416
[Epoch 44; Iter   409/ 1097] train: loss: 0.0005678
[Epoch 44; Iter   439/ 1097] train: loss: 0.0022240
[Epoch 44; Iter   469/ 1097] train: loss: 0.0507864
[Epoch 44; Iter   499/ 1097] train: loss: 0.0028397
[Epoch 44; Iter   529/ 1097] train: loss: 0.0615355
[Epoch 44; Iter   559/ 1097] train: loss: 0.0020994
[Epoch 44; Iter   589/ 1097] train: loss: 0.0340844
[Epoch 44; Iter   619/ 1097] train: loss: 0.0181300
[Epoch 44; Iter   649/ 1097] train: loss: 0.0025715
[Epoch 44; Iter   679/ 1097] train: loss: 0.0909682
[Epoch 44; Iter   709/ 1097] train: loss: 0.0061639
[Epoch 44; Iter   739/ 1097] train: loss: 0.0029496
[Epoch 40; Iter   687/ 1097] train: loss: 0.0040802
[Epoch 40; Iter   717/ 1097] train: loss: 0.0699987
[Epoch 40; Iter   747/ 1097] train: loss: 0.0943493
[Epoch 40; Iter   777/ 1097] train: loss: 0.0200006
[Epoch 40; Iter   807/ 1097] train: loss: 0.0016491
[Epoch 40; Iter   837/ 1097] train: loss: 0.0074043
[Epoch 40; Iter   867/ 1097] train: loss: 0.0224602
[Epoch 40; Iter   897/ 1097] train: loss: 0.0325015
[Epoch 40; Iter   927/ 1097] train: loss: 0.0077526
[Epoch 40; Iter   957/ 1097] train: loss: 0.0076103
[Epoch 40; Iter   987/ 1097] train: loss: 0.0145525
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0031687
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0003428
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0091008
[Epoch 40] ogbg-molhiv: 0.783390 val loss: 0.219274
[Epoch 40] ogbg-molhiv: 0.762690 test loss: 0.237444
[Epoch 41; Iter    10/ 1097] train: loss: 0.0065776
[Epoch 41; Iter    40/ 1097] train: loss: 0.0002718
[Epoch 41; Iter    70/ 1097] train: loss: 0.0024625
[Epoch 41; Iter   100/ 1097] train: loss: 0.0004147
[Epoch 41; Iter   130/ 1097] train: loss: 0.0385994
[Epoch 41; Iter   160/ 1097] train: loss: 0.0028215
[Epoch 41; Iter   190/ 1097] train: loss: 0.0009721
[Epoch 41; Iter   220/ 1097] train: loss: 0.0001805
[Epoch 41; Iter   250/ 1097] train: loss: 0.0050417
[Epoch 41; Iter   280/ 1097] train: loss: 0.0024599
[Epoch 41; Iter   310/ 1097] train: loss: 0.0146666
[Epoch 41; Iter   340/ 1097] train: loss: 0.0232403
[Epoch 41; Iter   370/ 1097] train: loss: 0.0010124
[Epoch 41; Iter   400/ 1097] train: loss: 0.0125463
[Epoch 41; Iter   430/ 1097] train: loss: 0.0026323
[Epoch 41; Iter   460/ 1097] train: loss: 0.1115490
[Epoch 41; Iter   490/ 1097] train: loss: 0.0763414
[Epoch 41; Iter   520/ 1097] train: loss: 0.0001720
[Epoch 41; Iter   550/ 1097] train: loss: 0.0043767
[Epoch 41; Iter   580/ 1097] train: loss: 0.0968112
[Epoch 41; Iter   610/ 1097] train: loss: 0.0050979
[Epoch 41; Iter   640/ 1097] train: loss: 0.0346919
[Epoch 41; Iter   670/ 1097] train: loss: 0.0006225
[Epoch 41; Iter   700/ 1097] train: loss: 0.0116236
[Epoch 41; Iter   730/ 1097] train: loss: 0.0032715
[Epoch 41; Iter   760/ 1097] train: loss: 0.0264794
[Epoch 41; Iter   790/ 1097] train: loss: 0.0400242
[Epoch 41; Iter   820/ 1097] train: loss: 0.0104622
[Epoch 41; Iter   850/ 1097] train: loss: 0.0035502
[Epoch 41; Iter   880/ 1097] train: loss: 0.0044512
[Epoch 41; Iter   910/ 1097] train: loss: 0.0164393
[Epoch 41; Iter   940/ 1097] train: loss: 0.0015205
[Epoch 41; Iter   970/ 1097] train: loss: 0.1403050
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0134627
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0027212
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0176255
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0063854
[Epoch 41] ogbg-molhiv: 0.800075 val loss: 0.215125
[Epoch 41] ogbg-molhiv: 0.810825 test loss: 0.243512
[Epoch 42; Iter    23/ 1097] train: loss: 0.0169458
[Epoch 42; Iter    53/ 1097] train: loss: 0.0887122
[Epoch 42; Iter    83/ 1097] train: loss: 0.0031947
[Epoch 42; Iter   113/ 1097] train: loss: 0.0018269
[Epoch 42; Iter   143/ 1097] train: loss: 0.0043583
[Epoch 42; Iter   173/ 1097] train: loss: 0.1153930
[Epoch 42; Iter   203/ 1097] train: loss: 0.0111244
[Epoch 42; Iter   233/ 1097] train: loss: 0.0003050
[Epoch 42; Iter   263/ 1097] train: loss: 0.0166522
[Epoch 42; Iter   293/ 1097] train: loss: 0.0937162
[Epoch 42; Iter   323/ 1097] train: loss: 0.0005548
[Epoch 42; Iter   353/ 1097] train: loss: 0.0036238
[Epoch 42; Iter   383/ 1097] train: loss: 0.0038201
[Epoch 42; Iter   413/ 1097] train: loss: 0.0021939
[Epoch 42; Iter   443/ 1097] train: loss: 0.0192511
[Epoch 42; Iter   473/ 1097] train: loss: 0.0009437
[Epoch 42; Iter   503/ 1097] train: loss: 0.0048653
[Epoch 42; Iter   533/ 1097] train: loss: 0.0161267
[Epoch 42; Iter   563/ 1097] train: loss: 0.0002715
[Epoch 42; Iter   593/ 1097] train: loss: 0.0125187
[Epoch 42; Iter   623/ 1097] train: loss: 0.0020919
[Epoch 42; Iter   653/ 1097] train: loss: 0.1771599
[Epoch 42; Iter   683/ 1097] train: loss: 0.0002942
[Epoch 42; Iter   713/ 1097] train: loss: 0.0003456
[Epoch 42; Iter   743/ 1097] train: loss: 0.0092526
[Epoch 42; Iter   773/ 1097] train: loss: 0.0732636
[Epoch 42; Iter   803/ 1097] train: loss: 0.0273149
[Epoch 42; Iter   833/ 1097] train: loss: 0.0067085
[Epoch 42; Iter   863/ 1097] train: loss: 0.0232164
[Epoch 42; Iter   893/ 1097] train: loss: 0.0070617
[Epoch 42; Iter   923/ 1097] train: loss: 0.0025304
[Epoch 42; Iter   953/ 1097] train: loss: 0.0702756
[Epoch 42; Iter   983/ 1097] train: loss: 0.0196463
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0014391
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0063221
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0054111
[Epoch 42] ogbg-molhiv: 0.785754 val loss: 0.215441
[Epoch 42] ogbg-molhiv: 0.800435 test loss: 0.254008
[Epoch 43; Iter     6/ 1097] train: loss: 0.0878647
[Epoch 43; Iter    36/ 1097] train: loss: 0.0007859
[Epoch 43; Iter    66/ 1097] train: loss: 0.0166583
[Epoch 43; Iter    96/ 1097] train: loss: 0.0065321
[Epoch 43; Iter   126/ 1097] train: loss: 0.0054329
[Epoch 43; Iter   156/ 1097] train: loss: 0.0161714
[Epoch 43; Iter   186/ 1097] train: loss: 0.0057754
[Epoch 43; Iter   216/ 1097] train: loss: 0.0035405
[Epoch 43; Iter   246/ 1097] train: loss: 0.0378395
[Epoch 43; Iter   276/ 1097] train: loss: 0.0074158
[Epoch 43; Iter   306/ 1097] train: loss: 0.0022821
[Epoch 43; Iter   336/ 1097] train: loss: 0.0002358
[Epoch 43; Iter   366/ 1097] train: loss: 0.0021766
[Epoch 43; Iter   396/ 1097] train: loss: 0.1619167
[Epoch 43; Iter   426/ 1097] train: loss: 0.0007809
[Epoch 43; Iter   456/ 1097] train: loss: 0.0034949
[Epoch 43; Iter   486/ 1097] train: loss: 0.0098882
[Epoch 43; Iter   516/ 1097] train: loss: 0.0006590
[Epoch 43; Iter   546/ 1097] train: loss: 0.0205801
[Epoch 43; Iter   576/ 1097] train: loss: 0.0433399
[Epoch 43; Iter   606/ 1097] train: loss: 0.0004807
[Epoch 43; Iter   636/ 1097] train: loss: 0.0126686
[Epoch 43; Iter   666/ 1097] train: loss: 0.0935684
[Epoch 43; Iter   696/ 1097] train: loss: 0.0517917
[Epoch 43; Iter   726/ 1097] train: loss: 0.0007581
[Epoch 43; Iter   756/ 1097] train: loss: 0.0333894
[Epoch 43; Iter   786/ 1097] train: loss: 0.0059475
[Epoch 43; Iter   816/ 1097] train: loss: 0.0016955
[Epoch 43; Iter   846/ 1097] train: loss: 0.0003357
[Epoch 43; Iter   876/ 1097] train: loss: 0.0101918
[Epoch 43; Iter   906/ 1097] train: loss: 0.0017078
[Epoch 43; Iter   936/ 1097] train: loss: 0.0063034
[Epoch 43; Iter   966/ 1097] train: loss: 0.0007689
[Epoch 43; Iter   996/ 1097] train: loss: 0.0016120
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0350950
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0318104
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0008378
[Epoch 43] ogbg-molhiv: 0.776375 val loss: 0.188738
[Epoch 43] ogbg-molhiv: 0.812634 test loss: 0.217256
[Epoch 44; Iter    19/ 1097] train: loss: 0.0004218
[Epoch 44; Iter    49/ 1097] train: loss: 0.0050507
[Epoch 44; Iter    79/ 1097] train: loss: 0.0111038
[Epoch 44; Iter   109/ 1097] train: loss: 0.0010006
[Epoch 44; Iter   139/ 1097] train: loss: 0.0000476
[Epoch 44; Iter   169/ 1097] train: loss: 0.0018611
[Epoch 44; Iter   199/ 1097] train: loss: 0.0011865
[Epoch 44; Iter   229/ 1097] train: loss: 0.0003374
[Epoch 44; Iter   259/ 1097] train: loss: 0.0250568
[Epoch 44; Iter   289/ 1097] train: loss: 0.0006409
[Epoch 44; Iter   319/ 1097] train: loss: 0.1016704
[Epoch 44; Iter   349/ 1097] train: loss: 0.0026605
[Epoch 44; Iter   379/ 1097] train: loss: 0.0006008
[Epoch 44; Iter   409/ 1097] train: loss: 0.0749684
[Epoch 44; Iter   439/ 1097] train: loss: 0.0005865
[Epoch 44; Iter   469/ 1097] train: loss: 0.0017504
[Epoch 44; Iter   499/ 1097] train: loss: 0.0004920
[Epoch 44; Iter   529/ 1097] train: loss: 0.0383665
[Epoch 44; Iter   559/ 1097] train: loss: 0.0004990
[Epoch 44; Iter   589/ 1097] train: loss: 0.0020152
[Epoch 44; Iter   619/ 1097] train: loss: 0.0002728
[Epoch 44; Iter   649/ 1097] train: loss: 0.0012175
[Epoch 44; Iter   679/ 1097] train: loss: 0.0301951
[Epoch 44; Iter   709/ 1097] train: loss: 0.0033157
[Epoch 44; Iter   739/ 1097] train: loss: 0.0021181
[Epoch 40; Iter   687/ 1097] train: loss: 0.0017369
[Epoch 40; Iter   717/ 1097] train: loss: 0.0017910
[Epoch 40; Iter   747/ 1097] train: loss: 0.0022584
[Epoch 40; Iter   777/ 1097] train: loss: 0.0218170
[Epoch 40; Iter   807/ 1097] train: loss: 0.0006948
[Epoch 40; Iter   837/ 1097] train: loss: 0.0004027
[Epoch 40; Iter   867/ 1097] train: loss: 0.0001892
[Epoch 40; Iter   897/ 1097] train: loss: 0.0006330
[Epoch 40; Iter   927/ 1097] train: loss: 0.0002319
[Epoch 40; Iter   957/ 1097] train: loss: 0.0035264
[Epoch 40; Iter   987/ 1097] train: loss: 0.0076352
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0025999
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0076855
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1413012
[Epoch 40] ogbg-molhiv: 0.714745 val loss: 7.993288
[Epoch 40] ogbg-molhiv: 0.624077 test loss: 11.017086
[Epoch 41; Iter    10/ 1097] train: loss: 0.0131465
[Epoch 41; Iter    40/ 1097] train: loss: 0.0038137
[Epoch 41; Iter    70/ 1097] train: loss: 0.0024254
[Epoch 41; Iter   100/ 1097] train: loss: 0.0002446
[Epoch 41; Iter   130/ 1097] train: loss: 0.0001384
[Epoch 41; Iter   160/ 1097] train: loss: 0.0452955
[Epoch 41; Iter   190/ 1097] train: loss: 0.0034569
[Epoch 41; Iter   220/ 1097] train: loss: 0.0002339
[Epoch 41; Iter   250/ 1097] train: loss: 0.0003136
[Epoch 41; Iter   280/ 1097] train: loss: 0.0592891
[Epoch 41; Iter   310/ 1097] train: loss: 0.0007413
[Epoch 41; Iter   340/ 1097] train: loss: 0.0045741
[Epoch 41; Iter   370/ 1097] train: loss: 0.0012173
[Epoch 41; Iter   400/ 1097] train: loss: 0.0054875
[Epoch 41; Iter   430/ 1097] train: loss: 0.0004365
[Epoch 41; Iter   460/ 1097] train: loss: 0.0093695
[Epoch 41; Iter   490/ 1097] train: loss: 0.0010480
[Epoch 41; Iter   520/ 1097] train: loss: 0.0019378
[Epoch 41; Iter   550/ 1097] train: loss: 0.0039952
[Epoch 41; Iter   580/ 1097] train: loss: 0.0003831
[Epoch 41; Iter   610/ 1097] train: loss: 0.0030111
[Epoch 41; Iter   640/ 1097] train: loss: 0.0004193
[Epoch 41; Iter   670/ 1097] train: loss: 0.0015448
[Epoch 41; Iter   700/ 1097] train: loss: 0.0038202
[Epoch 41; Iter   730/ 1097] train: loss: 0.0003418
[Epoch 41; Iter   760/ 1097] train: loss: 0.0393484
[Epoch 41; Iter   790/ 1097] train: loss: 0.0014483
[Epoch 41; Iter   820/ 1097] train: loss: 0.0035914
[Epoch 41; Iter   850/ 1097] train: loss: 0.1636571
[Epoch 41; Iter   880/ 1097] train: loss: 0.0003654
[Epoch 41; Iter   910/ 1097] train: loss: 0.0001931
[Epoch 41; Iter   940/ 1097] train: loss: 0.0008298
[Epoch 41; Iter   970/ 1097] train: loss: 0.0006545
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0083494
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0002216
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0017753
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0724565
[Epoch 41] ogbg-molhiv: 0.680271 val loss: 10.882269
[Epoch 41] ogbg-molhiv: 0.580650 test loss: 15.041039
[Epoch 42; Iter    23/ 1097] train: loss: 0.0000197
[Epoch 42; Iter    53/ 1097] train: loss: 0.0004450
[Epoch 42; Iter    83/ 1097] train: loss: 0.0018281
[Epoch 42; Iter   113/ 1097] train: loss: 0.0002617
[Epoch 42; Iter   143/ 1097] train: loss: 0.0013174
[Epoch 42; Iter   173/ 1097] train: loss: 0.0078327
[Epoch 42; Iter   203/ 1097] train: loss: 0.0071380
[Epoch 42; Iter   233/ 1097] train: loss: 0.0001198
[Epoch 42; Iter   263/ 1097] train: loss: 0.0001715
[Epoch 42; Iter   293/ 1097] train: loss: 0.0003640
[Epoch 42; Iter   323/ 1097] train: loss: 0.0033816
[Epoch 42; Iter   353/ 1097] train: loss: 0.0001459
[Epoch 42; Iter   383/ 1097] train: loss: 0.0041155
[Epoch 42; Iter   413/ 1097] train: loss: 0.0003669
[Epoch 42; Iter   443/ 1097] train: loss: 0.0102421
[Epoch 42; Iter   473/ 1097] train: loss: 0.0012273
[Epoch 42; Iter   503/ 1097] train: loss: 0.0040787
[Epoch 42; Iter   533/ 1097] train: loss: 0.0473507
[Epoch 42; Iter   563/ 1097] train: loss: 0.0456576
[Epoch 42; Iter   593/ 1097] train: loss: 0.0003378
[Epoch 42; Iter   623/ 1097] train: loss: 0.0021669
[Epoch 42; Iter   653/ 1097] train: loss: 0.0000411
[Epoch 42; Iter   683/ 1097] train: loss: 0.0040902
[Epoch 42; Iter   713/ 1097] train: loss: 0.0061648
[Epoch 42; Iter   743/ 1097] train: loss: 0.0005982
[Epoch 42; Iter   773/ 1097] train: loss: 0.0387554
[Epoch 42; Iter   803/ 1097] train: loss: 0.0333723
[Epoch 42; Iter   833/ 1097] train: loss: 0.0033324
[Epoch 42; Iter   863/ 1097] train: loss: 0.0011780
[Epoch 42; Iter   893/ 1097] train: loss: 0.0078284
[Epoch 42; Iter   923/ 1097] train: loss: 0.0004812
[Epoch 42; Iter   953/ 1097] train: loss: 0.0028331
[Epoch 42; Iter   983/ 1097] train: loss: 0.0010192
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0638346
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0004810
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0015928
[Epoch 42] ogbg-molhiv: 0.653807 val loss: 28.452650
[Epoch 42] ogbg-molhiv: 0.572738 test loss: 35.482678
[Epoch 43; Iter     6/ 1097] train: loss: 0.0020128
[Epoch 43; Iter    36/ 1097] train: loss: 0.0003124
[Epoch 43; Iter    66/ 1097] train: loss: 0.0828943
[Epoch 43; Iter    96/ 1097] train: loss: 0.0008059
[Epoch 43; Iter   126/ 1097] train: loss: 0.0024463
[Epoch 43; Iter   156/ 1097] train: loss: 0.0000422
[Epoch 43; Iter   186/ 1097] train: loss: 0.0429862
[Epoch 43; Iter   216/ 1097] train: loss: 0.0054205
[Epoch 43; Iter   246/ 1097] train: loss: 0.1398627
[Epoch 43; Iter   276/ 1097] train: loss: 0.0013162
[Epoch 43; Iter   306/ 1097] train: loss: 0.0011640
[Epoch 43; Iter   336/ 1097] train: loss: 0.0000313
[Epoch 43; Iter   366/ 1097] train: loss: 0.0014477
[Epoch 43; Iter   396/ 1097] train: loss: 0.0003115
[Epoch 43; Iter   426/ 1097] train: loss: 0.0002908
[Epoch 43; Iter   456/ 1097] train: loss: 0.0002594
[Epoch 43; Iter   486/ 1097] train: loss: 0.0003383
[Epoch 43; Iter   516/ 1097] train: loss: 0.0000816
[Epoch 43; Iter   546/ 1097] train: loss: 0.0005424
[Epoch 43; Iter   576/ 1097] train: loss: 0.0480177
[Epoch 43; Iter   606/ 1097] train: loss: 0.0336923
[Epoch 43; Iter   636/ 1097] train: loss: 0.0002357
[Epoch 43; Iter   666/ 1097] train: loss: 0.0001800
[Epoch 43; Iter   696/ 1097] train: loss: 0.0003103
[Epoch 43; Iter   726/ 1097] train: loss: 0.0005858
[Epoch 43; Iter   756/ 1097] train: loss: 0.0003313
[Epoch 43; Iter   786/ 1097] train: loss: 0.0247974
[Epoch 43; Iter   816/ 1097] train: loss: 0.0015755
[Epoch 43; Iter   846/ 1097] train: loss: 0.0000688
[Epoch 43; Iter   876/ 1097] train: loss: 0.0010311
[Epoch 43; Iter   906/ 1097] train: loss: 0.0003353
[Epoch 43; Iter   936/ 1097] train: loss: 0.0007196
[Epoch 43; Iter   966/ 1097] train: loss: 0.0019303
[Epoch 43; Iter   996/ 1097] train: loss: 0.0007950
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0028139
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1195392
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0004704
[Epoch 43] ogbg-molhiv: 0.670298 val loss: 1.105657
[Epoch 43] ogbg-molhiv: 0.586991 test loss: 1.508725
[Epoch 44; Iter    19/ 1097] train: loss: 0.0039286
[Epoch 44; Iter    49/ 1097] train: loss: 0.0003981
[Epoch 44; Iter    79/ 1097] train: loss: 0.0001265
[Epoch 44; Iter   109/ 1097] train: loss: 0.0642993
[Epoch 44; Iter   139/ 1097] train: loss: 0.0034314
[Epoch 44; Iter   169/ 1097] train: loss: 0.0004649
[Epoch 44; Iter   199/ 1097] train: loss: 0.0076788
[Epoch 44; Iter   229/ 1097] train: loss: 0.0033648
[Epoch 44; Iter   259/ 1097] train: loss: 0.0011968
[Epoch 44; Iter   289/ 1097] train: loss: 0.0610937
[Epoch 44; Iter   319/ 1097] train: loss: 0.0048016
[Epoch 44; Iter   349/ 1097] train: loss: 0.0273998
[Epoch 44; Iter   379/ 1097] train: loss: 0.0006214
[Epoch 44; Iter   409/ 1097] train: loss: 0.0408310
[Epoch 44; Iter   439/ 1097] train: loss: 0.0007261
[Epoch 44; Iter   469/ 1097] train: loss: 0.0953008
[Epoch 44; Iter   499/ 1097] train: loss: 0.0089989
[Epoch 44; Iter   529/ 1097] train: loss: 0.0194352
[Epoch 44; Iter   559/ 1097] train: loss: 0.0089087
[Epoch 44; Iter   589/ 1097] train: loss: 0.0024866
[Epoch 44; Iter   619/ 1097] train: loss: 0.0016844
[Epoch 44; Iter   649/ 1097] train: loss: 0.0001387
[Epoch 44; Iter   679/ 1097] train: loss: 0.0138442
[Epoch 44; Iter   709/ 1097] train: loss: 0.0018359
[Epoch 44; Iter   739/ 1097] train: loss: 0.0015175
[Epoch 40; Iter   687/ 1097] train: loss: 0.0274868
[Epoch 40; Iter   717/ 1097] train: loss: 0.0482262
[Epoch 40; Iter   747/ 1097] train: loss: 0.2215390
[Epoch 40; Iter   777/ 1097] train: loss: 0.0045300
[Epoch 40; Iter   807/ 1097] train: loss: 0.0550260
[Epoch 40; Iter   837/ 1097] train: loss: 0.0406138
[Epoch 40; Iter   867/ 1097] train: loss: 0.0031161
[Epoch 40; Iter   897/ 1097] train: loss: 0.0007118
[Epoch 40; Iter   927/ 1097] train: loss: 0.0085866
[Epoch 40; Iter   957/ 1097] train: loss: 0.0177960
[Epoch 40; Iter   987/ 1097] train: loss: 0.0281974
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0062493
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0139096
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0638705
[Epoch 40] ogbg-molhiv: 0.764336 val loss: 0.221808
[Epoch 40] ogbg-molhiv: 0.718844 test loss: 0.309356
[Epoch 41; Iter    10/ 1097] train: loss: 0.0049178
[Epoch 41; Iter    40/ 1097] train: loss: 0.0003849
[Epoch 41; Iter    70/ 1097] train: loss: 0.0032348
[Epoch 41; Iter   100/ 1097] train: loss: 0.0022617
[Epoch 41; Iter   130/ 1097] train: loss: 0.0471406
[Epoch 41; Iter   160/ 1097] train: loss: 0.2082875
[Epoch 41; Iter   190/ 1097] train: loss: 0.0640655
[Epoch 41; Iter   220/ 1097] train: loss: 0.0010099
[Epoch 41; Iter   250/ 1097] train: loss: 0.0047068
[Epoch 41; Iter   280/ 1097] train: loss: 0.0013532
[Epoch 41; Iter   310/ 1097] train: loss: 0.0309651
[Epoch 41; Iter   340/ 1097] train: loss: 0.1191372
[Epoch 41; Iter   370/ 1097] train: loss: 0.0168853
[Epoch 41; Iter   400/ 1097] train: loss: 0.0368885
[Epoch 41; Iter   430/ 1097] train: loss: 0.0160977
[Epoch 41; Iter   460/ 1097] train: loss: 0.0149031
[Epoch 41; Iter   490/ 1097] train: loss: 0.0747990
[Epoch 41; Iter   520/ 1097] train: loss: 0.0035522
[Epoch 41; Iter   550/ 1097] train: loss: 0.1120863
[Epoch 41; Iter   580/ 1097] train: loss: 0.0189215
[Epoch 41; Iter   610/ 1097] train: loss: 0.0225731
[Epoch 41; Iter   640/ 1097] train: loss: 0.0251975
[Epoch 41; Iter   670/ 1097] train: loss: 0.0071181
[Epoch 41; Iter   700/ 1097] train: loss: 0.0213256
[Epoch 41; Iter   730/ 1097] train: loss: 0.0308894
[Epoch 41; Iter   760/ 1097] train: loss: 0.0267660
[Epoch 41; Iter   790/ 1097] train: loss: 0.1475456
[Epoch 41; Iter   820/ 1097] train: loss: 0.0066791
[Epoch 41; Iter   850/ 1097] train: loss: 0.0147107
[Epoch 41; Iter   880/ 1097] train: loss: 0.0039493
[Epoch 41; Iter   910/ 1097] train: loss: 0.0406232
[Epoch 41; Iter   940/ 1097] train: loss: 0.0038321
[Epoch 41; Iter   970/ 1097] train: loss: 0.0094482
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0110038
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0051194
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0835798
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0649747
[Epoch 41] ogbg-molhiv: 0.773653 val loss: 0.528927
[Epoch 41] ogbg-molhiv: 0.710162 test loss: 0.618522
[Epoch 42; Iter    23/ 1097] train: loss: 0.0478278
[Epoch 42; Iter    53/ 1097] train: loss: 0.0243789
[Epoch 42; Iter    83/ 1097] train: loss: 0.0155033
[Epoch 42; Iter   113/ 1097] train: loss: 0.0130055
[Epoch 42; Iter   143/ 1097] train: loss: 0.0171410
[Epoch 42; Iter   173/ 1097] train: loss: 0.0010859
[Epoch 42; Iter   203/ 1097] train: loss: 0.0343267
[Epoch 42; Iter   233/ 1097] train: loss: 0.0100136
[Epoch 42; Iter   263/ 1097] train: loss: 0.1542383
[Epoch 42; Iter   293/ 1097] train: loss: 0.0452583
[Epoch 42; Iter   323/ 1097] train: loss: 0.0034922
[Epoch 42; Iter   353/ 1097] train: loss: 0.0026201
[Epoch 42; Iter   383/ 1097] train: loss: 0.0088003
[Epoch 42; Iter   413/ 1097] train: loss: 0.0524438
[Epoch 42; Iter   443/ 1097] train: loss: 0.0322323
[Epoch 42; Iter   473/ 1097] train: loss: 0.0044111
[Epoch 42; Iter   503/ 1097] train: loss: 0.0307039
[Epoch 42; Iter   533/ 1097] train: loss: 0.0662624
[Epoch 42; Iter   563/ 1097] train: loss: 0.0041355
[Epoch 42; Iter   593/ 1097] train: loss: 0.0052465
[Epoch 42; Iter   623/ 1097] train: loss: 0.0107961
[Epoch 42; Iter   653/ 1097] train: loss: 0.1099824
[Epoch 42; Iter   683/ 1097] train: loss: 0.0200490
[Epoch 42; Iter   713/ 1097] train: loss: 0.0049280
[Epoch 42; Iter   743/ 1097] train: loss: 0.0072954
[Epoch 42; Iter   773/ 1097] train: loss: 0.1045024
[Epoch 42; Iter   803/ 1097] train: loss: 0.0442369
[Epoch 42; Iter   833/ 1097] train: loss: 0.0062322
[Epoch 42; Iter   863/ 1097] train: loss: 0.0009054
[Epoch 42; Iter   893/ 1097] train: loss: 0.0176309
[Epoch 42; Iter   923/ 1097] train: loss: 0.0149861
[Epoch 42; Iter   953/ 1097] train: loss: 0.1365877
[Epoch 42; Iter   983/ 1097] train: loss: 0.0069579
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0599785
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0242632
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0082117
[Epoch 42] ogbg-molhiv: 0.766216 val loss: 2.500461
[Epoch 42] ogbg-molhiv: 0.711039 test loss: 4.617709
[Epoch 43; Iter     6/ 1097] train: loss: 0.0211586
[Epoch 43; Iter    36/ 1097] train: loss: 0.0006929
[Epoch 43; Iter    66/ 1097] train: loss: 0.0295983
[Epoch 43; Iter    96/ 1097] train: loss: 0.0167923
[Epoch 43; Iter   126/ 1097] train: loss: 0.0017773
[Epoch 43; Iter   156/ 1097] train: loss: 0.0032288
[Epoch 43; Iter   186/ 1097] train: loss: 0.0019598
[Epoch 43; Iter   216/ 1097] train: loss: 0.0293197
[Epoch 43; Iter   246/ 1097] train: loss: 0.0777317
[Epoch 43; Iter   276/ 1097] train: loss: 0.0047493
[Epoch 43; Iter   306/ 1097] train: loss: 0.0021788
[Epoch 43; Iter   336/ 1097] train: loss: 0.0013842
[Epoch 43; Iter   366/ 1097] train: loss: 0.0049767
[Epoch 43; Iter   396/ 1097] train: loss: 0.1002419
[Epoch 43; Iter   426/ 1097] train: loss: 0.0089619
[Epoch 43; Iter   456/ 1097] train: loss: 0.0009824
[Epoch 43; Iter   486/ 1097] train: loss: 0.0003580
[Epoch 43; Iter   516/ 1097] train: loss: 0.0044827
[Epoch 43; Iter   546/ 1097] train: loss: 0.0021351
[Epoch 43; Iter   576/ 1097] train: loss: 0.0177543
[Epoch 43; Iter   606/ 1097] train: loss: 0.1154704
[Epoch 43; Iter   636/ 1097] train: loss: 0.0009264
[Epoch 43; Iter   666/ 1097] train: loss: 0.0237058
[Epoch 43; Iter   696/ 1097] train: loss: 0.0163370
[Epoch 43; Iter   726/ 1097] train: loss: 0.1027047
[Epoch 43; Iter   756/ 1097] train: loss: 0.0870698
[Epoch 43; Iter   786/ 1097] train: loss: 0.0011102
[Epoch 43; Iter   816/ 1097] train: loss: 0.0529148
[Epoch 43; Iter   846/ 1097] train: loss: 0.0012413
[Epoch 43; Iter   876/ 1097] train: loss: 0.0055740
[Epoch 43; Iter   906/ 1097] train: loss: 0.0098357
[Epoch 43; Iter   936/ 1097] train: loss: 0.0041960
[Epoch 43; Iter   966/ 1097] train: loss: 0.0197558
[Epoch 43; Iter   996/ 1097] train: loss: 0.0117253
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0060283
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0560502
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0085810
[Epoch 43] ogbg-molhiv: 0.775494 val loss: 3.073385
[Epoch 43] ogbg-molhiv: 0.696958 test loss: 5.522361
[Epoch 44; Iter    19/ 1097] train: loss: 0.0066486
[Epoch 44; Iter    49/ 1097] train: loss: 0.0072593
[Epoch 44; Iter    79/ 1097] train: loss: 0.0093888
[Epoch 44; Iter   109/ 1097] train: loss: 0.0021060
[Epoch 44; Iter   139/ 1097] train: loss: 0.0010581
[Epoch 44; Iter   169/ 1097] train: loss: 0.0539671
[Epoch 44; Iter   199/ 1097] train: loss: 0.0102563
[Epoch 44; Iter   229/ 1097] train: loss: 0.0042389
[Epoch 44; Iter   259/ 1097] train: loss: 0.0113271
[Epoch 44; Iter   289/ 1097] train: loss: 0.0006006
[Epoch 44; Iter   319/ 1097] train: loss: 0.1350856
[Epoch 44; Iter   349/ 1097] train: loss: 0.0095904
[Epoch 44; Iter   379/ 1097] train: loss: 0.0010236
[Epoch 44; Iter   409/ 1097] train: loss: 0.0382630
[Epoch 44; Iter   439/ 1097] train: loss: 0.0333128
[Epoch 44; Iter   469/ 1097] train: loss: 0.0217329
[Epoch 44; Iter   499/ 1097] train: loss: 0.0017810
[Epoch 44; Iter   529/ 1097] train: loss: 0.0029836
[Epoch 44; Iter   559/ 1097] train: loss: 0.0009888
[Epoch 44; Iter   589/ 1097] train: loss: 0.0555990
[Epoch 44; Iter   619/ 1097] train: loss: 0.0008676
[Epoch 44; Iter   649/ 1097] train: loss: 0.0049851
[Epoch 44; Iter   679/ 1097] train: loss: 0.0235557
[Epoch 44; Iter   709/ 1097] train: loss: 0.0210059
[Epoch 44; Iter   739/ 1097] train: loss: 0.0227919
[Epoch 40; Iter   687/ 1097] train: loss: 0.0562691
[Epoch 40; Iter   717/ 1097] train: loss: 0.0080944
[Epoch 40; Iter   747/ 1097] train: loss: 0.0402164
[Epoch 40; Iter   777/ 1097] train: loss: 0.2068228
[Epoch 40; Iter   807/ 1097] train: loss: 0.0014510
[Epoch 40; Iter   837/ 1097] train: loss: 0.0010031
[Epoch 40; Iter   867/ 1097] train: loss: 0.0002094
[Epoch 40; Iter   897/ 1097] train: loss: 0.0343472
[Epoch 40; Iter   927/ 1097] train: loss: 0.0094858
[Epoch 40; Iter   957/ 1097] train: loss: 0.0025054
[Epoch 40; Iter   987/ 1097] train: loss: 0.0000780
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0003990
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0248904
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0006733
[Epoch 40] ogbg-molhiv: 0.682971 val loss: 92.499385
[Epoch 40] ogbg-molhiv: 0.585569 test loss: 95.843433
[Epoch 41; Iter    10/ 1097] train: loss: 0.0008696
[Epoch 41; Iter    40/ 1097] train: loss: 0.0011000
[Epoch 41; Iter    70/ 1097] train: loss: 0.0007115
[Epoch 41; Iter   100/ 1097] train: loss: 0.0005023
[Epoch 41; Iter   130/ 1097] train: loss: 0.0007763
[Epoch 41; Iter   160/ 1097] train: loss: 0.0133120
[Epoch 41; Iter   190/ 1097] train: loss: 0.0002780
[Epoch 41; Iter   220/ 1097] train: loss: 0.0057436
[Epoch 41; Iter   250/ 1097] train: loss: 0.0029523
[Epoch 41; Iter   280/ 1097] train: loss: 0.0014346
[Epoch 41; Iter   310/ 1097] train: loss: 0.0036923
[Epoch 41; Iter   340/ 1097] train: loss: 0.0024391
[Epoch 41; Iter   370/ 1097] train: loss: 0.0604329
[Epoch 41; Iter   400/ 1097] train: loss: 0.0064141
[Epoch 41; Iter   430/ 1097] train: loss: 0.0070098
[Epoch 41; Iter   460/ 1097] train: loss: 0.0015675
[Epoch 41; Iter   490/ 1097] train: loss: 0.0346323
[Epoch 41; Iter   520/ 1097] train: loss: 0.0040322
[Epoch 41; Iter   550/ 1097] train: loss: 0.1050268
[Epoch 41; Iter   580/ 1097] train: loss: 0.0006833
[Epoch 41; Iter   610/ 1097] train: loss: 0.0046929
[Epoch 41; Iter   640/ 1097] train: loss: 0.0025898
[Epoch 41; Iter   670/ 1097] train: loss: 0.0039645
[Epoch 41; Iter   700/ 1097] train: loss: 0.0092975
[Epoch 41; Iter   730/ 1097] train: loss: 0.0021839
[Epoch 41; Iter   760/ 1097] train: loss: 0.0022863
[Epoch 41; Iter   790/ 1097] train: loss: 0.0107149
[Epoch 41; Iter   820/ 1097] train: loss: 0.0008070
[Epoch 41; Iter   850/ 1097] train: loss: 0.0028041
[Epoch 41; Iter   880/ 1097] train: loss: 0.0003978
[Epoch 41; Iter   910/ 1097] train: loss: 0.0001610
[Epoch 41; Iter   940/ 1097] train: loss: 0.0125629
[Epoch 41; Iter   970/ 1097] train: loss: 0.0003400
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0257052
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0013565
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0064713
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0058092
[Epoch 41] ogbg-molhiv: 0.701028 val loss: 72.624633
[Epoch 41] ogbg-molhiv: 0.598818 test loss: 72.068548
[Epoch 42; Iter    23/ 1097] train: loss: 0.0018970
[Epoch 42; Iter    53/ 1097] train: loss: 0.0006663
[Epoch 42; Iter    83/ 1097] train: loss: 0.0190942
[Epoch 42; Iter   113/ 1097] train: loss: 0.0006263
[Epoch 42; Iter   143/ 1097] train: loss: 0.0055753
[Epoch 42; Iter   173/ 1097] train: loss: 0.0039511
[Epoch 42; Iter   203/ 1097] train: loss: 0.0094443
[Epoch 42; Iter   233/ 1097] train: loss: 0.0067589
[Epoch 42; Iter   263/ 1097] train: loss: 0.0458645
[Epoch 42; Iter   293/ 1097] train: loss: 0.0001498
[Epoch 42; Iter   323/ 1097] train: loss: 0.0099655
[Epoch 42; Iter   353/ 1097] train: loss: 0.0015064
[Epoch 42; Iter   383/ 1097] train: loss: 0.0001610
[Epoch 42; Iter   413/ 1097] train: loss: 0.0099437
[Epoch 42; Iter   443/ 1097] train: loss: 0.0009969
[Epoch 42; Iter   473/ 1097] train: loss: 0.0035281
[Epoch 42; Iter   503/ 1097] train: loss: 0.0250186
[Epoch 42; Iter   533/ 1097] train: loss: 0.0475466
[Epoch 42; Iter   563/ 1097] train: loss: 0.0003936
[Epoch 42; Iter   593/ 1097] train: loss: 0.0060198
[Epoch 42; Iter   623/ 1097] train: loss: 0.0003658
[Epoch 42; Iter   653/ 1097] train: loss: 0.0131746
[Epoch 42; Iter   683/ 1097] train: loss: 0.0019049
[Epoch 42; Iter   713/ 1097] train: loss: 0.0148739
[Epoch 42; Iter   743/ 1097] train: loss: 0.0917503
[Epoch 42; Iter   773/ 1097] train: loss: 0.0022785
[Epoch 42; Iter   803/ 1097] train: loss: 0.0005625
[Epoch 42; Iter   833/ 1097] train: loss: 0.0261666
[Epoch 42; Iter   863/ 1097] train: loss: 0.0002133
[Epoch 42; Iter   893/ 1097] train: loss: 0.0027117
[Epoch 42; Iter   923/ 1097] train: loss: 0.0365207
[Epoch 42; Iter   953/ 1097] train: loss: 0.0051011
[Epoch 42; Iter   983/ 1097] train: loss: 0.0003133
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0007208
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1106106
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0009339
[Epoch 42] ogbg-molhiv: 0.682503 val loss: 86.312561
[Epoch 42] ogbg-molhiv: 0.589809 test loss: 85.168696
[Epoch 43; Iter     6/ 1097] train: loss: 0.0090398
[Epoch 43; Iter    36/ 1097] train: loss: 0.0031988
[Epoch 43; Iter    66/ 1097] train: loss: 0.0014603
[Epoch 43; Iter    96/ 1097] train: loss: 0.0018263
[Epoch 43; Iter   126/ 1097] train: loss: 0.0120381
[Epoch 43; Iter   156/ 1097] train: loss: 0.0011522
[Epoch 43; Iter   186/ 1097] train: loss: 0.0005757
[Epoch 43; Iter   216/ 1097] train: loss: 0.0083145
[Epoch 43; Iter   246/ 1097] train: loss: 0.0067095
[Epoch 43; Iter   276/ 1097] train: loss: 0.0080685
[Epoch 43; Iter   306/ 1097] train: loss: 0.0275467
[Epoch 43; Iter   336/ 1097] train: loss: 0.0030021
[Epoch 43; Iter   366/ 1097] train: loss: 0.0014168
[Epoch 43; Iter   396/ 1097] train: loss: 0.0016440
[Epoch 43; Iter   426/ 1097] train: loss: 0.0010026
[Epoch 43; Iter   456/ 1097] train: loss: 0.0046727
[Epoch 43; Iter   486/ 1097] train: loss: 0.0063551
[Epoch 43; Iter   516/ 1097] train: loss: 0.0002510
[Epoch 43; Iter   546/ 1097] train: loss: 0.0004747
[Epoch 43; Iter   576/ 1097] train: loss: 0.0044769
[Epoch 43; Iter   606/ 1097] train: loss: 0.0023109
[Epoch 43; Iter   636/ 1097] train: loss: 0.0059713
[Epoch 43; Iter   666/ 1097] train: loss: 0.0022761
[Epoch 43; Iter   696/ 1097] train: loss: 0.0041605
[Epoch 43; Iter   726/ 1097] train: loss: 0.0006400
[Epoch 43; Iter   756/ 1097] train: loss: 0.0004614
[Epoch 43; Iter   786/ 1097] train: loss: 0.0136414
[Epoch 43; Iter   816/ 1097] train: loss: 0.0093390
[Epoch 43; Iter   846/ 1097] train: loss: 0.0002034
[Epoch 43; Iter   876/ 1097] train: loss: 0.0023985
[Epoch 43; Iter   906/ 1097] train: loss: 0.0035860
[Epoch 43; Iter   936/ 1097] train: loss: 0.0005341
[Epoch 43; Iter   966/ 1097] train: loss: 0.0015048
[Epoch 43; Iter   996/ 1097] train: loss: 0.0006825
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0008542
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0565925
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0005398
[Epoch 43] ogbg-molhiv: 0.702136 val loss: 82.334883
[Epoch 43] ogbg-molhiv: 0.577611 test loss: 81.826391
[Epoch 44; Iter    19/ 1097] train: loss: 0.0005223
[Epoch 44; Iter    49/ 1097] train: loss: 0.0002588
[Epoch 44; Iter    79/ 1097] train: loss: 0.0015977
[Epoch 44; Iter   109/ 1097] train: loss: 0.0004665
[Epoch 44; Iter   139/ 1097] train: loss: 0.0003760
[Epoch 44; Iter   169/ 1097] train: loss: 0.0001117
[Epoch 44; Iter   199/ 1097] train: loss: 0.0009695
[Epoch 44; Iter   229/ 1097] train: loss: 0.0061420
[Epoch 44; Iter   259/ 1097] train: loss: 0.0007486
[Epoch 44; Iter   289/ 1097] train: loss: 0.0027692
[Epoch 44; Iter   319/ 1097] train: loss: 0.0000799
[Epoch 44; Iter   349/ 1097] train: loss: 0.0001634
[Epoch 44; Iter   379/ 1097] train: loss: 0.0004206
[Epoch 44; Iter   409/ 1097] train: loss: 0.0012782
[Epoch 44; Iter   439/ 1097] train: loss: 0.0001579
[Epoch 44; Iter   469/ 1097] train: loss: 0.0055455
[Epoch 44; Iter   499/ 1097] train: loss: 0.1152786
[Epoch 44; Iter   529/ 1097] train: loss: 0.0004077
[Epoch 44; Iter   559/ 1097] train: loss: 0.0009002
[Epoch 44; Iter   589/ 1097] train: loss: 0.0005849
[Epoch 44; Iter   619/ 1097] train: loss: 0.0001684
[Epoch 44; Iter   649/ 1097] train: loss: 0.0065856
[Epoch 44; Iter   679/ 1097] train: loss: 0.0255505
[Epoch 44; Iter   709/ 1097] train: loss: 0.0015235
[Epoch 44; Iter   739/ 1097] train: loss: 0.0166098
[Epoch 44; Iter   769/ 1097] train: loss: 0.0001944
[Epoch 44; Iter   799/ 1097] train: loss: 0.0343052
[Epoch 44; Iter   829/ 1097] train: loss: 0.0050607
[Epoch 44; Iter   859/ 1097] train: loss: 0.0008764
[Epoch 44; Iter   889/ 1097] train: loss: 0.0044863
[Epoch 44; Iter   919/ 1097] train: loss: 0.0069010
[Epoch 44; Iter   949/ 1097] train: loss: 0.0050275
[Epoch 44; Iter   979/ 1097] train: loss: 0.0061119
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0032096
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0027545
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0031513
[Epoch 44] ogbg-molhiv: 0.752943 val loss: 0.199518
[Epoch 44] ogbg-molhiv: 0.731634 test loss: 0.331277
[Epoch 45; Iter     2/ 1097] train: loss: 0.0059900
[Epoch 45; Iter    32/ 1097] train: loss: 0.0056394
[Epoch 45; Iter    62/ 1097] train: loss: 0.0024919
[Epoch 45; Iter    92/ 1097] train: loss: 0.0051947
[Epoch 45; Iter   122/ 1097] train: loss: 0.0035372
[Epoch 45; Iter   152/ 1097] train: loss: 0.0017753
[Epoch 45; Iter   182/ 1097] train: loss: 0.0003021
[Epoch 45; Iter   212/ 1097] train: loss: 0.0505193
[Epoch 45; Iter   242/ 1097] train: loss: 0.0004714
[Epoch 45; Iter   272/ 1097] train: loss: 0.0005010
[Epoch 45; Iter   302/ 1097] train: loss: 0.0005647
[Epoch 45; Iter   332/ 1097] train: loss: 0.0013448
[Epoch 45; Iter   362/ 1097] train: loss: 0.0328641
[Epoch 45; Iter   392/ 1097] train: loss: 0.2190443
[Epoch 45; Iter   422/ 1097] train: loss: 0.0575027
[Epoch 45; Iter   452/ 1097] train: loss: 0.0121401
[Epoch 45; Iter   482/ 1097] train: loss: 0.0029109
[Epoch 45; Iter   512/ 1097] train: loss: 0.0096632
[Epoch 45; Iter   542/ 1097] train: loss: 0.0008551
[Epoch 45; Iter   572/ 1097] train: loss: 0.0206394
[Epoch 45; Iter   602/ 1097] train: loss: 0.0060166
[Epoch 45; Iter   632/ 1097] train: loss: 0.0004805
[Epoch 45; Iter   662/ 1097] train: loss: 0.0033566
[Epoch 45; Iter   692/ 1097] train: loss: 0.0374533
[Epoch 45; Iter   722/ 1097] train: loss: 0.0076672
[Epoch 45; Iter   752/ 1097] train: loss: 0.0013906
[Epoch 45; Iter   782/ 1097] train: loss: 0.0015159
[Epoch 45; Iter   812/ 1097] train: loss: 0.0002796
[Epoch 45; Iter   842/ 1097] train: loss: 0.0028149
[Epoch 45; Iter   872/ 1097] train: loss: 0.0113605
[Epoch 45; Iter   902/ 1097] train: loss: 0.0157768
[Epoch 45; Iter   932/ 1097] train: loss: 0.1822348
[Epoch 45; Iter   962/ 1097] train: loss: 0.0005999
[Epoch 45; Iter   992/ 1097] train: loss: 0.0359046
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0240654
[Epoch 45; Iter  1052/ 1097] train: loss: 0.1903518
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0144514
[Epoch 45] ogbg-molhiv: 0.712498 val loss: 0.178648
[Epoch 45] ogbg-molhiv: 0.717758 test loss: 0.303083
[Epoch 46; Iter    15/ 1097] train: loss: 0.0106238
[Epoch 46; Iter    45/ 1097] train: loss: 0.0036501
[Epoch 46; Iter    75/ 1097] train: loss: 0.0050316
[Epoch 46; Iter   105/ 1097] train: loss: 0.0035081
[Epoch 46; Iter   135/ 1097] train: loss: 0.0017322
[Epoch 46; Iter   165/ 1097] train: loss: 0.0030738
[Epoch 46; Iter   195/ 1097] train: loss: 0.0020013
[Epoch 46; Iter   225/ 1097] train: loss: 0.0051003
[Epoch 46; Iter   255/ 1097] train: loss: 0.0004083
[Epoch 46; Iter   285/ 1097] train: loss: 0.0011104
[Epoch 46; Iter   315/ 1097] train: loss: 0.0020192
[Epoch 46; Iter   345/ 1097] train: loss: 0.0200900
[Epoch 46; Iter   375/ 1097] train: loss: 0.0127344
[Epoch 46; Iter   405/ 1097] train: loss: 0.0010262
[Epoch 46; Iter   435/ 1097] train: loss: 0.0014394
[Epoch 46; Iter   465/ 1097] train: loss: 0.0820308
[Epoch 46; Iter   495/ 1097] train: loss: 0.0003702
[Epoch 46; Iter   525/ 1097] train: loss: 0.0015355
[Epoch 46; Iter   555/ 1097] train: loss: 0.0227686
[Epoch 46; Iter   585/ 1097] train: loss: 0.0012908
[Epoch 46; Iter   615/ 1097] train: loss: 0.0560772
[Epoch 46; Iter   645/ 1097] train: loss: 0.0832742
[Epoch 46; Iter   675/ 1097] train: loss: 0.0013049
[Epoch 46; Iter   705/ 1097] train: loss: 0.0013997
[Epoch 46; Iter   735/ 1097] train: loss: 0.0037780
[Epoch 46; Iter   765/ 1097] train: loss: 0.0013448
[Epoch 46; Iter   795/ 1097] train: loss: 0.0025995
[Epoch 46; Iter   825/ 1097] train: loss: 0.0150234
[Epoch 46; Iter   855/ 1097] train: loss: 0.0024909
[Epoch 46; Iter   885/ 1097] train: loss: 0.0681166
[Epoch 46; Iter   915/ 1097] train: loss: 0.1388490
[Epoch 46; Iter   945/ 1097] train: loss: 0.0277948
[Epoch 46; Iter   975/ 1097] train: loss: 0.0111520
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0233835
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0030495
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0062891
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0032676
[Epoch 46] ogbg-molhiv: 0.683036 val loss: 0.284835
[Epoch 46] ogbg-molhiv: 0.721744 test loss: 0.301039
[Epoch 47; Iter    28/ 1097] train: loss: 0.0013736
[Epoch 47; Iter    58/ 1097] train: loss: 0.0011873
[Epoch 47; Iter    88/ 1097] train: loss: 0.0021452
[Epoch 47; Iter   118/ 1097] train: loss: 0.0015034
[Epoch 47; Iter   148/ 1097] train: loss: 0.0019958
[Epoch 47; Iter   178/ 1097] train: loss: 0.0010472
[Epoch 47; Iter   208/ 1097] train: loss: 0.0024247
[Epoch 47; Iter   238/ 1097] train: loss: 0.0004840
[Epoch 47; Iter   268/ 1097] train: loss: 0.0081528
[Epoch 47; Iter   298/ 1097] train: loss: 0.0019158
[Epoch 47; Iter   328/ 1097] train: loss: 0.0024186
[Epoch 47; Iter   358/ 1097] train: loss: 0.0249978
[Epoch 47; Iter   388/ 1097] train: loss: 0.0237331
[Epoch 47; Iter   418/ 1097] train: loss: 0.0002685
[Epoch 47; Iter   448/ 1097] train: loss: 0.0004279
[Epoch 47; Iter   478/ 1097] train: loss: 0.0011926
[Epoch 47; Iter   508/ 1097] train: loss: 0.0019797
[Epoch 47; Iter   538/ 1097] train: loss: 0.0534468
[Epoch 47; Iter   568/ 1097] train: loss: 0.0003977
[Epoch 47; Iter   598/ 1097] train: loss: 0.0011050
[Epoch 47; Iter   628/ 1097] train: loss: 0.0055972
[Epoch 47; Iter   658/ 1097] train: loss: 0.0004104
[Epoch 47; Iter   688/ 1097] train: loss: 0.0600248
[Epoch 47; Iter   718/ 1097] train: loss: 0.0033884
[Epoch 47; Iter   748/ 1097] train: loss: 0.0119582
[Epoch 47; Iter   778/ 1097] train: loss: 0.0037314
[Epoch 47; Iter   808/ 1097] train: loss: 0.0015427
[Epoch 47; Iter   838/ 1097] train: loss: 0.0771721
[Epoch 47; Iter   868/ 1097] train: loss: 0.0708086
[Epoch 47; Iter   898/ 1097] train: loss: 0.0008566
[Epoch 47; Iter   928/ 1097] train: loss: 0.0021893
[Epoch 47; Iter   958/ 1097] train: loss: 0.0011821
[Epoch 47; Iter   988/ 1097] train: loss: 0.0037296
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0020770
[Epoch 47; Iter  1048/ 1097] train: loss: 0.1230887
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0703462
[Epoch 47] ogbg-molhiv: 0.767015 val loss: 0.175459
[Epoch 47] ogbg-molhiv: 0.750130 test loss: 0.259249
[Epoch 48; Iter    11/ 1097] train: loss: 0.0082585
[Epoch 48; Iter    41/ 1097] train: loss: 0.0727339
[Epoch 48; Iter    71/ 1097] train: loss: 0.0036543
[Epoch 48; Iter   101/ 1097] train: loss: 0.0609165
[Epoch 48; Iter   131/ 1097] train: loss: 0.0009021
[Epoch 48; Iter   161/ 1097] train: loss: 0.0019767
[Epoch 48; Iter   191/ 1097] train: loss: 0.0080702
[Epoch 48; Iter   221/ 1097] train: loss: 0.0017258
[Epoch 48; Iter   251/ 1097] train: loss: 0.0038968
[Epoch 48; Iter   281/ 1097] train: loss: 0.0020813
[Epoch 48; Iter   311/ 1097] train: loss: 0.0022214
[Epoch 48; Iter   341/ 1097] train: loss: 0.0015747
[Epoch 48; Iter   371/ 1097] train: loss: 0.0017624
[Epoch 48; Iter   401/ 1097] train: loss: 0.0025631
[Epoch 48; Iter   431/ 1097] train: loss: 0.0440528
[Epoch 48; Iter   461/ 1097] train: loss: 0.0004945
[Epoch 48; Iter   491/ 1097] train: loss: 0.0006172
[Epoch 48; Iter   521/ 1097] train: loss: 0.0007833
[Epoch 48; Iter   551/ 1097] train: loss: 0.0003679
[Epoch 48; Iter   581/ 1097] train: loss: 0.0489061
[Epoch 48; Iter   611/ 1097] train: loss: 0.0014853
[Epoch 48; Iter   641/ 1097] train: loss: 0.0180778
[Epoch 48; Iter   671/ 1097] train: loss: 0.0022435
[Epoch 48; Iter   701/ 1097] train: loss: 0.0348559
[Epoch 48; Iter   731/ 1097] train: loss: 0.0052649
[Epoch 48; Iter   761/ 1097] train: loss: 0.0019485
[Epoch 48; Iter   791/ 1097] train: loss: 0.0040439
[Epoch 48; Iter   821/ 1097] train: loss: 0.0011444
[Epoch 44; Iter   769/ 1097] train: loss: 0.0084837
[Epoch 44; Iter   799/ 1097] train: loss: 0.0429283
[Epoch 44; Iter   829/ 1097] train: loss: 0.0818000
[Epoch 44; Iter   859/ 1097] train: loss: 0.0052530
[Epoch 44; Iter   889/ 1097] train: loss: 0.0773105
[Epoch 44; Iter   919/ 1097] train: loss: 0.0110730
[Epoch 44; Iter   949/ 1097] train: loss: 0.0993806
[Epoch 44; Iter   979/ 1097] train: loss: 0.0305170
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0367623
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0029937
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0984753
[Epoch 44] ogbg-molhiv: 0.694435 val loss: 0.642945
[Epoch 44] ogbg-molhiv: 0.720186 test loss: 0.379283
[Epoch 45; Iter     2/ 1097] train: loss: 0.0143148
[Epoch 45; Iter    32/ 1097] train: loss: 0.0379746
[Epoch 45; Iter    62/ 1097] train: loss: 0.0057897
[Epoch 45; Iter    92/ 1097] train: loss: 0.0226868
[Epoch 45; Iter   122/ 1097] train: loss: 0.0020934
[Epoch 45; Iter   152/ 1097] train: loss: 0.0072251
[Epoch 45; Iter   182/ 1097] train: loss: 0.0192081
[Epoch 45; Iter   212/ 1097] train: loss: 0.0135377
[Epoch 45; Iter   242/ 1097] train: loss: 0.0004541
[Epoch 45; Iter   272/ 1097] train: loss: 0.0054195
[Epoch 45; Iter   302/ 1097] train: loss: 0.0084412
[Epoch 45; Iter   332/ 1097] train: loss: 0.0048851
[Epoch 45; Iter   362/ 1097] train: loss: 0.1040369
[Epoch 45; Iter   392/ 1097] train: loss: 0.0513350
[Epoch 45; Iter   422/ 1097] train: loss: 0.0020749
[Epoch 45; Iter   452/ 1097] train: loss: 0.0125298
[Epoch 45; Iter   482/ 1097] train: loss: 0.0008196
[Epoch 45; Iter   512/ 1097] train: loss: 0.0206939
[Epoch 45; Iter   542/ 1097] train: loss: 0.0021539
[Epoch 45; Iter   572/ 1097] train: loss: 0.0029921
[Epoch 45; Iter   602/ 1097] train: loss: 0.0835483
[Epoch 45; Iter   632/ 1097] train: loss: 0.0081192
[Epoch 45; Iter   662/ 1097] train: loss: 0.0732209
[Epoch 45; Iter   692/ 1097] train: loss: 0.0045326
[Epoch 45; Iter   722/ 1097] train: loss: 0.0097921
[Epoch 45; Iter   752/ 1097] train: loss: 0.0046238
[Epoch 45; Iter   782/ 1097] train: loss: 0.1213534
[Epoch 45; Iter   812/ 1097] train: loss: 0.0819985
[Epoch 45; Iter   842/ 1097] train: loss: 0.0076729
[Epoch 45; Iter   872/ 1097] train: loss: 0.0038235
[Epoch 45; Iter   902/ 1097] train: loss: 0.0100274
[Epoch 45; Iter   932/ 1097] train: loss: 0.0028465
[Epoch 45; Iter   962/ 1097] train: loss: 0.0085848
[Epoch 45; Iter   992/ 1097] train: loss: 0.0269154
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0201024
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0156789
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0736274
[Epoch 45] ogbg-molhiv: 0.687987 val loss: 0.656292
[Epoch 45] ogbg-molhiv: 0.730485 test loss: 0.452496
[Epoch 46; Iter    15/ 1097] train: loss: 0.0034142
[Epoch 46; Iter    45/ 1097] train: loss: 0.0202934
[Epoch 46; Iter    75/ 1097] train: loss: 0.0090778
[Epoch 46; Iter   105/ 1097] train: loss: 0.0064153
[Epoch 46; Iter   135/ 1097] train: loss: 0.1185781
[Epoch 46; Iter   165/ 1097] train: loss: 0.0036621
[Epoch 46; Iter   195/ 1097] train: loss: 0.0128365
[Epoch 46; Iter   225/ 1097] train: loss: 0.0051746
[Epoch 46; Iter   255/ 1097] train: loss: 0.0249937
[Epoch 46; Iter   285/ 1097] train: loss: 0.0053131
[Epoch 46; Iter   315/ 1097] train: loss: 0.0026120
[Epoch 46; Iter   345/ 1097] train: loss: 0.0616053
[Epoch 46; Iter   375/ 1097] train: loss: 0.0094015
[Epoch 46; Iter   405/ 1097] train: loss: 0.0081098
[Epoch 46; Iter   435/ 1097] train: loss: 0.0019157
[Epoch 46; Iter   465/ 1097] train: loss: 0.0021202
[Epoch 46; Iter   495/ 1097] train: loss: 0.0615225
[Epoch 46; Iter   525/ 1097] train: loss: 0.0170246
[Epoch 46; Iter   555/ 1097] train: loss: 0.0155417
[Epoch 46; Iter   585/ 1097] train: loss: 0.0774588
[Epoch 46; Iter   615/ 1097] train: loss: 0.0082764
[Epoch 46; Iter   645/ 1097] train: loss: 0.0013043
[Epoch 46; Iter   675/ 1097] train: loss: 0.0044819
[Epoch 46; Iter   705/ 1097] train: loss: 0.0047429
[Epoch 46; Iter   735/ 1097] train: loss: 0.0231315
[Epoch 46; Iter   765/ 1097] train: loss: 0.0253569
[Epoch 46; Iter   795/ 1097] train: loss: 0.0018027
[Epoch 46; Iter   825/ 1097] train: loss: 0.0121150
[Epoch 46; Iter   855/ 1097] train: loss: 0.0062147
[Epoch 46; Iter   885/ 1097] train: loss: 0.0067004
[Epoch 46; Iter   915/ 1097] train: loss: 0.0584552
[Epoch 46; Iter   945/ 1097] train: loss: 0.0027855
[Epoch 46; Iter   975/ 1097] train: loss: 0.0031699
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0020349
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0033318
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0105642
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0032726
[Epoch 46] ogbg-molhiv: 0.685574 val loss: 11.440162
[Epoch 46] ogbg-molhiv: 0.695789 test loss: 2.965893
[Epoch 47; Iter    28/ 1097] train: loss: 0.0148259
[Epoch 47; Iter    58/ 1097] train: loss: 0.0026254
[Epoch 47; Iter    88/ 1097] train: loss: 0.0105036
[Epoch 47; Iter   118/ 1097] train: loss: 0.1128084
[Epoch 47; Iter   148/ 1097] train: loss: 0.0113600
[Epoch 47; Iter   178/ 1097] train: loss: 0.0268474
[Epoch 47; Iter   208/ 1097] train: loss: 0.0380987
[Epoch 47; Iter   238/ 1097] train: loss: 0.0958897
[Epoch 47; Iter   268/ 1097] train: loss: 0.0020184
[Epoch 47; Iter   298/ 1097] train: loss: 0.0094763
[Epoch 47; Iter   328/ 1097] train: loss: 0.0072061
[Epoch 47; Iter   358/ 1097] train: loss: 0.0056897
[Epoch 47; Iter   388/ 1097] train: loss: 0.0285495
[Epoch 47; Iter   418/ 1097] train: loss: 0.0171634
[Epoch 47; Iter   448/ 1097] train: loss: 0.0380606
[Epoch 47; Iter   478/ 1097] train: loss: 0.0272489
[Epoch 47; Iter   508/ 1097] train: loss: 0.0597246
[Epoch 47; Iter   538/ 1097] train: loss: 0.0212489
[Epoch 47; Iter   568/ 1097] train: loss: 0.0041534
[Epoch 47; Iter   598/ 1097] train: loss: 0.0713123
[Epoch 47; Iter   628/ 1097] train: loss: 0.0034832
[Epoch 47; Iter   658/ 1097] train: loss: 0.0251429
[Epoch 47; Iter   688/ 1097] train: loss: 0.0184095
[Epoch 47; Iter   718/ 1097] train: loss: 0.0090627
[Epoch 47; Iter   748/ 1097] train: loss: 0.0766404
[Epoch 47; Iter   778/ 1097] train: loss: 0.0224493
[Epoch 47; Iter   808/ 1097] train: loss: 0.1147948
[Epoch 47; Iter   838/ 1097] train: loss: 0.0011215
[Epoch 47; Iter   868/ 1097] train: loss: 0.0077368
[Epoch 47; Iter   898/ 1097] train: loss: 0.0160186
[Epoch 47; Iter   928/ 1097] train: loss: 0.0016486
[Epoch 47; Iter   958/ 1097] train: loss: 0.1880031
[Epoch 47; Iter   988/ 1097] train: loss: 0.0794701
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0069290
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0661655
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0038724
[Epoch 47] ogbg-molhiv: 0.703707 val loss: 0.731615
[Epoch 47] ogbg-molhiv: 0.713571 test loss: 0.380489
[Epoch 48; Iter    11/ 1097] train: loss: 0.0830709
[Epoch 48; Iter    41/ 1097] train: loss: 0.0102293
[Epoch 48; Iter    71/ 1097] train: loss: 0.0019833
[Epoch 48; Iter   101/ 1097] train: loss: 0.0844022
[Epoch 48; Iter   131/ 1097] train: loss: 0.0019290
[Epoch 48; Iter   161/ 1097] train: loss: 0.0034319
[Epoch 48; Iter   191/ 1097] train: loss: 0.0092529
[Epoch 48; Iter   221/ 1097] train: loss: 0.0020742
[Epoch 48; Iter   251/ 1097] train: loss: 0.0056632
[Epoch 48; Iter   281/ 1097] train: loss: 0.0055598
[Epoch 48; Iter   311/ 1097] train: loss: 0.0347841
[Epoch 48; Iter   341/ 1097] train: loss: 0.0025030
[Epoch 48; Iter   371/ 1097] train: loss: 0.0006197
[Epoch 48; Iter   401/ 1097] train: loss: 0.0077043
[Epoch 48; Iter   431/ 1097] train: loss: 0.0156800
[Epoch 48; Iter   461/ 1097] train: loss: 0.0398514
[Epoch 48; Iter   491/ 1097] train: loss: 0.0012650
[Epoch 48; Iter   521/ 1097] train: loss: 0.0007435
[Epoch 48; Iter   551/ 1097] train: loss: 0.0739302
[Epoch 48; Iter   581/ 1097] train: loss: 0.0060322
[Epoch 48; Iter   611/ 1097] train: loss: 0.0142978
[Epoch 48; Iter   641/ 1097] train: loss: 0.0277256
[Epoch 48; Iter   671/ 1097] train: loss: 0.0138609
[Epoch 48; Iter   701/ 1097] train: loss: 0.0171222
[Epoch 48; Iter   731/ 1097] train: loss: 0.0096714
[Epoch 48; Iter   761/ 1097] train: loss: 0.0026687
[Epoch 48; Iter   791/ 1097] train: loss: 0.0082827
[Epoch 48; Iter   821/ 1097] train: loss: 0.0014823
[Epoch 44; Iter   769/ 1097] train: loss: 0.0132334
[Epoch 44; Iter   799/ 1097] train: loss: 0.0239817
[Epoch 44; Iter   829/ 1097] train: loss: 0.0244536
[Epoch 44; Iter   859/ 1097] train: loss: 0.0314992
[Epoch 44; Iter   889/ 1097] train: loss: 0.1181017
[Epoch 44; Iter   919/ 1097] train: loss: 0.0163969
[Epoch 44; Iter   949/ 1097] train: loss: 0.0031749
[Epoch 44; Iter   979/ 1097] train: loss: 0.0046258
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1072516
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0026640
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0053869
[Epoch 44] ogbg-molhiv: 0.762373 val loss: 0.213510
[Epoch 44] ogbg-molhiv: 0.732411 test loss: 0.228588
[Epoch 45; Iter     2/ 1097] train: loss: 0.0192463
[Epoch 45; Iter    32/ 1097] train: loss: 0.0037367
[Epoch 45; Iter    62/ 1097] train: loss: 0.0013932
[Epoch 45; Iter    92/ 1097] train: loss: 0.0350212
[Epoch 45; Iter   122/ 1097] train: loss: 0.0838802
[Epoch 45; Iter   152/ 1097] train: loss: 0.0199454
[Epoch 45; Iter   182/ 1097] train: loss: 0.0068517
[Epoch 45; Iter   212/ 1097] train: loss: 0.2048407
[Epoch 45; Iter   242/ 1097] train: loss: 0.0003290
[Epoch 45; Iter   272/ 1097] train: loss: 0.0058354
[Epoch 45; Iter   302/ 1097] train: loss: 0.1495193
[Epoch 45; Iter   332/ 1097] train: loss: 0.0182881
[Epoch 45; Iter   362/ 1097] train: loss: 0.0006815
[Epoch 45; Iter   392/ 1097] train: loss: 0.0046657
[Epoch 45; Iter   422/ 1097] train: loss: 0.0065452
[Epoch 45; Iter   452/ 1097] train: loss: 0.0014899
[Epoch 45; Iter   482/ 1097] train: loss: 0.0200964
[Epoch 45; Iter   512/ 1097] train: loss: 0.0024458
[Epoch 45; Iter   542/ 1097] train: loss: 0.0019793
[Epoch 45; Iter   572/ 1097] train: loss: 0.0064369
[Epoch 45; Iter   602/ 1097] train: loss: 0.0021122
[Epoch 45; Iter   632/ 1097] train: loss: 0.0237100
[Epoch 45; Iter   662/ 1097] train: loss: 0.0004737
[Epoch 45; Iter   692/ 1097] train: loss: 0.0028906
[Epoch 45; Iter   722/ 1097] train: loss: 0.0784300
[Epoch 45; Iter   752/ 1097] train: loss: 0.0180582
[Epoch 45; Iter   782/ 1097] train: loss: 0.0020397
[Epoch 45; Iter   812/ 1097] train: loss: 0.0002800
[Epoch 45; Iter   842/ 1097] train: loss: 0.0006167
[Epoch 45; Iter   872/ 1097] train: loss: 0.0282467
[Epoch 45; Iter   902/ 1097] train: loss: 0.0004796
[Epoch 45; Iter   932/ 1097] train: loss: 0.0115651
[Epoch 45; Iter   962/ 1097] train: loss: 0.0009855
[Epoch 45; Iter   992/ 1097] train: loss: 0.0152879
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0515557
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0038659
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0007291
[Epoch 45] ogbg-molhiv: 0.760897 val loss: 0.211613
[Epoch 45] ogbg-molhiv: 0.741764 test loss: 0.280568
[Epoch 46; Iter    15/ 1097] train: loss: 0.0037420
[Epoch 46; Iter    45/ 1097] train: loss: 0.0048208
[Epoch 46; Iter    75/ 1097] train: loss: 0.0079644
[Epoch 46; Iter   105/ 1097] train: loss: 0.0058205
[Epoch 46; Iter   135/ 1097] train: loss: 0.0044525
[Epoch 46; Iter   165/ 1097] train: loss: 0.0017884
[Epoch 46; Iter   195/ 1097] train: loss: 0.0063698
[Epoch 46; Iter   225/ 1097] train: loss: 0.0862962
[Epoch 46; Iter   255/ 1097] train: loss: 0.0022090
[Epoch 46; Iter   285/ 1097] train: loss: 0.0061882
[Epoch 46; Iter   315/ 1097] train: loss: 0.0013995
[Epoch 46; Iter   345/ 1097] train: loss: 0.0042171
[Epoch 46; Iter   375/ 1097] train: loss: 0.0008495
[Epoch 46; Iter   405/ 1097] train: loss: 0.0119753
[Epoch 46; Iter   435/ 1097] train: loss: 0.0295873
[Epoch 46; Iter   465/ 1097] train: loss: 0.0060238
[Epoch 46; Iter   495/ 1097] train: loss: 0.0015659
[Epoch 46; Iter   525/ 1097] train: loss: 0.1043211
[Epoch 46; Iter   555/ 1097] train: loss: 0.0103282
[Epoch 46; Iter   585/ 1097] train: loss: 0.0002818
[Epoch 46; Iter   615/ 1097] train: loss: 0.0034621
[Epoch 46; Iter   645/ 1097] train: loss: 0.0026384
[Epoch 46; Iter   675/ 1097] train: loss: 0.2123370
[Epoch 46; Iter   705/ 1097] train: loss: 0.0198974
[Epoch 46; Iter   735/ 1097] train: loss: 0.0148740
[Epoch 46; Iter   765/ 1097] train: loss: 0.0969929
[Epoch 46; Iter   795/ 1097] train: loss: 0.0576406
[Epoch 46; Iter   825/ 1097] train: loss: 0.0173877
[Epoch 46; Iter   855/ 1097] train: loss: 0.0868452
[Epoch 46; Iter   885/ 1097] train: loss: 0.0025308
[Epoch 46; Iter   915/ 1097] train: loss: 0.0088684
[Epoch 46; Iter   945/ 1097] train: loss: 0.0029369
[Epoch 46; Iter   975/ 1097] train: loss: 0.0408058
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0084907
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0116332
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0005706
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0051173
[Epoch 46] ogbg-molhiv: 0.770193 val loss: 0.232206
[Epoch 46] ogbg-molhiv: 0.756197 test loss: 0.248255
[Epoch 47; Iter    28/ 1097] train: loss: 0.0374434
[Epoch 47; Iter    58/ 1097] train: loss: 0.0015958
[Epoch 47; Iter    88/ 1097] train: loss: 0.0574206
[Epoch 47; Iter   118/ 1097] train: loss: 0.0016697
[Epoch 47; Iter   148/ 1097] train: loss: 0.0054144
[Epoch 47; Iter   178/ 1097] train: loss: 0.0046236
[Epoch 47; Iter   208/ 1097] train: loss: 0.0095758
[Epoch 47; Iter   238/ 1097] train: loss: 0.0009319
[Epoch 47; Iter   268/ 1097] train: loss: 0.0051045
[Epoch 47; Iter   298/ 1097] train: loss: 0.0015581
[Epoch 47; Iter   328/ 1097] train: loss: 0.0127730
[Epoch 47; Iter   358/ 1097] train: loss: 0.0343707
[Epoch 47; Iter   388/ 1097] train: loss: 0.0340677
[Epoch 47; Iter   418/ 1097] train: loss: 0.0015456
[Epoch 47; Iter   448/ 1097] train: loss: 0.0481928
[Epoch 47; Iter   478/ 1097] train: loss: 0.0548638
[Epoch 47; Iter   508/ 1097] train: loss: 0.0478118
[Epoch 47; Iter   538/ 1097] train: loss: 0.0079391
[Epoch 47; Iter   568/ 1097] train: loss: 0.0011278
[Epoch 47; Iter   598/ 1097] train: loss: 0.0209873
[Epoch 47; Iter   628/ 1097] train: loss: 0.0007901
[Epoch 47; Iter   658/ 1097] train: loss: 0.0523890
[Epoch 47; Iter   688/ 1097] train: loss: 0.0030283
[Epoch 47; Iter   718/ 1097] train: loss: 0.0165445
[Epoch 47; Iter   748/ 1097] train: loss: 0.0002753
[Epoch 47; Iter   778/ 1097] train: loss: 0.0493618
[Epoch 47; Iter   808/ 1097] train: loss: 0.0004242
[Epoch 47; Iter   838/ 1097] train: loss: 0.0076314
[Epoch 47; Iter   868/ 1097] train: loss: 0.0015227
[Epoch 47; Iter   898/ 1097] train: loss: 0.0036809
[Epoch 47; Iter   928/ 1097] train: loss: 0.0004617
[Epoch 47; Iter   958/ 1097] train: loss: 0.0037109
[Epoch 47; Iter   988/ 1097] train: loss: 0.0016105
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0027149
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0017683
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0723464
[Epoch 47] ogbg-molhiv: 0.775944 val loss: 0.237956
[Epoch 47] ogbg-molhiv: 0.762496 test loss: 0.249005
[Epoch 48; Iter    11/ 1097] train: loss: 0.0048961
[Epoch 48; Iter    41/ 1097] train: loss: 0.0031412
[Epoch 48; Iter    71/ 1097] train: loss: 0.0010033
[Epoch 48; Iter   101/ 1097] train: loss: 0.0119197
[Epoch 48; Iter   131/ 1097] train: loss: 0.0113457
[Epoch 48; Iter   161/ 1097] train: loss: 0.0001852
[Epoch 48; Iter   191/ 1097] train: loss: 0.0226869
[Epoch 48; Iter   221/ 1097] train: loss: 0.0082463
[Epoch 48; Iter   251/ 1097] train: loss: 0.0021815
[Epoch 48; Iter   281/ 1097] train: loss: 0.0037594
[Epoch 48; Iter   311/ 1097] train: loss: 0.0237917
[Epoch 48; Iter   341/ 1097] train: loss: 0.0388981
[Epoch 48; Iter   371/ 1097] train: loss: 0.0053769
[Epoch 48; Iter   401/ 1097] train: loss: 0.0492669
[Epoch 48; Iter   431/ 1097] train: loss: 0.0007271
[Epoch 48; Iter   461/ 1097] train: loss: 0.0038076
[Epoch 48; Iter   491/ 1097] train: loss: 0.0258180
[Epoch 48; Iter   521/ 1097] train: loss: 0.0028019
[Epoch 48; Iter   551/ 1097] train: loss: 0.0005184
[Epoch 48; Iter   581/ 1097] train: loss: 0.0020658
[Epoch 48; Iter   611/ 1097] train: loss: 0.0012077
[Epoch 48; Iter   641/ 1097] train: loss: 0.0023919
[Epoch 48; Iter   671/ 1097] train: loss: 0.0019592
[Epoch 48; Iter   701/ 1097] train: loss: 0.0005237
[Epoch 48; Iter   731/ 1097] train: loss: 0.0013346
[Epoch 48; Iter   761/ 1097] train: loss: 0.0745275
[Epoch 48; Iter   791/ 1097] train: loss: 0.0148292
[Epoch 48; Iter   821/ 1097] train: loss: 0.0353043
[Epoch 36; Iter   605/ 1097] train: loss: 0.1786170
[Epoch 36; Iter   635/ 1097] train: loss: 0.2629267
[Epoch 36; Iter   665/ 1097] train: loss: 0.0497893
[Epoch 36; Iter   695/ 1097] train: loss: 0.0184152
[Epoch 36; Iter   725/ 1097] train: loss: 0.1371168
[Epoch 36; Iter   755/ 1097] train: loss: 0.0214635
[Epoch 36; Iter   785/ 1097] train: loss: 0.0806892
[Epoch 36; Iter   815/ 1097] train: loss: 0.1393802
[Epoch 36; Iter   845/ 1097] train: loss: 0.1044789
[Epoch 36; Iter   875/ 1097] train: loss: 0.0427057
[Epoch 36; Iter   905/ 1097] train: loss: 0.0426379
[Epoch 36; Iter   935/ 1097] train: loss: 0.0502420
[Epoch 36; Iter   965/ 1097] train: loss: 0.0761369
[Epoch 36; Iter   995/ 1097] train: loss: 0.0318942
[Epoch 36; Iter  1025/ 1097] train: loss: 0.2841747
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0444281
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0161586
[Epoch 36] ogbg-molhiv: 0.846031 val loss: 0.076518
[Epoch 36] ogbg-molhiv: 0.753338 test loss: 0.132270
[Epoch 37; Iter    18/ 1097] train: loss: 0.0419383
[Epoch 37; Iter    48/ 1097] train: loss: 0.0212161
[Epoch 37; Iter    78/ 1097] train: loss: 0.0610578
[Epoch 37; Iter   108/ 1097] train: loss: 0.1120768
[Epoch 37; Iter   138/ 1097] train: loss: 0.0302942
[Epoch 37; Iter   168/ 1097] train: loss: 0.1469840
[Epoch 37; Iter   198/ 1097] train: loss: 0.0455700
[Epoch 37; Iter   228/ 1097] train: loss: 0.0295229
[Epoch 37; Iter   258/ 1097] train: loss: 0.1867337
[Epoch 37; Iter   288/ 1097] train: loss: 0.0966942
[Epoch 37; Iter   318/ 1097] train: loss: 0.0307448
[Epoch 37; Iter   348/ 1097] train: loss: 0.1097034
[Epoch 37; Iter   378/ 1097] train: loss: 0.0208215
[Epoch 37; Iter   408/ 1097] train: loss: 0.0321047
[Epoch 37; Iter   438/ 1097] train: loss: 0.0096596
[Epoch 37; Iter   468/ 1097] train: loss: 0.1373528
[Epoch 37; Iter   498/ 1097] train: loss: 0.0110543
[Epoch 37; Iter   528/ 1097] train: loss: 0.3174600
[Epoch 37; Iter   558/ 1097] train: loss: 0.3279251
[Epoch 37; Iter   588/ 1097] train: loss: 0.0083895
[Epoch 37; Iter   618/ 1097] train: loss: 0.0448870
[Epoch 37; Iter   648/ 1097] train: loss: 0.0752184
[Epoch 37; Iter   678/ 1097] train: loss: 0.0141055
[Epoch 37; Iter   708/ 1097] train: loss: 0.0681039
[Epoch 37; Iter   738/ 1097] train: loss: 0.1671371
[Epoch 37; Iter   768/ 1097] train: loss: 0.0415356
[Epoch 37; Iter   798/ 1097] train: loss: 0.0814449
[Epoch 37; Iter   828/ 1097] train: loss: 0.0362685
[Epoch 37; Iter   858/ 1097] train: loss: 0.1789389
[Epoch 37; Iter   888/ 1097] train: loss: 0.0085254
[Epoch 37; Iter   918/ 1097] train: loss: 0.1470701
[Epoch 37; Iter   948/ 1097] train: loss: 0.0103839
[Epoch 37; Iter   978/ 1097] train: loss: 0.0160564
[Epoch 37; Iter  1008/ 1097] train: loss: 0.1492562
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0529022
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0624969
[Epoch 37] ogbg-molhiv: 0.830425 val loss: 0.079147
[Epoch 37] ogbg-molhiv: 0.746702 test loss: 0.136416
[Epoch 38; Iter     1/ 1097] train: loss: 0.1223586
[Epoch 38; Iter    31/ 1097] train: loss: 0.0099191
[Epoch 38; Iter    61/ 1097] train: loss: 0.1156407
[Epoch 38; Iter    91/ 1097] train: loss: 0.0521942
[Epoch 38; Iter   121/ 1097] train: loss: 0.0163668
[Epoch 38; Iter   151/ 1097] train: loss: 0.0182452
[Epoch 38; Iter   181/ 1097] train: loss: 0.0281791
[Epoch 38; Iter   211/ 1097] train: loss: 0.0115717
[Epoch 38; Iter   241/ 1097] train: loss: 0.0147641
[Epoch 38; Iter   271/ 1097] train: loss: 0.0360593
[Epoch 38; Iter   301/ 1097] train: loss: 0.0215398
[Epoch 38; Iter   331/ 1097] train: loss: 0.0440567
[Epoch 38; Iter   361/ 1097] train: loss: 0.1492504
[Epoch 38; Iter   391/ 1097] train: loss: 0.0994946
[Epoch 38; Iter   421/ 1097] train: loss: 0.1516779
[Epoch 38; Iter   451/ 1097] train: loss: 0.0328127
[Epoch 38; Iter   481/ 1097] train: loss: 0.1903128
[Epoch 38; Iter   511/ 1097] train: loss: 0.0854459
[Epoch 38; Iter   541/ 1097] train: loss: 0.1617170
[Epoch 38; Iter   571/ 1097] train: loss: 0.0088022
[Epoch 38; Iter   601/ 1097] train: loss: 0.1544884
[Epoch 38; Iter   631/ 1097] train: loss: 0.0739206
[Epoch 38; Iter   661/ 1097] train: loss: 0.0654540
[Epoch 38; Iter   691/ 1097] train: loss: 0.0187673
[Epoch 38; Iter   721/ 1097] train: loss: 0.1598186
[Epoch 38; Iter   751/ 1097] train: loss: 0.1552791
[Epoch 38; Iter   781/ 1097] train: loss: 0.0583304
[Epoch 38; Iter   811/ 1097] train: loss: 0.1449498
[Epoch 38; Iter   841/ 1097] train: loss: 0.0190906
[Epoch 38; Iter   871/ 1097] train: loss: 0.0143902
[Epoch 38; Iter   901/ 1097] train: loss: 0.0144169
[Epoch 38; Iter   931/ 1097] train: loss: 0.0399274
[Epoch 38; Iter   961/ 1097] train: loss: 0.0799575
[Epoch 38; Iter   991/ 1097] train: loss: 0.1754728
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0093376
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0487672
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0987433
[Epoch 38] ogbg-molhiv: 0.833652 val loss: 0.082116
[Epoch 38] ogbg-molhiv: 0.741370 test loss: 0.147267
[Epoch 39; Iter    14/ 1097] train: loss: 0.0914220
[Epoch 39; Iter    44/ 1097] train: loss: 0.1356660
[Epoch 39; Iter    74/ 1097] train: loss: 0.0320939
[Epoch 39; Iter   104/ 1097] train: loss: 0.0563315
[Epoch 39; Iter   134/ 1097] train: loss: 0.1413825
[Epoch 39; Iter   164/ 1097] train: loss: 0.0103496
[Epoch 39; Iter   194/ 1097] train: loss: 0.0171317
[Epoch 39; Iter   224/ 1097] train: loss: 0.0210315
[Epoch 39; Iter   254/ 1097] train: loss: 0.0262475
[Epoch 39; Iter   284/ 1097] train: loss: 0.0159003
[Epoch 39; Iter   314/ 1097] train: loss: 0.0810978
[Epoch 39; Iter   344/ 1097] train: loss: 0.0325638
[Epoch 39; Iter   374/ 1097] train: loss: 0.0345766
[Epoch 39; Iter   404/ 1097] train: loss: 0.0610637
[Epoch 39; Iter   434/ 1097] train: loss: 0.0157364
[Epoch 39; Iter   464/ 1097] train: loss: 0.0401766
[Epoch 39; Iter   494/ 1097] train: loss: 0.0188794
[Epoch 39; Iter   524/ 1097] train: loss: 0.0184480
[Epoch 39; Iter   554/ 1097] train: loss: 0.0304157
[Epoch 39; Iter   584/ 1097] train: loss: 0.0491415
[Epoch 39; Iter   614/ 1097] train: loss: 0.0444690
[Epoch 39; Iter   644/ 1097] train: loss: 0.0784593
[Epoch 39; Iter   674/ 1097] train: loss: 0.0311228
[Epoch 39; Iter   704/ 1097] train: loss: 0.0193216
[Epoch 39; Iter   734/ 1097] train: loss: 0.2690133
[Epoch 39; Iter   764/ 1097] train: loss: 0.0902033
[Epoch 39; Iter   794/ 1097] train: loss: 0.0280195
[Epoch 39; Iter   824/ 1097] train: loss: 0.0171865
[Epoch 39; Iter   854/ 1097] train: loss: 0.1188014
[Epoch 39; Iter   884/ 1097] train: loss: 0.0592343
[Epoch 39; Iter   914/ 1097] train: loss: 0.0277557
[Epoch 39; Iter   944/ 1097] train: loss: 0.0432111
[Epoch 39; Iter   974/ 1097] train: loss: 0.0093633
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0481696
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0298624
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0772080
[Epoch 39; Iter  1094/ 1097] train: loss: 0.2399216
[Epoch 39] ogbg-molhiv: 0.817332 val loss: 0.082272
[Epoch 39] ogbg-molhiv: 0.745399 test loss: 0.136724
[Epoch 40; Iter    27/ 1097] train: loss: 0.0147022
[Epoch 40; Iter    57/ 1097] train: loss: 0.0488613
[Epoch 40; Iter    87/ 1097] train: loss: 0.0266105
[Epoch 40; Iter   117/ 1097] train: loss: 0.1122191
[Epoch 40; Iter   147/ 1097] train: loss: 0.0246579
[Epoch 40; Iter   177/ 1097] train: loss: 0.0953589
[Epoch 40; Iter   207/ 1097] train: loss: 0.1020793
[Epoch 40; Iter   237/ 1097] train: loss: 0.0127117
[Epoch 40; Iter   267/ 1097] train: loss: 0.0149361
[Epoch 40; Iter   297/ 1097] train: loss: 0.1712008
[Epoch 40; Iter   327/ 1097] train: loss: 0.1409993
[Epoch 40; Iter   357/ 1097] train: loss: 0.0204564
[Epoch 40; Iter   387/ 1097] train: loss: 0.0259029
[Epoch 40; Iter   417/ 1097] train: loss: 0.0820381
[Epoch 40; Iter   447/ 1097] train: loss: 0.0980265
[Epoch 40; Iter   477/ 1097] train: loss: 0.0164675
[Epoch 40; Iter   507/ 1097] train: loss: 0.0191704
[Epoch 40; Iter   537/ 1097] train: loss: 0.1438905
[Epoch 40; Iter   567/ 1097] train: loss: 0.0112998
[Epoch 40; Iter   597/ 1097] train: loss: 0.0460348
[Epoch 40; Iter   627/ 1097] train: loss: 0.0404195
[Epoch 40; Iter   657/ 1097] train: loss: 0.0188701
[Epoch 44; Iter   769/ 1097] train: loss: 0.0035873
[Epoch 44; Iter   799/ 1097] train: loss: 0.0036948
[Epoch 44; Iter   829/ 1097] train: loss: 0.0267898
[Epoch 44; Iter   859/ 1097] train: loss: 0.0493697
[Epoch 44; Iter   889/ 1097] train: loss: 0.0005833
[Epoch 44; Iter   919/ 1097] train: loss: 0.0019587
[Epoch 44; Iter   949/ 1097] train: loss: 0.0025028
[Epoch 44; Iter   979/ 1097] train: loss: 0.0002706
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0007458
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0118788
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0476130
[Epoch 44] ogbg-molhiv: 0.760937 val loss: 0.168995
[Epoch 44] ogbg-molhiv: 0.709525 test loss: 0.279266
[Epoch 45; Iter     2/ 1097] train: loss: 0.0060100
[Epoch 45; Iter    32/ 1097] train: loss: 0.0158494
[Epoch 45; Iter    62/ 1097] train: loss: 0.0007520
[Epoch 45; Iter    92/ 1097] train: loss: 0.0010609
[Epoch 45; Iter   122/ 1097] train: loss: 0.0352010
[Epoch 45; Iter   152/ 1097] train: loss: 0.0324723
[Epoch 45; Iter   182/ 1097] train: loss: 0.0123273
[Epoch 45; Iter   212/ 1097] train: loss: 0.0076887
[Epoch 45; Iter   242/ 1097] train: loss: 0.0009041
[Epoch 45; Iter   272/ 1097] train: loss: 0.0049419
[Epoch 45; Iter   302/ 1097] train: loss: 0.0137014
[Epoch 45; Iter   332/ 1097] train: loss: 0.0041110
[Epoch 45; Iter   362/ 1097] train: loss: 0.0051372
[Epoch 45; Iter   392/ 1097] train: loss: 0.0016546
[Epoch 45; Iter   422/ 1097] train: loss: 0.1451342
[Epoch 45; Iter   452/ 1097] train: loss: 0.0001540
[Epoch 45; Iter   482/ 1097] train: loss: 0.0031557
[Epoch 45; Iter   512/ 1097] train: loss: 0.0010070
[Epoch 45; Iter   542/ 1097] train: loss: 0.0002750
[Epoch 45; Iter   572/ 1097] train: loss: 0.0026252
[Epoch 45; Iter   602/ 1097] train: loss: 0.0310602
[Epoch 45; Iter   632/ 1097] train: loss: 0.0003878
[Epoch 45; Iter   662/ 1097] train: loss: 0.0028894
[Epoch 45; Iter   692/ 1097] train: loss: 0.0006608
[Epoch 45; Iter   722/ 1097] train: loss: 0.0005940
[Epoch 45; Iter   752/ 1097] train: loss: 0.0016501
[Epoch 45; Iter   782/ 1097] train: loss: 0.1648876
[Epoch 45; Iter   812/ 1097] train: loss: 0.0061657
[Epoch 45; Iter   842/ 1097] train: loss: 0.0013980
[Epoch 45; Iter   872/ 1097] train: loss: 0.0199404
[Epoch 45; Iter   902/ 1097] train: loss: 0.0055764
[Epoch 45; Iter   932/ 1097] train: loss: 0.0031858
[Epoch 45; Iter   962/ 1097] train: loss: 0.0007950
[Epoch 45; Iter   992/ 1097] train: loss: 0.0005393
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0074762
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0017955
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0094763
[Epoch 45] ogbg-molhiv: 0.751718 val loss: 0.169887
[Epoch 45] ogbg-molhiv: 0.719664 test loss: 0.265947
[Epoch 46; Iter    15/ 1097] train: loss: 0.0231164
[Epoch 46; Iter    45/ 1097] train: loss: 0.0009328
[Epoch 46; Iter    75/ 1097] train: loss: 0.0064803
[Epoch 46; Iter   105/ 1097] train: loss: 0.0211134
[Epoch 46; Iter   135/ 1097] train: loss: 0.0060073
[Epoch 46; Iter   165/ 1097] train: loss: 0.0046845
[Epoch 46; Iter   195/ 1097] train: loss: 0.0072480
[Epoch 46; Iter   225/ 1097] train: loss: 0.0008958
[Epoch 46; Iter   255/ 1097] train: loss: 0.0010366
[Epoch 46; Iter   285/ 1097] train: loss: 0.0115301
[Epoch 46; Iter   315/ 1097] train: loss: 0.0042819
[Epoch 46; Iter   345/ 1097] train: loss: 0.0022807
[Epoch 46; Iter   375/ 1097] train: loss: 0.0056810
[Epoch 46; Iter   405/ 1097] train: loss: 0.0009131
[Epoch 46; Iter   435/ 1097] train: loss: 0.0077011
[Epoch 46; Iter   465/ 1097] train: loss: 0.0069185
[Epoch 46; Iter   495/ 1097] train: loss: 0.0021804
[Epoch 46; Iter   525/ 1097] train: loss: 0.0587519
[Epoch 46; Iter   555/ 1097] train: loss: 0.0118424
[Epoch 46; Iter   585/ 1097] train: loss: 0.0524260
[Epoch 46; Iter   615/ 1097] train: loss: 0.0007127
[Epoch 46; Iter   645/ 1097] train: loss: 0.0006092
[Epoch 46; Iter   675/ 1097] train: loss: 0.0047022
[Epoch 46; Iter   705/ 1097] train: loss: 0.0023415
[Epoch 46; Iter   735/ 1097] train: loss: 0.0034370
[Epoch 46; Iter   765/ 1097] train: loss: 0.0972661
[Epoch 46; Iter   795/ 1097] train: loss: 0.0019856
[Epoch 46; Iter   825/ 1097] train: loss: 0.0133679
[Epoch 46; Iter   855/ 1097] train: loss: 0.0003382
[Epoch 46; Iter   885/ 1097] train: loss: 0.0060709
[Epoch 46; Iter   915/ 1097] train: loss: 0.0024428
[Epoch 46; Iter   945/ 1097] train: loss: 0.0001406
[Epoch 46; Iter   975/ 1097] train: loss: 0.0010231
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0025118
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0050815
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0006167
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0028414
[Epoch 46] ogbg-molhiv: 0.798541 val loss: 0.195826
[Epoch 46] ogbg-molhiv: 0.711462 test loss: 0.289205
[Epoch 47; Iter    28/ 1097] train: loss: 0.0039071
[Epoch 47; Iter    58/ 1097] train: loss: 0.0450444
[Epoch 47; Iter    88/ 1097] train: loss: 0.0264895
[Epoch 47; Iter   118/ 1097] train: loss: 0.0438319
[Epoch 47; Iter   148/ 1097] train: loss: 0.0013610
[Epoch 47; Iter   178/ 1097] train: loss: 0.0001567
[Epoch 47; Iter   208/ 1097] train: loss: 0.0015982
[Epoch 47; Iter   238/ 1097] train: loss: 0.0011061
[Epoch 47; Iter   268/ 1097] train: loss: 0.0090936
[Epoch 47; Iter   298/ 1097] train: loss: 0.0002727
[Epoch 47; Iter   328/ 1097] train: loss: 0.0006453
[Epoch 47; Iter   358/ 1097] train: loss: 0.0013600
[Epoch 47; Iter   388/ 1097] train: loss: 0.0073464
[Epoch 47; Iter   418/ 1097] train: loss: 0.0005610
[Epoch 47; Iter   448/ 1097] train: loss: 0.0005172
[Epoch 47; Iter   478/ 1097] train: loss: 0.0002327
[Epoch 47; Iter   508/ 1097] train: loss: 0.0003279
[Epoch 47; Iter   538/ 1097] train: loss: 0.1220947
[Epoch 47; Iter   568/ 1097] train: loss: 0.0065325
[Epoch 47; Iter   598/ 1097] train: loss: 0.0506821
[Epoch 47; Iter   628/ 1097] train: loss: 0.0006755
[Epoch 47; Iter   658/ 1097] train: loss: 0.0038670
[Epoch 47; Iter   688/ 1097] train: loss: 0.0340822
[Epoch 47; Iter   718/ 1097] train: loss: 0.0705869
[Epoch 47; Iter   748/ 1097] train: loss: 0.0540651
[Epoch 47; Iter   778/ 1097] train: loss: 0.0026564
[Epoch 47; Iter   808/ 1097] train: loss: 0.0030341
[Epoch 47; Iter   838/ 1097] train: loss: 0.0018701
[Epoch 47; Iter   868/ 1097] train: loss: 0.0038701
[Epoch 47; Iter   898/ 1097] train: loss: 0.0032405
[Epoch 47; Iter   928/ 1097] train: loss: 0.0056431
[Epoch 47; Iter   958/ 1097] train: loss: 0.0817577
[Epoch 47; Iter   988/ 1097] train: loss: 0.2599474
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0016273
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0076946
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0011197
[Epoch 47] ogbg-molhiv: 0.794502 val loss: 0.191630
[Epoch 47] ogbg-molhiv: 0.733954 test loss: 0.280262
[Epoch 48; Iter    11/ 1097] train: loss: 0.0054672
[Epoch 48; Iter    41/ 1097] train: loss: 0.0009231
[Epoch 48; Iter    71/ 1097] train: loss: 0.0075971
[Epoch 48; Iter   101/ 1097] train: loss: 0.0506105
[Epoch 48; Iter   131/ 1097] train: loss: 0.0001999
[Epoch 48; Iter   161/ 1097] train: loss: 0.0007406
[Epoch 48; Iter   191/ 1097] train: loss: 0.0012438
[Epoch 48; Iter   221/ 1097] train: loss: 0.0000784
[Epoch 48; Iter   251/ 1097] train: loss: 0.0063405
[Epoch 48; Iter   281/ 1097] train: loss: 0.0087626
[Epoch 48; Iter   311/ 1097] train: loss: 0.0025181
[Epoch 48; Iter   341/ 1097] train: loss: 0.0007360
[Epoch 48; Iter   371/ 1097] train: loss: 0.0002120
[Epoch 48; Iter   401/ 1097] train: loss: 0.0022054
[Epoch 48; Iter   431/ 1097] train: loss: 0.0062187
[Epoch 48; Iter   461/ 1097] train: loss: 0.0421193
[Epoch 48; Iter   491/ 1097] train: loss: 0.0094155
[Epoch 48; Iter   521/ 1097] train: loss: 0.0138317
[Epoch 48; Iter   551/ 1097] train: loss: 0.0009140
[Epoch 48; Iter   581/ 1097] train: loss: 0.0304406
[Epoch 48; Iter   611/ 1097] train: loss: 0.0024479
[Epoch 48; Iter   641/ 1097] train: loss: 0.0027688
[Epoch 48; Iter   671/ 1097] train: loss: 0.0060202
[Epoch 48; Iter   701/ 1097] train: loss: 0.0031633
[Epoch 48; Iter   731/ 1097] train: loss: 0.0011609
[Epoch 48; Iter   761/ 1097] train: loss: 0.0527992
[Epoch 48; Iter   791/ 1097] train: loss: 0.0058683
[Epoch 48; Iter   821/ 1097] train: loss: 0.0150514
[Epoch 44; Iter   769/ 1097] train: loss: 0.0359422
[Epoch 44; Iter   799/ 1097] train: loss: 0.0562277
[Epoch 44; Iter   829/ 1097] train: loss: 0.0042446
[Epoch 44; Iter   859/ 1097] train: loss: 0.0004950
[Epoch 44; Iter   889/ 1097] train: loss: 0.0098730
[Epoch 44; Iter   919/ 1097] train: loss: 0.1591111
[Epoch 44; Iter   949/ 1097] train: loss: 0.0044506
[Epoch 44; Iter   979/ 1097] train: loss: 0.0130485
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1724478
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0048477
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0064476
[Epoch 44] ogbg-molhiv: 0.785393 val loss: 0.164251
[Epoch 44] ogbg-molhiv: 0.703268 test loss: 0.334940
[Epoch 45; Iter     2/ 1097] train: loss: 0.0017404
[Epoch 45; Iter    32/ 1097] train: loss: 0.0050149
[Epoch 45; Iter    62/ 1097] train: loss: 0.0146241
[Epoch 45; Iter    92/ 1097] train: loss: 0.0239262
[Epoch 45; Iter   122/ 1097] train: loss: 0.0408964
[Epoch 45; Iter   152/ 1097] train: loss: 0.0052663
[Epoch 45; Iter   182/ 1097] train: loss: 0.0018505
[Epoch 45; Iter   212/ 1097] train: loss: 0.0312068
[Epoch 45; Iter   242/ 1097] train: loss: 0.0009494
[Epoch 45; Iter   272/ 1097] train: loss: 0.0062029
[Epoch 45; Iter   302/ 1097] train: loss: 0.0007857
[Epoch 45; Iter   332/ 1097] train: loss: 0.0634598
[Epoch 45; Iter   362/ 1097] train: loss: 0.0036250
[Epoch 45; Iter   392/ 1097] train: loss: 0.0012954
[Epoch 45; Iter   422/ 1097] train: loss: 0.0192952
[Epoch 45; Iter   452/ 1097] train: loss: 0.0064721
[Epoch 45; Iter   482/ 1097] train: loss: 0.0079701
[Epoch 45; Iter   512/ 1097] train: loss: 0.0009115
[Epoch 45; Iter   542/ 1097] train: loss: 0.0086734
[Epoch 45; Iter   572/ 1097] train: loss: 0.0621912
[Epoch 45; Iter   602/ 1097] train: loss: 0.0776765
[Epoch 45; Iter   632/ 1097] train: loss: 0.0042866
[Epoch 45; Iter   662/ 1097] train: loss: 0.0018199
[Epoch 45; Iter   692/ 1097] train: loss: 0.0013714
[Epoch 45; Iter   722/ 1097] train: loss: 0.1525775
[Epoch 45; Iter   752/ 1097] train: loss: 0.0470230
[Epoch 45; Iter   782/ 1097] train: loss: 0.0014329
[Epoch 45; Iter   812/ 1097] train: loss: 0.0005142
[Epoch 45; Iter   842/ 1097] train: loss: 0.0001250
[Epoch 45; Iter   872/ 1097] train: loss: 0.0069392
[Epoch 45; Iter   902/ 1097] train: loss: 0.0344272
[Epoch 45; Iter   932/ 1097] train: loss: 0.0080065
[Epoch 45; Iter   962/ 1097] train: loss: 0.0355168
[Epoch 45; Iter   992/ 1097] train: loss: 0.0322690
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0030235
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0028235
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0003991
[Epoch 45] ogbg-molhiv: 0.743019 val loss: 0.193844
[Epoch 45] ogbg-molhiv: 0.701082 test loss: 0.430726
[Epoch 46; Iter    15/ 1097] train: loss: 0.0095055
[Epoch 46; Iter    45/ 1097] train: loss: 0.0096219
[Epoch 46; Iter    75/ 1097] train: loss: 0.0261906
[Epoch 46; Iter   105/ 1097] train: loss: 0.0040893
[Epoch 46; Iter   135/ 1097] train: loss: 0.0227665
[Epoch 46; Iter   165/ 1097] train: loss: 0.0011146
[Epoch 46; Iter   195/ 1097] train: loss: 0.0041239
[Epoch 46; Iter   225/ 1097] train: loss: 0.0214218
[Epoch 46; Iter   255/ 1097] train: loss: 0.0065874
[Epoch 46; Iter   285/ 1097] train: loss: 0.0091288
[Epoch 46; Iter   315/ 1097] train: loss: 0.0006809
[Epoch 46; Iter   345/ 1097] train: loss: 0.0012050
[Epoch 46; Iter   375/ 1097] train: loss: 0.0016684
[Epoch 46; Iter   405/ 1097] train: loss: 0.0031059
[Epoch 46; Iter   435/ 1097] train: loss: 0.0097545
[Epoch 46; Iter   465/ 1097] train: loss: 0.4116984
[Epoch 46; Iter   495/ 1097] train: loss: 0.0006842
[Epoch 46; Iter   525/ 1097] train: loss: 0.0123553
[Epoch 46; Iter   555/ 1097] train: loss: 0.0238781
[Epoch 46; Iter   585/ 1097] train: loss: 0.0342822
[Epoch 46; Iter   615/ 1097] train: loss: 0.0104801
[Epoch 46; Iter   645/ 1097] train: loss: 0.0037412
[Epoch 46; Iter   675/ 1097] train: loss: 0.0044482
[Epoch 46; Iter   705/ 1097] train: loss: 0.0043227
[Epoch 46; Iter   735/ 1097] train: loss: 0.0005406
[Epoch 46; Iter   765/ 1097] train: loss: 0.0061474
[Epoch 46; Iter   795/ 1097] train: loss: 0.1156624
[Epoch 46; Iter   825/ 1097] train: loss: 0.0094696
[Epoch 46; Iter   855/ 1097] train: loss: 0.0050759
[Epoch 46; Iter   885/ 1097] train: loss: 0.0130346
[Epoch 46; Iter   915/ 1097] train: loss: 0.0015338
[Epoch 46; Iter   945/ 1097] train: loss: 0.0026661
[Epoch 46; Iter   975/ 1097] train: loss: 0.0460000
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0021025
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0639224
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0039926
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0054428
[Epoch 46] ogbg-molhiv: 0.745572 val loss: 0.260598
[Epoch 46] ogbg-molhiv: 0.683138 test loss: 0.433065
[Epoch 47; Iter    28/ 1097] train: loss: 0.0013709
[Epoch 47; Iter    58/ 1097] train: loss: 0.0273976
[Epoch 47; Iter    88/ 1097] train: loss: 0.0085963
[Epoch 47; Iter   118/ 1097] train: loss: 0.0050100
[Epoch 47; Iter   148/ 1097] train: loss: 0.0046577
[Epoch 47; Iter   178/ 1097] train: loss: 0.0044548
[Epoch 47; Iter   208/ 1097] train: loss: 0.0284894
[Epoch 47; Iter   238/ 1097] train: loss: 0.0010294
[Epoch 47; Iter   268/ 1097] train: loss: 0.0007909
[Epoch 47; Iter   298/ 1097] train: loss: 0.0296562
[Epoch 47; Iter   328/ 1097] train: loss: 0.0059157
[Epoch 47; Iter   358/ 1097] train: loss: 0.0490793
[Epoch 47; Iter   388/ 1097] train: loss: 0.0512452
[Epoch 47; Iter   418/ 1097] train: loss: 0.0039625
[Epoch 47; Iter   448/ 1097] train: loss: 0.0083396
[Epoch 47; Iter   478/ 1097] train: loss: 0.1074232
[Epoch 47; Iter   508/ 1097] train: loss: 0.0230939
[Epoch 47; Iter   538/ 1097] train: loss: 0.0008094
[Epoch 47; Iter   568/ 1097] train: loss: 0.0073955
[Epoch 47; Iter   598/ 1097] train: loss: 0.0245333
[Epoch 47; Iter   628/ 1097] train: loss: 0.0116411
[Epoch 47; Iter   658/ 1097] train: loss: 0.0043780
[Epoch 47; Iter   688/ 1097] train: loss: 0.0063049
[Epoch 47; Iter   718/ 1097] train: loss: 0.0016965
[Epoch 47; Iter   748/ 1097] train: loss: 0.0002566
[Epoch 47; Iter   778/ 1097] train: loss: 0.0019595
[Epoch 47; Iter   808/ 1097] train: loss: 0.0027530
[Epoch 47; Iter   838/ 1097] train: loss: 0.0729533
[Epoch 47; Iter   868/ 1097] train: loss: 0.0809300
[Epoch 47; Iter   898/ 1097] train: loss: 0.0359079
[Epoch 47; Iter   928/ 1097] train: loss: 0.0044083
[Epoch 47; Iter   958/ 1097] train: loss: 0.0010724
[Epoch 47; Iter   988/ 1097] train: loss: 0.0065383
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0073148
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0119620
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0007142
[Epoch 47] ogbg-molhiv: 0.790154 val loss: 0.209514
[Epoch 47] ogbg-molhiv: 0.729989 test loss: 0.412235
[Epoch 48; Iter    11/ 1097] train: loss: 0.0078442
[Epoch 48; Iter    41/ 1097] train: loss: 0.0026730
[Epoch 48; Iter    71/ 1097] train: loss: 0.0577193
[Epoch 48; Iter   101/ 1097] train: loss: 0.0199898
[Epoch 48; Iter   131/ 1097] train: loss: 0.0011600
[Epoch 48; Iter   161/ 1097] train: loss: 0.0051145
[Epoch 48; Iter   191/ 1097] train: loss: 0.0098779
[Epoch 48; Iter   221/ 1097] train: loss: 0.0013558
[Epoch 48; Iter   251/ 1097] train: loss: 0.0037265
[Epoch 48; Iter   281/ 1097] train: loss: 0.0124689
[Epoch 48; Iter   311/ 1097] train: loss: 0.0016552
[Epoch 48; Iter   341/ 1097] train: loss: 0.0302231
[Epoch 48; Iter   371/ 1097] train: loss: 0.0106256
[Epoch 48; Iter   401/ 1097] train: loss: 0.0164153
[Epoch 48; Iter   431/ 1097] train: loss: 0.0033491
[Epoch 48; Iter   461/ 1097] train: loss: 0.0079244
[Epoch 48; Iter   491/ 1097] train: loss: 0.0110702
[Epoch 48; Iter   521/ 1097] train: loss: 0.0089970
[Epoch 48; Iter   551/ 1097] train: loss: 0.0200944
[Epoch 48; Iter   581/ 1097] train: loss: 0.0276185
[Epoch 48; Iter   611/ 1097] train: loss: 0.0019257
[Epoch 48; Iter   641/ 1097] train: loss: 0.0000857
[Epoch 48; Iter   671/ 1097] train: loss: 0.0065308
[Epoch 48; Iter   701/ 1097] train: loss: 0.0160365
[Epoch 48; Iter   731/ 1097] train: loss: 0.0045115
[Epoch 48; Iter   761/ 1097] train: loss: 0.0396037
[Epoch 48; Iter   791/ 1097] train: loss: 0.0003153
[Epoch 48; Iter   821/ 1097] train: loss: 0.0005449
[Epoch 36; Iter   605/ 1097] train: loss: 0.0196755
[Epoch 36; Iter   635/ 1097] train: loss: 0.0114046
[Epoch 36; Iter   665/ 1097] train: loss: 0.0155725
[Epoch 36; Iter   695/ 1097] train: loss: 0.0922083
[Epoch 36; Iter   725/ 1097] train: loss: 0.0378440
[Epoch 36; Iter   755/ 1097] train: loss: 0.1370899
[Epoch 36; Iter   785/ 1097] train: loss: 0.0147881
[Epoch 36; Iter   815/ 1097] train: loss: 0.0692418
[Epoch 36; Iter   845/ 1097] train: loss: 0.0163236
[Epoch 36; Iter   875/ 1097] train: loss: 0.0110065
[Epoch 36; Iter   905/ 1097] train: loss: 0.0106739
[Epoch 36; Iter   935/ 1097] train: loss: 0.1292349
[Epoch 36; Iter   965/ 1097] train: loss: 0.0691597
[Epoch 36; Iter   995/ 1097] train: loss: 0.0220091
[Epoch 36; Iter  1025/ 1097] train: loss: 0.1083074
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1092507
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0334783
[Epoch 36] ogbg-molhiv: 0.819227 val loss: 0.077017
[Epoch 36] ogbg-molhiv: 0.768410 test loss: 0.132478
[Epoch 37; Iter    18/ 1097] train: loss: 0.0661929
[Epoch 37; Iter    48/ 1097] train: loss: 0.1589206
[Epoch 37; Iter    78/ 1097] train: loss: 0.0277700
[Epoch 37; Iter   108/ 1097] train: loss: 0.0727648
[Epoch 37; Iter   138/ 1097] train: loss: 0.0185678
[Epoch 37; Iter   168/ 1097] train: loss: 0.0764237
[Epoch 37; Iter   198/ 1097] train: loss: 0.0831783
[Epoch 37; Iter   228/ 1097] train: loss: 0.0371205
[Epoch 37; Iter   258/ 1097] train: loss: 0.0175042
[Epoch 37; Iter   288/ 1097] train: loss: 0.0954056
[Epoch 37; Iter   318/ 1097] train: loss: 0.0283333
[Epoch 37; Iter   348/ 1097] train: loss: 0.0582550
[Epoch 37; Iter   378/ 1097] train: loss: 0.0228123
[Epoch 37; Iter   408/ 1097] train: loss: 0.0269438
[Epoch 37; Iter   438/ 1097] train: loss: 0.0195062
[Epoch 37; Iter   468/ 1097] train: loss: 0.0498244
[Epoch 37; Iter   498/ 1097] train: loss: 0.1406311
[Epoch 37; Iter   528/ 1097] train: loss: 0.0351573
[Epoch 37; Iter   558/ 1097] train: loss: 0.0095865
[Epoch 37; Iter   588/ 1097] train: loss: 0.1401646
[Epoch 37; Iter   618/ 1097] train: loss: 0.0372274
[Epoch 37; Iter   648/ 1097] train: loss: 0.0991056
[Epoch 37; Iter   678/ 1097] train: loss: 0.0551293
[Epoch 37; Iter   708/ 1097] train: loss: 0.0098811
[Epoch 37; Iter   738/ 1097] train: loss: 0.0935608
[Epoch 37; Iter   768/ 1097] train: loss: 0.0106871
[Epoch 37; Iter   798/ 1097] train: loss: 0.1440081
[Epoch 37; Iter   828/ 1097] train: loss: 0.0269690
[Epoch 37; Iter   858/ 1097] train: loss: 0.0126342
[Epoch 37; Iter   888/ 1097] train: loss: 0.0551711
[Epoch 37; Iter   918/ 1097] train: loss: 0.0731285
[Epoch 37; Iter   948/ 1097] train: loss: 0.0255593
[Epoch 37; Iter   978/ 1097] train: loss: 0.1633163
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0156501
[Epoch 37; Iter  1038/ 1097] train: loss: 0.1227146
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0407938
[Epoch 37] ogbg-molhiv: 0.828786 val loss: 0.082969
[Epoch 37] ogbg-molhiv: 0.779013 test loss: 0.139105
[Epoch 38; Iter     1/ 1097] train: loss: 0.1508579
[Epoch 38; Iter    31/ 1097] train: loss: 0.0241539
[Epoch 38; Iter    61/ 1097] train: loss: 0.0742163
[Epoch 38; Iter    91/ 1097] train: loss: 0.0202558
[Epoch 38; Iter   121/ 1097] train: loss: 0.1084657
[Epoch 38; Iter   151/ 1097] train: loss: 0.0252991
[Epoch 38; Iter   181/ 1097] train: loss: 0.1025453
[Epoch 38; Iter   211/ 1097] train: loss: 0.0581436
[Epoch 38; Iter   241/ 1097] train: loss: 0.1293885
[Epoch 38; Iter   271/ 1097] train: loss: 0.0594049
[Epoch 38; Iter   301/ 1097] train: loss: 0.1167444
[Epoch 38; Iter   331/ 1097] train: loss: 0.0527857
[Epoch 38; Iter   361/ 1097] train: loss: 0.1572176
[Epoch 38; Iter   391/ 1097] train: loss: 0.0547950
[Epoch 38; Iter   421/ 1097] train: loss: 0.0507052
[Epoch 38; Iter   451/ 1097] train: loss: 0.0582969
[Epoch 38; Iter   481/ 1097] train: loss: 0.1237295
[Epoch 38; Iter   511/ 1097] train: loss: 0.0436843
[Epoch 38; Iter   541/ 1097] train: loss: 0.0324380
[Epoch 38; Iter   571/ 1097] train: loss: 0.0211580
[Epoch 38; Iter   601/ 1097] train: loss: 0.1272858
[Epoch 38; Iter   631/ 1097] train: loss: 0.0288547
[Epoch 38; Iter   661/ 1097] train: loss: 0.0378095
[Epoch 38; Iter   691/ 1097] train: loss: 0.0332523
[Epoch 38; Iter   721/ 1097] train: loss: 0.0604758
[Epoch 38; Iter   751/ 1097] train: loss: 0.0887738
[Epoch 38; Iter   781/ 1097] train: loss: 0.0821626
[Epoch 38; Iter   811/ 1097] train: loss: 0.0587302
[Epoch 38; Iter   841/ 1097] train: loss: 0.0882249
[Epoch 38; Iter   871/ 1097] train: loss: 0.1722242
[Epoch 38; Iter   901/ 1097] train: loss: 0.0856407
[Epoch 38; Iter   931/ 1097] train: loss: 0.0221380
[Epoch 38; Iter   961/ 1097] train: loss: 0.0104824
[Epoch 38; Iter   991/ 1097] train: loss: 0.0320421
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0281531
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0236102
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0428071
[Epoch 38] ogbg-molhiv: 0.793862 val loss: 0.086655
[Epoch 38] ogbg-molhiv: 0.757626 test loss: 0.150139
[Epoch 39; Iter    14/ 1097] train: loss: 0.0214592
[Epoch 39; Iter    44/ 1097] train: loss: 0.1368810
[Epoch 39; Iter    74/ 1097] train: loss: 0.2717889
[Epoch 39; Iter   104/ 1097] train: loss: 0.0559932
[Epoch 39; Iter   134/ 1097] train: loss: 0.0555833
[Epoch 39; Iter   164/ 1097] train: loss: 0.0318712
[Epoch 39; Iter   194/ 1097] train: loss: 0.1244095
[Epoch 39; Iter   224/ 1097] train: loss: 0.0159729
[Epoch 39; Iter   254/ 1097] train: loss: 0.0150107
[Epoch 39; Iter   284/ 1097] train: loss: 0.1306655
[Epoch 39; Iter   314/ 1097] train: loss: 0.0277961
[Epoch 39; Iter   344/ 1097] train: loss: 0.0126405
[Epoch 39; Iter   374/ 1097] train: loss: 0.0230980
[Epoch 39; Iter   404/ 1097] train: loss: 0.0127764
[Epoch 39; Iter   434/ 1097] train: loss: 0.1178142
[Epoch 39; Iter   464/ 1097] train: loss: 0.0110839
[Epoch 39; Iter   494/ 1097] train: loss: 0.0720309
[Epoch 39; Iter   524/ 1097] train: loss: 0.0468530
[Epoch 39; Iter   554/ 1097] train: loss: 0.0397994
[Epoch 39; Iter   584/ 1097] train: loss: 0.0239167
[Epoch 39; Iter   614/ 1097] train: loss: 0.2350053
[Epoch 39; Iter   644/ 1097] train: loss: 0.1028256
[Epoch 39; Iter   674/ 1097] train: loss: 0.0162264
[Epoch 39; Iter   704/ 1097] train: loss: 0.0328625
[Epoch 39; Iter   734/ 1097] train: loss: 0.0077359
[Epoch 39; Iter   764/ 1097] train: loss: 0.0182302
[Epoch 39; Iter   794/ 1097] train: loss: 0.0108457
[Epoch 39; Iter   824/ 1097] train: loss: 0.0389537
[Epoch 39; Iter   854/ 1097] train: loss: 0.0169514
[Epoch 39; Iter   884/ 1097] train: loss: 0.0140336
[Epoch 39; Iter   914/ 1097] train: loss: 0.1618101
[Epoch 39; Iter   944/ 1097] train: loss: 0.1797840
[Epoch 39; Iter   974/ 1097] train: loss: 0.1510990
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0156006
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0652997
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0406775
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0151927
[Epoch 39] ogbg-molhiv: 0.820133 val loss: 0.080384
[Epoch 39] ogbg-molhiv: 0.793945 test loss: 0.169667
[Epoch 40; Iter    27/ 1097] train: loss: 0.0924669
[Epoch 40; Iter    57/ 1097] train: loss: 0.1316693
[Epoch 40; Iter    87/ 1097] train: loss: 0.1645408
[Epoch 40; Iter   117/ 1097] train: loss: 0.0196607
[Epoch 40; Iter   147/ 1097] train: loss: 0.0098700
[Epoch 40; Iter   177/ 1097] train: loss: 0.0768905
[Epoch 40; Iter   207/ 1097] train: loss: 0.3487406
[Epoch 40; Iter   237/ 1097] train: loss: 0.0207021
[Epoch 40; Iter   267/ 1097] train: loss: 0.1478448
[Epoch 40; Iter   297/ 1097] train: loss: 0.1289247
[Epoch 40; Iter   327/ 1097] train: loss: 0.2300426
[Epoch 40; Iter   357/ 1097] train: loss: 0.0136374
[Epoch 40; Iter   387/ 1097] train: loss: 0.0371859
[Epoch 40; Iter   417/ 1097] train: loss: 0.1267797
[Epoch 40; Iter   447/ 1097] train: loss: 0.0397122
[Epoch 40; Iter   477/ 1097] train: loss: 0.2034501
[Epoch 40; Iter   507/ 1097] train: loss: 0.0195871
[Epoch 40; Iter   537/ 1097] train: loss: 0.0362254
[Epoch 40; Iter   567/ 1097] train: loss: 0.0259160
[Epoch 40; Iter   597/ 1097] train: loss: 0.0187657
[Epoch 40; Iter   627/ 1097] train: loss: 0.0296699
[Epoch 40; Iter   657/ 1097] train: loss: 0.1287681
[Epoch 36; Iter   605/ 1097] train: loss: 0.0193307
[Epoch 36; Iter   635/ 1097] train: loss: 0.0179386
[Epoch 36; Iter   665/ 1097] train: loss: 0.0829485
[Epoch 36; Iter   695/ 1097] train: loss: 0.3324753
[Epoch 36; Iter   725/ 1097] train: loss: 0.0860447
[Epoch 36; Iter   755/ 1097] train: loss: 0.0171030
[Epoch 36; Iter   785/ 1097] train: loss: 0.0201649
[Epoch 36; Iter   815/ 1097] train: loss: 0.0165165
[Epoch 36; Iter   845/ 1097] train: loss: 0.0392366
[Epoch 36; Iter   875/ 1097] train: loss: 0.0116484
[Epoch 36; Iter   905/ 1097] train: loss: 0.1928364
[Epoch 36; Iter   935/ 1097] train: loss: 0.1862635
[Epoch 36; Iter   965/ 1097] train: loss: 0.0235700
[Epoch 36; Iter   995/ 1097] train: loss: 0.0153140
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0618478
[Epoch 36; Iter  1055/ 1097] train: loss: 0.2642335
[Epoch 36; Iter  1085/ 1097] train: loss: 0.3798433
[Epoch 36] ogbg-molhiv: 0.825905 val loss: 0.073977
[Epoch 36] ogbg-molhiv: 0.773364 test loss: 0.122124
[Epoch 37; Iter    18/ 1097] train: loss: 0.0179082
[Epoch 37; Iter    48/ 1097] train: loss: 0.0298071
[Epoch 37; Iter    78/ 1097] train: loss: 0.0506506
[Epoch 37; Iter   108/ 1097] train: loss: 0.0330014
[Epoch 37; Iter   138/ 1097] train: loss: 0.0733018
[Epoch 37; Iter   168/ 1097] train: loss: 0.0881540
[Epoch 37; Iter   198/ 1097] train: loss: 0.0137032
[Epoch 37; Iter   228/ 1097] train: loss: 0.0126256
[Epoch 37; Iter   258/ 1097] train: loss: 0.0380010
[Epoch 37; Iter   288/ 1097] train: loss: 0.0121222
[Epoch 37; Iter   318/ 1097] train: loss: 0.0107083
[Epoch 37; Iter   348/ 1097] train: loss: 0.0239412
[Epoch 37; Iter   378/ 1097] train: loss: 0.3042881
[Epoch 37; Iter   408/ 1097] train: loss: 0.1192521
[Epoch 37; Iter   438/ 1097] train: loss: 0.1453772
[Epoch 37; Iter   468/ 1097] train: loss: 0.0421860
[Epoch 37; Iter   498/ 1097] train: loss: 0.1376233
[Epoch 37; Iter   528/ 1097] train: loss: 0.0593226
[Epoch 37; Iter   558/ 1097] train: loss: 0.0795859
[Epoch 37; Iter   588/ 1097] train: loss: 0.0424877
[Epoch 37; Iter   618/ 1097] train: loss: 0.1863859
[Epoch 37; Iter   648/ 1097] train: loss: 0.0522584
[Epoch 37; Iter   678/ 1097] train: loss: 0.0736097
[Epoch 37; Iter   708/ 1097] train: loss: 0.0161135
[Epoch 37; Iter   738/ 1097] train: loss: 0.0235515
[Epoch 37; Iter   768/ 1097] train: loss: 0.1740284
[Epoch 37; Iter   798/ 1097] train: loss: 0.2266548
[Epoch 37; Iter   828/ 1097] train: loss: 0.0220681
[Epoch 37; Iter   858/ 1097] train: loss: 0.0615561
[Epoch 37; Iter   888/ 1097] train: loss: 0.0278483
[Epoch 37; Iter   918/ 1097] train: loss: 0.1876129
[Epoch 37; Iter   948/ 1097] train: loss: 0.0144222
[Epoch 37; Iter   978/ 1097] train: loss: 0.1554140
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0174403
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0202430
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0853849
[Epoch 37] ogbg-molhiv: 0.823979 val loss: 0.077363
[Epoch 37] ogbg-molhiv: 0.756652 test loss: 0.127910
[Epoch 38; Iter     1/ 1097] train: loss: 0.0246932
[Epoch 38; Iter    31/ 1097] train: loss: 0.0360827
[Epoch 38; Iter    61/ 1097] train: loss: 0.2069097
[Epoch 38; Iter    91/ 1097] train: loss: 0.1289821
[Epoch 38; Iter   121/ 1097] train: loss: 0.0152772
[Epoch 38; Iter   151/ 1097] train: loss: 0.0104409
[Epoch 38; Iter   181/ 1097] train: loss: 0.1333920
[Epoch 38; Iter   211/ 1097] train: loss: 0.0109589
[Epoch 38; Iter   241/ 1097] train: loss: 0.1053778
[Epoch 38; Iter   271/ 1097] train: loss: 0.0133901
[Epoch 38; Iter   301/ 1097] train: loss: 0.4555057
[Epoch 38; Iter   331/ 1097] train: loss: 0.1346455
[Epoch 38; Iter   361/ 1097] train: loss: 0.0374495
[Epoch 38; Iter   391/ 1097] train: loss: 0.0546798
[Epoch 38; Iter   421/ 1097] train: loss: 0.1631019
[Epoch 38; Iter   451/ 1097] train: loss: 0.0550589
[Epoch 38; Iter   481/ 1097] train: loss: 0.0844426
[Epoch 38; Iter   511/ 1097] train: loss: 0.1517562
[Epoch 38; Iter   541/ 1097] train: loss: 0.1791786
[Epoch 38; Iter   571/ 1097] train: loss: 0.0113378
[Epoch 38; Iter   601/ 1097] train: loss: 0.2032432
[Epoch 38; Iter   631/ 1097] train: loss: 0.1257716
[Epoch 38; Iter   661/ 1097] train: loss: 0.0215477
[Epoch 38; Iter   691/ 1097] train: loss: 0.1452011
[Epoch 38; Iter   721/ 1097] train: loss: 0.2080141
[Epoch 38; Iter   751/ 1097] train: loss: 0.0235581
[Epoch 38; Iter   781/ 1097] train: loss: 0.0908257
[Epoch 38; Iter   811/ 1097] train: loss: 0.1408636
[Epoch 38; Iter   841/ 1097] train: loss: 0.1490799
[Epoch 38; Iter   871/ 1097] train: loss: 0.0280581
[Epoch 38; Iter   901/ 1097] train: loss: 0.0290090
[Epoch 38; Iter   931/ 1097] train: loss: 0.0392913
[Epoch 38; Iter   961/ 1097] train: loss: 0.0281130
[Epoch 38; Iter   991/ 1097] train: loss: 0.0218961
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0207436
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0205616
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0399445
[Epoch 38] ogbg-molhiv: 0.855511 val loss: 0.075667
[Epoch 38] ogbg-molhiv: 0.784075 test loss: 0.130015
[Epoch 39; Iter    14/ 1097] train: loss: 0.1886567
[Epoch 39; Iter    44/ 1097] train: loss: 0.4227348
[Epoch 39; Iter    74/ 1097] train: loss: 0.0778258
[Epoch 39; Iter   104/ 1097] train: loss: 0.0194444
[Epoch 39; Iter   134/ 1097] train: loss: 0.1083252
[Epoch 39; Iter   164/ 1097] train: loss: 0.2780277
[Epoch 39; Iter   194/ 1097] train: loss: 0.0171676
[Epoch 39; Iter   224/ 1097] train: loss: 0.0831089
[Epoch 39; Iter   254/ 1097] train: loss: 0.1192978
[Epoch 39; Iter   284/ 1097] train: loss: 0.0541056
[Epoch 39; Iter   314/ 1097] train: loss: 0.1138290
[Epoch 39; Iter   344/ 1097] train: loss: 0.0488621
[Epoch 39; Iter   374/ 1097] train: loss: 0.0152529
[Epoch 39; Iter   404/ 1097] train: loss: 0.1909614
[Epoch 39; Iter   434/ 1097] train: loss: 0.0119645
[Epoch 39; Iter   464/ 1097] train: loss: 0.0318771
[Epoch 39; Iter   494/ 1097] train: loss: 0.0388490
[Epoch 39; Iter   524/ 1097] train: loss: 0.0386158
[Epoch 39; Iter   554/ 1097] train: loss: 0.0148568
[Epoch 39; Iter   584/ 1097] train: loss: 0.0204036
[Epoch 39; Iter   614/ 1097] train: loss: 0.0693128
[Epoch 39; Iter   644/ 1097] train: loss: 0.0167731
[Epoch 39; Iter   674/ 1097] train: loss: 0.1758485
[Epoch 39; Iter   704/ 1097] train: loss: 0.1424760
[Epoch 39; Iter   734/ 1097] train: loss: 0.0254421
[Epoch 39; Iter   764/ 1097] train: loss: 0.2693003
[Epoch 39; Iter   794/ 1097] train: loss: 0.1548034
[Epoch 39; Iter   824/ 1097] train: loss: 0.1240557
[Epoch 39; Iter   854/ 1097] train: loss: 0.0261873
[Epoch 39; Iter   884/ 1097] train: loss: 0.0253076
[Epoch 39; Iter   914/ 1097] train: loss: 0.0457424
[Epoch 39; Iter   944/ 1097] train: loss: 0.0387810
[Epoch 39; Iter   974/ 1097] train: loss: 0.1288561
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0718803
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0164248
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0220780
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1240178
[Epoch 39] ogbg-molhiv: 0.813079 val loss: 0.121388
[Epoch 39] ogbg-molhiv: 0.751598 test loss: 0.161218
[Epoch 40; Iter    27/ 1097] train: loss: 0.1550623
[Epoch 40; Iter    57/ 1097] train: loss: 0.0476592
[Epoch 40; Iter    87/ 1097] train: loss: 0.1015273
[Epoch 40; Iter   117/ 1097] train: loss: 0.0843580
[Epoch 40; Iter   147/ 1097] train: loss: 0.0580458
[Epoch 40; Iter   177/ 1097] train: loss: 0.0439422
[Epoch 40; Iter   207/ 1097] train: loss: 0.0525395
[Epoch 40; Iter   237/ 1097] train: loss: 0.0729375
[Epoch 40; Iter   267/ 1097] train: loss: 0.2668211
[Epoch 40; Iter   297/ 1097] train: loss: 0.0425636
[Epoch 40; Iter   327/ 1097] train: loss: 0.0228223
[Epoch 40; Iter   357/ 1097] train: loss: 0.3257677
[Epoch 40; Iter   387/ 1097] train: loss: 0.1381016
[Epoch 40; Iter   417/ 1097] train: loss: 0.1084901
[Epoch 40; Iter   447/ 1097] train: loss: 0.1337607
[Epoch 40; Iter   477/ 1097] train: loss: 0.0296393
[Epoch 40; Iter   507/ 1097] train: loss: 0.1149579
[Epoch 40; Iter   537/ 1097] train: loss: 0.0721169
[Epoch 40; Iter   567/ 1097] train: loss: 0.0528210
[Epoch 40; Iter   597/ 1097] train: loss: 0.0705335
[Epoch 40; Iter   627/ 1097] train: loss: 0.0226692
[Epoch 40; Iter   657/ 1097] train: loss: 0.1039112
[Epoch 44; Iter   769/ 1097] train: loss: 0.0017082
[Epoch 44; Iter   799/ 1097] train: loss: 0.0022885
[Epoch 44; Iter   829/ 1097] train: loss: 0.0255547
[Epoch 44; Iter   859/ 1097] train: loss: 0.0028062
[Epoch 44; Iter   889/ 1097] train: loss: 0.0003533
[Epoch 44; Iter   919/ 1097] train: loss: 0.0012985
[Epoch 44; Iter   949/ 1097] train: loss: 0.1044850
[Epoch 44; Iter   979/ 1097] train: loss: 0.0012609
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0041551
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0023598
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0148433
[Epoch 44] ogbg-molhiv: 0.789811 val loss: 0.216897
[Epoch 44] ogbg-molhiv: 0.782987 test loss: 0.234034
[Epoch 45; Iter     2/ 1097] train: loss: 0.0112448
[Epoch 45; Iter    32/ 1097] train: loss: 0.0002018
[Epoch 45; Iter    62/ 1097] train: loss: 0.0033403
[Epoch 45; Iter    92/ 1097] train: loss: 0.0052311
[Epoch 45; Iter   122/ 1097] train: loss: 0.0150941
[Epoch 45; Iter   152/ 1097] train: loss: 0.0191473
[Epoch 45; Iter   182/ 1097] train: loss: 0.0004700
[Epoch 45; Iter   212/ 1097] train: loss: 0.0259935
[Epoch 45; Iter   242/ 1097] train: loss: 0.0014846
[Epoch 45; Iter   272/ 1097] train: loss: 0.0037338
[Epoch 45; Iter   302/ 1097] train: loss: 0.0142148
[Epoch 45; Iter   332/ 1097] train: loss: 0.0108930
[Epoch 45; Iter   362/ 1097] train: loss: 0.0005910
[Epoch 45; Iter   392/ 1097] train: loss: 0.0870223
[Epoch 45; Iter   422/ 1097] train: loss: 0.0037999
[Epoch 45; Iter   452/ 1097] train: loss: 0.0023923
[Epoch 45; Iter   482/ 1097] train: loss: 0.0003130
[Epoch 45; Iter   512/ 1097] train: loss: 0.0083734
[Epoch 45; Iter   542/ 1097] train: loss: 0.0029689
[Epoch 45; Iter   572/ 1097] train: loss: 0.0052902
[Epoch 45; Iter   602/ 1097] train: loss: 0.0017154
[Epoch 45; Iter   632/ 1097] train: loss: 0.0007040
[Epoch 45; Iter   662/ 1097] train: loss: 0.0005087
[Epoch 45; Iter   692/ 1097] train: loss: 0.0037537
[Epoch 45; Iter   722/ 1097] train: loss: 0.0004479
[Epoch 45; Iter   752/ 1097] train: loss: 0.0034589
[Epoch 45; Iter   782/ 1097] train: loss: 0.0036757
[Epoch 45; Iter   812/ 1097] train: loss: 0.0005417
[Epoch 45; Iter   842/ 1097] train: loss: 0.0039005
[Epoch 45; Iter   872/ 1097] train: loss: 0.0014383
[Epoch 45; Iter   902/ 1097] train: loss: 0.0125476
[Epoch 45; Iter   932/ 1097] train: loss: 0.0093853
[Epoch 45; Iter   962/ 1097] train: loss: 0.0111661
[Epoch 45; Iter   992/ 1097] train: loss: 0.0074206
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0046105
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0046097
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0046700
[Epoch 45] ogbg-molhiv: 0.810654 val loss: 0.232265
[Epoch 45] ogbg-molhiv: 0.785110 test loss: 0.244843
[Epoch 46; Iter    15/ 1097] train: loss: 0.0089605
[Epoch 46; Iter    45/ 1097] train: loss: 0.0011916
[Epoch 46; Iter    75/ 1097] train: loss: 0.0080852
[Epoch 46; Iter   105/ 1097] train: loss: 0.0043924
[Epoch 46; Iter   135/ 1097] train: loss: 0.0194420
[Epoch 46; Iter   165/ 1097] train: loss: 0.0002899
[Epoch 46; Iter   195/ 1097] train: loss: 0.0001330
[Epoch 46; Iter   225/ 1097] train: loss: 0.0003324
[Epoch 46; Iter   255/ 1097] train: loss: 0.0027628
[Epoch 46; Iter   285/ 1097] train: loss: 0.0999691
[Epoch 46; Iter   315/ 1097] train: loss: 0.0013962
[Epoch 46; Iter   345/ 1097] train: loss: 0.0009313
[Epoch 46; Iter   375/ 1097] train: loss: 0.0022775
[Epoch 46; Iter   405/ 1097] train: loss: 0.0506389
[Epoch 46; Iter   435/ 1097] train: loss: 0.0435093
[Epoch 46; Iter   465/ 1097] train: loss: 0.0014042
[Epoch 46; Iter   495/ 1097] train: loss: 0.0002483
[Epoch 46; Iter   525/ 1097] train: loss: 0.0059938
[Epoch 46; Iter   555/ 1097] train: loss: 0.0002255
[Epoch 46; Iter   585/ 1097] train: loss: 0.0147587
[Epoch 46; Iter   615/ 1097] train: loss: 0.0009474
[Epoch 46; Iter   645/ 1097] train: loss: 0.0821896
[Epoch 46; Iter   675/ 1097] train: loss: 0.0004520
[Epoch 46; Iter   705/ 1097] train: loss: 0.0010635
[Epoch 46; Iter   735/ 1097] train: loss: 0.0047301
[Epoch 46; Iter   765/ 1097] train: loss: 0.0144658
[Epoch 46; Iter   795/ 1097] train: loss: 0.0003237
[Epoch 46; Iter   825/ 1097] train: loss: 0.0068904
[Epoch 46; Iter   855/ 1097] train: loss: 0.0017587
[Epoch 46; Iter   885/ 1097] train: loss: 0.0236276
[Epoch 46; Iter   915/ 1097] train: loss: 0.0251715
[Epoch 46; Iter   945/ 1097] train: loss: 0.0109923
[Epoch 46; Iter   975/ 1097] train: loss: 0.0394796
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0035783
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0108628
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0075086
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0005374
[Epoch 46] ogbg-molhiv: 0.768353 val loss: 0.189179
[Epoch 46] ogbg-molhiv: 0.779918 test loss: 0.246981
[Epoch 47; Iter    28/ 1097] train: loss: 0.0171949
[Epoch 47; Iter    58/ 1097] train: loss: 0.0044624
[Epoch 47; Iter    88/ 1097] train: loss: 0.0010045
[Epoch 47; Iter   118/ 1097] train: loss: 0.0006640
[Epoch 47; Iter   148/ 1097] train: loss: 0.0016118
[Epoch 47; Iter   178/ 1097] train: loss: 0.0192429
[Epoch 47; Iter   208/ 1097] train: loss: 0.0020841
[Epoch 47; Iter   238/ 1097] train: loss: 0.0017196
[Epoch 47; Iter   268/ 1097] train: loss: 0.0022089
[Epoch 47; Iter   298/ 1097] train: loss: 0.0012967
[Epoch 47; Iter   328/ 1097] train: loss: 0.0027383
[Epoch 47; Iter   358/ 1097] train: loss: 0.0168004
[Epoch 47; Iter   388/ 1097] train: loss: 0.0063636
[Epoch 47; Iter   418/ 1097] train: loss: 0.0011235
[Epoch 47; Iter   448/ 1097] train: loss: 0.0061260
[Epoch 47; Iter   478/ 1097] train: loss: 0.0013530
[Epoch 47; Iter   508/ 1097] train: loss: 0.0019109
[Epoch 47; Iter   538/ 1097] train: loss: 0.0029415
[Epoch 47; Iter   568/ 1097] train: loss: 0.0010253
[Epoch 47; Iter   598/ 1097] train: loss: 0.0053971
[Epoch 47; Iter   628/ 1097] train: loss: 0.0035191
[Epoch 47; Iter   658/ 1097] train: loss: 0.0002258
[Epoch 47; Iter   688/ 1097] train: loss: 0.0459655
[Epoch 47; Iter   718/ 1097] train: loss: 0.0031485
[Epoch 47; Iter   748/ 1097] train: loss: 0.0135035
[Epoch 47; Iter   778/ 1097] train: loss: 0.0002050
[Epoch 47; Iter   808/ 1097] train: loss: 0.0017275
[Epoch 47; Iter   838/ 1097] train: loss: 0.0003418
[Epoch 47; Iter   868/ 1097] train: loss: 0.0146221
[Epoch 47; Iter   898/ 1097] train: loss: 0.0008993
[Epoch 47; Iter   928/ 1097] train: loss: 0.0070497
[Epoch 47; Iter   958/ 1097] train: loss: 0.0045770
[Epoch 47; Iter   988/ 1097] train: loss: 0.0224265
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0022549
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0110128
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0026194
[Epoch 47] ogbg-molhiv: 0.759541 val loss: 0.215073
[Epoch 47] ogbg-molhiv: 0.772943 test loss: 0.249818
[Epoch 48; Iter    11/ 1097] train: loss: 0.0015706
[Epoch 48; Iter    41/ 1097] train: loss: 0.0776992
[Epoch 48; Iter    71/ 1097] train: loss: 0.0065759
[Epoch 48; Iter   101/ 1097] train: loss: 0.0225502
[Epoch 48; Iter   131/ 1097] train: loss: 0.0023483
[Epoch 48; Iter   161/ 1097] train: loss: 0.0007934
[Epoch 48; Iter   191/ 1097] train: loss: 0.0134930
[Epoch 48; Iter   221/ 1097] train: loss: 0.0022159
[Epoch 48; Iter   251/ 1097] train: loss: 0.0002739
[Epoch 48; Iter   281/ 1097] train: loss: 0.0009223
[Epoch 48; Iter   311/ 1097] train: loss: 0.0012506
[Epoch 48; Iter   341/ 1097] train: loss: 0.0139429
[Epoch 48; Iter   371/ 1097] train: loss: 0.0246455
[Epoch 48; Iter   401/ 1097] train: loss: 0.0027833
[Epoch 48; Iter   431/ 1097] train: loss: 0.0105817
[Epoch 48; Iter   461/ 1097] train: loss: 0.0001214
[Epoch 48; Iter   491/ 1097] train: loss: 0.0071796
[Epoch 48; Iter   521/ 1097] train: loss: 0.0114732
[Epoch 48; Iter   551/ 1097] train: loss: 0.0149478
[Epoch 48; Iter   581/ 1097] train: loss: 0.0134948
[Epoch 48; Iter   611/ 1097] train: loss: 0.0003884
[Epoch 48; Iter   641/ 1097] train: loss: 0.0037007
[Epoch 48; Iter   671/ 1097] train: loss: 0.0004233
[Epoch 48; Iter   701/ 1097] train: loss: 0.0053424
[Epoch 48; Iter   731/ 1097] train: loss: 0.0032718
[Epoch 48; Iter   761/ 1097] train: loss: 0.0058490
[Epoch 48; Iter   791/ 1097] train: loss: 0.0093262
[Epoch 48; Iter   821/ 1097] train: loss: 0.0006475
[Epoch 44; Iter   769/ 1097] train: loss: 0.0309830
[Epoch 44; Iter   799/ 1097] train: loss: 0.0023491
[Epoch 44; Iter   829/ 1097] train: loss: 0.0629110
[Epoch 44; Iter   859/ 1097] train: loss: 0.0036590
[Epoch 44; Iter   889/ 1097] train: loss: 0.0025095
[Epoch 44; Iter   919/ 1097] train: loss: 0.0000503
[Epoch 44; Iter   949/ 1097] train: loss: 0.0023103
[Epoch 44; Iter   979/ 1097] train: loss: 0.0008846
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0005121
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0073703
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0681724
[Epoch 44] ogbg-molhiv: 0.716732 val loss: 3.495970
[Epoch 44] ogbg-molhiv: 0.624068 test loss: 4.857125
[Epoch 45; Iter     2/ 1097] train: loss: 0.0001893
[Epoch 45; Iter    32/ 1097] train: loss: 0.0010854
[Epoch 45; Iter    62/ 1097] train: loss: 0.0017419
[Epoch 45; Iter    92/ 1097] train: loss: 0.0043702
[Epoch 45; Iter   122/ 1097] train: loss: 0.0052286
[Epoch 45; Iter   152/ 1097] train: loss: 0.0134822
[Epoch 45; Iter   182/ 1097] train: loss: 0.0002652
[Epoch 45; Iter   212/ 1097] train: loss: 0.0028199
[Epoch 45; Iter   242/ 1097] train: loss: 0.0297279
[Epoch 45; Iter   272/ 1097] train: loss: 0.0032166
[Epoch 45; Iter   302/ 1097] train: loss: 0.0145138
[Epoch 45; Iter   332/ 1097] train: loss: 0.0000352
[Epoch 45; Iter   362/ 1097] train: loss: 0.0000880
[Epoch 45; Iter   392/ 1097] train: loss: 0.0012476
[Epoch 45; Iter   422/ 1097] train: loss: 0.0347266
[Epoch 45; Iter   452/ 1097] train: loss: 0.0008309
[Epoch 45; Iter   482/ 1097] train: loss: 0.0038666
[Epoch 45; Iter   512/ 1097] train: loss: 0.0000402
[Epoch 45; Iter   542/ 1097] train: loss: 0.0005627
[Epoch 45; Iter   572/ 1097] train: loss: 0.0159938
[Epoch 45; Iter   602/ 1097] train: loss: 0.0001496
[Epoch 45; Iter   632/ 1097] train: loss: 0.0042059
[Epoch 45; Iter   662/ 1097] train: loss: 0.0104874
[Epoch 45; Iter   692/ 1097] train: loss: 0.0028807
[Epoch 45; Iter   722/ 1097] train: loss: 0.0014793
[Epoch 45; Iter   752/ 1097] train: loss: 0.0042402
[Epoch 45; Iter   782/ 1097] train: loss: 0.1297162
[Epoch 45; Iter   812/ 1097] train: loss: 0.0025681
[Epoch 45; Iter   842/ 1097] train: loss: 0.0000852
[Epoch 45; Iter   872/ 1097] train: loss: 0.0096093
[Epoch 45; Iter   902/ 1097] train: loss: 0.0076162
[Epoch 45; Iter   932/ 1097] train: loss: 0.0026937
[Epoch 45; Iter   962/ 1097] train: loss: 0.0008398
[Epoch 45; Iter   992/ 1097] train: loss: 0.0012403
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0514962
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0226179
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0004155
[Epoch 45] ogbg-molhiv: 0.739684 val loss: 2.531072
[Epoch 45] ogbg-molhiv: 0.620765 test loss: 2.731034
[Epoch 46; Iter    15/ 1097] train: loss: 0.0469630
[Epoch 46; Iter    45/ 1097] train: loss: 0.0003374
[Epoch 46; Iter    75/ 1097] train: loss: 0.1075102
[Epoch 46; Iter   105/ 1097] train: loss: 0.0048973
[Epoch 46; Iter   135/ 1097] train: loss: 0.0228384
[Epoch 46; Iter   165/ 1097] train: loss: 0.0051049
[Epoch 46; Iter   195/ 1097] train: loss: 0.0020759
[Epoch 46; Iter   225/ 1097] train: loss: 0.0000308
[Epoch 46; Iter   255/ 1097] train: loss: 0.0035310
[Epoch 46; Iter   285/ 1097] train: loss: 0.0002035
[Epoch 46; Iter   315/ 1097] train: loss: 0.0004250
[Epoch 46; Iter   345/ 1097] train: loss: 0.0001347
[Epoch 46; Iter   375/ 1097] train: loss: 0.0050628
[Epoch 46; Iter   405/ 1097] train: loss: 0.0001141
[Epoch 46; Iter   435/ 1097] train: loss: 0.0001602
[Epoch 46; Iter   465/ 1097] train: loss: 0.0003686
[Epoch 46; Iter   495/ 1097] train: loss: 0.0098954
[Epoch 46; Iter   525/ 1097] train: loss: 0.0005236
[Epoch 46; Iter   555/ 1097] train: loss: 0.0001667
[Epoch 46; Iter   585/ 1097] train: loss: 0.0315619
[Epoch 46; Iter   615/ 1097] train: loss: 0.0047543
[Epoch 46; Iter   645/ 1097] train: loss: 0.0000817
[Epoch 46; Iter   675/ 1097] train: loss: 0.0045882
[Epoch 46; Iter   705/ 1097] train: loss: 0.0001898
[Epoch 46; Iter   735/ 1097] train: loss: 0.0204431
[Epoch 46; Iter   765/ 1097] train: loss: 0.2833887
[Epoch 46; Iter   795/ 1097] train: loss: 0.0005775
[Epoch 46; Iter   825/ 1097] train: loss: 0.0002136
[Epoch 46; Iter   855/ 1097] train: loss: 0.0062864
[Epoch 46; Iter   885/ 1097] train: loss: 0.0030152
[Epoch 46; Iter   915/ 1097] train: loss: 0.0034241
[Epoch 46; Iter   945/ 1097] train: loss: 0.0002925
[Epoch 46; Iter   975/ 1097] train: loss: 0.0007226
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0018748
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0368826
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0009571
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0007251
[Epoch 46] ogbg-molhiv: 0.659416 val loss: 2.479036
[Epoch 46] ogbg-molhiv: 0.654651 test loss: 2.021809
[Epoch 47; Iter    28/ 1097] train: loss: 0.0010281
[Epoch 47; Iter    58/ 1097] train: loss: 0.0038162
[Epoch 47; Iter    88/ 1097] train: loss: 0.0021509
[Epoch 47; Iter   118/ 1097] train: loss: 0.0916677
[Epoch 47; Iter   148/ 1097] train: loss: 0.0399448
[Epoch 47; Iter   178/ 1097] train: loss: 0.0000247
[Epoch 47; Iter   208/ 1097] train: loss: 0.0007662
[Epoch 47; Iter   238/ 1097] train: loss: 0.0003466
[Epoch 47; Iter   268/ 1097] train: loss: 0.0286435
[Epoch 47; Iter   298/ 1097] train: loss: 0.0003479
[Epoch 47; Iter   328/ 1097] train: loss: 0.0003462
[Epoch 47; Iter   358/ 1097] train: loss: 0.0022020
[Epoch 47; Iter   388/ 1097] train: loss: 0.0007513
[Epoch 47; Iter   418/ 1097] train: loss: 0.0004144
[Epoch 47; Iter   448/ 1097] train: loss: 0.0000424
[Epoch 47; Iter   478/ 1097] train: loss: 0.0001717
[Epoch 47; Iter   508/ 1097] train: loss: 0.0013896
[Epoch 47; Iter   538/ 1097] train: loss: 0.0180606
[Epoch 47; Iter   568/ 1097] train: loss: 0.0004184
[Epoch 47; Iter   598/ 1097] train: loss: 0.0035363
[Epoch 47; Iter   628/ 1097] train: loss: 0.0002285
[Epoch 47; Iter   658/ 1097] train: loss: 0.0006996
[Epoch 47; Iter   688/ 1097] train: loss: 0.0012954
[Epoch 47; Iter   718/ 1097] train: loss: 0.0011822
[Epoch 47; Iter   748/ 1097] train: loss: 0.0005627
[Epoch 47; Iter   778/ 1097] train: loss: 0.0396485
[Epoch 47; Iter   808/ 1097] train: loss: 0.0148238
[Epoch 47; Iter   838/ 1097] train: loss: 0.0015517
[Epoch 47; Iter   868/ 1097] train: loss: 0.0040523
[Epoch 47; Iter   898/ 1097] train: loss: 0.0004867
[Epoch 47; Iter   928/ 1097] train: loss: 0.0001473
[Epoch 47; Iter   958/ 1097] train: loss: 0.0018443
[Epoch 47; Iter   988/ 1097] train: loss: 0.0778808
[Epoch 47; Iter  1018/ 1097] train: loss: 0.1154688
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0005431
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0223907
[Epoch 47] ogbg-molhiv: 0.674435 val loss: 2.554713
[Epoch 47] ogbg-molhiv: 0.592644 test loss: 2.197890
[Epoch 48; Iter    11/ 1097] train: loss: 0.0440923
[Epoch 48; Iter    41/ 1097] train: loss: 0.0003585
[Epoch 48; Iter    71/ 1097] train: loss: 0.0001306
[Epoch 48; Iter   101/ 1097] train: loss: 0.0104249
[Epoch 48; Iter   131/ 1097] train: loss: 0.0036129
[Epoch 48; Iter   161/ 1097] train: loss: 0.0002780
[Epoch 48; Iter   191/ 1097] train: loss: 0.0001949
[Epoch 48; Iter   221/ 1097] train: loss: 0.0001641
[Epoch 48; Iter   251/ 1097] train: loss: 0.0002295
[Epoch 48; Iter   281/ 1097] train: loss: 0.0044826
[Epoch 48; Iter   311/ 1097] train: loss: 0.0036812
[Epoch 48; Iter   341/ 1097] train: loss: 0.0021635
[Epoch 48; Iter   371/ 1097] train: loss: 0.0076511
[Epoch 48; Iter   401/ 1097] train: loss: 0.0006814
[Epoch 48; Iter   431/ 1097] train: loss: 0.0022379
[Epoch 48; Iter   461/ 1097] train: loss: 0.0000912
[Epoch 48; Iter   491/ 1097] train: loss: 0.0003880
[Epoch 48; Iter   521/ 1097] train: loss: 0.0003096
[Epoch 48; Iter   551/ 1097] train: loss: 0.0252306
[Epoch 48; Iter   581/ 1097] train: loss: 0.0464350
[Epoch 48; Iter   611/ 1097] train: loss: 0.0008922
[Epoch 48; Iter   641/ 1097] train: loss: 0.0036558
[Epoch 48; Iter   671/ 1097] train: loss: 0.0162520
[Epoch 48; Iter   701/ 1097] train: loss: 0.0125899
[Epoch 48; Iter   731/ 1097] train: loss: 0.0039534
[Epoch 48; Iter   761/ 1097] train: loss: 0.0099762
[Epoch 48; Iter   791/ 1097] train: loss: 0.0189189
[Epoch 48; Iter   821/ 1097] train: loss: 0.0036872
[Epoch 44; Iter   769/ 1097] train: loss: 0.0006039
[Epoch 44; Iter   799/ 1097] train: loss: 0.0357403
[Epoch 44; Iter   829/ 1097] train: loss: 0.0078533
[Epoch 44; Iter   859/ 1097] train: loss: 0.0343987
[Epoch 44; Iter   889/ 1097] train: loss: 0.0004633
[Epoch 44; Iter   919/ 1097] train: loss: 0.0208812
[Epoch 44; Iter   949/ 1097] train: loss: 0.0682172
[Epoch 44; Iter   979/ 1097] train: loss: 0.0041378
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0135555
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0082840
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0059670
[Epoch 44] ogbg-molhiv: 0.771032 val loss: 3.298801
[Epoch 44] ogbg-molhiv: 0.716615 test loss: 5.986031
[Epoch 45; Iter     2/ 1097] train: loss: 0.0002800
[Epoch 45; Iter    32/ 1097] train: loss: 0.0013831
[Epoch 45; Iter    62/ 1097] train: loss: 0.0015499
[Epoch 45; Iter    92/ 1097] train: loss: 0.0097611
[Epoch 45; Iter   122/ 1097] train: loss: 0.0073037
[Epoch 45; Iter   152/ 1097] train: loss: 0.0213869
[Epoch 45; Iter   182/ 1097] train: loss: 0.0134896
[Epoch 45; Iter   212/ 1097] train: loss: 0.0037545
[Epoch 45; Iter   242/ 1097] train: loss: 0.0025136
[Epoch 45; Iter   272/ 1097] train: loss: 0.0069960
[Epoch 45; Iter   302/ 1097] train: loss: 0.1262360
[Epoch 45; Iter   332/ 1097] train: loss: 0.0124607
[Epoch 45; Iter   362/ 1097] train: loss: 0.0009995
[Epoch 45; Iter   392/ 1097] train: loss: 0.3538225
[Epoch 45; Iter   422/ 1097] train: loss: 0.1382629
[Epoch 45; Iter   452/ 1097] train: loss: 0.0054077
[Epoch 45; Iter   482/ 1097] train: loss: 0.0006190
[Epoch 45; Iter   512/ 1097] train: loss: 0.0037469
[Epoch 45; Iter   542/ 1097] train: loss: 0.0036832
[Epoch 45; Iter   572/ 1097] train: loss: 0.0055063
[Epoch 45; Iter   602/ 1097] train: loss: 0.0018379
[Epoch 45; Iter   632/ 1097] train: loss: 0.0188405
[Epoch 45; Iter   662/ 1097] train: loss: 0.0234332
[Epoch 45; Iter   692/ 1097] train: loss: 0.0282234
[Epoch 45; Iter   722/ 1097] train: loss: 0.0103374
[Epoch 45; Iter   752/ 1097] train: loss: 0.0082695
[Epoch 45; Iter   782/ 1097] train: loss: 0.0149812
[Epoch 45; Iter   812/ 1097] train: loss: 0.0028409
[Epoch 45; Iter   842/ 1097] train: loss: 0.0021133
[Epoch 45; Iter   872/ 1097] train: loss: 0.0487354
[Epoch 45; Iter   902/ 1097] train: loss: 0.0247850
[Epoch 45; Iter   932/ 1097] train: loss: 0.0529135
[Epoch 45; Iter   962/ 1097] train: loss: 0.0008229
[Epoch 45; Iter   992/ 1097] train: loss: 0.0191214
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0044297
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0284004
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0024528
[Epoch 45] ogbg-molhiv: 0.799830 val loss: 15.250976
[Epoch 45] ogbg-molhiv: 0.702140 test loss: 12.540249
[Epoch 46; Iter    15/ 1097] train: loss: 0.0027282
[Epoch 46; Iter    45/ 1097] train: loss: 0.0019482
[Epoch 46; Iter    75/ 1097] train: loss: 0.0015659
[Epoch 46; Iter   105/ 1097] train: loss: 0.0005710
[Epoch 46; Iter   135/ 1097] train: loss: 0.0968231
[Epoch 46; Iter   165/ 1097] train: loss: 0.0024664
[Epoch 46; Iter   195/ 1097] train: loss: 0.0029512
[Epoch 46; Iter   225/ 1097] train: loss: 0.0027791
[Epoch 46; Iter   255/ 1097] train: loss: 0.0154741
[Epoch 46; Iter   285/ 1097] train: loss: 0.0080718
[Epoch 46; Iter   315/ 1097] train: loss: 0.0115064
[Epoch 46; Iter   345/ 1097] train: loss: 0.0031173
[Epoch 46; Iter   375/ 1097] train: loss: 0.0706278
[Epoch 46; Iter   405/ 1097] train: loss: 0.0028433
[Epoch 46; Iter   435/ 1097] train: loss: 0.0070213
[Epoch 46; Iter   465/ 1097] train: loss: 0.0531918
[Epoch 46; Iter   495/ 1097] train: loss: 0.0669583
[Epoch 46; Iter   525/ 1097] train: loss: 0.0020561
[Epoch 46; Iter   555/ 1097] train: loss: 0.0071571
[Epoch 46; Iter   585/ 1097] train: loss: 0.0052975
[Epoch 46; Iter   615/ 1097] train: loss: 0.3044460
[Epoch 46; Iter   645/ 1097] train: loss: 0.0033815
[Epoch 46; Iter   675/ 1097] train: loss: 0.0816555
[Epoch 46; Iter   705/ 1097] train: loss: 0.0019351
[Epoch 46; Iter   735/ 1097] train: loss: 0.0899158
[Epoch 46; Iter   765/ 1097] train: loss: 0.0037345
[Epoch 46; Iter   795/ 1097] train: loss: 0.0333361
[Epoch 46; Iter   825/ 1097] train: loss: 0.0176628
[Epoch 46; Iter   855/ 1097] train: loss: 0.0014560
[Epoch 46; Iter   885/ 1097] train: loss: 0.0233602
[Epoch 46; Iter   915/ 1097] train: loss: 0.1179043
[Epoch 46; Iter   945/ 1097] train: loss: 0.0040269
[Epoch 46; Iter   975/ 1097] train: loss: 0.0306907
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0027561
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0355811
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0026905
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0275057
[Epoch 46] ogbg-molhiv: 0.794517 val loss: 7.382792
[Epoch 46] ogbg-molhiv: 0.707182 test loss: 7.790770
[Epoch 47; Iter    28/ 1097] train: loss: 0.0039075
[Epoch 47; Iter    58/ 1097] train: loss: 0.0062184
[Epoch 47; Iter    88/ 1097] train: loss: 0.0491191
[Epoch 47; Iter   118/ 1097] train: loss: 0.0065160
[Epoch 47; Iter   148/ 1097] train: loss: 0.0015638
[Epoch 47; Iter   178/ 1097] train: loss: 0.0689468
[Epoch 47; Iter   208/ 1097] train: loss: 0.0176119
[Epoch 47; Iter   238/ 1097] train: loss: 0.0009350
[Epoch 47; Iter   268/ 1097] train: loss: 0.0039515
[Epoch 47; Iter   298/ 1097] train: loss: 0.0030232
[Epoch 47; Iter   328/ 1097] train: loss: 0.0345678
[Epoch 47; Iter   358/ 1097] train: loss: 0.0094817
[Epoch 47; Iter   388/ 1097] train: loss: 0.0027521
[Epoch 47; Iter   418/ 1097] train: loss: 0.0054620
[Epoch 47; Iter   448/ 1097] train: loss: 0.0015843
[Epoch 47; Iter   478/ 1097] train: loss: 0.0243365
[Epoch 47; Iter   508/ 1097] train: loss: 0.0066702
[Epoch 47; Iter   538/ 1097] train: loss: 0.0012069
[Epoch 47; Iter   568/ 1097] train: loss: 0.0043248
[Epoch 47; Iter   598/ 1097] train: loss: 0.0007548
[Epoch 47; Iter   628/ 1097] train: loss: 0.0005544
[Epoch 47; Iter   658/ 1097] train: loss: 0.0076818
[Epoch 47; Iter   688/ 1097] train: loss: 0.0006154
[Epoch 47; Iter   718/ 1097] train: loss: 0.0002686
[Epoch 47; Iter   748/ 1097] train: loss: 0.0027451
[Epoch 47; Iter   778/ 1097] train: loss: 0.0030660
[Epoch 47; Iter   808/ 1097] train: loss: 0.0304777
[Epoch 47; Iter   838/ 1097] train: loss: 0.0039642
[Epoch 47; Iter   868/ 1097] train: loss: 0.0752468
[Epoch 47; Iter   898/ 1097] train: loss: 0.0114206
[Epoch 47; Iter   928/ 1097] train: loss: 0.0124942
[Epoch 47; Iter   958/ 1097] train: loss: 0.0270508
[Epoch 47; Iter   988/ 1097] train: loss: 0.0954956
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0235630
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0537328
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0803659
[Epoch 47] ogbg-molhiv: 0.771969 val loss: 10.799667
[Epoch 47] ogbg-molhiv: 0.705861 test loss: 9.016849
[Epoch 48; Iter    11/ 1097] train: loss: 0.0010449
[Epoch 48; Iter    41/ 1097] train: loss: 0.1495008
[Epoch 48; Iter    71/ 1097] train: loss: 0.0217063
[Epoch 48; Iter   101/ 1097] train: loss: 0.2196602
[Epoch 48; Iter   131/ 1097] train: loss: 0.0034584
[Epoch 48; Iter   161/ 1097] train: loss: 0.0050660
[Epoch 48; Iter   191/ 1097] train: loss: 0.0064196
[Epoch 48; Iter   221/ 1097] train: loss: 0.0193035
[Epoch 48; Iter   251/ 1097] train: loss: 0.0119307
[Epoch 48; Iter   281/ 1097] train: loss: 0.0097568
[Epoch 48; Iter   311/ 1097] train: loss: 0.0004824
[Epoch 48; Iter   341/ 1097] train: loss: 0.0125217
[Epoch 48; Iter   371/ 1097] train: loss: 0.0002689
[Epoch 48; Iter   401/ 1097] train: loss: 0.0064352
[Epoch 48; Iter   431/ 1097] train: loss: 0.0102031
[Epoch 48; Iter   461/ 1097] train: loss: 0.0445318
[Epoch 48; Iter   491/ 1097] train: loss: 0.0015861
[Epoch 48; Iter   521/ 1097] train: loss: 0.0079518
[Epoch 48; Iter   551/ 1097] train: loss: 0.0012357
[Epoch 48; Iter   581/ 1097] train: loss: 0.0135772
[Epoch 48; Iter   611/ 1097] train: loss: 0.0007830
[Epoch 48; Iter   641/ 1097] train: loss: 0.0023273
[Epoch 48; Iter   671/ 1097] train: loss: 0.0027332
[Epoch 48; Iter   701/ 1097] train: loss: 0.0439240
[Epoch 48; Iter   731/ 1097] train: loss: 0.0010253
[Epoch 48; Iter   761/ 1097] train: loss: 0.0144597
[Epoch 48; Iter   791/ 1097] train: loss: 0.0095700
[Epoch 48; Iter   821/ 1097] train: loss: 0.0079750
[Epoch 44; Iter   769/ 1097] train: loss: 0.0084669
[Epoch 44; Iter   799/ 1097] train: loss: 0.0031289
[Epoch 44; Iter   829/ 1097] train: loss: 0.0003598
[Epoch 44; Iter   859/ 1097] train: loss: 0.0005777
[Epoch 44; Iter   889/ 1097] train: loss: 0.0002928
[Epoch 44; Iter   919/ 1097] train: loss: 0.0110613
[Epoch 44; Iter   949/ 1097] train: loss: 0.0007163
[Epoch 44; Iter   979/ 1097] train: loss: 0.0004930
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0018904
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0006441
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1007156
[Epoch 44] ogbg-molhiv: 0.709491 val loss: 3.379740
[Epoch 44] ogbg-molhiv: 0.676073 test loss: 2.212064
[Epoch 45; Iter     2/ 1097] train: loss: 0.0378767
[Epoch 45; Iter    32/ 1097] train: loss: 0.0009465
[Epoch 45; Iter    62/ 1097] train: loss: 0.0029263
[Epoch 45; Iter    92/ 1097] train: loss: 0.0016334
[Epoch 45; Iter   122/ 1097] train: loss: 0.0005813
[Epoch 45; Iter   152/ 1097] train: loss: 0.1119302
[Epoch 45; Iter   182/ 1097] train: loss: 0.0262913
[Epoch 45; Iter   212/ 1097] train: loss: 0.0248046
[Epoch 45; Iter   242/ 1097] train: loss: 0.0000442
[Epoch 45; Iter   272/ 1097] train: loss: 0.0019146
[Epoch 45; Iter   302/ 1097] train: loss: 0.0011858
[Epoch 45; Iter   332/ 1097] train: loss: 0.0002737
[Epoch 45; Iter   362/ 1097] train: loss: 0.0005146
[Epoch 45; Iter   392/ 1097] train: loss: 0.0009225
[Epoch 45; Iter   422/ 1097] train: loss: 0.0009700
[Epoch 45; Iter   452/ 1097] train: loss: 0.0017115
[Epoch 45; Iter   482/ 1097] train: loss: 0.1337032
[Epoch 45; Iter   512/ 1097] train: loss: 0.0042770
[Epoch 45; Iter   542/ 1097] train: loss: 0.0019684
[Epoch 45; Iter   572/ 1097] train: loss: 0.0227457
[Epoch 45; Iter   602/ 1097] train: loss: 0.0008170
[Epoch 45; Iter   632/ 1097] train: loss: 0.0039362
[Epoch 45; Iter   662/ 1097] train: loss: 0.0016989
[Epoch 45; Iter   692/ 1097] train: loss: 0.0031471
[Epoch 45; Iter   722/ 1097] train: loss: 0.0305219
[Epoch 45; Iter   752/ 1097] train: loss: 0.0008250
[Epoch 45; Iter   782/ 1097] train: loss: 0.0002867
[Epoch 45; Iter   812/ 1097] train: loss: 0.0000528
[Epoch 45; Iter   842/ 1097] train: loss: 0.0000559
[Epoch 45; Iter   872/ 1097] train: loss: 0.0729841
[Epoch 45; Iter   902/ 1097] train: loss: 0.0004489
[Epoch 45; Iter   932/ 1097] train: loss: 0.0008974
[Epoch 45; Iter   962/ 1097] train: loss: 0.0000642
[Epoch 45; Iter   992/ 1097] train: loss: 0.0052522
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0137679
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0026486
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0004339
[Epoch 45] ogbg-molhiv: 0.721910 val loss: 3.688160
[Epoch 45] ogbg-molhiv: 0.656529 test loss: 2.406682
[Epoch 46; Iter    15/ 1097] train: loss: 0.0000917
[Epoch 46; Iter    45/ 1097] train: loss: 0.0390510
[Epoch 46; Iter    75/ 1097] train: loss: 0.0005543
[Epoch 46; Iter   105/ 1097] train: loss: 0.0004444
[Epoch 46; Iter   135/ 1097] train: loss: 0.0000744
[Epoch 46; Iter   165/ 1097] train: loss: 0.0027558
[Epoch 46; Iter   195/ 1097] train: loss: 0.0057097
[Epoch 46; Iter   225/ 1097] train: loss: 0.0017792
[Epoch 46; Iter   255/ 1097] train: loss: 0.0011189
[Epoch 46; Iter   285/ 1097] train: loss: 0.0023339
[Epoch 46; Iter   315/ 1097] train: loss: 0.0008523
[Epoch 46; Iter   345/ 1097] train: loss: 0.0000561
[Epoch 46; Iter   375/ 1097] train: loss: 0.0011025
[Epoch 46; Iter   405/ 1097] train: loss: 0.0001765
[Epoch 46; Iter   435/ 1097] train: loss: 0.0690718
[Epoch 46; Iter   465/ 1097] train: loss: 0.0034678
[Epoch 46; Iter   495/ 1097] train: loss: 0.0013995
[Epoch 46; Iter   525/ 1097] train: loss: 0.0016042
[Epoch 46; Iter   555/ 1097] train: loss: 0.0040743
[Epoch 46; Iter   585/ 1097] train: loss: 0.0132136
[Epoch 46; Iter   615/ 1097] train: loss: 0.0000396
[Epoch 46; Iter   645/ 1097] train: loss: 0.0003593
[Epoch 46; Iter   675/ 1097] train: loss: 0.0012722
[Epoch 46; Iter   705/ 1097] train: loss: 0.0015175
[Epoch 46; Iter   735/ 1097] train: loss: 0.0001121
[Epoch 46; Iter   765/ 1097] train: loss: 0.0024026
[Epoch 46; Iter   795/ 1097] train: loss: 0.0000588
[Epoch 46; Iter   825/ 1097] train: loss: 0.0039535
[Epoch 46; Iter   855/ 1097] train: loss: 0.0029635
[Epoch 46; Iter   885/ 1097] train: loss: 0.0007113
[Epoch 46; Iter   915/ 1097] train: loss: 0.0002453
[Epoch 46; Iter   945/ 1097] train: loss: 0.0001827
[Epoch 46; Iter   975/ 1097] train: loss: 0.0033731
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0004308
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0026634
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0004235
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0003503
[Epoch 46] ogbg-molhiv: 0.742639 val loss: 0.335543
[Epoch 46] ogbg-molhiv: 0.673959 test loss: 0.414691
[Epoch 47; Iter    28/ 1097] train: loss: 0.0002308
[Epoch 47; Iter    58/ 1097] train: loss: 0.0012000
[Epoch 47; Iter    88/ 1097] train: loss: 0.0006947
[Epoch 47; Iter   118/ 1097] train: loss: 0.0764671
[Epoch 47; Iter   148/ 1097] train: loss: 0.0003583
[Epoch 47; Iter   178/ 1097] train: loss: 0.0124943
[Epoch 47; Iter   208/ 1097] train: loss: 0.0001650
[Epoch 47; Iter   238/ 1097] train: loss: 0.0053633
[Epoch 47; Iter   268/ 1097] train: loss: 0.0009289
[Epoch 47; Iter   298/ 1097] train: loss: 0.0357142
[Epoch 47; Iter   328/ 1097] train: loss: 0.0025918
[Epoch 47; Iter   358/ 1097] train: loss: 0.1850817
[Epoch 47; Iter   388/ 1097] train: loss: 0.0021322
[Epoch 47; Iter   418/ 1097] train: loss: 0.0022985
[Epoch 47; Iter   448/ 1097] train: loss: 0.0053042
[Epoch 47; Iter   478/ 1097] train: loss: 0.0051927
[Epoch 47; Iter   508/ 1097] train: loss: 0.0130700
[Epoch 47; Iter   538/ 1097] train: loss: 0.0001432
[Epoch 47; Iter   568/ 1097] train: loss: 0.0001871
[Epoch 47; Iter   598/ 1097] train: loss: 0.0000649
[Epoch 47; Iter   628/ 1097] train: loss: 0.0040567
[Epoch 47; Iter   658/ 1097] train: loss: 0.0049852
[Epoch 47; Iter   688/ 1097] train: loss: 0.0188017
[Epoch 47; Iter   718/ 1097] train: loss: 0.0015923
[Epoch 47; Iter   748/ 1097] train: loss: 0.0017686
[Epoch 47; Iter   778/ 1097] train: loss: 0.0009590
[Epoch 47; Iter   808/ 1097] train: loss: 0.0001029
[Epoch 47; Iter   838/ 1097] train: loss: 0.0091310
[Epoch 47; Iter   868/ 1097] train: loss: 0.0014317
[Epoch 47; Iter   898/ 1097] train: loss: 0.0648655
[Epoch 47; Iter   928/ 1097] train: loss: 0.0011395
[Epoch 47; Iter   958/ 1097] train: loss: 0.0008764
[Epoch 47; Iter   988/ 1097] train: loss: 0.0010197
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0002194
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0013600
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0025907
[Epoch 47] ogbg-molhiv: 0.760000 val loss: 1.657230
[Epoch 47] ogbg-molhiv: 0.691531 test loss: 1.177578
[Epoch 48; Iter    11/ 1097] train: loss: 0.0664848
[Epoch 48; Iter    41/ 1097] train: loss: 0.0049163
[Epoch 48; Iter    71/ 1097] train: loss: 0.0000146
[Epoch 48; Iter   101/ 1097] train: loss: 0.0542042
[Epoch 48; Iter   131/ 1097] train: loss: 0.0011413
[Epoch 48; Iter   161/ 1097] train: loss: 0.0003089
[Epoch 48; Iter   191/ 1097] train: loss: 0.0002114
[Epoch 48; Iter   221/ 1097] train: loss: 0.0001934
[Epoch 48; Iter   251/ 1097] train: loss: 0.0021537
[Epoch 48; Iter   281/ 1097] train: loss: 0.0010260
[Epoch 48; Iter   311/ 1097] train: loss: 0.0005958
[Epoch 48; Iter   341/ 1097] train: loss: 0.0005922
[Epoch 48; Iter   371/ 1097] train: loss: 0.0222838
[Epoch 48; Iter   401/ 1097] train: loss: 0.0025852
[Epoch 48; Iter   431/ 1097] train: loss: 0.0004876
[Epoch 48; Iter   461/ 1097] train: loss: 0.0050820
[Epoch 48; Iter   491/ 1097] train: loss: 0.0004778
[Epoch 48; Iter   521/ 1097] train: loss: 0.0016655
[Epoch 48; Iter   551/ 1097] train: loss: 0.0277279
[Epoch 48; Iter   581/ 1097] train: loss: 0.1260920
[Epoch 48; Iter   611/ 1097] train: loss: 0.0003795
[Epoch 48; Iter   641/ 1097] train: loss: 0.0005567
[Epoch 48; Iter   671/ 1097] train: loss: 0.0013053
[Epoch 48; Iter   701/ 1097] train: loss: 0.0002421
[Epoch 48; Iter   731/ 1097] train: loss: 0.0002424
[Epoch 48; Iter   761/ 1097] train: loss: 0.0078230
[Epoch 48; Iter   791/ 1097] train: loss: 0.0002741
[Epoch 48; Iter   821/ 1097] train: loss: 0.0061954
[Epoch 48; Iter   851/ 1097] train: loss: 0.0009649
[Epoch 48; Iter   881/ 1097] train: loss: 0.0091507
[Epoch 48; Iter   911/ 1097] train: loss: 0.0046151
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015471
[Epoch 48; Iter   971/ 1097] train: loss: 0.0257413
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0142126
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0014518
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0004474
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0238573
[Epoch 48] ogbg-molhiv: 0.690225 val loss: 0.181587
[Epoch 48] ogbg-molhiv: 0.729504 test loss: 0.311847
[Epoch 49; Iter    24/ 1097] train: loss: 0.0085438
[Epoch 49; Iter    54/ 1097] train: loss: 0.0021518
[Epoch 49; Iter    84/ 1097] train: loss: 0.0235419
[Epoch 49; Iter   114/ 1097] train: loss: 0.0062532
[Epoch 49; Iter   144/ 1097] train: loss: 0.0002234
[Epoch 49; Iter   174/ 1097] train: loss: 0.0412132
[Epoch 49; Iter   204/ 1097] train: loss: 0.0045723
[Epoch 49; Iter   234/ 1097] train: loss: 0.0249704
[Epoch 49; Iter   264/ 1097] train: loss: 0.0107949
[Epoch 49; Iter   294/ 1097] train: loss: 0.0005576
[Epoch 49; Iter   324/ 1097] train: loss: 0.1650785
[Epoch 49; Iter   354/ 1097] train: loss: 0.0065107
[Epoch 49; Iter   384/ 1097] train: loss: 0.0077058
[Epoch 49; Iter   414/ 1097] train: loss: 0.0501331
[Epoch 49; Iter   444/ 1097] train: loss: 0.0004413
[Epoch 49; Iter   474/ 1097] train: loss: 0.0557584
[Epoch 49; Iter   504/ 1097] train: loss: 0.0076071
[Epoch 49; Iter   534/ 1097] train: loss: 0.1064919
[Epoch 49; Iter   564/ 1097] train: loss: 0.0007927
[Epoch 49; Iter   594/ 1097] train: loss: 0.0004984
[Epoch 49; Iter   624/ 1097] train: loss: 0.0286167
[Epoch 49; Iter   654/ 1097] train: loss: 0.0004241
[Epoch 49; Iter   684/ 1097] train: loss: 0.0020830
[Epoch 49; Iter   714/ 1097] train: loss: 0.0008499
[Epoch 49; Iter   744/ 1097] train: loss: 0.0516430
[Epoch 49; Iter   774/ 1097] train: loss: 0.0013592
[Epoch 49; Iter   804/ 1097] train: loss: 0.0108920
[Epoch 49; Iter   834/ 1097] train: loss: 0.0057505
[Epoch 49; Iter   864/ 1097] train: loss: 0.0083662
[Epoch 49; Iter   894/ 1097] train: loss: 0.0018878
[Epoch 49; Iter   924/ 1097] train: loss: 0.0015811
[Epoch 49; Iter   954/ 1097] train: loss: 0.0343895
[Epoch 49; Iter   984/ 1097] train: loss: 0.0583544
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0129377
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0011969
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0526132
[Epoch 49] ogbg-molhiv: 0.699086 val loss: 0.662221
[Epoch 49] ogbg-molhiv: 0.728457 test loss: 0.284211
[Epoch 50; Iter     7/ 1097] train: loss: 0.0245033
[Epoch 50; Iter    37/ 1097] train: loss: 0.0010682
[Epoch 50; Iter    67/ 1097] train: loss: 0.0227308
[Epoch 50; Iter    97/ 1097] train: loss: 0.0013529
[Epoch 50; Iter   127/ 1097] train: loss: 0.0022378
[Epoch 50; Iter   157/ 1097] train: loss: 0.0040547
[Epoch 50; Iter   187/ 1097] train: loss: 0.0004512
[Epoch 50; Iter   217/ 1097] train: loss: 0.0015095
[Epoch 50; Iter   247/ 1097] train: loss: 0.0023548
[Epoch 50; Iter   277/ 1097] train: loss: 0.0062655
[Epoch 50; Iter   307/ 1097] train: loss: 0.0073311
[Epoch 50; Iter   337/ 1097] train: loss: 0.0031848
[Epoch 50; Iter   367/ 1097] train: loss: 0.0479980
[Epoch 50; Iter   397/ 1097] train: loss: 0.0014401
[Epoch 50; Iter   427/ 1097] train: loss: 0.0011972
[Epoch 50; Iter   457/ 1097] train: loss: 0.0006207
[Epoch 50; Iter   487/ 1097] train: loss: 0.0431790
[Epoch 50; Iter   517/ 1097] train: loss: 0.0034869
[Epoch 50; Iter   547/ 1097] train: loss: 0.0162764
[Epoch 50; Iter   577/ 1097] train: loss: 0.0027752
[Epoch 50; Iter   607/ 1097] train: loss: 0.0054956
[Epoch 50; Iter   637/ 1097] train: loss: 0.0037107
[Epoch 50; Iter   667/ 1097] train: loss: 0.0003518
[Epoch 50; Iter   697/ 1097] train: loss: 0.0025034
[Epoch 50; Iter   727/ 1097] train: loss: 0.0352776
[Epoch 50; Iter   757/ 1097] train: loss: 0.0016356
[Epoch 50; Iter   787/ 1097] train: loss: 0.0156907
[Epoch 50; Iter   817/ 1097] train: loss: 0.0712824
[Epoch 50; Iter   847/ 1097] train: loss: 0.0009420
[Epoch 50; Iter   877/ 1097] train: loss: 0.0097078
[Epoch 50; Iter   907/ 1097] train: loss: 0.0497974
[Epoch 50; Iter   937/ 1097] train: loss: 0.0009454
[Epoch 50; Iter   967/ 1097] train: loss: 0.0207716
[Epoch 50; Iter   997/ 1097] train: loss: 0.0041456
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0013087
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0010408
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0158509
[Epoch 50] ogbg-molhiv: 0.671985 val loss: 0.194564
[Epoch 50] ogbg-molhiv: 0.708048 test loss: 0.310492
[Epoch 51; Iter    20/ 1097] train: loss: 0.0160332
[Epoch 51; Iter    50/ 1097] train: loss: 0.0049778
[Epoch 51; Iter    80/ 1097] train: loss: 0.0000941
[Epoch 51; Iter   110/ 1097] train: loss: 0.0134620
[Epoch 51; Iter   140/ 1097] train: loss: 0.0011967
[Epoch 51; Iter   170/ 1097] train: loss: 0.0003361
[Epoch 51; Iter   200/ 1097] train: loss: 0.0119354
[Epoch 51; Iter   230/ 1097] train: loss: 0.0650090
[Epoch 51; Iter   260/ 1097] train: loss: 0.0248393
[Epoch 51; Iter   290/ 1097] train: loss: 0.0007686
[Epoch 51; Iter   320/ 1097] train: loss: 0.0406092
[Epoch 51; Iter   350/ 1097] train: loss: 0.0006057
[Epoch 51; Iter   380/ 1097] train: loss: 0.0043257
[Epoch 51; Iter   410/ 1097] train: loss: 0.0051864
[Epoch 51; Iter   440/ 1097] train: loss: 0.0080614
[Epoch 51; Iter   470/ 1097] train: loss: 0.0318935
[Epoch 51; Iter   500/ 1097] train: loss: 0.0006877
[Epoch 51; Iter   530/ 1097] train: loss: 0.0034122
[Epoch 51; Iter   560/ 1097] train: loss: 0.0004320
[Epoch 51; Iter   590/ 1097] train: loss: 0.0093498
[Epoch 51; Iter   620/ 1097] train: loss: 0.0010592
[Epoch 51; Iter   650/ 1097] train: loss: 0.0004571
[Epoch 51; Iter   680/ 1097] train: loss: 0.0001919
[Epoch 51; Iter   710/ 1097] train: loss: 0.0002570
[Epoch 51; Iter   740/ 1097] train: loss: 0.0012981
[Epoch 51; Iter   770/ 1097] train: loss: 0.0415601
[Epoch 51; Iter   800/ 1097] train: loss: 0.0633049
[Epoch 51; Iter   830/ 1097] train: loss: 0.0933048
[Epoch 51; Iter   860/ 1097] train: loss: 0.0011079
[Epoch 51; Iter   890/ 1097] train: loss: 0.0003964
[Epoch 51; Iter   920/ 1097] train: loss: 0.0111532
[Epoch 51; Iter   950/ 1097] train: loss: 0.0011175
[Epoch 51; Iter   980/ 1097] train: loss: 0.0009988
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0373405
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0014837
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0004609
[Epoch 51] ogbg-molhiv: 0.692721 val loss: 0.384390
[Epoch 51] ogbg-molhiv: 0.731870 test loss: 0.429093
[Epoch 52; Iter     3/ 1097] train: loss: 0.0225908
[Epoch 52; Iter    33/ 1097] train: loss: 0.0017828
[Epoch 52; Iter    63/ 1097] train: loss: 0.0248116
[Epoch 52; Iter    93/ 1097] train: loss: 0.0261537
[Epoch 52; Iter   123/ 1097] train: loss: 0.0020002
[Epoch 52; Iter   153/ 1097] train: loss: 0.0075480
[Epoch 52; Iter   183/ 1097] train: loss: 0.0019646
[Epoch 52; Iter   213/ 1097] train: loss: 0.0021839
[Epoch 52; Iter   243/ 1097] train: loss: 0.0000809
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002226
[Epoch 52; Iter   303/ 1097] train: loss: 0.0324536
[Epoch 52; Iter   333/ 1097] train: loss: 0.0008417
[Epoch 52; Iter   363/ 1097] train: loss: 0.0018294
[Epoch 52; Iter   393/ 1097] train: loss: 0.0077556
[Epoch 52; Iter   423/ 1097] train: loss: 0.0667897
[Epoch 52; Iter   453/ 1097] train: loss: 0.0019607
[Epoch 52; Iter   483/ 1097] train: loss: 0.0026892
[Epoch 52; Iter   513/ 1097] train: loss: 0.0011445
[Epoch 52; Iter   543/ 1097] train: loss: 0.0048944
[Epoch 52; Iter   573/ 1097] train: loss: 0.0035877
[Epoch 52; Iter   603/ 1097] train: loss: 0.0005407
[Epoch 52; Iter   633/ 1097] train: loss: 0.0007161
[Epoch 52; Iter   663/ 1097] train: loss: 0.0059544
[Epoch 52; Iter   693/ 1097] train: loss: 0.0011019
[Epoch 52; Iter   723/ 1097] train: loss: 0.0013517
[Epoch 52; Iter   753/ 1097] train: loss: 0.0051917
[Epoch 52; Iter   783/ 1097] train: loss: 0.0030722
[Epoch 52; Iter   813/ 1097] train: loss: 0.0033229
[Epoch 52; Iter   843/ 1097] train: loss: 0.0010342
[Epoch 52; Iter   873/ 1097] train: loss: 0.0005400
[Epoch 52; Iter   903/ 1097] train: loss: 0.0104738
[Epoch 48; Iter   851/ 1097] train: loss: 0.0039712
[Epoch 48; Iter   881/ 1097] train: loss: 0.0116688
[Epoch 48; Iter   911/ 1097] train: loss: 0.0369079
[Epoch 48; Iter   941/ 1097] train: loss: 0.0133091
[Epoch 48; Iter   971/ 1097] train: loss: 0.0144820
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0006554
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0038324
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0319360
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0070733
[Epoch 48] ogbg-molhiv: 0.766237 val loss: 0.201748
[Epoch 48] ogbg-molhiv: 0.748423 test loss: 0.258861
[Epoch 49; Iter    24/ 1097] train: loss: 0.0009323
[Epoch 49; Iter    54/ 1097] train: loss: 0.0276855
[Epoch 49; Iter    84/ 1097] train: loss: 0.0000703
[Epoch 49; Iter   114/ 1097] train: loss: 0.0184949
[Epoch 49; Iter   144/ 1097] train: loss: 0.0039444
[Epoch 49; Iter   174/ 1097] train: loss: 0.0223565
[Epoch 49; Iter   204/ 1097] train: loss: 0.0026127
[Epoch 49; Iter   234/ 1097] train: loss: 0.0220484
[Epoch 49; Iter   264/ 1097] train: loss: 0.0016877
[Epoch 49; Iter   294/ 1097] train: loss: 0.0001706
[Epoch 49; Iter   324/ 1097] train: loss: 0.0003652
[Epoch 49; Iter   354/ 1097] train: loss: 0.0049159
[Epoch 49; Iter   384/ 1097] train: loss: 0.0004792
[Epoch 49; Iter   414/ 1097] train: loss: 0.0199411
[Epoch 49; Iter   444/ 1097] train: loss: 0.0057238
[Epoch 49; Iter   474/ 1097] train: loss: 0.0140996
[Epoch 49; Iter   504/ 1097] train: loss: 0.0030550
[Epoch 49; Iter   534/ 1097] train: loss: 0.0002400
[Epoch 49; Iter   564/ 1097] train: loss: 0.0068735
[Epoch 49; Iter   594/ 1097] train: loss: 0.0117199
[Epoch 49; Iter   624/ 1097] train: loss: 0.0750023
[Epoch 49; Iter   654/ 1097] train: loss: 0.0022725
[Epoch 49; Iter   684/ 1097] train: loss: 0.0039636
[Epoch 49; Iter   714/ 1097] train: loss: 0.0011123
[Epoch 49; Iter   744/ 1097] train: loss: 0.0067225
[Epoch 49; Iter   774/ 1097] train: loss: 0.0072292
[Epoch 49; Iter   804/ 1097] train: loss: 0.1020195
[Epoch 49; Iter   834/ 1097] train: loss: 0.0129402
[Epoch 49; Iter   864/ 1097] train: loss: 0.0150188
[Epoch 49; Iter   894/ 1097] train: loss: 0.0004638
[Epoch 49; Iter   924/ 1097] train: loss: 0.0052845
[Epoch 49; Iter   954/ 1097] train: loss: 0.0014045
[Epoch 49; Iter   984/ 1097] train: loss: 0.0004678
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0029618
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0007834
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0018521
[Epoch 49] ogbg-molhiv: 0.776342 val loss: 0.206935
[Epoch 49] ogbg-molhiv: 0.745121 test loss: 0.330680
[Epoch 50; Iter     7/ 1097] train: loss: 0.1784326
[Epoch 50; Iter    37/ 1097] train: loss: 0.0030247
[Epoch 50; Iter    67/ 1097] train: loss: 0.0008424
[Epoch 50; Iter    97/ 1097] train: loss: 0.0098249
[Epoch 50; Iter   127/ 1097] train: loss: 0.0129865
[Epoch 50; Iter   157/ 1097] train: loss: 0.0011727
[Epoch 50; Iter   187/ 1097] train: loss: 0.0004329
[Epoch 50; Iter   217/ 1097] train: loss: 0.0123581
[Epoch 50; Iter   247/ 1097] train: loss: 0.0206209
[Epoch 50; Iter   277/ 1097] train: loss: 0.0111611
[Epoch 50; Iter   307/ 1097] train: loss: 0.0022588
[Epoch 50; Iter   337/ 1097] train: loss: 0.0028252
[Epoch 50; Iter   367/ 1097] train: loss: 0.0039460
[Epoch 50; Iter   397/ 1097] train: loss: 0.0029384
[Epoch 50; Iter   427/ 1097] train: loss: 0.1864693
[Epoch 50; Iter   457/ 1097] train: loss: 0.0004364
[Epoch 50; Iter   487/ 1097] train: loss: 0.0074504
[Epoch 50; Iter   517/ 1097] train: loss: 0.0030333
[Epoch 50; Iter   547/ 1097] train: loss: 0.0047228
[Epoch 50; Iter   577/ 1097] train: loss: 0.1066095
[Epoch 50; Iter   607/ 1097] train: loss: 0.0007549
[Epoch 50; Iter   637/ 1097] train: loss: 0.0098491
[Epoch 50; Iter   667/ 1097] train: loss: 0.0050507
[Epoch 50; Iter   697/ 1097] train: loss: 0.0036235
[Epoch 50; Iter   727/ 1097] train: loss: 0.0083998
[Epoch 50; Iter   757/ 1097] train: loss: 0.0012998
[Epoch 50; Iter   787/ 1097] train: loss: 0.0062014
[Epoch 50; Iter   817/ 1097] train: loss: 0.0035880
[Epoch 50; Iter   847/ 1097] train: loss: 0.0102278
[Epoch 50; Iter   877/ 1097] train: loss: 0.0028709
[Epoch 50; Iter   907/ 1097] train: loss: 0.0157178
[Epoch 50; Iter   937/ 1097] train: loss: 0.0052421
[Epoch 50; Iter   967/ 1097] train: loss: 0.0370210
[Epoch 50; Iter   997/ 1097] train: loss: 0.0004479
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0026813
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0008321
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0097161
[Epoch 50] ogbg-molhiv: 0.761687 val loss: 0.210938
[Epoch 50] ogbg-molhiv: 0.752394 test loss: 0.251956
[Epoch 51; Iter    20/ 1097] train: loss: 0.0014609
[Epoch 51; Iter    50/ 1097] train: loss: 0.0062612
[Epoch 51; Iter    80/ 1097] train: loss: 0.0022039
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007610
[Epoch 51; Iter   140/ 1097] train: loss: 0.0704914
[Epoch 51; Iter   170/ 1097] train: loss: 0.0026576
[Epoch 51; Iter   200/ 1097] train: loss: 0.0005268
[Epoch 51; Iter   230/ 1097] train: loss: 0.0021410
[Epoch 51; Iter   260/ 1097] train: loss: 0.0011181
[Epoch 51; Iter   290/ 1097] train: loss: 0.0086973
[Epoch 51; Iter   320/ 1097] train: loss: 0.0045904
[Epoch 51; Iter   350/ 1097] train: loss: 0.0002801
[Epoch 51; Iter   380/ 1097] train: loss: 0.0080926
[Epoch 51; Iter   410/ 1097] train: loss: 0.0108411
[Epoch 51; Iter   440/ 1097] train: loss: 0.0005963
[Epoch 51; Iter   470/ 1097] train: loss: 0.0040017
[Epoch 51; Iter   500/ 1097] train: loss: 0.1798965
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004392
[Epoch 51; Iter   560/ 1097] train: loss: 0.0047196
[Epoch 51; Iter   590/ 1097] train: loss: 0.0011806
[Epoch 51; Iter   620/ 1097] train: loss: 0.0163468
[Epoch 51; Iter   650/ 1097] train: loss: 0.0034905
[Epoch 51; Iter   680/ 1097] train: loss: 0.0157751
[Epoch 51; Iter   710/ 1097] train: loss: 0.0018564
[Epoch 51; Iter   740/ 1097] train: loss: 0.0078144
[Epoch 51; Iter   770/ 1097] train: loss: 0.1091505
[Epoch 51; Iter   800/ 1097] train: loss: 0.0089452
[Epoch 51; Iter   830/ 1097] train: loss: 0.0064265
[Epoch 51; Iter   860/ 1097] train: loss: 0.0017296
[Epoch 51; Iter   890/ 1097] train: loss: 0.0037498
[Epoch 51; Iter   920/ 1097] train: loss: 0.0002995
[Epoch 51; Iter   950/ 1097] train: loss: 0.0006508
[Epoch 51; Iter   980/ 1097] train: loss: 0.0012331
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0009581
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0024319
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0232991
[Epoch 51] ogbg-molhiv: 0.758004 val loss: 0.284595
[Epoch 51] ogbg-molhiv: 0.739750 test loss: 0.305734
[Epoch 52; Iter     3/ 1097] train: loss: 0.0047814
[Epoch 52; Iter    33/ 1097] train: loss: 0.0010717
[Epoch 52; Iter    63/ 1097] train: loss: 0.0129217
[Epoch 52; Iter    93/ 1097] train: loss: 0.0034178
[Epoch 52; Iter   123/ 1097] train: loss: 0.0004124
[Epoch 52; Iter   153/ 1097] train: loss: 0.0002945
[Epoch 52; Iter   183/ 1097] train: loss: 0.0016344
[Epoch 52; Iter   213/ 1097] train: loss: 0.0038734
[Epoch 52; Iter   243/ 1097] train: loss: 0.0009790
[Epoch 52; Iter   273/ 1097] train: loss: 0.0055452
[Epoch 52; Iter   303/ 1097] train: loss: 0.0004692
[Epoch 52; Iter   333/ 1097] train: loss: 0.0429028
[Epoch 52; Iter   363/ 1097] train: loss: 0.0026768
[Epoch 52; Iter   393/ 1097] train: loss: 0.0045657
[Epoch 52; Iter   423/ 1097] train: loss: 0.0065662
[Epoch 52; Iter   453/ 1097] train: loss: 0.0146164
[Epoch 52; Iter   483/ 1097] train: loss: 0.0003228
[Epoch 52; Iter   513/ 1097] train: loss: 0.0869479
[Epoch 52; Iter   543/ 1097] train: loss: 0.0024747
[Epoch 52; Iter   573/ 1097] train: loss: 0.0011740
[Epoch 52; Iter   603/ 1097] train: loss: 0.0030708
[Epoch 52; Iter   633/ 1097] train: loss: 0.0004966
[Epoch 52; Iter   663/ 1097] train: loss: 0.0112828
[Epoch 52; Iter   693/ 1097] train: loss: 0.0087521
[Epoch 52; Iter   723/ 1097] train: loss: 0.0018254
[Epoch 52; Iter   753/ 1097] train: loss: 0.0004672
[Epoch 52; Iter   783/ 1097] train: loss: 0.0008679
[Epoch 52; Iter   813/ 1097] train: loss: 0.0445781
[Epoch 52; Iter   843/ 1097] train: loss: 0.0043409
[Epoch 52; Iter   873/ 1097] train: loss: 0.0809680
[Epoch 52; Iter   903/ 1097] train: loss: 0.0116869
[Epoch 48; Iter   851/ 1097] train: loss: 0.0019530
[Epoch 48; Iter   881/ 1097] train: loss: 0.1251931
[Epoch 48; Iter   911/ 1097] train: loss: 0.0220912
[Epoch 48; Iter   941/ 1097] train: loss: 0.0300006
[Epoch 48; Iter   971/ 1097] train: loss: 0.0016406
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0031614
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0065017
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0630816
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0038451
[Epoch 48] ogbg-molhiv: 0.739017 val loss: 0.502854
[Epoch 48] ogbg-molhiv: 0.716043 test loss: 0.280242
[Epoch 49; Iter    24/ 1097] train: loss: 0.0036770
[Epoch 49; Iter    54/ 1097] train: loss: 0.0057704
[Epoch 49; Iter    84/ 1097] train: loss: 0.0005477
[Epoch 49; Iter   114/ 1097] train: loss: 0.0161545
[Epoch 49; Iter   144/ 1097] train: loss: 0.0103910
[Epoch 49; Iter   174/ 1097] train: loss: 0.0902699
[Epoch 49; Iter   204/ 1097] train: loss: 0.0028592
[Epoch 49; Iter   234/ 1097] train: loss: 0.0226180
[Epoch 49; Iter   264/ 1097] train: loss: 0.0437636
[Epoch 49; Iter   294/ 1097] train: loss: 0.0034683
[Epoch 49; Iter   324/ 1097] train: loss: 0.0026733
[Epoch 49; Iter   354/ 1097] train: loss: 0.0012726
[Epoch 49; Iter   384/ 1097] train: loss: 0.0502026
[Epoch 49; Iter   414/ 1097] train: loss: 0.0161753
[Epoch 49; Iter   444/ 1097] train: loss: 0.0973233
[Epoch 49; Iter   474/ 1097] train: loss: 0.0018643
[Epoch 49; Iter   504/ 1097] train: loss: 0.0517030
[Epoch 49; Iter   534/ 1097] train: loss: 0.0016988
[Epoch 49; Iter   564/ 1097] train: loss: 0.0153193
[Epoch 49; Iter   594/ 1097] train: loss: 0.0018063
[Epoch 49; Iter   624/ 1097] train: loss: 0.1175374
[Epoch 49; Iter   654/ 1097] train: loss: 0.0114482
[Epoch 49; Iter   684/ 1097] train: loss: 0.0022036
[Epoch 49; Iter   714/ 1097] train: loss: 0.0040429
[Epoch 49; Iter   744/ 1097] train: loss: 0.0010796
[Epoch 49; Iter   774/ 1097] train: loss: 0.0114854
[Epoch 49; Iter   804/ 1097] train: loss: 0.0193571
[Epoch 49; Iter   834/ 1097] train: loss: 0.0022133
[Epoch 49; Iter   864/ 1097] train: loss: 0.0088992
[Epoch 49; Iter   894/ 1097] train: loss: 0.0062423
[Epoch 49; Iter   924/ 1097] train: loss: 0.0149924
[Epoch 49; Iter   954/ 1097] train: loss: 0.0093928
[Epoch 49; Iter   984/ 1097] train: loss: 0.0126754
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0213559
[Epoch 49; Iter  1044/ 1097] train: loss: 0.1229243
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0280534
[Epoch 49] ogbg-molhiv: 0.738610 val loss: 0.487953
[Epoch 49] ogbg-molhiv: 0.711188 test loss: 0.281120
[Epoch 50; Iter     7/ 1097] train: loss: 0.0067409
[Epoch 50; Iter    37/ 1097] train: loss: 0.0156805
[Epoch 50; Iter    67/ 1097] train: loss: 0.0066330
[Epoch 50; Iter    97/ 1097] train: loss: 0.0035172
[Epoch 50; Iter   127/ 1097] train: loss: 0.0105581
[Epoch 50; Iter   157/ 1097] train: loss: 0.0029343
[Epoch 50; Iter   187/ 1097] train: loss: 0.0080497
[Epoch 50; Iter   217/ 1097] train: loss: 0.0215147
[Epoch 50; Iter   247/ 1097] train: loss: 0.0015283
[Epoch 50; Iter   277/ 1097] train: loss: 0.0011125
[Epoch 50; Iter   307/ 1097] train: loss: 0.0185148
[Epoch 50; Iter   337/ 1097] train: loss: 0.0591958
[Epoch 50; Iter   367/ 1097] train: loss: 0.0082495
[Epoch 50; Iter   397/ 1097] train: loss: 0.0154418
[Epoch 50; Iter   427/ 1097] train: loss: 0.0011455
[Epoch 50; Iter   457/ 1097] train: loss: 0.0143536
[Epoch 50; Iter   487/ 1097] train: loss: 0.0321869
[Epoch 50; Iter   517/ 1097] train: loss: 0.0023272
[Epoch 50; Iter   547/ 1097] train: loss: 0.0666045
[Epoch 50; Iter   577/ 1097] train: loss: 0.0028678
[Epoch 50; Iter   607/ 1097] train: loss: 0.0009748
[Epoch 50; Iter   637/ 1097] train: loss: 0.0150398
[Epoch 50; Iter   667/ 1097] train: loss: 0.0104855
[Epoch 50; Iter   697/ 1097] train: loss: 0.0229066
[Epoch 50; Iter   727/ 1097] train: loss: 0.0003674
[Epoch 50; Iter   757/ 1097] train: loss: 0.0016730
[Epoch 50; Iter   787/ 1097] train: loss: 0.0029454
[Epoch 50; Iter   817/ 1097] train: loss: 0.1756625
[Epoch 50; Iter   847/ 1097] train: loss: 0.0067861
[Epoch 50; Iter   877/ 1097] train: loss: 0.0016157
[Epoch 50; Iter   907/ 1097] train: loss: 0.0099428
[Epoch 50; Iter   937/ 1097] train: loss: 0.0133079
[Epoch 50; Iter   967/ 1097] train: loss: 0.0273053
[Epoch 50; Iter   997/ 1097] train: loss: 0.1588880
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0120018
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0028753
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0125882
[Epoch 50] ogbg-molhiv: 0.715440 val loss: 0.609141
[Epoch 50] ogbg-molhiv: 0.688418 test loss: 0.525526
[Epoch 51; Iter    20/ 1097] train: loss: 0.0710082
[Epoch 51; Iter    50/ 1097] train: loss: 0.0003789
[Epoch 51; Iter    80/ 1097] train: loss: 0.0385678
[Epoch 51; Iter   110/ 1097] train: loss: 0.0003569
[Epoch 51; Iter   140/ 1097] train: loss: 0.0031680
[Epoch 51; Iter   170/ 1097] train: loss: 0.0163176
[Epoch 51; Iter   200/ 1097] train: loss: 0.0596270
[Epoch 51; Iter   230/ 1097] train: loss: 0.0047136
[Epoch 51; Iter   260/ 1097] train: loss: 0.0131921
[Epoch 51; Iter   290/ 1097] train: loss: 0.0238583
[Epoch 51; Iter   320/ 1097] train: loss: 0.0171233
[Epoch 51; Iter   350/ 1097] train: loss: 0.0613584
[Epoch 51; Iter   380/ 1097] train: loss: 0.0060874
[Epoch 51; Iter   410/ 1097] train: loss: 0.0113445
[Epoch 51; Iter   440/ 1097] train: loss: 0.0014079
[Epoch 51; Iter   470/ 1097] train: loss: 0.0013036
[Epoch 51; Iter   500/ 1097] train: loss: 0.0030853
[Epoch 51; Iter   530/ 1097] train: loss: 0.0267104
[Epoch 51; Iter   560/ 1097] train: loss: 0.0012133
[Epoch 51; Iter   590/ 1097] train: loss: 0.0029994
[Epoch 51; Iter   620/ 1097] train: loss: 0.0016934
[Epoch 51; Iter   650/ 1097] train: loss: 0.0004489
[Epoch 51; Iter   680/ 1097] train: loss: 0.0099405
[Epoch 51; Iter   710/ 1097] train: loss: 0.0800382
[Epoch 51; Iter   740/ 1097] train: loss: 0.0016727
[Epoch 51; Iter   770/ 1097] train: loss: 0.0228309
[Epoch 51; Iter   800/ 1097] train: loss: 0.0006339
[Epoch 51; Iter   830/ 1097] train: loss: 0.0072577
[Epoch 51; Iter   860/ 1097] train: loss: 0.0166114
[Epoch 51; Iter   890/ 1097] train: loss: 0.0215488
[Epoch 51; Iter   920/ 1097] train: loss: 0.0003432
[Epoch 51; Iter   950/ 1097] train: loss: 0.0031351
[Epoch 51; Iter   980/ 1097] train: loss: 0.0515132
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0219115
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0177255
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0019836
[Epoch 51] ogbg-molhiv: 0.738055 val loss: 0.771066
[Epoch 51] ogbg-molhiv: 0.727067 test loss: 0.440900
[Epoch 52; Iter     3/ 1097] train: loss: 0.0124176
[Epoch 52; Iter    33/ 1097] train: loss: 0.0404835
[Epoch 52; Iter    63/ 1097] train: loss: 0.0023554
[Epoch 52; Iter    93/ 1097] train: loss: 0.0156789
[Epoch 52; Iter   123/ 1097] train: loss: 0.0049067
[Epoch 52; Iter   153/ 1097] train: loss: 0.0060523
[Epoch 52; Iter   183/ 1097] train: loss: 0.0042641
[Epoch 52; Iter   213/ 1097] train: loss: 0.0002685
[Epoch 52; Iter   243/ 1097] train: loss: 0.0036808
[Epoch 52; Iter   273/ 1097] train: loss: 0.0010410
[Epoch 52; Iter   303/ 1097] train: loss: 0.0062147
[Epoch 52; Iter   333/ 1097] train: loss: 0.0145737
[Epoch 52; Iter   363/ 1097] train: loss: 0.0041271
[Epoch 52; Iter   393/ 1097] train: loss: 0.0045505
[Epoch 52; Iter   423/ 1097] train: loss: 0.0003806
[Epoch 52; Iter   453/ 1097] train: loss: 0.0037726
[Epoch 52; Iter   483/ 1097] train: loss: 0.0010502
[Epoch 52; Iter   513/ 1097] train: loss: 0.0005129
[Epoch 52; Iter   543/ 1097] train: loss: 0.0018780
[Epoch 52; Iter   573/ 1097] train: loss: 0.0045772
[Epoch 52; Iter   603/ 1097] train: loss: 0.0542806
[Epoch 52; Iter   633/ 1097] train: loss: 0.0457925
[Epoch 52; Iter   663/ 1097] train: loss: 0.0019092
[Epoch 52; Iter   693/ 1097] train: loss: 0.0073281
[Epoch 52; Iter   723/ 1097] train: loss: 0.0088817
[Epoch 52; Iter   753/ 1097] train: loss: 0.0428028
[Epoch 52; Iter   783/ 1097] train: loss: 0.0310312
[Epoch 52; Iter   813/ 1097] train: loss: 0.0038045
[Epoch 52; Iter   843/ 1097] train: loss: 0.0088436
[Epoch 52; Iter   873/ 1097] train: loss: 0.0056772
[Epoch 52; Iter   903/ 1097] train: loss: 0.0011686
[Epoch 48; Iter   851/ 1097] train: loss: 0.0203981
[Epoch 48; Iter   881/ 1097] train: loss: 0.0060751
[Epoch 48; Iter   911/ 1097] train: loss: 0.0353526
[Epoch 48; Iter   941/ 1097] train: loss: 0.0004864
[Epoch 48; Iter   971/ 1097] train: loss: 0.0005404
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0009166
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0010190
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0012460
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0003157
[Epoch 48] ogbg-molhiv: 0.786663 val loss: 0.198629
[Epoch 48] ogbg-molhiv: 0.711595 test loss: 0.270729
[Epoch 49; Iter    24/ 1097] train: loss: 0.0063518
[Epoch 49; Iter    54/ 1097] train: loss: 0.0038026
[Epoch 49; Iter    84/ 1097] train: loss: 0.0010969
[Epoch 49; Iter   114/ 1097] train: loss: 0.0007324
[Epoch 49; Iter   144/ 1097] train: loss: 0.0019135
[Epoch 49; Iter   174/ 1097] train: loss: 0.0006719
[Epoch 49; Iter   204/ 1097] train: loss: 0.0024384
[Epoch 49; Iter   234/ 1097] train: loss: 0.0017979
[Epoch 49; Iter   264/ 1097] train: loss: 0.0015814
[Epoch 49; Iter   294/ 1097] train: loss: 0.0008002
[Epoch 49; Iter   324/ 1097] train: loss: 0.0001888
[Epoch 49; Iter   354/ 1097] train: loss: 0.0012220
[Epoch 49; Iter   384/ 1097] train: loss: 0.0352495
[Epoch 49; Iter   414/ 1097] train: loss: 0.0002796
[Epoch 49; Iter   444/ 1097] train: loss: 0.0003279
[Epoch 49; Iter   474/ 1097] train: loss: 0.0243045
[Epoch 49; Iter   504/ 1097] train: loss: 0.0004248
[Epoch 49; Iter   534/ 1097] train: loss: 0.0008217
[Epoch 49; Iter   564/ 1097] train: loss: 0.0022573
[Epoch 49; Iter   594/ 1097] train: loss: 0.0141652
[Epoch 49; Iter   624/ 1097] train: loss: 0.0060351
[Epoch 49; Iter   654/ 1097] train: loss: 0.0019270
[Epoch 49; Iter   684/ 1097] train: loss: 0.0001938
[Epoch 49; Iter   714/ 1097] train: loss: 0.0070364
[Epoch 49; Iter   744/ 1097] train: loss: 0.0011273
[Epoch 49; Iter   774/ 1097] train: loss: 0.0320051
[Epoch 49; Iter   804/ 1097] train: loss: 0.0193657
[Epoch 49; Iter   834/ 1097] train: loss: 0.0013340
[Epoch 49; Iter   864/ 1097] train: loss: 0.0065708
[Epoch 49; Iter   894/ 1097] train: loss: 0.0025312
[Epoch 49; Iter   924/ 1097] train: loss: 0.0058277
[Epoch 49; Iter   954/ 1097] train: loss: 0.0123022
[Epoch 49; Iter   984/ 1097] train: loss: 0.0006638
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0007446
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0005904
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0003516
[Epoch 49] ogbg-molhiv: 0.812402 val loss: 0.159111
[Epoch 49] ogbg-molhiv: 0.743659 test loss: 0.286664
[Epoch 50; Iter     7/ 1097] train: loss: 0.0012178
[Epoch 50; Iter    37/ 1097] train: loss: 0.0051102
[Epoch 50; Iter    67/ 1097] train: loss: 0.0895673
[Epoch 50; Iter    97/ 1097] train: loss: 0.0019781
[Epoch 50; Iter   127/ 1097] train: loss: 0.0017757
[Epoch 50; Iter   157/ 1097] train: loss: 0.0016723
[Epoch 50; Iter   187/ 1097] train: loss: 0.0099348
[Epoch 50; Iter   217/ 1097] train: loss: 0.0366179
[Epoch 50; Iter   247/ 1097] train: loss: 0.0020568
[Epoch 50; Iter   277/ 1097] train: loss: 0.0035576
[Epoch 50; Iter   307/ 1097] train: loss: 0.0104485
[Epoch 50; Iter   337/ 1097] train: loss: 0.0112259
[Epoch 50; Iter   367/ 1097] train: loss: 0.0016311
[Epoch 50; Iter   397/ 1097] train: loss: 0.0027088
[Epoch 50; Iter   427/ 1097] train: loss: 0.0001722
[Epoch 50; Iter   457/ 1097] train: loss: 0.0005134
[Epoch 50; Iter   487/ 1097] train: loss: 0.0002492
[Epoch 50; Iter   517/ 1097] train: loss: 0.0062170
[Epoch 50; Iter   547/ 1097] train: loss: 0.0003958
[Epoch 50; Iter   577/ 1097] train: loss: 0.0691874
[Epoch 50; Iter   607/ 1097] train: loss: 0.0391990
[Epoch 50; Iter   637/ 1097] train: loss: 0.0556692
[Epoch 50; Iter   667/ 1097] train: loss: 0.0005970
[Epoch 50; Iter   697/ 1097] train: loss: 0.0049689
[Epoch 50; Iter   727/ 1097] train: loss: 0.0113164
[Epoch 50; Iter   757/ 1097] train: loss: 0.0038087
[Epoch 50; Iter   787/ 1097] train: loss: 0.0006700
[Epoch 50; Iter   817/ 1097] train: loss: 0.0623594
[Epoch 50; Iter   847/ 1097] train: loss: 0.0392050
[Epoch 50; Iter   877/ 1097] train: loss: 0.0009231
[Epoch 50; Iter   907/ 1097] train: loss: 0.0038739
[Epoch 50; Iter   937/ 1097] train: loss: 0.1171181
[Epoch 50; Iter   967/ 1097] train: loss: 0.0251081
[Epoch 50; Iter   997/ 1097] train: loss: 0.0070224
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0192745
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0940813
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0514877
[Epoch 50] ogbg-molhiv: 0.772450 val loss: 0.171223
[Epoch 50] ogbg-molhiv: 0.706895 test loss: 0.307520
[Epoch 51; Iter    20/ 1097] train: loss: 0.0009768
[Epoch 51; Iter    50/ 1097] train: loss: 0.0001710
[Epoch 51; Iter    80/ 1097] train: loss: 0.0002357
[Epoch 51; Iter   110/ 1097] train: loss: 0.0003701
[Epoch 51; Iter   140/ 1097] train: loss: 0.1116370
[Epoch 51; Iter   170/ 1097] train: loss: 0.0085965
[Epoch 51; Iter   200/ 1097] train: loss: 0.0003967
[Epoch 51; Iter   230/ 1097] train: loss: 0.0189894
[Epoch 51; Iter   260/ 1097] train: loss: 0.0007159
[Epoch 51; Iter   290/ 1097] train: loss: 0.0011502
[Epoch 51; Iter   320/ 1097] train: loss: 0.0049641
[Epoch 51; Iter   350/ 1097] train: loss: 0.0182085
[Epoch 51; Iter   380/ 1097] train: loss: 0.0013487
[Epoch 51; Iter   410/ 1097] train: loss: 0.0014019
[Epoch 51; Iter   440/ 1097] train: loss: 0.0047799
[Epoch 51; Iter   470/ 1097] train: loss: 0.0006506
[Epoch 51; Iter   500/ 1097] train: loss: 0.0019994
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004158
[Epoch 51; Iter   560/ 1097] train: loss: 0.0024948
[Epoch 51; Iter   590/ 1097] train: loss: 0.0264221
[Epoch 51; Iter   620/ 1097] train: loss: 0.0175006
[Epoch 51; Iter   650/ 1097] train: loss: 0.0015790
[Epoch 51; Iter   680/ 1097] train: loss: 0.0005979
[Epoch 51; Iter   710/ 1097] train: loss: 0.0067641
[Epoch 51; Iter   740/ 1097] train: loss: 0.0519854
[Epoch 51; Iter   770/ 1097] train: loss: 0.0001906
[Epoch 51; Iter   800/ 1097] train: loss: 0.0003661
[Epoch 51; Iter   830/ 1097] train: loss: 0.0010331
[Epoch 51; Iter   860/ 1097] train: loss: 0.0033677
[Epoch 51; Iter   890/ 1097] train: loss: 0.0003890
[Epoch 51; Iter   920/ 1097] train: loss: 0.0001948
[Epoch 51; Iter   950/ 1097] train: loss: 0.0015496
[Epoch 51; Iter   980/ 1097] train: loss: 0.0044632
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0046869
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0009254
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0005064
[Epoch 51] ogbg-molhiv: 0.768292 val loss: 0.171788
[Epoch 51] ogbg-molhiv: 0.721244 test loss: 0.269345
[Epoch 52; Iter     3/ 1097] train: loss: 0.0031803
[Epoch 52; Iter    33/ 1097] train: loss: 0.0046194
[Epoch 52; Iter    63/ 1097] train: loss: 0.0026250
[Epoch 52; Iter    93/ 1097] train: loss: 0.0014289
[Epoch 52; Iter   123/ 1097] train: loss: 0.0198127
[Epoch 52; Iter   153/ 1097] train: loss: 0.0007302
[Epoch 52; Iter   183/ 1097] train: loss: 0.0012662
[Epoch 52; Iter   213/ 1097] train: loss: 0.0044327
[Epoch 52; Iter   243/ 1097] train: loss: 0.0190165
[Epoch 52; Iter   273/ 1097] train: loss: 0.0007808
[Epoch 52; Iter   303/ 1097] train: loss: 0.0041575
[Epoch 52; Iter   333/ 1097] train: loss: 0.0034092
[Epoch 52; Iter   363/ 1097] train: loss: 0.0381931
[Epoch 52; Iter   393/ 1097] train: loss: 0.0001350
[Epoch 52; Iter   423/ 1097] train: loss: 0.0004954
[Epoch 52; Iter   453/ 1097] train: loss: 0.0003088
[Epoch 52; Iter   483/ 1097] train: loss: 0.0026830
[Epoch 52; Iter   513/ 1097] train: loss: 0.0565657
[Epoch 52; Iter   543/ 1097] train: loss: 0.0001605
[Epoch 52; Iter   573/ 1097] train: loss: 0.0021001
[Epoch 52; Iter   603/ 1097] train: loss: 0.0175585
[Epoch 52; Iter   633/ 1097] train: loss: 0.0076516
[Epoch 52; Iter   663/ 1097] train: loss: 0.0251536
[Epoch 52; Iter   693/ 1097] train: loss: 0.0409206
[Epoch 52; Iter   723/ 1097] train: loss: 0.0018410
[Epoch 52; Iter   753/ 1097] train: loss: 0.0001997
[Epoch 52; Iter   783/ 1097] train: loss: 0.0255715
[Epoch 52; Iter   813/ 1097] train: loss: 0.0034238
[Epoch 52; Iter   843/ 1097] train: loss: 0.0011611
[Epoch 52; Iter   873/ 1097] train: loss: 0.0233529
[Epoch 52; Iter   903/ 1097] train: loss: 0.0056477
[Epoch 48; Iter   851/ 1097] train: loss: 0.0134609
[Epoch 48; Iter   881/ 1097] train: loss: 0.0008573
[Epoch 48; Iter   911/ 1097] train: loss: 0.0030528
[Epoch 48; Iter   941/ 1097] train: loss: 0.0023981
[Epoch 48; Iter   971/ 1097] train: loss: 0.0030757
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0037193
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0025298
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0036371
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0053265
[Epoch 48] ogbg-molhiv: 0.790114 val loss: 0.222947
[Epoch 48] ogbg-molhiv: 0.725089 test loss: 0.379480
[Epoch 49; Iter    24/ 1097] train: loss: 0.0004945
[Epoch 49; Iter    54/ 1097] train: loss: 0.0007983
[Epoch 49; Iter    84/ 1097] train: loss: 0.0009221
[Epoch 49; Iter   114/ 1097] train: loss: 0.0006337
[Epoch 49; Iter   144/ 1097] train: loss: 0.0103320
[Epoch 49; Iter   174/ 1097] train: loss: 0.0026455
[Epoch 49; Iter   204/ 1097] train: loss: 0.0008005
[Epoch 49; Iter   234/ 1097] train: loss: 0.0073154
[Epoch 49; Iter   264/ 1097] train: loss: 0.0602384
[Epoch 49; Iter   294/ 1097] train: loss: 0.0007743
[Epoch 49; Iter   324/ 1097] train: loss: 0.0020005
[Epoch 49; Iter   354/ 1097] train: loss: 0.0295687
[Epoch 49; Iter   384/ 1097] train: loss: 0.0042064
[Epoch 49; Iter   414/ 1097] train: loss: 0.0017867
[Epoch 49; Iter   444/ 1097] train: loss: 0.0042852
[Epoch 49; Iter   474/ 1097] train: loss: 0.0269379
[Epoch 49; Iter   504/ 1097] train: loss: 0.0029954
[Epoch 49; Iter   534/ 1097] train: loss: 0.0038834
[Epoch 49; Iter   564/ 1097] train: loss: 0.0027805
[Epoch 49; Iter   594/ 1097] train: loss: 0.0038121
[Epoch 49; Iter   624/ 1097] train: loss: 0.0080287
[Epoch 49; Iter   654/ 1097] train: loss: 0.0041384
[Epoch 49; Iter   684/ 1097] train: loss: 0.0320177
[Epoch 49; Iter   714/ 1097] train: loss: 0.0157570
[Epoch 49; Iter   744/ 1097] train: loss: 0.0058876
[Epoch 49; Iter   774/ 1097] train: loss: 0.0557282
[Epoch 49; Iter   804/ 1097] train: loss: 0.0044554
[Epoch 49; Iter   834/ 1097] train: loss: 0.0398357
[Epoch 49; Iter   864/ 1097] train: loss: 0.0023527
[Epoch 49; Iter   894/ 1097] train: loss: 0.0009926
[Epoch 49; Iter   924/ 1097] train: loss: 0.0003848
[Epoch 49; Iter   954/ 1097] train: loss: 0.0039912
[Epoch 49; Iter   984/ 1097] train: loss: 0.1438213
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0010552
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0021662
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0004373
[Epoch 49] ogbg-molhiv: 0.788023 val loss: 0.170984
[Epoch 49] ogbg-molhiv: 0.705780 test loss: 0.346510
[Epoch 50; Iter     7/ 1097] train: loss: 0.0842074
[Epoch 50; Iter    37/ 1097] train: loss: 0.0009050
[Epoch 50; Iter    67/ 1097] train: loss: 0.0017514
[Epoch 50; Iter    97/ 1097] train: loss: 0.0038527
[Epoch 50; Iter   127/ 1097] train: loss: 0.0208995
[Epoch 50; Iter   157/ 1097] train: loss: 0.0120942
[Epoch 50; Iter   187/ 1097] train: loss: 0.0007245
[Epoch 50; Iter   217/ 1097] train: loss: 0.0018231
[Epoch 50; Iter   247/ 1097] train: loss: 0.0014796
[Epoch 50; Iter   277/ 1097] train: loss: 0.0022051
[Epoch 50; Iter   307/ 1097] train: loss: 0.0014545
[Epoch 50; Iter   337/ 1097] train: loss: 0.0171737
[Epoch 50; Iter   367/ 1097] train: loss: 0.0100314
[Epoch 50; Iter   397/ 1097] train: loss: 0.0074392
[Epoch 50; Iter   427/ 1097] train: loss: 0.0025663
[Epoch 50; Iter   457/ 1097] train: loss: 0.0486699
[Epoch 50; Iter   487/ 1097] train: loss: 0.0254026
[Epoch 50; Iter   517/ 1097] train: loss: 0.0242546
[Epoch 50; Iter   547/ 1097] train: loss: 0.0200321
[Epoch 50; Iter   577/ 1097] train: loss: 0.0008742
[Epoch 50; Iter   607/ 1097] train: loss: 0.0020932
[Epoch 50; Iter   637/ 1097] train: loss: 0.0003158
[Epoch 50; Iter   667/ 1097] train: loss: 0.0342240
[Epoch 50; Iter   697/ 1097] train: loss: 0.0452100
[Epoch 50; Iter   727/ 1097] train: loss: 0.0758637
[Epoch 50; Iter   757/ 1097] train: loss: 0.0389125
[Epoch 50; Iter   787/ 1097] train: loss: 0.0054481
[Epoch 50; Iter   817/ 1097] train: loss: 0.0119102
[Epoch 50; Iter   847/ 1097] train: loss: 0.0451213
[Epoch 50; Iter   877/ 1097] train: loss: 0.0006439
[Epoch 50; Iter   907/ 1097] train: loss: 0.0102108
[Epoch 50; Iter   937/ 1097] train: loss: 0.0038798
[Epoch 50; Iter   967/ 1097] train: loss: 0.0002123
[Epoch 50; Iter   997/ 1097] train: loss: 0.0473917
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0004956
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0002384
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0013030
[Epoch 50] ogbg-molhiv: 0.796263 val loss: 0.178209
[Epoch 50] ogbg-molhiv: 0.732731 test loss: 0.343553
[Epoch 51; Iter    20/ 1097] train: loss: 0.0100623
[Epoch 51; Iter    50/ 1097] train: loss: 0.0095364
[Epoch 51; Iter    80/ 1097] train: loss: 0.0004477
[Epoch 51; Iter   110/ 1097] train: loss: 0.0025315
[Epoch 51; Iter   140/ 1097] train: loss: 0.0012280
[Epoch 51; Iter   170/ 1097] train: loss: 0.0015999
[Epoch 51; Iter   200/ 1097] train: loss: 0.0198020
[Epoch 51; Iter   230/ 1097] train: loss: 0.0016706
[Epoch 51; Iter   260/ 1097] train: loss: 0.0103049
[Epoch 51; Iter   290/ 1097] train: loss: 0.0077019
[Epoch 51; Iter   320/ 1097] train: loss: 0.0430117
[Epoch 51; Iter   350/ 1097] train: loss: 0.0015020
[Epoch 51; Iter   380/ 1097] train: loss: 0.0005220
[Epoch 51; Iter   410/ 1097] train: loss: 0.0616121
[Epoch 51; Iter   440/ 1097] train: loss: 0.0014750
[Epoch 51; Iter   470/ 1097] train: loss: 0.0164229
[Epoch 51; Iter   500/ 1097] train: loss: 0.0021969
[Epoch 51; Iter   530/ 1097] train: loss: 0.0381100
[Epoch 51; Iter   560/ 1097] train: loss: 0.0004289
[Epoch 51; Iter   590/ 1097] train: loss: 0.0008315
[Epoch 51; Iter   620/ 1097] train: loss: 0.0013752
[Epoch 51; Iter   650/ 1097] train: loss: 0.0076650
[Epoch 51; Iter   680/ 1097] train: loss: 0.0016776
[Epoch 51; Iter   710/ 1097] train: loss: 0.0039333
[Epoch 51; Iter   740/ 1097] train: loss: 0.0025183
[Epoch 51; Iter   770/ 1097] train: loss: 0.0006116
[Epoch 51; Iter   800/ 1097] train: loss: 0.0025984
[Epoch 51; Iter   830/ 1097] train: loss: 0.0054070
[Epoch 51; Iter   860/ 1097] train: loss: 0.0026719
[Epoch 51; Iter   890/ 1097] train: loss: 0.0090151
[Epoch 51; Iter   920/ 1097] train: loss: 0.0010784
[Epoch 51; Iter   950/ 1097] train: loss: 0.0003706
[Epoch 51; Iter   980/ 1097] train: loss: 0.0065318
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0023861
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0023723
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0164187
[Epoch 51] ogbg-molhiv: 0.769936 val loss: 0.318433
[Epoch 51] ogbg-molhiv: 0.694057 test loss: 0.361539
[Epoch 52; Iter     3/ 1097] train: loss: 0.0010156
[Epoch 52; Iter    33/ 1097] train: loss: 0.0221695
[Epoch 52; Iter    63/ 1097] train: loss: 0.0065114
[Epoch 52; Iter    93/ 1097] train: loss: 0.0028056
[Epoch 52; Iter   123/ 1097] train: loss: 0.0010633
[Epoch 52; Iter   153/ 1097] train: loss: 0.0017021
[Epoch 52; Iter   183/ 1097] train: loss: 0.0012839
[Epoch 52; Iter   213/ 1097] train: loss: 0.0264711
[Epoch 52; Iter   243/ 1097] train: loss: 0.0078230
[Epoch 52; Iter   273/ 1097] train: loss: 0.0047333
[Epoch 52; Iter   303/ 1097] train: loss: 0.0175801
[Epoch 52; Iter   333/ 1097] train: loss: 0.0037006
[Epoch 52; Iter   363/ 1097] train: loss: 0.0004737
[Epoch 52; Iter   393/ 1097] train: loss: 0.0159498
[Epoch 52; Iter   423/ 1097] train: loss: 0.0005875
[Epoch 52; Iter   453/ 1097] train: loss: 0.0452642
[Epoch 52; Iter   483/ 1097] train: loss: 0.0021962
[Epoch 52; Iter   513/ 1097] train: loss: 0.0037676
[Epoch 52; Iter   543/ 1097] train: loss: 0.0004201
[Epoch 52; Iter   573/ 1097] train: loss: 0.0023126
[Epoch 52; Iter   603/ 1097] train: loss: 0.0366520
[Epoch 52; Iter   633/ 1097] train: loss: 0.0438942
[Epoch 52; Iter   663/ 1097] train: loss: 0.0329617
[Epoch 52; Iter   693/ 1097] train: loss: 0.0015443
[Epoch 52; Iter   723/ 1097] train: loss: 0.0016861
[Epoch 52; Iter   753/ 1097] train: loss: 0.0172385
[Epoch 52; Iter   783/ 1097] train: loss: 0.0069408
[Epoch 52; Iter   813/ 1097] train: loss: 0.0437164
[Epoch 52; Iter   843/ 1097] train: loss: 0.0278750
[Epoch 52; Iter   873/ 1097] train: loss: 0.0030542
[Epoch 52; Iter   903/ 1097] train: loss: 0.0891820
[Epoch 48; Iter   851/ 1097] train: loss: 0.0004761
[Epoch 48; Iter   881/ 1097] train: loss: 0.0011481
[Epoch 48; Iter   911/ 1097] train: loss: 0.0010833
[Epoch 48; Iter   941/ 1097] train: loss: 0.0035419
[Epoch 48; Iter   971/ 1097] train: loss: 0.0655153
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0017357
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0001403
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0122485
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0276360
[Epoch 48] ogbg-molhiv: 0.806884 val loss: 0.221262
[Epoch 48] ogbg-molhiv: 0.799272 test loss: 0.274008
[Epoch 49; Iter    24/ 1097] train: loss: 0.0109505
[Epoch 49; Iter    54/ 1097] train: loss: 0.0005954
[Epoch 49; Iter    84/ 1097] train: loss: 0.0009616
[Epoch 49; Iter   114/ 1097] train: loss: 0.0017919
[Epoch 49; Iter   144/ 1097] train: loss: 0.0020278
[Epoch 49; Iter   174/ 1097] train: loss: 0.0006536
[Epoch 49; Iter   204/ 1097] train: loss: 0.0421627
[Epoch 49; Iter   234/ 1097] train: loss: 0.0035448
[Epoch 49; Iter   264/ 1097] train: loss: 0.0028381
[Epoch 49; Iter   294/ 1097] train: loss: 0.0094519
[Epoch 49; Iter   324/ 1097] train: loss: 0.0066626
[Epoch 49; Iter   354/ 1097] train: loss: 0.0004510
[Epoch 49; Iter   384/ 1097] train: loss: 0.0037442
[Epoch 49; Iter   414/ 1097] train: loss: 0.0523515
[Epoch 49; Iter   444/ 1097] train: loss: 0.0050232
[Epoch 49; Iter   474/ 1097] train: loss: 0.0125236
[Epoch 49; Iter   504/ 1097] train: loss: 0.0010925
[Epoch 49; Iter   534/ 1097] train: loss: 0.0004046
[Epoch 49; Iter   564/ 1097] train: loss: 0.0009458
[Epoch 49; Iter   594/ 1097] train: loss: 0.0032522
[Epoch 49; Iter   624/ 1097] train: loss: 0.0010405
[Epoch 49; Iter   654/ 1097] train: loss: 0.0112733
[Epoch 49; Iter   684/ 1097] train: loss: 0.0006974
[Epoch 49; Iter   714/ 1097] train: loss: 0.0064587
[Epoch 49; Iter   744/ 1097] train: loss: 0.0002672
[Epoch 49; Iter   774/ 1097] train: loss: 0.0002307
[Epoch 49; Iter   804/ 1097] train: loss: 0.0002893
[Epoch 49; Iter   834/ 1097] train: loss: 0.0057317
[Epoch 49; Iter   864/ 1097] train: loss: 0.0101591
[Epoch 49; Iter   894/ 1097] train: loss: 0.0004210
[Epoch 49; Iter   924/ 1097] train: loss: 0.0023599
[Epoch 49; Iter   954/ 1097] train: loss: 0.0002634
[Epoch 49; Iter   984/ 1097] train: loss: 0.0007695
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0032206
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0026256
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0007049
[Epoch 49] ogbg-molhiv: 0.786464 val loss: 0.230398
[Epoch 49] ogbg-molhiv: 0.789494 test loss: 0.247991
[Epoch 50; Iter     7/ 1097] train: loss: 0.1071099
[Epoch 50; Iter    37/ 1097] train: loss: 0.0011716
[Epoch 50; Iter    67/ 1097] train: loss: 0.0010985
[Epoch 50; Iter    97/ 1097] train: loss: 0.0001815
[Epoch 50; Iter   127/ 1097] train: loss: 0.0022983
[Epoch 50; Iter   157/ 1097] train: loss: 0.0047679
[Epoch 50; Iter   187/ 1097] train: loss: 0.0050492
[Epoch 50; Iter   217/ 1097] train: loss: 0.0007843
[Epoch 50; Iter   247/ 1097] train: loss: 0.0020337
[Epoch 50; Iter   277/ 1097] train: loss: 0.0067613
[Epoch 50; Iter   307/ 1097] train: loss: 0.0009177
[Epoch 50; Iter   337/ 1097] train: loss: 0.0002817
[Epoch 50; Iter   367/ 1097] train: loss: 0.0045198
[Epoch 50; Iter   397/ 1097] train: loss: 0.0009067
[Epoch 50; Iter   427/ 1097] train: loss: 0.0076076
[Epoch 50; Iter   457/ 1097] train: loss: 0.0007775
[Epoch 50; Iter   487/ 1097] train: loss: 0.1227521
[Epoch 50; Iter   517/ 1097] train: loss: 0.0084415
[Epoch 50; Iter   547/ 1097] train: loss: 0.0003363
[Epoch 50; Iter   577/ 1097] train: loss: 0.0067149
[Epoch 50; Iter   607/ 1097] train: loss: 0.0006877
[Epoch 50; Iter   637/ 1097] train: loss: 0.0003348
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002783
[Epoch 50; Iter   697/ 1097] train: loss: 0.0022855
[Epoch 50; Iter   727/ 1097] train: loss: 0.0017735
[Epoch 50; Iter   757/ 1097] train: loss: 0.0003989
[Epoch 50; Iter   787/ 1097] train: loss: 0.0014408
[Epoch 50; Iter   817/ 1097] train: loss: 0.0075077
[Epoch 50; Iter   847/ 1097] train: loss: 0.0009760
[Epoch 50; Iter   877/ 1097] train: loss: 0.0331940
[Epoch 50; Iter   907/ 1097] train: loss: 0.0973158
[Epoch 50; Iter   937/ 1097] train: loss: 0.0003068
[Epoch 50; Iter   967/ 1097] train: loss: 0.0045739
[Epoch 50; Iter   997/ 1097] train: loss: 0.0008157
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0009284
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0002356
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0029019
[Epoch 50] ogbg-molhiv: 0.818912 val loss: 0.272029
[Epoch 50] ogbg-molhiv: 0.797451 test loss: 0.246614
[Epoch 51; Iter    20/ 1097] train: loss: 0.0004938
[Epoch 51; Iter    50/ 1097] train: loss: 0.0007315
[Epoch 51; Iter    80/ 1097] train: loss: 0.0001788
[Epoch 51; Iter   110/ 1097] train: loss: 0.0005679
[Epoch 51; Iter   140/ 1097] train: loss: 0.0114256
[Epoch 51; Iter   170/ 1097] train: loss: 0.0370343
[Epoch 51; Iter   200/ 1097] train: loss: 0.0099211
[Epoch 51; Iter   230/ 1097] train: loss: 0.0030037
[Epoch 51; Iter   260/ 1097] train: loss: 0.0003038
[Epoch 51; Iter   290/ 1097] train: loss: 0.0002347
[Epoch 51; Iter   320/ 1097] train: loss: 0.0016433
[Epoch 51; Iter   350/ 1097] train: loss: 0.0013823
[Epoch 51; Iter   380/ 1097] train: loss: 0.0345247
[Epoch 51; Iter   410/ 1097] train: loss: 0.1661133
[Epoch 51; Iter   440/ 1097] train: loss: 0.0247290
[Epoch 51; Iter   470/ 1097] train: loss: 0.1090484
[Epoch 51; Iter   500/ 1097] train: loss: 0.0005680
[Epoch 51; Iter   530/ 1097] train: loss: 0.0748516
[Epoch 51; Iter   560/ 1097] train: loss: 0.0593069
[Epoch 51; Iter   590/ 1097] train: loss: 0.1047566
[Epoch 51; Iter   620/ 1097] train: loss: 0.0012729
[Epoch 51; Iter   650/ 1097] train: loss: 0.0007589
[Epoch 51; Iter   680/ 1097] train: loss: 0.1048787
[Epoch 51; Iter   710/ 1097] train: loss: 0.0421371
[Epoch 51; Iter   740/ 1097] train: loss: 0.0004153
[Epoch 51; Iter   770/ 1097] train: loss: 0.0039886
[Epoch 51; Iter   800/ 1097] train: loss: 0.0045167
[Epoch 51; Iter   830/ 1097] train: loss: 0.0771132
[Epoch 51; Iter   860/ 1097] train: loss: 0.0008429
[Epoch 51; Iter   890/ 1097] train: loss: 0.0001266
[Epoch 51; Iter   920/ 1097] train: loss: 0.0005027
[Epoch 51; Iter   950/ 1097] train: loss: 0.0010609
[Epoch 51; Iter   980/ 1097] train: loss: 0.0002535
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0122406
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0005811
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0042396
[Epoch 51] ogbg-molhiv: 0.815097 val loss: 0.263454
[Epoch 51] ogbg-molhiv: 0.799706 test loss: 0.246954
[Epoch 52; Iter     3/ 1097] train: loss: 0.0066018
[Epoch 52; Iter    33/ 1097] train: loss: 0.0004927
[Epoch 52; Iter    63/ 1097] train: loss: 0.0132807
[Epoch 52; Iter    93/ 1097] train: loss: 0.0010838
[Epoch 52; Iter   123/ 1097] train: loss: 0.0005259
[Epoch 52; Iter   153/ 1097] train: loss: 0.0006856
[Epoch 52; Iter   183/ 1097] train: loss: 0.0863783
[Epoch 52; Iter   213/ 1097] train: loss: 0.0004299
[Epoch 52; Iter   243/ 1097] train: loss: 0.0007357
[Epoch 52; Iter   273/ 1097] train: loss: 0.0043581
[Epoch 52; Iter   303/ 1097] train: loss: 0.0112621
[Epoch 52; Iter   333/ 1097] train: loss: 0.0001026
[Epoch 52; Iter   363/ 1097] train: loss: 0.0018301
[Epoch 52; Iter   393/ 1097] train: loss: 0.0017615
[Epoch 52; Iter   423/ 1097] train: loss: 0.0492588
[Epoch 52; Iter   453/ 1097] train: loss: 0.0007216
[Epoch 52; Iter   483/ 1097] train: loss: 0.0127532
[Epoch 52; Iter   513/ 1097] train: loss: 0.0491469
[Epoch 52; Iter   543/ 1097] train: loss: 0.0127175
[Epoch 52; Iter   573/ 1097] train: loss: 0.0072275
[Epoch 52; Iter   603/ 1097] train: loss: 0.0080851
[Epoch 52; Iter   633/ 1097] train: loss: 0.0010596
[Epoch 52; Iter   663/ 1097] train: loss: 0.0586627
[Epoch 52; Iter   693/ 1097] train: loss: 0.0223549
[Epoch 52; Iter   723/ 1097] train: loss: 0.0306471
[Epoch 52; Iter   753/ 1097] train: loss: 0.0011707
[Epoch 52; Iter   783/ 1097] train: loss: 0.0482489
[Epoch 52; Iter   813/ 1097] train: loss: 0.0310152
[Epoch 52; Iter   843/ 1097] train: loss: 0.0011865
[Epoch 52; Iter   873/ 1097] train: loss: 0.0018094
[Epoch 52; Iter   903/ 1097] train: loss: 0.0018569
[Epoch 48; Iter   851/ 1097] train: loss: 0.0002661
[Epoch 48; Iter   881/ 1097] train: loss: 0.0023700
[Epoch 48; Iter   911/ 1097] train: loss: 0.0008487
[Epoch 48; Iter   941/ 1097] train: loss: 0.0004133
[Epoch 48; Iter   971/ 1097] train: loss: 0.0000587
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0003192
[Epoch 48; Iter  1031/ 1097] train: loss: 0.1123308
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0000542
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0003108
[Epoch 48] ogbg-molhiv: 0.699350 val loss: 4.587149
[Epoch 48] ogbg-molhiv: 0.605187 test loss: 6.592592
[Epoch 49; Iter    24/ 1097] train: loss: 0.0000863
[Epoch 49; Iter    54/ 1097] train: loss: 0.0003013
[Epoch 49; Iter    84/ 1097] train: loss: 0.0019420
[Epoch 49; Iter   114/ 1097] train: loss: 0.0037129
[Epoch 49; Iter   144/ 1097] train: loss: 0.0002230
[Epoch 49; Iter   174/ 1097] train: loss: 0.0091924
[Epoch 49; Iter   204/ 1097] train: loss: 0.0006149
[Epoch 49; Iter   234/ 1097] train: loss: 0.0002429
[Epoch 49; Iter   264/ 1097] train: loss: 0.0001597
[Epoch 49; Iter   294/ 1097] train: loss: 0.0003378
[Epoch 49; Iter   324/ 1097] train: loss: 0.0017354
[Epoch 49; Iter   354/ 1097] train: loss: 0.0024502
[Epoch 49; Iter   384/ 1097] train: loss: 0.0002147
[Epoch 49; Iter   414/ 1097] train: loss: 0.0015608
[Epoch 49; Iter   444/ 1097] train: loss: 0.0004612
[Epoch 49; Iter   474/ 1097] train: loss: 0.0020511
[Epoch 49; Iter   504/ 1097] train: loss: 0.0001959
[Epoch 49; Iter   534/ 1097] train: loss: 0.0008582
[Epoch 49; Iter   564/ 1097] train: loss: 0.0001066
[Epoch 49; Iter   594/ 1097] train: loss: 0.0005114
[Epoch 49; Iter   624/ 1097] train: loss: 0.0006374
[Epoch 49; Iter   654/ 1097] train: loss: 0.0077368
[Epoch 49; Iter   684/ 1097] train: loss: 0.0059241
[Epoch 49; Iter   714/ 1097] train: loss: 0.0022310
[Epoch 49; Iter   744/ 1097] train: loss: 0.0000264
[Epoch 49; Iter   774/ 1097] train: loss: 0.0077891
[Epoch 49; Iter   804/ 1097] train: loss: 0.0000449
[Epoch 49; Iter   834/ 1097] train: loss: 0.0011221
[Epoch 49; Iter   864/ 1097] train: loss: 0.0012299
[Epoch 49; Iter   894/ 1097] train: loss: 0.0000579
[Epoch 49; Iter   924/ 1097] train: loss: 0.0012145
[Epoch 49; Iter   954/ 1097] train: loss: 0.0007031
[Epoch 49; Iter   984/ 1097] train: loss: 0.0052891
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0003112
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0339920
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0005158
[Epoch 49] ogbg-molhiv: 0.717960 val loss: 2.928363
[Epoch 49] ogbg-molhiv: 0.629195 test loss: 3.863181
[Epoch 50; Iter     7/ 1097] train: loss: 0.0000299
[Epoch 50; Iter    37/ 1097] train: loss: 0.0002711
[Epoch 50; Iter    67/ 1097] train: loss: 0.0045926
[Epoch 50; Iter    97/ 1097] train: loss: 0.0120786
[Epoch 50; Iter   127/ 1097] train: loss: 0.0002600
[Epoch 50; Iter   157/ 1097] train: loss: 0.0004636
[Epoch 50; Iter   187/ 1097] train: loss: 0.0522479
[Epoch 50; Iter   217/ 1097] train: loss: 0.0000549
[Epoch 50; Iter   247/ 1097] train: loss: 0.0002514
[Epoch 50; Iter   277/ 1097] train: loss: 0.0012192
[Epoch 50; Iter   307/ 1097] train: loss: 0.0003380
[Epoch 50; Iter   337/ 1097] train: loss: 0.0001363
[Epoch 50; Iter   367/ 1097] train: loss: 0.0013397
[Epoch 50; Iter   397/ 1097] train: loss: 0.0002855
[Epoch 50; Iter   427/ 1097] train: loss: 0.0003021
[Epoch 50; Iter   457/ 1097] train: loss: 0.0002444
[Epoch 50; Iter   487/ 1097] train: loss: 0.0006865
[Epoch 50; Iter   517/ 1097] train: loss: 0.0002854
[Epoch 50; Iter   547/ 1097] train: loss: 0.0668291
[Epoch 50; Iter   577/ 1097] train: loss: 0.0001748
[Epoch 50; Iter   607/ 1097] train: loss: 0.0005399
[Epoch 50; Iter   637/ 1097] train: loss: 0.0549972
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002135
[Epoch 50; Iter   697/ 1097] train: loss: 0.0002233
[Epoch 50; Iter   727/ 1097] train: loss: 0.0117268
[Epoch 50; Iter   757/ 1097] train: loss: 0.0003496
[Epoch 50; Iter   787/ 1097] train: loss: 0.0002049
[Epoch 50; Iter   817/ 1097] train: loss: 0.0100886
[Epoch 50; Iter   847/ 1097] train: loss: 0.0061001
[Epoch 50; Iter   877/ 1097] train: loss: 0.0050803
[Epoch 50; Iter   907/ 1097] train: loss: 0.0001234
[Epoch 50; Iter   937/ 1097] train: loss: 0.0001003
[Epoch 50; Iter   967/ 1097] train: loss: 0.0004439
[Epoch 50; Iter   997/ 1097] train: loss: 0.0001741
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0009542
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0101722
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0018537
[Epoch 50] ogbg-molhiv: 0.704974 val loss: 3.385139
[Epoch 50] ogbg-molhiv: 0.588198 test loss: 3.405364
[Epoch 51; Iter    20/ 1097] train: loss: 0.0001170
[Epoch 51; Iter    50/ 1097] train: loss: 0.0000903
[Epoch 51; Iter    80/ 1097] train: loss: 0.0000737
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007845
[Epoch 51; Iter   140/ 1097] train: loss: 0.0000718
[Epoch 51; Iter   170/ 1097] train: loss: 0.0046936
[Epoch 51; Iter   200/ 1097] train: loss: 0.0115211
[Epoch 51; Iter   230/ 1097] train: loss: 0.0010666
[Epoch 51; Iter   260/ 1097] train: loss: 0.0005477
[Epoch 51; Iter   290/ 1097] train: loss: 0.0653973
[Epoch 51; Iter   320/ 1097] train: loss: 0.0005934
[Epoch 51; Iter   350/ 1097] train: loss: 0.0001922
[Epoch 51; Iter   380/ 1097] train: loss: 0.0023308
[Epoch 51; Iter   410/ 1097] train: loss: 0.0035160
[Epoch 51; Iter   440/ 1097] train: loss: 0.0004055
[Epoch 51; Iter   470/ 1097] train: loss: 0.0003400
[Epoch 51; Iter   500/ 1097] train: loss: 0.0058843
[Epoch 51; Iter   530/ 1097] train: loss: 0.0004859
[Epoch 51; Iter   560/ 1097] train: loss: 0.0029965
[Epoch 51; Iter   590/ 1097] train: loss: 0.0328920
[Epoch 51; Iter   620/ 1097] train: loss: 0.0001170
[Epoch 51; Iter   650/ 1097] train: loss: 0.0006277
[Epoch 51; Iter   680/ 1097] train: loss: 0.0040841
[Epoch 51; Iter   710/ 1097] train: loss: 0.0007437
[Epoch 51; Iter   740/ 1097] train: loss: 0.0001202
[Epoch 51; Iter   770/ 1097] train: loss: 0.0010281
[Epoch 51; Iter   800/ 1097] train: loss: 0.0002420
[Epoch 51; Iter   830/ 1097] train: loss: 0.0226614
[Epoch 51; Iter   860/ 1097] train: loss: 0.0072455
[Epoch 51; Iter   890/ 1097] train: loss: 0.0008075
[Epoch 51; Iter   920/ 1097] train: loss: 0.0016650
[Epoch 51; Iter   950/ 1097] train: loss: 0.0007179
[Epoch 51; Iter   980/ 1097] train: loss: 0.0006762
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0019585
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0003035
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0387996
[Epoch 51] ogbg-molhiv: 0.739219 val loss: 0.847070
[Epoch 51] ogbg-molhiv: 0.590641 test loss: 1.545429
[Epoch 52; Iter     3/ 1097] train: loss: 0.0001784
[Epoch 52; Iter    33/ 1097] train: loss: 0.0008262
[Epoch 52; Iter    63/ 1097] train: loss: 0.0007639
[Epoch 52; Iter    93/ 1097] train: loss: 0.0002775
[Epoch 52; Iter   123/ 1097] train: loss: 0.0024358
[Epoch 52; Iter   153/ 1097] train: loss: 0.0018901
[Epoch 52; Iter   183/ 1097] train: loss: 0.0073439
[Epoch 52; Iter   213/ 1097] train: loss: 0.0013095
[Epoch 52; Iter   243/ 1097] train: loss: 0.0013523
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002187
[Epoch 52; Iter   303/ 1097] train: loss: 0.0001146
[Epoch 52; Iter   333/ 1097] train: loss: 0.0019653
[Epoch 52; Iter   363/ 1097] train: loss: 0.0000064
[Epoch 52; Iter   393/ 1097] train: loss: 0.0005479
[Epoch 52; Iter   423/ 1097] train: loss: 0.0111710
[Epoch 52; Iter   453/ 1097] train: loss: 0.0005373
[Epoch 52; Iter   483/ 1097] train: loss: 0.0006583
[Epoch 52; Iter   513/ 1097] train: loss: 0.0009004
[Epoch 52; Iter   543/ 1097] train: loss: 0.0011187
[Epoch 52; Iter   573/ 1097] train: loss: 0.0001935
[Epoch 52; Iter   603/ 1097] train: loss: 0.0013689
[Epoch 52; Iter   633/ 1097] train: loss: 0.0031422
[Epoch 52; Iter   663/ 1097] train: loss: 0.0065371
[Epoch 52; Iter   693/ 1097] train: loss: 0.0591054
[Epoch 52; Iter   723/ 1097] train: loss: 0.0014471
[Epoch 52; Iter   753/ 1097] train: loss: 0.0114247
[Epoch 52; Iter   783/ 1097] train: loss: 0.0000977
[Epoch 52; Iter   813/ 1097] train: loss: 0.0659773
[Epoch 52; Iter   843/ 1097] train: loss: 0.0001736
[Epoch 52; Iter   873/ 1097] train: loss: 0.0001309
[Epoch 52; Iter   903/ 1097] train: loss: 0.0042933
[Epoch 40; Iter   687/ 1097] train: loss: 0.0808619
[Epoch 40; Iter   717/ 1097] train: loss: 0.0693599
[Epoch 40; Iter   747/ 1097] train: loss: 0.0670662
[Epoch 40; Iter   777/ 1097] train: loss: 0.1325265
[Epoch 40; Iter   807/ 1097] train: loss: 0.0752326
[Epoch 40; Iter   837/ 1097] train: loss: 0.0137528
[Epoch 40; Iter   867/ 1097] train: loss: 0.0328002
[Epoch 40; Iter   897/ 1097] train: loss: 0.0462498
[Epoch 40; Iter   927/ 1097] train: loss: 0.1365405
[Epoch 40; Iter   957/ 1097] train: loss: 0.2149723
[Epoch 40; Iter   987/ 1097] train: loss: 0.1109597
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0342209
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0143384
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0742930
[Epoch 40] ogbg-molhiv: 0.816888 val loss: 0.077285
[Epoch 40] ogbg-molhiv: 0.737166 test loss: 0.138215
[Epoch 41; Iter    10/ 1097] train: loss: 0.0676724
[Epoch 41; Iter    40/ 1097] train: loss: 0.0759427
[Epoch 41; Iter    70/ 1097] train: loss: 0.0722482
[Epoch 41; Iter   100/ 1097] train: loss: 0.1078370
[Epoch 41; Iter   130/ 1097] train: loss: 0.0707194
[Epoch 41; Iter   160/ 1097] train: loss: 0.1196527
[Epoch 41; Iter   190/ 1097] train: loss: 0.0207504
[Epoch 41; Iter   220/ 1097] train: loss: 0.0245215
[Epoch 41; Iter   250/ 1097] train: loss: 0.2177134
[Epoch 41; Iter   280/ 1097] train: loss: 0.2896635
[Epoch 41; Iter   310/ 1097] train: loss: 0.0093779
[Epoch 41; Iter   340/ 1097] train: loss: 0.2710432
[Epoch 41; Iter   370/ 1097] train: loss: 0.0162757
[Epoch 41; Iter   400/ 1097] train: loss: 0.0218780
[Epoch 41; Iter   430/ 1097] train: loss: 0.0223667
[Epoch 41; Iter   460/ 1097] train: loss: 0.0178509
[Epoch 41; Iter   490/ 1097] train: loss: 0.1480564
[Epoch 41; Iter   520/ 1097] train: loss: 0.0266415
[Epoch 41; Iter   550/ 1097] train: loss: 0.2325768
[Epoch 41; Iter   580/ 1097] train: loss: 0.0135309
[Epoch 41; Iter   610/ 1097] train: loss: 0.1813697
[Epoch 41; Iter   640/ 1097] train: loss: 0.0175326
[Epoch 41; Iter   670/ 1097] train: loss: 0.1866381
[Epoch 41; Iter   700/ 1097] train: loss: 0.0278205
[Epoch 41; Iter   730/ 1097] train: loss: 0.0104896
[Epoch 41; Iter   760/ 1097] train: loss: 0.0949916
[Epoch 41; Iter   790/ 1097] train: loss: 0.0549859
[Epoch 41; Iter   820/ 1097] train: loss: 0.0181176
[Epoch 41; Iter   850/ 1097] train: loss: 0.2997000
[Epoch 41; Iter   880/ 1097] train: loss: 0.0483352
[Epoch 41; Iter   910/ 1097] train: loss: 0.0137895
[Epoch 41; Iter   940/ 1097] train: loss: 0.1266274
[Epoch 41; Iter   970/ 1097] train: loss: 0.0288238
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2324993
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0216885
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0123468
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0689387
[Epoch 41] ogbg-molhiv: 0.819594 val loss: 0.087106
[Epoch 41] ogbg-molhiv: 0.770805 test loss: 0.137715
[Epoch 42; Iter    23/ 1097] train: loss: 0.0098634
[Epoch 42; Iter    53/ 1097] train: loss: 0.0134261
[Epoch 42; Iter    83/ 1097] train: loss: 0.0446528
[Epoch 42; Iter   113/ 1097] train: loss: 0.0260478
[Epoch 42; Iter   143/ 1097] train: loss: 0.0095232
[Epoch 42; Iter   173/ 1097] train: loss: 0.0089918
[Epoch 42; Iter   203/ 1097] train: loss: 0.0211514
[Epoch 42; Iter   233/ 1097] train: loss: 0.0389003
[Epoch 42; Iter   263/ 1097] train: loss: 0.0122568
[Epoch 42; Iter   293/ 1097] train: loss: 0.0380459
[Epoch 42; Iter   323/ 1097] train: loss: 0.2125954
[Epoch 42; Iter   353/ 1097] train: loss: 0.0134479
[Epoch 42; Iter   383/ 1097] train: loss: 0.0601004
[Epoch 42; Iter   413/ 1097] train: loss: 0.1576343
[Epoch 42; Iter   443/ 1097] train: loss: 0.0107980
[Epoch 42; Iter   473/ 1097] train: loss: 0.0501556
[Epoch 42; Iter   503/ 1097] train: loss: 0.1163104
[Epoch 42; Iter   533/ 1097] train: loss: 0.0339114
[Epoch 42; Iter   563/ 1097] train: loss: 0.0108929
[Epoch 42; Iter   593/ 1097] train: loss: 0.0357215
[Epoch 42; Iter   623/ 1097] train: loss: 0.0195256
[Epoch 42; Iter   653/ 1097] train: loss: 0.0704073
[Epoch 42; Iter   683/ 1097] train: loss: 0.0467270
[Epoch 42; Iter   713/ 1097] train: loss: 0.0134246
[Epoch 42; Iter   743/ 1097] train: loss: 0.1375613
[Epoch 42; Iter   773/ 1097] train: loss: 0.0179593
[Epoch 42; Iter   803/ 1097] train: loss: 0.1579271
[Epoch 42; Iter   833/ 1097] train: loss: 0.0129091
[Epoch 42; Iter   863/ 1097] train: loss: 0.0149673
[Epoch 42; Iter   893/ 1097] train: loss: 0.0359739
[Epoch 42; Iter   923/ 1097] train: loss: 0.0315225
[Epoch 42; Iter   953/ 1097] train: loss: 0.0188692
[Epoch 42; Iter   983/ 1097] train: loss: 0.0155273
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1980138
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0458059
[Epoch 42; Iter  1073/ 1097] train: loss: 0.1189456
[Epoch 42] ogbg-molhiv: 0.798412 val loss: 0.086472
[Epoch 42] ogbg-molhiv: 0.741490 test loss: 0.144618
[Epoch 43; Iter     6/ 1097] train: loss: 0.0293780
[Epoch 43; Iter    36/ 1097] train: loss: 0.0614519
[Epoch 43; Iter    66/ 1097] train: loss: 0.2986212
[Epoch 43; Iter    96/ 1097] train: loss: 0.0459513
[Epoch 43; Iter   126/ 1097] train: loss: 0.0197204
[Epoch 43; Iter   156/ 1097] train: loss: 0.0264054
[Epoch 43; Iter   186/ 1097] train: loss: 0.0557167
[Epoch 43; Iter   216/ 1097] train: loss: 0.0154191
[Epoch 43; Iter   246/ 1097] train: loss: 0.0301008
[Epoch 43; Iter   276/ 1097] train: loss: 0.0191704
[Epoch 43; Iter   306/ 1097] train: loss: 0.1666931
[Epoch 43; Iter   336/ 1097] train: loss: 0.0164319
[Epoch 43; Iter   366/ 1097] train: loss: 0.0322037
[Epoch 43; Iter   396/ 1097] train: loss: 0.0298937
[Epoch 43; Iter   426/ 1097] train: loss: 0.0724350
[Epoch 43; Iter   456/ 1097] train: loss: 0.0342456
[Epoch 43; Iter   486/ 1097] train: loss: 0.1778878
[Epoch 43; Iter   516/ 1097] train: loss: 0.2026751
[Epoch 43; Iter   546/ 1097] train: loss: 0.0610574
[Epoch 43; Iter   576/ 1097] train: loss: 0.0223556
[Epoch 43; Iter   606/ 1097] train: loss: 0.1312339
[Epoch 43; Iter   636/ 1097] train: loss: 0.0112653
[Epoch 43; Iter   666/ 1097] train: loss: 0.0110931
[Epoch 43; Iter   696/ 1097] train: loss: 0.0996459
[Epoch 43; Iter   726/ 1097] train: loss: 0.0594982
[Epoch 43; Iter   756/ 1097] train: loss: 0.0124345
[Epoch 43; Iter   786/ 1097] train: loss: 0.0103285
[Epoch 43; Iter   816/ 1097] train: loss: 0.0488917
[Epoch 43; Iter   846/ 1097] train: loss: 0.1079438
[Epoch 43; Iter   876/ 1097] train: loss: 0.1082895
[Epoch 43; Iter   906/ 1097] train: loss: 0.1341781
[Epoch 43; Iter   936/ 1097] train: loss: 0.1956100
[Epoch 43; Iter   966/ 1097] train: loss: 0.2605057
[Epoch 43; Iter   996/ 1097] train: loss: 0.0591056
[Epoch 43; Iter  1026/ 1097] train: loss: 0.1096151
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0141480
[Epoch 43; Iter  1086/ 1097] train: loss: 0.2488896
[Epoch 43] ogbg-molhiv: 0.808642 val loss: 0.097740
[Epoch 43] ogbg-molhiv: 0.740269 test loss: 0.153499
[Epoch 44; Iter    19/ 1097] train: loss: 0.0147807
[Epoch 44; Iter    49/ 1097] train: loss: 0.1158182
[Epoch 44; Iter    79/ 1097] train: loss: 0.0148445
[Epoch 44; Iter   109/ 1097] train: loss: 0.1271449
[Epoch 44; Iter   139/ 1097] train: loss: 0.0077976
[Epoch 44; Iter   169/ 1097] train: loss: 0.0791244
[Epoch 44; Iter   199/ 1097] train: loss: 0.1479550
[Epoch 44; Iter   229/ 1097] train: loss: 0.0928803
[Epoch 44; Iter   259/ 1097] train: loss: 0.0092431
[Epoch 44; Iter   289/ 1097] train: loss: 0.1544710
[Epoch 44; Iter   319/ 1097] train: loss: 0.1494798
[Epoch 44; Iter   349/ 1097] train: loss: 0.0484444
[Epoch 44; Iter   379/ 1097] train: loss: 0.0534609
[Epoch 44; Iter   409/ 1097] train: loss: 0.1080149
[Epoch 44; Iter   439/ 1097] train: loss: 0.0342600
[Epoch 44; Iter   469/ 1097] train: loss: 0.0409435
[Epoch 44; Iter   499/ 1097] train: loss: 0.0177641
[Epoch 44; Iter   529/ 1097] train: loss: 0.0140951
[Epoch 44; Iter   559/ 1097] train: loss: 0.0423747
[Epoch 44; Iter   589/ 1097] train: loss: 0.0413312
[Epoch 44; Iter   619/ 1097] train: loss: 0.0693156
[Epoch 44; Iter   649/ 1097] train: loss: 0.0164400
[Epoch 44; Iter   679/ 1097] train: loss: 0.2478355
[Epoch 44; Iter   709/ 1097] train: loss: 0.0497791
[Epoch 44; Iter   739/ 1097] train: loss: 0.0482366
[Epoch 48; Iter   851/ 1097] train: loss: 0.0021230
[Epoch 48; Iter   881/ 1097] train: loss: 0.0058270
[Epoch 48; Iter   911/ 1097] train: loss: 0.0032472
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015431
[Epoch 48; Iter   971/ 1097] train: loss: 0.0006322
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0029944
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0058725
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0053108
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0024770
[Epoch 48] ogbg-molhiv: 0.778779 val loss: 4.418376
[Epoch 48] ogbg-molhiv: 0.704351 test loss: 4.941884
[Epoch 49; Iter    24/ 1097] train: loss: 0.0087681
[Epoch 49; Iter    54/ 1097] train: loss: 0.0005326
[Epoch 49; Iter    84/ 1097] train: loss: 0.0153693
[Epoch 49; Iter   114/ 1097] train: loss: 0.0006899
[Epoch 49; Iter   144/ 1097] train: loss: 0.0077255
[Epoch 49; Iter   174/ 1097] train: loss: 0.0032910
[Epoch 49; Iter   204/ 1097] train: loss: 0.0067869
[Epoch 49; Iter   234/ 1097] train: loss: 0.0003709
[Epoch 49; Iter   264/ 1097] train: loss: 0.0424611
[Epoch 49; Iter   294/ 1097] train: loss: 0.0003275
[Epoch 49; Iter   324/ 1097] train: loss: 0.0933188
[Epoch 49; Iter   354/ 1097] train: loss: 0.0040088
[Epoch 49; Iter   384/ 1097] train: loss: 0.0161900
[Epoch 49; Iter   414/ 1097] train: loss: 0.0179425
[Epoch 49; Iter   444/ 1097] train: loss: 0.0230651
[Epoch 49; Iter   474/ 1097] train: loss: 0.0072727
[Epoch 49; Iter   504/ 1097] train: loss: 0.0015455
[Epoch 49; Iter   534/ 1097] train: loss: 0.0044531
[Epoch 49; Iter   564/ 1097] train: loss: 0.0005148
[Epoch 49; Iter   594/ 1097] train: loss: 0.0493398
[Epoch 49; Iter   624/ 1097] train: loss: 0.0144646
[Epoch 49; Iter   654/ 1097] train: loss: 0.0235888
[Epoch 49; Iter   684/ 1097] train: loss: 0.0150160
[Epoch 49; Iter   714/ 1097] train: loss: 0.0073531
[Epoch 49; Iter   744/ 1097] train: loss: 0.0034741
[Epoch 49; Iter   774/ 1097] train: loss: 0.0030129
[Epoch 49; Iter   804/ 1097] train: loss: 0.0213950
[Epoch 49; Iter   834/ 1097] train: loss: 0.0244222
[Epoch 49; Iter   864/ 1097] train: loss: 0.0024354
[Epoch 49; Iter   894/ 1097] train: loss: 0.0375521
[Epoch 49; Iter   924/ 1097] train: loss: 0.0016084
[Epoch 49; Iter   954/ 1097] train: loss: 0.1271552
[Epoch 49; Iter   984/ 1097] train: loss: 0.1859924
[Epoch 49; Iter  1014/ 1097] train: loss: 0.1257576
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0162267
[Epoch 49; Iter  1074/ 1097] train: loss: 0.1391846
[Epoch 49] ogbg-molhiv: 0.740499 val loss: 6.164430
[Epoch 49] ogbg-molhiv: 0.715232 test loss: 4.409670
[Epoch 50; Iter     7/ 1097] train: loss: 0.0843112
[Epoch 50; Iter    37/ 1097] train: loss: 0.0422791
[Epoch 50; Iter    67/ 1097] train: loss: 0.0476544
[Epoch 50; Iter    97/ 1097] train: loss: 0.0108950
[Epoch 50; Iter   127/ 1097] train: loss: 0.0057942
[Epoch 50; Iter   157/ 1097] train: loss: 0.0072713
[Epoch 50; Iter   187/ 1097] train: loss: 0.0113105
[Epoch 50; Iter   217/ 1097] train: loss: 0.0218953
[Epoch 50; Iter   247/ 1097] train: loss: 0.0074160
[Epoch 50; Iter   277/ 1097] train: loss: 0.0008386
[Epoch 50; Iter   307/ 1097] train: loss: 0.0029233
[Epoch 50; Iter   337/ 1097] train: loss: 0.0027627
[Epoch 50; Iter   367/ 1097] train: loss: 0.0012774
[Epoch 50; Iter   397/ 1097] train: loss: 0.0028234
[Epoch 50; Iter   427/ 1097] train: loss: 0.0013013
[Epoch 50; Iter   457/ 1097] train: loss: 0.0087182
[Epoch 50; Iter   487/ 1097] train: loss: 0.0668651
[Epoch 50; Iter   517/ 1097] train: loss: 0.0579471
[Epoch 50; Iter   547/ 1097] train: loss: 0.0002981
[Epoch 50; Iter   577/ 1097] train: loss: 0.0031329
[Epoch 50; Iter   607/ 1097] train: loss: 0.0555569
[Epoch 50; Iter   637/ 1097] train: loss: 0.0399288
[Epoch 50; Iter   667/ 1097] train: loss: 0.0167216
[Epoch 50; Iter   697/ 1097] train: loss: 0.0011846
[Epoch 50; Iter   727/ 1097] train: loss: 0.0025037
[Epoch 50; Iter   757/ 1097] train: loss: 0.0065839
[Epoch 50; Iter   787/ 1097] train: loss: 0.0010963
[Epoch 50; Iter   817/ 1097] train: loss: 0.0099313
[Epoch 50; Iter   847/ 1097] train: loss: 0.0265741
[Epoch 50; Iter   877/ 1097] train: loss: 0.0064720
[Epoch 50; Iter   907/ 1097] train: loss: 0.0020336
[Epoch 50; Iter   937/ 1097] train: loss: 0.0000890
[Epoch 50; Iter   967/ 1097] train: loss: 0.0013753
[Epoch 50; Iter   997/ 1097] train: loss: 0.0037501
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0010475
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0010196
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0050142
[Epoch 50] ogbg-molhiv: 0.782414 val loss: 17.592095
[Epoch 50] ogbg-molhiv: 0.686626 test loss: 16.239149
[Epoch 51; Iter    20/ 1097] train: loss: 0.0406094
[Epoch 51; Iter    50/ 1097] train: loss: 0.0109023
[Epoch 51; Iter    80/ 1097] train: loss: 0.0094095
[Epoch 51; Iter   110/ 1097] train: loss: 0.0006680
[Epoch 51; Iter   140/ 1097] train: loss: 0.0031883
[Epoch 51; Iter   170/ 1097] train: loss: 0.0053503
[Epoch 51; Iter   200/ 1097] train: loss: 0.0022489
[Epoch 51; Iter   230/ 1097] train: loss: 0.0689727
[Epoch 51; Iter   260/ 1097] train: loss: 0.0018048
[Epoch 51; Iter   290/ 1097] train: loss: 0.0079310
[Epoch 51; Iter   320/ 1097] train: loss: 0.0219216
[Epoch 51; Iter   350/ 1097] train: loss: 0.0049969
[Epoch 51; Iter   380/ 1097] train: loss: 0.0334202
[Epoch 51; Iter   410/ 1097] train: loss: 0.0042838
[Epoch 51; Iter   440/ 1097] train: loss: 0.0761693
[Epoch 51; Iter   470/ 1097] train: loss: 0.1035695
[Epoch 51; Iter   500/ 1097] train: loss: 0.0066819
[Epoch 51; Iter   530/ 1097] train: loss: 0.0430589
[Epoch 51; Iter   560/ 1097] train: loss: 0.0006360
[Epoch 51; Iter   590/ 1097] train: loss: 0.0053742
[Epoch 51; Iter   620/ 1097] train: loss: 0.0143052
[Epoch 51; Iter   650/ 1097] train: loss: 0.0026095
[Epoch 51; Iter   680/ 1097] train: loss: 0.1642186
[Epoch 51; Iter   710/ 1097] train: loss: 0.0004611
[Epoch 51; Iter   740/ 1097] train: loss: 0.0010798
[Epoch 51; Iter   770/ 1097] train: loss: 0.0169953
[Epoch 51; Iter   800/ 1097] train: loss: 0.0686945
[Epoch 51; Iter   830/ 1097] train: loss: 0.0813818
[Epoch 51; Iter   860/ 1097] train: loss: 0.0554563
[Epoch 51; Iter   890/ 1097] train: loss: 0.0398529
[Epoch 51; Iter   920/ 1097] train: loss: 0.0031680
[Epoch 51; Iter   950/ 1097] train: loss: 0.0223127
[Epoch 51; Iter   980/ 1097] train: loss: 0.0022863
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0274659
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0162968
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0171865
[Epoch 51] ogbg-molhiv: 0.792129 val loss: 11.836799
[Epoch 51] ogbg-molhiv: 0.686483 test loss: 8.035971
[Epoch 52; Iter     3/ 1097] train: loss: 0.0002310
[Epoch 52; Iter    33/ 1097] train: loss: 0.0005966
[Epoch 52; Iter    63/ 1097] train: loss: 0.0026386
[Epoch 52; Iter    93/ 1097] train: loss: 0.0023098
[Epoch 52; Iter   123/ 1097] train: loss: 0.0012379
[Epoch 52; Iter   153/ 1097] train: loss: 0.0012730
[Epoch 52; Iter   183/ 1097] train: loss: 0.0033011
[Epoch 52; Iter   213/ 1097] train: loss: 0.0113777
[Epoch 52; Iter   243/ 1097] train: loss: 0.0015505
[Epoch 52; Iter   273/ 1097] train: loss: 0.0078302
[Epoch 52; Iter   303/ 1097] train: loss: 0.0042114
[Epoch 52; Iter   333/ 1097] train: loss: 0.0001084
[Epoch 52; Iter   363/ 1097] train: loss: 0.0082079
[Epoch 52; Iter   393/ 1097] train: loss: 0.0060047
[Epoch 52; Iter   423/ 1097] train: loss: 0.0063548
[Epoch 52; Iter   453/ 1097] train: loss: 0.0024947
[Epoch 52; Iter   483/ 1097] train: loss: 0.0078720
[Epoch 52; Iter   513/ 1097] train: loss: 0.0156320
[Epoch 52; Iter   543/ 1097] train: loss: 0.0695286
[Epoch 52; Iter   573/ 1097] train: loss: 0.0372202
[Epoch 52; Iter   603/ 1097] train: loss: 0.1069059
[Epoch 52; Iter   633/ 1097] train: loss: 0.0005518
[Epoch 52; Iter   663/ 1097] train: loss: 0.0029256
[Epoch 52; Iter   693/ 1097] train: loss: 0.0008032
[Epoch 52; Iter   723/ 1097] train: loss: 0.0476195
[Epoch 52; Iter   753/ 1097] train: loss: 0.0045849
[Epoch 52; Iter   783/ 1097] train: loss: 0.0040573
[Epoch 52; Iter   813/ 1097] train: loss: 0.0946525
[Epoch 52; Iter   843/ 1097] train: loss: 0.0245637
[Epoch 52; Iter   873/ 1097] train: loss: 0.0020739
[Epoch 52; Iter   903/ 1097] train: loss: 0.0004966
[Epoch 40; Iter   687/ 1097] train: loss: 0.0415528
[Epoch 40; Iter   717/ 1097] train: loss: 0.0076603
[Epoch 40; Iter   747/ 1097] train: loss: 0.0211056
[Epoch 40; Iter   777/ 1097] train: loss: 0.2613224
[Epoch 40; Iter   807/ 1097] train: loss: 0.0145557
[Epoch 40; Iter   837/ 1097] train: loss: 0.0301693
[Epoch 40; Iter   867/ 1097] train: loss: 0.0823626
[Epoch 40; Iter   897/ 1097] train: loss: 0.0635919
[Epoch 40; Iter   927/ 1097] train: loss: 0.2291289
[Epoch 40; Iter   957/ 1097] train: loss: 0.0539131
[Epoch 40; Iter   987/ 1097] train: loss: 0.0145621
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0879032
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0860357
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0214977
[Epoch 40] ogbg-molhiv: 0.803418 val loss: 0.084083
[Epoch 40] ogbg-molhiv: 0.755588 test loss: 0.156080
[Epoch 41; Iter    10/ 1097] train: loss: 0.1055596
[Epoch 41; Iter    40/ 1097] train: loss: 0.2544296
[Epoch 41; Iter    70/ 1097] train: loss: 0.0145666
[Epoch 41; Iter   100/ 1097] train: loss: 0.0143387
[Epoch 41; Iter   130/ 1097] train: loss: 0.0762747
[Epoch 41; Iter   160/ 1097] train: loss: 0.0505378
[Epoch 41; Iter   190/ 1097] train: loss: 0.2568460
[Epoch 41; Iter   220/ 1097] train: loss: 0.2197056
[Epoch 41; Iter   250/ 1097] train: loss: 0.0333702
[Epoch 41; Iter   280/ 1097] train: loss: 0.0351626
[Epoch 41; Iter   310/ 1097] train: loss: 0.1011726
[Epoch 41; Iter   340/ 1097] train: loss: 0.0332548
[Epoch 41; Iter   370/ 1097] train: loss: 0.2371438
[Epoch 41; Iter   400/ 1097] train: loss: 0.0430637
[Epoch 41; Iter   430/ 1097] train: loss: 0.0433115
[Epoch 41; Iter   460/ 1097] train: loss: 0.1084815
[Epoch 41; Iter   490/ 1097] train: loss: 0.5896862
[Epoch 41; Iter   520/ 1097] train: loss: 0.1037524
[Epoch 41; Iter   550/ 1097] train: loss: 0.0282197
[Epoch 41; Iter   580/ 1097] train: loss: 0.0914261
[Epoch 41; Iter   610/ 1097] train: loss: 0.1124146
[Epoch 41; Iter   640/ 1097] train: loss: 0.0158837
[Epoch 41; Iter   670/ 1097] train: loss: 0.0151815
[Epoch 41; Iter   700/ 1097] train: loss: 0.0960123
[Epoch 41; Iter   730/ 1097] train: loss: 0.0164629
[Epoch 41; Iter   760/ 1097] train: loss: 0.0665213
[Epoch 41; Iter   790/ 1097] train: loss: 0.0556685
[Epoch 41; Iter   820/ 1097] train: loss: 0.0205559
[Epoch 41; Iter   850/ 1097] train: loss: 0.0186894
[Epoch 41; Iter   880/ 1097] train: loss: 0.0236783
[Epoch 41; Iter   910/ 1097] train: loss: 0.1144899
[Epoch 41; Iter   940/ 1097] train: loss: 0.0408913
[Epoch 41; Iter   970/ 1097] train: loss: 0.2297713
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2290442
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0357317
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0428749
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0883905
[Epoch 41] ogbg-molhiv: 0.818746 val loss: 0.079381
[Epoch 41] ogbg-molhiv: 0.748203 test loss: 0.157932
[Epoch 42; Iter    23/ 1097] train: loss: 0.0119974
[Epoch 42; Iter    53/ 1097] train: loss: 0.0288506
[Epoch 42; Iter    83/ 1097] train: loss: 0.1504862
[Epoch 42; Iter   113/ 1097] train: loss: 0.0286440
[Epoch 42; Iter   143/ 1097] train: loss: 0.1230987
[Epoch 42; Iter   173/ 1097] train: loss: 0.0379525
[Epoch 42; Iter   203/ 1097] train: loss: 0.0221660
[Epoch 42; Iter   233/ 1097] train: loss: 0.0246418
[Epoch 42; Iter   263/ 1097] train: loss: 0.0807485
[Epoch 42; Iter   293/ 1097] train: loss: 0.0393689
[Epoch 42; Iter   323/ 1097] train: loss: 0.1490833
[Epoch 42; Iter   353/ 1097] train: loss: 0.0133971
[Epoch 42; Iter   383/ 1097] train: loss: 0.1445475
[Epoch 42; Iter   413/ 1097] train: loss: 0.1457133
[Epoch 42; Iter   443/ 1097] train: loss: 0.0287378
[Epoch 42; Iter   473/ 1097] train: loss: 0.1487259
[Epoch 42; Iter   503/ 1097] train: loss: 0.0750417
[Epoch 42; Iter   533/ 1097] train: loss: 0.0450299
[Epoch 42; Iter   563/ 1097] train: loss: 0.0410505
[Epoch 42; Iter   593/ 1097] train: loss: 0.0206686
[Epoch 42; Iter   623/ 1097] train: loss: 0.0101218
[Epoch 42; Iter   653/ 1097] train: loss: 0.2591351
[Epoch 42; Iter   683/ 1097] train: loss: 0.0164815
[Epoch 42; Iter   713/ 1097] train: loss: 0.0566988
[Epoch 42; Iter   743/ 1097] train: loss: 0.0533098
[Epoch 42; Iter   773/ 1097] train: loss: 0.0499495
[Epoch 42; Iter   803/ 1097] train: loss: 0.0255693
[Epoch 42; Iter   833/ 1097] train: loss: 0.0203432
[Epoch 42; Iter   863/ 1097] train: loss: 0.0203500
[Epoch 42; Iter   893/ 1097] train: loss: 0.0532161
[Epoch 42; Iter   923/ 1097] train: loss: 0.2192865
[Epoch 42; Iter   953/ 1097] train: loss: 0.0087424
[Epoch 42; Iter   983/ 1097] train: loss: 0.0138455
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1111556
[Epoch 42; Iter  1043/ 1097] train: loss: 0.2353475
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0192574
[Epoch 42] ogbg-molhiv: 0.783501 val loss: 0.088224
[Epoch 42] ogbg-molhiv: 0.737840 test loss: 0.189696
[Epoch 43; Iter     6/ 1097] train: loss: 0.1482050
[Epoch 43; Iter    36/ 1097] train: loss: 0.0111595
[Epoch 43; Iter    66/ 1097] train: loss: 0.2219925
[Epoch 43; Iter    96/ 1097] train: loss: 0.0510612
[Epoch 43; Iter   126/ 1097] train: loss: 0.0871503
[Epoch 43; Iter   156/ 1097] train: loss: 0.1859501
[Epoch 43; Iter   186/ 1097] train: loss: 0.0785140
[Epoch 43; Iter   216/ 1097] train: loss: 0.0475862
[Epoch 43; Iter   246/ 1097] train: loss: 0.0484330
[Epoch 43; Iter   276/ 1097] train: loss: 0.3255461
[Epoch 43; Iter   306/ 1097] train: loss: 0.0090147
[Epoch 43; Iter   336/ 1097] train: loss: 0.1388184
[Epoch 43; Iter   366/ 1097] train: loss: 0.0227842
[Epoch 43; Iter   396/ 1097] train: loss: 0.0148467
[Epoch 43; Iter   426/ 1097] train: loss: 0.0546529
[Epoch 43; Iter   456/ 1097] train: loss: 0.1346550
[Epoch 43; Iter   486/ 1097] train: loss: 0.0467381
[Epoch 43; Iter   516/ 1097] train: loss: 0.0589655
[Epoch 43; Iter   546/ 1097] train: loss: 0.0118857
[Epoch 43; Iter   576/ 1097] train: loss: 0.2851824
[Epoch 43; Iter   606/ 1097] train: loss: 0.0304911
[Epoch 43; Iter   636/ 1097] train: loss: 0.0370201
[Epoch 43; Iter   666/ 1097] train: loss: 0.0125290
[Epoch 43; Iter   696/ 1097] train: loss: 0.2664056
[Epoch 43; Iter   726/ 1097] train: loss: 0.0511293
[Epoch 43; Iter   756/ 1097] train: loss: 0.0703626
[Epoch 43; Iter   786/ 1097] train: loss: 0.0202115
[Epoch 43; Iter   816/ 1097] train: loss: 0.0166882
[Epoch 43; Iter   846/ 1097] train: loss: 0.0545939
[Epoch 43; Iter   876/ 1097] train: loss: 0.0221042
[Epoch 43; Iter   906/ 1097] train: loss: 0.1123210
[Epoch 43; Iter   936/ 1097] train: loss: 0.0244887
[Epoch 43; Iter   966/ 1097] train: loss: 0.0479635
[Epoch 43; Iter   996/ 1097] train: loss: 0.0567128
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0228348
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1086540
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0184341
[Epoch 43] ogbg-molhiv: 0.813143 val loss: 0.080257
[Epoch 43] ogbg-molhiv: 0.767502 test loss: 0.142306
[Epoch 44; Iter    19/ 1097] train: loss: 0.0599339
[Epoch 44; Iter    49/ 1097] train: loss: 0.0106619
[Epoch 44; Iter    79/ 1097] train: loss: 0.0650093
[Epoch 44; Iter   109/ 1097] train: loss: 0.0370567
[Epoch 44; Iter   139/ 1097] train: loss: 0.0202352
[Epoch 44; Iter   169/ 1097] train: loss: 0.1123230
[Epoch 44; Iter   199/ 1097] train: loss: 0.0062156
[Epoch 44; Iter   229/ 1097] train: loss: 0.0880462
[Epoch 44; Iter   259/ 1097] train: loss: 0.0759802
[Epoch 44; Iter   289/ 1097] train: loss: 0.0241450
[Epoch 44; Iter   319/ 1097] train: loss: 0.0098423
[Epoch 44; Iter   349/ 1097] train: loss: 0.0496711
[Epoch 44; Iter   379/ 1097] train: loss: 0.0120190
[Epoch 44; Iter   409/ 1097] train: loss: 0.0193779
[Epoch 44; Iter   439/ 1097] train: loss: 0.0398518
[Epoch 44; Iter   469/ 1097] train: loss: 0.1741194
[Epoch 44; Iter   499/ 1097] train: loss: 0.0927242
[Epoch 44; Iter   529/ 1097] train: loss: 0.0677481
[Epoch 44; Iter   559/ 1097] train: loss: 0.1170463
[Epoch 44; Iter   589/ 1097] train: loss: 0.0967247
[Epoch 44; Iter   619/ 1097] train: loss: 0.0191206
[Epoch 44; Iter   649/ 1097] train: loss: 0.0243956
[Epoch 44; Iter   679/ 1097] train: loss: 0.2258555
[Epoch 44; Iter   709/ 1097] train: loss: 0.0110342
[Epoch 44; Iter   739/ 1097] train: loss: 0.0303160
[Epoch 40; Iter   687/ 1097] train: loss: 0.0130596
[Epoch 40; Iter   717/ 1097] train: loss: 0.1069354
[Epoch 40; Iter   747/ 1097] train: loss: 0.0641289
[Epoch 40; Iter   777/ 1097] train: loss: 0.0197013
[Epoch 40; Iter   807/ 1097] train: loss: 0.1102952
[Epoch 40; Iter   837/ 1097] train: loss: 0.0481654
[Epoch 40; Iter   867/ 1097] train: loss: 0.0509889
[Epoch 40; Iter   897/ 1097] train: loss: 0.0333206
[Epoch 40; Iter   927/ 1097] train: loss: 0.1462454
[Epoch 40; Iter   957/ 1097] train: loss: 0.1999992
[Epoch 40; Iter   987/ 1097] train: loss: 0.0339882
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0747102
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0451268
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0352875
[Epoch 40] ogbg-molhiv: 0.829111 val loss: 0.075109
[Epoch 40] ogbg-molhiv: 0.749889 test loss: 0.131606
[Epoch 41; Iter    10/ 1097] train: loss: 0.0954928
[Epoch 41; Iter    40/ 1097] train: loss: 0.0196972
[Epoch 41; Iter    70/ 1097] train: loss: 0.0094032
[Epoch 41; Iter   100/ 1097] train: loss: 0.0181502
[Epoch 41; Iter   130/ 1097] train: loss: 0.0534785
[Epoch 41; Iter   160/ 1097] train: loss: 0.0360724
[Epoch 41; Iter   190/ 1097] train: loss: 0.0391028
[Epoch 41; Iter   220/ 1097] train: loss: 0.0101007
[Epoch 41; Iter   250/ 1097] train: loss: 0.0557673
[Epoch 41; Iter   280/ 1097] train: loss: 0.0787777
[Epoch 41; Iter   310/ 1097] train: loss: 0.2073347
[Epoch 41; Iter   340/ 1097] train: loss: 0.2130984
[Epoch 41; Iter   370/ 1097] train: loss: 0.0128912
[Epoch 41; Iter   400/ 1097] train: loss: 0.0108458
[Epoch 41; Iter   430/ 1097] train: loss: 0.0203108
[Epoch 41; Iter   460/ 1097] train: loss: 0.0745554
[Epoch 41; Iter   490/ 1097] train: loss: 0.3443233
[Epoch 41; Iter   520/ 1097] train: loss: 0.1169426
[Epoch 41; Iter   550/ 1097] train: loss: 0.0180893
[Epoch 41; Iter   580/ 1097] train: loss: 0.1905924
[Epoch 41; Iter   610/ 1097] train: loss: 0.0165084
[Epoch 41; Iter   640/ 1097] train: loss: 0.2498351
[Epoch 41; Iter   670/ 1097] train: loss: 0.0978398
[Epoch 41; Iter   700/ 1097] train: loss: 0.0170414
[Epoch 41; Iter   730/ 1097] train: loss: 0.0205373
[Epoch 41; Iter   760/ 1097] train: loss: 0.0690459
[Epoch 41; Iter   790/ 1097] train: loss: 0.0983108
[Epoch 41; Iter   820/ 1097] train: loss: 0.0745449
[Epoch 41; Iter   850/ 1097] train: loss: 0.0519803
[Epoch 41; Iter   880/ 1097] train: loss: 0.0694908
[Epoch 41; Iter   910/ 1097] train: loss: 0.0613102
[Epoch 41; Iter   940/ 1097] train: loss: 0.0111775
[Epoch 41; Iter   970/ 1097] train: loss: 0.2316813
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0194669
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1117621
[Epoch 41; Iter  1060/ 1097] train: loss: 0.1621499
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1306845
[Epoch 41] ogbg-molhiv: 0.831793 val loss: 0.091033
[Epoch 41] ogbg-molhiv: 0.773120 test loss: 0.138054
[Epoch 42; Iter    23/ 1097] train: loss: 0.0929115
[Epoch 42; Iter    53/ 1097] train: loss: 0.1196661
[Epoch 42; Iter    83/ 1097] train: loss: 0.0479521
[Epoch 42; Iter   113/ 1097] train: loss: 0.0311482
[Epoch 42; Iter   143/ 1097] train: loss: 0.0158561
[Epoch 42; Iter   173/ 1097] train: loss: 0.0387366
[Epoch 42; Iter   203/ 1097] train: loss: 0.1409229
[Epoch 42; Iter   233/ 1097] train: loss: 0.1494912
[Epoch 42; Iter   263/ 1097] train: loss: 0.1156109
[Epoch 42; Iter   293/ 1097] train: loss: 0.1179565
[Epoch 42; Iter   323/ 1097] train: loss: 0.0584200
[Epoch 42; Iter   353/ 1097] train: loss: 0.0601764
[Epoch 42; Iter   383/ 1097] train: loss: 0.1321388
[Epoch 42; Iter   413/ 1097] train: loss: 0.0441333
[Epoch 42; Iter   443/ 1097] train: loss: 0.2933801
[Epoch 42; Iter   473/ 1097] train: loss: 0.0290574
[Epoch 42; Iter   503/ 1097] train: loss: 0.2079264
[Epoch 42; Iter   533/ 1097] train: loss: 0.1230721
[Epoch 42; Iter   563/ 1097] train: loss: 0.0216372
[Epoch 42; Iter   593/ 1097] train: loss: 0.0366630
[Epoch 42; Iter   623/ 1097] train: loss: 0.0420399
[Epoch 42; Iter   653/ 1097] train: loss: 0.1928781
[Epoch 42; Iter   683/ 1097] train: loss: 0.1763519
[Epoch 42; Iter   713/ 1097] train: loss: 0.0081712
[Epoch 42; Iter   743/ 1097] train: loss: 0.0759214
[Epoch 42; Iter   773/ 1097] train: loss: 0.2886717
[Epoch 42; Iter   803/ 1097] train: loss: 0.1221767
[Epoch 42; Iter   833/ 1097] train: loss: 0.0283842
[Epoch 42; Iter   863/ 1097] train: loss: 0.1027048
[Epoch 42; Iter   893/ 1097] train: loss: 0.1565685
[Epoch 42; Iter   923/ 1097] train: loss: 0.0366579
[Epoch 42; Iter   953/ 1097] train: loss: 0.1052875
[Epoch 42; Iter   983/ 1097] train: loss: 0.0188690
[Epoch 42; Iter  1013/ 1097] train: loss: 0.2721402
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1263507
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0175330
[Epoch 42] ogbg-molhiv: 0.837305 val loss: 0.074911
[Epoch 42] ogbg-molhiv: 0.777692 test loss: 0.130920
[Epoch 43; Iter     6/ 1097] train: loss: 0.1378729
[Epoch 43; Iter    36/ 1097] train: loss: 0.0568374
[Epoch 43; Iter    66/ 1097] train: loss: 0.1758462
[Epoch 43; Iter    96/ 1097] train: loss: 0.1599992
[Epoch 43; Iter   126/ 1097] train: loss: 0.0499493
[Epoch 43; Iter   156/ 1097] train: loss: 0.0246782
[Epoch 43; Iter   186/ 1097] train: loss: 0.2295657
[Epoch 43; Iter   216/ 1097] train: loss: 0.1463557
[Epoch 43; Iter   246/ 1097] train: loss: 0.2572462
[Epoch 43; Iter   276/ 1097] train: loss: 0.0216314
[Epoch 43; Iter   306/ 1097] train: loss: 0.0789973
[Epoch 43; Iter   336/ 1097] train: loss: 0.0215312
[Epoch 43; Iter   366/ 1097] train: loss: 0.0278420
[Epoch 43; Iter   396/ 1097] train: loss: 0.1276442
[Epoch 43; Iter   426/ 1097] train: loss: 0.0442255
[Epoch 43; Iter   456/ 1097] train: loss: 0.1127745
[Epoch 43; Iter   486/ 1097] train: loss: 0.0240509
[Epoch 43; Iter   516/ 1097] train: loss: 0.0138147
[Epoch 43; Iter   546/ 1097] train: loss: 0.0598967
[Epoch 43; Iter   576/ 1097] train: loss: 0.1826302
[Epoch 43; Iter   606/ 1097] train: loss: 0.1051801
[Epoch 43; Iter   636/ 1097] train: loss: 0.0263988
[Epoch 43; Iter   666/ 1097] train: loss: 0.0612881
[Epoch 43; Iter   696/ 1097] train: loss: 0.1196853
[Epoch 43; Iter   726/ 1097] train: loss: 0.0213013
[Epoch 43; Iter   756/ 1097] train: loss: 0.3054915
[Epoch 43; Iter   786/ 1097] train: loss: 0.0288346
[Epoch 43; Iter   816/ 1097] train: loss: 0.0121908
[Epoch 43; Iter   846/ 1097] train: loss: 0.0210840
[Epoch 43; Iter   876/ 1097] train: loss: 0.0818616
[Epoch 43; Iter   906/ 1097] train: loss: 0.0379657
[Epoch 43; Iter   936/ 1097] train: loss: 0.0302783
[Epoch 43; Iter   966/ 1097] train: loss: 0.0178661
[Epoch 43; Iter   996/ 1097] train: loss: 0.0173183
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0361661
[Epoch 43; Iter  1056/ 1097] train: loss: 0.2283701
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0233719
[Epoch 43] ogbg-molhiv: 0.821331 val loss: 0.075240
[Epoch 43] ogbg-molhiv: 0.741279 test loss: 0.142361
[Epoch 44; Iter    19/ 1097] train: loss: 0.0182873
[Epoch 44; Iter    49/ 1097] train: loss: 0.0146764
[Epoch 44; Iter    79/ 1097] train: loss: 0.1187200
[Epoch 44; Iter   109/ 1097] train: loss: 0.0378958
[Epoch 44; Iter   139/ 1097] train: loss: 0.0632560
[Epoch 44; Iter   169/ 1097] train: loss: 0.0197845
[Epoch 44; Iter   199/ 1097] train: loss: 0.0467730
[Epoch 44; Iter   229/ 1097] train: loss: 0.0200954
[Epoch 44; Iter   259/ 1097] train: loss: 0.0091252
[Epoch 44; Iter   289/ 1097] train: loss: 0.0198331
[Epoch 44; Iter   319/ 1097] train: loss: 0.2517519
[Epoch 44; Iter   349/ 1097] train: loss: 0.2805249
[Epoch 44; Iter   379/ 1097] train: loss: 0.0128282
[Epoch 44; Iter   409/ 1097] train: loss: 0.1966026
[Epoch 44; Iter   439/ 1097] train: loss: 0.0222842
[Epoch 44; Iter   469/ 1097] train: loss: 0.1776231
[Epoch 44; Iter   499/ 1097] train: loss: 0.0342918
[Epoch 44; Iter   529/ 1097] train: loss: 0.1143042
[Epoch 44; Iter   559/ 1097] train: loss: 0.0165232
[Epoch 44; Iter   589/ 1097] train: loss: 0.0553877
[Epoch 44; Iter   619/ 1097] train: loss: 0.0267845
[Epoch 44; Iter   649/ 1097] train: loss: 0.0946852
[Epoch 44; Iter   679/ 1097] train: loss: 0.1969192
[Epoch 44; Iter   709/ 1097] train: loss: 0.1385343
[Epoch 44; Iter   739/ 1097] train: loss: 0.0188612
[Epoch 48; Iter   851/ 1097] train: loss: 0.0002877
[Epoch 48; Iter   881/ 1097] train: loss: 0.0597648
[Epoch 48; Iter   911/ 1097] train: loss: 0.0014452
[Epoch 48; Iter   941/ 1097] train: loss: 0.0015439
[Epoch 48; Iter   971/ 1097] train: loss: 0.0005341
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0007899
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0012910
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0005441
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0014284
[Epoch 48] ogbg-molhiv: 0.720113 val loss: 1.175724
[Epoch 48] ogbg-molhiv: 0.658186 test loss: 0.668772
[Epoch 49; Iter    24/ 1097] train: loss: 0.0000863
[Epoch 49; Iter    54/ 1097] train: loss: 0.0022135
[Epoch 49; Iter    84/ 1097] train: loss: 0.0006958
[Epoch 49; Iter   114/ 1097] train: loss: 0.0021945
[Epoch 49; Iter   144/ 1097] train: loss: 0.0001576
[Epoch 49; Iter   174/ 1097] train: loss: 0.0004746
[Epoch 49; Iter   204/ 1097] train: loss: 0.0001885
[Epoch 49; Iter   234/ 1097] train: loss: 0.0028014
[Epoch 49; Iter   264/ 1097] train: loss: 0.0002825
[Epoch 49; Iter   294/ 1097] train: loss: 0.0000483
[Epoch 49; Iter   324/ 1097] train: loss: 0.0000833
[Epoch 49; Iter   354/ 1097] train: loss: 0.0013838
[Epoch 49; Iter   384/ 1097] train: loss: 0.0006284
[Epoch 49; Iter   414/ 1097] train: loss: 0.0355857
[Epoch 49; Iter   444/ 1097] train: loss: 0.0001013
[Epoch 49; Iter   474/ 1097] train: loss: 0.0001206
[Epoch 49; Iter   504/ 1097] train: loss: 0.0092124
[Epoch 49; Iter   534/ 1097] train: loss: 0.0019697
[Epoch 49; Iter   564/ 1097] train: loss: 0.0323092
[Epoch 49; Iter   594/ 1097] train: loss: 0.0002443
[Epoch 49; Iter   624/ 1097] train: loss: 0.0151819
[Epoch 49; Iter   654/ 1097] train: loss: 0.0002546
[Epoch 49; Iter   684/ 1097] train: loss: 0.0029125
[Epoch 49; Iter   714/ 1097] train: loss: 0.0023291
[Epoch 49; Iter   744/ 1097] train: loss: 0.0049612
[Epoch 49; Iter   774/ 1097] train: loss: 0.0028290
[Epoch 49; Iter   804/ 1097] train: loss: 0.0030558
[Epoch 49; Iter   834/ 1097] train: loss: 0.0068372
[Epoch 49; Iter   864/ 1097] train: loss: 0.0002632
[Epoch 49; Iter   894/ 1097] train: loss: 0.0018998
[Epoch 49; Iter   924/ 1097] train: loss: 0.0003371
[Epoch 49; Iter   954/ 1097] train: loss: 0.0071995
[Epoch 49; Iter   984/ 1097] train: loss: 0.0083472
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0017734
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0006971
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0001597
[Epoch 49] ogbg-molhiv: 0.746454 val loss: 2.472744
[Epoch 49] ogbg-molhiv: 0.669999 test loss: 1.723971
[Epoch 50; Iter     7/ 1097] train: loss: 0.0873026
[Epoch 50; Iter    37/ 1097] train: loss: 0.0002201
[Epoch 50; Iter    67/ 1097] train: loss: 0.0000747
[Epoch 50; Iter    97/ 1097] train: loss: 0.0058002
[Epoch 50; Iter   127/ 1097] train: loss: 0.0003567
[Epoch 50; Iter   157/ 1097] train: loss: 0.0010718
[Epoch 50; Iter   187/ 1097] train: loss: 0.0008887
[Epoch 50; Iter   217/ 1097] train: loss: 0.0002297
[Epoch 50; Iter   247/ 1097] train: loss: 0.0290657
[Epoch 50; Iter   277/ 1097] train: loss: 0.0386963
[Epoch 50; Iter   307/ 1097] train: loss: 0.0001062
[Epoch 50; Iter   337/ 1097] train: loss: 0.0244144
[Epoch 50; Iter   367/ 1097] train: loss: 0.0001631
[Epoch 50; Iter   397/ 1097] train: loss: 0.0000646
[Epoch 50; Iter   427/ 1097] train: loss: 0.0339828
[Epoch 50; Iter   457/ 1097] train: loss: 0.0004206
[Epoch 50; Iter   487/ 1097] train: loss: 0.0050216
[Epoch 50; Iter   517/ 1097] train: loss: 0.0009805
[Epoch 50; Iter   547/ 1097] train: loss: 0.0377361
[Epoch 50; Iter   577/ 1097] train: loss: 0.0023607
[Epoch 50; Iter   607/ 1097] train: loss: 0.0001554
[Epoch 50; Iter   637/ 1097] train: loss: 0.0001004
[Epoch 50; Iter   667/ 1097] train: loss: 0.0002262
[Epoch 50; Iter   697/ 1097] train: loss: 0.0170203
[Epoch 50; Iter   727/ 1097] train: loss: 0.0019601
[Epoch 50; Iter   757/ 1097] train: loss: 0.0243973
[Epoch 50; Iter   787/ 1097] train: loss: 0.0004660
[Epoch 50; Iter   817/ 1097] train: loss: 0.0013129
[Epoch 50; Iter   847/ 1097] train: loss: 0.0010075
[Epoch 50; Iter   877/ 1097] train: loss: 0.0028716
[Epoch 50; Iter   907/ 1097] train: loss: 0.0054191
[Epoch 50; Iter   937/ 1097] train: loss: 0.0870969
[Epoch 50; Iter   967/ 1097] train: loss: 0.0001241
[Epoch 50; Iter   997/ 1097] train: loss: 0.0023166
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0006683
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0092467
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0009061
[Epoch 50] ogbg-molhiv: 0.585345 val loss: 131.764413
[Epoch 50] ogbg-molhiv: 0.555389 test loss: 123.329884
[Epoch 51; Iter    20/ 1097] train: loss: 0.0001489
[Epoch 51; Iter    50/ 1097] train: loss: 0.0015811
[Epoch 51; Iter    80/ 1097] train: loss: 0.0001991
[Epoch 51; Iter   110/ 1097] train: loss: 0.0002991
[Epoch 51; Iter   140/ 1097] train: loss: 0.0141803
[Epoch 51; Iter   170/ 1097] train: loss: 0.0002761
[Epoch 51; Iter   200/ 1097] train: loss: 0.0045032
[Epoch 51; Iter   230/ 1097] train: loss: 0.0008090
[Epoch 51; Iter   260/ 1097] train: loss: 0.0009842
[Epoch 51; Iter   290/ 1097] train: loss: 0.0552974
[Epoch 51; Iter   320/ 1097] train: loss: 0.0055389
[Epoch 51; Iter   350/ 1097] train: loss: 0.0117080
[Epoch 51; Iter   380/ 1097] train: loss: 0.0002596
[Epoch 51; Iter   410/ 1097] train: loss: 0.0039367
[Epoch 51; Iter   440/ 1097] train: loss: 0.0008029
[Epoch 51; Iter   470/ 1097] train: loss: 0.0715559
[Epoch 51; Iter   500/ 1097] train: loss: 0.0002704
[Epoch 51; Iter   530/ 1097] train: loss: 0.0005535
[Epoch 51; Iter   560/ 1097] train: loss: 0.0001637
[Epoch 51; Iter   590/ 1097] train: loss: 0.0000440
[Epoch 51; Iter   620/ 1097] train: loss: 0.0002245
[Epoch 51; Iter   650/ 1097] train: loss: 0.0042012
[Epoch 51; Iter   680/ 1097] train: loss: 0.0000346
[Epoch 51; Iter   710/ 1097] train: loss: 0.0012009
[Epoch 51; Iter   740/ 1097] train: loss: 0.0051711
[Epoch 51; Iter   770/ 1097] train: loss: 0.0120974
[Epoch 51; Iter   800/ 1097] train: loss: 0.0000484
[Epoch 51; Iter   830/ 1097] train: loss: 0.0002138
[Epoch 51; Iter   860/ 1097] train: loss: 0.0004563
[Epoch 51; Iter   890/ 1097] train: loss: 0.0000261
[Epoch 51; Iter   920/ 1097] train: loss: 0.0003174
[Epoch 51; Iter   950/ 1097] train: loss: 0.0067373
[Epoch 51; Iter   980/ 1097] train: loss: 0.0058366
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0189234
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0067826
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0088331
[Epoch 51] ogbg-molhiv: 0.621044 val loss: 15.181062
[Epoch 51] ogbg-molhiv: 0.582968 test loss: 13.967536
[Epoch 52; Iter     3/ 1097] train: loss: 0.0001862
[Epoch 52; Iter    33/ 1097] train: loss: 0.0000876
[Epoch 52; Iter    63/ 1097] train: loss: 0.0005761
[Epoch 52; Iter    93/ 1097] train: loss: 0.0001459
[Epoch 52; Iter   123/ 1097] train: loss: 0.0000557
[Epoch 52; Iter   153/ 1097] train: loss: 0.0060452
[Epoch 52; Iter   183/ 1097] train: loss: 0.0671972
[Epoch 52; Iter   213/ 1097] train: loss: 0.0026340
[Epoch 52; Iter   243/ 1097] train: loss: 0.0004769
[Epoch 52; Iter   273/ 1097] train: loss: 0.0023132
[Epoch 52; Iter   303/ 1097] train: loss: 0.0002206
[Epoch 52; Iter   333/ 1097] train: loss: 0.0008213
[Epoch 52; Iter   363/ 1097] train: loss: 0.0007323
[Epoch 52; Iter   393/ 1097] train: loss: 0.0009742
[Epoch 52; Iter   423/ 1097] train: loss: 0.0002810
[Epoch 52; Iter   453/ 1097] train: loss: 0.0016734
[Epoch 52; Iter   483/ 1097] train: loss: 0.0008492
[Epoch 52; Iter   513/ 1097] train: loss: 0.0039947
[Epoch 52; Iter   543/ 1097] train: loss: 0.0013805
[Epoch 52; Iter   573/ 1097] train: loss: 0.0116226
[Epoch 52; Iter   603/ 1097] train: loss: 0.0001647
[Epoch 52; Iter   633/ 1097] train: loss: 0.0203394
[Epoch 52; Iter   663/ 1097] train: loss: 0.0020148
[Epoch 52; Iter   693/ 1097] train: loss: 0.0875476
[Epoch 52; Iter   723/ 1097] train: loss: 0.0016174
[Epoch 52; Iter   753/ 1097] train: loss: 0.0268663
[Epoch 52; Iter   783/ 1097] train: loss: 0.0001919
[Epoch 52; Iter   813/ 1097] train: loss: 0.0008392
[Epoch 52; Iter   843/ 1097] train: loss: 0.0031946
[Epoch 52; Iter   873/ 1097] train: loss: 0.0066819
[Epoch 52; Iter   903/ 1097] train: loss: 0.0011766
[Epoch 52; Iter   933/ 1097] train: loss: 0.0005321
[Epoch 52; Iter   963/ 1097] train: loss: 0.0042587
[Epoch 52; Iter   993/ 1097] train: loss: 0.0008436
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0035908
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0012465
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0046146
[Epoch 52] ogbg-molhiv: 0.676459 val loss: 0.560684
[Epoch 52] ogbg-molhiv: 0.727865 test loss: 0.323603
[Epoch 53; Iter    16/ 1097] train: loss: 0.0015934
[Epoch 53; Iter    46/ 1097] train: loss: 0.0277128
[Epoch 53; Iter    76/ 1097] train: loss: 0.0147115
[Epoch 53; Iter   106/ 1097] train: loss: 0.0059828
[Epoch 53; Iter   136/ 1097] train: loss: 0.0009929
[Epoch 53; Iter   166/ 1097] train: loss: 0.0019290
[Epoch 53; Iter   196/ 1097] train: loss: 0.0085160
[Epoch 53; Iter   226/ 1097] train: loss: 0.0023289
[Epoch 53; Iter   256/ 1097] train: loss: 0.0009543
[Epoch 53; Iter   286/ 1097] train: loss: 0.0015469
[Epoch 53; Iter   316/ 1097] train: loss: 0.0136114
[Epoch 53; Iter   346/ 1097] train: loss: 0.0067520
[Epoch 53; Iter   376/ 1097] train: loss: 0.0004361
[Epoch 53; Iter   406/ 1097] train: loss: 0.0216217
[Epoch 53; Iter   436/ 1097] train: loss: 0.0691118
[Epoch 53; Iter   466/ 1097] train: loss: 0.0034509
[Epoch 53; Iter   496/ 1097] train: loss: 0.0081461
[Epoch 53; Iter   526/ 1097] train: loss: 0.0079526
[Epoch 53; Iter   556/ 1097] train: loss: 0.0048980
[Epoch 53; Iter   586/ 1097] train: loss: 0.0046499
[Epoch 53; Iter   616/ 1097] train: loss: 0.0010407
[Epoch 53; Iter   646/ 1097] train: loss: 0.0092985
[Epoch 53; Iter   676/ 1097] train: loss: 0.0015185
[Epoch 53; Iter   706/ 1097] train: loss: 0.0038634
[Epoch 53; Iter   736/ 1097] train: loss: 0.0014370
[Epoch 53; Iter   766/ 1097] train: loss: 0.0223678
[Epoch 53; Iter   796/ 1097] train: loss: 0.0003036
[Epoch 53; Iter   826/ 1097] train: loss: 0.0103353
[Epoch 53; Iter   856/ 1097] train: loss: 0.0012363
[Epoch 53; Iter   886/ 1097] train: loss: 0.0009326
[Epoch 53; Iter   916/ 1097] train: loss: 0.0129922
[Epoch 53; Iter   946/ 1097] train: loss: 0.0044256
[Epoch 53; Iter   976/ 1097] train: loss: 0.0015913
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0208730
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0024430
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0258537
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0008694
[Epoch 53] ogbg-molhiv: 0.694683 val loss: 0.798214
[Epoch 53] ogbg-molhiv: 0.750764 test loss: 0.370803
[Epoch 54; Iter    29/ 1097] train: loss: 0.0000962
[Epoch 54; Iter    59/ 1097] train: loss: 0.0007711
[Epoch 54; Iter    89/ 1097] train: loss: 0.0031566
[Epoch 54; Iter   119/ 1097] train: loss: 0.0011223
[Epoch 54; Iter   149/ 1097] train: loss: 0.0069379
[Epoch 54; Iter   179/ 1097] train: loss: 0.0003965
[Epoch 54; Iter   209/ 1097] train: loss: 0.0057528
[Epoch 54; Iter   239/ 1097] train: loss: 0.0023289
[Epoch 54; Iter   269/ 1097] train: loss: 0.0079361
[Epoch 54; Iter   299/ 1097] train: loss: 0.0010217
[Epoch 54; Iter   329/ 1097] train: loss: 0.0056705
[Epoch 54; Iter   359/ 1097] train: loss: 0.0435731
[Epoch 54; Iter   389/ 1097] train: loss: 0.0011682
[Epoch 54; Iter   419/ 1097] train: loss: 0.0016788
[Epoch 54; Iter   449/ 1097] train: loss: 0.0027823
[Epoch 54; Iter   479/ 1097] train: loss: 0.0013470
[Epoch 54; Iter   509/ 1097] train: loss: 0.0162650
[Epoch 54; Iter   539/ 1097] train: loss: 0.1618676
[Epoch 54; Iter   569/ 1097] train: loss: 0.0042840
[Epoch 54; Iter   599/ 1097] train: loss: 0.0009515
[Epoch 54; Iter   629/ 1097] train: loss: 0.0028000
[Epoch 54; Iter   659/ 1097] train: loss: 0.0218193
[Epoch 54; Iter   689/ 1097] train: loss: 0.0061773
[Epoch 54; Iter   719/ 1097] train: loss: 0.0007235
[Epoch 54; Iter   749/ 1097] train: loss: 0.0037518
[Epoch 54; Iter   779/ 1097] train: loss: 0.0076406
[Epoch 54; Iter   809/ 1097] train: loss: 0.0020673
[Epoch 54; Iter   839/ 1097] train: loss: 0.0033702
[Epoch 54; Iter   869/ 1097] train: loss: 0.0120998
[Epoch 54; Iter   899/ 1097] train: loss: 0.0137402
[Epoch 54; Iter   929/ 1097] train: loss: 0.0007952
[Epoch 54; Iter   959/ 1097] train: loss: 0.0011713
[Epoch 54; Iter   989/ 1097] train: loss: 0.2226964
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0013532
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0050581
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0075384
[Epoch 54] ogbg-molhiv: 0.658366 val loss: 1.260199
[Epoch 54] ogbg-molhiv: 0.742260 test loss: 0.361766
[Epoch 55; Iter    12/ 1097] train: loss: 0.0001212
[Epoch 55; Iter    42/ 1097] train: loss: 0.0008562
[Epoch 55; Iter    72/ 1097] train: loss: 0.0010952
[Epoch 55; Iter   102/ 1097] train: loss: 0.0007943
[Epoch 55; Iter   132/ 1097] train: loss: 0.0087399
[Epoch 55; Iter   162/ 1097] train: loss: 0.0018197
[Epoch 55; Iter   192/ 1097] train: loss: 0.0184250
[Epoch 55; Iter   222/ 1097] train: loss: 0.0003603
[Epoch 55; Iter   252/ 1097] train: loss: 0.0014563
[Epoch 55; Iter   282/ 1097] train: loss: 0.0013455
[Epoch 55; Iter   312/ 1097] train: loss: 0.0027169
[Epoch 55; Iter   342/ 1097] train: loss: 0.0300517
[Epoch 55; Iter   372/ 1097] train: loss: 0.0025775
[Epoch 55; Iter   402/ 1097] train: loss: 0.0003226
[Epoch 55; Iter   432/ 1097] train: loss: 0.0004121
[Epoch 55; Iter   462/ 1097] train: loss: 0.0007910
[Epoch 55; Iter   492/ 1097] train: loss: 0.0019351
[Epoch 55; Iter   522/ 1097] train: loss: 0.0144091
[Epoch 55; Iter   552/ 1097] train: loss: 0.0076802
[Epoch 55; Iter   582/ 1097] train: loss: 0.0021924
[Epoch 55; Iter   612/ 1097] train: loss: 0.0003976
[Epoch 55; Iter   642/ 1097] train: loss: 0.0010345
[Epoch 55; Iter   672/ 1097] train: loss: 0.0026655
[Epoch 55; Iter   702/ 1097] train: loss: 0.0520292
[Epoch 55; Iter   732/ 1097] train: loss: 0.0034984
[Epoch 55; Iter   762/ 1097] train: loss: 0.0030651
[Epoch 55; Iter   792/ 1097] train: loss: 0.0003583
[Epoch 55; Iter   822/ 1097] train: loss: 0.3052980
[Epoch 55; Iter   852/ 1097] train: loss: 0.0036255
[Epoch 55; Iter   882/ 1097] train: loss: 0.0079941
[Epoch 55; Iter   912/ 1097] train: loss: 0.0128751
[Epoch 55; Iter   942/ 1097] train: loss: 0.0013715
[Epoch 55; Iter   972/ 1097] train: loss: 0.0021324
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0302208
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0046479
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0135205
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0044514
[Epoch 55] ogbg-molhiv: 0.679164 val loss: 2.134360
[Epoch 55] ogbg-molhiv: 0.744800 test loss: 0.280387
[Epoch 56; Iter    25/ 1097] train: loss: 0.0009471
[Epoch 56; Iter    55/ 1097] train: loss: 0.0206064
[Epoch 56; Iter    85/ 1097] train: loss: 0.0002187
[Epoch 56; Iter   115/ 1097] train: loss: 0.0035011
[Epoch 56; Iter   145/ 1097] train: loss: 0.0003120
[Epoch 56; Iter   175/ 1097] train: loss: 0.1284807
[Epoch 56; Iter   205/ 1097] train: loss: 0.0144248
[Epoch 56; Iter   235/ 1097] train: loss: 0.1371217
[Epoch 56; Iter   265/ 1097] train: loss: 0.0018795
[Epoch 56; Iter   295/ 1097] train: loss: 0.0642101
[Epoch 56; Iter   325/ 1097] train: loss: 0.0358888
[Epoch 56; Iter   355/ 1097] train: loss: 0.0000673
[Epoch 56; Iter   385/ 1097] train: loss: 0.0037167
[Epoch 56; Iter   415/ 1097] train: loss: 0.1248652
[Epoch 56; Iter   445/ 1097] train: loss: 0.0024049
[Epoch 56; Iter   475/ 1097] train: loss: 0.0240916
[Epoch 56; Iter   505/ 1097] train: loss: 0.0007438
[Epoch 56; Iter   535/ 1097] train: loss: 0.0045860
[Epoch 56; Iter   565/ 1097] train: loss: 0.0027883
[Epoch 56; Iter   595/ 1097] train: loss: 0.1161125
[Epoch 56; Iter   625/ 1097] train: loss: 0.0002291
[Epoch 56; Iter   655/ 1097] train: loss: 0.0013270
[Epoch 56; Iter   685/ 1097] train: loss: 0.0004434
[Epoch 56; Iter   715/ 1097] train: loss: 0.0010558
[Epoch 56; Iter   745/ 1097] train: loss: 0.0003215
[Epoch 56; Iter   775/ 1097] train: loss: 0.0160580
[Epoch 56; Iter   805/ 1097] train: loss: 0.0002822
[Epoch 56; Iter   835/ 1097] train: loss: 0.0034681
[Epoch 56; Iter   865/ 1097] train: loss: 0.0165667
[Epoch 56; Iter   895/ 1097] train: loss: 0.0555280
[Epoch 56; Iter   925/ 1097] train: loss: 0.0021944
[Epoch 56; Iter   955/ 1097] train: loss: 0.0020557
[Epoch 56; Iter   985/ 1097] train: loss: 0.0271471
[Epoch 52; Iter   933/ 1097] train: loss: 0.0024362
[Epoch 52; Iter   963/ 1097] train: loss: 0.0562207
[Epoch 52; Iter   993/ 1097] train: loss: 0.0001866
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0030147
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0038755
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0166486
[Epoch 52] ogbg-molhiv: 0.749106 val loss: 0.209342
[Epoch 52] ogbg-molhiv: 0.742241 test loss: 0.249652
[Epoch 53; Iter    16/ 1097] train: loss: 0.0023370
[Epoch 53; Iter    46/ 1097] train: loss: 0.0019037
[Epoch 53; Iter    76/ 1097] train: loss: 0.0124118
[Epoch 53; Iter   106/ 1097] train: loss: 0.0005443
[Epoch 53; Iter   136/ 1097] train: loss: 0.0009833
[Epoch 53; Iter   166/ 1097] train: loss: 0.0921281
[Epoch 53; Iter   196/ 1097] train: loss: 0.0028409
[Epoch 53; Iter   226/ 1097] train: loss: 0.0010737
[Epoch 53; Iter   256/ 1097] train: loss: 0.0102407
[Epoch 53; Iter   286/ 1097] train: loss: 0.0110048
[Epoch 53; Iter   316/ 1097] train: loss: 0.0001164
[Epoch 53; Iter   346/ 1097] train: loss: 0.0030053
[Epoch 53; Iter   376/ 1097] train: loss: 0.0071515
[Epoch 53; Iter   406/ 1097] train: loss: 0.0007890
[Epoch 53; Iter   436/ 1097] train: loss: 0.0081031
[Epoch 53; Iter   466/ 1097] train: loss: 0.0065688
[Epoch 53; Iter   496/ 1097] train: loss: 0.0051467
[Epoch 53; Iter   526/ 1097] train: loss: 0.0175627
[Epoch 53; Iter   556/ 1097] train: loss: 0.0060605
[Epoch 53; Iter   586/ 1097] train: loss: 0.0367307
[Epoch 53; Iter   616/ 1097] train: loss: 0.0439130
[Epoch 53; Iter   646/ 1097] train: loss: 0.0038166
[Epoch 53; Iter   676/ 1097] train: loss: 0.0062954
[Epoch 53; Iter   706/ 1097] train: loss: 0.0217968
[Epoch 53; Iter   736/ 1097] train: loss: 0.0057109
[Epoch 53; Iter   766/ 1097] train: loss: 0.0292737
[Epoch 53; Iter   796/ 1097] train: loss: 0.0010511
[Epoch 53; Iter   826/ 1097] train: loss: 0.0391414
[Epoch 53; Iter   856/ 1097] train: loss: 0.0145891
[Epoch 53; Iter   886/ 1097] train: loss: 0.0025627
[Epoch 53; Iter   916/ 1097] train: loss: 0.0004277
[Epoch 53; Iter   946/ 1097] train: loss: 0.0238898
[Epoch 53; Iter   976/ 1097] train: loss: 0.0022977
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0207656
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0019370
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0021626
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0017658
[Epoch 53] ogbg-molhiv: 0.768604 val loss: 0.244702
[Epoch 53] ogbg-molhiv: 0.777273 test loss: 0.254588
[Epoch 54; Iter    29/ 1097] train: loss: 0.0057674
[Epoch 54; Iter    59/ 1097] train: loss: 0.0053546
[Epoch 54; Iter    89/ 1097] train: loss: 0.0016479
[Epoch 54; Iter   119/ 1097] train: loss: 0.0032804
[Epoch 54; Iter   149/ 1097] train: loss: 0.0042510
[Epoch 54; Iter   179/ 1097] train: loss: 0.0017797
[Epoch 54; Iter   209/ 1097] train: loss: 0.0159816
[Epoch 54; Iter   239/ 1097] train: loss: 0.0011909
[Epoch 54; Iter   269/ 1097] train: loss: 0.0014179
[Epoch 54; Iter   299/ 1097] train: loss: 0.0017255
[Epoch 54; Iter   329/ 1097] train: loss: 0.1139520
[Epoch 54; Iter   359/ 1097] train: loss: 0.0021092
[Epoch 54; Iter   389/ 1097] train: loss: 0.0039196
[Epoch 54; Iter   419/ 1097] train: loss: 0.0013581
[Epoch 54; Iter   449/ 1097] train: loss: 0.0014215
[Epoch 54; Iter   479/ 1097] train: loss: 0.0069596
[Epoch 54; Iter   509/ 1097] train: loss: 0.0002645
[Epoch 54; Iter   539/ 1097] train: loss: 0.0011801
[Epoch 54; Iter   569/ 1097] train: loss: 0.0001091
[Epoch 54; Iter   599/ 1097] train: loss: 0.0006805
[Epoch 54; Iter   629/ 1097] train: loss: 0.0059607
[Epoch 54; Iter   659/ 1097] train: loss: 0.0015054
[Epoch 54; Iter   689/ 1097] train: loss: 0.0009340
[Epoch 54; Iter   719/ 1097] train: loss: 0.0007725
[Epoch 54; Iter   749/ 1097] train: loss: 0.0020285
[Epoch 54; Iter   779/ 1097] train: loss: 0.0086458
[Epoch 54; Iter   809/ 1097] train: loss: 0.0075019
[Epoch 54; Iter   839/ 1097] train: loss: 0.0023774
[Epoch 54; Iter   869/ 1097] train: loss: 0.0193660
[Epoch 54; Iter   899/ 1097] train: loss: 0.0019927
[Epoch 54; Iter   929/ 1097] train: loss: 0.0017475
[Epoch 54; Iter   959/ 1097] train: loss: 0.0036386
[Epoch 54; Iter   989/ 1097] train: loss: 0.0013971
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0478850
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0062726
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0015153
[Epoch 54] ogbg-molhiv: 0.774238 val loss: 0.304789
[Epoch 54] ogbg-molhiv: 0.737419 test loss: 0.256079
[Epoch 55; Iter    12/ 1097] train: loss: 0.0010650
[Epoch 55; Iter    42/ 1097] train: loss: 0.0106013
[Epoch 55; Iter    72/ 1097] train: loss: 0.0081057
[Epoch 55; Iter   102/ 1097] train: loss: 0.0008716
[Epoch 55; Iter   132/ 1097] train: loss: 0.0062515
[Epoch 55; Iter   162/ 1097] train: loss: 0.0002034
[Epoch 55; Iter   192/ 1097] train: loss: 0.0055641
[Epoch 55; Iter   222/ 1097] train: loss: 0.0004702
[Epoch 55; Iter   252/ 1097] train: loss: 0.0059519
[Epoch 55; Iter   282/ 1097] train: loss: 0.0005977
[Epoch 55; Iter   312/ 1097] train: loss: 0.0230309
[Epoch 55; Iter   342/ 1097] train: loss: 0.0005652
[Epoch 55; Iter   372/ 1097] train: loss: 0.0041204
[Epoch 55; Iter   402/ 1097] train: loss: 0.0202582
[Epoch 55; Iter   432/ 1097] train: loss: 0.0008852
[Epoch 55; Iter   462/ 1097] train: loss: 0.0031347
[Epoch 55; Iter   492/ 1097] train: loss: 0.0013687
[Epoch 55; Iter   522/ 1097] train: loss: 0.0023342
[Epoch 55; Iter   552/ 1097] train: loss: 0.0046966
[Epoch 55; Iter   582/ 1097] train: loss: 0.0061821
[Epoch 55; Iter   612/ 1097] train: loss: 0.0043251
[Epoch 55; Iter   642/ 1097] train: loss: 0.0007185
[Epoch 55; Iter   672/ 1097] train: loss: 0.0006369
[Epoch 55; Iter   702/ 1097] train: loss: 0.0013345
[Epoch 55; Iter   732/ 1097] train: loss: 0.0080909
[Epoch 55; Iter   762/ 1097] train: loss: 0.0069012
[Epoch 55; Iter   792/ 1097] train: loss: 0.0228698
[Epoch 55; Iter   822/ 1097] train: loss: 0.0552619
[Epoch 55; Iter   852/ 1097] train: loss: 0.0004545
[Epoch 55; Iter   882/ 1097] train: loss: 0.0003557
[Epoch 55; Iter   912/ 1097] train: loss: 0.0005673
[Epoch 55; Iter   942/ 1097] train: loss: 0.0015696
[Epoch 55; Iter   972/ 1097] train: loss: 0.0001038
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0001297
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006592
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0296888
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0053479
[Epoch 55] ogbg-molhiv: 0.778822 val loss: 0.271247
[Epoch 55] ogbg-molhiv: 0.762896 test loss: 0.256592
[Epoch 56; Iter    25/ 1097] train: loss: 0.0003449
[Epoch 56; Iter    55/ 1097] train: loss: 0.0017012
[Epoch 56; Iter    85/ 1097] train: loss: 0.0202840
[Epoch 56; Iter   115/ 1097] train: loss: 0.0016871
[Epoch 56; Iter   145/ 1097] train: loss: 0.0015505
[Epoch 56; Iter   175/ 1097] train: loss: 0.0101462
[Epoch 56; Iter   205/ 1097] train: loss: 0.0065760
[Epoch 56; Iter   235/ 1097] train: loss: 0.0028767
[Epoch 56; Iter   265/ 1097] train: loss: 0.0002173
[Epoch 56; Iter   295/ 1097] train: loss: 0.0009863
[Epoch 56; Iter   325/ 1097] train: loss: 0.0232468
[Epoch 56; Iter   355/ 1097] train: loss: 0.0014110
[Epoch 56; Iter   385/ 1097] train: loss: 0.0005038
[Epoch 56; Iter   415/ 1097] train: loss: 0.0002170
[Epoch 56; Iter   445/ 1097] train: loss: 0.0028499
[Epoch 56; Iter   475/ 1097] train: loss: 0.0000468
[Epoch 56; Iter   505/ 1097] train: loss: 0.0035380
[Epoch 56; Iter   535/ 1097] train: loss: 0.0318993
[Epoch 56; Iter   565/ 1097] train: loss: 0.0022759
[Epoch 56; Iter   595/ 1097] train: loss: 0.0746477
[Epoch 56; Iter   625/ 1097] train: loss: 0.0012083
[Epoch 56; Iter   655/ 1097] train: loss: 0.0011862
[Epoch 56; Iter   685/ 1097] train: loss: 0.0001909
[Epoch 56; Iter   715/ 1097] train: loss: 0.0005073
[Epoch 56; Iter   745/ 1097] train: loss: 0.0018626
[Epoch 56; Iter   775/ 1097] train: loss: 0.0230850
[Epoch 56; Iter   805/ 1097] train: loss: 0.0012106
[Epoch 56; Iter   835/ 1097] train: loss: 0.0116212
[Epoch 56; Iter   865/ 1097] train: loss: 0.0003283
[Epoch 56; Iter   895/ 1097] train: loss: 0.0424498
[Epoch 56; Iter   925/ 1097] train: loss: 0.0011283
[Epoch 56; Iter   955/ 1097] train: loss: 0.0039321
[Epoch 56; Iter   985/ 1097] train: loss: 0.0001265
[Epoch 52; Iter   933/ 1097] train: loss: 0.0094210
[Epoch 52; Iter   963/ 1097] train: loss: 0.0070725
[Epoch 52; Iter   993/ 1097] train: loss: 0.0060658
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0061862
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0007979
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0015376
[Epoch 52] ogbg-molhiv: 0.723689 val loss: 1.063734
[Epoch 52] ogbg-molhiv: 0.705989 test loss: 0.410674
[Epoch 53; Iter    16/ 1097] train: loss: 0.0004561
[Epoch 53; Iter    46/ 1097] train: loss: 0.0029960
[Epoch 53; Iter    76/ 1097] train: loss: 0.0055681
[Epoch 53; Iter   106/ 1097] train: loss: 0.0025457
[Epoch 53; Iter   136/ 1097] train: loss: 0.0088126
[Epoch 53; Iter   166/ 1097] train: loss: 0.0009927
[Epoch 53; Iter   196/ 1097] train: loss: 0.0080942
[Epoch 53; Iter   226/ 1097] train: loss: 0.0009383
[Epoch 53; Iter   256/ 1097] train: loss: 0.0007011
[Epoch 53; Iter   286/ 1097] train: loss: 0.0010293
[Epoch 53; Iter   316/ 1097] train: loss: 0.0007205
[Epoch 53; Iter   346/ 1097] train: loss: 0.0154837
[Epoch 53; Iter   376/ 1097] train: loss: 0.2307954
[Epoch 53; Iter   406/ 1097] train: loss: 0.1257301
[Epoch 53; Iter   436/ 1097] train: loss: 0.0350522
[Epoch 53; Iter   466/ 1097] train: loss: 0.0317223
[Epoch 53; Iter   496/ 1097] train: loss: 0.0103823
[Epoch 53; Iter   526/ 1097] train: loss: 0.0026018
[Epoch 53; Iter   556/ 1097] train: loss: 0.0128127
[Epoch 53; Iter   586/ 1097] train: loss: 0.0039061
[Epoch 53; Iter   616/ 1097] train: loss: 0.0059126
[Epoch 53; Iter   646/ 1097] train: loss: 0.1163705
[Epoch 53; Iter   676/ 1097] train: loss: 0.0437209
[Epoch 53; Iter   706/ 1097] train: loss: 0.0375542
[Epoch 53; Iter   736/ 1097] train: loss: 0.0042812
[Epoch 53; Iter   766/ 1097] train: loss: 0.0101761
[Epoch 53; Iter   796/ 1097] train: loss: 0.0170316
[Epoch 53; Iter   826/ 1097] train: loss: 0.0009226
[Epoch 53; Iter   856/ 1097] train: loss: 0.0043704
[Epoch 53; Iter   886/ 1097] train: loss: 0.0033434
[Epoch 53; Iter   916/ 1097] train: loss: 0.0304342
[Epoch 53; Iter   946/ 1097] train: loss: 0.0255320
[Epoch 53; Iter   976/ 1097] train: loss: 0.0013631
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0349512
[Epoch 53; Iter  1036/ 1097] train: loss: 0.1526782
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0042522
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0277171
[Epoch 53] ogbg-molhiv: 0.720893 val loss: 2.858687
[Epoch 53] ogbg-molhiv: 0.731646 test loss: 1.165511
[Epoch 54; Iter    29/ 1097] train: loss: 0.0261840
[Epoch 54; Iter    59/ 1097] train: loss: 0.0045184
[Epoch 54; Iter    89/ 1097] train: loss: 0.0024655
[Epoch 54; Iter   119/ 1097] train: loss: 0.0027890
[Epoch 54; Iter   149/ 1097] train: loss: 0.0007222
[Epoch 54; Iter   179/ 1097] train: loss: 0.0601393
[Epoch 54; Iter   209/ 1097] train: loss: 0.0131666
[Epoch 54; Iter   239/ 1097] train: loss: 0.0451331
[Epoch 54; Iter   269/ 1097] train: loss: 0.0029134
[Epoch 54; Iter   299/ 1097] train: loss: 0.0016871
[Epoch 54; Iter   329/ 1097] train: loss: 0.0021904
[Epoch 54; Iter   359/ 1097] train: loss: 0.0018752
[Epoch 54; Iter   389/ 1097] train: loss: 0.0096499
[Epoch 54; Iter   419/ 1097] train: loss: 0.0009702
[Epoch 54; Iter   449/ 1097] train: loss: 0.0008577
[Epoch 54; Iter   479/ 1097] train: loss: 0.0023490
[Epoch 54; Iter   509/ 1097] train: loss: 0.0364784
[Epoch 54; Iter   539/ 1097] train: loss: 0.0007421
[Epoch 54; Iter   569/ 1097] train: loss: 0.0087387
[Epoch 54; Iter   599/ 1097] train: loss: 0.0039828
[Epoch 54; Iter   629/ 1097] train: loss: 0.0135230
[Epoch 54; Iter   659/ 1097] train: loss: 0.0350145
[Epoch 54; Iter   689/ 1097] train: loss: 0.0006298
[Epoch 54; Iter   719/ 1097] train: loss: 0.0210069
[Epoch 54; Iter   749/ 1097] train: loss: 0.0099990
[Epoch 54; Iter   779/ 1097] train: loss: 0.0191053
[Epoch 54; Iter   809/ 1097] train: loss: 0.0053603
[Epoch 54; Iter   839/ 1097] train: loss: 0.1923078
[Epoch 54; Iter   869/ 1097] train: loss: 0.0018728
[Epoch 54; Iter   899/ 1097] train: loss: 0.0089489
[Epoch 54; Iter   929/ 1097] train: loss: 0.0024598
[Epoch 54; Iter   959/ 1097] train: loss: 0.0021353
[Epoch 54; Iter   989/ 1097] train: loss: 0.0016534
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0020836
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0116950
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0007503
[Epoch 54] ogbg-molhiv: 0.723514 val loss: 1.762074
[Epoch 54] ogbg-molhiv: 0.706418 test loss: 1.296844
[Epoch 55; Iter    12/ 1097] train: loss: 0.0014054
[Epoch 55; Iter    42/ 1097] train: loss: 0.0055521
[Epoch 55; Iter    72/ 1097] train: loss: 0.0001372
[Epoch 55; Iter   102/ 1097] train: loss: 0.0107604
[Epoch 55; Iter   132/ 1097] train: loss: 0.0376004
[Epoch 55; Iter   162/ 1097] train: loss: 0.0096470
[Epoch 55; Iter   192/ 1097] train: loss: 0.0011923
[Epoch 55; Iter   222/ 1097] train: loss: 0.0004220
[Epoch 55; Iter   252/ 1097] train: loss: 0.0044495
[Epoch 55; Iter   282/ 1097] train: loss: 0.0036433
[Epoch 55; Iter   312/ 1097] train: loss: 0.0017362
[Epoch 55; Iter   342/ 1097] train: loss: 0.0050372
[Epoch 55; Iter   372/ 1097] train: loss: 0.0015946
[Epoch 55; Iter   402/ 1097] train: loss: 0.0449230
[Epoch 55; Iter   432/ 1097] train: loss: 0.0058399
[Epoch 55; Iter   462/ 1097] train: loss: 0.0026377
[Epoch 55; Iter   492/ 1097] train: loss: 0.0084590
[Epoch 55; Iter   522/ 1097] train: loss: 0.0094025
[Epoch 55; Iter   552/ 1097] train: loss: 0.0237502
[Epoch 55; Iter   582/ 1097] train: loss: 0.0444272
[Epoch 55; Iter   612/ 1097] train: loss: 0.0170745
[Epoch 55; Iter   642/ 1097] train: loss: 0.0030346
[Epoch 55; Iter   672/ 1097] train: loss: 0.0096223
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010966
[Epoch 55; Iter   732/ 1097] train: loss: 0.0043541
[Epoch 55; Iter   762/ 1097] train: loss: 0.0049552
[Epoch 55; Iter   792/ 1097] train: loss: 0.0015373
[Epoch 55; Iter   822/ 1097] train: loss: 0.0348820
[Epoch 55; Iter   852/ 1097] train: loss: 0.0106475
[Epoch 55; Iter   882/ 1097] train: loss: 0.0036667
[Epoch 55; Iter   912/ 1097] train: loss: 0.0026124
[Epoch 55; Iter   942/ 1097] train: loss: 0.1249733
[Epoch 55; Iter   972/ 1097] train: loss: 0.0019575
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0771806
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0059437
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0173424
[Epoch 55; Iter  1092/ 1097] train: loss: 0.1014355
[Epoch 55] ogbg-molhiv: 0.704959 val loss: 1.239899
[Epoch 55] ogbg-molhiv: 0.742803 test loss: 0.689120
[Epoch 56; Iter    25/ 1097] train: loss: 0.0070492
[Epoch 56; Iter    55/ 1097] train: loss: 0.0038986
[Epoch 56; Iter    85/ 1097] train: loss: 0.0214379
[Epoch 56; Iter   115/ 1097] train: loss: 0.0325388
[Epoch 56; Iter   145/ 1097] train: loss: 0.0216142
[Epoch 56; Iter   175/ 1097] train: loss: 0.0741169
[Epoch 56; Iter   205/ 1097] train: loss: 0.1226633
[Epoch 56; Iter   235/ 1097] train: loss: 0.0028566
[Epoch 56; Iter   265/ 1097] train: loss: 0.0066672
[Epoch 56; Iter   295/ 1097] train: loss: 0.0062563
[Epoch 56; Iter   325/ 1097] train: loss: 0.0046778
[Epoch 56; Iter   355/ 1097] train: loss: 0.0029834
[Epoch 56; Iter   385/ 1097] train: loss: 0.0204742
[Epoch 56; Iter   415/ 1097] train: loss: 0.0273554
[Epoch 56; Iter   445/ 1097] train: loss: 0.0053890
[Epoch 56; Iter   475/ 1097] train: loss: 0.0011631
[Epoch 56; Iter   505/ 1097] train: loss: 0.0975030
[Epoch 56; Iter   535/ 1097] train: loss: 0.0272756
[Epoch 56; Iter   565/ 1097] train: loss: 0.0051189
[Epoch 56; Iter   595/ 1097] train: loss: 0.1213103
[Epoch 56; Iter   625/ 1097] train: loss: 0.0010577
[Epoch 56; Iter   655/ 1097] train: loss: 0.1234062
[Epoch 56; Iter   685/ 1097] train: loss: 0.0019581
[Epoch 56; Iter   715/ 1097] train: loss: 0.0057028
[Epoch 56; Iter   745/ 1097] train: loss: 0.0007401
[Epoch 56; Iter   775/ 1097] train: loss: 0.0071087
[Epoch 56; Iter   805/ 1097] train: loss: 0.0017323
[Epoch 56; Iter   835/ 1097] train: loss: 0.0019094
[Epoch 56; Iter   865/ 1097] train: loss: 0.0392750
[Epoch 56; Iter   895/ 1097] train: loss: 0.0550180
[Epoch 56; Iter   925/ 1097] train: loss: 0.0066529
[Epoch 56; Iter   955/ 1097] train: loss: 0.0010132
[Epoch 56; Iter   985/ 1097] train: loss: 0.0689153
[Epoch 52; Iter   933/ 1097] train: loss: 0.0006375
[Epoch 52; Iter   963/ 1097] train: loss: 0.0004579
[Epoch 52; Iter   993/ 1097] train: loss: 0.0004854
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0065521
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0011773
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0004311
[Epoch 52] ogbg-molhiv: 0.793375 val loss: 0.266469
[Epoch 52] ogbg-molhiv: 0.723123 test loss: 0.514352
[Epoch 53; Iter    16/ 1097] train: loss: 0.0049701
[Epoch 53; Iter    46/ 1097] train: loss: 0.0026256
[Epoch 53; Iter    76/ 1097] train: loss: 0.0056516
[Epoch 53; Iter   106/ 1097] train: loss: 0.0003363
[Epoch 53; Iter   136/ 1097] train: loss: 0.0010864
[Epoch 53; Iter   166/ 1097] train: loss: 0.1838544
[Epoch 53; Iter   196/ 1097] train: loss: 0.0111920
[Epoch 53; Iter   226/ 1097] train: loss: 0.0006658
[Epoch 53; Iter   256/ 1097] train: loss: 0.0023726
[Epoch 53; Iter   286/ 1097] train: loss: 0.0201318
[Epoch 53; Iter   316/ 1097] train: loss: 0.0031318
[Epoch 53; Iter   346/ 1097] train: loss: 0.0214386
[Epoch 53; Iter   376/ 1097] train: loss: 0.0026725
[Epoch 53; Iter   406/ 1097] train: loss: 0.0016993
[Epoch 53; Iter   436/ 1097] train: loss: 0.0732833
[Epoch 53; Iter   466/ 1097] train: loss: 0.0158980
[Epoch 53; Iter   496/ 1097] train: loss: 0.0244232
[Epoch 53; Iter   526/ 1097] train: loss: 0.0003656
[Epoch 53; Iter   556/ 1097] train: loss: 0.0009938
[Epoch 53; Iter   586/ 1097] train: loss: 0.1050127
[Epoch 53; Iter   616/ 1097] train: loss: 0.0002132
[Epoch 53; Iter   646/ 1097] train: loss: 0.0026796
[Epoch 53; Iter   676/ 1097] train: loss: 0.0004244
[Epoch 53; Iter   706/ 1097] train: loss: 0.1070691
[Epoch 53; Iter   736/ 1097] train: loss: 0.0076830
[Epoch 53; Iter   766/ 1097] train: loss: 0.0707520
[Epoch 53; Iter   796/ 1097] train: loss: 0.0023904
[Epoch 53; Iter   826/ 1097] train: loss: 0.0063690
[Epoch 53; Iter   856/ 1097] train: loss: 0.0160562
[Epoch 53; Iter   886/ 1097] train: loss: 0.0020888
[Epoch 53; Iter   916/ 1097] train: loss: 0.0019496
[Epoch 53; Iter   946/ 1097] train: loss: 0.0277335
[Epoch 53; Iter   976/ 1097] train: loss: 0.0004020
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0016981
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0008337
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0392847
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0243472
[Epoch 53] ogbg-molhiv: 0.786783 val loss: 0.256581
[Epoch 53] ogbg-molhiv: 0.722349 test loss: 0.511713
[Epoch 54; Iter    29/ 1097] train: loss: 0.0093253
[Epoch 54; Iter    59/ 1097] train: loss: 0.0082411
[Epoch 54; Iter    89/ 1097] train: loss: 0.0082798
[Epoch 54; Iter   119/ 1097] train: loss: 0.0025697
[Epoch 54; Iter   149/ 1097] train: loss: 0.0021209
[Epoch 54; Iter   179/ 1097] train: loss: 0.0073624
[Epoch 54; Iter   209/ 1097] train: loss: 0.0010480
[Epoch 54; Iter   239/ 1097] train: loss: 0.0026706
[Epoch 54; Iter   269/ 1097] train: loss: 0.0004132
[Epoch 54; Iter   299/ 1097] train: loss: 0.0002984
[Epoch 54; Iter   329/ 1097] train: loss: 0.0093798
[Epoch 54; Iter   359/ 1097] train: loss: 0.0022345
[Epoch 54; Iter   389/ 1097] train: loss: 0.0013348
[Epoch 54; Iter   419/ 1097] train: loss: 0.0160656
[Epoch 54; Iter   449/ 1097] train: loss: 0.0009454
[Epoch 54; Iter   479/ 1097] train: loss: 0.0146518
[Epoch 54; Iter   509/ 1097] train: loss: 0.0000871
[Epoch 54; Iter   539/ 1097] train: loss: 0.0262306
[Epoch 54; Iter   569/ 1097] train: loss: 0.0011309
[Epoch 54; Iter   599/ 1097] train: loss: 0.0144212
[Epoch 54; Iter   629/ 1097] train: loss: 0.0003058
[Epoch 54; Iter   659/ 1097] train: loss: 0.0027065
[Epoch 54; Iter   689/ 1097] train: loss: 0.0003603
[Epoch 54; Iter   719/ 1097] train: loss: 0.0010835
[Epoch 54; Iter   749/ 1097] train: loss: 0.0792133
[Epoch 54; Iter   779/ 1097] train: loss: 0.0376060
[Epoch 54; Iter   809/ 1097] train: loss: 0.0308225
[Epoch 54; Iter   839/ 1097] train: loss: 0.0056571
[Epoch 54; Iter   869/ 1097] train: loss: 0.0014144
[Epoch 54; Iter   899/ 1097] train: loss: 0.0005867
[Epoch 54; Iter   929/ 1097] train: loss: 0.0697191
[Epoch 54; Iter   959/ 1097] train: loss: 0.0014145
[Epoch 54; Iter   989/ 1097] train: loss: 0.0015050
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0089157
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0669540
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0004524
[Epoch 54] ogbg-molhiv: 0.779652 val loss: 0.299653
[Epoch 54] ogbg-molhiv: 0.689310 test loss: 0.372093
[Epoch 55; Iter    12/ 1097] train: loss: 0.0000984
[Epoch 55; Iter    42/ 1097] train: loss: 0.0002126
[Epoch 55; Iter    72/ 1097] train: loss: 0.0052038
[Epoch 55; Iter   102/ 1097] train: loss: 0.0011951
[Epoch 55; Iter   132/ 1097] train: loss: 0.0959857
[Epoch 55; Iter   162/ 1097] train: loss: 0.0649079
[Epoch 55; Iter   192/ 1097] train: loss: 0.0386491
[Epoch 55; Iter   222/ 1097] train: loss: 0.0007796
[Epoch 55; Iter   252/ 1097] train: loss: 0.0015080
[Epoch 55; Iter   282/ 1097] train: loss: 0.0495066
[Epoch 55; Iter   312/ 1097] train: loss: 0.0231787
[Epoch 55; Iter   342/ 1097] train: loss: 0.0010309
[Epoch 55; Iter   372/ 1097] train: loss: 0.0034530
[Epoch 55; Iter   402/ 1097] train: loss: 0.0282595
[Epoch 55; Iter   432/ 1097] train: loss: 0.0007857
[Epoch 55; Iter   462/ 1097] train: loss: 0.0057576
[Epoch 55; Iter   492/ 1097] train: loss: 0.0010669
[Epoch 55; Iter   522/ 1097] train: loss: 0.0800724
[Epoch 55; Iter   552/ 1097] train: loss: 0.0004935
[Epoch 55; Iter   582/ 1097] train: loss: 0.0004911
[Epoch 55; Iter   612/ 1097] train: loss: 0.0006768
[Epoch 55; Iter   642/ 1097] train: loss: 0.0012232
[Epoch 55; Iter   672/ 1097] train: loss: 0.0032382
[Epoch 55; Iter   702/ 1097] train: loss: 0.0026872
[Epoch 55; Iter   732/ 1097] train: loss: 0.0033011
[Epoch 55; Iter   762/ 1097] train: loss: 0.0052298
[Epoch 55; Iter   792/ 1097] train: loss: 0.0328434
[Epoch 55; Iter   822/ 1097] train: loss: 0.0057249
[Epoch 55; Iter   852/ 1097] train: loss: 0.0052405
[Epoch 55; Iter   882/ 1097] train: loss: 0.0002074
[Epoch 55; Iter   912/ 1097] train: loss: 0.0004451
[Epoch 55; Iter   942/ 1097] train: loss: 0.0201275
[Epoch 55; Iter   972/ 1097] train: loss: 0.0007684
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0030790
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006244
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0059307
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0011623
[Epoch 55] ogbg-molhiv: 0.787472 val loss: 0.174835
[Epoch 55] ogbg-molhiv: 0.723929 test loss: 0.284910
[Epoch 56; Iter    25/ 1097] train: loss: 0.0020790
[Epoch 56; Iter    55/ 1097] train: loss: 0.0001671
[Epoch 56; Iter    85/ 1097] train: loss: 0.0003906
[Epoch 56; Iter   115/ 1097] train: loss: 0.0001726
[Epoch 56; Iter   145/ 1097] train: loss: 0.0011200
[Epoch 56; Iter   175/ 1097] train: loss: 0.0015463
[Epoch 56; Iter   205/ 1097] train: loss: 0.0021576
[Epoch 56; Iter   235/ 1097] train: loss: 0.0006090
[Epoch 56; Iter   265/ 1097] train: loss: 0.0001436
[Epoch 56; Iter   295/ 1097] train: loss: 0.0004655
[Epoch 56; Iter   325/ 1097] train: loss: 0.0012615
[Epoch 56; Iter   355/ 1097] train: loss: 0.0005070
[Epoch 56; Iter   385/ 1097] train: loss: 0.0016046
[Epoch 56; Iter   415/ 1097] train: loss: 0.0075734
[Epoch 56; Iter   445/ 1097] train: loss: 0.0034935
[Epoch 56; Iter   475/ 1097] train: loss: 0.0007263
[Epoch 56; Iter   505/ 1097] train: loss: 0.0034982
[Epoch 56; Iter   535/ 1097] train: loss: 0.0008515
[Epoch 56; Iter   565/ 1097] train: loss: 0.0058823
[Epoch 56; Iter   595/ 1097] train: loss: 0.0042446
[Epoch 56; Iter   625/ 1097] train: loss: 0.0067577
[Epoch 56; Iter   655/ 1097] train: loss: 0.0005455
[Epoch 56; Iter   685/ 1097] train: loss: 0.0018052
[Epoch 56; Iter   715/ 1097] train: loss: 0.0091072
[Epoch 56; Iter   745/ 1097] train: loss: 0.0015978
[Epoch 56; Iter   775/ 1097] train: loss: 0.0175060
[Epoch 56; Iter   805/ 1097] train: loss: 0.0005394
[Epoch 56; Iter   835/ 1097] train: loss: 0.0008436
[Epoch 56; Iter   865/ 1097] train: loss: 0.0206987
[Epoch 56; Iter   895/ 1097] train: loss: 0.0011992
[Epoch 56; Iter   925/ 1097] train: loss: 0.0030069
[Epoch 56; Iter   955/ 1097] train: loss: 0.0010871
[Epoch 56; Iter   985/ 1097] train: loss: 0.0004671
[Epoch 52; Iter   933/ 1097] train: loss: 0.0015634
[Epoch 52; Iter   963/ 1097] train: loss: 0.0289703
[Epoch 52; Iter   993/ 1097] train: loss: 0.0012196
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0004958
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0047807
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0020922
[Epoch 52] ogbg-molhiv: 0.769673 val loss: 0.176208
[Epoch 52] ogbg-molhiv: 0.714763 test loss: 0.288069
[Epoch 53; Iter    16/ 1097] train: loss: 0.0001943
[Epoch 53; Iter    46/ 1097] train: loss: 0.0286732
[Epoch 53; Iter    76/ 1097] train: loss: 0.0001411
[Epoch 53; Iter   106/ 1097] train: loss: 0.0022504
[Epoch 53; Iter   136/ 1097] train: loss: 0.0005515
[Epoch 53; Iter   166/ 1097] train: loss: 0.0028707
[Epoch 53; Iter   196/ 1097] train: loss: 0.0006496
[Epoch 53; Iter   226/ 1097] train: loss: 0.0002089
[Epoch 53; Iter   256/ 1097] train: loss: 0.0008962
[Epoch 53; Iter   286/ 1097] train: loss: 0.0012369
[Epoch 53; Iter   316/ 1097] train: loss: 0.0005774
[Epoch 53; Iter   346/ 1097] train: loss: 0.0016516
[Epoch 53; Iter   376/ 1097] train: loss: 0.0009192
[Epoch 53; Iter   406/ 1097] train: loss: 0.0007779
[Epoch 53; Iter   436/ 1097] train: loss: 0.0039813
[Epoch 53; Iter   466/ 1097] train: loss: 0.0640969
[Epoch 53; Iter   496/ 1097] train: loss: 0.0008816
[Epoch 53; Iter   526/ 1097] train: loss: 0.1057352
[Epoch 53; Iter   556/ 1097] train: loss: 0.0049190
[Epoch 53; Iter   586/ 1097] train: loss: 0.0008117
[Epoch 53; Iter   616/ 1097] train: loss: 0.0007240
[Epoch 53; Iter   646/ 1097] train: loss: 0.0515315
[Epoch 53; Iter   676/ 1097] train: loss: 0.0218057
[Epoch 53; Iter   706/ 1097] train: loss: 0.0023673
[Epoch 53; Iter   736/ 1097] train: loss: 0.0011561
[Epoch 53; Iter   766/ 1097] train: loss: 0.0086710
[Epoch 53; Iter   796/ 1097] train: loss: 0.0225616
[Epoch 53; Iter   826/ 1097] train: loss: 0.0084014
[Epoch 53; Iter   856/ 1097] train: loss: 0.0125711
[Epoch 53; Iter   886/ 1097] train: loss: 0.0013667
[Epoch 53; Iter   916/ 1097] train: loss: 0.0332931
[Epoch 53; Iter   946/ 1097] train: loss: 0.0025011
[Epoch 53; Iter   976/ 1097] train: loss: 0.0033779
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0003153
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0800719
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0003992
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0561489
[Epoch 53] ogbg-molhiv: 0.764014 val loss: 0.190485
[Epoch 53] ogbg-molhiv: 0.749493 test loss: 0.293656
[Epoch 54; Iter    29/ 1097] train: loss: 0.0024947
[Epoch 54; Iter    59/ 1097] train: loss: 0.0071424
[Epoch 54; Iter    89/ 1097] train: loss: 0.0015860
[Epoch 54; Iter   119/ 1097] train: loss: 0.0094219
[Epoch 54; Iter   149/ 1097] train: loss: 0.0286533
[Epoch 54; Iter   179/ 1097] train: loss: 0.0004300
[Epoch 54; Iter   209/ 1097] train: loss: 0.0002060
[Epoch 54; Iter   239/ 1097] train: loss: 0.0105096
[Epoch 54; Iter   269/ 1097] train: loss: 0.0021572
[Epoch 54; Iter   299/ 1097] train: loss: 0.0001096
[Epoch 54; Iter   329/ 1097] train: loss: 0.0065776
[Epoch 54; Iter   359/ 1097] train: loss: 0.0028813
[Epoch 54; Iter   389/ 1097] train: loss: 0.0002475
[Epoch 54; Iter   419/ 1097] train: loss: 0.0000370
[Epoch 54; Iter   449/ 1097] train: loss: 0.0001535
[Epoch 54; Iter   479/ 1097] train: loss: 0.0066076
[Epoch 54; Iter   509/ 1097] train: loss: 0.0010027
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003603
[Epoch 54; Iter   569/ 1097] train: loss: 0.0008222
[Epoch 54; Iter   599/ 1097] train: loss: 0.0677770
[Epoch 54; Iter   629/ 1097] train: loss: 0.0041506
[Epoch 54; Iter   659/ 1097] train: loss: 0.0002349
[Epoch 54; Iter   689/ 1097] train: loss: 0.0003115
[Epoch 54; Iter   719/ 1097] train: loss: 0.0015540
[Epoch 54; Iter   749/ 1097] train: loss: 0.0124521
[Epoch 54; Iter   779/ 1097] train: loss: 0.0001123
[Epoch 54; Iter   809/ 1097] train: loss: 0.0033854
[Epoch 54; Iter   839/ 1097] train: loss: 0.0068595
[Epoch 54; Iter   869/ 1097] train: loss: 0.0009779
[Epoch 54; Iter   899/ 1097] train: loss: 0.0149395
[Epoch 54; Iter   929/ 1097] train: loss: 0.0009884
[Epoch 54; Iter   959/ 1097] train: loss: 0.0003477
[Epoch 54; Iter   989/ 1097] train: loss: 0.0007684
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0001690
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0046837
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0021983
[Epoch 54] ogbg-molhiv: 0.778810 val loss: 0.171470
[Epoch 54] ogbg-molhiv: 0.706541 test loss: 0.297502
[Epoch 55; Iter    12/ 1097] train: loss: 0.0049411
[Epoch 55; Iter    42/ 1097] train: loss: 0.0053384
[Epoch 55; Iter    72/ 1097] train: loss: 0.0018461
[Epoch 55; Iter   102/ 1097] train: loss: 0.0080379
[Epoch 55; Iter   132/ 1097] train: loss: 0.0350705
[Epoch 55; Iter   162/ 1097] train: loss: 0.0003802
[Epoch 55; Iter   192/ 1097] train: loss: 0.0003104
[Epoch 55; Iter   222/ 1097] train: loss: 0.0002386
[Epoch 55; Iter   252/ 1097] train: loss: 0.0001367
[Epoch 55; Iter   282/ 1097] train: loss: 0.0010998
[Epoch 55; Iter   312/ 1097] train: loss: 0.0002271
[Epoch 55; Iter   342/ 1097] train: loss: 0.0027326
[Epoch 55; Iter   372/ 1097] train: loss: 0.0024930
[Epoch 55; Iter   402/ 1097] train: loss: 0.0006037
[Epoch 55; Iter   432/ 1097] train: loss: 0.0245377
[Epoch 55; Iter   462/ 1097] train: loss: 0.0002809
[Epoch 55; Iter   492/ 1097] train: loss: 0.0207993
[Epoch 55; Iter   522/ 1097] train: loss: 0.0117656
[Epoch 55; Iter   552/ 1097] train: loss: 0.0002702
[Epoch 55; Iter   582/ 1097] train: loss: 0.0443012
[Epoch 55; Iter   612/ 1097] train: loss: 0.0364672
[Epoch 55; Iter   642/ 1097] train: loss: 0.0016898
[Epoch 55; Iter   672/ 1097] train: loss: 0.0009563
[Epoch 55; Iter   702/ 1097] train: loss: 0.0002590
[Epoch 55; Iter   732/ 1097] train: loss: 0.0001044
[Epoch 55; Iter   762/ 1097] train: loss: 0.0002072
[Epoch 55; Iter   792/ 1097] train: loss: 0.0015601
[Epoch 55; Iter   822/ 1097] train: loss: 0.0197545
[Epoch 55; Iter   852/ 1097] train: loss: 0.0002646
[Epoch 55; Iter   882/ 1097] train: loss: 0.0700714
[Epoch 55; Iter   912/ 1097] train: loss: 0.0048733
[Epoch 55; Iter   942/ 1097] train: loss: 0.0003399
[Epoch 55; Iter   972/ 1097] train: loss: 0.0000893
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0009117
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0031250
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0003874
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0015505
[Epoch 55] ogbg-molhiv: 0.761519 val loss: 0.187804
[Epoch 55] ogbg-molhiv: 0.707868 test loss: 0.313191
[Epoch 56; Iter    25/ 1097] train: loss: 0.0007692
[Epoch 56; Iter    55/ 1097] train: loss: 0.0279245
[Epoch 56; Iter    85/ 1097] train: loss: 0.0252612
[Epoch 56; Iter   115/ 1097] train: loss: 0.0007466
[Epoch 56; Iter   145/ 1097] train: loss: 0.0476725
[Epoch 56; Iter   175/ 1097] train: loss: 0.0004596
[Epoch 56; Iter   205/ 1097] train: loss: 0.1400725
[Epoch 56; Iter   235/ 1097] train: loss: 0.0002154
[Epoch 56; Iter   265/ 1097] train: loss: 0.0045345
[Epoch 56; Iter   295/ 1097] train: loss: 0.0157141
[Epoch 56; Iter   325/ 1097] train: loss: 0.0000930
[Epoch 56; Iter   355/ 1097] train: loss: 0.0052613
[Epoch 56; Iter   385/ 1097] train: loss: 0.0115916
[Epoch 56; Iter   415/ 1097] train: loss: 0.0003662
[Epoch 56; Iter   445/ 1097] train: loss: 0.0010999
[Epoch 56; Iter   475/ 1097] train: loss: 0.0167441
[Epoch 56; Iter   505/ 1097] train: loss: 0.0001458
[Epoch 56; Iter   535/ 1097] train: loss: 0.0032268
[Epoch 56; Iter   565/ 1097] train: loss: 0.0016662
[Epoch 56; Iter   595/ 1097] train: loss: 0.0155509
[Epoch 56; Iter   625/ 1097] train: loss: 0.0166186
[Epoch 56; Iter   655/ 1097] train: loss: 0.0995750
[Epoch 56; Iter   685/ 1097] train: loss: 0.0206354
[Epoch 56; Iter   715/ 1097] train: loss: 0.0009914
[Epoch 56; Iter   745/ 1097] train: loss: 0.0010898
[Epoch 56; Iter   775/ 1097] train: loss: 0.0014186
[Epoch 56; Iter   805/ 1097] train: loss: 0.0014014
[Epoch 56; Iter   835/ 1097] train: loss: 0.0421863
[Epoch 56; Iter   865/ 1097] train: loss: 0.2276533
[Epoch 56; Iter   895/ 1097] train: loss: 0.1669138
[Epoch 56; Iter   925/ 1097] train: loss: 0.0005769
[Epoch 56; Iter   955/ 1097] train: loss: 0.0076154
[Epoch 56; Iter   985/ 1097] train: loss: 0.0033693
[Epoch 52; Iter   933/ 1097] train: loss: 0.0015891
[Epoch 52; Iter   963/ 1097] train: loss: 0.0025521
[Epoch 52; Iter   993/ 1097] train: loss: 0.0006828
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0021561
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0010678
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0002328
[Epoch 52] ogbg-molhiv: 0.806894 val loss: 0.239582
[Epoch 52] ogbg-molhiv: 0.810477 test loss: 0.253745
[Epoch 53; Iter    16/ 1097] train: loss: 0.0024214
[Epoch 53; Iter    46/ 1097] train: loss: 0.0319833
[Epoch 53; Iter    76/ 1097] train: loss: 0.0009426
[Epoch 53; Iter   106/ 1097] train: loss: 0.0008821
[Epoch 53; Iter   136/ 1097] train: loss: 0.0006408
[Epoch 53; Iter   166/ 1097] train: loss: 0.0013285
[Epoch 53; Iter   196/ 1097] train: loss: 0.0062629
[Epoch 53; Iter   226/ 1097] train: loss: 0.0021044
[Epoch 53; Iter   256/ 1097] train: loss: 0.0018218
[Epoch 53; Iter   286/ 1097] train: loss: 0.0009147
[Epoch 53; Iter   316/ 1097] train: loss: 0.0008767
[Epoch 53; Iter   346/ 1097] train: loss: 0.0000724
[Epoch 53; Iter   376/ 1097] train: loss: 0.0002312
[Epoch 53; Iter   406/ 1097] train: loss: 0.0000906
[Epoch 53; Iter   436/ 1097] train: loss: 0.0396583
[Epoch 53; Iter   466/ 1097] train: loss: 0.0081111
[Epoch 53; Iter   496/ 1097] train: loss: 0.0019080
[Epoch 53; Iter   526/ 1097] train: loss: 0.0011053
[Epoch 53; Iter   556/ 1097] train: loss: 0.0003857
[Epoch 53; Iter   586/ 1097] train: loss: 0.0009657
[Epoch 53; Iter   616/ 1097] train: loss: 0.0006634
[Epoch 53; Iter   646/ 1097] train: loss: 0.0006807
[Epoch 53; Iter   676/ 1097] train: loss: 0.0043106
[Epoch 53; Iter   706/ 1097] train: loss: 0.0016820
[Epoch 53; Iter   736/ 1097] train: loss: 0.0164399
[Epoch 53; Iter   766/ 1097] train: loss: 0.0001309
[Epoch 53; Iter   796/ 1097] train: loss: 0.0005791
[Epoch 53; Iter   826/ 1097] train: loss: 0.0074077
[Epoch 53; Iter   856/ 1097] train: loss: 0.0000734
[Epoch 53; Iter   886/ 1097] train: loss: 0.0074309
[Epoch 53; Iter   916/ 1097] train: loss: 0.0026337
[Epoch 53; Iter   946/ 1097] train: loss: 0.0015037
[Epoch 53; Iter   976/ 1097] train: loss: 0.0007714
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0052245
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0005615
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0210174
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0018393
[Epoch 53] ogbg-molhiv: 0.788544 val loss: 0.231289
[Epoch 53] ogbg-molhiv: 0.795236 test loss: 0.246967
[Epoch 54; Iter    29/ 1097] train: loss: 0.0002683
[Epoch 54; Iter    59/ 1097] train: loss: 0.0004305
[Epoch 54; Iter    89/ 1097] train: loss: 0.0008942
[Epoch 54; Iter   119/ 1097] train: loss: 0.0061263
[Epoch 54; Iter   149/ 1097] train: loss: 0.0033245
[Epoch 54; Iter   179/ 1097] train: loss: 0.0028397
[Epoch 54; Iter   209/ 1097] train: loss: 0.0032648
[Epoch 54; Iter   239/ 1097] train: loss: 0.0126264
[Epoch 54; Iter   269/ 1097] train: loss: 0.0015582
[Epoch 54; Iter   299/ 1097] train: loss: 0.0049079
[Epoch 54; Iter   329/ 1097] train: loss: 0.0014331
[Epoch 54; Iter   359/ 1097] train: loss: 0.0044325
[Epoch 54; Iter   389/ 1097] train: loss: 0.0136019
[Epoch 54; Iter   419/ 1097] train: loss: 0.0077096
[Epoch 54; Iter   449/ 1097] train: loss: 0.0014941
[Epoch 54; Iter   479/ 1097] train: loss: 0.0016752
[Epoch 54; Iter   509/ 1097] train: loss: 0.0006319
[Epoch 54; Iter   539/ 1097] train: loss: 0.0742437
[Epoch 54; Iter   569/ 1097] train: loss: 0.0008861
[Epoch 54; Iter   599/ 1097] train: loss: 0.0102814
[Epoch 54; Iter   629/ 1097] train: loss: 0.0294331
[Epoch 54; Iter   659/ 1097] train: loss: 0.0110766
[Epoch 54; Iter   689/ 1097] train: loss: 0.0005752
[Epoch 54; Iter   719/ 1097] train: loss: 0.0032273
[Epoch 54; Iter   749/ 1097] train: loss: 0.0032430
[Epoch 54; Iter   779/ 1097] train: loss: 0.0007355
[Epoch 54; Iter   809/ 1097] train: loss: 0.0010885
[Epoch 54; Iter   839/ 1097] train: loss: 0.0018096
[Epoch 54; Iter   869/ 1097] train: loss: 0.0151779
[Epoch 54; Iter   899/ 1097] train: loss: 0.0001445
[Epoch 54; Iter   929/ 1097] train: loss: 0.0229026
[Epoch 54; Iter   959/ 1097] train: loss: 0.0639208
[Epoch 54; Iter   989/ 1097] train: loss: 0.0143992
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0007139
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0027010
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0008394
[Epoch 54] ogbg-molhiv: 0.758497 val loss: 0.289612
[Epoch 54] ogbg-molhiv: 0.791495 test loss: 0.302725
[Epoch 55; Iter    12/ 1097] train: loss: 0.0005438
[Epoch 55; Iter    42/ 1097] train: loss: 0.0001374
[Epoch 55; Iter    72/ 1097] train: loss: 0.0006767
[Epoch 55; Iter   102/ 1097] train: loss: 0.0001630
[Epoch 55; Iter   132/ 1097] train: loss: 0.0022818
[Epoch 55; Iter   162/ 1097] train: loss: 0.0879759
[Epoch 55; Iter   192/ 1097] train: loss: 0.0000964
[Epoch 55; Iter   222/ 1097] train: loss: 0.0008039
[Epoch 55; Iter   252/ 1097] train: loss: 0.0005113
[Epoch 55; Iter   282/ 1097] train: loss: 0.0018126
[Epoch 55; Iter   312/ 1097] train: loss: 0.0010958
[Epoch 55; Iter   342/ 1097] train: loss: 0.0001628
[Epoch 55; Iter   372/ 1097] train: loss: 0.0400668
[Epoch 55; Iter   402/ 1097] train: loss: 0.0012199
[Epoch 55; Iter   432/ 1097] train: loss: 0.0003688
[Epoch 55; Iter   462/ 1097] train: loss: 0.0015386
[Epoch 55; Iter   492/ 1097] train: loss: 0.0384678
[Epoch 55; Iter   522/ 1097] train: loss: 0.0072312
[Epoch 55; Iter   552/ 1097] train: loss: 0.0055826
[Epoch 55; Iter   582/ 1097] train: loss: 0.0008545
[Epoch 55; Iter   612/ 1097] train: loss: 0.0002229
[Epoch 55; Iter   642/ 1097] train: loss: 0.0199346
[Epoch 55; Iter   672/ 1097] train: loss: 0.0024381
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010556
[Epoch 55; Iter   732/ 1097] train: loss: 0.0020713
[Epoch 55; Iter   762/ 1097] train: loss: 0.0000792
[Epoch 55; Iter   792/ 1097] train: loss: 0.0001110
[Epoch 55; Iter   822/ 1097] train: loss: 0.0210091
[Epoch 55; Iter   852/ 1097] train: loss: 0.0007398
[Epoch 55; Iter   882/ 1097] train: loss: 0.0194704
[Epoch 55; Iter   912/ 1097] train: loss: 0.0011139
[Epoch 55; Iter   942/ 1097] train: loss: 0.0011565
[Epoch 55; Iter   972/ 1097] train: loss: 0.0001217
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0002443
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0029525
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0004683
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0047643
[Epoch 55] ogbg-molhiv: 0.769725 val loss: 0.245063
[Epoch 55] ogbg-molhiv: 0.792495 test loss: 0.274611
[Epoch 56; Iter    25/ 1097] train: loss: 0.0010662
[Epoch 56; Iter    55/ 1097] train: loss: 0.0640717
[Epoch 56; Iter    85/ 1097] train: loss: 0.0006478
[Epoch 56; Iter   115/ 1097] train: loss: 0.0001336
[Epoch 56; Iter   145/ 1097] train: loss: 0.0003461
[Epoch 56; Iter   175/ 1097] train: loss: 0.0005843
[Epoch 56; Iter   205/ 1097] train: loss: 0.0033805
[Epoch 56; Iter   235/ 1097] train: loss: 0.0001470
[Epoch 56; Iter   265/ 1097] train: loss: 0.0007074
[Epoch 56; Iter   295/ 1097] train: loss: 0.0000772
[Epoch 56; Iter   325/ 1097] train: loss: 0.0003861
[Epoch 56; Iter   355/ 1097] train: loss: 0.0009175
[Epoch 56; Iter   385/ 1097] train: loss: 0.0008107
[Epoch 56; Iter   415/ 1097] train: loss: 0.0028411
[Epoch 56; Iter   445/ 1097] train: loss: 0.0005279
[Epoch 56; Iter   475/ 1097] train: loss: 0.0028525
[Epoch 56; Iter   505/ 1097] train: loss: 0.0008560
[Epoch 56; Iter   535/ 1097] train: loss: 0.0021706
[Epoch 56; Iter   565/ 1097] train: loss: 0.0001570
[Epoch 56; Iter   595/ 1097] train: loss: 0.0013947
[Epoch 56; Iter   625/ 1097] train: loss: 0.0288570
[Epoch 56; Iter   655/ 1097] train: loss: 0.0004101
[Epoch 56; Iter   685/ 1097] train: loss: 0.0001035
[Epoch 56; Iter   715/ 1097] train: loss: 0.0002401
[Epoch 56; Iter   745/ 1097] train: loss: 0.0003077
[Epoch 56; Iter   775/ 1097] train: loss: 0.0003993
[Epoch 56; Iter   805/ 1097] train: loss: 0.0003860
[Epoch 56; Iter   835/ 1097] train: loss: 0.0058547
[Epoch 56; Iter   865/ 1097] train: loss: 0.0002302
[Epoch 56; Iter   895/ 1097] train: loss: 0.0012310
[Epoch 56; Iter   925/ 1097] train: loss: 0.0020381
[Epoch 56; Iter   955/ 1097] train: loss: 0.0163018
[Epoch 56; Iter   985/ 1097] train: loss: 0.0000150
[Epoch 52; Iter   933/ 1097] train: loss: 0.0932286
[Epoch 52; Iter   963/ 1097] train: loss: 0.0009692
[Epoch 52; Iter   993/ 1097] train: loss: 0.0003252
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0001990
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0001932
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0024029
[Epoch 52] ogbg-molhiv: 0.666596 val loss: 1.610110
[Epoch 52] ogbg-molhiv: 0.576317 test loss: 1.533130
[Epoch 53; Iter    16/ 1097] train: loss: 0.0161883
[Epoch 53; Iter    46/ 1097] train: loss: 0.0001615
[Epoch 53; Iter    76/ 1097] train: loss: 0.0000630
[Epoch 53; Iter   106/ 1097] train: loss: 0.0017181
[Epoch 53; Iter   136/ 1097] train: loss: 0.0547010
[Epoch 53; Iter   166/ 1097] train: loss: 0.0002782
[Epoch 53; Iter   196/ 1097] train: loss: 0.0003206
[Epoch 53; Iter   226/ 1097] train: loss: 0.0036314
[Epoch 53; Iter   256/ 1097] train: loss: 0.0001676
[Epoch 53; Iter   286/ 1097] train: loss: 0.0001046
[Epoch 53; Iter   316/ 1097] train: loss: 0.0011333
[Epoch 53; Iter   346/ 1097] train: loss: 0.0036653
[Epoch 53; Iter   376/ 1097] train: loss: 0.0006368
[Epoch 53; Iter   406/ 1097] train: loss: 0.0006617
[Epoch 53; Iter   436/ 1097] train: loss: 0.0137977
[Epoch 53; Iter   466/ 1097] train: loss: 0.0807830
[Epoch 53; Iter   496/ 1097] train: loss: 0.0055905
[Epoch 53; Iter   526/ 1097] train: loss: 0.0011101
[Epoch 53; Iter   556/ 1097] train: loss: 0.0604126
[Epoch 53; Iter   586/ 1097] train: loss: 0.0020566
[Epoch 53; Iter   616/ 1097] train: loss: 0.0222970
[Epoch 53; Iter   646/ 1097] train: loss: 0.0187933
[Epoch 53; Iter   676/ 1097] train: loss: 0.0696265
[Epoch 53; Iter   706/ 1097] train: loss: 0.0009746
[Epoch 53; Iter   736/ 1097] train: loss: 0.0015504
[Epoch 53; Iter   766/ 1097] train: loss: 0.0001858
[Epoch 53; Iter   796/ 1097] train: loss: 0.0062511
[Epoch 53; Iter   826/ 1097] train: loss: 0.0075927
[Epoch 53; Iter   856/ 1097] train: loss: 0.0025018
[Epoch 53; Iter   886/ 1097] train: loss: 0.0046889
[Epoch 53; Iter   916/ 1097] train: loss: 0.0003180
[Epoch 53; Iter   946/ 1097] train: loss: 0.0011796
[Epoch 53; Iter   976/ 1097] train: loss: 0.0024662
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0046970
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0019975
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0080428
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0149175
[Epoch 53] ogbg-molhiv: 0.683902 val loss: 1.977064
[Epoch 53] ogbg-molhiv: 0.620582 test loss: 2.124421
[Epoch 54; Iter    29/ 1097] train: loss: 0.0138078
[Epoch 54; Iter    59/ 1097] train: loss: 0.0001458
[Epoch 54; Iter    89/ 1097] train: loss: 0.0001011
[Epoch 54; Iter   119/ 1097] train: loss: 0.0028927
[Epoch 54; Iter   149/ 1097] train: loss: 0.0138368
[Epoch 54; Iter   179/ 1097] train: loss: 0.0000357
[Epoch 54; Iter   209/ 1097] train: loss: 0.0006584
[Epoch 54; Iter   239/ 1097] train: loss: 0.0002832
[Epoch 54; Iter   269/ 1097] train: loss: 0.0146181
[Epoch 54; Iter   299/ 1097] train: loss: 0.0047437
[Epoch 54; Iter   329/ 1097] train: loss: 0.0009858
[Epoch 54; Iter   359/ 1097] train: loss: 0.0122032
[Epoch 54; Iter   389/ 1097] train: loss: 0.0002942
[Epoch 54; Iter   419/ 1097] train: loss: 0.0013354
[Epoch 54; Iter   449/ 1097] train: loss: 0.0022954
[Epoch 54; Iter   479/ 1097] train: loss: 0.0368526
[Epoch 54; Iter   509/ 1097] train: loss: 0.0005409
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003536
[Epoch 54; Iter   569/ 1097] train: loss: 0.0015230
[Epoch 54; Iter   599/ 1097] train: loss: 0.0588159
[Epoch 54; Iter   629/ 1097] train: loss: 0.1010934
[Epoch 54; Iter   659/ 1097] train: loss: 0.0380899
[Epoch 54; Iter   689/ 1097] train: loss: 0.0007742
[Epoch 54; Iter   719/ 1097] train: loss: 0.0015494
[Epoch 54; Iter   749/ 1097] train: loss: 0.0037782
[Epoch 54; Iter   779/ 1097] train: loss: 0.0001849
[Epoch 54; Iter   809/ 1097] train: loss: 0.0019214
[Epoch 54; Iter   839/ 1097] train: loss: 0.0346177
[Epoch 54; Iter   869/ 1097] train: loss: 0.0012648
[Epoch 54; Iter   899/ 1097] train: loss: 0.0001822
[Epoch 54; Iter   929/ 1097] train: loss: 0.0004601
[Epoch 54; Iter   959/ 1097] train: loss: 0.0004666
[Epoch 54; Iter   989/ 1097] train: loss: 0.0072446
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0001183
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0056912
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0000237
[Epoch 54] ogbg-molhiv: 0.695360 val loss: 2.671744
[Epoch 54] ogbg-molhiv: 0.584592 test loss: 4.446673
[Epoch 55; Iter    12/ 1097] train: loss: 0.0009821
[Epoch 55; Iter    42/ 1097] train: loss: 0.0000338
[Epoch 55; Iter    72/ 1097] train: loss: 0.0001068
[Epoch 55; Iter   102/ 1097] train: loss: 0.0003642
[Epoch 55; Iter   132/ 1097] train: loss: 0.0006216
[Epoch 55; Iter   162/ 1097] train: loss: 0.0003711
[Epoch 55; Iter   192/ 1097] train: loss: 0.0007971
[Epoch 55; Iter   222/ 1097] train: loss: 0.0017829
[Epoch 55; Iter   252/ 1097] train: loss: 0.0008518
[Epoch 55; Iter   282/ 1097] train: loss: 0.0079717
[Epoch 55; Iter   312/ 1097] train: loss: 0.0000989
[Epoch 55; Iter   342/ 1097] train: loss: 0.0005574
[Epoch 55; Iter   372/ 1097] train: loss: 0.0047590
[Epoch 55; Iter   402/ 1097] train: loss: 0.0002145
[Epoch 55; Iter   432/ 1097] train: loss: 0.0077354
[Epoch 55; Iter   462/ 1097] train: loss: 0.0046610
[Epoch 55; Iter   492/ 1097] train: loss: 0.0062463
[Epoch 55; Iter   522/ 1097] train: loss: 0.0001739
[Epoch 55; Iter   552/ 1097] train: loss: 0.0000600
[Epoch 55; Iter   582/ 1097] train: loss: 0.0014275
[Epoch 55; Iter   612/ 1097] train: loss: 0.0000469
[Epoch 55; Iter   642/ 1097] train: loss: 0.0002230
[Epoch 55; Iter   672/ 1097] train: loss: 0.0056418
[Epoch 55; Iter   702/ 1097] train: loss: 0.0045407
[Epoch 55; Iter   732/ 1097] train: loss: 0.0005322
[Epoch 55; Iter   762/ 1097] train: loss: 0.0001261
[Epoch 55; Iter   792/ 1097] train: loss: 0.0010656
[Epoch 55; Iter   822/ 1097] train: loss: 0.0003491
[Epoch 55; Iter   852/ 1097] train: loss: 0.0017189
[Epoch 55; Iter   882/ 1097] train: loss: 0.0074907
[Epoch 55; Iter   912/ 1097] train: loss: 0.0001048
[Epoch 55; Iter   942/ 1097] train: loss: 0.0340014
[Epoch 55; Iter   972/ 1097] train: loss: 0.0043844
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0011919
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0629192
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0009870
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0022996
[Epoch 55] ogbg-molhiv: 0.707745 val loss: 5.798467
[Epoch 55] ogbg-molhiv: 0.588855 test loss: 8.305367
[Epoch 56; Iter    25/ 1097] train: loss: 0.0002214
[Epoch 56; Iter    55/ 1097] train: loss: 0.0011640
[Epoch 56; Iter    85/ 1097] train: loss: 0.0002694
[Epoch 56; Iter   115/ 1097] train: loss: 0.0000143
[Epoch 56; Iter   145/ 1097] train: loss: 0.0022471
[Epoch 56; Iter   175/ 1097] train: loss: 0.0006818
[Epoch 56; Iter   205/ 1097] train: loss: 0.0145786
[Epoch 56; Iter   235/ 1097] train: loss: 0.0151339
[Epoch 56; Iter   265/ 1097] train: loss: 0.0003763
[Epoch 56; Iter   295/ 1097] train: loss: 0.0014513
[Epoch 56; Iter   325/ 1097] train: loss: 0.0382452
[Epoch 56; Iter   355/ 1097] train: loss: 0.0003635
[Epoch 56; Iter   385/ 1097] train: loss: 0.0081653
[Epoch 56; Iter   415/ 1097] train: loss: 0.0007058
[Epoch 56; Iter   445/ 1097] train: loss: 0.0003862
[Epoch 56; Iter   475/ 1097] train: loss: 0.0004218
[Epoch 56; Iter   505/ 1097] train: loss: 0.0001398
[Epoch 56; Iter   535/ 1097] train: loss: 0.0001228
[Epoch 56; Iter   565/ 1097] train: loss: 0.0000546
[Epoch 56; Iter   595/ 1097] train: loss: 0.0064505
[Epoch 56; Iter   625/ 1097] train: loss: 0.0016691
[Epoch 56; Iter   655/ 1097] train: loss: 0.0012204
[Epoch 56; Iter   685/ 1097] train: loss: 0.0000302
[Epoch 56; Iter   715/ 1097] train: loss: 0.0032421
[Epoch 56; Iter   745/ 1097] train: loss: 0.0068574
[Epoch 56; Iter   775/ 1097] train: loss: 0.0003217
[Epoch 56; Iter   805/ 1097] train: loss: 0.0000649
[Epoch 56; Iter   835/ 1097] train: loss: 0.0000378
[Epoch 56; Iter   865/ 1097] train: loss: 0.0005735
[Epoch 56; Iter   895/ 1097] train: loss: 0.0003756
[Epoch 56; Iter   925/ 1097] train: loss: 0.0002368
[Epoch 56; Iter   955/ 1097] train: loss: 0.0000439
[Epoch 56; Iter   985/ 1097] train: loss: 0.0043377
[Epoch 52; Iter   933/ 1097] train: loss: 0.0769051
[Epoch 52; Iter   963/ 1097] train: loss: 0.0254303
[Epoch 52; Iter   993/ 1097] train: loss: 0.0081601
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0129766
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0016112
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0068517
[Epoch 52] ogbg-molhiv: 0.781489 val loss: 11.240899
[Epoch 52] ogbg-molhiv: 0.709919 test loss: 14.885870
[Epoch 53; Iter    16/ 1097] train: loss: 0.0004178
[Epoch 53; Iter    46/ 1097] train: loss: 0.0018576
[Epoch 53; Iter    76/ 1097] train: loss: 0.0024346
[Epoch 53; Iter   106/ 1097] train: loss: 0.0027868
[Epoch 53; Iter   136/ 1097] train: loss: 0.0033065
[Epoch 53; Iter   166/ 1097] train: loss: 0.0012993
[Epoch 53; Iter   196/ 1097] train: loss: 0.0027569
[Epoch 53; Iter   226/ 1097] train: loss: 0.0262946
[Epoch 53; Iter   256/ 1097] train: loss: 0.0008259
[Epoch 53; Iter   286/ 1097] train: loss: 0.0160894
[Epoch 53; Iter   316/ 1097] train: loss: 0.0140489
[Epoch 53; Iter   346/ 1097] train: loss: 0.0024376
[Epoch 53; Iter   376/ 1097] train: loss: 0.0022675
[Epoch 53; Iter   406/ 1097] train: loss: 0.0297333
[Epoch 53; Iter   436/ 1097] train: loss: 0.0014574
[Epoch 53; Iter   466/ 1097] train: loss: 0.0015632
[Epoch 53; Iter   496/ 1097] train: loss: 0.0003822
[Epoch 53; Iter   526/ 1097] train: loss: 0.0002047
[Epoch 53; Iter   556/ 1097] train: loss: 0.0096629
[Epoch 53; Iter   586/ 1097] train: loss: 0.0012058
[Epoch 53; Iter   616/ 1097] train: loss: 0.0222479
[Epoch 53; Iter   646/ 1097] train: loss: 0.0049436
[Epoch 53; Iter   676/ 1097] train: loss: 0.0052513
[Epoch 53; Iter   706/ 1097] train: loss: 0.0220315
[Epoch 53; Iter   736/ 1097] train: loss: 0.0466450
[Epoch 53; Iter   766/ 1097] train: loss: 0.0236163
[Epoch 53; Iter   796/ 1097] train: loss: 0.0010150
[Epoch 53; Iter   826/ 1097] train: loss: 0.0164654
[Epoch 53; Iter   856/ 1097] train: loss: 0.0015171
[Epoch 53; Iter   886/ 1097] train: loss: 0.0036134
[Epoch 53; Iter   916/ 1097] train: loss: 0.0251964
[Epoch 53; Iter   946/ 1097] train: loss: 0.0228266
[Epoch 53; Iter   976/ 1097] train: loss: 0.0001072
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0117672
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0016134
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0016998
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0310368
[Epoch 53] ogbg-molhiv: 0.761433 val loss: 23.633201
[Epoch 53] ogbg-molhiv: 0.675616 test loss: 17.904551
[Epoch 54; Iter    29/ 1097] train: loss: 0.0246282
[Epoch 54; Iter    59/ 1097] train: loss: 0.0010786
[Epoch 54; Iter    89/ 1097] train: loss: 0.0104839
[Epoch 54; Iter   119/ 1097] train: loss: 0.0071761
[Epoch 54; Iter   149/ 1097] train: loss: 0.0023650
[Epoch 54; Iter   179/ 1097] train: loss: 0.0184945
[Epoch 54; Iter   209/ 1097] train: loss: 0.0084463
[Epoch 54; Iter   239/ 1097] train: loss: 0.0019591
[Epoch 54; Iter   269/ 1097] train: loss: 0.0156296
[Epoch 54; Iter   299/ 1097] train: loss: 0.0027339
[Epoch 54; Iter   329/ 1097] train: loss: 0.0140579
[Epoch 54; Iter   359/ 1097] train: loss: 0.0246829
[Epoch 54; Iter   389/ 1097] train: loss: 0.0278478
[Epoch 54; Iter   419/ 1097] train: loss: 0.0159003
[Epoch 54; Iter   449/ 1097] train: loss: 0.0001085
[Epoch 54; Iter   479/ 1097] train: loss: 0.0270663
[Epoch 54; Iter   509/ 1097] train: loss: 0.0015499
[Epoch 54; Iter   539/ 1097] train: loss: 0.1676035
[Epoch 54; Iter   569/ 1097] train: loss: 0.0069084
[Epoch 54; Iter   599/ 1097] train: loss: 0.0070835
[Epoch 54; Iter   629/ 1097] train: loss: 0.0070405
[Epoch 54; Iter   659/ 1097] train: loss: 0.0426168
[Epoch 54; Iter   689/ 1097] train: loss: 0.0005524
[Epoch 54; Iter   719/ 1097] train: loss: 0.0006923
[Epoch 54; Iter   749/ 1097] train: loss: 0.0106496
[Epoch 54; Iter   779/ 1097] train: loss: 0.0410852
[Epoch 54; Iter   809/ 1097] train: loss: 0.0001856
[Epoch 54; Iter   839/ 1097] train: loss: 0.0121923
[Epoch 54; Iter   869/ 1097] train: loss: 0.0051656
[Epoch 54; Iter   899/ 1097] train: loss: 0.1022769
[Epoch 54; Iter   929/ 1097] train: loss: 0.0006206
[Epoch 54; Iter   959/ 1097] train: loss: 0.0041894
[Epoch 54; Iter   989/ 1097] train: loss: 0.0991740
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0672332
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0006992
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0017788
[Epoch 54] ogbg-molhiv: 0.744366 val loss: 16.255317
[Epoch 54] ogbg-molhiv: 0.678443 test loss: 16.657932
[Epoch 55; Iter    12/ 1097] train: loss: 0.0029243
[Epoch 55; Iter    42/ 1097] train: loss: 0.0080759
[Epoch 55; Iter    72/ 1097] train: loss: 0.0020173
[Epoch 55; Iter   102/ 1097] train: loss: 0.0015031
[Epoch 55; Iter   132/ 1097] train: loss: 0.0014576
[Epoch 55; Iter   162/ 1097] train: loss: 0.0000775
[Epoch 55; Iter   192/ 1097] train: loss: 0.0288459
[Epoch 55; Iter   222/ 1097] train: loss: 0.0538865
[Epoch 55; Iter   252/ 1097] train: loss: 0.0071889
[Epoch 55; Iter   282/ 1097] train: loss: 0.0007111
[Epoch 55; Iter   312/ 1097] train: loss: 0.0027222
[Epoch 55; Iter   342/ 1097] train: loss: 0.0053133
[Epoch 55; Iter   372/ 1097] train: loss: 0.0163098
[Epoch 55; Iter   402/ 1097] train: loss: 0.0030605
[Epoch 55; Iter   432/ 1097] train: loss: 0.0021253
[Epoch 55; Iter   462/ 1097] train: loss: 0.0011081
[Epoch 55; Iter   492/ 1097] train: loss: 0.0126013
[Epoch 55; Iter   522/ 1097] train: loss: 0.0004787
[Epoch 55; Iter   552/ 1097] train: loss: 0.0012100
[Epoch 55; Iter   582/ 1097] train: loss: 0.0024839
[Epoch 55; Iter   612/ 1097] train: loss: 0.0054339
[Epoch 55; Iter   642/ 1097] train: loss: 0.0386707
[Epoch 55; Iter   672/ 1097] train: loss: 0.0087338
[Epoch 55; Iter   702/ 1097] train: loss: 0.0010663
[Epoch 55; Iter   732/ 1097] train: loss: 0.0006644
[Epoch 55; Iter   762/ 1097] train: loss: 0.0041387
[Epoch 55; Iter   792/ 1097] train: loss: 0.0013964
[Epoch 55; Iter   822/ 1097] train: loss: 0.1943284
[Epoch 55; Iter   852/ 1097] train: loss: 0.0003247
[Epoch 55; Iter   882/ 1097] train: loss: 0.0086901
[Epoch 55; Iter   912/ 1097] train: loss: 0.2953227
[Epoch 55; Iter   942/ 1097] train: loss: 0.0014560
[Epoch 55; Iter   972/ 1097] train: loss: 0.0018501
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0104942
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0006020
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0032003
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0015956
[Epoch 55] ogbg-molhiv: 0.761987 val loss: 10.458780
[Epoch 55] ogbg-molhiv: 0.690589 test loss: 7.797542
[Epoch 56; Iter    25/ 1097] train: loss: 0.0020286
[Epoch 56; Iter    55/ 1097] train: loss: 0.0090678
[Epoch 56; Iter    85/ 1097] train: loss: 0.0019548
[Epoch 56; Iter   115/ 1097] train: loss: 0.0008164
[Epoch 56; Iter   145/ 1097] train: loss: 0.0002882
[Epoch 56; Iter   175/ 1097] train: loss: 0.0014484
[Epoch 56; Iter   205/ 1097] train: loss: 0.0045290
[Epoch 56; Iter   235/ 1097] train: loss: 0.0012022
[Epoch 56; Iter   265/ 1097] train: loss: 0.0037751
[Epoch 56; Iter   295/ 1097] train: loss: 0.0072521
[Epoch 56; Iter   325/ 1097] train: loss: 0.0459089
[Epoch 56; Iter   355/ 1097] train: loss: 0.0028603
[Epoch 56; Iter   385/ 1097] train: loss: 0.0288976
[Epoch 56; Iter   415/ 1097] train: loss: 0.0204070
[Epoch 56; Iter   445/ 1097] train: loss: 0.0008352
[Epoch 56; Iter   475/ 1097] train: loss: 0.0035400
[Epoch 56; Iter   505/ 1097] train: loss: 0.0054692
[Epoch 56; Iter   535/ 1097] train: loss: 0.0342543
[Epoch 56; Iter   565/ 1097] train: loss: 0.0006507
[Epoch 56; Iter   595/ 1097] train: loss: 0.0005846
[Epoch 56; Iter   625/ 1097] train: loss: 0.0006239
[Epoch 56; Iter   655/ 1097] train: loss: 0.0007150
[Epoch 56; Iter   685/ 1097] train: loss: 0.0009405
[Epoch 56; Iter   715/ 1097] train: loss: 0.0251389
[Epoch 56; Iter   745/ 1097] train: loss: 0.0151105
[Epoch 56; Iter   775/ 1097] train: loss: 0.0007272
[Epoch 56; Iter   805/ 1097] train: loss: 0.0200275
[Epoch 56; Iter   835/ 1097] train: loss: 0.1120442
[Epoch 56; Iter   865/ 1097] train: loss: 0.0012756
[Epoch 56; Iter   895/ 1097] train: loss: 0.0911218
[Epoch 56; Iter   925/ 1097] train: loss: 0.0005399
[Epoch 56; Iter   955/ 1097] train: loss: 0.0219454
[Epoch 56; Iter   985/ 1097] train: loss: 0.0020972
[Epoch 52; Iter   933/ 1097] train: loss: 0.0134065
[Epoch 52; Iter   963/ 1097] train: loss: 0.0004395
[Epoch 52; Iter   993/ 1097] train: loss: 0.0050863
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0005468
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0114369
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0018043
[Epoch 52] ogbg-molhiv: 0.694181 val loss: 5.538520
[Epoch 52] ogbg-molhiv: 0.630072 test loss: 5.150657
[Epoch 53; Iter    16/ 1097] train: loss: 0.0002946
[Epoch 53; Iter    46/ 1097] train: loss: 0.0006312
[Epoch 53; Iter    76/ 1097] train: loss: 0.0000964
[Epoch 53; Iter   106/ 1097] train: loss: 0.0006734
[Epoch 53; Iter   136/ 1097] train: loss: 0.0008206
[Epoch 53; Iter   166/ 1097] train: loss: 0.0427001
[Epoch 53; Iter   196/ 1097] train: loss: 0.0026697
[Epoch 53; Iter   226/ 1097] train: loss: 0.0201248
[Epoch 53; Iter   256/ 1097] train: loss: 0.0030812
[Epoch 53; Iter   286/ 1097] train: loss: 0.0024838
[Epoch 53; Iter   316/ 1097] train: loss: 0.0006766
[Epoch 53; Iter   346/ 1097] train: loss: 0.0019301
[Epoch 53; Iter   376/ 1097] train: loss: 0.0445432
[Epoch 53; Iter   406/ 1097] train: loss: 0.0023001
[Epoch 53; Iter   436/ 1097] train: loss: 0.0002129
[Epoch 53; Iter   466/ 1097] train: loss: 0.0561678
[Epoch 53; Iter   496/ 1097] train: loss: 0.0013485
[Epoch 53; Iter   526/ 1097] train: loss: 0.0001781
[Epoch 53; Iter   556/ 1097] train: loss: 0.0004561
[Epoch 53; Iter   586/ 1097] train: loss: 0.0177054
[Epoch 53; Iter   616/ 1097] train: loss: 0.0010418
[Epoch 53; Iter   646/ 1097] train: loss: 0.0164802
[Epoch 53; Iter   676/ 1097] train: loss: 0.0001694
[Epoch 53; Iter   706/ 1097] train: loss: 0.0021735
[Epoch 53; Iter   736/ 1097] train: loss: 0.0001699
[Epoch 53; Iter   766/ 1097] train: loss: 0.0011625
[Epoch 53; Iter   796/ 1097] train: loss: 0.0001050
[Epoch 53; Iter   826/ 1097] train: loss: 0.0051277
[Epoch 53; Iter   856/ 1097] train: loss: 0.0050568
[Epoch 53; Iter   886/ 1097] train: loss: 0.0017829
[Epoch 53; Iter   916/ 1097] train: loss: 0.0002857
[Epoch 53; Iter   946/ 1097] train: loss: 0.0022823
[Epoch 53; Iter   976/ 1097] train: loss: 0.0002526
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0009906
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0001630
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0254478
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0513380
[Epoch 53] ogbg-molhiv: 0.694010 val loss: 3.852416
[Epoch 53] ogbg-molhiv: 0.618044 test loss: 3.081247
[Epoch 54; Iter    29/ 1097] train: loss: 0.0000470
[Epoch 54; Iter    59/ 1097] train: loss: 0.0010189
[Epoch 54; Iter    89/ 1097] train: loss: 0.0002735
[Epoch 54; Iter   119/ 1097] train: loss: 0.0013462
[Epoch 54; Iter   149/ 1097] train: loss: 0.0010056
[Epoch 54; Iter   179/ 1097] train: loss: 0.0001575
[Epoch 54; Iter   209/ 1097] train: loss: 0.0007859
[Epoch 54; Iter   239/ 1097] train: loss: 0.0000715
[Epoch 54; Iter   269/ 1097] train: loss: 0.0001649
[Epoch 54; Iter   299/ 1097] train: loss: 0.0129911
[Epoch 54; Iter   329/ 1097] train: loss: 0.0026911
[Epoch 54; Iter   359/ 1097] train: loss: 0.0000135
[Epoch 54; Iter   389/ 1097] train: loss: 0.0032602
[Epoch 54; Iter   419/ 1097] train: loss: 0.0002406
[Epoch 54; Iter   449/ 1097] train: loss: 0.0002339
[Epoch 54; Iter   479/ 1097] train: loss: 0.0002766
[Epoch 54; Iter   509/ 1097] train: loss: 0.0008117
[Epoch 54; Iter   539/ 1097] train: loss: 0.0003747
[Epoch 54; Iter   569/ 1097] train: loss: 0.0677749
[Epoch 54; Iter   599/ 1097] train: loss: 0.0002621
[Epoch 54; Iter   629/ 1097] train: loss: 0.0000179
[Epoch 54; Iter   659/ 1097] train: loss: 0.0003292
[Epoch 54; Iter   689/ 1097] train: loss: 0.0011911
[Epoch 54; Iter   719/ 1097] train: loss: 0.0008476
[Epoch 54; Iter   749/ 1097] train: loss: 0.0017797
[Epoch 54; Iter   779/ 1097] train: loss: 0.0817535
[Epoch 54; Iter   809/ 1097] train: loss: 0.0059913
[Epoch 54; Iter   839/ 1097] train: loss: 0.0002701
[Epoch 54; Iter   869/ 1097] train: loss: 0.0119123
[Epoch 54; Iter   899/ 1097] train: loss: 0.0118687
[Epoch 54; Iter   929/ 1097] train: loss: 0.2077952
[Epoch 54; Iter   959/ 1097] train: loss: 0.0007348
[Epoch 54; Iter   989/ 1097] train: loss: 0.0065309
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0032005
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0008437
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0229654
[Epoch 54] ogbg-molhiv: 0.709332 val loss: 5.593771
[Epoch 54] ogbg-molhiv: 0.655015 test loss: 3.461250
[Epoch 55; Iter    12/ 1097] train: loss: 0.0001764
[Epoch 55; Iter    42/ 1097] train: loss: 0.0151022
[Epoch 55; Iter    72/ 1097] train: loss: 0.0319453
[Epoch 55; Iter   102/ 1097] train: loss: 0.0001364
[Epoch 55; Iter   132/ 1097] train: loss: 0.0137613
[Epoch 55; Iter   162/ 1097] train: loss: 0.0002510
[Epoch 55; Iter   192/ 1097] train: loss: 0.0041249
[Epoch 55; Iter   222/ 1097] train: loss: 0.0015332
[Epoch 55; Iter   252/ 1097] train: loss: 0.0001407
[Epoch 55; Iter   282/ 1097] train: loss: 0.0006317
[Epoch 55; Iter   312/ 1097] train: loss: 0.0005265
[Epoch 55; Iter   342/ 1097] train: loss: 0.0006769
[Epoch 55; Iter   372/ 1097] train: loss: 0.0018251
[Epoch 55; Iter   402/ 1097] train: loss: 0.2668535
[Epoch 55; Iter   432/ 1097] train: loss: 0.0096871
[Epoch 55; Iter   462/ 1097] train: loss: 0.0067861
[Epoch 55; Iter   492/ 1097] train: loss: 0.0014994
[Epoch 55; Iter   522/ 1097] train: loss: 0.0399636
[Epoch 55; Iter   552/ 1097] train: loss: 0.0011516
[Epoch 55; Iter   582/ 1097] train: loss: 0.0039475
[Epoch 55; Iter   612/ 1097] train: loss: 0.0000610
[Epoch 55; Iter   642/ 1097] train: loss: 0.0005767
[Epoch 55; Iter   672/ 1097] train: loss: 0.0083803
[Epoch 55; Iter   702/ 1097] train: loss: 0.0472160
[Epoch 55; Iter   732/ 1097] train: loss: 0.0037543
[Epoch 55; Iter   762/ 1097] train: loss: 0.0009787
[Epoch 55; Iter   792/ 1097] train: loss: 0.0005432
[Epoch 55; Iter   822/ 1097] train: loss: 0.0028526
[Epoch 55; Iter   852/ 1097] train: loss: 0.0001438
[Epoch 55; Iter   882/ 1097] train: loss: 0.0006333
[Epoch 55; Iter   912/ 1097] train: loss: 0.0009051
[Epoch 55; Iter   942/ 1097] train: loss: 0.0821735
[Epoch 55; Iter   972/ 1097] train: loss: 0.0008008
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0000578
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0000636
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0001243
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0056709
[Epoch 55] ogbg-molhiv: 0.689812 val loss: 4.502110
[Epoch 55] ogbg-molhiv: 0.657187 test loss: 2.911564
[Epoch 56; Iter    25/ 1097] train: loss: 0.0002173
[Epoch 56; Iter    55/ 1097] train: loss: 0.0004202
[Epoch 56; Iter    85/ 1097] train: loss: 0.0099706
[Epoch 56; Iter   115/ 1097] train: loss: 0.0002069
[Epoch 56; Iter   145/ 1097] train: loss: 0.0022126
[Epoch 56; Iter   175/ 1097] train: loss: 0.0005363
[Epoch 56; Iter   205/ 1097] train: loss: 0.0721813
[Epoch 56; Iter   235/ 1097] train: loss: 0.0050414
[Epoch 56; Iter   265/ 1097] train: loss: 0.0000390
[Epoch 56; Iter   295/ 1097] train: loss: 0.0003677
[Epoch 56; Iter   325/ 1097] train: loss: 0.0028047
[Epoch 56; Iter   355/ 1097] train: loss: 0.0058219
[Epoch 56; Iter   385/ 1097] train: loss: 0.0000393
[Epoch 56; Iter   415/ 1097] train: loss: 0.0005220
[Epoch 56; Iter   445/ 1097] train: loss: 0.0216627
[Epoch 56; Iter   475/ 1097] train: loss: 0.0014791
[Epoch 56; Iter   505/ 1097] train: loss: 0.0000288
[Epoch 56; Iter   535/ 1097] train: loss: 0.0010436
[Epoch 56; Iter   565/ 1097] train: loss: 0.0050215
[Epoch 56; Iter   595/ 1097] train: loss: 0.0023714
[Epoch 56; Iter   625/ 1097] train: loss: 0.0065751
[Epoch 56; Iter   655/ 1097] train: loss: 0.0004174
[Epoch 56; Iter   685/ 1097] train: loss: 0.0004097
[Epoch 56; Iter   715/ 1097] train: loss: 0.0007614
[Epoch 56; Iter   745/ 1097] train: loss: 0.0015971
[Epoch 56; Iter   775/ 1097] train: loss: 0.0567936
[Epoch 56; Iter   805/ 1097] train: loss: 0.0013831
[Epoch 56; Iter   835/ 1097] train: loss: 0.0002290
[Epoch 56; Iter   865/ 1097] train: loss: 0.0501665
[Epoch 56; Iter   895/ 1097] train: loss: 0.0112806
[Epoch 56; Iter   925/ 1097] train: loss: 0.0035559
[Epoch 56; Iter   955/ 1097] train: loss: 0.0002849
[Epoch 56; Iter   985/ 1097] train: loss: 0.0002823
[Epoch 44; Iter   769/ 1097] train: loss: 0.0316753
[Epoch 44; Iter   799/ 1097] train: loss: 0.0180100
[Epoch 44; Iter   829/ 1097] train: loss: 0.2410753
[Epoch 44; Iter   859/ 1097] train: loss: 0.0670661
[Epoch 44; Iter   889/ 1097] train: loss: 0.0096153
[Epoch 44; Iter   919/ 1097] train: loss: 0.0102880
[Epoch 44; Iter   949/ 1097] train: loss: 0.0858494
[Epoch 44; Iter   979/ 1097] train: loss: 0.0102910
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0160408
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0647072
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1056344
[Epoch 44] ogbg-molhiv: 0.844007 val loss: 0.079402
[Epoch 44] ogbg-molhiv: 0.759341 test loss: 0.142343
[Epoch 45; Iter     2/ 1097] train: loss: 0.0133943
[Epoch 45; Iter    32/ 1097] train: loss: 0.0180026
[Epoch 45; Iter    62/ 1097] train: loss: 0.1493860
[Epoch 45; Iter    92/ 1097] train: loss: 0.0461704
[Epoch 45; Iter   122/ 1097] train: loss: 0.0250738
[Epoch 45; Iter   152/ 1097] train: loss: 0.1147294
[Epoch 45; Iter   182/ 1097] train: loss: 0.2128627
[Epoch 45; Iter   212/ 1097] train: loss: 0.1693321
[Epoch 45; Iter   242/ 1097] train: loss: 0.0979485
[Epoch 45; Iter   272/ 1097] train: loss: 0.0718728
[Epoch 45; Iter   302/ 1097] train: loss: 0.1530004
[Epoch 45; Iter   332/ 1097] train: loss: 0.0210542
[Epoch 45; Iter   362/ 1097] train: loss: 0.0235195
[Epoch 45; Iter   392/ 1097] train: loss: 0.0153309
[Epoch 45; Iter   422/ 1097] train: loss: 0.1753436
[Epoch 45; Iter   452/ 1097] train: loss: 0.0543039
[Epoch 45; Iter   482/ 1097] train: loss: 0.0962267
[Epoch 45; Iter   512/ 1097] train: loss: 0.0785824
[Epoch 45; Iter   542/ 1097] train: loss: 0.0243316
[Epoch 45; Iter   572/ 1097] train: loss: 0.0545015
[Epoch 45; Iter   602/ 1097] train: loss: 0.2895057
[Epoch 45; Iter   632/ 1097] train: loss: 0.0332986
[Epoch 45; Iter   662/ 1097] train: loss: 0.1056254
[Epoch 45; Iter   692/ 1097] train: loss: 0.0263677
[Epoch 45; Iter   722/ 1097] train: loss: 0.0188101
[Epoch 45; Iter   752/ 1097] train: loss: 0.0213567
[Epoch 45; Iter   782/ 1097] train: loss: 0.3648979
[Epoch 45; Iter   812/ 1097] train: loss: 0.0279972
[Epoch 45; Iter   842/ 1097] train: loss: 0.0146527
[Epoch 45; Iter   872/ 1097] train: loss: 0.0819942
[Epoch 45; Iter   902/ 1097] train: loss: 0.0321521
[Epoch 45; Iter   932/ 1097] train: loss: 0.0146598
[Epoch 45; Iter   962/ 1097] train: loss: 0.0546593
[Epoch 45; Iter   992/ 1097] train: loss: 0.0588496
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0259746
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0266620
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0854677
[Epoch 45] ogbg-molhiv: 0.837072 val loss: 0.084935
[Epoch 45] ogbg-molhiv: 0.735059 test loss: 0.150589
[Epoch 46; Iter    15/ 1097] train: loss: 0.1190827
[Epoch 46; Iter    45/ 1097] train: loss: 0.0149923
[Epoch 46; Iter    75/ 1097] train: loss: 0.0842589
[Epoch 46; Iter   105/ 1097] train: loss: 0.0899340
[Epoch 46; Iter   135/ 1097] train: loss: 0.1353295
[Epoch 46; Iter   165/ 1097] train: loss: 0.2533341
[Epoch 46; Iter   195/ 1097] train: loss: 0.0135181
[Epoch 46; Iter   225/ 1097] train: loss: 0.0467598
[Epoch 46; Iter   255/ 1097] train: loss: 0.0442946
[Epoch 46; Iter   285/ 1097] train: loss: 0.0212331
[Epoch 46; Iter   315/ 1097] train: loss: 0.0425531
[Epoch 46; Iter   345/ 1097] train: loss: 0.0470489
[Epoch 46; Iter   375/ 1097] train: loss: 0.0142770
[Epoch 46; Iter   405/ 1097] train: loss: 0.0927071
[Epoch 46; Iter   435/ 1097] train: loss: 0.0163989
[Epoch 46; Iter   465/ 1097] train: loss: 0.0296404
[Epoch 46; Iter   495/ 1097] train: loss: 0.1735331
[Epoch 46; Iter   525/ 1097] train: loss: 0.0419025
[Epoch 46; Iter   555/ 1097] train: loss: 0.0623634
[Epoch 46; Iter   585/ 1097] train: loss: 0.1119914
[Epoch 46; Iter   615/ 1097] train: loss: 0.0409835
[Epoch 46; Iter   645/ 1097] train: loss: 0.0759205
[Epoch 46; Iter   675/ 1097] train: loss: 0.0707870
[Epoch 46; Iter   705/ 1097] train: loss: 0.0569699
[Epoch 46; Iter   735/ 1097] train: loss: 0.0196592
[Epoch 46; Iter   765/ 1097] train: loss: 0.2060051
[Epoch 46; Iter   795/ 1097] train: loss: 0.0364163
[Epoch 46; Iter   825/ 1097] train: loss: 0.0416654
[Epoch 46; Iter   855/ 1097] train: loss: 0.0100645
[Epoch 46; Iter   885/ 1097] train: loss: 0.1898124
[Epoch 46; Iter   915/ 1097] train: loss: 0.0087697
[Epoch 46; Iter   945/ 1097] train: loss: 0.0390213
[Epoch 46; Iter   975/ 1097] train: loss: 0.0178214
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0141130
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0275800
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0523403
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0545786
[Epoch 46] ogbg-molhiv: 0.846986 val loss: 0.080884
[Epoch 46] ogbg-molhiv: 0.754012 test loss: 0.144275
[Epoch 47; Iter    28/ 1097] train: loss: 0.0367181
[Epoch 47; Iter    58/ 1097] train: loss: 0.0412033
[Epoch 47; Iter    88/ 1097] train: loss: 0.0981525
[Epoch 47; Iter   118/ 1097] train: loss: 0.0613466
[Epoch 47; Iter   148/ 1097] train: loss: 0.0261339
[Epoch 47; Iter   178/ 1097] train: loss: 0.0608794
[Epoch 47; Iter   208/ 1097] train: loss: 0.1274643
[Epoch 47; Iter   238/ 1097] train: loss: 0.0233936
[Epoch 47; Iter   268/ 1097] train: loss: 0.0084606
[Epoch 47; Iter   298/ 1097] train: loss: 0.0084107
[Epoch 47; Iter   328/ 1097] train: loss: 0.1021552
[Epoch 47; Iter   358/ 1097] train: loss: 0.1451339
[Epoch 47; Iter   388/ 1097] train: loss: 0.0103332
[Epoch 47; Iter   418/ 1097] train: loss: 0.1029433
[Epoch 47; Iter   448/ 1097] train: loss: 0.0298414
[Epoch 47; Iter   478/ 1097] train: loss: 0.0547610
[Epoch 47; Iter   508/ 1097] train: loss: 0.2002996
[Epoch 47; Iter   538/ 1097] train: loss: 0.1452052
[Epoch 47; Iter   568/ 1097] train: loss: 0.0409135
[Epoch 47; Iter   598/ 1097] train: loss: 0.0689156
[Epoch 47; Iter   628/ 1097] train: loss: 0.0089596
[Epoch 47; Iter   658/ 1097] train: loss: 0.0091183
[Epoch 47; Iter   688/ 1097] train: loss: 0.0754160
[Epoch 47; Iter   718/ 1097] train: loss: 0.0181855
[Epoch 47; Iter   748/ 1097] train: loss: 0.0374533
[Epoch 47; Iter   778/ 1097] train: loss: 0.0476861
[Epoch 47; Iter   808/ 1097] train: loss: 0.0079941
[Epoch 47; Iter   838/ 1097] train: loss: 0.0207811
[Epoch 47; Iter   868/ 1097] train: loss: 0.0194429
[Epoch 47; Iter   898/ 1097] train: loss: 0.0497207
[Epoch 47; Iter   928/ 1097] train: loss: 0.0205119
[Epoch 47; Iter   958/ 1097] train: loss: 0.2820742
[Epoch 47; Iter   988/ 1097] train: loss: 0.1971139
[Epoch 47; Iter  1018/ 1097] train: loss: 0.1123066
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0488766
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0593945
[Epoch 47] ogbg-molhiv: 0.793461 val loss: 0.091229
[Epoch 47] ogbg-molhiv: 0.719487 test loss: 0.160992
[Epoch 48; Iter    11/ 1097] train: loss: 0.0962242
[Epoch 48; Iter    41/ 1097] train: loss: 0.0463982
[Epoch 48; Iter    71/ 1097] train: loss: 0.0195115
[Epoch 48; Iter   101/ 1097] train: loss: 0.2193964
[Epoch 48; Iter   131/ 1097] train: loss: 0.0255655
[Epoch 48; Iter   161/ 1097] train: loss: 0.0111597
[Epoch 48; Iter   191/ 1097] train: loss: 0.0690384
[Epoch 48; Iter   221/ 1097] train: loss: 0.0241388
[Epoch 48; Iter   251/ 1097] train: loss: 0.0480823
[Epoch 48; Iter   281/ 1097] train: loss: 0.0209899
[Epoch 48; Iter   311/ 1097] train: loss: 0.0296860
[Epoch 48; Iter   341/ 1097] train: loss: 0.0316469
[Epoch 48; Iter   371/ 1097] train: loss: 0.0322207
[Epoch 48; Iter   401/ 1097] train: loss: 0.0355319
[Epoch 48; Iter   431/ 1097] train: loss: 0.0361485
[Epoch 48; Iter   461/ 1097] train: loss: 0.0651125
[Epoch 48; Iter   491/ 1097] train: loss: 0.0317837
[Epoch 48; Iter   521/ 1097] train: loss: 0.0493609
[Epoch 48; Iter   551/ 1097] train: loss: 0.1114459
[Epoch 48; Iter   581/ 1097] train: loss: 0.0303650
[Epoch 48; Iter   611/ 1097] train: loss: 0.0469363
[Epoch 48; Iter   641/ 1097] train: loss: 0.0632284
[Epoch 48; Iter   671/ 1097] train: loss: 0.0080079
[Epoch 48; Iter   701/ 1097] train: loss: 0.0220216
[Epoch 48; Iter   731/ 1097] train: loss: 0.0423505
[Epoch 48; Iter   761/ 1097] train: loss: 0.0592101
[Epoch 48; Iter   791/ 1097] train: loss: 0.0289946
[Epoch 48; Iter   821/ 1097] train: loss: 0.0582487
[Epoch 44; Iter   769/ 1097] train: loss: 0.0398132
[Epoch 44; Iter   799/ 1097] train: loss: 0.0551871
[Epoch 44; Iter   829/ 1097] train: loss: 0.1565332
[Epoch 44; Iter   859/ 1097] train: loss: 0.1080054
[Epoch 44; Iter   889/ 1097] train: loss: 0.0351453
[Epoch 44; Iter   919/ 1097] train: loss: 0.0101682
[Epoch 44; Iter   949/ 1097] train: loss: 0.0933685
[Epoch 44; Iter   979/ 1097] train: loss: 0.0380517
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0169115
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0239892
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0248321
[Epoch 44] ogbg-molhiv: 0.825700 val loss: 0.084981
[Epoch 44] ogbg-molhiv: 0.767767 test loss: 0.137467
[Epoch 45; Iter     2/ 1097] train: loss: 0.0545722
[Epoch 45; Iter    32/ 1097] train: loss: 0.0303429
[Epoch 45; Iter    62/ 1097] train: loss: 0.0432708
[Epoch 45; Iter    92/ 1097] train: loss: 0.0356518
[Epoch 45; Iter   122/ 1097] train: loss: 0.0228839
[Epoch 45; Iter   152/ 1097] train: loss: 0.0966998
[Epoch 45; Iter   182/ 1097] train: loss: 0.1027064
[Epoch 45; Iter   212/ 1097] train: loss: 0.0714701
[Epoch 45; Iter   242/ 1097] train: loss: 0.0220405
[Epoch 45; Iter   272/ 1097] train: loss: 0.0928966
[Epoch 45; Iter   302/ 1097] train: loss: 0.2122503
[Epoch 45; Iter   332/ 1097] train: loss: 0.0902151
[Epoch 45; Iter   362/ 1097] train: loss: 0.0244211
[Epoch 45; Iter   392/ 1097] train: loss: 0.2571641
[Epoch 45; Iter   422/ 1097] train: loss: 0.0918776
[Epoch 45; Iter   452/ 1097] train: loss: 0.1223011
[Epoch 45; Iter   482/ 1097] train: loss: 0.0152311
[Epoch 45; Iter   512/ 1097] train: loss: 0.0202396
[Epoch 45; Iter   542/ 1097] train: loss: 0.0252234
[Epoch 45; Iter   572/ 1097] train: loss: 0.1091492
[Epoch 45; Iter   602/ 1097] train: loss: 0.0159034
[Epoch 45; Iter   632/ 1097] train: loss: 0.1045633
[Epoch 45; Iter   662/ 1097] train: loss: 0.0082390
[Epoch 45; Iter   692/ 1097] train: loss: 0.0653427
[Epoch 45; Iter   722/ 1097] train: loss: 0.0334201
[Epoch 45; Iter   752/ 1097] train: loss: 0.0221303
[Epoch 45; Iter   782/ 1097] train: loss: 0.1855601
[Epoch 45; Iter   812/ 1097] train: loss: 0.0436363
[Epoch 45; Iter   842/ 1097] train: loss: 0.0119322
[Epoch 45; Iter   872/ 1097] train: loss: 0.0625632
[Epoch 45; Iter   902/ 1097] train: loss: 0.0208534
[Epoch 45; Iter   932/ 1097] train: loss: 0.2340242
[Epoch 45; Iter   962/ 1097] train: loss: 0.0242695
[Epoch 45; Iter   992/ 1097] train: loss: 0.2049873
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0099969
[Epoch 45; Iter  1052/ 1097] train: loss: 0.2422665
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0237676
[Epoch 45] ogbg-molhiv: 0.813155 val loss: 0.081779
[Epoch 45] ogbg-molhiv: 0.750341 test loss: 0.142259
[Epoch 46; Iter    15/ 1097] train: loss: 0.0197477
[Epoch 46; Iter    45/ 1097] train: loss: 0.0170976
[Epoch 46; Iter    75/ 1097] train: loss: 0.0424604
[Epoch 46; Iter   105/ 1097] train: loss: 0.0256021
[Epoch 46; Iter   135/ 1097] train: loss: 0.0558609
[Epoch 46; Iter   165/ 1097] train: loss: 0.0625113
[Epoch 46; Iter   195/ 1097] train: loss: 0.0830261
[Epoch 46; Iter   225/ 1097] train: loss: 0.0365184
[Epoch 46; Iter   255/ 1097] train: loss: 0.0182741
[Epoch 46; Iter   285/ 1097] train: loss: 0.0271548
[Epoch 46; Iter   315/ 1097] train: loss: 0.0351316
[Epoch 46; Iter   345/ 1097] train: loss: 0.0135932
[Epoch 46; Iter   375/ 1097] train: loss: 0.1454518
[Epoch 46; Iter   405/ 1097] train: loss: 0.0360928
[Epoch 46; Iter   435/ 1097] train: loss: 0.2151672
[Epoch 46; Iter   465/ 1097] train: loss: 0.0324832
[Epoch 46; Iter   495/ 1097] train: loss: 0.0233637
[Epoch 46; Iter   525/ 1097] train: loss: 0.0118221
[Epoch 46; Iter   555/ 1097] train: loss: 0.1137935
[Epoch 46; Iter   585/ 1097] train: loss: 0.0174337
[Epoch 46; Iter   615/ 1097] train: loss: 0.1275658
[Epoch 46; Iter   645/ 1097] train: loss: 0.1185744
[Epoch 46; Iter   675/ 1097] train: loss: 0.0640084
[Epoch 46; Iter   705/ 1097] train: loss: 0.0236554
[Epoch 46; Iter   735/ 1097] train: loss: 0.0276021
[Epoch 46; Iter   765/ 1097] train: loss: 0.0609168
[Epoch 46; Iter   795/ 1097] train: loss: 0.0655824
[Epoch 46; Iter   825/ 1097] train: loss: 0.0972372
[Epoch 46; Iter   855/ 1097] train: loss: 0.0226421
[Epoch 46; Iter   885/ 1097] train: loss: 0.1635137
[Epoch 46; Iter   915/ 1097] train: loss: 0.2688521
[Epoch 46; Iter   945/ 1097] train: loss: 0.1253469
[Epoch 46; Iter   975/ 1097] train: loss: 0.1805401
[Epoch 46; Iter  1005/ 1097] train: loss: 0.1396412
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0181047
[Epoch 46; Iter  1065/ 1097] train: loss: 0.2225016
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0217475
[Epoch 46] ogbg-molhiv: 0.819040 val loss: 0.075912
[Epoch 46] ogbg-molhiv: 0.754404 test loss: 0.141894
[Epoch 47; Iter    28/ 1097] train: loss: 0.0127809
[Epoch 47; Iter    58/ 1097] train: loss: 0.0262840
[Epoch 47; Iter    88/ 1097] train: loss: 0.0772617
[Epoch 47; Iter   118/ 1097] train: loss: 0.0249681
[Epoch 47; Iter   148/ 1097] train: loss: 0.0422665
[Epoch 47; Iter   178/ 1097] train: loss: 0.1463804
[Epoch 47; Iter   208/ 1097] train: loss: 0.0283061
[Epoch 47; Iter   238/ 1097] train: loss: 0.0128702
[Epoch 47; Iter   268/ 1097] train: loss: 0.0537077
[Epoch 47; Iter   298/ 1097] train: loss: 0.0446402
[Epoch 47; Iter   328/ 1097] train: loss: 0.0099005
[Epoch 47; Iter   358/ 1097] train: loss: 0.1986495
[Epoch 47; Iter   388/ 1097] train: loss: 0.1238778
[Epoch 47; Iter   418/ 1097] train: loss: 0.0778916
[Epoch 47; Iter   448/ 1097] train: loss: 0.0280965
[Epoch 47; Iter   478/ 1097] train: loss: 0.0230261
[Epoch 47; Iter   508/ 1097] train: loss: 0.0194930
[Epoch 47; Iter   538/ 1097] train: loss: 0.0177351
[Epoch 47; Iter   568/ 1097] train: loss: 0.0749424
[Epoch 47; Iter   598/ 1097] train: loss: 0.0781138
[Epoch 47; Iter   628/ 1097] train: loss: 0.0390800
[Epoch 47; Iter   658/ 1097] train: loss: 0.0096549
[Epoch 47; Iter   688/ 1097] train: loss: 0.0717301
[Epoch 47; Iter   718/ 1097] train: loss: 0.0188752
[Epoch 47; Iter   748/ 1097] train: loss: 0.0270488
[Epoch 47; Iter   778/ 1097] train: loss: 0.0148239
[Epoch 47; Iter   808/ 1097] train: loss: 0.0253389
[Epoch 47; Iter   838/ 1097] train: loss: 0.1397531
[Epoch 47; Iter   868/ 1097] train: loss: 0.1104214
[Epoch 47; Iter   898/ 1097] train: loss: 0.0394107
[Epoch 47; Iter   928/ 1097] train: loss: 0.0090835
[Epoch 47; Iter   958/ 1097] train: loss: 0.1768295
[Epoch 47; Iter   988/ 1097] train: loss: 0.0493459
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0148345
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0335197
[Epoch 47; Iter  1078/ 1097] train: loss: 0.1256849
[Epoch 47] ogbg-molhiv: 0.821554 val loss: 0.090218
[Epoch 47] ogbg-molhiv: 0.760565 test loss: 0.139202
[Epoch 48; Iter    11/ 1097] train: loss: 0.0735237
[Epoch 48; Iter    41/ 1097] train: loss: 0.1853868
[Epoch 48; Iter    71/ 1097] train: loss: 0.0203989
[Epoch 48; Iter   101/ 1097] train: loss: 0.0450238
[Epoch 48; Iter   131/ 1097] train: loss: 0.0228687
[Epoch 48; Iter   161/ 1097] train: loss: 0.0162243
[Epoch 48; Iter   191/ 1097] train: loss: 0.1054622
[Epoch 48; Iter   221/ 1097] train: loss: 0.0514731
[Epoch 48; Iter   251/ 1097] train: loss: 0.0297784
[Epoch 48; Iter   281/ 1097] train: loss: 0.0207798
[Epoch 48; Iter   311/ 1097] train: loss: 0.0179747
[Epoch 48; Iter   341/ 1097] train: loss: 0.0466546
[Epoch 48; Iter   371/ 1097] train: loss: 0.1312553
[Epoch 48; Iter   401/ 1097] train: loss: 0.0239137
[Epoch 48; Iter   431/ 1097] train: loss: 0.1814925
[Epoch 48; Iter   461/ 1097] train: loss: 0.1416994
[Epoch 48; Iter   491/ 1097] train: loss: 0.0161509
[Epoch 48; Iter   521/ 1097] train: loss: 0.0138466
[Epoch 48; Iter   551/ 1097] train: loss: 0.1838936
[Epoch 48; Iter   581/ 1097] train: loss: 0.0852370
[Epoch 48; Iter   611/ 1097] train: loss: 0.0240217
[Epoch 48; Iter   641/ 1097] train: loss: 0.1239741
[Epoch 48; Iter   671/ 1097] train: loss: 0.1119707
[Epoch 48; Iter   701/ 1097] train: loss: 0.0673407
[Epoch 48; Iter   731/ 1097] train: loss: 0.1146865
[Epoch 48; Iter   761/ 1097] train: loss: 0.0875474
[Epoch 48; Iter   791/ 1097] train: loss: 0.0385030
[Epoch 48; Iter   821/ 1097] train: loss: 0.0911577
[Epoch 44; Iter   769/ 1097] train: loss: 0.1171874
[Epoch 44; Iter   799/ 1097] train: loss: 0.0848769
[Epoch 44; Iter   829/ 1097] train: loss: 0.0200710
[Epoch 44; Iter   859/ 1097] train: loss: 0.0841216
[Epoch 44; Iter   889/ 1097] train: loss: 0.0176509
[Epoch 44; Iter   919/ 1097] train: loss: 0.0195580
[Epoch 44; Iter   949/ 1097] train: loss: 0.0107119
[Epoch 44; Iter   979/ 1097] train: loss: 0.0257289
[Epoch 44; Iter  1009/ 1097] train: loss: 0.2213516
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0040154
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0921602
[Epoch 44] ogbg-molhiv: 0.800843 val loss: 0.088851
[Epoch 44] ogbg-molhiv: 0.746594 test loss: 0.173253
[Epoch 45; Iter     2/ 1097] train: loss: 0.0221105
[Epoch 45; Iter    32/ 1097] train: loss: 0.1278934
[Epoch 45; Iter    62/ 1097] train: loss: 0.0206956
[Epoch 45; Iter    92/ 1097] train: loss: 0.0523358
[Epoch 45; Iter   122/ 1097] train: loss: 0.0292136
[Epoch 45; Iter   152/ 1097] train: loss: 0.0895032
[Epoch 45; Iter   182/ 1097] train: loss: 0.0421235
[Epoch 45; Iter   212/ 1097] train: loss: 0.0520266
[Epoch 45; Iter   242/ 1097] train: loss: 0.1178097
[Epoch 45; Iter   272/ 1097] train: loss: 0.0389902
[Epoch 45; Iter   302/ 1097] train: loss: 0.1230013
[Epoch 45; Iter   332/ 1097] train: loss: 0.1610608
[Epoch 45; Iter   362/ 1097] train: loss: 0.0688468
[Epoch 45; Iter   392/ 1097] train: loss: 0.0223134
[Epoch 45; Iter   422/ 1097] train: loss: 0.0415293
[Epoch 45; Iter   452/ 1097] train: loss: 0.0230620
[Epoch 45; Iter   482/ 1097] train: loss: 0.0460114
[Epoch 45; Iter   512/ 1097] train: loss: 0.0402674
[Epoch 45; Iter   542/ 1097] train: loss: 0.0105178
[Epoch 45; Iter   572/ 1097] train: loss: 0.3198570
[Epoch 45; Iter   602/ 1097] train: loss: 0.0535710
[Epoch 45; Iter   632/ 1097] train: loss: 0.0759286
[Epoch 45; Iter   662/ 1097] train: loss: 0.0501813
[Epoch 45; Iter   692/ 1097] train: loss: 0.0154843
[Epoch 45; Iter   722/ 1097] train: loss: 0.3071426
[Epoch 45; Iter   752/ 1097] train: loss: 0.0214953
[Epoch 45; Iter   782/ 1097] train: loss: 0.0608756
[Epoch 45; Iter   812/ 1097] train: loss: 0.0289572
[Epoch 45; Iter   842/ 1097] train: loss: 0.0105163
[Epoch 45; Iter   872/ 1097] train: loss: 0.0136177
[Epoch 45; Iter   902/ 1097] train: loss: 0.0135014
[Epoch 45; Iter   932/ 1097] train: loss: 0.1437357
[Epoch 45; Iter   962/ 1097] train: loss: 0.0594574
[Epoch 45; Iter   992/ 1097] train: loss: 0.2148544
[Epoch 45; Iter  1022/ 1097] train: loss: 0.1603006
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0534230
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0390900
[Epoch 45] ogbg-molhiv: 0.814095 val loss: 0.085564
[Epoch 45] ogbg-molhiv: 0.756788 test loss: 0.323081
[Epoch 46; Iter    15/ 1097] train: loss: 0.0150153
[Epoch 46; Iter    45/ 1097] train: loss: 0.0126417
[Epoch 46; Iter    75/ 1097] train: loss: 0.0162608
[Epoch 46; Iter   105/ 1097] train: loss: 0.0249142
[Epoch 46; Iter   135/ 1097] train: loss: 0.0356700
[Epoch 46; Iter   165/ 1097] train: loss: 0.0079874
[Epoch 46; Iter   195/ 1097] train: loss: 0.0107981
[Epoch 46; Iter   225/ 1097] train: loss: 0.0293907
[Epoch 46; Iter   255/ 1097] train: loss: 0.0444941
[Epoch 46; Iter   285/ 1097] train: loss: 0.0184849
[Epoch 46; Iter   315/ 1097] train: loss: 0.0323726
[Epoch 46; Iter   345/ 1097] train: loss: 0.0202343
[Epoch 46; Iter   375/ 1097] train: loss: 0.0234235
[Epoch 46; Iter   405/ 1097] train: loss: 0.0133541
[Epoch 46; Iter   435/ 1097] train: loss: 0.0809998
[Epoch 46; Iter   465/ 1097] train: loss: 0.0440723
[Epoch 46; Iter   495/ 1097] train: loss: 0.0139793
[Epoch 46; Iter   525/ 1097] train: loss: 0.1430716
[Epoch 46; Iter   555/ 1097] train: loss: 0.0113847
[Epoch 46; Iter   585/ 1097] train: loss: 0.0141641
[Epoch 46; Iter   615/ 1097] train: loss: 0.1180184
[Epoch 46; Iter   645/ 1097] train: loss: 0.0450474
[Epoch 46; Iter   675/ 1097] train: loss: 0.1305241
[Epoch 46; Iter   705/ 1097] train: loss: 0.0917085
[Epoch 46; Iter   735/ 1097] train: loss: 0.0125554
[Epoch 46; Iter   765/ 1097] train: loss: 0.0468924
[Epoch 46; Iter   795/ 1097] train: loss: 0.1260078
[Epoch 46; Iter   825/ 1097] train: loss: 0.0306802
[Epoch 46; Iter   855/ 1097] train: loss: 0.0127650
[Epoch 46; Iter   885/ 1097] train: loss: 0.0911983
[Epoch 46; Iter   915/ 1097] train: loss: 0.0439056
[Epoch 46; Iter   945/ 1097] train: loss: 0.0048317
[Epoch 46; Iter   975/ 1097] train: loss: 0.0473490
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0350890
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0767978
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0112629
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0290952
[Epoch 46] ogbg-molhiv: 0.805589 val loss: 0.084060
[Epoch 46] ogbg-molhiv: 0.731621 test loss: 0.252565
[Epoch 47; Iter    28/ 1097] train: loss: 0.0318369
[Epoch 47; Iter    58/ 1097] train: loss: 0.0418911
[Epoch 47; Iter    88/ 1097] train: loss: 0.0101211
[Epoch 47; Iter   118/ 1097] train: loss: 0.0246169
[Epoch 47; Iter   148/ 1097] train: loss: 0.0152452
[Epoch 47; Iter   178/ 1097] train: loss: 0.0345879
[Epoch 47; Iter   208/ 1097] train: loss: 0.0390988
[Epoch 47; Iter   238/ 1097] train: loss: 0.2160293
[Epoch 47; Iter   268/ 1097] train: loss: 0.1002846
[Epoch 47; Iter   298/ 1097] train: loss: 0.1183582
[Epoch 47; Iter   328/ 1097] train: loss: 0.1384796
[Epoch 47; Iter   358/ 1097] train: loss: 0.0566461
[Epoch 47; Iter   388/ 1097] train: loss: 0.0206350
[Epoch 47; Iter   418/ 1097] train: loss: 0.0873220
[Epoch 47; Iter   448/ 1097] train: loss: 0.0332826
[Epoch 47; Iter   478/ 1097] train: loss: 0.1774763
[Epoch 47; Iter   508/ 1097] train: loss: 0.0697319
[Epoch 47; Iter   538/ 1097] train: loss: 0.0081963
[Epoch 47; Iter   568/ 1097] train: loss: 0.1190418
[Epoch 47; Iter   598/ 1097] train: loss: 0.0904559
[Epoch 47; Iter   628/ 1097] train: loss: 0.0176818
[Epoch 47; Iter   658/ 1097] train: loss: 0.0198941
[Epoch 47; Iter   688/ 1097] train: loss: 0.0075525
[Epoch 47; Iter   718/ 1097] train: loss: 0.0196927
[Epoch 47; Iter   748/ 1097] train: loss: 0.0336716
[Epoch 47; Iter   778/ 1097] train: loss: 0.0149498
[Epoch 47; Iter   808/ 1097] train: loss: 0.0055689
[Epoch 47; Iter   838/ 1097] train: loss: 0.0072538
[Epoch 47; Iter   868/ 1097] train: loss: 0.0157442
[Epoch 47; Iter   898/ 1097] train: loss: 0.0195924
[Epoch 47; Iter   928/ 1097] train: loss: 0.0493776
[Epoch 47; Iter   958/ 1097] train: loss: 0.0365484
[Epoch 47; Iter   988/ 1097] train: loss: 0.0366301
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0449324
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0097490
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0368304
[Epoch 47] ogbg-molhiv: 0.815743 val loss: 0.084900
[Epoch 47] ogbg-molhiv: 0.767180 test loss: 0.150536
[Epoch 48; Iter    11/ 1097] train: loss: 0.0132210
[Epoch 48; Iter    41/ 1097] train: loss: 0.0080913
[Epoch 48; Iter    71/ 1097] train: loss: 0.0151493
[Epoch 48; Iter   101/ 1097] train: loss: 0.2305830
[Epoch 48; Iter   131/ 1097] train: loss: 0.0110190
[Epoch 48; Iter   161/ 1097] train: loss: 0.0285441
[Epoch 48; Iter   191/ 1097] train: loss: 0.0721202
[Epoch 48; Iter   221/ 1097] train: loss: 0.0068170
[Epoch 48; Iter   251/ 1097] train: loss: 0.0176363
[Epoch 48; Iter   281/ 1097] train: loss: 0.0096011
[Epoch 48; Iter   311/ 1097] train: loss: 0.0829297
[Epoch 48; Iter   341/ 1097] train: loss: 0.0111778
[Epoch 48; Iter   371/ 1097] train: loss: 0.0575639
[Epoch 48; Iter   401/ 1097] train: loss: 0.0348726
[Epoch 48; Iter   431/ 1097] train: loss: 0.0466102
[Epoch 48; Iter   461/ 1097] train: loss: 0.0294286
[Epoch 48; Iter   491/ 1097] train: loss: 0.0199806
[Epoch 48; Iter   521/ 1097] train: loss: 0.0187394
[Epoch 48; Iter   551/ 1097] train: loss: 0.0279306
[Epoch 48; Iter   581/ 1097] train: loss: 0.2213081
[Epoch 48; Iter   611/ 1097] train: loss: 0.0737951
[Epoch 48; Iter   641/ 1097] train: loss: 0.1235160
[Epoch 48; Iter   671/ 1097] train: loss: 0.0169245
[Epoch 48; Iter   701/ 1097] train: loss: 0.0684802
[Epoch 48; Iter   731/ 1097] train: loss: 0.0070517
[Epoch 48; Iter   761/ 1097] train: loss: 0.2257903
[Epoch 48; Iter   791/ 1097] train: loss: 0.0070248
[Epoch 48; Iter   821/ 1097] train: loss: 0.0156666
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0003286
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0039776
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0123557
[Epoch 56] ogbg-molhiv: 0.671345 val loss: 0.360460
[Epoch 56] ogbg-molhiv: 0.739207 test loss: 0.314031
[Epoch 57; Iter     8/ 1097] train: loss: 0.0024611
[Epoch 57; Iter    38/ 1097] train: loss: 0.0004104
[Epoch 57; Iter    68/ 1097] train: loss: 0.0098117
[Epoch 57; Iter    98/ 1097] train: loss: 0.0017683
[Epoch 57; Iter   128/ 1097] train: loss: 0.0116121
[Epoch 57; Iter   158/ 1097] train: loss: 0.0002995
[Epoch 57; Iter   188/ 1097] train: loss: 0.0053366
[Epoch 57; Iter   218/ 1097] train: loss: 0.0089687
[Epoch 57; Iter   248/ 1097] train: loss: 0.0107607
[Epoch 57; Iter   278/ 1097] train: loss: 0.0095594
[Epoch 57; Iter   308/ 1097] train: loss: 0.0003182
[Epoch 57; Iter   338/ 1097] train: loss: 0.0089392
[Epoch 57; Iter   368/ 1097] train: loss: 0.0004793
[Epoch 57; Iter   398/ 1097] train: loss: 0.0003452
[Epoch 57; Iter   428/ 1097] train: loss: 0.0001061
[Epoch 57; Iter   458/ 1097] train: loss: 0.0036178
[Epoch 57; Iter   488/ 1097] train: loss: 0.2718510
[Epoch 57; Iter   518/ 1097] train: loss: 0.0006327
[Epoch 57; Iter   548/ 1097] train: loss: 0.0078002
[Epoch 57; Iter   578/ 1097] train: loss: 0.0005227
[Epoch 57; Iter   608/ 1097] train: loss: 0.0000513
[Epoch 57; Iter   638/ 1097] train: loss: 0.0060679
[Epoch 57; Iter   668/ 1097] train: loss: 0.0002227
[Epoch 57; Iter   698/ 1097] train: loss: 0.0083224
[Epoch 57; Iter   728/ 1097] train: loss: 0.0003613
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007665
[Epoch 57; Iter   788/ 1097] train: loss: 0.0034774
[Epoch 57; Iter   818/ 1097] train: loss: 0.0044183
[Epoch 57; Iter   848/ 1097] train: loss: 0.0052046
[Epoch 57; Iter   878/ 1097] train: loss: 0.0074673
[Epoch 57; Iter   908/ 1097] train: loss: 0.0016150
[Epoch 57; Iter   938/ 1097] train: loss: 0.0007317
[Epoch 57; Iter   968/ 1097] train: loss: 0.0167736
[Epoch 57; Iter   998/ 1097] train: loss: 0.0999816
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0128556
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0445190
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0071110
[Epoch 57] ogbg-molhiv: 0.654848 val loss: 0.259875
[Epoch 57] ogbg-molhiv: 0.717007 test loss: 0.344799
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002054
[Epoch 58; Iter    51/ 1097] train: loss: 0.0068985
[Epoch 58; Iter    81/ 1097] train: loss: 0.0070533
[Epoch 58; Iter   111/ 1097] train: loss: 0.0001205
[Epoch 58; Iter   141/ 1097] train: loss: 0.0007272
[Epoch 58; Iter   171/ 1097] train: loss: 0.0005777
[Epoch 58; Iter   201/ 1097] train: loss: 0.0136410
[Epoch 58; Iter   231/ 1097] train: loss: 0.0072960
[Epoch 58; Iter   261/ 1097] train: loss: 0.0078941
[Epoch 58; Iter   291/ 1097] train: loss: 0.0169359
[Epoch 58; Iter   321/ 1097] train: loss: 0.0295505
[Epoch 58; Iter   351/ 1097] train: loss: 0.0013993
[Epoch 58; Iter   381/ 1097] train: loss: 0.0112703
[Epoch 58; Iter   411/ 1097] train: loss: 0.0194022
[Epoch 58; Iter   441/ 1097] train: loss: 0.0017791
[Epoch 58; Iter   471/ 1097] train: loss: 0.0010618
[Epoch 58; Iter   501/ 1097] train: loss: 0.0091071
[Epoch 58; Iter   531/ 1097] train: loss: 0.0376695
[Epoch 58; Iter   561/ 1097] train: loss: 0.0002436
[Epoch 58; Iter   591/ 1097] train: loss: 0.0025399
[Epoch 58; Iter   621/ 1097] train: loss: 0.0095745
[Epoch 58; Iter   651/ 1097] train: loss: 0.0001843
[Epoch 58; Iter   681/ 1097] train: loss: 0.0030462
[Epoch 58; Iter   711/ 1097] train: loss: 0.0041160
[Epoch 58; Iter   741/ 1097] train: loss: 0.0005583
[Epoch 58; Iter   771/ 1097] train: loss: 0.0005096
[Epoch 58; Iter   801/ 1097] train: loss: 0.0483317
[Epoch 58; Iter   831/ 1097] train: loss: 0.0052437
[Epoch 58; Iter   861/ 1097] train: loss: 0.0024305
[Epoch 58; Iter   891/ 1097] train: loss: 0.0008565
[Epoch 58; Iter   921/ 1097] train: loss: 0.0005661
[Epoch 58; Iter   951/ 1097] train: loss: 0.0801361
[Epoch 58; Iter   981/ 1097] train: loss: 0.0011634
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0002445
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0273708
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0498363
[Epoch 58] ogbg-molhiv: 0.696505 val loss: 1.198068
[Epoch 58] ogbg-molhiv: 0.739161 test loss: 0.506351
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002519
[Epoch 59; Iter    34/ 1097] train: loss: 0.0004367
[Epoch 59; Iter    64/ 1097] train: loss: 0.0033387
[Epoch 59; Iter    94/ 1097] train: loss: 0.0003597
[Epoch 59; Iter   124/ 1097] train: loss: 0.0003758
[Epoch 59; Iter   154/ 1097] train: loss: 0.0013891
[Epoch 59; Iter   184/ 1097] train: loss: 0.0000764
[Epoch 59; Iter   214/ 1097] train: loss: 0.0001023
[Epoch 59; Iter   244/ 1097] train: loss: 0.0044366
[Epoch 59; Iter   274/ 1097] train: loss: 0.0000769
[Epoch 59; Iter   304/ 1097] train: loss: 0.0315536
[Epoch 59; Iter   334/ 1097] train: loss: 0.0030622
[Epoch 59; Iter   364/ 1097] train: loss: 0.0073507
[Epoch 59; Iter   394/ 1097] train: loss: 0.0045668
[Epoch 59; Iter   424/ 1097] train: loss: 0.0018183
[Epoch 59; Iter   454/ 1097] train: loss: 0.0006826
[Epoch 59; Iter   484/ 1097] train: loss: 0.0022622
[Epoch 59; Iter   514/ 1097] train: loss: 0.0095979
[Epoch 59; Iter   544/ 1097] train: loss: 0.0005762
[Epoch 59; Iter   574/ 1097] train: loss: 0.0041436
[Epoch 59; Iter   604/ 1097] train: loss: 0.0011173
[Epoch 59; Iter   634/ 1097] train: loss: 0.0152005
[Epoch 59; Iter   664/ 1097] train: loss: 0.0119132
[Epoch 59; Iter   694/ 1097] train: loss: 0.0034717
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001987
[Epoch 59; Iter   754/ 1097] train: loss: 0.0043749
[Epoch 59; Iter   784/ 1097] train: loss: 0.0014093
[Epoch 59; Iter   814/ 1097] train: loss: 0.0002835
[Epoch 59; Iter   844/ 1097] train: loss: 0.0052753
[Epoch 59; Iter   874/ 1097] train: loss: 0.0748578
[Epoch 59; Iter   904/ 1097] train: loss: 0.0006941
[Epoch 59; Iter   934/ 1097] train: loss: 0.0421101
[Epoch 59; Iter   964/ 1097] train: loss: 0.0004427
[Epoch 59; Iter   994/ 1097] train: loss: 0.0023113
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0095397
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0025999
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0113199
[Epoch 59] ogbg-molhiv: 0.733383 val loss: 0.194301
[Epoch 59] ogbg-molhiv: 0.738448 test loss: 0.308387
[Epoch 60; Iter    17/ 1097] train: loss: 0.0224152
[Epoch 60; Iter    47/ 1097] train: loss: 0.0043935
[Epoch 60; Iter    77/ 1097] train: loss: 0.0005322
[Epoch 60; Iter   107/ 1097] train: loss: 0.0197291
[Epoch 60; Iter   137/ 1097] train: loss: 0.0064587
[Epoch 60; Iter   167/ 1097] train: loss: 0.0026241
[Epoch 60; Iter   197/ 1097] train: loss: 0.1051992
[Epoch 60; Iter   227/ 1097] train: loss: 0.0138898
[Epoch 60; Iter   257/ 1097] train: loss: 0.0031357
[Epoch 60; Iter   287/ 1097] train: loss: 0.0077376
[Epoch 60; Iter   317/ 1097] train: loss: 0.0014416
[Epoch 60; Iter   347/ 1097] train: loss: 0.0065306
[Epoch 60; Iter   377/ 1097] train: loss: 0.0040330
[Epoch 60; Iter   407/ 1097] train: loss: 0.0016877
[Epoch 60; Iter   437/ 1097] train: loss: 0.0012631
[Epoch 60; Iter   467/ 1097] train: loss: 0.0001543
[Epoch 60; Iter   497/ 1097] train: loss: 0.0000896
[Epoch 60; Iter   527/ 1097] train: loss: 0.0019864
[Epoch 60; Iter   557/ 1097] train: loss: 0.0047822
[Epoch 60; Iter   587/ 1097] train: loss: 0.0014155
[Epoch 60; Iter   617/ 1097] train: loss: 0.0018574
[Epoch 60; Iter   647/ 1097] train: loss: 0.0007508
[Epoch 60; Iter   677/ 1097] train: loss: 0.0004278
[Epoch 60; Iter   707/ 1097] train: loss: 0.0024886
[Epoch 60; Iter   737/ 1097] train: loss: 0.0002334
[Epoch 60; Iter   767/ 1097] train: loss: 0.0002004
[Epoch 60; Iter   797/ 1097] train: loss: 0.0000456
[Epoch 60; Iter   827/ 1097] train: loss: 0.0023669
[Epoch 60; Iter   857/ 1097] train: loss: 0.0019718
[Epoch 60; Iter   887/ 1097] train: loss: 0.0011000
[Epoch 60; Iter   917/ 1097] train: loss: 0.0217625
[Epoch 60; Iter   947/ 1097] train: loss: 0.0234474
[Epoch 60; Iter   977/ 1097] train: loss: 0.0003028
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0972981
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0168197
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0012016
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0014639
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0791467
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0024930
[Epoch 56] ogbg-molhiv: 0.725061 val loss: 1.529102
[Epoch 56] ogbg-molhiv: 0.730070 test loss: 0.933466
[Epoch 57; Iter     8/ 1097] train: loss: 0.0012984
[Epoch 57; Iter    38/ 1097] train: loss: 0.0003761
[Epoch 57; Iter    68/ 1097] train: loss: 0.0001632
[Epoch 57; Iter    98/ 1097] train: loss: 0.0003806
[Epoch 57; Iter   128/ 1097] train: loss: 0.0016249
[Epoch 57; Iter   158/ 1097] train: loss: 0.0002669
[Epoch 57; Iter   188/ 1097] train: loss: 0.0412782
[Epoch 57; Iter   218/ 1097] train: loss: 0.0048640
[Epoch 57; Iter   248/ 1097] train: loss: 0.0308455
[Epoch 57; Iter   278/ 1097] train: loss: 0.0004026
[Epoch 57; Iter   308/ 1097] train: loss: 0.0251498
[Epoch 57; Iter   338/ 1097] train: loss: 0.0019438
[Epoch 57; Iter   368/ 1097] train: loss: 0.0025957
[Epoch 57; Iter   398/ 1097] train: loss: 0.0021998
[Epoch 57; Iter   428/ 1097] train: loss: 0.0225105
[Epoch 57; Iter   458/ 1097] train: loss: 0.0026974
[Epoch 57; Iter   488/ 1097] train: loss: 0.0300414
[Epoch 57; Iter   518/ 1097] train: loss: 0.0028585
[Epoch 57; Iter   548/ 1097] train: loss: 0.0193771
[Epoch 57; Iter   578/ 1097] train: loss: 0.0014537
[Epoch 57; Iter   608/ 1097] train: loss: 0.1493990
[Epoch 57; Iter   638/ 1097] train: loss: 0.0244643
[Epoch 57; Iter   668/ 1097] train: loss: 0.0019984
[Epoch 57; Iter   698/ 1097] train: loss: 0.0114854
[Epoch 57; Iter   728/ 1097] train: loss: 0.0027894
[Epoch 57; Iter   758/ 1097] train: loss: 0.0098471
[Epoch 57; Iter   788/ 1097] train: loss: 0.0019862
[Epoch 57; Iter   818/ 1097] train: loss: 0.0787888
[Epoch 57; Iter   848/ 1097] train: loss: 0.0058881
[Epoch 57; Iter   878/ 1097] train: loss: 0.0052305
[Epoch 57; Iter   908/ 1097] train: loss: 0.0072854
[Epoch 57; Iter   938/ 1097] train: loss: 0.0402373
[Epoch 57; Iter   968/ 1097] train: loss: 0.0262033
[Epoch 57; Iter   998/ 1097] train: loss: 0.0160230
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0119460
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0021188
[Epoch 57; Iter  1088/ 1097] train: loss: 0.1126415
[Epoch 57] ogbg-molhiv: 0.689420 val loss: 6.000117
[Epoch 57] ogbg-molhiv: 0.673329 test loss: 2.946623
[Epoch 58; Iter    21/ 1097] train: loss: 0.1739553
[Epoch 58; Iter    51/ 1097] train: loss: 0.0042350
[Epoch 58; Iter    81/ 1097] train: loss: 0.0012920
[Epoch 58; Iter   111/ 1097] train: loss: 0.0047988
[Epoch 58; Iter   141/ 1097] train: loss: 0.0019310
[Epoch 58; Iter   171/ 1097] train: loss: 0.0005529
[Epoch 58; Iter   201/ 1097] train: loss: 0.0938668
[Epoch 58; Iter   231/ 1097] train: loss: 0.0004746
[Epoch 58; Iter   261/ 1097] train: loss: 0.0093066
[Epoch 58; Iter   291/ 1097] train: loss: 0.0159109
[Epoch 58; Iter   321/ 1097] train: loss: 0.0069939
[Epoch 58; Iter   351/ 1097] train: loss: 0.0718067
[Epoch 58; Iter   381/ 1097] train: loss: 0.0050191
[Epoch 58; Iter   411/ 1097] train: loss: 0.0211114
[Epoch 58; Iter   441/ 1097] train: loss: 0.0399153
[Epoch 58; Iter   471/ 1097] train: loss: 0.0435817
[Epoch 58; Iter   501/ 1097] train: loss: 0.0029856
[Epoch 58; Iter   531/ 1097] train: loss: 0.0027930
[Epoch 58; Iter   561/ 1097] train: loss: 0.0063565
[Epoch 58; Iter   591/ 1097] train: loss: 0.0084843
[Epoch 58; Iter   621/ 1097] train: loss: 0.0009176
[Epoch 58; Iter   651/ 1097] train: loss: 0.0083403
[Epoch 58; Iter   681/ 1097] train: loss: 0.0181148
[Epoch 58; Iter   711/ 1097] train: loss: 0.0843930
[Epoch 58; Iter   741/ 1097] train: loss: 0.0502173
[Epoch 58; Iter   771/ 1097] train: loss: 0.0012864
[Epoch 58; Iter   801/ 1097] train: loss: 0.0033355
[Epoch 58; Iter   831/ 1097] train: loss: 0.0441062
[Epoch 58; Iter   861/ 1097] train: loss: 0.0327022
[Epoch 58; Iter   891/ 1097] train: loss: 0.0170550
[Epoch 58; Iter   921/ 1097] train: loss: 0.0063270
[Epoch 58; Iter   951/ 1097] train: loss: 0.0308696
[Epoch 58; Iter   981/ 1097] train: loss: 0.0008969
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0057313
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0036877
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0505977
[Epoch 58] ogbg-molhiv: 0.716135 val loss: 2.517565
[Epoch 58] ogbg-molhiv: 0.713357 test loss: 0.848195
[Epoch 59; Iter     4/ 1097] train: loss: 0.0098575
[Epoch 59; Iter    34/ 1097] train: loss: 0.0107470
[Epoch 59; Iter    64/ 1097] train: loss: 0.0015889
[Epoch 59; Iter    94/ 1097] train: loss: 0.0396544
[Epoch 59; Iter   124/ 1097] train: loss: 0.0005957
[Epoch 59; Iter   154/ 1097] train: loss: 0.0314725
[Epoch 59; Iter   184/ 1097] train: loss: 0.0034178
[Epoch 59; Iter   214/ 1097] train: loss: 0.0064126
[Epoch 59; Iter   244/ 1097] train: loss: 0.0003032
[Epoch 59; Iter   274/ 1097] train: loss: 0.0083336
[Epoch 59; Iter   304/ 1097] train: loss: 0.0252952
[Epoch 59; Iter   334/ 1097] train: loss: 0.0021803
[Epoch 59; Iter   364/ 1097] train: loss: 0.0020659
[Epoch 59; Iter   394/ 1097] train: loss: 0.0006222
[Epoch 59; Iter   424/ 1097] train: loss: 0.0134565
[Epoch 59; Iter   454/ 1097] train: loss: 0.0127218
[Epoch 59; Iter   484/ 1097] train: loss: 0.0012401
[Epoch 59; Iter   514/ 1097] train: loss: 0.0006948
[Epoch 59; Iter   544/ 1097] train: loss: 0.0113233
[Epoch 59; Iter   574/ 1097] train: loss: 0.0040843
[Epoch 59; Iter   604/ 1097] train: loss: 0.0015680
[Epoch 59; Iter   634/ 1097] train: loss: 0.0096393
[Epoch 59; Iter   664/ 1097] train: loss: 0.0022820
[Epoch 59; Iter   694/ 1097] train: loss: 0.0179429
[Epoch 59; Iter   724/ 1097] train: loss: 0.0039870
[Epoch 59; Iter   754/ 1097] train: loss: 0.0009588
[Epoch 59; Iter   784/ 1097] train: loss: 0.0015653
[Epoch 59; Iter   814/ 1097] train: loss: 0.0013824
[Epoch 59; Iter   844/ 1097] train: loss: 0.0006899
[Epoch 59; Iter   874/ 1097] train: loss: 0.0741757
[Epoch 59; Iter   904/ 1097] train: loss: 0.0086646
[Epoch 59; Iter   934/ 1097] train: loss: 0.0016005
[Epoch 59; Iter   964/ 1097] train: loss: 0.0043849
[Epoch 59; Iter   994/ 1097] train: loss: 0.0119792
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0128838
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0006426
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0007847
[Epoch 59] ogbg-molhiv: 0.701413 val loss: 1.688973
[Epoch 59] ogbg-molhiv: 0.720051 test loss: 0.645727
[Epoch 60; Iter    17/ 1097] train: loss: 0.0747419
[Epoch 60; Iter    47/ 1097] train: loss: 0.0405551
[Epoch 60; Iter    77/ 1097] train: loss: 0.0085400
[Epoch 60; Iter   107/ 1097] train: loss: 0.0260374
[Epoch 60; Iter   137/ 1097] train: loss: 0.0002808
[Epoch 60; Iter   167/ 1097] train: loss: 0.0059802
[Epoch 60; Iter   197/ 1097] train: loss: 0.0120490
[Epoch 60; Iter   227/ 1097] train: loss: 0.0895654
[Epoch 60; Iter   257/ 1097] train: loss: 0.0081202
[Epoch 60; Iter   287/ 1097] train: loss: 0.0004383
[Epoch 60; Iter   317/ 1097] train: loss: 0.0026970
[Epoch 60; Iter   347/ 1097] train: loss: 0.0349052
[Epoch 60; Iter   377/ 1097] train: loss: 0.0008598
[Epoch 60; Iter   407/ 1097] train: loss: 0.0004478
[Epoch 60; Iter   437/ 1097] train: loss: 0.0051448
[Epoch 60; Iter   467/ 1097] train: loss: 0.0171800
[Epoch 60; Iter   497/ 1097] train: loss: 0.0004575
[Epoch 60; Iter   527/ 1097] train: loss: 0.0210918
[Epoch 60; Iter   557/ 1097] train: loss: 0.0007378
[Epoch 60; Iter   587/ 1097] train: loss: 0.0203947
[Epoch 60; Iter   617/ 1097] train: loss: 0.0010406
[Epoch 60; Iter   647/ 1097] train: loss: 0.0340191
[Epoch 60; Iter   677/ 1097] train: loss: 0.0036828
[Epoch 60; Iter   707/ 1097] train: loss: 0.0004783
[Epoch 60; Iter   737/ 1097] train: loss: 0.0010689
[Epoch 60; Iter   767/ 1097] train: loss: 0.1916140
[Epoch 60; Iter   797/ 1097] train: loss: 0.0019004
[Epoch 60; Iter   827/ 1097] train: loss: 0.0017594
[Epoch 60; Iter   857/ 1097] train: loss: 0.0001126
[Epoch 60; Iter   887/ 1097] train: loss: 0.0003049
[Epoch 60; Iter   917/ 1097] train: loss: 0.0230762
[Epoch 60; Iter   947/ 1097] train: loss: 0.0027122
[Epoch 60; Iter   977/ 1097] train: loss: 0.0274573
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0061065
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0086500
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0024059
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0047963
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0049102
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0618107
[Epoch 56] ogbg-molhiv: 0.772860 val loss: 0.279071
[Epoch 56] ogbg-molhiv: 0.752711 test loss: 0.305997
[Epoch 57; Iter     8/ 1097] train: loss: 0.0002752
[Epoch 57; Iter    38/ 1097] train: loss: 0.0002855
[Epoch 57; Iter    68/ 1097] train: loss: 0.0006532
[Epoch 57; Iter    98/ 1097] train: loss: 0.0105995
[Epoch 57; Iter   128/ 1097] train: loss: 0.0018338
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000604
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023726
[Epoch 57; Iter   218/ 1097] train: loss: 0.0001329
[Epoch 57; Iter   248/ 1097] train: loss: 0.0025123
[Epoch 57; Iter   278/ 1097] train: loss: 0.0026994
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005770
[Epoch 57; Iter   338/ 1097] train: loss: 0.0001940
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001486
[Epoch 57; Iter   398/ 1097] train: loss: 0.0009665
[Epoch 57; Iter   428/ 1097] train: loss: 0.0049412
[Epoch 57; Iter   458/ 1097] train: loss: 0.0018863
[Epoch 57; Iter   488/ 1097] train: loss: 0.0003497
[Epoch 57; Iter   518/ 1097] train: loss: 0.0148051
[Epoch 57; Iter   548/ 1097] train: loss: 0.0039035
[Epoch 57; Iter   578/ 1097] train: loss: 0.0114963
[Epoch 57; Iter   608/ 1097] train: loss: 0.0077783
[Epoch 57; Iter   638/ 1097] train: loss: 0.0040632
[Epoch 57; Iter   668/ 1097] train: loss: 0.0091001
[Epoch 57; Iter   698/ 1097] train: loss: 0.0015888
[Epoch 57; Iter   728/ 1097] train: loss: 0.0015968
[Epoch 57; Iter   758/ 1097] train: loss: 0.0001357
[Epoch 57; Iter   788/ 1097] train: loss: 0.1301500
[Epoch 57; Iter   818/ 1097] train: loss: 0.0100291
[Epoch 57; Iter   848/ 1097] train: loss: 0.0299003
[Epoch 57; Iter   878/ 1097] train: loss: 0.0031015
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005176
[Epoch 57; Iter   938/ 1097] train: loss: 0.0030745
[Epoch 57; Iter   968/ 1097] train: loss: 0.0063760
[Epoch 57; Iter   998/ 1097] train: loss: 0.0005965
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0003880
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003470
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0006665
[Epoch 57] ogbg-molhiv: 0.771455 val loss: 0.276665
[Epoch 57] ogbg-molhiv: 0.744382 test loss: 0.261859
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002006
[Epoch 58; Iter    51/ 1097] train: loss: 0.0004367
[Epoch 58; Iter    81/ 1097] train: loss: 0.0002432
[Epoch 58; Iter   111/ 1097] train: loss: 0.0002438
[Epoch 58; Iter   141/ 1097] train: loss: 0.0004795
[Epoch 58; Iter   171/ 1097] train: loss: 0.0015323
[Epoch 58; Iter   201/ 1097] train: loss: 0.0027338
[Epoch 58; Iter   231/ 1097] train: loss: 0.0223957
[Epoch 58; Iter   261/ 1097] train: loss: 0.0004112
[Epoch 58; Iter   291/ 1097] train: loss: 0.0003503
[Epoch 58; Iter   321/ 1097] train: loss: 0.0022790
[Epoch 58; Iter   351/ 1097] train: loss: 0.0070012
[Epoch 58; Iter   381/ 1097] train: loss: 0.0009999
[Epoch 58; Iter   411/ 1097] train: loss: 0.0010581
[Epoch 58; Iter   441/ 1097] train: loss: 0.0018167
[Epoch 58; Iter   471/ 1097] train: loss: 0.0163482
[Epoch 58; Iter   501/ 1097] train: loss: 0.0029094
[Epoch 58; Iter   531/ 1097] train: loss: 0.0015594
[Epoch 58; Iter   561/ 1097] train: loss: 0.0007350
[Epoch 58; Iter   591/ 1097] train: loss: 0.0012775
[Epoch 58; Iter   621/ 1097] train: loss: 0.0761527
[Epoch 58; Iter   651/ 1097] train: loss: 0.0018141
[Epoch 58; Iter   681/ 1097] train: loss: 0.0054593
[Epoch 58; Iter   711/ 1097] train: loss: 0.0118868
[Epoch 58; Iter   741/ 1097] train: loss: 0.0061091
[Epoch 58; Iter   771/ 1097] train: loss: 0.0001247
[Epoch 58; Iter   801/ 1097] train: loss: 0.0005761
[Epoch 58; Iter   831/ 1097] train: loss: 0.0014317
[Epoch 58; Iter   861/ 1097] train: loss: 0.0005867
[Epoch 58; Iter   891/ 1097] train: loss: 0.0001937
[Epoch 58; Iter   921/ 1097] train: loss: 0.0047170
[Epoch 58; Iter   951/ 1097] train: loss: 0.0001170
[Epoch 58; Iter   981/ 1097] train: loss: 0.0050159
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0001250
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0001467
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0506568
[Epoch 58] ogbg-molhiv: 0.784636 val loss: 0.293226
[Epoch 58] ogbg-molhiv: 0.741594 test loss: 0.310647
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002586
[Epoch 59; Iter    34/ 1097] train: loss: 0.0078824
[Epoch 59; Iter    64/ 1097] train: loss: 0.0388659
[Epoch 59; Iter    94/ 1097] train: loss: 0.0015580
[Epoch 59; Iter   124/ 1097] train: loss: 0.0016822
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000407
[Epoch 59; Iter   184/ 1097] train: loss: 0.0008144
[Epoch 59; Iter   214/ 1097] train: loss: 0.0003181
[Epoch 59; Iter   244/ 1097] train: loss: 0.0000570
[Epoch 59; Iter   274/ 1097] train: loss: 0.0015524
[Epoch 59; Iter   304/ 1097] train: loss: 0.0000919
[Epoch 59; Iter   334/ 1097] train: loss: 0.0051319
[Epoch 59; Iter   364/ 1097] train: loss: 0.0024547
[Epoch 59; Iter   394/ 1097] train: loss: 0.0019371
[Epoch 59; Iter   424/ 1097] train: loss: 0.0001206
[Epoch 59; Iter   454/ 1097] train: loss: 0.0009854
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007053
[Epoch 59; Iter   514/ 1097] train: loss: 0.0035710
[Epoch 59; Iter   544/ 1097] train: loss: 0.0133519
[Epoch 59; Iter   574/ 1097] train: loss: 0.0121329
[Epoch 59; Iter   604/ 1097] train: loss: 0.0037318
[Epoch 59; Iter   634/ 1097] train: loss: 0.0004775
[Epoch 59; Iter   664/ 1097] train: loss: 0.0003002
[Epoch 59; Iter   694/ 1097] train: loss: 0.0005049
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001187
[Epoch 59; Iter   754/ 1097] train: loss: 0.0229635
[Epoch 59; Iter   784/ 1097] train: loss: 0.0011126
[Epoch 59; Iter   814/ 1097] train: loss: 0.0137631
[Epoch 59; Iter   844/ 1097] train: loss: 0.0002078
[Epoch 59; Iter   874/ 1097] train: loss: 0.0082950
[Epoch 59; Iter   904/ 1097] train: loss: 0.0011618
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001831
[Epoch 59; Iter   964/ 1097] train: loss: 0.0004172
[Epoch 59; Iter   994/ 1097] train: loss: 0.0036091
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0000914
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0004729
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0011380
[Epoch 59] ogbg-molhiv: 0.763730 val loss: 0.267400
[Epoch 59] ogbg-molhiv: 0.750414 test loss: 0.300179
[Epoch 60; Iter    17/ 1097] train: loss: 0.0000653
[Epoch 60; Iter    47/ 1097] train: loss: 0.0000809
[Epoch 60; Iter    77/ 1097] train: loss: 0.0074894
[Epoch 60; Iter   107/ 1097] train: loss: 0.0002337
[Epoch 60; Iter   137/ 1097] train: loss: 0.0587191
[Epoch 60; Iter   167/ 1097] train: loss: 0.0001593
[Epoch 60; Iter   197/ 1097] train: loss: 0.0008668
[Epoch 60; Iter   227/ 1097] train: loss: 0.0055796
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001444
[Epoch 60; Iter   287/ 1097] train: loss: 0.0001021
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003889
[Epoch 60; Iter   347/ 1097] train: loss: 0.0021350
[Epoch 60; Iter   377/ 1097] train: loss: 0.0002458
[Epoch 60; Iter   407/ 1097] train: loss: 0.0000978
[Epoch 60; Iter   437/ 1097] train: loss: 0.0078508
[Epoch 60; Iter   467/ 1097] train: loss: 0.0081572
[Epoch 60; Iter   497/ 1097] train: loss: 0.0167396
[Epoch 60; Iter   527/ 1097] train: loss: 0.0010222
[Epoch 60; Iter   557/ 1097] train: loss: 0.0012075
[Epoch 60; Iter   587/ 1097] train: loss: 0.0024916
[Epoch 60; Iter   617/ 1097] train: loss: 0.0002975
[Epoch 60; Iter   647/ 1097] train: loss: 0.0004742
[Epoch 60; Iter   677/ 1097] train: loss: 0.0076788
[Epoch 60; Iter   707/ 1097] train: loss: 0.0002554
[Epoch 60; Iter   737/ 1097] train: loss: 0.0034423
[Epoch 60; Iter   767/ 1097] train: loss: 0.0006371
[Epoch 60; Iter   797/ 1097] train: loss: 0.0002117
[Epoch 60; Iter   827/ 1097] train: loss: 0.0000768
[Epoch 60; Iter   857/ 1097] train: loss: 0.0139295
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001865
[Epoch 60; Iter   917/ 1097] train: loss: 0.0069005
[Epoch 60; Iter   947/ 1097] train: loss: 0.0220749
[Epoch 60; Iter   977/ 1097] train: loss: 0.0055831
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0006070
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0002217
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0003514
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000637
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0039209
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0062842
[Epoch 56] ogbg-molhiv: 0.779107 val loss: 0.192194
[Epoch 56] ogbg-molhiv: 0.737448 test loss: 0.340016
[Epoch 57; Iter     8/ 1097] train: loss: 0.0080982
[Epoch 57; Iter    38/ 1097] train: loss: 0.0007964
[Epoch 57; Iter    68/ 1097] train: loss: 0.0004282
[Epoch 57; Iter    98/ 1097] train: loss: 0.0078138
[Epoch 57; Iter   128/ 1097] train: loss: 0.0022961
[Epoch 57; Iter   158/ 1097] train: loss: 0.0055196
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023466
[Epoch 57; Iter   218/ 1097] train: loss: 0.0026420
[Epoch 57; Iter   248/ 1097] train: loss: 0.0005948
[Epoch 57; Iter   278/ 1097] train: loss: 0.0000675
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005465
[Epoch 57; Iter   338/ 1097] train: loss: 0.0001897
[Epoch 57; Iter   368/ 1097] train: loss: 0.0397476
[Epoch 57; Iter   398/ 1097] train: loss: 0.0336130
[Epoch 57; Iter   428/ 1097] train: loss: 0.0220011
[Epoch 57; Iter   458/ 1097] train: loss: 0.0022127
[Epoch 57; Iter   488/ 1097] train: loss: 0.0032239
[Epoch 57; Iter   518/ 1097] train: loss: 0.0003963
[Epoch 57; Iter   548/ 1097] train: loss: 0.0244291
[Epoch 57; Iter   578/ 1097] train: loss: 0.0003114
[Epoch 57; Iter   608/ 1097] train: loss: 0.0274337
[Epoch 57; Iter   638/ 1097] train: loss: 0.0014323
[Epoch 57; Iter   668/ 1097] train: loss: 0.0006151
[Epoch 57; Iter   698/ 1097] train: loss: 0.0468526
[Epoch 57; Iter   728/ 1097] train: loss: 0.0005883
[Epoch 57; Iter   758/ 1097] train: loss: 0.0034618
[Epoch 57; Iter   788/ 1097] train: loss: 0.0034749
[Epoch 57; Iter   818/ 1097] train: loss: 0.0013460
[Epoch 57; Iter   848/ 1097] train: loss: 0.0000559
[Epoch 57; Iter   878/ 1097] train: loss: 0.0021468
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005819
[Epoch 57; Iter   938/ 1097] train: loss: 0.0049393
[Epoch 57; Iter   968/ 1097] train: loss: 0.0007679
[Epoch 57; Iter   998/ 1097] train: loss: 0.0008456
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0200953
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0045316
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0015841
[Epoch 57] ogbg-molhiv: 0.755502 val loss: 0.171281
[Epoch 57] ogbg-molhiv: 0.698782 test loss: 0.303118
[Epoch 58; Iter    21/ 1097] train: loss: 0.0002392
[Epoch 58; Iter    51/ 1097] train: loss: 0.0016182
[Epoch 58; Iter    81/ 1097] train: loss: 0.0000746
[Epoch 58; Iter   111/ 1097] train: loss: 0.0005065
[Epoch 58; Iter   141/ 1097] train: loss: 0.0018523
[Epoch 58; Iter   171/ 1097] train: loss: 0.0018044
[Epoch 58; Iter   201/ 1097] train: loss: 0.0293751
[Epoch 58; Iter   231/ 1097] train: loss: 0.0467128
[Epoch 58; Iter   261/ 1097] train: loss: 0.0020168
[Epoch 58; Iter   291/ 1097] train: loss: 0.0058726
[Epoch 58; Iter   321/ 1097] train: loss: 0.0023651
[Epoch 58; Iter   351/ 1097] train: loss: 0.0000573
[Epoch 58; Iter   381/ 1097] train: loss: 0.0186978
[Epoch 58; Iter   411/ 1097] train: loss: 0.0003756
[Epoch 58; Iter   441/ 1097] train: loss: 0.0001628
[Epoch 58; Iter   471/ 1097] train: loss: 0.0012990
[Epoch 58; Iter   501/ 1097] train: loss: 0.0001565
[Epoch 58; Iter   531/ 1097] train: loss: 0.0003597
[Epoch 58; Iter   561/ 1097] train: loss: 0.0007687
[Epoch 58; Iter   591/ 1097] train: loss: 0.0004185
[Epoch 58; Iter   621/ 1097] train: loss: 0.0007356
[Epoch 58; Iter   651/ 1097] train: loss: 0.0006584
[Epoch 58; Iter   681/ 1097] train: loss: 0.0030540
[Epoch 58; Iter   711/ 1097] train: loss: 0.0031072
[Epoch 58; Iter   741/ 1097] train: loss: 0.0020601
[Epoch 58; Iter   771/ 1097] train: loss: 0.0004624
[Epoch 58; Iter   801/ 1097] train: loss: 0.0016194
[Epoch 58; Iter   831/ 1097] train: loss: 0.0182242
[Epoch 58; Iter   861/ 1097] train: loss: 0.0005509
[Epoch 58; Iter   891/ 1097] train: loss: 0.0010528
[Epoch 58; Iter   921/ 1097] train: loss: 0.0005608
[Epoch 58; Iter   951/ 1097] train: loss: 0.0034381
[Epoch 58; Iter   981/ 1097] train: loss: 0.0041989
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0005318
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0016878
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0003646
[Epoch 58] ogbg-molhiv: 0.755937 val loss: 0.209019
[Epoch 58] ogbg-molhiv: 0.685589 test loss: 0.324582
[Epoch 59; Iter     4/ 1097] train: loss: 0.0108423
[Epoch 59; Iter    34/ 1097] train: loss: 0.0003165
[Epoch 59; Iter    64/ 1097] train: loss: 0.0002424
[Epoch 59; Iter    94/ 1097] train: loss: 0.0013992
[Epoch 59; Iter   124/ 1097] train: loss: 0.0012979
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000933
[Epoch 59; Iter   184/ 1097] train: loss: 0.0015321
[Epoch 59; Iter   214/ 1097] train: loss: 0.0001738
[Epoch 59; Iter   244/ 1097] train: loss: 0.0005414
[Epoch 59; Iter   274/ 1097] train: loss: 0.0153148
[Epoch 59; Iter   304/ 1097] train: loss: 0.0286019
[Epoch 59; Iter   334/ 1097] train: loss: 0.0038318
[Epoch 59; Iter   364/ 1097] train: loss: 0.0008551
[Epoch 59; Iter   394/ 1097] train: loss: 0.0051812
[Epoch 59; Iter   424/ 1097] train: loss: 0.0039603
[Epoch 59; Iter   454/ 1097] train: loss: 0.0082870
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007878
[Epoch 59; Iter   514/ 1097] train: loss: 0.0101784
[Epoch 59; Iter   544/ 1097] train: loss: 0.0023163
[Epoch 59; Iter   574/ 1097] train: loss: 0.0004435
[Epoch 59; Iter   604/ 1097] train: loss: 0.0002632
[Epoch 59; Iter   634/ 1097] train: loss: 0.0023235
[Epoch 59; Iter   664/ 1097] train: loss: 0.0011284
[Epoch 59; Iter   694/ 1097] train: loss: 0.0009278
[Epoch 59; Iter   724/ 1097] train: loss: 0.0457641
[Epoch 59; Iter   754/ 1097] train: loss: 0.0018719
[Epoch 59; Iter   784/ 1097] train: loss: 0.0023863
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000724
[Epoch 59; Iter   844/ 1097] train: loss: 0.1542762
[Epoch 59; Iter   874/ 1097] train: loss: 0.0006984
[Epoch 59; Iter   904/ 1097] train: loss: 0.0003742
[Epoch 59; Iter   934/ 1097] train: loss: 0.0152872
[Epoch 59; Iter   964/ 1097] train: loss: 0.0023224
[Epoch 59; Iter   994/ 1097] train: loss: 0.0005077
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0006160
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0013695
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0015460
[Epoch 59] ogbg-molhiv: 0.788292 val loss: 0.192762
[Epoch 59] ogbg-molhiv: 0.743709 test loss: 0.304059
[Epoch 60; Iter    17/ 1097] train: loss: 0.0002995
[Epoch 60; Iter    47/ 1097] train: loss: 0.0001203
[Epoch 60; Iter    77/ 1097] train: loss: 0.0042175
[Epoch 60; Iter   107/ 1097] train: loss: 0.1315386
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000919
[Epoch 60; Iter   167/ 1097] train: loss: 0.0012853
[Epoch 60; Iter   197/ 1097] train: loss: 0.0018053
[Epoch 60; Iter   227/ 1097] train: loss: 0.0030160
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001401
[Epoch 60; Iter   287/ 1097] train: loss: 0.0002890
[Epoch 60; Iter   317/ 1097] train: loss: 0.0020090
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001968
[Epoch 60; Iter   377/ 1097] train: loss: 0.0301416
[Epoch 60; Iter   407/ 1097] train: loss: 0.0005065
[Epoch 60; Iter   437/ 1097] train: loss: 0.0110286
[Epoch 60; Iter   467/ 1097] train: loss: 0.0007489
[Epoch 60; Iter   497/ 1097] train: loss: 0.0002752
[Epoch 60; Iter   527/ 1097] train: loss: 0.0957194
[Epoch 60; Iter   557/ 1097] train: loss: 0.0050052
[Epoch 60; Iter   587/ 1097] train: loss: 0.0073052
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001893
[Epoch 60; Iter   647/ 1097] train: loss: 0.0022341
[Epoch 60; Iter   677/ 1097] train: loss: 0.0008038
[Epoch 60; Iter   707/ 1097] train: loss: 0.0026671
[Epoch 60; Iter   737/ 1097] train: loss: 0.0027948
[Epoch 60; Iter   767/ 1097] train: loss: 0.1048423
[Epoch 60; Iter   797/ 1097] train: loss: 0.0040392
[Epoch 60; Iter   827/ 1097] train: loss: 0.0016169
[Epoch 60; Iter   857/ 1097] train: loss: 0.0019321
[Epoch 60; Iter   887/ 1097] train: loss: 0.0003320
[Epoch 60; Iter   917/ 1097] train: loss: 0.0004599
[Epoch 60; Iter   947/ 1097] train: loss: 0.0003978
[Epoch 60; Iter   977/ 1097] train: loss: 0.0011970
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0086831
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0311290
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0023981
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0025274
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0332523
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0016420
[Epoch 56] ogbg-molhiv: 0.788522 val loss: 0.198983
[Epoch 56] ogbg-molhiv: 0.735856 test loss: 0.325227
[Epoch 57; Iter     8/ 1097] train: loss: 0.0001515
[Epoch 57; Iter    38/ 1097] train: loss: 0.0074106
[Epoch 57; Iter    68/ 1097] train: loss: 0.0296389
[Epoch 57; Iter    98/ 1097] train: loss: 0.0033440
[Epoch 57; Iter   128/ 1097] train: loss: 0.0018282
[Epoch 57; Iter   158/ 1097] train: loss: 0.0084361
[Epoch 57; Iter   188/ 1097] train: loss: 0.0023310
[Epoch 57; Iter   218/ 1097] train: loss: 0.0047967
[Epoch 57; Iter   248/ 1097] train: loss: 0.0016970
[Epoch 57; Iter   278/ 1097] train: loss: 0.0002474
[Epoch 57; Iter   308/ 1097] train: loss: 0.0010837
[Epoch 57; Iter   338/ 1097] train: loss: 0.0005564
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001941
[Epoch 57; Iter   398/ 1097] train: loss: 0.0010750
[Epoch 57; Iter   428/ 1097] train: loss: 0.0007350
[Epoch 57; Iter   458/ 1097] train: loss: 0.0022308
[Epoch 57; Iter   488/ 1097] train: loss: 0.0010137
[Epoch 57; Iter   518/ 1097] train: loss: 0.0001194
[Epoch 57; Iter   548/ 1097] train: loss: 0.0027326
[Epoch 57; Iter   578/ 1097] train: loss: 0.0593566
[Epoch 57; Iter   608/ 1097] train: loss: 0.1062663
[Epoch 57; Iter   638/ 1097] train: loss: 0.0002109
[Epoch 57; Iter   668/ 1097] train: loss: 0.0248921
[Epoch 57; Iter   698/ 1097] train: loss: 0.0002250
[Epoch 57; Iter   728/ 1097] train: loss: 0.0012580
[Epoch 57; Iter   758/ 1097] train: loss: 0.0015936
[Epoch 57; Iter   788/ 1097] train: loss: 0.0409803
[Epoch 57; Iter   818/ 1097] train: loss: 0.0668946
[Epoch 57; Iter   848/ 1097] train: loss: 0.0021253
[Epoch 57; Iter   878/ 1097] train: loss: 0.0009592
[Epoch 57; Iter   908/ 1097] train: loss: 0.0018604
[Epoch 57; Iter   938/ 1097] train: loss: 0.0021164
[Epoch 57; Iter   968/ 1097] train: loss: 0.0004193
[Epoch 57; Iter   998/ 1097] train: loss: 0.0003296
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0001278
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0017809
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0019699
[Epoch 57] ogbg-molhiv: 0.794970 val loss: 0.196800
[Epoch 57] ogbg-molhiv: 0.721588 test loss: 0.325240
[Epoch 58; Iter    21/ 1097] train: loss: 0.0032711
[Epoch 58; Iter    51/ 1097] train: loss: 0.0080315
[Epoch 58; Iter    81/ 1097] train: loss: 0.0028268
[Epoch 58; Iter   111/ 1097] train: loss: 0.0004621
[Epoch 58; Iter   141/ 1097] train: loss: 0.0001313
[Epoch 58; Iter   171/ 1097] train: loss: 0.0000836
[Epoch 58; Iter   201/ 1097] train: loss: 0.0011993
[Epoch 58; Iter   231/ 1097] train: loss: 0.0262059
[Epoch 58; Iter   261/ 1097] train: loss: 0.0011512
[Epoch 58; Iter   291/ 1097] train: loss: 0.0022385
[Epoch 58; Iter   321/ 1097] train: loss: 0.0019591
[Epoch 58; Iter   351/ 1097] train: loss: 0.0003426
[Epoch 58; Iter   381/ 1097] train: loss: 0.0002092
[Epoch 58; Iter   411/ 1097] train: loss: 0.0010317
[Epoch 58; Iter   441/ 1097] train: loss: 0.0007181
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001692
[Epoch 58; Iter   501/ 1097] train: loss: 0.0195988
[Epoch 58; Iter   531/ 1097] train: loss: 0.0212193
[Epoch 58; Iter   561/ 1097] train: loss: 0.0018597
[Epoch 58; Iter   591/ 1097] train: loss: 0.0022081
[Epoch 58; Iter   621/ 1097] train: loss: 0.0059295
[Epoch 58; Iter   651/ 1097] train: loss: 0.0003440
[Epoch 58; Iter   681/ 1097] train: loss: 0.0003713
[Epoch 58; Iter   711/ 1097] train: loss: 0.0133038
[Epoch 58; Iter   741/ 1097] train: loss: 0.0008666
[Epoch 58; Iter   771/ 1097] train: loss: 0.0003843
[Epoch 58; Iter   801/ 1097] train: loss: 0.0022346
[Epoch 58; Iter   831/ 1097] train: loss: 0.0036370
[Epoch 58; Iter   861/ 1097] train: loss: 0.0018374
[Epoch 58; Iter   891/ 1097] train: loss: 0.0002181
[Epoch 58; Iter   921/ 1097] train: loss: 0.0019087
[Epoch 58; Iter   951/ 1097] train: loss: 0.0006631
[Epoch 58; Iter   981/ 1097] train: loss: 0.0032050
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0144613
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0070502
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0005497
[Epoch 58] ogbg-molhiv: 0.781914 val loss: 0.200816
[Epoch 58] ogbg-molhiv: 0.725700 test loss: 0.323285
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002852
[Epoch 59; Iter    34/ 1097] train: loss: 0.0007698
[Epoch 59; Iter    64/ 1097] train: loss: 0.0069804
[Epoch 59; Iter    94/ 1097] train: loss: 0.0052840
[Epoch 59; Iter   124/ 1097] train: loss: 0.0136886
[Epoch 59; Iter   154/ 1097] train: loss: 0.0008545
[Epoch 59; Iter   184/ 1097] train: loss: 0.0020626
[Epoch 59; Iter   214/ 1097] train: loss: 0.0009997
[Epoch 59; Iter   244/ 1097] train: loss: 0.0005137
[Epoch 59; Iter   274/ 1097] train: loss: 0.0463825
[Epoch 59; Iter   304/ 1097] train: loss: 0.0007290
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000816
[Epoch 59; Iter   364/ 1097] train: loss: 0.0172231
[Epoch 59; Iter   394/ 1097] train: loss: 0.0016684
[Epoch 59; Iter   424/ 1097] train: loss: 0.0013531
[Epoch 59; Iter   454/ 1097] train: loss: 0.0006390
[Epoch 59; Iter   484/ 1097] train: loss: 0.0865986
[Epoch 59; Iter   514/ 1097] train: loss: 0.0000685
[Epoch 59; Iter   544/ 1097] train: loss: 0.0304154
[Epoch 59; Iter   574/ 1097] train: loss: 0.0036882
[Epoch 59; Iter   604/ 1097] train: loss: 0.0010076
[Epoch 59; Iter   634/ 1097] train: loss: 0.0007824
[Epoch 59; Iter   664/ 1097] train: loss: 0.0090088
[Epoch 59; Iter   694/ 1097] train: loss: 0.0007214
[Epoch 59; Iter   724/ 1097] train: loss: 0.0002990
[Epoch 59; Iter   754/ 1097] train: loss: 0.0015098
[Epoch 59; Iter   784/ 1097] train: loss: 0.0001554
[Epoch 59; Iter   814/ 1097] train: loss: 0.0120840
[Epoch 59; Iter   844/ 1097] train: loss: 0.0004355
[Epoch 59; Iter   874/ 1097] train: loss: 0.1020735
[Epoch 59; Iter   904/ 1097] train: loss: 0.0026460
[Epoch 59; Iter   934/ 1097] train: loss: 0.0002497
[Epoch 59; Iter   964/ 1097] train: loss: 0.0002883
[Epoch 59; Iter   994/ 1097] train: loss: 0.0006589
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0006500
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0002849
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0012732
[Epoch 59] ogbg-molhiv: 0.762762 val loss: 0.231561
[Epoch 59] ogbg-molhiv: 0.738674 test loss: 0.327167
[Epoch 60; Iter    17/ 1097] train: loss: 0.0049811
[Epoch 60; Iter    47/ 1097] train: loss: 0.0101925
[Epoch 60; Iter    77/ 1097] train: loss: 0.0022385
[Epoch 60; Iter   107/ 1097] train: loss: 0.0066180
[Epoch 60; Iter   137/ 1097] train: loss: 0.0028321
[Epoch 60; Iter   167/ 1097] train: loss: 0.0001838
[Epoch 60; Iter   197/ 1097] train: loss: 0.0029171
[Epoch 60; Iter   227/ 1097] train: loss: 0.0002783
[Epoch 60; Iter   257/ 1097] train: loss: 0.0035022
[Epoch 60; Iter   287/ 1097] train: loss: 0.0010152
[Epoch 60; Iter   317/ 1097] train: loss: 0.0000099
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001466
[Epoch 60; Iter   377/ 1097] train: loss: 0.0010792
[Epoch 60; Iter   407/ 1097] train: loss: 0.0000787
[Epoch 60; Iter   437/ 1097] train: loss: 0.0013225
[Epoch 60; Iter   467/ 1097] train: loss: 0.0002682
[Epoch 60; Iter   497/ 1097] train: loss: 0.0016330
[Epoch 60; Iter   527/ 1097] train: loss: 0.0003150
[Epoch 60; Iter   557/ 1097] train: loss: 0.0008366
[Epoch 60; Iter   587/ 1097] train: loss: 0.0010445
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001159
[Epoch 60; Iter   647/ 1097] train: loss: 0.0014808
[Epoch 60; Iter   677/ 1097] train: loss: 0.0046279
[Epoch 60; Iter   707/ 1097] train: loss: 0.0002376
[Epoch 60; Iter   737/ 1097] train: loss: 0.0032311
[Epoch 60; Iter   767/ 1097] train: loss: 0.0856156
[Epoch 60; Iter   797/ 1097] train: loss: 0.0011027
[Epoch 60; Iter   827/ 1097] train: loss: 0.0408284
[Epoch 60; Iter   857/ 1097] train: loss: 0.0096179
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001947
[Epoch 60; Iter   917/ 1097] train: loss: 0.0002336
[Epoch 60; Iter   947/ 1097] train: loss: 0.0061834
[Epoch 60; Iter   977/ 1097] train: loss: 0.0024552
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0006467
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0002713
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0028829
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000665
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0001486
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0054883
[Epoch 56] ogbg-molhiv: 0.787322 val loss: 0.261190
[Epoch 56] ogbg-molhiv: 0.800794 test loss: 0.267329
[Epoch 57; Iter     8/ 1097] train: loss: 0.0004099
[Epoch 57; Iter    38/ 1097] train: loss: 0.0030300
[Epoch 57; Iter    68/ 1097] train: loss: 0.0020611
[Epoch 57; Iter    98/ 1097] train: loss: 0.0035147
[Epoch 57; Iter   128/ 1097] train: loss: 0.0020486
[Epoch 57; Iter   158/ 1097] train: loss: 0.0021573
[Epoch 57; Iter   188/ 1097] train: loss: 0.0010385
[Epoch 57; Iter   218/ 1097] train: loss: 0.0003785
[Epoch 57; Iter   248/ 1097] train: loss: 0.0001605
[Epoch 57; Iter   278/ 1097] train: loss: 0.0002781
[Epoch 57; Iter   308/ 1097] train: loss: 0.0012792
[Epoch 57; Iter   338/ 1097] train: loss: 0.0002838
[Epoch 57; Iter   368/ 1097] train: loss: 0.0008186
[Epoch 57; Iter   398/ 1097] train: loss: 0.0006224
[Epoch 57; Iter   428/ 1097] train: loss: 0.0009278
[Epoch 57; Iter   458/ 1097] train: loss: 0.0009734
[Epoch 57; Iter   488/ 1097] train: loss: 0.0004664
[Epoch 57; Iter   518/ 1097] train: loss: 0.0006242
[Epoch 57; Iter   548/ 1097] train: loss: 0.0008472
[Epoch 57; Iter   578/ 1097] train: loss: 0.0000289
[Epoch 57; Iter   608/ 1097] train: loss: 0.0000670
[Epoch 57; Iter   638/ 1097] train: loss: 0.0001290
[Epoch 57; Iter   668/ 1097] train: loss: 0.0048001
[Epoch 57; Iter   698/ 1097] train: loss: 0.0000885
[Epoch 57; Iter   728/ 1097] train: loss: 0.0002503
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007490
[Epoch 57; Iter   788/ 1097] train: loss: 0.0020057
[Epoch 57; Iter   818/ 1097] train: loss: 0.0002134
[Epoch 57; Iter   848/ 1097] train: loss: 0.0006156
[Epoch 57; Iter   878/ 1097] train: loss: 0.0012258
[Epoch 57; Iter   908/ 1097] train: loss: 0.0005312
[Epoch 57; Iter   938/ 1097] train: loss: 0.0002542
[Epoch 57; Iter   968/ 1097] train: loss: 0.0004164
[Epoch 57; Iter   998/ 1097] train: loss: 0.0000286
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0084886
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0036877
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0031817
[Epoch 57] ogbg-molhiv: 0.766455 val loss: 0.271971
[Epoch 57] ogbg-molhiv: 0.800832 test loss: 0.263575
[Epoch 58; Iter    21/ 1097] train: loss: 0.0003887
[Epoch 58; Iter    51/ 1097] train: loss: 0.0069902
[Epoch 58; Iter    81/ 1097] train: loss: 0.0033071
[Epoch 58; Iter   111/ 1097] train: loss: 0.0017098
[Epoch 58; Iter   141/ 1097] train: loss: 0.0000949
[Epoch 58; Iter   171/ 1097] train: loss: 0.0003526
[Epoch 58; Iter   201/ 1097] train: loss: 0.0242150
[Epoch 58; Iter   231/ 1097] train: loss: 0.0002453
[Epoch 58; Iter   261/ 1097] train: loss: 0.0002405
[Epoch 58; Iter   291/ 1097] train: loss: 0.0005486
[Epoch 58; Iter   321/ 1097] train: loss: 0.0006464
[Epoch 58; Iter   351/ 1097] train: loss: 0.0006081
[Epoch 58; Iter   381/ 1097] train: loss: 0.0000912
[Epoch 58; Iter   411/ 1097] train: loss: 0.0117999
[Epoch 58; Iter   441/ 1097] train: loss: 0.0009449
[Epoch 58; Iter   471/ 1097] train: loss: 0.0019296
[Epoch 58; Iter   501/ 1097] train: loss: 0.0449860
[Epoch 58; Iter   531/ 1097] train: loss: 0.1650235
[Epoch 58; Iter   561/ 1097] train: loss: 0.0002027
[Epoch 58; Iter   591/ 1097] train: loss: 0.0027484
[Epoch 58; Iter   621/ 1097] train: loss: 0.0023334
[Epoch 58; Iter   651/ 1097] train: loss: 0.0000657
[Epoch 58; Iter   681/ 1097] train: loss: 0.0391931
[Epoch 58; Iter   711/ 1097] train: loss: 0.0001276
[Epoch 58; Iter   741/ 1097] train: loss: 0.0436130
[Epoch 58; Iter   771/ 1097] train: loss: 0.0021517
[Epoch 58; Iter   801/ 1097] train: loss: 0.0008695
[Epoch 58; Iter   831/ 1097] train: loss: 0.0004051
[Epoch 58; Iter   861/ 1097] train: loss: 0.0000420
[Epoch 58; Iter   891/ 1097] train: loss: 0.0010115
[Epoch 58; Iter   921/ 1097] train: loss: 0.0011884
[Epoch 58; Iter   951/ 1097] train: loss: 0.0000987
[Epoch 58; Iter   981/ 1097] train: loss: 0.0074623
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0000133
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0015965
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0001091
[Epoch 58] ogbg-molhiv: 0.801789 val loss: 0.249850
[Epoch 58] ogbg-molhiv: 0.797511 test loss: 0.273411
[Epoch 59; Iter     4/ 1097] train: loss: 0.0039365
[Epoch 59; Iter    34/ 1097] train: loss: 0.0005931
[Epoch 59; Iter    64/ 1097] train: loss: 0.0000333
[Epoch 59; Iter    94/ 1097] train: loss: 0.0001159
[Epoch 59; Iter   124/ 1097] train: loss: 0.0000632
[Epoch 59; Iter   154/ 1097] train: loss: 0.0007138
[Epoch 59; Iter   184/ 1097] train: loss: 0.0006492
[Epoch 59; Iter   214/ 1097] train: loss: 0.0000519
[Epoch 59; Iter   244/ 1097] train: loss: 0.0002716
[Epoch 59; Iter   274/ 1097] train: loss: 0.0001869
[Epoch 59; Iter   304/ 1097] train: loss: 0.0005381
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000988
[Epoch 59; Iter   364/ 1097] train: loss: 0.0048005
[Epoch 59; Iter   394/ 1097] train: loss: 0.0011935
[Epoch 59; Iter   424/ 1097] train: loss: 0.0002110
[Epoch 59; Iter   454/ 1097] train: loss: 0.0002100
[Epoch 59; Iter   484/ 1097] train: loss: 0.0007677
[Epoch 59; Iter   514/ 1097] train: loss: 0.0000472
[Epoch 59; Iter   544/ 1097] train: loss: 0.0009448
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000983
[Epoch 59; Iter   604/ 1097] train: loss: 0.0008062
[Epoch 59; Iter   634/ 1097] train: loss: 0.0004685
[Epoch 59; Iter   664/ 1097] train: loss: 0.0029042
[Epoch 59; Iter   694/ 1097] train: loss: 0.0005020
[Epoch 59; Iter   724/ 1097] train: loss: 0.0011145
[Epoch 59; Iter   754/ 1097] train: loss: 0.0006569
[Epoch 59; Iter   784/ 1097] train: loss: 0.0005904
[Epoch 59; Iter   814/ 1097] train: loss: 0.0012554
[Epoch 59; Iter   844/ 1097] train: loss: 0.0000551
[Epoch 59; Iter   874/ 1097] train: loss: 0.0010422
[Epoch 59; Iter   904/ 1097] train: loss: 0.0002551
[Epoch 59; Iter   934/ 1097] train: loss: 0.0000740
[Epoch 59; Iter   964/ 1097] train: loss: 0.0126702
[Epoch 59; Iter   994/ 1097] train: loss: 0.0004147
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0035366
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0001053
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0007032
[Epoch 59] ogbg-molhiv: 0.762802 val loss: 0.243741
[Epoch 59] ogbg-molhiv: 0.785411 test loss: 0.288287
[Epoch 60; Iter    17/ 1097] train: loss: 0.0279160
[Epoch 60; Iter    47/ 1097] train: loss: 0.0061336
[Epoch 60; Iter    77/ 1097] train: loss: 0.0002383
[Epoch 60; Iter   107/ 1097] train: loss: 0.0118119
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000786
[Epoch 60; Iter   167/ 1097] train: loss: 0.0015495
[Epoch 60; Iter   197/ 1097] train: loss: 0.0002547
[Epoch 60; Iter   227/ 1097] train: loss: 0.0011275
[Epoch 60; Iter   257/ 1097] train: loss: 0.0013842
[Epoch 60; Iter   287/ 1097] train: loss: 0.0007145
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003631
[Epoch 60; Iter   347/ 1097] train: loss: 0.0001528
[Epoch 60; Iter   377/ 1097] train: loss: 0.0027537
[Epoch 60; Iter   407/ 1097] train: loss: 0.0002835
[Epoch 60; Iter   437/ 1097] train: loss: 0.0015826
[Epoch 60; Iter   467/ 1097] train: loss: 0.0001101
[Epoch 60; Iter   497/ 1097] train: loss: 0.0001791
[Epoch 60; Iter   527/ 1097] train: loss: 0.0005307
[Epoch 60; Iter   557/ 1097] train: loss: 0.0002990
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001747
[Epoch 60; Iter   617/ 1097] train: loss: 0.0001481
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000052
[Epoch 60; Iter   677/ 1097] train: loss: 0.0000533
[Epoch 60; Iter   707/ 1097] train: loss: 0.0001442
[Epoch 60; Iter   737/ 1097] train: loss: 0.0037172
[Epoch 60; Iter   767/ 1097] train: loss: 0.0019126
[Epoch 60; Iter   797/ 1097] train: loss: 0.0094614
[Epoch 60; Iter   827/ 1097] train: loss: 0.0000370
[Epoch 60; Iter   857/ 1097] train: loss: 0.0002265
[Epoch 60; Iter   887/ 1097] train: loss: 0.0012124
[Epoch 60; Iter   917/ 1097] train: loss: 0.0191042
[Epoch 60; Iter   947/ 1097] train: loss: 0.0037075
[Epoch 60; Iter   977/ 1097] train: loss: 0.0000987
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0002019
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0004378
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0007021
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0014139
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0000207
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0016160
[Epoch 56] ogbg-molhiv: 0.683002 val loss: 8.331708
[Epoch 56] ogbg-molhiv: 0.552848 test loss: 10.479410
[Epoch 57; Iter     8/ 1097] train: loss: 0.0007215
[Epoch 57; Iter    38/ 1097] train: loss: 0.0003586
[Epoch 57; Iter    68/ 1097] train: loss: 0.0000575
[Epoch 57; Iter    98/ 1097] train: loss: 0.0014171
[Epoch 57; Iter   128/ 1097] train: loss: 0.0000640
[Epoch 57; Iter   158/ 1097] train: loss: 0.0001113
[Epoch 57; Iter   188/ 1097] train: loss: 0.0001659
[Epoch 57; Iter   218/ 1097] train: loss: 0.0002039
[Epoch 57; Iter   248/ 1097] train: loss: 0.0001895
[Epoch 57; Iter   278/ 1097] train: loss: 0.0000731
[Epoch 57; Iter   308/ 1097] train: loss: 0.0009052
[Epoch 57; Iter   338/ 1097] train: loss: 0.0054883
[Epoch 57; Iter   368/ 1097] train: loss: 0.0000960
[Epoch 57; Iter   398/ 1097] train: loss: 0.0000730
[Epoch 57; Iter   428/ 1097] train: loss: 0.0003831
[Epoch 57; Iter   458/ 1097] train: loss: 0.0000570
[Epoch 57; Iter   488/ 1097] train: loss: 0.0000078
[Epoch 57; Iter   518/ 1097] train: loss: 0.0000396
[Epoch 57; Iter   548/ 1097] train: loss: 0.0009981
[Epoch 57; Iter   578/ 1097] train: loss: 0.0000349
[Epoch 57; Iter   608/ 1097] train: loss: 0.0032398
[Epoch 57; Iter   638/ 1097] train: loss: 0.0018054
[Epoch 57; Iter   668/ 1097] train: loss: 0.0000310
[Epoch 57; Iter   698/ 1097] train: loss: 0.0050346
[Epoch 57; Iter   728/ 1097] train: loss: 0.0000667
[Epoch 57; Iter   758/ 1097] train: loss: 0.0007655
[Epoch 57; Iter   788/ 1097] train: loss: 0.0007863
[Epoch 57; Iter   818/ 1097] train: loss: 0.0044067
[Epoch 57; Iter   848/ 1097] train: loss: 0.0000345
[Epoch 57; Iter   878/ 1097] train: loss: 0.0281502
[Epoch 57; Iter   908/ 1097] train: loss: 0.0000757
[Epoch 57; Iter   938/ 1097] train: loss: 0.0000234
[Epoch 57; Iter   968/ 1097] train: loss: 0.0000181
[Epoch 57; Iter   998/ 1097] train: loss: 0.0003510
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0002044
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003756
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0000076
[Epoch 57] ogbg-molhiv: 0.712044 val loss: 1.686141
[Epoch 57] ogbg-molhiv: 0.619201 test loss: 2.510876
[Epoch 58; Iter    21/ 1097] train: loss: 0.0000577
[Epoch 58; Iter    51/ 1097] train: loss: 0.0017819
[Epoch 58; Iter    81/ 1097] train: loss: 0.0001862
[Epoch 58; Iter   111/ 1097] train: loss: 0.0006170
[Epoch 58; Iter   141/ 1097] train: loss: 0.0000980
[Epoch 58; Iter   171/ 1097] train: loss: 0.0001688
[Epoch 58; Iter   201/ 1097] train: loss: 0.0001631
[Epoch 58; Iter   231/ 1097] train: loss: 0.0000321
[Epoch 58; Iter   261/ 1097] train: loss: 0.0187724
[Epoch 58; Iter   291/ 1097] train: loss: 0.0007863
[Epoch 58; Iter   321/ 1097] train: loss: 0.0000241
[Epoch 58; Iter   351/ 1097] train: loss: 0.0115519
[Epoch 58; Iter   381/ 1097] train: loss: 0.0000231
[Epoch 58; Iter   411/ 1097] train: loss: 0.0009768
[Epoch 58; Iter   441/ 1097] train: loss: 0.0006132
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001248
[Epoch 58; Iter   501/ 1097] train: loss: 0.0001993
[Epoch 58; Iter   531/ 1097] train: loss: 0.0003279
[Epoch 58; Iter   561/ 1097] train: loss: 0.0000681
[Epoch 58; Iter   591/ 1097] train: loss: 0.0000415
[Epoch 58; Iter   621/ 1097] train: loss: 0.0000366
[Epoch 58; Iter   651/ 1097] train: loss: 0.0012000
[Epoch 58; Iter   681/ 1097] train: loss: 0.0002637
[Epoch 58; Iter   711/ 1097] train: loss: 0.0031381
[Epoch 58; Iter   741/ 1097] train: loss: 0.0034686
[Epoch 58; Iter   771/ 1097] train: loss: 0.0008493
[Epoch 58; Iter   801/ 1097] train: loss: 0.0001442
[Epoch 58; Iter   831/ 1097] train: loss: 0.0001265
[Epoch 58; Iter   861/ 1097] train: loss: 0.0001591
[Epoch 58; Iter   891/ 1097] train: loss: 0.0002075
[Epoch 58; Iter   921/ 1097] train: loss: 0.0009216
[Epoch 58; Iter   951/ 1097] train: loss: 0.0005285
[Epoch 58; Iter   981/ 1097] train: loss: 0.0001294
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0065492
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0001398
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0000194
[Epoch 58] ogbg-molhiv: 0.668816 val loss: 3.217429
[Epoch 58] ogbg-molhiv: 0.598521 test loss: 4.079403
[Epoch 59; Iter     4/ 1097] train: loss: 0.0006376
[Epoch 59; Iter    34/ 1097] train: loss: 0.0007879
[Epoch 59; Iter    64/ 1097] train: loss: 0.0001323
[Epoch 59; Iter    94/ 1097] train: loss: 0.0038820
[Epoch 59; Iter   124/ 1097] train: loss: 0.0014722
[Epoch 59; Iter   154/ 1097] train: loss: 0.0006885
[Epoch 59; Iter   184/ 1097] train: loss: 0.0105550
[Epoch 59; Iter   214/ 1097] train: loss: 0.0002417
[Epoch 59; Iter   244/ 1097] train: loss: 0.0000747
[Epoch 59; Iter   274/ 1097] train: loss: 0.0000741
[Epoch 59; Iter   304/ 1097] train: loss: 0.0002478
[Epoch 59; Iter   334/ 1097] train: loss: 0.0000112
[Epoch 59; Iter   364/ 1097] train: loss: 0.0059059
[Epoch 59; Iter   394/ 1097] train: loss: 0.0034776
[Epoch 59; Iter   424/ 1097] train: loss: 0.0026226
[Epoch 59; Iter   454/ 1097] train: loss: 0.0069848
[Epoch 59; Iter   484/ 1097] train: loss: 0.0000249
[Epoch 59; Iter   514/ 1097] train: loss: 0.0002875
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004114
[Epoch 59; Iter   574/ 1097] train: loss: 0.0001730
[Epoch 59; Iter   604/ 1097] train: loss: 0.0006421
[Epoch 59; Iter   634/ 1097] train: loss: 0.0086397
[Epoch 59; Iter   664/ 1097] train: loss: 0.0000164
[Epoch 59; Iter   694/ 1097] train: loss: 0.0000511
[Epoch 59; Iter   724/ 1097] train: loss: 0.0008791
[Epoch 59; Iter   754/ 1097] train: loss: 0.0001143
[Epoch 59; Iter   784/ 1097] train: loss: 0.0000157
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000287
[Epoch 59; Iter   844/ 1097] train: loss: 0.0064313
[Epoch 59; Iter   874/ 1097] train: loss: 0.0002454
[Epoch 59; Iter   904/ 1097] train: loss: 0.0015884
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001621
[Epoch 59; Iter   964/ 1097] train: loss: 0.0000679
[Epoch 59; Iter   994/ 1097] train: loss: 0.0001298
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0000245
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0000296
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000814
[Epoch 59] ogbg-molhiv: 0.702234 val loss: 4.421663
[Epoch 59] ogbg-molhiv: 0.591894 test loss: 5.976201
[Epoch 60; Iter    17/ 1097] train: loss: 0.0004859
[Epoch 60; Iter    47/ 1097] train: loss: 0.0010650
[Epoch 60; Iter    77/ 1097] train: loss: 0.0008098
[Epoch 60; Iter   107/ 1097] train: loss: 0.0068155
[Epoch 60; Iter   137/ 1097] train: loss: 0.0001469
[Epoch 60; Iter   167/ 1097] train: loss: 0.0000937
[Epoch 60; Iter   197/ 1097] train: loss: 0.0113412
[Epoch 60; Iter   227/ 1097] train: loss: 0.0000358
[Epoch 60; Iter   257/ 1097] train: loss: 0.0000765
[Epoch 60; Iter   287/ 1097] train: loss: 0.0002654
[Epoch 60; Iter   317/ 1097] train: loss: 0.0004287
[Epoch 60; Iter   347/ 1097] train: loss: 0.0000879
[Epoch 60; Iter   377/ 1097] train: loss: 0.0004859
[Epoch 60; Iter   407/ 1097] train: loss: 0.0007262
[Epoch 60; Iter   437/ 1097] train: loss: 0.0003232
[Epoch 60; Iter   467/ 1097] train: loss: 0.0000204
[Epoch 60; Iter   497/ 1097] train: loss: 0.0001259
[Epoch 60; Iter   527/ 1097] train: loss: 0.0001697
[Epoch 60; Iter   557/ 1097] train: loss: 0.0052118
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001134
[Epoch 60; Iter   617/ 1097] train: loss: 0.0000379
[Epoch 60; Iter   647/ 1097] train: loss: 0.0002268
[Epoch 60; Iter   677/ 1097] train: loss: 0.0000184
[Epoch 60; Iter   707/ 1097] train: loss: 0.0014978
[Epoch 60; Iter   737/ 1097] train: loss: 0.0003413
[Epoch 60; Iter   767/ 1097] train: loss: 0.0002763
[Epoch 60; Iter   797/ 1097] train: loss: 0.0001637
[Epoch 60; Iter   827/ 1097] train: loss: 0.0016104
[Epoch 60; Iter   857/ 1097] train: loss: 0.0000222
[Epoch 60; Iter   887/ 1097] train: loss: 0.0044546
[Epoch 60; Iter   917/ 1097] train: loss: 0.0001495
[Epoch 60; Iter   947/ 1097] train: loss: 0.0002760
[Epoch 60; Iter   977/ 1097] train: loss: 0.0005549
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0000098
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0000255
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0000411
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0000542
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0002693
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0003548
[Epoch 56] ogbg-molhiv: 0.786728 val loss: 20.724912
[Epoch 56] ogbg-molhiv: 0.711207 test loss: 15.966664
[Epoch 57; Iter     8/ 1097] train: loss: 0.0020186
[Epoch 57; Iter    38/ 1097] train: loss: 0.0067935
[Epoch 57; Iter    68/ 1097] train: loss: 0.0020931
[Epoch 57; Iter    98/ 1097] train: loss: 0.0005728
[Epoch 57; Iter   128/ 1097] train: loss: 0.0052075
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000688
[Epoch 57; Iter   188/ 1097] train: loss: 0.0067893
[Epoch 57; Iter   218/ 1097] train: loss: 0.0021895
[Epoch 57; Iter   248/ 1097] train: loss: 0.0002049
[Epoch 57; Iter   278/ 1097] train: loss: 0.0028128
[Epoch 57; Iter   308/ 1097] train: loss: 0.0068438
[Epoch 57; Iter   338/ 1097] train: loss: 0.0004563
[Epoch 57; Iter   368/ 1097] train: loss: 0.0015499
[Epoch 57; Iter   398/ 1097] train: loss: 0.0011066
[Epoch 57; Iter   428/ 1097] train: loss: 0.0002921
[Epoch 57; Iter   458/ 1097] train: loss: 0.0051409
[Epoch 57; Iter   488/ 1097] train: loss: 0.0202259
[Epoch 57; Iter   518/ 1097] train: loss: 0.0032412
[Epoch 57; Iter   548/ 1097] train: loss: 0.0026742
[Epoch 57; Iter   578/ 1097] train: loss: 0.0019474
[Epoch 57; Iter   608/ 1097] train: loss: 0.0010945
[Epoch 57; Iter   638/ 1097] train: loss: 0.0087602
[Epoch 57; Iter   668/ 1097] train: loss: 0.0044254
[Epoch 57; Iter   698/ 1097] train: loss: 0.0005872
[Epoch 57; Iter   728/ 1097] train: loss: 0.0050548
[Epoch 57; Iter   758/ 1097] train: loss: 0.0458506
[Epoch 57; Iter   788/ 1097] train: loss: 0.0086120
[Epoch 57; Iter   818/ 1097] train: loss: 0.0002471
[Epoch 57; Iter   848/ 1097] train: loss: 0.0012120
[Epoch 57; Iter   878/ 1097] train: loss: 0.0003404
[Epoch 57; Iter   908/ 1097] train: loss: 0.0234615
[Epoch 57; Iter   938/ 1097] train: loss: 0.0011349
[Epoch 57; Iter   968/ 1097] train: loss: 0.0002468
[Epoch 57; Iter   998/ 1097] train: loss: 0.0035655
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0225277
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0051217
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0081271
[Epoch 57] ogbg-molhiv: 0.771063 val loss: 9.929186
[Epoch 57] ogbg-molhiv: 0.694546 test loss: 9.618674
[Epoch 58; Iter    21/ 1097] train: loss: 0.0005104
[Epoch 58; Iter    51/ 1097] train: loss: 0.0016361
[Epoch 58; Iter    81/ 1097] train: loss: 0.0005098
[Epoch 58; Iter   111/ 1097] train: loss: 0.0061830
[Epoch 58; Iter   141/ 1097] train: loss: 0.0015973
[Epoch 58; Iter   171/ 1097] train: loss: 0.0004034
[Epoch 58; Iter   201/ 1097] train: loss: 0.0002150
[Epoch 58; Iter   231/ 1097] train: loss: 0.0005550
[Epoch 58; Iter   261/ 1097] train: loss: 0.0136433
[Epoch 58; Iter   291/ 1097] train: loss: 0.0004434
[Epoch 58; Iter   321/ 1097] train: loss: 0.0010227
[Epoch 58; Iter   351/ 1097] train: loss: 0.0002034
[Epoch 58; Iter   381/ 1097] train: loss: 0.0001593
[Epoch 58; Iter   411/ 1097] train: loss: 0.0040763
[Epoch 58; Iter   441/ 1097] train: loss: 0.0008170
[Epoch 58; Iter   471/ 1097] train: loss: 0.0033118
[Epoch 58; Iter   501/ 1097] train: loss: 0.0577298
[Epoch 58; Iter   531/ 1097] train: loss: 0.0393394
[Epoch 58; Iter   561/ 1097] train: loss: 0.0047600
[Epoch 58; Iter   591/ 1097] train: loss: 0.0005956
[Epoch 58; Iter   621/ 1097] train: loss: 0.0021966
[Epoch 58; Iter   651/ 1097] train: loss: 0.0522519
[Epoch 58; Iter   681/ 1097] train: loss: 0.0088557
[Epoch 58; Iter   711/ 1097] train: loss: 0.0005392
[Epoch 58; Iter   741/ 1097] train: loss: 0.0023950
[Epoch 58; Iter   771/ 1097] train: loss: 0.0001389
[Epoch 58; Iter   801/ 1097] train: loss: 0.0146188
[Epoch 58; Iter   831/ 1097] train: loss: 0.0003147
[Epoch 58; Iter   861/ 1097] train: loss: 0.0016843
[Epoch 58; Iter   891/ 1097] train: loss: 0.0006448
[Epoch 58; Iter   921/ 1097] train: loss: 0.0002142
[Epoch 58; Iter   951/ 1097] train: loss: 0.0029123
[Epoch 58; Iter   981/ 1097] train: loss: 0.0022136
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0005550
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0004992
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0081532
[Epoch 58] ogbg-molhiv: 0.735658 val loss: 9.878995
[Epoch 58] ogbg-molhiv: 0.692858 test loss: 12.233140
[Epoch 59; Iter     4/ 1097] train: loss: 0.0014489
[Epoch 59; Iter    34/ 1097] train: loss: 0.0014666
[Epoch 59; Iter    64/ 1097] train: loss: 0.0009093
[Epoch 59; Iter    94/ 1097] train: loss: 0.0011589
[Epoch 59; Iter   124/ 1097] train: loss: 0.0004185
[Epoch 59; Iter   154/ 1097] train: loss: 0.0000942
[Epoch 59; Iter   184/ 1097] train: loss: 0.0051372
[Epoch 59; Iter   214/ 1097] train: loss: 0.0002247
[Epoch 59; Iter   244/ 1097] train: loss: 0.0012221
[Epoch 59; Iter   274/ 1097] train: loss: 0.0001176
[Epoch 59; Iter   304/ 1097] train: loss: 0.0034417
[Epoch 59; Iter   334/ 1097] train: loss: 0.0018823
[Epoch 59; Iter   364/ 1097] train: loss: 0.0015920
[Epoch 59; Iter   394/ 1097] train: loss: 0.0006458
[Epoch 59; Iter   424/ 1097] train: loss: 0.0025336
[Epoch 59; Iter   454/ 1097] train: loss: 0.0012862
[Epoch 59; Iter   484/ 1097] train: loss: 0.0068192
[Epoch 59; Iter   514/ 1097] train: loss: 0.0019693
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004480
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000445
[Epoch 59; Iter   604/ 1097] train: loss: 0.0002380
[Epoch 59; Iter   634/ 1097] train: loss: 0.0005080
[Epoch 59; Iter   664/ 1097] train: loss: 0.0048538
[Epoch 59; Iter   694/ 1097] train: loss: 0.0000532
[Epoch 59; Iter   724/ 1097] train: loss: 0.0245409
[Epoch 59; Iter   754/ 1097] train: loss: 0.0003662
[Epoch 59; Iter   784/ 1097] train: loss: 0.0000357
[Epoch 59; Iter   814/ 1097] train: loss: 0.0000523
[Epoch 59; Iter   844/ 1097] train: loss: 0.0000360
[Epoch 59; Iter   874/ 1097] train: loss: 0.0006410
[Epoch 59; Iter   904/ 1097] train: loss: 0.0012759
[Epoch 59; Iter   934/ 1097] train: loss: 0.0125703
[Epoch 59; Iter   964/ 1097] train: loss: 0.0326750
[Epoch 59; Iter   994/ 1097] train: loss: 0.0001007
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0605469
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0006397
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000127
[Epoch 59] ogbg-molhiv: 0.786734 val loss: 7.686280
[Epoch 59] ogbg-molhiv: 0.724145 test loss: 6.924354
[Epoch 60; Iter    17/ 1097] train: loss: 0.0024132
[Epoch 60; Iter    47/ 1097] train: loss: 0.0133835
[Epoch 60; Iter    77/ 1097] train: loss: 0.0036176
[Epoch 60; Iter   107/ 1097] train: loss: 0.0050014
[Epoch 60; Iter   137/ 1097] train: loss: 0.0000512
[Epoch 60; Iter   167/ 1097] train: loss: 0.0007421
[Epoch 60; Iter   197/ 1097] train: loss: 0.0199642
[Epoch 60; Iter   227/ 1097] train: loss: 0.0013328
[Epoch 60; Iter   257/ 1097] train: loss: 0.0004761
[Epoch 60; Iter   287/ 1097] train: loss: 0.0081408
[Epoch 60; Iter   317/ 1097] train: loss: 0.0003015
[Epoch 60; Iter   347/ 1097] train: loss: 0.0068296
[Epoch 60; Iter   377/ 1097] train: loss: 0.0000127
[Epoch 60; Iter   407/ 1097] train: loss: 0.0002466
[Epoch 60; Iter   437/ 1097] train: loss: 0.0001973
[Epoch 60; Iter   467/ 1097] train: loss: 0.0005135
[Epoch 60; Iter   497/ 1097] train: loss: 0.0010129
[Epoch 60; Iter   527/ 1097] train: loss: 0.0002021
[Epoch 60; Iter   557/ 1097] train: loss: 0.0035389
[Epoch 60; Iter   587/ 1097] train: loss: 0.0000230
[Epoch 60; Iter   617/ 1097] train: loss: 0.0003846
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000565
[Epoch 60; Iter   677/ 1097] train: loss: 0.0004857
[Epoch 60; Iter   707/ 1097] train: loss: 0.0038905
[Epoch 60; Iter   737/ 1097] train: loss: 0.0022826
[Epoch 60; Iter   767/ 1097] train: loss: 0.0009051
[Epoch 60; Iter   797/ 1097] train: loss: 0.0000830
[Epoch 60; Iter   827/ 1097] train: loss: 0.0003203
[Epoch 60; Iter   857/ 1097] train: loss: 0.0002317
[Epoch 60; Iter   887/ 1097] train: loss: 0.0001718
[Epoch 60; Iter   917/ 1097] train: loss: 0.0040796
[Epoch 60; Iter   947/ 1097] train: loss: 0.0027748
[Epoch 60; Iter   977/ 1097] train: loss: 0.0020037
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0065171
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0013188
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0733223
[Epoch 56; Iter  1015/ 1097] train: loss: 0.1419935
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0019177
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0051758
[Epoch 56] ogbg-molhiv: 0.615560 val loss: 59.827676
[Epoch 56] ogbg-molhiv: 0.569422 test loss: 56.540242
[Epoch 57; Iter     8/ 1097] train: loss: 0.0287202
[Epoch 57; Iter    38/ 1097] train: loss: 0.0002936
[Epoch 57; Iter    68/ 1097] train: loss: 0.0004095
[Epoch 57; Iter    98/ 1097] train: loss: 0.0011821
[Epoch 57; Iter   128/ 1097] train: loss: 0.0191494
[Epoch 57; Iter   158/ 1097] train: loss: 0.0000982
[Epoch 57; Iter   188/ 1097] train: loss: 0.0011820
[Epoch 57; Iter   218/ 1097] train: loss: 0.0153755
[Epoch 57; Iter   248/ 1097] train: loss: 0.0025998
[Epoch 57; Iter   278/ 1097] train: loss: 0.0011838
[Epoch 57; Iter   308/ 1097] train: loss: 0.0005500
[Epoch 57; Iter   338/ 1097] train: loss: 0.0011825
[Epoch 57; Iter   368/ 1097] train: loss: 0.0001301
[Epoch 57; Iter   398/ 1097] train: loss: 0.0004334
[Epoch 57; Iter   428/ 1097] train: loss: 0.0004118
[Epoch 57; Iter   458/ 1097] train: loss: 0.0001147
[Epoch 57; Iter   488/ 1097] train: loss: 0.0000564
[Epoch 57; Iter   518/ 1097] train: loss: 0.0003394
[Epoch 57; Iter   548/ 1097] train: loss: 0.0000873
[Epoch 57; Iter   578/ 1097] train: loss: 0.0279936
[Epoch 57; Iter   608/ 1097] train: loss: 0.0328166
[Epoch 57; Iter   638/ 1097] train: loss: 0.0017078
[Epoch 57; Iter   668/ 1097] train: loss: 0.0006071
[Epoch 57; Iter   698/ 1097] train: loss: 0.0021816
[Epoch 57; Iter   728/ 1097] train: loss: 0.0000620
[Epoch 57; Iter   758/ 1097] train: loss: 0.0296946
[Epoch 57; Iter   788/ 1097] train: loss: 0.0172294
[Epoch 57; Iter   818/ 1097] train: loss: 0.0243032
[Epoch 57; Iter   848/ 1097] train: loss: 0.0002564
[Epoch 57; Iter   878/ 1097] train: loss: 0.0000502
[Epoch 57; Iter   908/ 1097] train: loss: 0.0009772
[Epoch 57; Iter   938/ 1097] train: loss: 0.0015493
[Epoch 57; Iter   968/ 1097] train: loss: 0.0000640
[Epoch 57; Iter   998/ 1097] train: loss: 0.0304023
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0042933
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0003713
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0004510
[Epoch 57] ogbg-molhiv: 0.703238 val loss: 5.447008
[Epoch 57] ogbg-molhiv: 0.640773 test loss: 3.921848
[Epoch 58; Iter    21/ 1097] train: loss: 0.0009560
[Epoch 58; Iter    51/ 1097] train: loss: 0.0001522
[Epoch 58; Iter    81/ 1097] train: loss: 0.0079300
[Epoch 58; Iter   111/ 1097] train: loss: 0.0059356
[Epoch 58; Iter   141/ 1097] train: loss: 0.0013961
[Epoch 58; Iter   171/ 1097] train: loss: 0.0001104
[Epoch 58; Iter   201/ 1097] train: loss: 0.0000642
[Epoch 58; Iter   231/ 1097] train: loss: 0.0004957
[Epoch 58; Iter   261/ 1097] train: loss: 0.0003967
[Epoch 58; Iter   291/ 1097] train: loss: 0.0174506
[Epoch 58; Iter   321/ 1097] train: loss: 0.0005043
[Epoch 58; Iter   351/ 1097] train: loss: 0.0096898
[Epoch 58; Iter   381/ 1097] train: loss: 0.0080392
[Epoch 58; Iter   411/ 1097] train: loss: 0.0028504
[Epoch 58; Iter   441/ 1097] train: loss: 0.0002734
[Epoch 58; Iter   471/ 1097] train: loss: 0.0001274
[Epoch 58; Iter   501/ 1097] train: loss: 0.0018120
[Epoch 58; Iter   531/ 1097] train: loss: 0.0001440
[Epoch 58; Iter   561/ 1097] train: loss: 0.0052308
[Epoch 58; Iter   591/ 1097] train: loss: 0.0082570
[Epoch 58; Iter   621/ 1097] train: loss: 0.0011967
[Epoch 58; Iter   651/ 1097] train: loss: 0.0068539
[Epoch 58; Iter   681/ 1097] train: loss: 0.0765996
[Epoch 58; Iter   711/ 1097] train: loss: 0.0128383
[Epoch 58; Iter   741/ 1097] train: loss: 0.0009138
[Epoch 58; Iter   771/ 1097] train: loss: 0.0008207
[Epoch 58; Iter   801/ 1097] train: loss: 0.0060041
[Epoch 58; Iter   831/ 1097] train: loss: 0.1253991
[Epoch 58; Iter   861/ 1097] train: loss: 0.0007247
[Epoch 58; Iter   891/ 1097] train: loss: 0.0000460
[Epoch 58; Iter   921/ 1097] train: loss: 0.0017212
[Epoch 58; Iter   951/ 1097] train: loss: 0.0044354
[Epoch 58; Iter   981/ 1097] train: loss: 0.0080897
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0004067
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0000807
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0005755
[Epoch 58] ogbg-molhiv: 0.634743 val loss: 85.054147
[Epoch 58] ogbg-molhiv: 0.604367 test loss: 76.375956
[Epoch 59; Iter     4/ 1097] train: loss: 0.0002237
[Epoch 59; Iter    34/ 1097] train: loss: 0.0025912
[Epoch 59; Iter    64/ 1097] train: loss: 0.1995348
[Epoch 59; Iter    94/ 1097] train: loss: 0.0012630
[Epoch 59; Iter   124/ 1097] train: loss: 0.0450101
[Epoch 59; Iter   154/ 1097] train: loss: 0.0103472
[Epoch 59; Iter   184/ 1097] train: loss: 0.0021840
[Epoch 59; Iter   214/ 1097] train: loss: 0.0003221
[Epoch 59; Iter   244/ 1097] train: loss: 0.0026906
[Epoch 59; Iter   274/ 1097] train: loss: 0.0014408
[Epoch 59; Iter   304/ 1097] train: loss: 0.0016184
[Epoch 59; Iter   334/ 1097] train: loss: 0.0004559
[Epoch 59; Iter   364/ 1097] train: loss: 0.0068383
[Epoch 59; Iter   394/ 1097] train: loss: 0.0001220
[Epoch 59; Iter   424/ 1097] train: loss: 0.0003931
[Epoch 59; Iter   454/ 1097] train: loss: 0.0021441
[Epoch 59; Iter   484/ 1097] train: loss: 0.0102916
[Epoch 59; Iter   514/ 1097] train: loss: 0.0010879
[Epoch 59; Iter   544/ 1097] train: loss: 0.0004295
[Epoch 59; Iter   574/ 1097] train: loss: 0.0000540
[Epoch 59; Iter   604/ 1097] train: loss: 0.0008098
[Epoch 59; Iter   634/ 1097] train: loss: 0.0007702
[Epoch 59; Iter   664/ 1097] train: loss: 0.0012508
[Epoch 59; Iter   694/ 1097] train: loss: 0.0252373
[Epoch 59; Iter   724/ 1097] train: loss: 0.0001482
[Epoch 59; Iter   754/ 1097] train: loss: 0.0010473
[Epoch 59; Iter   784/ 1097] train: loss: 0.0001742
[Epoch 59; Iter   814/ 1097] train: loss: 0.0051857
[Epoch 59; Iter   844/ 1097] train: loss: 0.0012162
[Epoch 59; Iter   874/ 1097] train: loss: 0.0480589
[Epoch 59; Iter   904/ 1097] train: loss: 0.2270273
[Epoch 59; Iter   934/ 1097] train: loss: 0.0001999
[Epoch 59; Iter   964/ 1097] train: loss: 0.0085250
[Epoch 59; Iter   994/ 1097] train: loss: 0.0008358
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0067512
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0000606
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0000301
[Epoch 59] ogbg-molhiv: 0.657606 val loss: 63.296858
[Epoch 59] ogbg-molhiv: 0.611366 test loss: 56.676261
[Epoch 60; Iter    17/ 1097] train: loss: 0.0001905
[Epoch 60; Iter    47/ 1097] train: loss: 0.0002525
[Epoch 60; Iter    77/ 1097] train: loss: 0.0075256
[Epoch 60; Iter   107/ 1097] train: loss: 0.0025436
[Epoch 60; Iter   137/ 1097] train: loss: 0.0058335
[Epoch 60; Iter   167/ 1097] train: loss: 0.0002015
[Epoch 60; Iter   197/ 1097] train: loss: 0.0001577
[Epoch 60; Iter   227/ 1097] train: loss: 0.0351634
[Epoch 60; Iter   257/ 1097] train: loss: 0.0001799
[Epoch 60; Iter   287/ 1097] train: loss: 0.0272332
[Epoch 60; Iter   317/ 1097] train: loss: 0.0001514
[Epoch 60; Iter   347/ 1097] train: loss: 0.0006073
[Epoch 60; Iter   377/ 1097] train: loss: 0.0003742
[Epoch 60; Iter   407/ 1097] train: loss: 0.0299396
[Epoch 60; Iter   437/ 1097] train: loss: 0.0000512
[Epoch 60; Iter   467/ 1097] train: loss: 0.0081972
[Epoch 60; Iter   497/ 1097] train: loss: 0.0011462
[Epoch 60; Iter   527/ 1097] train: loss: 0.0001336
[Epoch 60; Iter   557/ 1097] train: loss: 0.0004576
[Epoch 60; Iter   587/ 1097] train: loss: 0.0001565
[Epoch 60; Iter   617/ 1097] train: loss: 0.0026325
[Epoch 60; Iter   647/ 1097] train: loss: 0.0000361
[Epoch 60; Iter   677/ 1097] train: loss: 0.0016328
[Epoch 60; Iter   707/ 1097] train: loss: 0.0362563
[Epoch 60; Iter   737/ 1097] train: loss: 0.0003786
[Epoch 60; Iter   767/ 1097] train: loss: 0.0006933
[Epoch 60; Iter   797/ 1097] train: loss: 0.0034115
[Epoch 60; Iter   827/ 1097] train: loss: 0.0004598
[Epoch 60; Iter   857/ 1097] train: loss: 0.0009109
[Epoch 60; Iter   887/ 1097] train: loss: 0.0004827
[Epoch 60; Iter   917/ 1097] train: loss: 0.0014962
[Epoch 60; Iter   947/ 1097] train: loss: 0.0009962
[Epoch 60; Iter   977/ 1097] train: loss: 0.0014480
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0020633
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0000751
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0005201
[Epoch 48; Iter   851/ 1097] train: loss: 0.0047389
[Epoch 48; Iter   881/ 1097] train: loss: 0.1987624
[Epoch 48; Iter   911/ 1097] train: loss: 0.2530694
[Epoch 48; Iter   941/ 1097] train: loss: 0.0432729
[Epoch 48; Iter   971/ 1097] train: loss: 0.0321711
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0790867
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0840767
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0104406
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0299013
[Epoch 48] ogbg-molhiv: 0.833505 val loss: 0.082201
[Epoch 48] ogbg-molhiv: 0.722727 test loss: 0.155492
[Epoch 49; Iter    24/ 1097] train: loss: 0.0636845
[Epoch 49; Iter    54/ 1097] train: loss: 0.1339335
[Epoch 49; Iter    84/ 1097] train: loss: 0.0322023
[Epoch 49; Iter   114/ 1097] train: loss: 0.0329137
[Epoch 49; Iter   144/ 1097] train: loss: 0.0467436
[Epoch 49; Iter   174/ 1097] train: loss: 0.0888547
[Epoch 49; Iter   204/ 1097] train: loss: 0.0115461
[Epoch 49; Iter   234/ 1097] train: loss: 0.0179924
[Epoch 49; Iter   264/ 1097] train: loss: 0.0415421
[Epoch 49; Iter   294/ 1097] train: loss: 0.0679585
[Epoch 49; Iter   324/ 1097] train: loss: 0.0083943
[Epoch 49; Iter   354/ 1097] train: loss: 0.0132644
[Epoch 49; Iter   384/ 1097] train: loss: 0.1829354
[Epoch 49; Iter   414/ 1097] train: loss: 0.0170732
[Epoch 49; Iter   444/ 1097] train: loss: 0.0137785
[Epoch 49; Iter   474/ 1097] train: loss: 0.2832489
[Epoch 49; Iter   504/ 1097] train: loss: 0.0307126
[Epoch 49; Iter   534/ 1097] train: loss: 0.0279525
[Epoch 49; Iter   564/ 1097] train: loss: 0.0344822
[Epoch 49; Iter   594/ 1097] train: loss: 0.1079337
[Epoch 49; Iter   624/ 1097] train: loss: 0.0531520
[Epoch 49; Iter   654/ 1097] train: loss: 0.1206815
[Epoch 49; Iter   684/ 1097] train: loss: 0.0286447
[Epoch 49; Iter   714/ 1097] train: loss: 0.0183857
[Epoch 49; Iter   744/ 1097] train: loss: 0.0803529
[Epoch 49; Iter   774/ 1097] train: loss: 0.0793030
[Epoch 49; Iter   804/ 1097] train: loss: 0.1147343
[Epoch 49; Iter   834/ 1097] train: loss: 0.0206862
[Epoch 49; Iter   864/ 1097] train: loss: 0.0265022
[Epoch 49; Iter   894/ 1097] train: loss: 0.0167899
[Epoch 49; Iter   924/ 1097] train: loss: 0.1534593
[Epoch 49; Iter   954/ 1097] train: loss: 0.0359800
[Epoch 49; Iter   984/ 1097] train: loss: 0.0527522
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0106937
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0472277
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0406114
[Epoch 49] ogbg-molhiv: 0.831756 val loss: 0.081551
[Epoch 49] ogbg-molhiv: 0.754377 test loss: 0.148244
[Epoch 50; Iter     7/ 1097] train: loss: 0.0328040
[Epoch 50; Iter    37/ 1097] train: loss: 0.0748252
[Epoch 50; Iter    67/ 1097] train: loss: 0.0211368
[Epoch 50; Iter    97/ 1097] train: loss: 0.0090662
[Epoch 50; Iter   127/ 1097] train: loss: 0.0161905
[Epoch 50; Iter   157/ 1097] train: loss: 0.0546115
[Epoch 50; Iter   187/ 1097] train: loss: 0.1599066
[Epoch 50; Iter   217/ 1097] train: loss: 0.0344132
[Epoch 50; Iter   247/ 1097] train: loss: 0.0265399
[Epoch 50; Iter   277/ 1097] train: loss: 0.0165963
[Epoch 50; Iter   307/ 1097] train: loss: 0.0960500
[Epoch 50; Iter   337/ 1097] train: loss: 0.0723720
[Epoch 50; Iter   367/ 1097] train: loss: 0.2197659
[Epoch 50; Iter   397/ 1097] train: loss: 0.0130971
[Epoch 50; Iter   427/ 1097] train: loss: 0.1430018
[Epoch 50; Iter   457/ 1097] train: loss: 0.1235707
[Epoch 50; Iter   487/ 1097] train: loss: 0.0550500
[Epoch 50; Iter   517/ 1097] train: loss: 0.0481967
[Epoch 50; Iter   547/ 1097] train: loss: 0.0190850
[Epoch 50; Iter   577/ 1097] train: loss: 0.0094848
[Epoch 50; Iter   607/ 1097] train: loss: 0.0107938
[Epoch 50; Iter   637/ 1097] train: loss: 0.0645011
[Epoch 50; Iter   667/ 1097] train: loss: 0.0775709
[Epoch 50; Iter   697/ 1097] train: loss: 0.0275694
[Epoch 50; Iter   727/ 1097] train: loss: 0.0646060
[Epoch 50; Iter   757/ 1097] train: loss: 0.0083658
[Epoch 50; Iter   787/ 1097] train: loss: 0.1287740
[Epoch 50; Iter   817/ 1097] train: loss: 0.0809360
[Epoch 50; Iter   847/ 1097] train: loss: 0.0212179
[Epoch 50; Iter   877/ 1097] train: loss: 0.0477371
[Epoch 50; Iter   907/ 1097] train: loss: 0.0310242
[Epoch 50; Iter   937/ 1097] train: loss: 0.0127320
[Epoch 50; Iter   967/ 1097] train: loss: 0.0790512
[Epoch 50; Iter   997/ 1097] train: loss: 0.0307110
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0218251
[Epoch 50; Iter  1057/ 1097] train: loss: 0.1515321
[Epoch 50; Iter  1087/ 1097] train: loss: 0.1979884
[Epoch 50] ogbg-molhiv: 0.835789 val loss: 0.080619
[Epoch 50] ogbg-molhiv: 0.745354 test loss: 0.151486
[Epoch 51; Iter    20/ 1097] train: loss: 0.0650939
[Epoch 51; Iter    50/ 1097] train: loss: 0.0122809
[Epoch 51; Iter    80/ 1097] train: loss: 0.0624482
[Epoch 51; Iter   110/ 1097] train: loss: 0.1498010
[Epoch 51; Iter   140/ 1097] train: loss: 0.0363845
[Epoch 51; Iter   170/ 1097] train: loss: 0.0691353
[Epoch 51; Iter   200/ 1097] train: loss: 0.0673707
[Epoch 51; Iter   230/ 1097] train: loss: 0.2366465
[Epoch 51; Iter   260/ 1097] train: loss: 0.1474856
[Epoch 51; Iter   290/ 1097] train: loss: 0.0997261
[Epoch 51; Iter   320/ 1097] train: loss: 0.0243598
[Epoch 51; Iter   350/ 1097] train: loss: 0.0124042
[Epoch 51; Iter   380/ 1097] train: loss: 0.0676965
[Epoch 51; Iter   410/ 1097] train: loss: 0.1127905
[Epoch 51; Iter   440/ 1097] train: loss: 0.0241490
[Epoch 51; Iter   470/ 1097] train: loss: 0.0850751
[Epoch 51; Iter   500/ 1097] train: loss: 0.0398145
[Epoch 51; Iter   530/ 1097] train: loss: 0.0237129
[Epoch 51; Iter   560/ 1097] train: loss: 0.0215542
[Epoch 51; Iter   590/ 1097] train: loss: 0.1524655
[Epoch 51; Iter   620/ 1097] train: loss: 0.0353142
[Epoch 51; Iter   650/ 1097] train: loss: 0.0097895
[Epoch 51; Iter   680/ 1097] train: loss: 0.0677033
[Epoch 51; Iter   710/ 1097] train: loss: 0.1025931
[Epoch 51; Iter   740/ 1097] train: loss: 0.0812194
[Epoch 51; Iter   770/ 1097] train: loss: 0.0326600
[Epoch 51; Iter   800/ 1097] train: loss: 0.0398119
[Epoch 51; Iter   830/ 1097] train: loss: 0.0079266
[Epoch 51; Iter   860/ 1097] train: loss: 0.0113521
[Epoch 51; Iter   890/ 1097] train: loss: 0.0375874
[Epoch 51; Iter   920/ 1097] train: loss: 0.0097698
[Epoch 51; Iter   950/ 1097] train: loss: 0.0950122
[Epoch 51; Iter   980/ 1097] train: loss: 0.0145326
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0316707
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0515594
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0799732
[Epoch 51] ogbg-molhiv: 0.832602 val loss: 0.079631
[Epoch 51] ogbg-molhiv: 0.734491 test loss: 0.155651
[Epoch 52; Iter     3/ 1097] train: loss: 0.1535134
[Epoch 52; Iter    33/ 1097] train: loss: 0.0171681
[Epoch 52; Iter    63/ 1097] train: loss: 0.0555152
[Epoch 52; Iter    93/ 1097] train: loss: 0.0953347
[Epoch 52; Iter   123/ 1097] train: loss: 0.0826733
[Epoch 52; Iter   153/ 1097] train: loss: 0.0320694
[Epoch 52; Iter   183/ 1097] train: loss: 0.0160241
[Epoch 52; Iter   213/ 1097] train: loss: 0.0315483
[Epoch 52; Iter   243/ 1097] train: loss: 0.0263399
[Epoch 52; Iter   273/ 1097] train: loss: 0.0172009
[Epoch 52; Iter   303/ 1097] train: loss: 0.0586685
[Epoch 52; Iter   333/ 1097] train: loss: 0.0829067
[Epoch 52; Iter   363/ 1097] train: loss: 0.0137497
[Epoch 52; Iter   393/ 1097] train: loss: 0.0717875
[Epoch 52; Iter   423/ 1097] train: loss: 0.0113635
[Epoch 52; Iter   453/ 1097] train: loss: 0.0767455
[Epoch 52; Iter   483/ 1097] train: loss: 0.0543864
[Epoch 52; Iter   513/ 1097] train: loss: 0.0159400
[Epoch 52; Iter   543/ 1097] train: loss: 0.0627891
[Epoch 52; Iter   573/ 1097] train: loss: 0.1694669
[Epoch 52; Iter   603/ 1097] train: loss: 0.0212972
[Epoch 52; Iter   633/ 1097] train: loss: 0.0496171
[Epoch 52; Iter   663/ 1097] train: loss: 0.0146047
[Epoch 52; Iter   693/ 1097] train: loss: 0.0274697
[Epoch 52; Iter   723/ 1097] train: loss: 0.0313365
[Epoch 52; Iter   753/ 1097] train: loss: 0.0603372
[Epoch 52; Iter   783/ 1097] train: loss: 0.0563696
[Epoch 52; Iter   813/ 1097] train: loss: 0.0716392
[Epoch 52; Iter   843/ 1097] train: loss: 0.0069852
[Epoch 52; Iter   873/ 1097] train: loss: 0.0508668
[Epoch 52; Iter   903/ 1097] train: loss: 0.1393601
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0046739
[Epoch 60] ogbg-molhiv: 0.625193 val loss: 0.280559
[Epoch 60] ogbg-molhiv: 0.712141 test loss: 0.320210
[Epoch 61; Iter    30/ 1097] train: loss: 0.0005795
[Epoch 61; Iter    60/ 1097] train: loss: 0.0006906
[Epoch 61; Iter    90/ 1097] train: loss: 0.0138919
[Epoch 61; Iter   120/ 1097] train: loss: 0.0039661
[Epoch 61; Iter   150/ 1097] train: loss: 0.0867226
[Epoch 61; Iter   180/ 1097] train: loss: 0.0020189
[Epoch 61; Iter   210/ 1097] train: loss: 0.0014121
[Epoch 61; Iter   240/ 1097] train: loss: 0.0002778
[Epoch 61; Iter   270/ 1097] train: loss: 0.0027918
[Epoch 61; Iter   300/ 1097] train: loss: 0.0040633
[Epoch 61; Iter   330/ 1097] train: loss: 0.0011668
[Epoch 61; Iter   360/ 1097] train: loss: 0.0047329
[Epoch 61; Iter   390/ 1097] train: loss: 0.0225375
[Epoch 61; Iter   420/ 1097] train: loss: 0.0019848
[Epoch 61; Iter   450/ 1097] train: loss: 0.0926883
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001517
[Epoch 61; Iter   510/ 1097] train: loss: 0.0014172
[Epoch 61; Iter   540/ 1097] train: loss: 0.0004512
[Epoch 61; Iter   570/ 1097] train: loss: 0.0146493
[Epoch 61; Iter   600/ 1097] train: loss: 0.0087160
[Epoch 61; Iter   630/ 1097] train: loss: 0.0361341
[Epoch 61; Iter   660/ 1097] train: loss: 0.0004343
[Epoch 61; Iter   690/ 1097] train: loss: 0.0003965
[Epoch 61; Iter   720/ 1097] train: loss: 0.0003240
[Epoch 61; Iter   750/ 1097] train: loss: 0.0007751
[Epoch 61; Iter   780/ 1097] train: loss: 0.0058532
[Epoch 61; Iter   810/ 1097] train: loss: 0.1319216
[Epoch 61; Iter   840/ 1097] train: loss: 0.0308694
[Epoch 61; Iter   870/ 1097] train: loss: 0.0010561
[Epoch 61; Iter   900/ 1097] train: loss: 0.0143928
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000666
[Epoch 61; Iter   960/ 1097] train: loss: 0.0044947
[Epoch 61; Iter   990/ 1097] train: loss: 0.1007650
[Epoch 61; Iter  1020/ 1097] train: loss: 0.2175823
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0248086
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0002268
[Epoch 61] ogbg-molhiv: 0.664021 val loss: 0.232306
[Epoch 61] ogbg-molhiv: 0.684005 test loss: 0.315478
[Epoch 62; Iter    13/ 1097] train: loss: 0.0451893
[Epoch 62; Iter    43/ 1097] train: loss: 0.0051075
[Epoch 62; Iter    73/ 1097] train: loss: 0.0124368
[Epoch 62; Iter   103/ 1097] train: loss: 0.0051815
[Epoch 62; Iter   133/ 1097] train: loss: 0.0035319
[Epoch 62; Iter   163/ 1097] train: loss: 0.0000847
[Epoch 62; Iter   193/ 1097] train: loss: 0.0011143
[Epoch 62; Iter   223/ 1097] train: loss: 0.0016729
[Epoch 62; Iter   253/ 1097] train: loss: 0.0005369
[Epoch 62; Iter   283/ 1097] train: loss: 0.0005491
[Epoch 62; Iter   313/ 1097] train: loss: 0.0016677
[Epoch 62; Iter   343/ 1097] train: loss: 0.0003737
[Epoch 62; Iter   373/ 1097] train: loss: 0.0046166
[Epoch 62; Iter   403/ 1097] train: loss: 0.0004174
[Epoch 62; Iter   433/ 1097] train: loss: 0.0070616
[Epoch 62; Iter   463/ 1097] train: loss: 0.0790522
[Epoch 62; Iter   493/ 1097] train: loss: 0.0037867
[Epoch 62; Iter   523/ 1097] train: loss: 0.0002480
[Epoch 62; Iter   553/ 1097] train: loss: 0.0006442
[Epoch 62; Iter   583/ 1097] train: loss: 0.0267663
[Epoch 62; Iter   613/ 1097] train: loss: 0.0001847
[Epoch 62; Iter   643/ 1097] train: loss: 0.0041336
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000781
[Epoch 62; Iter   703/ 1097] train: loss: 0.0011116
[Epoch 62; Iter   733/ 1097] train: loss: 0.0136223
[Epoch 62; Iter   763/ 1097] train: loss: 0.0037555
[Epoch 62; Iter   793/ 1097] train: loss: 0.0057100
[Epoch 62; Iter   823/ 1097] train: loss: 0.0006330
[Epoch 62; Iter   853/ 1097] train: loss: 0.0006183
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027678
[Epoch 62; Iter   913/ 1097] train: loss: 0.0001646
[Epoch 62; Iter   943/ 1097] train: loss: 0.0028298
[Epoch 62; Iter   973/ 1097] train: loss: 0.0003894
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0011171
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0005405
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000934
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0002443
[Epoch 62] ogbg-molhiv: 0.700360 val loss: 0.210726
[Epoch 62] ogbg-molhiv: 0.730437 test loss: 0.280914
[Epoch 63; Iter    26/ 1097] train: loss: 0.0001041
[Epoch 63; Iter    56/ 1097] train: loss: 0.0002448
[Epoch 63; Iter    86/ 1097] train: loss: 0.0127419
[Epoch 63; Iter   116/ 1097] train: loss: 0.0021373
[Epoch 63; Iter   146/ 1097] train: loss: 0.0029109
[Epoch 63; Iter   176/ 1097] train: loss: 0.0233127
[Epoch 63; Iter   206/ 1097] train: loss: 0.0010703
[Epoch 63; Iter   236/ 1097] train: loss: 0.0641593
[Epoch 63; Iter   266/ 1097] train: loss: 0.0044266
[Epoch 63; Iter   296/ 1097] train: loss: 0.0012258
[Epoch 63; Iter   326/ 1097] train: loss: 0.0561043
[Epoch 63; Iter   356/ 1097] train: loss: 0.0131931
[Epoch 63; Iter   386/ 1097] train: loss: 0.0008853
[Epoch 63; Iter   416/ 1097] train: loss: 0.0042147
[Epoch 63; Iter   446/ 1097] train: loss: 0.0001693
[Epoch 63; Iter   476/ 1097] train: loss: 0.0001355
[Epoch 63; Iter   506/ 1097] train: loss: 0.0003743
[Epoch 63; Iter   536/ 1097] train: loss: 0.0069393
[Epoch 63; Iter   566/ 1097] train: loss: 0.0002735
[Epoch 63; Iter   596/ 1097] train: loss: 0.0059836
[Epoch 63; Iter   626/ 1097] train: loss: 0.0009935
[Epoch 63; Iter   656/ 1097] train: loss: 0.0004312
[Epoch 63; Iter   686/ 1097] train: loss: 0.0001057
[Epoch 63; Iter   716/ 1097] train: loss: 0.0243852
[Epoch 63; Iter   746/ 1097] train: loss: 0.0018301
[Epoch 63; Iter   776/ 1097] train: loss: 0.0013762
[Epoch 63; Iter   806/ 1097] train: loss: 0.0007696
[Epoch 63; Iter   836/ 1097] train: loss: 0.0079877
[Epoch 63; Iter   866/ 1097] train: loss: 0.0004695
[Epoch 63; Iter   896/ 1097] train: loss: 0.0004846
[Epoch 63; Iter   926/ 1097] train: loss: 0.0014346
[Epoch 63; Iter   956/ 1097] train: loss: 0.0494487
[Epoch 63; Iter   986/ 1097] train: loss: 0.0024998
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0001280
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0034140
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0184442
[Epoch 63] ogbg-molhiv: 0.750220 val loss: 0.210280
[Epoch 63] ogbg-molhiv: 0.731318 test loss: 0.326410
[Epoch 64; Iter     9/ 1097] train: loss: 0.0004909
[Epoch 64; Iter    39/ 1097] train: loss: 0.0001792
[Epoch 64; Iter    69/ 1097] train: loss: 0.0069287
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000347
[Epoch 64; Iter   129/ 1097] train: loss: 0.0003854
[Epoch 64; Iter   159/ 1097] train: loss: 0.0031017
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002084
[Epoch 64; Iter   219/ 1097] train: loss: 0.0019127
[Epoch 64; Iter   249/ 1097] train: loss: 0.0006262
[Epoch 64; Iter   279/ 1097] train: loss: 0.0006152
[Epoch 64; Iter   309/ 1097] train: loss: 0.0007593
[Epoch 64; Iter   339/ 1097] train: loss: 0.0959073
[Epoch 64; Iter   369/ 1097] train: loss: 0.0028748
[Epoch 64; Iter   399/ 1097] train: loss: 0.0275876
[Epoch 64; Iter   429/ 1097] train: loss: 0.0020834
[Epoch 64; Iter   459/ 1097] train: loss: 0.0003305
[Epoch 64; Iter   489/ 1097] train: loss: 0.0005518
[Epoch 64; Iter   519/ 1097] train: loss: 0.0157033
[Epoch 64; Iter   549/ 1097] train: loss: 0.0008284
[Epoch 64; Iter   579/ 1097] train: loss: 0.0004595
[Epoch 64; Iter   609/ 1097] train: loss: 0.0009276
[Epoch 64; Iter   639/ 1097] train: loss: 0.0036578
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002868
[Epoch 64; Iter   699/ 1097] train: loss: 0.0127574
[Epoch 64; Iter   729/ 1097] train: loss: 0.0011118
[Epoch 64; Iter   759/ 1097] train: loss: 0.0007177
[Epoch 64; Iter   789/ 1097] train: loss: 0.0003779
[Epoch 64; Iter   819/ 1097] train: loss: 0.0004295
[Epoch 64; Iter   849/ 1097] train: loss: 0.1067576
[Epoch 64; Iter   879/ 1097] train: loss: 0.0019167
[Epoch 64; Iter   909/ 1097] train: loss: 0.0236455
[Epoch 64; Iter   939/ 1097] train: loss: 0.0001227
[Epoch 64; Iter   969/ 1097] train: loss: 0.0198451
[Epoch 64; Iter   999/ 1097] train: loss: 0.0558699
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0149809
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0004096
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0074842
[Epoch 64] ogbg-molhiv: 0.697127 val loss: 0.211933
[Epoch 64] ogbg-molhiv: 0.745725 test loss: 0.290957
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0406775
[Epoch 60] ogbg-molhiv: 0.669805 val loss: 5.514464
[Epoch 60] ogbg-molhiv: 0.699623 test loss: 2.177849
[Epoch 61; Iter    30/ 1097] train: loss: 0.0002899
[Epoch 61; Iter    60/ 1097] train: loss: 0.0019969
[Epoch 61; Iter    90/ 1097] train: loss: 0.0006908
[Epoch 61; Iter   120/ 1097] train: loss: 0.0012082
[Epoch 61; Iter   150/ 1097] train: loss: 0.0023778
[Epoch 61; Iter   180/ 1097] train: loss: 0.0033497
[Epoch 61; Iter   210/ 1097] train: loss: 0.0003624
[Epoch 61; Iter   240/ 1097] train: loss: 0.0003326
[Epoch 61; Iter   270/ 1097] train: loss: 0.0006194
[Epoch 61; Iter   300/ 1097] train: loss: 0.0012220
[Epoch 61; Iter   330/ 1097] train: loss: 0.0125597
[Epoch 61; Iter   360/ 1097] train: loss: 0.0036513
[Epoch 61; Iter   390/ 1097] train: loss: 0.0007285
[Epoch 61; Iter   420/ 1097] train: loss: 0.0160689
[Epoch 61; Iter   450/ 1097] train: loss: 0.0257441
[Epoch 61; Iter   480/ 1097] train: loss: 0.0011818
[Epoch 61; Iter   510/ 1097] train: loss: 0.0014505
[Epoch 61; Iter   540/ 1097] train: loss: 0.0154070
[Epoch 61; Iter   570/ 1097] train: loss: 0.0300529
[Epoch 61; Iter   600/ 1097] train: loss: 0.0008854
[Epoch 61; Iter   630/ 1097] train: loss: 0.0051491
[Epoch 61; Iter   660/ 1097] train: loss: 0.0047906
[Epoch 61; Iter   690/ 1097] train: loss: 0.0636925
[Epoch 61; Iter   720/ 1097] train: loss: 0.0361374
[Epoch 61; Iter   750/ 1097] train: loss: 0.0004877
[Epoch 61; Iter   780/ 1097] train: loss: 0.0105164
[Epoch 61; Iter   810/ 1097] train: loss: 0.0111788
[Epoch 61; Iter   840/ 1097] train: loss: 0.0011322
[Epoch 61; Iter   870/ 1097] train: loss: 0.0006157
[Epoch 61; Iter   900/ 1097] train: loss: 0.0101793
[Epoch 61; Iter   930/ 1097] train: loss: 0.0008646
[Epoch 61; Iter   960/ 1097] train: loss: 0.0031591
[Epoch 61; Iter   990/ 1097] train: loss: 0.0011609
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0046060
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0086116
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0033315
[Epoch 61] ogbg-molhiv: 0.705856 val loss: 1.720467
[Epoch 61] ogbg-molhiv: 0.693237 test loss: 1.048191
[Epoch 62; Iter    13/ 1097] train: loss: 0.0019478
[Epoch 62; Iter    43/ 1097] train: loss: 0.0093883
[Epoch 62; Iter    73/ 1097] train: loss: 0.0030231
[Epoch 62; Iter   103/ 1097] train: loss: 0.0001710
[Epoch 62; Iter   133/ 1097] train: loss: 0.0130297
[Epoch 62; Iter   163/ 1097] train: loss: 0.0040248
[Epoch 62; Iter   193/ 1097] train: loss: 0.0003125
[Epoch 62; Iter   223/ 1097] train: loss: 0.0407286
[Epoch 62; Iter   253/ 1097] train: loss: 0.0009981
[Epoch 62; Iter   283/ 1097] train: loss: 0.0026501
[Epoch 62; Iter   313/ 1097] train: loss: 0.0571193
[Epoch 62; Iter   343/ 1097] train: loss: 0.0007428
[Epoch 62; Iter   373/ 1097] train: loss: 0.0004107
[Epoch 62; Iter   403/ 1097] train: loss: 0.0178076
[Epoch 62; Iter   433/ 1097] train: loss: 0.0011213
[Epoch 62; Iter   463/ 1097] train: loss: 0.0023696
[Epoch 62; Iter   493/ 1097] train: loss: 0.1098500
[Epoch 62; Iter   523/ 1097] train: loss: 0.0055955
[Epoch 62; Iter   553/ 1097] train: loss: 0.0071214
[Epoch 62; Iter   583/ 1097] train: loss: 0.0215840
[Epoch 62; Iter   613/ 1097] train: loss: 0.0001426
[Epoch 62; Iter   643/ 1097] train: loss: 0.0141761
[Epoch 62; Iter   673/ 1097] train: loss: 0.0107721
[Epoch 62; Iter   703/ 1097] train: loss: 0.0007099
[Epoch 62; Iter   733/ 1097] train: loss: 0.0176091
[Epoch 62; Iter   763/ 1097] train: loss: 0.0024608
[Epoch 62; Iter   793/ 1097] train: loss: 0.0390372
[Epoch 62; Iter   823/ 1097] train: loss: 0.0046749
[Epoch 62; Iter   853/ 1097] train: loss: 0.0141396
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027121
[Epoch 62; Iter   913/ 1097] train: loss: 0.0003556
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001685
[Epoch 62; Iter   973/ 1097] train: loss: 0.0124343
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0042684
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001504
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0018185
[Epoch 62; Iter  1093/ 1097] train: loss: 0.2096782
[Epoch 62] ogbg-molhiv: 0.685703 val loss: 1.684361
[Epoch 62] ogbg-molhiv: 0.718564 test loss: 0.617230
[Epoch 63; Iter    26/ 1097] train: loss: 0.0025909
[Epoch 63; Iter    56/ 1097] train: loss: 0.0003378
[Epoch 63; Iter    86/ 1097] train: loss: 0.0071679
[Epoch 63; Iter   116/ 1097] train: loss: 0.0011766
[Epoch 63; Iter   146/ 1097] train: loss: 0.0017869
[Epoch 63; Iter   176/ 1097] train: loss: 0.0002969
[Epoch 63; Iter   206/ 1097] train: loss: 0.0166931
[Epoch 63; Iter   236/ 1097] train: loss: 0.0254598
[Epoch 63; Iter   266/ 1097] train: loss: 0.0017333
[Epoch 63; Iter   296/ 1097] train: loss: 0.0119749
[Epoch 63; Iter   326/ 1097] train: loss: 0.0068410
[Epoch 63; Iter   356/ 1097] train: loss: 0.0010443
[Epoch 63; Iter   386/ 1097] train: loss: 0.0719335
[Epoch 63; Iter   416/ 1097] train: loss: 0.0004159
[Epoch 63; Iter   446/ 1097] train: loss: 0.0058169
[Epoch 63; Iter   476/ 1097] train: loss: 0.0644456
[Epoch 63; Iter   506/ 1097] train: loss: 0.0692232
[Epoch 63; Iter   536/ 1097] train: loss: 0.0002832
[Epoch 63; Iter   566/ 1097] train: loss: 0.0164005
[Epoch 63; Iter   596/ 1097] train: loss: 0.0023258
[Epoch 63; Iter   626/ 1097] train: loss: 0.0013322
[Epoch 63; Iter   656/ 1097] train: loss: 0.0022104
[Epoch 63; Iter   686/ 1097] train: loss: 0.0038094
[Epoch 63; Iter   716/ 1097] train: loss: 0.0109156
[Epoch 63; Iter   746/ 1097] train: loss: 0.0038874
[Epoch 63; Iter   776/ 1097] train: loss: 0.0025897
[Epoch 63; Iter   806/ 1097] train: loss: 0.0003214
[Epoch 63; Iter   836/ 1097] train: loss: 0.0029312
[Epoch 63; Iter   866/ 1097] train: loss: 0.0176287
[Epoch 63; Iter   896/ 1097] train: loss: 0.0002533
[Epoch 63; Iter   926/ 1097] train: loss: 0.0139792
[Epoch 63; Iter   956/ 1097] train: loss: 0.0066725
[Epoch 63; Iter   986/ 1097] train: loss: 0.0001893
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0357350
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0008619
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0218532
[Epoch 63] ogbg-molhiv: 0.701793 val loss: 4.062165
[Epoch 63] ogbg-molhiv: 0.687132 test loss: 1.782676
[Epoch 64; Iter     9/ 1097] train: loss: 0.0085568
[Epoch 64; Iter    39/ 1097] train: loss: 0.0161962
[Epoch 64; Iter    69/ 1097] train: loss: 0.0021231
[Epoch 64; Iter    99/ 1097] train: loss: 0.0024304
[Epoch 64; Iter   129/ 1097] train: loss: 0.0092530
[Epoch 64; Iter   159/ 1097] train: loss: 0.0023866
[Epoch 64; Iter   189/ 1097] train: loss: 0.0003994
[Epoch 64; Iter   219/ 1097] train: loss: 0.0001196
[Epoch 64; Iter   249/ 1097] train: loss: 0.0002618
[Epoch 64; Iter   279/ 1097] train: loss: 0.0026410
[Epoch 64; Iter   309/ 1097] train: loss: 0.0002651
[Epoch 64; Iter   339/ 1097] train: loss: 0.0023290
[Epoch 64; Iter   369/ 1097] train: loss: 0.0008364
[Epoch 64; Iter   399/ 1097] train: loss: 0.0008063
[Epoch 64; Iter   429/ 1097] train: loss: 0.0120012
[Epoch 64; Iter   459/ 1097] train: loss: 0.0214526
[Epoch 64; Iter   489/ 1097] train: loss: 0.0047249
[Epoch 64; Iter   519/ 1097] train: loss: 0.0004178
[Epoch 64; Iter   549/ 1097] train: loss: 0.0011827
[Epoch 64; Iter   579/ 1097] train: loss: 0.0010950
[Epoch 64; Iter   609/ 1097] train: loss: 0.0006858
[Epoch 64; Iter   639/ 1097] train: loss: 0.0052525
[Epoch 64; Iter   669/ 1097] train: loss: 0.0123656
[Epoch 64; Iter   699/ 1097] train: loss: 0.0017499
[Epoch 64; Iter   729/ 1097] train: loss: 0.0357981
[Epoch 64; Iter   759/ 1097] train: loss: 0.0014802
[Epoch 64; Iter   789/ 1097] train: loss: 0.0436741
[Epoch 64; Iter   819/ 1097] train: loss: 0.0054836
[Epoch 64; Iter   849/ 1097] train: loss: 0.0156480
[Epoch 64; Iter   879/ 1097] train: loss: 0.0002039
[Epoch 64; Iter   909/ 1097] train: loss: 0.0220254
[Epoch 64; Iter   939/ 1097] train: loss: 0.0049951
[Epoch 64; Iter   969/ 1097] train: loss: 0.0698467
[Epoch 64; Iter   999/ 1097] train: loss: 0.0001692
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0148948
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0555560
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0058233
[Epoch 64] ogbg-molhiv: 0.706986 val loss: 3.056569
[Epoch 64] ogbg-molhiv: 0.713096 test loss: 1.346892
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003596
[Epoch 60] ogbg-molhiv: 0.793115 val loss: 0.172453
[Epoch 60] ogbg-molhiv: 0.726171 test loss: 0.300685
[Epoch 61; Iter    30/ 1097] train: loss: 0.0005864
[Epoch 61; Iter    60/ 1097] train: loss: 0.0135515
[Epoch 61; Iter    90/ 1097] train: loss: 0.0043921
[Epoch 61; Iter   120/ 1097] train: loss: 0.0086030
[Epoch 61; Iter   150/ 1097] train: loss: 0.0896983
[Epoch 61; Iter   180/ 1097] train: loss: 0.0002123
[Epoch 61; Iter   210/ 1097] train: loss: 0.0009627
[Epoch 61; Iter   240/ 1097] train: loss: 0.0009336
[Epoch 61; Iter   270/ 1097] train: loss: 0.0018402
[Epoch 61; Iter   300/ 1097] train: loss: 0.0004782
[Epoch 61; Iter   330/ 1097] train: loss: 0.0077008
[Epoch 61; Iter   360/ 1097] train: loss: 0.0002692
[Epoch 61; Iter   390/ 1097] train: loss: 0.0021830
[Epoch 61; Iter   420/ 1097] train: loss: 0.0018102
[Epoch 61; Iter   450/ 1097] train: loss: 0.0044784
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001549
[Epoch 61; Iter   510/ 1097] train: loss: 0.0009502
[Epoch 61; Iter   540/ 1097] train: loss: 0.0003822
[Epoch 61; Iter   570/ 1097] train: loss: 0.0055592
[Epoch 61; Iter   600/ 1097] train: loss: 0.0015460
[Epoch 61; Iter   630/ 1097] train: loss: 0.0009952
[Epoch 61; Iter   660/ 1097] train: loss: 0.0016285
[Epoch 61; Iter   690/ 1097] train: loss: 0.0107107
[Epoch 61; Iter   720/ 1097] train: loss: 0.0910162
[Epoch 61; Iter   750/ 1097] train: loss: 0.0134993
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002030
[Epoch 61; Iter   810/ 1097] train: loss: 0.0004419
[Epoch 61; Iter   840/ 1097] train: loss: 0.0104562
[Epoch 61; Iter   870/ 1097] train: loss: 0.0010745
[Epoch 61; Iter   900/ 1097] train: loss: 0.0624454
[Epoch 61; Iter   930/ 1097] train: loss: 0.0006474
[Epoch 61; Iter   960/ 1097] train: loss: 0.0018127
[Epoch 61; Iter   990/ 1097] train: loss: 0.0009271
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0031253
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0014740
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0197733
[Epoch 61] ogbg-molhiv: 0.769805 val loss: 0.187933
[Epoch 61] ogbg-molhiv: 0.738315 test loss: 0.307102
[Epoch 62; Iter    13/ 1097] train: loss: 0.0052430
[Epoch 62; Iter    43/ 1097] train: loss: 0.0021354
[Epoch 62; Iter    73/ 1097] train: loss: 0.0059230
[Epoch 62; Iter   103/ 1097] train: loss: 0.0000495
[Epoch 62; Iter   133/ 1097] train: loss: 0.0013007
[Epoch 62; Iter   163/ 1097] train: loss: 0.0508322
[Epoch 62; Iter   193/ 1097] train: loss: 0.0002098
[Epoch 62; Iter   223/ 1097] train: loss: 0.0125734
[Epoch 62; Iter   253/ 1097] train: loss: 0.0012350
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000936
[Epoch 62; Iter   313/ 1097] train: loss: 0.0045422
[Epoch 62; Iter   343/ 1097] train: loss: 0.0023255
[Epoch 62; Iter   373/ 1097] train: loss: 0.0010583
[Epoch 62; Iter   403/ 1097] train: loss: 0.0023703
[Epoch 62; Iter   433/ 1097] train: loss: 0.0001990
[Epoch 62; Iter   463/ 1097] train: loss: 0.0008546
[Epoch 62; Iter   493/ 1097] train: loss: 0.0014690
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003492
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000665
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003008
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000361
[Epoch 62; Iter   643/ 1097] train: loss: 0.0008750
[Epoch 62; Iter   673/ 1097] train: loss: 0.0007323
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001527
[Epoch 62; Iter   733/ 1097] train: loss: 0.0007597
[Epoch 62; Iter   763/ 1097] train: loss: 0.0000290
[Epoch 62; Iter   793/ 1097] train: loss: 0.0005035
[Epoch 62; Iter   823/ 1097] train: loss: 0.0007458
[Epoch 62; Iter   853/ 1097] train: loss: 0.0022275
[Epoch 62; Iter   883/ 1097] train: loss: 0.0004108
[Epoch 62; Iter   913/ 1097] train: loss: 0.0489996
[Epoch 62; Iter   943/ 1097] train: loss: 0.0005114
[Epoch 62; Iter   973/ 1097] train: loss: 0.0003430
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001831
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001162
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000504
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0006446
[Epoch 62] ogbg-molhiv: 0.761148 val loss: 0.207789
[Epoch 62] ogbg-molhiv: 0.707893 test loss: 0.310997
[Epoch 63; Iter    26/ 1097] train: loss: 0.0034885
[Epoch 63; Iter    56/ 1097] train: loss: 0.0006216
[Epoch 63; Iter    86/ 1097] train: loss: 0.0150210
[Epoch 63; Iter   116/ 1097] train: loss: 0.0003546
[Epoch 63; Iter   146/ 1097] train: loss: 0.0006145
[Epoch 63; Iter   176/ 1097] train: loss: 0.0000687
[Epoch 63; Iter   206/ 1097] train: loss: 0.0000342
[Epoch 63; Iter   236/ 1097] train: loss: 0.0007323
[Epoch 63; Iter   266/ 1097] train: loss: 0.0049521
[Epoch 63; Iter   296/ 1097] train: loss: 0.0009678
[Epoch 63; Iter   326/ 1097] train: loss: 0.0076118
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000553
[Epoch 63; Iter   386/ 1097] train: loss: 0.0258493
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000912
[Epoch 63; Iter   446/ 1097] train: loss: 0.0012887
[Epoch 63; Iter   476/ 1097] train: loss: 0.0036927
[Epoch 63; Iter   506/ 1097] train: loss: 0.0379671
[Epoch 63; Iter   536/ 1097] train: loss: 0.0001630
[Epoch 63; Iter   566/ 1097] train: loss: 0.0564113
[Epoch 63; Iter   596/ 1097] train: loss: 0.0000582
[Epoch 63; Iter   626/ 1097] train: loss: 0.0416108
[Epoch 63; Iter   656/ 1097] train: loss: 0.0002703
[Epoch 63; Iter   686/ 1097] train: loss: 0.0011964
[Epoch 63; Iter   716/ 1097] train: loss: 0.0012970
[Epoch 63; Iter   746/ 1097] train: loss: 0.0001693
[Epoch 63; Iter   776/ 1097] train: loss: 0.0206748
[Epoch 63; Iter   806/ 1097] train: loss: 0.0009531
[Epoch 63; Iter   836/ 1097] train: loss: 0.0006795
[Epoch 63; Iter   866/ 1097] train: loss: 0.0006369
[Epoch 63; Iter   896/ 1097] train: loss: 0.0048633
[Epoch 63; Iter   926/ 1097] train: loss: 0.0002251
[Epoch 63; Iter   956/ 1097] train: loss: 0.0000715
[Epoch 63; Iter   986/ 1097] train: loss: 0.0005591
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0008966
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0002413
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0065274
[Epoch 63] ogbg-molhiv: 0.767560 val loss: 0.196819
[Epoch 63] ogbg-molhiv: 0.723334 test loss: 0.310615
[Epoch 64; Iter     9/ 1097] train: loss: 0.0003123
[Epoch 64; Iter    39/ 1097] train: loss: 0.0204361
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000675
[Epoch 64; Iter    99/ 1097] train: loss: 0.0194807
[Epoch 64; Iter   129/ 1097] train: loss: 0.0000272
[Epoch 64; Iter   159/ 1097] train: loss: 0.0012966
[Epoch 64; Iter   189/ 1097] train: loss: 0.0079129
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000150
[Epoch 64; Iter   249/ 1097] train: loss: 0.0036438
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000946
[Epoch 64; Iter   309/ 1097] train: loss: 0.0012886
[Epoch 64; Iter   339/ 1097] train: loss: 0.0013215
[Epoch 64; Iter   369/ 1097] train: loss: 0.0010826
[Epoch 64; Iter   399/ 1097] train: loss: 0.0003343
[Epoch 64; Iter   429/ 1097] train: loss: 0.0020827
[Epoch 64; Iter   459/ 1097] train: loss: 0.0007235
[Epoch 64; Iter   489/ 1097] train: loss: 0.0068938
[Epoch 64; Iter   519/ 1097] train: loss: 0.0004332
[Epoch 64; Iter   549/ 1097] train: loss: 0.0004100
[Epoch 64; Iter   579/ 1097] train: loss: 0.0001179
[Epoch 64; Iter   609/ 1097] train: loss: 0.0002812
[Epoch 64; Iter   639/ 1097] train: loss: 0.0003388
[Epoch 64; Iter   669/ 1097] train: loss: 0.0801511
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001682
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002599
[Epoch 64; Iter   759/ 1097] train: loss: 0.0005371
[Epoch 64; Iter   789/ 1097] train: loss: 0.0023658
[Epoch 64; Iter   819/ 1097] train: loss: 0.0002928
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000803
[Epoch 64; Iter   879/ 1097] train: loss: 0.0003298
[Epoch 64; Iter   909/ 1097] train: loss: 0.0000395
[Epoch 64; Iter   939/ 1097] train: loss: 0.0004554
[Epoch 64; Iter   969/ 1097] train: loss: 0.0004415
[Epoch 64; Iter   999/ 1097] train: loss: 0.0067353
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0009737
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0039600
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0018828
[Epoch 64] ogbg-molhiv: 0.770637 val loss: 0.208303
[Epoch 64] ogbg-molhiv: 0.714969 test loss: 0.321924
[Epoch 48; Iter   851/ 1097] train: loss: 0.0961988
[Epoch 48; Iter   881/ 1097] train: loss: 0.0279280
[Epoch 48; Iter   911/ 1097] train: loss: 0.0698997
[Epoch 48; Iter   941/ 1097] train: loss: 0.0436805
[Epoch 48; Iter   971/ 1097] train: loss: 0.1679258
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0204187
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0421901
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0608696
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0979631
[Epoch 48] ogbg-molhiv: 0.811894 val loss: 0.080386
[Epoch 48] ogbg-molhiv: 0.758340 test loss: 0.143803
[Epoch 49; Iter    24/ 1097] train: loss: 0.0252192
[Epoch 49; Iter    54/ 1097] train: loss: 0.0189256
[Epoch 49; Iter    84/ 1097] train: loss: 0.0529459
[Epoch 49; Iter   114/ 1097] train: loss: 0.0166016
[Epoch 49; Iter   144/ 1097] train: loss: 0.0379143
[Epoch 49; Iter   174/ 1097] train: loss: 0.0147694
[Epoch 49; Iter   204/ 1097] train: loss: 0.0416996
[Epoch 49; Iter   234/ 1097] train: loss: 0.0316254
[Epoch 49; Iter   264/ 1097] train: loss: 0.0334005
[Epoch 49; Iter   294/ 1097] train: loss: 0.0185382
[Epoch 49; Iter   324/ 1097] train: loss: 0.1070679
[Epoch 49; Iter   354/ 1097] train: loss: 0.0586373
[Epoch 49; Iter   384/ 1097] train: loss: 0.0113015
[Epoch 49; Iter   414/ 1097] train: loss: 0.3352073
[Epoch 49; Iter   444/ 1097] train: loss: 0.0324332
[Epoch 49; Iter   474/ 1097] train: loss: 0.1092097
[Epoch 49; Iter   504/ 1097] train: loss: 0.0202612
[Epoch 49; Iter   534/ 1097] train: loss: 0.0357893
[Epoch 49; Iter   564/ 1097] train: loss: 0.0295613
[Epoch 49; Iter   594/ 1097] train: loss: 0.0433620
[Epoch 49; Iter   624/ 1097] train: loss: 0.0359070
[Epoch 49; Iter   654/ 1097] train: loss: 0.0215429
[Epoch 49; Iter   684/ 1097] train: loss: 0.0160596
[Epoch 49; Iter   714/ 1097] train: loss: 0.0212493
[Epoch 49; Iter   744/ 1097] train: loss: 0.0107404
[Epoch 49; Iter   774/ 1097] train: loss: 0.0457645
[Epoch 49; Iter   804/ 1097] train: loss: 0.0229503
[Epoch 49; Iter   834/ 1097] train: loss: 0.0207001
[Epoch 49; Iter   864/ 1097] train: loss: 0.0228086
[Epoch 49; Iter   894/ 1097] train: loss: 0.0665649
[Epoch 49; Iter   924/ 1097] train: loss: 0.0303924
[Epoch 49; Iter   954/ 1097] train: loss: 0.2417280
[Epoch 49; Iter   984/ 1097] train: loss: 0.0853603
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0510817
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0219311
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0117081
[Epoch 49] ogbg-molhiv: 0.773708 val loss: 0.088579
[Epoch 49] ogbg-molhiv: 0.737879 test loss: 0.153958
[Epoch 50; Iter     7/ 1097] train: loss: 0.0538041
[Epoch 50; Iter    37/ 1097] train: loss: 0.0141189
[Epoch 50; Iter    67/ 1097] train: loss: 0.1558783
[Epoch 50; Iter    97/ 1097] train: loss: 0.0207953
[Epoch 50; Iter   127/ 1097] train: loss: 0.1738478
[Epoch 50; Iter   157/ 1097] train: loss: 0.0197973
[Epoch 50; Iter   187/ 1097] train: loss: 0.0209727
[Epoch 50; Iter   217/ 1097] train: loss: 0.0239616
[Epoch 50; Iter   247/ 1097] train: loss: 0.0607687
[Epoch 50; Iter   277/ 1097] train: loss: 0.0720215
[Epoch 50; Iter   307/ 1097] train: loss: 0.0081307
[Epoch 50; Iter   337/ 1097] train: loss: 0.0134359
[Epoch 50; Iter   367/ 1097] train: loss: 0.0147738
[Epoch 50; Iter   397/ 1097] train: loss: 0.1295482
[Epoch 50; Iter   427/ 1097] train: loss: 0.0436384
[Epoch 50; Iter   457/ 1097] train: loss: 0.0184036
[Epoch 50; Iter   487/ 1097] train: loss: 0.1652537
[Epoch 50; Iter   517/ 1097] train: loss: 0.2168164
[Epoch 50; Iter   547/ 1097] train: loss: 0.0398929
[Epoch 50; Iter   577/ 1097] train: loss: 0.0797325
[Epoch 50; Iter   607/ 1097] train: loss: 0.1672455
[Epoch 50; Iter   637/ 1097] train: loss: 0.0449835
[Epoch 50; Iter   667/ 1097] train: loss: 0.0535830
[Epoch 50; Iter   697/ 1097] train: loss: 0.0173022
[Epoch 50; Iter   727/ 1097] train: loss: 0.1400758
[Epoch 50; Iter   757/ 1097] train: loss: 0.0405101
[Epoch 50; Iter   787/ 1097] train: loss: 0.0200359
[Epoch 50; Iter   817/ 1097] train: loss: 0.0105742
[Epoch 50; Iter   847/ 1097] train: loss: 0.0754779
[Epoch 50; Iter   877/ 1097] train: loss: 0.0178750
[Epoch 50; Iter   907/ 1097] train: loss: 0.0392127
[Epoch 50; Iter   937/ 1097] train: loss: 0.0237751
[Epoch 50; Iter   967/ 1097] train: loss: 0.1024811
[Epoch 50; Iter   997/ 1097] train: loss: 0.0471631
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0231826
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0257390
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0741599
[Epoch 50] ogbg-molhiv: 0.810874 val loss: 0.081557
[Epoch 50] ogbg-molhiv: 0.743881 test loss: 0.151759
[Epoch 51; Iter    20/ 1097] train: loss: 0.0383481
[Epoch 51; Iter    50/ 1097] train: loss: 0.2046150
[Epoch 51; Iter    80/ 1097] train: loss: 0.0891519
[Epoch 51; Iter   110/ 1097] train: loss: 0.0417785
[Epoch 51; Iter   140/ 1097] train: loss: 0.1250415
[Epoch 51; Iter   170/ 1097] train: loss: 0.0211324
[Epoch 51; Iter   200/ 1097] train: loss: 0.0799099
[Epoch 51; Iter   230/ 1097] train: loss: 0.0258105
[Epoch 51; Iter   260/ 1097] train: loss: 0.0105572
[Epoch 51; Iter   290/ 1097] train: loss: 0.0099878
[Epoch 51; Iter   320/ 1097] train: loss: 0.1982370
[Epoch 51; Iter   350/ 1097] train: loss: 0.0121242
[Epoch 51; Iter   380/ 1097] train: loss: 0.0872279
[Epoch 51; Iter   410/ 1097] train: loss: 0.0301291
[Epoch 51; Iter   440/ 1097] train: loss: 0.0617483
[Epoch 51; Iter   470/ 1097] train: loss: 0.1114739
[Epoch 51; Iter   500/ 1097] train: loss: 0.0120751
[Epoch 51; Iter   530/ 1097] train: loss: 0.0259058
[Epoch 51; Iter   560/ 1097] train: loss: 0.0254264
[Epoch 51; Iter   590/ 1097] train: loss: 0.1108088
[Epoch 51; Iter   620/ 1097] train: loss: 0.0145575
[Epoch 51; Iter   650/ 1097] train: loss: 0.0110405
[Epoch 51; Iter   680/ 1097] train: loss: 0.1181952
[Epoch 51; Iter   710/ 1097] train: loss: 0.0592276
[Epoch 51; Iter   740/ 1097] train: loss: 0.0061099
[Epoch 51; Iter   770/ 1097] train: loss: 0.0376430
[Epoch 51; Iter   800/ 1097] train: loss: 0.3539389
[Epoch 51; Iter   830/ 1097] train: loss: 0.0940784
[Epoch 51; Iter   860/ 1097] train: loss: 0.0551055
[Epoch 51; Iter   890/ 1097] train: loss: 0.1532081
[Epoch 51; Iter   920/ 1097] train: loss: 0.0292912
[Epoch 51; Iter   950/ 1097] train: loss: 0.0498546
[Epoch 51; Iter   980/ 1097] train: loss: 0.0417514
[Epoch 51; Iter  1010/ 1097] train: loss: 0.1732119
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1192931
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0751283
[Epoch 51] ogbg-molhiv: 0.794698 val loss: 0.081360
[Epoch 51] ogbg-molhiv: 0.750028 test loss: 0.149208
[Epoch 52; Iter     3/ 1097] train: loss: 0.1874983
[Epoch 52; Iter    33/ 1097] train: loss: 0.0455005
[Epoch 52; Iter    63/ 1097] train: loss: 0.0983351
[Epoch 52; Iter    93/ 1097] train: loss: 0.1171486
[Epoch 52; Iter   123/ 1097] train: loss: 0.0092890
[Epoch 52; Iter   153/ 1097] train: loss: 0.0087297
[Epoch 52; Iter   183/ 1097] train: loss: 0.0196064
[Epoch 52; Iter   213/ 1097] train: loss: 0.0135730
[Epoch 52; Iter   243/ 1097] train: loss: 0.0278760
[Epoch 52; Iter   273/ 1097] train: loss: 0.0802585
[Epoch 52; Iter   303/ 1097] train: loss: 0.2122773
[Epoch 52; Iter   333/ 1097] train: loss: 0.0131168
[Epoch 52; Iter   363/ 1097] train: loss: 0.0990964
[Epoch 52; Iter   393/ 1097] train: loss: 0.1142664
[Epoch 52; Iter   423/ 1097] train: loss: 0.0924171
[Epoch 52; Iter   453/ 1097] train: loss: 0.0165338
[Epoch 52; Iter   483/ 1097] train: loss: 0.1755978
[Epoch 52; Iter   513/ 1097] train: loss: 0.0209999
[Epoch 52; Iter   543/ 1097] train: loss: 0.0431990
[Epoch 52; Iter   573/ 1097] train: loss: 0.0085805
[Epoch 52; Iter   603/ 1097] train: loss: 0.0507375
[Epoch 52; Iter   633/ 1097] train: loss: 0.0925944
[Epoch 52; Iter   663/ 1097] train: loss: 0.1138075
[Epoch 52; Iter   693/ 1097] train: loss: 0.0763416
[Epoch 52; Iter   723/ 1097] train: loss: 0.1537886
[Epoch 52; Iter   753/ 1097] train: loss: 0.0244197
[Epoch 52; Iter   783/ 1097] train: loss: 0.0669417
[Epoch 52; Iter   813/ 1097] train: loss: 0.1071798
[Epoch 52; Iter   843/ 1097] train: loss: 0.2347269
[Epoch 52; Iter   873/ 1097] train: loss: 0.0168622
[Epoch 52; Iter   903/ 1097] train: loss: 0.0189516
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0013463
[Epoch 60] ogbg-molhiv: 0.772778 val loss: 0.316351
[Epoch 60] ogbg-molhiv: 0.744031 test loss: 0.310010
[Epoch 61; Iter    30/ 1097] train: loss: 0.0023381
[Epoch 61; Iter    60/ 1097] train: loss: 0.0556146
[Epoch 61; Iter    90/ 1097] train: loss: 0.0002164
[Epoch 61; Iter   120/ 1097] train: loss: 0.0001566
[Epoch 61; Iter   150/ 1097] train: loss: 0.0013863
[Epoch 61; Iter   180/ 1097] train: loss: 0.0008221
[Epoch 61; Iter   210/ 1097] train: loss: 0.0010873
[Epoch 61; Iter   240/ 1097] train: loss: 0.0156772
[Epoch 61; Iter   270/ 1097] train: loss: 0.0057003
[Epoch 61; Iter   300/ 1097] train: loss: 0.0002463
[Epoch 61; Iter   330/ 1097] train: loss: 0.0004813
[Epoch 61; Iter   360/ 1097] train: loss: 0.0064598
[Epoch 61; Iter   390/ 1097] train: loss: 0.0000917
[Epoch 61; Iter   420/ 1097] train: loss: 0.1434545
[Epoch 61; Iter   450/ 1097] train: loss: 0.0000221
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001147
[Epoch 61; Iter   510/ 1097] train: loss: 0.0006969
[Epoch 61; Iter   540/ 1097] train: loss: 0.0023553
[Epoch 61; Iter   570/ 1097] train: loss: 0.0040215
[Epoch 61; Iter   600/ 1097] train: loss: 0.0007939
[Epoch 61; Iter   630/ 1097] train: loss: 0.0009731
[Epoch 61; Iter   660/ 1097] train: loss: 0.0000525
[Epoch 61; Iter   690/ 1097] train: loss: 0.0276218
[Epoch 61; Iter   720/ 1097] train: loss: 0.0003874
[Epoch 61; Iter   750/ 1097] train: loss: 0.0026584
[Epoch 61; Iter   780/ 1097] train: loss: 0.0006085
[Epoch 61; Iter   810/ 1097] train: loss: 0.0005911
[Epoch 61; Iter   840/ 1097] train: loss: 0.0042387
[Epoch 61; Iter   870/ 1097] train: loss: 0.0002776
[Epoch 61; Iter   900/ 1097] train: loss: 0.0005715
[Epoch 61; Iter   930/ 1097] train: loss: 0.0060830
[Epoch 61; Iter   960/ 1097] train: loss: 0.0304093
[Epoch 61; Iter   990/ 1097] train: loss: 0.0001433
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0000342
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0003730
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0005121
[Epoch 61] ogbg-molhiv: 0.762633 val loss: 0.418303
[Epoch 61] ogbg-molhiv: 0.738591 test loss: 0.325683
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003327
[Epoch 62; Iter    43/ 1097] train: loss: 0.0033279
[Epoch 62; Iter    73/ 1097] train: loss: 0.0264821
[Epoch 62; Iter   103/ 1097] train: loss: 0.0006860
[Epoch 62; Iter   133/ 1097] train: loss: 0.0017516
[Epoch 62; Iter   163/ 1097] train: loss: 0.0017100
[Epoch 62; Iter   193/ 1097] train: loss: 0.0014489
[Epoch 62; Iter   223/ 1097] train: loss: 0.0004739
[Epoch 62; Iter   253/ 1097] train: loss: 0.0001855
[Epoch 62; Iter   283/ 1097] train: loss: 0.0001097
[Epoch 62; Iter   313/ 1097] train: loss: 0.0252561
[Epoch 62; Iter   343/ 1097] train: loss: 0.0013143
[Epoch 62; Iter   373/ 1097] train: loss: 0.0001259
[Epoch 62; Iter   403/ 1097] train: loss: 0.0049148
[Epoch 62; Iter   433/ 1097] train: loss: 0.0005046
[Epoch 62; Iter   463/ 1097] train: loss: 0.0003390
[Epoch 62; Iter   493/ 1097] train: loss: 0.0098081
[Epoch 62; Iter   523/ 1097] train: loss: 0.0012761
[Epoch 62; Iter   553/ 1097] train: loss: 0.1156173
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003636
[Epoch 62; Iter   613/ 1097] train: loss: 0.0005200
[Epoch 62; Iter   643/ 1097] train: loss: 0.0155621
[Epoch 62; Iter   673/ 1097] train: loss: 0.0001005
[Epoch 62; Iter   703/ 1097] train: loss: 0.0004437
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001046
[Epoch 62; Iter   763/ 1097] train: loss: 0.0002653
[Epoch 62; Iter   793/ 1097] train: loss: 0.0347438
[Epoch 62; Iter   823/ 1097] train: loss: 0.0077135
[Epoch 62; Iter   853/ 1097] train: loss: 0.0017710
[Epoch 62; Iter   883/ 1097] train: loss: 0.0027052
[Epoch 62; Iter   913/ 1097] train: loss: 0.0003751
[Epoch 62; Iter   943/ 1097] train: loss: 0.0103923
[Epoch 62; Iter   973/ 1097] train: loss: 0.0020153
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001117
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0004904
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0000906
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0001146
[Epoch 62] ogbg-molhiv: 0.771210 val loss: 0.331175
[Epoch 62] ogbg-molhiv: 0.751648 test loss: 0.302379
[Epoch 63; Iter    26/ 1097] train: loss: 0.0005892
[Epoch 63; Iter    56/ 1097] train: loss: 0.0055889
[Epoch 63; Iter    86/ 1097] train: loss: 0.0000124
[Epoch 63; Iter   116/ 1097] train: loss: 0.0017321
[Epoch 63; Iter   146/ 1097] train: loss: 0.0035063
[Epoch 63; Iter   176/ 1097] train: loss: 0.0007376
[Epoch 63; Iter   206/ 1097] train: loss: 0.0031733
[Epoch 63; Iter   236/ 1097] train: loss: 0.0003340
[Epoch 63; Iter   266/ 1097] train: loss: 0.0004894
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000476
[Epoch 63; Iter   326/ 1097] train: loss: 0.0018239
[Epoch 63; Iter   356/ 1097] train: loss: 0.0023822
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001141
[Epoch 63; Iter   416/ 1097] train: loss: 0.0021884
[Epoch 63; Iter   446/ 1097] train: loss: 0.0051229
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008028
[Epoch 63; Iter   506/ 1097] train: loss: 0.0001062
[Epoch 63; Iter   536/ 1097] train: loss: 0.0013288
[Epoch 63; Iter   566/ 1097] train: loss: 0.0002668
[Epoch 63; Iter   596/ 1097] train: loss: 0.0047355
[Epoch 63; Iter   626/ 1097] train: loss: 0.0000634
[Epoch 63; Iter   656/ 1097] train: loss: 0.0010746
[Epoch 63; Iter   686/ 1097] train: loss: 0.0001030
[Epoch 63; Iter   716/ 1097] train: loss: 0.0062347
[Epoch 63; Iter   746/ 1097] train: loss: 0.0003598
[Epoch 63; Iter   776/ 1097] train: loss: 0.0263336
[Epoch 63; Iter   806/ 1097] train: loss: 0.0026599
[Epoch 63; Iter   836/ 1097] train: loss: 0.0008773
[Epoch 63; Iter   866/ 1097] train: loss: 0.0006462
[Epoch 63; Iter   896/ 1097] train: loss: 0.0005137
[Epoch 63; Iter   926/ 1097] train: loss: 0.0062654
[Epoch 63; Iter   956/ 1097] train: loss: 0.0012152
[Epoch 63; Iter   986/ 1097] train: loss: 0.0015773
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0015908
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0008567
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0014966
[Epoch 63] ogbg-molhiv: 0.769002 val loss: 0.310021
[Epoch 63] ogbg-molhiv: 0.749294 test loss: 0.296586
[Epoch 64; Iter     9/ 1097] train: loss: 0.0006760
[Epoch 64; Iter    39/ 1097] train: loss: 0.0015223
[Epoch 64; Iter    69/ 1097] train: loss: 0.0030518
[Epoch 64; Iter    99/ 1097] train: loss: 0.0058078
[Epoch 64; Iter   129/ 1097] train: loss: 0.0023056
[Epoch 64; Iter   159/ 1097] train: loss: 0.0159403
[Epoch 64; Iter   189/ 1097] train: loss: 0.0012293
[Epoch 64; Iter   219/ 1097] train: loss: 0.0026575
[Epoch 64; Iter   249/ 1097] train: loss: 0.0000940
[Epoch 64; Iter   279/ 1097] train: loss: 0.0001246
[Epoch 64; Iter   309/ 1097] train: loss: 0.0002241
[Epoch 64; Iter   339/ 1097] train: loss: 0.0028462
[Epoch 64; Iter   369/ 1097] train: loss: 0.0036423
[Epoch 64; Iter   399/ 1097] train: loss: 0.0006920
[Epoch 64; Iter   429/ 1097] train: loss: 0.0004071
[Epoch 64; Iter   459/ 1097] train: loss: 0.0007549
[Epoch 64; Iter   489/ 1097] train: loss: 0.0001089
[Epoch 64; Iter   519/ 1097] train: loss: 0.0098427
[Epoch 64; Iter   549/ 1097] train: loss: 0.0002449
[Epoch 64; Iter   579/ 1097] train: loss: 0.0328531
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000693
[Epoch 64; Iter   639/ 1097] train: loss: 0.0019470
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002761
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001203
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002909
[Epoch 64; Iter   759/ 1097] train: loss: 0.0113044
[Epoch 64; Iter   789/ 1097] train: loss: 0.0003956
[Epoch 64; Iter   819/ 1097] train: loss: 0.0016405
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000378
[Epoch 64; Iter   879/ 1097] train: loss: 0.0007769
[Epoch 64; Iter   909/ 1097] train: loss: 0.0001543
[Epoch 64; Iter   939/ 1097] train: loss: 0.0057114
[Epoch 64; Iter   969/ 1097] train: loss: 0.0000604
[Epoch 64; Iter   999/ 1097] train: loss: 0.0000820
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0932660
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0004231
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0002751
[Epoch 64] ogbg-molhiv: 0.755089 val loss: 0.340112
[Epoch 64] ogbg-molhiv: 0.761911 test loss: 0.299921
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0002422
[Epoch 60] ogbg-molhiv: 0.800923 val loss: 0.218461
[Epoch 60] ogbg-molhiv: 0.723224 test loss: 0.364526
[Epoch 61; Iter    30/ 1097] train: loss: 0.0000279
[Epoch 61; Iter    60/ 1097] train: loss: 0.0133094
[Epoch 61; Iter    90/ 1097] train: loss: 0.0006840
[Epoch 61; Iter   120/ 1097] train: loss: 0.0000771
[Epoch 61; Iter   150/ 1097] train: loss: 0.0000541
[Epoch 61; Iter   180/ 1097] train: loss: 0.0019243
[Epoch 61; Iter   210/ 1097] train: loss: 0.0015303
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001258
[Epoch 61; Iter   270/ 1097] train: loss: 0.0022603
[Epoch 61; Iter   300/ 1097] train: loss: 0.0003220
[Epoch 61; Iter   330/ 1097] train: loss: 0.0003114
[Epoch 61; Iter   360/ 1097] train: loss: 0.0006099
[Epoch 61; Iter   390/ 1097] train: loss: 0.0011801
[Epoch 61; Iter   420/ 1097] train: loss: 0.0304503
[Epoch 61; Iter   450/ 1097] train: loss: 0.0004633
[Epoch 61; Iter   480/ 1097] train: loss: 0.0032683
[Epoch 61; Iter   510/ 1097] train: loss: 0.0001186
[Epoch 61; Iter   540/ 1097] train: loss: 0.0006350
[Epoch 61; Iter   570/ 1097] train: loss: 0.0412649
[Epoch 61; Iter   600/ 1097] train: loss: 0.0176836
[Epoch 61; Iter   630/ 1097] train: loss: 0.0034386
[Epoch 61; Iter   660/ 1097] train: loss: 0.0012412
[Epoch 61; Iter   690/ 1097] train: loss: 0.0005780
[Epoch 61; Iter   720/ 1097] train: loss: 0.0109292
[Epoch 61; Iter   750/ 1097] train: loss: 0.0005999
[Epoch 61; Iter   780/ 1097] train: loss: 0.0005156
[Epoch 61; Iter   810/ 1097] train: loss: 0.0001098
[Epoch 61; Iter   840/ 1097] train: loss: 0.0113765
[Epoch 61; Iter   870/ 1097] train: loss: 0.0051104
[Epoch 61; Iter   900/ 1097] train: loss: 0.0008709
[Epoch 61; Iter   930/ 1097] train: loss: 0.0043376
[Epoch 61; Iter   960/ 1097] train: loss: 0.0022846
[Epoch 61; Iter   990/ 1097] train: loss: 0.0000090
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0001315
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0000556
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0012407
[Epoch 61] ogbg-molhiv: 0.801762 val loss: 0.249594
[Epoch 61] ogbg-molhiv: 0.730111 test loss: 0.329257
[Epoch 62; Iter    13/ 1097] train: loss: 0.0032205
[Epoch 62; Iter    43/ 1097] train: loss: 0.0003369
[Epoch 62; Iter    73/ 1097] train: loss: 0.0047343
[Epoch 62; Iter   103/ 1097] train: loss: 0.0000446
[Epoch 62; Iter   133/ 1097] train: loss: 0.0004045
[Epoch 62; Iter   163/ 1097] train: loss: 0.0013500
[Epoch 62; Iter   193/ 1097] train: loss: 0.0023998
[Epoch 62; Iter   223/ 1097] train: loss: 0.0504993
[Epoch 62; Iter   253/ 1097] train: loss: 0.0000342
[Epoch 62; Iter   283/ 1097] train: loss: 0.0003021
[Epoch 62; Iter   313/ 1097] train: loss: 0.0019799
[Epoch 62; Iter   343/ 1097] train: loss: 0.0008593
[Epoch 62; Iter   373/ 1097] train: loss: 0.0003843
[Epoch 62; Iter   403/ 1097] train: loss: 0.0040959
[Epoch 62; Iter   433/ 1097] train: loss: 0.0033559
[Epoch 62; Iter   463/ 1097] train: loss: 0.0004541
[Epoch 62; Iter   493/ 1097] train: loss: 0.0006586
[Epoch 62; Iter   523/ 1097] train: loss: 0.0011123
[Epoch 62; Iter   553/ 1097] train: loss: 0.0100046
[Epoch 62; Iter   583/ 1097] train: loss: 0.0125293
[Epoch 62; Iter   613/ 1097] train: loss: 0.0061423
[Epoch 62; Iter   643/ 1097] train: loss: 0.0006868
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000909
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001763
[Epoch 62; Iter   733/ 1097] train: loss: 0.0009052
[Epoch 62; Iter   763/ 1097] train: loss: 0.0028860
[Epoch 62; Iter   793/ 1097] train: loss: 0.0004966
[Epoch 62; Iter   823/ 1097] train: loss: 0.0008958
[Epoch 62; Iter   853/ 1097] train: loss: 0.0175531
[Epoch 62; Iter   883/ 1097] train: loss: 0.0001305
[Epoch 62; Iter   913/ 1097] train: loss: 0.0012464
[Epoch 62; Iter   943/ 1097] train: loss: 0.0347026
[Epoch 62; Iter   973/ 1097] train: loss: 0.0062923
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0028421
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0054730
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0021654
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0000241
[Epoch 62] ogbg-molhiv: 0.807861 val loss: 0.670590
[Epoch 62] ogbg-molhiv: 0.736833 test loss: 0.358730
[Epoch 63; Iter    26/ 1097] train: loss: 0.0006495
[Epoch 63; Iter    56/ 1097] train: loss: 0.0000395
[Epoch 63; Iter    86/ 1097] train: loss: 0.0004475
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001920
[Epoch 63; Iter   146/ 1097] train: loss: 0.0089358
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001335
[Epoch 63; Iter   206/ 1097] train: loss: 0.0001097
[Epoch 63; Iter   236/ 1097] train: loss: 0.0001649
[Epoch 63; Iter   266/ 1097] train: loss: 0.0000725
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000931
[Epoch 63; Iter   326/ 1097] train: loss: 0.0009501
[Epoch 63; Iter   356/ 1097] train: loss: 0.0005025
[Epoch 63; Iter   386/ 1097] train: loss: 0.0009983
[Epoch 63; Iter   416/ 1097] train: loss: 0.0081296
[Epoch 63; Iter   446/ 1097] train: loss: 0.0018640
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008063
[Epoch 63; Iter   506/ 1097] train: loss: 0.0204077
[Epoch 63; Iter   536/ 1097] train: loss: 0.0068599
[Epoch 63; Iter   566/ 1097] train: loss: 0.0001039
[Epoch 63; Iter   596/ 1097] train: loss: 0.0057989
[Epoch 63; Iter   626/ 1097] train: loss: 0.0000428
[Epoch 63; Iter   656/ 1097] train: loss: 0.0004121
[Epoch 63; Iter   686/ 1097] train: loss: 0.0438742
[Epoch 63; Iter   716/ 1097] train: loss: 0.0001102
[Epoch 63; Iter   746/ 1097] train: loss: 0.0011007
[Epoch 63; Iter   776/ 1097] train: loss: 0.0000191
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006625
[Epoch 63; Iter   836/ 1097] train: loss: 0.0004639
[Epoch 63; Iter   866/ 1097] train: loss: 0.0030533
[Epoch 63; Iter   896/ 1097] train: loss: 0.0038987
[Epoch 63; Iter   926/ 1097] train: loss: 0.0008599
[Epoch 63; Iter   956/ 1097] train: loss: 0.0009472
[Epoch 63; Iter   986/ 1097] train: loss: 0.0242783
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0002867
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0003524
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0011030
[Epoch 63] ogbg-molhiv: 0.807322 val loss: 0.228796
[Epoch 63] ogbg-molhiv: 0.725008 test loss: 0.343276
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000180
[Epoch 64; Iter    39/ 1097] train: loss: 0.0008587
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000417
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000587
[Epoch 64; Iter   129/ 1097] train: loss: 0.0017253
[Epoch 64; Iter   159/ 1097] train: loss: 0.0001946
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002616
[Epoch 64; Iter   219/ 1097] train: loss: 0.0005908
[Epoch 64; Iter   249/ 1097] train: loss: 0.0005131
[Epoch 64; Iter   279/ 1097] train: loss: 0.0002010
[Epoch 64; Iter   309/ 1097] train: loss: 0.0007478
[Epoch 64; Iter   339/ 1097] train: loss: 0.0003219
[Epoch 64; Iter   369/ 1097] train: loss: 0.0003061
[Epoch 64; Iter   399/ 1097] train: loss: 0.0002986
[Epoch 64; Iter   429/ 1097] train: loss: 0.0014634
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001582
[Epoch 64; Iter   489/ 1097] train: loss: 0.0000788
[Epoch 64; Iter   519/ 1097] train: loss: 0.0000934
[Epoch 64; Iter   549/ 1097] train: loss: 0.0006971
[Epoch 64; Iter   579/ 1097] train: loss: 0.0002789
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000132
[Epoch 64; Iter   639/ 1097] train: loss: 0.0213699
[Epoch 64; Iter   669/ 1097] train: loss: 0.0062585
[Epoch 64; Iter   699/ 1097] train: loss: 0.0933060
[Epoch 64; Iter   729/ 1097] train: loss: 0.0004907
[Epoch 64; Iter   759/ 1097] train: loss: 0.0834665
[Epoch 64; Iter   789/ 1097] train: loss: 0.0065409
[Epoch 64; Iter   819/ 1097] train: loss: 0.0018027
[Epoch 64; Iter   849/ 1097] train: loss: 0.0002736
[Epoch 64; Iter   879/ 1097] train: loss: 0.0008970
[Epoch 64; Iter   909/ 1097] train: loss: 0.0020056
[Epoch 64; Iter   939/ 1097] train: loss: 0.0086293
[Epoch 64; Iter   969/ 1097] train: loss: 0.0055503
[Epoch 64; Iter   999/ 1097] train: loss: 0.0054587
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0127733
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0000201
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0001828
[Epoch 64] ogbg-molhiv: 0.783439 val loss: 0.270612
[Epoch 64] ogbg-molhiv: 0.726710 test loss: 0.358558
[Epoch 48; Iter   851/ 1097] train: loss: 0.0690345
[Epoch 48; Iter   881/ 1097] train: loss: 0.0297876
[Epoch 48; Iter   911/ 1097] train: loss: 0.1952441
[Epoch 48; Iter   941/ 1097] train: loss: 0.0215519
[Epoch 48; Iter   971/ 1097] train: loss: 0.0103831
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0125542
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0149491
[Epoch 48; Iter  1061/ 1097] train: loss: 0.1111146
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0102885
[Epoch 48] ogbg-molhiv: 0.813581 val loss: 0.084040
[Epoch 48] ogbg-molhiv: 0.756407 test loss: 0.178621
[Epoch 49; Iter    24/ 1097] train: loss: 0.0540316
[Epoch 49; Iter    54/ 1097] train: loss: 0.0133211
[Epoch 49; Iter    84/ 1097] train: loss: 0.0105005
[Epoch 49; Iter   114/ 1097] train: loss: 0.0053734
[Epoch 49; Iter   144/ 1097] train: loss: 0.0141985
[Epoch 49; Iter   174/ 1097] train: loss: 0.0062307
[Epoch 49; Iter   204/ 1097] train: loss: 0.0085903
[Epoch 49; Iter   234/ 1097] train: loss: 0.0067034
[Epoch 49; Iter   264/ 1097] train: loss: 0.1981740
[Epoch 49; Iter   294/ 1097] train: loss: 0.0055416
[Epoch 49; Iter   324/ 1097] train: loss: 0.0248704
[Epoch 49; Iter   354/ 1097] train: loss: 0.0725690
[Epoch 49; Iter   384/ 1097] train: loss: 0.0194268
[Epoch 49; Iter   414/ 1097] train: loss: 0.2934948
[Epoch 49; Iter   444/ 1097] train: loss: 0.0323227
[Epoch 49; Iter   474/ 1097] train: loss: 0.0292235
[Epoch 49; Iter   504/ 1097] train: loss: 0.0214007
[Epoch 49; Iter   534/ 1097] train: loss: 0.0122350
[Epoch 49; Iter   564/ 1097] train: loss: 0.0239301
[Epoch 49; Iter   594/ 1097] train: loss: 0.1434681
[Epoch 49; Iter   624/ 1097] train: loss: 0.1808376
[Epoch 49; Iter   654/ 1097] train: loss: 0.1916826
[Epoch 49; Iter   684/ 1097] train: loss: 0.0451050
[Epoch 49; Iter   714/ 1097] train: loss: 0.0041657
[Epoch 49; Iter   744/ 1097] train: loss: 0.0550566
[Epoch 49; Iter   774/ 1097] train: loss: 0.0170340
[Epoch 49; Iter   804/ 1097] train: loss: 0.0484481
[Epoch 49; Iter   834/ 1097] train: loss: 0.0323271
[Epoch 49; Iter   864/ 1097] train: loss: 0.0226942
[Epoch 49; Iter   894/ 1097] train: loss: 0.1285512
[Epoch 49; Iter   924/ 1097] train: loss: 0.0404674
[Epoch 49; Iter   954/ 1097] train: loss: 0.0259388
[Epoch 49; Iter   984/ 1097] train: loss: 0.0176965
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0267786
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0200603
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0183187
[Epoch 49] ogbg-molhiv: 0.816912 val loss: 0.092197
[Epoch 49] ogbg-molhiv: 0.761060 test loss: 0.155136
[Epoch 50; Iter     7/ 1097] train: loss: 0.2038089
[Epoch 50; Iter    37/ 1097] train: loss: 0.0162708
[Epoch 50; Iter    67/ 1097] train: loss: 0.1358978
[Epoch 50; Iter    97/ 1097] train: loss: 0.0123838
[Epoch 50; Iter   127/ 1097] train: loss: 0.0296394
[Epoch 50; Iter   157/ 1097] train: loss: 0.0183821
[Epoch 50; Iter   187/ 1097] train: loss: 0.0130969
[Epoch 50; Iter   217/ 1097] train: loss: 0.0571242
[Epoch 50; Iter   247/ 1097] train: loss: 0.0250038
[Epoch 50; Iter   277/ 1097] train: loss: 0.1185289
[Epoch 50; Iter   307/ 1097] train: loss: 0.0235438
[Epoch 50; Iter   337/ 1097] train: loss: 0.0310998
[Epoch 50; Iter   367/ 1097] train: loss: 0.0248320
[Epoch 50; Iter   397/ 1097] train: loss: 0.1083348
[Epoch 50; Iter   427/ 1097] train: loss: 0.1499744
[Epoch 50; Iter   457/ 1097] train: loss: 0.0290747
[Epoch 50; Iter   487/ 1097] train: loss: 0.0188011
[Epoch 50; Iter   517/ 1097] train: loss: 0.0131404
[Epoch 50; Iter   547/ 1097] train: loss: 0.1367545
[Epoch 50; Iter   577/ 1097] train: loss: 0.1967483
[Epoch 50; Iter   607/ 1097] train: loss: 0.0111602
[Epoch 50; Iter   637/ 1097] train: loss: 0.0924807
[Epoch 50; Iter   667/ 1097] train: loss: 0.0166337
[Epoch 50; Iter   697/ 1097] train: loss: 0.1708052
[Epoch 50; Iter   727/ 1097] train: loss: 0.1554839
[Epoch 50; Iter   757/ 1097] train: loss: 0.0061027
[Epoch 50; Iter   787/ 1097] train: loss: 0.0776882
[Epoch 50; Iter   817/ 1097] train: loss: 0.0455708
[Epoch 50; Iter   847/ 1097] train: loss: 0.0473941
[Epoch 50; Iter   877/ 1097] train: loss: 0.0256808
[Epoch 50; Iter   907/ 1097] train: loss: 0.1157253
[Epoch 50; Iter   937/ 1097] train: loss: 0.0257315
[Epoch 50; Iter   967/ 1097] train: loss: 0.0380536
[Epoch 50; Iter   997/ 1097] train: loss: 0.0066301
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0683992
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0092695
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0501810
[Epoch 50] ogbg-molhiv: 0.810436 val loss: 0.095858
[Epoch 50] ogbg-molhiv: 0.761425 test loss: 0.162265
[Epoch 51; Iter    20/ 1097] train: loss: 0.1467137
[Epoch 51; Iter    50/ 1097] train: loss: 0.0319965
[Epoch 51; Iter    80/ 1097] train: loss: 0.0242525
[Epoch 51; Iter   110/ 1097] train: loss: 0.0430033
[Epoch 51; Iter   140/ 1097] train: loss: 0.0251396
[Epoch 51; Iter   170/ 1097] train: loss: 0.0191154
[Epoch 51; Iter   200/ 1097] train: loss: 0.0403167
[Epoch 51; Iter   230/ 1097] train: loss: 0.0113074
[Epoch 51; Iter   260/ 1097] train: loss: 0.0092958
[Epoch 51; Iter   290/ 1097] train: loss: 0.0228628
[Epoch 51; Iter   320/ 1097] train: loss: 0.0122377
[Epoch 51; Iter   350/ 1097] train: loss: 0.0234666
[Epoch 51; Iter   380/ 1097] train: loss: 0.0210627
[Epoch 51; Iter   410/ 1097] train: loss: 0.0237876
[Epoch 51; Iter   440/ 1097] train: loss: 0.1342886
[Epoch 51; Iter   470/ 1097] train: loss: 0.0326115
[Epoch 51; Iter   500/ 1097] train: loss: 0.1218727
[Epoch 51; Iter   530/ 1097] train: loss: 0.0527294
[Epoch 51; Iter   560/ 1097] train: loss: 0.0060993
[Epoch 51; Iter   590/ 1097] train: loss: 0.0192801
[Epoch 51; Iter   620/ 1097] train: loss: 0.0470483
[Epoch 51; Iter   650/ 1097] train: loss: 0.0104178
[Epoch 51; Iter   680/ 1097] train: loss: 0.0549056
[Epoch 51; Iter   710/ 1097] train: loss: 0.0559986
[Epoch 51; Iter   740/ 1097] train: loss: 0.0486065
[Epoch 51; Iter   770/ 1097] train: loss: 0.2219317
[Epoch 51; Iter   800/ 1097] train: loss: 0.0578190
[Epoch 51; Iter   830/ 1097] train: loss: 0.0134142
[Epoch 51; Iter   860/ 1097] train: loss: 0.0695806
[Epoch 51; Iter   890/ 1097] train: loss: 0.0049077
[Epoch 51; Iter   920/ 1097] train: loss: 0.0703492
[Epoch 51; Iter   950/ 1097] train: loss: 0.0218737
[Epoch 51; Iter   980/ 1097] train: loss: 0.0398500
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0304991
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1292909
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0264403
[Epoch 51] ogbg-molhiv: 0.794911 val loss: 0.097958
[Epoch 51] ogbg-molhiv: 0.742193 test loss: 0.206393
[Epoch 52; Iter     3/ 1097] train: loss: 0.0208782
[Epoch 52; Iter    33/ 1097] train: loss: 0.0732696
[Epoch 52; Iter    63/ 1097] train: loss: 0.0100284
[Epoch 52; Iter    93/ 1097] train: loss: 0.0358391
[Epoch 52; Iter   123/ 1097] train: loss: 0.0562884
[Epoch 52; Iter   153/ 1097] train: loss: 0.0778058
[Epoch 52; Iter   183/ 1097] train: loss: 0.1104498
[Epoch 52; Iter   213/ 1097] train: loss: 0.0151802
[Epoch 52; Iter   243/ 1097] train: loss: 0.1600889
[Epoch 52; Iter   273/ 1097] train: loss: 0.0612284
[Epoch 52; Iter   303/ 1097] train: loss: 0.1733461
[Epoch 52; Iter   333/ 1097] train: loss: 0.0192628
[Epoch 52; Iter   363/ 1097] train: loss: 0.0325170
[Epoch 52; Iter   393/ 1097] train: loss: 0.0430702
[Epoch 52; Iter   423/ 1097] train: loss: 0.0090459
[Epoch 52; Iter   453/ 1097] train: loss: 0.0808443
[Epoch 52; Iter   483/ 1097] train: loss: 0.0052005
[Epoch 52; Iter   513/ 1097] train: loss: 0.1092525
[Epoch 52; Iter   543/ 1097] train: loss: 0.1447595
[Epoch 52; Iter   573/ 1097] train: loss: 0.1889725
[Epoch 52; Iter   603/ 1097] train: loss: 0.0101591
[Epoch 52; Iter   633/ 1097] train: loss: 0.1054244
[Epoch 52; Iter   663/ 1097] train: loss: 0.0202051
[Epoch 52; Iter   693/ 1097] train: loss: 0.0290887
[Epoch 52; Iter   723/ 1097] train: loss: 0.0260323
[Epoch 52; Iter   753/ 1097] train: loss: 0.1288410
[Epoch 52; Iter   783/ 1097] train: loss: 0.0099058
[Epoch 52; Iter   813/ 1097] train: loss: 0.0098209
[Epoch 52; Iter   843/ 1097] train: loss: 0.0264934
[Epoch 52; Iter   873/ 1097] train: loss: 0.0451123
[Epoch 52; Iter   903/ 1097] train: loss: 0.0539212
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003952
[Epoch 60] ogbg-molhiv: 0.764909 val loss: 0.276172
[Epoch 60] ogbg-molhiv: 0.800626 test loss: 0.276815
[Epoch 61; Iter    30/ 1097] train: loss: 0.0007118
[Epoch 61; Iter    60/ 1097] train: loss: 0.0002030
[Epoch 61; Iter    90/ 1097] train: loss: 0.0003418
[Epoch 61; Iter   120/ 1097] train: loss: 0.0006924
[Epoch 61; Iter   150/ 1097] train: loss: 0.0000237
[Epoch 61; Iter   180/ 1097] train: loss: 0.0183286
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002345
[Epoch 61; Iter   240/ 1097] train: loss: 0.0039420
[Epoch 61; Iter   270/ 1097] train: loss: 0.0004153
[Epoch 61; Iter   300/ 1097] train: loss: 0.0001488
[Epoch 61; Iter   330/ 1097] train: loss: 0.0002595
[Epoch 61; Iter   360/ 1097] train: loss: 0.0010786
[Epoch 61; Iter   390/ 1097] train: loss: 0.0008129
[Epoch 61; Iter   420/ 1097] train: loss: 0.0001819
[Epoch 61; Iter   450/ 1097] train: loss: 0.0002463
[Epoch 61; Iter   480/ 1097] train: loss: 0.0000436
[Epoch 61; Iter   510/ 1097] train: loss: 0.0064476
[Epoch 61; Iter   540/ 1097] train: loss: 0.0006874
[Epoch 61; Iter   570/ 1097] train: loss: 0.0006522
[Epoch 61; Iter   600/ 1097] train: loss: 0.0005349
[Epoch 61; Iter   630/ 1097] train: loss: 0.0001070
[Epoch 61; Iter   660/ 1097] train: loss: 0.0280998
[Epoch 61; Iter   690/ 1097] train: loss: 0.0006714
[Epoch 61; Iter   720/ 1097] train: loss: 0.0000998
[Epoch 61; Iter   750/ 1097] train: loss: 0.0125667
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002852
[Epoch 61; Iter   810/ 1097] train: loss: 0.0097001
[Epoch 61; Iter   840/ 1097] train: loss: 0.0072922
[Epoch 61; Iter   870/ 1097] train: loss: 0.0001940
[Epoch 61; Iter   900/ 1097] train: loss: 0.0036252
[Epoch 61; Iter   930/ 1097] train: loss: 0.0032954
[Epoch 61; Iter   960/ 1097] train: loss: 0.0006502
[Epoch 61; Iter   990/ 1097] train: loss: 0.0028367
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0008981
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0000916
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0001465
[Epoch 61] ogbg-molhiv: 0.766877 val loss: 0.222988
[Epoch 61] ogbg-molhiv: 0.796412 test loss: 0.276660
[Epoch 62; Iter    13/ 1097] train: loss: 0.0002700
[Epoch 62; Iter    43/ 1097] train: loss: 0.0040847
[Epoch 62; Iter    73/ 1097] train: loss: 0.0032944
[Epoch 62; Iter   103/ 1097] train: loss: 0.0002986
[Epoch 62; Iter   133/ 1097] train: loss: 0.0000567
[Epoch 62; Iter   163/ 1097] train: loss: 0.0015112
[Epoch 62; Iter   193/ 1097] train: loss: 0.0018630
[Epoch 62; Iter   223/ 1097] train: loss: 0.0008842
[Epoch 62; Iter   253/ 1097] train: loss: 0.0001915
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000111
[Epoch 62; Iter   313/ 1097] train: loss: 0.0254393
[Epoch 62; Iter   343/ 1097] train: loss: 0.0000234
[Epoch 62; Iter   373/ 1097] train: loss: 0.0002416
[Epoch 62; Iter   403/ 1097] train: loss: 0.0025744
[Epoch 62; Iter   433/ 1097] train: loss: 0.0002202
[Epoch 62; Iter   463/ 1097] train: loss: 0.0045392
[Epoch 62; Iter   493/ 1097] train: loss: 0.0000815
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003892
[Epoch 62; Iter   553/ 1097] train: loss: 0.0015094
[Epoch 62; Iter   583/ 1097] train: loss: 0.0813485
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000267
[Epoch 62; Iter   643/ 1097] train: loss: 0.0003231
[Epoch 62; Iter   673/ 1097] train: loss: 0.0004067
[Epoch 62; Iter   703/ 1097] train: loss: 0.0007740
[Epoch 62; Iter   733/ 1097] train: loss: 0.0000355
[Epoch 62; Iter   763/ 1097] train: loss: 0.0357923
[Epoch 62; Iter   793/ 1097] train: loss: 0.0010814
[Epoch 62; Iter   823/ 1097] train: loss: 0.0000291
[Epoch 62; Iter   853/ 1097] train: loss: 0.0017074
[Epoch 62; Iter   883/ 1097] train: loss: 0.0046427
[Epoch 62; Iter   913/ 1097] train: loss: 0.0013623
[Epoch 62; Iter   943/ 1097] train: loss: 0.0024453
[Epoch 62; Iter   973/ 1097] train: loss: 0.0002437
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0000990
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001664
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0086436
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0008117
[Epoch 62] ogbg-molhiv: 0.789441 val loss: 0.272468
[Epoch 62] ogbg-molhiv: 0.806066 test loss: 0.285754
[Epoch 63; Iter    26/ 1097] train: loss: 0.0000877
[Epoch 63; Iter    56/ 1097] train: loss: 0.0007742
[Epoch 63; Iter    86/ 1097] train: loss: 0.0006099
[Epoch 63; Iter   116/ 1097] train: loss: 0.0242904
[Epoch 63; Iter   146/ 1097] train: loss: 0.0037820
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001498
[Epoch 63; Iter   206/ 1097] train: loss: 0.0001831
[Epoch 63; Iter   236/ 1097] train: loss: 0.0014076
[Epoch 63; Iter   266/ 1097] train: loss: 0.0007457
[Epoch 63; Iter   296/ 1097] train: loss: 0.0002746
[Epoch 63; Iter   326/ 1097] train: loss: 0.0431182
[Epoch 63; Iter   356/ 1097] train: loss: 0.0019992
[Epoch 63; Iter   386/ 1097] train: loss: 0.0046574
[Epoch 63; Iter   416/ 1097] train: loss: 0.0004021
[Epoch 63; Iter   446/ 1097] train: loss: 0.0001275
[Epoch 63; Iter   476/ 1097] train: loss: 0.0000498
[Epoch 63; Iter   506/ 1097] train: loss: 0.0000166
[Epoch 63; Iter   536/ 1097] train: loss: 0.0002665
[Epoch 63; Iter   566/ 1097] train: loss: 0.0013949
[Epoch 63; Iter   596/ 1097] train: loss: 0.0005656
[Epoch 63; Iter   626/ 1097] train: loss: 0.0125141
[Epoch 63; Iter   656/ 1097] train: loss: 0.0001480
[Epoch 63; Iter   686/ 1097] train: loss: 0.0014546
[Epoch 63; Iter   716/ 1097] train: loss: 0.0000146
[Epoch 63; Iter   746/ 1097] train: loss: 0.0012400
[Epoch 63; Iter   776/ 1097] train: loss: 0.0002915
[Epoch 63; Iter   806/ 1097] train: loss: 0.0003120
[Epoch 63; Iter   836/ 1097] train: loss: 0.0000167
[Epoch 63; Iter   866/ 1097] train: loss: 0.0047146
[Epoch 63; Iter   896/ 1097] train: loss: 0.0000853
[Epoch 63; Iter   926/ 1097] train: loss: 0.0004509
[Epoch 63; Iter   956/ 1097] train: loss: 0.0036352
[Epoch 63; Iter   986/ 1097] train: loss: 0.0021236
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0000983
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0025181
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0002901
[Epoch 63] ogbg-molhiv: 0.781786 val loss: 0.313688
[Epoch 63] ogbg-molhiv: 0.779694 test loss: 0.299272
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000370
[Epoch 64; Iter    39/ 1097] train: loss: 0.0000862
[Epoch 64; Iter    69/ 1097] train: loss: 0.0004379
[Epoch 64; Iter    99/ 1097] train: loss: 0.0011847
[Epoch 64; Iter   129/ 1097] train: loss: 0.0002011
[Epoch 64; Iter   159/ 1097] train: loss: 0.0109823
[Epoch 64; Iter   189/ 1097] train: loss: 0.0002835
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000653
[Epoch 64; Iter   249/ 1097] train: loss: 0.0004126
[Epoch 64; Iter   279/ 1097] train: loss: 0.0158182
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000299
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000133
[Epoch 64; Iter   369/ 1097] train: loss: 0.0000319
[Epoch 64; Iter   399/ 1097] train: loss: 0.0002262
[Epoch 64; Iter   429/ 1097] train: loss: 0.0006027
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001653
[Epoch 64; Iter   489/ 1097] train: loss: 0.0005271
[Epoch 64; Iter   519/ 1097] train: loss: 0.0003652
[Epoch 64; Iter   549/ 1097] train: loss: 0.0004720
[Epoch 64; Iter   579/ 1097] train: loss: 0.0012331
[Epoch 64; Iter   609/ 1097] train: loss: 0.0000944
[Epoch 64; Iter   639/ 1097] train: loss: 0.0000083
[Epoch 64; Iter   669/ 1097] train: loss: 0.0002011
[Epoch 64; Iter   699/ 1097] train: loss: 0.0001596
[Epoch 64; Iter   729/ 1097] train: loss: 0.0000672
[Epoch 64; Iter   759/ 1097] train: loss: 0.0001280
[Epoch 64; Iter   789/ 1097] train: loss: 0.0001598
[Epoch 64; Iter   819/ 1097] train: loss: 0.0186871
[Epoch 64; Iter   849/ 1097] train: loss: 0.0005672
[Epoch 64; Iter   879/ 1097] train: loss: 0.0001011
[Epoch 64; Iter   909/ 1097] train: loss: 0.0003698
[Epoch 64; Iter   939/ 1097] train: loss: 0.0057486
[Epoch 64; Iter   969/ 1097] train: loss: 0.0003708
[Epoch 64; Iter   999/ 1097] train: loss: 0.0046257
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0048857
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0010226
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0391158
[Epoch 64] ogbg-molhiv: 0.794582 val loss: 0.289066
[Epoch 64] ogbg-molhiv: 0.804598 test loss: 0.304605
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0007748
[Epoch 60] ogbg-molhiv: 0.686183 val loss: 2.609524
[Epoch 60] ogbg-molhiv: 0.582257 test loss: 2.733538
[Epoch 61; Iter    30/ 1097] train: loss: 0.0010579
[Epoch 61; Iter    60/ 1097] train: loss: 0.0000128
[Epoch 61; Iter    90/ 1097] train: loss: 0.0000298
[Epoch 61; Iter   120/ 1097] train: loss: 0.0004974
[Epoch 61; Iter   150/ 1097] train: loss: 0.0005836
[Epoch 61; Iter   180/ 1097] train: loss: 0.0013831
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002251
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001683
[Epoch 61; Iter   270/ 1097] train: loss: 0.0000572
[Epoch 61; Iter   300/ 1097] train: loss: 0.0000142
[Epoch 61; Iter   330/ 1097] train: loss: 0.0004503
[Epoch 61; Iter   360/ 1097] train: loss: 0.0000965
[Epoch 61; Iter   390/ 1097] train: loss: 0.0001227
[Epoch 61; Iter   420/ 1097] train: loss: 0.0007527
[Epoch 61; Iter   450/ 1097] train: loss: 0.0036096
[Epoch 61; Iter   480/ 1097] train: loss: 0.0000768
[Epoch 61; Iter   510/ 1097] train: loss: 0.0000095
[Epoch 61; Iter   540/ 1097] train: loss: 0.0000142
[Epoch 61; Iter   570/ 1097] train: loss: 0.0000650
[Epoch 61; Iter   600/ 1097] train: loss: 0.0039914
[Epoch 61; Iter   630/ 1097] train: loss: 0.0000656
[Epoch 61; Iter   660/ 1097] train: loss: 0.0000647
[Epoch 61; Iter   690/ 1097] train: loss: 0.0003005
[Epoch 61; Iter   720/ 1097] train: loss: 0.0001355
[Epoch 61; Iter   750/ 1097] train: loss: 0.0000662
[Epoch 61; Iter   780/ 1097] train: loss: 0.0001385
[Epoch 61; Iter   810/ 1097] train: loss: 0.0417296
[Epoch 61; Iter   840/ 1097] train: loss: 0.0188916
[Epoch 61; Iter   870/ 1097] train: loss: 0.0021776
[Epoch 61; Iter   900/ 1097] train: loss: 0.0003852
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000096
[Epoch 61; Iter   960/ 1097] train: loss: 0.0000986
[Epoch 61; Iter   990/ 1097] train: loss: 0.0003236
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0008956
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0001732
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0004201
[Epoch 61] ogbg-molhiv: 0.716656 val loss: 1.103538
[Epoch 61] ogbg-molhiv: 0.627859 test loss: 2.024368
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003246
[Epoch 62; Iter    43/ 1097] train: loss: 0.0001894
[Epoch 62; Iter    73/ 1097] train: loss: 0.0000445
[Epoch 62; Iter   103/ 1097] train: loss: 0.0016657
[Epoch 62; Iter   133/ 1097] train: loss: 0.0000050
[Epoch 62; Iter   163/ 1097] train: loss: 0.0019923
[Epoch 62; Iter   193/ 1097] train: loss: 0.0054881
[Epoch 62; Iter   223/ 1097] train: loss: 0.0026084
[Epoch 62; Iter   253/ 1097] train: loss: 0.0043682
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000078
[Epoch 62; Iter   313/ 1097] train: loss: 0.0004170
[Epoch 62; Iter   343/ 1097] train: loss: 0.0000555
[Epoch 62; Iter   373/ 1097] train: loss: 0.0000261
[Epoch 62; Iter   403/ 1097] train: loss: 0.0001095
[Epoch 62; Iter   433/ 1097] train: loss: 0.0002575
[Epoch 62; Iter   463/ 1097] train: loss: 0.0000437
[Epoch 62; Iter   493/ 1097] train: loss: 0.0024944
[Epoch 62; Iter   523/ 1097] train: loss: 0.0000536
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000783
[Epoch 62; Iter   583/ 1097] train: loss: 0.0000977
[Epoch 62; Iter   613/ 1097] train: loss: 0.0000171
[Epoch 62; Iter   643/ 1097] train: loss: 0.0000452
[Epoch 62; Iter   673/ 1097] train: loss: 0.0122459
[Epoch 62; Iter   703/ 1097] train: loss: 0.0000203
[Epoch 62; Iter   733/ 1097] train: loss: 0.0006815
[Epoch 62; Iter   763/ 1097] train: loss: 0.0000519
[Epoch 62; Iter   793/ 1097] train: loss: 0.0003355
[Epoch 62; Iter   823/ 1097] train: loss: 0.0017640
[Epoch 62; Iter   853/ 1097] train: loss: 0.0001041
[Epoch 62; Iter   883/ 1097] train: loss: 0.0000126
[Epoch 62; Iter   913/ 1097] train: loss: 0.0000167
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001066
[Epoch 62; Iter   973/ 1097] train: loss: 0.0000648
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0000067
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0001126
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0030043
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0077386
[Epoch 62] ogbg-molhiv: 0.701793 val loss: 3.080653
[Epoch 62] ogbg-molhiv: 0.588376 test loss: 4.487486
[Epoch 63; Iter    26/ 1097] train: loss: 0.0000848
[Epoch 63; Iter    56/ 1097] train: loss: 0.0000721
[Epoch 63; Iter    86/ 1097] train: loss: 0.0003567
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001557
[Epoch 63; Iter   146/ 1097] train: loss: 0.0001883
[Epoch 63; Iter   176/ 1097] train: loss: 0.0001290
[Epoch 63; Iter   206/ 1097] train: loss: 0.0000210
[Epoch 63; Iter   236/ 1097] train: loss: 0.0000311
[Epoch 63; Iter   266/ 1097] train: loss: 0.0002549
[Epoch 63; Iter   296/ 1097] train: loss: 0.0000504
[Epoch 63; Iter   326/ 1097] train: loss: 0.0000063
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000637
[Epoch 63; Iter   386/ 1097] train: loss: 0.0005949
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000277
[Epoch 63; Iter   446/ 1097] train: loss: 0.0000110
[Epoch 63; Iter   476/ 1097] train: loss: 0.0000097
[Epoch 63; Iter   506/ 1097] train: loss: 0.0008662
[Epoch 63; Iter   536/ 1097] train: loss: 0.0000102
[Epoch 63; Iter   566/ 1097] train: loss: 0.0026474
[Epoch 63; Iter   596/ 1097] train: loss: 0.0000078
[Epoch 63; Iter   626/ 1097] train: loss: 0.0009789
[Epoch 63; Iter   656/ 1097] train: loss: 0.0000923
[Epoch 63; Iter   686/ 1097] train: loss: 0.0006403
[Epoch 63; Iter   716/ 1097] train: loss: 0.0000187
[Epoch 63; Iter   746/ 1097] train: loss: 0.0018294
[Epoch 63; Iter   776/ 1097] train: loss: 0.0000153
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006051
[Epoch 63; Iter   836/ 1097] train: loss: 0.0002334
[Epoch 63; Iter   866/ 1097] train: loss: 0.0005242
[Epoch 63; Iter   896/ 1097] train: loss: 0.0000951
[Epoch 63; Iter   926/ 1097] train: loss: 0.0000391
[Epoch 63; Iter   956/ 1097] train: loss: 0.0000399
[Epoch 63; Iter   986/ 1097] train: loss: 0.0012724
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004419
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0019764
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0001467
[Epoch 63] ogbg-molhiv: 0.709390 val loss: 4.034613
[Epoch 63] ogbg-molhiv: 0.592369 test loss: 5.400616
[Epoch 64; Iter     9/ 1097] train: loss: 0.0000811
[Epoch 64; Iter    39/ 1097] train: loss: 0.0032032
[Epoch 64; Iter    69/ 1097] train: loss: 0.0000134
[Epoch 64; Iter    99/ 1097] train: loss: 0.0001032
[Epoch 64; Iter   129/ 1097] train: loss: 0.0022163
[Epoch 64; Iter   159/ 1097] train: loss: 0.0003327
[Epoch 64; Iter   189/ 1097] train: loss: 0.0015390
[Epoch 64; Iter   219/ 1097] train: loss: 0.0000280
[Epoch 64; Iter   249/ 1097] train: loss: 0.0001287
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000085
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000147
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000122
[Epoch 64; Iter   369/ 1097] train: loss: 0.0019212
[Epoch 64; Iter   399/ 1097] train: loss: 0.0003380
[Epoch 64; Iter   429/ 1097] train: loss: 0.0003048
[Epoch 64; Iter   459/ 1097] train: loss: 0.0001946
[Epoch 64; Iter   489/ 1097] train: loss: 0.0000898
[Epoch 64; Iter   519/ 1097] train: loss: 0.0002934
[Epoch 64; Iter   549/ 1097] train: loss: 0.0014125
[Epoch 64; Iter   579/ 1097] train: loss: 0.0000093
[Epoch 64; Iter   609/ 1097] train: loss: 0.0001092
[Epoch 64; Iter   639/ 1097] train: loss: 0.0000209
[Epoch 64; Iter   669/ 1097] train: loss: 0.0007291
[Epoch 64; Iter   699/ 1097] train: loss: 0.0000037
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002367
[Epoch 64; Iter   759/ 1097] train: loss: 0.0000211
[Epoch 64; Iter   789/ 1097] train: loss: 0.0242523
[Epoch 64; Iter   819/ 1097] train: loss: 0.0000526
[Epoch 64; Iter   849/ 1097] train: loss: 0.0000910
[Epoch 64; Iter   879/ 1097] train: loss: 0.0000658
[Epoch 64; Iter   909/ 1097] train: loss: 0.0008503
[Epoch 64; Iter   939/ 1097] train: loss: 0.0000102
[Epoch 64; Iter   969/ 1097] train: loss: 0.0004973
[Epoch 64; Iter   999/ 1097] train: loss: 0.0001471
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0001251
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0021332
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0002146
[Epoch 64] ogbg-molhiv: 0.696517 val loss: 3.432242
[Epoch 64] ogbg-molhiv: 0.646600 test loss: 3.657058
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0003564
[Epoch 60] ogbg-molhiv: 0.779832 val loss: 12.775035
[Epoch 60] ogbg-molhiv: 0.714261 test loss: 12.345723
[Epoch 61; Iter    30/ 1097] train: loss: 0.0004838
[Epoch 61; Iter    60/ 1097] train: loss: 0.0008419
[Epoch 61; Iter    90/ 1097] train: loss: 0.0004366
[Epoch 61; Iter   120/ 1097] train: loss: 0.0307589
[Epoch 61; Iter   150/ 1097] train: loss: 0.0229467
[Epoch 61; Iter   180/ 1097] train: loss: 0.0005872
[Epoch 61; Iter   210/ 1097] train: loss: 0.0002891
[Epoch 61; Iter   240/ 1097] train: loss: 0.0208309
[Epoch 61; Iter   270/ 1097] train: loss: 0.0004479
[Epoch 61; Iter   300/ 1097] train: loss: 0.0000323
[Epoch 61; Iter   330/ 1097] train: loss: 0.0010398
[Epoch 61; Iter   360/ 1097] train: loss: 0.0021703
[Epoch 61; Iter   390/ 1097] train: loss: 0.0000435
[Epoch 61; Iter   420/ 1097] train: loss: 0.0028738
[Epoch 61; Iter   450/ 1097] train: loss: 0.0016836
[Epoch 61; Iter   480/ 1097] train: loss: 0.0001441
[Epoch 61; Iter   510/ 1097] train: loss: 0.0004742
[Epoch 61; Iter   540/ 1097] train: loss: 0.0013921
[Epoch 61; Iter   570/ 1097] train: loss: 0.0557930
[Epoch 61; Iter   600/ 1097] train: loss: 0.0311580
[Epoch 61; Iter   630/ 1097] train: loss: 0.0087516
[Epoch 61; Iter   660/ 1097] train: loss: 0.0014100
[Epoch 61; Iter   690/ 1097] train: loss: 0.0000611
[Epoch 61; Iter   720/ 1097] train: loss: 0.0010368
[Epoch 61; Iter   750/ 1097] train: loss: 0.0025330
[Epoch 61; Iter   780/ 1097] train: loss: 0.0002754
[Epoch 61; Iter   810/ 1097] train: loss: 0.0914670
[Epoch 61; Iter   840/ 1097] train: loss: 0.0084208
[Epoch 61; Iter   870/ 1097] train: loss: 0.0003725
[Epoch 61; Iter   900/ 1097] train: loss: 0.0060805
[Epoch 61; Iter   930/ 1097] train: loss: 0.0004718
[Epoch 61; Iter   960/ 1097] train: loss: 0.0003148
[Epoch 61; Iter   990/ 1097] train: loss: 0.0089250
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0001702
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0236182
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0000254
[Epoch 61] ogbg-molhiv: 0.760512 val loss: 2.160940
[Epoch 61] ogbg-molhiv: 0.721760 test loss: 5.441449
[Epoch 62; Iter    13/ 1097] train: loss: 0.0003270
[Epoch 62; Iter    43/ 1097] train: loss: 0.0017690
[Epoch 62; Iter    73/ 1097] train: loss: 0.0001117
[Epoch 62; Iter   103/ 1097] train: loss: 0.0001383
[Epoch 62; Iter   133/ 1097] train: loss: 0.0003480
[Epoch 62; Iter   163/ 1097] train: loss: 0.0001599
[Epoch 62; Iter   193/ 1097] train: loss: 0.0022749
[Epoch 62; Iter   223/ 1097] train: loss: 0.0038358
[Epoch 62; Iter   253/ 1097] train: loss: 0.0002181
[Epoch 62; Iter   283/ 1097] train: loss: 0.0003609
[Epoch 62; Iter   313/ 1097] train: loss: 0.0005591
[Epoch 62; Iter   343/ 1097] train: loss: 0.0006407
[Epoch 62; Iter   373/ 1097] train: loss: 0.0000268
[Epoch 62; Iter   403/ 1097] train: loss: 0.0000651
[Epoch 62; Iter   433/ 1097] train: loss: 0.1051709
[Epoch 62; Iter   463/ 1097] train: loss: 0.0439262
[Epoch 62; Iter   493/ 1097] train: loss: 0.0000634
[Epoch 62; Iter   523/ 1097] train: loss: 0.0003292
[Epoch 62; Iter   553/ 1097] train: loss: 0.0000419
[Epoch 62; Iter   583/ 1097] train: loss: 0.0003951
[Epoch 62; Iter   613/ 1097] train: loss: 0.0008999
[Epoch 62; Iter   643/ 1097] train: loss: 0.0004892
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000141
[Epoch 62; Iter   703/ 1097] train: loss: 0.0001056
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001997
[Epoch 62; Iter   763/ 1097] train: loss: 0.0024618
[Epoch 62; Iter   793/ 1097] train: loss: 0.0001938
[Epoch 62; Iter   823/ 1097] train: loss: 0.0004238
[Epoch 62; Iter   853/ 1097] train: loss: 0.0001979
[Epoch 62; Iter   883/ 1097] train: loss: 0.0000124
[Epoch 62; Iter   913/ 1097] train: loss: 0.0041715
[Epoch 62; Iter   943/ 1097] train: loss: 0.0005689
[Epoch 62; Iter   973/ 1097] train: loss: 0.0038789
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0001627
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0040513
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0002601
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0001006
[Epoch 62] ogbg-molhiv: 0.764970 val loss: 9.921717
[Epoch 62] ogbg-molhiv: 0.726936 test loss: 9.285245
[Epoch 63; Iter    26/ 1097] train: loss: 0.0001697
[Epoch 63; Iter    56/ 1097] train: loss: 0.0001086
[Epoch 63; Iter    86/ 1097] train: loss: 0.0003100
[Epoch 63; Iter   116/ 1097] train: loss: 0.0004068
[Epoch 63; Iter   146/ 1097] train: loss: 0.0102345
[Epoch 63; Iter   176/ 1097] train: loss: 0.0042396
[Epoch 63; Iter   206/ 1097] train: loss: 0.0002416
[Epoch 63; Iter   236/ 1097] train: loss: 0.0000597
[Epoch 63; Iter   266/ 1097] train: loss: 0.0001115
[Epoch 63; Iter   296/ 1097] train: loss: 0.0003167
[Epoch 63; Iter   326/ 1097] train: loss: 0.0626594
[Epoch 63; Iter   356/ 1097] train: loss: 0.0000223
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001576
[Epoch 63; Iter   416/ 1097] train: loss: 0.0009353
[Epoch 63; Iter   446/ 1097] train: loss: 0.0003275
[Epoch 63; Iter   476/ 1097] train: loss: 0.0008379
[Epoch 63; Iter   506/ 1097] train: loss: 0.0015240
[Epoch 63; Iter   536/ 1097] train: loss: 0.0433930
[Epoch 63; Iter   566/ 1097] train: loss: 0.0019681
[Epoch 63; Iter   596/ 1097] train: loss: 0.0037475
[Epoch 63; Iter   626/ 1097] train: loss: 0.0003801
[Epoch 63; Iter   656/ 1097] train: loss: 0.0001412
[Epoch 63; Iter   686/ 1097] train: loss: 0.0169190
[Epoch 63; Iter   716/ 1097] train: loss: 0.0007622
[Epoch 63; Iter   746/ 1097] train: loss: 0.0016403
[Epoch 63; Iter   776/ 1097] train: loss: 0.0003385
[Epoch 63; Iter   806/ 1097] train: loss: 0.0006005
[Epoch 63; Iter   836/ 1097] train: loss: 0.0009033
[Epoch 63; Iter   866/ 1097] train: loss: 0.0004839
[Epoch 63; Iter   896/ 1097] train: loss: 0.0006998
[Epoch 63; Iter   926/ 1097] train: loss: 0.0158618
[Epoch 63; Iter   956/ 1097] train: loss: 0.0072602
[Epoch 63; Iter   986/ 1097] train: loss: 0.0002437
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004843
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0036602
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0000602
[Epoch 63] ogbg-molhiv: 0.775840 val loss: 6.377900
[Epoch 63] ogbg-molhiv: 0.708502 test loss: 9.033629
[Epoch 64; Iter     9/ 1097] train: loss: 0.0003566
[Epoch 64; Iter    39/ 1097] train: loss: 0.0012031
[Epoch 64; Iter    69/ 1097] train: loss: 0.0010804
[Epoch 64; Iter    99/ 1097] train: loss: 0.0001251
[Epoch 64; Iter   129/ 1097] train: loss: 0.0000841
[Epoch 64; Iter   159/ 1097] train: loss: 0.0005776
[Epoch 64; Iter   189/ 1097] train: loss: 0.0000389
[Epoch 64; Iter   219/ 1097] train: loss: 0.0010077
[Epoch 64; Iter   249/ 1097] train: loss: 0.0002724
[Epoch 64; Iter   279/ 1097] train: loss: 0.0006985
[Epoch 64; Iter   309/ 1097] train: loss: 0.0000432
[Epoch 64; Iter   339/ 1097] train: loss: 0.0019143
[Epoch 64; Iter   369/ 1097] train: loss: 0.0002257
[Epoch 64; Iter   399/ 1097] train: loss: 0.0001185
[Epoch 64; Iter   429/ 1097] train: loss: 0.0000271
[Epoch 64; Iter   459/ 1097] train: loss: 0.0000842
[Epoch 64; Iter   489/ 1097] train: loss: 0.0309157
[Epoch 64; Iter   519/ 1097] train: loss: 0.0042081
[Epoch 64; Iter   549/ 1097] train: loss: 0.0139428
[Epoch 64; Iter   579/ 1097] train: loss: 0.0003443
[Epoch 64; Iter   609/ 1097] train: loss: 0.0009269
[Epoch 64; Iter   639/ 1097] train: loss: 0.0222355
[Epoch 64; Iter   669/ 1097] train: loss: 0.0000973
[Epoch 64; Iter   699/ 1097] train: loss: 0.0003386
[Epoch 64; Iter   729/ 1097] train: loss: 0.0011025
[Epoch 64; Iter   759/ 1097] train: loss: 0.0001770
[Epoch 64; Iter   789/ 1097] train: loss: 0.0012588
[Epoch 64; Iter   819/ 1097] train: loss: 0.0025285
[Epoch 64; Iter   849/ 1097] train: loss: 0.0487288
[Epoch 64; Iter   879/ 1097] train: loss: 0.0002744
[Epoch 64; Iter   909/ 1097] train: loss: 0.0000388
[Epoch 64; Iter   939/ 1097] train: loss: 0.0001182
[Epoch 64; Iter   969/ 1097] train: loss: 0.0001367
[Epoch 64; Iter   999/ 1097] train: loss: 0.0034672
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0011596
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0001310
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0117984
[Epoch 64] ogbg-molhiv: 0.729507 val loss: 3.377933
[Epoch 64] ogbg-molhiv: 0.724321 test loss: 4.067614
[Epoch 60; Iter  1097/ 1097] train: loss: 0.2053896
[Epoch 60] ogbg-molhiv: 0.681979 val loss: 83.914417
[Epoch 60] ogbg-molhiv: 0.571865 test loss: 73.667704
[Epoch 61; Iter    30/ 1097] train: loss: 0.0780411
[Epoch 61; Iter    60/ 1097] train: loss: 0.0002596
[Epoch 61; Iter    90/ 1097] train: loss: 0.0017158
[Epoch 61; Iter   120/ 1097] train: loss: 0.0001561
[Epoch 61; Iter   150/ 1097] train: loss: 0.0001807
[Epoch 61; Iter   180/ 1097] train: loss: 0.0018364
[Epoch 61; Iter   210/ 1097] train: loss: 0.0019858
[Epoch 61; Iter   240/ 1097] train: loss: 0.0001035
[Epoch 61; Iter   270/ 1097] train: loss: 0.0151094
[Epoch 61; Iter   300/ 1097] train: loss: 0.0005735
[Epoch 61; Iter   330/ 1097] train: loss: 0.0009635
[Epoch 61; Iter   360/ 1097] train: loss: 0.0002387
[Epoch 61; Iter   390/ 1097] train: loss: 0.0002311
[Epoch 61; Iter   420/ 1097] train: loss: 0.0027466
[Epoch 61; Iter   450/ 1097] train: loss: 0.0001448
[Epoch 61; Iter   480/ 1097] train: loss: 0.0090078
[Epoch 61; Iter   510/ 1097] train: loss: 0.0012644
[Epoch 61; Iter   540/ 1097] train: loss: 0.0075010
[Epoch 61; Iter   570/ 1097] train: loss: 0.0814558
[Epoch 61; Iter   600/ 1097] train: loss: 0.0076508
[Epoch 61; Iter   630/ 1097] train: loss: 0.0003329
[Epoch 61; Iter   660/ 1097] train: loss: 0.0010211
[Epoch 61; Iter   690/ 1097] train: loss: 0.0009504
[Epoch 61; Iter   720/ 1097] train: loss: 0.0000711
[Epoch 61; Iter   750/ 1097] train: loss: 0.0000473
[Epoch 61; Iter   780/ 1097] train: loss: 0.0025825
[Epoch 61; Iter   810/ 1097] train: loss: 0.0222849
[Epoch 61; Iter   840/ 1097] train: loss: 0.0002947
[Epoch 61; Iter   870/ 1097] train: loss: 0.0126887
[Epoch 61; Iter   900/ 1097] train: loss: 0.0049062
[Epoch 61; Iter   930/ 1097] train: loss: 0.0000980
[Epoch 61; Iter   960/ 1097] train: loss: 0.0041152
[Epoch 61; Iter   990/ 1097] train: loss: 0.0007603
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0009122
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0003400
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0259348
[Epoch 61] ogbg-molhiv: 0.647955 val loss: 293.024454
[Epoch 61] ogbg-molhiv: 0.539667 test loss: 256.413319
[Epoch 62; Iter    13/ 1097] train: loss: 0.0088939
[Epoch 62; Iter    43/ 1097] train: loss: 0.0125436
[Epoch 62; Iter    73/ 1097] train: loss: 0.0013714
[Epoch 62; Iter   103/ 1097] train: loss: 0.1301192
[Epoch 62; Iter   133/ 1097] train: loss: 0.0006323
[Epoch 62; Iter   163/ 1097] train: loss: 0.0021697
[Epoch 62; Iter   193/ 1097] train: loss: 0.0000403
[Epoch 62; Iter   223/ 1097] train: loss: 0.0003744
[Epoch 62; Iter   253/ 1097] train: loss: 0.0000180
[Epoch 62; Iter   283/ 1097] train: loss: 0.0000919
[Epoch 62; Iter   313/ 1097] train: loss: 0.0106719
[Epoch 62; Iter   343/ 1097] train: loss: 0.0255580
[Epoch 62; Iter   373/ 1097] train: loss: 0.0036721
[Epoch 62; Iter   403/ 1097] train: loss: 0.0002586
[Epoch 62; Iter   433/ 1097] train: loss: 0.0015796
[Epoch 62; Iter   463/ 1097] train: loss: 0.0053651
[Epoch 62; Iter   493/ 1097] train: loss: 0.0077436
[Epoch 62; Iter   523/ 1097] train: loss: 0.0002231
[Epoch 62; Iter   553/ 1097] train: loss: 0.0024303
[Epoch 62; Iter   583/ 1097] train: loss: 0.0013422
[Epoch 62; Iter   613/ 1097] train: loss: 0.0016687
[Epoch 62; Iter   643/ 1097] train: loss: 0.0019320
[Epoch 62; Iter   673/ 1097] train: loss: 0.0000739
[Epoch 62; Iter   703/ 1097] train: loss: 0.0017848
[Epoch 62; Iter   733/ 1097] train: loss: 0.0001445
[Epoch 62; Iter   763/ 1097] train: loss: 0.0007832
[Epoch 62; Iter   793/ 1097] train: loss: 0.0002208
[Epoch 62; Iter   823/ 1097] train: loss: 0.0005467
[Epoch 62; Iter   853/ 1097] train: loss: 0.0028200
[Epoch 62; Iter   883/ 1097] train: loss: 0.0038727
[Epoch 62; Iter   913/ 1097] train: loss: 0.0319293
[Epoch 62; Iter   943/ 1097] train: loss: 0.0001109
[Epoch 62; Iter   973/ 1097] train: loss: 0.0000656
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0269900
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0021423
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0001709
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0036377
[Epoch 62] ogbg-molhiv: 0.635851 val loss: 245.948858
[Epoch 62] ogbg-molhiv: 0.559787 test loss: 207.139549
[Epoch 63; Iter    26/ 1097] train: loss: 0.0004868
[Epoch 63; Iter    56/ 1097] train: loss: 0.0766049
[Epoch 63; Iter    86/ 1097] train: loss: 0.0000304
[Epoch 63; Iter   116/ 1097] train: loss: 0.0001551
[Epoch 63; Iter   146/ 1097] train: loss: 0.0003487
[Epoch 63; Iter   176/ 1097] train: loss: 0.0012800
[Epoch 63; Iter   206/ 1097] train: loss: 0.0016838
[Epoch 63; Iter   236/ 1097] train: loss: 0.0001754
[Epoch 63; Iter   266/ 1097] train: loss: 0.0001606
[Epoch 63; Iter   296/ 1097] train: loss: 0.0048603
[Epoch 63; Iter   326/ 1097] train: loss: 0.0118174
[Epoch 63; Iter   356/ 1097] train: loss: 0.0253176
[Epoch 63; Iter   386/ 1097] train: loss: 0.0001244
[Epoch 63; Iter   416/ 1097] train: loss: 0.0000327
[Epoch 63; Iter   446/ 1097] train: loss: 0.0057439
[Epoch 63; Iter   476/ 1097] train: loss: 0.0003459
[Epoch 63; Iter   506/ 1097] train: loss: 0.0000556
[Epoch 63; Iter   536/ 1097] train: loss: 0.0256801
[Epoch 63; Iter   566/ 1097] train: loss: 0.0244499
[Epoch 63; Iter   596/ 1097] train: loss: 0.0279326
[Epoch 63; Iter   626/ 1097] train: loss: 0.0003207
[Epoch 63; Iter   656/ 1097] train: loss: 0.0221120
[Epoch 63; Iter   686/ 1097] train: loss: 0.0005673
[Epoch 63; Iter   716/ 1097] train: loss: 0.0003552
[Epoch 63; Iter   746/ 1097] train: loss: 0.0003059
[Epoch 63; Iter   776/ 1097] train: loss: 0.0010636
[Epoch 63; Iter   806/ 1097] train: loss: 0.0010160
[Epoch 63; Iter   836/ 1097] train: loss: 0.0014984
[Epoch 63; Iter   866/ 1097] train: loss: 0.0147568
[Epoch 63; Iter   896/ 1097] train: loss: 0.0003477
[Epoch 63; Iter   926/ 1097] train: loss: 0.0056617
[Epoch 63; Iter   956/ 1097] train: loss: 0.0158326
[Epoch 63; Iter   986/ 1097] train: loss: 0.0002512
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0004149
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0726336
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0002773
[Epoch 63] ogbg-molhiv: 0.640438 val loss: 110.360777
[Epoch 63] ogbg-molhiv: 0.562207 test loss: 104.842225
[Epoch 64; Iter     9/ 1097] train: loss: 0.0058025
[Epoch 64; Iter    39/ 1097] train: loss: 0.0000361
[Epoch 64; Iter    69/ 1097] train: loss: 0.0039808
[Epoch 64; Iter    99/ 1097] train: loss: 0.0000240
[Epoch 64; Iter   129/ 1097] train: loss: 0.0001609
[Epoch 64; Iter   159/ 1097] train: loss: 0.0001018
[Epoch 64; Iter   189/ 1097] train: loss: 0.0001107
[Epoch 64; Iter   219/ 1097] train: loss: 0.0072185
[Epoch 64; Iter   249/ 1097] train: loss: 0.0004304
[Epoch 64; Iter   279/ 1097] train: loss: 0.0000448
[Epoch 64; Iter   309/ 1097] train: loss: 0.0013352
[Epoch 64; Iter   339/ 1097] train: loss: 0.0000338
[Epoch 64; Iter   369/ 1097] train: loss: 0.0107471
[Epoch 64; Iter   399/ 1097] train: loss: 0.0016517
[Epoch 64; Iter   429/ 1097] train: loss: 0.0037365
[Epoch 64; Iter   459/ 1097] train: loss: 0.0000184
[Epoch 64; Iter   489/ 1097] train: loss: 0.0003471
[Epoch 64; Iter   519/ 1097] train: loss: 0.0058583
[Epoch 64; Iter   549/ 1097] train: loss: 0.0001961
[Epoch 64; Iter   579/ 1097] train: loss: 0.0029937
[Epoch 64; Iter   609/ 1097] train: loss: 0.0006057
[Epoch 64; Iter   639/ 1097] train: loss: 0.0068171
[Epoch 64; Iter   669/ 1097] train: loss: 0.0003746
[Epoch 64; Iter   699/ 1097] train: loss: 0.0006891
[Epoch 64; Iter   729/ 1097] train: loss: 0.0002158
[Epoch 64; Iter   759/ 1097] train: loss: 0.0002849
[Epoch 64; Iter   789/ 1097] train: loss: 0.0000207
[Epoch 64; Iter   819/ 1097] train: loss: 0.0066099
[Epoch 64; Iter   849/ 1097] train: loss: 0.0071001
[Epoch 64; Iter   879/ 1097] train: loss: 0.0004985
[Epoch 64; Iter   909/ 1097] train: loss: 0.0025770
[Epoch 64; Iter   939/ 1097] train: loss: 0.0029797
[Epoch 64; Iter   969/ 1097] train: loss: 0.0141887
[Epoch 64; Iter   999/ 1097] train: loss: 0.0361027
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0004291
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0000796
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0007862
[Epoch 64] ogbg-molhiv: 0.770867 val loss: 0.563279
[Epoch 64] ogbg-molhiv: 0.672844 test loss: 0.626775
[Epoch 65; Iter    22/ 1097] train: loss: 0.0458499
[Epoch 65; Iter    52/ 1097] train: loss: 0.0001414
[Epoch 65; Iter    82/ 1097] train: loss: 0.0017132
[Epoch 65; Iter   112/ 1097] train: loss: 0.0004679
[Epoch 65; Iter   142/ 1097] train: loss: 0.0005852
[Epoch 65; Iter   172/ 1097] train: loss: 0.0320824
[Epoch 65; Iter   202/ 1097] train: loss: 0.0015723
[Epoch 65; Iter   232/ 1097] train: loss: 0.0516097
[Epoch 65; Iter   262/ 1097] train: loss: 0.0056207
[Epoch 65; Iter   292/ 1097] train: loss: 0.0269901
[Epoch 65; Iter   322/ 1097] train: loss: 0.0117465
[Epoch 65; Iter   352/ 1097] train: loss: 0.0042934
[Epoch 65; Iter   382/ 1097] train: loss: 0.0250211
[Epoch 65; Iter   412/ 1097] train: loss: 0.0005199
[Epoch 65; Iter   442/ 1097] train: loss: 0.0002638
[Epoch 65; Iter   472/ 1097] train: loss: 0.0724705
[Epoch 65; Iter   502/ 1097] train: loss: 0.0098766
[Epoch 65; Iter   532/ 1097] train: loss: 0.0001271
[Epoch 65; Iter   562/ 1097] train: loss: 0.0116185
[Epoch 65; Iter   592/ 1097] train: loss: 0.0069169
[Epoch 65; Iter   622/ 1097] train: loss: 0.0008025
[Epoch 65; Iter   652/ 1097] train: loss: 0.0002172
[Epoch 65; Iter   682/ 1097] train: loss: 0.0001558
[Epoch 65; Iter   712/ 1097] train: loss: 0.0847249
[Epoch 65; Iter   742/ 1097] train: loss: 0.0013989
[Epoch 65; Iter   772/ 1097] train: loss: 0.0002419
[Epoch 65; Iter   802/ 1097] train: loss: 0.0752924
[Epoch 65; Iter   832/ 1097] train: loss: 0.0099174
[Epoch 65; Iter   862/ 1097] train: loss: 0.0059502
[Epoch 65; Iter   892/ 1097] train: loss: 0.0149567
[Epoch 65; Iter   922/ 1097] train: loss: 0.0131336
[Epoch 65; Iter   952/ 1097] train: loss: 0.0114648
[Epoch 65; Iter   982/ 1097] train: loss: 0.0062990
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0154117
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0005399
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0020089
[Epoch 65] ogbg-molhiv: 0.711306 val loss: 0.210244
[Epoch 65] ogbg-molhiv: 0.705238 test loss: 0.319400
[Epoch 66; Iter     5/ 1097] train: loss: 0.0078215
[Epoch 66; Iter    35/ 1097] train: loss: 0.0203636
[Epoch 66; Iter    65/ 1097] train: loss: 0.0011901
[Epoch 66; Iter    95/ 1097] train: loss: 0.0037182
[Epoch 66; Iter   125/ 1097] train: loss: 0.0009258
[Epoch 66; Iter   155/ 1097] train: loss: 0.0273324
[Epoch 66; Iter   185/ 1097] train: loss: 0.0018677
[Epoch 66; Iter   215/ 1097] train: loss: 0.0018146
[Epoch 66; Iter   245/ 1097] train: loss: 0.0075891
[Epoch 66; Iter   275/ 1097] train: loss: 0.0035610
[Epoch 66; Iter   305/ 1097] train: loss: 0.0058080
[Epoch 66; Iter   335/ 1097] train: loss: 0.0005462
[Epoch 66; Iter   365/ 1097] train: loss: 0.0295445
[Epoch 66; Iter   395/ 1097] train: loss: 0.0708682
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022615
[Epoch 66; Iter   455/ 1097] train: loss: 0.0031576
[Epoch 66; Iter   485/ 1097] train: loss: 0.0009473
[Epoch 66; Iter   515/ 1097] train: loss: 0.0001063
[Epoch 66; Iter   545/ 1097] train: loss: 0.0003098
[Epoch 66; Iter   575/ 1097] train: loss: 0.0021811
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000563
[Epoch 66; Iter   635/ 1097] train: loss: 0.0267272
[Epoch 66; Iter   665/ 1097] train: loss: 0.0050125
[Epoch 66; Iter   695/ 1097] train: loss: 0.0217094
[Epoch 66; Iter   725/ 1097] train: loss: 0.0211561
[Epoch 66; Iter   755/ 1097] train: loss: 0.0299390
[Epoch 66; Iter   785/ 1097] train: loss: 0.1398416
[Epoch 66; Iter   815/ 1097] train: loss: 0.0089880
[Epoch 66; Iter   845/ 1097] train: loss: 0.0013424
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000411
[Epoch 66; Iter   905/ 1097] train: loss: 0.0020190
[Epoch 66; Iter   935/ 1097] train: loss: 0.0023331
[Epoch 66; Iter   965/ 1097] train: loss: 0.1039859
[Epoch 66; Iter   995/ 1097] train: loss: 0.0001275
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0000616
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0000333
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0003521
[Epoch 66] ogbg-molhiv: 0.740701 val loss: 0.210285
[Epoch 66] ogbg-molhiv: 0.727069 test loss: 0.327778
[Epoch 67; Iter    18/ 1097] train: loss: 0.0011665
[Epoch 67; Iter    48/ 1097] train: loss: 0.0156937
[Epoch 67; Iter    78/ 1097] train: loss: 0.0060667
[Epoch 67; Iter   108/ 1097] train: loss: 0.0104810
[Epoch 67; Iter   138/ 1097] train: loss: 0.0061123
[Epoch 67; Iter   168/ 1097] train: loss: 0.0001030
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000232
[Epoch 67; Iter   228/ 1097] train: loss: 0.0025481
[Epoch 67; Iter   258/ 1097] train: loss: 0.0003120
[Epoch 67; Iter   288/ 1097] train: loss: 0.0032057
[Epoch 67; Iter   318/ 1097] train: loss: 0.0217312
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002696
[Epoch 67; Iter   378/ 1097] train: loss: 0.0026233
[Epoch 67; Iter   408/ 1097] train: loss: 0.0001173
[Epoch 67; Iter   438/ 1097] train: loss: 0.0000731
[Epoch 67; Iter   468/ 1097] train: loss: 0.0171757
[Epoch 67; Iter   498/ 1097] train: loss: 0.0139866
[Epoch 67; Iter   528/ 1097] train: loss: 0.0128909
[Epoch 67; Iter   558/ 1097] train: loss: 0.0001583
[Epoch 67; Iter   588/ 1097] train: loss: 0.0005100
[Epoch 67; Iter   618/ 1097] train: loss: 0.0109673
[Epoch 67; Iter   648/ 1097] train: loss: 0.0008834
[Epoch 67; Iter   678/ 1097] train: loss: 0.0023118
[Epoch 67; Iter   708/ 1097] train: loss: 0.0012901
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000316
[Epoch 67; Iter   768/ 1097] train: loss: 0.0007318
[Epoch 67; Iter   798/ 1097] train: loss: 0.0002688
[Epoch 67; Iter   828/ 1097] train: loss: 0.0356493
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004385
[Epoch 67; Iter   888/ 1097] train: loss: 0.0003713
[Epoch 67; Iter   918/ 1097] train: loss: 0.0026683
[Epoch 67; Iter   948/ 1097] train: loss: 0.0002096
[Epoch 67; Iter   978/ 1097] train: loss: 0.0001897
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0008662
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013424
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000681
[Epoch 67] ogbg-molhiv: 0.721166 val loss: 1.360581
[Epoch 67] ogbg-molhiv: 0.702513 test loss: 1.106982
[Epoch 68; Iter     1/ 1097] train: loss: 0.0096381
[Epoch 68; Iter    31/ 1097] train: loss: 0.0263228
[Epoch 68; Iter    61/ 1097] train: loss: 0.0011344
[Epoch 68; Iter    91/ 1097] train: loss: 0.0041466
[Epoch 68; Iter   121/ 1097] train: loss: 0.0084354
[Epoch 68; Iter   151/ 1097] train: loss: 0.0041448
[Epoch 68; Iter   181/ 1097] train: loss: 0.0028243
[Epoch 68; Iter   211/ 1097] train: loss: 0.0300024
[Epoch 68; Iter   241/ 1097] train: loss: 0.0016289
[Epoch 68; Iter   271/ 1097] train: loss: 0.0024348
[Epoch 68; Iter   301/ 1097] train: loss: 0.0017898
[Epoch 68; Iter   331/ 1097] train: loss: 0.0002593
[Epoch 68; Iter   361/ 1097] train: loss: 0.0023316
[Epoch 68; Iter   391/ 1097] train: loss: 0.0010838
[Epoch 68; Iter   421/ 1097] train: loss: 0.0000714
[Epoch 68; Iter   451/ 1097] train: loss: 0.0009877
[Epoch 68; Iter   481/ 1097] train: loss: 0.0003191
[Epoch 68; Iter   511/ 1097] train: loss: 0.0022090
[Epoch 68; Iter   541/ 1097] train: loss: 0.0001189
[Epoch 68; Iter   571/ 1097] train: loss: 0.0021806
[Epoch 68; Iter   601/ 1097] train: loss: 0.0093891
[Epoch 68; Iter   631/ 1097] train: loss: 0.0000297
[Epoch 68; Iter   661/ 1097] train: loss: 0.0037229
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000473
[Epoch 68; Iter   721/ 1097] train: loss: 0.0079535
[Epoch 68; Iter   751/ 1097] train: loss: 0.0006010
[Epoch 68; Iter   781/ 1097] train: loss: 0.0002445
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001593
[Epoch 68; Iter   841/ 1097] train: loss: 0.0022489
[Epoch 68; Iter   871/ 1097] train: loss: 0.0009986
[Epoch 68; Iter   901/ 1097] train: loss: 0.0158628
[Epoch 68; Iter   931/ 1097] train: loss: 0.0001045
[Epoch 68; Iter   961/ 1097] train: loss: 0.0183131
[Epoch 68; Iter   991/ 1097] train: loss: 0.0033863
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0004971
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0012450
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0004039
[Epoch 68] ogbg-molhiv: 0.778898 val loss: 0.861659
[Epoch 68] ogbg-molhiv: 0.680484 test loss: 1.154759
[Epoch 69; Iter    14/ 1097] train: loss: 0.0001578
[Epoch 69; Iter    44/ 1097] train: loss: 0.0298883
[Epoch 69; Iter    74/ 1097] train: loss: 0.0012194
[Epoch 65; Iter    22/ 1097] train: loss: 0.0000970
[Epoch 65; Iter    52/ 1097] train: loss: 0.0003434
[Epoch 65; Iter    82/ 1097] train: loss: 0.0001835
[Epoch 65; Iter   112/ 1097] train: loss: 0.0000419
[Epoch 65; Iter   142/ 1097] train: loss: 0.0006100
[Epoch 65; Iter   172/ 1097] train: loss: 0.0002770
[Epoch 65; Iter   202/ 1097] train: loss: 0.0001106
[Epoch 65; Iter   232/ 1097] train: loss: 0.0020679
[Epoch 65; Iter   262/ 1097] train: loss: 0.0000133
[Epoch 65; Iter   292/ 1097] train: loss: 0.0002288
[Epoch 65; Iter   322/ 1097] train: loss: 0.0001840
[Epoch 65; Iter   352/ 1097] train: loss: 0.0002086
[Epoch 65; Iter   382/ 1097] train: loss: 0.0023528
[Epoch 65; Iter   412/ 1097] train: loss: 0.0246181
[Epoch 65; Iter   442/ 1097] train: loss: 0.0009464
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000452
[Epoch 65; Iter   502/ 1097] train: loss: 0.0001038
[Epoch 65; Iter   532/ 1097] train: loss: 0.0002319
[Epoch 65; Iter   562/ 1097] train: loss: 0.0000931
[Epoch 65; Iter   592/ 1097] train: loss: 0.0003388
[Epoch 65; Iter   622/ 1097] train: loss: 0.0053736
[Epoch 65; Iter   652/ 1097] train: loss: 0.0005569
[Epoch 65; Iter   682/ 1097] train: loss: 0.0014046
[Epoch 65; Iter   712/ 1097] train: loss: 0.0001418
[Epoch 65; Iter   742/ 1097] train: loss: 0.0000738
[Epoch 65; Iter   772/ 1097] train: loss: 0.0007091
[Epoch 65; Iter   802/ 1097] train: loss: 0.0004094
[Epoch 65; Iter   832/ 1097] train: loss: 0.0077106
[Epoch 65; Iter   862/ 1097] train: loss: 0.0011573
[Epoch 65; Iter   892/ 1097] train: loss: 0.0011327
[Epoch 65; Iter   922/ 1097] train: loss: 0.0010465
[Epoch 65; Iter   952/ 1097] train: loss: 0.0008652
[Epoch 65; Iter   982/ 1097] train: loss: 0.0003924
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0017211
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0002751
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0016761
[Epoch 65] ogbg-molhiv: 0.756571 val loss: 0.224727
[Epoch 65] ogbg-molhiv: 0.713623 test loss: 0.330349
[Epoch 66; Iter     5/ 1097] train: loss: 0.0000316
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001819
[Epoch 66; Iter    65/ 1097] train: loss: 0.0010457
[Epoch 66; Iter    95/ 1097] train: loss: 0.0006894
[Epoch 66; Iter   125/ 1097] train: loss: 0.0053776
[Epoch 66; Iter   155/ 1097] train: loss: 0.0004512
[Epoch 66; Iter   185/ 1097] train: loss: 0.0033797
[Epoch 66; Iter   215/ 1097] train: loss: 0.0001821
[Epoch 66; Iter   245/ 1097] train: loss: 0.0016869
[Epoch 66; Iter   275/ 1097] train: loss: 0.0001603
[Epoch 66; Iter   305/ 1097] train: loss: 0.0039081
[Epoch 66; Iter   335/ 1097] train: loss: 0.0043374
[Epoch 66; Iter   365/ 1097] train: loss: 0.0003445
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002546
[Epoch 66; Iter   425/ 1097] train: loss: 0.0006111
[Epoch 66; Iter   455/ 1097] train: loss: 0.0023967
[Epoch 66; Iter   485/ 1097] train: loss: 0.0232202
[Epoch 66; Iter   515/ 1097] train: loss: 0.0002058
[Epoch 66; Iter   545/ 1097] train: loss: 0.0000920
[Epoch 66; Iter   575/ 1097] train: loss: 0.0011007
[Epoch 66; Iter   605/ 1097] train: loss: 0.0008745
[Epoch 66; Iter   635/ 1097] train: loss: 0.0049825
[Epoch 66; Iter   665/ 1097] train: loss: 0.0004526
[Epoch 66; Iter   695/ 1097] train: loss: 0.0032351
[Epoch 66; Iter   725/ 1097] train: loss: 0.0000604
[Epoch 66; Iter   755/ 1097] train: loss: 0.0000465
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000479
[Epoch 66; Iter   815/ 1097] train: loss: 0.0011926
[Epoch 66; Iter   845/ 1097] train: loss: 0.0000938
[Epoch 66; Iter   875/ 1097] train: loss: 0.0002634
[Epoch 66; Iter   905/ 1097] train: loss: 0.0001237
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001101
[Epoch 66; Iter   965/ 1097] train: loss: 0.0137203
[Epoch 66; Iter   995/ 1097] train: loss: 0.0184217
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0020627
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0000819
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0012577
[Epoch 66] ogbg-molhiv: 0.737709 val loss: 0.223274
[Epoch 66] ogbg-molhiv: 0.730008 test loss: 0.319835
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000219
[Epoch 67; Iter    48/ 1097] train: loss: 0.0009639
[Epoch 67; Iter    78/ 1097] train: loss: 0.0006599
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003301
[Epoch 67; Iter   138/ 1097] train: loss: 0.0001919
[Epoch 67; Iter   168/ 1097] train: loss: 0.0050429
[Epoch 67; Iter   198/ 1097] train: loss: 0.0010158
[Epoch 67; Iter   228/ 1097] train: loss: 0.0003312
[Epoch 67; Iter   258/ 1097] train: loss: 0.0004154
[Epoch 67; Iter   288/ 1097] train: loss: 0.0002091
[Epoch 67; Iter   318/ 1097] train: loss: 0.0032985
[Epoch 67; Iter   348/ 1097] train: loss: 0.0003539
[Epoch 67; Iter   378/ 1097] train: loss: 0.0000449
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000330
[Epoch 67; Iter   438/ 1097] train: loss: 0.0141462
[Epoch 67; Iter   468/ 1097] train: loss: 0.0000529
[Epoch 67; Iter   498/ 1097] train: loss: 0.0006391
[Epoch 67; Iter   528/ 1097] train: loss: 0.0016518
[Epoch 67; Iter   558/ 1097] train: loss: 0.0001110
[Epoch 67; Iter   588/ 1097] train: loss: 0.0020235
[Epoch 67; Iter   618/ 1097] train: loss: 0.0275111
[Epoch 67; Iter   648/ 1097] train: loss: 0.0035043
[Epoch 67; Iter   678/ 1097] train: loss: 0.0001606
[Epoch 67; Iter   708/ 1097] train: loss: 0.0054734
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000548
[Epoch 67; Iter   768/ 1097] train: loss: 0.0001531
[Epoch 67; Iter   798/ 1097] train: loss: 0.0000409
[Epoch 67; Iter   828/ 1097] train: loss: 0.0003972
[Epoch 67; Iter   858/ 1097] train: loss: 0.0097009
[Epoch 67; Iter   888/ 1097] train: loss: 0.0001065
[Epoch 67; Iter   918/ 1097] train: loss: 0.0001804
[Epoch 67; Iter   948/ 1097] train: loss: 0.0003261
[Epoch 67; Iter   978/ 1097] train: loss: 0.0005422
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0010367
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013956
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001173
[Epoch 67] ogbg-molhiv: 0.790920 val loss: 0.241966
[Epoch 67] ogbg-molhiv: 0.724746 test loss: 0.339259
[Epoch 68; Iter     1/ 1097] train: loss: 0.0170525
[Epoch 68; Iter    31/ 1097] train: loss: 0.0000716
[Epoch 68; Iter    61/ 1097] train: loss: 0.0007431
[Epoch 68; Iter    91/ 1097] train: loss: 0.0019586
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000291
[Epoch 68; Iter   151/ 1097] train: loss: 0.0060844
[Epoch 68; Iter   181/ 1097] train: loss: 0.0010048
[Epoch 68; Iter   211/ 1097] train: loss: 0.0000433
[Epoch 68; Iter   241/ 1097] train: loss: 0.0003467
[Epoch 68; Iter   271/ 1097] train: loss: 0.0003853
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000821
[Epoch 68; Iter   331/ 1097] train: loss: 0.0000278
[Epoch 68; Iter   361/ 1097] train: loss: 0.0011798
[Epoch 68; Iter   391/ 1097] train: loss: 0.0006749
[Epoch 68; Iter   421/ 1097] train: loss: 0.0010477
[Epoch 68; Iter   451/ 1097] train: loss: 0.0031421
[Epoch 68; Iter   481/ 1097] train: loss: 0.0000368
[Epoch 68; Iter   511/ 1097] train: loss: 0.0037974
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000563
[Epoch 68; Iter   571/ 1097] train: loss: 0.0000702
[Epoch 68; Iter   601/ 1097] train: loss: 0.0001101
[Epoch 68; Iter   631/ 1097] train: loss: 0.0001409
[Epoch 68; Iter   661/ 1097] train: loss: 0.0001015
[Epoch 68; Iter   691/ 1097] train: loss: 0.0026809
[Epoch 68; Iter   721/ 1097] train: loss: 0.0003301
[Epoch 68; Iter   751/ 1097] train: loss: 0.0487157
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000274
[Epoch 68; Iter   811/ 1097] train: loss: 0.0007827
[Epoch 68; Iter   841/ 1097] train: loss: 0.0135703
[Epoch 68; Iter   871/ 1097] train: loss: 0.0026055
[Epoch 68; Iter   901/ 1097] train: loss: 0.0007480
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000291
[Epoch 68; Iter   961/ 1097] train: loss: 0.0013154
[Epoch 68; Iter   991/ 1097] train: loss: 0.0220227
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0000627
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0001437
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0000798
[Epoch 68] ogbg-molhiv: 0.752638 val loss: 0.206130
[Epoch 68] ogbg-molhiv: 0.709033 test loss: 0.332724
[Epoch 69; Iter    14/ 1097] train: loss: 0.0029830
[Epoch 69; Iter    44/ 1097] train: loss: 0.0000084
[Epoch 69; Iter    74/ 1097] train: loss: 0.0007535
[Epoch 65; Iter    22/ 1097] train: loss: 0.0470107
[Epoch 65; Iter    52/ 1097] train: loss: 0.0006282
[Epoch 65; Iter    82/ 1097] train: loss: 0.1435570
[Epoch 65; Iter   112/ 1097] train: loss: 0.0022975
[Epoch 65; Iter   142/ 1097] train: loss: 0.0002128
[Epoch 65; Iter   172/ 1097] train: loss: 0.0095999
[Epoch 65; Iter   202/ 1097] train: loss: 0.0006600
[Epoch 65; Iter   232/ 1097] train: loss: 0.0470379
[Epoch 65; Iter   262/ 1097] train: loss: 0.0259030
[Epoch 65; Iter   292/ 1097] train: loss: 0.0084162
[Epoch 65; Iter   322/ 1097] train: loss: 0.0397477
[Epoch 65; Iter   352/ 1097] train: loss: 0.2309143
[Epoch 65; Iter   382/ 1097] train: loss: 0.0014246
[Epoch 65; Iter   412/ 1097] train: loss: 0.0619738
[Epoch 65; Iter   442/ 1097] train: loss: 0.0299858
[Epoch 65; Iter   472/ 1097] train: loss: 0.0104850
[Epoch 65; Iter   502/ 1097] train: loss: 0.0440871
[Epoch 65; Iter   532/ 1097] train: loss: 0.0021510
[Epoch 65; Iter   562/ 1097] train: loss: 0.0121871
[Epoch 65; Iter   592/ 1097] train: loss: 0.0004390
[Epoch 65; Iter   622/ 1097] train: loss: 0.0000711
[Epoch 65; Iter   652/ 1097] train: loss: 0.0057457
[Epoch 65; Iter   682/ 1097] train: loss: 0.0010046
[Epoch 65; Iter   712/ 1097] train: loss: 0.0038300
[Epoch 65; Iter   742/ 1097] train: loss: 0.0027048
[Epoch 65; Iter   772/ 1097] train: loss: 0.0210134
[Epoch 65; Iter   802/ 1097] train: loss: 0.0139738
[Epoch 65; Iter   832/ 1097] train: loss: 0.1747053
[Epoch 65; Iter   862/ 1097] train: loss: 0.0088429
[Epoch 65; Iter   892/ 1097] train: loss: 0.0067614
[Epoch 65; Iter   922/ 1097] train: loss: 0.0001282
[Epoch 65; Iter   952/ 1097] train: loss: 0.0026852
[Epoch 65; Iter   982/ 1097] train: loss: 0.0047266
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0239170
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0003201
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0020509
[Epoch 65] ogbg-molhiv: 0.702999 val loss: 5.432815
[Epoch 65] ogbg-molhiv: 0.715070 test loss: 1.704674
[Epoch 66; Iter     5/ 1097] train: loss: 0.0112011
[Epoch 66; Iter    35/ 1097] train: loss: 0.0003513
[Epoch 66; Iter    65/ 1097] train: loss: 0.0086806
[Epoch 66; Iter    95/ 1097] train: loss: 0.0072638
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003073
[Epoch 66; Iter   155/ 1097] train: loss: 0.0009676
[Epoch 66; Iter   185/ 1097] train: loss: 0.0151729
[Epoch 66; Iter   215/ 1097] train: loss: 0.0006797
[Epoch 66; Iter   245/ 1097] train: loss: 0.0040406
[Epoch 66; Iter   275/ 1097] train: loss: 0.0001335
[Epoch 66; Iter   305/ 1097] train: loss: 0.0004673
[Epoch 66; Iter   335/ 1097] train: loss: 0.0318179
[Epoch 66; Iter   365/ 1097] train: loss: 0.0431712
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002483
[Epoch 66; Iter   425/ 1097] train: loss: 0.0037656
[Epoch 66; Iter   455/ 1097] train: loss: 0.1346431
[Epoch 66; Iter   485/ 1097] train: loss: 0.0126779
[Epoch 66; Iter   515/ 1097] train: loss: 0.0390965
[Epoch 66; Iter   545/ 1097] train: loss: 0.0002533
[Epoch 66; Iter   575/ 1097] train: loss: 0.0021513
[Epoch 66; Iter   605/ 1097] train: loss: 0.0009815
[Epoch 66; Iter   635/ 1097] train: loss: 0.0002062
[Epoch 66; Iter   665/ 1097] train: loss: 0.0086270
[Epoch 66; Iter   695/ 1097] train: loss: 0.0002002
[Epoch 66; Iter   725/ 1097] train: loss: 0.0033026
[Epoch 66; Iter   755/ 1097] train: loss: 0.0008380
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000734
[Epoch 66; Iter   815/ 1097] train: loss: 0.0553874
[Epoch 66; Iter   845/ 1097] train: loss: 0.0004112
[Epoch 66; Iter   875/ 1097] train: loss: 0.0005774
[Epoch 66; Iter   905/ 1097] train: loss: 0.0012046
[Epoch 66; Iter   935/ 1097] train: loss: 0.0012557
[Epoch 66; Iter   965/ 1097] train: loss: 0.0010904
[Epoch 66; Iter   995/ 1097] train: loss: 0.0025643
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0021599
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0025511
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0028518
[Epoch 66] ogbg-molhiv: 0.699438 val loss: 8.497340
[Epoch 66] ogbg-molhiv: 0.717783 test loss: 2.185959
[Epoch 67; Iter    18/ 1097] train: loss: 0.0005717
[Epoch 67; Iter    48/ 1097] train: loss: 0.0012591
[Epoch 67; Iter    78/ 1097] train: loss: 0.0002442
[Epoch 67; Iter   108/ 1097] train: loss: 0.0745981
[Epoch 67; Iter   138/ 1097] train: loss: 0.0148298
[Epoch 67; Iter   168/ 1097] train: loss: 0.0176930
[Epoch 67; Iter   198/ 1097] train: loss: 0.0008566
[Epoch 67; Iter   228/ 1097] train: loss: 0.0251000
[Epoch 67; Iter   258/ 1097] train: loss: 0.0079865
[Epoch 67; Iter   288/ 1097] train: loss: 0.0017978
[Epoch 67; Iter   318/ 1097] train: loss: 0.0023910
[Epoch 67; Iter   348/ 1097] train: loss: 0.0548686
[Epoch 67; Iter   378/ 1097] train: loss: 0.0056236
[Epoch 67; Iter   408/ 1097] train: loss: 0.0068864
[Epoch 67; Iter   438/ 1097] train: loss: 0.0001847
[Epoch 67; Iter   468/ 1097] train: loss: 0.0207791
[Epoch 67; Iter   498/ 1097] train: loss: 0.0067579
[Epoch 67; Iter   528/ 1097] train: loss: 0.0026428
[Epoch 67; Iter   558/ 1097] train: loss: 0.0061373
[Epoch 67; Iter   588/ 1097] train: loss: 0.0009199
[Epoch 67; Iter   618/ 1097] train: loss: 0.0830637
[Epoch 67; Iter   648/ 1097] train: loss: 0.0226444
[Epoch 67; Iter   678/ 1097] train: loss: 0.0135663
[Epoch 67; Iter   708/ 1097] train: loss: 0.0014255
[Epoch 67; Iter   738/ 1097] train: loss: 0.0021335
[Epoch 67; Iter   768/ 1097] train: loss: 0.0093593
[Epoch 67; Iter   798/ 1097] train: loss: 0.0006395
[Epoch 67; Iter   828/ 1097] train: loss: 0.0035098
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004241
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000895
[Epoch 67; Iter   918/ 1097] train: loss: 0.0120399
[Epoch 67; Iter   948/ 1097] train: loss: 0.0005854
[Epoch 67; Iter   978/ 1097] train: loss: 0.0172572
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0024584
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0113914
[Epoch 67; Iter  1068/ 1097] train: loss: 0.1355211
[Epoch 67] ogbg-molhiv: 0.738132 val loss: 2.211960
[Epoch 67] ogbg-molhiv: 0.697312 test loss: 0.755871
[Epoch 68; Iter     1/ 1097] train: loss: 0.0838592
[Epoch 68; Iter    31/ 1097] train: loss: 0.0037387
[Epoch 68; Iter    61/ 1097] train: loss: 0.0389138
[Epoch 68; Iter    91/ 1097] train: loss: 0.0065893
[Epoch 68; Iter   121/ 1097] train: loss: 0.0009492
[Epoch 68; Iter   151/ 1097] train: loss: 0.0046475
[Epoch 68; Iter   181/ 1097] train: loss: 0.0075202
[Epoch 68; Iter   211/ 1097] train: loss: 0.0002730
[Epoch 68; Iter   241/ 1097] train: loss: 0.0098977
[Epoch 68; Iter   271/ 1097] train: loss: 0.0004715
[Epoch 68; Iter   301/ 1097] train: loss: 0.0673547
[Epoch 68; Iter   331/ 1097] train: loss: 0.0011097
[Epoch 68; Iter   361/ 1097] train: loss: 0.0041963
[Epoch 68; Iter   391/ 1097] train: loss: 0.0003094
[Epoch 68; Iter   421/ 1097] train: loss: 0.1058811
[Epoch 68; Iter   451/ 1097] train: loss: 0.0372355
[Epoch 68; Iter   481/ 1097] train: loss: 0.0050142
[Epoch 68; Iter   511/ 1097] train: loss: 0.0016367
[Epoch 68; Iter   541/ 1097] train: loss: 0.0081063
[Epoch 68; Iter   571/ 1097] train: loss: 0.0002268
[Epoch 68; Iter   601/ 1097] train: loss: 0.0008602
[Epoch 68; Iter   631/ 1097] train: loss: 0.0888578
[Epoch 68; Iter   661/ 1097] train: loss: 0.0191590
[Epoch 68; Iter   691/ 1097] train: loss: 0.0037719
[Epoch 68; Iter   721/ 1097] train: loss: 0.0008406
[Epoch 68; Iter   751/ 1097] train: loss: 0.0083663
[Epoch 68; Iter   781/ 1097] train: loss: 0.0001000
[Epoch 68; Iter   811/ 1097] train: loss: 0.0138201
[Epoch 68; Iter   841/ 1097] train: loss: 0.0143262
[Epoch 68; Iter   871/ 1097] train: loss: 0.0207979
[Epoch 68; Iter   901/ 1097] train: loss: 0.0003152
[Epoch 68; Iter   931/ 1097] train: loss: 0.0008096
[Epoch 68; Iter   961/ 1097] train: loss: 0.0023000
[Epoch 68; Iter   991/ 1097] train: loss: 0.0025458
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0029290
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003228
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0002797
[Epoch 68] ogbg-molhiv: 0.706089 val loss: 9.345147
[Epoch 68] ogbg-molhiv: 0.690834 test loss: 2.764074
[Epoch 69; Iter    14/ 1097] train: loss: 0.0053543
[Epoch 69; Iter    44/ 1097] train: loss: 0.0002877
[Epoch 69; Iter    74/ 1097] train: loss: 0.0000567
[Epoch 65; Iter    22/ 1097] train: loss: 0.0000492
[Epoch 65; Iter    52/ 1097] train: loss: 0.0009570
[Epoch 65; Iter    82/ 1097] train: loss: 0.0002935
[Epoch 65; Iter   112/ 1097] train: loss: 0.0004635
[Epoch 65; Iter   142/ 1097] train: loss: 0.0010622
[Epoch 65; Iter   172/ 1097] train: loss: 0.0000786
[Epoch 65; Iter   202/ 1097] train: loss: 0.0044144
[Epoch 65; Iter   232/ 1097] train: loss: 0.0011320
[Epoch 65; Iter   262/ 1097] train: loss: 0.0001728
[Epoch 65; Iter   292/ 1097] train: loss: 0.0000669
[Epoch 65; Iter   322/ 1097] train: loss: 0.0014805
[Epoch 65; Iter   352/ 1097] train: loss: 0.0005851
[Epoch 65; Iter   382/ 1097] train: loss: 0.0000170
[Epoch 65; Iter   412/ 1097] train: loss: 0.0002951
[Epoch 65; Iter   442/ 1097] train: loss: 0.0001237
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000239
[Epoch 65; Iter   502/ 1097] train: loss: 0.0033081
[Epoch 65; Iter   532/ 1097] train: loss: 0.0006690
[Epoch 65; Iter   562/ 1097] train: loss: 0.0006080
[Epoch 65; Iter   592/ 1097] train: loss: 0.0002202
[Epoch 65; Iter   622/ 1097] train: loss: 0.0010132
[Epoch 65; Iter   652/ 1097] train: loss: 0.0020506
[Epoch 65; Iter   682/ 1097] train: loss: 0.0002735
[Epoch 65; Iter   712/ 1097] train: loss: 0.0011484
[Epoch 65; Iter   742/ 1097] train: loss: 0.0025907
[Epoch 65; Iter   772/ 1097] train: loss: 0.0022459
[Epoch 65; Iter   802/ 1097] train: loss: 0.0001170
[Epoch 65; Iter   832/ 1097] train: loss: 0.0001500
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001911
[Epoch 65; Iter   892/ 1097] train: loss: 0.0001206
[Epoch 65; Iter   922/ 1097] train: loss: 0.0023544
[Epoch 65; Iter   952/ 1097] train: loss: 0.0171173
[Epoch 65; Iter   982/ 1097] train: loss: 0.0240842
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0008188
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0012253
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0034001
[Epoch 65] ogbg-molhiv: 0.762453 val loss: 0.318902
[Epoch 65] ogbg-molhiv: 0.753869 test loss: 0.318466
[Epoch 66; Iter     5/ 1097] train: loss: 0.0010636
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001206
[Epoch 66; Iter    65/ 1097] train: loss: 0.0002309
[Epoch 66; Iter    95/ 1097] train: loss: 0.0001860
[Epoch 66; Iter   125/ 1097] train: loss: 0.0014813
[Epoch 66; Iter   155/ 1097] train: loss: 0.0613579
[Epoch 66; Iter   185/ 1097] train: loss: 0.0012067
[Epoch 66; Iter   215/ 1097] train: loss: 0.0018905
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000616
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000621
[Epoch 66; Iter   305/ 1097] train: loss: 0.0001132
[Epoch 66; Iter   335/ 1097] train: loss: 0.0004249
[Epoch 66; Iter   365/ 1097] train: loss: 0.0000970
[Epoch 66; Iter   395/ 1097] train: loss: 0.0039090
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022481
[Epoch 66; Iter   455/ 1097] train: loss: 0.0062502
[Epoch 66; Iter   485/ 1097] train: loss: 0.0000467
[Epoch 66; Iter   515/ 1097] train: loss: 0.0014947
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001248
[Epoch 66; Iter   575/ 1097] train: loss: 0.0009787
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000370
[Epoch 66; Iter   635/ 1097] train: loss: 0.0001118
[Epoch 66; Iter   665/ 1097] train: loss: 0.0000164
[Epoch 66; Iter   695/ 1097] train: loss: 0.0001520
[Epoch 66; Iter   725/ 1097] train: loss: 0.0045892
[Epoch 66; Iter   755/ 1097] train: loss: 0.0003500
[Epoch 66; Iter   785/ 1097] train: loss: 0.0032922
[Epoch 66; Iter   815/ 1097] train: loss: 0.0162748
[Epoch 66; Iter   845/ 1097] train: loss: 0.0120124
[Epoch 66; Iter   875/ 1097] train: loss: 0.0219260
[Epoch 66; Iter   905/ 1097] train: loss: 0.0000450
[Epoch 66; Iter   935/ 1097] train: loss: 0.0002197
[Epoch 66; Iter   965/ 1097] train: loss: 0.0013709
[Epoch 66; Iter   995/ 1097] train: loss: 0.0008000
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0009843
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0061559
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0149067
[Epoch 66] ogbg-molhiv: 0.752832 val loss: 0.296899
[Epoch 66] ogbg-molhiv: 0.755974 test loss: 0.292253
[Epoch 67; Iter    18/ 1097] train: loss: 0.0001443
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000120
[Epoch 67; Iter    78/ 1097] train: loss: 0.0000938
[Epoch 67; Iter   108/ 1097] train: loss: 0.0019682
[Epoch 67; Iter   138/ 1097] train: loss: 0.0001323
[Epoch 67; Iter   168/ 1097] train: loss: 0.0546193
[Epoch 67; Iter   198/ 1097] train: loss: 0.0491535
[Epoch 67; Iter   228/ 1097] train: loss: 0.0000421
[Epoch 67; Iter   258/ 1097] train: loss: 0.0000125
[Epoch 67; Iter   288/ 1097] train: loss: 0.0174621
[Epoch 67; Iter   318/ 1097] train: loss: 0.0080734
[Epoch 67; Iter   348/ 1097] train: loss: 0.0007331
[Epoch 67; Iter   378/ 1097] train: loss: 0.0021186
[Epoch 67; Iter   408/ 1097] train: loss: 0.0104353
[Epoch 67; Iter   438/ 1097] train: loss: 0.0015467
[Epoch 67; Iter   468/ 1097] train: loss: 0.0010065
[Epoch 67; Iter   498/ 1097] train: loss: 0.0203940
[Epoch 67; Iter   528/ 1097] train: loss: 0.0051172
[Epoch 67; Iter   558/ 1097] train: loss: 0.0002251
[Epoch 67; Iter   588/ 1097] train: loss: 0.0005095
[Epoch 67; Iter   618/ 1097] train: loss: 0.0031743
[Epoch 67; Iter   648/ 1097] train: loss: 0.0002126
[Epoch 67; Iter   678/ 1097] train: loss: 0.0003284
[Epoch 67; Iter   708/ 1097] train: loss: 0.0006847
[Epoch 67; Iter   738/ 1097] train: loss: 0.0000867
[Epoch 67; Iter   768/ 1097] train: loss: 0.0000176
[Epoch 67; Iter   798/ 1097] train: loss: 0.0033798
[Epoch 67; Iter   828/ 1097] train: loss: 0.0025728
[Epoch 67; Iter   858/ 1097] train: loss: 0.0028816
[Epoch 67; Iter   888/ 1097] train: loss: 0.0007726
[Epoch 67; Iter   918/ 1097] train: loss: 0.0000677
[Epoch 67; Iter   948/ 1097] train: loss: 0.0071209
[Epoch 67; Iter   978/ 1097] train: loss: 0.0006741
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0006008
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000270
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001918
[Epoch 67] ogbg-molhiv: 0.756053 val loss: 0.298884
[Epoch 67] ogbg-molhiv: 0.758425 test loss: 0.306313
[Epoch 68; Iter     1/ 1097] train: loss: 0.0047599
[Epoch 68; Iter    31/ 1097] train: loss: 0.0002378
[Epoch 68; Iter    61/ 1097] train: loss: 0.0105043
[Epoch 68; Iter    91/ 1097] train: loss: 0.0005623
[Epoch 68; Iter   121/ 1097] train: loss: 0.0001260
[Epoch 68; Iter   151/ 1097] train: loss: 0.0003281
[Epoch 68; Iter   181/ 1097] train: loss: 0.0008573
[Epoch 68; Iter   211/ 1097] train: loss: 0.0004565
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002200
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000967
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000368
[Epoch 68; Iter   331/ 1097] train: loss: 0.0001243
[Epoch 68; Iter   361/ 1097] train: loss: 0.0051804
[Epoch 68; Iter   391/ 1097] train: loss: 0.0064077
[Epoch 68; Iter   421/ 1097] train: loss: 0.0370611
[Epoch 68; Iter   451/ 1097] train: loss: 0.0000610
[Epoch 68; Iter   481/ 1097] train: loss: 0.0004427
[Epoch 68; Iter   511/ 1097] train: loss: 0.0171676
[Epoch 68; Iter   541/ 1097] train: loss: 0.0034634
[Epoch 68; Iter   571/ 1097] train: loss: 0.0105023
[Epoch 68; Iter   601/ 1097] train: loss: 0.0217570
[Epoch 68; Iter   631/ 1097] train: loss: 0.0207619
[Epoch 68; Iter   661/ 1097] train: loss: 0.0004625
[Epoch 68; Iter   691/ 1097] train: loss: 0.0002011
[Epoch 68; Iter   721/ 1097] train: loss: 0.0801122
[Epoch 68; Iter   751/ 1097] train: loss: 0.0001333
[Epoch 68; Iter   781/ 1097] train: loss: 0.0020628
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001935
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000745
[Epoch 68; Iter   871/ 1097] train: loss: 0.0114615
[Epoch 68; Iter   901/ 1097] train: loss: 0.0004145
[Epoch 68; Iter   931/ 1097] train: loss: 0.0006316
[Epoch 68; Iter   961/ 1097] train: loss: 0.0034835
[Epoch 68; Iter   991/ 1097] train: loss: 0.0002500
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0002647
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0011778
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0009531
[Epoch 68] ogbg-molhiv: 0.765046 val loss: 0.340312
[Epoch 68] ogbg-molhiv: 0.729054 test loss: 0.326092
[Epoch 69; Iter    14/ 1097] train: loss: 0.0577969
[Epoch 69; Iter    44/ 1097] train: loss: 0.0027400
[Epoch 69; Iter    74/ 1097] train: loss: 0.0003513
[Epoch 65; Iter    22/ 1097] train: loss: 0.0063051
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000710
[Epoch 65; Iter    82/ 1097] train: loss: 0.0007818
[Epoch 65; Iter   112/ 1097] train: loss: 0.0005497
[Epoch 65; Iter   142/ 1097] train: loss: 0.0001036
[Epoch 65; Iter   172/ 1097] train: loss: 0.0119044
[Epoch 65; Iter   202/ 1097] train: loss: 0.0075548
[Epoch 65; Iter   232/ 1097] train: loss: 0.0000231
[Epoch 65; Iter   262/ 1097] train: loss: 0.0000803
[Epoch 65; Iter   292/ 1097] train: loss: 0.0007070
[Epoch 65; Iter   322/ 1097] train: loss: 0.0063854
[Epoch 65; Iter   352/ 1097] train: loss: 0.0018846
[Epoch 65; Iter   382/ 1097] train: loss: 0.0014824
[Epoch 65; Iter   412/ 1097] train: loss: 0.0000442
[Epoch 65; Iter   442/ 1097] train: loss: 0.0110511
[Epoch 65; Iter   472/ 1097] train: loss: 0.0080721
[Epoch 65; Iter   502/ 1097] train: loss: 0.0000434
[Epoch 65; Iter   532/ 1097] train: loss: 0.0132560
[Epoch 65; Iter   562/ 1097] train: loss: 0.0001154
[Epoch 65; Iter   592/ 1097] train: loss: 0.0000506
[Epoch 65; Iter   622/ 1097] train: loss: 0.0001732
[Epoch 65; Iter   652/ 1097] train: loss: 0.0008366
[Epoch 65; Iter   682/ 1097] train: loss: 0.0016593
[Epoch 65; Iter   712/ 1097] train: loss: 0.0016110
[Epoch 65; Iter   742/ 1097] train: loss: 0.0028485
[Epoch 65; Iter   772/ 1097] train: loss: 0.0001050
[Epoch 65; Iter   802/ 1097] train: loss: 0.0002844
[Epoch 65; Iter   832/ 1097] train: loss: 0.0003418
[Epoch 65; Iter   862/ 1097] train: loss: 0.0138540
[Epoch 65; Iter   892/ 1097] train: loss: 0.0000299
[Epoch 65; Iter   922/ 1097] train: loss: 0.0017412
[Epoch 65; Iter   952/ 1097] train: loss: 0.0011339
[Epoch 65; Iter   982/ 1097] train: loss: 0.0018116
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0004476
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0004716
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0588978
[Epoch 65] ogbg-molhiv: 0.772419 val loss: 0.232163
[Epoch 65] ogbg-molhiv: 0.726457 test loss: 0.314523
[Epoch 66; Iter     5/ 1097] train: loss: 0.0005556
[Epoch 66; Iter    35/ 1097] train: loss: 0.0000363
[Epoch 66; Iter    65/ 1097] train: loss: 0.0002691
[Epoch 66; Iter    95/ 1097] train: loss: 0.0006619
[Epoch 66; Iter   125/ 1097] train: loss: 0.0034733
[Epoch 66; Iter   155/ 1097] train: loss: 0.0019491
[Epoch 66; Iter   185/ 1097] train: loss: 0.0004382
[Epoch 66; Iter   215/ 1097] train: loss: 0.0026262
[Epoch 66; Iter   245/ 1097] train: loss: 0.0118963
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000419
[Epoch 66; Iter   305/ 1097] train: loss: 0.0017222
[Epoch 66; Iter   335/ 1097] train: loss: 0.0002484
[Epoch 66; Iter   365/ 1097] train: loss: 0.0002315
[Epoch 66; Iter   395/ 1097] train: loss: 0.0012582
[Epoch 66; Iter   425/ 1097] train: loss: 0.0000795
[Epoch 66; Iter   455/ 1097] train: loss: 0.0028617
[Epoch 66; Iter   485/ 1097] train: loss: 0.0003207
[Epoch 66; Iter   515/ 1097] train: loss: 0.0015792
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001540
[Epoch 66; Iter   575/ 1097] train: loss: 0.0012906
[Epoch 66; Iter   605/ 1097] train: loss: 0.0010948
[Epoch 66; Iter   635/ 1097] train: loss: 0.0164859
[Epoch 66; Iter   665/ 1097] train: loss: 0.0010976
[Epoch 66; Iter   695/ 1097] train: loss: 0.0002169
[Epoch 66; Iter   725/ 1097] train: loss: 0.0327910
[Epoch 66; Iter   755/ 1097] train: loss: 0.0009268
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000271
[Epoch 66; Iter   815/ 1097] train: loss: 0.0000849
[Epoch 66; Iter   845/ 1097] train: loss: 0.0000441
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000993
[Epoch 66; Iter   905/ 1097] train: loss: 0.0014598
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001428
[Epoch 66; Iter   965/ 1097] train: loss: 0.0000928
[Epoch 66; Iter   995/ 1097] train: loss: 0.0014079
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0012217
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0001500
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0006688
[Epoch 66] ogbg-molhiv: 0.785062 val loss: 0.235264
[Epoch 66] ogbg-molhiv: 0.713183 test loss: 0.387722
[Epoch 67; Iter    18/ 1097] train: loss: 0.0007739
[Epoch 67; Iter    48/ 1097] train: loss: 0.0001935
[Epoch 67; Iter    78/ 1097] train: loss: 0.0039587
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003103
[Epoch 67; Iter   138/ 1097] train: loss: 0.0002004
[Epoch 67; Iter   168/ 1097] train: loss: 0.0059387
[Epoch 67; Iter   198/ 1097] train: loss: 0.0014565
[Epoch 67; Iter   228/ 1097] train: loss: 0.0001886
[Epoch 67; Iter   258/ 1097] train: loss: 0.0221459
[Epoch 67; Iter   288/ 1097] train: loss: 0.0005222
[Epoch 67; Iter   318/ 1097] train: loss: 0.0000197
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002332
[Epoch 67; Iter   378/ 1097] train: loss: 0.0001602
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000146
[Epoch 67; Iter   438/ 1097] train: loss: 0.0021919
[Epoch 67; Iter   468/ 1097] train: loss: 0.0004093
[Epoch 67; Iter   498/ 1097] train: loss: 0.0000317
[Epoch 67; Iter   528/ 1097] train: loss: 0.0000192
[Epoch 67; Iter   558/ 1097] train: loss: 0.0024132
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000791
[Epoch 67; Iter   618/ 1097] train: loss: 0.0006891
[Epoch 67; Iter   648/ 1097] train: loss: 0.0005726
[Epoch 67; Iter   678/ 1097] train: loss: 0.0005412
[Epoch 67; Iter   708/ 1097] train: loss: 0.0012026
[Epoch 67; Iter   738/ 1097] train: loss: 0.0007346
[Epoch 67; Iter   768/ 1097] train: loss: 0.0012930
[Epoch 67; Iter   798/ 1097] train: loss: 0.0000557
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000422
[Epoch 67; Iter   858/ 1097] train: loss: 0.0014934
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000309
[Epoch 67; Iter   918/ 1097] train: loss: 0.0002834
[Epoch 67; Iter   948/ 1097] train: loss: 0.0007958
[Epoch 67; Iter   978/ 1097] train: loss: 0.0057545
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0022526
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0013847
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001896
[Epoch 67] ogbg-molhiv: 0.790270 val loss: 0.272167
[Epoch 67] ogbg-molhiv: 0.733244 test loss: 0.405989
[Epoch 68; Iter     1/ 1097] train: loss: 0.0009141
[Epoch 68; Iter    31/ 1097] train: loss: 0.0014241
[Epoch 68; Iter    61/ 1097] train: loss: 0.0006685
[Epoch 68; Iter    91/ 1097] train: loss: 0.0003374
[Epoch 68; Iter   121/ 1097] train: loss: 0.0002078
[Epoch 68; Iter   151/ 1097] train: loss: 0.0000607
[Epoch 68; Iter   181/ 1097] train: loss: 0.0014281
[Epoch 68; Iter   211/ 1097] train: loss: 0.0007085
[Epoch 68; Iter   241/ 1097] train: loss: 0.0003416
[Epoch 68; Iter   271/ 1097] train: loss: 0.0062670
[Epoch 68; Iter   301/ 1097] train: loss: 0.0015945
[Epoch 68; Iter   331/ 1097] train: loss: 0.0002336
[Epoch 68; Iter   361/ 1097] train: loss: 0.0023877
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000561
[Epoch 68; Iter   421/ 1097] train: loss: 0.0001311
[Epoch 68; Iter   451/ 1097] train: loss: 0.0003342
[Epoch 68; Iter   481/ 1097] train: loss: 0.0004292
[Epoch 68; Iter   511/ 1097] train: loss: 0.0001291
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000240
[Epoch 68; Iter   571/ 1097] train: loss: 0.0047011
[Epoch 68; Iter   601/ 1097] train: loss: 0.0005732
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002848
[Epoch 68; Iter   661/ 1097] train: loss: 0.0027758
[Epoch 68; Iter   691/ 1097] train: loss: 0.0003046
[Epoch 68; Iter   721/ 1097] train: loss: 0.0001764
[Epoch 68; Iter   751/ 1097] train: loss: 0.0054303
[Epoch 68; Iter   781/ 1097] train: loss: 0.0012685
[Epoch 68; Iter   811/ 1097] train: loss: 0.0009425
[Epoch 68; Iter   841/ 1097] train: loss: 0.0084438
[Epoch 68; Iter   871/ 1097] train: loss: 0.0122049
[Epoch 68; Iter   901/ 1097] train: loss: 0.0134268
[Epoch 68; Iter   931/ 1097] train: loss: 0.0023479
[Epoch 68; Iter   961/ 1097] train: loss: 0.0022811
[Epoch 68; Iter   991/ 1097] train: loss: 0.0430393
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0024305
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0001312
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0001466
[Epoch 68] ogbg-molhiv: 0.792040 val loss: 0.236461
[Epoch 68] ogbg-molhiv: 0.738552 test loss: 0.581168
[Epoch 69; Iter    14/ 1097] train: loss: 0.0002315
[Epoch 69; Iter    44/ 1097] train: loss: 0.0001275
[Epoch 69; Iter    74/ 1097] train: loss: 0.0003475
[Epoch 65; Iter    22/ 1097] train: loss: 0.0960650
[Epoch 65; Iter    52/ 1097] train: loss: 0.0007544
[Epoch 65; Iter    82/ 1097] train: loss: 0.0000422
[Epoch 65; Iter   112/ 1097] train: loss: 0.0001639
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000201
[Epoch 65; Iter   172/ 1097] train: loss: 0.0334121
[Epoch 65; Iter   202/ 1097] train: loss: 0.0000645
[Epoch 65; Iter   232/ 1097] train: loss: 0.0129337
[Epoch 65; Iter   262/ 1097] train: loss: 0.0145340
[Epoch 65; Iter   292/ 1097] train: loss: 0.0005884
[Epoch 65; Iter   322/ 1097] train: loss: 0.0042340
[Epoch 65; Iter   352/ 1097] train: loss: 0.0001527
[Epoch 65; Iter   382/ 1097] train: loss: 0.0004889
[Epoch 65; Iter   412/ 1097] train: loss: 0.0004698
[Epoch 65; Iter   442/ 1097] train: loss: 0.0000216
[Epoch 65; Iter   472/ 1097] train: loss: 0.0218516
[Epoch 65; Iter   502/ 1097] train: loss: 0.0003672
[Epoch 65; Iter   532/ 1097] train: loss: 0.0016977
[Epoch 65; Iter   562/ 1097] train: loss: 0.0033836
[Epoch 65; Iter   592/ 1097] train: loss: 0.0010214
[Epoch 65; Iter   622/ 1097] train: loss: 0.0001983
[Epoch 65; Iter   652/ 1097] train: loss: 0.0000695
[Epoch 65; Iter   682/ 1097] train: loss: 0.0014673
[Epoch 65; Iter   712/ 1097] train: loss: 0.0267931
[Epoch 65; Iter   742/ 1097] train: loss: 0.0003532
[Epoch 65; Iter   772/ 1097] train: loss: 0.0001711
[Epoch 65; Iter   802/ 1097] train: loss: 0.0000247
[Epoch 65; Iter   832/ 1097] train: loss: 0.0009002
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001759
[Epoch 65; Iter   892/ 1097] train: loss: 0.0001985
[Epoch 65; Iter   922/ 1097] train: loss: 0.0002428
[Epoch 65; Iter   952/ 1097] train: loss: 0.0000684
[Epoch 65; Iter   982/ 1097] train: loss: 0.0000118
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0006152
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0043850
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0002392
[Epoch 65] ogbg-molhiv: 0.789294 val loss: 0.427604
[Epoch 65] ogbg-molhiv: 0.793654 test loss: 0.287460
[Epoch 66; Iter     5/ 1097] train: loss: 0.0004276
[Epoch 66; Iter    35/ 1097] train: loss: 0.0001059
[Epoch 66; Iter    65/ 1097] train: loss: 0.0286570
[Epoch 66; Iter    95/ 1097] train: loss: 0.0078604
[Epoch 66; Iter   125/ 1097] train: loss: 0.0008318
[Epoch 66; Iter   155/ 1097] train: loss: 0.0007165
[Epoch 66; Iter   185/ 1097] train: loss: 0.0020878
[Epoch 66; Iter   215/ 1097] train: loss: 0.0000698
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000283
[Epoch 66; Iter   275/ 1097] train: loss: 0.0004328
[Epoch 66; Iter   305/ 1097] train: loss: 0.0002846
[Epoch 66; Iter   335/ 1097] train: loss: 0.0038796
[Epoch 66; Iter   365/ 1097] train: loss: 0.0001797
[Epoch 66; Iter   395/ 1097] train: loss: 0.0004027
[Epoch 66; Iter   425/ 1097] train: loss: 0.0004303
[Epoch 66; Iter   455/ 1097] train: loss: 0.0179094
[Epoch 66; Iter   485/ 1097] train: loss: 0.0003071
[Epoch 66; Iter   515/ 1097] train: loss: 0.0000189
[Epoch 66; Iter   545/ 1097] train: loss: 0.0001720
[Epoch 66; Iter   575/ 1097] train: loss: 0.0011867
[Epoch 66; Iter   605/ 1097] train: loss: 0.0000637
[Epoch 66; Iter   635/ 1097] train: loss: 0.0000103
[Epoch 66; Iter   665/ 1097] train: loss: 0.0004386
[Epoch 66; Iter   695/ 1097] train: loss: 0.0000346
[Epoch 66; Iter   725/ 1097] train: loss: 0.0018602
[Epoch 66; Iter   755/ 1097] train: loss: 0.0001385
[Epoch 66; Iter   785/ 1097] train: loss: 0.0007738
[Epoch 66; Iter   815/ 1097] train: loss: 0.0008652
[Epoch 66; Iter   845/ 1097] train: loss: 0.0154965
[Epoch 66; Iter   875/ 1097] train: loss: 0.0004182
[Epoch 66; Iter   905/ 1097] train: loss: 0.0000299
[Epoch 66; Iter   935/ 1097] train: loss: 0.0000149
[Epoch 66; Iter   965/ 1097] train: loss: 0.0361374
[Epoch 66; Iter   995/ 1097] train: loss: 0.0014734
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0000298
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0009952
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0000817
[Epoch 66] ogbg-molhiv: 0.790868 val loss: 0.357581
[Epoch 66] ogbg-molhiv: 0.802507 test loss: 0.304715
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000108
[Epoch 67; Iter    48/ 1097] train: loss: 0.0011437
[Epoch 67; Iter    78/ 1097] train: loss: 0.0005893
[Epoch 67; Iter   108/ 1097] train: loss: 0.0001720
[Epoch 67; Iter   138/ 1097] train: loss: 0.0000486
[Epoch 67; Iter   168/ 1097] train: loss: 0.0000715
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000659
[Epoch 67; Iter   228/ 1097] train: loss: 0.0001712
[Epoch 67; Iter   258/ 1097] train: loss: 0.0004310
[Epoch 67; Iter   288/ 1097] train: loss: 0.0005475
[Epoch 67; Iter   318/ 1097] train: loss: 0.0000831
[Epoch 67; Iter   348/ 1097] train: loss: 0.0001324
[Epoch 67; Iter   378/ 1097] train: loss: 0.0001000
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000358
[Epoch 67; Iter   438/ 1097] train: loss: 0.0000372
[Epoch 67; Iter   468/ 1097] train: loss: 0.0000584
[Epoch 67; Iter   498/ 1097] train: loss: 0.0007570
[Epoch 67; Iter   528/ 1097] train: loss: 0.0000291
[Epoch 67; Iter   558/ 1097] train: loss: 0.0000333
[Epoch 67; Iter   588/ 1097] train: loss: 0.0002072
[Epoch 67; Iter   618/ 1097] train: loss: 0.0002548
[Epoch 67; Iter   648/ 1097] train: loss: 0.0025042
[Epoch 67; Iter   678/ 1097] train: loss: 0.0000174
[Epoch 67; Iter   708/ 1097] train: loss: 0.0007713
[Epoch 67; Iter   738/ 1097] train: loss: 0.0002003
[Epoch 67; Iter   768/ 1097] train: loss: 0.0017364
[Epoch 67; Iter   798/ 1097] train: loss: 0.0015412
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000379
[Epoch 67; Iter   858/ 1097] train: loss: 0.0000071
[Epoch 67; Iter   888/ 1097] train: loss: 0.0007137
[Epoch 67; Iter   918/ 1097] train: loss: 0.0011066
[Epoch 67; Iter   948/ 1097] train: loss: 0.0003916
[Epoch 67; Iter   978/ 1097] train: loss: 0.0001861
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000269
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0009870
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000040
[Epoch 67] ogbg-molhiv: 0.781299 val loss: 0.341165
[Epoch 67] ogbg-molhiv: 0.801223 test loss: 0.313650
[Epoch 68; Iter     1/ 1097] train: loss: 0.0000358
[Epoch 68; Iter    31/ 1097] train: loss: 0.0004369
[Epoch 68; Iter    61/ 1097] train: loss: 0.0000349
[Epoch 68; Iter    91/ 1097] train: loss: 0.0000709
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000200
[Epoch 68; Iter   151/ 1097] train: loss: 0.0002996
[Epoch 68; Iter   181/ 1097] train: loss: 0.0000845
[Epoch 68; Iter   211/ 1097] train: loss: 0.0000645
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002461
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000859
[Epoch 68; Iter   301/ 1097] train: loss: 0.0002069
[Epoch 68; Iter   331/ 1097] train: loss: 0.0003289
[Epoch 68; Iter   361/ 1097] train: loss: 0.0029025
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000178
[Epoch 68; Iter   421/ 1097] train: loss: 0.0044749
[Epoch 68; Iter   451/ 1097] train: loss: 0.0001889
[Epoch 68; Iter   481/ 1097] train: loss: 0.0001507
[Epoch 68; Iter   511/ 1097] train: loss: 0.0000593
[Epoch 68; Iter   541/ 1097] train: loss: 0.0003657
[Epoch 68; Iter   571/ 1097] train: loss: 0.0006542
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000873
[Epoch 68; Iter   631/ 1097] train: loss: 0.0008489
[Epoch 68; Iter   661/ 1097] train: loss: 0.0011224
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000257
[Epoch 68; Iter   721/ 1097] train: loss: 0.0000113
[Epoch 68; Iter   751/ 1097] train: loss: 0.0003009
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000528
[Epoch 68; Iter   811/ 1097] train: loss: 0.0000105
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000046
[Epoch 68; Iter   871/ 1097] train: loss: 0.0005250
[Epoch 68; Iter   901/ 1097] train: loss: 0.0000165
[Epoch 68; Iter   931/ 1097] train: loss: 0.0008402
[Epoch 68; Iter   961/ 1097] train: loss: 0.0017620
[Epoch 68; Iter   991/ 1097] train: loss: 0.0033113
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0000595
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003395
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0013392
[Epoch 68] ogbg-molhiv: 0.792447 val loss: 0.361897
[Epoch 68] ogbg-molhiv: 0.790923 test loss: 0.312593
[Epoch 69; Iter    14/ 1097] train: loss: 0.0004599
[Epoch 69; Iter    44/ 1097] train: loss: 0.0008460
[Epoch 69; Iter    74/ 1097] train: loss: 0.0027538
[Epoch 52; Iter   933/ 1097] train: loss: 0.0241091
[Epoch 52; Iter   963/ 1097] train: loss: 0.0484079
[Epoch 52; Iter   993/ 1097] train: loss: 0.0081010
[Epoch 52; Iter  1023/ 1097] train: loss: 0.1189663
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0366619
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0085936
[Epoch 52] ogbg-molhiv: 0.806287 val loss: 0.086436
[Epoch 52] ogbg-molhiv: 0.738261 test loss: 0.154983
[Epoch 53; Iter    16/ 1097] train: loss: 0.0240463
[Epoch 53; Iter    46/ 1097] train: loss: 0.0309928
[Epoch 53; Iter    76/ 1097] train: loss: 0.0066618
[Epoch 53; Iter   106/ 1097] train: loss: 0.0213130
[Epoch 53; Iter   136/ 1097] train: loss: 0.0216375
[Epoch 53; Iter   166/ 1097] train: loss: 0.0480142
[Epoch 53; Iter   196/ 1097] train: loss: 0.0131756
[Epoch 53; Iter   226/ 1097] train: loss: 0.1023088
[Epoch 53; Iter   256/ 1097] train: loss: 0.0090050
[Epoch 53; Iter   286/ 1097] train: loss: 0.0171148
[Epoch 53; Iter   316/ 1097] train: loss: 0.0289263
[Epoch 53; Iter   346/ 1097] train: loss: 0.1584013
[Epoch 53; Iter   376/ 1097] train: loss: 0.0938989
[Epoch 53; Iter   406/ 1097] train: loss: 0.0079180
[Epoch 53; Iter   436/ 1097] train: loss: 0.0189688
[Epoch 53; Iter   466/ 1097] train: loss: 0.0648226
[Epoch 53; Iter   496/ 1097] train: loss: 0.0920727
[Epoch 53; Iter   526/ 1097] train: loss: 0.0282406
[Epoch 53; Iter   556/ 1097] train: loss: 0.1851591
[Epoch 53; Iter   586/ 1097] train: loss: 0.0956128
[Epoch 53; Iter   616/ 1097] train: loss: 0.0139415
[Epoch 53; Iter   646/ 1097] train: loss: 0.2523533
[Epoch 53; Iter   676/ 1097] train: loss: 0.1120494
[Epoch 53; Iter   706/ 1097] train: loss: 0.0818857
[Epoch 53; Iter   736/ 1097] train: loss: 0.0285127
[Epoch 53; Iter   766/ 1097] train: loss: 0.0073663
[Epoch 53; Iter   796/ 1097] train: loss: 0.0168769
[Epoch 53; Iter   826/ 1097] train: loss: 0.0312876
[Epoch 53; Iter   856/ 1097] train: loss: 0.0697718
[Epoch 53; Iter   886/ 1097] train: loss: 0.0727590
[Epoch 53; Iter   916/ 1097] train: loss: 0.0576850
[Epoch 53; Iter   946/ 1097] train: loss: 0.0147041
[Epoch 53; Iter   976/ 1097] train: loss: 0.0267051
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0505628
[Epoch 53; Iter  1036/ 1097] train: loss: 0.1413947
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0140280
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0342137
[Epoch 53] ogbg-molhiv: 0.816643 val loss: 0.090886
[Epoch 53] ogbg-molhiv: 0.748354 test loss: 0.158366
[Epoch 54; Iter    29/ 1097] train: loss: 0.0076438
[Epoch 54; Iter    59/ 1097] train: loss: 0.0167474
[Epoch 54; Iter    89/ 1097] train: loss: 0.0145986
[Epoch 54; Iter   119/ 1097] train: loss: 0.0961953
[Epoch 54; Iter   149/ 1097] train: loss: 0.0498384
[Epoch 54; Iter   179/ 1097] train: loss: 0.0535181
[Epoch 54; Iter   209/ 1097] train: loss: 0.0264195
[Epoch 54; Iter   239/ 1097] train: loss: 0.0359331
[Epoch 54; Iter   269/ 1097] train: loss: 0.0092406
[Epoch 54; Iter   299/ 1097] train: loss: 0.1230084
[Epoch 54; Iter   329/ 1097] train: loss: 0.0120066
[Epoch 54; Iter   359/ 1097] train: loss: 0.0073060
[Epoch 54; Iter   389/ 1097] train: loss: 0.0740405
[Epoch 54; Iter   419/ 1097] train: loss: 0.0149973
[Epoch 54; Iter   449/ 1097] train: loss: 0.0633358
[Epoch 54; Iter   479/ 1097] train: loss: 0.0145950
[Epoch 54; Iter   509/ 1097] train: loss: 0.1367305
[Epoch 54; Iter   539/ 1097] train: loss: 0.0180959
[Epoch 54; Iter   569/ 1097] train: loss: 0.0155399
[Epoch 54; Iter   599/ 1097] train: loss: 0.0289089
[Epoch 54; Iter   629/ 1097] train: loss: 0.2551935
[Epoch 54; Iter   659/ 1097] train: loss: 0.0180168
[Epoch 54; Iter   689/ 1097] train: loss: 0.0309787
[Epoch 54; Iter   719/ 1097] train: loss: 0.1022983
[Epoch 54; Iter   749/ 1097] train: loss: 0.0204009
[Epoch 54; Iter   779/ 1097] train: loss: 0.0091593
[Epoch 54; Iter   809/ 1097] train: loss: 0.0714445
[Epoch 54; Iter   839/ 1097] train: loss: 0.2658492
[Epoch 54; Iter   869/ 1097] train: loss: 0.0112022
[Epoch 54; Iter   899/ 1097] train: loss: 0.0177689
[Epoch 54; Iter   929/ 1097] train: loss: 0.0169134
[Epoch 54; Iter   959/ 1097] train: loss: 0.0546590
[Epoch 54; Iter   989/ 1097] train: loss: 0.0211291
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0051528
[Epoch 54; Iter  1049/ 1097] train: loss: 0.1517468
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0200489
[Epoch 54] ogbg-molhiv: 0.783877 val loss: 0.098258
[Epoch 54] ogbg-molhiv: 0.723990 test loss: 0.173378
[Epoch 55; Iter    12/ 1097] train: loss: 0.0411192
[Epoch 55; Iter    42/ 1097] train: loss: 0.0319300
[Epoch 55; Iter    72/ 1097] train: loss: 0.0186271
[Epoch 55; Iter   102/ 1097] train: loss: 0.0455842
[Epoch 55; Iter   132/ 1097] train: loss: 0.2980496
[Epoch 55; Iter   162/ 1097] train: loss: 0.0718607
[Epoch 55; Iter   192/ 1097] train: loss: 0.0321738
[Epoch 55; Iter   222/ 1097] train: loss: 0.0180788
[Epoch 55; Iter   252/ 1097] train: loss: 0.0693004
[Epoch 55; Iter   282/ 1097] train: loss: 0.0940318
[Epoch 55; Iter   312/ 1097] train: loss: 0.1689150
[Epoch 55; Iter   342/ 1097] train: loss: 0.0212279
[Epoch 55; Iter   372/ 1097] train: loss: 0.0408316
[Epoch 55; Iter   402/ 1097] train: loss: 0.0093718
[Epoch 55; Iter   432/ 1097] train: loss: 0.0215589
[Epoch 55; Iter   462/ 1097] train: loss: 0.0102190
[Epoch 55; Iter   492/ 1097] train: loss: 0.0345533
[Epoch 55; Iter   522/ 1097] train: loss: 0.0275059
[Epoch 55; Iter   552/ 1097] train: loss: 0.0228982
[Epoch 55; Iter   582/ 1097] train: loss: 0.0994701
[Epoch 55; Iter   612/ 1097] train: loss: 0.0751897
[Epoch 55; Iter   642/ 1097] train: loss: 0.0072041
[Epoch 55; Iter   672/ 1097] train: loss: 0.0104602
[Epoch 55; Iter   702/ 1097] train: loss: 0.0226093
[Epoch 55; Iter   732/ 1097] train: loss: 0.0186805
[Epoch 55; Iter   762/ 1097] train: loss: 0.0066055
[Epoch 55; Iter   792/ 1097] train: loss: 0.0246917
[Epoch 55; Iter   822/ 1097] train: loss: 0.0263930
[Epoch 55; Iter   852/ 1097] train: loss: 0.0309669
[Epoch 55; Iter   882/ 1097] train: loss: 0.0837708
[Epoch 55; Iter   912/ 1097] train: loss: 0.0177210
[Epoch 55; Iter   942/ 1097] train: loss: 0.0105415
[Epoch 55; Iter   972/ 1097] train: loss: 0.0095976
[Epoch 55; Iter  1002/ 1097] train: loss: 0.1882827
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0160318
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0062180
[Epoch 55; Iter  1092/ 1097] train: loss: 0.2365794
[Epoch 55] ogbg-molhiv: 0.824238 val loss: 0.088206
[Epoch 55] ogbg-molhiv: 0.744433 test loss: 0.163670
[Epoch 56; Iter    25/ 1097] train: loss: 0.0184045
[Epoch 56; Iter    55/ 1097] train: loss: 0.0769450
[Epoch 56; Iter    85/ 1097] train: loss: 0.0143666
[Epoch 56; Iter   115/ 1097] train: loss: 0.0119001
[Epoch 56; Iter   145/ 1097] train: loss: 0.0950435
[Epoch 56; Iter   175/ 1097] train: loss: 0.1700828
[Epoch 56; Iter   205/ 1097] train: loss: 0.2389728
[Epoch 56; Iter   235/ 1097] train: loss: 0.0063513
[Epoch 56; Iter   265/ 1097] train: loss: 0.0371188
[Epoch 56; Iter   295/ 1097] train: loss: 0.1274285
[Epoch 56; Iter   325/ 1097] train: loss: 0.0206883
[Epoch 56; Iter   355/ 1097] train: loss: 0.0756028
[Epoch 56; Iter   385/ 1097] train: loss: 0.0810376
[Epoch 56; Iter   415/ 1097] train: loss: 0.0078111
[Epoch 56; Iter   445/ 1097] train: loss: 0.0748858
[Epoch 56; Iter   475/ 1097] train: loss: 0.0222721
[Epoch 56; Iter   505/ 1097] train: loss: 0.0249075
[Epoch 56; Iter   535/ 1097] train: loss: 0.0702224
[Epoch 56; Iter   565/ 1097] train: loss: 0.0088539
[Epoch 56; Iter   595/ 1097] train: loss: 0.0324088
[Epoch 56; Iter   625/ 1097] train: loss: 0.0160917
[Epoch 56; Iter   655/ 1097] train: loss: 0.0608853
[Epoch 56; Iter   685/ 1097] train: loss: 0.0168926
[Epoch 56; Iter   715/ 1097] train: loss: 0.0410502
[Epoch 56; Iter   745/ 1097] train: loss: 0.0144586
[Epoch 56; Iter   775/ 1097] train: loss: 0.1193405
[Epoch 56; Iter   805/ 1097] train: loss: 0.0244222
[Epoch 56; Iter   835/ 1097] train: loss: 0.0153377
[Epoch 56; Iter   865/ 1097] train: loss: 0.1654923
[Epoch 56; Iter   895/ 1097] train: loss: 0.1261779
[Epoch 56; Iter   925/ 1097] train: loss: 0.1044481
[Epoch 56; Iter   955/ 1097] train: loss: 0.0141115
[Epoch 56; Iter   985/ 1097] train: loss: 0.1309388
[Epoch 65; Iter    22/ 1097] train: loss: 0.0242794
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000044
[Epoch 65; Iter    82/ 1097] train: loss: 0.0000102
[Epoch 65; Iter   112/ 1097] train: loss: 0.0000128
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000682
[Epoch 65; Iter   172/ 1097] train: loss: 0.0000839
[Epoch 65; Iter   202/ 1097] train: loss: 0.0036529
[Epoch 65; Iter   232/ 1097] train: loss: 0.0094753
[Epoch 65; Iter   262/ 1097] train: loss: 0.0002396
[Epoch 65; Iter   292/ 1097] train: loss: 0.0016119
[Epoch 65; Iter   322/ 1097] train: loss: 0.0008116
[Epoch 65; Iter   352/ 1097] train: loss: 0.0000242
[Epoch 65; Iter   382/ 1097] train: loss: 0.0127334
[Epoch 65; Iter   412/ 1097] train: loss: 0.0047759
[Epoch 65; Iter   442/ 1097] train: loss: 0.0000119
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000912
[Epoch 65; Iter   502/ 1097] train: loss: 0.0001449
[Epoch 65; Iter   532/ 1097] train: loss: 0.0001090
[Epoch 65; Iter   562/ 1097] train: loss: 0.0000250
[Epoch 65; Iter   592/ 1097] train: loss: 0.0000056
[Epoch 65; Iter   622/ 1097] train: loss: 0.0000295
[Epoch 65; Iter   652/ 1097] train: loss: 0.0031707
[Epoch 65; Iter   682/ 1097] train: loss: 0.0015527
[Epoch 65; Iter   712/ 1097] train: loss: 0.0003347
[Epoch 65; Iter   742/ 1097] train: loss: 0.0002318
[Epoch 65; Iter   772/ 1097] train: loss: 0.0004500
[Epoch 65; Iter   802/ 1097] train: loss: 0.0001927
[Epoch 65; Iter   832/ 1097] train: loss: 0.0007582
[Epoch 65; Iter   862/ 1097] train: loss: 0.0000719
[Epoch 65; Iter   892/ 1097] train: loss: 0.0002829
[Epoch 65; Iter   922/ 1097] train: loss: 0.0017395
[Epoch 65; Iter   952/ 1097] train: loss: 0.0000232
[Epoch 65; Iter   982/ 1097] train: loss: 0.0002008
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0004128
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000068
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0001037
[Epoch 65] ogbg-molhiv: 0.715624 val loss: 1.041346
[Epoch 65] ogbg-molhiv: 0.637477 test loss: 2.445465
[Epoch 66; Iter     5/ 1097] train: loss: 0.0001029
[Epoch 66; Iter    35/ 1097] train: loss: 0.0044185
[Epoch 66; Iter    65/ 1097] train: loss: 0.0009901
[Epoch 66; Iter    95/ 1097] train: loss: 0.0000741
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003532
[Epoch 66; Iter   155/ 1097] train: loss: 0.0000027
[Epoch 66; Iter   185/ 1097] train: loss: 0.0000458
[Epoch 66; Iter   215/ 1097] train: loss: 0.0000731
[Epoch 66; Iter   245/ 1097] train: loss: 0.0000073
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000034
[Epoch 66; Iter   305/ 1097] train: loss: 0.0002494
[Epoch 66; Iter   335/ 1097] train: loss: 0.0009489
[Epoch 66; Iter   365/ 1097] train: loss: 0.0000344
[Epoch 66; Iter   395/ 1097] train: loss: 0.0000333
[Epoch 66; Iter   425/ 1097] train: loss: 0.0000579
[Epoch 66; Iter   455/ 1097] train: loss: 0.0000864
[Epoch 66; Iter   485/ 1097] train: loss: 0.0001072
[Epoch 66; Iter   515/ 1097] train: loss: 0.0002773
[Epoch 66; Iter   545/ 1097] train: loss: 0.0002428
[Epoch 66; Iter   575/ 1097] train: loss: 0.0001085
[Epoch 66; Iter   605/ 1097] train: loss: 0.0001385
[Epoch 66; Iter   635/ 1097] train: loss: 0.0000624
[Epoch 66; Iter   665/ 1097] train: loss: 0.0013366
[Epoch 66; Iter   695/ 1097] train: loss: 0.0006330
[Epoch 66; Iter   725/ 1097] train: loss: 0.0000026
[Epoch 66; Iter   755/ 1097] train: loss: 0.0000359
[Epoch 66; Iter   785/ 1097] train: loss: 0.0000739
[Epoch 66; Iter   815/ 1097] train: loss: 0.0005754
[Epoch 66; Iter   845/ 1097] train: loss: 0.0007215
[Epoch 66; Iter   875/ 1097] train: loss: 0.0012046
[Epoch 66; Iter   905/ 1097] train: loss: 0.0018030
[Epoch 66; Iter   935/ 1097] train: loss: 0.0001027
[Epoch 66; Iter   965/ 1097] train: loss: 0.0000660
[Epoch 66; Iter   995/ 1097] train: loss: 0.0019862
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0002087
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0420928
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0025653
[Epoch 66] ogbg-molhiv: 0.685164 val loss: 2.420372
[Epoch 66] ogbg-molhiv: 0.639251 test loss: 3.116060
[Epoch 67; Iter    18/ 1097] train: loss: 0.0025277
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000758
[Epoch 67; Iter    78/ 1097] train: loss: 0.0007005
[Epoch 67; Iter   108/ 1097] train: loss: 0.0004310
[Epoch 67; Iter   138/ 1097] train: loss: 0.0000889
[Epoch 67; Iter   168/ 1097] train: loss: 0.0002563
[Epoch 67; Iter   198/ 1097] train: loss: 0.0000248
[Epoch 67; Iter   228/ 1097] train: loss: 0.0011533
[Epoch 67; Iter   258/ 1097] train: loss: 0.0103562
[Epoch 67; Iter   288/ 1097] train: loss: 0.0001045
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001570
[Epoch 67; Iter   348/ 1097] train: loss: 0.0002022
[Epoch 67; Iter   378/ 1097] train: loss: 0.0007909
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000272
[Epoch 67; Iter   438/ 1097] train: loss: 0.0014721
[Epoch 67; Iter   468/ 1097] train: loss: 0.0001582
[Epoch 67; Iter   498/ 1097] train: loss: 0.0009604
[Epoch 67; Iter   528/ 1097] train: loss: 0.0001391
[Epoch 67; Iter   558/ 1097] train: loss: 0.0003726
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000348
[Epoch 67; Iter   618/ 1097] train: loss: 0.0019310
[Epoch 67; Iter   648/ 1097] train: loss: 0.0017797
[Epoch 67; Iter   678/ 1097] train: loss: 0.0003324
[Epoch 67; Iter   708/ 1097] train: loss: 0.0000180
[Epoch 67; Iter   738/ 1097] train: loss: 0.0001045
[Epoch 67; Iter   768/ 1097] train: loss: 0.0000286
[Epoch 67; Iter   798/ 1097] train: loss: 0.0001128
[Epoch 67; Iter   828/ 1097] train: loss: 0.0007221
[Epoch 67; Iter   858/ 1097] train: loss: 0.0004961
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000148
[Epoch 67; Iter   918/ 1097] train: loss: 0.0000201
[Epoch 67; Iter   948/ 1097] train: loss: 0.0001205
[Epoch 67; Iter   978/ 1097] train: loss: 0.0007512
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000247
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000063
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0001089
[Epoch 67] ogbg-molhiv: 0.712730 val loss: 1.873888
[Epoch 67] ogbg-molhiv: 0.654468 test loss: 3.000572
[Epoch 68; Iter     1/ 1097] train: loss: 0.0029783
[Epoch 68; Iter    31/ 1097] train: loss: 0.0003562
[Epoch 68; Iter    61/ 1097] train: loss: 0.0974564
[Epoch 68; Iter    91/ 1097] train: loss: 0.0007104
[Epoch 68; Iter   121/ 1097] train: loss: 0.0003119
[Epoch 68; Iter   151/ 1097] train: loss: 0.0000589
[Epoch 68; Iter   181/ 1097] train: loss: 0.0003160
[Epoch 68; Iter   211/ 1097] train: loss: 0.0001238
[Epoch 68; Iter   241/ 1097] train: loss: 0.0000563
[Epoch 68; Iter   271/ 1097] train: loss: 0.0000369
[Epoch 68; Iter   301/ 1097] train: loss: 0.0001030
[Epoch 68; Iter   331/ 1097] train: loss: 0.0005874
[Epoch 68; Iter   361/ 1097] train: loss: 0.0011497
[Epoch 68; Iter   391/ 1097] train: loss: 0.0005048
[Epoch 68; Iter   421/ 1097] train: loss: 0.0006108
[Epoch 68; Iter   451/ 1097] train: loss: 0.0280367
[Epoch 68; Iter   481/ 1097] train: loss: 0.0006634
[Epoch 68; Iter   511/ 1097] train: loss: 0.0332464
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000113
[Epoch 68; Iter   571/ 1097] train: loss: 0.0001626
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000977
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002609
[Epoch 68; Iter   661/ 1097] train: loss: 0.0314867
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000308
[Epoch 68; Iter   721/ 1097] train: loss: 0.0002370
[Epoch 68; Iter   751/ 1097] train: loss: 0.0000516
[Epoch 68; Iter   781/ 1097] train: loss: 0.0000093
[Epoch 68; Iter   811/ 1097] train: loss: 0.0000025
[Epoch 68; Iter   841/ 1097] train: loss: 0.0055586
[Epoch 68; Iter   871/ 1097] train: loss: 0.0006074
[Epoch 68; Iter   901/ 1097] train: loss: 0.0000028
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000193
[Epoch 68; Iter   961/ 1097] train: loss: 0.0000115
[Epoch 68; Iter   991/ 1097] train: loss: 0.0029077
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0001289
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0000536
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0000919
[Epoch 68] ogbg-molhiv: 0.701560 val loss: 3.156001
[Epoch 68] ogbg-molhiv: 0.621771 test loss: 4.655309
[Epoch 69; Iter    14/ 1097] train: loss: 0.0099523
[Epoch 69; Iter    44/ 1097] train: loss: 0.0003425
[Epoch 69; Iter    74/ 1097] train: loss: 0.0000843
[Epoch 52; Iter   933/ 1097] train: loss: 0.0308502
[Epoch 52; Iter   963/ 1097] train: loss: 0.0253218
[Epoch 52; Iter   993/ 1097] train: loss: 0.0452143
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0531532
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0217514
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0917241
[Epoch 52] ogbg-molhiv: 0.798219 val loss: 0.085530
[Epoch 52] ogbg-molhiv: 0.737919 test loss: 0.159322
[Epoch 53; Iter    16/ 1097] train: loss: 0.0370972
[Epoch 53; Iter    46/ 1097] train: loss: 0.0198459
[Epoch 53; Iter    76/ 1097] train: loss: 0.0293908
[Epoch 53; Iter   106/ 1097] train: loss: 0.1309510
[Epoch 53; Iter   136/ 1097] train: loss: 0.0431872
[Epoch 53; Iter   166/ 1097] train: loss: 0.1474756
[Epoch 53; Iter   196/ 1097] train: loss: 0.0148932
[Epoch 53; Iter   226/ 1097] train: loss: 0.0810441
[Epoch 53; Iter   256/ 1097] train: loss: 0.0216553
[Epoch 53; Iter   286/ 1097] train: loss: 0.1393756
[Epoch 53; Iter   316/ 1097] train: loss: 0.0296286
[Epoch 53; Iter   346/ 1097] train: loss: 0.0232727
[Epoch 53; Iter   376/ 1097] train: loss: 0.0473384
[Epoch 53; Iter   406/ 1097] train: loss: 0.0160799
[Epoch 53; Iter   436/ 1097] train: loss: 0.0213770
[Epoch 53; Iter   466/ 1097] train: loss: 0.1608611
[Epoch 53; Iter   496/ 1097] train: loss: 0.0851922
[Epoch 53; Iter   526/ 1097] train: loss: 0.0637064
[Epoch 53; Iter   556/ 1097] train: loss: 0.0640809
[Epoch 53; Iter   586/ 1097] train: loss: 0.0430149
[Epoch 53; Iter   616/ 1097] train: loss: 0.0460576
[Epoch 53; Iter   646/ 1097] train: loss: 0.0125565
[Epoch 53; Iter   676/ 1097] train: loss: 0.3767759
[Epoch 53; Iter   706/ 1097] train: loss: 0.0414486
[Epoch 53; Iter   736/ 1097] train: loss: 0.1565778
[Epoch 53; Iter   766/ 1097] train: loss: 0.0561553
[Epoch 53; Iter   796/ 1097] train: loss: 0.0682743
[Epoch 53; Iter   826/ 1097] train: loss: 0.0253832
[Epoch 53; Iter   856/ 1097] train: loss: 0.0125790
[Epoch 53; Iter   886/ 1097] train: loss: 0.0115166
[Epoch 53; Iter   916/ 1097] train: loss: 0.0104478
[Epoch 53; Iter   946/ 1097] train: loss: 0.1768703
[Epoch 53; Iter   976/ 1097] train: loss: 0.0101848
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0215216
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0825492
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0239215
[Epoch 53; Iter  1096/ 1097] train: loss: 0.1416265
[Epoch 53] ogbg-molhiv: 0.791354 val loss: 0.096062
[Epoch 53] ogbg-molhiv: 0.760451 test loss: 0.151118
[Epoch 54; Iter    29/ 1097] train: loss: 0.0107247
[Epoch 54; Iter    59/ 1097] train: loss: 0.0092104
[Epoch 54; Iter    89/ 1097] train: loss: 0.0132687
[Epoch 54; Iter   119/ 1097] train: loss: 0.0509183
[Epoch 54; Iter   149/ 1097] train: loss: 0.0470154
[Epoch 54; Iter   179/ 1097] train: loss: 0.0182131
[Epoch 54; Iter   209/ 1097] train: loss: 0.0336821
[Epoch 54; Iter   239/ 1097] train: loss: 0.0475748
[Epoch 54; Iter   269/ 1097] train: loss: 0.0467931
[Epoch 54; Iter   299/ 1097] train: loss: 0.0768314
[Epoch 54; Iter   329/ 1097] train: loss: 0.1636388
[Epoch 54; Iter   359/ 1097] train: loss: 0.1074439
[Epoch 54; Iter   389/ 1097] train: loss: 0.1399838
[Epoch 54; Iter   419/ 1097] train: loss: 0.0095641
[Epoch 54; Iter   449/ 1097] train: loss: 0.1308812
[Epoch 54; Iter   479/ 1097] train: loss: 0.0206449
[Epoch 54; Iter   509/ 1097] train: loss: 0.0727294
[Epoch 54; Iter   539/ 1097] train: loss: 0.2201972
[Epoch 54; Iter   569/ 1097] train: loss: 0.0163401
[Epoch 54; Iter   599/ 1097] train: loss: 0.0414997
[Epoch 54; Iter   629/ 1097] train: loss: 0.0926754
[Epoch 54; Iter   659/ 1097] train: loss: 0.1502642
[Epoch 54; Iter   689/ 1097] train: loss: 0.0308825
[Epoch 54; Iter   719/ 1097] train: loss: 0.0161719
[Epoch 54; Iter   749/ 1097] train: loss: 0.0248728
[Epoch 54; Iter   779/ 1097] train: loss: 0.0209707
[Epoch 54; Iter   809/ 1097] train: loss: 0.0324352
[Epoch 54; Iter   839/ 1097] train: loss: 0.0132133
[Epoch 54; Iter   869/ 1097] train: loss: 0.0089051
[Epoch 54; Iter   899/ 1097] train: loss: 0.0150167
[Epoch 54; Iter   929/ 1097] train: loss: 0.0125872
[Epoch 54; Iter   959/ 1097] train: loss: 0.0254031
[Epoch 54; Iter   989/ 1097] train: loss: 0.0653951
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0216114
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0375945
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0096080
[Epoch 54] ogbg-molhiv: 0.808856 val loss: 0.103476
[Epoch 54] ogbg-molhiv: 0.747552 test loss: 0.159384
[Epoch 55; Iter    12/ 1097] train: loss: 0.0372129
[Epoch 55; Iter    42/ 1097] train: loss: 0.0389141
[Epoch 55; Iter    72/ 1097] train: loss: 0.0323691
[Epoch 55; Iter   102/ 1097] train: loss: 0.0104499
[Epoch 55; Iter   132/ 1097] train: loss: 0.0143972
[Epoch 55; Iter   162/ 1097] train: loss: 0.1633876
[Epoch 55; Iter   192/ 1097] train: loss: 0.0751664
[Epoch 55; Iter   222/ 1097] train: loss: 0.0117802
[Epoch 55; Iter   252/ 1097] train: loss: 0.0324246
[Epoch 55; Iter   282/ 1097] train: loss: 0.0219104
[Epoch 55; Iter   312/ 1097] train: loss: 0.0117126
[Epoch 55; Iter   342/ 1097] train: loss: 0.0126762
[Epoch 55; Iter   372/ 1097] train: loss: 0.0515536
[Epoch 55; Iter   402/ 1097] train: loss: 0.0337629
[Epoch 55; Iter   432/ 1097] train: loss: 0.0137485
[Epoch 55; Iter   462/ 1097] train: loss: 0.0234808
[Epoch 55; Iter   492/ 1097] train: loss: 0.0485286
[Epoch 55; Iter   522/ 1097] train: loss: 0.0211016
[Epoch 55; Iter   552/ 1097] train: loss: 0.0135990
[Epoch 55; Iter   582/ 1097] train: loss: 0.1034436
[Epoch 55; Iter   612/ 1097] train: loss: 0.0154565
[Epoch 55; Iter   642/ 1097] train: loss: 0.0171118
[Epoch 55; Iter   672/ 1097] train: loss: 0.1748164
[Epoch 55; Iter   702/ 1097] train: loss: 0.0747035
[Epoch 55; Iter   732/ 1097] train: loss: 0.0629763
[Epoch 55; Iter   762/ 1097] train: loss: 0.0633990
[Epoch 55; Iter   792/ 1097] train: loss: 0.0419127
[Epoch 55; Iter   822/ 1097] train: loss: 0.2365793
[Epoch 55; Iter   852/ 1097] train: loss: 0.0373694
[Epoch 55; Iter   882/ 1097] train: loss: 0.0148951
[Epoch 55; Iter   912/ 1097] train: loss: 0.0317385
[Epoch 55; Iter   942/ 1097] train: loss: 0.1646902
[Epoch 55; Iter   972/ 1097] train: loss: 0.0497468
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0440441
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0220618
[Epoch 55; Iter  1062/ 1097] train: loss: 0.1881066
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0114801
[Epoch 55] ogbg-molhiv: 0.805801 val loss: 0.086251
[Epoch 55] ogbg-molhiv: 0.744935 test loss: 0.159645
[Epoch 56; Iter    25/ 1097] train: loss: 0.0363807
[Epoch 56; Iter    55/ 1097] train: loss: 0.0620901
[Epoch 56; Iter    85/ 1097] train: loss: 0.0081633
[Epoch 56; Iter   115/ 1097] train: loss: 0.0351241
[Epoch 56; Iter   145/ 1097] train: loss: 0.0248463
[Epoch 56; Iter   175/ 1097] train: loss: 0.0658558
[Epoch 56; Iter   205/ 1097] train: loss: 0.1000359
[Epoch 56; Iter   235/ 1097] train: loss: 0.0821142
[Epoch 56; Iter   265/ 1097] train: loss: 0.0909628
[Epoch 56; Iter   295/ 1097] train: loss: 0.0637256
[Epoch 56; Iter   325/ 1097] train: loss: 0.0072261
[Epoch 56; Iter   355/ 1097] train: loss: 0.0723847
[Epoch 56; Iter   385/ 1097] train: loss: 0.0176396
[Epoch 56; Iter   415/ 1097] train: loss: 0.1362949
[Epoch 56; Iter   445/ 1097] train: loss: 0.0129445
[Epoch 56; Iter   475/ 1097] train: loss: 0.0065587
[Epoch 56; Iter   505/ 1097] train: loss: 0.0113020
[Epoch 56; Iter   535/ 1097] train: loss: 0.0093890
[Epoch 56; Iter   565/ 1097] train: loss: 0.1554945
[Epoch 56; Iter   595/ 1097] train: loss: 0.2742061
[Epoch 56; Iter   625/ 1097] train: loss: 0.0195357
[Epoch 56; Iter   655/ 1097] train: loss: 0.0707350
[Epoch 56; Iter   685/ 1097] train: loss: 0.2220442
[Epoch 56; Iter   715/ 1097] train: loss: 0.1617081
[Epoch 56; Iter   745/ 1097] train: loss: 0.0091177
[Epoch 56; Iter   775/ 1097] train: loss: 0.0182936
[Epoch 56; Iter   805/ 1097] train: loss: 0.0249070
[Epoch 56; Iter   835/ 1097] train: loss: 0.0229659
[Epoch 56; Iter   865/ 1097] train: loss: 0.0860869
[Epoch 56; Iter   895/ 1097] train: loss: 0.0784028
[Epoch 56; Iter   925/ 1097] train: loss: 0.1348729
[Epoch 56; Iter   955/ 1097] train: loss: 0.1170660
[Epoch 56; Iter   985/ 1097] train: loss: 0.0242353
[Epoch 52; Iter   933/ 1097] train: loss: 0.0107410
[Epoch 52; Iter   963/ 1097] train: loss: 0.0091081
[Epoch 52; Iter   993/ 1097] train: loss: 0.0072174
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0080198
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0126776
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0111665
[Epoch 52] ogbg-molhiv: 0.820323 val loss: 0.080238
[Epoch 52] ogbg-molhiv: 0.756556 test loss: 0.199091
[Epoch 53; Iter    16/ 1097] train: loss: 0.0105201
[Epoch 53; Iter    46/ 1097] train: loss: 0.0247120
[Epoch 53; Iter    76/ 1097] train: loss: 0.0290438
[Epoch 53; Iter   106/ 1097] train: loss: 0.0088015
[Epoch 53; Iter   136/ 1097] train: loss: 0.0144005
[Epoch 53; Iter   166/ 1097] train: loss: 0.2586915
[Epoch 53; Iter   196/ 1097] train: loss: 0.0093355
[Epoch 53; Iter   226/ 1097] train: loss: 0.0130063
[Epoch 53; Iter   256/ 1097] train: loss: 0.0149703
[Epoch 53; Iter   286/ 1097] train: loss: 0.3156807
[Epoch 53; Iter   316/ 1097] train: loss: 0.0212960
[Epoch 53; Iter   346/ 1097] train: loss: 0.1467578
[Epoch 53; Iter   376/ 1097] train: loss: 0.0117087
[Epoch 53; Iter   406/ 1097] train: loss: 0.0185728
[Epoch 53; Iter   436/ 1097] train: loss: 0.2961732
[Epoch 53; Iter   466/ 1097] train: loss: 0.1222187
[Epoch 53; Iter   496/ 1097] train: loss: 0.0138922
[Epoch 53; Iter   526/ 1097] train: loss: 0.1487768
[Epoch 53; Iter   556/ 1097] train: loss: 0.0374351
[Epoch 53; Iter   586/ 1097] train: loss: 0.0699288
[Epoch 53; Iter   616/ 1097] train: loss: 0.0763287
[Epoch 53; Iter   646/ 1097] train: loss: 0.0442474
[Epoch 53; Iter   676/ 1097] train: loss: 0.0193535
[Epoch 53; Iter   706/ 1097] train: loss: 0.0492158
[Epoch 53; Iter   736/ 1097] train: loss: 0.0536574
[Epoch 53; Iter   766/ 1097] train: loss: 0.0259385
[Epoch 53; Iter   796/ 1097] train: loss: 0.0747073
[Epoch 53; Iter   826/ 1097] train: loss: 0.1499404
[Epoch 53; Iter   856/ 1097] train: loss: 0.1342247
[Epoch 53; Iter   886/ 1097] train: loss: 0.0284953
[Epoch 53; Iter   916/ 1097] train: loss: 0.0202363
[Epoch 53; Iter   946/ 1097] train: loss: 0.0084194
[Epoch 53; Iter   976/ 1097] train: loss: 0.0416056
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0330081
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0050965
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0947565
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0110587
[Epoch 53] ogbg-molhiv: 0.802570 val loss: 0.092213
[Epoch 53] ogbg-molhiv: 0.760104 test loss: 0.226051
[Epoch 54; Iter    29/ 1097] train: loss: 0.0122027
[Epoch 54; Iter    59/ 1097] train: loss: 0.0565385
[Epoch 54; Iter    89/ 1097] train: loss: 0.0252990
[Epoch 54; Iter   119/ 1097] train: loss: 0.0101471
[Epoch 54; Iter   149/ 1097] train: loss: 0.1154791
[Epoch 54; Iter   179/ 1097] train: loss: 0.0051400
[Epoch 54; Iter   209/ 1097] train: loss: 0.0822733
[Epoch 54; Iter   239/ 1097] train: loss: 0.1566104
[Epoch 54; Iter   269/ 1097] train: loss: 0.1494794
[Epoch 54; Iter   299/ 1097] train: loss: 0.0125741
[Epoch 54; Iter   329/ 1097] train: loss: 0.0262077
[Epoch 54; Iter   359/ 1097] train: loss: 0.0220534
[Epoch 54; Iter   389/ 1097] train: loss: 0.0286279
[Epoch 54; Iter   419/ 1097] train: loss: 0.0161572
[Epoch 54; Iter   449/ 1097] train: loss: 0.0106459
[Epoch 54; Iter   479/ 1097] train: loss: 0.0088044
[Epoch 54; Iter   509/ 1097] train: loss: 0.0143211
[Epoch 54; Iter   539/ 1097] train: loss: 0.1599574
[Epoch 54; Iter   569/ 1097] train: loss: 0.0270380
[Epoch 54; Iter   599/ 1097] train: loss: 0.0196827
[Epoch 54; Iter   629/ 1097] train: loss: 0.0052391
[Epoch 54; Iter   659/ 1097] train: loss: 0.0971849
[Epoch 54; Iter   689/ 1097] train: loss: 0.0066707
[Epoch 54; Iter   719/ 1097] train: loss: 0.0155738
[Epoch 54; Iter   749/ 1097] train: loss: 0.0841458
[Epoch 54; Iter   779/ 1097] train: loss: 0.0624811
[Epoch 54; Iter   809/ 1097] train: loss: 0.2452298
[Epoch 54; Iter   839/ 1097] train: loss: 0.0592775
[Epoch 54; Iter   869/ 1097] train: loss: 0.0559854
[Epoch 54; Iter   899/ 1097] train: loss: 0.0169028
[Epoch 54; Iter   929/ 1097] train: loss: 0.0686202
[Epoch 54; Iter   959/ 1097] train: loss: 0.0172033
[Epoch 54; Iter   989/ 1097] train: loss: 0.1931911
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0689687
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0075797
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0197364
[Epoch 54] ogbg-molhiv: 0.804631 val loss: 0.093317
[Epoch 54] ogbg-molhiv: 0.744982 test loss: 0.190306
[Epoch 55; Iter    12/ 1097] train: loss: 0.0250995
[Epoch 55; Iter    42/ 1097] train: loss: 0.0767801
[Epoch 55; Iter    72/ 1097] train: loss: 0.0116885
[Epoch 55; Iter   102/ 1097] train: loss: 0.0206588
[Epoch 55; Iter   132/ 1097] train: loss: 0.3039365
[Epoch 55; Iter   162/ 1097] train: loss: 0.0092677
[Epoch 55; Iter   192/ 1097] train: loss: 0.0178467
[Epoch 55; Iter   222/ 1097] train: loss: 0.0525942
[Epoch 55; Iter   252/ 1097] train: loss: 0.0236547
[Epoch 55; Iter   282/ 1097] train: loss: 0.0197933
[Epoch 55; Iter   312/ 1097] train: loss: 0.0899530
[Epoch 55; Iter   342/ 1097] train: loss: 0.0185423
[Epoch 55; Iter   372/ 1097] train: loss: 0.0625047
[Epoch 55; Iter   402/ 1097] train: loss: 0.0946531
[Epoch 55; Iter   432/ 1097] train: loss: 0.0077021
[Epoch 55; Iter   462/ 1097] train: loss: 0.0206475
[Epoch 55; Iter   492/ 1097] train: loss: 0.0120298
[Epoch 55; Iter   522/ 1097] train: loss: 0.0934648
[Epoch 55; Iter   552/ 1097] train: loss: 0.0086872
[Epoch 55; Iter   582/ 1097] train: loss: 0.0696067
[Epoch 55; Iter   612/ 1097] train: loss: 0.0378997
[Epoch 55; Iter   642/ 1097] train: loss: 0.0078725
[Epoch 55; Iter   672/ 1097] train: loss: 0.0321634
[Epoch 55; Iter   702/ 1097] train: loss: 0.0193946
[Epoch 55; Iter   732/ 1097] train: loss: 0.0774340
[Epoch 55; Iter   762/ 1097] train: loss: 0.0348143
[Epoch 55; Iter   792/ 1097] train: loss: 0.1303917
[Epoch 55; Iter   822/ 1097] train: loss: 0.0686496
[Epoch 55; Iter   852/ 1097] train: loss: 0.0135020
[Epoch 55; Iter   882/ 1097] train: loss: 0.1377510
[Epoch 55; Iter   912/ 1097] train: loss: 0.0058270
[Epoch 55; Iter   942/ 1097] train: loss: 0.0116281
[Epoch 55; Iter   972/ 1097] train: loss: 0.0424422
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0062469
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0122183
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0585714
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0867155
[Epoch 55] ogbg-molhiv: 0.793237 val loss: 0.094767
[Epoch 55] ogbg-molhiv: 0.750424 test loss: 0.189764
[Epoch 56; Iter    25/ 1097] train: loss: 0.0125890
[Epoch 56; Iter    55/ 1097] train: loss: 0.0148540
[Epoch 56; Iter    85/ 1097] train: loss: 0.0862815
[Epoch 56; Iter   115/ 1097] train: loss: 0.0109276
[Epoch 56; Iter   145/ 1097] train: loss: 0.0144797
[Epoch 56; Iter   175/ 1097] train: loss: 0.0053068
[Epoch 56; Iter   205/ 1097] train: loss: 0.0101972
[Epoch 56; Iter   235/ 1097] train: loss: 0.0066899
[Epoch 56; Iter   265/ 1097] train: loss: 0.0125745
[Epoch 56; Iter   295/ 1097] train: loss: 0.0058806
[Epoch 56; Iter   325/ 1097] train: loss: 0.0111717
[Epoch 56; Iter   355/ 1097] train: loss: 0.0283057
[Epoch 56; Iter   385/ 1097] train: loss: 0.0367908
[Epoch 56; Iter   415/ 1097] train: loss: 0.0166217
[Epoch 56; Iter   445/ 1097] train: loss: 0.0806011
[Epoch 56; Iter   475/ 1097] train: loss: 0.0102025
[Epoch 56; Iter   505/ 1097] train: loss: 0.1472638
[Epoch 56; Iter   535/ 1097] train: loss: 0.0131782
[Epoch 56; Iter   565/ 1097] train: loss: 0.1577095
[Epoch 56; Iter   595/ 1097] train: loss: 0.1051658
[Epoch 56; Iter   625/ 1097] train: loss: 0.0227928
[Epoch 56; Iter   655/ 1097] train: loss: 0.0139231
[Epoch 56; Iter   685/ 1097] train: loss: 0.0152692
[Epoch 56; Iter   715/ 1097] train: loss: 0.0046772
[Epoch 56; Iter   745/ 1097] train: loss: 0.0622112
[Epoch 56; Iter   775/ 1097] train: loss: 0.1772674
[Epoch 56; Iter   805/ 1097] train: loss: 0.0411629
[Epoch 56; Iter   835/ 1097] train: loss: 0.0279873
[Epoch 56; Iter   865/ 1097] train: loss: 0.1333609
[Epoch 56; Iter   895/ 1097] train: loss: 0.0432230
[Epoch 56; Iter   925/ 1097] train: loss: 0.0047061
[Epoch 56; Iter   955/ 1097] train: loss: 0.0365206
[Epoch 56; Iter   985/ 1097] train: loss: 0.0061180
[Epoch 65; Iter    22/ 1097] train: loss: 0.0112965
[Epoch 65; Iter    52/ 1097] train: loss: 0.0000336
[Epoch 65; Iter    82/ 1097] train: loss: 0.0002147
[Epoch 65; Iter   112/ 1097] train: loss: 0.0007204
[Epoch 65; Iter   142/ 1097] train: loss: 0.0161064
[Epoch 65; Iter   172/ 1097] train: loss: 0.0484706
[Epoch 65; Iter   202/ 1097] train: loss: 0.0008593
[Epoch 65; Iter   232/ 1097] train: loss: 0.0010263
[Epoch 65; Iter   262/ 1097] train: loss: 0.0040614
[Epoch 65; Iter   292/ 1097] train: loss: 0.0000384
[Epoch 65; Iter   322/ 1097] train: loss: 0.0017669
[Epoch 65; Iter   352/ 1097] train: loss: 0.0073320
[Epoch 65; Iter   382/ 1097] train: loss: 0.0020137
[Epoch 65; Iter   412/ 1097] train: loss: 0.0011137
[Epoch 65; Iter   442/ 1097] train: loss: 0.0005372
[Epoch 65; Iter   472/ 1097] train: loss: 0.0004052
[Epoch 65; Iter   502/ 1097] train: loss: 0.0105671
[Epoch 65; Iter   532/ 1097] train: loss: 0.0000115
[Epoch 65; Iter   562/ 1097] train: loss: 0.0005762
[Epoch 65; Iter   592/ 1097] train: loss: 0.0002875
[Epoch 65; Iter   622/ 1097] train: loss: 0.0049650
[Epoch 65; Iter   652/ 1097] train: loss: 0.0016585
[Epoch 65; Iter   682/ 1097] train: loss: 0.0013297
[Epoch 65; Iter   712/ 1097] train: loss: 0.0005276
[Epoch 65; Iter   742/ 1097] train: loss: 0.0001314
[Epoch 65; Iter   772/ 1097] train: loss: 0.0004642
[Epoch 65; Iter   802/ 1097] train: loss: 0.0000315
[Epoch 65; Iter   832/ 1097] train: loss: 0.0000757
[Epoch 65; Iter   862/ 1097] train: loss: 0.0001704
[Epoch 65; Iter   892/ 1097] train: loss: 0.0029428
[Epoch 65; Iter   922/ 1097] train: loss: 0.0007188
[Epoch 65; Iter   952/ 1097] train: loss: 0.0001473
[Epoch 65; Iter   982/ 1097] train: loss: 0.0244644
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0039430
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000147
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0093797
[Epoch 65] ogbg-molhiv: 0.775230 val loss: 3.883363
[Epoch 65] ogbg-molhiv: 0.736420 test loss: 7.703512
[Epoch 66; Iter     5/ 1097] train: loss: 0.0000565
[Epoch 66; Iter    35/ 1097] train: loss: 0.0002927
[Epoch 66; Iter    65/ 1097] train: loss: 0.0001299
[Epoch 66; Iter    95/ 1097] train: loss: 0.0002723
[Epoch 66; Iter   125/ 1097] train: loss: 0.0000390
[Epoch 66; Iter   155/ 1097] train: loss: 0.0020063
[Epoch 66; Iter   185/ 1097] train: loss: 0.0006966
[Epoch 66; Iter   215/ 1097] train: loss: 0.0014056
[Epoch 66; Iter   245/ 1097] train: loss: 0.0051437
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000445
[Epoch 66; Iter   305/ 1097] train: loss: 0.0294834
[Epoch 66; Iter   335/ 1097] train: loss: 0.0059670
[Epoch 66; Iter   365/ 1097] train: loss: 0.0033834
[Epoch 66; Iter   395/ 1097] train: loss: 0.0002331
[Epoch 66; Iter   425/ 1097] train: loss: 0.0002989
[Epoch 66; Iter   455/ 1097] train: loss: 0.0012200
[Epoch 66; Iter   485/ 1097] train: loss: 0.0001044
[Epoch 66; Iter   515/ 1097] train: loss: 0.0006096
[Epoch 66; Iter   545/ 1097] train: loss: 0.0000751
[Epoch 66; Iter   575/ 1097] train: loss: 0.0002540
[Epoch 66; Iter   605/ 1097] train: loss: 0.0025412
[Epoch 66; Iter   635/ 1097] train: loss: 0.0013113
[Epoch 66; Iter   665/ 1097] train: loss: 0.0002186
[Epoch 66; Iter   695/ 1097] train: loss: 0.0001750
[Epoch 66; Iter   725/ 1097] train: loss: 0.0019992
[Epoch 66; Iter   755/ 1097] train: loss: 0.0091990
[Epoch 66; Iter   785/ 1097] train: loss: 0.0002497
[Epoch 66; Iter   815/ 1097] train: loss: 0.0012449
[Epoch 66; Iter   845/ 1097] train: loss: 0.0018417
[Epoch 66; Iter   875/ 1097] train: loss: 0.0000097
[Epoch 66; Iter   905/ 1097] train: loss: 0.0027277
[Epoch 66; Iter   935/ 1097] train: loss: 0.0000516
[Epoch 66; Iter   965/ 1097] train: loss: 0.0080984
[Epoch 66; Iter   995/ 1097] train: loss: 0.0000171
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0024577
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0034395
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0000087
[Epoch 66] ogbg-molhiv: 0.764832 val loss: 5.653968
[Epoch 66] ogbg-molhiv: 0.700848 test loss: 4.891059
[Epoch 67; Iter    18/ 1097] train: loss: 0.0162472
[Epoch 67; Iter    48/ 1097] train: loss: 0.0000897
[Epoch 67; Iter    78/ 1097] train: loss: 0.0024890
[Epoch 67; Iter   108/ 1097] train: loss: 0.0003586
[Epoch 67; Iter   138/ 1097] train: loss: 0.0002012
[Epoch 67; Iter   168/ 1097] train: loss: 0.0000275
[Epoch 67; Iter   198/ 1097] train: loss: 0.0002079
[Epoch 67; Iter   228/ 1097] train: loss: 0.0006653
[Epoch 67; Iter   258/ 1097] train: loss: 0.0002392
[Epoch 67; Iter   288/ 1097] train: loss: 0.0024040
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001717
[Epoch 67; Iter   348/ 1097] train: loss: 0.0000900
[Epoch 67; Iter   378/ 1097] train: loss: 0.0000667
[Epoch 67; Iter   408/ 1097] train: loss: 0.0000219
[Epoch 67; Iter   438/ 1097] train: loss: 0.0018757
[Epoch 67; Iter   468/ 1097] train: loss: 0.0349594
[Epoch 67; Iter   498/ 1097] train: loss: 0.0000737
[Epoch 67; Iter   528/ 1097] train: loss: 0.0005050
[Epoch 67; Iter   558/ 1097] train: loss: 0.1065334
[Epoch 67; Iter   588/ 1097] train: loss: 0.0000098
[Epoch 67; Iter   618/ 1097] train: loss: 0.0000265
[Epoch 67; Iter   648/ 1097] train: loss: 0.0010273
[Epoch 67; Iter   678/ 1097] train: loss: 0.0006216
[Epoch 67; Iter   708/ 1097] train: loss: 0.0047170
[Epoch 67; Iter   738/ 1097] train: loss: 0.0001779
[Epoch 67; Iter   768/ 1097] train: loss: 0.0001832
[Epoch 67; Iter   798/ 1097] train: loss: 0.0008556
[Epoch 67; Iter   828/ 1097] train: loss: 0.0000085
[Epoch 67; Iter   858/ 1097] train: loss: 0.0001339
[Epoch 67; Iter   888/ 1097] train: loss: 0.0001474
[Epoch 67; Iter   918/ 1097] train: loss: 0.0001374
[Epoch 67; Iter   948/ 1097] train: loss: 0.0083964
[Epoch 67; Iter   978/ 1097] train: loss: 0.0002896
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0004420
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0003120
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0000244
[Epoch 67] ogbg-molhiv: 0.737881 val loss: 3.363085
[Epoch 67] ogbg-molhiv: 0.725165 test loss: 4.598067
[Epoch 68; Iter     1/ 1097] train: loss: 0.0006357
[Epoch 68; Iter    31/ 1097] train: loss: 0.0000956
[Epoch 68; Iter    61/ 1097] train: loss: 0.0009101
[Epoch 68; Iter    91/ 1097] train: loss: 0.0003910
[Epoch 68; Iter   121/ 1097] train: loss: 0.0003103
[Epoch 68; Iter   151/ 1097] train: loss: 0.0001010
[Epoch 68; Iter   181/ 1097] train: loss: 0.0025338
[Epoch 68; Iter   211/ 1097] train: loss: 0.0002285
[Epoch 68; Iter   241/ 1097] train: loss: 0.0002718
[Epoch 68; Iter   271/ 1097] train: loss: 0.0001642
[Epoch 68; Iter   301/ 1097] train: loss: 0.0014551
[Epoch 68; Iter   331/ 1097] train: loss: 0.0000144
[Epoch 68; Iter   361/ 1097] train: loss: 0.0000913
[Epoch 68; Iter   391/ 1097] train: loss: 0.0000578
[Epoch 68; Iter   421/ 1097] train: loss: 0.0007945
[Epoch 68; Iter   451/ 1097] train: loss: 0.0005968
[Epoch 68; Iter   481/ 1097] train: loss: 0.0072760
[Epoch 68; Iter   511/ 1097] train: loss: 0.0048310
[Epoch 68; Iter   541/ 1097] train: loss: 0.0000226
[Epoch 68; Iter   571/ 1097] train: loss: 0.0003039
[Epoch 68; Iter   601/ 1097] train: loss: 0.0006730
[Epoch 68; Iter   631/ 1097] train: loss: 0.0000009
[Epoch 68; Iter   661/ 1097] train: loss: 0.0000265
[Epoch 68; Iter   691/ 1097] train: loss: 0.0000083
[Epoch 68; Iter   721/ 1097] train: loss: 0.0021652
[Epoch 68; Iter   751/ 1097] train: loss: 0.0004508
[Epoch 68; Iter   781/ 1097] train: loss: 0.0008390
[Epoch 68; Iter   811/ 1097] train: loss: 0.0004593
[Epoch 68; Iter   841/ 1097] train: loss: 0.0000215
[Epoch 68; Iter   871/ 1097] train: loss: 0.0000405
[Epoch 68; Iter   901/ 1097] train: loss: 0.0042803
[Epoch 68; Iter   931/ 1097] train: loss: 0.0000024
[Epoch 68; Iter   961/ 1097] train: loss: 0.0079138
[Epoch 68; Iter   991/ 1097] train: loss: 0.0006383
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0016454
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0041856
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0025315
[Epoch 68] ogbg-molhiv: 0.756081 val loss: 4.206703
[Epoch 68] ogbg-molhiv: 0.747716 test loss: 8.602781
[Epoch 69; Iter    14/ 1097] train: loss: 0.0001767
[Epoch 69; Iter    44/ 1097] train: loss: 0.0000022
[Epoch 69; Iter    74/ 1097] train: loss: 0.0012034
[Epoch 65; Iter    22/ 1097] train: loss: 0.0003766
[Epoch 65; Iter    52/ 1097] train: loss: 0.0002733
[Epoch 65; Iter    82/ 1097] train: loss: 0.0030551
[Epoch 65; Iter   112/ 1097] train: loss: 0.0002200
[Epoch 65; Iter   142/ 1097] train: loss: 0.0000283
[Epoch 65; Iter   172/ 1097] train: loss: 0.0003123
[Epoch 65; Iter   202/ 1097] train: loss: 0.0001147
[Epoch 65; Iter   232/ 1097] train: loss: 0.0153291
[Epoch 65; Iter   262/ 1097] train: loss: 0.0006079
[Epoch 65; Iter   292/ 1097] train: loss: 0.0001607
[Epoch 65; Iter   322/ 1097] train: loss: 0.0032798
[Epoch 65; Iter   352/ 1097] train: loss: 0.0003319
[Epoch 65; Iter   382/ 1097] train: loss: 0.0001760
[Epoch 65; Iter   412/ 1097] train: loss: 0.0000364
[Epoch 65; Iter   442/ 1097] train: loss: 0.0003256
[Epoch 65; Iter   472/ 1097] train: loss: 0.0000325
[Epoch 65; Iter   502/ 1097] train: loss: 0.0107720
[Epoch 65; Iter   532/ 1097] train: loss: 0.0004437
[Epoch 65; Iter   562/ 1097] train: loss: 0.0001930
[Epoch 65; Iter   592/ 1097] train: loss: 0.0023803
[Epoch 65; Iter   622/ 1097] train: loss: 0.0008265
[Epoch 65; Iter   652/ 1097] train: loss: 0.0001082
[Epoch 65; Iter   682/ 1097] train: loss: 0.0080991
[Epoch 65; Iter   712/ 1097] train: loss: 0.0015592
[Epoch 65; Iter   742/ 1097] train: loss: 0.0035605
[Epoch 65; Iter   772/ 1097] train: loss: 0.0002094
[Epoch 65; Iter   802/ 1097] train: loss: 0.0450282
[Epoch 65; Iter   832/ 1097] train: loss: 0.0046948
[Epoch 65; Iter   862/ 1097] train: loss: 0.0033257
[Epoch 65; Iter   892/ 1097] train: loss: 0.0002688
[Epoch 65; Iter   922/ 1097] train: loss: 0.0031164
[Epoch 65; Iter   952/ 1097] train: loss: 0.0003129
[Epoch 65; Iter   982/ 1097] train: loss: 0.0002465
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0102130
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0000197
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0003424
[Epoch 65] ogbg-molhiv: 0.659101 val loss: 22.625723
[Epoch 65] ogbg-molhiv: 0.590960 test loss: 20.141054
[Epoch 66; Iter     5/ 1097] train: loss: 0.0011598
[Epoch 66; Iter    35/ 1097] train: loss: 0.0020645
[Epoch 66; Iter    65/ 1097] train: loss: 0.0016626
[Epoch 66; Iter    95/ 1097] train: loss: 0.0009327
[Epoch 66; Iter   125/ 1097] train: loss: 0.0003393
[Epoch 66; Iter   155/ 1097] train: loss: 0.0279320
[Epoch 66; Iter   185/ 1097] train: loss: 0.0005296
[Epoch 66; Iter   215/ 1097] train: loss: 0.0011750
[Epoch 66; Iter   245/ 1097] train: loss: 0.0186500
[Epoch 66; Iter   275/ 1097] train: loss: 0.0000996
[Epoch 66; Iter   305/ 1097] train: loss: 0.0026337
[Epoch 66; Iter   335/ 1097] train: loss: 0.0013849
[Epoch 66; Iter   365/ 1097] train: loss: 0.0001146
[Epoch 66; Iter   395/ 1097] train: loss: 0.0000780
[Epoch 66; Iter   425/ 1097] train: loss: 0.0022986
[Epoch 66; Iter   455/ 1097] train: loss: 0.1176651
[Epoch 66; Iter   485/ 1097] train: loss: 0.0007257
[Epoch 66; Iter   515/ 1097] train: loss: 0.0003631
[Epoch 66; Iter   545/ 1097] train: loss: 0.0017379
[Epoch 66; Iter   575/ 1097] train: loss: 0.0124084
[Epoch 66; Iter   605/ 1097] train: loss: 0.0001834
[Epoch 66; Iter   635/ 1097] train: loss: 0.0043271
[Epoch 66; Iter   665/ 1097] train: loss: 0.0018241
[Epoch 66; Iter   695/ 1097] train: loss: 0.0055945
[Epoch 66; Iter   725/ 1097] train: loss: 0.0020299
[Epoch 66; Iter   755/ 1097] train: loss: 0.0001942
[Epoch 66; Iter   785/ 1097] train: loss: 0.0176263
[Epoch 66; Iter   815/ 1097] train: loss: 0.0006783
[Epoch 66; Iter   845/ 1097] train: loss: 0.0028294
[Epoch 66; Iter   875/ 1097] train: loss: 0.0002709
[Epoch 66; Iter   905/ 1097] train: loss: 0.0016854
[Epoch 66; Iter   935/ 1097] train: loss: 0.0028575
[Epoch 66; Iter   965/ 1097] train: loss: 0.0026175
[Epoch 66; Iter   995/ 1097] train: loss: 0.0000297
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0001451
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0013169
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0001603
[Epoch 66] ogbg-molhiv: 0.656553 val loss: 153.809215
[Epoch 66] ogbg-molhiv: 0.569793 test loss: 140.881522
[Epoch 67; Iter    18/ 1097] train: loss: 0.0000595
[Epoch 67; Iter    48/ 1097] train: loss: 0.0011265
[Epoch 67; Iter    78/ 1097] train: loss: 0.0022108
[Epoch 67; Iter   108/ 1097] train: loss: 0.0000732
[Epoch 67; Iter   138/ 1097] train: loss: 0.0021005
[Epoch 67; Iter   168/ 1097] train: loss: 0.0824282
[Epoch 67; Iter   198/ 1097] train: loss: 0.0024527
[Epoch 67; Iter   228/ 1097] train: loss: 0.0040344
[Epoch 67; Iter   258/ 1097] train: loss: 0.0110572
[Epoch 67; Iter   288/ 1097] train: loss: 0.0000879
[Epoch 67; Iter   318/ 1097] train: loss: 0.0001007
[Epoch 67; Iter   348/ 1097] train: loss: 0.0001738
[Epoch 67; Iter   378/ 1097] train: loss: 0.0011122
[Epoch 67; Iter   408/ 1097] train: loss: 0.0003808
[Epoch 67; Iter   438/ 1097] train: loss: 0.0001732
[Epoch 67; Iter   468/ 1097] train: loss: 0.0031580
[Epoch 67; Iter   498/ 1097] train: loss: 0.0050815
[Epoch 67; Iter   528/ 1097] train: loss: 0.0096694
[Epoch 67; Iter   558/ 1097] train: loss: 0.0034084
[Epoch 67; Iter   588/ 1097] train: loss: 0.0001113
[Epoch 67; Iter   618/ 1097] train: loss: 0.0014797
[Epoch 67; Iter   648/ 1097] train: loss: 0.0000167
[Epoch 67; Iter   678/ 1097] train: loss: 0.0009770
[Epoch 67; Iter   708/ 1097] train: loss: 0.0000670
[Epoch 67; Iter   738/ 1097] train: loss: 0.0009835
[Epoch 67; Iter   768/ 1097] train: loss: 0.0086570
[Epoch 67; Iter   798/ 1097] train: loss: 0.0058914
[Epoch 67; Iter   828/ 1097] train: loss: 0.0001595
[Epoch 67; Iter   858/ 1097] train: loss: 0.0003356
[Epoch 67; Iter   888/ 1097] train: loss: 0.0000183
[Epoch 67; Iter   918/ 1097] train: loss: 0.0018096
[Epoch 67; Iter   948/ 1097] train: loss: 0.0009892
[Epoch 67; Iter   978/ 1097] train: loss: 0.0023168
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0000860
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0000757
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0003662
[Epoch 67] ogbg-molhiv: 0.709512 val loss: 13.370313
[Epoch 67] ogbg-molhiv: 0.639300 test loss: 13.987558
[Epoch 68; Iter     1/ 1097] train: loss: 0.0000520
[Epoch 68; Iter    31/ 1097] train: loss: 0.0013257
[Epoch 68; Iter    61/ 1097] train: loss: 0.0010650
[Epoch 68; Iter    91/ 1097] train: loss: 0.0004700
[Epoch 68; Iter   121/ 1097] train: loss: 0.0000482
[Epoch 68; Iter   151/ 1097] train: loss: 0.0002078
[Epoch 68; Iter   181/ 1097] train: loss: 0.0000258
[Epoch 68; Iter   211/ 1097] train: loss: 0.0001344
[Epoch 68; Iter   241/ 1097] train: loss: 0.0052047
[Epoch 68; Iter   271/ 1097] train: loss: 0.0018003
[Epoch 68; Iter   301/ 1097] train: loss: 0.0000519
[Epoch 68; Iter   331/ 1097] train: loss: 0.0004594
[Epoch 68; Iter   361/ 1097] train: loss: 0.0205388
[Epoch 68; Iter   391/ 1097] train: loss: 0.0033270
[Epoch 68; Iter   421/ 1097] train: loss: 0.0000630
[Epoch 68; Iter   451/ 1097] train: loss: 0.0007594
[Epoch 68; Iter   481/ 1097] train: loss: 0.0000316
[Epoch 68; Iter   511/ 1097] train: loss: 0.0057732
[Epoch 68; Iter   541/ 1097] train: loss: 0.0039651
[Epoch 68; Iter   571/ 1097] train: loss: 0.0000245
[Epoch 68; Iter   601/ 1097] train: loss: 0.0000502
[Epoch 68; Iter   631/ 1097] train: loss: 0.0002509
[Epoch 68; Iter   661/ 1097] train: loss: 0.0029221
[Epoch 68; Iter   691/ 1097] train: loss: 0.0001520
[Epoch 68; Iter   721/ 1097] train: loss: 0.0000753
[Epoch 68; Iter   751/ 1097] train: loss: 0.0013585
[Epoch 68; Iter   781/ 1097] train: loss: 0.0076448
[Epoch 68; Iter   811/ 1097] train: loss: 0.0001452
[Epoch 68; Iter   841/ 1097] train: loss: 0.0012323
[Epoch 68; Iter   871/ 1097] train: loss: 0.0006464
[Epoch 68; Iter   901/ 1097] train: loss: 0.0065077
[Epoch 68; Iter   931/ 1097] train: loss: 0.0001888
[Epoch 68; Iter   961/ 1097] train: loss: 0.0006579
[Epoch 68; Iter   991/ 1097] train: loss: 0.0001360
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0003808
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0003550
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0115134
[Epoch 68] ogbg-molhiv: 0.635864 val loss: 90.254602
[Epoch 68] ogbg-molhiv: 0.548508 test loss: 84.998088
[Epoch 69; Iter    14/ 1097] train: loss: 0.0010024
[Epoch 69; Iter    44/ 1097] train: loss: 0.0022517
[Epoch 69; Iter    74/ 1097] train: loss: 0.0040211
[Epoch 69; Iter   104/ 1097] train: loss: 0.0007263
[Epoch 69; Iter   134/ 1097] train: loss: 0.0035205
[Epoch 69; Iter   164/ 1097] train: loss: 0.0009192
[Epoch 69; Iter   194/ 1097] train: loss: 0.0009453
[Epoch 69; Iter   224/ 1097] train: loss: 0.0058850
[Epoch 69; Iter   254/ 1097] train: loss: 0.0057621
[Epoch 69; Iter   284/ 1097] train: loss: 0.0005302
[Epoch 69; Iter   314/ 1097] train: loss: 0.0153769
[Epoch 69; Iter   344/ 1097] train: loss: 0.0001636
[Epoch 69; Iter   374/ 1097] train: loss: 0.0156050
[Epoch 69; Iter   404/ 1097] train: loss: 0.0013450
[Epoch 69; Iter   434/ 1097] train: loss: 0.0007221
[Epoch 69; Iter   464/ 1097] train: loss: 0.0600988
[Epoch 69; Iter   494/ 1097] train: loss: 0.0015433
[Epoch 69; Iter   524/ 1097] train: loss: 0.0001606
[Epoch 69; Iter   554/ 1097] train: loss: 0.0020615
[Epoch 69; Iter   584/ 1097] train: loss: 0.0001812
[Epoch 69; Iter   614/ 1097] train: loss: 0.0012693
[Epoch 69; Iter   644/ 1097] train: loss: 0.0035859
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001430
[Epoch 69; Iter   704/ 1097] train: loss: 0.0002820
[Epoch 69; Iter   734/ 1097] train: loss: 0.0246074
[Epoch 69; Iter   764/ 1097] train: loss: 0.0002150
[Epoch 69; Iter   794/ 1097] train: loss: 0.0501385
[Epoch 69; Iter   824/ 1097] train: loss: 0.0004365
[Epoch 69; Iter   854/ 1097] train: loss: 0.0104768
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000344
[Epoch 69; Iter   914/ 1097] train: loss: 0.0016509
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001123
[Epoch 69; Iter   974/ 1097] train: loss: 0.0012190
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0002874
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0106926
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0933852
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0047052
[Epoch 69] ogbg-molhiv: 0.739455 val loss: 1.288482
[Epoch 69] ogbg-molhiv: 0.720682 test loss: 1.108166
[Epoch 70; Iter    27/ 1097] train: loss: 0.0009370
[Epoch 70; Iter    57/ 1097] train: loss: 0.0008185
[Epoch 70; Iter    87/ 1097] train: loss: 0.0115331
[Epoch 70; Iter   117/ 1097] train: loss: 0.1025309
[Epoch 70; Iter   147/ 1097] train: loss: 0.0066912
[Epoch 70; Iter   177/ 1097] train: loss: 0.0044500
[Epoch 70; Iter   207/ 1097] train: loss: 0.0005004
[Epoch 70; Iter   237/ 1097] train: loss: 0.0091454
[Epoch 70; Iter   267/ 1097] train: loss: 0.0116563
[Epoch 70; Iter   297/ 1097] train: loss: 0.0003898
[Epoch 70; Iter   327/ 1097] train: loss: 0.0010451
[Epoch 70; Iter   357/ 1097] train: loss: 0.0043861
[Epoch 70; Iter   387/ 1097] train: loss: 0.0008210
[Epoch 70; Iter   417/ 1097] train: loss: 0.0003040
[Epoch 70; Iter   447/ 1097] train: loss: 0.0017099
[Epoch 70; Iter   477/ 1097] train: loss: 0.0012634
[Epoch 70; Iter   507/ 1097] train: loss: 0.0040883
[Epoch 70; Iter   537/ 1097] train: loss: 0.0026284
[Epoch 70; Iter   567/ 1097] train: loss: 0.0008567
[Epoch 70; Iter   597/ 1097] train: loss: 0.0015793
[Epoch 70; Iter   627/ 1097] train: loss: 0.0005620
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001149
[Epoch 70; Iter   687/ 1097] train: loss: 0.0002498
[Epoch 70; Iter   717/ 1097] train: loss: 0.0021811
[Epoch 70; Iter   747/ 1097] train: loss: 0.0004124
[Epoch 70; Iter   777/ 1097] train: loss: 0.0005135
[Epoch 70; Iter   807/ 1097] train: loss: 0.0002699
[Epoch 70; Iter   837/ 1097] train: loss: 0.0007545
[Epoch 70; Iter   867/ 1097] train: loss: 0.0206099
[Epoch 70; Iter   897/ 1097] train: loss: 0.0004337
[Epoch 70; Iter   927/ 1097] train: loss: 0.0007314
[Epoch 70; Iter   957/ 1097] train: loss: 0.0007811
[Epoch 70; Iter   987/ 1097] train: loss: 0.0151008
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0003920
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0002069
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000684
[Epoch 70] ogbg-molhiv: 0.692552 val loss: 1.719021
[Epoch 70] ogbg-molhiv: 0.730870 test loss: 0.355478
[Epoch 71; Iter    10/ 1097] train: loss: 0.0014314
[Epoch 71; Iter    40/ 1097] train: loss: 0.0017522
[Epoch 71; Iter    70/ 1097] train: loss: 0.0044620
[Epoch 71; Iter   100/ 1097] train: loss: 0.1175425
[Epoch 71; Iter   130/ 1097] train: loss: 0.0061387
[Epoch 71; Iter   160/ 1097] train: loss: 0.0002214
[Epoch 71; Iter   190/ 1097] train: loss: 0.0008966
[Epoch 71; Iter   220/ 1097] train: loss: 0.0101896
[Epoch 71; Iter   250/ 1097] train: loss: 0.0002770
[Epoch 71; Iter   280/ 1097] train: loss: 0.0199207
[Epoch 71; Iter   310/ 1097] train: loss: 0.0017141
[Epoch 71; Iter   340/ 1097] train: loss: 0.0065737
[Epoch 71; Iter   370/ 1097] train: loss: 0.0006802
[Epoch 71; Iter   400/ 1097] train: loss: 0.0006638
[Epoch 71; Iter   430/ 1097] train: loss: 0.0009348
[Epoch 71; Iter   460/ 1097] train: loss: 0.0017727
[Epoch 71; Iter   490/ 1097] train: loss: 0.0023319
[Epoch 71; Iter   520/ 1097] train: loss: 0.0058213
[Epoch 71; Iter   550/ 1097] train: loss: 0.0038722
[Epoch 71; Iter   580/ 1097] train: loss: 0.0016291
[Epoch 71; Iter   610/ 1097] train: loss: 0.0002619
[Epoch 71; Iter   640/ 1097] train: loss: 0.0002986
[Epoch 71; Iter   670/ 1097] train: loss: 0.0000490
[Epoch 71; Iter   700/ 1097] train: loss: 0.0064164
[Epoch 71; Iter   730/ 1097] train: loss: 0.0011999
[Epoch 71; Iter   760/ 1097] train: loss: 0.0421643
[Epoch 71; Iter   790/ 1097] train: loss: 0.0002317
[Epoch 71; Iter   820/ 1097] train: loss: 0.0004879
[Epoch 71; Iter   850/ 1097] train: loss: 0.0007767
[Epoch 71; Iter   880/ 1097] train: loss: 0.0341415
[Epoch 71; Iter   910/ 1097] train: loss: 0.0001584
[Epoch 71; Iter   940/ 1097] train: loss: 0.0008396
[Epoch 71; Iter   970/ 1097] train: loss: 0.0134558
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0126219
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0001934
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0003389
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0032958
[Epoch 71] ogbg-molhiv: 0.724944 val loss: 1.287376
[Epoch 71] ogbg-molhiv: 0.746648 test loss: 1.067407
[Epoch 72; Iter    23/ 1097] train: loss: 0.0109095
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000613
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000577
[Epoch 72; Iter   113/ 1097] train: loss: 0.0003476
[Epoch 72; Iter   143/ 1097] train: loss: 0.0015509
[Epoch 72; Iter   173/ 1097] train: loss: 0.0004682
[Epoch 72; Iter   203/ 1097] train: loss: 0.0003133
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000581
[Epoch 72; Iter   263/ 1097] train: loss: 0.0104281
[Epoch 72; Iter   293/ 1097] train: loss: 0.0118264
[Epoch 72; Iter   323/ 1097] train: loss: 0.0002523
[Epoch 72; Iter   353/ 1097] train: loss: 0.0332795
[Epoch 72; Iter   383/ 1097] train: loss: 0.0003710
[Epoch 72; Iter   413/ 1097] train: loss: 0.0010468
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001391
[Epoch 72; Iter   473/ 1097] train: loss: 0.0038803
[Epoch 72; Iter   503/ 1097] train: loss: 0.0322665
[Epoch 72; Iter   533/ 1097] train: loss: 0.0028199
[Epoch 72; Iter   563/ 1097] train: loss: 0.0007100
[Epoch 72; Iter   593/ 1097] train: loss: 0.0002406
[Epoch 72; Iter   623/ 1097] train: loss: 0.0064564
[Epoch 72; Iter   653/ 1097] train: loss: 0.0001128
[Epoch 72; Iter   683/ 1097] train: loss: 0.0010495
[Epoch 72; Iter   713/ 1097] train: loss: 0.0067762
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000115
[Epoch 72; Iter   773/ 1097] train: loss: 0.0411503
[Epoch 72; Iter   803/ 1097] train: loss: 0.0012431
[Epoch 72; Iter   833/ 1097] train: loss: 0.0126984
[Epoch 72; Iter   863/ 1097] train: loss: 0.0048252
[Epoch 72; Iter   893/ 1097] train: loss: 0.0009480
[Epoch 72; Iter   923/ 1097] train: loss: 0.0033692
[Epoch 72; Iter   953/ 1097] train: loss: 0.0051663
[Epoch 72; Iter   983/ 1097] train: loss: 0.0007818
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000991
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0022892
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0272122
[Epoch 72] ogbg-molhiv: 0.744565 val loss: 2.595115
[Epoch 72] ogbg-molhiv: 0.721045 test loss: 1.990519
[Epoch 73; Iter     6/ 1097] train: loss: 0.0012042
[Epoch 73; Iter    36/ 1097] train: loss: 0.0255287
[Epoch 73; Iter    66/ 1097] train: loss: 0.0002008
[Epoch 73; Iter    96/ 1097] train: loss: 0.0000529
[Epoch 73; Iter   126/ 1097] train: loss: 0.0007028
[Epoch 73; Iter   156/ 1097] train: loss: 0.0052184
[Epoch 69; Iter   104/ 1097] train: loss: 0.0001673
[Epoch 69; Iter   134/ 1097] train: loss: 0.0002051
[Epoch 69; Iter   164/ 1097] train: loss: 0.0011977
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000102
[Epoch 69; Iter   224/ 1097] train: loss: 0.0003488
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000731
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001849
[Epoch 69; Iter   314/ 1097] train: loss: 0.0000364
[Epoch 69; Iter   344/ 1097] train: loss: 0.0000048
[Epoch 69; Iter   374/ 1097] train: loss: 0.0000617
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001165
[Epoch 69; Iter   434/ 1097] train: loss: 0.0004152
[Epoch 69; Iter   464/ 1097] train: loss: 0.0006867
[Epoch 69; Iter   494/ 1097] train: loss: 0.0115619
[Epoch 69; Iter   524/ 1097] train: loss: 0.0002551
[Epoch 69; Iter   554/ 1097] train: loss: 0.0184268
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000689
[Epoch 69; Iter   614/ 1097] train: loss: 0.0002222
[Epoch 69; Iter   644/ 1097] train: loss: 0.0002244
[Epoch 69; Iter   674/ 1097] train: loss: 0.0005110
[Epoch 69; Iter   704/ 1097] train: loss: 0.0005317
[Epoch 69; Iter   734/ 1097] train: loss: 0.0034322
[Epoch 69; Iter   764/ 1097] train: loss: 0.0064859
[Epoch 69; Iter   794/ 1097] train: loss: 0.0005520
[Epoch 69; Iter   824/ 1097] train: loss: 0.0008224
[Epoch 69; Iter   854/ 1097] train: loss: 0.0009687
[Epoch 69; Iter   884/ 1097] train: loss: 0.0632592
[Epoch 69; Iter   914/ 1097] train: loss: 0.0005226
[Epoch 69; Iter   944/ 1097] train: loss: 0.0272598
[Epoch 69; Iter   974/ 1097] train: loss: 0.0035855
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0002081
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0000422
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0001762
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0003767
[Epoch 69] ogbg-molhiv: 0.776568 val loss: 0.210211
[Epoch 69] ogbg-molhiv: 0.726661 test loss: 0.333000
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000931
[Epoch 70; Iter    57/ 1097] train: loss: 0.0001254
[Epoch 70; Iter    87/ 1097] train: loss: 0.0029995
[Epoch 70; Iter   117/ 1097] train: loss: 0.0002608
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000510
[Epoch 70; Iter   177/ 1097] train: loss: 0.0001136
[Epoch 70; Iter   207/ 1097] train: loss: 0.0011424
[Epoch 70; Iter   237/ 1097] train: loss: 0.0000895
[Epoch 70; Iter   267/ 1097] train: loss: 0.0005480
[Epoch 70; Iter   297/ 1097] train: loss: 0.0001101
[Epoch 70; Iter   327/ 1097] train: loss: 0.0002531
[Epoch 70; Iter   357/ 1097] train: loss: 0.0065079
[Epoch 70; Iter   387/ 1097] train: loss: 0.0005731
[Epoch 70; Iter   417/ 1097] train: loss: 0.0016818
[Epoch 70; Iter   447/ 1097] train: loss: 0.0008193
[Epoch 70; Iter   477/ 1097] train: loss: 0.0000442
[Epoch 70; Iter   507/ 1097] train: loss: 0.0006640
[Epoch 70; Iter   537/ 1097] train: loss: 0.0005551
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000227
[Epoch 70; Iter   597/ 1097] train: loss: 0.0002376
[Epoch 70; Iter   627/ 1097] train: loss: 0.0091126
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000217
[Epoch 70; Iter   687/ 1097] train: loss: 0.0009878
[Epoch 70; Iter   717/ 1097] train: loss: 0.0002123
[Epoch 70; Iter   747/ 1097] train: loss: 0.0014264
[Epoch 70; Iter   777/ 1097] train: loss: 0.0004924
[Epoch 70; Iter   807/ 1097] train: loss: 0.0555258
[Epoch 70; Iter   837/ 1097] train: loss: 0.0045243
[Epoch 70; Iter   867/ 1097] train: loss: 0.0011934
[Epoch 70; Iter   897/ 1097] train: loss: 0.0003232
[Epoch 70; Iter   927/ 1097] train: loss: 0.0011192
[Epoch 70; Iter   957/ 1097] train: loss: 0.0072558
[Epoch 70; Iter   987/ 1097] train: loss: 0.0002885
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0003539
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0003008
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000225
[Epoch 70] ogbg-molhiv: 0.775218 val loss: 0.222668
[Epoch 70] ogbg-molhiv: 0.716039 test loss: 0.359029
[Epoch 71; Iter    10/ 1097] train: loss: 0.0098242
[Epoch 71; Iter    40/ 1097] train: loss: 0.0017914
[Epoch 71; Iter    70/ 1097] train: loss: 0.0027027
[Epoch 71; Iter   100/ 1097] train: loss: 0.0013942
[Epoch 71; Iter   130/ 1097] train: loss: 0.0010562
[Epoch 71; Iter   160/ 1097] train: loss: 0.0011482
[Epoch 71; Iter   190/ 1097] train: loss: 0.0002744
[Epoch 71; Iter   220/ 1097] train: loss: 0.0001604
[Epoch 71; Iter   250/ 1097] train: loss: 0.0001685
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001426
[Epoch 71; Iter   310/ 1097] train: loss: 0.0000017
[Epoch 71; Iter   340/ 1097] train: loss: 0.0000719
[Epoch 71; Iter   370/ 1097] train: loss: 0.0002528
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000155
[Epoch 71; Iter   430/ 1097] train: loss: 0.0000451
[Epoch 71; Iter   460/ 1097] train: loss: 0.0002082
[Epoch 71; Iter   490/ 1097] train: loss: 0.0001261
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000210
[Epoch 71; Iter   550/ 1097] train: loss: 0.0075487
[Epoch 71; Iter   580/ 1097] train: loss: 0.0001031
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000654
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000159
[Epoch 71; Iter   670/ 1097] train: loss: 0.0000338
[Epoch 71; Iter   700/ 1097] train: loss: 0.0001115
[Epoch 71; Iter   730/ 1097] train: loss: 0.0067081
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000869
[Epoch 71; Iter   790/ 1097] train: loss: 0.0172743
[Epoch 71; Iter   820/ 1097] train: loss: 0.0077265
[Epoch 71; Iter   850/ 1097] train: loss: 0.0011478
[Epoch 71; Iter   880/ 1097] train: loss: 0.0001934
[Epoch 71; Iter   910/ 1097] train: loss: 0.0039354
[Epoch 71; Iter   940/ 1097] train: loss: 0.0003572
[Epoch 71; Iter   970/ 1097] train: loss: 0.0012476
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0002388
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000706
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0001416
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0064904
[Epoch 71] ogbg-molhiv: 0.759529 val loss: 0.234501
[Epoch 71] ogbg-molhiv: 0.727907 test loss: 0.341285
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000577
[Epoch 72; Iter    53/ 1097] train: loss: 0.0002629
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000899
[Epoch 72; Iter   113/ 1097] train: loss: 0.0009174
[Epoch 72; Iter   143/ 1097] train: loss: 0.0005454
[Epoch 72; Iter   173/ 1097] train: loss: 0.0001705
[Epoch 72; Iter   203/ 1097] train: loss: 0.0001802
[Epoch 72; Iter   233/ 1097] train: loss: 0.0004034
[Epoch 72; Iter   263/ 1097] train: loss: 0.0012472
[Epoch 72; Iter   293/ 1097] train: loss: 0.0008079
[Epoch 72; Iter   323/ 1097] train: loss: 0.0017449
[Epoch 72; Iter   353/ 1097] train: loss: 0.0000428
[Epoch 72; Iter   383/ 1097] train: loss: 0.0060882
[Epoch 72; Iter   413/ 1097] train: loss: 0.0000058
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001190
[Epoch 72; Iter   473/ 1097] train: loss: 0.0029878
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002014
[Epoch 72; Iter   533/ 1097] train: loss: 0.0000724
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000192
[Epoch 72; Iter   593/ 1097] train: loss: 0.0001584
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000024
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000163
[Epoch 72; Iter   683/ 1097] train: loss: 0.0000566
[Epoch 72; Iter   713/ 1097] train: loss: 0.0000904
[Epoch 72; Iter   743/ 1097] train: loss: 0.0002274
[Epoch 72; Iter   773/ 1097] train: loss: 0.0376577
[Epoch 72; Iter   803/ 1097] train: loss: 0.0008541
[Epoch 72; Iter   833/ 1097] train: loss: 0.0004568
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000580
[Epoch 72; Iter   893/ 1097] train: loss: 0.0005008
[Epoch 72; Iter   923/ 1097] train: loss: 0.0000125
[Epoch 72; Iter   953/ 1097] train: loss: 0.0013796
[Epoch 72; Iter   983/ 1097] train: loss: 0.0001616
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000651
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0006025
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0029657
[Epoch 72] ogbg-molhiv: 0.746457 val loss: 0.230450
[Epoch 72] ogbg-molhiv: 0.724682 test loss: 0.370858
[Epoch 73; Iter     6/ 1097] train: loss: 0.0275577
[Epoch 73; Iter    36/ 1097] train: loss: 0.0002524
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000839
[Epoch 73; Iter    96/ 1097] train: loss: 0.0002867
[Epoch 73; Iter   126/ 1097] train: loss: 0.0010455
[Epoch 73; Iter   156/ 1097] train: loss: 0.0009879
[Epoch 69; Iter   104/ 1097] train: loss: 0.0004938
[Epoch 69; Iter   134/ 1097] train: loss: 0.0009195
[Epoch 69; Iter   164/ 1097] train: loss: 0.0006930
[Epoch 69; Iter   194/ 1097] train: loss: 0.0632817
[Epoch 69; Iter   224/ 1097] train: loss: 0.0005212
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000592
[Epoch 69; Iter   284/ 1097] train: loss: 0.0000369
[Epoch 69; Iter   314/ 1097] train: loss: 0.0013244
[Epoch 69; Iter   344/ 1097] train: loss: 0.0082277
[Epoch 69; Iter   374/ 1097] train: loss: 0.0002009
[Epoch 69; Iter   404/ 1097] train: loss: 0.0013980
[Epoch 69; Iter   434/ 1097] train: loss: 0.0003218
[Epoch 69; Iter   464/ 1097] train: loss: 0.0051819
[Epoch 69; Iter   494/ 1097] train: loss: 0.0519868
[Epoch 69; Iter   524/ 1097] train: loss: 0.0076566
[Epoch 69; Iter   554/ 1097] train: loss: 0.0002000
[Epoch 69; Iter   584/ 1097] train: loss: 0.0007547
[Epoch 69; Iter   614/ 1097] train: loss: 0.0000286
[Epoch 69; Iter   644/ 1097] train: loss: 0.0570228
[Epoch 69; Iter   674/ 1097] train: loss: 0.0004919
[Epoch 69; Iter   704/ 1097] train: loss: 0.0000640
[Epoch 69; Iter   734/ 1097] train: loss: 0.0004383
[Epoch 69; Iter   764/ 1097] train: loss: 0.0006044
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000131
[Epoch 69; Iter   824/ 1097] train: loss: 0.0007380
[Epoch 69; Iter   854/ 1097] train: loss: 0.0003334
[Epoch 69; Iter   884/ 1097] train: loss: 0.0003891
[Epoch 69; Iter   914/ 1097] train: loss: 0.0030596
[Epoch 69; Iter   944/ 1097] train: loss: 0.0000371
[Epoch 69; Iter   974/ 1097] train: loss: 0.0001652
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000735
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001751
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0067768
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0059856
[Epoch 69] ogbg-molhiv: 0.765466 val loss: 0.343090
[Epoch 69] ogbg-molhiv: 0.740439 test loss: 0.361665
[Epoch 70; Iter    27/ 1097] train: loss: 0.0744683
[Epoch 70; Iter    57/ 1097] train: loss: 0.0001302
[Epoch 70; Iter    87/ 1097] train: loss: 0.0064479
[Epoch 70; Iter   117/ 1097] train: loss: 0.0002404
[Epoch 70; Iter   147/ 1097] train: loss: 0.0001365
[Epoch 70; Iter   177/ 1097] train: loss: 0.0007743
[Epoch 70; Iter   207/ 1097] train: loss: 0.0002217
[Epoch 70; Iter   237/ 1097] train: loss: 0.0014498
[Epoch 70; Iter   267/ 1097] train: loss: 0.0000067
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000796
[Epoch 70; Iter   327/ 1097] train: loss: 0.0259521
[Epoch 70; Iter   357/ 1097] train: loss: 0.0002454
[Epoch 70; Iter   387/ 1097] train: loss: 0.0001382
[Epoch 70; Iter   417/ 1097] train: loss: 0.0001695
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000570
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001361
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000912
[Epoch 70; Iter   537/ 1097] train: loss: 0.0000384
[Epoch 70; Iter   567/ 1097] train: loss: 0.0001778
[Epoch 70; Iter   597/ 1097] train: loss: 0.0002777
[Epoch 70; Iter   627/ 1097] train: loss: 0.0289305
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001733
[Epoch 70; Iter   687/ 1097] train: loss: 0.0078694
[Epoch 70; Iter   717/ 1097] train: loss: 0.0002205
[Epoch 70; Iter   747/ 1097] train: loss: 0.0008409
[Epoch 70; Iter   777/ 1097] train: loss: 0.0010262
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001994
[Epoch 70; Iter   837/ 1097] train: loss: 0.0008787
[Epoch 70; Iter   867/ 1097] train: loss: 0.0035781
[Epoch 70; Iter   897/ 1097] train: loss: 0.0033781
[Epoch 70; Iter   927/ 1097] train: loss: 0.0016546
[Epoch 70; Iter   957/ 1097] train: loss: 0.0097912
[Epoch 70; Iter   987/ 1097] train: loss: 0.0094293
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0001951
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000674
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0028227
[Epoch 70] ogbg-molhiv: 0.766850 val loss: 0.337536
[Epoch 70] ogbg-molhiv: 0.754366 test loss: 0.348985
[Epoch 71; Iter    10/ 1097] train: loss: 0.0000223
[Epoch 71; Iter    40/ 1097] train: loss: 0.0002374
[Epoch 71; Iter    70/ 1097] train: loss: 0.0021002
[Epoch 71; Iter   100/ 1097] train: loss: 0.0007712
[Epoch 71; Iter   130/ 1097] train: loss: 0.0034977
[Epoch 71; Iter   160/ 1097] train: loss: 0.0003431
[Epoch 71; Iter   190/ 1097] train: loss: 0.0003447
[Epoch 71; Iter   220/ 1097] train: loss: 0.0002680
[Epoch 71; Iter   250/ 1097] train: loss: 0.0079932
[Epoch 71; Iter   280/ 1097] train: loss: 0.0005639
[Epoch 71; Iter   310/ 1097] train: loss: 0.0106743
[Epoch 71; Iter   340/ 1097] train: loss: 0.0001778
[Epoch 71; Iter   370/ 1097] train: loss: 0.0072084
[Epoch 71; Iter   400/ 1097] train: loss: 0.0001568
[Epoch 71; Iter   430/ 1097] train: loss: 0.0001139
[Epoch 71; Iter   460/ 1097] train: loss: 0.0006557
[Epoch 71; Iter   490/ 1097] train: loss: 0.0002700
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000589
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000911
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000594
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000482
[Epoch 71; Iter   640/ 1097] train: loss: 0.0027854
[Epoch 71; Iter   670/ 1097] train: loss: 0.0006810
[Epoch 71; Iter   700/ 1097] train: loss: 0.0029534
[Epoch 71; Iter   730/ 1097] train: loss: 0.0005561
[Epoch 71; Iter   760/ 1097] train: loss: 0.0020689
[Epoch 71; Iter   790/ 1097] train: loss: 0.0003170
[Epoch 71; Iter   820/ 1097] train: loss: 0.0021292
[Epoch 71; Iter   850/ 1097] train: loss: 0.0139178
[Epoch 71; Iter   880/ 1097] train: loss: 0.0718949
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000327
[Epoch 71; Iter   940/ 1097] train: loss: 0.0005727
[Epoch 71; Iter   970/ 1097] train: loss: 0.0004585
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0011185
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0002351
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0002693
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0001922
[Epoch 71] ogbg-molhiv: 0.730707 val loss: 0.336968
[Epoch 71] ogbg-molhiv: 0.729892 test loss: 0.348736
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000160
[Epoch 72; Iter    53/ 1097] train: loss: 0.0010701
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000907
[Epoch 72; Iter   113/ 1097] train: loss: 0.0007918
[Epoch 72; Iter   143/ 1097] train: loss: 0.0001540
[Epoch 72; Iter   173/ 1097] train: loss: 0.0004904
[Epoch 72; Iter   203/ 1097] train: loss: 0.0266065
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000145
[Epoch 72; Iter   263/ 1097] train: loss: 0.0008637
[Epoch 72; Iter   293/ 1097] train: loss: 0.0000131
[Epoch 72; Iter   323/ 1097] train: loss: 0.0009327
[Epoch 72; Iter   353/ 1097] train: loss: 0.0001746
[Epoch 72; Iter   383/ 1097] train: loss: 0.0002939
[Epoch 72; Iter   413/ 1097] train: loss: 0.0062324
[Epoch 72; Iter   443/ 1097] train: loss: 0.0001378
[Epoch 72; Iter   473/ 1097] train: loss: 0.0043954
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002868
[Epoch 72; Iter   533/ 1097] train: loss: 0.0000544
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001439
[Epoch 72; Iter   593/ 1097] train: loss: 0.0004291
[Epoch 72; Iter   623/ 1097] train: loss: 0.0002747
[Epoch 72; Iter   653/ 1097] train: loss: 0.0113568
[Epoch 72; Iter   683/ 1097] train: loss: 0.0001896
[Epoch 72; Iter   713/ 1097] train: loss: 0.0001209
[Epoch 72; Iter   743/ 1097] train: loss: 0.0020369
[Epoch 72; Iter   773/ 1097] train: loss: 0.0003210
[Epoch 72; Iter   803/ 1097] train: loss: 0.0002771
[Epoch 72; Iter   833/ 1097] train: loss: 0.0000586
[Epoch 72; Iter   863/ 1097] train: loss: 0.0001234
[Epoch 72; Iter   893/ 1097] train: loss: 0.0019527
[Epoch 72; Iter   923/ 1097] train: loss: 0.0039918
[Epoch 72; Iter   953/ 1097] train: loss: 0.0022865
[Epoch 72; Iter   983/ 1097] train: loss: 0.0003095
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0005244
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0059638
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0313252
[Epoch 72] ogbg-molhiv: 0.723514 val loss: 0.349307
[Epoch 72] ogbg-molhiv: 0.741986 test loss: 0.349205
[Epoch 73; Iter     6/ 1097] train: loss: 0.0000305
[Epoch 73; Iter    36/ 1097] train: loss: 0.0003199
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001778
[Epoch 73; Iter    96/ 1097] train: loss: 0.0001333
[Epoch 73; Iter   126/ 1097] train: loss: 0.0015970
[Epoch 73; Iter   156/ 1097] train: loss: 0.0000069
[Epoch 69; Iter   104/ 1097] train: loss: 0.0006648
[Epoch 69; Iter   134/ 1097] train: loss: 0.0001116
[Epoch 69; Iter   164/ 1097] train: loss: 0.0009964
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000902
[Epoch 69; Iter   224/ 1097] train: loss: 0.0004433
[Epoch 69; Iter   254/ 1097] train: loss: 0.0012721
[Epoch 69; Iter   284/ 1097] train: loss: 0.0049430
[Epoch 69; Iter   314/ 1097] train: loss: 0.0015586
[Epoch 69; Iter   344/ 1097] train: loss: 0.0228493
[Epoch 69; Iter   374/ 1097] train: loss: 0.0058963
[Epoch 69; Iter   404/ 1097] train: loss: 0.0005701
[Epoch 69; Iter   434/ 1097] train: loss: 0.0112445
[Epoch 69; Iter   464/ 1097] train: loss: 0.0024172
[Epoch 69; Iter   494/ 1097] train: loss: 0.0256937
[Epoch 69; Iter   524/ 1097] train: loss: 0.0008263
[Epoch 69; Iter   554/ 1097] train: loss: 0.0319661
[Epoch 69; Iter   584/ 1097] train: loss: 0.0026685
[Epoch 69; Iter   614/ 1097] train: loss: 0.0678381
[Epoch 69; Iter   644/ 1097] train: loss: 0.0478780
[Epoch 69; Iter   674/ 1097] train: loss: 0.0180336
[Epoch 69; Iter   704/ 1097] train: loss: 0.0032415
[Epoch 69; Iter   734/ 1097] train: loss: 0.0070612
[Epoch 69; Iter   764/ 1097] train: loss: 0.0010493
[Epoch 69; Iter   794/ 1097] train: loss: 0.0039211
[Epoch 69; Iter   824/ 1097] train: loss: 0.0004285
[Epoch 69; Iter   854/ 1097] train: loss: 0.0001417
[Epoch 69; Iter   884/ 1097] train: loss: 0.0470073
[Epoch 69; Iter   914/ 1097] train: loss: 0.0001358
[Epoch 69; Iter   944/ 1097] train: loss: 0.0021166
[Epoch 69; Iter   974/ 1097] train: loss: 0.0006314
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0517977
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0195104
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0004386
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0008817
[Epoch 69] ogbg-molhiv: 0.682298 val loss: 3.664987
[Epoch 69] ogbg-molhiv: 0.704915 test loss: 1.393299
[Epoch 70; Iter    27/ 1097] train: loss: 0.0004830
[Epoch 70; Iter    57/ 1097] train: loss: 0.0029216
[Epoch 70; Iter    87/ 1097] train: loss: 0.0514242
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000765
[Epoch 70; Iter   147/ 1097] train: loss: 0.0001155
[Epoch 70; Iter   177/ 1097] train: loss: 0.0144962
[Epoch 70; Iter   207/ 1097] train: loss: 0.0009851
[Epoch 70; Iter   237/ 1097] train: loss: 0.0474392
[Epoch 70; Iter   267/ 1097] train: loss: 0.0135286
[Epoch 70; Iter   297/ 1097] train: loss: 0.0014054
[Epoch 70; Iter   327/ 1097] train: loss: 0.0011424
[Epoch 70; Iter   357/ 1097] train: loss: 0.0097297
[Epoch 70; Iter   387/ 1097] train: loss: 0.0040197
[Epoch 70; Iter   417/ 1097] train: loss: 0.0067540
[Epoch 70; Iter   447/ 1097] train: loss: 0.0004318
[Epoch 70; Iter   477/ 1097] train: loss: 0.0056723
[Epoch 70; Iter   507/ 1097] train: loss: 0.0106516
[Epoch 70; Iter   537/ 1097] train: loss: 0.0037107
[Epoch 70; Iter   567/ 1097] train: loss: 0.0024573
[Epoch 70; Iter   597/ 1097] train: loss: 0.0247738
[Epoch 70; Iter   627/ 1097] train: loss: 0.0035375
[Epoch 70; Iter   657/ 1097] train: loss: 0.0010833
[Epoch 70; Iter   687/ 1097] train: loss: 0.0485762
[Epoch 70; Iter   717/ 1097] train: loss: 0.0022578
[Epoch 70; Iter   747/ 1097] train: loss: 0.0112259
[Epoch 70; Iter   777/ 1097] train: loss: 0.0258276
[Epoch 70; Iter   807/ 1097] train: loss: 0.0410026
[Epoch 70; Iter   837/ 1097] train: loss: 0.0003138
[Epoch 70; Iter   867/ 1097] train: loss: 0.0039345
[Epoch 70; Iter   897/ 1097] train: loss: 0.0003426
[Epoch 70; Iter   927/ 1097] train: loss: 0.0013367
[Epoch 70; Iter   957/ 1097] train: loss: 0.0008582
[Epoch 70; Iter   987/ 1097] train: loss: 0.0122012
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0019852
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0002875
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0012149
[Epoch 70] ogbg-molhiv: 0.700498 val loss: 5.385252
[Epoch 70] ogbg-molhiv: 0.681684 test loss: 2.014298
[Epoch 71; Iter    10/ 1097] train: loss: 0.0493720
[Epoch 71; Iter    40/ 1097] train: loss: 0.0007992
[Epoch 71; Iter    70/ 1097] train: loss: 0.0290334
[Epoch 71; Iter   100/ 1097] train: loss: 0.0060063
[Epoch 71; Iter   130/ 1097] train: loss: 0.0036825
[Epoch 71; Iter   160/ 1097] train: loss: 0.0132434
[Epoch 71; Iter   190/ 1097] train: loss: 0.0137512
[Epoch 71; Iter   220/ 1097] train: loss: 0.0071007
[Epoch 71; Iter   250/ 1097] train: loss: 0.0681740
[Epoch 71; Iter   280/ 1097] train: loss: 0.0065764
[Epoch 71; Iter   310/ 1097] train: loss: 0.0030413
[Epoch 71; Iter   340/ 1097] train: loss: 0.0101090
[Epoch 71; Iter   370/ 1097] train: loss: 0.0017996
[Epoch 71; Iter   400/ 1097] train: loss: 0.0021417
[Epoch 71; Iter   430/ 1097] train: loss: 0.0012601
[Epoch 71; Iter   460/ 1097] train: loss: 0.0002177
[Epoch 71; Iter   490/ 1097] train: loss: 0.0009057
[Epoch 71; Iter   520/ 1097] train: loss: 0.0013715
[Epoch 71; Iter   550/ 1097] train: loss: 0.0040556
[Epoch 71; Iter   580/ 1097] train: loss: 0.0041853
[Epoch 71; Iter   610/ 1097] train: loss: 0.0097797
[Epoch 71; Iter   640/ 1097] train: loss: 0.0047909
[Epoch 71; Iter   670/ 1097] train: loss: 0.0120450
[Epoch 71; Iter   700/ 1097] train: loss: 0.0004688
[Epoch 71; Iter   730/ 1097] train: loss: 0.3050707
[Epoch 71; Iter   760/ 1097] train: loss: 0.0027240
[Epoch 71; Iter   790/ 1097] train: loss: 0.0904477
[Epoch 71; Iter   820/ 1097] train: loss: 0.0067094
[Epoch 71; Iter   850/ 1097] train: loss: 0.0049881
[Epoch 71; Iter   880/ 1097] train: loss: 0.0001184
[Epoch 71; Iter   910/ 1097] train: loss: 0.0135507
[Epoch 71; Iter   940/ 1097] train: loss: 0.0009909
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002007
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0754116
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0976288
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0241291
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0084813
[Epoch 71] ogbg-molhiv: 0.678026 val loss: 4.416862
[Epoch 71] ogbg-molhiv: 0.682756 test loss: 1.121717
[Epoch 72; Iter    23/ 1097] train: loss: 0.0012567
[Epoch 72; Iter    53/ 1097] train: loss: 0.0235507
[Epoch 72; Iter    83/ 1097] train: loss: 0.0444950
[Epoch 72; Iter   113/ 1097] train: loss: 0.0020490
[Epoch 72; Iter   143/ 1097] train: loss: 0.0099978
[Epoch 72; Iter   173/ 1097] train: loss: 0.0042034
[Epoch 72; Iter   203/ 1097] train: loss: 0.0010597
[Epoch 72; Iter   233/ 1097] train: loss: 0.0817110
[Epoch 72; Iter   263/ 1097] train: loss: 0.0353079
[Epoch 72; Iter   293/ 1097] train: loss: 0.0010144
[Epoch 72; Iter   323/ 1097] train: loss: 0.0028712
[Epoch 72; Iter   353/ 1097] train: loss: 0.0004590
[Epoch 72; Iter   383/ 1097] train: loss: 0.0001608
[Epoch 72; Iter   413/ 1097] train: loss: 0.0001654
[Epoch 72; Iter   443/ 1097] train: loss: 0.0014202
[Epoch 72; Iter   473/ 1097] train: loss: 0.0317618
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002282
[Epoch 72; Iter   533/ 1097] train: loss: 0.0127132
[Epoch 72; Iter   563/ 1097] train: loss: 0.0053301
[Epoch 72; Iter   593/ 1097] train: loss: 0.0012016
[Epoch 72; Iter   623/ 1097] train: loss: 0.0328011
[Epoch 72; Iter   653/ 1097] train: loss: 0.0001318
[Epoch 72; Iter   683/ 1097] train: loss: 0.0014393
[Epoch 72; Iter   713/ 1097] train: loss: 0.0006283
[Epoch 72; Iter   743/ 1097] train: loss: 0.0002458
[Epoch 72; Iter   773/ 1097] train: loss: 0.0867020
[Epoch 72; Iter   803/ 1097] train: loss: 0.0346715
[Epoch 72; Iter   833/ 1097] train: loss: 0.0033607
[Epoch 72; Iter   863/ 1097] train: loss: 0.0042598
[Epoch 72; Iter   893/ 1097] train: loss: 0.0054011
[Epoch 72; Iter   923/ 1097] train: loss: 0.0060441
[Epoch 72; Iter   953/ 1097] train: loss: 0.0152313
[Epoch 72; Iter   983/ 1097] train: loss: 0.0044199
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0068781
[Epoch 72; Iter  1043/ 1097] train: loss: 0.1338633
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0454243
[Epoch 72] ogbg-molhiv: 0.714748 val loss: 2.942610
[Epoch 72] ogbg-molhiv: 0.685600 test loss: 1.543471
[Epoch 73; Iter     6/ 1097] train: loss: 0.0004201
[Epoch 73; Iter    36/ 1097] train: loss: 0.0010028
[Epoch 73; Iter    66/ 1097] train: loss: 0.0007393
[Epoch 73; Iter    96/ 1097] train: loss: 0.0006299
[Epoch 73; Iter   126/ 1097] train: loss: 0.0054398
[Epoch 73; Iter   156/ 1097] train: loss: 0.0017700
[Epoch 69; Iter   104/ 1097] train: loss: 0.0004268
[Epoch 69; Iter   134/ 1097] train: loss: 0.0003630
[Epoch 69; Iter   164/ 1097] train: loss: 0.0014231
[Epoch 69; Iter   194/ 1097] train: loss: 0.0008461
[Epoch 69; Iter   224/ 1097] train: loss: 0.0000719
[Epoch 69; Iter   254/ 1097] train: loss: 0.0002522
[Epoch 69; Iter   284/ 1097] train: loss: 0.0003313
[Epoch 69; Iter   314/ 1097] train: loss: 0.0018932
[Epoch 69; Iter   344/ 1097] train: loss: 0.0138509
[Epoch 69; Iter   374/ 1097] train: loss: 0.0038855
[Epoch 69; Iter   404/ 1097] train: loss: 0.0000224
[Epoch 69; Iter   434/ 1097] train: loss: 0.0025387
[Epoch 69; Iter   464/ 1097] train: loss: 0.0210439
[Epoch 69; Iter   494/ 1097] train: loss: 0.0027710
[Epoch 69; Iter   524/ 1097] train: loss: 0.0024180
[Epoch 69; Iter   554/ 1097] train: loss: 0.0023297
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000460
[Epoch 69; Iter   614/ 1097] train: loss: 0.0019070
[Epoch 69; Iter   644/ 1097] train: loss: 0.0123285
[Epoch 69; Iter   674/ 1097] train: loss: 0.0000273
[Epoch 69; Iter   704/ 1097] train: loss: 0.0010085
[Epoch 69; Iter   734/ 1097] train: loss: 0.0001148
[Epoch 69; Iter   764/ 1097] train: loss: 0.0001307
[Epoch 69; Iter   794/ 1097] train: loss: 0.0012451
[Epoch 69; Iter   824/ 1097] train: loss: 0.0002351
[Epoch 69; Iter   854/ 1097] train: loss: 0.0039273
[Epoch 69; Iter   884/ 1097] train: loss: 0.0005068
[Epoch 69; Iter   914/ 1097] train: loss: 0.0050450
[Epoch 69; Iter   944/ 1097] train: loss: 0.0002492
[Epoch 69; Iter   974/ 1097] train: loss: 0.0003516
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0005450
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0000129
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0005818
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0003496
[Epoch 69] ogbg-molhiv: 0.794612 val loss: 0.240345
[Epoch 69] ogbg-molhiv: 0.713420 test loss: 0.416214
[Epoch 70; Iter    27/ 1097] train: loss: 0.0008613
[Epoch 70; Iter    57/ 1097] train: loss: 0.0002096
[Epoch 70; Iter    87/ 1097] train: loss: 0.0019743
[Epoch 70; Iter   117/ 1097] train: loss: 0.0252805
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000372
[Epoch 70; Iter   177/ 1097] train: loss: 0.0000604
[Epoch 70; Iter   207/ 1097] train: loss: 0.0000240
[Epoch 70; Iter   237/ 1097] train: loss: 0.0048481
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001558
[Epoch 70; Iter   297/ 1097] train: loss: 0.0005671
[Epoch 70; Iter   327/ 1097] train: loss: 0.0010224
[Epoch 70; Iter   357/ 1097] train: loss: 0.0000526
[Epoch 70; Iter   387/ 1097] train: loss: 0.0001521
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000645
[Epoch 70; Iter   447/ 1097] train: loss: 0.0013317
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001335
[Epoch 70; Iter   507/ 1097] train: loss: 0.0004587
[Epoch 70; Iter   537/ 1097] train: loss: 0.0000517
[Epoch 70; Iter   567/ 1097] train: loss: 0.0338961
[Epoch 70; Iter   597/ 1097] train: loss: 0.0008405
[Epoch 70; Iter   627/ 1097] train: loss: 0.0005429
[Epoch 70; Iter   657/ 1097] train: loss: 0.0001659
[Epoch 70; Iter   687/ 1097] train: loss: 0.0145602
[Epoch 70; Iter   717/ 1097] train: loss: 0.0005364
[Epoch 70; Iter   747/ 1097] train: loss: 0.0001573
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000097
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001108
[Epoch 70; Iter   837/ 1097] train: loss: 0.0013700
[Epoch 70; Iter   867/ 1097] train: loss: 0.0002030
[Epoch 70; Iter   897/ 1097] train: loss: 0.0041881
[Epoch 70; Iter   927/ 1097] train: loss: 0.0001204
[Epoch 70; Iter   957/ 1097] train: loss: 0.0488403
[Epoch 70; Iter   987/ 1097] train: loss: 0.0007948
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0006383
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0004152
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0000548
[Epoch 70] ogbg-molhiv: 0.798253 val loss: 0.208112
[Epoch 70] ogbg-molhiv: 0.738689 test loss: 0.637073
[Epoch 71; Iter    10/ 1097] train: loss: 0.0000549
[Epoch 71; Iter    40/ 1097] train: loss: 0.0000847
[Epoch 71; Iter    70/ 1097] train: loss: 0.0001445
[Epoch 71; Iter   100/ 1097] train: loss: 0.0036921
[Epoch 71; Iter   130/ 1097] train: loss: 0.0004884
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000870
[Epoch 71; Iter   190/ 1097] train: loss: 0.0001579
[Epoch 71; Iter   220/ 1097] train: loss: 0.0004598
[Epoch 71; Iter   250/ 1097] train: loss: 0.0076843
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001018
[Epoch 71; Iter   310/ 1097] train: loss: 0.0061488
[Epoch 71; Iter   340/ 1097] train: loss: 0.0000767
[Epoch 71; Iter   370/ 1097] train: loss: 0.0000942
[Epoch 71; Iter   400/ 1097] train: loss: 0.0002464
[Epoch 71; Iter   430/ 1097] train: loss: 0.0007283
[Epoch 71; Iter   460/ 1097] train: loss: 0.0000817
[Epoch 71; Iter   490/ 1097] train: loss: 0.0015710
[Epoch 71; Iter   520/ 1097] train: loss: 0.0001045
[Epoch 71; Iter   550/ 1097] train: loss: 0.0092991
[Epoch 71; Iter   580/ 1097] train: loss: 0.0005114
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000052
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000160
[Epoch 71; Iter   670/ 1097] train: loss: 0.0006834
[Epoch 71; Iter   700/ 1097] train: loss: 0.0530996
[Epoch 71; Iter   730/ 1097] train: loss: 0.0113852
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000333
[Epoch 71; Iter   790/ 1097] train: loss: 0.0001522
[Epoch 71; Iter   820/ 1097] train: loss: 0.0586297
[Epoch 71; Iter   850/ 1097] train: loss: 0.0005767
[Epoch 71; Iter   880/ 1097] train: loss: 0.0003633
[Epoch 71; Iter   910/ 1097] train: loss: 0.0069573
[Epoch 71; Iter   940/ 1097] train: loss: 0.0019373
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002578
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0000367
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0002889
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0049833
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0018291
[Epoch 71] ogbg-molhiv: 0.783001 val loss: 0.239561
[Epoch 71] ogbg-molhiv: 0.727774 test loss: 0.553407
[Epoch 72; Iter    23/ 1097] train: loss: 0.0001422
[Epoch 72; Iter    53/ 1097] train: loss: 0.0001046
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000161
[Epoch 72; Iter   113/ 1097] train: loss: 0.0004743
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004850
[Epoch 72; Iter   173/ 1097] train: loss: 0.0005666
[Epoch 72; Iter   203/ 1097] train: loss: 0.0123669
[Epoch 72; Iter   233/ 1097] train: loss: 0.0002603
[Epoch 72; Iter   263/ 1097] train: loss: 0.0002513
[Epoch 72; Iter   293/ 1097] train: loss: 0.0001274
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000230
[Epoch 72; Iter   353/ 1097] train: loss: 0.0001129
[Epoch 72; Iter   383/ 1097] train: loss: 0.0052352
[Epoch 72; Iter   413/ 1097] train: loss: 0.0004573
[Epoch 72; Iter   443/ 1097] train: loss: 0.0002253
[Epoch 72; Iter   473/ 1097] train: loss: 0.0029440
[Epoch 72; Iter   503/ 1097] train: loss: 0.0065550
[Epoch 72; Iter   533/ 1097] train: loss: 0.0191258
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000432
[Epoch 72; Iter   593/ 1097] train: loss: 0.0005430
[Epoch 72; Iter   623/ 1097] train: loss: 0.0004862
[Epoch 72; Iter   653/ 1097] train: loss: 0.0014630
[Epoch 72; Iter   683/ 1097] train: loss: 0.0002617
[Epoch 72; Iter   713/ 1097] train: loss: 0.0023848
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000084
[Epoch 72; Iter   773/ 1097] train: loss: 0.0035138
[Epoch 72; Iter   803/ 1097] train: loss: 0.0008923
[Epoch 72; Iter   833/ 1097] train: loss: 0.0001561
[Epoch 72; Iter   863/ 1097] train: loss: 0.0004390
[Epoch 72; Iter   893/ 1097] train: loss: 0.0000656
[Epoch 72; Iter   923/ 1097] train: loss: 0.0083497
[Epoch 72; Iter   953/ 1097] train: loss: 0.0000294
[Epoch 72; Iter   983/ 1097] train: loss: 0.0004199
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0002855
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0191290
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0008397
[Epoch 72] ogbg-molhiv: 0.787640 val loss: 0.270358
[Epoch 72] ogbg-molhiv: 0.739406 test loss: 0.397660
[Epoch 73; Iter     6/ 1097] train: loss: 0.0066416
[Epoch 73; Iter    36/ 1097] train: loss: 0.0000718
[Epoch 73; Iter    66/ 1097] train: loss: 0.0007893
[Epoch 73; Iter    96/ 1097] train: loss: 0.0003543
[Epoch 73; Iter   126/ 1097] train: loss: 0.0006568
[Epoch 73; Iter   156/ 1097] train: loss: 0.0021305
[Epoch 69; Iter   104/ 1097] train: loss: 0.0029135
[Epoch 69; Iter   134/ 1097] train: loss: 0.0005737
[Epoch 69; Iter   164/ 1097] train: loss: 0.0005466
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000494
[Epoch 69; Iter   224/ 1097] train: loss: 0.0001488
[Epoch 69; Iter   254/ 1097] train: loss: 0.0005638
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001299
[Epoch 69; Iter   314/ 1097] train: loss: 0.0001670
[Epoch 69; Iter   344/ 1097] train: loss: 0.0006009
[Epoch 69; Iter   374/ 1097] train: loss: 0.0000569
[Epoch 69; Iter   404/ 1097] train: loss: 0.0007465
[Epoch 69; Iter   434/ 1097] train: loss: 0.0002278
[Epoch 69; Iter   464/ 1097] train: loss: 0.0000894
[Epoch 69; Iter   494/ 1097] train: loss: 0.0072749
[Epoch 69; Iter   524/ 1097] train: loss: 0.0001472
[Epoch 69; Iter   554/ 1097] train: loss: 0.0000382
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000065
[Epoch 69; Iter   614/ 1097] train: loss: 0.0109336
[Epoch 69; Iter   644/ 1097] train: loss: 0.0001892
[Epoch 69; Iter   674/ 1097] train: loss: 0.0005058
[Epoch 69; Iter   704/ 1097] train: loss: 0.0000228
[Epoch 69; Iter   734/ 1097] train: loss: 0.0077547
[Epoch 69; Iter   764/ 1097] train: loss: 0.0001018
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000206
[Epoch 69; Iter   824/ 1097] train: loss: 0.0000352
[Epoch 69; Iter   854/ 1097] train: loss: 0.0447718
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000272
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000330
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001537
[Epoch 69; Iter   974/ 1097] train: loss: 0.0005287
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000061
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0004177
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0002513
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0016782
[Epoch 69] ogbg-molhiv: 0.769293 val loss: 0.258938
[Epoch 69] ogbg-molhiv: 0.786722 test loss: 0.306357
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000034
[Epoch 70; Iter    57/ 1097] train: loss: 0.0000252
[Epoch 70; Iter    87/ 1097] train: loss: 0.0001694
[Epoch 70; Iter   117/ 1097] train: loss: 0.0043757
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000028
[Epoch 70; Iter   177/ 1097] train: loss: 0.0000375
[Epoch 70; Iter   207/ 1097] train: loss: 0.0005237
[Epoch 70; Iter   237/ 1097] train: loss: 0.0005093
[Epoch 70; Iter   267/ 1097] train: loss: 0.0004728
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000036
[Epoch 70; Iter   327/ 1097] train: loss: 0.0007905
[Epoch 70; Iter   357/ 1097] train: loss: 0.0005362
[Epoch 70; Iter   387/ 1097] train: loss: 0.0002410
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000785
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000707
[Epoch 70; Iter   477/ 1097] train: loss: 0.0096535
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000948
[Epoch 70; Iter   537/ 1097] train: loss: 0.0001501
[Epoch 70; Iter   567/ 1097] train: loss: 0.0008768
[Epoch 70; Iter   597/ 1097] train: loss: 0.0000274
[Epoch 70; Iter   627/ 1097] train: loss: 0.0015702
[Epoch 70; Iter   657/ 1097] train: loss: 0.0106356
[Epoch 70; Iter   687/ 1097] train: loss: 0.0001702
[Epoch 70; Iter   717/ 1097] train: loss: 0.0000445
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000123
[Epoch 70; Iter   777/ 1097] train: loss: 0.0074870
[Epoch 70; Iter   807/ 1097] train: loss: 0.0000085
[Epoch 70; Iter   837/ 1097] train: loss: 0.0008930
[Epoch 70; Iter   867/ 1097] train: loss: 0.0001649
[Epoch 70; Iter   897/ 1097] train: loss: 0.0001821
[Epoch 70; Iter   927/ 1097] train: loss: 0.0081811
[Epoch 70; Iter   957/ 1097] train: loss: 0.0007236
[Epoch 70; Iter   987/ 1097] train: loss: 0.0001162
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0002843
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000156
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0003430
[Epoch 70] ogbg-molhiv: 0.767346 val loss: 0.326789
[Epoch 70] ogbg-molhiv: 0.780874 test loss: 0.317737
[Epoch 71; Iter    10/ 1097] train: loss: 0.0004538
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001578
[Epoch 71; Iter    70/ 1097] train: loss: 0.0001331
[Epoch 71; Iter   100/ 1097] train: loss: 0.0230496
[Epoch 71; Iter   130/ 1097] train: loss: 0.0000320
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000599
[Epoch 71; Iter   190/ 1097] train: loss: 0.0003223
[Epoch 71; Iter   220/ 1097] train: loss: 0.0972073
[Epoch 71; Iter   250/ 1097] train: loss: 0.0003524
[Epoch 71; Iter   280/ 1097] train: loss: 0.0041652
[Epoch 71; Iter   310/ 1097] train: loss: 0.0007587
[Epoch 71; Iter   340/ 1097] train: loss: 0.0004072
[Epoch 71; Iter   370/ 1097] train: loss: 0.0006012
[Epoch 71; Iter   400/ 1097] train: loss: 0.0001323
[Epoch 71; Iter   430/ 1097] train: loss: 0.0002088
[Epoch 71; Iter   460/ 1097] train: loss: 0.0011307
[Epoch 71; Iter   490/ 1097] train: loss: 0.0175663
[Epoch 71; Iter   520/ 1097] train: loss: 0.0005367
[Epoch 71; Iter   550/ 1097] train: loss: 0.0008385
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000137
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000094
[Epoch 71; Iter   640/ 1097] train: loss: 0.0021661
[Epoch 71; Iter   670/ 1097] train: loss: 0.0003036
[Epoch 71; Iter   700/ 1097] train: loss: 0.0000657
[Epoch 71; Iter   730/ 1097] train: loss: 0.0000579
[Epoch 71; Iter   760/ 1097] train: loss: 0.0001078
[Epoch 71; Iter   790/ 1097] train: loss: 0.0005104
[Epoch 71; Iter   820/ 1097] train: loss: 0.0004228
[Epoch 71; Iter   850/ 1097] train: loss: 0.0022237
[Epoch 71; Iter   880/ 1097] train: loss: 0.0044097
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000173
[Epoch 71; Iter   940/ 1097] train: loss: 0.0007516
[Epoch 71; Iter   970/ 1097] train: loss: 0.0002998
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0041833
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0094210
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0002035
[Epoch 71; Iter  1090/ 1097] train: loss: 0.1013557
[Epoch 71] ogbg-molhiv: 0.810029 val loss: 0.264673
[Epoch 71] ogbg-molhiv: 0.777315 test loss: 0.313073
[Epoch 72; Iter    23/ 1097] train: loss: 0.0000569
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000479
[Epoch 72; Iter    83/ 1097] train: loss: 0.0003432
[Epoch 72; Iter   113/ 1097] train: loss: 0.0000977
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004929
[Epoch 72; Iter   173/ 1097] train: loss: 0.0008547
[Epoch 72; Iter   203/ 1097] train: loss: 0.0000027
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000630
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000805
[Epoch 72; Iter   293/ 1097] train: loss: 0.0002711
[Epoch 72; Iter   323/ 1097] train: loss: 0.0071224
[Epoch 72; Iter   353/ 1097] train: loss: 0.0324760
[Epoch 72; Iter   383/ 1097] train: loss: 0.0005926
[Epoch 72; Iter   413/ 1097] train: loss: 0.0007424
[Epoch 72; Iter   443/ 1097] train: loss: 0.0006023
[Epoch 72; Iter   473/ 1097] train: loss: 0.0246511
[Epoch 72; Iter   503/ 1097] train: loss: 0.0082529
[Epoch 72; Iter   533/ 1097] train: loss: 0.0004941
[Epoch 72; Iter   563/ 1097] train: loss: 0.0026749
[Epoch 72; Iter   593/ 1097] train: loss: 0.0000222
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000346
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000960
[Epoch 72; Iter   683/ 1097] train: loss: 0.0003305
[Epoch 72; Iter   713/ 1097] train: loss: 0.0011228
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000935
[Epoch 72; Iter   773/ 1097] train: loss: 0.0026265
[Epoch 72; Iter   803/ 1097] train: loss: 0.0003136
[Epoch 72; Iter   833/ 1097] train: loss: 0.0327321
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000386
[Epoch 72; Iter   893/ 1097] train: loss: 0.0013577
[Epoch 72; Iter   923/ 1097] train: loss: 0.0000170
[Epoch 72; Iter   953/ 1097] train: loss: 0.0072361
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000811
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0099089
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0000267
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0003184
[Epoch 72] ogbg-molhiv: 0.759492 val loss: 0.313335
[Epoch 72] ogbg-molhiv: 0.778416 test loss: 0.340840
[Epoch 73; Iter     6/ 1097] train: loss: 0.0019960
[Epoch 73; Iter    36/ 1097] train: loss: 0.0002370
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000019
[Epoch 73; Iter    96/ 1097] train: loss: 0.0004639
[Epoch 73; Iter   126/ 1097] train: loss: 0.0000333
[Epoch 73; Iter   156/ 1097] train: loss: 0.0003831
[Epoch 69; Iter   104/ 1097] train: loss: 0.0000381
[Epoch 69; Iter   134/ 1097] train: loss: 0.0000121
[Epoch 69; Iter   164/ 1097] train: loss: 0.0001456
[Epoch 69; Iter   194/ 1097] train: loss: 0.0000134
[Epoch 69; Iter   224/ 1097] train: loss: 0.0000442
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000519
[Epoch 69; Iter   284/ 1097] train: loss: 0.0000478
[Epoch 69; Iter   314/ 1097] train: loss: 0.0000324
[Epoch 69; Iter   344/ 1097] train: loss: 0.0000070
[Epoch 69; Iter   374/ 1097] train: loss: 0.0001072
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001525
[Epoch 69; Iter   434/ 1097] train: loss: 0.0001297
[Epoch 69; Iter   464/ 1097] train: loss: 0.0000152
[Epoch 69; Iter   494/ 1097] train: loss: 0.0022664
[Epoch 69; Iter   524/ 1097] train: loss: 0.0000262
[Epoch 69; Iter   554/ 1097] train: loss: 0.0048090
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000784
[Epoch 69; Iter   614/ 1097] train: loss: 0.0044764
[Epoch 69; Iter   644/ 1097] train: loss: 0.0000341
[Epoch 69; Iter   674/ 1097] train: loss: 0.0000269
[Epoch 69; Iter   704/ 1097] train: loss: 0.0015147
[Epoch 69; Iter   734/ 1097] train: loss: 0.0044121
[Epoch 69; Iter   764/ 1097] train: loss: 0.0006212
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000995
[Epoch 69; Iter   824/ 1097] train: loss: 0.0000216
[Epoch 69; Iter   854/ 1097] train: loss: 0.0000363
[Epoch 69; Iter   884/ 1097] train: loss: 0.0004912
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000809
[Epoch 69; Iter   944/ 1097] train: loss: 0.0000884
[Epoch 69; Iter   974/ 1097] train: loss: 0.0082079
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0020063
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001196
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0000643
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0000800
[Epoch 69] ogbg-molhiv: 0.705278 val loss: 2.331071
[Epoch 69] ogbg-molhiv: 0.592881 test loss: 3.505069
[Epoch 70; Iter    27/ 1097] train: loss: 0.0001601
[Epoch 70; Iter    57/ 1097] train: loss: 0.0000313
[Epoch 70; Iter    87/ 1097] train: loss: 0.0002632
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000215
[Epoch 70; Iter   147/ 1097] train: loss: 0.0044327
[Epoch 70; Iter   177/ 1097] train: loss: 0.0004310
[Epoch 70; Iter   207/ 1097] train: loss: 0.0059137
[Epoch 70; Iter   237/ 1097] train: loss: 0.0002043
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001933
[Epoch 70; Iter   297/ 1097] train: loss: 0.0000892
[Epoch 70; Iter   327/ 1097] train: loss: 0.0000263
[Epoch 70; Iter   357/ 1097] train: loss: 0.0001505
[Epoch 70; Iter   387/ 1097] train: loss: 0.0246061
[Epoch 70; Iter   417/ 1097] train: loss: 0.0000058
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000225
[Epoch 70; Iter   477/ 1097] train: loss: 0.0002105
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000466
[Epoch 70; Iter   537/ 1097] train: loss: 0.0001311
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000136
[Epoch 70; Iter   597/ 1097] train: loss: 0.0012394
[Epoch 70; Iter   627/ 1097] train: loss: 0.0000039
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000888
[Epoch 70; Iter   687/ 1097] train: loss: 0.0001749
[Epoch 70; Iter   717/ 1097] train: loss: 0.0003433
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000022
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000320
[Epoch 70; Iter   807/ 1097] train: loss: 0.0005875
[Epoch 70; Iter   837/ 1097] train: loss: 0.0001935
[Epoch 70; Iter   867/ 1097] train: loss: 0.0004459
[Epoch 70; Iter   897/ 1097] train: loss: 0.0000962
[Epoch 70; Iter   927/ 1097] train: loss: 0.0000090
[Epoch 70; Iter   957/ 1097] train: loss: 0.0000027
[Epoch 70; Iter   987/ 1097] train: loss: 0.0008869
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0000462
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0011425
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0004593
[Epoch 70] ogbg-molhiv: 0.719384 val loss: 2.371061
[Epoch 70] ogbg-molhiv: 0.650613 test loss: 2.935907
[Epoch 71; Iter    10/ 1097] train: loss: 0.0001849
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001018
[Epoch 71; Iter    70/ 1097] train: loss: 0.0000077
[Epoch 71; Iter   100/ 1097] train: loss: 0.0000956
[Epoch 71; Iter   130/ 1097] train: loss: 0.0000184
[Epoch 71; Iter   160/ 1097] train: loss: 0.0000507
[Epoch 71; Iter   190/ 1097] train: loss: 0.0120898
[Epoch 71; Iter   220/ 1097] train: loss: 0.0000605
[Epoch 71; Iter   250/ 1097] train: loss: 0.0000024
[Epoch 71; Iter   280/ 1097] train: loss: 0.0077968
[Epoch 71; Iter   310/ 1097] train: loss: 0.0010694
[Epoch 71; Iter   340/ 1097] train: loss: 0.0006109
[Epoch 71; Iter   370/ 1097] train: loss: 0.0023235
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000477
[Epoch 71; Iter   430/ 1097] train: loss: 0.0005506
[Epoch 71; Iter   460/ 1097] train: loss: 0.0001360
[Epoch 71; Iter   490/ 1097] train: loss: 0.0000019
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000088
[Epoch 71; Iter   550/ 1097] train: loss: 0.0420335
[Epoch 71; Iter   580/ 1097] train: loss: 0.0002022
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000639
[Epoch 71; Iter   640/ 1097] train: loss: 0.0000131
[Epoch 71; Iter   670/ 1097] train: loss: 0.0001916
[Epoch 71; Iter   700/ 1097] train: loss: 0.0000040
[Epoch 71; Iter   730/ 1097] train: loss: 0.0621984
[Epoch 71; Iter   760/ 1097] train: loss: 0.0000327
[Epoch 71; Iter   790/ 1097] train: loss: 0.0032107
[Epoch 71; Iter   820/ 1097] train: loss: 0.0021357
[Epoch 71; Iter   850/ 1097] train: loss: 0.0000112
[Epoch 71; Iter   880/ 1097] train: loss: 0.0002783
[Epoch 71; Iter   910/ 1097] train: loss: 0.0001941
[Epoch 71; Iter   940/ 1097] train: loss: 0.0004970
[Epoch 71; Iter   970/ 1097] train: loss: 0.0000385
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0003776
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000649
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0001354
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0000088
[Epoch 71] ogbg-molhiv: 0.719613 val loss: 0.461594
[Epoch 71] ogbg-molhiv: 0.596937 test loss: 0.576821
[Epoch 72; Iter    23/ 1097] train: loss: 0.0002790
[Epoch 72; Iter    53/ 1097] train: loss: 0.0001026
[Epoch 72; Iter    83/ 1097] train: loss: 0.0010432
[Epoch 72; Iter   113/ 1097] train: loss: 0.0000348
[Epoch 72; Iter   143/ 1097] train: loss: 0.0000040
[Epoch 72; Iter   173/ 1097] train: loss: 0.0000417
[Epoch 72; Iter   203/ 1097] train: loss: 0.0002128
[Epoch 72; Iter   233/ 1097] train: loss: 0.0066512
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000355
[Epoch 72; Iter   293/ 1097] train: loss: 0.0000264
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000280
[Epoch 72; Iter   353/ 1097] train: loss: 0.0000021
[Epoch 72; Iter   383/ 1097] train: loss: 0.0000031
[Epoch 72; Iter   413/ 1097] train: loss: 0.0001358
[Epoch 72; Iter   443/ 1097] train: loss: 0.0000205
[Epoch 72; Iter   473/ 1097] train: loss: 0.0002328
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002232
[Epoch 72; Iter   533/ 1097] train: loss: 0.0003186
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001613
[Epoch 72; Iter   593/ 1097] train: loss: 0.0000314
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000058
[Epoch 72; Iter   653/ 1097] train: loss: 0.0000066
[Epoch 72; Iter   683/ 1097] train: loss: 0.0006557
[Epoch 72; Iter   713/ 1097] train: loss: 0.0009177
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000263
[Epoch 72; Iter   773/ 1097] train: loss: 0.0670469
[Epoch 72; Iter   803/ 1097] train: loss: 0.0000211
[Epoch 72; Iter   833/ 1097] train: loss: 0.0000152
[Epoch 72; Iter   863/ 1097] train: loss: 0.0001610
[Epoch 72; Iter   893/ 1097] train: loss: 0.0001022
[Epoch 72; Iter   923/ 1097] train: loss: 0.0015420
[Epoch 72; Iter   953/ 1097] train: loss: 0.0000690
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000126
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0000023
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0002145
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0169106
[Epoch 72] ogbg-molhiv: 0.705679 val loss: 1.935648
[Epoch 72] ogbg-molhiv: 0.647500 test loss: 2.957284
[Epoch 73; Iter     6/ 1097] train: loss: 0.0000383
[Epoch 73; Iter    36/ 1097] train: loss: 0.0025910
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001343
[Epoch 73; Iter    96/ 1097] train: loss: 0.0000869
[Epoch 73; Iter   126/ 1097] train: loss: 0.0001404
[Epoch 73; Iter   156/ 1097] train: loss: 0.0024408
[Epoch 69; Iter   104/ 1097] train: loss: 0.0091167
[Epoch 69; Iter   134/ 1097] train: loss: 0.0015617
[Epoch 69; Iter   164/ 1097] train: loss: 0.0012560
[Epoch 69; Iter   194/ 1097] train: loss: 0.0005340
[Epoch 69; Iter   224/ 1097] train: loss: 0.0011736
[Epoch 69; Iter   254/ 1097] train: loss: 0.0000118
[Epoch 69; Iter   284/ 1097] train: loss: 0.0001764
[Epoch 69; Iter   314/ 1097] train: loss: 0.0015165
[Epoch 69; Iter   344/ 1097] train: loss: 0.0003471
[Epoch 69; Iter   374/ 1097] train: loss: 0.0014556
[Epoch 69; Iter   404/ 1097] train: loss: 0.0037744
[Epoch 69; Iter   434/ 1097] train: loss: 0.0292223
[Epoch 69; Iter   464/ 1097] train: loss: 0.0008172
[Epoch 69; Iter   494/ 1097] train: loss: 0.0002354
[Epoch 69; Iter   524/ 1097] train: loss: 0.0000214
[Epoch 69; Iter   554/ 1097] train: loss: 0.0005825
[Epoch 69; Iter   584/ 1097] train: loss: 0.0000897
[Epoch 69; Iter   614/ 1097] train: loss: 0.0002427
[Epoch 69; Iter   644/ 1097] train: loss: 0.0000670
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001044
[Epoch 69; Iter   704/ 1097] train: loss: 0.0002139
[Epoch 69; Iter   734/ 1097] train: loss: 0.0028128
[Epoch 69; Iter   764/ 1097] train: loss: 0.0268212
[Epoch 69; Iter   794/ 1097] train: loss: 0.0000228
[Epoch 69; Iter   824/ 1097] train: loss: 0.0273110
[Epoch 69; Iter   854/ 1097] train: loss: 0.0008712
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000979
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000202
[Epoch 69; Iter   944/ 1097] train: loss: 0.0011131
[Epoch 69; Iter   974/ 1097] train: loss: 0.0141176
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0000113
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0001198
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0014957
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0001085
[Epoch 69] ogbg-molhiv: 0.771440 val loss: 14.263231
[Epoch 69] ogbg-molhiv: 0.724303 test loss: 13.741340
[Epoch 70; Iter    27/ 1097] train: loss: 0.0000739
[Epoch 70; Iter    57/ 1097] train: loss: 0.0008507
[Epoch 70; Iter    87/ 1097] train: loss: 0.0205051
[Epoch 70; Iter   117/ 1097] train: loss: 0.0737998
[Epoch 70; Iter   147/ 1097] train: loss: 0.0000524
[Epoch 70; Iter   177/ 1097] train: loss: 0.0002895
[Epoch 70; Iter   207/ 1097] train: loss: 0.0001008
[Epoch 70; Iter   237/ 1097] train: loss: 0.0045046
[Epoch 70; Iter   267/ 1097] train: loss: 0.0001503
[Epoch 70; Iter   297/ 1097] train: loss: 0.0001430
[Epoch 70; Iter   327/ 1097] train: loss: 0.0042368
[Epoch 70; Iter   357/ 1097] train: loss: 0.0020253
[Epoch 70; Iter   387/ 1097] train: loss: 0.0706834
[Epoch 70; Iter   417/ 1097] train: loss: 0.0002288
[Epoch 70; Iter   447/ 1097] train: loss: 0.0000231
[Epoch 70; Iter   477/ 1097] train: loss: 0.0001755
[Epoch 70; Iter   507/ 1097] train: loss: 0.0001497
[Epoch 70; Iter   537/ 1097] train: loss: 0.0034335
[Epoch 70; Iter   567/ 1097] train: loss: 0.0000110
[Epoch 70; Iter   597/ 1097] train: loss: 0.0001390
[Epoch 70; Iter   627/ 1097] train: loss: 0.0022298
[Epoch 70; Iter   657/ 1097] train: loss: 0.0000111
[Epoch 70; Iter   687/ 1097] train: loss: 0.0009594
[Epoch 70; Iter   717/ 1097] train: loss: 0.0055644
[Epoch 70; Iter   747/ 1097] train: loss: 0.0000098
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000463
[Epoch 70; Iter   807/ 1097] train: loss: 0.0001342
[Epoch 70; Iter   837/ 1097] train: loss: 0.0000347
[Epoch 70; Iter   867/ 1097] train: loss: 0.0073639
[Epoch 70; Iter   897/ 1097] train: loss: 0.0028972
[Epoch 70; Iter   927/ 1097] train: loss: 0.0042973
[Epoch 70; Iter   957/ 1097] train: loss: 0.0003895
[Epoch 70; Iter   987/ 1097] train: loss: 0.0001521
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0001485
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0000458
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0025759
[Epoch 70] ogbg-molhiv: 0.776256 val loss: 1.932775
[Epoch 70] ogbg-molhiv: 0.717861 test loss: 4.149127
[Epoch 71; Iter    10/ 1097] train: loss: 0.0002526
[Epoch 71; Iter    40/ 1097] train: loss: 0.0002346
[Epoch 71; Iter    70/ 1097] train: loss: 0.0002473
[Epoch 71; Iter   100/ 1097] train: loss: 0.0073364
[Epoch 71; Iter   130/ 1097] train: loss: 0.0008833
[Epoch 71; Iter   160/ 1097] train: loss: 0.0001765
[Epoch 71; Iter   190/ 1097] train: loss: 0.0002426
[Epoch 71; Iter   220/ 1097] train: loss: 0.0002925
[Epoch 71; Iter   250/ 1097] train: loss: 0.0010195
[Epoch 71; Iter   280/ 1097] train: loss: 0.0001090
[Epoch 71; Iter   310/ 1097] train: loss: 0.0000228
[Epoch 71; Iter   340/ 1097] train: loss: 0.0010787
[Epoch 71; Iter   370/ 1097] train: loss: 0.0000194
[Epoch 71; Iter   400/ 1097] train: loss: 0.0000245
[Epoch 71; Iter   430/ 1097] train: loss: 0.0000807
[Epoch 71; Iter   460/ 1097] train: loss: 0.0037518
[Epoch 71; Iter   490/ 1097] train: loss: 0.0006365
[Epoch 71; Iter   520/ 1097] train: loss: 0.0000222
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000289
[Epoch 71; Iter   580/ 1097] train: loss: 0.0000225
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000446
[Epoch 71; Iter   640/ 1097] train: loss: 0.0229038
[Epoch 71; Iter   670/ 1097] train: loss: 0.0040990
[Epoch 71; Iter   700/ 1097] train: loss: 0.0201882
[Epoch 71; Iter   730/ 1097] train: loss: 0.0000119
[Epoch 71; Iter   760/ 1097] train: loss: 0.0001887
[Epoch 71; Iter   790/ 1097] train: loss: 0.0003902
[Epoch 71; Iter   820/ 1097] train: loss: 0.0317151
[Epoch 71; Iter   850/ 1097] train: loss: 0.0003773
[Epoch 71; Iter   880/ 1097] train: loss: 0.0050018
[Epoch 71; Iter   910/ 1097] train: loss: 0.0000267
[Epoch 71; Iter   940/ 1097] train: loss: 0.0002053
[Epoch 71; Iter   970/ 1097] train: loss: 0.0000480
[Epoch 71; Iter  1000/ 1097] train: loss: 0.1607221
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0000293
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0049620
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0454823
[Epoch 71] ogbg-molhiv: 0.764912 val loss: 6.979458
[Epoch 71] ogbg-molhiv: 0.722988 test loss: 6.300052
[Epoch 72; Iter    23/ 1097] train: loss: 0.0004355
[Epoch 72; Iter    53/ 1097] train: loss: 0.0000019
[Epoch 72; Iter    83/ 1097] train: loss: 0.0021592
[Epoch 72; Iter   113/ 1097] train: loss: 0.0370400
[Epoch 72; Iter   143/ 1097] train: loss: 0.0001125
[Epoch 72; Iter   173/ 1097] train: loss: 0.0000243
[Epoch 72; Iter   203/ 1097] train: loss: 0.0001011
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000203
[Epoch 72; Iter   263/ 1097] train: loss: 0.0000020
[Epoch 72; Iter   293/ 1097] train: loss: 0.0006350
[Epoch 72; Iter   323/ 1097] train: loss: 0.0217118
[Epoch 72; Iter   353/ 1097] train: loss: 0.0517958
[Epoch 72; Iter   383/ 1097] train: loss: 0.0001127
[Epoch 72; Iter   413/ 1097] train: loss: 0.0000987
[Epoch 72; Iter   443/ 1097] train: loss: 0.0000731
[Epoch 72; Iter   473/ 1097] train: loss: 0.0118782
[Epoch 72; Iter   503/ 1097] train: loss: 0.0043894
[Epoch 72; Iter   533/ 1097] train: loss: 0.0032288
[Epoch 72; Iter   563/ 1097] train: loss: 0.0000147
[Epoch 72; Iter   593/ 1097] train: loss: 0.0001155
[Epoch 72; Iter   623/ 1097] train: loss: 0.0000406
[Epoch 72; Iter   653/ 1097] train: loss: 0.0003388
[Epoch 72; Iter   683/ 1097] train: loss: 0.0000404
[Epoch 72; Iter   713/ 1097] train: loss: 0.0002305
[Epoch 72; Iter   743/ 1097] train: loss: 0.0016108
[Epoch 72; Iter   773/ 1097] train: loss: 0.0107803
[Epoch 72; Iter   803/ 1097] train: loss: 0.0001208
[Epoch 72; Iter   833/ 1097] train: loss: 0.0073493
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000273
[Epoch 72; Iter   893/ 1097] train: loss: 0.0013032
[Epoch 72; Iter   923/ 1097] train: loss: 0.0003526
[Epoch 72; Iter   953/ 1097] train: loss: 0.0009860
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000051
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0006640
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0003450
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0013645
[Epoch 72] ogbg-molhiv: 0.747612 val loss: 2.120755
[Epoch 72] ogbg-molhiv: 0.718737 test loss: 3.508364
[Epoch 73; Iter     6/ 1097] train: loss: 0.0010817
[Epoch 73; Iter    36/ 1097] train: loss: 0.0009260
[Epoch 73; Iter    66/ 1097] train: loss: 0.0000972
[Epoch 73; Iter    96/ 1097] train: loss: 0.0072605
[Epoch 73; Iter   126/ 1097] train: loss: 0.0003823
[Epoch 73; Iter   156/ 1097] train: loss: 0.0144883
[Epoch 69; Iter   104/ 1097] train: loss: 0.0000173
[Epoch 69; Iter   134/ 1097] train: loss: 0.0004163
[Epoch 69; Iter   164/ 1097] train: loss: 0.0001749
[Epoch 69; Iter   194/ 1097] train: loss: 0.0046157
[Epoch 69; Iter   224/ 1097] train: loss: 0.0010822
[Epoch 69; Iter   254/ 1097] train: loss: 0.0424322
[Epoch 69; Iter   284/ 1097] train: loss: 0.0042886
[Epoch 69; Iter   314/ 1097] train: loss: 0.0017452
[Epoch 69; Iter   344/ 1097] train: loss: 0.0028204
[Epoch 69; Iter   374/ 1097] train: loss: 0.0003730
[Epoch 69; Iter   404/ 1097] train: loss: 0.0001523
[Epoch 69; Iter   434/ 1097] train: loss: 0.0017274
[Epoch 69; Iter   464/ 1097] train: loss: 0.0021959
[Epoch 69; Iter   494/ 1097] train: loss: 0.0001695
[Epoch 69; Iter   524/ 1097] train: loss: 0.0002379
[Epoch 69; Iter   554/ 1097] train: loss: 0.0034673
[Epoch 69; Iter   584/ 1097] train: loss: 0.0008790
[Epoch 69; Iter   614/ 1097] train: loss: 0.0459512
[Epoch 69; Iter   644/ 1097] train: loss: 0.0636112
[Epoch 69; Iter   674/ 1097] train: loss: 0.0001736
[Epoch 69; Iter   704/ 1097] train: loss: 0.0001215
[Epoch 69; Iter   734/ 1097] train: loss: 0.0003649
[Epoch 69; Iter   764/ 1097] train: loss: 0.0009591
[Epoch 69; Iter   794/ 1097] train: loss: 0.0065862
[Epoch 69; Iter   824/ 1097] train: loss: 0.0016282
[Epoch 69; Iter   854/ 1097] train: loss: 0.0001829
[Epoch 69; Iter   884/ 1097] train: loss: 0.0000766
[Epoch 69; Iter   914/ 1097] train: loss: 0.0000677
[Epoch 69; Iter   944/ 1097] train: loss: 0.0001107
[Epoch 69; Iter   974/ 1097] train: loss: 0.0000211
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0015529
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0028582
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0000900
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0077027
[Epoch 69] ogbg-molhiv: 0.628065 val loss: 81.998429
[Epoch 69] ogbg-molhiv: 0.556231 test loss: 76.188471
[Epoch 70; Iter    27/ 1097] train: loss: 0.0003616
[Epoch 70; Iter    57/ 1097] train: loss: 0.0009695
[Epoch 70; Iter    87/ 1097] train: loss: 0.0350622
[Epoch 70; Iter   117/ 1097] train: loss: 0.0000710
[Epoch 70; Iter   147/ 1097] train: loss: 0.0061953
[Epoch 70; Iter   177/ 1097] train: loss: 0.0003094
[Epoch 70; Iter   207/ 1097] train: loss: 0.0000673
[Epoch 70; Iter   237/ 1097] train: loss: 0.0014740
[Epoch 70; Iter   267/ 1097] train: loss: 0.0029674
[Epoch 70; Iter   297/ 1097] train: loss: 0.0171278
[Epoch 70; Iter   327/ 1097] train: loss: 0.0007094
[Epoch 70; Iter   357/ 1097] train: loss: 0.0040744
[Epoch 70; Iter   387/ 1097] train: loss: 0.0004221
[Epoch 70; Iter   417/ 1097] train: loss: 0.0003035
[Epoch 70; Iter   447/ 1097] train: loss: 0.0002953
[Epoch 70; Iter   477/ 1097] train: loss: 0.0023136
[Epoch 70; Iter   507/ 1097] train: loss: 0.0000367
[Epoch 70; Iter   537/ 1097] train: loss: 0.0002206
[Epoch 70; Iter   567/ 1097] train: loss: 0.0004467
[Epoch 70; Iter   597/ 1097] train: loss: 0.0000600
[Epoch 70; Iter   627/ 1097] train: loss: 0.1293772
[Epoch 70; Iter   657/ 1097] train: loss: 0.0004562
[Epoch 70; Iter   687/ 1097] train: loss: 0.0132868
[Epoch 70; Iter   717/ 1097] train: loss: 0.0088820
[Epoch 70; Iter   747/ 1097] train: loss: 0.0169615
[Epoch 70; Iter   777/ 1097] train: loss: 0.0000137
[Epoch 70; Iter   807/ 1097] train: loss: 0.0000215
[Epoch 70; Iter   837/ 1097] train: loss: 0.0038334
[Epoch 70; Iter   867/ 1097] train: loss: 0.0495190
[Epoch 70; Iter   897/ 1097] train: loss: 0.0004618
[Epoch 70; Iter   927/ 1097] train: loss: 0.0031693
[Epoch 70; Iter   957/ 1097] train: loss: 0.0003019
[Epoch 70; Iter   987/ 1097] train: loss: 0.0010555
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0005739
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0006035
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0012123
[Epoch 70] ogbg-molhiv: 0.595955 val loss: 280.670247
[Epoch 70] ogbg-molhiv: 0.545928 test loss: 264.721632
[Epoch 71; Iter    10/ 1097] train: loss: 0.0001871
[Epoch 71; Iter    40/ 1097] train: loss: 0.0001829
[Epoch 71; Iter    70/ 1097] train: loss: 0.0004854
[Epoch 71; Iter   100/ 1097] train: loss: 0.1169637
[Epoch 71; Iter   130/ 1097] train: loss: 0.0007341
[Epoch 71; Iter   160/ 1097] train: loss: 0.0416297
[Epoch 71; Iter   190/ 1097] train: loss: 0.0569596
[Epoch 71; Iter   220/ 1097] train: loss: 0.0001824
[Epoch 71; Iter   250/ 1097] train: loss: 0.0004619
[Epoch 71; Iter   280/ 1097] train: loss: 0.0062335
[Epoch 71; Iter   310/ 1097] train: loss: 0.0030579
[Epoch 71; Iter   340/ 1097] train: loss: 0.0010342
[Epoch 71; Iter   370/ 1097] train: loss: 0.0011182
[Epoch 71; Iter   400/ 1097] train: loss: 0.0132507
[Epoch 71; Iter   430/ 1097] train: loss: 0.0006497
[Epoch 71; Iter   460/ 1097] train: loss: 0.2174922
[Epoch 71; Iter   490/ 1097] train: loss: 0.0011468
[Epoch 71; Iter   520/ 1097] train: loss: 0.0011252
[Epoch 71; Iter   550/ 1097] train: loss: 0.0000808
[Epoch 71; Iter   580/ 1097] train: loss: 0.0038960
[Epoch 71; Iter   610/ 1097] train: loss: 0.0000477
[Epoch 71; Iter   640/ 1097] train: loss: 0.0005329
[Epoch 71; Iter   670/ 1097] train: loss: 0.0001659
[Epoch 71; Iter   700/ 1097] train: loss: 0.1524809
[Epoch 71; Iter   730/ 1097] train: loss: 0.0067918
[Epoch 71; Iter   760/ 1097] train: loss: 0.0514076
[Epoch 71; Iter   790/ 1097] train: loss: 0.0014129
[Epoch 71; Iter   820/ 1097] train: loss: 0.0031792
[Epoch 71; Iter   850/ 1097] train: loss: 0.0195211
[Epoch 71; Iter   880/ 1097] train: loss: 0.0078805
[Epoch 71; Iter   910/ 1097] train: loss: 0.0018005
[Epoch 71; Iter   940/ 1097] train: loss: 0.0009195
[Epoch 71; Iter   970/ 1097] train: loss: 0.0010486
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0095622
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0050871
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0105759
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0006315
[Epoch 71] ogbg-molhiv: 0.646629 val loss: 29.903494
[Epoch 71] ogbg-molhiv: 0.564283 test loss: 28.444888
[Epoch 72; Iter    23/ 1097] train: loss: 0.0010847
[Epoch 72; Iter    53/ 1097] train: loss: 0.0021177
[Epoch 72; Iter    83/ 1097] train: loss: 0.0000309
[Epoch 72; Iter   113/ 1097] train: loss: 0.0004853
[Epoch 72; Iter   143/ 1097] train: loss: 0.0004385
[Epoch 72; Iter   173/ 1097] train: loss: 0.0003169
[Epoch 72; Iter   203/ 1097] train: loss: 0.0004162
[Epoch 72; Iter   233/ 1097] train: loss: 0.0000262
[Epoch 72; Iter   263/ 1097] train: loss: 0.0750820
[Epoch 72; Iter   293/ 1097] train: loss: 0.0001001
[Epoch 72; Iter   323/ 1097] train: loss: 0.0000889
[Epoch 72; Iter   353/ 1097] train: loss: 0.0002070
[Epoch 72; Iter   383/ 1097] train: loss: 0.0000396
[Epoch 72; Iter   413/ 1097] train: loss: 0.0345573
[Epoch 72; Iter   443/ 1097] train: loss: 0.0039971
[Epoch 72; Iter   473/ 1097] train: loss: 0.0000966
[Epoch 72; Iter   503/ 1097] train: loss: 0.0002261
[Epoch 72; Iter   533/ 1097] train: loss: 0.0011818
[Epoch 72; Iter   563/ 1097] train: loss: 0.0001253
[Epoch 72; Iter   593/ 1097] train: loss: 0.0072376
[Epoch 72; Iter   623/ 1097] train: loss: 0.0366509
[Epoch 72; Iter   653/ 1097] train: loss: 0.0141456
[Epoch 72; Iter   683/ 1097] train: loss: 0.0117797
[Epoch 72; Iter   713/ 1097] train: loss: 0.0001363
[Epoch 72; Iter   743/ 1097] train: loss: 0.0000850
[Epoch 72; Iter   773/ 1097] train: loss: 0.0086044
[Epoch 72; Iter   803/ 1097] train: loss: 0.0000338
[Epoch 72; Iter   833/ 1097] train: loss: 0.0531110
[Epoch 72; Iter   863/ 1097] train: loss: 0.0000067
[Epoch 72; Iter   893/ 1097] train: loss: 0.0199273
[Epoch 72; Iter   923/ 1097] train: loss: 0.1243393
[Epoch 72; Iter   953/ 1097] train: loss: 0.0016358
[Epoch 72; Iter   983/ 1097] train: loss: 0.0000245
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0014200
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0780304
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0009500
[Epoch 72] ogbg-molhiv: 0.601977 val loss: 51.916261
[Epoch 72] ogbg-molhiv: 0.546712 test loss: 50.321965
[Epoch 73; Iter     6/ 1097] train: loss: 0.0001787
[Epoch 73; Iter    36/ 1097] train: loss: 0.0010909
[Epoch 73; Iter    66/ 1097] train: loss: 0.0001175
[Epoch 73; Iter    96/ 1097] train: loss: 0.0011444
[Epoch 73; Iter   126/ 1097] train: loss: 0.0002208
[Epoch 73; Iter   156/ 1097] train: loss: 0.0013537
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0646751
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0480215
[Epoch 56; Iter  1075/ 1097] train: loss: 0.1316475
[Epoch 56] ogbg-molhiv: 0.806909 val loss: 0.096466
[Epoch 56] ogbg-molhiv: 0.749342 test loss: 0.168501
[Epoch 57; Iter     8/ 1097] train: loss: 0.0339389
[Epoch 57; Iter    38/ 1097] train: loss: 0.0372796
[Epoch 57; Iter    68/ 1097] train: loss: 0.0603657
[Epoch 57; Iter    98/ 1097] train: loss: 0.0253719
[Epoch 57; Iter   128/ 1097] train: loss: 0.0371780
[Epoch 57; Iter   158/ 1097] train: loss: 0.0975750
[Epoch 57; Iter   188/ 1097] train: loss: 0.0099545
[Epoch 57; Iter   218/ 1097] train: loss: 0.0097855
[Epoch 57; Iter   248/ 1097] train: loss: 0.0499757
[Epoch 57; Iter   278/ 1097] train: loss: 0.0152312
[Epoch 57; Iter   308/ 1097] train: loss: 0.1533651
[Epoch 57; Iter   338/ 1097] train: loss: 0.0548816
[Epoch 57; Iter   368/ 1097] train: loss: 0.0498567
[Epoch 57; Iter   398/ 1097] train: loss: 0.1236711
[Epoch 57; Iter   428/ 1097] train: loss: 0.0786215
[Epoch 57; Iter   458/ 1097] train: loss: 0.2028264
[Epoch 57; Iter   488/ 1097] train: loss: 0.0136928
[Epoch 57; Iter   518/ 1097] train: loss: 0.1625620
[Epoch 57; Iter   548/ 1097] train: loss: 0.0090235
[Epoch 57; Iter   578/ 1097] train: loss: 0.0165785
[Epoch 57; Iter   608/ 1097] train: loss: 0.2961018
[Epoch 57; Iter   638/ 1097] train: loss: 0.2127641
[Epoch 57; Iter   668/ 1097] train: loss: 0.0272493
[Epoch 57; Iter   698/ 1097] train: loss: 0.2614498
[Epoch 57; Iter   728/ 1097] train: loss: 0.0678253
[Epoch 57; Iter   758/ 1097] train: loss: 0.0714133
[Epoch 57; Iter   788/ 1097] train: loss: 0.0081145
[Epoch 57; Iter   818/ 1097] train: loss: 0.0281551
[Epoch 57; Iter   848/ 1097] train: loss: 0.0120524
[Epoch 57; Iter   878/ 1097] train: loss: 0.0098857
[Epoch 57; Iter   908/ 1097] train: loss: 0.1325600
[Epoch 57; Iter   938/ 1097] train: loss: 0.0238277
[Epoch 57; Iter   968/ 1097] train: loss: 0.1889798
[Epoch 57; Iter   998/ 1097] train: loss: 0.0083721
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0150860
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0116635
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0072997
[Epoch 57] ogbg-molhiv: 0.810449 val loss: 0.092903
[Epoch 57] ogbg-molhiv: 0.750036 test loss: 0.167489
[Epoch 58; Iter    21/ 1097] train: loss: 0.0092567
[Epoch 58; Iter    51/ 1097] train: loss: 0.0329749
[Epoch 58; Iter    81/ 1097] train: loss: 0.0445025
[Epoch 58; Iter   111/ 1097] train: loss: 0.0413188
[Epoch 58; Iter   141/ 1097] train: loss: 0.1029785
[Epoch 58; Iter   171/ 1097] train: loss: 0.0164561
[Epoch 58; Iter   201/ 1097] train: loss: 0.0441962
[Epoch 58; Iter   231/ 1097] train: loss: 0.1807076
[Epoch 58; Iter   261/ 1097] train: loss: 0.0438652
[Epoch 58; Iter   291/ 1097] train: loss: 0.0066442
[Epoch 58; Iter   321/ 1097] train: loss: 0.0263170
[Epoch 58; Iter   351/ 1097] train: loss: 0.0206694
[Epoch 58; Iter   381/ 1097] train: loss: 0.0945044
[Epoch 58; Iter   411/ 1097] train: loss: 0.0335232
[Epoch 58; Iter   441/ 1097] train: loss: 0.0192694
[Epoch 58; Iter   471/ 1097] train: loss: 0.0113879
[Epoch 58; Iter   501/ 1097] train: loss: 0.0162619
[Epoch 58; Iter   531/ 1097] train: loss: 0.0375030
[Epoch 58; Iter   561/ 1097] train: loss: 0.0104467
[Epoch 58; Iter   591/ 1097] train: loss: 0.0249188
[Epoch 58; Iter   621/ 1097] train: loss: 0.0202875
[Epoch 58; Iter   651/ 1097] train: loss: 0.0224673
[Epoch 58; Iter   681/ 1097] train: loss: 0.0476107
[Epoch 58; Iter   711/ 1097] train: loss: 0.0197380
[Epoch 58; Iter   741/ 1097] train: loss: 0.0234999
[Epoch 58; Iter   771/ 1097] train: loss: 0.0629591
[Epoch 58; Iter   801/ 1097] train: loss: 0.0045923
[Epoch 58; Iter   831/ 1097] train: loss: 0.0088216
[Epoch 58; Iter   861/ 1097] train: loss: 0.0650030
[Epoch 58; Iter   891/ 1097] train: loss: 0.0545651
[Epoch 58; Iter   921/ 1097] train: loss: 0.1624526
[Epoch 58; Iter   951/ 1097] train: loss: 0.0859139
[Epoch 58; Iter   981/ 1097] train: loss: 0.0105616
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0095978
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0081311
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0240619
[Epoch 58] ogbg-molhiv: 0.811860 val loss: 0.097801
[Epoch 58] ogbg-molhiv: 0.741741 test loss: 0.176401
[Epoch 59; Iter     4/ 1097] train: loss: 0.0128515
[Epoch 59; Iter    34/ 1097] train: loss: 0.0187807
[Epoch 59; Iter    64/ 1097] train: loss: 0.0615896
[Epoch 59; Iter    94/ 1097] train: loss: 0.1744278
[Epoch 59; Iter   124/ 1097] train: loss: 0.0030618
[Epoch 59; Iter   154/ 1097] train: loss: 0.0563165
[Epoch 59; Iter   184/ 1097] train: loss: 0.0116480
[Epoch 59; Iter   214/ 1097] train: loss: 0.0126162
[Epoch 59; Iter   244/ 1097] train: loss: 0.0304646
[Epoch 59; Iter   274/ 1097] train: loss: 0.0313288
[Epoch 59; Iter   304/ 1097] train: loss: 0.1645621
[Epoch 59; Iter   334/ 1097] train: loss: 0.0192458
[Epoch 59; Iter   364/ 1097] train: loss: 0.0099962
[Epoch 59; Iter   394/ 1097] train: loss: 0.0248091
[Epoch 59; Iter   424/ 1097] train: loss: 0.0578628
[Epoch 59; Iter   454/ 1097] train: loss: 0.0574081
[Epoch 59; Iter   484/ 1097] train: loss: 0.0060381
[Epoch 59; Iter   514/ 1097] train: loss: 0.0103523
[Epoch 59; Iter   544/ 1097] train: loss: 0.0336456
[Epoch 59; Iter   574/ 1097] train: loss: 0.0236691
[Epoch 59; Iter   604/ 1097] train: loss: 0.0364679
[Epoch 59; Iter   634/ 1097] train: loss: 0.0710812
[Epoch 59; Iter   664/ 1097] train: loss: 0.0035215
[Epoch 59; Iter   694/ 1097] train: loss: 0.0042108
[Epoch 59; Iter   724/ 1097] train: loss: 0.1009505
[Epoch 59; Iter   754/ 1097] train: loss: 0.0907407
[Epoch 59; Iter   784/ 1097] train: loss: 0.0101059
[Epoch 59; Iter   814/ 1097] train: loss: 0.0621389
[Epoch 59; Iter   844/ 1097] train: loss: 0.1114663
[Epoch 59; Iter   874/ 1097] train: loss: 0.0114983
[Epoch 59; Iter   904/ 1097] train: loss: 0.0959191
[Epoch 59; Iter   934/ 1097] train: loss: 0.1722826
[Epoch 59; Iter   964/ 1097] train: loss: 0.0589801
[Epoch 59; Iter   994/ 1097] train: loss: 0.0119553
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0059604
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0063026
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0753599
[Epoch 59] ogbg-molhiv: 0.796189 val loss: 0.100859
[Epoch 59] ogbg-molhiv: 0.745418 test loss: 0.175570
[Epoch 60; Iter    17/ 1097] train: loss: 0.0418234
[Epoch 60; Iter    47/ 1097] train: loss: 0.0116016
[Epoch 60; Iter    77/ 1097] train: loss: 0.0439185
[Epoch 60; Iter   107/ 1097] train: loss: 0.0285942
[Epoch 60; Iter   137/ 1097] train: loss: 0.0900491
[Epoch 60; Iter   167/ 1097] train: loss: 0.0052405
[Epoch 60; Iter   197/ 1097] train: loss: 0.0169892
[Epoch 60; Iter   227/ 1097] train: loss: 0.0047498
[Epoch 60; Iter   257/ 1097] train: loss: 0.0418673
[Epoch 60; Iter   287/ 1097] train: loss: 0.0200373
[Epoch 60; Iter   317/ 1097] train: loss: 0.0432592
[Epoch 60; Iter   347/ 1097] train: loss: 0.0255580
[Epoch 60; Iter   377/ 1097] train: loss: 0.1083201
[Epoch 60; Iter   407/ 1097] train: loss: 0.0110860
[Epoch 60; Iter   437/ 1097] train: loss: 0.0868942
[Epoch 60; Iter   467/ 1097] train: loss: 0.1216777
[Epoch 60; Iter   497/ 1097] train: loss: 0.0150226
[Epoch 60; Iter   527/ 1097] train: loss: 0.0121173
[Epoch 60; Iter   557/ 1097] train: loss: 0.1295907
[Epoch 60; Iter   587/ 1097] train: loss: 0.0499055
[Epoch 60; Iter   617/ 1097] train: loss: 0.0441445
[Epoch 60; Iter   647/ 1097] train: loss: 0.1112411
[Epoch 60; Iter   677/ 1097] train: loss: 0.0163760
[Epoch 60; Iter   707/ 1097] train: loss: 0.0145108
[Epoch 60; Iter   737/ 1097] train: loss: 0.0220055
[Epoch 60; Iter   767/ 1097] train: loss: 0.0327781
[Epoch 60; Iter   797/ 1097] train: loss: 0.0040244
[Epoch 60; Iter   827/ 1097] train: loss: 0.0128939
[Epoch 60; Iter   857/ 1097] train: loss: 0.0119334
[Epoch 60; Iter   887/ 1097] train: loss: 0.0694564
[Epoch 60; Iter   917/ 1097] train: loss: 0.0123322
[Epoch 60; Iter   947/ 1097] train: loss: 0.0137059
[Epoch 60; Iter   977/ 1097] train: loss: 0.0221031
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0064835
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0075448
[Epoch 60; Iter  1067/ 1097] train: loss: 0.1084183
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0872894
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0215170
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0259709
[Epoch 56] ogbg-molhiv: 0.789738 val loss: 0.157601
[Epoch 56] ogbg-molhiv: 0.735959 test loss: 0.295415
[Epoch 57; Iter     8/ 1097] train: loss: 0.0344893
[Epoch 57; Iter    38/ 1097] train: loss: 0.0040818
[Epoch 57; Iter    68/ 1097] train: loss: 0.0338953
[Epoch 57; Iter    98/ 1097] train: loss: 0.0214095
[Epoch 57; Iter   128/ 1097] train: loss: 0.1472165
[Epoch 57; Iter   158/ 1097] train: loss: 0.0096489
[Epoch 57; Iter   188/ 1097] train: loss: 0.0991813
[Epoch 57; Iter   218/ 1097] train: loss: 0.0276012
[Epoch 57; Iter   248/ 1097] train: loss: 0.1492409
[Epoch 57; Iter   278/ 1097] train: loss: 0.0345138
[Epoch 57; Iter   308/ 1097] train: loss: 0.0535603
[Epoch 57; Iter   338/ 1097] train: loss: 0.1318976
[Epoch 57; Iter   368/ 1097] train: loss: 0.0873305
[Epoch 57; Iter   398/ 1097] train: loss: 0.0077414
[Epoch 57; Iter   428/ 1097] train: loss: 0.0903218
[Epoch 57; Iter   458/ 1097] train: loss: 0.0137794
[Epoch 57; Iter   488/ 1097] train: loss: 0.2130148
[Epoch 57; Iter   518/ 1097] train: loss: 0.0623615
[Epoch 57; Iter   548/ 1097] train: loss: 0.0232496
[Epoch 57; Iter   578/ 1097] train: loss: 0.0023180
[Epoch 57; Iter   608/ 1097] train: loss: 0.0705458
[Epoch 57; Iter   638/ 1097] train: loss: 0.1139480
[Epoch 57; Iter   668/ 1097] train: loss: 0.0537937
[Epoch 57; Iter   698/ 1097] train: loss: 0.0733790
[Epoch 57; Iter   728/ 1097] train: loss: 0.0588967
[Epoch 57; Iter   758/ 1097] train: loss: 0.1161771
[Epoch 57; Iter   788/ 1097] train: loss: 0.1156986
[Epoch 57; Iter   818/ 1097] train: loss: 0.0430762
[Epoch 57; Iter   848/ 1097] train: loss: 0.1978732
[Epoch 57; Iter   878/ 1097] train: loss: 0.0800308
[Epoch 57; Iter   908/ 1097] train: loss: 0.0616638
[Epoch 57; Iter   938/ 1097] train: loss: 0.0254997
[Epoch 57; Iter   968/ 1097] train: loss: 0.0307957
[Epoch 57; Iter   998/ 1097] train: loss: 0.0545103
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0507900
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0073694
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0127601
[Epoch 57] ogbg-molhiv: 0.780809 val loss: 0.109631
[Epoch 57] ogbg-molhiv: 0.717496 test loss: 0.207125
[Epoch 58; Iter    21/ 1097] train: loss: 0.0275419
[Epoch 58; Iter    51/ 1097] train: loss: 0.0089390
[Epoch 58; Iter    81/ 1097] train: loss: 0.0310412
[Epoch 58; Iter   111/ 1097] train: loss: 0.0253173
[Epoch 58; Iter   141/ 1097] train: loss: 0.0130562
[Epoch 58; Iter   171/ 1097] train: loss: 0.0219531
[Epoch 58; Iter   201/ 1097] train: loss: 0.1705127
[Epoch 58; Iter   231/ 1097] train: loss: 0.0078070
[Epoch 58; Iter   261/ 1097] train: loss: 0.1192164
[Epoch 58; Iter   291/ 1097] train: loss: 0.0729196
[Epoch 58; Iter   321/ 1097] train: loss: 0.0697696
[Epoch 58; Iter   351/ 1097] train: loss: 0.0088624
[Epoch 58; Iter   381/ 1097] train: loss: 0.0068142
[Epoch 58; Iter   411/ 1097] train: loss: 0.0481604
[Epoch 58; Iter   441/ 1097] train: loss: 0.0167099
[Epoch 58; Iter   471/ 1097] train: loss: 0.0794031
[Epoch 58; Iter   501/ 1097] train: loss: 0.0988400
[Epoch 58; Iter   531/ 1097] train: loss: 0.1514748
[Epoch 58; Iter   561/ 1097] train: loss: 0.0334759
[Epoch 58; Iter   591/ 1097] train: loss: 0.0071100
[Epoch 58; Iter   621/ 1097] train: loss: 0.0249605
[Epoch 58; Iter   651/ 1097] train: loss: 0.0162277
[Epoch 58; Iter   681/ 1097] train: loss: 0.1831346
[Epoch 58; Iter   711/ 1097] train: loss: 0.0050989
[Epoch 58; Iter   741/ 1097] train: loss: 0.0289183
[Epoch 58; Iter   771/ 1097] train: loss: 0.0579506
[Epoch 58; Iter   801/ 1097] train: loss: 0.0095160
[Epoch 58; Iter   831/ 1097] train: loss: 0.0209693
[Epoch 58; Iter   861/ 1097] train: loss: 0.0090828
[Epoch 58; Iter   891/ 1097] train: loss: 0.0168245
[Epoch 58; Iter   921/ 1097] train: loss: 0.0105299
[Epoch 58; Iter   951/ 1097] train: loss: 0.0489018
[Epoch 58; Iter   981/ 1097] train: loss: 0.0270167
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0068067
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0078921
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0110731
[Epoch 58] ogbg-molhiv: 0.794352 val loss: 0.094756
[Epoch 58] ogbg-molhiv: 0.733021 test loss: 0.178677
[Epoch 59; Iter     4/ 1097] train: loss: 0.0030629
[Epoch 59; Iter    34/ 1097] train: loss: 0.0182011
[Epoch 59; Iter    64/ 1097] train: loss: 0.0203273
[Epoch 59; Iter    94/ 1097] train: loss: 0.0619823
[Epoch 59; Iter   124/ 1097] train: loss: 0.0135770
[Epoch 59; Iter   154/ 1097] train: loss: 0.0536823
[Epoch 59; Iter   184/ 1097] train: loss: 0.0233858
[Epoch 59; Iter   214/ 1097] train: loss: 0.0620351
[Epoch 59; Iter   244/ 1097] train: loss: 0.1583385
[Epoch 59; Iter   274/ 1097] train: loss: 0.0211355
[Epoch 59; Iter   304/ 1097] train: loss: 0.1145973
[Epoch 59; Iter   334/ 1097] train: loss: 0.0533456
[Epoch 59; Iter   364/ 1097] train: loss: 0.0175049
[Epoch 59; Iter   394/ 1097] train: loss: 0.0206648
[Epoch 59; Iter   424/ 1097] train: loss: 0.0290611
[Epoch 59; Iter   454/ 1097] train: loss: 0.0594698
[Epoch 59; Iter   484/ 1097] train: loss: 0.0078285
[Epoch 59; Iter   514/ 1097] train: loss: 0.0631186
[Epoch 59; Iter   544/ 1097] train: loss: 0.0261563
[Epoch 59; Iter   574/ 1097] train: loss: 0.2225500
[Epoch 59; Iter   604/ 1097] train: loss: 0.0144564
[Epoch 59; Iter   634/ 1097] train: loss: 0.0444791
[Epoch 59; Iter   664/ 1097] train: loss: 0.1363302
[Epoch 59; Iter   694/ 1097] train: loss: 0.0109822
[Epoch 59; Iter   724/ 1097] train: loss: 0.0161542
[Epoch 59; Iter   754/ 1097] train: loss: 0.0528832
[Epoch 59; Iter   784/ 1097] train: loss: 0.1025538
[Epoch 59; Iter   814/ 1097] train: loss: 0.0210915
[Epoch 59; Iter   844/ 1097] train: loss: 0.0829426
[Epoch 59; Iter   874/ 1097] train: loss: 0.0353822
[Epoch 59; Iter   904/ 1097] train: loss: 0.2038570
[Epoch 59; Iter   934/ 1097] train: loss: 0.0945501
[Epoch 59; Iter   964/ 1097] train: loss: 0.0227925
[Epoch 59; Iter   994/ 1097] train: loss: 0.0162646
[Epoch 59; Iter  1024/ 1097] train: loss: 0.1023480
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0120457
[Epoch 59; Iter  1084/ 1097] train: loss: 0.1238150
[Epoch 59] ogbg-molhiv: 0.805115 val loss: 0.093117
[Epoch 59] ogbg-molhiv: 0.743962 test loss: 0.175967
[Epoch 60; Iter    17/ 1097] train: loss: 0.0162448
[Epoch 60; Iter    47/ 1097] train: loss: 0.0146074
[Epoch 60; Iter    77/ 1097] train: loss: 0.0199540
[Epoch 60; Iter   107/ 1097] train: loss: 0.0144851
[Epoch 60; Iter   137/ 1097] train: loss: 0.0079584
[Epoch 60; Iter   167/ 1097] train: loss: 0.0454675
[Epoch 60; Iter   197/ 1097] train: loss: 0.0373284
[Epoch 60; Iter   227/ 1097] train: loss: 0.0963887
[Epoch 60; Iter   257/ 1097] train: loss: 0.0503750
[Epoch 60; Iter   287/ 1097] train: loss: 0.0201073
[Epoch 60; Iter   317/ 1097] train: loss: 0.0154411
[Epoch 60; Iter   347/ 1097] train: loss: 0.0138912
[Epoch 60; Iter   377/ 1097] train: loss: 0.0161627
[Epoch 60; Iter   407/ 1097] train: loss: 0.0610920
[Epoch 60; Iter   437/ 1097] train: loss: 0.0242893
[Epoch 60; Iter   467/ 1097] train: loss: 0.0093347
[Epoch 60; Iter   497/ 1097] train: loss: 0.0278669
[Epoch 60; Iter   527/ 1097] train: loss: 0.0105353
[Epoch 60; Iter   557/ 1097] train: loss: 0.0725771
[Epoch 60; Iter   587/ 1097] train: loss: 0.0255585
[Epoch 60; Iter   617/ 1097] train: loss: 0.0231405
[Epoch 60; Iter   647/ 1097] train: loss: 0.0035981
[Epoch 60; Iter   677/ 1097] train: loss: 0.0094982
[Epoch 60; Iter   707/ 1097] train: loss: 0.0792416
[Epoch 60; Iter   737/ 1097] train: loss: 0.0174109
[Epoch 60; Iter   767/ 1097] train: loss: 0.0394705
[Epoch 60; Iter   797/ 1097] train: loss: 0.0172103
[Epoch 60; Iter   827/ 1097] train: loss: 0.0378199
[Epoch 60; Iter   857/ 1097] train: loss: 0.1503452
[Epoch 60; Iter   887/ 1097] train: loss: 0.0102370
[Epoch 60; Iter   917/ 1097] train: loss: 0.2341542
[Epoch 60; Iter   947/ 1097] train: loss: 0.2127752
[Epoch 60; Iter   977/ 1097] train: loss: 0.0123662
[Epoch 60; Iter  1007/ 1097] train: loss: 0.1316673
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0148247
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0240706
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0208898
[Epoch 56; Iter  1045/ 1097] train: loss: 0.1769281
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0310669
[Epoch 56] ogbg-molhiv: 0.803749 val loss: 0.095952
[Epoch 56] ogbg-molhiv: 0.752403 test loss: 0.167980
[Epoch 57; Iter     8/ 1097] train: loss: 0.0400393
[Epoch 57; Iter    38/ 1097] train: loss: 0.0171711
[Epoch 57; Iter    68/ 1097] train: loss: 0.1012090
[Epoch 57; Iter    98/ 1097] train: loss: 0.1158598
[Epoch 57; Iter   128/ 1097] train: loss: 0.0095224
[Epoch 57; Iter   158/ 1097] train: loss: 0.0100378
[Epoch 57; Iter   188/ 1097] train: loss: 0.0030492
[Epoch 57; Iter   218/ 1097] train: loss: 0.0056475
[Epoch 57; Iter   248/ 1097] train: loss: 0.0313264
[Epoch 57; Iter   278/ 1097] train: loss: 0.0079817
[Epoch 57; Iter   308/ 1097] train: loss: 0.0264327
[Epoch 57; Iter   338/ 1097] train: loss: 0.0150385
[Epoch 57; Iter   368/ 1097] train: loss: 0.0127295
[Epoch 57; Iter   398/ 1097] train: loss: 0.0172625
[Epoch 57; Iter   428/ 1097] train: loss: 0.0090954
[Epoch 57; Iter   458/ 1097] train: loss: 0.0320685
[Epoch 57; Iter   488/ 1097] train: loss: 0.0032037
[Epoch 57; Iter   518/ 1097] train: loss: 0.0033817
[Epoch 57; Iter   548/ 1097] train: loss: 0.1065569
[Epoch 57; Iter   578/ 1097] train: loss: 0.0640620
[Epoch 57; Iter   608/ 1097] train: loss: 0.0476266
[Epoch 57; Iter   638/ 1097] train: loss: 0.0224127
[Epoch 57; Iter   668/ 1097] train: loss: 0.0282106
[Epoch 57; Iter   698/ 1097] train: loss: 0.0284457
[Epoch 57; Iter   728/ 1097] train: loss: 0.0182258
[Epoch 57; Iter   758/ 1097] train: loss: 0.0058613
[Epoch 57; Iter   788/ 1097] train: loss: 0.0943961
[Epoch 57; Iter   818/ 1097] train: loss: 0.0440877
[Epoch 57; Iter   848/ 1097] train: loss: 0.0094090
[Epoch 57; Iter   878/ 1097] train: loss: 0.0049062
[Epoch 57; Iter   908/ 1097] train: loss: 0.0261578
[Epoch 57; Iter   938/ 1097] train: loss: 0.0180835
[Epoch 57; Iter   968/ 1097] train: loss: 0.0349557
[Epoch 57; Iter   998/ 1097] train: loss: 0.0801061
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0051808
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0038230
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0034458
[Epoch 57] ogbg-molhiv: 0.795142 val loss: 0.103370
[Epoch 57] ogbg-molhiv: 0.734311 test loss: 0.197698
[Epoch 58; Iter    21/ 1097] train: loss: 0.0046634
[Epoch 58; Iter    51/ 1097] train: loss: 0.0162445
[Epoch 58; Iter    81/ 1097] train: loss: 0.0258088
[Epoch 58; Iter   111/ 1097] train: loss: 0.0110892
[Epoch 58; Iter   141/ 1097] train: loss: 0.0072721
[Epoch 58; Iter   171/ 1097] train: loss: 0.0077335
[Epoch 58; Iter   201/ 1097] train: loss: 0.0152156
[Epoch 58; Iter   231/ 1097] train: loss: 0.0347738
[Epoch 58; Iter   261/ 1097] train: loss: 0.0076510
[Epoch 58; Iter   291/ 1097] train: loss: 0.0091329
[Epoch 58; Iter   321/ 1097] train: loss: 0.0444646
[Epoch 58; Iter   351/ 1097] train: loss: 0.1047874
[Epoch 58; Iter   381/ 1097] train: loss: 0.1511738
[Epoch 58; Iter   411/ 1097] train: loss: 0.0560259
[Epoch 58; Iter   441/ 1097] train: loss: 0.0124581
[Epoch 58; Iter   471/ 1097] train: loss: 0.0141626
[Epoch 58; Iter   501/ 1097] train: loss: 0.0083223
[Epoch 58; Iter   531/ 1097] train: loss: 0.0072215
[Epoch 58; Iter   561/ 1097] train: loss: 0.0343170
[Epoch 58; Iter   591/ 1097] train: loss: 0.0428632
[Epoch 58; Iter   621/ 1097] train: loss: 0.0790895
[Epoch 58; Iter   651/ 1097] train: loss: 0.0340439
[Epoch 58; Iter   681/ 1097] train: loss: 0.0165232
[Epoch 58; Iter   711/ 1097] train: loss: 0.3055798
[Epoch 58; Iter   741/ 1097] train: loss: 0.0629857
[Epoch 58; Iter   771/ 1097] train: loss: 0.0140334
[Epoch 58; Iter   801/ 1097] train: loss: 0.0106152
[Epoch 58; Iter   831/ 1097] train: loss: 0.0644748
[Epoch 58; Iter   861/ 1097] train: loss: 0.0035829
[Epoch 58; Iter   891/ 1097] train: loss: 0.0060032
[Epoch 58; Iter   921/ 1097] train: loss: 0.0067173
[Epoch 58; Iter   951/ 1097] train: loss: 0.0159437
[Epoch 58; Iter   981/ 1097] train: loss: 0.0848527
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0071230
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0440675
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0371791
[Epoch 58] ogbg-molhiv: 0.807494 val loss: 0.114857
[Epoch 58] ogbg-molhiv: 0.753914 test loss: 0.198956
[Epoch 59; Iter     4/ 1097] train: loss: 0.0094629
[Epoch 59; Iter    34/ 1097] train: loss: 0.0138768
[Epoch 59; Iter    64/ 1097] train: loss: 0.0194466
[Epoch 59; Iter    94/ 1097] train: loss: 0.1060402
[Epoch 59; Iter   124/ 1097] train: loss: 0.0311159
[Epoch 59; Iter   154/ 1097] train: loss: 0.0069294
[Epoch 59; Iter   184/ 1097] train: loss: 0.0096790
[Epoch 59; Iter   214/ 1097] train: loss: 0.0186958
[Epoch 59; Iter   244/ 1097] train: loss: 0.0016423
[Epoch 59; Iter   274/ 1097] train: loss: 0.0068355
[Epoch 59; Iter   304/ 1097] train: loss: 0.0415103
[Epoch 59; Iter   334/ 1097] train: loss: 0.0997775
[Epoch 59; Iter   364/ 1097] train: loss: 0.0588661
[Epoch 59; Iter   394/ 1097] train: loss: 0.0050041
[Epoch 59; Iter   424/ 1097] train: loss: 0.0058392
[Epoch 59; Iter   454/ 1097] train: loss: 0.0071009
[Epoch 59; Iter   484/ 1097] train: loss: 0.1241786
[Epoch 59; Iter   514/ 1097] train: loss: 0.1167046
[Epoch 59; Iter   544/ 1097] train: loss: 0.0606954
[Epoch 59; Iter   574/ 1097] train: loss: 0.0034643
[Epoch 59; Iter   604/ 1097] train: loss: 0.0134693
[Epoch 59; Iter   634/ 1097] train: loss: 0.0174188
[Epoch 59; Iter   664/ 1097] train: loss: 0.0330385
[Epoch 59; Iter   694/ 1097] train: loss: 0.0086633
[Epoch 59; Iter   724/ 1097] train: loss: 0.0070588
[Epoch 59; Iter   754/ 1097] train: loss: 0.0132784
[Epoch 59; Iter   784/ 1097] train: loss: 0.0030006
[Epoch 59; Iter   814/ 1097] train: loss: 0.1323575
[Epoch 59; Iter   844/ 1097] train: loss: 0.0152112
[Epoch 59; Iter   874/ 1097] train: loss: 0.1597935
[Epoch 59; Iter   904/ 1097] train: loss: 0.0815689
[Epoch 59; Iter   934/ 1097] train: loss: 0.0216224
[Epoch 59; Iter   964/ 1097] train: loss: 0.0118864
[Epoch 59; Iter   994/ 1097] train: loss: 0.0115021
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0042456
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0070596
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0878662
[Epoch 59] ogbg-molhiv: 0.803593 val loss: 0.109561
[Epoch 59] ogbg-molhiv: 0.742150 test loss: 0.192775
[Epoch 60; Iter    17/ 1097] train: loss: 0.0066736
[Epoch 60; Iter    47/ 1097] train: loss: 0.0118840
[Epoch 60; Iter    77/ 1097] train: loss: 0.0125199
[Epoch 60; Iter   107/ 1097] train: loss: 0.0163499
[Epoch 60; Iter   137/ 1097] train: loss: 0.0300454
[Epoch 60; Iter   167/ 1097] train: loss: 0.0071923
[Epoch 60; Iter   197/ 1097] train: loss: 0.0079515
[Epoch 60; Iter   227/ 1097] train: loss: 0.0232932
[Epoch 60; Iter   257/ 1097] train: loss: 0.0096017
[Epoch 60; Iter   287/ 1097] train: loss: 0.0043231
[Epoch 60; Iter   317/ 1097] train: loss: 0.0232173
[Epoch 60; Iter   347/ 1097] train: loss: 0.1887882
[Epoch 60; Iter   377/ 1097] train: loss: 0.0104020
[Epoch 60; Iter   407/ 1097] train: loss: 0.0222072
[Epoch 60; Iter   437/ 1097] train: loss: 0.0186638
[Epoch 60; Iter   467/ 1097] train: loss: 0.0517258
[Epoch 60; Iter   497/ 1097] train: loss: 0.0161477
[Epoch 60; Iter   527/ 1097] train: loss: 0.0037145
[Epoch 60; Iter   557/ 1097] train: loss: 0.0078910
[Epoch 60; Iter   587/ 1097] train: loss: 0.0672101
[Epoch 60; Iter   617/ 1097] train: loss: 0.0642446
[Epoch 60; Iter   647/ 1097] train: loss: 0.0107255
[Epoch 60; Iter   677/ 1097] train: loss: 0.0100260
[Epoch 60; Iter   707/ 1097] train: loss: 0.0917077
[Epoch 60; Iter   737/ 1097] train: loss: 0.0173553
[Epoch 60; Iter   767/ 1097] train: loss: 0.0154306
[Epoch 60; Iter   797/ 1097] train: loss: 0.0049072
[Epoch 60; Iter   827/ 1097] train: loss: 0.0099966
[Epoch 60; Iter   857/ 1097] train: loss: 0.0285666
[Epoch 60; Iter   887/ 1097] train: loss: 0.0139834
[Epoch 60; Iter   917/ 1097] train: loss: 0.0376959
[Epoch 60; Iter   947/ 1097] train: loss: 0.0146557
[Epoch 60; Iter   977/ 1097] train: loss: 0.0648187
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0142958
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0842366
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0261882
[Epoch 73; Iter   186/ 1097] train: loss: 0.0001245
[Epoch 73; Iter   216/ 1097] train: loss: 0.0487431
[Epoch 73; Iter   246/ 1097] train: loss: 0.0006539
[Epoch 73; Iter   276/ 1097] train: loss: 0.0008523
[Epoch 73; Iter   306/ 1097] train: loss: 0.0001283
[Epoch 73; Iter   336/ 1097] train: loss: 0.0003906
[Epoch 73; Iter   366/ 1097] train: loss: 0.1571003
[Epoch 73; Iter   396/ 1097] train: loss: 0.0572087
[Epoch 73; Iter   426/ 1097] train: loss: 0.0016038
[Epoch 73; Iter   456/ 1097] train: loss: 0.0105762
[Epoch 73; Iter   486/ 1097] train: loss: 0.0031084
[Epoch 73; Iter   516/ 1097] train: loss: 0.0021086
[Epoch 73; Iter   546/ 1097] train: loss: 0.0026785
[Epoch 73; Iter   576/ 1097] train: loss: 0.0026949
[Epoch 73; Iter   606/ 1097] train: loss: 0.0436744
[Epoch 73; Iter   636/ 1097] train: loss: 0.0006557
[Epoch 73; Iter   666/ 1097] train: loss: 0.0038794
[Epoch 73; Iter   696/ 1097] train: loss: 0.0000859
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001476
[Epoch 73; Iter   756/ 1097] train: loss: 0.0043531
[Epoch 73; Iter   786/ 1097] train: loss: 0.0035967
[Epoch 73; Iter   816/ 1097] train: loss: 0.0000302
[Epoch 73; Iter   846/ 1097] train: loss: 0.0501572
[Epoch 73; Iter   876/ 1097] train: loss: 0.0058695
[Epoch 73; Iter   906/ 1097] train: loss: 0.0108722
[Epoch 73; Iter   936/ 1097] train: loss: 0.0007701
[Epoch 73; Iter   966/ 1097] train: loss: 0.0001158
[Epoch 73; Iter   996/ 1097] train: loss: 0.0011896
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0052690
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0002036
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0056303
[Epoch 73] ogbg-molhiv: 0.741289 val loss: 1.833760
[Epoch 73] ogbg-molhiv: 0.714342 test loss: 1.289315
[Epoch 74; Iter    19/ 1097] train: loss: 0.0017908
[Epoch 74; Iter    49/ 1097] train: loss: 0.0004202
[Epoch 74; Iter    79/ 1097] train: loss: 0.0279389
[Epoch 74; Iter   109/ 1097] train: loss: 0.0936747
[Epoch 74; Iter   139/ 1097] train: loss: 0.0004344
[Epoch 74; Iter   169/ 1097] train: loss: 0.0014849
[Epoch 74; Iter   199/ 1097] train: loss: 0.0078381
[Epoch 74; Iter   229/ 1097] train: loss: 0.0001240
[Epoch 74; Iter   259/ 1097] train: loss: 0.0028787
[Epoch 74; Iter   289/ 1097] train: loss: 0.0004169
[Epoch 74; Iter   319/ 1097] train: loss: 0.2361460
[Epoch 74; Iter   349/ 1097] train: loss: 0.0001785
[Epoch 74; Iter   379/ 1097] train: loss: 0.0020408
[Epoch 74; Iter   409/ 1097] train: loss: 0.0008466
[Epoch 74; Iter   439/ 1097] train: loss: 0.0010183
[Epoch 74; Iter   469/ 1097] train: loss: 0.0003645
[Epoch 74; Iter   499/ 1097] train: loss: 0.0002588
[Epoch 74; Iter   529/ 1097] train: loss: 0.0053256
[Epoch 74; Iter   559/ 1097] train: loss: 0.0006618
[Epoch 74; Iter   589/ 1097] train: loss: 0.0007815
[Epoch 74; Iter   619/ 1097] train: loss: 0.0031658
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001634
[Epoch 74; Iter   679/ 1097] train: loss: 0.0004813
[Epoch 74; Iter   709/ 1097] train: loss: 0.2172703
[Epoch 74; Iter   739/ 1097] train: loss: 0.0166110
[Epoch 74; Iter   769/ 1097] train: loss: 0.0009900
[Epoch 74; Iter   799/ 1097] train: loss: 0.1312601
[Epoch 74; Iter   829/ 1097] train: loss: 0.0021610
[Epoch 74; Iter   859/ 1097] train: loss: 0.0004487
[Epoch 74; Iter   889/ 1097] train: loss: 0.0012333
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000576
[Epoch 74; Iter   949/ 1097] train: loss: 0.0021115
[Epoch 74; Iter   979/ 1097] train: loss: 0.0006850
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0293225
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0048390
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0001293
[Epoch 74] ogbg-molhiv: 0.762575 val loss: 0.909353
[Epoch 74] ogbg-molhiv: 0.742585 test loss: 0.950220
[Epoch 75; Iter     2/ 1097] train: loss: 0.0177257
[Epoch 75; Iter    32/ 1097] train: loss: 0.0143599
[Epoch 75; Iter    62/ 1097] train: loss: 0.0039446
[Epoch 75; Iter    92/ 1097] train: loss: 0.0006272
[Epoch 75; Iter   122/ 1097] train: loss: 0.0008471
[Epoch 75; Iter   152/ 1097] train: loss: 0.0075265
[Epoch 75; Iter   182/ 1097] train: loss: 0.0045618
[Epoch 75; Iter   212/ 1097] train: loss: 0.0011725
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000333
[Epoch 75; Iter   272/ 1097] train: loss: 0.0003356
[Epoch 75; Iter   302/ 1097] train: loss: 0.0025029
[Epoch 75; Iter   332/ 1097] train: loss: 0.0003551
[Epoch 75; Iter   362/ 1097] train: loss: 0.0004766
[Epoch 75; Iter   392/ 1097] train: loss: 0.0810980
[Epoch 75; Iter   422/ 1097] train: loss: 0.0006927
[Epoch 75; Iter   452/ 1097] train: loss: 0.0214499
[Epoch 75; Iter   482/ 1097] train: loss: 0.0003889
[Epoch 75; Iter   512/ 1097] train: loss: 0.0002298
[Epoch 75; Iter   542/ 1097] train: loss: 0.0009333
[Epoch 75; Iter   572/ 1097] train: loss: 0.0184262
[Epoch 75; Iter   602/ 1097] train: loss: 0.0040424
[Epoch 75; Iter   632/ 1097] train: loss: 0.0003323
[Epoch 75; Iter   662/ 1097] train: loss: 0.0124364
[Epoch 75; Iter   692/ 1097] train: loss: 0.0002949
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000440
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000649
[Epoch 75; Iter   782/ 1097] train: loss: 0.0025169
[Epoch 75; Iter   812/ 1097] train: loss: 0.0016574
[Epoch 75; Iter   842/ 1097] train: loss: 0.0002587
[Epoch 75; Iter   872/ 1097] train: loss: 0.0010540
[Epoch 75; Iter   902/ 1097] train: loss: 0.0041363
[Epoch 75; Iter   932/ 1097] train: loss: 0.0171296
[Epoch 75; Iter   962/ 1097] train: loss: 0.0642206
[Epoch 75; Iter   992/ 1097] train: loss: 0.0313464
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0310573
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0043477
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0199625
[Epoch 75] ogbg-molhiv: 0.756577 val loss: 0.310987
[Epoch 75] ogbg-molhiv: 0.710863 test loss: 0.366335
[Epoch 76; Iter    15/ 1097] train: loss: 0.0031491
[Epoch 76; Iter    45/ 1097] train: loss: 0.0064090
[Epoch 76; Iter    75/ 1097] train: loss: 0.0018050
[Epoch 76; Iter   105/ 1097] train: loss: 0.0001476
[Epoch 76; Iter   135/ 1097] train: loss: 0.0022732
[Epoch 76; Iter   165/ 1097] train: loss: 0.0006518
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001792
[Epoch 76; Iter   225/ 1097] train: loss: 0.0254317
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000980
[Epoch 76; Iter   285/ 1097] train: loss: 0.0002703
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000295
[Epoch 76; Iter   345/ 1097] train: loss: 0.0054988
[Epoch 76; Iter   375/ 1097] train: loss: 0.0146256
[Epoch 76; Iter   405/ 1097] train: loss: 0.0033289
[Epoch 76; Iter   435/ 1097] train: loss: 0.0053657
[Epoch 76; Iter   465/ 1097] train: loss: 0.0009261
[Epoch 76; Iter   495/ 1097] train: loss: 0.0018038
[Epoch 76; Iter   525/ 1097] train: loss: 0.0029681
[Epoch 76; Iter   555/ 1097] train: loss: 0.0001494
[Epoch 76; Iter   585/ 1097] train: loss: 0.0000647
[Epoch 76; Iter   615/ 1097] train: loss: 0.0007799
[Epoch 76; Iter   645/ 1097] train: loss: 0.0196312
[Epoch 76; Iter   675/ 1097] train: loss: 0.0006441
[Epoch 76; Iter   705/ 1097] train: loss: 0.0014310
[Epoch 76; Iter   735/ 1097] train: loss: 0.0012282
[Epoch 76; Iter   765/ 1097] train: loss: 0.0045233
[Epoch 76; Iter   795/ 1097] train: loss: 0.0006974
[Epoch 76; Iter   825/ 1097] train: loss: 0.0029799
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000447
[Epoch 76; Iter   885/ 1097] train: loss: 0.0154462
[Epoch 76; Iter   915/ 1097] train: loss: 0.0004774
[Epoch 76; Iter   945/ 1097] train: loss: 0.0005089
[Epoch 76; Iter   975/ 1097] train: loss: 0.0007176
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0001382
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0010356
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0018546
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0879023
[Epoch 76] ogbg-molhiv: 0.771945 val loss: 1.060261
[Epoch 76] ogbg-molhiv: 0.730902 test loss: 1.179119
[Epoch 77; Iter    28/ 1097] train: loss: 0.0007797
[Epoch 77; Iter    58/ 1097] train: loss: 0.0021567
[Epoch 77; Iter    88/ 1097] train: loss: 0.0031698
[Epoch 77; Iter   118/ 1097] train: loss: 0.0293090
[Epoch 77; Iter   148/ 1097] train: loss: 0.0114487
[Epoch 77; Iter   178/ 1097] train: loss: 0.0125911
[Epoch 77; Iter   208/ 1097] train: loss: 0.0053697
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000324
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000150
[Epoch 73; Iter   216/ 1097] train: loss: 0.0000176
[Epoch 73; Iter   246/ 1097] train: loss: 0.0001552
[Epoch 73; Iter   276/ 1097] train: loss: 0.0000290
[Epoch 73; Iter   306/ 1097] train: loss: 0.0003849
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000031
[Epoch 73; Iter   366/ 1097] train: loss: 0.0003279
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000177
[Epoch 73; Iter   426/ 1097] train: loss: 0.0007426
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000079
[Epoch 73; Iter   486/ 1097] train: loss: 0.0001162
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000070
[Epoch 73; Iter   546/ 1097] train: loss: 0.0025206
[Epoch 73; Iter   576/ 1097] train: loss: 0.0000709
[Epoch 73; Iter   606/ 1097] train: loss: 0.0002038
[Epoch 73; Iter   636/ 1097] train: loss: 0.0030450
[Epoch 73; Iter   666/ 1097] train: loss: 0.0002104
[Epoch 73; Iter   696/ 1097] train: loss: 0.0034422
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001372
[Epoch 73; Iter   756/ 1097] train: loss: 0.0002917
[Epoch 73; Iter   786/ 1097] train: loss: 0.0002366
[Epoch 73; Iter   816/ 1097] train: loss: 0.0000728
[Epoch 73; Iter   846/ 1097] train: loss: 0.0000167
[Epoch 73; Iter   876/ 1097] train: loss: 0.0040190
[Epoch 73; Iter   906/ 1097] train: loss: 0.0240022
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000909
[Epoch 73; Iter   966/ 1097] train: loss: 0.0001856
[Epoch 73; Iter   996/ 1097] train: loss: 0.0149468
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0021411
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0028324
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0008331
[Epoch 73] ogbg-molhiv: 0.773225 val loss: 0.246513
[Epoch 73] ogbg-molhiv: 0.713806 test loss: 0.349686
[Epoch 74; Iter    19/ 1097] train: loss: 0.0000957
[Epoch 74; Iter    49/ 1097] train: loss: 0.0005869
[Epoch 74; Iter    79/ 1097] train: loss: 0.0011036
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000169
[Epoch 74; Iter   139/ 1097] train: loss: 0.0005405
[Epoch 74; Iter   169/ 1097] train: loss: 0.0052551
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001280
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000438
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000475
[Epoch 74; Iter   289/ 1097] train: loss: 0.0001330
[Epoch 74; Iter   319/ 1097] train: loss: 0.0006756
[Epoch 74; Iter   349/ 1097] train: loss: 0.0175473
[Epoch 74; Iter   379/ 1097] train: loss: 0.0000512
[Epoch 74; Iter   409/ 1097] train: loss: 0.0000606
[Epoch 74; Iter   439/ 1097] train: loss: 0.0000629
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001222
[Epoch 74; Iter   499/ 1097] train: loss: 0.0003304
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000098
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000124
[Epoch 74; Iter   589/ 1097] train: loss: 0.0000213
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000774
[Epoch 74; Iter   649/ 1097] train: loss: 0.0031722
[Epoch 74; Iter   679/ 1097] train: loss: 0.0014153
[Epoch 74; Iter   709/ 1097] train: loss: 0.0000259
[Epoch 74; Iter   739/ 1097] train: loss: 0.0003826
[Epoch 74; Iter   769/ 1097] train: loss: 0.0001617
[Epoch 74; Iter   799/ 1097] train: loss: 0.0000602
[Epoch 74; Iter   829/ 1097] train: loss: 0.0045312
[Epoch 74; Iter   859/ 1097] train: loss: 0.0000894
[Epoch 74; Iter   889/ 1097] train: loss: 0.0055039
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000418
[Epoch 74; Iter   949/ 1097] train: loss: 0.0032525
[Epoch 74; Iter   979/ 1097] train: loss: 0.0002710
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0100267
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0010170
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0003419
[Epoch 74] ogbg-molhiv: 0.771087 val loss: 0.239993
[Epoch 74] ogbg-molhiv: 0.716586 test loss: 0.366320
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000178
[Epoch 75; Iter    32/ 1097] train: loss: 0.0000038
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000050
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001627
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000101
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000117
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000260
[Epoch 75; Iter   212/ 1097] train: loss: 0.0001325
[Epoch 75; Iter   242/ 1097] train: loss: 0.0003812
[Epoch 75; Iter   272/ 1097] train: loss: 0.0113067
[Epoch 75; Iter   302/ 1097] train: loss: 0.0020636
[Epoch 75; Iter   332/ 1097] train: loss: 0.0007250
[Epoch 75; Iter   362/ 1097] train: loss: 0.0006102
[Epoch 75; Iter   392/ 1097] train: loss: 0.0031691
[Epoch 75; Iter   422/ 1097] train: loss: 0.0042542
[Epoch 75; Iter   452/ 1097] train: loss: 0.0013085
[Epoch 75; Iter   482/ 1097] train: loss: 0.0001785
[Epoch 75; Iter   512/ 1097] train: loss: 0.0000164
[Epoch 75; Iter   542/ 1097] train: loss: 0.0001293
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000124
[Epoch 75; Iter   602/ 1097] train: loss: 0.0008590
[Epoch 75; Iter   632/ 1097] train: loss: 0.0006042
[Epoch 75; Iter   662/ 1097] train: loss: 0.0036881
[Epoch 75; Iter   692/ 1097] train: loss: 0.0013547
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000478
[Epoch 75; Iter   752/ 1097] train: loss: 0.0001446
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000982
[Epoch 75; Iter   812/ 1097] train: loss: 0.0001672
[Epoch 75; Iter   842/ 1097] train: loss: 0.0266582
[Epoch 75; Iter   872/ 1097] train: loss: 0.0009853
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000132
[Epoch 75; Iter   932/ 1097] train: loss: 0.0000642
[Epoch 75; Iter   962/ 1097] train: loss: 0.0006976
[Epoch 75; Iter   992/ 1097] train: loss: 0.0023654
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0018996
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0089592
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0006619
[Epoch 75] ogbg-molhiv: 0.775258 val loss: 0.222890
[Epoch 75] ogbg-molhiv: 0.733981 test loss: 0.360239
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000421
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000598
[Epoch 76; Iter    75/ 1097] train: loss: 0.0000538
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000565
[Epoch 76; Iter   135/ 1097] train: loss: 0.0000215
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000139
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000145
[Epoch 76; Iter   225/ 1097] train: loss: 0.0054096
[Epoch 76; Iter   255/ 1097] train: loss: 0.0013152
[Epoch 76; Iter   285/ 1097] train: loss: 0.0030827
[Epoch 76; Iter   315/ 1097] train: loss: 0.0001042
[Epoch 76; Iter   345/ 1097] train: loss: 0.0001121
[Epoch 76; Iter   375/ 1097] train: loss: 0.0060971
[Epoch 76; Iter   405/ 1097] train: loss: 0.0001531
[Epoch 76; Iter   435/ 1097] train: loss: 0.0004934
[Epoch 76; Iter   465/ 1097] train: loss: 0.0005390
[Epoch 76; Iter   495/ 1097] train: loss: 0.0003209
[Epoch 76; Iter   525/ 1097] train: loss: 0.0002957
[Epoch 76; Iter   555/ 1097] train: loss: 0.0153815
[Epoch 76; Iter   585/ 1097] train: loss: 0.0034549
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000876
[Epoch 76; Iter   645/ 1097] train: loss: 0.0005889
[Epoch 76; Iter   675/ 1097] train: loss: 0.0000032
[Epoch 76; Iter   705/ 1097] train: loss: 0.0010701
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000362
[Epoch 76; Iter   765/ 1097] train: loss: 0.0009861
[Epoch 76; Iter   795/ 1097] train: loss: 0.0001872
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000187
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001006
[Epoch 76; Iter   885/ 1097] train: loss: 0.0001160
[Epoch 76; Iter   915/ 1097] train: loss: 0.0000516
[Epoch 76; Iter   945/ 1097] train: loss: 0.0001009
[Epoch 76; Iter   975/ 1097] train: loss: 0.0000064
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0004435
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000393
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0002749
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0000780
[Epoch 76] ogbg-molhiv: 0.775524 val loss: 0.244115
[Epoch 76] ogbg-molhiv: 0.727490 test loss: 0.383016
[Epoch 77; Iter    28/ 1097] train: loss: 0.0011340
[Epoch 77; Iter    58/ 1097] train: loss: 0.0123691
[Epoch 77; Iter    88/ 1097] train: loss: 0.0060730
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002976
[Epoch 77; Iter   148/ 1097] train: loss: 0.0086074
[Epoch 77; Iter   178/ 1097] train: loss: 0.0016820
[Epoch 77; Iter   208/ 1097] train: loss: 0.0003831
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000125
[Epoch 73; Iter   186/ 1097] train: loss: 0.0002439
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001095
[Epoch 73; Iter   246/ 1097] train: loss: 0.0005966
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001815
[Epoch 73; Iter   306/ 1097] train: loss: 0.0028576
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000908
[Epoch 73; Iter   366/ 1097] train: loss: 0.0003078
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000108
[Epoch 73; Iter   426/ 1097] train: loss: 0.0001077
[Epoch 73; Iter   456/ 1097] train: loss: 0.0002320
[Epoch 73; Iter   486/ 1097] train: loss: 0.0000157
[Epoch 73; Iter   516/ 1097] train: loss: 0.0002521
[Epoch 73; Iter   546/ 1097] train: loss: 0.0001726
[Epoch 73; Iter   576/ 1097] train: loss: 0.0000892
[Epoch 73; Iter   606/ 1097] train: loss: 0.0009328
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001081
[Epoch 73; Iter   666/ 1097] train: loss: 0.0333195
[Epoch 73; Iter   696/ 1097] train: loss: 0.0001665
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001953
[Epoch 73; Iter   756/ 1097] train: loss: 0.0008430
[Epoch 73; Iter   786/ 1097] train: loss: 0.0130361
[Epoch 73; Iter   816/ 1097] train: loss: 0.0012171
[Epoch 73; Iter   846/ 1097] train: loss: 0.0003571
[Epoch 73; Iter   876/ 1097] train: loss: 0.0005213
[Epoch 73; Iter   906/ 1097] train: loss: 0.0007427
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000508
[Epoch 73; Iter   966/ 1097] train: loss: 0.0120598
[Epoch 73; Iter   996/ 1097] train: loss: 0.0021822
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0003381
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0001320
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0063012
[Epoch 73] ogbg-molhiv: 0.744556 val loss: 0.335759
[Epoch 73] ogbg-molhiv: 0.753667 test loss: 0.351640
[Epoch 74; Iter    19/ 1097] train: loss: 0.0008089
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000474
[Epoch 74; Iter    79/ 1097] train: loss: 0.0001785
[Epoch 74; Iter   109/ 1097] train: loss: 0.0005021
[Epoch 74; Iter   139/ 1097] train: loss: 0.0005742
[Epoch 74; Iter   169/ 1097] train: loss: 0.0000432
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000482
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000313
[Epoch 74; Iter   259/ 1097] train: loss: 0.0121655
[Epoch 74; Iter   289/ 1097] train: loss: 0.0000113
[Epoch 74; Iter   319/ 1097] train: loss: 0.0009423
[Epoch 74; Iter   349/ 1097] train: loss: 0.0008431
[Epoch 74; Iter   379/ 1097] train: loss: 0.0020702
[Epoch 74; Iter   409/ 1097] train: loss: 0.0002505
[Epoch 74; Iter   439/ 1097] train: loss: 0.0002541
[Epoch 74; Iter   469/ 1097] train: loss: 0.0003951
[Epoch 74; Iter   499/ 1097] train: loss: 0.0067651
[Epoch 74; Iter   529/ 1097] train: loss: 0.0033077
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000109
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001716
[Epoch 74; Iter   619/ 1097] train: loss: 0.0027549
[Epoch 74; Iter   649/ 1097] train: loss: 0.0002142
[Epoch 74; Iter   679/ 1097] train: loss: 0.0073436
[Epoch 74; Iter   709/ 1097] train: loss: 0.0006358
[Epoch 74; Iter   739/ 1097] train: loss: 0.0463667
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000453
[Epoch 74; Iter   799/ 1097] train: loss: 0.0017686
[Epoch 74; Iter   829/ 1097] train: loss: 0.0001032
[Epoch 74; Iter   859/ 1097] train: loss: 0.0116037
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000486
[Epoch 74; Iter   919/ 1097] train: loss: 0.0031064
[Epoch 74; Iter   949/ 1097] train: loss: 0.0005506
[Epoch 74; Iter   979/ 1097] train: loss: 0.0031860
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0002412
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0003259
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0021640
[Epoch 74] ogbg-molhiv: 0.752624 val loss: 0.346504
[Epoch 74] ogbg-molhiv: 0.745377 test loss: 0.357328
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001213
[Epoch 75; Iter    32/ 1097] train: loss: 0.0011585
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000239
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001179
[Epoch 75; Iter   122/ 1097] train: loss: 0.0028977
[Epoch 75; Iter   152/ 1097] train: loss: 0.0491277
[Epoch 75; Iter   182/ 1097] train: loss: 0.0001387
[Epoch 75; Iter   212/ 1097] train: loss: 0.0009547
[Epoch 75; Iter   242/ 1097] train: loss: 0.0002592
[Epoch 75; Iter   272/ 1097] train: loss: 0.0001039
[Epoch 75; Iter   302/ 1097] train: loss: 0.0006952
[Epoch 75; Iter   332/ 1097] train: loss: 0.0088722
[Epoch 75; Iter   362/ 1097] train: loss: 0.0006884
[Epoch 75; Iter   392/ 1097] train: loss: 0.0010153
[Epoch 75; Iter   422/ 1097] train: loss: 0.0024445
[Epoch 75; Iter   452/ 1097] train: loss: 0.0000878
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000964
[Epoch 75; Iter   512/ 1097] train: loss: 0.0001849
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000255
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000053
[Epoch 75; Iter   602/ 1097] train: loss: 0.0003717
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000211
[Epoch 75; Iter   662/ 1097] train: loss: 0.0271209
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001826
[Epoch 75; Iter   722/ 1097] train: loss: 0.0003264
[Epoch 75; Iter   752/ 1097] train: loss: 0.0019135
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000800
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000792
[Epoch 75; Iter   842/ 1097] train: loss: 0.0001439
[Epoch 75; Iter   872/ 1097] train: loss: 0.0018811
[Epoch 75; Iter   902/ 1097] train: loss: 0.0004674
[Epoch 75; Iter   932/ 1097] train: loss: 0.0010216
[Epoch 75; Iter   962/ 1097] train: loss: 0.0005794
[Epoch 75; Iter   992/ 1097] train: loss: 0.0000804
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0014881
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0005735
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0016415
[Epoch 75] ogbg-molhiv: 0.746993 val loss: 0.361840
[Epoch 75] ogbg-molhiv: 0.748369 test loss: 0.361449
[Epoch 76; Iter    15/ 1097] train: loss: 0.0001354
[Epoch 76; Iter    45/ 1097] train: loss: 0.0001004
[Epoch 76; Iter    75/ 1097] train: loss: 0.0002694
[Epoch 76; Iter   105/ 1097] train: loss: 0.0008750
[Epoch 76; Iter   135/ 1097] train: loss: 0.0010051
[Epoch 76; Iter   165/ 1097] train: loss: 0.0004763
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001428
[Epoch 76; Iter   225/ 1097] train: loss: 0.0001324
[Epoch 76; Iter   255/ 1097] train: loss: 0.0007799
[Epoch 76; Iter   285/ 1097] train: loss: 0.0062634
[Epoch 76; Iter   315/ 1097] train: loss: 0.0034507
[Epoch 76; Iter   345/ 1097] train: loss: 0.0002102
[Epoch 76; Iter   375/ 1097] train: loss: 0.0017063
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000261
[Epoch 76; Iter   435/ 1097] train: loss: 0.0273927
[Epoch 76; Iter   465/ 1097] train: loss: 0.0036441
[Epoch 76; Iter   495/ 1097] train: loss: 0.0056084
[Epoch 76; Iter   525/ 1097] train: loss: 0.0000911
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000336
[Epoch 76; Iter   585/ 1097] train: loss: 0.0003395
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000272
[Epoch 76; Iter   645/ 1097] train: loss: 0.0045938
[Epoch 76; Iter   675/ 1097] train: loss: 0.0002492
[Epoch 76; Iter   705/ 1097] train: loss: 0.0003172
[Epoch 76; Iter   735/ 1097] train: loss: 0.0884001
[Epoch 76; Iter   765/ 1097] train: loss: 0.0000782
[Epoch 76; Iter   795/ 1097] train: loss: 0.0002288
[Epoch 76; Iter   825/ 1097] train: loss: 0.0005541
[Epoch 76; Iter   855/ 1097] train: loss: 0.0004155
[Epoch 76; Iter   885/ 1097] train: loss: 0.1013916
[Epoch 76; Iter   915/ 1097] train: loss: 0.0086311
[Epoch 76; Iter   945/ 1097] train: loss: 0.0019504
[Epoch 76; Iter   975/ 1097] train: loss: 0.0003604
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0013013
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000190
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0001950
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0016165
[Epoch 76] ogbg-molhiv: 0.746614 val loss: 0.309452
[Epoch 76] ogbg-molhiv: 0.743432 test loss: 0.350326
[Epoch 77; Iter    28/ 1097] train: loss: 0.0002243
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000737
[Epoch 77; Iter    88/ 1097] train: loss: 0.0001359
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002229
[Epoch 77; Iter   148/ 1097] train: loss: 0.0001210
[Epoch 77; Iter   178/ 1097] train: loss: 0.0002185
[Epoch 77; Iter   208/ 1097] train: loss: 0.0002155
[Epoch 77; Iter   238/ 1097] train: loss: 0.0053833
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000196
[Epoch 73; Iter   216/ 1097] train: loss: 0.0005739
[Epoch 73; Iter   246/ 1097] train: loss: 0.0023355
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001938
[Epoch 73; Iter   306/ 1097] train: loss: 0.0004082
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000516
[Epoch 73; Iter   366/ 1097] train: loss: 0.0000713
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000182
[Epoch 73; Iter   426/ 1097] train: loss: 0.0001791
[Epoch 73; Iter   456/ 1097] train: loss: 0.0002720
[Epoch 73; Iter   486/ 1097] train: loss: 0.0000417
[Epoch 73; Iter   516/ 1097] train: loss: 0.0002589
[Epoch 73; Iter   546/ 1097] train: loss: 0.0000954
[Epoch 73; Iter   576/ 1097] train: loss: 0.0001038
[Epoch 73; Iter   606/ 1097] train: loss: 0.0010108
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001336
[Epoch 73; Iter   666/ 1097] train: loss: 0.0109301
[Epoch 73; Iter   696/ 1097] train: loss: 0.0004068
[Epoch 73; Iter   726/ 1097] train: loss: 0.0002185
[Epoch 73; Iter   756/ 1097] train: loss: 0.0057319
[Epoch 73; Iter   786/ 1097] train: loss: 0.0070871
[Epoch 73; Iter   816/ 1097] train: loss: 0.0065679
[Epoch 73; Iter   846/ 1097] train: loss: 0.0001002
[Epoch 73; Iter   876/ 1097] train: loss: 0.0024237
[Epoch 73; Iter   906/ 1097] train: loss: 0.0004467
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000680
[Epoch 73; Iter   966/ 1097] train: loss: 0.0249963
[Epoch 73; Iter   996/ 1097] train: loss: 0.0005741
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0111313
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0002232
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0002085
[Epoch 73] ogbg-molhiv: 0.789015 val loss: 0.243760
[Epoch 73] ogbg-molhiv: 0.736571 test loss: 0.416064
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001301
[Epoch 74; Iter    49/ 1097] train: loss: 0.0001614
[Epoch 74; Iter    79/ 1097] train: loss: 0.0022239
[Epoch 74; Iter   109/ 1097] train: loss: 0.0009305
[Epoch 74; Iter   139/ 1097] train: loss: 0.0118668
[Epoch 74; Iter   169/ 1097] train: loss: 0.0000042
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000253
[Epoch 74; Iter   229/ 1097] train: loss: 0.0001088
[Epoch 74; Iter   259/ 1097] train: loss: 0.0003277
[Epoch 74; Iter   289/ 1097] train: loss: 0.0000573
[Epoch 74; Iter   319/ 1097] train: loss: 0.0000766
[Epoch 74; Iter   349/ 1097] train: loss: 0.0001908
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001573
[Epoch 74; Iter   409/ 1097] train: loss: 0.0000960
[Epoch 74; Iter   439/ 1097] train: loss: 0.0019845
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000127
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000521
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000686
[Epoch 74; Iter   559/ 1097] train: loss: 0.0006322
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001256
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000022
[Epoch 74; Iter   649/ 1097] train: loss: 0.0000061
[Epoch 74; Iter   679/ 1097] train: loss: 0.0000642
[Epoch 74; Iter   709/ 1097] train: loss: 0.0001133
[Epoch 74; Iter   739/ 1097] train: loss: 0.0001029
[Epoch 74; Iter   769/ 1097] train: loss: 0.0386109
[Epoch 74; Iter   799/ 1097] train: loss: 0.0008392
[Epoch 74; Iter   829/ 1097] train: loss: 0.0006893
[Epoch 74; Iter   859/ 1097] train: loss: 0.0053861
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000534
[Epoch 74; Iter   919/ 1097] train: loss: 0.0002557
[Epoch 74; Iter   949/ 1097] train: loss: 0.0018695
[Epoch 74; Iter   979/ 1097] train: loss: 0.0003851
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0000325
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0002603
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0013470
[Epoch 74] ogbg-molhiv: 0.793577 val loss: 0.263045
[Epoch 74] ogbg-molhiv: 0.732478 test loss: 0.416431
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001112
[Epoch 75; Iter    32/ 1097] train: loss: 0.0001055
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000515
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000551
[Epoch 75; Iter   122/ 1097] train: loss: 0.0023458
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000724
[Epoch 75; Iter   182/ 1097] train: loss: 0.0002014
[Epoch 75; Iter   212/ 1097] train: loss: 0.0002969
[Epoch 75; Iter   242/ 1097] train: loss: 0.0093382
[Epoch 75; Iter   272/ 1097] train: loss: 0.0007456
[Epoch 75; Iter   302/ 1097] train: loss: 0.0000608
[Epoch 75; Iter   332/ 1097] train: loss: 0.0054674
[Epoch 75; Iter   362/ 1097] train: loss: 0.0001492
[Epoch 75; Iter   392/ 1097] train: loss: 0.0035304
[Epoch 75; Iter   422/ 1097] train: loss: 0.0011130
[Epoch 75; Iter   452/ 1097] train: loss: 0.0027461
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000139
[Epoch 75; Iter   512/ 1097] train: loss: 0.0015564
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000254
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000074
[Epoch 75; Iter   602/ 1097] train: loss: 0.0293842
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000015
[Epoch 75; Iter   662/ 1097] train: loss: 0.0001289
[Epoch 75; Iter   692/ 1097] train: loss: 0.0010950
[Epoch 75; Iter   722/ 1097] train: loss: 0.0000150
[Epoch 75; Iter   752/ 1097] train: loss: 0.0054390
[Epoch 75; Iter   782/ 1097] train: loss: 0.0003494
[Epoch 75; Iter   812/ 1097] train: loss: 0.0118136
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000360
[Epoch 75; Iter   872/ 1097] train: loss: 0.0001272
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000914
[Epoch 75; Iter   932/ 1097] train: loss: 0.0056699
[Epoch 75; Iter   962/ 1097] train: loss: 0.0009098
[Epoch 75; Iter   992/ 1097] train: loss: 0.0006888
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0007526
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0015166
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0000491
[Epoch 75] ogbg-molhiv: 0.816410 val loss: 0.242439
[Epoch 75] ogbg-molhiv: 0.725991 test loss: 0.444878
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000174
[Epoch 76; Iter    45/ 1097] train: loss: 0.0004504
[Epoch 76; Iter    75/ 1097] train: loss: 0.0018152
[Epoch 76; Iter   105/ 1097] train: loss: 0.0001228
[Epoch 76; Iter   135/ 1097] train: loss: 0.0031332
[Epoch 76; Iter   165/ 1097] train: loss: 0.0002475
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001761
[Epoch 76; Iter   225/ 1097] train: loss: 0.0002789
[Epoch 76; Iter   255/ 1097] train: loss: 0.0001654
[Epoch 76; Iter   285/ 1097] train: loss: 0.0015762
[Epoch 76; Iter   315/ 1097] train: loss: 0.0588955
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000091
[Epoch 76; Iter   375/ 1097] train: loss: 0.0002598
[Epoch 76; Iter   405/ 1097] train: loss: 0.0007367
[Epoch 76; Iter   435/ 1097] train: loss: 0.0000442
[Epoch 76; Iter   465/ 1097] train: loss: 0.0013037
[Epoch 76; Iter   495/ 1097] train: loss: 0.0001622
[Epoch 76; Iter   525/ 1097] train: loss: 0.0012699
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000167
[Epoch 76; Iter   585/ 1097] train: loss: 0.0001962
[Epoch 76; Iter   615/ 1097] train: loss: 0.0026432
[Epoch 76; Iter   645/ 1097] train: loss: 0.0019440
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001984
[Epoch 76; Iter   705/ 1097] train: loss: 0.0026061
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000568
[Epoch 76; Iter   765/ 1097] train: loss: 0.0087972
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000337
[Epoch 76; Iter   825/ 1097] train: loss: 0.0001568
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000033
[Epoch 76; Iter   885/ 1097] train: loss: 0.0010340
[Epoch 76; Iter   915/ 1097] train: loss: 0.0141156
[Epoch 76; Iter   945/ 1097] train: loss: 0.0351209
[Epoch 76; Iter   975/ 1097] train: loss: 0.0004630
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0000356
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0004839
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0003472
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0011978
[Epoch 76] ogbg-molhiv: 0.782962 val loss: 0.246111
[Epoch 76] ogbg-molhiv: 0.718444 test loss: 0.483896
[Epoch 77; Iter    28/ 1097] train: loss: 0.0007036
[Epoch 77; Iter    58/ 1097] train: loss: 0.0005388
[Epoch 77; Iter    88/ 1097] train: loss: 0.0005768
[Epoch 77; Iter   118/ 1097] train: loss: 0.0001594
[Epoch 77; Iter   148/ 1097] train: loss: 0.0021264
[Epoch 77; Iter   178/ 1097] train: loss: 0.0005642
[Epoch 77; Iter   208/ 1097] train: loss: 0.0094670
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000701
[Epoch 73; Iter   186/ 1097] train: loss: 0.0296606
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001466
[Epoch 73; Iter   246/ 1097] train: loss: 0.0175455
[Epoch 73; Iter   276/ 1097] train: loss: 0.0794364
[Epoch 73; Iter   306/ 1097] train: loss: 0.0123804
[Epoch 73; Iter   336/ 1097] train: loss: 0.0012168
[Epoch 73; Iter   366/ 1097] train: loss: 0.0222638
[Epoch 73; Iter   396/ 1097] train: loss: 0.0002970
[Epoch 73; Iter   426/ 1097] train: loss: 0.0016694
[Epoch 73; Iter   456/ 1097] train: loss: 0.0010691
[Epoch 73; Iter   486/ 1097] train: loss: 0.0687871
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000928
[Epoch 73; Iter   546/ 1097] train: loss: 0.0053008
[Epoch 73; Iter   576/ 1097] train: loss: 0.0003033
[Epoch 73; Iter   606/ 1097] train: loss: 0.0006023
[Epoch 73; Iter   636/ 1097] train: loss: 0.0012089
[Epoch 73; Iter   666/ 1097] train: loss: 0.0212422
[Epoch 73; Iter   696/ 1097] train: loss: 0.0104686
[Epoch 73; Iter   726/ 1097] train: loss: 0.0129643
[Epoch 73; Iter   756/ 1097] train: loss: 0.0012393
[Epoch 73; Iter   786/ 1097] train: loss: 0.0020413
[Epoch 73; Iter   816/ 1097] train: loss: 0.0203088
[Epoch 73; Iter   846/ 1097] train: loss: 0.0017680
[Epoch 73; Iter   876/ 1097] train: loss: 0.0009848
[Epoch 73; Iter   906/ 1097] train: loss: 0.0047570
[Epoch 73; Iter   936/ 1097] train: loss: 0.0082768
[Epoch 73; Iter   966/ 1097] train: loss: 0.0004757
[Epoch 73; Iter   996/ 1097] train: loss: 0.0002947
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0019811
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0012680
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0065043
[Epoch 73] ogbg-molhiv: 0.680234 val loss: 4.518130
[Epoch 73] ogbg-molhiv: 0.691875 test loss: 3.065631
[Epoch 74; Iter    19/ 1097] train: loss: 0.0535406
[Epoch 74; Iter    49/ 1097] train: loss: 0.0007069
[Epoch 74; Iter    79/ 1097] train: loss: 0.0543171
[Epoch 74; Iter   109/ 1097] train: loss: 0.0108209
[Epoch 74; Iter   139/ 1097] train: loss: 0.0122836
[Epoch 74; Iter   169/ 1097] train: loss: 0.0061116
[Epoch 74; Iter   199/ 1097] train: loss: 0.0007366
[Epoch 74; Iter   229/ 1097] train: loss: 0.0014969
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000980
[Epoch 74; Iter   289/ 1097] train: loss: 0.0312757
[Epoch 74; Iter   319/ 1097] train: loss: 0.0007532
[Epoch 74; Iter   349/ 1097] train: loss: 0.0004761
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001632
[Epoch 74; Iter   409/ 1097] train: loss: 0.0852084
[Epoch 74; Iter   439/ 1097] train: loss: 0.0250320
[Epoch 74; Iter   469/ 1097] train: loss: 0.0106746
[Epoch 74; Iter   499/ 1097] train: loss: 0.0011827
[Epoch 74; Iter   529/ 1097] train: loss: 0.0010945
[Epoch 74; Iter   559/ 1097] train: loss: 0.0001975
[Epoch 74; Iter   589/ 1097] train: loss: 0.0015294
[Epoch 74; Iter   619/ 1097] train: loss: 0.0507415
[Epoch 74; Iter   649/ 1097] train: loss: 0.0659361
[Epoch 74; Iter   679/ 1097] train: loss: 0.0048179
[Epoch 74; Iter   709/ 1097] train: loss: 0.0008907
[Epoch 74; Iter   739/ 1097] train: loss: 0.0640516
[Epoch 74; Iter   769/ 1097] train: loss: 0.0016632
[Epoch 74; Iter   799/ 1097] train: loss: 0.0010602
[Epoch 74; Iter   829/ 1097] train: loss: 0.0057539
[Epoch 74; Iter   859/ 1097] train: loss: 0.0011362
[Epoch 74; Iter   889/ 1097] train: loss: 0.0094152
[Epoch 74; Iter   919/ 1097] train: loss: 0.0005218
[Epoch 74; Iter   949/ 1097] train: loss: 0.0003716
[Epoch 74; Iter   979/ 1097] train: loss: 0.0008354
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0002220
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0011076
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0001494
[Epoch 74] ogbg-molhiv: 0.688713 val loss: 2.789869
[Epoch 74] ogbg-molhiv: 0.697064 test loss: 0.686414
[Epoch 75; Iter     2/ 1097] train: loss: 0.0008053
[Epoch 75; Iter    32/ 1097] train: loss: 0.0007502
[Epoch 75; Iter    62/ 1097] train: loss: 0.0002705
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001426
[Epoch 75; Iter   122/ 1097] train: loss: 0.0001773
[Epoch 75; Iter   152/ 1097] train: loss: 0.0014022
[Epoch 75; Iter   182/ 1097] train: loss: 0.0009061
[Epoch 75; Iter   212/ 1097] train: loss: 0.0022280
[Epoch 75; Iter   242/ 1097] train: loss: 0.0001636
[Epoch 75; Iter   272/ 1097] train: loss: 0.0062435
[Epoch 75; Iter   302/ 1097] train: loss: 0.0010198
[Epoch 75; Iter   332/ 1097] train: loss: 0.0014282
[Epoch 75; Iter   362/ 1097] train: loss: 0.0055395
[Epoch 75; Iter   392/ 1097] train: loss: 0.0105497
[Epoch 75; Iter   422/ 1097] train: loss: 0.0007167
[Epoch 75; Iter   452/ 1097] train: loss: 0.0036172
[Epoch 75; Iter   482/ 1097] train: loss: 0.0016089
[Epoch 75; Iter   512/ 1097] train: loss: 0.0006128
[Epoch 75; Iter   542/ 1097] train: loss: 0.1053536
[Epoch 75; Iter   572/ 1097] train: loss: 0.0019370
[Epoch 75; Iter   602/ 1097] train: loss: 0.0142483
[Epoch 75; Iter   632/ 1097] train: loss: 0.0043005
[Epoch 75; Iter   662/ 1097] train: loss: 0.0020826
[Epoch 75; Iter   692/ 1097] train: loss: 0.2066503
[Epoch 75; Iter   722/ 1097] train: loss: 0.0004121
[Epoch 75; Iter   752/ 1097] train: loss: 0.0001299
[Epoch 75; Iter   782/ 1097] train: loss: 0.1473681
[Epoch 75; Iter   812/ 1097] train: loss: 0.0628552
[Epoch 75; Iter   842/ 1097] train: loss: 0.1828741
[Epoch 75; Iter   872/ 1097] train: loss: 0.0020416
[Epoch 75; Iter   902/ 1097] train: loss: 0.0477821
[Epoch 75; Iter   932/ 1097] train: loss: 0.0005067
[Epoch 75; Iter   962/ 1097] train: loss: 0.0002656
[Epoch 75; Iter   992/ 1097] train: loss: 0.0010475
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0015626
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0164946
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0028214
[Epoch 75] ogbg-molhiv: 0.698024 val loss: 5.835137
[Epoch 75] ogbg-molhiv: 0.698272 test loss: 2.444622
[Epoch 76; Iter    15/ 1097] train: loss: 0.0004449
[Epoch 76; Iter    45/ 1097] train: loss: 0.0048822
[Epoch 76; Iter    75/ 1097] train: loss: 0.0003109
[Epoch 76; Iter   105/ 1097] train: loss: 0.0025699
[Epoch 76; Iter   135/ 1097] train: loss: 0.0054846
[Epoch 76; Iter   165/ 1097] train: loss: 0.0001564
[Epoch 76; Iter   195/ 1097] train: loss: 0.0001565
[Epoch 76; Iter   225/ 1097] train: loss: 0.0046272
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000331
[Epoch 76; Iter   285/ 1097] train: loss: 0.0272581
[Epoch 76; Iter   315/ 1097] train: loss: 0.0092959
[Epoch 76; Iter   345/ 1097] train: loss: 0.0052155
[Epoch 76; Iter   375/ 1097] train: loss: 0.0000712
[Epoch 76; Iter   405/ 1097] train: loss: 0.0002389
[Epoch 76; Iter   435/ 1097] train: loss: 0.0023770
[Epoch 76; Iter   465/ 1097] train: loss: 0.0010334
[Epoch 76; Iter   495/ 1097] train: loss: 0.0031046
[Epoch 76; Iter   525/ 1097] train: loss: 0.0028148
[Epoch 76; Iter   555/ 1097] train: loss: 0.0013558
[Epoch 76; Iter   585/ 1097] train: loss: 0.0040638
[Epoch 76; Iter   615/ 1097] train: loss: 0.0007172
[Epoch 76; Iter   645/ 1097] train: loss: 0.0001039
[Epoch 76; Iter   675/ 1097] train: loss: 0.0004076
[Epoch 76; Iter   705/ 1097] train: loss: 0.0002539
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000760
[Epoch 76; Iter   765/ 1097] train: loss: 0.0000573
[Epoch 76; Iter   795/ 1097] train: loss: 0.0002597
[Epoch 76; Iter   825/ 1097] train: loss: 0.0007267
[Epoch 76; Iter   855/ 1097] train: loss: 0.0049110
[Epoch 76; Iter   885/ 1097] train: loss: 0.0018810
[Epoch 76; Iter   915/ 1097] train: loss: 0.0025361
[Epoch 76; Iter   945/ 1097] train: loss: 0.0013428
[Epoch 76; Iter   975/ 1097] train: loss: 0.0169623
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0006022
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0236596
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0009956
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0019846
[Epoch 76] ogbg-molhiv: 0.702482 val loss: 3.853508
[Epoch 76] ogbg-molhiv: 0.710128 test loss: 2.665659
[Epoch 77; Iter    28/ 1097] train: loss: 0.0767632
[Epoch 77; Iter    58/ 1097] train: loss: 0.0060594
[Epoch 77; Iter    88/ 1097] train: loss: 0.0009625
[Epoch 77; Iter   118/ 1097] train: loss: 0.0021390
[Epoch 77; Iter   148/ 1097] train: loss: 0.0003051
[Epoch 77; Iter   178/ 1097] train: loss: 0.0003839
[Epoch 77; Iter   208/ 1097] train: loss: 0.0709068
[Epoch 77; Iter   238/ 1097] train: loss: 0.1743102
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000410
[Epoch 73; Iter   216/ 1097] train: loss: 0.0075714
[Epoch 73; Iter   246/ 1097] train: loss: 0.0003515
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001313
[Epoch 73; Iter   306/ 1097] train: loss: 0.0005473
[Epoch 73; Iter   336/ 1097] train: loss: 0.0004260
[Epoch 73; Iter   366/ 1097] train: loss: 0.0701977
[Epoch 73; Iter   396/ 1097] train: loss: 0.0000966
[Epoch 73; Iter   426/ 1097] train: loss: 0.0003230
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000137
[Epoch 73; Iter   486/ 1097] train: loss: 0.0037172
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000640
[Epoch 73; Iter   546/ 1097] train: loss: 0.0007676
[Epoch 73; Iter   576/ 1097] train: loss: 0.0001362
[Epoch 73; Iter   606/ 1097] train: loss: 0.0004269
[Epoch 73; Iter   636/ 1097] train: loss: 0.0001945
[Epoch 73; Iter   666/ 1097] train: loss: 0.0000759
[Epoch 73; Iter   696/ 1097] train: loss: 0.0000802
[Epoch 73; Iter   726/ 1097] train: loss: 0.0000511
[Epoch 73; Iter   756/ 1097] train: loss: 0.0003307
[Epoch 73; Iter   786/ 1097] train: loss: 0.0001015
[Epoch 73; Iter   816/ 1097] train: loss: 0.0001365
[Epoch 73; Iter   846/ 1097] train: loss: 0.0002308
[Epoch 73; Iter   876/ 1097] train: loss: 0.0003395
[Epoch 73; Iter   906/ 1097] train: loss: 0.0001145
[Epoch 73; Iter   936/ 1097] train: loss: 0.0004163
[Epoch 73; Iter   966/ 1097] train: loss: 0.0000832
[Epoch 73; Iter   996/ 1097] train: loss: 0.0000821
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0000784
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0000552
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0002984
[Epoch 73] ogbg-molhiv: 0.773111 val loss: 0.355791
[Epoch 73] ogbg-molhiv: 0.777317 test loss: 0.326288
[Epoch 74; Iter    19/ 1097] train: loss: 0.0002147
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000373
[Epoch 74; Iter    79/ 1097] train: loss: 0.0003320
[Epoch 74; Iter   109/ 1097] train: loss: 0.0005208
[Epoch 74; Iter   139/ 1097] train: loss: 0.0000244
[Epoch 74; Iter   169/ 1097] train: loss: 0.0245303
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001397
[Epoch 74; Iter   229/ 1097] train: loss: 0.0002955
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000757
[Epoch 74; Iter   289/ 1097] train: loss: 0.0124265
[Epoch 74; Iter   319/ 1097] train: loss: 0.0002088
[Epoch 74; Iter   349/ 1097] train: loss: 0.0002620
[Epoch 74; Iter   379/ 1097] train: loss: 0.0002340
[Epoch 74; Iter   409/ 1097] train: loss: 0.0002932
[Epoch 74; Iter   439/ 1097] train: loss: 0.0196361
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001308
[Epoch 74; Iter   499/ 1097] train: loss: 0.0006100
[Epoch 74; Iter   529/ 1097] train: loss: 0.0004032
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000180
[Epoch 74; Iter   589/ 1097] train: loss: 0.0000375
[Epoch 74; Iter   619/ 1097] train: loss: 0.0003261
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001518
[Epoch 74; Iter   679/ 1097] train: loss: 0.0020759
[Epoch 74; Iter   709/ 1097] train: loss: 0.0063700
[Epoch 74; Iter   739/ 1097] train: loss: 0.0000049
[Epoch 74; Iter   769/ 1097] train: loss: 0.0039486
[Epoch 74; Iter   799/ 1097] train: loss: 0.0501966
[Epoch 74; Iter   829/ 1097] train: loss: 0.0040054
[Epoch 74; Iter   859/ 1097] train: loss: 0.0010466
[Epoch 74; Iter   889/ 1097] train: loss: 0.0001863
[Epoch 74; Iter   919/ 1097] train: loss: 0.0000776
[Epoch 74; Iter   949/ 1097] train: loss: 0.0022873
[Epoch 74; Iter   979/ 1097] train: loss: 0.0018308
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0000190
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0001177
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000338
[Epoch 74] ogbg-molhiv: 0.795571 val loss: 0.321724
[Epoch 74] ogbg-molhiv: 0.812354 test loss: 0.307078
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000429
[Epoch 75; Iter    32/ 1097] train: loss: 0.0145905
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000341
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000440
[Epoch 75; Iter   122/ 1097] train: loss: 0.0011320
[Epoch 75; Iter   152/ 1097] train: loss: 0.0306173
[Epoch 75; Iter   182/ 1097] train: loss: 0.0012060
[Epoch 75; Iter   212/ 1097] train: loss: 0.0014865
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000483
[Epoch 75; Iter   272/ 1097] train: loss: 0.0001122
[Epoch 75; Iter   302/ 1097] train: loss: 0.0019002
[Epoch 75; Iter   332/ 1097] train: loss: 0.0000886
[Epoch 75; Iter   362/ 1097] train: loss: 0.0008866
[Epoch 75; Iter   392/ 1097] train: loss: 0.0281647
[Epoch 75; Iter   422/ 1097] train: loss: 0.0019688
[Epoch 75; Iter   452/ 1097] train: loss: 0.0008559
[Epoch 75; Iter   482/ 1097] train: loss: 0.0139040
[Epoch 75; Iter   512/ 1097] train: loss: 0.0005950
[Epoch 75; Iter   542/ 1097] train: loss: 0.0000235
[Epoch 75; Iter   572/ 1097] train: loss: 0.0047670
[Epoch 75; Iter   602/ 1097] train: loss: 0.0008696
[Epoch 75; Iter   632/ 1097] train: loss: 0.0001039
[Epoch 75; Iter   662/ 1097] train: loss: 0.0004892
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001587
[Epoch 75; Iter   722/ 1097] train: loss: 0.0001017
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000805
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000625
[Epoch 75; Iter   812/ 1097] train: loss: 0.0002225
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000037
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000259
[Epoch 75; Iter   902/ 1097] train: loss: 0.0001381
[Epoch 75; Iter   932/ 1097] train: loss: 0.0311379
[Epoch 75; Iter   962/ 1097] train: loss: 0.0006230
[Epoch 75; Iter   992/ 1097] train: loss: 0.0021515
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000945
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0000316
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0010848
[Epoch 75] ogbg-molhiv: 0.786360 val loss: 0.250762
[Epoch 75] ogbg-molhiv: 0.811717 test loss: 0.319270
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000580
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000357
[Epoch 76; Iter    75/ 1097] train: loss: 0.0001228
[Epoch 76; Iter   105/ 1097] train: loss: 0.0002721
[Epoch 76; Iter   135/ 1097] train: loss: 0.0001043
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000508
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000753
[Epoch 76; Iter   225/ 1097] train: loss: 0.0001591
[Epoch 76; Iter   255/ 1097] train: loss: 0.0001181
[Epoch 76; Iter   285/ 1097] train: loss: 0.0008270
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000773
[Epoch 76; Iter   345/ 1097] train: loss: 0.0004305
[Epoch 76; Iter   375/ 1097] train: loss: 0.0002817
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000594
[Epoch 76; Iter   435/ 1097] train: loss: 0.0084562
[Epoch 76; Iter   465/ 1097] train: loss: 0.0000608
[Epoch 76; Iter   495/ 1097] train: loss: 0.0014045
[Epoch 76; Iter   525/ 1097] train: loss: 0.0002128
[Epoch 76; Iter   555/ 1097] train: loss: 0.0014974
[Epoch 76; Iter   585/ 1097] train: loss: 0.0007104
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000156
[Epoch 76; Iter   645/ 1097] train: loss: 0.0383845
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001846
[Epoch 76; Iter   705/ 1097] train: loss: 0.0000328
[Epoch 76; Iter   735/ 1097] train: loss: 0.0001558
[Epoch 76; Iter   765/ 1097] train: loss: 0.0001026
[Epoch 76; Iter   795/ 1097] train: loss: 0.0069734
[Epoch 76; Iter   825/ 1097] train: loss: 0.0018327
[Epoch 76; Iter   855/ 1097] train: loss: 0.0000234
[Epoch 76; Iter   885/ 1097] train: loss: 0.0016034
[Epoch 76; Iter   915/ 1097] train: loss: 0.0001628
[Epoch 76; Iter   945/ 1097] train: loss: 0.0000330
[Epoch 76; Iter   975/ 1097] train: loss: 0.0009263
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0000185
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000213
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0194568
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0102147
[Epoch 76] ogbg-molhiv: 0.800234 val loss: 0.349916
[Epoch 76] ogbg-molhiv: 0.786087 test loss: 0.339582
[Epoch 77; Iter    28/ 1097] train: loss: 0.0036055
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000671
[Epoch 77; Iter    88/ 1097] train: loss: 0.0636926
[Epoch 77; Iter   118/ 1097] train: loss: 0.0000395
[Epoch 77; Iter   148/ 1097] train: loss: 0.0005120
[Epoch 77; Iter   178/ 1097] train: loss: 0.0224122
[Epoch 77; Iter   208/ 1097] train: loss: 0.0017686
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000781
[Epoch 73; Iter   186/ 1097] train: loss: 0.0018360
[Epoch 73; Iter   216/ 1097] train: loss: 0.0004090
[Epoch 73; Iter   246/ 1097] train: loss: 0.0084504
[Epoch 73; Iter   276/ 1097] train: loss: 0.0000874
[Epoch 73; Iter   306/ 1097] train: loss: 0.0002262
[Epoch 73; Iter   336/ 1097] train: loss: 0.0003474
[Epoch 73; Iter   366/ 1097] train: loss: 0.0002104
[Epoch 73; Iter   396/ 1097] train: loss: 0.0001249
[Epoch 73; Iter   426/ 1097] train: loss: 0.0048395
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000184
[Epoch 73; Iter   486/ 1097] train: loss: 0.0156417
[Epoch 73; Iter   516/ 1097] train: loss: 0.0014617
[Epoch 73; Iter   546/ 1097] train: loss: 0.0000039
[Epoch 73; Iter   576/ 1097] train: loss: 0.0004526
[Epoch 73; Iter   606/ 1097] train: loss: 0.0000121
[Epoch 73; Iter   636/ 1097] train: loss: 0.0000677
[Epoch 73; Iter   666/ 1097] train: loss: 0.0139176
[Epoch 73; Iter   696/ 1097] train: loss: 0.0009732
[Epoch 73; Iter   726/ 1097] train: loss: 0.0001394
[Epoch 73; Iter   756/ 1097] train: loss: 0.0000143
[Epoch 73; Iter   786/ 1097] train: loss: 0.0000023
[Epoch 73; Iter   816/ 1097] train: loss: 0.0189658
[Epoch 73; Iter   846/ 1097] train: loss: 0.0094178
[Epoch 73; Iter   876/ 1097] train: loss: 0.0001876
[Epoch 73; Iter   906/ 1097] train: loss: 0.0024723
[Epoch 73; Iter   936/ 1097] train: loss: 0.0007174
[Epoch 73; Iter   966/ 1097] train: loss: 0.0002894
[Epoch 73; Iter   996/ 1097] train: loss: 0.0000945
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0000725
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0001777
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0004087
[Epoch 73] ogbg-molhiv: 0.705271 val loss: 1.355861
[Epoch 73] ogbg-molhiv: 0.627391 test loss: 2.238579
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001757
[Epoch 74; Iter    49/ 1097] train: loss: 0.0097297
[Epoch 74; Iter    79/ 1097] train: loss: 0.0002815
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000597
[Epoch 74; Iter   139/ 1097] train: loss: 0.0001039
[Epoch 74; Iter   169/ 1097] train: loss: 0.0005063
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000365
[Epoch 74; Iter   229/ 1097] train: loss: 0.0000174
[Epoch 74; Iter   259/ 1097] train: loss: 0.0000621
[Epoch 74; Iter   289/ 1097] train: loss: 0.0001180
[Epoch 74; Iter   319/ 1097] train: loss: 0.0001154
[Epoch 74; Iter   349/ 1097] train: loss: 0.0000200
[Epoch 74; Iter   379/ 1097] train: loss: 0.0001937
[Epoch 74; Iter   409/ 1097] train: loss: 0.0004553
[Epoch 74; Iter   439/ 1097] train: loss: 0.0003034
[Epoch 74; Iter   469/ 1097] train: loss: 0.0001498
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000063
[Epoch 74; Iter   529/ 1097] train: loss: 0.0000465
[Epoch 74; Iter   559/ 1097] train: loss: 0.0004352
[Epoch 74; Iter   589/ 1097] train: loss: 0.0002544
[Epoch 74; Iter   619/ 1097] train: loss: 0.0000385
[Epoch 74; Iter   649/ 1097] train: loss: 0.0002045
[Epoch 74; Iter   679/ 1097] train: loss: 0.0008166
[Epoch 74; Iter   709/ 1097] train: loss: 0.0000115
[Epoch 74; Iter   739/ 1097] train: loss: 0.0000275
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000291
[Epoch 74; Iter   799/ 1097] train: loss: 0.0002913
[Epoch 74; Iter   829/ 1097] train: loss: 0.0013222
[Epoch 74; Iter   859/ 1097] train: loss: 0.0019644
[Epoch 74; Iter   889/ 1097] train: loss: 0.0000213
[Epoch 74; Iter   919/ 1097] train: loss: 0.0001152
[Epoch 74; Iter   949/ 1097] train: loss: 0.0001535
[Epoch 74; Iter   979/ 1097] train: loss: 0.0000766
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0001149
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0005463
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000700
[Epoch 74] ogbg-molhiv: 0.698422 val loss: 3.007563
[Epoch 74] ogbg-molhiv: 0.626625 test loss: 3.309936
[Epoch 75; Iter     2/ 1097] train: loss: 0.0001004
[Epoch 75; Iter    32/ 1097] train: loss: 0.0000117
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000023
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001348
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000058
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000128
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000550
[Epoch 75; Iter   212/ 1097] train: loss: 0.0102404
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000206
[Epoch 75; Iter   272/ 1097] train: loss: 0.0038412
[Epoch 75; Iter   302/ 1097] train: loss: 0.0003772
[Epoch 75; Iter   332/ 1097] train: loss: 0.0002929
[Epoch 75; Iter   362/ 1097] train: loss: 0.1011527
[Epoch 75; Iter   392/ 1097] train: loss: 0.0000042
[Epoch 75; Iter   422/ 1097] train: loss: 0.0000123
[Epoch 75; Iter   452/ 1097] train: loss: 0.0008492
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000512
[Epoch 75; Iter   512/ 1097] train: loss: 0.0002928
[Epoch 75; Iter   542/ 1097] train: loss: 0.0002883
[Epoch 75; Iter   572/ 1097] train: loss: 0.0017546
[Epoch 75; Iter   602/ 1097] train: loss: 0.0031579
[Epoch 75; Iter   632/ 1097] train: loss: 0.0000908
[Epoch 75; Iter   662/ 1097] train: loss: 0.0001234
[Epoch 75; Iter   692/ 1097] train: loss: 0.0001684
[Epoch 75; Iter   722/ 1097] train: loss: 0.0003523
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000076
[Epoch 75; Iter   782/ 1097] train: loss: 0.0000076
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000050
[Epoch 75; Iter   842/ 1097] train: loss: 0.0091247
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000080
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000174
[Epoch 75; Iter   932/ 1097] train: loss: 0.0557282
[Epoch 75; Iter   962/ 1097] train: loss: 0.0013962
[Epoch 75; Iter   992/ 1097] train: loss: 0.0000367
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000612
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0000118
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0000132
[Epoch 75] ogbg-molhiv: 0.689830 val loss: 3.275856
[Epoch 75] ogbg-molhiv: 0.634566 test loss: 2.891472
[Epoch 76; Iter    15/ 1097] train: loss: 0.0004211
[Epoch 76; Iter    45/ 1097] train: loss: 0.0000854
[Epoch 76; Iter    75/ 1097] train: loss: 0.0000112
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000102
[Epoch 76; Iter   135/ 1097] train: loss: 0.0001064
[Epoch 76; Iter   165/ 1097] train: loss: 0.0000066
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000912
[Epoch 76; Iter   225/ 1097] train: loss: 0.0002571
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000298
[Epoch 76; Iter   285/ 1097] train: loss: 0.0109761
[Epoch 76; Iter   315/ 1097] train: loss: 0.0027354
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000031
[Epoch 76; Iter   375/ 1097] train: loss: 0.0004475
[Epoch 76; Iter   405/ 1097] train: loss: 0.0039392
[Epoch 76; Iter   435/ 1097] train: loss: 0.0000154
[Epoch 76; Iter   465/ 1097] train: loss: 0.0000133
[Epoch 76; Iter   495/ 1097] train: loss: 0.0001652
[Epoch 76; Iter   525/ 1097] train: loss: 0.0000038
[Epoch 76; Iter   555/ 1097] train: loss: 0.0000543
[Epoch 76; Iter   585/ 1097] train: loss: 0.0012575
[Epoch 76; Iter   615/ 1097] train: loss: 0.0001280
[Epoch 76; Iter   645/ 1097] train: loss: 0.0232959
[Epoch 76; Iter   675/ 1097] train: loss: 0.0001301
[Epoch 76; Iter   705/ 1097] train: loss: 0.0002584
[Epoch 76; Iter   735/ 1097] train: loss: 0.0000640
[Epoch 76; Iter   765/ 1097] train: loss: 0.0004628
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000235
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000267
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001963
[Epoch 76; Iter   885/ 1097] train: loss: 0.0000664
[Epoch 76; Iter   915/ 1097] train: loss: 0.0000339
[Epoch 76; Iter   945/ 1097] train: loss: 0.0002160
[Epoch 76; Iter   975/ 1097] train: loss: 0.0000356
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0007768
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0007636
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0000088
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0000042
[Epoch 76] ogbg-molhiv: 0.683575 val loss: 3.290067
[Epoch 76] ogbg-molhiv: 0.636119 test loss: 3.071214
[Epoch 77; Iter    28/ 1097] train: loss: 0.0003720
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000256
[Epoch 77; Iter    88/ 1097] train: loss: 0.0000352
[Epoch 77; Iter   118/ 1097] train: loss: 0.0000157
[Epoch 77; Iter   148/ 1097] train: loss: 0.0016737
[Epoch 77; Iter   178/ 1097] train: loss: 0.0143535
[Epoch 77; Iter   208/ 1097] train: loss: 0.0000059
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000059
[Epoch 73; Iter   186/ 1097] train: loss: 0.0003455
[Epoch 73; Iter   216/ 1097] train: loss: 0.0010249
[Epoch 73; Iter   246/ 1097] train: loss: 0.0001740
[Epoch 73; Iter   276/ 1097] train: loss: 0.0001952
[Epoch 73; Iter   306/ 1097] train: loss: 0.0000381
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000893
[Epoch 73; Iter   366/ 1097] train: loss: 0.0281110
[Epoch 73; Iter   396/ 1097] train: loss: 0.0005191
[Epoch 73; Iter   426/ 1097] train: loss: 0.0000100
[Epoch 73; Iter   456/ 1097] train: loss: 0.0000436
[Epoch 73; Iter   486/ 1097] train: loss: 0.0021968
[Epoch 73; Iter   516/ 1097] train: loss: 0.0006924
[Epoch 73; Iter   546/ 1097] train: loss: 0.0007119
[Epoch 73; Iter   576/ 1097] train: loss: 0.0004631
[Epoch 73; Iter   606/ 1097] train: loss: 0.0005854
[Epoch 73; Iter   636/ 1097] train: loss: 0.0000047
[Epoch 73; Iter   666/ 1097] train: loss: 0.0074694
[Epoch 73; Iter   696/ 1097] train: loss: 0.0003321
[Epoch 73; Iter   726/ 1097] train: loss: 0.0011637
[Epoch 73; Iter   756/ 1097] train: loss: 0.0001817
[Epoch 73; Iter   786/ 1097] train: loss: 0.0017167
[Epoch 73; Iter   816/ 1097] train: loss: 0.0002038
[Epoch 73; Iter   846/ 1097] train: loss: 0.0014466
[Epoch 73; Iter   876/ 1097] train: loss: 0.0026411
[Epoch 73; Iter   906/ 1097] train: loss: 0.0147867
[Epoch 73; Iter   936/ 1097] train: loss: 0.0000237
[Epoch 73; Iter   966/ 1097] train: loss: 0.0007353
[Epoch 73; Iter   996/ 1097] train: loss: 0.0041301
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0008188
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0079700
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0382616
[Epoch 73] ogbg-molhiv: 0.771556 val loss: 0.755255
[Epoch 73] ogbg-molhiv: 0.742237 test loss: 1.981038
[Epoch 74; Iter    19/ 1097] train: loss: 0.0000834
[Epoch 74; Iter    49/ 1097] train: loss: 0.0000970
[Epoch 74; Iter    79/ 1097] train: loss: 0.0000678
[Epoch 74; Iter   109/ 1097] train: loss: 0.0000255
[Epoch 74; Iter   139/ 1097] train: loss: 0.0001014
[Epoch 74; Iter   169/ 1097] train: loss: 0.0041505
[Epoch 74; Iter   199/ 1097] train: loss: 0.0001015
[Epoch 74; Iter   229/ 1097] train: loss: 0.0015766
[Epoch 74; Iter   259/ 1097] train: loss: 0.0013754
[Epoch 74; Iter   289/ 1097] train: loss: 0.0192950
[Epoch 74; Iter   319/ 1097] train: loss: 0.0009150
[Epoch 74; Iter   349/ 1097] train: loss: 0.0062912
[Epoch 74; Iter   379/ 1097] train: loss: 0.0000155
[Epoch 74; Iter   409/ 1097] train: loss: 0.0030186
[Epoch 74; Iter   439/ 1097] train: loss: 0.0000428
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000147
[Epoch 74; Iter   499/ 1097] train: loss: 0.0000014
[Epoch 74; Iter   529/ 1097] train: loss: 0.0002589
[Epoch 74; Iter   559/ 1097] train: loss: 0.0000813
[Epoch 74; Iter   589/ 1097] train: loss: 0.0001095
[Epoch 74; Iter   619/ 1097] train: loss: 0.0007107
[Epoch 74; Iter   649/ 1097] train: loss: 0.0001106
[Epoch 74; Iter   679/ 1097] train: loss: 0.0000771
[Epoch 74; Iter   709/ 1097] train: loss: 0.0005708
[Epoch 74; Iter   739/ 1097] train: loss: 0.0001078
[Epoch 74; Iter   769/ 1097] train: loss: 0.0000372
[Epoch 74; Iter   799/ 1097] train: loss: 0.0005980
[Epoch 74; Iter   829/ 1097] train: loss: 0.0239678
[Epoch 74; Iter   859/ 1097] train: loss: 0.0000775
[Epoch 74; Iter   889/ 1097] train: loss: 0.0001026
[Epoch 74; Iter   919/ 1097] train: loss: 0.0001686
[Epoch 74; Iter   949/ 1097] train: loss: 0.0001202
[Epoch 74; Iter   979/ 1097] train: loss: 0.0000343
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0036151
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0000595
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000529
[Epoch 74] ogbg-molhiv: 0.775922 val loss: 2.079450
[Epoch 74] ogbg-molhiv: 0.666824 test loss: 4.632004
[Epoch 75; Iter     2/ 1097] train: loss: 0.0032208
[Epoch 75; Iter    32/ 1097] train: loss: 0.0001919
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000305
[Epoch 75; Iter    92/ 1097] train: loss: 0.0000268
[Epoch 75; Iter   122/ 1097] train: loss: 0.0000142
[Epoch 75; Iter   152/ 1097] train: loss: 0.0015537
[Epoch 75; Iter   182/ 1097] train: loss: 0.0027722
[Epoch 75; Iter   212/ 1097] train: loss: 0.0000523
[Epoch 75; Iter   242/ 1097] train: loss: 0.0000073
[Epoch 75; Iter   272/ 1097] train: loss: 0.0005889
[Epoch 75; Iter   302/ 1097] train: loss: 0.0032984
[Epoch 75; Iter   332/ 1097] train: loss: 0.0000588
[Epoch 75; Iter   362/ 1097] train: loss: 0.0002115
[Epoch 75; Iter   392/ 1097] train: loss: 0.0001660
[Epoch 75; Iter   422/ 1097] train: loss: 0.0015719
[Epoch 75; Iter   452/ 1097] train: loss: 0.0000554
[Epoch 75; Iter   482/ 1097] train: loss: 0.0002457
[Epoch 75; Iter   512/ 1097] train: loss: 0.0001016
[Epoch 75; Iter   542/ 1097] train: loss: 0.0007399
[Epoch 75; Iter   572/ 1097] train: loss: 0.0017164
[Epoch 75; Iter   602/ 1097] train: loss: 0.0000067
[Epoch 75; Iter   632/ 1097] train: loss: 0.0023717
[Epoch 75; Iter   662/ 1097] train: loss: 0.0005921
[Epoch 75; Iter   692/ 1097] train: loss: 0.0000528
[Epoch 75; Iter   722/ 1097] train: loss: 0.0008180
[Epoch 75; Iter   752/ 1097] train: loss: 0.0000801
[Epoch 75; Iter   782/ 1097] train: loss: 0.0002805
[Epoch 75; Iter   812/ 1097] train: loss: 0.0000819
[Epoch 75; Iter   842/ 1097] train: loss: 0.0016214
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000929
[Epoch 75; Iter   902/ 1097] train: loss: 0.0000114
[Epoch 75; Iter   932/ 1097] train: loss: 0.1140241
[Epoch 75; Iter   962/ 1097] train: loss: 0.1292765
[Epoch 75; Iter   992/ 1097] train: loss: 0.0403787
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0009797
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0003051
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0077124
[Epoch 75] ogbg-molhiv: 0.765898 val loss: 1.192391
[Epoch 75] ogbg-molhiv: 0.721107 test loss: 3.456977
[Epoch 76; Iter    15/ 1097] train: loss: 0.0000102
[Epoch 76; Iter    45/ 1097] train: loss: 0.1688136
[Epoch 76; Iter    75/ 1097] train: loss: 0.0281216
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000148
[Epoch 76; Iter   135/ 1097] train: loss: 0.0003838
[Epoch 76; Iter   165/ 1097] train: loss: 0.0004125
[Epoch 76; Iter   195/ 1097] train: loss: 0.0000784
[Epoch 76; Iter   225/ 1097] train: loss: 0.0000915
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000757
[Epoch 76; Iter   285/ 1097] train: loss: 0.0000121
[Epoch 76; Iter   315/ 1097] train: loss: 0.0000617
[Epoch 76; Iter   345/ 1097] train: loss: 0.0000182
[Epoch 76; Iter   375/ 1097] train: loss: 0.0007142
[Epoch 76; Iter   405/ 1097] train: loss: 0.0085529
[Epoch 76; Iter   435/ 1097] train: loss: 0.0001623
[Epoch 76; Iter   465/ 1097] train: loss: 0.0004641
[Epoch 76; Iter   495/ 1097] train: loss: 0.0004745
[Epoch 76; Iter   525/ 1097] train: loss: 0.0003073
[Epoch 76; Iter   555/ 1097] train: loss: 0.0003812
[Epoch 76; Iter   585/ 1097] train: loss: 0.0002729
[Epoch 76; Iter   615/ 1097] train: loss: 0.0000662
[Epoch 76; Iter   645/ 1097] train: loss: 0.0000949
[Epoch 76; Iter   675/ 1097] train: loss: 0.0015103
[Epoch 76; Iter   705/ 1097] train: loss: 0.0000589
[Epoch 76; Iter   735/ 1097] train: loss: 0.0007162
[Epoch 76; Iter   765/ 1097] train: loss: 0.0033919
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000257
[Epoch 76; Iter   825/ 1097] train: loss: 0.0000033
[Epoch 76; Iter   855/ 1097] train: loss: 0.0001246
[Epoch 76; Iter   885/ 1097] train: loss: 0.0002962
[Epoch 76; Iter   915/ 1097] train: loss: 0.0002066
[Epoch 76; Iter   945/ 1097] train: loss: 0.0001193
[Epoch 76; Iter   975/ 1097] train: loss: 0.0005900
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0003230
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0001634
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0002449
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0003081
[Epoch 76] ogbg-molhiv: 0.724399 val loss: 18.396986
[Epoch 76] ogbg-molhiv: 0.678634 test loss: 13.731402
[Epoch 77; Iter    28/ 1097] train: loss: 0.0004292
[Epoch 77; Iter    58/ 1097] train: loss: 0.0000329
[Epoch 77; Iter    88/ 1097] train: loss: 0.0012737
[Epoch 77; Iter   118/ 1097] train: loss: 0.0002694
[Epoch 77; Iter   148/ 1097] train: loss: 0.0011993
[Epoch 77; Iter   178/ 1097] train: loss: 0.0000801
[Epoch 77; Iter   208/ 1097] train: loss: 0.0096791
[Epoch 77; Iter   238/ 1097] train: loss: 0.0000268
[Epoch 73; Iter   186/ 1097] train: loss: 0.0000156
[Epoch 73; Iter   216/ 1097] train: loss: 0.0001749
[Epoch 73; Iter   246/ 1097] train: loss: 0.0000943
[Epoch 73; Iter   276/ 1097] train: loss: 0.0374361
[Epoch 73; Iter   306/ 1097] train: loss: 0.0128214
[Epoch 73; Iter   336/ 1097] train: loss: 0.0000648
[Epoch 73; Iter   366/ 1097] train: loss: 0.0000146
[Epoch 73; Iter   396/ 1097] train: loss: 0.0005520
[Epoch 73; Iter   426/ 1097] train: loss: 0.0239583
[Epoch 73; Iter   456/ 1097] train: loss: 0.0033342
[Epoch 73; Iter   486/ 1097] train: loss: 0.0011353
[Epoch 73; Iter   516/ 1097] train: loss: 0.0000730
[Epoch 73; Iter   546/ 1097] train: loss: 0.0086129
[Epoch 73; Iter   576/ 1097] train: loss: 0.0007920
[Epoch 73; Iter   606/ 1097] train: loss: 0.0016092
[Epoch 73; Iter   636/ 1097] train: loss: 0.0121108
[Epoch 73; Iter   666/ 1097] train: loss: 0.0004721
[Epoch 73; Iter   696/ 1097] train: loss: 0.0011188
[Epoch 73; Iter   726/ 1097] train: loss: 0.0011633
[Epoch 73; Iter   756/ 1097] train: loss: 0.0002163
[Epoch 73; Iter   786/ 1097] train: loss: 0.0001256
[Epoch 73; Iter   816/ 1097] train: loss: 0.0005441
[Epoch 73; Iter   846/ 1097] train: loss: 0.0032496
[Epoch 73; Iter   876/ 1097] train: loss: 0.0000438
[Epoch 73; Iter   906/ 1097] train: loss: 0.0001684
[Epoch 73; Iter   936/ 1097] train: loss: 0.0010200
[Epoch 73; Iter   966/ 1097] train: loss: 0.0015788
[Epoch 73; Iter   996/ 1097] train: loss: 0.0088761
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0002590
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0006555
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0001498
[Epoch 73] ogbg-molhiv: 0.594834 val loss: 49.481685
[Epoch 73] ogbg-molhiv: 0.546386 test loss: 47.034638
[Epoch 74; Iter    19/ 1097] train: loss: 0.0001811
[Epoch 74; Iter    49/ 1097] train: loss: 0.0008405
[Epoch 74; Iter    79/ 1097] train: loss: 0.0006782
[Epoch 74; Iter   109/ 1097] train: loss: 0.0049766
[Epoch 74; Iter   139/ 1097] train: loss: 0.0000581
[Epoch 74; Iter   169/ 1097] train: loss: 0.0016344
[Epoch 74; Iter   199/ 1097] train: loss: 0.0000395
[Epoch 74; Iter   229/ 1097] train: loss: 0.0010516
[Epoch 74; Iter   259/ 1097] train: loss: 0.0305570
[Epoch 74; Iter   289/ 1097] train: loss: 0.0002164
[Epoch 74; Iter   319/ 1097] train: loss: 0.0000840
[Epoch 74; Iter   349/ 1097] train: loss: 0.0051156
[Epoch 74; Iter   379/ 1097] train: loss: 0.0015318
[Epoch 74; Iter   409/ 1097] train: loss: 0.0050482
[Epoch 74; Iter   439/ 1097] train: loss: 0.0004186
[Epoch 74; Iter   469/ 1097] train: loss: 0.0000533
[Epoch 74; Iter   499/ 1097] train: loss: 0.0003977
[Epoch 74; Iter   529/ 1097] train: loss: 0.0011121
[Epoch 74; Iter   559/ 1097] train: loss: 0.0001899
[Epoch 74; Iter   589/ 1097] train: loss: 0.0008705
[Epoch 74; Iter   619/ 1097] train: loss: 0.0003109
[Epoch 74; Iter   649/ 1097] train: loss: 0.0043846
[Epoch 74; Iter   679/ 1097] train: loss: 0.0041785
[Epoch 74; Iter   709/ 1097] train: loss: 0.0047775
[Epoch 74; Iter   739/ 1097] train: loss: 0.0011798
[Epoch 74; Iter   769/ 1097] train: loss: 0.0013269
[Epoch 74; Iter   799/ 1097] train: loss: 0.0001235
[Epoch 74; Iter   829/ 1097] train: loss: 0.0010203
[Epoch 74; Iter   859/ 1097] train: loss: 0.0006838
[Epoch 74; Iter   889/ 1097] train: loss: 0.0009391
[Epoch 74; Iter   919/ 1097] train: loss: 0.0004400
[Epoch 74; Iter   949/ 1097] train: loss: 0.0558944
[Epoch 74; Iter   979/ 1097] train: loss: 0.0012769
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0084366
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0000480
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0000334
[Epoch 74] ogbg-molhiv: 0.584044 val loss: 100.840509
[Epoch 74] ogbg-molhiv: 0.543139 test loss: 87.736535
[Epoch 75; Iter     2/ 1097] train: loss: 0.0000212
[Epoch 75; Iter    32/ 1097] train: loss: 0.0166806
[Epoch 75; Iter    62/ 1097] train: loss: 0.0000526
[Epoch 75; Iter    92/ 1097] train: loss: 0.0001037
[Epoch 75; Iter   122/ 1097] train: loss: 0.0071833
[Epoch 75; Iter   152/ 1097] train: loss: 0.0000707
[Epoch 75; Iter   182/ 1097] train: loss: 0.0000552
[Epoch 75; Iter   212/ 1097] train: loss: 0.0002228
[Epoch 75; Iter   242/ 1097] train: loss: 0.0013726
[Epoch 75; Iter   272/ 1097] train: loss: 0.0003815
[Epoch 75; Iter   302/ 1097] train: loss: 0.0019684
[Epoch 75; Iter   332/ 1097] train: loss: 0.0027782
[Epoch 75; Iter   362/ 1097] train: loss: 0.0000516
[Epoch 75; Iter   392/ 1097] train: loss: 0.0001943
[Epoch 75; Iter   422/ 1097] train: loss: 0.0008161
[Epoch 75; Iter   452/ 1097] train: loss: 0.0019601
[Epoch 75; Iter   482/ 1097] train: loss: 0.0000993
[Epoch 75; Iter   512/ 1097] train: loss: 0.0156812
[Epoch 75; Iter   542/ 1097] train: loss: 0.0003698
[Epoch 75; Iter   572/ 1097] train: loss: 0.0000532
[Epoch 75; Iter   602/ 1097] train: loss: 0.0003208
[Epoch 75; Iter   632/ 1097] train: loss: 0.0021382
[Epoch 75; Iter   662/ 1097] train: loss: 0.0000641
[Epoch 75; Iter   692/ 1097] train: loss: 0.0000683
[Epoch 75; Iter   722/ 1097] train: loss: 0.0002459
[Epoch 75; Iter   752/ 1097] train: loss: 0.0034322
[Epoch 75; Iter   782/ 1097] train: loss: 0.0002953
[Epoch 75; Iter   812/ 1097] train: loss: 0.0011695
[Epoch 75; Iter   842/ 1097] train: loss: 0.0000119
[Epoch 75; Iter   872/ 1097] train: loss: 0.0000613
[Epoch 75; Iter   902/ 1097] train: loss: 0.0054302
[Epoch 75; Iter   932/ 1097] train: loss: 0.0020509
[Epoch 75; Iter   962/ 1097] train: loss: 0.0001449
[Epoch 75; Iter   992/ 1097] train: loss: 0.0004820
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0000041
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0008120
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0118385
[Epoch 75] ogbg-molhiv: 0.604053 val loss: 77.576757
[Epoch 75] ogbg-molhiv: 0.569005 test loss: 65.158668
[Epoch 76; Iter    15/ 1097] train: loss: 0.0896147
[Epoch 76; Iter    45/ 1097] train: loss: 0.0017606
[Epoch 76; Iter    75/ 1097] train: loss: 0.0004204
[Epoch 76; Iter   105/ 1097] train: loss: 0.0000424
[Epoch 76; Iter   135/ 1097] train: loss: 0.0018232
[Epoch 76; Iter   165/ 1097] train: loss: 0.0001985
[Epoch 76; Iter   195/ 1097] train: loss: 0.0006155
[Epoch 76; Iter   225/ 1097] train: loss: 0.0003053
[Epoch 76; Iter   255/ 1097] train: loss: 0.0000504
[Epoch 76; Iter   285/ 1097] train: loss: 0.0004244
[Epoch 76; Iter   315/ 1097] train: loss: 0.0024114
[Epoch 76; Iter   345/ 1097] train: loss: 0.0001702
[Epoch 76; Iter   375/ 1097] train: loss: 0.0000576
[Epoch 76; Iter   405/ 1097] train: loss: 0.0000118
[Epoch 76; Iter   435/ 1097] train: loss: 0.0003470
[Epoch 76; Iter   465/ 1097] train: loss: 0.0004760
[Epoch 76; Iter   495/ 1097] train: loss: 0.0457441
[Epoch 76; Iter   525/ 1097] train: loss: 0.0005100
[Epoch 76; Iter   555/ 1097] train: loss: 0.0281308
[Epoch 76; Iter   585/ 1097] train: loss: 0.0000805
[Epoch 76; Iter   615/ 1097] train: loss: 0.0021197
[Epoch 76; Iter   645/ 1097] train: loss: 0.0059587
[Epoch 76; Iter   675/ 1097] train: loss: 0.0000503
[Epoch 76; Iter   705/ 1097] train: loss: 0.0007077
[Epoch 76; Iter   735/ 1097] train: loss: 0.0005477
[Epoch 76; Iter   765/ 1097] train: loss: 0.0001614
[Epoch 76; Iter   795/ 1097] train: loss: 0.0000658
[Epoch 76; Iter   825/ 1097] train: loss: 0.0071220
[Epoch 76; Iter   855/ 1097] train: loss: 0.0026234
[Epoch 76; Iter   885/ 1097] train: loss: 0.0022076
[Epoch 76; Iter   915/ 1097] train: loss: 0.0001759
[Epoch 76; Iter   945/ 1097] train: loss: 0.0040411
[Epoch 76; Iter   975/ 1097] train: loss: 0.0003981
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0003113
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0000234
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0006137
[Epoch 76; Iter  1095/ 1097] train: loss: 0.1344297
[Epoch 76] ogbg-molhiv: 0.647407 val loss: 133.496454
[Epoch 76] ogbg-molhiv: 0.553456 test loss: 109.054875
[Epoch 77; Iter    28/ 1097] train: loss: 0.0004730
[Epoch 77; Iter    58/ 1097] train: loss: 0.0051328
[Epoch 77; Iter    88/ 1097] train: loss: 0.0027240
[Epoch 77; Iter   118/ 1097] train: loss: 0.0001122
[Epoch 77; Iter   148/ 1097] train: loss: 0.0052816
[Epoch 77; Iter   178/ 1097] train: loss: 0.0000260
[Epoch 77; Iter   208/ 1097] train: loss: 0.0124878
[Epoch 77; Iter   238/ 1097] train: loss: 0.0001333
[Epoch 60; Iter  1097/ 1097] train: loss: 0.3885251
[Epoch 60] ogbg-molhiv: 0.814882 val loss: 0.100650
[Epoch 60] ogbg-molhiv: 0.740316 test loss: 0.184346
[Epoch 61; Iter    30/ 1097] train: loss: 0.0773029
[Epoch 61; Iter    60/ 1097] train: loss: 0.0022895
[Epoch 61; Iter    90/ 1097] train: loss: 0.0646777
[Epoch 61; Iter   120/ 1097] train: loss: 0.0135829
[Epoch 61; Iter   150/ 1097] train: loss: 0.2705396
[Epoch 61; Iter   180/ 1097] train: loss: 0.0473051
[Epoch 61; Iter   210/ 1097] train: loss: 0.0398792
[Epoch 61; Iter   240/ 1097] train: loss: 0.0311784
[Epoch 61; Iter   270/ 1097] train: loss: 0.1024250
[Epoch 61; Iter   300/ 1097] train: loss: 0.0240445
[Epoch 61; Iter   330/ 1097] train: loss: 0.0249364
[Epoch 61; Iter   360/ 1097] train: loss: 0.0077336
[Epoch 61; Iter   390/ 1097] train: loss: 0.0411683
[Epoch 61; Iter   420/ 1097] train: loss: 0.0393182
[Epoch 61; Iter   450/ 1097] train: loss: 0.1654736
[Epoch 61; Iter   480/ 1097] train: loss: 0.0143608
[Epoch 61; Iter   510/ 1097] train: loss: 0.2663291
[Epoch 61; Iter   540/ 1097] train: loss: 0.0230742
[Epoch 61; Iter   570/ 1097] train: loss: 0.0553451
[Epoch 61; Iter   600/ 1097] train: loss: 0.0144441
[Epoch 61; Iter   630/ 1097] train: loss: 0.1532965
[Epoch 61; Iter   660/ 1097] train: loss: 0.0504898
[Epoch 61; Iter   690/ 1097] train: loss: 0.0042049
[Epoch 61; Iter   720/ 1097] train: loss: 0.1514145
[Epoch 61; Iter   750/ 1097] train: loss: 0.1598731
[Epoch 61; Iter   780/ 1097] train: loss: 0.0045142
[Epoch 61; Iter   810/ 1097] train: loss: 0.0074924
[Epoch 61; Iter   840/ 1097] train: loss: 0.0269225
[Epoch 61; Iter   870/ 1097] train: loss: 0.1227909
[Epoch 61; Iter   900/ 1097] train: loss: 0.1498028
[Epoch 61; Iter   930/ 1097] train: loss: 0.0129781
[Epoch 61; Iter   960/ 1097] train: loss: 0.0334542
[Epoch 61; Iter   990/ 1097] train: loss: 0.0127963
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0363752
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0024300
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0181530
[Epoch 61] ogbg-molhiv: 0.827145 val loss: 0.092979
[Epoch 61] ogbg-molhiv: 0.761069 test loss: 0.176783
[Epoch 62; Iter    13/ 1097] train: loss: 0.0541316
[Epoch 62; Iter    43/ 1097] train: loss: 0.0373537
[Epoch 62; Iter    73/ 1097] train: loss: 0.0340212
[Epoch 62; Iter   103/ 1097] train: loss: 0.0335497
[Epoch 62; Iter   133/ 1097] train: loss: 0.0177857
[Epoch 62; Iter   163/ 1097] train: loss: 0.0278905
[Epoch 62; Iter   193/ 1097] train: loss: 0.0044953
[Epoch 62; Iter   223/ 1097] train: loss: 0.0066643
[Epoch 62; Iter   253/ 1097] train: loss: 0.0076748
[Epoch 62; Iter   283/ 1097] train: loss: 0.0094553
[Epoch 62; Iter   313/ 1097] train: loss: 0.0225693
[Epoch 62; Iter   343/ 1097] train: loss: 0.0019055
[Epoch 62; Iter   373/ 1097] train: loss: 0.0443105
[Epoch 62; Iter   403/ 1097] train: loss: 0.0092810
[Epoch 62; Iter   433/ 1097] train: loss: 0.0164969
[Epoch 62; Iter   463/ 1097] train: loss: 0.0201251
[Epoch 62; Iter   493/ 1097] train: loss: 0.0135362
[Epoch 62; Iter   523/ 1097] train: loss: 0.0139314
[Epoch 62; Iter   553/ 1097] train: loss: 0.0509336
[Epoch 62; Iter   583/ 1097] train: loss: 0.0127464
[Epoch 62; Iter   613/ 1097] train: loss: 0.0037065
[Epoch 62; Iter   643/ 1097] train: loss: 0.0194033
[Epoch 62; Iter   673/ 1097] train: loss: 0.1460990
[Epoch 62; Iter   703/ 1097] train: loss: 0.0631947
[Epoch 62; Iter   733/ 1097] train: loss: 0.1404565
[Epoch 62; Iter   763/ 1097] train: loss: 0.0189178
[Epoch 62; Iter   793/ 1097] train: loss: 0.2469337
[Epoch 62; Iter   823/ 1097] train: loss: 0.0644910
[Epoch 62; Iter   853/ 1097] train: loss: 0.1072463
[Epoch 62; Iter   883/ 1097] train: loss: 0.0143431
[Epoch 62; Iter   913/ 1097] train: loss: 0.0353034
[Epoch 62; Iter   943/ 1097] train: loss: 0.0310463
[Epoch 62; Iter   973/ 1097] train: loss: 0.0399600
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0108994
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0176098
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0858955
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0068243
[Epoch 62] ogbg-molhiv: 0.833952 val loss: 0.099283
[Epoch 62] ogbg-molhiv: 0.756478 test loss: 0.184782
[Epoch 63; Iter    26/ 1097] train: loss: 0.0266107
[Epoch 63; Iter    56/ 1097] train: loss: 0.0205616
[Epoch 63; Iter    86/ 1097] train: loss: 0.0867083
[Epoch 63; Iter   116/ 1097] train: loss: 0.0372327
[Epoch 63; Iter   146/ 1097] train: loss: 0.0718702
[Epoch 63; Iter   176/ 1097] train: loss: 0.0119074
[Epoch 63; Iter   206/ 1097] train: loss: 0.0679076
[Epoch 63; Iter   236/ 1097] train: loss: 0.2078877
[Epoch 63; Iter   266/ 1097] train: loss: 0.0042644
[Epoch 63; Iter   296/ 1097] train: loss: 0.0464347
[Epoch 63; Iter   326/ 1097] train: loss: 0.0053170
[Epoch 63; Iter   356/ 1097] train: loss: 0.1382150
[Epoch 63; Iter   386/ 1097] train: loss: 0.0253230
[Epoch 63; Iter   416/ 1097] train: loss: 0.0214601
[Epoch 63; Iter   446/ 1097] train: loss: 0.0049721
[Epoch 63; Iter   476/ 1097] train: loss: 0.0017894
[Epoch 63; Iter   506/ 1097] train: loss: 0.0178277
[Epoch 63; Iter   536/ 1097] train: loss: 0.0326992
[Epoch 63; Iter   566/ 1097] train: loss: 0.2662270
[Epoch 63; Iter   596/ 1097] train: loss: 0.0607934
[Epoch 63; Iter   626/ 1097] train: loss: 0.0045439
[Epoch 63; Iter   656/ 1097] train: loss: 0.0237225
[Epoch 63; Iter   686/ 1097] train: loss: 0.0086905
[Epoch 63; Iter   716/ 1097] train: loss: 0.1188430
[Epoch 63; Iter   746/ 1097] train: loss: 0.1274344
[Epoch 63; Iter   776/ 1097] train: loss: 0.0339680
[Epoch 63; Iter   806/ 1097] train: loss: 0.0947473
[Epoch 63; Iter   836/ 1097] train: loss: 0.0146626
[Epoch 63; Iter   866/ 1097] train: loss: 0.0091108
[Epoch 63; Iter   896/ 1097] train: loss: 0.0127800
[Epoch 63; Iter   926/ 1097] train: loss: 0.0034228
[Epoch 63; Iter   956/ 1097] train: loss: 0.0053372
[Epoch 63; Iter   986/ 1097] train: loss: 0.0077471
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0149802
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0416006
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0395743
[Epoch 63] ogbg-molhiv: 0.810733 val loss: 0.103652
[Epoch 63] ogbg-molhiv: 0.738249 test loss: 0.195695
[Epoch 64; Iter     9/ 1097] train: loss: 0.0052422
[Epoch 64; Iter    39/ 1097] train: loss: 0.3070163
[Epoch 64; Iter    69/ 1097] train: loss: 0.0289097
[Epoch 64; Iter    99/ 1097] train: loss: 0.0436775
[Epoch 64; Iter   129/ 1097] train: loss: 0.0277242
[Epoch 64; Iter   159/ 1097] train: loss: 0.0062036
[Epoch 64; Iter   189/ 1097] train: loss: 0.0195849
[Epoch 64; Iter   219/ 1097] train: loss: 0.0500254
[Epoch 64; Iter   249/ 1097] train: loss: 0.0030081
[Epoch 64; Iter   279/ 1097] train: loss: 0.0031349
[Epoch 64; Iter   309/ 1097] train: loss: 0.0029885
[Epoch 64; Iter   339/ 1097] train: loss: 0.0388526
[Epoch 64; Iter   369/ 1097] train: loss: 0.0530108
[Epoch 64; Iter   399/ 1097] train: loss: 0.0856700
[Epoch 64; Iter   429/ 1097] train: loss: 0.0084465
[Epoch 64; Iter   459/ 1097] train: loss: 0.0453273
[Epoch 64; Iter   489/ 1097] train: loss: 0.0040776
[Epoch 64; Iter   519/ 1097] train: loss: 0.0338322
[Epoch 64; Iter   549/ 1097] train: loss: 0.0139827
[Epoch 64; Iter   579/ 1097] train: loss: 0.0729555
[Epoch 64; Iter   609/ 1097] train: loss: 0.0595130
[Epoch 64; Iter   639/ 1097] train: loss: 0.0061554
[Epoch 64; Iter   669/ 1097] train: loss: 0.0186758
[Epoch 64; Iter   699/ 1097] train: loss: 0.0680234
[Epoch 64; Iter   729/ 1097] train: loss: 0.0078613
[Epoch 64; Iter   759/ 1097] train: loss: 0.0484951
[Epoch 64; Iter   789/ 1097] train: loss: 0.0097601
[Epoch 64; Iter   819/ 1097] train: loss: 0.0037222
[Epoch 64; Iter   849/ 1097] train: loss: 0.1942877
[Epoch 64; Iter   879/ 1097] train: loss: 0.0165318
[Epoch 64; Iter   909/ 1097] train: loss: 0.0282811
[Epoch 64; Iter   939/ 1097] train: loss: 0.0434170
[Epoch 64; Iter   969/ 1097] train: loss: 0.0722580
[Epoch 64; Iter   999/ 1097] train: loss: 0.0528670
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0461098
[Epoch 64; Iter  1059/ 1097] train: loss: 0.1421757
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0101173
[Epoch 64] ogbg-molhiv: 0.823336 val loss: 0.100196
[Epoch 64] ogbg-molhiv: 0.752633 test loss: 0.185934
[Epoch 77; Iter   268/ 1097] train: loss: 0.0003346
[Epoch 77; Iter   298/ 1097] train: loss: 0.0005654
[Epoch 77; Iter   328/ 1097] train: loss: 0.0580002
[Epoch 77; Iter   358/ 1097] train: loss: 0.0009104
[Epoch 77; Iter   388/ 1097] train: loss: 0.0031529
[Epoch 77; Iter   418/ 1097] train: loss: 0.0016120
[Epoch 77; Iter   448/ 1097] train: loss: 0.0072542
[Epoch 77; Iter   478/ 1097] train: loss: 0.0012922
[Epoch 77; Iter   508/ 1097] train: loss: 0.0002893
[Epoch 77; Iter   538/ 1097] train: loss: 0.0000317
[Epoch 77; Iter   568/ 1097] train: loss: 0.0076646
[Epoch 77; Iter   598/ 1097] train: loss: 0.0003623
[Epoch 77; Iter   628/ 1097] train: loss: 0.0000708
[Epoch 77; Iter   658/ 1097] train: loss: 0.0024654
[Epoch 77; Iter   688/ 1097] train: loss: 0.0022549
[Epoch 77; Iter   718/ 1097] train: loss: 0.0070571
[Epoch 77; Iter   748/ 1097] train: loss: 0.0102392
[Epoch 77; Iter   778/ 1097] train: loss: 0.0037982
[Epoch 77; Iter   808/ 1097] train: loss: 0.0003125
[Epoch 77; Iter   838/ 1097] train: loss: 0.0031685
[Epoch 77; Iter   868/ 1097] train: loss: 0.0218225
[Epoch 77; Iter   898/ 1097] train: loss: 0.0018927
[Epoch 77; Iter   928/ 1097] train: loss: 0.0110899
[Epoch 77; Iter   958/ 1097] train: loss: 0.0123794
[Epoch 77; Iter   988/ 1097] train: loss: 0.0056445
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0327130
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0271714
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0059325
[Epoch 77] ogbg-molhiv: 0.744283 val loss: 0.660685
[Epoch 77] ogbg-molhiv: 0.743578 test loss: 0.730908
[Epoch 78; Iter    11/ 1097] train: loss: 0.0001162
[Epoch 78; Iter    41/ 1097] train: loss: 0.0000462
[Epoch 78; Iter    71/ 1097] train: loss: 0.0112925
[Epoch 78; Iter   101/ 1097] train: loss: 0.0003178
[Epoch 78; Iter   131/ 1097] train: loss: 0.0005682
[Epoch 78; Iter   161/ 1097] train: loss: 0.0002234
[Epoch 78; Iter   191/ 1097] train: loss: 0.0000290
[Epoch 78; Iter   221/ 1097] train: loss: 0.0009391
[Epoch 78; Iter   251/ 1097] train: loss: 0.0032676
[Epoch 78; Iter   281/ 1097] train: loss: 0.0003722
[Epoch 78; Iter   311/ 1097] train: loss: 0.0012485
[Epoch 78; Iter   341/ 1097] train: loss: 0.0037040
[Epoch 78; Iter   371/ 1097] train: loss: 0.0000568
[Epoch 78; Iter   401/ 1097] train: loss: 0.0000779
[Epoch 78; Iter   431/ 1097] train: loss: 0.0045446
[Epoch 78; Iter   461/ 1097] train: loss: 0.0012488
[Epoch 78; Iter   491/ 1097] train: loss: 0.0015550
[Epoch 78; Iter   521/ 1097] train: loss: 0.0014202
[Epoch 78; Iter   551/ 1097] train: loss: 0.0002542
[Epoch 78; Iter   581/ 1097] train: loss: 0.0033914
[Epoch 78; Iter   611/ 1097] train: loss: 0.0366027
[Epoch 78; Iter   641/ 1097] train: loss: 0.0016761
[Epoch 78; Iter   671/ 1097] train: loss: 0.0007399
[Epoch 78; Iter   701/ 1097] train: loss: 0.0416955
[Epoch 78; Iter   731/ 1097] train: loss: 0.0001634
[Epoch 78; Iter   761/ 1097] train: loss: 0.0014133
[Epoch 78; Iter   791/ 1097] train: loss: 0.0000633
[Epoch 78; Iter   821/ 1097] train: loss: 0.0000214
[Epoch 78; Iter   851/ 1097] train: loss: 0.0003508
[Epoch 78; Iter   881/ 1097] train: loss: 0.0292026
[Epoch 78; Iter   911/ 1097] train: loss: 0.0001819
[Epoch 78; Iter   941/ 1097] train: loss: 0.0001353
[Epoch 78; Iter   971/ 1097] train: loss: 0.0000632
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0005007
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0006235
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0186541
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0006899
[Epoch 78] ogbg-molhiv: 0.770680 val loss: 1.252219
[Epoch 78] ogbg-molhiv: 0.759439 test loss: 1.858776
[Epoch 79; Iter    24/ 1097] train: loss: 0.0034271
[Epoch 79; Iter    54/ 1097] train: loss: 0.0010444
[Epoch 79; Iter    84/ 1097] train: loss: 0.0001490
[Epoch 79; Iter   114/ 1097] train: loss: 0.0002682
[Epoch 79; Iter   144/ 1097] train: loss: 0.0011989
[Epoch 79; Iter   174/ 1097] train: loss: 0.0000373
[Epoch 79; Iter   204/ 1097] train: loss: 0.0771175
[Epoch 79; Iter   234/ 1097] train: loss: 0.0000388
[Epoch 79; Iter   264/ 1097] train: loss: 0.0439550
[Epoch 79; Iter   294/ 1097] train: loss: 0.1136449
[Epoch 79; Iter   324/ 1097] train: loss: 0.0003903
[Epoch 79; Iter   354/ 1097] train: loss: 0.0003151
[Epoch 79; Iter   384/ 1097] train: loss: 0.0022690
[Epoch 79; Iter   414/ 1097] train: loss: 0.0001395
[Epoch 79; Iter   444/ 1097] train: loss: 0.0003803
[Epoch 79; Iter   474/ 1097] train: loss: 0.0025517
[Epoch 79; Iter   504/ 1097] train: loss: 0.0003446
[Epoch 79; Iter   534/ 1097] train: loss: 0.0002647
[Epoch 79; Iter   564/ 1097] train: loss: 0.0238108
[Epoch 79; Iter   594/ 1097] train: loss: 0.0038014
[Epoch 79; Iter   624/ 1097] train: loss: 0.0002973
[Epoch 79; Iter   654/ 1097] train: loss: 0.0056528
[Epoch 79; Iter   684/ 1097] train: loss: 0.0035218
[Epoch 79; Iter   714/ 1097] train: loss: 0.0585095
[Epoch 79; Iter   744/ 1097] train: loss: 0.0001889
[Epoch 79; Iter   774/ 1097] train: loss: 0.0020673
[Epoch 79; Iter   804/ 1097] train: loss: 0.0004729
[Epoch 79; Iter   834/ 1097] train: loss: 0.0081498
[Epoch 79; Iter   864/ 1097] train: loss: 0.0162277
[Epoch 79; Iter   894/ 1097] train: loss: 0.0007608
[Epoch 79; Iter   924/ 1097] train: loss: 0.0005295
[Epoch 79; Iter   954/ 1097] train: loss: 0.0012283
[Epoch 79; Iter   984/ 1097] train: loss: 0.0342936
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0005728
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0000214
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0030392
[Epoch 79] ogbg-molhiv: 0.769988 val loss: 0.650788
[Epoch 79] ogbg-molhiv: 0.718697 test loss: 0.766424
[Epoch 80; Iter     7/ 1097] train: loss: 0.0179422
[Epoch 80; Iter    37/ 1097] train: loss: 0.0031278
[Epoch 80; Iter    67/ 1097] train: loss: 0.0001741
[Epoch 80; Iter    97/ 1097] train: loss: 0.0031973
[Epoch 80; Iter   127/ 1097] train: loss: 0.0004691
[Epoch 80; Iter   157/ 1097] train: loss: 0.0001426
[Epoch 80; Iter   187/ 1097] train: loss: 0.0209609
[Epoch 80; Iter   217/ 1097] train: loss: 0.0318174
[Epoch 80; Iter   247/ 1097] train: loss: 0.0019361
[Epoch 80; Iter   277/ 1097] train: loss: 0.0000342
[Epoch 80; Iter   307/ 1097] train: loss: 0.0000223
[Epoch 80; Iter   337/ 1097] train: loss: 0.0063105
[Epoch 80; Iter   367/ 1097] train: loss: 0.0071976
[Epoch 80; Iter   397/ 1097] train: loss: 0.0011575
[Epoch 80; Iter   427/ 1097] train: loss: 0.0002779
[Epoch 80; Iter   457/ 1097] train: loss: 0.0524029
[Epoch 80; Iter   487/ 1097] train: loss: 0.0003318
[Epoch 80; Iter   517/ 1097] train: loss: 0.0012266
[Epoch 80; Iter   547/ 1097] train: loss: 0.0000697
[Epoch 80; Iter   577/ 1097] train: loss: 0.1388564
[Epoch 80; Iter   607/ 1097] train: loss: 0.0002737
[Epoch 80; Iter   637/ 1097] train: loss: 0.0004624
[Epoch 80; Iter   667/ 1097] train: loss: 0.0049275
[Epoch 80; Iter   697/ 1097] train: loss: 0.0002497
[Epoch 80; Iter   727/ 1097] train: loss: 0.0003794
[Epoch 80; Iter   757/ 1097] train: loss: 0.0957279
[Epoch 80; Iter   787/ 1097] train: loss: 0.0022985
[Epoch 80; Iter   817/ 1097] train: loss: 0.0086160
[Epoch 80; Iter   847/ 1097] train: loss: 0.0107768
[Epoch 80; Iter   877/ 1097] train: loss: 0.0172016
[Epoch 80; Iter   907/ 1097] train: loss: 0.0006154
[Epoch 80; Iter   937/ 1097] train: loss: 0.0100370
[Epoch 80; Iter   967/ 1097] train: loss: 0.0003018
[Epoch 80; Iter   997/ 1097] train: loss: 0.0066180
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0780759
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0005967
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0000536
[Epoch 80] ogbg-molhiv: 0.751926 val loss: 0.794888
[Epoch 80] ogbg-molhiv: 0.727561 test loss: 0.975489
[Epoch 81; Iter    20/ 1097] train: loss: 0.0124376
[Epoch 81; Iter    50/ 1097] train: loss: 0.0007282
[Epoch 81; Iter    80/ 1097] train: loss: 0.0016191
[Epoch 81; Iter   110/ 1097] train: loss: 0.0002944
[Epoch 81; Iter   140/ 1097] train: loss: 0.0000540
[Epoch 81; Iter   170/ 1097] train: loss: 0.0347921
[Epoch 81; Iter   200/ 1097] train: loss: 0.0045481
[Epoch 81; Iter   230/ 1097] train: loss: 0.0036391
[Epoch 81; Iter   260/ 1097] train: loss: 0.0102759
[Epoch 81; Iter   290/ 1097] train: loss: 0.0196635
[Epoch 81; Iter   320/ 1097] train: loss: 0.0056694
