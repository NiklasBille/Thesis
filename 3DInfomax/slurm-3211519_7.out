>>> Starting run for dataset: toxcast
Running configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.0/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.0_4_26-05_10-52-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.0
logdir: runs/static_noise/GraphCL/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931497
[Epoch 1; Iter    60/  229] train: loss: 0.6931714
[Epoch 1; Iter    90/  229] train: loss: 0.6931844
[Epoch 1; Iter   120/  229] train: loss: 0.6931431
[Epoch 1; Iter   150/  229] train: loss: 0.6931259
[Epoch 1; Iter   180/  229] train: loss: 0.6931096
[Epoch 1; Iter   210/  229] train: loss: 0.6930931
[Epoch 1] ogbg-moltoxcast: 0.495290 val loss: 0.693076
[Epoch 1] ogbg-moltoxcast: 0.496743 test loss: 0.693073
[Epoch 2; Iter    11/  229] train: loss: 0.6931412
[Epoch 2; Iter    41/  229] train: loss: 0.6930594
[Epoch 2; Iter    71/  229] train: loss: 0.6930700
[Epoch 2; Iter   101/  229] train: loss: 0.6931484
[Epoch 2; Iter   131/  229] train: loss: 0.6931148
[Epoch 2; Iter   161/  229] train: loss: 0.6930408
[Epoch 2; Iter   191/  229] train: loss: 0.6930220
[Epoch 2; Iter   221/  229] train: loss: 0.6929916
[Epoch 2] ogbg-moltoxcast: 0.496103 val loss: 0.692991
[Epoch 2] ogbg-moltoxcast: 0.497068 test loss: 0.693000
[Epoch 3; Iter    22/  229] train: loss: 0.6929821
[Epoch 3; Iter    52/  229] train: loss: 0.6929782
[Epoch 3; Iter    82/  229] train: loss: 0.6929922
[Epoch 3; Iter   112/  229] train: loss: 0.6929609
[Epoch 3; Iter   142/  229] train: loss: 0.6928953
[Epoch 3; Iter   172/  229] train: loss: 0.6928861
[Epoch 3; Iter   202/  229] train: loss: 0.6928747
[Epoch 3] ogbg-moltoxcast: 0.494515 val loss: 0.692828
[Epoch 3] ogbg-moltoxcast: 0.497311 test loss: 0.692854
[Epoch 4; Iter     3/  229] train: loss: 0.6929197
[Epoch 4; Iter    33/  229] train: loss: 0.6900464
[Epoch 4; Iter    63/  229] train: loss: 0.6738368
[Epoch 4; Iter    93/  229] train: loss: 0.6539524
[Epoch 4; Iter   123/  229] train: loss: 0.6121913
[Epoch 4; Iter   153/  229] train: loss: 0.5775990
[Epoch 4; Iter   183/  229] train: loss: 0.5166746
[Epoch 4; Iter   213/  229] train: loss: 0.4469429
[Epoch 4] ogbg-moltoxcast: 0.595498 val loss: 0.481272
[Epoch 4] ogbg-moltoxcast: 0.556060 test loss: 0.499907
[Epoch 5; Iter    14/  229] train: loss: 0.4213946
[Epoch 5; Iter    44/  229] train: loss: 0.3478724
[Epoch 5; Iter    74/  229] train: loss: 0.2868555
[Epoch 5; Iter   104/  229] train: loss: 0.3171404
[Epoch 5; Iter   134/  229] train: loss: 0.3228222
[Epoch 5; Iter   164/  229] train: loss: 0.2520163
[Epoch 5; Iter   194/  229] train: loss: 0.2550236
[Epoch 5; Iter   224/  229] train: loss: 0.1680996
[Epoch 5] ogbg-moltoxcast: 0.636365 val loss: 0.280028
[Epoch 5] ogbg-moltoxcast: 0.585944 test loss: 0.314591
[Epoch 6; Iter    25/  229] train: loss: 0.2597849
[Epoch 6; Iter    55/  229] train: loss: 0.2067361
[Epoch 6; Iter    85/  229] train: loss: 0.3019025
[Epoch 6; Iter   115/  229] train: loss: 0.2240948
[Epoch 6; Iter   145/  229] train: loss: 0.2003880
[Epoch 6; Iter   175/  229] train: loss: 0.1832266
[Epoch 6; Iter   205/  229] train: loss: 0.1764330
[Epoch 6] ogbg-moltoxcast: 0.657390 val loss: 0.262359
[Epoch 6] ogbg-moltoxcast: 0.618228 test loss: 0.299144
[Epoch 7; Iter     6/  229] train: loss: 0.1242949
[Epoch 7; Iter    36/  229] train: loss: 0.2334784
[Epoch 7; Iter    66/  229] train: loss: 0.2198029
[Epoch 7; Iter    96/  229] train: loss: 0.1846606
[Epoch 7; Iter   126/  229] train: loss: 0.2904757
[Epoch 7; Iter   156/  229] train: loss: 0.1761917
[Epoch 7; Iter   186/  229] train: loss: 0.3214080
[Epoch 7; Iter   216/  229] train: loss: 0.1975090
[Epoch 7] ogbg-moltoxcast: 0.642017 val loss: 0.270818
[Epoch 7] ogbg-moltoxcast: 0.595363 test loss: 0.315432
[Epoch 8; Iter    17/  229] train: loss: 0.1501595
[Epoch 8; Iter    47/  229] train: loss: 0.3101094
[Epoch 8; Iter    77/  229] train: loss: 0.1806228
[Epoch 8; Iter   107/  229] train: loss: 0.2607083
[Epoch 8; Iter   137/  229] train: loss: 0.1952269
[Epoch 8; Iter   167/  229] train: loss: 0.1692667
[Epoch 8; Iter   197/  229] train: loss: 0.2282378
[Epoch 8; Iter   227/  229] train: loss: 0.2127542
[Epoch 8] ogbg-moltoxcast: 0.646868 val loss: 0.263991
[Epoch 8] ogbg-moltoxcast: 0.614234 test loss: 0.304118
[Epoch 9; Iter    28/  229] train: loss: 0.1344221
[Epoch 9; Iter    58/  229] train: loss: 0.1329035
[Epoch 9; Iter    88/  229] train: loss: 0.2101739
[Epoch 9; Iter   118/  229] train: loss: 0.1155761
[Epoch 9; Iter   148/  229] train: loss: 0.2494125
[Epoch 9; Iter   178/  229] train: loss: 0.2278073
[Epoch 9; Iter   208/  229] train: loss: 0.1756353
[Epoch 9] ogbg-moltoxcast: 0.660623 val loss: 0.260824
[Epoch 9] ogbg-moltoxcast: 0.633628 test loss: 0.297956
[Epoch 10; Iter     9/  229] train: loss: 0.1464703
[Epoch 10; Iter    39/  229] train: loss: 0.1475478
[Epoch 10; Iter    69/  229] train: loss: 0.2261933
[Epoch 10; Iter    99/  229] train: loss: 0.2685210
[Epoch 10; Iter   129/  229] train: loss: 0.1717881
[Epoch 10; Iter   159/  229] train: loss: 0.2068834
[Epoch 10; Iter   189/  229] train: loss: 0.2400950
[Epoch 10; Iter   219/  229] train: loss: 0.2657329
[Epoch 10] ogbg-moltoxcast: 0.647911 val loss: 0.263234
[Epoch 10] ogbg-moltoxcast: 0.629747 test loss: 0.299039
[Epoch 11; Iter    20/  229] train: loss: 0.1642591
[Epoch 11; Iter    50/  229] train: loss: 0.1972732
[Epoch 11; Iter    80/  229] train: loss: 0.1729400
[Epoch 11; Iter   110/  229] train: loss: 0.1672244
[Epoch 11; Iter   140/  229] train: loss: 0.2610992
[Epoch 11; Iter   170/  229] train: loss: 0.2148610
[Epoch 11; Iter   200/  229] train: loss: 0.2833494
[Epoch 11] ogbg-moltoxcast: 0.655090 val loss: 0.256416
[Epoch 11] ogbg-moltoxcast: 0.637544 test loss: 0.294180
[Epoch 12; Iter     1/  229] train: loss: 0.1697549
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.0/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.0_5_26-05_10-52-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.0
logdir: runs/static_noise/GraphCL/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931581
[Epoch 1; Iter    60/  229] train: loss: 0.6931779
[Epoch 1; Iter    90/  229] train: loss: 0.6931946
[Epoch 1; Iter   120/  229] train: loss: 0.6931390
[Epoch 1; Iter   150/  229] train: loss: 0.6931357
[Epoch 1; Iter   180/  229] train: loss: 0.6930536
[Epoch 1; Iter   210/  229] train: loss: 0.6930958
[Epoch 1] ogbg-moltoxcast: 0.502406 val loss: 0.692998
[Epoch 1] ogbg-moltoxcast: 0.499999 test loss: 0.692976
[Epoch 2; Iter    11/  229] train: loss: 0.6931233
[Epoch 2; Iter    41/  229] train: loss: 0.6930510
[Epoch 2; Iter    71/  229] train: loss: 0.6930448
[Epoch 2; Iter   101/  229] train: loss: 0.6930963
[Epoch 2; Iter   131/  229] train: loss: 0.6930626
[Epoch 2; Iter   161/  229] train: loss: 0.6929995
[Epoch 2; Iter   191/  229] train: loss: 0.6930235
[Epoch 2; Iter   221/  229] train: loss: 0.6929896
[Epoch 2] ogbg-moltoxcast: 0.503114 val loss: 0.692854
[Epoch 2] ogbg-moltoxcast: 0.499710 test loss: 0.692842
[Epoch 3; Iter    22/  229] train: loss: 0.6929408
[Epoch 3; Iter    52/  229] train: loss: 0.6928868
[Epoch 3; Iter    82/  229] train: loss: 0.6929260
[Epoch 3; Iter   112/  229] train: loss: 0.6928506
[Epoch 3; Iter   142/  229] train: loss: 0.6928117
[Epoch 3; Iter   172/  229] train: loss: 0.6928121
[Epoch 3; Iter   202/  229] train: loss: 0.6928120
[Epoch 3] ogbg-moltoxcast: 0.503280 val loss: 0.692659
[Epoch 3] ogbg-moltoxcast: 0.499966 test loss: 0.692672
[Epoch 4; Iter     3/  229] train: loss: 0.6929179
[Epoch 4; Iter    33/  229] train: loss: 0.6894733
[Epoch 4; Iter    63/  229] train: loss: 0.6720691
[Epoch 4; Iter    93/  229] train: loss: 0.6215068
[Epoch 4; Iter   123/  229] train: loss: 0.5833986
[Epoch 4; Iter   153/  229] train: loss: 0.5374007
[Epoch 4; Iter   183/  229] train: loss: 0.4624019
[Epoch 4; Iter   213/  229] train: loss: 0.4295404
[Epoch 4] ogbg-moltoxcast: 0.584840 val loss: 0.501610
[Epoch 4] ogbg-moltoxcast: 0.532663 test loss: 0.517421
[Epoch 5; Iter    14/  229] train: loss: 0.3955096
[Epoch 5; Iter    44/  229] train: loss: 0.3139827
[Epoch 5; Iter    74/  229] train: loss: 0.3517908
[Epoch 5; Iter   104/  229] train: loss: 0.2779080
[Epoch 5; Iter   134/  229] train: loss: 0.2493790
[Epoch 5; Iter   164/  229] train: loss: 0.2137391
[Epoch 5; Iter   194/  229] train: loss: 0.2225495
[Epoch 5; Iter   224/  229] train: loss: 0.1596726
[Epoch 5] ogbg-moltoxcast: 0.625994 val loss: 0.289057
[Epoch 5] ogbg-moltoxcast: 0.591643 test loss: 0.322400
[Epoch 6; Iter    25/  229] train: loss: 0.2970202
[Epoch 6; Iter    55/  229] train: loss: 0.2079745
[Epoch 6; Iter    85/  229] train: loss: 0.1748263
[Epoch 6; Iter   115/  229] train: loss: 0.1899210
[Epoch 6; Iter   145/  229] train: loss: 0.2552728
[Epoch 6; Iter   175/  229] train: loss: 0.2190222
[Epoch 6; Iter   205/  229] train: loss: 0.1859222
[Epoch 6] ogbg-moltoxcast: 0.631785 val loss: 0.271893
[Epoch 6] ogbg-moltoxcast: 0.606728 test loss: 0.312389
[Epoch 7; Iter     6/  229] train: loss: 0.1682702
[Epoch 7; Iter    36/  229] train: loss: 0.1438351
[Epoch 7; Iter    66/  229] train: loss: 0.2374838
[Epoch 7; Iter    96/  229] train: loss: 0.2362249
[Epoch 7; Iter   126/  229] train: loss: 0.2664446
[Epoch 7; Iter   156/  229] train: loss: 0.1564862
[Epoch 7; Iter   186/  229] train: loss: 0.3335118
[Epoch 7; Iter   216/  229] train: loss: 0.1902444
[Epoch 7] ogbg-moltoxcast: 0.651241 val loss: 0.277010
[Epoch 7] ogbg-moltoxcast: 0.619195 test loss: 0.354018
[Epoch 8; Iter    17/  229] train: loss: 0.2519876
[Epoch 8; Iter    47/  229] train: loss: 0.1632340
[Epoch 8; Iter    77/  229] train: loss: 0.1800392
[Epoch 8; Iter   107/  229] train: loss: 0.2241964
[Epoch 8; Iter   137/  229] train: loss: 0.2418577
[Epoch 8; Iter   167/  229] train: loss: 0.1691551
[Epoch 8; Iter   197/  229] train: loss: 0.2088196
[Epoch 8; Iter   227/  229] train: loss: 0.1450208
[Epoch 8] ogbg-moltoxcast: 0.637507 val loss: 0.258218
[Epoch 8] ogbg-moltoxcast: 0.610220 test loss: 0.296153
[Epoch 9; Iter    28/  229] train: loss: 0.1609924
[Epoch 9; Iter    58/  229] train: loss: 0.2088433
[Epoch 9; Iter    88/  229] train: loss: 0.2081574
[Epoch 9; Iter   118/  229] train: loss: 0.1645087
[Epoch 9; Iter   148/  229] train: loss: 0.2311943
[Epoch 9; Iter   178/  229] train: loss: 0.1891322
[Epoch 9; Iter   208/  229] train: loss: 0.1932367
[Epoch 9] ogbg-moltoxcast: 0.601283 val loss: 0.298746
[Epoch 9] ogbg-moltoxcast: 0.605243 test loss: 0.356276
[Epoch 10; Iter     9/  229] train: loss: 0.1442986
[Epoch 10; Iter    39/  229] train: loss: 0.1130720
[Epoch 10; Iter    69/  229] train: loss: 0.2687366
[Epoch 10; Iter    99/  229] train: loss: 0.1594390
[Epoch 10; Iter   129/  229] train: loss: 0.1669736
[Epoch 10; Iter   159/  229] train: loss: 0.1769923
[Epoch 10; Iter   189/  229] train: loss: 0.2878028
[Epoch 10; Iter   219/  229] train: loss: 0.1731113
[Epoch 10] ogbg-moltoxcast: 0.665911 val loss: 0.259328
[Epoch 10] ogbg-moltoxcast: 0.633550 test loss: 0.301263
[Epoch 11; Iter    20/  229] train: loss: 0.1812049
[Epoch 11; Iter    50/  229] train: loss: 0.1751489
[Epoch 11; Iter    80/  229] train: loss: 0.1732610
[Epoch 11; Iter   110/  229] train: loss: 0.1874287
[Epoch 11; Iter   140/  229] train: loss: 0.2157427
[Epoch 11; Iter   170/  229] train: loss: 0.1574495
[Epoch 11; Iter   200/  229] train: loss: 0.2055921
[Epoch 11] ogbg-moltoxcast: 0.672745 val loss: 0.267468
[Epoch 11] ogbg-moltoxcast: 0.637238 test loss: 0.306246
[Epoch 12; Iter     1/  229] train: loss: 0.2067777
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.0/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.0_6_26-05_10-52-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.0
logdir: runs/static_noise/GraphCL/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931946
[Epoch 1; Iter    60/  229] train: loss: 0.6931317
[Epoch 1; Iter    90/  229] train: loss: 0.6931166
[Epoch 1; Iter   120/  229] train: loss: 0.6931515
[Epoch 1; Iter   150/  229] train: loss: 0.6931350
[Epoch 1; Iter   180/  229] train: loss: 0.6931351
[Epoch 1; Iter   210/  229] train: loss: 0.6931400
[Epoch 1] ogbg-moltoxcast: 0.506428 val loss: 0.693134
[Epoch 1] ogbg-moltoxcast: 0.500122 test loss: 0.693210
[Epoch 2; Iter    11/  229] train: loss: 0.6930764
[Epoch 2; Iter    41/  229] train: loss: 0.6930979
[Epoch 2; Iter    71/  229] train: loss: 0.6930750
[Epoch 2; Iter   101/  229] train: loss: 0.6931231
[Epoch 2; Iter   131/  229] train: loss: 0.6931165
[Epoch 2; Iter   161/  229] train: loss: 0.6930628
[Epoch 2; Iter   191/  229] train: loss: 0.6930342
[Epoch 2; Iter   221/  229] train: loss: 0.6929967
[Epoch 2] ogbg-moltoxcast: 0.508186 val loss: 0.692987
[Epoch 2] ogbg-moltoxcast: 0.499746 test loss: 0.693073
[Epoch 3; Iter    22/  229] train: loss: 0.6930100
[Epoch 3; Iter    52/  229] train: loss: 0.6929141
[Epoch 3; Iter    82/  229] train: loss: 0.6929750
[Epoch 3; Iter   112/  229] train: loss: 0.6929163
[Epoch 3; Iter   142/  229] train: loss: 0.6928487
[Epoch 3; Iter   172/  229] train: loss: 0.6928104
[Epoch 3; Iter   202/  229] train: loss: 0.6928424
[Epoch 3] ogbg-moltoxcast: 0.507964 val loss: 0.692838
[Epoch 3] ogbg-moltoxcast: 0.499086 test loss: 0.692943
[Epoch 4; Iter     3/  229] train: loss: 0.6928262
[Epoch 4; Iter    33/  229] train: loss: 0.6890059
[Epoch 4; Iter    63/  229] train: loss: 0.6729757
[Epoch 4; Iter    93/  229] train: loss: 0.6330649
[Epoch 4; Iter   123/  229] train: loss: 0.6335372
[Epoch 4; Iter   153/  229] train: loss: 0.5428810
[Epoch 4; Iter   183/  229] train: loss: 0.5619822
[Epoch 4; Iter   213/  229] train: loss: 0.4289413
[Epoch 4] ogbg-moltoxcast: 0.611094 val loss: 0.585912
[Epoch 4] ogbg-moltoxcast: 0.556231 test loss: 0.602667
[Epoch 5; Iter    14/  229] train: loss: 0.4436116
[Epoch 5; Iter    44/  229] train: loss: 0.3648249
[Epoch 5; Iter    74/  229] train: loss: 0.3163283
[Epoch 5; Iter   104/  229] train: loss: 0.3104354
[Epoch 5; Iter   134/  229] train: loss: 0.2983662
[Epoch 5; Iter   164/  229] train: loss: 0.2414715
[Epoch 5; Iter   194/  229] train: loss: 0.2677874
[Epoch 5; Iter   224/  229] train: loss: 0.3086970
[Epoch 5] ogbg-moltoxcast: 0.639199 val loss: 0.283510
[Epoch 5] ogbg-moltoxcast: 0.597066 test loss: 0.321721
[Epoch 6; Iter    25/  229] train: loss: 0.3131064
[Epoch 6; Iter    55/  229] train: loss: 0.1867107
[Epoch 6; Iter    85/  229] train: loss: 0.2428264
[Epoch 6; Iter   115/  229] train: loss: 0.2451224
[Epoch 6; Iter   145/  229] train: loss: 0.2104033
[Epoch 6; Iter   175/  229] train: loss: 0.1781444
[Epoch 6; Iter   205/  229] train: loss: 0.1489742
[Epoch 6] ogbg-moltoxcast: 0.653556 val loss: 0.267029
[Epoch 6] ogbg-moltoxcast: 0.617907 test loss: 0.306024
[Epoch 7; Iter     6/  229] train: loss: 0.1716107
[Epoch 7; Iter    36/  229] train: loss: 0.1573531
[Epoch 7; Iter    66/  229] train: loss: 0.2025119
[Epoch 7; Iter    96/  229] train: loss: 0.2826472
[Epoch 7; Iter   126/  229] train: loss: 0.1907786
[Epoch 7; Iter   156/  229] train: loss: 0.2559970
[Epoch 7; Iter   186/  229] train: loss: 0.1969710
[Epoch 7; Iter   216/  229] train: loss: 0.2081037
[Epoch 7] ogbg-moltoxcast: 0.648730 val loss: 0.267593
[Epoch 7] ogbg-moltoxcast: 0.610025 test loss: 0.315363
[Epoch 8; Iter    17/  229] train: loss: 0.1676529
[Epoch 8; Iter    47/  229] train: loss: 0.1817997
[Epoch 8; Iter    77/  229] train: loss: 0.1678946
[Epoch 8; Iter   107/  229] train: loss: 0.2156225
[Epoch 8; Iter   137/  229] train: loss: 0.2435556
[Epoch 8; Iter   167/  229] train: loss: 0.1913949
[Epoch 8; Iter   197/  229] train: loss: 0.2285268
[Epoch 8; Iter   227/  229] train: loss: 0.3828632
[Epoch 8] ogbg-moltoxcast: 0.647235 val loss: 0.273199
[Epoch 8] ogbg-moltoxcast: 0.629567 test loss: 0.637155
[Epoch 9; Iter    28/  229] train: loss: 0.1594361
[Epoch 9; Iter    58/  229] train: loss: 0.1408802
[Epoch 9; Iter    88/  229] train: loss: 0.1667695
[Epoch 9; Iter   118/  229] train: loss: 0.2456603
[Epoch 9; Iter   148/  229] train: loss: 0.3026704
[Epoch 9; Iter   178/  229] train: loss: 0.1541025
[Epoch 9; Iter   208/  229] train: loss: 0.2485811
[Epoch 9] ogbg-moltoxcast: 0.655678 val loss: 0.262582
[Epoch 9] ogbg-moltoxcast: 0.611638 test loss: 0.447777
[Epoch 10; Iter     9/  229] train: loss: 0.2244963
[Epoch 10; Iter    39/  229] train: loss: 0.2117465
[Epoch 10; Iter    69/  229] train: loss: 0.1520443
[Epoch 10; Iter    99/  229] train: loss: 0.1127748
[Epoch 10; Iter   129/  229] train: loss: 0.1633615
[Epoch 10; Iter   159/  229] train: loss: 0.2300606
[Epoch 10; Iter   189/  229] train: loss: 0.1964786
[Epoch 10; Iter   219/  229] train: loss: 0.2345305
[Epoch 10] ogbg-moltoxcast: 0.655163 val loss: 0.271532
[Epoch 10] ogbg-moltoxcast: 0.634549 test loss: 0.399538
[Epoch 11; Iter    20/  229] train: loss: 0.1561411
[Epoch 11; Iter    50/  229] train: loss: 0.1822135
[Epoch 11; Iter    80/  229] train: loss: 0.1609117
[Epoch 11; Iter   110/  229] train: loss: 0.1358081
[Epoch 11; Iter   140/  229] train: loss: 0.2255742
[Epoch 11; Iter   170/  229] train: loss: 0.2920725
[Epoch 11; Iter   200/  229] train: loss: 0.1451195
[Epoch 11] ogbg-moltoxcast: 0.646844 val loss: 0.329831
[Epoch 11] ogbg-moltoxcast: 0.633458 test loss: 0.589070
[Epoch 12; Iter     1/  229] train: loss: 0.2125261
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.05/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.05_4_26-05_10-54-46
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.05
logdir: runs/static_noise/GraphCL/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931430
[Epoch 1; Iter    60/  229] train: loss: 0.6931665
[Epoch 1; Iter    90/  229] train: loss: 0.6931501
[Epoch 1; Iter   120/  229] train: loss: 0.6931397
[Epoch 1; Iter   150/  229] train: loss: 0.6931150
[Epoch 1; Iter   180/  229] train: loss: 0.6931379
[Epoch 1; Iter   210/  229] train: loss: 0.6931124
[Epoch 1] ogbg-moltoxcast: 0.492824 val loss: 0.693001
[Epoch 1] ogbg-moltoxcast: 0.493266 test loss: 0.693000
[Epoch 2; Iter    11/  229] train: loss: 0.6931605
[Epoch 2; Iter    41/  229] train: loss: 0.6930795
[Epoch 2; Iter    71/  229] train: loss: 0.6931074
[Epoch 2; Iter   101/  229] train: loss: 0.6931210
[Epoch 2; Iter   131/  229] train: loss: 0.6931208
[Epoch 2; Iter   161/  229] train: loss: 0.6930717
[Epoch 2; Iter   191/  229] train: loss: 0.6929966
[Epoch 2; Iter   221/  229] train: loss: 0.6930130
[Epoch 2] ogbg-moltoxcast: 0.492732 val loss: 0.692898
[Epoch 2] ogbg-moltoxcast: 0.493611 test loss: 0.692912
[Epoch 3; Iter    22/  229] train: loss: 0.6929690
[Epoch 3; Iter    52/  229] train: loss: 0.6929545
[Epoch 3; Iter    82/  229] train: loss: 0.6930090
[Epoch 3; Iter   112/  229] train: loss: 0.6929591
[Epoch 3; Iter   142/  229] train: loss: 0.6928971
[Epoch 3; Iter   172/  229] train: loss: 0.6928918
[Epoch 3; Iter   202/  229] train: loss: 0.6928681
[Epoch 3] ogbg-moltoxcast: 0.491311 val loss: 0.692743
[Epoch 3] ogbg-moltoxcast: 0.494071 test loss: 0.692775
[Epoch 4; Iter     3/  229] train: loss: 0.6929280
[Epoch 4; Iter    33/  229] train: loss: 0.6900231
[Epoch 4; Iter    63/  229] train: loss: 0.6751688
[Epoch 4; Iter    93/  229] train: loss: 0.6531351
[Epoch 4; Iter   123/  229] train: loss: 0.6077434
[Epoch 4; Iter   153/  229] train: loss: 0.5802883
[Epoch 4; Iter   183/  229] train: loss: 0.5114125
[Epoch 4; Iter   213/  229] train: loss: 0.4506633
[Epoch 4] ogbg-moltoxcast: 0.623690 val loss: 0.440663
[Epoch 4] ogbg-moltoxcast: 0.566398 test loss: 0.469830
[Epoch 5; Iter    14/  229] train: loss: 0.4343018
[Epoch 5; Iter    44/  229] train: loss: 0.3538123
[Epoch 5; Iter    74/  229] train: loss: 0.2832034
[Epoch 5; Iter   104/  229] train: loss: 0.3274502
[Epoch 5; Iter   134/  229] train: loss: 0.3261773
[Epoch 5; Iter   164/  229] train: loss: 0.2572817
[Epoch 5; Iter   194/  229] train: loss: 0.2499282
[Epoch 5; Iter   224/  229] train: loss: 0.1675679
[Epoch 5] ogbg-moltoxcast: 0.614453 val loss: 1.115378
[Epoch 5] ogbg-moltoxcast: 0.568757 test loss: 0.989196
[Epoch 6; Iter    25/  229] train: loss: 0.2760191
[Epoch 6; Iter    55/  229] train: loss: 0.2054854
[Epoch 6; Iter    85/  229] train: loss: 0.3014775
[Epoch 6; Iter   115/  229] train: loss: 0.2140708
[Epoch 6; Iter   145/  229] train: loss: 0.2058134
[Epoch 6; Iter   175/  229] train: loss: 0.1851479
[Epoch 6; Iter   205/  229] train: loss: 0.1835622
[Epoch 6] ogbg-moltoxcast: 0.640404 val loss: 0.279414
[Epoch 6] ogbg-moltoxcast: 0.599579 test loss: 0.320460
[Epoch 7; Iter     6/  229] train: loss: 0.1244351
[Epoch 7; Iter    36/  229] train: loss: 0.2300133
[Epoch 7; Iter    66/  229] train: loss: 0.2159967
[Epoch 7; Iter    96/  229] train: loss: 0.1874433
[Epoch 7; Iter   126/  229] train: loss: 0.2747424
[Epoch 7; Iter   156/  229] train: loss: 0.1818121
[Epoch 7; Iter   186/  229] train: loss: 0.3174452
[Epoch 7; Iter   216/  229] train: loss: 0.1983214
[Epoch 7] ogbg-moltoxcast: 0.642983 val loss: 0.276234
[Epoch 7] ogbg-moltoxcast: 0.594635 test loss: 0.324821
[Epoch 8; Iter    17/  229] train: loss: 0.1546888
[Epoch 8; Iter    47/  229] train: loss: 0.3104863
[Epoch 8; Iter    77/  229] train: loss: 0.1914045
[Epoch 8; Iter   107/  229] train: loss: 0.2542168
[Epoch 8; Iter   137/  229] train: loss: 0.1877940
[Epoch 8; Iter   167/  229] train: loss: 0.1700621
[Epoch 8; Iter   197/  229] train: loss: 0.2269426
[Epoch 8; Iter   227/  229] train: loss: 0.2198551
[Epoch 8] ogbg-moltoxcast: 0.635497 val loss: 0.269598
[Epoch 8] ogbg-moltoxcast: 0.602292 test loss: 0.313423
[Epoch 9; Iter    28/  229] train: loss: 0.1296778
[Epoch 9; Iter    58/  229] train: loss: 0.1279496
[Epoch 9; Iter    88/  229] train: loss: 0.2116199
[Epoch 9; Iter   118/  229] train: loss: 0.1274887
[Epoch 9; Iter   148/  229] train: loss: 0.2403319
[Epoch 9; Iter   178/  229] train: loss: 0.2129376
[Epoch 9; Iter   208/  229] train: loss: 0.1940621
[Epoch 9] ogbg-moltoxcast: 0.674378 val loss: 0.276372
[Epoch 9] ogbg-moltoxcast: 0.626709 test loss: 0.302069
[Epoch 10; Iter     9/  229] train: loss: 0.1455935
[Epoch 10; Iter    39/  229] train: loss: 0.1594065
[Epoch 10; Iter    69/  229] train: loss: 0.2480124
[Epoch 10; Iter    99/  229] train: loss: 0.2726371
[Epoch 10; Iter   129/  229] train: loss: 0.1773594
[Epoch 10; Iter   159/  229] train: loss: 0.2153746
[Epoch 10; Iter   189/  229] train: loss: 0.2470908
[Epoch 10; Iter   219/  229] train: loss: 0.2791047
[Epoch 10] ogbg-moltoxcast: 0.666265 val loss: 0.258287
[Epoch 10] ogbg-moltoxcast: 0.636513 test loss: 0.293407
[Epoch 11; Iter    20/  229] train: loss: 0.1745184
[Epoch 11; Iter    50/  229] train: loss: 0.1954038
[Epoch 11; Iter    80/  229] train: loss: 0.1677225
[Epoch 11; Iter   110/  229] train: loss: 0.1587010
[Epoch 11; Iter   140/  229] train: loss: 0.2792091
[Epoch 11; Iter   170/  229] train: loss: 0.2189564
[Epoch 11; Iter   200/  229] train: loss: 0.2822843
[Epoch 11] ogbg-moltoxcast: 0.677965 val loss: 0.265283
[Epoch 11] ogbg-moltoxcast: 0.622905 test loss: 0.307155
[Epoch 12; Iter     1/  229] train: loss: 0.1620022
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.05/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.05_6_26-05_10-54-50
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.05
logdir: runs/static_noise/GraphCL/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6932058
[Epoch 1; Iter    60/  229] train: loss: 0.6931345
[Epoch 1; Iter    90/  229] train: loss: 0.6931329
[Epoch 1; Iter   120/  229] train: loss: 0.6931254
[Epoch 1; Iter   150/  229] train: loss: 0.6931503
[Epoch 1; Iter   180/  229] train: loss: 0.6931182
[Epoch 1; Iter   210/  229] train: loss: 0.6931411
[Epoch 1] ogbg-moltoxcast: 0.501263 val loss: 0.693066
[Epoch 1] ogbg-moltoxcast: 0.496950 test loss: 0.693170
[Epoch 2; Iter    11/  229] train: loss: 0.6931177
[Epoch 2; Iter    41/  229] train: loss: 0.6931229
[Epoch 2; Iter    71/  229] train: loss: 0.6931069
[Epoch 2; Iter   101/  229] train: loss: 0.6931252
[Epoch 2; Iter   131/  229] train: loss: 0.6931241
[Epoch 2; Iter   161/  229] train: loss: 0.6930737
[Epoch 2; Iter   191/  229] train: loss: 0.6930207
[Epoch 2; Iter   221/  229] train: loss: 0.6930145
[Epoch 2] ogbg-moltoxcast: 0.501621 val loss: 0.692938
[Epoch 2] ogbg-moltoxcast: 0.497310 test loss: 0.693045
[Epoch 3; Iter    22/  229] train: loss: 0.6930172
[Epoch 3; Iter    52/  229] train: loss: 0.6929488
[Epoch 3; Iter    82/  229] train: loss: 0.6929761
[Epoch 3; Iter   112/  229] train: loss: 0.6929407
[Epoch 3; Iter   142/  229] train: loss: 0.6928211
[Epoch 3; Iter   172/  229] train: loss: 0.6928734
[Epoch 3; Iter   202/  229] train: loss: 0.6928623
[Epoch 3] ogbg-moltoxcast: 0.504097 val loss: 0.692757
[Epoch 3] ogbg-moltoxcast: 0.498352 test loss: 0.692878
[Epoch 4; Iter     3/  229] train: loss: 0.6928221
[Epoch 4; Iter    33/  229] train: loss: 0.6887429
[Epoch 4; Iter    63/  229] train: loss: 0.6735048
[Epoch 4; Iter    93/  229] train: loss: 0.6377758
[Epoch 4; Iter   123/  229] train: loss: 0.6347780
[Epoch 4; Iter   153/  229] train: loss: 0.5414407
[Epoch 4; Iter   183/  229] train: loss: 0.5560916
[Epoch 4; Iter   213/  229] train: loss: 0.4345872
[Epoch 4] ogbg-moltoxcast: 0.611149 val loss: 0.545113
[Epoch 4] ogbg-moltoxcast: 0.560565 test loss: 0.563342
[Epoch 5; Iter    14/  229] train: loss: 0.4467903
[Epoch 5; Iter    44/  229] train: loss: 0.3586549
[Epoch 5; Iter    74/  229] train: loss: 0.3172331
[Epoch 5; Iter   104/  229] train: loss: 0.3101666
[Epoch 5; Iter   134/  229] train: loss: 0.2930249
[Epoch 5; Iter   164/  229] train: loss: 0.2426133
[Epoch 5; Iter   194/  229] train: loss: 0.2636654
[Epoch 5; Iter   224/  229] train: loss: 0.3129746
[Epoch 5] ogbg-moltoxcast: 0.626161 val loss: 0.283896
[Epoch 5] ogbg-moltoxcast: 0.593390 test loss: 0.319644
[Epoch 6; Iter    25/  229] train: loss: 0.3176388
[Epoch 6; Iter    55/  229] train: loss: 0.1847421
[Epoch 6; Iter    85/  229] train: loss: 0.2451721
[Epoch 6; Iter   115/  229] train: loss: 0.2611051
[Epoch 6; Iter   145/  229] train: loss: 0.2103803
[Epoch 6; Iter   175/  229] train: loss: 0.1877092
[Epoch 6; Iter   205/  229] train: loss: 0.1444253
[Epoch 6] ogbg-moltoxcast: 0.650758 val loss: 0.284401
[Epoch 6] ogbg-moltoxcast: 0.613115 test loss: 0.317008
[Epoch 7; Iter     6/  229] train: loss: 0.1758471
[Epoch 7; Iter    36/  229] train: loss: 0.1543140
[Epoch 7; Iter    66/  229] train: loss: 0.2083145
[Epoch 7; Iter    96/  229] train: loss: 0.2924600
[Epoch 7; Iter   126/  229] train: loss: 0.1911542
[Epoch 7; Iter   156/  229] train: loss: 0.2398047
[Epoch 7; Iter   186/  229] train: loss: 0.1954047
[Epoch 7; Iter   216/  229] train: loss: 0.2016667
[Epoch 7] ogbg-moltoxcast: 0.632552 val loss: 0.268425
[Epoch 7] ogbg-moltoxcast: 0.599965 test loss: 0.306295
[Epoch 8; Iter    17/  229] train: loss: 0.1640463
[Epoch 8; Iter    47/  229] train: loss: 0.1974687
[Epoch 8; Iter    77/  229] train: loss: 0.1736041
[Epoch 8; Iter   107/  229] train: loss: 0.2217803
[Epoch 8; Iter   137/  229] train: loss: 0.2360972
[Epoch 8; Iter   167/  229] train: loss: 0.1990684
[Epoch 8; Iter   197/  229] train: loss: 0.2345015
[Epoch 8; Iter   227/  229] train: loss: 0.4127637
[Epoch 8] ogbg-moltoxcast: 0.641874 val loss: 0.267176
[Epoch 8] ogbg-moltoxcast: 0.614645 test loss: 0.314308
[Epoch 9; Iter    28/  229] train: loss: 0.1638106
[Epoch 9; Iter    58/  229] train: loss: 0.1421667
[Epoch 9; Iter    88/  229] train: loss: 0.1804834
[Epoch 9; Iter   118/  229] train: loss: 0.2377253
[Epoch 9; Iter   148/  229] train: loss: 0.2967907
[Epoch 9; Iter   178/  229] train: loss: 0.1571125
[Epoch 9; Iter   208/  229] train: loss: 0.2528078
[Epoch 9] ogbg-moltoxcast: 0.648118 val loss: 0.271527
[Epoch 9] ogbg-moltoxcast: 0.619992 test loss: 0.320573
[Epoch 10; Iter     9/  229] train: loss: 0.2260575
[Epoch 10; Iter    39/  229] train: loss: 0.1903230
[Epoch 10; Iter    69/  229] train: loss: 0.1478693
[Epoch 10; Iter    99/  229] train: loss: 0.1130279
[Epoch 10; Iter   129/  229] train: loss: 0.1877774
[Epoch 10; Iter   159/  229] train: loss: 0.2269868
[Epoch 10; Iter   189/  229] train: loss: 0.2003795
[Epoch 10; Iter   219/  229] train: loss: 0.2274373
[Epoch 10] ogbg-moltoxcast: 0.653091 val loss: 0.269297
[Epoch 10] ogbg-moltoxcast: 0.634812 test loss: 0.306033
[Epoch 11; Iter    20/  229] train: loss: 0.1591867
[Epoch 11; Iter    50/  229] train: loss: 0.1860714
[Epoch 11; Iter    80/  229] train: loss: 0.1544662
[Epoch 11; Iter   110/  229] train: loss: 0.1279954
[Epoch 11; Iter   140/  229] train: loss: 0.2251135
[Epoch 11; Iter   170/  229] train: loss: 0.3117207
[Epoch 11; Iter   200/  229] train: loss: 0.1440881
[Epoch 11] ogbg-moltoxcast: 0.652939 val loss: 0.270048
[Epoch 11] ogbg-moltoxcast: 0.626125 test loss: 0.425926
[Epoch 12; Iter     1/  229] train: loss: 0.2406594
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.05/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.05_5_26-05_10-54-49
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.05
logdir: runs/static_noise/GraphCL/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931528
[Epoch 1; Iter    60/  229] train: loss: 0.6931798
[Epoch 1; Iter    90/  229] train: loss: 0.6931682
[Epoch 1; Iter   120/  229] train: loss: 0.6931483
[Epoch 1; Iter   150/  229] train: loss: 0.6931154
[Epoch 1; Iter   180/  229] train: loss: 0.6930771
[Epoch 1; Iter   210/  229] train: loss: 0.6930802
[Epoch 1] ogbg-moltoxcast: 0.506223 val loss: 0.693006
[Epoch 1] ogbg-moltoxcast: 0.497791 test loss: 0.692978
[Epoch 2; Iter    11/  229] train: loss: 0.6931076
[Epoch 2; Iter    41/  229] train: loss: 0.6930464
[Epoch 2; Iter    71/  229] train: loss: 0.6930318
[Epoch 2; Iter   101/  229] train: loss: 0.6930906
[Epoch 2; Iter   131/  229] train: loss: 0.6930633
[Epoch 2; Iter   161/  229] train: loss: 0.6930289
[Epoch 2; Iter   191/  229] train: loss: 0.6929963
[Epoch 2; Iter   221/  229] train: loss: 0.6929658
[Epoch 2] ogbg-moltoxcast: 0.507240 val loss: 0.692857
[Epoch 2] ogbg-moltoxcast: 0.498697 test loss: 0.692839
[Epoch 3; Iter    22/  229] train: loss: 0.6929030
[Epoch 3; Iter    52/  229] train: loss: 0.6928954
[Epoch 3; Iter    82/  229] train: loss: 0.6929176
[Epoch 3; Iter   112/  229] train: loss: 0.6928703
[Epoch 3; Iter   142/  229] train: loss: 0.6928284
[Epoch 3; Iter   172/  229] train: loss: 0.6928151
[Epoch 3; Iter   202/  229] train: loss: 0.6928111
[Epoch 3] ogbg-moltoxcast: 0.506132 val loss: 0.692633
[Epoch 3] ogbg-moltoxcast: 0.497618 test loss: 0.692641
[Epoch 4; Iter     3/  229] train: loss: 0.6928571
[Epoch 4; Iter    33/  229] train: loss: 0.6895991
[Epoch 4; Iter    63/  229] train: loss: 0.6723408
[Epoch 4; Iter    93/  229] train: loss: 0.6264094
[Epoch 4; Iter   123/  229] train: loss: 0.5908791
[Epoch 4; Iter   153/  229] train: loss: 0.5486678
[Epoch 4; Iter   183/  229] train: loss: 0.4781502
[Epoch 4; Iter   213/  229] train: loss: 0.4314099
[Epoch 4] ogbg-moltoxcast: 0.583239 val loss: 0.477521
[Epoch 4] ogbg-moltoxcast: 0.527874 test loss: 0.504435
[Epoch 5; Iter    14/  229] train: loss: 0.3949135
[Epoch 5; Iter    44/  229] train: loss: 0.3080100
[Epoch 5; Iter    74/  229] train: loss: 0.3489909
[Epoch 5; Iter   104/  229] train: loss: 0.2766741
[Epoch 5; Iter   134/  229] train: loss: 0.2553356
[Epoch 5; Iter   164/  229] train: loss: 0.2071496
[Epoch 5; Iter   194/  229] train: loss: 0.2257300
[Epoch 5; Iter   224/  229] train: loss: 0.1572303
[Epoch 5] ogbg-moltoxcast: 0.629315 val loss: 0.287831
[Epoch 5] ogbg-moltoxcast: 0.585329 test loss: 0.325260
[Epoch 6; Iter    25/  229] train: loss: 0.2938472
[Epoch 6; Iter    55/  229] train: loss: 0.2075283
[Epoch 6; Iter    85/  229] train: loss: 0.1786916
[Epoch 6; Iter   115/  229] train: loss: 0.1957175
[Epoch 6; Iter   145/  229] train: loss: 0.2690171
[Epoch 6; Iter   175/  229] train: loss: 0.2206395
[Epoch 6; Iter   205/  229] train: loss: 0.1924284
[Epoch 6] ogbg-moltoxcast: 0.640791 val loss: 0.267673
[Epoch 6] ogbg-moltoxcast: 0.605732 test loss: 0.304741
[Epoch 7; Iter     6/  229] train: loss: 0.1726429
[Epoch 7; Iter    36/  229] train: loss: 0.1460033
[Epoch 7; Iter    66/  229] train: loss: 0.2564750
[Epoch 7; Iter    96/  229] train: loss: 0.2373550
[Epoch 7; Iter   126/  229] train: loss: 0.2694502
[Epoch 7; Iter   156/  229] train: loss: 0.1534193
[Epoch 7; Iter   186/  229] train: loss: 0.3461771
[Epoch 7; Iter   216/  229] train: loss: 0.1833906
[Epoch 7] ogbg-moltoxcast: 0.640689 val loss: 0.279332
[Epoch 7] ogbg-moltoxcast: 0.615442 test loss: 0.317176
[Epoch 8; Iter    17/  229] train: loss: 0.2490788
[Epoch 8; Iter    47/  229] train: loss: 0.1663864
[Epoch 8; Iter    77/  229] train: loss: 0.1804118
[Epoch 8; Iter   107/  229] train: loss: 0.2104909
[Epoch 8; Iter   137/  229] train: loss: 0.2547866
[Epoch 8; Iter   167/  229] train: loss: 0.1577948
[Epoch 8; Iter   197/  229] train: loss: 0.2133914
[Epoch 8; Iter   227/  229] train: loss: 0.1523045
[Epoch 8] ogbg-moltoxcast: 0.667632 val loss: 0.264493
[Epoch 8] ogbg-moltoxcast: 0.616392 test loss: 0.304589
[Epoch 9; Iter    28/  229] train: loss: 0.1668372
[Epoch 9; Iter    58/  229] train: loss: 0.1927734
[Epoch 9; Iter    88/  229] train: loss: 0.2077923
[Epoch 9; Iter   118/  229] train: loss: 0.1616864
[Epoch 9; Iter   148/  229] train: loss: 0.2270812
[Epoch 9; Iter   178/  229] train: loss: 0.1909828
[Epoch 9; Iter   208/  229] train: loss: 0.1938243
[Epoch 9] ogbg-moltoxcast: 0.638255 val loss: 0.276704
[Epoch 9] ogbg-moltoxcast: 0.620066 test loss: 0.317377
[Epoch 10; Iter     9/  229] train: loss: 0.1513369
[Epoch 10; Iter    39/  229] train: loss: 0.1090771
[Epoch 10; Iter    69/  229] train: loss: 0.2486565
[Epoch 10; Iter    99/  229] train: loss: 0.1563384
[Epoch 10; Iter   129/  229] train: loss: 0.1642829
[Epoch 10; Iter   159/  229] train: loss: 0.1714918
[Epoch 10; Iter   189/  229] train: loss: 0.2771462
[Epoch 10; Iter   219/  229] train: loss: 0.1680309
[Epoch 10] ogbg-moltoxcast: 0.663747 val loss: 0.263619
[Epoch 10] ogbg-moltoxcast: 0.631314 test loss: 0.303163
[Epoch 11; Iter    20/  229] train: loss: 0.1809619
[Epoch 11; Iter    50/  229] train: loss: 0.1691815
[Epoch 11; Iter    80/  229] train: loss: 0.1860920
[Epoch 11; Iter   110/  229] train: loss: 0.1935724
[Epoch 11; Iter   140/  229] train: loss: 0.2245345
[Epoch 11; Iter   170/  229] train: loss: 0.1413406
[Epoch 11; Iter   200/  229] train: loss: 0.2148478
[Epoch 11] ogbg-moltoxcast: 0.666850 val loss: 0.281915
[Epoch 11] ogbg-moltoxcast: 0.631771 test loss: 0.318381
[Epoch 12; Iter     1/  229] train: loss: 0.2224108
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.1/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.1_6_26-05_10-55-15
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.1
logdir: runs/static_noise/GraphCL/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6932175
[Epoch 1; Iter    60/  229] train: loss: 0.6931409
[Epoch 1; Iter    90/  229] train: loss: 0.6931079
[Epoch 1; Iter   120/  229] train: loss: 0.6931275
[Epoch 1; Iter   150/  229] train: loss: 0.6931212
[Epoch 1; Iter   180/  229] train: loss: 0.6930848
[Epoch 1; Iter   210/  229] train: loss: 0.6931656
[Epoch 1] ogbg-moltoxcast: 0.503720 val loss: 0.693008
[Epoch 1] ogbg-moltoxcast: 0.493562 test loss: 0.693131
[Epoch 2; Iter    11/  229] train: loss: 0.6931005
[Epoch 2; Iter    41/  229] train: loss: 0.6931325
[Epoch 2; Iter    71/  229] train: loss: 0.6930896
[Epoch 2; Iter   101/  229] train: loss: 0.6931433
[Epoch 2; Iter   131/  229] train: loss: 0.6931111
[Epoch 2; Iter   161/  229] train: loss: 0.6930810
[Epoch 2; Iter   191/  229] train: loss: 0.6930265
[Epoch 2; Iter   221/  229] train: loss: 0.6930144
[Epoch 2] ogbg-moltoxcast: 0.504076 val loss: 0.692879
[Epoch 2] ogbg-moltoxcast: 0.494106 test loss: 0.693010
[Epoch 3; Iter    22/  229] train: loss: 0.6929972
[Epoch 3; Iter    52/  229] train: loss: 0.6929252
[Epoch 3; Iter    82/  229] train: loss: 0.6929646
[Epoch 3; Iter   112/  229] train: loss: 0.6928921
[Epoch 3; Iter   142/  229] train: loss: 0.6928604
[Epoch 3; Iter   172/  229] train: loss: 0.6928687
[Epoch 3; Iter   202/  229] train: loss: 0.6928525
[Epoch 3] ogbg-moltoxcast: 0.503996 val loss: 0.692707
[Epoch 3] ogbg-moltoxcast: 0.494026 test loss: 0.692848
[Epoch 4; Iter     3/  229] train: loss: 0.6928400
[Epoch 4; Iter    33/  229] train: loss: 0.6890691
[Epoch 4; Iter    63/  229] train: loss: 0.6749265
[Epoch 4; Iter    93/  229] train: loss: 0.6364977
[Epoch 4; Iter   123/  229] train: loss: 0.6318562
[Epoch 4; Iter   153/  229] train: loss: 0.5499386
[Epoch 4; Iter   183/  229] train: loss: 0.5580732
[Epoch 4; Iter   213/  229] train: loss: 0.4376773
[Epoch 4] ogbg-moltoxcast: 0.603405 val loss: 0.502824
[Epoch 4] ogbg-moltoxcast: 0.543442 test loss: 0.530125
[Epoch 5; Iter    14/  229] train: loss: 0.4449705
[Epoch 5; Iter    44/  229] train: loss: 0.3540434
[Epoch 5; Iter    74/  229] train: loss: 0.3143007
[Epoch 5; Iter   104/  229] train: loss: 0.3089530
[Epoch 5; Iter   134/  229] train: loss: 0.2978924
[Epoch 5; Iter   164/  229] train: loss: 0.2414698
[Epoch 5; Iter   194/  229] train: loss: 0.2587096
[Epoch 5; Iter   224/  229] train: loss: 0.3109393
[Epoch 5] ogbg-moltoxcast: 0.627300 val loss: 0.282860
[Epoch 5] ogbg-moltoxcast: 0.587831 test loss: 0.334518
[Epoch 6; Iter    25/  229] train: loss: 0.3151453
[Epoch 6; Iter    55/  229] train: loss: 0.1858343
[Epoch 6; Iter    85/  229] train: loss: 0.2423366
[Epoch 6; Iter   115/  229] train: loss: 0.2474621
[Epoch 6; Iter   145/  229] train: loss: 0.2129167
[Epoch 6; Iter   175/  229] train: loss: 0.1856530
[Epoch 6; Iter   205/  229] train: loss: 0.1434523
[Epoch 6] ogbg-moltoxcast: 0.648613 val loss: 0.277457
[Epoch 6] ogbg-moltoxcast: 0.608812 test loss: 0.314183
[Epoch 7; Iter     6/  229] train: loss: 0.1720212
[Epoch 7; Iter    36/  229] train: loss: 0.1580085
[Epoch 7; Iter    66/  229] train: loss: 0.1925332
[Epoch 7; Iter    96/  229] train: loss: 0.2963265
[Epoch 7; Iter   126/  229] train: loss: 0.2136104
[Epoch 7; Iter   156/  229] train: loss: 0.2419939
[Epoch 7; Iter   186/  229] train: loss: 0.2004552
[Epoch 7; Iter   216/  229] train: loss: 0.2018048
[Epoch 7] ogbg-moltoxcast: 0.627910 val loss: 0.283830
[Epoch 7] ogbg-moltoxcast: 0.594964 test loss: 0.334266
[Epoch 8; Iter    17/  229] train: loss: 0.1646558
[Epoch 8; Iter    47/  229] train: loss: 0.1880665
[Epoch 8; Iter    77/  229] train: loss: 0.1766852
[Epoch 8; Iter   107/  229] train: loss: 0.2299995
[Epoch 8; Iter   137/  229] train: loss: 0.2377591
[Epoch 8; Iter   167/  229] train: loss: 0.2007412
[Epoch 8; Iter   197/  229] train: loss: 0.2370941
[Epoch 8; Iter   227/  229] train: loss: 0.3951272
[Epoch 8] ogbg-moltoxcast: 0.638426 val loss: 0.346932
[Epoch 8] ogbg-moltoxcast: 0.622489 test loss: 0.652706
[Epoch 9; Iter    28/  229] train: loss: 0.1681315
[Epoch 9; Iter    58/  229] train: loss: 0.1411288
[Epoch 9; Iter    88/  229] train: loss: 0.1541151
[Epoch 9; Iter   118/  229] train: loss: 0.2376385
[Epoch 9; Iter   148/  229] train: loss: 0.3110826
[Epoch 9; Iter   178/  229] train: loss: 0.1555569
[Epoch 9; Iter   208/  229] train: loss: 0.2806289
[Epoch 9] ogbg-moltoxcast: 0.644033 val loss: 0.445931
[Epoch 9] ogbg-moltoxcast: 0.612889 test loss: 0.680687
[Epoch 10; Iter     9/  229] train: loss: 0.2282299
[Epoch 10; Iter    39/  229] train: loss: 0.1884359
[Epoch 10; Iter    69/  229] train: loss: 0.1498204
[Epoch 10; Iter    99/  229] train: loss: 0.1187731
[Epoch 10; Iter   129/  229] train: loss: 0.1737321
[Epoch 10; Iter   159/  229] train: loss: 0.2361125
[Epoch 10; Iter   189/  229] train: loss: 0.1904414
[Epoch 10; Iter   219/  229] train: loss: 0.2329682
[Epoch 10] ogbg-moltoxcast: 0.658479 val loss: 0.275080
[Epoch 10] ogbg-moltoxcast: 0.628557 test loss: 0.311153
[Epoch 11; Iter    20/  229] train: loss: 0.1535657
[Epoch 11; Iter    50/  229] train: loss: 0.1974089
[Epoch 11; Iter    80/  229] train: loss: 0.1431077
[Epoch 11; Iter   110/  229] train: loss: 0.1324975
[Epoch 11; Iter   140/  229] train: loss: 0.2251901
[Epoch 11; Iter   170/  229] train: loss: 0.3119356
[Epoch 11; Iter   200/  229] train: loss: 0.1466922
[Epoch 11] ogbg-moltoxcast: 0.657507 val loss: 0.271466
[Epoch 11] ogbg-moltoxcast: 0.625362 test loss: 0.313704
[Epoch 12; Iter     1/  229] train: loss: 0.2272856
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.1/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.1_5_26-05_10-55-17
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.1
logdir: runs/static_noise/GraphCL/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931466
[Epoch 1; Iter    60/  229] train: loss: 0.6931887
[Epoch 1; Iter    90/  229] train: loss: 0.6931520
[Epoch 1; Iter   120/  229] train: loss: 0.6931403
[Epoch 1; Iter   150/  229] train: loss: 0.6931409
[Epoch 1; Iter   180/  229] train: loss: 0.6930953
[Epoch 1; Iter   210/  229] train: loss: 0.6930861
[Epoch 1] ogbg-moltoxcast: 0.507925 val loss: 0.693025
[Epoch 1] ogbg-moltoxcast: 0.496006 test loss: 0.692991
[Epoch 2; Iter    11/  229] train: loss: 0.6931057
[Epoch 2; Iter    41/  229] train: loss: 0.6930367
[Epoch 2; Iter    71/  229] train: loss: 0.6930439
[Epoch 2; Iter   101/  229] train: loss: 0.6931002
[Epoch 2; Iter   131/  229] train: loss: 0.6930516
[Epoch 2; Iter   161/  229] train: loss: 0.6930236
[Epoch 2; Iter   191/  229] train: loss: 0.6930204
[Epoch 2; Iter   221/  229] train: loss: 0.6929330
[Epoch 2] ogbg-moltoxcast: 0.508333 val loss: 0.692868
[Epoch 2] ogbg-moltoxcast: 0.496736 test loss: 0.692848
[Epoch 3; Iter    22/  229] train: loss: 0.6929476
[Epoch 3; Iter    52/  229] train: loss: 0.6928896
[Epoch 3; Iter    82/  229] train: loss: 0.6929139
[Epoch 3; Iter   112/  229] train: loss: 0.6928782
[Epoch 3; Iter   142/  229] train: loss: 0.6928338
[Epoch 3; Iter   172/  229] train: loss: 0.6928151
[Epoch 3; Iter   202/  229] train: loss: 0.6927952
[Epoch 3] ogbg-moltoxcast: 0.509666 val loss: 0.692637
[Epoch 3] ogbg-moltoxcast: 0.495850 test loss: 0.692643
[Epoch 4; Iter     3/  229] train: loss: 0.6928800
[Epoch 4; Iter    33/  229] train: loss: 0.6894870
[Epoch 4; Iter    63/  229] train: loss: 0.6730179
[Epoch 4; Iter    93/  229] train: loss: 0.6220977
[Epoch 4; Iter   123/  229] train: loss: 0.5952462
[Epoch 4; Iter   153/  229] train: loss: 0.5560414
[Epoch 4; Iter   183/  229] train: loss: 0.4885386
[Epoch 4; Iter   213/  229] train: loss: 0.4269277
[Epoch 4] ogbg-moltoxcast: 0.566416 val loss: 0.455570
[Epoch 4] ogbg-moltoxcast: 0.533168 test loss: 0.506101
[Epoch 5; Iter    14/  229] train: loss: 0.3920759
[Epoch 5; Iter    44/  229] train: loss: 0.3089485
[Epoch 5; Iter    74/  229] train: loss: 0.3468950
[Epoch 5; Iter   104/  229] train: loss: 0.2764643
[Epoch 5; Iter   134/  229] train: loss: 0.2527817
[Epoch 5; Iter   164/  229] train: loss: 0.2050942
[Epoch 5; Iter   194/  229] train: loss: 0.2247844
[Epoch 5; Iter   224/  229] train: loss: 0.1570746
[Epoch 5] ogbg-moltoxcast: 0.629499 val loss: 0.321638
[Epoch 5] ogbg-moltoxcast: 0.588533 test loss: 0.356014
[Epoch 6; Iter    25/  229] train: loss: 0.3000183
[Epoch 6; Iter    55/  229] train: loss: 0.2044755
[Epoch 6; Iter    85/  229] train: loss: 0.1791200
[Epoch 6; Iter   115/  229] train: loss: 0.1950089
[Epoch 6; Iter   145/  229] train: loss: 0.2690378
[Epoch 6; Iter   175/  229] train: loss: 0.2195639
[Epoch 6; Iter   205/  229] train: loss: 0.1910005
[Epoch 6] ogbg-moltoxcast: 0.641381 val loss: 0.280192
[Epoch 6] ogbg-moltoxcast: 0.610904 test loss: 0.316471
[Epoch 7; Iter     6/  229] train: loss: 0.1728422
[Epoch 7; Iter    36/  229] train: loss: 0.1484226
[Epoch 7; Iter    66/  229] train: loss: 0.2483237
[Epoch 7; Iter    96/  229] train: loss: 0.2412151
[Epoch 7; Iter   126/  229] train: loss: 0.2688840
[Epoch 7; Iter   156/  229] train: loss: 0.1608746
[Epoch 7; Iter   186/  229] train: loss: 0.3378688
[Epoch 7; Iter   216/  229] train: loss: 0.1934801
[Epoch 7] ogbg-moltoxcast: 0.608884 val loss: 0.297612
[Epoch 7] ogbg-moltoxcast: 0.586869 test loss: 0.354282
[Epoch 8; Iter    17/  229] train: loss: 0.2414443
[Epoch 8; Iter    47/  229] train: loss: 0.1642729
[Epoch 8; Iter    77/  229] train: loss: 0.1890741
[Epoch 8; Iter   107/  229] train: loss: 0.2109475
[Epoch 8; Iter   137/  229] train: loss: 0.2500636
[Epoch 8; Iter   167/  229] train: loss: 0.1548387
[Epoch 8; Iter   197/  229] train: loss: 0.2216168
[Epoch 8; Iter   227/  229] train: loss: 0.1533173
[Epoch 8] ogbg-moltoxcast: 0.650232 val loss: 0.287894
[Epoch 8] ogbg-moltoxcast: 0.615494 test loss: 0.502492
[Epoch 9; Iter    28/  229] train: loss: 0.1680247
[Epoch 9; Iter    58/  229] train: loss: 0.1838110
[Epoch 9; Iter    88/  229] train: loss: 0.2088234
[Epoch 9; Iter   118/  229] train: loss: 0.1690935
[Epoch 9; Iter   148/  229] train: loss: 0.2305094
[Epoch 9; Iter   178/  229] train: loss: 0.1959931
[Epoch 9; Iter   208/  229] train: loss: 0.1970859
[Epoch 9] ogbg-moltoxcast: 0.643744 val loss: 0.312379
[Epoch 9] ogbg-moltoxcast: 0.612638 test loss: 0.372604
[Epoch 10; Iter     9/  229] train: loss: 0.1612277
[Epoch 10; Iter    39/  229] train: loss: 0.1110429
[Epoch 10; Iter    69/  229] train: loss: 0.2527184
[Epoch 10; Iter    99/  229] train: loss: 0.1563262
[Epoch 10; Iter   129/  229] train: loss: 0.1748850
[Epoch 10; Iter   159/  229] train: loss: 0.1707686
[Epoch 10; Iter   189/  229] train: loss: 0.2777906
[Epoch 10; Iter   219/  229] train: loss: 0.1684535
[Epoch 10] ogbg-moltoxcast: 0.634278 val loss: 0.266792
[Epoch 10] ogbg-moltoxcast: 0.614077 test loss: 0.312844
[Epoch 11; Iter    20/  229] train: loss: 0.1807583
[Epoch 11; Iter    50/  229] train: loss: 0.1698196
[Epoch 11; Iter    80/  229] train: loss: 0.1924872
[Epoch 11; Iter   110/  229] train: loss: 0.1922683
[Epoch 11; Iter   140/  229] train: loss: 0.2605903
[Epoch 11; Iter   170/  229] train: loss: 0.1496366
[Epoch 11; Iter   200/  229] train: loss: 0.2361631
[Epoch 11] ogbg-moltoxcast: 0.650208 val loss: 0.336086
[Epoch 11] ogbg-moltoxcast: 0.625724 test loss: 0.544218
[Epoch 12; Iter     1/  229] train: loss: 0.2241496
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.1/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.1_4_26-05_10-55-14
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.1
logdir: runs/static_noise/GraphCL/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931394
[Epoch 1; Iter    60/  229] train: loss: 0.6931590
[Epoch 1; Iter    90/  229] train: loss: 0.6931505
[Epoch 1; Iter   120/  229] train: loss: 0.6931607
[Epoch 1; Iter   150/  229] train: loss: 0.6931006
[Epoch 1; Iter   180/  229] train: loss: 0.6931528
[Epoch 1; Iter   210/  229] train: loss: 0.6931008
[Epoch 1] ogbg-moltoxcast: 0.491135 val loss: 0.692956
[Epoch 1] ogbg-moltoxcast: 0.491570 test loss: 0.692962
[Epoch 2; Iter    11/  229] train: loss: 0.6931561
[Epoch 2; Iter    41/  229] train: loss: 0.6930581
[Epoch 2; Iter    71/  229] train: loss: 0.6930631
[Epoch 2; Iter   101/  229] train: loss: 0.6931179
[Epoch 2; Iter   131/  229] train: loss: 0.6931279
[Epoch 2; Iter   161/  229] train: loss: 0.6930783
[Epoch 2; Iter   191/  229] train: loss: 0.6929985
[Epoch 2; Iter   221/  229] train: loss: 0.6930092
[Epoch 2] ogbg-moltoxcast: 0.491365 val loss: 0.692845
[Epoch 2] ogbg-moltoxcast: 0.492602 test loss: 0.692866
[Epoch 3; Iter    22/  229] train: loss: 0.6929647
[Epoch 3; Iter    52/  229] train: loss: 0.6929750
[Epoch 3; Iter    82/  229] train: loss: 0.6929786
[Epoch 3; Iter   112/  229] train: loss: 0.6929396
[Epoch 3; Iter   142/  229] train: loss: 0.6928983
[Epoch 3; Iter   172/  229] train: loss: 0.6928872
[Epoch 3; Iter   202/  229] train: loss: 0.6928682
[Epoch 3] ogbg-moltoxcast: 0.491733 val loss: 0.692699
[Epoch 3] ogbg-moltoxcast: 0.493008 test loss: 0.692737
[Epoch 4; Iter     3/  229] train: loss: 0.6929393
[Epoch 4; Iter    33/  229] train: loss: 0.6900975
[Epoch 4; Iter    63/  229] train: loss: 0.6751608
[Epoch 4; Iter    93/  229] train: loss: 0.6519307
[Epoch 4; Iter   123/  229] train: loss: 0.6099454
[Epoch 4; Iter   153/  229] train: loss: 0.5766260
[Epoch 4; Iter   183/  229] train: loss: 0.5121145
[Epoch 4; Iter   213/  229] train: loss: 0.4472502
[Epoch 4] ogbg-moltoxcast: 0.615771 val loss: 0.495571
[Epoch 4] ogbg-moltoxcast: 0.581739 test loss: 0.519759
[Epoch 5; Iter    14/  229] train: loss: 0.4426306
[Epoch 5; Iter    44/  229] train: loss: 0.3528227
[Epoch 5; Iter    74/  229] train: loss: 0.2852874
[Epoch 5; Iter   104/  229] train: loss: 0.3263888
[Epoch 5; Iter   134/  229] train: loss: 0.3184926
[Epoch 5; Iter   164/  229] train: loss: 0.2503984
[Epoch 5; Iter   194/  229] train: loss: 0.2557224
[Epoch 5; Iter   224/  229] train: loss: 0.1654950
[Epoch 5] ogbg-moltoxcast: 0.642916 val loss: 0.287956
[Epoch 5] ogbg-moltoxcast: 0.588509 test loss: 0.319440
[Epoch 6; Iter    25/  229] train: loss: 0.2822081
[Epoch 6; Iter    55/  229] train: loss: 0.2088693
[Epoch 6; Iter    85/  229] train: loss: 0.2955211
[Epoch 6; Iter   115/  229] train: loss: 0.2139177
[Epoch 6; Iter   145/  229] train: loss: 0.2031895
[Epoch 6; Iter   175/  229] train: loss: 0.1888053
[Epoch 6; Iter   205/  229] train: loss: 0.1863016
[Epoch 6] ogbg-moltoxcast: 0.621650 val loss: 0.296627
[Epoch 6] ogbg-moltoxcast: 0.591280 test loss: 0.335780
[Epoch 7; Iter     6/  229] train: loss: 0.1209335
[Epoch 7; Iter    36/  229] train: loss: 0.2336157
[Epoch 7; Iter    66/  229] train: loss: 0.2235408
[Epoch 7; Iter    96/  229] train: loss: 0.1715710
[Epoch 7; Iter   126/  229] train: loss: 0.2857192
[Epoch 7; Iter   156/  229] train: loss: 0.1901688
[Epoch 7; Iter   186/  229] train: loss: 0.3305946
[Epoch 7; Iter   216/  229] train: loss: 0.2090921
[Epoch 7] ogbg-moltoxcast: 0.614967 val loss: 0.296763
[Epoch 7] ogbg-moltoxcast: 0.563381 test loss: 0.330582
[Epoch 8; Iter    17/  229] train: loss: 0.1456383
[Epoch 8; Iter    47/  229] train: loss: 0.3351615
[Epoch 8; Iter    77/  229] train: loss: 0.1854607
[Epoch 8; Iter   107/  229] train: loss: 0.2453556
[Epoch 8; Iter   137/  229] train: loss: 0.1906256
[Epoch 8; Iter   167/  229] train: loss: 0.1615459
[Epoch 8; Iter   197/  229] train: loss: 0.2313801
[Epoch 8; Iter   227/  229] train: loss: 0.2289158
[Epoch 8] ogbg-moltoxcast: 0.646269 val loss: 0.269823
[Epoch 8] ogbg-moltoxcast: 0.619682 test loss: 0.313139
[Epoch 9; Iter    28/  229] train: loss: 0.1362895
[Epoch 9; Iter    58/  229] train: loss: 0.1319672
[Epoch 9; Iter    88/  229] train: loss: 0.2079059
[Epoch 9; Iter   118/  229] train: loss: 0.1201260
[Epoch 9; Iter   148/  229] train: loss: 0.2290770
[Epoch 9; Iter   178/  229] train: loss: 0.2195302
[Epoch 9; Iter   208/  229] train: loss: 0.1900000
[Epoch 9] ogbg-moltoxcast: 0.654707 val loss: 0.288037
[Epoch 9] ogbg-moltoxcast: 0.609438 test loss: 0.336370
[Epoch 10; Iter     9/  229] train: loss: 0.1541202
[Epoch 10; Iter    39/  229] train: loss: 0.1521661
[Epoch 10; Iter    69/  229] train: loss: 0.2248130
[Epoch 10; Iter    99/  229] train: loss: 0.2763295
[Epoch 10; Iter   129/  229] train: loss: 0.1763676
[Epoch 10; Iter   159/  229] train: loss: 0.2177847
[Epoch 10; Iter   189/  229] train: loss: 0.2667118
[Epoch 10; Iter   219/  229] train: loss: 0.2752332
[Epoch 10] ogbg-moltoxcast: 0.664611 val loss: 0.269262
[Epoch 10] ogbg-moltoxcast: 0.629471 test loss: 0.300700
[Epoch 11; Iter    20/  229] train: loss: 0.1720793
[Epoch 11; Iter    50/  229] train: loss: 0.2049038
[Epoch 11; Iter    80/  229] train: loss: 0.1724095
[Epoch 11; Iter   110/  229] train: loss: 0.1883613
[Epoch 11; Iter   140/  229] train: loss: 0.2842122
[Epoch 11; Iter   170/  229] train: loss: 0.2126968
[Epoch 11; Iter   200/  229] train: loss: 0.3066996
[Epoch 11] ogbg-moltoxcast: 0.660730 val loss: 0.265990
[Epoch 11] ogbg-moltoxcast: 0.606753 test loss: 0.308383
[Epoch 12; Iter     1/  229] train: loss: 0.1775613
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.2/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.2_5_26-05_10-55-53
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.2
logdir: runs/static_noise/GraphCL/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931865
[Epoch 1; Iter    60/  229] train: loss: 0.6931681
[Epoch 1; Iter    90/  229] train: loss: 0.6931552
[Epoch 1; Iter   120/  229] train: loss: 0.6931854
[Epoch 1; Iter   150/  229] train: loss: 0.6931331
[Epoch 1; Iter   180/  229] train: loss: 0.6931030
[Epoch 1; Iter   210/  229] train: loss: 0.6931093
[Epoch 1] ogbg-moltoxcast: 0.510696 val loss: 0.692979
[Epoch 1] ogbg-moltoxcast: 0.497699 test loss: 0.692932
[Epoch 2; Iter    11/  229] train: loss: 0.6930919
[Epoch 2; Iter    41/  229] train: loss: 0.6930540
[Epoch 2; Iter    71/  229] train: loss: 0.6930522
[Epoch 2; Iter   101/  229] train: loss: 0.6930888
[Epoch 2; Iter   131/  229] train: loss: 0.6930775
[Epoch 2; Iter   161/  229] train: loss: 0.6930262
[Epoch 2; Iter   191/  229] train: loss: 0.6929789
[Epoch 2; Iter   221/  229] train: loss: 0.6929918
[Epoch 2] ogbg-moltoxcast: 0.511428 val loss: 0.692833
[Epoch 2] ogbg-moltoxcast: 0.497526 test loss: 0.692793
[Epoch 3; Iter    22/  229] train: loss: 0.6929902
[Epoch 3; Iter    52/  229] train: loss: 0.6928775
[Epoch 3; Iter    82/  229] train: loss: 0.6928877
[Epoch 3; Iter   112/  229] train: loss: 0.6928456
[Epoch 3; Iter   142/  229] train: loss: 0.6928269
[Epoch 3; Iter   172/  229] train: loss: 0.6928092
[Epoch 3; Iter   202/  229] train: loss: 0.6928139
[Epoch 3] ogbg-moltoxcast: 0.511996 val loss: 0.692594
[Epoch 3] ogbg-moltoxcast: 0.496059 test loss: 0.692575
[Epoch 4; Iter     3/  229] train: loss: 0.6928487
[Epoch 4; Iter    33/  229] train: loss: 0.6893687
[Epoch 4; Iter    63/  229] train: loss: 0.6726299
[Epoch 4; Iter    93/  229] train: loss: 0.6257639
[Epoch 4; Iter   123/  229] train: loss: 0.5902299
[Epoch 4; Iter   153/  229] train: loss: 0.5498092
[Epoch 4; Iter   183/  229] train: loss: 0.5071059
[Epoch 4; Iter   213/  229] train: loss: 0.4410224
[Epoch 4] ogbg-moltoxcast: 0.595661 val loss: 0.571280
[Epoch 4] ogbg-moltoxcast: 0.544613 test loss: 0.597117
[Epoch 5; Iter    14/  229] train: loss: 0.4039438
[Epoch 5; Iter    44/  229] train: loss: 0.3055682
[Epoch 5; Iter    74/  229] train: loss: 0.3435377
[Epoch 5; Iter   104/  229] train: loss: 0.2791244
[Epoch 5; Iter   134/  229] train: loss: 0.2564117
[Epoch 5; Iter   164/  229] train: loss: 0.2038355
[Epoch 5; Iter   194/  229] train: loss: 0.2279191
[Epoch 5; Iter   224/  229] train: loss: 0.1584066
[Epoch 5] ogbg-moltoxcast: 0.625598 val loss: 0.352321
[Epoch 5] ogbg-moltoxcast: 0.579627 test loss: 0.427583
[Epoch 6; Iter    25/  229] train: loss: 0.3117149
[Epoch 6; Iter    55/  229] train: loss: 0.2034476
[Epoch 6; Iter    85/  229] train: loss: 0.1774072
[Epoch 6; Iter   115/  229] train: loss: 0.1976628
[Epoch 6; Iter   145/  229] train: loss: 0.2726146
[Epoch 6; Iter   175/  229] train: loss: 0.2205668
[Epoch 6; Iter   205/  229] train: loss: 0.1990897
[Epoch 6] ogbg-moltoxcast: 0.610918 val loss: 4.626315
[Epoch 6] ogbg-moltoxcast: 0.590398 test loss: 5.356930
[Epoch 7; Iter     6/  229] train: loss: 0.1702332
[Epoch 7; Iter    36/  229] train: loss: 0.1474702
[Epoch 7; Iter    66/  229] train: loss: 0.2717310
[Epoch 7; Iter    96/  229] train: loss: 0.2425429
[Epoch 7; Iter   126/  229] train: loss: 0.2769537
[Epoch 7; Iter   156/  229] train: loss: 0.1632268
[Epoch 7; Iter   186/  229] train: loss: 0.3528536
[Epoch 7; Iter   216/  229] train: loss: 0.1869105
[Epoch 7] ogbg-moltoxcast: 0.624765 val loss: 0.611422
[Epoch 7] ogbg-moltoxcast: 0.584094 test loss: 0.957014
[Epoch 8; Iter    17/  229] train: loss: 0.2474102
[Epoch 8; Iter    47/  229] train: loss: 0.1698135
[Epoch 8; Iter    77/  229] train: loss: 0.1822600
[Epoch 8; Iter   107/  229] train: loss: 0.2159485
[Epoch 8; Iter   137/  229] train: loss: 0.2545082
[Epoch 8; Iter   167/  229] train: loss: 0.1633217
[Epoch 8; Iter   197/  229] train: loss: 0.2045563
[Epoch 8; Iter   227/  229] train: loss: 0.1533322
[Epoch 8] ogbg-moltoxcast: 0.637535 val loss: 0.307209
[Epoch 8] ogbg-moltoxcast: 0.607640 test loss: 0.425794
[Epoch 9; Iter    28/  229] train: loss: 0.1746325
[Epoch 9; Iter    58/  229] train: loss: 0.1836272
[Epoch 9; Iter    88/  229] train: loss: 0.2133111
[Epoch 9; Iter   118/  229] train: loss: 0.1668715
[Epoch 9; Iter   148/  229] train: loss: 0.2176981
[Epoch 9; Iter   178/  229] train: loss: 0.2022368
[Epoch 9; Iter   208/  229] train: loss: 0.1990204
[Epoch 9] ogbg-moltoxcast: 0.643642 val loss: 0.327054
[Epoch 9] ogbg-moltoxcast: 0.618785 test loss: 0.367564
[Epoch 10; Iter     9/  229] train: loss: 0.1583323
[Epoch 10; Iter    39/  229] train: loss: 0.1122044
[Epoch 10; Iter    69/  229] train: loss: 0.2454174
[Epoch 10; Iter    99/  229] train: loss: 0.1528340
[Epoch 10; Iter   129/  229] train: loss: 0.1842039
[Epoch 10; Iter   159/  229] train: loss: 0.1732178
[Epoch 10; Iter   189/  229] train: loss: 0.2747866
[Epoch 10; Iter   219/  229] train: loss: 0.1731287
[Epoch 10] ogbg-moltoxcast: 0.637832 val loss: 0.271168
[Epoch 10] ogbg-moltoxcast: 0.621901 test loss: 0.311532
[Epoch 11; Iter    20/  229] train: loss: 0.1713206
[Epoch 11; Iter    50/  229] train: loss: 0.1687330
[Epoch 11; Iter    80/  229] train: loss: 0.1633212
[Epoch 11; Iter   110/  229] train: loss: 0.1866363
[Epoch 11; Iter   140/  229] train: loss: 0.2422782
[Epoch 11; Iter   170/  229] train: loss: 0.1377263
[Epoch 11; Iter   200/  229] train: loss: 0.2288979
[Epoch 11] ogbg-moltoxcast: 0.647579 val loss: 0.298268
[Epoch 11] ogbg-moltoxcast: 0.620606 test loss: 0.342108
[Epoch 12; Iter     1/  229] train: loss: 0.2159530
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.2/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.2_4_26-05_10-55-37
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.2
logdir: runs/static_noise/GraphCL/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931604
[Epoch 1; Iter    60/  229] train: loss: 0.6931601
[Epoch 1; Iter    90/  229] train: loss: 0.6931229
[Epoch 1; Iter   120/  229] train: loss: 0.6931740
[Epoch 1; Iter   150/  229] train: loss: 0.6930962
[Epoch 1; Iter   180/  229] train: loss: 0.6931641
[Epoch 1; Iter   210/  229] train: loss: 0.6931357
[Epoch 1] ogbg-moltoxcast: 0.496757 val loss: 0.692918
[Epoch 1] ogbg-moltoxcast: 0.494271 test loss: 0.692942
[Epoch 2; Iter    11/  229] train: loss: 0.6931612
[Epoch 2; Iter    41/  229] train: loss: 0.6930997
[Epoch 2; Iter    71/  229] train: loss: 0.6930587
[Epoch 2; Iter   101/  229] train: loss: 0.6931304
[Epoch 2; Iter   131/  229] train: loss: 0.6930632
[Epoch 2; Iter   161/  229] train: loss: 0.6930588
[Epoch 2; Iter   191/  229] train: loss: 0.6930345
[Epoch 2; Iter   221/  229] train: loss: 0.6929643
[Epoch 2] ogbg-moltoxcast: 0.495899 val loss: 0.692822
[Epoch 2] ogbg-moltoxcast: 0.493642 test loss: 0.692861
[Epoch 3; Iter    22/  229] train: loss: 0.6929970
[Epoch 3; Iter    52/  229] train: loss: 0.6929901
[Epoch 3; Iter    82/  229] train: loss: 0.6929916
[Epoch 3; Iter   112/  229] train: loss: 0.6929534
[Epoch 3; Iter   142/  229] train: loss: 0.6928720
[Epoch 3; Iter   172/  229] train: loss: 0.6928678
[Epoch 3; Iter   202/  229] train: loss: 0.6929054
[Epoch 3] ogbg-moltoxcast: 0.494829 val loss: 0.692652
[Epoch 3] ogbg-moltoxcast: 0.494564 test loss: 0.692706
[Epoch 4; Iter     3/  229] train: loss: 0.6929314
[Epoch 4; Iter    33/  229] train: loss: 0.6901788
[Epoch 4; Iter    63/  229] train: loss: 0.6749133
[Epoch 4; Iter    93/  229] train: loss: 0.6497295
[Epoch 4; Iter   123/  229] train: loss: 0.6101385
[Epoch 4; Iter   153/  229] train: loss: 0.5777730
[Epoch 4; Iter   183/  229] train: loss: 0.5226654
[Epoch 4; Iter   213/  229] train: loss: 0.4540522
[Epoch 4] ogbg-moltoxcast: 0.586063 val loss: 0.432735
[Epoch 4] ogbg-moltoxcast: 0.532415 test loss: 0.472391
[Epoch 5; Iter    14/  229] train: loss: 0.4330050
[Epoch 5; Iter    44/  229] train: loss: 0.3563440
[Epoch 5; Iter    74/  229] train: loss: 0.2800793
[Epoch 5; Iter   104/  229] train: loss: 0.3290113
[Epoch 5; Iter   134/  229] train: loss: 0.3274082
[Epoch 5; Iter   164/  229] train: loss: 0.2457095
[Epoch 5; Iter   194/  229] train: loss: 0.2586595
[Epoch 5; Iter   224/  229] train: loss: 0.1643418
[Epoch 5] ogbg-moltoxcast: 0.623521 val loss: 0.304508
[Epoch 5] ogbg-moltoxcast: 0.577662 test loss: 0.357520
[Epoch 6; Iter    25/  229] train: loss: 0.2798089
[Epoch 6; Iter    55/  229] train: loss: 0.2165732
[Epoch 6; Iter    85/  229] train: loss: 0.3037899
[Epoch 6; Iter   115/  229] train: loss: 0.2107338
[Epoch 6; Iter   145/  229] train: loss: 0.2022576
[Epoch 6; Iter   175/  229] train: loss: 0.1897307
[Epoch 6; Iter   205/  229] train: loss: 0.1960298
[Epoch 6] ogbg-moltoxcast: 0.604654 val loss: 2.300732
[Epoch 6] ogbg-moltoxcast: 0.568804 test loss: 2.482948
[Epoch 7; Iter     6/  229] train: loss: 0.1208506
[Epoch 7; Iter    36/  229] train: loss: 0.2361179
[Epoch 7; Iter    66/  229] train: loss: 0.2249892
[Epoch 7; Iter    96/  229] train: loss: 0.1795220
[Epoch 7; Iter   126/  229] train: loss: 0.2828878
[Epoch 7; Iter   156/  229] train: loss: 0.1836694
[Epoch 7; Iter   186/  229] train: loss: 0.3341329
[Epoch 7; Iter   216/  229] train: loss: 0.1996980
[Epoch 7] ogbg-moltoxcast: 0.602894 val loss: 0.704456
[Epoch 7] ogbg-moltoxcast: 0.554349 test loss: 0.880544
[Epoch 8; Iter    17/  229] train: loss: 0.1468916
[Epoch 8; Iter    47/  229] train: loss: 0.3414490
[Epoch 8; Iter    77/  229] train: loss: 0.1937409
[Epoch 8; Iter   107/  229] train: loss: 0.2621619
[Epoch 8; Iter   137/  229] train: loss: 0.1964396
[Epoch 8; Iter   167/  229] train: loss: 0.1681433
[Epoch 8; Iter   197/  229] train: loss: 0.2308030
[Epoch 8; Iter   227/  229] train: loss: 0.2281617
[Epoch 8] ogbg-moltoxcast: 0.627636 val loss: 0.270512
[Epoch 8] ogbg-moltoxcast: 0.618965 test loss: 0.303842
[Epoch 9; Iter    28/  229] train: loss: 0.1430102
[Epoch 9; Iter    58/  229] train: loss: 0.1270696
[Epoch 9; Iter    88/  229] train: loss: 0.2124179
[Epoch 9; Iter   118/  229] train: loss: 0.1143144
[Epoch 9; Iter   148/  229] train: loss: 0.2323936
[Epoch 9; Iter   178/  229] train: loss: 0.2176985
[Epoch 9; Iter   208/  229] train: loss: 0.1958230
[Epoch 9] ogbg-moltoxcast: 0.632595 val loss: 0.321747
[Epoch 9] ogbg-moltoxcast: 0.614511 test loss: 0.326471
[Epoch 10; Iter     9/  229] train: loss: 0.1588915
[Epoch 10; Iter    39/  229] train: loss: 0.1506634
[Epoch 10; Iter    69/  229] train: loss: 0.2563793
[Epoch 10; Iter    99/  229] train: loss: 0.2711722
[Epoch 10; Iter   129/  229] train: loss: 0.1766977
[Epoch 10; Iter   159/  229] train: loss: 0.2188338
[Epoch 10; Iter   189/  229] train: loss: 0.2439336
[Epoch 10; Iter   219/  229] train: loss: 0.2702616
[Epoch 10] ogbg-moltoxcast: 0.662093 val loss: 0.272490
[Epoch 10] ogbg-moltoxcast: 0.624891 test loss: 0.304434
[Epoch 11; Iter    20/  229] train: loss: 0.1817878
[Epoch 11; Iter    50/  229] train: loss: 0.2001545
[Epoch 11; Iter    80/  229] train: loss: 0.1665515
[Epoch 11; Iter   110/  229] train: loss: 0.1686816
[Epoch 11; Iter   140/  229] train: loss: 0.2825749
[Epoch 11; Iter   170/  229] train: loss: 0.2235958
[Epoch 11; Iter   200/  229] train: loss: 0.3037666
[Epoch 11] ogbg-moltoxcast: 0.634581 val loss: 0.655844
[Epoch 11] ogbg-moltoxcast: 0.592349 test loss: 0.535760
[Epoch 12; Iter     1/  229] train: loss: 0.1801045
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/toxcast/noise=0.2/PNA_ogbg-moltoxcast_GraphCL_toxcast_static_noise=0.2_6_26-05_10-55-46
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_static_noise=0.2
logdir: runs/static_noise/GraphCL/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931636
[Epoch 1; Iter    60/  229] train: loss: 0.6931466
[Epoch 1; Iter    90/  229] train: loss: 0.6931351
[Epoch 1; Iter   120/  229] train: loss: 0.6931325
[Epoch 1; Iter   150/  229] train: loss: 0.6931622
[Epoch 1; Iter   180/  229] train: loss: 0.6930959
[Epoch 1; Iter   210/  229] train: loss: 0.6931251
[Epoch 1] ogbg-moltoxcast: 0.503334 val loss: 0.692876
[Epoch 1] ogbg-moltoxcast: 0.493615 test loss: 0.693046
[Epoch 2; Iter    11/  229] train: loss: 0.6931149
[Epoch 2; Iter    41/  229] train: loss: 0.6931285
[Epoch 2; Iter    71/  229] train: loss: 0.6930767
[Epoch 2; Iter   101/  229] train: loss: 0.6930976
[Epoch 2; Iter   131/  229] train: loss: 0.6931146
[Epoch 2; Iter   161/  229] train: loss: 0.6930745
[Epoch 2; Iter   191/  229] train: loss: 0.6930202
[Epoch 2; Iter   221/  229] train: loss: 0.6929758
[Epoch 2] ogbg-moltoxcast: 0.504423 val loss: 0.692752
[Epoch 2] ogbg-moltoxcast: 0.492977 test loss: 0.692930
[Epoch 3; Iter    22/  229] train: loss: 0.6930084
[Epoch 3; Iter    52/  229] train: loss: 0.6929056
[Epoch 3; Iter    82/  229] train: loss: 0.6929718
[Epoch 3; Iter   112/  229] train: loss: 0.6929151
[Epoch 3; Iter   142/  229] train: loss: 0.6928698
[Epoch 3; Iter   172/  229] train: loss: 0.6928704
[Epoch 3; Iter   202/  229] train: loss: 0.6928406
[Epoch 3] ogbg-moltoxcast: 0.504620 val loss: 0.692589
[Epoch 3] ogbg-moltoxcast: 0.493062 test loss: 0.692767
[Epoch 4; Iter     3/  229] train: loss: 0.6928594
[Epoch 4; Iter    33/  229] train: loss: 0.6891124
[Epoch 4; Iter    63/  229] train: loss: 0.6739961
[Epoch 4; Iter    93/  229] train: loss: 0.6380155
[Epoch 4; Iter   123/  229] train: loss: 0.6389024
[Epoch 4; Iter   153/  229] train: loss: 0.5518053
[Epoch 4; Iter   183/  229] train: loss: 0.5757207
[Epoch 4; Iter   213/  229] train: loss: 0.4352624
[Epoch 4] ogbg-moltoxcast: 0.621065 val loss: 0.550231
[Epoch 4] ogbg-moltoxcast: 0.561164 test loss: 0.583272
[Epoch 5; Iter    14/  229] train: loss: 0.4464473
[Epoch 5; Iter    44/  229] train: loss: 0.3514154
[Epoch 5; Iter    74/  229] train: loss: 0.3205502
[Epoch 5; Iter   104/  229] train: loss: 0.3156341
[Epoch 5; Iter   134/  229] train: loss: 0.3033045
[Epoch 5; Iter   164/  229] train: loss: 0.2417624
[Epoch 5; Iter   194/  229] train: loss: 0.2588332
[Epoch 5; Iter   224/  229] train: loss: 0.3077399
[Epoch 5] ogbg-moltoxcast: 0.626591 val loss: 0.319693
[Epoch 5] ogbg-moltoxcast: 0.597138 test loss: 0.377468
[Epoch 6; Iter    25/  229] train: loss: 0.3180787
[Epoch 6; Iter    55/  229] train: loss: 0.1839854
[Epoch 6; Iter    85/  229] train: loss: 0.2549980
[Epoch 6; Iter   115/  229] train: loss: 0.2367606
[Epoch 6; Iter   145/  229] train: loss: 0.2048701
[Epoch 6; Iter   175/  229] train: loss: 0.1934120
[Epoch 6; Iter   205/  229] train: loss: 0.1495772
[Epoch 6] ogbg-moltoxcast: 0.626914 val loss: 4.212966
[Epoch 6] ogbg-moltoxcast: 0.591752 test loss: 3.620151
[Epoch 7; Iter     6/  229] train: loss: 0.1718255
[Epoch 7; Iter    36/  229] train: loss: 0.1560256
[Epoch 7; Iter    66/  229] train: loss: 0.2024127
[Epoch 7; Iter    96/  229] train: loss: 0.2787471
[Epoch 7; Iter   126/  229] train: loss: 0.2194840
[Epoch 7; Iter   156/  229] train: loss: 0.2462608
[Epoch 7; Iter   186/  229] train: loss: 0.2015302
[Epoch 7; Iter   216/  229] train: loss: 0.2111299
[Epoch 7] ogbg-moltoxcast: 0.620059 val loss: 1.689282
[Epoch 7] ogbg-moltoxcast: 0.592896 test loss: 1.519112
[Epoch 8; Iter    17/  229] train: loss: 0.1850938
[Epoch 8; Iter    47/  229] train: loss: 0.2025088
[Epoch 8; Iter    77/  229] train: loss: 0.1853651
[Epoch 8; Iter   107/  229] train: loss: 0.2226503
[Epoch 8; Iter   137/  229] train: loss: 0.2495316
[Epoch 8; Iter   167/  229] train: loss: 0.1966738
[Epoch 8; Iter   197/  229] train: loss: 0.2409130
[Epoch 8; Iter   227/  229] train: loss: 0.4085015
[Epoch 8] ogbg-moltoxcast: 0.601588 val loss: 0.852406
[Epoch 8] ogbg-moltoxcast: 0.588642 test loss: 1.369942
[Epoch 9; Iter    28/  229] train: loss: 0.1736322
[Epoch 9; Iter    58/  229] train: loss: 0.1426274
[Epoch 9; Iter    88/  229] train: loss: 0.1545439
[Epoch 9; Iter   118/  229] train: loss: 0.2568462
[Epoch 9; Iter   148/  229] train: loss: 0.3005864
[Epoch 9; Iter   178/  229] train: loss: 0.1780504
[Epoch 9; Iter   208/  229] train: loss: 0.2775282
[Epoch 9] ogbg-moltoxcast: 0.659215 val loss: 0.277764
[Epoch 9] ogbg-moltoxcast: 0.612203 test loss: 0.800192
[Epoch 10; Iter     9/  229] train: loss: 0.2396984
[Epoch 10; Iter    39/  229] train: loss: 0.1966324
[Epoch 10; Iter    69/  229] train: loss: 0.1511335
[Epoch 10; Iter    99/  229] train: loss: 0.1124070
[Epoch 10; Iter   129/  229] train: loss: 0.1933509
[Epoch 10; Iter   159/  229] train: loss: 0.2205100
[Epoch 10; Iter   189/  229] train: loss: 0.1960612
[Epoch 10; Iter   219/  229] train: loss: 0.2270299
[Epoch 10] ogbg-moltoxcast: 0.650796 val loss: 0.304508
[Epoch 10] ogbg-moltoxcast: 0.619041 test loss: 0.326749
[Epoch 11; Iter    20/  229] train: loss: 0.1606078
[Epoch 11; Iter    50/  229] train: loss: 0.1796879
[Epoch 11; Iter    80/  229] train: loss: 0.1479081
[Epoch 11; Iter   110/  229] train: loss: 0.1327891
[Epoch 11; Iter   140/  229] train: loss: 0.2388666
[Epoch 11; Iter   170/  229] train: loss: 0.3066393
[Epoch 11; Iter   200/  229] train: loss: 0.1513157
[Epoch 11] ogbg-moltoxcast: 0.637545 val loss: 0.290976
[Epoch 11] ogbg-moltoxcast: 0.607282 test loss: 0.438248
[Epoch 12; Iter     1/  229] train: loss: 0.2342429
[Epoch 12; Iter    31/  229] train: loss: 0.2114090
[Epoch 12; Iter    61/  229] train: loss: 0.1494958
[Epoch 12; Iter    91/  229] train: loss: 0.2017180
[Epoch 12; Iter   121/  229] train: loss: 0.2088205
[Epoch 12; Iter   151/  229] train: loss: 0.1283706
[Epoch 12; Iter   181/  229] train: loss: 0.2272087
[Epoch 12; Iter   211/  229] train: loss: 0.1965668
[Epoch 12] ogbg-moltoxcast: 0.688030 val loss: 0.263797
[Epoch 12] ogbg-moltoxcast: 0.643456 test loss: 0.307839
[Epoch 13; Iter    12/  229] train: loss: 0.1361329
[Epoch 13; Iter    42/  229] train: loss: 0.1362142
[Epoch 13; Iter    72/  229] train: loss: 0.1721149
[Epoch 13; Iter   102/  229] train: loss: 0.2579642
[Epoch 13; Iter   132/  229] train: loss: 0.2131803
[Epoch 13; Iter   162/  229] train: loss: 0.1493830
[Epoch 13; Iter   192/  229] train: loss: 0.1804532
[Epoch 13; Iter   222/  229] train: loss: 0.2237973
[Epoch 13] ogbg-moltoxcast: 0.663699 val loss: 0.300697
[Epoch 13] ogbg-moltoxcast: 0.625820 test loss: 0.372683
[Epoch 14; Iter    23/  229] train: loss: 0.1997225
[Epoch 14; Iter    53/  229] train: loss: 0.1837370
[Epoch 14; Iter    83/  229] train: loss: 0.2374359
[Epoch 14; Iter   113/  229] train: loss: 0.1793228
[Epoch 14; Iter   143/  229] train: loss: 0.1969932
[Epoch 14; Iter   173/  229] train: loss: 0.1927791
[Epoch 14; Iter   203/  229] train: loss: 0.1879584
[Epoch 14] ogbg-moltoxcast: 0.686669 val loss: 0.264222
[Epoch 14] ogbg-moltoxcast: 0.644815 test loss: 0.301086
[Epoch 15; Iter     4/  229] train: loss: 0.1609388
[Epoch 15; Iter    34/  229] train: loss: 0.1073811
[Epoch 15; Iter    64/  229] train: loss: 0.1632079
[Epoch 15; Iter    94/  229] train: loss: 0.2617493
[Epoch 15; Iter   124/  229] train: loss: 0.1654895
[Epoch 15; Iter   154/  229] train: loss: 0.1661228
[Epoch 15; Iter   184/  229] train: loss: 0.1670873
[Epoch 15; Iter   214/  229] train: loss: 0.2331239
[Epoch 15] ogbg-moltoxcast: 0.672032 val loss: 0.280269
[Epoch 15] ogbg-moltoxcast: 0.640166 test loss: 0.315656
[Epoch 16; Iter    15/  229] train: loss: 0.2501501
[Epoch 16; Iter    45/  229] train: loss: 0.1343705
[Epoch 16; Iter    75/  229] train: loss: 0.1258815
[Epoch 16; Iter   105/  229] train: loss: 0.1569907
[Epoch 16; Iter   135/  229] train: loss: 0.1618845
[Epoch 16; Iter   165/  229] train: loss: 0.1846525
[Epoch 16; Iter   195/  229] train: loss: 0.2035323
[Epoch 16; Iter   225/  229] train: loss: 0.1378636
[Epoch 16] ogbg-moltoxcast: 0.697393 val loss: 0.265131
[Epoch 16] ogbg-moltoxcast: 0.645158 test loss: 0.303577
[Epoch 17; Iter    26/  229] train: loss: 0.1594771
[Epoch 17; Iter    56/  229] train: loss: 0.2066602
[Epoch 17; Iter    86/  229] train: loss: 0.1485815
[Epoch 17; Iter   116/  229] train: loss: 0.1694823
[Epoch 17; Iter   146/  229] train: loss: 0.1668257
[Epoch 17; Iter   176/  229] train: loss: 0.2582683
[Epoch 17; Iter   206/  229] train: loss: 0.2061059
[Epoch 17] ogbg-moltoxcast: 0.665332 val loss: 0.297358
[Epoch 17] ogbg-moltoxcast: 0.647589 test loss: 0.326887
[Epoch 18; Iter     7/  229] train: loss: 0.1292429
[Epoch 18; Iter    37/  229] train: loss: 0.1712944
[Epoch 18; Iter    67/  229] train: loss: 0.1918058
[Epoch 18; Iter    97/  229] train: loss: 0.2954476
[Epoch 18; Iter   127/  229] train: loss: 0.1889572
[Epoch 18; Iter   157/  229] train: loss: 0.1788934
[Epoch 18; Iter   187/  229] train: loss: 0.1104125
[Epoch 18; Iter   217/  229] train: loss: 0.2306127
[Epoch 18] ogbg-moltoxcast: 0.700265 val loss: 0.258995
[Epoch 18] ogbg-moltoxcast: 0.650317 test loss: 0.302635
[Epoch 19; Iter    18/  229] train: loss: 0.2133374
[Epoch 19; Iter    48/  229] train: loss: 0.1739081
[Epoch 19; Iter    78/  229] train: loss: 0.1067216
[Epoch 19; Iter   108/  229] train: loss: 0.1430382
[Epoch 19; Iter   138/  229] train: loss: 0.1118940
[Epoch 19; Iter   168/  229] train: loss: 0.1878492
[Epoch 19; Iter   198/  229] train: loss: 0.1965076
[Epoch 19; Iter   228/  229] train: loss: 0.1413108
[Epoch 19] ogbg-moltoxcast: 0.679808 val loss: 0.268258
[Epoch 19] ogbg-moltoxcast: 0.641692 test loss: 0.305516
[Epoch 20; Iter    29/  229] train: loss: 0.1717933
[Epoch 20; Iter    59/  229] train: loss: 0.2177148
[Epoch 20; Iter    89/  229] train: loss: 0.1458255
[Epoch 20; Iter   119/  229] train: loss: 0.1581200
[Epoch 20; Iter   149/  229] train: loss: 0.2635144
[Epoch 20; Iter   179/  229] train: loss: 0.1109065
[Epoch 20; Iter   209/  229] train: loss: 0.1588757
[Epoch 20] ogbg-moltoxcast: 0.682229 val loss: 0.268576
[Epoch 20] ogbg-moltoxcast: 0.654730 test loss: 0.305939
[Epoch 21; Iter    10/  229] train: loss: 0.2049370
[Epoch 21; Iter    40/  229] train: loss: 0.1052888
[Epoch 21; Iter    70/  229] train: loss: 0.1939917
[Epoch 21; Iter   100/  229] train: loss: 0.2274594
[Epoch 21; Iter   130/  229] train: loss: 0.1965995
[Epoch 21; Iter   160/  229] train: loss: 0.2001908
[Epoch 21; Iter   190/  229] train: loss: 0.1433115
[Epoch 21; Iter   220/  229] train: loss: 0.1918313
[Epoch 21] ogbg-moltoxcast: 0.692192 val loss: 0.264857
[Epoch 21] ogbg-moltoxcast: 0.652256 test loss: 0.306249
[Epoch 22; Iter    21/  229] train: loss: 0.1446164
[Epoch 22; Iter    51/  229] train: loss: 0.1735287
[Epoch 22; Iter    81/  229] train: loss: 0.1435428
[Epoch 22; Iter   111/  229] train: loss: 0.1872330
[Epoch 22; Iter   141/  229] train: loss: 0.1285674
[Epoch 22; Iter   171/  229] train: loss: 0.1890330
[Epoch 22; Iter   201/  229] train: loss: 0.1526689
[Epoch 22] ogbg-moltoxcast: 0.692292 val loss: 0.269568
[Epoch 22] ogbg-moltoxcast: 0.656528 test loss: 0.305012
[Epoch 23; Iter     2/  229] train: loss: 0.1658899
[Epoch 23; Iter    32/  229] train: loss: 0.1295222
[Epoch 23; Iter    62/  229] train: loss: 0.0913633
[Epoch 23; Iter    92/  229] train: loss: 0.1144967
[Epoch 23; Iter   122/  229] train: loss: 0.1523696
[Epoch 23; Iter   152/  229] train: loss: 0.1161985
[Epoch 23; Iter   182/  229] train: loss: 0.1752665
[Epoch 23; Iter   212/  229] train: loss: 0.1856266
[Epoch 23] ogbg-moltoxcast: 0.694052 val loss: 0.266644
[Epoch 23] ogbg-moltoxcast: 0.653453 test loss: 0.303044
[Epoch 24; Iter    13/  229] train: loss: 0.1228680
[Epoch 24; Iter    43/  229] train: loss: 0.1904540
[Epoch 24; Iter    73/  229] train: loss: 0.1680996
[Epoch 24; Iter   103/  229] train: loss: 0.1688571
[Epoch 24; Iter   133/  229] train: loss: 0.2033561
[Epoch 24; Iter   163/  229] train: loss: 0.1761353
[Epoch 24; Iter   193/  229] train: loss: 0.1642819
[Epoch 24; Iter   223/  229] train: loss: 0.1261012
[Epoch 24] ogbg-moltoxcast: 0.691213 val loss: 0.274864
[Epoch 24] ogbg-moltoxcast: 0.642530 test loss: 0.317276
[Epoch 25; Iter    24/  229] train: loss: 0.1709033
[Epoch 25; Iter    54/  229] train: loss: 0.1722143
[Epoch 25; Iter    84/  229] train: loss: 0.1459935
[Epoch 25; Iter   114/  229] train: loss: 0.2841808
[Epoch 25; Iter   144/  229] train: loss: 0.1208284
[Epoch 25; Iter   174/  229] train: loss: 0.1984243
[Epoch 25; Iter   204/  229] train: loss: 0.1368650
[Epoch 25] ogbg-moltoxcast: 0.681362 val loss: 0.280111
[Epoch 25] ogbg-moltoxcast: 0.643992 test loss: 0.326313
[Epoch 26; Iter     5/  229] train: loss: 0.1308433
[Epoch 26; Iter    35/  229] train: loss: 0.1592139
[Epoch 26; Iter    65/  229] train: loss: 0.1189969
[Epoch 26; Iter    95/  229] train: loss: 0.1436522
[Epoch 26; Iter   125/  229] train: loss: 0.1680784
[Epoch 26; Iter   155/  229] train: loss: 0.1673738
[Epoch 26; Iter   185/  229] train: loss: 0.1518773
[Epoch 26; Iter   215/  229] train: loss: 0.1826205
[Epoch 26] ogbg-moltoxcast: 0.685888 val loss: 0.273896
[Epoch 26] ogbg-moltoxcast: 0.662568 test loss: 0.312879
[Epoch 27; Iter    16/  229] train: loss: 0.0796433
[Epoch 27; Iter    46/  229] train: loss: 0.1681034
[Epoch 27; Iter    76/  229] train: loss: 0.1309693
[Epoch 27; Iter   106/  229] train: loss: 0.1780315
[Epoch 27; Iter   136/  229] train: loss: 0.1654614
[Epoch 27; Iter   166/  229] train: loss: 0.2140808
[Epoch 27; Iter   196/  229] train: loss: 0.1949565
[Epoch 27; Iter   226/  229] train: loss: 0.1794444
[Epoch 27] ogbg-moltoxcast: 0.684997 val loss: 0.287215
[Epoch 27] ogbg-moltoxcast: 0.656062 test loss: 0.322669
[Epoch 12; Iter    31/  229] train: loss: 0.1757901
[Epoch 12; Iter    61/  229] train: loss: 0.1736770
[Epoch 12; Iter    91/  229] train: loss: 0.1721555
[Epoch 12; Iter   121/  229] train: loss: 0.3359579
[Epoch 12; Iter   151/  229] train: loss: 0.1970531
[Epoch 12; Iter   181/  229] train: loss: 0.2203721
[Epoch 12; Iter   211/  229] train: loss: 0.3121764
[Epoch 12] ogbg-moltoxcast: 0.635289 val loss: 0.269485
[Epoch 12] ogbg-moltoxcast: 0.613366 test loss: 0.312009
[Epoch 13; Iter    12/  229] train: loss: 0.2321004
[Epoch 13; Iter    42/  229] train: loss: 0.1925333
[Epoch 13; Iter    72/  229] train: loss: 0.2032871
[Epoch 13; Iter   102/  229] train: loss: 0.1994067
[Epoch 13; Iter   132/  229] train: loss: 0.1437910
[Epoch 13; Iter   162/  229] train: loss: 0.2479129
[Epoch 13; Iter   192/  229] train: loss: 0.1429495
[Epoch 13; Iter   222/  229] train: loss: 0.1779540
[Epoch 13] ogbg-moltoxcast: 0.666869 val loss: 0.274176
[Epoch 13] ogbg-moltoxcast: 0.624010 test loss: 0.313693
[Epoch 14; Iter    23/  229] train: loss: 0.1664060
[Epoch 14; Iter    53/  229] train: loss: 0.1497010
[Epoch 14; Iter    83/  229] train: loss: 0.1797386
[Epoch 14; Iter   113/  229] train: loss: 0.1510151
[Epoch 14; Iter   143/  229] train: loss: 0.2361420
[Epoch 14; Iter   173/  229] train: loss: 0.1246024
[Epoch 14; Iter   203/  229] train: loss: 0.2024805
[Epoch 14] ogbg-moltoxcast: 0.678980 val loss: 0.260628
[Epoch 14] ogbg-moltoxcast: 0.635062 test loss: 0.303771
[Epoch 15; Iter     4/  229] train: loss: 0.1523725
[Epoch 15; Iter    34/  229] train: loss: 0.1954648
[Epoch 15; Iter    64/  229] train: loss: 0.1980859
[Epoch 15; Iter    94/  229] train: loss: 0.1469244
[Epoch 15; Iter   124/  229] train: loss: 0.1329698
[Epoch 15; Iter   154/  229] train: loss: 0.2067551
[Epoch 15; Iter   184/  229] train: loss: 0.1764380
[Epoch 15; Iter   214/  229] train: loss: 0.1246520
[Epoch 15] ogbg-moltoxcast: 0.655517 val loss: 0.278213
[Epoch 15] ogbg-moltoxcast: 0.631241 test loss: 0.315881
[Epoch 16; Iter    15/  229] train: loss: 0.1721718
[Epoch 16; Iter    45/  229] train: loss: 0.1160203
[Epoch 16; Iter    75/  229] train: loss: 0.1679089
[Epoch 16; Iter   105/  229] train: loss: 0.1547659
[Epoch 16; Iter   135/  229] train: loss: 0.1732273
[Epoch 16; Iter   165/  229] train: loss: 0.1283859
[Epoch 16; Iter   195/  229] train: loss: 0.1554830
[Epoch 16; Iter   225/  229] train: loss: 0.2589881
[Epoch 16] ogbg-moltoxcast: 0.668311 val loss: 0.266942
[Epoch 16] ogbg-moltoxcast: 0.628333 test loss: 0.306890
[Epoch 17; Iter    26/  229] train: loss: 0.1736565
[Epoch 17; Iter    56/  229] train: loss: 0.1106205
[Epoch 17; Iter    86/  229] train: loss: 0.2461582
[Epoch 17; Iter   116/  229] train: loss: 0.2120833
[Epoch 17; Iter   146/  229] train: loss: 0.1782158
[Epoch 17; Iter   176/  229] train: loss: 0.2395329
[Epoch 17; Iter   206/  229] train: loss: 0.1444606
[Epoch 17] ogbg-moltoxcast: 0.677630 val loss: 0.275750
[Epoch 17] ogbg-moltoxcast: 0.649534 test loss: 0.310237
[Epoch 18; Iter     7/  229] train: loss: 0.1722455
[Epoch 18; Iter    37/  229] train: loss: 0.1896252
[Epoch 18; Iter    67/  229] train: loss: 0.1530637
[Epoch 18; Iter    97/  229] train: loss: 0.1246771
[Epoch 18; Iter   127/  229] train: loss: 0.1646641
[Epoch 18; Iter   157/  229] train: loss: 0.1660443
[Epoch 18; Iter   187/  229] train: loss: 0.1837902
[Epoch 18; Iter   217/  229] train: loss: 0.2280661
[Epoch 18] ogbg-moltoxcast: 0.666025 val loss: 0.289713
[Epoch 18] ogbg-moltoxcast: 0.640525 test loss: 0.325737
[Epoch 19; Iter    18/  229] train: loss: 0.1100681
[Epoch 19; Iter    48/  229] train: loss: 0.1606622
[Epoch 19; Iter    78/  229] train: loss: 0.1258095
[Epoch 19; Iter   108/  229] train: loss: 0.1355704
[Epoch 19; Iter   138/  229] train: loss: 0.1816870
[Epoch 19; Iter   168/  229] train: loss: 0.2038270
[Epoch 19; Iter   198/  229] train: loss: 0.1593331
[Epoch 19; Iter   228/  229] train: loss: 0.1948449
[Epoch 19] ogbg-moltoxcast: 0.683270 val loss: 0.265665
[Epoch 19] ogbg-moltoxcast: 0.648282 test loss: 0.302916
[Epoch 20; Iter    29/  229] train: loss: 0.1230190
[Epoch 20; Iter    59/  229] train: loss: 0.1574369
[Epoch 20; Iter    89/  229] train: loss: 0.1909655
[Epoch 20; Iter   119/  229] train: loss: 0.1226651
[Epoch 20; Iter   149/  229] train: loss: 0.1764869
[Epoch 20; Iter   179/  229] train: loss: 0.1970931
[Epoch 20; Iter   209/  229] train: loss: 0.1565139
[Epoch 20] ogbg-moltoxcast: 0.675810 val loss: 0.289421
[Epoch 20] ogbg-moltoxcast: 0.633531 test loss: 0.321319
[Epoch 21; Iter    10/  229] train: loss: 0.1903257
[Epoch 21; Iter    40/  229] train: loss: 0.1345324
[Epoch 21; Iter    70/  229] train: loss: 0.1899103
[Epoch 21; Iter   100/  229] train: loss: 0.1574363
[Epoch 21; Iter   130/  229] train: loss: 0.1976660
[Epoch 21; Iter   160/  229] train: loss: 0.1857839
[Epoch 21; Iter   190/  229] train: loss: 0.1858037
[Epoch 21; Iter   220/  229] train: loss: 0.1400594
[Epoch 21] ogbg-moltoxcast: 0.691385 val loss: 0.254931
[Epoch 21] ogbg-moltoxcast: 0.638990 test loss: 0.305429
[Epoch 22; Iter    21/  229] train: loss: 0.1074376
[Epoch 22; Iter    51/  229] train: loss: 0.2114527
[Epoch 22; Iter    81/  229] train: loss: 0.1307924
[Epoch 22; Iter   111/  229] train: loss: 0.1911614
[Epoch 22; Iter   141/  229] train: loss: 0.1431070
[Epoch 22; Iter   171/  229] train: loss: 0.1839449
[Epoch 22; Iter   201/  229] train: loss: 0.1033793
[Epoch 22] ogbg-moltoxcast: 0.682150 val loss: 0.265238
[Epoch 22] ogbg-moltoxcast: 0.636354 test loss: 0.322912
[Epoch 23; Iter     2/  229] train: loss: 0.1373670
[Epoch 23; Iter    32/  229] train: loss: 0.1582206
[Epoch 23; Iter    62/  229] train: loss: 0.1291474
[Epoch 23; Iter    92/  229] train: loss: 0.1158136
[Epoch 23; Iter   122/  229] train: loss: 0.1380479
[Epoch 23; Iter   152/  229] train: loss: 0.2244137
[Epoch 23; Iter   182/  229] train: loss: 0.1650309
[Epoch 23; Iter   212/  229] train: loss: 0.1430106
[Epoch 23] ogbg-moltoxcast: 0.681462 val loss: 0.280126
[Epoch 23] ogbg-moltoxcast: 0.639667 test loss: 0.321440
[Epoch 24; Iter    13/  229] train: loss: 0.1271624
[Epoch 24; Iter    43/  229] train: loss: 0.1747260
[Epoch 24; Iter    73/  229] train: loss: 0.1165820
[Epoch 24; Iter   103/  229] train: loss: 0.2142543
[Epoch 24; Iter   133/  229] train: loss: 0.1215908
[Epoch 24; Iter   163/  229] train: loss: 0.1420453
[Epoch 24; Iter   193/  229] train: loss: 0.1846128
[Epoch 24; Iter   223/  229] train: loss: 0.1208741
[Epoch 24] ogbg-moltoxcast: 0.678991 val loss: 0.282063
[Epoch 24] ogbg-moltoxcast: 0.644571 test loss: 0.322655
[Epoch 25; Iter    24/  229] train: loss: 0.1050421
[Epoch 25; Iter    54/  229] train: loss: 0.1194405
[Epoch 25; Iter    84/  229] train: loss: 0.1266772
[Epoch 25; Iter   114/  229] train: loss: 0.2153752
[Epoch 25; Iter   144/  229] train: loss: 0.1763578
[Epoch 25; Iter   174/  229] train: loss: 0.1250527
[Epoch 25; Iter   204/  229] train: loss: 0.1302051
[Epoch 25] ogbg-moltoxcast: 0.669971 val loss: 0.279777
[Epoch 25] ogbg-moltoxcast: 0.640338 test loss: 0.324487
[Epoch 26; Iter     5/  229] train: loss: 0.1629527
[Epoch 26; Iter    35/  229] train: loss: 0.1486309
[Epoch 26; Iter    65/  229] train: loss: 0.1611476
[Epoch 26; Iter    95/  229] train: loss: 0.1778146
[Epoch 26; Iter   125/  229] train: loss: 0.1925136
[Epoch 26; Iter   155/  229] train: loss: 0.1599382
[Epoch 26; Iter   185/  229] train: loss: 0.1081420
[Epoch 26; Iter   215/  229] train: loss: 0.1601631
[Epoch 26] ogbg-moltoxcast: 0.673194 val loss: 0.277881
[Epoch 26] ogbg-moltoxcast: 0.634547 test loss: 0.320056
[Epoch 27; Iter    16/  229] train: loss: 0.1096015
[Epoch 27; Iter    46/  229] train: loss: 0.1462348
[Epoch 27; Iter    76/  229] train: loss: 0.1545685
[Epoch 27; Iter   106/  229] train: loss: 0.0823447
[Epoch 27; Iter   136/  229] train: loss: 0.1787031
[Epoch 27; Iter   166/  229] train: loss: 0.1433913
[Epoch 27; Iter   196/  229] train: loss: 0.2049217
[Epoch 27; Iter   226/  229] train: loss: 0.1326526
[Epoch 27] ogbg-moltoxcast: 0.678904 val loss: 0.281123
[Epoch 27] ogbg-moltoxcast: 0.639870 test loss: 0.318644
[Epoch 12; Iter    31/  229] train: loss: 0.2266459
[Epoch 12; Iter    61/  229] train: loss: 0.2415500
[Epoch 12; Iter    91/  229] train: loss: 0.1456589
[Epoch 12; Iter   121/  229] train: loss: 0.1352294
[Epoch 12; Iter   151/  229] train: loss: 0.1631633
[Epoch 12; Iter   181/  229] train: loss: 0.1930979
[Epoch 12; Iter   211/  229] train: loss: 0.1419953
[Epoch 12] ogbg-moltoxcast: 0.657333 val loss: 0.269079
[Epoch 12] ogbg-moltoxcast: 0.632791 test loss: 0.300325
[Epoch 13; Iter    12/  229] train: loss: 0.1891893
[Epoch 13; Iter    42/  229] train: loss: 0.1968556
[Epoch 13; Iter    72/  229] train: loss: 0.1910531
[Epoch 13; Iter   102/  229] train: loss: 0.2106442
[Epoch 13; Iter   132/  229] train: loss: 0.2095450
[Epoch 13; Iter   162/  229] train: loss: 0.2069300
[Epoch 13; Iter   192/  229] train: loss: 0.2012517
[Epoch 13; Iter   222/  229] train: loss: 0.1285576
[Epoch 13] ogbg-moltoxcast: 0.668840 val loss: 0.257745
[Epoch 13] ogbg-moltoxcast: 0.628491 test loss: 0.299477
[Epoch 14; Iter    23/  229] train: loss: 0.2923267
[Epoch 14; Iter    53/  229] train: loss: 0.1501823
[Epoch 14; Iter    83/  229] train: loss: 0.1514333
[Epoch 14; Iter   113/  229] train: loss: 0.1917102
[Epoch 14; Iter   143/  229] train: loss: 0.1869791
[Epoch 14; Iter   173/  229] train: loss: 0.1666196
[Epoch 14; Iter   203/  229] train: loss: 0.1618076
[Epoch 14] ogbg-moltoxcast: 0.672755 val loss: 0.265807
[Epoch 14] ogbg-moltoxcast: 0.628718 test loss: 0.305246
[Epoch 15; Iter     4/  229] train: loss: 0.2774890
[Epoch 15; Iter    34/  229] train: loss: 0.1530431
[Epoch 15; Iter    64/  229] train: loss: 0.1266294
[Epoch 15; Iter    94/  229] train: loss: 0.2071337
[Epoch 15; Iter   124/  229] train: loss: 0.1523923
[Epoch 15; Iter   154/  229] train: loss: 0.2684643
[Epoch 15; Iter   184/  229] train: loss: 0.1926116
[Epoch 15; Iter   214/  229] train: loss: 0.1644241
[Epoch 15] ogbg-moltoxcast: 0.651685 val loss: 0.273769
[Epoch 15] ogbg-moltoxcast: 0.629028 test loss: 0.320030
[Epoch 16; Iter    15/  229] train: loss: 0.1303531
[Epoch 16; Iter    45/  229] train: loss: 0.1735236
[Epoch 16; Iter    75/  229] train: loss: 0.1674188
[Epoch 16; Iter   105/  229] train: loss: 0.2230648
[Epoch 16; Iter   135/  229] train: loss: 0.1262738
[Epoch 16; Iter   165/  229] train: loss: 0.1689688
[Epoch 16; Iter   195/  229] train: loss: 0.2219985
[Epoch 16; Iter   225/  229] train: loss: 0.1609410
[Epoch 16] ogbg-moltoxcast: 0.682207 val loss: 0.266943
[Epoch 16] ogbg-moltoxcast: 0.646486 test loss: 0.302266
[Epoch 17; Iter    26/  229] train: loss: 0.1343050
[Epoch 17; Iter    56/  229] train: loss: 0.1726559
[Epoch 17; Iter    86/  229] train: loss: 0.1029669
[Epoch 17; Iter   116/  229] train: loss: 0.1253386
[Epoch 17; Iter   146/  229] train: loss: 0.1989598
[Epoch 17; Iter   176/  229] train: loss: 0.1639437
[Epoch 17; Iter   206/  229] train: loss: 0.2064896
[Epoch 17] ogbg-moltoxcast: 0.684358 val loss: 0.261438
[Epoch 17] ogbg-moltoxcast: 0.650931 test loss: 0.296435
[Epoch 18; Iter     7/  229] train: loss: 0.1865721
[Epoch 18; Iter    37/  229] train: loss: 0.1923798
[Epoch 18; Iter    67/  229] train: loss: 0.2079496
[Epoch 18; Iter    97/  229] train: loss: 0.2539595
[Epoch 18; Iter   127/  229] train: loss: 0.1623950
[Epoch 18; Iter   157/  229] train: loss: 0.1931171
[Epoch 18; Iter   187/  229] train: loss: 0.2535342
[Epoch 18; Iter   217/  229] train: loss: 0.2162990
[Epoch 18] ogbg-moltoxcast: 0.668385 val loss: 0.262768
[Epoch 18] ogbg-moltoxcast: 0.642623 test loss: 0.301432
[Epoch 19; Iter    18/  229] train: loss: 0.1283564
[Epoch 19; Iter    48/  229] train: loss: 0.2144659
[Epoch 19; Iter    78/  229] train: loss: 0.2091367
[Epoch 19; Iter   108/  229] train: loss: 0.1761334
[Epoch 19; Iter   138/  229] train: loss: 0.1838554
[Epoch 19; Iter   168/  229] train: loss: 0.1692188
[Epoch 19; Iter   198/  229] train: loss: 0.2534881
[Epoch 19; Iter   228/  229] train: loss: 0.2890515
[Epoch 19] ogbg-moltoxcast: 0.676226 val loss: 0.265698
[Epoch 19] ogbg-moltoxcast: 0.645663 test loss: 0.304105
[Epoch 20; Iter    29/  229] train: loss: 0.1618560
[Epoch 20; Iter    59/  229] train: loss: 0.1440686
[Epoch 20; Iter    89/  229] train: loss: 0.2326933
[Epoch 20; Iter   119/  229] train: loss: 0.1298427
[Epoch 20; Iter   149/  229] train: loss: 0.2156844
[Epoch 20; Iter   179/  229] train: loss: 0.1654432
[Epoch 20; Iter   209/  229] train: loss: 0.1775931
[Epoch 20] ogbg-moltoxcast: 0.677894 val loss: 0.262991
[Epoch 20] ogbg-moltoxcast: 0.655442 test loss: 0.301564
[Epoch 21; Iter    10/  229] train: loss: 0.2017880
[Epoch 21; Iter    40/  229] train: loss: 0.2032881
[Epoch 21; Iter    70/  229] train: loss: 0.2348923
[Epoch 21; Iter   100/  229] train: loss: 0.1936216
[Epoch 21; Iter   130/  229] train: loss: 0.1910746
[Epoch 21; Iter   160/  229] train: loss: 0.2025385
[Epoch 21; Iter   190/  229] train: loss: 0.1883226
[Epoch 21; Iter   220/  229] train: loss: 0.1159348
[Epoch 21] ogbg-moltoxcast: 0.680328 val loss: 0.275052
[Epoch 21] ogbg-moltoxcast: 0.650193 test loss: 0.310564
[Epoch 22; Iter    21/  229] train: loss: 0.0933836
[Epoch 22; Iter    51/  229] train: loss: 0.1953674
[Epoch 22; Iter    81/  229] train: loss: 0.1102211
[Epoch 22; Iter   111/  229] train: loss: 0.1925092
[Epoch 22; Iter   141/  229] train: loss: 0.2601438
[Epoch 22; Iter   171/  229] train: loss: 0.1301139
[Epoch 22; Iter   201/  229] train: loss: 0.1658614
[Epoch 22] ogbg-moltoxcast: 0.671333 val loss: 0.272727
[Epoch 22] ogbg-moltoxcast: 0.646642 test loss: 0.316186
[Epoch 23; Iter     2/  229] train: loss: 0.2515750
[Epoch 23; Iter    32/  229] train: loss: 0.1208002
[Epoch 23; Iter    62/  229] train: loss: 0.1736378
[Epoch 23; Iter    92/  229] train: loss: 0.1652928
[Epoch 23; Iter   122/  229] train: loss: 0.1696423
[Epoch 23; Iter   152/  229] train: loss: 0.2808645
[Epoch 23; Iter   182/  229] train: loss: 0.1967901
[Epoch 23; Iter   212/  229] train: loss: 0.1440572
[Epoch 23] ogbg-moltoxcast: 0.685716 val loss: 0.264666
[Epoch 23] ogbg-moltoxcast: 0.654818 test loss: 0.307342
[Epoch 24; Iter    13/  229] train: loss: 0.1753195
[Epoch 24; Iter    43/  229] train: loss: 0.1545559
[Epoch 24; Iter    73/  229] train: loss: 0.1292219
[Epoch 24; Iter   103/  229] train: loss: 0.1388214
[Epoch 24; Iter   133/  229] train: loss: 0.2033385
[Epoch 24; Iter   163/  229] train: loss: 0.2185743
[Epoch 24; Iter   193/  229] train: loss: 0.1234990
[Epoch 24; Iter   223/  229] train: loss: 0.1555618
[Epoch 24] ogbg-moltoxcast: 0.676354 val loss: 0.268070
[Epoch 24] ogbg-moltoxcast: 0.651728 test loss: 0.305852
[Epoch 25; Iter    24/  229] train: loss: 0.2389076
[Epoch 25; Iter    54/  229] train: loss: 0.1720297
[Epoch 25; Iter    84/  229] train: loss: 0.2195157
[Epoch 25; Iter   114/  229] train: loss: 0.1663820
[Epoch 25; Iter   144/  229] train: loss: 0.1234908
[Epoch 25; Iter   174/  229] train: loss: 0.1446500
[Epoch 25; Iter   204/  229] train: loss: 0.1591024
[Epoch 25] ogbg-moltoxcast: 0.681611 val loss: 0.267084
[Epoch 25] ogbg-moltoxcast: 0.659485 test loss: 0.312152
[Epoch 26; Iter     5/  229] train: loss: 0.1414840
[Epoch 26; Iter    35/  229] train: loss: 0.2270567
[Epoch 26; Iter    65/  229] train: loss: 0.1892677
[Epoch 26; Iter    95/  229] train: loss: 0.1975028
[Epoch 26; Iter   125/  229] train: loss: 0.1374361
[Epoch 26; Iter   155/  229] train: loss: 0.1691248
[Epoch 26; Iter   185/  229] train: loss: 0.1470010
[Epoch 26; Iter   215/  229] train: loss: 0.1155523
[Epoch 26] ogbg-moltoxcast: 0.683294 val loss: 0.266239
[Epoch 26] ogbg-moltoxcast: 0.654229 test loss: 0.315558
[Epoch 27; Iter    16/  229] train: loss: 0.1647713
[Epoch 27; Iter    46/  229] train: loss: 0.1693869
[Epoch 27; Iter    76/  229] train: loss: 0.1360771
[Epoch 27; Iter   106/  229] train: loss: 0.1967797
[Epoch 27; Iter   136/  229] train: loss: 0.1941850
[Epoch 27; Iter   166/  229] train: loss: 0.1268051
[Epoch 27; Iter   196/  229] train: loss: 0.1362956
[Epoch 27; Iter   226/  229] train: loss: 0.1519074
[Epoch 27] ogbg-moltoxcast: 0.681556 val loss: 0.280157
[Epoch 27] ogbg-moltoxcast: 0.658628 test loss: 0.336561
[Epoch 12; Iter    31/  229] train: loss: 0.1955712
[Epoch 12; Iter    61/  229] train: loss: 0.1675805
[Epoch 12; Iter    91/  229] train: loss: 0.1626717
[Epoch 12; Iter   121/  229] train: loss: 0.3464276
[Epoch 12; Iter   151/  229] train: loss: 0.2117515
[Epoch 12; Iter   181/  229] train: loss: 0.2207561
[Epoch 12; Iter   211/  229] train: loss: 0.3317167
[Epoch 12] ogbg-moltoxcast: 0.654105 val loss: 0.261648
[Epoch 12] ogbg-moltoxcast: 0.627127 test loss: 0.305805
[Epoch 13; Iter    12/  229] train: loss: 0.2373384
[Epoch 13; Iter    42/  229] train: loss: 0.2217664
[Epoch 13; Iter    72/  229] train: loss: 0.1811414
[Epoch 13; Iter   102/  229] train: loss: 0.2212858
[Epoch 13; Iter   132/  229] train: loss: 0.1442679
[Epoch 13; Iter   162/  229] train: loss: 0.2392744
[Epoch 13; Iter   192/  229] train: loss: 0.1494167
[Epoch 13; Iter   222/  229] train: loss: 0.1925681
[Epoch 13] ogbg-moltoxcast: 0.653848 val loss: 0.258150
[Epoch 13] ogbg-moltoxcast: 0.626168 test loss: 0.303120
[Epoch 14; Iter    23/  229] train: loss: 0.1779214
[Epoch 14; Iter    53/  229] train: loss: 0.1506744
[Epoch 14; Iter    83/  229] train: loss: 0.1813456
[Epoch 14; Iter   113/  229] train: loss: 0.1420785
[Epoch 14; Iter   143/  229] train: loss: 0.2523190
[Epoch 14; Iter   173/  229] train: loss: 0.1360061
[Epoch 14; Iter   203/  229] train: loss: 0.2114507
[Epoch 14] ogbg-moltoxcast: 0.674076 val loss: 0.295092
[Epoch 14] ogbg-moltoxcast: 0.627549 test loss: 0.385810
[Epoch 15; Iter     4/  229] train: loss: 0.1557379
[Epoch 15; Iter    34/  229] train: loss: 0.2243940
[Epoch 15; Iter    64/  229] train: loss: 0.1946858
[Epoch 15; Iter    94/  229] train: loss: 0.1615853
[Epoch 15; Iter   124/  229] train: loss: 0.1293895
[Epoch 15; Iter   154/  229] train: loss: 0.1945491
[Epoch 15; Iter   184/  229] train: loss: 0.1727373
[Epoch 15; Iter   214/  229] train: loss: 0.1259223
[Epoch 15] ogbg-moltoxcast: 0.649120 val loss: 0.280603
[Epoch 15] ogbg-moltoxcast: 0.640909 test loss: 0.328296
[Epoch 16; Iter    15/  229] train: loss: 0.1868739
[Epoch 16; Iter    45/  229] train: loss: 0.1270832
[Epoch 16; Iter    75/  229] train: loss: 0.1680894
[Epoch 16; Iter   105/  229] train: loss: 0.1505521
[Epoch 16; Iter   135/  229] train: loss: 0.1816852
[Epoch 16; Iter   165/  229] train: loss: 0.1274849
[Epoch 16; Iter   195/  229] train: loss: 0.1640891
[Epoch 16; Iter   225/  229] train: loss: 0.2226042
[Epoch 16] ogbg-moltoxcast: 0.669353 val loss: 0.267015
[Epoch 16] ogbg-moltoxcast: 0.629268 test loss: 0.308568
[Epoch 17; Iter    26/  229] train: loss: 0.1735459
[Epoch 17; Iter    56/  229] train: loss: 0.1054292
[Epoch 17; Iter    86/  229] train: loss: 0.2495424
[Epoch 17; Iter   116/  229] train: loss: 0.2082210
[Epoch 17; Iter   146/  229] train: loss: 0.1797445
[Epoch 17; Iter   176/  229] train: loss: 0.2338100
[Epoch 17; Iter   206/  229] train: loss: 0.1541877
[Epoch 17] ogbg-moltoxcast: 0.675917 val loss: 0.264379
[Epoch 17] ogbg-moltoxcast: 0.639347 test loss: 0.302509
[Epoch 18; Iter     7/  229] train: loss: 0.1655873
[Epoch 18; Iter    37/  229] train: loss: 0.2079612
[Epoch 18; Iter    67/  229] train: loss: 0.1721849
[Epoch 18; Iter    97/  229] train: loss: 0.1354969
[Epoch 18; Iter   127/  229] train: loss: 0.1687178
[Epoch 18; Iter   157/  229] train: loss: 0.1939192
[Epoch 18; Iter   187/  229] train: loss: 0.1903990
[Epoch 18; Iter   217/  229] train: loss: 0.2385825
[Epoch 18] ogbg-moltoxcast: 0.664906 val loss: 0.264961
[Epoch 18] ogbg-moltoxcast: 0.643521 test loss: 0.309627
[Epoch 19; Iter    18/  229] train: loss: 0.0989576
[Epoch 19; Iter    48/  229] train: loss: 0.1793574
[Epoch 19; Iter    78/  229] train: loss: 0.1478690
[Epoch 19; Iter   108/  229] train: loss: 0.1425855
[Epoch 19; Iter   138/  229] train: loss: 0.1816333
[Epoch 19; Iter   168/  229] train: loss: 0.2302089
[Epoch 19; Iter   198/  229] train: loss: 0.1701629
[Epoch 19; Iter   228/  229] train: loss: 0.1962704
[Epoch 19] ogbg-moltoxcast: 0.673398 val loss: 0.262854
[Epoch 19] ogbg-moltoxcast: 0.643889 test loss: 0.305593
[Epoch 20; Iter    29/  229] train: loss: 0.1316698
[Epoch 20; Iter    59/  229] train: loss: 0.1915028
[Epoch 20; Iter    89/  229] train: loss: 0.2043057
[Epoch 20; Iter   119/  229] train: loss: 0.1249113
[Epoch 20; Iter   149/  229] train: loss: 0.1810786
[Epoch 20; Iter   179/  229] train: loss: 0.1762823
[Epoch 20; Iter   209/  229] train: loss: 0.1522578
[Epoch 20] ogbg-moltoxcast: 0.671273 val loss: 0.259624
[Epoch 20] ogbg-moltoxcast: 0.644824 test loss: 0.301354
[Epoch 21; Iter    10/  229] train: loss: 0.2020397
[Epoch 21; Iter    40/  229] train: loss: 0.1370337
[Epoch 21; Iter    70/  229] train: loss: 0.2057198
[Epoch 21; Iter   100/  229] train: loss: 0.1679198
[Epoch 21; Iter   130/  229] train: loss: 0.1839008
[Epoch 21; Iter   160/  229] train: loss: 0.1895849
[Epoch 21; Iter   190/  229] train: loss: 0.1950284
[Epoch 21; Iter   220/  229] train: loss: 0.1548887
[Epoch 21] ogbg-moltoxcast: 0.667851 val loss: 0.255717
[Epoch 21] ogbg-moltoxcast: 0.638207 test loss: 0.302400
[Epoch 22; Iter    21/  229] train: loss: 0.1057657
[Epoch 22; Iter    51/  229] train: loss: 0.2130250
[Epoch 22; Iter    81/  229] train: loss: 0.1227593
[Epoch 22; Iter   111/  229] train: loss: 0.1936589
[Epoch 22; Iter   141/  229] train: loss: 0.1578858
[Epoch 22; Iter   171/  229] train: loss: 0.1858549
[Epoch 22; Iter   201/  229] train: loss: 0.1153538
[Epoch 22] ogbg-moltoxcast: 0.664029 val loss: 0.258172
[Epoch 22] ogbg-moltoxcast: 0.636339 test loss: 0.381222
[Epoch 23; Iter     2/  229] train: loss: 0.1450783
[Epoch 23; Iter    32/  229] train: loss: 0.1621683
[Epoch 23; Iter    62/  229] train: loss: 0.1373220
[Epoch 23; Iter    92/  229] train: loss: 0.1193545
[Epoch 23; Iter   122/  229] train: loss: 0.1389369
[Epoch 23; Iter   152/  229] train: loss: 0.2238068
[Epoch 23; Iter   182/  229] train: loss: 0.1523066
[Epoch 23; Iter   212/  229] train: loss: 0.1420131
[Epoch 23] ogbg-moltoxcast: 0.682564 val loss: 0.277047
[Epoch 23] ogbg-moltoxcast: 0.645504 test loss: 0.330906
[Epoch 24; Iter    13/  229] train: loss: 0.1353844
[Epoch 24; Iter    43/  229] train: loss: 0.1859110
[Epoch 24; Iter    73/  229] train: loss: 0.1179494
[Epoch 24; Iter   103/  229] train: loss: 0.2353227
[Epoch 24; Iter   133/  229] train: loss: 0.1140073
[Epoch 24; Iter   163/  229] train: loss: 0.1377162
[Epoch 24; Iter   193/  229] train: loss: 0.1861833
[Epoch 24; Iter   223/  229] train: loss: 0.1345656
[Epoch 24] ogbg-moltoxcast: 0.671301 val loss: 0.266700
[Epoch 24] ogbg-moltoxcast: 0.651554 test loss: 0.312391
[Epoch 25; Iter    24/  229] train: loss: 0.1058898
[Epoch 25; Iter    54/  229] train: loss: 0.1089561
[Epoch 25; Iter    84/  229] train: loss: 0.1359992
[Epoch 25; Iter   114/  229] train: loss: 0.2213039
[Epoch 25; Iter   144/  229] train: loss: 0.1823309
[Epoch 25; Iter   174/  229] train: loss: 0.1306679
[Epoch 25; Iter   204/  229] train: loss: 0.1345097
[Epoch 25] ogbg-moltoxcast: 0.669361 val loss: 0.262574
[Epoch 25] ogbg-moltoxcast: 0.648976 test loss: 0.305375
[Epoch 26; Iter     5/  229] train: loss: 0.1610231
[Epoch 26; Iter    35/  229] train: loss: 0.1718664
[Epoch 26; Iter    65/  229] train: loss: 0.1631580
[Epoch 26; Iter    95/  229] train: loss: 0.2024918
[Epoch 26; Iter   125/  229] train: loss: 0.2042627
[Epoch 26; Iter   155/  229] train: loss: 0.1546670
[Epoch 26; Iter   185/  229] train: loss: 0.1156214
[Epoch 26; Iter   215/  229] train: loss: 0.1603912
[Epoch 26] ogbg-moltoxcast: 0.676950 val loss: 0.259607
[Epoch 26] ogbg-moltoxcast: 0.649747 test loss: 0.311054
[Epoch 27; Iter    16/  229] train: loss: 0.1083145
[Epoch 27; Iter    46/  229] train: loss: 0.1498726
[Epoch 27; Iter    76/  229] train: loss: 0.1432989
[Epoch 27; Iter   106/  229] train: loss: 0.0963212
[Epoch 27; Iter   136/  229] train: loss: 0.1936412
[Epoch 27; Iter   166/  229] train: loss: 0.1621017
[Epoch 27; Iter   196/  229] train: loss: 0.1996743
[Epoch 27; Iter   226/  229] train: loss: 0.1379525
[Epoch 27] ogbg-moltoxcast: 0.679850 val loss: 0.262488
[Epoch 27] ogbg-moltoxcast: 0.648039 test loss: 0.307565
[Epoch 12; Iter    31/  229] train: loss: 0.1908332
[Epoch 12; Iter    61/  229] train: loss: 0.1757839
[Epoch 12; Iter    91/  229] train: loss: 0.1643570
[Epoch 12; Iter   121/  229] train: loss: 0.3618248
[Epoch 12; Iter   151/  229] train: loss: 0.1910825
[Epoch 12; Iter   181/  229] train: loss: 0.2212300
[Epoch 12; Iter   211/  229] train: loss: 0.3198714
[Epoch 12] ogbg-moltoxcast: 0.646100 val loss: 0.287827
[Epoch 12] ogbg-moltoxcast: 0.601515 test loss: 0.396027
[Epoch 13; Iter    12/  229] train: loss: 0.2459656
[Epoch 13; Iter    42/  229] train: loss: 0.1927115
[Epoch 13; Iter    72/  229] train: loss: 0.1929810
[Epoch 13; Iter   102/  229] train: loss: 0.2056783
[Epoch 13; Iter   132/  229] train: loss: 0.1352739
[Epoch 13; Iter   162/  229] train: loss: 0.2593549
[Epoch 13; Iter   192/  229] train: loss: 0.1411850
[Epoch 13; Iter   222/  229] train: loss: 0.1777783
[Epoch 13] ogbg-moltoxcast: 0.666608 val loss: 0.275620
[Epoch 13] ogbg-moltoxcast: 0.617921 test loss: 0.345163
[Epoch 14; Iter    23/  229] train: loss: 0.1868566
[Epoch 14; Iter    53/  229] train: loss: 0.1498229
[Epoch 14; Iter    83/  229] train: loss: 0.1825029
[Epoch 14; Iter   113/  229] train: loss: 0.1418732
[Epoch 14; Iter   143/  229] train: loss: 0.2512001
[Epoch 14; Iter   173/  229] train: loss: 0.1303729
[Epoch 14; Iter   203/  229] train: loss: 0.1881696
[Epoch 14] ogbg-moltoxcast: 0.636800 val loss: 0.634891
[Epoch 14] ogbg-moltoxcast: 0.592371 test loss: 1.603607
[Epoch 15; Iter     4/  229] train: loss: 0.1497175
[Epoch 15; Iter    34/  229] train: loss: 0.2295875
[Epoch 15; Iter    64/  229] train: loss: 0.1980124
[Epoch 15; Iter    94/  229] train: loss: 0.1637901
[Epoch 15; Iter   124/  229] train: loss: 0.1280094
[Epoch 15; Iter   154/  229] train: loss: 0.2028316
[Epoch 15; Iter   184/  229] train: loss: 0.1565586
[Epoch 15; Iter   214/  229] train: loss: 0.1261278
[Epoch 15] ogbg-moltoxcast: 0.626356 val loss: 0.286138
[Epoch 15] ogbg-moltoxcast: 0.613101 test loss: 0.351973
[Epoch 16; Iter    15/  229] train: loss: 0.2010643
[Epoch 16; Iter    45/  229] train: loss: 0.1421639
[Epoch 16; Iter    75/  229] train: loss: 0.1721794
[Epoch 16; Iter   105/  229] train: loss: 0.1548487
[Epoch 16; Iter   135/  229] train: loss: 0.1868060
[Epoch 16; Iter   165/  229] train: loss: 0.1219902
[Epoch 16; Iter   195/  229] train: loss: 0.1588919
[Epoch 16; Iter   225/  229] train: loss: 0.2155601
[Epoch 16] ogbg-moltoxcast: 0.647239 val loss: 0.304119
[Epoch 16] ogbg-moltoxcast: 0.616128 test loss: 0.343800
[Epoch 17; Iter    26/  229] train: loss: 0.1647986
[Epoch 17; Iter    56/  229] train: loss: 0.1053917
[Epoch 17; Iter    86/  229] train: loss: 0.2644854
[Epoch 17; Iter   116/  229] train: loss: 0.2092001
[Epoch 17; Iter   146/  229] train: loss: 0.1711994
[Epoch 17; Iter   176/  229] train: loss: 0.2275244
[Epoch 17; Iter   206/  229] train: loss: 0.1347050
[Epoch 17] ogbg-moltoxcast: 0.673366 val loss: 0.319009
[Epoch 17] ogbg-moltoxcast: 0.631061 test loss: 0.364573
[Epoch 18; Iter     7/  229] train: loss: 0.1653674
[Epoch 18; Iter    37/  229] train: loss: 0.1974102
[Epoch 18; Iter    67/  229] train: loss: 0.1508874
[Epoch 18; Iter    97/  229] train: loss: 0.1298610
[Epoch 18; Iter   127/  229] train: loss: 0.1551548
[Epoch 18; Iter   157/  229] train: loss: 0.1707745
[Epoch 18; Iter   187/  229] train: loss: 0.1835799
[Epoch 18; Iter   217/  229] train: loss: 0.2228879
[Epoch 18] ogbg-moltoxcast: 0.628015 val loss: 0.522695
[Epoch 18] ogbg-moltoxcast: 0.614986 test loss: 0.605240
[Epoch 19; Iter    18/  229] train: loss: 0.0995945
[Epoch 19; Iter    48/  229] train: loss: 0.1663963
[Epoch 19; Iter    78/  229] train: loss: 0.1288554
[Epoch 19; Iter   108/  229] train: loss: 0.1494239
[Epoch 19; Iter   138/  229] train: loss: 0.1842463
[Epoch 19; Iter   168/  229] train: loss: 0.2242549
[Epoch 19; Iter   198/  229] train: loss: 0.1670379
[Epoch 19; Iter   228/  229] train: loss: 0.1741536
[Epoch 19] ogbg-moltoxcast: 0.631914 val loss: 0.363191
[Epoch 19] ogbg-moltoxcast: 0.611785 test loss: 0.568388
[Epoch 20; Iter    29/  229] train: loss: 0.1231754
[Epoch 20; Iter    59/  229] train: loss: 0.1556864
[Epoch 20; Iter    89/  229] train: loss: 0.1874155
[Epoch 20; Iter   119/  229] train: loss: 0.1194870
[Epoch 20; Iter   149/  229] train: loss: 0.1791616
[Epoch 20; Iter   179/  229] train: loss: 0.1876763
[Epoch 20; Iter   209/  229] train: loss: 0.1560271
[Epoch 20] ogbg-moltoxcast: 0.640956 val loss: 0.607489
[Epoch 20] ogbg-moltoxcast: 0.616009 test loss: 1.662516
[Epoch 21; Iter    10/  229] train: loss: 0.1838912
[Epoch 21; Iter    40/  229] train: loss: 0.1395304
[Epoch 21; Iter    70/  229] train: loss: 0.1790099
[Epoch 21; Iter   100/  229] train: loss: 0.1594528
[Epoch 21; Iter   130/  229] train: loss: 0.1933067
[Epoch 21; Iter   160/  229] train: loss: 0.1859635
[Epoch 21; Iter   190/  229] train: loss: 0.1729141
[Epoch 21; Iter   220/  229] train: loss: 0.1423343
[Epoch 21] ogbg-moltoxcast: 0.644785 val loss: 0.371823
[Epoch 21] ogbg-moltoxcast: 0.626875 test loss: 0.380119
[Epoch 22; Iter    21/  229] train: loss: 0.1133524
[Epoch 22; Iter    51/  229] train: loss: 0.1977589
[Epoch 22; Iter    81/  229] train: loss: 0.1362885
[Epoch 22; Iter   111/  229] train: loss: 0.1974100
[Epoch 22; Iter   141/  229] train: loss: 0.1328111
[Epoch 22; Iter   171/  229] train: loss: 0.1960735
[Epoch 22; Iter   201/  229] train: loss: 0.1251795
[Epoch 22] ogbg-moltoxcast: 0.656673 val loss: 0.853395
[Epoch 22] ogbg-moltoxcast: 0.622851 test loss: 1.342213
[Epoch 23; Iter     2/  229] train: loss: 0.1359790
[Epoch 23; Iter    32/  229] train: loss: 0.1616695
[Epoch 23; Iter    62/  229] train: loss: 0.1295259
[Epoch 23; Iter    92/  229] train: loss: 0.1183732
[Epoch 23; Iter   122/  229] train: loss: 0.1283509
[Epoch 23; Iter   152/  229] train: loss: 0.2035027
[Epoch 23; Iter   182/  229] train: loss: 0.1603958
[Epoch 23; Iter   212/  229] train: loss: 0.1359078
[Epoch 23] ogbg-moltoxcast: 0.652111 val loss: 0.580946
[Epoch 23] ogbg-moltoxcast: 0.615265 test loss: 0.974581
[Epoch 24; Iter    13/  229] train: loss: 0.1350769
[Epoch 24; Iter    43/  229] train: loss: 0.1751345
[Epoch 24; Iter    73/  229] train: loss: 0.1117654
[Epoch 24; Iter   103/  229] train: loss: 0.2064880
[Epoch 24; Iter   133/  229] train: loss: 0.1461696
[Epoch 24; Iter   163/  229] train: loss: 0.1324077
[Epoch 24; Iter   193/  229] train: loss: 0.1865470
[Epoch 24; Iter   223/  229] train: loss: 0.1239481
[Epoch 24] ogbg-moltoxcast: 0.653503 val loss: 0.514500
[Epoch 24] ogbg-moltoxcast: 0.623549 test loss: 0.361304
[Epoch 25; Iter    24/  229] train: loss: 0.1043500
[Epoch 25; Iter    54/  229] train: loss: 0.1112267
[Epoch 25; Iter    84/  229] train: loss: 0.1294521
[Epoch 25; Iter   114/  229] train: loss: 0.2205187
[Epoch 25; Iter   144/  229] train: loss: 0.1772478
[Epoch 25; Iter   174/  229] train: loss: 0.1212439
[Epoch 25; Iter   204/  229] train: loss: 0.1327097
[Epoch 25] ogbg-moltoxcast: 0.642813 val loss: 0.899927
[Epoch 25] ogbg-moltoxcast: 0.631187 test loss: 2.540925
[Epoch 26; Iter     5/  229] train: loss: 0.1495690
[Epoch 26; Iter    35/  229] train: loss: 0.1555211
[Epoch 26; Iter    65/  229] train: loss: 0.1558254
[Epoch 26; Iter    95/  229] train: loss: 0.1734110
[Epoch 26; Iter   125/  229] train: loss: 0.2029490
[Epoch 26; Iter   155/  229] train: loss: 0.1563765
[Epoch 26; Iter   185/  229] train: loss: 0.1220710
[Epoch 26; Iter   215/  229] train: loss: 0.1492665
[Epoch 26] ogbg-moltoxcast: 0.671157 val loss: 0.327654
[Epoch 26] ogbg-moltoxcast: 0.639001 test loss: 0.352602
[Epoch 27; Iter    16/  229] train: loss: 0.1070022
[Epoch 27; Iter    46/  229] train: loss: 0.1442005
[Epoch 27; Iter    76/  229] train: loss: 0.1396749
[Epoch 27; Iter   106/  229] train: loss: 0.0784869
[Epoch 27; Iter   136/  229] train: loss: 0.1939969
[Epoch 27; Iter   166/  229] train: loss: 0.1480615
[Epoch 27; Iter   196/  229] train: loss: 0.2071106
[Epoch 27; Iter   226/  229] train: loss: 0.1365831
[Epoch 27] ogbg-moltoxcast: 0.664903 val loss: 0.804720
[Epoch 27] ogbg-moltoxcast: 0.625811 test loss: 2.263782
[Epoch 12; Iter    31/  229] train: loss: 0.2201542
[Epoch 12; Iter    61/  229] train: loss: 0.2807010
[Epoch 12; Iter    91/  229] train: loss: 0.1495283
[Epoch 12; Iter   121/  229] train: loss: 0.1361646
[Epoch 12; Iter   151/  229] train: loss: 0.1698093
[Epoch 12; Iter   181/  229] train: loss: 0.2044432
[Epoch 12; Iter   211/  229] train: loss: 0.1295499
[Epoch 12] ogbg-moltoxcast: 0.654409 val loss: 1.203619
[Epoch 12] ogbg-moltoxcast: 0.627263 test loss: 3.196804
[Epoch 13; Iter    12/  229] train: loss: 0.2071267
[Epoch 13; Iter    42/  229] train: loss: 0.1942951
[Epoch 13; Iter    72/  229] train: loss: 0.1998731
[Epoch 13; Iter   102/  229] train: loss: 0.2162229
[Epoch 13; Iter   132/  229] train: loss: 0.2236627
[Epoch 13; Iter   162/  229] train: loss: 0.2107028
[Epoch 13; Iter   192/  229] train: loss: 0.2006855
[Epoch 13; Iter   222/  229] train: loss: 0.1393339
[Epoch 13] ogbg-moltoxcast: 0.642721 val loss: 0.269280
[Epoch 13] ogbg-moltoxcast: 0.612439 test loss: 0.664402
[Epoch 14; Iter    23/  229] train: loss: 0.2866115
[Epoch 14; Iter    53/  229] train: loss: 0.1441009
[Epoch 14; Iter    83/  229] train: loss: 0.1489198
[Epoch 14; Iter   113/  229] train: loss: 0.2127365
[Epoch 14; Iter   143/  229] train: loss: 0.1778299
[Epoch 14; Iter   173/  229] train: loss: 0.1708949
[Epoch 14; Iter   203/  229] train: loss: 0.1732333
[Epoch 14] ogbg-moltoxcast: 0.652167 val loss: 0.298368
[Epoch 14] ogbg-moltoxcast: 0.625459 test loss: 0.304319
[Epoch 15; Iter     4/  229] train: loss: 0.3048677
[Epoch 15; Iter    34/  229] train: loss: 0.1567580
[Epoch 15; Iter    64/  229] train: loss: 0.1277967
[Epoch 15; Iter    94/  229] train: loss: 0.2222870
[Epoch 15; Iter   124/  229] train: loss: 0.1798191
[Epoch 15; Iter   154/  229] train: loss: 0.2887643
[Epoch 15; Iter   184/  229] train: loss: 0.1980228
[Epoch 15; Iter   214/  229] train: loss: 0.1682363
[Epoch 15] ogbg-moltoxcast: 0.648108 val loss: 0.270604
[Epoch 15] ogbg-moltoxcast: 0.629286 test loss: 0.309519
[Epoch 16; Iter    15/  229] train: loss: 0.1352445
[Epoch 16; Iter    45/  229] train: loss: 0.1995491
[Epoch 16; Iter    75/  229] train: loss: 0.1843049
[Epoch 16; Iter   105/  229] train: loss: 0.2167754
[Epoch 16; Iter   135/  229] train: loss: 0.1333738
[Epoch 16; Iter   165/  229] train: loss: 0.1839824
[Epoch 16; Iter   195/  229] train: loss: 0.2308816
[Epoch 16; Iter   225/  229] train: loss: 0.1772789
[Epoch 16] ogbg-moltoxcast: 0.671388 val loss: 0.258827
[Epoch 16] ogbg-moltoxcast: 0.644841 test loss: 0.296403
[Epoch 17; Iter    26/  229] train: loss: 0.1424242
[Epoch 17; Iter    56/  229] train: loss: 0.1783991
[Epoch 17; Iter    86/  229] train: loss: 0.1095455
[Epoch 17; Iter   116/  229] train: loss: 0.1353413
[Epoch 17; Iter   146/  229] train: loss: 0.2332282
[Epoch 17; Iter   176/  229] train: loss: 0.1607711
[Epoch 17; Iter   206/  229] train: loss: 0.2152417
[Epoch 17] ogbg-moltoxcast: 0.669762 val loss: 0.259954
[Epoch 17] ogbg-moltoxcast: 0.638793 test loss: 0.301154
[Epoch 18; Iter     7/  229] train: loss: 0.1851867
[Epoch 18; Iter    37/  229] train: loss: 0.2047368
[Epoch 18; Iter    67/  229] train: loss: 0.1956333
[Epoch 18; Iter    97/  229] train: loss: 0.2953908
[Epoch 18; Iter   127/  229] train: loss: 0.1906235
[Epoch 18; Iter   157/  229] train: loss: 0.2215663
[Epoch 18; Iter   187/  229] train: loss: 0.2566660
[Epoch 18; Iter   217/  229] train: loss: 0.2515108
[Epoch 18] ogbg-moltoxcast: 0.655931 val loss: 0.266449
[Epoch 18] ogbg-moltoxcast: 0.644189 test loss: 0.640118
[Epoch 19; Iter    18/  229] train: loss: 0.1370366
[Epoch 19; Iter    48/  229] train: loss: 0.2325219
[Epoch 19; Iter    78/  229] train: loss: 0.2040914
[Epoch 19; Iter   108/  229] train: loss: 0.1898383
[Epoch 19; Iter   138/  229] train: loss: 0.1939841
[Epoch 19; Iter   168/  229] train: loss: 0.1534444
[Epoch 19; Iter   198/  229] train: loss: 0.2346421
[Epoch 19; Iter   228/  229] train: loss: 0.2777647
[Epoch 19] ogbg-moltoxcast: 0.666394 val loss: 0.262767
[Epoch 19] ogbg-moltoxcast: 0.635431 test loss: 0.300147
[Epoch 20; Iter    29/  229] train: loss: 0.1677028
[Epoch 20; Iter    59/  229] train: loss: 0.1387791
[Epoch 20; Iter    89/  229] train: loss: 0.2650458
[Epoch 20; Iter   119/  229] train: loss: 0.1523717
[Epoch 20; Iter   149/  229] train: loss: 0.2254803
[Epoch 20; Iter   179/  229] train: loss: 0.1539033
[Epoch 20; Iter   209/  229] train: loss: 0.1780034
[Epoch 20] ogbg-moltoxcast: 0.666717 val loss: 0.269122
[Epoch 20] ogbg-moltoxcast: 0.639192 test loss: 0.446849
[Epoch 21; Iter    10/  229] train: loss: 0.2179418
[Epoch 21; Iter    40/  229] train: loss: 0.2036065
[Epoch 21; Iter    70/  229] train: loss: 0.2359082
[Epoch 21; Iter   100/  229] train: loss: 0.2167510
[Epoch 21; Iter   130/  229] train: loss: 0.1893835
[Epoch 21; Iter   160/  229] train: loss: 0.2036811
[Epoch 21; Iter   190/  229] train: loss: 0.2156928
[Epoch 21; Iter   220/  229] train: loss: 0.1378025
[Epoch 21] ogbg-moltoxcast: 0.655858 val loss: 0.288545
[Epoch 21] ogbg-moltoxcast: 0.632870 test loss: 0.319947
[Epoch 22; Iter    21/  229] train: loss: 0.1052959
[Epoch 22; Iter    51/  229] train: loss: 0.2168473
[Epoch 22; Iter    81/  229] train: loss: 0.1092974
[Epoch 22; Iter   111/  229] train: loss: 0.2252093
[Epoch 22; Iter   141/  229] train: loss: 0.2583872
[Epoch 22; Iter   171/  229] train: loss: 0.1487460
[Epoch 22; Iter   201/  229] train: loss: 0.1575765
[Epoch 22] ogbg-moltoxcast: 0.664476 val loss: 0.420519
[Epoch 22] ogbg-moltoxcast: 0.639908 test loss: 0.310159
[Epoch 23; Iter     2/  229] train: loss: 0.2622657
[Epoch 23; Iter    32/  229] train: loss: 0.1277359
[Epoch 23; Iter    62/  229] train: loss: 0.1908950
[Epoch 23; Iter    92/  229] train: loss: 0.1706825
[Epoch 23; Iter   122/  229] train: loss: 0.1814829
[Epoch 23; Iter   152/  229] train: loss: 0.2753070
[Epoch 23; Iter   182/  229] train: loss: 0.1888918
[Epoch 23; Iter   212/  229] train: loss: 0.1597892
[Epoch 23] ogbg-moltoxcast: 0.665507 val loss: 0.290302
[Epoch 23] ogbg-moltoxcast: 0.631528 test loss: 0.324603
[Epoch 24; Iter    13/  229] train: loss: 0.2013677
[Epoch 24; Iter    43/  229] train: loss: 0.1624764
[Epoch 24; Iter    73/  229] train: loss: 0.1367386
[Epoch 24; Iter   103/  229] train: loss: 0.1513735
[Epoch 24; Iter   133/  229] train: loss: 0.2104550
[Epoch 24; Iter   163/  229] train: loss: 0.2362129
[Epoch 24; Iter   193/  229] train: loss: 0.1484529
[Epoch 24; Iter   223/  229] train: loss: 0.1593075
[Epoch 24] ogbg-moltoxcast: 0.654564 val loss: 0.274005
[Epoch 24] ogbg-moltoxcast: 0.635689 test loss: 0.309794
[Epoch 25; Iter    24/  229] train: loss: 0.2670887
[Epoch 25; Iter    54/  229] train: loss: 0.1744409
[Epoch 25; Iter    84/  229] train: loss: 0.2295832
[Epoch 25; Iter   114/  229] train: loss: 0.1809772
[Epoch 25; Iter   144/  229] train: loss: 0.1169518
[Epoch 25; Iter   174/  229] train: loss: 0.1384563
[Epoch 25; Iter   204/  229] train: loss: 0.1833998
[Epoch 25] ogbg-moltoxcast: 0.654855 val loss: 0.284020
[Epoch 25] ogbg-moltoxcast: 0.613432 test loss: 0.415381
[Epoch 26; Iter     5/  229] train: loss: 0.1404859
[Epoch 26; Iter    35/  229] train: loss: 0.2803386
[Epoch 26; Iter    65/  229] train: loss: 0.2160998
[Epoch 26; Iter    95/  229] train: loss: 0.2173460
[Epoch 26; Iter   125/  229] train: loss: 0.1453997
[Epoch 26; Iter   155/  229] train: loss: 0.1703029
[Epoch 26; Iter   185/  229] train: loss: 0.1749552
[Epoch 26; Iter   215/  229] train: loss: 0.1217103
[Epoch 26] ogbg-moltoxcast: 0.669718 val loss: 0.827890
[Epoch 26] ogbg-moltoxcast: 0.634033 test loss: 3.032596
[Epoch 27; Iter    16/  229] train: loss: 0.1775281
[Epoch 27; Iter    46/  229] train: loss: 0.2031111
[Epoch 27; Iter    76/  229] train: loss: 0.1433314
[Epoch 27; Iter   106/  229] train: loss: 0.2054919
[Epoch 27; Iter   136/  229] train: loss: 0.1962189
[Epoch 27; Iter   166/  229] train: loss: 0.1286210
[Epoch 27; Iter   196/  229] train: loss: 0.1404521
[Epoch 27; Iter   226/  229] train: loss: 0.1714960
[Epoch 27] ogbg-moltoxcast: 0.665016 val loss: 0.594308
[Epoch 27] ogbg-moltoxcast: 0.643181 test loss: 1.687641
[Epoch 12; Iter    31/  229] train: loss: 0.2387892
[Epoch 12; Iter    61/  229] train: loss: 0.1520850
[Epoch 12; Iter    91/  229] train: loss: 0.1928724
[Epoch 12; Iter   121/  229] train: loss: 0.2207095
[Epoch 12; Iter   151/  229] train: loss: 0.1160911
[Epoch 12; Iter   181/  229] train: loss: 0.2149661
[Epoch 12; Iter   211/  229] train: loss: 0.2037976
[Epoch 12] ogbg-moltoxcast: 0.672350 val loss: 0.259606
[Epoch 12] ogbg-moltoxcast: 0.623172 test loss: 0.304096
[Epoch 13; Iter    12/  229] train: loss: 0.1368213
[Epoch 13; Iter    42/  229] train: loss: 0.1309028
[Epoch 13; Iter    72/  229] train: loss: 0.1734727
[Epoch 13; Iter   102/  229] train: loss: 0.2585054
[Epoch 13; Iter   132/  229] train: loss: 0.2191888
[Epoch 13; Iter   162/  229] train: loss: 0.1609943
[Epoch 13; Iter   192/  229] train: loss: 0.1881156
[Epoch 13; Iter   222/  229] train: loss: 0.2231597
[Epoch 13] ogbg-moltoxcast: 0.642509 val loss: 0.266982
[Epoch 13] ogbg-moltoxcast: 0.618211 test loss: 0.311778
[Epoch 14; Iter    23/  229] train: loss: 0.2027496
[Epoch 14; Iter    53/  229] train: loss: 0.1789666
[Epoch 14; Iter    83/  229] train: loss: 0.2495844
[Epoch 14; Iter   113/  229] train: loss: 0.1803411
[Epoch 14; Iter   143/  229] train: loss: 0.1857476
[Epoch 14; Iter   173/  229] train: loss: 0.2333806
[Epoch 14; Iter   203/  229] train: loss: 0.1966189
[Epoch 14] ogbg-moltoxcast: 0.636449 val loss: 0.265954
[Epoch 14] ogbg-moltoxcast: 0.628441 test loss: 0.306233
[Epoch 15; Iter     4/  229] train: loss: 0.1905386
[Epoch 15; Iter    34/  229] train: loss: 0.1260353
[Epoch 15; Iter    64/  229] train: loss: 0.1786498
[Epoch 15; Iter    94/  229] train: loss: 0.2585731
[Epoch 15; Iter   124/  229] train: loss: 0.1603557
[Epoch 15; Iter   154/  229] train: loss: 0.1707877
[Epoch 15; Iter   184/  229] train: loss: 0.1715923
[Epoch 15; Iter   214/  229] train: loss: 0.2185655
[Epoch 15] ogbg-moltoxcast: 0.662172 val loss: 0.272773
[Epoch 15] ogbg-moltoxcast: 0.606718 test loss: 0.324443
[Epoch 16; Iter    15/  229] train: loss: 0.2730283
[Epoch 16; Iter    45/  229] train: loss: 0.1355572
[Epoch 16; Iter    75/  229] train: loss: 0.1242813
[Epoch 16; Iter   105/  229] train: loss: 0.1607257
[Epoch 16; Iter   135/  229] train: loss: 0.1595343
[Epoch 16; Iter   165/  229] train: loss: 0.1813244
[Epoch 16; Iter   195/  229] train: loss: 0.2082221
[Epoch 16; Iter   225/  229] train: loss: 0.1370507
[Epoch 16] ogbg-moltoxcast: 0.681875 val loss: 0.263658
[Epoch 16] ogbg-moltoxcast: 0.628359 test loss: 0.303751
[Epoch 17; Iter    26/  229] train: loss: 0.1579381
[Epoch 17; Iter    56/  229] train: loss: 0.2191267
[Epoch 17; Iter    86/  229] train: loss: 0.1389037
[Epoch 17; Iter   116/  229] train: loss: 0.1847615
[Epoch 17; Iter   146/  229] train: loss: 0.1729335
[Epoch 17; Iter   176/  229] train: loss: 0.2601963
[Epoch 17; Iter   206/  229] train: loss: 0.2086444
[Epoch 17] ogbg-moltoxcast: 0.667080 val loss: 0.289694
[Epoch 17] ogbg-moltoxcast: 0.626957 test loss: 0.353958
[Epoch 18; Iter     7/  229] train: loss: 0.1309297
[Epoch 18; Iter    37/  229] train: loss: 0.1740855
[Epoch 18; Iter    67/  229] train: loss: 0.1649128
[Epoch 18; Iter    97/  229] train: loss: 0.2886975
[Epoch 18; Iter   127/  229] train: loss: 0.1774288
[Epoch 18; Iter   157/  229] train: loss: 0.1927804
[Epoch 18; Iter   187/  229] train: loss: 0.1061015
[Epoch 18; Iter   217/  229] train: loss: 0.2264198
[Epoch 18] ogbg-moltoxcast: 0.652528 val loss: 0.278989
[Epoch 18] ogbg-moltoxcast: 0.622104 test loss: 0.321526
[Epoch 19; Iter    18/  229] train: loss: 0.2105242
[Epoch 19; Iter    48/  229] train: loss: 0.1790465
[Epoch 19; Iter    78/  229] train: loss: 0.1003735
[Epoch 19; Iter   108/  229] train: loss: 0.1532103
[Epoch 19; Iter   138/  229] train: loss: 0.1180020
[Epoch 19; Iter   168/  229] train: loss: 0.2109133
[Epoch 19; Iter   198/  229] train: loss: 0.2003811
[Epoch 19; Iter   228/  229] train: loss: 0.1556094
[Epoch 19] ogbg-moltoxcast: 0.650294 val loss: 0.272456
[Epoch 19] ogbg-moltoxcast: 0.624186 test loss: 0.311140
[Epoch 20; Iter    29/  229] train: loss: 0.1843864
[Epoch 20; Iter    59/  229] train: loss: 0.2318521
[Epoch 20; Iter    89/  229] train: loss: 0.1434048
[Epoch 20; Iter   119/  229] train: loss: 0.1586539
[Epoch 20; Iter   149/  229] train: loss: 0.2561705
[Epoch 20; Iter   179/  229] train: loss: 0.1150898
[Epoch 20; Iter   209/  229] train: loss: 0.1609861
[Epoch 20] ogbg-moltoxcast: 0.657820 val loss: 0.276823
[Epoch 20] ogbg-moltoxcast: 0.635226 test loss: 0.328523
[Epoch 21; Iter    10/  229] train: loss: 0.1827404
[Epoch 21; Iter    40/  229] train: loss: 0.1134053
[Epoch 21; Iter    70/  229] train: loss: 0.1916721
[Epoch 21; Iter   100/  229] train: loss: 0.2188632
[Epoch 21; Iter   130/  229] train: loss: 0.1893131
[Epoch 21; Iter   160/  229] train: loss: 0.1922717
[Epoch 21; Iter   190/  229] train: loss: 0.1466425
[Epoch 21; Iter   220/  229] train: loss: 0.2107874
[Epoch 21] ogbg-moltoxcast: 0.661860 val loss: 0.273875
[Epoch 21] ogbg-moltoxcast: 0.624914 test loss: 0.318576
[Epoch 22; Iter    21/  229] train: loss: 0.1648368
[Epoch 22; Iter    51/  229] train: loss: 0.1791340
[Epoch 22; Iter    81/  229] train: loss: 0.1378702
[Epoch 22; Iter   111/  229] train: loss: 0.1980930
[Epoch 22; Iter   141/  229] train: loss: 0.1351364
[Epoch 22; Iter   171/  229] train: loss: 0.1598481
[Epoch 22; Iter   201/  229] train: loss: 0.1541469
[Epoch 22] ogbg-moltoxcast: 0.676196 val loss: 0.272098
[Epoch 22] ogbg-moltoxcast: 0.638843 test loss: 0.335500
[Epoch 23; Iter     2/  229] train: loss: 0.1750567
[Epoch 23; Iter    32/  229] train: loss: 0.1257383
[Epoch 23; Iter    62/  229] train: loss: 0.0921276
[Epoch 23; Iter    92/  229] train: loss: 0.1099117
[Epoch 23; Iter   122/  229] train: loss: 0.1537631
[Epoch 23; Iter   152/  229] train: loss: 0.1165643
[Epoch 23; Iter   182/  229] train: loss: 0.1672501
[Epoch 23; Iter   212/  229] train: loss: 0.1878011
[Epoch 23] ogbg-moltoxcast: 0.669164 val loss: 0.269875
[Epoch 23] ogbg-moltoxcast: 0.644526 test loss: 0.313724
[Epoch 24; Iter    13/  229] train: loss: 0.1249571
[Epoch 24; Iter    43/  229] train: loss: 0.1971660
[Epoch 24; Iter    73/  229] train: loss: 0.1593930
[Epoch 24; Iter   103/  229] train: loss: 0.1842653
[Epoch 24; Iter   133/  229] train: loss: 0.2107838
[Epoch 24; Iter   163/  229] train: loss: 0.1608923
[Epoch 24; Iter   193/  229] train: loss: 0.1642659
[Epoch 24; Iter   223/  229] train: loss: 0.1331712
[Epoch 24] ogbg-moltoxcast: 0.669766 val loss: 0.289341
[Epoch 24] ogbg-moltoxcast: 0.635768 test loss: 0.337705
[Epoch 25; Iter    24/  229] train: loss: 0.1697928
[Epoch 25; Iter    54/  229] train: loss: 0.1676629
[Epoch 25; Iter    84/  229] train: loss: 0.1327700
[Epoch 25; Iter   114/  229] train: loss: 0.2586822
[Epoch 25; Iter   144/  229] train: loss: 0.1309676
[Epoch 25; Iter   174/  229] train: loss: 0.2154952
[Epoch 25; Iter   204/  229] train: loss: 0.1374011
[Epoch 25] ogbg-moltoxcast: 0.661685 val loss: 0.279842
[Epoch 25] ogbg-moltoxcast: 0.637500 test loss: 0.348447
[Epoch 26; Iter     5/  229] train: loss: 0.1376030
[Epoch 26; Iter    35/  229] train: loss: 0.1627517
[Epoch 26; Iter    65/  229] train: loss: 0.1281484
[Epoch 26; Iter    95/  229] train: loss: 0.1249617
[Epoch 26; Iter   125/  229] train: loss: 0.1684962
[Epoch 26; Iter   155/  229] train: loss: 0.1552809
[Epoch 26; Iter   185/  229] train: loss: 0.1582883
[Epoch 26; Iter   215/  229] train: loss: 0.1810972
[Epoch 26] ogbg-moltoxcast: 0.671054 val loss: 0.275761
[Epoch 26] ogbg-moltoxcast: 0.634350 test loss: 0.320754
[Epoch 27; Iter    16/  229] train: loss: 0.0787461
[Epoch 27; Iter    46/  229] train: loss: 0.1610762
[Epoch 27; Iter    76/  229] train: loss: 0.1269957
[Epoch 27; Iter   106/  229] train: loss: 0.1866482
[Epoch 27; Iter   136/  229] train: loss: 0.1487314
[Epoch 27; Iter   166/  229] train: loss: 0.2216101
[Epoch 27; Iter   196/  229] train: loss: 0.1915415
[Epoch 27; Iter   226/  229] train: loss: 0.1904846
[Epoch 27] ogbg-moltoxcast: 0.668851 val loss: 0.291752
[Epoch 27] ogbg-moltoxcast: 0.626661 test loss: 0.333593
[Epoch 12; Iter    31/  229] train: loss: 0.2215883
[Epoch 12; Iter    61/  229] train: loss: 0.2467346
[Epoch 12; Iter    91/  229] train: loss: 0.1415635
[Epoch 12; Iter   121/  229] train: loss: 0.1402550
[Epoch 12; Iter   151/  229] train: loss: 0.1553853
[Epoch 12; Iter   181/  229] train: loss: 0.1911209
[Epoch 12; Iter   211/  229] train: loss: 0.1449473
[Epoch 12] ogbg-moltoxcast: 0.653123 val loss: 0.283859
[Epoch 12] ogbg-moltoxcast: 0.626637 test loss: 0.319737
[Epoch 13; Iter    12/  229] train: loss: 0.1987189
[Epoch 13; Iter    42/  229] train: loss: 0.1875619
[Epoch 13; Iter    72/  229] train: loss: 0.1960794
[Epoch 13; Iter   102/  229] train: loss: 0.2026885
[Epoch 13; Iter   132/  229] train: loss: 0.2213904
[Epoch 13; Iter   162/  229] train: loss: 0.2076449
[Epoch 13; Iter   192/  229] train: loss: 0.2164430
[Epoch 13; Iter   222/  229] train: loss: 0.1332624
[Epoch 13] ogbg-moltoxcast: 0.654167 val loss: 0.269479
[Epoch 13] ogbg-moltoxcast: 0.615338 test loss: 0.305079
[Epoch 14; Iter    23/  229] train: loss: 0.2713683
[Epoch 14; Iter    53/  229] train: loss: 0.1411643
[Epoch 14; Iter    83/  229] train: loss: 0.1467237
[Epoch 14; Iter   113/  229] train: loss: 0.1963624
[Epoch 14; Iter   143/  229] train: loss: 0.1768944
[Epoch 14; Iter   173/  229] train: loss: 0.1755611
[Epoch 14; Iter   203/  229] train: loss: 0.1676237
[Epoch 14] ogbg-moltoxcast: 0.662835 val loss: 0.281995
[Epoch 14] ogbg-moltoxcast: 0.620810 test loss: 0.330087
[Epoch 15; Iter     4/  229] train: loss: 0.2972671
[Epoch 15; Iter    34/  229] train: loss: 0.1521979
[Epoch 15; Iter    64/  229] train: loss: 0.1259984
[Epoch 15; Iter    94/  229] train: loss: 0.2109447
[Epoch 15; Iter   124/  229] train: loss: 0.1576631
[Epoch 15; Iter   154/  229] train: loss: 0.2605869
[Epoch 15; Iter   184/  229] train: loss: 0.1927793
[Epoch 15; Iter   214/  229] train: loss: 0.1764513
[Epoch 15] ogbg-moltoxcast: 0.651444 val loss: 0.321884
[Epoch 15] ogbg-moltoxcast: 0.618750 test loss: 0.384731
[Epoch 16; Iter    15/  229] train: loss: 0.1296148
[Epoch 16; Iter    45/  229] train: loss: 0.1798413
[Epoch 16; Iter    75/  229] train: loss: 0.1615835
[Epoch 16; Iter   105/  229] train: loss: 0.2163305
[Epoch 16; Iter   135/  229] train: loss: 0.1146260
[Epoch 16; Iter   165/  229] train: loss: 0.1639072
[Epoch 16; Iter   195/  229] train: loss: 0.1996621
[Epoch 16; Iter   225/  229] train: loss: 0.1768374
[Epoch 16] ogbg-moltoxcast: 0.664105 val loss: 0.308358
[Epoch 16] ogbg-moltoxcast: 0.635067 test loss: 0.355752
[Epoch 17; Iter    26/  229] train: loss: 0.1242110
[Epoch 17; Iter    56/  229] train: loss: 0.1761014
[Epoch 17; Iter    86/  229] train: loss: 0.0941931
[Epoch 17; Iter   116/  229] train: loss: 0.1306829
[Epoch 17; Iter   146/  229] train: loss: 0.1970666
[Epoch 17; Iter   176/  229] train: loss: 0.1646844
[Epoch 17; Iter   206/  229] train: loss: 0.2023900
[Epoch 17] ogbg-moltoxcast: 0.641138 val loss: 0.381445
[Epoch 17] ogbg-moltoxcast: 0.628799 test loss: 0.452364
[Epoch 18; Iter     7/  229] train: loss: 0.1719429
[Epoch 18; Iter    37/  229] train: loss: 0.1742804
[Epoch 18; Iter    67/  229] train: loss: 0.1772222
[Epoch 18; Iter    97/  229] train: loss: 0.2682816
[Epoch 18; Iter   127/  229] train: loss: 0.1714138
[Epoch 18; Iter   157/  229] train: loss: 0.1992792
[Epoch 18; Iter   187/  229] train: loss: 0.2574780
[Epoch 18; Iter   217/  229] train: loss: 0.2041355
[Epoch 18] ogbg-moltoxcast: 0.644960 val loss: 0.507451
[Epoch 18] ogbg-moltoxcast: 0.625686 test loss: 0.645254
[Epoch 19; Iter    18/  229] train: loss: 0.1216453
[Epoch 19; Iter    48/  229] train: loss: 0.2269069
[Epoch 19; Iter    78/  229] train: loss: 0.2106793
[Epoch 19; Iter   108/  229] train: loss: 0.1761279
[Epoch 19; Iter   138/  229] train: loss: 0.1610979
[Epoch 19; Iter   168/  229] train: loss: 0.1440172
[Epoch 19; Iter   198/  229] train: loss: 0.2128620
[Epoch 19; Iter   228/  229] train: loss: 0.2761929
[Epoch 19] ogbg-moltoxcast: 0.667660 val loss: 0.320020
[Epoch 19] ogbg-moltoxcast: 0.635748 test loss: 0.379389
[Epoch 20; Iter    29/  229] train: loss: 0.1516888
[Epoch 20; Iter    59/  229] train: loss: 0.1379256
[Epoch 20; Iter    89/  229] train: loss: 0.2276843
[Epoch 20; Iter   119/  229] train: loss: 0.1232567
[Epoch 20; Iter   149/  229] train: loss: 0.2097828
[Epoch 20; Iter   179/  229] train: loss: 0.1540880
[Epoch 20; Iter   209/  229] train: loss: 0.1680335
[Epoch 20] ogbg-moltoxcast: 0.664402 val loss: 0.337051
[Epoch 20] ogbg-moltoxcast: 0.632946 test loss: 0.414078
[Epoch 21; Iter    10/  229] train: loss: 0.1891587
[Epoch 21; Iter    40/  229] train: loss: 0.1945385
[Epoch 21; Iter    70/  229] train: loss: 0.2145779
[Epoch 21; Iter   100/  229] train: loss: 0.1738123
[Epoch 21; Iter   130/  229] train: loss: 0.2011866
[Epoch 21; Iter   160/  229] train: loss: 0.1767203
[Epoch 21; Iter   190/  229] train: loss: 0.1931817
[Epoch 21; Iter   220/  229] train: loss: 0.1222686
[Epoch 21] ogbg-moltoxcast: 0.669140 val loss: 0.372703
[Epoch 21] ogbg-moltoxcast: 0.636780 test loss: 0.446316
[Epoch 22; Iter    21/  229] train: loss: 0.0932931
[Epoch 22; Iter    51/  229] train: loss: 0.2188348
[Epoch 22; Iter    81/  229] train: loss: 0.1180230
[Epoch 22; Iter   111/  229] train: loss: 0.1970972
[Epoch 22; Iter   141/  229] train: loss: 0.2606234
[Epoch 22; Iter   171/  229] train: loss: 0.1211239
[Epoch 22; Iter   201/  229] train: loss: 0.1693483
[Epoch 22] ogbg-moltoxcast: 0.665859 val loss: 0.350957
[Epoch 22] ogbg-moltoxcast: 0.640156 test loss: 0.405171
[Epoch 23; Iter     2/  229] train: loss: 0.2525724
[Epoch 23; Iter    32/  229] train: loss: 0.1091758
[Epoch 23; Iter    62/  229] train: loss: 0.1626497
[Epoch 23; Iter    92/  229] train: loss: 0.1541121
[Epoch 23; Iter   122/  229] train: loss: 0.1735188
[Epoch 23; Iter   152/  229] train: loss: 0.2795951
[Epoch 23; Iter   182/  229] train: loss: 0.1789339
[Epoch 23; Iter   212/  229] train: loss: 0.1360179
[Epoch 23] ogbg-moltoxcast: 0.674389 val loss: 0.296989
[Epoch 23] ogbg-moltoxcast: 0.637568 test loss: 0.358521
[Epoch 24; Iter    13/  229] train: loss: 0.1777014
[Epoch 24; Iter    43/  229] train: loss: 0.1546838
[Epoch 24; Iter    73/  229] train: loss: 0.1400046
[Epoch 24; Iter   103/  229] train: loss: 0.1494195
[Epoch 24; Iter   133/  229] train: loss: 0.2159219
[Epoch 24; Iter   163/  229] train: loss: 0.2350057
[Epoch 24; Iter   193/  229] train: loss: 0.1712638
[Epoch 24; Iter   223/  229] train: loss: 0.1862132
[Epoch 24] ogbg-moltoxcast: 0.647517 val loss: 3.129705
[Epoch 24] ogbg-moltoxcast: 0.627900 test loss: 2.220620
[Epoch 25; Iter    24/  229] train: loss: 0.2686190
[Epoch 25; Iter    54/  229] train: loss: 0.1955407
[Epoch 25; Iter    84/  229] train: loss: 0.2403231
[Epoch 25; Iter   114/  229] train: loss: 0.1875838
[Epoch 25; Iter   144/  229] train: loss: 0.1107472
[Epoch 25; Iter   174/  229] train: loss: 0.1407089
[Epoch 25; Iter   204/  229] train: loss: 0.1803697
[Epoch 25] ogbg-moltoxcast: 0.662039 val loss: 0.412855
[Epoch 25] ogbg-moltoxcast: 0.632580 test loss: 0.571018
[Epoch 26; Iter     5/  229] train: loss: 0.1409860
[Epoch 26; Iter    35/  229] train: loss: 0.2420095
[Epoch 26; Iter    65/  229] train: loss: 0.2257999
[Epoch 26; Iter    95/  229] train: loss: 0.1941488
[Epoch 26; Iter   125/  229] train: loss: 0.1456668
[Epoch 26; Iter   155/  229] train: loss: 0.1673532
[Epoch 26; Iter   185/  229] train: loss: 0.1658943
[Epoch 26; Iter   215/  229] train: loss: 0.1120212
[Epoch 26] ogbg-moltoxcast: 0.641216 val loss: 0.414348
[Epoch 26] ogbg-moltoxcast: 0.619318 test loss: 0.619721
[Epoch 27; Iter    16/  229] train: loss: 0.1701546
[Epoch 27; Iter    46/  229] train: loss: 0.1744682
[Epoch 27; Iter    76/  229] train: loss: 0.1453663
[Epoch 27; Iter   106/  229] train: loss: 0.1928393
[Epoch 27; Iter   136/  229] train: loss: 0.1848311
[Epoch 27; Iter   166/  229] train: loss: 0.1334471
[Epoch 27; Iter   196/  229] train: loss: 0.1358771
[Epoch 27; Iter   226/  229] train: loss: 0.1657069
[Epoch 27] ogbg-moltoxcast: 0.660422 val loss: 0.381620
[Epoch 27] ogbg-moltoxcast: 0.629203 test loss: 0.686980
[Epoch 12; Iter    31/  229] train: loss: 0.2283944
[Epoch 12; Iter    61/  229] train: loss: 0.1569232
[Epoch 12; Iter    91/  229] train: loss: 0.2138505
[Epoch 12; Iter   121/  229] train: loss: 0.2320195
[Epoch 12; Iter   151/  229] train: loss: 0.1244029
[Epoch 12; Iter   181/  229] train: loss: 0.2451066
[Epoch 12; Iter   211/  229] train: loss: 0.2058010
[Epoch 12] ogbg-moltoxcast: 0.649420 val loss: 0.328418
[Epoch 12] ogbg-moltoxcast: 0.611303 test loss: 0.421279
[Epoch 13; Iter    12/  229] train: loss: 0.1445842
[Epoch 13; Iter    42/  229] train: loss: 0.1351969
[Epoch 13; Iter    72/  229] train: loss: 0.1622049
[Epoch 13; Iter   102/  229] train: loss: 0.2576855
[Epoch 13; Iter   132/  229] train: loss: 0.2223527
[Epoch 13; Iter   162/  229] train: loss: 0.1829835
[Epoch 13; Iter   192/  229] train: loss: 0.1888032
[Epoch 13; Iter   222/  229] train: loss: 0.2232386
[Epoch 13] ogbg-moltoxcast: 0.642071 val loss: 0.281872
[Epoch 13] ogbg-moltoxcast: 0.619632 test loss: 0.317217
[Epoch 14; Iter    23/  229] train: loss: 0.1962391
[Epoch 14; Iter    53/  229] train: loss: 0.1979129
[Epoch 14; Iter    83/  229] train: loss: 0.2376053
[Epoch 14; Iter   113/  229] train: loss: 0.1924660
[Epoch 14; Iter   143/  229] train: loss: 0.1906053
[Epoch 14; Iter   173/  229] train: loss: 0.2254192
[Epoch 14; Iter   203/  229] train: loss: 0.1925574
[Epoch 14] ogbg-moltoxcast: 0.653559 val loss: 0.271674
[Epoch 14] ogbg-moltoxcast: 0.628851 test loss: 0.309235
[Epoch 15; Iter     4/  229] train: loss: 0.1710144
[Epoch 15; Iter    34/  229] train: loss: 0.1135866
[Epoch 15; Iter    64/  229] train: loss: 0.1835705
[Epoch 15; Iter    94/  229] train: loss: 0.2599534
[Epoch 15; Iter   124/  229] train: loss: 0.1682926
[Epoch 15; Iter   154/  229] train: loss: 0.1714309
[Epoch 15; Iter   184/  229] train: loss: 0.1668049
[Epoch 15; Iter   214/  229] train: loss: 0.2238240
[Epoch 15] ogbg-moltoxcast: 0.642966 val loss: 0.285172
[Epoch 15] ogbg-moltoxcast: 0.631944 test loss: 0.322803
[Epoch 16; Iter    15/  229] train: loss: 0.2723277
[Epoch 16; Iter    45/  229] train: loss: 0.1340064
[Epoch 16; Iter    75/  229] train: loss: 0.1240199
[Epoch 16; Iter   105/  229] train: loss: 0.1649765
[Epoch 16; Iter   135/  229] train: loss: 0.1633315
[Epoch 16; Iter   165/  229] train: loss: 0.2008213
[Epoch 16; Iter   195/  229] train: loss: 0.1961426
[Epoch 16; Iter   225/  229] train: loss: 0.1463172
[Epoch 16] ogbg-moltoxcast: 0.664411 val loss: 0.273155
[Epoch 16] ogbg-moltoxcast: 0.632267 test loss: 0.309009
[Epoch 17; Iter    26/  229] train: loss: 0.1660079
[Epoch 17; Iter    56/  229] train: loss: 0.2239329
[Epoch 17; Iter    86/  229] train: loss: 0.1375395
[Epoch 17; Iter   116/  229] train: loss: 0.1667254
[Epoch 17; Iter   146/  229] train: loss: 0.1896118
[Epoch 17; Iter   176/  229] train: loss: 0.2773900
[Epoch 17; Iter   206/  229] train: loss: 0.2174900
[Epoch 17] ogbg-moltoxcast: 0.663864 val loss: 0.285230
[Epoch 17] ogbg-moltoxcast: 0.641688 test loss: 0.318907
[Epoch 18; Iter     7/  229] train: loss: 0.1229753
[Epoch 18; Iter    37/  229] train: loss: 0.1765905
[Epoch 18; Iter    67/  229] train: loss: 0.1676554
[Epoch 18; Iter    97/  229] train: loss: 0.2905898
[Epoch 18; Iter   127/  229] train: loss: 0.1677177
[Epoch 18; Iter   157/  229] train: loss: 0.2065590
[Epoch 18; Iter   187/  229] train: loss: 0.1064487
[Epoch 18; Iter   217/  229] train: loss: 0.2208860
[Epoch 18] ogbg-moltoxcast: 0.672968 val loss: 0.276429
[Epoch 18] ogbg-moltoxcast: 0.634370 test loss: 0.312919
[Epoch 19; Iter    18/  229] train: loss: 0.2209015
[Epoch 19; Iter    48/  229] train: loss: 0.1763976
[Epoch 19; Iter    78/  229] train: loss: 0.1043341
[Epoch 19; Iter   108/  229] train: loss: 0.1653702
[Epoch 19; Iter   138/  229] train: loss: 0.1038678
[Epoch 19; Iter   168/  229] train: loss: 0.2123447
[Epoch 19; Iter   198/  229] train: loss: 0.1952148
[Epoch 19; Iter   228/  229] train: loss: 0.1450643
[Epoch 19] ogbg-moltoxcast: 0.657313 val loss: 0.301002
[Epoch 19] ogbg-moltoxcast: 0.634647 test loss: 0.323640
[Epoch 20; Iter    29/  229] train: loss: 0.1777699
[Epoch 20; Iter    59/  229] train: loss: 0.2131417
[Epoch 20; Iter    89/  229] train: loss: 0.1412284
[Epoch 20; Iter   119/  229] train: loss: 0.1696984
[Epoch 20; Iter   149/  229] train: loss: 0.2518092
[Epoch 20; Iter   179/  229] train: loss: 0.1095890
[Epoch 20; Iter   209/  229] train: loss: 0.1718437
[Epoch 20] ogbg-moltoxcast: 0.652546 val loss: 0.276156
[Epoch 20] ogbg-moltoxcast: 0.641239 test loss: 0.315027
[Epoch 21; Iter    10/  229] train: loss: 0.1824585
[Epoch 21; Iter    40/  229] train: loss: 0.1116444
[Epoch 21; Iter    70/  229] train: loss: 0.1966363
[Epoch 21; Iter   100/  229] train: loss: 0.2000476
[Epoch 21; Iter   130/  229] train: loss: 0.1985680
[Epoch 21; Iter   160/  229] train: loss: 0.2042455
[Epoch 21; Iter   190/  229] train: loss: 0.1539368
[Epoch 21; Iter   220/  229] train: loss: 0.2361398
[Epoch 21] ogbg-moltoxcast: 0.661107 val loss: 0.276502
[Epoch 21] ogbg-moltoxcast: 0.638035 test loss: 0.319439
[Epoch 22; Iter    21/  229] train: loss: 0.1542788
[Epoch 22; Iter    51/  229] train: loss: 0.1750598
[Epoch 22; Iter    81/  229] train: loss: 0.1550556
[Epoch 22; Iter   111/  229] train: loss: 0.2162233
[Epoch 22; Iter   141/  229] train: loss: 0.1497061
[Epoch 22; Iter   171/  229] train: loss: 0.1897726
[Epoch 22; Iter   201/  229] train: loss: 0.1538326
[Epoch 22] ogbg-moltoxcast: 0.659618 val loss: 0.295142
[Epoch 22] ogbg-moltoxcast: 0.627075 test loss: 0.334023
[Epoch 23; Iter     2/  229] train: loss: 0.1763935
[Epoch 23; Iter    32/  229] train: loss: 0.1296790
[Epoch 23; Iter    62/  229] train: loss: 0.0970316
[Epoch 23; Iter    92/  229] train: loss: 0.1129637
[Epoch 23; Iter   122/  229] train: loss: 0.1479081
[Epoch 23; Iter   152/  229] train: loss: 0.1004927
[Epoch 23; Iter   182/  229] train: loss: 0.1818642
[Epoch 23; Iter   212/  229] train: loss: 0.1911733
[Epoch 23] ogbg-moltoxcast: 0.660160 val loss: 0.280610
[Epoch 23] ogbg-moltoxcast: 0.641772 test loss: 0.317052
[Epoch 24; Iter    13/  229] train: loss: 0.1188990
[Epoch 24; Iter    43/  229] train: loss: 0.1927333
[Epoch 24; Iter    73/  229] train: loss: 0.1674349
[Epoch 24; Iter   103/  229] train: loss: 0.1854778
[Epoch 24; Iter   133/  229] train: loss: 0.2154837
[Epoch 24; Iter   163/  229] train: loss: 0.1734913
[Epoch 24; Iter   193/  229] train: loss: 0.1660129
[Epoch 24; Iter   223/  229] train: loss: 0.1267337
[Epoch 24] ogbg-moltoxcast: 0.658034 val loss: 0.287239
[Epoch 24] ogbg-moltoxcast: 0.636246 test loss: 0.330488
[Epoch 25; Iter    24/  229] train: loss: 0.1678908
[Epoch 25; Iter    54/  229] train: loss: 0.1703462
[Epoch 25; Iter    84/  229] train: loss: 0.1437279
[Epoch 25; Iter   114/  229] train: loss: 0.2516991
[Epoch 25; Iter   144/  229] train: loss: 0.1280549
[Epoch 25; Iter   174/  229] train: loss: 0.2058011
[Epoch 25; Iter   204/  229] train: loss: 0.1410850
[Epoch 25] ogbg-moltoxcast: 0.662582 val loss: 0.279627
[Epoch 25] ogbg-moltoxcast: 0.638525 test loss: 0.331387
[Epoch 26; Iter     5/  229] train: loss: 0.1521346
[Epoch 26; Iter    35/  229] train: loss: 0.1733295
[Epoch 26; Iter    65/  229] train: loss: 0.1113633
[Epoch 26; Iter    95/  229] train: loss: 0.1450215
[Epoch 26; Iter   125/  229] train: loss: 0.1654263
[Epoch 26; Iter   155/  229] train: loss: 0.1650685
[Epoch 26; Iter   185/  229] train: loss: 0.1452285
[Epoch 26; Iter   215/  229] train: loss: 0.1741923
[Epoch 26] ogbg-moltoxcast: 0.647330 val loss: 0.295911
[Epoch 26] ogbg-moltoxcast: 0.629812 test loss: 0.349237
[Epoch 27; Iter    16/  229] train: loss: 0.0817574
[Epoch 27; Iter    46/  229] train: loss: 0.1629244
[Epoch 27; Iter    76/  229] train: loss: 0.1408232
[Epoch 27; Iter   106/  229] train: loss: 0.1930177
[Epoch 27; Iter   136/  229] train: loss: 0.1546844
[Epoch 27; Iter   166/  229] train: loss: 0.2236300
[Epoch 27; Iter   196/  229] train: loss: 0.1887511
[Epoch 27; Iter   226/  229] train: loss: 0.1754526
[Epoch 27] ogbg-moltoxcast: 0.657760 val loss: 0.289790
[Epoch 27] ogbg-moltoxcast: 0.641162 test loss: 0.334219
[Epoch 12; Iter    31/  229] train: loss: 0.2031281
[Epoch 12; Iter    61/  229] train: loss: 0.1471766
[Epoch 12; Iter    91/  229] train: loss: 0.1920844
[Epoch 12; Iter   121/  229] train: loss: 0.2097706
[Epoch 12; Iter   151/  229] train: loss: 0.1225047
[Epoch 12; Iter   181/  229] train: loss: 0.2125894
[Epoch 12; Iter   211/  229] train: loss: 0.1899948
[Epoch 12] ogbg-moltoxcast: 0.686325 val loss: 0.250423
[Epoch 12] ogbg-moltoxcast: 0.652704 test loss: 0.290361
[Epoch 13; Iter    12/  229] train: loss: 0.1414850
[Epoch 13; Iter    42/  229] train: loss: 0.1331922
[Epoch 13; Iter    72/  229] train: loss: 0.1502374
[Epoch 13; Iter   102/  229] train: loss: 0.2535228
[Epoch 13; Iter   132/  229] train: loss: 0.1977923
[Epoch 13; Iter   162/  229] train: loss: 0.1461200
[Epoch 13; Iter   192/  229] train: loss: 0.1773746
[Epoch 13; Iter   222/  229] train: loss: 0.2143234
[Epoch 13] ogbg-moltoxcast: 0.671107 val loss: 0.267487
[Epoch 13] ogbg-moltoxcast: 0.638223 test loss: 0.312333
[Epoch 14; Iter    23/  229] train: loss: 0.1860651
[Epoch 14; Iter    53/  229] train: loss: 0.1954989
[Epoch 14; Iter    83/  229] train: loss: 0.2435721
[Epoch 14; Iter   113/  229] train: loss: 0.1685308
[Epoch 14; Iter   143/  229] train: loss: 0.1835873
[Epoch 14; Iter   173/  229] train: loss: 0.1954848
[Epoch 14; Iter   203/  229] train: loss: 0.1953439
[Epoch 14] ogbg-moltoxcast: 0.671789 val loss: 0.253585
[Epoch 14] ogbg-moltoxcast: 0.650863 test loss: 0.290018
[Epoch 15; Iter     4/  229] train: loss: 0.1972898
[Epoch 15; Iter    34/  229] train: loss: 0.1071968
[Epoch 15; Iter    64/  229] train: loss: 0.1467360
[Epoch 15; Iter    94/  229] train: loss: 0.2779123
[Epoch 15; Iter   124/  229] train: loss: 0.1454795
[Epoch 15; Iter   154/  229] train: loss: 0.1562332
[Epoch 15; Iter   184/  229] train: loss: 0.1535858
[Epoch 15; Iter   214/  229] train: loss: 0.2280031
[Epoch 15] ogbg-moltoxcast: 0.664409 val loss: 0.258796
[Epoch 15] ogbg-moltoxcast: 0.646099 test loss: 0.300706
[Epoch 16; Iter    15/  229] train: loss: 0.2621205
[Epoch 16; Iter    45/  229] train: loss: 0.1429835
[Epoch 16; Iter    75/  229] train: loss: 0.1283883
[Epoch 16; Iter   105/  229] train: loss: 0.1649528
[Epoch 16; Iter   135/  229] train: loss: 0.1660182
[Epoch 16; Iter   165/  229] train: loss: 0.1756967
[Epoch 16; Iter   195/  229] train: loss: 0.2203406
[Epoch 16; Iter   225/  229] train: loss: 0.1433184
[Epoch 16] ogbg-moltoxcast: 0.686647 val loss: 0.258550
[Epoch 16] ogbg-moltoxcast: 0.651018 test loss: 0.296055
[Epoch 17; Iter    26/  229] train: loss: 0.1644648
[Epoch 17; Iter    56/  229] train: loss: 0.1893532
[Epoch 17; Iter    86/  229] train: loss: 0.1661026
[Epoch 17; Iter   116/  229] train: loss: 0.2133585
[Epoch 17; Iter   146/  229] train: loss: 0.1732506
[Epoch 17; Iter   176/  229] train: loss: 0.2555714
[Epoch 17; Iter   206/  229] train: loss: 0.1918997
[Epoch 17] ogbg-moltoxcast: 0.663704 val loss: 0.256230
[Epoch 17] ogbg-moltoxcast: 0.659831 test loss: 0.290555
[Epoch 18; Iter     7/  229] train: loss: 0.1235988
[Epoch 18; Iter    37/  229] train: loss: 0.1733645
[Epoch 18; Iter    67/  229] train: loss: 0.1666220
[Epoch 18; Iter    97/  229] train: loss: 0.2662913
[Epoch 18; Iter   127/  229] train: loss: 0.1918034
[Epoch 18; Iter   157/  229] train: loss: 0.1628761
[Epoch 18; Iter   187/  229] train: loss: 0.1000528
[Epoch 18; Iter   217/  229] train: loss: 0.2255740
[Epoch 18] ogbg-moltoxcast: 0.681469 val loss: 0.252707
[Epoch 18] ogbg-moltoxcast: 0.650624 test loss: 0.299931
[Epoch 19; Iter    18/  229] train: loss: 0.2241743
[Epoch 19; Iter    48/  229] train: loss: 0.1799857
[Epoch 19; Iter    78/  229] train: loss: 0.0964426
[Epoch 19; Iter   108/  229] train: loss: 0.1543945
[Epoch 19; Iter   138/  229] train: loss: 0.1078008
[Epoch 19; Iter   168/  229] train: loss: 0.2119978
[Epoch 19; Iter   198/  229] train: loss: 0.2076660
[Epoch 19; Iter   228/  229] train: loss: 0.1527338
[Epoch 19] ogbg-moltoxcast: 0.688204 val loss: 0.261228
[Epoch 19] ogbg-moltoxcast: 0.650621 test loss: 0.316961
[Epoch 20; Iter    29/  229] train: loss: 0.1841306
[Epoch 20; Iter    59/  229] train: loss: 0.2238402
[Epoch 20; Iter    89/  229] train: loss: 0.1530993
[Epoch 20; Iter   119/  229] train: loss: 0.1550989
[Epoch 20; Iter   149/  229] train: loss: 0.2631868
[Epoch 20; Iter   179/  229] train: loss: 0.1067931
[Epoch 20; Iter   209/  229] train: loss: 0.1586499
[Epoch 20] ogbg-moltoxcast: 0.672676 val loss: 0.254327
[Epoch 20] ogbg-moltoxcast: 0.650180 test loss: 0.297033
[Epoch 21; Iter    10/  229] train: loss: 0.2034116
[Epoch 21; Iter    40/  229] train: loss: 0.1096021
[Epoch 21; Iter    70/  229] train: loss: 0.2052514
[Epoch 21; Iter   100/  229] train: loss: 0.2243803
[Epoch 21; Iter   130/  229] train: loss: 0.1872137
[Epoch 21; Iter   160/  229] train: loss: 0.1857046
[Epoch 21; Iter   190/  229] train: loss: 0.1382120
[Epoch 21; Iter   220/  229] train: loss: 0.1934041
[Epoch 21] ogbg-moltoxcast: 0.681606 val loss: 0.256393
[Epoch 21] ogbg-moltoxcast: 0.660652 test loss: 0.297870
[Epoch 22; Iter    21/  229] train: loss: 0.1609903
[Epoch 22; Iter    51/  229] train: loss: 0.1723742
[Epoch 22; Iter    81/  229] train: loss: 0.1641800
[Epoch 22; Iter   111/  229] train: loss: 0.2130216
[Epoch 22; Iter   141/  229] train: loss: 0.1608880
[Epoch 22; Iter   171/  229] train: loss: 0.1838827
[Epoch 22; Iter   201/  229] train: loss: 0.1494303
[Epoch 22] ogbg-moltoxcast: 0.692948 val loss: 0.246584
[Epoch 22] ogbg-moltoxcast: 0.654394 test loss: 0.292584
[Epoch 23; Iter     2/  229] train: loss: 0.1758936
[Epoch 23; Iter    32/  229] train: loss: 0.1222940
[Epoch 23; Iter    62/  229] train: loss: 0.0894228
[Epoch 23; Iter    92/  229] train: loss: 0.1092476
[Epoch 23; Iter   122/  229] train: loss: 0.1616814
[Epoch 23; Iter   152/  229] train: loss: 0.1065118
[Epoch 23; Iter   182/  229] train: loss: 0.1741840
[Epoch 23; Iter   212/  229] train: loss: 0.1956892
[Epoch 23] ogbg-moltoxcast: 0.685589 val loss: 0.248151
[Epoch 23] ogbg-moltoxcast: 0.661571 test loss: 0.291653
[Epoch 24; Iter    13/  229] train: loss: 0.1243139
[Epoch 24; Iter    43/  229] train: loss: 0.2081683
[Epoch 24; Iter    73/  229] train: loss: 0.1621563
[Epoch 24; Iter   103/  229] train: loss: 0.1812685
[Epoch 24; Iter   133/  229] train: loss: 0.2008556
[Epoch 24; Iter   163/  229] train: loss: 0.2031571
[Epoch 24; Iter   193/  229] train: loss: 0.1608237
[Epoch 24; Iter   223/  229] train: loss: 0.1303243
[Epoch 24] ogbg-moltoxcast: 0.694772 val loss: 0.249901
[Epoch 24] ogbg-moltoxcast: 0.663000 test loss: 0.293329
[Epoch 25; Iter    24/  229] train: loss: 0.1871662
[Epoch 25; Iter    54/  229] train: loss: 0.1833425
[Epoch 25; Iter    84/  229] train: loss: 0.1756150
[Epoch 25; Iter   114/  229] train: loss: 0.2920239
[Epoch 25; Iter   144/  229] train: loss: 0.1256569
[Epoch 25; Iter   174/  229] train: loss: 0.2040818
[Epoch 25; Iter   204/  229] train: loss: 0.1272948
[Epoch 25] ogbg-moltoxcast: 0.678285 val loss: 0.250861
[Epoch 25] ogbg-moltoxcast: 0.646854 test loss: 0.300108
[Epoch 26; Iter     5/  229] train: loss: 0.1445680
[Epoch 26; Iter    35/  229] train: loss: 0.1727083
[Epoch 26; Iter    65/  229] train: loss: 0.1363016
[Epoch 26; Iter    95/  229] train: loss: 0.1515927
[Epoch 26; Iter   125/  229] train: loss: 0.1593375
[Epoch 26; Iter   155/  229] train: loss: 0.1673769
[Epoch 26; Iter   185/  229] train: loss: 0.1607859
[Epoch 26; Iter   215/  229] train: loss: 0.1796100
[Epoch 26] ogbg-moltoxcast: 0.685968 val loss: 0.250851
[Epoch 26] ogbg-moltoxcast: 0.661590 test loss: 0.292664
[Epoch 27; Iter    16/  229] train: loss: 0.0794627
[Epoch 27; Iter    46/  229] train: loss: 0.1768448
[Epoch 27; Iter    76/  229] train: loss: 0.1290205
[Epoch 27; Iter   106/  229] train: loss: 0.1937108
[Epoch 27; Iter   136/  229] train: loss: 0.1687517
[Epoch 27; Iter   166/  229] train: loss: 0.2971437
[Epoch 27; Iter   196/  229] train: loss: 0.1950769
[Epoch 27; Iter   226/  229] train: loss: 0.1934619
[Epoch 27] ogbg-moltoxcast: 0.689831 val loss: 0.250736
[Epoch 27] ogbg-moltoxcast: 0.664529 test loss: 0.290499
[Epoch 12; Iter    31/  229] train: loss: 0.2080998
[Epoch 12; Iter    61/  229] train: loss: 0.1754972
[Epoch 12; Iter    91/  229] train: loss: 0.1588525
[Epoch 12; Iter   121/  229] train: loss: 0.3343519
[Epoch 12; Iter   151/  229] train: loss: 0.2134895
[Epoch 12; Iter   181/  229] train: loss: 0.2254194
[Epoch 12; Iter   211/  229] train: loss: 0.3303543
[Epoch 12] ogbg-moltoxcast: 0.638282 val loss: 0.269231
[Epoch 12] ogbg-moltoxcast: 0.614877 test loss: 0.306652
[Epoch 13; Iter    12/  229] train: loss: 0.2338797
[Epoch 13; Iter    42/  229] train: loss: 0.1896430
[Epoch 13; Iter    72/  229] train: loss: 0.2011543
[Epoch 13; Iter   102/  229] train: loss: 0.2187740
[Epoch 13; Iter   132/  229] train: loss: 0.1343291
[Epoch 13; Iter   162/  229] train: loss: 0.2382677
[Epoch 13; Iter   192/  229] train: loss: 0.1498409
[Epoch 13; Iter   222/  229] train: loss: 0.1869453
[Epoch 13] ogbg-moltoxcast: 0.677477 val loss: 0.252988
[Epoch 13] ogbg-moltoxcast: 0.622937 test loss: 0.303118
[Epoch 14; Iter    23/  229] train: loss: 0.1967467
[Epoch 14; Iter    53/  229] train: loss: 0.1439899
[Epoch 14; Iter    83/  229] train: loss: 0.1838527
[Epoch 14; Iter   113/  229] train: loss: 0.1431629
[Epoch 14; Iter   143/  229] train: loss: 0.2634815
[Epoch 14; Iter   173/  229] train: loss: 0.1305679
[Epoch 14; Iter   203/  229] train: loss: 0.1940115
[Epoch 14] ogbg-moltoxcast: 0.667502 val loss: 0.265423
[Epoch 14] ogbg-moltoxcast: 0.637832 test loss: 0.327665
[Epoch 15; Iter     4/  229] train: loss: 0.1647985
[Epoch 15; Iter    34/  229] train: loss: 0.2356035
[Epoch 15; Iter    64/  229] train: loss: 0.2041099
[Epoch 15; Iter    94/  229] train: loss: 0.1523726
[Epoch 15; Iter   124/  229] train: loss: 0.1380882
[Epoch 15; Iter   154/  229] train: loss: 0.1997935
[Epoch 15; Iter   184/  229] train: loss: 0.1773386
[Epoch 15; Iter   214/  229] train: loss: 0.1262966
[Epoch 15] ogbg-moltoxcast: 0.660432 val loss: 0.266416
[Epoch 15] ogbg-moltoxcast: 0.646706 test loss: 0.307855
[Epoch 16; Iter    15/  229] train: loss: 0.1986961
[Epoch 16; Iter    45/  229] train: loss: 0.1228503
[Epoch 16; Iter    75/  229] train: loss: 0.1731459
[Epoch 16; Iter   105/  229] train: loss: 0.1539764
[Epoch 16; Iter   135/  229] train: loss: 0.1828572
[Epoch 16; Iter   165/  229] train: loss: 0.1242533
[Epoch 16; Iter   195/  229] train: loss: 0.1556504
[Epoch 16; Iter   225/  229] train: loss: 0.2385768
[Epoch 16] ogbg-moltoxcast: 0.657208 val loss: 0.265919
[Epoch 16] ogbg-moltoxcast: 0.639020 test loss: 0.309037
[Epoch 17; Iter    26/  229] train: loss: 0.1704543
[Epoch 17; Iter    56/  229] train: loss: 0.1051925
[Epoch 17; Iter    86/  229] train: loss: 0.2293741
[Epoch 17; Iter   116/  229] train: loss: 0.2204001
[Epoch 17; Iter   146/  229] train: loss: 0.1685430
[Epoch 17; Iter   176/  229] train: loss: 0.2520857
[Epoch 17; Iter   206/  229] train: loss: 0.1424820
[Epoch 17] ogbg-moltoxcast: 0.675543 val loss: 0.255897
[Epoch 17] ogbg-moltoxcast: 0.641731 test loss: 0.427366
[Epoch 18; Iter     7/  229] train: loss: 0.1727945
[Epoch 18; Iter    37/  229] train: loss: 0.2088410
[Epoch 18; Iter    67/  229] train: loss: 0.1716194
[Epoch 18; Iter    97/  229] train: loss: 0.1422277
[Epoch 18; Iter   127/  229] train: loss: 0.1853539
[Epoch 18; Iter   157/  229] train: loss: 0.1777355
[Epoch 18; Iter   187/  229] train: loss: 0.1832815
[Epoch 18; Iter   217/  229] train: loss: 0.2452006
[Epoch 18] ogbg-moltoxcast: 0.667970 val loss: 0.251713
[Epoch 18] ogbg-moltoxcast: 0.644340 test loss: 0.300040
[Epoch 19; Iter    18/  229] train: loss: 0.1037812
[Epoch 19; Iter    48/  229] train: loss: 0.2299693
[Epoch 19; Iter    78/  229] train: loss: 0.1431653
[Epoch 19; Iter   108/  229] train: loss: 0.1578903
[Epoch 19; Iter   138/  229] train: loss: 0.1875356
[Epoch 19; Iter   168/  229] train: loss: 0.2497108
[Epoch 19; Iter   198/  229] train: loss: 0.1594004
[Epoch 19; Iter   228/  229] train: loss: 0.1786383
[Epoch 19] ogbg-moltoxcast: 0.681935 val loss: 0.253997
[Epoch 19] ogbg-moltoxcast: 0.646396 test loss: 0.319444
[Epoch 20; Iter    29/  229] train: loss: 0.1331606
[Epoch 20; Iter    59/  229] train: loss: 0.1588251
[Epoch 20; Iter    89/  229] train: loss: 0.2045101
[Epoch 20; Iter   119/  229] train: loss: 0.1259958
[Epoch 20; Iter   149/  229] train: loss: 0.2248960
[Epoch 20; Iter   179/  229] train: loss: 0.1888027
[Epoch 20; Iter   209/  229] train: loss: 0.1474017
[Epoch 20] ogbg-moltoxcast: 0.680366 val loss: 0.252502
[Epoch 20] ogbg-moltoxcast: 0.647769 test loss: 0.297535
[Epoch 21; Iter    10/  229] train: loss: 0.2031668
[Epoch 21; Iter    40/  229] train: loss: 0.1386229
[Epoch 21; Iter    70/  229] train: loss: 0.2046186
[Epoch 21; Iter   100/  229] train: loss: 0.1553094
[Epoch 21; Iter   130/  229] train: loss: 0.1917966
[Epoch 21; Iter   160/  229] train: loss: 0.1798319
[Epoch 21; Iter   190/  229] train: loss: 0.2009224
[Epoch 21; Iter   220/  229] train: loss: 0.1501229
[Epoch 21] ogbg-moltoxcast: 0.691472 val loss: 0.245858
[Epoch 21] ogbg-moltoxcast: 0.660199 test loss: 0.286703
[Epoch 22; Iter    21/  229] train: loss: 0.1029318
[Epoch 22; Iter    51/  229] train: loss: 0.2163651
[Epoch 22; Iter    81/  229] train: loss: 0.1331507
[Epoch 22; Iter   111/  229] train: loss: 0.2032978
[Epoch 22; Iter   141/  229] train: loss: 0.1590571
[Epoch 22; Iter   171/  229] train: loss: 0.2055008
[Epoch 22; Iter   201/  229] train: loss: 0.1359323
[Epoch 22] ogbg-moltoxcast: 0.677290 val loss: 0.249121
[Epoch 22] ogbg-moltoxcast: 0.657873 test loss: 0.287130
[Epoch 23; Iter     2/  229] train: loss: 0.1415881
[Epoch 23; Iter    32/  229] train: loss: 0.1556800
[Epoch 23; Iter    62/  229] train: loss: 0.1493983
[Epoch 23; Iter    92/  229] train: loss: 0.1250805
[Epoch 23; Iter   122/  229] train: loss: 0.1492372
[Epoch 23; Iter   152/  229] train: loss: 0.2418284
[Epoch 23; Iter   182/  229] train: loss: 0.1677327
[Epoch 23; Iter   212/  229] train: loss: 0.1364862
[Epoch 23] ogbg-moltoxcast: 0.682496 val loss: 0.259285
[Epoch 23] ogbg-moltoxcast: 0.656725 test loss: 0.301605
[Epoch 24; Iter    13/  229] train: loss: 0.1235118
[Epoch 24; Iter    43/  229] train: loss: 0.1952555
[Epoch 24; Iter    73/  229] train: loss: 0.1171175
[Epoch 24; Iter   103/  229] train: loss: 0.2572977
[Epoch 24; Iter   133/  229] train: loss: 0.1261259
[Epoch 24; Iter   163/  229] train: loss: 0.1383492
[Epoch 24; Iter   193/  229] train: loss: 0.1990776
[Epoch 24; Iter   223/  229] train: loss: 0.1363334
[Epoch 24] ogbg-moltoxcast: 0.680667 val loss: 0.256320
[Epoch 24] ogbg-moltoxcast: 0.660891 test loss: 0.300389
[Epoch 25; Iter    24/  229] train: loss: 0.1091809
[Epoch 25; Iter    54/  229] train: loss: 0.1095771
[Epoch 25; Iter    84/  229] train: loss: 0.1409508
[Epoch 25; Iter   114/  229] train: loss: 0.2294924
[Epoch 25; Iter   144/  229] train: loss: 0.1784180
[Epoch 25; Iter   174/  229] train: loss: 0.1422440
[Epoch 25; Iter   204/  229] train: loss: 0.1330562
[Epoch 25] ogbg-moltoxcast: 0.672448 val loss: 0.252057
[Epoch 25] ogbg-moltoxcast: 0.655930 test loss: 0.296026
[Epoch 26; Iter     5/  229] train: loss: 0.1612006
[Epoch 26; Iter    35/  229] train: loss: 0.1668557
[Epoch 26; Iter    65/  229] train: loss: 0.1828091
[Epoch 26; Iter    95/  229] train: loss: 0.1905977
[Epoch 26; Iter   125/  229] train: loss: 0.2004853
[Epoch 26; Iter   155/  229] train: loss: 0.1535290
[Epoch 26; Iter   185/  229] train: loss: 0.1164474
[Epoch 26; Iter   215/  229] train: loss: 0.1545770
[Epoch 26] ogbg-moltoxcast: 0.674547 val loss: 0.259272
[Epoch 26] ogbg-moltoxcast: 0.656683 test loss: 0.300069
[Epoch 27; Iter    16/  229] train: loss: 0.1272108
[Epoch 27; Iter    46/  229] train: loss: 0.1575035
[Epoch 27; Iter    76/  229] train: loss: 0.1481263
[Epoch 27; Iter   106/  229] train: loss: 0.0883177
[Epoch 27; Iter   136/  229] train: loss: 0.1813634
[Epoch 27; Iter   166/  229] train: loss: 0.1590221
[Epoch 27; Iter   196/  229] train: loss: 0.2088019
[Epoch 27; Iter   226/  229] train: loss: 0.1353835
[Epoch 27] ogbg-moltoxcast: 0.672392 val loss: 0.296909
[Epoch 27] ogbg-moltoxcast: 0.669750 test loss: 0.293892
[Epoch 12; Iter    31/  229] train: loss: 0.2377868
[Epoch 12; Iter    61/  229] train: loss: 0.2557354
[Epoch 12; Iter    91/  229] train: loss: 0.1506346
[Epoch 12; Iter   121/  229] train: loss: 0.1301379
[Epoch 12; Iter   151/  229] train: loss: 0.1629375
[Epoch 12; Iter   181/  229] train: loss: 0.2041616
[Epoch 12; Iter   211/  229] train: loss: 0.1397375
[Epoch 12] ogbg-moltoxcast: 0.670327 val loss: 0.264262
[Epoch 12] ogbg-moltoxcast: 0.646625 test loss: 0.302084
[Epoch 13; Iter    12/  229] train: loss: 0.1851023
[Epoch 13; Iter    42/  229] train: loss: 0.1906956
[Epoch 13; Iter    72/  229] train: loss: 0.1965116
[Epoch 13; Iter   102/  229] train: loss: 0.2033323
[Epoch 13; Iter   132/  229] train: loss: 0.2060351
[Epoch 13; Iter   162/  229] train: loss: 0.2093815
[Epoch 13; Iter   192/  229] train: loss: 0.2028843
[Epoch 13; Iter   222/  229] train: loss: 0.1479542
[Epoch 13] ogbg-moltoxcast: 0.675697 val loss: 0.255000
[Epoch 13] ogbg-moltoxcast: 0.633107 test loss: 0.293044
[Epoch 14; Iter    23/  229] train: loss: 0.2929289
[Epoch 14; Iter    53/  229] train: loss: 0.1499250
[Epoch 14; Iter    83/  229] train: loss: 0.1666876
[Epoch 14; Iter   113/  229] train: loss: 0.1813167
[Epoch 14; Iter   143/  229] train: loss: 0.1689522
[Epoch 14; Iter   173/  229] train: loss: 0.1585731
[Epoch 14; Iter   203/  229] train: loss: 0.1730179
[Epoch 14] ogbg-moltoxcast: 0.660476 val loss: 0.276127
[Epoch 14] ogbg-moltoxcast: 0.628526 test loss: 0.299183
[Epoch 15; Iter     4/  229] train: loss: 0.2877989
[Epoch 15; Iter    34/  229] train: loss: 0.1604621
[Epoch 15; Iter    64/  229] train: loss: 0.1235311
[Epoch 15; Iter    94/  229] train: loss: 0.2106937
[Epoch 15; Iter   124/  229] train: loss: 0.1564271
[Epoch 15; Iter   154/  229] train: loss: 0.2847158
[Epoch 15; Iter   184/  229] train: loss: 0.1904436
[Epoch 15; Iter   214/  229] train: loss: 0.1663140
[Epoch 15] ogbg-moltoxcast: 0.679583 val loss: 0.255443
[Epoch 15] ogbg-moltoxcast: 0.638748 test loss: 0.297396
[Epoch 16; Iter    15/  229] train: loss: 0.1287847
[Epoch 16; Iter    45/  229] train: loss: 0.2178437
[Epoch 16; Iter    75/  229] train: loss: 0.1689377
[Epoch 16; Iter   105/  229] train: loss: 0.2265918
[Epoch 16; Iter   135/  229] train: loss: 0.1322136
[Epoch 16; Iter   165/  229] train: loss: 0.1681122
[Epoch 16; Iter   195/  229] train: loss: 0.2111669
[Epoch 16; Iter   225/  229] train: loss: 0.1596265
[Epoch 16] ogbg-moltoxcast: 0.690708 val loss: 0.255590
[Epoch 16] ogbg-moltoxcast: 0.646017 test loss: 0.295528
[Epoch 17; Iter    26/  229] train: loss: 0.1277740
[Epoch 17; Iter    56/  229] train: loss: 0.1766459
[Epoch 17; Iter    86/  229] train: loss: 0.0968527
[Epoch 17; Iter   116/  229] train: loss: 0.1174762
[Epoch 17; Iter   146/  229] train: loss: 0.2103632
[Epoch 17; Iter   176/  229] train: loss: 0.1515434
[Epoch 17; Iter   206/  229] train: loss: 0.2067869
[Epoch 17] ogbg-moltoxcast: 0.609333 val loss: 0.378546
[Epoch 17] ogbg-moltoxcast: 0.565228 test loss: 0.629970
[Epoch 18; Iter     7/  229] train: loss: 0.1891208
[Epoch 18; Iter    37/  229] train: loss: 0.2003352
[Epoch 18; Iter    67/  229] train: loss: 0.2107930
[Epoch 18; Iter    97/  229] train: loss: 0.2661667
[Epoch 18; Iter   127/  229] train: loss: 0.1650536
[Epoch 18; Iter   157/  229] train: loss: 0.2353187
[Epoch 18; Iter   187/  229] train: loss: 0.2580735
[Epoch 18; Iter   217/  229] train: loss: 0.2327969
[Epoch 18] ogbg-moltoxcast: 0.682002 val loss: 0.255424
[Epoch 18] ogbg-moltoxcast: 0.648500 test loss: 0.292553
[Epoch 19; Iter    18/  229] train: loss: 0.1371127
[Epoch 19; Iter    48/  229] train: loss: 0.2220632
[Epoch 19; Iter    78/  229] train: loss: 0.2043255
[Epoch 19; Iter   108/  229] train: loss: 0.1776321
[Epoch 19; Iter   138/  229] train: loss: 0.1685790
[Epoch 19; Iter   168/  229] train: loss: 0.1633839
[Epoch 19; Iter   198/  229] train: loss: 0.2512575
[Epoch 19; Iter   228/  229] train: loss: 0.2722705
[Epoch 19] ogbg-moltoxcast: 0.679583 val loss: 0.260174
[Epoch 19] ogbg-moltoxcast: 0.637169 test loss: 0.313547
[Epoch 20; Iter    29/  229] train: loss: 0.1657472
[Epoch 20; Iter    59/  229] train: loss: 0.1335063
[Epoch 20; Iter    89/  229] train: loss: 0.2879204
[Epoch 20; Iter   119/  229] train: loss: 0.1332593
[Epoch 20; Iter   149/  229] train: loss: 0.2368798
[Epoch 20; Iter   179/  229] train: loss: 0.1668952
[Epoch 20; Iter   209/  229] train: loss: 0.1753789
[Epoch 20] ogbg-moltoxcast: 0.677861 val loss: 0.256620
[Epoch 20] ogbg-moltoxcast: 0.645787 test loss: 0.295353
[Epoch 21; Iter    10/  229] train: loss: 0.2059031
[Epoch 21; Iter    40/  229] train: loss: 0.1939177
[Epoch 21; Iter    70/  229] train: loss: 0.2280847
[Epoch 21; Iter   100/  229] train: loss: 0.1969553
[Epoch 21; Iter   130/  229] train: loss: 0.2041582
[Epoch 21; Iter   160/  229] train: loss: 0.2065812
[Epoch 21; Iter   190/  229] train: loss: 0.2014977
[Epoch 21; Iter   220/  229] train: loss: 0.1279668
[Epoch 21] ogbg-moltoxcast: 0.681650 val loss: 0.258554
[Epoch 21] ogbg-moltoxcast: 0.655214 test loss: 0.306824
[Epoch 22; Iter    21/  229] train: loss: 0.1076029
[Epoch 22; Iter    51/  229] train: loss: 0.1888464
[Epoch 22; Iter    81/  229] train: loss: 0.1123175
[Epoch 22; Iter   111/  229] train: loss: 0.2026468
[Epoch 22; Iter   141/  229] train: loss: 0.2517104
[Epoch 22; Iter   171/  229] train: loss: 0.1355799
[Epoch 22; Iter   201/  229] train: loss: 0.1713320
[Epoch 22] ogbg-moltoxcast: 0.682742 val loss: 0.251589
[Epoch 22] ogbg-moltoxcast: 0.654617 test loss: 0.295078
[Epoch 23; Iter     2/  229] train: loss: 0.2605505
[Epoch 23; Iter    32/  229] train: loss: 0.1428876
[Epoch 23; Iter    62/  229] train: loss: 0.1833377
[Epoch 23; Iter    92/  229] train: loss: 0.1475391
[Epoch 23; Iter   122/  229] train: loss: 0.1668058
[Epoch 23; Iter   152/  229] train: loss: 0.2721044
[Epoch 23; Iter   182/  229] train: loss: 0.1979425
[Epoch 23; Iter   212/  229] train: loss: 0.1533815
[Epoch 23] ogbg-moltoxcast: 0.693855 val loss: 0.247179
[Epoch 23] ogbg-moltoxcast: 0.650376 test loss: 0.288043
[Epoch 24; Iter    13/  229] train: loss: 0.1966377
[Epoch 24; Iter    43/  229] train: loss: 0.1568727
[Epoch 24; Iter    73/  229] train: loss: 0.1260994
[Epoch 24; Iter   103/  229] train: loss: 0.1335177
[Epoch 24; Iter   133/  229] train: loss: 0.2153109
[Epoch 24; Iter   163/  229] train: loss: 0.2192419
[Epoch 24; Iter   193/  229] train: loss: 0.1403451
[Epoch 24; Iter   223/  229] train: loss: 0.1685826
[Epoch 24] ogbg-moltoxcast: 0.694109 val loss: 0.249843
[Epoch 24] ogbg-moltoxcast: 0.652107 test loss: 0.288634
[Epoch 25; Iter    24/  229] train: loss: 0.2330799
[Epoch 25; Iter    54/  229] train: loss: 0.1792842
[Epoch 25; Iter    84/  229] train: loss: 0.2207408
[Epoch 25; Iter   114/  229] train: loss: 0.1886011
[Epoch 25; Iter   144/  229] train: loss: 0.1109354
[Epoch 25; Iter   174/  229] train: loss: 0.1440826
[Epoch 25; Iter   204/  229] train: loss: 0.1668478
[Epoch 25] ogbg-moltoxcast: 0.691969 val loss: 0.244713
[Epoch 25] ogbg-moltoxcast: 0.655077 test loss: 0.293490
[Epoch 26; Iter     5/  229] train: loss: 0.1438958
[Epoch 26; Iter    35/  229] train: loss: 0.2462792
[Epoch 26; Iter    65/  229] train: loss: 0.1972957
[Epoch 26; Iter    95/  229] train: loss: 0.1922986
[Epoch 26; Iter   125/  229] train: loss: 0.1533164
[Epoch 26; Iter   155/  229] train: loss: 0.1594002
[Epoch 26; Iter   185/  229] train: loss: 0.1657465
[Epoch 26; Iter   215/  229] train: loss: 0.1244173
[Epoch 26] ogbg-moltoxcast: 0.688174 val loss: 0.278261
[Epoch 26] ogbg-moltoxcast: 0.646877 test loss: 0.313378
[Epoch 27; Iter    16/  229] train: loss: 0.1732586
[Epoch 27; Iter    46/  229] train: loss: 0.1700571
[Epoch 27; Iter    76/  229] train: loss: 0.1382737
[Epoch 27; Iter   106/  229] train: loss: 0.2069728
[Epoch 27; Iter   136/  229] train: loss: 0.1889166
[Epoch 27; Iter   166/  229] train: loss: 0.1384098
[Epoch 27; Iter   196/  229] train: loss: 0.1351777
[Epoch 27; Iter   226/  229] train: loss: 0.1704977
[Epoch 27] ogbg-moltoxcast: 0.689062 val loss: 0.251617
[Epoch 27] ogbg-moltoxcast: 0.652961 test loss: 0.297738
[Epoch 28; Iter    27/  229] train: loss: 0.1738202
[Epoch 28; Iter    57/  229] train: loss: 0.1591110
[Epoch 28; Iter    87/  229] train: loss: 0.1623385
[Epoch 28; Iter   117/  229] train: loss: 0.1808612
[Epoch 28; Iter   147/  229] train: loss: 0.1704494
[Epoch 28; Iter   177/  229] train: loss: 0.1408944
[Epoch 28; Iter   207/  229] train: loss: 0.1744946
[Epoch 28] ogbg-moltoxcast: 0.699324 val loss: 0.281176
[Epoch 28] ogbg-moltoxcast: 0.664928 test loss: 0.305716
[Epoch 29; Iter     8/  229] train: loss: 0.1038097
[Epoch 29; Iter    38/  229] train: loss: 0.1189896
[Epoch 29; Iter    68/  229] train: loss: 0.1242507
[Epoch 29; Iter    98/  229] train: loss: 0.2049479
[Epoch 29; Iter   128/  229] train: loss: 0.1449968
[Epoch 29; Iter   158/  229] train: loss: 0.0961313
[Epoch 29; Iter   188/  229] train: loss: 0.1440591
[Epoch 29; Iter   218/  229] train: loss: 0.1373162
[Epoch 29] ogbg-moltoxcast: 0.681748 val loss: 0.274026
[Epoch 29] ogbg-moltoxcast: 0.649616 test loss: 0.320963
[Epoch 30; Iter    19/  229] train: loss: 0.1378317
[Epoch 30; Iter    49/  229] train: loss: 0.1872425
[Epoch 30; Iter    79/  229] train: loss: 0.1107762
[Epoch 30; Iter   109/  229] train: loss: 0.1842169
[Epoch 30; Iter   139/  229] train: loss: 0.1653235
[Epoch 30; Iter   169/  229] train: loss: 0.1756967
[Epoch 30; Iter   199/  229] train: loss: 0.1479332
[Epoch 30; Iter   229/  229] train: loss: 0.1847976
[Epoch 30] ogbg-moltoxcast: 0.694453 val loss: 0.278186
[Epoch 30] ogbg-moltoxcast: 0.658073 test loss: 0.330252
[Epoch 31; Iter    30/  229] train: loss: 0.1991649
[Epoch 31; Iter    60/  229] train: loss: 0.1795911
[Epoch 31; Iter    90/  229] train: loss: 0.1582433
[Epoch 31; Iter   120/  229] train: loss: 0.1593304
[Epoch 31; Iter   150/  229] train: loss: 0.1570101
[Epoch 31; Iter   180/  229] train: loss: 0.2413632
[Epoch 31; Iter   210/  229] train: loss: 0.1386020
[Epoch 31] ogbg-moltoxcast: 0.697705 val loss: 0.276828
[Epoch 31] ogbg-moltoxcast: 0.665266 test loss: 0.311012
[Epoch 32; Iter    11/  229] train: loss: 0.1461063
[Epoch 32; Iter    41/  229] train: loss: 0.1318514
[Epoch 32; Iter    71/  229] train: loss: 0.1609946
[Epoch 32; Iter   101/  229] train: loss: 0.1932281
[Epoch 32; Iter   131/  229] train: loss: 0.1078405
[Epoch 32; Iter   161/  229] train: loss: 0.1430836
[Epoch 32; Iter   191/  229] train: loss: 0.0992596
[Epoch 32; Iter   221/  229] train: loss: 0.1421115
[Epoch 32] ogbg-moltoxcast: 0.697649 val loss: 0.271353
[Epoch 32] ogbg-moltoxcast: 0.669210 test loss: 0.303524
[Epoch 33; Iter    22/  229] train: loss: 0.1146912
[Epoch 33; Iter    52/  229] train: loss: 0.1178275
[Epoch 33; Iter    82/  229] train: loss: 0.1350912
[Epoch 33; Iter   112/  229] train: loss: 0.1971505
[Epoch 33; Iter   142/  229] train: loss: 0.1127557
[Epoch 33; Iter   172/  229] train: loss: 0.1596584
[Epoch 33; Iter   202/  229] train: loss: 0.1035754
[Epoch 33] ogbg-moltoxcast: 0.705023 val loss: 0.278763
[Epoch 33] ogbg-moltoxcast: 0.665517 test loss: 0.318710
[Epoch 34; Iter     3/  229] train: loss: 0.1838958
[Epoch 34; Iter    33/  229] train: loss: 0.1537656
[Epoch 34; Iter    63/  229] train: loss: 0.1532267
[Epoch 34; Iter    93/  229] train: loss: 0.1591596
[Epoch 34; Iter   123/  229] train: loss: 0.1398292
[Epoch 34; Iter   153/  229] train: loss: 0.1273140
[Epoch 34; Iter   183/  229] train: loss: 0.1213460
[Epoch 34; Iter   213/  229] train: loss: 0.2013323
[Epoch 34] ogbg-moltoxcast: 0.692808 val loss: 0.272017
[Epoch 34] ogbg-moltoxcast: 0.658748 test loss: 0.307468
[Epoch 35; Iter    14/  229] train: loss: 0.0761706
[Epoch 35; Iter    44/  229] train: loss: 0.1526879
[Epoch 35; Iter    74/  229] train: loss: 0.1340466
[Epoch 35; Iter   104/  229] train: loss: 0.1778290
[Epoch 35; Iter   134/  229] train: loss: 0.1840450
[Epoch 35; Iter   164/  229] train: loss: 0.1545105
[Epoch 35; Iter   194/  229] train: loss: 0.1288845
[Epoch 35; Iter   224/  229] train: loss: 0.1193276
[Epoch 35] ogbg-moltoxcast: 0.697095 val loss: 0.265765
[Epoch 35] ogbg-moltoxcast: 0.660187 test loss: 0.311421
[Epoch 36; Iter    25/  229] train: loss: 0.1578424
[Epoch 36; Iter    55/  229] train: loss: 0.1626486
[Epoch 36; Iter    85/  229] train: loss: 0.1323264
[Epoch 36; Iter   115/  229] train: loss: 0.1134928
[Epoch 36; Iter   145/  229] train: loss: 0.1562211
[Epoch 36; Iter   175/  229] train: loss: 0.1720972
[Epoch 36; Iter   205/  229] train: loss: 0.1771966
[Epoch 36] ogbg-moltoxcast: 0.696148 val loss: 0.267161
[Epoch 36] ogbg-moltoxcast: 0.663718 test loss: 0.305711
[Epoch 37; Iter     6/  229] train: loss: 0.1149135
[Epoch 37; Iter    36/  229] train: loss: 0.0931439
[Epoch 37; Iter    66/  229] train: loss: 0.1368639
[Epoch 37; Iter    96/  229] train: loss: 0.1331611
[Epoch 37; Iter   126/  229] train: loss: 0.1245929
[Epoch 37; Iter   156/  229] train: loss: 0.1305421
[Epoch 37; Iter   186/  229] train: loss: 0.1322541
[Epoch 37; Iter   216/  229] train: loss: 0.1497452
[Epoch 37] ogbg-moltoxcast: 0.700404 val loss: 0.263271
[Epoch 37] ogbg-moltoxcast: 0.668495 test loss: 0.305069
[Epoch 38; Iter    17/  229] train: loss: 0.1722283
[Epoch 38; Iter    47/  229] train: loss: 0.1441468
[Epoch 38; Iter    77/  229] train: loss: 0.1179885
[Epoch 38; Iter   107/  229] train: loss: 0.1330942
[Epoch 38; Iter   137/  229] train: loss: 0.1610813
[Epoch 38; Iter   167/  229] train: loss: 0.1432942
[Epoch 38; Iter   197/  229] train: loss: 0.1533738
[Epoch 38; Iter   227/  229] train: loss: 0.1597328
[Epoch 38] ogbg-moltoxcast: 0.694820 val loss: 0.276201
[Epoch 38] ogbg-moltoxcast: 0.668803 test loss: 0.311789
[Epoch 39; Iter    28/  229] train: loss: 0.1812472
[Epoch 39; Iter    58/  229] train: loss: 0.1064043
[Epoch 39; Iter    88/  229] train: loss: 0.1132742
[Epoch 39; Iter   118/  229] train: loss: 0.2281110
[Epoch 39; Iter   148/  229] train: loss: 0.1369898
[Epoch 39; Iter   178/  229] train: loss: 0.1625030
[Epoch 39; Iter   208/  229] train: loss: 0.1871195
[Epoch 39] ogbg-moltoxcast: 0.698041 val loss: 0.264150
[Epoch 39] ogbg-moltoxcast: 0.661998 test loss: 0.308110
[Epoch 40; Iter     9/  229] train: loss: 0.1414125
[Epoch 40; Iter    39/  229] train: loss: 0.1124488
[Epoch 40; Iter    69/  229] train: loss: 0.1116218
[Epoch 40; Iter    99/  229] train: loss: 0.1703121
[Epoch 40; Iter   129/  229] train: loss: 0.1268173
[Epoch 40; Iter   159/  229] train: loss: 0.1240896
[Epoch 40; Iter   189/  229] train: loss: 0.1448903
[Epoch 40; Iter   219/  229] train: loss: 0.1947477
[Epoch 40] ogbg-moltoxcast: 0.696703 val loss: 0.286282
[Epoch 40] ogbg-moltoxcast: 0.661092 test loss: 0.319341
[Epoch 41; Iter    20/  229] train: loss: 0.1438625
[Epoch 41; Iter    50/  229] train: loss: 0.1158767
[Epoch 41; Iter    80/  229] train: loss: 0.0905085
[Epoch 41; Iter   110/  229] train: loss: 0.1020727
[Epoch 41; Iter   140/  229] train: loss: 0.1060347
[Epoch 41; Iter   170/  229] train: loss: 0.1039154
[Epoch 41; Iter   200/  229] train: loss: 0.1594706
[Epoch 41] ogbg-moltoxcast: 0.700417 val loss: 0.273670
[Epoch 41] ogbg-moltoxcast: 0.667902 test loss: 0.315533
[Epoch 42; Iter     1/  229] train: loss: 0.1610806
[Epoch 42; Iter    31/  229] train: loss: 0.1379879
[Epoch 42; Iter    61/  229] train: loss: 0.1719127
[Epoch 42; Iter    91/  229] train: loss: 0.1152359
[Epoch 42; Iter   121/  229] train: loss: 0.1613212
[Epoch 42; Iter   151/  229] train: loss: 0.1185857
[Epoch 42; Iter   181/  229] train: loss: 0.1428799
[Epoch 42; Iter   211/  229] train: loss: 0.1458027
[Epoch 42] ogbg-moltoxcast: 0.696197 val loss: 0.273317
[Epoch 42] ogbg-moltoxcast: 0.658431 test loss: 0.313558
[Epoch 43; Iter    12/  229] train: loss: 0.1685652
[Epoch 43; Iter    42/  229] train: loss: 0.1632578
[Epoch 43; Iter    72/  229] train: loss: 0.1582638
[Epoch 43; Iter   102/  229] train: loss: 0.1517729
[Epoch 43; Iter   132/  229] train: loss: 0.1123151
[Epoch 43; Iter   162/  229] train: loss: 0.1588600
[Epoch 43; Iter   192/  229] train: loss: 0.1008564
[Epoch 43; Iter   222/  229] train: loss: 0.1370981
[Epoch 43] ogbg-moltoxcast: 0.695378 val loss: 0.277965
[Epoch 43] ogbg-moltoxcast: 0.666835 test loss: 0.319542
[Epoch 28; Iter    27/  229] train: loss: 0.1898807
[Epoch 28; Iter    57/  229] train: loss: 0.1863299
[Epoch 28; Iter    87/  229] train: loss: 0.1540752
[Epoch 28; Iter   117/  229] train: loss: 0.2477315
[Epoch 28; Iter   147/  229] train: loss: 0.1443676
[Epoch 28; Iter   177/  229] train: loss: 0.1450607
[Epoch 28; Iter   207/  229] train: loss: 0.1941823
[Epoch 28] ogbg-moltoxcast: 0.667695 val loss: 0.291175
[Epoch 28] ogbg-moltoxcast: 0.643552 test loss: 0.321414
[Epoch 29; Iter     8/  229] train: loss: 0.2785739
[Epoch 29; Iter    38/  229] train: loss: 0.1874078
[Epoch 29; Iter    68/  229] train: loss: 0.2527905
[Epoch 29; Iter    98/  229] train: loss: 0.1344683
[Epoch 29; Iter   128/  229] train: loss: 0.1455428
[Epoch 29; Iter   158/  229] train: loss: 0.2009727
[Epoch 29; Iter   188/  229] train: loss: 0.1143129
[Epoch 29; Iter   218/  229] train: loss: 0.1679175
[Epoch 29] ogbg-moltoxcast: 0.675572 val loss: 0.298212
[Epoch 29] ogbg-moltoxcast: 0.646163 test loss: 0.334998
[Epoch 30; Iter    19/  229] train: loss: 0.1238398
[Epoch 30; Iter    49/  229] train: loss: 0.1244655
[Epoch 30; Iter    79/  229] train: loss: 0.2320923
[Epoch 30; Iter   109/  229] train: loss: 0.1410180
[Epoch 30; Iter   139/  229] train: loss: 0.1576213
[Epoch 30; Iter   169/  229] train: loss: 0.1692205
[Epoch 30; Iter   199/  229] train: loss: 0.1537734
[Epoch 30; Iter   229/  229] train: loss: 0.1518954
[Epoch 30] ogbg-moltoxcast: 0.686063 val loss: 0.290592
[Epoch 30] ogbg-moltoxcast: 0.657657 test loss: 0.323233
[Epoch 31; Iter    30/  229] train: loss: 0.1055152
[Epoch 31; Iter    60/  229] train: loss: 0.1348638
[Epoch 31; Iter    90/  229] train: loss: 0.1338852
[Epoch 31; Iter   120/  229] train: loss: 0.0702474
[Epoch 31; Iter   150/  229] train: loss: 0.1837308
[Epoch 31; Iter   180/  229] train: loss: 0.1449175
[Epoch 31; Iter   210/  229] train: loss: 0.1719957
[Epoch 31] ogbg-moltoxcast: 0.680240 val loss: 0.280191
[Epoch 31] ogbg-moltoxcast: 0.648914 test loss: 0.320472
[Epoch 32; Iter    11/  229] train: loss: 0.1699420
[Epoch 32; Iter    41/  229] train: loss: 0.1319603
[Epoch 32; Iter    71/  229] train: loss: 0.1522100
[Epoch 32; Iter   101/  229] train: loss: 0.1468900
[Epoch 32; Iter   131/  229] train: loss: 0.1937282
[Epoch 32; Iter   161/  229] train: loss: 0.1489354
[Epoch 32; Iter   191/  229] train: loss: 0.1175492
[Epoch 32; Iter   221/  229] train: loss: 0.1027161
[Epoch 32] ogbg-moltoxcast: 0.678845 val loss: 0.287431
[Epoch 32] ogbg-moltoxcast: 0.650020 test loss: 0.331021
[Epoch 33; Iter    22/  229] train: loss: 0.1437156
[Epoch 33; Iter    52/  229] train: loss: 0.1478390
[Epoch 33; Iter    82/  229] train: loss: 0.1377076
[Epoch 33; Iter   112/  229] train: loss: 0.1765665
[Epoch 33; Iter   142/  229] train: loss: 0.1638279
[Epoch 33; Iter   172/  229] train: loss: 0.1434079
[Epoch 33; Iter   202/  229] train: loss: 0.1566912
[Epoch 33] ogbg-moltoxcast: 0.680591 val loss: 0.296148
[Epoch 33] ogbg-moltoxcast: 0.650662 test loss: 0.337198
[Epoch 34; Iter     3/  229] train: loss: 0.1872643
[Epoch 34; Iter    33/  229] train: loss: 0.1200277
[Epoch 34; Iter    63/  229] train: loss: 0.1803417
[Epoch 34; Iter    93/  229] train: loss: 0.1621017
[Epoch 34; Iter   123/  229] train: loss: 0.1582630
[Epoch 34; Iter   153/  229] train: loss: 0.1352829
[Epoch 34; Iter   183/  229] train: loss: 0.1334041
[Epoch 34; Iter   213/  229] train: loss: 0.1506160
[Epoch 34] ogbg-moltoxcast: 0.670080 val loss: 0.293353
[Epoch 34] ogbg-moltoxcast: 0.644926 test loss: 0.326458
[Epoch 35; Iter    14/  229] train: loss: 0.1440896
[Epoch 35; Iter    44/  229] train: loss: 0.1140396
[Epoch 35; Iter    74/  229] train: loss: 0.1046344
[Epoch 35; Iter   104/  229] train: loss: 0.1554959
[Epoch 35; Iter   134/  229] train: loss: 0.1536884
[Epoch 35; Iter   164/  229] train: loss: 0.1388719
[Epoch 35; Iter   194/  229] train: loss: 0.1737437
[Epoch 35; Iter   224/  229] train: loss: 0.1506032
[Epoch 35] ogbg-moltoxcast: 0.670846 val loss: 0.290858
[Epoch 35] ogbg-moltoxcast: 0.644587 test loss: 0.327636
[Epoch 36; Iter    25/  229] train: loss: 0.1257071
[Epoch 36; Iter    55/  229] train: loss: 0.1514503
[Epoch 36; Iter    85/  229] train: loss: 0.1579223
[Epoch 36; Iter   115/  229] train: loss: 0.1146739
[Epoch 36; Iter   145/  229] train: loss: 0.1801101
[Epoch 36; Iter   175/  229] train: loss: 0.1207597
[Epoch 36; Iter   205/  229] train: loss: 0.1618782
[Epoch 36] ogbg-moltoxcast: 0.671299 val loss: 0.297340
[Epoch 36] ogbg-moltoxcast: 0.649663 test loss: 0.329963
[Epoch 37; Iter     6/  229] train: loss: 0.1460044
[Epoch 37; Iter    36/  229] train: loss: 0.1347126
[Epoch 37; Iter    66/  229] train: loss: 0.2208539
[Epoch 37; Iter    96/  229] train: loss: 0.1087855
[Epoch 37; Iter   126/  229] train: loss: 0.1352115
[Epoch 37; Iter   156/  229] train: loss: 0.1624576
[Epoch 37; Iter   186/  229] train: loss: 0.1488653
[Epoch 37; Iter   216/  229] train: loss: 0.1646000
[Epoch 37] ogbg-moltoxcast: 0.675737 val loss: 0.462990
[Epoch 37] ogbg-moltoxcast: 0.652406 test loss: 0.315906
[Epoch 38; Iter    17/  229] train: loss: 0.1299778
[Epoch 38; Iter    47/  229] train: loss: 0.1736370
[Epoch 38; Iter    77/  229] train: loss: 0.1241132
[Epoch 38; Iter   107/  229] train: loss: 0.1202710
[Epoch 38; Iter   137/  229] train: loss: 0.1449318
[Epoch 38; Iter   167/  229] train: loss: 0.1153764
[Epoch 38; Iter   197/  229] train: loss: 0.1499634
[Epoch 38; Iter   227/  229] train: loss: 0.1315945
[Epoch 38] ogbg-moltoxcast: 0.678031 val loss: 0.298632
[Epoch 38] ogbg-moltoxcast: 0.645768 test loss: 0.324449
[Epoch 39; Iter    28/  229] train: loss: 0.1651471
[Epoch 39; Iter    58/  229] train: loss: 0.1163828
[Epoch 39; Iter    88/  229] train: loss: 0.1399605
[Epoch 39; Iter   118/  229] train: loss: 0.1665401
[Epoch 39; Iter   148/  229] train: loss: 0.1399626
[Epoch 39; Iter   178/  229] train: loss: 0.1147037
[Epoch 39; Iter   208/  229] train: loss: 0.1105366
[Epoch 39] ogbg-moltoxcast: 0.669437 val loss: 0.409815
[Epoch 39] ogbg-moltoxcast: 0.650283 test loss: 0.336208
[Epoch 40; Iter     9/  229] train: loss: 0.1542205
[Epoch 40; Iter    39/  229] train: loss: 0.1154565
[Epoch 40; Iter    69/  229] train: loss: 0.1565678
[Epoch 40; Iter    99/  229] train: loss: 0.1129013
[Epoch 40; Iter   129/  229] train: loss: 0.1213025
[Epoch 40; Iter   159/  229] train: loss: 0.1304232
[Epoch 40; Iter   189/  229] train: loss: 0.1376492
[Epoch 40; Iter   219/  229] train: loss: 0.1192499
[Epoch 40] ogbg-moltoxcast: 0.678147 val loss: 0.295143
[Epoch 40] ogbg-moltoxcast: 0.653637 test loss: 0.325016
[Epoch 41; Iter    20/  229] train: loss: 0.1692926
[Epoch 41; Iter    50/  229] train: loss: 0.1217525
[Epoch 41; Iter    80/  229] train: loss: 0.1954923
[Epoch 41; Iter   110/  229] train: loss: 0.0694931
[Epoch 41; Iter   140/  229] train: loss: 0.1617169
[Epoch 41; Iter   170/  229] train: loss: 0.1746257
[Epoch 41; Iter   200/  229] train: loss: 0.1523902
[Epoch 41] ogbg-moltoxcast: 0.674118 val loss: 0.302689
[Epoch 41] ogbg-moltoxcast: 0.652776 test loss: 0.340161
[Epoch 42; Iter     1/  229] train: loss: 0.1412589
[Epoch 42; Iter    31/  229] train: loss: 0.1089223
[Epoch 42; Iter    61/  229] train: loss: 0.1252379
[Epoch 42; Iter    91/  229] train: loss: 0.1482330
[Epoch 42; Iter   121/  229] train: loss: 0.1585737
[Epoch 42; Iter   151/  229] train: loss: 0.1170501
[Epoch 42; Iter   181/  229] train: loss: 0.1373300
[Epoch 42; Iter   211/  229] train: loss: 0.1287006
[Epoch 42] ogbg-moltoxcast: 0.675690 val loss: 0.296452
[Epoch 42] ogbg-moltoxcast: 0.656094 test loss: 0.336167
[Epoch 43; Iter    12/  229] train: loss: 0.0854321
[Epoch 43; Iter    42/  229] train: loss: 0.1614380
[Epoch 43; Iter    72/  229] train: loss: 0.1257400
[Epoch 43; Iter   102/  229] train: loss: 0.1655967
[Epoch 43; Iter   132/  229] train: loss: 0.1111859
[Epoch 43; Iter   162/  229] train: loss: 0.0956890
[Epoch 43; Iter   192/  229] train: loss: 0.1606197
[Epoch 43; Iter   222/  229] train: loss: 0.1145171
[Epoch 43] ogbg-moltoxcast: 0.670323 val loss: 0.304241
[Epoch 43] ogbg-moltoxcast: 0.652238 test loss: 0.333480
[Epoch 28; Iter    27/  229] train: loss: 0.1831274
[Epoch 28; Iter    57/  229] train: loss: 0.2103803
[Epoch 28; Iter    87/  229] train: loss: 0.1600028
[Epoch 28; Iter   117/  229] train: loss: 0.2420642
[Epoch 28; Iter   147/  229] train: loss: 0.1267065
[Epoch 28; Iter   177/  229] train: loss: 0.1589658
[Epoch 28; Iter   207/  229] train: loss: 0.1959806
[Epoch 28] ogbg-moltoxcast: 0.675283 val loss: 0.319506
[Epoch 28] ogbg-moltoxcast: 0.650429 test loss: 0.342521
[Epoch 29; Iter     8/  229] train: loss: 0.2890203
[Epoch 29; Iter    38/  229] train: loss: 0.1876645
[Epoch 29; Iter    68/  229] train: loss: 0.2715842
[Epoch 29; Iter    98/  229] train: loss: 0.1343618
[Epoch 29; Iter   128/  229] train: loss: 0.1552416
[Epoch 29; Iter   158/  229] train: loss: 0.1981157
[Epoch 29; Iter   188/  229] train: loss: 0.1153232
[Epoch 29; Iter   218/  229] train: loss: 0.1597845
[Epoch 29] ogbg-moltoxcast: 0.676142 val loss: 0.305986
[Epoch 29] ogbg-moltoxcast: 0.653185 test loss: 0.313694
[Epoch 30; Iter    19/  229] train: loss: 0.1280437
[Epoch 30; Iter    49/  229] train: loss: 0.1232178
[Epoch 30; Iter    79/  229] train: loss: 0.2488077
[Epoch 30; Iter   109/  229] train: loss: 0.1338709
[Epoch 30; Iter   139/  229] train: loss: 0.1615753
[Epoch 30; Iter   169/  229] train: loss: 0.1729745
[Epoch 30; Iter   199/  229] train: loss: 0.1520555
[Epoch 30; Iter   229/  229] train: loss: 0.1569761
[Epoch 30] ogbg-moltoxcast: 0.682420 val loss: 0.287069
[Epoch 30] ogbg-moltoxcast: 0.665407 test loss: 0.319933
[Epoch 31; Iter    30/  229] train: loss: 0.1009649
[Epoch 31; Iter    60/  229] train: loss: 0.1415442
[Epoch 31; Iter    90/  229] train: loss: 0.1420917
[Epoch 31; Iter   120/  229] train: loss: 0.0735144
[Epoch 31; Iter   150/  229] train: loss: 0.1741146
[Epoch 31; Iter   180/  229] train: loss: 0.1336246
[Epoch 31; Iter   210/  229] train: loss: 0.1745450
[Epoch 31] ogbg-moltoxcast: 0.678372 val loss: 0.316401
[Epoch 31] ogbg-moltoxcast: 0.645614 test loss: 0.336796
[Epoch 32; Iter    11/  229] train: loss: 0.1823216
[Epoch 32; Iter    41/  229] train: loss: 0.1471069
[Epoch 32; Iter    71/  229] train: loss: 0.1447202
[Epoch 32; Iter   101/  229] train: loss: 0.1537490
[Epoch 32; Iter   131/  229] train: loss: 0.1955922
[Epoch 32; Iter   161/  229] train: loss: 0.1580703
[Epoch 32; Iter   191/  229] train: loss: 0.1256397
[Epoch 32; Iter   221/  229] train: loss: 0.1055035
[Epoch 32] ogbg-moltoxcast: 0.690294 val loss: 0.315533
[Epoch 32] ogbg-moltoxcast: 0.648493 test loss: 0.351421
[Epoch 33; Iter    22/  229] train: loss: 0.1436365
[Epoch 33; Iter    52/  229] train: loss: 0.1544788
[Epoch 33; Iter    82/  229] train: loss: 0.1519668
[Epoch 33; Iter   112/  229] train: loss: 0.1707267
[Epoch 33; Iter   142/  229] train: loss: 0.1676237
[Epoch 33; Iter   172/  229] train: loss: 0.1453622
[Epoch 33; Iter   202/  229] train: loss: 0.1624338
[Epoch 33] ogbg-moltoxcast: 0.688375 val loss: 0.306699
[Epoch 33] ogbg-moltoxcast: 0.661424 test loss: 0.353724
[Epoch 34; Iter     3/  229] train: loss: 0.1966794
[Epoch 34; Iter    33/  229] train: loss: 0.1324650
[Epoch 34; Iter    63/  229] train: loss: 0.1845000
[Epoch 34; Iter    93/  229] train: loss: 0.1635721
[Epoch 34; Iter   123/  229] train: loss: 0.1605817
[Epoch 34; Iter   153/  229] train: loss: 0.1374907
[Epoch 34; Iter   183/  229] train: loss: 0.1432998
[Epoch 34; Iter   213/  229] train: loss: 0.1628002
[Epoch 34] ogbg-moltoxcast: 0.690375 val loss: 0.271774
[Epoch 34] ogbg-moltoxcast: 0.657302 test loss: 0.323757
[Epoch 35; Iter    14/  229] train: loss: 0.1508153
[Epoch 35; Iter    44/  229] train: loss: 0.1160632
[Epoch 35; Iter    74/  229] train: loss: 0.1012661
[Epoch 35; Iter   104/  229] train: loss: 0.1488592
[Epoch 35; Iter   134/  229] train: loss: 0.1388666
[Epoch 35; Iter   164/  229] train: loss: 0.1330522
[Epoch 35; Iter   194/  229] train: loss: 0.1708560
[Epoch 35; Iter   224/  229] train: loss: 0.1459537
[Epoch 35] ogbg-moltoxcast: 0.685912 val loss: 0.265208
[Epoch 35] ogbg-moltoxcast: 0.651609 test loss: 0.314988
[Epoch 36; Iter    25/  229] train: loss: 0.1235238
[Epoch 36; Iter    55/  229] train: loss: 0.1483068
[Epoch 36; Iter    85/  229] train: loss: 0.1521667
[Epoch 36; Iter   115/  229] train: loss: 0.1112378
[Epoch 36; Iter   145/  229] train: loss: 0.1708429
[Epoch 36; Iter   175/  229] train: loss: 0.1152561
[Epoch 36; Iter   205/  229] train: loss: 0.1603758
[Epoch 36] ogbg-moltoxcast: 0.697818 val loss: 0.307910
[Epoch 36] ogbg-moltoxcast: 0.652370 test loss: 0.332471
[Epoch 37; Iter     6/  229] train: loss: 0.1463878
[Epoch 37; Iter    36/  229] train: loss: 0.1274393
[Epoch 37; Iter    66/  229] train: loss: 0.2057367
[Epoch 37; Iter    96/  229] train: loss: 0.1030071
[Epoch 37; Iter   126/  229] train: loss: 0.1337996
[Epoch 37; Iter   156/  229] train: loss: 0.1663914
[Epoch 37; Iter   186/  229] train: loss: 0.1521654
[Epoch 37; Iter   216/  229] train: loss: 0.1609366
[Epoch 37] ogbg-moltoxcast: 0.690854 val loss: 0.270789
[Epoch 37] ogbg-moltoxcast: 0.656620 test loss: 0.319585
[Epoch 38; Iter    17/  229] train: loss: 0.1304055
[Epoch 38; Iter    47/  229] train: loss: 0.1566315
[Epoch 38; Iter    77/  229] train: loss: 0.1204317
[Epoch 38; Iter   107/  229] train: loss: 0.1161918
[Epoch 38; Iter   137/  229] train: loss: 0.1461914
[Epoch 38; Iter   167/  229] train: loss: 0.1091943
[Epoch 38; Iter   197/  229] train: loss: 0.1535779
[Epoch 38; Iter   227/  229] train: loss: 0.1306149
[Epoch 38] ogbg-moltoxcast: 0.685918 val loss: 0.291004
[Epoch 38] ogbg-moltoxcast: 0.655837 test loss: 0.315716
[Epoch 39; Iter    28/  229] train: loss: 0.1621118
[Epoch 39; Iter    58/  229] train: loss: 0.1179537
[Epoch 39; Iter    88/  229] train: loss: 0.1421406
[Epoch 39; Iter   118/  229] train: loss: 0.1674512
[Epoch 39; Iter   148/  229] train: loss: 0.1368795
[Epoch 39; Iter   178/  229] train: loss: 0.1187055
[Epoch 39; Iter   208/  229] train: loss: 0.1089651
[Epoch 39] ogbg-moltoxcast: 0.694633 val loss: 0.291595
[Epoch 39] ogbg-moltoxcast: 0.654987 test loss: 0.327076
[Epoch 40; Iter     9/  229] train: loss: 0.1534246
[Epoch 40; Iter    39/  229] train: loss: 0.1232954
[Epoch 40; Iter    69/  229] train: loss: 0.1597189
[Epoch 40; Iter    99/  229] train: loss: 0.1122951
[Epoch 40; Iter   129/  229] train: loss: 0.1458804
[Epoch 40; Iter   159/  229] train: loss: 0.1369617
[Epoch 40; Iter   189/  229] train: loss: 0.1444197
[Epoch 40; Iter   219/  229] train: loss: 0.1471538
[Epoch 40] ogbg-moltoxcast: 0.697201 val loss: 0.326886
[Epoch 40] ogbg-moltoxcast: 0.662800 test loss: 0.371294
[Epoch 41; Iter    20/  229] train: loss: 0.1705150
[Epoch 41; Iter    50/  229] train: loss: 0.1195983
[Epoch 41; Iter    80/  229] train: loss: 0.1992043
[Epoch 41; Iter   110/  229] train: loss: 0.0706568
[Epoch 41; Iter   140/  229] train: loss: 0.1758755
[Epoch 41; Iter   170/  229] train: loss: 0.1821369
[Epoch 41; Iter   200/  229] train: loss: 0.1543033
[Epoch 41] ogbg-moltoxcast: 0.693493 val loss: 0.328312
[Epoch 41] ogbg-moltoxcast: 0.658562 test loss: 0.328652
[Epoch 42; Iter     1/  229] train: loss: 0.1448051
[Epoch 42; Iter    31/  229] train: loss: 0.1102728
[Epoch 42; Iter    61/  229] train: loss: 0.1218224
[Epoch 42; Iter    91/  229] train: loss: 0.1607851
[Epoch 42; Iter   121/  229] train: loss: 0.1740210
[Epoch 42; Iter   151/  229] train: loss: 0.1202970
[Epoch 42; Iter   181/  229] train: loss: 0.1402852
[Epoch 42; Iter   211/  229] train: loss: 0.1207323
[Epoch 42] ogbg-moltoxcast: 0.687244 val loss: 0.293362
[Epoch 42] ogbg-moltoxcast: 0.660923 test loss: 0.320262
[Epoch 43; Iter    12/  229] train: loss: 0.0824821
[Epoch 43; Iter    42/  229] train: loss: 0.1714330
[Epoch 43; Iter    72/  229] train: loss: 0.1222096
[Epoch 43; Iter   102/  229] train: loss: 0.1673734
[Epoch 43; Iter   132/  229] train: loss: 0.1200637
[Epoch 43; Iter   162/  229] train: loss: 0.1020750
[Epoch 43; Iter   192/  229] train: loss: 0.1759381
[Epoch 43; Iter   222/  229] train: loss: 0.1235320
[Epoch 43] ogbg-moltoxcast: 0.700534 val loss: 0.276295
[Epoch 43] ogbg-moltoxcast: 0.667054 test loss: 0.320425
[Epoch 28; Iter    27/  229] train: loss: 0.2107830
[Epoch 28; Iter    57/  229] train: loss: 0.1642539
[Epoch 28; Iter    87/  229] train: loss: 0.1680136
[Epoch 28; Iter   117/  229] train: loss: 0.2139115
[Epoch 28; Iter   147/  229] train: loss: 0.1628747
[Epoch 28; Iter   177/  229] train: loss: 0.1647257
[Epoch 28; Iter   207/  229] train: loss: 0.1810250
[Epoch 28] ogbg-moltoxcast: 0.684087 val loss: 0.264245
[Epoch 28] ogbg-moltoxcast: 0.661138 test loss: 0.304243
[Epoch 29; Iter     8/  229] train: loss: 0.1415366
[Epoch 29; Iter    38/  229] train: loss: 0.1337788
[Epoch 29; Iter    68/  229] train: loss: 0.2005991
[Epoch 29; Iter    98/  229] train: loss: 0.1903236
[Epoch 29; Iter   128/  229] train: loss: 0.2458808
[Epoch 29; Iter   158/  229] train: loss: 0.1496390
[Epoch 29; Iter   188/  229] train: loss: 0.2114775
[Epoch 29; Iter   218/  229] train: loss: 0.1463654
[Epoch 29] ogbg-moltoxcast: 0.676207 val loss: 0.275606
[Epoch 29] ogbg-moltoxcast: 0.654271 test loss: 0.315610
[Epoch 30; Iter    19/  229] train: loss: 0.1577564
[Epoch 30; Iter    49/  229] train: loss: 0.1989610
[Epoch 30; Iter    79/  229] train: loss: 0.1269752
[Epoch 30; Iter   109/  229] train: loss: 0.1246822
[Epoch 30; Iter   139/  229] train: loss: 0.1472159
[Epoch 30; Iter   169/  229] train: loss: 0.1565783
[Epoch 30; Iter   199/  229] train: loss: 0.1131024
[Epoch 30; Iter   229/  229] train: loss: 0.2385819
[Epoch 30] ogbg-moltoxcast: 0.687865 val loss: 0.267492
[Epoch 30] ogbg-moltoxcast: 0.666484 test loss: 0.314773
[Epoch 31; Iter    30/  229] train: loss: 0.1509364
[Epoch 31; Iter    60/  229] train: loss: 0.1493189
[Epoch 31; Iter    90/  229] train: loss: 0.1531670
[Epoch 31; Iter   120/  229] train: loss: 0.1121531
[Epoch 31; Iter   150/  229] train: loss: 0.1995291
[Epoch 31; Iter   180/  229] train: loss: 0.1432729
[Epoch 31; Iter   210/  229] train: loss: 0.0803217
[Epoch 31] ogbg-moltoxcast: 0.679195 val loss: 0.280701
[Epoch 31] ogbg-moltoxcast: 0.663207 test loss: 0.308672
[Epoch 32; Iter    11/  229] train: loss: 0.1787610
[Epoch 32; Iter    41/  229] train: loss: 0.1271812
[Epoch 32; Iter    71/  229] train: loss: 0.1216163
[Epoch 32; Iter   101/  229] train: loss: 0.1446265
[Epoch 32; Iter   131/  229] train: loss: 0.1444279
[Epoch 32; Iter   161/  229] train: loss: 0.1159089
[Epoch 32; Iter   191/  229] train: loss: 0.1513715
[Epoch 32; Iter   221/  229] train: loss: 0.1032610
[Epoch 32] ogbg-moltoxcast: 0.670574 val loss: 0.293588
[Epoch 32] ogbg-moltoxcast: 0.660357 test loss: 0.327083
[Epoch 33; Iter    22/  229] train: loss: 0.1861380
[Epoch 33; Iter    52/  229] train: loss: 0.1634856
[Epoch 33; Iter    82/  229] train: loss: 0.1496330
[Epoch 33; Iter   112/  229] train: loss: 0.1486942
[Epoch 33; Iter   142/  229] train: loss: 0.1618326
[Epoch 33; Iter   172/  229] train: loss: 0.1168744
[Epoch 33; Iter   202/  229] train: loss: 0.1318115
[Epoch 33] ogbg-moltoxcast: 0.686013 val loss: 0.268116
[Epoch 33] ogbg-moltoxcast: 0.661290 test loss: 0.318337
[Epoch 34; Iter     3/  229] train: loss: 0.1303325
[Epoch 34; Iter    33/  229] train: loss: 0.1969525
[Epoch 34; Iter    63/  229] train: loss: 0.1756548
[Epoch 34; Iter    93/  229] train: loss: 0.2185507
[Epoch 34; Iter   123/  229] train: loss: 0.1166771
[Epoch 34; Iter   153/  229] train: loss: 0.1283317
[Epoch 34; Iter   183/  229] train: loss: 0.1758053
[Epoch 34; Iter   213/  229] train: loss: 0.1647311
[Epoch 34] ogbg-moltoxcast: 0.679840 val loss: 0.275422
[Epoch 34] ogbg-moltoxcast: 0.660029 test loss: 0.314423
[Epoch 35; Iter    14/  229] train: loss: 0.1854982
[Epoch 35; Iter    44/  229] train: loss: 0.1213669
[Epoch 35; Iter    74/  229] train: loss: 0.1494690
[Epoch 35; Iter   104/  229] train: loss: 0.2876288
[Epoch 35; Iter   134/  229] train: loss: 0.1322739
[Epoch 35; Iter   164/  229] train: loss: 0.1563278
[Epoch 35; Iter   194/  229] train: loss: 0.1436746
[Epoch 35; Iter   224/  229] train: loss: 0.1358158
[Epoch 35] ogbg-moltoxcast: 0.697548 val loss: 0.264621
[Epoch 35] ogbg-moltoxcast: 0.673170 test loss: 0.311752
[Epoch 36; Iter    25/  229] train: loss: 0.1522968
[Epoch 36; Iter    55/  229] train: loss: 0.1811644
[Epoch 36; Iter    85/  229] train: loss: 0.1270425
[Epoch 36; Iter   115/  229] train: loss: 0.1275499
[Epoch 36; Iter   145/  229] train: loss: 0.1256631
[Epoch 36; Iter   175/  229] train: loss: 0.1433187
[Epoch 36; Iter   205/  229] train: loss: 0.1719388
[Epoch 36] ogbg-moltoxcast: 0.685457 val loss: 0.267307
[Epoch 36] ogbg-moltoxcast: 0.665073 test loss: 0.311981
[Epoch 37; Iter     6/  229] train: loss: 0.1567794
[Epoch 37; Iter    36/  229] train: loss: 0.2198128
[Epoch 37; Iter    66/  229] train: loss: 0.1372151
[Epoch 37; Iter    96/  229] train: loss: 0.1611203
[Epoch 37; Iter   126/  229] train: loss: 0.1373226
[Epoch 37; Iter   156/  229] train: loss: 0.1451720
[Epoch 37; Iter   186/  229] train: loss: 0.1065868
[Epoch 37; Iter   216/  229] train: loss: 0.1415847
[Epoch 37] ogbg-moltoxcast: 0.677207 val loss: 0.279793
[Epoch 37] ogbg-moltoxcast: 0.668280 test loss: 0.317714
[Epoch 38; Iter    17/  229] train: loss: 0.1783618
[Epoch 38; Iter    47/  229] train: loss: 0.1385512
[Epoch 38; Iter    77/  229] train: loss: 0.1443817
[Epoch 38; Iter   107/  229] train: loss: 0.1440904
[Epoch 38; Iter   137/  229] train: loss: 0.1165715
[Epoch 38; Iter   167/  229] train: loss: 0.1285753
[Epoch 38; Iter   197/  229] train: loss: 0.1811619
[Epoch 38; Iter   227/  229] train: loss: 0.1224318
[Epoch 38] ogbg-moltoxcast: 0.687861 val loss: 0.272784
[Epoch 38] ogbg-moltoxcast: 0.672310 test loss: 0.314313
[Epoch 39; Iter    28/  229] train: loss: 0.1662278
[Epoch 39; Iter    58/  229] train: loss: 0.1431156
[Epoch 39; Iter    88/  229] train: loss: 0.1521250
[Epoch 39; Iter   118/  229] train: loss: 0.2039072
[Epoch 39; Iter   148/  229] train: loss: 0.1435364
[Epoch 39; Iter   178/  229] train: loss: 0.1647678
[Epoch 39; Iter   208/  229] train: loss: 0.1441956
[Epoch 39] ogbg-moltoxcast: 0.687076 val loss: 0.270400
[Epoch 39] ogbg-moltoxcast: 0.670067 test loss: 0.313850
[Epoch 40; Iter     9/  229] train: loss: 0.1273538
[Epoch 40; Iter    39/  229] train: loss: 0.1895517
[Epoch 40; Iter    69/  229] train: loss: 0.1670129
[Epoch 40; Iter    99/  229] train: loss: 0.0811391
[Epoch 40; Iter   129/  229] train: loss: 0.1636329
[Epoch 40; Iter   159/  229] train: loss: 0.1185210
[Epoch 40; Iter   189/  229] train: loss: 0.1154366
[Epoch 40; Iter   219/  229] train: loss: 0.1688416
[Epoch 40] ogbg-moltoxcast: 0.678071 val loss: 0.281273
[Epoch 40] ogbg-moltoxcast: 0.667590 test loss: 0.324196
[Epoch 41; Iter    20/  229] train: loss: 0.1364386
[Epoch 41; Iter    50/  229] train: loss: 0.1744877
[Epoch 41; Iter    80/  229] train: loss: 0.1528492
[Epoch 41; Iter   110/  229] train: loss: 0.1735239
[Epoch 41; Iter   140/  229] train: loss: 0.1417039
[Epoch 41; Iter   170/  229] train: loss: 0.1197766
[Epoch 41; Iter   200/  229] train: loss: 0.1713644
[Epoch 41] ogbg-moltoxcast: 0.680815 val loss: 0.278149
[Epoch 41] ogbg-moltoxcast: 0.669404 test loss: 0.318948
[Epoch 42; Iter     1/  229] train: loss: 0.1845872
[Epoch 42; Iter    31/  229] train: loss: 0.1054671
[Epoch 42; Iter    61/  229] train: loss: 0.1154997
[Epoch 42; Iter    91/  229] train: loss: 0.1753443
[Epoch 42; Iter   121/  229] train: loss: 0.1052881
[Epoch 42; Iter   151/  229] train: loss: 0.1182402
[Epoch 42; Iter   181/  229] train: loss: 0.2139425
[Epoch 42; Iter   211/  229] train: loss: 0.1162088
[Epoch 42] ogbg-moltoxcast: 0.690839 val loss: 0.279522
[Epoch 42] ogbg-moltoxcast: 0.666463 test loss: 0.324135
[Epoch 43; Iter    12/  229] train: loss: 0.1283446
[Epoch 43; Iter    42/  229] train: loss: 0.1339041
[Epoch 43; Iter    72/  229] train: loss: 0.1799769
[Epoch 43; Iter   102/  229] train: loss: 0.1435229
[Epoch 43; Iter   132/  229] train: loss: 0.1437326
[Epoch 43; Iter   162/  229] train: loss: 0.1440429
[Epoch 43; Iter   192/  229] train: loss: 0.1458954
[Epoch 43; Iter   222/  229] train: loss: 0.1662505
[Epoch 43] ogbg-moltoxcast: 0.677891 val loss: 0.279260
[Epoch 43] ogbg-moltoxcast: 0.670005 test loss: 0.322311
[Epoch 28; Iter    27/  229] train: loss: 0.1815426
[Epoch 28; Iter    57/  229] train: loss: 0.1805559
[Epoch 28; Iter    87/  229] train: loss: 0.1561306
[Epoch 28; Iter   117/  229] train: loss: 0.2478175
[Epoch 28; Iter   147/  229] train: loss: 0.1286289
[Epoch 28; Iter   177/  229] train: loss: 0.1421446
[Epoch 28; Iter   207/  229] train: loss: 0.1846279
[Epoch 28] ogbg-moltoxcast: 0.632029 val loss: 0.324902
[Epoch 28] ogbg-moltoxcast: 0.620167 test loss: 0.376811
[Epoch 29; Iter     8/  229] train: loss: 0.2624151
[Epoch 29; Iter    38/  229] train: loss: 0.1844282
[Epoch 29; Iter    68/  229] train: loss: 0.2386622
[Epoch 29; Iter    98/  229] train: loss: 0.1328821
[Epoch 29; Iter   128/  229] train: loss: 0.1412557
[Epoch 29; Iter   158/  229] train: loss: 0.1899767
[Epoch 29; Iter   188/  229] train: loss: 0.1057929
[Epoch 29; Iter   218/  229] train: loss: 0.1668354
[Epoch 29] ogbg-moltoxcast: 0.625123 val loss: 1.427010
[Epoch 29] ogbg-moltoxcast: 0.627534 test loss: 3.838957
[Epoch 30; Iter    19/  229] train: loss: 0.1178522
[Epoch 30; Iter    49/  229] train: loss: 0.1249922
[Epoch 30; Iter    79/  229] train: loss: 0.2348697
[Epoch 30; Iter   109/  229] train: loss: 0.1352431
[Epoch 30; Iter   139/  229] train: loss: 0.1460076
[Epoch 30; Iter   169/  229] train: loss: 0.1915293
[Epoch 30; Iter   199/  229] train: loss: 0.1446435
[Epoch 30; Iter   229/  229] train: loss: 0.1516707
[Epoch 30] ogbg-moltoxcast: 0.653300 val loss: 0.322066
[Epoch 30] ogbg-moltoxcast: 0.631352 test loss: 0.378560
[Epoch 31; Iter    30/  229] train: loss: 0.0958448
[Epoch 31; Iter    60/  229] train: loss: 0.1382247
[Epoch 31; Iter    90/  229] train: loss: 0.1348438
[Epoch 31; Iter   120/  229] train: loss: 0.0772170
[Epoch 31; Iter   150/  229] train: loss: 0.1763755
[Epoch 31; Iter   180/  229] train: loss: 0.1374189
[Epoch 31; Iter   210/  229] train: loss: 0.1715295
[Epoch 31] ogbg-moltoxcast: 0.649593 val loss: 0.362323
[Epoch 31] ogbg-moltoxcast: 0.638280 test loss: 0.543512
[Epoch 32; Iter    11/  229] train: loss: 0.1573037
[Epoch 32; Iter    41/  229] train: loss: 0.1237583
[Epoch 32; Iter    71/  229] train: loss: 0.1613452
[Epoch 32; Iter   101/  229] train: loss: 0.1418621
[Epoch 32; Iter   131/  229] train: loss: 0.1921352
[Epoch 32; Iter   161/  229] train: loss: 0.1611484
[Epoch 32; Iter   191/  229] train: loss: 0.1225990
[Epoch 32; Iter   221/  229] train: loss: 0.1008393
[Epoch 32] ogbg-moltoxcast: 0.654035 val loss: 0.354588
[Epoch 32] ogbg-moltoxcast: 0.641775 test loss: 0.366995
[Epoch 33; Iter    22/  229] train: loss: 0.1459026
[Epoch 33; Iter    52/  229] train: loss: 0.1501558
[Epoch 33; Iter    82/  229] train: loss: 0.1435986
[Epoch 33; Iter   112/  229] train: loss: 0.1711638
[Epoch 33; Iter   142/  229] train: loss: 0.1604718
[Epoch 33; Iter   172/  229] train: loss: 0.1435439
[Epoch 33; Iter   202/  229] train: loss: 0.1628535
[Epoch 33] ogbg-moltoxcast: 0.643664 val loss: 0.870565
[Epoch 33] ogbg-moltoxcast: 0.634272 test loss: 2.277937
[Epoch 34; Iter     3/  229] train: loss: 0.2178618
[Epoch 34; Iter    33/  229] train: loss: 0.1227149
[Epoch 34; Iter    63/  229] train: loss: 0.2090105
[Epoch 34; Iter    93/  229] train: loss: 0.1650769
[Epoch 34; Iter   123/  229] train: loss: 0.1557294
[Epoch 34; Iter   153/  229] train: loss: 0.1258992
[Epoch 34; Iter   183/  229] train: loss: 0.1370164
[Epoch 34; Iter   213/  229] train: loss: 0.1585092
[Epoch 34] ogbg-moltoxcast: 0.644767 val loss: 0.366984
[Epoch 34] ogbg-moltoxcast: 0.641477 test loss: 0.554727
[Epoch 35; Iter    14/  229] train: loss: 0.1420707
[Epoch 35; Iter    44/  229] train: loss: 0.1106292
[Epoch 35; Iter    74/  229] train: loss: 0.0948005
[Epoch 35; Iter   104/  229] train: loss: 0.1443419
[Epoch 35; Iter   134/  229] train: loss: 0.1398878
[Epoch 35; Iter   164/  229] train: loss: 0.1424868
[Epoch 35; Iter   194/  229] train: loss: 0.1686369
[Epoch 35; Iter   224/  229] train: loss: 0.1527064
[Epoch 35] ogbg-moltoxcast: 0.648304 val loss: 0.323311
[Epoch 35] ogbg-moltoxcast: 0.639591 test loss: 0.450753
[Epoch 36; Iter    25/  229] train: loss: 0.1271009
[Epoch 36; Iter    55/  229] train: loss: 0.1523053
[Epoch 36; Iter    85/  229] train: loss: 0.1483310
[Epoch 36; Iter   115/  229] train: loss: 0.1113688
[Epoch 36; Iter   145/  229] train: loss: 0.1663215
[Epoch 36; Iter   175/  229] train: loss: 0.1224493
[Epoch 36; Iter   205/  229] train: loss: 0.1495346
[Epoch 36] ogbg-moltoxcast: 0.648192 val loss: 0.319039
[Epoch 36] ogbg-moltoxcast: 0.645330 test loss: 0.363968
[Epoch 37; Iter     6/  229] train: loss: 0.1350073
[Epoch 37; Iter    36/  229] train: loss: 0.1302316
[Epoch 37; Iter    66/  229] train: loss: 0.2052590
[Epoch 37; Iter    96/  229] train: loss: 0.1012874
[Epoch 37; Iter   126/  229] train: loss: 0.1367310
[Epoch 37; Iter   156/  229] train: loss: 0.1562614
[Epoch 37; Iter   186/  229] train: loss: 0.1406585
[Epoch 37; Iter   216/  229] train: loss: 0.1552927
[Epoch 37] ogbg-moltoxcast: 0.650251 val loss: 0.321123
[Epoch 37] ogbg-moltoxcast: 0.641419 test loss: 0.369601
[Epoch 38; Iter    17/  229] train: loss: 0.1190030
[Epoch 38; Iter    47/  229] train: loss: 0.1530837
[Epoch 38; Iter    77/  229] train: loss: 0.1105587
[Epoch 38; Iter   107/  229] train: loss: 0.1161184
[Epoch 38; Iter   137/  229] train: loss: 0.1367200
[Epoch 38; Iter   167/  229] train: loss: 0.1071959
[Epoch 38; Iter   197/  229] train: loss: 0.1457242
[Epoch 38; Iter   227/  229] train: loss: 0.1297688
[Epoch 38] ogbg-moltoxcast: 0.644451 val loss: 0.339393
[Epoch 38] ogbg-moltoxcast: 0.644973 test loss: 0.383512
[Epoch 39; Iter    28/  229] train: loss: 0.1612702
[Epoch 39; Iter    58/  229] train: loss: 0.1160532
[Epoch 39; Iter    88/  229] train: loss: 0.1404751
[Epoch 39; Iter   118/  229] train: loss: 0.1715112
[Epoch 39; Iter   148/  229] train: loss: 0.1411034
[Epoch 39; Iter   178/  229] train: loss: 0.1236745
[Epoch 39; Iter   208/  229] train: loss: 0.1156563
[Epoch 39] ogbg-moltoxcast: 0.650459 val loss: 0.459485
[Epoch 39] ogbg-moltoxcast: 0.633671 test loss: 0.856882
[Epoch 40; Iter     9/  229] train: loss: 0.1553826
[Epoch 40; Iter    39/  229] train: loss: 0.1103243
[Epoch 40; Iter    69/  229] train: loss: 0.1633001
[Epoch 40; Iter    99/  229] train: loss: 0.1123886
[Epoch 40; Iter   129/  229] train: loss: 0.1285559
[Epoch 40; Iter   159/  229] train: loss: 0.1321191
[Epoch 40; Iter   189/  229] train: loss: 0.1431232
[Epoch 40; Iter   219/  229] train: loss: 0.1243763
[Epoch 40] ogbg-moltoxcast: 0.653697 val loss: 0.329699
[Epoch 40] ogbg-moltoxcast: 0.643597 test loss: 0.372057
[Epoch 41; Iter    20/  229] train: loss: 0.1624135
[Epoch 41; Iter    50/  229] train: loss: 0.1279949
[Epoch 41; Iter    80/  229] train: loss: 0.1916476
[Epoch 41; Iter   110/  229] train: loss: 0.0620951
[Epoch 41; Iter   140/  229] train: loss: 0.1702055
[Epoch 41; Iter   170/  229] train: loss: 0.1841399
[Epoch 41; Iter   200/  229] train: loss: 0.1445122
[Epoch 41] ogbg-moltoxcast: 0.649366 val loss: 0.327534
[Epoch 41] ogbg-moltoxcast: 0.647084 test loss: 0.374107
[Epoch 42; Iter     1/  229] train: loss: 0.1426785
[Epoch 42; Iter    31/  229] train: loss: 0.1079988
[Epoch 42; Iter    61/  229] train: loss: 0.1229231
[Epoch 42; Iter    91/  229] train: loss: 0.1487785
[Epoch 42; Iter   121/  229] train: loss: 0.1551015
[Epoch 42; Iter   151/  229] train: loss: 0.1122471
[Epoch 42; Iter   181/  229] train: loss: 0.1360591
[Epoch 42; Iter   211/  229] train: loss: 0.1288993
[Epoch 42] ogbg-moltoxcast: 0.641480 val loss: 0.326250
[Epoch 42] ogbg-moltoxcast: 0.643135 test loss: 0.370325
[Epoch 43; Iter    12/  229] train: loss: 0.0853745
[Epoch 43; Iter    42/  229] train: loss: 0.1655528
[Epoch 43; Iter    72/  229] train: loss: 0.1177764
[Epoch 43; Iter   102/  229] train: loss: 0.1721838
[Epoch 43; Iter   132/  229] train: loss: 0.1116557
[Epoch 43; Iter   162/  229] train: loss: 0.0948928
[Epoch 43; Iter   192/  229] train: loss: 0.1582506
[Epoch 43; Iter   222/  229] train: loss: 0.1196521
[Epoch 43] ogbg-moltoxcast: 0.651202 val loss: 0.325524
[Epoch 43] ogbg-moltoxcast: 0.637426 test loss: 0.375133
[Epoch 28; Iter    27/  229] train: loss: 0.1928382
[Epoch 28; Iter    57/  229] train: loss: 0.1691696
[Epoch 28; Iter    87/  229] train: loss: 0.1736140
[Epoch 28; Iter   117/  229] train: loss: 0.2326487
[Epoch 28; Iter   147/  229] train: loss: 0.1728440
[Epoch 28; Iter   177/  229] train: loss: 0.1761856
[Epoch 28; Iter   207/  229] train: loss: 0.2066964
[Epoch 28] ogbg-moltoxcast: 0.654641 val loss: 0.279342
[Epoch 28] ogbg-moltoxcast: 0.634577 test loss: 0.350035
[Epoch 29; Iter     8/  229] train: loss: 0.1529078
[Epoch 29; Iter    38/  229] train: loss: 0.1377453
[Epoch 29; Iter    68/  229] train: loss: 0.1965094
[Epoch 29; Iter    98/  229] train: loss: 0.2136421
[Epoch 29; Iter   128/  229] train: loss: 0.2550936
[Epoch 29; Iter   158/  229] train: loss: 0.1562165
[Epoch 29; Iter   188/  229] train: loss: 0.2100780
[Epoch 29; Iter   218/  229] train: loss: 0.1592229
[Epoch 29] ogbg-moltoxcast: 0.656852 val loss: 0.484734
[Epoch 29] ogbg-moltoxcast: 0.628980 test loss: 0.742910
[Epoch 30; Iter    19/  229] train: loss: 0.1715225
[Epoch 30; Iter    49/  229] train: loss: 0.2056085
[Epoch 30; Iter    79/  229] train: loss: 0.1315650
[Epoch 30; Iter   109/  229] train: loss: 0.1282701
[Epoch 30; Iter   139/  229] train: loss: 0.1590521
[Epoch 30; Iter   169/  229] train: loss: 0.1861862
[Epoch 30; Iter   199/  229] train: loss: 0.1234762
[Epoch 30; Iter   229/  229] train: loss: 0.2603380
[Epoch 30] ogbg-moltoxcast: 0.665696 val loss: 0.263009
[Epoch 30] ogbg-moltoxcast: 0.637481 test loss: 0.307880
[Epoch 31; Iter    30/  229] train: loss: 0.1506170
[Epoch 31; Iter    60/  229] train: loss: 0.1511599
[Epoch 31; Iter    90/  229] train: loss: 0.1461997
[Epoch 31; Iter   120/  229] train: loss: 0.1112377
[Epoch 31; Iter   150/  229] train: loss: 0.1967953
[Epoch 31; Iter   180/  229] train: loss: 0.1456362
[Epoch 31; Iter   210/  229] train: loss: 0.0799872
[Epoch 31] ogbg-moltoxcast: 0.655370 val loss: 0.293988
[Epoch 31] ogbg-moltoxcast: 0.628209 test loss: 0.335471
[Epoch 32; Iter    11/  229] train: loss: 0.1702780
[Epoch 32; Iter    41/  229] train: loss: 0.1297983
[Epoch 32; Iter    71/  229] train: loss: 0.1212028
[Epoch 32; Iter   101/  229] train: loss: 0.1591466
[Epoch 32; Iter   131/  229] train: loss: 0.1507619
[Epoch 32; Iter   161/  229] train: loss: 0.1234386
[Epoch 32; Iter   191/  229] train: loss: 0.1618048
[Epoch 32; Iter   221/  229] train: loss: 0.1047981
[Epoch 32] ogbg-moltoxcast: 0.658606 val loss: 0.285065
[Epoch 32] ogbg-moltoxcast: 0.634117 test loss: 0.348070
[Epoch 33; Iter    22/  229] train: loss: 0.1884198
[Epoch 33; Iter    52/  229] train: loss: 0.1711306
[Epoch 33; Iter    82/  229] train: loss: 0.1480069
[Epoch 33; Iter   112/  229] train: loss: 0.1596212
[Epoch 33; Iter   142/  229] train: loss: 0.1657167
[Epoch 33; Iter   172/  229] train: loss: 0.1158753
[Epoch 33; Iter   202/  229] train: loss: 0.1296360
[Epoch 33] ogbg-moltoxcast: 0.667437 val loss: 0.273630
[Epoch 33] ogbg-moltoxcast: 0.643056 test loss: 0.328478
[Epoch 34; Iter     3/  229] train: loss: 0.1308555
[Epoch 34; Iter    33/  229] train: loss: 0.2008721
[Epoch 34; Iter    63/  229] train: loss: 0.1755970
[Epoch 34; Iter    93/  229] train: loss: 0.1930245
[Epoch 34; Iter   123/  229] train: loss: 0.1241795
[Epoch 34; Iter   153/  229] train: loss: 0.1307262
[Epoch 34; Iter   183/  229] train: loss: 0.1922689
[Epoch 34; Iter   213/  229] train: loss: 0.1838159
[Epoch 34] ogbg-moltoxcast: 0.673211 val loss: 0.267707
[Epoch 34] ogbg-moltoxcast: 0.644161 test loss: 0.307134
[Epoch 35; Iter    14/  229] train: loss: 0.1864677
[Epoch 35; Iter    44/  229] train: loss: 0.1358062
[Epoch 35; Iter    74/  229] train: loss: 0.1479958
[Epoch 35; Iter   104/  229] train: loss: 0.2553542
[Epoch 35; Iter   134/  229] train: loss: 0.1356175
[Epoch 35; Iter   164/  229] train: loss: 0.1534745
[Epoch 35; Iter   194/  229] train: loss: 0.1533602
[Epoch 35; Iter   224/  229] train: loss: 0.1452303
[Epoch 35] ogbg-moltoxcast: 0.659407 val loss: 0.267993
[Epoch 35] ogbg-moltoxcast: 0.640070 test loss: 0.312122
[Epoch 36; Iter    25/  229] train: loss: 0.1533750
[Epoch 36; Iter    55/  229] train: loss: 0.1852913
[Epoch 36; Iter    85/  229] train: loss: 0.1387272
[Epoch 36; Iter   115/  229] train: loss: 0.1331000
[Epoch 36; Iter   145/  229] train: loss: 0.1293972
[Epoch 36; Iter   175/  229] train: loss: 0.1497392
[Epoch 36; Iter   205/  229] train: loss: 0.1837606
[Epoch 36] ogbg-moltoxcast: 0.650903 val loss: 0.289034
[Epoch 36] ogbg-moltoxcast: 0.624364 test loss: 0.337673
[Epoch 37; Iter     6/  229] train: loss: 0.1728081
[Epoch 37; Iter    36/  229] train: loss: 0.2350266
[Epoch 37; Iter    66/  229] train: loss: 0.1344226
[Epoch 37; Iter    96/  229] train: loss: 0.1644583
[Epoch 37; Iter   126/  229] train: loss: 0.1390535
[Epoch 37; Iter   156/  229] train: loss: 0.1582975
[Epoch 37; Iter   186/  229] train: loss: 0.1092448
[Epoch 37; Iter   216/  229] train: loss: 0.1497313
[Epoch 37] ogbg-moltoxcast: 0.661488 val loss: 0.307703
[Epoch 37] ogbg-moltoxcast: 0.635280 test loss: 0.327897
[Epoch 38; Iter    17/  229] train: loss: 0.1880181
[Epoch 38; Iter    47/  229] train: loss: 0.1555351
[Epoch 38; Iter    77/  229] train: loss: 0.1449682
[Epoch 38; Iter   107/  229] train: loss: 0.1527103
[Epoch 38; Iter   137/  229] train: loss: 0.1174430
[Epoch 38; Iter   167/  229] train: loss: 0.1343895
[Epoch 38; Iter   197/  229] train: loss: 0.1831242
[Epoch 38; Iter   227/  229] train: loss: 0.1281072
[Epoch 38] ogbg-moltoxcast: 0.666037 val loss: 0.290956
[Epoch 38] ogbg-moltoxcast: 0.640855 test loss: 0.330764
[Epoch 39; Iter    28/  229] train: loss: 0.1803762
[Epoch 39; Iter    58/  229] train: loss: 0.1526987
[Epoch 39; Iter    88/  229] train: loss: 0.1576665
[Epoch 39; Iter   118/  229] train: loss: 0.2047920
[Epoch 39; Iter   148/  229] train: loss: 0.1513142
[Epoch 39; Iter   178/  229] train: loss: 0.1683602
[Epoch 39; Iter   208/  229] train: loss: 0.1469669
[Epoch 39] ogbg-moltoxcast: 0.659866 val loss: 0.317948
[Epoch 39] ogbg-moltoxcast: 0.640564 test loss: 0.329262
[Epoch 40; Iter     9/  229] train: loss: 0.1326077
[Epoch 40; Iter    39/  229] train: loss: 0.2018710
[Epoch 40; Iter    69/  229] train: loss: 0.1819105
[Epoch 40; Iter    99/  229] train: loss: 0.0811434
[Epoch 40; Iter   129/  229] train: loss: 0.1733547
[Epoch 40; Iter   159/  229] train: loss: 0.1182464
[Epoch 40; Iter   189/  229] train: loss: 0.1258852
[Epoch 40; Iter   219/  229] train: loss: 0.1762783
[Epoch 40] ogbg-moltoxcast: 0.660359 val loss: 0.311485
[Epoch 40] ogbg-moltoxcast: 0.630396 test loss: 0.333690
[Epoch 41; Iter    20/  229] train: loss: 0.1423543
[Epoch 41; Iter    50/  229] train: loss: 0.1764894
[Epoch 41; Iter    80/  229] train: loss: 0.1554750
[Epoch 41; Iter   110/  229] train: loss: 0.1715002
[Epoch 41; Iter   140/  229] train: loss: 0.1509635
[Epoch 41; Iter   170/  229] train: loss: 0.1302648
[Epoch 41; Iter   200/  229] train: loss: 0.1790888
[Epoch 41] ogbg-moltoxcast: 0.664589 val loss: 0.289403
[Epoch 41] ogbg-moltoxcast: 0.642609 test loss: 0.327142
[Epoch 42; Iter     1/  229] train: loss: 0.1899435
[Epoch 42; Iter    31/  229] train: loss: 0.1155424
[Epoch 42; Iter    61/  229] train: loss: 0.1220609
[Epoch 42; Iter    91/  229] train: loss: 0.1680091
[Epoch 42; Iter   121/  229] train: loss: 0.1103704
[Epoch 42; Iter   151/  229] train: loss: 0.1174617
[Epoch 42; Iter   181/  229] train: loss: 0.2175650
[Epoch 42; Iter   211/  229] train: loss: 0.1245441
[Epoch 42] ogbg-moltoxcast: 0.670079 val loss: 0.326698
[Epoch 42] ogbg-moltoxcast: 0.645481 test loss: 0.337792
[Epoch 43; Iter    12/  229] train: loss: 0.1376147
[Epoch 43; Iter    42/  229] train: loss: 0.1442790
[Epoch 43; Iter    72/  229] train: loss: 0.1881893
[Epoch 43; Iter   102/  229] train: loss: 0.1471917
[Epoch 43; Iter   132/  229] train: loss: 0.1419742
[Epoch 43; Iter   162/  229] train: loss: 0.1467105
[Epoch 43; Iter   192/  229] train: loss: 0.1412459
[Epoch 43; Iter   222/  229] train: loss: 0.1684031
[Epoch 43] ogbg-moltoxcast: 0.653489 val loss: 0.331456
[Epoch 43] ogbg-moltoxcast: 0.633897 test loss: 0.343110
[Epoch 28; Iter    27/  229] train: loss: 0.1701520
[Epoch 28; Iter    57/  229] train: loss: 0.1609580
[Epoch 28; Iter    87/  229] train: loss: 0.1545283
[Epoch 28; Iter   117/  229] train: loss: 0.1732591
[Epoch 28; Iter   147/  229] train: loss: 0.1758615
[Epoch 28; Iter   177/  229] train: loss: 0.1516692
[Epoch 28; Iter   207/  229] train: loss: 0.1840877
[Epoch 28] ogbg-moltoxcast: 0.665590 val loss: 0.283210
[Epoch 28] ogbg-moltoxcast: 0.635305 test loss: 0.336468
[Epoch 29; Iter     8/  229] train: loss: 0.1080483
[Epoch 29; Iter    38/  229] train: loss: 0.1241238
[Epoch 29; Iter    68/  229] train: loss: 0.1353698
[Epoch 29; Iter    98/  229] train: loss: 0.1962297
[Epoch 29; Iter   128/  229] train: loss: 0.1628259
[Epoch 29; Iter   158/  229] train: loss: 0.1015411
[Epoch 29; Iter   188/  229] train: loss: 0.1527618
[Epoch 29; Iter   218/  229] train: loss: 0.1379055
[Epoch 29] ogbg-moltoxcast: 0.665245 val loss: 0.282497
[Epoch 29] ogbg-moltoxcast: 0.634446 test loss: 0.329744
[Epoch 30; Iter    19/  229] train: loss: 0.1400676
[Epoch 30; Iter    49/  229] train: loss: 0.1887775
[Epoch 30; Iter    79/  229] train: loss: 0.1122976
[Epoch 30; Iter   109/  229] train: loss: 0.1679918
[Epoch 30; Iter   139/  229] train: loss: 0.1930029
[Epoch 30; Iter   169/  229] train: loss: 0.1681401
[Epoch 30; Iter   199/  229] train: loss: 0.1598783
[Epoch 30; Iter   229/  229] train: loss: 0.1720463
[Epoch 30] ogbg-moltoxcast: 0.679755 val loss: 0.286969
[Epoch 30] ogbg-moltoxcast: 0.642996 test loss: 0.342234
[Epoch 31; Iter    30/  229] train: loss: 0.2019035
[Epoch 31; Iter    60/  229] train: loss: 0.1874805
[Epoch 31; Iter    90/  229] train: loss: 0.1645787
[Epoch 31; Iter   120/  229] train: loss: 0.1471290
[Epoch 31; Iter   150/  229] train: loss: 0.1608533
[Epoch 31; Iter   180/  229] train: loss: 0.2396881
[Epoch 31; Iter   210/  229] train: loss: 0.1362474
[Epoch 31] ogbg-moltoxcast: 0.685443 val loss: 0.274226
[Epoch 31] ogbg-moltoxcast: 0.648281 test loss: 0.320632
[Epoch 32; Iter    11/  229] train: loss: 0.1407739
[Epoch 32; Iter    41/  229] train: loss: 0.1350621
[Epoch 32; Iter    71/  229] train: loss: 0.1733294
[Epoch 32; Iter   101/  229] train: loss: 0.1961631
[Epoch 32; Iter   131/  229] train: loss: 0.1063081
[Epoch 32; Iter   161/  229] train: loss: 0.1638214
[Epoch 32; Iter   191/  229] train: loss: 0.1002747
[Epoch 32; Iter   221/  229] train: loss: 0.1433015
[Epoch 32] ogbg-moltoxcast: 0.683968 val loss: 0.273529
[Epoch 32] ogbg-moltoxcast: 0.646253 test loss: 0.321566
[Epoch 33; Iter    22/  229] train: loss: 0.1157297
[Epoch 33; Iter    52/  229] train: loss: 0.1140107
[Epoch 33; Iter    82/  229] train: loss: 0.1408895
[Epoch 33; Iter   112/  229] train: loss: 0.2011698
[Epoch 33; Iter   142/  229] train: loss: 0.1166648
[Epoch 33; Iter   172/  229] train: loss: 0.1563304
[Epoch 33; Iter   202/  229] train: loss: 0.1036302
[Epoch 33] ogbg-moltoxcast: 0.676040 val loss: 0.284355
[Epoch 33] ogbg-moltoxcast: 0.643466 test loss: 0.337159
[Epoch 34; Iter     3/  229] train: loss: 0.1875810
[Epoch 34; Iter    33/  229] train: loss: 0.1611167
[Epoch 34; Iter    63/  229] train: loss: 0.1621197
[Epoch 34; Iter    93/  229] train: loss: 0.1667306
[Epoch 34; Iter   123/  229] train: loss: 0.1355936
[Epoch 34; Iter   153/  229] train: loss: 0.1354389
[Epoch 34; Iter   183/  229] train: loss: 0.1169665
[Epoch 34; Iter   213/  229] train: loss: 0.1970391
[Epoch 34] ogbg-moltoxcast: 0.661327 val loss: 0.286759
[Epoch 34] ogbg-moltoxcast: 0.635088 test loss: 0.338299
[Epoch 35; Iter    14/  229] train: loss: 0.0757879
[Epoch 35; Iter    44/  229] train: loss: 0.1733537
[Epoch 35; Iter    74/  229] train: loss: 0.1478891
[Epoch 35; Iter   104/  229] train: loss: 0.1790488
[Epoch 35; Iter   134/  229] train: loss: 0.1774362
[Epoch 35; Iter   164/  229] train: loss: 0.1646370
[Epoch 35; Iter   194/  229] train: loss: 0.1240317
[Epoch 35; Iter   224/  229] train: loss: 0.1297852
[Epoch 35] ogbg-moltoxcast: 0.676676 val loss: 0.281098
[Epoch 35] ogbg-moltoxcast: 0.644078 test loss: 0.328563
[Epoch 36; Iter    25/  229] train: loss: 0.1573965
[Epoch 36; Iter    55/  229] train: loss: 0.1719228
[Epoch 36; Iter    85/  229] train: loss: 0.1376252
[Epoch 36; Iter   115/  229] train: loss: 0.1169326
[Epoch 36; Iter   145/  229] train: loss: 0.1681629
[Epoch 36; Iter   175/  229] train: loss: 0.1934946
[Epoch 36; Iter   205/  229] train: loss: 0.1907583
[Epoch 36] ogbg-moltoxcast: 0.671541 val loss: 0.284637
[Epoch 36] ogbg-moltoxcast: 0.645323 test loss: 0.333160
[Epoch 37; Iter     6/  229] train: loss: 0.1221864
[Epoch 37; Iter    36/  229] train: loss: 0.0979053
[Epoch 37; Iter    66/  229] train: loss: 0.1439311
[Epoch 37; Iter    96/  229] train: loss: 0.1485267
[Epoch 37; Iter   126/  229] train: loss: 0.1253955
[Epoch 37; Iter   156/  229] train: loss: 0.1378989
[Epoch 37; Iter   186/  229] train: loss: 0.1346095
[Epoch 37; Iter   216/  229] train: loss: 0.1721597
[Epoch 37] ogbg-moltoxcast: 0.669559 val loss: 0.302402
[Epoch 37] ogbg-moltoxcast: 0.641773 test loss: 0.354174
[Epoch 38; Iter    17/  229] train: loss: 0.1882741
[Epoch 38; Iter    47/  229] train: loss: 0.1528880
[Epoch 38; Iter    77/  229] train: loss: 0.1276678
[Epoch 38; Iter   107/  229] train: loss: 0.1450396
[Epoch 38; Iter   137/  229] train: loss: 0.1593284
[Epoch 38; Iter   167/  229] train: loss: 0.1607761
[Epoch 38; Iter   197/  229] train: loss: 0.1629023
[Epoch 38; Iter   227/  229] train: loss: 0.1684407
[Epoch 38] ogbg-moltoxcast: 0.667539 val loss: 0.300461
[Epoch 38] ogbg-moltoxcast: 0.647098 test loss: 0.347404
[Epoch 39; Iter    28/  229] train: loss: 0.1825464
[Epoch 39; Iter    58/  229] train: loss: 0.1108698
[Epoch 39; Iter    88/  229] train: loss: 0.1144016
[Epoch 39; Iter   118/  229] train: loss: 0.2366282
[Epoch 39; Iter   148/  229] train: loss: 0.1479774
[Epoch 39; Iter   178/  229] train: loss: 0.1621659
[Epoch 39; Iter   208/  229] train: loss: 0.1940629
[Epoch 39] ogbg-moltoxcast: 0.669725 val loss: 0.293913
[Epoch 39] ogbg-moltoxcast: 0.634925 test loss: 0.342251
[Epoch 40; Iter     9/  229] train: loss: 0.1414702
[Epoch 40; Iter    39/  229] train: loss: 0.1163572
[Epoch 40; Iter    69/  229] train: loss: 0.1141963
[Epoch 40; Iter    99/  229] train: loss: 0.1878234
[Epoch 40; Iter   129/  229] train: loss: 0.1364426
[Epoch 40; Iter   159/  229] train: loss: 0.1290141
[Epoch 40; Iter   189/  229] train: loss: 0.1460721
[Epoch 40; Iter   219/  229] train: loss: 0.2050171
[Epoch 40] ogbg-moltoxcast: 0.670614 val loss: 0.303822
[Epoch 40] ogbg-moltoxcast: 0.649680 test loss: 0.341367
[Epoch 41; Iter    20/  229] train: loss: 0.1492096
[Epoch 41; Iter    50/  229] train: loss: 0.1204376
[Epoch 41; Iter    80/  229] train: loss: 0.0868130
[Epoch 41; Iter   110/  229] train: loss: 0.1076203
[Epoch 41; Iter   140/  229] train: loss: 0.1207426
[Epoch 41; Iter   170/  229] train: loss: 0.1164395
[Epoch 41; Iter   200/  229] train: loss: 0.1596586
[Epoch 41] ogbg-moltoxcast: 0.682956 val loss: 0.288397
[Epoch 41] ogbg-moltoxcast: 0.659202 test loss: 0.329671
[Epoch 42; Iter     1/  229] train: loss: 0.1661557
[Epoch 42; Iter    31/  229] train: loss: 0.1344161
[Epoch 42; Iter    61/  229] train: loss: 0.1709138
[Epoch 42; Iter    91/  229] train: loss: 0.1196113
[Epoch 42; Iter   121/  229] train: loss: 0.1648151
[Epoch 42; Iter   151/  229] train: loss: 0.1156227
[Epoch 42; Iter   181/  229] train: loss: 0.1415502
[Epoch 42; Iter   211/  229] train: loss: 0.1372065
[Epoch 42] ogbg-moltoxcast: 0.677838 val loss: 0.291110
[Epoch 42] ogbg-moltoxcast: 0.647111 test loss: 0.337407
[Epoch 43; Iter    12/  229] train: loss: 0.1704137
[Epoch 43; Iter    42/  229] train: loss: 0.1549209
[Epoch 43; Iter    72/  229] train: loss: 0.1600690
[Epoch 43; Iter   102/  229] train: loss: 0.1498383
[Epoch 43; Iter   132/  229] train: loss: 0.1113508
[Epoch 43; Iter   162/  229] train: loss: 0.1612245
[Epoch 43; Iter   192/  229] train: loss: 0.1058686
[Epoch 43; Iter   222/  229] train: loss: 0.1418133
[Epoch 43] ogbg-moltoxcast: 0.679521 val loss: 0.301657
[Epoch 43] ogbg-moltoxcast: 0.653735 test loss: 0.352077
[Epoch 28; Iter    27/  229] train: loss: 0.1919594
[Epoch 28; Iter    57/  229] train: loss: 0.1574798
[Epoch 28; Iter    87/  229] train: loss: 0.1625783
[Epoch 28; Iter   117/  229] train: loss: 0.2238629
[Epoch 28; Iter   147/  229] train: loss: 0.1722721
[Epoch 28; Iter   177/  229] train: loss: 0.1768188
[Epoch 28; Iter   207/  229] train: loss: 0.1929976
[Epoch 28] ogbg-moltoxcast: 0.659595 val loss: 0.565821
[Epoch 28] ogbg-moltoxcast: 0.629783 test loss: 1.017795
[Epoch 29; Iter     8/  229] train: loss: 0.1424893
[Epoch 29; Iter    38/  229] train: loss: 0.1365689
[Epoch 29; Iter    68/  229] train: loss: 0.2025500
[Epoch 29; Iter    98/  229] train: loss: 0.1897001
[Epoch 29; Iter   128/  229] train: loss: 0.2473404
[Epoch 29; Iter   158/  229] train: loss: 0.1515309
[Epoch 29; Iter   188/  229] train: loss: 0.1959427
[Epoch 29; Iter   218/  229] train: loss: 0.1488484
[Epoch 29] ogbg-moltoxcast: 0.658645 val loss: 0.933536
[Epoch 29] ogbg-moltoxcast: 0.631659 test loss: 1.810715
[Epoch 30; Iter    19/  229] train: loss: 0.1669138
[Epoch 30; Iter    49/  229] train: loss: 0.2110987
[Epoch 30; Iter    79/  229] train: loss: 0.1362281
[Epoch 30; Iter   109/  229] train: loss: 0.1307154
[Epoch 30; Iter   139/  229] train: loss: 0.1584683
[Epoch 30; Iter   169/  229] train: loss: 0.1536044
[Epoch 30; Iter   199/  229] train: loss: 0.1147758
[Epoch 30; Iter   229/  229] train: loss: 0.2384809
[Epoch 30] ogbg-moltoxcast: 0.659630 val loss: 0.965350
[Epoch 30] ogbg-moltoxcast: 0.640023 test loss: 2.726358
[Epoch 31; Iter    30/  229] train: loss: 0.1509089
[Epoch 31; Iter    60/  229] train: loss: 0.1582429
[Epoch 31; Iter    90/  229] train: loss: 0.1398126
[Epoch 31; Iter   120/  229] train: loss: 0.1045888
[Epoch 31; Iter   150/  229] train: loss: 0.1867575
[Epoch 31; Iter   180/  229] train: loss: 0.1369881
[Epoch 31; Iter   210/  229] train: loss: 0.0830864
[Epoch 31] ogbg-moltoxcast: 0.664820 val loss: 0.751697
[Epoch 31] ogbg-moltoxcast: 0.631230 test loss: 2.143103
[Epoch 32; Iter    11/  229] train: loss: 0.1790229
[Epoch 32; Iter    41/  229] train: loss: 0.1236621
[Epoch 32; Iter    71/  229] train: loss: 0.1187172
[Epoch 32; Iter   101/  229] train: loss: 0.1474427
[Epoch 32; Iter   131/  229] train: loss: 0.1463706
[Epoch 32; Iter   161/  229] train: loss: 0.1289791
[Epoch 32; Iter   191/  229] train: loss: 0.1494374
[Epoch 32; Iter   221/  229] train: loss: 0.1042151
[Epoch 32] ogbg-moltoxcast: 0.653187 val loss: 0.877811
[Epoch 32] ogbg-moltoxcast: 0.625123 test loss: 2.225125
[Epoch 33; Iter    22/  229] train: loss: 0.2163040
[Epoch 33; Iter    52/  229] train: loss: 0.1658910
[Epoch 33; Iter    82/  229] train: loss: 0.1371625
[Epoch 33; Iter   112/  229] train: loss: 0.1598421
[Epoch 33; Iter   142/  229] train: loss: 0.1659878
[Epoch 33; Iter   172/  229] train: loss: 0.1242742
[Epoch 33; Iter   202/  229] train: loss: 0.1414299
[Epoch 33] ogbg-moltoxcast: 0.665648 val loss: 0.654396
[Epoch 33] ogbg-moltoxcast: 0.631677 test loss: 1.228166
[Epoch 34; Iter     3/  229] train: loss: 0.1335860
[Epoch 34; Iter    33/  229] train: loss: 0.2119998
[Epoch 34; Iter    63/  229] train: loss: 0.1769114
[Epoch 34; Iter    93/  229] train: loss: 0.1875403
[Epoch 34; Iter   123/  229] train: loss: 0.1174682
[Epoch 34; Iter   153/  229] train: loss: 0.1257177
[Epoch 34; Iter   183/  229] train: loss: 0.1810354
[Epoch 34; Iter   213/  229] train: loss: 0.1699955
[Epoch 34] ogbg-moltoxcast: 0.660326 val loss: 0.990345
[Epoch 34] ogbg-moltoxcast: 0.629365 test loss: 2.721607
[Epoch 35; Iter    14/  229] train: loss: 0.1762082
[Epoch 35; Iter    44/  229] train: loss: 0.1225624
[Epoch 35; Iter    74/  229] train: loss: 0.1414162
[Epoch 35; Iter   104/  229] train: loss: 0.2712773
[Epoch 35; Iter   134/  229] train: loss: 0.1190926
[Epoch 35; Iter   164/  229] train: loss: 0.1558782
[Epoch 35; Iter   194/  229] train: loss: 0.1459463
[Epoch 35; Iter   224/  229] train: loss: 0.1332578
[Epoch 35] ogbg-moltoxcast: 0.665832 val loss: 1.165397
[Epoch 35] ogbg-moltoxcast: 0.631441 test loss: 3.127166
[Epoch 36; Iter    25/  229] train: loss: 0.1486720
[Epoch 36; Iter    55/  229] train: loss: 0.1813000
[Epoch 36; Iter    85/  229] train: loss: 0.1338923
[Epoch 36; Iter   115/  229] train: loss: 0.1297374
[Epoch 36; Iter   145/  229] train: loss: 0.1256327
[Epoch 36; Iter   175/  229] train: loss: 0.1306768
[Epoch 36; Iter   205/  229] train: loss: 0.1678528
[Epoch 36] ogbg-moltoxcast: 0.652985 val loss: 1.327166
[Epoch 36] ogbg-moltoxcast: 0.629461 test loss: 3.318365
[Epoch 37; Iter     6/  229] train: loss: 0.1518446
[Epoch 37; Iter    36/  229] train: loss: 0.2175541
[Epoch 37; Iter    66/  229] train: loss: 0.1294988
[Epoch 37; Iter    96/  229] train: loss: 0.1534201
[Epoch 37; Iter   126/  229] train: loss: 0.1380676
[Epoch 37; Iter   156/  229] train: loss: 0.1558558
[Epoch 37; Iter   186/  229] train: loss: 0.1120738
[Epoch 37; Iter   216/  229] train: loss: 0.1493816
[Epoch 37] ogbg-moltoxcast: 0.655231 val loss: 0.846772
[Epoch 37] ogbg-moltoxcast: 0.633885 test loss: 1.838886
[Epoch 38; Iter    17/  229] train: loss: 0.1809332
[Epoch 38; Iter    47/  229] train: loss: 0.1470921
[Epoch 38; Iter    77/  229] train: loss: 0.1390514
[Epoch 38; Iter   107/  229] train: loss: 0.1554448
[Epoch 38; Iter   137/  229] train: loss: 0.1156556
[Epoch 38; Iter   167/  229] train: loss: 0.1280780
[Epoch 38; Iter   197/  229] train: loss: 0.1818484
[Epoch 38; Iter   227/  229] train: loss: 0.1248648
[Epoch 38] ogbg-moltoxcast: 0.652680 val loss: 1.240462
[Epoch 38] ogbg-moltoxcast: 0.626577 test loss: 2.853254
[Epoch 39; Iter    28/  229] train: loss: 0.1800756
[Epoch 39; Iter    58/  229] train: loss: 0.1522136
[Epoch 39; Iter    88/  229] train: loss: 0.1597765
[Epoch 39; Iter   118/  229] train: loss: 0.2069311
[Epoch 39; Iter   148/  229] train: loss: 0.1502190
[Epoch 39; Iter   178/  229] train: loss: 0.1682164
[Epoch 39; Iter   208/  229] train: loss: 0.1490433
[Epoch 39] ogbg-moltoxcast: 0.648245 val loss: 0.807365
[Epoch 39] ogbg-moltoxcast: 0.623577 test loss: 1.759856
[Epoch 40; Iter     9/  229] train: loss: 0.1243317
[Epoch 40; Iter    39/  229] train: loss: 0.1955156
[Epoch 40; Iter    69/  229] train: loss: 0.1734735
[Epoch 40; Iter    99/  229] train: loss: 0.0761533
[Epoch 40; Iter   129/  229] train: loss: 0.1653715
[Epoch 40; Iter   159/  229] train: loss: 0.1116385
[Epoch 40; Iter   189/  229] train: loss: 0.1191678
[Epoch 40; Iter   219/  229] train: loss: 0.1733434
[Epoch 40] ogbg-moltoxcast: 0.655924 val loss: 1.640924
[Epoch 40] ogbg-moltoxcast: 0.626867 test loss: 3.491345
[Epoch 41; Iter    20/  229] train: loss: 0.1389308
[Epoch 41; Iter    50/  229] train: loss: 0.1791243
[Epoch 41; Iter    80/  229] train: loss: 0.1578028
[Epoch 41; Iter   110/  229] train: loss: 0.1663473
[Epoch 41; Iter   140/  229] train: loss: 0.1400825
[Epoch 41; Iter   170/  229] train: loss: 0.1219322
[Epoch 41; Iter   200/  229] train: loss: 0.1710284
[Epoch 41] ogbg-moltoxcast: 0.653578 val loss: 1.326784
[Epoch 41] ogbg-moltoxcast: 0.626964 test loss: 2.977648
[Epoch 42; Iter     1/  229] train: loss: 0.1850017
[Epoch 42; Iter    31/  229] train: loss: 0.1083250
[Epoch 42; Iter    61/  229] train: loss: 0.1168598
[Epoch 42; Iter    91/  229] train: loss: 0.1627112
[Epoch 42; Iter   121/  229] train: loss: 0.1039990
[Epoch 42; Iter   151/  229] train: loss: 0.1265370
[Epoch 42; Iter   181/  229] train: loss: 0.2415205
[Epoch 42; Iter   211/  229] train: loss: 0.1181758
[Epoch 42] ogbg-moltoxcast: 0.643846 val loss: 1.439531
[Epoch 42] ogbg-moltoxcast: 0.627327 test loss: 3.076910
[Epoch 43; Iter    12/  229] train: loss: 0.1352284
[Epoch 43; Iter    42/  229] train: loss: 0.1483712
[Epoch 43; Iter    72/  229] train: loss: 0.1840957
[Epoch 43; Iter   102/  229] train: loss: 0.1530637
[Epoch 43; Iter   132/  229] train: loss: 0.1417497
[Epoch 43; Iter   162/  229] train: loss: 0.1409530
[Epoch 43; Iter   192/  229] train: loss: 0.1363099
[Epoch 43; Iter   222/  229] train: loss: 0.1653714
[Epoch 43] ogbg-moltoxcast: 0.638324 val loss: 1.479033
[Epoch 43] ogbg-moltoxcast: 0.625929 test loss: 3.148759
[Epoch 28; Iter    27/  229] train: loss: 0.1880047
[Epoch 28; Iter    57/  229] train: loss: 0.1601903
[Epoch 28; Iter    87/  229] train: loss: 0.1514683
[Epoch 28; Iter   117/  229] train: loss: 0.1785594
[Epoch 28; Iter   147/  229] train: loss: 0.1799250
[Epoch 28; Iter   177/  229] train: loss: 0.1450460
[Epoch 28; Iter   207/  229] train: loss: 0.1666589
[Epoch 28] ogbg-moltoxcast: 0.663350 val loss: 0.292858
[Epoch 28] ogbg-moltoxcast: 0.646111 test loss: 0.335414
[Epoch 29; Iter     8/  229] train: loss: 0.1090553
[Epoch 29; Iter    38/  229] train: loss: 0.1184981
[Epoch 29; Iter    68/  229] train: loss: 0.1371941
[Epoch 29; Iter    98/  229] train: loss: 0.1891406
[Epoch 29; Iter   128/  229] train: loss: 0.1454696
[Epoch 29; Iter   158/  229] train: loss: 0.0962218
[Epoch 29; Iter   188/  229] train: loss: 0.1489972
[Epoch 29; Iter   218/  229] train: loss: 0.1338317
[Epoch 29] ogbg-moltoxcast: 0.662547 val loss: 0.295237
[Epoch 29] ogbg-moltoxcast: 0.636555 test loss: 0.343643
[Epoch 30; Iter    19/  229] train: loss: 0.1395111
[Epoch 30; Iter    49/  229] train: loss: 0.1908456
[Epoch 30; Iter    79/  229] train: loss: 0.1147715
[Epoch 30; Iter   109/  229] train: loss: 0.1733337
[Epoch 30; Iter   139/  229] train: loss: 0.1654299
[Epoch 30; Iter   169/  229] train: loss: 0.1741681
[Epoch 30; Iter   199/  229] train: loss: 0.1530281
[Epoch 30; Iter   229/  229] train: loss: 0.1784780
[Epoch 30] ogbg-moltoxcast: 0.667886 val loss: 0.293019
[Epoch 30] ogbg-moltoxcast: 0.657473 test loss: 0.335397
[Epoch 31; Iter    30/  229] train: loss: 0.1989453
[Epoch 31; Iter    60/  229] train: loss: 0.1843360
[Epoch 31; Iter    90/  229] train: loss: 0.1615625
[Epoch 31; Iter   120/  229] train: loss: 0.1486736
[Epoch 31; Iter   150/  229] train: loss: 0.1522073
[Epoch 31; Iter   180/  229] train: loss: 0.2478458
[Epoch 31; Iter   210/  229] train: loss: 0.1252050
[Epoch 31] ogbg-moltoxcast: 0.664843 val loss: 0.294042
[Epoch 31] ogbg-moltoxcast: 0.648804 test loss: 0.329917
[Epoch 32; Iter    11/  229] train: loss: 0.1425491
[Epoch 32; Iter    41/  229] train: loss: 0.1339999
[Epoch 32; Iter    71/  229] train: loss: 0.1699160
[Epoch 32; Iter   101/  229] train: loss: 0.1957653
[Epoch 32; Iter   131/  229] train: loss: 0.1169885
[Epoch 32; Iter   161/  229] train: loss: 0.1644214
[Epoch 32; Iter   191/  229] train: loss: 0.1035263
[Epoch 32; Iter   221/  229] train: loss: 0.1388253
[Epoch 32] ogbg-moltoxcast: 0.660946 val loss: 0.298196
[Epoch 32] ogbg-moltoxcast: 0.641620 test loss: 0.347821
[Epoch 33; Iter    22/  229] train: loss: 0.1069042
[Epoch 33; Iter    52/  229] train: loss: 0.1239375
[Epoch 33; Iter    82/  229] train: loss: 0.1522090
[Epoch 33; Iter   112/  229] train: loss: 0.1975446
[Epoch 33; Iter   142/  229] train: loss: 0.1177648
[Epoch 33; Iter   172/  229] train: loss: 0.1553155
[Epoch 33; Iter   202/  229] train: loss: 0.1030959
[Epoch 33] ogbg-moltoxcast: 0.672708 val loss: 0.288357
[Epoch 33] ogbg-moltoxcast: 0.654071 test loss: 0.330928
[Epoch 34; Iter     3/  229] train: loss: 0.1798347
[Epoch 34; Iter    33/  229] train: loss: 0.1551321
[Epoch 34; Iter    63/  229] train: loss: 0.1562391
[Epoch 34; Iter    93/  229] train: loss: 0.1621705
[Epoch 34; Iter   123/  229] train: loss: 0.1386023
[Epoch 34; Iter   153/  229] train: loss: 0.1338585
[Epoch 34; Iter   183/  229] train: loss: 0.1188709
[Epoch 34; Iter   213/  229] train: loss: 0.2011320
[Epoch 34] ogbg-moltoxcast: 0.656598 val loss: 0.293225
[Epoch 34] ogbg-moltoxcast: 0.642745 test loss: 0.341590
[Epoch 35; Iter    14/  229] train: loss: 0.0778804
[Epoch 35; Iter    44/  229] train: loss: 0.1586421
[Epoch 35; Iter    74/  229] train: loss: 0.1418732
[Epoch 35; Iter   104/  229] train: loss: 0.1877117
[Epoch 35; Iter   134/  229] train: loss: 0.1829173
[Epoch 35; Iter   164/  229] train: loss: 0.1556133
[Epoch 35; Iter   194/  229] train: loss: 0.1172850
[Epoch 35; Iter   224/  229] train: loss: 0.1218697
[Epoch 35] ogbg-moltoxcast: 0.660878 val loss: 0.302860
[Epoch 35] ogbg-moltoxcast: 0.647834 test loss: 0.350546
[Epoch 36; Iter    25/  229] train: loss: 0.1619715
[Epoch 36; Iter    55/  229] train: loss: 0.1561344
[Epoch 36; Iter    85/  229] train: loss: 0.1387319
[Epoch 36; Iter   115/  229] train: loss: 0.1170472
[Epoch 36; Iter   145/  229] train: loss: 0.1717762
[Epoch 36; Iter   175/  229] train: loss: 0.1643730
[Epoch 36; Iter   205/  229] train: loss: 0.1735463
[Epoch 36] ogbg-moltoxcast: 0.662249 val loss: 0.296167
[Epoch 36] ogbg-moltoxcast: 0.644966 test loss: 0.346997
[Epoch 37; Iter     6/  229] train: loss: 0.1191974
[Epoch 37; Iter    36/  229] train: loss: 0.0882505
[Epoch 37; Iter    66/  229] train: loss: 0.1466735
[Epoch 37; Iter    96/  229] train: loss: 0.1331422
[Epoch 37; Iter   126/  229] train: loss: 0.1245441
[Epoch 37; Iter   156/  229] train: loss: 0.1255496
[Epoch 37; Iter   186/  229] train: loss: 0.1331414
[Epoch 37; Iter   216/  229] train: loss: 0.1548763
[Epoch 37] ogbg-moltoxcast: 0.661289 val loss: 0.292401
[Epoch 37] ogbg-moltoxcast: 0.648805 test loss: 0.341123
[Epoch 38; Iter    17/  229] train: loss: 0.1788475
[Epoch 38; Iter    47/  229] train: loss: 0.1438881
[Epoch 38; Iter    77/  229] train: loss: 0.1231631
[Epoch 38; Iter   107/  229] train: loss: 0.1491110
[Epoch 38; Iter   137/  229] train: loss: 0.1618432
[Epoch 38; Iter   167/  229] train: loss: 0.1533090
[Epoch 38; Iter   197/  229] train: loss: 0.1523217
[Epoch 38; Iter   227/  229] train: loss: 0.1618209
[Epoch 38] ogbg-moltoxcast: 0.658771 val loss: 0.298519
[Epoch 38] ogbg-moltoxcast: 0.645257 test loss: 0.346480
[Epoch 39; Iter    28/  229] train: loss: 0.1750474
[Epoch 39; Iter    58/  229] train: loss: 0.0998735
[Epoch 39; Iter    88/  229] train: loss: 0.1112493
[Epoch 39; Iter   118/  229] train: loss: 0.2225097
[Epoch 39; Iter   148/  229] train: loss: 0.1403602
[Epoch 39; Iter   178/  229] train: loss: 0.1524704
[Epoch 39; Iter   208/  229] train: loss: 0.1840586
[Epoch 39] ogbg-moltoxcast: 0.662541 val loss: 0.286449
[Epoch 39] ogbg-moltoxcast: 0.648460 test loss: 0.330519
[Epoch 40; Iter     9/  229] train: loss: 0.1382885
[Epoch 40; Iter    39/  229] train: loss: 0.1096208
[Epoch 40; Iter    69/  229] train: loss: 0.1131384
[Epoch 40; Iter    99/  229] train: loss: 0.1802271
[Epoch 40; Iter   129/  229] train: loss: 0.1301709
[Epoch 40; Iter   159/  229] train: loss: 0.1197697
[Epoch 40; Iter   189/  229] train: loss: 0.1416422
[Epoch 40; Iter   219/  229] train: loss: 0.1983330
[Epoch 40] ogbg-moltoxcast: 0.662315 val loss: 0.300021
[Epoch 40] ogbg-moltoxcast: 0.649484 test loss: 0.350391
[Epoch 41; Iter    20/  229] train: loss: 0.1500895
[Epoch 41; Iter    50/  229] train: loss: 0.1162633
[Epoch 41; Iter    80/  229] train: loss: 0.0884657
[Epoch 41; Iter   110/  229] train: loss: 0.1029892
[Epoch 41; Iter   140/  229] train: loss: 0.1116971
[Epoch 41; Iter   170/  229] train: loss: 0.1061495
[Epoch 41; Iter   200/  229] train: loss: 0.1431530
[Epoch 41] ogbg-moltoxcast: 0.655514 val loss: 0.302205
[Epoch 41] ogbg-moltoxcast: 0.642745 test loss: 0.348150
[Epoch 42; Iter     1/  229] train: loss: 0.1601324
[Epoch 42; Iter    31/  229] train: loss: 0.1303742
[Epoch 42; Iter    61/  229] train: loss: 0.1717328
[Epoch 42; Iter    91/  229] train: loss: 0.1183298
[Epoch 42; Iter   121/  229] train: loss: 0.1559036
[Epoch 42; Iter   151/  229] train: loss: 0.1155400
[Epoch 42; Iter   181/  229] train: loss: 0.1371852
[Epoch 42; Iter   211/  229] train: loss: 0.1376619
[Epoch 42] ogbg-moltoxcast: 0.661648 val loss: 0.306195
[Epoch 42] ogbg-moltoxcast: 0.645556 test loss: 0.350535
[Epoch 43; Iter    12/  229] train: loss: 0.1793161
[Epoch 43; Iter    42/  229] train: loss: 0.1565885
[Epoch 43; Iter    72/  229] train: loss: 0.1541136
[Epoch 43; Iter   102/  229] train: loss: 0.1553588
[Epoch 43; Iter   132/  229] train: loss: 0.1141665
[Epoch 43; Iter   162/  229] train: loss: 0.1633240
[Epoch 43; Iter   192/  229] train: loss: 0.1038361
[Epoch 43; Iter   222/  229] train: loss: 0.1426098
[Epoch 43] ogbg-moltoxcast: 0.660258 val loss: 0.311724
[Epoch 43] ogbg-moltoxcast: 0.646960 test loss: 0.360918
[Epoch 28; Iter    27/  229] train: loss: 0.1804906
[Epoch 28; Iter    57/  229] train: loss: 0.1677948
[Epoch 28; Iter    87/  229] train: loss: 0.1810977
[Epoch 28; Iter   117/  229] train: loss: 0.1916670
[Epoch 28; Iter   147/  229] train: loss: 0.1796816
[Epoch 28; Iter   177/  229] train: loss: 0.1507664
[Epoch 28; Iter   207/  229] train: loss: 0.1688792
[Epoch 28] ogbg-moltoxcast: 0.693720 val loss: 0.245627
[Epoch 28] ogbg-moltoxcast: 0.670616 test loss: 0.289120
[Epoch 29; Iter     8/  229] train: loss: 0.1141936
[Epoch 29; Iter    38/  229] train: loss: 0.1370973
[Epoch 29; Iter    68/  229] train: loss: 0.1412105
[Epoch 29; Iter    98/  229] train: loss: 0.1886519
[Epoch 29; Iter   128/  229] train: loss: 0.1427448
[Epoch 29; Iter   158/  229] train: loss: 0.0996458
[Epoch 29; Iter   188/  229] train: loss: 0.1513176
[Epoch 29; Iter   218/  229] train: loss: 0.1321684
[Epoch 29] ogbg-moltoxcast: 0.674414 val loss: 0.253715
[Epoch 29] ogbg-moltoxcast: 0.658744 test loss: 0.300962
[Epoch 30; Iter    19/  229] train: loss: 0.1397133
[Epoch 30; Iter    49/  229] train: loss: 0.1891928
[Epoch 30; Iter    79/  229] train: loss: 0.1381797
[Epoch 30; Iter   109/  229] train: loss: 0.2237042
[Epoch 30; Iter   139/  229] train: loss: 0.1776862
[Epoch 30; Iter   169/  229] train: loss: 0.1804734
[Epoch 30; Iter   199/  229] train: loss: 0.1526955
[Epoch 30; Iter   229/  229] train: loss: 0.1800812
[Epoch 30] ogbg-moltoxcast: 0.687671 val loss: 0.246365
[Epoch 30] ogbg-moltoxcast: 0.662047 test loss: 0.299589
[Epoch 31; Iter    30/  229] train: loss: 0.2195875
[Epoch 31; Iter    60/  229] train: loss: 0.1857907
[Epoch 31; Iter    90/  229] train: loss: 0.1765064
[Epoch 31; Iter   120/  229] train: loss: 0.1649299
[Epoch 31; Iter   150/  229] train: loss: 0.1610939
[Epoch 31; Iter   180/  229] train: loss: 0.2375444
[Epoch 31; Iter   210/  229] train: loss: 0.1503874
[Epoch 31] ogbg-moltoxcast: 0.687707 val loss: 0.250069
[Epoch 31] ogbg-moltoxcast: 0.659031 test loss: 0.296451
[Epoch 32; Iter    11/  229] train: loss: 0.1374040
[Epoch 32; Iter    41/  229] train: loss: 0.1309551
[Epoch 32; Iter    71/  229] train: loss: 0.1755384
[Epoch 32; Iter   101/  229] train: loss: 0.2074222
[Epoch 32; Iter   131/  229] train: loss: 0.1165391
[Epoch 32; Iter   161/  229] train: loss: 0.1800284
[Epoch 32; Iter   191/  229] train: loss: 0.0968977
[Epoch 32; Iter   221/  229] train: loss: 0.1438645
[Epoch 32] ogbg-moltoxcast: 0.693069 val loss: 0.251440
[Epoch 32] ogbg-moltoxcast: 0.666376 test loss: 0.296164
[Epoch 33; Iter    22/  229] train: loss: 0.1100311
[Epoch 33; Iter    52/  229] train: loss: 0.1243983
[Epoch 33; Iter    82/  229] train: loss: 0.1511376
[Epoch 33; Iter   112/  229] train: loss: 0.1896861
[Epoch 33; Iter   142/  229] train: loss: 0.1205849
[Epoch 33; Iter   172/  229] train: loss: 0.1602729
[Epoch 33; Iter   202/  229] train: loss: 0.1050409
[Epoch 33] ogbg-moltoxcast: 0.699719 val loss: 0.247337
[Epoch 33] ogbg-moltoxcast: 0.666397 test loss: 0.297464
[Epoch 34; Iter     3/  229] train: loss: 0.1857276
[Epoch 34; Iter    33/  229] train: loss: 0.1570891
[Epoch 34; Iter    63/  229] train: loss: 0.1533593
[Epoch 34; Iter    93/  229] train: loss: 0.1679578
[Epoch 34; Iter   123/  229] train: loss: 0.1415334
[Epoch 34; Iter   153/  229] train: loss: 0.1378734
[Epoch 34; Iter   183/  229] train: loss: 0.1149435
[Epoch 34; Iter   213/  229] train: loss: 0.2195612
[Epoch 34] ogbg-moltoxcast: 0.695269 val loss: 0.249867
[Epoch 34] ogbg-moltoxcast: 0.652044 test loss: 0.306107
[Epoch 35; Iter    14/  229] train: loss: 0.0802066
[Epoch 35; Iter    44/  229] train: loss: 0.1630746
[Epoch 35; Iter    74/  229] train: loss: 0.1495540
[Epoch 35; Iter   104/  229] train: loss: 0.2185297
[Epoch 35; Iter   134/  229] train: loss: 0.2105287
[Epoch 35; Iter   164/  229] train: loss: 0.1705889
[Epoch 35; Iter   194/  229] train: loss: 0.1232739
[Epoch 35; Iter   224/  229] train: loss: 0.1292361
[Epoch 35] ogbg-moltoxcast: 0.703177 val loss: 0.243088
[Epoch 35] ogbg-moltoxcast: 0.667376 test loss: 0.296923
[Epoch 36; Iter    25/  229] train: loss: 0.1877056
[Epoch 36; Iter    55/  229] train: loss: 0.1769383
[Epoch 36; Iter    85/  229] train: loss: 0.1353533
[Epoch 36; Iter   115/  229] train: loss: 0.1163262
[Epoch 36; Iter   145/  229] train: loss: 0.1683885
[Epoch 36; Iter   175/  229] train: loss: 0.1797391
[Epoch 36; Iter   205/  229] train: loss: 0.1821753
[Epoch 36] ogbg-moltoxcast: 0.706063 val loss: 0.241751
[Epoch 36] ogbg-moltoxcast: 0.672278 test loss: 0.293549
[Epoch 37; Iter     6/  229] train: loss: 0.1210583
[Epoch 37; Iter    36/  229] train: loss: 0.1065296
[Epoch 37; Iter    66/  229] train: loss: 0.1454109
[Epoch 37; Iter    96/  229] train: loss: 0.1408393
[Epoch 37; Iter   126/  229] train: loss: 0.1329903
[Epoch 37; Iter   156/  229] train: loss: 0.1374083
[Epoch 37; Iter   186/  229] train: loss: 0.1624172
[Epoch 37; Iter   216/  229] train: loss: 0.1588652
[Epoch 37] ogbg-moltoxcast: 0.709683 val loss: 0.244071
[Epoch 37] ogbg-moltoxcast: 0.669065 test loss: 0.304409
[Epoch 38; Iter    17/  229] train: loss: 0.1929893
[Epoch 38; Iter    47/  229] train: loss: 0.1576326
[Epoch 38; Iter    77/  229] train: loss: 0.1265544
[Epoch 38; Iter   107/  229] train: loss: 0.1527235
[Epoch 38; Iter   137/  229] train: loss: 0.1677513
[Epoch 38; Iter   167/  229] train: loss: 0.1489541
[Epoch 38; Iter   197/  229] train: loss: 0.1566027
[Epoch 38; Iter   227/  229] train: loss: 0.1631030
[Epoch 38] ogbg-moltoxcast: 0.693302 val loss: 0.248857
[Epoch 38] ogbg-moltoxcast: 0.664234 test loss: 0.302823
[Epoch 39; Iter    28/  229] train: loss: 0.2007020
[Epoch 39; Iter    58/  229] train: loss: 0.1063890
[Epoch 39; Iter    88/  229] train: loss: 0.1232864
[Epoch 39; Iter   118/  229] train: loss: 0.2280517
[Epoch 39; Iter   148/  229] train: loss: 0.1383274
[Epoch 39; Iter   178/  229] train: loss: 0.1698025
[Epoch 39; Iter   208/  229] train: loss: 0.1937408
[Epoch 39] ogbg-moltoxcast: 0.710829 val loss: 0.241499
[Epoch 39] ogbg-moltoxcast: 0.673035 test loss: 0.301794
[Epoch 40; Iter     9/  229] train: loss: 0.1402897
[Epoch 40; Iter    39/  229] train: loss: 0.1267117
[Epoch 40; Iter    69/  229] train: loss: 0.1084431
[Epoch 40; Iter    99/  229] train: loss: 0.1810246
[Epoch 40; Iter   129/  229] train: loss: 0.1417255
[Epoch 40; Iter   159/  229] train: loss: 0.1424425
[Epoch 40; Iter   189/  229] train: loss: 0.1537899
[Epoch 40; Iter   219/  229] train: loss: 0.2111025
[Epoch 40] ogbg-moltoxcast: 0.702986 val loss: 0.250187
[Epoch 40] ogbg-moltoxcast: 0.670273 test loss: 0.305517
[Epoch 41; Iter    20/  229] train: loss: 0.1554391
[Epoch 41; Iter    50/  229] train: loss: 0.1250298
[Epoch 41; Iter    80/  229] train: loss: 0.0880734
[Epoch 41; Iter   110/  229] train: loss: 0.1050289
[Epoch 41; Iter   140/  229] train: loss: 0.1148083
[Epoch 41; Iter   170/  229] train: loss: 0.1023075
[Epoch 41; Iter   200/  229] train: loss: 0.1632411
[Epoch 41] ogbg-moltoxcast: 0.694853 val loss: 0.248887
[Epoch 41] ogbg-moltoxcast: 0.667945 test loss: 0.304567
[Epoch 42; Iter     1/  229] train: loss: 0.1873815
[Epoch 42; Iter    31/  229] train: loss: 0.1516476
[Epoch 42; Iter    61/  229] train: loss: 0.1704703
[Epoch 42; Iter    91/  229] train: loss: 0.1283574
[Epoch 42; Iter   121/  229] train: loss: 0.1727035
[Epoch 42; Iter   151/  229] train: loss: 0.1156188
[Epoch 42; Iter   181/  229] train: loss: 0.1416802
[Epoch 42; Iter   211/  229] train: loss: 0.1732008
[Epoch 42] ogbg-moltoxcast: 0.699850 val loss: 0.248538
[Epoch 42] ogbg-moltoxcast: 0.668314 test loss: 0.303468
[Epoch 43; Iter    12/  229] train: loss: 0.1800794
[Epoch 43; Iter    42/  229] train: loss: 0.1564389
[Epoch 43; Iter    72/  229] train: loss: 0.1728386
[Epoch 43; Iter   102/  229] train: loss: 0.1535136
[Epoch 43; Iter   132/  229] train: loss: 0.1155936
[Epoch 43; Iter   162/  229] train: loss: 0.1805917
[Epoch 43; Iter   192/  229] train: loss: 0.1106549
[Epoch 43; Iter   222/  229] train: loss: 0.1460388
[Epoch 43] ogbg-moltoxcast: 0.708028 val loss: 0.253126
[Epoch 43] ogbg-moltoxcast: 0.672005 test loss: 0.306486
[Epoch 28; Iter    27/  229] train: loss: 0.1959793
[Epoch 28; Iter    57/  229] train: loss: 0.1622398
[Epoch 28; Iter    87/  229] train: loss: 0.1788285
[Epoch 28; Iter   117/  229] train: loss: 0.2261155
[Epoch 28; Iter   147/  229] train: loss: 0.1807061
[Epoch 28; Iter   177/  229] train: loss: 0.1974852
[Epoch 28; Iter   207/  229] train: loss: 0.1954296
[Epoch 28] ogbg-moltoxcast: 0.686831 val loss: 0.253417
[Epoch 28] ogbg-moltoxcast: 0.650171 test loss: 0.296605
[Epoch 29; Iter     8/  229] train: loss: 0.1460022
[Epoch 29; Iter    38/  229] train: loss: 0.1604516
[Epoch 29; Iter    68/  229] train: loss: 0.2128867
[Epoch 29; Iter    98/  229] train: loss: 0.2193058
[Epoch 29; Iter   128/  229] train: loss: 0.2608933
[Epoch 29; Iter   158/  229] train: loss: 0.1631743
[Epoch 29; Iter   188/  229] train: loss: 0.2175925
[Epoch 29; Iter   218/  229] train: loss: 0.1612574
[Epoch 29] ogbg-moltoxcast: 0.696259 val loss: 0.249906
[Epoch 29] ogbg-moltoxcast: 0.652858 test loss: 0.297244
[Epoch 30; Iter    19/  229] train: loss: 0.1726867
[Epoch 30; Iter    49/  229] train: loss: 0.2200778
[Epoch 30; Iter    79/  229] train: loss: 0.1304166
[Epoch 30; Iter   109/  229] train: loss: 0.1251259
[Epoch 30; Iter   139/  229] train: loss: 0.1464689
[Epoch 30; Iter   169/  229] train: loss: 0.1590269
[Epoch 30; Iter   199/  229] train: loss: 0.1286953
[Epoch 30; Iter   229/  229] train: loss: 0.2571579
[Epoch 30] ogbg-moltoxcast: 0.697020 val loss: 0.253617
[Epoch 30] ogbg-moltoxcast: 0.648405 test loss: 0.304539
[Epoch 31; Iter    30/  229] train: loss: 0.1488892
[Epoch 31; Iter    60/  229] train: loss: 0.1651564
[Epoch 31; Iter    90/  229] train: loss: 0.1634546
[Epoch 31; Iter   120/  229] train: loss: 0.1133380
[Epoch 31; Iter   150/  229] train: loss: 0.2100105
[Epoch 31; Iter   180/  229] train: loss: 0.1522098
[Epoch 31; Iter   210/  229] train: loss: 0.0752453
[Epoch 31] ogbg-moltoxcast: 0.694449 val loss: 0.254730
[Epoch 31] ogbg-moltoxcast: 0.656817 test loss: 0.304095
[Epoch 32; Iter    11/  229] train: loss: 0.1879049
[Epoch 32; Iter    41/  229] train: loss: 0.1271812
[Epoch 32; Iter    71/  229] train: loss: 0.1176183
[Epoch 32; Iter   101/  229] train: loss: 0.1480847
[Epoch 32; Iter   131/  229] train: loss: 0.1687411
[Epoch 32; Iter   161/  229] train: loss: 0.1564748
[Epoch 32; Iter   191/  229] train: loss: 0.1649015
[Epoch 32; Iter   221/  229] train: loss: 0.1108593
[Epoch 32] ogbg-moltoxcast: 0.684319 val loss: 0.250201
[Epoch 32] ogbg-moltoxcast: 0.643710 test loss: 0.299936
[Epoch 33; Iter    22/  229] train: loss: 0.2233648
[Epoch 33; Iter    52/  229] train: loss: 0.1733945
[Epoch 33; Iter    82/  229] train: loss: 0.1661218
[Epoch 33; Iter   112/  229] train: loss: 0.1483719
[Epoch 33; Iter   142/  229] train: loss: 0.1694000
[Epoch 33; Iter   172/  229] train: loss: 0.1149087
[Epoch 33; Iter   202/  229] train: loss: 0.1363325
[Epoch 33] ogbg-moltoxcast: 0.701142 val loss: 0.258938
[Epoch 33] ogbg-moltoxcast: 0.666253 test loss: 0.291717
[Epoch 34; Iter     3/  229] train: loss: 0.1337494
[Epoch 34; Iter    33/  229] train: loss: 0.2163477
[Epoch 34; Iter    63/  229] train: loss: 0.1690646
[Epoch 34; Iter    93/  229] train: loss: 0.1999548
[Epoch 34; Iter   123/  229] train: loss: 0.1384102
[Epoch 34; Iter   153/  229] train: loss: 0.1251322
[Epoch 34; Iter   183/  229] train: loss: 0.1766251
[Epoch 34; Iter   213/  229] train: loss: 0.1918631
[Epoch 34] ogbg-moltoxcast: 0.702336 val loss: 0.251734
[Epoch 34] ogbg-moltoxcast: 0.653429 test loss: 0.299668
[Epoch 35; Iter    14/  229] train: loss: 0.1828977
[Epoch 35; Iter    44/  229] train: loss: 0.1360049
[Epoch 35; Iter    74/  229] train: loss: 0.1687690
[Epoch 35; Iter   104/  229] train: loss: 0.2850485
[Epoch 35; Iter   134/  229] train: loss: 0.1305012
[Epoch 35; Iter   164/  229] train: loss: 0.1572755
[Epoch 35; Iter   194/  229] train: loss: 0.1445884
[Epoch 35; Iter   224/  229] train: loss: 0.1410698
[Epoch 35] ogbg-moltoxcast: 0.695400 val loss: 0.252359
[Epoch 35] ogbg-moltoxcast: 0.654935 test loss: 0.306385
[Epoch 36; Iter    25/  229] train: loss: 0.1634819
[Epoch 36; Iter    55/  229] train: loss: 0.1958353
[Epoch 36; Iter    85/  229] train: loss: 0.1349014
[Epoch 36; Iter   115/  229] train: loss: 0.1341814
[Epoch 36; Iter   145/  229] train: loss: 0.1275164
[Epoch 36; Iter   175/  229] train: loss: 0.1426063
[Epoch 36; Iter   205/  229] train: loss: 0.1734776
[Epoch 36] ogbg-moltoxcast: 0.698303 val loss: 0.252493
[Epoch 36] ogbg-moltoxcast: 0.659462 test loss: 0.307335
[Epoch 37; Iter     6/  229] train: loss: 0.1626164
[Epoch 37; Iter    36/  229] train: loss: 0.2212426
[Epoch 37; Iter    66/  229] train: loss: 0.1364330
[Epoch 37; Iter    96/  229] train: loss: 0.1732051
[Epoch 37; Iter   126/  229] train: loss: 0.1359060
[Epoch 37; Iter   156/  229] train: loss: 0.1635937
[Epoch 37; Iter   186/  229] train: loss: 0.1151219
[Epoch 37; Iter   216/  229] train: loss: 0.1449236
[Epoch 37] ogbg-moltoxcast: 0.696380 val loss: 0.250479
[Epoch 37] ogbg-moltoxcast: 0.656113 test loss: 0.304467
[Epoch 38; Iter    17/  229] train: loss: 0.1743572
[Epoch 38; Iter    47/  229] train: loss: 0.1566024
[Epoch 38; Iter    77/  229] train: loss: 0.1491607
[Epoch 38; Iter   107/  229] train: loss: 0.1541395
[Epoch 38; Iter   137/  229] train: loss: 0.1179104
[Epoch 38; Iter   167/  229] train: loss: 0.1298213
[Epoch 38; Iter   197/  229] train: loss: 0.1921939
[Epoch 38; Iter   227/  229] train: loss: 0.1358166
[Epoch 38] ogbg-moltoxcast: 0.700205 val loss: 0.247566
[Epoch 38] ogbg-moltoxcast: 0.659130 test loss: 0.294185
[Epoch 39; Iter    28/  229] train: loss: 0.1769650
[Epoch 39; Iter    58/  229] train: loss: 0.1488233
[Epoch 39; Iter    88/  229] train: loss: 0.1520748
[Epoch 39; Iter   118/  229] train: loss: 0.2141246
[Epoch 39; Iter   148/  229] train: loss: 0.1552882
[Epoch 39; Iter   178/  229] train: loss: 0.1772263
[Epoch 39; Iter   208/  229] train: loss: 0.1586387
[Epoch 39] ogbg-moltoxcast: 0.697263 val loss: 0.254426
[Epoch 39] ogbg-moltoxcast: 0.663782 test loss: 0.327186
[Epoch 40; Iter     9/  229] train: loss: 0.1357020
[Epoch 40; Iter    39/  229] train: loss: 0.2025067
[Epoch 40; Iter    69/  229] train: loss: 0.1673775
[Epoch 40; Iter    99/  229] train: loss: 0.0835987
[Epoch 40; Iter   129/  229] train: loss: 0.1820152
[Epoch 40; Iter   159/  229] train: loss: 0.1213848
[Epoch 40; Iter   189/  229] train: loss: 0.1164203
[Epoch 40; Iter   219/  229] train: loss: 0.1791365
[Epoch 40] ogbg-moltoxcast: 0.694937 val loss: 0.255561
[Epoch 40] ogbg-moltoxcast: 0.659008 test loss: 0.324226
[Epoch 41; Iter    20/  229] train: loss: 0.1362617
[Epoch 41; Iter    50/  229] train: loss: 0.1759953
[Epoch 41; Iter    80/  229] train: loss: 0.1871481
[Epoch 41; Iter   110/  229] train: loss: 0.1819727
[Epoch 41; Iter   140/  229] train: loss: 0.1590610
[Epoch 41; Iter   170/  229] train: loss: 0.1298469
[Epoch 41; Iter   200/  229] train: loss: 0.1890531
[Epoch 41] ogbg-moltoxcast: 0.698749 val loss: 0.247795
[Epoch 41] ogbg-moltoxcast: 0.664521 test loss: 0.301580
[Epoch 42; Iter     1/  229] train: loss: 0.2048857
[Epoch 42; Iter    31/  229] train: loss: 0.1096003
[Epoch 42; Iter    61/  229] train: loss: 0.1244426
[Epoch 42; Iter    91/  229] train: loss: 0.1840647
[Epoch 42; Iter   121/  229] train: loss: 0.1485376
[Epoch 42; Iter   151/  229] train: loss: 0.1330691
[Epoch 42; Iter   181/  229] train: loss: 0.2389257
[Epoch 42; Iter   211/  229] train: loss: 0.1207535
[Epoch 42] ogbg-moltoxcast: 0.692371 val loss: 0.254032
[Epoch 42] ogbg-moltoxcast: 0.657880 test loss: 0.316624
[Epoch 43; Iter    12/  229] train: loss: 0.1358000
[Epoch 43; Iter    42/  229] train: loss: 0.1464342
[Epoch 43; Iter    72/  229] train: loss: 0.1985695
[Epoch 43; Iter   102/  229] train: loss: 0.1491936
[Epoch 43; Iter   132/  229] train: loss: 0.1436464
[Epoch 43; Iter   162/  229] train: loss: 0.1481121
[Epoch 43; Iter   192/  229] train: loss: 0.1548614
[Epoch 43; Iter   222/  229] train: loss: 0.1703611
[Epoch 43] ogbg-moltoxcast: 0.691011 val loss: 0.259502
[Epoch 43] ogbg-moltoxcast: 0.665181 test loss: 0.302092
[Epoch 28; Iter    27/  229] train: loss: 0.1856921
[Epoch 28; Iter    57/  229] train: loss: 0.2030910
[Epoch 28; Iter    87/  229] train: loss: 0.1559065
[Epoch 28; Iter   117/  229] train: loss: 0.2542165
[Epoch 28; Iter   147/  229] train: loss: 0.1823002
[Epoch 28; Iter   177/  229] train: loss: 0.1515741
[Epoch 28; Iter   207/  229] train: loss: 0.1939169
[Epoch 28] ogbg-moltoxcast: 0.673018 val loss: 0.249662
[Epoch 28] ogbg-moltoxcast: 0.651823 test loss: 0.292238
[Epoch 29; Iter     8/  229] train: loss: 0.2720024
[Epoch 29; Iter    38/  229] train: loss: 0.2061773
[Epoch 29; Iter    68/  229] train: loss: 0.2946199
[Epoch 29; Iter    98/  229] train: loss: 0.1565517
[Epoch 29; Iter   128/  229] train: loss: 0.1477233
[Epoch 29; Iter   158/  229] train: loss: 0.2014819
[Epoch 29; Iter   188/  229] train: loss: 0.1268263
[Epoch 29; Iter   218/  229] train: loss: 0.1910850
[Epoch 29] ogbg-moltoxcast: 0.688257 val loss: 0.253094
[Epoch 29] ogbg-moltoxcast: 0.669380 test loss: 0.296466
[Epoch 30; Iter    19/  229] train: loss: 0.1241153
[Epoch 30; Iter    49/  229] train: loss: 0.1241478
[Epoch 30; Iter    79/  229] train: loss: 0.2370460
[Epoch 30; Iter   109/  229] train: loss: 0.1447555
[Epoch 30; Iter   139/  229] train: loss: 0.1772231
[Epoch 30; Iter   169/  229] train: loss: 0.1913823
[Epoch 30; Iter   199/  229] train: loss: 0.1708760
[Epoch 30; Iter   229/  229] train: loss: 0.1467449
[Epoch 30] ogbg-moltoxcast: 0.674394 val loss: 0.258365
[Epoch 30] ogbg-moltoxcast: 0.655853 test loss: 0.292224
[Epoch 31; Iter    30/  229] train: loss: 0.0926125
[Epoch 31; Iter    60/  229] train: loss: 0.1368621
[Epoch 31; Iter    90/  229] train: loss: 0.1438294
[Epoch 31; Iter   120/  229] train: loss: 0.0689224
[Epoch 31; Iter   150/  229] train: loss: 0.1810136
[Epoch 31; Iter   180/  229] train: loss: 0.1553413
[Epoch 31; Iter   210/  229] train: loss: 0.1901201
[Epoch 31] ogbg-moltoxcast: 0.676546 val loss: 0.282052
[Epoch 31] ogbg-moltoxcast: 0.641221 test loss: 0.329767
[Epoch 32; Iter    11/  229] train: loss: 0.2019366
[Epoch 32; Iter    41/  229] train: loss: 0.1779133
[Epoch 32; Iter    71/  229] train: loss: 0.1625519
[Epoch 32; Iter   101/  229] train: loss: 0.1539523
[Epoch 32; Iter   131/  229] train: loss: 0.2450758
[Epoch 32; Iter   161/  229] train: loss: 0.1513941
[Epoch 32; Iter   191/  229] train: loss: 0.1499531
[Epoch 32; Iter   221/  229] train: loss: 0.1058898
[Epoch 32] ogbg-moltoxcast: 0.684817 val loss: 0.261283
[Epoch 32] ogbg-moltoxcast: 0.656292 test loss: 0.298185
[Epoch 33; Iter    22/  229] train: loss: 0.1523441
[Epoch 33; Iter    52/  229] train: loss: 0.1602553
[Epoch 33; Iter    82/  229] train: loss: 0.1682498
[Epoch 33; Iter   112/  229] train: loss: 0.1925893
[Epoch 33; Iter   142/  229] train: loss: 0.1622968
[Epoch 33; Iter   172/  229] train: loss: 0.1540873
[Epoch 33; Iter   202/  229] train: loss: 0.1556899
[Epoch 33] ogbg-moltoxcast: 0.686671 val loss: 0.260686
[Epoch 33] ogbg-moltoxcast: 0.656828 test loss: 0.298959
[Epoch 34; Iter     3/  229] train: loss: 0.2022137
[Epoch 34; Iter    33/  229] train: loss: 0.1347714
[Epoch 34; Iter    63/  229] train: loss: 0.1965781
[Epoch 34; Iter    93/  229] train: loss: 0.1724370
[Epoch 34; Iter   123/  229] train: loss: 0.1633974
[Epoch 34; Iter   153/  229] train: loss: 0.1360705
[Epoch 34; Iter   183/  229] train: loss: 0.1450668
[Epoch 34; Iter   213/  229] train: loss: 0.1845978
[Epoch 34] ogbg-moltoxcast: 0.668712 val loss: 0.257128
[Epoch 34] ogbg-moltoxcast: 0.653355 test loss: 0.297772
[Epoch 35; Iter    14/  229] train: loss: 0.1477713
[Epoch 35; Iter    44/  229] train: loss: 0.1246685
[Epoch 35; Iter    74/  229] train: loss: 0.1044099
[Epoch 35; Iter   104/  229] train: loss: 0.1712612
[Epoch 35; Iter   134/  229] train: loss: 0.1508224
[Epoch 35; Iter   164/  229] train: loss: 0.1383554
[Epoch 35; Iter   194/  229] train: loss: 0.1832431
[Epoch 35; Iter   224/  229] train: loss: 0.1535958
[Epoch 35] ogbg-moltoxcast: 0.682493 val loss: 0.258486
[Epoch 35] ogbg-moltoxcast: 0.651317 test loss: 0.296317
[Epoch 36; Iter    25/  229] train: loss: 0.1573418
[Epoch 36; Iter    55/  229] train: loss: 0.1651306
[Epoch 36; Iter    85/  229] train: loss: 0.1569454
[Epoch 36; Iter   115/  229] train: loss: 0.1212999
[Epoch 36; Iter   145/  229] train: loss: 0.1885910
[Epoch 36; Iter   175/  229] train: loss: 0.1217951
[Epoch 36; Iter   205/  229] train: loss: 0.1597630
[Epoch 36] ogbg-moltoxcast: 0.687292 val loss: 0.253520
[Epoch 36] ogbg-moltoxcast: 0.661662 test loss: 0.297358
[Epoch 37; Iter     6/  229] train: loss: 0.1680611
[Epoch 37; Iter    36/  229] train: loss: 0.1434132
[Epoch 37; Iter    66/  229] train: loss: 0.2381792
[Epoch 37; Iter    96/  229] train: loss: 0.1214948
[Epoch 37; Iter   126/  229] train: loss: 0.1482205
[Epoch 37; Iter   156/  229] train: loss: 0.1704121
[Epoch 37; Iter   186/  229] train: loss: 0.1684789
[Epoch 37; Iter   216/  229] train: loss: 0.1706571
[Epoch 37] ogbg-moltoxcast: 0.686463 val loss: 0.247795
[Epoch 37] ogbg-moltoxcast: 0.651834 test loss: 0.299839
[Epoch 38; Iter    17/  229] train: loss: 0.1298230
[Epoch 38; Iter    47/  229] train: loss: 0.1714351
[Epoch 38; Iter    77/  229] train: loss: 0.1254000
[Epoch 38; Iter   107/  229] train: loss: 0.1292186
[Epoch 38; Iter   137/  229] train: loss: 0.1634227
[Epoch 38; Iter   167/  229] train: loss: 0.1352151
[Epoch 38; Iter   197/  229] train: loss: 0.1668819
[Epoch 38; Iter   227/  229] train: loss: 0.1367699
[Epoch 38] ogbg-moltoxcast: 0.689123 val loss: 0.258659
[Epoch 38] ogbg-moltoxcast: 0.656369 test loss: 0.298012
[Epoch 39; Iter    28/  229] train: loss: 0.1730765
[Epoch 39; Iter    58/  229] train: loss: 0.1227888
[Epoch 39; Iter    88/  229] train: loss: 0.1526801
[Epoch 39; Iter   118/  229] train: loss: 0.1846553
[Epoch 39; Iter   148/  229] train: loss: 0.1623298
[Epoch 39; Iter   178/  229] train: loss: 0.1306119
[Epoch 39; Iter   208/  229] train: loss: 0.1196766
[Epoch 39] ogbg-moltoxcast: 0.693870 val loss: 0.245251
[Epoch 39] ogbg-moltoxcast: 0.662297 test loss: 0.290929
[Epoch 40; Iter     9/  229] train: loss: 0.1619762
[Epoch 40; Iter    39/  229] train: loss: 0.1302041
[Epoch 40; Iter    69/  229] train: loss: 0.1746906
[Epoch 40; Iter    99/  229] train: loss: 0.1176807
[Epoch 40; Iter   129/  229] train: loss: 0.1842653
[Epoch 40; Iter   159/  229] train: loss: 0.1358513
[Epoch 40; Iter   189/  229] train: loss: 0.1628369
[Epoch 40; Iter   219/  229] train: loss: 0.1468215
[Epoch 40] ogbg-moltoxcast: 0.690822 val loss: 0.248176
[Epoch 40] ogbg-moltoxcast: 0.655257 test loss: 0.297546
[Epoch 41; Iter    20/  229] train: loss: 0.1782230
[Epoch 41; Iter    50/  229] train: loss: 0.1307581
[Epoch 41; Iter    80/  229] train: loss: 0.2104521
[Epoch 41; Iter   110/  229] train: loss: 0.0722584
[Epoch 41; Iter   140/  229] train: loss: 0.1787193
[Epoch 41; Iter   170/  229] train: loss: 0.1992550
[Epoch 41; Iter   200/  229] train: loss: 0.1521409
[Epoch 41] ogbg-moltoxcast: 0.692625 val loss: 0.254186
[Epoch 41] ogbg-moltoxcast: 0.663653 test loss: 0.300407
[Epoch 42; Iter     1/  229] train: loss: 0.1500375
[Epoch 42; Iter    31/  229] train: loss: 0.1214597
[Epoch 42; Iter    61/  229] train: loss: 0.1241102
[Epoch 42; Iter    91/  229] train: loss: 0.1858382
[Epoch 42; Iter   121/  229] train: loss: 0.1987613
[Epoch 42; Iter   151/  229] train: loss: 0.1203951
[Epoch 42; Iter   181/  229] train: loss: 0.1434333
[Epoch 42; Iter   211/  229] train: loss: 0.1268248
[Epoch 42] ogbg-moltoxcast: 0.681977 val loss: 0.253610
[Epoch 42] ogbg-moltoxcast: 0.664226 test loss: 0.297029
[Epoch 43; Iter    12/  229] train: loss: 0.0925457
[Epoch 43; Iter    42/  229] train: loss: 0.1792540
[Epoch 43; Iter    72/  229] train: loss: 0.1323097
[Epoch 43; Iter   102/  229] train: loss: 0.1727019
[Epoch 43; Iter   132/  229] train: loss: 0.1180943
[Epoch 43; Iter   162/  229] train: loss: 0.0995131
[Epoch 43; Iter   192/  229] train: loss: 0.1719520
[Epoch 43; Iter   222/  229] train: loss: 0.1353814
[Epoch 43] ogbg-moltoxcast: 0.685371 val loss: 0.247437
[Epoch 43] ogbg-moltoxcast: 0.662014 test loss: 0.298934
[Epoch 44; Iter    23/  229] train: loss: 0.1772265
[Epoch 44; Iter    53/  229] train: loss: 0.0952646
[Epoch 44; Iter    83/  229] train: loss: 0.1453519
[Epoch 44; Iter   113/  229] train: loss: 0.0932244
[Epoch 44; Iter   143/  229] train: loss: 0.1426628
[Epoch 44; Iter   173/  229] train: loss: 0.1192334
[Epoch 44; Iter   203/  229] train: loss: 0.1364610
[Epoch 44] ogbg-moltoxcast: 0.693154 val loss: 0.266336
[Epoch 44] ogbg-moltoxcast: 0.654820 test loss: 0.322817
[Epoch 45; Iter     4/  229] train: loss: 0.1154327
[Epoch 45; Iter    34/  229] train: loss: 0.1232779
[Epoch 45; Iter    64/  229] train: loss: 0.1613856
[Epoch 45; Iter    94/  229] train: loss: 0.1158131
[Epoch 45; Iter   124/  229] train: loss: 0.1461619
[Epoch 45; Iter   154/  229] train: loss: 0.1314729
[Epoch 45; Iter   184/  229] train: loss: 0.1500367
[Epoch 45; Iter   214/  229] train: loss: 0.1563197
[Epoch 45] ogbg-moltoxcast: 0.687943 val loss: 0.278294
[Epoch 45] ogbg-moltoxcast: 0.660826 test loss: 0.330611
[Epoch 46; Iter    15/  229] train: loss: 0.1322235
[Epoch 46; Iter    45/  229] train: loss: 0.1603040
[Epoch 46; Iter    75/  229] train: loss: 0.1902521
[Epoch 46; Iter   105/  229] train: loss: 0.1470672
[Epoch 46; Iter   135/  229] train: loss: 0.1469743
[Epoch 46; Iter   165/  229] train: loss: 0.1245041
[Epoch 46; Iter   195/  229] train: loss: 0.1419022
[Epoch 46; Iter   225/  229] train: loss: 0.1443650
[Epoch 46] ogbg-moltoxcast: 0.697650 val loss: 0.271107
[Epoch 46] ogbg-moltoxcast: 0.662292 test loss: 0.325385
[Epoch 47; Iter    26/  229] train: loss: 0.1512761
[Epoch 47; Iter    56/  229] train: loss: 0.1573081
[Epoch 47; Iter    86/  229] train: loss: 0.1263496
[Epoch 47; Iter   116/  229] train: loss: 0.0856854
[Epoch 47; Iter   146/  229] train: loss: 0.1043919
[Epoch 47; Iter   176/  229] train: loss: 0.1523594
[Epoch 47; Iter   206/  229] train: loss: 0.1229055
[Epoch 47] ogbg-moltoxcast: 0.686753 val loss: 0.274101
[Epoch 47] ogbg-moltoxcast: 0.656293 test loss: 0.328594
[Epoch 48; Iter     7/  229] train: loss: 0.1192113
[Epoch 48; Iter    37/  229] train: loss: 0.1157264
[Epoch 48; Iter    67/  229] train: loss: 0.1434986
[Epoch 48; Iter    97/  229] train: loss: 0.1594898
[Epoch 48; Iter   127/  229] train: loss: 0.1518287
[Epoch 48; Iter   157/  229] train: loss: 0.1094666
[Epoch 48; Iter   187/  229] train: loss: 0.1865622
[Epoch 48; Iter   217/  229] train: loss: 0.1352881
[Epoch 48] ogbg-moltoxcast: 0.685441 val loss: 0.267505
[Epoch 48] ogbg-moltoxcast: 0.651727 test loss: 0.322519
[Epoch 49; Iter    18/  229] train: loss: 0.1721803
[Epoch 49; Iter    48/  229] train: loss: 0.1094799
[Epoch 49; Iter    78/  229] train: loss: 0.1858695
[Epoch 49; Iter   108/  229] train: loss: 0.1309721
[Epoch 49; Iter   138/  229] train: loss: 0.1488609
[Epoch 49; Iter   168/  229] train: loss: 0.1187292
[Epoch 49; Iter   198/  229] train: loss: 0.1388926
[Epoch 49; Iter   228/  229] train: loss: 0.1354757
[Epoch 49] ogbg-moltoxcast: 0.692627 val loss: 0.273200
[Epoch 49] ogbg-moltoxcast: 0.659200 test loss: 0.327245
[Epoch 50; Iter    29/  229] train: loss: 0.1513767
[Epoch 50; Iter    59/  229] train: loss: 0.1290817
[Epoch 50; Iter    89/  229] train: loss: 0.1552435
[Epoch 50; Iter   119/  229] train: loss: 0.1131746
[Epoch 50; Iter   149/  229] train: loss: 0.1661929
[Epoch 50; Iter   179/  229] train: loss: 0.1720306
[Epoch 50; Iter   209/  229] train: loss: 0.1954468
[Epoch 50] ogbg-moltoxcast: 0.694994 val loss: 0.280583
[Epoch 50] ogbg-moltoxcast: 0.659021 test loss: 0.340415
[Epoch 51; Iter    10/  229] train: loss: 0.1489046
[Epoch 51; Iter    40/  229] train: loss: 0.0997308
[Epoch 51; Iter    70/  229] train: loss: 0.1513629
[Epoch 51; Iter   100/  229] train: loss: 0.1400257
[Epoch 51; Iter   130/  229] train: loss: 0.1276515
[Epoch 51; Iter   160/  229] train: loss: 0.1036525
[Epoch 51; Iter   190/  229] train: loss: 0.1132174
[Epoch 51; Iter   220/  229] train: loss: 0.1492572
[Epoch 51] ogbg-moltoxcast: 0.695140 val loss: 0.308535
[Epoch 51] ogbg-moltoxcast: 0.657285 test loss: 0.354670
[Epoch 52; Iter    21/  229] train: loss: 0.1387124
[Epoch 52; Iter    51/  229] train: loss: 0.1215641
[Epoch 52; Iter    81/  229] train: loss: 0.1461703
[Epoch 52; Iter   111/  229] train: loss: 0.1166066
[Epoch 52; Iter   141/  229] train: loss: 0.1189362
[Epoch 52; Iter   171/  229] train: loss: 0.0847764
[Epoch 52; Iter   201/  229] train: loss: 0.1300686
[Epoch 52] ogbg-moltoxcast: 0.696592 val loss: 0.272443
[Epoch 52] ogbg-moltoxcast: 0.658649 test loss: 0.329101
[Epoch 53; Iter     2/  229] train: loss: 0.1065180
[Epoch 53; Iter    32/  229] train: loss: 0.0829437
[Epoch 53; Iter    62/  229] train: loss: 0.1239531
[Epoch 53; Iter    92/  229] train: loss: 0.1121171
[Epoch 53; Iter   122/  229] train: loss: 0.0982128
[Epoch 53; Iter   152/  229] train: loss: 0.1522409
[Epoch 53; Iter   182/  229] train: loss: 0.1234590
[Epoch 53; Iter   212/  229] train: loss: 0.1443938
[Epoch 53] ogbg-moltoxcast: 0.691929 val loss: 0.266640
[Epoch 53] ogbg-moltoxcast: 0.654006 test loss: 0.320621
[Epoch 54; Iter    13/  229] train: loss: 0.0863109
[Epoch 54; Iter    43/  229] train: loss: 0.0987269
[Epoch 54; Iter    73/  229] train: loss: 0.1040135
[Epoch 54; Iter   103/  229] train: loss: 0.1005476
[Epoch 54; Iter   133/  229] train: loss: 0.1176717
[Epoch 54; Iter   163/  229] train: loss: 0.1207284
[Epoch 54; Iter   193/  229] train: loss: 0.1516635
[Epoch 54; Iter   223/  229] train: loss: 0.1554478
[Epoch 54] ogbg-moltoxcast: 0.695162 val loss: 0.288862
[Epoch 54] ogbg-moltoxcast: 0.661490 test loss: 0.330002
[Epoch 55; Iter    24/  229] train: loss: 0.1576811
[Epoch 55; Iter    54/  229] train: loss: 0.1595403
[Epoch 55; Iter    84/  229] train: loss: 0.1119919
[Epoch 55; Iter   114/  229] train: loss: 0.1336851
[Epoch 55; Iter   144/  229] train: loss: 0.1362358
[Epoch 55; Iter   174/  229] train: loss: 0.1372720
[Epoch 55; Iter   204/  229] train: loss: 0.1557620
[Epoch 55] ogbg-moltoxcast: 0.698066 val loss: 0.272640
[Epoch 55] ogbg-moltoxcast: 0.657832 test loss: 0.328564
[Epoch 56; Iter     5/  229] train: loss: 0.1438691
[Epoch 56; Iter    35/  229] train: loss: 0.0996674
[Epoch 56; Iter    65/  229] train: loss: 0.1770172
[Epoch 56; Iter    95/  229] train: loss: 0.1298829
[Epoch 56; Iter   125/  229] train: loss: 0.1378091
[Epoch 56; Iter   155/  229] train: loss: 0.1383988
[Epoch 56; Iter   185/  229] train: loss: 0.1588039
[Epoch 56; Iter   215/  229] train: loss: 0.1150508
[Epoch 56] ogbg-moltoxcast: 0.697101 val loss: 0.272909
[Epoch 56] ogbg-moltoxcast: 0.658004 test loss: 0.330116
[Epoch 57; Iter    16/  229] train: loss: 0.1939633
[Epoch 57; Iter    46/  229] train: loss: 0.1426852
[Epoch 57; Iter    76/  229] train: loss: 0.1034210
[Epoch 57; Iter   106/  229] train: loss: 0.1576301
[Epoch 57; Iter   136/  229] train: loss: 0.1056560
[Epoch 57; Iter   166/  229] train: loss: 0.0863859
[Epoch 57; Iter   196/  229] train: loss: 0.1356153
[Epoch 57; Iter   226/  229] train: loss: 0.2111452
[Epoch 57] ogbg-moltoxcast: 0.694748 val loss: 0.273127
[Epoch 57] ogbg-moltoxcast: 0.656166 test loss: 0.325785
[Epoch 58; Iter    27/  229] train: loss: 0.1292208
[Epoch 58; Iter    57/  229] train: loss: 0.1568189
[Epoch 58; Iter    87/  229] train: loss: 0.1371649
[Epoch 58; Iter   117/  229] train: loss: 0.1507076
[Epoch 58; Iter   147/  229] train: loss: 0.1770842
[Epoch 58; Iter   177/  229] train: loss: 0.2013453
[Epoch 58; Iter   207/  229] train: loss: 0.1202159
[Epoch 58] ogbg-moltoxcast: 0.691403 val loss: 0.272119
[Epoch 58] ogbg-moltoxcast: 0.655510 test loss: 0.325576
[Epoch 59; Iter     8/  229] train: loss: 0.1265875
[Epoch 59; Iter    38/  229] train: loss: 0.1094835
[Epoch 59; Iter    68/  229] train: loss: 0.1160539
[Epoch 59; Iter    98/  229] train: loss: 0.1098042
[Epoch 59; Iter   128/  229] train: loss: 0.1189955
[Epoch 59; Iter   158/  229] train: loss: 0.1253257
[Epoch 59; Iter   188/  229] train: loss: 0.1126105
[Epoch 59; Iter   218/  229] train: loss: 0.1201498
[Epoch 59] ogbg-moltoxcast: 0.685602 val loss: 0.282356
[Epoch 59] ogbg-moltoxcast: 0.656363 test loss: 0.333960
[Epoch 44; Iter    23/  229] train: loss: 0.1979344
[Epoch 44; Iter    53/  229] train: loss: 0.0899988
[Epoch 44; Iter    83/  229] train: loss: 0.1333466
[Epoch 44; Iter   113/  229] train: loss: 0.1281425
[Epoch 44; Iter   143/  229] train: loss: 0.1677541
[Epoch 44; Iter   173/  229] train: loss: 0.1572597
[Epoch 44; Iter   203/  229] train: loss: 0.1411285
[Epoch 44] ogbg-moltoxcast: 0.702122 val loss: 0.274395
[Epoch 44] ogbg-moltoxcast: 0.667620 test loss: 0.312076
[Epoch 45; Iter     4/  229] train: loss: 0.1197733
[Epoch 45; Iter    34/  229] train: loss: 0.1228387
[Epoch 45; Iter    64/  229] train: loss: 0.1536287
[Epoch 45; Iter    94/  229] train: loss: 0.0936677
[Epoch 45; Iter   124/  229] train: loss: 0.1412483
[Epoch 45; Iter   154/  229] train: loss: 0.1180143
[Epoch 45; Iter   184/  229] train: loss: 0.1044311
[Epoch 45; Iter   214/  229] train: loss: 0.0924193
[Epoch 45] ogbg-moltoxcast: 0.700046 val loss: 0.277314
[Epoch 45] ogbg-moltoxcast: 0.664107 test loss: 0.320106
[Epoch 46; Iter    15/  229] train: loss: 0.1509593
[Epoch 46; Iter    45/  229] train: loss: 0.1715284
[Epoch 46; Iter    75/  229] train: loss: 0.1381470
[Epoch 46; Iter   105/  229] train: loss: 0.1720978
[Epoch 46; Iter   135/  229] train: loss: 0.1548660
[Epoch 46; Iter   165/  229] train: loss: 0.1336891
[Epoch 46; Iter   195/  229] train: loss: 0.1338870
[Epoch 46; Iter   225/  229] train: loss: 0.1395703
[Epoch 46] ogbg-moltoxcast: 0.695918 val loss: 0.274094
[Epoch 46] ogbg-moltoxcast: 0.665883 test loss: 0.316201
[Epoch 47; Iter    26/  229] train: loss: 0.1590456
[Epoch 47; Iter    56/  229] train: loss: 0.1654902
[Epoch 47; Iter    86/  229] train: loss: 0.1356991
[Epoch 47; Iter   116/  229] train: loss: 0.1233562
[Epoch 47; Iter   146/  229] train: loss: 0.1149874
[Epoch 47; Iter   176/  229] train: loss: 0.0951599
[Epoch 47; Iter   206/  229] train: loss: 0.1240110
[Epoch 47] ogbg-moltoxcast: 0.700067 val loss: 0.270752
[Epoch 47] ogbg-moltoxcast: 0.666293 test loss: 0.310804
[Epoch 48; Iter     7/  229] train: loss: 0.1405530
[Epoch 48; Iter    37/  229] train: loss: 0.1352394
[Epoch 48; Iter    67/  229] train: loss: 0.1226943
[Epoch 48; Iter    97/  229] train: loss: 0.1467160
[Epoch 48; Iter   127/  229] train: loss: 0.1489029
[Epoch 48; Iter   157/  229] train: loss: 0.1033108
[Epoch 48; Iter   187/  229] train: loss: 0.1478152
[Epoch 48; Iter   217/  229] train: loss: 0.1444936
[Epoch 48] ogbg-moltoxcast: 0.702042 val loss: 0.276220
[Epoch 48] ogbg-moltoxcast: 0.663120 test loss: 0.318759
[Epoch 49; Iter    18/  229] train: loss: 0.1555725
[Epoch 49; Iter    48/  229] train: loss: 0.1332625
[Epoch 49; Iter    78/  229] train: loss: 0.0893382
[Epoch 49; Iter   108/  229] train: loss: 0.1235659
[Epoch 49; Iter   138/  229] train: loss: 0.1171093
[Epoch 49; Iter   168/  229] train: loss: 0.1262826
[Epoch 49; Iter   198/  229] train: loss: 0.1375647
[Epoch 49; Iter   228/  229] train: loss: 0.1508142
[Epoch 49] ogbg-moltoxcast: 0.690210 val loss: 0.279298
[Epoch 49] ogbg-moltoxcast: 0.662002 test loss: 0.321689
[Epoch 50; Iter    29/  229] train: loss: 0.1072017
[Epoch 50; Iter    59/  229] train: loss: 0.1345923
[Epoch 50; Iter    89/  229] train: loss: 0.0811742
[Epoch 50; Iter   119/  229] train: loss: 0.1660159
[Epoch 50; Iter   149/  229] train: loss: 0.1283005
[Epoch 50; Iter   179/  229] train: loss: 0.1367351
[Epoch 50; Iter   209/  229] train: loss: 0.1044352
[Epoch 50] ogbg-moltoxcast: 0.690389 val loss: 0.276077
[Epoch 50] ogbg-moltoxcast: 0.657339 test loss: 0.321711
[Epoch 51; Iter    10/  229] train: loss: 0.1450328
[Epoch 51; Iter    40/  229] train: loss: 0.1023005
[Epoch 51; Iter    70/  229] train: loss: 0.1411104
[Epoch 51; Iter   100/  229] train: loss: 0.1438534
[Epoch 51; Iter   130/  229] train: loss: 0.1109205
[Epoch 51; Iter   160/  229] train: loss: 0.1136403
[Epoch 51; Iter   190/  229] train: loss: 0.1355919
[Epoch 51; Iter   220/  229] train: loss: 0.1604904
[Epoch 51] ogbg-moltoxcast: 0.692182 val loss: 0.284840
[Epoch 51] ogbg-moltoxcast: 0.655314 test loss: 0.331386
[Epoch 52; Iter    21/  229] train: loss: 0.1194224
[Epoch 52; Iter    51/  229] train: loss: 0.1449316
[Epoch 52; Iter    81/  229] train: loss: 0.1270840
[Epoch 52; Iter   111/  229] train: loss: 0.1775262
[Epoch 52; Iter   141/  229] train: loss: 0.1376322
[Epoch 52; Iter   171/  229] train: loss: 0.1500749
[Epoch 52; Iter   201/  229] train: loss: 0.1223302
[Epoch 52] ogbg-moltoxcast: 0.687997 val loss: 0.281469
[Epoch 52] ogbg-moltoxcast: 0.656447 test loss: 0.321733
[Epoch 53; Iter     2/  229] train: loss: 0.0942766
[Epoch 53; Iter    32/  229] train: loss: 0.1229165
[Epoch 53; Iter    62/  229] train: loss: 0.1411881
[Epoch 53; Iter    92/  229] train: loss: 0.1610081
[Epoch 53; Iter   122/  229] train: loss: 0.0806802
[Epoch 53; Iter   152/  229] train: loss: 0.1174963
[Epoch 53; Iter   182/  229] train: loss: 0.1219767
[Epoch 53; Iter   212/  229] train: loss: 0.1224309
[Epoch 53] ogbg-moltoxcast: 0.692544 val loss: 0.280133
[Epoch 53] ogbg-moltoxcast: 0.651832 test loss: 0.321958
[Epoch 54; Iter    13/  229] train: loss: 0.0850228
[Epoch 54; Iter    43/  229] train: loss: 0.1468411
[Epoch 54; Iter    73/  229] train: loss: 0.1116560
[Epoch 54; Iter   103/  229] train: loss: 0.1244644
[Epoch 54; Iter   133/  229] train: loss: 0.1323850
[Epoch 54; Iter   163/  229] train: loss: 0.1567456
[Epoch 54; Iter   193/  229] train: loss: 0.1548398
[Epoch 54; Iter   223/  229] train: loss: 0.1641664
[Epoch 54] ogbg-moltoxcast: 0.689981 val loss: 0.295573
[Epoch 54] ogbg-moltoxcast: 0.657555 test loss: 0.328813
[Epoch 55; Iter    24/  229] train: loss: 0.1675583
[Epoch 55; Iter    54/  229] train: loss: 0.1765193
[Epoch 55; Iter    84/  229] train: loss: 0.1052692
[Epoch 55; Iter   114/  229] train: loss: 0.1536466
[Epoch 55; Iter   144/  229] train: loss: 0.1439511
[Epoch 55; Iter   174/  229] train: loss: 0.1575646
[Epoch 55; Iter   204/  229] train: loss: 0.1035614
[Epoch 55] ogbg-moltoxcast: 0.682733 val loss: 0.279217
[Epoch 55] ogbg-moltoxcast: 0.653091 test loss: 0.320942
[Epoch 56; Iter     5/  229] train: loss: 0.1119736
[Epoch 56; Iter    35/  229] train: loss: 0.1376361
[Epoch 56; Iter    65/  229] train: loss: 0.1176712
[Epoch 56; Iter    95/  229] train: loss: 0.1417125
[Epoch 56; Iter   125/  229] train: loss: 0.0898508
[Epoch 56; Iter   155/  229] train: loss: 0.1133121
[Epoch 56; Iter   185/  229] train: loss: 0.1379406
[Epoch 56; Iter   215/  229] train: loss: 0.1311561
[Epoch 56] ogbg-moltoxcast: 0.694714 val loss: 0.294172
[Epoch 56] ogbg-moltoxcast: 0.658986 test loss: 0.341413
[Epoch 57; Iter    16/  229] train: loss: 0.1062702
[Epoch 57; Iter    46/  229] train: loss: 0.1119699
[Epoch 57; Iter    76/  229] train: loss: 0.1735902
[Epoch 57; Iter   106/  229] train: loss: 0.1503740
[Epoch 57; Iter   136/  229] train: loss: 0.1295805
[Epoch 57; Iter   166/  229] train: loss: 0.1007471
[Epoch 57; Iter   196/  229] train: loss: 0.1693016
[Epoch 57; Iter   226/  229] train: loss: 0.1794733
[Epoch 57] ogbg-moltoxcast: 0.696762 val loss: 0.283768
[Epoch 57] ogbg-moltoxcast: 0.651291 test loss: 0.330872
[Epoch 58; Iter    27/  229] train: loss: 0.1078916
[Epoch 58; Iter    57/  229] train: loss: 0.0989840
[Epoch 58; Iter    87/  229] train: loss: 0.1185734
[Epoch 58; Iter   117/  229] train: loss: 0.0963878
[Epoch 58; Iter   147/  229] train: loss: 0.1208124
[Epoch 58; Iter   177/  229] train: loss: 0.1608259
[Epoch 58; Iter   207/  229] train: loss: 0.1103152
[Epoch 58] ogbg-moltoxcast: 0.688574 val loss: 0.278310
[Epoch 58] ogbg-moltoxcast: 0.658341 test loss: 0.319951
[Epoch 59; Iter     8/  229] train: loss: 0.1166341
[Epoch 59; Iter    38/  229] train: loss: 0.1244376
[Epoch 59; Iter    68/  229] train: loss: 0.1063343
[Epoch 59; Iter    98/  229] train: loss: 0.1618511
[Epoch 59; Iter   128/  229] train: loss: 0.1485044
[Epoch 59; Iter   158/  229] train: loss: 0.1035565
[Epoch 59; Iter   188/  229] train: loss: 0.1151652
[Epoch 59; Iter   218/  229] train: loss: 0.1146855
[Epoch 59] ogbg-moltoxcast: 0.691330 val loss: 0.287843
[Epoch 59] ogbg-moltoxcast: 0.654456 test loss: 0.332343
[Epoch 44; Iter    23/  229] train: loss: 0.1136761
[Epoch 44; Iter    53/  229] train: loss: 0.1185705
[Epoch 44; Iter    83/  229] train: loss: 0.1334059
[Epoch 44; Iter   113/  229] train: loss: 0.1269289
[Epoch 44; Iter   143/  229] train: loss: 0.1462834
[Epoch 44; Iter   173/  229] train: loss: 0.1187361
[Epoch 44; Iter   203/  229] train: loss: 0.0966889
[Epoch 44] ogbg-moltoxcast: 0.680232 val loss: 0.277211
[Epoch 44] ogbg-moltoxcast: 0.668768 test loss: 0.324101
[Epoch 45; Iter     4/  229] train: loss: 0.1200650
[Epoch 45; Iter    34/  229] train: loss: 0.1542042
[Epoch 45; Iter    64/  229] train: loss: 0.1050512
[Epoch 45; Iter    94/  229] train: loss: 0.1546419
[Epoch 45; Iter   124/  229] train: loss: 0.1953828
[Epoch 45; Iter   154/  229] train: loss: 0.1432855
[Epoch 45; Iter   184/  229] train: loss: 0.1767450
[Epoch 45; Iter   214/  229] train: loss: 0.1338928
[Epoch 45] ogbg-moltoxcast: 0.683106 val loss: 0.276993
[Epoch 45] ogbg-moltoxcast: 0.664773 test loss: 0.332415
[Epoch 46; Iter    15/  229] train: loss: 0.1599356
[Epoch 46; Iter    45/  229] train: loss: 0.1712770
[Epoch 46; Iter    75/  229] train: loss: 0.1925508
[Epoch 46; Iter   105/  229] train: loss: 0.1208363
[Epoch 46; Iter   135/  229] train: loss: 0.1423285
[Epoch 46; Iter   165/  229] train: loss: 0.1150629
[Epoch 46; Iter   195/  229] train: loss: 0.1625312
[Epoch 46; Iter   225/  229] train: loss: 0.1109543
[Epoch 46] ogbg-moltoxcast: 0.674199 val loss: 0.284456
[Epoch 46] ogbg-moltoxcast: 0.663562 test loss: 0.329161
[Epoch 47; Iter    26/  229] train: loss: 0.1283307
[Epoch 47; Iter    56/  229] train: loss: 0.1404853
[Epoch 47; Iter    86/  229] train: loss: 0.1100002
[Epoch 47; Iter   116/  229] train: loss: 0.1366469
[Epoch 47; Iter   146/  229] train: loss: 0.1093455
[Epoch 47; Iter   176/  229] train: loss: 0.1340587
[Epoch 47; Iter   206/  229] train: loss: 0.1475011
[Epoch 47] ogbg-moltoxcast: 0.680562 val loss: 0.286143
[Epoch 47] ogbg-moltoxcast: 0.664891 test loss: 0.329635
[Epoch 48; Iter     7/  229] train: loss: 0.1763970
[Epoch 48; Iter    37/  229] train: loss: 0.1174449
[Epoch 48; Iter    67/  229] train: loss: 0.1698229
[Epoch 48; Iter    97/  229] train: loss: 0.1444239
[Epoch 48; Iter   127/  229] train: loss: 0.1921168
[Epoch 48; Iter   157/  229] train: loss: 0.1502850
[Epoch 48; Iter   187/  229] train: loss: 0.1558281
[Epoch 48; Iter   217/  229] train: loss: 0.0994964
[Epoch 48] ogbg-moltoxcast: 0.675221 val loss: 0.281160
[Epoch 48] ogbg-moltoxcast: 0.661474 test loss: 0.337793
[Epoch 49; Iter    18/  229] train: loss: 0.1172013
[Epoch 49; Iter    48/  229] train: loss: 0.1312085
[Epoch 49; Iter    78/  229] train: loss: 0.1092228
[Epoch 49; Iter   108/  229] train: loss: 0.2096538
[Epoch 49; Iter   138/  229] train: loss: 0.1380520
[Epoch 49; Iter   168/  229] train: loss: 0.1170080
[Epoch 49; Iter   198/  229] train: loss: 0.1629256
[Epoch 49; Iter   228/  229] train: loss: 0.1101011
[Epoch 49] ogbg-moltoxcast: 0.665410 val loss: 0.292048
[Epoch 49] ogbg-moltoxcast: 0.666568 test loss: 0.335429
[Epoch 50; Iter    29/  229] train: loss: 0.1322851
[Epoch 50; Iter    59/  229] train: loss: 0.1138387
[Epoch 50; Iter    89/  229] train: loss: 0.1087032
[Epoch 50; Iter   119/  229] train: loss: 0.1348016
[Epoch 50; Iter   149/  229] train: loss: 0.0951101
[Epoch 50; Iter   179/  229] train: loss: 0.1717641
[Epoch 50; Iter   209/  229] train: loss: 0.1193058
[Epoch 50] ogbg-moltoxcast: 0.671098 val loss: 0.287297
[Epoch 50] ogbg-moltoxcast: 0.658586 test loss: 0.333346
[Epoch 51; Iter    10/  229] train: loss: 0.1097961
[Epoch 51; Iter    40/  229] train: loss: 0.1280994
[Epoch 51; Iter    70/  229] train: loss: 0.1274702
[Epoch 51; Iter   100/  229] train: loss: 0.1356996
[Epoch 51; Iter   130/  229] train: loss: 0.1269776
[Epoch 51; Iter   160/  229] train: loss: 0.1140743
[Epoch 51; Iter   190/  229] train: loss: 0.1424326
[Epoch 51; Iter   220/  229] train: loss: 0.0894717
[Epoch 51] ogbg-moltoxcast: 0.681072 val loss: 0.288678
[Epoch 51] ogbg-moltoxcast: 0.662905 test loss: 0.333520
[Epoch 52; Iter    21/  229] train: loss: 0.2062800
[Epoch 52; Iter    51/  229] train: loss: 0.1457275
[Epoch 52; Iter    81/  229] train: loss: 0.1497651
[Epoch 52; Iter   111/  229] train: loss: 0.1231923
[Epoch 52; Iter   141/  229] train: loss: 0.1182682
[Epoch 52; Iter   171/  229] train: loss: 0.1517871
[Epoch 52; Iter   201/  229] train: loss: 0.1467398
[Epoch 52] ogbg-moltoxcast: 0.675080 val loss: 0.274880
[Epoch 52] ogbg-moltoxcast: 0.660443 test loss: 0.326435
[Epoch 53; Iter     2/  229] train: loss: 0.1182950
[Epoch 53; Iter    32/  229] train: loss: 0.1367559
[Epoch 53; Iter    62/  229] train: loss: 0.1358182
[Epoch 53; Iter    92/  229] train: loss: 0.1097523
[Epoch 53; Iter   122/  229] train: loss: 0.1577220
[Epoch 53; Iter   152/  229] train: loss: 0.1482019
[Epoch 53; Iter   182/  229] train: loss: 0.1424482
[Epoch 53; Iter   212/  229] train: loss: 0.1548887
[Epoch 53] ogbg-moltoxcast: 0.681008 val loss: 0.280338
[Epoch 53] ogbg-moltoxcast: 0.658890 test loss: 0.332003
[Epoch 54; Iter    13/  229] train: loss: 0.0862639
[Epoch 54; Iter    43/  229] train: loss: 0.1403096
[Epoch 54; Iter    73/  229] train: loss: 0.1016964
[Epoch 54; Iter   103/  229] train: loss: 0.1570053
[Epoch 54; Iter   133/  229] train: loss: 0.1723336
[Epoch 54; Iter   163/  229] train: loss: 0.1539813
[Epoch 54; Iter   193/  229] train: loss: 0.1885630
[Epoch 54; Iter   223/  229] train: loss: 0.1766225
[Epoch 54] ogbg-moltoxcast: 0.682866 val loss: 0.273519
[Epoch 54] ogbg-moltoxcast: 0.664981 test loss: 0.323143
[Epoch 55; Iter    24/  229] train: loss: 0.1188133
[Epoch 55; Iter    54/  229] train: loss: 0.1938137
[Epoch 55; Iter    84/  229] train: loss: 0.1414857
[Epoch 55; Iter   114/  229] train: loss: 0.1315227
[Epoch 55; Iter   144/  229] train: loss: 0.1213547
[Epoch 55; Iter   174/  229] train: loss: 0.1490805
[Epoch 55; Iter   204/  229] train: loss: 0.0935678
[Epoch 55] ogbg-moltoxcast: 0.669986 val loss: 0.284327
[Epoch 55] ogbg-moltoxcast: 0.665129 test loss: 0.331680
[Epoch 56; Iter     5/  229] train: loss: 0.1254306
[Epoch 56; Iter    35/  229] train: loss: 0.1241418
[Epoch 56; Iter    65/  229] train: loss: 0.1257992
[Epoch 56; Iter    95/  229] train: loss: 0.1197133
[Epoch 56; Iter   125/  229] train: loss: 0.1506792
[Epoch 56; Iter   155/  229] train: loss: 0.1303130
[Epoch 56; Iter   185/  229] train: loss: 0.1125604
[Epoch 56; Iter   215/  229] train: loss: 0.1296455
[Epoch 56] ogbg-moltoxcast: 0.673480 val loss: 0.283862
[Epoch 56] ogbg-moltoxcast: 0.658844 test loss: 0.329512
[Epoch 57; Iter    16/  229] train: loss: 0.1457663
[Epoch 57; Iter    46/  229] train: loss: 0.1271941
[Epoch 57; Iter    76/  229] train: loss: 0.1416014
[Epoch 57; Iter   106/  229] train: loss: 0.0995099
[Epoch 57; Iter   136/  229] train: loss: 0.1243851
[Epoch 57; Iter   166/  229] train: loss: 0.1147766
[Epoch 57; Iter   196/  229] train: loss: 0.1270577
[Epoch 57; Iter   226/  229] train: loss: 0.1489888
[Epoch 57] ogbg-moltoxcast: 0.677303 val loss: 0.283656
[Epoch 57] ogbg-moltoxcast: 0.662717 test loss: 0.330954
[Epoch 58; Iter    27/  229] train: loss: 0.1433343
[Epoch 58; Iter    57/  229] train: loss: 0.1378899
[Epoch 58; Iter    87/  229] train: loss: 0.1138681
[Epoch 58; Iter   117/  229] train: loss: 0.1137301
[Epoch 58; Iter   147/  229] train: loss: 0.1370683
[Epoch 58; Iter   177/  229] train: loss: 0.2070801
[Epoch 58; Iter   207/  229] train: loss: 0.1525829
[Epoch 58] ogbg-moltoxcast: 0.672300 val loss: 0.287585
[Epoch 58] ogbg-moltoxcast: 0.663468 test loss: 0.337929
[Epoch 59; Iter     8/  229] train: loss: 0.1006991
[Epoch 59; Iter    38/  229] train: loss: 0.1432849
[Epoch 59; Iter    68/  229] train: loss: 0.1090888
[Epoch 59; Iter    98/  229] train: loss: 0.1373806
[Epoch 59; Iter   128/  229] train: loss: 0.1630425
[Epoch 59; Iter   158/  229] train: loss: 0.1303007
[Epoch 59; Iter   188/  229] train: loss: 0.1023257
[Epoch 59; Iter   218/  229] train: loss: 0.1558993
[Epoch 59] ogbg-moltoxcast: 0.660924 val loss: 0.296084
[Epoch 59] ogbg-moltoxcast: 0.658304 test loss: 0.336971
[Epoch 44; Iter    23/  229] train: loss: 0.1789682
[Epoch 44; Iter    53/  229] train: loss: 0.0842799
[Epoch 44; Iter    83/  229] train: loss: 0.1391986
[Epoch 44; Iter   113/  229] train: loss: 0.0945428
[Epoch 44; Iter   143/  229] train: loss: 0.1400918
[Epoch 44; Iter   173/  229] train: loss: 0.1190873
[Epoch 44; Iter   203/  229] train: loss: 0.1408767
[Epoch 44] ogbg-moltoxcast: 0.677359 val loss: 0.293540
[Epoch 44] ogbg-moltoxcast: 0.655874 test loss: 0.334703
[Epoch 45; Iter     4/  229] train: loss: 0.1214727
[Epoch 45; Iter    34/  229] train: loss: 0.1156224
[Epoch 45; Iter    64/  229] train: loss: 0.1661395
[Epoch 45; Iter    94/  229] train: loss: 0.1171485
[Epoch 45; Iter   124/  229] train: loss: 0.1503135
[Epoch 45; Iter   154/  229] train: loss: 0.1274924
[Epoch 45; Iter   184/  229] train: loss: 0.1439822
[Epoch 45; Iter   214/  229] train: loss: 0.1488483
[Epoch 45] ogbg-moltoxcast: 0.676909 val loss: 0.293041
[Epoch 45] ogbg-moltoxcast: 0.661108 test loss: 0.329642
[Epoch 46; Iter    15/  229] train: loss: 0.1217296
[Epoch 46; Iter    45/  229] train: loss: 0.1654865
[Epoch 46; Iter    75/  229] train: loss: 0.1765784
[Epoch 46; Iter   105/  229] train: loss: 0.1423461
[Epoch 46; Iter   135/  229] train: loss: 0.1503150
[Epoch 46; Iter   165/  229] train: loss: 0.1254778
[Epoch 46; Iter   195/  229] train: loss: 0.1534397
[Epoch 46; Iter   225/  229] train: loss: 0.1454205
[Epoch 46] ogbg-moltoxcast: 0.675054 val loss: 0.299756
[Epoch 46] ogbg-moltoxcast: 0.648724 test loss: 0.341273
[Epoch 47; Iter    26/  229] train: loss: 0.1421953
[Epoch 47; Iter    56/  229] train: loss: 0.1493856
[Epoch 47; Iter    86/  229] train: loss: 0.1207568
[Epoch 47; Iter   116/  229] train: loss: 0.0866568
[Epoch 47; Iter   146/  229] train: loss: 0.1039776
[Epoch 47; Iter   176/  229] train: loss: 0.1585250
[Epoch 47; Iter   206/  229] train: loss: 0.1179567
[Epoch 47] ogbg-moltoxcast: 0.670997 val loss: 0.299370
[Epoch 47] ogbg-moltoxcast: 0.653741 test loss: 0.335869
[Epoch 48; Iter     7/  229] train: loss: 0.1111207
[Epoch 48; Iter    37/  229] train: loss: 0.1125911
[Epoch 48; Iter    67/  229] train: loss: 0.1318266
[Epoch 48; Iter    97/  229] train: loss: 0.1524439
[Epoch 48; Iter   127/  229] train: loss: 0.1546359
[Epoch 48; Iter   157/  229] train: loss: 0.1125343
[Epoch 48; Iter   187/  229] train: loss: 0.1844179
[Epoch 48; Iter   217/  229] train: loss: 0.1267641
[Epoch 48] ogbg-moltoxcast: 0.665598 val loss: 0.301130
[Epoch 48] ogbg-moltoxcast: 0.653392 test loss: 0.333782
[Epoch 49; Iter    18/  229] train: loss: 0.1665442
[Epoch 49; Iter    48/  229] train: loss: 0.1078248
[Epoch 49; Iter    78/  229] train: loss: 0.1819413
[Epoch 49; Iter   108/  229] train: loss: 0.1268846
[Epoch 49; Iter   138/  229] train: loss: 0.1499503
[Epoch 49; Iter   168/  229] train: loss: 0.1129732
[Epoch 49; Iter   198/  229] train: loss: 0.1358348
[Epoch 49; Iter   228/  229] train: loss: 0.1301691
[Epoch 49] ogbg-moltoxcast: 0.676326 val loss: 0.316223
[Epoch 49] ogbg-moltoxcast: 0.657064 test loss: 0.342055
[Epoch 50; Iter    29/  229] train: loss: 0.1523895
[Epoch 50; Iter    59/  229] train: loss: 0.1195330
[Epoch 50; Iter    89/  229] train: loss: 0.1533527
[Epoch 50; Iter   119/  229] train: loss: 0.1063748
[Epoch 50; Iter   149/  229] train: loss: 0.1604691
[Epoch 50; Iter   179/  229] train: loss: 0.1697318
[Epoch 50; Iter   209/  229] train: loss: 0.1797152
[Epoch 50] ogbg-moltoxcast: 0.667254 val loss: 0.303113
[Epoch 50] ogbg-moltoxcast: 0.651535 test loss: 0.338094
[Epoch 51; Iter    10/  229] train: loss: 0.1449336
[Epoch 51; Iter    40/  229] train: loss: 0.0936291
[Epoch 51; Iter    70/  229] train: loss: 0.1506938
[Epoch 51; Iter   100/  229] train: loss: 0.1369706
[Epoch 51; Iter   130/  229] train: loss: 0.1227047
[Epoch 51; Iter   160/  229] train: loss: 0.1108113
[Epoch 51; Iter   190/  229] train: loss: 0.1064124
[Epoch 51; Iter   220/  229] train: loss: 0.1477661
[Epoch 51] ogbg-moltoxcast: 0.675687 val loss: 0.313656
[Epoch 51] ogbg-moltoxcast: 0.655943 test loss: 0.344848
[Epoch 52; Iter    21/  229] train: loss: 0.1327175
[Epoch 52; Iter    51/  229] train: loss: 0.1125179
[Epoch 52; Iter    81/  229] train: loss: 0.1482517
[Epoch 52; Iter   111/  229] train: loss: 0.1094994
[Epoch 52; Iter   141/  229] train: loss: 0.1174875
[Epoch 52; Iter   171/  229] train: loss: 0.0849525
[Epoch 52; Iter   201/  229] train: loss: 0.1106262
[Epoch 52] ogbg-moltoxcast: 0.679536 val loss: 0.298489
[Epoch 52] ogbg-moltoxcast: 0.654443 test loss: 0.342998
[Epoch 53; Iter     2/  229] train: loss: 0.1031574
[Epoch 53; Iter    32/  229] train: loss: 0.0794553
[Epoch 53; Iter    62/  229] train: loss: 0.1247471
[Epoch 53; Iter    92/  229] train: loss: 0.1043226
[Epoch 53; Iter   122/  229] train: loss: 0.0958106
[Epoch 53; Iter   152/  229] train: loss: 0.1533721
[Epoch 53; Iter   182/  229] train: loss: 0.1306803
[Epoch 53; Iter   212/  229] train: loss: 0.1465554
[Epoch 53] ogbg-moltoxcast: 0.672278 val loss: 0.298464
[Epoch 53] ogbg-moltoxcast: 0.649706 test loss: 0.337577
[Epoch 54; Iter    13/  229] train: loss: 0.0831584
[Epoch 54; Iter    43/  229] train: loss: 0.0946974
[Epoch 54; Iter    73/  229] train: loss: 0.1143695
[Epoch 54; Iter   103/  229] train: loss: 0.0976250
[Epoch 54; Iter   133/  229] train: loss: 0.1153402
[Epoch 54; Iter   163/  229] train: loss: 0.1192247
[Epoch 54; Iter   193/  229] train: loss: 0.1438616
[Epoch 54; Iter   223/  229] train: loss: 0.1505612
[Epoch 54] ogbg-moltoxcast: 0.668373 val loss: 0.298469
[Epoch 54] ogbg-moltoxcast: 0.651384 test loss: 0.342139
[Epoch 55; Iter    24/  229] train: loss: 0.1417597
[Epoch 55; Iter    54/  229] train: loss: 0.1538864
[Epoch 55; Iter    84/  229] train: loss: 0.1115588
[Epoch 55; Iter   114/  229] train: loss: 0.1274691
[Epoch 55; Iter   144/  229] train: loss: 0.1320067
[Epoch 55; Iter   174/  229] train: loss: 0.1335632
[Epoch 55; Iter   204/  229] train: loss: 0.1487797
[Epoch 55] ogbg-moltoxcast: 0.676607 val loss: 0.297250
[Epoch 55] ogbg-moltoxcast: 0.654506 test loss: 0.341302
[Epoch 56; Iter     5/  229] train: loss: 0.1340180
[Epoch 56; Iter    35/  229] train: loss: 0.1044009
[Epoch 56; Iter    65/  229] train: loss: 0.1635179
[Epoch 56; Iter    95/  229] train: loss: 0.1241696
[Epoch 56; Iter   125/  229] train: loss: 0.1159005
[Epoch 56; Iter   155/  229] train: loss: 0.1312645
[Epoch 56; Iter   185/  229] train: loss: 0.1617390
[Epoch 56; Iter   215/  229] train: loss: 0.1091862
[Epoch 56] ogbg-moltoxcast: 0.674421 val loss: 0.306827
[Epoch 56] ogbg-moltoxcast: 0.654646 test loss: 0.339217
[Epoch 57; Iter    16/  229] train: loss: 0.1919275
[Epoch 57; Iter    46/  229] train: loss: 0.1293115
[Epoch 57; Iter    76/  229] train: loss: 0.0979415
[Epoch 57; Iter   106/  229] train: loss: 0.1375100
[Epoch 57; Iter   136/  229] train: loss: 0.1048379
[Epoch 57; Iter   166/  229] train: loss: 0.0911456
[Epoch 57; Iter   196/  229] train: loss: 0.1203062
[Epoch 57; Iter   226/  229] train: loss: 0.2078832
[Epoch 57] ogbg-moltoxcast: 0.671479 val loss: 0.311355
[Epoch 57] ogbg-moltoxcast: 0.652270 test loss: 0.346546
[Epoch 58; Iter    27/  229] train: loss: 0.1207136
[Epoch 58; Iter    57/  229] train: loss: 0.1483005
[Epoch 58; Iter    87/  229] train: loss: 0.1324091
[Epoch 58; Iter   117/  229] train: loss: 0.1380677
[Epoch 58; Iter   147/  229] train: loss: 0.1786949
[Epoch 58; Iter   177/  229] train: loss: 0.1920345
[Epoch 58; Iter   207/  229] train: loss: 0.1204160
[Epoch 58] ogbg-moltoxcast: 0.677729 val loss: 0.304222
[Epoch 58] ogbg-moltoxcast: 0.652144 test loss: 0.344390
[Epoch 59; Iter     8/  229] train: loss: 0.1230494
[Epoch 59; Iter    38/  229] train: loss: 0.1032844
[Epoch 59; Iter    68/  229] train: loss: 0.1209820
[Epoch 59; Iter    98/  229] train: loss: 0.1035126
[Epoch 59; Iter   128/  229] train: loss: 0.1146065
[Epoch 59; Iter   158/  229] train: loss: 0.1127970
[Epoch 59; Iter   188/  229] train: loss: 0.1149588
[Epoch 59; Iter   218/  229] train: loss: 0.1139018
[Epoch 59] ogbg-moltoxcast: 0.662800 val loss: 0.310385
[Epoch 59] ogbg-moltoxcast: 0.647104 test loss: 0.344452
[Epoch 44; Iter    23/  229] train: loss: 0.1713220
[Epoch 44; Iter    53/  229] train: loss: 0.0885527
[Epoch 44; Iter    83/  229] train: loss: 0.1371964
[Epoch 44; Iter   113/  229] train: loss: 0.0907690
[Epoch 44; Iter   143/  229] train: loss: 0.1437661
[Epoch 44; Iter   173/  229] train: loss: 0.1205016
[Epoch 44; Iter   203/  229] train: loss: 0.1329095
[Epoch 44] ogbg-moltoxcast: 0.642163 val loss: 0.336784
[Epoch 44] ogbg-moltoxcast: 0.633907 test loss: 0.393351
[Epoch 45; Iter     4/  229] train: loss: 0.1135714
[Epoch 45; Iter    34/  229] train: loss: 0.1368045
[Epoch 45; Iter    64/  229] train: loss: 0.1561936
[Epoch 45; Iter    94/  229] train: loss: 0.1130355
[Epoch 45; Iter   124/  229] train: loss: 0.1487327
[Epoch 45; Iter   154/  229] train: loss: 0.1227432
[Epoch 45; Iter   184/  229] train: loss: 0.1430686
[Epoch 45; Iter   214/  229] train: loss: 0.1474191
[Epoch 45] ogbg-moltoxcast: 0.637094 val loss: 0.355677
[Epoch 45] ogbg-moltoxcast: 0.629781 test loss: 0.412108
[Epoch 46; Iter    15/  229] train: loss: 0.1296511
[Epoch 46; Iter    45/  229] train: loss: 0.1525617
[Epoch 46; Iter    75/  229] train: loss: 0.1719767
[Epoch 46; Iter   105/  229] train: loss: 0.1452319
[Epoch 46; Iter   135/  229] train: loss: 0.1442151
[Epoch 46; Iter   165/  229] train: loss: 0.1198866
[Epoch 46; Iter   195/  229] train: loss: 0.1526902
[Epoch 46; Iter   225/  229] train: loss: 0.1485945
[Epoch 46] ogbg-moltoxcast: 0.642201 val loss: 0.338877
[Epoch 46] ogbg-moltoxcast: 0.637956 test loss: 0.390744
[Epoch 47; Iter    26/  229] train: loss: 0.1427879
[Epoch 47; Iter    56/  229] train: loss: 0.1482780
[Epoch 47; Iter    86/  229] train: loss: 0.1239506
[Epoch 47; Iter   116/  229] train: loss: 0.0844048
[Epoch 47; Iter   146/  229] train: loss: 0.1050883
[Epoch 47; Iter   176/  229] train: loss: 0.1451858
[Epoch 47; Iter   206/  229] train: loss: 0.1218293
[Epoch 47] ogbg-moltoxcast: 0.638328 val loss: 0.349564
[Epoch 47] ogbg-moltoxcast: 0.632660 test loss: 0.405207
[Epoch 48; Iter     7/  229] train: loss: 0.1048515
[Epoch 48; Iter    37/  229] train: loss: 0.1115299
[Epoch 48; Iter    67/  229] train: loss: 0.1320665
[Epoch 48; Iter    97/  229] train: loss: 0.1541268
[Epoch 48; Iter   127/  229] train: loss: 0.1511807
[Epoch 48; Iter   157/  229] train: loss: 0.1061581
[Epoch 48; Iter   187/  229] train: loss: 0.1725466
[Epoch 48; Iter   217/  229] train: loss: 0.1300417
[Epoch 48] ogbg-moltoxcast: 0.633667 val loss: 0.343441
[Epoch 48] ogbg-moltoxcast: 0.631600 test loss: 0.395562
[Epoch 49; Iter    18/  229] train: loss: 0.1595895
[Epoch 49; Iter    48/  229] train: loss: 0.1072293
[Epoch 49; Iter    78/  229] train: loss: 0.1893410
[Epoch 49; Iter   108/  229] train: loss: 0.1284277
[Epoch 49; Iter   138/  229] train: loss: 0.1425720
[Epoch 49; Iter   168/  229] train: loss: 0.1182119
[Epoch 49; Iter   198/  229] train: loss: 0.1376317
[Epoch 49; Iter   228/  229] train: loss: 0.1259886
[Epoch 49] ogbg-moltoxcast: 0.646925 val loss: 0.348505
[Epoch 49] ogbg-moltoxcast: 0.642084 test loss: 0.408328
[Epoch 50; Iter    29/  229] train: loss: 0.1479153
[Epoch 50; Iter    59/  229] train: loss: 0.1187054
[Epoch 50; Iter    89/  229] train: loss: 0.1562304
[Epoch 50; Iter   119/  229] train: loss: 0.1049224
[Epoch 50; Iter   149/  229] train: loss: 0.1598558
[Epoch 50; Iter   179/  229] train: loss: 0.1722196
[Epoch 50; Iter   209/  229] train: loss: 0.1925493
[Epoch 50] ogbg-moltoxcast: 0.637469 val loss: 0.342703
[Epoch 50] ogbg-moltoxcast: 0.633956 test loss: 0.389857
[Epoch 51; Iter    10/  229] train: loss: 0.1387364
[Epoch 51; Iter    40/  229] train: loss: 0.0857495
[Epoch 51; Iter    70/  229] train: loss: 0.1427122
[Epoch 51; Iter   100/  229] train: loss: 0.1444498
[Epoch 51; Iter   130/  229] train: loss: 0.1237135
[Epoch 51; Iter   160/  229] train: loss: 0.1112469
[Epoch 51; Iter   190/  229] train: loss: 0.1088683
[Epoch 51; Iter   220/  229] train: loss: 0.1493425
[Epoch 51] ogbg-moltoxcast: 0.638293 val loss: 0.346213
[Epoch 51] ogbg-moltoxcast: 0.636060 test loss: 0.402008
[Epoch 52; Iter    21/  229] train: loss: 0.1344955
[Epoch 52; Iter    51/  229] train: loss: 0.1128808
[Epoch 52; Iter    81/  229] train: loss: 0.1469619
[Epoch 52; Iter   111/  229] train: loss: 0.1136167
[Epoch 52; Iter   141/  229] train: loss: 0.1134830
[Epoch 52; Iter   171/  229] train: loss: 0.0778092
[Epoch 52; Iter   201/  229] train: loss: 0.1204024
[Epoch 52] ogbg-moltoxcast: 0.634281 val loss: 0.368945
[Epoch 52] ogbg-moltoxcast: 0.629907 test loss: 0.424254
[Epoch 53; Iter     2/  229] train: loss: 0.1023809
[Epoch 53; Iter    32/  229] train: loss: 0.0789731
[Epoch 53; Iter    62/  229] train: loss: 0.1103711
[Epoch 53; Iter    92/  229] train: loss: 0.1052932
[Epoch 53; Iter   122/  229] train: loss: 0.0929367
[Epoch 53; Iter   152/  229] train: loss: 0.1550190
[Epoch 53; Iter   182/  229] train: loss: 0.1221118
[Epoch 53; Iter   212/  229] train: loss: 0.1393850
[Epoch 53] ogbg-moltoxcast: 0.640246 val loss: 0.355049
[Epoch 53] ogbg-moltoxcast: 0.635809 test loss: 0.409015
[Epoch 54; Iter    13/  229] train: loss: 0.0901460
[Epoch 54; Iter    43/  229] train: loss: 0.0916913
[Epoch 54; Iter    73/  229] train: loss: 0.1052273
[Epoch 54; Iter   103/  229] train: loss: 0.0904333
[Epoch 54; Iter   133/  229] train: loss: 0.1179135
[Epoch 54; Iter   163/  229] train: loss: 0.1156017
[Epoch 54; Iter   193/  229] train: loss: 0.1451061
[Epoch 54; Iter   223/  229] train: loss: 0.1550341
[Epoch 54] ogbg-moltoxcast: 0.629402 val loss: 0.365767
[Epoch 54] ogbg-moltoxcast: 0.631202 test loss: 0.423157
[Epoch 55; Iter    24/  229] train: loss: 0.1411596
[Epoch 55; Iter    54/  229] train: loss: 0.1480152
[Epoch 55; Iter    84/  229] train: loss: 0.1070325
[Epoch 55; Iter   114/  229] train: loss: 0.1216205
[Epoch 55; Iter   144/  229] train: loss: 0.1330380
[Epoch 55; Iter   174/  229] train: loss: 0.1333608
[Epoch 55; Iter   204/  229] train: loss: 0.1421334
[Epoch 55] ogbg-moltoxcast: 0.643042 val loss: 0.350556
[Epoch 55] ogbg-moltoxcast: 0.638366 test loss: 0.403063
[Epoch 56; Iter     5/  229] train: loss: 0.1338416
[Epoch 56; Iter    35/  229] train: loss: 0.1007178
[Epoch 56; Iter    65/  229] train: loss: 0.1711592
[Epoch 56; Iter    95/  229] train: loss: 0.1227114
[Epoch 56; Iter   125/  229] train: loss: 0.1155535
[Epoch 56; Iter   155/  229] train: loss: 0.1329036
[Epoch 56; Iter   185/  229] train: loss: 0.1634149
[Epoch 56; Iter   215/  229] train: loss: 0.1098003
[Epoch 56] ogbg-moltoxcast: 0.629546 val loss: 0.379402
[Epoch 56] ogbg-moltoxcast: 0.626525 test loss: 0.436792
[Epoch 57; Iter    16/  229] train: loss: 0.1921612
[Epoch 57; Iter    46/  229] train: loss: 0.1274859
[Epoch 57; Iter    76/  229] train: loss: 0.1049631
[Epoch 57; Iter   106/  229] train: loss: 0.1477131
[Epoch 57; Iter   136/  229] train: loss: 0.1062606
[Epoch 57; Iter   166/  229] train: loss: 0.0828121
[Epoch 57; Iter   196/  229] train: loss: 0.1234866
[Epoch 57; Iter   226/  229] train: loss: 0.2029633
[Epoch 57] ogbg-moltoxcast: 0.635421 val loss: 0.379251
[Epoch 57] ogbg-moltoxcast: 0.630729 test loss: 0.435182
[Epoch 58; Iter    27/  229] train: loss: 0.1253303
[Epoch 58; Iter    57/  229] train: loss: 0.1496911
[Epoch 58; Iter    87/  229] train: loss: 0.1313829
[Epoch 58; Iter   117/  229] train: loss: 0.1444567
[Epoch 58; Iter   147/  229] train: loss: 0.1939916
[Epoch 58; Iter   177/  229] train: loss: 0.1956982
[Epoch 58; Iter   207/  229] train: loss: 0.1299502
[Epoch 58] ogbg-moltoxcast: 0.646679 val loss: 0.341338
[Epoch 58] ogbg-moltoxcast: 0.637185 test loss: 0.398057
[Epoch 59; Iter     8/  229] train: loss: 0.1180765
[Epoch 59; Iter    38/  229] train: loss: 0.1023335
[Epoch 59; Iter    68/  229] train: loss: 0.1194178
[Epoch 59; Iter    98/  229] train: loss: 0.1079512
[Epoch 59; Iter   128/  229] train: loss: 0.1096399
[Epoch 59; Iter   158/  229] train: loss: 0.1172793
[Epoch 59; Iter   188/  229] train: loss: 0.1042913
[Epoch 59; Iter   218/  229] train: loss: 0.1176657
[Epoch 59] ogbg-moltoxcast: 0.631207 val loss: 0.368643
[Epoch 59] ogbg-moltoxcast: 0.637239 test loss: 0.418814
[Epoch 44; Iter    23/  229] train: loss: 0.2041599
[Epoch 44; Iter    53/  229] train: loss: 0.0847411
[Epoch 44; Iter    83/  229] train: loss: 0.1355788
[Epoch 44; Iter   113/  229] train: loss: 0.1327776
[Epoch 44; Iter   143/  229] train: loss: 0.1720338
[Epoch 44; Iter   173/  229] train: loss: 0.1532258
[Epoch 44; Iter   203/  229] train: loss: 0.1430579
[Epoch 44] ogbg-moltoxcast: 0.677284 val loss: 0.296344
[Epoch 44] ogbg-moltoxcast: 0.649498 test loss: 0.344306
[Epoch 45; Iter     4/  229] train: loss: 0.1125487
[Epoch 45; Iter    34/  229] train: loss: 0.1248061
[Epoch 45; Iter    64/  229] train: loss: 0.1560480
[Epoch 45; Iter    94/  229] train: loss: 0.0920300
[Epoch 45; Iter   124/  229] train: loss: 0.1350262
[Epoch 45; Iter   154/  229] train: loss: 0.1177642
[Epoch 45; Iter   184/  229] train: loss: 0.1093034
[Epoch 45; Iter   214/  229] train: loss: 0.0857816
[Epoch 45] ogbg-moltoxcast: 0.677168 val loss: 0.290772
[Epoch 45] ogbg-moltoxcast: 0.658710 test loss: 0.334497
[Epoch 46; Iter    15/  229] train: loss: 0.1549199
[Epoch 46; Iter    45/  229] train: loss: 0.1729240
[Epoch 46; Iter    75/  229] train: loss: 0.1308087
[Epoch 46; Iter   105/  229] train: loss: 0.1752373
[Epoch 46; Iter   135/  229] train: loss: 0.1512761
[Epoch 46; Iter   165/  229] train: loss: 0.1329311
[Epoch 46; Iter   195/  229] train: loss: 0.1307661
[Epoch 46; Iter   225/  229] train: loss: 0.1400966
[Epoch 46] ogbg-moltoxcast: 0.678490 val loss: 0.292100
[Epoch 46] ogbg-moltoxcast: 0.650590 test loss: 0.338970
[Epoch 47; Iter    26/  229] train: loss: 0.1578525
[Epoch 47; Iter    56/  229] train: loss: 0.1611341
[Epoch 47; Iter    86/  229] train: loss: 0.1383656
[Epoch 47; Iter   116/  229] train: loss: 0.1190353
[Epoch 47; Iter   146/  229] train: loss: 0.1149279
[Epoch 47; Iter   176/  229] train: loss: 0.0954665
[Epoch 47; Iter   206/  229] train: loss: 0.1205743
[Epoch 47] ogbg-moltoxcast: 0.663905 val loss: 0.309618
[Epoch 47] ogbg-moltoxcast: 0.643410 test loss: 0.363540
[Epoch 48; Iter     7/  229] train: loss: 0.1429960
[Epoch 48; Iter    37/  229] train: loss: 0.1308317
[Epoch 48; Iter    67/  229] train: loss: 0.1255948
[Epoch 48; Iter    97/  229] train: loss: 0.1402926
[Epoch 48; Iter   127/  229] train: loss: 0.1450951
[Epoch 48; Iter   157/  229] train: loss: 0.1062874
[Epoch 48; Iter   187/  229] train: loss: 0.1427113
[Epoch 48; Iter   217/  229] train: loss: 0.1440042
[Epoch 48] ogbg-moltoxcast: 0.676056 val loss: 0.305325
[Epoch 48] ogbg-moltoxcast: 0.656599 test loss: 0.353715
[Epoch 49; Iter    18/  229] train: loss: 0.1553739
[Epoch 49; Iter    48/  229] train: loss: 0.1267356
[Epoch 49; Iter    78/  229] train: loss: 0.0914607
[Epoch 49; Iter   108/  229] train: loss: 0.1243880
[Epoch 49; Iter   138/  229] train: loss: 0.1199409
[Epoch 49; Iter   168/  229] train: loss: 0.1283672
[Epoch 49; Iter   198/  229] train: loss: 0.1324297
[Epoch 49; Iter   228/  229] train: loss: 0.1444908
[Epoch 49] ogbg-moltoxcast: 0.672624 val loss: 0.305806
[Epoch 49] ogbg-moltoxcast: 0.646739 test loss: 0.348934
[Epoch 50; Iter    29/  229] train: loss: 0.1040126
[Epoch 50; Iter    59/  229] train: loss: 0.1528071
[Epoch 50; Iter    89/  229] train: loss: 0.0809650
[Epoch 50; Iter   119/  229] train: loss: 0.1648895
[Epoch 50; Iter   149/  229] train: loss: 0.1258279
[Epoch 50; Iter   179/  229] train: loss: 0.1347351
[Epoch 50; Iter   209/  229] train: loss: 0.1053080
[Epoch 50] ogbg-moltoxcast: 0.675217 val loss: 0.299220
[Epoch 50] ogbg-moltoxcast: 0.647320 test loss: 0.348180
[Epoch 51; Iter    10/  229] train: loss: 0.1534518
[Epoch 51; Iter    40/  229] train: loss: 0.1033078
[Epoch 51; Iter    70/  229] train: loss: 0.1469479
[Epoch 51; Iter   100/  229] train: loss: 0.1435611
[Epoch 51; Iter   130/  229] train: loss: 0.1197518
[Epoch 51; Iter   160/  229] train: loss: 0.1110300
[Epoch 51; Iter   190/  229] train: loss: 0.1399729
[Epoch 51; Iter   220/  229] train: loss: 0.1671520
[Epoch 51] ogbg-moltoxcast: 0.674262 val loss: 0.352237
[Epoch 51] ogbg-moltoxcast: 0.653887 test loss: 0.422187
[Epoch 52; Iter    21/  229] train: loss: 0.1145883
[Epoch 52; Iter    51/  229] train: loss: 0.1493053
[Epoch 52; Iter    81/  229] train: loss: 0.1218955
[Epoch 52; Iter   111/  229] train: loss: 0.1851954
[Epoch 52; Iter   141/  229] train: loss: 0.1392297
[Epoch 52; Iter   171/  229] train: loss: 0.1493092
[Epoch 52; Iter   201/  229] train: loss: 0.1251373
[Epoch 52] ogbg-moltoxcast: 0.674005 val loss: 0.307062
[Epoch 52] ogbg-moltoxcast: 0.653260 test loss: 0.352767
[Epoch 53; Iter     2/  229] train: loss: 0.0953188
[Epoch 53; Iter    32/  229] train: loss: 0.1181765
[Epoch 53; Iter    62/  229] train: loss: 0.1451466
[Epoch 53; Iter    92/  229] train: loss: 0.1579818
[Epoch 53; Iter   122/  229] train: loss: 0.0856471
[Epoch 53; Iter   152/  229] train: loss: 0.1116430
[Epoch 53; Iter   182/  229] train: loss: 0.1256787
[Epoch 53; Iter   212/  229] train: loss: 0.1248332
[Epoch 53] ogbg-moltoxcast: 0.666816 val loss: 0.357422
[Epoch 53] ogbg-moltoxcast: 0.648730 test loss: 0.403813
[Epoch 54; Iter    13/  229] train: loss: 0.0878155
[Epoch 54; Iter    43/  229] train: loss: 0.1390379
[Epoch 54; Iter    73/  229] train: loss: 0.1183715
[Epoch 54; Iter   103/  229] train: loss: 0.1240694
[Epoch 54; Iter   133/  229] train: loss: 0.1263002
[Epoch 54; Iter   163/  229] train: loss: 0.1511347
[Epoch 54; Iter   193/  229] train: loss: 0.1603871
[Epoch 54; Iter   223/  229] train: loss: 0.1732265
[Epoch 54] ogbg-moltoxcast: 0.676452 val loss: 0.303222
[Epoch 54] ogbg-moltoxcast: 0.652018 test loss: 0.352601
[Epoch 55; Iter    24/  229] train: loss: 0.1616845
[Epoch 55; Iter    54/  229] train: loss: 0.1834158
[Epoch 55; Iter    84/  229] train: loss: 0.1008196
[Epoch 55; Iter   114/  229] train: loss: 0.1627414
[Epoch 55; Iter   144/  229] train: loss: 0.1472796
[Epoch 55; Iter   174/  229] train: loss: 0.1560643
[Epoch 55; Iter   204/  229] train: loss: 0.1123898
[Epoch 55] ogbg-moltoxcast: 0.671395 val loss: 0.296770
[Epoch 55] ogbg-moltoxcast: 0.650401 test loss: 0.342736
[Epoch 56; Iter     5/  229] train: loss: 0.1070634
[Epoch 56; Iter    35/  229] train: loss: 0.1379506
[Epoch 56; Iter    65/  229] train: loss: 0.1166190
[Epoch 56; Iter    95/  229] train: loss: 0.1388589
[Epoch 56; Iter   125/  229] train: loss: 0.0949040
[Epoch 56; Iter   155/  229] train: loss: 0.1067975
[Epoch 56; Iter   185/  229] train: loss: 0.1383560
[Epoch 56; Iter   215/  229] train: loss: 0.1331111
[Epoch 56] ogbg-moltoxcast: 0.670944 val loss: 0.302608
[Epoch 56] ogbg-moltoxcast: 0.641121 test loss: 0.353913
[Epoch 57; Iter    16/  229] train: loss: 0.1081329
[Epoch 57; Iter    46/  229] train: loss: 0.1125971
[Epoch 57; Iter    76/  229] train: loss: 0.1706906
[Epoch 57; Iter   106/  229] train: loss: 0.1571104
[Epoch 57; Iter   136/  229] train: loss: 0.1277723
[Epoch 57; Iter   166/  229] train: loss: 0.0938805
[Epoch 57; Iter   196/  229] train: loss: 0.1616244
[Epoch 57; Iter   226/  229] train: loss: 0.1765635
[Epoch 57] ogbg-moltoxcast: 0.675062 val loss: 0.314545
[Epoch 57] ogbg-moltoxcast: 0.643053 test loss: 0.368400
[Epoch 58; Iter    27/  229] train: loss: 0.1087127
[Epoch 58; Iter    57/  229] train: loss: 0.0993173
[Epoch 58; Iter    87/  229] train: loss: 0.1205469
[Epoch 58; Iter   117/  229] train: loss: 0.0962398
[Epoch 58; Iter   147/  229] train: loss: 0.1121881
[Epoch 58; Iter   177/  229] train: loss: 0.1662936
[Epoch 58; Iter   207/  229] train: loss: 0.1088713
[Epoch 58] ogbg-moltoxcast: 0.669388 val loss: 0.302326
[Epoch 58] ogbg-moltoxcast: 0.651854 test loss: 0.349125
[Epoch 59; Iter     8/  229] train: loss: 0.1151401
[Epoch 59; Iter    38/  229] train: loss: 0.1299688
[Epoch 59; Iter    68/  229] train: loss: 0.1059547
[Epoch 59; Iter    98/  229] train: loss: 0.1667742
[Epoch 59; Iter   128/  229] train: loss: 0.1524304
[Epoch 59; Iter   158/  229] train: loss: 0.1017436
[Epoch 59; Iter   188/  229] train: loss: 0.1171255
[Epoch 59; Iter   218/  229] train: loss: 0.1072949
[Epoch 59] ogbg-moltoxcast: 0.659834 val loss: 0.309862
[Epoch 59] ogbg-moltoxcast: 0.642982 test loss: 0.358238
[Epoch 44; Iter    23/  229] train: loss: 0.1169867
[Epoch 44; Iter    53/  229] train: loss: 0.1237674
[Epoch 44; Iter    83/  229] train: loss: 0.1364130
[Epoch 44; Iter   113/  229] train: loss: 0.1358229
[Epoch 44; Iter   143/  229] train: loss: 0.1432369
[Epoch 44; Iter   173/  229] train: loss: 0.1298209
[Epoch 44; Iter   203/  229] train: loss: 0.0927442
[Epoch 44] ogbg-moltoxcast: 0.654656 val loss: 0.315909
[Epoch 44] ogbg-moltoxcast: 0.639294 test loss: 0.341007
[Epoch 45; Iter     4/  229] train: loss: 0.1324162
[Epoch 45; Iter    34/  229] train: loss: 0.1605375
[Epoch 45; Iter    64/  229] train: loss: 0.1079591
[Epoch 45; Iter    94/  229] train: loss: 0.1736697
[Epoch 45; Iter   124/  229] train: loss: 0.2002729
[Epoch 45; Iter   154/  229] train: loss: 0.1460335
[Epoch 45; Iter   184/  229] train: loss: 0.1887498
[Epoch 45; Iter   214/  229] train: loss: 0.1349215
[Epoch 45] ogbg-moltoxcast: 0.658747 val loss: 0.318195
[Epoch 45] ogbg-moltoxcast: 0.635851 test loss: 0.341627
[Epoch 46; Iter    15/  229] train: loss: 0.1643586
[Epoch 46; Iter    45/  229] train: loss: 0.1886957
[Epoch 46; Iter    75/  229] train: loss: 0.2148826
[Epoch 46; Iter   105/  229] train: loss: 0.1311626
[Epoch 46; Iter   135/  229] train: loss: 0.1498271
[Epoch 46; Iter   165/  229] train: loss: 0.1160984
[Epoch 46; Iter   195/  229] train: loss: 0.1779697
[Epoch 46; Iter   225/  229] train: loss: 0.1132371
[Epoch 46] ogbg-moltoxcast: 0.655040 val loss: 0.301963
[Epoch 46] ogbg-moltoxcast: 0.637028 test loss: 0.332197
[Epoch 47; Iter    26/  229] train: loss: 0.1374084
[Epoch 47; Iter    56/  229] train: loss: 0.1531788
[Epoch 47; Iter    86/  229] train: loss: 0.1114754
[Epoch 47; Iter   116/  229] train: loss: 0.1459189
[Epoch 47; Iter   146/  229] train: loss: 0.1133104
[Epoch 47; Iter   176/  229] train: loss: 0.1426590
[Epoch 47; Iter   206/  229] train: loss: 0.1467110
[Epoch 47] ogbg-moltoxcast: 0.657047 val loss: 0.321522
[Epoch 47] ogbg-moltoxcast: 0.643654 test loss: 0.338588
[Epoch 48; Iter     7/  229] train: loss: 0.1889206
[Epoch 48; Iter    37/  229] train: loss: 0.1166049
[Epoch 48; Iter    67/  229] train: loss: 0.1779162
[Epoch 48; Iter    97/  229] train: loss: 0.1493520
[Epoch 48; Iter   127/  229] train: loss: 0.2084767
[Epoch 48; Iter   157/  229] train: loss: 0.1579140
[Epoch 48; Iter   187/  229] train: loss: 0.1538971
[Epoch 48; Iter   217/  229] train: loss: 0.0964016
[Epoch 48] ogbg-moltoxcast: 0.657167 val loss: 0.314565
[Epoch 48] ogbg-moltoxcast: 0.640614 test loss: 0.338456
[Epoch 49; Iter    18/  229] train: loss: 0.1274973
[Epoch 49; Iter    48/  229] train: loss: 0.1385923
[Epoch 49; Iter    78/  229] train: loss: 0.1138959
[Epoch 49; Iter   108/  229] train: loss: 0.2240474
[Epoch 49; Iter   138/  229] train: loss: 0.1436542
[Epoch 49; Iter   168/  229] train: loss: 0.1216555
[Epoch 49; Iter   198/  229] train: loss: 0.1727578
[Epoch 49; Iter   228/  229] train: loss: 0.1258030
[Epoch 49] ogbg-moltoxcast: 0.659534 val loss: 0.323765
[Epoch 49] ogbg-moltoxcast: 0.644520 test loss: 0.341073
[Epoch 50; Iter    29/  229] train: loss: 0.1335306
[Epoch 50; Iter    59/  229] train: loss: 0.1226776
[Epoch 50; Iter    89/  229] train: loss: 0.1026163
[Epoch 50; Iter   119/  229] train: loss: 0.1435985
[Epoch 50; Iter   149/  229] train: loss: 0.0973156
[Epoch 50; Iter   179/  229] train: loss: 0.1804702
[Epoch 50; Iter   209/  229] train: loss: 0.1323827
[Epoch 50] ogbg-moltoxcast: 0.656426 val loss: 0.317393
[Epoch 50] ogbg-moltoxcast: 0.640225 test loss: 0.335936
[Epoch 51; Iter    10/  229] train: loss: 0.1195582
[Epoch 51; Iter    40/  229] train: loss: 0.1378687
[Epoch 51; Iter    70/  229] train: loss: 0.1315138
[Epoch 51; Iter   100/  229] train: loss: 0.1373682
[Epoch 51; Iter   130/  229] train: loss: 0.1205556
[Epoch 51; Iter   160/  229] train: loss: 0.1165526
[Epoch 51; Iter   190/  229] train: loss: 0.1337224
[Epoch 51; Iter   220/  229] train: loss: 0.0913470
[Epoch 51] ogbg-moltoxcast: 0.669614 val loss: 0.318046
[Epoch 51] ogbg-moltoxcast: 0.644110 test loss: 0.333158
[Epoch 52; Iter    21/  229] train: loss: 0.2072268
[Epoch 52; Iter    51/  229] train: loss: 0.1560182
[Epoch 52; Iter    81/  229] train: loss: 0.1512491
[Epoch 52; Iter   111/  229] train: loss: 0.1353601
[Epoch 52; Iter   141/  229] train: loss: 0.1202918
[Epoch 52; Iter   171/  229] train: loss: 0.1640274
[Epoch 52; Iter   201/  229] train: loss: 0.1369529
[Epoch 52] ogbg-moltoxcast: 0.645614 val loss: 0.313776
[Epoch 52] ogbg-moltoxcast: 0.637902 test loss: 0.338941
[Epoch 53; Iter     2/  229] train: loss: 0.1279016
[Epoch 53; Iter    32/  229] train: loss: 0.1375025
[Epoch 53; Iter    62/  229] train: loss: 0.1457702
[Epoch 53; Iter    92/  229] train: loss: 0.1237081
[Epoch 53; Iter   122/  229] train: loss: 0.1654186
[Epoch 53; Iter   152/  229] train: loss: 0.1562663
[Epoch 53; Iter   182/  229] train: loss: 0.1450481
[Epoch 53; Iter   212/  229] train: loss: 0.1551163
[Epoch 53] ogbg-moltoxcast: 0.660121 val loss: 0.332333
[Epoch 53] ogbg-moltoxcast: 0.640867 test loss: 0.424892
[Epoch 54; Iter    13/  229] train: loss: 0.0881958
[Epoch 54; Iter    43/  229] train: loss: 0.1508907
[Epoch 54; Iter    73/  229] train: loss: 0.1098509
[Epoch 54; Iter   103/  229] train: loss: 0.1658289
[Epoch 54; Iter   133/  229] train: loss: 0.1809020
[Epoch 54; Iter   163/  229] train: loss: 0.1584349
[Epoch 54; Iter   193/  229] train: loss: 0.2008180
[Epoch 54; Iter   223/  229] train: loss: 0.1879291
[Epoch 54] ogbg-moltoxcast: 0.661144 val loss: 0.303431
[Epoch 54] ogbg-moltoxcast: 0.648341 test loss: 0.322998
[Epoch 55; Iter    24/  229] train: loss: 0.1281297
[Epoch 55; Iter    54/  229] train: loss: 0.1917293
[Epoch 55; Iter    84/  229] train: loss: 0.1435856
[Epoch 55; Iter   114/  229] train: loss: 0.1293125
[Epoch 55; Iter   144/  229] train: loss: 0.1461303
[Epoch 55; Iter   174/  229] train: loss: 0.1467422
[Epoch 55; Iter   204/  229] train: loss: 0.0955536
[Epoch 55] ogbg-moltoxcast: 0.652949 val loss: 0.295427
[Epoch 55] ogbg-moltoxcast: 0.641270 test loss: 0.374405
[Epoch 56; Iter     5/  229] train: loss: 0.1335864
[Epoch 56; Iter    35/  229] train: loss: 0.1233579
[Epoch 56; Iter    65/  229] train: loss: 0.1254272
[Epoch 56; Iter    95/  229] train: loss: 0.1191096
[Epoch 56; Iter   125/  229] train: loss: 0.1557412
[Epoch 56; Iter   155/  229] train: loss: 0.1323911
[Epoch 56; Iter   185/  229] train: loss: 0.1099590
[Epoch 56; Iter   215/  229] train: loss: 0.1430621
[Epoch 56] ogbg-moltoxcast: 0.659775 val loss: 0.314121
[Epoch 56] ogbg-moltoxcast: 0.646490 test loss: 0.333242
[Epoch 57; Iter    16/  229] train: loss: 0.1545754
[Epoch 57; Iter    46/  229] train: loss: 0.1315293
[Epoch 57; Iter    76/  229] train: loss: 0.1508019
[Epoch 57; Iter   106/  229] train: loss: 0.1118756
[Epoch 57; Iter   136/  229] train: loss: 0.1343556
[Epoch 57; Iter   166/  229] train: loss: 0.1151305
[Epoch 57; Iter   196/  229] train: loss: 0.1371992
[Epoch 57; Iter   226/  229] train: loss: 0.1569146
[Epoch 57] ogbg-moltoxcast: 0.661780 val loss: 0.320602
[Epoch 57] ogbg-moltoxcast: 0.644639 test loss: 0.336947
[Epoch 58; Iter    27/  229] train: loss: 0.1497189
[Epoch 58; Iter    57/  229] train: loss: 0.1518530
[Epoch 58; Iter    87/  229] train: loss: 0.1188654
[Epoch 58; Iter   117/  229] train: loss: 0.1141213
[Epoch 58; Iter   147/  229] train: loss: 0.1505574
[Epoch 58; Iter   177/  229] train: loss: 0.2103173
[Epoch 58; Iter   207/  229] train: loss: 0.1575204
[Epoch 58] ogbg-moltoxcast: 0.665135 val loss: 0.316661
[Epoch 58] ogbg-moltoxcast: 0.644563 test loss: 0.336043
[Epoch 59; Iter     8/  229] train: loss: 0.1084092
[Epoch 59; Iter    38/  229] train: loss: 0.1517133
[Epoch 59; Iter    68/  229] train: loss: 0.1031979
[Epoch 59; Iter    98/  229] train: loss: 0.1371100
[Epoch 59; Iter   128/  229] train: loss: 0.1684942
[Epoch 59; Iter   158/  229] train: loss: 0.1351797
[Epoch 59; Iter   188/  229] train: loss: 0.1169643
[Epoch 59; Iter   218/  229] train: loss: 0.1543034
[Epoch 59] ogbg-moltoxcast: 0.664484 val loss: 0.319560
[Epoch 59] ogbg-moltoxcast: 0.647009 test loss: 0.340669
[Epoch 44; Iter    23/  229] train: loss: 0.1143348
[Epoch 44; Iter    53/  229] train: loss: 0.1220628
[Epoch 44; Iter    83/  229] train: loss: 0.1338103
[Epoch 44; Iter   113/  229] train: loss: 0.1327937
[Epoch 44; Iter   143/  229] train: loss: 0.1399275
[Epoch 44; Iter   173/  229] train: loss: 0.1214719
[Epoch 44; Iter   203/  229] train: loss: 0.0931131
[Epoch 44] ogbg-moltoxcast: 0.658070 val loss: 1.600279
[Epoch 44] ogbg-moltoxcast: 0.632392 test loss: 3.453976
[Epoch 45; Iter     4/  229] train: loss: 0.1213786
[Epoch 45; Iter    34/  229] train: loss: 0.1572414
[Epoch 45; Iter    64/  229] train: loss: 0.1060458
[Epoch 45; Iter    94/  229] train: loss: 0.1528945
[Epoch 45; Iter   124/  229] train: loss: 0.1902326
[Epoch 45; Iter   154/  229] train: loss: 0.1399745
[Epoch 45; Iter   184/  229] train: loss: 0.1799956
[Epoch 45; Iter   214/  229] train: loss: 0.1279238
[Epoch 45] ogbg-moltoxcast: 0.643501 val loss: 1.032742
[Epoch 45] ogbg-moltoxcast: 0.626859 test loss: 2.709525
[Epoch 46; Iter    15/  229] train: loss: 0.1627192
[Epoch 46; Iter    45/  229] train: loss: 0.1728347
[Epoch 46; Iter    75/  229] train: loss: 0.2127519
[Epoch 46; Iter   105/  229] train: loss: 0.1199298
[Epoch 46; Iter   135/  229] train: loss: 0.1502809
[Epoch 46; Iter   165/  229] train: loss: 0.1158359
[Epoch 46; Iter   195/  229] train: loss: 0.1604231
[Epoch 46; Iter   225/  229] train: loss: 0.1147134
[Epoch 46] ogbg-moltoxcast: 0.650119 val loss: 1.190813
[Epoch 46] ogbg-moltoxcast: 0.633667 test loss: 3.026611
[Epoch 47; Iter    26/  229] train: loss: 0.1313722
[Epoch 47; Iter    56/  229] train: loss: 0.1499916
[Epoch 47; Iter    86/  229] train: loss: 0.1135052
[Epoch 47; Iter   116/  229] train: loss: 0.1446025
[Epoch 47; Iter   146/  229] train: loss: 0.1005259
[Epoch 47; Iter   176/  229] train: loss: 0.1405070
[Epoch 47; Iter   206/  229] train: loss: 0.1468727
[Epoch 47] ogbg-moltoxcast: 0.642442 val loss: 1.624126
[Epoch 47] ogbg-moltoxcast: 0.630437 test loss: 3.051613
[Epoch 48; Iter     7/  229] train: loss: 0.1781527
[Epoch 48; Iter    37/  229] train: loss: 0.1124552
[Epoch 48; Iter    67/  229] train: loss: 0.1611533
[Epoch 48; Iter    97/  229] train: loss: 0.1445588
[Epoch 48; Iter   127/  229] train: loss: 0.2154334
[Epoch 48; Iter   157/  229] train: loss: 0.1584581
[Epoch 48; Iter   187/  229] train: loss: 0.1494281
[Epoch 48; Iter   217/  229] train: loss: 0.1041988
[Epoch 48] ogbg-moltoxcast: 0.641401 val loss: 1.565561
[Epoch 48] ogbg-moltoxcast: 0.620537 test loss: 3.185555
[Epoch 49; Iter    18/  229] train: loss: 0.1181508
[Epoch 49; Iter    48/  229] train: loss: 0.1377268
[Epoch 49; Iter    78/  229] train: loss: 0.1096133
[Epoch 49; Iter   108/  229] train: loss: 0.1946166
[Epoch 49; Iter   138/  229] train: loss: 0.1345972
[Epoch 49; Iter   168/  229] train: loss: 0.1268976
[Epoch 49; Iter   198/  229] train: loss: 0.1620639
[Epoch 49; Iter   228/  229] train: loss: 0.1248152
[Epoch 49] ogbg-moltoxcast: 0.644692 val loss: 1.471110
[Epoch 49] ogbg-moltoxcast: 0.622562 test loss: 3.024069
[Epoch 50; Iter    29/  229] train: loss: 0.1379253
[Epoch 50; Iter    59/  229] train: loss: 0.1187464
[Epoch 50; Iter    89/  229] train: loss: 0.1067793
[Epoch 50; Iter   119/  229] train: loss: 0.1341805
[Epoch 50; Iter   149/  229] train: loss: 0.1045780
[Epoch 50; Iter   179/  229] train: loss: 0.1600875
[Epoch 50; Iter   209/  229] train: loss: 0.1157151
[Epoch 50] ogbg-moltoxcast: 0.639782 val loss: 1.591955
[Epoch 50] ogbg-moltoxcast: 0.619130 test loss: 3.287936
[Epoch 51; Iter    10/  229] train: loss: 0.1162256
[Epoch 51; Iter    40/  229] train: loss: 0.1321622
[Epoch 51; Iter    70/  229] train: loss: 0.1363978
[Epoch 51; Iter   100/  229] train: loss: 0.1389240
[Epoch 51; Iter   130/  229] train: loss: 0.1176816
[Epoch 51; Iter   160/  229] train: loss: 0.1201336
[Epoch 51; Iter   190/  229] train: loss: 0.1473923
[Epoch 51; Iter   220/  229] train: loss: 0.0944204
[Epoch 51] ogbg-moltoxcast: 0.647488 val loss: 2.270323
[Epoch 51] ogbg-moltoxcast: 0.627425 test loss: 4.321891
[Epoch 52; Iter    21/  229] train: loss: 0.2009568
[Epoch 52; Iter    51/  229] train: loss: 0.1539249
[Epoch 52; Iter    81/  229] train: loss: 0.1540416
[Epoch 52; Iter   111/  229] train: loss: 0.1282122
[Epoch 52; Iter   141/  229] train: loss: 0.1103687
[Epoch 52; Iter   171/  229] train: loss: 0.1603112
[Epoch 52; Iter   201/  229] train: loss: 0.1398734
[Epoch 52] ogbg-moltoxcast: 0.638632 val loss: 1.721756
[Epoch 52] ogbg-moltoxcast: 0.627628 test loss: 3.376685
[Epoch 53; Iter     2/  229] train: loss: 0.1223456
[Epoch 53; Iter    32/  229] train: loss: 0.1346501
[Epoch 53; Iter    62/  229] train: loss: 0.1409781
[Epoch 53; Iter    92/  229] train: loss: 0.1154821
[Epoch 53; Iter   122/  229] train: loss: 0.1629679
[Epoch 53; Iter   152/  229] train: loss: 0.1496032
[Epoch 53; Iter   182/  229] train: loss: 0.1446502
[Epoch 53; Iter   212/  229] train: loss: 0.1430803
[Epoch 53] ogbg-moltoxcast: 0.633809 val loss: 2.231281
[Epoch 53] ogbg-moltoxcast: 0.625210 test loss: 4.099219
[Epoch 54; Iter    13/  229] train: loss: 0.0902063
[Epoch 54; Iter    43/  229] train: loss: 0.1522971
[Epoch 54; Iter    73/  229] train: loss: 0.1097159
[Epoch 54; Iter   103/  229] train: loss: 0.1551262
[Epoch 54; Iter   133/  229] train: loss: 0.1720167
[Epoch 54; Iter   163/  229] train: loss: 0.1595677
[Epoch 54; Iter   193/  229] train: loss: 0.1983059
[Epoch 54; Iter   223/  229] train: loss: 0.1766549
[Epoch 54] ogbg-moltoxcast: 0.640616 val loss: 2.540633
[Epoch 54] ogbg-moltoxcast: 0.627503 test loss: 4.341555
[Epoch 55; Iter    24/  229] train: loss: 0.1232149
[Epoch 55; Iter    54/  229] train: loss: 0.1758354
[Epoch 55; Iter    84/  229] train: loss: 0.1493945
[Epoch 55; Iter   114/  229] train: loss: 0.1398704
[Epoch 55; Iter   144/  229] train: loss: 0.1223689
[Epoch 55; Iter   174/  229] train: loss: 0.1454566
[Epoch 55; Iter   204/  229] train: loss: 0.0930827
[Epoch 55] ogbg-moltoxcast: 0.635585 val loss: 1.867308
[Epoch 55] ogbg-moltoxcast: 0.626238 test loss: 3.464336
[Epoch 56; Iter     5/  229] train: loss: 0.1325997
[Epoch 56; Iter    35/  229] train: loss: 0.1271742
[Epoch 56; Iter    65/  229] train: loss: 0.1223528
[Epoch 56; Iter    95/  229] train: loss: 0.1111037
[Epoch 56; Iter   125/  229] train: loss: 0.1503411
[Epoch 56; Iter   155/  229] train: loss: 0.1295472
[Epoch 56; Iter   185/  229] train: loss: 0.1120004
[Epoch 56; Iter   215/  229] train: loss: 0.1354063
[Epoch 56] ogbg-moltoxcast: 0.642587 val loss: 2.551285
[Epoch 56] ogbg-moltoxcast: 0.628509 test loss: 4.414316
[Epoch 57; Iter    16/  229] train: loss: 0.1494077
[Epoch 57; Iter    46/  229] train: loss: 0.1382174
[Epoch 57; Iter    76/  229] train: loss: 0.1457136
[Epoch 57; Iter   106/  229] train: loss: 0.1086546
[Epoch 57; Iter   136/  229] train: loss: 0.1270577
[Epoch 57; Iter   166/  229] train: loss: 0.1124087
[Epoch 57; Iter   196/  229] train: loss: 0.1314559
[Epoch 57; Iter   226/  229] train: loss: 0.1503174
[Epoch 57] ogbg-moltoxcast: 0.638981 val loss: 2.368169
[Epoch 57] ogbg-moltoxcast: 0.623678 test loss: 4.028559
[Epoch 58; Iter    27/  229] train: loss: 0.1392005
[Epoch 58; Iter    57/  229] train: loss: 0.1466561
[Epoch 58; Iter    87/  229] train: loss: 0.1125984
[Epoch 58; Iter   117/  229] train: loss: 0.1095997
[Epoch 58; Iter   147/  229] train: loss: 0.1341382
[Epoch 58; Iter   177/  229] train: loss: 0.2050185
[Epoch 58; Iter   207/  229] train: loss: 0.1484223
[Epoch 58] ogbg-moltoxcast: 0.635218 val loss: 2.297045
[Epoch 58] ogbg-moltoxcast: 0.618693 test loss: 3.619397
[Epoch 59; Iter     8/  229] train: loss: 0.1058433
[Epoch 59; Iter    38/  229] train: loss: 0.1440044
[Epoch 59; Iter    68/  229] train: loss: 0.1060028
[Epoch 59; Iter    98/  229] train: loss: 0.1327926
[Epoch 59; Iter   128/  229] train: loss: 0.1625356
[Epoch 59; Iter   158/  229] train: loss: 0.1319587
[Epoch 59; Iter   188/  229] train: loss: 0.1008469
[Epoch 59; Iter   218/  229] train: loss: 0.1520051
[Epoch 59] ogbg-moltoxcast: 0.632480 val loss: 2.081796
[Epoch 59] ogbg-moltoxcast: 0.613852 test loss: 3.736842
[Epoch 44; Iter    23/  229] train: loss: 0.1999736
[Epoch 44; Iter    53/  229] train: loss: 0.0901795
[Epoch 44; Iter    83/  229] train: loss: 0.1379688
[Epoch 44; Iter   113/  229] train: loss: 0.1309879
[Epoch 44; Iter   143/  229] train: loss: 0.1697782
[Epoch 44; Iter   173/  229] train: loss: 0.1518137
[Epoch 44; Iter   203/  229] train: loss: 0.1435308
[Epoch 44] ogbg-moltoxcast: 0.664525 val loss: 0.296936
[Epoch 44] ogbg-moltoxcast: 0.651629 test loss: 0.341828
[Epoch 45; Iter     4/  229] train: loss: 0.1166031
[Epoch 45; Iter    34/  229] train: loss: 0.1245684
[Epoch 45; Iter    64/  229] train: loss: 0.1546737
[Epoch 45; Iter    94/  229] train: loss: 0.0956394
[Epoch 45; Iter   124/  229] train: loss: 0.1447835
[Epoch 45; Iter   154/  229] train: loss: 0.1214131
[Epoch 45; Iter   184/  229] train: loss: 0.1010054
[Epoch 45; Iter   214/  229] train: loss: 0.0910221
[Epoch 45] ogbg-moltoxcast: 0.660506 val loss: 0.314068
[Epoch 45] ogbg-moltoxcast: 0.647801 test loss: 0.360170
[Epoch 46; Iter    15/  229] train: loss: 0.1544234
[Epoch 46; Iter    45/  229] train: loss: 0.1693176
[Epoch 46; Iter    75/  229] train: loss: 0.1363918
[Epoch 46; Iter   105/  229] train: loss: 0.1702143
[Epoch 46; Iter   135/  229] train: loss: 0.1576226
[Epoch 46; Iter   165/  229] train: loss: 0.1292403
[Epoch 46; Iter   195/  229] train: loss: 0.1370884
[Epoch 46; Iter   225/  229] train: loss: 0.1437455
[Epoch 46] ogbg-moltoxcast: 0.652751 val loss: 0.312485
[Epoch 46] ogbg-moltoxcast: 0.643186 test loss: 0.359234
[Epoch 47; Iter    26/  229] train: loss: 0.1609689
[Epoch 47; Iter    56/  229] train: loss: 0.1604025
[Epoch 47; Iter    86/  229] train: loss: 0.1381713
[Epoch 47; Iter   116/  229] train: loss: 0.1143305
[Epoch 47; Iter   146/  229] train: loss: 0.1244925
[Epoch 47; Iter   176/  229] train: loss: 0.1058152
[Epoch 47; Iter   206/  229] train: loss: 0.1192417
[Epoch 47] ogbg-moltoxcast: 0.652700 val loss: 0.315541
[Epoch 47] ogbg-moltoxcast: 0.641067 test loss: 0.366923
[Epoch 48; Iter     7/  229] train: loss: 0.1425311
[Epoch 48; Iter    37/  229] train: loss: 0.1348391
[Epoch 48; Iter    67/  229] train: loss: 0.1225070
[Epoch 48; Iter    97/  229] train: loss: 0.1410227
[Epoch 48; Iter   127/  229] train: loss: 0.1375707
[Epoch 48; Iter   157/  229] train: loss: 0.1081855
[Epoch 48; Iter   187/  229] train: loss: 0.1443828
[Epoch 48; Iter   217/  229] train: loss: 0.1377184
[Epoch 48] ogbg-moltoxcast: 0.660903 val loss: 0.307638
[Epoch 48] ogbg-moltoxcast: 0.647648 test loss: 0.356297
[Epoch 49; Iter    18/  229] train: loss: 0.1548299
[Epoch 49; Iter    48/  229] train: loss: 0.1328290
[Epoch 49; Iter    78/  229] train: loss: 0.0936995
[Epoch 49; Iter   108/  229] train: loss: 0.1228043
[Epoch 49; Iter   138/  229] train: loss: 0.1157747
[Epoch 49; Iter   168/  229] train: loss: 0.1305684
[Epoch 49; Iter   198/  229] train: loss: 0.1401106
[Epoch 49; Iter   228/  229] train: loss: 0.1463216
[Epoch 49] ogbg-moltoxcast: 0.654563 val loss: 0.313413
[Epoch 49] ogbg-moltoxcast: 0.641640 test loss: 0.365520
[Epoch 50; Iter    29/  229] train: loss: 0.1147590
[Epoch 50; Iter    59/  229] train: loss: 0.1379344
[Epoch 50; Iter    89/  229] train: loss: 0.0802028
[Epoch 50; Iter   119/  229] train: loss: 0.1668628
[Epoch 50; Iter   149/  229] train: loss: 0.1324297
[Epoch 50; Iter   179/  229] train: loss: 0.1411584
[Epoch 50; Iter   209/  229] train: loss: 0.1092213
[Epoch 50] ogbg-moltoxcast: 0.653201 val loss: 0.306783
[Epoch 50] ogbg-moltoxcast: 0.641204 test loss: 0.362656
[Epoch 51; Iter    10/  229] train: loss: 0.1577002
[Epoch 51; Iter    40/  229] train: loss: 0.1058242
[Epoch 51; Iter    70/  229] train: loss: 0.1428166
[Epoch 51; Iter   100/  229] train: loss: 0.1462077
[Epoch 51; Iter   130/  229] train: loss: 0.1079770
[Epoch 51; Iter   160/  229] train: loss: 0.1046362
[Epoch 51; Iter   190/  229] train: loss: 0.1309518
[Epoch 51; Iter   220/  229] train: loss: 0.1603096
[Epoch 51] ogbg-moltoxcast: 0.644075 val loss: 0.327458
[Epoch 51] ogbg-moltoxcast: 0.634439 test loss: 0.388318
[Epoch 52; Iter    21/  229] train: loss: 0.1185390
[Epoch 52; Iter    51/  229] train: loss: 0.1387367
[Epoch 52; Iter    81/  229] train: loss: 0.1234446
[Epoch 52; Iter   111/  229] train: loss: 0.1828606
[Epoch 52; Iter   141/  229] train: loss: 0.1406015
[Epoch 52; Iter   171/  229] train: loss: 0.1529444
[Epoch 52; Iter   201/  229] train: loss: 0.1320667
[Epoch 52] ogbg-moltoxcast: 0.645848 val loss: 0.325099
[Epoch 52] ogbg-moltoxcast: 0.638010 test loss: 0.382984
[Epoch 53; Iter     2/  229] train: loss: 0.0927984
[Epoch 53; Iter    32/  229] train: loss: 0.1309794
[Epoch 53; Iter    62/  229] train: loss: 0.1442924
[Epoch 53; Iter    92/  229] train: loss: 0.1688109
[Epoch 53; Iter   122/  229] train: loss: 0.0787701
[Epoch 53; Iter   152/  229] train: loss: 0.1116282
[Epoch 53; Iter   182/  229] train: loss: 0.1248962
[Epoch 53; Iter   212/  229] train: loss: 0.1196800
[Epoch 53] ogbg-moltoxcast: 0.651806 val loss: 0.316821
[Epoch 53] ogbg-moltoxcast: 0.634073 test loss: 0.376813
[Epoch 54; Iter    13/  229] train: loss: 0.0819781
[Epoch 54; Iter    43/  229] train: loss: 0.1383200
[Epoch 54; Iter    73/  229] train: loss: 0.1206533
[Epoch 54; Iter   103/  229] train: loss: 0.1293609
[Epoch 54; Iter   133/  229] train: loss: 0.1393162
[Epoch 54; Iter   163/  229] train: loss: 0.1598898
[Epoch 54; Iter   193/  229] train: loss: 0.1504191
[Epoch 54; Iter   223/  229] train: loss: 0.1663862
[Epoch 54] ogbg-moltoxcast: 0.651439 val loss: 0.312354
[Epoch 54] ogbg-moltoxcast: 0.642996 test loss: 0.363826
[Epoch 55; Iter    24/  229] train: loss: 0.1658748
[Epoch 55; Iter    54/  229] train: loss: 0.1791561
[Epoch 55; Iter    84/  229] train: loss: 0.0939185
[Epoch 55; Iter   114/  229] train: loss: 0.1576967
[Epoch 55; Iter   144/  229] train: loss: 0.1446128
[Epoch 55; Iter   174/  229] train: loss: 0.1615873
[Epoch 55; Iter   204/  229] train: loss: 0.1077032
[Epoch 55] ogbg-moltoxcast: 0.654214 val loss: 0.310416
[Epoch 55] ogbg-moltoxcast: 0.639813 test loss: 0.358853
[Epoch 56; Iter     5/  229] train: loss: 0.1121305
[Epoch 56; Iter    35/  229] train: loss: 0.1379927
[Epoch 56; Iter    65/  229] train: loss: 0.1170639
[Epoch 56; Iter    95/  229] train: loss: 0.1421787
[Epoch 56; Iter   125/  229] train: loss: 0.0900461
[Epoch 56; Iter   155/  229] train: loss: 0.1056145
[Epoch 56; Iter   185/  229] train: loss: 0.1322421
[Epoch 56; Iter   215/  229] train: loss: 0.1346972
[Epoch 56] ogbg-moltoxcast: 0.661490 val loss: 0.316106
[Epoch 56] ogbg-moltoxcast: 0.646660 test loss: 0.367194
[Epoch 57; Iter    16/  229] train: loss: 0.1082138
[Epoch 57; Iter    46/  229] train: loss: 0.1175983
[Epoch 57; Iter    76/  229] train: loss: 0.1772102
[Epoch 57; Iter   106/  229] train: loss: 0.1514132
[Epoch 57; Iter   136/  229] train: loss: 0.1282523
[Epoch 57; Iter   166/  229] train: loss: 0.0949136
[Epoch 57; Iter   196/  229] train: loss: 0.1645376
[Epoch 57; Iter   226/  229] train: loss: 0.1759987
[Epoch 57] ogbg-moltoxcast: 0.656853 val loss: 0.319818
[Epoch 57] ogbg-moltoxcast: 0.637830 test loss: 0.373659
[Epoch 58; Iter    27/  229] train: loss: 0.1070964
[Epoch 58; Iter    57/  229] train: loss: 0.1000384
[Epoch 58; Iter    87/  229] train: loss: 0.1138166
[Epoch 58; Iter   117/  229] train: loss: 0.0986659
[Epoch 58; Iter   147/  229] train: loss: 0.1097102
[Epoch 58; Iter   177/  229] train: loss: 0.1614443
[Epoch 58; Iter   207/  229] train: loss: 0.1119537
[Epoch 58] ogbg-moltoxcast: 0.657089 val loss: 0.318040
[Epoch 58] ogbg-moltoxcast: 0.632967 test loss: 0.376032
[Epoch 59; Iter     8/  229] train: loss: 0.1159652
[Epoch 59; Iter    38/  229] train: loss: 0.1281332
[Epoch 59; Iter    68/  229] train: loss: 0.1119185
[Epoch 59; Iter    98/  229] train: loss: 0.1657747
[Epoch 59; Iter   128/  229] train: loss: 0.1517653
[Epoch 59; Iter   158/  229] train: loss: 0.1078205
[Epoch 59; Iter   188/  229] train: loss: 0.1155694
[Epoch 59; Iter   218/  229] train: loss: 0.1088719
[Epoch 59] ogbg-moltoxcast: 0.650399 val loss: 0.322499
[Epoch 59] ogbg-moltoxcast: 0.635852 test loss: 0.375916
[Epoch 44; Iter    23/  229] train: loss: 0.2264849
[Epoch 44; Iter    53/  229] train: loss: 0.0886771
[Epoch 44; Iter    83/  229] train: loss: 0.1390251
[Epoch 44; Iter   113/  229] train: loss: 0.1349181
[Epoch 44; Iter   143/  229] train: loss: 0.1792378
[Epoch 44; Iter   173/  229] train: loss: 0.1813403
[Epoch 44; Iter   203/  229] train: loss: 0.1456348
[Epoch 44] ogbg-moltoxcast: 0.705559 val loss: 0.245466
[Epoch 44] ogbg-moltoxcast: 0.666341 test loss: 0.306116
[Epoch 45; Iter     4/  229] train: loss: 0.1232257
[Epoch 45; Iter    34/  229] train: loss: 0.1231837
[Epoch 45; Iter    64/  229] train: loss: 0.1774980
[Epoch 45; Iter    94/  229] train: loss: 0.1012383
[Epoch 45; Iter   124/  229] train: loss: 0.1465953
[Epoch 45; Iter   154/  229] train: loss: 0.1291458
[Epoch 45; Iter   184/  229] train: loss: 0.1219420
[Epoch 45; Iter   214/  229] train: loss: 0.1104531
[Epoch 45] ogbg-moltoxcast: 0.704615 val loss: 0.247379
[Epoch 45] ogbg-moltoxcast: 0.671021 test loss: 0.307819
[Epoch 46; Iter    15/  229] train: loss: 0.1821057
[Epoch 46; Iter    45/  229] train: loss: 0.1924276
[Epoch 46; Iter    75/  229] train: loss: 0.1452564
[Epoch 46; Iter   105/  229] train: loss: 0.1902489
[Epoch 46; Iter   135/  229] train: loss: 0.1714316
[Epoch 46; Iter   165/  229] train: loss: 0.1479156
[Epoch 46; Iter   195/  229] train: loss: 0.1530933
[Epoch 46; Iter   225/  229] train: loss: 0.1574866
[Epoch 46] ogbg-moltoxcast: 0.716601 val loss: 0.251838
[Epoch 46] ogbg-moltoxcast: 0.668564 test loss: 0.318547
[Epoch 47; Iter    26/  229] train: loss: 0.1636443
[Epoch 47; Iter    56/  229] train: loss: 0.1707651
[Epoch 47; Iter    86/  229] train: loss: 0.1491275
[Epoch 47; Iter   116/  229] train: loss: 0.1297825
[Epoch 47; Iter   146/  229] train: loss: 0.1247748
[Epoch 47; Iter   176/  229] train: loss: 0.1116011
[Epoch 47; Iter   206/  229] train: loss: 0.1319237
[Epoch 47] ogbg-moltoxcast: 0.703550 val loss: 0.257762
[Epoch 47] ogbg-moltoxcast: 0.670302 test loss: 0.314986
[Epoch 48; Iter     7/  229] train: loss: 0.1540356
[Epoch 48; Iter    37/  229] train: loss: 0.1363062
[Epoch 48; Iter    67/  229] train: loss: 0.1215944
[Epoch 48; Iter    97/  229] train: loss: 0.1487880
[Epoch 48; Iter   127/  229] train: loss: 0.1480041
[Epoch 48; Iter   157/  229] train: loss: 0.1217473
[Epoch 48; Iter   187/  229] train: loss: 0.1528045
[Epoch 48; Iter   217/  229] train: loss: 0.1440135
[Epoch 48] ogbg-moltoxcast: 0.702789 val loss: 0.252574
[Epoch 48] ogbg-moltoxcast: 0.671333 test loss: 0.308870
[Epoch 49; Iter    18/  229] train: loss: 0.1653854
[Epoch 49; Iter    48/  229] train: loss: 0.1472142
[Epoch 49; Iter    78/  229] train: loss: 0.0897216
[Epoch 49; Iter   108/  229] train: loss: 0.1332829
[Epoch 49; Iter   138/  229] train: loss: 0.1278258
[Epoch 49; Iter   168/  229] train: loss: 0.1354849
[Epoch 49; Iter   198/  229] train: loss: 0.1466219
[Epoch 49; Iter   228/  229] train: loss: 0.1681656
[Epoch 49] ogbg-moltoxcast: 0.704880 val loss: 0.253895
[Epoch 49] ogbg-moltoxcast: 0.674955 test loss: 0.307377
[Epoch 50; Iter    29/  229] train: loss: 0.1128514
[Epoch 50; Iter    59/  229] train: loss: 0.1580453
[Epoch 50; Iter    89/  229] train: loss: 0.0847655
[Epoch 50; Iter   119/  229] train: loss: 0.1752099
[Epoch 50; Iter   149/  229] train: loss: 0.1431818
[Epoch 50; Iter   179/  229] train: loss: 0.1425008
[Epoch 50; Iter   209/  229] train: loss: 0.1178907
[Epoch 50] ogbg-moltoxcast: 0.697912 val loss: 0.251743
[Epoch 50] ogbg-moltoxcast: 0.663674 test loss: 0.306254
[Epoch 51; Iter    10/  229] train: loss: 0.1681324
[Epoch 51; Iter    40/  229] train: loss: 0.1074758
[Epoch 51; Iter    70/  229] train: loss: 0.1577649
[Epoch 51; Iter   100/  229] train: loss: 0.1703412
[Epoch 51; Iter   130/  229] train: loss: 0.1137150
[Epoch 51; Iter   160/  229] train: loss: 0.1147684
[Epoch 51; Iter   190/  229] train: loss: 0.1450088
[Epoch 51; Iter   220/  229] train: loss: 0.1603104
[Epoch 51] ogbg-moltoxcast: 0.705770 val loss: 0.249206
[Epoch 51] ogbg-moltoxcast: 0.675873 test loss: 0.302145
[Epoch 52; Iter    21/  229] train: loss: 0.1338279
[Epoch 52; Iter    51/  229] train: loss: 0.1601805
[Epoch 52; Iter    81/  229] train: loss: 0.1255042
[Epoch 52; Iter   111/  229] train: loss: 0.1902180
[Epoch 52; Iter   141/  229] train: loss: 0.1535891
[Epoch 52; Iter   171/  229] train: loss: 0.1724107
[Epoch 52; Iter   201/  229] train: loss: 0.1518135
[Epoch 52] ogbg-moltoxcast: 0.693831 val loss: 0.254669
[Epoch 52] ogbg-moltoxcast: 0.665864 test loss: 0.307921
[Epoch 53; Iter     2/  229] train: loss: 0.0997288
[Epoch 53; Iter    32/  229] train: loss: 0.1228001
[Epoch 53; Iter    62/  229] train: loss: 0.1482532
[Epoch 53; Iter    92/  229] train: loss: 0.1810121
[Epoch 53; Iter   122/  229] train: loss: 0.0987774
[Epoch 53; Iter   152/  229] train: loss: 0.1239230
[Epoch 53; Iter   182/  229] train: loss: 0.1384839
[Epoch 53; Iter   212/  229] train: loss: 0.1269152
[Epoch 53] ogbg-moltoxcast: 0.703958 val loss: 0.252785
[Epoch 53] ogbg-moltoxcast: 0.668591 test loss: 0.307035
[Epoch 54; Iter    13/  229] train: loss: 0.0871103
[Epoch 54; Iter    43/  229] train: loss: 0.1643041
[Epoch 54; Iter    73/  229] train: loss: 0.1188603
[Epoch 54; Iter   103/  229] train: loss: 0.1450619
[Epoch 54; Iter   133/  229] train: loss: 0.1586923
[Epoch 54; Iter   163/  229] train: loss: 0.1787100
[Epoch 54; Iter   193/  229] train: loss: 0.1572791
[Epoch 54; Iter   223/  229] train: loss: 0.1827616
[Epoch 54] ogbg-moltoxcast: 0.700767 val loss: 0.252091
[Epoch 54] ogbg-moltoxcast: 0.675351 test loss: 0.309961
[Epoch 55; Iter    24/  229] train: loss: 0.1793937
[Epoch 55; Iter    54/  229] train: loss: 0.1892455
[Epoch 55; Iter    84/  229] train: loss: 0.1121193
[Epoch 55; Iter   114/  229] train: loss: 0.1992428
[Epoch 55; Iter   144/  229] train: loss: 0.1766348
[Epoch 55; Iter   174/  229] train: loss: 0.1710216
[Epoch 55; Iter   204/  229] train: loss: 0.1057604
[Epoch 55] ogbg-moltoxcast: 0.699349 val loss: 0.253260
[Epoch 55] ogbg-moltoxcast: 0.662835 test loss: 0.309124
[Epoch 56; Iter     5/  229] train: loss: 0.1260610
[Epoch 56; Iter    35/  229] train: loss: 0.1441931
[Epoch 56; Iter    65/  229] train: loss: 0.1292225
[Epoch 56; Iter    95/  229] train: loss: 0.1394640
[Epoch 56; Iter   125/  229] train: loss: 0.0978814
[Epoch 56; Iter   155/  229] train: loss: 0.1073519
[Epoch 56; Iter   185/  229] train: loss: 0.1444837
[Epoch 56; Iter   215/  229] train: loss: 0.1415189
[Epoch 56] ogbg-moltoxcast: 0.709785 val loss: 0.249834
[Epoch 56] ogbg-moltoxcast: 0.662099 test loss: 0.313367
[Epoch 57; Iter    16/  229] train: loss: 0.1060757
[Epoch 57; Iter    46/  229] train: loss: 0.1183152
[Epoch 57; Iter    76/  229] train: loss: 0.1899498
[Epoch 57; Iter   106/  229] train: loss: 0.1603939
[Epoch 57; Iter   136/  229] train: loss: 0.1375384
[Epoch 57; Iter   166/  229] train: loss: 0.1127108
[Epoch 57; Iter   196/  229] train: loss: 0.1671257
[Epoch 57; Iter   226/  229] train: loss: 0.1956039
[Epoch 57] ogbg-moltoxcast: 0.709224 val loss: 0.251696
[Epoch 57] ogbg-moltoxcast: 0.668171 test loss: 0.316320
[Epoch 58; Iter    27/  229] train: loss: 0.1208176
[Epoch 58; Iter    57/  229] train: loss: 0.1067629
[Epoch 58; Iter    87/  229] train: loss: 0.1279798
[Epoch 58; Iter   117/  229] train: loss: 0.1006484
[Epoch 58; Iter   147/  229] train: loss: 0.1381811
[Epoch 58; Iter   177/  229] train: loss: 0.1651250
[Epoch 58; Iter   207/  229] train: loss: 0.1117299
[Epoch 58] ogbg-moltoxcast: 0.698846 val loss: 0.249670
[Epoch 58] ogbg-moltoxcast: 0.661016 test loss: 0.312062
[Epoch 59; Iter     8/  229] train: loss: 0.1249564
[Epoch 59; Iter    38/  229] train: loss: 0.1350152
[Epoch 59; Iter    68/  229] train: loss: 0.1161533
[Epoch 59; Iter    98/  229] train: loss: 0.1755823
[Epoch 59; Iter   128/  229] train: loss: 0.1596832
[Epoch 59; Iter   158/  229] train: loss: 0.1197142
[Epoch 59; Iter   188/  229] train: loss: 0.1309542
[Epoch 59; Iter   218/  229] train: loss: 0.1140565
[Epoch 59] ogbg-moltoxcast: 0.703307 val loss: 0.252697
[Epoch 59] ogbg-moltoxcast: 0.672537 test loss: 0.313717
[Epoch 44; Iter    23/  229] train: loss: 0.1843886
[Epoch 44; Iter    53/  229] train: loss: 0.1059363
[Epoch 44; Iter    83/  229] train: loss: 0.1530440
[Epoch 44; Iter   113/  229] train: loss: 0.0952458
[Epoch 44; Iter   143/  229] train: loss: 0.1496808
[Epoch 44; Iter   173/  229] train: loss: 0.1277926
[Epoch 44; Iter   203/  229] train: loss: 0.1495623
[Epoch 44] ogbg-moltoxcast: 0.691792 val loss: 0.252056
[Epoch 44] ogbg-moltoxcast: 0.662090 test loss: 0.301775
[Epoch 45; Iter     4/  229] train: loss: 0.1187527
[Epoch 45; Iter    34/  229] train: loss: 0.1272575
[Epoch 45; Iter    64/  229] train: loss: 0.1670236
[Epoch 45; Iter    94/  229] train: loss: 0.1284234
[Epoch 45; Iter   124/  229] train: loss: 0.1470515
[Epoch 45; Iter   154/  229] train: loss: 0.1368459
[Epoch 45; Iter   184/  229] train: loss: 0.1564129
[Epoch 45; Iter   214/  229] train: loss: 0.1558041
[Epoch 45] ogbg-moltoxcast: 0.687911 val loss: 0.250168
[Epoch 45] ogbg-moltoxcast: 0.660808 test loss: 0.298532
[Epoch 46; Iter    15/  229] train: loss: 0.1333483
[Epoch 46; Iter    45/  229] train: loss: 0.1586552
[Epoch 46; Iter    75/  229] train: loss: 0.2113491
[Epoch 46; Iter   105/  229] train: loss: 0.1531540
[Epoch 46; Iter   135/  229] train: loss: 0.1446548
[Epoch 46; Iter   165/  229] train: loss: 0.1264178
[Epoch 46; Iter   195/  229] train: loss: 0.1506032
[Epoch 46; Iter   225/  229] train: loss: 0.1625613
[Epoch 46] ogbg-moltoxcast: 0.672418 val loss: 0.255427
[Epoch 46] ogbg-moltoxcast: 0.654533 test loss: 0.305447
[Epoch 47; Iter    26/  229] train: loss: 0.1545801
[Epoch 47; Iter    56/  229] train: loss: 0.1572247
[Epoch 47; Iter    86/  229] train: loss: 0.1347034
[Epoch 47; Iter   116/  229] train: loss: 0.0953220
[Epoch 47; Iter   146/  229] train: loss: 0.1204580
[Epoch 47; Iter   176/  229] train: loss: 0.1615346
[Epoch 47; Iter   206/  229] train: loss: 0.1404316
[Epoch 47] ogbg-moltoxcast: 0.681591 val loss: 0.253592
[Epoch 47] ogbg-moltoxcast: 0.656752 test loss: 0.302161
[Epoch 48; Iter     7/  229] train: loss: 0.1227152
[Epoch 48; Iter    37/  229] train: loss: 0.1246189
[Epoch 48; Iter    67/  229] train: loss: 0.1489461
[Epoch 48; Iter    97/  229] train: loss: 0.1698775
[Epoch 48; Iter   127/  229] train: loss: 0.1644041
[Epoch 48; Iter   157/  229] train: loss: 0.1141821
[Epoch 48; Iter   187/  229] train: loss: 0.1896807
[Epoch 48; Iter   217/  229] train: loss: 0.1438832
[Epoch 48] ogbg-moltoxcast: 0.680042 val loss: 0.262632
[Epoch 48] ogbg-moltoxcast: 0.650015 test loss: 0.311660
[Epoch 49; Iter    18/  229] train: loss: 0.1780891
[Epoch 49; Iter    48/  229] train: loss: 0.1202103
[Epoch 49; Iter    78/  229] train: loss: 0.1792873
[Epoch 49; Iter   108/  229] train: loss: 0.1336836
[Epoch 49; Iter   138/  229] train: loss: 0.1723468
[Epoch 49; Iter   168/  229] train: loss: 0.1212621
[Epoch 49; Iter   198/  229] train: loss: 0.1412496
[Epoch 49; Iter   228/  229] train: loss: 0.1346210
[Epoch 49] ogbg-moltoxcast: 0.686184 val loss: 0.255014
[Epoch 49] ogbg-moltoxcast: 0.656298 test loss: 0.302779
[Epoch 50; Iter    29/  229] train: loss: 0.1626970
[Epoch 50; Iter    59/  229] train: loss: 0.1366295
[Epoch 50; Iter    89/  229] train: loss: 0.1627083
[Epoch 50; Iter   119/  229] train: loss: 0.1253844
[Epoch 50; Iter   149/  229] train: loss: 0.1616828
[Epoch 50; Iter   179/  229] train: loss: 0.1733536
[Epoch 50; Iter   209/  229] train: loss: 0.2014156
[Epoch 50] ogbg-moltoxcast: 0.686191 val loss: 0.252009
[Epoch 50] ogbg-moltoxcast: 0.654238 test loss: 0.307982
[Epoch 51; Iter    10/  229] train: loss: 0.1688887
[Epoch 51; Iter    40/  229] train: loss: 0.0997753
[Epoch 51; Iter    70/  229] train: loss: 0.1632632
[Epoch 51; Iter   100/  229] train: loss: 0.1613082
[Epoch 51; Iter   130/  229] train: loss: 0.1228642
[Epoch 51; Iter   160/  229] train: loss: 0.1191549
[Epoch 51; Iter   190/  229] train: loss: 0.1095177
[Epoch 51; Iter   220/  229] train: loss: 0.1656498
[Epoch 51] ogbg-moltoxcast: 0.687699 val loss: 0.253751
[Epoch 51] ogbg-moltoxcast: 0.657674 test loss: 0.304314
[Epoch 52; Iter    21/  229] train: loss: 0.1486205
[Epoch 52; Iter    51/  229] train: loss: 0.1379902
[Epoch 52; Iter    81/  229] train: loss: 0.1560814
[Epoch 52; Iter   111/  229] train: loss: 0.1173953
[Epoch 52; Iter   141/  229] train: loss: 0.1301934
[Epoch 52; Iter   171/  229] train: loss: 0.0837205
[Epoch 52; Iter   201/  229] train: loss: 0.1227874
[Epoch 52] ogbg-moltoxcast: 0.677381 val loss: 0.255802
[Epoch 52] ogbg-moltoxcast: 0.648658 test loss: 0.309222
[Epoch 53; Iter     2/  229] train: loss: 0.1097873
[Epoch 53; Iter    32/  229] train: loss: 0.0924182
[Epoch 53; Iter    62/  229] train: loss: 0.1338834
[Epoch 53; Iter    92/  229] train: loss: 0.1144331
[Epoch 53; Iter   122/  229] train: loss: 0.1056914
[Epoch 53; Iter   152/  229] train: loss: 0.1561530
[Epoch 53; Iter   182/  229] train: loss: 0.1354111
[Epoch 53; Iter   212/  229] train: loss: 0.1574510
[Epoch 53] ogbg-moltoxcast: 0.686299 val loss: 0.259923
[Epoch 53] ogbg-moltoxcast: 0.657916 test loss: 0.306868
[Epoch 54; Iter    13/  229] train: loss: 0.0936452
[Epoch 54; Iter    43/  229] train: loss: 0.0978789
[Epoch 54; Iter    73/  229] train: loss: 0.1252038
[Epoch 54; Iter   103/  229] train: loss: 0.1048040
[Epoch 54; Iter   133/  229] train: loss: 0.1206400
[Epoch 54; Iter   163/  229] train: loss: 0.1254055
[Epoch 54; Iter   193/  229] train: loss: 0.1554903
[Epoch 54; Iter   223/  229] train: loss: 0.1745140
[Epoch 54] ogbg-moltoxcast: 0.679546 val loss: 0.257372
[Epoch 54] ogbg-moltoxcast: 0.655042 test loss: 0.310916
[Epoch 55; Iter    24/  229] train: loss: 0.1682225
[Epoch 55; Iter    54/  229] train: loss: 0.1674983
[Epoch 55; Iter    84/  229] train: loss: 0.1290281
[Epoch 55; Iter   114/  229] train: loss: 0.1374671
[Epoch 55; Iter   144/  229] train: loss: 0.1421679
[Epoch 55; Iter   174/  229] train: loss: 0.1449495
[Epoch 55; Iter   204/  229] train: loss: 0.1676448
[Epoch 55] ogbg-moltoxcast: 0.689100 val loss: 0.252916
[Epoch 55] ogbg-moltoxcast: 0.652911 test loss: 0.311609
[Epoch 56; Iter     5/  229] train: loss: 0.1467443
[Epoch 56; Iter    35/  229] train: loss: 0.1023606
[Epoch 56; Iter    65/  229] train: loss: 0.1843311
[Epoch 56; Iter    95/  229] train: loss: 0.1348189
[Epoch 56; Iter   125/  229] train: loss: 0.1481176
[Epoch 56; Iter   155/  229] train: loss: 0.1409911
[Epoch 56; Iter   185/  229] train: loss: 0.1568080
[Epoch 56; Iter   215/  229] train: loss: 0.1214026
[Epoch 56] ogbg-moltoxcast: 0.689324 val loss: 0.278739
[Epoch 56] ogbg-moltoxcast: 0.659759 test loss: 0.309943
[Epoch 57; Iter    16/  229] train: loss: 0.1948642
[Epoch 57; Iter    46/  229] train: loss: 0.1349595
[Epoch 57; Iter    76/  229] train: loss: 0.1097557
[Epoch 57; Iter   106/  229] train: loss: 0.1570770
[Epoch 57; Iter   136/  229] train: loss: 0.1194018
[Epoch 57; Iter   166/  229] train: loss: 0.1009194
[Epoch 57; Iter   196/  229] train: loss: 0.1350736
[Epoch 57; Iter   226/  229] train: loss: 0.2185119
[Epoch 57] ogbg-moltoxcast: 0.686353 val loss: 0.255892
[Epoch 57] ogbg-moltoxcast: 0.655213 test loss: 0.312202
[Epoch 58; Iter    27/  229] train: loss: 0.1437173
[Epoch 58; Iter    57/  229] train: loss: 0.1589039
[Epoch 58; Iter    87/  229] train: loss: 0.1420552
[Epoch 58; Iter   117/  229] train: loss: 0.1437139
[Epoch 58; Iter   147/  229] train: loss: 0.2036111
[Epoch 58; Iter   177/  229] train: loss: 0.1999174
[Epoch 58; Iter   207/  229] train: loss: 0.1255480
[Epoch 58] ogbg-moltoxcast: 0.686098 val loss: 0.254165
[Epoch 58] ogbg-moltoxcast: 0.659209 test loss: 0.305029
[Epoch 59; Iter     8/  229] train: loss: 0.1361603
[Epoch 59; Iter    38/  229] train: loss: 0.1215909
[Epoch 59; Iter    68/  229] train: loss: 0.1277279
[Epoch 59; Iter    98/  229] train: loss: 0.1145828
[Epoch 59; Iter   128/  229] train: loss: 0.1230592
[Epoch 59; Iter   158/  229] train: loss: 0.1355696
[Epoch 59; Iter   188/  229] train: loss: 0.1268574
[Epoch 59; Iter   218/  229] train: loss: 0.1285722
[Epoch 59] ogbg-moltoxcast: 0.686859 val loss: 0.254872
[Epoch 59] ogbg-moltoxcast: 0.655724 test loss: 0.304923
[Epoch 44; Iter    23/  229] train: loss: 0.1172390
[Epoch 44; Iter    53/  229] train: loss: 0.1249169
[Epoch 44; Iter    83/  229] train: loss: 0.1368655
[Epoch 44; Iter   113/  229] train: loss: 0.1289664
[Epoch 44; Iter   143/  229] train: loss: 0.1443797
[Epoch 44; Iter   173/  229] train: loss: 0.1368084
[Epoch 44; Iter   203/  229] train: loss: 0.0897362
[Epoch 44] ogbg-moltoxcast: 0.695429 val loss: 0.342072
[Epoch 44] ogbg-moltoxcast: 0.664870 test loss: 0.309730
[Epoch 45; Iter     4/  229] train: loss: 0.1238546
[Epoch 45; Iter    34/  229] train: loss: 0.1602061
[Epoch 45; Iter    64/  229] train: loss: 0.1130783
[Epoch 45; Iter    94/  229] train: loss: 0.1715284
[Epoch 45; Iter   124/  229] train: loss: 0.2088538
[Epoch 45; Iter   154/  229] train: loss: 0.1444549
[Epoch 45; Iter   184/  229] train: loss: 0.1894329
[Epoch 45; Iter   214/  229] train: loss: 0.1442901
[Epoch 45] ogbg-moltoxcast: 0.692277 val loss: 0.254996
[Epoch 45] ogbg-moltoxcast: 0.655980 test loss: 0.308811
[Epoch 46; Iter    15/  229] train: loss: 0.1676051
[Epoch 46; Iter    45/  229] train: loss: 0.1738595
[Epoch 46; Iter    75/  229] train: loss: 0.2090591
[Epoch 46; Iter   105/  229] train: loss: 0.1243359
[Epoch 46; Iter   135/  229] train: loss: 0.1484008
[Epoch 46; Iter   165/  229] train: loss: 0.1161755
[Epoch 46; Iter   195/  229] train: loss: 0.1700980
[Epoch 46; Iter   225/  229] train: loss: 0.1177886
[Epoch 46] ogbg-moltoxcast: 0.686506 val loss: 0.454488
[Epoch 46] ogbg-moltoxcast: 0.659575 test loss: 0.306130
[Epoch 47; Iter    26/  229] train: loss: 0.1391372
[Epoch 47; Iter    56/  229] train: loss: 0.1543858
[Epoch 47; Iter    86/  229] train: loss: 0.1254813
[Epoch 47; Iter   116/  229] train: loss: 0.1549128
[Epoch 47; Iter   146/  229] train: loss: 0.1198560
[Epoch 47; Iter   176/  229] train: loss: 0.1436119
[Epoch 47; Iter   206/  229] train: loss: 0.1610626
[Epoch 47] ogbg-moltoxcast: 0.692915 val loss: 0.264290
[Epoch 47] ogbg-moltoxcast: 0.658782 test loss: 0.310696
[Epoch 48; Iter     7/  229] train: loss: 0.1789989
[Epoch 48; Iter    37/  229] train: loss: 0.1201017
[Epoch 48; Iter    67/  229] train: loss: 0.1843355
[Epoch 48; Iter    97/  229] train: loss: 0.1539391
[Epoch 48; Iter   127/  229] train: loss: 0.2083441
[Epoch 48; Iter   157/  229] train: loss: 0.1668931
[Epoch 48; Iter   187/  229] train: loss: 0.1573689
[Epoch 48; Iter   217/  229] train: loss: 0.1045992
[Epoch 48] ogbg-moltoxcast: 0.698117 val loss: 0.257069
[Epoch 48] ogbg-moltoxcast: 0.664854 test loss: 0.307197
[Epoch 49; Iter    18/  229] train: loss: 0.1436864
[Epoch 49; Iter    48/  229] train: loss: 0.1396096
[Epoch 49; Iter    78/  229] train: loss: 0.1075851
[Epoch 49; Iter   108/  229] train: loss: 0.2781485
[Epoch 49; Iter   138/  229] train: loss: 0.1440219
[Epoch 49; Iter   168/  229] train: loss: 0.1209903
[Epoch 49; Iter   198/  229] train: loss: 0.1692223
[Epoch 49; Iter   228/  229] train: loss: 0.1152378
[Epoch 49] ogbg-moltoxcast: 0.688466 val loss: 0.257908
[Epoch 49] ogbg-moltoxcast: 0.661031 test loss: 0.304687
[Epoch 50; Iter    29/  229] train: loss: 0.1325211
[Epoch 50; Iter    59/  229] train: loss: 0.1146823
[Epoch 50; Iter    89/  229] train: loss: 0.1063446
[Epoch 50; Iter   119/  229] train: loss: 0.1421195
[Epoch 50; Iter   149/  229] train: loss: 0.1089769
[Epoch 50; Iter   179/  229] train: loss: 0.1840346
[Epoch 50; Iter   209/  229] train: loss: 0.1307913
[Epoch 50] ogbg-moltoxcast: 0.693463 val loss: 0.289928
[Epoch 50] ogbg-moltoxcast: 0.656119 test loss: 0.309848
[Epoch 51; Iter    10/  229] train: loss: 0.1137224
[Epoch 51; Iter    40/  229] train: loss: 0.1386868
[Epoch 51; Iter    70/  229] train: loss: 0.1370265
[Epoch 51; Iter   100/  229] train: loss: 0.1360188
[Epoch 51; Iter   130/  229] train: loss: 0.1244949
[Epoch 51; Iter   160/  229] train: loss: 0.1352906
[Epoch 51; Iter   190/  229] train: loss: 0.1414012
[Epoch 51; Iter   220/  229] train: loss: 0.0846061
[Epoch 51] ogbg-moltoxcast: 0.697923 val loss: 0.266052
[Epoch 51] ogbg-moltoxcast: 0.663778 test loss: 0.313447
[Epoch 52; Iter    21/  229] train: loss: 0.1935452
[Epoch 52; Iter    51/  229] train: loss: 0.1562120
[Epoch 52; Iter    81/  229] train: loss: 0.1661614
[Epoch 52; Iter   111/  229] train: loss: 0.1306046
[Epoch 52; Iter   141/  229] train: loss: 0.1152466
[Epoch 52; Iter   171/  229] train: loss: 0.1673645
[Epoch 52; Iter   201/  229] train: loss: 0.1506793
[Epoch 52] ogbg-moltoxcast: 0.689289 val loss: 0.288155
[Epoch 52] ogbg-moltoxcast: 0.660807 test loss: 0.307696
[Epoch 53; Iter     2/  229] train: loss: 0.1279434
[Epoch 53; Iter    32/  229] train: loss: 0.1409747
[Epoch 53; Iter    62/  229] train: loss: 0.1524652
[Epoch 53; Iter    92/  229] train: loss: 0.1250079
[Epoch 53; Iter   122/  229] train: loss: 0.1628552
[Epoch 53; Iter   152/  229] train: loss: 0.1563886
[Epoch 53; Iter   182/  229] train: loss: 0.1496038
[Epoch 53; Iter   212/  229] train: loss: 0.1644041
[Epoch 53] ogbg-moltoxcast: 0.694525 val loss: 0.434415
[Epoch 53] ogbg-moltoxcast: 0.662637 test loss: 0.311826
[Epoch 54; Iter    13/  229] train: loss: 0.0852600
[Epoch 54; Iter    43/  229] train: loss: 0.1501544
[Epoch 54; Iter    73/  229] train: loss: 0.1084939
[Epoch 54; Iter   103/  229] train: loss: 0.1627064
[Epoch 54; Iter   133/  229] train: loss: 0.1851071
[Epoch 54; Iter   163/  229] train: loss: 0.1679776
[Epoch 54; Iter   193/  229] train: loss: 0.1994695
[Epoch 54; Iter   223/  229] train: loss: 0.1836877
[Epoch 54] ogbg-moltoxcast: 0.698068 val loss: 0.402663
[Epoch 54] ogbg-moltoxcast: 0.660303 test loss: 0.322528
[Epoch 55; Iter    24/  229] train: loss: 0.1241839
[Epoch 55; Iter    54/  229] train: loss: 0.1922415
[Epoch 55; Iter    84/  229] train: loss: 0.1377667
[Epoch 55; Iter   114/  229] train: loss: 0.1288301
[Epoch 55; Iter   144/  229] train: loss: 0.1216775
[Epoch 55; Iter   174/  229] train: loss: 0.1492995
[Epoch 55; Iter   204/  229] train: loss: 0.0913945
[Epoch 55] ogbg-moltoxcast: 0.690011 val loss: 0.285902
[Epoch 55] ogbg-moltoxcast: 0.661516 test loss: 0.321661
[Epoch 56; Iter     5/  229] train: loss: 0.1335356
[Epoch 56; Iter    35/  229] train: loss: 0.1314545
[Epoch 56; Iter    65/  229] train: loss: 0.1164966
[Epoch 56; Iter    95/  229] train: loss: 0.1152133
[Epoch 56; Iter   125/  229] train: loss: 0.1569395
[Epoch 56; Iter   155/  229] train: loss: 0.1393903
[Epoch 56; Iter   185/  229] train: loss: 0.1515275
[Epoch 56; Iter   215/  229] train: loss: 0.1458388
[Epoch 56] ogbg-moltoxcast: 0.679800 val loss: 0.389972
[Epoch 56] ogbg-moltoxcast: 0.651184 test loss: 0.320765
[Epoch 57; Iter    16/  229] train: loss: 0.1460956
[Epoch 57; Iter    46/  229] train: loss: 0.1300469
[Epoch 57; Iter    76/  229] train: loss: 0.1758826
[Epoch 57; Iter   106/  229] train: loss: 0.1061948
[Epoch 57; Iter   136/  229] train: loss: 0.1264298
[Epoch 57; Iter   166/  229] train: loss: 0.1313542
[Epoch 57; Iter   196/  229] train: loss: 0.1548224
[Epoch 57; Iter   226/  229] train: loss: 0.1554240
[Epoch 57] ogbg-moltoxcast: 0.698818 val loss: 0.327616
[Epoch 57] ogbg-moltoxcast: 0.656611 test loss: 0.315362
[Epoch 58; Iter    27/  229] train: loss: 0.1566981
[Epoch 58; Iter    57/  229] train: loss: 0.1521786
[Epoch 58; Iter    87/  229] train: loss: 0.1188799
[Epoch 58; Iter   117/  229] train: loss: 0.1081086
[Epoch 58; Iter   147/  229] train: loss: 0.1477635
[Epoch 58; Iter   177/  229] train: loss: 0.2050346
[Epoch 58; Iter   207/  229] train: loss: 0.1535331
[Epoch 58] ogbg-moltoxcast: 0.691600 val loss: 0.284354
[Epoch 58] ogbg-moltoxcast: 0.655306 test loss: 0.443723
[Epoch 59; Iter     8/  229] train: loss: 0.1140421
[Epoch 59; Iter    38/  229] train: loss: 0.1512967
[Epoch 59; Iter    68/  229] train: loss: 0.1013312
[Epoch 59; Iter    98/  229] train: loss: 0.1406204
[Epoch 59; Iter   128/  229] train: loss: 0.1631190
[Epoch 59; Iter   158/  229] train: loss: 0.1452794
[Epoch 59; Iter   188/  229] train: loss: 0.1141500
[Epoch 59; Iter   218/  229] train: loss: 0.1650154
[Epoch 59] ogbg-moltoxcast: 0.699854 val loss: 0.297188
[Epoch 59] ogbg-moltoxcast: 0.665285 test loss: 0.350583
[Epoch 60; Iter    19/  229] train: loss: 0.1070209
[Epoch 60; Iter    49/  229] train: loss: 0.1095749
[Epoch 60; Iter    79/  229] train: loss: 0.1975903
[Epoch 60; Iter   109/  229] train: loss: 0.2177756
[Epoch 60; Iter   139/  229] train: loss: 0.1596499
[Epoch 60; Iter   169/  229] train: loss: 0.1339059
[Epoch 60; Iter   199/  229] train: loss: 0.1666135
[Epoch 60; Iter   229/  229] train: loss: 0.1324287
[Epoch 60] ogbg-moltoxcast: 0.688989 val loss: 0.278190
[Epoch 60] ogbg-moltoxcast: 0.644341 test loss: 0.327067
[Epoch 61; Iter    30/  229] train: loss: 0.1301037
[Epoch 61; Iter    60/  229] train: loss: 0.1376152
[Epoch 61; Iter    90/  229] train: loss: 0.0820802
[Epoch 61; Iter   120/  229] train: loss: 0.0780470
[Epoch 61; Iter   150/  229] train: loss: 0.1516841
[Epoch 61; Iter   180/  229] train: loss: 0.0994348
[Epoch 61; Iter   210/  229] train: loss: 0.1025444
[Epoch 61] ogbg-moltoxcast: 0.696701 val loss: 0.280910
[Epoch 61] ogbg-moltoxcast: 0.649200 test loss: 0.327974
[Epoch 62; Iter    11/  229] train: loss: 0.1045852
[Epoch 62; Iter    41/  229] train: loss: 0.1260829
[Epoch 62; Iter    71/  229] train: loss: 0.0922560
[Epoch 62; Iter   101/  229] train: loss: 0.1091881
[Epoch 62; Iter   131/  229] train: loss: 0.0960107
[Epoch 62; Iter   161/  229] train: loss: 0.1126294
[Epoch 62; Iter   191/  229] train: loss: 0.1142393
[Epoch 62; Iter   221/  229] train: loss: 0.1203646
[Epoch 62] ogbg-moltoxcast: 0.696700 val loss: 0.281162
[Epoch 62] ogbg-moltoxcast: 0.650277 test loss: 0.327599
[Epoch 63; Iter    22/  229] train: loss: 0.1573912
[Epoch 63; Iter    52/  229] train: loss: 0.1501774
[Epoch 63; Iter    82/  229] train: loss: 0.1016053
[Epoch 63; Iter   112/  229] train: loss: 0.1243354
[Epoch 63; Iter   142/  229] train: loss: 0.1114669
[Epoch 63; Iter   172/  229] train: loss: 0.1499524
[Epoch 63; Iter   202/  229] train: loss: 0.0877361
[Epoch 63] ogbg-moltoxcast: 0.692498 val loss: 0.279080
[Epoch 63] ogbg-moltoxcast: 0.645799 test loss: 0.329321
[Epoch 64; Iter     3/  229] train: loss: 0.1983060
[Epoch 64; Iter    33/  229] train: loss: 0.1235597
[Epoch 64; Iter    63/  229] train: loss: 0.1684536
[Epoch 64; Iter    93/  229] train: loss: 0.1880049
[Epoch 64; Iter   123/  229] train: loss: 0.1434538
[Epoch 64; Iter   153/  229] train: loss: 0.1555029
[Epoch 64; Iter   183/  229] train: loss: 0.1530549
[Epoch 64; Iter   213/  229] train: loss: 0.0930715
[Epoch 64] ogbg-moltoxcast: 0.695098 val loss: 0.281114
[Epoch 64] ogbg-moltoxcast: 0.653015 test loss: 0.325441
[Epoch 65; Iter    14/  229] train: loss: 0.0959500
[Epoch 65; Iter    44/  229] train: loss: 0.1141870
[Epoch 65; Iter    74/  229] train: loss: 0.1181935
[Epoch 65; Iter   104/  229] train: loss: 0.1204429
[Epoch 65; Iter   134/  229] train: loss: 0.0975404
[Epoch 65; Iter   164/  229] train: loss: 0.1293799
[Epoch 65; Iter   194/  229] train: loss: 0.0959549
[Epoch 65; Iter   224/  229] train: loss: 0.1265353
[Epoch 65] ogbg-moltoxcast: 0.697456 val loss: 0.284690
[Epoch 65] ogbg-moltoxcast: 0.652010 test loss: 0.328945
[Epoch 66; Iter    25/  229] train: loss: 0.1122483
[Epoch 66; Iter    55/  229] train: loss: 0.1620988
[Epoch 66; Iter    85/  229] train: loss: 0.0961291
[Epoch 66; Iter   115/  229] train: loss: 0.1435204
[Epoch 66; Iter   145/  229] train: loss: 0.1065919
[Epoch 66; Iter   175/  229] train: loss: 0.0944330
[Epoch 66; Iter   205/  229] train: loss: 0.1535684
[Epoch 66] ogbg-moltoxcast: 0.690705 val loss: 0.289898
[Epoch 66] ogbg-moltoxcast: 0.651459 test loss: 0.331823
[Epoch 67; Iter     6/  229] train: loss: 0.0682280
[Epoch 67; Iter    36/  229] train: loss: 0.1068835
[Epoch 67; Iter    66/  229] train: loss: 0.1269687
[Epoch 67; Iter    96/  229] train: loss: 0.1061415
[Epoch 67; Iter   126/  229] train: loss: 0.1562746
[Epoch 67; Iter   156/  229] train: loss: 0.0960115
[Epoch 67; Iter   186/  229] train: loss: 0.1130323
[Epoch 67; Iter   216/  229] train: loss: 0.0911913
[Epoch 67] ogbg-moltoxcast: 0.692443 val loss: 0.287457
[Epoch 67] ogbg-moltoxcast: 0.650444 test loss: 0.331038
[Epoch 68; Iter    17/  229] train: loss: 0.1299189
[Epoch 68; Iter    47/  229] train: loss: 0.1271708
[Epoch 68; Iter    77/  229] train: loss: 0.1772722
[Epoch 68; Iter   107/  229] train: loss: 0.1160283
[Epoch 68; Iter   137/  229] train: loss: 0.1084900
[Epoch 68; Iter   167/  229] train: loss: 0.1312415
[Epoch 68; Iter   197/  229] train: loss: 0.1270315
[Epoch 68; Iter   227/  229] train: loss: 0.1313822
[Epoch 68] ogbg-moltoxcast: 0.689453 val loss: 0.293908
[Epoch 68] ogbg-moltoxcast: 0.644677 test loss: 0.334652
[Epoch 69; Iter    28/  229] train: loss: 0.1473753
[Epoch 69; Iter    58/  229] train: loss: 0.1406831
[Epoch 69; Iter    88/  229] train: loss: 0.1352493
[Epoch 69; Iter   118/  229] train: loss: 0.1690040
[Epoch 69; Iter   148/  229] train: loss: 0.1639533
[Epoch 69; Iter   178/  229] train: loss: 0.0923441
[Epoch 69; Iter   208/  229] train: loss: 0.1117137
[Epoch 69] ogbg-moltoxcast: 0.689307 val loss: 0.286910
[Epoch 69] ogbg-moltoxcast: 0.643551 test loss: 0.334622
[Epoch 70; Iter     9/  229] train: loss: 0.1434242
[Epoch 70; Iter    39/  229] train: loss: 0.1269635
[Epoch 70; Iter    69/  229] train: loss: 0.1269224
[Epoch 70; Iter    99/  229] train: loss: 0.1671469
[Epoch 70; Iter   129/  229] train: loss: 0.1424813
[Epoch 70; Iter   159/  229] train: loss: 0.1107448
[Epoch 70; Iter   189/  229] train: loss: 0.1085791
[Epoch 70; Iter   219/  229] train: loss: 0.1728806
[Epoch 70] ogbg-moltoxcast: 0.687704 val loss: 0.291943
[Epoch 70] ogbg-moltoxcast: 0.649543 test loss: 0.332593
[Epoch 71; Iter    20/  229] train: loss: 0.1295629
[Epoch 71; Iter    50/  229] train: loss: 0.0900864
[Epoch 71; Iter    80/  229] train: loss: 0.1489316
[Epoch 71; Iter   110/  229] train: loss: 0.1398052
[Epoch 71; Iter   140/  229] train: loss: 0.1245930
[Epoch 71; Iter   170/  229] train: loss: 0.1507787
[Epoch 71; Iter   200/  229] train: loss: 0.1136408
[Epoch 71] ogbg-moltoxcast: 0.694238 val loss: 0.287058
[Epoch 71] ogbg-moltoxcast: 0.644333 test loss: 0.335180
[Epoch 72; Iter     1/  229] train: loss: 0.1339111
[Epoch 72; Iter    31/  229] train: loss: 0.1343244
[Epoch 72; Iter    61/  229] train: loss: 0.1599859
[Epoch 72; Iter    91/  229] train: loss: 0.0985300
[Epoch 72; Iter   121/  229] train: loss: 0.0850075
[Epoch 72; Iter   151/  229] train: loss: 0.1454223
[Epoch 72; Iter   181/  229] train: loss: 0.1707560
[Epoch 72; Iter   211/  229] train: loss: 0.0922286
[Epoch 72] ogbg-moltoxcast: 0.688461 val loss: 0.288319
[Epoch 72] ogbg-moltoxcast: 0.642864 test loss: 0.331384
[Epoch 73; Iter    12/  229] train: loss: 0.0994959
[Epoch 73; Iter    42/  229] train: loss: 0.1291799
[Epoch 73; Iter    72/  229] train: loss: 0.1577560
[Epoch 73; Iter   102/  229] train: loss: 0.1404523
[Epoch 73; Iter   132/  229] train: loss: 0.1128520
[Epoch 73; Iter   162/  229] train: loss: 0.1336862
[Epoch 73; Iter   192/  229] train: loss: 0.0977178
[Epoch 73; Iter   222/  229] train: loss: 0.1091531
[Epoch 73] ogbg-moltoxcast: 0.686080 val loss: 0.287614
[Epoch 73] ogbg-moltoxcast: 0.643662 test loss: 0.333544
[Epoch 74; Iter    23/  229] train: loss: 0.0835764
[Epoch 74; Iter    53/  229] train: loss: 0.1292565
[Epoch 74; Iter    83/  229] train: loss: 0.1179547
[Epoch 74; Iter   113/  229] train: loss: 0.0863963
[Epoch 74; Iter   143/  229] train: loss: 0.1166491
[Epoch 74; Iter   173/  229] train: loss: 0.1258813
[Epoch 74; Iter   203/  229] train: loss: 0.1256762
[Epoch 74] ogbg-moltoxcast: 0.681807 val loss: 0.289177
[Epoch 74] ogbg-moltoxcast: 0.648123 test loss: 0.331759
[Epoch 75; Iter     4/  229] train: loss: 0.0843862
[Epoch 75; Iter    34/  229] train: loss: 0.1338568
[Epoch 75; Iter    64/  229] train: loss: 0.1714215
[Epoch 75; Iter    94/  229] train: loss: 0.1243510
[Epoch 75; Iter   124/  229] train: loss: 0.1271825
[Epoch 75; Iter   154/  229] train: loss: 0.1177936
[Epoch 75; Iter   184/  229] train: loss: 0.1722055
[Epoch 75; Iter   214/  229] train: loss: 0.1227558
[Epoch 75] ogbg-moltoxcast: 0.687080 val loss: 0.289071
[Epoch 75] ogbg-moltoxcast: 0.645482 test loss: 0.335714
[Epoch 60; Iter    19/  229] train: loss: 0.1540103
[Epoch 60; Iter    49/  229] train: loss: 0.1282472
[Epoch 60; Iter    79/  229] train: loss: 0.1096618
[Epoch 60; Iter   109/  229] train: loss: 0.1364464
[Epoch 60; Iter   139/  229] train: loss: 0.1257370
[Epoch 60; Iter   169/  229] train: loss: 0.1746734
[Epoch 60; Iter   199/  229] train: loss: 0.1028090
[Epoch 60; Iter   229/  229] train: loss: 0.1246108
[Epoch 60] ogbg-moltoxcast: 0.657806 val loss: 0.297909
[Epoch 60] ogbg-moltoxcast: 0.653488 test loss: 0.341636
[Epoch 61; Iter    30/  229] train: loss: 0.1196046
[Epoch 61; Iter    60/  229] train: loss: 0.1412901
[Epoch 61; Iter    90/  229] train: loss: 0.0874695
[Epoch 61; Iter   120/  229] train: loss: 0.1396755
[Epoch 61; Iter   150/  229] train: loss: 0.1000319
[Epoch 61; Iter   180/  229] train: loss: 0.1806428
[Epoch 61; Iter   210/  229] train: loss: 0.1144042
[Epoch 61] ogbg-moltoxcast: 0.672230 val loss: 0.284628
[Epoch 61] ogbg-moltoxcast: 0.660304 test loss: 0.332877
[Epoch 62; Iter    11/  229] train: loss: 0.1157383
[Epoch 62; Iter    41/  229] train: loss: 0.1788479
[Epoch 62; Iter    71/  229] train: loss: 0.1544828
[Epoch 62; Iter   101/  229] train: loss: 0.1790228
[Epoch 62; Iter   131/  229] train: loss: 0.1169512
[Epoch 62; Iter   161/  229] train: loss: 0.1260939
[Epoch 62; Iter   191/  229] train: loss: 0.0862188
[Epoch 62; Iter   221/  229] train: loss: 0.1880511
[Epoch 62] ogbg-moltoxcast: 0.670178 val loss: 0.291841
[Epoch 62] ogbg-moltoxcast: 0.658513 test loss: 0.339806
[Epoch 63; Iter    22/  229] train: loss: 0.0997014
[Epoch 63; Iter    52/  229] train: loss: 0.1210860
[Epoch 63; Iter    82/  229] train: loss: 0.0706283
[Epoch 63; Iter   112/  229] train: loss: 0.1174468
[Epoch 63; Iter   142/  229] train: loss: 0.1457135
[Epoch 63; Iter   172/  229] train: loss: 0.1694023
[Epoch 63; Iter   202/  229] train: loss: 0.1059854
[Epoch 63] ogbg-moltoxcast: 0.664775 val loss: 0.384493
[Epoch 63] ogbg-moltoxcast: 0.654060 test loss: 0.442736
[Epoch 64; Iter     3/  229] train: loss: 0.1364174
[Epoch 64; Iter    33/  229] train: loss: 0.1525698
[Epoch 64; Iter    63/  229] train: loss: 0.1202443
[Epoch 64; Iter    93/  229] train: loss: 0.1022444
[Epoch 64; Iter   123/  229] train: loss: 0.1360534
[Epoch 64; Iter   153/  229] train: loss: 0.1205016
[Epoch 64; Iter   183/  229] train: loss: 0.1680054
[Epoch 64; Iter   213/  229] train: loss: 0.1124415
[Epoch 64] ogbg-moltoxcast: 0.665375 val loss: 0.301645
[Epoch 64] ogbg-moltoxcast: 0.655731 test loss: 0.350151
[Epoch 65; Iter    14/  229] train: loss: 0.0919023
[Epoch 65; Iter    44/  229] train: loss: 0.1013143
[Epoch 65; Iter    74/  229] train: loss: 0.1010291
[Epoch 65; Iter   104/  229] train: loss: 0.1084525
[Epoch 65; Iter   134/  229] train: loss: 0.1753040
[Epoch 65; Iter   164/  229] train: loss: 0.1520769
[Epoch 65; Iter   194/  229] train: loss: 0.1237829
[Epoch 65; Iter   224/  229] train: loss: 0.1890485
[Epoch 65] ogbg-moltoxcast: 0.660772 val loss: 0.326686
[Epoch 65] ogbg-moltoxcast: 0.654990 test loss: 0.369976
[Epoch 66; Iter    25/  229] train: loss: 0.1043672
[Epoch 66; Iter    55/  229] train: loss: 0.0982501
[Epoch 66; Iter    85/  229] train: loss: 0.1417795
[Epoch 66; Iter   115/  229] train: loss: 0.1772900
[Epoch 66; Iter   145/  229] train: loss: 0.1075287
[Epoch 66; Iter   175/  229] train: loss: 0.1521445
[Epoch 66; Iter   205/  229] train: loss: 0.1498735
[Epoch 66] ogbg-moltoxcast: 0.663905 val loss: 0.294786
[Epoch 66] ogbg-moltoxcast: 0.656321 test loss: 0.340109
[Epoch 67; Iter     6/  229] train: loss: 0.1358153
[Epoch 67; Iter    36/  229] train: loss: 0.1502942
[Epoch 67; Iter    66/  229] train: loss: 0.1157104
[Epoch 67; Iter    96/  229] train: loss: 0.1191995
[Epoch 67; Iter   126/  229] train: loss: 0.1526444
[Epoch 67; Iter   156/  229] train: loss: 0.1511574
[Epoch 67; Iter   186/  229] train: loss: 0.1576812
[Epoch 67; Iter   216/  229] train: loss: 0.1240827
[Epoch 67] ogbg-moltoxcast: 0.662908 val loss: 0.295266
[Epoch 67] ogbg-moltoxcast: 0.656615 test loss: 0.342857
[Epoch 68; Iter    17/  229] train: loss: 0.1863795
[Epoch 68; Iter    47/  229] train: loss: 0.1044220
[Epoch 68; Iter    77/  229] train: loss: 0.1143790
[Epoch 68; Iter   107/  229] train: loss: 0.1252345
[Epoch 68; Iter   137/  229] train: loss: 0.1011745
[Epoch 68; Iter   167/  229] train: loss: 0.1105962
[Epoch 68; Iter   197/  229] train: loss: 0.1345439
[Epoch 68; Iter   227/  229] train: loss: 0.1187161
[Epoch 68] ogbg-moltoxcast: 0.665691 val loss: 0.289631
[Epoch 68] ogbg-moltoxcast: 0.653562 test loss: 0.338335
[Epoch 69; Iter    28/  229] train: loss: 0.1329679
[Epoch 69; Iter    58/  229] train: loss: 0.1735703
[Epoch 69; Iter    88/  229] train: loss: 0.1013250
[Epoch 69; Iter   118/  229] train: loss: 0.0910973
[Epoch 69; Iter   148/  229] train: loss: 0.1360698
[Epoch 69; Iter   178/  229] train: loss: 0.1517240
[Epoch 69; Iter   208/  229] train: loss: 0.0905518
[Epoch 69] ogbg-moltoxcast: 0.664011 val loss: 0.302541
[Epoch 69] ogbg-moltoxcast: 0.651379 test loss: 0.351094
[Epoch 70; Iter     9/  229] train: loss: 0.0900009
[Epoch 70; Iter    39/  229] train: loss: 0.1023376
[Epoch 70; Iter    69/  229] train: loss: 0.1117468
[Epoch 70; Iter    99/  229] train: loss: 0.1506408
[Epoch 70; Iter   129/  229] train: loss: 0.1286992
[Epoch 70; Iter   159/  229] train: loss: 0.1316586
[Epoch 70; Iter   189/  229] train: loss: 0.1445340
[Epoch 70; Iter   219/  229] train: loss: 0.1271002
[Epoch 70] ogbg-moltoxcast: 0.659716 val loss: 0.307558
[Epoch 70] ogbg-moltoxcast: 0.652088 test loss: 0.354802
[Epoch 71; Iter    20/  229] train: loss: 0.1404786
[Epoch 71; Iter    50/  229] train: loss: 0.1365423
[Epoch 71; Iter    80/  229] train: loss: 0.1035128
[Epoch 71; Iter   110/  229] train: loss: 0.1523917
[Epoch 71; Iter   140/  229] train: loss: 0.1185802
[Epoch 71; Iter   170/  229] train: loss: 0.0818135
[Epoch 71; Iter   200/  229] train: loss: 0.1195847
[Epoch 71] ogbg-moltoxcast: 0.657245 val loss: 0.297306
[Epoch 71] ogbg-moltoxcast: 0.650908 test loss: 0.344495
[Epoch 72; Iter     1/  229] train: loss: 0.1032154
[Epoch 72; Iter    31/  229] train: loss: 0.1652362
[Epoch 72; Iter    61/  229] train: loss: 0.1252578
[Epoch 72; Iter    91/  229] train: loss: 0.1435943
[Epoch 72; Iter   121/  229] train: loss: 0.1554625
[Epoch 72; Iter   151/  229] train: loss: 0.1647194
[Epoch 72; Iter   181/  229] train: loss: 0.1098712
[Epoch 72; Iter   211/  229] train: loss: 0.1263876
[Epoch 72] ogbg-moltoxcast: 0.661039 val loss: 0.298392
[Epoch 72] ogbg-moltoxcast: 0.652443 test loss: 0.345366
[Epoch 73; Iter    12/  229] train: loss: 0.1172946
[Epoch 73; Iter    42/  229] train: loss: 0.1709797
[Epoch 73; Iter    72/  229] train: loss: 0.1801873
[Epoch 73; Iter   102/  229] train: loss: 0.1142655
[Epoch 73; Iter   132/  229] train: loss: 0.1436993
[Epoch 73; Iter   162/  229] train: loss: 0.1349678
[Epoch 73; Iter   192/  229] train: loss: 0.1046387
[Epoch 73; Iter   222/  229] train: loss: 0.1240229
[Epoch 73] ogbg-moltoxcast: 0.655693 val loss: 0.298141
[Epoch 73] ogbg-moltoxcast: 0.649833 test loss: 0.343073
[Epoch 74; Iter    23/  229] train: loss: 0.1226035
[Epoch 74; Iter    53/  229] train: loss: 0.1062982
[Epoch 74; Iter    83/  229] train: loss: 0.0941339
[Epoch 74; Iter   113/  229] train: loss: 0.1192940
[Epoch 74; Iter   143/  229] train: loss: 0.1417124
[Epoch 74; Iter   173/  229] train: loss: 0.1069836
[Epoch 74; Iter   203/  229] train: loss: 0.0911341
[Epoch 74] ogbg-moltoxcast: 0.660883 val loss: 0.300323
[Epoch 74] ogbg-moltoxcast: 0.652583 test loss: 0.349447
[Epoch 75; Iter     4/  229] train: loss: 0.0912386
[Epoch 75; Iter    34/  229] train: loss: 0.1432365
[Epoch 75; Iter    64/  229] train: loss: 0.1399690
[Epoch 75; Iter    94/  229] train: loss: 0.1152508
[Epoch 75; Iter   124/  229] train: loss: 0.1283768
[Epoch 75; Iter   154/  229] train: loss: 0.1383403
[Epoch 75; Iter   184/  229] train: loss: 0.1283312
[Epoch 75; Iter   214/  229] train: loss: 0.1287892
[Epoch 75] ogbg-moltoxcast: 0.653478 val loss: 0.384547
[Epoch 75] ogbg-moltoxcast: 0.647584 test loss: 0.454094
[Epoch 60; Iter    19/  229] train: loss: 0.0963553
[Epoch 60; Iter    49/  229] train: loss: 0.1277052
[Epoch 60; Iter    79/  229] train: loss: 0.1597075
[Epoch 60; Iter   109/  229] train: loss: 0.1197876
[Epoch 60; Iter   139/  229] train: loss: 0.1339811
[Epoch 60; Iter   169/  229] train: loss: 0.1015359
[Epoch 60; Iter   199/  229] train: loss: 0.1654798
[Epoch 60; Iter   229/  229] train: loss: 0.1350412
[Epoch 60] ogbg-moltoxcast: 0.688711 val loss: 0.273238
[Epoch 60] ogbg-moltoxcast: 0.651177 test loss: 0.329376
[Epoch 61; Iter    30/  229] train: loss: 0.1472771
[Epoch 61; Iter    60/  229] train: loss: 0.1472052
[Epoch 61; Iter    90/  229] train: loss: 0.1724848
[Epoch 61; Iter   120/  229] train: loss: 0.1354484
[Epoch 61; Iter   150/  229] train: loss: 0.1437506
[Epoch 61; Iter   180/  229] train: loss: 0.1659382
[Epoch 61; Iter   210/  229] train: loss: 0.0859056
[Epoch 61] ogbg-moltoxcast: 0.692833 val loss: 0.273518
[Epoch 61] ogbg-moltoxcast: 0.655341 test loss: 0.329644
[Epoch 62; Iter    11/  229] train: loss: 0.0885769
[Epoch 62; Iter    41/  229] train: loss: 0.1692682
[Epoch 62; Iter    71/  229] train: loss: 0.1401823
[Epoch 62; Iter   101/  229] train: loss: 0.1260704
[Epoch 62; Iter   131/  229] train: loss: 0.1595198
[Epoch 62; Iter   161/  229] train: loss: 0.1247399
[Epoch 62; Iter   191/  229] train: loss: 0.1387478
[Epoch 62; Iter   221/  229] train: loss: 0.1419534
[Epoch 62] ogbg-moltoxcast: 0.685524 val loss: 0.276953
[Epoch 62] ogbg-moltoxcast: 0.649006 test loss: 0.331493
[Epoch 63; Iter    22/  229] train: loss: 0.1319168
[Epoch 63; Iter    52/  229] train: loss: 0.0843911
[Epoch 63; Iter    82/  229] train: loss: 0.0913347
[Epoch 63; Iter   112/  229] train: loss: 0.0939429
[Epoch 63; Iter   142/  229] train: loss: 0.1575392
[Epoch 63; Iter   172/  229] train: loss: 0.1702965
[Epoch 63; Iter   202/  229] train: loss: 0.1170895
[Epoch 63] ogbg-moltoxcast: 0.687309 val loss: 0.282441
[Epoch 63] ogbg-moltoxcast: 0.651847 test loss: 0.338484
[Epoch 64; Iter     3/  229] train: loss: 0.0786954
[Epoch 64; Iter    33/  229] train: loss: 0.1325365
[Epoch 64; Iter    63/  229] train: loss: 0.1402247
[Epoch 64; Iter    93/  229] train: loss: 0.1122371
[Epoch 64; Iter   123/  229] train: loss: 0.1104215
[Epoch 64; Iter   153/  229] train: loss: 0.1065775
[Epoch 64; Iter   183/  229] train: loss: 0.0990458
[Epoch 64; Iter   213/  229] train: loss: 0.1375181
[Epoch 64] ogbg-moltoxcast: 0.686896 val loss: 0.280391
[Epoch 64] ogbg-moltoxcast: 0.648812 test loss: 0.338222
[Epoch 65; Iter    14/  229] train: loss: 0.1403504
[Epoch 65; Iter    44/  229] train: loss: 0.1385808
[Epoch 65; Iter    74/  229] train: loss: 0.1248921
[Epoch 65; Iter   104/  229] train: loss: 0.1441482
[Epoch 65; Iter   134/  229] train: loss: 0.1230443
[Epoch 65; Iter   164/  229] train: loss: 0.1508915
[Epoch 65; Iter   194/  229] train: loss: 0.0992407
[Epoch 65; Iter   224/  229] train: loss: 0.1322492
[Epoch 65] ogbg-moltoxcast: 0.687834 val loss: 0.283105
[Epoch 65] ogbg-moltoxcast: 0.649021 test loss: 0.338472
[Epoch 66; Iter    25/  229] train: loss: 0.1170002
[Epoch 66; Iter    55/  229] train: loss: 0.1511234
[Epoch 66; Iter    85/  229] train: loss: 0.1350758
[Epoch 66; Iter   115/  229] train: loss: 0.1018085
[Epoch 66; Iter   145/  229] train: loss: 0.0988100
[Epoch 66; Iter   175/  229] train: loss: 0.1383088
[Epoch 66; Iter   205/  229] train: loss: 0.1081588
[Epoch 66] ogbg-moltoxcast: 0.687168 val loss: 0.316870
[Epoch 66] ogbg-moltoxcast: 0.647715 test loss: 0.347570
[Epoch 67; Iter     6/  229] train: loss: 0.1293124
[Epoch 67; Iter    36/  229] train: loss: 0.1554818
[Epoch 67; Iter    66/  229] train: loss: 0.1025480
[Epoch 67; Iter    96/  229] train: loss: 0.1603349
[Epoch 67; Iter   126/  229] train: loss: 0.0989183
[Epoch 67; Iter   156/  229] train: loss: 0.0976619
[Epoch 67; Iter   186/  229] train: loss: 0.1038827
[Epoch 67; Iter   216/  229] train: loss: 0.1011349
[Epoch 67] ogbg-moltoxcast: 0.687056 val loss: 0.287366
[Epoch 67] ogbg-moltoxcast: 0.651291 test loss: 0.341203
[Epoch 68; Iter    17/  229] train: loss: 0.1568469
[Epoch 68; Iter    47/  229] train: loss: 0.1116186
[Epoch 68; Iter    77/  229] train: loss: 0.1088031
[Epoch 68; Iter   107/  229] train: loss: 0.1462987
[Epoch 68; Iter   137/  229] train: loss: 0.1028352
[Epoch 68; Iter   167/  229] train: loss: 0.0988656
[Epoch 68; Iter   197/  229] train: loss: 0.1477808
[Epoch 68; Iter   227/  229] train: loss: 0.1361971
[Epoch 68] ogbg-moltoxcast: 0.682576 val loss: 0.286508
[Epoch 68] ogbg-moltoxcast: 0.645572 test loss: 0.341865
[Epoch 69; Iter    28/  229] train: loss: 0.1258056
[Epoch 69; Iter    58/  229] train: loss: 0.0843790
[Epoch 69; Iter    88/  229] train: loss: 0.1092217
[Epoch 69; Iter   118/  229] train: loss: 0.1112216
[Epoch 69; Iter   148/  229] train: loss: 0.0879438
[Epoch 69; Iter   178/  229] train: loss: 0.1790949
[Epoch 69; Iter   208/  229] train: loss: 0.1141020
[Epoch 69] ogbg-moltoxcast: 0.687454 val loss: 0.289020
[Epoch 69] ogbg-moltoxcast: 0.647328 test loss: 0.343432
[Epoch 70; Iter     9/  229] train: loss: 0.1052891
[Epoch 70; Iter    39/  229] train: loss: 0.1311701
[Epoch 70; Iter    69/  229] train: loss: 0.1230410
[Epoch 70; Iter    99/  229] train: loss: 0.1595872
[Epoch 70; Iter   129/  229] train: loss: 0.1048274
[Epoch 70; Iter   159/  229] train: loss: 0.1425687
[Epoch 70; Iter   189/  229] train: loss: 0.1700389
[Epoch 70; Iter   219/  229] train: loss: 0.1387566
[Epoch 70] ogbg-moltoxcast: 0.687146 val loss: 0.281625
[Epoch 70] ogbg-moltoxcast: 0.650622 test loss: 0.338002
[Epoch 71; Iter    20/  229] train: loss: 0.0967529
[Epoch 71; Iter    50/  229] train: loss: 0.0912553
[Epoch 71; Iter    80/  229] train: loss: 0.1234475
[Epoch 71; Iter   110/  229] train: loss: 0.1167355
[Epoch 71; Iter   140/  229] train: loss: 0.0984339
[Epoch 71; Iter   170/  229] train: loss: 0.1314972
[Epoch 71; Iter   200/  229] train: loss: 0.1063091
[Epoch 71] ogbg-moltoxcast: 0.682496 val loss: 0.297134
[Epoch 71] ogbg-moltoxcast: 0.645046 test loss: 0.349051
[Epoch 72; Iter     1/  229] train: loss: 0.0823500
[Epoch 72; Iter    31/  229] train: loss: 0.0992575
[Epoch 72; Iter    61/  229] train: loss: 0.1160773
[Epoch 72; Iter    91/  229] train: loss: 0.1227546
[Epoch 72; Iter   121/  229] train: loss: 0.1066602
[Epoch 72; Iter   151/  229] train: loss: 0.1289435
[Epoch 72; Iter   181/  229] train: loss: 0.0943566
[Epoch 72; Iter   211/  229] train: loss: 0.1284182
[Epoch 72] ogbg-moltoxcast: 0.687568 val loss: 0.291360
[Epoch 72] ogbg-moltoxcast: 0.653572 test loss: 0.347620
[Epoch 73; Iter    12/  229] train: loss: 0.1558593
[Epoch 73; Iter    42/  229] train: loss: 0.1035072
[Epoch 73; Iter    72/  229] train: loss: 0.0911671
[Epoch 73; Iter   102/  229] train: loss: 0.1238795
[Epoch 73; Iter   132/  229] train: loss: 0.1648141
[Epoch 73; Iter   162/  229] train: loss: 0.1260929
[Epoch 73; Iter   192/  229] train: loss: 0.1214704
[Epoch 73; Iter   222/  229] train: loss: 0.1265051
[Epoch 73] ogbg-moltoxcast: 0.685677 val loss: 0.286386
[Epoch 73] ogbg-moltoxcast: 0.654126 test loss: 0.339298
[Epoch 74; Iter    23/  229] train: loss: 0.0880880
[Epoch 74; Iter    53/  229] train: loss: 0.1697013
[Epoch 74; Iter    83/  229] train: loss: 0.0871042
[Epoch 74; Iter   113/  229] train: loss: 0.1251037
[Epoch 74; Iter   143/  229] train: loss: 0.1660260
[Epoch 74; Iter   173/  229] train: loss: 0.0878853
[Epoch 74; Iter   203/  229] train: loss: 0.1007853
[Epoch 74] ogbg-moltoxcast: 0.683773 val loss: 0.291146
[Epoch 74] ogbg-moltoxcast: 0.646737 test loss: 0.346380
[Epoch 75; Iter     4/  229] train: loss: 0.0869086
[Epoch 75; Iter    34/  229] train: loss: 0.1478621
[Epoch 75; Iter    64/  229] train: loss: 0.0958930
[Epoch 75; Iter    94/  229] train: loss: 0.1486722
[Epoch 75; Iter   124/  229] train: loss: 0.1394567
[Epoch 75; Iter   154/  229] train: loss: 0.1004295
[Epoch 75; Iter   184/  229] train: loss: 0.1306847
[Epoch 75; Iter   214/  229] train: loss: 0.1061435
[Epoch 75] ogbg-moltoxcast: 0.689539 val loss: 0.286013
[Epoch 75] ogbg-moltoxcast: 0.647877 test loss: 0.346666
[Epoch 60; Iter    19/  229] train: loss: 0.1012881
[Epoch 60; Iter    49/  229] train: loss: 0.1195942
[Epoch 60; Iter    79/  229] train: loss: 0.1520267
[Epoch 60; Iter   109/  229] train: loss: 0.1125468
[Epoch 60; Iter   139/  229] train: loss: 0.1290081
[Epoch 60; Iter   169/  229] train: loss: 0.0926957
[Epoch 60; Iter   199/  229] train: loss: 0.1530041
[Epoch 60; Iter   229/  229] train: loss: 0.1340465
[Epoch 60] ogbg-moltoxcast: 0.670560 val loss: 0.304670
[Epoch 60] ogbg-moltoxcast: 0.650426 test loss: 0.345337
[Epoch 61; Iter    30/  229] train: loss: 0.1490303
[Epoch 61; Iter    60/  229] train: loss: 0.1491472
[Epoch 61; Iter    90/  229] train: loss: 0.1611038
[Epoch 61; Iter   120/  229] train: loss: 0.1370250
[Epoch 61; Iter   150/  229] train: loss: 0.1411592
[Epoch 61; Iter   180/  229] train: loss: 0.1554683
[Epoch 61; Iter   210/  229] train: loss: 0.0855592
[Epoch 61] ogbg-moltoxcast: 0.670560 val loss: 0.303326
[Epoch 61] ogbg-moltoxcast: 0.657938 test loss: 0.342122
[Epoch 62; Iter    11/  229] train: loss: 0.0850042
[Epoch 62; Iter    41/  229] train: loss: 0.1753819
[Epoch 62; Iter    71/  229] train: loss: 0.1447945
[Epoch 62; Iter   101/  229] train: loss: 0.1286272
[Epoch 62; Iter   131/  229] train: loss: 0.1565531
[Epoch 62; Iter   161/  229] train: loss: 0.1176959
[Epoch 62; Iter   191/  229] train: loss: 0.1382967
[Epoch 62; Iter   221/  229] train: loss: 0.1457195
[Epoch 62] ogbg-moltoxcast: 0.666808 val loss: 0.312273
[Epoch 62] ogbg-moltoxcast: 0.650396 test loss: 0.349737
[Epoch 63; Iter    22/  229] train: loss: 0.1345374
[Epoch 63; Iter    52/  229] train: loss: 0.0806169
[Epoch 63; Iter    82/  229] train: loss: 0.0861278
[Epoch 63; Iter   112/  229] train: loss: 0.0902476
[Epoch 63; Iter   142/  229] train: loss: 0.1518485
[Epoch 63; Iter   172/  229] train: loss: 0.1794659
[Epoch 63; Iter   202/  229] train: loss: 0.1110142
[Epoch 63] ogbg-moltoxcast: 0.673368 val loss: 0.300804
[Epoch 63] ogbg-moltoxcast: 0.653722 test loss: 0.340941
[Epoch 64; Iter     3/  229] train: loss: 0.0758774
[Epoch 64; Iter    33/  229] train: loss: 0.1343317
[Epoch 64; Iter    63/  229] train: loss: 0.1291115
[Epoch 64; Iter    93/  229] train: loss: 0.1078803
[Epoch 64; Iter   123/  229] train: loss: 0.1173261
[Epoch 64; Iter   153/  229] train: loss: 0.1018982
[Epoch 64; Iter   183/  229] train: loss: 0.1025218
[Epoch 64; Iter   213/  229] train: loss: 0.1428261
[Epoch 64] ogbg-moltoxcast: 0.665919 val loss: 0.302605
[Epoch 64] ogbg-moltoxcast: 0.652850 test loss: 0.340036
[Epoch 65; Iter    14/  229] train: loss: 0.1439338
[Epoch 65; Iter    44/  229] train: loss: 0.1358847
[Epoch 65; Iter    74/  229] train: loss: 0.1274271
[Epoch 65; Iter   104/  229] train: loss: 0.1475550
[Epoch 65; Iter   134/  229] train: loss: 0.1187206
[Epoch 65; Iter   164/  229] train: loss: 0.1476946
[Epoch 65; Iter   194/  229] train: loss: 0.0969409
[Epoch 65; Iter   224/  229] train: loss: 0.1313551
[Epoch 65] ogbg-moltoxcast: 0.668225 val loss: 0.303414
[Epoch 65] ogbg-moltoxcast: 0.650548 test loss: 0.340397
[Epoch 66; Iter    25/  229] train: loss: 0.1146562
[Epoch 66; Iter    55/  229] train: loss: 0.1483316
[Epoch 66; Iter    85/  229] train: loss: 0.1318588
[Epoch 66; Iter   115/  229] train: loss: 0.1020380
[Epoch 66; Iter   145/  229] train: loss: 0.0948638
[Epoch 66; Iter   175/  229] train: loss: 0.1290102
[Epoch 66; Iter   205/  229] train: loss: 0.1030552
[Epoch 66] ogbg-moltoxcast: 0.663049 val loss: 0.308782
[Epoch 66] ogbg-moltoxcast: 0.648237 test loss: 0.343753
[Epoch 67; Iter     6/  229] train: loss: 0.1266229
[Epoch 67; Iter    36/  229] train: loss: 0.1596861
[Epoch 67; Iter    66/  229] train: loss: 0.1019379
[Epoch 67; Iter    96/  229] train: loss: 0.1568069
[Epoch 67; Iter   126/  229] train: loss: 0.1019301
[Epoch 67; Iter   156/  229] train: loss: 0.0997905
[Epoch 67; Iter   186/  229] train: loss: 0.1015867
[Epoch 67; Iter   216/  229] train: loss: 0.0970771
[Epoch 67] ogbg-moltoxcast: 0.673375 val loss: 0.300322
[Epoch 67] ogbg-moltoxcast: 0.650870 test loss: 0.342266
[Epoch 68; Iter    17/  229] train: loss: 0.1512719
[Epoch 68; Iter    47/  229] train: loss: 0.1098447
[Epoch 68; Iter    77/  229] train: loss: 0.1122895
[Epoch 68; Iter   107/  229] train: loss: 0.1412269
[Epoch 68; Iter   137/  229] train: loss: 0.1034083
[Epoch 68; Iter   167/  229] train: loss: 0.0953642
[Epoch 68; Iter   197/  229] train: loss: 0.1403367
[Epoch 68; Iter   227/  229] train: loss: 0.1364565
[Epoch 68] ogbg-moltoxcast: 0.667912 val loss: 0.315946
[Epoch 68] ogbg-moltoxcast: 0.649605 test loss: 0.349531
[Epoch 69; Iter    28/  229] train: loss: 0.1294496
[Epoch 69; Iter    58/  229] train: loss: 0.0802683
[Epoch 69; Iter    88/  229] train: loss: 0.1098327
[Epoch 69; Iter   118/  229] train: loss: 0.1102606
[Epoch 69; Iter   148/  229] train: loss: 0.0905527
[Epoch 69; Iter   178/  229] train: loss: 0.1743039
[Epoch 69; Iter   208/  229] train: loss: 0.1204628
[Epoch 69] ogbg-moltoxcast: 0.665223 val loss: 0.312702
[Epoch 69] ogbg-moltoxcast: 0.646966 test loss: 0.350560
[Epoch 70; Iter     9/  229] train: loss: 0.1005970
[Epoch 70; Iter    39/  229] train: loss: 0.1376639
[Epoch 70; Iter    69/  229] train: loss: 0.1209941
[Epoch 70; Iter    99/  229] train: loss: 0.1600345
[Epoch 70; Iter   129/  229] train: loss: 0.1057110
[Epoch 70; Iter   159/  229] train: loss: 0.1405402
[Epoch 70; Iter   189/  229] train: loss: 0.1545213
[Epoch 70; Iter   219/  229] train: loss: 0.1339298
[Epoch 70] ogbg-moltoxcast: 0.666382 val loss: 0.312501
[Epoch 70] ogbg-moltoxcast: 0.650643 test loss: 0.348851
[Epoch 71; Iter    20/  229] train: loss: 0.1045854
[Epoch 71; Iter    50/  229] train: loss: 0.0915343
[Epoch 71; Iter    80/  229] train: loss: 0.1229802
[Epoch 71; Iter   110/  229] train: loss: 0.1163108
[Epoch 71; Iter   140/  229] train: loss: 0.0935148
[Epoch 71; Iter   170/  229] train: loss: 0.1292436
[Epoch 71; Iter   200/  229] train: loss: 0.1044056
[Epoch 71] ogbg-moltoxcast: 0.667613 val loss: 0.312350
[Epoch 71] ogbg-moltoxcast: 0.651438 test loss: 0.348565
[Epoch 72; Iter     1/  229] train: loss: 0.0907589
[Epoch 72; Iter    31/  229] train: loss: 0.0935361
[Epoch 72; Iter    61/  229] train: loss: 0.1165449
[Epoch 72; Iter    91/  229] train: loss: 0.1198017
[Epoch 72; Iter   121/  229] train: loss: 0.1087129
[Epoch 72; Iter   151/  229] train: loss: 0.1329966
[Epoch 72; Iter   181/  229] train: loss: 0.1000665
[Epoch 72; Iter   211/  229] train: loss: 0.1245739
[Epoch 72] ogbg-moltoxcast: 0.669006 val loss: 0.310059
[Epoch 72] ogbg-moltoxcast: 0.651824 test loss: 0.347456
[Epoch 73; Iter    12/  229] train: loss: 0.1509892
[Epoch 73; Iter    42/  229] train: loss: 0.1005283
[Epoch 73; Iter    72/  229] train: loss: 0.0868799
[Epoch 73; Iter   102/  229] train: loss: 0.1216456
[Epoch 73; Iter   132/  229] train: loss: 0.1621069
[Epoch 73; Iter   162/  229] train: loss: 0.1294198
[Epoch 73; Iter   192/  229] train: loss: 0.1174624
[Epoch 73; Iter   222/  229] train: loss: 0.1208942
[Epoch 73] ogbg-moltoxcast: 0.663899 val loss: 0.313863
[Epoch 73] ogbg-moltoxcast: 0.646440 test loss: 0.355472
[Epoch 74; Iter    23/  229] train: loss: 0.0818623
[Epoch 74; Iter    53/  229] train: loss: 0.1922113
[Epoch 74; Iter    83/  229] train: loss: 0.0891713
[Epoch 74; Iter   113/  229] train: loss: 0.1261183
[Epoch 74; Iter   143/  229] train: loss: 0.1560693
[Epoch 74; Iter   173/  229] train: loss: 0.0805182
[Epoch 74; Iter   203/  229] train: loss: 0.0884613
[Epoch 74] ogbg-moltoxcast: 0.667716 val loss: 0.312384
[Epoch 74] ogbg-moltoxcast: 0.649433 test loss: 0.353287
[Epoch 75; Iter     4/  229] train: loss: 0.0840654
[Epoch 75; Iter    34/  229] train: loss: 0.1397710
[Epoch 75; Iter    64/  229] train: loss: 0.0874611
[Epoch 75; Iter    94/  229] train: loss: 0.1393685
[Epoch 75; Iter   124/  229] train: loss: 0.1325203
[Epoch 75; Iter   154/  229] train: loss: 0.1004886
[Epoch 75; Iter   184/  229] train: loss: 0.1339950
[Epoch 75; Iter   214/  229] train: loss: 0.0999327
[Epoch 75] ogbg-moltoxcast: 0.666321 val loss: 0.317092
[Epoch 75] ogbg-moltoxcast: 0.650864 test loss: 0.354886
[Epoch 60; Iter    19/  229] train: loss: 0.1099142
[Epoch 60; Iter    49/  229] train: loss: 0.1068536
[Epoch 60; Iter    79/  229] train: loss: 0.1866649
[Epoch 60; Iter   109/  229] train: loss: 0.2081632
[Epoch 60; Iter   139/  229] train: loss: 0.1551451
[Epoch 60; Iter   169/  229] train: loss: 0.1334023
[Epoch 60; Iter   199/  229] train: loss: 0.1717545
[Epoch 60; Iter   229/  229] train: loss: 0.1462071
[Epoch 60] ogbg-moltoxcast: 0.674717 val loss: 0.382268
[Epoch 60] ogbg-moltoxcast: 0.643056 test loss: 0.412753
[Epoch 61; Iter    30/  229] train: loss: 0.1398405
[Epoch 61; Iter    60/  229] train: loss: 0.1478378
[Epoch 61; Iter    90/  229] train: loss: 0.0787960
[Epoch 61; Iter   120/  229] train: loss: 0.0745607
[Epoch 61; Iter   150/  229] train: loss: 0.1541374
[Epoch 61; Iter   180/  229] train: loss: 0.1032853
[Epoch 61; Iter   210/  229] train: loss: 0.0997722
[Epoch 61] ogbg-moltoxcast: 0.670180 val loss: 0.340573
[Epoch 61] ogbg-moltoxcast: 0.647382 test loss: 0.391645
[Epoch 62; Iter    11/  229] train: loss: 0.1086903
[Epoch 62; Iter    41/  229] train: loss: 0.1343599
[Epoch 62; Iter    71/  229] train: loss: 0.0982537
[Epoch 62; Iter   101/  229] train: loss: 0.1145879
[Epoch 62; Iter   131/  229] train: loss: 0.1083911
[Epoch 62; Iter   161/  229] train: loss: 0.1192324
[Epoch 62; Iter   191/  229] train: loss: 0.1208358
[Epoch 62; Iter   221/  229] train: loss: 0.1240624
[Epoch 62] ogbg-moltoxcast: 0.673850 val loss: 0.325554
[Epoch 62] ogbg-moltoxcast: 0.645334 test loss: 0.376789
[Epoch 63; Iter    22/  229] train: loss: 0.1595998
[Epoch 63; Iter    52/  229] train: loss: 0.1445423
[Epoch 63; Iter    82/  229] train: loss: 0.0977515
[Epoch 63; Iter   112/  229] train: loss: 0.1278463
[Epoch 63; Iter   142/  229] train: loss: 0.1181223
[Epoch 63; Iter   172/  229] train: loss: 0.1549962
[Epoch 63; Iter   202/  229] train: loss: 0.0910119
[Epoch 63] ogbg-moltoxcast: 0.673024 val loss: 0.312173
[Epoch 63] ogbg-moltoxcast: 0.642426 test loss: 0.369436
[Epoch 64; Iter     3/  229] train: loss: 0.1896424
[Epoch 64; Iter    33/  229] train: loss: 0.1302606
[Epoch 64; Iter    63/  229] train: loss: 0.1789341
[Epoch 64; Iter    93/  229] train: loss: 0.1906185
[Epoch 64; Iter   123/  229] train: loss: 0.1404364
[Epoch 64; Iter   153/  229] train: loss: 0.1543002
[Epoch 64; Iter   183/  229] train: loss: 0.1666643
[Epoch 64; Iter   213/  229] train: loss: 0.0995782
[Epoch 64] ogbg-moltoxcast: 0.677299 val loss: 0.297244
[Epoch 64] ogbg-moltoxcast: 0.647424 test loss: 0.346337
[Epoch 65; Iter    14/  229] train: loss: 0.1052919
[Epoch 65; Iter    44/  229] train: loss: 0.1199793
[Epoch 65; Iter    74/  229] train: loss: 0.1310904
[Epoch 65; Iter   104/  229] train: loss: 0.1235480
[Epoch 65; Iter   134/  229] train: loss: 0.0964821
[Epoch 65; Iter   164/  229] train: loss: 0.1387756
[Epoch 65; Iter   194/  229] train: loss: 0.1011494
[Epoch 65; Iter   224/  229] train: loss: 0.1308439
[Epoch 65] ogbg-moltoxcast: 0.682503 val loss: 0.308688
[Epoch 65] ogbg-moltoxcast: 0.649436 test loss: 0.365820
[Epoch 66; Iter    25/  229] train: loss: 0.1176585
[Epoch 66; Iter    55/  229] train: loss: 0.1606128
[Epoch 66; Iter    85/  229] train: loss: 0.0968413
[Epoch 66; Iter   115/  229] train: loss: 0.1525116
[Epoch 66; Iter   145/  229] train: loss: 0.1065390
[Epoch 66; Iter   175/  229] train: loss: 0.0916850
[Epoch 66; Iter   205/  229] train: loss: 0.1531261
[Epoch 66] ogbg-moltoxcast: 0.672614 val loss: 0.459420
[Epoch 66] ogbg-moltoxcast: 0.645873 test loss: 0.652541
[Epoch 67; Iter     6/  229] train: loss: 0.0758606
[Epoch 67; Iter    36/  229] train: loss: 0.1093541
[Epoch 67; Iter    66/  229] train: loss: 0.1317800
[Epoch 67; Iter    96/  229] train: loss: 0.1111546
[Epoch 67; Iter   126/  229] train: loss: 0.1550553
[Epoch 67; Iter   156/  229] train: loss: 0.1029503
[Epoch 67; Iter   186/  229] train: loss: 0.1135009
[Epoch 67; Iter   216/  229] train: loss: 0.0927525
[Epoch 67] ogbg-moltoxcast: 0.678063 val loss: 0.323527
[Epoch 67] ogbg-moltoxcast: 0.648357 test loss: 0.383856
[Epoch 68; Iter    17/  229] train: loss: 0.1237675
[Epoch 68; Iter    47/  229] train: loss: 0.1292251
[Epoch 68; Iter    77/  229] train: loss: 0.1724065
[Epoch 68; Iter   107/  229] train: loss: 0.1146094
[Epoch 68; Iter   137/  229] train: loss: 0.1155851
[Epoch 68; Iter   167/  229] train: loss: 0.1418474
[Epoch 68; Iter   197/  229] train: loss: 0.1225583
[Epoch 68; Iter   227/  229] train: loss: 0.1300642
[Epoch 68] ogbg-moltoxcast: 0.673853 val loss: 0.315466
[Epoch 68] ogbg-moltoxcast: 0.647378 test loss: 0.368992
[Epoch 69; Iter    28/  229] train: loss: 0.1508121
[Epoch 69; Iter    58/  229] train: loss: 0.1428889
[Epoch 69; Iter    88/  229] train: loss: 0.1362304
[Epoch 69; Iter   118/  229] train: loss: 0.1730999
[Epoch 69; Iter   148/  229] train: loss: 0.1663061
[Epoch 69; Iter   178/  229] train: loss: 0.0893737
[Epoch 69; Iter   208/  229] train: loss: 0.0949881
[Epoch 69] ogbg-moltoxcast: 0.671480 val loss: 0.316134
[Epoch 69] ogbg-moltoxcast: 0.644238 test loss: 0.384222
[Epoch 70; Iter     9/  229] train: loss: 0.1453623
[Epoch 70; Iter    39/  229] train: loss: 0.1254176
[Epoch 70; Iter    69/  229] train: loss: 0.1283766
[Epoch 70; Iter    99/  229] train: loss: 0.1626869
[Epoch 70; Iter   129/  229] train: loss: 0.1404477
[Epoch 70; Iter   159/  229] train: loss: 0.1078216
[Epoch 70; Iter   189/  229] train: loss: 0.1062459
[Epoch 70; Iter   219/  229] train: loss: 0.1738307
[Epoch 70] ogbg-moltoxcast: 0.674100 val loss: 0.316782
[Epoch 70] ogbg-moltoxcast: 0.646591 test loss: 0.370819
[Epoch 71; Iter    20/  229] train: loss: 0.1246465
[Epoch 71; Iter    50/  229] train: loss: 0.0873162
[Epoch 71; Iter    80/  229] train: loss: 0.1435421
[Epoch 71; Iter   110/  229] train: loss: 0.1433317
[Epoch 71; Iter   140/  229] train: loss: 0.1272253
[Epoch 71; Iter   170/  229] train: loss: 0.1536116
[Epoch 71; Iter   200/  229] train: loss: 0.1180712
[Epoch 71] ogbg-moltoxcast: 0.674135 val loss: 0.360718
[Epoch 71] ogbg-moltoxcast: 0.641711 test loss: 0.434946
[Epoch 72; Iter     1/  229] train: loss: 0.1298997
[Epoch 72; Iter    31/  229] train: loss: 0.1282282
[Epoch 72; Iter    61/  229] train: loss: 0.1565465
[Epoch 72; Iter    91/  229] train: loss: 0.0989938
[Epoch 72; Iter   121/  229] train: loss: 0.0862233
[Epoch 72; Iter   151/  229] train: loss: 0.1430162
[Epoch 72; Iter   181/  229] train: loss: 0.1750851
[Epoch 72; Iter   211/  229] train: loss: 0.0925254
[Epoch 72] ogbg-moltoxcast: 0.673686 val loss: 0.311704
[Epoch 72] ogbg-moltoxcast: 0.643644 test loss: 0.366798
[Epoch 73; Iter    12/  229] train: loss: 0.1041116
[Epoch 73; Iter    42/  229] train: loss: 0.1314721
[Epoch 73; Iter    72/  229] train: loss: 0.1490660
[Epoch 73; Iter   102/  229] train: loss: 0.1371743
[Epoch 73; Iter   132/  229] train: loss: 0.1163146
[Epoch 73; Iter   162/  229] train: loss: 0.1389063
[Epoch 73; Iter   192/  229] train: loss: 0.1070826
[Epoch 73; Iter   222/  229] train: loss: 0.1130856
[Epoch 73] ogbg-moltoxcast: 0.669205 val loss: 0.337886
[Epoch 73] ogbg-moltoxcast: 0.637162 test loss: 0.414491
[Epoch 74; Iter    23/  229] train: loss: 0.0811082
[Epoch 74; Iter    53/  229] train: loss: 0.1322008
[Epoch 74; Iter    83/  229] train: loss: 0.1152411
[Epoch 74; Iter   113/  229] train: loss: 0.0889276
[Epoch 74; Iter   143/  229] train: loss: 0.1168930
[Epoch 74; Iter   173/  229] train: loss: 0.1216162
[Epoch 74; Iter   203/  229] train: loss: 0.1245914
[Epoch 74] ogbg-moltoxcast: 0.667312 val loss: 0.323266
[Epoch 74] ogbg-moltoxcast: 0.639657 test loss: 0.398033
[Epoch 75; Iter     4/  229] train: loss: 0.0844897
[Epoch 75; Iter    34/  229] train: loss: 0.1396774
[Epoch 75; Iter    64/  229] train: loss: 0.1812617
[Epoch 75; Iter    94/  229] train: loss: 0.1216072
[Epoch 75; Iter   124/  229] train: loss: 0.1243819
[Epoch 75; Iter   154/  229] train: loss: 0.1191702
[Epoch 75; Iter   184/  229] train: loss: 0.1645308
[Epoch 75; Iter   214/  229] train: loss: 0.1267266
[Epoch 75] ogbg-moltoxcast: 0.668303 val loss: 0.315988
[Epoch 75] ogbg-moltoxcast: 0.639370 test loss: 0.372047
[Epoch 60; Iter    19/  229] train: loss: 0.0949815
[Epoch 60; Iter    49/  229] train: loss: 0.1224678
[Epoch 60; Iter    79/  229] train: loss: 0.1513508
[Epoch 60; Iter   109/  229] train: loss: 0.1081868
[Epoch 60; Iter   139/  229] train: loss: 0.1326008
[Epoch 60; Iter   169/  229] train: loss: 0.0895812
[Epoch 60; Iter   199/  229] train: loss: 0.1467852
[Epoch 60; Iter   229/  229] train: loss: 0.1318498
[Epoch 60] ogbg-moltoxcast: 0.633680 val loss: 0.361594
[Epoch 60] ogbg-moltoxcast: 0.636415 test loss: 0.412514
[Epoch 61; Iter    30/  229] train: loss: 0.1419736
[Epoch 61; Iter    60/  229] train: loss: 0.1469643
[Epoch 61; Iter    90/  229] train: loss: 0.1616291
[Epoch 61; Iter   120/  229] train: loss: 0.1398376
[Epoch 61; Iter   150/  229] train: loss: 0.1348154
[Epoch 61; Iter   180/  229] train: loss: 0.1462636
[Epoch 61; Iter   210/  229] train: loss: 0.0779172
[Epoch 61] ogbg-moltoxcast: 0.631473 val loss: 0.360595
[Epoch 61] ogbg-moltoxcast: 0.632304 test loss: 0.415553
[Epoch 62; Iter    11/  229] train: loss: 0.0842896
[Epoch 62; Iter    41/  229] train: loss: 0.1670126
[Epoch 62; Iter    71/  229] train: loss: 0.1309570
[Epoch 62; Iter   101/  229] train: loss: 0.1270956
[Epoch 62; Iter   131/  229] train: loss: 0.1515812
[Epoch 62; Iter   161/  229] train: loss: 0.1171773
[Epoch 62; Iter   191/  229] train: loss: 0.1233993
[Epoch 62; Iter   221/  229] train: loss: 0.1435842
[Epoch 62] ogbg-moltoxcast: 0.630208 val loss: 0.365873
[Epoch 62] ogbg-moltoxcast: 0.632630 test loss: 0.418243
[Epoch 63; Iter    22/  229] train: loss: 0.1249998
[Epoch 63; Iter    52/  229] train: loss: 0.0781163
[Epoch 63; Iter    82/  229] train: loss: 0.0849886
[Epoch 63; Iter   112/  229] train: loss: 0.0874176
[Epoch 63; Iter   142/  229] train: loss: 0.1466524
[Epoch 63; Iter   172/  229] train: loss: 0.1669316
[Epoch 63; Iter   202/  229] train: loss: 0.1038405
[Epoch 63] ogbg-moltoxcast: 0.626745 val loss: 0.372999
[Epoch 63] ogbg-moltoxcast: 0.627243 test loss: 0.431027
[Epoch 64; Iter     3/  229] train: loss: 0.0816196
[Epoch 64; Iter    33/  229] train: loss: 0.1258874
[Epoch 64; Iter    63/  229] train: loss: 0.1257579
[Epoch 64; Iter    93/  229] train: loss: 0.1057646
[Epoch 64; Iter   123/  229] train: loss: 0.1064447
[Epoch 64; Iter   153/  229] train: loss: 0.1016862
[Epoch 64; Iter   183/  229] train: loss: 0.1010894
[Epoch 64; Iter   213/  229] train: loss: 0.1316328
[Epoch 64] ogbg-moltoxcast: 0.626815 val loss: 0.377531
[Epoch 64] ogbg-moltoxcast: 0.628171 test loss: 0.434426
[Epoch 65; Iter    14/  229] train: loss: 0.1388689
[Epoch 65; Iter    44/  229] train: loss: 0.1357021
[Epoch 65; Iter    74/  229] train: loss: 0.1213015
[Epoch 65; Iter   104/  229] train: loss: 0.1450008
[Epoch 65; Iter   134/  229] train: loss: 0.1218873
[Epoch 65; Iter   164/  229] train: loss: 0.1367063
[Epoch 65; Iter   194/  229] train: loss: 0.0990260
[Epoch 65; Iter   224/  229] train: loss: 0.1272316
[Epoch 65] ogbg-moltoxcast: 0.623111 val loss: 0.375443
[Epoch 65] ogbg-moltoxcast: 0.628101 test loss: 0.431515
[Epoch 66; Iter    25/  229] train: loss: 0.1137966
[Epoch 66; Iter    55/  229] train: loss: 0.1467351
[Epoch 66; Iter    85/  229] train: loss: 0.1269154
[Epoch 66; Iter   115/  229] train: loss: 0.1041821
[Epoch 66; Iter   145/  229] train: loss: 0.0996714
[Epoch 66; Iter   175/  229] train: loss: 0.1265114
[Epoch 66; Iter   205/  229] train: loss: 0.1040476
[Epoch 66] ogbg-moltoxcast: 0.627228 val loss: 0.365261
[Epoch 66] ogbg-moltoxcast: 0.628371 test loss: 0.419370
[Epoch 67; Iter     6/  229] train: loss: 0.1264532
[Epoch 67; Iter    36/  229] train: loss: 0.1465919
[Epoch 67; Iter    66/  229] train: loss: 0.1019692
[Epoch 67; Iter    96/  229] train: loss: 0.1527690
[Epoch 67; Iter   126/  229] train: loss: 0.1021693
[Epoch 67; Iter   156/  229] train: loss: 0.1051634
[Epoch 67; Iter   186/  229] train: loss: 0.1039100
[Epoch 67; Iter   216/  229] train: loss: 0.0906128
[Epoch 67] ogbg-moltoxcast: 0.624724 val loss: 0.360759
[Epoch 67] ogbg-moltoxcast: 0.634293 test loss: 0.414554
[Epoch 68; Iter    17/  229] train: loss: 0.1517875
[Epoch 68; Iter    47/  229] train: loss: 0.1045935
[Epoch 68; Iter    77/  229] train: loss: 0.1118936
[Epoch 68; Iter   107/  229] train: loss: 0.1442284
[Epoch 68; Iter   137/  229] train: loss: 0.1038101
[Epoch 68; Iter   167/  229] train: loss: 0.1004356
[Epoch 68; Iter   197/  229] train: loss: 0.1425320
[Epoch 68; Iter   227/  229] train: loss: 0.1333225
[Epoch 68] ogbg-moltoxcast: 0.629120 val loss: 0.384854
[Epoch 68] ogbg-moltoxcast: 0.630143 test loss: 0.442714
[Epoch 69; Iter    28/  229] train: loss: 0.1281460
[Epoch 69; Iter    58/  229] train: loss: 0.0816013
[Epoch 69; Iter    88/  229] train: loss: 0.1046258
[Epoch 69; Iter   118/  229] train: loss: 0.1046900
[Epoch 69; Iter   148/  229] train: loss: 0.0919750
[Epoch 69; Iter   178/  229] train: loss: 0.1817763
[Epoch 69; Iter   208/  229] train: loss: 0.1166254
[Epoch 69] ogbg-moltoxcast: 0.630365 val loss: 0.364515
[Epoch 69] ogbg-moltoxcast: 0.631174 test loss: 0.421917
[Epoch 70; Iter     9/  229] train: loss: 0.1007655
[Epoch 70; Iter    39/  229] train: loss: 0.1309086
[Epoch 70; Iter    69/  229] train: loss: 0.1181819
[Epoch 70; Iter    99/  229] train: loss: 0.1531046
[Epoch 70; Iter   129/  229] train: loss: 0.1017037
[Epoch 70; Iter   159/  229] train: loss: 0.1455462
[Epoch 70; Iter   189/  229] train: loss: 0.1604365
[Epoch 70; Iter   219/  229] train: loss: 0.1418039
[Epoch 70] ogbg-moltoxcast: 0.630930 val loss: 0.379442
[Epoch 70] ogbg-moltoxcast: 0.628994 test loss: 0.437595
[Epoch 71; Iter    20/  229] train: loss: 0.0975268
[Epoch 71; Iter    50/  229] train: loss: 0.0888450
[Epoch 71; Iter    80/  229] train: loss: 0.1186432
[Epoch 71; Iter   110/  229] train: loss: 0.1171312
[Epoch 71; Iter   140/  229] train: loss: 0.0883486
[Epoch 71; Iter   170/  229] train: loss: 0.1274243
[Epoch 71; Iter   200/  229] train: loss: 0.1013115
[Epoch 71] ogbg-moltoxcast: 0.626432 val loss: 0.387443
[Epoch 71] ogbg-moltoxcast: 0.626274 test loss: 0.447928
[Epoch 72; Iter     1/  229] train: loss: 0.0897827
[Epoch 72; Iter    31/  229] train: loss: 0.0990446
[Epoch 72; Iter    61/  229] train: loss: 0.1152495
[Epoch 72; Iter    91/  229] train: loss: 0.1259968
[Epoch 72; Iter   121/  229] train: loss: 0.1062089
[Epoch 72; Iter   151/  229] train: loss: 0.1435788
[Epoch 72; Iter   181/  229] train: loss: 0.0866482
[Epoch 72; Iter   211/  229] train: loss: 0.1258609
[Epoch 72] ogbg-moltoxcast: 0.630554 val loss: 0.371296
[Epoch 72] ogbg-moltoxcast: 0.632211 test loss: 0.423931
[Epoch 73; Iter    12/  229] train: loss: 0.1572525
[Epoch 73; Iter    42/  229] train: loss: 0.1029716
[Epoch 73; Iter    72/  229] train: loss: 0.0930919
[Epoch 73; Iter   102/  229] train: loss: 0.1214526
[Epoch 73; Iter   132/  229] train: loss: 0.1638673
[Epoch 73; Iter   162/  229] train: loss: 0.1259352
[Epoch 73; Iter   192/  229] train: loss: 0.1131623
[Epoch 73; Iter   222/  229] train: loss: 0.1268812
[Epoch 73] ogbg-moltoxcast: 0.628118 val loss: 0.369447
[Epoch 73] ogbg-moltoxcast: 0.625857 test loss: 0.431285
[Epoch 74; Iter    23/  229] train: loss: 0.0825196
[Epoch 74; Iter    53/  229] train: loss: 0.1738769
[Epoch 74; Iter    83/  229] train: loss: 0.0834143
[Epoch 74; Iter   113/  229] train: loss: 0.1193162
[Epoch 74; Iter   143/  229] train: loss: 0.1678076
[Epoch 74; Iter   173/  229] train: loss: 0.0838138
[Epoch 74; Iter   203/  229] train: loss: 0.0903140
[Epoch 74] ogbg-moltoxcast: 0.628429 val loss: 0.386643
[Epoch 74] ogbg-moltoxcast: 0.626217 test loss: 0.448780
[Epoch 75; Iter     4/  229] train: loss: 0.0833299
[Epoch 75; Iter    34/  229] train: loss: 0.1404685
[Epoch 75; Iter    64/  229] train: loss: 0.0888584
[Epoch 75; Iter    94/  229] train: loss: 0.1317607
[Epoch 75; Iter   124/  229] train: loss: 0.1379157
[Epoch 75; Iter   154/  229] train: loss: 0.1016911
[Epoch 75; Iter   184/  229] train: loss: 0.1263088
[Epoch 75; Iter   214/  229] train: loss: 0.1026947
[Epoch 75] ogbg-moltoxcast: 0.637585 val loss: 0.372370
[Epoch 75] ogbg-moltoxcast: 0.631769 test loss: 0.431023
[Epoch 60; Iter    19/  229] train: loss: 0.1721348
[Epoch 60; Iter    49/  229] train: loss: 0.1348625
[Epoch 60; Iter    79/  229] train: loss: 0.1187147
[Epoch 60; Iter   109/  229] train: loss: 0.1446816
[Epoch 60; Iter   139/  229] train: loss: 0.1353007
[Epoch 60; Iter   169/  229] train: loss: 0.1782090
[Epoch 60; Iter   199/  229] train: loss: 0.1155105
[Epoch 60; Iter   229/  229] train: loss: 0.1275752
[Epoch 60] ogbg-moltoxcast: 0.656150 val loss: 0.314619
[Epoch 60] ogbg-moltoxcast: 0.636339 test loss: 0.334527
[Epoch 61; Iter    30/  229] train: loss: 0.1492364
[Epoch 61; Iter    60/  229] train: loss: 0.1524702
[Epoch 61; Iter    90/  229] train: loss: 0.0950174
[Epoch 61; Iter   120/  229] train: loss: 0.1493175
[Epoch 61; Iter   150/  229] train: loss: 0.1030125
[Epoch 61; Iter   180/  229] train: loss: 0.1867902
[Epoch 61; Iter   210/  229] train: loss: 0.1212804
[Epoch 61] ogbg-moltoxcast: 0.645605 val loss: 0.318608
[Epoch 61] ogbg-moltoxcast: 0.638709 test loss: 0.353436
[Epoch 62; Iter    11/  229] train: loss: 0.1343406
[Epoch 62; Iter    41/  229] train: loss: 0.1775663
[Epoch 62; Iter    71/  229] train: loss: 0.1768310
[Epoch 62; Iter   101/  229] train: loss: 0.1870153
[Epoch 62; Iter   131/  229] train: loss: 0.1387422
[Epoch 62; Iter   161/  229] train: loss: 0.1367962
[Epoch 62; Iter   191/  229] train: loss: 0.0932007
[Epoch 62; Iter   221/  229] train: loss: 0.1930260
[Epoch 62] ogbg-moltoxcast: 0.659886 val loss: 0.316297
[Epoch 62] ogbg-moltoxcast: 0.655870 test loss: 0.322384
[Epoch 63; Iter    22/  229] train: loss: 0.1124387
[Epoch 63; Iter    52/  229] train: loss: 0.1284140
[Epoch 63; Iter    82/  229] train: loss: 0.0760561
[Epoch 63; Iter   112/  229] train: loss: 0.1259394
[Epoch 63; Iter   142/  229] train: loss: 0.1604773
[Epoch 63; Iter   172/  229] train: loss: 0.1856906
[Epoch 63; Iter   202/  229] train: loss: 0.1186999
[Epoch 63] ogbg-moltoxcast: 0.661262 val loss: 0.307422
[Epoch 63] ogbg-moltoxcast: 0.651836 test loss: 0.332699
[Epoch 64; Iter     3/  229] train: loss: 0.1449752
[Epoch 64; Iter    33/  229] train: loss: 0.1585452
[Epoch 64; Iter    63/  229] train: loss: 0.1302197
[Epoch 64; Iter    93/  229] train: loss: 0.1121617
[Epoch 64; Iter   123/  229] train: loss: 0.1374977
[Epoch 64; Iter   153/  229] train: loss: 0.1280473
[Epoch 64; Iter   183/  229] train: loss: 0.1845588
[Epoch 64; Iter   213/  229] train: loss: 0.1170689
[Epoch 64] ogbg-moltoxcast: 0.656808 val loss: 0.312087
[Epoch 64] ogbg-moltoxcast: 0.649999 test loss: 0.335224
[Epoch 65; Iter    14/  229] train: loss: 0.0926970
[Epoch 65; Iter    44/  229] train: loss: 0.1090875
[Epoch 65; Iter    74/  229] train: loss: 0.1043576
[Epoch 65; Iter   104/  229] train: loss: 0.1158786
[Epoch 65; Iter   134/  229] train: loss: 0.1860116
[Epoch 65; Iter   164/  229] train: loss: 0.1626568
[Epoch 65; Iter   194/  229] train: loss: 0.1394000
[Epoch 65; Iter   224/  229] train: loss: 0.1994201
[Epoch 65] ogbg-moltoxcast: 0.653135 val loss: 0.317107
[Epoch 65] ogbg-moltoxcast: 0.649370 test loss: 0.341258
[Epoch 66; Iter    25/  229] train: loss: 0.1045278
[Epoch 66; Iter    55/  229] train: loss: 0.1001658
[Epoch 66; Iter    85/  229] train: loss: 0.1519919
[Epoch 66; Iter   115/  229] train: loss: 0.1899804
[Epoch 66; Iter   145/  229] train: loss: 0.1203745
[Epoch 66; Iter   175/  229] train: loss: 0.1623380
[Epoch 66; Iter   205/  229] train: loss: 0.1680087
[Epoch 66] ogbg-moltoxcast: 0.656024 val loss: 0.310840
[Epoch 66] ogbg-moltoxcast: 0.646138 test loss: 0.375554
[Epoch 67; Iter     6/  229] train: loss: 0.1400841
[Epoch 67; Iter    36/  229] train: loss: 0.1560301
[Epoch 67; Iter    66/  229] train: loss: 0.1249097
[Epoch 67; Iter    96/  229] train: loss: 0.1282540
[Epoch 67; Iter   126/  229] train: loss: 0.1580235
[Epoch 67; Iter   156/  229] train: loss: 0.1582756
[Epoch 67; Iter   186/  229] train: loss: 0.1678670
[Epoch 67; Iter   216/  229] train: loss: 0.1378243
[Epoch 67] ogbg-moltoxcast: 0.654829 val loss: 0.321527
[Epoch 67] ogbg-moltoxcast: 0.642818 test loss: 0.408340
[Epoch 68; Iter    17/  229] train: loss: 0.1844985
[Epoch 68; Iter    47/  229] train: loss: 0.1137896
[Epoch 68; Iter    77/  229] train: loss: 0.1163429
[Epoch 68; Iter   107/  229] train: loss: 0.1308291
[Epoch 68; Iter   137/  229] train: loss: 0.1092850
[Epoch 68; Iter   167/  229] train: loss: 0.1064075
[Epoch 68; Iter   197/  229] train: loss: 0.1427826
[Epoch 68; Iter   227/  229] train: loss: 0.1311909
[Epoch 68] ogbg-moltoxcast: 0.664910 val loss: 0.312767
[Epoch 68] ogbg-moltoxcast: 0.646292 test loss: 0.330953
[Epoch 69; Iter    28/  229] train: loss: 0.1526320
[Epoch 69; Iter    58/  229] train: loss: 0.1829624
[Epoch 69; Iter    88/  229] train: loss: 0.1037688
[Epoch 69; Iter   118/  229] train: loss: 0.0959548
[Epoch 69; Iter   148/  229] train: loss: 0.1437455
[Epoch 69; Iter   178/  229] train: loss: 0.1489066
[Epoch 69; Iter   208/  229] train: loss: 0.0945409
[Epoch 69] ogbg-moltoxcast: 0.662097 val loss: 0.314343
[Epoch 69] ogbg-moltoxcast: 0.648726 test loss: 0.337115
[Epoch 70; Iter     9/  229] train: loss: 0.0972840
[Epoch 70; Iter    39/  229] train: loss: 0.1069113
[Epoch 70; Iter    69/  229] train: loss: 0.1205333
[Epoch 70; Iter    99/  229] train: loss: 0.1498035
[Epoch 70; Iter   129/  229] train: loss: 0.1381950
[Epoch 70; Iter   159/  229] train: loss: 0.1358033
[Epoch 70; Iter   189/  229] train: loss: 0.1501993
[Epoch 70; Iter   219/  229] train: loss: 0.1335567
[Epoch 70] ogbg-moltoxcast: 0.660198 val loss: 0.318458
[Epoch 70] ogbg-moltoxcast: 0.648140 test loss: 0.333767
[Epoch 71; Iter    20/  229] train: loss: 0.1431524
[Epoch 71; Iter    50/  229] train: loss: 0.1454168
[Epoch 71; Iter    80/  229] train: loss: 0.1090405
[Epoch 71; Iter   110/  229] train: loss: 0.1542855
[Epoch 71; Iter   140/  229] train: loss: 0.1251732
[Epoch 71; Iter   170/  229] train: loss: 0.0898695
[Epoch 71; Iter   200/  229] train: loss: 0.1215263
[Epoch 71] ogbg-moltoxcast: 0.661305 val loss: 0.325141
[Epoch 71] ogbg-moltoxcast: 0.643959 test loss: 0.342030
[Epoch 72; Iter     1/  229] train: loss: 0.1061031
[Epoch 72; Iter    31/  229] train: loss: 0.1875236
[Epoch 72; Iter    61/  229] train: loss: 0.1346550
[Epoch 72; Iter    91/  229] train: loss: 0.1493716
[Epoch 72; Iter   121/  229] train: loss: 0.1616034
[Epoch 72; Iter   151/  229] train: loss: 0.1881526
[Epoch 72; Iter   181/  229] train: loss: 0.1182157
[Epoch 72; Iter   211/  229] train: loss: 0.1334512
[Epoch 72] ogbg-moltoxcast: 0.658081 val loss: 0.320661
[Epoch 72] ogbg-moltoxcast: 0.645708 test loss: 0.342341
[Epoch 73; Iter    12/  229] train: loss: 0.1253451
[Epoch 73; Iter    42/  229] train: loss: 0.1813056
[Epoch 73; Iter    72/  229] train: loss: 0.1927944
[Epoch 73; Iter   102/  229] train: loss: 0.1193918
[Epoch 73; Iter   132/  229] train: loss: 0.1413185
[Epoch 73; Iter   162/  229] train: loss: 0.1468215
[Epoch 73; Iter   192/  229] train: loss: 0.1176593
[Epoch 73; Iter   222/  229] train: loss: 0.1372239
[Epoch 73] ogbg-moltoxcast: 0.658897 val loss: 0.318452
[Epoch 73] ogbg-moltoxcast: 0.646596 test loss: 0.359428
[Epoch 74; Iter    23/  229] train: loss: 0.1233691
[Epoch 74; Iter    53/  229] train: loss: 0.1160030
[Epoch 74; Iter    83/  229] train: loss: 0.0955575
[Epoch 74; Iter   113/  229] train: loss: 0.1174471
[Epoch 74; Iter   143/  229] train: loss: 0.1520013
[Epoch 74; Iter   173/  229] train: loss: 0.1150291
[Epoch 74; Iter   203/  229] train: loss: 0.0981518
[Epoch 74] ogbg-moltoxcast: 0.657972 val loss: 0.326090
[Epoch 74] ogbg-moltoxcast: 0.649004 test loss: 0.343874
[Epoch 75; Iter     4/  229] train: loss: 0.1001319
[Epoch 75; Iter    34/  229] train: loss: 0.1771347
[Epoch 75; Iter    64/  229] train: loss: 0.1581687
[Epoch 75; Iter    94/  229] train: loss: 0.1177082
[Epoch 75; Iter   124/  229] train: loss: 0.1264365
[Epoch 75; Iter   154/  229] train: loss: 0.1454975
[Epoch 75; Iter   184/  229] train: loss: 0.1321711
[Epoch 75; Iter   214/  229] train: loss: 0.1381706
[Epoch 75] ogbg-moltoxcast: 0.655010 val loss: 0.320880
[Epoch 75] ogbg-moltoxcast: 0.643969 test loss: 0.338455
[Epoch 60; Iter    19/  229] train: loss: 0.1089729
[Epoch 60; Iter    49/  229] train: loss: 0.1080315
[Epoch 60; Iter    79/  229] train: loss: 0.1899665
[Epoch 60; Iter   109/  229] train: loss: 0.2178092
[Epoch 60; Iter   139/  229] train: loss: 0.1500258
[Epoch 60; Iter   169/  229] train: loss: 0.1261662
[Epoch 60; Iter   199/  229] train: loss: 0.1707937
[Epoch 60; Iter   229/  229] train: loss: 0.1314165
[Epoch 60] ogbg-moltoxcast: 0.651005 val loss: 0.314215
[Epoch 60] ogbg-moltoxcast: 0.629718 test loss: 0.373237
[Epoch 61; Iter    30/  229] train: loss: 0.1356002
[Epoch 61; Iter    60/  229] train: loss: 0.1465988
[Epoch 61; Iter    90/  229] train: loss: 0.0873841
[Epoch 61; Iter   120/  229] train: loss: 0.0760798
[Epoch 61; Iter   150/  229] train: loss: 0.1484417
[Epoch 61; Iter   180/  229] train: loss: 0.1015045
[Epoch 61; Iter   210/  229] train: loss: 0.0982182
[Epoch 61] ogbg-moltoxcast: 0.655407 val loss: 0.320297
[Epoch 61] ogbg-moltoxcast: 0.637469 test loss: 0.378358
[Epoch 62; Iter    11/  229] train: loss: 0.1094382
[Epoch 62; Iter    41/  229] train: loss: 0.1277633
[Epoch 62; Iter    71/  229] train: loss: 0.0933191
[Epoch 62; Iter   101/  229] train: loss: 0.1124702
[Epoch 62; Iter   131/  229] train: loss: 0.1010934
[Epoch 62; Iter   161/  229] train: loss: 0.1191535
[Epoch 62; Iter   191/  229] train: loss: 0.1138201
[Epoch 62; Iter   221/  229] train: loss: 0.1233322
[Epoch 62] ogbg-moltoxcast: 0.655226 val loss: 0.335632
[Epoch 62] ogbg-moltoxcast: 0.637544 test loss: 0.397505
[Epoch 63; Iter    22/  229] train: loss: 0.1526357
[Epoch 63; Iter    52/  229] train: loss: 0.1452633
[Epoch 63; Iter    82/  229] train: loss: 0.0936375
[Epoch 63; Iter   112/  229] train: loss: 0.1227246
[Epoch 63; Iter   142/  229] train: loss: 0.1146225
[Epoch 63; Iter   172/  229] train: loss: 0.1610158
[Epoch 63; Iter   202/  229] train: loss: 0.0877350
[Epoch 63] ogbg-moltoxcast: 0.652663 val loss: 0.326501
[Epoch 63] ogbg-moltoxcast: 0.636171 test loss: 0.388011
[Epoch 64; Iter     3/  229] train: loss: 0.1884273
[Epoch 64; Iter    33/  229] train: loss: 0.1269593
[Epoch 64; Iter    63/  229] train: loss: 0.1694957
[Epoch 64; Iter    93/  229] train: loss: 0.1753670
[Epoch 64; Iter   123/  229] train: loss: 0.1417737
[Epoch 64; Iter   153/  229] train: loss: 0.1499162
[Epoch 64; Iter   183/  229] train: loss: 0.1571864
[Epoch 64; Iter   213/  229] train: loss: 0.0951425
[Epoch 64] ogbg-moltoxcast: 0.657248 val loss: 0.319623
[Epoch 64] ogbg-moltoxcast: 0.634798 test loss: 0.379768
[Epoch 65; Iter    14/  229] train: loss: 0.0978946
[Epoch 65; Iter    44/  229] train: loss: 0.1169329
[Epoch 65; Iter    74/  229] train: loss: 0.1167386
[Epoch 65; Iter   104/  229] train: loss: 0.1236381
[Epoch 65; Iter   134/  229] train: loss: 0.0961525
[Epoch 65; Iter   164/  229] train: loss: 0.1310915
[Epoch 65; Iter   194/  229] train: loss: 0.0868196
[Epoch 65; Iter   224/  229] train: loss: 0.1273388
[Epoch 65] ogbg-moltoxcast: 0.655537 val loss: 0.322785
[Epoch 65] ogbg-moltoxcast: 0.634651 test loss: 0.383639
[Epoch 66; Iter    25/  229] train: loss: 0.1168564
[Epoch 66; Iter    55/  229] train: loss: 0.1657101
[Epoch 66; Iter    85/  229] train: loss: 0.0951229
[Epoch 66; Iter   115/  229] train: loss: 0.1430320
[Epoch 66; Iter   145/  229] train: loss: 0.1102652
[Epoch 66; Iter   175/  229] train: loss: 0.0969231
[Epoch 66; Iter   205/  229] train: loss: 0.1454240
[Epoch 66] ogbg-moltoxcast: 0.656710 val loss: 0.333795
[Epoch 66] ogbg-moltoxcast: 0.639811 test loss: 0.395590
[Epoch 67; Iter     6/  229] train: loss: 0.0678730
[Epoch 67; Iter    36/  229] train: loss: 0.1066478
[Epoch 67; Iter    66/  229] train: loss: 0.1266595
[Epoch 67; Iter    96/  229] train: loss: 0.1053366
[Epoch 67; Iter   126/  229] train: loss: 0.1521443
[Epoch 67; Iter   156/  229] train: loss: 0.0974862
[Epoch 67; Iter   186/  229] train: loss: 0.1124857
[Epoch 67; Iter   216/  229] train: loss: 0.0856165
[Epoch 67] ogbg-moltoxcast: 0.658788 val loss: 0.324352
[Epoch 67] ogbg-moltoxcast: 0.638728 test loss: 0.387017
[Epoch 68; Iter    17/  229] train: loss: 0.1248753
[Epoch 68; Iter    47/  229] train: loss: 0.1221736
[Epoch 68; Iter    77/  229] train: loss: 0.1714730
[Epoch 68; Iter   107/  229] train: loss: 0.1167041
[Epoch 68; Iter   137/  229] train: loss: 0.1096933
[Epoch 68; Iter   167/  229] train: loss: 0.1423823
[Epoch 68; Iter   197/  229] train: loss: 0.1224583
[Epoch 68; Iter   227/  229] train: loss: 0.1289216
[Epoch 68] ogbg-moltoxcast: 0.654819 val loss: 0.322446
[Epoch 68] ogbg-moltoxcast: 0.633773 test loss: 0.383694
[Epoch 69; Iter    28/  229] train: loss: 0.1468505
[Epoch 69; Iter    58/  229] train: loss: 0.1390911
[Epoch 69; Iter    88/  229] train: loss: 0.1361413
[Epoch 69; Iter   118/  229] train: loss: 0.1706649
[Epoch 69; Iter   148/  229] train: loss: 0.1703952
[Epoch 69; Iter   178/  229] train: loss: 0.0897645
[Epoch 69; Iter   208/  229] train: loss: 0.0981375
[Epoch 69] ogbg-moltoxcast: 0.652517 val loss: 0.322553
[Epoch 69] ogbg-moltoxcast: 0.636171 test loss: 0.380561
[Epoch 70; Iter     9/  229] train: loss: 0.1461259
[Epoch 70; Iter    39/  229] train: loss: 0.1245452
[Epoch 70; Iter    69/  229] train: loss: 0.1272344
[Epoch 70; Iter    99/  229] train: loss: 0.1604338
[Epoch 70; Iter   129/  229] train: loss: 0.1460387
[Epoch 70; Iter   159/  229] train: loss: 0.1140015
[Epoch 70; Iter   189/  229] train: loss: 0.1058419
[Epoch 70; Iter   219/  229] train: loss: 0.1664758
[Epoch 70] ogbg-moltoxcast: 0.651706 val loss: 0.326001
[Epoch 70] ogbg-moltoxcast: 0.636151 test loss: 0.385623
[Epoch 71; Iter    20/  229] train: loss: 0.1227986
[Epoch 71; Iter    50/  229] train: loss: 0.0951306
[Epoch 71; Iter    80/  229] train: loss: 0.1478926
[Epoch 71; Iter   110/  229] train: loss: 0.1423620
[Epoch 71; Iter   140/  229] train: loss: 0.1275188
[Epoch 71; Iter   170/  229] train: loss: 0.1609603
[Epoch 71; Iter   200/  229] train: loss: 0.1198144
[Epoch 71] ogbg-moltoxcast: 0.647570 val loss: 0.332481
[Epoch 71] ogbg-moltoxcast: 0.629446 test loss: 0.394820
[Epoch 72; Iter     1/  229] train: loss: 0.1322967
[Epoch 72; Iter    31/  229] train: loss: 0.1261264
[Epoch 72; Iter    61/  229] train: loss: 0.1629001
[Epoch 72; Iter    91/  229] train: loss: 0.0955058
[Epoch 72; Iter   121/  229] train: loss: 0.0902630
[Epoch 72; Iter   151/  229] train: loss: 0.1476878
[Epoch 72; Iter   181/  229] train: loss: 0.1821007
[Epoch 72; Iter   211/  229] train: loss: 0.0927698
[Epoch 72] ogbg-moltoxcast: 0.654848 val loss: 0.320716
[Epoch 72] ogbg-moltoxcast: 0.635125 test loss: 0.378186
[Epoch 73; Iter    12/  229] train: loss: 0.1010785
[Epoch 73; Iter    42/  229] train: loss: 0.1346516
[Epoch 73; Iter    72/  229] train: loss: 0.1605363
[Epoch 73; Iter   102/  229] train: loss: 0.1439680
[Epoch 73; Iter   132/  229] train: loss: 0.1187854
[Epoch 73; Iter   162/  229] train: loss: 0.1330291
[Epoch 73; Iter   192/  229] train: loss: 0.1020214
[Epoch 73; Iter   222/  229] train: loss: 0.1082293
[Epoch 73] ogbg-moltoxcast: 0.649846 val loss: 0.334102
[Epoch 73] ogbg-moltoxcast: 0.636272 test loss: 0.391380
[Epoch 74; Iter    23/  229] train: loss: 0.0884715
[Epoch 74; Iter    53/  229] train: loss: 0.1345416
[Epoch 74; Iter    83/  229] train: loss: 0.1095019
[Epoch 74; Iter   113/  229] train: loss: 0.0905111
[Epoch 74; Iter   143/  229] train: loss: 0.1195421
[Epoch 74; Iter   173/  229] train: loss: 0.1240552
[Epoch 74; Iter   203/  229] train: loss: 0.1239388
[Epoch 74] ogbg-moltoxcast: 0.649123 val loss: 0.329040
[Epoch 74] ogbg-moltoxcast: 0.633683 test loss: 0.392790
[Epoch 75; Iter     4/  229] train: loss: 0.0822063
[Epoch 75; Iter    34/  229] train: loss: 0.1371892
[Epoch 75; Iter    64/  229] train: loss: 0.1743832
[Epoch 75; Iter    94/  229] train: loss: 0.1291852
[Epoch 75; Iter   124/  229] train: loss: 0.1296046
[Epoch 75; Iter   154/  229] train: loss: 0.1203470
[Epoch 75; Iter   184/  229] train: loss: 0.1684995
[Epoch 75; Iter   214/  229] train: loss: 0.1295184
[Epoch 75] ogbg-moltoxcast: 0.654795 val loss: 0.335934
[Epoch 75] ogbg-moltoxcast: 0.634195 test loss: 0.400691
[Epoch 60; Iter    19/  229] train: loss: 0.1580260
[Epoch 60; Iter    49/  229] train: loss: 0.1315591
[Epoch 60; Iter    79/  229] train: loss: 0.1101518
[Epoch 60; Iter   109/  229] train: loss: 0.1370846
[Epoch 60; Iter   139/  229] train: loss: 0.1304283
[Epoch 60; Iter   169/  229] train: loss: 0.1764619
[Epoch 60; Iter   199/  229] train: loss: 0.1103259
[Epoch 60; Iter   229/  229] train: loss: 0.1271196
[Epoch 60] ogbg-moltoxcast: 0.626978 val loss: 1.564760
[Epoch 60] ogbg-moltoxcast: 0.611190 test loss: 3.750110
[Epoch 61; Iter    30/  229] train: loss: 0.1320004
[Epoch 61; Iter    60/  229] train: loss: 0.1456840
[Epoch 61; Iter    90/  229] train: loss: 0.0907278
[Epoch 61; Iter   120/  229] train: loss: 0.1402575
[Epoch 61; Iter   150/  229] train: loss: 0.0991538
[Epoch 61; Iter   180/  229] train: loss: 0.1732567
[Epoch 61; Iter   210/  229] train: loss: 0.1159587
[Epoch 61] ogbg-moltoxcast: 0.628357 val loss: 1.866445
[Epoch 61] ogbg-moltoxcast: 0.617398 test loss: 3.975781
[Epoch 62; Iter    11/  229] train: loss: 0.1161620
[Epoch 62; Iter    41/  229] train: loss: 0.1618422
[Epoch 62; Iter    71/  229] train: loss: 0.1663223
[Epoch 62; Iter   101/  229] train: loss: 0.1884934
[Epoch 62; Iter   131/  229] train: loss: 0.1112016
[Epoch 62; Iter   161/  229] train: loss: 0.1302789
[Epoch 62; Iter   191/  229] train: loss: 0.0916074
[Epoch 62; Iter   221/  229] train: loss: 0.1805443
[Epoch 62] ogbg-moltoxcast: 0.633653 val loss: 2.100306
[Epoch 62] ogbg-moltoxcast: 0.624358 test loss: 3.629620
[Epoch 63; Iter    22/  229] train: loss: 0.1050341
[Epoch 63; Iter    52/  229] train: loss: 0.1216421
[Epoch 63; Iter    82/  229] train: loss: 0.0750378
[Epoch 63; Iter   112/  229] train: loss: 0.1220289
[Epoch 63; Iter   142/  229] train: loss: 0.1487541
[Epoch 63; Iter   172/  229] train: loss: 0.1689018
[Epoch 63; Iter   202/  229] train: loss: 0.1186872
[Epoch 63] ogbg-moltoxcast: 0.636798 val loss: 1.661761
[Epoch 63] ogbg-moltoxcast: 0.618622 test loss: 2.855583
[Epoch 64; Iter     3/  229] train: loss: 0.1533740
[Epoch 64; Iter    33/  229] train: loss: 0.1632122
[Epoch 64; Iter    63/  229] train: loss: 0.1265834
[Epoch 64; Iter    93/  229] train: loss: 0.1046816
[Epoch 64; Iter   123/  229] train: loss: 0.1461831
[Epoch 64; Iter   153/  229] train: loss: 0.1201763
[Epoch 64; Iter   183/  229] train: loss: 0.1859672
[Epoch 64; Iter   213/  229] train: loss: 0.1219423
[Epoch 64] ogbg-moltoxcast: 0.636264 val loss: 1.578514
[Epoch 64] ogbg-moltoxcast: 0.621796 test loss: 3.386221
[Epoch 65; Iter    14/  229] train: loss: 0.0940956
[Epoch 65; Iter    44/  229] train: loss: 0.1096713
[Epoch 65; Iter    74/  229] train: loss: 0.0961751
[Epoch 65; Iter   104/  229] train: loss: 0.1180061
[Epoch 65; Iter   134/  229] train: loss: 0.1854872
[Epoch 65; Iter   164/  229] train: loss: 0.1599163
[Epoch 65; Iter   194/  229] train: loss: 0.1416265
[Epoch 65; Iter   224/  229] train: loss: 0.1965464
[Epoch 65] ogbg-moltoxcast: 0.645191 val loss: 2.077256
[Epoch 65] ogbg-moltoxcast: 0.623141 test loss: 3.660712
[Epoch 66; Iter    25/  229] train: loss: 0.0974890
[Epoch 66; Iter    55/  229] train: loss: 0.1031717
[Epoch 66; Iter    85/  229] train: loss: 0.1537346
[Epoch 66; Iter   115/  229] train: loss: 0.1827901
[Epoch 66; Iter   145/  229] train: loss: 0.1119391
[Epoch 66; Iter   175/  229] train: loss: 0.1574756
[Epoch 66; Iter   205/  229] train: loss: 0.1554472
[Epoch 66] ogbg-moltoxcast: 0.637392 val loss: 1.972899
[Epoch 66] ogbg-moltoxcast: 0.617284 test loss: 3.615514
[Epoch 67; Iter     6/  229] train: loss: 0.1415309
[Epoch 67; Iter    36/  229] train: loss: 0.1529572
[Epoch 67; Iter    66/  229] train: loss: 0.1227906
[Epoch 67; Iter    96/  229] train: loss: 0.1263724
[Epoch 67; Iter   126/  229] train: loss: 0.1546126
[Epoch 67; Iter   156/  229] train: loss: 0.1570908
[Epoch 67; Iter   186/  229] train: loss: 0.1723595
[Epoch 67; Iter   216/  229] train: loss: 0.1304831
[Epoch 67] ogbg-moltoxcast: 0.638560 val loss: 2.157438
[Epoch 67] ogbg-moltoxcast: 0.623616 test loss: 3.648278
[Epoch 68; Iter    17/  229] train: loss: 0.1748581
[Epoch 68; Iter    47/  229] train: loss: 0.1077569
[Epoch 68; Iter    77/  229] train: loss: 0.1253729
[Epoch 68; Iter   107/  229] train: loss: 0.1277227
[Epoch 68; Iter   137/  229] train: loss: 0.1018787
[Epoch 68; Iter   167/  229] train: loss: 0.1109250
[Epoch 68; Iter   197/  229] train: loss: 0.1408998
[Epoch 68; Iter   227/  229] train: loss: 0.1240067
[Epoch 68] ogbg-moltoxcast: 0.645640 val loss: 1.845405
[Epoch 68] ogbg-moltoxcast: 0.621541 test loss: 3.395939
[Epoch 69; Iter    28/  229] train: loss: 0.1453024
[Epoch 69; Iter    58/  229] train: loss: 0.1787808
[Epoch 69; Iter    88/  229] train: loss: 0.1029640
[Epoch 69; Iter   118/  229] train: loss: 0.0847767
[Epoch 69; Iter   148/  229] train: loss: 0.1431585
[Epoch 69; Iter   178/  229] train: loss: 0.1510193
[Epoch 69; Iter   208/  229] train: loss: 0.0978103
[Epoch 69] ogbg-moltoxcast: 0.636008 val loss: 1.979720
[Epoch 69] ogbg-moltoxcast: 0.621442 test loss: 3.279336
[Epoch 70; Iter     9/  229] train: loss: 0.0950773
[Epoch 70; Iter    39/  229] train: loss: 0.1096536
[Epoch 70; Iter    69/  229] train: loss: 0.1149422
[Epoch 70; Iter    99/  229] train: loss: 0.1544385
[Epoch 70; Iter   129/  229] train: loss: 0.1274647
[Epoch 70; Iter   159/  229] train: loss: 0.1339895
[Epoch 70; Iter   189/  229] train: loss: 0.1507966
[Epoch 70; Iter   219/  229] train: loss: 0.1257499
[Epoch 70] ogbg-moltoxcast: 0.629490 val loss: 2.244794
[Epoch 70] ogbg-moltoxcast: 0.618505 test loss: 3.018148
[Epoch 71; Iter    20/  229] train: loss: 0.1409734
[Epoch 71; Iter    50/  229] train: loss: 0.1332005
[Epoch 71; Iter    80/  229] train: loss: 0.1041708
[Epoch 71; Iter   110/  229] train: loss: 0.1551259
[Epoch 71; Iter   140/  229] train: loss: 0.1210610
[Epoch 71; Iter   170/  229] train: loss: 0.0875530
[Epoch 71; Iter   200/  229] train: loss: 0.1190971
[Epoch 71] ogbg-moltoxcast: 0.633443 val loss: 2.240660
[Epoch 71] ogbg-moltoxcast: 0.622920 test loss: 3.448041
[Epoch 72; Iter     1/  229] train: loss: 0.1080850
[Epoch 72; Iter    31/  229] train: loss: 0.1755827
[Epoch 72; Iter    61/  229] train: loss: 0.1341086
[Epoch 72; Iter    91/  229] train: loss: 0.1413982
[Epoch 72; Iter   121/  229] train: loss: 0.1625455
[Epoch 72; Iter   151/  229] train: loss: 0.1795229
[Epoch 72; Iter   181/  229] train: loss: 0.1101194
[Epoch 72; Iter   211/  229] train: loss: 0.1277515
[Epoch 72] ogbg-moltoxcast: 0.639917 val loss: 1.313473
[Epoch 72] ogbg-moltoxcast: 0.619028 test loss: 2.828897
[Epoch 73; Iter    12/  229] train: loss: 0.1204825
[Epoch 73; Iter    42/  229] train: loss: 0.1829304
[Epoch 73; Iter    72/  229] train: loss: 0.1797860
[Epoch 73; Iter   102/  229] train: loss: 0.1133030
[Epoch 73; Iter   132/  229] train: loss: 0.1473089
[Epoch 73; Iter   162/  229] train: loss: 0.1514103
[Epoch 73; Iter   192/  229] train: loss: 0.1078336
[Epoch 73; Iter   222/  229] train: loss: 0.1293405
[Epoch 73] ogbg-moltoxcast: 0.636379 val loss: 2.199065
[Epoch 73] ogbg-moltoxcast: 0.623338 test loss: 2.850983
[Epoch 74; Iter    23/  229] train: loss: 0.1261381
[Epoch 74; Iter    53/  229] train: loss: 0.1134580
[Epoch 74; Iter    83/  229] train: loss: 0.1051020
[Epoch 74; Iter   113/  229] train: loss: 0.1187837
[Epoch 74; Iter   143/  229] train: loss: 0.1464823
[Epoch 74; Iter   173/  229] train: loss: 0.1041976
[Epoch 74; Iter   203/  229] train: loss: 0.1008635
[Epoch 74] ogbg-moltoxcast: 0.639992 val loss: 2.147666
[Epoch 74] ogbg-moltoxcast: 0.622248 test loss: 3.093700
[Epoch 75; Iter     4/  229] train: loss: 0.0934449
[Epoch 75; Iter    34/  229] train: loss: 0.1433941
[Epoch 75; Iter    64/  229] train: loss: 0.1664326
[Epoch 75; Iter    94/  229] train: loss: 0.1169057
[Epoch 75; Iter   124/  229] train: loss: 0.1296711
[Epoch 75; Iter   154/  229] train: loss: 0.1482777
[Epoch 75; Iter   184/  229] train: loss: 0.1328529
[Epoch 75; Iter   214/  229] train: loss: 0.1419588
[Epoch 75] ogbg-moltoxcast: 0.631685 val loss: 1.582521
[Epoch 75] ogbg-moltoxcast: 0.618679 test loss: 2.625012
[Epoch 60; Iter    19/  229] train: loss: 0.1099921
[Epoch 60; Iter    49/  229] train: loss: 0.1190412
[Epoch 60; Iter    79/  229] train: loss: 0.2128718
[Epoch 60; Iter   109/  229] train: loss: 0.2345738
[Epoch 60; Iter   139/  229] train: loss: 0.1665155
[Epoch 60; Iter   169/  229] train: loss: 0.1362116
[Epoch 60; Iter   199/  229] train: loss: 0.1879650
[Epoch 60; Iter   229/  229] train: loss: 0.1376235
[Epoch 60] ogbg-moltoxcast: 0.709020 val loss: 0.254708
[Epoch 60] ogbg-moltoxcast: 0.665184 test loss: 0.316016
[Epoch 61; Iter    30/  229] train: loss: 0.1490174
[Epoch 61; Iter    60/  229] train: loss: 0.1598053
[Epoch 61; Iter    90/  229] train: loss: 0.0900810
[Epoch 61; Iter   120/  229] train: loss: 0.0899123
[Epoch 61; Iter   150/  229] train: loss: 0.1511897
[Epoch 61; Iter   180/  229] train: loss: 0.1136535
[Epoch 61; Iter   210/  229] train: loss: 0.1086272
[Epoch 61] ogbg-moltoxcast: 0.707053 val loss: 0.253894
[Epoch 61] ogbg-moltoxcast: 0.665921 test loss: 0.317237
[Epoch 62; Iter    11/  229] train: loss: 0.1188066
[Epoch 62; Iter    41/  229] train: loss: 0.1444927
[Epoch 62; Iter    71/  229] train: loss: 0.1033047
[Epoch 62; Iter   101/  229] train: loss: 0.1157144
[Epoch 62; Iter   131/  229] train: loss: 0.1016669
[Epoch 62; Iter   161/  229] train: loss: 0.1278751
[Epoch 62; Iter   191/  229] train: loss: 0.1218869
[Epoch 62; Iter   221/  229] train: loss: 0.1223307
[Epoch 62] ogbg-moltoxcast: 0.710236 val loss: 0.249181
[Epoch 62] ogbg-moltoxcast: 0.664388 test loss: 0.310442
[Epoch 63; Iter    22/  229] train: loss: 0.1592142
[Epoch 63; Iter    52/  229] train: loss: 0.1497962
[Epoch 63; Iter    82/  229] train: loss: 0.1019524
[Epoch 63; Iter   112/  229] train: loss: 0.1354769
[Epoch 63; Iter   142/  229] train: loss: 0.1156632
[Epoch 63; Iter   172/  229] train: loss: 0.1698044
[Epoch 63; Iter   202/  229] train: loss: 0.0926142
[Epoch 63] ogbg-moltoxcast: 0.706435 val loss: 0.251204
[Epoch 63] ogbg-moltoxcast: 0.663080 test loss: 0.318888
[Epoch 64; Iter     3/  229] train: loss: 0.2212563
[Epoch 64; Iter    33/  229] train: loss: 0.1370540
[Epoch 64; Iter    63/  229] train: loss: 0.1878992
[Epoch 64; Iter    93/  229] train: loss: 0.2000694
[Epoch 64; Iter   123/  229] train: loss: 0.1518912
[Epoch 64; Iter   153/  229] train: loss: 0.1530811
[Epoch 64; Iter   183/  229] train: loss: 0.1791263
[Epoch 64; Iter   213/  229] train: loss: 0.1032433
[Epoch 64] ogbg-moltoxcast: 0.710158 val loss: 0.253874
[Epoch 64] ogbg-moltoxcast: 0.668651 test loss: 0.313856
[Epoch 65; Iter    14/  229] train: loss: 0.1094045
[Epoch 65; Iter    44/  229] train: loss: 0.1324168
[Epoch 65; Iter    74/  229] train: loss: 0.1289077
[Epoch 65; Iter   104/  229] train: loss: 0.1474789
[Epoch 65; Iter   134/  229] train: loss: 0.0979341
[Epoch 65; Iter   164/  229] train: loss: 0.1397663
[Epoch 65; Iter   194/  229] train: loss: 0.1026416
[Epoch 65; Iter   224/  229] train: loss: 0.1507098
[Epoch 65] ogbg-moltoxcast: 0.711195 val loss: 0.252135
[Epoch 65] ogbg-moltoxcast: 0.668156 test loss: 0.317867
[Epoch 66; Iter    25/  229] train: loss: 0.1284545
[Epoch 66; Iter    55/  229] train: loss: 0.1751517
[Epoch 66; Iter    85/  229] train: loss: 0.1013360
[Epoch 66; Iter   115/  229] train: loss: 0.1523867
[Epoch 66; Iter   145/  229] train: loss: 0.1167764
[Epoch 66; Iter   175/  229] train: loss: 0.1051149
[Epoch 66; Iter   205/  229] train: loss: 0.1582157
[Epoch 66] ogbg-moltoxcast: 0.710587 val loss: 0.255727
[Epoch 66] ogbg-moltoxcast: 0.666199 test loss: 0.315337
[Epoch 67; Iter     6/  229] train: loss: 0.0819014
[Epoch 67; Iter    36/  229] train: loss: 0.1116829
[Epoch 67; Iter    66/  229] train: loss: 0.1702456
[Epoch 67; Iter    96/  229] train: loss: 0.1232685
[Epoch 67; Iter   126/  229] train: loss: 0.1598234
[Epoch 67; Iter   156/  229] train: loss: 0.1083264
[Epoch 67; Iter   186/  229] train: loss: 0.1218300
[Epoch 67; Iter   216/  229] train: loss: 0.1087999
[Epoch 67] ogbg-moltoxcast: 0.708565 val loss: 0.254229
[Epoch 67] ogbg-moltoxcast: 0.662071 test loss: 0.317838
[Epoch 68; Iter    17/  229] train: loss: 0.1376919
[Epoch 68; Iter    47/  229] train: loss: 0.1308859
[Epoch 68; Iter    77/  229] train: loss: 0.2129191
[Epoch 68; Iter   107/  229] train: loss: 0.1231220
[Epoch 68; Iter   137/  229] train: loss: 0.1160984
[Epoch 68; Iter   167/  229] train: loss: 0.1513720
[Epoch 68; Iter   197/  229] train: loss: 0.1321580
[Epoch 68; Iter   227/  229] train: loss: 0.1404772
[Epoch 68] ogbg-moltoxcast: 0.706514 val loss: 0.257782
[Epoch 68] ogbg-moltoxcast: 0.665063 test loss: 0.319519
[Epoch 69; Iter    28/  229] train: loss: 0.1598435
[Epoch 69; Iter    58/  229] train: loss: 0.1583880
[Epoch 69; Iter    88/  229] train: loss: 0.1513832
[Epoch 69; Iter   118/  229] train: loss: 0.2002066
[Epoch 69; Iter   148/  229] train: loss: 0.1758639
[Epoch 69; Iter   178/  229] train: loss: 0.0987365
[Epoch 69; Iter   208/  229] train: loss: 0.1037118
[Epoch 69] ogbg-moltoxcast: 0.710941 val loss: 0.252735
[Epoch 69] ogbg-moltoxcast: 0.661164 test loss: 0.319428
[Epoch 70; Iter     9/  229] train: loss: 0.1602236
[Epoch 70; Iter    39/  229] train: loss: 0.1364197
[Epoch 70; Iter    69/  229] train: loss: 0.1358654
[Epoch 70; Iter    99/  229] train: loss: 0.1835765
[Epoch 70; Iter   129/  229] train: loss: 0.1582429
[Epoch 70; Iter   159/  229] train: loss: 0.1218165
[Epoch 70; Iter   189/  229] train: loss: 0.1165112
[Epoch 70; Iter   219/  229] train: loss: 0.1978544
[Epoch 70] ogbg-moltoxcast: 0.706338 val loss: 0.256794
[Epoch 70] ogbg-moltoxcast: 0.664108 test loss: 0.317509
[Epoch 71; Iter    20/  229] train: loss: 0.1313213
[Epoch 71; Iter    50/  229] train: loss: 0.1059954
[Epoch 71; Iter    80/  229] train: loss: 0.1516108
[Epoch 71; Iter   110/  229] train: loss: 0.1487679
[Epoch 71; Iter   140/  229] train: loss: 0.1394542
[Epoch 71; Iter   170/  229] train: loss: 0.1654184
[Epoch 71; Iter   200/  229] train: loss: 0.1404025
[Epoch 71] ogbg-moltoxcast: 0.700654 val loss: 0.257242
[Epoch 71] ogbg-moltoxcast: 0.661607 test loss: 0.319315
[Epoch 72; Iter     1/  229] train: loss: 0.1430777
[Epoch 72; Iter    31/  229] train: loss: 0.1409892
[Epoch 72; Iter    61/  229] train: loss: 0.1722557
[Epoch 72; Iter    91/  229] train: loss: 0.1064769
[Epoch 72; Iter   121/  229] train: loss: 0.0937792
[Epoch 72; Iter   151/  229] train: loss: 0.1548757
[Epoch 72; Iter   181/  229] train: loss: 0.1874063
[Epoch 72; Iter   211/  229] train: loss: 0.0971230
[Epoch 72] ogbg-moltoxcast: 0.703987 val loss: 0.258034
[Epoch 72] ogbg-moltoxcast: 0.667036 test loss: 0.320563
[Epoch 73; Iter    12/  229] train: loss: 0.1047672
[Epoch 73; Iter    42/  229] train: loss: 0.1423348
[Epoch 73; Iter    72/  229] train: loss: 0.1639055
[Epoch 73; Iter   102/  229] train: loss: 0.1429035
[Epoch 73; Iter   132/  229] train: loss: 0.1235258
[Epoch 73; Iter   162/  229] train: loss: 0.1455490
[Epoch 73; Iter   192/  229] train: loss: 0.1089184
[Epoch 73; Iter   222/  229] train: loss: 0.1255001
[Epoch 73] ogbg-moltoxcast: 0.703036 val loss: 0.255773
[Epoch 73] ogbg-moltoxcast: 0.659366 test loss: 0.317921
[Epoch 74; Iter    23/  229] train: loss: 0.0896057
[Epoch 74; Iter    53/  229] train: loss: 0.1419527
[Epoch 74; Iter    83/  229] train: loss: 0.1208485
[Epoch 74; Iter   113/  229] train: loss: 0.0960248
[Epoch 74; Iter   143/  229] train: loss: 0.1286596
[Epoch 74; Iter   173/  229] train: loss: 0.1419309
[Epoch 74; Iter   203/  229] train: loss: 0.1449791
[Epoch 74] ogbg-moltoxcast: 0.707118 val loss: 0.254444
[Epoch 74] ogbg-moltoxcast: 0.658387 test loss: 0.322066
[Epoch 75; Iter     4/  229] train: loss: 0.0917617
[Epoch 75; Iter    34/  229] train: loss: 0.1554049
[Epoch 75; Iter    64/  229] train: loss: 0.1788585
[Epoch 75; Iter    94/  229] train: loss: 0.1276556
[Epoch 75; Iter   124/  229] train: loss: 0.1319753
[Epoch 75; Iter   154/  229] train: loss: 0.1216711
[Epoch 75; Iter   184/  229] train: loss: 0.1838097
[Epoch 75; Iter   214/  229] train: loss: 0.1300469
[Epoch 75] ogbg-moltoxcast: 0.702045 val loss: 0.258537
[Epoch 75] ogbg-moltoxcast: 0.663171 test loss: 0.323518
[Epoch 60; Iter    19/  229] train: loss: 0.1616720
[Epoch 60; Iter    49/  229] train: loss: 0.1280204
[Epoch 60; Iter    79/  229] train: loss: 0.1117926
[Epoch 60; Iter   109/  229] train: loss: 0.1393614
[Epoch 60; Iter   139/  229] train: loss: 0.1369755
[Epoch 60; Iter   169/  229] train: loss: 0.1901086
[Epoch 60; Iter   199/  229] train: loss: 0.1060710
[Epoch 60; Iter   229/  229] train: loss: 0.1274733
[Epoch 60] ogbg-moltoxcast: 0.689530 val loss: 0.468651
[Epoch 60] ogbg-moltoxcast: 0.653481 test loss: 0.311923
[Epoch 61; Iter    30/  229] train: loss: 0.1299683
[Epoch 61; Iter    60/  229] train: loss: 0.1625297
[Epoch 61; Iter    90/  229] train: loss: 0.1128486
[Epoch 61; Iter   120/  229] train: loss: 0.1451839
[Epoch 61; Iter   150/  229] train: loss: 0.1143902
[Epoch 61; Iter   180/  229] train: loss: 0.1865575
[Epoch 61; Iter   210/  229] train: loss: 0.1209695
[Epoch 61] ogbg-moltoxcast: 0.688566 val loss: 0.402557
[Epoch 61] ogbg-moltoxcast: 0.656414 test loss: 0.405428
[Epoch 62; Iter    11/  229] train: loss: 0.1208001
[Epoch 62; Iter    41/  229] train: loss: 0.1785457
[Epoch 62; Iter    71/  229] train: loss: 0.1644529
[Epoch 62; Iter   101/  229] train: loss: 0.2004635
[Epoch 62; Iter   131/  229] train: loss: 0.1175773
[Epoch 62; Iter   161/  229] train: loss: 0.1322856
[Epoch 62; Iter   191/  229] train: loss: 0.0923383
[Epoch 62; Iter   221/  229] train: loss: 0.2018590
[Epoch 62] ogbg-moltoxcast: 0.693225 val loss: 0.334760
[Epoch 62] ogbg-moltoxcast: 0.664775 test loss: 0.312607
[Epoch 63; Iter    22/  229] train: loss: 0.1166462
[Epoch 63; Iter    52/  229] train: loss: 0.1267895
[Epoch 63; Iter    82/  229] train: loss: 0.0803822
[Epoch 63; Iter   112/  229] train: loss: 0.1289496
[Epoch 63; Iter   142/  229] train: loss: 0.1712644
[Epoch 63; Iter   172/  229] train: loss: 0.1823416
[Epoch 63; Iter   202/  229] train: loss: 0.1088022
[Epoch 63] ogbg-moltoxcast: 0.692879 val loss: 0.294562
[Epoch 63] ogbg-moltoxcast: 0.661466 test loss: 0.477927
[Epoch 64; Iter     3/  229] train: loss: 0.1455152
[Epoch 64; Iter    33/  229] train: loss: 0.1545881
[Epoch 64; Iter    63/  229] train: loss: 0.1237223
[Epoch 64; Iter    93/  229] train: loss: 0.1257102
[Epoch 64; Iter   123/  229] train: loss: 0.1440963
[Epoch 64; Iter   153/  229] train: loss: 0.1423707
[Epoch 64; Iter   183/  229] train: loss: 0.1785187
[Epoch 64; Iter   213/  229] train: loss: 0.1184471
[Epoch 64] ogbg-moltoxcast: 0.688562 val loss: 0.292632
[Epoch 64] ogbg-moltoxcast: 0.661953 test loss: 0.412567
[Epoch 65; Iter    14/  229] train: loss: 0.0963105
[Epoch 65; Iter    44/  229] train: loss: 0.1064496
[Epoch 65; Iter    74/  229] train: loss: 0.1042750
[Epoch 65; Iter   104/  229] train: loss: 0.1228904
[Epoch 65; Iter   134/  229] train: loss: 0.1941868
[Epoch 65; Iter   164/  229] train: loss: 0.1635873
[Epoch 65; Iter   194/  229] train: loss: 0.1344326
[Epoch 65; Iter   224/  229] train: loss: 0.2093440
[Epoch 65] ogbg-moltoxcast: 0.689668 val loss: 0.492953
[Epoch 65] ogbg-moltoxcast: 0.665031 test loss: 0.316347
[Epoch 66; Iter    25/  229] train: loss: 0.0979804
[Epoch 66; Iter    55/  229] train: loss: 0.1045582
[Epoch 66; Iter    85/  229] train: loss: 0.1571945
[Epoch 66; Iter   115/  229] train: loss: 0.1877884
[Epoch 66; Iter   145/  229] train: loss: 0.1336353
[Epoch 66; Iter   175/  229] train: loss: 0.1584464
[Epoch 66; Iter   205/  229] train: loss: 0.1717913
[Epoch 66] ogbg-moltoxcast: 0.691585 val loss: 0.533737
[Epoch 66] ogbg-moltoxcast: 0.659492 test loss: 0.320012
[Epoch 67; Iter     6/  229] train: loss: 0.1494506
[Epoch 67; Iter    36/  229] train: loss: 0.1631959
[Epoch 67; Iter    66/  229] train: loss: 0.1179583
[Epoch 67; Iter    96/  229] train: loss: 0.1223024
[Epoch 67; Iter   126/  229] train: loss: 0.1627429
[Epoch 67; Iter   156/  229] train: loss: 0.1645665
[Epoch 67; Iter   186/  229] train: loss: 0.1631514
[Epoch 67; Iter   216/  229] train: loss: 0.1484855
[Epoch 67] ogbg-moltoxcast: 0.689528 val loss: 0.275016
[Epoch 67] ogbg-moltoxcast: 0.663402 test loss: 0.324980
[Epoch 68; Iter    17/  229] train: loss: 0.1820945
[Epoch 68; Iter    47/  229] train: loss: 0.1164039
[Epoch 68; Iter    77/  229] train: loss: 0.1135365
[Epoch 68; Iter   107/  229] train: loss: 0.1256768
[Epoch 68; Iter   137/  229] train: loss: 0.1120321
[Epoch 68; Iter   167/  229] train: loss: 0.1127762
[Epoch 68; Iter   197/  229] train: loss: 0.1397020
[Epoch 68; Iter   227/  229] train: loss: 0.1304315
[Epoch 68] ogbg-moltoxcast: 0.688136 val loss: 0.470124
[Epoch 68] ogbg-moltoxcast: 0.661549 test loss: 0.320608
[Epoch 69; Iter    28/  229] train: loss: 0.1439070
[Epoch 69; Iter    58/  229] train: loss: 0.1756947
[Epoch 69; Iter    88/  229] train: loss: 0.1073293
[Epoch 69; Iter   118/  229] train: loss: 0.0957218
[Epoch 69; Iter   148/  229] train: loss: 0.1606136
[Epoch 69; Iter   178/  229] train: loss: 0.1690034
[Epoch 69; Iter   208/  229] train: loss: 0.1006888
[Epoch 69] ogbg-moltoxcast: 0.689047 val loss: 0.272027
[Epoch 69] ogbg-moltoxcast: 0.663649 test loss: 0.325686
[Epoch 70; Iter     9/  229] train: loss: 0.1034200
[Epoch 70; Iter    39/  229] train: loss: 0.1161763
[Epoch 70; Iter    69/  229] train: loss: 0.1262751
[Epoch 70; Iter    99/  229] train: loss: 0.1590945
[Epoch 70; Iter   129/  229] train: loss: 0.1310725
[Epoch 70; Iter   159/  229] train: loss: 0.1367787
[Epoch 70; Iter   189/  229] train: loss: 0.1520699
[Epoch 70; Iter   219/  229] train: loss: 0.1356734
[Epoch 70] ogbg-moltoxcast: 0.685546 val loss: 0.300816
[Epoch 70] ogbg-moltoxcast: 0.660883 test loss: 0.358634
[Epoch 71; Iter    20/  229] train: loss: 0.1495708
[Epoch 71; Iter    50/  229] train: loss: 0.1441018
[Epoch 71; Iter    80/  229] train: loss: 0.1045041
[Epoch 71; Iter   110/  229] train: loss: 0.1568082
[Epoch 71; Iter   140/  229] train: loss: 0.1292531
[Epoch 71; Iter   170/  229] train: loss: 0.0912827
[Epoch 71; Iter   200/  229] train: loss: 0.1236364
[Epoch 71] ogbg-moltoxcast: 0.690962 val loss: 0.271094
[Epoch 71] ogbg-moltoxcast: 0.663096 test loss: 0.322798
[Epoch 72; Iter     1/  229] train: loss: 0.1287326
[Epoch 72; Iter    31/  229] train: loss: 0.1780591
[Epoch 72; Iter    61/  229] train: loss: 0.1361951
[Epoch 72; Iter    91/  229] train: loss: 0.1504448
[Epoch 72; Iter   121/  229] train: loss: 0.1675638
[Epoch 72; Iter   151/  229] train: loss: 0.1800429
[Epoch 72; Iter   181/  229] train: loss: 0.1275600
[Epoch 72; Iter   211/  229] train: loss: 0.1434219
[Epoch 72] ogbg-moltoxcast: 0.686667 val loss: 0.438288
[Epoch 72] ogbg-moltoxcast: 0.661857 test loss: 0.325294
[Epoch 73; Iter    12/  229] train: loss: 0.1238235
[Epoch 73; Iter    42/  229] train: loss: 0.1823288
[Epoch 73; Iter    72/  229] train: loss: 0.1828760
[Epoch 73; Iter   102/  229] train: loss: 0.1313155
[Epoch 73; Iter   132/  229] train: loss: 0.1482026
[Epoch 73; Iter   162/  229] train: loss: 0.1398705
[Epoch 73; Iter   192/  229] train: loss: 0.1196356
[Epoch 73; Iter   222/  229] train: loss: 0.1299195
[Epoch 73] ogbg-moltoxcast: 0.685163 val loss: 0.282998
[Epoch 73] ogbg-moltoxcast: 0.659947 test loss: 0.318920
[Epoch 74; Iter    23/  229] train: loss: 0.1337802
[Epoch 74; Iter    53/  229] train: loss: 0.1277041
[Epoch 74; Iter    83/  229] train: loss: 0.0980101
[Epoch 74; Iter   113/  229] train: loss: 0.1164126
[Epoch 74; Iter   143/  229] train: loss: 0.1745712
[Epoch 74; Iter   173/  229] train: loss: 0.1092738
[Epoch 74; Iter   203/  229] train: loss: 0.0942929
[Epoch 74] ogbg-moltoxcast: 0.694734 val loss: 0.276469
[Epoch 74] ogbg-moltoxcast: 0.664006 test loss: 0.325323
[Epoch 75; Iter     4/  229] train: loss: 0.0985862
[Epoch 75; Iter    34/  229] train: loss: 0.1572416
[Epoch 75; Iter    64/  229] train: loss: 0.1462258
[Epoch 75; Iter    94/  229] train: loss: 0.1249043
[Epoch 75; Iter   124/  229] train: loss: 0.1354686
[Epoch 75; Iter   154/  229] train: loss: 0.1488487
[Epoch 75; Iter   184/  229] train: loss: 0.1367741
[Epoch 75; Iter   214/  229] train: loss: 0.1303393
[Epoch 75] ogbg-moltoxcast: 0.688211 val loss: 0.270529
[Epoch 75] ogbg-moltoxcast: 0.659320 test loss: 0.318418
[Epoch 76; Iter    15/  229] train: loss: 0.1176204
[Epoch 76; Iter    45/  229] train: loss: 0.1252945
[Epoch 76; Iter    75/  229] train: loss: 0.1366539
[Epoch 76; Iter   105/  229] train: loss: 0.1289965
[Epoch 76; Iter   135/  229] train: loss: 0.1000151
[Epoch 76; Iter   165/  229] train: loss: 0.1310776
[Epoch 76; Iter   195/  229] train: loss: 0.1194747
[Epoch 76; Iter   225/  229] train: loss: 0.1312308
[Epoch 76] ogbg-moltoxcast: 0.681985 val loss: 0.295668
[Epoch 76] ogbg-moltoxcast: 0.643886 test loss: 0.350559
[Epoch 77; Iter    26/  229] train: loss: 0.1187938
[Epoch 77; Iter    56/  229] train: loss: 0.0955726
[Epoch 77; Iter    86/  229] train: loss: 0.1725302
[Epoch 77; Iter   116/  229] train: loss: 0.1176250
[Epoch 77; Iter   146/  229] train: loss: 0.0986943
[Epoch 77; Iter   176/  229] train: loss: 0.1266070
[Epoch 77; Iter   206/  229] train: loss: 0.1368930
[Epoch 77] ogbg-moltoxcast: 0.685358 val loss: 0.295593
[Epoch 77] ogbg-moltoxcast: 0.649766 test loss: 0.352908
[Epoch 78; Iter     7/  229] train: loss: 0.1209117
[Epoch 78; Iter    37/  229] train: loss: 0.1034173
[Epoch 78; Iter    67/  229] train: loss: 0.0940728
[Epoch 78; Iter    97/  229] train: loss: 0.1135461
[Epoch 78; Iter   127/  229] train: loss: 0.1602703
[Epoch 78; Iter   157/  229] train: loss: 0.0934895
[Epoch 78; Iter   187/  229] train: loss: 0.1335641
[Epoch 78; Iter   217/  229] train: loss: 0.1099484
[Epoch 78] ogbg-moltoxcast: 0.687369 val loss: 0.289932
[Epoch 78] ogbg-moltoxcast: 0.649745 test loss: 0.348838
[Epoch 79; Iter    18/  229] train: loss: 0.1661451
[Epoch 79; Iter    48/  229] train: loss: 0.1407913
[Epoch 79; Iter    78/  229] train: loss: 0.1435116
[Epoch 79; Iter   108/  229] train: loss: 0.1258673
[Epoch 79; Iter   138/  229] train: loss: 0.1356008
[Epoch 79; Iter   168/  229] train: loss: 0.1319287
[Epoch 79; Iter   198/  229] train: loss: 0.0838172
[Epoch 79; Iter   228/  229] train: loss: 0.1455173
[Epoch 79] ogbg-moltoxcast: 0.686863 val loss: 0.292893
[Epoch 79] ogbg-moltoxcast: 0.650638 test loss: 0.348003
[Epoch 80; Iter    29/  229] train: loss: 0.1079509
[Epoch 80; Iter    59/  229] train: loss: 0.1141575
[Epoch 80; Iter    89/  229] train: loss: 0.1323070
[Epoch 80; Iter   119/  229] train: loss: 0.1112346
[Epoch 80; Iter   149/  229] train: loss: 0.1158341
[Epoch 80; Iter   179/  229] train: loss: 0.1124026
[Epoch 80; Iter   209/  229] train: loss: 0.1259043
[Epoch 80] ogbg-moltoxcast: 0.685535 val loss: 0.290997
[Epoch 80] ogbg-moltoxcast: 0.650011 test loss: 0.348288
[Epoch 81; Iter    10/  229] train: loss: 0.1189655
[Epoch 81; Iter    40/  229] train: loss: 0.1320394
[Epoch 81; Iter    70/  229] train: loss: 0.1212042
[Epoch 81; Iter   100/  229] train: loss: 0.1440147
[Epoch 81; Iter   130/  229] train: loss: 0.1397843
[Epoch 81; Iter   160/  229] train: loss: 0.1371780
[Epoch 81; Iter   190/  229] train: loss: 0.1200407
[Epoch 81; Iter   220/  229] train: loss: 0.0986674
[Epoch 81] ogbg-moltoxcast: 0.683209 val loss: 0.296760
[Epoch 81] ogbg-moltoxcast: 0.647395 test loss: 0.350458
[Epoch 82; Iter    21/  229] train: loss: 0.0985062
[Epoch 82; Iter    51/  229] train: loss: 0.1134126
[Epoch 82; Iter    81/  229] train: loss: 0.1266521
[Epoch 82; Iter   111/  229] train: loss: 0.0986041
[Epoch 82; Iter   141/  229] train: loss: 0.0980116
[Epoch 82; Iter   171/  229] train: loss: 0.1164550
[Epoch 82; Iter   201/  229] train: loss: 0.1142827
[Epoch 82] ogbg-moltoxcast: 0.678257 val loss: 0.297340
[Epoch 82] ogbg-moltoxcast: 0.644594 test loss: 0.353737
[Epoch 83; Iter     2/  229] train: loss: 0.1643979
[Epoch 83; Iter    32/  229] train: loss: 0.0927108
[Epoch 83; Iter    62/  229] train: loss: 0.1079856
[Epoch 83; Iter    92/  229] train: loss: 0.1256594
[Epoch 83; Iter   122/  229] train: loss: 0.1067868
[Epoch 83; Iter   152/  229] train: loss: 0.0942320
[Epoch 83; Iter   182/  229] train: loss: 0.0813435
[Epoch 83; Iter   212/  229] train: loss: 0.1508861
[Epoch 83] ogbg-moltoxcast: 0.682953 val loss: 0.297373
[Epoch 83] ogbg-moltoxcast: 0.643135 test loss: 0.349928
[Epoch 84; Iter    13/  229] train: loss: 0.1052163
[Epoch 84; Iter    43/  229] train: loss: 0.1146434
[Epoch 84; Iter    73/  229] train: loss: 0.0915415
[Epoch 84; Iter   103/  229] train: loss: 0.1059739
[Epoch 84; Iter   133/  229] train: loss: 0.0800459
[Epoch 84; Iter   163/  229] train: loss: 0.1043565
[Epoch 84; Iter   193/  229] train: loss: 0.1378657
[Epoch 84; Iter   223/  229] train: loss: 0.0970546
[Epoch 84] ogbg-moltoxcast: 0.684409 val loss: 0.300306
[Epoch 84] ogbg-moltoxcast: 0.647011 test loss: 0.354712
[Epoch 85; Iter    24/  229] train: loss: 0.1210557
[Epoch 85; Iter    54/  229] train: loss: 0.1119240
[Epoch 85; Iter    84/  229] train: loss: 0.1128536
[Epoch 85; Iter   114/  229] train: loss: 0.0886570
[Epoch 85; Iter   144/  229] train: loss: 0.1152714
[Epoch 85; Iter   174/  229] train: loss: 0.1798383
[Epoch 85; Iter   204/  229] train: loss: 0.1314767
[Epoch 85] ogbg-moltoxcast: 0.678586 val loss: 0.294144
[Epoch 85] ogbg-moltoxcast: 0.643834 test loss: 0.351494
[Epoch 86; Iter     5/  229] train: loss: 0.1051209
[Epoch 86; Iter    35/  229] train: loss: 0.1144465
[Epoch 86; Iter    65/  229] train: loss: 0.0706160
[Epoch 86; Iter    95/  229] train: loss: 0.1408962
[Epoch 86; Iter   125/  229] train: loss: 0.0735134
[Epoch 86; Iter   155/  229] train: loss: 0.1143268
[Epoch 86; Iter   185/  229] train: loss: 0.1124996
[Epoch 86; Iter   215/  229] train: loss: 0.1651449
[Epoch 86] ogbg-moltoxcast: 0.686573 val loss: 0.294603
[Epoch 86] ogbg-moltoxcast: 0.650445 test loss: 0.348407
[Epoch 87; Iter    16/  229] train: loss: 0.0816951
[Epoch 87; Iter    46/  229] train: loss: 0.0914702
[Epoch 87; Iter    76/  229] train: loss: 0.1351297
[Epoch 87; Iter   106/  229] train: loss: 0.1105630
[Epoch 87; Iter   136/  229] train: loss: 0.1721172
[Epoch 87; Iter   166/  229] train: loss: 0.1071478
[Epoch 87; Iter   196/  229] train: loss: 0.1142817
[Epoch 87; Iter   226/  229] train: loss: 0.0942584
[Epoch 87] ogbg-moltoxcast: 0.686460 val loss: 0.296962
[Epoch 87] ogbg-moltoxcast: 0.646876 test loss: 0.350399
[Epoch 88; Iter    27/  229] train: loss: 0.1128897
[Epoch 88; Iter    57/  229] train: loss: 0.1050332
[Epoch 88; Iter    87/  229] train: loss: 0.1095484
[Epoch 88; Iter   117/  229] train: loss: 0.1410818
[Epoch 88; Iter   147/  229] train: loss: 0.1144655
[Epoch 88; Iter   177/  229] train: loss: 0.1226201
[Epoch 88; Iter   207/  229] train: loss: 0.0928063
[Epoch 88] ogbg-moltoxcast: 0.688005 val loss: 0.293914
[Epoch 88] ogbg-moltoxcast: 0.645359 test loss: 0.353565
[Epoch 89; Iter     8/  229] train: loss: 0.1151825
[Epoch 89; Iter    38/  229] train: loss: 0.1391312
[Epoch 89; Iter    68/  229] train: loss: 0.1470198
[Epoch 89; Iter    98/  229] train: loss: 0.1077656
[Epoch 89; Iter   128/  229] train: loss: 0.1065310
[Epoch 89; Iter   158/  229] train: loss: 0.1027621
[Epoch 89; Iter   188/  229] train: loss: 0.0966963
[Epoch 89; Iter   218/  229] train: loss: 0.1313356
[Epoch 89] ogbg-moltoxcast: 0.684644 val loss: 0.299118
[Epoch 89] ogbg-moltoxcast: 0.644317 test loss: 0.351119
[Epoch 90; Iter    19/  229] train: loss: 0.1159546
[Epoch 90; Iter    49/  229] train: loss: 0.1151338
[Epoch 90; Iter    79/  229] train: loss: 0.0950770
[Epoch 90; Iter   109/  229] train: loss: 0.0764960
[Epoch 90; Iter   139/  229] train: loss: 0.0911504
[Epoch 90; Iter   169/  229] train: loss: 0.0943967
[Epoch 90; Iter   199/  229] train: loss: 0.1594845
[Epoch 90; Iter   229/  229] train: loss: 0.1264086
[Epoch 90] ogbg-moltoxcast: 0.684141 val loss: 0.294794
[Epoch 90] ogbg-moltoxcast: 0.643871 test loss: 0.353088
[Epoch 91; Iter    30/  229] train: loss: 0.1074988
[Epoch 91; Iter    60/  229] train: loss: 0.1322815
[Epoch 91; Iter    90/  229] train: loss: 0.1471266
[Epoch 91; Iter   120/  229] train: loss: 0.1029288
[Epoch 91; Iter   150/  229] train: loss: 0.1396825
[Epoch 91; Iter   180/  229] train: loss: 0.1721197
[Epoch 91; Iter   210/  229] train: loss: 0.1512059
[Epoch 91] ogbg-moltoxcast: 0.679922 val loss: 0.300722
[Epoch 91] ogbg-moltoxcast: 0.644979 test loss: 0.354558
[Epoch 76; Iter    15/  229] train: loss: 0.1059936
[Epoch 76; Iter    45/  229] train: loss: 0.1226135
[Epoch 76; Iter    75/  229] train: loss: 0.1343887
[Epoch 76; Iter   105/  229] train: loss: 0.0939005
[Epoch 76; Iter   135/  229] train: loss: 0.1838515
[Epoch 76; Iter   165/  229] train: loss: 0.0977238
[Epoch 76; Iter   195/  229] train: loss: 0.1191773
[Epoch 76; Iter   225/  229] train: loss: 0.0979834
[Epoch 76] ogbg-moltoxcast: 0.655351 val loss: 0.299662
[Epoch 76] ogbg-moltoxcast: 0.652178 test loss: 0.345146
[Epoch 77; Iter    26/  229] train: loss: 0.1336036
[Epoch 77; Iter    56/  229] train: loss: 0.0954622
[Epoch 77; Iter    86/  229] train: loss: 0.1980423
[Epoch 77; Iter   116/  229] train: loss: 0.1575826
[Epoch 77; Iter   146/  229] train: loss: 0.1270549
[Epoch 77; Iter   176/  229] train: loss: 0.1530257
[Epoch 77; Iter   206/  229] train: loss: 0.1414715
[Epoch 77] ogbg-moltoxcast: 0.660854 val loss: 0.301846
[Epoch 77] ogbg-moltoxcast: 0.649365 test loss: 0.346418
[Epoch 78; Iter     7/  229] train: loss: 0.1273499
[Epoch 78; Iter    37/  229] train: loss: 0.1257999
[Epoch 78; Iter    67/  229] train: loss: 0.1197154
[Epoch 78; Iter    97/  229] train: loss: 0.0898331
[Epoch 78; Iter   127/  229] train: loss: 0.1215075
[Epoch 78; Iter   157/  229] train: loss: 0.1089595
[Epoch 78; Iter   187/  229] train: loss: 0.1382467
[Epoch 78; Iter   217/  229] train: loss: 0.1468449
[Epoch 78] ogbg-moltoxcast: 0.656517 val loss: 0.308864
[Epoch 78] ogbg-moltoxcast: 0.648760 test loss: 0.356630
[Epoch 79; Iter    18/  229] train: loss: 0.1056282
[Epoch 79; Iter    48/  229] train: loss: 0.1365344
[Epoch 79; Iter    78/  229] train: loss: 0.1457657
[Epoch 79; Iter   108/  229] train: loss: 0.1478053
[Epoch 79; Iter   138/  229] train: loss: 0.1641052
[Epoch 79; Iter   168/  229] train: loss: 0.1638430
[Epoch 79; Iter   198/  229] train: loss: 0.1399437
[Epoch 79; Iter   228/  229] train: loss: 0.1529137
[Epoch 79] ogbg-moltoxcast: 0.652050 val loss: 0.305100
[Epoch 79] ogbg-moltoxcast: 0.648761 test loss: 0.350828
[Epoch 80; Iter    29/  229] train: loss: 0.1418445
[Epoch 80; Iter    59/  229] train: loss: 0.1196994
[Epoch 80; Iter    89/  229] train: loss: 0.1470295
[Epoch 80; Iter   119/  229] train: loss: 0.1140947
[Epoch 80; Iter   149/  229] train: loss: 0.1310964
[Epoch 80; Iter   179/  229] train: loss: 0.1330824
[Epoch 80; Iter   209/  229] train: loss: 0.1379424
[Epoch 80] ogbg-moltoxcast: 0.657355 val loss: 0.314262
[Epoch 80] ogbg-moltoxcast: 0.652986 test loss: 0.356584
[Epoch 81; Iter    10/  229] train: loss: 0.1061605
[Epoch 81; Iter    40/  229] train: loss: 0.1462247
[Epoch 81; Iter    70/  229] train: loss: 0.1360352
[Epoch 81; Iter   100/  229] train: loss: 0.0736018
[Epoch 81; Iter   130/  229] train: loss: 0.0893531
[Epoch 81; Iter   160/  229] train: loss: 0.1349735
[Epoch 81; Iter   190/  229] train: loss: 0.1289421
[Epoch 81; Iter   220/  229] train: loss: 0.1355715
[Epoch 81] ogbg-moltoxcast: 0.660476 val loss: 0.305622
[Epoch 81] ogbg-moltoxcast: 0.647552 test loss: 0.351976
[Epoch 82; Iter    21/  229] train: loss: 0.1416912
[Epoch 82; Iter    51/  229] train: loss: 0.1350248
[Epoch 82; Iter    81/  229] train: loss: 0.0972822
[Epoch 82; Iter   111/  229] train: loss: 0.1033304
[Epoch 82; Iter   141/  229] train: loss: 0.1423413
[Epoch 82; Iter   171/  229] train: loss: 0.1013593
[Epoch 82; Iter   201/  229] train: loss: 0.1429771
[Epoch 82] ogbg-moltoxcast: 0.655592 val loss: 0.381362
[Epoch 82] ogbg-moltoxcast: 0.645587 test loss: 0.424506
[Epoch 83; Iter     2/  229] train: loss: 0.1056108
[Epoch 83; Iter    32/  229] train: loss: 0.1162015
[Epoch 83; Iter    62/  229] train: loss: 0.0885543
[Epoch 83; Iter    92/  229] train: loss: 0.1512681
[Epoch 83; Iter   122/  229] train: loss: 0.1151951
[Epoch 83; Iter   152/  229] train: loss: 0.1480599
[Epoch 83; Iter   182/  229] train: loss: 0.1655027
[Epoch 83; Iter   212/  229] train: loss: 0.1126323
[Epoch 83] ogbg-moltoxcast: 0.659705 val loss: 0.308171
[Epoch 83] ogbg-moltoxcast: 0.647821 test loss: 0.357499
[Epoch 84; Iter    13/  229] train: loss: 0.1353780
[Epoch 84; Iter    43/  229] train: loss: 0.1194532
[Epoch 84; Iter    73/  229] train: loss: 0.1622225
[Epoch 84; Iter   103/  229] train: loss: 0.1024746
[Epoch 84; Iter   133/  229] train: loss: 0.1356184
[Epoch 84; Iter   163/  229] train: loss: 0.0859187
[Epoch 84; Iter   193/  229] train: loss: 0.1362296
[Epoch 84; Iter   223/  229] train: loss: 0.1064255
[Epoch 84] ogbg-moltoxcast: 0.652294 val loss: 0.310925
[Epoch 84] ogbg-moltoxcast: 0.648231 test loss: 0.360922
[Epoch 85; Iter    24/  229] train: loss: 0.1257339
[Epoch 85; Iter    54/  229] train: loss: 0.1012097
[Epoch 85; Iter    84/  229] train: loss: 0.1089925
[Epoch 85; Iter   114/  229] train: loss: 0.1020816
[Epoch 85; Iter   144/  229] train: loss: 0.1346865
[Epoch 85; Iter   174/  229] train: loss: 0.1387936
[Epoch 85; Iter   204/  229] train: loss: 0.1500957
[Epoch 85] ogbg-moltoxcast: 0.653022 val loss: 0.305536
[Epoch 85] ogbg-moltoxcast: 0.647048 test loss: 0.355828
[Epoch 86; Iter     5/  229] train: loss: 0.1743436
[Epoch 86; Iter    35/  229] train: loss: 0.1474459
[Epoch 86; Iter    65/  229] train: loss: 0.1214088
[Epoch 86; Iter    95/  229] train: loss: 0.1609061
[Epoch 86; Iter   125/  229] train: loss: 0.1214764
[Epoch 86; Iter   155/  229] train: loss: 0.1132754
[Epoch 86; Iter   185/  229] train: loss: 0.1301146
[Epoch 86; Iter   215/  229] train: loss: 0.1459265
[Epoch 86] ogbg-moltoxcast: 0.653838 val loss: 0.344493
[Epoch 86] ogbg-moltoxcast: 0.645879 test loss: 0.397278
[Epoch 87; Iter    16/  229] train: loss: 0.1108232
[Epoch 87; Iter    46/  229] train: loss: 0.1127549
[Epoch 87; Iter    76/  229] train: loss: 0.1024493
[Epoch 87; Iter   106/  229] train: loss: 0.1178911
[Epoch 87; Iter   136/  229] train: loss: 0.1215627
[Epoch 87; Iter   166/  229] train: loss: 0.1279080
[Epoch 87; Iter   196/  229] train: loss: 0.1321681
[Epoch 87; Iter   226/  229] train: loss: 0.1180873
[Epoch 87] ogbg-moltoxcast: 0.654284 val loss: 0.317677
[Epoch 87] ogbg-moltoxcast: 0.645838 test loss: 0.366366
[Epoch 88; Iter    27/  229] train: loss: 0.1903742
[Epoch 88; Iter    57/  229] train: loss: 0.1107992
[Epoch 88; Iter    87/  229] train: loss: 0.1033129
[Epoch 88; Iter   117/  229] train: loss: 0.1127814
[Epoch 88; Iter   147/  229] train: loss: 0.1000221
[Epoch 88; Iter   177/  229] train: loss: 0.1253236
[Epoch 88; Iter   207/  229] train: loss: 0.1177364
[Epoch 88] ogbg-moltoxcast: 0.655158 val loss: 0.308162
[Epoch 88] ogbg-moltoxcast: 0.647069 test loss: 0.354396
[Epoch 89; Iter     8/  229] train: loss: 0.1057694
[Epoch 89; Iter    38/  229] train: loss: 0.1037905
[Epoch 89; Iter    68/  229] train: loss: 0.1303287
[Epoch 89; Iter    98/  229] train: loss: 0.0991912
[Epoch 89; Iter   128/  229] train: loss: 0.1171663
[Epoch 89; Iter   158/  229] train: loss: 0.1188417
[Epoch 89; Iter   188/  229] train: loss: 0.1138647
[Epoch 89; Iter   218/  229] train: loss: 0.0854984
[Epoch 89] ogbg-moltoxcast: 0.653767 val loss: 0.312821
[Epoch 89] ogbg-moltoxcast: 0.644984 test loss: 0.360175
[Epoch 90; Iter    19/  229] train: loss: 0.1137332
[Epoch 90; Iter    49/  229] train: loss: 0.1541736
[Epoch 90; Iter    79/  229] train: loss: 0.1515967
[Epoch 90; Iter   109/  229] train: loss: 0.1641942
[Epoch 90; Iter   139/  229] train: loss: 0.1411161
[Epoch 90; Iter   169/  229] train: loss: 0.1238613
[Epoch 90; Iter   199/  229] train: loss: 0.0980869
[Epoch 90; Iter   229/  229] train: loss: 0.1124241
[Epoch 90] ogbg-moltoxcast: 0.651991 val loss: 0.313561
[Epoch 90] ogbg-moltoxcast: 0.644629 test loss: 0.364896
[Epoch 91; Iter    30/  229] train: loss: 0.1284408
[Epoch 91; Iter    60/  229] train: loss: 0.0999371
[Epoch 91; Iter    90/  229] train: loss: 0.1158857
[Epoch 91; Iter   120/  229] train: loss: 0.0983598
[Epoch 91; Iter   150/  229] train: loss: 0.1187873
[Epoch 91; Iter   180/  229] train: loss: 0.1286254
[Epoch 91; Iter   210/  229] train: loss: 0.1413012
[Epoch 91] ogbg-moltoxcast: 0.651274 val loss: 0.305282
[Epoch 91] ogbg-moltoxcast: 0.649690 test loss: 0.350686
[Epoch 76; Iter    15/  229] train: loss: 0.1451763
[Epoch 76; Iter    45/  229] train: loss: 0.1208213
[Epoch 76; Iter    75/  229] train: loss: 0.1943742
[Epoch 76; Iter   105/  229] train: loss: 0.1140500
[Epoch 76; Iter   135/  229] train: loss: 0.0947090
[Epoch 76; Iter   165/  229] train: loss: 0.1392529
[Epoch 76; Iter   195/  229] train: loss: 0.0734168
[Epoch 76; Iter   225/  229] train: loss: 0.1074519
[Epoch 76] ogbg-moltoxcast: 0.691587 val loss: 0.289349
[Epoch 76] ogbg-moltoxcast: 0.649414 test loss: 0.335170
[Epoch 77; Iter    26/  229] train: loss: 0.1293722
[Epoch 77; Iter    56/  229] train: loss: 0.1172919
[Epoch 77; Iter    86/  229] train: loss: 0.0906036
[Epoch 77; Iter   116/  229] train: loss: 0.1389779
[Epoch 77; Iter   146/  229] train: loss: 0.1128923
[Epoch 77; Iter   176/  229] train: loss: 0.1272996
[Epoch 77; Iter   206/  229] train: loss: 0.1491375
[Epoch 77] ogbg-moltoxcast: 0.690866 val loss: 0.291791
[Epoch 77] ogbg-moltoxcast: 0.645161 test loss: 0.339289
[Epoch 78; Iter     7/  229] train: loss: 0.1437251
[Epoch 78; Iter    37/  229] train: loss: 0.1306179
[Epoch 78; Iter    67/  229] train: loss: 0.0935371
[Epoch 78; Iter    97/  229] train: loss: 0.1376631
[Epoch 78; Iter   127/  229] train: loss: 0.1240694
[Epoch 78; Iter   157/  229] train: loss: 0.1066609
[Epoch 78; Iter   187/  229] train: loss: 0.1067956
[Epoch 78; Iter   217/  229] train: loss: 0.1136704
[Epoch 78] ogbg-moltoxcast: 0.687617 val loss: 0.294857
[Epoch 78] ogbg-moltoxcast: 0.646258 test loss: 0.334419
[Epoch 79; Iter    18/  229] train: loss: 0.0913358
[Epoch 79; Iter    48/  229] train: loss: 0.1205495
[Epoch 79; Iter    78/  229] train: loss: 0.0975067
[Epoch 79; Iter   108/  229] train: loss: 0.1266607
[Epoch 79; Iter   138/  229] train: loss: 0.1006822
[Epoch 79; Iter   168/  229] train: loss: 0.0836626
[Epoch 79; Iter   198/  229] train: loss: 0.0690414
[Epoch 79; Iter   228/  229] train: loss: 0.1544227
[Epoch 79] ogbg-moltoxcast: 0.688760 val loss: 0.287668
[Epoch 79] ogbg-moltoxcast: 0.639390 test loss: 0.336836
[Epoch 80; Iter    29/  229] train: loss: 0.1408908
[Epoch 80; Iter    59/  229] train: loss: 0.1094393
[Epoch 80; Iter    89/  229] train: loss: 0.0957429
[Epoch 80; Iter   119/  229] train: loss: 0.1385342
[Epoch 80; Iter   149/  229] train: loss: 0.1375102
[Epoch 80; Iter   179/  229] train: loss: 0.2335127
[Epoch 80; Iter   209/  229] train: loss: 0.1094534
[Epoch 80] ogbg-moltoxcast: 0.688628 val loss: 0.289777
[Epoch 80] ogbg-moltoxcast: 0.642764 test loss: 0.337150
[Epoch 81; Iter    10/  229] train: loss: 0.0823967
[Epoch 81; Iter    40/  229] train: loss: 0.1167208
[Epoch 81; Iter    70/  229] train: loss: 0.1485948
[Epoch 81; Iter   100/  229] train: loss: 0.1156111
[Epoch 81; Iter   130/  229] train: loss: 0.1018055
[Epoch 81; Iter   160/  229] train: loss: 0.1305698
[Epoch 81; Iter   190/  229] train: loss: 0.1525220
[Epoch 81; Iter   220/  229] train: loss: 0.0870219
[Epoch 81] ogbg-moltoxcast: 0.687395 val loss: 0.291897
[Epoch 81] ogbg-moltoxcast: 0.645183 test loss: 0.335086
[Epoch 82; Iter    21/  229] train: loss: 0.0690525
[Epoch 82; Iter    51/  229] train: loss: 0.1125995
[Epoch 82; Iter    81/  229] train: loss: 0.1047241
[Epoch 82; Iter   111/  229] train: loss: 0.0943074
[Epoch 82; Iter   141/  229] train: loss: 0.1466359
[Epoch 82; Iter   171/  229] train: loss: 0.0985902
[Epoch 82; Iter   201/  229] train: loss: 0.0842552
[Epoch 82] ogbg-moltoxcast: 0.692051 val loss: 0.294638
[Epoch 82] ogbg-moltoxcast: 0.647274 test loss: 0.336726
[Epoch 83; Iter     2/  229] train: loss: 0.0866591
[Epoch 83; Iter    32/  229] train: loss: 0.1597120
[Epoch 83; Iter    62/  229] train: loss: 0.1369340
[Epoch 83; Iter    92/  229] train: loss: 0.1008021
[Epoch 83; Iter   122/  229] train: loss: 0.1015996
[Epoch 83; Iter   152/  229] train: loss: 0.0953169
[Epoch 83; Iter   182/  229] train: loss: 0.1340619
[Epoch 83; Iter   212/  229] train: loss: 0.0779268
[Epoch 83] ogbg-moltoxcast: 0.684853 val loss: 0.298130
[Epoch 83] ogbg-moltoxcast: 0.648691 test loss: 0.336162
[Epoch 84; Iter    13/  229] train: loss: 0.1701379
[Epoch 84; Iter    43/  229] train: loss: 0.1262040
[Epoch 84; Iter    73/  229] train: loss: 0.1547716
[Epoch 84; Iter   103/  229] train: loss: 0.0913639
[Epoch 84; Iter   133/  229] train: loss: 0.0939300
[Epoch 84; Iter   163/  229] train: loss: 0.0905022
[Epoch 84; Iter   193/  229] train: loss: 0.1347906
[Epoch 84; Iter   223/  229] train: loss: 0.1109010
[Epoch 84] ogbg-moltoxcast: 0.687704 val loss: 0.294572
[Epoch 84] ogbg-moltoxcast: 0.647248 test loss: 0.340461
[Epoch 85; Iter    24/  229] train: loss: 0.0695780
[Epoch 85; Iter    54/  229] train: loss: 0.1201597
[Epoch 85; Iter    84/  229] train: loss: 0.1119518
[Epoch 85; Iter   114/  229] train: loss: 0.0777109
[Epoch 85; Iter   144/  229] train: loss: 0.1071256
[Epoch 85; Iter   174/  229] train: loss: 0.1278259
[Epoch 85; Iter   204/  229] train: loss: 0.1199852
[Epoch 85] ogbg-moltoxcast: 0.688177 val loss: 0.296182
[Epoch 85] ogbg-moltoxcast: 0.645079 test loss: 0.337492
[Epoch 86; Iter     5/  229] train: loss: 0.0891127
[Epoch 86; Iter    35/  229] train: loss: 0.1557127
[Epoch 86; Iter    65/  229] train: loss: 0.1380587
[Epoch 86; Iter    95/  229] train: loss: 0.1364795
[Epoch 86; Iter   125/  229] train: loss: 0.0969979
[Epoch 86; Iter   155/  229] train: loss: 0.1365257
[Epoch 86; Iter   185/  229] train: loss: 0.1504824
[Epoch 86; Iter   215/  229] train: loss: 0.1304374
[Epoch 86] ogbg-moltoxcast: 0.681748 val loss: 0.299332
[Epoch 86] ogbg-moltoxcast: 0.644369 test loss: 0.341689
[Epoch 87; Iter    16/  229] train: loss: 0.1183642
[Epoch 87; Iter    46/  229] train: loss: 0.1306765
[Epoch 87; Iter    76/  229] train: loss: 0.0785999
[Epoch 87; Iter   106/  229] train: loss: 0.0947471
[Epoch 87; Iter   136/  229] train: loss: 0.0926337
[Epoch 87; Iter   166/  229] train: loss: 0.1138591
[Epoch 87; Iter   196/  229] train: loss: 0.1672359
[Epoch 87; Iter   226/  229] train: loss: 0.1273226
[Epoch 87] ogbg-moltoxcast: 0.690107 val loss: 0.292514
[Epoch 87] ogbg-moltoxcast: 0.648299 test loss: 0.335872
[Epoch 88; Iter    27/  229] train: loss: 0.1012713
[Epoch 88; Iter    57/  229] train: loss: 0.0749082
[Epoch 88; Iter    87/  229] train: loss: 0.0911085
[Epoch 88; Iter   117/  229] train: loss: 0.1009071
[Epoch 88; Iter   147/  229] train: loss: 0.1193060
[Epoch 88; Iter   177/  229] train: loss: 0.0944569
[Epoch 88; Iter   207/  229] train: loss: 0.0947781
[Epoch 88] ogbg-moltoxcast: 0.686929 val loss: 0.293779
[Epoch 88] ogbg-moltoxcast: 0.645100 test loss: 0.337052
[Epoch 89; Iter     8/  229] train: loss: 0.1144061
[Epoch 89; Iter    38/  229] train: loss: 0.1315397
[Epoch 89; Iter    68/  229] train: loss: 0.1012366
[Epoch 89; Iter    98/  229] train: loss: 0.1310714
[Epoch 89; Iter   128/  229] train: loss: 0.1526622
[Epoch 89; Iter   158/  229] train: loss: 0.1113812
[Epoch 89; Iter   188/  229] train: loss: 0.0726883
[Epoch 89; Iter   218/  229] train: loss: 0.1170431
[Epoch 89] ogbg-moltoxcast: 0.687259 val loss: 0.298783
[Epoch 89] ogbg-moltoxcast: 0.645987 test loss: 0.344091
[Epoch 90; Iter    19/  229] train: loss: 0.0906603
[Epoch 90; Iter    49/  229] train: loss: 0.1021091
[Epoch 90; Iter    79/  229] train: loss: 0.0847837
[Epoch 90; Iter   109/  229] train: loss: 0.1074415
[Epoch 90; Iter   139/  229] train: loss: 0.1547347
[Epoch 90; Iter   169/  229] train: loss: 0.1408494
[Epoch 90; Iter   199/  229] train: loss: 0.1350280
[Epoch 90; Iter   229/  229] train: loss: 0.1602160
[Epoch 90] ogbg-moltoxcast: 0.684595 val loss: 0.301992
[Epoch 90] ogbg-moltoxcast: 0.643245 test loss: 0.343284
[Epoch 91; Iter    30/  229] train: loss: 0.0852301
[Epoch 91; Iter    60/  229] train: loss: 0.1081162
[Epoch 91; Iter    90/  229] train: loss: 0.1133208
[Epoch 91; Iter   120/  229] train: loss: 0.1123175
[Epoch 91; Iter   150/  229] train: loss: 0.0816285
[Epoch 91; Iter   180/  229] train: loss: 0.1369155
[Epoch 91; Iter   210/  229] train: loss: 0.1257154
[Epoch 91] ogbg-moltoxcast: 0.684638 val loss: 0.298380
[Epoch 91] ogbg-moltoxcast: 0.644814 test loss: 0.343943
[Epoch 76; Iter    15/  229] train: loss: 0.1431218
[Epoch 76; Iter    45/  229] train: loss: 0.1219155
[Epoch 76; Iter    75/  229] train: loss: 0.1940156
[Epoch 76; Iter   105/  229] train: loss: 0.1086762
[Epoch 76; Iter   135/  229] train: loss: 0.0879166
[Epoch 76; Iter   165/  229] train: loss: 0.1405321
[Epoch 76; Iter   195/  229] train: loss: 0.0787435
[Epoch 76; Iter   225/  229] train: loss: 0.1119159
[Epoch 76] ogbg-moltoxcast: 0.670291 val loss: 0.355646
[Epoch 76] ogbg-moltoxcast: 0.638778 test loss: 0.455844
[Epoch 77; Iter    26/  229] train: loss: 0.1294748
[Epoch 77; Iter    56/  229] train: loss: 0.1217910
[Epoch 77; Iter    86/  229] train: loss: 0.0883779
[Epoch 77; Iter   116/  229] train: loss: 0.1379664
[Epoch 77; Iter   146/  229] train: loss: 0.1119017
[Epoch 77; Iter   176/  229] train: loss: 0.1239054
[Epoch 77; Iter   206/  229] train: loss: 0.1473782
[Epoch 77] ogbg-moltoxcast: 0.672205 val loss: 0.335531
[Epoch 77] ogbg-moltoxcast: 0.639862 test loss: 0.400312
[Epoch 78; Iter     7/  229] train: loss: 0.1387576
[Epoch 78; Iter    37/  229] train: loss: 0.1232806
[Epoch 78; Iter    67/  229] train: loss: 0.0907897
[Epoch 78; Iter    97/  229] train: loss: 0.1438641
[Epoch 78; Iter   127/  229] train: loss: 0.1160750
[Epoch 78; Iter   157/  229] train: loss: 0.1036228
[Epoch 78; Iter   187/  229] train: loss: 0.1057597
[Epoch 78; Iter   217/  229] train: loss: 0.1144104
[Epoch 78] ogbg-moltoxcast: 0.670737 val loss: 0.346582
[Epoch 78] ogbg-moltoxcast: 0.637226 test loss: 0.423239
[Epoch 79; Iter    18/  229] train: loss: 0.0902960
[Epoch 79; Iter    48/  229] train: loss: 0.1223294
[Epoch 79; Iter    78/  229] train: loss: 0.0951868
[Epoch 79; Iter   108/  229] train: loss: 0.1286498
[Epoch 79; Iter   138/  229] train: loss: 0.1079637
[Epoch 79; Iter   168/  229] train: loss: 0.0784882
[Epoch 79; Iter   198/  229] train: loss: 0.0706963
[Epoch 79; Iter   228/  229] train: loss: 0.1516055
[Epoch 79] ogbg-moltoxcast: 0.667236 val loss: 0.467576
[Epoch 79] ogbg-moltoxcast: 0.638258 test loss: 0.590581
[Epoch 80; Iter    29/  229] train: loss: 0.1304743
[Epoch 80; Iter    59/  229] train: loss: 0.1065307
[Epoch 80; Iter    89/  229] train: loss: 0.0981896
[Epoch 80; Iter   119/  229] train: loss: 0.1383054
[Epoch 80; Iter   149/  229] train: loss: 0.1351980
[Epoch 80; Iter   179/  229] train: loss: 0.2238913
[Epoch 80; Iter   209/  229] train: loss: 0.1112925
[Epoch 80] ogbg-moltoxcast: 0.670074 val loss: 0.371359
[Epoch 80] ogbg-moltoxcast: 0.640196 test loss: 0.435497
[Epoch 81; Iter    10/  229] train: loss: 0.0871756
[Epoch 81; Iter    40/  229] train: loss: 0.1171822
[Epoch 81; Iter    70/  229] train: loss: 0.1535946
[Epoch 81; Iter   100/  229] train: loss: 0.1162577
[Epoch 81; Iter   130/  229] train: loss: 0.1145287
[Epoch 81; Iter   160/  229] train: loss: 0.1321689
[Epoch 81; Iter   190/  229] train: loss: 0.1583235
[Epoch 81; Iter   220/  229] train: loss: 0.0852800
[Epoch 81] ogbg-moltoxcast: 0.668404 val loss: 0.325994
[Epoch 81] ogbg-moltoxcast: 0.640673 test loss: 0.380280
[Epoch 82; Iter    21/  229] train: loss: 0.0643593
[Epoch 82; Iter    51/  229] train: loss: 0.1119402
[Epoch 82; Iter    81/  229] train: loss: 0.1084334
[Epoch 82; Iter   111/  229] train: loss: 0.0988275
[Epoch 82; Iter   141/  229] train: loss: 0.1391303
[Epoch 82; Iter   171/  229] train: loss: 0.0966173
[Epoch 82; Iter   201/  229] train: loss: 0.0914973
[Epoch 82] ogbg-moltoxcast: 0.659719 val loss: 0.327519
[Epoch 82] ogbg-moltoxcast: 0.640161 test loss: 0.383937
[Epoch 83; Iter     2/  229] train: loss: 0.0930620
[Epoch 83; Iter    32/  229] train: loss: 0.1530933
[Epoch 83; Iter    62/  229] train: loss: 0.1382524
[Epoch 83; Iter    92/  229] train: loss: 0.0970890
[Epoch 83; Iter   122/  229] train: loss: 0.1022949
[Epoch 83; Iter   152/  229] train: loss: 0.0911385
[Epoch 83; Iter   182/  229] train: loss: 0.1367923
[Epoch 83; Iter   212/  229] train: loss: 0.0809029
[Epoch 83] ogbg-moltoxcast: 0.669299 val loss: 0.354842
[Epoch 83] ogbg-moltoxcast: 0.644472 test loss: 0.418929
[Epoch 84; Iter    13/  229] train: loss: 0.1767385
[Epoch 84; Iter    43/  229] train: loss: 0.1308040
[Epoch 84; Iter    73/  229] train: loss: 0.1603982
[Epoch 84; Iter   103/  229] train: loss: 0.0972825
[Epoch 84; Iter   133/  229] train: loss: 0.0984932
[Epoch 84; Iter   163/  229] train: loss: 0.0921065
[Epoch 84; Iter   193/  229] train: loss: 0.1322450
[Epoch 84; Iter   223/  229] train: loss: 0.1062440
[Epoch 84] ogbg-moltoxcast: 0.667426 val loss: 0.318876
[Epoch 84] ogbg-moltoxcast: 0.641322 test loss: 0.374155
[Epoch 85; Iter    24/  229] train: loss: 0.0704315
[Epoch 85; Iter    54/  229] train: loss: 0.1230253
[Epoch 85; Iter    84/  229] train: loss: 0.1201366
[Epoch 85; Iter   114/  229] train: loss: 0.0827918
[Epoch 85; Iter   144/  229] train: loss: 0.0992355
[Epoch 85; Iter   174/  229] train: loss: 0.1308087
[Epoch 85; Iter   204/  229] train: loss: 0.1199038
[Epoch 85] ogbg-moltoxcast: 0.668272 val loss: 0.316724
[Epoch 85] ogbg-moltoxcast: 0.641862 test loss: 0.370358
[Epoch 86; Iter     5/  229] train: loss: 0.0894754
[Epoch 86; Iter    35/  229] train: loss: 0.1565902
[Epoch 86; Iter    65/  229] train: loss: 0.1427043
[Epoch 86; Iter    95/  229] train: loss: 0.1366768
[Epoch 86; Iter   125/  229] train: loss: 0.0964506
[Epoch 86; Iter   155/  229] train: loss: 0.1378590
[Epoch 86; Iter   185/  229] train: loss: 0.1580297
[Epoch 86; Iter   215/  229] train: loss: 0.1359335
[Epoch 86] ogbg-moltoxcast: 0.659745 val loss: 0.404637
[Epoch 86] ogbg-moltoxcast: 0.641672 test loss: 0.489684
[Epoch 87; Iter    16/  229] train: loss: 0.1219852
[Epoch 87; Iter    46/  229] train: loss: 0.1401376
[Epoch 87; Iter    76/  229] train: loss: 0.0739459
[Epoch 87; Iter   106/  229] train: loss: 0.0973006
[Epoch 87; Iter   136/  229] train: loss: 0.0928381
[Epoch 87; Iter   166/  229] train: loss: 0.1116830
[Epoch 87; Iter   196/  229] train: loss: 0.1595865
[Epoch 87; Iter   226/  229] train: loss: 0.1328301
[Epoch 87] ogbg-moltoxcast: 0.663192 val loss: 0.317447
[Epoch 87] ogbg-moltoxcast: 0.637013 test loss: 0.367528
[Epoch 88; Iter    27/  229] train: loss: 0.1015547
[Epoch 88; Iter    57/  229] train: loss: 0.0770149
[Epoch 88; Iter    87/  229] train: loss: 0.0902044
[Epoch 88; Iter   117/  229] train: loss: 0.1074001
[Epoch 88; Iter   147/  229] train: loss: 0.1226162
[Epoch 88; Iter   177/  229] train: loss: 0.0952118
[Epoch 88; Iter   207/  229] train: loss: 0.0964647
[Epoch 88] ogbg-moltoxcast: 0.665267 val loss: 0.363079
[Epoch 88] ogbg-moltoxcast: 0.642105 test loss: 0.407549
[Epoch 89; Iter     8/  229] train: loss: 0.1224279
[Epoch 89; Iter    38/  229] train: loss: 0.1313919
[Epoch 89; Iter    68/  229] train: loss: 0.1063336
[Epoch 89; Iter    98/  229] train: loss: 0.1311922
[Epoch 89; Iter   128/  229] train: loss: 0.1530832
[Epoch 89; Iter   158/  229] train: loss: 0.1152607
[Epoch 89; Iter   188/  229] train: loss: 0.0717295
[Epoch 89; Iter   218/  229] train: loss: 0.1205377
[Epoch 89] ogbg-moltoxcast: 0.664690 val loss: 0.342411
[Epoch 89] ogbg-moltoxcast: 0.644015 test loss: 0.390781
[Epoch 90; Iter    19/  229] train: loss: 0.0961452
[Epoch 90; Iter    49/  229] train: loss: 0.1031355
[Epoch 90; Iter    79/  229] train: loss: 0.0852440
[Epoch 90; Iter   109/  229] train: loss: 0.1065818
[Epoch 90; Iter   139/  229] train: loss: 0.1544781
[Epoch 90; Iter   169/  229] train: loss: 0.1400723
[Epoch 90; Iter   199/  229] train: loss: 0.1409861
[Epoch 90; Iter   229/  229] train: loss: 0.1554734
[Epoch 90] ogbg-moltoxcast: 0.657456 val loss: 0.331298
[Epoch 90] ogbg-moltoxcast: 0.634851 test loss: 0.385907
[Epoch 91; Iter    30/  229] train: loss: 0.0839176
[Epoch 91; Iter    60/  229] train: loss: 0.1048138
[Epoch 91; Iter    90/  229] train: loss: 0.1119678
[Epoch 91; Iter   120/  229] train: loss: 0.1172011
[Epoch 91; Iter   150/  229] train: loss: 0.0869036
[Epoch 91; Iter   180/  229] train: loss: 0.1397754
[Epoch 91; Iter   210/  229] train: loss: 0.1332883
[Epoch 91] ogbg-moltoxcast: 0.657073 val loss: 0.323081
[Epoch 91] ogbg-moltoxcast: 0.636871 test loss: 0.376237
[Epoch 60; Iter    19/  229] train: loss: 0.1022321
[Epoch 60; Iter    49/  229] train: loss: 0.1375059
[Epoch 60; Iter    79/  229] train: loss: 0.1597571
[Epoch 60; Iter   109/  229] train: loss: 0.1215078
[Epoch 60; Iter   139/  229] train: loss: 0.1484925
[Epoch 60; Iter   169/  229] train: loss: 0.1075711
[Epoch 60; Iter   199/  229] train: loss: 0.1652367
[Epoch 60; Iter   229/  229] train: loss: 0.1453305
[Epoch 60] ogbg-moltoxcast: 0.689111 val loss: 0.275649
[Epoch 60] ogbg-moltoxcast: 0.656092 test loss: 0.304127
[Epoch 61; Iter    30/  229] train: loss: 0.1494474
[Epoch 61; Iter    60/  229] train: loss: 0.1867144
[Epoch 61; Iter    90/  229] train: loss: 0.1810800
[Epoch 61; Iter   120/  229] train: loss: 0.1656921
[Epoch 61; Iter   150/  229] train: loss: 0.1697642
[Epoch 61; Iter   180/  229] train: loss: 0.1683509
[Epoch 61; Iter   210/  229] train: loss: 0.0972890
[Epoch 61] ogbg-moltoxcast: 0.684176 val loss: 0.256869
[Epoch 61] ogbg-moltoxcast: 0.659899 test loss: 0.312511
[Epoch 62; Iter    11/  229] train: loss: 0.0891549
[Epoch 62; Iter    41/  229] train: loss: 0.2130166
[Epoch 62; Iter    71/  229] train: loss: 0.1489145
[Epoch 62; Iter   101/  229] train: loss: 0.1383837
[Epoch 62; Iter   131/  229] train: loss: 0.1669133
[Epoch 62; Iter   161/  229] train: loss: 0.1307798
[Epoch 62; Iter   191/  229] train: loss: 0.1370053
[Epoch 62; Iter   221/  229] train: loss: 0.1563865
[Epoch 62] ogbg-moltoxcast: 0.678129 val loss: 0.260871
[Epoch 62] ogbg-moltoxcast: 0.654690 test loss: 0.311735
[Epoch 63; Iter    22/  229] train: loss: 0.1417505
[Epoch 63; Iter    52/  229] train: loss: 0.0967543
[Epoch 63; Iter    82/  229] train: loss: 0.1019763
[Epoch 63; Iter   112/  229] train: loss: 0.1032220
[Epoch 63; Iter   142/  229] train: loss: 0.2068200
[Epoch 63; Iter   172/  229] train: loss: 0.1779194
[Epoch 63; Iter   202/  229] train: loss: 0.1143710
[Epoch 63] ogbg-moltoxcast: 0.682561 val loss: 0.266277
[Epoch 63] ogbg-moltoxcast: 0.655594 test loss: 0.319006
[Epoch 64; Iter     3/  229] train: loss: 0.0879565
[Epoch 64; Iter    33/  229] train: loss: 0.1357278
[Epoch 64; Iter    63/  229] train: loss: 0.1453799
[Epoch 64; Iter    93/  229] train: loss: 0.1308145
[Epoch 64; Iter   123/  229] train: loss: 0.1214801
[Epoch 64; Iter   153/  229] train: loss: 0.1117688
[Epoch 64; Iter   183/  229] train: loss: 0.1122888
[Epoch 64; Iter   213/  229] train: loss: 0.1529602
[Epoch 64] ogbg-moltoxcast: 0.680007 val loss: 0.256487
[Epoch 64] ogbg-moltoxcast: 0.657541 test loss: 0.311226
[Epoch 65; Iter    14/  229] train: loss: 0.1591106
[Epoch 65; Iter    44/  229] train: loss: 0.1518547
[Epoch 65; Iter    74/  229] train: loss: 0.1329161
[Epoch 65; Iter   104/  229] train: loss: 0.1571363
[Epoch 65; Iter   134/  229] train: loss: 0.1352583
[Epoch 65; Iter   164/  229] train: loss: 0.1514453
[Epoch 65; Iter   194/  229] train: loss: 0.1070005
[Epoch 65; Iter   224/  229] train: loss: 0.1381272
[Epoch 65] ogbg-moltoxcast: 0.684852 val loss: 0.254547
[Epoch 65] ogbg-moltoxcast: 0.654198 test loss: 0.310216
[Epoch 66; Iter    25/  229] train: loss: 0.1281703
[Epoch 66; Iter    55/  229] train: loss: 0.1739730
[Epoch 66; Iter    85/  229] train: loss: 0.1421374
[Epoch 66; Iter   115/  229] train: loss: 0.1088876
[Epoch 66; Iter   145/  229] train: loss: 0.1072360
[Epoch 66; Iter   175/  229] train: loss: 0.1399460
[Epoch 66; Iter   205/  229] train: loss: 0.1124524
[Epoch 66] ogbg-moltoxcast: 0.685684 val loss: 0.259166
[Epoch 66] ogbg-moltoxcast: 0.656508 test loss: 0.313346
[Epoch 67; Iter     6/  229] train: loss: 0.1290088
[Epoch 67; Iter    36/  229] train: loss: 0.1683424
[Epoch 67; Iter    66/  229] train: loss: 0.1048797
[Epoch 67; Iter    96/  229] train: loss: 0.1675260
[Epoch 67; Iter   126/  229] train: loss: 0.1026081
[Epoch 67; Iter   156/  229] train: loss: 0.1077759
[Epoch 67; Iter   186/  229] train: loss: 0.1150608
[Epoch 67; Iter   216/  229] train: loss: 0.1025967
[Epoch 67] ogbg-moltoxcast: 0.678974 val loss: 0.261885
[Epoch 67] ogbg-moltoxcast: 0.655246 test loss: 0.316366
[Epoch 68; Iter    17/  229] train: loss: 0.1691435
[Epoch 68; Iter    47/  229] train: loss: 0.1243700
[Epoch 68; Iter    77/  229] train: loss: 0.1213830
[Epoch 68; Iter   107/  229] train: loss: 0.1642774
[Epoch 68; Iter   137/  229] train: loss: 0.1151263
[Epoch 68; Iter   167/  229] train: loss: 0.1108818
[Epoch 68; Iter   197/  229] train: loss: 0.1487078
[Epoch 68; Iter   227/  229] train: loss: 0.1477743
[Epoch 68] ogbg-moltoxcast: 0.688982 val loss: 0.259294
[Epoch 68] ogbg-moltoxcast: 0.655333 test loss: 0.314659
[Epoch 69; Iter    28/  229] train: loss: 0.1424959
[Epoch 69; Iter    58/  229] train: loss: 0.1054494
[Epoch 69; Iter    88/  229] train: loss: 0.1151464
[Epoch 69; Iter   118/  229] train: loss: 0.1195716
[Epoch 69; Iter   148/  229] train: loss: 0.1025848
[Epoch 69; Iter   178/  229] train: loss: 0.1887815
[Epoch 69; Iter   208/  229] train: loss: 0.1244397
[Epoch 69] ogbg-moltoxcast: 0.685582 val loss: 0.260519
[Epoch 69] ogbg-moltoxcast: 0.655582 test loss: 0.316679
[Epoch 70; Iter     9/  229] train: loss: 0.1082053
[Epoch 70; Iter    39/  229] train: loss: 0.1419025
[Epoch 70; Iter    69/  229] train: loss: 0.1384309
[Epoch 70; Iter    99/  229] train: loss: 0.1718381
[Epoch 70; Iter   129/  229] train: loss: 0.1158808
[Epoch 70; Iter   159/  229] train: loss: 0.1510746
[Epoch 70; Iter   189/  229] train: loss: 0.1767546
[Epoch 70; Iter   219/  229] train: loss: 0.1516947
[Epoch 70] ogbg-moltoxcast: 0.683285 val loss: 0.258649
[Epoch 70] ogbg-moltoxcast: 0.655405 test loss: 0.314692
[Epoch 71; Iter    20/  229] train: loss: 0.1088294
[Epoch 71; Iter    50/  229] train: loss: 0.1031811
[Epoch 71; Iter    80/  229] train: loss: 0.1451498
[Epoch 71; Iter   110/  229] train: loss: 0.1220371
[Epoch 71; Iter   140/  229] train: loss: 0.1034518
[Epoch 71; Iter   170/  229] train: loss: 0.1376594
[Epoch 71; Iter   200/  229] train: loss: 0.1267135
[Epoch 71] ogbg-moltoxcast: 0.682516 val loss: 0.259943
[Epoch 71] ogbg-moltoxcast: 0.655701 test loss: 0.315653
[Epoch 72; Iter     1/  229] train: loss: 0.1026868
[Epoch 72; Iter    31/  229] train: loss: 0.1003955
[Epoch 72; Iter    61/  229] train: loss: 0.1260341
[Epoch 72; Iter    91/  229] train: loss: 0.1389763
[Epoch 72; Iter   121/  229] train: loss: 0.1223308
[Epoch 72; Iter   151/  229] train: loss: 0.1504363
[Epoch 72; Iter   181/  229] train: loss: 0.1130560
[Epoch 72; Iter   211/  229] train: loss: 0.1322313
[Epoch 72] ogbg-moltoxcast: 0.688132 val loss: 0.260360
[Epoch 72] ogbg-moltoxcast: 0.659121 test loss: 0.316767
[Epoch 73; Iter    12/  229] train: loss: 0.1703646
[Epoch 73; Iter    42/  229] train: loss: 0.1124118
[Epoch 73; Iter    72/  229] train: loss: 0.0964869
[Epoch 73; Iter   102/  229] train: loss: 0.1426025
[Epoch 73; Iter   132/  229] train: loss: 0.1786963
[Epoch 73; Iter   162/  229] train: loss: 0.1357175
[Epoch 73; Iter   192/  229] train: loss: 0.1277319
[Epoch 73; Iter   222/  229] train: loss: 0.1380274
[Epoch 73] ogbg-moltoxcast: 0.685735 val loss: 0.260246
[Epoch 73] ogbg-moltoxcast: 0.656402 test loss: 0.316808
[Epoch 74; Iter    23/  229] train: loss: 0.0869801
[Epoch 74; Iter    53/  229] train: loss: 0.1854784
[Epoch 74; Iter    83/  229] train: loss: 0.0936158
[Epoch 74; Iter   113/  229] train: loss: 0.1537640
[Epoch 74; Iter   143/  229] train: loss: 0.1822363
[Epoch 74; Iter   173/  229] train: loss: 0.0861708
[Epoch 74; Iter   203/  229] train: loss: 0.1125527
[Epoch 74] ogbg-moltoxcast: 0.688582 val loss: 0.261269
[Epoch 74] ogbg-moltoxcast: 0.658463 test loss: 0.316538
[Epoch 75; Iter     4/  229] train: loss: 0.0946210
[Epoch 75; Iter    34/  229] train: loss: 0.1537311
[Epoch 75; Iter    64/  229] train: loss: 0.0990167
[Epoch 75; Iter    94/  229] train: loss: 0.1516079
[Epoch 75; Iter   124/  229] train: loss: 0.1555226
[Epoch 75; Iter   154/  229] train: loss: 0.1055367
[Epoch 75; Iter   184/  229] train: loss: 0.1424913
[Epoch 75; Iter   214/  229] train: loss: 0.1140783
[Epoch 75] ogbg-moltoxcast: 0.686408 val loss: 0.261751
[Epoch 75] ogbg-moltoxcast: 0.653681 test loss: 0.318163
[Epoch 76; Iter    15/  229] train: loss: 0.1116443
[Epoch 76; Iter    45/  229] train: loss: 0.1223347
[Epoch 76; Iter    75/  229] train: loss: 0.1347648
[Epoch 76; Iter   105/  229] train: loss: 0.1291305
[Epoch 76; Iter   135/  229] train: loss: 0.0941104
[Epoch 76; Iter   165/  229] train: loss: 0.1224850
[Epoch 76; Iter   195/  229] train: loss: 0.1090511
[Epoch 76; Iter   225/  229] train: loss: 0.1345971
[Epoch 76] ogbg-moltoxcast: 0.667355 val loss: 0.313401
[Epoch 76] ogbg-moltoxcast: 0.649139 test loss: 0.350562
[Epoch 77; Iter    26/  229] train: loss: 0.1080524
[Epoch 77; Iter    56/  229] train: loss: 0.0986320
[Epoch 77; Iter    86/  229] train: loss: 0.1584940
[Epoch 77; Iter   116/  229] train: loss: 0.1201781
[Epoch 77; Iter   146/  229] train: loss: 0.0997448
[Epoch 77; Iter   176/  229] train: loss: 0.1295346
[Epoch 77; Iter   206/  229] train: loss: 0.1314254
[Epoch 77] ogbg-moltoxcast: 0.659420 val loss: 0.321446
[Epoch 77] ogbg-moltoxcast: 0.645130 test loss: 0.357365
[Epoch 78; Iter     7/  229] train: loss: 0.1201305
[Epoch 78; Iter    37/  229] train: loss: 0.1030215
[Epoch 78; Iter    67/  229] train: loss: 0.0977006
[Epoch 78; Iter    97/  229] train: loss: 0.1130219
[Epoch 78; Iter   127/  229] train: loss: 0.1557530
[Epoch 78; Iter   157/  229] train: loss: 0.0897714
[Epoch 78; Iter   187/  229] train: loss: 0.1324257
[Epoch 78; Iter   217/  229] train: loss: 0.1030805
[Epoch 78] ogbg-moltoxcast: 0.667070 val loss: 0.313724
[Epoch 78] ogbg-moltoxcast: 0.649889 test loss: 0.354468
[Epoch 79; Iter    18/  229] train: loss: 0.1612017
[Epoch 79; Iter    48/  229] train: loss: 0.1414361
[Epoch 79; Iter    78/  229] train: loss: 0.1379008
[Epoch 79; Iter   108/  229] train: loss: 0.1250589
[Epoch 79; Iter   138/  229] train: loss: 0.1409417
[Epoch 79; Iter   168/  229] train: loss: 0.1343510
[Epoch 79; Iter   198/  229] train: loss: 0.0834166
[Epoch 79; Iter   228/  229] train: loss: 0.1348866
[Epoch 79] ogbg-moltoxcast: 0.667227 val loss: 0.315712
[Epoch 79] ogbg-moltoxcast: 0.652192 test loss: 0.357417
[Epoch 80; Iter    29/  229] train: loss: 0.1080906
[Epoch 80; Iter    59/  229] train: loss: 0.1105630
[Epoch 80; Iter    89/  229] train: loss: 0.1224959
[Epoch 80; Iter   119/  229] train: loss: 0.1084838
[Epoch 80; Iter   149/  229] train: loss: 0.1132356
[Epoch 80; Iter   179/  229] train: loss: 0.1103962
[Epoch 80; Iter   209/  229] train: loss: 0.1217154
[Epoch 80] ogbg-moltoxcast: 0.667193 val loss: 0.314192
[Epoch 80] ogbg-moltoxcast: 0.651453 test loss: 0.354699
[Epoch 81; Iter    10/  229] train: loss: 0.1159326
[Epoch 81; Iter    40/  229] train: loss: 0.1272635
[Epoch 81; Iter    70/  229] train: loss: 0.1200643
[Epoch 81; Iter   100/  229] train: loss: 0.1279639
[Epoch 81; Iter   130/  229] train: loss: 0.1421695
[Epoch 81; Iter   160/  229] train: loss: 0.1334779
[Epoch 81; Iter   190/  229] train: loss: 0.1191061
[Epoch 81; Iter   220/  229] train: loss: 0.0971847
[Epoch 81] ogbg-moltoxcast: 0.667231 val loss: 0.311207
[Epoch 81] ogbg-moltoxcast: 0.648397 test loss: 0.357302
[Epoch 82; Iter    21/  229] train: loss: 0.0859669
[Epoch 82; Iter    51/  229] train: loss: 0.1096696
[Epoch 82; Iter    81/  229] train: loss: 0.1231470
[Epoch 82; Iter   111/  229] train: loss: 0.0948311
[Epoch 82; Iter   141/  229] train: loss: 0.0928618
[Epoch 82; Iter   171/  229] train: loss: 0.1122910
[Epoch 82; Iter   201/  229] train: loss: 0.1136190
[Epoch 82] ogbg-moltoxcast: 0.672248 val loss: 0.316313
[Epoch 82] ogbg-moltoxcast: 0.651856 test loss: 0.361208
[Epoch 83; Iter     2/  229] train: loss: 0.1612670
[Epoch 83; Iter    32/  229] train: loss: 0.0987065
[Epoch 83; Iter    62/  229] train: loss: 0.1052238
[Epoch 83; Iter    92/  229] train: loss: 0.1205772
[Epoch 83; Iter   122/  229] train: loss: 0.1092158
[Epoch 83; Iter   152/  229] train: loss: 0.0872112
[Epoch 83; Iter   182/  229] train: loss: 0.0737846
[Epoch 83; Iter   212/  229] train: loss: 0.1492370
[Epoch 83] ogbg-moltoxcast: 0.667244 val loss: 0.317643
[Epoch 83] ogbg-moltoxcast: 0.644786 test loss: 0.357163
[Epoch 84; Iter    13/  229] train: loss: 0.1040716
[Epoch 84; Iter    43/  229] train: loss: 0.1072690
[Epoch 84; Iter    73/  229] train: loss: 0.0881183
[Epoch 84; Iter   103/  229] train: loss: 0.0995052
[Epoch 84; Iter   133/  229] train: loss: 0.0753468
[Epoch 84; Iter   163/  229] train: loss: 0.1023021
[Epoch 84; Iter   193/  229] train: loss: 0.1336714
[Epoch 84; Iter   223/  229] train: loss: 0.0932115
[Epoch 84] ogbg-moltoxcast: 0.668556 val loss: 0.318292
[Epoch 84] ogbg-moltoxcast: 0.650840 test loss: 0.363220
[Epoch 85; Iter    24/  229] train: loss: 0.1271862
[Epoch 85; Iter    54/  229] train: loss: 0.1056442
[Epoch 85; Iter    84/  229] train: loss: 0.1086396
[Epoch 85; Iter   114/  229] train: loss: 0.0885698
[Epoch 85; Iter   144/  229] train: loss: 0.1019157
[Epoch 85; Iter   174/  229] train: loss: 0.1597107
[Epoch 85; Iter   204/  229] train: loss: 0.1331658
[Epoch 85] ogbg-moltoxcast: 0.665679 val loss: 0.310332
[Epoch 85] ogbg-moltoxcast: 0.646876 test loss: 0.353808
[Epoch 86; Iter     5/  229] train: loss: 0.1006984
[Epoch 86; Iter    35/  229] train: loss: 0.1140680
[Epoch 86; Iter    65/  229] train: loss: 0.0815807
[Epoch 86; Iter    95/  229] train: loss: 0.1301388
[Epoch 86; Iter   125/  229] train: loss: 0.0683857
[Epoch 86; Iter   155/  229] train: loss: 0.1115744
[Epoch 86; Iter   185/  229] train: loss: 0.1081293
[Epoch 86; Iter   215/  229] train: loss: 0.1492548
[Epoch 86] ogbg-moltoxcast: 0.665148 val loss: 0.314784
[Epoch 86] ogbg-moltoxcast: 0.643219 test loss: 0.359316
[Epoch 87; Iter    16/  229] train: loss: 0.0773073
[Epoch 87; Iter    46/  229] train: loss: 0.0870604
[Epoch 87; Iter    76/  229] train: loss: 0.1378367
[Epoch 87; Iter   106/  229] train: loss: 0.1139255
[Epoch 87; Iter   136/  229] train: loss: 0.1672639
[Epoch 87; Iter   166/  229] train: loss: 0.0974565
[Epoch 87; Iter   196/  229] train: loss: 0.1114206
[Epoch 87; Iter   226/  229] train: loss: 0.0937268
[Epoch 87] ogbg-moltoxcast: 0.664198 val loss: 0.323647
[Epoch 87] ogbg-moltoxcast: 0.645003 test loss: 0.363393
[Epoch 88; Iter    27/  229] train: loss: 0.1137767
[Epoch 88; Iter    57/  229] train: loss: 0.1041369
[Epoch 88; Iter    87/  229] train: loss: 0.1087826
[Epoch 88; Iter   117/  229] train: loss: 0.1397428
[Epoch 88; Iter   147/  229] train: loss: 0.1119388
[Epoch 88; Iter   177/  229] train: loss: 0.1161364
[Epoch 88; Iter   207/  229] train: loss: 0.0900728
[Epoch 88] ogbg-moltoxcast: 0.669502 val loss: 0.328791
[Epoch 88] ogbg-moltoxcast: 0.645246 test loss: 0.364962
[Epoch 89; Iter     8/  229] train: loss: 0.1200491
[Epoch 89; Iter    38/  229] train: loss: 0.1401622
[Epoch 89; Iter    68/  229] train: loss: 0.1359467
[Epoch 89; Iter    98/  229] train: loss: 0.1032932
[Epoch 89; Iter   128/  229] train: loss: 0.0996319
[Epoch 89; Iter   158/  229] train: loss: 0.1044866
[Epoch 89; Iter   188/  229] train: loss: 0.0876689
[Epoch 89; Iter   218/  229] train: loss: 0.1311570
[Epoch 89] ogbg-moltoxcast: 0.664080 val loss: 0.327731
[Epoch 89] ogbg-moltoxcast: 0.641365 test loss: 0.378572
[Epoch 90; Iter    19/  229] train: loss: 0.1134024
[Epoch 90; Iter    49/  229] train: loss: 0.1070844
[Epoch 90; Iter    79/  229] train: loss: 0.0952960
[Epoch 90; Iter   109/  229] train: loss: 0.0715784
[Epoch 90; Iter   139/  229] train: loss: 0.0912504
[Epoch 90; Iter   169/  229] train: loss: 0.0867618
[Epoch 90; Iter   199/  229] train: loss: 0.1628861
[Epoch 90; Iter   229/  229] train: loss: 0.1166965
[Epoch 90] ogbg-moltoxcast: 0.663608 val loss: 0.314347
[Epoch 90] ogbg-moltoxcast: 0.640702 test loss: 0.362451
[Epoch 91; Iter    30/  229] train: loss: 0.1028147
[Epoch 91; Iter    60/  229] train: loss: 0.1281811
[Epoch 91; Iter    90/  229] train: loss: 0.1376434
[Epoch 91; Iter   120/  229] train: loss: 0.0998110
[Epoch 91; Iter   150/  229] train: loss: 0.1258360
[Epoch 91; Iter   180/  229] train: loss: 0.1621338
[Epoch 91; Iter   210/  229] train: loss: 0.1555842
[Epoch 91] ogbg-moltoxcast: 0.666322 val loss: 0.315414
[Epoch 91] ogbg-moltoxcast: 0.643514 test loss: 0.363029
[Epoch 76; Iter    15/  229] train: loss: 0.1175063
[Epoch 76; Iter    45/  229] train: loss: 0.1317662
[Epoch 76; Iter    75/  229] train: loss: 0.1479698
[Epoch 76; Iter   105/  229] train: loss: 0.0869190
[Epoch 76; Iter   135/  229] train: loss: 0.2028089
[Epoch 76; Iter   165/  229] train: loss: 0.1085529
[Epoch 76; Iter   195/  229] train: loss: 0.1311128
[Epoch 76; Iter   225/  229] train: loss: 0.1018560
[Epoch 76] ogbg-moltoxcast: 0.656414 val loss: 0.332531
[Epoch 76] ogbg-moltoxcast: 0.645283 test loss: 0.354294
[Epoch 77; Iter    26/  229] train: loss: 0.1493564
[Epoch 77; Iter    56/  229] train: loss: 0.0993799
[Epoch 77; Iter    86/  229] train: loss: 0.2108898
[Epoch 77; Iter   116/  229] train: loss: 0.1668949
[Epoch 77; Iter   146/  229] train: loss: 0.1375811
[Epoch 77; Iter   176/  229] train: loss: 0.1570560
[Epoch 77; Iter   206/  229] train: loss: 0.1482554
[Epoch 77] ogbg-moltoxcast: 0.654392 val loss: 0.311767
[Epoch 77] ogbg-moltoxcast: 0.644596 test loss: 0.345788
[Epoch 78; Iter     7/  229] train: loss: 0.1410377
[Epoch 78; Iter    37/  229] train: loss: 0.1368038
[Epoch 78; Iter    67/  229] train: loss: 0.1283186
[Epoch 78; Iter    97/  229] train: loss: 0.1000236
[Epoch 78; Iter   127/  229] train: loss: 0.1241754
[Epoch 78; Iter   157/  229] train: loss: 0.1210280
[Epoch 78; Iter   187/  229] train: loss: 0.1534097
[Epoch 78; Iter   217/  229] train: loss: 0.1506245
[Epoch 78] ogbg-moltoxcast: 0.659415 val loss: 0.328366
[Epoch 78] ogbg-moltoxcast: 0.651646 test loss: 0.349255
[Epoch 79; Iter    18/  229] train: loss: 0.1120373
[Epoch 79; Iter    48/  229] train: loss: 0.1466110
[Epoch 79; Iter    78/  229] train: loss: 0.1484168
[Epoch 79; Iter   108/  229] train: loss: 0.1602565
[Epoch 79; Iter   138/  229] train: loss: 0.1695110
[Epoch 79; Iter   168/  229] train: loss: 0.1706847
[Epoch 79; Iter   198/  229] train: loss: 0.1451598
[Epoch 79; Iter   228/  229] train: loss: 0.1652618
[Epoch 79] ogbg-moltoxcast: 0.662983 val loss: 0.329804
[Epoch 79] ogbg-moltoxcast: 0.649549 test loss: 0.347139
[Epoch 80; Iter    29/  229] train: loss: 0.1425897
[Epoch 80; Iter    59/  229] train: loss: 0.1225005
[Epoch 80; Iter    89/  229] train: loss: 0.1611956
[Epoch 80; Iter   119/  229] train: loss: 0.1252683
[Epoch 80; Iter   149/  229] train: loss: 0.1356538
[Epoch 80; Iter   179/  229] train: loss: 0.1439458
[Epoch 80; Iter   209/  229] train: loss: 0.1436125
[Epoch 80] ogbg-moltoxcast: 0.658602 val loss: 0.371151
[Epoch 80] ogbg-moltoxcast: 0.647631 test loss: 0.354765
[Epoch 81; Iter    10/  229] train: loss: 0.1149968
[Epoch 81; Iter    40/  229] train: loss: 0.1544815
[Epoch 81; Iter    70/  229] train: loss: 0.1451043
[Epoch 81; Iter   100/  229] train: loss: 0.0834161
[Epoch 81; Iter   130/  229] train: loss: 0.0965064
[Epoch 81; Iter   160/  229] train: loss: 0.1485347
[Epoch 81; Iter   190/  229] train: loss: 0.1328639
[Epoch 81; Iter   220/  229] train: loss: 0.1376640
[Epoch 81] ogbg-moltoxcast: 0.655308 val loss: 0.335212
[Epoch 81] ogbg-moltoxcast: 0.647644 test loss: 0.350449
[Epoch 82; Iter    21/  229] train: loss: 0.1556044
[Epoch 82; Iter    51/  229] train: loss: 0.1419383
[Epoch 82; Iter    81/  229] train: loss: 0.1009091
[Epoch 82; Iter   111/  229] train: loss: 0.1135273
[Epoch 82; Iter   141/  229] train: loss: 0.1524636
[Epoch 82; Iter   171/  229] train: loss: 0.1075342
[Epoch 82; Iter   201/  229] train: loss: 0.1487116
[Epoch 82] ogbg-moltoxcast: 0.659882 val loss: 0.335567
[Epoch 82] ogbg-moltoxcast: 0.648858 test loss: 0.389318
[Epoch 83; Iter     2/  229] train: loss: 0.1147450
[Epoch 83; Iter    32/  229] train: loss: 0.1162747
[Epoch 83; Iter    62/  229] train: loss: 0.0994264
[Epoch 83; Iter    92/  229] train: loss: 0.1599377
[Epoch 83; Iter   122/  229] train: loss: 0.1273230
[Epoch 83; Iter   152/  229] train: loss: 0.1625720
[Epoch 83; Iter   182/  229] train: loss: 0.1758122
[Epoch 83; Iter   212/  229] train: loss: 0.1215796
[Epoch 83] ogbg-moltoxcast: 0.656577 val loss: 0.343242
[Epoch 83] ogbg-moltoxcast: 0.647457 test loss: 0.347131
[Epoch 84; Iter    13/  229] train: loss: 0.1523373
[Epoch 84; Iter    43/  229] train: loss: 0.1302163
[Epoch 84; Iter    73/  229] train: loss: 0.1636246
[Epoch 84; Iter   103/  229] train: loss: 0.1098994
[Epoch 84; Iter   133/  229] train: loss: 0.1458939
[Epoch 84; Iter   163/  229] train: loss: 0.0868692
[Epoch 84; Iter   193/  229] train: loss: 0.1442793
[Epoch 84; Iter   223/  229] train: loss: 0.1062477
[Epoch 84] ogbg-moltoxcast: 0.651013 val loss: 0.343776
[Epoch 84] ogbg-moltoxcast: 0.647863 test loss: 0.351593
[Epoch 85; Iter    24/  229] train: loss: 0.1226650
[Epoch 85; Iter    54/  229] train: loss: 0.1051379
[Epoch 85; Iter    84/  229] train: loss: 0.1107297
[Epoch 85; Iter   114/  229] train: loss: 0.1019534
[Epoch 85; Iter   144/  229] train: loss: 0.1388654
[Epoch 85; Iter   174/  229] train: loss: 0.1495987
[Epoch 85; Iter   204/  229] train: loss: 0.1620033
[Epoch 85] ogbg-moltoxcast: 0.656716 val loss: 0.316840
[Epoch 85] ogbg-moltoxcast: 0.644864 test loss: 0.342514
[Epoch 86; Iter     5/  229] train: loss: 0.1776848
[Epoch 86; Iter    35/  229] train: loss: 0.1611140
[Epoch 86; Iter    65/  229] train: loss: 0.1301425
[Epoch 86; Iter    95/  229] train: loss: 0.1604304
[Epoch 86; Iter   125/  229] train: loss: 0.1281301
[Epoch 86; Iter   155/  229] train: loss: 0.1253598
[Epoch 86; Iter   185/  229] train: loss: 0.1393929
[Epoch 86; Iter   215/  229] train: loss: 0.1440565
[Epoch 86] ogbg-moltoxcast: 0.660645 val loss: 0.334151
[Epoch 86] ogbg-moltoxcast: 0.643819 test loss: 0.347099
[Epoch 87; Iter    16/  229] train: loss: 0.1119383
[Epoch 87; Iter    46/  229] train: loss: 0.1184513
[Epoch 87; Iter    76/  229] train: loss: 0.1109837
[Epoch 87; Iter   106/  229] train: loss: 0.1217592
[Epoch 87; Iter   136/  229] train: loss: 0.1323908
[Epoch 87; Iter   166/  229] train: loss: 0.1365508
[Epoch 87; Iter   196/  229] train: loss: 0.1397087
[Epoch 87; Iter   226/  229] train: loss: 0.1286269
[Epoch 87] ogbg-moltoxcast: 0.652255 val loss: 0.303183
[Epoch 87] ogbg-moltoxcast: 0.650056 test loss: 0.339213
[Epoch 88; Iter    27/  229] train: loss: 0.2056490
[Epoch 88; Iter    57/  229] train: loss: 0.1139452
[Epoch 88; Iter    87/  229] train: loss: 0.1154647
[Epoch 88; Iter   117/  229] train: loss: 0.1259458
[Epoch 88; Iter   147/  229] train: loss: 0.1103343
[Epoch 88; Iter   177/  229] train: loss: 0.1321485
[Epoch 88; Iter   207/  229] train: loss: 0.1267355
[Epoch 88] ogbg-moltoxcast: 0.652075 val loss: 0.333107
[Epoch 88] ogbg-moltoxcast: 0.637991 test loss: 0.355703
[Epoch 89; Iter     8/  229] train: loss: 0.1061407
[Epoch 89; Iter    38/  229] train: loss: 0.1110980
[Epoch 89; Iter    68/  229] train: loss: 0.1460286
[Epoch 89; Iter    98/  229] train: loss: 0.1059004
[Epoch 89; Iter   128/  229] train: loss: 0.1253053
[Epoch 89; Iter   158/  229] train: loss: 0.1262741
[Epoch 89; Iter   188/  229] train: loss: 0.1156863
[Epoch 89; Iter   218/  229] train: loss: 0.1000563
[Epoch 89] ogbg-moltoxcast: 0.651848 val loss: 0.337302
[Epoch 89] ogbg-moltoxcast: 0.640848 test loss: 0.359169
[Epoch 90; Iter    19/  229] train: loss: 0.1210215
[Epoch 90; Iter    49/  229] train: loss: 0.1603364
[Epoch 90; Iter    79/  229] train: loss: 0.1580236
[Epoch 90; Iter   109/  229] train: loss: 0.1797758
[Epoch 90; Iter   139/  229] train: loss: 0.1558937
[Epoch 90; Iter   169/  229] train: loss: 0.1349770
[Epoch 90; Iter   199/  229] train: loss: 0.0989284
[Epoch 90; Iter   229/  229] train: loss: 0.1256382
[Epoch 90] ogbg-moltoxcast: 0.652636 val loss: 0.326534
[Epoch 90] ogbg-moltoxcast: 0.643436 test loss: 0.360163
[Epoch 91; Iter    30/  229] train: loss: 0.1353059
[Epoch 91; Iter    60/  229] train: loss: 0.1058104
[Epoch 91; Iter    90/  229] train: loss: 0.1175607
[Epoch 91; Iter   120/  229] train: loss: 0.1084927
[Epoch 91; Iter   150/  229] train: loss: 0.1261088
[Epoch 91; Iter   180/  229] train: loss: 0.1329735
[Epoch 91; Iter   210/  229] train: loss: 0.1460143
[Epoch 91] ogbg-moltoxcast: 0.651526 val loss: 0.336759
[Epoch 91] ogbg-moltoxcast: 0.639854 test loss: 0.358119
[Epoch 76; Iter    15/  229] train: loss: 0.1108902
[Epoch 76; Iter    45/  229] train: loss: 0.1208536
[Epoch 76; Iter    75/  229] train: loss: 0.1296064
[Epoch 76; Iter   105/  229] train: loss: 0.1320059
[Epoch 76; Iter   135/  229] train: loss: 0.0988633
[Epoch 76; Iter   165/  229] train: loss: 0.1212810
[Epoch 76; Iter   195/  229] train: loss: 0.1076800
[Epoch 76; Iter   225/  229] train: loss: 0.1369107
[Epoch 76] ogbg-moltoxcast: 0.622454 val loss: 0.386770
[Epoch 76] ogbg-moltoxcast: 0.624593 test loss: 0.444159
[Epoch 77; Iter    26/  229] train: loss: 0.1090830
[Epoch 77; Iter    56/  229] train: loss: 0.0961276
[Epoch 77; Iter    86/  229] train: loss: 0.1511824
[Epoch 77; Iter   116/  229] train: loss: 0.1222121
[Epoch 77; Iter   146/  229] train: loss: 0.0986849
[Epoch 77; Iter   176/  229] train: loss: 0.1237647
[Epoch 77; Iter   206/  229] train: loss: 0.1393111
[Epoch 77] ogbg-moltoxcast: 0.625739 val loss: 0.397285
[Epoch 77] ogbg-moltoxcast: 0.628769 test loss: 0.450307
[Epoch 78; Iter     7/  229] train: loss: 0.1233727
[Epoch 78; Iter    37/  229] train: loss: 0.0980971
[Epoch 78; Iter    67/  229] train: loss: 0.0927154
[Epoch 78; Iter    97/  229] train: loss: 0.1147366
[Epoch 78; Iter   127/  229] train: loss: 0.1637788
[Epoch 78; Iter   157/  229] train: loss: 0.0875875
[Epoch 78; Iter   187/  229] train: loss: 0.1335948
[Epoch 78; Iter   217/  229] train: loss: 0.1081961
[Epoch 78] ogbg-moltoxcast: 0.633620 val loss: 0.377387
[Epoch 78] ogbg-moltoxcast: 0.632520 test loss: 0.432742
[Epoch 79; Iter    18/  229] train: loss: 0.1552932
[Epoch 79; Iter    48/  229] train: loss: 0.1310745
[Epoch 79; Iter    78/  229] train: loss: 0.1402810
[Epoch 79; Iter   108/  229] train: loss: 0.1237671
[Epoch 79; Iter   138/  229] train: loss: 0.1331210
[Epoch 79; Iter   168/  229] train: loss: 0.1350537
[Epoch 79; Iter   198/  229] train: loss: 0.0833989
[Epoch 79; Iter   228/  229] train: loss: 0.1298407
[Epoch 79] ogbg-moltoxcast: 0.637344 val loss: 0.373382
[Epoch 79] ogbg-moltoxcast: 0.632859 test loss: 0.433939
[Epoch 80; Iter    29/  229] train: loss: 0.1110967
[Epoch 80; Iter    59/  229] train: loss: 0.1042429
[Epoch 80; Iter    89/  229] train: loss: 0.1220485
[Epoch 80; Iter   119/  229] train: loss: 0.1012573
[Epoch 80; Iter   149/  229] train: loss: 0.1088457
[Epoch 80; Iter   179/  229] train: loss: 0.1128487
[Epoch 80; Iter   209/  229] train: loss: 0.1176647
[Epoch 80] ogbg-moltoxcast: 0.626202 val loss: 0.380375
[Epoch 80] ogbg-moltoxcast: 0.629863 test loss: 0.436570
[Epoch 81; Iter    10/  229] train: loss: 0.1143031
[Epoch 81; Iter    40/  229] train: loss: 0.1241935
[Epoch 81; Iter    70/  229] train: loss: 0.1132948
[Epoch 81; Iter   100/  229] train: loss: 0.1336960
[Epoch 81; Iter   130/  229] train: loss: 0.1462232
[Epoch 81; Iter   160/  229] train: loss: 0.1272495
[Epoch 81; Iter   190/  229] train: loss: 0.1211856
[Epoch 81; Iter   220/  229] train: loss: 0.1016496
[Epoch 81] ogbg-moltoxcast: 0.633417 val loss: 0.381407
[Epoch 81] ogbg-moltoxcast: 0.631078 test loss: 0.440727
[Epoch 82; Iter    21/  229] train: loss: 0.0886746
[Epoch 82; Iter    51/  229] train: loss: 0.1125941
[Epoch 82; Iter    81/  229] train: loss: 0.1240389
[Epoch 82; Iter   111/  229] train: loss: 0.0945898
[Epoch 82; Iter   141/  229] train: loss: 0.0925281
[Epoch 82; Iter   171/  229] train: loss: 0.1067740
[Epoch 82; Iter   201/  229] train: loss: 0.1113621
[Epoch 82] ogbg-moltoxcast: 0.622332 val loss: 0.384344
[Epoch 82] ogbg-moltoxcast: 0.629874 test loss: 0.441181
[Epoch 83; Iter     2/  229] train: loss: 0.1563978
[Epoch 83; Iter    32/  229] train: loss: 0.0922414
[Epoch 83; Iter    62/  229] train: loss: 0.1052901
[Epoch 83; Iter    92/  229] train: loss: 0.1217566
[Epoch 83; Iter   122/  229] train: loss: 0.1012389
[Epoch 83; Iter   152/  229] train: loss: 0.0848325
[Epoch 83; Iter   182/  229] train: loss: 0.0813328
[Epoch 83; Iter   212/  229] train: loss: 0.1442014
[Epoch 83] ogbg-moltoxcast: 0.624998 val loss: 0.385105
[Epoch 83] ogbg-moltoxcast: 0.626666 test loss: 0.444738
[Epoch 84; Iter    13/  229] train: loss: 0.1032007
[Epoch 84; Iter    43/  229] train: loss: 0.1033200
[Epoch 84; Iter    73/  229] train: loss: 0.0825583
[Epoch 84; Iter   103/  229] train: loss: 0.0989379
[Epoch 84; Iter   133/  229] train: loss: 0.0689645
[Epoch 84; Iter   163/  229] train: loss: 0.1010062
[Epoch 84; Iter   193/  229] train: loss: 0.1323690
[Epoch 84; Iter   223/  229] train: loss: 0.0946104
[Epoch 84] ogbg-moltoxcast: 0.631209 val loss: 0.391606
[Epoch 84] ogbg-moltoxcast: 0.631017 test loss: 0.452506
[Epoch 85; Iter    24/  229] train: loss: 0.1246082
[Epoch 85; Iter    54/  229] train: loss: 0.1082310
[Epoch 85; Iter    84/  229] train: loss: 0.1040110
[Epoch 85; Iter   114/  229] train: loss: 0.0894254
[Epoch 85; Iter   144/  229] train: loss: 0.1049208
[Epoch 85; Iter   174/  229] train: loss: 0.1663092
[Epoch 85; Iter   204/  229] train: loss: 0.1388734
[Epoch 85] ogbg-moltoxcast: 0.625117 val loss: 0.382593
[Epoch 85] ogbg-moltoxcast: 0.628405 test loss: 0.439955
[Epoch 86; Iter     5/  229] train: loss: 0.1058829
[Epoch 86; Iter    35/  229] train: loss: 0.1118866
[Epoch 86; Iter    65/  229] train: loss: 0.0772522
[Epoch 86; Iter    95/  229] train: loss: 0.1403307
[Epoch 86; Iter   125/  229] train: loss: 0.0730452
[Epoch 86; Iter   155/  229] train: loss: 0.1166191
[Epoch 86; Iter   185/  229] train: loss: 0.1093737
[Epoch 86; Iter   215/  229] train: loss: 0.1465015
[Epoch 86] ogbg-moltoxcast: 0.625574 val loss: 0.382542
[Epoch 86] ogbg-moltoxcast: 0.631459 test loss: 0.441059
[Epoch 87; Iter    16/  229] train: loss: 0.0771587
[Epoch 87; Iter    46/  229] train: loss: 0.0896760
[Epoch 87; Iter    76/  229] train: loss: 0.1301216
[Epoch 87; Iter   106/  229] train: loss: 0.1081252
[Epoch 87; Iter   136/  229] train: loss: 0.1731398
[Epoch 87; Iter   166/  229] train: loss: 0.1017397
[Epoch 87; Iter   196/  229] train: loss: 0.1111499
[Epoch 87; Iter   226/  229] train: loss: 0.0899760
[Epoch 87] ogbg-moltoxcast: 0.628659 val loss: 0.394269
[Epoch 87] ogbg-moltoxcast: 0.627607 test loss: 0.458203
[Epoch 88; Iter    27/  229] train: loss: 0.1124669
[Epoch 88; Iter    57/  229] train: loss: 0.1013993
[Epoch 88; Iter    87/  229] train: loss: 0.1056173
[Epoch 88; Iter   117/  229] train: loss: 0.1397533
[Epoch 88; Iter   147/  229] train: loss: 0.1153047
[Epoch 88; Iter   177/  229] train: loss: 0.1188181
[Epoch 88; Iter   207/  229] train: loss: 0.0895052
[Epoch 88] ogbg-moltoxcast: 0.628348 val loss: 0.385844
[Epoch 88] ogbg-moltoxcast: 0.629684 test loss: 0.444012
[Epoch 89; Iter     8/  229] train: loss: 0.1247994
[Epoch 89; Iter    38/  229] train: loss: 0.1375092
[Epoch 89; Iter    68/  229] train: loss: 0.1404635
[Epoch 89; Iter    98/  229] train: loss: 0.1028220
[Epoch 89; Iter   128/  229] train: loss: 0.0981699
[Epoch 89; Iter   158/  229] train: loss: 0.1015839
[Epoch 89; Iter   188/  229] train: loss: 0.0863589
[Epoch 89; Iter   218/  229] train: loss: 0.1279573
[Epoch 89] ogbg-moltoxcast: 0.630092 val loss: 0.386086
[Epoch 89] ogbg-moltoxcast: 0.631432 test loss: 0.445507
[Epoch 90; Iter    19/  229] train: loss: 0.1131077
[Epoch 90; Iter    49/  229] train: loss: 0.1066929
[Epoch 90; Iter    79/  229] train: loss: 0.0923741
[Epoch 90; Iter   109/  229] train: loss: 0.0768478
[Epoch 90; Iter   139/  229] train: loss: 0.0869794
[Epoch 90; Iter   169/  229] train: loss: 0.0896416
[Epoch 90; Iter   199/  229] train: loss: 0.1539540
[Epoch 90; Iter   229/  229] train: loss: 0.1163317
[Epoch 90] ogbg-moltoxcast: 0.628558 val loss: 0.387544
[Epoch 90] ogbg-moltoxcast: 0.627107 test loss: 0.446516
[Epoch 91; Iter    30/  229] train: loss: 0.1121344
[Epoch 91; Iter    60/  229] train: loss: 0.1244755
[Epoch 91; Iter    90/  229] train: loss: 0.1292975
[Epoch 91; Iter   120/  229] train: loss: 0.1010664
[Epoch 91; Iter   150/  229] train: loss: 0.1310988
[Epoch 91; Iter   180/  229] train: loss: 0.1596652
[Epoch 91; Iter   210/  229] train: loss: 0.1550326
[Epoch 91] ogbg-moltoxcast: 0.622585 val loss: 0.391630
[Epoch 91] ogbg-moltoxcast: 0.628342 test loss: 0.449533
[Epoch 76; Iter    15/  229] train: loss: 0.1432852
[Epoch 76; Iter    45/  229] train: loss: 0.1154687
[Epoch 76; Iter    75/  229] train: loss: 0.1944024
[Epoch 76; Iter   105/  229] train: loss: 0.1110307
[Epoch 76; Iter   135/  229] train: loss: 0.0923218
[Epoch 76; Iter   165/  229] train: loss: 0.1474926
[Epoch 76; Iter   195/  229] train: loss: 0.0756899
[Epoch 76; Iter   225/  229] train: loss: 0.1092527
[Epoch 76] ogbg-moltoxcast: 0.650659 val loss: 0.328052
[Epoch 76] ogbg-moltoxcast: 0.630030 test loss: 0.394640
[Epoch 77; Iter    26/  229] train: loss: 0.1280208
[Epoch 77; Iter    56/  229] train: loss: 0.1138921
[Epoch 77; Iter    86/  229] train: loss: 0.0952547
[Epoch 77; Iter   116/  229] train: loss: 0.1392066
[Epoch 77; Iter   146/  229] train: loss: 0.1102008
[Epoch 77; Iter   176/  229] train: loss: 0.1261219
[Epoch 77; Iter   206/  229] train: loss: 0.1357872
[Epoch 77] ogbg-moltoxcast: 0.648525 val loss: 0.341284
[Epoch 77] ogbg-moltoxcast: 0.628910 test loss: 0.411643
[Epoch 78; Iter     7/  229] train: loss: 0.1398179
[Epoch 78; Iter    37/  229] train: loss: 0.1326038
[Epoch 78; Iter    67/  229] train: loss: 0.1009339
[Epoch 78; Iter    97/  229] train: loss: 0.1371652
[Epoch 78; Iter   127/  229] train: loss: 0.1189272
[Epoch 78; Iter   157/  229] train: loss: 0.1065497
[Epoch 78; Iter   187/  229] train: loss: 0.1059461
[Epoch 78; Iter   217/  229] train: loss: 0.1138518
[Epoch 78] ogbg-moltoxcast: 0.655017 val loss: 0.330668
[Epoch 78] ogbg-moltoxcast: 0.638522 test loss: 0.391286
[Epoch 79; Iter    18/  229] train: loss: 0.0943054
[Epoch 79; Iter    48/  229] train: loss: 0.1137653
[Epoch 79; Iter    78/  229] train: loss: 0.0955680
[Epoch 79; Iter   108/  229] train: loss: 0.1316168
[Epoch 79; Iter   138/  229] train: loss: 0.1081557
[Epoch 79; Iter   168/  229] train: loss: 0.0805927
[Epoch 79; Iter   198/  229] train: loss: 0.0732613
[Epoch 79; Iter   228/  229] train: loss: 0.1473488
[Epoch 79] ogbg-moltoxcast: 0.653547 val loss: 0.329629
[Epoch 79] ogbg-moltoxcast: 0.632470 test loss: 0.393704
[Epoch 80; Iter    29/  229] train: loss: 0.1333029
[Epoch 80; Iter    59/  229] train: loss: 0.1080122
[Epoch 80; Iter    89/  229] train: loss: 0.0974864
[Epoch 80; Iter   119/  229] train: loss: 0.1347924
[Epoch 80; Iter   149/  229] train: loss: 0.1363893
[Epoch 80; Iter   179/  229] train: loss: 0.2246539
[Epoch 80; Iter   209/  229] train: loss: 0.1109739
[Epoch 80] ogbg-moltoxcast: 0.653180 val loss: 0.332779
[Epoch 80] ogbg-moltoxcast: 0.632784 test loss: 0.397487
[Epoch 81; Iter    10/  229] train: loss: 0.0826488
[Epoch 81; Iter    40/  229] train: loss: 0.1220216
[Epoch 81; Iter    70/  229] train: loss: 0.1538355
[Epoch 81; Iter   100/  229] train: loss: 0.1170556
[Epoch 81; Iter   130/  229] train: loss: 0.1046494
[Epoch 81; Iter   160/  229] train: loss: 0.1285409
[Epoch 81; Iter   190/  229] train: loss: 0.1617476
[Epoch 81; Iter   220/  229] train: loss: 0.0867765
[Epoch 81] ogbg-moltoxcast: 0.648619 val loss: 0.338448
[Epoch 81] ogbg-moltoxcast: 0.633111 test loss: 0.400701
[Epoch 82; Iter    21/  229] train: loss: 0.0694596
[Epoch 82; Iter    51/  229] train: loss: 0.1176206
[Epoch 82; Iter    81/  229] train: loss: 0.1055024
[Epoch 82; Iter   111/  229] train: loss: 0.0969876
[Epoch 82; Iter   141/  229] train: loss: 0.1471844
[Epoch 82; Iter   171/  229] train: loss: 0.0954361
[Epoch 82; Iter   201/  229] train: loss: 0.0894168
[Epoch 82] ogbg-moltoxcast: 0.648111 val loss: 0.339169
[Epoch 82] ogbg-moltoxcast: 0.637478 test loss: 0.394388
[Epoch 83; Iter     2/  229] train: loss: 0.0922174
[Epoch 83; Iter    32/  229] train: loss: 0.1614276
[Epoch 83; Iter    62/  229] train: loss: 0.1374076
[Epoch 83; Iter    92/  229] train: loss: 0.0910352
[Epoch 83; Iter   122/  229] train: loss: 0.1012333
[Epoch 83; Iter   152/  229] train: loss: 0.0949566
[Epoch 83; Iter   182/  229] train: loss: 0.1401860
[Epoch 83; Iter   212/  229] train: loss: 0.0812719
[Epoch 83] ogbg-moltoxcast: 0.649228 val loss: 0.340674
[Epoch 83] ogbg-moltoxcast: 0.633563 test loss: 0.405053
[Epoch 84; Iter    13/  229] train: loss: 0.1811997
[Epoch 84; Iter    43/  229] train: loss: 0.1319613
[Epoch 84; Iter    73/  229] train: loss: 0.1616017
[Epoch 84; Iter   103/  229] train: loss: 0.0895412
[Epoch 84; Iter   133/  229] train: loss: 0.0976664
[Epoch 84; Iter   163/  229] train: loss: 0.0923178
[Epoch 84; Iter   193/  229] train: loss: 0.1377078
[Epoch 84; Iter   223/  229] train: loss: 0.1090760
[Epoch 84] ogbg-moltoxcast: 0.646251 val loss: 0.342343
[Epoch 84] ogbg-moltoxcast: 0.635295 test loss: 0.400117
[Epoch 85; Iter    24/  229] train: loss: 0.0745466
[Epoch 85; Iter    54/  229] train: loss: 0.1222206
[Epoch 85; Iter    84/  229] train: loss: 0.1109574
[Epoch 85; Iter   114/  229] train: loss: 0.0816572
[Epoch 85; Iter   144/  229] train: loss: 0.0977436
[Epoch 85; Iter   174/  229] train: loss: 0.1359130
[Epoch 85; Iter   204/  229] train: loss: 0.1249110
[Epoch 85] ogbg-moltoxcast: 0.649005 val loss: 0.337378
[Epoch 85] ogbg-moltoxcast: 0.633563 test loss: 0.398244
[Epoch 86; Iter     5/  229] train: loss: 0.0884775
[Epoch 86; Iter    35/  229] train: loss: 0.1546245
[Epoch 86; Iter    65/  229] train: loss: 0.1454275
[Epoch 86; Iter    95/  229] train: loss: 0.1347618
[Epoch 86; Iter   125/  229] train: loss: 0.1012562
[Epoch 86; Iter   155/  229] train: loss: 0.1413940
[Epoch 86; Iter   185/  229] train: loss: 0.1538595
[Epoch 86; Iter   215/  229] train: loss: 0.1359614
[Epoch 86] ogbg-moltoxcast: 0.645388 val loss: 0.341202
[Epoch 86] ogbg-moltoxcast: 0.631971 test loss: 0.401760
[Epoch 87; Iter    16/  229] train: loss: 0.1186430
[Epoch 87; Iter    46/  229] train: loss: 0.1404543
[Epoch 87; Iter    76/  229] train: loss: 0.0733634
[Epoch 87; Iter   106/  229] train: loss: 0.0952236
[Epoch 87; Iter   136/  229] train: loss: 0.0935959
[Epoch 87; Iter   166/  229] train: loss: 0.1068093
[Epoch 87; Iter   196/  229] train: loss: 0.1602152
[Epoch 87; Iter   226/  229] train: loss: 0.1319193
[Epoch 87] ogbg-moltoxcast: 0.650248 val loss: 0.344107
[Epoch 87] ogbg-moltoxcast: 0.633404 test loss: 0.406253
[Epoch 88; Iter    27/  229] train: loss: 0.1056049
[Epoch 88; Iter    57/  229] train: loss: 0.0765711
[Epoch 88; Iter    87/  229] train: loss: 0.0876056
[Epoch 88; Iter   117/  229] train: loss: 0.1050239
[Epoch 88; Iter   147/  229] train: loss: 0.1182850
[Epoch 88; Iter   177/  229] train: loss: 0.0952350
[Epoch 88; Iter   207/  229] train: loss: 0.0995300
[Epoch 88] ogbg-moltoxcast: 0.646026 val loss: 0.341574
[Epoch 88] ogbg-moltoxcast: 0.632419 test loss: 0.403130
[Epoch 89; Iter     8/  229] train: loss: 0.1118409
[Epoch 89; Iter    38/  229] train: loss: 0.1290048
[Epoch 89; Iter    68/  229] train: loss: 0.1035912
[Epoch 89; Iter    98/  229] train: loss: 0.1232237
[Epoch 89; Iter   128/  229] train: loss: 0.1486579
[Epoch 89; Iter   158/  229] train: loss: 0.1045603
[Epoch 89; Iter   188/  229] train: loss: 0.0699714
[Epoch 89; Iter   218/  229] train: loss: 0.1183747
[Epoch 89] ogbg-moltoxcast: 0.650383 val loss: 0.345100
[Epoch 89] ogbg-moltoxcast: 0.633608 test loss: 0.407705
[Epoch 90; Iter    19/  229] train: loss: 0.0919214
[Epoch 90; Iter    49/  229] train: loss: 0.0978388
[Epoch 90; Iter    79/  229] train: loss: 0.0827442
[Epoch 90; Iter   109/  229] train: loss: 0.1105894
[Epoch 90; Iter   139/  229] train: loss: 0.1527746
[Epoch 90; Iter   169/  229] train: loss: 0.1380732
[Epoch 90; Iter   199/  229] train: loss: 0.1396846
[Epoch 90; Iter   229/  229] train: loss: 0.1503590
[Epoch 90] ogbg-moltoxcast: 0.650333 val loss: 0.341775
[Epoch 90] ogbg-moltoxcast: 0.635046 test loss: 0.403342
[Epoch 91; Iter    30/  229] train: loss: 0.0867755
[Epoch 91; Iter    60/  229] train: loss: 0.1014848
[Epoch 91; Iter    90/  229] train: loss: 0.1093695
[Epoch 91; Iter   120/  229] train: loss: 0.1138748
[Epoch 91; Iter   150/  229] train: loss: 0.0815025
[Epoch 91; Iter   180/  229] train: loss: 0.1381242
[Epoch 91; Iter   210/  229] train: loss: 0.1307705
[Epoch 91] ogbg-moltoxcast: 0.648109 val loss: 0.343125
[Epoch 91] ogbg-moltoxcast: 0.633116 test loss: 0.406547
[Epoch 76; Iter    15/  229] train: loss: 0.1082130
[Epoch 76; Iter    45/  229] train: loss: 0.1244525
[Epoch 76; Iter    75/  229] train: loss: 0.1425665
[Epoch 76; Iter   105/  229] train: loss: 0.0888535
[Epoch 76; Iter   135/  229] train: loss: 0.1790225
[Epoch 76; Iter   165/  229] train: loss: 0.1018460
[Epoch 76; Iter   195/  229] train: loss: 0.1173370
[Epoch 76; Iter   225/  229] train: loss: 0.1011986
[Epoch 76] ogbg-moltoxcast: 0.631109 val loss: 1.220725
[Epoch 76] ogbg-moltoxcast: 0.621182 test loss: 2.211114
[Epoch 77; Iter    26/  229] train: loss: 0.1401015
[Epoch 77; Iter    56/  229] train: loss: 0.1067364
[Epoch 77; Iter    86/  229] train: loss: 0.1904306
[Epoch 77; Iter   116/  229] train: loss: 0.1598912
[Epoch 77; Iter   146/  229] train: loss: 0.1298511
[Epoch 77; Iter   176/  229] train: loss: 0.1623093
[Epoch 77; Iter   206/  229] train: loss: 0.1430310
[Epoch 77] ogbg-moltoxcast: 0.635630 val loss: 1.958812
[Epoch 77] ogbg-moltoxcast: 0.615863 test loss: 3.175934
[Epoch 78; Iter     7/  229] train: loss: 0.1361030
[Epoch 78; Iter    37/  229] train: loss: 0.1326353
[Epoch 78; Iter    67/  229] train: loss: 0.1207082
[Epoch 78; Iter    97/  229] train: loss: 0.0971204
[Epoch 78; Iter   127/  229] train: loss: 0.1276277
[Epoch 78; Iter   157/  229] train: loss: 0.1187245
[Epoch 78; Iter   187/  229] train: loss: 0.1402125
[Epoch 78; Iter   217/  229] train: loss: 0.1611388
[Epoch 78] ogbg-moltoxcast: 0.636878 val loss: 2.788757
[Epoch 78] ogbg-moltoxcast: 0.620790 test loss: 3.781620
[Epoch 79; Iter    18/  229] train: loss: 0.1002051
[Epoch 79; Iter    48/  229] train: loss: 0.1338176
[Epoch 79; Iter    78/  229] train: loss: 0.1476856
[Epoch 79; Iter   108/  229] train: loss: 0.1451702
[Epoch 79; Iter   138/  229] train: loss: 0.1733323
[Epoch 79; Iter   168/  229] train: loss: 0.1605708
[Epoch 79; Iter   198/  229] train: loss: 0.1392790
[Epoch 79; Iter   228/  229] train: loss: 0.1530027
[Epoch 79] ogbg-moltoxcast: 0.643224 val loss: 1.329554
[Epoch 79] ogbg-moltoxcast: 0.627236 test loss: 2.008386
[Epoch 80; Iter    29/  229] train: loss: 0.1334024
[Epoch 80; Iter    59/  229] train: loss: 0.1112183
[Epoch 80; Iter    89/  229] train: loss: 0.1519921
[Epoch 80; Iter   119/  229] train: loss: 0.1190248
[Epoch 80; Iter   149/  229] train: loss: 0.1420378
[Epoch 80; Iter   179/  229] train: loss: 0.1408924
[Epoch 80; Iter   209/  229] train: loss: 0.1445336
[Epoch 80] ogbg-moltoxcast: 0.624929 val loss: 2.784734
[Epoch 80] ogbg-moltoxcast: 0.619855 test loss: 3.585528
[Epoch 81; Iter    10/  229] train: loss: 0.1082377
[Epoch 81; Iter    40/  229] train: loss: 0.1428329
[Epoch 81; Iter    70/  229] train: loss: 0.1621991
[Epoch 81; Iter   100/  229] train: loss: 0.0763828
[Epoch 81; Iter   130/  229] train: loss: 0.0922063
[Epoch 81; Iter   160/  229] train: loss: 0.1480770
[Epoch 81; Iter   190/  229] train: loss: 0.1338036
[Epoch 81; Iter   220/  229] train: loss: 0.1283459
[Epoch 81] ogbg-moltoxcast: 0.634982 val loss: 1.979897
[Epoch 81] ogbg-moltoxcast: 0.620916 test loss: 2.797007
[Epoch 82; Iter    21/  229] train: loss: 0.1438310
[Epoch 82; Iter    51/  229] train: loss: 0.1444035
[Epoch 82; Iter    81/  229] train: loss: 0.0984803
[Epoch 82; Iter   111/  229] train: loss: 0.1025222
[Epoch 82; Iter   141/  229] train: loss: 0.1363779
[Epoch 82; Iter   171/  229] train: loss: 0.1008521
[Epoch 82; Iter   201/  229] train: loss: 0.1455888
[Epoch 82] ogbg-moltoxcast: 0.614176 val loss: 1.936099
[Epoch 82] ogbg-moltoxcast: 0.609969 test loss: 2.860057
[Epoch 83; Iter     2/  229] train: loss: 0.1100737
[Epoch 83; Iter    32/  229] train: loss: 0.1144894
[Epoch 83; Iter    62/  229] train: loss: 0.1018314
[Epoch 83; Iter    92/  229] train: loss: 0.1479221
[Epoch 83; Iter   122/  229] train: loss: 0.1175414
[Epoch 83; Iter   152/  229] train: loss: 0.1549381
[Epoch 83; Iter   182/  229] train: loss: 0.1609002
[Epoch 83; Iter   212/  229] train: loss: 0.1151869
[Epoch 83] ogbg-moltoxcast: 0.630788 val loss: 2.277350
[Epoch 83] ogbg-moltoxcast: 0.617470 test loss: 3.205564
[Epoch 84; Iter    13/  229] train: loss: 0.1385384
[Epoch 84; Iter    43/  229] train: loss: 0.1220361
[Epoch 84; Iter    73/  229] train: loss: 0.1538736
[Epoch 84; Iter   103/  229] train: loss: 0.1052819
[Epoch 84; Iter   133/  229] train: loss: 0.1415237
[Epoch 84; Iter   163/  229] train: loss: 0.0857565
[Epoch 84; Iter   193/  229] train: loss: 0.1362765
[Epoch 84; Iter   223/  229] train: loss: 0.1009002
[Epoch 84] ogbg-moltoxcast: 0.619520 val loss: 2.409302
[Epoch 84] ogbg-moltoxcast: 0.611596 test loss: 3.413294
[Epoch 85; Iter    24/  229] train: loss: 0.1219760
[Epoch 85; Iter    54/  229] train: loss: 0.1040325
[Epoch 85; Iter    84/  229] train: loss: 0.1081224
[Epoch 85; Iter   114/  229] train: loss: 0.1009831
[Epoch 85; Iter   144/  229] train: loss: 0.1271420
[Epoch 85; Iter   174/  229] train: loss: 0.1456343
[Epoch 85; Iter   204/  229] train: loss: 0.1563123
[Epoch 85] ogbg-moltoxcast: 0.625871 val loss: 2.353452
[Epoch 85] ogbg-moltoxcast: 0.613164 test loss: 2.932530
[Epoch 86; Iter     5/  229] train: loss: 0.1656692
[Epoch 86; Iter    35/  229] train: loss: 0.1511326
[Epoch 86; Iter    65/  229] train: loss: 0.1244608
[Epoch 86; Iter    95/  229] train: loss: 0.1557591
[Epoch 86; Iter   125/  229] train: loss: 0.1229121
[Epoch 86; Iter   155/  229] train: loss: 0.1141778
[Epoch 86; Iter   185/  229] train: loss: 0.1410885
[Epoch 86; Iter   215/  229] train: loss: 0.1471889
[Epoch 86] ogbg-moltoxcast: 0.618771 val loss: 1.881970
[Epoch 86] ogbg-moltoxcast: 0.620619 test loss: 2.787704
[Epoch 87; Iter    16/  229] train: loss: 0.1013611
[Epoch 87; Iter    46/  229] train: loss: 0.1263453
[Epoch 87; Iter    76/  229] train: loss: 0.1093621
[Epoch 87; Iter   106/  229] train: loss: 0.1243618
[Epoch 87; Iter   136/  229] train: loss: 0.1257347
[Epoch 87; Iter   166/  229] train: loss: 0.1266780
[Epoch 87; Iter   196/  229] train: loss: 0.1347679
[Epoch 87; Iter   226/  229] train: loss: 0.1207935
[Epoch 87] ogbg-moltoxcast: 0.621927 val loss: 2.179589
[Epoch 87] ogbg-moltoxcast: 0.616570 test loss: 2.979992
[Epoch 88; Iter    27/  229] train: loss: 0.2069841
[Epoch 88; Iter    57/  229] train: loss: 0.1114912
[Epoch 88; Iter    87/  229] train: loss: 0.1086559
[Epoch 88; Iter   117/  229] train: loss: 0.1144944
[Epoch 88; Iter   147/  229] train: loss: 0.1001982
[Epoch 88; Iter   177/  229] train: loss: 0.1258759
[Epoch 88; Iter   207/  229] train: loss: 0.1190911
[Epoch 88] ogbg-moltoxcast: 0.624165 val loss: 1.932260
[Epoch 88] ogbg-moltoxcast: 0.613944 test loss: 2.698409
[Epoch 89; Iter     8/  229] train: loss: 0.1002782
[Epoch 89; Iter    38/  229] train: loss: 0.1006724
[Epoch 89; Iter    68/  229] train: loss: 0.1324657
[Epoch 89; Iter    98/  229] train: loss: 0.1082174
[Epoch 89; Iter   128/  229] train: loss: 0.1177130
[Epoch 89; Iter   158/  229] train: loss: 0.1189504
[Epoch 89; Iter   188/  229] train: loss: 0.1183340
[Epoch 89; Iter   218/  229] train: loss: 0.0902943
[Epoch 89] ogbg-moltoxcast: 0.630192 val loss: 2.016107
[Epoch 89] ogbg-moltoxcast: 0.616833 test loss: 2.738894
[Epoch 90; Iter    19/  229] train: loss: 0.1175341
[Epoch 90; Iter    49/  229] train: loss: 0.1552461
[Epoch 90; Iter    79/  229] train: loss: 0.1564100
[Epoch 90; Iter   109/  229] train: loss: 0.1623613
[Epoch 90; Iter   139/  229] train: loss: 0.1504316
[Epoch 90; Iter   169/  229] train: loss: 0.1195009
[Epoch 90; Iter   199/  229] train: loss: 0.0966880
[Epoch 90; Iter   229/  229] train: loss: 0.1180020
[Epoch 90] ogbg-moltoxcast: 0.623347 val loss: 2.508478
[Epoch 90] ogbg-moltoxcast: 0.622535 test loss: 3.457675
[Epoch 91; Iter    30/  229] train: loss: 0.1329692
[Epoch 91; Iter    60/  229] train: loss: 0.1000008
[Epoch 91; Iter    90/  229] train: loss: 0.1169274
[Epoch 91; Iter   120/  229] train: loss: 0.1020084
[Epoch 91; Iter   150/  229] train: loss: 0.1208555
[Epoch 91; Iter   180/  229] train: loss: 0.1300061
[Epoch 91; Iter   210/  229] train: loss: 0.1472254
[Epoch 91] ogbg-moltoxcast: 0.617899 val loss: 2.335952
[Epoch 91] ogbg-moltoxcast: 0.610619 test loss: 2.948360
[Epoch 92; Iter    11/  229] train: loss: 0.1213648
[Epoch 92; Iter    41/  229] train: loss: 0.1375642
[Epoch 92; Iter    71/  229] train: loss: 0.0904560
[Epoch 92; Iter   101/  229] train: loss: 0.1389409
[Epoch 92; Iter   131/  229] train: loss: 0.0954433
[Epoch 92; Iter   161/  229] train: loss: 0.1148762
[Epoch 92; Iter   191/  229] train: loss: 0.1028953
[Epoch 92; Iter   221/  229] train: loss: 0.1144600
[Epoch 92] ogbg-moltoxcast: 0.682759 val loss: 0.295383
[Epoch 92] ogbg-moltoxcast: 0.645290 test loss: 0.352517
[Epoch 93; Iter    22/  229] train: loss: 0.1165936
[Epoch 93; Iter    52/  229] train: loss: 0.1089359
[Epoch 93; Iter    82/  229] train: loss: 0.0713510
[Epoch 93; Iter   112/  229] train: loss: 0.1179311
[Epoch 93; Iter   142/  229] train: loss: 0.1373449
[Epoch 93; Iter   172/  229] train: loss: 0.1013244
[Epoch 93; Iter   202/  229] train: loss: 0.0962538
[Epoch 93] ogbg-moltoxcast: 0.683806 val loss: 0.299399
[Epoch 93] ogbg-moltoxcast: 0.648944 test loss: 0.350653
[Epoch 94; Iter     3/  229] train: loss: 0.1065236
[Epoch 94; Iter    33/  229] train: loss: 0.1244528
[Epoch 94; Iter    63/  229] train: loss: 0.1014971
[Epoch 94; Iter    93/  229] train: loss: 0.1431384
[Epoch 94; Iter   123/  229] train: loss: 0.1333687
[Epoch 94; Iter   153/  229] train: loss: 0.0741846
[Epoch 94; Iter   183/  229] train: loss: 0.0992734
[Epoch 94; Iter   213/  229] train: loss: 0.1080753
[Epoch 94] ogbg-moltoxcast: 0.682946 val loss: 0.299799
[Epoch 94] ogbg-moltoxcast: 0.645347 test loss: 0.354486
[Epoch 95; Iter    14/  229] train: loss: 0.1302304
[Epoch 95; Iter    44/  229] train: loss: 0.1093478
[Epoch 95; Iter    74/  229] train: loss: 0.1069310
[Epoch 95; Iter   104/  229] train: loss: 0.1023502
[Epoch 95; Iter   134/  229] train: loss: 0.0783767
[Epoch 95; Iter   164/  229] train: loss: 0.1346547
[Epoch 95; Iter   194/  229] train: loss: 0.1155095
[Epoch 95; Iter   224/  229] train: loss: 0.1065653
[Epoch 95] ogbg-moltoxcast: 0.684225 val loss: 0.301026
[Epoch 95] ogbg-moltoxcast: 0.644921 test loss: 0.354709
[Epoch 96; Iter    25/  229] train: loss: 0.1303086
[Epoch 96; Iter    55/  229] train: loss: 0.0969591
[Epoch 96; Iter    85/  229] train: loss: 0.1191727
[Epoch 96; Iter   115/  229] train: loss: 0.0916950
[Epoch 96; Iter   145/  229] train: loss: 0.1163516
[Epoch 96; Iter   175/  229] train: loss: 0.1027074
[Epoch 96; Iter   205/  229] train: loss: 0.1111054
[Epoch 96] ogbg-moltoxcast: 0.684290 val loss: 0.300537
[Epoch 96] ogbg-moltoxcast: 0.645111 test loss: 0.354099
[Epoch 97; Iter     6/  229] train: loss: 0.0605844
[Epoch 97; Iter    36/  229] train: loss: 0.1311913
[Epoch 97; Iter    66/  229] train: loss: 0.0790062
[Epoch 97; Iter    96/  229] train: loss: 0.1859275
[Epoch 97; Iter   126/  229] train: loss: 0.0840511
[Epoch 97; Iter   156/  229] train: loss: 0.0948095
[Epoch 97; Iter   186/  229] train: loss: 0.1154203
[Epoch 97; Iter   216/  229] train: loss: 0.0899996
[Epoch 97] ogbg-moltoxcast: 0.682438 val loss: 0.299509
[Epoch 97] ogbg-moltoxcast: 0.643159 test loss: 0.357812
[Epoch 98; Iter    17/  229] train: loss: 0.1579219
[Epoch 98; Iter    47/  229] train: loss: 0.1272511
[Epoch 98; Iter    77/  229] train: loss: 0.1318151
[Epoch 98; Iter   107/  229] train: loss: 0.1153917
[Epoch 98; Iter   137/  229] train: loss: 0.0941858
[Epoch 98; Iter   167/  229] train: loss: 0.0629167
[Epoch 98; Iter   197/  229] train: loss: 0.1035698
[Epoch 98; Iter   227/  229] train: loss: 0.1517091
[Epoch 98] ogbg-moltoxcast: 0.681428 val loss: 0.301841
[Epoch 98] ogbg-moltoxcast: 0.640846 test loss: 0.354816
[Epoch 99; Iter    28/  229] train: loss: 0.1433232
[Epoch 99; Iter    58/  229] train: loss: 0.0756704
[Epoch 99; Iter    88/  229] train: loss: 0.1182200
[Epoch 99; Iter   118/  229] train: loss: 0.1425031
[Epoch 99; Iter   148/  229] train: loss: 0.1408136
[Epoch 99; Iter   178/  229] train: loss: 0.1322349
[Epoch 99; Iter   208/  229] train: loss: 0.1224851
[Epoch 99] ogbg-moltoxcast: 0.684367 val loss: 0.299189
[Epoch 99] ogbg-moltoxcast: 0.642970 test loss: 0.356914
[Epoch 100; Iter     9/  229] train: loss: 0.0915706
[Epoch 100; Iter    39/  229] train: loss: 0.1307997
[Epoch 100; Iter    69/  229] train: loss: 0.1183977
[Epoch 100; Iter    99/  229] train: loss: 0.1019753
[Epoch 100; Iter   129/  229] train: loss: 0.1346788
[Epoch 100; Iter   159/  229] train: loss: 0.1232940
[Epoch 100; Iter   189/  229] train: loss: 0.1245950
[Epoch 100; Iter   219/  229] train: loss: 0.1844099
[Epoch 100] ogbg-moltoxcast: 0.684105 val loss: 0.303531
[Epoch 100] ogbg-moltoxcast: 0.644863 test loss: 0.361015
[Epoch 101; Iter    20/  229] train: loss: 0.1064669
[Epoch 101; Iter    50/  229] train: loss: 0.1262364
[Epoch 101; Iter    80/  229] train: loss: 0.0928930
[Epoch 101; Iter   110/  229] train: loss: 0.1323612
[Epoch 101; Iter   140/  229] train: loss: 0.1281704
[Epoch 101; Iter   170/  229] train: loss: 0.0918950
[Epoch 101; Iter   200/  229] train: loss: 0.1054822
[Epoch 101] ogbg-moltoxcast: 0.682634 val loss: 0.300512
[Epoch 101] ogbg-moltoxcast: 0.644749 test loss: 0.359608
[Epoch 102; Iter     1/  229] train: loss: 0.1209906
[Epoch 102; Iter    31/  229] train: loss: 0.0953676
[Epoch 102; Iter    61/  229] train: loss: 0.1334317
[Epoch 102; Iter    91/  229] train: loss: 0.1092432
[Epoch 102; Iter   121/  229] train: loss: 0.1023855
[Epoch 102; Iter   151/  229] train: loss: 0.1012796
[Epoch 102; Iter   181/  229] train: loss: 0.0938366
[Epoch 102; Iter   211/  229] train: loss: 0.1380707
[Epoch 102] ogbg-moltoxcast: 0.678490 val loss: 0.302095
[Epoch 102] ogbg-moltoxcast: 0.645776 test loss: 0.360626
[Epoch 103; Iter    12/  229] train: loss: 0.1092046
[Epoch 103; Iter    42/  229] train: loss: 0.1139233
[Epoch 103; Iter    72/  229] train: loss: 0.1144513
[Epoch 103; Iter   102/  229] train: loss: 0.1179316
[Epoch 103; Iter   132/  229] train: loss: 0.1031689
[Epoch 103; Iter   162/  229] train: loss: 0.1479603
[Epoch 103; Iter   192/  229] train: loss: 0.1085763
[Epoch 103; Iter   222/  229] train: loss: 0.1167916
[Epoch 103] ogbg-moltoxcast: 0.680899 val loss: 0.299688
[Epoch 103] ogbg-moltoxcast: 0.644490 test loss: 0.357419
[Epoch 104; Iter    23/  229] train: loss: 0.1027503
[Epoch 104; Iter    53/  229] train: loss: 0.0953366
[Epoch 104; Iter    83/  229] train: loss: 0.1110747
[Epoch 104; Iter   113/  229] train: loss: 0.1020173
[Epoch 104; Iter   143/  229] train: loss: 0.0846173
[Epoch 104; Iter   173/  229] train: loss: 0.0977943
[Epoch 104; Iter   203/  229] train: loss: 0.1243422
[Epoch 104] ogbg-moltoxcast: 0.680795 val loss: 0.301760
[Epoch 104] ogbg-moltoxcast: 0.644554 test loss: 0.358437
[Epoch 105; Iter     4/  229] train: loss: 0.1099445
[Epoch 105; Iter    34/  229] train: loss: 0.0900606
[Epoch 105; Iter    64/  229] train: loss: 0.1023833
[Epoch 105; Iter    94/  229] train: loss: 0.1111527
[Epoch 105; Iter   124/  229] train: loss: 0.0735266
[Epoch 105; Iter   154/  229] train: loss: 0.0942420
[Epoch 105; Iter   184/  229] train: loss: 0.1156204
[Epoch 105; Iter   214/  229] train: loss: 0.1254964
[Epoch 105] ogbg-moltoxcast: 0.685263 val loss: 0.303180
[Epoch 105] ogbg-moltoxcast: 0.643896 test loss: 0.360953
[Epoch 106; Iter    15/  229] train: loss: 0.0778860
[Epoch 106; Iter    45/  229] train: loss: 0.0806796
[Epoch 106; Iter    75/  229] train: loss: 0.0889393
[Epoch 106; Iter   105/  229] train: loss: 0.0908949
[Epoch 106; Iter   135/  229] train: loss: 0.1095629
[Epoch 106; Iter   165/  229] train: loss: 0.0916687
[Epoch 106; Iter   195/  229] train: loss: 0.1552841
[Epoch 106; Iter   225/  229] train: loss: 0.1310785
[Epoch 106] ogbg-moltoxcast: 0.680949 val loss: 0.301599
[Epoch 106] ogbg-moltoxcast: 0.640622 test loss: 0.362409
[Epoch 107; Iter    26/  229] train: loss: 0.0873019
[Epoch 107; Iter    56/  229] train: loss: 0.1106512
[Epoch 107; Iter    86/  229] train: loss: 0.1093632
[Epoch 107; Iter   116/  229] train: loss: 0.1249184
[Epoch 107; Iter   146/  229] train: loss: 0.1083957
[Epoch 107; Iter   176/  229] train: loss: 0.1412093
[Epoch 107; Iter   206/  229] train: loss: 0.1198224
[Epoch 107] ogbg-moltoxcast: 0.687082 val loss: 0.295631
[Epoch 92; Iter    11/  229] train: loss: 0.1082487
[Epoch 92; Iter    41/  229] train: loss: 0.1027841
[Epoch 92; Iter    71/  229] train: loss: 0.1223896
[Epoch 92; Iter   101/  229] train: loss: 0.0908482
[Epoch 92; Iter   131/  229] train: loss: 0.0877327
[Epoch 92; Iter   161/  229] train: loss: 0.0748797
[Epoch 92; Iter   191/  229] train: loss: 0.1085643
[Epoch 92; Iter   221/  229] train: loss: 0.1184746
[Epoch 92] ogbg-moltoxcast: 0.681485 val loss: 0.299118
[Epoch 92] ogbg-moltoxcast: 0.638694 test loss: 0.347060
[Epoch 93; Iter    22/  229] train: loss: 0.0789989
[Epoch 93; Iter    52/  229] train: loss: 0.0702805
[Epoch 93; Iter    82/  229] train: loss: 0.1039285
[Epoch 93; Iter   112/  229] train: loss: 0.1111929
[Epoch 93; Iter   142/  229] train: loss: 0.0887804
[Epoch 93; Iter   172/  229] train: loss: 0.1430287
[Epoch 93; Iter   202/  229] train: loss: 0.1112284
[Epoch 93] ogbg-moltoxcast: 0.682962 val loss: 0.298280
[Epoch 93] ogbg-moltoxcast: 0.639315 test loss: 0.343716
[Epoch 94; Iter     3/  229] train: loss: 0.1765150
[Epoch 94; Iter    33/  229] train: loss: 0.1349273
[Epoch 94; Iter    63/  229] train: loss: 0.1328548
[Epoch 94; Iter    93/  229] train: loss: 0.0789237
[Epoch 94; Iter   123/  229] train: loss: 0.0932712
[Epoch 94; Iter   153/  229] train: loss: 0.1008085
[Epoch 94; Iter   183/  229] train: loss: 0.1222955
[Epoch 94; Iter   213/  229] train: loss: 0.1665564
[Epoch 94] ogbg-moltoxcast: 0.682706 val loss: 0.298851
[Epoch 94] ogbg-moltoxcast: 0.640013 test loss: 0.345726
[Epoch 95; Iter    14/  229] train: loss: 0.1078300
[Epoch 95; Iter    44/  229] train: loss: 0.1187081
[Epoch 95; Iter    74/  229] train: loss: 0.1600593
[Epoch 95; Iter   104/  229] train: loss: 0.1116500
[Epoch 95; Iter   134/  229] train: loss: 0.1275782
[Epoch 95; Iter   164/  229] train: loss: 0.1004254
[Epoch 95; Iter   194/  229] train: loss: 0.0707848
[Epoch 95; Iter   224/  229] train: loss: 0.1001136
[Epoch 95] ogbg-moltoxcast: 0.682959 val loss: 0.298983
[Epoch 95] ogbg-moltoxcast: 0.639143 test loss: 0.343855
[Epoch 96; Iter    25/  229] train: loss: 0.1206696
[Epoch 96; Iter    55/  229] train: loss: 0.0636080
[Epoch 96; Iter    85/  229] train: loss: 0.1107621
[Epoch 96; Iter   115/  229] train: loss: 0.1271320
[Epoch 96; Iter   145/  229] train: loss: 0.1236921
[Epoch 96; Iter   175/  229] train: loss: 0.1288354
[Epoch 96; Iter   205/  229] train: loss: 0.1021245
[Epoch 96] ogbg-moltoxcast: 0.680510 val loss: 0.303251
[Epoch 96] ogbg-moltoxcast: 0.639575 test loss: 0.346592
[Epoch 97; Iter     6/  229] train: loss: 0.1147708
[Epoch 97; Iter    36/  229] train: loss: 0.0912205
[Epoch 97; Iter    66/  229] train: loss: 0.0914982
[Epoch 97; Iter    96/  229] train: loss: 0.0948649
[Epoch 97; Iter   126/  229] train: loss: 0.1117688
[Epoch 97; Iter   156/  229] train: loss: 0.1178638
[Epoch 97; Iter   186/  229] train: loss: 0.0821084
[Epoch 97; Iter   216/  229] train: loss: 0.1118703
[Epoch 97] ogbg-moltoxcast: 0.680860 val loss: 0.303145
[Epoch 97] ogbg-moltoxcast: 0.640477 test loss: 0.345856
[Epoch 98; Iter    17/  229] train: loss: 0.1216845
[Epoch 98; Iter    47/  229] train: loss: 0.1055189
[Epoch 98; Iter    77/  229] train: loss: 0.0816059
[Epoch 98; Iter   107/  229] train: loss: 0.0984914
[Epoch 98; Iter   137/  229] train: loss: 0.1046048
[Epoch 98; Iter   167/  229] train: loss: 0.1239594
[Epoch 98; Iter   197/  229] train: loss: 0.1303670
[Epoch 98; Iter   227/  229] train: loss: 0.1066108
[Epoch 98] ogbg-moltoxcast: 0.686552 val loss: 0.298547
[Epoch 98] ogbg-moltoxcast: 0.639778 test loss: 0.346392
[Epoch 99; Iter    28/  229] train: loss: 0.1176257
[Epoch 99; Iter    58/  229] train: loss: 0.1271623
[Epoch 99; Iter    88/  229] train: loss: 0.1243965
[Epoch 99; Iter   118/  229] train: loss: 0.1216343
[Epoch 99; Iter   148/  229] train: loss: 0.1354886
[Epoch 99; Iter   178/  229] train: loss: 0.1633593
[Epoch 99; Iter   208/  229] train: loss: 0.0534753
[Epoch 99] ogbg-moltoxcast: 0.681305 val loss: 0.300526
[Epoch 99] ogbg-moltoxcast: 0.639686 test loss: 0.348115
[Epoch 100; Iter     9/  229] train: loss: 0.0929315
[Epoch 100; Iter    39/  229] train: loss: 0.1137268
[Epoch 100; Iter    69/  229] train: loss: 0.0945224
[Epoch 100; Iter    99/  229] train: loss: 0.1018221
[Epoch 100; Iter   129/  229] train: loss: 0.1016228
[Epoch 100; Iter   159/  229] train: loss: 0.0926092
[Epoch 100; Iter   189/  229] train: loss: 0.1110004
[Epoch 100; Iter   219/  229] train: loss: 0.1075698
[Epoch 100] ogbg-moltoxcast: 0.682896 val loss: 0.303593
[Epoch 100] ogbg-moltoxcast: 0.643897 test loss: 0.346966
[Epoch 101; Iter    20/  229] train: loss: 0.1383582
[Epoch 101; Iter    50/  229] train: loss: 0.1042192
[Epoch 101; Iter    80/  229] train: loss: 0.0901510
[Epoch 101; Iter   110/  229] train: loss: 0.1100664
[Epoch 101; Iter   140/  229] train: loss: 0.1187907
[Epoch 101; Iter   170/  229] train: loss: 0.1149502
[Epoch 101; Iter   200/  229] train: loss: 0.1598600
[Epoch 101] ogbg-moltoxcast: 0.682620 val loss: 0.300965
[Epoch 101] ogbg-moltoxcast: 0.641368 test loss: 0.347544
[Epoch 102; Iter     1/  229] train: loss: 0.0959548
[Epoch 102; Iter    31/  229] train: loss: 0.1054663
[Epoch 102; Iter    61/  229] train: loss: 0.1589488
[Epoch 102; Iter    91/  229] train: loss: 0.1381677
[Epoch 102; Iter   121/  229] train: loss: 0.1203222
[Epoch 102; Iter   151/  229] train: loss: 0.1015749
[Epoch 102; Iter   181/  229] train: loss: 0.1486443
[Epoch 102; Iter   211/  229] train: loss: 0.1114234
[Epoch 102] ogbg-moltoxcast: 0.684191 val loss: 0.297177
[Epoch 102] ogbg-moltoxcast: 0.637657 test loss: 0.345974
[Epoch 103; Iter    12/  229] train: loss: 0.0839062
[Epoch 103; Iter    42/  229] train: loss: 0.1098458
[Epoch 103; Iter    72/  229] train: loss: 0.0944038
[Epoch 103; Iter   102/  229] train: loss: 0.1493080
[Epoch 103; Iter   132/  229] train: loss: 0.1338265
[Epoch 103; Iter   162/  229] train: loss: 0.0667980
[Epoch 103; Iter   192/  229] train: loss: 0.1042761
[Epoch 103; Iter   222/  229] train: loss: 0.1318350
[Epoch 103] ogbg-moltoxcast: 0.682966 val loss: 0.300380
[Epoch 103] ogbg-moltoxcast: 0.639591 test loss: 0.346755
[Epoch 104; Iter    23/  229] train: loss: 0.1085862
[Epoch 104; Iter    53/  229] train: loss: 0.0776497
[Epoch 104; Iter    83/  229] train: loss: 0.1019734
[Epoch 104; Iter   113/  229] train: loss: 0.1559292
[Epoch 104; Iter   143/  229] train: loss: 0.1375319
[Epoch 104; Iter   173/  229] train: loss: 0.1140164
[Epoch 104; Iter   203/  229] train: loss: 0.1059767
[Epoch 104] ogbg-moltoxcast: 0.682851 val loss: 0.297857
[Epoch 104] ogbg-moltoxcast: 0.645424 test loss: 0.341858
[Epoch 105; Iter     4/  229] train: loss: 0.1029389
[Epoch 105; Iter    34/  229] train: loss: 0.1070618
[Epoch 105; Iter    64/  229] train: loss: 0.1058847
[Epoch 105; Iter    94/  229] train: loss: 0.1040206
[Epoch 105; Iter   124/  229] train: loss: 0.1384141
[Epoch 105; Iter   154/  229] train: loss: 0.0890402
[Epoch 105; Iter   184/  229] train: loss: 0.0985982
[Epoch 105; Iter   214/  229] train: loss: 0.1261076
[Epoch 105] ogbg-moltoxcast: 0.679959 val loss: 0.302294
[Epoch 105] ogbg-moltoxcast: 0.640969 test loss: 0.346248
[Epoch 106; Iter    15/  229] train: loss: 0.1021495
[Epoch 106; Iter    45/  229] train: loss: 0.0943109
[Epoch 106; Iter    75/  229] train: loss: 0.1407739
[Epoch 106; Iter   105/  229] train: loss: 0.1293378
[Epoch 106; Iter   135/  229] train: loss: 0.1108450
[Epoch 106; Iter   165/  229] train: loss: 0.1240866
[Epoch 106; Iter   195/  229] train: loss: 0.1227208
[Epoch 106; Iter   225/  229] train: loss: 0.1169649
[Epoch 106] ogbg-moltoxcast: 0.682547 val loss: 0.303877
[Epoch 106] ogbg-moltoxcast: 0.640364 test loss: 0.348245
[Epoch 107; Iter    26/  229] train: loss: 0.0930921
[Epoch 107; Iter    56/  229] train: loss: 0.1072106
[Epoch 107; Iter    86/  229] train: loss: 0.1004023
[Epoch 107; Iter   116/  229] train: loss: 0.1049616
[Epoch 107; Iter   146/  229] train: loss: 0.0881017
[Epoch 107; Iter   176/  229] train: loss: 0.1081546
[Epoch 107; Iter   206/  229] train: loss: 0.1463398
[Epoch 107] ogbg-moltoxcast: 0.683790 val loss: 0.302069
[Epoch 92; Iter    11/  229] train: loss: 0.1274397
[Epoch 92; Iter    41/  229] train: loss: 0.1213080
[Epoch 92; Iter    71/  229] train: loss: 0.1257180
[Epoch 92; Iter   101/  229] train: loss: 0.1402698
[Epoch 92; Iter   131/  229] train: loss: 0.1289319
[Epoch 92; Iter   161/  229] train: loss: 0.0990575
[Epoch 92; Iter   191/  229] train: loss: 0.1156934
[Epoch 92; Iter   221/  229] train: loss: 0.1466237
[Epoch 92] ogbg-moltoxcast: 0.648104 val loss: 0.321615
[Epoch 92] ogbg-moltoxcast: 0.642611 test loss: 0.378045
[Epoch 93; Iter    22/  229] train: loss: 0.1014531
[Epoch 93; Iter    52/  229] train: loss: 0.1071603
[Epoch 93; Iter    82/  229] train: loss: 0.1561041
[Epoch 93; Iter   112/  229] train: loss: 0.1173959
[Epoch 93; Iter   142/  229] train: loss: 0.1266123
[Epoch 93; Iter   172/  229] train: loss: 0.1164589
[Epoch 93; Iter   202/  229] train: loss: 0.0904713
[Epoch 93] ogbg-moltoxcast: 0.644855 val loss: 0.318418
[Epoch 93] ogbg-moltoxcast: 0.644532 test loss: 0.363852
[Epoch 94; Iter     3/  229] train: loss: 0.1108987
[Epoch 94; Iter    33/  229] train: loss: 0.1205264
[Epoch 94; Iter    63/  229] train: loss: 0.1395434
[Epoch 94; Iter    93/  229] train: loss: 0.1119385
[Epoch 94; Iter   123/  229] train: loss: 0.1170844
[Epoch 94; Iter   153/  229] train: loss: 0.1676798
[Epoch 94; Iter   183/  229] train: loss: 0.1386076
[Epoch 94; Iter   213/  229] train: loss: 0.0924793
[Epoch 94] ogbg-moltoxcast: 0.652602 val loss: 0.312459
[Epoch 94] ogbg-moltoxcast: 0.646710 test loss: 0.364704
[Epoch 95; Iter    14/  229] train: loss: 0.1237218
[Epoch 95; Iter    44/  229] train: loss: 0.0941129
[Epoch 95; Iter    74/  229] train: loss: 0.1253802
[Epoch 95; Iter   104/  229] train: loss: 0.1326292
[Epoch 95; Iter   134/  229] train: loss: 0.0873763
[Epoch 95; Iter   164/  229] train: loss: 0.1108681
[Epoch 95; Iter   194/  229] train: loss: 0.1245302
[Epoch 95; Iter   224/  229] train: loss: 0.1391934
[Epoch 95] ogbg-moltoxcast: 0.651226 val loss: 0.317340
[Epoch 95] ogbg-moltoxcast: 0.646238 test loss: 0.365276
[Epoch 96; Iter    25/  229] train: loss: 0.1298580
[Epoch 96; Iter    55/  229] train: loss: 0.1092822
[Epoch 96; Iter    85/  229] train: loss: 0.0981508
[Epoch 96; Iter   115/  229] train: loss: 0.1399539
[Epoch 96; Iter   145/  229] train: loss: 0.1099602
[Epoch 96; Iter   175/  229] train: loss: 0.0917393
[Epoch 96; Iter   205/  229] train: loss: 0.1438524
[Epoch 96] ogbg-moltoxcast: 0.645880 val loss: 0.343763
[Epoch 96] ogbg-moltoxcast: 0.645626 test loss: 0.393947
[Epoch 97; Iter     6/  229] train: loss: 0.1202537
[Epoch 97; Iter    36/  229] train: loss: 0.1085001
[Epoch 97; Iter    66/  229] train: loss: 0.0845713
[Epoch 97; Iter    96/  229] train: loss: 0.1023043
[Epoch 97; Iter   126/  229] train: loss: 0.1269825
[Epoch 97; Iter   156/  229] train: loss: 0.0955717
[Epoch 97; Iter   186/  229] train: loss: 0.0948282
[Epoch 97; Iter   216/  229] train: loss: 0.1763349
[Epoch 97] ogbg-moltoxcast: 0.646624 val loss: 0.318233
[Epoch 97] ogbg-moltoxcast: 0.644641 test loss: 0.371589
[Epoch 98; Iter    17/  229] train: loss: 0.1161894
[Epoch 98; Iter    47/  229] train: loss: 0.1203340
[Epoch 98; Iter    77/  229] train: loss: 0.1354423
[Epoch 98; Iter   107/  229] train: loss: 0.1000324
[Epoch 98; Iter   137/  229] train: loss: 0.1240759
[Epoch 98; Iter   167/  229] train: loss: 0.1052751
[Epoch 98; Iter   197/  229] train: loss: 0.1054895
[Epoch 98; Iter   227/  229] train: loss: 0.1386633
[Epoch 98] ogbg-moltoxcast: 0.648654 val loss: 0.338100
[Epoch 98] ogbg-moltoxcast: 0.648148 test loss: 0.394757
[Epoch 99; Iter    28/  229] train: loss: 0.1171851
[Epoch 99; Iter    58/  229] train: loss: 0.1286268
[Epoch 99; Iter    88/  229] train: loss: 0.1187012
[Epoch 99; Iter   118/  229] train: loss: 0.1068041
[Epoch 99; Iter   148/  229] train: loss: 0.1833075
[Epoch 99; Iter   178/  229] train: loss: 0.1420669
[Epoch 99; Iter   208/  229] train: loss: 0.1178837
[Epoch 99] ogbg-moltoxcast: 0.646980 val loss: 0.318481
[Epoch 99] ogbg-moltoxcast: 0.641146 test loss: 0.368878
[Epoch 100; Iter     9/  229] train: loss: 0.0885195
[Epoch 100; Iter    39/  229] train: loss: 0.1313896
[Epoch 100; Iter    69/  229] train: loss: 0.1208507
[Epoch 100; Iter    99/  229] train: loss: 0.1094800
[Epoch 100; Iter   129/  229] train: loss: 0.1621569
[Epoch 100; Iter   159/  229] train: loss: 0.1170705
[Epoch 100; Iter   189/  229] train: loss: 0.1118630
[Epoch 100; Iter   219/  229] train: loss: 0.1118183
[Epoch 100] ogbg-moltoxcast: 0.649006 val loss: 0.314663
[Epoch 100] ogbg-moltoxcast: 0.645565 test loss: 0.366410
[Epoch 101; Iter    20/  229] train: loss: 0.1074822
[Epoch 101; Iter    50/  229] train: loss: 0.0914854
[Epoch 101; Iter    80/  229] train: loss: 0.1083964
[Epoch 101; Iter   110/  229] train: loss: 0.1148572
[Epoch 101; Iter   140/  229] train: loss: 0.0806696
[Epoch 101; Iter   170/  229] train: loss: 0.1270404
[Epoch 101; Iter   200/  229] train: loss: 0.1012101
[Epoch 101] ogbg-moltoxcast: 0.647646 val loss: 0.337579
[Epoch 101] ogbg-moltoxcast: 0.646658 test loss: 0.382652
[Epoch 102; Iter     1/  229] train: loss: 0.1163436
[Epoch 102; Iter    31/  229] train: loss: 0.0850771
[Epoch 102; Iter    61/  229] train: loss: 0.0834761
[Epoch 102; Iter    91/  229] train: loss: 0.1130750
[Epoch 102; Iter   121/  229] train: loss: 0.1085914
[Epoch 102; Iter   151/  229] train: loss: 0.1064736
[Epoch 102; Iter   181/  229] train: loss: 0.1204195
[Epoch 102; Iter   211/  229] train: loss: 0.1182505
[Epoch 102] ogbg-moltoxcast: 0.652304 val loss: 0.313418
[Epoch 102] ogbg-moltoxcast: 0.645901 test loss: 0.364607
[Epoch 103; Iter    12/  229] train: loss: 0.0762955
[Epoch 103; Iter    42/  229] train: loss: 0.1202963
[Epoch 103; Iter    72/  229] train: loss: 0.1156500
[Epoch 103; Iter   102/  229] train: loss: 0.1379547
[Epoch 103; Iter   132/  229] train: loss: 0.1136599
[Epoch 103; Iter   162/  229] train: loss: 0.1120758
[Epoch 103; Iter   192/  229] train: loss: 0.1341366
[Epoch 103; Iter   222/  229] train: loss: 0.1106911
[Epoch 103] ogbg-moltoxcast: 0.649623 val loss: 0.316925
[Epoch 103] ogbg-moltoxcast: 0.647812 test loss: 0.362303
[Epoch 104; Iter    23/  229] train: loss: 0.1107243
[Epoch 104; Iter    53/  229] train: loss: 0.1203157
[Epoch 104; Iter    83/  229] train: loss: 0.1005826
[Epoch 104; Iter   113/  229] train: loss: 0.1433580
[Epoch 104; Iter   143/  229] train: loss: 0.1059829
[Epoch 104; Iter   173/  229] train: loss: 0.1062277
[Epoch 104; Iter   203/  229] train: loss: 0.0880134
[Epoch 104] ogbg-moltoxcast: 0.647682 val loss: 0.312170
[Epoch 104] ogbg-moltoxcast: 0.648757 test loss: 0.358643
[Epoch 105; Iter     4/  229] train: loss: 0.1344530
[Epoch 105; Iter    34/  229] train: loss: 0.1026216
[Epoch 105; Iter    64/  229] train: loss: 0.1002770
[Epoch 105; Iter    94/  229] train: loss: 0.1124608
[Epoch 105; Iter   124/  229] train: loss: 0.1344755
[Epoch 105; Iter   154/  229] train: loss: 0.1103305
[Epoch 105; Iter   184/  229] train: loss: 0.1082614
[Epoch 105; Iter   214/  229] train: loss: 0.1165980
[Epoch 105] ogbg-moltoxcast: 0.649793 val loss: 0.313849
[Epoch 105] ogbg-moltoxcast: 0.646334 test loss: 0.361115
[Epoch 106; Iter    15/  229] train: loss: 0.1143603
[Epoch 106; Iter    45/  229] train: loss: 0.0904128
[Epoch 106; Iter    75/  229] train: loss: 0.1259437
[Epoch 106; Iter   105/  229] train: loss: 0.1032929
[Epoch 106; Iter   135/  229] train: loss: 0.1207131
[Epoch 106; Iter   165/  229] train: loss: 0.1375115
[Epoch 106; Iter   195/  229] train: loss: 0.1115939
[Epoch 106; Iter   225/  229] train: loss: 0.1223635
[Epoch 106] ogbg-moltoxcast: 0.641750 val loss: 0.337552
[Epoch 106] ogbg-moltoxcast: 0.645253 test loss: 0.381706
[Epoch 107; Iter    26/  229] train: loss: 0.1312928
[Epoch 107; Iter    56/  229] train: loss: 0.1091396
[Epoch 107; Iter    86/  229] train: loss: 0.1013066
[Epoch 107; Iter   116/  229] train: loss: 0.0987825
[Epoch 107; Iter   146/  229] train: loss: 0.0857108
[Epoch 107; Iter   176/  229] train: loss: 0.1377674
[Epoch 107; Iter   206/  229] train: loss: 0.0898070
[Epoch 107] ogbg-moltoxcast: 0.644942 val loss: 0.335840
[Epoch 92; Iter    11/  229] train: loss: 0.1092272
[Epoch 92; Iter    41/  229] train: loss: 0.1005094
[Epoch 92; Iter    71/  229] train: loss: 0.1227953
[Epoch 92; Iter   101/  229] train: loss: 0.0969419
[Epoch 92; Iter   131/  229] train: loss: 0.0853181
[Epoch 92; Iter   161/  229] train: loss: 0.0713218
[Epoch 92; Iter   191/  229] train: loss: 0.1074128
[Epoch 92; Iter   221/  229] train: loss: 0.1147566
[Epoch 92] ogbg-moltoxcast: 0.664637 val loss: 0.324568
[Epoch 92] ogbg-moltoxcast: 0.640162 test loss: 0.375808
[Epoch 93; Iter    22/  229] train: loss: 0.0793814
[Epoch 93; Iter    52/  229] train: loss: 0.0709098
[Epoch 93; Iter    82/  229] train: loss: 0.1089488
[Epoch 93; Iter   112/  229] train: loss: 0.1172974
[Epoch 93; Iter   142/  229] train: loss: 0.0898864
[Epoch 93; Iter   172/  229] train: loss: 0.1435969
[Epoch 93; Iter   202/  229] train: loss: 0.1125313
[Epoch 93] ogbg-moltoxcast: 0.666064 val loss: 0.349491
[Epoch 93] ogbg-moltoxcast: 0.637841 test loss: 0.407766
[Epoch 94; Iter     3/  229] train: loss: 0.1686395
[Epoch 94; Iter    33/  229] train: loss: 0.1349227
[Epoch 94; Iter    63/  229] train: loss: 0.1296025
[Epoch 94; Iter    93/  229] train: loss: 0.0786345
[Epoch 94; Iter   123/  229] train: loss: 0.0945685
[Epoch 94; Iter   153/  229] train: loss: 0.1074962
[Epoch 94; Iter   183/  229] train: loss: 0.1193945
[Epoch 94; Iter   213/  229] train: loss: 0.1481933
[Epoch 94] ogbg-moltoxcast: 0.666430 val loss: 0.326796
[Epoch 94] ogbg-moltoxcast: 0.642387 test loss: 0.377854
[Epoch 95; Iter    14/  229] train: loss: 0.1051153
[Epoch 95; Iter    44/  229] train: loss: 0.1145778
[Epoch 95; Iter    74/  229] train: loss: 0.1514999
[Epoch 95; Iter   104/  229] train: loss: 0.1125723
[Epoch 95; Iter   134/  229] train: loss: 0.1251158
[Epoch 95; Iter   164/  229] train: loss: 0.1028070
[Epoch 95; Iter   194/  229] train: loss: 0.0741339
[Epoch 95; Iter   224/  229] train: loss: 0.0970447
[Epoch 95] ogbg-moltoxcast: 0.661939 val loss: 0.392521
[Epoch 95] ogbg-moltoxcast: 0.635845 test loss: 0.461675
[Epoch 96; Iter    25/  229] train: loss: 0.1176678
[Epoch 96; Iter    55/  229] train: loss: 0.0615746
[Epoch 96; Iter    85/  229] train: loss: 0.1154675
[Epoch 96; Iter   115/  229] train: loss: 0.1306314
[Epoch 96; Iter   145/  229] train: loss: 0.1242773
[Epoch 96; Iter   175/  229] train: loss: 0.1387950
[Epoch 96; Iter   205/  229] train: loss: 0.0983266
[Epoch 96] ogbg-moltoxcast: 0.660808 val loss: 0.332398
[Epoch 96] ogbg-moltoxcast: 0.634828 test loss: 0.388247
[Epoch 97; Iter     6/  229] train: loss: 0.1152436
[Epoch 97; Iter    36/  229] train: loss: 0.0902322
[Epoch 97; Iter    66/  229] train: loss: 0.0922710
[Epoch 97; Iter    96/  229] train: loss: 0.0928405
[Epoch 97; Iter   126/  229] train: loss: 0.1173078
[Epoch 97; Iter   156/  229] train: loss: 0.1047653
[Epoch 97; Iter   186/  229] train: loss: 0.0794808
[Epoch 97; Iter   216/  229] train: loss: 0.1125198
[Epoch 97] ogbg-moltoxcast: 0.663923 val loss: 0.488293
[Epoch 97] ogbg-moltoxcast: 0.637648 test loss: 0.568563
[Epoch 98; Iter    17/  229] train: loss: 0.1267624
[Epoch 98; Iter    47/  229] train: loss: 0.1056550
[Epoch 98; Iter    77/  229] train: loss: 0.0922681
[Epoch 98; Iter   107/  229] train: loss: 0.0952465
[Epoch 98; Iter   137/  229] train: loss: 0.1035240
[Epoch 98; Iter   167/  229] train: loss: 0.1273261
[Epoch 98; Iter   197/  229] train: loss: 0.1434976
[Epoch 98; Iter   227/  229] train: loss: 0.1060898
[Epoch 98] ogbg-moltoxcast: 0.656765 val loss: 0.346017
[Epoch 98] ogbg-moltoxcast: 0.634158 test loss: 0.401483
[Epoch 99; Iter    28/  229] train: loss: 0.1300405
[Epoch 99; Iter    58/  229] train: loss: 0.1242961
[Epoch 99; Iter    88/  229] train: loss: 0.1263995
[Epoch 99; Iter   118/  229] train: loss: 0.1175778
[Epoch 99; Iter   148/  229] train: loss: 0.1385971
[Epoch 99; Iter   178/  229] train: loss: 0.1635398
[Epoch 99; Iter   208/  229] train: loss: 0.0491946
[Epoch 99] ogbg-moltoxcast: 0.661336 val loss: 0.450643
[Epoch 99] ogbg-moltoxcast: 0.635374 test loss: 0.524645
[Epoch 100; Iter     9/  229] train: loss: 0.0854526
[Epoch 100; Iter    39/  229] train: loss: 0.1116907
[Epoch 100; Iter    69/  229] train: loss: 0.0967395
[Epoch 100; Iter    99/  229] train: loss: 0.0968108
[Epoch 100; Iter   129/  229] train: loss: 0.1004457
[Epoch 100; Iter   159/  229] train: loss: 0.0892388
[Epoch 100; Iter   189/  229] train: loss: 0.1053972
[Epoch 100; Iter   219/  229] train: loss: 0.1075966
[Epoch 100] ogbg-moltoxcast: 0.660059 val loss: 0.411788
[Epoch 100] ogbg-moltoxcast: 0.637442 test loss: 0.468460
[Epoch 101; Iter    20/  229] train: loss: 0.1422745
[Epoch 101; Iter    50/  229] train: loss: 0.1069695
[Epoch 101; Iter    80/  229] train: loss: 0.0863912
[Epoch 101; Iter   110/  229] train: loss: 0.1067110
[Epoch 101; Iter   140/  229] train: loss: 0.1163620
[Epoch 101; Iter   170/  229] train: loss: 0.1109025
[Epoch 101; Iter   200/  229] train: loss: 0.1520257
[Epoch 101] ogbg-moltoxcast: 0.656562 val loss: 0.329741
[Epoch 101] ogbg-moltoxcast: 0.634030 test loss: 0.386725
[Epoch 102; Iter     1/  229] train: loss: 0.0926118
[Epoch 102; Iter    31/  229] train: loss: 0.1113704
[Epoch 102; Iter    61/  229] train: loss: 0.1520075
[Epoch 102; Iter    91/  229] train: loss: 0.1367536
[Epoch 102; Iter   121/  229] train: loss: 0.1208889
[Epoch 102; Iter   151/  229] train: loss: 0.1025095
[Epoch 102; Iter   181/  229] train: loss: 0.1437854
[Epoch 102; Iter   211/  229] train: loss: 0.1045829
[Epoch 102] ogbg-moltoxcast: 0.658398 val loss: 0.347708
[Epoch 102] ogbg-moltoxcast: 0.633116 test loss: 0.407049
[Epoch 103; Iter    12/  229] train: loss: 0.0924886
[Epoch 103; Iter    42/  229] train: loss: 0.1162202
[Epoch 103; Iter    72/  229] train: loss: 0.0983810
[Epoch 103; Iter   102/  229] train: loss: 0.1425029
[Epoch 103; Iter   132/  229] train: loss: 0.1319798
[Epoch 103; Iter   162/  229] train: loss: 0.0703487
[Epoch 103; Iter   192/  229] train: loss: 0.1103923
[Epoch 103; Iter   222/  229] train: loss: 0.1299762
[Epoch 103] ogbg-moltoxcast: 0.657845 val loss: 0.507789
[Epoch 103] ogbg-moltoxcast: 0.635616 test loss: 0.616648
[Epoch 104; Iter    23/  229] train: loss: 0.1096619
[Epoch 104; Iter    53/  229] train: loss: 0.0770196
[Epoch 104; Iter    83/  229] train: loss: 0.1051326
[Epoch 104; Iter   113/  229] train: loss: 0.1445361
[Epoch 104; Iter   143/  229] train: loss: 0.1381801
[Epoch 104; Iter   173/  229] train: loss: 0.1127032
[Epoch 104; Iter   203/  229] train: loss: 0.1012196
[Epoch 104] ogbg-moltoxcast: 0.658553 val loss: 0.319557
[Epoch 104] ogbg-moltoxcast: 0.638486 test loss: 0.369164
[Epoch 105; Iter     4/  229] train: loss: 0.0982779
[Epoch 105; Iter    34/  229] train: loss: 0.1048759
[Epoch 105; Iter    64/  229] train: loss: 0.0995048
[Epoch 105; Iter    94/  229] train: loss: 0.0995625
[Epoch 105; Iter   124/  229] train: loss: 0.1311671
[Epoch 105; Iter   154/  229] train: loss: 0.0929614
[Epoch 105; Iter   184/  229] train: loss: 0.0951273
[Epoch 105; Iter   214/  229] train: loss: 0.1266907
[Epoch 105] ogbg-moltoxcast: 0.659327 val loss: 0.325049
[Epoch 105] ogbg-moltoxcast: 0.635473 test loss: 0.375716
[Epoch 106; Iter    15/  229] train: loss: 0.1024959
[Epoch 106; Iter    45/  229] train: loss: 0.0882317
[Epoch 106; Iter    75/  229] train: loss: 0.1412411
[Epoch 106; Iter   105/  229] train: loss: 0.1262456
[Epoch 106; Iter   135/  229] train: loss: 0.1098510
[Epoch 106; Iter   165/  229] train: loss: 0.1344589
[Epoch 106; Iter   195/  229] train: loss: 0.1171073
[Epoch 106; Iter   225/  229] train: loss: 0.1197960
[Epoch 106] ogbg-moltoxcast: 0.658058 val loss: 0.423732
[Epoch 106] ogbg-moltoxcast: 0.633356 test loss: 0.534711
[Epoch 107; Iter    26/  229] train: loss: 0.0970557
[Epoch 107; Iter    56/  229] train: loss: 0.1071471
[Epoch 107; Iter    86/  229] train: loss: 0.0933759
[Epoch 107; Iter   116/  229] train: loss: 0.1055823
[Epoch 107; Iter   146/  229] train: loss: 0.0855199
[Epoch 107; Iter   176/  229] train: loss: 0.1084485
[Epoch 107; Iter   206/  229] train: loss: 0.1509431
[Epoch 107] ogbg-moltoxcast: 0.658309 val loss: 0.324155
[Epoch 92; Iter    11/  229] train: loss: 0.1377364
[Epoch 92; Iter    41/  229] train: loss: 0.1313561
[Epoch 92; Iter    71/  229] train: loss: 0.1273460
[Epoch 92; Iter   101/  229] train: loss: 0.1337580
[Epoch 92; Iter   131/  229] train: loss: 0.1443461
[Epoch 92; Iter   161/  229] train: loss: 0.1035891
[Epoch 92; Iter   191/  229] train: loss: 0.1206451
[Epoch 92; Iter   221/  229] train: loss: 0.1477831
[Epoch 92] ogbg-moltoxcast: 0.656783 val loss: 0.300435
[Epoch 92] ogbg-moltoxcast: 0.644788 test loss: 0.350104
[Epoch 93; Iter    22/  229] train: loss: 0.1126378
[Epoch 93; Iter    52/  229] train: loss: 0.1097470
[Epoch 93; Iter    82/  229] train: loss: 0.1649614
[Epoch 93; Iter   112/  229] train: loss: 0.1147740
[Epoch 93; Iter   142/  229] train: loss: 0.1315180
[Epoch 93; Iter   172/  229] train: loss: 0.1225191
[Epoch 93; Iter   202/  229] train: loss: 0.0911946
[Epoch 93] ogbg-moltoxcast: 0.653162 val loss: 0.338145
[Epoch 93] ogbg-moltoxcast: 0.641306 test loss: 0.359268
[Epoch 94; Iter     3/  229] train: loss: 0.1145368
[Epoch 94; Iter    33/  229] train: loss: 0.1235477
[Epoch 94; Iter    63/  229] train: loss: 0.1424771
[Epoch 94; Iter    93/  229] train: loss: 0.1091411
[Epoch 94; Iter   123/  229] train: loss: 0.1220801
[Epoch 94; Iter   153/  229] train: loss: 0.1862537
[Epoch 94; Iter   183/  229] train: loss: 0.1386221
[Epoch 94; Iter   213/  229] train: loss: 0.0989685
[Epoch 94] ogbg-moltoxcast: 0.659965 val loss: 0.335110
[Epoch 94] ogbg-moltoxcast: 0.647729 test loss: 0.355124
[Epoch 95; Iter    14/  229] train: loss: 0.1290001
[Epoch 95; Iter    44/  229] train: loss: 0.0926165
[Epoch 95; Iter    74/  229] train: loss: 0.1315255
[Epoch 95; Iter   104/  229] train: loss: 0.1404853
[Epoch 95; Iter   134/  229] train: loss: 0.1011736
[Epoch 95; Iter   164/  229] train: loss: 0.1160429
[Epoch 95; Iter   194/  229] train: loss: 0.1294974
[Epoch 95; Iter   224/  229] train: loss: 0.1591444
[Epoch 95] ogbg-moltoxcast: 0.652661 val loss: 0.342939
[Epoch 95] ogbg-moltoxcast: 0.639589 test loss: 0.368832
[Epoch 96; Iter    25/  229] train: loss: 0.1300733
[Epoch 96; Iter    55/  229] train: loss: 0.1096635
[Epoch 96; Iter    85/  229] train: loss: 0.0996709
[Epoch 96; Iter   115/  229] train: loss: 0.1461767
[Epoch 96; Iter   145/  229] train: loss: 0.1170368
[Epoch 96; Iter   175/  229] train: loss: 0.1047365
[Epoch 96; Iter   205/  229] train: loss: 0.1578110
[Epoch 96] ogbg-moltoxcast: 0.653382 val loss: 0.303476
[Epoch 96] ogbg-moltoxcast: 0.644039 test loss: 0.368616
[Epoch 97; Iter     6/  229] train: loss: 0.1281998
[Epoch 97; Iter    36/  229] train: loss: 0.1108362
[Epoch 97; Iter    66/  229] train: loss: 0.0927586
[Epoch 97; Iter    96/  229] train: loss: 0.1113528
[Epoch 97; Iter   126/  229] train: loss: 0.1388087
[Epoch 97; Iter   156/  229] train: loss: 0.0994910
[Epoch 97; Iter   186/  229] train: loss: 0.0994381
[Epoch 97; Iter   216/  229] train: loss: 0.1929176
[Epoch 97] ogbg-moltoxcast: 0.647884 val loss: 0.344939
[Epoch 97] ogbg-moltoxcast: 0.639230 test loss: 0.366582
[Epoch 98; Iter    17/  229] train: loss: 0.1301566
[Epoch 98; Iter    47/  229] train: loss: 0.1220903
[Epoch 98; Iter    77/  229] train: loss: 0.1304772
[Epoch 98; Iter   107/  229] train: loss: 0.1027193
[Epoch 98; Iter   137/  229] train: loss: 0.1333224
[Epoch 98; Iter   167/  229] train: loss: 0.1066947
[Epoch 98; Iter   197/  229] train: loss: 0.1118054
[Epoch 98; Iter   227/  229] train: loss: 0.1575352
[Epoch 98] ogbg-moltoxcast: 0.653766 val loss: 0.339491
[Epoch 98] ogbg-moltoxcast: 0.644597 test loss: 0.360890
[Epoch 99; Iter    28/  229] train: loss: 0.1326338
[Epoch 99; Iter    58/  229] train: loss: 0.1312180
[Epoch 99; Iter    88/  229] train: loss: 0.1207236
[Epoch 99; Iter   118/  229] train: loss: 0.1091371
[Epoch 99; Iter   148/  229] train: loss: 0.1935413
[Epoch 99; Iter   178/  229] train: loss: 0.1528324
[Epoch 99; Iter   208/  229] train: loss: 0.1266250
[Epoch 99] ogbg-moltoxcast: 0.650438 val loss: 0.329831
[Epoch 99] ogbg-moltoxcast: 0.640508 test loss: 0.351804
[Epoch 100; Iter     9/  229] train: loss: 0.0973596
[Epoch 100; Iter    39/  229] train: loss: 0.1365730
[Epoch 100; Iter    69/  229] train: loss: 0.1219444
[Epoch 100; Iter    99/  229] train: loss: 0.1114154
[Epoch 100; Iter   129/  229] train: loss: 0.1693196
[Epoch 100; Iter   159/  229] train: loss: 0.1218088
[Epoch 100; Iter   189/  229] train: loss: 0.1246208
[Epoch 100; Iter   219/  229] train: loss: 0.1118109
[Epoch 100] ogbg-moltoxcast: 0.659923 val loss: 0.308418
[Epoch 100] ogbg-moltoxcast: 0.645904 test loss: 0.348687
[Epoch 101; Iter    20/  229] train: loss: 0.1149764
[Epoch 101; Iter    50/  229] train: loss: 0.0967941
[Epoch 101; Iter    80/  229] train: loss: 0.1133401
[Epoch 101; Iter   110/  229] train: loss: 0.1195438
[Epoch 101; Iter   140/  229] train: loss: 0.0849358
[Epoch 101; Iter   170/  229] train: loss: 0.1369203
[Epoch 101; Iter   200/  229] train: loss: 0.1092571
[Epoch 101] ogbg-moltoxcast: 0.651251 val loss: 0.332027
[Epoch 101] ogbg-moltoxcast: 0.640732 test loss: 0.357236
[Epoch 102; Iter     1/  229] train: loss: 0.1292390
[Epoch 102; Iter    31/  229] train: loss: 0.0875322
[Epoch 102; Iter    61/  229] train: loss: 0.0924969
[Epoch 102; Iter    91/  229] train: loss: 0.1159402
[Epoch 102; Iter   121/  229] train: loss: 0.1200836
[Epoch 102; Iter   151/  229] train: loss: 0.1122294
[Epoch 102; Iter   181/  229] train: loss: 0.1289522
[Epoch 102; Iter   211/  229] train: loss: 0.1241232
[Epoch 102] ogbg-moltoxcast: 0.655418 val loss: 0.306365
[Epoch 102] ogbg-moltoxcast: 0.644693 test loss: 0.345879
[Epoch 103; Iter    12/  229] train: loss: 0.0853584
[Epoch 103; Iter    42/  229] train: loss: 0.1306060
[Epoch 103; Iter    72/  229] train: loss: 0.1211260
[Epoch 103; Iter   102/  229] train: loss: 0.1446656
[Epoch 103; Iter   132/  229] train: loss: 0.1189674
[Epoch 103; Iter   162/  229] train: loss: 0.1184784
[Epoch 103; Iter   192/  229] train: loss: 0.1492717
[Epoch 103; Iter   222/  229] train: loss: 0.1252318
[Epoch 103] ogbg-moltoxcast: 0.651778 val loss: 0.350204
[Epoch 103] ogbg-moltoxcast: 0.641960 test loss: 0.366122
[Epoch 104; Iter    23/  229] train: loss: 0.1173113
[Epoch 104; Iter    53/  229] train: loss: 0.1245278
[Epoch 104; Iter    83/  229] train: loss: 0.1030158
[Epoch 104; Iter   113/  229] train: loss: 0.1496293
[Epoch 104; Iter   143/  229] train: loss: 0.1121162
[Epoch 104; Iter   173/  229] train: loss: 0.1071139
[Epoch 104; Iter   203/  229] train: loss: 0.0977992
[Epoch 104] ogbg-moltoxcast: 0.655763 val loss: 0.307082
[Epoch 104] ogbg-moltoxcast: 0.641543 test loss: 0.350295
[Epoch 105; Iter     4/  229] train: loss: 0.1362287
[Epoch 105; Iter    34/  229] train: loss: 0.1132898
[Epoch 105; Iter    64/  229] train: loss: 0.1044878
[Epoch 105; Iter    94/  229] train: loss: 0.1120424
[Epoch 105; Iter   124/  229] train: loss: 0.1458828
[Epoch 105; Iter   154/  229] train: loss: 0.1151721
[Epoch 105; Iter   184/  229] train: loss: 0.1175305
[Epoch 105; Iter   214/  229] train: loss: 0.1196681
[Epoch 105] ogbg-moltoxcast: 0.657282 val loss: 0.310454
[Epoch 105] ogbg-moltoxcast: 0.643315 test loss: 0.356817
[Epoch 106; Iter    15/  229] train: loss: 0.1205628
[Epoch 106; Iter    45/  229] train: loss: 0.0988283
[Epoch 106; Iter    75/  229] train: loss: 0.1371111
[Epoch 106; Iter   105/  229] train: loss: 0.1101539
[Epoch 106; Iter   135/  229] train: loss: 0.1349683
[Epoch 106; Iter   165/  229] train: loss: 0.1440952
[Epoch 106; Iter   195/  229] train: loss: 0.1151868
[Epoch 106; Iter   225/  229] train: loss: 0.1252655
[Epoch 106] ogbg-moltoxcast: 0.652220 val loss: 0.355176
[Epoch 106] ogbg-moltoxcast: 0.637780 test loss: 0.369280
[Epoch 107; Iter    26/  229] train: loss: 0.1348389
[Epoch 107; Iter    56/  229] train: loss: 0.1197281
[Epoch 107; Iter    86/  229] train: loss: 0.1113922
[Epoch 107; Iter   116/  229] train: loss: 0.1093046
[Epoch 107; Iter   146/  229] train: loss: 0.0850475
[Epoch 107; Iter   176/  229] train: loss: 0.1489833
[Epoch 107; Iter   206/  229] train: loss: 0.0932830
[Epoch 107] ogbg-moltoxcast: 0.651533 val loss: 0.357603
[Epoch 92; Iter    11/  229] train: loss: 0.1161274
[Epoch 92; Iter    41/  229] train: loss: 0.1296623
[Epoch 92; Iter    71/  229] train: loss: 0.0862774
[Epoch 92; Iter   101/  229] train: loss: 0.1225547
[Epoch 92; Iter   131/  229] train: loss: 0.0910267
[Epoch 92; Iter   161/  229] train: loss: 0.1109706
[Epoch 92; Iter   191/  229] train: loss: 0.0960934
[Epoch 92; Iter   221/  229] train: loss: 0.1147173
[Epoch 92] ogbg-moltoxcast: 0.664362 val loss: 0.315746
[Epoch 92] ogbg-moltoxcast: 0.642811 test loss: 0.361661
[Epoch 93; Iter    22/  229] train: loss: 0.1127629
[Epoch 93; Iter    52/  229] train: loss: 0.1022557
[Epoch 93; Iter    82/  229] train: loss: 0.0663876
[Epoch 93; Iter   112/  229] train: loss: 0.1109090
[Epoch 93; Iter   142/  229] train: loss: 0.1344065
[Epoch 93; Iter   172/  229] train: loss: 0.1015558
[Epoch 93; Iter   202/  229] train: loss: 0.0957434
[Epoch 93] ogbg-moltoxcast: 0.668282 val loss: 0.320080
[Epoch 93] ogbg-moltoxcast: 0.646131 test loss: 0.363950
[Epoch 94; Iter     3/  229] train: loss: 0.1010383
[Epoch 94; Iter    33/  229] train: loss: 0.1180455
[Epoch 94; Iter    63/  229] train: loss: 0.0934947
[Epoch 94; Iter    93/  229] train: loss: 0.1446435
[Epoch 94; Iter   123/  229] train: loss: 0.1359386
[Epoch 94; Iter   153/  229] train: loss: 0.0700618
[Epoch 94; Iter   183/  229] train: loss: 0.0955840
[Epoch 94; Iter   213/  229] train: loss: 0.1049306
[Epoch 94] ogbg-moltoxcast: 0.665005 val loss: 0.315252
[Epoch 94] ogbg-moltoxcast: 0.641548 test loss: 0.362710
[Epoch 95; Iter    14/  229] train: loss: 0.1290565
[Epoch 95; Iter    44/  229] train: loss: 0.1122696
[Epoch 95; Iter    74/  229] train: loss: 0.1124721
[Epoch 95; Iter   104/  229] train: loss: 0.0976530
[Epoch 95; Iter   134/  229] train: loss: 0.0747188
[Epoch 95; Iter   164/  229] train: loss: 0.1357175
[Epoch 95; Iter   194/  229] train: loss: 0.1156342
[Epoch 95; Iter   224/  229] train: loss: 0.1094732
[Epoch 95] ogbg-moltoxcast: 0.663515 val loss: 0.322693
[Epoch 95] ogbg-moltoxcast: 0.643064 test loss: 0.361384
[Epoch 96; Iter    25/  229] train: loss: 0.1183957
[Epoch 96; Iter    55/  229] train: loss: 0.0955002
[Epoch 96; Iter    85/  229] train: loss: 0.1132169
[Epoch 96; Iter   115/  229] train: loss: 0.0838966
[Epoch 96; Iter   145/  229] train: loss: 0.1171997
[Epoch 96; Iter   175/  229] train: loss: 0.1042222
[Epoch 96; Iter   205/  229] train: loss: 0.1082530
[Epoch 96] ogbg-moltoxcast: 0.665065 val loss: 0.320866
[Epoch 96] ogbg-moltoxcast: 0.642420 test loss: 0.364056
[Epoch 97; Iter     6/  229] train: loss: 0.0623880
[Epoch 97; Iter    36/  229] train: loss: 0.1237689
[Epoch 97; Iter    66/  229] train: loss: 0.0794799
[Epoch 97; Iter    96/  229] train: loss: 0.1754100
[Epoch 97; Iter   126/  229] train: loss: 0.0893623
[Epoch 97; Iter   156/  229] train: loss: 0.0921842
[Epoch 97; Iter   186/  229] train: loss: 0.1091186
[Epoch 97; Iter   216/  229] train: loss: 0.0928718
[Epoch 97] ogbg-moltoxcast: 0.663627 val loss: 0.326445
[Epoch 97] ogbg-moltoxcast: 0.641723 test loss: 0.369130
[Epoch 98; Iter    17/  229] train: loss: 0.1447028
[Epoch 98; Iter    47/  229] train: loss: 0.1186655
[Epoch 98; Iter    77/  229] train: loss: 0.1371608
[Epoch 98; Iter   107/  229] train: loss: 0.1134664
[Epoch 98; Iter   137/  229] train: loss: 0.0911551
[Epoch 98; Iter   167/  229] train: loss: 0.0632908
[Epoch 98; Iter   197/  229] train: loss: 0.1041627
[Epoch 98; Iter   227/  229] train: loss: 0.1392574
[Epoch 98] ogbg-moltoxcast: 0.662386 val loss: 0.326947
[Epoch 98] ogbg-moltoxcast: 0.641571 test loss: 0.370651
[Epoch 99; Iter    28/  229] train: loss: 0.1329330
[Epoch 99; Iter    58/  229] train: loss: 0.0742384
[Epoch 99; Iter    88/  229] train: loss: 0.1162779
[Epoch 99; Iter   118/  229] train: loss: 0.1362250
[Epoch 99; Iter   148/  229] train: loss: 0.1328598
[Epoch 99; Iter   178/  229] train: loss: 0.1190816
[Epoch 99; Iter   208/  229] train: loss: 0.1239283
[Epoch 99] ogbg-moltoxcast: 0.665906 val loss: 0.320351
[Epoch 99] ogbg-moltoxcast: 0.642813 test loss: 0.368098
[Epoch 100; Iter     9/  229] train: loss: 0.0843605
[Epoch 100; Iter    39/  229] train: loss: 0.1237623
[Epoch 100; Iter    69/  229] train: loss: 0.1148578
[Epoch 100; Iter    99/  229] train: loss: 0.1027163
[Epoch 100; Iter   129/  229] train: loss: 0.1318125
[Epoch 100; Iter   159/  229] train: loss: 0.1145600
[Epoch 100; Iter   189/  229] train: loss: 0.1229115
[Epoch 100; Iter   219/  229] train: loss: 0.1797420
[Epoch 100] ogbg-moltoxcast: 0.666168 val loss: 0.324164
[Epoch 100] ogbg-moltoxcast: 0.639812 test loss: 0.368285
[Epoch 101; Iter    20/  229] train: loss: 0.1025163
[Epoch 101; Iter    50/  229] train: loss: 0.1178155
[Epoch 101; Iter    80/  229] train: loss: 0.0940784
[Epoch 101; Iter   110/  229] train: loss: 0.1177477
[Epoch 101; Iter   140/  229] train: loss: 0.1178873
[Epoch 101; Iter   170/  229] train: loss: 0.0993096
[Epoch 101; Iter   200/  229] train: loss: 0.1064572
[Epoch 101] ogbg-moltoxcast: 0.660485 val loss: 0.326554
[Epoch 101] ogbg-moltoxcast: 0.642475 test loss: 0.364691
[Epoch 102; Iter     1/  229] train: loss: 0.1213749
[Epoch 102; Iter    31/  229] train: loss: 0.0912655
[Epoch 102; Iter    61/  229] train: loss: 0.1357494
[Epoch 102; Iter    91/  229] train: loss: 0.1107887
[Epoch 102; Iter   121/  229] train: loss: 0.1002706
[Epoch 102; Iter   151/  229] train: loss: 0.0959677
[Epoch 102; Iter   181/  229] train: loss: 0.0872392
[Epoch 102; Iter   211/  229] train: loss: 0.1290161
[Epoch 102] ogbg-moltoxcast: 0.660636 val loss: 0.328984
[Epoch 102] ogbg-moltoxcast: 0.639931 test loss: 0.366422
[Epoch 103; Iter    12/  229] train: loss: 0.1036873
[Epoch 103; Iter    42/  229] train: loss: 0.1173386
[Epoch 103; Iter    72/  229] train: loss: 0.1137264
[Epoch 103; Iter   102/  229] train: loss: 0.1156436
[Epoch 103; Iter   132/  229] train: loss: 0.1025096
[Epoch 103; Iter   162/  229] train: loss: 0.1466529
[Epoch 103; Iter   192/  229] train: loss: 0.1010512
[Epoch 103; Iter   222/  229] train: loss: 0.1136159
[Epoch 103] ogbg-moltoxcast: 0.661699 val loss: 0.328408
[Epoch 103] ogbg-moltoxcast: 0.639738 test loss: 0.371459
[Epoch 104; Iter    23/  229] train: loss: 0.0948952
[Epoch 104; Iter    53/  229] train: loss: 0.0946025
[Epoch 104; Iter    83/  229] train: loss: 0.1003907
[Epoch 104; Iter   113/  229] train: loss: 0.0938469
[Epoch 104; Iter   143/  229] train: loss: 0.0823520
[Epoch 104; Iter   173/  229] train: loss: 0.0954990
[Epoch 104; Iter   203/  229] train: loss: 0.1149131
[Epoch 104] ogbg-moltoxcast: 0.664140 val loss: 0.326492
[Epoch 104] ogbg-moltoxcast: 0.639411 test loss: 0.371805
[Epoch 105; Iter     4/  229] train: loss: 0.1037562
[Epoch 105; Iter    34/  229] train: loss: 0.0898008
[Epoch 105; Iter    64/  229] train: loss: 0.0961729
[Epoch 105; Iter    94/  229] train: loss: 0.1107252
[Epoch 105; Iter   124/  229] train: loss: 0.0706462
[Epoch 105; Iter   154/  229] train: loss: 0.0888059
[Epoch 105; Iter   184/  229] train: loss: 0.1099623
[Epoch 105; Iter   214/  229] train: loss: 0.1231477
[Epoch 105] ogbg-moltoxcast: 0.659932 val loss: 0.327824
[Epoch 105] ogbg-moltoxcast: 0.638960 test loss: 0.368117
[Epoch 106; Iter    15/  229] train: loss: 0.0719417
[Epoch 106; Iter    45/  229] train: loss: 0.0817997
[Epoch 106; Iter    75/  229] train: loss: 0.0853136
[Epoch 106; Iter   105/  229] train: loss: 0.0916273
[Epoch 106; Iter   135/  229] train: loss: 0.1056861
[Epoch 106; Iter   165/  229] train: loss: 0.0908897
[Epoch 106; Iter   195/  229] train: loss: 0.1578822
[Epoch 106; Iter   225/  229] train: loss: 0.1454036
[Epoch 106] ogbg-moltoxcast: 0.660167 val loss: 0.330819
[Epoch 106] ogbg-moltoxcast: 0.636514 test loss: 0.372447
[Epoch 107; Iter    26/  229] train: loss: 0.0912277
[Epoch 107; Iter    56/  229] train: loss: 0.1104857
[Epoch 107; Iter    86/  229] train: loss: 0.1082364
[Epoch 107; Iter   116/  229] train: loss: 0.1255831
[Epoch 107; Iter   146/  229] train: loss: 0.1053396
[Epoch 107; Iter   176/  229] train: loss: 0.1375564
[Epoch 107; Iter   206/  229] train: loss: 0.1206875
[Epoch 107] ogbg-moltoxcast: 0.662735 val loss: 0.326546
[Epoch 92; Iter    11/  229] train: loss: 0.1197830
[Epoch 92; Iter    41/  229] train: loss: 0.1363424
[Epoch 92; Iter    71/  229] train: loss: 0.0842833
[Epoch 92; Iter   101/  229] train: loss: 0.1224780
[Epoch 92; Iter   131/  229] train: loss: 0.0953102
[Epoch 92; Iter   161/  229] train: loss: 0.1092620
[Epoch 92; Iter   191/  229] train: loss: 0.0963092
[Epoch 92; Iter   221/  229] train: loss: 0.1085704
[Epoch 92] ogbg-moltoxcast: 0.622249 val loss: 0.387101
[Epoch 92] ogbg-moltoxcast: 0.629031 test loss: 0.445967
[Epoch 93; Iter    22/  229] train: loss: 0.1090962
[Epoch 93; Iter    52/  229] train: loss: 0.1053792
[Epoch 93; Iter    82/  229] train: loss: 0.0646509
[Epoch 93; Iter   112/  229] train: loss: 0.1149733
[Epoch 93; Iter   142/  229] train: loss: 0.1335764
[Epoch 93; Iter   172/  229] train: loss: 0.0997259
[Epoch 93; Iter   202/  229] train: loss: 0.0936600
[Epoch 93] ogbg-moltoxcast: 0.624156 val loss: 0.394424
[Epoch 93] ogbg-moltoxcast: 0.627152 test loss: 0.453609
[Epoch 94; Iter     3/  229] train: loss: 0.1057341
[Epoch 94; Iter    33/  229] train: loss: 0.1171666
[Epoch 94; Iter    63/  229] train: loss: 0.0897369
[Epoch 94; Iter    93/  229] train: loss: 0.1423996
[Epoch 94; Iter   123/  229] train: loss: 0.1388694
[Epoch 94; Iter   153/  229] train: loss: 0.0736179
[Epoch 94; Iter   183/  229] train: loss: 0.0986340
[Epoch 94; Iter   213/  229] train: loss: 0.1062995
[Epoch 94] ogbg-moltoxcast: 0.619645 val loss: 0.386179
[Epoch 94] ogbg-moltoxcast: 0.627597 test loss: 0.444723
[Epoch 95; Iter    14/  229] train: loss: 0.1259169
[Epoch 95; Iter    44/  229] train: loss: 0.1150613
[Epoch 95; Iter    74/  229] train: loss: 0.1039710
[Epoch 95; Iter   104/  229] train: loss: 0.0934808
[Epoch 95; Iter   134/  229] train: loss: 0.0770317
[Epoch 95; Iter   164/  229] train: loss: 0.1334389
[Epoch 95; Iter   194/  229] train: loss: 0.1193506
[Epoch 95; Iter   224/  229] train: loss: 0.1088586
[Epoch 95] ogbg-moltoxcast: 0.617910 val loss: 0.394431
[Epoch 95] ogbg-moltoxcast: 0.623527 test loss: 0.451872
[Epoch 96; Iter    25/  229] train: loss: 0.1165350
[Epoch 96; Iter    55/  229] train: loss: 0.0947110
[Epoch 96; Iter    85/  229] train: loss: 0.1160890
[Epoch 96; Iter   115/  229] train: loss: 0.0824235
[Epoch 96; Iter   145/  229] train: loss: 0.1156923
[Epoch 96; Iter   175/  229] train: loss: 0.1087578
[Epoch 96; Iter   205/  229] train: loss: 0.1062408
[Epoch 96] ogbg-moltoxcast: 0.622356 val loss: 0.384849
[Epoch 96] ogbg-moltoxcast: 0.625632 test loss: 0.443529
[Epoch 97; Iter     6/  229] train: loss: 0.0688433
[Epoch 97; Iter    36/  229] train: loss: 0.1257631
[Epoch 97; Iter    66/  229] train: loss: 0.0782226
[Epoch 97; Iter    96/  229] train: loss: 0.1728372
[Epoch 97; Iter   126/  229] train: loss: 0.0834720
[Epoch 97; Iter   156/  229] train: loss: 0.0909867
[Epoch 97; Iter   186/  229] train: loss: 0.1089636
[Epoch 97; Iter   216/  229] train: loss: 0.0894383
[Epoch 97] ogbg-moltoxcast: 0.624666 val loss: 0.393992
[Epoch 97] ogbg-moltoxcast: 0.626151 test loss: 0.456444
[Epoch 98; Iter    17/  229] train: loss: 0.1533074
[Epoch 98; Iter    47/  229] train: loss: 0.1209784
[Epoch 98; Iter    77/  229] train: loss: 0.1273216
[Epoch 98; Iter   107/  229] train: loss: 0.1155804
[Epoch 98; Iter   137/  229] train: loss: 0.0928718
[Epoch 98; Iter   167/  229] train: loss: 0.0674693
[Epoch 98; Iter   197/  229] train: loss: 0.0993442
[Epoch 98; Iter   227/  229] train: loss: 0.1471553
[Epoch 98] ogbg-moltoxcast: 0.618672 val loss: 0.402607
[Epoch 98] ogbg-moltoxcast: 0.623758 test loss: 0.462274
[Epoch 99; Iter    28/  229] train: loss: 0.1351451
[Epoch 99; Iter    58/  229] train: loss: 0.0726112
[Epoch 99; Iter    88/  229] train: loss: 0.1161901
[Epoch 99; Iter   118/  229] train: loss: 0.1410615
[Epoch 99; Iter   148/  229] train: loss: 0.1312638
[Epoch 99; Iter   178/  229] train: loss: 0.1270883
[Epoch 99; Iter   208/  229] train: loss: 0.1231973
[Epoch 99] ogbg-moltoxcast: 0.624807 val loss: 0.393992
[Epoch 99] ogbg-moltoxcast: 0.626650 test loss: 0.457129
[Epoch 100; Iter     9/  229] train: loss: 0.0824560
[Epoch 100; Iter    39/  229] train: loss: 0.1262889
[Epoch 100; Iter    69/  229] train: loss: 0.1152196
[Epoch 100; Iter    99/  229] train: loss: 0.1028866
[Epoch 100; Iter   129/  229] train: loss: 0.1427399
[Epoch 100; Iter   159/  229] train: loss: 0.1171166
[Epoch 100; Iter   189/  229] train: loss: 0.1259580
[Epoch 100; Iter   219/  229] train: loss: 0.1765021
[Epoch 100] ogbg-moltoxcast: 0.620849 val loss: 0.405220
[Epoch 100] ogbg-moltoxcast: 0.627716 test loss: 0.463470
[Epoch 101; Iter    20/  229] train: loss: 0.1037853
[Epoch 101; Iter    50/  229] train: loss: 0.1183060
[Epoch 101; Iter    80/  229] train: loss: 0.0929503
[Epoch 101; Iter   110/  229] train: loss: 0.1214185
[Epoch 101; Iter   140/  229] train: loss: 0.1185121
[Epoch 101; Iter   170/  229] train: loss: 0.1037132
[Epoch 101; Iter   200/  229] train: loss: 0.1057388
[Epoch 101] ogbg-moltoxcast: 0.621509 val loss: 0.398146
[Epoch 101] ogbg-moltoxcast: 0.630442 test loss: 0.453348
[Epoch 102; Iter     1/  229] train: loss: 0.1183882
[Epoch 102; Iter    31/  229] train: loss: 0.0902323
[Epoch 102; Iter    61/  229] train: loss: 0.1311773
[Epoch 102; Iter    91/  229] train: loss: 0.1114549
[Epoch 102; Iter   121/  229] train: loss: 0.1034534
[Epoch 102; Iter   151/  229] train: loss: 0.1007563
[Epoch 102; Iter   181/  229] train: loss: 0.0875377
[Epoch 102; Iter   211/  229] train: loss: 0.1337156
[Epoch 102] ogbg-moltoxcast: 0.619400 val loss: 0.407259
[Epoch 102] ogbg-moltoxcast: 0.628091 test loss: 0.465489
[Epoch 103; Iter    12/  229] train: loss: 0.1055532
[Epoch 103; Iter    42/  229] train: loss: 0.1142244
[Epoch 103; Iter    72/  229] train: loss: 0.1142074
[Epoch 103; Iter   102/  229] train: loss: 0.1153947
[Epoch 103; Iter   132/  229] train: loss: 0.1065297
[Epoch 103; Iter   162/  229] train: loss: 0.1472846
[Epoch 103; Iter   192/  229] train: loss: 0.1107154
[Epoch 103; Iter   222/  229] train: loss: 0.1102142
[Epoch 103] ogbg-moltoxcast: 0.621219 val loss: 0.411705
[Epoch 103] ogbg-moltoxcast: 0.628180 test loss: 0.471663
[Epoch 104; Iter    23/  229] train: loss: 0.0967235
[Epoch 104; Iter    53/  229] train: loss: 0.0918169
[Epoch 104; Iter    83/  229] train: loss: 0.1007001
[Epoch 104; Iter   113/  229] train: loss: 0.1033019
[Epoch 104; Iter   143/  229] train: loss: 0.0853362
[Epoch 104; Iter   173/  229] train: loss: 0.0939625
[Epoch 104; Iter   203/  229] train: loss: 0.1211694
[Epoch 104] ogbg-moltoxcast: 0.626820 val loss: 0.398919
[Epoch 104] ogbg-moltoxcast: 0.629484 test loss: 0.458104
[Epoch 105; Iter     4/  229] train: loss: 0.1013322
[Epoch 105; Iter    34/  229] train: loss: 0.0837781
[Epoch 105; Iter    64/  229] train: loss: 0.0995495
[Epoch 105; Iter    94/  229] train: loss: 0.1147113
[Epoch 105; Iter   124/  229] train: loss: 0.0675819
[Epoch 105; Iter   154/  229] train: loss: 0.0892783
[Epoch 105; Iter   184/  229] train: loss: 0.1110141
[Epoch 105; Iter   214/  229] train: loss: 0.1178904
[Epoch 105] ogbg-moltoxcast: 0.625615 val loss: 0.391522
[Epoch 105] ogbg-moltoxcast: 0.628658 test loss: 0.448063
[Epoch 106; Iter    15/  229] train: loss: 0.0749888
[Epoch 106; Iter    45/  229] train: loss: 0.0807387
[Epoch 106; Iter    75/  229] train: loss: 0.0874377
[Epoch 106; Iter   105/  229] train: loss: 0.0874279
[Epoch 106; Iter   135/  229] train: loss: 0.1044679
[Epoch 106; Iter   165/  229] train: loss: 0.0880627
[Epoch 106; Iter   195/  229] train: loss: 0.1522824
[Epoch 106; Iter   225/  229] train: loss: 0.1325576
[Epoch 106] ogbg-moltoxcast: 0.623847 val loss: 0.398163
[Epoch 106] ogbg-moltoxcast: 0.628359 test loss: 0.457181
[Epoch 107; Iter    26/  229] train: loss: 0.0878528
[Epoch 107; Iter    56/  229] train: loss: 0.1078463
[Epoch 107; Iter    86/  229] train: loss: 0.1064056
[Epoch 107; Iter   116/  229] train: loss: 0.1252163
[Epoch 107; Iter   146/  229] train: loss: 0.1064822
[Epoch 107; Iter   176/  229] train: loss: 0.1390252
[Epoch 107; Iter   206/  229] train: loss: 0.1152734
[Epoch 107] ogbg-moltoxcast: 0.622562 val loss: 0.406305
[Epoch 92; Iter    11/  229] train: loss: 0.1104444
[Epoch 92; Iter    41/  229] train: loss: 0.1053049
[Epoch 92; Iter    71/  229] train: loss: 0.1205687
[Epoch 92; Iter   101/  229] train: loss: 0.0951930
[Epoch 92; Iter   131/  229] train: loss: 0.0838861
[Epoch 92; Iter   161/  229] train: loss: 0.0748314
[Epoch 92; Iter   191/  229] train: loss: 0.1105516
[Epoch 92; Iter   221/  229] train: loss: 0.1183182
[Epoch 92] ogbg-moltoxcast: 0.647373 val loss: 0.341212
[Epoch 92] ogbg-moltoxcast: 0.632251 test loss: 0.401210
[Epoch 93; Iter    22/  229] train: loss: 0.0800050
[Epoch 93; Iter    52/  229] train: loss: 0.0708626
[Epoch 93; Iter    82/  229] train: loss: 0.1126870
[Epoch 93; Iter   112/  229] train: loss: 0.1151440
[Epoch 93; Iter   142/  229] train: loss: 0.0953323
[Epoch 93; Iter   172/  229] train: loss: 0.1363746
[Epoch 93; Iter   202/  229] train: loss: 0.1080799
[Epoch 93] ogbg-moltoxcast: 0.645045 val loss: 0.339532
[Epoch 93] ogbg-moltoxcast: 0.632196 test loss: 0.397696
[Epoch 94; Iter     3/  229] train: loss: 0.1672256
[Epoch 94; Iter    33/  229] train: loss: 0.1305068
[Epoch 94; Iter    63/  229] train: loss: 0.1329554
[Epoch 94; Iter    93/  229] train: loss: 0.0778955
[Epoch 94; Iter   123/  229] train: loss: 0.0958829
[Epoch 94; Iter   153/  229] train: loss: 0.1043550
[Epoch 94; Iter   183/  229] train: loss: 0.1295034
[Epoch 94; Iter   213/  229] train: loss: 0.1498537
[Epoch 94] ogbg-moltoxcast: 0.645096 val loss: 0.345629
[Epoch 94] ogbg-moltoxcast: 0.632587 test loss: 0.408282
[Epoch 95; Iter    14/  229] train: loss: 0.0996325
[Epoch 95; Iter    44/  229] train: loss: 0.1175886
[Epoch 95; Iter    74/  229] train: loss: 0.1493008
[Epoch 95; Iter   104/  229] train: loss: 0.1122262
[Epoch 95; Iter   134/  229] train: loss: 0.1281345
[Epoch 95; Iter   164/  229] train: loss: 0.1021293
[Epoch 95; Iter   194/  229] train: loss: 0.0703949
[Epoch 95; Iter   224/  229] train: loss: 0.0941420
[Epoch 95] ogbg-moltoxcast: 0.643699 val loss: 0.341855
[Epoch 95] ogbg-moltoxcast: 0.630453 test loss: 0.404372
[Epoch 96; Iter    25/  229] train: loss: 0.1161540
[Epoch 96; Iter    55/  229] train: loss: 0.0615084
[Epoch 96; Iter    85/  229] train: loss: 0.1095211
[Epoch 96; Iter   115/  229] train: loss: 0.1354377
[Epoch 96; Iter   145/  229] train: loss: 0.1178068
[Epoch 96; Iter   175/  229] train: loss: 0.1378847
[Epoch 96; Iter   205/  229] train: loss: 0.1005409
[Epoch 96] ogbg-moltoxcast: 0.643701 val loss: 0.343437
[Epoch 96] ogbg-moltoxcast: 0.630906 test loss: 0.406406
[Epoch 97; Iter     6/  229] train: loss: 0.1136748
[Epoch 97; Iter    36/  229] train: loss: 0.0903224
[Epoch 97; Iter    66/  229] train: loss: 0.0946163
[Epoch 97; Iter    96/  229] train: loss: 0.0968922
[Epoch 97; Iter   126/  229] train: loss: 0.1124313
[Epoch 97; Iter   156/  229] train: loss: 0.1044719
[Epoch 97; Iter   186/  229] train: loss: 0.0779812
[Epoch 97; Iter   216/  229] train: loss: 0.1142681
[Epoch 97] ogbg-moltoxcast: 0.646393 val loss: 0.344194
[Epoch 97] ogbg-moltoxcast: 0.634989 test loss: 0.407326
[Epoch 98; Iter    17/  229] train: loss: 0.1233765
[Epoch 98; Iter    47/  229] train: loss: 0.1087874
[Epoch 98; Iter    77/  229] train: loss: 0.0910576
[Epoch 98; Iter   107/  229] train: loss: 0.0964922
[Epoch 98; Iter   137/  229] train: loss: 0.1056586
[Epoch 98; Iter   167/  229] train: loss: 0.1315919
[Epoch 98; Iter   197/  229] train: loss: 0.1370455
[Epoch 98; Iter   227/  229] train: loss: 0.1115008
[Epoch 98] ogbg-moltoxcast: 0.644445 val loss: 0.340991
[Epoch 98] ogbg-moltoxcast: 0.634234 test loss: 0.403226
[Epoch 99; Iter    28/  229] train: loss: 0.1226946
[Epoch 99; Iter    58/  229] train: loss: 0.1295010
[Epoch 99; Iter    88/  229] train: loss: 0.1208972
[Epoch 99; Iter   118/  229] train: loss: 0.1226391
[Epoch 99; Iter   148/  229] train: loss: 0.1325139
[Epoch 99; Iter   178/  229] train: loss: 0.1682273
[Epoch 99; Iter   208/  229] train: loss: 0.0543788
[Epoch 99] ogbg-moltoxcast: 0.646751 val loss: 0.347115
[Epoch 99] ogbg-moltoxcast: 0.635570 test loss: 0.407676
[Epoch 100; Iter     9/  229] train: loss: 0.0855686
[Epoch 100; Iter    39/  229] train: loss: 0.1125376
[Epoch 100; Iter    69/  229] train: loss: 0.0910753
[Epoch 100; Iter    99/  229] train: loss: 0.0911019
[Epoch 100; Iter   129/  229] train: loss: 0.1037264
[Epoch 100; Iter   159/  229] train: loss: 0.0910010
[Epoch 100; Iter   189/  229] train: loss: 0.1044455
[Epoch 100; Iter   219/  229] train: loss: 0.1064483
[Epoch 100] ogbg-moltoxcast: 0.651347 val loss: 0.341178
[Epoch 100] ogbg-moltoxcast: 0.638919 test loss: 0.398949
[Epoch 101; Iter    20/  229] train: loss: 0.1413568
[Epoch 101; Iter    50/  229] train: loss: 0.1066961
[Epoch 101; Iter    80/  229] train: loss: 0.0888833
[Epoch 101; Iter   110/  229] train: loss: 0.1034272
[Epoch 101; Iter   140/  229] train: loss: 0.1191001
[Epoch 101; Iter   170/  229] train: loss: 0.1070265
[Epoch 101; Iter   200/  229] train: loss: 0.1488813
[Epoch 101] ogbg-moltoxcast: 0.645552 val loss: 0.347542
[Epoch 101] ogbg-moltoxcast: 0.631388 test loss: 0.411306
[Epoch 102; Iter     1/  229] train: loss: 0.0946094
[Epoch 102; Iter    31/  229] train: loss: 0.1124641
[Epoch 102; Iter    61/  229] train: loss: 0.1581629
[Epoch 102; Iter    91/  229] train: loss: 0.1353371
[Epoch 102; Iter   121/  229] train: loss: 0.1173771
[Epoch 102; Iter   151/  229] train: loss: 0.0981997
[Epoch 102; Iter   181/  229] train: loss: 0.1438104
[Epoch 102; Iter   211/  229] train: loss: 0.0976903
[Epoch 102] ogbg-moltoxcast: 0.643274 val loss: 0.345356
[Epoch 102] ogbg-moltoxcast: 0.631209 test loss: 0.407006
[Epoch 103; Iter    12/  229] train: loss: 0.0937533
[Epoch 103; Iter    42/  229] train: loss: 0.1170194
[Epoch 103; Iter    72/  229] train: loss: 0.0941816
[Epoch 103; Iter   102/  229] train: loss: 0.1421455
[Epoch 103; Iter   132/  229] train: loss: 0.1287262
[Epoch 103; Iter   162/  229] train: loss: 0.0678657
[Epoch 103; Iter   192/  229] train: loss: 0.1135439
[Epoch 103; Iter   222/  229] train: loss: 0.1227902
[Epoch 103] ogbg-moltoxcast: 0.649480 val loss: 0.344800
[Epoch 103] ogbg-moltoxcast: 0.635514 test loss: 0.403521
[Epoch 104; Iter    23/  229] train: loss: 0.1066581
[Epoch 104; Iter    53/  229] train: loss: 0.0774699
[Epoch 104; Iter    83/  229] train: loss: 0.1032475
[Epoch 104; Iter   113/  229] train: loss: 0.1441234
[Epoch 104; Iter   143/  229] train: loss: 0.1336823
[Epoch 104; Iter   173/  229] train: loss: 0.1121058
[Epoch 104; Iter   203/  229] train: loss: 0.1009460
[Epoch 104] ogbg-moltoxcast: 0.647951 val loss: 0.345358
[Epoch 104] ogbg-moltoxcast: 0.632482 test loss: 0.405186
[Epoch 105; Iter     4/  229] train: loss: 0.1059116
[Epoch 105; Iter    34/  229] train: loss: 0.1038400
[Epoch 105; Iter    64/  229] train: loss: 0.1045892
[Epoch 105; Iter    94/  229] train: loss: 0.0991269
[Epoch 105; Iter   124/  229] train: loss: 0.1325504
[Epoch 105; Iter   154/  229] train: loss: 0.0918464
[Epoch 105; Iter   184/  229] train: loss: 0.1006829
[Epoch 105; Iter   214/  229] train: loss: 0.1338727
[Epoch 105] ogbg-moltoxcast: 0.646013 val loss: 0.346336
[Epoch 105] ogbg-moltoxcast: 0.630280 test loss: 0.407898
[Epoch 106; Iter    15/  229] train: loss: 0.0971132
[Epoch 106; Iter    45/  229] train: loss: 0.0905283
[Epoch 106; Iter    75/  229] train: loss: 0.1403231
[Epoch 106; Iter   105/  229] train: loss: 0.1277626
[Epoch 106; Iter   135/  229] train: loss: 0.1104460
[Epoch 106; Iter   165/  229] train: loss: 0.1280271
[Epoch 106; Iter   195/  229] train: loss: 0.1223451
[Epoch 106; Iter   225/  229] train: loss: 0.1218996
[Epoch 106] ogbg-moltoxcast: 0.646058 val loss: 0.350992
[Epoch 106] ogbg-moltoxcast: 0.633753 test loss: 0.409836
[Epoch 107; Iter    26/  229] train: loss: 0.0935524
[Epoch 107; Iter    56/  229] train: loss: 0.1067276
[Epoch 107; Iter    86/  229] train: loss: 0.1007884
[Epoch 107; Iter   116/  229] train: loss: 0.1037656
[Epoch 107; Iter   146/  229] train: loss: 0.0837970
[Epoch 107; Iter   176/  229] train: loss: 0.1119342
[Epoch 107; Iter   206/  229] train: loss: 0.1477078
[Epoch 107] ogbg-moltoxcast: 0.643646 val loss: 0.354718
[Epoch 92; Iter    11/  229] train: loss: 0.1260974
[Epoch 92; Iter    41/  229] train: loss: 0.1235228
[Epoch 92; Iter    71/  229] train: loss: 0.1206993
[Epoch 92; Iter   101/  229] train: loss: 0.1314742
[Epoch 92; Iter   131/  229] train: loss: 0.1282124
[Epoch 92; Iter   161/  229] train: loss: 0.1004414
[Epoch 92; Iter   191/  229] train: loss: 0.1261164
[Epoch 92; Iter   221/  229] train: loss: 0.1577238
[Epoch 92] ogbg-moltoxcast: 0.621948 val loss: 2.423455
[Epoch 92] ogbg-moltoxcast: 0.609156 test loss: 3.260827
[Epoch 93; Iter    22/  229] train: loss: 0.1054876
[Epoch 93; Iter    52/  229] train: loss: 0.1038711
[Epoch 93; Iter    82/  229] train: loss: 0.1591622
[Epoch 93; Iter   112/  229] train: loss: 0.1126691
[Epoch 93; Iter   142/  229] train: loss: 0.1200997
[Epoch 93; Iter   172/  229] train: loss: 0.1156203
[Epoch 93; Iter   202/  229] train: loss: 0.0957039
[Epoch 93] ogbg-moltoxcast: 0.604537 val loss: 1.890555
[Epoch 93] ogbg-moltoxcast: 0.614912 test loss: 2.712492
[Epoch 94; Iter     3/  229] train: loss: 0.1086376
[Epoch 94; Iter    33/  229] train: loss: 0.1110679
[Epoch 94; Iter    63/  229] train: loss: 0.1404677
[Epoch 94; Iter    93/  229] train: loss: 0.1131158
[Epoch 94; Iter   123/  229] train: loss: 0.1199180
[Epoch 94; Iter   153/  229] train: loss: 0.1720947
[Epoch 94; Iter   183/  229] train: loss: 0.1388559
[Epoch 94; Iter   213/  229] train: loss: 0.0915799
[Epoch 94] ogbg-moltoxcast: 0.627420 val loss: 2.617900
[Epoch 94] ogbg-moltoxcast: 0.615925 test loss: 3.244984
[Epoch 95; Iter    14/  229] train: loss: 0.1176546
[Epoch 95; Iter    44/  229] train: loss: 0.0890559
[Epoch 95; Iter    74/  229] train: loss: 0.1239034
[Epoch 95; Iter   104/  229] train: loss: 0.1287475
[Epoch 95; Iter   134/  229] train: loss: 0.0889033
[Epoch 95; Iter   164/  229] train: loss: 0.1201537
[Epoch 95; Iter   194/  229] train: loss: 0.1353403
[Epoch 95; Iter   224/  229] train: loss: 0.1484865
[Epoch 95] ogbg-moltoxcast: 0.631331 val loss: 1.644718
[Epoch 95] ogbg-moltoxcast: 0.615759 test loss: 2.271453
[Epoch 96; Iter    25/  229] train: loss: 0.1204162
[Epoch 96; Iter    55/  229] train: loss: 0.1094549
[Epoch 96; Iter    85/  229] train: loss: 0.0953489
[Epoch 96; Iter   115/  229] train: loss: 0.1427341
[Epoch 96; Iter   145/  229] train: loss: 0.1142503
[Epoch 96; Iter   175/  229] train: loss: 0.1051855
[Epoch 96; Iter   205/  229] train: loss: 0.1522485
[Epoch 96] ogbg-moltoxcast: 0.631223 val loss: 3.040562
[Epoch 96] ogbg-moltoxcast: 0.616888 test loss: 3.421131
[Epoch 97; Iter     6/  229] train: loss: 0.1229933
[Epoch 97; Iter    36/  229] train: loss: 0.1118462
[Epoch 97; Iter    66/  229] train: loss: 0.0784908
[Epoch 97; Iter    96/  229] train: loss: 0.1036844
[Epoch 97; Iter   126/  229] train: loss: 0.1300091
[Epoch 97; Iter   156/  229] train: loss: 0.0931980
[Epoch 97; Iter   186/  229] train: loss: 0.0979789
[Epoch 97; Iter   216/  229] train: loss: 0.1846091
[Epoch 97] ogbg-moltoxcast: 0.608311 val loss: 2.298188
[Epoch 97] ogbg-moltoxcast: 0.611944 test loss: 3.110623
[Epoch 98; Iter    17/  229] train: loss: 0.1119180
[Epoch 98; Iter    47/  229] train: loss: 0.1191000
[Epoch 98; Iter    77/  229] train: loss: 0.1270457
[Epoch 98; Iter   107/  229] train: loss: 0.0999987
[Epoch 98; Iter   137/  229] train: loss: 0.1284828
[Epoch 98; Iter   167/  229] train: loss: 0.1017829
[Epoch 98; Iter   197/  229] train: loss: 0.1009464
[Epoch 98; Iter   227/  229] train: loss: 0.1416098
[Epoch 98] ogbg-moltoxcast: 0.629184 val loss: 1.903941
[Epoch 98] ogbg-moltoxcast: 0.615992 test loss: 2.532857
[Epoch 99; Iter    28/  229] train: loss: 0.1275679
[Epoch 99; Iter    58/  229] train: loss: 0.1192760
[Epoch 99; Iter    88/  229] train: loss: 0.1137911
[Epoch 99; Iter   118/  229] train: loss: 0.1092741
[Epoch 99; Iter   148/  229] train: loss: 0.1757621
[Epoch 99; Iter   178/  229] train: loss: 0.1437520
[Epoch 99; Iter   208/  229] train: loss: 0.1224903
[Epoch 99] ogbg-moltoxcast: 0.615358 val loss: 2.308856
[Epoch 99] ogbg-moltoxcast: 0.615123 test loss: 2.972761
[Epoch 100; Iter     9/  229] train: loss: 0.0906063
[Epoch 100; Iter    39/  229] train: loss: 0.1254668
[Epoch 100; Iter    69/  229] train: loss: 0.1100215
[Epoch 100; Iter    99/  229] train: loss: 0.1084798
[Epoch 100; Iter   129/  229] train: loss: 0.1626146
[Epoch 100; Iter   159/  229] train: loss: 0.1127431
[Epoch 100; Iter   189/  229] train: loss: 0.1289918
[Epoch 100; Iter   219/  229] train: loss: 0.1084165
[Epoch 100] ogbg-moltoxcast: 0.628020 val loss: 2.461449
[Epoch 100] ogbg-moltoxcast: 0.613709 test loss: 2.967885
[Epoch 101; Iter    20/  229] train: loss: 0.1096266
[Epoch 101; Iter    50/  229] train: loss: 0.1018951
[Epoch 101; Iter    80/  229] train: loss: 0.1147885
[Epoch 101; Iter   110/  229] train: loss: 0.1144149
[Epoch 101; Iter   140/  229] train: loss: 0.0745720
[Epoch 101; Iter   170/  229] train: loss: 0.1344038
[Epoch 101; Iter   200/  229] train: loss: 0.0997762
[Epoch 101] ogbg-moltoxcast: 0.627927 val loss: 2.468072
[Epoch 101] ogbg-moltoxcast: 0.624550 test loss: 3.095979
[Epoch 102; Iter     1/  229] train: loss: 0.1135238
[Epoch 102; Iter    31/  229] train: loss: 0.0812721
[Epoch 102; Iter    61/  229] train: loss: 0.0855800
[Epoch 102; Iter    91/  229] train: loss: 0.1139255
[Epoch 102; Iter   121/  229] train: loss: 0.1070482
[Epoch 102; Iter   151/  229] train: loss: 0.1096696
[Epoch 102; Iter   181/  229] train: loss: 0.1201700
[Epoch 102; Iter   211/  229] train: loss: 0.1159117
[Epoch 102] ogbg-moltoxcast: 0.635298 val loss: 2.190225
[Epoch 102] ogbg-moltoxcast: 0.616984 test loss: 2.904511
[Epoch 103; Iter    12/  229] train: loss: 0.0784168
[Epoch 103; Iter    42/  229] train: loss: 0.1222575
[Epoch 103; Iter    72/  229] train: loss: 0.1135638
[Epoch 103; Iter   102/  229] train: loss: 0.1354214
[Epoch 103; Iter   132/  229] train: loss: 0.1100628
[Epoch 103; Iter   162/  229] train: loss: 0.1170310
[Epoch 103; Iter   192/  229] train: loss: 0.1412605
[Epoch 103; Iter   222/  229] train: loss: 0.1116869
[Epoch 103] ogbg-moltoxcast: 0.614681 val loss: 2.522526
[Epoch 103] ogbg-moltoxcast: 0.608731 test loss: 2.798610
[Epoch 104; Iter    23/  229] train: loss: 0.1140067
[Epoch 104; Iter    53/  229] train: loss: 0.1187053
[Epoch 104; Iter    83/  229] train: loss: 0.0967933
[Epoch 104; Iter   113/  229] train: loss: 0.1493907
[Epoch 104; Iter   143/  229] train: loss: 0.1106880
[Epoch 104; Iter   173/  229] train: loss: 0.0980220
[Epoch 104; Iter   203/  229] train: loss: 0.0849550
[Epoch 104] ogbg-moltoxcast: 0.619489 val loss: 3.225825
[Epoch 104] ogbg-moltoxcast: 0.615229 test loss: 3.335709
[Epoch 105; Iter     4/  229] train: loss: 0.1271483
[Epoch 105; Iter    34/  229] train: loss: 0.1005602
[Epoch 105; Iter    64/  229] train: loss: 0.0931252
[Epoch 105; Iter    94/  229] train: loss: 0.1115637
[Epoch 105; Iter   124/  229] train: loss: 0.1442457
[Epoch 105; Iter   154/  229] train: loss: 0.1082402
[Epoch 105; Iter   184/  229] train: loss: 0.1019484
[Epoch 105; Iter   214/  229] train: loss: 0.1173392
[Epoch 105] ogbg-moltoxcast: 0.625920 val loss: 2.123722
[Epoch 105] ogbg-moltoxcast: 0.613770 test loss: 2.595325
[Epoch 106; Iter    15/  229] train: loss: 0.1143778
[Epoch 106; Iter    45/  229] train: loss: 0.0948419
[Epoch 106; Iter    75/  229] train: loss: 0.1294243
[Epoch 106; Iter   105/  229] train: loss: 0.1011729
[Epoch 106; Iter   135/  229] train: loss: 0.1270877
[Epoch 106; Iter   165/  229] train: loss: 0.1281751
[Epoch 106; Iter   195/  229] train: loss: 0.1120121
[Epoch 106; Iter   225/  229] train: loss: 0.1191720
[Epoch 106] ogbg-moltoxcast: 0.617588 val loss: 2.617319
[Epoch 106] ogbg-moltoxcast: 0.609952 test loss: 2.968673
[Epoch 107; Iter    26/  229] train: loss: 0.1255232
[Epoch 107; Iter    56/  229] train: loss: 0.1115177
[Epoch 107; Iter    86/  229] train: loss: 0.1029491
[Epoch 107; Iter   116/  229] train: loss: 0.1002234
[Epoch 107; Iter   146/  229] train: loss: 0.0807889
[Epoch 107; Iter   176/  229] train: loss: 0.1429896
[Epoch 107; Iter   206/  229] train: loss: 0.0886721
[Epoch 107] ogbg-moltoxcast: 0.627938 val loss: 2.294585
[Epoch 76; Iter    15/  229] train: loss: 0.1516754
[Epoch 76; Iter    45/  229] train: loss: 0.1257138
[Epoch 76; Iter    75/  229] train: loss: 0.2110779
[Epoch 76; Iter   105/  229] train: loss: 0.1249380
[Epoch 76; Iter   135/  229] train: loss: 0.0989254
[Epoch 76; Iter   165/  229] train: loss: 0.1558437
[Epoch 76; Iter   195/  229] train: loss: 0.0833222
[Epoch 76; Iter   225/  229] train: loss: 0.1154949
[Epoch 76] ogbg-moltoxcast: 0.708182 val loss: 0.257546
[Epoch 76] ogbg-moltoxcast: 0.659775 test loss: 0.323984
[Epoch 77; Iter    26/  229] train: loss: 0.1413018
[Epoch 77; Iter    56/  229] train: loss: 0.1218678
[Epoch 77; Iter    86/  229] train: loss: 0.0941015
[Epoch 77; Iter   116/  229] train: loss: 0.1453373
[Epoch 77; Iter   146/  229] train: loss: 0.1159510
[Epoch 77; Iter   176/  229] train: loss: 0.1296290
[Epoch 77; Iter   206/  229] train: loss: 0.1566529
[Epoch 77] ogbg-moltoxcast: 0.706709 val loss: 0.255797
[Epoch 77] ogbg-moltoxcast: 0.657030 test loss: 0.326906
[Epoch 78; Iter     7/  229] train: loss: 0.1513007
[Epoch 78; Iter    37/  229] train: loss: 0.1377399
[Epoch 78; Iter    67/  229] train: loss: 0.0901005
[Epoch 78; Iter    97/  229] train: loss: 0.1395026
[Epoch 78; Iter   127/  229] train: loss: 0.1358119
[Epoch 78; Iter   157/  229] train: loss: 0.1122750
[Epoch 78; Iter   187/  229] train: loss: 0.1098109
[Epoch 78; Iter   217/  229] train: loss: 0.1148407
[Epoch 78] ogbg-moltoxcast: 0.710009 val loss: 0.259560
[Epoch 78] ogbg-moltoxcast: 0.660368 test loss: 0.329657
[Epoch 79; Iter    18/  229] train: loss: 0.0935964
[Epoch 79; Iter    48/  229] train: loss: 0.1324403
[Epoch 79; Iter    78/  229] train: loss: 0.1006164
[Epoch 79; Iter   108/  229] train: loss: 0.1407294
[Epoch 79; Iter   138/  229] train: loss: 0.1072971
[Epoch 79; Iter   168/  229] train: loss: 0.0877221
[Epoch 79; Iter   198/  229] train: loss: 0.0763857
[Epoch 79; Iter   228/  229] train: loss: 0.1702947
[Epoch 79] ogbg-moltoxcast: 0.702666 val loss: 0.261965
[Epoch 79] ogbg-moltoxcast: 0.656418 test loss: 0.328919
[Epoch 80; Iter    29/  229] train: loss: 0.1444027
[Epoch 80; Iter    59/  229] train: loss: 0.1213528
[Epoch 80; Iter    89/  229] train: loss: 0.1081954
[Epoch 80; Iter   119/  229] train: loss: 0.1478110
[Epoch 80; Iter   149/  229] train: loss: 0.1488797
[Epoch 80; Iter   179/  229] train: loss: 0.2449027
[Epoch 80; Iter   209/  229] train: loss: 0.1229551
[Epoch 80] ogbg-moltoxcast: 0.713091 val loss: 0.257301
[Epoch 80] ogbg-moltoxcast: 0.662219 test loss: 0.327097
[Epoch 81; Iter    10/  229] train: loss: 0.0883610
[Epoch 81; Iter    40/  229] train: loss: 0.1222015
[Epoch 81; Iter    70/  229] train: loss: 0.1584891
[Epoch 81; Iter   100/  229] train: loss: 0.1273149
[Epoch 81; Iter   130/  229] train: loss: 0.1201618
[Epoch 81; Iter   160/  229] train: loss: 0.1424432
[Epoch 81; Iter   190/  229] train: loss: 0.1720988
[Epoch 81; Iter   220/  229] train: loss: 0.1040593
[Epoch 81] ogbg-moltoxcast: 0.701794 val loss: 0.259513
[Epoch 81] ogbg-moltoxcast: 0.656985 test loss: 0.328161
[Epoch 82; Iter    21/  229] train: loss: 0.0793555
[Epoch 82; Iter    51/  229] train: loss: 0.1256465
[Epoch 82; Iter    81/  229] train: loss: 0.1133175
[Epoch 82; Iter   111/  229] train: loss: 0.1037869
[Epoch 82; Iter   141/  229] train: loss: 0.1597674
[Epoch 82; Iter   171/  229] train: loss: 0.1111415
[Epoch 82; Iter   201/  229] train: loss: 0.0982408
[Epoch 82] ogbg-moltoxcast: 0.702750 val loss: 0.262182
[Epoch 82] ogbg-moltoxcast: 0.653677 test loss: 0.328216
[Epoch 83; Iter     2/  229] train: loss: 0.0993621
[Epoch 83; Iter    32/  229] train: loss: 0.1641933
[Epoch 83; Iter    62/  229] train: loss: 0.1718207
[Epoch 83; Iter    92/  229] train: loss: 0.1057837
[Epoch 83; Iter   122/  229] train: loss: 0.1106265
[Epoch 83; Iter   152/  229] train: loss: 0.0991076
[Epoch 83; Iter   182/  229] train: loss: 0.1461372
[Epoch 83; Iter   212/  229] train: loss: 0.0893729
[Epoch 83] ogbg-moltoxcast: 0.696578 val loss: 0.263509
[Epoch 83] ogbg-moltoxcast: 0.655776 test loss: 0.328577
[Epoch 84; Iter    13/  229] train: loss: 0.1927166
[Epoch 84; Iter    43/  229] train: loss: 0.1447549
[Epoch 84; Iter    73/  229] train: loss: 0.1831507
[Epoch 84; Iter   103/  229] train: loss: 0.0966401
[Epoch 84; Iter   133/  229] train: loss: 0.1062583
[Epoch 84; Iter   163/  229] train: loss: 0.0973467
[Epoch 84; Iter   193/  229] train: loss: 0.1516183
[Epoch 84; Iter   223/  229] train: loss: 0.1351388
[Epoch 84] ogbg-moltoxcast: 0.707484 val loss: 0.257400
[Epoch 84] ogbg-moltoxcast: 0.661030 test loss: 0.330634
[Epoch 85; Iter    24/  229] train: loss: 0.0754881
[Epoch 85; Iter    54/  229] train: loss: 0.1435003
[Epoch 85; Iter    84/  229] train: loss: 0.1241552
[Epoch 85; Iter   114/  229] train: loss: 0.0869251
[Epoch 85; Iter   144/  229] train: loss: 0.1103687
[Epoch 85; Iter   174/  229] train: loss: 0.1441422
[Epoch 85; Iter   204/  229] train: loss: 0.1289707
[Epoch 85] ogbg-moltoxcast: 0.707270 val loss: 0.259207
[Epoch 85] ogbg-moltoxcast: 0.655321 test loss: 0.330886
[Epoch 86; Iter     5/  229] train: loss: 0.0943768
[Epoch 86; Iter    35/  229] train: loss: 0.1736055
[Epoch 86; Iter    65/  229] train: loss: 0.1549749
[Epoch 86; Iter    95/  229] train: loss: 0.1417799
[Epoch 86; Iter   125/  229] train: loss: 0.1116880
[Epoch 86; Iter   155/  229] train: loss: 0.1543038
[Epoch 86; Iter   185/  229] train: loss: 0.1660513
[Epoch 86; Iter   215/  229] train: loss: 0.1419515
[Epoch 86] ogbg-moltoxcast: 0.700854 val loss: 0.260491
[Epoch 86] ogbg-moltoxcast: 0.650628 test loss: 0.329986
[Epoch 87; Iter    16/  229] train: loss: 0.1343838
[Epoch 87; Iter    46/  229] train: loss: 0.1502700
[Epoch 87; Iter    76/  229] train: loss: 0.0776299
[Epoch 87; Iter   106/  229] train: loss: 0.1064354
[Epoch 87; Iter   136/  229] train: loss: 0.1041525
[Epoch 87; Iter   166/  229] train: loss: 0.1253902
[Epoch 87; Iter   196/  229] train: loss: 0.1725759
[Epoch 87; Iter   226/  229] train: loss: 0.1451691
[Epoch 87] ogbg-moltoxcast: 0.705459 val loss: 0.260009
[Epoch 87] ogbg-moltoxcast: 0.655134 test loss: 0.331588
[Epoch 88; Iter    27/  229] train: loss: 0.1120341
[Epoch 88; Iter    57/  229] train: loss: 0.0798438
[Epoch 88; Iter    87/  229] train: loss: 0.1107655
[Epoch 88; Iter   117/  229] train: loss: 0.1120161
[Epoch 88; Iter   147/  229] train: loss: 0.1372761
[Epoch 88; Iter   177/  229] train: loss: 0.0921308
[Epoch 88; Iter   207/  229] train: loss: 0.1143455
[Epoch 88] ogbg-moltoxcast: 0.702350 val loss: 0.261741
[Epoch 88] ogbg-moltoxcast: 0.656393 test loss: 0.326926
[Epoch 89; Iter     8/  229] train: loss: 0.1182712
[Epoch 89; Iter    38/  229] train: loss: 0.1436438
[Epoch 89; Iter    68/  229] train: loss: 0.1179347
[Epoch 89; Iter    98/  229] train: loss: 0.1448350
[Epoch 89; Iter   128/  229] train: loss: 0.1696409
[Epoch 89; Iter   158/  229] train: loss: 0.1217455
[Epoch 89; Iter   188/  229] train: loss: 0.0726266
[Epoch 89; Iter   218/  229] train: loss: 0.1317188
[Epoch 89] ogbg-moltoxcast: 0.704228 val loss: 0.260802
[Epoch 89] ogbg-moltoxcast: 0.653087 test loss: 0.333866
[Epoch 90; Iter    19/  229] train: loss: 0.1045841
[Epoch 90; Iter    49/  229] train: loss: 0.1068594
[Epoch 90; Iter    79/  229] train: loss: 0.0904519
[Epoch 90; Iter   109/  229] train: loss: 0.1159616
[Epoch 90; Iter   139/  229] train: loss: 0.1660443
[Epoch 90; Iter   169/  229] train: loss: 0.1589657
[Epoch 90; Iter   199/  229] train: loss: 0.1434389
[Epoch 90; Iter   229/  229] train: loss: 0.1654634
[Epoch 90] ogbg-moltoxcast: 0.705197 val loss: 0.261316
[Epoch 90] ogbg-moltoxcast: 0.652878 test loss: 0.332492
[Epoch 91; Iter    30/  229] train: loss: 0.0936314
[Epoch 91; Iter    60/  229] train: loss: 0.1174171
[Epoch 91; Iter    90/  229] train: loss: 0.1156662
[Epoch 91; Iter   120/  229] train: loss: 0.1327428
[Epoch 91; Iter   150/  229] train: loss: 0.0902285
[Epoch 91; Iter   180/  229] train: loss: 0.1557158
[Epoch 91; Iter   210/  229] train: loss: 0.1401102
[Epoch 91] ogbg-moltoxcast: 0.705242 val loss: 0.260983
[Epoch 91] ogbg-moltoxcast: 0.657092 test loss: 0.333122
[Epoch 76; Iter    15/  229] train: loss: 0.1186640
[Epoch 76; Iter    45/  229] train: loss: 0.1349458
[Epoch 76; Iter    75/  229] train: loss: 0.1459191
[Epoch 76; Iter   105/  229] train: loss: 0.0968128
[Epoch 76; Iter   135/  229] train: loss: 0.1879648
[Epoch 76; Iter   165/  229] train: loss: 0.1050539
[Epoch 76; Iter   195/  229] train: loss: 0.1339436
[Epoch 76; Iter   225/  229] train: loss: 0.1038949
[Epoch 76] ogbg-moltoxcast: 0.690059 val loss: 0.925041
[Epoch 76] ogbg-moltoxcast: 0.660176 test loss: 0.322863
[Epoch 77; Iter    26/  229] train: loss: 0.1567417
[Epoch 77; Iter    56/  229] train: loss: 0.1100883
[Epoch 77; Iter    86/  229] train: loss: 0.2034928
[Epoch 77; Iter   116/  229] train: loss: 0.1703392
[Epoch 77; Iter   146/  229] train: loss: 0.1425924
[Epoch 77; Iter   176/  229] train: loss: 0.1611566
[Epoch 77; Iter   206/  229] train: loss: 0.1495003
[Epoch 77] ogbg-moltoxcast: 0.693172 val loss: 0.267285
[Epoch 77] ogbg-moltoxcast: 0.658740 test loss: 0.319094
[Epoch 78; Iter     7/  229] train: loss: 0.1385339
[Epoch 78; Iter    37/  229] train: loss: 0.1368604
[Epoch 78; Iter    67/  229] train: loss: 0.1249177
[Epoch 78; Iter    97/  229] train: loss: 0.0954024
[Epoch 78; Iter   127/  229] train: loss: 0.1227423
[Epoch 78; Iter   157/  229] train: loss: 0.1236674
[Epoch 78; Iter   187/  229] train: loss: 0.1683469
[Epoch 78; Iter   217/  229] train: loss: 0.1486775
[Epoch 78] ogbg-moltoxcast: 0.691386 val loss: 0.270269
[Epoch 78] ogbg-moltoxcast: 0.659234 test loss: 0.321879
[Epoch 79; Iter    18/  229] train: loss: 0.1259206
[Epoch 79; Iter    48/  229] train: loss: 0.1386486
[Epoch 79; Iter    78/  229] train: loss: 0.1742998
[Epoch 79; Iter   108/  229] train: loss: 0.1647261
[Epoch 79; Iter   138/  229] train: loss: 0.1864935
[Epoch 79; Iter   168/  229] train: loss: 0.1645059
[Epoch 79; Iter   198/  229] train: loss: 0.1461007
[Epoch 79; Iter   228/  229] train: loss: 0.1672788
[Epoch 79] ogbg-moltoxcast: 0.689053 val loss: 0.268920
[Epoch 79] ogbg-moltoxcast: 0.663170 test loss: 0.316874
[Epoch 80; Iter    29/  229] train: loss: 0.1472985
[Epoch 80; Iter    59/  229] train: loss: 0.1401699
[Epoch 80; Iter    89/  229] train: loss: 0.1573776
[Epoch 80; Iter   119/  229] train: loss: 0.1187538
[Epoch 80; Iter   149/  229] train: loss: 0.1439054
[Epoch 80; Iter   179/  229] train: loss: 0.1532704
[Epoch 80; Iter   209/  229] train: loss: 0.1480061
[Epoch 80] ogbg-moltoxcast: 0.685897 val loss: 0.272773
[Epoch 80] ogbg-moltoxcast: 0.661194 test loss: 0.321743
[Epoch 81; Iter    10/  229] train: loss: 0.0992415
[Epoch 81; Iter    40/  229] train: loss: 0.1452856
[Epoch 81; Iter    70/  229] train: loss: 0.1430040
[Epoch 81; Iter   100/  229] train: loss: 0.0804935
[Epoch 81; Iter   130/  229] train: loss: 0.0917775
[Epoch 81; Iter   160/  229] train: loss: 0.1543238
[Epoch 81; Iter   190/  229] train: loss: 0.1395002
[Epoch 81; Iter   220/  229] train: loss: 0.1400438
[Epoch 81] ogbg-moltoxcast: 0.689797 val loss: 0.270157
[Epoch 81] ogbg-moltoxcast: 0.663343 test loss: 0.320140
[Epoch 82; Iter    21/  229] train: loss: 0.1389135
[Epoch 82; Iter    51/  229] train: loss: 0.1399201
[Epoch 82; Iter    81/  229] train: loss: 0.1045020
[Epoch 82; Iter   111/  229] train: loss: 0.1130289
[Epoch 82; Iter   141/  229] train: loss: 0.1408804
[Epoch 82; Iter   171/  229] train: loss: 0.1140222
[Epoch 82; Iter   201/  229] train: loss: 0.1438641
[Epoch 82] ogbg-moltoxcast: 0.688300 val loss: 0.272681
[Epoch 82] ogbg-moltoxcast: 0.664178 test loss: 0.320266
[Epoch 83; Iter     2/  229] train: loss: 0.1225699
[Epoch 83; Iter    32/  229] train: loss: 0.1216863
[Epoch 83; Iter    62/  229] train: loss: 0.0946094
[Epoch 83; Iter    92/  229] train: loss: 0.1629137
[Epoch 83; Iter   122/  229] train: loss: 0.1302183
[Epoch 83; Iter   152/  229] train: loss: 0.1477346
[Epoch 83; Iter   182/  229] train: loss: 0.1801952
[Epoch 83; Iter   212/  229] train: loss: 0.1213184
[Epoch 83] ogbg-moltoxcast: 0.693384 val loss: 0.268946
[Epoch 83] ogbg-moltoxcast: 0.661599 test loss: 0.320676
[Epoch 84; Iter    13/  229] train: loss: 0.1510578
[Epoch 84; Iter    43/  229] train: loss: 0.1252884
[Epoch 84; Iter    73/  229] train: loss: 0.1615339
[Epoch 84; Iter   103/  229] train: loss: 0.1207243
[Epoch 84; Iter   133/  229] train: loss: 0.1398383
[Epoch 84; Iter   163/  229] train: loss: 0.0939134
[Epoch 84; Iter   193/  229] train: loss: 0.1396157
[Epoch 84; Iter   223/  229] train: loss: 0.1073102
[Epoch 84] ogbg-moltoxcast: 0.690013 val loss: 0.277931
[Epoch 84] ogbg-moltoxcast: 0.660873 test loss: 0.327097
[Epoch 85; Iter    24/  229] train: loss: 0.1264033
[Epoch 85; Iter    54/  229] train: loss: 0.1133782
[Epoch 85; Iter    84/  229] train: loss: 0.1141270
[Epoch 85; Iter   114/  229] train: loss: 0.1032804
[Epoch 85; Iter   144/  229] train: loss: 0.1416849
[Epoch 85; Iter   174/  229] train: loss: 0.1460932
[Epoch 85; Iter   204/  229] train: loss: 0.1640097
[Epoch 85] ogbg-moltoxcast: 0.690005 val loss: 0.271110
[Epoch 85] ogbg-moltoxcast: 0.655467 test loss: 0.324481
[Epoch 86; Iter     5/  229] train: loss: 0.1885917
[Epoch 86; Iter    35/  229] train: loss: 0.1532487
[Epoch 86; Iter    65/  229] train: loss: 0.1338170
[Epoch 86; Iter    95/  229] train: loss: 0.1603418
[Epoch 86; Iter   125/  229] train: loss: 0.1350468
[Epoch 86; Iter   155/  229] train: loss: 0.1280380
[Epoch 86; Iter   185/  229] train: loss: 0.1456458
[Epoch 86; Iter   215/  229] train: loss: 0.1512364
[Epoch 86] ogbg-moltoxcast: 0.691523 val loss: 0.282047
[Epoch 86] ogbg-moltoxcast: 0.661957 test loss: 0.330338
[Epoch 87; Iter    16/  229] train: loss: 0.1186644
[Epoch 87; Iter    46/  229] train: loss: 0.1250103
[Epoch 87; Iter    76/  229] train: loss: 0.1116126
[Epoch 87; Iter   106/  229] train: loss: 0.1296953
[Epoch 87; Iter   136/  229] train: loss: 0.1365886
[Epoch 87; Iter   166/  229] train: loss: 0.1365872
[Epoch 87; Iter   196/  229] train: loss: 0.1326070
[Epoch 87; Iter   226/  229] train: loss: 0.1271867
[Epoch 87] ogbg-moltoxcast: 0.688302 val loss: 0.295851
[Epoch 87] ogbg-moltoxcast: 0.659744 test loss: 0.329724
[Epoch 88; Iter    27/  229] train: loss: 0.1894460
[Epoch 88; Iter    57/  229] train: loss: 0.1174178
[Epoch 88; Iter    87/  229] train: loss: 0.1153754
[Epoch 88; Iter   117/  229] train: loss: 0.1309561
[Epoch 88; Iter   147/  229] train: loss: 0.1096400
[Epoch 88; Iter   177/  229] train: loss: 0.1279887
[Epoch 88; Iter   207/  229] train: loss: 0.1421267
[Epoch 88] ogbg-moltoxcast: 0.688735 val loss: 0.298904
[Epoch 88] ogbg-moltoxcast: 0.656473 test loss: 0.327104
[Epoch 89; Iter     8/  229] train: loss: 0.1069630
[Epoch 89; Iter    38/  229] train: loss: 0.1140723
[Epoch 89; Iter    68/  229] train: loss: 0.1509909
[Epoch 89; Iter    98/  229] train: loss: 0.1169369
[Epoch 89; Iter   128/  229] train: loss: 0.1251385
[Epoch 89; Iter   158/  229] train: loss: 0.1308448
[Epoch 89; Iter   188/  229] train: loss: 0.1247196
[Epoch 89; Iter   218/  229] train: loss: 0.0973839
[Epoch 89] ogbg-moltoxcast: 0.688516 val loss: 0.281356
[Epoch 89] ogbg-moltoxcast: 0.660045 test loss: 0.336133
[Epoch 90; Iter    19/  229] train: loss: 0.1298024
[Epoch 90; Iter    49/  229] train: loss: 0.1660183
[Epoch 90; Iter    79/  229] train: loss: 0.1657084
[Epoch 90; Iter   109/  229] train: loss: 0.1766809
[Epoch 90; Iter   139/  229] train: loss: 0.1537526
[Epoch 90; Iter   169/  229] train: loss: 0.1377521
[Epoch 90; Iter   199/  229] train: loss: 0.1031968
[Epoch 90; Iter   229/  229] train: loss: 0.1230778
[Epoch 90] ogbg-moltoxcast: 0.684883 val loss: 0.274842
[Epoch 90] ogbg-moltoxcast: 0.657290 test loss: 0.324477
[Epoch 91; Iter    30/  229] train: loss: 0.1366888
[Epoch 91; Iter    60/  229] train: loss: 0.1025818
[Epoch 91; Iter    90/  229] train: loss: 0.1278075
[Epoch 91; Iter   120/  229] train: loss: 0.1087580
[Epoch 91; Iter   150/  229] train: loss: 0.1336156
[Epoch 91; Iter   180/  229] train: loss: 0.1324562
[Epoch 91; Iter   210/  229] train: loss: 0.1579621
[Epoch 91] ogbg-moltoxcast: 0.688359 val loss: 0.276922
[Epoch 91] ogbg-moltoxcast: 0.659456 test loss: 0.326593
[Epoch 76; Iter    15/  229] train: loss: 0.1216180
[Epoch 76; Iter    45/  229] train: loss: 0.1288901
[Epoch 76; Iter    75/  229] train: loss: 0.1514916
[Epoch 76; Iter   105/  229] train: loss: 0.1492043
[Epoch 76; Iter   135/  229] train: loss: 0.1049043
[Epoch 76; Iter   165/  229] train: loss: 0.1363911
[Epoch 76; Iter   195/  229] train: loss: 0.1198963
[Epoch 76; Iter   225/  229] train: loss: 0.1390109
[Epoch 76] ogbg-moltoxcast: 0.684518 val loss: 0.268221
[Epoch 76] ogbg-moltoxcast: 0.651821 test loss: 0.321320
[Epoch 77; Iter    26/  229] train: loss: 0.1266653
[Epoch 77; Iter    56/  229] train: loss: 0.1063505
[Epoch 77; Iter    86/  229] train: loss: 0.1846439
[Epoch 77; Iter   116/  229] train: loss: 0.1266039
[Epoch 77; Iter   146/  229] train: loss: 0.1139984
[Epoch 77; Iter   176/  229] train: loss: 0.1408268
[Epoch 77; Iter   206/  229] train: loss: 0.1384618
[Epoch 77] ogbg-moltoxcast: 0.679536 val loss: 0.273948
[Epoch 77] ogbg-moltoxcast: 0.655712 test loss: 0.315935
[Epoch 78; Iter     7/  229] train: loss: 0.1272261
[Epoch 78; Iter    37/  229] train: loss: 0.1094682
[Epoch 78; Iter    67/  229] train: loss: 0.1002041
[Epoch 78; Iter    97/  229] train: loss: 0.1275194
[Epoch 78; Iter   127/  229] train: loss: 0.1820403
[Epoch 78; Iter   157/  229] train: loss: 0.1077550
[Epoch 78; Iter   187/  229] train: loss: 0.1425039
[Epoch 78; Iter   217/  229] train: loss: 0.1115800
[Epoch 78] ogbg-moltoxcast: 0.683840 val loss: 0.264873
[Epoch 78] ogbg-moltoxcast: 0.655764 test loss: 0.322031
[Epoch 79; Iter    18/  229] train: loss: 0.1847904
[Epoch 79; Iter    48/  229] train: loss: 0.1391112
[Epoch 79; Iter    78/  229] train: loss: 0.1604730
[Epoch 79; Iter   108/  229] train: loss: 0.1411566
[Epoch 79; Iter   138/  229] train: loss: 0.1528254
[Epoch 79; Iter   168/  229] train: loss: 0.1441713
[Epoch 79; Iter   198/  229] train: loss: 0.0913823
[Epoch 79; Iter   228/  229] train: loss: 0.1524176
[Epoch 79] ogbg-moltoxcast: 0.684839 val loss: 0.264734
[Epoch 79] ogbg-moltoxcast: 0.652980 test loss: 0.319514
[Epoch 80; Iter    29/  229] train: loss: 0.1167567
[Epoch 80; Iter    59/  229] train: loss: 0.1138299
[Epoch 80; Iter    89/  229] train: loss: 0.1282360
[Epoch 80; Iter   119/  229] train: loss: 0.1190045
[Epoch 80; Iter   149/  229] train: loss: 0.1290339
[Epoch 80; Iter   179/  229] train: loss: 0.1232306
[Epoch 80; Iter   209/  229] train: loss: 0.1340028
[Epoch 80] ogbg-moltoxcast: 0.684997 val loss: 0.263222
[Epoch 80] ogbg-moltoxcast: 0.655121 test loss: 0.319630
[Epoch 81; Iter    10/  229] train: loss: 0.1278762
[Epoch 81; Iter    40/  229] train: loss: 0.1398017
[Epoch 81; Iter    70/  229] train: loss: 0.1460280
[Epoch 81; Iter   100/  229] train: loss: 0.1371437
[Epoch 81; Iter   130/  229] train: loss: 0.1546746
[Epoch 81; Iter   160/  229] train: loss: 0.1471887
[Epoch 81; Iter   190/  229] train: loss: 0.1447560
[Epoch 81; Iter   220/  229] train: loss: 0.1086786
[Epoch 81] ogbg-moltoxcast: 0.678650 val loss: 0.265647
[Epoch 81] ogbg-moltoxcast: 0.646572 test loss: 0.321958
[Epoch 82; Iter    21/  229] train: loss: 0.0950296
[Epoch 82; Iter    51/  229] train: loss: 0.1422373
[Epoch 82; Iter    81/  229] train: loss: 0.1527483
[Epoch 82; Iter   111/  229] train: loss: 0.1086005
[Epoch 82; Iter   141/  229] train: loss: 0.1053541
[Epoch 82; Iter   171/  229] train: loss: 0.1222141
[Epoch 82; Iter   201/  229] train: loss: 0.1242803
[Epoch 82] ogbg-moltoxcast: 0.683890 val loss: 0.264595
[Epoch 82] ogbg-moltoxcast: 0.655085 test loss: 0.320485
[Epoch 83; Iter     2/  229] train: loss: 0.1794982
[Epoch 83; Iter    32/  229] train: loss: 0.0980214
[Epoch 83; Iter    62/  229] train: loss: 0.1154779
[Epoch 83; Iter    92/  229] train: loss: 0.1311384
[Epoch 83; Iter   122/  229] train: loss: 0.1219626
[Epoch 83; Iter   152/  229] train: loss: 0.0972699
[Epoch 83; Iter   182/  229] train: loss: 0.0902971
[Epoch 83; Iter   212/  229] train: loss: 0.1723235
[Epoch 83] ogbg-moltoxcast: 0.688337 val loss: 0.265024
[Epoch 83] ogbg-moltoxcast: 0.651491 test loss: 0.329065
[Epoch 84; Iter    13/  229] train: loss: 0.1201708
[Epoch 84; Iter    43/  229] train: loss: 0.1170860
[Epoch 84; Iter    73/  229] train: loss: 0.0950276
[Epoch 84; Iter   103/  229] train: loss: 0.1117580
[Epoch 84; Iter   133/  229] train: loss: 0.0809785
[Epoch 84; Iter   163/  229] train: loss: 0.1181768
[Epoch 84; Iter   193/  229] train: loss: 0.1460819
[Epoch 84; Iter   223/  229] train: loss: 0.1139325
[Epoch 84] ogbg-moltoxcast: 0.686263 val loss: 0.265578
[Epoch 84] ogbg-moltoxcast: 0.657934 test loss: 0.318198
[Epoch 85; Iter    24/  229] train: loss: 0.1362413
[Epoch 85; Iter    54/  229] train: loss: 0.1229884
[Epoch 85; Iter    84/  229] train: loss: 0.1222193
[Epoch 85; Iter   114/  229] train: loss: 0.0900758
[Epoch 85; Iter   144/  229] train: loss: 0.1158310
[Epoch 85; Iter   174/  229] train: loss: 0.1787667
[Epoch 85; Iter   204/  229] train: loss: 0.1495861
[Epoch 85] ogbg-moltoxcast: 0.682663 val loss: 0.264648
[Epoch 85] ogbg-moltoxcast: 0.653698 test loss: 0.319798
[Epoch 86; Iter     5/  229] train: loss: 0.1186115
[Epoch 86; Iter    35/  229] train: loss: 0.1295498
[Epoch 86; Iter    65/  229] train: loss: 0.0812607
[Epoch 86; Iter    95/  229] train: loss: 0.1463448
[Epoch 86; Iter   125/  229] train: loss: 0.0805319
[Epoch 86; Iter   155/  229] train: loss: 0.1286198
[Epoch 86; Iter   185/  229] train: loss: 0.1211578
[Epoch 86; Iter   215/  229] train: loss: 0.1591930
[Epoch 86] ogbg-moltoxcast: 0.685425 val loss: 0.262346
[Epoch 86] ogbg-moltoxcast: 0.653080 test loss: 0.321230
[Epoch 87; Iter    16/  229] train: loss: 0.0928775
[Epoch 87; Iter    46/  229] train: loss: 0.1072511
[Epoch 87; Iter    76/  229] train: loss: 0.1330499
[Epoch 87; Iter   106/  229] train: loss: 0.1208631
[Epoch 87; Iter   136/  229] train: loss: 0.1921757
[Epoch 87; Iter   166/  229] train: loss: 0.1152816
[Epoch 87; Iter   196/  229] train: loss: 0.1304796
[Epoch 87; Iter   226/  229] train: loss: 0.1024855
[Epoch 87] ogbg-moltoxcast: 0.689048 val loss: 0.269700
[Epoch 87] ogbg-moltoxcast: 0.650051 test loss: 0.326313
[Epoch 88; Iter    27/  229] train: loss: 0.1431388
[Epoch 88; Iter    57/  229] train: loss: 0.1220671
[Epoch 88; Iter    87/  229] train: loss: 0.1197994
[Epoch 88; Iter   117/  229] train: loss: 0.1504543
[Epoch 88; Iter   147/  229] train: loss: 0.1254318
[Epoch 88; Iter   177/  229] train: loss: 0.1347061
[Epoch 88; Iter   207/  229] train: loss: 0.0998527
[Epoch 88] ogbg-moltoxcast: 0.686474 val loss: 0.265628
[Epoch 88] ogbg-moltoxcast: 0.648011 test loss: 0.326036
[Epoch 89; Iter     8/  229] train: loss: 0.1317554
[Epoch 89; Iter    38/  229] train: loss: 0.1517368
[Epoch 89; Iter    68/  229] train: loss: 0.1531472
[Epoch 89; Iter    98/  229] train: loss: 0.1084116
[Epoch 89; Iter   128/  229] train: loss: 0.1144412
[Epoch 89; Iter   158/  229] train: loss: 0.1110550
[Epoch 89; Iter   188/  229] train: loss: 0.0987934
[Epoch 89; Iter   218/  229] train: loss: 0.1378385
[Epoch 89] ogbg-moltoxcast: 0.688770 val loss: 0.263876
[Epoch 89] ogbg-moltoxcast: 0.649710 test loss: 0.326647
[Epoch 90; Iter    19/  229] train: loss: 0.1294434
[Epoch 90; Iter    49/  229] train: loss: 0.1195644
[Epoch 90; Iter    79/  229] train: loss: 0.1118243
[Epoch 90; Iter   109/  229] train: loss: 0.0889479
[Epoch 90; Iter   139/  229] train: loss: 0.0973006
[Epoch 90; Iter   169/  229] train: loss: 0.1120412
[Epoch 90; Iter   199/  229] train: loss: 0.1635708
[Epoch 90; Iter   229/  229] train: loss: 0.1397034
[Epoch 90] ogbg-moltoxcast: 0.687762 val loss: 0.278005
[Epoch 90] ogbg-moltoxcast: 0.648654 test loss: 0.328560
[Epoch 91; Iter    30/  229] train: loss: 0.1214487
[Epoch 91; Iter    60/  229] train: loss: 0.1542417
[Epoch 91; Iter    90/  229] train: loss: 0.1500910
[Epoch 91; Iter   120/  229] train: loss: 0.1252314
[Epoch 91; Iter   150/  229] train: loss: 0.1551823
[Epoch 91; Iter   180/  229] train: loss: 0.1799817
[Epoch 91; Iter   210/  229] train: loss: 0.1746101
[Epoch 91] ogbg-moltoxcast: 0.682090 val loss: 0.270330
[Epoch 91] ogbg-moltoxcast: 0.647642 test loss: 0.328795
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.640007 test loss: 0.347873
[Epoch 108; Iter     7/  229] train: loss: 0.1207092
[Epoch 108; Iter    37/  229] train: loss: 0.1573373
[Epoch 108; Iter    67/  229] train: loss: 0.1240202
[Epoch 108; Iter    97/  229] train: loss: 0.0847077
[Epoch 108; Iter   127/  229] train: loss: 0.0978692
[Epoch 108; Iter   157/  229] train: loss: 0.0902478
[Epoch 108; Iter   187/  229] train: loss: 0.1139205
[Epoch 108; Iter   217/  229] train: loss: 0.1150698
[Epoch 108] ogbg-moltoxcast: 0.679123 val loss: 0.304123
[Epoch 108] ogbg-moltoxcast: 0.637707 test loss: 0.349486
[Epoch 109; Iter    18/  229] train: loss: 0.1139555
[Epoch 109; Iter    48/  229] train: loss: 0.1125873
[Epoch 109; Iter    78/  229] train: loss: 0.0787338
[Epoch 109; Iter   108/  229] train: loss: 0.1655529
[Epoch 109; Iter   138/  229] train: loss: 0.1750063
[Epoch 109; Iter   168/  229] train: loss: 0.1517951
[Epoch 109; Iter   198/  229] train: loss: 0.1029868
[Epoch 109; Iter   228/  229] train: loss: 0.1538091
[Epoch 109] ogbg-moltoxcast: 0.682374 val loss: 0.304301
[Epoch 109] ogbg-moltoxcast: 0.637279 test loss: 0.354234
[Epoch 110; Iter    29/  229] train: loss: 0.1053314
[Epoch 110; Iter    59/  229] train: loss: 0.1126871
[Epoch 110; Iter    89/  229] train: loss: 0.1755190
[Epoch 110; Iter   119/  229] train: loss: 0.1826221
[Epoch 110; Iter   149/  229] train: loss: 0.1097882
[Epoch 110; Iter   179/  229] train: loss: 0.1533696
[Epoch 110; Iter   209/  229] train: loss: 0.0952108
[Epoch 110] ogbg-moltoxcast: 0.683742 val loss: 0.305518
[Epoch 110] ogbg-moltoxcast: 0.640950 test loss: 0.354646
[Epoch 111; Iter    10/  229] train: loss: 0.1320548
[Epoch 111; Iter    40/  229] train: loss: 0.0823098
[Epoch 111; Iter    70/  229] train: loss: 0.0828600
[Epoch 111; Iter   100/  229] train: loss: 0.1088810
[Epoch 111; Iter   130/  229] train: loss: 0.1220330
[Epoch 111; Iter   160/  229] train: loss: 0.1138881
[Epoch 111; Iter   190/  229] train: loss: 0.0982022
[Epoch 111; Iter   220/  229] train: loss: 0.1293534
[Epoch 111] ogbg-moltoxcast: 0.681174 val loss: 0.304350
[Epoch 111] ogbg-moltoxcast: 0.636050 test loss: 0.353910
[Epoch 112; Iter    21/  229] train: loss: 0.0956068
[Epoch 112; Iter    51/  229] train: loss: 0.0928639
[Epoch 112; Iter    81/  229] train: loss: 0.1128831
[Epoch 112; Iter   111/  229] train: loss: 0.1217343
[Epoch 112; Iter   141/  229] train: loss: 0.1284044
[Epoch 112; Iter   171/  229] train: loss: 0.0937374
[Epoch 112; Iter   201/  229] train: loss: 0.1148705
[Epoch 112] ogbg-moltoxcast: 0.683032 val loss: 0.302769
[Epoch 112] ogbg-moltoxcast: 0.639069 test loss: 0.350963
[Epoch 113; Iter     2/  229] train: loss: 0.0480562
[Epoch 113; Iter    32/  229] train: loss: 0.0988825
[Epoch 113; Iter    62/  229] train: loss: 0.1229880
[Epoch 113; Iter    92/  229] train: loss: 0.1552758
[Epoch 113; Iter   122/  229] train: loss: 0.0683409
[Epoch 113; Iter   152/  229] train: loss: 0.1306525
[Epoch 113; Iter   182/  229] train: loss: 0.0986201
[Epoch 113; Iter   212/  229] train: loss: 0.1117850
[Epoch 113] ogbg-moltoxcast: 0.677969 val loss: 0.303234
[Epoch 113] ogbg-moltoxcast: 0.635752 test loss: 0.352205
[Epoch 114; Iter    13/  229] train: loss: 0.0953450
[Epoch 114; Iter    43/  229] train: loss: 0.1020946
[Epoch 114; Iter    73/  229] train: loss: 0.1092824
[Epoch 114; Iter   103/  229] train: loss: 0.0841682
[Epoch 114; Iter   133/  229] train: loss: 0.1204207
[Epoch 114; Iter   163/  229] train: loss: 0.0805310
[Epoch 114; Iter   193/  229] train: loss: 0.1023889
[Epoch 114; Iter   223/  229] train: loss: 0.0879882
[Epoch 114] ogbg-moltoxcast: 0.677719 val loss: 0.306489
[Epoch 114] ogbg-moltoxcast: 0.633974 test loss: 0.354645
[Epoch 115; Iter    24/  229] train: loss: 0.1054063
[Epoch 115; Iter    54/  229] train: loss: 0.0969784
[Epoch 115; Iter    84/  229] train: loss: 0.1498871
[Epoch 115; Iter   114/  229] train: loss: 0.1120500
[Epoch 115; Iter   144/  229] train: loss: 0.1066701
[Epoch 115; Iter   174/  229] train: loss: 0.0699442
[Epoch 115; Iter   204/  229] train: loss: 0.1431142
[Epoch 115] ogbg-moltoxcast: 0.679853 val loss: 0.304782
[Epoch 115] ogbg-moltoxcast: 0.635099 test loss: 0.352486
[Epoch 116; Iter     5/  229] train: loss: 0.1042434
[Epoch 116; Iter    35/  229] train: loss: 0.0779734
[Epoch 116; Iter    65/  229] train: loss: 0.1880692
[Epoch 116; Iter    95/  229] train: loss: 0.1088390
[Epoch 116; Iter   125/  229] train: loss: 0.1270173
[Epoch 116; Iter   155/  229] train: loss: 0.1269422
[Epoch 116; Iter   185/  229] train: loss: 0.1069084
[Epoch 116; Iter   215/  229] train: loss: 0.0927647
[Epoch 116] ogbg-moltoxcast: 0.676763 val loss: 0.308962
[Epoch 116] ogbg-moltoxcast: 0.634999 test loss: 0.353816
[Epoch 117; Iter    16/  229] train: loss: 0.1315831
[Epoch 117; Iter    46/  229] train: loss: 0.1462986
[Epoch 117; Iter    76/  229] train: loss: 0.1038274
[Epoch 117; Iter   106/  229] train: loss: 0.1390414
[Epoch 117; Iter   136/  229] train: loss: 0.0780581
[Epoch 117; Iter   166/  229] train: loss: 0.0638693
[Epoch 117; Iter   196/  229] train: loss: 0.1648981
[Epoch 117; Iter   226/  229] train: loss: 0.0907862
[Epoch 117] ogbg-moltoxcast: 0.679873 val loss: 0.306852
[Epoch 117] ogbg-moltoxcast: 0.637280 test loss: 0.353575
[Epoch 118; Iter    27/  229] train: loss: 0.0568665
[Epoch 118; Iter    57/  229] train: loss: 0.1059314
[Epoch 118; Iter    87/  229] train: loss: 0.0712726
[Epoch 118; Iter   117/  229] train: loss: 0.1260487
[Epoch 118; Iter   147/  229] train: loss: 0.1055662
[Epoch 118; Iter   177/  229] train: loss: 0.1081587
[Epoch 118; Iter   207/  229] train: loss: 0.1763538
[Epoch 118] ogbg-moltoxcast: 0.680636 val loss: 0.304113
[Epoch 118] ogbg-moltoxcast: 0.636702 test loss: 0.352452
[Epoch 119; Iter     8/  229] train: loss: 0.1270143
[Epoch 119; Iter    38/  229] train: loss: 0.0922585
[Epoch 119; Iter    68/  229] train: loss: 0.1319970
[Epoch 119; Iter    98/  229] train: loss: 0.0663544
[Epoch 119; Iter   128/  229] train: loss: 0.1067665
[Epoch 119; Iter   158/  229] train: loss: 0.0961649
[Epoch 119; Iter   188/  229] train: loss: 0.1459518
[Epoch 119; Iter   218/  229] train: loss: 0.1359748
[Epoch 119] ogbg-moltoxcast: 0.683380 val loss: 0.305369
[Epoch 119] ogbg-moltoxcast: 0.639394 test loss: 0.352481
[Epoch 120; Iter    19/  229] train: loss: 0.1042656
[Epoch 120; Iter    49/  229] train: loss: 0.1209480
[Epoch 120; Iter    79/  229] train: loss: 0.0882897
[Epoch 120; Iter   109/  229] train: loss: 0.1350902
[Epoch 120; Iter   139/  229] train: loss: 0.1202824
[Epoch 120; Iter   169/  229] train: loss: 0.1250328
[Epoch 120; Iter   199/  229] train: loss: 0.0878184
[Epoch 120; Iter   229/  229] train: loss: 0.1651633
[Epoch 120] ogbg-moltoxcast: 0.678963 val loss: 0.308485
[Epoch 120] ogbg-moltoxcast: 0.638922 test loss: 0.352844
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 33.
Statistics on  val_best_checkpoint
mean_pred: -3.0142974853515625
std_pred: 7.10863733291626
mean_targets: nan
std_targets: nan
prcauc: 0.3971316418549038
rocauc: 0.7050234425604306
ogbg-moltoxcast: 0.7050234425604306
OGBNanLabelBCEWithLogitsLoss: 0.278763082006882
Statistics on  test
mean_pred: -2.9406685829162598
std_pred: 9.77160358428955
mean_targets: nan
std_targets: nan
prcauc: 0.36610853543680655
rocauc: 0.6655169417965625
ogbg-moltoxcast: 0.6655169417965625
OGBNanLabelBCEWithLogitsLoss: 0.31871043916406305
Statistics on  train
mean_pred: -3.223285675048828
std_pred: 3.2490434646606445
mean_targets: nan
std_targets: nan
prcauc: 0.548235883546584
rocauc: 0.8631868055290948
ogbg-moltoxcast: 0.8631868055290948
OGBNanLabelBCEWithLogitsLoss: 0.14349556873719244
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.642811 test loss: 0.395995
[Epoch 108; Iter     7/  229] train: loss: 0.1109638
[Epoch 108; Iter    37/  229] train: loss: 0.1506233
[Epoch 108; Iter    67/  229] train: loss: 0.1087944
[Epoch 108; Iter    97/  229] train: loss: 0.1247738
[Epoch 108; Iter   127/  229] train: loss: 0.1795834
[Epoch 108; Iter   157/  229] train: loss: 0.0983304
[Epoch 108; Iter   187/  229] train: loss: 0.0853470
[Epoch 108; Iter   217/  229] train: loss: 0.0938494
[Epoch 108] ogbg-moltoxcast: 0.646772 val loss: 0.327301
[Epoch 108] ogbg-moltoxcast: 0.644193 test loss: 0.381903
[Epoch 109; Iter    18/  229] train: loss: 0.1174191
[Epoch 109; Iter    48/  229] train: loss: 0.1239053
[Epoch 109; Iter    78/  229] train: loss: 0.1141112
[Epoch 109; Iter   108/  229] train: loss: 0.1451026
[Epoch 109; Iter   138/  229] train: loss: 0.1131227
[Epoch 109; Iter   168/  229] train: loss: 0.1340876
[Epoch 109; Iter   198/  229] train: loss: 0.1014716
[Epoch 109; Iter   228/  229] train: loss: 0.0862523
[Epoch 109] ogbg-moltoxcast: 0.641585 val loss: 0.322862
[Epoch 109] ogbg-moltoxcast: 0.642504 test loss: 0.371759
[Epoch 110; Iter    29/  229] train: loss: 0.0669955
[Epoch 110; Iter    59/  229] train: loss: 0.0889580
[Epoch 110; Iter    89/  229] train: loss: 0.0682089
[Epoch 110; Iter   119/  229] train: loss: 0.1217967
[Epoch 110; Iter   149/  229] train: loss: 0.0925283
[Epoch 110; Iter   179/  229] train: loss: 0.1574619
[Epoch 110; Iter   209/  229] train: loss: 0.0925093
[Epoch 110] ogbg-moltoxcast: 0.646512 val loss: 0.319613
[Epoch 110] ogbg-moltoxcast: 0.644096 test loss: 0.366772
[Epoch 111; Iter    10/  229] train: loss: 0.1238968
[Epoch 111; Iter    40/  229] train: loss: 0.0818757
[Epoch 111; Iter    70/  229] train: loss: 0.1040587
[Epoch 111; Iter   100/  229] train: loss: 0.1256616
[Epoch 111; Iter   130/  229] train: loss: 0.1001617
[Epoch 111; Iter   160/  229] train: loss: 0.1284655
[Epoch 111; Iter   190/  229] train: loss: 0.1127502
[Epoch 111; Iter   220/  229] train: loss: 0.0957092
[Epoch 111] ogbg-moltoxcast: 0.650855 val loss: 0.321564
[Epoch 111] ogbg-moltoxcast: 0.643884 test loss: 0.373715
[Epoch 112; Iter    21/  229] train: loss: 0.1116692
[Epoch 112; Iter    51/  229] train: loss: 0.0984449
[Epoch 112; Iter    81/  229] train: loss: 0.0812024
[Epoch 112; Iter   111/  229] train: loss: 0.1031809
[Epoch 112; Iter   141/  229] train: loss: 0.1034948
[Epoch 112; Iter   171/  229] train: loss: 0.1316845
[Epoch 112; Iter   201/  229] train: loss: 0.0879985
[Epoch 112] ogbg-moltoxcast: 0.644720 val loss: 0.331242
[Epoch 112] ogbg-moltoxcast: 0.643662 test loss: 0.386489
[Epoch 113; Iter     2/  229] train: loss: 0.1502884
[Epoch 113; Iter    32/  229] train: loss: 0.0964531
[Epoch 113; Iter    62/  229] train: loss: 0.1444030
[Epoch 113; Iter    92/  229] train: loss: 0.1016712
[Epoch 113; Iter   122/  229] train: loss: 0.1219642
[Epoch 113; Iter   152/  229] train: loss: 0.0967847
[Epoch 113; Iter   182/  229] train: loss: 0.1094285
[Epoch 113; Iter   212/  229] train: loss: 0.1636709
[Epoch 113] ogbg-moltoxcast: 0.645580 val loss: 0.319585
[Epoch 113] ogbg-moltoxcast: 0.640678 test loss: 0.368713
[Epoch 114; Iter    13/  229] train: loss: 0.0872448
[Epoch 114; Iter    43/  229] train: loss: 0.1273251
[Epoch 114; Iter    73/  229] train: loss: 0.1347932
[Epoch 114; Iter   103/  229] train: loss: 0.1084478
[Epoch 114; Iter   133/  229] train: loss: 0.1282034
[Epoch 114; Iter   163/  229] train: loss: 0.1329684
[Epoch 114; Iter   193/  229] train: loss: 0.1404482
[Epoch 114; Iter   223/  229] train: loss: 0.1032830
[Epoch 114] ogbg-moltoxcast: 0.648298 val loss: 0.317878
[Epoch 114] ogbg-moltoxcast: 0.641516 test loss: 0.365253
[Epoch 115; Iter    24/  229] train: loss: 0.0765990
[Epoch 115; Iter    54/  229] train: loss: 0.1115726
[Epoch 115; Iter    84/  229] train: loss: 0.1453835
[Epoch 115; Iter   114/  229] train: loss: 0.0847930
[Epoch 115; Iter   144/  229] train: loss: 0.1393940
[Epoch 115; Iter   174/  229] train: loss: 0.1030205
[Epoch 115; Iter   204/  229] train: loss: 0.0824774
[Epoch 115] ogbg-moltoxcast: 0.647052 val loss: 0.320938
[Epoch 115] ogbg-moltoxcast: 0.642125 test loss: 0.372303
[Epoch 116; Iter     5/  229] train: loss: 0.1650348
[Epoch 116; Iter    35/  229] train: loss: 0.1088095
[Epoch 116; Iter    65/  229] train: loss: 0.1036537
[Epoch 116; Iter    95/  229] train: loss: 0.1091059
[Epoch 116; Iter   125/  229] train: loss: 0.1149872
[Epoch 116; Iter   155/  229] train: loss: 0.1274693
[Epoch 116; Iter   185/  229] train: loss: 0.0865258
[Epoch 116; Iter   215/  229] train: loss: 0.0800317
[Epoch 116] ogbg-moltoxcast: 0.641497 val loss: 0.337646
[Epoch 116] ogbg-moltoxcast: 0.642493 test loss: 0.394266
[Epoch 117; Iter    16/  229] train: loss: 0.1197147
[Epoch 117; Iter    46/  229] train: loss: 0.1278201
[Epoch 117; Iter    76/  229] train: loss: 0.1026463
[Epoch 117; Iter   106/  229] train: loss: 0.1157055
[Epoch 117; Iter   136/  229] train: loss: 0.1231720
[Epoch 117; Iter   166/  229] train: loss: 0.0815624
[Epoch 117; Iter   196/  229] train: loss: 0.1180603
[Epoch 117; Iter   226/  229] train: loss: 0.0946201
[Epoch 117] ogbg-moltoxcast: 0.643346 val loss: 0.342387
[Epoch 117] ogbg-moltoxcast: 0.639657 test loss: 0.399835
[Epoch 118; Iter    27/  229] train: loss: 0.1083387
[Epoch 118; Iter    57/  229] train: loss: 0.0769101
[Epoch 118; Iter    87/  229] train: loss: 0.1096143
[Epoch 118; Iter   117/  229] train: loss: 0.0908271
[Epoch 118; Iter   147/  229] train: loss: 0.1044703
[Epoch 118; Iter   177/  229] train: loss: 0.1256818
[Epoch 118; Iter   207/  229] train: loss: 0.0895165
[Epoch 118] ogbg-moltoxcast: 0.645366 val loss: 0.317743
[Epoch 118] ogbg-moltoxcast: 0.641377 test loss: 0.367237
[Epoch 119; Iter     8/  229] train: loss: 0.0688422
[Epoch 119; Iter    38/  229] train: loss: 0.0982256
[Epoch 119; Iter    68/  229] train: loss: 0.1301076
[Epoch 119; Iter    98/  229] train: loss: 0.0833286
[Epoch 119; Iter   128/  229] train: loss: 0.1402265
[Epoch 119; Iter   158/  229] train: loss: 0.1206005
[Epoch 119; Iter   188/  229] train: loss: 0.1264971
[Epoch 119; Iter   218/  229] train: loss: 0.1716958
[Epoch 119] ogbg-moltoxcast: 0.646800 val loss: 0.321229
[Epoch 119] ogbg-moltoxcast: 0.642089 test loss: 0.371279
[Epoch 120; Iter    19/  229] train: loss: 0.0882232
[Epoch 120; Iter    49/  229] train: loss: 0.1202889
[Epoch 120; Iter    79/  229] train: loss: 0.0791281
[Epoch 120; Iter   109/  229] train: loss: 0.0710609
[Epoch 120; Iter   139/  229] train: loss: 0.1273968
[Epoch 120; Iter   169/  229] train: loss: 0.0840702
[Epoch 120; Iter   199/  229] train: loss: 0.0862564
[Epoch 120; Iter   229/  229] train: loss: 0.1081326
[Epoch 120] ogbg-moltoxcast: 0.642469 val loss: 0.339001
[Epoch 120] ogbg-moltoxcast: 0.641972 test loss: 0.396656
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -2.6251983642578125
std_pred: 2.889798402786255
mean_targets: nan
std_targets: nan
prcauc: 0.3933138133783785
rocauc: 0.6975483340468572
ogbg-moltoxcast: 0.6975483340468572
OGBNanLabelBCEWithLogitsLoss: 0.26462084877079933
Statistics on  test
mean_pred: -2.3578507900238037
std_pred: 2.6597771644592285
mean_targets: nan
std_targets: nan
prcauc: 0.36834930966399887
rocauc: 0.6731701941687819
ogbg-moltoxcast: 0.6731701941687819
OGBNanLabelBCEWithLogitsLoss: 0.3117522155416423
Statistics on  train
mean_pred: -2.97607421875
std_pred: 2.672320604324341
mean_targets: nan
std_targets: nan
prcauc: 0.529153936868541
rocauc: 0.8586055272501244
ogbg-moltoxcast: 0.8586055272501244
OGBNanLabelBCEWithLogitsLoss: 0.15635546651469567
[Epoch 107] ogbg-moltoxcast: 0.645262 test loss: 0.351744
[Epoch 108; Iter     7/  229] train: loss: 0.0950937
[Epoch 108; Iter    37/  229] train: loss: 0.1781456
[Epoch 108; Iter    67/  229] train: loss: 0.1174420
[Epoch 108; Iter    97/  229] train: loss: 0.1387749
[Epoch 108; Iter   127/  229] train: loss: 0.1160400
[Epoch 108; Iter   157/  229] train: loss: 0.1180263
[Epoch 108; Iter   187/  229] train: loss: 0.1171915
[Epoch 108; Iter   217/  229] train: loss: 0.1081761
[Epoch 108] ogbg-moltoxcast: 0.682189 val loss: 0.305440
[Epoch 108] ogbg-moltoxcast: 0.641841 test loss: 0.365455
[Epoch 109; Iter    18/  229] train: loss: 0.0971145
[Epoch 109; Iter    48/  229] train: loss: 0.1222448
[Epoch 109; Iter    78/  229] train: loss: 0.0855241
[Epoch 109; Iter   108/  229] train: loss: 0.1022671
[Epoch 109; Iter   138/  229] train: loss: 0.0681247
[Epoch 109; Iter   168/  229] train: loss: 0.1184488
[Epoch 109; Iter   198/  229] train: loss: 0.1056438
[Epoch 109; Iter   228/  229] train: loss: 0.1207024
[Epoch 109] ogbg-moltoxcast: 0.686381 val loss: 0.301615
[Epoch 109] ogbg-moltoxcast: 0.645347 test loss: 0.360695
[Epoch 110; Iter    29/  229] train: loss: 0.1298892
[Epoch 110; Iter    59/  229] train: loss: 0.1343832
[Epoch 110; Iter    89/  229] train: loss: 0.1283825
[Epoch 110; Iter   119/  229] train: loss: 0.1516072
[Epoch 110; Iter   149/  229] train: loss: 0.1433543
[Epoch 110; Iter   179/  229] train: loss: 0.1529859
[Epoch 110; Iter   209/  229] train: loss: 0.1007621
[Epoch 110] ogbg-moltoxcast: 0.679342 val loss: 0.302980
[Epoch 110] ogbg-moltoxcast: 0.640871 test loss: 0.361345
[Epoch 111; Iter    10/  229] train: loss: 0.0816354
[Epoch 111; Iter    40/  229] train: loss: 0.1129829
[Epoch 111; Iter    70/  229] train: loss: 0.1346254
[Epoch 111; Iter   100/  229] train: loss: 0.1103537
[Epoch 111; Iter   130/  229] train: loss: 0.1270538
[Epoch 111; Iter   160/  229] train: loss: 0.1576006
[Epoch 111; Iter   190/  229] train: loss: 0.0864496
[Epoch 111; Iter   220/  229] train: loss: 0.1047403
[Epoch 111] ogbg-moltoxcast: 0.684609 val loss: 0.302478
[Epoch 111] ogbg-moltoxcast: 0.644942 test loss: 0.362934
[Epoch 112; Iter    21/  229] train: loss: 0.1016428
[Epoch 112; Iter    51/  229] train: loss: 0.1204504
[Epoch 112; Iter    81/  229] train: loss: 0.0746766
[Epoch 112; Iter   111/  229] train: loss: 0.0984552
[Epoch 112; Iter   141/  229] train: loss: 0.1065009
[Epoch 112; Iter   171/  229] train: loss: 0.1137529
[Epoch 112; Iter   201/  229] train: loss: 0.0845444
[Epoch 112] ogbg-moltoxcast: 0.688391 val loss: 0.296682
[Epoch 112] ogbg-moltoxcast: 0.645390 test loss: 0.357149
[Epoch 113; Iter     2/  229] train: loss: 0.1361988
[Epoch 113; Iter    32/  229] train: loss: 0.1412774
[Epoch 113; Iter    62/  229] train: loss: 0.1160016
[Epoch 113; Iter    92/  229] train: loss: 0.1407585
[Epoch 113; Iter   122/  229] train: loss: 0.1614718
[Epoch 113; Iter   152/  229] train: loss: 0.1136800
[Epoch 113; Iter   182/  229] train: loss: 0.1023874
[Epoch 113; Iter   212/  229] train: loss: 0.1007885
[Epoch 113] ogbg-moltoxcast: 0.686746 val loss: 0.306931
[Epoch 113] ogbg-moltoxcast: 0.647055 test loss: 0.365702
[Epoch 114; Iter    13/  229] train: loss: 0.0765344
[Epoch 114; Iter    43/  229] train: loss: 0.1122866
[Epoch 114; Iter    73/  229] train: loss: 0.1069043
[Epoch 114; Iter   103/  229] train: loss: 0.1312383
[Epoch 114; Iter   133/  229] train: loss: 0.1153026
[Epoch 114; Iter   163/  229] train: loss: 0.0817412
[Epoch 114; Iter   193/  229] train: loss: 0.1221750
[Epoch 114; Iter   223/  229] train: loss: 0.0796081
[Epoch 114] ogbg-moltoxcast: 0.683350 val loss: 0.304964
[Epoch 114] ogbg-moltoxcast: 0.644459 test loss: 0.363201
[Epoch 115; Iter    24/  229] train: loss: 0.0799020
[Epoch 115; Iter    54/  229] train: loss: 0.1085128
[Epoch 115; Iter    84/  229] train: loss: 0.1086042
[Epoch 115; Iter   114/  229] train: loss: 0.0777639
[Epoch 115; Iter   144/  229] train: loss: 0.0689903
[Epoch 115; Iter   174/  229] train: loss: 0.1240743
[Epoch 115; Iter   204/  229] train: loss: 0.1462897
[Epoch 115] ogbg-moltoxcast: 0.681597 val loss: 0.304445
[Epoch 115] ogbg-moltoxcast: 0.645012 test loss: 0.360348
[Epoch 116; Iter     5/  229] train: loss: 0.1175116
[Epoch 116; Iter    35/  229] train: loss: 0.1096318
[Epoch 116; Iter    65/  229] train: loss: 0.0991504
[Epoch 116; Iter    95/  229] train: loss: 0.1417796
[Epoch 116; Iter   125/  229] train: loss: 0.0850994
[Epoch 116; Iter   155/  229] train: loss: 0.1551531
[Epoch 116; Iter   185/  229] train: loss: 0.0896200
[Epoch 116; Iter   215/  229] train: loss: 0.1323411
[Epoch 116] ogbg-moltoxcast: 0.681577 val loss: 0.306210
[Epoch 116] ogbg-moltoxcast: 0.646036 test loss: 0.365233
[Epoch 117; Iter    16/  229] train: loss: 0.0959266
[Epoch 117; Iter    46/  229] train: loss: 0.0816748
[Epoch 117; Iter    76/  229] train: loss: 0.0877310
[Epoch 117; Iter   106/  229] train: loss: 0.1029587
[Epoch 117; Iter   136/  229] train: loss: 0.1277256
[Epoch 117; Iter   166/  229] train: loss: 0.1196939
[Epoch 117; Iter   196/  229] train: loss: 0.1331163
[Epoch 117; Iter   226/  229] train: loss: 0.1103022
[Epoch 117] ogbg-moltoxcast: 0.682246 val loss: 0.301926
[Epoch 117] ogbg-moltoxcast: 0.644180 test loss: 0.358982
[Epoch 118; Iter    27/  229] train: loss: 0.0825049
[Epoch 118; Iter    57/  229] train: loss: 0.0942347
[Epoch 118; Iter    87/  229] train: loss: 0.1119346
[Epoch 118; Iter   117/  229] train: loss: 0.1107598
[Epoch 118; Iter   147/  229] train: loss: 0.1151103
[Epoch 118; Iter   177/  229] train: loss: 0.1335208
[Epoch 118; Iter   207/  229] train: loss: 0.1005905
[Epoch 118] ogbg-moltoxcast: 0.683953 val loss: 0.303022
[Epoch 118] ogbg-moltoxcast: 0.644184 test loss: 0.360135
[Epoch 119; Iter     8/  229] train: loss: 0.1037043
[Epoch 119; Iter    38/  229] train: loss: 0.0874802
[Epoch 119; Iter    68/  229] train: loss: 0.0988916
[Epoch 119; Iter    98/  229] train: loss: 0.1070211
[Epoch 119; Iter   128/  229] train: loss: 0.1201007
[Epoch 119; Iter   158/  229] train: loss: 0.1316942
[Epoch 119; Iter   188/  229] train: loss: 0.1083638
[Epoch 119; Iter   218/  229] train: loss: 0.0669108
[Epoch 119] ogbg-moltoxcast: 0.683795 val loss: 0.299130
[Epoch 119] ogbg-moltoxcast: 0.642096 test loss: 0.356846
[Epoch 120; Iter    19/  229] train: loss: 0.1024446
[Epoch 120; Iter    49/  229] train: loss: 0.1089570
[Epoch 120; Iter    79/  229] train: loss: 0.1031668
[Epoch 120; Iter   109/  229] train: loss: 0.1809823
[Epoch 120; Iter   139/  229] train: loss: 0.1015751
[Epoch 120; Iter   169/  229] train: loss: 0.0885211
[Epoch 120; Iter   199/  229] train: loss: 0.0659108
[Epoch 120; Iter   229/  229] train: loss: 0.1123955
[Epoch 120] ogbg-moltoxcast: 0.684234 val loss: 0.300691
[Epoch 120] ogbg-moltoxcast: 0.642915 test loss: 0.358335
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 43.
Statistics on  val_best_checkpoint
mean_pred: -3.1233303546905518
std_pred: 7.640190601348877
mean_targets: nan
std_targets: nan
prcauc: 0.4141378317680665
rocauc: 0.7005344437508857
ogbg-moltoxcast: 0.7005344437508857
OGBNanLabelBCEWithLogitsLoss: 0.2762952369862589
Statistics on  test
mean_pred: -2.7449779510498047
std_pred: 3.3396899700164795
mean_targets: nan
std_targets: nan
prcauc: 0.3607311173597517
rocauc: 0.6670538880367513
ogbg-moltoxcast: 0.6670538880367513
OGBNanLabelBCEWithLogitsLoss: 0.32042543179002303
Statistics on  train
mean_pred: -3.2542922496795654
std_pred: 2.5494911670684814
mean_targets: nan
std_targets: nan
prcauc: 0.5866657850239235
rocauc: 0.8838824148488389
ogbg-moltoxcast: 0.8838824148488389
OGBNanLabelBCEWithLogitsLoss: 0.13430948792977104
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.637536 test loss: 0.377850
[Epoch 108; Iter     7/  229] train: loss: 0.1242688
[Epoch 108; Iter    37/  229] train: loss: 0.1617441
[Epoch 108; Iter    67/  229] train: loss: 0.1216349
[Epoch 108; Iter    97/  229] train: loss: 0.0857537
[Epoch 108; Iter   127/  229] train: loss: 0.0976044
[Epoch 108; Iter   157/  229] train: loss: 0.0918673
[Epoch 108; Iter   187/  229] train: loss: 0.1237200
[Epoch 108; Iter   217/  229] train: loss: 0.1158713
[Epoch 108] ogbg-moltoxcast: 0.659021 val loss: 0.411579
[Epoch 108] ogbg-moltoxcast: 0.636478 test loss: 0.509351
[Epoch 109; Iter    18/  229] train: loss: 0.1154500
[Epoch 109; Iter    48/  229] train: loss: 0.1102914
[Epoch 109; Iter    78/  229] train: loss: 0.0731487
[Epoch 109; Iter   108/  229] train: loss: 0.1570808
[Epoch 109; Iter   138/  229] train: loss: 0.1787020
[Epoch 109; Iter   168/  229] train: loss: 0.1554919
[Epoch 109; Iter   198/  229] train: loss: 0.1022811
[Epoch 109; Iter   228/  229] train: loss: 0.1495625
[Epoch 109] ogbg-moltoxcast: 0.657051 val loss: 0.333291
[Epoch 109] ogbg-moltoxcast: 0.637954 test loss: 0.389199
[Epoch 110; Iter    29/  229] train: loss: 0.1037980
[Epoch 110; Iter    59/  229] train: loss: 0.1178209
[Epoch 110; Iter    89/  229] train: loss: 0.1693753
[Epoch 110; Iter   119/  229] train: loss: 0.1763596
[Epoch 110; Iter   149/  229] train: loss: 0.1119958
[Epoch 110; Iter   179/  229] train: loss: 0.1475949
[Epoch 110; Iter   209/  229] train: loss: 0.1025731
[Epoch 110] ogbg-moltoxcast: 0.654519 val loss: 0.417986
[Epoch 110] ogbg-moltoxcast: 0.633131 test loss: 0.516916
[Epoch 111; Iter    10/  229] train: loss: 0.1292552
[Epoch 111; Iter    40/  229] train: loss: 0.0742513
[Epoch 111; Iter    70/  229] train: loss: 0.0851957
[Epoch 111; Iter   100/  229] train: loss: 0.1066823
[Epoch 111; Iter   130/  229] train: loss: 0.1164501
[Epoch 111; Iter   160/  229] train: loss: 0.1116253
[Epoch 111; Iter   190/  229] train: loss: 0.1003974
[Epoch 111; Iter   220/  229] train: loss: 0.1269419
[Epoch 111] ogbg-moltoxcast: 0.657015 val loss: 0.450394
[Epoch 111] ogbg-moltoxcast: 0.635311 test loss: 0.525599
[Epoch 112; Iter    21/  229] train: loss: 0.0929621
[Epoch 112; Iter    51/  229] train: loss: 0.0968675
[Epoch 112; Iter    81/  229] train: loss: 0.1043545
[Epoch 112; Iter   111/  229] train: loss: 0.1212015
[Epoch 112; Iter   141/  229] train: loss: 0.1322032
[Epoch 112; Iter   171/  229] train: loss: 0.0957983
[Epoch 112; Iter   201/  229] train: loss: 0.1182032
[Epoch 112] ogbg-moltoxcast: 0.659609 val loss: 0.383499
[Epoch 112] ogbg-moltoxcast: 0.636852 test loss: 0.450602
[Epoch 113; Iter     2/  229] train: loss: 0.0481619
[Epoch 113; Iter    32/  229] train: loss: 0.0988981
[Epoch 113; Iter    62/  229] train: loss: 0.1145524
[Epoch 113; Iter    92/  229] train: loss: 0.1642327
[Epoch 113; Iter   122/  229] train: loss: 0.0656723
[Epoch 113; Iter   152/  229] train: loss: 0.1365439
[Epoch 113; Iter   182/  229] train: loss: 0.0999956
[Epoch 113; Iter   212/  229] train: loss: 0.1117446
[Epoch 113] ogbg-moltoxcast: 0.654118 val loss: 0.328961
[Epoch 113] ogbg-moltoxcast: 0.639294 test loss: 0.379233
[Epoch 114; Iter    13/  229] train: loss: 0.0972426
[Epoch 114; Iter    43/  229] train: loss: 0.0953258
[Epoch 114; Iter    73/  229] train: loss: 0.1117316
[Epoch 114; Iter   103/  229] train: loss: 0.0822830
[Epoch 114; Iter   133/  229] train: loss: 0.1191837
[Epoch 114; Iter   163/  229] train: loss: 0.0814006
[Epoch 114; Iter   193/  229] train: loss: 0.1049703
[Epoch 114; Iter   223/  229] train: loss: 0.0878355
[Epoch 114] ogbg-moltoxcast: 0.656364 val loss: 0.477969
[Epoch 114] ogbg-moltoxcast: 0.634086 test loss: 0.583008
[Epoch 115; Iter    24/  229] train: loss: 0.1054353
[Epoch 115; Iter    54/  229] train: loss: 0.0995356
[Epoch 115; Iter    84/  229] train: loss: 0.1546848
[Epoch 115; Iter   114/  229] train: loss: 0.1105309
[Epoch 115; Iter   144/  229] train: loss: 0.1068446
[Epoch 115; Iter   174/  229] train: loss: 0.0721865
[Epoch 115; Iter   204/  229] train: loss: 0.1472117
[Epoch 115] ogbg-moltoxcast: 0.654969 val loss: 0.340109
[Epoch 115] ogbg-moltoxcast: 0.633429 test loss: 0.393662
[Epoch 116; Iter     5/  229] train: loss: 0.1009003
[Epoch 116; Iter    35/  229] train: loss: 0.0851899
[Epoch 116; Iter    65/  229] train: loss: 0.1972068
[Epoch 116; Iter    95/  229] train: loss: 0.1121144
[Epoch 116; Iter   125/  229] train: loss: 0.1228577
[Epoch 116; Iter   155/  229] train: loss: 0.1318114
[Epoch 116; Iter   185/  229] train: loss: 0.1051420
[Epoch 116; Iter   215/  229] train: loss: 0.0894828
[Epoch 116] ogbg-moltoxcast: 0.652579 val loss: 0.338047
[Epoch 116] ogbg-moltoxcast: 0.633919 test loss: 0.389974
[Epoch 117; Iter    16/  229] train: loss: 0.1354830
[Epoch 117; Iter    46/  229] train: loss: 0.1516080
[Epoch 117; Iter    76/  229] train: loss: 0.1002883
[Epoch 117; Iter   106/  229] train: loss: 0.1402866
[Epoch 117; Iter   136/  229] train: loss: 0.0899298
[Epoch 117; Iter   166/  229] train: loss: 0.0645161
[Epoch 117; Iter   196/  229] train: loss: 0.1576897
[Epoch 117; Iter   226/  229] train: loss: 0.0870241
[Epoch 117] ogbg-moltoxcast: 0.659207 val loss: 0.329725
[Epoch 117] ogbg-moltoxcast: 0.642952 test loss: 0.380074
[Epoch 118; Iter    27/  229] train: loss: 0.0605400
[Epoch 118; Iter    57/  229] train: loss: 0.1055542
[Epoch 118; Iter    87/  229] train: loss: 0.0735124
[Epoch 118; Iter   117/  229] train: loss: 0.1264473
[Epoch 118; Iter   147/  229] train: loss: 0.1079322
[Epoch 118; Iter   177/  229] train: loss: 0.1165539
[Epoch 118; Iter   207/  229] train: loss: 0.1733098
[Epoch 118] ogbg-moltoxcast: 0.656570 val loss: 0.477607
[Epoch 118] ogbg-moltoxcast: 0.633446 test loss: 0.561287
[Epoch 119; Iter     8/  229] train: loss: 0.1295466
[Epoch 119; Iter    38/  229] train: loss: 0.0945218
[Epoch 119; Iter    68/  229] train: loss: 0.1275240
[Epoch 119; Iter    98/  229] train: loss: 0.0693856
[Epoch 119; Iter   128/  229] train: loss: 0.1088500
[Epoch 119; Iter   158/  229] train: loss: 0.0933177
[Epoch 119; Iter   188/  229] train: loss: 0.1494021
[Epoch 119; Iter   218/  229] train: loss: 0.1318995
[Epoch 119] ogbg-moltoxcast: 0.657987 val loss: 0.425821
[Epoch 119] ogbg-moltoxcast: 0.635762 test loss: 0.515241
[Epoch 120; Iter    19/  229] train: loss: 0.0983499
[Epoch 120; Iter    49/  229] train: loss: 0.1151190
[Epoch 120; Iter    79/  229] train: loss: 0.0899558
[Epoch 120; Iter   109/  229] train: loss: 0.1382999
[Epoch 120; Iter   139/  229] train: loss: 0.1242100
[Epoch 120; Iter   169/  229] train: loss: 0.1270526
[Epoch 120; Iter   199/  229] train: loss: 0.0825292
[Epoch 120; Iter   229/  229] train: loss: 0.1777908
[Epoch 120] ogbg-moltoxcast: 0.658436 val loss: 0.332568
[Epoch 120] ogbg-moltoxcast: 0.636293 test loss: 0.384085
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 31.
Statistics on  val_best_checkpoint
mean_pred: -2.8039026260375977
std_pred: 2.399456262588501
mean_targets: nan
std_targets: nan
prcauc: 0.38916224206859357
rocauc: 0.6854432834124736
ogbg-moltoxcast: 0.6854432834124736
OGBNanLabelBCEWithLogitsLoss: 0.2742262878294649
Statistics on  test
mean_pred: -2.663052558898926
std_pred: 2.3816657066345215
mean_targets: nan
std_targets: nan
prcauc: 0.34964599781035344
rocauc: 0.648280903851211
ogbg-moltoxcast: 0.648280903851211
OGBNanLabelBCEWithLogitsLoss: 0.32063216793126076
Statistics on  train
mean_pred: -3.1292824745178223
std_pred: 2.3495826721191406
mean_targets: nan
std_targets: nan
prcauc: 0.5368067710614133
rocauc: 0.8572909895974375
ogbg-moltoxcast: 0.8572909895974375
OGBNanLabelBCEWithLogitsLoss: 0.1449010847827753
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.638057 test loss: 0.370514
[Epoch 108; Iter     7/  229] train: loss: 0.0992109
[Epoch 108; Iter    37/  229] train: loss: 0.1700850
[Epoch 108; Iter    67/  229] train: loss: 0.1135974
[Epoch 108; Iter    97/  229] train: loss: 0.1372674
[Epoch 108; Iter   127/  229] train: loss: 0.1083412
[Epoch 108; Iter   157/  229] train: loss: 0.1161239
[Epoch 108; Iter   187/  229] train: loss: 0.1165749
[Epoch 108; Iter   217/  229] train: loss: 0.1049097
[Epoch 108] ogbg-moltoxcast: 0.661096 val loss: 0.327652
[Epoch 108] ogbg-moltoxcast: 0.639799 test loss: 0.371096
[Epoch 109; Iter    18/  229] train: loss: 0.0909018
[Epoch 109; Iter    48/  229] train: loss: 0.1167498
[Epoch 109; Iter    78/  229] train: loss: 0.0811856
[Epoch 109; Iter   108/  229] train: loss: 0.0986230
[Epoch 109; Iter   138/  229] train: loss: 0.0619399
[Epoch 109; Iter   168/  229] train: loss: 0.1149728
[Epoch 109; Iter   198/  229] train: loss: 0.1019295
[Epoch 109; Iter   228/  229] train: loss: 0.1230698
[Epoch 109] ogbg-moltoxcast: 0.660072 val loss: 0.329858
[Epoch 109] ogbg-moltoxcast: 0.640467 test loss: 0.371806
[Epoch 110; Iter    29/  229] train: loss: 0.1238661
[Epoch 110; Iter    59/  229] train: loss: 0.1229076
[Epoch 110; Iter    89/  229] train: loss: 0.1227554
[Epoch 110; Iter   119/  229] train: loss: 0.1503749
[Epoch 110; Iter   149/  229] train: loss: 0.1379267
[Epoch 110; Iter   179/  229] train: loss: 0.1438801
[Epoch 110; Iter   209/  229] train: loss: 0.0893250
[Epoch 110] ogbg-moltoxcast: 0.660621 val loss: 0.326705
[Epoch 110] ogbg-moltoxcast: 0.638739 test loss: 0.371642
[Epoch 111; Iter    10/  229] train: loss: 0.0770299
[Epoch 111; Iter    40/  229] train: loss: 0.1128221
[Epoch 111; Iter    70/  229] train: loss: 0.1343545
[Epoch 111; Iter   100/  229] train: loss: 0.1054663
[Epoch 111; Iter   130/  229] train: loss: 0.1236965
[Epoch 111; Iter   160/  229] train: loss: 0.1567290
[Epoch 111; Iter   190/  229] train: loss: 0.0826995
[Epoch 111; Iter   220/  229] train: loss: 0.0977047
[Epoch 111] ogbg-moltoxcast: 0.663255 val loss: 0.324165
[Epoch 111] ogbg-moltoxcast: 0.639923 test loss: 0.368136
[Epoch 112; Iter    21/  229] train: loss: 0.0940553
[Epoch 112; Iter    51/  229] train: loss: 0.1158198
[Epoch 112; Iter    81/  229] train: loss: 0.0764413
[Epoch 112; Iter   111/  229] train: loss: 0.1092261
[Epoch 112; Iter   141/  229] train: loss: 0.1016512
[Epoch 112; Iter   171/  229] train: loss: 0.1087290
[Epoch 112; Iter   201/  229] train: loss: 0.0762012
[Epoch 112] ogbg-moltoxcast: 0.661610 val loss: 0.330361
[Epoch 112] ogbg-moltoxcast: 0.635124 test loss: 0.376899
[Epoch 113; Iter     2/  229] train: loss: 0.1314837
[Epoch 113; Iter    32/  229] train: loss: 0.1356547
[Epoch 113; Iter    62/  229] train: loss: 0.1115087
[Epoch 113; Iter    92/  229] train: loss: 0.1380791
[Epoch 113; Iter   122/  229] train: loss: 0.1532467
[Epoch 113; Iter   152/  229] train: loss: 0.1117836
[Epoch 113; Iter   182/  229] train: loss: 0.1001938
[Epoch 113; Iter   212/  229] train: loss: 0.0946035
[Epoch 113] ogbg-moltoxcast: 0.663269 val loss: 0.339235
[Epoch 113] ogbg-moltoxcast: 0.639859 test loss: 0.377551
[Epoch 114; Iter    13/  229] train: loss: 0.0705656
[Epoch 114; Iter    43/  229] train: loss: 0.1072214
[Epoch 114; Iter    73/  229] train: loss: 0.1009966
[Epoch 114; Iter   103/  229] train: loss: 0.1282222
[Epoch 114; Iter   133/  229] train: loss: 0.1125750
[Epoch 114; Iter   163/  229] train: loss: 0.0774876
[Epoch 114; Iter   193/  229] train: loss: 0.1177216
[Epoch 114; Iter   223/  229] train: loss: 0.0770218
[Epoch 114] ogbg-moltoxcast: 0.658975 val loss: 0.336362
[Epoch 114] ogbg-moltoxcast: 0.638578 test loss: 0.375666
[Epoch 115; Iter    24/  229] train: loss: 0.0831595
[Epoch 115; Iter    54/  229] train: loss: 0.1071984
[Epoch 115; Iter    84/  229] train: loss: 0.1105764
[Epoch 115; Iter   114/  229] train: loss: 0.0725788
[Epoch 115; Iter   144/  229] train: loss: 0.0680181
[Epoch 115; Iter   174/  229] train: loss: 0.1192389
[Epoch 115; Iter   204/  229] train: loss: 0.1330897
[Epoch 115] ogbg-moltoxcast: 0.655678 val loss: 0.332353
[Epoch 115] ogbg-moltoxcast: 0.636352 test loss: 0.371199
[Epoch 116; Iter     5/  229] train: loss: 0.1150063
[Epoch 116; Iter    35/  229] train: loss: 0.1044917
[Epoch 116; Iter    65/  229] train: loss: 0.0993737
[Epoch 116; Iter    95/  229] train: loss: 0.1382013
[Epoch 116; Iter   125/  229] train: loss: 0.0825228
[Epoch 116; Iter   155/  229] train: loss: 0.1464887
[Epoch 116; Iter   185/  229] train: loss: 0.0909751
[Epoch 116; Iter   215/  229] train: loss: 0.1351445
[Epoch 116] ogbg-moltoxcast: 0.660668 val loss: 0.330950
[Epoch 116] ogbg-moltoxcast: 0.636354 test loss: 0.375706
[Epoch 117; Iter    16/  229] train: loss: 0.0923532
[Epoch 117; Iter    46/  229] train: loss: 0.0785564
[Epoch 117; Iter    76/  229] train: loss: 0.0856792
[Epoch 117; Iter   106/  229] train: loss: 0.0980345
[Epoch 117; Iter   136/  229] train: loss: 0.1340965
[Epoch 117; Iter   166/  229] train: loss: 0.1122298
[Epoch 117; Iter   196/  229] train: loss: 0.1315909
[Epoch 117; Iter   226/  229] train: loss: 0.1019513
[Epoch 117] ogbg-moltoxcast: 0.658847 val loss: 0.334550
[Epoch 117] ogbg-moltoxcast: 0.636137 test loss: 0.376305
[Epoch 118; Iter    27/  229] train: loss: 0.0829952
[Epoch 118; Iter    57/  229] train: loss: 0.0884074
[Epoch 118; Iter    87/  229] train: loss: 0.1047885
[Epoch 118; Iter   117/  229] train: loss: 0.1018967
[Epoch 118; Iter   147/  229] train: loss: 0.1149329
[Epoch 118; Iter   177/  229] train: loss: 0.1318156
[Epoch 118; Iter   207/  229] train: loss: 0.0926128
[Epoch 118] ogbg-moltoxcast: 0.660686 val loss: 0.334602
[Epoch 118] ogbg-moltoxcast: 0.635774 test loss: 0.377711
[Epoch 119; Iter     8/  229] train: loss: 0.0989853
[Epoch 119; Iter    38/  229] train: loss: 0.0811821
[Epoch 119; Iter    68/  229] train: loss: 0.0989347
[Epoch 119; Iter    98/  229] train: loss: 0.1035270
[Epoch 119; Iter   128/  229] train: loss: 0.1077053
[Epoch 119; Iter   158/  229] train: loss: 0.1271114
[Epoch 119; Iter   188/  229] train: loss: 0.1002497
[Epoch 119; Iter   218/  229] train: loss: 0.0616258
[Epoch 119] ogbg-moltoxcast: 0.661012 val loss: 0.329710
[Epoch 119] ogbg-moltoxcast: 0.637792 test loss: 0.372101
[Epoch 120; Iter    19/  229] train: loss: 0.0892404
[Epoch 120; Iter    49/  229] train: loss: 0.1051197
[Epoch 120; Iter    79/  229] train: loss: 0.0965570
[Epoch 120; Iter   109/  229] train: loss: 0.1663769
[Epoch 120; Iter   139/  229] train: loss: 0.0924236
[Epoch 120; Iter   169/  229] train: loss: 0.0816940
[Epoch 120; Iter   199/  229] train: loss: 0.0686755
[Epoch 120; Iter   229/  229] train: loss: 0.1154845
[Epoch 120] ogbg-moltoxcast: 0.660588 val loss: 0.339955
[Epoch 120] ogbg-moltoxcast: 0.638991 test loss: 0.383153
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 21.
Statistics on  val_best_checkpoint
mean_pred: -2.4716577529907227
std_pred: 2.265281915664673
mean_targets: nan
std_targets: nan
prcauc: 0.38747898811560116
rocauc: 0.6913846681935599
ogbg-moltoxcast: 0.6913846681935599
OGBNanLabelBCEWithLogitsLoss: 0.254930992578638
Statistics on  test
mean_pred: -2.2943994998931885
std_pred: 2.270111083984375
mean_targets: nan
std_targets: nan
prcauc: 0.33986362293607164
rocauc: 0.6389902255213942
ogbg-moltoxcast: 0.6389902255213942
OGBNanLabelBCEWithLogitsLoss: 0.3054291621364396
Statistics on  train
mean_pred: -2.8234739303588867
std_pred: 2.175334930419922
mean_targets: nan
std_targets: nan
prcauc: 0.47104303107408774
rocauc: 0.8168091745610788
ogbg-moltoxcast: 0.8168091745610788
OGBNanLabelBCEWithLogitsLoss: 0.16325583006357
[Epoch 107] ogbg-moltoxcast: 0.639375 test loss: 0.369517
[Epoch 108; Iter     7/  229] train: loss: 0.1181523
[Epoch 108; Iter    37/  229] train: loss: 0.1654071
[Epoch 108; Iter    67/  229] train: loss: 0.1162690
[Epoch 108; Iter    97/  229] train: loss: 0.1328381
[Epoch 108; Iter   127/  229] train: loss: 0.2008053
[Epoch 108; Iter   157/  229] train: loss: 0.1021680
[Epoch 108; Iter   187/  229] train: loss: 0.0911621
[Epoch 108; Iter   217/  229] train: loss: 0.1029808
[Epoch 108] ogbg-moltoxcast: 0.654552 val loss: 0.306188
[Epoch 108] ogbg-moltoxcast: 0.642308 test loss: 0.344273
[Epoch 109; Iter    18/  229] train: loss: 0.1244239
[Epoch 109; Iter    48/  229] train: loss: 0.1256073
[Epoch 109; Iter    78/  229] train: loss: 0.1268667
[Epoch 109; Iter   108/  229] train: loss: 0.1522969
[Epoch 109; Iter   138/  229] train: loss: 0.1161235
[Epoch 109; Iter   168/  229] train: loss: 0.1458426
[Epoch 109; Iter   198/  229] train: loss: 0.1162654
[Epoch 109; Iter   228/  229] train: loss: 0.0850910
[Epoch 109] ogbg-moltoxcast: 0.653811 val loss: 0.350059
[Epoch 109] ogbg-moltoxcast: 0.639726 test loss: 0.363713
[Epoch 110; Iter    29/  229] train: loss: 0.0730717
[Epoch 110; Iter    59/  229] train: loss: 0.0936067
[Epoch 110; Iter    89/  229] train: loss: 0.0700638
[Epoch 110; Iter   119/  229] train: loss: 0.1326673
[Epoch 110; Iter   149/  229] train: loss: 0.0952581
[Epoch 110; Iter   179/  229] train: loss: 0.1674492
[Epoch 110; Iter   209/  229] train: loss: 0.0933276
[Epoch 110] ogbg-moltoxcast: 0.656549 val loss: 0.346382
[Epoch 110] ogbg-moltoxcast: 0.642868 test loss: 0.362429
[Epoch 111; Iter    10/  229] train: loss: 0.1353846
[Epoch 111; Iter    40/  229] train: loss: 0.0864499
[Epoch 111; Iter    70/  229] train: loss: 0.1081270
[Epoch 111; Iter   100/  229] train: loss: 0.1376570
[Epoch 111; Iter   130/  229] train: loss: 0.1029825
[Epoch 111; Iter   160/  229] train: loss: 0.1378792
[Epoch 111; Iter   190/  229] train: loss: 0.1124582
[Epoch 111; Iter   220/  229] train: loss: 0.0950495
[Epoch 111] ogbg-moltoxcast: 0.654075 val loss: 0.345211
[Epoch 111] ogbg-moltoxcast: 0.642325 test loss: 0.372777
[Epoch 112; Iter    21/  229] train: loss: 0.1183821
[Epoch 112; Iter    51/  229] train: loss: 0.1104749
[Epoch 112; Iter    81/  229] train: loss: 0.0912865
[Epoch 112; Iter   111/  229] train: loss: 0.1134502
[Epoch 112; Iter   141/  229] train: loss: 0.1095912
[Epoch 112; Iter   171/  229] train: loss: 0.1515566
[Epoch 112; Iter   201/  229] train: loss: 0.0948770
[Epoch 112] ogbg-moltoxcast: 0.652932 val loss: 0.336822
[Epoch 112] ogbg-moltoxcast: 0.640720 test loss: 0.440629
[Epoch 113; Iter     2/  229] train: loss: 0.1640111
[Epoch 113; Iter    32/  229] train: loss: 0.0984291
[Epoch 113; Iter    62/  229] train: loss: 0.1541442
[Epoch 113; Iter    92/  229] train: loss: 0.1055214
[Epoch 113; Iter   122/  229] train: loss: 0.1254855
[Epoch 113; Iter   152/  229] train: loss: 0.1043877
[Epoch 113; Iter   182/  229] train: loss: 0.1127473
[Epoch 113; Iter   212/  229] train: loss: 0.1737273
[Epoch 113] ogbg-moltoxcast: 0.654757 val loss: 0.335226
[Epoch 113] ogbg-moltoxcast: 0.643471 test loss: 0.357032
[Epoch 114; Iter    13/  229] train: loss: 0.0964899
[Epoch 114; Iter    43/  229] train: loss: 0.1434087
[Epoch 114; Iter    73/  229] train: loss: 0.1427667
[Epoch 114; Iter   103/  229] train: loss: 0.1081533
[Epoch 114; Iter   133/  229] train: loss: 0.1375621
[Epoch 114; Iter   163/  229] train: loss: 0.1398057
[Epoch 114; Iter   193/  229] train: loss: 0.1573349
[Epoch 114; Iter   223/  229] train: loss: 0.1132678
[Epoch 114] ogbg-moltoxcast: 0.654706 val loss: 0.306945
[Epoch 114] ogbg-moltoxcast: 0.641358 test loss: 0.350986
[Epoch 115; Iter    24/  229] train: loss: 0.0901947
[Epoch 115; Iter    54/  229] train: loss: 0.1188477
[Epoch 115; Iter    84/  229] train: loss: 0.1472898
[Epoch 115; Iter   114/  229] train: loss: 0.0864141
[Epoch 115; Iter   144/  229] train: loss: 0.1476784
[Epoch 115; Iter   174/  229] train: loss: 0.1175881
[Epoch 115; Iter   204/  229] train: loss: 0.0876684
[Epoch 115] ogbg-moltoxcast: 0.654545 val loss: 0.354590
[Epoch 115] ogbg-moltoxcast: 0.642101 test loss: 0.368278
[Epoch 116; Iter     5/  229] train: loss: 0.1611054
[Epoch 116; Iter    35/  229] train: loss: 0.1119627
[Epoch 116; Iter    65/  229] train: loss: 0.1194239
[Epoch 116; Iter    95/  229] train: loss: 0.1163189
[Epoch 116; Iter   125/  229] train: loss: 0.1227376
[Epoch 116; Iter   155/  229] train: loss: 0.1387654
[Epoch 116; Iter   185/  229] train: loss: 0.0918856
[Epoch 116; Iter   215/  229] train: loss: 0.0968899
[Epoch 116] ogbg-moltoxcast: 0.654129 val loss: 0.309623
[Epoch 116] ogbg-moltoxcast: 0.641037 test loss: 0.356040
[Epoch 117; Iter    16/  229] train: loss: 0.1282227
[Epoch 117; Iter    46/  229] train: loss: 0.1394822
[Epoch 117; Iter    76/  229] train: loss: 0.1194562
[Epoch 117; Iter   106/  229] train: loss: 0.1369036
[Epoch 117; Iter   136/  229] train: loss: 0.1242795
[Epoch 117; Iter   166/  229] train: loss: 0.0834236
[Epoch 117; Iter   196/  229] train: loss: 0.1117621
[Epoch 117; Iter   226/  229] train: loss: 0.0998923
[Epoch 117] ogbg-moltoxcast: 0.654881 val loss: 0.315685
[Epoch 117] ogbg-moltoxcast: 0.640506 test loss: 0.372720
[Epoch 118; Iter    27/  229] train: loss: 0.1079015
[Epoch 118; Iter    57/  229] train: loss: 0.0924732
[Epoch 118; Iter    87/  229] train: loss: 0.1189636
[Epoch 118; Iter   117/  229] train: loss: 0.0913678
[Epoch 118; Iter   147/  229] train: loss: 0.1095497
[Epoch 118; Iter   177/  229] train: loss: 0.1457011
[Epoch 118; Iter   207/  229] train: loss: 0.0957675
[Epoch 118] ogbg-moltoxcast: 0.653370 val loss: 0.325626
[Epoch 118] ogbg-moltoxcast: 0.638510 test loss: 0.358920
[Epoch 119; Iter     8/  229] train: loss: 0.0792644
[Epoch 119; Iter    38/  229] train: loss: 0.1018547
[Epoch 119; Iter    68/  229] train: loss: 0.1299138
[Epoch 119; Iter    98/  229] train: loss: 0.0985038
[Epoch 119; Iter   128/  229] train: loss: 0.1526024
[Epoch 119; Iter   158/  229] train: loss: 0.1259261
[Epoch 119; Iter   188/  229] train: loss: 0.1403525
[Epoch 119; Iter   218/  229] train: loss: 0.1847651
[Epoch 119] ogbg-moltoxcast: 0.652206 val loss: 0.317669
[Epoch 119] ogbg-moltoxcast: 0.640170 test loss: 0.365192
[Epoch 120; Iter    19/  229] train: loss: 0.0900277
[Epoch 120; Iter    49/  229] train: loss: 0.1187900
[Epoch 120; Iter    79/  229] train: loss: 0.0900290
[Epoch 120; Iter   109/  229] train: loss: 0.0713260
[Epoch 120; Iter   139/  229] train: loss: 0.1324437
[Epoch 120; Iter   169/  229] train: loss: 0.0958745
[Epoch 120; Iter   199/  229] train: loss: 0.0889365
[Epoch 120; Iter   229/  229] train: loss: 0.1065749
[Epoch 120] ogbg-moltoxcast: 0.653104 val loss: 0.347098
[Epoch 120] ogbg-moltoxcast: 0.642853 test loss: 0.367572
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.4021148681640625
std_pred: 2.34541392326355
mean_targets: nan
std_targets: nan
prcauc: 0.3731028094719726
rocauc: 0.6732111427916924
ogbg-moltoxcast: 0.6732111427916924
OGBNanLabelBCEWithLogitsLoss: 0.26770658431382016
Statistics on  test
mean_pred: -2.142942428588867
std_pred: 2.257129192352295
mean_targets: nan
std_targets: nan
prcauc: 0.3361969210687487
rocauc: 0.6441613050161175
ogbg-moltoxcast: 0.6441613050161175
OGBNanLabelBCEWithLogitsLoss: 0.3071335903529463
Statistics on  train
mean_pred: -2.9951772689819336
std_pred: 2.3483593463897705
mean_targets: nan
std_targets: nan
prcauc: 0.4969103642930169
rocauc: 0.8346743973811761
ogbg-moltoxcast: 0.8346743973811761
OGBNanLabelBCEWithLogitsLoss: 0.15824371794295625
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.622847 test loss: 0.469112
[Epoch 108; Iter     7/  229] train: loss: 0.0951966
[Epoch 108; Iter    37/  229] train: loss: 0.1663030
[Epoch 108; Iter    67/  229] train: loss: 0.1102827
[Epoch 108; Iter    97/  229] train: loss: 0.1346074
[Epoch 108; Iter   127/  229] train: loss: 0.1112908
[Epoch 108; Iter   157/  229] train: loss: 0.1168771
[Epoch 108; Iter   187/  229] train: loss: 0.1164213
[Epoch 108; Iter   217/  229] train: loss: 0.1041580
[Epoch 108] ogbg-moltoxcast: 0.618334 val loss: 0.413763
[Epoch 108] ogbg-moltoxcast: 0.624851 test loss: 0.475077
[Epoch 109; Iter    18/  229] train: loss: 0.0891051
[Epoch 109; Iter    48/  229] train: loss: 0.1176456
[Epoch 109; Iter    78/  229] train: loss: 0.0853852
[Epoch 109; Iter   108/  229] train: loss: 0.0991785
[Epoch 109; Iter   138/  229] train: loss: 0.0686338
[Epoch 109; Iter   168/  229] train: loss: 0.1224329
[Epoch 109; Iter   198/  229] train: loss: 0.1060273
[Epoch 109; Iter   228/  229] train: loss: 0.1180752
[Epoch 109] ogbg-moltoxcast: 0.618865 val loss: 0.404422
[Epoch 109] ogbg-moltoxcast: 0.624451 test loss: 0.463926
[Epoch 110; Iter    29/  229] train: loss: 0.1212419
[Epoch 110; Iter    59/  229] train: loss: 0.1319672
[Epoch 110; Iter    89/  229] train: loss: 0.1293581
[Epoch 110; Iter   119/  229] train: loss: 0.1454240
[Epoch 110; Iter   149/  229] train: loss: 0.1336803
[Epoch 110; Iter   179/  229] train: loss: 0.1356971
[Epoch 110; Iter   209/  229] train: loss: 0.0943564
[Epoch 110] ogbg-moltoxcast: 0.613204 val loss: 0.407124
[Epoch 110] ogbg-moltoxcast: 0.624959 test loss: 0.465450
[Epoch 111; Iter    10/  229] train: loss: 0.0850466
[Epoch 111; Iter    40/  229] train: loss: 0.1094339
[Epoch 111; Iter    70/  229] train: loss: 0.1377954
[Epoch 111; Iter   100/  229] train: loss: 0.1045238
[Epoch 111; Iter   130/  229] train: loss: 0.1307658
[Epoch 111; Iter   160/  229] train: loss: 0.1542349
[Epoch 111; Iter   190/  229] train: loss: 0.0870288
[Epoch 111; Iter   220/  229] train: loss: 0.1022616
[Epoch 111] ogbg-moltoxcast: 0.620014 val loss: 0.407144
[Epoch 111] ogbg-moltoxcast: 0.626748 test loss: 0.466890
[Epoch 112; Iter    21/  229] train: loss: 0.0951236
[Epoch 112; Iter    51/  229] train: loss: 0.1121595
[Epoch 112; Iter    81/  229] train: loss: 0.0789349
[Epoch 112; Iter   111/  229] train: loss: 0.1017311
[Epoch 112; Iter   141/  229] train: loss: 0.1082640
[Epoch 112; Iter   171/  229] train: loss: 0.1125818
[Epoch 112; Iter   201/  229] train: loss: 0.0786138
[Epoch 112] ogbg-moltoxcast: 0.623959 val loss: 0.403612
[Epoch 112] ogbg-moltoxcast: 0.626635 test loss: 0.463855
[Epoch 113; Iter     2/  229] train: loss: 0.1348345
[Epoch 113; Iter    32/  229] train: loss: 0.1373500
[Epoch 113; Iter    62/  229] train: loss: 0.1113262
[Epoch 113; Iter    92/  229] train: loss: 0.1402137
[Epoch 113; Iter   122/  229] train: loss: 0.1546947
[Epoch 113; Iter   152/  229] train: loss: 0.1080433
[Epoch 113; Iter   182/  229] train: loss: 0.1014370
[Epoch 113; Iter   212/  229] train: loss: 0.1016834
[Epoch 113] ogbg-moltoxcast: 0.622515 val loss: 0.415432
[Epoch 113] ogbg-moltoxcast: 0.625829 test loss: 0.474908
[Epoch 114; Iter    13/  229] train: loss: 0.0660874
[Epoch 114; Iter    43/  229] train: loss: 0.1141100
[Epoch 114; Iter    73/  229] train: loss: 0.1027406
[Epoch 114; Iter   103/  229] train: loss: 0.1271203
[Epoch 114; Iter   133/  229] train: loss: 0.1110157
[Epoch 114; Iter   163/  229] train: loss: 0.0762536
[Epoch 114; Iter   193/  229] train: loss: 0.1179975
[Epoch 114; Iter   223/  229] train: loss: 0.0788104
[Epoch 114] ogbg-moltoxcast: 0.619125 val loss: 0.412389
[Epoch 114] ogbg-moltoxcast: 0.623647 test loss: 0.475402
[Epoch 115; Iter    24/  229] train: loss: 0.0800560
[Epoch 115; Iter    54/  229] train: loss: 0.1135481
[Epoch 115; Iter    84/  229] train: loss: 0.1098787
[Epoch 115; Iter   114/  229] train: loss: 0.0748412
[Epoch 115; Iter   144/  229] train: loss: 0.0667533
[Epoch 115; Iter   174/  229] train: loss: 0.1211040
[Epoch 115; Iter   204/  229] train: loss: 0.1328375
[Epoch 115] ogbg-moltoxcast: 0.619213 val loss: 0.418966
[Epoch 115] ogbg-moltoxcast: 0.624283 test loss: 0.482176
[Epoch 116; Iter     5/  229] train: loss: 0.1075390
[Epoch 116; Iter    35/  229] train: loss: 0.1034566
[Epoch 116; Iter    65/  229] train: loss: 0.1021662
[Epoch 116; Iter    95/  229] train: loss: 0.1456263
[Epoch 116; Iter   125/  229] train: loss: 0.0796400
[Epoch 116; Iter   155/  229] train: loss: 0.1491746
[Epoch 116; Iter   185/  229] train: loss: 0.0819250
[Epoch 116; Iter   215/  229] train: loss: 0.1320863
[Epoch 116] ogbg-moltoxcast: 0.622925 val loss: 0.403358
[Epoch 116] ogbg-moltoxcast: 0.627559 test loss: 0.462830
[Epoch 117; Iter    16/  229] train: loss: 0.0942284
[Epoch 117; Iter    46/  229] train: loss: 0.0831462
[Epoch 117; Iter    76/  229] train: loss: 0.0879789
[Epoch 117; Iter   106/  229] train: loss: 0.1007353
[Epoch 117; Iter   136/  229] train: loss: 0.1270255
[Epoch 117; Iter   166/  229] train: loss: 0.1114006
[Epoch 117; Iter   196/  229] train: loss: 0.1353946
[Epoch 117; Iter   226/  229] train: loss: 0.1047127
[Epoch 117] ogbg-moltoxcast: 0.617917 val loss: 0.411404
[Epoch 117] ogbg-moltoxcast: 0.624213 test loss: 0.472256
[Epoch 118; Iter    27/  229] train: loss: 0.0765365
[Epoch 118; Iter    57/  229] train: loss: 0.0938516
[Epoch 118; Iter    87/  229] train: loss: 0.1081556
[Epoch 118; Iter   117/  229] train: loss: 0.1040649
[Epoch 118; Iter   147/  229] train: loss: 0.1107855
[Epoch 118; Iter   177/  229] train: loss: 0.1320690
[Epoch 118; Iter   207/  229] train: loss: 0.0949971
[Epoch 118] ogbg-moltoxcast: 0.619601 val loss: 0.411934
[Epoch 118] ogbg-moltoxcast: 0.625438 test loss: 0.472213
[Epoch 119; Iter     8/  229] train: loss: 0.0983169
[Epoch 119; Iter    38/  229] train: loss: 0.0805101
[Epoch 119; Iter    68/  229] train: loss: 0.0942833
[Epoch 119; Iter    98/  229] train: loss: 0.1037176
[Epoch 119; Iter   128/  229] train: loss: 0.1108716
[Epoch 119; Iter   158/  229] train: loss: 0.1275019
[Epoch 119; Iter   188/  229] train: loss: 0.0973816
[Epoch 119; Iter   218/  229] train: loss: 0.0644886
[Epoch 119] ogbg-moltoxcast: 0.616183 val loss: 0.416531
[Epoch 119] ogbg-moltoxcast: 0.622248 test loss: 0.477547
[Epoch 120; Iter    19/  229] train: loss: 0.0933597
[Epoch 120; Iter    49/  229] train: loss: 0.1083564
[Epoch 120; Iter    79/  229] train: loss: 0.0930831
[Epoch 120; Iter   109/  229] train: loss: 0.1669273
[Epoch 120; Iter   139/  229] train: loss: 0.0962072
[Epoch 120; Iter   169/  229] train: loss: 0.0804684
[Epoch 120; Iter   199/  229] train: loss: 0.0727062
[Epoch 120; Iter   229/  229] train: loss: 0.1118009
[Epoch 120] ogbg-moltoxcast: 0.619638 val loss: 0.405168
[Epoch 120] ogbg-moltoxcast: 0.625400 test loss: 0.463394
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 17.
Statistics on  val_best_checkpoint
mean_pred: -2.0979361534118652
std_pred: 2.409961462020874
mean_targets: nan
std_targets: nan
prcauc: 0.364926866628346
rocauc: 0.6733656628578175
ogbg-moltoxcast: 0.6733656628578175
OGBNanLabelBCEWithLogitsLoss: 0.3190086859053579
Statistics on  test
mean_pred: -1.8133918046951294
std_pred: 2.3223419189453125
mean_targets: nan
std_targets: nan
prcauc: 0.3300030569491415
rocauc: 0.6310612629352543
ogbg-moltoxcast: 0.6310612629352543
OGBNanLabelBCEWithLogitsLoss: 0.36457266838386143
Statistics on  train
mean_pred: -2.772341251373291
std_pred: 2.1360020637512207
mean_targets: nan
std_targets: nan
prcauc: 0.45557083796394965
rocauc: 0.8039735409519052
ogbg-moltoxcast: 0.8039735409519052
OGBNanLabelBCEWithLogitsLoss: 0.16728378968988444
[Epoch 107] ogbg-moltoxcast: 0.628126 test loss: 0.422452
[Epoch 108; Iter     7/  229] train: loss: 0.1258867
[Epoch 108; Iter    37/  229] train: loss: 0.1557732
[Epoch 108; Iter    67/  229] train: loss: 0.1253187
[Epoch 108; Iter    97/  229] train: loss: 0.0882370
[Epoch 108; Iter   127/  229] train: loss: 0.0965152
[Epoch 108; Iter   157/  229] train: loss: 0.0949260
[Epoch 108; Iter   187/  229] train: loss: 0.1222077
[Epoch 108; Iter   217/  229] train: loss: 0.1200042
[Epoch 108] ogbg-moltoxcast: 0.644933 val loss: 0.347558
[Epoch 108] ogbg-moltoxcast: 0.628814 test loss: 0.410842
[Epoch 109; Iter    18/  229] train: loss: 0.1105238
[Epoch 109; Iter    48/  229] train: loss: 0.1064295
[Epoch 109; Iter    78/  229] train: loss: 0.0780552
[Epoch 109; Iter   108/  229] train: loss: 0.1581772
[Epoch 109; Iter   138/  229] train: loss: 0.1839216
[Epoch 109; Iter   168/  229] train: loss: 0.1452466
[Epoch 109; Iter   198/  229] train: loss: 0.0975828
[Epoch 109; Iter   228/  229] train: loss: 0.1477810
[Epoch 109] ogbg-moltoxcast: 0.644392 val loss: 0.351788
[Epoch 109] ogbg-moltoxcast: 0.630562 test loss: 0.411446
[Epoch 110; Iter    29/  229] train: loss: 0.1070761
[Epoch 110; Iter    59/  229] train: loss: 0.1182608
[Epoch 110; Iter    89/  229] train: loss: 0.1793037
[Epoch 110; Iter   119/  229] train: loss: 0.1758404
[Epoch 110; Iter   149/  229] train: loss: 0.1106175
[Epoch 110; Iter   179/  229] train: loss: 0.1477516
[Epoch 110; Iter   209/  229] train: loss: 0.1030958
[Epoch 110] ogbg-moltoxcast: 0.645688 val loss: 0.349283
[Epoch 110] ogbg-moltoxcast: 0.631825 test loss: 0.413335
[Epoch 111; Iter    10/  229] train: loss: 0.1390430
[Epoch 111; Iter    40/  229] train: loss: 0.0923292
[Epoch 111; Iter    70/  229] train: loss: 0.0849655
[Epoch 111; Iter   100/  229] train: loss: 0.1051843
[Epoch 111; Iter   130/  229] train: loss: 0.1181748
[Epoch 111; Iter   160/  229] train: loss: 0.1126802
[Epoch 111; Iter   190/  229] train: loss: 0.1002657
[Epoch 111; Iter   220/  229] train: loss: 0.1281226
[Epoch 111] ogbg-moltoxcast: 0.642966 val loss: 0.346023
[Epoch 111] ogbg-moltoxcast: 0.630665 test loss: 0.409674
[Epoch 112; Iter    21/  229] train: loss: 0.0910480
[Epoch 112; Iter    51/  229] train: loss: 0.0952498
[Epoch 112; Iter    81/  229] train: loss: 0.1079798
[Epoch 112; Iter   111/  229] train: loss: 0.1218030
[Epoch 112; Iter   141/  229] train: loss: 0.1203196
[Epoch 112; Iter   171/  229] train: loss: 0.0914044
[Epoch 112; Iter   201/  229] train: loss: 0.1229841
[Epoch 112] ogbg-moltoxcast: 0.646658 val loss: 0.347901
[Epoch 112] ogbg-moltoxcast: 0.630856 test loss: 0.404274
[Epoch 113; Iter     2/  229] train: loss: 0.0499201
[Epoch 113; Iter    32/  229] train: loss: 0.1040886
[Epoch 113; Iter    62/  229] train: loss: 0.1183265
[Epoch 113; Iter    92/  229] train: loss: 0.1721392
[Epoch 113; Iter   122/  229] train: loss: 0.0681281
[Epoch 113; Iter   152/  229] train: loss: 0.1341202
[Epoch 113; Iter   182/  229] train: loss: 0.0976408
[Epoch 113; Iter   212/  229] train: loss: 0.1038865
[Epoch 113] ogbg-moltoxcast: 0.642878 val loss: 0.350330
[Epoch 113] ogbg-moltoxcast: 0.629897 test loss: 0.410518
[Epoch 114; Iter    13/  229] train: loss: 0.1001428
[Epoch 114; Iter    43/  229] train: loss: 0.0923069
[Epoch 114; Iter    73/  229] train: loss: 0.1092685
[Epoch 114; Iter   103/  229] train: loss: 0.0832379
[Epoch 114; Iter   133/  229] train: loss: 0.1160361
[Epoch 114; Iter   163/  229] train: loss: 0.0779171
[Epoch 114; Iter   193/  229] train: loss: 0.1088449
[Epoch 114; Iter   223/  229] train: loss: 0.0902873
[Epoch 114] ogbg-moltoxcast: 0.642830 val loss: 0.349494
[Epoch 114] ogbg-moltoxcast: 0.629076 test loss: 0.410439
[Epoch 115; Iter    24/  229] train: loss: 0.1062853
[Epoch 115; Iter    54/  229] train: loss: 0.0985769
[Epoch 115; Iter    84/  229] train: loss: 0.1387271
[Epoch 115; Iter   114/  229] train: loss: 0.1138185
[Epoch 115; Iter   144/  229] train: loss: 0.1035116
[Epoch 115; Iter   174/  229] train: loss: 0.0737078
[Epoch 115; Iter   204/  229] train: loss: 0.1507702
[Epoch 115] ogbg-moltoxcast: 0.641170 val loss: 0.348575
[Epoch 115] ogbg-moltoxcast: 0.627295 test loss: 0.413642
[Epoch 116; Iter     5/  229] train: loss: 0.1055555
[Epoch 116; Iter    35/  229] train: loss: 0.0889525
[Epoch 116; Iter    65/  229] train: loss: 0.1946504
[Epoch 116; Iter    95/  229] train: loss: 0.1050731
[Epoch 116; Iter   125/  229] train: loss: 0.1244400
[Epoch 116; Iter   155/  229] train: loss: 0.1290669
[Epoch 116; Iter   185/  229] train: loss: 0.1011576
[Epoch 116; Iter   215/  229] train: loss: 0.0897094
[Epoch 116] ogbg-moltoxcast: 0.641838 val loss: 0.351504
[Epoch 116] ogbg-moltoxcast: 0.627060 test loss: 0.412813
[Epoch 117; Iter    16/  229] train: loss: 0.1377622
[Epoch 117; Iter    46/  229] train: loss: 0.1441126
[Epoch 117; Iter    76/  229] train: loss: 0.0996692
[Epoch 117; Iter   106/  229] train: loss: 0.1349175
[Epoch 117; Iter   136/  229] train: loss: 0.0881742
[Epoch 117; Iter   166/  229] train: loss: 0.0612814
[Epoch 117; Iter   196/  229] train: loss: 0.1619467
[Epoch 117; Iter   226/  229] train: loss: 0.0830056
[Epoch 117] ogbg-moltoxcast: 0.641941 val loss: 0.349268
[Epoch 117] ogbg-moltoxcast: 0.626946 test loss: 0.415758
[Epoch 118; Iter    27/  229] train: loss: 0.0557406
[Epoch 118; Iter    57/  229] train: loss: 0.0998712
[Epoch 118; Iter    87/  229] train: loss: 0.0672619
[Epoch 118; Iter   117/  229] train: loss: 0.1306180
[Epoch 118; Iter   147/  229] train: loss: 0.1075631
[Epoch 118; Iter   177/  229] train: loss: 0.1250490
[Epoch 118; Iter   207/  229] train: loss: 0.1829477
[Epoch 118] ogbg-moltoxcast: 0.644612 val loss: 0.347040
[Epoch 118] ogbg-moltoxcast: 0.627989 test loss: 0.410485
[Epoch 119; Iter     8/  229] train: loss: 0.1242984
[Epoch 119; Iter    38/  229] train: loss: 0.0986102
[Epoch 119; Iter    68/  229] train: loss: 0.1293011
[Epoch 119; Iter    98/  229] train: loss: 0.0655011
[Epoch 119; Iter   128/  229] train: loss: 0.1087907
[Epoch 119; Iter   158/  229] train: loss: 0.1013922
[Epoch 119; Iter   188/  229] train: loss: 0.1412478
[Epoch 119; Iter   218/  229] train: loss: 0.1300330
[Epoch 119] ogbg-moltoxcast: 0.643948 val loss: 0.355988
[Epoch 119] ogbg-moltoxcast: 0.629831 test loss: 0.421817
[Epoch 120; Iter    19/  229] train: loss: 0.1017410
[Epoch 120; Iter    49/  229] train: loss: 0.1260924
[Epoch 120; Iter    79/  229] train: loss: 0.0929074
[Epoch 120; Iter   109/  229] train: loss: 0.1399170
[Epoch 120; Iter   139/  229] train: loss: 0.1221068
[Epoch 120; Iter   169/  229] train: loss: 0.1306776
[Epoch 120; Iter   199/  229] train: loss: 0.0883947
[Epoch 120; Iter   229/  229] train: loss: 0.1709789
[Epoch 120] ogbg-moltoxcast: 0.643603 val loss: 0.350164
[Epoch 120] ogbg-moltoxcast: 0.629924 test loss: 0.408906
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 18.
Statistics on  val_best_checkpoint
mean_pred: -2.3466832637786865
std_pred: 2.3299612998962402
mean_targets: nan
std_targets: nan
prcauc: 0.3653923473686318
rocauc: 0.6729681186232024
ogbg-moltoxcast: 0.6729681186232024
OGBNanLabelBCEWithLogitsLoss: 0.2764291675954029
Statistics on  test
mean_pred: -2.1576309204101562
std_pred: 2.210364580154419
mean_targets: nan
std_targets: nan
prcauc: 0.34167844838940736
rocauc: 0.6343704260365475
ogbg-moltoxcast: 0.6343704260365475
OGBNanLabelBCEWithLogitsLoss: 0.31291882796534176
Statistics on  train
mean_pred: -2.651420831680298
std_pred: 2.05592942237854
mean_targets: nan
std_targets: nan
prcauc: 0.45265741275167437
rocauc: 0.8021786639459266
ogbg-moltoxcast: 0.8021786639459266
OGBNanLabelBCEWithLogitsLoss: 0.1700430149334487
[Epoch 107] ogbg-moltoxcast: 0.618288 test loss: 3.193260
[Epoch 108; Iter     7/  229] train: loss: 0.1095016
[Epoch 108; Iter    37/  229] train: loss: 0.1444041
[Epoch 108; Iter    67/  229] train: loss: 0.1131339
[Epoch 108; Iter    97/  229] train: loss: 0.1188355
[Epoch 108; Iter   127/  229] train: loss: 0.1783016
[Epoch 108; Iter   157/  229] train: loss: 0.0942545
[Epoch 108; Iter   187/  229] train: loss: 0.0832961
[Epoch 108; Iter   217/  229] train: loss: 0.0875694
[Epoch 108] ogbg-moltoxcast: 0.625845 val loss: 2.284186
[Epoch 108] ogbg-moltoxcast: 0.617349 test loss: 2.978043
[Epoch 109; Iter    18/  229] train: loss: 0.1103418
[Epoch 109; Iter    48/  229] train: loss: 0.1215016
[Epoch 109; Iter    78/  229] train: loss: 0.1136080
[Epoch 109; Iter   108/  229] train: loss: 0.1449144
[Epoch 109; Iter   138/  229] train: loss: 0.1069871
[Epoch 109; Iter   168/  229] train: loss: 0.1359911
[Epoch 109; Iter   198/  229] train: loss: 0.0950370
[Epoch 109; Iter   228/  229] train: loss: 0.0850111
[Epoch 109] ogbg-moltoxcast: 0.606463 val loss: 2.998140
[Epoch 109] ogbg-moltoxcast: 0.606943 test loss: 3.161124
[Epoch 110; Iter    29/  229] train: loss: 0.0697067
[Epoch 110; Iter    59/  229] train: loss: 0.0918649
[Epoch 110; Iter    89/  229] train: loss: 0.0756886
[Epoch 110; Iter   119/  229] train: loss: 0.1150707
[Epoch 110; Iter   149/  229] train: loss: 0.0898060
[Epoch 110; Iter   179/  229] train: loss: 0.1432622
[Epoch 110; Iter   209/  229] train: loss: 0.0899454
[Epoch 110] ogbg-moltoxcast: 0.620696 val loss: 3.249122
[Epoch 110] ogbg-moltoxcast: 0.617454 test loss: 3.437480
[Epoch 111; Iter    10/  229] train: loss: 0.1347841
[Epoch 111; Iter    40/  229] train: loss: 0.0855290
[Epoch 111; Iter    70/  229] train: loss: 0.0981077
[Epoch 111; Iter   100/  229] train: loss: 0.1226211
[Epoch 111; Iter   130/  229] train: loss: 0.1003647
[Epoch 111; Iter   160/  229] train: loss: 0.1303499
[Epoch 111; Iter   190/  229] train: loss: 0.1161332
[Epoch 111; Iter   220/  229] train: loss: 0.0889492
[Epoch 111] ogbg-moltoxcast: 0.606440 val loss: 2.665594
[Epoch 111] ogbg-moltoxcast: 0.607461 test loss: 3.272111
[Epoch 112; Iter    21/  229] train: loss: 0.1132110
[Epoch 112; Iter    51/  229] train: loss: 0.0860809
[Epoch 112; Iter    81/  229] train: loss: 0.0800061
[Epoch 112; Iter   111/  229] train: loss: 0.0936598
[Epoch 112; Iter   141/  229] train: loss: 0.1024384
[Epoch 112; Iter   171/  229] train: loss: 0.1412585
[Epoch 112; Iter   201/  229] train: loss: 0.0813739
[Epoch 112] ogbg-moltoxcast: 0.611710 val loss: 3.515022
[Epoch 112] ogbg-moltoxcast: 0.604443 test loss: 3.682156
[Epoch 113; Iter     2/  229] train: loss: 0.1459083
[Epoch 113; Iter    32/  229] train: loss: 0.0940133
[Epoch 113; Iter    62/  229] train: loss: 0.1327648
[Epoch 113; Iter    92/  229] train: loss: 0.0991756
[Epoch 113; Iter   122/  229] train: loss: 0.1106708
[Epoch 113; Iter   152/  229] train: loss: 0.0985453
[Epoch 113; Iter   182/  229] train: loss: 0.1032257
[Epoch 113; Iter   212/  229] train: loss: 0.1653195
[Epoch 113] ogbg-moltoxcast: 0.608026 val loss: 3.572222
[Epoch 113] ogbg-moltoxcast: 0.609124 test loss: 4.172550
[Epoch 114; Iter    13/  229] train: loss: 0.0891321
[Epoch 114; Iter    43/  229] train: loss: 0.1221211
[Epoch 114; Iter    73/  229] train: loss: 0.1273123
[Epoch 114; Iter   103/  229] train: loss: 0.0990470
[Epoch 114; Iter   133/  229] train: loss: 0.1318673
[Epoch 114; Iter   163/  229] train: loss: 0.1348587
[Epoch 114; Iter   193/  229] train: loss: 0.1395573
[Epoch 114; Iter   223/  229] train: loss: 0.1053766
[Epoch 114] ogbg-moltoxcast: 0.611557 val loss: 3.007664
[Epoch 114] ogbg-moltoxcast: 0.604629 test loss: 3.593550
[Epoch 115; Iter    24/  229] train: loss: 0.0734518
[Epoch 115; Iter    54/  229] train: loss: 0.1066180
[Epoch 115; Iter    84/  229] train: loss: 0.1341740
[Epoch 115; Iter   114/  229] train: loss: 0.0866223
[Epoch 115; Iter   144/  229] train: loss: 0.1453710
[Epoch 115; Iter   174/  229] train: loss: 0.1000975
[Epoch 115; Iter   204/  229] train: loss: 0.0848609
[Epoch 115] ogbg-moltoxcast: 0.597261 val loss: 3.272099
[Epoch 115] ogbg-moltoxcast: 0.602729 test loss: 3.869341
[Epoch 116; Iter     5/  229] train: loss: 0.1574723
[Epoch 116; Iter    35/  229] train: loss: 0.1053714
[Epoch 116; Iter    65/  229] train: loss: 0.1115327
[Epoch 116; Iter    95/  229] train: loss: 0.1057414
[Epoch 116; Iter   125/  229] train: loss: 0.1123689
[Epoch 116; Iter   155/  229] train: loss: 0.1348517
[Epoch 116; Iter   185/  229] train: loss: 0.0874366
[Epoch 116; Iter   215/  229] train: loss: 0.0828383
[Epoch 116] ogbg-moltoxcast: 0.617684 val loss: 2.435445
[Epoch 116] ogbg-moltoxcast: 0.611649 test loss: 2.810876
[Epoch 117; Iter    16/  229] train: loss: 0.1168501
[Epoch 117; Iter    46/  229] train: loss: 0.1264740
[Epoch 117; Iter    76/  229] train: loss: 0.1081713
[Epoch 117; Iter   106/  229] train: loss: 0.1139030
[Epoch 117; Iter   136/  229] train: loss: 0.1226796
[Epoch 117; Iter   166/  229] train: loss: 0.0804680
[Epoch 117; Iter   196/  229] train: loss: 0.1069433
[Epoch 117; Iter   226/  229] train: loss: 0.1009477
[Epoch 117] ogbg-moltoxcast: 0.611221 val loss: 2.915220
[Epoch 117] ogbg-moltoxcast: 0.609883 test loss: 3.123099
[Epoch 118; Iter    27/  229] train: loss: 0.1059368
[Epoch 118; Iter    57/  229] train: loss: 0.0854272
[Epoch 118; Iter    87/  229] train: loss: 0.1137568
[Epoch 118; Iter   117/  229] train: loss: 0.0918591
[Epoch 118; Iter   147/  229] train: loss: 0.1015341
[Epoch 118; Iter   177/  229] train: loss: 0.1211539
[Epoch 118; Iter   207/  229] train: loss: 0.0875682
[Epoch 118] ogbg-moltoxcast: 0.623316 val loss: 2.590581
[Epoch 118] ogbg-moltoxcast: 0.612991 test loss: 3.228041
[Epoch 119; Iter     8/  229] train: loss: 0.0663641
[Epoch 119; Iter    38/  229] train: loss: 0.0929325
[Epoch 119; Iter    68/  229] train: loss: 0.1242575
[Epoch 119; Iter    98/  229] train: loss: 0.0843079
[Epoch 119; Iter   128/  229] train: loss: 0.1435143
[Epoch 119; Iter   158/  229] train: loss: 0.1170397
[Epoch 119; Iter   188/  229] train: loss: 0.1324676
[Epoch 119; Iter   218/  229] train: loss: 0.1779100
[Epoch 119] ogbg-moltoxcast: 0.606558 val loss: 2.627100
[Epoch 119] ogbg-moltoxcast: 0.608472 test loss: 3.305948
[Epoch 120; Iter    19/  229] train: loss: 0.0797895
[Epoch 120; Iter    49/  229] train: loss: 0.1143952
[Epoch 120; Iter    79/  229] train: loss: 0.0802356
[Epoch 120; Iter   109/  229] train: loss: 0.0720576
[Epoch 120; Iter   139/  229] train: loss: 0.1258484
[Epoch 120; Iter   169/  229] train: loss: 0.0751742
[Epoch 120; Iter   199/  229] train: loss: 0.0855854
[Epoch 120; Iter   229/  229] train: loss: 0.1035599
[Epoch 120] ogbg-moltoxcast: 0.619681 val loss: 2.045174
[Epoch 120] ogbg-moltoxcast: 0.611955 test loss: 2.721407
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -2.00441312789917
std_pred: 2.297667980194092
mean_targets: nan
std_targets: nan
prcauc: 0.3692951217354673
rocauc: 0.6743889436521521
ogbg-moltoxcast: 0.6743889436521521
OGBNanLabelBCEWithLogitsLoss: 0.2969891156615882
Statistics on  test
mean_pred: -1.8189780712127686
std_pred: 2.282121181488037
mean_targets: nan
std_targets: nan
prcauc: 0.3438430063815722
rocauc: 0.6375681283375226
ogbg-moltoxcast: 0.6375681283375226
OGBNanLabelBCEWithLogitsLoss: 0.3585207734642358
Statistics on  train
mean_pred: -2.745720148086548
std_pred: 2.1221871376037598
mean_targets: nan
std_targets: nan
prcauc: 0.48443349268554103
rocauc: 0.8262697939023884
ogbg-moltoxcast: 0.8262697939023884
OGBNanLabelBCEWithLogitsLoss: 0.15889474440479903
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 92; Iter    11/  229] train: loss: 0.1215817
[Epoch 92; Iter    41/  229] train: loss: 0.1110005
[Epoch 92; Iter    71/  229] train: loss: 0.1286909
[Epoch 92; Iter   101/  229] train: loss: 0.1107963
[Epoch 92; Iter   131/  229] train: loss: 0.0907227
[Epoch 92; Iter   161/  229] train: loss: 0.0822809
[Epoch 92; Iter   191/  229] train: loss: 0.1155337
[Epoch 92; Iter   221/  229] train: loss: 0.1340541
[Epoch 92] ogbg-moltoxcast: 0.701689 val loss: 0.260401
[Epoch 92] ogbg-moltoxcast: 0.648263 test loss: 0.335052
[Epoch 93; Iter    22/  229] train: loss: 0.0859868
[Epoch 93; Iter    52/  229] train: loss: 0.0739541
[Epoch 93; Iter    82/  229] train: loss: 0.1149496
[Epoch 93; Iter   112/  229] train: loss: 0.1206863
[Epoch 93; Iter   142/  229] train: loss: 0.0926079
[Epoch 93; Iter   172/  229] train: loss: 0.1565294
[Epoch 93; Iter   202/  229] train: loss: 0.1246251
[Epoch 93] ogbg-moltoxcast: 0.704750 val loss: 0.260837
[Epoch 93] ogbg-moltoxcast: 0.653684 test loss: 0.330671
[Epoch 94; Iter     3/  229] train: loss: 0.1779343
[Epoch 94; Iter    33/  229] train: loss: 0.1479226
[Epoch 94; Iter    63/  229] train: loss: 0.1392618
[Epoch 94; Iter    93/  229] train: loss: 0.0859756
[Epoch 94; Iter   123/  229] train: loss: 0.1029948
[Epoch 94; Iter   153/  229] train: loss: 0.1217883
[Epoch 94; Iter   183/  229] train: loss: 0.1340124
[Epoch 94; Iter   213/  229] train: loss: 0.1714856
[Epoch 94] ogbg-moltoxcast: 0.704147 val loss: 0.263004
[Epoch 94] ogbg-moltoxcast: 0.649772 test loss: 0.334383
[Epoch 95; Iter    14/  229] train: loss: 0.1201974
[Epoch 95; Iter    44/  229] train: loss: 0.1275265
[Epoch 95; Iter    74/  229] train: loss: 0.1659502
[Epoch 95; Iter   104/  229] train: loss: 0.1212714
[Epoch 95; Iter   134/  229] train: loss: 0.1347568
[Epoch 95; Iter   164/  229] train: loss: 0.1095356
[Epoch 95; Iter   194/  229] train: loss: 0.0822298
[Epoch 95; Iter   224/  229] train: loss: 0.1124914
[Epoch 95] ogbg-moltoxcast: 0.701325 val loss: 0.265584
[Epoch 95] ogbg-moltoxcast: 0.650802 test loss: 0.335896
[Epoch 96; Iter    25/  229] train: loss: 0.1324442
[Epoch 96; Iter    55/  229] train: loss: 0.0660788
[Epoch 96; Iter    85/  229] train: loss: 0.1348658
[Epoch 96; Iter   115/  229] train: loss: 0.1402254
[Epoch 96; Iter   145/  229] train: loss: 0.1317904
[Epoch 96; Iter   175/  229] train: loss: 0.1361515
[Epoch 96; Iter   205/  229] train: loss: 0.1103098
[Epoch 96] ogbg-moltoxcast: 0.701845 val loss: 0.264425
[Epoch 96] ogbg-moltoxcast: 0.653618 test loss: 0.335707
[Epoch 97; Iter     6/  229] train: loss: 0.1218729
[Epoch 97; Iter    36/  229] train: loss: 0.1051089
[Epoch 97; Iter    66/  229] train: loss: 0.1052361
[Epoch 97; Iter    96/  229] train: loss: 0.1035716
[Epoch 97; Iter   126/  229] train: loss: 0.1343102
[Epoch 97; Iter   156/  229] train: loss: 0.1212038
[Epoch 97; Iter   186/  229] train: loss: 0.0913790
[Epoch 97; Iter   216/  229] train: loss: 0.1268687
[Epoch 97] ogbg-moltoxcast: 0.704658 val loss: 0.260524
[Epoch 97] ogbg-moltoxcast: 0.654996 test loss: 0.330222
[Epoch 98; Iter    17/  229] train: loss: 0.1302670
[Epoch 98; Iter    47/  229] train: loss: 0.1277915
[Epoch 98; Iter    77/  229] train: loss: 0.0991056
[Epoch 98; Iter   107/  229] train: loss: 0.1093482
[Epoch 98; Iter   137/  229] train: loss: 0.1172713
[Epoch 98; Iter   167/  229] train: loss: 0.1420145
[Epoch 98; Iter   197/  229] train: loss: 0.1392667
[Epoch 98; Iter   227/  229] train: loss: 0.1170219
[Epoch 98] ogbg-moltoxcast: 0.701130 val loss: 0.262776
[Epoch 98] ogbg-moltoxcast: 0.648779 test loss: 0.337347
[Epoch 99; Iter    28/  229] train: loss: 0.1385375
[Epoch 99; Iter    58/  229] train: loss: 0.1439033
[Epoch 99; Iter    88/  229] train: loss: 0.1513686
[Epoch 99; Iter   118/  229] train: loss: 0.1459172
[Epoch 99; Iter   148/  229] train: loss: 0.1386673
[Epoch 99; Iter   178/  229] train: loss: 0.1842379
[Epoch 99; Iter   208/  229] train: loss: 0.0567780
[Epoch 99] ogbg-moltoxcast: 0.699597 val loss: 0.263515
[Epoch 99] ogbg-moltoxcast: 0.649273 test loss: 0.339167
[Epoch 100; Iter     9/  229] train: loss: 0.0918557
[Epoch 100; Iter    39/  229] train: loss: 0.1216659
[Epoch 100; Iter    69/  229] train: loss: 0.0961819
[Epoch 100; Iter    99/  229] train: loss: 0.1124067
[Epoch 100; Iter   129/  229] train: loss: 0.1081844
[Epoch 100; Iter   159/  229] train: loss: 0.1068273
[Epoch 100; Iter   189/  229] train: loss: 0.1231195
[Epoch 100; Iter   219/  229] train: loss: 0.1181607
[Epoch 100] ogbg-moltoxcast: 0.705475 val loss: 0.264587
[Epoch 100] ogbg-moltoxcast: 0.651373 test loss: 0.340601
[Epoch 101; Iter    20/  229] train: loss: 0.1564497
[Epoch 101; Iter    50/  229] train: loss: 0.1102807
[Epoch 101; Iter    80/  229] train: loss: 0.0910979
[Epoch 101; Iter   110/  229] train: loss: 0.1195149
[Epoch 101; Iter   140/  229] train: loss: 0.1271186
[Epoch 101; Iter   170/  229] train: loss: 0.1246814
[Epoch 101; Iter   200/  229] train: loss: 0.1649674
[Epoch 101] ogbg-moltoxcast: 0.700402 val loss: 0.265035
[Epoch 101] ogbg-moltoxcast: 0.650656 test loss: 0.337501
[Epoch 102; Iter     1/  229] train: loss: 0.1120063
[Epoch 102; Iter    31/  229] train: loss: 0.1135370
[Epoch 102; Iter    61/  229] train: loss: 0.1660599
[Epoch 102; Iter    91/  229] train: loss: 0.1501189
[Epoch 102; Iter   121/  229] train: loss: 0.1289636
[Epoch 102; Iter   151/  229] train: loss: 0.1095269
[Epoch 102; Iter   181/  229] train: loss: 0.1577696
[Epoch 102; Iter   211/  229] train: loss: 0.1066393
[Epoch 102] ogbg-moltoxcast: 0.700457 val loss: 0.265802
[Epoch 102] ogbg-moltoxcast: 0.652726 test loss: 0.337386
[Epoch 103; Iter    12/  229] train: loss: 0.1033954
[Epoch 103; Iter    42/  229] train: loss: 0.1252983
[Epoch 103; Iter    72/  229] train: loss: 0.0975505
[Epoch 103; Iter   102/  229] train: loss: 0.1605455
[Epoch 103; Iter   132/  229] train: loss: 0.1516217
[Epoch 103; Iter   162/  229] train: loss: 0.0691905
[Epoch 103; Iter   192/  229] train: loss: 0.1214377
[Epoch 103; Iter   222/  229] train: loss: 0.1487893
[Epoch 103] ogbg-moltoxcast: 0.707367 val loss: 0.264071
[Epoch 103] ogbg-moltoxcast: 0.653267 test loss: 0.339209
[Epoch 104; Iter    23/  229] train: loss: 0.1267692
[Epoch 104; Iter    53/  229] train: loss: 0.0785536
[Epoch 104; Iter    83/  229] train: loss: 0.1082481
[Epoch 104; Iter   113/  229] train: loss: 0.1579168
[Epoch 104; Iter   143/  229] train: loss: 0.1483052
[Epoch 104; Iter   173/  229] train: loss: 0.1228833
[Epoch 104; Iter   203/  229] train: loss: 0.1118977
[Epoch 104] ogbg-moltoxcast: 0.710572 val loss: 0.261716
[Epoch 104] ogbg-moltoxcast: 0.655655 test loss: 0.337793
[Epoch 105; Iter     4/  229] train: loss: 0.1099307
[Epoch 105; Iter    34/  229] train: loss: 0.1134430
[Epoch 105; Iter    64/  229] train: loss: 0.1149714
[Epoch 105; Iter    94/  229] train: loss: 0.1209591
[Epoch 105; Iter   124/  229] train: loss: 0.1414487
[Epoch 105; Iter   154/  229] train: loss: 0.1052879
[Epoch 105; Iter   184/  229] train: loss: 0.1069249
[Epoch 105; Iter   214/  229] train: loss: 0.1395632
[Epoch 105] ogbg-moltoxcast: 0.704778 val loss: 0.265829
[Epoch 105] ogbg-moltoxcast: 0.650307 test loss: 0.339119
[Epoch 106; Iter    15/  229] train: loss: 0.1091565
[Epoch 106; Iter    45/  229] train: loss: 0.1031104
[Epoch 106; Iter    75/  229] train: loss: 0.1617881
[Epoch 106; Iter   105/  229] train: loss: 0.1359720
[Epoch 106; Iter   135/  229] train: loss: 0.1256158
[Epoch 106; Iter   165/  229] train: loss: 0.1407288
[Epoch 106; Iter   195/  229] train: loss: 0.1238675
[Epoch 106; Iter   225/  229] train: loss: 0.1266895
[Epoch 106] ogbg-moltoxcast: 0.699082 val loss: 0.267072
[Epoch 106] ogbg-moltoxcast: 0.645347 test loss: 0.342448
[Epoch 107; Iter    26/  229] train: loss: 0.0990683
[Epoch 107; Iter    56/  229] train: loss: 0.1210468
[Epoch 107; Iter    86/  229] train: loss: 0.1067636
[Epoch 107; Iter   116/  229] train: loss: 0.1232405
[Epoch 107; Iter   146/  229] train: loss: 0.0989495
[Epoch 107; Iter   176/  229] train: loss: 0.1194299
[Epoch 107; Iter   206/  229] train: loss: 0.1644166
[Epoch 107] ogbg-moltoxcast: 0.702999 val loss: 0.266552
[Epoch 92; Iter    11/  229] train: loss: 0.1394813
[Epoch 92; Iter    41/  229] train: loss: 0.1295934
[Epoch 92; Iter    71/  229] train: loss: 0.1242096
[Epoch 92; Iter   101/  229] train: loss: 0.1414913
[Epoch 92; Iter   131/  229] train: loss: 0.1332017
[Epoch 92; Iter   161/  229] train: loss: 0.1136881
[Epoch 92; Iter   191/  229] train: loss: 0.1261385
[Epoch 92; Iter   221/  229] train: loss: 0.1688181
[Epoch 92] ogbg-moltoxcast: 0.685386 val loss: 0.278482
[Epoch 92] ogbg-moltoxcast: 0.655932 test loss: 0.330441
[Epoch 93; Iter    22/  229] train: loss: 0.1076056
[Epoch 93; Iter    52/  229] train: loss: 0.1159275
[Epoch 93; Iter    82/  229] train: loss: 0.1624494
[Epoch 93; Iter   112/  229] train: loss: 0.1419087
[Epoch 93; Iter   142/  229] train: loss: 0.1371424
[Epoch 93; Iter   172/  229] train: loss: 0.1209669
[Epoch 93; Iter   202/  229] train: loss: 0.0957408
[Epoch 93] ogbg-moltoxcast: 0.689757 val loss: 0.282334
[Epoch 93] ogbg-moltoxcast: 0.655748 test loss: 0.337253
[Epoch 94; Iter     3/  229] train: loss: 0.1168543
[Epoch 94; Iter    33/  229] train: loss: 0.1322263
[Epoch 94; Iter    63/  229] train: loss: 0.1392555
[Epoch 94; Iter    93/  229] train: loss: 0.1129008
[Epoch 94; Iter   123/  229] train: loss: 0.1299715
[Epoch 94; Iter   153/  229] train: loss: 0.1860798
[Epoch 94; Iter   183/  229] train: loss: 0.1422615
[Epoch 94; Iter   213/  229] train: loss: 0.1152101
[Epoch 94] ogbg-moltoxcast: 0.690773 val loss: 0.279010
[Epoch 94] ogbg-moltoxcast: 0.658983 test loss: 0.332565
[Epoch 95; Iter    14/  229] train: loss: 0.1282827
[Epoch 95; Iter    44/  229] train: loss: 0.0969125
[Epoch 95; Iter    74/  229] train: loss: 0.1526437
[Epoch 95; Iter   104/  229] train: loss: 0.1398512
[Epoch 95; Iter   134/  229] train: loss: 0.0934523
[Epoch 95; Iter   164/  229] train: loss: 0.1181266
[Epoch 95; Iter   194/  229] train: loss: 0.1370158
[Epoch 95; Iter   224/  229] train: loss: 0.1531451
[Epoch 95] ogbg-moltoxcast: 0.688314 val loss: 0.286950
[Epoch 95] ogbg-moltoxcast: 0.656519 test loss: 0.333009
[Epoch 96; Iter    25/  229] train: loss: 0.1371954
[Epoch 96; Iter    55/  229] train: loss: 0.1138640
[Epoch 96; Iter    85/  229] train: loss: 0.1036071
[Epoch 96; Iter   115/  229] train: loss: 0.1462739
[Epoch 96; Iter   145/  229] train: loss: 0.1243009
[Epoch 96; Iter   175/  229] train: loss: 0.1050793
[Epoch 96; Iter   205/  229] train: loss: 0.1574263
[Epoch 96] ogbg-moltoxcast: 0.689392 val loss: 0.280222
[Epoch 96] ogbg-moltoxcast: 0.659695 test loss: 0.330003
[Epoch 97; Iter     6/  229] train: loss: 0.1342092
[Epoch 97; Iter    36/  229] train: loss: 0.1125948
[Epoch 97; Iter    66/  229] train: loss: 0.0932702
[Epoch 97; Iter    96/  229] train: loss: 0.1136934
[Epoch 97; Iter   126/  229] train: loss: 0.1333958
[Epoch 97; Iter   156/  229] train: loss: 0.1022467
[Epoch 97; Iter   186/  229] train: loss: 0.1023790
[Epoch 97; Iter   216/  229] train: loss: 0.1979160
[Epoch 97] ogbg-moltoxcast: 0.685913 val loss: 0.278453
[Epoch 97] ogbg-moltoxcast: 0.655192 test loss: 0.326019
[Epoch 98; Iter    17/  229] train: loss: 0.1282804
[Epoch 98; Iter    47/  229] train: loss: 0.1342440
[Epoch 98; Iter    77/  229] train: loss: 0.1309703
[Epoch 98; Iter   107/  229] train: loss: 0.1113341
[Epoch 98; Iter   137/  229] train: loss: 0.1535191
[Epoch 98; Iter   167/  229] train: loss: 0.1123437
[Epoch 98; Iter   197/  229] train: loss: 0.1071781
[Epoch 98; Iter   227/  229] train: loss: 0.1500272
[Epoch 98] ogbg-moltoxcast: 0.689756 val loss: 0.285523
[Epoch 98] ogbg-moltoxcast: 0.660534 test loss: 0.330398
[Epoch 99; Iter    28/  229] train: loss: 0.1291005
[Epoch 99; Iter    58/  229] train: loss: 0.1472499
[Epoch 99; Iter    88/  229] train: loss: 0.1267715
[Epoch 99; Iter   118/  229] train: loss: 0.1132183
[Epoch 99; Iter   148/  229] train: loss: 0.1984173
[Epoch 99; Iter   178/  229] train: loss: 0.1561140
[Epoch 99; Iter   208/  229] train: loss: 0.1263324
[Epoch 99] ogbg-moltoxcast: 0.686115 val loss: 0.280465
[Epoch 99] ogbg-moltoxcast: 0.658002 test loss: 0.329585
[Epoch 100; Iter     9/  229] train: loss: 0.0965459
[Epoch 100; Iter    39/  229] train: loss: 0.1466550
[Epoch 100; Iter    69/  229] train: loss: 0.1310824
[Epoch 100; Iter    99/  229] train: loss: 0.1204809
[Epoch 100; Iter   129/  229] train: loss: 0.1895972
[Epoch 100; Iter   159/  229] train: loss: 0.1237721
[Epoch 100; Iter   189/  229] train: loss: 0.1259760
[Epoch 100; Iter   219/  229] train: loss: 0.1231671
[Epoch 100] ogbg-moltoxcast: 0.689458 val loss: 0.304839
[Epoch 100] ogbg-moltoxcast: 0.659759 test loss: 0.331548
[Epoch 101; Iter    20/  229] train: loss: 0.1239178
[Epoch 101; Iter    50/  229] train: loss: 0.1005156
[Epoch 101; Iter    80/  229] train: loss: 0.1197153
[Epoch 101; Iter   110/  229] train: loss: 0.1323996
[Epoch 101; Iter   140/  229] train: loss: 0.0799730
[Epoch 101; Iter   170/  229] train: loss: 0.1500799
[Epoch 101; Iter   200/  229] train: loss: 0.1117751
[Epoch 101] ogbg-moltoxcast: 0.690784 val loss: 0.278837
[Epoch 101] ogbg-moltoxcast: 0.660518 test loss: 0.329389
[Epoch 102; Iter     1/  229] train: loss: 0.1419910
[Epoch 102; Iter    31/  229] train: loss: 0.0867580
[Epoch 102; Iter    61/  229] train: loss: 0.0953417
[Epoch 102; Iter    91/  229] train: loss: 0.1187056
[Epoch 102; Iter   121/  229] train: loss: 0.1204888
[Epoch 102; Iter   151/  229] train: loss: 0.1265899
[Epoch 102; Iter   181/  229] train: loss: 0.1265869
[Epoch 102; Iter   211/  229] train: loss: 0.1239679
[Epoch 102] ogbg-moltoxcast: 0.688813 val loss: 0.282361
[Epoch 102] ogbg-moltoxcast: 0.660921 test loss: 0.327589
[Epoch 103; Iter    12/  229] train: loss: 0.0830843
[Epoch 103; Iter    42/  229] train: loss: 0.1245597
[Epoch 103; Iter    72/  229] train: loss: 0.1239095
[Epoch 103; Iter   102/  229] train: loss: 0.1408603
[Epoch 103; Iter   132/  229] train: loss: 0.1213029
[Epoch 103; Iter   162/  229] train: loss: 0.1216686
[Epoch 103; Iter   192/  229] train: loss: 0.1389141
[Epoch 103; Iter   222/  229] train: loss: 0.1366720
[Epoch 103] ogbg-moltoxcast: 0.687570 val loss: 0.293255
[Epoch 103] ogbg-moltoxcast: 0.657696 test loss: 0.332220
[Epoch 104; Iter    23/  229] train: loss: 0.1139650
[Epoch 104; Iter    53/  229] train: loss: 0.1249754
[Epoch 104; Iter    83/  229] train: loss: 0.1045161
[Epoch 104; Iter   113/  229] train: loss: 0.1546613
[Epoch 104; Iter   143/  229] train: loss: 0.1187653
[Epoch 104; Iter   173/  229] train: loss: 0.1106872
[Epoch 104; Iter   203/  229] train: loss: 0.1020841
[Epoch 104] ogbg-moltoxcast: 0.686975 val loss: 0.281750
[Epoch 104] ogbg-moltoxcast: 0.659557 test loss: 0.332323
[Epoch 105; Iter     4/  229] train: loss: 0.1396650
[Epoch 105; Iter    34/  229] train: loss: 0.1069453
[Epoch 105; Iter    64/  229] train: loss: 0.1088746
[Epoch 105; Iter    94/  229] train: loss: 0.1205534
[Epoch 105; Iter   124/  229] train: loss: 0.1480464
[Epoch 105; Iter   154/  229] train: loss: 0.1212566
[Epoch 105; Iter   184/  229] train: loss: 0.1190066
[Epoch 105; Iter   214/  229] train: loss: 0.1203057
[Epoch 105] ogbg-moltoxcast: 0.686893 val loss: 0.283977
[Epoch 105] ogbg-moltoxcast: 0.656959 test loss: 0.334942
[Epoch 106; Iter    15/  229] train: loss: 0.1227841
[Epoch 106; Iter    45/  229] train: loss: 0.0952062
[Epoch 106; Iter    75/  229] train: loss: 0.1401499
[Epoch 106; Iter   105/  229] train: loss: 0.1243555
[Epoch 106; Iter   135/  229] train: loss: 0.1280905
[Epoch 106; Iter   165/  229] train: loss: 0.1419910
[Epoch 106; Iter   195/  229] train: loss: 0.1224402
[Epoch 106; Iter   225/  229] train: loss: 0.1336744
[Epoch 106] ogbg-moltoxcast: 0.686896 val loss: 0.281554
[Epoch 106] ogbg-moltoxcast: 0.656587 test loss: 0.329513
[Epoch 107; Iter    26/  229] train: loss: 0.1358499
[Epoch 107; Iter    56/  229] train: loss: 0.1198923
[Epoch 107; Iter    86/  229] train: loss: 0.1131558
[Epoch 107; Iter   116/  229] train: loss: 0.1110876
[Epoch 107; Iter   146/  229] train: loss: 0.0916274
[Epoch 107; Iter   176/  229] train: loss: 0.1469638
[Epoch 107; Iter   206/  229] train: loss: 0.0957256
[Epoch 107] ogbg-moltoxcast: 0.689463 val loss: 0.282544
[Epoch 92; Iter    11/  229] train: loss: 0.1342323
[Epoch 92; Iter    41/  229] train: loss: 0.1544301
[Epoch 92; Iter    71/  229] train: loss: 0.1006384
[Epoch 92; Iter   101/  229] train: loss: 0.1424629
[Epoch 92; Iter   131/  229] train: loss: 0.1081625
[Epoch 92; Iter   161/  229] train: loss: 0.1211308
[Epoch 92; Iter   191/  229] train: loss: 0.1100558
[Epoch 92; Iter   221/  229] train: loss: 0.1231325
[Epoch 92] ogbg-moltoxcast: 0.682333 val loss: 0.269794
[Epoch 92] ogbg-moltoxcast: 0.648796 test loss: 0.328273
[Epoch 93; Iter    22/  229] train: loss: 0.1284376
[Epoch 93; Iter    52/  229] train: loss: 0.1251028
[Epoch 93; Iter    82/  229] train: loss: 0.0758908
[Epoch 93; Iter   112/  229] train: loss: 0.1298141
[Epoch 93; Iter   142/  229] train: loss: 0.1437867
[Epoch 93; Iter   172/  229] train: loss: 0.1080212
[Epoch 93; Iter   202/  229] train: loss: 0.1152182
[Epoch 93] ogbg-moltoxcast: 0.688108 val loss: 0.265453
[Epoch 93] ogbg-moltoxcast: 0.650908 test loss: 0.326703
[Epoch 94; Iter     3/  229] train: loss: 0.1114050
[Epoch 94; Iter    33/  229] train: loss: 0.1273791
[Epoch 94; Iter    63/  229] train: loss: 0.0998584
[Epoch 94; Iter    93/  229] train: loss: 0.1623401
[Epoch 94; Iter   123/  229] train: loss: 0.1465322
[Epoch 94; Iter   153/  229] train: loss: 0.0844721
[Epoch 94; Iter   183/  229] train: loss: 0.1047101
[Epoch 94; Iter   213/  229] train: loss: 0.1149253
[Epoch 94] ogbg-moltoxcast: 0.681569 val loss: 0.267965
[Epoch 94] ogbg-moltoxcast: 0.647356 test loss: 0.327917
[Epoch 95; Iter    14/  229] train: loss: 0.1428372
[Epoch 95; Iter    44/  229] train: loss: 0.1243994
[Epoch 95; Iter    74/  229] train: loss: 0.1122666
[Epoch 95; Iter   104/  229] train: loss: 0.1038212
[Epoch 95; Iter   134/  229] train: loss: 0.0832589
[Epoch 95; Iter   164/  229] train: loss: 0.1581489
[Epoch 95; Iter   194/  229] train: loss: 0.1231931
[Epoch 95; Iter   224/  229] train: loss: 0.1190279
[Epoch 95] ogbg-moltoxcast: 0.682888 val loss: 0.266317
[Epoch 95] ogbg-moltoxcast: 0.650824 test loss: 0.326634
[Epoch 96; Iter    25/  229] train: loss: 0.1377470
[Epoch 96; Iter    55/  229] train: loss: 0.1180261
[Epoch 96; Iter    85/  229] train: loss: 0.1251802
[Epoch 96; Iter   115/  229] train: loss: 0.0969354
[Epoch 96; Iter   145/  229] train: loss: 0.1330419
[Epoch 96; Iter   175/  229] train: loss: 0.1140089
[Epoch 96; Iter   205/  229] train: loss: 0.1211245
[Epoch 96] ogbg-moltoxcast: 0.684028 val loss: 0.266953
[Epoch 96] ogbg-moltoxcast: 0.650053 test loss: 0.325988
[Epoch 97; Iter     6/  229] train: loss: 0.0746249
[Epoch 97; Iter    36/  229] train: loss: 0.1396063
[Epoch 97; Iter    66/  229] train: loss: 0.0988764
[Epoch 97; Iter    96/  229] train: loss: 0.1902051
[Epoch 97; Iter   126/  229] train: loss: 0.0965322
[Epoch 97; Iter   156/  229] train: loss: 0.1002775
[Epoch 97; Iter   186/  229] train: loss: 0.1225339
[Epoch 97; Iter   216/  229] train: loss: 0.0942437
[Epoch 97] ogbg-moltoxcast: 0.685063 val loss: 0.266238
[Epoch 97] ogbg-moltoxcast: 0.649969 test loss: 0.326400
[Epoch 98; Iter    17/  229] train: loss: 0.1722644
[Epoch 98; Iter    47/  229] train: loss: 0.1357222
[Epoch 98; Iter    77/  229] train: loss: 0.1450009
[Epoch 98; Iter   107/  229] train: loss: 0.1312566
[Epoch 98; Iter   137/  229] train: loss: 0.1025959
[Epoch 98; Iter   167/  229] train: loss: 0.0714899
[Epoch 98; Iter   197/  229] train: loss: 0.1130021
[Epoch 98; Iter   227/  229] train: loss: 0.1587896
[Epoch 98] ogbg-moltoxcast: 0.681728 val loss: 0.267727
[Epoch 98] ogbg-moltoxcast: 0.650246 test loss: 0.330445
[Epoch 99; Iter    28/  229] train: loss: 0.1478349
[Epoch 99; Iter    58/  229] train: loss: 0.0866061
[Epoch 99; Iter    88/  229] train: loss: 0.1232876
[Epoch 99; Iter   118/  229] train: loss: 0.1551297
[Epoch 99; Iter   148/  229] train: loss: 0.1551490
[Epoch 99; Iter   178/  229] train: loss: 0.1293203
[Epoch 99; Iter   208/  229] train: loss: 0.1414226
[Epoch 99] ogbg-moltoxcast: 0.685054 val loss: 0.267469
[Epoch 99] ogbg-moltoxcast: 0.651622 test loss: 0.327292
[Epoch 100; Iter     9/  229] train: loss: 0.0964044
[Epoch 100; Iter    39/  229] train: loss: 0.1447554
[Epoch 100; Iter    69/  229] train: loss: 0.1267432
[Epoch 100; Iter    99/  229] train: loss: 0.1162274
[Epoch 100; Iter   129/  229] train: loss: 0.1500066
[Epoch 100; Iter   159/  229] train: loss: 0.1329056
[Epoch 100; Iter   189/  229] train: loss: 0.1319558
[Epoch 100; Iter   219/  229] train: loss: 0.2224204
[Epoch 100] ogbg-moltoxcast: 0.681391 val loss: 0.272380
[Epoch 100] ogbg-moltoxcast: 0.652062 test loss: 0.331102
[Epoch 101; Iter    20/  229] train: loss: 0.1174413
[Epoch 101; Iter    50/  229] train: loss: 0.1322807
[Epoch 101; Iter    80/  229] train: loss: 0.1082356
[Epoch 101; Iter   110/  229] train: loss: 0.1374609
[Epoch 101; Iter   140/  229] train: loss: 0.1280813
[Epoch 101; Iter   170/  229] train: loss: 0.0963965
[Epoch 101; Iter   200/  229] train: loss: 0.1160036
[Epoch 101] ogbg-moltoxcast: 0.680087 val loss: 0.267967
[Epoch 101] ogbg-moltoxcast: 0.648257 test loss: 0.330849
[Epoch 102; Iter     1/  229] train: loss: 0.1294057
[Epoch 102; Iter    31/  229] train: loss: 0.1023010
[Epoch 102; Iter    61/  229] train: loss: 0.1453090
[Epoch 102; Iter    91/  229] train: loss: 0.1153494
[Epoch 102; Iter   121/  229] train: loss: 0.1076043
[Epoch 102; Iter   151/  229] train: loss: 0.1149648
[Epoch 102; Iter   181/  229] train: loss: 0.0936442
[Epoch 102; Iter   211/  229] train: loss: 0.1441154
[Epoch 102] ogbg-moltoxcast: 0.681074 val loss: 0.269328
[Epoch 102] ogbg-moltoxcast: 0.649486 test loss: 0.331056
[Epoch 103; Iter    12/  229] train: loss: 0.1110987
[Epoch 103; Iter    42/  229] train: loss: 0.1211185
[Epoch 103; Iter    72/  229] train: loss: 0.1166866
[Epoch 103; Iter   102/  229] train: loss: 0.1335644
[Epoch 103; Iter   132/  229] train: loss: 0.1073883
[Epoch 103; Iter   162/  229] train: loss: 0.1570200
[Epoch 103; Iter   192/  229] train: loss: 0.1120998
[Epoch 103; Iter   222/  229] train: loss: 0.1244377
[Epoch 103] ogbg-moltoxcast: 0.678793 val loss: 0.270911
[Epoch 103] ogbg-moltoxcast: 0.646441 test loss: 0.335055
[Epoch 104; Iter    23/  229] train: loss: 0.1110230
[Epoch 104; Iter    53/  229] train: loss: 0.1029358
[Epoch 104; Iter    83/  229] train: loss: 0.1251419
[Epoch 104; Iter   113/  229] train: loss: 0.1026774
[Epoch 104; Iter   143/  229] train: loss: 0.0902900
[Epoch 104; Iter   173/  229] train: loss: 0.1050157
[Epoch 104; Iter   203/  229] train: loss: 0.1347065
[Epoch 104] ogbg-moltoxcast: 0.684867 val loss: 0.269466
[Epoch 104] ogbg-moltoxcast: 0.648196 test loss: 0.332713
[Epoch 105; Iter     4/  229] train: loss: 0.1055964
[Epoch 105; Iter    34/  229] train: loss: 0.1024313
[Epoch 105; Iter    64/  229] train: loss: 0.1227168
[Epoch 105; Iter    94/  229] train: loss: 0.1230948
[Epoch 105; Iter   124/  229] train: loss: 0.0780398
[Epoch 105; Iter   154/  229] train: loss: 0.1079940
[Epoch 105; Iter   184/  229] train: loss: 0.1283722
[Epoch 105; Iter   214/  229] train: loss: 0.1475283
[Epoch 105] ogbg-moltoxcast: 0.680358 val loss: 0.282980
[Epoch 105] ogbg-moltoxcast: 0.648204 test loss: 0.340659
[Epoch 106; Iter    15/  229] train: loss: 0.0865475
[Epoch 106; Iter    45/  229] train: loss: 0.0904587
[Epoch 106; Iter    75/  229] train: loss: 0.1064900
[Epoch 106; Iter   105/  229] train: loss: 0.1018786
[Epoch 106; Iter   135/  229] train: loss: 0.1116620
[Epoch 106; Iter   165/  229] train: loss: 0.1067776
[Epoch 106; Iter   195/  229] train: loss: 0.1722133
[Epoch 106; Iter   225/  229] train: loss: 0.1398122
[Epoch 106] ogbg-moltoxcast: 0.679997 val loss: 0.272275
[Epoch 106] ogbg-moltoxcast: 0.646053 test loss: 0.336396
[Epoch 107; Iter    26/  229] train: loss: 0.0980274
[Epoch 107; Iter    56/  229] train: loss: 0.1252140
[Epoch 107; Iter    86/  229] train: loss: 0.1265721
[Epoch 107; Iter   116/  229] train: loss: 0.1350680
[Epoch 107; Iter   146/  229] train: loss: 0.1163329
[Epoch 107; Iter   176/  229] train: loss: 0.1632052
[Epoch 107; Iter   206/  229] train: loss: 0.1301666
[Epoch 107] ogbg-moltoxcast: 0.680821 val loss: 0.268575
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.653205 test loss: 0.339651
[Epoch 108; Iter     7/  229] train: loss: 0.1362269
[Epoch 108; Iter    37/  229] train: loss: 0.1692741
[Epoch 108; Iter    67/  229] train: loss: 0.1312223
[Epoch 108; Iter    97/  229] train: loss: 0.0922830
[Epoch 108; Iter   127/  229] train: loss: 0.1157352
[Epoch 108; Iter   157/  229] train: loss: 0.1056473
[Epoch 108; Iter   187/  229] train: loss: 0.1274070
[Epoch 108; Iter   217/  229] train: loss: 0.1237063
[Epoch 108] ogbg-moltoxcast: 0.697707 val loss: 0.265995
[Epoch 108] ogbg-moltoxcast: 0.649822 test loss: 0.337841
[Epoch 109; Iter    18/  229] train: loss: 0.1250589
[Epoch 109; Iter    48/  229] train: loss: 0.1294975
[Epoch 109; Iter    78/  229] train: loss: 0.0830490
[Epoch 109; Iter   108/  229] train: loss: 0.1825874
[Epoch 109; Iter   138/  229] train: loss: 0.1843050
[Epoch 109; Iter   168/  229] train: loss: 0.1785925
[Epoch 109; Iter   198/  229] train: loss: 0.1106875
[Epoch 109; Iter   228/  229] train: loss: 0.1687803
[Epoch 109] ogbg-moltoxcast: 0.698991 val loss: 0.266644
[Epoch 109] ogbg-moltoxcast: 0.649101 test loss: 0.345472
[Epoch 110; Iter    29/  229] train: loss: 0.1162004
[Epoch 110; Iter    59/  229] train: loss: 0.1222666
[Epoch 110; Iter    89/  229] train: loss: 0.1879136
[Epoch 110; Iter   119/  229] train: loss: 0.1876076
[Epoch 110; Iter   149/  229] train: loss: 0.1251141
[Epoch 110; Iter   179/  229] train: loss: 0.1588785
[Epoch 110; Iter   209/  229] train: loss: 0.1042257
[Epoch 110] ogbg-moltoxcast: 0.702543 val loss: 0.264910
[Epoch 110] ogbg-moltoxcast: 0.650305 test loss: 0.342513
[Epoch 111; Iter    10/  229] train: loss: 0.1439061
[Epoch 111; Iter    40/  229] train: loss: 0.0938390
[Epoch 111; Iter    70/  229] train: loss: 0.0961121
[Epoch 111; Iter   100/  229] train: loss: 0.1183336
[Epoch 111; Iter   130/  229] train: loss: 0.1268781
[Epoch 111; Iter   160/  229] train: loss: 0.1280649
[Epoch 111; Iter   190/  229] train: loss: 0.1130376
[Epoch 111; Iter   220/  229] train: loss: 0.1418781
[Epoch 111] ogbg-moltoxcast: 0.697485 val loss: 0.269014
[Epoch 111] ogbg-moltoxcast: 0.648755 test loss: 0.345164
[Epoch 112; Iter    21/  229] train: loss: 0.1032806
[Epoch 112; Iter    51/  229] train: loss: 0.0937336
[Epoch 112; Iter    81/  229] train: loss: 0.1217559
[Epoch 112; Iter   111/  229] train: loss: 0.1239078
[Epoch 112; Iter   141/  229] train: loss: 0.1313616
[Epoch 112; Iter   171/  229] train: loss: 0.1038664
[Epoch 112; Iter   201/  229] train: loss: 0.1276551
[Epoch 112] ogbg-moltoxcast: 0.701515 val loss: 0.267784
[Epoch 112] ogbg-moltoxcast: 0.652706 test loss: 0.343748
[Epoch 113; Iter     2/  229] train: loss: 0.0602878
[Epoch 113; Iter    32/  229] train: loss: 0.1081497
[Epoch 113; Iter    62/  229] train: loss: 0.1314821
[Epoch 113; Iter    92/  229] train: loss: 0.1823218
[Epoch 113; Iter   122/  229] train: loss: 0.0745748
[Epoch 113; Iter   152/  229] train: loss: 0.1549773
[Epoch 113; Iter   182/  229] train: loss: 0.1030208
[Epoch 113; Iter   212/  229] train: loss: 0.1244705
[Epoch 113] ogbg-moltoxcast: 0.698221 val loss: 0.269251
[Epoch 113] ogbg-moltoxcast: 0.649070 test loss: 0.346277
[Epoch 114; Iter    13/  229] train: loss: 0.1097691
[Epoch 114; Iter    43/  229] train: loss: 0.1015043
[Epoch 114; Iter    73/  229] train: loss: 0.1141364
[Epoch 114; Iter   103/  229] train: loss: 0.0953723
[Epoch 114; Iter   133/  229] train: loss: 0.1315564
[Epoch 114; Iter   163/  229] train: loss: 0.0943159
[Epoch 114; Iter   193/  229] train: loss: 0.1149172
[Epoch 114; Iter   223/  229] train: loss: 0.0962419
[Epoch 114] ogbg-moltoxcast: 0.699284 val loss: 0.266891
[Epoch 114] ogbg-moltoxcast: 0.648499 test loss: 0.343548
[Epoch 115; Iter    24/  229] train: loss: 0.1160739
[Epoch 115; Iter    54/  229] train: loss: 0.1050304
[Epoch 115; Iter    84/  229] train: loss: 0.1562672
[Epoch 115; Iter   114/  229] train: loss: 0.1155900
[Epoch 115; Iter   144/  229] train: loss: 0.1159384
[Epoch 115; Iter   174/  229] train: loss: 0.0854741
[Epoch 115; Iter   204/  229] train: loss: 0.1421216
[Epoch 115] ogbg-moltoxcast: 0.696318 val loss: 0.267188
[Epoch 115] ogbg-moltoxcast: 0.648741 test loss: 0.343711
[Epoch 116; Iter     5/  229] train: loss: 0.1201729
[Epoch 116; Iter    35/  229] train: loss: 0.0976625
[Epoch 116; Iter    65/  229] train: loss: 0.2070557
[Epoch 116; Iter    95/  229] train: loss: 0.1132281
[Epoch 116; Iter   125/  229] train: loss: 0.1302086
[Epoch 116; Iter   155/  229] train: loss: 0.1387359
[Epoch 116; Iter   185/  229] train: loss: 0.1109364
[Epoch 116; Iter   215/  229] train: loss: 0.0978753
[Epoch 116] ogbg-moltoxcast: 0.698575 val loss: 0.269325
[Epoch 116] ogbg-moltoxcast: 0.651028 test loss: 0.340598
[Epoch 117; Iter    16/  229] train: loss: 0.1480966
[Epoch 117; Iter    46/  229] train: loss: 0.1557550
[Epoch 117; Iter    76/  229] train: loss: 0.1068913
[Epoch 117; Iter   106/  229] train: loss: 0.1508177
[Epoch 117; Iter   136/  229] train: loss: 0.0983735
[Epoch 117; Iter   166/  229] train: loss: 0.0698072
[Epoch 117; Iter   196/  229] train: loss: 0.1795204
[Epoch 117; Iter   226/  229] train: loss: 0.1012976
[Epoch 117] ogbg-moltoxcast: 0.698746 val loss: 0.271077
[Epoch 117] ogbg-moltoxcast: 0.650865 test loss: 0.346062
[Epoch 118; Iter    27/  229] train: loss: 0.0681702
[Epoch 118; Iter    57/  229] train: loss: 0.1099918
[Epoch 118; Iter    87/  229] train: loss: 0.0815185
[Epoch 118; Iter   117/  229] train: loss: 0.1356679
[Epoch 118; Iter   147/  229] train: loss: 0.1162262
[Epoch 118; Iter   177/  229] train: loss: 0.1205815
[Epoch 118; Iter   207/  229] train: loss: 0.1930025
[Epoch 118] ogbg-moltoxcast: 0.699971 val loss: 0.266669
[Epoch 118] ogbg-moltoxcast: 0.651126 test loss: 0.343341
[Epoch 119; Iter     8/  229] train: loss: 0.1410051
[Epoch 119; Iter    38/  229] train: loss: 0.0991396
[Epoch 119; Iter    68/  229] train: loss: 0.1367947
[Epoch 119; Iter    98/  229] train: loss: 0.0778540
[Epoch 119; Iter   128/  229] train: loss: 0.1161446
[Epoch 119; Iter   158/  229] train: loss: 0.1053039
[Epoch 119; Iter   188/  229] train: loss: 0.1546464
[Epoch 119; Iter   218/  229] train: loss: 0.1425093
[Epoch 119] ogbg-moltoxcast: 0.702996 val loss: 0.270162
[Epoch 119] ogbg-moltoxcast: 0.649548 test loss: 0.348951
[Epoch 120; Iter    19/  229] train: loss: 0.1198018
[Epoch 120; Iter    49/  229] train: loss: 0.1283962
[Epoch 120; Iter    79/  229] train: loss: 0.1043757
[Epoch 120; Iter   109/  229] train: loss: 0.1392220
[Epoch 120; Iter   139/  229] train: loss: 0.1385048
[Epoch 120; Iter   169/  229] train: loss: 0.1320587
[Epoch 120; Iter   199/  229] train: loss: 0.0922659
[Epoch 120; Iter   229/  229] train: loss: 0.1876520
[Epoch 120] ogbg-moltoxcast: 0.701819 val loss: 0.269781
[Epoch 120] ogbg-moltoxcast: 0.648696 test loss: 0.348066
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: -2.416414737701416
std_pred: 2.5998830795288086
mean_targets: nan
std_targets: nan
prcauc: 0.43193447007061425
rocauc: 0.7166011436399109
ogbg-moltoxcast: 0.7166011436399109
OGBNanLabelBCEWithLogitsLoss: 0.25183759218659896
Statistics on  test
mean_pred: -2.09997296333313
std_pred: 2.592548131942749
mean_targets: nan
std_targets: nan
prcauc: 0.36586217020055134
rocauc: 0.6685639728556221
ogbg-moltoxcast: 0.6685639728556221
OGBNanLabelBCEWithLogitsLoss: 0.31854702223991527
Statistics on  train
mean_pred: -3.074699878692627
std_pred: 2.600250005722046
mean_targets: nan
std_targets: nan
prcauc: 0.574371449797848
rocauc: 0.8780917907180967
ogbg-moltoxcast: 0.8780917907180967
OGBNanLabelBCEWithLogitsLoss: 0.1431685439493979
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.657176 test loss: 0.335368
[Epoch 108; Iter     7/  229] train: loss: 0.1207911
[Epoch 108; Iter    37/  229] train: loss: 0.1520306
[Epoch 108; Iter    67/  229] train: loss: 0.1201097
[Epoch 108; Iter    97/  229] train: loss: 0.1320766
[Epoch 108; Iter   127/  229] train: loss: 0.2071780
[Epoch 108; Iter   157/  229] train: loss: 0.1047032
[Epoch 108; Iter   187/  229] train: loss: 0.1069652
[Epoch 108; Iter   217/  229] train: loss: 0.0945871
[Epoch 108] ogbg-moltoxcast: 0.686271 val loss: 0.287035
[Epoch 108] ogbg-moltoxcast: 0.656057 test loss: 0.331771
[Epoch 109; Iter    18/  229] train: loss: 0.1281507
[Epoch 109; Iter    48/  229] train: loss: 0.1294060
[Epoch 109; Iter    78/  229] train: loss: 0.1220473
[Epoch 109; Iter   108/  229] train: loss: 0.1516809
[Epoch 109; Iter   138/  229] train: loss: 0.1192166
[Epoch 109; Iter   168/  229] train: loss: 0.1521774
[Epoch 109; Iter   198/  229] train: loss: 0.1217499
[Epoch 109; Iter   228/  229] train: loss: 0.0875807
[Epoch 109] ogbg-moltoxcast: 0.686927 val loss: 0.285022
[Epoch 109] ogbg-moltoxcast: 0.656139 test loss: 0.332347
[Epoch 110; Iter    29/  229] train: loss: 0.0814622
[Epoch 110; Iter    59/  229] train: loss: 0.0930246
[Epoch 110; Iter    89/  229] train: loss: 0.0764563
[Epoch 110; Iter   119/  229] train: loss: 0.1328083
[Epoch 110; Iter   149/  229] train: loss: 0.1044758
[Epoch 110; Iter   179/  229] train: loss: 0.1685258
[Epoch 110; Iter   209/  229] train: loss: 0.0940431
[Epoch 110] ogbg-moltoxcast: 0.686893 val loss: 0.287313
[Epoch 110] ogbg-moltoxcast: 0.657651 test loss: 0.335096
[Epoch 111; Iter    10/  229] train: loss: 0.1360738
[Epoch 111; Iter    40/  229] train: loss: 0.0927863
[Epoch 111; Iter    70/  229] train: loss: 0.1090493
[Epoch 111; Iter   100/  229] train: loss: 0.1365901
[Epoch 111; Iter   130/  229] train: loss: 0.1055307
[Epoch 111; Iter   160/  229] train: loss: 0.1499663
[Epoch 111; Iter   190/  229] train: loss: 0.1198304
[Epoch 111; Iter   220/  229] train: loss: 0.1034263
[Epoch 111] ogbg-moltoxcast: 0.689631 val loss: 0.292217
[Epoch 111] ogbg-moltoxcast: 0.656914 test loss: 0.340710
[Epoch 112; Iter    21/  229] train: loss: 0.1242186
[Epoch 112; Iter    51/  229] train: loss: 0.0911511
[Epoch 112; Iter    81/  229] train: loss: 0.0866688
[Epoch 112; Iter   111/  229] train: loss: 0.1140202
[Epoch 112; Iter   141/  229] train: loss: 0.1119169
[Epoch 112; Iter   171/  229] train: loss: 0.1449386
[Epoch 112; Iter   201/  229] train: loss: 0.1031761
[Epoch 112] ogbg-moltoxcast: 0.690551 val loss: 0.286248
[Epoch 112] ogbg-moltoxcast: 0.657318 test loss: 0.339363
[Epoch 113; Iter     2/  229] train: loss: 0.1589251
[Epoch 113; Iter    32/  229] train: loss: 0.1041778
[Epoch 113; Iter    62/  229] train: loss: 0.1533340
[Epoch 113; Iter    92/  229] train: loss: 0.1102261
[Epoch 113; Iter   122/  229] train: loss: 0.1329794
[Epoch 113; Iter   152/  229] train: loss: 0.1057439
[Epoch 113; Iter   182/  229] train: loss: 0.1143375
[Epoch 113; Iter   212/  229] train: loss: 0.1789971
[Epoch 113] ogbg-moltoxcast: 0.690988 val loss: 0.286033
[Epoch 113] ogbg-moltoxcast: 0.662105 test loss: 0.330830
[Epoch 114; Iter    13/  229] train: loss: 0.0966083
[Epoch 114; Iter    43/  229] train: loss: 0.1421606
[Epoch 114; Iter    73/  229] train: loss: 0.1545461
[Epoch 114; Iter   103/  229] train: loss: 0.1152197
[Epoch 114; Iter   133/  229] train: loss: 0.1408787
[Epoch 114; Iter   163/  229] train: loss: 0.1438129
[Epoch 114; Iter   193/  229] train: loss: 0.1537682
[Epoch 114; Iter   223/  229] train: loss: 0.1127988
[Epoch 114] ogbg-moltoxcast: 0.688041 val loss: 0.283502
[Epoch 114] ogbg-moltoxcast: 0.656826 test loss: 0.333001
[Epoch 115; Iter    24/  229] train: loss: 0.0916155
[Epoch 115; Iter    54/  229] train: loss: 0.1203042
[Epoch 115; Iter    84/  229] train: loss: 0.1452611
[Epoch 115; Iter   114/  229] train: loss: 0.0874324
[Epoch 115; Iter   144/  229] train: loss: 0.1535480
[Epoch 115; Iter   174/  229] train: loss: 0.1130102
[Epoch 115; Iter   204/  229] train: loss: 0.0909734
[Epoch 115] ogbg-moltoxcast: 0.689890 val loss: 0.286898
[Epoch 115] ogbg-moltoxcast: 0.659023 test loss: 0.335507
[Epoch 116; Iter     5/  229] train: loss: 0.1691233
[Epoch 116; Iter    35/  229] train: loss: 0.1182462
[Epoch 116; Iter    65/  229] train: loss: 0.1170111
[Epoch 116; Iter    95/  229] train: loss: 0.1154478
[Epoch 116; Iter   125/  229] train: loss: 0.1274779
[Epoch 116; Iter   155/  229] train: loss: 0.1345088
[Epoch 116; Iter   185/  229] train: loss: 0.0965797
[Epoch 116; Iter   215/  229] train: loss: 0.0862750
[Epoch 116] ogbg-moltoxcast: 0.689872 val loss: 0.287033
[Epoch 116] ogbg-moltoxcast: 0.658883 test loss: 0.334792
[Epoch 117; Iter    16/  229] train: loss: 0.1310332
[Epoch 117; Iter    46/  229] train: loss: 0.1436297
[Epoch 117; Iter    76/  229] train: loss: 0.1190599
[Epoch 117; Iter   106/  229] train: loss: 0.1282627
[Epoch 117; Iter   136/  229] train: loss: 0.1329931
[Epoch 117; Iter   166/  229] train: loss: 0.0898387
[Epoch 117; Iter   196/  229] train: loss: 0.1154626
[Epoch 117; Iter   226/  229] train: loss: 0.1136572
[Epoch 117] ogbg-moltoxcast: 0.686977 val loss: 0.294188
[Epoch 117] ogbg-moltoxcast: 0.655998 test loss: 0.335245
[Epoch 118; Iter    27/  229] train: loss: 0.1160182
[Epoch 118; Iter    57/  229] train: loss: 0.0856105
[Epoch 118; Iter    87/  229] train: loss: 0.1239390
[Epoch 118; Iter   117/  229] train: loss: 0.0878148
[Epoch 118; Iter   147/  229] train: loss: 0.1113181
[Epoch 118; Iter   177/  229] train: loss: 0.1454142
[Epoch 118; Iter   207/  229] train: loss: 0.1063351
[Epoch 118] ogbg-moltoxcast: 0.686918 val loss: 0.288948
[Epoch 118] ogbg-moltoxcast: 0.656221 test loss: 0.336875
[Epoch 119; Iter     8/  229] train: loss: 0.0821091
[Epoch 119; Iter    38/  229] train: loss: 0.1081907
[Epoch 119; Iter    68/  229] train: loss: 0.1364412
[Epoch 119; Iter    98/  229] train: loss: 0.0937872
[Epoch 119; Iter   128/  229] train: loss: 0.1535323
[Epoch 119; Iter   158/  229] train: loss: 0.1325100
[Epoch 119; Iter   188/  229] train: loss: 0.1437301
[Epoch 119; Iter   218/  229] train: loss: 0.1849701
[Epoch 119] ogbg-moltoxcast: 0.689265 val loss: 0.288213
[Epoch 119] ogbg-moltoxcast: 0.656619 test loss: 0.339511
[Epoch 120; Iter    19/  229] train: loss: 0.0944119
[Epoch 120; Iter    49/  229] train: loss: 0.1230481
[Epoch 120; Iter    79/  229] train: loss: 0.0892831
[Epoch 120; Iter   109/  229] train: loss: 0.0711335
[Epoch 120; Iter   139/  229] train: loss: 0.1398140
[Epoch 120; Iter   169/  229] train: loss: 0.0970680
[Epoch 120; Iter   199/  229] train: loss: 0.0960799
[Epoch 120; Iter   229/  229] train: loss: 0.1096054
[Epoch 120] ogbg-moltoxcast: 0.692259 val loss: 0.285132
[Epoch 120] ogbg-moltoxcast: 0.657248 test loss: 0.337509
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.4056639671325684
std_pred: 2.4655351638793945
mean_targets: nan
std_targets: nan
prcauc: 0.4026091836189579
rocauc: 0.7023357415079149
ogbg-moltoxcast: 0.7023357415079149
OGBNanLabelBCEWithLogitsLoss: 0.25173449619063015
Statistics on  test
mean_pred: -2.124009609222412
std_pred: 2.383417844772339
mean_targets: nan
std_targets: nan
prcauc: 0.3588069019508483
rocauc: 0.6534294366583111
ogbg-moltoxcast: 0.6534294366583111
OGBNanLabelBCEWithLogitsLoss: 0.29966756495936164
Statistics on  train
mean_pred: -3.0579323768615723
std_pred: 2.3847854137420654
mean_targets: nan
std_targets: nan
prcauc: 0.521837932515861
rocauc: 0.8479118295364787
ogbg-moltoxcast: 0.8479118295364787
OGBNanLabelBCEWithLogitsLoss: 0.15653427185970623
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.644842 test loss: 0.331965
[Epoch 108; Iter     7/  229] train: loss: 0.1060706
[Epoch 108; Iter    37/  229] train: loss: 0.1850419
[Epoch 108; Iter    67/  229] train: loss: 0.1180436
[Epoch 108; Iter    97/  229] train: loss: 0.1614865
[Epoch 108; Iter   127/  229] train: loss: 0.1329097
[Epoch 108; Iter   157/  229] train: loss: 0.1303495
[Epoch 108; Iter   187/  229] train: loss: 0.1263914
[Epoch 108; Iter   217/  229] train: loss: 0.1121814
[Epoch 108] ogbg-moltoxcast: 0.683138 val loss: 0.273232
[Epoch 108] ogbg-moltoxcast: 0.645547 test loss: 0.335132
[Epoch 109; Iter    18/  229] train: loss: 0.1021111
[Epoch 109; Iter    48/  229] train: loss: 0.1247959
[Epoch 109; Iter    78/  229] train: loss: 0.0968249
[Epoch 109; Iter   108/  229] train: loss: 0.1163449
[Epoch 109; Iter   138/  229] train: loss: 0.0838683
[Epoch 109; Iter   168/  229] train: loss: 0.1329962
[Epoch 109; Iter   198/  229] train: loss: 0.1213929
[Epoch 109; Iter   228/  229] train: loss: 0.1328222
[Epoch 109] ogbg-moltoxcast: 0.674509 val loss: 0.270826
[Epoch 109] ogbg-moltoxcast: 0.646577 test loss: 0.331831
[Epoch 110; Iter    29/  229] train: loss: 0.1263885
[Epoch 110; Iter    59/  229] train: loss: 0.1340405
[Epoch 110; Iter    89/  229] train: loss: 0.1412487
[Epoch 110; Iter   119/  229] train: loss: 0.1734269
[Epoch 110; Iter   149/  229] train: loss: 0.1560347
[Epoch 110; Iter   179/  229] train: loss: 0.1513281
[Epoch 110; Iter   209/  229] train: loss: 0.0988901
[Epoch 110] ogbg-moltoxcast: 0.676409 val loss: 0.271543
[Epoch 110] ogbg-moltoxcast: 0.644407 test loss: 0.335505
[Epoch 111; Iter    10/  229] train: loss: 0.0898684
[Epoch 111; Iter    40/  229] train: loss: 0.1264901
[Epoch 111; Iter    70/  229] train: loss: 0.1447038
[Epoch 111; Iter   100/  229] train: loss: 0.1168144
[Epoch 111; Iter   130/  229] train: loss: 0.1370777
[Epoch 111; Iter   160/  229] train: loss: 0.1734084
[Epoch 111; Iter   190/  229] train: loss: 0.0964749
[Epoch 111; Iter   220/  229] train: loss: 0.1253756
[Epoch 111] ogbg-moltoxcast: 0.676980 val loss: 0.271844
[Epoch 111] ogbg-moltoxcast: 0.644985 test loss: 0.336339
[Epoch 112; Iter    21/  229] train: loss: 0.1103404
[Epoch 112; Iter    51/  229] train: loss: 0.1312860
[Epoch 112; Iter    81/  229] train: loss: 0.0806447
[Epoch 112; Iter   111/  229] train: loss: 0.1085491
[Epoch 112; Iter   141/  229] train: loss: 0.1137742
[Epoch 112; Iter   171/  229] train: loss: 0.1189720
[Epoch 112; Iter   201/  229] train: loss: 0.0913980
[Epoch 112] ogbg-moltoxcast: 0.677250 val loss: 0.271182
[Epoch 112] ogbg-moltoxcast: 0.643003 test loss: 0.337530
[Epoch 113; Iter     2/  229] train: loss: 0.1500899
[Epoch 113; Iter    32/  229] train: loss: 0.1485034
[Epoch 113; Iter    62/  229] train: loss: 0.1381436
[Epoch 113; Iter    92/  229] train: loss: 0.1497844
[Epoch 113; Iter   122/  229] train: loss: 0.1662286
[Epoch 113; Iter   152/  229] train: loss: 0.1187786
[Epoch 113; Iter   182/  229] train: loss: 0.1192420
[Epoch 113; Iter   212/  229] train: loss: 0.1050226
[Epoch 113] ogbg-moltoxcast: 0.680231 val loss: 0.276509
[Epoch 113] ogbg-moltoxcast: 0.644198 test loss: 0.340554
[Epoch 114; Iter    13/  229] train: loss: 0.0778209
[Epoch 114; Iter    43/  229] train: loss: 0.1324259
[Epoch 114; Iter    73/  229] train: loss: 0.1175748
[Epoch 114; Iter   103/  229] train: loss: 0.1438984
[Epoch 114; Iter   133/  229] train: loss: 0.1289580
[Epoch 114; Iter   163/  229] train: loss: 0.0903715
[Epoch 114; Iter   193/  229] train: loss: 0.1349676
[Epoch 114; Iter   223/  229] train: loss: 0.0859039
[Epoch 114] ogbg-moltoxcast: 0.675644 val loss: 0.272672
[Epoch 114] ogbg-moltoxcast: 0.645127 test loss: 0.338002
[Epoch 115; Iter    24/  229] train: loss: 0.0899402
[Epoch 115; Iter    54/  229] train: loss: 0.1327222
[Epoch 115; Iter    84/  229] train: loss: 0.1256109
[Epoch 115; Iter   114/  229] train: loss: 0.0778927
[Epoch 115; Iter   144/  229] train: loss: 0.0737963
[Epoch 115; Iter   174/  229] train: loss: 0.1467011
[Epoch 115; Iter   204/  229] train: loss: 0.1463928
[Epoch 115] ogbg-moltoxcast: 0.679847 val loss: 0.273731
[Epoch 115] ogbg-moltoxcast: 0.645336 test loss: 0.339688
[Epoch 116; Iter     5/  229] train: loss: 0.1376811
[Epoch 116; Iter    35/  229] train: loss: 0.1241938
[Epoch 116; Iter    65/  229] train: loss: 0.1092238
[Epoch 116; Iter    95/  229] train: loss: 0.1583974
[Epoch 116; Iter   125/  229] train: loss: 0.0890216
[Epoch 116; Iter   155/  229] train: loss: 0.1615390
[Epoch 116; Iter   185/  229] train: loss: 0.1017646
[Epoch 116; Iter   215/  229] train: loss: 0.1435822
[Epoch 116] ogbg-moltoxcast: 0.681907 val loss: 0.273214
[Epoch 116] ogbg-moltoxcast: 0.646072 test loss: 0.337981
[Epoch 117; Iter    16/  229] train: loss: 0.1040751
[Epoch 117; Iter    46/  229] train: loss: 0.0885497
[Epoch 117; Iter    76/  229] train: loss: 0.1007928
[Epoch 117; Iter   106/  229] train: loss: 0.1111341
[Epoch 117; Iter   136/  229] train: loss: 0.1515785
[Epoch 117; Iter   166/  229] train: loss: 0.1271232
[Epoch 117; Iter   196/  229] train: loss: 0.1449901
[Epoch 117; Iter   226/  229] train: loss: 0.1281128
[Epoch 117] ogbg-moltoxcast: 0.679709 val loss: 0.271721
[Epoch 117] ogbg-moltoxcast: 0.642895 test loss: 0.339169
[Epoch 118; Iter    27/  229] train: loss: 0.0927224
[Epoch 118; Iter    57/  229] train: loss: 0.1061606
[Epoch 118; Iter    87/  229] train: loss: 0.1299984
[Epoch 118; Iter   117/  229] train: loss: 0.1135403
[Epoch 118; Iter   147/  229] train: loss: 0.1243116
[Epoch 118; Iter   177/  229] train: loss: 0.1401345
[Epoch 118; Iter   207/  229] train: loss: 0.1046793
[Epoch 118] ogbg-moltoxcast: 0.677210 val loss: 0.274153
[Epoch 118] ogbg-moltoxcast: 0.643865 test loss: 0.339127
[Epoch 119; Iter     8/  229] train: loss: 0.1114368
[Epoch 119; Iter    38/  229] train: loss: 0.0917724
[Epoch 119; Iter    68/  229] train: loss: 0.1045437
[Epoch 119; Iter    98/  229] train: loss: 0.1152090
[Epoch 119; Iter   128/  229] train: loss: 0.1242362
[Epoch 119; Iter   158/  229] train: loss: 0.1436417
[Epoch 119; Iter   188/  229] train: loss: 0.1250473
[Epoch 119; Iter   218/  229] train: loss: 0.0736720
[Epoch 119] ogbg-moltoxcast: 0.679298 val loss: 0.273273
[Epoch 119] ogbg-moltoxcast: 0.642888 test loss: 0.339152
[Epoch 120; Iter    19/  229] train: loss: 0.1068746
[Epoch 120; Iter    49/  229] train: loss: 0.1076375
[Epoch 120; Iter    79/  229] train: loss: 0.1120271
[Epoch 120; Iter   109/  229] train: loss: 0.1895944
[Epoch 120; Iter   139/  229] train: loss: 0.1062229
[Epoch 120; Iter   169/  229] train: loss: 0.0966325
[Epoch 120; Iter   199/  229] train: loss: 0.0735734
[Epoch 120; Iter   229/  229] train: loss: 0.1269138
[Epoch 120] ogbg-moltoxcast: 0.678347 val loss: 0.271371
[Epoch 120] ogbg-moltoxcast: 0.643385 test loss: 0.338633
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -2.7057738304138184
std_pred: 2.4366655349731445
mean_targets: nan
std_targets: nan
prcauc: 0.4020098054783008
rocauc: 0.6938697926005558
ogbg-moltoxcast: 0.6938697926005558
OGBNanLabelBCEWithLogitsLoss: 0.2452512907570806
Statistics on  test
mean_pred: -2.4590647220611572
std_pred: 2.3936421871185303
mean_targets: nan
std_targets: nan
prcauc: 0.36826983193419177
rocauc: 0.6622965943820497
ogbg-moltoxcast: 0.6622965943820497
OGBNanLabelBCEWithLogitsLoss: 0.29092896447099487
Statistics on  train
mean_pred: -3.162705898284912
std_pred: 2.402132749557495
mean_targets: nan
std_targets: nan
prcauc: 0.55483341920846
rocauc: 0.8663463147529218
ogbg-moltoxcast: 0.8663463147529218
OGBNanLabelBCEWithLogitsLoss: 0.1459105522351494
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/toxcast/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
