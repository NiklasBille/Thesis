>>> Starting run for dataset: muv
Running RANDOM configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.8/PNA_ogbg-molmuv_3DInfomax_muv_random=0.8_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.8
logdir: runs/split/3DInfomax/muv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 2483] train: loss: 0.6927952
[Epoch 1; Iter    60/ 2483] train: loss: 0.6942682
[Epoch 1; Iter    90/ 2483] train: loss: 0.6935987
[Epoch 1; Iter   120/ 2483] train: loss: 0.6932168
[Epoch 1; Iter   150/ 2483] train: loss: 0.6937937
[Epoch 1; Iter   180/ 2483] train: loss: 0.6919731
[Epoch 1; Iter   210/ 2483] train: loss: 0.6927302
[Epoch 1; Iter   240/ 2483] train: loss: 0.6940901
[Epoch 1; Iter   270/ 2483] train: loss: 0.6907023
[Epoch 1; Iter   300/ 2483] train: loss: 0.6930699
[Epoch 1; Iter   330/ 2483] train: loss: 0.6946780
[Epoch 1; Iter   360/ 2483] train: loss: 0.6927060
[Epoch 1; Iter   390/ 2483] train: loss: 0.6925271
[Epoch 1; Iter   420/ 2483] train: loss: 0.6925539
[Epoch 1; Iter   450/ 2483] train: loss: 0.6909698
[Epoch 1; Iter   480/ 2483] train: loss: 0.6896206
[Epoch 1; Iter   510/ 2483] train: loss: 0.6908869
[Epoch 1; Iter   540/ 2483] train: loss: 0.6903316
[Epoch 1; Iter   570/ 2483] train: loss: 0.6895779
[Epoch 1; Iter   600/ 2483] train: loss: 0.6880761
[Epoch 1; Iter   630/ 2483] train: loss: 0.6865148
[Epoch 1; Iter   660/ 2483] train: loss: 0.6873512
[Epoch 1; Iter   690/ 2483] train: loss: 0.6874701
[Epoch 1; Iter   720/ 2483] train: loss: 0.6836433
[Epoch 1; Iter   750/ 2483] train: loss: 0.6741300
[Epoch 1; Iter   780/ 2483] train: loss: 0.6575361
[Epoch 1; Iter   810/ 2483] train: loss: 0.6245144
[Epoch 1; Iter   840/ 2483] train: loss: 0.6159468
[Epoch 1; Iter   870/ 2483] train: loss: 0.5438724
[Epoch 1; Iter   900/ 2483] train: loss: 0.5218629
[Epoch 1; Iter   930/ 2483] train: loss: 0.4423188
[Epoch 1; Iter   960/ 2483] train: loss: 0.3995984
[Epoch 1; Iter   990/ 2483] train: loss: 0.3143709
[Epoch 1; Iter  1020/ 2483] train: loss: 0.2708548
[Epoch 1; Iter  1050/ 2483] train: loss: 0.2231840
[Epoch 1; Iter  1080/ 2483] train: loss: 0.1655351
[Epoch 1; Iter  1110/ 2483] train: loss: 0.1341840
[Epoch 1; Iter  1140/ 2483] train: loss: 0.1201263
[Epoch 1; Iter  1170/ 2483] train: loss: 0.0795623
[Epoch 1; Iter  1200/ 2483] train: loss: 0.0665955
[Epoch 1; Iter  1230/ 2483] train: loss: 0.0533920
[Epoch 1; Iter  1260/ 2483] train: loss: 0.0451952
[Epoch 1; Iter  1290/ 2483] train: loss: 0.0876785
[Epoch 1; Iter  1320/ 2483] train: loss: 0.0288568
[Epoch 1; Iter  1350/ 2483] train: loss: 0.0257761
[Epoch 1; Iter  1380/ 2483] train: loss: 0.0632296
[Epoch 1; Iter  1410/ 2483] train: loss: 0.0207932
[Epoch 1; Iter  1440/ 2483] train: loss: 0.0192664
[Epoch 1; Iter  1470/ 2483] train: loss: 0.0176568
[Epoch 1; Iter  1500/ 2483] train: loss: 0.0200327
[Epoch 1; Iter  1530/ 2483] train: loss: 0.0163107
[Epoch 1; Iter  1560/ 2483] train: loss: 0.0643800
[Epoch 1; Iter  1590/ 2483] train: loss: 0.0156982
[Epoch 1; Iter  1620/ 2483] train: loss: 0.0137654
[Epoch 1; Iter  1650/ 2483] train: loss: 0.0126943
[Epoch 1; Iter  1680/ 2483] train: loss: 0.0112685
[Epoch 1; Iter  1710/ 2483] train: loss: 0.0118244
[Epoch 1; Iter  1740/ 2483] train: loss: 0.0090349
[Epoch 1; Iter  1770/ 2483] train: loss: 0.0086584
[Epoch 1; Iter  1800/ 2483] train: loss: 0.0092926
[Epoch 1; Iter  1830/ 2483] train: loss: 0.0077835
[Epoch 1; Iter  1860/ 2483] train: loss: 0.0081303
[Epoch 1; Iter  1890/ 2483] train: loss: 0.0076750
[Epoch 1; Iter  1920/ 2483] train: loss: 0.0074003
[Epoch 1; Iter  1950/ 2483] train: loss: 0.0063900
[Epoch 1; Iter  1980/ 2483] train: loss: 0.0729070
[Epoch 1; Iter  2010/ 2483] train: loss: 0.0061913
[Epoch 1; Iter  2040/ 2483] train: loss: 0.0056793
[Epoch 1; Iter  2070/ 2483] train: loss: 0.0052128
[Epoch 1; Iter  2100/ 2483] train: loss: 0.0042566
[Epoch 1; Iter  2130/ 2483] train: loss: 0.0063314
[Epoch 1; Iter  2160/ 2483] train: loss: 0.0049401
[Epoch 1; Iter  2190/ 2483] train: loss: 0.0056783
[Epoch 1; Iter  2220/ 2483] train: loss: 0.0046583
[Epoch 1; Iter  2250/ 2483] train: loss: 0.0045669
[Epoch 1; Iter  2280/ 2483] train: loss: 0.0037335
[Epoch 1; Iter  2310/ 2483] train: loss: 0.0037006
[Epoch 1; Iter  2340/ 2483] train: loss: 0.0035659
[Epoch 1; Iter  2370/ 2483] train: loss: 0.0034109
[Epoch 1; Iter  2400/ 2483] train: loss: 0.0030882
[Epoch 1; Iter  2430/ 2483] train: loss: 0.0032284
[Epoch 1; Iter  2460/ 2483] train: loss: 0.0035312
[Epoch 1] ogbg-molmuv: 0.010755 val loss: 0.012177
[Epoch 1] ogbg-molmuv: 0.013381 test loss: 0.015536
[Epoch 2; Iter     7/ 2483] train: loss: 0.0030352
[Epoch 2; Iter    37/ 2483] train: loss: 0.0032552
[Epoch 2; Iter    67/ 2483] train: loss: 0.0027686
[Epoch 2; Iter    97/ 2483] train: loss: 0.0025523
[Epoch 2; Iter   127/ 2483] train: loss: 0.0026451
[Epoch 2; Iter   157/ 2483] train: loss: 0.0026711
[Epoch 2; Iter   187/ 2483] train: loss: 0.0026596
[Epoch 2; Iter   217/ 2483] train: loss: 0.0022712
[Epoch 2; Iter   247/ 2483] train: loss: 0.0028069
[Epoch 2; Iter   277/ 2483] train: loss: 0.0023208
[Epoch 2; Iter   307/ 2483] train: loss: 0.0530324
[Epoch 2; Iter   337/ 2483] train: loss: 0.0024640
[Epoch 2; Iter   367/ 2483] train: loss: 0.0857008
[Epoch 2; Iter   397/ 2483] train: loss: 0.0695785
[Epoch 2; Iter   427/ 2483] train: loss: 0.0022009
[Epoch 2; Iter   457/ 2483] train: loss: 0.0021153
[Epoch 2; Iter   487/ 2483] train: loss: 0.0023767
[Epoch 2; Iter   517/ 2483] train: loss: 0.0031794
[Epoch 2; Iter   547/ 2483] train: loss: 0.0019669
[Epoch 2; Iter   577/ 2483] train: loss: 0.1551393
[Epoch 2; Iter   607/ 2483] train: loss: 0.0021015
[Epoch 2; Iter   637/ 2483] train: loss: 0.0020743
[Epoch 2; Iter   667/ 2483] train: loss: 0.0020016
[Epoch 2; Iter   697/ 2483] train: loss: 0.0020631
[Epoch 2; Iter   727/ 2483] train: loss: 0.0023152
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.8/PNA_ogbg-molmuv_3DInfomax_muv_random=0.8_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.8
logdir: runs/split/3DInfomax/muv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 2483] train: loss: 0.6909521
[Epoch 1; Iter    60/ 2483] train: loss: 0.6934183
[Epoch 1; Iter    90/ 2483] train: loss: 0.6921731
[Epoch 1; Iter   120/ 2483] train: loss: 0.6914359
[Epoch 1; Iter   150/ 2483] train: loss: 0.6921136
[Epoch 1; Iter   180/ 2483] train: loss: 0.6921365
[Epoch 1; Iter   210/ 2483] train: loss: 0.6922134
[Epoch 1; Iter   240/ 2483] train: loss: 0.6930110
[Epoch 1; Iter   270/ 2483] train: loss: 0.6943095
[Epoch 1; Iter   300/ 2483] train: loss: 0.6919721
[Epoch 1; Iter   330/ 2483] train: loss: 0.6904843
[Epoch 1; Iter   360/ 2483] train: loss: 0.6919934
[Epoch 1; Iter   390/ 2483] train: loss: 0.6917849
[Epoch 1; Iter   420/ 2483] train: loss: 0.6906859
[Epoch 1; Iter   450/ 2483] train: loss: 0.6905156
[Epoch 1; Iter   480/ 2483] train: loss: 0.6914164
[Epoch 1; Iter   510/ 2483] train: loss: 0.6867852
[Epoch 1; Iter   540/ 2483] train: loss: 0.6903757
[Epoch 1; Iter   570/ 2483] train: loss: 0.6896482
[Epoch 1; Iter   600/ 2483] train: loss: 0.6890252
[Epoch 1; Iter   630/ 2483] train: loss: 0.6892346
[Epoch 1; Iter   660/ 2483] train: loss: 0.6877394
[Epoch 1; Iter   690/ 2483] train: loss: 0.6917835
[Epoch 1; Iter   720/ 2483] train: loss: 0.6881205
[Epoch 1; Iter   750/ 2483] train: loss: 0.6752775
[Epoch 1; Iter   780/ 2483] train: loss: 0.6591624
[Epoch 1; Iter   810/ 2483] train: loss: 0.6394892
[Epoch 1; Iter   840/ 2483] train: loss: 0.5791906
[Epoch 1; Iter   870/ 2483] train: loss: 0.5669254
[Epoch 1; Iter   900/ 2483] train: loss: 0.4714313
[Epoch 1; Iter   930/ 2483] train: loss: 0.4320368
[Epoch 1; Iter   960/ 2483] train: loss: 0.3606071
[Epoch 1; Iter   990/ 2483] train: loss: 0.3437192
[Epoch 1; Iter  1020/ 2483] train: loss: 0.2690700
[Epoch 1; Iter  1050/ 2483] train: loss: 0.2418905
[Epoch 1; Iter  1080/ 2483] train: loss: 0.1626807
[Epoch 1; Iter  1110/ 2483] train: loss: 0.1413591
[Epoch 1; Iter  1140/ 2483] train: loss: 0.0998664
[Epoch 1; Iter  1170/ 2483] train: loss: 0.1030719
[Epoch 1; Iter  1200/ 2483] train: loss: 0.0647940
[Epoch 1; Iter  1230/ 2483] train: loss: 0.0489923
[Epoch 1; Iter  1260/ 2483] train: loss: 0.0389783
[Epoch 1; Iter  1290/ 2483] train: loss: 0.0361390
[Epoch 1; Iter  1320/ 2483] train: loss: 0.0276897
[Epoch 1; Iter  1350/ 2483] train: loss: 0.0244050
[Epoch 1; Iter  1380/ 2483] train: loss: 0.0220884
[Epoch 1; Iter  1410/ 2483] train: loss: 0.0191239
[Epoch 1; Iter  1440/ 2483] train: loss: 0.0202696
[Epoch 1; Iter  1470/ 2483] train: loss: 0.0221763
[Epoch 1; Iter  1500/ 2483] train: loss: 0.0168067
[Epoch 1; Iter  1530/ 2483] train: loss: 0.0201628
[Epoch 1; Iter  1560/ 2483] train: loss: 0.0180470
[Epoch 1; Iter  1590/ 2483] train: loss: 0.0203508
[Epoch 1; Iter  1620/ 2483] train: loss: 0.0170229
[Epoch 1; Iter  1650/ 2483] train: loss: 0.0157355
[Epoch 1; Iter  1680/ 2483] train: loss: 0.0113539
[Epoch 1; Iter  1710/ 2483] train: loss: 0.0106326
[Epoch 1; Iter  1740/ 2483] train: loss: 0.0092936
[Epoch 1; Iter  1770/ 2483] train: loss: 0.0092258
[Epoch 1; Iter  1800/ 2483] train: loss: 0.0100672
[Epoch 1; Iter  1830/ 2483] train: loss: 0.0084110
[Epoch 1; Iter  1860/ 2483] train: loss: 0.0078825
[Epoch 1; Iter  1890/ 2483] train: loss: 0.0066839
[Epoch 1; Iter  1920/ 2483] train: loss: 0.0058724
[Epoch 1; Iter  1950/ 2483] train: loss: 0.0060321
[Epoch 1; Iter  1980/ 2483] train: loss: 0.0062070
[Epoch 1; Iter  2010/ 2483] train: loss: 0.0051136
[Epoch 1; Iter  2040/ 2483] train: loss: 0.0045143
[Epoch 1; Iter  2070/ 2483] train: loss: 0.0047856
[Epoch 1; Iter  2100/ 2483] train: loss: 0.0575921
[Epoch 1; Iter  2130/ 2483] train: loss: 0.0046151
[Epoch 1; Iter  2160/ 2483] train: loss: 0.0046504
[Epoch 1; Iter  2190/ 2483] train: loss: 0.0036389
[Epoch 1; Iter  2220/ 2483] train: loss: 0.0040634
[Epoch 1; Iter  2250/ 2483] train: loss: 0.0045694
[Epoch 1; Iter  2280/ 2483] train: loss: 0.0038038
[Epoch 1; Iter  2310/ 2483] train: loss: 0.0035379
[Epoch 1; Iter  2340/ 2483] train: loss: 0.0562101
[Epoch 1; Iter  2370/ 2483] train: loss: 0.0049698
[Epoch 1; Iter  2400/ 2483] train: loss: 0.0029380
[Epoch 1; Iter  2430/ 2483] train: loss: 0.0030135
[Epoch 1; Iter  2460/ 2483] train: loss: 0.0032377
[Epoch 1] ogbg-molmuv: 0.035827 val loss: 0.011240
[Epoch 1] ogbg-molmuv: 0.008259 test loss: 0.015711
[Epoch 2; Iter     7/ 2483] train: loss: 0.0030888
[Epoch 2; Iter    37/ 2483] train: loss: 0.0027787
[Epoch 2; Iter    67/ 2483] train: loss: 0.0029940
[Epoch 2; Iter    97/ 2483] train: loss: 0.0026047
[Epoch 2; Iter   127/ 2483] train: loss: 0.0026678
[Epoch 2; Iter   157/ 2483] train: loss: 0.0033984
[Epoch 2; Iter   187/ 2483] train: loss: 0.0041902
[Epoch 2; Iter   217/ 2483] train: loss: 0.0025330
[Epoch 2; Iter   247/ 2483] train: loss: 0.0024554
[Epoch 2; Iter   277/ 2483] train: loss: 0.0026366
[Epoch 2; Iter   307/ 2483] train: loss: 0.0029823
[Epoch 2; Iter   337/ 2483] train: loss: 0.0029494
[Epoch 2; Iter   367/ 2483] train: loss: 0.0025310
[Epoch 2; Iter   397/ 2483] train: loss: 0.0030879
[Epoch 2; Iter   427/ 2483] train: loss: 0.0031695
[Epoch 2; Iter   457/ 2483] train: loss: 0.0038922
[Epoch 2; Iter   487/ 2483] train: loss: 0.0869788
[Epoch 2; Iter   517/ 2483] train: loss: 0.0022374
[Epoch 2; Iter   547/ 2483] train: loss: 0.0023104
[Epoch 2; Iter   577/ 2483] train: loss: 0.0026741
[Epoch 2; Iter   607/ 2483] train: loss: 0.0750400
[Epoch 2; Iter   637/ 2483] train: loss: 0.0023122
[Epoch 2; Iter   667/ 2483] train: loss: 0.0019734
[Epoch 2; Iter   697/ 2483] train: loss: 0.0018692
[Epoch 2; Iter   727/ 2483] train: loss: 0.0019782
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.8/PNA_ogbg-molmuv_3DInfomax_muv_random=0.8_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.8
logdir: runs/split/3DInfomax/muv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 2483] train: loss: 0.6920162
[Epoch 1; Iter    60/ 2483] train: loss: 0.6924832
[Epoch 1; Iter    90/ 2483] train: loss: 0.6936458
[Epoch 1; Iter   120/ 2483] train: loss: 0.6934032
[Epoch 1; Iter   150/ 2483] train: loss: 0.6934767
[Epoch 1; Iter   180/ 2483] train: loss: 0.6937813
[Epoch 1; Iter   210/ 2483] train: loss: 0.6939313
[Epoch 1; Iter   240/ 2483] train: loss: 0.6916652
[Epoch 1; Iter   270/ 2483] train: loss: 0.6926835
[Epoch 1; Iter   300/ 2483] train: loss: 0.6938495
[Epoch 1; Iter   330/ 2483] train: loss: 0.6924487
[Epoch 1; Iter   360/ 2483] train: loss: 0.6913469
[Epoch 1; Iter   390/ 2483] train: loss: 0.6925780
[Epoch 1; Iter   420/ 2483] train: loss: 0.6927487
[Epoch 1; Iter   450/ 2483] train: loss: 0.6895649
[Epoch 1; Iter   480/ 2483] train: loss: 0.6919653
[Epoch 1; Iter   510/ 2483] train: loss: 0.6920526
[Epoch 1; Iter   540/ 2483] train: loss: 0.6917306
[Epoch 1; Iter   570/ 2483] train: loss: 0.6908477
[Epoch 1; Iter   600/ 2483] train: loss: 0.6896731
[Epoch 1; Iter   630/ 2483] train: loss: 0.6895583
[Epoch 1; Iter   660/ 2483] train: loss: 0.6919897
[Epoch 1; Iter   690/ 2483] train: loss: 0.6882646
[Epoch 1; Iter   720/ 2483] train: loss: 0.6857616
[Epoch 1; Iter   750/ 2483] train: loss: 0.6733308
[Epoch 1; Iter   780/ 2483] train: loss: 0.6622662
[Epoch 1; Iter   810/ 2483] train: loss: 0.6326491
[Epoch 1; Iter   840/ 2483] train: loss: 0.5922316
[Epoch 1; Iter   870/ 2483] train: loss: 0.5897564
[Epoch 1; Iter   900/ 2483] train: loss: 0.4947275
[Epoch 1; Iter   930/ 2483] train: loss: 0.4429311
[Epoch 1; Iter   960/ 2483] train: loss: 0.4371158
[Epoch 1; Iter   990/ 2483] train: loss: 0.3329613
[Epoch 1; Iter  1020/ 2483] train: loss: 0.2458940
[Epoch 1; Iter  1050/ 2483] train: loss: 0.2242080
[Epoch 1; Iter  1080/ 2483] train: loss: 0.2207135
[Epoch 1; Iter  1110/ 2483] train: loss: 0.1374664
[Epoch 1; Iter  1140/ 2483] train: loss: 0.1057990
[Epoch 1; Iter  1170/ 2483] train: loss: 0.0880865
[Epoch 1; Iter  1200/ 2483] train: loss: 0.0666323
[Epoch 1; Iter  1230/ 2483] train: loss: 0.0556318
[Epoch 1; Iter  1260/ 2483] train: loss: 0.0434707
[Epoch 1; Iter  1290/ 2483] train: loss: 0.0403163
[Epoch 1; Iter  1320/ 2483] train: loss: 0.0306496
[Epoch 1; Iter  1350/ 2483] train: loss: 0.0259745
[Epoch 1; Iter  1380/ 2483] train: loss: 0.0225379
[Epoch 1; Iter  1410/ 2483] train: loss: 0.0642637
[Epoch 1; Iter  1440/ 2483] train: loss: 0.0197596
[Epoch 1; Iter  1470/ 2483] train: loss: 0.0632194
[Epoch 1; Iter  1500/ 2483] train: loss: 0.0188078
[Epoch 1; Iter  1530/ 2483] train: loss: 0.0176540
[Epoch 1; Iter  1560/ 2483] train: loss: 0.0154768
[Epoch 1; Iter  1590/ 2483] train: loss: 0.0159882
[Epoch 1; Iter  1620/ 2483] train: loss: 0.0138986
[Epoch 1; Iter  1650/ 2483] train: loss: 0.0161902
[Epoch 1; Iter  1680/ 2483] train: loss: 0.0121079
[Epoch 1; Iter  1710/ 2483] train: loss: 0.0116255
[Epoch 1; Iter  1740/ 2483] train: loss: 0.0103332
[Epoch 1; Iter  1770/ 2483] train: loss: 0.0131015
[Epoch 1; Iter  1800/ 2483] train: loss: 0.0092774
[Epoch 1; Iter  1830/ 2483] train: loss: 0.0068310
[Epoch 1; Iter  1860/ 2483] train: loss: 0.1231115
[Epoch 1; Iter  1890/ 2483] train: loss: 0.0069288
[Epoch 1; Iter  1920/ 2483] train: loss: 0.0067546
[Epoch 1; Iter  1950/ 2483] train: loss: 0.0058250
[Epoch 1; Iter  1980/ 2483] train: loss: 0.0055316
[Epoch 1; Iter  2010/ 2483] train: loss: 0.0055408
[Epoch 1; Iter  2040/ 2483] train: loss: 0.0680820
[Epoch 1; Iter  2070/ 2483] train: loss: 0.0051776
[Epoch 1; Iter  2100/ 2483] train: loss: 0.0672891
[Epoch 1; Iter  2130/ 2483] train: loss: 0.0046620
[Epoch 1; Iter  2160/ 2483] train: loss: 0.0048872
[Epoch 1; Iter  2190/ 2483] train: loss: 0.0048066
[Epoch 1; Iter  2220/ 2483] train: loss: 0.0039165
[Epoch 1; Iter  2250/ 2483] train: loss: 0.0036887
[Epoch 1; Iter  2280/ 2483] train: loss: 0.0037787
[Epoch 1; Iter  2310/ 2483] train: loss: 0.0037787
[Epoch 1; Iter  2340/ 2483] train: loss: 0.0761670
[Epoch 1; Iter  2370/ 2483] train: loss: 0.0629435
[Epoch 1; Iter  2400/ 2483] train: loss: 0.0037351
[Epoch 1; Iter  2430/ 2483] train: loss: 0.0038488
[Epoch 1; Iter  2460/ 2483] train: loss: 0.0029818
[Epoch 1] ogbg-molmuv: 0.013533 val loss: 0.025984
[Epoch 1] ogbg-molmuv: 0.009015 test loss: 0.027755
[Epoch 2; Iter     7/ 2483] train: loss: 0.0626486
[Epoch 2; Iter    37/ 2483] train: loss: 0.0037157
[Epoch 2; Iter    67/ 2483] train: loss: 0.0033258
[Epoch 2; Iter    97/ 2483] train: loss: 0.0027614
[Epoch 2; Iter   127/ 2483] train: loss: 0.0029590
[Epoch 2; Iter   157/ 2483] train: loss: 0.0036469
[Epoch 2; Iter   187/ 2483] train: loss: 0.0027499
[Epoch 2; Iter   217/ 2483] train: loss: 0.0029106
[Epoch 2; Iter   247/ 2483] train: loss: 0.0026089
[Epoch 2; Iter   277/ 2483] train: loss: 0.0028354
[Epoch 2; Iter   307/ 2483] train: loss: 0.0033752
[Epoch 2; Iter   337/ 2483] train: loss: 0.0025093
[Epoch 2; Iter   367/ 2483] train: loss: 0.0030483
[Epoch 2; Iter   397/ 2483] train: loss: 0.0026806
[Epoch 2; Iter   427/ 2483] train: loss: 0.0029675
[Epoch 2; Iter   457/ 2483] train: loss: 0.0029776
[Epoch 2; Iter   487/ 2483] train: loss: 0.0680469
[Epoch 2; Iter   517/ 2483] train: loss: 0.0024597
[Epoch 2; Iter   547/ 2483] train: loss: 0.0032979
[Epoch 2; Iter   577/ 2483] train: loss: 0.0748122
[Epoch 2; Iter   607/ 2483] train: loss: 0.0026269
[Epoch 2; Iter   637/ 2483] train: loss: 0.0027214
[Epoch 2; Iter   667/ 2483] train: loss: 0.0789414
[Epoch 2; Iter   697/ 2483] train: loss: 0.0022475
[Epoch 2; Iter   727/ 2483] train: loss: 0.0022596
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.7/PNA_ogbg-molmuv_3DInfomax_muv_random=0.7_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.7
logdir: runs/split/3DInfomax/muv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/ 2172] train: loss: 0.6934746
[Epoch 1; Iter    60/ 2172] train: loss: 0.6922320
[Epoch 1; Iter    90/ 2172] train: loss: 0.6940632
[Epoch 1; Iter   120/ 2172] train: loss: 0.6949942
[Epoch 1; Iter   150/ 2172] train: loss: 0.6947349
[Epoch 1; Iter   180/ 2172] train: loss: 0.6933458
[Epoch 1; Iter   210/ 2172] train: loss: 0.6914919
[Epoch 1; Iter   240/ 2172] train: loss: 0.6919485
[Epoch 1; Iter   270/ 2172] train: loss: 0.6928545
[Epoch 1; Iter   300/ 2172] train: loss: 0.6940094
[Epoch 1; Iter   330/ 2172] train: loss: 0.6909515
[Epoch 1; Iter   360/ 2172] train: loss: 0.6922727
[Epoch 1; Iter   390/ 2172] train: loss: 0.6910098
[Epoch 1; Iter   420/ 2172] train: loss: 0.6912717
[Epoch 1; Iter   450/ 2172] train: loss: 0.6923180
[Epoch 1; Iter   480/ 2172] train: loss: 0.6913557
[Epoch 1; Iter   510/ 2172] train: loss: 0.6908841
[Epoch 1; Iter   540/ 2172] train: loss: 0.6884385
[Epoch 1; Iter   570/ 2172] train: loss: 0.6885573
[Epoch 1; Iter   600/ 2172] train: loss: 0.6863714
[Epoch 1; Iter   630/ 2172] train: loss: 0.6898010
[Epoch 1; Iter   660/ 2172] train: loss: 0.6864883
[Epoch 1; Iter   690/ 2172] train: loss: 0.6877103
[Epoch 1; Iter   720/ 2172] train: loss: 0.6852733
[Epoch 1; Iter   750/ 2172] train: loss: 0.6768967
[Epoch 1; Iter   780/ 2172] train: loss: 0.6573138
[Epoch 1; Iter   810/ 2172] train: loss: 0.6226315
[Epoch 1; Iter   840/ 2172] train: loss: 0.5977885
[Epoch 1; Iter   870/ 2172] train: loss: 0.5618506
[Epoch 1; Iter   900/ 2172] train: loss: 0.4872474
[Epoch 1; Iter   930/ 2172] train: loss: 0.4283425
[Epoch 1; Iter   960/ 2172] train: loss: 0.3675654
[Epoch 1; Iter   990/ 2172] train: loss: 0.2992502
[Epoch 1; Iter  1020/ 2172] train: loss: 0.2839976
[Epoch 1; Iter  1050/ 2172] train: loss: 0.1933701
[Epoch 1; Iter  1080/ 2172] train: loss: 0.1508818
[Epoch 1; Iter  1110/ 2172] train: loss: 0.1251593
[Epoch 1; Iter  1140/ 2172] train: loss: 0.0949050
[Epoch 1; Iter  1170/ 2172] train: loss: 0.0791568
[Epoch 1; Iter  1200/ 2172] train: loss: 0.0680665
[Epoch 1; Iter  1230/ 2172] train: loss: 0.0826737
[Epoch 1; Iter  1260/ 2172] train: loss: 0.0421785
[Epoch 1; Iter  1290/ 2172] train: loss: 0.0325486
[Epoch 1; Iter  1320/ 2172] train: loss: 0.0273703
[Epoch 1; Iter  1350/ 2172] train: loss: 0.0245935
[Epoch 1; Iter  1380/ 2172] train: loss: 0.0221684
[Epoch 1; Iter  1410/ 2172] train: loss: 0.0213943
[Epoch 1; Iter  1440/ 2172] train: loss: 0.0215499
[Epoch 1; Iter  1470/ 2172] train: loss: 0.0197937
[Epoch 1; Iter  1500/ 2172] train: loss: 0.0191507
[Epoch 1; Iter  1530/ 2172] train: loss: 0.0186268
[Epoch 1; Iter  1560/ 2172] train: loss: 0.0162859
[Epoch 1; Iter  1590/ 2172] train: loss: 0.0172691
[Epoch 1; Iter  1620/ 2172] train: loss: 0.0145207
[Epoch 1; Iter  1650/ 2172] train: loss: 0.0117721
[Epoch 1; Iter  1680/ 2172] train: loss: 0.0111032
[Epoch 1; Iter  1710/ 2172] train: loss: 0.0108393
[Epoch 1; Iter  1740/ 2172] train: loss: 0.0963937
[Epoch 1; Iter  1770/ 2172] train: loss: 0.0091983
[Epoch 1; Iter  1800/ 2172] train: loss: 0.0095450
[Epoch 1; Iter  1830/ 2172] train: loss: 0.0709015
[Epoch 1; Iter  1860/ 2172] train: loss: 0.0074188
[Epoch 1; Iter  1890/ 2172] train: loss: 0.0066054
[Epoch 1; Iter  1920/ 2172] train: loss: 0.0095795
[Epoch 1; Iter  1950/ 2172] train: loss: 0.0063175
[Epoch 1; Iter  1980/ 2172] train: loss: 0.0059016
[Epoch 1; Iter  2010/ 2172] train: loss: 0.0053465
[Epoch 1; Iter  2040/ 2172] train: loss: 0.0819727
[Epoch 1; Iter  2070/ 2172] train: loss: 0.0044018
[Epoch 1; Iter  2100/ 2172] train: loss: 0.0054465
[Epoch 1; Iter  2130/ 2172] train: loss: 0.0046552
[Epoch 1; Iter  2160/ 2172] train: loss: 0.0045245
[Epoch 1] ogbg-molmuv: 0.006921 val loss: 0.013616
[Epoch 1] ogbg-molmuv: 0.006752 test loss: 0.016102
[Epoch 2; Iter    18/ 2172] train: loss: 0.0773889
[Epoch 2; Iter    48/ 2172] train: loss: 0.0045689
[Epoch 2; Iter    78/ 2172] train: loss: 0.0037384
[Epoch 2; Iter   108/ 2172] train: loss: 0.0036675
[Epoch 2; Iter   138/ 2172] train: loss: 0.0039954
[Epoch 2; Iter   168/ 2172] train: loss: 0.0040969
[Epoch 2; Iter   198/ 2172] train: loss: 0.0038161
[Epoch 2; Iter   228/ 2172] train: loss: 0.0904217
[Epoch 2; Iter   258/ 2172] train: loss: 0.0031928
[Epoch 2; Iter   288/ 2172] train: loss: 0.0029735
[Epoch 2; Iter   318/ 2172] train: loss: 0.0027568
[Epoch 2; Iter   348/ 2172] train: loss: 0.0029129
[Epoch 2; Iter   378/ 2172] train: loss: 0.0026889
[Epoch 2; Iter   408/ 2172] train: loss: 0.0656701
[Epoch 2; Iter   438/ 2172] train: loss: 0.0023514
[Epoch 2; Iter   468/ 2172] train: loss: 0.0024497
[Epoch 2; Iter   498/ 2172] train: loss: 0.0028904
[Epoch 2; Iter   528/ 2172] train: loss: 0.0033900
[Epoch 2; Iter   558/ 2172] train: loss: 0.0025717
[Epoch 2; Iter   588/ 2172] train: loss: 0.0035884
[Epoch 2; Iter   618/ 2172] train: loss: 0.0023501
[Epoch 2; Iter   648/ 2172] train: loss: 0.0026173
[Epoch 2; Iter   678/ 2172] train: loss: 0.1359309
[Epoch 2; Iter   708/ 2172] train: loss: 0.0032943
[Epoch 2; Iter   738/ 2172] train: loss: 0.0852974
[Epoch 2; Iter   768/ 2172] train: loss: 0.0028352
[Epoch 2; Iter   798/ 2172] train: loss: 0.0031451
[Epoch 2; Iter   828/ 2172] train: loss: 0.0024584
[Epoch 2; Iter   858/ 2172] train: loss: 0.0030550
[Epoch 2; Iter   888/ 2172] train: loss: 0.0032610
[Epoch 2; Iter   918/ 2172] train: loss: 0.0031662
[Epoch 2; Iter   948/ 2172] train: loss: 0.0795293
[Epoch 2; Iter   978/ 2172] train: loss: 0.0025004
[Epoch 2; Iter  1008/ 2172] train: loss: 0.0027340
[Epoch 2; Iter  1038/ 2172] train: loss: 0.0028597
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.7/PNA_ogbg-molmuv_3DInfomax_muv_random=0.7_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.7
logdir: runs/split/3DInfomax/muv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/ 2172] train: loss: 0.6933306
[Epoch 1; Iter    60/ 2172] train: loss: 0.6932153
[Epoch 1; Iter    90/ 2172] train: loss: 0.6929044
[Epoch 1; Iter   120/ 2172] train: loss: 0.6948398
[Epoch 1; Iter   150/ 2172] train: loss: 0.6967062
[Epoch 1; Iter   180/ 2172] train: loss: 0.6946685
[Epoch 1; Iter   210/ 2172] train: loss: 0.6916872
[Epoch 1; Iter   240/ 2172] train: loss: 0.6943499
[Epoch 1; Iter   270/ 2172] train: loss: 0.6927380
[Epoch 1; Iter   300/ 2172] train: loss: 0.6919509
[Epoch 1; Iter   330/ 2172] train: loss: 0.6941605
[Epoch 1; Iter   360/ 2172] train: loss: 0.6926073
[Epoch 1; Iter   390/ 2172] train: loss: 0.6925662
[Epoch 1; Iter   420/ 2172] train: loss: 0.6916288
[Epoch 1; Iter   450/ 2172] train: loss: 0.6924484
[Epoch 1; Iter   480/ 2172] train: loss: 0.6922321
[Epoch 1; Iter   510/ 2172] train: loss: 0.6928804
[Epoch 1; Iter   540/ 2172] train: loss: 0.6905446
[Epoch 1; Iter   570/ 2172] train: loss: 0.6899158
[Epoch 1; Iter   600/ 2172] train: loss: 0.6880315
[Epoch 1; Iter   630/ 2172] train: loss: 0.6898850
[Epoch 1; Iter   660/ 2172] train: loss: 0.6908811
[Epoch 1; Iter   690/ 2172] train: loss: 0.6893364
[Epoch 1; Iter   720/ 2172] train: loss: 0.6861687
[Epoch 1; Iter   750/ 2172] train: loss: 0.6762838
[Epoch 1; Iter   780/ 2172] train: loss: 0.6614779
[Epoch 1; Iter   810/ 2172] train: loss: 0.6369512
[Epoch 1; Iter   840/ 2172] train: loss: 0.5890025
[Epoch 1; Iter   870/ 2172] train: loss: 0.5513397
[Epoch 1; Iter   900/ 2172] train: loss: 0.5482455
[Epoch 1; Iter   930/ 2172] train: loss: 0.4549711
[Epoch 1; Iter   960/ 2172] train: loss: 0.4105044
[Epoch 1; Iter   990/ 2172] train: loss: 0.3267026
[Epoch 1; Iter  1020/ 2172] train: loss: 0.2716872
[Epoch 1; Iter  1050/ 2172] train: loss: 0.2110485
[Epoch 1; Iter  1080/ 2172] train: loss: 0.1936194
[Epoch 1; Iter  1110/ 2172] train: loss: 0.1403822
[Epoch 1; Iter  1140/ 2172] train: loss: 0.1045223
[Epoch 1; Iter  1170/ 2172] train: loss: 0.0825689
[Epoch 1; Iter  1200/ 2172] train: loss: 0.0617309
[Epoch 1; Iter  1230/ 2172] train: loss: 0.0537903
[Epoch 1; Iter  1260/ 2172] train: loss: 0.0427574
[Epoch 1; Iter  1290/ 2172] train: loss: 0.0391693
[Epoch 1; Iter  1320/ 2172] train: loss: 0.0312371
[Epoch 1; Iter  1350/ 2172] train: loss: 0.0237575
[Epoch 1; Iter  1380/ 2172] train: loss: 0.0227120
[Epoch 1; Iter  1410/ 2172] train: loss: 0.0193954
[Epoch 1; Iter  1440/ 2172] train: loss: 0.0187299
[Epoch 1; Iter  1470/ 2172] train: loss: 0.0210663
[Epoch 1; Iter  1500/ 2172] train: loss: 0.0174177
[Epoch 1; Iter  1530/ 2172] train: loss: 0.0194015
[Epoch 1; Iter  1560/ 2172] train: loss: 0.0933608
[Epoch 1; Iter  1590/ 2172] train: loss: 0.0147657
[Epoch 1; Iter  1620/ 2172] train: loss: 0.0759617
[Epoch 1; Iter  1650/ 2172] train: loss: 0.0145064
[Epoch 1; Iter  1680/ 2172] train: loss: 0.0122864
[Epoch 1; Iter  1710/ 2172] train: loss: 0.0117985
[Epoch 1; Iter  1740/ 2172] train: loss: 0.0622737
[Epoch 1; Iter  1770/ 2172] train: loss: 0.0106417
[Epoch 1; Iter  1800/ 2172] train: loss: 0.0088057
[Epoch 1; Iter  1830/ 2172] train: loss: 0.0077596
[Epoch 1; Iter  1860/ 2172] train: loss: 0.0075872
[Epoch 1; Iter  1890/ 2172] train: loss: 0.0592290
[Epoch 1; Iter  1920/ 2172] train: loss: 0.0069777
[Epoch 1; Iter  1950/ 2172] train: loss: 0.0065507
[Epoch 1; Iter  1980/ 2172] train: loss: 0.0055640
[Epoch 1; Iter  2010/ 2172] train: loss: 0.0061237
[Epoch 1; Iter  2040/ 2172] train: loss: 0.0054481
[Epoch 1; Iter  2070/ 2172] train: loss: 0.0055379
[Epoch 1; Iter  2100/ 2172] train: loss: 0.0054619
[Epoch 1; Iter  2130/ 2172] train: loss: 0.0708475
[Epoch 1; Iter  2160/ 2172] train: loss: 0.0042741
[Epoch 1] ogbg-molmuv: 0.011909 val loss: 0.014058
[Epoch 1] ogbg-molmuv: 0.005263 test loss: 0.017390
[Epoch 2; Iter    18/ 2172] train: loss: 0.0039900
[Epoch 2; Iter    48/ 2172] train: loss: 0.0041090
[Epoch 2; Iter    78/ 2172] train: loss: 0.0045764
[Epoch 2; Iter   108/ 2172] train: loss: 0.0033139
[Epoch 2; Iter   138/ 2172] train: loss: 0.0752245
[Epoch 2; Iter   168/ 2172] train: loss: 0.0039417
[Epoch 2; Iter   198/ 2172] train: loss: 0.0039166
[Epoch 2; Iter   228/ 2172] train: loss: 0.0032651
[Epoch 2; Iter   258/ 2172] train: loss: 0.0031511
[Epoch 2; Iter   288/ 2172] train: loss: 0.0035133
[Epoch 2; Iter   318/ 2172] train: loss: 0.0887859
[Epoch 2; Iter   348/ 2172] train: loss: 0.0675288
[Epoch 2; Iter   378/ 2172] train: loss: 0.0032913
[Epoch 2; Iter   408/ 2172] train: loss: 0.0511873
[Epoch 2; Iter   438/ 2172] train: loss: 0.0026608
[Epoch 2; Iter   468/ 2172] train: loss: 0.0028502
[Epoch 2; Iter   498/ 2172] train: loss: 0.0025270
[Epoch 2; Iter   528/ 2172] train: loss: 0.0028791
[Epoch 2; Iter   558/ 2172] train: loss: 0.0027232
[Epoch 2; Iter   588/ 2172] train: loss: 0.0030105
[Epoch 2; Iter   618/ 2172] train: loss: 0.0705751
[Epoch 2; Iter   648/ 2172] train: loss: 0.0031252
[Epoch 2; Iter   678/ 2172] train: loss: 0.0035645
[Epoch 2; Iter   708/ 2172] train: loss: 0.0066491
[Epoch 2; Iter   738/ 2172] train: loss: 0.0946485
[Epoch 2; Iter   768/ 2172] train: loss: 0.0795362
[Epoch 2; Iter   798/ 2172] train: loss: 0.2507302
[Epoch 2; Iter   828/ 2172] train: loss: 0.0031491
[Epoch 2; Iter   858/ 2172] train: loss: 0.0027153
[Epoch 2; Iter   888/ 2172] train: loss: 0.0023965
[Epoch 2; Iter   918/ 2172] train: loss: 0.0028034
[Epoch 2; Iter   948/ 2172] train: loss: 0.0021876
[Epoch 2; Iter   978/ 2172] train: loss: 0.0023999
[Epoch 2; Iter  1008/ 2172] train: loss: 0.0023549
[Epoch 2; Iter  1038/ 2172] train: loss: 0.0020919
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.7/PNA_ogbg-molmuv_3DInfomax_muv_random=0.7_4_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.7
logdir: runs/split/3DInfomax/muv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/ 2172] train: loss: 0.6931881
[Epoch 1; Iter    60/ 2172] train: loss: 0.6936628
[Epoch 1; Iter    90/ 2172] train: loss: 0.6924434
[Epoch 1; Iter   120/ 2172] train: loss: 0.6919682
[Epoch 1; Iter   150/ 2172] train: loss: 0.6933935
[Epoch 1; Iter   180/ 2172] train: loss: 0.6924950
[Epoch 1; Iter   210/ 2172] train: loss: 0.6923230
[Epoch 1; Iter   240/ 2172] train: loss: 0.6919881
[Epoch 1; Iter   270/ 2172] train: loss: 0.6899049
[Epoch 1; Iter   300/ 2172] train: loss: 0.6924519
[Epoch 1; Iter   330/ 2172] train: loss: 0.6918112
[Epoch 1; Iter   360/ 2172] train: loss: 0.6888637
[Epoch 1; Iter   390/ 2172] train: loss: 0.6904640
[Epoch 1; Iter   420/ 2172] train: loss: 0.6930264
[Epoch 1; Iter   450/ 2172] train: loss: 0.6917154
[Epoch 1; Iter   480/ 2172] train: loss: 0.6917125
[Epoch 1; Iter   510/ 2172] train: loss: 0.6888679
[Epoch 1; Iter   540/ 2172] train: loss: 0.6886505
[Epoch 1; Iter   570/ 2172] train: loss: 0.6911490
[Epoch 1; Iter   600/ 2172] train: loss: 0.6882737
[Epoch 1; Iter   630/ 2172] train: loss: 0.6890730
[Epoch 1; Iter   660/ 2172] train: loss: 0.6852872
[Epoch 1; Iter   690/ 2172] train: loss: 0.6888711
[Epoch 1; Iter   720/ 2172] train: loss: 0.6851953
[Epoch 1; Iter   750/ 2172] train: loss: 0.6809443
[Epoch 1; Iter   780/ 2172] train: loss: 0.6551188
[Epoch 1; Iter   810/ 2172] train: loss: 0.6222707
[Epoch 1; Iter   840/ 2172] train: loss: 0.5737845
[Epoch 1; Iter   870/ 2172] train: loss: 0.5594677
[Epoch 1; Iter   900/ 2172] train: loss: 0.4680862
[Epoch 1; Iter   930/ 2172] train: loss: 0.4852373
[Epoch 1; Iter   960/ 2172] train: loss: 0.4211439
[Epoch 1; Iter   990/ 2172] train: loss: 0.3482457
[Epoch 1; Iter  1020/ 2172] train: loss: 0.2656717
[Epoch 1; Iter  1050/ 2172] train: loss: 0.1963316
[Epoch 1; Iter  1080/ 2172] train: loss: 0.1717563
[Epoch 1; Iter  1110/ 2172] train: loss: 0.1274276
[Epoch 1; Iter  1140/ 2172] train: loss: 0.2053746
[Epoch 1; Iter  1170/ 2172] train: loss: 0.0868350
[Epoch 1; Iter  1200/ 2172] train: loss: 0.0683229
[Epoch 1; Iter  1230/ 2172] train: loss: 0.0518640
[Epoch 1; Iter  1260/ 2172] train: loss: 0.0432071
[Epoch 1; Iter  1290/ 2172] train: loss: 0.0338074
[Epoch 1; Iter  1320/ 2172] train: loss: 0.0292181
[Epoch 1; Iter  1350/ 2172] train: loss: 0.0271185
[Epoch 1; Iter  1380/ 2172] train: loss: 0.0225553
[Epoch 1; Iter  1410/ 2172] train: loss: 0.0205861
[Epoch 1; Iter  1440/ 2172] train: loss: 0.0184060
[Epoch 1; Iter  1470/ 2172] train: loss: 0.0180586
[Epoch 1; Iter  1500/ 2172] train: loss: 0.0183964
[Epoch 1; Iter  1530/ 2172] train: loss: 0.0174338
[Epoch 1; Iter  1560/ 2172] train: loss: 0.0171523
[Epoch 1; Iter  1590/ 2172] train: loss: 0.0160681
[Epoch 1; Iter  1620/ 2172] train: loss: 0.0162609
[Epoch 1; Iter  1650/ 2172] train: loss: 0.0140750
[Epoch 1; Iter  1680/ 2172] train: loss: 0.0117065
[Epoch 1; Iter  1710/ 2172] train: loss: 0.0124487
[Epoch 1; Iter  1740/ 2172] train: loss: 0.0125920
[Epoch 1; Iter  1770/ 2172] train: loss: 0.0113280
[Epoch 1; Iter  1800/ 2172] train: loss: 0.0102365
[Epoch 1; Iter  1830/ 2172] train: loss: 0.0083510
[Epoch 1; Iter  1860/ 2172] train: loss: 0.0070130
[Epoch 1; Iter  1890/ 2172] train: loss: 0.0069627
[Epoch 1; Iter  1920/ 2172] train: loss: 0.0065306
[Epoch 1; Iter  1950/ 2172] train: loss: 0.0062885
[Epoch 1; Iter  1980/ 2172] train: loss: 0.0053057
[Epoch 1; Iter  2010/ 2172] train: loss: 0.0054477
[Epoch 1; Iter  2040/ 2172] train: loss: 0.0052442
[Epoch 1; Iter  2070/ 2172] train: loss: 0.0039872
[Epoch 1; Iter  2100/ 2172] train: loss: 0.0040660
[Epoch 1; Iter  2130/ 2172] train: loss: 0.0042848
[Epoch 1; Iter  2160/ 2172] train: loss: 0.0039922
[Epoch 1] ogbg-molmuv: 0.003628 val loss: 0.016073
[Epoch 1] ogbg-molmuv: 0.004994 test loss: 0.016847
[Epoch 2; Iter    18/ 2172] train: loss: 0.0051362
[Epoch 2; Iter    48/ 2172] train: loss: 0.0035627
[Epoch 2; Iter    78/ 2172] train: loss: 0.0041806
[Epoch 2; Iter   108/ 2172] train: loss: 0.0039743
[Epoch 2; Iter   138/ 2172] train: loss: 0.0844336
[Epoch 2; Iter   168/ 2172] train: loss: 0.0036903
[Epoch 2; Iter   198/ 2172] train: loss: 0.0034442
[Epoch 2; Iter   228/ 2172] train: loss: 0.0036295
[Epoch 2; Iter   258/ 2172] train: loss: 0.0033109
[Epoch 2; Iter   288/ 2172] train: loss: 0.0034138
[Epoch 2; Iter   318/ 2172] train: loss: 0.0028152
[Epoch 2; Iter   348/ 2172] train: loss: 0.0028944
[Epoch 2; Iter   378/ 2172] train: loss: 0.0030415
[Epoch 2; Iter   408/ 2172] train: loss: 0.0028693
[Epoch 2; Iter   438/ 2172] train: loss: 0.0031761
[Epoch 2; Iter   468/ 2172] train: loss: 0.0031420
[Epoch 2; Iter   498/ 2172] train: loss: 0.0026141
[Epoch 2; Iter   528/ 2172] train: loss: 0.0030270
[Epoch 2; Iter   558/ 2172] train: loss: 0.0024729
[Epoch 2; Iter   588/ 2172] train: loss: 0.0031941
[Epoch 2; Iter   618/ 2172] train: loss: 0.0025120
[Epoch 2; Iter   648/ 2172] train: loss: 0.0022791
[Epoch 2; Iter   678/ 2172] train: loss: 0.0036191
[Epoch 2; Iter   708/ 2172] train: loss: 0.0024856
[Epoch 2; Iter   738/ 2172] train: loss: 0.0022351
[Epoch 2; Iter   768/ 2172] train: loss: 0.0023668
[Epoch 2; Iter   798/ 2172] train: loss: 0.0021378
[Epoch 2; Iter   828/ 2172] train: loss: 0.0023287
[Epoch 2; Iter   858/ 2172] train: loss: 0.0023022
[Epoch 2; Iter   888/ 2172] train: loss: 0.0024066
[Epoch 2; Iter   918/ 2172] train: loss: 0.0022927
[Epoch 2; Iter   948/ 2172] train: loss: 0.0702287
[Epoch 2; Iter   978/ 2172] train: loss: 0.0023599
[Epoch 2; Iter  1008/ 2172] train: loss: 0.0037539
[Epoch 2; Iter  1038/ 2172] train: loss: 0.0019539
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.6/PNA_ogbg-molmuv_3DInfomax_muv_random=0.6_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.6
logdir: runs/split/3DInfomax/muv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/ 1862] train: loss: 0.6918954
[Epoch 1; Iter    60/ 1862] train: loss: 0.6934730
[Epoch 1; Iter    90/ 1862] train: loss: 0.6928129
[Epoch 1; Iter   120/ 1862] train: loss: 0.6933318
[Epoch 1; Iter   150/ 1862] train: loss: 0.6927553
[Epoch 1; Iter   180/ 1862] train: loss: 0.6933533
[Epoch 1; Iter   210/ 1862] train: loss: 0.6925451
[Epoch 1; Iter   240/ 1862] train: loss: 0.6944460
[Epoch 1; Iter   270/ 1862] train: loss: 0.6939731
[Epoch 1; Iter   300/ 1862] train: loss: 0.6920031
[Epoch 1; Iter   330/ 1862] train: loss: 0.6927799
[Epoch 1; Iter   360/ 1862] train: loss: 0.6925805
[Epoch 1; Iter   390/ 1862] train: loss: 0.6928262
[Epoch 1; Iter   420/ 1862] train: loss: 0.6932552
[Epoch 1; Iter   450/ 1862] train: loss: 0.6927624
[Epoch 1; Iter   480/ 1862] train: loss: 0.6911733
[Epoch 1; Iter   510/ 1862] train: loss: 0.6908775
[Epoch 1; Iter   540/ 1862] train: loss: 0.6906248
[Epoch 1; Iter   570/ 1862] train: loss: 0.6892183
[Epoch 1; Iter   600/ 1862] train: loss: 0.6886362
[Epoch 1; Iter   630/ 1862] train: loss: 0.6901084
[Epoch 1; Iter   660/ 1862] train: loss: 0.6891164
[Epoch 1; Iter   690/ 1862] train: loss: 0.6895697
[Epoch 1; Iter   720/ 1862] train: loss: 0.6867319
[Epoch 1; Iter   750/ 1862] train: loss: 0.6782311
[Epoch 1; Iter   780/ 1862] train: loss: 0.6573255
[Epoch 1; Iter   810/ 1862] train: loss: 0.6351073
[Epoch 1; Iter   840/ 1862] train: loss: 0.6189166
[Epoch 1; Iter   870/ 1862] train: loss: 0.5372596
[Epoch 1; Iter   900/ 1862] train: loss: 0.5189162
[Epoch 1; Iter   930/ 1862] train: loss: 0.4760550
[Epoch 1; Iter   960/ 1862] train: loss: 0.4068594
[Epoch 1; Iter   990/ 1862] train: loss: 0.3380416
[Epoch 1; Iter  1020/ 1862] train: loss: 0.2598346
[Epoch 1; Iter  1050/ 1862] train: loss: 0.2075789
[Epoch 1; Iter  1080/ 1862] train: loss: 0.1613324
[Epoch 1; Iter  1110/ 1862] train: loss: 0.1279328
[Epoch 1; Iter  1140/ 1862] train: loss: 0.1068123
[Epoch 1; Iter  1170/ 1862] train: loss: 0.0993002
[Epoch 1; Iter  1200/ 1862] train: loss: 0.0741838
[Epoch 1; Iter  1230/ 1862] train: loss: 0.0472332
[Epoch 1; Iter  1260/ 1862] train: loss: 0.0415878
[Epoch 1; Iter  1290/ 1862] train: loss: 0.0382512
[Epoch 1; Iter  1320/ 1862] train: loss: 0.0285258
[Epoch 1; Iter  1350/ 1862] train: loss: 0.0237562
[Epoch 1; Iter  1380/ 1862] train: loss: 0.0717733
[Epoch 1; Iter  1410/ 1862] train: loss: 0.0190853
[Epoch 1; Iter  1440/ 1862] train: loss: 0.0188107
[Epoch 1; Iter  1470/ 1862] train: loss: 0.0176005
[Epoch 1; Iter  1500/ 1862] train: loss: 0.0654492
[Epoch 1; Iter  1530/ 1862] train: loss: 0.0171655
[Epoch 1; Iter  1560/ 1862] train: loss: 0.0594361
[Epoch 1; Iter  1590/ 1862] train: loss: 0.0173689
[Epoch 1; Iter  1620/ 1862] train: loss: 0.0156773
[Epoch 1; Iter  1650/ 1862] train: loss: 0.0146607
[Epoch 1; Iter  1680/ 1862] train: loss: 0.0121952
[Epoch 1; Iter  1710/ 1862] train: loss: 0.0122406
[Epoch 1; Iter  1740/ 1862] train: loss: 0.0706975
[Epoch 1; Iter  1770/ 1862] train: loss: 0.0673144
[Epoch 1; Iter  1800/ 1862] train: loss: 0.0090455
[Epoch 1; Iter  1830/ 1862] train: loss: 0.0087536
[Epoch 1; Iter  1860/ 1862] train: loss: 0.0074001
[Epoch 1] ogbg-molmuv: 0.014769 val loss: 0.017672
[Epoch 1] ogbg-molmuv: 0.008284 test loss: 0.017328
[Epoch 2; Iter    28/ 1862] train: loss: 0.0109177
[Epoch 2; Iter    58/ 1862] train: loss: 0.0576682
[Epoch 2; Iter    88/ 1862] train: loss: 0.0062411
[Epoch 2; Iter   118/ 1862] train: loss: 0.1345883
[Epoch 2; Iter   148/ 1862] train: loss: 0.0052710
[Epoch 2; Iter   178/ 1862] train: loss: 0.0050424
[Epoch 2; Iter   208/ 1862] train: loss: 0.0052895
[Epoch 2; Iter   238/ 1862] train: loss: 0.0045397
[Epoch 2; Iter   268/ 1862] train: loss: 0.0055005
[Epoch 2; Iter   298/ 1862] train: loss: 0.0048062
[Epoch 2; Iter   328/ 1862] train: loss: 0.0050305
[Epoch 2; Iter   358/ 1862] train: loss: 0.0037353
[Epoch 2; Iter   388/ 1862] train: loss: 0.0038070
[Epoch 2; Iter   418/ 1862] train: loss: 0.0034908
[Epoch 2; Iter   448/ 1862] train: loss: 0.0733543
[Epoch 2; Iter   478/ 1862] train: loss: 0.0032156
[Epoch 2; Iter   508/ 1862] train: loss: 0.0035721
[Epoch 2; Iter   538/ 1862] train: loss: 0.0039386
[Epoch 2; Iter   568/ 1862] train: loss: 0.0029717
[Epoch 2; Iter   598/ 1862] train: loss: 0.0029395
[Epoch 2; Iter   628/ 1862] train: loss: 0.0027659
[Epoch 2; Iter   658/ 1862] train: loss: 0.0809772
[Epoch 2; Iter   688/ 1862] train: loss: 0.0027973
[Epoch 2; Iter   718/ 1862] train: loss: 0.0026682
[Epoch 2; Iter   748/ 1862] train: loss: 0.0661280
[Epoch 2; Iter   778/ 1862] train: loss: 0.0028565
[Epoch 2; Iter   808/ 1862] train: loss: 0.0767591
[Epoch 2; Iter   838/ 1862] train: loss: 0.0026715
[Epoch 2; Iter   868/ 1862] train: loss: 0.0025067
[Epoch 2; Iter   898/ 1862] train: loss: 0.0024280
[Epoch 2; Iter   928/ 1862] train: loss: 0.0827563
[Epoch 2; Iter   958/ 1862] train: loss: 0.0024093
[Epoch 2; Iter   988/ 1862] train: loss: 0.0023976
[Epoch 2; Iter  1018/ 1862] train: loss: 0.0026497
[Epoch 2; Iter  1048/ 1862] train: loss: 0.0596189
[Epoch 2; Iter  1078/ 1862] train: loss: 0.0031902
[Epoch 2; Iter  1108/ 1862] train: loss: 0.0024394
[Epoch 2; Iter  1138/ 1862] train: loss: 0.0022185
[Epoch 2; Iter  1168/ 1862] train: loss: 0.0021119
[Epoch 2; Iter  1198/ 1862] train: loss: 0.0022745
[Epoch 2; Iter  1228/ 1862] train: loss: 0.0027246
[Epoch 2; Iter  1258/ 1862] train: loss: 0.0020176
[Epoch 2; Iter  1288/ 1862] train: loss: 0.0020291
[Epoch 2; Iter  1318/ 1862] train: loss: 0.0021834
[Epoch 2; Iter  1348/ 1862] train: loss: 0.0922755
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.6/PNA_ogbg-molmuv_3DInfomax_muv_random=0.6_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.6
logdir: runs/split/3DInfomax/muv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/ 1862] train: loss: 0.6927721
[Epoch 1; Iter    60/ 1862] train: loss: 0.6937750
[Epoch 1; Iter    90/ 1862] train: loss: 0.6931298
[Epoch 1; Iter   120/ 1862] train: loss: 0.6935001
[Epoch 1; Iter   150/ 1862] train: loss: 0.6920946
[Epoch 1; Iter   180/ 1862] train: loss: 0.6940670
[Epoch 1; Iter   210/ 1862] train: loss: 0.6916447
[Epoch 1; Iter   240/ 1862] train: loss: 0.6926174
[Epoch 1; Iter   270/ 1862] train: loss: 0.6933724
[Epoch 1; Iter   300/ 1862] train: loss: 0.6925195
[Epoch 1; Iter   330/ 1862] train: loss: 0.6943632
[Epoch 1; Iter   360/ 1862] train: loss: 0.6934147
[Epoch 1; Iter   390/ 1862] train: loss: 0.6904677
[Epoch 1; Iter   420/ 1862] train: loss: 0.6902480
[Epoch 1; Iter   450/ 1862] train: loss: 0.6923187
[Epoch 1; Iter   480/ 1862] train: loss: 0.6925491
[Epoch 1; Iter   510/ 1862] train: loss: 0.6921038
[Epoch 1; Iter   540/ 1862] train: loss: 0.6890582
[Epoch 1; Iter   570/ 1862] train: loss: 0.6886132
[Epoch 1; Iter   600/ 1862] train: loss: 0.6886647
[Epoch 1; Iter   630/ 1862] train: loss: 0.6859598
[Epoch 1; Iter   660/ 1862] train: loss: 0.6874088
[Epoch 1; Iter   690/ 1862] train: loss: 0.6898972
[Epoch 1; Iter   720/ 1862] train: loss: 0.6854119
[Epoch 1; Iter   750/ 1862] train: loss: 0.6774037
[Epoch 1; Iter   780/ 1862] train: loss: 0.6510354
[Epoch 1; Iter   810/ 1862] train: loss: 0.6391439
[Epoch 1; Iter   840/ 1862] train: loss: 0.5903506
[Epoch 1; Iter   870/ 1862] train: loss: 0.5448662
[Epoch 1; Iter   900/ 1862] train: loss: 0.4824482
[Epoch 1; Iter   930/ 1862] train: loss: 0.4609170
[Epoch 1; Iter   960/ 1862] train: loss: 0.3748063
[Epoch 1; Iter   990/ 1862] train: loss: 0.3235972
[Epoch 1; Iter  1020/ 1862] train: loss: 0.2722010
[Epoch 1; Iter  1050/ 1862] train: loss: 0.2437873
[Epoch 1; Iter  1080/ 1862] train: loss: 0.1770842
[Epoch 1; Iter  1110/ 1862] train: loss: 0.1191495
[Epoch 1; Iter  1140/ 1862] train: loss: 0.1052673
[Epoch 1; Iter  1170/ 1862] train: loss: 0.0739795
[Epoch 1; Iter  1200/ 1862] train: loss: 0.1035672
[Epoch 1; Iter  1230/ 1862] train: loss: 0.0532975
[Epoch 1; Iter  1260/ 1862] train: loss: 0.0408179
[Epoch 1; Iter  1290/ 1862] train: loss: 0.0317984
[Epoch 1; Iter  1320/ 1862] train: loss: 0.0293941
[Epoch 1; Iter  1350/ 1862] train: loss: 0.0233266
[Epoch 1; Iter  1380/ 1862] train: loss: 0.0738270
[Epoch 1; Iter  1410/ 1862] train: loss: 0.0765864
[Epoch 1; Iter  1440/ 1862] train: loss: 0.0192715
[Epoch 1; Iter  1470/ 1862] train: loss: 0.0177940
[Epoch 1; Iter  1500/ 1862] train: loss: 0.1404874
[Epoch 1; Iter  1530/ 1862] train: loss: 0.0185623
[Epoch 1; Iter  1560/ 1862] train: loss: 0.0180733
[Epoch 1; Iter  1590/ 1862] train: loss: 0.0726808
[Epoch 1; Iter  1620/ 1862] train: loss: 0.0147544
[Epoch 1; Iter  1650/ 1862] train: loss: 0.0136518
[Epoch 1; Iter  1680/ 1862] train: loss: 0.0107220
[Epoch 1; Iter  1710/ 1862] train: loss: 0.0116453
[Epoch 1; Iter  1740/ 1862] train: loss: 0.0701710
[Epoch 1; Iter  1770/ 1862] train: loss: 0.0098839
[Epoch 1; Iter  1800/ 1862] train: loss: 0.0097448
[Epoch 1; Iter  1830/ 1862] train: loss: 0.0079706
[Epoch 1; Iter  1860/ 1862] train: loss: 0.0080843
[Epoch 1] ogbg-molmuv: 0.010974 val loss: 0.017234
[Epoch 1] ogbg-molmuv: 0.004308 test loss: 0.016676
[Epoch 2; Iter    28/ 1862] train: loss: 0.0066436
[Epoch 2; Iter    58/ 1862] train: loss: 0.0062175
[Epoch 2; Iter    88/ 1862] train: loss: 0.0056426
[Epoch 2; Iter   118/ 1862] train: loss: 0.0058512
[Epoch 2; Iter   148/ 1862] train: loss: 0.0053370
[Epoch 2; Iter   178/ 1862] train: loss: 0.0050035
[Epoch 2; Iter   208/ 1862] train: loss: 0.0061112
[Epoch 2; Iter   238/ 1862] train: loss: 0.0668019
[Epoch 2; Iter   268/ 1862] train: loss: 0.0051460
[Epoch 2; Iter   298/ 1862] train: loss: 0.0041611
[Epoch 2; Iter   328/ 1862] train: loss: 0.0042613
[Epoch 2; Iter   358/ 1862] train: loss: 0.0037360
[Epoch 2; Iter   388/ 1862] train: loss: 0.0037776
[Epoch 2; Iter   418/ 1862] train: loss: 0.0041446
[Epoch 2; Iter   448/ 1862] train: loss: 0.0775409
[Epoch 2; Iter   478/ 1862] train: loss: 0.0041411
[Epoch 2; Iter   508/ 1862] train: loss: 0.0037285
[Epoch 2; Iter   538/ 1862] train: loss: 0.0034366
[Epoch 2; Iter   568/ 1862] train: loss: 0.0028919
[Epoch 2; Iter   598/ 1862] train: loss: 0.0031284
[Epoch 2; Iter   628/ 1862] train: loss: 0.0030206
[Epoch 2; Iter   658/ 1862] train: loss: 0.0027304
[Epoch 2; Iter   688/ 1862] train: loss: 0.0029446
[Epoch 2; Iter   718/ 1862] train: loss: 0.0026692
[Epoch 2; Iter   748/ 1862] train: loss: 0.0027555
[Epoch 2; Iter   778/ 1862] train: loss: 0.0030933
[Epoch 2; Iter   808/ 1862] train: loss: 0.0025730
[Epoch 2; Iter   838/ 1862] train: loss: 0.0023403
[Epoch 2; Iter   868/ 1862] train: loss: 0.0026183
[Epoch 2; Iter   898/ 1862] train: loss: 0.0030808
[Epoch 2; Iter   928/ 1862] train: loss: 0.0021077
[Epoch 2; Iter   958/ 1862] train: loss: 0.0022991
[Epoch 2; Iter   988/ 1862] train: loss: 0.0768504
[Epoch 2; Iter  1018/ 1862] train: loss: 0.0027394
[Epoch 2; Iter  1048/ 1862] train: loss: 0.0040007
[Epoch 2; Iter  1078/ 1862] train: loss: 0.0025007
[Epoch 2; Iter  1108/ 1862] train: loss: 0.0023676
[Epoch 2; Iter  1138/ 1862] train: loss: 0.0019835
[Epoch 2; Iter  1168/ 1862] train: loss: 0.0020800
[Epoch 2; Iter  1198/ 1862] train: loss: 0.0020692
[Epoch 2; Iter  1228/ 1862] train: loss: 0.0828803
[Epoch 2; Iter  1258/ 1862] train: loss: 0.0023494
[Epoch 2; Iter  1288/ 1862] train: loss: 0.0765296
[Epoch 2; Iter  1318/ 1862] train: loss: 0.0020604
[Epoch 2; Iter  1348/ 1862] train: loss: 0.0021902
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/muv/random/train_prop=0.6/PNA_ogbg-molmuv_3DInfomax_muv_random=0.6_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/muv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_muv_random=0.6
logdir: runs/split/3DInfomax/muv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molmuv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molmuv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 17
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/ 1862] train: loss: 0.6915838
[Epoch 1; Iter    60/ 1862] train: loss: 0.6913664
[Epoch 1; Iter    90/ 1862] train: loss: 0.6939557
[Epoch 1; Iter   120/ 1862] train: loss: 0.6903381
[Epoch 1; Iter   150/ 1862] train: loss: 0.6923639
[Epoch 1; Iter   180/ 1862] train: loss: 0.6926553
[Epoch 1; Iter   210/ 1862] train: loss: 0.6916167
[Epoch 1; Iter   240/ 1862] train: loss: 0.6919976
[Epoch 1; Iter   270/ 1862] train: loss: 0.6910314
[Epoch 1; Iter   300/ 1862] train: loss: 0.6915689
[Epoch 1; Iter   330/ 1862] train: loss: 0.6931113
[Epoch 1; Iter   360/ 1862] train: loss: 0.6921893
[Epoch 1; Iter   390/ 1862] train: loss: 0.6903227
[Epoch 1; Iter   420/ 1862] train: loss: 0.6888357
[Epoch 1; Iter   450/ 1862] train: loss: 0.6903738
[Epoch 1; Iter   480/ 1862] train: loss: 0.6894908
[Epoch 1; Iter   510/ 1862] train: loss: 0.6886349
[Epoch 1; Iter   540/ 1862] train: loss: 0.6898649
[Epoch 1; Iter   570/ 1862] train: loss: 0.6883965
[Epoch 1; Iter   600/ 1862] train: loss: 0.6883478
[Epoch 1; Iter   630/ 1862] train: loss: 0.6891032
[Epoch 1; Iter   660/ 1862] train: loss: 0.6881507
[Epoch 1; Iter   690/ 1862] train: loss: 0.6880883
[Epoch 1; Iter   720/ 1862] train: loss: 0.6850257
[Epoch 1; Iter   750/ 1862] train: loss: 0.6737229
[Epoch 1; Iter   780/ 1862] train: loss: 0.6595047
[Epoch 1; Iter   810/ 1862] train: loss: 0.6190197
[Epoch 1; Iter   840/ 1862] train: loss: 0.5999485
[Epoch 1; Iter   870/ 1862] train: loss: 0.5353562
[Epoch 1; Iter   900/ 1862] train: loss: 0.5010887
[Epoch 1; Iter   930/ 1862] train: loss: 0.4665506
[Epoch 1; Iter   960/ 1862] train: loss: 0.3573838
[Epoch 1; Iter   990/ 1862] train: loss: 0.3135648
[Epoch 1; Iter  1020/ 1862] train: loss: 0.2633129
[Epoch 1; Iter  1050/ 1862] train: loss: 0.2051450
[Epoch 1; Iter  1080/ 1862] train: loss: 0.1538182
[Epoch 1; Iter  1110/ 1862] train: loss: 0.1275254
[Epoch 1; Iter  1140/ 1862] train: loss: 0.1052354
[Epoch 1; Iter  1170/ 1862] train: loss: 0.1105985
[Epoch 1; Iter  1200/ 1862] train: loss: 0.0580458
[Epoch 1; Iter  1230/ 1862] train: loss: 0.0654962
[Epoch 1; Iter  1260/ 1862] train: loss: 0.0455578
[Epoch 1; Iter  1290/ 1862] train: loss: 0.0746869
[Epoch 1; Iter  1320/ 1862] train: loss: 0.0313659
[Epoch 1; Iter  1350/ 1862] train: loss: 0.0423940
[Epoch 1; Iter  1380/ 1862] train: loss: 0.0196114
[Epoch 1; Iter  1410/ 1862] train: loss: 0.0815189
[Epoch 1; Iter  1440/ 1862] train: loss: 0.0179077
[Epoch 1; Iter  1470/ 1862] train: loss: 0.0170103
[Epoch 1; Iter  1500/ 1862] train: loss: 0.0759052
[Epoch 1; Iter  1530/ 1862] train: loss: 0.0186425
[Epoch 1; Iter  1560/ 1862] train: loss: 0.0168287
[Epoch 1; Iter  1590/ 1862] train: loss: 0.0160444
[Epoch 1; Iter  1620/ 1862] train: loss: 0.0180924
[Epoch 1; Iter  1650/ 1862] train: loss: 0.0150377
[Epoch 1; Iter  1680/ 1862] train: loss: 0.0141235
[Epoch 1; Iter  1710/ 1862] train: loss: 0.0134762
[Epoch 1; Iter  1740/ 1862] train: loss: 0.0111997
[Epoch 1; Iter  1770/ 1862] train: loss: 0.0091647
[Epoch 1; Iter  1800/ 1862] train: loss: 0.0643034
[Epoch 1; Iter  1830/ 1862] train: loss: 0.0086726
[Epoch 1; Iter  1860/ 1862] train: loss: 0.0078254
[Epoch 1] ogbg-molmuv: 0.015967 val loss: 0.035049
[Epoch 1] ogbg-molmuv: 0.014066 test loss: 0.029264
[Epoch 2; Iter    28/ 1862] train: loss: 0.0062932
[Epoch 2; Iter    58/ 1862] train: loss: 0.0054427
[Epoch 2; Iter    88/ 1862] train: loss: 0.0057988
[Epoch 2; Iter   118/ 1862] train: loss: 0.0719366
[Epoch 2; Iter   148/ 1862] train: loss: 0.0057799
[Epoch 2; Iter   178/ 1862] train: loss: 0.0074176
[Epoch 2; Iter   208/ 1862] train: loss: 0.0060387
[Epoch 2; Iter   238/ 1862] train: loss: 0.0047226
[Epoch 2; Iter   268/ 1862] train: loss: 0.0042599
[Epoch 2; Iter   298/ 1862] train: loss: 0.0043299
[Epoch 2; Iter   328/ 1862] train: loss: 0.0036612
[Epoch 2; Iter   358/ 1862] train: loss: 0.0035797
[Epoch 2; Iter   388/ 1862] train: loss: 0.0044381
[Epoch 2; Iter   418/ 1862] train: loss: 0.0034804
[Epoch 2; Iter   448/ 1862] train: loss: 0.0038343
[Epoch 2; Iter   478/ 1862] train: loss: 0.0033216
[Epoch 2; Iter   508/ 1862] train: loss: 0.0036194
[Epoch 2; Iter   538/ 1862] train: loss: 0.0036700
[Epoch 2; Iter   568/ 1862] train: loss: 0.0035438
[Epoch 2; Iter   598/ 1862] train: loss: 0.0034986
[Epoch 2; Iter   628/ 1862] train: loss: 0.0027956
[Epoch 2; Iter   658/ 1862] train: loss: 0.0032969
[Epoch 2; Iter   688/ 1862] train: loss: 0.0030588
[Epoch 2; Iter   718/ 1862] train: loss: 0.0027302
[Epoch 2; Iter   748/ 1862] train: loss: 0.0024031
[Epoch 2; Iter   778/ 1862] train: loss: 0.0026457
[Epoch 2; Iter   808/ 1862] train: loss: 0.0026505
[Epoch 2; Iter   838/ 1862] train: loss: 0.0037763
[Epoch 2; Iter   868/ 1862] train: loss: 0.0025037
[Epoch 2; Iter   898/ 1862] train: loss: 0.0025292
[Epoch 2; Iter   928/ 1862] train: loss: 0.0031958
[Epoch 2; Iter   958/ 1862] train: loss: 0.0026522
[Epoch 2; Iter   988/ 1862] train: loss: 0.0027085
[Epoch 2; Iter  1018/ 1862] train: loss: 0.0025699
[Epoch 2; Iter  1048/ 1862] train: loss: 0.0030687
[Epoch 2; Iter  1078/ 1862] train: loss: 0.0023958
[Epoch 2; Iter  1108/ 1862] train: loss: 0.0025995
[Epoch 2; Iter  1138/ 1862] train: loss: 0.0027356
[Epoch 2; Iter  1168/ 1862] train: loss: 0.0812140
[Epoch 2; Iter  1198/ 1862] train: loss: 0.0854544
[Epoch 2; Iter  1228/ 1862] train: loss: 0.0023427
[Epoch 2; Iter  1258/ 1862] train: loss: 0.0023571
[Epoch 2; Iter  1288/ 1862] train: loss: 0.0025741
[Epoch 2; Iter  1318/ 1862] train: loss: 0.0023154
[Epoch 2; Iter  1348/ 1862] train: loss: 0.0022815
[Epoch 2; Iter   757/ 2483] train: loss: 0.0023193
[Epoch 2; Iter   787/ 2483] train: loss: 0.0747261
[Epoch 2; Iter   817/ 2483] train: loss: 0.0022216
[Epoch 2; Iter   847/ 2483] train: loss: 0.0019829
[Epoch 2; Iter   877/ 2483] train: loss: 0.0017581
[Epoch 2; Iter   907/ 2483] train: loss: 0.0021060
[Epoch 2; Iter   937/ 2483] train: loss: 0.0020452
[Epoch 2; Iter   967/ 2483] train: loss: 0.0020251
[Epoch 2; Iter   997/ 2483] train: loss: 0.0017320
[Epoch 2; Iter  1027/ 2483] train: loss: 0.0019593
[Epoch 2; Iter  1057/ 2483] train: loss: 0.0020362
[Epoch 2; Iter  1087/ 2483] train: loss: 0.0021948
[Epoch 2; Iter  1117/ 2483] train: loss: 0.0024754
[Epoch 2; Iter  1147/ 2483] train: loss: 0.0024772
[Epoch 2; Iter  1177/ 2483] train: loss: 0.0020005
[Epoch 2; Iter  1207/ 2483] train: loss: 0.0015958
[Epoch 2; Iter  1237/ 2483] train: loss: 0.0017441
[Epoch 2; Iter  1267/ 2483] train: loss: 0.0016796
[Epoch 2; Iter  1297/ 2483] train: loss: 0.0017815
[Epoch 2; Iter  1327/ 2483] train: loss: 0.0861765
[Epoch 2; Iter  1357/ 2483] train: loss: 0.0018292
[Epoch 2; Iter  1387/ 2483] train: loss: 0.0016815
[Epoch 2; Iter  1417/ 2483] train: loss: 0.0024392
[Epoch 2; Iter  1447/ 2483] train: loss: 0.0040987
[Epoch 2; Iter  1477/ 2483] train: loss: 0.0019944
[Epoch 2; Iter  1507/ 2483] train: loss: 0.0018296
[Epoch 2; Iter  1537/ 2483] train: loss: 0.0677111
[Epoch 2; Iter  1567/ 2483] train: loss: 0.0019149
[Epoch 2; Iter  1597/ 2483] train: loss: 0.0016651
[Epoch 2; Iter  1627/ 2483] train: loss: 0.2071721
[Epoch 2; Iter  1657/ 2483] train: loss: 0.0017138
[Epoch 2; Iter  1687/ 2483] train: loss: 0.0016623
[Epoch 2; Iter  1717/ 2483] train: loss: 0.0019289
[Epoch 2; Iter  1747/ 2483] train: loss: 0.0018480
[Epoch 2; Iter  1777/ 2483] train: loss: 0.0021240
[Epoch 2; Iter  1807/ 2483] train: loss: 0.0835301
[Epoch 2; Iter  1837/ 2483] train: loss: 0.0022003
[Epoch 2; Iter  1867/ 2483] train: loss: 0.0021398
[Epoch 2; Iter  1897/ 2483] train: loss: 0.0031036
[Epoch 2; Iter  1927/ 2483] train: loss: 0.0022204
[Epoch 2; Iter  1957/ 2483] train: loss: 0.0594550
[Epoch 2; Iter  1987/ 2483] train: loss: 0.0019636
[Epoch 2; Iter  2017/ 2483] train: loss: 0.0020672
[Epoch 2; Iter  2047/ 2483] train: loss: 0.0018299
[Epoch 2; Iter  2077/ 2483] train: loss: 0.0022846
[Epoch 2; Iter  2107/ 2483] train: loss: 0.0023239
[Epoch 2; Iter  2137/ 2483] train: loss: 0.0022000
[Epoch 2; Iter  2167/ 2483] train: loss: 0.0560220
[Epoch 2; Iter  2197/ 2483] train: loss: 0.0023814
[Epoch 2; Iter  2227/ 2483] train: loss: 0.0024050
[Epoch 2; Iter  2257/ 2483] train: loss: 0.0705350
[Epoch 2; Iter  2287/ 2483] train: loss: 0.0020394
[Epoch 2; Iter  2317/ 2483] train: loss: 0.0017537
[Epoch 2; Iter  2347/ 2483] train: loss: 0.0021210
[Epoch 2; Iter  2377/ 2483] train: loss: 0.0019585
[Epoch 2; Iter  2407/ 2483] train: loss: 0.0019378
[Epoch 2; Iter  2437/ 2483] train: loss: 0.1234122
[Epoch 2; Iter  2467/ 2483] train: loss: 0.0021441
[Epoch 2] ogbg-molmuv: 0.009957 val loss: 0.010871
[Epoch 2] ogbg-molmuv: 0.010180 test loss: 0.015230
[Epoch 3; Iter    14/ 2483] train: loss: 0.0021518
[Epoch 3; Iter    44/ 2483] train: loss: 0.0024133
[Epoch 3; Iter    74/ 2483] train: loss: 0.0019500
[Epoch 3; Iter   104/ 2483] train: loss: 0.0015868
[Epoch 3; Iter   134/ 2483] train: loss: 0.0020249
[Epoch 3; Iter   164/ 2483] train: loss: 0.0018164
[Epoch 3; Iter   194/ 2483] train: loss: 0.0018138
[Epoch 3; Iter   224/ 2483] train: loss: 0.0027309
[Epoch 3; Iter   254/ 2483] train: loss: 0.0020774
[Epoch 3; Iter   284/ 2483] train: loss: 0.0016259
[Epoch 3; Iter   314/ 2483] train: loss: 0.0016390
[Epoch 3; Iter   344/ 2483] train: loss: 0.0020079
[Epoch 3; Iter   374/ 2483] train: loss: 0.0017142
[Epoch 3; Iter   404/ 2483] train: loss: 0.0018581
[Epoch 3; Iter   434/ 2483] train: loss: 0.0023213
[Epoch 3; Iter   464/ 2483] train: loss: 0.0014747
[Epoch 3; Iter   494/ 2483] train: loss: 0.0697083
[Epoch 3; Iter   524/ 2483] train: loss: 0.0028208
[Epoch 3; Iter   554/ 2483] train: loss: 0.0015092
[Epoch 3; Iter   584/ 2483] train: loss: 0.0638249
[Epoch 3; Iter   614/ 2483] train: loss: 0.0026918
[Epoch 3; Iter   644/ 2483] train: loss: 0.0022393
[Epoch 3; Iter   674/ 2483] train: loss: 0.0041057
[Epoch 3; Iter   704/ 2483] train: loss: 0.0017406
[Epoch 3; Iter   734/ 2483] train: loss: 0.0014028
[Epoch 3; Iter   764/ 2483] train: loss: 0.0019815
[Epoch 3; Iter   794/ 2483] train: loss: 0.0023129
[Epoch 3; Iter   824/ 2483] train: loss: 0.0018227
[Epoch 3; Iter   854/ 2483] train: loss: 0.0017346
[Epoch 3; Iter   884/ 2483] train: loss: 0.0018313
[Epoch 3; Iter   914/ 2483] train: loss: 0.0809889
[Epoch 3; Iter   944/ 2483] train: loss: 0.0019396
[Epoch 3; Iter   974/ 2483] train: loss: 0.0018128
[Epoch 3; Iter  1004/ 2483] train: loss: 0.0025854
[Epoch 3; Iter  1034/ 2483] train: loss: 0.0020427
[Epoch 3; Iter  1064/ 2483] train: loss: 0.0019489
[Epoch 3; Iter  1094/ 2483] train: loss: 0.3056889
[Epoch 3; Iter  1124/ 2483] train: loss: 0.0028613
[Epoch 3; Iter  1154/ 2483] train: loss: 0.0030058
[Epoch 3; Iter  1184/ 2483] train: loss: 0.0581740
[Epoch 3; Iter  1214/ 2483] train: loss: 0.0022155
[Epoch 3; Iter  1244/ 2483] train: loss: 0.0020444
[Epoch 3; Iter  1274/ 2483] train: loss: 0.0016501
[Epoch 3; Iter  1304/ 2483] train: loss: 0.0018091
[Epoch 3; Iter  1334/ 2483] train: loss: 0.0022723
[Epoch 3; Iter  1364/ 2483] train: loss: 0.0021921
[Epoch 3; Iter  1394/ 2483] train: loss: 0.0013962
[Epoch 3; Iter  1424/ 2483] train: loss: 0.0023155
[Epoch 3; Iter  1454/ 2483] train: loss: 0.0023726
[Epoch 3; Iter  1484/ 2483] train: loss: 0.0025899
[Epoch 3; Iter  1514/ 2483] train: loss: 0.0026893
[Epoch 3; Iter  1544/ 2483] train: loss: 0.0694559
[Epoch 3; Iter  1574/ 2483] train: loss: 0.0926792
[Epoch 3; Iter  1604/ 2483] train: loss: 0.0025520
[Epoch 3; Iter  1634/ 2483] train: loss: 0.0823950
[Epoch 3; Iter  1664/ 2483] train: loss: 0.1030733
[Epoch 3; Iter  1694/ 2483] train: loss: 0.0016693
[Epoch 3; Iter  1724/ 2483] train: loss: 0.0016691
[Epoch 3; Iter  1754/ 2483] train: loss: 0.1612353
[Epoch 3; Iter  1784/ 2483] train: loss: 0.0023469
[Epoch 3; Iter  1814/ 2483] train: loss: 0.0018951
[Epoch 3; Iter  1844/ 2483] train: loss: 0.0023258
[Epoch 3; Iter  1874/ 2483] train: loss: 0.0035456
[Epoch 3; Iter  1904/ 2483] train: loss: 0.0016245
[Epoch 3; Iter  1934/ 2483] train: loss: 0.0018265
[Epoch 3; Iter  1964/ 2483] train: loss: 0.0018033
[Epoch 3; Iter  1994/ 2483] train: loss: 0.0018253
[Epoch 3; Iter  2024/ 2483] train: loss: 0.0017257
[Epoch 3; Iter  2054/ 2483] train: loss: 0.0022832
[Epoch 3; Iter  2084/ 2483] train: loss: 0.0019694
[Epoch 3; Iter  2114/ 2483] train: loss: 0.0018419
[Epoch 3; Iter  2144/ 2483] train: loss: 0.0015638
[Epoch 3; Iter  2174/ 2483] train: loss: 0.0016608
[Epoch 3; Iter  2204/ 2483] train: loss: 0.0015709
[Epoch 3; Iter  2234/ 2483] train: loss: 0.0017037
[Epoch 3; Iter  2264/ 2483] train: loss: 0.0024906
[Epoch 3; Iter  2294/ 2483] train: loss: 0.0020426
[Epoch 3; Iter  2324/ 2483] train: loss: 0.0017293
[Epoch 3; Iter  2354/ 2483] train: loss: 0.0023825
[Epoch 3; Iter  2384/ 2483] train: loss: 0.1188569
[Epoch 3; Iter  2414/ 2483] train: loss: 0.1645346
[Epoch 3; Iter  2444/ 2483] train: loss: 0.0028220
[Epoch 3; Iter  2474/ 2483] train: loss: 0.0023800
[Epoch 3] ogbg-molmuv: 0.051090 val loss: 0.011287
[Epoch 3] ogbg-molmuv: 0.016803 test loss: 0.015239
[Epoch 4; Iter    21/ 2483] train: loss: 0.0698595
[Epoch 4; Iter    51/ 2483] train: loss: 0.0727113
[Epoch 4; Iter    81/ 2483] train: loss: 0.0023002
[Epoch 4; Iter   111/ 2483] train: loss: 0.0018887
[Epoch 4; Iter   141/ 2483] train: loss: 0.0017483
[Epoch 4; Iter   171/ 2483] train: loss: 0.0014300
[Epoch 4; Iter   201/ 2483] train: loss: 0.0019602
[Epoch 4; Iter   231/ 2483] train: loss: 0.0013897
[Epoch 4; Iter   261/ 2483] train: loss: 0.0021626
[Epoch 4; Iter   291/ 2483] train: loss: 0.0027983
[Epoch 4; Iter   321/ 2483] train: loss: 0.0021103
[Epoch 4; Iter   351/ 2483] train: loss: 0.0021993
[Epoch 4; Iter   381/ 2483] train: loss: 0.0014826
[Epoch 4; Iter   411/ 2483] train: loss: 0.0016494
[Epoch 4; Iter   441/ 2483] train: loss: 0.0316167
[Epoch 2; Iter   757/ 2483] train: loss: 0.0025219
[Epoch 2; Iter   787/ 2483] train: loss: 0.0036811
[Epoch 2; Iter   817/ 2483] train: loss: 0.0020447
[Epoch 2; Iter   847/ 2483] train: loss: 0.0795540
[Epoch 2; Iter   877/ 2483] train: loss: 0.0021405
[Epoch 2; Iter   907/ 2483] train: loss: 0.0034188
[Epoch 2; Iter   937/ 2483] train: loss: 0.0020156
[Epoch 2; Iter   967/ 2483] train: loss: 0.0024673
[Epoch 2; Iter   997/ 2483] train: loss: 0.0019256
[Epoch 2; Iter  1027/ 2483] train: loss: 0.0018181
[Epoch 2; Iter  1057/ 2483] train: loss: 0.0023403
[Epoch 2; Iter  1087/ 2483] train: loss: 0.0022115
[Epoch 2; Iter  1117/ 2483] train: loss: 0.0020841
[Epoch 2; Iter  1147/ 2483] train: loss: 0.0019445
[Epoch 2; Iter  1177/ 2483] train: loss: 0.0624804
[Epoch 2; Iter  1207/ 2483] train: loss: 0.0734124
[Epoch 2; Iter  1237/ 2483] train: loss: 0.0020876
[Epoch 2; Iter  1267/ 2483] train: loss: 0.0017402
[Epoch 2; Iter  1297/ 2483] train: loss: 0.0015834
[Epoch 2; Iter  1327/ 2483] train: loss: 0.0016970
[Epoch 2; Iter  1357/ 2483] train: loss: 0.0015228
[Epoch 2; Iter  1387/ 2483] train: loss: 0.0015837
[Epoch 2; Iter  1417/ 2483] train: loss: 0.0021435
[Epoch 2; Iter  1447/ 2483] train: loss: 0.0020259
[Epoch 2; Iter  1477/ 2483] train: loss: 0.0025604
[Epoch 2; Iter  1507/ 2483] train: loss: 0.0014829
[Epoch 2; Iter  1537/ 2483] train: loss: 0.0015487
[Epoch 2; Iter  1567/ 2483] train: loss: 0.0031479
[Epoch 2; Iter  1597/ 2483] train: loss: 0.0035879
[Epoch 2; Iter  1627/ 2483] train: loss: 0.0016520
[Epoch 2; Iter  1657/ 2483] train: loss: 0.0017693
[Epoch 2; Iter  1687/ 2483] train: loss: 0.0022239
[Epoch 2; Iter  1717/ 2483] train: loss: 0.0015809
[Epoch 2; Iter  1747/ 2483] train: loss: 0.0015630
[Epoch 2; Iter  1777/ 2483] train: loss: 0.0019679
[Epoch 2; Iter  1807/ 2483] train: loss: 0.0022750
[Epoch 2; Iter  1837/ 2483] train: loss: 0.0881460
[Epoch 2; Iter  1867/ 2483] train: loss: 0.0016442
[Epoch 2; Iter  1897/ 2483] train: loss: 0.0021485
[Epoch 2; Iter  1927/ 2483] train: loss: 0.0019282
[Epoch 2; Iter  1957/ 2483] train: loss: 0.0019964
[Epoch 2; Iter  1987/ 2483] train: loss: 0.0017555
[Epoch 2; Iter  2017/ 2483] train: loss: 0.0021270
[Epoch 2; Iter  2047/ 2483] train: loss: 0.0021151
[Epoch 2; Iter  2077/ 2483] train: loss: 0.0784023
[Epoch 2; Iter  2107/ 2483] train: loss: 0.0023980
[Epoch 2; Iter  2137/ 2483] train: loss: 0.0019918
[Epoch 2; Iter  2167/ 2483] train: loss: 0.0021115
[Epoch 2; Iter  2197/ 2483] train: loss: 0.0016861
[Epoch 2; Iter  2227/ 2483] train: loss: 0.0024717
[Epoch 2; Iter  2257/ 2483] train: loss: 0.0020867
[Epoch 2; Iter  2287/ 2483] train: loss: 0.0015881
[Epoch 2; Iter  2317/ 2483] train: loss: 0.0016702
[Epoch 2; Iter  2347/ 2483] train: loss: 0.0017680
[Epoch 2; Iter  2377/ 2483] train: loss: 0.0026903
[Epoch 2; Iter  2407/ 2483] train: loss: 0.0022244
[Epoch 2; Iter  2437/ 2483] train: loss: 0.0021416
[Epoch 2; Iter  2467/ 2483] train: loss: 0.0063114
[Epoch 2] ogbg-molmuv: 0.064727 val loss: 0.011810
[Epoch 2] ogbg-molmuv: 0.011611 test loss: 0.015866
[Epoch 3; Iter    14/ 2483] train: loss: 0.0027330
[Epoch 3; Iter    44/ 2483] train: loss: 0.0030379
[Epoch 3; Iter    74/ 2483] train: loss: 0.0021495
[Epoch 3; Iter   104/ 2483] train: loss: 0.0577422
[Epoch 3; Iter   134/ 2483] train: loss: 0.0691997
[Epoch 3; Iter   164/ 2483] train: loss: 0.0018211
[Epoch 3; Iter   194/ 2483] train: loss: 0.0021248
[Epoch 3; Iter   224/ 2483] train: loss: 0.0023219
[Epoch 3; Iter   254/ 2483] train: loss: 0.0022498
[Epoch 3; Iter   284/ 2483] train: loss: 0.0024034
[Epoch 3; Iter   314/ 2483] train: loss: 0.0018661
[Epoch 3; Iter   344/ 2483] train: loss: 0.0024283
[Epoch 3; Iter   374/ 2483] train: loss: 0.0016998
[Epoch 3; Iter   404/ 2483] train: loss: 0.0015543
[Epoch 3; Iter   434/ 2483] train: loss: 0.0021045
[Epoch 3; Iter   464/ 2483] train: loss: 0.0727340
[Epoch 3; Iter   494/ 2483] train: loss: 0.0017813
[Epoch 3; Iter   524/ 2483] train: loss: 0.0021271
[Epoch 3; Iter   554/ 2483] train: loss: 0.0018022
[Epoch 3; Iter   584/ 2483] train: loss: 0.0958458
[Epoch 3; Iter   614/ 2483] train: loss: 0.0016870
[Epoch 3; Iter   644/ 2483] train: loss: 0.0015448
[Epoch 3; Iter   674/ 2483] train: loss: 0.0015542
[Epoch 3; Iter   704/ 2483] train: loss: 0.0017074
[Epoch 3; Iter   734/ 2483] train: loss: 0.0015314
[Epoch 3; Iter   764/ 2483] train: loss: 0.0019945
[Epoch 3; Iter   794/ 2483] train: loss: 0.0014782
[Epoch 3; Iter   824/ 2483] train: loss: 0.0015615
[Epoch 3; Iter   854/ 2483] train: loss: 0.0891571
[Epoch 3; Iter   884/ 2483] train: loss: 0.0024960
[Epoch 3; Iter   914/ 2483] train: loss: 0.0017898
[Epoch 3; Iter   944/ 2483] train: loss: 0.0024738
[Epoch 3; Iter   974/ 2483] train: loss: 0.0885995
[Epoch 3; Iter  1004/ 2483] train: loss: 0.0022554
[Epoch 3; Iter  1034/ 2483] train: loss: 0.0706510
[Epoch 3; Iter  1064/ 2483] train: loss: 0.0024944
[Epoch 3; Iter  1094/ 2483] train: loss: 0.0021786
[Epoch 3; Iter  1124/ 2483] train: loss: 0.0018283
[Epoch 3; Iter  1154/ 2483] train: loss: 0.0835737
[Epoch 3; Iter  1184/ 2483] train: loss: 0.0743417
[Epoch 3; Iter  1214/ 2483] train: loss: 0.0016539
[Epoch 3; Iter  1244/ 2483] train: loss: 0.0018946
[Epoch 3; Iter  1274/ 2483] train: loss: 0.0016971
[Epoch 3; Iter  1304/ 2483] train: loss: 0.0014170
[Epoch 3; Iter  1334/ 2483] train: loss: 0.0011883
[Epoch 3; Iter  1364/ 2483] train: loss: 0.0013730
[Epoch 3; Iter  1394/ 2483] train: loss: 0.0016565
[Epoch 3; Iter  1424/ 2483] train: loss: 0.0959098
[Epoch 3; Iter  1454/ 2483] train: loss: 0.0930752
[Epoch 3; Iter  1484/ 2483] train: loss: 0.0014291
[Epoch 3; Iter  1514/ 2483] train: loss: 0.0014802
[Epoch 3; Iter  1544/ 2483] train: loss: 0.0032912
[Epoch 3; Iter  1574/ 2483] train: loss: 0.1468204
[Epoch 3; Iter  1604/ 2483] train: loss: 0.0023146
[Epoch 3; Iter  1634/ 2483] train: loss: 0.0018444
[Epoch 3; Iter  1664/ 2483] train: loss: 0.0540948
[Epoch 3; Iter  1694/ 2483] train: loss: 0.0020997
[Epoch 3; Iter  1724/ 2483] train: loss: 0.0017885
[Epoch 3; Iter  1754/ 2483] train: loss: 0.0016361
[Epoch 3; Iter  1784/ 2483] train: loss: 0.0818966
[Epoch 3; Iter  1814/ 2483] train: loss: 0.0024584
[Epoch 3; Iter  1844/ 2483] train: loss: 0.0529622
[Epoch 3; Iter  1874/ 2483] train: loss: 0.0021813
[Epoch 3; Iter  1904/ 2483] train: loss: 0.0022716
[Epoch 3; Iter  1934/ 2483] train: loss: 0.0021759
[Epoch 3; Iter  1964/ 2483] train: loss: 0.0030976
[Epoch 3; Iter  1994/ 2483] train: loss: 0.0022593
[Epoch 3; Iter  2024/ 2483] train: loss: 0.0021747
[Epoch 3; Iter  2054/ 2483] train: loss: 0.0020416
[Epoch 3; Iter  2084/ 2483] train: loss: 0.0020185
[Epoch 3; Iter  2114/ 2483] train: loss: 0.2100341
[Epoch 3; Iter  2144/ 2483] train: loss: 0.0021102
[Epoch 3; Iter  2174/ 2483] train: loss: 0.0027558
[Epoch 3; Iter  2204/ 2483] train: loss: 0.0025148
[Epoch 3; Iter  2234/ 2483] train: loss: 0.0020945
[Epoch 3; Iter  2264/ 2483] train: loss: 0.0019726
[Epoch 3; Iter  2294/ 2483] train: loss: 0.0835963
[Epoch 3; Iter  2324/ 2483] train: loss: 0.0019774
[Epoch 3; Iter  2354/ 2483] train: loss: 0.0933122
[Epoch 3; Iter  2384/ 2483] train: loss: 0.0021499
[Epoch 3; Iter  2414/ 2483] train: loss: 0.0673311
[Epoch 3; Iter  2444/ 2483] train: loss: 0.0017336
[Epoch 3; Iter  2474/ 2483] train: loss: 0.0019333
[Epoch 3] ogbg-molmuv: 0.014793 val loss: 0.010482
[Epoch 3] ogbg-molmuv: 0.027075 test loss: 0.015228
[Epoch 4; Iter    21/ 2483] train: loss: 0.0678565
[Epoch 4; Iter    51/ 2483] train: loss: 0.0016995
[Epoch 4; Iter    81/ 2483] train: loss: 0.0020613
[Epoch 4; Iter   111/ 2483] train: loss: 0.0778036
[Epoch 4; Iter   141/ 2483] train: loss: 0.0682917
[Epoch 4; Iter   171/ 2483] train: loss: 0.0018735
[Epoch 4; Iter   201/ 2483] train: loss: 0.0018039
[Epoch 4; Iter   231/ 2483] train: loss: 0.0015231
[Epoch 4; Iter   261/ 2483] train: loss: 0.0721315
[Epoch 4; Iter   291/ 2483] train: loss: 0.0019731
[Epoch 4; Iter   321/ 2483] train: loss: 0.0015165
[Epoch 4; Iter   351/ 2483] train: loss: 0.0016456
[Epoch 4; Iter   381/ 2483] train: loss: 0.0018370
[Epoch 4; Iter   411/ 2483] train: loss: 0.0019478
[Epoch 4; Iter   441/ 2483] train: loss: 0.0016278
[Epoch 2; Iter   757/ 2483] train: loss: 0.0018710
[Epoch 2; Iter   787/ 2483] train: loss: 0.1187084
[Epoch 2; Iter   817/ 2483] train: loss: 0.0020792
[Epoch 2; Iter   847/ 2483] train: loss: 0.0021707
[Epoch 2; Iter   877/ 2483] train: loss: 0.0816441
[Epoch 2; Iter   907/ 2483] train: loss: 0.0017687
[Epoch 2; Iter   937/ 2483] train: loss: 0.0020221
[Epoch 2; Iter   967/ 2483] train: loss: 0.0019655
[Epoch 2; Iter   997/ 2483] train: loss: 0.0016760
[Epoch 2; Iter  1027/ 2483] train: loss: 0.0586427
[Epoch 2; Iter  1057/ 2483] train: loss: 0.0018486
[Epoch 2; Iter  1087/ 2483] train: loss: 0.0019138
[Epoch 2; Iter  1117/ 2483] train: loss: 0.0019205
[Epoch 2; Iter  1147/ 2483] train: loss: 0.0017931
[Epoch 2; Iter  1177/ 2483] train: loss: 0.0013038
[Epoch 2; Iter  1207/ 2483] train: loss: 0.0016694
[Epoch 2; Iter  1237/ 2483] train: loss: 0.0018139
[Epoch 2; Iter  1267/ 2483] train: loss: 0.0015624
[Epoch 2; Iter  1297/ 2483] train: loss: 0.0015733
[Epoch 2; Iter  1327/ 2483] train: loss: 0.0837903
[Epoch 2; Iter  1357/ 2483] train: loss: 0.0800591
[Epoch 2; Iter  1387/ 2483] train: loss: 0.0022299
[Epoch 2; Iter  1417/ 2483] train: loss: 0.0017694
[Epoch 2; Iter  1447/ 2483] train: loss: 0.0015549
[Epoch 2; Iter  1477/ 2483] train: loss: 0.0743585
[Epoch 2; Iter  1507/ 2483] train: loss: 0.0020576
[Epoch 2; Iter  1537/ 2483] train: loss: 0.0015856
[Epoch 2; Iter  1567/ 2483] train: loss: 0.0023353
[Epoch 2; Iter  1597/ 2483] train: loss: 0.0015651
[Epoch 2; Iter  1627/ 2483] train: loss: 0.0622171
[Epoch 2; Iter  1657/ 2483] train: loss: 0.0023585
[Epoch 2; Iter  1687/ 2483] train: loss: 0.0019455
[Epoch 2; Iter  1717/ 2483] train: loss: 0.0648625
[Epoch 2; Iter  1747/ 2483] train: loss: 0.0023303
[Epoch 2; Iter  1777/ 2483] train: loss: 0.0022842
[Epoch 2; Iter  1807/ 2483] train: loss: 0.0015995
[Epoch 2; Iter  1837/ 2483] train: loss: 0.0906793
[Epoch 2; Iter  1867/ 2483] train: loss: 0.0030232
[Epoch 2; Iter  1897/ 2483] train: loss: 0.0026845
[Epoch 2; Iter  1927/ 2483] train: loss: 0.0020246
[Epoch 2; Iter  1957/ 2483] train: loss: 0.0022722
[Epoch 2; Iter  1987/ 2483] train: loss: 0.0023888
[Epoch 2; Iter  2017/ 2483] train: loss: 0.0023525
[Epoch 2; Iter  2047/ 2483] train: loss: 0.0022540
[Epoch 2; Iter  2077/ 2483] train: loss: 0.0019724
[Epoch 2; Iter  2107/ 2483] train: loss: 0.0022324
[Epoch 2; Iter  2137/ 2483] train: loss: 0.0022428
[Epoch 2; Iter  2167/ 2483] train: loss: 0.0019814
[Epoch 2; Iter  2197/ 2483] train: loss: 0.0024861
[Epoch 2; Iter  2227/ 2483] train: loss: 0.0020092
[Epoch 2; Iter  2257/ 2483] train: loss: 0.0021497
[Epoch 2; Iter  2287/ 2483] train: loss: 0.0030069
[Epoch 2; Iter  2317/ 2483] train: loss: 0.0018370
[Epoch 2; Iter  2347/ 2483] train: loss: 0.0018370
[Epoch 2; Iter  2377/ 2483] train: loss: 0.0018731
[Epoch 2; Iter  2407/ 2483] train: loss: 0.0023450
[Epoch 2; Iter  2437/ 2483] train: loss: 0.0019821
[Epoch 2; Iter  2467/ 2483] train: loss: 0.0016436
[Epoch 2] ogbg-molmuv: 0.016561 val loss: 0.010830
[Epoch 2] ogbg-molmuv: 0.009841 test loss: 0.021690
[Epoch 3; Iter    14/ 2483] train: loss: 0.0015763
[Epoch 3; Iter    44/ 2483] train: loss: 0.0481402
[Epoch 3; Iter    74/ 2483] train: loss: 0.0022144
[Epoch 3; Iter   104/ 2483] train: loss: 0.0043926
[Epoch 3; Iter   134/ 2483] train: loss: 0.0019557
[Epoch 3; Iter   164/ 2483] train: loss: 0.0015276
[Epoch 3; Iter   194/ 2483] train: loss: 0.0013545
[Epoch 3; Iter   224/ 2483] train: loss: 0.1028341
[Epoch 3; Iter   254/ 2483] train: loss: 0.0772697
[Epoch 3; Iter   284/ 2483] train: loss: 0.0018760
[Epoch 3; Iter   314/ 2483] train: loss: 0.0015455
[Epoch 3; Iter   344/ 2483] train: loss: 0.2739705
[Epoch 3; Iter   374/ 2483] train: loss: 0.0016249
[Epoch 3; Iter   404/ 2483] train: loss: 0.0017294
[Epoch 3; Iter   434/ 2483] train: loss: 0.0014218
[Epoch 3; Iter   464/ 2483] train: loss: 0.0021740
[Epoch 3; Iter   494/ 2483] train: loss: 0.0023808
[Epoch 3; Iter   524/ 2483] train: loss: 0.0021494
[Epoch 3; Iter   554/ 2483] train: loss: 0.0014366
[Epoch 3; Iter   584/ 2483] train: loss: 0.0850882
[Epoch 3; Iter   614/ 2483] train: loss: 0.0015391
[Epoch 3; Iter   644/ 2483] train: loss: 0.0018528
[Epoch 3; Iter   674/ 2483] train: loss: 0.0017939
[Epoch 3; Iter   704/ 2483] train: loss: 0.0025121
[Epoch 3; Iter   734/ 2483] train: loss: 0.0021686
[Epoch 3; Iter   764/ 2483] train: loss: 0.0838465
[Epoch 3; Iter   794/ 2483] train: loss: 0.0024153
[Epoch 3; Iter   824/ 2483] train: loss: 0.0015533
[Epoch 3; Iter   854/ 2483] train: loss: 0.0016155
[Epoch 3; Iter   884/ 2483] train: loss: 0.0018460
[Epoch 3; Iter   914/ 2483] train: loss: 0.0014388
[Epoch 3; Iter   944/ 2483] train: loss: 0.0015671
[Epoch 3; Iter   974/ 2483] train: loss: 0.0012635
[Epoch 3; Iter  1004/ 2483] train: loss: 0.0019786
[Epoch 3; Iter  1034/ 2483] train: loss: 0.0023221
[Epoch 3; Iter  1064/ 2483] train: loss: 0.0016487
[Epoch 3; Iter  1094/ 2483] train: loss: 0.0019678
[Epoch 3; Iter  1124/ 2483] train: loss: 0.0022985
[Epoch 3; Iter  1154/ 2483] train: loss: 0.0016885
[Epoch 3; Iter  1184/ 2483] train: loss: 0.0019549
[Epoch 3; Iter  1214/ 2483] train: loss: 0.0023331
[Epoch 3; Iter  1244/ 2483] train: loss: 0.1764507
[Epoch 3; Iter  1274/ 2483] train: loss: 0.0970589
[Epoch 3; Iter  1304/ 2483] train: loss: 0.0020507
[Epoch 3; Iter  1334/ 2483] train: loss: 0.0028374
[Epoch 3; Iter  1364/ 2483] train: loss: 0.0019028
[Epoch 3; Iter  1394/ 2483] train: loss: 0.0020562
[Epoch 3; Iter  1424/ 2483] train: loss: 0.0016643
[Epoch 3; Iter  1454/ 2483] train: loss: 0.0031997
[Epoch 3; Iter  1484/ 2483] train: loss: 0.0753415
[Epoch 3; Iter  1514/ 2483] train: loss: 0.0024943
[Epoch 3; Iter  1544/ 2483] train: loss: 0.0017595
[Epoch 3; Iter  1574/ 2483] train: loss: 0.0034129
[Epoch 3; Iter  1604/ 2483] train: loss: 0.0023896
[Epoch 3; Iter  1634/ 2483] train: loss: 0.0021577
[Epoch 3; Iter  1664/ 2483] train: loss: 0.0020144
[Epoch 3; Iter  1694/ 2483] train: loss: 0.0030889
[Epoch 3; Iter  1724/ 2483] train: loss: 0.0017844
[Epoch 3; Iter  1754/ 2483] train: loss: 0.0018149
[Epoch 3; Iter  1784/ 2483] train: loss: 0.0017537
[Epoch 3; Iter  1814/ 2483] train: loss: 0.0015127
[Epoch 3; Iter  1844/ 2483] train: loss: 0.0030135
[Epoch 3; Iter  1874/ 2483] train: loss: 0.0020206
[Epoch 3; Iter  1904/ 2483] train: loss: 0.0021562
[Epoch 3; Iter  1934/ 2483] train: loss: 0.0021714
[Epoch 3; Iter  1964/ 2483] train: loss: 0.0027279
[Epoch 3; Iter  1994/ 2483] train: loss: 0.0730127
[Epoch 3; Iter  2024/ 2483] train: loss: 0.0018372
[Epoch 3; Iter  2054/ 2483] train: loss: 0.0021363
[Epoch 3; Iter  2084/ 2483] train: loss: 0.0023146
[Epoch 3; Iter  2114/ 2483] train: loss: 0.0021758
[Epoch 3; Iter  2144/ 2483] train: loss: 0.0021702
[Epoch 3; Iter  2174/ 2483] train: loss: 0.0022835
[Epoch 3; Iter  2204/ 2483] train: loss: 0.0016726
[Epoch 3; Iter  2234/ 2483] train: loss: 0.0022461
[Epoch 3; Iter  2264/ 2483] train: loss: 0.0657130
[Epoch 3; Iter  2294/ 2483] train: loss: 0.0035962
[Epoch 3; Iter  2324/ 2483] train: loss: 0.0861547
[Epoch 3; Iter  2354/ 2483] train: loss: 0.0027834
[Epoch 3; Iter  2384/ 2483] train: loss: 0.0020840
[Epoch 3; Iter  2414/ 2483] train: loss: 0.0019998
[Epoch 3; Iter  2444/ 2483] train: loss: 0.0020483
[Epoch 3; Iter  2474/ 2483] train: loss: 0.0020812
[Epoch 3] ogbg-molmuv: 0.038332 val loss: 0.011767
[Epoch 3] ogbg-molmuv: 0.013986 test loss: 0.015311
[Epoch 4; Iter    21/ 2483] train: loss: 0.0016096
[Epoch 4; Iter    51/ 2483] train: loss: 0.0017057
[Epoch 4; Iter    81/ 2483] train: loss: 0.0017930
[Epoch 4; Iter   111/ 2483] train: loss: 0.0017848
[Epoch 4; Iter   141/ 2483] train: loss: 0.0642406
[Epoch 4; Iter   171/ 2483] train: loss: 0.0017149
[Epoch 4; Iter   201/ 2483] train: loss: 0.0022001
[Epoch 4; Iter   231/ 2483] train: loss: 0.0020198
[Epoch 4; Iter   261/ 2483] train: loss: 0.0017842
[Epoch 4; Iter   291/ 2483] train: loss: 0.0019488
[Epoch 4; Iter   321/ 2483] train: loss: 0.0025274
[Epoch 4; Iter   351/ 2483] train: loss: 0.0022045
[Epoch 4; Iter   381/ 2483] train: loss: 0.0016608
[Epoch 4; Iter   411/ 2483] train: loss: 0.0015548
[Epoch 4; Iter   441/ 2483] train: loss: 0.0956436
[Epoch 2; Iter  1068/ 2172] train: loss: 0.0031387
[Epoch 2; Iter  1098/ 2172] train: loss: 0.0023789
[Epoch 2; Iter  1128/ 2172] train: loss: 0.0024678
[Epoch 2; Iter  1158/ 2172] train: loss: 0.0019895
[Epoch 2; Iter  1188/ 2172] train: loss: 0.0019848
[Epoch 2; Iter  1218/ 2172] train: loss: 0.0871504
[Epoch 2; Iter  1248/ 2172] train: loss: 0.0024681
[Epoch 2; Iter  1278/ 2172] train: loss: 0.0021110
[Epoch 2; Iter  1308/ 2172] train: loss: 0.0021243
[Epoch 2; Iter  1338/ 2172] train: loss: 0.0020374
[Epoch 2; Iter  1368/ 2172] train: loss: 0.0024116
[Epoch 2; Iter  1398/ 2172] train: loss: 0.0023137
[Epoch 2; Iter  1428/ 2172] train: loss: 0.0025511
[Epoch 2; Iter  1458/ 2172] train: loss: 0.0019416
[Epoch 2; Iter  1488/ 2172] train: loss: 0.0015810
[Epoch 2; Iter  1518/ 2172] train: loss: 0.0017272
[Epoch 2; Iter  1548/ 2172] train: loss: 0.0018561
[Epoch 2; Iter  1578/ 2172] train: loss: 0.0014602
[Epoch 2; Iter  1608/ 2172] train: loss: 0.0018544
[Epoch 2; Iter  1638/ 2172] train: loss: 0.0575233
[Epoch 2; Iter  1668/ 2172] train: loss: 0.0018231
[Epoch 2; Iter  1698/ 2172] train: loss: 0.0778630
[Epoch 2; Iter  1728/ 2172] train: loss: 0.0456379
[Epoch 2; Iter  1758/ 2172] train: loss: 0.0017995
[Epoch 2; Iter  1788/ 2172] train: loss: 0.0017319
[Epoch 2; Iter  1818/ 2172] train: loss: 0.0016338
[Epoch 2; Iter  1848/ 2172] train: loss: 0.0034766
[Epoch 2; Iter  1878/ 2172] train: loss: 0.0018083
[Epoch 2; Iter  1908/ 2172] train: loss: 0.0017234
[Epoch 2; Iter  1938/ 2172] train: loss: 0.0018868
[Epoch 2; Iter  1968/ 2172] train: loss: 0.0659805
[Epoch 2; Iter  1998/ 2172] train: loss: 0.0023518
[Epoch 2; Iter  2028/ 2172] train: loss: 0.0023488
[Epoch 2; Iter  2058/ 2172] train: loss: 0.0018640
[Epoch 2; Iter  2088/ 2172] train: loss: 0.0016215
[Epoch 2; Iter  2118/ 2172] train: loss: 0.0014801
[Epoch 2; Iter  2148/ 2172] train: loss: 0.0016889
[Epoch 2] ogbg-molmuv: 0.014141 val loss: 0.012258
[Epoch 2] ogbg-molmuv: 0.007561 test loss: 0.013954
[Epoch 3; Iter     6/ 2172] train: loss: 0.0017982
[Epoch 3; Iter    36/ 2172] train: loss: 0.0019074
[Epoch 3; Iter    66/ 2172] train: loss: 0.0017419
[Epoch 3; Iter    96/ 2172] train: loss: 0.0016715
[Epoch 3; Iter   126/ 2172] train: loss: 0.0015814
[Epoch 3; Iter   156/ 2172] train: loss: 0.0020067
[Epoch 3; Iter   186/ 2172] train: loss: 0.0017816
[Epoch 3; Iter   216/ 2172] train: loss: 0.0014715
[Epoch 3; Iter   246/ 2172] train: loss: 0.0013557
[Epoch 3; Iter   276/ 2172] train: loss: 0.0901754
[Epoch 3; Iter   306/ 2172] train: loss: 0.0696761
[Epoch 3; Iter   336/ 2172] train: loss: 0.0558726
[Epoch 3; Iter   366/ 2172] train: loss: 0.0019225
[Epoch 3; Iter   396/ 2172] train: loss: 0.0024225
[Epoch 3; Iter   426/ 2172] train: loss: 0.0687936
[Epoch 3; Iter   456/ 2172] train: loss: 0.0026777
[Epoch 3; Iter   486/ 2172] train: loss: 0.0023610
[Epoch 3; Iter   516/ 2172] train: loss: 0.0017085
[Epoch 3; Iter   546/ 2172] train: loss: 0.0017402
[Epoch 3; Iter   576/ 2172] train: loss: 0.0023124
[Epoch 3; Iter   606/ 2172] train: loss: 0.0019100
[Epoch 3; Iter   636/ 2172] train: loss: 0.0017263
[Epoch 3; Iter   666/ 2172] train: loss: 0.0015387
[Epoch 3; Iter   696/ 2172] train: loss: 0.0021655
[Epoch 3; Iter   726/ 2172] train: loss: 0.0014794
[Epoch 3; Iter   756/ 2172] train: loss: 0.0017325
[Epoch 3; Iter   786/ 2172] train: loss: 0.0022799
[Epoch 3; Iter   816/ 2172] train: loss: 0.0015350
[Epoch 3; Iter   846/ 2172] train: loss: 0.0016722
[Epoch 3; Iter   876/ 2172] train: loss: 0.0016287
[Epoch 3; Iter   906/ 2172] train: loss: 0.0014922
[Epoch 3; Iter   936/ 2172] train: loss: 0.0025809
[Epoch 3; Iter   966/ 2172] train: loss: 0.0018106
[Epoch 3; Iter   996/ 2172] train: loss: 0.0019441
[Epoch 3; Iter  1026/ 2172] train: loss: 0.0018662
[Epoch 3; Iter  1056/ 2172] train: loss: 0.0021007
[Epoch 3; Iter  1086/ 2172] train: loss: 0.0018234
[Epoch 3; Iter  1116/ 2172] train: loss: 0.0021529
[Epoch 3; Iter  1146/ 2172] train: loss: 0.0773007
[Epoch 3; Iter  1176/ 2172] train: loss: 0.0016839
[Epoch 3; Iter  1206/ 2172] train: loss: 0.0017151
[Epoch 3; Iter  1236/ 2172] train: loss: 0.0847768
[Epoch 3; Iter  1266/ 2172] train: loss: 0.0022060
[Epoch 3; Iter  1296/ 2172] train: loss: 0.0023079
[Epoch 3; Iter  1326/ 2172] train: loss: 0.0867756
[Epoch 3; Iter  1356/ 2172] train: loss: 0.1379256
[Epoch 3; Iter  1386/ 2172] train: loss: 0.0018947
[Epoch 3; Iter  1416/ 2172] train: loss: 0.0900199
[Epoch 3; Iter  1446/ 2172] train: loss: 0.0019652
[Epoch 3; Iter  1476/ 2172] train: loss: 0.0015946
[Epoch 3; Iter  1506/ 2172] train: loss: 0.0572698
[Epoch 3; Iter  1536/ 2172] train: loss: 0.0022188
[Epoch 3; Iter  1566/ 2172] train: loss: 0.0025745
[Epoch 3; Iter  1596/ 2172] train: loss: 0.0028620
[Epoch 3; Iter  1626/ 2172] train: loss: 0.0022874
[Epoch 3; Iter  1656/ 2172] train: loss: 0.0016540
[Epoch 3; Iter  1686/ 2172] train: loss: 0.0021362
[Epoch 3; Iter  1716/ 2172] train: loss: 0.0036060
[Epoch 3; Iter  1746/ 2172] train: loss: 0.0016369
[Epoch 3; Iter  1776/ 2172] train: loss: 0.0017677
[Epoch 3; Iter  1806/ 2172] train: loss: 0.0026146
[Epoch 3; Iter  1836/ 2172] train: loss: 0.0017646
[Epoch 3; Iter  1866/ 2172] train: loss: 0.0017327
[Epoch 3; Iter  1896/ 2172] train: loss: 0.0021758
[Epoch 3; Iter  1926/ 2172] train: loss: 0.0016790
[Epoch 3; Iter  1956/ 2172] train: loss: 0.0469569
[Epoch 3; Iter  1986/ 2172] train: loss: 0.0021798
[Epoch 3; Iter  2016/ 2172] train: loss: 0.0021361
[Epoch 3; Iter  2046/ 2172] train: loss: 0.0019028
[Epoch 3; Iter  2076/ 2172] train: loss: 0.1365441
[Epoch 3; Iter  2106/ 2172] train: loss: 0.0021716
[Epoch 3; Iter  2136/ 2172] train: loss: 0.0019366
[Epoch 3; Iter  2166/ 2172] train: loss: 0.0021727
[Epoch 3] ogbg-molmuv: 0.010252 val loss: 0.014284
[Epoch 3] ogbg-molmuv: 0.014351 test loss: 0.014909
[Epoch 4; Iter    24/ 2172] train: loss: 0.0023585
[Epoch 4; Iter    54/ 2172] train: loss: 0.0028890
[Epoch 4; Iter    84/ 2172] train: loss: 0.0895366
[Epoch 4; Iter   114/ 2172] train: loss: 0.0022467
[Epoch 4; Iter   144/ 2172] train: loss: 0.0023292
[Epoch 4; Iter   174/ 2172] train: loss: 0.0017976
[Epoch 4; Iter   204/ 2172] train: loss: 0.0022583
[Epoch 4; Iter   234/ 2172] train: loss: 0.0022661
[Epoch 4; Iter   264/ 2172] train: loss: 0.0019813
[Epoch 4; Iter   294/ 2172] train: loss: 0.0015533
[Epoch 4; Iter   324/ 2172] train: loss: 0.0015823
[Epoch 4; Iter   354/ 2172] train: loss: 0.0016818
[Epoch 4; Iter   384/ 2172] train: loss: 0.0016904
[Epoch 4; Iter   414/ 2172] train: loss: 0.0013142
[Epoch 4; Iter   444/ 2172] train: loss: 0.0014065
[Epoch 4; Iter   474/ 2172] train: loss: 0.0015806
[Epoch 4; Iter   504/ 2172] train: loss: 0.0690917
[Epoch 4; Iter   534/ 2172] train: loss: 0.0829721
[Epoch 4; Iter   564/ 2172] train: loss: 0.0019374
[Epoch 4; Iter   594/ 2172] train: loss: 0.0022942
[Epoch 4; Iter   624/ 2172] train: loss: 0.0022512
[Epoch 4; Iter   654/ 2172] train: loss: 0.0868626
[Epoch 4; Iter   684/ 2172] train: loss: 0.0017676
[Epoch 4; Iter   714/ 2172] train: loss: 0.0014191
[Epoch 4; Iter   744/ 2172] train: loss: 0.0015843
[Epoch 4; Iter   774/ 2172] train: loss: 0.1224839
[Epoch 4; Iter   804/ 2172] train: loss: 0.0017827
[Epoch 4; Iter   834/ 2172] train: loss: 0.0018567
[Epoch 4; Iter   864/ 2172] train: loss: 0.0017689
[Epoch 4; Iter   894/ 2172] train: loss: 0.0019108
[Epoch 4; Iter   924/ 2172] train: loss: 0.0021705
[Epoch 4; Iter   954/ 2172] train: loss: 0.0020818
[Epoch 4; Iter   984/ 2172] train: loss: 0.0020759
[Epoch 4; Iter  1014/ 2172] train: loss: 0.0017064
[Epoch 4; Iter  1044/ 2172] train: loss: 0.0019595
[Epoch 4; Iter  1074/ 2172] train: loss: 0.0052726
[Epoch 4; Iter  1104/ 2172] train: loss: 0.0020187
[Epoch 4; Iter  1134/ 2172] train: loss: 0.0803776
[Epoch 4; Iter  1164/ 2172] train: loss: 0.0014046
[Epoch 4; Iter  1194/ 2172] train: loss: 0.0013645
[Epoch 4; Iter  1224/ 2172] train: loss: 0.0014445
[Epoch 4; Iter  1254/ 2172] train: loss: 0.0024186
[Epoch 4; Iter  1284/ 2172] train: loss: 0.0790163
[Epoch 4; Iter  1314/ 2172] train: loss: 0.0033108
[Epoch 4; Iter  1344/ 2172] train: loss: 0.0942296
[Epoch 4; Iter  1374/ 2172] train: loss: 0.0021219
[Epoch 2; Iter  1068/ 2172] train: loss: 0.0773602
[Epoch 2; Iter  1098/ 2172] train: loss: 0.0019862
[Epoch 2; Iter  1128/ 2172] train: loss: 0.0023819
[Epoch 2; Iter  1158/ 2172] train: loss: 0.0020081
[Epoch 2; Iter  1188/ 2172] train: loss: 0.0026816
[Epoch 2; Iter  1218/ 2172] train: loss: 0.0018629
[Epoch 2; Iter  1248/ 2172] train: loss: 0.0637766
[Epoch 2; Iter  1278/ 2172] train: loss: 0.0027181
[Epoch 2; Iter  1308/ 2172] train: loss: 0.0022263
[Epoch 2; Iter  1338/ 2172] train: loss: 0.0023186
[Epoch 2; Iter  1368/ 2172] train: loss: 0.1836578
[Epoch 2; Iter  1398/ 2172] train: loss: 0.0021313
[Epoch 2; Iter  1428/ 2172] train: loss: 0.0018693
[Epoch 2; Iter  1458/ 2172] train: loss: 0.0017807
[Epoch 2; Iter  1488/ 2172] train: loss: 0.0019918
[Epoch 2; Iter  1518/ 2172] train: loss: 0.0019175
[Epoch 2; Iter  1548/ 2172] train: loss: 0.0024373
[Epoch 2; Iter  1578/ 2172] train: loss: 0.0667956
[Epoch 2; Iter  1608/ 2172] train: loss: 0.0024158
[Epoch 2; Iter  1638/ 2172] train: loss: 0.0019954
[Epoch 2; Iter  1668/ 2172] train: loss: 0.0019412
[Epoch 2; Iter  1698/ 2172] train: loss: 0.0812927
[Epoch 2; Iter  1728/ 2172] train: loss: 0.0995361
[Epoch 2; Iter  1758/ 2172] train: loss: 0.0016762
[Epoch 2; Iter  1788/ 2172] train: loss: 0.0016799
[Epoch 2; Iter  1818/ 2172] train: loss: 0.0018889
[Epoch 2; Iter  1848/ 2172] train: loss: 0.0017627
[Epoch 2; Iter  1878/ 2172] train: loss: 0.0020640
[Epoch 2; Iter  1908/ 2172] train: loss: 0.0021410
[Epoch 2; Iter  1938/ 2172] train: loss: 0.0016717
[Epoch 2; Iter  1968/ 2172] train: loss: 0.0911594
[Epoch 2; Iter  1998/ 2172] train: loss: 0.0018430
[Epoch 2; Iter  2028/ 2172] train: loss: 0.0844820
[Epoch 2; Iter  2058/ 2172] train: loss: 0.0018329
[Epoch 2; Iter  2088/ 2172] train: loss: 0.0017114
[Epoch 2; Iter  2118/ 2172] train: loss: 0.0017365
[Epoch 2; Iter  2148/ 2172] train: loss: 0.0680824
[Epoch 2] ogbg-molmuv: 0.022398 val loss: 0.012114
[Epoch 2] ogbg-molmuv: 0.010475 test loss: 0.014389
[Epoch 3; Iter     6/ 2172] train: loss: 0.0651067
[Epoch 3; Iter    36/ 2172] train: loss: 0.0015670
[Epoch 3; Iter    66/ 2172] train: loss: 0.0018141
[Epoch 3; Iter    96/ 2172] train: loss: 0.0024981
[Epoch 3; Iter   126/ 2172] train: loss: 0.0030213
[Epoch 3; Iter   156/ 2172] train: loss: 0.0028063
[Epoch 3; Iter   186/ 2172] train: loss: 0.0018390
[Epoch 3; Iter   216/ 2172] train: loss: 0.0019780
[Epoch 3; Iter   246/ 2172] train: loss: 0.0015935
[Epoch 3; Iter   276/ 2172] train: loss: 0.0016972
[Epoch 3; Iter   306/ 2172] train: loss: 0.0018283
[Epoch 3; Iter   336/ 2172] train: loss: 0.0925808
[Epoch 3; Iter   366/ 2172] train: loss: 0.0017351
[Epoch 3; Iter   396/ 2172] train: loss: 0.0019501
[Epoch 3; Iter   426/ 2172] train: loss: 0.0018906
[Epoch 3; Iter   456/ 2172] train: loss: 0.0025482
[Epoch 3; Iter   486/ 2172] train: loss: 0.0737010
[Epoch 3; Iter   516/ 2172] train: loss: 0.0030456
[Epoch 3; Iter   546/ 2172] train: loss: 0.0026422
[Epoch 3; Iter   576/ 2172] train: loss: 0.0022816
[Epoch 3; Iter   606/ 2172] train: loss: 0.0701829
[Epoch 3; Iter   636/ 2172] train: loss: 0.0017818
[Epoch 3; Iter   666/ 2172] train: loss: 0.0018003
[Epoch 3; Iter   696/ 2172] train: loss: 0.0890540
[Epoch 3; Iter   726/ 2172] train: loss: 0.0021355
[Epoch 3; Iter   756/ 2172] train: loss: 0.0020984
[Epoch 3; Iter   786/ 2172] train: loss: 0.0017436
[Epoch 3; Iter   816/ 2172] train: loss: 0.0017565
[Epoch 3; Iter   846/ 2172] train: loss: 0.0016997
[Epoch 3; Iter   876/ 2172] train: loss: 0.0019847
[Epoch 3; Iter   906/ 2172] train: loss: 0.0015810
[Epoch 3; Iter   936/ 2172] train: loss: 0.0020703
[Epoch 3; Iter   966/ 2172] train: loss: 0.0028047
[Epoch 3; Iter   996/ 2172] train: loss: 0.0041018
[Epoch 3; Iter  1026/ 2172] train: loss: 0.0023680
[Epoch 3; Iter  1056/ 2172] train: loss: 0.0024238
[Epoch 3; Iter  1086/ 2172] train: loss: 0.0817619
[Epoch 3; Iter  1116/ 2172] train: loss: 0.0632058
[Epoch 3; Iter  1146/ 2172] train: loss: 0.0020958
[Epoch 3; Iter  1176/ 2172] train: loss: 0.0758119
[Epoch 3; Iter  1206/ 2172] train: loss: 0.0021572
[Epoch 3; Iter  1236/ 2172] train: loss: 0.0018480
[Epoch 3; Iter  1266/ 2172] train: loss: 0.0021035
[Epoch 3; Iter  1296/ 2172] train: loss: 0.0013553
[Epoch 3; Iter  1326/ 2172] train: loss: 0.0019293
[Epoch 3; Iter  1356/ 2172] train: loss: 0.0021540
[Epoch 3; Iter  1386/ 2172] train: loss: 0.0038633
[Epoch 3; Iter  1416/ 2172] train: loss: 0.0017047
[Epoch 3; Iter  1446/ 2172] train: loss: 0.0020526
[Epoch 3; Iter  1476/ 2172] train: loss: 0.0018056
[Epoch 3; Iter  1506/ 2172] train: loss: 0.0018120
[Epoch 3; Iter  1536/ 2172] train: loss: 0.0016993
[Epoch 3; Iter  1566/ 2172] train: loss: 0.0021816
[Epoch 3; Iter  1596/ 2172] train: loss: 0.0014594
[Epoch 3; Iter  1626/ 2172] train: loss: 0.0018200
[Epoch 3; Iter  1656/ 2172] train: loss: 0.0015078
[Epoch 3; Iter  1686/ 2172] train: loss: 0.0019510
[Epoch 3; Iter  1716/ 2172] train: loss: 0.0015382
[Epoch 3; Iter  1746/ 2172] train: loss: 0.0016154
[Epoch 3; Iter  1776/ 2172] train: loss: 0.0016238
[Epoch 3; Iter  1806/ 2172] train: loss: 0.0020890
[Epoch 3; Iter  1836/ 2172] train: loss: 0.0021915
[Epoch 3; Iter  1866/ 2172] train: loss: 0.0032507
[Epoch 3; Iter  1896/ 2172] train: loss: 0.0036276
[Epoch 3; Iter  1926/ 2172] train: loss: 0.0028960
[Epoch 3; Iter  1956/ 2172] train: loss: 0.0019938
[Epoch 3; Iter  1986/ 2172] train: loss: 0.0019299
[Epoch 3; Iter  2016/ 2172] train: loss: 0.0014280
[Epoch 3; Iter  2046/ 2172] train: loss: 0.0015274
[Epoch 3; Iter  2076/ 2172] train: loss: 0.0020258
[Epoch 3; Iter  2106/ 2172] train: loss: 0.0014140
[Epoch 3; Iter  2136/ 2172] train: loss: 0.0013980
[Epoch 3; Iter  2166/ 2172] train: loss: 0.0016424
[Epoch 3] ogbg-molmuv: 0.019175 val loss: 0.012423
[Epoch 3] ogbg-molmuv: 0.007285 test loss: 0.017355
[Epoch 4; Iter    24/ 2172] train: loss: 0.0020299
[Epoch 4; Iter    54/ 2172] train: loss: 0.0016577
[Epoch 4; Iter    84/ 2172] train: loss: 0.0020280
[Epoch 4; Iter   114/ 2172] train: loss: 0.0030945
[Epoch 4; Iter   144/ 2172] train: loss: 0.0017673
[Epoch 4; Iter   174/ 2172] train: loss: 0.0022285
[Epoch 4; Iter   204/ 2172] train: loss: 0.0015031
[Epoch 4; Iter   234/ 2172] train: loss: 0.0027067
[Epoch 4; Iter   264/ 2172] train: loss: 0.0896179
[Epoch 4; Iter   294/ 2172] train: loss: 0.0017652
[Epoch 4; Iter   324/ 2172] train: loss: 0.0021107
[Epoch 4; Iter   354/ 2172] train: loss: 0.0011616
[Epoch 4; Iter   384/ 2172] train: loss: 0.0016424
[Epoch 4; Iter   414/ 2172] train: loss: 0.0020418
[Epoch 4; Iter   444/ 2172] train: loss: 0.0025059
[Epoch 4; Iter   474/ 2172] train: loss: 0.0016369
[Epoch 4; Iter   504/ 2172] train: loss: 0.0022491
[Epoch 4; Iter   534/ 2172] train: loss: 0.0015793
[Epoch 4; Iter   564/ 2172] train: loss: 0.0014447
[Epoch 4; Iter   594/ 2172] train: loss: 0.0020590
[Epoch 4; Iter   624/ 2172] train: loss: 0.0027207
[Epoch 4; Iter   654/ 2172] train: loss: 0.0023684
[Epoch 4; Iter   684/ 2172] train: loss: 0.0018315
[Epoch 4; Iter   714/ 2172] train: loss: 0.0716074
[Epoch 4; Iter   744/ 2172] train: loss: 0.0022517
[Epoch 4; Iter   774/ 2172] train: loss: 0.0020933
[Epoch 4; Iter   804/ 2172] train: loss: 0.0022870
[Epoch 4; Iter   834/ 2172] train: loss: 0.0026647
[Epoch 4; Iter   864/ 2172] train: loss: 0.0661879
[Epoch 4; Iter   894/ 2172] train: loss: 0.0023359
[Epoch 4; Iter   924/ 2172] train: loss: 0.0017508
[Epoch 4; Iter   954/ 2172] train: loss: 0.0018641
[Epoch 4; Iter   984/ 2172] train: loss: 0.0015689
[Epoch 4; Iter  1014/ 2172] train: loss: 0.0015211
[Epoch 4; Iter  1044/ 2172] train: loss: 0.0791363
[Epoch 4; Iter  1074/ 2172] train: loss: 0.0016862
[Epoch 4; Iter  1104/ 2172] train: loss: 0.0014500
[Epoch 4; Iter  1134/ 2172] train: loss: 0.0024447
[Epoch 4; Iter  1164/ 2172] train: loss: 0.0013986
[Epoch 4; Iter  1194/ 2172] train: loss: 0.0014325
[Epoch 4; Iter  1224/ 2172] train: loss: 0.0015922
[Epoch 4; Iter  1254/ 2172] train: loss: 0.0015971
[Epoch 4; Iter  1284/ 2172] train: loss: 0.0013500
[Epoch 4; Iter  1314/ 2172] train: loss: 0.0017226
[Epoch 4; Iter  1344/ 2172] train: loss: 0.0020187
[Epoch 4; Iter  1374/ 2172] train: loss: 0.0020725
[Epoch 2; Iter  1068/ 2172] train: loss: 0.0021299
[Epoch 2; Iter  1098/ 2172] train: loss: 0.0027542
[Epoch 2; Iter  1128/ 2172] train: loss: 0.0019847
[Epoch 2; Iter  1158/ 2172] train: loss: 0.0022194
[Epoch 2; Iter  1188/ 2172] train: loss: 0.0021423
[Epoch 2; Iter  1218/ 2172] train: loss: 0.0021176
[Epoch 2; Iter  1248/ 2172] train: loss: 0.0019365
[Epoch 2; Iter  1278/ 2172] train: loss: 0.0688269
[Epoch 2; Iter  1308/ 2172] train: loss: 0.0019722
[Epoch 2; Iter  1338/ 2172] train: loss: 0.0024016
[Epoch 2; Iter  1368/ 2172] train: loss: 0.0022054
[Epoch 2; Iter  1398/ 2172] train: loss: 0.0022366
[Epoch 2; Iter  1428/ 2172] train: loss: 0.0026606
[Epoch 2; Iter  1458/ 2172] train: loss: 0.1287269
[Epoch 2; Iter  1488/ 2172] train: loss: 0.0022328
[Epoch 2; Iter  1518/ 2172] train: loss: 0.0021580
[Epoch 2; Iter  1548/ 2172] train: loss: 0.0688306
[Epoch 2; Iter  1578/ 2172] train: loss: 0.0029050
[Epoch 2; Iter  1608/ 2172] train: loss: 0.0021695
[Epoch 2; Iter  1638/ 2172] train: loss: 0.0022354
[Epoch 2; Iter  1668/ 2172] train: loss: 0.0025876
[Epoch 2; Iter  1698/ 2172] train: loss: 0.0024743
[Epoch 2; Iter  1728/ 2172] train: loss: 0.0021868
[Epoch 2; Iter  1758/ 2172] train: loss: 0.0860015
[Epoch 2; Iter  1788/ 2172] train: loss: 0.0020179
[Epoch 2; Iter  1818/ 2172] train: loss: 0.0016735
[Epoch 2; Iter  1848/ 2172] train: loss: 0.0015657
[Epoch 2; Iter  1878/ 2172] train: loss: 0.0015747
[Epoch 2; Iter  1908/ 2172] train: loss: 0.0015237
[Epoch 2; Iter  1938/ 2172] train: loss: 0.0017141
[Epoch 2; Iter  1968/ 2172] train: loss: 0.0017723
[Epoch 2; Iter  1998/ 2172] train: loss: 0.0019091
[Epoch 2; Iter  2028/ 2172] train: loss: 0.0015991
[Epoch 2; Iter  2058/ 2172] train: loss: 0.0017138
[Epoch 2; Iter  2088/ 2172] train: loss: 0.0015997
[Epoch 2; Iter  2118/ 2172] train: loss: 0.0015037
[Epoch 2; Iter  2148/ 2172] train: loss: 0.0016390
[Epoch 2] ogbg-molmuv: 0.032824 val loss: 0.012760
[Epoch 2] ogbg-molmuv: 0.007131 test loss: 0.014884
[Epoch 3; Iter     6/ 2172] train: loss: 0.0029140
[Epoch 3; Iter    36/ 2172] train: loss: 0.0764064
[Epoch 3; Iter    66/ 2172] train: loss: 0.0020431
[Epoch 3; Iter    96/ 2172] train: loss: 0.0019431
[Epoch 3; Iter   126/ 2172] train: loss: 0.0020843
[Epoch 3; Iter   156/ 2172] train: loss: 0.0595667
[Epoch 3; Iter   186/ 2172] train: loss: 0.0740522
[Epoch 3; Iter   216/ 2172] train: loss: 0.0022975
[Epoch 3; Iter   246/ 2172] train: loss: 0.0017874
[Epoch 3; Iter   276/ 2172] train: loss: 0.0020073
[Epoch 3; Iter   306/ 2172] train: loss: 0.0029221
[Epoch 3; Iter   336/ 2172] train: loss: 0.0025305
[Epoch 3; Iter   366/ 2172] train: loss: 0.0021095
[Epoch 3; Iter   396/ 2172] train: loss: 0.0816664
[Epoch 3; Iter   426/ 2172] train: loss: 0.0020758
[Epoch 3; Iter   456/ 2172] train: loss: 0.0018724
[Epoch 3; Iter   486/ 2172] train: loss: 0.0017348
[Epoch 3; Iter   516/ 2172] train: loss: 0.0027350
[Epoch 3; Iter   546/ 2172] train: loss: 0.0826922
[Epoch 3; Iter   576/ 2172] train: loss: 0.0020017
[Epoch 3; Iter   606/ 2172] train: loss: 0.0019809
[Epoch 3; Iter   636/ 2172] train: loss: 0.0790799
[Epoch 3; Iter   666/ 2172] train: loss: 0.0017053
[Epoch 3; Iter   696/ 2172] train: loss: 0.0016722
[Epoch 3; Iter   726/ 2172] train: loss: 0.0018133
[Epoch 3; Iter   756/ 2172] train: loss: 0.0017845
[Epoch 3; Iter   786/ 2172] train: loss: 0.0017024
[Epoch 3; Iter   816/ 2172] train: loss: 0.0015943
[Epoch 3; Iter   846/ 2172] train: loss: 0.0915623
[Epoch 3; Iter   876/ 2172] train: loss: 0.0021604
[Epoch 3; Iter   906/ 2172] train: loss: 0.0031124
[Epoch 3; Iter   936/ 2172] train: loss: 0.0028238
[Epoch 3; Iter   966/ 2172] train: loss: 0.0025170
[Epoch 3; Iter   996/ 2172] train: loss: 0.0729371
[Epoch 3; Iter  1026/ 2172] train: loss: 0.0023571
[Epoch 3; Iter  1056/ 2172] train: loss: 0.0019421
[Epoch 3; Iter  1086/ 2172] train: loss: 0.0016827
[Epoch 3; Iter  1116/ 2172] train: loss: 0.0019879
[Epoch 3; Iter  1146/ 2172] train: loss: 0.0627535
[Epoch 3; Iter  1176/ 2172] train: loss: 0.0020691
[Epoch 3; Iter  1206/ 2172] train: loss: 0.0018534
[Epoch 3; Iter  1236/ 2172] train: loss: 0.0020657
[Epoch 3; Iter  1266/ 2172] train: loss: 0.0025175
[Epoch 3; Iter  1296/ 2172] train: loss: 0.0017879
[Epoch 3; Iter  1326/ 2172] train: loss: 0.0894775
[Epoch 3; Iter  1356/ 2172] train: loss: 0.0019626
[Epoch 3; Iter  1386/ 2172] train: loss: 0.1011499
[Epoch 3; Iter  1416/ 2172] train: loss: 0.0025325
[Epoch 3; Iter  1446/ 2172] train: loss: 0.0021320
[Epoch 3; Iter  1476/ 2172] train: loss: 0.2278065
[Epoch 3; Iter  1506/ 2172] train: loss: 0.0020752
[Epoch 3; Iter  1536/ 2172] train: loss: 0.0021601
[Epoch 3; Iter  1566/ 2172] train: loss: 0.0902150
[Epoch 3; Iter  1596/ 2172] train: loss: 0.0811896
[Epoch 3; Iter  1626/ 2172] train: loss: 0.0024682
[Epoch 3; Iter  1656/ 2172] train: loss: 0.0018234
[Epoch 3; Iter  1686/ 2172] train: loss: 0.0486580
[Epoch 3; Iter  1716/ 2172] train: loss: 0.0016295
[Epoch 3; Iter  1746/ 2172] train: loss: 0.0014675
[Epoch 3; Iter  1776/ 2172] train: loss: 0.0018854
[Epoch 3; Iter  1806/ 2172] train: loss: 0.0017650
[Epoch 3; Iter  1836/ 2172] train: loss: 0.0742707
[Epoch 3; Iter  1866/ 2172] train: loss: 0.0017194
[Epoch 3; Iter  1896/ 2172] train: loss: 0.0012751
[Epoch 3; Iter  1926/ 2172] train: loss: 0.1704156
[Epoch 3; Iter  1956/ 2172] train: loss: 0.0020639
[Epoch 3; Iter  1986/ 2172] train: loss: 0.0020267
[Epoch 3; Iter  2016/ 2172] train: loss: 0.0018132
[Epoch 3; Iter  2046/ 2172] train: loss: 0.0025707
[Epoch 3; Iter  2076/ 2172] train: loss: 0.0020724
[Epoch 3; Iter  2106/ 2172] train: loss: 0.0022956
[Epoch 3; Iter  2136/ 2172] train: loss: 0.0022075
[Epoch 3; Iter  2166/ 2172] train: loss: 0.0018688
[Epoch 3] ogbg-molmuv: 0.014859 val loss: 0.012058
[Epoch 3] ogbg-molmuv: 0.009534 test loss: 0.013982
[Epoch 4; Iter    24/ 2172] train: loss: 0.0022090
[Epoch 4; Iter    54/ 2172] train: loss: 0.0016920
[Epoch 4; Iter    84/ 2172] train: loss: 0.0016253
[Epoch 4; Iter   114/ 2172] train: loss: 0.0013603
[Epoch 4; Iter   144/ 2172] train: loss: 0.0878389
[Epoch 4; Iter   174/ 2172] train: loss: 0.0016111
[Epoch 4; Iter   204/ 2172] train: loss: 0.0018247
[Epoch 4; Iter   234/ 2172] train: loss: 0.0017284
[Epoch 4; Iter   264/ 2172] train: loss: 0.0644049
[Epoch 4; Iter   294/ 2172] train: loss: 0.0017470
[Epoch 4; Iter   324/ 2172] train: loss: 0.0020193
[Epoch 4; Iter   354/ 2172] train: loss: 0.0019312
[Epoch 4; Iter   384/ 2172] train: loss: 0.0020141
[Epoch 4; Iter   414/ 2172] train: loss: 0.0926941
[Epoch 4; Iter   444/ 2172] train: loss: 0.0016687
[Epoch 4; Iter   474/ 2172] train: loss: 0.0020872
[Epoch 4; Iter   504/ 2172] train: loss: 0.0012405
[Epoch 4; Iter   534/ 2172] train: loss: 0.0020352
[Epoch 4; Iter   564/ 2172] train: loss: 0.0016024
[Epoch 4; Iter   594/ 2172] train: loss: 0.0014707
[Epoch 4; Iter   624/ 2172] train: loss: 0.0014927
[Epoch 4; Iter   654/ 2172] train: loss: 0.0013833
[Epoch 4; Iter   684/ 2172] train: loss: 0.0018759
[Epoch 4; Iter   714/ 2172] train: loss: 0.0036670
[Epoch 4; Iter   744/ 2172] train: loss: 0.0027019
[Epoch 4; Iter   774/ 2172] train: loss: 0.0019928
[Epoch 4; Iter   804/ 2172] train: loss: 0.0015669
[Epoch 4; Iter   834/ 2172] train: loss: 0.0026584
[Epoch 4; Iter   864/ 2172] train: loss: 0.0023851
[Epoch 4; Iter   894/ 2172] train: loss: 0.0022670
[Epoch 4; Iter   924/ 2172] train: loss: 0.0019012
[Epoch 4; Iter   954/ 2172] train: loss: 0.0698659
[Epoch 4; Iter   984/ 2172] train: loss: 0.0024959
[Epoch 4; Iter  1014/ 2172] train: loss: 0.0890192
[Epoch 4; Iter  1044/ 2172] train: loss: 0.0021047
[Epoch 4; Iter  1074/ 2172] train: loss: 0.0025643
[Epoch 4; Iter  1104/ 2172] train: loss: 0.0026941
[Epoch 4; Iter  1134/ 2172] train: loss: 0.0027581
[Epoch 4; Iter  1164/ 2172] train: loss: 0.0029069
[Epoch 4; Iter  1194/ 2172] train: loss: 0.0025902
[Epoch 4; Iter  1224/ 2172] train: loss: 0.0026741
[Epoch 4; Iter  1254/ 2172] train: loss: 0.0019186
[Epoch 4; Iter  1284/ 2172] train: loss: 0.1013552
[Epoch 4; Iter  1314/ 2172] train: loss: 0.0015733
[Epoch 4; Iter  1344/ 2172] train: loss: 0.0013811
[Epoch 4; Iter  1374/ 2172] train: loss: 0.0716375
[Epoch 2; Iter  1378/ 1862] train: loss: 0.0024375
[Epoch 2; Iter  1408/ 1862] train: loss: 0.0024601
[Epoch 2; Iter  1438/ 1862] train: loss: 0.0020361
[Epoch 2; Iter  1468/ 1862] train: loss: 0.0023339
[Epoch 2; Iter  1498/ 1862] train: loss: 0.0023520
[Epoch 2; Iter  1528/ 1862] train: loss: 0.0020209
[Epoch 2; Iter  1558/ 1862] train: loss: 0.0736303
[Epoch 2; Iter  1588/ 1862] train: loss: 0.0018921
[Epoch 2; Iter  1618/ 1862] train: loss: 0.0018790
[Epoch 2; Iter  1648/ 1862] train: loss: 0.0868114
[Epoch 2; Iter  1678/ 1862] train: loss: 0.0023127
[Epoch 2; Iter  1708/ 1862] train: loss: 0.0023726
[Epoch 2; Iter  1738/ 1862] train: loss: 0.0024769
[Epoch 2; Iter  1768/ 1862] train: loss: 0.0024234
[Epoch 2; Iter  1798/ 1862] train: loss: 0.0023349
[Epoch 2; Iter  1828/ 1862] train: loss: 0.0020160
[Epoch 2; Iter  1858/ 1862] train: loss: 0.0020804
[Epoch 2] ogbg-molmuv: 0.004375 val loss: 0.014494
[Epoch 2] ogbg-molmuv: 0.005696 test loss: 0.013450
[Epoch 3; Iter    26/ 1862] train: loss: 0.0024574
[Epoch 3; Iter    56/ 1862] train: loss: 0.0021852
[Epoch 3; Iter    86/ 1862] train: loss: 0.0022080
[Epoch 3; Iter   116/ 1862] train: loss: 0.0551287
[Epoch 3; Iter   146/ 1862] train: loss: 0.0020527
[Epoch 3; Iter   176/ 1862] train: loss: 0.0019988
[Epoch 3; Iter   206/ 1862] train: loss: 0.0023694
[Epoch 3; Iter   236/ 1862] train: loss: 0.0018002
[Epoch 3; Iter   266/ 1862] train: loss: 0.0878209
[Epoch 3; Iter   296/ 1862] train: loss: 0.0017268
[Epoch 3; Iter   326/ 1862] train: loss: 0.0676351
[Epoch 3; Iter   356/ 1862] train: loss: 0.0017990
[Epoch 3; Iter   386/ 1862] train: loss: 0.0023518
[Epoch 3; Iter   416/ 1862] train: loss: 0.0774830
[Epoch 3; Iter   446/ 1862] train: loss: 0.0016416
[Epoch 3; Iter   476/ 1862] train: loss: 0.0719870
[Epoch 3; Iter   506/ 1862] train: loss: 0.1826015
[Epoch 3; Iter   536/ 1862] train: loss: 0.0019797
[Epoch 3; Iter   566/ 1862] train: loss: 0.0019504
[Epoch 3; Iter   596/ 1862] train: loss: 0.0018790
[Epoch 3; Iter   626/ 1862] train: loss: 0.0015329
[Epoch 3; Iter   656/ 1862] train: loss: 0.0014444
[Epoch 3; Iter   686/ 1862] train: loss: 0.0016705
[Epoch 3; Iter   716/ 1862] train: loss: 0.0804142
[Epoch 3; Iter   746/ 1862] train: loss: 0.0670368
[Epoch 3; Iter   776/ 1862] train: loss: 0.0487752
[Epoch 3; Iter   806/ 1862] train: loss: 0.0019223
[Epoch 3; Iter   836/ 1862] train: loss: 0.0016048
[Epoch 3; Iter   866/ 1862] train: loss: 0.0016469
[Epoch 3; Iter   896/ 1862] train: loss: 0.0019520
[Epoch 3; Iter   926/ 1862] train: loss: 0.0016743
[Epoch 3; Iter   956/ 1862] train: loss: 0.0019105
[Epoch 3; Iter   986/ 1862] train: loss: 0.0016689
[Epoch 3; Iter  1016/ 1862] train: loss: 0.0711683
[Epoch 3; Iter  1046/ 1862] train: loss: 0.1314259
[Epoch 3; Iter  1076/ 1862] train: loss: 0.0683744
[Epoch 3; Iter  1106/ 1862] train: loss: 0.0019963
[Epoch 3; Iter  1136/ 1862] train: loss: 0.0021174
[Epoch 3; Iter  1166/ 1862] train: loss: 0.0995422
[Epoch 3; Iter  1196/ 1862] train: loss: 0.0021823
[Epoch 3; Iter  1226/ 1862] train: loss: 0.0840381
[Epoch 3; Iter  1256/ 1862] train: loss: 0.0024242
[Epoch 3; Iter  1286/ 1862] train: loss: 0.0022184
[Epoch 3; Iter  1316/ 1862] train: loss: 0.0023019
[Epoch 3; Iter  1346/ 1862] train: loss: 0.0021449
[Epoch 3; Iter  1376/ 1862] train: loss: 0.0020134
[Epoch 3; Iter  1406/ 1862] train: loss: 0.0927244
[Epoch 3; Iter  1436/ 1862] train: loss: 0.0019370
[Epoch 3; Iter  1466/ 1862] train: loss: 0.0018369
[Epoch 3; Iter  1496/ 1862] train: loss: 0.0020436
[Epoch 3; Iter  1526/ 1862] train: loss: 0.0029993
[Epoch 3; Iter  1556/ 1862] train: loss: 0.0021693
[Epoch 3; Iter  1586/ 1862] train: loss: 0.1004143
[Epoch 3; Iter  1616/ 1862] train: loss: 0.0019763
[Epoch 3; Iter  1646/ 1862] train: loss: 0.0019199
[Epoch 3; Iter  1676/ 1862] train: loss: 0.0025221
[Epoch 3; Iter  1706/ 1862] train: loss: 0.0020205
[Epoch 3; Iter  1736/ 1862] train: loss: 0.0019009
[Epoch 3; Iter  1766/ 1862] train: loss: 0.0023150
[Epoch 3; Iter  1796/ 1862] train: loss: 0.0023192
[Epoch 3; Iter  1826/ 1862] train: loss: 0.0021633
[Epoch 3; Iter  1856/ 1862] train: loss: 0.0016978
[Epoch 3] ogbg-molmuv: 0.011929 val loss: 0.016730
[Epoch 3] ogbg-molmuv: 0.009759 test loss: 0.017805
[Epoch 4; Iter    24/ 1862] train: loss: 0.0019265
[Epoch 4; Iter    54/ 1862] train: loss: 0.0019925
[Epoch 4; Iter    84/ 1862] train: loss: 0.0019067
[Epoch 4; Iter   114/ 1862] train: loss: 0.0017119
[Epoch 4; Iter   144/ 1862] train: loss: 0.0022103
[Epoch 4; Iter   174/ 1862] train: loss: 0.0018401
[Epoch 4; Iter   204/ 1862] train: loss: 0.0019595
[Epoch 4; Iter   234/ 1862] train: loss: 0.0019909
[Epoch 4; Iter   264/ 1862] train: loss: 0.0023278
[Epoch 4; Iter   294/ 1862] train: loss: 0.0024724
[Epoch 4; Iter   324/ 1862] train: loss: 0.0918440
[Epoch 4; Iter   354/ 1862] train: loss: 0.0022937
[Epoch 4; Iter   384/ 1862] train: loss: 0.0024532
[Epoch 4; Iter   414/ 1862] train: loss: 0.0022781
[Epoch 4; Iter   444/ 1862] train: loss: 0.0021799
[Epoch 4; Iter   474/ 1862] train: loss: 0.0027049
[Epoch 4; Iter   504/ 1862] train: loss: 0.0877689
[Epoch 4; Iter   534/ 1862] train: loss: 0.0024285
[Epoch 4; Iter   564/ 1862] train: loss: 0.0047100
[Epoch 4; Iter   594/ 1862] train: loss: 0.0024851
[Epoch 4; Iter   624/ 1862] train: loss: 0.0023829
[Epoch 4; Iter   654/ 1862] train: loss: 0.0026061
[Epoch 4; Iter   684/ 1862] train: loss: 0.0020797
[Epoch 4; Iter   714/ 1862] train: loss: 0.0018256
[Epoch 4; Iter   744/ 1862] train: loss: 0.0021901
[Epoch 4; Iter   774/ 1862] train: loss: 0.1237237
[Epoch 4; Iter   804/ 1862] train: loss: 0.0023272
[Epoch 4; Iter   834/ 1862] train: loss: 0.0023263
[Epoch 4; Iter   864/ 1862] train: loss: 0.0018777
[Epoch 4; Iter   894/ 1862] train: loss: 0.0018224
[Epoch 4; Iter   924/ 1862] train: loss: 0.0017037
[Epoch 4; Iter   954/ 1862] train: loss: 0.0015907
[Epoch 4; Iter   984/ 1862] train: loss: 0.0023676
[Epoch 4; Iter  1014/ 1862] train: loss: 0.0022875
[Epoch 4; Iter  1044/ 1862] train: loss: 0.0018779
[Epoch 4; Iter  1074/ 1862] train: loss: 0.0016576
[Epoch 4; Iter  1104/ 1862] train: loss: 0.1178405
[Epoch 4; Iter  1134/ 1862] train: loss: 0.0012495
[Epoch 4; Iter  1164/ 1862] train: loss: 0.0767013
[Epoch 4; Iter  1194/ 1862] train: loss: 0.0018264
[Epoch 4; Iter  1224/ 1862] train: loss: 0.0016144
[Epoch 4; Iter  1254/ 1862] train: loss: 0.0016507
[Epoch 4; Iter  1284/ 1862] train: loss: 0.0018110
[Epoch 4; Iter  1314/ 1862] train: loss: 0.0020749
[Epoch 4; Iter  1344/ 1862] train: loss: 0.0018946
[Epoch 4; Iter  1374/ 1862] train: loss: 0.0023976
[Epoch 4; Iter  1404/ 1862] train: loss: 0.0033258
[Epoch 4; Iter  1434/ 1862] train: loss: 0.0029468
[Epoch 4; Iter  1464/ 1862] train: loss: 0.0015226
[Epoch 4; Iter  1494/ 1862] train: loss: 0.0013163
[Epoch 4; Iter  1524/ 1862] train: loss: 0.0012814
[Epoch 4; Iter  1554/ 1862] train: loss: 0.0015796
[Epoch 4; Iter  1584/ 1862] train: loss: 0.0017283
[Epoch 4; Iter  1614/ 1862] train: loss: 0.0017624
[Epoch 4; Iter  1644/ 1862] train: loss: 0.0016601
[Epoch 4; Iter  1674/ 1862] train: loss: 0.0018638
[Epoch 4; Iter  1704/ 1862] train: loss: 0.0016315
[Epoch 4; Iter  1734/ 1862] train: loss: 0.0016829
[Epoch 4; Iter  1764/ 1862] train: loss: 0.0016135
[Epoch 4; Iter  1794/ 1862] train: loss: 0.0028451
[Epoch 4; Iter  1824/ 1862] train: loss: 0.0019517
[Epoch 4; Iter  1854/ 1862] train: loss: 0.0026333
[Epoch 4] ogbg-molmuv: 0.023984 val loss: 0.026482
[Epoch 4] ogbg-molmuv: 0.009353 test loss: 0.027762
[Epoch 5; Iter    22/ 1862] train: loss: 0.0019507
[Epoch 5; Iter    52/ 1862] train: loss: 0.0021134
[Epoch 5; Iter    82/ 1862] train: loss: 0.0027923
[Epoch 5; Iter   112/ 1862] train: loss: 0.0801567
[Epoch 5; Iter   142/ 1862] train: loss: 0.0027044
[Epoch 5; Iter   172/ 1862] train: loss: 0.0020657
[Epoch 5; Iter   202/ 1862] train: loss: 0.0025530
[Epoch 5; Iter   232/ 1862] train: loss: 0.0756044
[Epoch 5; Iter   262/ 1862] train: loss: 0.0015104
[Epoch 5; Iter   292/ 1862] train: loss: 0.0015012
[Epoch 5; Iter   322/ 1862] train: loss: 0.0590643
[Epoch 5; Iter   352/ 1862] train: loss: 0.0938693
[Epoch 5; Iter   382/ 1862] train: loss: 0.0016973
[Epoch 2; Iter  1378/ 1862] train: loss: 0.0020484
[Epoch 2; Iter  1408/ 1862] train: loss: 0.0022577
[Epoch 2; Iter  1438/ 1862] train: loss: 0.0020088
[Epoch 2; Iter  1468/ 1862] train: loss: 0.0025484
[Epoch 2; Iter  1498/ 1862] train: loss: 0.0021356
[Epoch 2; Iter  1528/ 1862] train: loss: 0.0023588
[Epoch 2; Iter  1558/ 1862] train: loss: 0.0020353
[Epoch 2; Iter  1588/ 1862] train: loss: 0.0022316
[Epoch 2; Iter  1618/ 1862] train: loss: 0.0019082
[Epoch 2; Iter  1648/ 1862] train: loss: 0.0029039
[Epoch 2; Iter  1678/ 1862] train: loss: 0.0019997
[Epoch 2; Iter  1708/ 1862] train: loss: 0.0017516
[Epoch 2; Iter  1738/ 1862] train: loss: 0.0023224
[Epoch 2; Iter  1768/ 1862] train: loss: 0.0018715
[Epoch 2; Iter  1798/ 1862] train: loss: 0.0018893
[Epoch 2; Iter  1828/ 1862] train: loss: 0.0016640
[Epoch 2; Iter  1858/ 1862] train: loss: 0.0019030
[Epoch 2] ogbg-molmuv: 0.024163 val loss: 0.013795
[Epoch 2] ogbg-molmuv: 0.008890 test loss: 0.012863
[Epoch 3; Iter    26/ 1862] train: loss: 0.0020993
[Epoch 3; Iter    56/ 1862] train: loss: 0.0020695
[Epoch 3; Iter    86/ 1862] train: loss: 0.0689391
[Epoch 3; Iter   116/ 1862] train: loss: 0.0017257
[Epoch 3; Iter   146/ 1862] train: loss: 0.0019803
[Epoch 3; Iter   176/ 1862] train: loss: 0.0017034
[Epoch 3; Iter   206/ 1862] train: loss: 0.0018639
[Epoch 3; Iter   236/ 1862] train: loss: 0.0017079
[Epoch 3; Iter   266/ 1862] train: loss: 0.0607230
[Epoch 3; Iter   296/ 1862] train: loss: 0.0019924
[Epoch 3; Iter   326/ 1862] train: loss: 0.0017739
[Epoch 3; Iter   356/ 1862] train: loss: 0.0018755
[Epoch 3; Iter   386/ 1862] train: loss: 0.0022903
[Epoch 3; Iter   416/ 1862] train: loss: 0.0017422
[Epoch 3; Iter   446/ 1862] train: loss: 0.0018763
[Epoch 3; Iter   476/ 1862] train: loss: 0.0036224
[Epoch 3; Iter   506/ 1862] train: loss: 0.0026953
[Epoch 3; Iter   536/ 1862] train: loss: 0.0021229
[Epoch 3; Iter   566/ 1862] train: loss: 0.0019890
[Epoch 3; Iter   596/ 1862] train: loss: 0.0017217
[Epoch 3; Iter   626/ 1862] train: loss: 0.0023485
[Epoch 3; Iter   656/ 1862] train: loss: 0.0017056
[Epoch 3; Iter   686/ 1862] train: loss: 0.0017575
[Epoch 3; Iter   716/ 1862] train: loss: 0.0024199
[Epoch 3; Iter   746/ 1862] train: loss: 0.0027511
[Epoch 3; Iter   776/ 1862] train: loss: 0.0016844
[Epoch 3; Iter   806/ 1862] train: loss: 0.0743137
[Epoch 3; Iter   836/ 1862] train: loss: 0.0016017
[Epoch 3; Iter   866/ 1862] train: loss: 0.0020418
[Epoch 3; Iter   896/ 1862] train: loss: 0.0018903
[Epoch 3; Iter   926/ 1862] train: loss: 0.0024053
[Epoch 3; Iter   956/ 1862] train: loss: 0.0016832
[Epoch 3; Iter   986/ 1862] train: loss: 0.0704440
[Epoch 3; Iter  1016/ 1862] train: loss: 0.0019931
[Epoch 3; Iter  1046/ 1862] train: loss: 0.0019483
[Epoch 3; Iter  1076/ 1862] train: loss: 0.0019136
[Epoch 3; Iter  1106/ 1862] train: loss: 0.0027524
[Epoch 3; Iter  1136/ 1862] train: loss: 0.0022172
[Epoch 3; Iter  1166/ 1862] train: loss: 0.0020391
[Epoch 3; Iter  1196/ 1862] train: loss: 0.0025287
[Epoch 3; Iter  1226/ 1862] train: loss: 0.0632958
[Epoch 3; Iter  1256/ 1862] train: loss: 0.0022110
[Epoch 3; Iter  1286/ 1862] train: loss: 0.0016133
[Epoch 3; Iter  1316/ 1862] train: loss: 0.0020258
[Epoch 3; Iter  1346/ 1862] train: loss: 0.0473360
[Epoch 3; Iter  1376/ 1862] train: loss: 0.0021229
[Epoch 3; Iter  1406/ 1862] train: loss: 0.0031360
[Epoch 3; Iter  1436/ 1862] train: loss: 0.0036389
[Epoch 3; Iter  1466/ 1862] train: loss: 0.0016496
[Epoch 3; Iter  1496/ 1862] train: loss: 0.0019373
[Epoch 3; Iter  1526/ 1862] train: loss: 0.0835045
[Epoch 3; Iter  1556/ 1862] train: loss: 0.0457602
[Epoch 3; Iter  1586/ 1862] train: loss: 0.0019516
[Epoch 3; Iter  1616/ 1862] train: loss: 0.0649859
[Epoch 3; Iter  1646/ 1862] train: loss: 0.0025578
[Epoch 3; Iter  1676/ 1862] train: loss: 0.0025508
[Epoch 3; Iter  1706/ 1862] train: loss: 0.0025869
[Epoch 3; Iter  1736/ 1862] train: loss: 0.0020275
[Epoch 3; Iter  1766/ 1862] train: loss: 0.0023363
[Epoch 3; Iter  1796/ 1862] train: loss: 0.0038473
[Epoch 3; Iter  1826/ 1862] train: loss: 0.0020682
[Epoch 3; Iter  1856/ 1862] train: loss: 0.0019104
[Epoch 3] ogbg-molmuv: 0.022056 val loss: 0.013821
[Epoch 3] ogbg-molmuv: 0.012453 test loss: 0.012841
[Epoch 4; Iter    24/ 1862] train: loss: 0.0019981
[Epoch 4; Iter    54/ 1862] train: loss: 0.0020848
[Epoch 4; Iter    84/ 1862] train: loss: 0.0014450
[Epoch 4; Iter   114/ 1862] train: loss: 0.0016110
[Epoch 4; Iter   144/ 1862] train: loss: 0.0022417
[Epoch 4; Iter   174/ 1862] train: loss: 0.0020565
[Epoch 4; Iter   204/ 1862] train: loss: 0.0019360
[Epoch 4; Iter   234/ 1862] train: loss: 0.0018716
[Epoch 4; Iter   264/ 1862] train: loss: 0.0026370
[Epoch 4; Iter   294/ 1862] train: loss: 0.0023597
[Epoch 4; Iter   324/ 1862] train: loss: 0.0013730
[Epoch 4; Iter   354/ 1862] train: loss: 0.0915708
[Epoch 4; Iter   384/ 1862] train: loss: 0.0596002
[Epoch 4; Iter   414/ 1862] train: loss: 0.0016419
[Epoch 4; Iter   444/ 1862] train: loss: 0.0016697
[Epoch 4; Iter   474/ 1862] train: loss: 0.0018943
[Epoch 4; Iter   504/ 1862] train: loss: 0.0831129
[Epoch 4; Iter   534/ 1862] train: loss: 0.0018696
[Epoch 4; Iter   564/ 1862] train: loss: 0.0016423
[Epoch 4; Iter   594/ 1862] train: loss: 0.0871290
[Epoch 4; Iter   624/ 1862] train: loss: 0.0018967
[Epoch 4; Iter   654/ 1862] train: loss: 0.0022365
[Epoch 4; Iter   684/ 1862] train: loss: 0.0027695
[Epoch 4; Iter   714/ 1862] train: loss: 0.0018459
[Epoch 4; Iter   744/ 1862] train: loss: 0.0022669
[Epoch 4; Iter   774/ 1862] train: loss: 0.0637752
[Epoch 4; Iter   804/ 1862] train: loss: 0.0014988
[Epoch 4; Iter   834/ 1862] train: loss: 0.0714036
[Epoch 4; Iter   864/ 1862] train: loss: 0.0731308
[Epoch 4; Iter   894/ 1862] train: loss: 0.0017849
[Epoch 4; Iter   924/ 1862] train: loss: 0.1115125
[Epoch 4; Iter   954/ 1862] train: loss: 0.0032933
[Epoch 4; Iter   984/ 1862] train: loss: 0.0024087
[Epoch 4; Iter  1014/ 1862] train: loss: 0.0705379
[Epoch 4; Iter  1044/ 1862] train: loss: 0.0915168
[Epoch 4; Iter  1074/ 1862] train: loss: 0.0718349
[Epoch 4; Iter  1104/ 1862] train: loss: 0.0056204
[Epoch 4; Iter  1134/ 1862] train: loss: 0.0024687
[Epoch 4; Iter  1164/ 1862] train: loss: 0.0027148
[Epoch 4; Iter  1194/ 1862] train: loss: 0.0027796
[Epoch 4; Iter  1224/ 1862] train: loss: 0.1030862
[Epoch 4; Iter  1254/ 1862] train: loss: 0.0024257
[Epoch 4; Iter  1284/ 1862] train: loss: 0.0019267
[Epoch 4; Iter  1314/ 1862] train: loss: 0.0016454
[Epoch 4; Iter  1344/ 1862] train: loss: 0.0016272
[Epoch 4; Iter  1374/ 1862] train: loss: 0.0019162
[Epoch 4; Iter  1404/ 1862] train: loss: 0.0018839
[Epoch 4; Iter  1434/ 1862] train: loss: 0.1699746
[Epoch 4; Iter  1464/ 1862] train: loss: 0.0955304
[Epoch 4; Iter  1494/ 1862] train: loss: 0.0021575
[Epoch 4; Iter  1524/ 1862] train: loss: 0.0020122
[Epoch 4; Iter  1554/ 1862] train: loss: 0.0019446
[Epoch 4; Iter  1584/ 1862] train: loss: 0.0019727
[Epoch 4; Iter  1614/ 1862] train: loss: 0.0021074
[Epoch 4; Iter  1644/ 1862] train: loss: 0.0021184
[Epoch 4; Iter  1674/ 1862] train: loss: 0.0020176
[Epoch 4; Iter  1704/ 1862] train: loss: 0.0018189
[Epoch 4; Iter  1734/ 1862] train: loss: 0.0781551
[Epoch 4; Iter  1764/ 1862] train: loss: 0.0016957
[Epoch 4; Iter  1794/ 1862] train: loss: 0.0017398
[Epoch 4; Iter  1824/ 1862] train: loss: 0.0014716
[Epoch 4; Iter  1854/ 1862] train: loss: 0.0017395
[Epoch 4] ogbg-molmuv: 0.029733 val loss: 0.013894
[Epoch 4] ogbg-molmuv: 0.016414 test loss: 0.012784
[Epoch 5; Iter    22/ 1862] train: loss: 0.0016329
[Epoch 5; Iter    52/ 1862] train: loss: 0.0023200
[Epoch 5; Iter    82/ 1862] train: loss: 0.0019347
[Epoch 5; Iter   112/ 1862] train: loss: 0.0016367
[Epoch 5; Iter   142/ 1862] train: loss: 0.0015841
[Epoch 5; Iter   172/ 1862] train: loss: 0.0012753
[Epoch 5; Iter   202/ 1862] train: loss: 0.0960559
[Epoch 5; Iter   232/ 1862] train: loss: 0.0016209
[Epoch 5; Iter   262/ 1862] train: loss: 0.0017849
[Epoch 5; Iter   292/ 1862] train: loss: 0.0018432
[Epoch 5; Iter   322/ 1862] train: loss: 0.0026925
[Epoch 5; Iter   352/ 1862] train: loss: 0.0024130
[Epoch 5; Iter   382/ 1862] train: loss: 0.0021785
[Epoch 2; Iter  1378/ 1862] train: loss: 0.0023788
[Epoch 2; Iter  1408/ 1862] train: loss: 0.1083222
[Epoch 2; Iter  1438/ 1862] train: loss: 0.0022561
[Epoch 2; Iter  1468/ 1862] train: loss: 0.0021014
[Epoch 2; Iter  1498/ 1862] train: loss: 0.0022664
[Epoch 2; Iter  1528/ 1862] train: loss: 0.0023050
[Epoch 2; Iter  1558/ 1862] train: loss: 0.0025067
[Epoch 2; Iter  1588/ 1862] train: loss: 0.0021332
[Epoch 2; Iter  1618/ 1862] train: loss: 0.0019998
[Epoch 2; Iter  1648/ 1862] train: loss: 0.0021834
[Epoch 2; Iter  1678/ 1862] train: loss: 0.0021445
[Epoch 2; Iter  1708/ 1862] train: loss: 0.0022424
[Epoch 2; Iter  1738/ 1862] train: loss: 0.0018824
[Epoch 2; Iter  1768/ 1862] train: loss: 0.0016541
[Epoch 2; Iter  1798/ 1862] train: loss: 0.0037645
[Epoch 2; Iter  1828/ 1862] train: loss: 0.0021175
[Epoch 2; Iter  1858/ 1862] train: loss: 0.0847644
[Epoch 2] ogbg-molmuv: 0.018914 val loss: 0.013873
[Epoch 2] ogbg-molmuv: 0.014211 test loss: 0.012866
[Epoch 3; Iter    26/ 1862] train: loss: 0.0018628
[Epoch 3; Iter    56/ 1862] train: loss: 0.0017112
[Epoch 3; Iter    86/ 1862] train: loss: 0.0025416
[Epoch 3; Iter   116/ 1862] train: loss: 0.0024885
[Epoch 3; Iter   146/ 1862] train: loss: 0.0019978
[Epoch 3; Iter   176/ 1862] train: loss: 0.0024189
[Epoch 3; Iter   206/ 1862] train: loss: 0.0020005
[Epoch 3; Iter   236/ 1862] train: loss: 0.0070402
[Epoch 3; Iter   266/ 1862] train: loss: 0.0955390
[Epoch 3; Iter   296/ 1862] train: loss: 0.0017724
[Epoch 3; Iter   326/ 1862] train: loss: 0.0023477
[Epoch 3; Iter   356/ 1862] train: loss: 0.0019199
[Epoch 3; Iter   386/ 1862] train: loss: 0.0022325
[Epoch 3; Iter   416/ 1862] train: loss: 0.0726868
[Epoch 3; Iter   446/ 1862] train: loss: 0.0020763
[Epoch 3; Iter   476/ 1862] train: loss: 0.0019016
[Epoch 3; Iter   506/ 1862] train: loss: 0.0680521
[Epoch 3; Iter   536/ 1862] train: loss: 0.0024450
[Epoch 3; Iter   566/ 1862] train: loss: 0.0021343
[Epoch 3; Iter   596/ 1862] train: loss: 0.0029876
[Epoch 3; Iter   626/ 1862] train: loss: 0.0853122
[Epoch 3; Iter   656/ 1862] train: loss: 0.0020474
[Epoch 3; Iter   686/ 1862] train: loss: 0.0021276
[Epoch 3; Iter   716/ 1862] train: loss: 0.0018631
[Epoch 3; Iter   746/ 1862] train: loss: 0.0018063
[Epoch 3; Iter   776/ 1862] train: loss: 0.0020628
[Epoch 3; Iter   806/ 1862] train: loss: 0.0023988
[Epoch 3; Iter   836/ 1862] train: loss: 0.0020421
[Epoch 3; Iter   866/ 1862] train: loss: 0.0018020
[Epoch 3; Iter   896/ 1862] train: loss: 0.0019569
[Epoch 3; Iter   926/ 1862] train: loss: 0.0022139
[Epoch 3; Iter   956/ 1862] train: loss: 0.0023734
[Epoch 3; Iter   986/ 1862] train: loss: 0.0020821
[Epoch 3; Iter  1016/ 1862] train: loss: 0.0017817
[Epoch 3; Iter  1046/ 1862] train: loss: 0.0771956
[Epoch 3; Iter  1076/ 1862] train: loss: 0.0017300
[Epoch 3; Iter  1106/ 1862] train: loss: 0.0018075
[Epoch 3; Iter  1136/ 1862] train: loss: 0.0018841
[Epoch 3; Iter  1166/ 1862] train: loss: 0.0017885
[Epoch 3; Iter  1196/ 1862] train: loss: 0.1320905
[Epoch 3; Iter  1226/ 1862] train: loss: 0.0019816
[Epoch 3; Iter  1256/ 1862] train: loss: 0.0017374
[Epoch 3; Iter  1286/ 1862] train: loss: 0.0017061
[Epoch 3; Iter  1316/ 1862] train: loss: 0.0017306
[Epoch 3; Iter  1346/ 1862] train: loss: 0.0770521
[Epoch 3; Iter  1376/ 1862] train: loss: 0.0018125
[Epoch 3; Iter  1406/ 1862] train: loss: 0.0017894
[Epoch 3; Iter  1436/ 1862] train: loss: 0.0020066
[Epoch 3; Iter  1466/ 1862] train: loss: 0.0017060
[Epoch 3; Iter  1496/ 1862] train: loss: 0.0022143
[Epoch 3; Iter  1526/ 1862] train: loss: 0.0022684
[Epoch 3; Iter  1556/ 1862] train: loss: 0.0027190
[Epoch 3; Iter  1586/ 1862] train: loss: 0.0021156
[Epoch 3; Iter  1616/ 1862] train: loss: 0.0017043
[Epoch 3; Iter  1646/ 1862] train: loss: 0.0810459
[Epoch 3; Iter  1676/ 1862] train: loss: 0.0708754
[Epoch 3; Iter  1706/ 1862] train: loss: 0.0021532
[Epoch 3; Iter  1736/ 1862] train: loss: 0.0014117
[Epoch 3; Iter  1766/ 1862] train: loss: 0.0019174
[Epoch 3; Iter  1796/ 1862] train: loss: 0.0018460
[Epoch 3; Iter  1826/ 1862] train: loss: 0.0835184
[Epoch 3; Iter  1856/ 1862] train: loss: 0.0014438
[Epoch 3] ogbg-molmuv: 0.004836 val loss: 0.014660
[Epoch 3] ogbg-molmuv: 0.003597 test loss: 0.013686
[Epoch 4; Iter    24/ 1862] train: loss: 0.0014788
[Epoch 4; Iter    54/ 1862] train: loss: 0.0013635
[Epoch 4; Iter    84/ 1862] train: loss: 0.0015348
[Epoch 4; Iter   114/ 1862] train: loss: 0.0016788
[Epoch 4; Iter   144/ 1862] train: loss: 0.0019560
[Epoch 4; Iter   174/ 1862] train: loss: 0.0013352
[Epoch 4; Iter   204/ 1862] train: loss: 0.0016049
[Epoch 4; Iter   234/ 1862] train: loss: 0.0013931
[Epoch 4; Iter   264/ 1862] train: loss: 0.0012644
[Epoch 4; Iter   294/ 1862] train: loss: 0.0012321
[Epoch 4; Iter   324/ 1862] train: loss: 0.0015308
[Epoch 4; Iter   354/ 1862] train: loss: 0.0012953
[Epoch 4; Iter   384/ 1862] train: loss: 0.0012321
[Epoch 4; Iter   414/ 1862] train: loss: 0.0017344
[Epoch 4; Iter   444/ 1862] train: loss: 0.0016538
[Epoch 4; Iter   474/ 1862] train: loss: 0.0018837
[Epoch 4; Iter   504/ 1862] train: loss: 0.0717911
[Epoch 4; Iter   534/ 1862] train: loss: 0.0014411
[Epoch 4; Iter   564/ 1862] train: loss: 0.0016386
[Epoch 4; Iter   594/ 1862] train: loss: 0.0021196
[Epoch 4; Iter   624/ 1862] train: loss: 0.0017035
[Epoch 4; Iter   654/ 1862] train: loss: 0.0018736
[Epoch 4; Iter   684/ 1862] train: loss: 0.0018897
[Epoch 4; Iter   714/ 1862] train: loss: 0.0018414
[Epoch 4; Iter   744/ 1862] train: loss: 0.0763919
[Epoch 4; Iter   774/ 1862] train: loss: 0.0019394
[Epoch 4; Iter   804/ 1862] train: loss: 0.0015819
[Epoch 4; Iter   834/ 1862] train: loss: 0.0716934
[Epoch 4; Iter   864/ 1862] train: loss: 0.0017238
[Epoch 4; Iter   894/ 1862] train: loss: 0.0025801
[Epoch 4; Iter   924/ 1862] train: loss: 0.0023168
[Epoch 4; Iter   954/ 1862] train: loss: 0.0783851
[Epoch 4; Iter   984/ 1862] train: loss: 0.0025131
[Epoch 4; Iter  1014/ 1862] train: loss: 0.0020685
[Epoch 4; Iter  1044/ 1862] train: loss: 0.0016505
[Epoch 4; Iter  1074/ 1862] train: loss: 0.0659650
[Epoch 4; Iter  1104/ 1862] train: loss: 0.0031636
[Epoch 4; Iter  1134/ 1862] train: loss: 0.0022905
[Epoch 4; Iter  1164/ 1862] train: loss: 0.0030532
[Epoch 4; Iter  1194/ 1862] train: loss: 0.0020898
[Epoch 4; Iter  1224/ 1862] train: loss: 0.0029111
[Epoch 4; Iter  1254/ 1862] train: loss: 0.0028403
[Epoch 4; Iter  1284/ 1862] train: loss: 0.0021135
[Epoch 4; Iter  1314/ 1862] train: loss: 0.0022786
[Epoch 4; Iter  1344/ 1862] train: loss: 0.0886848
[Epoch 4; Iter  1374/ 1862] train: loss: 0.0025163
[Epoch 4; Iter  1404/ 1862] train: loss: 0.0019410
[Epoch 4; Iter  1434/ 1862] train: loss: 0.0016765
[Epoch 4; Iter  1464/ 1862] train: loss: 0.0017462
[Epoch 4; Iter  1494/ 1862] train: loss: 0.0016813
[Epoch 4; Iter  1524/ 1862] train: loss: 0.0019182
[Epoch 4; Iter  1554/ 1862] train: loss: 0.0022152
[Epoch 4; Iter  1584/ 1862] train: loss: 0.0838448
[Epoch 4; Iter  1614/ 1862] train: loss: 0.0020715
[Epoch 4; Iter  1644/ 1862] train: loss: 0.0021782
[Epoch 4; Iter  1674/ 1862] train: loss: 0.0020599
[Epoch 4; Iter  1704/ 1862] train: loss: 0.0015734
[Epoch 4; Iter  1734/ 1862] train: loss: 0.0018290
[Epoch 4; Iter  1764/ 1862] train: loss: 0.0014914
[Epoch 4; Iter  1794/ 1862] train: loss: 0.0017558
[Epoch 4; Iter  1824/ 1862] train: loss: 0.0020870
[Epoch 4; Iter  1854/ 1862] train: loss: 0.0030400
[Epoch 4] ogbg-molmuv: 0.013014 val loss: 0.013744
[Epoch 4] ogbg-molmuv: 0.012780 test loss: 0.012750
[Epoch 5; Iter    22/ 1862] train: loss: 0.0030923
[Epoch 5; Iter    52/ 1862] train: loss: 0.0025083
[Epoch 5; Iter    82/ 1862] train: loss: 0.2072183
[Epoch 5; Iter   112/ 1862] train: loss: 0.0024986
[Epoch 5; Iter   142/ 1862] train: loss: 0.0024779
[Epoch 5; Iter   172/ 1862] train: loss: 0.0560334
[Epoch 5; Iter   202/ 1862] train: loss: 0.0026843
[Epoch 5; Iter   232/ 1862] train: loss: 0.0702536
[Epoch 5; Iter   262/ 1862] train: loss: 0.0020918
[Epoch 5; Iter   292/ 1862] train: loss: 0.0022249
[Epoch 5; Iter   322/ 1862] train: loss: 0.0016664
[Epoch 5; Iter   352/ 1862] train: loss: 0.0022409
[Epoch 5; Iter   382/ 1862] train: loss: 0.0019949
[Epoch 4; Iter   471/ 2483] train: loss: 0.0020938
[Epoch 4; Iter   501/ 2483] train: loss: 0.0728099
[Epoch 4; Iter   531/ 2483] train: loss: 0.0016729
[Epoch 4; Iter   561/ 2483] train: loss: 0.0016958
[Epoch 4; Iter   591/ 2483] train: loss: 0.0018337
[Epoch 4; Iter   621/ 2483] train: loss: 0.0013823
[Epoch 4; Iter   651/ 2483] train: loss: 0.0014957
[Epoch 4; Iter   681/ 2483] train: loss: 0.0028086
[Epoch 4; Iter   711/ 2483] train: loss: 0.0015786
[Epoch 4; Iter   741/ 2483] train: loss: 0.0013981
[Epoch 4; Iter   771/ 2483] train: loss: 0.0017377
[Epoch 4; Iter   801/ 2483] train: loss: 0.0016280
[Epoch 4; Iter   831/ 2483] train: loss: 0.0016532
[Epoch 4; Iter   861/ 2483] train: loss: 0.0025609
[Epoch 4; Iter   891/ 2483] train: loss: 0.0018795
[Epoch 4; Iter   921/ 2483] train: loss: 0.0019470
[Epoch 4; Iter   951/ 2483] train: loss: 0.0018327
[Epoch 4; Iter   981/ 2483] train: loss: 0.0026978
[Epoch 4; Iter  1011/ 2483] train: loss: 0.0018934
[Epoch 4; Iter  1041/ 2483] train: loss: 0.0804836
[Epoch 4; Iter  1071/ 2483] train: loss: 0.0017978
[Epoch 4; Iter  1101/ 2483] train: loss: 0.0022844
[Epoch 4; Iter  1131/ 2483] train: loss: 0.0019961
[Epoch 4; Iter  1161/ 2483] train: loss: 0.0022911
[Epoch 4; Iter  1191/ 2483] train: loss: 0.0020180
[Epoch 4; Iter  1221/ 2483] train: loss: 0.0017531
[Epoch 4; Iter  1251/ 2483] train: loss: 0.0021740
[Epoch 4; Iter  1281/ 2483] train: loss: 0.0022314
[Epoch 4; Iter  1311/ 2483] train: loss: 0.0021736
[Epoch 4; Iter  1341/ 2483] train: loss: 0.0678278
[Epoch 4; Iter  1371/ 2483] train: loss: 0.0019188
[Epoch 4; Iter  1401/ 2483] train: loss: 0.0019709
[Epoch 4; Iter  1431/ 2483] train: loss: 0.0022084
[Epoch 4; Iter  1461/ 2483] train: loss: 0.0028533
[Epoch 4; Iter  1491/ 2483] train: loss: 0.0896690
[Epoch 4; Iter  1521/ 2483] train: loss: 0.0021832
[Epoch 4; Iter  1551/ 2483] train: loss: 0.0024157
[Epoch 4; Iter  1581/ 2483] train: loss: 0.0018482
[Epoch 4; Iter  1611/ 2483] train: loss: 0.0932712
[Epoch 4; Iter  1641/ 2483] train: loss: 0.0024840
[Epoch 4; Iter  1671/ 2483] train: loss: 0.0022279
[Epoch 4; Iter  1701/ 2483] train: loss: 0.0018565
[Epoch 4; Iter  1731/ 2483] train: loss: 0.0017417
[Epoch 4; Iter  1761/ 2483] train: loss: 0.0017895
[Epoch 4; Iter  1791/ 2483] train: loss: 0.0016696
[Epoch 4; Iter  1821/ 2483] train: loss: 0.0961992
[Epoch 4; Iter  1851/ 2483] train: loss: 0.0020836
[Epoch 4; Iter  1881/ 2483] train: loss: 0.1296226
[Epoch 4; Iter  1911/ 2483] train: loss: 0.0015884
[Epoch 4; Iter  1941/ 2483] train: loss: 0.0016482
[Epoch 4; Iter  1971/ 2483] train: loss: 0.0019092
[Epoch 4; Iter  2001/ 2483] train: loss: 0.0014381
[Epoch 4; Iter  2031/ 2483] train: loss: 0.0803624
[Epoch 4; Iter  2061/ 2483] train: loss: 0.0025356
[Epoch 4; Iter  2091/ 2483] train: loss: 0.0017050
[Epoch 4; Iter  2121/ 2483] train: loss: 0.0017910
[Epoch 4; Iter  2151/ 2483] train: loss: 0.0020517
[Epoch 4; Iter  2181/ 2483] train: loss: 0.0017282
[Epoch 4; Iter  2211/ 2483] train: loss: 0.0015962
[Epoch 4; Iter  2241/ 2483] train: loss: 0.0014161
[Epoch 4; Iter  2271/ 2483] train: loss: 0.0018276
[Epoch 4; Iter  2301/ 2483] train: loss: 0.0016909
[Epoch 4; Iter  2331/ 2483] train: loss: 0.0014634
[Epoch 4; Iter  2361/ 2483] train: loss: 0.0020199
[Epoch 4; Iter  2391/ 2483] train: loss: 0.0014532
[Epoch 4; Iter  2421/ 2483] train: loss: 0.0014802
[Epoch 4; Iter  2451/ 2483] train: loss: 0.0685425
[Epoch 4; Iter  2481/ 2483] train: loss: 0.0025390
[Epoch 4] ogbg-molmuv: 0.027171 val loss: 0.010386
[Epoch 4] ogbg-molmuv: 0.027029 test loss: 0.015184
[Epoch 5; Iter    28/ 2483] train: loss: 0.0841322
[Epoch 5; Iter    58/ 2483] train: loss: 0.0015903
[Epoch 5; Iter    88/ 2483] train: loss: 0.0019318
[Epoch 5; Iter   118/ 2483] train: loss: 0.0017702
[Epoch 5; Iter   148/ 2483] train: loss: 0.0014610
[Epoch 5; Iter   178/ 2483] train: loss: 0.0687799
[Epoch 5; Iter   208/ 2483] train: loss: 0.0016526
[Epoch 5; Iter   238/ 2483] train: loss: 0.0016901
[Epoch 5; Iter   268/ 2483] train: loss: 0.0016098
[Epoch 5; Iter   298/ 2483] train: loss: 0.0016045
[Epoch 5; Iter   328/ 2483] train: loss: 0.1806952
[Epoch 5; Iter   358/ 2483] train: loss: 0.0021433
[Epoch 5; Iter   388/ 2483] train: loss: 0.0019863
[Epoch 5; Iter   418/ 2483] train: loss: 0.0021418
[Epoch 5; Iter   448/ 2483] train: loss: 0.0015897
[Epoch 5; Iter   478/ 2483] train: loss: 0.0014988
[Epoch 5; Iter   508/ 2483] train: loss: 0.0016660
[Epoch 5; Iter   538/ 2483] train: loss: 0.0018360
[Epoch 5; Iter   568/ 2483] train: loss: 0.0015518
[Epoch 5; Iter   598/ 2483] train: loss: 0.0014231
[Epoch 5; Iter   628/ 2483] train: loss: 0.0017215
[Epoch 5; Iter   658/ 2483] train: loss: 0.0815154
[Epoch 5; Iter   688/ 2483] train: loss: 0.0014228
[Epoch 5; Iter   718/ 2483] train: loss: 0.0013773
[Epoch 5; Iter   748/ 2483] train: loss: 0.0015852
[Epoch 5; Iter   778/ 2483] train: loss: 0.0022018
[Epoch 5; Iter   808/ 2483] train: loss: 0.0661840
[Epoch 5; Iter   838/ 2483] train: loss: 0.0030120
[Epoch 5; Iter   868/ 2483] train: loss: 0.0018471
[Epoch 5; Iter   898/ 2483] train: loss: 0.0032821
[Epoch 5; Iter   928/ 2483] train: loss: 0.0025635
[Epoch 5; Iter   958/ 2483] train: loss: 0.0854692
[Epoch 5; Iter   988/ 2483] train: loss: 0.0022651
[Epoch 5; Iter  1018/ 2483] train: loss: 0.0031791
[Epoch 5; Iter  1048/ 2483] train: loss: 0.0025536
[Epoch 5; Iter  1078/ 2483] train: loss: 0.0017575
[Epoch 5; Iter  1108/ 2483] train: loss: 0.0024899
[Epoch 5; Iter  1138/ 2483] train: loss: 0.0017410
[Epoch 5; Iter  1168/ 2483] train: loss: 0.0026548
[Epoch 5; Iter  1198/ 2483] train: loss: 0.0019575
[Epoch 5; Iter  1228/ 2483] train: loss: 0.0801533
[Epoch 5; Iter  1258/ 2483] train: loss: 0.0619061
[Epoch 5; Iter  1288/ 2483] train: loss: 0.0018821
[Epoch 5; Iter  1318/ 2483] train: loss: 0.0775778
[Epoch 5; Iter  1348/ 2483] train: loss: 0.0026448
[Epoch 5; Iter  1378/ 2483] train: loss: 0.0019730
[Epoch 5; Iter  1408/ 2483] train: loss: 0.0723873
[Epoch 5; Iter  1438/ 2483] train: loss: 0.0028590
[Epoch 5; Iter  1468/ 2483] train: loss: 0.0022245
[Epoch 5; Iter  1498/ 2483] train: loss: 0.0020230
[Epoch 5; Iter  1528/ 2483] train: loss: 0.0018151
[Epoch 5; Iter  1558/ 2483] train: loss: 0.0019283
[Epoch 5; Iter  1588/ 2483] train: loss: 0.0016793
[Epoch 5; Iter  1618/ 2483] train: loss: 0.0014402
[Epoch 5; Iter  1648/ 2483] train: loss: 0.0023663
[Epoch 5; Iter  1678/ 2483] train: loss: 0.0024207
[Epoch 5; Iter  1708/ 2483] train: loss: 0.0018988
[Epoch 5; Iter  1738/ 2483] train: loss: 0.0021351
[Epoch 5; Iter  1768/ 2483] train: loss: 0.0022958
[Epoch 5; Iter  1798/ 2483] train: loss: 0.0020505
[Epoch 5; Iter  1828/ 2483] train: loss: 0.0017805
[Epoch 5; Iter  1858/ 2483] train: loss: 0.0019262
[Epoch 5; Iter  1888/ 2483] train: loss: 0.0016588
[Epoch 5; Iter  1918/ 2483] train: loss: 0.0156036
[Epoch 5; Iter  1948/ 2483] train: loss: 0.0023287
[Epoch 5; Iter  1978/ 2483] train: loss: 0.0016686
[Epoch 5; Iter  2008/ 2483] train: loss: 0.0013862
[Epoch 5; Iter  2038/ 2483] train: loss: 0.0017662
[Epoch 5; Iter  2068/ 2483] train: loss: 0.0704885
[Epoch 5; Iter  2098/ 2483] train: loss: 0.0013569
[Epoch 5; Iter  2128/ 2483] train: loss: 0.0018720
[Epoch 5; Iter  2158/ 2483] train: loss: 0.0016130
[Epoch 5; Iter  2188/ 2483] train: loss: 0.0019278
[Epoch 5; Iter  2218/ 2483] train: loss: 0.0014495
[Epoch 5; Iter  2248/ 2483] train: loss: 0.0017048
[Epoch 5; Iter  2278/ 2483] train: loss: 0.0014712
[Epoch 5; Iter  2308/ 2483] train: loss: 0.0020322
[Epoch 5; Iter  2338/ 2483] train: loss: 0.0016709
[Epoch 5; Iter  2368/ 2483] train: loss: 0.0014160
[Epoch 5; Iter  2398/ 2483] train: loss: 0.0018691
[Epoch 5; Iter  2428/ 2483] train: loss: 0.0023834
[Epoch 5; Iter  2458/ 2483] train: loss: 0.0018889
[Epoch 5] ogbg-molmuv: 0.010308 val loss: 0.011015
[Epoch 5] ogbg-molmuv: 0.028940 test loss: 0.015587
[Epoch 6; Iter     5/ 2483] train: loss: 0.0020157
[Epoch 6; Iter    35/ 2483] train: loss: 0.0029952
[Epoch 6; Iter    65/ 2483] train: loss: 0.1287516
[Epoch 6; Iter    95/ 2483] train: loss: 0.0018398
[Epoch 6; Iter   125/ 2483] train: loss: 0.0033810
[Epoch 6; Iter   155/ 2483] train: loss: 0.0019347
[Epoch 4; Iter   471/ 2483] train: loss: 0.0024915
[Epoch 4; Iter   501/ 2483] train: loss: 0.0018086
[Epoch 4; Iter   531/ 2483] train: loss: 0.0017818
[Epoch 4; Iter   561/ 2483] train: loss: 0.0014529
[Epoch 4; Iter   591/ 2483] train: loss: 0.1001296
[Epoch 4; Iter   621/ 2483] train: loss: 0.0018144
[Epoch 4; Iter   651/ 2483] train: loss: 0.0018555
[Epoch 4; Iter   681/ 2483] train: loss: 0.0666622
[Epoch 4; Iter   711/ 2483] train: loss: 0.0018706
[Epoch 4; Iter   741/ 2483] train: loss: 0.0029480
[Epoch 4; Iter   771/ 2483] train: loss: 0.0040306
[Epoch 4; Iter   801/ 2483] train: loss: 0.0031074
[Epoch 4; Iter   831/ 2483] train: loss: 0.0018743
[Epoch 4; Iter   861/ 2483] train: loss: 0.0026151
[Epoch 4; Iter   891/ 2483] train: loss: 0.2729058
[Epoch 4; Iter   921/ 2483] train: loss: 0.0027072
[Epoch 4; Iter   951/ 2483] train: loss: 0.0026193
[Epoch 4; Iter   981/ 2483] train: loss: 0.0024044
[Epoch 4; Iter  1011/ 2483] train: loss: 0.0022703
[Epoch 4; Iter  1041/ 2483] train: loss: 0.0695760
[Epoch 4; Iter  1071/ 2483] train: loss: 0.0020137
[Epoch 4; Iter  1101/ 2483] train: loss: 0.1146563
[Epoch 4; Iter  1131/ 2483] train: loss: 0.0018141
[Epoch 4; Iter  1161/ 2483] train: loss: 0.0665887
[Epoch 4; Iter  1191/ 2483] train: loss: 0.0025635
[Epoch 4; Iter  1221/ 2483] train: loss: 0.0664559
[Epoch 4; Iter  1251/ 2483] train: loss: 0.0020621
[Epoch 4; Iter  1281/ 2483] train: loss: 0.0019250
[Epoch 4; Iter  1311/ 2483] train: loss: 0.1041548
[Epoch 4; Iter  1341/ 2483] train: loss: 0.0029616
[Epoch 4; Iter  1371/ 2483] train: loss: 0.0032090
[Epoch 4; Iter  1401/ 2483] train: loss: 0.0034442
[Epoch 4; Iter  1431/ 2483] train: loss: 0.0019783
[Epoch 4; Iter  1461/ 2483] train: loss: 0.0016077
[Epoch 4; Iter  1491/ 2483] train: loss: 0.0017739
[Epoch 4; Iter  1521/ 2483] train: loss: 0.0026345
[Epoch 4; Iter  1551/ 2483] train: loss: 0.0790807
[Epoch 4; Iter  1581/ 2483] train: loss: 0.0016548
[Epoch 4; Iter  1611/ 2483] train: loss: 0.0017327
[Epoch 4; Iter  1641/ 2483] train: loss: 0.0019914
[Epoch 4; Iter  1671/ 2483] train: loss: 0.0020446
[Epoch 4; Iter  1701/ 2483] train: loss: 0.0025396
[Epoch 4; Iter  1731/ 2483] train: loss: 0.0017683
[Epoch 4; Iter  1761/ 2483] train: loss: 0.0590610
[Epoch 4; Iter  1791/ 2483] train: loss: 0.0015617
[Epoch 4; Iter  1821/ 2483] train: loss: 0.0021182
[Epoch 4; Iter  1851/ 2483] train: loss: 0.0025963
[Epoch 4; Iter  1881/ 2483] train: loss: 0.0018203
[Epoch 4; Iter  1911/ 2483] train: loss: 0.0024371
[Epoch 4; Iter  1941/ 2483] train: loss: 0.0021826
[Epoch 4; Iter  1971/ 2483] train: loss: 0.0017388
[Epoch 4; Iter  2001/ 2483] train: loss: 0.0021034
[Epoch 4; Iter  2031/ 2483] train: loss: 0.0020311
[Epoch 4; Iter  2061/ 2483] train: loss: 0.0017834
[Epoch 4; Iter  2091/ 2483] train: loss: 0.0013714
[Epoch 4; Iter  2121/ 2483] train: loss: 0.0014162
[Epoch 4; Iter  2151/ 2483] train: loss: 0.0015673
[Epoch 4; Iter  2181/ 2483] train: loss: 0.0012637
[Epoch 4; Iter  2211/ 2483] train: loss: 0.0013808
[Epoch 4; Iter  2241/ 2483] train: loss: 0.0014689
[Epoch 4; Iter  2271/ 2483] train: loss: 0.0023279
[Epoch 4; Iter  2301/ 2483] train: loss: 0.0992061
[Epoch 4; Iter  2331/ 2483] train: loss: 0.0017881
[Epoch 4; Iter  2361/ 2483] train: loss: 0.0014301
[Epoch 4; Iter  2391/ 2483] train: loss: 0.0015011
[Epoch 4; Iter  2421/ 2483] train: loss: 0.0016348
[Epoch 4; Iter  2451/ 2483] train: loss: 0.0016286
[Epoch 4; Iter  2481/ 2483] train: loss: 0.0015125
[Epoch 4] ogbg-molmuv: 0.019950 val loss: 0.010350
[Epoch 4] ogbg-molmuv: 0.012767 test loss: 0.015256
[Epoch 5; Iter    28/ 2483] train: loss: 0.0022091
[Epoch 5; Iter    58/ 2483] train: loss: 0.0017477
[Epoch 5; Iter    88/ 2483] train: loss: 0.0029950
[Epoch 5; Iter   118/ 2483] train: loss: 0.0015400
[Epoch 5; Iter   148/ 2483] train: loss: 0.0011493
[Epoch 5; Iter   178/ 2483] train: loss: 0.0013029
[Epoch 5; Iter   208/ 2483] train: loss: 0.0011989
[Epoch 5; Iter   238/ 2483] train: loss: 0.0013559
[Epoch 5; Iter   268/ 2483] train: loss: 0.0787618
[Epoch 5; Iter   298/ 2483] train: loss: 0.0017388
[Epoch 5; Iter   328/ 2483] train: loss: 0.0017527
[Epoch 5; Iter   358/ 2483] train: loss: 0.0012784
[Epoch 5; Iter   388/ 2483] train: loss: 0.0016128
[Epoch 5; Iter   418/ 2483] train: loss: 0.0029949
[Epoch 5; Iter   448/ 2483] train: loss: 0.0017930
[Epoch 5; Iter   478/ 2483] train: loss: 0.0776395
[Epoch 5; Iter   508/ 2483] train: loss: 0.0020034
[Epoch 5; Iter   538/ 2483] train: loss: 0.0678998
[Epoch 5; Iter   568/ 2483] train: loss: 0.0033765
[Epoch 5; Iter   598/ 2483] train: loss: 0.0018426
[Epoch 5; Iter   628/ 2483] train: loss: 0.0023828
[Epoch 5; Iter   658/ 2483] train: loss: 0.0016302
[Epoch 5; Iter   688/ 2483] train: loss: 0.0773915
[Epoch 5; Iter   718/ 2483] train: loss: 0.0013472
[Epoch 5; Iter   748/ 2483] train: loss: 0.0017627
[Epoch 5; Iter   778/ 2483] train: loss: 0.0855742
[Epoch 5; Iter   808/ 2483] train: loss: 0.0028744
[Epoch 5; Iter   838/ 2483] train: loss: 0.0765354
[Epoch 5; Iter   868/ 2483] train: loss: 0.0659356
[Epoch 5; Iter   898/ 2483] train: loss: 0.0024833
[Epoch 5; Iter   928/ 2483] train: loss: 0.0023788
[Epoch 5; Iter   958/ 2483] train: loss: 0.0013711
[Epoch 5; Iter   988/ 2483] train: loss: 0.0015385
[Epoch 5; Iter  1018/ 2483] train: loss: 0.0025057
[Epoch 5; Iter  1048/ 2483] train: loss: 0.0015840
[Epoch 5; Iter  1078/ 2483] train: loss: 0.0773360
[Epoch 5; Iter  1108/ 2483] train: loss: 0.0024813
[Epoch 5; Iter  1138/ 2483] train: loss: 0.0017834
[Epoch 5; Iter  1168/ 2483] train: loss: 0.0016850
[Epoch 5; Iter  1198/ 2483] train: loss: 0.0012554
[Epoch 5; Iter  1228/ 2483] train: loss: 0.0021679
[Epoch 5; Iter  1258/ 2483] train: loss: 0.0019690
[Epoch 5; Iter  1288/ 2483] train: loss: 0.0023556
[Epoch 5; Iter  1318/ 2483] train: loss: 0.0020682
[Epoch 5; Iter  1348/ 2483] train: loss: 0.0021792
[Epoch 5; Iter  1378/ 2483] train: loss: 0.0635260
[Epoch 5; Iter  1408/ 2483] train: loss: 0.0019069
[Epoch 5; Iter  1438/ 2483] train: loss: 0.0019918
[Epoch 5; Iter  1468/ 2483] train: loss: 0.0022290
[Epoch 5; Iter  1498/ 2483] train: loss: 0.0013510
[Epoch 5; Iter  1528/ 2483] train: loss: 0.0018427
[Epoch 5; Iter  1558/ 2483] train: loss: 0.0017771
[Epoch 5; Iter  1588/ 2483] train: loss: 0.0909804
[Epoch 5; Iter  1618/ 2483] train: loss: 0.0018956
[Epoch 5; Iter  1648/ 2483] train: loss: 0.0016461
[Epoch 5; Iter  1678/ 2483] train: loss: 0.0018905
[Epoch 5; Iter  1708/ 2483] train: loss: 0.0016901
[Epoch 5; Iter  1738/ 2483] train: loss: 0.0018563
[Epoch 5; Iter  1768/ 2483] train: loss: 0.0018053
[Epoch 5; Iter  1798/ 2483] train: loss: 0.0018381
[Epoch 5; Iter  1828/ 2483] train: loss: 0.0018954
[Epoch 5; Iter  1858/ 2483] train: loss: 0.0016906
[Epoch 5; Iter  1888/ 2483] train: loss: 0.0014320
[Epoch 5; Iter  1918/ 2483] train: loss: 0.0017944
[Epoch 5; Iter  1948/ 2483] train: loss: 0.0015374
[Epoch 5; Iter  1978/ 2483] train: loss: 0.0021567
[Epoch 5; Iter  2008/ 2483] train: loss: 0.0012396
[Epoch 5; Iter  2038/ 2483] train: loss: 0.0013195
[Epoch 5; Iter  2068/ 2483] train: loss: 0.0015932
[Epoch 5; Iter  2098/ 2483] train: loss: 0.0014443
[Epoch 5; Iter  2128/ 2483] train: loss: 0.0734322
[Epoch 5; Iter  2158/ 2483] train: loss: 0.0886788
[Epoch 5; Iter  2188/ 2483] train: loss: 0.0014228
[Epoch 5; Iter  2218/ 2483] train: loss: 0.0018838
[Epoch 5; Iter  2248/ 2483] train: loss: 0.0019017
[Epoch 5; Iter  2278/ 2483] train: loss: 0.0019274
[Epoch 5; Iter  2308/ 2483] train: loss: 0.0017284
[Epoch 5; Iter  2338/ 2483] train: loss: 0.0016203
[Epoch 5; Iter  2368/ 2483] train: loss: 0.0552554
[Epoch 5; Iter  2398/ 2483] train: loss: 0.0020678
[Epoch 5; Iter  2428/ 2483] train: loss: 0.0024025
[Epoch 5; Iter  2458/ 2483] train: loss: 0.0025829
[Epoch 5] ogbg-molmuv: 0.028677 val loss: 0.010513
[Epoch 5] ogbg-molmuv: 0.023285 test loss: 0.014906
[Epoch 6; Iter     5/ 2483] train: loss: 0.0480148
[Epoch 6; Iter    35/ 2483] train: loss: 0.0022446
[Epoch 6; Iter    65/ 2483] train: loss: 0.0018593
[Epoch 6; Iter    95/ 2483] train: loss: 0.0019138
[Epoch 6; Iter   125/ 2483] train: loss: 0.0017258
[Epoch 6; Iter   155/ 2483] train: loss: 0.0015372
[Epoch 4; Iter   471/ 2483] train: loss: 0.0019048
[Epoch 4; Iter   501/ 2483] train: loss: 0.0020236
[Epoch 4; Iter   531/ 2483] train: loss: 0.2380259
[Epoch 4; Iter   561/ 2483] train: loss: 0.0025289
[Epoch 4; Iter   591/ 2483] train: loss: 0.0020393
[Epoch 4; Iter   621/ 2483] train: loss: 0.0019529
[Epoch 4; Iter   651/ 2483] train: loss: 0.0019016
[Epoch 4; Iter   681/ 2483] train: loss: 0.0017333
[Epoch 4; Iter   711/ 2483] train: loss: 0.0016782
[Epoch 4; Iter   741/ 2483] train: loss: 0.0018597
[Epoch 4; Iter   771/ 2483] train: loss: 0.0017176
[Epoch 4; Iter   801/ 2483] train: loss: 0.0012590
[Epoch 4; Iter   831/ 2483] train: loss: 0.0015744
[Epoch 4; Iter   861/ 2483] train: loss: 0.0015359
[Epoch 4; Iter   891/ 2483] train: loss: 0.0016574
[Epoch 4; Iter   921/ 2483] train: loss: 0.0017951
[Epoch 4; Iter   951/ 2483] train: loss: 0.0022251
[Epoch 4; Iter   981/ 2483] train: loss: 0.1054000
[Epoch 4; Iter  1011/ 2483] train: loss: 0.0020178
[Epoch 4; Iter  1041/ 2483] train: loss: 0.0019478
[Epoch 4; Iter  1071/ 2483] train: loss: 0.0024496
[Epoch 4; Iter  1101/ 2483] train: loss: 0.0022607
[Epoch 4; Iter  1131/ 2483] train: loss: 0.0017865
[Epoch 4; Iter  1161/ 2483] train: loss: 0.0818482
[Epoch 4; Iter  1191/ 2483] train: loss: 0.0018663
[Epoch 4; Iter  1221/ 2483] train: loss: 0.0854902
[Epoch 4; Iter  1251/ 2483] train: loss: 0.0805596
[Epoch 4; Iter  1281/ 2483] train: loss: 0.0036307
[Epoch 4; Iter  1311/ 2483] train: loss: 0.0022002
[Epoch 4; Iter  1341/ 2483] train: loss: 0.0662430
[Epoch 4; Iter  1371/ 2483] train: loss: 0.0023237
[Epoch 4; Iter  1401/ 2483] train: loss: 0.0027360
[Epoch 4; Iter  1431/ 2483] train: loss: 0.0021222
[Epoch 4; Iter  1461/ 2483] train: loss: 0.0868233
[Epoch 4; Iter  1491/ 2483] train: loss: 0.0013195
[Epoch 4; Iter  1521/ 2483] train: loss: 0.0013970
[Epoch 4; Iter  1551/ 2483] train: loss: 0.0928428
[Epoch 4; Iter  1581/ 2483] train: loss: 0.0017356
[Epoch 4; Iter  1611/ 2483] train: loss: 0.0020610
[Epoch 4; Iter  1641/ 2483] train: loss: 0.0022090
[Epoch 4; Iter  1671/ 2483] train: loss: 0.0027575
[Epoch 4; Iter  1701/ 2483] train: loss: 0.0041507
[Epoch 4; Iter  1731/ 2483] train: loss: 0.0032070
[Epoch 4; Iter  1761/ 2483] train: loss: 0.0024827
[Epoch 4; Iter  1791/ 2483] train: loss: 0.0023107
[Epoch 4; Iter  1821/ 2483] train: loss: 0.0025743
[Epoch 4; Iter  1851/ 2483] train: loss: 0.0022653
[Epoch 4; Iter  1881/ 2483] train: loss: 0.0018042
[Epoch 4; Iter  1911/ 2483] train: loss: 0.0017107
[Epoch 4; Iter  1941/ 2483] train: loss: 0.0016270
[Epoch 4; Iter  1971/ 2483] train: loss: 0.0022998
[Epoch 4; Iter  2001/ 2483] train: loss: 0.0015403
[Epoch 4; Iter  2031/ 2483] train: loss: 0.0017587
[Epoch 4; Iter  2061/ 2483] train: loss: 0.0017942
[Epoch 4; Iter  2091/ 2483] train: loss: 0.0016326
[Epoch 4; Iter  2121/ 2483] train: loss: 0.0015313
[Epoch 4; Iter  2151/ 2483] train: loss: 0.0013574
[Epoch 4; Iter  2181/ 2483] train: loss: 0.0011371
[Epoch 4; Iter  2211/ 2483] train: loss: 0.0016584
[Epoch 4; Iter  2241/ 2483] train: loss: 0.0013654
[Epoch 4; Iter  2271/ 2483] train: loss: 0.0013528
[Epoch 4; Iter  2301/ 2483] train: loss: 0.0013121
[Epoch 4; Iter  2331/ 2483] train: loss: 0.0016072
[Epoch 4; Iter  2361/ 2483] train: loss: 0.0810723
[Epoch 4; Iter  2391/ 2483] train: loss: 0.0017707
[Epoch 4; Iter  2421/ 2483] train: loss: 0.0763329
[Epoch 4; Iter  2451/ 2483] train: loss: 0.0018237
[Epoch 4; Iter  2481/ 2483] train: loss: 0.0021118
[Epoch 4] ogbg-molmuv: 0.013846 val loss: 0.011049
[Epoch 4] ogbg-molmuv: 0.015830 test loss: 0.015166
[Epoch 5; Iter    28/ 2483] train: loss: 0.0018682
[Epoch 5; Iter    58/ 2483] train: loss: 0.0026483
[Epoch 5; Iter    88/ 2483] train: loss: 0.0018564
[Epoch 5; Iter   118/ 2483] train: loss: 0.0022551
[Epoch 5; Iter   148/ 2483] train: loss: 0.0026562
[Epoch 5; Iter   178/ 2483] train: loss: 0.0038899
[Epoch 5; Iter   208/ 2483] train: loss: 0.0502322
[Epoch 5; Iter   238/ 2483] train: loss: 0.0020288
[Epoch 5; Iter   268/ 2483] train: loss: 0.0019430
[Epoch 5; Iter   298/ 2483] train: loss: 0.0013516
[Epoch 5; Iter   328/ 2483] train: loss: 0.0014619
[Epoch 5; Iter   358/ 2483] train: loss: 0.0025896
[Epoch 5; Iter   388/ 2483] train: loss: 0.0740200
[Epoch 5; Iter   418/ 2483] train: loss: 0.0016146
[Epoch 5; Iter   448/ 2483] train: loss: 0.0768282
[Epoch 5; Iter   478/ 2483] train: loss: 0.0705716
[Epoch 5; Iter   508/ 2483] train: loss: 0.1167983
[Epoch 5; Iter   538/ 2483] train: loss: 0.0022298
[Epoch 5; Iter   568/ 2483] train: loss: 0.0019094
[Epoch 5; Iter   598/ 2483] train: loss: 0.0019204
[Epoch 5; Iter   628/ 2483] train: loss: 0.0019550
[Epoch 5; Iter   658/ 2483] train: loss: 0.0018654
[Epoch 5; Iter   688/ 2483] train: loss: 0.0019034
[Epoch 5; Iter   718/ 2483] train: loss: 0.0752136
[Epoch 5; Iter   748/ 2483] train: loss: 0.0032089
[Epoch 5; Iter   778/ 2483] train: loss: 0.0017643
[Epoch 5; Iter   808/ 2483] train: loss: 0.0018309
[Epoch 5; Iter   838/ 2483] train: loss: 0.0021002
[Epoch 5; Iter   868/ 2483] train: loss: 0.0014155
[Epoch 5; Iter   898/ 2483] train: loss: 0.0019505
[Epoch 5; Iter   928/ 2483] train: loss: 0.0016120
[Epoch 5; Iter   958/ 2483] train: loss: 0.0014731
[Epoch 5; Iter   988/ 2483] train: loss: 0.0016355
[Epoch 5; Iter  1018/ 2483] train: loss: 0.0015975
[Epoch 5; Iter  1048/ 2483] train: loss: 0.0016769
[Epoch 5; Iter  1078/ 2483] train: loss: 0.0018957
[Epoch 5; Iter  1108/ 2483] train: loss: 0.0016406
[Epoch 5; Iter  1138/ 2483] train: loss: 0.0021803
[Epoch 5; Iter  1168/ 2483] train: loss: 0.0017965
[Epoch 5; Iter  1198/ 2483] train: loss: 0.0016558
[Epoch 5; Iter  1228/ 2483] train: loss: 0.0015284
[Epoch 5; Iter  1258/ 2483] train: loss: 0.0013175
[Epoch 5; Iter  1288/ 2483] train: loss: 0.0013939
[Epoch 5; Iter  1318/ 2483] train: loss: 0.0031035
[Epoch 5; Iter  1348/ 2483] train: loss: 0.0020532
[Epoch 5; Iter  1378/ 2483] train: loss: 0.0789875
[Epoch 5; Iter  1408/ 2483] train: loss: 0.0028548
[Epoch 5; Iter  1438/ 2483] train: loss: 0.0021162
[Epoch 5; Iter  1468/ 2483] train: loss: 0.0776033
[Epoch 5; Iter  1498/ 2483] train: loss: 0.0029530
[Epoch 5; Iter  1528/ 2483] train: loss: 0.0020260
[Epoch 5; Iter  1558/ 2483] train: loss: 0.0020318
[Epoch 5; Iter  1588/ 2483] train: loss: 0.0022631
[Epoch 5; Iter  1618/ 2483] train: loss: 0.0023130
[Epoch 5; Iter  1648/ 2483] train: loss: 0.0021912
[Epoch 5; Iter  1678/ 2483] train: loss: 0.0023996
[Epoch 5; Iter  1708/ 2483] train: loss: 0.0030372
[Epoch 5; Iter  1738/ 2483] train: loss: 0.0017494
[Epoch 5; Iter  1768/ 2483] train: loss: 0.0016284
[Epoch 5; Iter  1798/ 2483] train: loss: 0.0013143
[Epoch 5; Iter  1828/ 2483] train: loss: 0.0012804
[Epoch 5; Iter  1858/ 2483] train: loss: 0.0014612
[Epoch 5; Iter  1888/ 2483] train: loss: 0.0996910
[Epoch 5; Iter  1918/ 2483] train: loss: 0.0015363
[Epoch 5; Iter  1948/ 2483] train: loss: 0.0013306
[Epoch 5; Iter  1978/ 2483] train: loss: 0.0018759
[Epoch 5; Iter  2008/ 2483] train: loss: 0.0019414
[Epoch 5; Iter  2038/ 2483] train: loss: 0.0018587
[Epoch 5; Iter  2068/ 2483] train: loss: 0.0021392
[Epoch 5; Iter  2098/ 2483] train: loss: 0.0017118
[Epoch 5; Iter  2128/ 2483] train: loss: 0.0924279
[Epoch 5; Iter  2158/ 2483] train: loss: 0.0020927
[Epoch 5; Iter  2188/ 2483] train: loss: 0.0018977
[Epoch 5; Iter  2218/ 2483] train: loss: 0.0717404
[Epoch 5; Iter  2248/ 2483] train: loss: 0.0019905
[Epoch 5; Iter  2278/ 2483] train: loss: 0.0020254
[Epoch 5; Iter  2308/ 2483] train: loss: 0.0022660
[Epoch 5; Iter  2338/ 2483] train: loss: 0.0030884
[Epoch 5; Iter  2368/ 2483] train: loss: 0.0022078
[Epoch 5; Iter  2398/ 2483] train: loss: 0.0020728
[Epoch 5; Iter  2428/ 2483] train: loss: 0.0019847
[Epoch 5; Iter  2458/ 2483] train: loss: 0.0033562
[Epoch 5] ogbg-molmuv: 0.025056 val loss: 0.010562
[Epoch 5] ogbg-molmuv: 0.018154 test loss: 0.014712
[Epoch 6; Iter     5/ 2483] train: loss: 0.0019295
[Epoch 6; Iter    35/ 2483] train: loss: 0.0017027
[Epoch 6; Iter    65/ 2483] train: loss: 0.0899432
[Epoch 6; Iter    95/ 2483] train: loss: 0.0026614
[Epoch 6; Iter   125/ 2483] train: loss: 0.0032014
[Epoch 6; Iter   155/ 2483] train: loss: 0.0021708
[Epoch 4; Iter  1404/ 2172] train: loss: 0.0018158
[Epoch 4; Iter  1434/ 2172] train: loss: 0.0022249
[Epoch 4; Iter  1464/ 2172] train: loss: 0.0022790
[Epoch 4; Iter  1494/ 2172] train: loss: 0.0020070
[Epoch 4; Iter  1524/ 2172] train: loss: 0.0851485
[Epoch 4; Iter  1554/ 2172] train: loss: 0.0029509
[Epoch 4; Iter  1584/ 2172] train: loss: 0.0021032
[Epoch 4; Iter  1614/ 2172] train: loss: 0.0017627
[Epoch 4; Iter  1644/ 2172] train: loss: 0.0016979
[Epoch 4; Iter  1674/ 2172] train: loss: 0.0016487
[Epoch 4; Iter  1704/ 2172] train: loss: 0.0020814
[Epoch 4; Iter  1734/ 2172] train: loss: 0.0017677
[Epoch 4; Iter  1764/ 2172] train: loss: 0.0017288
[Epoch 4; Iter  1794/ 2172] train: loss: 0.0018283
[Epoch 4; Iter  1824/ 2172] train: loss: 0.0020285
[Epoch 4; Iter  1854/ 2172] train: loss: 0.0020084
[Epoch 4; Iter  1884/ 2172] train: loss: 0.0590662
[Epoch 4; Iter  1914/ 2172] train: loss: 0.0018831
[Epoch 4; Iter  1944/ 2172] train: loss: 0.0030096
[Epoch 4; Iter  1974/ 2172] train: loss: 0.0738776
[Epoch 4; Iter  2004/ 2172] train: loss: 0.0014815
[Epoch 4; Iter  2034/ 2172] train: loss: 0.0014117
[Epoch 4; Iter  2064/ 2172] train: loss: 0.0876295
[Epoch 4; Iter  2094/ 2172] train: loss: 0.0015019
[Epoch 4; Iter  2124/ 2172] train: loss: 0.0018536
[Epoch 4; Iter  2154/ 2172] train: loss: 0.0017358
[Epoch 4] ogbg-molmuv: 0.011976 val loss: 0.012560
[Epoch 4] ogbg-molmuv: 0.013550 test loss: 0.014219
[Epoch 5; Iter    12/ 2172] train: loss: 0.0709605
[Epoch 5; Iter    42/ 2172] train: loss: 0.0015502
[Epoch 5; Iter    72/ 2172] train: loss: 0.0015582
[Epoch 5; Iter   102/ 2172] train: loss: 0.0016944
[Epoch 5; Iter   132/ 2172] train: loss: 0.0018132
[Epoch 5; Iter   162/ 2172] train: loss: 0.0044055
[Epoch 5; Iter   192/ 2172] train: loss: 0.0022349
[Epoch 5; Iter   222/ 2172] train: loss: 0.0017948
[Epoch 5; Iter   252/ 2172] train: loss: 0.0017606
[Epoch 5; Iter   282/ 2172] train: loss: 0.0018618
[Epoch 5; Iter   312/ 2172] train: loss: 0.0021146
[Epoch 5; Iter   342/ 2172] train: loss: 0.0019429
[Epoch 5; Iter   372/ 2172] train: loss: 0.0019036
[Epoch 5; Iter   402/ 2172] train: loss: 0.0021242
[Epoch 5; Iter   432/ 2172] train: loss: 0.0027284
[Epoch 5; Iter   462/ 2172] train: loss: 0.0021873
[Epoch 5; Iter   492/ 2172] train: loss: 0.0021503
[Epoch 5; Iter   522/ 2172] train: loss: 0.0016198
[Epoch 5; Iter   552/ 2172] train: loss: 0.0767036
[Epoch 5; Iter   582/ 2172] train: loss: 0.0824537
[Epoch 5; Iter   612/ 2172] train: loss: 0.0020330
[Epoch 5; Iter   642/ 2172] train: loss: 0.0544725
[Epoch 5; Iter   672/ 2172] train: loss: 0.0017422
[Epoch 5; Iter   702/ 2172] train: loss: 0.0028767
[Epoch 5; Iter   732/ 2172] train: loss: 0.0021597
[Epoch 5; Iter   762/ 2172] train: loss: 0.0024308
[Epoch 5; Iter   792/ 2172] train: loss: 0.0017668
[Epoch 5; Iter   822/ 2172] train: loss: 0.0017917
[Epoch 5; Iter   852/ 2172] train: loss: 0.0796869
[Epoch 5; Iter   882/ 2172] train: loss: 0.0013925
[Epoch 5; Iter   912/ 2172] train: loss: 0.0021207
[Epoch 5; Iter   942/ 2172] train: loss: 0.0986070
[Epoch 5; Iter   972/ 2172] train: loss: 0.0014747
[Epoch 5; Iter  1002/ 2172] train: loss: 0.0012561
[Epoch 5; Iter  1032/ 2172] train: loss: 0.0012683
[Epoch 5; Iter  1062/ 2172] train: loss: 0.0013606
[Epoch 5; Iter  1092/ 2172] train: loss: 0.0882812
[Epoch 5; Iter  1122/ 2172] train: loss: 0.0015766
[Epoch 5; Iter  1152/ 2172] train: loss: 0.0011846
[Epoch 5; Iter  1182/ 2172] train: loss: 0.0014984
[Epoch 5; Iter  1212/ 2172] train: loss: 0.0837309
[Epoch 5; Iter  1242/ 2172] train: loss: 0.0020992
[Epoch 5; Iter  1272/ 2172] train: loss: 0.0015987
[Epoch 5; Iter  1302/ 2172] train: loss: 0.0015501
[Epoch 5; Iter  1332/ 2172] train: loss: 0.0963025
[Epoch 5; Iter  1362/ 2172] train: loss: 0.0023305
[Epoch 5; Iter  1392/ 2172] train: loss: 0.0027258
[Epoch 5; Iter  1422/ 2172] train: loss: 0.0022274
[Epoch 5; Iter  1452/ 2172] train: loss: 0.0022832
[Epoch 5; Iter  1482/ 2172] train: loss: 0.0016951
[Epoch 5; Iter  1512/ 2172] train: loss: 0.0018639
[Epoch 5; Iter  1542/ 2172] train: loss: 0.0017959
[Epoch 5; Iter  1572/ 2172] train: loss: 0.0877233
[Epoch 5; Iter  1602/ 2172] train: loss: 0.0895719
[Epoch 5; Iter  1632/ 2172] train: loss: 0.0018514
[Epoch 5; Iter  1662/ 2172] train: loss: 0.0022133
[Epoch 5; Iter  1692/ 2172] train: loss: 0.0774958
[Epoch 5; Iter  1722/ 2172] train: loss: 0.0033918
[Epoch 5; Iter  1752/ 2172] train: loss: 0.0026861
[Epoch 5; Iter  1782/ 2172] train: loss: 0.0022503
[Epoch 5; Iter  1812/ 2172] train: loss: 0.0021792
[Epoch 5; Iter  1842/ 2172] train: loss: 0.0644088
[Epoch 5; Iter  1872/ 2172] train: loss: 0.0812243
[Epoch 5; Iter  1902/ 2172] train: loss: 0.0835480
[Epoch 5; Iter  1932/ 2172] train: loss: 0.0019208
[Epoch 5; Iter  1962/ 2172] train: loss: 0.0019804
[Epoch 5; Iter  1992/ 2172] train: loss: 0.0018328
[Epoch 5; Iter  2022/ 2172] train: loss: 0.0014942
[Epoch 5; Iter  2052/ 2172] train: loss: 0.0014775
[Epoch 5; Iter  2082/ 2172] train: loss: 0.0013909
[Epoch 5; Iter  2112/ 2172] train: loss: 0.0016076
[Epoch 5; Iter  2142/ 2172] train: loss: 0.0022030
[Epoch 5; Iter  2172/ 2172] train: loss: 0.0020183
[Epoch 5] ogbg-molmuv: 0.029606 val loss: 0.012114
[Epoch 5] ogbg-molmuv: 0.025958 test loss: 0.013988
[Epoch 6; Iter    30/ 2172] train: loss: 0.0020591
[Epoch 6; Iter    60/ 2172] train: loss: 0.0018299
[Epoch 6; Iter    90/ 2172] train: loss: 0.0028460
[Epoch 6; Iter   120/ 2172] train: loss: 0.0021753
[Epoch 6; Iter   150/ 2172] train: loss: 0.0021794
[Epoch 6; Iter   180/ 2172] train: loss: 0.0018916
[Epoch 6; Iter   210/ 2172] train: loss: 0.0014706
[Epoch 6; Iter   240/ 2172] train: loss: 0.0016945
[Epoch 6; Iter   270/ 2172] train: loss: 0.0017645
[Epoch 6; Iter   300/ 2172] train: loss: 0.0019728
[Epoch 6; Iter   330/ 2172] train: loss: 0.0012420
[Epoch 6; Iter   360/ 2172] train: loss: 0.0021770
[Epoch 6; Iter   390/ 2172] train: loss: 0.0012442
[Epoch 6; Iter   420/ 2172] train: loss: 0.0018683
[Epoch 6; Iter   450/ 2172] train: loss: 0.0018468
[Epoch 6; Iter   480/ 2172] train: loss: 0.0014719
[Epoch 6; Iter   510/ 2172] train: loss: 0.0012032
[Epoch 6; Iter   540/ 2172] train: loss: 0.0705874
[Epoch 6; Iter   570/ 2172] train: loss: 0.0010199
[Epoch 6; Iter   600/ 2172] train: loss: 0.0021006
[Epoch 6; Iter   630/ 2172] train: loss: 0.0031991
[Epoch 6; Iter   660/ 2172] train: loss: 0.0020430
[Epoch 6; Iter   690/ 2172] train: loss: 0.0018192
[Epoch 6; Iter   720/ 2172] train: loss: 0.0024930
[Epoch 6; Iter   750/ 2172] train: loss: 0.0018494
[Epoch 6; Iter   780/ 2172] train: loss: 0.0028485
[Epoch 6; Iter   810/ 2172] train: loss: 0.0022394
[Epoch 6; Iter   840/ 2172] train: loss: 0.0016033
[Epoch 6; Iter   870/ 2172] train: loss: 0.0020045
[Epoch 6; Iter   900/ 2172] train: loss: 0.0023016
[Epoch 6; Iter   930/ 2172] train: loss: 0.0021672
[Epoch 6; Iter   960/ 2172] train: loss: 0.0018520
[Epoch 6; Iter   990/ 2172] train: loss: 0.0678380
[Epoch 6; Iter  1020/ 2172] train: loss: 0.0767937
[Epoch 6; Iter  1050/ 2172] train: loss: 0.0022502
[Epoch 6; Iter  1080/ 2172] train: loss: 0.0020951
[Epoch 6; Iter  1110/ 2172] train: loss: 0.0022556
[Epoch 6; Iter  1140/ 2172] train: loss: 0.0019373
[Epoch 6; Iter  1170/ 2172] train: loss: 0.0020023
[Epoch 6; Iter  1200/ 2172] train: loss: 0.0018554
[Epoch 6; Iter  1230/ 2172] train: loss: 0.0021530
[Epoch 6; Iter  1260/ 2172] train: loss: 0.0017756
[Epoch 6; Iter  1290/ 2172] train: loss: 0.0022129
[Epoch 6; Iter  1320/ 2172] train: loss: 0.0839805
[Epoch 6; Iter  1350/ 2172] train: loss: 0.0025029
[Epoch 6; Iter  1380/ 2172] train: loss: 0.0781383
[Epoch 6; Iter  1410/ 2172] train: loss: 0.0020217
[Epoch 6; Iter  1440/ 2172] train: loss: 0.0016132
[Epoch 6; Iter  1470/ 2172] train: loss: 0.0637713
[Epoch 6; Iter  1500/ 2172] train: loss: 0.0022186
[Epoch 6; Iter  1530/ 2172] train: loss: 0.0019406
[Epoch 6; Iter  1560/ 2172] train: loss: 0.0664074
[Epoch 6; Iter  1590/ 2172] train: loss: 0.0029178
[Epoch 6; Iter  1620/ 2172] train: loss: 0.0021630
[Epoch 6; Iter  1650/ 2172] train: loss: 0.0031656
[Epoch 6; Iter  1680/ 2172] train: loss: 0.0017131
[Epoch 6; Iter  1710/ 2172] train: loss: 0.0018139
[Epoch 4; Iter  1404/ 2172] train: loss: 0.0017809
[Epoch 4; Iter  1434/ 2172] train: loss: 0.0709668
[Epoch 4; Iter  1464/ 2172] train: loss: 0.0017986
[Epoch 4; Iter  1494/ 2172] train: loss: 0.0020079
[Epoch 4; Iter  1524/ 2172] train: loss: 0.0018761
[Epoch 4; Iter  1554/ 2172] train: loss: 0.0018365
[Epoch 4; Iter  1584/ 2172] train: loss: 0.0020747
[Epoch 4; Iter  1614/ 2172] train: loss: 0.0016911
[Epoch 4; Iter  1644/ 2172] train: loss: 0.0026157
[Epoch 4; Iter  1674/ 2172] train: loss: 0.0016923
[Epoch 4; Iter  1704/ 2172] train: loss: 0.0020851
[Epoch 4; Iter  1734/ 2172] train: loss: 0.0950546
[Epoch 4; Iter  1764/ 2172] train: loss: 0.0018560
[Epoch 4; Iter  1794/ 2172] train: loss: 0.0905951
[Epoch 4; Iter  1824/ 2172] train: loss: 0.0652452
[Epoch 4; Iter  1854/ 2172] train: loss: 0.0950438
[Epoch 4; Iter  1884/ 2172] train: loss: 0.0019512
[Epoch 4; Iter  1914/ 2172] train: loss: 0.0017915
[Epoch 4; Iter  1944/ 2172] train: loss: 0.0021137
[Epoch 4; Iter  1974/ 2172] train: loss: 0.0013869
[Epoch 4; Iter  2004/ 2172] train: loss: 0.0015529
[Epoch 4; Iter  2034/ 2172] train: loss: 0.0017849
[Epoch 4; Iter  2064/ 2172] train: loss: 0.0027190
[Epoch 4; Iter  2094/ 2172] train: loss: 0.0930005
[Epoch 4; Iter  2124/ 2172] train: loss: 0.0023272
[Epoch 4; Iter  2154/ 2172] train: loss: 0.0023200
[Epoch 4] ogbg-molmuv: 0.019634 val loss: 0.012379
[Epoch 4] ogbg-molmuv: 0.015368 test loss: 0.014165
[Epoch 5; Iter    12/ 2172] train: loss: 0.0022971
[Epoch 5; Iter    42/ 2172] train: loss: 0.0015018
[Epoch 5; Iter    72/ 2172] train: loss: 0.0022489
[Epoch 5; Iter   102/ 2172] train: loss: 0.0017002
[Epoch 5; Iter   132/ 2172] train: loss: 0.0016850
[Epoch 5; Iter   162/ 2172] train: loss: 0.0016876
[Epoch 5; Iter   192/ 2172] train: loss: 0.0022018
[Epoch 5; Iter   222/ 2172] train: loss: 0.0017066
[Epoch 5; Iter   252/ 2172] train: loss: 0.1422489
[Epoch 5; Iter   282/ 2172] train: loss: 0.0034394
[Epoch 5; Iter   312/ 2172] train: loss: 0.0028171
[Epoch 5; Iter   342/ 2172] train: loss: 0.0023262
[Epoch 5; Iter   372/ 2172] train: loss: 0.0022910
[Epoch 5; Iter   402/ 2172] train: loss: 0.1214269
[Epoch 5; Iter   432/ 2172] train: loss: 0.0024715
[Epoch 5; Iter   462/ 2172] train: loss: 0.0023778
[Epoch 5; Iter   492/ 2172] train: loss: 0.0021758
[Epoch 5; Iter   522/ 2172] train: loss: 0.0018513
[Epoch 5; Iter   552/ 2172] train: loss: 0.0022162
[Epoch 5; Iter   582/ 2172] train: loss: 0.0024102
[Epoch 5; Iter   612/ 2172] train: loss: 0.0025344
[Epoch 5; Iter   642/ 2172] train: loss: 0.0031535
[Epoch 5; Iter   672/ 2172] train: loss: 0.0021886
[Epoch 5; Iter   702/ 2172] train: loss: 0.0028503
[Epoch 5; Iter   732/ 2172] train: loss: 0.0026052
[Epoch 5; Iter   762/ 2172] train: loss: 0.0020894
[Epoch 5; Iter   792/ 2172] train: loss: 0.0018316
[Epoch 5; Iter   822/ 2172] train: loss: 0.0024687
[Epoch 5; Iter   852/ 2172] train: loss: 0.0017824
[Epoch 5; Iter   882/ 2172] train: loss: 0.0716225
[Epoch 5; Iter   912/ 2172] train: loss: 0.0014310
[Epoch 5; Iter   942/ 2172] train: loss: 0.0024228
[Epoch 5; Iter   972/ 2172] train: loss: 0.0017437
[Epoch 5; Iter  1002/ 2172] train: loss: 0.0023146
[Epoch 5; Iter  1032/ 2172] train: loss: 0.0018421
[Epoch 5; Iter  1062/ 2172] train: loss: 0.0018124
[Epoch 5; Iter  1092/ 2172] train: loss: 0.0792992
[Epoch 5; Iter  1122/ 2172] train: loss: 0.0016129
[Epoch 5; Iter  1152/ 2172] train: loss: 0.0012491
[Epoch 5; Iter  1182/ 2172] train: loss: 0.0030034
[Epoch 5; Iter  1212/ 2172] train: loss: 0.0018113
[Epoch 5; Iter  1242/ 2172] train: loss: 0.0013050
[Epoch 5; Iter  1272/ 2172] train: loss: 0.0016884
[Epoch 5; Iter  1302/ 2172] train: loss: 0.0017696
[Epoch 5; Iter  1332/ 2172] train: loss: 0.0727068
[Epoch 5; Iter  1362/ 2172] train: loss: 0.0022793
[Epoch 5; Iter  1392/ 2172] train: loss: 0.0015238
[Epoch 5; Iter  1422/ 2172] train: loss: 0.0015288
[Epoch 5; Iter  1452/ 2172] train: loss: 0.0013132
[Epoch 5; Iter  1482/ 2172] train: loss: 0.0020801
[Epoch 5; Iter  1512/ 2172] train: loss: 0.0016290
[Epoch 5; Iter  1542/ 2172] train: loss: 0.0023236
[Epoch 5; Iter  1572/ 2172] train: loss: 0.0018231
[Epoch 5; Iter  1602/ 2172] train: loss: 0.0018818
[Epoch 5; Iter  1632/ 2172] train: loss: 0.0013392
[Epoch 5; Iter  1662/ 2172] train: loss: 0.0012537
[Epoch 5; Iter  1692/ 2172] train: loss: 0.0022788
[Epoch 5; Iter  1722/ 2172] train: loss: 0.0016661
[Epoch 5; Iter  1752/ 2172] train: loss: 0.0019654
[Epoch 5; Iter  1782/ 2172] train: loss: 0.1147993
[Epoch 5; Iter  1812/ 2172] train: loss: 0.0024107
[Epoch 5; Iter  1842/ 2172] train: loss: 0.0023656
[Epoch 5; Iter  1872/ 2172] train: loss: 0.0015663
[Epoch 5; Iter  1902/ 2172] train: loss: 0.0012672
[Epoch 5; Iter  1932/ 2172] train: loss: 0.0013612
[Epoch 5; Iter  1962/ 2172] train: loss: 0.0015822
[Epoch 5; Iter  1992/ 2172] train: loss: 0.0017892
[Epoch 5; Iter  2022/ 2172] train: loss: 0.0013028
[Epoch 5; Iter  2052/ 2172] train: loss: 0.0018201
[Epoch 5; Iter  2082/ 2172] train: loss: 0.0016295
[Epoch 5; Iter  2112/ 2172] train: loss: 0.0888710
[Epoch 5; Iter  2142/ 2172] train: loss: 0.0017840
[Epoch 5; Iter  2172/ 2172] train: loss: 0.0023529
[Epoch 5] ogbg-molmuv: 0.009196 val loss: 0.012745
[Epoch 5] ogbg-molmuv: 0.013064 test loss: 0.014183
[Epoch 6; Iter    30/ 2172] train: loss: 0.0020918
[Epoch 6; Iter    60/ 2172] train: loss: 0.0025051
[Epoch 6; Iter    90/ 2172] train: loss: 0.0019997
[Epoch 6; Iter   120/ 2172] train: loss: 0.0039114
[Epoch 6; Iter   150/ 2172] train: loss: 0.0016460
[Epoch 6; Iter   180/ 2172] train: loss: 0.0018623
[Epoch 6; Iter   210/ 2172] train: loss: 0.0027237
[Epoch 6; Iter   240/ 2172] train: loss: 0.0017149
[Epoch 6; Iter   270/ 2172] train: loss: 0.0016328
[Epoch 6; Iter   300/ 2172] train: loss: 0.0017872
[Epoch 6; Iter   330/ 2172] train: loss: 0.0020551
[Epoch 6; Iter   360/ 2172] train: loss: 0.0015255
[Epoch 6; Iter   390/ 2172] train: loss: 0.0023202
[Epoch 6; Iter   420/ 2172] train: loss: 0.0025145
[Epoch 6; Iter   450/ 2172] train: loss: 0.0022677
[Epoch 6; Iter   480/ 2172] train: loss: 0.0020481
[Epoch 6; Iter   510/ 2172] train: loss: 0.0018395
[Epoch 6; Iter   540/ 2172] train: loss: 0.0036120
[Epoch 6; Iter   570/ 2172] train: loss: 0.0025093
[Epoch 6; Iter   600/ 2172] train: loss: 0.0024160
[Epoch 6; Iter   630/ 2172] train: loss: 0.0017014
[Epoch 6; Iter   660/ 2172] train: loss: 0.0020896
[Epoch 6; Iter   690/ 2172] train: loss: 0.0014143
[Epoch 6; Iter   720/ 2172] train: loss: 0.0016493
[Epoch 6; Iter   750/ 2172] train: loss: 0.0013521
[Epoch 6; Iter   780/ 2172] train: loss: 0.0014330
[Epoch 6; Iter   810/ 2172] train: loss: 0.0015821
[Epoch 6; Iter   840/ 2172] train: loss: 0.0014819
[Epoch 6; Iter   870/ 2172] train: loss: 0.0013247
[Epoch 6; Iter   900/ 2172] train: loss: 0.0015498
[Epoch 6; Iter   930/ 2172] train: loss: 0.0014441
[Epoch 6; Iter   960/ 2172] train: loss: 0.0014972
[Epoch 6; Iter   990/ 2172] train: loss: 0.1010294
[Epoch 6; Iter  1020/ 2172] train: loss: 0.0033179
[Epoch 6; Iter  1050/ 2172] train: loss: 0.0023657
[Epoch 6; Iter  1080/ 2172] train: loss: 0.0750782
[Epoch 6; Iter  1110/ 2172] train: loss: 0.0021838
[Epoch 6; Iter  1140/ 2172] train: loss: 0.0027537
[Epoch 6; Iter  1170/ 2172] train: loss: 0.0892522
[Epoch 6; Iter  1200/ 2172] train: loss: 0.0020547
[Epoch 6; Iter  1230/ 2172] train: loss: 0.0031628
[Epoch 6; Iter  1260/ 2172] train: loss: 0.0022152
[Epoch 6; Iter  1290/ 2172] train: loss: 0.0016703
[Epoch 6; Iter  1320/ 2172] train: loss: 0.0022754
[Epoch 6; Iter  1350/ 2172] train: loss: 0.0019573
[Epoch 6; Iter  1380/ 2172] train: loss: 0.0020727
[Epoch 6; Iter  1410/ 2172] train: loss: 0.0014611
[Epoch 6; Iter  1440/ 2172] train: loss: 0.0013748
[Epoch 6; Iter  1470/ 2172] train: loss: 0.0013590
[Epoch 6; Iter  1500/ 2172] train: loss: 0.0015254
[Epoch 6; Iter  1530/ 2172] train: loss: 0.0015615
[Epoch 6; Iter  1560/ 2172] train: loss: 0.0016576
[Epoch 6; Iter  1590/ 2172] train: loss: 0.0894614
[Epoch 6; Iter  1620/ 2172] train: loss: 0.0016547
[Epoch 6; Iter  1650/ 2172] train: loss: 0.0017592
[Epoch 6; Iter  1680/ 2172] train: loss: 0.0737498
[Epoch 6; Iter  1710/ 2172] train: loss: 0.0020905
[Epoch 4; Iter  1404/ 2172] train: loss: 0.0018076
[Epoch 4; Iter  1434/ 2172] train: loss: 0.0632406
[Epoch 4; Iter  1464/ 2172] train: loss: 0.0024138
[Epoch 4; Iter  1494/ 2172] train: loss: 0.0023467
[Epoch 4; Iter  1524/ 2172] train: loss: 0.0023229
[Epoch 4; Iter  1554/ 2172] train: loss: 0.0721796
[Epoch 4; Iter  1584/ 2172] train: loss: 0.0020610
[Epoch 4; Iter  1614/ 2172] train: loss: 0.0019690
[Epoch 4; Iter  1644/ 2172] train: loss: 0.0018446
[Epoch 4; Iter  1674/ 2172] train: loss: 0.0666861
[Epoch 4; Iter  1704/ 2172] train: loss: 0.0027017
[Epoch 4; Iter  1734/ 2172] train: loss: 0.0018591
[Epoch 4; Iter  1764/ 2172] train: loss: 0.0020280
[Epoch 4; Iter  1794/ 2172] train: loss: 0.0016090
[Epoch 4; Iter  1824/ 2172] train: loss: 0.0029605
[Epoch 4; Iter  1854/ 2172] train: loss: 0.0020579
[Epoch 4; Iter  1884/ 2172] train: loss: 0.0019776
[Epoch 4; Iter  1914/ 2172] train: loss: 0.0014917
[Epoch 4; Iter  1944/ 2172] train: loss: 0.0015987
[Epoch 4; Iter  1974/ 2172] train: loss: 0.0019036
[Epoch 4; Iter  2004/ 2172] train: loss: 0.0020979
[Epoch 4; Iter  2034/ 2172] train: loss: 0.0025451
[Epoch 4; Iter  2064/ 2172] train: loss: 0.0618610
[Epoch 4; Iter  2094/ 2172] train: loss: 0.0020296
[Epoch 4; Iter  2124/ 2172] train: loss: 0.0027566
[Epoch 4; Iter  2154/ 2172] train: loss: 0.0026716
[Epoch 4] ogbg-molmuv: 0.017715 val loss: 0.012418
[Epoch 4] ogbg-molmuv: 0.009617 test loss: 0.014464
[Epoch 5; Iter    12/ 2172] train: loss: 0.0024553
[Epoch 5; Iter    42/ 2172] train: loss: 0.0489399
[Epoch 5; Iter    72/ 2172] train: loss: 0.0015878
[Epoch 5; Iter   102/ 2172] train: loss: 0.0014493
[Epoch 5; Iter   132/ 2172] train: loss: 0.0022003
[Epoch 5; Iter   162/ 2172] train: loss: 0.0563814
[Epoch 5; Iter   192/ 2172] train: loss: 0.0922232
[Epoch 5; Iter   222/ 2172] train: loss: 0.0025532
[Epoch 5; Iter   252/ 2172] train: loss: 0.0025963
[Epoch 5; Iter   282/ 2172] train: loss: 0.0025643
[Epoch 5; Iter   312/ 2172] train: loss: 0.0027709
[Epoch 5; Iter   342/ 2172] train: loss: 0.0022136
[Epoch 5; Iter   372/ 2172] train: loss: 0.0014775
[Epoch 5; Iter   402/ 2172] train: loss: 0.0015121
[Epoch 5; Iter   432/ 2172] train: loss: 0.0016099
[Epoch 5; Iter   462/ 2172] train: loss: 0.0017799
[Epoch 5; Iter   492/ 2172] train: loss: 0.0016868
[Epoch 5; Iter   522/ 2172] train: loss: 0.0024698
[Epoch 5; Iter   552/ 2172] train: loss: 0.0017842
[Epoch 5; Iter   582/ 2172] train: loss: 0.0018800
[Epoch 5; Iter   612/ 2172] train: loss: 0.0017683
[Epoch 5; Iter   642/ 2172] train: loss: 0.0791991
[Epoch 5; Iter   672/ 2172] train: loss: 0.0016917
[Epoch 5; Iter   702/ 2172] train: loss: 0.0018153
[Epoch 5; Iter   732/ 2172] train: loss: 0.0019655
[Epoch 5; Iter   762/ 2172] train: loss: 0.0024122
[Epoch 5; Iter   792/ 2172] train: loss: 0.0660331
[Epoch 5; Iter   822/ 2172] train: loss: 0.0016937
[Epoch 5; Iter   852/ 2172] train: loss: 0.0015806
[Epoch 5; Iter   882/ 2172] train: loss: 0.0017769
[Epoch 5; Iter   912/ 2172] train: loss: 0.0012844
[Epoch 5; Iter   942/ 2172] train: loss: 0.0015140
[Epoch 5; Iter   972/ 2172] train: loss: 0.0017051
[Epoch 5; Iter  1002/ 2172] train: loss: 0.0029419
[Epoch 5; Iter  1032/ 2172] train: loss: 0.0018797
[Epoch 5; Iter  1062/ 2172] train: loss: 0.0014792
[Epoch 5; Iter  1092/ 2172] train: loss: 0.0016599
[Epoch 5; Iter  1122/ 2172] train: loss: 0.0020043
[Epoch 5; Iter  1152/ 2172] train: loss: 0.0026631
[Epoch 5; Iter  1182/ 2172] train: loss: 0.0648507
[Epoch 5; Iter  1212/ 2172] train: loss: 0.0021939
[Epoch 5; Iter  1242/ 2172] train: loss: 0.0024844
[Epoch 5; Iter  1272/ 2172] train: loss: 0.0017674
[Epoch 5; Iter  1302/ 2172] train: loss: 0.0014262
[Epoch 5; Iter  1332/ 2172] train: loss: 0.0012931
[Epoch 5; Iter  1362/ 2172] train: loss: 0.0012671
[Epoch 5; Iter  1392/ 2172] train: loss: 0.0754353
[Epoch 5; Iter  1422/ 2172] train: loss: 0.0017301
[Epoch 5; Iter  1452/ 2172] train: loss: 0.0853073
[Epoch 5; Iter  1482/ 2172] train: loss: 0.0015268
[Epoch 5; Iter  1512/ 2172] train: loss: 0.0033111
[Epoch 5; Iter  1542/ 2172] train: loss: 0.0028767
[Epoch 5; Iter  1572/ 2172] train: loss: 0.0013841
[Epoch 5; Iter  1602/ 2172] train: loss: 0.0014159
[Epoch 5; Iter  1632/ 2172] train: loss: 0.0015252
[Epoch 5; Iter  1662/ 2172] train: loss: 0.0016183
[Epoch 5; Iter  1692/ 2172] train: loss: 0.0017534
[Epoch 5; Iter  1722/ 2172] train: loss: 0.0013262
[Epoch 5; Iter  1752/ 2172] train: loss: 0.0021805
[Epoch 5; Iter  1782/ 2172] train: loss: 0.0018541
[Epoch 5; Iter  1812/ 2172] train: loss: 0.0017781
[Epoch 5; Iter  1842/ 2172] train: loss: 0.0022854
[Epoch 5; Iter  1872/ 2172] train: loss: 0.0773213
[Epoch 5; Iter  1902/ 2172] train: loss: 0.0024783
[Epoch 5; Iter  1932/ 2172] train: loss: 0.0022124
[Epoch 5; Iter  1962/ 2172] train: loss: 0.0023269
[Epoch 5; Iter  1992/ 2172] train: loss: 0.0842045
[Epoch 5; Iter  2022/ 2172] train: loss: 0.0791757
[Epoch 5; Iter  2052/ 2172] train: loss: 0.0022652
[Epoch 5; Iter  2082/ 2172] train: loss: 0.0019581
[Epoch 5; Iter  2112/ 2172] train: loss: 0.0767309
[Epoch 5; Iter  2142/ 2172] train: loss: 0.0015958
[Epoch 5; Iter  2172/ 2172] train: loss: 0.0017479
[Epoch 5] ogbg-molmuv: 0.026230 val loss: 0.012225
[Epoch 5] ogbg-molmuv: 0.015051 test loss: 0.014007
[Epoch 6; Iter    30/ 2172] train: loss: 0.0017981
[Epoch 6; Iter    60/ 2172] train: loss: 0.0793749
[Epoch 6; Iter    90/ 2172] train: loss: 0.0024633
[Epoch 6; Iter   120/ 2172] train: loss: 0.0733735
[Epoch 6; Iter   150/ 2172] train: loss: 0.0706462
[Epoch 6; Iter   180/ 2172] train: loss: 0.0046831
[Epoch 6; Iter   210/ 2172] train: loss: 0.0020842
[Epoch 6; Iter   240/ 2172] train: loss: 0.0020107
[Epoch 6; Iter   270/ 2172] train: loss: 0.0013989
[Epoch 6; Iter   300/ 2172] train: loss: 0.0728009
[Epoch 6; Iter   330/ 2172] train: loss: 0.0019438
[Epoch 6; Iter   360/ 2172] train: loss: 0.0019054
[Epoch 6; Iter   390/ 2172] train: loss: 0.0011538
[Epoch 6; Iter   420/ 2172] train: loss: 0.0017916
[Epoch 6; Iter   450/ 2172] train: loss: 0.2006239
[Epoch 6; Iter   480/ 2172] train: loss: 0.0013921
[Epoch 6; Iter   510/ 2172] train: loss: 0.0013356
[Epoch 6; Iter   540/ 2172] train: loss: 0.0753596
[Epoch 6; Iter   570/ 2172] train: loss: 0.0016611
[Epoch 6; Iter   600/ 2172] train: loss: 0.0017347
[Epoch 6; Iter   630/ 2172] train: loss: 0.0723239
[Epoch 6; Iter   660/ 2172] train: loss: 0.0022127
[Epoch 6; Iter   690/ 2172] train: loss: 0.0027039
[Epoch 6; Iter   720/ 2172] train: loss: 0.0021657
[Epoch 6; Iter   750/ 2172] train: loss: 0.0024584
[Epoch 6; Iter   780/ 2172] train: loss: 0.0527658
[Epoch 6; Iter   810/ 2172] train: loss: 0.0024181
[Epoch 6; Iter   840/ 2172] train: loss: 0.0021227
[Epoch 6; Iter   870/ 2172] train: loss: 0.0015013
[Epoch 6; Iter   900/ 2172] train: loss: 0.0016935
[Epoch 6; Iter   930/ 2172] train: loss: 0.0016124
[Epoch 6; Iter   960/ 2172] train: loss: 0.0034703
[Epoch 6; Iter   990/ 2172] train: loss: 0.0029751
[Epoch 6; Iter  1020/ 2172] train: loss: 0.0018167
[Epoch 6; Iter  1050/ 2172] train: loss: 0.0019699
[Epoch 6; Iter  1080/ 2172] train: loss: 0.0018236
[Epoch 6; Iter  1110/ 2172] train: loss: 0.0021993
[Epoch 6; Iter  1140/ 2172] train: loss: 0.0031339
[Epoch 6; Iter  1170/ 2172] train: loss: 0.0017884
[Epoch 6; Iter  1200/ 2172] train: loss: 0.0020732
[Epoch 6; Iter  1230/ 2172] train: loss: 0.0620624
[Epoch 6; Iter  1260/ 2172] train: loss: 0.0015967
[Epoch 6; Iter  1290/ 2172] train: loss: 0.0015738
[Epoch 6; Iter  1320/ 2172] train: loss: 0.0019694
[Epoch 6; Iter  1350/ 2172] train: loss: 0.0882942
[Epoch 6; Iter  1380/ 2172] train: loss: 0.0014027
[Epoch 6; Iter  1410/ 2172] train: loss: 0.0013946
[Epoch 6; Iter  1440/ 2172] train: loss: 0.0013685
[Epoch 6; Iter  1470/ 2172] train: loss: 0.0014120
[Epoch 6; Iter  1500/ 2172] train: loss: 0.0011955
[Epoch 6; Iter  1530/ 2172] train: loss: 0.0014017
[Epoch 6; Iter  1560/ 2172] train: loss: 0.0016710
[Epoch 6; Iter  1590/ 2172] train: loss: 0.0017805
[Epoch 6; Iter  1620/ 2172] train: loss: 0.0031591
[Epoch 6; Iter  1650/ 2172] train: loss: 0.0020026
[Epoch 6; Iter  1680/ 2172] train: loss: 0.0024889
[Epoch 6; Iter  1710/ 2172] train: loss: 0.0780365
[Epoch 5; Iter   412/ 1862] train: loss: 0.0016329
[Epoch 5; Iter   442/ 1862] train: loss: 0.0017947
[Epoch 5; Iter   472/ 1862] train: loss: 0.0020983
[Epoch 5; Iter   502/ 1862] train: loss: 0.0022166
[Epoch 5; Iter   532/ 1862] train: loss: 0.0019173
[Epoch 5; Iter   562/ 1862] train: loss: 0.0018978
[Epoch 5; Iter   592/ 1862] train: loss: 0.0016662
[Epoch 5; Iter   622/ 1862] train: loss: 0.0016583
[Epoch 5; Iter   652/ 1862] train: loss: 0.0024644
[Epoch 5; Iter   682/ 1862] train: loss: 0.0020979
[Epoch 5; Iter   712/ 1862] train: loss: 0.1399557
[Epoch 5; Iter   742/ 1862] train: loss: 0.0025610
[Epoch 5; Iter   772/ 1862] train: loss: 0.0022069
[Epoch 5; Iter   802/ 1862] train: loss: 0.0019513
[Epoch 5; Iter   832/ 1862] train: loss: 0.0022654
[Epoch 5; Iter   862/ 1862] train: loss: 0.0018792
[Epoch 5; Iter   892/ 1862] train: loss: 0.0016581
[Epoch 5; Iter   922/ 1862] train: loss: 0.0016202
[Epoch 5; Iter   952/ 1862] train: loss: 0.0018522
[Epoch 5; Iter   982/ 1862] train: loss: 0.0822896
[Epoch 5; Iter  1012/ 1862] train: loss: 0.0021136
[Epoch 5; Iter  1042/ 1862] train: loss: 0.0019358
[Epoch 5; Iter  1072/ 1862] train: loss: 0.0018346
[Epoch 5; Iter  1102/ 1862] train: loss: 0.0016472
[Epoch 5; Iter  1132/ 1862] train: loss: 0.0019144
[Epoch 5; Iter  1162/ 1862] train: loss: 0.0033338
[Epoch 5; Iter  1192/ 1862] train: loss: 0.0028077
[Epoch 5; Iter  1222/ 1862] train: loss: 0.0018797
[Epoch 5; Iter  1252/ 1862] train: loss: 0.1324268
[Epoch 5; Iter  1282/ 1862] train: loss: 0.0022327
[Epoch 5; Iter  1312/ 1862] train: loss: 0.0022257
[Epoch 5; Iter  1342/ 1862] train: loss: 0.0022198
[Epoch 5; Iter  1372/ 1862] train: loss: 0.0017256
[Epoch 5; Iter  1402/ 1862] train: loss: 0.0021550
[Epoch 5; Iter  1432/ 1862] train: loss: 0.0012822
[Epoch 5; Iter  1462/ 1862] train: loss: 0.0014015
[Epoch 5; Iter  1492/ 1862] train: loss: 0.0022922
[Epoch 5; Iter  1522/ 1862] train: loss: 0.0023194
[Epoch 5; Iter  1552/ 1862] train: loss: 0.0017766
[Epoch 5; Iter  1582/ 1862] train: loss: 0.0019597
[Epoch 5; Iter  1612/ 1862] train: loss: 0.0019594
[Epoch 5; Iter  1642/ 1862] train: loss: 0.0015747
[Epoch 5; Iter  1672/ 1862] train: loss: 0.0012941
[Epoch 5; Iter  1702/ 1862] train: loss: 0.0013812
[Epoch 5; Iter  1732/ 1862] train: loss: 0.0015497
[Epoch 5; Iter  1762/ 1862] train: loss: 0.0018125
[Epoch 5; Iter  1792/ 1862] train: loss: 0.0622583
[Epoch 5; Iter  1822/ 1862] train: loss: 0.0018258
[Epoch 5; Iter  1852/ 1862] train: loss: 0.0666804
[Epoch 5] ogbg-molmuv: 0.021972 val loss: 0.013563
[Epoch 5] ogbg-molmuv: 0.013970 test loss: 0.014337
[Epoch 6; Iter    20/ 1862] train: loss: 0.0014259
[Epoch 6; Iter    50/ 1862] train: loss: 0.0015514
[Epoch 6; Iter    80/ 1862] train: loss: 0.0013513
[Epoch 6; Iter   110/ 1862] train: loss: 0.0015349
[Epoch 6; Iter   140/ 1862] train: loss: 0.0015461
[Epoch 6; Iter   170/ 1862] train: loss: 0.0016942
[Epoch 6; Iter   200/ 1862] train: loss: 0.0015010
[Epoch 6; Iter   230/ 1862] train: loss: 0.0014844
[Epoch 6; Iter   260/ 1862] train: loss: 0.0029836
[Epoch 6; Iter   290/ 1862] train: loss: 0.0019424
[Epoch 6; Iter   320/ 1862] train: loss: 0.0022514
[Epoch 6; Iter   350/ 1862] train: loss: 0.0018255
[Epoch 6; Iter   380/ 1862] train: loss: 0.0017105
[Epoch 6; Iter   410/ 1862] train: loss: 0.1392180
[Epoch 6; Iter   440/ 1862] train: loss: 0.0696836
[Epoch 6; Iter   470/ 1862] train: loss: 0.0020560
[Epoch 6; Iter   500/ 1862] train: loss: 0.0013314
[Epoch 6; Iter   530/ 1862] train: loss: 0.0019568
[Epoch 6; Iter   560/ 1862] train: loss: 0.0023427
[Epoch 6; Iter   590/ 1862] train: loss: 0.0033875
[Epoch 6; Iter   620/ 1862] train: loss: 0.0028563
[Epoch 6; Iter   650/ 1862] train: loss: 0.0031672
[Epoch 6; Iter   680/ 1862] train: loss: 0.0020196
[Epoch 6; Iter   710/ 1862] train: loss: 0.0637451
[Epoch 6; Iter   740/ 1862] train: loss: 0.0020126
[Epoch 6; Iter   770/ 1862] train: loss: 0.0015917
[Epoch 6; Iter   800/ 1862] train: loss: 0.0013301
[Epoch 6; Iter   830/ 1862] train: loss: 0.0014452
[Epoch 6; Iter   860/ 1862] train: loss: 0.0845378
[Epoch 6; Iter   890/ 1862] train: loss: 0.0018466
[Epoch 6; Iter   920/ 1862] train: loss: 0.0016952
[Epoch 6; Iter   950/ 1862] train: loss: 0.0018592
[Epoch 6; Iter   980/ 1862] train: loss: 0.0016437
[Epoch 6; Iter  1010/ 1862] train: loss: 0.0027546
[Epoch 6; Iter  1040/ 1862] train: loss: 0.0927935
[Epoch 6; Iter  1070/ 1862] train: loss: 0.0776990
[Epoch 6; Iter  1100/ 1862] train: loss: 0.0017599
[Epoch 6; Iter  1130/ 1862] train: loss: 0.0020133
[Epoch 6; Iter  1160/ 1862] train: loss: 0.0018002
[Epoch 6; Iter  1190/ 1862] train: loss: 0.0016135
[Epoch 6; Iter  1220/ 1862] train: loss: 0.0015048
[Epoch 6; Iter  1250/ 1862] train: loss: 0.0770282
[Epoch 6; Iter  1280/ 1862] train: loss: 0.0023488
[Epoch 6; Iter  1310/ 1862] train: loss: 0.0032589
[Epoch 6; Iter  1340/ 1862] train: loss: 0.0018344
[Epoch 6; Iter  1370/ 1862] train: loss: 0.0750079
[Epoch 6; Iter  1400/ 1862] train: loss: 0.0014524
[Epoch 6; Iter  1430/ 1862] train: loss: 0.0017265
[Epoch 6; Iter  1460/ 1862] train: loss: 0.0015537
[Epoch 6; Iter  1490/ 1862] train: loss: 0.0025831
[Epoch 6; Iter  1520/ 1862] train: loss: 0.0017269
[Epoch 6; Iter  1550/ 1862] train: loss: 0.0019257
[Epoch 6; Iter  1580/ 1862] train: loss: 0.0017250
[Epoch 6; Iter  1610/ 1862] train: loss: 0.0017991
[Epoch 6; Iter  1640/ 1862] train: loss: 0.0016678
[Epoch 6; Iter  1670/ 1862] train: loss: 0.0021788
[Epoch 6; Iter  1700/ 1862] train: loss: 0.0028379
[Epoch 6; Iter  1730/ 1862] train: loss: 0.0022476
[Epoch 6; Iter  1760/ 1862] train: loss: 0.0016829
[Epoch 6; Iter  1790/ 1862] train: loss: 0.0015937
[Epoch 6; Iter  1820/ 1862] train: loss: 0.0021523
[Epoch 6; Iter  1850/ 1862] train: loss: 0.0016731
[Epoch 6] ogbg-molmuv: 0.017359 val loss: 0.013678
[Epoch 6] ogbg-molmuv: 0.051674 test loss: 0.012593
[Epoch 7; Iter    18/ 1862] train: loss: 0.0016334
[Epoch 7; Iter    48/ 1862] train: loss: 0.0037372
[Epoch 7; Iter    78/ 1862] train: loss: 0.0019476
[Epoch 7; Iter   108/ 1862] train: loss: 0.0034281
[Epoch 7; Iter   138/ 1862] train: loss: 0.0018621
[Epoch 7; Iter   168/ 1862] train: loss: 0.0508785
[Epoch 7; Iter   198/ 1862] train: loss: 0.1180707
[Epoch 7; Iter   228/ 1862] train: loss: 0.0031646
[Epoch 7; Iter   258/ 1862] train: loss: 0.0021566
[Epoch 7; Iter   288/ 1862] train: loss: 0.0051355
[Epoch 7; Iter   318/ 1862] train: loss: 0.0021914
[Epoch 7; Iter   348/ 1862] train: loss: 0.0023813
[Epoch 7; Iter   378/ 1862] train: loss: 0.1132858
[Epoch 7; Iter   408/ 1862] train: loss: 0.0029687
[Epoch 7; Iter   438/ 1862] train: loss: 0.0017167
[Epoch 7; Iter   468/ 1862] train: loss: 0.0765764
[Epoch 7; Iter   498/ 1862] train: loss: 0.0019421
[Epoch 7; Iter   528/ 1862] train: loss: 0.0024062
[Epoch 7; Iter   558/ 1862] train: loss: 0.0019136
[Epoch 7; Iter   588/ 1862] train: loss: 0.0019584
[Epoch 7; Iter   618/ 1862] train: loss: 0.0024224
[Epoch 7; Iter   648/ 1862] train: loss: 0.0018798
[Epoch 7; Iter   678/ 1862] train: loss: 0.0016658
[Epoch 7; Iter   708/ 1862] train: loss: 0.0016134
[Epoch 7; Iter   738/ 1862] train: loss: 0.0018140
[Epoch 7; Iter   768/ 1862] train: loss: 0.0862931
[Epoch 7; Iter   798/ 1862] train: loss: 0.0022420
[Epoch 7; Iter   828/ 1862] train: loss: 0.0019965
[Epoch 7; Iter   858/ 1862] train: loss: 0.0014992
[Epoch 7; Iter   888/ 1862] train: loss: 0.0015353
[Epoch 7; Iter   918/ 1862] train: loss: 0.0015223
[Epoch 7; Iter   948/ 1862] train: loss: 0.0022159
[Epoch 7; Iter   978/ 1862] train: loss: 0.0898679
[Epoch 7; Iter  1008/ 1862] train: loss: 0.0017472
[Epoch 7; Iter  1038/ 1862] train: loss: 0.0019646
[Epoch 7; Iter  1068/ 1862] train: loss: 0.0022304
[Epoch 7; Iter  1098/ 1862] train: loss: 0.0856030
[Epoch 7; Iter  1128/ 1862] train: loss: 0.0021452
[Epoch 7; Iter  1158/ 1862] train: loss: 0.0022273
[Epoch 7; Iter  1188/ 1862] train: loss: 0.0025748
[Epoch 7; Iter  1218/ 1862] train: loss: 0.0016608
[Epoch 7; Iter  1248/ 1862] train: loss: 0.0023709
[Epoch 7; Iter  1278/ 1862] train: loss: 0.0022525
[Epoch 7; Iter  1308/ 1862] train: loss: 0.0017771
[Epoch 7; Iter  1338/ 1862] train: loss: 0.0014890
[Epoch 5; Iter   412/ 1862] train: loss: 0.0017804
[Epoch 5; Iter   442/ 1862] train: loss: 0.0022532
[Epoch 5; Iter   472/ 1862] train: loss: 0.0018766
[Epoch 5; Iter   502/ 1862] train: loss: 0.0022155
[Epoch 5; Iter   532/ 1862] train: loss: 0.0022108
[Epoch 5; Iter   562/ 1862] train: loss: 0.0028866
[Epoch 5; Iter   592/ 1862] train: loss: 0.0019349
[Epoch 5; Iter   622/ 1862] train: loss: 0.0035182
[Epoch 5; Iter   652/ 1862] train: loss: 0.0788645
[Epoch 5; Iter   682/ 1862] train: loss: 0.0469313
[Epoch 5; Iter   712/ 1862] train: loss: 0.0019215
[Epoch 5; Iter   742/ 1862] train: loss: 0.0017901
[Epoch 5; Iter   772/ 1862] train: loss: 0.0020057
[Epoch 5; Iter   802/ 1862] train: loss: 0.0040190
[Epoch 5; Iter   832/ 1862] train: loss: 0.0012567
[Epoch 5; Iter   862/ 1862] train: loss: 0.0631058
[Epoch 5; Iter   892/ 1862] train: loss: 0.0019368
[Epoch 5; Iter   922/ 1862] train: loss: 0.0017148
[Epoch 5; Iter   952/ 1862] train: loss: 0.0014319
[Epoch 5; Iter   982/ 1862] train: loss: 0.0019184
[Epoch 5; Iter  1012/ 1862] train: loss: 0.0015408
[Epoch 5; Iter  1042/ 1862] train: loss: 0.0012900
[Epoch 5; Iter  1072/ 1862] train: loss: 0.1582130
[Epoch 5; Iter  1102/ 1862] train: loss: 0.0029029
[Epoch 5; Iter  1132/ 1862] train: loss: 0.0018897
[Epoch 5; Iter  1162/ 1862] train: loss: 0.0016246
[Epoch 5; Iter  1192/ 1862] train: loss: 0.0013798
[Epoch 5; Iter  1222/ 1862] train: loss: 0.0015931
[Epoch 5; Iter  1252/ 1862] train: loss: 0.0015211
[Epoch 5; Iter  1282/ 1862] train: loss: 0.0018025
[Epoch 5; Iter  1312/ 1862] train: loss: 0.0018696
[Epoch 5; Iter  1342/ 1862] train: loss: 0.0021672
[Epoch 5; Iter  1372/ 1862] train: loss: 0.0022098
[Epoch 5; Iter  1402/ 1862] train: loss: 0.0025539
[Epoch 5; Iter  1432/ 1862] train: loss: 0.0020894
[Epoch 5; Iter  1462/ 1862] train: loss: 0.0020743
[Epoch 5; Iter  1492/ 1862] train: loss: 0.0037756
[Epoch 5; Iter  1522/ 1862] train: loss: 0.0027594
[Epoch 5; Iter  1552/ 1862] train: loss: 0.0022168
[Epoch 5; Iter  1582/ 1862] train: loss: 0.0018480
[Epoch 5; Iter  1612/ 1862] train: loss: 0.0018630
[Epoch 5; Iter  1642/ 1862] train: loss: 0.0022372
[Epoch 5; Iter  1672/ 1862] train: loss: 0.0717464
[Epoch 5; Iter  1702/ 1862] train: loss: 0.0024758
[Epoch 5; Iter  1732/ 1862] train: loss: 0.0934540
[Epoch 5; Iter  1762/ 1862] train: loss: 0.0020179
[Epoch 5; Iter  1792/ 1862] train: loss: 0.0023619
[Epoch 5; Iter  1822/ 1862] train: loss: 0.0022382
[Epoch 5; Iter  1852/ 1862] train: loss: 0.0014226
[Epoch 5] ogbg-molmuv: 0.012820 val loss: 0.013869
[Epoch 5] ogbg-molmuv: 0.013997 test loss: 0.012623
[Epoch 6; Iter    20/ 1862] train: loss: 0.0020113
[Epoch 6; Iter    50/ 1862] train: loss: 0.0025932
[Epoch 6; Iter    80/ 1862] train: loss: 0.0525794
[Epoch 6; Iter   110/ 1862] train: loss: 0.0020444
[Epoch 6; Iter   140/ 1862] train: loss: 0.0020253
[Epoch 6; Iter   170/ 1862] train: loss: 0.0021690
[Epoch 6; Iter   200/ 1862] train: loss: 0.0822888
[Epoch 6; Iter   230/ 1862] train: loss: 0.0026083
[Epoch 6; Iter   260/ 1862] train: loss: 0.0015652
[Epoch 6; Iter   290/ 1862] train: loss: 0.0014863
[Epoch 6; Iter   320/ 1862] train: loss: 0.0770388
[Epoch 6; Iter   350/ 1862] train: loss: 0.0016829
[Epoch 6; Iter   380/ 1862] train: loss: 0.0019469
[Epoch 6; Iter   410/ 1862] train: loss: 0.0021374
[Epoch 6; Iter   440/ 1862] train: loss: 0.0022327
[Epoch 6; Iter   470/ 1862] train: loss: 0.0021758
[Epoch 6; Iter   500/ 1862] train: loss: 0.0020650
[Epoch 6; Iter   530/ 1862] train: loss: 0.0016268
[Epoch 6; Iter   560/ 1862] train: loss: 0.0015533
[Epoch 6; Iter   590/ 1862] train: loss: 0.0018663
[Epoch 6; Iter   620/ 1862] train: loss: 0.0021561
[Epoch 6; Iter   650/ 1862] train: loss: 0.0020420
[Epoch 6; Iter   680/ 1862] train: loss: 0.0018317
[Epoch 6; Iter   710/ 1862] train: loss: 0.0581317
[Epoch 6; Iter   740/ 1862] train: loss: 0.0012836
[Epoch 6; Iter   770/ 1862] train: loss: 0.0032765
[Epoch 6; Iter   800/ 1862] train: loss: 0.0018390
[Epoch 6; Iter   830/ 1862] train: loss: 0.0020327
[Epoch 6; Iter   860/ 1862] train: loss: 0.0850730
[Epoch 6; Iter   890/ 1862] train: loss: 0.0023558
[Epoch 6; Iter   920/ 1862] train: loss: 0.0023047
[Epoch 6; Iter   950/ 1862] train: loss: 0.0021946
[Epoch 6; Iter   980/ 1862] train: loss: 0.0018454
[Epoch 6; Iter  1010/ 1862] train: loss: 0.0017487
[Epoch 6; Iter  1040/ 1862] train: loss: 0.0616772
[Epoch 6; Iter  1070/ 1862] train: loss: 0.0954692
[Epoch 6; Iter  1100/ 1862] train: loss: 0.0018236
[Epoch 6; Iter  1130/ 1862] train: loss: 0.0016916
[Epoch 6; Iter  1160/ 1862] train: loss: 0.0034639
[Epoch 6; Iter  1190/ 1862] train: loss: 0.0018043
[Epoch 6; Iter  1220/ 1862] train: loss: 0.0016702
[Epoch 6; Iter  1250/ 1862] train: loss: 0.0019224
[Epoch 6; Iter  1280/ 1862] train: loss: 0.0016982
[Epoch 6; Iter  1310/ 1862] train: loss: 0.0017266
[Epoch 6; Iter  1340/ 1862] train: loss: 0.0018643
[Epoch 6; Iter  1370/ 1862] train: loss: 0.0023768
[Epoch 6; Iter  1400/ 1862] train: loss: 0.0017798
[Epoch 6; Iter  1430/ 1862] train: loss: 0.0021548
[Epoch 6; Iter  1460/ 1862] train: loss: 0.0022373
[Epoch 6; Iter  1490/ 1862] train: loss: 0.0021507
[Epoch 6; Iter  1520/ 1862] train: loss: 0.0032255
[Epoch 6; Iter  1550/ 1862] train: loss: 0.0019692
[Epoch 6; Iter  1580/ 1862] train: loss: 0.0018844
[Epoch 6; Iter  1610/ 1862] train: loss: 0.0019866
[Epoch 6; Iter  1640/ 1862] train: loss: 0.0744077
[Epoch 6; Iter  1670/ 1862] train: loss: 0.0016933
[Epoch 6; Iter  1700/ 1862] train: loss: 0.0020117
[Epoch 6; Iter  1730/ 1862] train: loss: 0.0019733
[Epoch 6; Iter  1760/ 1862] train: loss: 0.0014082
[Epoch 6; Iter  1790/ 1862] train: loss: 0.0720528
[Epoch 6; Iter  1820/ 1862] train: loss: 0.0024754
[Epoch 6; Iter  1850/ 1862] train: loss: 0.0018482
[Epoch 6] ogbg-molmuv: 0.010638 val loss: 0.013978
[Epoch 6] ogbg-molmuv: 0.018880 test loss: 0.013078
[Epoch 7; Iter    18/ 1862] train: loss: 0.0015514
[Epoch 7; Iter    48/ 1862] train: loss: 0.0026948
[Epoch 7; Iter    78/ 1862] train: loss: 0.0014143
[Epoch 7; Iter   108/ 1862] train: loss: 0.0014785
[Epoch 7; Iter   138/ 1862] train: loss: 0.0017577
[Epoch 7; Iter   168/ 1862] train: loss: 0.0019516
[Epoch 7; Iter   198/ 1862] train: loss: 0.0016458
[Epoch 7; Iter   228/ 1862] train: loss: 0.0013584
[Epoch 7; Iter   258/ 1862] train: loss: 0.0019062
[Epoch 7; Iter   288/ 1862] train: loss: 0.0017412
[Epoch 7; Iter   318/ 1862] train: loss: 0.0027142
[Epoch 7; Iter   348/ 1862] train: loss: 0.0024951
[Epoch 7; Iter   378/ 1862] train: loss: 0.0024105
[Epoch 7; Iter   408/ 1862] train: loss: 0.0636703
[Epoch 7; Iter   438/ 1862] train: loss: 0.0019577
[Epoch 7; Iter   468/ 1862] train: loss: 0.0023882
[Epoch 7; Iter   498/ 1862] train: loss: 0.0025002
[Epoch 7; Iter   528/ 1862] train: loss: 0.0019597
[Epoch 7; Iter   558/ 1862] train: loss: 0.0025495
[Epoch 7; Iter   588/ 1862] train: loss: 0.0018765
[Epoch 7; Iter   618/ 1862] train: loss: 0.0017699
[Epoch 7; Iter   648/ 1862] train: loss: 0.0013392
[Epoch 7; Iter   678/ 1862] train: loss: 0.0704345
[Epoch 7; Iter   708/ 1862] train: loss: 0.0016687
[Epoch 7; Iter   738/ 1862] train: loss: 0.0022158
[Epoch 7; Iter   768/ 1862] train: loss: 0.0020507
[Epoch 7; Iter   798/ 1862] train: loss: 0.0022823
[Epoch 7; Iter   828/ 1862] train: loss: 0.0586368
[Epoch 7; Iter   858/ 1862] train: loss: 0.0950298
[Epoch 7; Iter   888/ 1862] train: loss: 0.0021104
[Epoch 7; Iter   918/ 1862] train: loss: 0.0017463
[Epoch 7; Iter   948/ 1862] train: loss: 0.0021421
[Epoch 7; Iter   978/ 1862] train: loss: 0.0020548
[Epoch 7; Iter  1008/ 1862] train: loss: 0.0018261
[Epoch 7; Iter  1038/ 1862] train: loss: 0.0029411
[Epoch 7; Iter  1068/ 1862] train: loss: 0.0022136
[Epoch 7; Iter  1098/ 1862] train: loss: 0.0019234
[Epoch 7; Iter  1128/ 1862] train: loss: 0.0019701
[Epoch 7; Iter  1158/ 1862] train: loss: 0.0018785
[Epoch 7; Iter  1188/ 1862] train: loss: 0.0022034
[Epoch 7; Iter  1218/ 1862] train: loss: 0.0017434
[Epoch 7; Iter  1248/ 1862] train: loss: 0.0016735
[Epoch 7; Iter  1278/ 1862] train: loss: 0.0015520
[Epoch 7; Iter  1308/ 1862] train: loss: 0.0013646
[Epoch 7; Iter  1338/ 1862] train: loss: 0.0017922
[Epoch 5; Iter   412/ 1862] train: loss: 0.0921791
[Epoch 5; Iter   442/ 1862] train: loss: 0.0022821
[Epoch 5; Iter   472/ 1862] train: loss: 0.0021562
[Epoch 5; Iter   502/ 1862] train: loss: 0.0018719
[Epoch 5; Iter   532/ 1862] train: loss: 0.0023420
[Epoch 5; Iter   562/ 1862] train: loss: 0.0022530
[Epoch 5; Iter   592/ 1862] train: loss: 0.0024321
[Epoch 5; Iter   622/ 1862] train: loss: 0.0018712
[Epoch 5; Iter   652/ 1862] train: loss: 0.0017168
[Epoch 5; Iter   682/ 1862] train: loss: 0.0021499
[Epoch 5; Iter   712/ 1862] train: loss: 0.0019584
[Epoch 5; Iter   742/ 1862] train: loss: 0.0969498
[Epoch 5; Iter   772/ 1862] train: loss: 0.0870696
[Epoch 5; Iter   802/ 1862] train: loss: 0.0019085
[Epoch 5; Iter   832/ 1862] train: loss: 0.0015090
[Epoch 5; Iter   862/ 1862] train: loss: 0.0020404
[Epoch 5; Iter   892/ 1862] train: loss: 0.0020191
[Epoch 5; Iter   922/ 1862] train: loss: 0.0020646
[Epoch 5; Iter   952/ 1862] train: loss: 0.0021628
[Epoch 5; Iter   982/ 1862] train: loss: 0.0017154
[Epoch 5; Iter  1012/ 1862] train: loss: 0.0021470
[Epoch 5; Iter  1042/ 1862] train: loss: 0.0016813
[Epoch 5; Iter  1072/ 1862] train: loss: 0.0016240
[Epoch 5; Iter  1102/ 1862] train: loss: 0.0014332
[Epoch 5; Iter  1132/ 1862] train: loss: 0.0012763
[Epoch 5; Iter  1162/ 1862] train: loss: 0.0014757
[Epoch 5; Iter  1192/ 1862] train: loss: 0.0012934
[Epoch 5; Iter  1222/ 1862] train: loss: 0.0012445
[Epoch 5; Iter  1252/ 1862] train: loss: 0.0013644
[Epoch 5; Iter  1282/ 1862] train: loss: 0.0012638
[Epoch 5; Iter  1312/ 1862] train: loss: 0.0012368
[Epoch 5; Iter  1342/ 1862] train: loss: 0.0013377
[Epoch 5; Iter  1372/ 1862] train: loss: 0.0018340
[Epoch 5; Iter  1402/ 1862] train: loss: 0.0014953
[Epoch 5; Iter  1432/ 1862] train: loss: 0.0867334
[Epoch 5; Iter  1462/ 1862] train: loss: 0.0027945
[Epoch 5; Iter  1492/ 1862] train: loss: 0.0021545
[Epoch 5; Iter  1522/ 1862] train: loss: 0.0017641
[Epoch 5; Iter  1552/ 1862] train: loss: 0.0015314
[Epoch 5; Iter  1582/ 1862] train: loss: 0.0018493
[Epoch 5; Iter  1612/ 1862] train: loss: 0.0015717
[Epoch 5; Iter  1642/ 1862] train: loss: 0.0020030
[Epoch 5; Iter  1672/ 1862] train: loss: 0.0024527
[Epoch 5; Iter  1702/ 1862] train: loss: 0.0022055
[Epoch 5; Iter  1732/ 1862] train: loss: 0.0022274
[Epoch 5; Iter  1762/ 1862] train: loss: 0.0805138
[Epoch 5; Iter  1792/ 1862] train: loss: 0.0821845
[Epoch 5; Iter  1822/ 1862] train: loss: 0.0018709
[Epoch 5; Iter  1852/ 1862] train: loss: 0.0021769
[Epoch 5] ogbg-molmuv: 0.018042 val loss: 0.013887
[Epoch 5] ogbg-molmuv: 0.009335 test loss: 0.012755
[Epoch 6; Iter    20/ 1862] train: loss: 0.0022519
[Epoch 6; Iter    50/ 1862] train: loss: 0.0724488
[Epoch 6; Iter    80/ 1862] train: loss: 0.0666678
[Epoch 6; Iter   110/ 1862] train: loss: 0.0047254
[Epoch 6; Iter   140/ 1862] train: loss: 0.0017545
[Epoch 6; Iter   170/ 1862] train: loss: 0.0018340
[Epoch 6; Iter   200/ 1862] train: loss: 0.0022345
[Epoch 6; Iter   230/ 1862] train: loss: 0.0025838
[Epoch 6; Iter   260/ 1862] train: loss: 0.0027825
[Epoch 6; Iter   290/ 1862] train: loss: 0.0027326
[Epoch 6; Iter   320/ 1862] train: loss: 0.0022422
[Epoch 6; Iter   350/ 1862] train: loss: 0.0035766
[Epoch 6; Iter   380/ 1862] train: loss: 0.0025136
[Epoch 6; Iter   410/ 1862] train: loss: 0.0032386
[Epoch 6; Iter   440/ 1862] train: loss: 0.0023595
[Epoch 6; Iter   470/ 1862] train: loss: 0.0018274
[Epoch 6; Iter   500/ 1862] train: loss: 0.0018886
[Epoch 6; Iter   530/ 1862] train: loss: 0.0019131
[Epoch 6; Iter   560/ 1862] train: loss: 0.0018831
[Epoch 6; Iter   590/ 1862] train: loss: 0.0019325
[Epoch 6; Iter   620/ 1862] train: loss: 0.0023773
[Epoch 6; Iter   650/ 1862] train: loss: 0.0023798
[Epoch 6; Iter   680/ 1862] train: loss: 0.0810423
[Epoch 6; Iter   710/ 1862] train: loss: 0.0027338
[Epoch 6; Iter   740/ 1862] train: loss: 0.0022583
[Epoch 6; Iter   770/ 1862] train: loss: 0.0017315
[Epoch 6; Iter   800/ 1862] train: loss: 0.0017411
[Epoch 6; Iter   830/ 1862] train: loss: 0.0013957
[Epoch 6; Iter   860/ 1862] train: loss: 0.0631066
[Epoch 6; Iter   890/ 1862] train: loss: 0.0026899
[Epoch 6; Iter   920/ 1862] train: loss: 0.0016648
[Epoch 6; Iter   950/ 1862] train: loss: 0.0019009
[Epoch 6; Iter   980/ 1862] train: loss: 0.1628433
[Epoch 6; Iter  1010/ 1862] train: loss: 0.0019651
[Epoch 6; Iter  1040/ 1862] train: loss: 0.0868791
[Epoch 6; Iter  1070/ 1862] train: loss: 0.0016978
[Epoch 6; Iter  1100/ 1862] train: loss: 0.0015230
[Epoch 6; Iter  1130/ 1862] train: loss: 0.0017936
[Epoch 6; Iter  1160/ 1862] train: loss: 0.0012028
[Epoch 6; Iter  1190/ 1862] train: loss: 0.0017992
[Epoch 6; Iter  1220/ 1862] train: loss: 0.0014448
[Epoch 6; Iter  1250/ 1862] train: loss: 0.0013743
[Epoch 6; Iter  1280/ 1862] train: loss: 0.0015396
[Epoch 6; Iter  1310/ 1862] train: loss: 0.0647344
[Epoch 6; Iter  1340/ 1862] train: loss: 0.0330690
[Epoch 6; Iter  1370/ 1862] train: loss: 0.0031013
[Epoch 6; Iter  1400/ 1862] train: loss: 0.0027680
[Epoch 6; Iter  1430/ 1862] train: loss: 0.0023242
[Epoch 6; Iter  1460/ 1862] train: loss: 0.0752801
[Epoch 6; Iter  1490/ 1862] train: loss: 0.0018767
[Epoch 6; Iter  1520/ 1862] train: loss: 0.0030931
[Epoch 6; Iter  1550/ 1862] train: loss: 0.0030669
[Epoch 6; Iter  1580/ 1862] train: loss: 0.0024379
[Epoch 6; Iter  1610/ 1862] train: loss: 0.0022936
[Epoch 6; Iter  1640/ 1862] train: loss: 0.0024720
[Epoch 6; Iter  1670/ 1862] train: loss: 0.0018135
[Epoch 6; Iter  1700/ 1862] train: loss: 0.0023520
[Epoch 6; Iter  1730/ 1862] train: loss: 0.0017376
[Epoch 6; Iter  1760/ 1862] train: loss: 0.0018645
[Epoch 6; Iter  1790/ 1862] train: loss: 0.0016923
[Epoch 6; Iter  1820/ 1862] train: loss: 0.0852365
[Epoch 6; Iter  1850/ 1862] train: loss: 0.0721651
[Epoch 6] ogbg-molmuv: 0.011294 val loss: 0.053160
[Epoch 6] ogbg-molmuv: 0.010855 test loss: 0.036673
[Epoch 7; Iter    18/ 1862] train: loss: 0.0016857
[Epoch 7; Iter    48/ 1862] train: loss: 0.0016746
[Epoch 7; Iter    78/ 1862] train: loss: 0.0014488
[Epoch 7; Iter   108/ 1862] train: loss: 0.0011308
[Epoch 7; Iter   138/ 1862] train: loss: 0.0014370
[Epoch 7; Iter   168/ 1862] train: loss: 0.0016080
[Epoch 7; Iter   198/ 1862] train: loss: 0.0015655
[Epoch 7; Iter   228/ 1862] train: loss: 0.0022897
[Epoch 7; Iter   258/ 1862] train: loss: 0.0019854
[Epoch 7; Iter   288/ 1862] train: loss: 0.0019338
[Epoch 7; Iter   318/ 1862] train: loss: 0.0015687
[Epoch 7; Iter   348/ 1862] train: loss: 0.0026148
[Epoch 7; Iter   378/ 1862] train: loss: 0.0016713
[Epoch 7; Iter   408/ 1862] train: loss: 0.0014845
[Epoch 7; Iter   438/ 1862] train: loss: 0.0023946
[Epoch 7; Iter   468/ 1862] train: loss: 0.0015367
[Epoch 7; Iter   498/ 1862] train: loss: 0.0016091
[Epoch 7; Iter   528/ 1862] train: loss: 0.0021740
[Epoch 7; Iter   558/ 1862] train: loss: 0.0029904
[Epoch 7; Iter   588/ 1862] train: loss: 0.0026438
[Epoch 7; Iter   618/ 1862] train: loss: 0.0017347
[Epoch 7; Iter   648/ 1862] train: loss: 0.0017562
[Epoch 7; Iter   678/ 1862] train: loss: 0.0022696
[Epoch 7; Iter   708/ 1862] train: loss: 0.0917683
[Epoch 7; Iter   738/ 1862] train: loss: 0.1332461
[Epoch 7; Iter   768/ 1862] train: loss: 0.0020870
[Epoch 7; Iter   798/ 1862] train: loss: 0.0025944
[Epoch 7; Iter   828/ 1862] train: loss: 0.0018398
[Epoch 7; Iter   858/ 1862] train: loss: 0.1115309
[Epoch 7; Iter   888/ 1862] train: loss: 0.0018660
[Epoch 7; Iter   918/ 1862] train: loss: 0.0017872
[Epoch 7; Iter   948/ 1862] train: loss: 0.0619453
[Epoch 7; Iter   978/ 1862] train: loss: 0.0016339
[Epoch 7; Iter  1008/ 1862] train: loss: 0.0013505
[Epoch 7; Iter  1038/ 1862] train: loss: 0.0026783
[Epoch 7; Iter  1068/ 1862] train: loss: 0.0016796
[Epoch 7; Iter  1098/ 1862] train: loss: 0.0017675
[Epoch 7; Iter  1128/ 1862] train: loss: 0.0019734
[Epoch 7; Iter  1158/ 1862] train: loss: 0.0014254
[Epoch 7; Iter  1188/ 1862] train: loss: 0.0015789
[Epoch 7; Iter  1218/ 1862] train: loss: 0.0021230
[Epoch 7; Iter  1248/ 1862] train: loss: 0.0016221
[Epoch 7; Iter  1278/ 1862] train: loss: 0.0022397
[Epoch 7; Iter  1308/ 1862] train: loss: 0.0038661
[Epoch 7; Iter  1338/ 1862] train: loss: 0.0028393
[Epoch 6; Iter   185/ 2483] train: loss: 0.0013306
[Epoch 6; Iter   215/ 2483] train: loss: 0.0016870
[Epoch 6; Iter   245/ 2483] train: loss: 0.0022552
[Epoch 6; Iter   275/ 2483] train: loss: 0.0030648
[Epoch 6; Iter   305/ 2483] train: loss: 0.0857337
[Epoch 6; Iter   335/ 2483] train: loss: 0.0021911
[Epoch 6; Iter   365/ 2483] train: loss: 0.0737241
[Epoch 6; Iter   395/ 2483] train: loss: 0.0020767
[Epoch 6; Iter   425/ 2483] train: loss: 0.0024987
[Epoch 6; Iter   455/ 2483] train: loss: 0.0709427
[Epoch 6; Iter   485/ 2483] train: loss: 0.0020393
[Epoch 6; Iter   515/ 2483] train: loss: 0.0033980
[Epoch 6; Iter   545/ 2483] train: loss: 0.0028534
[Epoch 6; Iter   575/ 2483] train: loss: 0.0023283
[Epoch 6; Iter   605/ 2483] train: loss: 0.0636377
[Epoch 6; Iter   635/ 2483] train: loss: 0.0024928
[Epoch 6; Iter   665/ 2483] train: loss: 0.0682450
[Epoch 6; Iter   695/ 2483] train: loss: 0.0020822
[Epoch 6; Iter   725/ 2483] train: loss: 0.0717137
[Epoch 6; Iter   755/ 2483] train: loss: 0.0025952
[Epoch 6; Iter   785/ 2483] train: loss: 0.0992884
[Epoch 6; Iter   815/ 2483] train: loss: 0.0022195
[Epoch 6; Iter   845/ 2483] train: loss: 0.0019679
[Epoch 6; Iter   875/ 2483] train: loss: 0.0870252
[Epoch 6; Iter   905/ 2483] train: loss: 0.0023509
[Epoch 6; Iter   935/ 2483] train: loss: 0.0020246
[Epoch 6; Iter   965/ 2483] train: loss: 0.0023540
[Epoch 6; Iter   995/ 2483] train: loss: 0.0015322
[Epoch 6; Iter  1025/ 2483] train: loss: 0.0017283
[Epoch 6; Iter  1055/ 2483] train: loss: 0.0015085
[Epoch 6; Iter  1085/ 2483] train: loss: 0.0742864
[Epoch 6; Iter  1115/ 2483] train: loss: 0.0013734
[Epoch 6; Iter  1145/ 2483] train: loss: 0.0012727
[Epoch 6; Iter  1175/ 2483] train: loss: 0.0013670
[Epoch 6; Iter  1205/ 2483] train: loss: 0.0018160
[Epoch 6; Iter  1235/ 2483] train: loss: 0.0013053
[Epoch 6; Iter  1265/ 2483] train: loss: 0.0018244
[Epoch 6; Iter  1295/ 2483] train: loss: 0.0015168
[Epoch 6; Iter  1325/ 2483] train: loss: 0.0019317
[Epoch 6; Iter  1355/ 2483] train: loss: 0.1422801
[Epoch 6; Iter  1385/ 2483] train: loss: 0.0028072
[Epoch 6; Iter  1415/ 2483] train: loss: 0.0026187
[Epoch 6; Iter  1445/ 2483] train: loss: 0.0023602
[Epoch 6; Iter  1475/ 2483] train: loss: 0.0015033
[Epoch 6; Iter  1505/ 2483] train: loss: 0.0016011
[Epoch 6; Iter  1535/ 2483] train: loss: 0.0014077
[Epoch 6; Iter  1565/ 2483] train: loss: 0.0016596
[Epoch 6; Iter  1595/ 2483] train: loss: 0.0016646
[Epoch 6; Iter  1625/ 2483] train: loss: 0.0825902
[Epoch 6; Iter  1655/ 2483] train: loss: 0.0959715
[Epoch 6; Iter  1685/ 2483] train: loss: 0.0708629
[Epoch 6; Iter  1715/ 2483] train: loss: 0.0017891
[Epoch 6; Iter  1745/ 2483] train: loss: 0.0014361
[Epoch 6; Iter  1775/ 2483] train: loss: 0.0021011
[Epoch 6; Iter  1805/ 2483] train: loss: 0.0609407
[Epoch 6; Iter  1835/ 2483] train: loss: 0.0020474
[Epoch 6; Iter  1865/ 2483] train: loss: 0.0017820
[Epoch 6; Iter  1895/ 2483] train: loss: 0.0015528
[Epoch 6; Iter  1925/ 2483] train: loss: 0.0032369
[Epoch 6; Iter  1955/ 2483] train: loss: 0.0014761
[Epoch 6; Iter  1985/ 2483] train: loss: 0.0020405
[Epoch 6; Iter  2015/ 2483] train: loss: 0.0807974
[Epoch 6; Iter  2045/ 2483] train: loss: 0.0024986
[Epoch 6; Iter  2075/ 2483] train: loss: 0.0025700
[Epoch 6; Iter  2105/ 2483] train: loss: 0.0018525
[Epoch 6; Iter  2135/ 2483] train: loss: 0.0018541
[Epoch 6; Iter  2165/ 2483] train: loss: 0.0015415
[Epoch 6; Iter  2195/ 2483] train: loss: 0.0021590
[Epoch 6; Iter  2225/ 2483] train: loss: 0.0020713
[Epoch 6; Iter  2255/ 2483] train: loss: 0.0051545
[Epoch 6; Iter  2285/ 2483] train: loss: 0.0024467
[Epoch 6; Iter  2315/ 2483] train: loss: 0.0022859
[Epoch 6; Iter  2345/ 2483] train: loss: 0.0018951
[Epoch 6; Iter  2375/ 2483] train: loss: 0.0021650
[Epoch 6; Iter  2405/ 2483] train: loss: 0.0023866
[Epoch 6; Iter  2435/ 2483] train: loss: 0.0018690
[Epoch 6; Iter  2465/ 2483] train: loss: 0.0019624
[Epoch 6] ogbg-molmuv: 0.029832 val loss: 0.033807
[Epoch 6] ogbg-molmuv: 0.019799 test loss: 0.016530
[Epoch 7; Iter    12/ 2483] train: loss: 0.0019678
[Epoch 7; Iter    42/ 2483] train: loss: 0.0030182
[Epoch 7; Iter    72/ 2483] train: loss: 0.0015608
[Epoch 7; Iter   102/ 2483] train: loss: 0.0444183
[Epoch 7; Iter   132/ 2483] train: loss: 0.0022596
[Epoch 7; Iter   162/ 2483] train: loss: 0.0020429
[Epoch 7; Iter   192/ 2483] train: loss: 0.0016109
[Epoch 7; Iter   222/ 2483] train: loss: 0.0017712
[Epoch 7; Iter   252/ 2483] train: loss: 0.0017709
[Epoch 7; Iter   282/ 2483] train: loss: 0.0818932
[Epoch 7; Iter   312/ 2483] train: loss: 0.0026926
[Epoch 7; Iter   342/ 2483] train: loss: 0.0016293
[Epoch 7; Iter   372/ 2483] train: loss: 0.0015869
[Epoch 7; Iter   402/ 2483] train: loss: 0.0021113
[Epoch 7; Iter   432/ 2483] train: loss: 0.0021355
[Epoch 7; Iter   462/ 2483] train: loss: 0.0024405
[Epoch 7; Iter   492/ 2483] train: loss: 0.0020683
[Epoch 7; Iter   522/ 2483] train: loss: 0.0020493
[Epoch 7; Iter   552/ 2483] train: loss: 0.0018851
[Epoch 7; Iter   582/ 2483] train: loss: 0.0016722
[Epoch 7; Iter   612/ 2483] train: loss: 0.0024992
[Epoch 7; Iter   642/ 2483] train: loss: 0.0978164
[Epoch 7; Iter   672/ 2483] train: loss: 0.0017250
[Epoch 7; Iter   702/ 2483] train: loss: 0.0013452
[Epoch 7; Iter   732/ 2483] train: loss: 0.0010975
[Epoch 7; Iter   762/ 2483] train: loss: 0.0013539
[Epoch 7; Iter   792/ 2483] train: loss: 0.0012699
[Epoch 7; Iter   822/ 2483] train: loss: 0.0012771
[Epoch 7; Iter   852/ 2483] train: loss: 0.0015905
[Epoch 7; Iter   882/ 2483] train: loss: 0.0017357
[Epoch 7; Iter   912/ 2483] train: loss: 0.0022298
[Epoch 7; Iter   942/ 2483] train: loss: 0.0014855
[Epoch 7; Iter   972/ 2483] train: loss: 0.0012258
[Epoch 7; Iter  1002/ 2483] train: loss: 0.0014280
[Epoch 7; Iter  1032/ 2483] train: loss: 0.0023222
[Epoch 7; Iter  1062/ 2483] train: loss: 0.0017097
[Epoch 7; Iter  1092/ 2483] train: loss: 0.0016929
[Epoch 7; Iter  1122/ 2483] train: loss: 0.0019954
[Epoch 7; Iter  1152/ 2483] train: loss: 0.0015737
[Epoch 7; Iter  1182/ 2483] train: loss: 0.0021186
[Epoch 7; Iter  1212/ 2483] train: loss: 0.0022770
[Epoch 7; Iter  1242/ 2483] train: loss: 0.1167405
[Epoch 7; Iter  1272/ 2483] train: loss: 0.0017927
[Epoch 7; Iter  1302/ 2483] train: loss: 0.0017190
[Epoch 7; Iter  1332/ 2483] train: loss: 0.0033340
[Epoch 7; Iter  1362/ 2483] train: loss: 0.0025556
[Epoch 7; Iter  1392/ 2483] train: loss: 0.0021205
[Epoch 7; Iter  1422/ 2483] train: loss: 0.0020674
[Epoch 7; Iter  1452/ 2483] train: loss: 0.0017776
[Epoch 7; Iter  1482/ 2483] train: loss: 0.0634209
[Epoch 7; Iter  1512/ 2483] train: loss: 0.0018870
[Epoch 7; Iter  1542/ 2483] train: loss: 0.0019529
[Epoch 7; Iter  1572/ 2483] train: loss: 0.0016571
[Epoch 7; Iter  1602/ 2483] train: loss: 0.0020899
[Epoch 7; Iter  1632/ 2483] train: loss: 0.0018945
[Epoch 7; Iter  1662/ 2483] train: loss: 0.0019677
[Epoch 7; Iter  1692/ 2483] train: loss: 0.0032304
[Epoch 7; Iter  1722/ 2483] train: loss: 0.1025736
[Epoch 7; Iter  1752/ 2483] train: loss: 0.0030907
[Epoch 7; Iter  1782/ 2483] train: loss: 0.0020251
[Epoch 7; Iter  1812/ 2483] train: loss: 0.0021679
[Epoch 7; Iter  1842/ 2483] train: loss: 0.0017220
[Epoch 7; Iter  1872/ 2483] train: loss: 0.0020043
[Epoch 7; Iter  1902/ 2483] train: loss: 0.0014448
[Epoch 7; Iter  1932/ 2483] train: loss: 0.0015672
[Epoch 7; Iter  1962/ 2483] train: loss: 0.0722475
[Epoch 7; Iter  1992/ 2483] train: loss: 0.0019711
[Epoch 7; Iter  2022/ 2483] train: loss: 0.0033726
[Epoch 7; Iter  2052/ 2483] train: loss: 0.0020223
[Epoch 7; Iter  2082/ 2483] train: loss: 0.0018649
[Epoch 7; Iter  2112/ 2483] train: loss: 0.0024652
[Epoch 7; Iter  2142/ 2483] train: loss: 0.0036268
[Epoch 7; Iter  2172/ 2483] train: loss: 0.0017648
[Epoch 7; Iter  2202/ 2483] train: loss: 0.0015347
[Epoch 7; Iter  2232/ 2483] train: loss: 0.0016028
[Epoch 7; Iter  2262/ 2483] train: loss: 0.0015033
[Epoch 7; Iter  2292/ 2483] train: loss: 0.0018221
[Epoch 7; Iter  2322/ 2483] train: loss: 0.0786647
[Epoch 7; Iter  2352/ 2483] train: loss: 0.0025696
[Epoch 7; Iter  2382/ 2483] train: loss: 0.0019332
[Epoch 7; Iter  2412/ 2483] train: loss: 0.0017348
[Epoch 6; Iter   185/ 2483] train: loss: 0.0021895
[Epoch 6; Iter   215/ 2483] train: loss: 0.0776149
[Epoch 6; Iter   245/ 2483] train: loss: 0.0019458
[Epoch 6; Iter   275/ 2483] train: loss: 0.0034187
[Epoch 6; Iter   305/ 2483] train: loss: 0.0600420
[Epoch 6; Iter   335/ 2483] train: loss: 0.0023983
[Epoch 6; Iter   365/ 2483] train: loss: 0.0015902
[Epoch 6; Iter   395/ 2483] train: loss: 0.0018488
[Epoch 6; Iter   425/ 2483] train: loss: 0.0026251
[Epoch 6; Iter   455/ 2483] train: loss: 0.0018624
[Epoch 6; Iter   485/ 2483] train: loss: 0.0018317
[Epoch 6; Iter   515/ 2483] train: loss: 0.0022623
[Epoch 6; Iter   545/ 2483] train: loss: 0.0020525
[Epoch 6; Iter   575/ 2483] train: loss: 0.0520378
[Epoch 6; Iter   605/ 2483] train: loss: 0.0032447
[Epoch 6; Iter   635/ 2483] train: loss: 0.0016553
[Epoch 6; Iter   665/ 2483] train: loss: 0.0011734
[Epoch 6; Iter   695/ 2483] train: loss: 0.0012636
[Epoch 6; Iter   725/ 2483] train: loss: 0.0016123
[Epoch 6; Iter   755/ 2483] train: loss: 0.0020020
[Epoch 6; Iter   785/ 2483] train: loss: 0.0015292
[Epoch 6; Iter   815/ 2483] train: loss: 0.0963384
[Epoch 6; Iter   845/ 2483] train: loss: 0.0017013
[Epoch 6; Iter   875/ 2483] train: loss: 0.0020996
[Epoch 6; Iter   905/ 2483] train: loss: 0.0021570
[Epoch 6; Iter   935/ 2483] train: loss: 0.0018476
[Epoch 6; Iter   965/ 2483] train: loss: 0.0760341
[Epoch 6; Iter   995/ 2483] train: loss: 0.0015845
[Epoch 6; Iter  1025/ 2483] train: loss: 0.0587371
[Epoch 6; Iter  1055/ 2483] train: loss: 0.0023131
[Epoch 6; Iter  1085/ 2483] train: loss: 0.0023235
[Epoch 6; Iter  1115/ 2483] train: loss: 0.0018907
[Epoch 6; Iter  1145/ 2483] train: loss: 0.0020595
[Epoch 6; Iter  1175/ 2483] train: loss: 0.0017716
[Epoch 6; Iter  1205/ 2483] train: loss: 0.0020747
[Epoch 6; Iter  1235/ 2483] train: loss: 0.0614395
[Epoch 6; Iter  1265/ 2483] train: loss: 0.0034986
[Epoch 6; Iter  1295/ 2483] train: loss: 0.0014083
[Epoch 6; Iter  1325/ 2483] train: loss: 0.0017511
[Epoch 6; Iter  1355/ 2483] train: loss: 0.0022408
[Epoch 6; Iter  1385/ 2483] train: loss: 0.0025662
[Epoch 6; Iter  1415/ 2483] train: loss: 0.0019999
[Epoch 6; Iter  1445/ 2483] train: loss: 0.0017881
[Epoch 6; Iter  1475/ 2483] train: loss: 0.0491879
[Epoch 6; Iter  1505/ 2483] train: loss: 0.0042305
[Epoch 6; Iter  1535/ 2483] train: loss: 0.0844573
[Epoch 6; Iter  1565/ 2483] train: loss: 0.0017470
[Epoch 6; Iter  1595/ 2483] train: loss: 0.0020052
[Epoch 6; Iter  1625/ 2483] train: loss: 0.0019381
[Epoch 6; Iter  1655/ 2483] train: loss: 0.0019520
[Epoch 6; Iter  1685/ 2483] train: loss: 0.0018406
[Epoch 6; Iter  1715/ 2483] train: loss: 0.0813344
[Epoch 6; Iter  1745/ 2483] train: loss: 0.0019937
[Epoch 6; Iter  1775/ 2483] train: loss: 0.0030590
[Epoch 6; Iter  1805/ 2483] train: loss: 0.0029267
[Epoch 6; Iter  1835/ 2483] train: loss: 0.0018474
[Epoch 6; Iter  1865/ 2483] train: loss: 0.0013860
[Epoch 6; Iter  1895/ 2483] train: loss: 0.0011374
[Epoch 6; Iter  1925/ 2483] train: loss: 0.0012840
[Epoch 6; Iter  1955/ 2483] train: loss: 0.0826157
[Epoch 6; Iter  1985/ 2483] train: loss: 0.0018383
[Epoch 6; Iter  2015/ 2483] train: loss: 0.0018044
[Epoch 6; Iter  2045/ 2483] train: loss: 0.0022276
[Epoch 6; Iter  2075/ 2483] train: loss: 0.0019516
[Epoch 6; Iter  2105/ 2483] train: loss: 0.0015943
[Epoch 6; Iter  2135/ 2483] train: loss: 0.0020034
[Epoch 6; Iter  2165/ 2483] train: loss: 0.0016344
[Epoch 6; Iter  2195/ 2483] train: loss: 0.0018948
[Epoch 6; Iter  2225/ 2483] train: loss: 0.0014167
[Epoch 6; Iter  2255/ 2483] train: loss: 0.0015644
[Epoch 6; Iter  2285/ 2483] train: loss: 0.0018659
[Epoch 6; Iter  2315/ 2483] train: loss: 0.0030257
[Epoch 6; Iter  2345/ 2483] train: loss: 0.0026743
[Epoch 6; Iter  2375/ 2483] train: loss: 0.0018385
[Epoch 6; Iter  2405/ 2483] train: loss: 0.0018362
[Epoch 6; Iter  2435/ 2483] train: loss: 0.0529753
[Epoch 6; Iter  2465/ 2483] train: loss: 0.0017760
[Epoch 6] ogbg-molmuv: 0.017227 val loss: 0.010492
[Epoch 6] ogbg-molmuv: 0.013122 test loss: 0.014858
[Epoch 7; Iter    12/ 2483] train: loss: 0.0018106
[Epoch 7; Iter    42/ 2483] train: loss: 0.0017304
[Epoch 7; Iter    72/ 2483] train: loss: 0.0032449
[Epoch 7; Iter   102/ 2483] train: loss: 0.0017002
[Epoch 7; Iter   132/ 2483] train: loss: 0.1434882
[Epoch 7; Iter   162/ 2483] train: loss: 0.0737690
[Epoch 7; Iter   192/ 2483] train: loss: 0.0026882
[Epoch 7; Iter   222/ 2483] train: loss: 0.0028776
[Epoch 7; Iter   252/ 2483] train: loss: 0.0040330
[Epoch 7; Iter   282/ 2483] train: loss: 0.0022390
[Epoch 7; Iter   312/ 2483] train: loss: 0.0014142
[Epoch 7; Iter   342/ 2483] train: loss: 0.0021532
[Epoch 7; Iter   372/ 2483] train: loss: 0.0019295
[Epoch 7; Iter   402/ 2483] train: loss: 0.0019108
[Epoch 7; Iter   432/ 2483] train: loss: 0.0015746
[Epoch 7; Iter   462/ 2483] train: loss: 0.0015311
[Epoch 7; Iter   492/ 2483] train: loss: 0.0013901
[Epoch 7; Iter   522/ 2483] train: loss: 0.0012495
[Epoch 7; Iter   552/ 2483] train: loss: 0.0012819
[Epoch 7; Iter   582/ 2483] train: loss: 0.0017732
[Epoch 7; Iter   612/ 2483] train: loss: 0.0016288
[Epoch 7; Iter   642/ 2483] train: loss: 0.0015820
[Epoch 7; Iter   672/ 2483] train: loss: 0.0766173
[Epoch 7; Iter   702/ 2483] train: loss: 0.0010217
[Epoch 7; Iter   732/ 2483] train: loss: 0.0016114
[Epoch 7; Iter   762/ 2483] train: loss: 0.0023718
[Epoch 7; Iter   792/ 2483] train: loss: 0.0015391
[Epoch 7; Iter   822/ 2483] train: loss: 0.0016782
[Epoch 7; Iter   852/ 2483] train: loss: 0.0018413
[Epoch 7; Iter   882/ 2483] train: loss: 0.0014163
[Epoch 7; Iter   912/ 2483] train: loss: 0.0017520
[Epoch 7; Iter   942/ 2483] train: loss: 0.0021666
[Epoch 7; Iter   972/ 2483] train: loss: 0.0712041
[Epoch 7; Iter  1002/ 2483] train: loss: 0.0015107
[Epoch 7; Iter  1032/ 2483] train: loss: 0.0014033
[Epoch 7; Iter  1062/ 2483] train: loss: 0.0819550
[Epoch 7; Iter  1092/ 2483] train: loss: 0.0668340
[Epoch 7; Iter  1122/ 2483] train: loss: 0.0019798
[Epoch 7; Iter  1152/ 2483] train: loss: 0.0017356
[Epoch 7; Iter  1182/ 2483] train: loss: 0.0014324
[Epoch 7; Iter  1212/ 2483] train: loss: 0.0025708
[Epoch 7; Iter  1242/ 2483] train: loss: 0.0026991
[Epoch 7; Iter  1272/ 2483] train: loss: 0.0682847
[Epoch 7; Iter  1302/ 2483] train: loss: 0.0087189
[Epoch 7; Iter  1332/ 2483] train: loss: 0.0020133
[Epoch 7; Iter  1362/ 2483] train: loss: 0.0023129
[Epoch 7; Iter  1392/ 2483] train: loss: 0.0018653
[Epoch 7; Iter  1422/ 2483] train: loss: 0.0019223
[Epoch 7; Iter  1452/ 2483] train: loss: 0.0020928
[Epoch 7; Iter  1482/ 2483] train: loss: 0.0017955
[Epoch 7; Iter  1512/ 2483] train: loss: 0.0029479
[Epoch 7; Iter  1542/ 2483] train: loss: 0.0019941
[Epoch 7; Iter  1572/ 2483] train: loss: 0.0023131
[Epoch 7; Iter  1602/ 2483] train: loss: 0.1554818
[Epoch 7; Iter  1632/ 2483] train: loss: 0.0020022
[Epoch 7; Iter  1662/ 2483] train: loss: 0.0027260
[Epoch 7; Iter  1692/ 2483] train: loss: 0.0037900
[Epoch 7; Iter  1722/ 2483] train: loss: 0.0026356
[Epoch 7; Iter  1752/ 2483] train: loss: 0.0017592
[Epoch 7; Iter  1782/ 2483] train: loss: 0.0017454
[Epoch 7; Iter  1812/ 2483] train: loss: 0.0716700
[Epoch 7; Iter  1842/ 2483] train: loss: 0.0019244
[Epoch 7; Iter  1872/ 2483] train: loss: 0.0015116
[Epoch 7; Iter  1902/ 2483] train: loss: 0.0019592
[Epoch 7; Iter  1932/ 2483] train: loss: 0.0031412
[Epoch 7; Iter  1962/ 2483] train: loss: 0.0018264
[Epoch 7; Iter  1992/ 2483] train: loss: 0.0027715
[Epoch 7; Iter  2022/ 2483] train: loss: 0.0015476
[Epoch 7; Iter  2052/ 2483] train: loss: 0.0011994
[Epoch 7; Iter  2082/ 2483] train: loss: 0.0021243
[Epoch 7; Iter  2112/ 2483] train: loss: 0.0023249
[Epoch 7; Iter  2142/ 2483] train: loss: 0.0017093
[Epoch 7; Iter  2172/ 2483] train: loss: 0.0020534
[Epoch 7; Iter  2202/ 2483] train: loss: 0.0032054
[Epoch 7; Iter  2232/ 2483] train: loss: 0.0019845
[Epoch 7; Iter  2262/ 2483] train: loss: 0.0013898
[Epoch 7; Iter  2292/ 2483] train: loss: 0.0555268
[Epoch 7; Iter  2322/ 2483] train: loss: 0.0016036
[Epoch 7; Iter  2352/ 2483] train: loss: 0.0012803
[Epoch 7; Iter  2382/ 2483] train: loss: 0.0012998
[Epoch 7; Iter  2412/ 2483] train: loss: 0.0010562
[Epoch 6; Iter   185/ 2483] train: loss: 0.0027830
[Epoch 6; Iter   215/ 2483] train: loss: 0.0023019
[Epoch 6; Iter   245/ 2483] train: loss: 0.0022968
[Epoch 6; Iter   275/ 2483] train: loss: 0.0029782
[Epoch 6; Iter   305/ 2483] train: loss: 0.0019956
[Epoch 6; Iter   335/ 2483] train: loss: 0.0019516
[Epoch 6; Iter   365/ 2483] train: loss: 0.0729000
[Epoch 6; Iter   395/ 2483] train: loss: 0.0017775
[Epoch 6; Iter   425/ 2483] train: loss: 0.1738384
[Epoch 6; Iter   455/ 2483] train: loss: 0.0013512
[Epoch 6; Iter   485/ 2483] train: loss: 0.0015789
[Epoch 6; Iter   515/ 2483] train: loss: 0.0018622
[Epoch 6; Iter   545/ 2483] train: loss: 0.0019453
[Epoch 6; Iter   575/ 2483] train: loss: 0.0017172
[Epoch 6; Iter   605/ 2483] train: loss: 0.0019750
[Epoch 6; Iter   635/ 2483] train: loss: 0.0022770
[Epoch 6; Iter   665/ 2483] train: loss: 0.0017332
[Epoch 6; Iter   695/ 2483] train: loss: 0.0024955
[Epoch 6; Iter   725/ 2483] train: loss: 0.0043664
[Epoch 6; Iter   755/ 2483] train: loss: 0.0784038
[Epoch 6; Iter   785/ 2483] train: loss: 0.0016918
[Epoch 6; Iter   815/ 2483] train: loss: 0.0018860
[Epoch 6; Iter   845/ 2483] train: loss: 0.0024499
[Epoch 6; Iter   875/ 2483] train: loss: 0.0014890
[Epoch 6; Iter   905/ 2483] train: loss: 0.0016800
[Epoch 6; Iter   935/ 2483] train: loss: 0.0019711
[Epoch 6; Iter   965/ 2483] train: loss: 0.0019835
[Epoch 6; Iter   995/ 2483] train: loss: 0.0024883
[Epoch 6; Iter  1025/ 2483] train: loss: 0.0014643
[Epoch 6; Iter  1055/ 2483] train: loss: 0.0016032
[Epoch 6; Iter  1085/ 2483] train: loss: 0.0018550
[Epoch 6; Iter  1115/ 2483] train: loss: 0.0022094
[Epoch 6; Iter  1145/ 2483] train: loss: 0.0017249
[Epoch 6; Iter  1175/ 2483] train: loss: 0.0023076
[Epoch 6; Iter  1205/ 2483] train: loss: 0.0018524
[Epoch 6; Iter  1235/ 2483] train: loss: 0.0013436
[Epoch 6; Iter  1265/ 2483] train: loss: 0.0020932
[Epoch 6; Iter  1295/ 2483] train: loss: 0.0616043
[Epoch 6; Iter  1325/ 2483] train: loss: 0.0031692
[Epoch 6; Iter  1355/ 2483] train: loss: 0.0027034
[Epoch 6; Iter  1385/ 2483] train: loss: 0.0017936
[Epoch 6; Iter  1415/ 2483] train: loss: 0.0019757
[Epoch 6; Iter  1445/ 2483] train: loss: 0.0023629
[Epoch 6; Iter  1475/ 2483] train: loss: 0.0016585
[Epoch 6; Iter  1505/ 2483] train: loss: 0.1029145
[Epoch 6; Iter  1535/ 2483] train: loss: 0.0016059
[Epoch 6; Iter  1565/ 2483] train: loss: 0.0018915
[Epoch 6; Iter  1595/ 2483] train: loss: 0.0023049
[Epoch 6; Iter  1625/ 2483] train: loss: 0.0014641
[Epoch 6; Iter  1655/ 2483] train: loss: 0.0022147
[Epoch 6; Iter  1685/ 2483] train: loss: 0.0019611
[Epoch 6; Iter  1715/ 2483] train: loss: 0.0018177
[Epoch 6; Iter  1745/ 2483] train: loss: 0.0017577
[Epoch 6; Iter  1775/ 2483] train: loss: 0.0558100
[Epoch 6; Iter  1805/ 2483] train: loss: 0.0019275
[Epoch 6; Iter  1835/ 2483] train: loss: 0.0021873
[Epoch 6; Iter  1865/ 2483] train: loss: 0.0647771
[Epoch 6; Iter  1895/ 2483] train: loss: 0.0022336
[Epoch 6; Iter  1925/ 2483] train: loss: 0.0020649
[Epoch 6; Iter  1955/ 2483] train: loss: 0.0605029
[Epoch 6; Iter  1985/ 2483] train: loss: 0.0022461
[Epoch 6; Iter  2015/ 2483] train: loss: 0.0018082
[Epoch 6; Iter  2045/ 2483] train: loss: 0.0017235
[Epoch 6; Iter  2075/ 2483] train: loss: 0.0015452
[Epoch 6; Iter  2105/ 2483] train: loss: 0.0017487
[Epoch 6; Iter  2135/ 2483] train: loss: 0.0722954
[Epoch 6; Iter  2165/ 2483] train: loss: 0.0019134
[Epoch 6; Iter  2195/ 2483] train: loss: 0.0034525
[Epoch 6; Iter  2225/ 2483] train: loss: 0.0024087
[Epoch 6; Iter  2255/ 2483] train: loss: 0.0022029
[Epoch 6; Iter  2285/ 2483] train: loss: 0.0019327
[Epoch 6; Iter  2315/ 2483] train: loss: 0.0742568
[Epoch 6; Iter  2345/ 2483] train: loss: 0.0016081
[Epoch 6; Iter  2375/ 2483] train: loss: 0.0015737
[Epoch 6; Iter  2405/ 2483] train: loss: 0.0015400
[Epoch 6; Iter  2435/ 2483] train: loss: 0.0018765
[Epoch 6; Iter  2465/ 2483] train: loss: 0.0016410
[Epoch 6] ogbg-molmuv: 0.024393 val loss: 0.016128
[Epoch 6] ogbg-molmuv: 0.020363 test loss: 0.014979
[Epoch 7; Iter    12/ 2483] train: loss: 0.0893882
[Epoch 7; Iter    42/ 2483] train: loss: 0.0716718
[Epoch 7; Iter    72/ 2483] train: loss: 0.0020595
[Epoch 7; Iter   102/ 2483] train: loss: 0.0021361
[Epoch 7; Iter   132/ 2483] train: loss: 0.0018716
[Epoch 7; Iter   162/ 2483] train: loss: 0.0017322
[Epoch 7; Iter   192/ 2483] train: loss: 0.0015256
[Epoch 7; Iter   222/ 2483] train: loss: 0.0015570
[Epoch 7; Iter   252/ 2483] train: loss: 0.0027120
[Epoch 7; Iter   282/ 2483] train: loss: 0.0017608
[Epoch 7; Iter   312/ 2483] train: loss: 0.0020687
[Epoch 7; Iter   342/ 2483] train: loss: 0.0021215
[Epoch 7; Iter   372/ 2483] train: loss: 0.0019993
[Epoch 7; Iter   402/ 2483] train: loss: 0.0020305
[Epoch 7; Iter   432/ 2483] train: loss: 0.0017235
[Epoch 7; Iter   462/ 2483] train: loss: 0.0017820
[Epoch 7; Iter   492/ 2483] train: loss: 0.0015385
[Epoch 7; Iter   522/ 2483] train: loss: 0.0638517
[Epoch 7; Iter   552/ 2483] train: loss: 0.0017594
[Epoch 7; Iter   582/ 2483] train: loss: 0.0023760
[Epoch 7; Iter   612/ 2483] train: loss: 0.0013022
[Epoch 7; Iter   642/ 2483] train: loss: 0.0019433
[Epoch 7; Iter   672/ 2483] train: loss: 0.0024008
[Epoch 7; Iter   702/ 2483] train: loss: 0.0022267
[Epoch 7; Iter   732/ 2483] train: loss: 0.0030345
[Epoch 7; Iter   762/ 2483] train: loss: 0.0019557
[Epoch 7; Iter   792/ 2483] train: loss: 0.0018569
[Epoch 7; Iter   822/ 2483] train: loss: 0.0014696
[Epoch 7; Iter   852/ 2483] train: loss: 0.0016526
[Epoch 7; Iter   882/ 2483] train: loss: 0.0017391
[Epoch 7; Iter   912/ 2483] train: loss: 0.0017616
[Epoch 7; Iter   942/ 2483] train: loss: 0.0019774
[Epoch 7; Iter   972/ 2483] train: loss: 0.0020831
[Epoch 7; Iter  1002/ 2483] train: loss: 0.0020500
[Epoch 7; Iter  1032/ 2483] train: loss: 0.0018445
[Epoch 7; Iter  1062/ 2483] train: loss: 0.0016839
[Epoch 7; Iter  1092/ 2483] train: loss: 0.0015668
[Epoch 7; Iter  1122/ 2483] train: loss: 0.0018027
[Epoch 7; Iter  1152/ 2483] train: loss: 0.0631006
[Epoch 7; Iter  1182/ 2483] train: loss: 0.0022046
[Epoch 7; Iter  1212/ 2483] train: loss: 0.0872846
[Epoch 7; Iter  1242/ 2483] train: loss: 0.0026084
[Epoch 7; Iter  1272/ 2483] train: loss: 0.0762986
[Epoch 7; Iter  1302/ 2483] train: loss: 0.0021188
[Epoch 7; Iter  1332/ 2483] train: loss: 0.0016705
[Epoch 7; Iter  1362/ 2483] train: loss: 0.0022734
[Epoch 7; Iter  1392/ 2483] train: loss: 0.0019297
[Epoch 7; Iter  1422/ 2483] train: loss: 0.0017753
[Epoch 7; Iter  1452/ 2483] train: loss: 0.0017629
[Epoch 7; Iter  1482/ 2483] train: loss: 0.0019530
[Epoch 7; Iter  1512/ 2483] train: loss: 0.0020192
[Epoch 7; Iter  1542/ 2483] train: loss: 0.0022087
[Epoch 7; Iter  1572/ 2483] train: loss: 0.0028885
[Epoch 7; Iter  1602/ 2483] train: loss: 0.0019042
[Epoch 7; Iter  1632/ 2483] train: loss: 0.0025891
[Epoch 7; Iter  1662/ 2483] train: loss: 0.0033048
[Epoch 7; Iter  1692/ 2483] train: loss: 0.0023096
[Epoch 7; Iter  1722/ 2483] train: loss: 0.0023674
[Epoch 7; Iter  1752/ 2483] train: loss: 0.0025296
[Epoch 7; Iter  1782/ 2483] train: loss: 0.0021568
[Epoch 7; Iter  1812/ 2483] train: loss: 0.0022277
[Epoch 7; Iter  1842/ 2483] train: loss: 0.0678670
[Epoch 7; Iter  1872/ 2483] train: loss: 0.0023104
[Epoch 7; Iter  1902/ 2483] train: loss: 0.0015632
[Epoch 7; Iter  1932/ 2483] train: loss: 0.0018740
[Epoch 7; Iter  1962/ 2483] train: loss: 0.0014033
[Epoch 7; Iter  1992/ 2483] train: loss: 0.0017929
[Epoch 7; Iter  2022/ 2483] train: loss: 0.0022653
[Epoch 7; Iter  2052/ 2483] train: loss: 0.0018898
[Epoch 7; Iter  2082/ 2483] train: loss: 0.0012985
[Epoch 7; Iter  2112/ 2483] train: loss: 0.0015194
[Epoch 7; Iter  2142/ 2483] train: loss: 0.0015898
[Epoch 7; Iter  2172/ 2483] train: loss: 0.0017562
[Epoch 7; Iter  2202/ 2483] train: loss: 0.0016893
[Epoch 7; Iter  2232/ 2483] train: loss: 0.0023455
[Epoch 7; Iter  2262/ 2483] train: loss: 0.0018536
[Epoch 7; Iter  2292/ 2483] train: loss: 0.0016897
[Epoch 7; Iter  2322/ 2483] train: loss: 0.0015884
[Epoch 7; Iter  2352/ 2483] train: loss: 0.0016706
[Epoch 7; Iter  2382/ 2483] train: loss: 0.0662796
[Epoch 7; Iter  2412/ 2483] train: loss: 0.0016767
[Epoch 6; Iter  1740/ 2172] train: loss: 0.0600171
[Epoch 6; Iter  1770/ 2172] train: loss: 0.0018926
[Epoch 6; Iter  1800/ 2172] train: loss: 0.0018086
[Epoch 6; Iter  1830/ 2172] train: loss: 0.0018064
[Epoch 6; Iter  1860/ 2172] train: loss: 0.0022649
[Epoch 6; Iter  1890/ 2172] train: loss: 0.1019406
[Epoch 6; Iter  1920/ 2172] train: loss: 0.0640511
[Epoch 6; Iter  1950/ 2172] train: loss: 0.0024630
[Epoch 6; Iter  1980/ 2172] train: loss: 0.0023436
[Epoch 6; Iter  2010/ 2172] train: loss: 0.0019307
[Epoch 6; Iter  2040/ 2172] train: loss: 0.0016411
[Epoch 6; Iter  2070/ 2172] train: loss: 0.1548705
[Epoch 6; Iter  2100/ 2172] train: loss: 0.0018647
[Epoch 6; Iter  2130/ 2172] train: loss: 0.0017974
[Epoch 6; Iter  2160/ 2172] train: loss: 0.0020357
[Epoch 6] ogbg-molmuv: 0.023995 val loss: 0.012081
[Epoch 6] ogbg-molmuv: 0.025618 test loss: 0.013553
[Epoch 7; Iter    18/ 2172] train: loss: 0.1238162
[Epoch 7; Iter    48/ 2172] train: loss: 0.0038741
[Epoch 7; Iter    78/ 2172] train: loss: 0.0023520
[Epoch 7; Iter   108/ 2172] train: loss: 0.0025867
[Epoch 7; Iter   138/ 2172] train: loss: 0.0019424
[Epoch 7; Iter   168/ 2172] train: loss: 0.0020881
[Epoch 7; Iter   198/ 2172] train: loss: 0.0020957
[Epoch 7; Iter   228/ 2172] train: loss: 0.0016119
[Epoch 7; Iter   258/ 2172] train: loss: 0.0015723
[Epoch 7; Iter   288/ 2172] train: loss: 0.0014357
[Epoch 7; Iter   318/ 2172] train: loss: 0.0018778
[Epoch 7; Iter   348/ 2172] train: loss: 0.0018033
[Epoch 7; Iter   378/ 2172] train: loss: 0.0803754
[Epoch 7; Iter   408/ 2172] train: loss: 0.0019645
[Epoch 7; Iter   438/ 2172] train: loss: 0.0023230
[Epoch 7; Iter   468/ 2172] train: loss: 0.0023659
[Epoch 7; Iter   498/ 2172] train: loss: 0.0018839
[Epoch 7; Iter   528/ 2172] train: loss: 0.0019685
[Epoch 7; Iter   558/ 2172] train: loss: 0.0018104
[Epoch 7; Iter   588/ 2172] train: loss: 0.0013610
[Epoch 7; Iter   618/ 2172] train: loss: 0.0013789
[Epoch 7; Iter   648/ 2172] train: loss: 0.0018158
[Epoch 7; Iter   678/ 2172] train: loss: 0.1077271
[Epoch 7; Iter   708/ 2172] train: loss: 0.0015337
[Epoch 7; Iter   738/ 2172] train: loss: 0.0021303
[Epoch 7; Iter   768/ 2172] train: loss: 0.0017418
[Epoch 7; Iter   798/ 2172] train: loss: 0.0023025
[Epoch 7; Iter   828/ 2172] train: loss: 0.0018472
[Epoch 7; Iter   858/ 2172] train: loss: 0.0022042
[Epoch 7; Iter   888/ 2172] train: loss: 0.0020828
[Epoch 7; Iter   918/ 2172] train: loss: 0.0018826
[Epoch 7; Iter   948/ 2172] train: loss: 0.0019098
[Epoch 7; Iter   978/ 2172] train: loss: 0.0022684
[Epoch 7; Iter  1008/ 2172] train: loss: 0.0024608
[Epoch 7; Iter  1038/ 2172] train: loss: 0.0041658
[Epoch 7; Iter  1068/ 2172] train: loss: 0.0021709
[Epoch 7; Iter  1098/ 2172] train: loss: 0.0024935
[Epoch 7; Iter  1128/ 2172] train: loss: 0.0889518
[Epoch 7; Iter  1158/ 2172] train: loss: 0.0026801
[Epoch 7; Iter  1188/ 2172] train: loss: 0.0025322
[Epoch 7; Iter  1218/ 2172] train: loss: 0.0023190
[Epoch 7; Iter  1248/ 2172] train: loss: 0.0015494
[Epoch 7; Iter  1278/ 2172] train: loss: 0.0023469
[Epoch 7; Iter  1308/ 2172] train: loss: 0.0015039
[Epoch 7; Iter  1338/ 2172] train: loss: 0.0732083
[Epoch 7; Iter  1368/ 2172] train: loss: 0.0025235
[Epoch 7; Iter  1398/ 2172] train: loss: 0.0520819
[Epoch 7; Iter  1428/ 2172] train: loss: 0.0018165
[Epoch 7; Iter  1458/ 2172] train: loss: 0.0018540
[Epoch 7; Iter  1488/ 2172] train: loss: 0.0018175
[Epoch 7; Iter  1518/ 2172] train: loss: 0.0447506
[Epoch 7; Iter  1548/ 2172] train: loss: 0.0704253
[Epoch 7; Iter  1578/ 2172] train: loss: 0.0707289
[Epoch 7; Iter  1608/ 2172] train: loss: 0.0016417
[Epoch 7; Iter  1638/ 2172] train: loss: 0.0017879
[Epoch 7; Iter  1668/ 2172] train: loss: 0.0020692
[Epoch 7; Iter  1698/ 2172] train: loss: 0.0019191
[Epoch 7; Iter  1728/ 2172] train: loss: 0.0016316
[Epoch 7; Iter  1758/ 2172] train: loss: 0.0014896
[Epoch 7; Iter  1788/ 2172] train: loss: 0.0015420
[Epoch 7; Iter  1818/ 2172] train: loss: 0.0833829
[Epoch 7; Iter  1848/ 2172] train: loss: 0.0028775
[Epoch 7; Iter  1878/ 2172] train: loss: 0.0018308
[Epoch 7; Iter  1908/ 2172] train: loss: 0.0021181
[Epoch 7; Iter  1938/ 2172] train: loss: 0.0017953
[Epoch 7; Iter  1968/ 2172] train: loss: 0.0017498
[Epoch 7; Iter  1998/ 2172] train: loss: 0.0015919
[Epoch 7; Iter  2028/ 2172] train: loss: 0.0014848
[Epoch 7; Iter  2058/ 2172] train: loss: 0.0018139
[Epoch 7; Iter  2088/ 2172] train: loss: 0.0686279
[Epoch 7; Iter  2118/ 2172] train: loss: 0.0020483
[Epoch 7; Iter  2148/ 2172] train: loss: 0.0693721
[Epoch 7] ogbg-molmuv: 0.028444 val loss: 0.011825
[Epoch 7] ogbg-molmuv: 0.021216 test loss: 0.013949
[Epoch 8; Iter     6/ 2172] train: loss: 0.0023001
[Epoch 8; Iter    36/ 2172] train: loss: 0.0016810
[Epoch 8; Iter    66/ 2172] train: loss: 0.0013935
[Epoch 8; Iter    96/ 2172] train: loss: 0.0017699
[Epoch 8; Iter   126/ 2172] train: loss: 0.0017617
[Epoch 8; Iter   156/ 2172] train: loss: 0.1510950
[Epoch 8; Iter   186/ 2172] train: loss: 0.0019162
[Epoch 8; Iter   216/ 2172] train: loss: 0.0103951
[Epoch 8; Iter   246/ 2172] train: loss: 0.0020741
[Epoch 8; Iter   276/ 2172] train: loss: 0.0024337
[Epoch 8; Iter   306/ 2172] train: loss: 0.0016066
[Epoch 8; Iter   336/ 2172] train: loss: 0.0017838
[Epoch 8; Iter   366/ 2172] train: loss: 0.0749529
[Epoch 8; Iter   396/ 2172] train: loss: 0.0015843
[Epoch 8; Iter   426/ 2172] train: loss: 0.0010966
[Epoch 8; Iter   456/ 2172] train: loss: 0.0012654
[Epoch 8; Iter   486/ 2172] train: loss: 0.0017437
[Epoch 8; Iter   516/ 2172] train: loss: 0.0014915
[Epoch 8; Iter   546/ 2172] train: loss: 0.0017255
[Epoch 8; Iter   576/ 2172] train: loss: 0.0014908
[Epoch 8; Iter   606/ 2172] train: loss: 0.0017220
[Epoch 8; Iter   636/ 2172] train: loss: 0.0016207
[Epoch 8; Iter   666/ 2172] train: loss: 0.0015305
[Epoch 8; Iter   696/ 2172] train: loss: 0.1015195
[Epoch 8; Iter   726/ 2172] train: loss: 0.0021530
[Epoch 8; Iter   756/ 2172] train: loss: 0.0012047
[Epoch 8; Iter   786/ 2172] train: loss: 0.0013954
[Epoch 8; Iter   816/ 2172] train: loss: 0.0020006
[Epoch 8; Iter   846/ 2172] train: loss: 0.0017465
[Epoch 8; Iter   876/ 2172] train: loss: 0.0025135
[Epoch 8; Iter   906/ 2172] train: loss: 0.0019878
[Epoch 8; Iter   936/ 2172] train: loss: 0.0014421
[Epoch 8; Iter   966/ 2172] train: loss: 0.0022029
[Epoch 8; Iter   996/ 2172] train: loss: 0.0018504
[Epoch 8; Iter  1026/ 2172] train: loss: 0.0840734
[Epoch 8; Iter  1056/ 2172] train: loss: 0.0018659
[Epoch 8; Iter  1086/ 2172] train: loss: 0.0019678
[Epoch 8; Iter  1116/ 2172] train: loss: 0.0019242
[Epoch 8; Iter  1146/ 2172] train: loss: 0.0021604
[Epoch 8; Iter  1176/ 2172] train: loss: 0.0022688
[Epoch 8; Iter  1206/ 2172] train: loss: 0.0027159
[Epoch 8; Iter  1236/ 2172] train: loss: 0.0023130
[Epoch 8; Iter  1266/ 2172] train: loss: 0.0768201
[Epoch 8; Iter  1296/ 2172] train: loss: 0.0017009
[Epoch 8; Iter  1326/ 2172] train: loss: 0.0021942
[Epoch 8; Iter  1356/ 2172] train: loss: 0.0020953
[Epoch 8; Iter  1386/ 2172] train: loss: 0.0031788
[Epoch 8; Iter  1416/ 2172] train: loss: 0.0020378
[Epoch 8; Iter  1446/ 2172] train: loss: 0.0017656
[Epoch 8; Iter  1476/ 2172] train: loss: 0.0018920
[Epoch 8; Iter  1506/ 2172] train: loss: 0.0015695
[Epoch 8; Iter  1536/ 2172] train: loss: 0.0016963
[Epoch 8; Iter  1566/ 2172] train: loss: 0.0019905
[Epoch 8; Iter  1596/ 2172] train: loss: 0.0020065
[Epoch 8; Iter  1626/ 2172] train: loss: 0.0019719
[Epoch 8; Iter  1656/ 2172] train: loss: 0.0021996
[Epoch 8; Iter  1686/ 2172] train: loss: 0.0020657
[Epoch 8; Iter  1716/ 2172] train: loss: 0.0022473
[Epoch 8; Iter  1746/ 2172] train: loss: 0.0023247
[Epoch 8; Iter  1776/ 2172] train: loss: 0.0022668
[Epoch 8; Iter  1806/ 2172] train: loss: 0.0022394
[Epoch 8; Iter  1836/ 2172] train: loss: 0.0026433
[Epoch 8; Iter  1866/ 2172] train: loss: 0.0023552
[Epoch 8; Iter  1896/ 2172] train: loss: 0.0021184
[Epoch 8; Iter  1926/ 2172] train: loss: 0.1681971
[Epoch 8; Iter  1956/ 2172] train: loss: 0.0039656
[Epoch 8; Iter  1986/ 2172] train: loss: 0.0027582
[Epoch 8; Iter  2016/ 2172] train: loss: 0.0035541
[Epoch 8; Iter  2046/ 2172] train: loss: 0.0564337
[Epoch 6; Iter  1740/ 2172] train: loss: 0.0809853
[Epoch 6; Iter  1770/ 2172] train: loss: 0.0016609
[Epoch 6; Iter  1800/ 2172] train: loss: 0.0019271
[Epoch 6; Iter  1830/ 2172] train: loss: 0.0017802
[Epoch 6; Iter  1860/ 2172] train: loss: 0.0027332
[Epoch 6; Iter  1890/ 2172] train: loss: 0.0837311
[Epoch 6; Iter  1920/ 2172] train: loss: 0.0024101
[Epoch 6; Iter  1950/ 2172] train: loss: 0.0019437
[Epoch 6; Iter  1980/ 2172] train: loss: 0.0015917
[Epoch 6; Iter  2010/ 2172] train: loss: 0.0021023
[Epoch 6; Iter  2040/ 2172] train: loss: 0.0017070
[Epoch 6; Iter  2070/ 2172] train: loss: 0.0945186
[Epoch 6; Iter  2100/ 2172] train: loss: 0.0024811
[Epoch 6; Iter  2130/ 2172] train: loss: 0.0013600
[Epoch 6; Iter  2160/ 2172] train: loss: 0.0016519
[Epoch 6] ogbg-molmuv: 0.007987 val loss: 0.012369
[Epoch 6] ogbg-molmuv: 0.016866 test loss: 0.014273
[Epoch 7; Iter    18/ 2172] train: loss: 0.0015719
[Epoch 7; Iter    48/ 2172] train: loss: 0.0016305
[Epoch 7; Iter    78/ 2172] train: loss: 0.0017750
[Epoch 7; Iter   108/ 2172] train: loss: 0.0019017
[Epoch 7; Iter   138/ 2172] train: loss: 0.0022179
[Epoch 7; Iter   168/ 2172] train: loss: 0.0021640
[Epoch 7; Iter   198/ 2172] train: loss: 0.0044635
[Epoch 7; Iter   228/ 2172] train: loss: 0.0020346
[Epoch 7; Iter   258/ 2172] train: loss: 0.1414210
[Epoch 7; Iter   288/ 2172] train: loss: 0.0016019
[Epoch 7; Iter   318/ 2172] train: loss: 0.0935216
[Epoch 7; Iter   348/ 2172] train: loss: 0.0024524
[Epoch 7; Iter   378/ 2172] train: loss: 0.0033676
[Epoch 7; Iter   408/ 2172] train: loss: 0.0797589
[Epoch 7; Iter   438/ 2172] train: loss: 0.0020255
[Epoch 7; Iter   468/ 2172] train: loss: 0.0016746
[Epoch 7; Iter   498/ 2172] train: loss: 0.0741067
[Epoch 7; Iter   528/ 2172] train: loss: 0.0022766
[Epoch 7; Iter   558/ 2172] train: loss: 0.0014194
[Epoch 7; Iter   588/ 2172] train: loss: 0.0018031
[Epoch 7; Iter   618/ 2172] train: loss: 0.0038363
[Epoch 7; Iter   648/ 2172] train: loss: 0.0016803
[Epoch 7; Iter   678/ 2172] train: loss: 0.0022617
[Epoch 7; Iter   708/ 2172] train: loss: 0.0035326
[Epoch 7; Iter   738/ 2172] train: loss: 0.0020861
[Epoch 7; Iter   768/ 2172] train: loss: 0.0016007
[Epoch 7; Iter   798/ 2172] train: loss: 0.0033578
[Epoch 7; Iter   828/ 2172] train: loss: 0.0022316
[Epoch 7; Iter   858/ 2172] train: loss: 0.0026517
[Epoch 7; Iter   888/ 2172] train: loss: 0.0016157
[Epoch 7; Iter   918/ 2172] train: loss: 0.0026465
[Epoch 7; Iter   948/ 2172] train: loss: 0.0031435
[Epoch 7; Iter   978/ 2172] train: loss: 0.0637586
[Epoch 7; Iter  1008/ 2172] train: loss: 0.0027250
[Epoch 7; Iter  1038/ 2172] train: loss: 0.0025163
[Epoch 7; Iter  1068/ 2172] train: loss: 0.0015109
[Epoch 7; Iter  1098/ 2172] train: loss: 0.0020821
[Epoch 7; Iter  1128/ 2172] train: loss: 0.0034949
[Epoch 7; Iter  1158/ 2172] train: loss: 0.0013779
[Epoch 7; Iter  1188/ 2172] train: loss: 0.0014776
[Epoch 7; Iter  1218/ 2172] train: loss: 0.0015675
[Epoch 7; Iter  1248/ 2172] train: loss: 0.0018456
[Epoch 7; Iter  1278/ 2172] train: loss: 0.0024688
[Epoch 7; Iter  1308/ 2172] train: loss: 0.0017655
[Epoch 7; Iter  1338/ 2172] train: loss: 0.0020858
[Epoch 7; Iter  1368/ 2172] train: loss: 0.0018280
[Epoch 7; Iter  1398/ 2172] train: loss: 0.1780428
[Epoch 7; Iter  1428/ 2172] train: loss: 0.0017506
[Epoch 7; Iter  1458/ 2172] train: loss: 0.0777938
[Epoch 7; Iter  1488/ 2172] train: loss: 0.0690921
[Epoch 7; Iter  1518/ 2172] train: loss: 0.0556389
[Epoch 7; Iter  1548/ 2172] train: loss: 0.0034761
[Epoch 7; Iter  1578/ 2172] train: loss: 0.0020622
[Epoch 7; Iter  1608/ 2172] train: loss: 0.0019711
[Epoch 7; Iter  1638/ 2172] train: loss: 0.0018197
[Epoch 7; Iter  1668/ 2172] train: loss: 0.0015511
[Epoch 7; Iter  1698/ 2172] train: loss: 0.0015641
[Epoch 7; Iter  1728/ 2172] train: loss: 0.0016949
[Epoch 7; Iter  1758/ 2172] train: loss: 0.0012968
[Epoch 7; Iter  1788/ 2172] train: loss: 0.0030441
[Epoch 7; Iter  1818/ 2172] train: loss: 0.0027931
[Epoch 7; Iter  1848/ 2172] train: loss: 0.0021337
[Epoch 7; Iter  1878/ 2172] train: loss: 0.0027480
[Epoch 7; Iter  1908/ 2172] train: loss: 0.0019062
[Epoch 7; Iter  1938/ 2172] train: loss: 0.0020055
[Epoch 7; Iter  1968/ 2172] train: loss: 0.0021710
[Epoch 7; Iter  1998/ 2172] train: loss: 0.0014728
[Epoch 7; Iter  2028/ 2172] train: loss: 0.0014101
[Epoch 7; Iter  2058/ 2172] train: loss: 0.0880841
[Epoch 7; Iter  2088/ 2172] train: loss: 0.0014008
[Epoch 7; Iter  2118/ 2172] train: loss: 0.0013805
[Epoch 7; Iter  2148/ 2172] train: loss: 0.0798524
[Epoch 7] ogbg-molmuv: 0.007787 val loss: 0.017984
[Epoch 7] ogbg-molmuv: 0.016054 test loss: 0.037472
[Epoch 8; Iter     6/ 2172] train: loss: 0.0028477
[Epoch 8; Iter    36/ 2172] train: loss: 0.0026505
[Epoch 8; Iter    66/ 2172] train: loss: 0.1125014
[Epoch 8; Iter    96/ 2172] train: loss: 0.0015425
[Epoch 8; Iter   126/ 2172] train: loss: 0.0013850
[Epoch 8; Iter   156/ 2172] train: loss: 0.0011258
[Epoch 8; Iter   186/ 2172] train: loss: 0.0011799
[Epoch 8; Iter   216/ 2172] train: loss: 0.0016609
[Epoch 8; Iter   246/ 2172] train: loss: 0.0044343
[Epoch 8; Iter   276/ 2172] train: loss: 0.0021753
[Epoch 8; Iter   306/ 2172] train: loss: 0.0027233
[Epoch 8; Iter   336/ 2172] train: loss: 0.0637011
[Epoch 8; Iter   366/ 2172] train: loss: 0.0026898
[Epoch 8; Iter   396/ 2172] train: loss: 0.0019325
[Epoch 8; Iter   426/ 2172] train: loss: 0.0020604
[Epoch 8; Iter   456/ 2172] train: loss: 0.0019618
[Epoch 8; Iter   486/ 2172] train: loss: 0.0017837
[Epoch 8; Iter   516/ 2172] train: loss: 0.0016645
[Epoch 8; Iter   546/ 2172] train: loss: 0.0020771
[Epoch 8; Iter   576/ 2172] train: loss: 0.0018133
[Epoch 8; Iter   606/ 2172] train: loss: 0.0018376
[Epoch 8; Iter   636/ 2172] train: loss: 0.0954777
[Epoch 8; Iter   666/ 2172] train: loss: 0.0019848
[Epoch 8; Iter   696/ 2172] train: loss: 0.0598046
[Epoch 8; Iter   726/ 2172] train: loss: 0.0970183
[Epoch 8; Iter   756/ 2172] train: loss: 0.0810942
[Epoch 8; Iter   786/ 2172] train: loss: 0.0923720
[Epoch 8; Iter   816/ 2172] train: loss: 0.0018458
[Epoch 8; Iter   846/ 2172] train: loss: 0.0020353
[Epoch 8; Iter   876/ 2172] train: loss: 0.0639269
[Epoch 8; Iter   906/ 2172] train: loss: 0.0023196
[Epoch 8; Iter   936/ 2172] train: loss: 0.0018301
[Epoch 8; Iter   966/ 2172] train: loss: 0.0016629
[Epoch 8; Iter   996/ 2172] train: loss: 0.0025739
[Epoch 8; Iter  1026/ 2172] train: loss: 0.0022399
[Epoch 8; Iter  1056/ 2172] train: loss: 0.0022099
[Epoch 8; Iter  1086/ 2172] train: loss: 0.0023157
[Epoch 8; Iter  1116/ 2172] train: loss: 0.0018426
[Epoch 8; Iter  1146/ 2172] train: loss: 0.0020456
[Epoch 8; Iter  1176/ 2172] train: loss: 0.0021648
[Epoch 8; Iter  1206/ 2172] train: loss: 0.0017130
[Epoch 8; Iter  1236/ 2172] train: loss: 0.0017287
[Epoch 8; Iter  1266/ 2172] train: loss: 0.0015587
[Epoch 8; Iter  1296/ 2172] train: loss: 0.0907270
[Epoch 8; Iter  1326/ 2172] train: loss: 0.0022066
[Epoch 8; Iter  1356/ 2172] train: loss: 0.0776904
[Epoch 8; Iter  1386/ 2172] train: loss: 0.0032396
[Epoch 8; Iter  1416/ 2172] train: loss: 0.0014541
[Epoch 8; Iter  1446/ 2172] train: loss: 0.0020605
[Epoch 8; Iter  1476/ 2172] train: loss: 0.0017193
[Epoch 8; Iter  1506/ 2172] train: loss: 0.0029244
[Epoch 8; Iter  1536/ 2172] train: loss: 0.0821421
[Epoch 8; Iter  1566/ 2172] train: loss: 0.0018136
[Epoch 8; Iter  1596/ 2172] train: loss: 0.0020603
[Epoch 8; Iter  1626/ 2172] train: loss: 0.0017243
[Epoch 8; Iter  1656/ 2172] train: loss: 0.0016197
[Epoch 8; Iter  1686/ 2172] train: loss: 0.0016720
[Epoch 8; Iter  1716/ 2172] train: loss: 0.0014665
[Epoch 8; Iter  1746/ 2172] train: loss: 0.0014649
[Epoch 8; Iter  1776/ 2172] train: loss: 0.0020033
[Epoch 8; Iter  1806/ 2172] train: loss: 0.0016412
[Epoch 8; Iter  1836/ 2172] train: loss: 0.0771358
[Epoch 8; Iter  1866/ 2172] train: loss: 0.0035241
[Epoch 8; Iter  1896/ 2172] train: loss: 0.0015673
[Epoch 8; Iter  1926/ 2172] train: loss: 0.0018095
[Epoch 8; Iter  1956/ 2172] train: loss: 0.0017405
[Epoch 8; Iter  1986/ 2172] train: loss: 0.0718502
[Epoch 8; Iter  2016/ 2172] train: loss: 0.0902176
[Epoch 8; Iter  2046/ 2172] train: loss: 0.0016856
[Epoch 6; Iter  1740/ 2172] train: loss: 0.0024195
[Epoch 6; Iter  1770/ 2172] train: loss: 0.0018798
[Epoch 6; Iter  1800/ 2172] train: loss: 0.0019885
[Epoch 6; Iter  1830/ 2172] train: loss: 0.0020843
[Epoch 6; Iter  1860/ 2172] train: loss: 0.0017624
[Epoch 6; Iter  1890/ 2172] train: loss: 0.0018887
[Epoch 6; Iter  1920/ 2172] train: loss: 0.0020616
[Epoch 6; Iter  1950/ 2172] train: loss: 0.0016982
[Epoch 6; Iter  1980/ 2172] train: loss: 0.0019933
[Epoch 6; Iter  2010/ 2172] train: loss: 0.0015975
[Epoch 6; Iter  2040/ 2172] train: loss: 0.1067640
[Epoch 6; Iter  2070/ 2172] train: loss: 0.0020717
[Epoch 6; Iter  2100/ 2172] train: loss: 0.0016403
[Epoch 6; Iter  2130/ 2172] train: loss: 0.0020854
[Epoch 6; Iter  2160/ 2172] train: loss: 0.0019913
[Epoch 6] ogbg-molmuv: 0.028421 val loss: 0.011837
[Epoch 6] ogbg-molmuv: 0.021620 test loss: 0.013816
[Epoch 7; Iter    18/ 2172] train: loss: 0.0017451
[Epoch 7; Iter    48/ 2172] train: loss: 0.0015539
[Epoch 7; Iter    78/ 2172] train: loss: 0.0012571
[Epoch 7; Iter   108/ 2172] train: loss: 0.0013188
[Epoch 7; Iter   138/ 2172] train: loss: 0.0030416
[Epoch 7; Iter   168/ 2172] train: loss: 0.0015057
[Epoch 7; Iter   198/ 2172] train: loss: 0.0020998
[Epoch 7; Iter   228/ 2172] train: loss: 0.0021106
[Epoch 7; Iter   258/ 2172] train: loss: 0.0024796
[Epoch 7; Iter   288/ 2172] train: loss: 0.0018461
[Epoch 7; Iter   318/ 2172] train: loss: 0.0017891
[Epoch 7; Iter   348/ 2172] train: loss: 0.0014945
[Epoch 7; Iter   378/ 2172] train: loss: 0.1366987
[Epoch 7; Iter   408/ 2172] train: loss: 0.0015906
[Epoch 7; Iter   438/ 2172] train: loss: 0.0020294
[Epoch 7; Iter   468/ 2172] train: loss: 0.1008406
[Epoch 7; Iter   498/ 2172] train: loss: 0.0016037
[Epoch 7; Iter   528/ 2172] train: loss: 0.0016209
[Epoch 7; Iter   558/ 2172] train: loss: 0.0017969
[Epoch 7; Iter   588/ 2172] train: loss: 0.0022725
[Epoch 7; Iter   618/ 2172] train: loss: 0.0023914
[Epoch 7; Iter   648/ 2172] train: loss: 0.0018052
[Epoch 7; Iter   678/ 2172] train: loss: 0.0013782
[Epoch 7; Iter   708/ 2172] train: loss: 0.0016485
[Epoch 7; Iter   738/ 2172] train: loss: 0.0018925
[Epoch 7; Iter   768/ 2172] train: loss: 0.0021443
[Epoch 7; Iter   798/ 2172] train: loss: 0.0021755
[Epoch 7; Iter   828/ 2172] train: loss: 0.0015408
[Epoch 7; Iter   858/ 2172] train: loss: 0.0017791
[Epoch 7; Iter   888/ 2172] train: loss: 0.0014525
[Epoch 7; Iter   918/ 2172] train: loss: 0.1149712
[Epoch 7; Iter   948/ 2172] train: loss: 0.0020740
[Epoch 7; Iter   978/ 2172] train: loss: 0.0049598
[Epoch 7; Iter  1008/ 2172] train: loss: 0.0021091
[Epoch 7; Iter  1038/ 2172] train: loss: 0.0018944
[Epoch 7; Iter  1068/ 2172] train: loss: 0.0016447
[Epoch 7; Iter  1098/ 2172] train: loss: 0.0021601
[Epoch 7; Iter  1128/ 2172] train: loss: 0.0014692
[Epoch 7; Iter  1158/ 2172] train: loss: 0.0041935
[Epoch 7; Iter  1188/ 2172] train: loss: 0.0754362
[Epoch 7; Iter  1218/ 2172] train: loss: 0.0022987
[Epoch 7; Iter  1248/ 2172] train: loss: 0.0021910
[Epoch 7; Iter  1278/ 2172] train: loss: 0.0017008
[Epoch 7; Iter  1308/ 2172] train: loss: 0.0767641
[Epoch 7; Iter  1338/ 2172] train: loss: 0.0030253
[Epoch 7; Iter  1368/ 2172] train: loss: 0.0849638
[Epoch 7; Iter  1398/ 2172] train: loss: 0.0819273
[Epoch 7; Iter  1428/ 2172] train: loss: 0.0022186
[Epoch 7; Iter  1458/ 2172] train: loss: 0.0017666
[Epoch 7; Iter  1488/ 2172] train: loss: 0.0014079
[Epoch 7; Iter  1518/ 2172] train: loss: 0.1125343
[Epoch 7; Iter  1548/ 2172] train: loss: 0.0027698
[Epoch 7; Iter  1578/ 2172] train: loss: 0.0025874
[Epoch 7; Iter  1608/ 2172] train: loss: 0.0021121
[Epoch 7; Iter  1638/ 2172] train: loss: 0.0015649
[Epoch 7; Iter  1668/ 2172] train: loss: 0.0015418
[Epoch 7; Iter  1698/ 2172] train: loss: 0.0017357
[Epoch 7; Iter  1728/ 2172] train: loss: 0.0839829
[Epoch 7; Iter  1758/ 2172] train: loss: 0.0018543
[Epoch 7; Iter  1788/ 2172] train: loss: 0.0018799
[Epoch 7; Iter  1818/ 2172] train: loss: 0.0023412
[Epoch 7; Iter  1848/ 2172] train: loss: 0.0021095
[Epoch 7; Iter  1878/ 2172] train: loss: 0.0023388
[Epoch 7; Iter  1908/ 2172] train: loss: 0.0022060
[Epoch 7; Iter  1938/ 2172] train: loss: 0.0012588
[Epoch 7; Iter  1968/ 2172] train: loss: 0.0010815
[Epoch 7; Iter  1998/ 2172] train: loss: 0.0016568
[Epoch 7; Iter  2028/ 2172] train: loss: 0.0676074
[Epoch 7; Iter  2058/ 2172] train: loss: 0.0014302
[Epoch 7; Iter  2088/ 2172] train: loss: 0.0018202
[Epoch 7; Iter  2118/ 2172] train: loss: 0.0015814
[Epoch 7; Iter  2148/ 2172] train: loss: 0.0016438
[Epoch 7] ogbg-molmuv: 0.021854 val loss: 0.017939
[Epoch 7] ogbg-molmuv: 0.010031 test loss: 0.016608
[Epoch 8; Iter     6/ 2172] train: loss: 0.0033689
[Epoch 8; Iter    36/ 2172] train: loss: 0.0022219
[Epoch 8; Iter    66/ 2172] train: loss: 0.0023420
[Epoch 8; Iter    96/ 2172] train: loss: 0.0025817
[Epoch 8; Iter   126/ 2172] train: loss: 0.0018958
[Epoch 8; Iter   156/ 2172] train: loss: 0.0016549
[Epoch 8; Iter   186/ 2172] train: loss: 0.0018646
[Epoch 8; Iter   216/ 2172] train: loss: 0.0663092
[Epoch 8; Iter   246/ 2172] train: loss: 0.0016325
[Epoch 8; Iter   276/ 2172] train: loss: 0.0012261
[Epoch 8; Iter   306/ 2172] train: loss: 0.0014272
[Epoch 8; Iter   336/ 2172] train: loss: 0.0010819
[Epoch 8; Iter   366/ 2172] train: loss: 0.0015061
[Epoch 8; Iter   396/ 2172] train: loss: 0.0876982
[Epoch 8; Iter   426/ 2172] train: loss: 0.0038678
[Epoch 8; Iter   456/ 2172] train: loss: 0.0022641
[Epoch 8; Iter   486/ 2172] train: loss: 0.0020116
[Epoch 8; Iter   516/ 2172] train: loss: 0.0016163
[Epoch 8; Iter   546/ 2172] train: loss: 0.1140060
[Epoch 8; Iter   576/ 2172] train: loss: 0.0016887
[Epoch 8; Iter   606/ 2172] train: loss: 0.0816231
[Epoch 8; Iter   636/ 2172] train: loss: 0.0651370
[Epoch 8; Iter   666/ 2172] train: loss: 0.0018523
[Epoch 8; Iter   696/ 2172] train: loss: 0.0021405
[Epoch 8; Iter   726/ 2172] train: loss: 0.0034153
[Epoch 8; Iter   756/ 2172] train: loss: 0.0034601
[Epoch 8; Iter   786/ 2172] train: loss: 0.0028198
[Epoch 8; Iter   816/ 2172] train: loss: 0.0023009
[Epoch 8; Iter   846/ 2172] train: loss: 0.0021031
[Epoch 8; Iter   876/ 2172] train: loss: 0.0632456
[Epoch 8; Iter   906/ 2172] train: loss: 0.0058910
[Epoch 8; Iter   936/ 2172] train: loss: 0.0015851
[Epoch 8; Iter   966/ 2172] train: loss: 0.0018510
[Epoch 8; Iter   996/ 2172] train: loss: 0.0017703
[Epoch 8; Iter  1026/ 2172] train: loss: 0.0020081
[Epoch 8; Iter  1056/ 2172] train: loss: 0.0018785
[Epoch 8; Iter  1086/ 2172] train: loss: 0.0019867
[Epoch 8; Iter  1116/ 2172] train: loss: 0.0020528
[Epoch 8; Iter  1146/ 2172] train: loss: 0.0023874
[Epoch 8; Iter  1176/ 2172] train: loss: 0.0989148
[Epoch 8; Iter  1206/ 2172] train: loss: 0.0022203
[Epoch 8; Iter  1236/ 2172] train: loss: 0.0039899
[Epoch 8; Iter  1266/ 2172] train: loss: 0.0033907
[Epoch 8; Iter  1296/ 2172] train: loss: 0.0022538
[Epoch 8; Iter  1326/ 2172] train: loss: 0.0021790
[Epoch 8; Iter  1356/ 2172] train: loss: 0.0021596
[Epoch 8; Iter  1386/ 2172] train: loss: 0.0029905
[Epoch 8; Iter  1416/ 2172] train: loss: 0.0033767
[Epoch 8; Iter  1446/ 2172] train: loss: 0.0021581
[Epoch 8; Iter  1476/ 2172] train: loss: 0.2407543
[Epoch 8; Iter  1506/ 2172] train: loss: 0.0028724
[Epoch 8; Iter  1536/ 2172] train: loss: 0.0028808
[Epoch 8; Iter  1566/ 2172] train: loss: 0.0020782
[Epoch 8; Iter  1596/ 2172] train: loss: 0.0018969
[Epoch 8; Iter  1626/ 2172] train: loss: 0.0026797
[Epoch 8; Iter  1656/ 2172] train: loss: 0.0020376
[Epoch 8; Iter  1686/ 2172] train: loss: 0.0018719
[Epoch 8; Iter  1716/ 2172] train: loss: 0.0013082
[Epoch 8; Iter  1746/ 2172] train: loss: 0.0015635
[Epoch 8; Iter  1776/ 2172] train: loss: 0.0015053
[Epoch 8; Iter  1806/ 2172] train: loss: 0.0017490
[Epoch 8; Iter  1836/ 2172] train: loss: 0.0015403
[Epoch 8; Iter  1866/ 2172] train: loss: 0.0014365
[Epoch 8; Iter  1896/ 2172] train: loss: 0.0020779
[Epoch 8; Iter  1926/ 2172] train: loss: 0.0016584
[Epoch 8; Iter  1956/ 2172] train: loss: 0.0011991
[Epoch 8; Iter  1986/ 2172] train: loss: 0.0016304
[Epoch 8; Iter  2016/ 2172] train: loss: 0.0016912
[Epoch 8; Iter  2046/ 2172] train: loss: 0.1138660
[Epoch 7; Iter  1368/ 1862] train: loss: 0.0017592
[Epoch 7; Iter  1398/ 1862] train: loss: 0.0013485
[Epoch 7; Iter  1428/ 1862] train: loss: 0.0014973
[Epoch 7; Iter  1458/ 1862] train: loss: 0.0018865
[Epoch 7; Iter  1488/ 1862] train: loss: 0.0015661
[Epoch 7; Iter  1518/ 1862] train: loss: 0.0020125
[Epoch 7; Iter  1548/ 1862] train: loss: 0.0020246
[Epoch 7; Iter  1578/ 1862] train: loss: 0.0014459
[Epoch 7; Iter  1608/ 1862] train: loss: 0.0019487
[Epoch 7; Iter  1638/ 1862] train: loss: 0.0018407
[Epoch 7; Iter  1668/ 1862] train: loss: 0.0015355
[Epoch 7; Iter  1698/ 1862] train: loss: 0.0903572
[Epoch 7; Iter  1728/ 1862] train: loss: 0.0015200
[Epoch 7; Iter  1758/ 1862] train: loss: 0.0017771
[Epoch 7; Iter  1788/ 1862] train: loss: 0.0856079
[Epoch 7; Iter  1818/ 1862] train: loss: 0.0015744
[Epoch 7; Iter  1848/ 1862] train: loss: 0.0021875
[Epoch 7] ogbg-molmuv: 0.012595 val loss: 0.013726
[Epoch 7] ogbg-molmuv: 0.014788 test loss: 0.012588
[Epoch 8; Iter    16/ 1862] train: loss: 0.1005663
[Epoch 8; Iter    46/ 1862] train: loss: 0.0036065
[Epoch 8; Iter    76/ 1862] train: loss: 0.0019480
[Epoch 8; Iter   106/ 1862] train: loss: 0.0019525
[Epoch 8; Iter   136/ 1862] train: loss: 0.0016734
[Epoch 8; Iter   166/ 1862] train: loss: 0.0020318
[Epoch 8; Iter   196/ 1862] train: loss: 0.0021898
[Epoch 8; Iter   226/ 1862] train: loss: 0.0018533
[Epoch 8; Iter   256/ 1862] train: loss: 0.0016694
[Epoch 8; Iter   286/ 1862] train: loss: 0.0022519
[Epoch 8; Iter   316/ 1862] train: loss: 0.0023658
[Epoch 8; Iter   346/ 1862] train: loss: 0.0040493
[Epoch 8; Iter   376/ 1862] train: loss: 0.0026220
[Epoch 8; Iter   406/ 1862] train: loss: 0.0692654
[Epoch 8; Iter   436/ 1862] train: loss: 0.0027496
[Epoch 8; Iter   466/ 1862] train: loss: 0.0622832
[Epoch 8; Iter   496/ 1862] train: loss: 0.0033102
[Epoch 8; Iter   526/ 1862] train: loss: 0.0022958
[Epoch 8; Iter   556/ 1862] train: loss: 0.0031134
[Epoch 8; Iter   586/ 1862] train: loss: 0.0020215
[Epoch 8; Iter   616/ 1862] train: loss: 0.0019942
[Epoch 8; Iter   646/ 1862] train: loss: 0.0015032
[Epoch 8; Iter   676/ 1862] train: loss: 0.0015894
[Epoch 8; Iter   706/ 1862] train: loss: 0.0018979
[Epoch 8; Iter   736/ 1862] train: loss: 0.0016242
[Epoch 8; Iter   766/ 1862] train: loss: 0.0017782
[Epoch 8; Iter   796/ 1862] train: loss: 0.0027562
[Epoch 8; Iter   826/ 1862] train: loss: 0.0690754
[Epoch 8; Iter   856/ 1862] train: loss: 0.0024246
[Epoch 8; Iter   886/ 1862] train: loss: 0.0025684
[Epoch 8; Iter   916/ 1862] train: loss: 0.1980962
[Epoch 8; Iter   946/ 1862] train: loss: 0.0933591
[Epoch 8; Iter   976/ 1862] train: loss: 0.0018058
[Epoch 8; Iter  1006/ 1862] train: loss: 0.0015635
[Epoch 8; Iter  1036/ 1862] train: loss: 0.0015382
[Epoch 8; Iter  1066/ 1862] train: loss: 0.0014926
[Epoch 8; Iter  1096/ 1862] train: loss: 0.0023424
[Epoch 8; Iter  1126/ 1862] train: loss: 0.0026602
[Epoch 8; Iter  1156/ 1862] train: loss: 0.0017790
[Epoch 8; Iter  1186/ 1862] train: loss: 0.0018873
[Epoch 8; Iter  1216/ 1862] train: loss: 0.0014848
[Epoch 8; Iter  1246/ 1862] train: loss: 0.0022359
[Epoch 8; Iter  1276/ 1862] train: loss: 0.0017520
[Epoch 8; Iter  1306/ 1862] train: loss: 0.0017679
[Epoch 8; Iter  1336/ 1862] train: loss: 0.0853890
[Epoch 8; Iter  1366/ 1862] train: loss: 0.0016645
[Epoch 8; Iter  1396/ 1862] train: loss: 0.0014977
[Epoch 8; Iter  1426/ 1862] train: loss: 0.0014935
[Epoch 8; Iter  1456/ 1862] train: loss: 0.0654181
[Epoch 8; Iter  1486/ 1862] train: loss: 0.0020855
[Epoch 8; Iter  1516/ 1862] train: loss: 0.0016729
[Epoch 8; Iter  1546/ 1862] train: loss: 0.0982451
[Epoch 8; Iter  1576/ 1862] train: loss: 0.0019429
[Epoch 8; Iter  1606/ 1862] train: loss: 0.0021962
[Epoch 8; Iter  1636/ 1862] train: loss: 0.0012473
[Epoch 8; Iter  1666/ 1862] train: loss: 0.0017315
[Epoch 8; Iter  1696/ 1862] train: loss: 0.0015434
[Epoch 8; Iter  1726/ 1862] train: loss: 0.0017954
[Epoch 8; Iter  1756/ 1862] train: loss: 0.0013781
[Epoch 8; Iter  1786/ 1862] train: loss: 0.0014297
[Epoch 8; Iter  1816/ 1862] train: loss: 0.0015397
[Epoch 8; Iter  1846/ 1862] train: loss: 0.0015555
[Epoch 8] ogbg-molmuv: 0.005546 val loss: 0.014823
[Epoch 8] ogbg-molmuv: 0.015496 test loss: 0.013648
[Epoch 9; Iter    14/ 1862] train: loss: 0.0014294
[Epoch 9; Iter    44/ 1862] train: loss: 0.0012450
[Epoch 9; Iter    74/ 1862] train: loss: 0.0740109
[Epoch 9; Iter   104/ 1862] train: loss: 0.0014785
[Epoch 9; Iter   134/ 1862] train: loss: 0.0016053
[Epoch 9; Iter   164/ 1862] train: loss: 0.0014883
[Epoch 9; Iter   194/ 1862] train: loss: 0.0014077
[Epoch 9; Iter   224/ 1862] train: loss: 0.0824457
[Epoch 9; Iter   254/ 1862] train: loss: 0.0818590
[Epoch 9; Iter   284/ 1862] train: loss: 0.0018799
[Epoch 9; Iter   314/ 1862] train: loss: 0.0014891
[Epoch 9; Iter   344/ 1862] train: loss: 0.0019052
[Epoch 9; Iter   374/ 1862] train: loss: 0.0018500
[Epoch 9; Iter   404/ 1862] train: loss: 0.0015737
[Epoch 9; Iter   434/ 1862] train: loss: 0.0018314
[Epoch 9; Iter   464/ 1862] train: loss: 0.0019142
[Epoch 9; Iter   494/ 1862] train: loss: 0.0018029
[Epoch 9; Iter   524/ 1862] train: loss: 0.0020865
[Epoch 9; Iter   554/ 1862] train: loss: 0.0020252
[Epoch 9; Iter   584/ 1862] train: loss: 0.0016950
[Epoch 9; Iter   614/ 1862] train: loss: 0.0025501
[Epoch 9; Iter   644/ 1862] train: loss: 0.0026285
[Epoch 9; Iter   674/ 1862] train: loss: 0.0019931
[Epoch 9; Iter   704/ 1862] train: loss: 0.0015252
[Epoch 9; Iter   734/ 1862] train: loss: 0.0016132
[Epoch 9; Iter   764/ 1862] train: loss: 0.0017035
[Epoch 9; Iter   794/ 1862] train: loss: 0.0016176
[Epoch 9; Iter   824/ 1862] train: loss: 0.0017484
[Epoch 9; Iter   854/ 1862] train: loss: 0.0016855
[Epoch 9; Iter   884/ 1862] train: loss: 0.0025613
[Epoch 9; Iter   914/ 1862] train: loss: 0.0023483
[Epoch 9; Iter   944/ 1862] train: loss: 0.0020466
[Epoch 9; Iter   974/ 1862] train: loss: 0.0025837
[Epoch 9; Iter  1004/ 1862] train: loss: 0.0022051
[Epoch 9; Iter  1034/ 1862] train: loss: 0.0629345
[Epoch 9; Iter  1064/ 1862] train: loss: 0.0030609
[Epoch 9; Iter  1094/ 1862] train: loss: 0.0026688
[Epoch 9; Iter  1124/ 1862] train: loss: 0.0016874
[Epoch 9; Iter  1154/ 1862] train: loss: 0.0019124
[Epoch 9; Iter  1184/ 1862] train: loss: 0.0018493
[Epoch 9; Iter  1214/ 1862] train: loss: 0.0018789
[Epoch 9; Iter  1244/ 1862] train: loss: 0.0027389
[Epoch 9; Iter  1274/ 1862] train: loss: 0.0017762
[Epoch 9; Iter  1304/ 1862] train: loss: 0.0017558
[Epoch 9; Iter  1334/ 1862] train: loss: 0.0019108
[Epoch 9; Iter  1364/ 1862] train: loss: 0.0019360
[Epoch 9; Iter  1394/ 1862] train: loss: 0.0016854
[Epoch 9; Iter  1424/ 1862] train: loss: 0.0019625
[Epoch 9; Iter  1454/ 1862] train: loss: 0.0018380
[Epoch 9; Iter  1484/ 1862] train: loss: 0.0644502
[Epoch 9; Iter  1514/ 1862] train: loss: 0.0819685
[Epoch 9; Iter  1544/ 1862] train: loss: 0.0021746
[Epoch 9; Iter  1574/ 1862] train: loss: 0.0026174
[Epoch 9; Iter  1604/ 1862] train: loss: 0.0747396
[Epoch 9; Iter  1634/ 1862] train: loss: 0.0027610
[Epoch 9; Iter  1664/ 1862] train: loss: 0.0018481
[Epoch 9; Iter  1694/ 1862] train: loss: 0.0019336
[Epoch 9; Iter  1724/ 1862] train: loss: 0.0017182
[Epoch 9; Iter  1754/ 1862] train: loss: 0.0017772
[Epoch 9; Iter  1784/ 1862] train: loss: 0.0019305
[Epoch 9; Iter  1814/ 1862] train: loss: 0.0018743
[Epoch 9; Iter  1844/ 1862] train: loss: 0.0016873
[Epoch 9] ogbg-molmuv: 0.009914 val loss: 0.093482
[Epoch 9] ogbg-molmuv: 0.038428 test loss: 0.072986
[Epoch 10; Iter    12/ 1862] train: loss: 0.0014452
[Epoch 10; Iter    42/ 1862] train: loss: 0.0023164
[Epoch 10; Iter    72/ 1862] train: loss: 0.0014773
[Epoch 10; Iter   102/ 1862] train: loss: 0.0013622
[Epoch 10; Iter   132/ 1862] train: loss: 0.0720134
[Epoch 10; Iter   162/ 1862] train: loss: 0.0035188
[Epoch 10; Iter   192/ 1862] train: loss: 0.0022874
[Epoch 10; Iter   222/ 1862] train: loss: 0.0015663
[Epoch 10; Iter   252/ 1862] train: loss: 0.0025816
[Epoch 10; Iter   282/ 1862] train: loss: 0.0016788
[Epoch 10; Iter   312/ 1862] train: loss: 0.0018629
[Epoch 10; Iter   342/ 1862] train: loss: 0.0013929
[Epoch 10; Iter   372/ 1862] train: loss: 0.0018223
[Epoch 7; Iter  1368/ 1862] train: loss: 0.0609235
[Epoch 7; Iter  1398/ 1862] train: loss: 0.0019369
[Epoch 7; Iter  1428/ 1862] train: loss: 0.0025444
[Epoch 7; Iter  1458/ 1862] train: loss: 0.0021019
[Epoch 7; Iter  1488/ 1862] train: loss: 0.0021513
[Epoch 7; Iter  1518/ 1862] train: loss: 0.0859395
[Epoch 7; Iter  1548/ 1862] train: loss: 0.0024411
[Epoch 7; Iter  1578/ 1862] train: loss: 0.0020365
[Epoch 7; Iter  1608/ 1862] train: loss: 0.0018786
[Epoch 7; Iter  1638/ 1862] train: loss: 0.0025107
[Epoch 7; Iter  1668/ 1862] train: loss: 0.0020737
[Epoch 7; Iter  1698/ 1862] train: loss: 0.0756286
[Epoch 7; Iter  1728/ 1862] train: loss: 0.0019351
[Epoch 7; Iter  1758/ 1862] train: loss: 0.0026184
[Epoch 7; Iter  1788/ 1862] train: loss: 0.0017942
[Epoch 7; Iter  1818/ 1862] train: loss: 0.0022575
[Epoch 7; Iter  1848/ 1862] train: loss: 0.0018482
[Epoch 7] ogbg-molmuv: 0.018404 val loss: 0.014419
[Epoch 7] ogbg-molmuv: 0.016068 test loss: 0.013607
[Epoch 8; Iter    16/ 1862] train: loss: 0.0937927
[Epoch 8; Iter    46/ 1862] train: loss: 0.0022818
[Epoch 8; Iter    76/ 1862] train: loss: 0.0625906
[Epoch 8; Iter   106/ 1862] train: loss: 0.0017468
[Epoch 8; Iter   136/ 1862] train: loss: 0.0016785
[Epoch 8; Iter   166/ 1862] train: loss: 0.0016498
[Epoch 8; Iter   196/ 1862] train: loss: 0.0875668
[Epoch 8; Iter   226/ 1862] train: loss: 0.0024762
[Epoch 8; Iter   256/ 1862] train: loss: 0.0020263
[Epoch 8; Iter   286/ 1862] train: loss: 0.0013170
[Epoch 8; Iter   316/ 1862] train: loss: 0.0020037
[Epoch 8; Iter   346/ 1862] train: loss: 0.0015364
[Epoch 8; Iter   376/ 1862] train: loss: 0.0017066
[Epoch 8; Iter   406/ 1862] train: loss: 0.0014083
[Epoch 8; Iter   436/ 1862] train: loss: 0.0663083
[Epoch 8; Iter   466/ 1862] train: loss: 0.0014184
[Epoch 8; Iter   496/ 1862] train: loss: 0.0013203
[Epoch 8; Iter   526/ 1862] train: loss: 0.0017756
[Epoch 8; Iter   556/ 1862] train: loss: 0.0016762
[Epoch 8; Iter   586/ 1862] train: loss: 0.0014616
[Epoch 8; Iter   616/ 1862] train: loss: 0.1125919
[Epoch 8; Iter   646/ 1862] train: loss: 0.0026435
[Epoch 8; Iter   676/ 1862] train: loss: 0.0015951
[Epoch 8; Iter   706/ 1862] train: loss: 0.0019659
[Epoch 8; Iter   736/ 1862] train: loss: 0.0031953
[Epoch 8; Iter   766/ 1862] train: loss: 0.0025202
[Epoch 8; Iter   796/ 1862] train: loss: 0.0026868
[Epoch 8; Iter   826/ 1862] train: loss: 0.0023627
[Epoch 8; Iter   856/ 1862] train: loss: 0.0020330
[Epoch 8; Iter   886/ 1862] train: loss: 0.0021449
[Epoch 8; Iter   916/ 1862] train: loss: 0.0020442
[Epoch 8; Iter   946/ 1862] train: loss: 0.0017434
[Epoch 8; Iter   976/ 1862] train: loss: 0.0013617
[Epoch 8; Iter  1006/ 1862] train: loss: 0.0016057
[Epoch 8; Iter  1036/ 1862] train: loss: 0.0015527
[Epoch 8; Iter  1066/ 1862] train: loss: 0.0016340
[Epoch 8; Iter  1096/ 1862] train: loss: 0.0017675
[Epoch 8; Iter  1126/ 1862] train: loss: 0.0013848
[Epoch 8; Iter  1156/ 1862] train: loss: 0.0015775
[Epoch 8; Iter  1186/ 1862] train: loss: 0.0016607
[Epoch 8; Iter  1216/ 1862] train: loss: 0.0019490
[Epoch 8; Iter  1246/ 1862] train: loss: 0.0024545
[Epoch 8; Iter  1276/ 1862] train: loss: 0.0021480
[Epoch 8; Iter  1306/ 1862] train: loss: 0.0021530
[Epoch 8; Iter  1336/ 1862] train: loss: 0.0019428
[Epoch 8; Iter  1366/ 1862] train: loss: 0.0015432
[Epoch 8; Iter  1396/ 1862] train: loss: 0.0014011
[Epoch 8; Iter  1426/ 1862] train: loss: 0.0637281
[Epoch 8; Iter  1456/ 1862] train: loss: 0.0018476
[Epoch 8; Iter  1486/ 1862] train: loss: 0.0014980
[Epoch 8; Iter  1516/ 1862] train: loss: 0.0757663
[Epoch 8; Iter  1546/ 1862] train: loss: 0.1681594
[Epoch 8; Iter  1576/ 1862] train: loss: 0.0018818
[Epoch 8; Iter  1606/ 1862] train: loss: 0.0017804
[Epoch 8; Iter  1636/ 1862] train: loss: 0.0021128
[Epoch 8; Iter  1666/ 1862] train: loss: 0.0013262
[Epoch 8; Iter  1696/ 1862] train: loss: 0.0013381
[Epoch 8; Iter  1726/ 1862] train: loss: 0.0015626
[Epoch 8; Iter  1756/ 1862] train: loss: 0.0013832
[Epoch 8; Iter  1786/ 1862] train: loss: 0.0017925
[Epoch 8; Iter  1816/ 1862] train: loss: 0.0019508
[Epoch 8; Iter  1846/ 1862] train: loss: 0.0029952
[Epoch 8] ogbg-molmuv: 0.018735 val loss: 0.017642
[Epoch 8] ogbg-molmuv: 0.012408 test loss: 0.016703
[Epoch 9; Iter    14/ 1862] train: loss: 0.0030854
[Epoch 9; Iter    44/ 1862] train: loss: 0.0024635
[Epoch 9; Iter    74/ 1862] train: loss: 0.0026284
[Epoch 9; Iter   104/ 1862] train: loss: 0.0790717
[Epoch 9; Iter   134/ 1862] train: loss: 0.0017273
[Epoch 9; Iter   164/ 1862] train: loss: 0.0014076
[Epoch 9; Iter   194/ 1862] train: loss: 0.0012587
[Epoch 9; Iter   224/ 1862] train: loss: 0.0014582
[Epoch 9; Iter   254/ 1862] train: loss: 0.0011700
[Epoch 9; Iter   284/ 1862] train: loss: 0.0010752
[Epoch 9; Iter   314/ 1862] train: loss: 0.0014316
[Epoch 9; Iter   344/ 1862] train: loss: 0.0014236
[Epoch 9; Iter   374/ 1862] train: loss: 0.0012785
[Epoch 9; Iter   404/ 1862] train: loss: 0.0024538
[Epoch 9; Iter   434/ 1862] train: loss: 0.0023405
[Epoch 9; Iter   464/ 1862] train: loss: 0.0021827
[Epoch 9; Iter   494/ 1862] train: loss: 0.0828861
[Epoch 9; Iter   524/ 1862] train: loss: 0.0028183
[Epoch 9; Iter   554/ 1862] train: loss: 0.0974011
[Epoch 9; Iter   584/ 1862] train: loss: 0.0015261
[Epoch 9; Iter   614/ 1862] train: loss: 0.0016511
[Epoch 9; Iter   644/ 1862] train: loss: 0.0016264
[Epoch 9; Iter   674/ 1862] train: loss: 0.0018631
[Epoch 9; Iter   704/ 1862] train: loss: 0.0550116
[Epoch 9; Iter   734/ 1862] train: loss: 0.0028794
[Epoch 9; Iter   764/ 1862] train: loss: 0.1351622
[Epoch 9; Iter   794/ 1862] train: loss: 0.0021654
[Epoch 9; Iter   824/ 1862] train: loss: 0.0026427
[Epoch 9; Iter   854/ 1862] train: loss: 0.0019885
[Epoch 9; Iter   884/ 1862] train: loss: 0.0020180
[Epoch 9; Iter   914/ 1862] train: loss: 0.0018877
[Epoch 9; Iter   944/ 1862] train: loss: 0.0017071
[Epoch 9; Iter   974/ 1862] train: loss: 0.0014816
[Epoch 9; Iter  1004/ 1862] train: loss: 0.0017203
[Epoch 9; Iter  1034/ 1862] train: loss: 0.0019175
[Epoch 9; Iter  1064/ 1862] train: loss: 0.0029248
[Epoch 9; Iter  1094/ 1862] train: loss: 0.0019952
[Epoch 9; Iter  1124/ 1862] train: loss: 0.0024646
[Epoch 9; Iter  1154/ 1862] train: loss: 0.0020832
[Epoch 9; Iter  1184/ 1862] train: loss: 0.0023079
[Epoch 9; Iter  1214/ 1862] train: loss: 0.0019772
[Epoch 9; Iter  1244/ 1862] train: loss: 0.0013976
[Epoch 9; Iter  1274/ 1862] train: loss: 0.0021786
[Epoch 9; Iter  1304/ 1862] train: loss: 0.0024832
[Epoch 9; Iter  1334/ 1862] train: loss: 0.0017695
[Epoch 9; Iter  1364/ 1862] train: loss: 0.0020308
[Epoch 9; Iter  1394/ 1862] train: loss: 0.0026658
[Epoch 9; Iter  1424/ 1862] train: loss: 0.0017896
[Epoch 9; Iter  1454/ 1862] train: loss: 0.0017954
[Epoch 9; Iter  1484/ 1862] train: loss: 0.0015995
[Epoch 9; Iter  1514/ 1862] train: loss: 0.0671450
[Epoch 9; Iter  1544/ 1862] train: loss: 0.0016807
[Epoch 9; Iter  1574/ 1862] train: loss: 0.0013437
[Epoch 9; Iter  1604/ 1862] train: loss: 0.0013734
[Epoch 9; Iter  1634/ 1862] train: loss: 0.0030009
[Epoch 9; Iter  1664/ 1862] train: loss: 0.0022435
[Epoch 9; Iter  1694/ 1862] train: loss: 0.0028130
[Epoch 9; Iter  1724/ 1862] train: loss: 0.0023230
[Epoch 9; Iter  1754/ 1862] train: loss: 0.0023198
[Epoch 9; Iter  1784/ 1862] train: loss: 0.0020799
[Epoch 9; Iter  1814/ 1862] train: loss: 0.0019966
[Epoch 9; Iter  1844/ 1862] train: loss: 0.0019160
[Epoch 9] ogbg-molmuv: 0.010680 val loss: 0.013765
[Epoch 9] ogbg-molmuv: 0.012812 test loss: 0.012798
[Epoch 10; Iter    12/ 1862] train: loss: 0.0018805
[Epoch 10; Iter    42/ 1862] train: loss: 0.0021954
[Epoch 10; Iter    72/ 1862] train: loss: 0.0017620
[Epoch 10; Iter   102/ 1862] train: loss: 0.0018334
[Epoch 10; Iter   132/ 1862] train: loss: 0.0015459
[Epoch 10; Iter   162/ 1862] train: loss: 0.0651849
[Epoch 10; Iter   192/ 1862] train: loss: 0.0013741
[Epoch 10; Iter   222/ 1862] train: loss: 0.1114171
[Epoch 10; Iter   252/ 1862] train: loss: 0.0818377
[Epoch 10; Iter   282/ 1862] train: loss: 0.0033767
[Epoch 10; Iter   312/ 1862] train: loss: 0.0886562
[Epoch 10; Iter   342/ 1862] train: loss: 0.0023485
[Epoch 10; Iter   372/ 1862] train: loss: 0.0020791
[Epoch 7; Iter  1368/ 1862] train: loss: 0.0019476
[Epoch 7; Iter  1398/ 1862] train: loss: 0.0020371
[Epoch 7; Iter  1428/ 1862] train: loss: 0.0020002
[Epoch 7; Iter  1458/ 1862] train: loss: 0.0022975
[Epoch 7; Iter  1488/ 1862] train: loss: 0.0020156
[Epoch 7; Iter  1518/ 1862] train: loss: 0.0021144
[Epoch 7; Iter  1548/ 1862] train: loss: 0.0023872
[Epoch 7; Iter  1578/ 1862] train: loss: 0.0020664
[Epoch 7; Iter  1608/ 1862] train: loss: 0.0028778
[Epoch 7; Iter  1638/ 1862] train: loss: 0.0022869
[Epoch 7; Iter  1668/ 1862] train: loss: 0.0024856
[Epoch 7; Iter  1698/ 1862] train: loss: 0.0756406
[Epoch 7; Iter  1728/ 1862] train: loss: 0.0027977
[Epoch 7; Iter  1758/ 1862] train: loss: 0.0036438
[Epoch 7; Iter  1788/ 1862] train: loss: 0.0021808
[Epoch 7; Iter  1818/ 1862] train: loss: 0.0019862
[Epoch 7; Iter  1848/ 1862] train: loss: 0.0016201
[Epoch 7] ogbg-molmuv: 0.011466 val loss: 0.013758
[Epoch 7] ogbg-molmuv: 0.017270 test loss: 0.012465
[Epoch 8; Iter    16/ 1862] train: loss: 0.0523486
[Epoch 8; Iter    46/ 1862] train: loss: 0.0020353
[Epoch 8; Iter    76/ 1862] train: loss: 0.0019215
[Epoch 8; Iter   106/ 1862] train: loss: 0.0018331
[Epoch 8; Iter   136/ 1862] train: loss: 0.0017007
[Epoch 8; Iter   166/ 1862] train: loss: 0.0033240
[Epoch 8; Iter   196/ 1862] train: loss: 0.0017897
[Epoch 8; Iter   226/ 1862] train: loss: 0.0018353
[Epoch 8; Iter   256/ 1862] train: loss: 0.0021984
[Epoch 8; Iter   286/ 1862] train: loss: 0.0017060
[Epoch 8; Iter   316/ 1862] train: loss: 0.0015220
[Epoch 8; Iter   346/ 1862] train: loss: 0.0015558
[Epoch 8; Iter   376/ 1862] train: loss: 0.0019091
[Epoch 8; Iter   406/ 1862] train: loss: 0.0017909
[Epoch 8; Iter   436/ 1862] train: loss: 0.0022417
[Epoch 8; Iter   466/ 1862] train: loss: 0.0021015
[Epoch 8; Iter   496/ 1862] train: loss: 0.0015348
[Epoch 8; Iter   526/ 1862] train: loss: 0.0020200
[Epoch 8; Iter   556/ 1862] train: loss: 0.0017536
[Epoch 8; Iter   586/ 1862] train: loss: 0.0018491
[Epoch 8; Iter   616/ 1862] train: loss: 0.0021701
[Epoch 8; Iter   646/ 1862] train: loss: 0.0016538
[Epoch 8; Iter   676/ 1862] train: loss: 0.0017451
[Epoch 8; Iter   706/ 1862] train: loss: 0.0029872
[Epoch 8; Iter   736/ 1862] train: loss: 0.0023433
[Epoch 8; Iter   766/ 1862] train: loss: 0.0024956
[Epoch 8; Iter   796/ 1862] train: loss: 0.0024765
[Epoch 8; Iter   826/ 1862] train: loss: 0.0025941
[Epoch 8; Iter   856/ 1862] train: loss: 0.0026372
[Epoch 8; Iter   886/ 1862] train: loss: 0.0026576
[Epoch 8; Iter   916/ 1862] train: loss: 0.0015967
[Epoch 8; Iter   946/ 1862] train: loss: 0.0018691
[Epoch 8; Iter   976/ 1862] train: loss: 0.0020190
[Epoch 8; Iter  1006/ 1862] train: loss: 0.0013695
[Epoch 8; Iter  1036/ 1862] train: loss: 0.0513175
[Epoch 8; Iter  1066/ 1862] train: loss: 0.0016328
[Epoch 8; Iter  1096/ 1862] train: loss: 0.0014296
[Epoch 8; Iter  1126/ 1862] train: loss: 0.0012515
[Epoch 8; Iter  1156/ 1862] train: loss: 0.0915249
[Epoch 8; Iter  1186/ 1862] train: loss: 0.0644765
[Epoch 8; Iter  1216/ 1862] train: loss: 0.0018898
[Epoch 8; Iter  1246/ 1862] train: loss: 0.0017293
[Epoch 8; Iter  1276/ 1862] train: loss: 0.0031079
[Epoch 8; Iter  1306/ 1862] train: loss: 0.0014596
[Epoch 8; Iter  1336/ 1862] train: loss: 0.0015261
[Epoch 8; Iter  1366/ 1862] train: loss: 0.0021717
[Epoch 8; Iter  1396/ 1862] train: loss: 0.0016456
[Epoch 8; Iter  1426/ 1862] train: loss: 0.0014535
[Epoch 8; Iter  1456/ 1862] train: loss: 0.0023246
[Epoch 8; Iter  1486/ 1862] train: loss: 0.0020292
[Epoch 8; Iter  1516/ 1862] train: loss: 0.0023537
[Epoch 8; Iter  1546/ 1862] train: loss: 0.0017820
[Epoch 8; Iter  1576/ 1862] train: loss: 0.0016902
[Epoch 8; Iter  1606/ 1862] train: loss: 0.0016991
[Epoch 8; Iter  1636/ 1862] train: loss: 0.0691262
[Epoch 8; Iter  1666/ 1862] train: loss: 0.0024239
[Epoch 8; Iter  1696/ 1862] train: loss: 0.0024340
[Epoch 8; Iter  1726/ 1862] train: loss: 0.0019898
[Epoch 8; Iter  1756/ 1862] train: loss: 0.0020162
[Epoch 8; Iter  1786/ 1862] train: loss: 0.0016092
[Epoch 8; Iter  1816/ 1862] train: loss: 0.0020741
[Epoch 8; Iter  1846/ 1862] train: loss: 0.0020225
[Epoch 8] ogbg-molmuv: 0.018322 val loss: 0.013924
[Epoch 8] ogbg-molmuv: 0.012736 test loss: 0.012842
[Epoch 9; Iter    14/ 1862] train: loss: 0.0020225
[Epoch 9; Iter    44/ 1862] train: loss: 0.0047712
[Epoch 9; Iter    74/ 1862] train: loss: 0.1645332
[Epoch 9; Iter   104/ 1862] train: loss: 0.0023272
[Epoch 9; Iter   134/ 1862] train: loss: 0.0022919
[Epoch 9; Iter   164/ 1862] train: loss: 0.0019498
[Epoch 9; Iter   194/ 1862] train: loss: 0.0025250
[Epoch 9; Iter   224/ 1862] train: loss: 0.0827088
[Epoch 9; Iter   254/ 1862] train: loss: 0.0025185
[Epoch 9; Iter   284/ 1862] train: loss: 0.0672143
[Epoch 9; Iter   314/ 1862] train: loss: 0.0898706
[Epoch 9; Iter   344/ 1862] train: loss: 0.0013529
[Epoch 9; Iter   374/ 1862] train: loss: 0.0016813
[Epoch 9; Iter   404/ 1862] train: loss: 0.0018070
[Epoch 9; Iter   434/ 1862] train: loss: 0.0014470
[Epoch 9; Iter   464/ 1862] train: loss: 0.0023131
[Epoch 9; Iter   494/ 1862] train: loss: 0.0019627
[Epoch 9; Iter   524/ 1862] train: loss: 0.0559715
[Epoch 9; Iter   554/ 1862] train: loss: 0.0015043
[Epoch 9; Iter   584/ 1862] train: loss: 0.0023322
[Epoch 9; Iter   614/ 1862] train: loss: 0.0020572
[Epoch 9; Iter   644/ 1862] train: loss: 0.0724351
[Epoch 9; Iter   674/ 1862] train: loss: 0.0026498
[Epoch 9; Iter   704/ 1862] train: loss: 0.0434831
[Epoch 9; Iter   734/ 1862] train: loss: 0.0019717
[Epoch 9; Iter   764/ 1862] train: loss: 0.0640656
[Epoch 9; Iter   794/ 1862] train: loss: 0.0759919
[Epoch 9; Iter   824/ 1862] train: loss: 0.0021504
[Epoch 9; Iter   854/ 1862] train: loss: 0.0017359
[Epoch 9; Iter   884/ 1862] train: loss: 0.1733742
[Epoch 9; Iter   914/ 1862] train: loss: 0.0016232
[Epoch 9; Iter   944/ 1862] train: loss: 0.0017560
[Epoch 9; Iter   974/ 1862] train: loss: 0.0013131
[Epoch 9; Iter  1004/ 1862] train: loss: 0.0016782
[Epoch 9; Iter  1034/ 1862] train: loss: 0.0018728
[Epoch 9; Iter  1064/ 1862] train: loss: 0.0017953
[Epoch 9; Iter  1094/ 1862] train: loss: 0.0018188
[Epoch 9; Iter  1124/ 1862] train: loss: 0.0017831
[Epoch 9; Iter  1154/ 1862] train: loss: 0.1428432
[Epoch 9; Iter  1184/ 1862] train: loss: 0.0027185
[Epoch 9; Iter  1214/ 1862] train: loss: 0.0670596
[Epoch 9; Iter  1244/ 1862] train: loss: 0.0024336
[Epoch 9; Iter  1274/ 1862] train: loss: 0.0642107
[Epoch 9; Iter  1304/ 1862] train: loss: 0.0020397
[Epoch 9; Iter  1334/ 1862] train: loss: 0.0020160
[Epoch 9; Iter  1364/ 1862] train: loss: 0.0024834
[Epoch 9; Iter  1394/ 1862] train: loss: 0.0029110
[Epoch 9; Iter  1424/ 1862] train: loss: 0.0012811
[Epoch 9; Iter  1454/ 1862] train: loss: 0.0014006
[Epoch 9; Iter  1484/ 1862] train: loss: 0.0012829
[Epoch 9; Iter  1514/ 1862] train: loss: 0.0014376
[Epoch 9; Iter  1544/ 1862] train: loss: 0.0013794
[Epoch 9; Iter  1574/ 1862] train: loss: 0.0832899
[Epoch 9; Iter  1604/ 1862] train: loss: 0.0817056
[Epoch 9; Iter  1634/ 1862] train: loss: 0.0013177
[Epoch 9; Iter  1664/ 1862] train: loss: 0.0019592
[Epoch 9; Iter  1694/ 1862] train: loss: 0.0015370
[Epoch 9; Iter  1724/ 1862] train: loss: 0.0015170
[Epoch 9; Iter  1754/ 1862] train: loss: 0.0020472
[Epoch 9; Iter  1784/ 1862] train: loss: 0.0019865
[Epoch 9; Iter  1814/ 1862] train: loss: 0.0888214
[Epoch 9; Iter  1844/ 1862] train: loss: 0.0020282
[Epoch 9] ogbg-molmuv: 0.022137 val loss: 0.014338
[Epoch 9] ogbg-molmuv: 0.023595 test loss: 0.013034
[Epoch 10; Iter    12/ 1862] train: loss: 0.0031752
[Epoch 10; Iter    42/ 1862] train: loss: 0.0021241
[Epoch 10; Iter    72/ 1862] train: loss: 0.0019697
[Epoch 10; Iter   102/ 1862] train: loss: 0.0029066
[Epoch 10; Iter   132/ 1862] train: loss: 0.0017527
[Epoch 10; Iter   162/ 1862] train: loss: 0.0032010
[Epoch 10; Iter   192/ 1862] train: loss: 0.0016353
[Epoch 10; Iter   222/ 1862] train: loss: 0.0016117
[Epoch 10; Iter   252/ 1862] train: loss: 0.0017246
[Epoch 10; Iter   282/ 1862] train: loss: 0.0015559
[Epoch 10; Iter   312/ 1862] train: loss: 0.0018511
[Epoch 10; Iter   342/ 1862] train: loss: 0.0015695
[Epoch 10; Iter   372/ 1862] train: loss: 0.0019933
[Epoch 7; Iter  2442/ 2483] train: loss: 0.0676997
[Epoch 7; Iter  2472/ 2483] train: loss: 0.0024829
[Epoch 7] ogbg-molmuv: 0.024053 val loss: 0.244899
[Epoch 7] ogbg-molmuv: 0.014814 test loss: 0.290775
[Epoch 8; Iter    19/ 2483] train: loss: 0.0035203
[Epoch 8; Iter    49/ 2483] train: loss: 0.0024589
[Epoch 8; Iter    79/ 2483] train: loss: 0.0012956
[Epoch 8; Iter   109/ 2483] train: loss: 0.0015917
[Epoch 8; Iter   139/ 2483] train: loss: 0.0014864
[Epoch 8; Iter   169/ 2483] train: loss: 0.0016143
[Epoch 8; Iter   199/ 2483] train: loss: 0.0027787
[Epoch 8; Iter   229/ 2483] train: loss: 0.0422110
[Epoch 8; Iter   259/ 2483] train: loss: 0.0020957
[Epoch 8; Iter   289/ 2483] train: loss: 0.0015734
[Epoch 8; Iter   319/ 2483] train: loss: 0.0014516
[Epoch 8; Iter   349/ 2483] train: loss: 0.0019175
[Epoch 8; Iter   379/ 2483] train: loss: 0.0018783
[Epoch 8; Iter   409/ 2483] train: loss: 0.0017986
[Epoch 8; Iter   439/ 2483] train: loss: 0.0015909
[Epoch 8; Iter   469/ 2483] train: loss: 0.0016486
[Epoch 8; Iter   499/ 2483] train: loss: 0.0632186
[Epoch 8; Iter   529/ 2483] train: loss: 0.0018868
[Epoch 8; Iter   559/ 2483] train: loss: 0.0016799
[Epoch 8; Iter   589/ 2483] train: loss: 0.0840965
[Epoch 8; Iter   619/ 2483] train: loss: 0.0017243
[Epoch 8; Iter   649/ 2483] train: loss: 0.0018634
[Epoch 8; Iter   679/ 2483] train: loss: 0.0013988
[Epoch 8; Iter   709/ 2483] train: loss: 0.0018830
[Epoch 8; Iter   739/ 2483] train: loss: 0.0026258
[Epoch 8; Iter   769/ 2483] train: loss: 0.0694496
[Epoch 8; Iter   799/ 2483] train: loss: 0.0030778
[Epoch 8; Iter   829/ 2483] train: loss: 0.0025118
[Epoch 8; Iter   859/ 2483] train: loss: 0.0019041
[Epoch 8; Iter   889/ 2483] train: loss: 0.0019825
[Epoch 8; Iter   919/ 2483] train: loss: 0.0013582
[Epoch 8; Iter   949/ 2483] train: loss: 0.0014718
[Epoch 8; Iter   979/ 2483] train: loss: 0.0018229
[Epoch 8; Iter  1009/ 2483] train: loss: 0.0019831
[Epoch 8; Iter  1039/ 2483] train: loss: 0.0018715
[Epoch 8; Iter  1069/ 2483] train: loss: 0.0026247
[Epoch 8; Iter  1099/ 2483] train: loss: 0.0024520
[Epoch 8; Iter  1129/ 2483] train: loss: 0.0021919
[Epoch 8; Iter  1159/ 2483] train: loss: 0.0025287
[Epoch 8; Iter  1189/ 2483] train: loss: 0.0805759
[Epoch 8; Iter  1219/ 2483] train: loss: 0.0041251
[Epoch 8; Iter  1249/ 2483] train: loss: 0.0023928
[Epoch 8; Iter  1279/ 2483] train: loss: 0.0965082
[Epoch 8; Iter  1309/ 2483] train: loss: 0.0019637
[Epoch 8; Iter  1339/ 2483] train: loss: 0.0021039
[Epoch 8; Iter  1369/ 2483] train: loss: 0.0778980
[Epoch 8; Iter  1399/ 2483] train: loss: 0.0024933
[Epoch 8; Iter  1429/ 2483] train: loss: 0.0020691
[Epoch 8; Iter  1459/ 2483] train: loss: 0.0022559
[Epoch 8; Iter  1489/ 2483] train: loss: 0.0020181
[Epoch 8; Iter  1519/ 2483] train: loss: 0.0020934
[Epoch 8; Iter  1549/ 2483] train: loss: 0.0019369
[Epoch 8; Iter  1579/ 2483] train: loss: 0.0023734
[Epoch 8; Iter  1609/ 2483] train: loss: 0.0020389
[Epoch 8; Iter  1639/ 2483] train: loss: 0.0018982
[Epoch 8; Iter  1669/ 2483] train: loss: 0.0018191
[Epoch 8; Iter  1699/ 2483] train: loss: 0.0018803
[Epoch 8; Iter  1729/ 2483] train: loss: 0.0013374
[Epoch 8; Iter  1759/ 2483] train: loss: 0.0013618
[Epoch 8; Iter  1789/ 2483] train: loss: 0.0019389
[Epoch 8; Iter  1819/ 2483] train: loss: 0.0021638
[Epoch 8; Iter  1849/ 2483] train: loss: 0.0020615
[Epoch 8; Iter  1879/ 2483] train: loss: 0.0015704
[Epoch 8; Iter  1909/ 2483] train: loss: 0.0020252
[Epoch 8; Iter  1939/ 2483] train: loss: 0.0015749
[Epoch 8; Iter  1969/ 2483] train: loss: 0.0024498
[Epoch 8; Iter  1999/ 2483] train: loss: 0.0013297
[Epoch 8; Iter  2029/ 2483] train: loss: 0.1722771
[Epoch 8; Iter  2059/ 2483] train: loss: 0.0015846
[Epoch 8; Iter  2089/ 2483] train: loss: 0.0016331
[Epoch 8; Iter  2119/ 2483] train: loss: 0.0019576
[Epoch 8; Iter  2149/ 2483] train: loss: 0.0020090
[Epoch 8; Iter  2179/ 2483] train: loss: 0.0017269
[Epoch 8; Iter  2209/ 2483] train: loss: 0.0020896
[Epoch 8; Iter  2239/ 2483] train: loss: 0.0016537
[Epoch 8; Iter  2269/ 2483] train: loss: 0.0016264
[Epoch 8; Iter  2299/ 2483] train: loss: 0.0016939
[Epoch 8; Iter  2329/ 2483] train: loss: 0.0018388
[Epoch 8; Iter  2359/ 2483] train: loss: 0.0020703
[Epoch 8; Iter  2389/ 2483] train: loss: 0.0021384
[Epoch 8; Iter  2419/ 2483] train: loss: 0.0018339
[Epoch 8; Iter  2449/ 2483] train: loss: 0.0014013
[Epoch 8; Iter  2479/ 2483] train: loss: 0.0021351
[Epoch 8] ogbg-molmuv: 0.014468 val loss: 0.010524
[Epoch 8] ogbg-molmuv: 0.023449 test loss: 0.014726
[Epoch 9; Iter    26/ 2483] train: loss: 0.0026551
[Epoch 9; Iter    56/ 2483] train: loss: 0.0037822
[Epoch 9; Iter    86/ 2483] train: loss: 0.2210260
[Epoch 9; Iter   116/ 2483] train: loss: 0.0015046
[Epoch 9; Iter   146/ 2483] train: loss: 0.0018468
[Epoch 9; Iter   176/ 2483] train: loss: 0.0018474
[Epoch 9; Iter   206/ 2483] train: loss: 0.0016969
[Epoch 9; Iter   236/ 2483] train: loss: 0.0778894
[Epoch 9; Iter   266/ 2483] train: loss: 0.0020856
[Epoch 9; Iter   296/ 2483] train: loss: 0.0019771
[Epoch 9; Iter   326/ 2483] train: loss: 0.0019303
[Epoch 9; Iter   356/ 2483] train: loss: 0.0020939
[Epoch 9; Iter   386/ 2483] train: loss: 0.0019331
[Epoch 9; Iter   416/ 2483] train: loss: 0.0030024
[Epoch 9; Iter   446/ 2483] train: loss: 0.0020672
[Epoch 9; Iter   476/ 2483] train: loss: 0.0021482
[Epoch 9; Iter   506/ 2483] train: loss: 0.0642634
[Epoch 9; Iter   536/ 2483] train: loss: 0.0025881
[Epoch 9; Iter   566/ 2483] train: loss: 0.0020958
[Epoch 9; Iter   596/ 2483] train: loss: 0.0022570
[Epoch 9; Iter   626/ 2483] train: loss: 0.0020831
[Epoch 9; Iter   656/ 2483] train: loss: 0.0013965
[Epoch 9; Iter   686/ 2483] train: loss: 0.0019615
[Epoch 9; Iter   716/ 2483] train: loss: 0.0826326
[Epoch 9; Iter   746/ 2483] train: loss: 0.0019789
[Epoch 9; Iter   776/ 2483] train: loss: 0.2514559
[Epoch 9; Iter   806/ 2483] train: loss: 0.0018125
[Epoch 9; Iter   836/ 2483] train: loss: 0.0785543
[Epoch 9; Iter   866/ 2483] train: loss: 0.0021658
[Epoch 9; Iter   896/ 2483] train: loss: 0.0022688
[Epoch 9; Iter   926/ 2483] train: loss: 0.0015481
[Epoch 9; Iter   956/ 2483] train: loss: 0.0014843
[Epoch 9; Iter   986/ 2483] train: loss: 0.0016526
[Epoch 9; Iter  1016/ 2483] train: loss: 0.0742163
[Epoch 9; Iter  1046/ 2483] train: loss: 0.0024993
[Epoch 9; Iter  1076/ 2483] train: loss: 0.0017131
[Epoch 9; Iter  1106/ 2483] train: loss: 0.0012355
[Epoch 9; Iter  1136/ 2483] train: loss: 0.0016267
[Epoch 9; Iter  1166/ 2483] train: loss: 0.0027501
[Epoch 9; Iter  1196/ 2483] train: loss: 0.0024988
[Epoch 9; Iter  1226/ 2483] train: loss: 0.0026016
[Epoch 9; Iter  1256/ 2483] train: loss: 0.0027634
[Epoch 9; Iter  1286/ 2483] train: loss: 0.0018687
[Epoch 9; Iter  1316/ 2483] train: loss: 0.0018404
[Epoch 9; Iter  1346/ 2483] train: loss: 0.0022008
[Epoch 9; Iter  1376/ 2483] train: loss: 0.0015343
[Epoch 9; Iter  1406/ 2483] train: loss: 0.0577656
[Epoch 9; Iter  1436/ 2483] train: loss: 0.0016352
[Epoch 9; Iter  1466/ 2483] train: loss: 0.0013665
[Epoch 9; Iter  1496/ 2483] train: loss: 0.0016951
[Epoch 9; Iter  1526/ 2483] train: loss: 0.1391436
[Epoch 9; Iter  1556/ 2483] train: loss: 0.0023871
[Epoch 9; Iter  1586/ 2483] train: loss: 0.0018070
[Epoch 9; Iter  1616/ 2483] train: loss: 0.0015369
[Epoch 9; Iter  1646/ 2483] train: loss: 0.0011311
[Epoch 9; Iter  1676/ 2483] train: loss: 0.0012292
[Epoch 9; Iter  1706/ 2483] train: loss: 0.0017336
[Epoch 9; Iter  1736/ 2483] train: loss: 0.0020310
[Epoch 9; Iter  1766/ 2483] train: loss: 0.0017715
[Epoch 9; Iter  1796/ 2483] train: loss: 0.0030786
[Epoch 9; Iter  1826/ 2483] train: loss: 0.0036794
[Epoch 9; Iter  1856/ 2483] train: loss: 0.0019028
[Epoch 9; Iter  1886/ 2483] train: loss: 0.0025677
[Epoch 9; Iter  1916/ 2483] train: loss: 0.0022739
[Epoch 9; Iter  1946/ 2483] train: loss: 0.0021066
[Epoch 9; Iter  1976/ 2483] train: loss: 0.0780672
[Epoch 9; Iter  2006/ 2483] train: loss: 0.0969315
[Epoch 9; Iter  2036/ 2483] train: loss: 0.0810281
[Epoch 9; Iter  2066/ 2483] train: loss: 0.0020949
[Epoch 9; Iter  2096/ 2483] train: loss: 0.0018304
[Epoch 9; Iter  2126/ 2483] train: loss: 0.0015736
[Epoch 7; Iter  2442/ 2483] train: loss: 0.0013354
[Epoch 7; Iter  2472/ 2483] train: loss: 0.0013886
[Epoch 7] ogbg-molmuv: 0.027852 val loss: 0.010153
[Epoch 7] ogbg-molmuv: 0.019436 test loss: 0.014826
[Epoch 8; Iter    19/ 2483] train: loss: 0.0011607
[Epoch 8; Iter    49/ 2483] train: loss: 0.0016866
[Epoch 8; Iter    79/ 2483] train: loss: 0.0713021
[Epoch 8; Iter   109/ 2483] train: loss: 0.0023023
[Epoch 8; Iter   139/ 2483] train: loss: 0.0025870
[Epoch 8; Iter   169/ 2483] train: loss: 0.0668182
[Epoch 8; Iter   199/ 2483] train: loss: 0.0948775
[Epoch 8; Iter   229/ 2483] train: loss: 0.0021466
[Epoch 8; Iter   259/ 2483] train: loss: 0.0018678
[Epoch 8; Iter   289/ 2483] train: loss: 0.0021890
[Epoch 8; Iter   319/ 2483] train: loss: 0.0019591
[Epoch 8; Iter   349/ 2483] train: loss: 0.0019604
[Epoch 8; Iter   379/ 2483] train: loss: 0.0027142
[Epoch 8; Iter   409/ 2483] train: loss: 0.0023644
[Epoch 8; Iter   439/ 2483] train: loss: 0.0024348
[Epoch 8; Iter   469/ 2483] train: loss: 0.0669986
[Epoch 8; Iter   499/ 2483] train: loss: 0.0023830
[Epoch 8; Iter   529/ 2483] train: loss: 0.0016133
[Epoch 8; Iter   559/ 2483] train: loss: 0.0015526
[Epoch 8; Iter   589/ 2483] train: loss: 0.0017120
[Epoch 8; Iter   619/ 2483] train: loss: 0.0013963
[Epoch 8; Iter   649/ 2483] train: loss: 0.0021896
[Epoch 8; Iter   679/ 2483] train: loss: 0.0022526
[Epoch 8; Iter   709/ 2483] train: loss: 0.0020537
[Epoch 8; Iter   739/ 2483] train: loss: 0.0020943
[Epoch 8; Iter   769/ 2483] train: loss: 0.0016373
[Epoch 8; Iter   799/ 2483] train: loss: 0.0823622
[Epoch 8; Iter   829/ 2483] train: loss: 0.0022501
[Epoch 8; Iter   859/ 2483] train: loss: 0.0015826
[Epoch 8; Iter   889/ 2483] train: loss: 0.0017103
[Epoch 8; Iter   919/ 2483] train: loss: 0.1259139
[Epoch 8; Iter   949/ 2483] train: loss: 0.1292099
[Epoch 8; Iter   979/ 2483] train: loss: 0.0017862
[Epoch 8; Iter  1009/ 2483] train: loss: 0.0018662
[Epoch 8; Iter  1039/ 2483] train: loss: 0.1290442
[Epoch 8; Iter  1069/ 2483] train: loss: 0.0014235
[Epoch 8; Iter  1099/ 2483] train: loss: 0.0016491
[Epoch 8; Iter  1129/ 2483] train: loss: 0.0015953
[Epoch 8; Iter  1159/ 2483] train: loss: 0.0017957
[Epoch 8; Iter  1189/ 2483] train: loss: 0.0618185
[Epoch 8; Iter  1219/ 2483] train: loss: 0.0016869
[Epoch 8; Iter  1249/ 2483] train: loss: 0.0013291
[Epoch 8; Iter  1279/ 2483] train: loss: 0.0016418
[Epoch 8; Iter  1309/ 2483] train: loss: 0.0020340
[Epoch 8; Iter  1339/ 2483] train: loss: 0.0012738
[Epoch 8; Iter  1369/ 2483] train: loss: 0.0012998
[Epoch 8; Iter  1399/ 2483] train: loss: 0.0011828
[Epoch 8; Iter  1429/ 2483] train: loss: 0.0020308
[Epoch 8; Iter  1459/ 2483] train: loss: 0.0024588
[Epoch 8; Iter  1489/ 2483] train: loss: 0.0043881
[Epoch 8; Iter  1519/ 2483] train: loss: 0.0030385
[Epoch 8; Iter  1549/ 2483] train: loss: 0.0018767
[Epoch 8; Iter  1579/ 2483] train: loss: 0.0024974
[Epoch 8; Iter  1609/ 2483] train: loss: 0.0021060
[Epoch 8; Iter  1639/ 2483] train: loss: 0.0020342
[Epoch 8; Iter  1669/ 2483] train: loss: 0.0026953
[Epoch 8; Iter  1699/ 2483] train: loss: 0.0021157
[Epoch 8; Iter  1729/ 2483] train: loss: 0.0020408
[Epoch 8; Iter  1759/ 2483] train: loss: 0.0016346
[Epoch 8; Iter  1789/ 2483] train: loss: 0.0016414
[Epoch 8; Iter  1819/ 2483] train: loss: 0.0017485
[Epoch 8; Iter  1849/ 2483] train: loss: 0.0016420
[Epoch 8; Iter  1879/ 2483] train: loss: 0.0022544
[Epoch 8; Iter  1909/ 2483] train: loss: 0.0022279
[Epoch 8; Iter  1939/ 2483] train: loss: 0.0023418
[Epoch 8; Iter  1969/ 2483] train: loss: 0.0013838
[Epoch 8; Iter  1999/ 2483] train: loss: 0.0017351
[Epoch 8; Iter  2029/ 2483] train: loss: 0.0021115
[Epoch 8; Iter  2059/ 2483] train: loss: 0.0018941
[Epoch 8; Iter  2089/ 2483] train: loss: 0.0015083
[Epoch 8; Iter  2119/ 2483] train: loss: 0.0028013
[Epoch 8; Iter  2149/ 2483] train: loss: 0.0024466
[Epoch 8; Iter  2179/ 2483] train: loss: 0.0022067
[Epoch 8; Iter  2209/ 2483] train: loss: 0.1160172
[Epoch 8; Iter  2239/ 2483] train: loss: 0.0797963
[Epoch 8; Iter  2269/ 2483] train: loss: 0.0556563
[Epoch 8; Iter  2299/ 2483] train: loss: 0.0021452
[Epoch 8; Iter  2329/ 2483] train: loss: 0.0016974
[Epoch 8; Iter  2359/ 2483] train: loss: 0.0017502
[Epoch 8; Iter  2389/ 2483] train: loss: 0.0014578
[Epoch 8; Iter  2419/ 2483] train: loss: 0.0021536
[Epoch 8; Iter  2449/ 2483] train: loss: 0.0023471
[Epoch 8; Iter  2479/ 2483] train: loss: 0.0016169
[Epoch 8] ogbg-molmuv: 0.041713 val loss: 0.010445
[Epoch 8] ogbg-molmuv: 0.015112 test loss: 0.017145
[Epoch 9; Iter    26/ 2483] train: loss: 0.0020910
[Epoch 9; Iter    56/ 2483] train: loss: 0.0024646
[Epoch 9; Iter    86/ 2483] train: loss: 0.0014125
[Epoch 9; Iter   116/ 2483] train: loss: 0.1073931
[Epoch 9; Iter   146/ 2483] train: loss: 0.0882613
[Epoch 9; Iter   176/ 2483] train: loss: 0.0023290
[Epoch 9; Iter   206/ 2483] train: loss: 0.0018902
[Epoch 9; Iter   236/ 2483] train: loss: 0.0019647
[Epoch 9; Iter   266/ 2483] train: loss: 0.0561440
[Epoch 9; Iter   296/ 2483] train: loss: 0.0496170
[Epoch 9; Iter   326/ 2483] train: loss: 0.0021467
[Epoch 9; Iter   356/ 2483] train: loss: 0.0016673
[Epoch 9; Iter   386/ 2483] train: loss: 0.0020013
[Epoch 9; Iter   416/ 2483] train: loss: 0.0025262
[Epoch 9; Iter   446/ 2483] train: loss: 0.0018634
[Epoch 9; Iter   476/ 2483] train: loss: 0.0021150
[Epoch 9; Iter   506/ 2483] train: loss: 0.0015792
[Epoch 9; Iter   536/ 2483] train: loss: 0.0016332
[Epoch 9; Iter   566/ 2483] train: loss: 0.0017008
[Epoch 9; Iter   596/ 2483] train: loss: 0.0010701
[Epoch 9; Iter   626/ 2483] train: loss: 0.0019255
[Epoch 9; Iter   656/ 2483] train: loss: 0.0018744
[Epoch 9; Iter   686/ 2483] train: loss: 0.0020710
[Epoch 9; Iter   716/ 2483] train: loss: 0.0014087
[Epoch 9; Iter   746/ 2483] train: loss: 0.0020235
[Epoch 9; Iter   776/ 2483] train: loss: 0.0021176
[Epoch 9; Iter   806/ 2483] train: loss: 0.0018216
[Epoch 9; Iter   836/ 2483] train: loss: 0.0012243
[Epoch 9; Iter   866/ 2483] train: loss: 0.0018490
[Epoch 9; Iter   896/ 2483] train: loss: 0.0020821
[Epoch 9; Iter   926/ 2483] train: loss: 0.1507231
[Epoch 9; Iter   956/ 2483] train: loss: 0.0021982
[Epoch 9; Iter   986/ 2483] train: loss: 0.0019104
[Epoch 9; Iter  1016/ 2483] train: loss: 0.0017967
[Epoch 9; Iter  1046/ 2483] train: loss: 0.0020438
[Epoch 9; Iter  1076/ 2483] train: loss: 0.0017238
[Epoch 9; Iter  1106/ 2483] train: loss: 0.0014676
[Epoch 9; Iter  1136/ 2483] train: loss: 0.0012900
[Epoch 9; Iter  1166/ 2483] train: loss: 0.0014444
[Epoch 9; Iter  1196/ 2483] train: loss: 0.0015994
[Epoch 9; Iter  1226/ 2483] train: loss: 0.1771295
[Epoch 9; Iter  1256/ 2483] train: loss: 0.0031471
[Epoch 9; Iter  1286/ 2483] train: loss: 0.0657533
[Epoch 9; Iter  1316/ 2483] train: loss: 0.0020342
[Epoch 9; Iter  1346/ 2483] train: loss: 0.1230403
[Epoch 9; Iter  1376/ 2483] train: loss: 0.0020871
[Epoch 9; Iter  1406/ 2483] train: loss: 0.0023237
[Epoch 9; Iter  1436/ 2483] train: loss: 0.0019793
[Epoch 9; Iter  1466/ 2483] train: loss: 0.0015895
[Epoch 9; Iter  1496/ 2483] train: loss: 0.0023327
[Epoch 9; Iter  1526/ 2483] train: loss: 0.0017861
[Epoch 9; Iter  1556/ 2483] train: loss: 0.0023431
[Epoch 9; Iter  1586/ 2483] train: loss: 0.0014745
[Epoch 9; Iter  1616/ 2483] train: loss: 0.0018386
[Epoch 9; Iter  1646/ 2483] train: loss: 0.0024542
[Epoch 9; Iter  1676/ 2483] train: loss: 0.0030764
[Epoch 9; Iter  1706/ 2483] train: loss: 0.1415134
[Epoch 9; Iter  1736/ 2483] train: loss: 0.0018053
[Epoch 9; Iter  1766/ 2483] train: loss: 0.0021847
[Epoch 9; Iter  1796/ 2483] train: loss: 0.0019189
[Epoch 9; Iter  1826/ 2483] train: loss: 0.0898181
[Epoch 9; Iter  1856/ 2483] train: loss: 0.0020954
[Epoch 9; Iter  1886/ 2483] train: loss: 0.0019853
[Epoch 9; Iter  1916/ 2483] train: loss: 0.0018702
[Epoch 9; Iter  1946/ 2483] train: loss: 0.0019996
[Epoch 9; Iter  1976/ 2483] train: loss: 0.0017192
[Epoch 9; Iter  2006/ 2483] train: loss: 0.0015707
[Epoch 9; Iter  2036/ 2483] train: loss: 0.0018248
[Epoch 9; Iter  2066/ 2483] train: loss: 0.0027273
[Epoch 9; Iter  2096/ 2483] train: loss: 0.0014897
[Epoch 9; Iter  2126/ 2483] train: loss: 0.0019830
[Epoch 7; Iter  2442/ 2483] train: loss: 0.0023132
[Epoch 7; Iter  2472/ 2483] train: loss: 0.0021010
[Epoch 7] ogbg-molmuv: 0.028313 val loss: 0.010796
[Epoch 7] ogbg-molmuv: 0.013541 test loss: 0.015594
[Epoch 8; Iter    19/ 2483] train: loss: 0.0018058
[Epoch 8; Iter    49/ 2483] train: loss: 0.0020951
[Epoch 8; Iter    79/ 2483] train: loss: 0.0022762
[Epoch 8; Iter   109/ 2483] train: loss: 0.0021059
[Epoch 8; Iter   139/ 2483] train: loss: 0.0018172
[Epoch 8; Iter   169/ 2483] train: loss: 0.0015011
[Epoch 8; Iter   199/ 2483] train: loss: 0.0019613
[Epoch 8; Iter   229/ 2483] train: loss: 0.0018484
[Epoch 8; Iter   259/ 2483] train: loss: 0.0020678
[Epoch 8; Iter   289/ 2483] train: loss: 0.0014714
[Epoch 8; Iter   319/ 2483] train: loss: 0.0013692
[Epoch 8; Iter   349/ 2483] train: loss: 0.0015476
[Epoch 8; Iter   379/ 2483] train: loss: 0.0016230
[Epoch 8; Iter   409/ 2483] train: loss: 0.0848931
[Epoch 8; Iter   439/ 2483] train: loss: 0.0892376
[Epoch 8; Iter   469/ 2483] train: loss: 0.0675317
[Epoch 8; Iter   499/ 2483] train: loss: 0.0020707
[Epoch 8; Iter   529/ 2483] train: loss: 0.0025599
[Epoch 8; Iter   559/ 2483] train: loss: 0.0018367
[Epoch 8; Iter   589/ 2483] train: loss: 0.0017190
[Epoch 8; Iter   619/ 2483] train: loss: 0.0020904
[Epoch 8; Iter   649/ 2483] train: loss: 0.0026797
[Epoch 8; Iter   679/ 2483] train: loss: 0.0760589
[Epoch 8; Iter   709/ 2483] train: loss: 0.0026713
[Epoch 8; Iter   739/ 2483] train: loss: 0.0027361
[Epoch 8; Iter   769/ 2483] train: loss: 0.0017693
[Epoch 8; Iter   799/ 2483] train: loss: 0.0019311
[Epoch 8; Iter   829/ 2483] train: loss: 0.0019661
[Epoch 8; Iter   859/ 2483] train: loss: 0.0017531
[Epoch 8; Iter   889/ 2483] train: loss: 0.0014221
[Epoch 8; Iter   919/ 2483] train: loss: 0.0012568
[Epoch 8; Iter   949/ 2483] train: loss: 0.0698796
[Epoch 8; Iter   979/ 2483] train: loss: 0.1041320
[Epoch 8; Iter  1009/ 2483] train: loss: 0.0019906
[Epoch 8; Iter  1039/ 2483] train: loss: 0.0016675
[Epoch 8; Iter  1069/ 2483] train: loss: 0.0018279
[Epoch 8; Iter  1099/ 2483] train: loss: 0.0012336
[Epoch 8; Iter  1129/ 2483] train: loss: 0.0011310
[Epoch 8; Iter  1159/ 2483] train: loss: 0.0017930
[Epoch 8; Iter  1189/ 2483] train: loss: 0.0019912
[Epoch 8; Iter  1219/ 2483] train: loss: 0.0017529
[Epoch 8; Iter  1249/ 2483] train: loss: 0.0012688
[Epoch 8; Iter  1279/ 2483] train: loss: 0.0013567
[Epoch 8; Iter  1309/ 2483] train: loss: 0.0014371
[Epoch 8; Iter  1339/ 2483] train: loss: 0.0017286
[Epoch 8; Iter  1369/ 2483] train: loss: 0.0012734
[Epoch 8; Iter  1399/ 2483] train: loss: 0.0011439
[Epoch 8; Iter  1429/ 2483] train: loss: 0.0016528
[Epoch 8; Iter  1459/ 2483] train: loss: 0.0021517
[Epoch 8; Iter  1489/ 2483] train: loss: 0.0021022
[Epoch 8; Iter  1519/ 2483] train: loss: 0.0013835
[Epoch 8; Iter  1549/ 2483] train: loss: 0.0021057
[Epoch 8; Iter  1579/ 2483] train: loss: 0.0016129
[Epoch 8; Iter  1609/ 2483] train: loss: 0.0016310
[Epoch 8; Iter  1639/ 2483] train: loss: 0.0015229
[Epoch 8; Iter  1669/ 2483] train: loss: 0.0019371
[Epoch 8; Iter  1699/ 2483] train: loss: 0.0015224
[Epoch 8; Iter  1729/ 2483] train: loss: 0.0015563
[Epoch 8; Iter  1759/ 2483] train: loss: 0.0018887
[Epoch 8; Iter  1789/ 2483] train: loss: 0.0763495
[Epoch 8; Iter  1819/ 2483] train: loss: 0.0025498
[Epoch 8; Iter  1849/ 2483] train: loss: 0.0023839
[Epoch 8; Iter  1879/ 2483] train: loss: 0.0017468
[Epoch 8; Iter  1909/ 2483] train: loss: 0.0019077
[Epoch 8; Iter  1939/ 2483] train: loss: 0.0018188
[Epoch 8; Iter  1969/ 2483] train: loss: 0.0021853
[Epoch 8; Iter  1999/ 2483] train: loss: 0.0035938
[Epoch 8; Iter  2029/ 2483] train: loss: 0.0021516
[Epoch 8; Iter  2059/ 2483] train: loss: 0.0024512
[Epoch 8; Iter  2089/ 2483] train: loss: 0.0020871
[Epoch 8; Iter  2119/ 2483] train: loss: 0.0021355
[Epoch 8; Iter  2149/ 2483] train: loss: 0.0023173
[Epoch 8; Iter  2179/ 2483] train: loss: 0.0021301
[Epoch 8; Iter  2209/ 2483] train: loss: 0.0018649
[Epoch 8; Iter  2239/ 2483] train: loss: 0.0018635
[Epoch 8; Iter  2269/ 2483] train: loss: 0.0019391
[Epoch 8; Iter  2299/ 2483] train: loss: 0.0029602
[Epoch 8; Iter  2329/ 2483] train: loss: 0.0020826
[Epoch 8; Iter  2359/ 2483] train: loss: 0.0018767
[Epoch 8; Iter  2389/ 2483] train: loss: 0.0022125
[Epoch 8; Iter  2419/ 2483] train: loss: 0.0830208
[Epoch 8; Iter  2449/ 2483] train: loss: 0.0018159
[Epoch 8; Iter  2479/ 2483] train: loss: 0.1005452
[Epoch 8] ogbg-molmuv: 0.026271 val loss: 0.010407
[Epoch 8] ogbg-molmuv: 0.022682 test loss: 0.014631
[Epoch 9; Iter    26/ 2483] train: loss: 0.0025849
[Epoch 9; Iter    56/ 2483] train: loss: 0.0019827
[Epoch 9; Iter    86/ 2483] train: loss: 0.0017768
[Epoch 9; Iter   116/ 2483] train: loss: 0.1073354
[Epoch 9; Iter   146/ 2483] train: loss: 0.0017877
[Epoch 9; Iter   176/ 2483] train: loss: 0.0017383
[Epoch 9; Iter   206/ 2483] train: loss: 0.0023218
[Epoch 9; Iter   236/ 2483] train: loss: 0.0020532
[Epoch 9; Iter   266/ 2483] train: loss: 0.1215441
[Epoch 9; Iter   296/ 2483] train: loss: 0.0019886
[Epoch 9; Iter   326/ 2483] train: loss: 0.0023047
[Epoch 9; Iter   356/ 2483] train: loss: 0.0022255
[Epoch 9; Iter   386/ 2483] train: loss: 0.0015905
[Epoch 9; Iter   416/ 2483] train: loss: 0.0019873
[Epoch 9; Iter   446/ 2483] train: loss: 0.0017130
[Epoch 9; Iter   476/ 2483] train: loss: 0.0017406
[Epoch 9; Iter   506/ 2483] train: loss: 0.0548158
[Epoch 9; Iter   536/ 2483] train: loss: 0.0496143
[Epoch 9; Iter   566/ 2483] train: loss: 0.0027807
[Epoch 9; Iter   596/ 2483] train: loss: 0.0017544
[Epoch 9; Iter   626/ 2483] train: loss: 0.0018521
[Epoch 9; Iter   656/ 2483] train: loss: 0.0797849
[Epoch 9; Iter   686/ 2483] train: loss: 0.0021434
[Epoch 9; Iter   716/ 2483] train: loss: 0.0033948
[Epoch 9; Iter   746/ 2483] train: loss: 0.0019345
[Epoch 9; Iter   776/ 2483] train: loss: 0.0017299
[Epoch 9; Iter   806/ 2483] train: loss: 0.1469575
[Epoch 9; Iter   836/ 2483] train: loss: 0.0021904
[Epoch 9; Iter   866/ 2483] train: loss: 0.0690462
[Epoch 9; Iter   896/ 2483] train: loss: 0.0019716
[Epoch 9; Iter   926/ 2483] train: loss: 0.0021675
[Epoch 9; Iter   956/ 2483] train: loss: 0.0022653
[Epoch 9; Iter   986/ 2483] train: loss: 0.0013719
[Epoch 9; Iter  1016/ 2483] train: loss: 0.0013995
[Epoch 9; Iter  1046/ 2483] train: loss: 0.0019070
[Epoch 9; Iter  1076/ 2483] train: loss: 0.0851836
[Epoch 9; Iter  1106/ 2483] train: loss: 0.0020564
[Epoch 9; Iter  1136/ 2483] train: loss: 0.0030666
[Epoch 9; Iter  1166/ 2483] train: loss: 0.0051429
[Epoch 9; Iter  1196/ 2483] train: loss: 0.0029082
[Epoch 9; Iter  1226/ 2483] train: loss: 0.0020156
[Epoch 9; Iter  1256/ 2483] train: loss: 0.0015344
[Epoch 9; Iter  1286/ 2483] train: loss: 0.0821482
[Epoch 9; Iter  1316/ 2483] train: loss: 0.0014740
[Epoch 9; Iter  1346/ 2483] train: loss: 0.0021526
[Epoch 9; Iter  1376/ 2483] train: loss: 0.0732555
[Epoch 9; Iter  1406/ 2483] train: loss: 0.0012900
[Epoch 9; Iter  1436/ 2483] train: loss: 0.0019282
[Epoch 9; Iter  1466/ 2483] train: loss: 0.0607545
[Epoch 9; Iter  1496/ 2483] train: loss: 0.0013559
[Epoch 9; Iter  1526/ 2483] train: loss: 0.0015446
[Epoch 9; Iter  1556/ 2483] train: loss: 0.0025076
[Epoch 9; Iter  1586/ 2483] train: loss: 0.0013033
[Epoch 9; Iter  1616/ 2483] train: loss: 0.0014995
[Epoch 9; Iter  1646/ 2483] train: loss: 0.0015033
[Epoch 9; Iter  1676/ 2483] train: loss: 0.0018578
[Epoch 9; Iter  1706/ 2483] train: loss: 0.0021448
[Epoch 9; Iter  1736/ 2483] train: loss: 0.0835979
[Epoch 9; Iter  1766/ 2483] train: loss: 0.0012365
[Epoch 9; Iter  1796/ 2483] train: loss: 0.0018236
[Epoch 9; Iter  1826/ 2483] train: loss: 0.0026902
[Epoch 9; Iter  1856/ 2483] train: loss: 0.0018218
[Epoch 9; Iter  1886/ 2483] train: loss: 0.0766293
[Epoch 9; Iter  1916/ 2483] train: loss: 0.0485151
[Epoch 9; Iter  1946/ 2483] train: loss: 0.0400895
[Epoch 9; Iter  1976/ 2483] train: loss: 0.0029909
[Epoch 9; Iter  2006/ 2483] train: loss: 0.0019496
[Epoch 9; Iter  2036/ 2483] train: loss: 0.0033003
[Epoch 9; Iter  2066/ 2483] train: loss: 0.0016185
[Epoch 9; Iter  2096/ 2483] train: loss: 0.0015887
[Epoch 9; Iter  2126/ 2483] train: loss: 0.0014072
[Epoch 8; Iter  2076/ 2172] train: loss: 0.0016274
[Epoch 8; Iter  2106/ 2172] train: loss: 0.0020068
[Epoch 8; Iter  2136/ 2172] train: loss: 0.0755126
[Epoch 8; Iter  2166/ 2172] train: loss: 0.0012757
[Epoch 8] ogbg-molmuv: 0.030240 val loss: 0.011922
[Epoch 8] ogbg-molmuv: 0.044571 test loss: 0.014070
[Epoch 9; Iter    24/ 2172] train: loss: 0.0014369
[Epoch 9; Iter    54/ 2172] train: loss: 0.0022330
[Epoch 9; Iter    84/ 2172] train: loss: 0.0014066
[Epoch 9; Iter   114/ 2172] train: loss: 0.0014467
[Epoch 9; Iter   144/ 2172] train: loss: 0.0012248
[Epoch 9; Iter   174/ 2172] train: loss: 0.0017522
[Epoch 9; Iter   204/ 2172] train: loss: 0.0012331
[Epoch 9; Iter   234/ 2172] train: loss: 0.0011504
[Epoch 9; Iter   264/ 2172] train: loss: 0.0012288
[Epoch 9; Iter   294/ 2172] train: loss: 0.0012206
[Epoch 9; Iter   324/ 2172] train: loss: 0.0012425
[Epoch 9; Iter   354/ 2172] train: loss: 0.0013991
[Epoch 9; Iter   384/ 2172] train: loss: 0.0013544
[Epoch 9; Iter   414/ 2172] train: loss: 0.0013302
[Epoch 9; Iter   444/ 2172] train: loss: 0.0973493
[Epoch 9; Iter   474/ 2172] train: loss: 0.0012560
[Epoch 9; Iter   504/ 2172] train: loss: 0.0017235
[Epoch 9; Iter   534/ 2172] train: loss: 0.0015595
[Epoch 9; Iter   564/ 2172] train: loss: 0.0018366
[Epoch 9; Iter   594/ 2172] train: loss: 0.0024802
[Epoch 9; Iter   624/ 2172] train: loss: 0.0757900
[Epoch 9; Iter   654/ 2172] train: loss: 0.0604415
[Epoch 9; Iter   684/ 2172] train: loss: 0.0020979
[Epoch 9; Iter   714/ 2172] train: loss: 0.0019801
[Epoch 9; Iter   744/ 2172] train: loss: 0.0020098
[Epoch 9; Iter   774/ 2172] train: loss: 0.1422497
[Epoch 9; Iter   804/ 2172] train: loss: 0.0017341
[Epoch 9; Iter   834/ 2172] train: loss: 0.0026047
[Epoch 9; Iter   864/ 2172] train: loss: 0.0027064
[Epoch 9; Iter   894/ 2172] train: loss: 0.0027951
[Epoch 9; Iter   924/ 2172] train: loss: 0.0020903
[Epoch 9; Iter   954/ 2172] train: loss: 0.0022484
[Epoch 9; Iter   984/ 2172] train: loss: 0.0015887
[Epoch 9; Iter  1014/ 2172] train: loss: 0.0427314
[Epoch 9; Iter  1044/ 2172] train: loss: 0.0023277
[Epoch 9; Iter  1074/ 2172] train: loss: 0.0025003
[Epoch 9; Iter  1104/ 2172] train: loss: 0.0694989
[Epoch 9; Iter  1134/ 2172] train: loss: 0.0026636
[Epoch 9; Iter  1164/ 2172] train: loss: 0.0019356
[Epoch 9; Iter  1194/ 2172] train: loss: 0.0887249
[Epoch 9; Iter  1224/ 2172] train: loss: 0.0030908
[Epoch 9; Iter  1254/ 2172] train: loss: 0.0022200
[Epoch 9; Iter  1284/ 2172] train: loss: 0.0601514
[Epoch 9; Iter  1314/ 2172] train: loss: 0.0015950
[Epoch 9; Iter  1344/ 2172] train: loss: 0.0020461
[Epoch 9; Iter  1374/ 2172] train: loss: 0.0013480
[Epoch 9; Iter  1404/ 2172] train: loss: 0.0014392
[Epoch 9; Iter  1434/ 2172] train: loss: 0.0014880
[Epoch 9; Iter  1464/ 2172] train: loss: 0.0820651
[Epoch 9; Iter  1494/ 2172] train: loss: 0.0025376
[Epoch 9; Iter  1524/ 2172] train: loss: 0.0021041
[Epoch 9; Iter  1554/ 2172] train: loss: 0.0016454
[Epoch 9; Iter  1584/ 2172] train: loss: 0.0478605
[Epoch 9; Iter  1614/ 2172] train: loss: 0.0016776
[Epoch 9; Iter  1644/ 2172] train: loss: 0.0434048
[Epoch 9; Iter  1674/ 2172] train: loss: 0.0362006
[Epoch 9; Iter  1704/ 2172] train: loss: 0.0038331
[Epoch 9; Iter  1734/ 2172] train: loss: 0.0026651
[Epoch 9; Iter  1764/ 2172] train: loss: 0.0017110
[Epoch 9; Iter  1794/ 2172] train: loss: 0.0009917
[Epoch 9; Iter  1824/ 2172] train: loss: 0.0013765
[Epoch 9; Iter  1854/ 2172] train: loss: 0.0017010
[Epoch 9; Iter  1884/ 2172] train: loss: 0.0014704
[Epoch 9; Iter  1914/ 2172] train: loss: 0.0975225
[Epoch 9; Iter  1944/ 2172] train: loss: 0.0877627
[Epoch 9; Iter  1974/ 2172] train: loss: 0.0877261
[Epoch 9; Iter  2004/ 2172] train: loss: 0.0580516
[Epoch 9; Iter  2034/ 2172] train: loss: 0.0025601
[Epoch 9; Iter  2064/ 2172] train: loss: 0.0891716
[Epoch 9; Iter  2094/ 2172] train: loss: 0.0024255
[Epoch 9; Iter  2124/ 2172] train: loss: 0.0027566
[Epoch 9; Iter  2154/ 2172] train: loss: 0.0023213
[Epoch 9] ogbg-molmuv: 0.026203 val loss: 0.012007
[Epoch 9] ogbg-molmuv: 0.025110 test loss: 0.013492
[Epoch 10; Iter    12/ 2172] train: loss: 0.0019735
[Epoch 10; Iter    42/ 2172] train: loss: 0.0022570
[Epoch 10; Iter    72/ 2172] train: loss: 0.0057009
[Epoch 10; Iter   102/ 2172] train: loss: 0.0025526
[Epoch 10; Iter   132/ 2172] train: loss: 0.0029339
[Epoch 10; Iter   162/ 2172] train: loss: 0.0014791
[Epoch 10; Iter   192/ 2172] train: loss: 0.0019316
[Epoch 10; Iter   222/ 2172] train: loss: 0.0018685
[Epoch 10; Iter   252/ 2172] train: loss: 0.0021458
[Epoch 10; Iter   282/ 2172] train: loss: 0.0025006
[Epoch 10; Iter   312/ 2172] train: loss: 0.0018084
[Epoch 10; Iter   342/ 2172] train: loss: 0.0978922
[Epoch 10; Iter   372/ 2172] train: loss: 0.0019273
[Epoch 10; Iter   402/ 2172] train: loss: 0.0021111
[Epoch 10; Iter   432/ 2172] train: loss: 0.0023905
[Epoch 10; Iter   462/ 2172] train: loss: 0.0021779
[Epoch 10; Iter   492/ 2172] train: loss: 0.0019585
[Epoch 10; Iter   522/ 2172] train: loss: 0.0019636
[Epoch 10; Iter   552/ 2172] train: loss: 0.0014004
[Epoch 10; Iter   582/ 2172] train: loss: 0.0013653
[Epoch 10; Iter   612/ 2172] train: loss: 0.0018845
[Epoch 10; Iter   642/ 2172] train: loss: 0.0014421
[Epoch 10; Iter   672/ 2172] train: loss: 0.0019189
[Epoch 10; Iter   702/ 2172] train: loss: 0.0019408
[Epoch 10; Iter   732/ 2172] train: loss: 0.0018381
[Epoch 10; Iter   762/ 2172] train: loss: 0.0018124
[Epoch 10; Iter   792/ 2172] train: loss: 0.0014794
[Epoch 10; Iter   822/ 2172] train: loss: 0.0021562
[Epoch 10; Iter   852/ 2172] train: loss: 0.0020321
[Epoch 10; Iter   882/ 2172] train: loss: 0.0646770
[Epoch 10; Iter   912/ 2172] train: loss: 0.0015493
[Epoch 10; Iter   942/ 2172] train: loss: 0.0534922
[Epoch 10; Iter   972/ 2172] train: loss: 0.0014638
[Epoch 10; Iter  1002/ 2172] train: loss: 0.0017798
[Epoch 10; Iter  1032/ 2172] train: loss: 0.0022516
[Epoch 10; Iter  1062/ 2172] train: loss: 0.0019007
[Epoch 10; Iter  1092/ 2172] train: loss: 0.0684364
[Epoch 10; Iter  1122/ 2172] train: loss: 0.0019863
[Epoch 10; Iter  1152/ 2172] train: loss: 0.0016889
[Epoch 10; Iter  1182/ 2172] train: loss: 0.0015030
[Epoch 10; Iter  1212/ 2172] train: loss: 0.0017484
[Epoch 10; Iter  1242/ 2172] train: loss: 0.0009059
[Epoch 10; Iter  1272/ 2172] train: loss: 0.0015861
[Epoch 10; Iter  1302/ 2172] train: loss: 0.0900777
[Epoch 10; Iter  1332/ 2172] train: loss: 0.0012960
[Epoch 10; Iter  1362/ 2172] train: loss: 0.0015316
[Epoch 10; Iter  1392/ 2172] train: loss: 0.0023621
[Epoch 10; Iter  1422/ 2172] train: loss: 0.0017832
[Epoch 10; Iter  1452/ 2172] train: loss: 0.0013371
[Epoch 10; Iter  1482/ 2172] train: loss: 0.0015632
[Epoch 10; Iter  1512/ 2172] train: loss: 0.0017068
[Epoch 10; Iter  1542/ 2172] train: loss: 0.0015623
[Epoch 10; Iter  1572/ 2172] train: loss: 0.1477599
[Epoch 10; Iter  1602/ 2172] train: loss: 0.0023332
[Epoch 10; Iter  1632/ 2172] train: loss: 0.0582931
[Epoch 10; Iter  1662/ 2172] train: loss: 0.0015718
[Epoch 10; Iter  1692/ 2172] train: loss: 0.0015552
[Epoch 10; Iter  1722/ 2172] train: loss: 0.0021365
[Epoch 10; Iter  1752/ 2172] train: loss: 0.0014817
[Epoch 10; Iter  1782/ 2172] train: loss: 0.0013053
[Epoch 10; Iter  1812/ 2172] train: loss: 0.0014080
[Epoch 10; Iter  1842/ 2172] train: loss: 0.0017005
[Epoch 10; Iter  1872/ 2172] train: loss: 0.0787345
[Epoch 10; Iter  1902/ 2172] train: loss: 0.0014567
[Epoch 10; Iter  1932/ 2172] train: loss: 0.0022607
[Epoch 10; Iter  1962/ 2172] train: loss: 0.0032625
[Epoch 10; Iter  1992/ 2172] train: loss: 0.0016312
[Epoch 10; Iter  2022/ 2172] train: loss: 0.0020421
[Epoch 10; Iter  2052/ 2172] train: loss: 0.0898683
[Epoch 10; Iter  2082/ 2172] train: loss: 0.1111819
[Epoch 10; Iter  2112/ 2172] train: loss: 0.0016961
[Epoch 10; Iter  2142/ 2172] train: loss: 0.0027909
[Epoch 10; Iter  2172/ 2172] train: loss: 0.0014407
[Epoch 10] ogbg-molmuv: 0.033308 val loss: 0.011570
[Epoch 10] ogbg-molmuv: 0.030230 test loss: 0.013373
[Epoch 11; Iter    30/ 2172] train: loss: 0.0023659
[Epoch 11; Iter    60/ 2172] train: loss: 0.0019211
[Epoch 11; Iter    90/ 2172] train: loss: 0.0019504
[Epoch 11; Iter   120/ 2172] train: loss: 0.0018364
[Epoch 8; Iter  2076/ 2172] train: loss: 0.0032736
[Epoch 8; Iter  2106/ 2172] train: loss: 0.0022135
[Epoch 8; Iter  2136/ 2172] train: loss: 0.0025223
[Epoch 8; Iter  2166/ 2172] train: loss: 0.0030679
[Epoch 8] ogbg-molmuv: 0.005915 val loss: 0.012420
[Epoch 8] ogbg-molmuv: 0.020073 test loss: 0.016422
[Epoch 9; Iter    24/ 2172] train: loss: 0.0024032
[Epoch 9; Iter    54/ 2172] train: loss: 0.0014175
[Epoch 9; Iter    84/ 2172] train: loss: 0.1046932
[Epoch 9; Iter   114/ 2172] train: loss: 0.0017570
[Epoch 9; Iter   144/ 2172] train: loss: 0.0016522
[Epoch 9; Iter   174/ 2172] train: loss: 0.0015732
[Epoch 9; Iter   204/ 2172] train: loss: 0.0025478
[Epoch 9; Iter   234/ 2172] train: loss: 0.0766264
[Epoch 9; Iter   264/ 2172] train: loss: 0.0032419
[Epoch 9; Iter   294/ 2172] train: loss: 0.0024793
[Epoch 9; Iter   324/ 2172] train: loss: 0.0027829
[Epoch 9; Iter   354/ 2172] train: loss: 0.0017391
[Epoch 9; Iter   384/ 2172] train: loss: 0.0025775
[Epoch 9; Iter   414/ 2172] train: loss: 0.0021229
[Epoch 9; Iter   444/ 2172] train: loss: 0.0764990
[Epoch 9; Iter   474/ 2172] train: loss: 0.0023477
[Epoch 9; Iter   504/ 2172] train: loss: 0.0018875
[Epoch 9; Iter   534/ 2172] train: loss: 0.0026668
[Epoch 9; Iter   564/ 2172] train: loss: 0.0598282
[Epoch 9; Iter   594/ 2172] train: loss: 0.0028405
[Epoch 9; Iter   624/ 2172] train: loss: 0.0048018
[Epoch 9; Iter   654/ 2172] train: loss: 0.0734828
[Epoch 9; Iter   684/ 2172] train: loss: 0.0612916
[Epoch 9; Iter   714/ 2172] train: loss: 0.0020742
[Epoch 9; Iter   744/ 2172] train: loss: 0.0828872
[Epoch 9; Iter   774/ 2172] train: loss: 0.0018099
[Epoch 9; Iter   804/ 2172] train: loss: 0.0021657
[Epoch 9; Iter   834/ 2172] train: loss: 0.0022060
[Epoch 9; Iter   864/ 2172] train: loss: 0.0015653
[Epoch 9; Iter   894/ 2172] train: loss: 0.0017113
[Epoch 9; Iter   924/ 2172] train: loss: 0.0620667
[Epoch 9; Iter   954/ 2172] train: loss: 0.0026494
[Epoch 9; Iter   984/ 2172] train: loss: 0.0021026
[Epoch 9; Iter  1014/ 2172] train: loss: 0.0015638
[Epoch 9; Iter  1044/ 2172] train: loss: 0.0012966
[Epoch 9; Iter  1074/ 2172] train: loss: 0.0015394
[Epoch 9; Iter  1104/ 2172] train: loss: 0.0015860
[Epoch 9; Iter  1134/ 2172] train: loss: 0.0023164
[Epoch 9; Iter  1164/ 2172] train: loss: 0.0018306
[Epoch 9; Iter  1194/ 2172] train: loss: 0.0017001
[Epoch 9; Iter  1224/ 2172] train: loss: 0.0019154
[Epoch 9; Iter  1254/ 2172] train: loss: 0.0015943
[Epoch 9; Iter  1284/ 2172] train: loss: 0.0018768
[Epoch 9; Iter  1314/ 2172] train: loss: 0.0014123
[Epoch 9; Iter  1344/ 2172] train: loss: 0.0865452
[Epoch 9; Iter  1374/ 2172] train: loss: 0.0018688
[Epoch 9; Iter  1404/ 2172] train: loss: 0.0727273
[Epoch 9; Iter  1434/ 2172] train: loss: 0.0024752
[Epoch 9; Iter  1464/ 2172] train: loss: 0.0025939
[Epoch 9; Iter  1494/ 2172] train: loss: 0.0024042
[Epoch 9; Iter  1524/ 2172] train: loss: 0.0017244
[Epoch 9; Iter  1554/ 2172] train: loss: 0.0564998
[Epoch 9; Iter  1584/ 2172] train: loss: 0.0016152
[Epoch 9; Iter  1614/ 2172] train: loss: 0.0020327
[Epoch 9; Iter  1644/ 2172] train: loss: 0.0023403
[Epoch 9; Iter  1674/ 2172] train: loss: 0.0024878
[Epoch 9; Iter  1704/ 2172] train: loss: 0.0722971
[Epoch 9; Iter  1734/ 2172] train: loss: 0.0023864
[Epoch 9; Iter  1764/ 2172] train: loss: 0.0018299
[Epoch 9; Iter  1794/ 2172] train: loss: 0.1011957
[Epoch 9; Iter  1824/ 2172] train: loss: 0.0863992
[Epoch 9; Iter  1854/ 2172] train: loss: 0.0019917
[Epoch 9; Iter  1884/ 2172] train: loss: 0.0022303
[Epoch 9; Iter  1914/ 2172] train: loss: 0.0023419
[Epoch 9; Iter  1944/ 2172] train: loss: 0.0020839
[Epoch 9; Iter  1974/ 2172] train: loss: 0.0022964
[Epoch 9; Iter  2004/ 2172] train: loss: 0.0024798
[Epoch 9; Iter  2034/ 2172] train: loss: 0.0016155
[Epoch 9; Iter  2064/ 2172] train: loss: 0.0017004
[Epoch 9; Iter  2094/ 2172] train: loss: 0.0016990
[Epoch 9; Iter  2124/ 2172] train: loss: 0.0020771
[Epoch 9; Iter  2154/ 2172] train: loss: 0.0014776
[Epoch 9] ogbg-molmuv: 0.050350 val loss: 0.012304
[Epoch 9] ogbg-molmuv: 0.018222 test loss: 0.013944
[Epoch 10; Iter    12/ 2172] train: loss: 0.0015702
[Epoch 10; Iter    42/ 2172] train: loss: 0.0020032
[Epoch 10; Iter    72/ 2172] train: loss: 0.0015787
[Epoch 10; Iter   102/ 2172] train: loss: 0.0939029
[Epoch 10; Iter   132/ 2172] train: loss: 0.0017403
[Epoch 10; Iter   162/ 2172] train: loss: 0.0014260
[Epoch 10; Iter   192/ 2172] train: loss: 0.0012195
[Epoch 10; Iter   222/ 2172] train: loss: 0.0674700
[Epoch 10; Iter   252/ 2172] train: loss: 0.0018395
[Epoch 10; Iter   282/ 2172] train: loss: 0.0026526
[Epoch 10; Iter   312/ 2172] train: loss: 0.0020675
[Epoch 10; Iter   342/ 2172] train: loss: 0.0026761
[Epoch 10; Iter   372/ 2172] train: loss: 0.0023225
[Epoch 10; Iter   402/ 2172] train: loss: 0.0017537
[Epoch 10; Iter   432/ 2172] train: loss: 0.0019503
[Epoch 10; Iter   462/ 2172] train: loss: 0.0020309
[Epoch 10; Iter   492/ 2172] train: loss: 0.0027211
[Epoch 10; Iter   522/ 2172] train: loss: 0.0012157
[Epoch 10; Iter   552/ 2172] train: loss: 0.0016250
[Epoch 10; Iter   582/ 2172] train: loss: 0.0019182
[Epoch 10; Iter   612/ 2172] train: loss: 0.0028120
[Epoch 10; Iter   642/ 2172] train: loss: 0.1093833
[Epoch 10; Iter   672/ 2172] train: loss: 0.0016737
[Epoch 10; Iter   702/ 2172] train: loss: 0.0018334
[Epoch 10; Iter   732/ 2172] train: loss: 0.0022415
[Epoch 10; Iter   762/ 2172] train: loss: 0.0018002
[Epoch 10; Iter   792/ 2172] train: loss: 0.0016008
[Epoch 10; Iter   822/ 2172] train: loss: 0.0017788
[Epoch 10; Iter   852/ 2172] train: loss: 0.0014023
[Epoch 10; Iter   882/ 2172] train: loss: 0.0016693
[Epoch 10; Iter   912/ 2172] train: loss: 0.0012512
[Epoch 10; Iter   942/ 2172] train: loss: 0.0013632
[Epoch 10; Iter   972/ 2172] train: loss: 0.0016665
[Epoch 10; Iter  1002/ 2172] train: loss: 0.0018909
[Epoch 10; Iter  1032/ 2172] train: loss: 0.0013610
[Epoch 10; Iter  1062/ 2172] train: loss: 0.0014153
[Epoch 10; Iter  1092/ 2172] train: loss: 0.0015384
[Epoch 10; Iter  1122/ 2172] train: loss: 0.0016222
[Epoch 10; Iter  1152/ 2172] train: loss: 0.0015613
[Epoch 10; Iter  1182/ 2172] train: loss: 0.0583594
[Epoch 10; Iter  1212/ 2172] train: loss: 0.0023437
[Epoch 10; Iter  1242/ 2172] train: loss: 0.0018807
[Epoch 10; Iter  1272/ 2172] train: loss: 0.0635585
[Epoch 10; Iter  1302/ 2172] train: loss: 0.0019518
[Epoch 10; Iter  1332/ 2172] train: loss: 0.0019088
[Epoch 10; Iter  1362/ 2172] train: loss: 0.0023185
[Epoch 10; Iter  1392/ 2172] train: loss: 0.0019512
[Epoch 10; Iter  1422/ 2172] train: loss: 0.0021252
[Epoch 10; Iter  1452/ 2172] train: loss: 0.0016480
[Epoch 10; Iter  1482/ 2172] train: loss: 0.0020134
[Epoch 10; Iter  1512/ 2172] train: loss: 0.0014676
[Epoch 10; Iter  1542/ 2172] train: loss: 0.0032402
[Epoch 10; Iter  1572/ 2172] train: loss: 0.0029714
[Epoch 10; Iter  1602/ 2172] train: loss: 0.0020182
[Epoch 10; Iter  1632/ 2172] train: loss: 0.0023499
[Epoch 10; Iter  1662/ 2172] train: loss: 0.0015688
[Epoch 10; Iter  1692/ 2172] train: loss: 0.0031777
[Epoch 10; Iter  1722/ 2172] train: loss: 0.0017156
[Epoch 10; Iter  1752/ 2172] train: loss: 0.0020494
[Epoch 10; Iter  1782/ 2172] train: loss: 0.0022384
[Epoch 10; Iter  1812/ 2172] train: loss: 0.0025519
[Epoch 10; Iter  1842/ 2172] train: loss: 0.0021016
[Epoch 10; Iter  1872/ 2172] train: loss: 0.1063742
[Epoch 10; Iter  1902/ 2172] train: loss: 0.0020502
[Epoch 10; Iter  1932/ 2172] train: loss: 0.0020556
[Epoch 10; Iter  1962/ 2172] train: loss: 0.0021159
[Epoch 10; Iter  1992/ 2172] train: loss: 0.0022430
[Epoch 10; Iter  2022/ 2172] train: loss: 0.0020659
[Epoch 10; Iter  2052/ 2172] train: loss: 0.0016782
[Epoch 10; Iter  2082/ 2172] train: loss: 0.0020451
[Epoch 10; Iter  2112/ 2172] train: loss: 0.0738608
[Epoch 10; Iter  2142/ 2172] train: loss: 0.0020453
[Epoch 10; Iter  2172/ 2172] train: loss: 0.0032777
[Epoch 10] ogbg-molmuv: 0.010856 val loss: 0.012505
[Epoch 10] ogbg-molmuv: 0.024800 test loss: 0.013886
[Epoch 11; Iter    30/ 2172] train: loss: 0.0043958
[Epoch 11; Iter    60/ 2172] train: loss: 0.0025494
[Epoch 11; Iter    90/ 2172] train: loss: 0.0028221
[Epoch 11; Iter   120/ 2172] train: loss: 0.0016060
[Epoch 8; Iter  2076/ 2172] train: loss: 0.0018382
[Epoch 8; Iter  2106/ 2172] train: loss: 0.0013040
[Epoch 8; Iter  2136/ 2172] train: loss: 0.0016483
[Epoch 8; Iter  2166/ 2172] train: loss: 0.0013837
[Epoch 8] ogbg-molmuv: 0.008816 val loss: 0.012084
[Epoch 8] ogbg-molmuv: 0.011557 test loss: 0.014168
[Epoch 9; Iter    24/ 2172] train: loss: 0.0011205
[Epoch 9; Iter    54/ 2172] train: loss: 0.0015763
[Epoch 9; Iter    84/ 2172] train: loss: 0.0021288
[Epoch 9; Iter   114/ 2172] train: loss: 0.0018509
[Epoch 9; Iter   144/ 2172] train: loss: 0.0016241
[Epoch 9; Iter   174/ 2172] train: loss: 0.0011153
[Epoch 9; Iter   204/ 2172] train: loss: 0.0013081
[Epoch 9; Iter   234/ 2172] train: loss: 0.0010607
[Epoch 9; Iter   264/ 2172] train: loss: 0.0015879
[Epoch 9; Iter   294/ 2172] train: loss: 0.0025045
[Epoch 9; Iter   324/ 2172] train: loss: 0.0017595
[Epoch 9; Iter   354/ 2172] train: loss: 0.0011108
[Epoch 9; Iter   384/ 2172] train: loss: 0.0013699
[Epoch 9; Iter   414/ 2172] train: loss: 0.1093278
[Epoch 9; Iter   444/ 2172] train: loss: 0.0015111
[Epoch 9; Iter   474/ 2172] train: loss: 0.0017971
[Epoch 9; Iter   504/ 2172] train: loss: 0.0015517
[Epoch 9; Iter   534/ 2172] train: loss: 0.0008865
[Epoch 9; Iter   564/ 2172] train: loss: 0.0011824
[Epoch 9; Iter   594/ 2172] train: loss: 0.0009666
[Epoch 9; Iter   624/ 2172] train: loss: 0.0011345
[Epoch 9; Iter   654/ 2172] train: loss: 0.0022719
[Epoch 9; Iter   684/ 2172] train: loss: 0.0781484
[Epoch 9; Iter   714/ 2172] train: loss: 0.0021139
[Epoch 9; Iter   744/ 2172] train: loss: 0.0017245
[Epoch 9; Iter   774/ 2172] train: loss: 0.0722726
[Epoch 9; Iter   804/ 2172] train: loss: 0.0015934
[Epoch 9; Iter   834/ 2172] train: loss: 0.0686253
[Epoch 9; Iter   864/ 2172] train: loss: 0.0017732
[Epoch 9; Iter   894/ 2172] train: loss: 0.0019324
[Epoch 9; Iter   924/ 2172] train: loss: 0.0682875
[Epoch 9; Iter   954/ 2172] train: loss: 0.0021816
[Epoch 9; Iter   984/ 2172] train: loss: 0.1726163
[Epoch 9; Iter  1014/ 2172] train: loss: 0.0662820
[Epoch 9; Iter  1044/ 2172] train: loss: 0.0028504
[Epoch 9; Iter  1074/ 2172] train: loss: 0.0021379
[Epoch 9; Iter  1104/ 2172] train: loss: 0.0030535
[Epoch 9; Iter  1134/ 2172] train: loss: 0.1232913
[Epoch 9; Iter  1164/ 2172] train: loss: 0.0022707
[Epoch 9; Iter  1194/ 2172] train: loss: 0.0025608
[Epoch 9; Iter  1224/ 2172] train: loss: 0.0024753
[Epoch 9; Iter  1254/ 2172] train: loss: 0.0039866
[Epoch 9; Iter  1284/ 2172] train: loss: 0.0032287
[Epoch 9; Iter  1314/ 2172] train: loss: 0.0019139
[Epoch 9; Iter  1344/ 2172] train: loss: 0.0015857
[Epoch 9; Iter  1374/ 2172] train: loss: 0.0670530
[Epoch 9; Iter  1404/ 2172] train: loss: 0.0034692
[Epoch 9; Iter  1434/ 2172] train: loss: 0.0019496
[Epoch 9; Iter  1464/ 2172] train: loss: 0.0022171
[Epoch 9; Iter  1494/ 2172] train: loss: 0.0016899
[Epoch 9; Iter  1524/ 2172] train: loss: 0.0033603
[Epoch 9; Iter  1554/ 2172] train: loss: 0.0017968
[Epoch 9; Iter  1584/ 2172] train: loss: 0.0021286
[Epoch 9; Iter  1614/ 2172] train: loss: 0.0017945
[Epoch 9; Iter  1644/ 2172] train: loss: 0.0016805
[Epoch 9; Iter  1674/ 2172] train: loss: 0.0023885
[Epoch 9; Iter  1704/ 2172] train: loss: 0.0017149
[Epoch 9; Iter  1734/ 2172] train: loss: 0.0018803
[Epoch 9; Iter  1764/ 2172] train: loss: 0.0018938
[Epoch 9; Iter  1794/ 2172] train: loss: 0.0019009
[Epoch 9; Iter  1824/ 2172] train: loss: 0.0016339
[Epoch 9; Iter  1854/ 2172] train: loss: 0.0012834
[Epoch 9; Iter  1884/ 2172] train: loss: 0.0014240
[Epoch 9; Iter  1914/ 2172] train: loss: 0.0022213
[Epoch 9; Iter  1944/ 2172] train: loss: 0.0023540
[Epoch 9; Iter  1974/ 2172] train: loss: 0.0018275
[Epoch 9; Iter  2004/ 2172] train: loss: 0.0022766
[Epoch 9; Iter  2034/ 2172] train: loss: 0.0018435
[Epoch 9; Iter  2064/ 2172] train: loss: 0.0015483
[Epoch 9; Iter  2094/ 2172] train: loss: 0.0017449
[Epoch 9; Iter  2124/ 2172] train: loss: 0.0018958
[Epoch 9; Iter  2154/ 2172] train: loss: 0.0028876
[Epoch 9] ogbg-molmuv: 0.017392 val loss: 0.013025
[Epoch 9] ogbg-molmuv: 0.014023 test loss: 0.015544
[Epoch 10; Iter    12/ 2172] train: loss: 0.0033846
[Epoch 10; Iter    42/ 2172] train: loss: 0.0019041
[Epoch 10; Iter    72/ 2172] train: loss: 0.0020797
[Epoch 10; Iter   102/ 2172] train: loss: 0.0018528
[Epoch 10; Iter   132/ 2172] train: loss: 0.0778397
[Epoch 10; Iter   162/ 2172] train: loss: 0.0021430
[Epoch 10; Iter   192/ 2172] train: loss: 0.0022042
[Epoch 10; Iter   222/ 2172] train: loss: 0.0027692
[Epoch 10; Iter   252/ 2172] train: loss: 0.0017451
[Epoch 10; Iter   282/ 2172] train: loss: 0.0017939
[Epoch 10; Iter   312/ 2172] train: loss: 0.0491381
[Epoch 10; Iter   342/ 2172] train: loss: 0.0914488
[Epoch 10; Iter   372/ 2172] train: loss: 0.0023807
[Epoch 10; Iter   402/ 2172] train: loss: 0.0680395
[Epoch 10; Iter   432/ 2172] train: loss: 0.0023664
[Epoch 10; Iter   462/ 2172] train: loss: 0.0020410
[Epoch 10; Iter   492/ 2172] train: loss: 0.0016035
[Epoch 10; Iter   522/ 2172] train: loss: 0.0020280
[Epoch 10; Iter   552/ 2172] train: loss: 0.0020057
[Epoch 10; Iter   582/ 2172] train: loss: 0.0018076
[Epoch 10; Iter   612/ 2172] train: loss: 0.0022416
[Epoch 10; Iter   642/ 2172] train: loss: 0.0547939
[Epoch 10; Iter   672/ 2172] train: loss: 0.0018076
[Epoch 10; Iter   702/ 2172] train: loss: 0.0020982
[Epoch 10; Iter   732/ 2172] train: loss: 0.0020559
[Epoch 10; Iter   762/ 2172] train: loss: 0.0018128
[Epoch 10; Iter   792/ 2172] train: loss: 0.0795082
[Epoch 10; Iter   822/ 2172] train: loss: 0.0946264
[Epoch 10; Iter   852/ 2172] train: loss: 0.2241798
[Epoch 10; Iter   882/ 2172] train: loss: 0.0044872
[Epoch 10; Iter   912/ 2172] train: loss: 0.0028541
[Epoch 10; Iter   942/ 2172] train: loss: 0.0939287
[Epoch 10; Iter   972/ 2172] train: loss: 0.0015491
[Epoch 10; Iter  1002/ 2172] train: loss: 0.0019586
[Epoch 10; Iter  1032/ 2172] train: loss: 0.0023680
[Epoch 10; Iter  1062/ 2172] train: loss: 0.0026997
[Epoch 10; Iter  1092/ 2172] train: loss: 0.0016686
[Epoch 10; Iter  1122/ 2172] train: loss: 0.0012094
[Epoch 10; Iter  1152/ 2172] train: loss: 0.0025335
[Epoch 10; Iter  1182/ 2172] train: loss: 0.0023923
[Epoch 10; Iter  1212/ 2172] train: loss: 0.0018192
[Epoch 10; Iter  1242/ 2172] train: loss: 0.0023005
[Epoch 10; Iter  1272/ 2172] train: loss: 0.0021855
[Epoch 10; Iter  1302/ 2172] train: loss: 0.0019542
[Epoch 10; Iter  1332/ 2172] train: loss: 0.0017471
[Epoch 10; Iter  1362/ 2172] train: loss: 0.0019133
[Epoch 10; Iter  1392/ 2172] train: loss: 0.0016218
[Epoch 10; Iter  1422/ 2172] train: loss: 0.0016918
[Epoch 10; Iter  1452/ 2172] train: loss: 0.0018032
[Epoch 10; Iter  1482/ 2172] train: loss: 0.0022942
[Epoch 10; Iter  1512/ 2172] train: loss: 0.0015413
[Epoch 10; Iter  1542/ 2172] train: loss: 0.0035507
[Epoch 10; Iter  1572/ 2172] train: loss: 0.0014113
[Epoch 10; Iter  1602/ 2172] train: loss: 0.0012779
[Epoch 10; Iter  1632/ 2172] train: loss: 0.0016652
[Epoch 10; Iter  1662/ 2172] train: loss: 0.0012293
[Epoch 10; Iter  1692/ 2172] train: loss: 0.0491786
[Epoch 10; Iter  1722/ 2172] train: loss: 0.0017831
[Epoch 10; Iter  1752/ 2172] train: loss: 0.0016821
[Epoch 10; Iter  1782/ 2172] train: loss: 0.0033444
[Epoch 10; Iter  1812/ 2172] train: loss: 0.0830423
[Epoch 10; Iter  1842/ 2172] train: loss: 0.0015429
[Epoch 10; Iter  1872/ 2172] train: loss: 0.0016051
[Epoch 10; Iter  1902/ 2172] train: loss: 0.0020132
[Epoch 10; Iter  1932/ 2172] train: loss: 0.0026260
[Epoch 10; Iter  1962/ 2172] train: loss: 0.0015447
[Epoch 10; Iter  1992/ 2172] train: loss: 0.0015366
[Epoch 10; Iter  2022/ 2172] train: loss: 0.1250688
[Epoch 10; Iter  2052/ 2172] train: loss: 0.0017835
[Epoch 10; Iter  2082/ 2172] train: loss: 0.0015709
[Epoch 10; Iter  2112/ 2172] train: loss: 0.0796963
[Epoch 10; Iter  2142/ 2172] train: loss: 0.0020069
[Epoch 10; Iter  2172/ 2172] train: loss: 0.0017654
[Epoch 10] ogbg-molmuv: 0.023827 val loss: 0.011963
[Epoch 10] ogbg-molmuv: 0.018579 test loss: 0.013504
[Epoch 11; Iter    30/ 2172] train: loss: 0.0019405
[Epoch 11; Iter    60/ 2172] train: loss: 0.0021738
[Epoch 11; Iter    90/ 2172] train: loss: 0.0022200
[Epoch 11; Iter   120/ 2172] train: loss: 0.0018634
[Epoch 9; Iter  2156/ 2483] train: loss: 0.0012930
[Epoch 9; Iter  2186/ 2483] train: loss: 0.0014248
[Epoch 9; Iter  2216/ 2483] train: loss: 0.0021967
[Epoch 9; Iter  2246/ 2483] train: loss: 0.0029124
[Epoch 9; Iter  2276/ 2483] train: loss: 0.0648900
[Epoch 9; Iter  2306/ 2483] train: loss: 0.0016568
[Epoch 9; Iter  2336/ 2483] train: loss: 0.0016706
[Epoch 9; Iter  2366/ 2483] train: loss: 0.0020520
[Epoch 9; Iter  2396/ 2483] train: loss: 0.0016233
[Epoch 9; Iter  2426/ 2483] train: loss: 0.0022149
[Epoch 9; Iter  2456/ 2483] train: loss: 0.0021318
[Epoch 9] ogbg-molmuv: 0.025113 val loss: 0.010144
[Epoch 9] ogbg-molmuv: 0.031527 test loss: 0.014486
[Epoch 10; Iter     3/ 2483] train: loss: 0.0015915
[Epoch 10; Iter    33/ 2483] train: loss: 0.0013785
[Epoch 10; Iter    63/ 2483] train: loss: 0.0015206
[Epoch 10; Iter    93/ 2483] train: loss: 0.0019848
[Epoch 10; Iter   123/ 2483] train: loss: 0.0017457
[Epoch 10; Iter   153/ 2483] train: loss: 0.0022974
[Epoch 10; Iter   183/ 2483] train: loss: 0.0014588
[Epoch 10; Iter   213/ 2483] train: loss: 0.0014904
[Epoch 10; Iter   243/ 2483] train: loss: 0.0017556
[Epoch 10; Iter   273/ 2483] train: loss: 0.0024257
[Epoch 10; Iter   303/ 2483] train: loss: 0.0019068
[Epoch 10; Iter   333/ 2483] train: loss: 0.0024798
[Epoch 10; Iter   363/ 2483] train: loss: 0.0016279
[Epoch 10; Iter   393/ 2483] train: loss: 0.0016245
[Epoch 10; Iter   423/ 2483] train: loss: 0.0014666
[Epoch 10; Iter   453/ 2483] train: loss: 0.0013966
[Epoch 10; Iter   483/ 2483] train: loss: 0.0023792
[Epoch 10; Iter   513/ 2483] train: loss: 0.0016578
[Epoch 10; Iter   543/ 2483] train: loss: 0.0016168
[Epoch 10; Iter   573/ 2483] train: loss: 0.0015868
[Epoch 10; Iter   603/ 2483] train: loss: 0.0015957
[Epoch 10; Iter   633/ 2483] train: loss: 0.0020532
[Epoch 10; Iter   663/ 2483] train: loss: 0.0021302
[Epoch 10; Iter   693/ 2483] train: loss: 0.0034758
[Epoch 10; Iter   723/ 2483] train: loss: 0.0037326
[Epoch 10; Iter   753/ 2483] train: loss: 0.0022438
[Epoch 10; Iter   783/ 2483] train: loss: 0.0019329
[Epoch 10; Iter   813/ 2483] train: loss: 0.0527574
[Epoch 10; Iter   843/ 2483] train: loss: 0.0018238
[Epoch 10; Iter   873/ 2483] train: loss: 0.0023702
[Epoch 10; Iter   903/ 2483] train: loss: 0.0020347
[Epoch 10; Iter   933/ 2483] train: loss: 0.0022254
[Epoch 10; Iter   963/ 2483] train: loss: 0.0018143
[Epoch 10; Iter   993/ 2483] train: loss: 0.0677537
[Epoch 10; Iter  1023/ 2483] train: loss: 0.0016287
[Epoch 10; Iter  1053/ 2483] train: loss: 0.0717471
[Epoch 10; Iter  1083/ 2483] train: loss: 0.0020674
[Epoch 10; Iter  1113/ 2483] train: loss: 0.0034091
[Epoch 10; Iter  1143/ 2483] train: loss: 0.0024353
[Epoch 10; Iter  1173/ 2483] train: loss: 0.0018530
[Epoch 10; Iter  1203/ 2483] train: loss: 0.0016684
[Epoch 10; Iter  1233/ 2483] train: loss: 0.0013800
[Epoch 10; Iter  1263/ 2483] train: loss: 0.0025276
[Epoch 10; Iter  1293/ 2483] train: loss: 0.0022801
[Epoch 10; Iter  1323/ 2483] train: loss: 0.0841644
[Epoch 10; Iter  1353/ 2483] train: loss: 0.0017517
[Epoch 10; Iter  1383/ 2483] train: loss: 0.0016265
[Epoch 10; Iter  1413/ 2483] train: loss: 0.0012038
[Epoch 10; Iter  1443/ 2483] train: loss: 0.0013285
[Epoch 10; Iter  1473/ 2483] train: loss: 0.0020578
[Epoch 10; Iter  1503/ 2483] train: loss: 0.0027826
[Epoch 10; Iter  1533/ 2483] train: loss: 0.0015217
[Epoch 10; Iter  1563/ 2483] train: loss: 0.2356795
[Epoch 10; Iter  1593/ 2483] train: loss: 0.0017919
[Epoch 10; Iter  1623/ 2483] train: loss: 0.0016186
[Epoch 10; Iter  1653/ 2483] train: loss: 0.0018920
[Epoch 10; Iter  1683/ 2483] train: loss: 0.0021129
[Epoch 10; Iter  1713/ 2483] train: loss: 0.0022016
[Epoch 10; Iter  1743/ 2483] train: loss: 0.0018068
[Epoch 10; Iter  1773/ 2483] train: loss: 0.0025217
[Epoch 10; Iter  1803/ 2483] train: loss: 0.0026172
[Epoch 10; Iter  1833/ 2483] train: loss: 0.0023240
[Epoch 10; Iter  1863/ 2483] train: loss: 0.0525619
[Epoch 10; Iter  1893/ 2483] train: loss: 0.0016317
[Epoch 10; Iter  1923/ 2483] train: loss: 0.0023954
[Epoch 10; Iter  1953/ 2483] train: loss: 0.0032585
[Epoch 10; Iter  1983/ 2483] train: loss: 0.0016396
[Epoch 10; Iter  2013/ 2483] train: loss: 0.0011299
[Epoch 10; Iter  2043/ 2483] train: loss: 0.0012900
[Epoch 10; Iter  2073/ 2483] train: loss: 0.0817193
[Epoch 10; Iter  2103/ 2483] train: loss: 0.0624230
[Epoch 10; Iter  2133/ 2483] train: loss: 0.0020361
[Epoch 10; Iter  2163/ 2483] train: loss: 0.0016724
[Epoch 10; Iter  2193/ 2483] train: loss: 0.0031887
[Epoch 10; Iter  2223/ 2483] train: loss: 0.0020850
[Epoch 10; Iter  2253/ 2483] train: loss: 0.0015748
[Epoch 10; Iter  2283/ 2483] train: loss: 0.0856039
[Epoch 10; Iter  2313/ 2483] train: loss: 0.0798603
[Epoch 10; Iter  2343/ 2483] train: loss: 0.0029557
[Epoch 10; Iter  2373/ 2483] train: loss: 0.0022073
[Epoch 10; Iter  2403/ 2483] train: loss: 0.0669107
[Epoch 10; Iter  2433/ 2483] train: loss: 0.0024700
[Epoch 10; Iter  2463/ 2483] train: loss: 0.0021397
[Epoch 10] ogbg-molmuv: 0.039373 val loss: 0.010050
[Epoch 10] ogbg-molmuv: 0.029591 test loss: 0.014216
[Epoch 11; Iter    10/ 2483] train: loss: 0.0029180
[Epoch 11; Iter    40/ 2483] train: loss: 0.0027297
[Epoch 11; Iter    70/ 2483] train: loss: 0.0023171
[Epoch 11; Iter   100/ 2483] train: loss: 0.0019569
[Epoch 11; Iter   130/ 2483] train: loss: 0.0017851
[Epoch 11; Iter   160/ 2483] train: loss: 0.0023144
[Epoch 11; Iter   190/ 2483] train: loss: 0.0019259
[Epoch 11; Iter   220/ 2483] train: loss: 0.0018650
[Epoch 11; Iter   250/ 2483] train: loss: 0.0016853
[Epoch 11; Iter   280/ 2483] train: loss: 0.0022582
[Epoch 11; Iter   310/ 2483] train: loss: 0.0020664
[Epoch 11; Iter   340/ 2483] train: loss: 0.0020605
[Epoch 11; Iter   370/ 2483] train: loss: 0.0025900
[Epoch 11; Iter   400/ 2483] train: loss: 0.0020205
[Epoch 11; Iter   430/ 2483] train: loss: 0.0495786
[Epoch 11; Iter   460/ 2483] train: loss: 0.0027544
[Epoch 11; Iter   490/ 2483] train: loss: 0.0016649
[Epoch 11; Iter   520/ 2483] train: loss: 0.0624801
[Epoch 11; Iter   550/ 2483] train: loss: 0.0028783
[Epoch 11; Iter   580/ 2483] train: loss: 0.0642410
[Epoch 11; Iter   610/ 2483] train: loss: 0.0019940
[Epoch 11; Iter   640/ 2483] train: loss: 0.0030503
[Epoch 11; Iter   670/ 2483] train: loss: 0.0029277
[Epoch 11; Iter   700/ 2483] train: loss: 0.0681141
[Epoch 11; Iter   730/ 2483] train: loss: 0.0018434
[Epoch 11; Iter   760/ 2483] train: loss: 0.0417938
[Epoch 11; Iter   790/ 2483] train: loss: 0.0024577
[Epoch 11; Iter   820/ 2483] train: loss: 0.0020256
[Epoch 11; Iter   850/ 2483] train: loss: 0.0993651
[Epoch 11; Iter   880/ 2483] train: loss: 0.0015283
[Epoch 11; Iter   910/ 2483] train: loss: 0.0014467
[Epoch 11; Iter   940/ 2483] train: loss: 0.0016448
[Epoch 11; Iter   970/ 2483] train: loss: 0.0013733
[Epoch 11; Iter  1000/ 2483] train: loss: 0.0015396
[Epoch 11; Iter  1030/ 2483] train: loss: 0.0012729
[Epoch 11; Iter  1060/ 2483] train: loss: 0.0017441
[Epoch 11; Iter  1090/ 2483] train: loss: 0.0015081
[Epoch 11; Iter  1120/ 2483] train: loss: 0.0645195
[Epoch 11; Iter  1150/ 2483] train: loss: 0.0012917
[Epoch 11; Iter  1180/ 2483] train: loss: 0.0014269
[Epoch 11; Iter  1210/ 2483] train: loss: 0.1086150
[Epoch 11; Iter  1240/ 2483] train: loss: 0.0596013
[Epoch 11; Iter  1270/ 2483] train: loss: 0.0018466
[Epoch 11; Iter  1300/ 2483] train: loss: 0.0014463
[Epoch 11; Iter  1330/ 2483] train: loss: 0.0011316
[Epoch 11; Iter  1360/ 2483] train: loss: 0.0678420
[Epoch 11; Iter  1390/ 2483] train: loss: 0.0013542
[Epoch 11; Iter  1420/ 2483] train: loss: 0.0011804
[Epoch 11; Iter  1450/ 2483] train: loss: 0.0621613
[Epoch 11; Iter  1480/ 2483] train: loss: 0.0014430
[Epoch 11; Iter  1510/ 2483] train: loss: 0.0018859
[Epoch 11; Iter  1540/ 2483] train: loss: 0.0015122
[Epoch 11; Iter  1570/ 2483] train: loss: 0.0020586
[Epoch 11; Iter  1600/ 2483] train: loss: 0.0020298
[Epoch 11; Iter  1630/ 2483] train: loss: 0.0023745
[Epoch 11; Iter  1660/ 2483] train: loss: 0.0015431
[Epoch 11; Iter  1690/ 2483] train: loss: 0.0014055
[Epoch 11; Iter  1720/ 2483] train: loss: 0.0024128
[Epoch 11; Iter  1750/ 2483] train: loss: 0.0016134
[Epoch 10; Iter   402/ 1862] train: loss: 0.0019502
[Epoch 10; Iter   432/ 1862] train: loss: 0.0837579
[Epoch 10; Iter   462/ 1862] train: loss: 0.0023727
[Epoch 10; Iter   492/ 1862] train: loss: 0.0024077
[Epoch 10; Iter   522/ 1862] train: loss: 0.0025906
[Epoch 10; Iter   552/ 1862] train: loss: 0.0645307
[Epoch 10; Iter   582/ 1862] train: loss: 0.0026670
[Epoch 10; Iter   612/ 1862] train: loss: 0.0022076
[Epoch 10; Iter   642/ 1862] train: loss: 0.0014602
[Epoch 10; Iter   672/ 1862] train: loss: 0.0014341
[Epoch 10; Iter   702/ 1862] train: loss: 0.0019064
[Epoch 10; Iter   732/ 1862] train: loss: 0.0017804
[Epoch 10; Iter   762/ 1862] train: loss: 0.0023193
[Epoch 10; Iter   792/ 1862] train: loss: 0.0019338
[Epoch 10; Iter   822/ 1862] train: loss: 0.0018577
[Epoch 10; Iter   852/ 1862] train: loss: 0.0016522
[Epoch 10; Iter   882/ 1862] train: loss: 0.0018002
[Epoch 10; Iter   912/ 1862] train: loss: 0.0687250
[Epoch 10; Iter   942/ 1862] train: loss: 0.0017094
[Epoch 10; Iter   972/ 1862] train: loss: 0.0647846
[Epoch 10; Iter  1002/ 1862] train: loss: 0.0017290
[Epoch 10; Iter  1032/ 1862] train: loss: 0.0012432
[Epoch 10; Iter  1062/ 1862] train: loss: 0.0013678
[Epoch 10; Iter  1092/ 1862] train: loss: 0.0018737
[Epoch 10; Iter  1122/ 1862] train: loss: 0.0830123
[Epoch 10; Iter  1152/ 1862] train: loss: 0.0027361
[Epoch 10; Iter  1182/ 1862] train: loss: 0.0023894
[Epoch 10; Iter  1212/ 1862] train: loss: 0.0020243
[Epoch 10; Iter  1242/ 1862] train: loss: 0.0019601
[Epoch 10; Iter  1272/ 1862] train: loss: 0.0021434
[Epoch 10; Iter  1302/ 1862] train: loss: 0.0031510
[Epoch 10; Iter  1332/ 1862] train: loss: 0.0659428
[Epoch 10; Iter  1362/ 1862] train: loss: 0.0044170
[Epoch 10; Iter  1392/ 1862] train: loss: 0.0027472
[Epoch 10; Iter  1422/ 1862] train: loss: 0.0024378
[Epoch 10; Iter  1452/ 1862] train: loss: 0.0022831
[Epoch 10; Iter  1482/ 1862] train: loss: 0.0547887
[Epoch 10; Iter  1512/ 1862] train: loss: 0.0986461
[Epoch 10; Iter  1542/ 1862] train: loss: 0.0021946
[Epoch 10; Iter  1572/ 1862] train: loss: 0.0031043
[Epoch 10; Iter  1602/ 1862] train: loss: 0.0017451
[Epoch 10; Iter  1632/ 1862] train: loss: 0.0017724
[Epoch 10; Iter  1662/ 1862] train: loss: 0.0014251
[Epoch 10; Iter  1692/ 1862] train: loss: 0.0021915
[Epoch 10; Iter  1722/ 1862] train: loss: 0.0017298
[Epoch 10; Iter  1752/ 1862] train: loss: 0.0019780
[Epoch 10; Iter  1782/ 1862] train: loss: 0.0015093
[Epoch 10; Iter  1812/ 1862] train: loss: 0.0719954
[Epoch 10; Iter  1842/ 1862] train: loss: 0.0028606
[Epoch 10] ogbg-molmuv: 0.013142 val loss: 0.013554
[Epoch 10] ogbg-molmuv: 0.033661 test loss: 0.012238
[Epoch 11; Iter    10/ 1862] train: loss: 0.0015977
[Epoch 11; Iter    40/ 1862] train: loss: 0.0619933
[Epoch 11; Iter    70/ 1862] train: loss: 0.0019352
[Epoch 11; Iter   100/ 1862] train: loss: 0.0015432
[Epoch 11; Iter   130/ 1862] train: loss: 0.0605895
[Epoch 11; Iter   160/ 1862] train: loss: 0.0021247
[Epoch 11; Iter   190/ 1862] train: loss: 0.0019006
[Epoch 11; Iter   220/ 1862] train: loss: 0.0019204
[Epoch 11; Iter   250/ 1862] train: loss: 0.0752746
[Epoch 11; Iter   280/ 1862] train: loss: 0.2487844
[Epoch 11; Iter   310/ 1862] train: loss: 0.0028987
[Epoch 11; Iter   340/ 1862] train: loss: 0.0020233
[Epoch 11; Iter   370/ 1862] train: loss: 0.0026386
[Epoch 11; Iter   400/ 1862] train: loss: 0.0020189
[Epoch 11; Iter   430/ 1862] train: loss: 0.0638680
[Epoch 11; Iter   460/ 1862] train: loss: 0.0025945
[Epoch 11; Iter   490/ 1862] train: loss: 0.0014415
[Epoch 11; Iter   520/ 1862] train: loss: 0.0023294
[Epoch 11; Iter   550/ 1862] train: loss: 0.0021038
[Epoch 11; Iter   580/ 1862] train: loss: 0.0020930
[Epoch 11; Iter   610/ 1862] train: loss: 0.0018897
[Epoch 11; Iter   640/ 1862] train: loss: 0.0013495
[Epoch 11; Iter   670/ 1862] train: loss: 0.0016075
[Epoch 11; Iter   700/ 1862] train: loss: 0.0024572
[Epoch 11; Iter   730/ 1862] train: loss: 0.0015652
[Epoch 11; Iter   760/ 1862] train: loss: 0.0018879
[Epoch 11; Iter   790/ 1862] train: loss: 0.0734476
[Epoch 11; Iter   820/ 1862] train: loss: 0.0017164
[Epoch 11; Iter   850/ 1862] train: loss: 0.0015760
[Epoch 11; Iter   880/ 1862] train: loss: 0.0019169
[Epoch 11; Iter   910/ 1862] train: loss: 0.0021466
[Epoch 11; Iter   940/ 1862] train: loss: 0.0014224
[Epoch 11; Iter   970/ 1862] train: loss: 0.0017800
[Epoch 11; Iter  1000/ 1862] train: loss: 0.0017274
[Epoch 11; Iter  1030/ 1862] train: loss: 0.0014622
[Epoch 11; Iter  1060/ 1862] train: loss: 0.0015240
[Epoch 11; Iter  1090/ 1862] train: loss: 0.0018138
[Epoch 11; Iter  1120/ 1862] train: loss: 0.0024819
[Epoch 11; Iter  1150/ 1862] train: loss: 0.0022152
[Epoch 11; Iter  1180/ 1862] train: loss: 0.0015878
[Epoch 11; Iter  1210/ 1862] train: loss: 0.0857785
[Epoch 11; Iter  1240/ 1862] train: loss: 0.0026771
[Epoch 11; Iter  1270/ 1862] train: loss: 0.0028150
[Epoch 11; Iter  1300/ 1862] train: loss: 0.0017095
[Epoch 11; Iter  1330/ 1862] train: loss: 0.0015018
[Epoch 11; Iter  1360/ 1862] train: loss: 0.0010806
[Epoch 11; Iter  1390/ 1862] train: loss: 0.2893952
[Epoch 11; Iter  1420/ 1862] train: loss: 0.0019715
[Epoch 11; Iter  1450/ 1862] train: loss: 0.0013413
[Epoch 11; Iter  1480/ 1862] train: loss: 0.0013010
[Epoch 11; Iter  1510/ 1862] train: loss: 0.0013726
[Epoch 11; Iter  1540/ 1862] train: loss: 0.0016922
[Epoch 11; Iter  1570/ 1862] train: loss: 0.0030179
[Epoch 11; Iter  1600/ 1862] train: loss: 0.0022213
[Epoch 11; Iter  1630/ 1862] train: loss: 0.0750676
[Epoch 11; Iter  1660/ 1862] train: loss: 0.0016317
[Epoch 11; Iter  1690/ 1862] train: loss: 0.0017059
[Epoch 11; Iter  1720/ 1862] train: loss: 0.0019478
[Epoch 11; Iter  1750/ 1862] train: loss: 0.0017726
[Epoch 11; Iter  1780/ 1862] train: loss: 0.0015101
[Epoch 11; Iter  1810/ 1862] train: loss: 0.0018575
[Epoch 11; Iter  1840/ 1862] train: loss: 0.0014927
[Epoch 11] ogbg-molmuv: 0.010306 val loss: 0.101574
[Epoch 11] ogbg-molmuv: 0.009843 test loss: 0.069182
[Epoch 12; Iter     8/ 1862] train: loss: 0.0017268
[Epoch 12; Iter    38/ 1862] train: loss: 0.0015919
[Epoch 12; Iter    68/ 1862] train: loss: 0.0016537
[Epoch 12; Iter    98/ 1862] train: loss: 0.0021314
[Epoch 12; Iter   128/ 1862] train: loss: 0.0017776
[Epoch 12; Iter   158/ 1862] train: loss: 0.0020457
[Epoch 12; Iter   188/ 1862] train: loss: 0.0029676
[Epoch 12; Iter   218/ 1862] train: loss: 0.0755806
[Epoch 12; Iter   248/ 1862] train: loss: 0.0645975
[Epoch 12; Iter   278/ 1862] train: loss: 0.0014664
[Epoch 12; Iter   308/ 1862] train: loss: 0.0019974
[Epoch 12; Iter   338/ 1862] train: loss: 0.0016503
[Epoch 12; Iter   368/ 1862] train: loss: 0.0020158
[Epoch 12; Iter   398/ 1862] train: loss: 0.0016312
[Epoch 12; Iter   428/ 1862] train: loss: 0.1151788
[Epoch 12; Iter   458/ 1862] train: loss: 0.0020376
[Epoch 12; Iter   488/ 1862] train: loss: 0.0018070
[Epoch 12; Iter   518/ 1862] train: loss: 0.0013795
[Epoch 12; Iter   548/ 1862] train: loss: 0.0025728
[Epoch 12; Iter   578/ 1862] train: loss: 0.0021580
[Epoch 12; Iter   608/ 1862] train: loss: 0.0019009
[Epoch 12; Iter   638/ 1862] train: loss: 0.0823896
[Epoch 12; Iter   668/ 1862] train: loss: 0.0016870
[Epoch 12; Iter   698/ 1862] train: loss: 0.0018917
[Epoch 12; Iter   728/ 1862] train: loss: 0.0025229
[Epoch 12; Iter   758/ 1862] train: loss: 0.0033710
[Epoch 12; Iter   788/ 1862] train: loss: 0.0024984
[Epoch 12; Iter   818/ 1862] train: loss: 0.0025228
[Epoch 12; Iter   848/ 1862] train: loss: 0.0019667
[Epoch 12; Iter   878/ 1862] train: loss: 0.0842221
[Epoch 12; Iter   908/ 1862] train: loss: 0.0013952
[Epoch 12; Iter   938/ 1862] train: loss: 0.0036729
[Epoch 12; Iter   968/ 1862] train: loss: 0.0018589
[Epoch 12; Iter   998/ 1862] train: loss: 0.0018246
[Epoch 12; Iter  1028/ 1862] train: loss: 0.0021268
[Epoch 12; Iter  1058/ 1862] train: loss: 0.0016558
[Epoch 12; Iter  1088/ 1862] train: loss: 0.0018458
[Epoch 12; Iter  1118/ 1862] train: loss: 0.0011692
[Epoch 12; Iter  1148/ 1862] train: loss: 0.0021236
[Epoch 12; Iter  1178/ 1862] train: loss: 0.0689900
[Epoch 12; Iter  1208/ 1862] train: loss: 0.0518485
[Epoch 12; Iter  1238/ 1862] train: loss: 0.0018318
[Epoch 9; Iter  2156/ 2483] train: loss: 0.0019086
[Epoch 9; Iter  2186/ 2483] train: loss: 0.0016008
[Epoch 9; Iter  2216/ 2483] train: loss: 0.0751747
[Epoch 9; Iter  2246/ 2483] train: loss: 0.0016747
[Epoch 9; Iter  2276/ 2483] train: loss: 0.0024047
[Epoch 9; Iter  2306/ 2483] train: loss: 0.0023135
[Epoch 9; Iter  2336/ 2483] train: loss: 0.0022257
[Epoch 9; Iter  2366/ 2483] train: loss: 0.0754521
[Epoch 9; Iter  2396/ 2483] train: loss: 0.0798191
[Epoch 9; Iter  2426/ 2483] train: loss: 0.0966282
[Epoch 9; Iter  2456/ 2483] train: loss: 0.0015714
[Epoch 9] ogbg-molmuv: 0.022387 val loss: 0.010061
[Epoch 9] ogbg-molmuv: 0.026503 test loss: 0.014539
[Epoch 10; Iter     3/ 2483] train: loss: 0.0867354
[Epoch 10; Iter    33/ 2483] train: loss: 0.0018200
[Epoch 10; Iter    63/ 2483] train: loss: 0.0030312
[Epoch 10; Iter    93/ 2483] train: loss: 0.0018974
[Epoch 10; Iter   123/ 2483] train: loss: 0.0020277
[Epoch 10; Iter   153/ 2483] train: loss: 0.0015943
[Epoch 10; Iter   183/ 2483] train: loss: 0.0015947
[Epoch 10; Iter   213/ 2483] train: loss: 0.0015726
[Epoch 10; Iter   243/ 2483] train: loss: 0.0022743
[Epoch 10; Iter   273/ 2483] train: loss: 0.0023149
[Epoch 10; Iter   303/ 2483] train: loss: 0.0733174
[Epoch 10; Iter   333/ 2483] train: loss: 0.0026443
[Epoch 10; Iter   363/ 2483] train: loss: 0.0020446
[Epoch 10; Iter   393/ 2483] train: loss: 0.0019294
[Epoch 10; Iter   423/ 2483] train: loss: 0.0019063
[Epoch 10; Iter   453/ 2483] train: loss: 0.0670969
[Epoch 10; Iter   483/ 2483] train: loss: 0.0020480
[Epoch 10; Iter   513/ 2483] train: loss: 0.0018739
[Epoch 10; Iter   543/ 2483] train: loss: 0.0019447
[Epoch 10; Iter   573/ 2483] train: loss: 0.0028292
[Epoch 10; Iter   603/ 2483] train: loss: 0.0019833
[Epoch 10; Iter   633/ 2483] train: loss: 0.0020607
[Epoch 10; Iter   663/ 2483] train: loss: 0.0016388
[Epoch 10; Iter   693/ 2483] train: loss: 0.0025571
[Epoch 10; Iter   723/ 2483] train: loss: 0.0025198
[Epoch 10; Iter   753/ 2483] train: loss: 0.0017600
[Epoch 10; Iter   783/ 2483] train: loss: 0.0017052
[Epoch 10; Iter   813/ 2483] train: loss: 0.0021630
[Epoch 10; Iter   843/ 2483] train: loss: 0.0023665
[Epoch 10; Iter   873/ 2483] train: loss: 0.0023822
[Epoch 10; Iter   903/ 2483] train: loss: 0.0022896
[Epoch 10; Iter   933/ 2483] train: loss: 0.0018877
[Epoch 10; Iter   963/ 2483] train: loss: 0.0025870
[Epoch 10; Iter   993/ 2483] train: loss: 0.0025763
[Epoch 10; Iter  1023/ 2483] train: loss: 0.0800786
[Epoch 10; Iter  1053/ 2483] train: loss: 0.0020278
[Epoch 10; Iter  1083/ 2483] train: loss: 0.0014383
[Epoch 10; Iter  1113/ 2483] train: loss: 0.0020059
[Epoch 10; Iter  1143/ 2483] train: loss: 0.0016895
[Epoch 10; Iter  1173/ 2483] train: loss: 0.0035427
[Epoch 10; Iter  1203/ 2483] train: loss: 0.0021293
[Epoch 10; Iter  1233/ 2483] train: loss: 0.0021638
[Epoch 10; Iter  1263/ 2483] train: loss: 0.0016826
[Epoch 10; Iter  1293/ 2483] train: loss: 0.0017704
[Epoch 10; Iter  1323/ 2483] train: loss: 0.0012928
[Epoch 10; Iter  1353/ 2483] train: loss: 0.0013261
[Epoch 10; Iter  1383/ 2483] train: loss: 0.0015579
[Epoch 10; Iter  1413/ 2483] train: loss: 0.0012365
[Epoch 10; Iter  1443/ 2483] train: loss: 0.0011892
[Epoch 10; Iter  1473/ 2483] train: loss: 0.0015051
[Epoch 10; Iter  1503/ 2483] train: loss: 0.0729832
[Epoch 10; Iter  1533/ 2483] train: loss: 0.0015820
[Epoch 10; Iter  1563/ 2483] train: loss: 0.0018320
[Epoch 10; Iter  1593/ 2483] train: loss: 0.0021519
[Epoch 10; Iter  1623/ 2483] train: loss: 0.0018955
[Epoch 10; Iter  1653/ 2483] train: loss: 0.0011092
[Epoch 10; Iter  1683/ 2483] train: loss: 0.0022004
[Epoch 10; Iter  1713/ 2483] train: loss: 0.0013678
[Epoch 10; Iter  1743/ 2483] train: loss: 0.0016756
[Epoch 10; Iter  1773/ 2483] train: loss: 0.0034452
[Epoch 10; Iter  1803/ 2483] train: loss: 0.0755654
[Epoch 10; Iter  1833/ 2483] train: loss: 0.0821250
[Epoch 10; Iter  1863/ 2483] train: loss: 0.0024088
[Epoch 10; Iter  1893/ 2483] train: loss: 0.0016146
[Epoch 10; Iter  1923/ 2483] train: loss: 0.0017558
[Epoch 10; Iter  1953/ 2483] train: loss: 0.0966944
[Epoch 10; Iter  1983/ 2483] train: loss: 0.0017879
[Epoch 10; Iter  2013/ 2483] train: loss: 0.0018108
[Epoch 10; Iter  2043/ 2483] train: loss: 0.0620965
[Epoch 10; Iter  2073/ 2483] train: loss: 0.0695106
[Epoch 10; Iter  2103/ 2483] train: loss: 0.0020331
[Epoch 10; Iter  2133/ 2483] train: loss: 0.0021562
[Epoch 10; Iter  2163/ 2483] train: loss: 0.0607825
[Epoch 10; Iter  2193/ 2483] train: loss: 0.0024611
[Epoch 10; Iter  2223/ 2483] train: loss: 0.0018349
[Epoch 10; Iter  2253/ 2483] train: loss: 0.0021848
[Epoch 10; Iter  2283/ 2483] train: loss: 0.0021080
[Epoch 10; Iter  2313/ 2483] train: loss: 0.0026743
[Epoch 10; Iter  2343/ 2483] train: loss: 0.0015210
[Epoch 10; Iter  2373/ 2483] train: loss: 0.0013388
[Epoch 10; Iter  2403/ 2483] train: loss: 0.0017940
[Epoch 10; Iter  2433/ 2483] train: loss: 0.0016737
[Epoch 10; Iter  2463/ 2483] train: loss: 0.1448080
[Epoch 10] ogbg-molmuv: 0.021945 val loss: 0.011435
[Epoch 10] ogbg-molmuv: 0.019568 test loss: 0.014932
[Epoch 11; Iter    10/ 2483] train: loss: 0.0527872
[Epoch 11; Iter    40/ 2483] train: loss: 0.0019827
[Epoch 11; Iter    70/ 2483] train: loss: 0.0019995
[Epoch 11; Iter   100/ 2483] train: loss: 0.0806625
[Epoch 11; Iter   130/ 2483] train: loss: 0.0013833
[Epoch 11; Iter   160/ 2483] train: loss: 0.0011562
[Epoch 11; Iter   190/ 2483] train: loss: 0.0012293
[Epoch 11; Iter   220/ 2483] train: loss: 0.0018602
[Epoch 11; Iter   250/ 2483] train: loss: 0.0014484
[Epoch 11; Iter   280/ 2483] train: loss: 0.0653584
[Epoch 11; Iter   310/ 2483] train: loss: 0.0017013
[Epoch 11; Iter   340/ 2483] train: loss: 0.0582444
[Epoch 11; Iter   370/ 2483] train: loss: 0.0018275
[Epoch 11; Iter   400/ 2483] train: loss: 0.0026099
[Epoch 11; Iter   430/ 2483] train: loss: 0.0022189
[Epoch 11; Iter   460/ 2483] train: loss: 0.0514766
[Epoch 11; Iter   490/ 2483] train: loss: 0.0021677
[Epoch 11; Iter   520/ 2483] train: loss: 0.0018214
[Epoch 11; Iter   550/ 2483] train: loss: 0.0017427
[Epoch 11; Iter   580/ 2483] train: loss: 0.0013072
[Epoch 11; Iter   610/ 2483] train: loss: 0.0017750
[Epoch 11; Iter   640/ 2483] train: loss: 0.0022197
[Epoch 11; Iter   670/ 2483] train: loss: 0.0018546
[Epoch 11; Iter   700/ 2483] train: loss: 0.0718294
[Epoch 11; Iter   730/ 2483] train: loss: 0.0029419
[Epoch 11; Iter   760/ 2483] train: loss: 0.0030148
[Epoch 11; Iter   790/ 2483] train: loss: 0.0021443
[Epoch 11; Iter   820/ 2483] train: loss: 0.0020922
[Epoch 11; Iter   850/ 2483] train: loss: 0.1037966
[Epoch 11; Iter   880/ 2483] train: loss: 0.0019625
[Epoch 11; Iter   910/ 2483] train: loss: 0.0021822
[Epoch 11; Iter   940/ 2483] train: loss: 0.0025160
[Epoch 11; Iter   970/ 2483] train: loss: 0.0021703
[Epoch 11; Iter  1000/ 2483] train: loss: 0.0026237
[Epoch 11; Iter  1030/ 2483] train: loss: 0.0017679
[Epoch 11; Iter  1060/ 2483] train: loss: 0.0018864
[Epoch 11; Iter  1090/ 2483] train: loss: 0.0018394
[Epoch 11; Iter  1120/ 2483] train: loss: 0.0015076
[Epoch 11; Iter  1150/ 2483] train: loss: 0.0012046
[Epoch 11; Iter  1180/ 2483] train: loss: 0.0029613
[Epoch 11; Iter  1210/ 2483] train: loss: 0.0018240
[Epoch 11; Iter  1240/ 2483] train: loss: 0.0016811
[Epoch 11; Iter  1270/ 2483] train: loss: 0.0027447
[Epoch 11; Iter  1300/ 2483] train: loss: 0.0019006
[Epoch 11; Iter  1330/ 2483] train: loss: 0.0019275
[Epoch 11; Iter  1360/ 2483] train: loss: 0.0017365
[Epoch 11; Iter  1390/ 2483] train: loss: 0.0015480
[Epoch 11; Iter  1420/ 2483] train: loss: 0.0639717
[Epoch 11; Iter  1450/ 2483] train: loss: 0.1113025
[Epoch 11; Iter  1480/ 2483] train: loss: 0.0027544
[Epoch 11; Iter  1510/ 2483] train: loss: 0.0019689
[Epoch 11; Iter  1540/ 2483] train: loss: 0.0018296
[Epoch 11; Iter  1570/ 2483] train: loss: 0.0691994
[Epoch 11; Iter  1600/ 2483] train: loss: 0.0021429
[Epoch 11; Iter  1630/ 2483] train: loss: 0.0013612
[Epoch 11; Iter  1660/ 2483] train: loss: 0.0015960
[Epoch 11; Iter  1690/ 2483] train: loss: 0.0015787
[Epoch 11; Iter  1720/ 2483] train: loss: 0.0016502
[Epoch 11; Iter  1750/ 2483] train: loss: 0.0758056
[Epoch 10; Iter   402/ 1862] train: loss: 0.0022830
[Epoch 10; Iter   432/ 1862] train: loss: 0.0017265
[Epoch 10; Iter   462/ 1862] train: loss: 0.0017574
[Epoch 10; Iter   492/ 1862] train: loss: 0.0018952
[Epoch 10; Iter   522/ 1862] train: loss: 0.0018422
[Epoch 10; Iter   552/ 1862] train: loss: 0.0025874
[Epoch 10; Iter   582/ 1862] train: loss: 0.0023622
[Epoch 10; Iter   612/ 1862] train: loss: 0.0048244
[Epoch 10; Iter   642/ 1862] train: loss: 0.0021919
[Epoch 10; Iter   672/ 1862] train: loss: 0.0018001
[Epoch 10; Iter   702/ 1862] train: loss: 0.0032432
[Epoch 10; Iter   732/ 1862] train: loss: 0.0018170
[Epoch 10; Iter   762/ 1862] train: loss: 0.0874610
[Epoch 10; Iter   792/ 1862] train: loss: 0.0014253
[Epoch 10; Iter   822/ 1862] train: loss: 0.0011116
[Epoch 10; Iter   852/ 1862] train: loss: 0.0016443
[Epoch 10; Iter   882/ 1862] train: loss: 0.0015394
[Epoch 10; Iter   912/ 1862] train: loss: 0.0012237
[Epoch 10; Iter   942/ 1862] train: loss: 0.0016698
[Epoch 10; Iter   972/ 1862] train: loss: 0.1357990
[Epoch 10; Iter  1002/ 1862] train: loss: 0.0022996
[Epoch 10; Iter  1032/ 1862] train: loss: 0.0017334
[Epoch 10; Iter  1062/ 1862] train: loss: 0.0015952
[Epoch 10; Iter  1092/ 1862] train: loss: 0.0018780
[Epoch 10; Iter  1122/ 1862] train: loss: 0.0017458
[Epoch 10; Iter  1152/ 1862] train: loss: 0.0020365
[Epoch 10; Iter  1182/ 1862] train: loss: 0.0018686
[Epoch 10; Iter  1212/ 1862] train: loss: 0.0016571
[Epoch 10; Iter  1242/ 1862] train: loss: 0.0014933
[Epoch 10; Iter  1272/ 1862] train: loss: 0.0013134
[Epoch 10; Iter  1302/ 1862] train: loss: 0.0883785
[Epoch 10; Iter  1332/ 1862] train: loss: 0.0012881
[Epoch 10; Iter  1362/ 1862] train: loss: 0.0016442
[Epoch 10; Iter  1392/ 1862] train: loss: 0.0012437
[Epoch 10; Iter  1422/ 1862] train: loss: 0.0016744
[Epoch 10; Iter  1452/ 1862] train: loss: 0.0032683
[Epoch 10; Iter  1482/ 1862] train: loss: 0.0728054
[Epoch 10; Iter  1512/ 1862] train: loss: 0.0020358
[Epoch 10; Iter  1542/ 1862] train: loss: 0.0024060
[Epoch 10; Iter  1572/ 1862] train: loss: 0.0016750
[Epoch 10; Iter  1602/ 1862] train: loss: 0.0014857
[Epoch 10; Iter  1632/ 1862] train: loss: 0.0019229
[Epoch 10; Iter  1662/ 1862] train: loss: 0.0017026
[Epoch 10; Iter  1692/ 1862] train: loss: 0.0021128
[Epoch 10; Iter  1722/ 1862] train: loss: 0.0019746
[Epoch 10; Iter  1752/ 1862] train: loss: 0.0023661
[Epoch 10; Iter  1782/ 1862] train: loss: 0.0027758
[Epoch 10; Iter  1812/ 1862] train: loss: 0.0020752
[Epoch 10; Iter  1842/ 1862] train: loss: 0.0019117
[Epoch 10] ogbg-molmuv: 0.019869 val loss: 0.013674
[Epoch 10] ogbg-molmuv: 0.012172 test loss: 0.012613
[Epoch 11; Iter    10/ 1862] train: loss: 0.0012958
[Epoch 11; Iter    40/ 1862] train: loss: 0.0023491
[Epoch 11; Iter    70/ 1862] train: loss: 0.0020854
[Epoch 11; Iter   100/ 1862] train: loss: 0.0017245
[Epoch 11; Iter   130/ 1862] train: loss: 0.0027337
[Epoch 11; Iter   160/ 1862] train: loss: 0.1137006
[Epoch 11; Iter   190/ 1862] train: loss: 0.0022607
[Epoch 11; Iter   220/ 1862] train: loss: 0.0024845
[Epoch 11; Iter   250/ 1862] train: loss: 0.0019450
[Epoch 11; Iter   280/ 1862] train: loss: 0.0019105
[Epoch 11; Iter   310/ 1862] train: loss: 0.0018807
[Epoch 11; Iter   340/ 1862] train: loss: 0.0855902
[Epoch 11; Iter   370/ 1862] train: loss: 0.0016896
[Epoch 11; Iter   400/ 1862] train: loss: 0.0017557
[Epoch 11; Iter   430/ 1862] train: loss: 0.0011493
[Epoch 11; Iter   460/ 1862] train: loss: 0.0012420
[Epoch 11; Iter   490/ 1862] train: loss: 0.0009354
[Epoch 11; Iter   520/ 1862] train: loss: 0.0013403
[Epoch 11; Iter   550/ 1862] train: loss: 0.0029403
[Epoch 11; Iter   580/ 1862] train: loss: 0.0015317
[Epoch 11; Iter   610/ 1862] train: loss: 0.0022861
[Epoch 11; Iter   640/ 1862] train: loss: 0.0021137
[Epoch 11; Iter   670/ 1862] train: loss: 0.0016506
[Epoch 11; Iter   700/ 1862] train: loss: 0.1847688
[Epoch 11; Iter   730/ 1862] train: loss: 0.0784468
[Epoch 11; Iter   760/ 1862] train: loss: 0.0021615
[Epoch 11; Iter   790/ 1862] train: loss: 0.0018434
[Epoch 11; Iter   820/ 1862] train: loss: 0.0796870
[Epoch 11; Iter   850/ 1862] train: loss: 0.0016607
[Epoch 11; Iter   880/ 1862] train: loss: 0.0013056
[Epoch 11; Iter   910/ 1862] train: loss: 0.0013501
[Epoch 11; Iter   940/ 1862] train: loss: 0.0017091
[Epoch 11; Iter   970/ 1862] train: loss: 0.0013662
[Epoch 11; Iter  1000/ 1862] train: loss: 0.0012673
[Epoch 11; Iter  1030/ 1862] train: loss: 0.0019121
[Epoch 11; Iter  1060/ 1862] train: loss: 0.0018626
[Epoch 11; Iter  1090/ 1862] train: loss: 0.0019189
[Epoch 11; Iter  1120/ 1862] train: loss: 0.0023558
[Epoch 11; Iter  1150/ 1862] train: loss: 0.0026239
[Epoch 11; Iter  1180/ 1862] train: loss: 0.0030424
[Epoch 11; Iter  1210/ 1862] train: loss: 0.0021935
[Epoch 11; Iter  1240/ 1862] train: loss: 0.0024706
[Epoch 11; Iter  1270/ 1862] train: loss: 0.0019902
[Epoch 11; Iter  1300/ 1862] train: loss: 0.0016439
[Epoch 11; Iter  1330/ 1862] train: loss: 0.0026230
[Epoch 11; Iter  1360/ 1862] train: loss: 0.0054521
[Epoch 11; Iter  1390/ 1862] train: loss: 0.0059052
[Epoch 11; Iter  1420/ 1862] train: loss: 0.0020515
[Epoch 11; Iter  1450/ 1862] train: loss: 0.0028071
[Epoch 11; Iter  1480/ 1862] train: loss: 0.0022230
[Epoch 11; Iter  1510/ 1862] train: loss: 0.0023802
[Epoch 11; Iter  1540/ 1862] train: loss: 0.0019701
[Epoch 11; Iter  1570/ 1862] train: loss: 0.0025040
[Epoch 11; Iter  1600/ 1862] train: loss: 0.0017636
[Epoch 11; Iter  1630/ 1862] train: loss: 0.0022992
[Epoch 11; Iter  1660/ 1862] train: loss: 0.0012805
[Epoch 11; Iter  1690/ 1862] train: loss: 0.0019007
[Epoch 11; Iter  1720/ 1862] train: loss: 0.0021645
[Epoch 11; Iter  1750/ 1862] train: loss: 0.0019572
[Epoch 11; Iter  1780/ 1862] train: loss: 0.0019870
[Epoch 11; Iter  1810/ 1862] train: loss: 0.0030530
[Epoch 11; Iter  1840/ 1862] train: loss: 0.0018035
[Epoch 11] ogbg-molmuv: 0.014996 val loss: 0.013698
[Epoch 11] ogbg-molmuv: 0.029279 test loss: 0.012422
[Epoch 12; Iter     8/ 1862] train: loss: 0.0016556
[Epoch 12; Iter    38/ 1862] train: loss: 0.0015535
[Epoch 12; Iter    68/ 1862] train: loss: 0.0020234
[Epoch 12; Iter    98/ 1862] train: loss: 0.0020993
[Epoch 12; Iter   128/ 1862] train: loss: 0.0022181
[Epoch 12; Iter   158/ 1862] train: loss: 0.0021848
[Epoch 12; Iter   188/ 1862] train: loss: 0.0013190
[Epoch 12; Iter   218/ 1862] train: loss: 0.0014837
[Epoch 12; Iter   248/ 1862] train: loss: 0.0011870
[Epoch 12; Iter   278/ 1862] train: loss: 0.0027081
[Epoch 12; Iter   308/ 1862] train: loss: 0.0015312
[Epoch 12; Iter   338/ 1862] train: loss: 0.0019406
[Epoch 12; Iter   368/ 1862] train: loss: 0.0017835
[Epoch 12; Iter   398/ 1862] train: loss: 0.0032410
[Epoch 12; Iter   428/ 1862] train: loss: 0.0016635
[Epoch 12; Iter   458/ 1862] train: loss: 0.0017929
[Epoch 12; Iter   488/ 1862] train: loss: 0.0020575
[Epoch 12; Iter   518/ 1862] train: loss: 0.0012223
[Epoch 12; Iter   548/ 1862] train: loss: 0.0019584
[Epoch 12; Iter   578/ 1862] train: loss: 0.0026475
[Epoch 12; Iter   608/ 1862] train: loss: 0.0744981
[Epoch 12; Iter   638/ 1862] train: loss: 0.0019014
[Epoch 12; Iter   668/ 1862] train: loss: 0.0010608
[Epoch 12; Iter   698/ 1862] train: loss: 0.0890849
[Epoch 12; Iter   728/ 1862] train: loss: 0.0822468
[Epoch 12; Iter   758/ 1862] train: loss: 0.0967383
[Epoch 12; Iter   788/ 1862] train: loss: 0.0013122
[Epoch 12; Iter   818/ 1862] train: loss: 0.0016603
[Epoch 12; Iter   848/ 1862] train: loss: 0.0017518
[Epoch 12; Iter   878/ 1862] train: loss: 0.0022138
[Epoch 12; Iter   908/ 1862] train: loss: 0.0017567
[Epoch 12; Iter   938/ 1862] train: loss: 0.0024093
[Epoch 12; Iter   968/ 1862] train: loss: 0.0024332
[Epoch 12; Iter   998/ 1862] train: loss: 0.0023247
[Epoch 12; Iter  1028/ 1862] train: loss: 0.0017718
[Epoch 12; Iter  1058/ 1862] train: loss: 0.0027888
[Epoch 12; Iter  1088/ 1862] train: loss: 0.0025253
[Epoch 12; Iter  1118/ 1862] train: loss: 0.0024606
[Epoch 12; Iter  1148/ 1862] train: loss: 0.0825926
[Epoch 12; Iter  1178/ 1862] train: loss: 0.0019815
[Epoch 12; Iter  1208/ 1862] train: loss: 0.0021860
[Epoch 12; Iter  1238/ 1862] train: loss: 0.0021600
[Epoch 10; Iter   402/ 1862] train: loss: 0.0014971
[Epoch 10; Iter   432/ 1862] train: loss: 0.0020528
[Epoch 10; Iter   462/ 1862] train: loss: 0.0029790
[Epoch 10; Iter   492/ 1862] train: loss: 0.0018178
[Epoch 10; Iter   522/ 1862] train: loss: 0.0019412
[Epoch 10; Iter   552/ 1862] train: loss: 0.0021281
[Epoch 10; Iter   582/ 1862] train: loss: 0.0025179
[Epoch 10; Iter   612/ 1862] train: loss: 0.0025372
[Epoch 10; Iter   642/ 1862] train: loss: 0.0020057
[Epoch 10; Iter   672/ 1862] train: loss: 0.0020844
[Epoch 10; Iter   702/ 1862] train: loss: 0.0020669
[Epoch 10; Iter   732/ 1862] train: loss: 0.1215987
[Epoch 10; Iter   762/ 1862] train: loss: 0.0021582
[Epoch 10; Iter   792/ 1862] train: loss: 0.0025234
[Epoch 10; Iter   822/ 1862] train: loss: 0.0018663
[Epoch 10; Iter   852/ 1862] train: loss: 0.0995364
[Epoch 10; Iter   882/ 1862] train: loss: 0.0018505
[Epoch 10; Iter   912/ 1862] train: loss: 0.0017187
[Epoch 10; Iter   942/ 1862] train: loss: 0.0020634
[Epoch 10; Iter   972/ 1862] train: loss: 0.0020065
[Epoch 10; Iter  1002/ 1862] train: loss: 0.0018605
[Epoch 10; Iter  1032/ 1862] train: loss: 0.0021904
[Epoch 10; Iter  1062/ 1862] train: loss: 0.0026992
[Epoch 10; Iter  1092/ 1862] train: loss: 0.0801849
[Epoch 10; Iter  1122/ 1862] train: loss: 0.0020715
[Epoch 10; Iter  1152/ 1862] train: loss: 0.0019618
[Epoch 10; Iter  1182/ 1862] train: loss: 0.0017839
[Epoch 10; Iter  1212/ 1862] train: loss: 0.0648176
[Epoch 10; Iter  1242/ 1862] train: loss: 0.0021259
[Epoch 10; Iter  1272/ 1862] train: loss: 0.0017362
[Epoch 10; Iter  1302/ 1862] train: loss: 0.0898585
[Epoch 10; Iter  1332/ 1862] train: loss: 0.0025431
[Epoch 10; Iter  1362/ 1862] train: loss: 0.0027251
[Epoch 10; Iter  1392/ 1862] train: loss: 0.0017276
[Epoch 10; Iter  1422/ 1862] train: loss: 0.0017802
[Epoch 10; Iter  1452/ 1862] train: loss: 0.0014240
[Epoch 10; Iter  1482/ 1862] train: loss: 0.0016050
[Epoch 10; Iter  1512/ 1862] train: loss: 0.0015374
[Epoch 10; Iter  1542/ 1862] train: loss: 0.0021735
[Epoch 10; Iter  1572/ 1862] train: loss: 0.0018247
[Epoch 10; Iter  1602/ 1862] train: loss: 0.0016292
[Epoch 10; Iter  1632/ 1862] train: loss: 0.0990687
[Epoch 10; Iter  1662/ 1862] train: loss: 0.0016823
[Epoch 10; Iter  1692/ 1862] train: loss: 0.0027359
[Epoch 10; Iter  1722/ 1862] train: loss: 0.0019346
[Epoch 10; Iter  1752/ 1862] train: loss: 0.0017330
[Epoch 10; Iter  1782/ 1862] train: loss: 0.0023339
[Epoch 10; Iter  1812/ 1862] train: loss: 0.0898239
[Epoch 10; Iter  1842/ 1862] train: loss: 0.0020475
[Epoch 10] ogbg-molmuv: 0.016589 val loss: 0.013677
[Epoch 10] ogbg-molmuv: 0.017931 test loss: 0.012558
[Epoch 11; Iter    10/ 1862] train: loss: 0.0019473
[Epoch 11; Iter    40/ 1862] train: loss: 0.0016456
[Epoch 11; Iter    70/ 1862] train: loss: 0.0865138
[Epoch 11; Iter   100/ 1862] train: loss: 0.0020901
[Epoch 11; Iter   130/ 1862] train: loss: 0.0021966
[Epoch 11; Iter   160/ 1862] train: loss: 0.1884810
[Epoch 11; Iter   190/ 1862] train: loss: 0.0016652
[Epoch 11; Iter   220/ 1862] train: loss: 0.0019581
[Epoch 11; Iter   250/ 1862] train: loss: 0.0021773
[Epoch 11; Iter   280/ 1862] train: loss: 0.0860807
[Epoch 11; Iter   310/ 1862] train: loss: 0.0020474
[Epoch 11; Iter   340/ 1862] train: loss: 0.0028861
[Epoch 11; Iter   370/ 1862] train: loss: 0.0849698
[Epoch 11; Iter   400/ 1862] train: loss: 0.0024727
[Epoch 11; Iter   430/ 1862] train: loss: 0.0023846
[Epoch 11; Iter   460/ 1862] train: loss: 0.0023346
[Epoch 11; Iter   490/ 1862] train: loss: 0.0021356
[Epoch 11; Iter   520/ 1862] train: loss: 0.0023005
[Epoch 11; Iter   550/ 1862] train: loss: 0.0017358
[Epoch 11; Iter   580/ 1862] train: loss: 0.0020441
[Epoch 11; Iter   610/ 1862] train: loss: 0.0846593
[Epoch 11; Iter   640/ 1862] train: loss: 0.0017260
[Epoch 11; Iter   670/ 1862] train: loss: 0.0015759
[Epoch 11; Iter   700/ 1862] train: loss: 0.0934098
[Epoch 11; Iter   730/ 1862] train: loss: 0.0019513
[Epoch 11; Iter   760/ 1862] train: loss: 0.0701855
[Epoch 11; Iter   790/ 1862] train: loss: 0.0019663
[Epoch 11; Iter   820/ 1862] train: loss: 0.0015728
[Epoch 11; Iter   850/ 1862] train: loss: 0.0022422
[Epoch 11; Iter   880/ 1862] train: loss: 0.0030313
[Epoch 11; Iter   910/ 1862] train: loss: 0.0020776
[Epoch 11; Iter   940/ 1862] train: loss: 0.0028202
[Epoch 11; Iter   970/ 1862] train: loss: 0.0019925
[Epoch 11; Iter  1000/ 1862] train: loss: 0.0015943
[Epoch 11; Iter  1030/ 1862] train: loss: 0.0019172
[Epoch 11; Iter  1060/ 1862] train: loss: 0.0015738
[Epoch 11; Iter  1090/ 1862] train: loss: 0.0014120
[Epoch 11; Iter  1120/ 1862] train: loss: 0.0018671
[Epoch 11; Iter  1150/ 1862] train: loss: 0.0774737
[Epoch 11; Iter  1180/ 1862] train: loss: 0.0015918
[Epoch 11; Iter  1210/ 1862] train: loss: 0.0013912
[Epoch 11; Iter  1240/ 1862] train: loss: 0.0047999
[Epoch 11; Iter  1270/ 1862] train: loss: 0.0017686
[Epoch 11; Iter  1300/ 1862] train: loss: 0.0014189
[Epoch 11; Iter  1330/ 1862] train: loss: 0.0679011
[Epoch 11; Iter  1360/ 1862] train: loss: 0.0021350
[Epoch 11; Iter  1390/ 1862] train: loss: 0.0018599
[Epoch 11; Iter  1420/ 1862] train: loss: 0.0011123
[Epoch 11; Iter  1450/ 1862] train: loss: 0.0011379
[Epoch 11; Iter  1480/ 1862] train: loss: 0.0012764
[Epoch 11; Iter  1510/ 1862] train: loss: 0.0014051
[Epoch 11; Iter  1540/ 1862] train: loss: 0.0018718
[Epoch 11; Iter  1570/ 1862] train: loss: 0.0018699
[Epoch 11; Iter  1600/ 1862] train: loss: 0.0022322
[Epoch 11; Iter  1630/ 1862] train: loss: 0.0014171
[Epoch 11; Iter  1660/ 1862] train: loss: 0.0012732
[Epoch 11; Iter  1690/ 1862] train: loss: 0.0018865
[Epoch 11; Iter  1720/ 1862] train: loss: 0.1491142
[Epoch 11; Iter  1750/ 1862] train: loss: 0.0023295
[Epoch 11; Iter  1780/ 1862] train: loss: 0.0020734
[Epoch 11; Iter  1810/ 1862] train: loss: 0.0019937
[Epoch 11; Iter  1840/ 1862] train: loss: 0.0019639
[Epoch 11] ogbg-molmuv: 0.013227 val loss: 0.013857
[Epoch 11] ogbg-molmuv: 0.009632 test loss: 0.012675
[Epoch 12; Iter     8/ 1862] train: loss: 0.0016641
[Epoch 12; Iter    38/ 1862] train: loss: 0.0027041
[Epoch 12; Iter    68/ 1862] train: loss: 0.0047237
[Epoch 12; Iter    98/ 1862] train: loss: 0.0026878
[Epoch 12; Iter   128/ 1862] train: loss: 0.0024143
[Epoch 12; Iter   158/ 1862] train: loss: 0.0017875
[Epoch 12; Iter   188/ 1862] train: loss: 0.0015445
[Epoch 12; Iter   218/ 1862] train: loss: 0.0018067
[Epoch 12; Iter   248/ 1862] train: loss: 0.0782542
[Epoch 12; Iter   278/ 1862] train: loss: 0.0015379
[Epoch 12; Iter   308/ 1862] train: loss: 0.0015975
[Epoch 12; Iter   338/ 1862] train: loss: 0.0015129
[Epoch 12; Iter   368/ 1862] train: loss: 0.0019624
[Epoch 12; Iter   398/ 1862] train: loss: 0.0022234
[Epoch 12; Iter   428/ 1862] train: loss: 0.0019327
[Epoch 12; Iter   458/ 1862] train: loss: 0.0021450
[Epoch 12; Iter   488/ 1862] train: loss: 0.0014380
[Epoch 12; Iter   518/ 1862] train: loss: 0.0015524
[Epoch 12; Iter   548/ 1862] train: loss: 0.0029437
[Epoch 12; Iter   578/ 1862] train: loss: 0.0529340
[Epoch 12; Iter   608/ 1862] train: loss: 0.0026319
[Epoch 12; Iter   638/ 1862] train: loss: 0.0019102
[Epoch 12; Iter   668/ 1862] train: loss: 0.0015293
[Epoch 12; Iter   698/ 1862] train: loss: 0.0015951
[Epoch 12; Iter   728/ 1862] train: loss: 0.0021862
[Epoch 12; Iter   758/ 1862] train: loss: 0.0025249
[Epoch 12; Iter   788/ 1862] train: loss: 0.0755040
[Epoch 12; Iter   818/ 1862] train: loss: 0.0014577
[Epoch 12; Iter   848/ 1862] train: loss: 0.0018653
[Epoch 12; Iter   878/ 1862] train: loss: 0.0016580
[Epoch 12; Iter   908/ 1862] train: loss: 0.0025042
[Epoch 12; Iter   938/ 1862] train: loss: 0.0017751
[Epoch 12; Iter   968/ 1862] train: loss: 0.0021031
[Epoch 12; Iter   998/ 1862] train: loss: 0.0016058
[Epoch 12; Iter  1028/ 1862] train: loss: 0.0022729
[Epoch 12; Iter  1058/ 1862] train: loss: 0.0724808
[Epoch 12; Iter  1088/ 1862] train: loss: 0.0030875
[Epoch 12; Iter  1118/ 1862] train: loss: 0.0020290
[Epoch 12; Iter  1148/ 1862] train: loss: 0.0020554
[Epoch 12; Iter  1178/ 1862] train: loss: 0.0926823
[Epoch 12; Iter  1208/ 1862] train: loss: 0.0690682
[Epoch 12; Iter  1238/ 1862] train: loss: 0.0025465
[Epoch 9; Iter  2156/ 2483] train: loss: 0.0608726
[Epoch 9; Iter  2186/ 2483] train: loss: 0.0018281
[Epoch 9; Iter  2216/ 2483] train: loss: 0.0017627
[Epoch 9; Iter  2246/ 2483] train: loss: 0.0061651
[Epoch 9; Iter  2276/ 2483] train: loss: 0.0999677
[Epoch 9; Iter  2306/ 2483] train: loss: 0.0021671
[Epoch 9; Iter  2336/ 2483] train: loss: 0.0022497
[Epoch 9; Iter  2366/ 2483] train: loss: 0.0018375
[Epoch 9; Iter  2396/ 2483] train: loss: 0.0016632
[Epoch 9; Iter  2426/ 2483] train: loss: 0.0688315
[Epoch 9; Iter  2456/ 2483] train: loss: 0.0016706
[Epoch 9] ogbg-molmuv: 0.030186 val loss: 0.010569
[Epoch 9] ogbg-molmuv: 0.018413 test loss: 0.014938
[Epoch 10; Iter     3/ 2483] train: loss: 0.0022715
[Epoch 10; Iter    33/ 2483] train: loss: 0.0035604
[Epoch 10; Iter    63/ 2483] train: loss: 0.0024137
[Epoch 10; Iter    93/ 2483] train: loss: 0.1669221
[Epoch 10; Iter   123/ 2483] train: loss: 0.0637034
[Epoch 10; Iter   153/ 2483] train: loss: 0.0020777
[Epoch 10; Iter   183/ 2483] train: loss: 0.0019597
[Epoch 10; Iter   213/ 2483] train: loss: 0.0776020
[Epoch 10; Iter   243/ 2483] train: loss: 0.0706345
[Epoch 10; Iter   273/ 2483] train: loss: 0.0020104
[Epoch 10; Iter   303/ 2483] train: loss: 0.0023065
[Epoch 10; Iter   333/ 2483] train: loss: 0.0025656
[Epoch 10; Iter   363/ 2483] train: loss: 0.0013636
[Epoch 10; Iter   393/ 2483] train: loss: 0.0016440
[Epoch 10; Iter   423/ 2483] train: loss: 0.0015617
[Epoch 10; Iter   453/ 2483] train: loss: 0.0015003
[Epoch 10; Iter   483/ 2483] train: loss: 0.0010297
[Epoch 10; Iter   513/ 2483] train: loss: 0.0012478
[Epoch 10; Iter   543/ 2483] train: loss: 0.0017154
[Epoch 10; Iter   573/ 2483] train: loss: 0.0017120
[Epoch 10; Iter   603/ 2483] train: loss: 0.0020337
[Epoch 10; Iter   633/ 2483] train: loss: 0.0709476
[Epoch 10; Iter   663/ 2483] train: loss: 0.0017396
[Epoch 10; Iter   693/ 2483] train: loss: 0.0016527
[Epoch 10; Iter   723/ 2483] train: loss: 0.0017256
[Epoch 10; Iter   753/ 2483] train: loss: 0.0013880
[Epoch 10; Iter   783/ 2483] train: loss: 0.0021259
[Epoch 10; Iter   813/ 2483] train: loss: 0.0990355
[Epoch 10; Iter   843/ 2483] train: loss: 0.0025287
[Epoch 10; Iter   873/ 2483] train: loss: 0.0018927
[Epoch 10; Iter   903/ 2483] train: loss: 0.0024234
[Epoch 10; Iter   933/ 2483] train: loss: 0.0019413
[Epoch 10; Iter   963/ 2483] train: loss: 0.0016539
[Epoch 10; Iter   993/ 2483] train: loss: 0.0024171
[Epoch 10; Iter  1023/ 2483] train: loss: 0.0015773
[Epoch 10; Iter  1053/ 2483] train: loss: 0.0565385
[Epoch 10; Iter  1083/ 2483] train: loss: 0.0019578
[Epoch 10; Iter  1113/ 2483] train: loss: 0.0031017
[Epoch 10; Iter  1143/ 2483] train: loss: 0.0026877
[Epoch 10; Iter  1173/ 2483] train: loss: 0.0023189
[Epoch 10; Iter  1203/ 2483] train: loss: 0.0022365
[Epoch 10; Iter  1233/ 2483] train: loss: 0.0500222
[Epoch 10; Iter  1263/ 2483] train: loss: 0.0024640
[Epoch 10; Iter  1293/ 2483] train: loss: 0.0014986
[Epoch 10; Iter  1323/ 2483] train: loss: 0.0028674
[Epoch 10; Iter  1353/ 2483] train: loss: 0.0018603
[Epoch 10; Iter  1383/ 2483] train: loss: 0.0019548
[Epoch 10; Iter  1413/ 2483] train: loss: 0.0020234
[Epoch 10; Iter  1443/ 2483] train: loss: 0.0856089
[Epoch 10; Iter  1473/ 2483] train: loss: 0.0019996
[Epoch 10; Iter  1503/ 2483] train: loss: 0.0021796
[Epoch 10; Iter  1533/ 2483] train: loss: 0.0024272
[Epoch 10; Iter  1563/ 2483] train: loss: 0.0017278
[Epoch 10; Iter  1593/ 2483] train: loss: 0.0028539
[Epoch 10; Iter  1623/ 2483] train: loss: 0.0023334
[Epoch 10; Iter  1653/ 2483] train: loss: 0.0024602
[Epoch 10; Iter  1683/ 2483] train: loss: 0.0492132
[Epoch 10; Iter  1713/ 2483] train: loss: 0.0020148
[Epoch 10; Iter  1743/ 2483] train: loss: 0.0024659
[Epoch 10; Iter  1773/ 2483] train: loss: 0.0019636
[Epoch 10; Iter  1803/ 2483] train: loss: 0.0929119
[Epoch 10; Iter  1833/ 2483] train: loss: 0.0018351
[Epoch 10; Iter  1863/ 2483] train: loss: 0.1539523
[Epoch 10; Iter  1893/ 2483] train: loss: 0.0014636
[Epoch 10; Iter  1923/ 2483] train: loss: 0.0018242
[Epoch 10; Iter  1953/ 2483] train: loss: 0.0016729
[Epoch 10; Iter  1983/ 2483] train: loss: 0.0023260
[Epoch 10; Iter  2013/ 2483] train: loss: 0.0460294
[Epoch 10; Iter  2043/ 2483] train: loss: 0.0023547
[Epoch 10; Iter  2073/ 2483] train: loss: 0.0023154
[Epoch 10; Iter  2103/ 2483] train: loss: 0.0021418
[Epoch 10; Iter  2133/ 2483] train: loss: 0.0023216
[Epoch 10; Iter  2163/ 2483] train: loss: 0.0024049
[Epoch 10; Iter  2193/ 2483] train: loss: 0.0025595
[Epoch 10; Iter  2223/ 2483] train: loss: 0.0671751
[Epoch 10; Iter  2253/ 2483] train: loss: 0.0023764
[Epoch 10; Iter  2283/ 2483] train: loss: 0.0027669
[Epoch 10; Iter  2313/ 2483] train: loss: 0.0023902
[Epoch 10; Iter  2343/ 2483] train: loss: 0.0041628
[Epoch 10; Iter  2373/ 2483] train: loss: 0.0017252
[Epoch 10; Iter  2403/ 2483] train: loss: 0.0028934
[Epoch 10; Iter  2433/ 2483] train: loss: 0.0026200
[Epoch 10; Iter  2463/ 2483] train: loss: 0.0017140
[Epoch 10] ogbg-molmuv: 0.053755 val loss: 0.010050
[Epoch 10] ogbg-molmuv: 0.018887 test loss: 0.024696
[Epoch 11; Iter    10/ 2483] train: loss: 0.0013900
[Epoch 11; Iter    40/ 2483] train: loss: 0.0017292
[Epoch 11; Iter    70/ 2483] train: loss: 0.0014887
[Epoch 11; Iter   100/ 2483] train: loss: 0.0012908
[Epoch 11; Iter   130/ 2483] train: loss: 0.0015403
[Epoch 11; Iter   160/ 2483] train: loss: 0.0021427
[Epoch 11; Iter   190/ 2483] train: loss: 0.0026486
[Epoch 11; Iter   220/ 2483] train: loss: 0.0730024
[Epoch 11; Iter   250/ 2483] train: loss: 0.0020366
[Epoch 11; Iter   280/ 2483] train: loss: 0.0018700
[Epoch 11; Iter   310/ 2483] train: loss: 0.0013943
[Epoch 11; Iter   340/ 2483] train: loss: 0.0013758
[Epoch 11; Iter   370/ 2483] train: loss: 0.0011202
[Epoch 11; Iter   400/ 2483] train: loss: 0.0851317
[Epoch 11; Iter   430/ 2483] train: loss: 0.0014852
[Epoch 11; Iter   460/ 2483] train: loss: 0.0016172
[Epoch 11; Iter   490/ 2483] train: loss: 0.0014659
[Epoch 11; Iter   520/ 2483] train: loss: 0.0012441
[Epoch 11; Iter   550/ 2483] train: loss: 0.0023194
[Epoch 11; Iter   580/ 2483] train: loss: 0.0028533
[Epoch 11; Iter   610/ 2483] train: loss: 0.0018886
[Epoch 11; Iter   640/ 2483] train: loss: 0.1031341
[Epoch 11; Iter   670/ 2483] train: loss: 0.0023809
[Epoch 11; Iter   700/ 2483] train: loss: 0.0018921
[Epoch 11; Iter   730/ 2483] train: loss: 0.0015002
[Epoch 11; Iter   760/ 2483] train: loss: 0.0977011
[Epoch 11; Iter   790/ 2483] train: loss: 0.0016145
[Epoch 11; Iter   820/ 2483] train: loss: 0.0020651
[Epoch 11; Iter   850/ 2483] train: loss: 0.1372645
[Epoch 11; Iter   880/ 2483] train: loss: 0.0019115
[Epoch 11; Iter   910/ 2483] train: loss: 0.0017046
[Epoch 11; Iter   940/ 2483] train: loss: 0.0014965
[Epoch 11; Iter   970/ 2483] train: loss: 0.0013450
[Epoch 11; Iter  1000/ 2483] train: loss: 0.0017069
[Epoch 11; Iter  1030/ 2483] train: loss: 0.0023738
[Epoch 11; Iter  1060/ 2483] train: loss: 0.0014039
[Epoch 11; Iter  1090/ 2483] train: loss: 0.0014871
[Epoch 11; Iter  1120/ 2483] train: loss: 0.0016099
[Epoch 11; Iter  1150/ 2483] train: loss: 0.0036681
[Epoch 11; Iter  1180/ 2483] train: loss: 0.0024820
[Epoch 11; Iter  1210/ 2483] train: loss: 0.0017132
[Epoch 11; Iter  1240/ 2483] train: loss: 0.0017237
[Epoch 11; Iter  1270/ 2483] train: loss: 0.0728460
[Epoch 11; Iter  1300/ 2483] train: loss: 0.0035855
[Epoch 11; Iter  1330/ 2483] train: loss: 0.0596930
[Epoch 11; Iter  1360/ 2483] train: loss: 0.0824299
[Epoch 11; Iter  1390/ 2483] train: loss: 0.0027140
[Epoch 11; Iter  1420/ 2483] train: loss: 0.0020936
[Epoch 11; Iter  1450/ 2483] train: loss: 0.0021253
[Epoch 11; Iter  1480/ 2483] train: loss: 0.0026880
[Epoch 11; Iter  1510/ 2483] train: loss: 0.0020160
[Epoch 11; Iter  1540/ 2483] train: loss: 0.0018718
[Epoch 11; Iter  1570/ 2483] train: loss: 0.0026322
[Epoch 11; Iter  1600/ 2483] train: loss: 0.0026945
[Epoch 11; Iter  1630/ 2483] train: loss: 0.0014589
[Epoch 11; Iter  1660/ 2483] train: loss: 0.0017338
[Epoch 11; Iter  1690/ 2483] train: loss: 0.0014910
[Epoch 11; Iter  1720/ 2483] train: loss: 0.0758102
[Epoch 11; Iter  1750/ 2483] train: loss: 0.0699035
[Epoch 11; Iter   150/ 2172] train: loss: 0.0018897
[Epoch 11; Iter   180/ 2172] train: loss: 0.0019032
[Epoch 11; Iter   210/ 2172] train: loss: 0.0923545
[Epoch 11; Iter   240/ 2172] train: loss: 0.0011669
[Epoch 11; Iter   270/ 2172] train: loss: 0.0020283
[Epoch 11; Iter   300/ 2172] train: loss: 0.0021766
[Epoch 11; Iter   330/ 2172] train: loss: 0.0025405
[Epoch 11; Iter   360/ 2172] train: loss: 0.0019461
[Epoch 11; Iter   390/ 2172] train: loss: 0.0018013
[Epoch 11; Iter   420/ 2172] train: loss: 0.0042079
[Epoch 11; Iter   450/ 2172] train: loss: 0.0018695
[Epoch 11; Iter   480/ 2172] train: loss: 0.0033761
[Epoch 11; Iter   510/ 2172] train: loss: 0.0014217
[Epoch 11; Iter   540/ 2172] train: loss: 0.0018594
[Epoch 11; Iter   570/ 2172] train: loss: 0.0032073
[Epoch 11; Iter   600/ 2172] train: loss: 0.0034088
[Epoch 11; Iter   630/ 2172] train: loss: 0.0603940
[Epoch 11; Iter   660/ 2172] train: loss: 0.0024334
[Epoch 11; Iter   690/ 2172] train: loss: 0.0014071
[Epoch 11; Iter   720/ 2172] train: loss: 0.0703055
[Epoch 11; Iter   750/ 2172] train: loss: 0.0015038
[Epoch 11; Iter   780/ 2172] train: loss: 0.0710552
[Epoch 11; Iter   810/ 2172] train: loss: 0.0018795
[Epoch 11; Iter   840/ 2172] train: loss: 0.0028120
[Epoch 11; Iter   870/ 2172] train: loss: 0.0021860
[Epoch 11; Iter   900/ 2172] train: loss: 0.0019164
[Epoch 11; Iter   930/ 2172] train: loss: 0.0017977
[Epoch 11; Iter   960/ 2172] train: loss: 0.0742918
[Epoch 11; Iter   990/ 2172] train: loss: 0.0025891
[Epoch 11; Iter  1020/ 2172] train: loss: 0.0017158
[Epoch 11; Iter  1050/ 2172] train: loss: 0.0012969
[Epoch 11; Iter  1080/ 2172] train: loss: 0.0023405
[Epoch 11; Iter  1110/ 2172] train: loss: 0.0011912
[Epoch 11; Iter  1140/ 2172] train: loss: 0.0015134
[Epoch 11; Iter  1170/ 2172] train: loss: 0.0011753
[Epoch 11; Iter  1200/ 2172] train: loss: 0.0016033
[Epoch 11; Iter  1230/ 2172] train: loss: 0.0010916
[Epoch 11; Iter  1260/ 2172] train: loss: 0.0017191
[Epoch 11; Iter  1290/ 2172] train: loss: 0.0015410
[Epoch 11; Iter  1320/ 2172] train: loss: 0.0909657
[Epoch 11; Iter  1350/ 2172] train: loss: 0.0014838
[Epoch 11; Iter  1380/ 2172] train: loss: 0.0016896
[Epoch 11; Iter  1410/ 2172] train: loss: 0.0016422
[Epoch 11; Iter  1440/ 2172] train: loss: 0.0019312
[Epoch 11; Iter  1470/ 2172] train: loss: 0.0023627
[Epoch 11; Iter  1500/ 2172] train: loss: 0.0019047
[Epoch 11; Iter  1530/ 2172] train: loss: 0.0016013
[Epoch 11; Iter  1560/ 2172] train: loss: 0.1035027
[Epoch 11; Iter  1590/ 2172] train: loss: 0.0018402
[Epoch 11; Iter  1620/ 2172] train: loss: 0.0022900
[Epoch 11; Iter  1650/ 2172] train: loss: 0.0029197
[Epoch 11; Iter  1680/ 2172] train: loss: 0.0016550
[Epoch 11; Iter  1710/ 2172] train: loss: 0.0016878
[Epoch 11; Iter  1740/ 2172] train: loss: 0.0024953
[Epoch 11; Iter  1770/ 2172] train: loss: 0.0017077
[Epoch 11; Iter  1800/ 2172] train: loss: 0.0016884
[Epoch 11; Iter  1830/ 2172] train: loss: 0.0032147
[Epoch 11; Iter  1860/ 2172] train: loss: 0.0031840
[Epoch 11; Iter  1890/ 2172] train: loss: 0.0011544
[Epoch 11; Iter  1920/ 2172] train: loss: 0.0012364
[Epoch 11; Iter  1950/ 2172] train: loss: 0.0015120
[Epoch 11; Iter  1980/ 2172] train: loss: 0.0022240
[Epoch 11; Iter  2010/ 2172] train: loss: 0.0426442
[Epoch 11; Iter  2040/ 2172] train: loss: 0.0546079
[Epoch 11; Iter  2070/ 2172] train: loss: 0.0023665
[Epoch 11; Iter  2100/ 2172] train: loss: 0.0025166
[Epoch 11; Iter  2130/ 2172] train: loss: 0.0013421
[Epoch 11; Iter  2160/ 2172] train: loss: 0.0038016
[Epoch 11] ogbg-molmuv: 0.051571 val loss: 0.011485
[Epoch 11] ogbg-molmuv: 0.018006 test loss: 0.013422
[Epoch 12; Iter    18/ 2172] train: loss: 0.0018500
[Epoch 12; Iter    48/ 2172] train: loss: 0.0023212
[Epoch 12; Iter    78/ 2172] train: loss: 0.0383630
[Epoch 12; Iter   108/ 2172] train: loss: 0.0569335
[Epoch 12; Iter   138/ 2172] train: loss: 0.0027978
[Epoch 12; Iter   168/ 2172] train: loss: 0.0046934
[Epoch 12; Iter   198/ 2172] train: loss: 0.0019608
[Epoch 12; Iter   228/ 2172] train: loss: 0.0020646
[Epoch 12; Iter   258/ 2172] train: loss: 0.0233633
[Epoch 12; Iter   288/ 2172] train: loss: 0.0020234
[Epoch 12; Iter   318/ 2172] train: loss: 0.0022789
[Epoch 12; Iter   348/ 2172] train: loss: 0.0017358
[Epoch 12; Iter   378/ 2172] train: loss: 0.0016460
[Epoch 12; Iter   408/ 2172] train: loss: 0.0013521
[Epoch 12; Iter   438/ 2172] train: loss: 0.0020974
[Epoch 12; Iter   468/ 2172] train: loss: 0.0016312
[Epoch 12; Iter   498/ 2172] train: loss: 0.0023803
[Epoch 12; Iter   528/ 2172] train: loss: 0.0019652
[Epoch 12; Iter   558/ 2172] train: loss: 0.0035517
[Epoch 12; Iter   588/ 2172] train: loss: 0.0640723
[Epoch 12; Iter   618/ 2172] train: loss: 0.0024272
[Epoch 12; Iter   648/ 2172] train: loss: 0.1162375
[Epoch 12; Iter   678/ 2172] train: loss: 0.0023478
[Epoch 12; Iter   708/ 2172] train: loss: 0.0019469
[Epoch 12; Iter   738/ 2172] train: loss: 0.0019183
[Epoch 12; Iter   768/ 2172] train: loss: 0.0017862
[Epoch 12; Iter   798/ 2172] train: loss: 0.0024472
[Epoch 12; Iter   828/ 2172] train: loss: 0.0741617
[Epoch 12; Iter   858/ 2172] train: loss: 0.0013339
[Epoch 12; Iter   888/ 2172] train: loss: 0.0018419
[Epoch 12; Iter   918/ 2172] train: loss: 0.0027740
[Epoch 12; Iter   948/ 2172] train: loss: 0.0015254
[Epoch 12; Iter   978/ 2172] train: loss: 0.0026284
[Epoch 12; Iter  1008/ 2172] train: loss: 0.0018039
[Epoch 12; Iter  1038/ 2172] train: loss: 0.0015127
[Epoch 12; Iter  1068/ 2172] train: loss: 0.0017896
[Epoch 12; Iter  1098/ 2172] train: loss: 0.0011227
[Epoch 12; Iter  1128/ 2172] train: loss: 0.0019544
[Epoch 12; Iter  1158/ 2172] train: loss: 0.0017911
[Epoch 12; Iter  1188/ 2172] train: loss: 0.0025568
[Epoch 12; Iter  1218/ 2172] train: loss: 0.0359636
[Epoch 12; Iter  1248/ 2172] train: loss: 0.0020964
[Epoch 12; Iter  1278/ 2172] train: loss: 0.0658168
[Epoch 12; Iter  1308/ 2172] train: loss: 0.0013414
[Epoch 12; Iter  1338/ 2172] train: loss: 0.0015418
[Epoch 12; Iter  1368/ 2172] train: loss: 0.0019659
[Epoch 12; Iter  1398/ 2172] train: loss: 0.0028566
[Epoch 12; Iter  1428/ 2172] train: loss: 0.0013538
[Epoch 12; Iter  1458/ 2172] train: loss: 0.0016449
[Epoch 12; Iter  1488/ 2172] train: loss: 0.0722098
[Epoch 12; Iter  1518/ 2172] train: loss: 0.0024277
[Epoch 12; Iter  1548/ 2172] train: loss: 0.1081815
[Epoch 12; Iter  1578/ 2172] train: loss: 0.0024156
[Epoch 12; Iter  1608/ 2172] train: loss: 0.0013469
[Epoch 12; Iter  1638/ 2172] train: loss: 0.0015018
[Epoch 12; Iter  1668/ 2172] train: loss: 0.0021259
[Epoch 12; Iter  1698/ 2172] train: loss: 0.0017404
[Epoch 12; Iter  1728/ 2172] train: loss: 0.0026383
[Epoch 12; Iter  1758/ 2172] train: loss: 0.0023958
[Epoch 12; Iter  1788/ 2172] train: loss: 0.0021798
[Epoch 12; Iter  1818/ 2172] train: loss: 0.0013701
[Epoch 12; Iter  1848/ 2172] train: loss: 0.0483727
[Epoch 12; Iter  1878/ 2172] train: loss: 0.0038801
[Epoch 12; Iter  1908/ 2172] train: loss: 0.0013510
[Epoch 12; Iter  1938/ 2172] train: loss: 0.0022508
[Epoch 12; Iter  1968/ 2172] train: loss: 0.0019301
[Epoch 12; Iter  1998/ 2172] train: loss: 0.0016990
[Epoch 12; Iter  2028/ 2172] train: loss: 0.0016351
[Epoch 12; Iter  2058/ 2172] train: loss: 0.0854075
[Epoch 12; Iter  2088/ 2172] train: loss: 0.0549523
[Epoch 12; Iter  2118/ 2172] train: loss: 0.0020280
[Epoch 12; Iter  2148/ 2172] train: loss: 0.0015797
[Epoch 12] ogbg-molmuv: 0.037875 val loss: 0.014104
[Epoch 12] ogbg-molmuv: 0.041807 test loss: 0.013691
[Epoch 13; Iter     6/ 2172] train: loss: 0.0024281
[Epoch 13; Iter    36/ 2172] train: loss: 0.0638526
[Epoch 13; Iter    66/ 2172] train: loss: 0.0619977
[Epoch 13; Iter    96/ 2172] train: loss: 0.0025681
[Epoch 13; Iter   126/ 2172] train: loss: 0.0016164
[Epoch 13; Iter   156/ 2172] train: loss: 0.0018692
[Epoch 13; Iter   186/ 2172] train: loss: 0.0083237
[Epoch 13; Iter   216/ 2172] train: loss: 0.1071687
[Epoch 13; Iter   246/ 2172] train: loss: 0.0028701
[Epoch 13; Iter   276/ 2172] train: loss: 0.0027992
[Epoch 13; Iter   306/ 2172] train: loss: 0.0018426
[Epoch 13; Iter   336/ 2172] train: loss: 0.0028388
[Epoch 13; Iter   366/ 2172] train: loss: 0.0017959
[Epoch 11; Iter   150/ 2172] train: loss: 0.0020326
[Epoch 11; Iter   180/ 2172] train: loss: 0.0017018
[Epoch 11; Iter   210/ 2172] train: loss: 0.0037412
[Epoch 11; Iter   240/ 2172] train: loss: 0.0021872
[Epoch 11; Iter   270/ 2172] train: loss: 0.0023353
[Epoch 11; Iter   300/ 2172] train: loss: 0.0028403
[Epoch 11; Iter   330/ 2172] train: loss: 0.0026000
[Epoch 11; Iter   360/ 2172] train: loss: 0.0015155
[Epoch 11; Iter   390/ 2172] train: loss: 0.0025278
[Epoch 11; Iter   420/ 2172] train: loss: 0.0020467
[Epoch 11; Iter   450/ 2172] train: loss: 0.0021940
[Epoch 11; Iter   480/ 2172] train: loss: 0.0017944
[Epoch 11; Iter   510/ 2172] train: loss: 0.0017428
[Epoch 11; Iter   540/ 2172] train: loss: 0.0013750
[Epoch 11; Iter   570/ 2172] train: loss: 0.0854753
[Epoch 11; Iter   600/ 2172] train: loss: 0.0017860
[Epoch 11; Iter   630/ 2172] train: loss: 0.0014785
[Epoch 11; Iter   660/ 2172] train: loss: 0.0928094
[Epoch 11; Iter   690/ 2172] train: loss: 0.0014122
[Epoch 11; Iter   720/ 2172] train: loss: 0.0011589
[Epoch 11; Iter   750/ 2172] train: loss: 0.0016387
[Epoch 11; Iter   780/ 2172] train: loss: 0.0015968
[Epoch 11; Iter   810/ 2172] train: loss: 0.0017011
[Epoch 11; Iter   840/ 2172] train: loss: 0.0020928
[Epoch 11; Iter   870/ 2172] train: loss: 0.0027191
[Epoch 11; Iter   900/ 2172] train: loss: 0.0019451
[Epoch 11; Iter   930/ 2172] train: loss: 0.0015626
[Epoch 11; Iter   960/ 2172] train: loss: 0.0021741
[Epoch 11; Iter   990/ 2172] train: loss: 0.0020676
[Epoch 11; Iter  1020/ 2172] train: loss: 0.0021530
[Epoch 11; Iter  1050/ 2172] train: loss: 0.0015983
[Epoch 11; Iter  1080/ 2172] train: loss: 0.0016419
[Epoch 11; Iter  1110/ 2172] train: loss: 0.0015916
[Epoch 11; Iter  1140/ 2172] train: loss: 0.0026151
[Epoch 11; Iter  1170/ 2172] train: loss: 0.0818439
[Epoch 11; Iter  1200/ 2172] train: loss: 0.0018705
[Epoch 11; Iter  1230/ 2172] train: loss: 0.0762463
[Epoch 11; Iter  1260/ 2172] train: loss: 0.0016496
[Epoch 11; Iter  1290/ 2172] train: loss: 0.0017039
[Epoch 11; Iter  1320/ 2172] train: loss: 0.0017202
[Epoch 11; Iter  1350/ 2172] train: loss: 0.0019730
[Epoch 11; Iter  1380/ 2172] train: loss: 0.0014824
[Epoch 11; Iter  1410/ 2172] train: loss: 0.0021573
[Epoch 11; Iter  1440/ 2172] train: loss: 0.0012731
[Epoch 11; Iter  1470/ 2172] train: loss: 0.0021170
[Epoch 11; Iter  1500/ 2172] train: loss: 0.0014726
[Epoch 11; Iter  1530/ 2172] train: loss: 0.0012546
[Epoch 11; Iter  1560/ 2172] train: loss: 0.0018278
[Epoch 11; Iter  1590/ 2172] train: loss: 0.0017025
[Epoch 11; Iter  1620/ 2172] train: loss: 0.0775705
[Epoch 11; Iter  1650/ 2172] train: loss: 0.0020512
[Epoch 11; Iter  1680/ 2172] train: loss: 0.0019507
[Epoch 11; Iter  1710/ 2172] train: loss: 0.0018859
[Epoch 11; Iter  1740/ 2172] train: loss: 0.0017239
[Epoch 11; Iter  1770/ 2172] train: loss: 0.0022631
[Epoch 11; Iter  1800/ 2172] train: loss: 0.0029886
[Epoch 11; Iter  1830/ 2172] train: loss: 0.0754123
[Epoch 11; Iter  1860/ 2172] train: loss: 0.0021286
[Epoch 11; Iter  1890/ 2172] train: loss: 0.0016298
[Epoch 11; Iter  1920/ 2172] train: loss: 0.0021379
[Epoch 11; Iter  1950/ 2172] train: loss: 0.0017987
[Epoch 11; Iter  1980/ 2172] train: loss: 0.0021095
[Epoch 11; Iter  2010/ 2172] train: loss: 0.0029297
[Epoch 11; Iter  2040/ 2172] train: loss: 0.0018690
[Epoch 11; Iter  2070/ 2172] train: loss: 0.0494612
[Epoch 11; Iter  2100/ 2172] train: loss: 0.0021506
[Epoch 11; Iter  2130/ 2172] train: loss: 0.0017031
[Epoch 11; Iter  2160/ 2172] train: loss: 0.0558201
[Epoch 11] ogbg-molmuv: 0.010248 val loss: 0.012522
[Epoch 11] ogbg-molmuv: 0.011596 test loss: 0.014420
[Epoch 12; Iter    18/ 2172] train: loss: 0.0015850
[Epoch 12; Iter    48/ 2172] train: loss: 0.0016666
[Epoch 12; Iter    78/ 2172] train: loss: 0.0015390
[Epoch 12; Iter   108/ 2172] train: loss: 0.0028803
[Epoch 12; Iter   138/ 2172] train: loss: 0.0020353
[Epoch 12; Iter   168/ 2172] train: loss: 0.0020047
[Epoch 12; Iter   198/ 2172] train: loss: 0.0023676
[Epoch 12; Iter   228/ 2172] train: loss: 0.0021345
[Epoch 12; Iter   258/ 2172] train: loss: 0.0028877
[Epoch 12; Iter   288/ 2172] train: loss: 0.0023702
[Epoch 12; Iter   318/ 2172] train: loss: 0.0020031
[Epoch 12; Iter   348/ 2172] train: loss: 0.0025985
[Epoch 12; Iter   378/ 2172] train: loss: 0.0014720
[Epoch 12; Iter   408/ 2172] train: loss: 0.0013110
[Epoch 12; Iter   438/ 2172] train: loss: 0.0017453
[Epoch 12; Iter   468/ 2172] train: loss: 0.0020044
[Epoch 12; Iter   498/ 2172] train: loss: 0.0024894
[Epoch 12; Iter   528/ 2172] train: loss: 0.0015509
[Epoch 12; Iter   558/ 2172] train: loss: 0.0017741
[Epoch 12; Iter   588/ 2172] train: loss: 0.0017976
[Epoch 12; Iter   618/ 2172] train: loss: 0.0018962
[Epoch 12; Iter   648/ 2172] train: loss: 0.0016760
[Epoch 12; Iter   678/ 2172] train: loss: 0.0018637
[Epoch 12; Iter   708/ 2172] train: loss: 0.0369684
[Epoch 12; Iter   738/ 2172] train: loss: 0.0024473
[Epoch 12; Iter   768/ 2172] train: loss: 0.0019990
[Epoch 12; Iter   798/ 2172] train: loss: 0.0018990
[Epoch 12; Iter   828/ 2172] train: loss: 0.0020593
[Epoch 12; Iter   858/ 2172] train: loss: 0.0015031
[Epoch 12; Iter   888/ 2172] train: loss: 0.0023385
[Epoch 12; Iter   918/ 2172] train: loss: 0.0027380
[Epoch 12; Iter   948/ 2172] train: loss: 0.0016654
[Epoch 12; Iter   978/ 2172] train: loss: 0.0014743
[Epoch 12; Iter  1008/ 2172] train: loss: 0.0027320
[Epoch 12; Iter  1038/ 2172] train: loss: 0.0013901
[Epoch 12; Iter  1068/ 2172] train: loss: 0.0015945
[Epoch 12; Iter  1098/ 2172] train: loss: 0.0775192
[Epoch 12; Iter  1128/ 2172] train: loss: 0.0014922
[Epoch 12; Iter  1158/ 2172] train: loss: 0.0017246
[Epoch 12; Iter  1188/ 2172] train: loss: 0.0015988
[Epoch 12; Iter  1218/ 2172] train: loss: 0.0021619
[Epoch 12; Iter  1248/ 2172] train: loss: 0.0026522
[Epoch 12; Iter  1278/ 2172] train: loss: 0.0024365
[Epoch 12; Iter  1308/ 2172] train: loss: 0.0012266
[Epoch 12; Iter  1338/ 2172] train: loss: 0.0019981
[Epoch 12; Iter  1368/ 2172] train: loss: 0.0020690
[Epoch 12; Iter  1398/ 2172] train: loss: 0.0014821
[Epoch 12; Iter  1428/ 2172] train: loss: 0.0016233
[Epoch 12; Iter  1458/ 2172] train: loss: 0.0018288
[Epoch 12; Iter  1488/ 2172] train: loss: 0.0034137
[Epoch 12; Iter  1518/ 2172] train: loss: 0.0018026
[Epoch 12; Iter  1548/ 2172] train: loss: 0.0021978
[Epoch 12; Iter  1578/ 2172] train: loss: 0.0018363
[Epoch 12; Iter  1608/ 2172] train: loss: 0.0013083
[Epoch 12; Iter  1638/ 2172] train: loss: 0.0613256
[Epoch 12; Iter  1668/ 2172] train: loss: 0.0035371
[Epoch 12; Iter  1698/ 2172] train: loss: 0.0835795
[Epoch 12; Iter  1728/ 2172] train: loss: 0.0019849
[Epoch 12; Iter  1758/ 2172] train: loss: 0.0718613
[Epoch 12; Iter  1788/ 2172] train: loss: 0.0017882
[Epoch 12; Iter  1818/ 2172] train: loss: 0.0028025
[Epoch 12; Iter  1848/ 2172] train: loss: 0.0025273
[Epoch 12; Iter  1878/ 2172] train: loss: 0.0019528
[Epoch 12; Iter  1908/ 2172] train: loss: 0.0018106
[Epoch 12; Iter  1938/ 2172] train: loss: 0.0018033
[Epoch 12; Iter  1968/ 2172] train: loss: 0.0029515
[Epoch 12; Iter  1998/ 2172] train: loss: 0.0030188
[Epoch 12; Iter  2028/ 2172] train: loss: 0.0024879
[Epoch 12; Iter  2058/ 2172] train: loss: 0.0017618
[Epoch 12; Iter  2088/ 2172] train: loss: 0.0018298
[Epoch 12; Iter  2118/ 2172] train: loss: 0.0017946
[Epoch 12; Iter  2148/ 2172] train: loss: 0.0016477
[Epoch 12] ogbg-molmuv: 0.015254 val loss: 0.014564
[Epoch 12] ogbg-molmuv: 0.024946 test loss: 0.017246
[Epoch 13; Iter     6/ 2172] train: loss: 0.0016079
[Epoch 13; Iter    36/ 2172] train: loss: 0.0016826
[Epoch 13; Iter    66/ 2172] train: loss: 0.0019617
[Epoch 13; Iter    96/ 2172] train: loss: 0.0708999
[Epoch 13; Iter   126/ 2172] train: loss: 0.0034853
[Epoch 13; Iter   156/ 2172] train: loss: 0.0024073
[Epoch 13; Iter   186/ 2172] train: loss: 0.0022263
[Epoch 13; Iter   216/ 2172] train: loss: 0.0021680
[Epoch 13; Iter   246/ 2172] train: loss: 0.0022425
[Epoch 13; Iter   276/ 2172] train: loss: 0.0022646
[Epoch 13; Iter   306/ 2172] train: loss: 0.0015653
[Epoch 13; Iter   336/ 2172] train: loss: 0.0024167
[Epoch 13; Iter   366/ 2172] train: loss: 0.0024456
[Epoch 11; Iter   150/ 2172] train: loss: 0.0017234
[Epoch 11; Iter   180/ 2172] train: loss: 0.0030828
[Epoch 11; Iter   210/ 2172] train: loss: 0.1107908
[Epoch 11; Iter   240/ 2172] train: loss: 0.0532178
[Epoch 11; Iter   270/ 2172] train: loss: 0.0021955
[Epoch 11; Iter   300/ 2172] train: loss: 0.0017639
[Epoch 11; Iter   330/ 2172] train: loss: 0.0018418
[Epoch 11; Iter   360/ 2172] train: loss: 0.0710863
[Epoch 11; Iter   390/ 2172] train: loss: 0.0021616
[Epoch 11; Iter   420/ 2172] train: loss: 0.0012945
[Epoch 11; Iter   450/ 2172] train: loss: 0.0016785
[Epoch 11; Iter   480/ 2172] train: loss: 0.0025765
[Epoch 11; Iter   510/ 2172] train: loss: 0.0022592
[Epoch 11; Iter   540/ 2172] train: loss: 0.1155163
[Epoch 11; Iter   570/ 2172] train: loss: 0.0021918
[Epoch 11; Iter   600/ 2172] train: loss: 0.0020280
[Epoch 11; Iter   630/ 2172] train: loss: 0.0014936
[Epoch 11; Iter   660/ 2172] train: loss: 0.0013049
[Epoch 11; Iter   690/ 2172] train: loss: 0.0756847
[Epoch 11; Iter   720/ 2172] train: loss: 0.0018334
[Epoch 11; Iter   750/ 2172] train: loss: 0.0027722
[Epoch 11; Iter   780/ 2172] train: loss: 0.0036930
[Epoch 11; Iter   810/ 2172] train: loss: 0.0047920
[Epoch 11; Iter   840/ 2172] train: loss: 0.0515327
[Epoch 11; Iter   870/ 2172] train: loss: 0.0020820
[Epoch 11; Iter   900/ 2172] train: loss: 0.0016209
[Epoch 11; Iter   930/ 2172] train: loss: 0.0017538
[Epoch 11; Iter   960/ 2172] train: loss: 0.0017915
[Epoch 11; Iter   990/ 2172] train: loss: 0.0021988
[Epoch 11; Iter  1020/ 2172] train: loss: 0.0031549
[Epoch 11; Iter  1050/ 2172] train: loss: 0.0021350
[Epoch 11; Iter  1080/ 2172] train: loss: 0.0026464
[Epoch 11; Iter  1110/ 2172] train: loss: 0.0019635
[Epoch 11; Iter  1140/ 2172] train: loss: 0.0018221
[Epoch 11; Iter  1170/ 2172] train: loss: 0.0024886
[Epoch 11; Iter  1200/ 2172] train: loss: 0.0025221
[Epoch 11; Iter  1230/ 2172] train: loss: 0.0865494
[Epoch 11; Iter  1260/ 2172] train: loss: 0.0502191
[Epoch 11; Iter  1290/ 2172] train: loss: 0.0020176
[Epoch 11; Iter  1320/ 2172] train: loss: 0.0019078
[Epoch 11; Iter  1350/ 2172] train: loss: 0.0019969
[Epoch 11; Iter  1380/ 2172] train: loss: 0.0017737
[Epoch 11; Iter  1410/ 2172] train: loss: 0.0017184
[Epoch 11; Iter  1440/ 2172] train: loss: 0.0014105
[Epoch 11; Iter  1470/ 2172] train: loss: 0.0013291
[Epoch 11; Iter  1500/ 2172] train: loss: 0.0014756
[Epoch 11; Iter  1530/ 2172] train: loss: 0.0013715
[Epoch 11; Iter  1560/ 2172] train: loss: 0.0019910
[Epoch 11; Iter  1590/ 2172] train: loss: 0.0020301
[Epoch 11; Iter  1620/ 2172] train: loss: 0.0022321
[Epoch 11; Iter  1650/ 2172] train: loss: 0.0010802
[Epoch 11; Iter  1680/ 2172] train: loss: 0.0017051
[Epoch 11; Iter  1710/ 2172] train: loss: 0.0014326
[Epoch 11; Iter  1740/ 2172] train: loss: 0.0012671
[Epoch 11; Iter  1770/ 2172] train: loss: 0.0018735
[Epoch 11; Iter  1800/ 2172] train: loss: 0.0015515
[Epoch 11; Iter  1830/ 2172] train: loss: 0.0024074
[Epoch 11; Iter  1860/ 2172] train: loss: 0.0026799
[Epoch 11; Iter  1890/ 2172] train: loss: 0.0022303
[Epoch 11; Iter  1920/ 2172] train: loss: 0.0016554
[Epoch 11; Iter  1950/ 2172] train: loss: 0.0021402
[Epoch 11; Iter  1980/ 2172] train: loss: 0.0016468
[Epoch 11; Iter  2010/ 2172] train: loss: 0.0646170
[Epoch 11; Iter  2040/ 2172] train: loss: 0.0028559
[Epoch 11; Iter  2070/ 2172] train: loss: 0.0016613
[Epoch 11; Iter  2100/ 2172] train: loss: 0.1303670
[Epoch 11; Iter  2130/ 2172] train: loss: 0.0571320
[Epoch 11; Iter  2160/ 2172] train: loss: 0.0012498
[Epoch 11] ogbg-molmuv: 0.018784 val loss: 0.012295
[Epoch 11] ogbg-molmuv: 0.039439 test loss: 0.014082
[Epoch 12; Iter    18/ 2172] train: loss: 0.0024667
[Epoch 12; Iter    48/ 2172] train: loss: 0.0024840
[Epoch 12; Iter    78/ 2172] train: loss: 0.0014766
[Epoch 12; Iter   108/ 2172] train: loss: 0.0015921
[Epoch 12; Iter   138/ 2172] train: loss: 0.0021097
[Epoch 12; Iter   168/ 2172] train: loss: 0.0035660
[Epoch 12; Iter   198/ 2172] train: loss: 0.0015373
[Epoch 12; Iter   228/ 2172] train: loss: 0.0020493
[Epoch 12; Iter   258/ 2172] train: loss: 0.0011847
[Epoch 12; Iter   288/ 2172] train: loss: 0.0014807
[Epoch 12; Iter   318/ 2172] train: loss: 0.0017534
[Epoch 12; Iter   348/ 2172] train: loss: 0.0022180
[Epoch 12; Iter   378/ 2172] train: loss: 0.0016136
[Epoch 12; Iter   408/ 2172] train: loss: 0.0018116
[Epoch 12; Iter   438/ 2172] train: loss: 0.0016935
[Epoch 12; Iter   468/ 2172] train: loss: 0.0022515
[Epoch 12; Iter   498/ 2172] train: loss: 0.0014330
[Epoch 12; Iter   528/ 2172] train: loss: 0.0842097
[Epoch 12; Iter   558/ 2172] train: loss: 0.0019429
[Epoch 12; Iter   588/ 2172] train: loss: 0.0026780
[Epoch 12; Iter   618/ 2172] train: loss: 0.0020839
[Epoch 12; Iter   648/ 2172] train: loss: 0.0641402
[Epoch 12; Iter   678/ 2172] train: loss: 0.0031980
[Epoch 12; Iter   708/ 2172] train: loss: 0.0015956
[Epoch 12; Iter   738/ 2172] train: loss: 0.0017151
[Epoch 12; Iter   768/ 2172] train: loss: 0.0020291
[Epoch 12; Iter   798/ 2172] train: loss: 0.0022362
[Epoch 12; Iter   828/ 2172] train: loss: 0.0017758
[Epoch 12; Iter   858/ 2172] train: loss: 0.0020572
[Epoch 12; Iter   888/ 2172] train: loss: 0.0020743
[Epoch 12; Iter   918/ 2172] train: loss: 0.0022910
[Epoch 12; Iter   948/ 2172] train: loss: 0.0025132
[Epoch 12; Iter   978/ 2172] train: loss: 0.0016392
[Epoch 12; Iter  1008/ 2172] train: loss: 0.0023549
[Epoch 12; Iter  1038/ 2172] train: loss: 0.0017104
[Epoch 12; Iter  1068/ 2172] train: loss: 0.0013501
[Epoch 12; Iter  1098/ 2172] train: loss: 0.0652799
[Epoch 12; Iter  1128/ 2172] train: loss: 0.0713752
[Epoch 12; Iter  1158/ 2172] train: loss: 0.0018998
[Epoch 12; Iter  1188/ 2172] train: loss: 0.0019426
[Epoch 12; Iter  1218/ 2172] train: loss: 0.0015888
[Epoch 12; Iter  1248/ 2172] train: loss: 0.0025774
[Epoch 12; Iter  1278/ 2172] train: loss: 0.0021133
[Epoch 12; Iter  1308/ 2172] train: loss: 0.0012969
[Epoch 12; Iter  1338/ 2172] train: loss: 0.0033231
[Epoch 12; Iter  1368/ 2172] train: loss: 0.0015686
[Epoch 12; Iter  1398/ 2172] train: loss: 0.0022435
[Epoch 12; Iter  1428/ 2172] train: loss: 0.0026205
[Epoch 12; Iter  1458/ 2172] train: loss: 0.0020273
[Epoch 12; Iter  1488/ 2172] train: loss: 0.0023321
[Epoch 12; Iter  1518/ 2172] train: loss: 0.0013219
[Epoch 12; Iter  1548/ 2172] train: loss: 0.0020458
[Epoch 12; Iter  1578/ 2172] train: loss: 0.0023331
[Epoch 12; Iter  1608/ 2172] train: loss: 0.0023330
[Epoch 12; Iter  1638/ 2172] train: loss: 0.0025695
[Epoch 12; Iter  1668/ 2172] train: loss: 0.0799222
[Epoch 12; Iter  1698/ 2172] train: loss: 0.0899281
[Epoch 12; Iter  1728/ 2172] train: loss: 0.0014643
[Epoch 12; Iter  1758/ 2172] train: loss: 0.0799895
[Epoch 12; Iter  1788/ 2172] train: loss: 0.0019350
[Epoch 12; Iter  1818/ 2172] train: loss: 0.0011320
[Epoch 12; Iter  1848/ 2172] train: loss: 0.0011428
[Epoch 12; Iter  1878/ 2172] train: loss: 0.0016694
[Epoch 12; Iter  1908/ 2172] train: loss: 0.0689481
[Epoch 12; Iter  1938/ 2172] train: loss: 0.0017556
[Epoch 12; Iter  1968/ 2172] train: loss: 0.0018838
[Epoch 12; Iter  1998/ 2172] train: loss: 0.0698885
[Epoch 12; Iter  2028/ 2172] train: loss: 0.0021908
[Epoch 12; Iter  2058/ 2172] train: loss: 0.0024632
[Epoch 12; Iter  2088/ 2172] train: loss: 0.0015874
[Epoch 12; Iter  2118/ 2172] train: loss: 0.0036008
[Epoch 12; Iter  2148/ 2172] train: loss: 0.0034242
[Epoch 12] ogbg-molmuv: 0.027236 val loss: 0.012036
[Epoch 12] ogbg-molmuv: 0.043403 test loss: 0.013350
[Epoch 13; Iter     6/ 2172] train: loss: 0.0711709
[Epoch 13; Iter    36/ 2172] train: loss: 0.0031984
[Epoch 13; Iter    66/ 2172] train: loss: 0.0021188
[Epoch 13; Iter    96/ 2172] train: loss: 0.0036585
[Epoch 13; Iter   126/ 2172] train: loss: 0.0015696
[Epoch 13; Iter   156/ 2172] train: loss: 0.0024997
[Epoch 13; Iter   186/ 2172] train: loss: 0.0015432
[Epoch 13; Iter   216/ 2172] train: loss: 0.0013792
[Epoch 13; Iter   246/ 2172] train: loss: 0.0016967
[Epoch 13; Iter   276/ 2172] train: loss: 0.0029883
[Epoch 13; Iter   306/ 2172] train: loss: 0.0015421
[Epoch 13; Iter   336/ 2172] train: loss: 0.0784482
[Epoch 13; Iter   366/ 2172] train: loss: 0.0017039
[Epoch 11; Iter  1780/ 2483] train: loss: 0.0016280
[Epoch 11; Iter  1810/ 2483] train: loss: 0.0024424
[Epoch 11; Iter  1840/ 2483] train: loss: 0.0030277
[Epoch 11; Iter  1870/ 2483] train: loss: 0.0642965
[Epoch 11; Iter  1900/ 2483] train: loss: 0.0017520
[Epoch 11; Iter  1930/ 2483] train: loss: 0.0027817
[Epoch 11; Iter  1960/ 2483] train: loss: 0.0029911
[Epoch 11; Iter  1990/ 2483] train: loss: 0.0026092
[Epoch 11; Iter  2020/ 2483] train: loss: 0.0022133
[Epoch 11; Iter  2050/ 2483] train: loss: 0.0022625
[Epoch 11; Iter  2080/ 2483] train: loss: 0.0020954
[Epoch 11; Iter  2110/ 2483] train: loss: 0.0018059
[Epoch 11; Iter  2140/ 2483] train: loss: 0.0026222
[Epoch 11; Iter  2170/ 2483] train: loss: 0.0023686
[Epoch 11; Iter  2200/ 2483] train: loss: 0.1672036
[Epoch 11; Iter  2230/ 2483] train: loss: 0.0016522
[Epoch 11; Iter  2260/ 2483] train: loss: 0.0018223
[Epoch 11; Iter  2290/ 2483] train: loss: 0.0025422
[Epoch 11; Iter  2320/ 2483] train: loss: 0.0024566
[Epoch 11; Iter  2350/ 2483] train: loss: 0.0023033
[Epoch 11; Iter  2380/ 2483] train: loss: 0.0021477
[Epoch 11; Iter  2410/ 2483] train: loss: 0.0022334
[Epoch 11; Iter  2440/ 2483] train: loss: 0.0018271
[Epoch 11; Iter  2470/ 2483] train: loss: 0.0015771
[Epoch 11] ogbg-molmuv: 0.029629 val loss: 0.010044
[Epoch 11] ogbg-molmuv: 0.035074 test loss: 0.014452
[Epoch 12; Iter    17/ 2483] train: loss: 0.0015941
[Epoch 12; Iter    47/ 2483] train: loss: 0.0016895
[Epoch 12; Iter    77/ 2483] train: loss: 0.0015892
[Epoch 12; Iter   107/ 2483] train: loss: 0.0016986
[Epoch 12; Iter   137/ 2483] train: loss: 0.0015559
[Epoch 12; Iter   167/ 2483] train: loss: 0.0014401
[Epoch 12; Iter   197/ 2483] train: loss: 0.0014522
[Epoch 12; Iter   227/ 2483] train: loss: 0.0015795
[Epoch 12; Iter   257/ 2483] train: loss: 0.0698099
[Epoch 12; Iter   287/ 2483] train: loss: 0.0018525
[Epoch 12; Iter   317/ 2483] train: loss: 0.0012524
[Epoch 12; Iter   347/ 2483] train: loss: 0.0013322
[Epoch 12; Iter   377/ 2483] train: loss: 0.0729960
[Epoch 12; Iter   407/ 2483] train: loss: 0.0023993
[Epoch 12; Iter   437/ 2483] train: loss: 0.0019043
[Epoch 12; Iter   467/ 2483] train: loss: 0.0023796
[Epoch 12; Iter   497/ 2483] train: loss: 0.0023348
[Epoch 12; Iter   527/ 2483] train: loss: 0.0032091
[Epoch 12; Iter   557/ 2483] train: loss: 0.0021203
[Epoch 12; Iter   587/ 2483] train: loss: 0.0017070
[Epoch 12; Iter   617/ 2483] train: loss: 0.0017724
[Epoch 12; Iter   647/ 2483] train: loss: 0.0015830
[Epoch 12; Iter   677/ 2483] train: loss: 0.0013100
[Epoch 12; Iter   707/ 2483] train: loss: 0.0888560
[Epoch 12; Iter   737/ 2483] train: loss: 0.0020677
[Epoch 12; Iter   767/ 2483] train: loss: 0.0025243
[Epoch 12; Iter   797/ 2483] train: loss: 0.0017010
[Epoch 12; Iter   827/ 2483] train: loss: 0.0013871
[Epoch 12; Iter   857/ 2483] train: loss: 0.0016687
[Epoch 12; Iter   887/ 2483] train: loss: 0.0030659
[Epoch 12; Iter   917/ 2483] train: loss: 0.0021932
[Epoch 12; Iter   947/ 2483] train: loss: 0.0031283
[Epoch 12; Iter   977/ 2483] train: loss: 0.0023984
[Epoch 12; Iter  1007/ 2483] train: loss: 0.0020609
[Epoch 12; Iter  1037/ 2483] train: loss: 0.0020800
[Epoch 12; Iter  1067/ 2483] train: loss: 0.0030380
[Epoch 12; Iter  1097/ 2483] train: loss: 0.0021622
[Epoch 12; Iter  1127/ 2483] train: loss: 0.0029526
[Epoch 12; Iter  1157/ 2483] train: loss: 0.0018871
[Epoch 12; Iter  1187/ 2483] train: loss: 0.0016230
[Epoch 12; Iter  1217/ 2483] train: loss: 0.0015106
[Epoch 12; Iter  1247/ 2483] train: loss: 0.0834156
[Epoch 12; Iter  1277/ 2483] train: loss: 0.0017943
[Epoch 12; Iter  1307/ 2483] train: loss: 0.0026244
[Epoch 12; Iter  1337/ 2483] train: loss: 0.0021965
[Epoch 12; Iter  1367/ 2483] train: loss: 0.0016901
[Epoch 12; Iter  1397/ 2483] train: loss: 0.0015293
[Epoch 12; Iter  1427/ 2483] train: loss: 0.0017290
[Epoch 12; Iter  1457/ 2483] train: loss: 0.0012705
[Epoch 12; Iter  1487/ 2483] train: loss: 0.0030767
[Epoch 12; Iter  1517/ 2483] train: loss: 0.0019939
[Epoch 12; Iter  1547/ 2483] train: loss: 0.0364370
[Epoch 12; Iter  1577/ 2483] train: loss: 0.0021635
[Epoch 12; Iter  1607/ 2483] train: loss: 0.0015862
[Epoch 12; Iter  1637/ 2483] train: loss: 0.0016730
[Epoch 12; Iter  1667/ 2483] train: loss: 0.0010970
[Epoch 12; Iter  1697/ 2483] train: loss: 0.0531152
[Epoch 12; Iter  1727/ 2483] train: loss: 0.0736730
[Epoch 12; Iter  1757/ 2483] train: loss: 0.0013588
[Epoch 12; Iter  1787/ 2483] train: loss: 0.1264184
[Epoch 12; Iter  1817/ 2483] train: loss: 0.0015975
[Epoch 12; Iter  1847/ 2483] train: loss: 0.0017533
[Epoch 12; Iter  1877/ 2483] train: loss: 0.0014828
[Epoch 12; Iter  1907/ 2483] train: loss: 0.0011240
[Epoch 12; Iter  1937/ 2483] train: loss: 0.0011647
[Epoch 12; Iter  1967/ 2483] train: loss: 0.0018223
[Epoch 12; Iter  1997/ 2483] train: loss: 0.0016199
[Epoch 12; Iter  2027/ 2483] train: loss: 0.0020988
[Epoch 12; Iter  2057/ 2483] train: loss: 0.1419712
[Epoch 12; Iter  2087/ 2483] train: loss: 0.0020548
[Epoch 12; Iter  2117/ 2483] train: loss: 0.0019642
[Epoch 12; Iter  2147/ 2483] train: loss: 0.0016978
[Epoch 12; Iter  2177/ 2483] train: loss: 0.0012111
[Epoch 12; Iter  2207/ 2483] train: loss: 0.0543337
[Epoch 12; Iter  2237/ 2483] train: loss: 0.0014663
[Epoch 12; Iter  2267/ 2483] train: loss: 0.0719994
[Epoch 12; Iter  2297/ 2483] train: loss: 0.0020521
[Epoch 12; Iter  2327/ 2483] train: loss: 0.0022816
[Epoch 12; Iter  2357/ 2483] train: loss: 0.0620204
[Epoch 12; Iter  2387/ 2483] train: loss: 0.0024514
[Epoch 12; Iter  2417/ 2483] train: loss: 0.0019615
[Epoch 12; Iter  2447/ 2483] train: loss: 0.0829412
[Epoch 12; Iter  2477/ 2483] train: loss: 0.0021647
[Epoch 12] ogbg-molmuv: 0.090214 val loss: 0.022499
[Epoch 12] ogbg-molmuv: 0.024448 test loss: 0.014375
[Epoch 13; Iter    24/ 2483] train: loss: 0.0020727
[Epoch 13; Iter    54/ 2483] train: loss: 0.0023352
[Epoch 13; Iter    84/ 2483] train: loss: 0.0027583
[Epoch 13; Iter   114/ 2483] train: loss: 0.0021876
[Epoch 13; Iter   144/ 2483] train: loss: 0.0018535
[Epoch 13; Iter   174/ 2483] train: loss: 0.0041203
[Epoch 13; Iter   204/ 2483] train: loss: 0.0024203
[Epoch 13; Iter   234/ 2483] train: loss: 0.0034502
[Epoch 13; Iter   264/ 2483] train: loss: 0.0032060
[Epoch 13; Iter   294/ 2483] train: loss: 0.0612402
[Epoch 13; Iter   324/ 2483] train: loss: 0.0045193
[Epoch 13; Iter   354/ 2483] train: loss: 0.0931903
[Epoch 13; Iter   384/ 2483] train: loss: 0.0020120
[Epoch 13; Iter   414/ 2483] train: loss: 0.0841137
[Epoch 13; Iter   444/ 2483] train: loss: 0.0018306
[Epoch 13; Iter   474/ 2483] train: loss: 0.0031184
[Epoch 13; Iter   504/ 2483] train: loss: 0.0513761
[Epoch 13; Iter   534/ 2483] train: loss: 0.0027897
[Epoch 13; Iter   564/ 2483] train: loss: 0.0036210
[Epoch 13; Iter   594/ 2483] train: loss: 0.0018895
[Epoch 13; Iter   624/ 2483] train: loss: 0.0022001
[Epoch 13; Iter   654/ 2483] train: loss: 0.0031382
[Epoch 13; Iter   684/ 2483] train: loss: 0.0693884
[Epoch 13; Iter   714/ 2483] train: loss: 0.0731968
[Epoch 13; Iter   744/ 2483] train: loss: 0.0016682
[Epoch 13; Iter   774/ 2483] train: loss: 0.0021845
[Epoch 13; Iter   804/ 2483] train: loss: 0.0017253
[Epoch 13; Iter   834/ 2483] train: loss: 0.0017196
[Epoch 13; Iter   864/ 2483] train: loss: 0.0017370
[Epoch 13; Iter   894/ 2483] train: loss: 0.0012026
[Epoch 13; Iter   924/ 2483] train: loss: 0.0011410
[Epoch 13; Iter   954/ 2483] train: loss: 0.0017591
[Epoch 13; Iter   984/ 2483] train: loss: 0.0016286
[Epoch 13; Iter  1014/ 2483] train: loss: 0.0015831
[Epoch 13; Iter  1044/ 2483] train: loss: 0.0015430
[Epoch 13; Iter  1074/ 2483] train: loss: 0.0566850
[Epoch 13; Iter  1104/ 2483] train: loss: 0.0016369
[Epoch 13; Iter  1134/ 2483] train: loss: 0.0014534
[Epoch 13; Iter  1164/ 2483] train: loss: 0.0012229
[Epoch 13; Iter  1194/ 2483] train: loss: 0.0012161
[Epoch 13; Iter  1224/ 2483] train: loss: 0.0021106
[Epoch 13; Iter  1254/ 2483] train: loss: 0.0017192
[Epoch 13; Iter  1284/ 2483] train: loss: 0.0016958
[Epoch 13; Iter  1314/ 2483] train: loss: 0.0720577
[Epoch 13; Iter  1344/ 2483] train: loss: 0.1593666
[Epoch 13; Iter  1374/ 2483] train: loss: 0.0013561
[Epoch 11; Iter  1780/ 2483] train: loss: 0.0015460
[Epoch 11; Iter  1810/ 2483] train: loss: 0.0015994
[Epoch 11; Iter  1840/ 2483] train: loss: 0.0017665
[Epoch 11; Iter  1870/ 2483] train: loss: 0.0024020
[Epoch 11; Iter  1900/ 2483] train: loss: 0.0013695
[Epoch 11; Iter  1930/ 2483] train: loss: 0.0012804
[Epoch 11; Iter  1960/ 2483] train: loss: 0.1344810
[Epoch 11; Iter  1990/ 2483] train: loss: 0.0023308
[Epoch 11; Iter  2020/ 2483] train: loss: 0.0030360
[Epoch 11; Iter  2050/ 2483] train: loss: 0.0027920
[Epoch 11; Iter  2080/ 2483] train: loss: 0.0062684
[Epoch 11; Iter  2110/ 2483] train: loss: 0.0681155
[Epoch 11; Iter  2140/ 2483] train: loss: 0.0741099
[Epoch 11; Iter  2170/ 2483] train: loss: 0.0019877
[Epoch 11; Iter  2200/ 2483] train: loss: 0.0025183
[Epoch 11; Iter  2230/ 2483] train: loss: 0.0031730
[Epoch 11; Iter  2260/ 2483] train: loss: 0.0022999
[Epoch 11; Iter  2290/ 2483] train: loss: 0.0014786
[Epoch 11; Iter  2320/ 2483] train: loss: 0.0018531
[Epoch 11; Iter  2350/ 2483] train: loss: 0.0018628
[Epoch 11; Iter  2380/ 2483] train: loss: 0.0726310
[Epoch 11; Iter  2410/ 2483] train: loss: 0.0014401
[Epoch 11; Iter  2440/ 2483] train: loss: 0.0020543
[Epoch 11; Iter  2470/ 2483] train: loss: 0.0692144
[Epoch 11] ogbg-molmuv: 0.041345 val loss: 0.011757
[Epoch 11] ogbg-molmuv: 0.031113 test loss: 0.017512
[Epoch 12; Iter    17/ 2483] train: loss: 0.0018452
[Epoch 12; Iter    47/ 2483] train: loss: 0.0015529
[Epoch 12; Iter    77/ 2483] train: loss: 0.0014998
[Epoch 12; Iter   107/ 2483] train: loss: 0.0037007
[Epoch 12; Iter   137/ 2483] train: loss: 0.0017518
[Epoch 12; Iter   167/ 2483] train: loss: 0.0014593
[Epoch 12; Iter   197/ 2483] train: loss: 0.0015356
[Epoch 12; Iter   227/ 2483] train: loss: 0.0013829
[Epoch 12; Iter   257/ 2483] train: loss: 0.0019672
[Epoch 12; Iter   287/ 2483] train: loss: 0.0013056
[Epoch 12; Iter   317/ 2483] train: loss: 0.0018642
[Epoch 12; Iter   347/ 2483] train: loss: 0.0012379
[Epoch 12; Iter   377/ 2483] train: loss: 0.0017075
[Epoch 12; Iter   407/ 2483] train: loss: 0.0025100
[Epoch 12; Iter   437/ 2483] train: loss: 0.0024245
[Epoch 12; Iter   467/ 2483] train: loss: 0.0017412
[Epoch 12; Iter   497/ 2483] train: loss: 0.0010662
[Epoch 12; Iter   527/ 2483] train: loss: 0.0023788
[Epoch 12; Iter   557/ 2483] train: loss: 0.0018192
[Epoch 12; Iter   587/ 2483] train: loss: 0.0016873
[Epoch 12; Iter   617/ 2483] train: loss: 0.0018177
[Epoch 12; Iter   647/ 2483] train: loss: 0.0019445
[Epoch 12; Iter   677/ 2483] train: loss: 0.0030589
[Epoch 12; Iter   707/ 2483] train: loss: 0.0079056
[Epoch 12; Iter   737/ 2483] train: loss: 0.0016417
[Epoch 12; Iter   767/ 2483] train: loss: 0.0022019
[Epoch 12; Iter   797/ 2483] train: loss: 0.0016106
[Epoch 12; Iter   827/ 2483] train: loss: 0.0022369
[Epoch 12; Iter   857/ 2483] train: loss: 0.0871778
[Epoch 12; Iter   887/ 2483] train: loss: 0.0020318
[Epoch 12; Iter   917/ 2483] train: loss: 0.0035982
[Epoch 12; Iter   947/ 2483] train: loss: 0.0028677
[Epoch 12; Iter   977/ 2483] train: loss: 0.0509545
[Epoch 12; Iter  1007/ 2483] train: loss: 0.0028582
[Epoch 12; Iter  1037/ 2483] train: loss: 0.0021822
[Epoch 12; Iter  1067/ 2483] train: loss: 0.0022936
[Epoch 12; Iter  1097/ 2483] train: loss: 0.0020984
[Epoch 12; Iter  1127/ 2483] train: loss: 0.0033355
[Epoch 12; Iter  1157/ 2483] train: loss: 0.0019033
[Epoch 12; Iter  1187/ 2483] train: loss: 0.0016933
[Epoch 12; Iter  1217/ 2483] train: loss: 0.0020576
[Epoch 12; Iter  1247/ 2483] train: loss: 0.0022093
[Epoch 12; Iter  1277/ 2483] train: loss: 0.0020944
[Epoch 12; Iter  1307/ 2483] train: loss: 0.0013582
[Epoch 12; Iter  1337/ 2483] train: loss: 0.0019476
[Epoch 12; Iter  1367/ 2483] train: loss: 0.0015571
[Epoch 12; Iter  1397/ 2483] train: loss: 0.0021182
[Epoch 12; Iter  1427/ 2483] train: loss: 0.0016901
[Epoch 12; Iter  1457/ 2483] train: loss: 0.0019081
[Epoch 12; Iter  1487/ 2483] train: loss: 0.0019543
[Epoch 12; Iter  1517/ 2483] train: loss: 0.0018300
[Epoch 12; Iter  1547/ 2483] train: loss: 0.0021995
[Epoch 12; Iter  1577/ 2483] train: loss: 0.0018320
[Epoch 12; Iter  1607/ 2483] train: loss: 0.0023302
[Epoch 12; Iter  1637/ 2483] train: loss: 0.0014798
[Epoch 12; Iter  1667/ 2483] train: loss: 0.0015350
[Epoch 12; Iter  1697/ 2483] train: loss: 0.0015683
[Epoch 12; Iter  1727/ 2483] train: loss: 0.0024574
[Epoch 12; Iter  1757/ 2483] train: loss: 0.0688258
[Epoch 12; Iter  1787/ 2483] train: loss: 0.0523246
[Epoch 12; Iter  1817/ 2483] train: loss: 0.0020565
[Epoch 12; Iter  1847/ 2483] train: loss: 0.0023182
[Epoch 12; Iter  1877/ 2483] train: loss: 0.0780456
[Epoch 12; Iter  1907/ 2483] train: loss: 0.0019001
[Epoch 12; Iter  1937/ 2483] train: loss: 0.0011814
[Epoch 12; Iter  1967/ 2483] train: loss: 0.0013909
[Epoch 12; Iter  1997/ 2483] train: loss: 0.0018327
[Epoch 12; Iter  2027/ 2483] train: loss: 0.0018443
[Epoch 12; Iter  2057/ 2483] train: loss: 0.0015697
[Epoch 12; Iter  2087/ 2483] train: loss: 0.0018911
[Epoch 12; Iter  2117/ 2483] train: loss: 0.0017718
[Epoch 12; Iter  2147/ 2483] train: loss: 0.0018301
[Epoch 12; Iter  2177/ 2483] train: loss: 0.0020804
[Epoch 12; Iter  2207/ 2483] train: loss: 0.0014786
[Epoch 12; Iter  2237/ 2483] train: loss: 0.0014864
[Epoch 12; Iter  2267/ 2483] train: loss: 0.0014489
[Epoch 12; Iter  2297/ 2483] train: loss: 0.0011912
[Epoch 12; Iter  2327/ 2483] train: loss: 0.0023437
[Epoch 12; Iter  2357/ 2483] train: loss: 0.0015548
[Epoch 12; Iter  2387/ 2483] train: loss: 0.1271556
[Epoch 12; Iter  2417/ 2483] train: loss: 0.0016288
[Epoch 12; Iter  2447/ 2483] train: loss: 0.0017962
[Epoch 12; Iter  2477/ 2483] train: loss: 0.0021297
[Epoch 12] ogbg-molmuv: 0.048166 val loss: 0.011497
[Epoch 12] ogbg-molmuv: 0.078267 test loss: 0.014404
[Epoch 13; Iter    24/ 2483] train: loss: 0.0020915
[Epoch 13; Iter    54/ 2483] train: loss: 0.0016930
[Epoch 13; Iter    84/ 2483] train: loss: 0.0014403
[Epoch 13; Iter   114/ 2483] train: loss: 0.0845546
[Epoch 13; Iter   144/ 2483] train: loss: 0.0020945
[Epoch 13; Iter   174/ 2483] train: loss: 0.0021359
[Epoch 13; Iter   204/ 2483] train: loss: 0.0700605
[Epoch 13; Iter   234/ 2483] train: loss: 0.0030031
[Epoch 13; Iter   264/ 2483] train: loss: 0.0015447
[Epoch 13; Iter   294/ 2483] train: loss: 0.0015331
[Epoch 13; Iter   324/ 2483] train: loss: 0.0014539
[Epoch 13; Iter   354/ 2483] train: loss: 0.0021789
[Epoch 13; Iter   384/ 2483] train: loss: 0.0024317
[Epoch 13; Iter   414/ 2483] train: loss: 0.0018748
[Epoch 13; Iter   444/ 2483] train: loss: 0.0014981
[Epoch 13; Iter   474/ 2483] train: loss: 0.0025287
[Epoch 13; Iter   504/ 2483] train: loss: 0.0015051
[Epoch 13; Iter   534/ 2483] train: loss: 0.0012462
[Epoch 13; Iter   564/ 2483] train: loss: 0.0621859
[Epoch 13; Iter   594/ 2483] train: loss: 0.0018455
[Epoch 13; Iter   624/ 2483] train: loss: 0.0016694
[Epoch 13; Iter   654/ 2483] train: loss: 0.0018571
[Epoch 13; Iter   684/ 2483] train: loss: 0.0034265
[Epoch 13; Iter   714/ 2483] train: loss: 0.0012968
[Epoch 13; Iter   744/ 2483] train: loss: 0.0669538
[Epoch 13; Iter   774/ 2483] train: loss: 0.0020396
[Epoch 13; Iter   804/ 2483] train: loss: 0.0013323
[Epoch 13; Iter   834/ 2483] train: loss: 0.0017190
[Epoch 13; Iter   864/ 2483] train: loss: 0.0018106
[Epoch 13; Iter   894/ 2483] train: loss: 0.0019965
[Epoch 13; Iter   924/ 2483] train: loss: 0.0017338
[Epoch 13; Iter   954/ 2483] train: loss: 0.0015279
[Epoch 13; Iter   984/ 2483] train: loss: 0.0018340
[Epoch 13; Iter  1014/ 2483] train: loss: 0.0031321
[Epoch 13; Iter  1044/ 2483] train: loss: 0.0017264
[Epoch 13; Iter  1074/ 2483] train: loss: 0.0035757
[Epoch 13; Iter  1104/ 2483] train: loss: 0.0018870
[Epoch 13; Iter  1134/ 2483] train: loss: 0.0025199
[Epoch 13; Iter  1164/ 2483] train: loss: 0.0710026
[Epoch 13; Iter  1194/ 2483] train: loss: 0.1289977
[Epoch 13; Iter  1224/ 2483] train: loss: 0.1000154
[Epoch 13; Iter  1254/ 2483] train: loss: 0.0023198
[Epoch 13; Iter  1284/ 2483] train: loss: 0.0014212
[Epoch 13; Iter  1314/ 2483] train: loss: 0.0016268
[Epoch 13; Iter  1344/ 2483] train: loss: 0.0022927
[Epoch 13; Iter  1374/ 2483] train: loss: 0.0702552
[Epoch 11; Iter  1780/ 2483] train: loss: 0.0014584
[Epoch 11; Iter  1810/ 2483] train: loss: 0.0027680
[Epoch 11; Iter  1840/ 2483] train: loss: 0.0021063
[Epoch 11; Iter  1870/ 2483] train: loss: 0.0532116
[Epoch 11; Iter  1900/ 2483] train: loss: 0.0027824
[Epoch 11; Iter  1930/ 2483] train: loss: 0.0026135
[Epoch 11; Iter  1960/ 2483] train: loss: 0.0012269
[Epoch 11; Iter  1990/ 2483] train: loss: 0.0019192
[Epoch 11; Iter  2020/ 2483] train: loss: 0.0021915
[Epoch 11; Iter  2050/ 2483] train: loss: 0.0027569
[Epoch 11; Iter  2080/ 2483] train: loss: 0.0021074
[Epoch 11; Iter  2110/ 2483] train: loss: 0.0018367
[Epoch 11; Iter  2140/ 2483] train: loss: 0.0015692
[Epoch 11; Iter  2170/ 2483] train: loss: 0.0014608
[Epoch 11; Iter  2200/ 2483] train: loss: 0.0797473
[Epoch 11; Iter  2230/ 2483] train: loss: 0.0014054
[Epoch 11; Iter  2260/ 2483] train: loss: 0.0021207
[Epoch 11; Iter  2290/ 2483] train: loss: 0.0019030
[Epoch 11; Iter  2320/ 2483] train: loss: 0.0015778
[Epoch 11; Iter  2350/ 2483] train: loss: 0.0021573
[Epoch 11; Iter  2380/ 2483] train: loss: 0.0018198
[Epoch 11; Iter  2410/ 2483] train: loss: 0.0018251
[Epoch 11; Iter  2440/ 2483] train: loss: 0.0015693
[Epoch 11; Iter  2470/ 2483] train: loss: 0.0019994
[Epoch 11] ogbg-molmuv: 0.050305 val loss: 0.010600
[Epoch 11] ogbg-molmuv: 0.017661 test loss: 0.017349
[Epoch 12; Iter    17/ 2483] train: loss: 0.0016605
[Epoch 12; Iter    47/ 2483] train: loss: 0.0015804
[Epoch 12; Iter    77/ 2483] train: loss: 0.0019399
[Epoch 12; Iter   107/ 2483] train: loss: 0.0017578
[Epoch 12; Iter   137/ 2483] train: loss: 0.0017346
[Epoch 12; Iter   167/ 2483] train: loss: 0.0015280
[Epoch 12; Iter   197/ 2483] train: loss: 0.0605700
[Epoch 12; Iter   227/ 2483] train: loss: 0.0030749
[Epoch 12; Iter   257/ 2483] train: loss: 0.0605895
[Epoch 12; Iter   287/ 2483] train: loss: 0.0026237
[Epoch 12; Iter   317/ 2483] train: loss: 0.0022915
[Epoch 12; Iter   347/ 2483] train: loss: 0.0024749
[Epoch 12; Iter   377/ 2483] train: loss: 0.0016035
[Epoch 12; Iter   407/ 2483] train: loss: 0.0026420
[Epoch 12; Iter   437/ 2483] train: loss: 0.0018661
[Epoch 12; Iter   467/ 2483] train: loss: 0.0019062
[Epoch 12; Iter   497/ 2483] train: loss: 0.0016742
[Epoch 12; Iter   527/ 2483] train: loss: 0.0024812
[Epoch 12; Iter   557/ 2483] train: loss: 0.0020587
[Epoch 12; Iter   587/ 2483] train: loss: 0.0018929
[Epoch 12; Iter   617/ 2483] train: loss: 0.0018140
[Epoch 12; Iter   647/ 2483] train: loss: 0.0020242
[Epoch 12; Iter   677/ 2483] train: loss: 0.0027675
[Epoch 12; Iter   707/ 2483] train: loss: 0.0029948
[Epoch 12; Iter   737/ 2483] train: loss: 0.0021190
[Epoch 12; Iter   767/ 2483] train: loss: 0.0018780
[Epoch 12; Iter   797/ 2483] train: loss: 0.0014523
[Epoch 12; Iter   827/ 2483] train: loss: 0.0019931
[Epoch 12; Iter   857/ 2483] train: loss: 0.0020481
[Epoch 12; Iter   887/ 2483] train: loss: 0.0016561
[Epoch 12; Iter   917/ 2483] train: loss: 0.0016793
[Epoch 12; Iter   947/ 2483] train: loss: 0.0015506
[Epoch 12; Iter   977/ 2483] train: loss: 0.0019018
[Epoch 12; Iter  1007/ 2483] train: loss: 0.0011694
[Epoch 12; Iter  1037/ 2483] train: loss: 0.0015925
[Epoch 12; Iter  1067/ 2483] train: loss: 0.0056939
[Epoch 12; Iter  1097/ 2483] train: loss: 0.0016531
[Epoch 12; Iter  1127/ 2483] train: loss: 0.0015593
[Epoch 12; Iter  1157/ 2483] train: loss: 0.0013299
[Epoch 12; Iter  1187/ 2483] train: loss: 0.0016490
[Epoch 12; Iter  1217/ 2483] train: loss: 0.0015570
[Epoch 12; Iter  1247/ 2483] train: loss: 0.0014766
[Epoch 12; Iter  1277/ 2483] train: loss: 0.0020019
[Epoch 12; Iter  1307/ 2483] train: loss: 0.0017650
[Epoch 12; Iter  1337/ 2483] train: loss: 0.0017491
[Epoch 12; Iter  1367/ 2483] train: loss: 0.0015314
[Epoch 12; Iter  1397/ 2483] train: loss: 0.0011788
[Epoch 12; Iter  1427/ 2483] train: loss: 0.1005715
[Epoch 12; Iter  1457/ 2483] train: loss: 0.0014557
[Epoch 12; Iter  1487/ 2483] train: loss: 0.0774069
[Epoch 12; Iter  1517/ 2483] train: loss: 0.0017206
[Epoch 12; Iter  1547/ 2483] train: loss: 0.0017429
[Epoch 12; Iter  1577/ 2483] train: loss: 0.0016561
[Epoch 12; Iter  1607/ 2483] train: loss: 0.0014102
[Epoch 12; Iter  1637/ 2483] train: loss: 0.0020217
[Epoch 12; Iter  1667/ 2483] train: loss: 0.0017554
[Epoch 12; Iter  1697/ 2483] train: loss: 0.0016477
[Epoch 12; Iter  1727/ 2483] train: loss: 0.0508013
[Epoch 12; Iter  1757/ 2483] train: loss: 0.0017346
[Epoch 12; Iter  1787/ 2483] train: loss: 0.0016747
[Epoch 12; Iter  1817/ 2483] train: loss: 0.0014266
[Epoch 12; Iter  1847/ 2483] train: loss: 0.0015822
[Epoch 12; Iter  1877/ 2483] train: loss: 0.0014346
[Epoch 12; Iter  1907/ 2483] train: loss: 0.0021668
[Epoch 12; Iter  1937/ 2483] train: loss: 0.0033709
[Epoch 12; Iter  1967/ 2483] train: loss: 0.0022850
[Epoch 12; Iter  1997/ 2483] train: loss: 0.2022976
[Epoch 12; Iter  2027/ 2483] train: loss: 0.0024558
[Epoch 12; Iter  2057/ 2483] train: loss: 0.0545582
[Epoch 12; Iter  2087/ 2483] train: loss: 0.1371311
[Epoch 12; Iter  2117/ 2483] train: loss: 0.0015195
[Epoch 12; Iter  2147/ 2483] train: loss: 0.0018366
[Epoch 12; Iter  2177/ 2483] train: loss: 0.0800121
[Epoch 12; Iter  2207/ 2483] train: loss: 0.0013753
[Epoch 12; Iter  2237/ 2483] train: loss: 0.0753076
[Epoch 12; Iter  2267/ 2483] train: loss: 0.0805709
[Epoch 12; Iter  2297/ 2483] train: loss: 0.0011734
[Epoch 12; Iter  2327/ 2483] train: loss: 0.0578750
[Epoch 12; Iter  2357/ 2483] train: loss: 0.0019377
[Epoch 12; Iter  2387/ 2483] train: loss: 0.0020956
[Epoch 12; Iter  2417/ 2483] train: loss: 0.0015000
[Epoch 12; Iter  2447/ 2483] train: loss: 0.0014619
[Epoch 12; Iter  2477/ 2483] train: loss: 0.0540894
[Epoch 12] ogbg-molmuv: 0.057148 val loss: 0.011063
[Epoch 12] ogbg-molmuv: 0.018934 test loss: 0.015308
[Epoch 13; Iter    24/ 2483] train: loss: 0.0026464
[Epoch 13; Iter    54/ 2483] train: loss: 0.0029702
[Epoch 13; Iter    84/ 2483] train: loss: 0.0015485
[Epoch 13; Iter   114/ 2483] train: loss: 0.0019462
[Epoch 13; Iter   144/ 2483] train: loss: 0.0536280
[Epoch 13; Iter   174/ 2483] train: loss: 0.0013857
[Epoch 13; Iter   204/ 2483] train: loss: 0.0025053
[Epoch 13; Iter   234/ 2483] train: loss: 0.0899166
[Epoch 13; Iter   264/ 2483] train: loss: 0.0025921
[Epoch 13; Iter   294/ 2483] train: loss: 0.0017339
[Epoch 13; Iter   324/ 2483] train: loss: 0.0013896
[Epoch 13; Iter   354/ 2483] train: loss: 0.0014546
[Epoch 13; Iter   384/ 2483] train: loss: 0.0016048
[Epoch 13; Iter   414/ 2483] train: loss: 0.0018158
[Epoch 13; Iter   444/ 2483] train: loss: 0.0021359
[Epoch 13; Iter   474/ 2483] train: loss: 0.1208027
[Epoch 13; Iter   504/ 2483] train: loss: 0.0926248
[Epoch 13; Iter   534/ 2483] train: loss: 0.0027791
[Epoch 13; Iter   564/ 2483] train: loss: 0.0012669
[Epoch 13; Iter   594/ 2483] train: loss: 0.0017098
[Epoch 13; Iter   624/ 2483] train: loss: 0.0013396
[Epoch 13; Iter   654/ 2483] train: loss: 0.0012135
[Epoch 13; Iter   684/ 2483] train: loss: 0.0016734
[Epoch 13; Iter   714/ 2483] train: loss: 0.0020108
[Epoch 13; Iter   744/ 2483] train: loss: 0.0017950
[Epoch 13; Iter   774/ 2483] train: loss: 0.0025429
[Epoch 13; Iter   804/ 2483] train: loss: 0.0017987
[Epoch 13; Iter   834/ 2483] train: loss: 0.0016096
[Epoch 13; Iter   864/ 2483] train: loss: 0.0013733
[Epoch 13; Iter   894/ 2483] train: loss: 0.0015731
[Epoch 13; Iter   924/ 2483] train: loss: 0.0015252
[Epoch 13; Iter   954/ 2483] train: loss: 0.0015357
[Epoch 13; Iter   984/ 2483] train: loss: 0.0008838
[Epoch 13; Iter  1014/ 2483] train: loss: 0.0010434
[Epoch 13; Iter  1044/ 2483] train: loss: 0.0012265
[Epoch 13; Iter  1074/ 2483] train: loss: 0.0013703
[Epoch 13; Iter  1104/ 2483] train: loss: 0.0788009
[Epoch 13; Iter  1134/ 2483] train: loss: 0.0020070
[Epoch 13; Iter  1164/ 2483] train: loss: 0.0019822
[Epoch 13; Iter  1194/ 2483] train: loss: 0.0024487
[Epoch 13; Iter  1224/ 2483] train: loss: 0.0025644
[Epoch 13; Iter  1254/ 2483] train: loss: 0.0014302
[Epoch 13; Iter  1284/ 2483] train: loss: 0.0017208
[Epoch 13; Iter  1314/ 2483] train: loss: 0.0014655
[Epoch 13; Iter  1344/ 2483] train: loss: 0.0022757
[Epoch 13; Iter  1374/ 2483] train: loss: 0.0016366
[Epoch 12; Iter  1268/ 1862] train: loss: 0.0028044
[Epoch 12; Iter  1298/ 1862] train: loss: 0.0022367
[Epoch 12; Iter  1328/ 1862] train: loss: 0.0781344
[Epoch 12; Iter  1358/ 1862] train: loss: 0.0027841
[Epoch 12; Iter  1388/ 1862] train: loss: 0.0016658
[Epoch 12; Iter  1418/ 1862] train: loss: 0.0017607
[Epoch 12; Iter  1448/ 1862] train: loss: 0.0014683
[Epoch 12; Iter  1478/ 1862] train: loss: 0.0019163
[Epoch 12; Iter  1508/ 1862] train: loss: 0.0016245
[Epoch 12; Iter  1538/ 1862] train: loss: 0.0025623
[Epoch 12; Iter  1568/ 1862] train: loss: 0.0027737
[Epoch 12; Iter  1598/ 1862] train: loss: 0.0024531
[Epoch 12; Iter  1628/ 1862] train: loss: 0.0020559
[Epoch 12; Iter  1658/ 1862] train: loss: 0.0036122
[Epoch 12; Iter  1688/ 1862] train: loss: 0.0017469
[Epoch 12; Iter  1718/ 1862] train: loss: 0.0016322
[Epoch 12; Iter  1748/ 1862] train: loss: 0.0013330
[Epoch 12; Iter  1778/ 1862] train: loss: 0.0021248
[Epoch 12; Iter  1808/ 1862] train: loss: 0.0022585
[Epoch 12; Iter  1838/ 1862] train: loss: 0.0019697
[Epoch 12] ogbg-molmuv: 0.010636 val loss: 0.213447
[Epoch 12] ogbg-molmuv: 0.017626 test loss: 0.104344
[Epoch 13; Iter     6/ 1862] train: loss: 0.0021230
[Epoch 13; Iter    36/ 1862] train: loss: 0.0027970
[Epoch 13; Iter    66/ 1862] train: loss: 0.0014188
[Epoch 13; Iter    96/ 1862] train: loss: 0.0023670
[Epoch 13; Iter   126/ 1862] train: loss: 0.0018026
[Epoch 13; Iter   156/ 1862] train: loss: 0.0013970
[Epoch 13; Iter   186/ 1862] train: loss: 0.0018785
[Epoch 13; Iter   216/ 1862] train: loss: 0.0020782
[Epoch 13; Iter   246/ 1862] train: loss: 0.0033026
[Epoch 13; Iter   276/ 1862] train: loss: 0.0023041
[Epoch 13; Iter   306/ 1862] train: loss: 0.0015355
[Epoch 13; Iter   336/ 1862] train: loss: 0.0014724
[Epoch 13; Iter   366/ 1862] train: loss: 0.0016320
[Epoch 13; Iter   396/ 1862] train: loss: 0.0014805
[Epoch 13; Iter   426/ 1862] train: loss: 0.0015899
[Epoch 13; Iter   456/ 1862] train: loss: 0.0545010
[Epoch 13; Iter   486/ 1862] train: loss: 0.0019214
[Epoch 13; Iter   516/ 1862] train: loss: 0.0014173
[Epoch 13; Iter   546/ 1862] train: loss: 0.0018569
[Epoch 13; Iter   576/ 1862] train: loss: 0.0860008
[Epoch 13; Iter   606/ 1862] train: loss: 0.0021648
[Epoch 13; Iter   636/ 1862] train: loss: 0.0023614
[Epoch 13; Iter   666/ 1862] train: loss: 0.0016835
[Epoch 13; Iter   696/ 1862] train: loss: 0.0028496
[Epoch 13; Iter   726/ 1862] train: loss: 0.0030333
[Epoch 13; Iter   756/ 1862] train: loss: 0.0020772
[Epoch 13; Iter   786/ 1862] train: loss: 0.0025587
[Epoch 13; Iter   816/ 1862] train: loss: 0.0030338
[Epoch 13; Iter   846/ 1862] train: loss: 0.1443641
[Epoch 13; Iter   876/ 1862] train: loss: 0.0022805
[Epoch 13; Iter   906/ 1862] train: loss: 0.0917211
[Epoch 13; Iter   936/ 1862] train: loss: 0.0532271
[Epoch 13; Iter   966/ 1862] train: loss: 0.0018242
[Epoch 13; Iter   996/ 1862] train: loss: 0.0013589
[Epoch 13; Iter  1026/ 1862] train: loss: 0.0013353
[Epoch 13; Iter  1056/ 1862] train: loss: 0.0014092
[Epoch 13; Iter  1086/ 1862] train: loss: 0.0015299
[Epoch 13; Iter  1116/ 1862] train: loss: 0.0021475
[Epoch 13; Iter  1146/ 1862] train: loss: 0.0011411
[Epoch 13; Iter  1176/ 1862] train: loss: 0.0019450
[Epoch 13; Iter  1206/ 1862] train: loss: 0.0022261
[Epoch 13; Iter  1236/ 1862] train: loss: 0.0018318
[Epoch 13; Iter  1266/ 1862] train: loss: 0.0014895
[Epoch 13; Iter  1296/ 1862] train: loss: 0.0017796
[Epoch 13; Iter  1326/ 1862] train: loss: 0.0022819
[Epoch 13; Iter  1356/ 1862] train: loss: 0.0023290
[Epoch 13; Iter  1386/ 1862] train: loss: 0.0870257
[Epoch 13; Iter  1416/ 1862] train: loss: 0.0029276
[Epoch 13; Iter  1446/ 1862] train: loss: 0.0027543
[Epoch 13; Iter  1476/ 1862] train: loss: 0.0016891
[Epoch 13; Iter  1506/ 1862] train: loss: 0.0022261
[Epoch 13; Iter  1536/ 1862] train: loss: 0.0018958
[Epoch 13; Iter  1566/ 1862] train: loss: 0.0027575
[Epoch 13; Iter  1596/ 1862] train: loss: 0.0612184
[Epoch 13; Iter  1626/ 1862] train: loss: 0.0813020
[Epoch 13; Iter  1656/ 1862] train: loss: 0.0017849
[Epoch 13; Iter  1686/ 1862] train: loss: 0.0033937
[Epoch 13; Iter  1716/ 1862] train: loss: 0.0013264
[Epoch 13; Iter  1746/ 1862] train: loss: 0.0019663
[Epoch 13; Iter  1776/ 1862] train: loss: 0.0018759
[Epoch 13; Iter  1806/ 1862] train: loss: 0.0054644
[Epoch 13; Iter  1836/ 1862] train: loss: 0.0016113
[Epoch 13] ogbg-molmuv: 0.020880 val loss: 0.014169
[Epoch 13] ogbg-molmuv: 0.050817 test loss: 0.012742
[Epoch 14; Iter     4/ 1862] train: loss: 0.0018681
[Epoch 14; Iter    34/ 1862] train: loss: 0.0016715
[Epoch 14; Iter    64/ 1862] train: loss: 0.0014091
[Epoch 14; Iter    94/ 1862] train: loss: 0.0016322
[Epoch 14; Iter   124/ 1862] train: loss: 0.0019935
[Epoch 14; Iter   154/ 1862] train: loss: 0.0972897
[Epoch 14; Iter   184/ 1862] train: loss: 0.0029762
[Epoch 14; Iter   214/ 1862] train: loss: 0.0015168
[Epoch 14; Iter   244/ 1862] train: loss: 0.0015368
[Epoch 14; Iter   274/ 1862] train: loss: 0.0017455
[Epoch 14; Iter   304/ 1862] train: loss: 0.0018949
[Epoch 14; Iter   334/ 1862] train: loss: 0.0016637
[Epoch 14; Iter   364/ 1862] train: loss: 0.0016363
[Epoch 14; Iter   394/ 1862] train: loss: 0.0631171
[Epoch 14; Iter   424/ 1862] train: loss: 0.0022274
[Epoch 14; Iter   454/ 1862] train: loss: 0.0853396
[Epoch 14; Iter   484/ 1862] train: loss: 0.0045865
[Epoch 14; Iter   514/ 1862] train: loss: 0.0020416
[Epoch 14; Iter   544/ 1862] train: loss: 0.0025345
[Epoch 14; Iter   574/ 1862] train: loss: 0.0720918
[Epoch 14; Iter   604/ 1862] train: loss: 0.0018877
[Epoch 14; Iter   634/ 1862] train: loss: 0.0016751
[Epoch 14; Iter   664/ 1862] train: loss: 0.0016868
[Epoch 14; Iter   694/ 1862] train: loss: 0.0900130
[Epoch 14; Iter   724/ 1862] train: loss: 0.0498473
[Epoch 14; Iter   754/ 1862] train: loss: 0.0019513
[Epoch 14; Iter   784/ 1862] train: loss: 0.0018170
[Epoch 14; Iter   814/ 1862] train: loss: 0.0023188
[Epoch 14; Iter   844/ 1862] train: loss: 0.0017064
[Epoch 14; Iter   874/ 1862] train: loss: 0.0021097
[Epoch 14; Iter   904/ 1862] train: loss: 0.0016777
[Epoch 14; Iter   934/ 1862] train: loss: 0.0695821
[Epoch 14; Iter   964/ 1862] train: loss: 0.0022806
[Epoch 14; Iter   994/ 1862] train: loss: 0.0016875
[Epoch 14; Iter  1024/ 1862] train: loss: 0.0018009
[Epoch 14; Iter  1054/ 1862] train: loss: 0.0015741
[Epoch 14; Iter  1084/ 1862] train: loss: 0.0014411
[Epoch 14; Iter  1114/ 1862] train: loss: 0.0014424
[Epoch 14; Iter  1144/ 1862] train: loss: 0.0014590
[Epoch 14; Iter  1174/ 1862] train: loss: 0.0015305
[Epoch 14; Iter  1204/ 1862] train: loss: 0.0016222
[Epoch 14; Iter  1234/ 1862] train: loss: 0.0014270
[Epoch 14; Iter  1264/ 1862] train: loss: 0.1243877
[Epoch 14; Iter  1294/ 1862] train: loss: 0.0020787
[Epoch 14; Iter  1324/ 1862] train: loss: 0.0016886
[Epoch 14; Iter  1354/ 1862] train: loss: 0.0658386
[Epoch 14; Iter  1384/ 1862] train: loss: 0.0020925
[Epoch 14; Iter  1414/ 1862] train: loss: 0.0661278
[Epoch 14; Iter  1444/ 1862] train: loss: 0.0035004
[Epoch 14; Iter  1474/ 1862] train: loss: 0.0022748
[Epoch 14; Iter  1504/ 1862] train: loss: 0.0074559
[Epoch 14; Iter  1534/ 1862] train: loss: 0.0021999
[Epoch 14; Iter  1564/ 1862] train: loss: 0.0021468
[Epoch 14; Iter  1594/ 1862] train: loss: 0.0016729
[Epoch 14; Iter  1624/ 1862] train: loss: 0.0017968
[Epoch 14; Iter  1654/ 1862] train: loss: 0.0015015
[Epoch 14; Iter  1684/ 1862] train: loss: 0.0021554
[Epoch 14; Iter  1714/ 1862] train: loss: 0.0011675
[Epoch 14; Iter  1744/ 1862] train: loss: 0.0012198
[Epoch 14; Iter  1774/ 1862] train: loss: 0.0014944
[Epoch 14; Iter  1804/ 1862] train: loss: 0.0012523
[Epoch 14; Iter  1834/ 1862] train: loss: 0.0011380
[Epoch 14] ogbg-molmuv: 0.015733 val loss: 0.013948
[Epoch 14] ogbg-molmuv: 0.048630 test loss: 0.013613
[Epoch 15; Iter     2/ 1862] train: loss: 0.0014419
[Epoch 15; Iter    32/ 1862] train: loss: 0.0012862
[Epoch 15; Iter    62/ 1862] train: loss: 0.0052314
[Epoch 15; Iter    92/ 1862] train: loss: 0.0013645
[Epoch 15; Iter   122/ 1862] train: loss: 0.0016980
[Epoch 15; Iter   152/ 1862] train: loss: 0.0016282
[Epoch 15; Iter   182/ 1862] train: loss: 0.0533295
[Epoch 12; Iter  1268/ 1862] train: loss: 0.0018024
[Epoch 12; Iter  1298/ 1862] train: loss: 0.0017745
[Epoch 12; Iter  1328/ 1862] train: loss: 0.0019989
[Epoch 12; Iter  1358/ 1862] train: loss: 0.0025453
[Epoch 12; Iter  1388/ 1862] train: loss: 0.0022941
[Epoch 12; Iter  1418/ 1862] train: loss: 0.0017886
[Epoch 12; Iter  1448/ 1862] train: loss: 0.0674517
[Epoch 12; Iter  1478/ 1862] train: loss: 0.0024114
[Epoch 12; Iter  1508/ 1862] train: loss: 0.0019646
[Epoch 12; Iter  1538/ 1862] train: loss: 0.0021431
[Epoch 12; Iter  1568/ 1862] train: loss: 0.0013250
[Epoch 12; Iter  1598/ 1862] train: loss: 0.0021903
[Epoch 12; Iter  1628/ 1862] train: loss: 0.0017929
[Epoch 12; Iter  1658/ 1862] train: loss: 0.0022239
[Epoch 12; Iter  1688/ 1862] train: loss: 0.0018615
[Epoch 12; Iter  1718/ 1862] train: loss: 0.0022334
[Epoch 12; Iter  1748/ 1862] train: loss: 0.1143729
[Epoch 12; Iter  1778/ 1862] train: loss: 0.0028309
[Epoch 12; Iter  1808/ 1862] train: loss: 0.0017722
[Epoch 12; Iter  1838/ 1862] train: loss: 0.0033014
[Epoch 12] ogbg-molmuv: 0.018580 val loss: 0.013865
[Epoch 12] ogbg-molmuv: 0.015910 test loss: 0.012592
[Epoch 13; Iter     6/ 1862] train: loss: 0.0014871
[Epoch 13; Iter    36/ 1862] train: loss: 0.0011857
[Epoch 13; Iter    66/ 1862] train: loss: 0.0015620
[Epoch 13; Iter    96/ 1862] train: loss: 0.0026430
[Epoch 13; Iter   126/ 1862] train: loss: 0.0023028
[Epoch 13; Iter   156/ 1862] train: loss: 0.0030955
[Epoch 13; Iter   186/ 1862] train: loss: 0.0023697
[Epoch 13; Iter   216/ 1862] train: loss: 0.0017462
[Epoch 13; Iter   246/ 1862] train: loss: 0.0016964
[Epoch 13; Iter   276/ 1862] train: loss: 0.0019437
[Epoch 13; Iter   306/ 1862] train: loss: 0.0023663
[Epoch 13; Iter   336/ 1862] train: loss: 0.0017226
[Epoch 13; Iter   366/ 1862] train: loss: 0.0026965
[Epoch 13; Iter   396/ 1862] train: loss: 0.0024902
[Epoch 13; Iter   426/ 1862] train: loss: 0.0016764
[Epoch 13; Iter   456/ 1862] train: loss: 0.0486182
[Epoch 13; Iter   486/ 1862] train: loss: 0.0012668
[Epoch 13; Iter   516/ 1862] train: loss: 0.0011700
[Epoch 13; Iter   546/ 1862] train: loss: 0.0018627
[Epoch 13; Iter   576/ 1862] train: loss: 0.0022607
[Epoch 13; Iter   606/ 1862] train: loss: 0.0019121
[Epoch 13; Iter   636/ 1862] train: loss: 0.0029586
[Epoch 13; Iter   666/ 1862] train: loss: 0.0782310
[Epoch 13; Iter   696/ 1862] train: loss: 0.0022173
[Epoch 13; Iter   726/ 1862] train: loss: 0.0027321
[Epoch 13; Iter   756/ 1862] train: loss: 0.0018168
[Epoch 13; Iter   786/ 1862] train: loss: 0.0777620
[Epoch 13; Iter   816/ 1862] train: loss: 0.0021245
[Epoch 13; Iter   846/ 1862] train: loss: 0.0019902
[Epoch 13; Iter   876/ 1862] train: loss: 0.0022857
[Epoch 13; Iter   906/ 1862] train: loss: 0.0022973
[Epoch 13; Iter   936/ 1862] train: loss: 0.0827695
[Epoch 13; Iter   966/ 1862] train: loss: 0.0024825
[Epoch 13; Iter   996/ 1862] train: loss: 0.0017670
[Epoch 13; Iter  1026/ 1862] train: loss: 0.0014762
[Epoch 13; Iter  1056/ 1862] train: loss: 0.0015073
[Epoch 13; Iter  1086/ 1862] train: loss: 0.0025764
[Epoch 13; Iter  1116/ 1862] train: loss: 0.0014765
[Epoch 13; Iter  1146/ 1862] train: loss: 0.0013200
[Epoch 13; Iter  1176/ 1862] train: loss: 0.0010513
[Epoch 13; Iter  1206/ 1862] train: loss: 0.0478962
[Epoch 13; Iter  1236/ 1862] train: loss: 0.0016891
[Epoch 13; Iter  1266/ 1862] train: loss: 0.0014660
[Epoch 13; Iter  1296/ 1862] train: loss: 0.0014802
[Epoch 13; Iter  1326/ 1862] train: loss: 0.0406541
[Epoch 13; Iter  1356/ 1862] train: loss: 0.0017017
[Epoch 13; Iter  1386/ 1862] train: loss: 0.0559643
[Epoch 13; Iter  1416/ 1862] train: loss: 0.0013525
[Epoch 13; Iter  1446/ 1862] train: loss: 0.0019256
[Epoch 13; Iter  1476/ 1862] train: loss: 0.0019459
[Epoch 13; Iter  1506/ 1862] train: loss: 0.2226788
[Epoch 13; Iter  1536/ 1862] train: loss: 0.0042743
[Epoch 13; Iter  1566/ 1862] train: loss: 0.0876502
[Epoch 13; Iter  1596/ 1862] train: loss: 0.0016820
[Epoch 13; Iter  1626/ 1862] train: loss: 0.0017187
[Epoch 13; Iter  1656/ 1862] train: loss: 0.0011742
[Epoch 13; Iter  1686/ 1862] train: loss: 0.0676350
[Epoch 13; Iter  1716/ 1862] train: loss: 0.0026780
[Epoch 13; Iter  1746/ 1862] train: loss: 0.0686892
[Epoch 13; Iter  1776/ 1862] train: loss: 0.0028317
[Epoch 13; Iter  1806/ 1862] train: loss: 0.0024596
[Epoch 13; Iter  1836/ 1862] train: loss: 0.0030572
[Epoch 13] ogbg-molmuv: 0.015001 val loss: 0.013478
[Epoch 13] ogbg-molmuv: 0.021631 test loss: 0.012054
[Epoch 14; Iter     4/ 1862] train: loss: 0.0848932
[Epoch 14; Iter    34/ 1862] train: loss: 0.0025082
[Epoch 14; Iter    64/ 1862] train: loss: 0.0014940
[Epoch 14; Iter    94/ 1862] train: loss: 0.0939528
[Epoch 14; Iter   124/ 1862] train: loss: 0.0028631
[Epoch 14; Iter   154/ 1862] train: loss: 0.0023627
[Epoch 14; Iter   184/ 1862] train: loss: 0.0020988
[Epoch 14; Iter   214/ 1862] train: loss: 0.0028249
[Epoch 14; Iter   244/ 1862] train: loss: 0.0021470
[Epoch 14; Iter   274/ 1862] train: loss: 0.0011939
[Epoch 14; Iter   304/ 1862] train: loss: 0.0017550
[Epoch 14; Iter   334/ 1862] train: loss: 0.0015595
[Epoch 14; Iter   364/ 1862] train: loss: 0.0014644
[Epoch 14; Iter   394/ 1862] train: loss: 0.0017344
[Epoch 14; Iter   424/ 1862] train: loss: 0.0024046
[Epoch 14; Iter   454/ 1862] train: loss: 0.0028082
[Epoch 14; Iter   484/ 1862] train: loss: 0.0026221
[Epoch 14; Iter   514/ 1862] train: loss: 0.0019068
[Epoch 14; Iter   544/ 1862] train: loss: 0.0019724
[Epoch 14; Iter   574/ 1862] train: loss: 0.0015283
[Epoch 14; Iter   604/ 1862] train: loss: 0.0018158
[Epoch 14; Iter   634/ 1862] train: loss: 0.0022275
[Epoch 14; Iter   664/ 1862] train: loss: 0.0018164
[Epoch 14; Iter   694/ 1862] train: loss: 0.0027744
[Epoch 14; Iter   724/ 1862] train: loss: 0.0568832
[Epoch 14; Iter   754/ 1862] train: loss: 0.0024443
[Epoch 14; Iter   784/ 1862] train: loss: 0.0799144
[Epoch 14; Iter   814/ 1862] train: loss: 0.0035081
[Epoch 14; Iter   844/ 1862] train: loss: 0.0033324
[Epoch 14; Iter   874/ 1862] train: loss: 0.0028710
[Epoch 14; Iter   904/ 1862] train: loss: 0.0018654
[Epoch 14; Iter   934/ 1862] train: loss: 0.0019832
[Epoch 14; Iter   964/ 1862] train: loss: 0.0026303
[Epoch 14; Iter   994/ 1862] train: loss: 0.0026486
[Epoch 14; Iter  1024/ 1862] train: loss: 0.1354867
[Epoch 14; Iter  1054/ 1862] train: loss: 0.0031762
[Epoch 14; Iter  1084/ 1862] train: loss: 0.0016409
[Epoch 14; Iter  1114/ 1862] train: loss: 0.0016572
[Epoch 14; Iter  1144/ 1862] train: loss: 0.0013429
[Epoch 14; Iter  1174/ 1862] train: loss: 0.0022384
[Epoch 14; Iter  1204/ 1862] train: loss: 0.0013774
[Epoch 14; Iter  1234/ 1862] train: loss: 0.0022020
[Epoch 14; Iter  1264/ 1862] train: loss: 0.1294992
[Epoch 14; Iter  1294/ 1862] train: loss: 0.0016745
[Epoch 14; Iter  1324/ 1862] train: loss: 0.0611533
[Epoch 14; Iter  1354/ 1862] train: loss: 0.0013292
[Epoch 14; Iter  1384/ 1862] train: loss: 0.0019631
[Epoch 14; Iter  1414/ 1862] train: loss: 0.0019214
[Epoch 14; Iter  1444/ 1862] train: loss: 0.0017180
[Epoch 14; Iter  1474/ 1862] train: loss: 0.0027245
[Epoch 14; Iter  1504/ 1862] train: loss: 0.0022515
[Epoch 14; Iter  1534/ 1862] train: loss: 0.0016845
[Epoch 14; Iter  1564/ 1862] train: loss: 0.0015509
[Epoch 14; Iter  1594/ 1862] train: loss: 0.0021138
[Epoch 14; Iter  1624/ 1862] train: loss: 0.0538680
[Epoch 14; Iter  1654/ 1862] train: loss: 0.0018742
[Epoch 14; Iter  1684/ 1862] train: loss: 0.0013262
[Epoch 14; Iter  1714/ 1862] train: loss: 0.0010716
[Epoch 14; Iter  1744/ 1862] train: loss: 0.0011026
[Epoch 14; Iter  1774/ 1862] train: loss: 0.0011590
[Epoch 14; Iter  1804/ 1862] train: loss: 0.0011898
[Epoch 14; Iter  1834/ 1862] train: loss: 0.1019573
[Epoch 14] ogbg-molmuv: 0.009768 val loss: 0.013924
[Epoch 14] ogbg-molmuv: 0.024443 test loss: 0.012667
[Epoch 15; Iter     2/ 1862] train: loss: 0.0011688
[Epoch 15; Iter    32/ 1862] train: loss: 0.0010503
[Epoch 15; Iter    62/ 1862] train: loss: 0.0011519
[Epoch 15; Iter    92/ 1862] train: loss: 0.0881353
[Epoch 15; Iter   122/ 1862] train: loss: 0.0014114
[Epoch 15; Iter   152/ 1862] train: loss: 0.0016057
[Epoch 15; Iter   182/ 1862] train: loss: 0.0015650
[Epoch 12; Iter  1268/ 1862] train: loss: 0.0021514
[Epoch 12; Iter  1298/ 1862] train: loss: 0.0807473
[Epoch 12; Iter  1328/ 1862] train: loss: 0.0022213
[Epoch 12; Iter  1358/ 1862] train: loss: 0.0025360
[Epoch 12; Iter  1388/ 1862] train: loss: 0.0018209
[Epoch 12; Iter  1418/ 1862] train: loss: 0.0016851
[Epoch 12; Iter  1448/ 1862] train: loss: 0.0016389
[Epoch 12; Iter  1478/ 1862] train: loss: 0.1557014
[Epoch 12; Iter  1508/ 1862] train: loss: 0.0799815
[Epoch 12; Iter  1538/ 1862] train: loss: 0.0854390
[Epoch 12; Iter  1568/ 1862] train: loss: 0.0911644
[Epoch 12; Iter  1598/ 1862] train: loss: 0.0022426
[Epoch 12; Iter  1628/ 1862] train: loss: 0.0021137
[Epoch 12; Iter  1658/ 1862] train: loss: 0.0014636
[Epoch 12; Iter  1688/ 1862] train: loss: 0.0608467
[Epoch 12; Iter  1718/ 1862] train: loss: 0.0019134
[Epoch 12; Iter  1748/ 1862] train: loss: 0.0021827
[Epoch 12; Iter  1778/ 1862] train: loss: 0.0017239
[Epoch 12; Iter  1808/ 1862] train: loss: 0.0021825
[Epoch 12; Iter  1838/ 1862] train: loss: 0.0756184
[Epoch 12] ogbg-molmuv: 0.018875 val loss: 0.014544
[Epoch 12] ogbg-molmuv: 0.014011 test loss: 0.013177
[Epoch 13; Iter     6/ 1862] train: loss: 0.0023096
[Epoch 13; Iter    36/ 1862] train: loss: 0.0024029
[Epoch 13; Iter    66/ 1862] train: loss: 0.0020509
[Epoch 13; Iter    96/ 1862] train: loss: 0.0017820
[Epoch 13; Iter   126/ 1862] train: loss: 0.0017011
[Epoch 13; Iter   156/ 1862] train: loss: 0.0017438
[Epoch 13; Iter   186/ 1862] train: loss: 0.0013643
[Epoch 13; Iter   216/ 1862] train: loss: 0.0016213
[Epoch 13; Iter   246/ 1862] train: loss: 0.0765244
[Epoch 13; Iter   276/ 1862] train: loss: 0.0026978
[Epoch 13; Iter   306/ 1862] train: loss: 0.0022367
[Epoch 13; Iter   336/ 1862] train: loss: 0.0665070
[Epoch 13; Iter   366/ 1862] train: loss: 0.0023592
[Epoch 13; Iter   396/ 1862] train: loss: 0.0025167
[Epoch 13; Iter   426/ 1862] train: loss: 0.0029177
[Epoch 13; Iter   456/ 1862] train: loss: 0.0030524
[Epoch 13; Iter   486/ 1862] train: loss: 0.0025880
[Epoch 13; Iter   516/ 1862] train: loss: 0.0029888
[Epoch 13; Iter   546/ 1862] train: loss: 0.0018158
[Epoch 13; Iter   576/ 1862] train: loss: 0.0019045
[Epoch 13; Iter   606/ 1862] train: loss: 0.0020907
[Epoch 13; Iter   636/ 1862] train: loss: 0.0015383
[Epoch 13; Iter   666/ 1862] train: loss: 0.0026800
[Epoch 13; Iter   696/ 1862] train: loss: 0.0016625
[Epoch 13; Iter   726/ 1862] train: loss: 0.0027108
[Epoch 13; Iter   756/ 1862] train: loss: 0.0566358
[Epoch 13; Iter   786/ 1862] train: loss: 0.0016590
[Epoch 13; Iter   816/ 1862] train: loss: 0.0017946
[Epoch 13; Iter   846/ 1862] train: loss: 0.0014816
[Epoch 13; Iter   876/ 1862] train: loss: 0.0798853
[Epoch 13; Iter   906/ 1862] train: loss: 0.0027216
[Epoch 13; Iter   936/ 1862] train: loss: 0.0016666
[Epoch 13; Iter   966/ 1862] train: loss: 0.0016233
[Epoch 13; Iter   996/ 1862] train: loss: 0.0012025
[Epoch 13; Iter  1026/ 1862] train: loss: 0.0013626
[Epoch 13; Iter  1056/ 1862] train: loss: 0.0011430
[Epoch 13; Iter  1086/ 1862] train: loss: 0.0011169
[Epoch 13; Iter  1116/ 1862] train: loss: 0.0017718
[Epoch 13; Iter  1146/ 1862] train: loss: 0.0569678
[Epoch 13; Iter  1176/ 1862] train: loss: 0.0016765
[Epoch 13; Iter  1206/ 1862] train: loss: 0.0025834
[Epoch 13; Iter  1236/ 1862] train: loss: 0.0023440
[Epoch 13; Iter  1266/ 1862] train: loss: 0.0014257
[Epoch 13; Iter  1296/ 1862] train: loss: 0.0018851
[Epoch 13; Iter  1326/ 1862] train: loss: 0.0692471
[Epoch 13; Iter  1356/ 1862] train: loss: 0.0017529
[Epoch 13; Iter  1386/ 1862] train: loss: 0.0027289
[Epoch 13; Iter  1416/ 1862] train: loss: 0.0023884
[Epoch 13; Iter  1446/ 1862] train: loss: 0.0024813
[Epoch 13; Iter  1476/ 1862] train: loss: 0.0016286
[Epoch 13; Iter  1506/ 1862] train: loss: 0.0013711
[Epoch 13; Iter  1536/ 1862] train: loss: 0.0935284
[Epoch 13; Iter  1566/ 1862] train: loss: 0.0014130
[Epoch 13; Iter  1596/ 1862] train: loss: 0.0013358
[Epoch 13; Iter  1626/ 1862] train: loss: 0.0011759
[Epoch 13; Iter  1656/ 1862] train: loss: 0.0044868
[Epoch 13; Iter  1686/ 1862] train: loss: 0.0653017
[Epoch 13; Iter  1716/ 1862] train: loss: 0.0017249
[Epoch 13; Iter  1746/ 1862] train: loss: 0.0012599
[Epoch 13; Iter  1776/ 1862] train: loss: 0.0021541
[Epoch 13; Iter  1806/ 1862] train: loss: 0.0021784
[Epoch 13; Iter  1836/ 1862] train: loss: 0.0018031
[Epoch 13] ogbg-molmuv: 0.011574 val loss: 0.013505
[Epoch 13] ogbg-molmuv: 0.009359 test loss: 0.012550
[Epoch 14; Iter     4/ 1862] train: loss: 0.0018810
[Epoch 14; Iter    34/ 1862] train: loss: 0.0016689
[Epoch 14; Iter    64/ 1862] train: loss: 0.0016755
[Epoch 14; Iter    94/ 1862] train: loss: 0.0011281
[Epoch 14; Iter   124/ 1862] train: loss: 0.0014347
[Epoch 14; Iter   154/ 1862] train: loss: 0.0015850
[Epoch 14; Iter   184/ 1862] train: loss: 0.0020692
[Epoch 14; Iter   214/ 1862] train: loss: 0.0016123
[Epoch 14; Iter   244/ 1862] train: loss: 0.0016142
[Epoch 14; Iter   274/ 1862] train: loss: 0.0026169
[Epoch 14; Iter   304/ 1862] train: loss: 0.0023081
[Epoch 14; Iter   334/ 1862] train: loss: 0.0891451
[Epoch 14; Iter   364/ 1862] train: loss: 0.0014252
[Epoch 14; Iter   394/ 1862] train: loss: 0.0015978
[Epoch 14; Iter   424/ 1862] train: loss: 0.0015430
[Epoch 14; Iter   454/ 1862] train: loss: 0.0024540
[Epoch 14; Iter   484/ 1862] train: loss: 0.0600122
[Epoch 14; Iter   514/ 1862] train: loss: 0.1281383
[Epoch 14; Iter   544/ 1862] train: loss: 0.0023423
[Epoch 14; Iter   574/ 1862] train: loss: 0.0019784
[Epoch 14; Iter   604/ 1862] train: loss: 0.0051156
[Epoch 14; Iter   634/ 1862] train: loss: 0.0585719
[Epoch 14; Iter   664/ 1862] train: loss: 0.0021454
[Epoch 14; Iter   694/ 1862] train: loss: 0.0024011
[Epoch 14; Iter   724/ 1862] train: loss: 0.0018491
[Epoch 14; Iter   754/ 1862] train: loss: 0.0018389
[Epoch 14; Iter   784/ 1862] train: loss: 0.0018598
[Epoch 14; Iter   814/ 1862] train: loss: 0.0020796
[Epoch 14; Iter   844/ 1862] train: loss: 0.0015518
[Epoch 14; Iter   874/ 1862] train: loss: 0.0014758
[Epoch 14; Iter   904/ 1862] train: loss: 0.0016791
[Epoch 14; Iter   934/ 1862] train: loss: 0.0017499
[Epoch 14; Iter   964/ 1862] train: loss: 0.0016155
[Epoch 14; Iter   994/ 1862] train: loss: 0.1191516
[Epoch 14; Iter  1024/ 1862] train: loss: 0.0016853
[Epoch 14; Iter  1054/ 1862] train: loss: 0.0727169
[Epoch 14; Iter  1084/ 1862] train: loss: 0.0023354
[Epoch 14; Iter  1114/ 1862] train: loss: 0.0014476
[Epoch 14; Iter  1144/ 1862] train: loss: 0.0022878
[Epoch 14; Iter  1174/ 1862] train: loss: 0.0023642
[Epoch 14; Iter  1204/ 1862] train: loss: 0.0021019
[Epoch 14; Iter  1234/ 1862] train: loss: 0.0018497
[Epoch 14; Iter  1264/ 1862] train: loss: 0.0018676
[Epoch 14; Iter  1294/ 1862] train: loss: 0.0018187
[Epoch 14; Iter  1324/ 1862] train: loss: 0.0018721
[Epoch 14; Iter  1354/ 1862] train: loss: 0.0017928
[Epoch 14; Iter  1384/ 1862] train: loss: 0.0628913
[Epoch 14; Iter  1414/ 1862] train: loss: 0.0020454
[Epoch 14; Iter  1444/ 1862] train: loss: 0.0018819
[Epoch 14; Iter  1474/ 1862] train: loss: 0.0022677
[Epoch 14; Iter  1504/ 1862] train: loss: 0.0034582
[Epoch 14; Iter  1534/ 1862] train: loss: 0.0025072
[Epoch 14; Iter  1564/ 1862] train: loss: 0.0590102
[Epoch 14; Iter  1594/ 1862] train: loss: 0.0018577
[Epoch 14; Iter  1624/ 1862] train: loss: 0.0019421
[Epoch 14; Iter  1654/ 1862] train: loss: 0.0009570
[Epoch 14; Iter  1684/ 1862] train: loss: 0.0017895
[Epoch 14; Iter  1714/ 1862] train: loss: 0.1126522
[Epoch 14; Iter  1744/ 1862] train: loss: 0.0018619
[Epoch 14; Iter  1774/ 1862] train: loss: 0.0023367
[Epoch 14; Iter  1804/ 1862] train: loss: 0.0023652
[Epoch 14; Iter  1834/ 1862] train: loss: 0.0017540
[Epoch 14] ogbg-molmuv: 0.015244 val loss: 0.013432
[Epoch 14] ogbg-molmuv: 0.009606 test loss: 0.012568
[Epoch 15; Iter     2/ 1862] train: loss: 0.0019016
[Epoch 15; Iter    32/ 1862] train: loss: 0.0016360
[Epoch 15; Iter    62/ 1862] train: loss: 0.0013533
[Epoch 15; Iter    92/ 1862] train: loss: 0.0015327
[Epoch 15; Iter   122/ 1862] train: loss: 0.0015892
[Epoch 15; Iter   152/ 1862] train: loss: 0.0011745
[Epoch 15; Iter   182/ 1862] train: loss: 0.0012475
[Epoch 13; Iter   396/ 2172] train: loss: 0.0023572
[Epoch 13; Iter   426/ 2172] train: loss: 0.0022686
[Epoch 13; Iter   456/ 2172] train: loss: 0.0020090
[Epoch 13; Iter   486/ 2172] train: loss: 0.0013191
[Epoch 13; Iter   516/ 2172] train: loss: 0.0024370
[Epoch 13; Iter   546/ 2172] train: loss: 0.0014556
[Epoch 13; Iter   576/ 2172] train: loss: 0.0617518
[Epoch 13; Iter   606/ 2172] train: loss: 0.0014888
[Epoch 13; Iter   636/ 2172] train: loss: 0.0013790
[Epoch 13; Iter   666/ 2172] train: loss: 0.0014807
[Epoch 13; Iter   696/ 2172] train: loss: 0.0018704
[Epoch 13; Iter   726/ 2172] train: loss: 0.0015002
[Epoch 13; Iter   756/ 2172] train: loss: 0.0012431
[Epoch 13; Iter   786/ 2172] train: loss: 0.0013225
[Epoch 13; Iter   816/ 2172] train: loss: 0.0012252
[Epoch 13; Iter   846/ 2172] train: loss: 0.0013032
[Epoch 13; Iter   876/ 2172] train: loss: 0.0011169
[Epoch 13; Iter   906/ 2172] train: loss: 0.0015895
[Epoch 13; Iter   936/ 2172] train: loss: 0.0017175
[Epoch 13; Iter   966/ 2172] train: loss: 0.0025871
[Epoch 13; Iter   996/ 2172] train: loss: 0.0029388
[Epoch 13; Iter  1026/ 2172] train: loss: 0.0064001
[Epoch 13; Iter  1056/ 2172] train: loss: 0.0016120
[Epoch 13; Iter  1086/ 2172] train: loss: 0.0364045
[Epoch 13; Iter  1116/ 2172] train: loss: 0.0016373
[Epoch 13; Iter  1146/ 2172] train: loss: 0.0019947
[Epoch 13; Iter  1176/ 2172] train: loss: 0.0014623
[Epoch 13; Iter  1206/ 2172] train: loss: 0.0014338
[Epoch 13; Iter  1236/ 2172] train: loss: 0.0027370
[Epoch 13; Iter  1266/ 2172] train: loss: 0.0014536
[Epoch 13; Iter  1296/ 2172] train: loss: 0.0025709
[Epoch 13; Iter  1326/ 2172] train: loss: 0.0013682
[Epoch 13; Iter  1356/ 2172] train: loss: 0.0016403
[Epoch 13; Iter  1386/ 2172] train: loss: 0.0016508
[Epoch 13; Iter  1416/ 2172] train: loss: 0.0020012
[Epoch 13; Iter  1446/ 2172] train: loss: 0.0028908
[Epoch 13; Iter  1476/ 2172] train: loss: 0.0021060
[Epoch 13; Iter  1506/ 2172] train: loss: 0.0013169
[Epoch 13; Iter  1536/ 2172] train: loss: 0.0023638
[Epoch 13; Iter  1566/ 2172] train: loss: 0.0020271
[Epoch 13; Iter  1596/ 2172] train: loss: 0.0032921
[Epoch 13; Iter  1626/ 2172] train: loss: 0.0017465
[Epoch 13; Iter  1656/ 2172] train: loss: 0.0018092
[Epoch 13; Iter  1686/ 2172] train: loss: 0.0020936
[Epoch 13; Iter  1716/ 2172] train: loss: 0.0018652
[Epoch 13; Iter  1746/ 2172] train: loss: 0.0018498
[Epoch 13; Iter  1776/ 2172] train: loss: 0.0021113
[Epoch 13; Iter  1806/ 2172] train: loss: 0.0011593
[Epoch 13; Iter  1836/ 2172] train: loss: 0.0014335
[Epoch 13; Iter  1866/ 2172] train: loss: 0.0011447
[Epoch 13; Iter  1896/ 2172] train: loss: 0.0008902
[Epoch 13; Iter  1926/ 2172] train: loss: 0.0019633
[Epoch 13; Iter  1956/ 2172] train: loss: 0.0034905
[Epoch 13; Iter  1986/ 2172] train: loss: 0.0017815
[Epoch 13; Iter  2016/ 2172] train: loss: 0.0016013
[Epoch 13; Iter  2046/ 2172] train: loss: 0.0013724
[Epoch 13; Iter  2076/ 2172] train: loss: 0.0017497
[Epoch 13; Iter  2106/ 2172] train: loss: 0.0021073
[Epoch 13; Iter  2136/ 2172] train: loss: 0.0015121
[Epoch 13; Iter  2166/ 2172] train: loss: 0.0037719
[Epoch 13] ogbg-molmuv: 0.063392 val loss: 0.014434
[Epoch 13] ogbg-molmuv: 0.089497 test loss: 0.016395
[Epoch 14; Iter    24/ 2172] train: loss: 0.0019787
[Epoch 14; Iter    54/ 2172] train: loss: 0.0017541
[Epoch 14; Iter    84/ 2172] train: loss: 0.0013408
[Epoch 14; Iter   114/ 2172] train: loss: 0.0015092
[Epoch 14; Iter   144/ 2172] train: loss: 0.0017560
[Epoch 14; Iter   174/ 2172] train: loss: 0.0033437
[Epoch 14; Iter   204/ 2172] train: loss: 0.0023679
[Epoch 14; Iter   234/ 2172] train: loss: 0.0012874
[Epoch 14; Iter   264/ 2172] train: loss: 0.0027269
[Epoch 14; Iter   294/ 2172] train: loss: 0.0018098
[Epoch 14; Iter   324/ 2172] train: loss: 0.0013696
[Epoch 14; Iter   354/ 2172] train: loss: 0.0024738
[Epoch 14; Iter   384/ 2172] train: loss: 0.0019706
[Epoch 14; Iter   414/ 2172] train: loss: 0.0558926
[Epoch 14; Iter   444/ 2172] train: loss: 0.0019096
[Epoch 14; Iter   474/ 2172] train: loss: 0.0021554
[Epoch 14; Iter   504/ 2172] train: loss: 0.0024544
[Epoch 14; Iter   534/ 2172] train: loss: 0.0866481
[Epoch 14; Iter   564/ 2172] train: loss: 0.0031438
[Epoch 14; Iter   594/ 2172] train: loss: 0.0571581
[Epoch 14; Iter   624/ 2172] train: loss: 0.0021252
[Epoch 14; Iter   654/ 2172] train: loss: 0.0029122
[Epoch 14; Iter   684/ 2172] train: loss: 0.0037908
[Epoch 14; Iter   714/ 2172] train: loss: 0.0023500
[Epoch 14; Iter   744/ 2172] train: loss: 0.0030685
[Epoch 14; Iter   774/ 2172] train: loss: 0.0017075
[Epoch 14; Iter   804/ 2172] train: loss: 0.0024634
[Epoch 14; Iter   834/ 2172] train: loss: 0.0017226
[Epoch 14; Iter   864/ 2172] train: loss: 0.0017049
[Epoch 14; Iter   894/ 2172] train: loss: 0.0019202
[Epoch 14; Iter   924/ 2172] train: loss: 0.0013270
[Epoch 14; Iter   954/ 2172] train: loss: 0.0012538
[Epoch 14; Iter   984/ 2172] train: loss: 0.0015614
[Epoch 14; Iter  1014/ 2172] train: loss: 0.0012353
[Epoch 14; Iter  1044/ 2172] train: loss: 0.0011220
[Epoch 14; Iter  1074/ 2172] train: loss: 0.0011097
[Epoch 14; Iter  1104/ 2172] train: loss: 0.0013287
[Epoch 14; Iter  1134/ 2172] train: loss: 0.0010145
[Epoch 14; Iter  1164/ 2172] train: loss: 0.0010658
[Epoch 14; Iter  1194/ 2172] train: loss: 0.0012464
[Epoch 14; Iter  1224/ 2172] train: loss: 0.0015296
[Epoch 14; Iter  1254/ 2172] train: loss: 0.0535131
[Epoch 14; Iter  1284/ 2172] train: loss: 0.0021258
[Epoch 14; Iter  1314/ 2172] train: loss: 0.0015988
[Epoch 14; Iter  1344/ 2172] train: loss: 0.0013762
[Epoch 14; Iter  1374/ 2172] train: loss: 0.0015139
[Epoch 14; Iter  1404/ 2172] train: loss: 0.0970103
[Epoch 14; Iter  1434/ 2172] train: loss: 0.0024913
[Epoch 14; Iter  1464/ 2172] train: loss: 0.0010100
[Epoch 14; Iter  1494/ 2172] train: loss: 0.0720976
[Epoch 14; Iter  1524/ 2172] train: loss: 0.0013722
[Epoch 14; Iter  1554/ 2172] train: loss: 0.0016694
[Epoch 14; Iter  1584/ 2172] train: loss: 0.0013430
[Epoch 14; Iter  1614/ 2172] train: loss: 0.0025070
[Epoch 14; Iter  1644/ 2172] train: loss: 0.0014481
[Epoch 14; Iter  1674/ 2172] train: loss: 0.0015242
[Epoch 14; Iter  1704/ 2172] train: loss: 0.0026753
[Epoch 14; Iter  1734/ 2172] train: loss: 0.0798676
[Epoch 14; Iter  1764/ 2172] train: loss: 0.0610023
[Epoch 14; Iter  1794/ 2172] train: loss: 0.0020455
[Epoch 14; Iter  1824/ 2172] train: loss: 0.0023040
[Epoch 14; Iter  1854/ 2172] train: loss: 0.0025165
[Epoch 14; Iter  1884/ 2172] train: loss: 0.0014604
[Epoch 14; Iter  1914/ 2172] train: loss: 0.0011809
[Epoch 14; Iter  1944/ 2172] train: loss: 0.0024511
[Epoch 14; Iter  1974/ 2172] train: loss: 0.0019237
[Epoch 14; Iter  2004/ 2172] train: loss: 0.0025416
[Epoch 14; Iter  2034/ 2172] train: loss: 0.0018832
[Epoch 14; Iter  2064/ 2172] train: loss: 0.0023077
[Epoch 14; Iter  2094/ 2172] train: loss: 0.0013078
[Epoch 14; Iter  2124/ 2172] train: loss: 0.0014523
[Epoch 14; Iter  2154/ 2172] train: loss: 0.0017924
[Epoch 14] ogbg-molmuv: 0.053172 val loss: 0.011898
[Epoch 14] ogbg-molmuv: 0.052114 test loss: 0.013062
[Epoch 15; Iter    12/ 2172] train: loss: 0.0020230
[Epoch 15; Iter    42/ 2172] train: loss: 0.0016125
[Epoch 15; Iter    72/ 2172] train: loss: 0.0008665
[Epoch 15; Iter   102/ 2172] train: loss: 0.1285898
[Epoch 15; Iter   132/ 2172] train: loss: 0.0013759
[Epoch 15; Iter   162/ 2172] train: loss: 0.0011095
[Epoch 15; Iter   192/ 2172] train: loss: 0.0012391
[Epoch 15; Iter   222/ 2172] train: loss: 0.0019590
[Epoch 15; Iter   252/ 2172] train: loss: 0.0014212
[Epoch 15; Iter   282/ 2172] train: loss: 0.0017411
[Epoch 15; Iter   312/ 2172] train: loss: 0.0016198
[Epoch 15; Iter   342/ 2172] train: loss: 0.0014388
[Epoch 15; Iter   372/ 2172] train: loss: 0.0011785
[Epoch 15; Iter   402/ 2172] train: loss: 0.0017508
[Epoch 15; Iter   432/ 2172] train: loss: 0.0942260
[Epoch 15; Iter   462/ 2172] train: loss: 0.0040043
[Epoch 15; Iter   492/ 2172] train: loss: 0.0017137
[Epoch 15; Iter   522/ 2172] train: loss: 0.0037408
[Epoch 15; Iter   552/ 2172] train: loss: 0.0016645
[Epoch 15; Iter   582/ 2172] train: loss: 0.0016175
[Epoch 15; Iter   612/ 2172] train: loss: 0.0026081
[Epoch 13; Iter   396/ 2172] train: loss: 0.0024702
[Epoch 13; Iter   426/ 2172] train: loss: 0.0017540
[Epoch 13; Iter   456/ 2172] train: loss: 0.0024319
[Epoch 13; Iter   486/ 2172] train: loss: 0.0024045
[Epoch 13; Iter   516/ 2172] train: loss: 0.0837036
[Epoch 13; Iter   546/ 2172] train: loss: 0.0019937
[Epoch 13; Iter   576/ 2172] train: loss: 0.0027452
[Epoch 13; Iter   606/ 2172] train: loss: 0.0041044
[Epoch 13; Iter   636/ 2172] train: loss: 0.0024895
[Epoch 13; Iter   666/ 2172] train: loss: 0.0023938
[Epoch 13; Iter   696/ 2172] train: loss: 0.0692097
[Epoch 13; Iter   726/ 2172] train: loss: 0.0696842
[Epoch 13; Iter   756/ 2172] train: loss: 0.0018975
[Epoch 13; Iter   786/ 2172] train: loss: 0.0020284
[Epoch 13; Iter   816/ 2172] train: loss: 0.0023665
[Epoch 13; Iter   846/ 2172] train: loss: 0.0026233
[Epoch 13; Iter   876/ 2172] train: loss: 0.0020528
[Epoch 13; Iter   906/ 2172] train: loss: 0.0020148
[Epoch 13; Iter   936/ 2172] train: loss: 0.0018143
[Epoch 13; Iter   966/ 2172] train: loss: 0.1391580
[Epoch 13; Iter   996/ 2172] train: loss: 0.0022371
[Epoch 13; Iter  1026/ 2172] train: loss: 0.0017294
[Epoch 13; Iter  1056/ 2172] train: loss: 0.0017283
[Epoch 13; Iter  1086/ 2172] train: loss: 0.0014906
[Epoch 13; Iter  1116/ 2172] train: loss: 0.0012950
[Epoch 13; Iter  1146/ 2172] train: loss: 0.0016709
[Epoch 13; Iter  1176/ 2172] train: loss: 0.0017345
[Epoch 13; Iter  1206/ 2172] train: loss: 0.0029672
[Epoch 13; Iter  1236/ 2172] train: loss: 0.0020418
[Epoch 13; Iter  1266/ 2172] train: loss: 0.0668407
[Epoch 13; Iter  1296/ 2172] train: loss: 0.0017457
[Epoch 13; Iter  1326/ 2172] train: loss: 0.0019196
[Epoch 13; Iter  1356/ 2172] train: loss: 0.0013389
[Epoch 13; Iter  1386/ 2172] train: loss: 0.0021041
[Epoch 13; Iter  1416/ 2172] train: loss: 0.0020073
[Epoch 13; Iter  1446/ 2172] train: loss: 0.0018038
[Epoch 13; Iter  1476/ 2172] train: loss: 0.0017940
[Epoch 13; Iter  1506/ 2172] train: loss: 0.0015605
[Epoch 13; Iter  1536/ 2172] train: loss: 0.0020364
[Epoch 13; Iter  1566/ 2172] train: loss: 0.0016186
[Epoch 13; Iter  1596/ 2172] train: loss: 0.0018514
[Epoch 13; Iter  1626/ 2172] train: loss: 0.0018204
[Epoch 13; Iter  1656/ 2172] train: loss: 0.0018890
[Epoch 13; Iter  1686/ 2172] train: loss: 0.0016435
[Epoch 13; Iter  1716/ 2172] train: loss: 0.0032145
[Epoch 13; Iter  1746/ 2172] train: loss: 0.0023427
[Epoch 13; Iter  1776/ 2172] train: loss: 0.0636096
[Epoch 13; Iter  1806/ 2172] train: loss: 0.0018338
[Epoch 13; Iter  1836/ 2172] train: loss: 0.0014587
[Epoch 13; Iter  1866/ 2172] train: loss: 0.0018592
[Epoch 13; Iter  1896/ 2172] train: loss: 0.0023416
[Epoch 13; Iter  1926/ 2172] train: loss: 0.0013684
[Epoch 13; Iter  1956/ 2172] train: loss: 0.0019845
[Epoch 13; Iter  1986/ 2172] train: loss: 0.0018778
[Epoch 13; Iter  2016/ 2172] train: loss: 0.0785585
[Epoch 13; Iter  2046/ 2172] train: loss: 0.0012815
[Epoch 13; Iter  2076/ 2172] train: loss: 0.0013304
[Epoch 13; Iter  2106/ 2172] train: loss: 0.0015001
[Epoch 13; Iter  2136/ 2172] train: loss: 0.0015482
[Epoch 13; Iter  2166/ 2172] train: loss: 0.0014197
[Epoch 13] ogbg-molmuv: 0.021366 val loss: 0.011880
[Epoch 13] ogbg-molmuv: 0.018143 test loss: 0.013468
[Epoch 14; Iter    24/ 2172] train: loss: 0.0855722
[Epoch 14; Iter    54/ 2172] train: loss: 0.0619101
[Epoch 14; Iter    84/ 2172] train: loss: 0.0946329
[Epoch 14; Iter   114/ 2172] train: loss: 0.0019032
[Epoch 14; Iter   144/ 2172] train: loss: 0.0921046
[Epoch 14; Iter   174/ 2172] train: loss: 0.0021277
[Epoch 14; Iter   204/ 2172] train: loss: 0.0023505
[Epoch 14; Iter   234/ 2172] train: loss: 0.0035215
[Epoch 14; Iter   264/ 2172] train: loss: 0.0015576
[Epoch 14; Iter   294/ 2172] train: loss: 0.0016100
[Epoch 14; Iter   324/ 2172] train: loss: 0.0016752
[Epoch 14; Iter   354/ 2172] train: loss: 0.0016276
[Epoch 14; Iter   384/ 2172] train: loss: 0.0014735
[Epoch 14; Iter   414/ 2172] train: loss: 0.0011413
[Epoch 14; Iter   444/ 2172] train: loss: 0.0782030
[Epoch 14; Iter   474/ 2172] train: loss: 0.0023906
[Epoch 14; Iter   504/ 2172] train: loss: 0.0021413
[Epoch 14; Iter   534/ 2172] train: loss: 0.0022760
[Epoch 14; Iter   564/ 2172] train: loss: 0.0017397
[Epoch 14; Iter   594/ 2172] train: loss: 0.0024924
[Epoch 14; Iter   624/ 2172] train: loss: 0.0028122
[Epoch 14; Iter   654/ 2172] train: loss: 0.0013768
[Epoch 14; Iter   684/ 2172] train: loss: 0.0011868
[Epoch 14; Iter   714/ 2172] train: loss: 0.0782985
[Epoch 14; Iter   744/ 2172] train: loss: 0.0024044
[Epoch 14; Iter   774/ 2172] train: loss: 0.0535601
[Epoch 14; Iter   804/ 2172] train: loss: 0.0026152
[Epoch 14; Iter   834/ 2172] train: loss: 0.0024895
[Epoch 14; Iter   864/ 2172] train: loss: 0.0021856
[Epoch 14; Iter   894/ 2172] train: loss: 0.0019617
[Epoch 14; Iter   924/ 2172] train: loss: 0.0020829
[Epoch 14; Iter   954/ 2172] train: loss: 0.0026882
[Epoch 14; Iter   984/ 2172] train: loss: 0.0015698
[Epoch 14; Iter  1014/ 2172] train: loss: 0.0022762
[Epoch 14; Iter  1044/ 2172] train: loss: 0.0017999
[Epoch 14; Iter  1074/ 2172] train: loss: 0.0020568
[Epoch 14; Iter  1104/ 2172] train: loss: 0.0015599
[Epoch 14; Iter  1134/ 2172] train: loss: 0.0018020
[Epoch 14; Iter  1164/ 2172] train: loss: 0.0015572
[Epoch 14; Iter  1194/ 2172] train: loss: 0.0016260
[Epoch 14; Iter  1224/ 2172] train: loss: 0.0018676
[Epoch 14; Iter  1254/ 2172] train: loss: 0.0018574
[Epoch 14; Iter  1284/ 2172] train: loss: 0.1344516
[Epoch 14; Iter  1314/ 2172] train: loss: 0.0018834
[Epoch 14; Iter  1344/ 2172] train: loss: 0.0015984
[Epoch 14; Iter  1374/ 2172] train: loss: 0.0013889
[Epoch 14; Iter  1404/ 2172] train: loss: 0.0010794
[Epoch 14; Iter  1434/ 2172] train: loss: 0.0013368
[Epoch 14; Iter  1464/ 2172] train: loss: 0.0015966
[Epoch 14; Iter  1494/ 2172] train: loss: 0.0012178
[Epoch 14; Iter  1524/ 2172] train: loss: 0.0017744
[Epoch 14; Iter  1554/ 2172] train: loss: 0.0024285
[Epoch 14; Iter  1584/ 2172] train: loss: 0.0014404
[Epoch 14; Iter  1614/ 2172] train: loss: 0.0020014
[Epoch 14; Iter  1644/ 2172] train: loss: 0.0045846
[Epoch 14; Iter  1674/ 2172] train: loss: 0.0024774
[Epoch 14; Iter  1704/ 2172] train: loss: 0.0024794
[Epoch 14; Iter  1734/ 2172] train: loss: 0.0059673
[Epoch 14; Iter  1764/ 2172] train: loss: 0.0035460
[Epoch 14; Iter  1794/ 2172] train: loss: 0.0035110
[Epoch 14; Iter  1824/ 2172] train: loss: 0.0018256
[Epoch 14; Iter  1854/ 2172] train: loss: 0.0017816
[Epoch 14; Iter  1884/ 2172] train: loss: 0.0016429
[Epoch 14; Iter  1914/ 2172] train: loss: 0.0016737
[Epoch 14; Iter  1944/ 2172] train: loss: 0.0016423
[Epoch 14; Iter  1974/ 2172] train: loss: 0.0035842
[Epoch 14; Iter  2004/ 2172] train: loss: 0.0017879
[Epoch 14; Iter  2034/ 2172] train: loss: 0.0016551
[Epoch 14; Iter  2064/ 2172] train: loss: 0.0015389
[Epoch 14; Iter  2094/ 2172] train: loss: 0.0016261
[Epoch 14; Iter  2124/ 2172] train: loss: 0.0029645
[Epoch 14; Iter  2154/ 2172] train: loss: 0.0019053
[Epoch 14] ogbg-molmuv: 0.029613 val loss: 0.012087
[Epoch 14] ogbg-molmuv: 0.016637 test loss: 0.013436
[Epoch 15; Iter    12/ 2172] train: loss: 0.0014492
[Epoch 15; Iter    42/ 2172] train: loss: 0.0015089
[Epoch 15; Iter    72/ 2172] train: loss: 0.0015318
[Epoch 15; Iter   102/ 2172] train: loss: 0.0010763
[Epoch 15; Iter   132/ 2172] train: loss: 0.0642834
[Epoch 15; Iter   162/ 2172] train: loss: 0.0016267
[Epoch 15; Iter   192/ 2172] train: loss: 0.0013896
[Epoch 15; Iter   222/ 2172] train: loss: 0.0013977
[Epoch 15; Iter   252/ 2172] train: loss: 0.0017619
[Epoch 15; Iter   282/ 2172] train: loss: 0.0019213
[Epoch 15; Iter   312/ 2172] train: loss: 0.0027107
[Epoch 15; Iter   342/ 2172] train: loss: 0.0686080
[Epoch 15; Iter   372/ 2172] train: loss: 0.0016963
[Epoch 15; Iter   402/ 2172] train: loss: 0.0928477
[Epoch 15; Iter   432/ 2172] train: loss: 0.0014729
[Epoch 15; Iter   462/ 2172] train: loss: 0.0014347
[Epoch 15; Iter   492/ 2172] train: loss: 0.0018456
[Epoch 15; Iter   522/ 2172] train: loss: 0.0015983
[Epoch 15; Iter   552/ 2172] train: loss: 0.1739359
[Epoch 15; Iter   582/ 2172] train: loss: 0.0011125
[Epoch 15; Iter   612/ 2172] train: loss: 0.0016693
[Epoch 13; Iter   396/ 2172] train: loss: 0.0023866
[Epoch 13; Iter   426/ 2172] train: loss: 0.0016104
[Epoch 13; Iter   456/ 2172] train: loss: 0.1193798
[Epoch 13; Iter   486/ 2172] train: loss: 0.0015597
[Epoch 13; Iter   516/ 2172] train: loss: 0.0020025
[Epoch 13; Iter   546/ 2172] train: loss: 0.0024119
[Epoch 13; Iter   576/ 2172] train: loss: 0.0016905
[Epoch 13; Iter   606/ 2172] train: loss: 0.0026874
[Epoch 13; Iter   636/ 2172] train: loss: 0.0022497
[Epoch 13; Iter   666/ 2172] train: loss: 0.0016590
[Epoch 13; Iter   696/ 2172] train: loss: 0.0570787
[Epoch 13; Iter   726/ 2172] train: loss: 0.0025885
[Epoch 13; Iter   756/ 2172] train: loss: 0.0679543
[Epoch 13; Iter   786/ 2172] train: loss: 0.0041675
[Epoch 13; Iter   816/ 2172] train: loss: 0.0019159
[Epoch 13; Iter   846/ 2172] train: loss: 0.0019074
[Epoch 13; Iter   876/ 2172] train: loss: 0.1156952
[Epoch 13; Iter   906/ 2172] train: loss: 0.0014578
[Epoch 13; Iter   936/ 2172] train: loss: 0.0016924
[Epoch 13; Iter   966/ 2172] train: loss: 0.0018943
[Epoch 13; Iter   996/ 2172] train: loss: 0.0015127
[Epoch 13; Iter  1026/ 2172] train: loss: 0.0016132
[Epoch 13; Iter  1056/ 2172] train: loss: 0.0014177
[Epoch 13; Iter  1086/ 2172] train: loss: 0.0015519
[Epoch 13; Iter  1116/ 2172] train: loss: 0.0023027
[Epoch 13; Iter  1146/ 2172] train: loss: 0.0016668
[Epoch 13; Iter  1176/ 2172] train: loss: 0.0016318
[Epoch 13; Iter  1206/ 2172] train: loss: 0.0012922
[Epoch 13; Iter  1236/ 2172] train: loss: 0.0011279
[Epoch 13; Iter  1266/ 2172] train: loss: 0.0017027
[Epoch 13; Iter  1296/ 2172] train: loss: 0.0017041
[Epoch 13; Iter  1326/ 2172] train: loss: 0.0023762
[Epoch 13; Iter  1356/ 2172] train: loss: 0.0859005
[Epoch 13; Iter  1386/ 2172] train: loss: 0.0020603
[Epoch 13; Iter  1416/ 2172] train: loss: 0.0017741
[Epoch 13; Iter  1446/ 2172] train: loss: 0.0018405
[Epoch 13; Iter  1476/ 2172] train: loss: 0.0026859
[Epoch 13; Iter  1506/ 2172] train: loss: 0.0031699
[Epoch 13; Iter  1536/ 2172] train: loss: 0.0025473
[Epoch 13; Iter  1566/ 2172] train: loss: 0.0016059
[Epoch 13; Iter  1596/ 2172] train: loss: 0.0013713
[Epoch 13; Iter  1626/ 2172] train: loss: 0.0038923
[Epoch 13; Iter  1656/ 2172] train: loss: 0.0016753
[Epoch 13; Iter  1686/ 2172] train: loss: 0.0022909
[Epoch 13; Iter  1716/ 2172] train: loss: 0.0023283
[Epoch 13; Iter  1746/ 2172] train: loss: 0.0022140
[Epoch 13; Iter  1776/ 2172] train: loss: 0.0025315
[Epoch 13; Iter  1806/ 2172] train: loss: 0.0014169
[Epoch 13; Iter  1836/ 2172] train: loss: 0.0016025
[Epoch 13; Iter  1866/ 2172] train: loss: 0.0029120
[Epoch 13; Iter  1896/ 2172] train: loss: 0.0026530
[Epoch 13; Iter  1926/ 2172] train: loss: 0.0017097
[Epoch 13; Iter  1956/ 2172] train: loss: 0.0015959
[Epoch 13; Iter  1986/ 2172] train: loss: 0.0016414
[Epoch 13; Iter  2016/ 2172] train: loss: 0.0932605
[Epoch 13; Iter  2046/ 2172] train: loss: 0.0014245
[Epoch 13; Iter  2076/ 2172] train: loss: 0.0015926
[Epoch 13; Iter  2106/ 2172] train: loss: 0.0747883
[Epoch 13; Iter  2136/ 2172] train: loss: 0.0051529
[Epoch 13; Iter  2166/ 2172] train: loss: 0.0009592
[Epoch 13] ogbg-molmuv: 0.039616 val loss: 0.011593
[Epoch 13] ogbg-molmuv: 0.073895 test loss: 0.012866
[Epoch 14; Iter    24/ 2172] train: loss: 0.0015083
[Epoch 14; Iter    54/ 2172] train: loss: 0.0016421
[Epoch 14; Iter    84/ 2172] train: loss: 0.0020340
[Epoch 14; Iter   114/ 2172] train: loss: 0.0009492
[Epoch 14; Iter   144/ 2172] train: loss: 0.0018349
[Epoch 14; Iter   174/ 2172] train: loss: 0.0013233
[Epoch 14; Iter   204/ 2172] train: loss: 0.0034996
[Epoch 14; Iter   234/ 2172] train: loss: 0.0025114
[Epoch 14; Iter   264/ 2172] train: loss: 0.0017507
[Epoch 14; Iter   294/ 2172] train: loss: 0.0013538
[Epoch 14; Iter   324/ 2172] train: loss: 0.0843578
[Epoch 14; Iter   354/ 2172] train: loss: 0.0022353
[Epoch 14; Iter   384/ 2172] train: loss: 0.0474897
[Epoch 14; Iter   414/ 2172] train: loss: 0.0048305
[Epoch 14; Iter   444/ 2172] train: loss: 0.0588317
[Epoch 14; Iter   474/ 2172] train: loss: 0.0017629
[Epoch 14; Iter   504/ 2172] train: loss: 0.0008832
[Epoch 14; Iter   534/ 2172] train: loss: 0.0013427
[Epoch 14; Iter   564/ 2172] train: loss: 0.0012136
[Epoch 14; Iter   594/ 2172] train: loss: 0.0744325
[Epoch 14; Iter   624/ 2172] train: loss: 0.0019919
[Epoch 14; Iter   654/ 2172] train: loss: 0.0834763
[Epoch 14; Iter   684/ 2172] train: loss: 0.0023544
[Epoch 14; Iter   714/ 2172] train: loss: 0.0013020
[Epoch 14; Iter   744/ 2172] train: loss: 0.0039723
[Epoch 14; Iter   774/ 2172] train: loss: 0.0029777
[Epoch 14; Iter   804/ 2172] train: loss: 0.0026781
[Epoch 14; Iter   834/ 2172] train: loss: 0.0017349
[Epoch 14; Iter   864/ 2172] train: loss: 0.0020031
[Epoch 14; Iter   894/ 2172] train: loss: 0.0033036
[Epoch 14; Iter   924/ 2172] train: loss: 0.0030424
[Epoch 14; Iter   954/ 2172] train: loss: 0.0027310
[Epoch 14; Iter   984/ 2172] train: loss: 0.0022696
[Epoch 14; Iter  1014/ 2172] train: loss: 0.0017239
[Epoch 14; Iter  1044/ 2172] train: loss: 0.0019818
[Epoch 14; Iter  1074/ 2172] train: loss: 0.0015029
[Epoch 14; Iter  1104/ 2172] train: loss: 0.0795498
[Epoch 14; Iter  1134/ 2172] train: loss: 0.0823774
[Epoch 14; Iter  1164/ 2172] train: loss: 0.0019621
[Epoch 14; Iter  1194/ 2172] train: loss: 0.0020841
[Epoch 14; Iter  1224/ 2172] train: loss: 0.0022677
[Epoch 14; Iter  1254/ 2172] train: loss: 0.0040874
[Epoch 14; Iter  1284/ 2172] train: loss: 0.0036420
[Epoch 14; Iter  1314/ 2172] train: loss: 0.0032049
[Epoch 14; Iter  1344/ 2172] train: loss: 0.0036126
[Epoch 14; Iter  1374/ 2172] train: loss: 0.0992231
[Epoch 14; Iter  1404/ 2172] train: loss: 0.0014621
[Epoch 14; Iter  1434/ 2172] train: loss: 0.0918767
[Epoch 14; Iter  1464/ 2172] train: loss: 0.0030465
[Epoch 14; Iter  1494/ 2172] train: loss: 0.1654383
[Epoch 14; Iter  1524/ 2172] train: loss: 0.0029031
[Epoch 14; Iter  1554/ 2172] train: loss: 0.0020197
[Epoch 14; Iter  1584/ 2172] train: loss: 0.0014623
[Epoch 14; Iter  1614/ 2172] train: loss: 0.0045860
[Epoch 14; Iter  1644/ 2172] train: loss: 0.0021818
[Epoch 14; Iter  1674/ 2172] train: loss: 0.0016072
[Epoch 14; Iter  1704/ 2172] train: loss: 0.0014575
[Epoch 14; Iter  1734/ 2172] train: loss: 0.0021572
[Epoch 14; Iter  1764/ 2172] train: loss: 0.0523243
[Epoch 14; Iter  1794/ 2172] train: loss: 0.0028046
[Epoch 14; Iter  1824/ 2172] train: loss: 0.0024594
[Epoch 14; Iter  1854/ 2172] train: loss: 0.0886087
[Epoch 14; Iter  1884/ 2172] train: loss: 0.0018586
[Epoch 14; Iter  1914/ 2172] train: loss: 0.0017466
[Epoch 14; Iter  1944/ 2172] train: loss: 0.0616484
[Epoch 14; Iter  1974/ 2172] train: loss: 0.0020962
[Epoch 14; Iter  2004/ 2172] train: loss: 0.0022206
[Epoch 14; Iter  2034/ 2172] train: loss: 0.0018759
[Epoch 14; Iter  2064/ 2172] train: loss: 0.0020274
[Epoch 14; Iter  2094/ 2172] train: loss: 0.0014815
[Epoch 14; Iter  2124/ 2172] train: loss: 0.0019558
[Epoch 14; Iter  2154/ 2172] train: loss: 0.0018325
[Epoch 14] ogbg-molmuv: 0.033423 val loss: 0.011760
[Epoch 14] ogbg-molmuv: 0.065469 test loss: 0.013265
[Epoch 15; Iter    12/ 2172] train: loss: 0.0016874
[Epoch 15; Iter    42/ 2172] train: loss: 0.0013573
[Epoch 15; Iter    72/ 2172] train: loss: 0.0011995
[Epoch 15; Iter   102/ 2172] train: loss: 0.0009656
[Epoch 15; Iter   132/ 2172] train: loss: 0.0009746
[Epoch 15; Iter   162/ 2172] train: loss: 0.1464408
[Epoch 15; Iter   192/ 2172] train: loss: 0.0020102
[Epoch 15; Iter   222/ 2172] train: loss: 0.0021965
[Epoch 15; Iter   252/ 2172] train: loss: 0.0026185
[Epoch 15; Iter   282/ 2172] train: loss: 0.0014034
[Epoch 15; Iter   312/ 2172] train: loss: 0.0015050
[Epoch 15; Iter   342/ 2172] train: loss: 0.0015087
[Epoch 15; Iter   372/ 2172] train: loss: 0.0015583
[Epoch 15; Iter   402/ 2172] train: loss: 0.0016846
[Epoch 15; Iter   432/ 2172] train: loss: 0.0016546
[Epoch 15; Iter   462/ 2172] train: loss: 0.0639745
[Epoch 15; Iter   492/ 2172] train: loss: 0.0011891
[Epoch 15; Iter   522/ 2172] train: loss: 0.0566437
[Epoch 15; Iter   552/ 2172] train: loss: 0.0017648
[Epoch 15; Iter   582/ 2172] train: loss: 0.0015462
[Epoch 15; Iter   612/ 2172] train: loss: 0.0018826
[Epoch 13; Iter  1404/ 2483] train: loss: 0.0018407
[Epoch 13; Iter  1434/ 2483] train: loss: 0.0015880
[Epoch 13; Iter  1464/ 2483] train: loss: 0.0016801
[Epoch 13; Iter  1494/ 2483] train: loss: 0.0025236
[Epoch 13; Iter  1524/ 2483] train: loss: 0.0016965
[Epoch 13; Iter  1554/ 2483] train: loss: 0.0026452
[Epoch 13; Iter  1584/ 2483] train: loss: 0.0016282
[Epoch 13; Iter  1614/ 2483] train: loss: 0.0015101
[Epoch 13; Iter  1644/ 2483] train: loss: 0.0069284
[Epoch 13; Iter  1674/ 2483] train: loss: 0.0018599
[Epoch 13; Iter  1704/ 2483] train: loss: 0.1324775
[Epoch 13; Iter  1734/ 2483] train: loss: 0.0023495
[Epoch 13; Iter  1764/ 2483] train: loss: 0.1603548
[Epoch 13; Iter  1794/ 2483] train: loss: 0.0022290
[Epoch 13; Iter  1824/ 2483] train: loss: 0.0871306
[Epoch 13; Iter  1854/ 2483] train: loss: 0.0015620
[Epoch 13; Iter  1884/ 2483] train: loss: 0.0020660
[Epoch 13; Iter  1914/ 2483] train: loss: 0.0013434
[Epoch 13; Iter  1944/ 2483] train: loss: 0.0021006
[Epoch 13; Iter  1974/ 2483] train: loss: 0.0010060
[Epoch 13; Iter  2004/ 2483] train: loss: 0.0011700
[Epoch 13; Iter  2034/ 2483] train: loss: 0.0589409
[Epoch 13; Iter  2064/ 2483] train: loss: 0.0020366
[Epoch 13; Iter  2094/ 2483] train: loss: 0.0016362
[Epoch 13; Iter  2124/ 2483] train: loss: 0.0017640
[Epoch 13; Iter  2154/ 2483] train: loss: 0.0023105
[Epoch 13; Iter  2184/ 2483] train: loss: 0.0396056
[Epoch 13; Iter  2214/ 2483] train: loss: 0.0020627
[Epoch 13; Iter  2244/ 2483] train: loss: 0.0017877
[Epoch 13; Iter  2274/ 2483] train: loss: 0.0025099
[Epoch 13; Iter  2304/ 2483] train: loss: 0.0023285
[Epoch 13; Iter  2334/ 2483] train: loss: 0.0033924
[Epoch 13; Iter  2364/ 2483] train: loss: 0.0016787
[Epoch 13; Iter  2394/ 2483] train: loss: 0.0016632
[Epoch 13; Iter  2424/ 2483] train: loss: 0.0014082
[Epoch 13; Iter  2454/ 2483] train: loss: 0.0021830
[Epoch 13] ogbg-molmuv: 0.041000 val loss: 0.084838
[Epoch 13] ogbg-molmuv: 0.038073 test loss: 0.067600
[Epoch 14; Iter     1/ 2483] train: loss: 0.0017185
[Epoch 14; Iter    31/ 2483] train: loss: 0.0016246
[Epoch 14; Iter    61/ 2483] train: loss: 0.0733759
[Epoch 14; Iter    91/ 2483] train: loss: 0.0014067
[Epoch 14; Iter   121/ 2483] train: loss: 0.0756243
[Epoch 14; Iter   151/ 2483] train: loss: 0.0021462
[Epoch 14; Iter   181/ 2483] train: loss: 0.0022787
[Epoch 14; Iter   211/ 2483] train: loss: 0.0021226
[Epoch 14; Iter   241/ 2483] train: loss: 0.0011588
[Epoch 14; Iter   271/ 2483] train: loss: 0.0015457
[Epoch 14; Iter   301/ 2483] train: loss: 0.0015578
[Epoch 14; Iter   331/ 2483] train: loss: 0.0013917
[Epoch 14; Iter   361/ 2483] train: loss: 0.0016485
[Epoch 14; Iter   391/ 2483] train: loss: 0.0015359
[Epoch 14; Iter   421/ 2483] train: loss: 0.0017958
[Epoch 14; Iter   451/ 2483] train: loss: 0.0013973
[Epoch 14; Iter   481/ 2483] train: loss: 0.0712705
[Epoch 14; Iter   511/ 2483] train: loss: 0.0014208
[Epoch 14; Iter   541/ 2483] train: loss: 0.0016886
[Epoch 14; Iter   571/ 2483] train: loss: 0.0014340
[Epoch 14; Iter   601/ 2483] train: loss: 0.0015338
[Epoch 14; Iter   631/ 2483] train: loss: 0.0967261
[Epoch 14; Iter   661/ 2483] train: loss: 0.0013634
[Epoch 14; Iter   691/ 2483] train: loss: 0.0018062
[Epoch 14; Iter   721/ 2483] train: loss: 0.0016867
[Epoch 14; Iter   751/ 2483] train: loss: 0.0015712
[Epoch 14; Iter   781/ 2483] train: loss: 0.0024192
[Epoch 14; Iter   811/ 2483] train: loss: 0.0025207
[Epoch 14; Iter   841/ 2483] train: loss: 0.0021704
[Epoch 14; Iter   871/ 2483] train: loss: 0.0018462
[Epoch 14; Iter   901/ 2483] train: loss: 0.0019748
[Epoch 14; Iter   931/ 2483] train: loss: 0.0621417
[Epoch 14; Iter   961/ 2483] train: loss: 0.0021757
[Epoch 14; Iter   991/ 2483] train: loss: 0.0022977
[Epoch 14; Iter  1021/ 2483] train: loss: 0.0022021
[Epoch 14; Iter  1051/ 2483] train: loss: 0.1309226
[Epoch 14; Iter  1081/ 2483] train: loss: 0.0017233
[Epoch 14; Iter  1111/ 2483] train: loss: 0.0735544
[Epoch 14; Iter  1141/ 2483] train: loss: 0.0024894
[Epoch 14; Iter  1171/ 2483] train: loss: 0.0024382
[Epoch 14; Iter  1201/ 2483] train: loss: 0.0023264
[Epoch 14; Iter  1231/ 2483] train: loss: 0.0019233
[Epoch 14; Iter  1261/ 2483] train: loss: 0.0020048
[Epoch 14; Iter  1291/ 2483] train: loss: 0.0010411
[Epoch 14; Iter  1321/ 2483] train: loss: 0.0022316
[Epoch 14; Iter  1351/ 2483] train: loss: 0.0013215
[Epoch 14; Iter  1381/ 2483] train: loss: 0.0714315
[Epoch 14; Iter  1411/ 2483] train: loss: 0.0025708
[Epoch 14; Iter  1441/ 2483] train: loss: 0.0020449
[Epoch 14; Iter  1471/ 2483] train: loss: 0.0019757
[Epoch 14; Iter  1501/ 2483] train: loss: 0.0015471
[Epoch 14; Iter  1531/ 2483] train: loss: 0.0022232
[Epoch 14; Iter  1561/ 2483] train: loss: 0.0020195
[Epoch 14; Iter  1591/ 2483] train: loss: 0.0017799
[Epoch 14; Iter  1621/ 2483] train: loss: 0.0020617
[Epoch 14; Iter  1651/ 2483] train: loss: 0.0020806
[Epoch 14; Iter  1681/ 2483] train: loss: 0.0021187
[Epoch 14; Iter  1711/ 2483] train: loss: 0.0015076
[Epoch 14; Iter  1741/ 2483] train: loss: 0.0029496
[Epoch 14; Iter  1771/ 2483] train: loss: 0.0018827
[Epoch 14; Iter  1801/ 2483] train: loss: 0.0030426
[Epoch 14; Iter  1831/ 2483] train: loss: 0.0014080
[Epoch 14; Iter  1861/ 2483] train: loss: 0.0013084
[Epoch 14; Iter  1891/ 2483] train: loss: 0.0013679
[Epoch 14; Iter  1921/ 2483] train: loss: 0.0012555
[Epoch 14; Iter  1951/ 2483] train: loss: 0.0013290
[Epoch 14; Iter  1981/ 2483] train: loss: 0.0014540
[Epoch 14; Iter  2011/ 2483] train: loss: 0.0214281
[Epoch 14; Iter  2041/ 2483] train: loss: 0.0015062
[Epoch 14; Iter  2071/ 2483] train: loss: 0.0015741
[Epoch 14; Iter  2101/ 2483] train: loss: 0.0903421
[Epoch 14; Iter  2131/ 2483] train: loss: 0.0030827
[Epoch 14; Iter  2161/ 2483] train: loss: 0.0020171
[Epoch 14; Iter  2191/ 2483] train: loss: 0.2174761
[Epoch 14; Iter  2221/ 2483] train: loss: 0.0015887
[Epoch 14; Iter  2251/ 2483] train: loss: 0.0016021
[Epoch 14; Iter  2281/ 2483] train: loss: 0.0014416
[Epoch 14; Iter  2311/ 2483] train: loss: 0.0018603
[Epoch 14; Iter  2341/ 2483] train: loss: 0.0021088
[Epoch 14; Iter  2371/ 2483] train: loss: 0.0016763
[Epoch 14; Iter  2401/ 2483] train: loss: 0.0017741
[Epoch 14; Iter  2431/ 2483] train: loss: 0.0019293
[Epoch 14; Iter  2461/ 2483] train: loss: 0.0022231
[Epoch 14] ogbg-molmuv: 0.048359 val loss: 0.013375
[Epoch 14] ogbg-molmuv: 0.071445 test loss: 0.013767
[Epoch 15; Iter     8/ 2483] train: loss: 0.0027835
[Epoch 15; Iter    38/ 2483] train: loss: 0.0039640
[Epoch 15; Iter    68/ 2483] train: loss: 0.0021381
[Epoch 15; Iter    98/ 2483] train: loss: 0.0023432
[Epoch 15; Iter   128/ 2483] train: loss: 0.0018204
[Epoch 15; Iter   158/ 2483] train: loss: 0.0795143
[Epoch 15; Iter   188/ 2483] train: loss: 0.0022507
[Epoch 15; Iter   218/ 2483] train: loss: 0.0018653
[Epoch 15; Iter   248/ 2483] train: loss: 0.0016902
[Epoch 15; Iter   278/ 2483] train: loss: 0.0018795
[Epoch 15; Iter   308/ 2483] train: loss: 0.0022314
[Epoch 15; Iter   338/ 2483] train: loss: 0.0022109
[Epoch 15; Iter   368/ 2483] train: loss: 0.0019260
[Epoch 15; Iter   398/ 2483] train: loss: 0.0018687
[Epoch 15; Iter   428/ 2483] train: loss: 0.0016666
[Epoch 15; Iter   458/ 2483] train: loss: 0.0022182
[Epoch 15; Iter   488/ 2483] train: loss: 0.0022783
[Epoch 15; Iter   518/ 2483] train: loss: 0.0027677
[Epoch 15; Iter   548/ 2483] train: loss: 0.0038291
[Epoch 15; Iter   578/ 2483] train: loss: 0.0022269
[Epoch 15; Iter   608/ 2483] train: loss: 0.0021831
[Epoch 15; Iter   638/ 2483] train: loss: 0.0022324
[Epoch 15; Iter   668/ 2483] train: loss: 0.0013915
[Epoch 15; Iter   698/ 2483] train: loss: 0.0023211
[Epoch 15; Iter   728/ 2483] train: loss: 0.0014376
[Epoch 15; Iter   758/ 2483] train: loss: 0.0088456
[Epoch 15; Iter   788/ 2483] train: loss: 0.0021611
[Epoch 15; Iter   818/ 2483] train: loss: 0.0632220
[Epoch 15; Iter   848/ 2483] train: loss: 0.0017694
[Epoch 15; Iter   878/ 2483] train: loss: 0.0027275
[Epoch 15; Iter   908/ 2483] train: loss: 0.0021453
[Epoch 15; Iter   938/ 2483] train: loss: 0.0015571
[Epoch 15; Iter   968/ 2483] train: loss: 0.0016620
[Epoch 15; Iter   998/ 2483] train: loss: 0.0013804
[Epoch 13; Iter  1404/ 2483] train: loss: 0.0019399
[Epoch 13; Iter  1434/ 2483] train: loss: 0.0845567
[Epoch 13; Iter  1464/ 2483] train: loss: 0.0018725
[Epoch 13; Iter  1494/ 2483] train: loss: 0.0015445
[Epoch 13; Iter  1524/ 2483] train: loss: 0.0013905
[Epoch 13; Iter  1554/ 2483] train: loss: 0.0017520
[Epoch 13; Iter  1584/ 2483] train: loss: 0.0017410
[Epoch 13; Iter  1614/ 2483] train: loss: 0.0016965
[Epoch 13; Iter  1644/ 2483] train: loss: 0.0019390
[Epoch 13; Iter  1674/ 2483] train: loss: 0.0704303
[Epoch 13; Iter  1704/ 2483] train: loss: 0.0550722
[Epoch 13; Iter  1734/ 2483] train: loss: 0.1246476
[Epoch 13; Iter  1764/ 2483] train: loss: 0.0024370
[Epoch 13; Iter  1794/ 2483] train: loss: 0.0894104
[Epoch 13; Iter  1824/ 2483] train: loss: 0.0025811
[Epoch 13; Iter  1854/ 2483] train: loss: 0.0914967
[Epoch 13; Iter  1884/ 2483] train: loss: 0.0614344
[Epoch 13; Iter  1914/ 2483] train: loss: 0.0013136
[Epoch 13; Iter  1944/ 2483] train: loss: 0.0017508
[Epoch 13; Iter  1974/ 2483] train: loss: 0.0015062
[Epoch 13; Iter  2004/ 2483] train: loss: 0.0024621
[Epoch 13; Iter  2034/ 2483] train: loss: 0.0018581
[Epoch 13; Iter  2064/ 2483] train: loss: 0.0023042
[Epoch 13; Iter  2094/ 2483] train: loss: 0.0032335
[Epoch 13; Iter  2124/ 2483] train: loss: 0.0025195
[Epoch 13; Iter  2154/ 2483] train: loss: 0.0011219
[Epoch 13; Iter  2184/ 2483] train: loss: 0.0020337
[Epoch 13; Iter  2214/ 2483] train: loss: 0.0013266
[Epoch 13; Iter  2244/ 2483] train: loss: 0.0010982
[Epoch 13; Iter  2274/ 2483] train: loss: 0.0762245
[Epoch 13; Iter  2304/ 2483] train: loss: 0.1407098
[Epoch 13; Iter  2334/ 2483] train: loss: 0.0021242
[Epoch 13; Iter  2364/ 2483] train: loss: 0.0022505
[Epoch 13; Iter  2394/ 2483] train: loss: 0.0011449
[Epoch 13; Iter  2424/ 2483] train: loss: 0.0021780
[Epoch 13; Iter  2454/ 2483] train: loss: 0.0020707
[Epoch 13] ogbg-molmuv: 0.046015 val loss: 0.009665
[Epoch 13] ogbg-molmuv: 0.039725 test loss: 0.014373
[Epoch 14; Iter     1/ 2483] train: loss: 0.0024574
[Epoch 14; Iter    31/ 2483] train: loss: 0.0015013
[Epoch 14; Iter    61/ 2483] train: loss: 0.0013103
[Epoch 14; Iter    91/ 2483] train: loss: 0.0540724
[Epoch 14; Iter   121/ 2483] train: loss: 0.0014072
[Epoch 14; Iter   151/ 2483] train: loss: 0.0015412
[Epoch 14; Iter   181/ 2483] train: loss: 0.0023510
[Epoch 14; Iter   211/ 2483] train: loss: 0.0024454
[Epoch 14; Iter   241/ 2483] train: loss: 0.0031759
[Epoch 14; Iter   271/ 2483] train: loss: 0.0025097
[Epoch 14; Iter   301/ 2483] train: loss: 0.0016882
[Epoch 14; Iter   331/ 2483] train: loss: 0.0017566
[Epoch 14; Iter   361/ 2483] train: loss: 0.0026002
[Epoch 14; Iter   391/ 2483] train: loss: 0.0027408
[Epoch 14; Iter   421/ 2483] train: loss: 0.0018712
[Epoch 14; Iter   451/ 2483] train: loss: 0.0593799
[Epoch 14; Iter   481/ 2483] train: loss: 0.0022486
[Epoch 14; Iter   511/ 2483] train: loss: 0.0744444
[Epoch 14; Iter   541/ 2483] train: loss: 0.0600507
[Epoch 14; Iter   571/ 2483] train: loss: 0.0014327
[Epoch 14; Iter   601/ 2483] train: loss: 0.0024048
[Epoch 14; Iter   631/ 2483] train: loss: 0.0019288
[Epoch 14; Iter   661/ 2483] train: loss: 0.1153868
[Epoch 14; Iter   691/ 2483] train: loss: 0.0015933
[Epoch 14; Iter   721/ 2483] train: loss: 0.0021876
[Epoch 14; Iter   751/ 2483] train: loss: 0.0023614
[Epoch 14; Iter   781/ 2483] train: loss: 0.0021549
[Epoch 14; Iter   811/ 2483] train: loss: 0.0634410
[Epoch 14; Iter   841/ 2483] train: loss: 0.0023060
[Epoch 14; Iter   871/ 2483] train: loss: 0.0907750
[Epoch 14; Iter   901/ 2483] train: loss: 0.0023027
[Epoch 14; Iter   931/ 2483] train: loss: 0.0025186
[Epoch 14; Iter   961/ 2483] train: loss: 0.0026991
[Epoch 14; Iter   991/ 2483] train: loss: 0.0020681
[Epoch 14; Iter  1021/ 2483] train: loss: 0.0022820
[Epoch 14; Iter  1051/ 2483] train: loss: 0.0022806
[Epoch 14; Iter  1081/ 2483] train: loss: 0.0024557
[Epoch 14; Iter  1111/ 2483] train: loss: 0.0026375
[Epoch 14; Iter  1141/ 2483] train: loss: 0.0024170
[Epoch 14; Iter  1171/ 2483] train: loss: 0.0024483
[Epoch 14; Iter  1201/ 2483] train: loss: 0.0026959
[Epoch 14; Iter  1231/ 2483] train: loss: 0.0495282
[Epoch 14; Iter  1261/ 2483] train: loss: 0.0024606
[Epoch 14; Iter  1291/ 2483] train: loss: 0.0016299
[Epoch 14; Iter  1321/ 2483] train: loss: 0.0016945
[Epoch 14; Iter  1351/ 2483] train: loss: 0.0011462
[Epoch 14; Iter  1381/ 2483] train: loss: 0.0017875
[Epoch 14; Iter  1411/ 2483] train: loss: 0.0021934
[Epoch 14; Iter  1441/ 2483] train: loss: 0.0018233
[Epoch 14; Iter  1471/ 2483] train: loss: 0.0023903
[Epoch 14; Iter  1501/ 2483] train: loss: 0.0019256
[Epoch 14; Iter  1531/ 2483] train: loss: 0.0022163
[Epoch 14; Iter  1561/ 2483] train: loss: 0.0013191
[Epoch 14; Iter  1591/ 2483] train: loss: 0.0016237
[Epoch 14; Iter  1621/ 2483] train: loss: 0.0026329
[Epoch 14; Iter  1651/ 2483] train: loss: 0.0019139
[Epoch 14; Iter  1681/ 2483] train: loss: 0.0020685
[Epoch 14; Iter  1711/ 2483] train: loss: 0.0822200
[Epoch 14; Iter  1741/ 2483] train: loss: 0.0013415
[Epoch 14; Iter  1771/ 2483] train: loss: 0.0013761
[Epoch 14; Iter  1801/ 2483] train: loss: 0.0024586
[Epoch 14; Iter  1831/ 2483] train: loss: 0.0018944
[Epoch 14; Iter  1861/ 2483] train: loss: 0.0016912
[Epoch 14; Iter  1891/ 2483] train: loss: 0.0020757
[Epoch 14; Iter  1921/ 2483] train: loss: 0.0808772
[Epoch 14; Iter  1951/ 2483] train: loss: 0.0017705
[Epoch 14; Iter  1981/ 2483] train: loss: 0.0020359
[Epoch 14; Iter  2011/ 2483] train: loss: 0.0023472
[Epoch 14; Iter  2041/ 2483] train: loss: 0.0739039
[Epoch 14; Iter  2071/ 2483] train: loss: 0.0016472
[Epoch 14; Iter  2101/ 2483] train: loss: 0.0566772
[Epoch 14; Iter  2131/ 2483] train: loss: 0.0033119
[Epoch 14; Iter  2161/ 2483] train: loss: 0.0016411
[Epoch 14; Iter  2191/ 2483] train: loss: 0.0039543
[Epoch 14; Iter  2221/ 2483] train: loss: 0.0017661
[Epoch 14; Iter  2251/ 2483] train: loss: 0.0765844
[Epoch 14; Iter  2281/ 2483] train: loss: 0.0026632
[Epoch 14; Iter  2311/ 2483] train: loss: 0.0021419
[Epoch 14; Iter  2341/ 2483] train: loss: 0.0014498
[Epoch 14; Iter  2371/ 2483] train: loss: 0.0016542
[Epoch 14; Iter  2401/ 2483] train: loss: 0.0015068
[Epoch 14; Iter  2431/ 2483] train: loss: 0.0015739
[Epoch 14; Iter  2461/ 2483] train: loss: 0.0012562
[Epoch 14] ogbg-molmuv: 0.087018 val loss: 0.010537
[Epoch 14] ogbg-molmuv: 0.154306 test loss: 0.014144
[Epoch 15; Iter     8/ 2483] train: loss: 0.0017475
[Epoch 15; Iter    38/ 2483] train: loss: 0.0021399
[Epoch 15; Iter    68/ 2483] train: loss: 0.0011943
[Epoch 15; Iter    98/ 2483] train: loss: 0.0012925
[Epoch 15; Iter   128/ 2483] train: loss: 0.0019416
[Epoch 15; Iter   158/ 2483] train: loss: 0.0029010
[Epoch 15; Iter   188/ 2483] train: loss: 0.0011077
[Epoch 15; Iter   218/ 2483] train: loss: 0.0018324
[Epoch 15; Iter   248/ 2483] train: loss: 0.0011561
[Epoch 15; Iter   278/ 2483] train: loss: 0.0013160
[Epoch 15; Iter   308/ 2483] train: loss: 0.0012199
[Epoch 15; Iter   338/ 2483] train: loss: 0.0014069
[Epoch 15; Iter   368/ 2483] train: loss: 0.0015286
[Epoch 15; Iter   398/ 2483] train: loss: 0.0014140
[Epoch 15; Iter   428/ 2483] train: loss: 0.0015016
[Epoch 15; Iter   458/ 2483] train: loss: 0.0008687
[Epoch 15; Iter   488/ 2483] train: loss: 0.0014818
[Epoch 15; Iter   518/ 2483] train: loss: 0.0015055
[Epoch 15; Iter   548/ 2483] train: loss: 0.0021275
[Epoch 15; Iter   578/ 2483] train: loss: 0.0019015
[Epoch 15; Iter   608/ 2483] train: loss: 0.0018410
[Epoch 15; Iter   638/ 2483] train: loss: 0.0407049
[Epoch 15; Iter   668/ 2483] train: loss: 0.0016488
[Epoch 15; Iter   698/ 2483] train: loss: 0.0046630
[Epoch 15; Iter   728/ 2483] train: loss: 0.0013933
[Epoch 15; Iter   758/ 2483] train: loss: 0.1476623
[Epoch 15; Iter   788/ 2483] train: loss: 0.0027788
[Epoch 15; Iter   818/ 2483] train: loss: 0.0021751
[Epoch 15; Iter   848/ 2483] train: loss: 0.1012184
[Epoch 15; Iter   878/ 2483] train: loss: 0.0014404
[Epoch 15; Iter   908/ 2483] train: loss: 0.0018746
[Epoch 15; Iter   938/ 2483] train: loss: 0.0024772
[Epoch 15; Iter   968/ 2483] train: loss: 0.0020461
[Epoch 15; Iter   998/ 2483] train: loss: 0.0047013
[Epoch 13; Iter  1404/ 2483] train: loss: 0.0778853
[Epoch 13; Iter  1434/ 2483] train: loss: 0.0014282
[Epoch 13; Iter  1464/ 2483] train: loss: 0.0024919
[Epoch 13; Iter  1494/ 2483] train: loss: 0.0030078
[Epoch 13; Iter  1524/ 2483] train: loss: 0.0019498
[Epoch 13; Iter  1554/ 2483] train: loss: 0.0058397
[Epoch 13; Iter  1584/ 2483] train: loss: 0.0594353
[Epoch 13; Iter  1614/ 2483] train: loss: 0.0016565
[Epoch 13; Iter  1644/ 2483] train: loss: 0.0020746
[Epoch 13; Iter  1674/ 2483] train: loss: 0.0022966
[Epoch 13; Iter  1704/ 2483] train: loss: 0.0017337
[Epoch 13; Iter  1734/ 2483] train: loss: 0.0019189
[Epoch 13; Iter  1764/ 2483] train: loss: 0.0021069
[Epoch 13; Iter  1794/ 2483] train: loss: 0.0016990
[Epoch 13; Iter  1824/ 2483] train: loss: 0.0024535
[Epoch 13; Iter  1854/ 2483] train: loss: 0.0017618
[Epoch 13; Iter  1884/ 2483] train: loss: 0.0031387
[Epoch 13; Iter  1914/ 2483] train: loss: 0.0033447
[Epoch 13; Iter  1944/ 2483] train: loss: 0.0030455
[Epoch 13; Iter  1974/ 2483] train: loss: 0.0019468
[Epoch 13; Iter  2004/ 2483] train: loss: 0.0021847
[Epoch 13; Iter  2034/ 2483] train: loss: 0.0689047
[Epoch 13; Iter  2064/ 2483] train: loss: 0.0025908
[Epoch 13; Iter  2094/ 2483] train: loss: 0.0020713
[Epoch 13; Iter  2124/ 2483] train: loss: 0.0030224
[Epoch 13; Iter  2154/ 2483] train: loss: 0.0024857
[Epoch 13; Iter  2184/ 2483] train: loss: 0.0019302
[Epoch 13; Iter  2214/ 2483] train: loss: 0.0639223
[Epoch 13; Iter  2244/ 2483] train: loss: 0.0794213
[Epoch 13; Iter  2274/ 2483] train: loss: 0.0025001
[Epoch 13; Iter  2304/ 2483] train: loss: 0.0025930
[Epoch 13; Iter  2334/ 2483] train: loss: 0.0030548
[Epoch 13; Iter  2364/ 2483] train: loss: 0.0018812
[Epoch 13; Iter  2394/ 2483] train: loss: 0.0018066
[Epoch 13; Iter  2424/ 2483] train: loss: 0.0016146
[Epoch 13; Iter  2454/ 2483] train: loss: 0.0723966
[Epoch 13] ogbg-molmuv: 0.037677 val loss: 0.030887
[Epoch 13] ogbg-molmuv: 0.027078 test loss: 0.071007
[Epoch 14; Iter     1/ 2483] train: loss: 0.0014266
[Epoch 14; Iter    31/ 2483] train: loss: 0.0017581
[Epoch 14; Iter    61/ 2483] train: loss: 0.0017304
[Epoch 14; Iter    91/ 2483] train: loss: 0.0018769
[Epoch 14; Iter   121/ 2483] train: loss: 0.0020798
[Epoch 14; Iter   151/ 2483] train: loss: 0.0018188
[Epoch 14; Iter   181/ 2483] train: loss: 0.0016699
[Epoch 14; Iter   211/ 2483] train: loss: 0.0029306
[Epoch 14; Iter   241/ 2483] train: loss: 0.0016205
[Epoch 14; Iter   271/ 2483] train: loss: 0.0020860
[Epoch 14; Iter   301/ 2483] train: loss: 0.0015023
[Epoch 14; Iter   331/ 2483] train: loss: 0.0013428
[Epoch 14; Iter   361/ 2483] train: loss: 0.0023719
[Epoch 14; Iter   391/ 2483] train: loss: 0.0016058
[Epoch 14; Iter   421/ 2483] train: loss: 0.0022463
[Epoch 14; Iter   451/ 2483] train: loss: 0.0022179
[Epoch 14; Iter   481/ 2483] train: loss: 0.0025867
[Epoch 14; Iter   511/ 2483] train: loss: 0.0016264
[Epoch 14; Iter   541/ 2483] train: loss: 0.0021941
[Epoch 14; Iter   571/ 2483] train: loss: 0.0018070
[Epoch 14; Iter   601/ 2483] train: loss: 0.0018408
[Epoch 14; Iter   631/ 2483] train: loss: 0.0014187
[Epoch 14; Iter   661/ 2483] train: loss: 0.0015807
[Epoch 14; Iter   691/ 2483] train: loss: 0.0017509
[Epoch 14; Iter   721/ 2483] train: loss: 0.0023714
[Epoch 14; Iter   751/ 2483] train: loss: 0.0018334
[Epoch 14; Iter   781/ 2483] train: loss: 0.0597388
[Epoch 14; Iter   811/ 2483] train: loss: 0.0023771
[Epoch 14; Iter   841/ 2483] train: loss: 0.0018117
[Epoch 14; Iter   871/ 2483] train: loss: 0.0038406
[Epoch 14; Iter   901/ 2483] train: loss: 0.0016097
[Epoch 14; Iter   931/ 2483] train: loss: 0.0646097
[Epoch 14; Iter   961/ 2483] train: loss: 0.0018854
[Epoch 14; Iter   991/ 2483] train: loss: 0.0029862
[Epoch 14; Iter  1021/ 2483] train: loss: 0.0013797
[Epoch 14; Iter  1051/ 2483] train: loss: 0.0017457
[Epoch 14; Iter  1081/ 2483] train: loss: 0.0013768
[Epoch 14; Iter  1111/ 2483] train: loss: 0.0810813
[Epoch 14; Iter  1141/ 2483] train: loss: 0.0014451
[Epoch 14; Iter  1171/ 2483] train: loss: 0.0030709
[Epoch 14; Iter  1201/ 2483] train: loss: 0.0023586
[Epoch 14; Iter  1231/ 2483] train: loss: 0.0019651
[Epoch 14; Iter  1261/ 2483] train: loss: 0.0026262
[Epoch 14; Iter  1291/ 2483] train: loss: 0.0030856
[Epoch 14; Iter  1321/ 2483] train: loss: 0.0864733
[Epoch 14; Iter  1351/ 2483] train: loss: 0.0015097
[Epoch 14; Iter  1381/ 2483] train: loss: 0.0020839
[Epoch 14; Iter  1411/ 2483] train: loss: 0.0012600
[Epoch 14; Iter  1441/ 2483] train: loss: 0.0020154
[Epoch 14; Iter  1471/ 2483] train: loss: 0.0014225
[Epoch 14; Iter  1501/ 2483] train: loss: 0.0032758
[Epoch 14; Iter  1531/ 2483] train: loss: 0.0023270
[Epoch 14; Iter  1561/ 2483] train: loss: 0.0029249
[Epoch 14; Iter  1591/ 2483] train: loss: 0.0011991
[Epoch 14; Iter  1621/ 2483] train: loss: 0.0009846
[Epoch 14; Iter  1651/ 2483] train: loss: 0.0011036
[Epoch 14; Iter  1681/ 2483] train: loss: 0.0019595
[Epoch 14; Iter  1711/ 2483] train: loss: 0.0019996
[Epoch 14; Iter  1741/ 2483] train: loss: 0.0016816
[Epoch 14; Iter  1771/ 2483] train: loss: 0.0014932
[Epoch 14; Iter  1801/ 2483] train: loss: 0.0016151
[Epoch 14; Iter  1831/ 2483] train: loss: 0.0019815
[Epoch 14; Iter  1861/ 2483] train: loss: 0.0048886
[Epoch 14; Iter  1891/ 2483] train: loss: 0.0017498
[Epoch 14; Iter  1921/ 2483] train: loss: 0.0025611
[Epoch 14; Iter  1951/ 2483] train: loss: 0.0019623
[Epoch 14; Iter  1981/ 2483] train: loss: 0.0015117
[Epoch 14; Iter  2011/ 2483] train: loss: 0.0011744
[Epoch 14; Iter  2041/ 2483] train: loss: 0.1294713
[Epoch 14; Iter  2071/ 2483] train: loss: 0.0023994
[Epoch 14; Iter  2101/ 2483] train: loss: 0.0018505
[Epoch 14; Iter  2131/ 2483] train: loss: 0.0023414
[Epoch 14; Iter  2161/ 2483] train: loss: 0.0021723
[Epoch 14; Iter  2191/ 2483] train: loss: 0.0404173
[Epoch 14; Iter  2221/ 2483] train: loss: 0.0034987
[Epoch 14; Iter  2251/ 2483] train: loss: 0.0024214
[Epoch 14; Iter  2281/ 2483] train: loss: 0.0013576
[Epoch 14; Iter  2311/ 2483] train: loss: 0.0377130
[Epoch 14; Iter  2341/ 2483] train: loss: 0.0032465
[Epoch 14; Iter  2371/ 2483] train: loss: 0.0015773
[Epoch 14; Iter  2401/ 2483] train: loss: 0.0018623
[Epoch 14; Iter  2431/ 2483] train: loss: 0.0724075
[Epoch 14; Iter  2461/ 2483] train: loss: 0.0490347
[Epoch 14] ogbg-molmuv: 0.085323 val loss: 0.010614
[Epoch 14] ogbg-molmuv: 0.032309 test loss: 0.028702
[Epoch 15; Iter     8/ 2483] train: loss: 0.0023388
[Epoch 15; Iter    38/ 2483] train: loss: 0.0019516
[Epoch 15; Iter    68/ 2483] train: loss: 0.0012782
[Epoch 15; Iter    98/ 2483] train: loss: 0.0018622
[Epoch 15; Iter   128/ 2483] train: loss: 0.0013633
[Epoch 15; Iter   158/ 2483] train: loss: 0.0019208
[Epoch 15; Iter   188/ 2483] train: loss: 0.0016994
[Epoch 15; Iter   218/ 2483] train: loss: 0.0014493
[Epoch 15; Iter   248/ 2483] train: loss: 0.0017421
[Epoch 15; Iter   278/ 2483] train: loss: 0.0018432
[Epoch 15; Iter   308/ 2483] train: loss: 0.0016988
[Epoch 15; Iter   338/ 2483] train: loss: 0.0015113
[Epoch 15; Iter   368/ 2483] train: loss: 0.0618590
[Epoch 15; Iter   398/ 2483] train: loss: 0.0016011
[Epoch 15; Iter   428/ 2483] train: loss: 0.0020073
[Epoch 15; Iter   458/ 2483] train: loss: 0.0017001
[Epoch 15; Iter   488/ 2483] train: loss: 0.0676571
[Epoch 15; Iter   518/ 2483] train: loss: 0.0027537
[Epoch 15; Iter   548/ 2483] train: loss: 0.0020508
[Epoch 15; Iter   578/ 2483] train: loss: 0.0909180
[Epoch 15; Iter   608/ 2483] train: loss: 0.0603642
[Epoch 15; Iter   638/ 2483] train: loss: 0.0026621
[Epoch 15; Iter   668/ 2483] train: loss: 0.0020539
[Epoch 15; Iter   698/ 2483] train: loss: 0.0021645
[Epoch 15; Iter   728/ 2483] train: loss: 0.0026757
[Epoch 15; Iter   758/ 2483] train: loss: 0.0019810
[Epoch 15; Iter   788/ 2483] train: loss: 0.0012585
[Epoch 15; Iter   818/ 2483] train: loss: 0.0764626
[Epoch 15; Iter   848/ 2483] train: loss: 0.0015596
[Epoch 15; Iter   878/ 2483] train: loss: 0.0028380
[Epoch 15; Iter   908/ 2483] train: loss: 0.0018263
[Epoch 15; Iter   938/ 2483] train: loss: 0.0023754
[Epoch 15; Iter   968/ 2483] train: loss: 0.0016042
[Epoch 15; Iter   998/ 2483] train: loss: 0.0012858
[Epoch 15; Iter   212/ 1862] train: loss: 0.0022903
[Epoch 15; Iter   242/ 1862] train: loss: 0.0018607
[Epoch 15; Iter   272/ 1862] train: loss: 0.0011955
[Epoch 15; Iter   302/ 1862] train: loss: 0.0017427
[Epoch 15; Iter   332/ 1862] train: loss: 0.0889312
[Epoch 15; Iter   362/ 1862] train: loss: 0.0017068
[Epoch 15; Iter   392/ 1862] train: loss: 0.0020375
[Epoch 15; Iter   422/ 1862] train: loss: 0.0652732
[Epoch 15; Iter   452/ 1862] train: loss: 0.0013615
[Epoch 15; Iter   482/ 1862] train: loss: 0.0015521
[Epoch 15; Iter   512/ 1862] train: loss: 0.0016422
[Epoch 15; Iter   542/ 1862] train: loss: 0.0695843
[Epoch 15; Iter   572/ 1862] train: loss: 0.0017444
[Epoch 15; Iter   602/ 1862] train: loss: 0.0015208
[Epoch 15; Iter   632/ 1862] train: loss: 0.0020121
[Epoch 15; Iter   662/ 1862] train: loss: 0.0020359
[Epoch 15; Iter   692/ 1862] train: loss: 0.0013556
[Epoch 15; Iter   722/ 1862] train: loss: 0.0011800
[Epoch 15; Iter   752/ 1862] train: loss: 0.0013210
[Epoch 15; Iter   782/ 1862] train: loss: 0.0010223
[Epoch 15; Iter   812/ 1862] train: loss: 0.0021242
[Epoch 15; Iter   842/ 1862] train: loss: 0.0025398
[Epoch 15; Iter   872/ 1862] train: loss: 0.0026557
[Epoch 15; Iter   902/ 1862] train: loss: 0.0030439
[Epoch 15; Iter   932/ 1862] train: loss: 0.0016508
[Epoch 15; Iter   962/ 1862] train: loss: 0.0012210
[Epoch 15; Iter   992/ 1862] train: loss: 0.0023513
[Epoch 15; Iter  1022/ 1862] train: loss: 0.0016760
[Epoch 15; Iter  1052/ 1862] train: loss: 0.0019763
[Epoch 15; Iter  1082/ 1862] train: loss: 0.0023923
[Epoch 15; Iter  1112/ 1862] train: loss: 0.0010612
[Epoch 15; Iter  1142/ 1862] train: loss: 0.0666483
[Epoch 15; Iter  1172/ 1862] train: loss: 0.0903631
[Epoch 15; Iter  1202/ 1862] train: loss: 0.0013724
[Epoch 15; Iter  1232/ 1862] train: loss: 0.0611189
[Epoch 15; Iter  1262/ 1862] train: loss: 0.0016200
[Epoch 15; Iter  1292/ 1862] train: loss: 0.0039767
[Epoch 15; Iter  1322/ 1862] train: loss: 0.0018234
[Epoch 15; Iter  1352/ 1862] train: loss: 0.0027587
[Epoch 15; Iter  1382/ 1862] train: loss: 0.0015776
[Epoch 15; Iter  1412/ 1862] train: loss: 0.0013200
[Epoch 15; Iter  1442/ 1862] train: loss: 0.0014253
[Epoch 15; Iter  1472/ 1862] train: loss: 0.0023478
[Epoch 15; Iter  1502/ 1862] train: loss: 0.0018044
[Epoch 15; Iter  1532/ 1862] train: loss: 0.0017730
[Epoch 15; Iter  1562/ 1862] train: loss: 0.0021436
[Epoch 15; Iter  1592/ 1862] train: loss: 0.0013899
[Epoch 15; Iter  1622/ 1862] train: loss: 0.0030481
[Epoch 15; Iter  1652/ 1862] train: loss: 0.0018559
[Epoch 15; Iter  1682/ 1862] train: loss: 0.0024990
[Epoch 15; Iter  1712/ 1862] train: loss: 0.0367760
[Epoch 15; Iter  1742/ 1862] train: loss: 0.0016217
[Epoch 15; Iter  1772/ 1862] train: loss: 0.0487567
[Epoch 15; Iter  1802/ 1862] train: loss: 0.0022340
[Epoch 15; Iter  1832/ 1862] train: loss: 0.0016641
[Epoch 15; Iter  1862/ 1862] train: loss: 0.0014886
[Epoch 15] ogbg-molmuv: 0.018164 val loss: 0.086868
[Epoch 15] ogbg-molmuv: 0.045923 test loss: 0.087070
[Epoch 16; Iter    30/ 1862] train: loss: 0.0023331
[Epoch 16; Iter    60/ 1862] train: loss: 0.0022013
[Epoch 16; Iter    90/ 1862] train: loss: 0.0025930
[Epoch 16; Iter   120/ 1862] train: loss: 0.0015923
[Epoch 16; Iter   150/ 1862] train: loss: 0.0016920
[Epoch 16; Iter   180/ 1862] train: loss: 0.0016812
[Epoch 16; Iter   210/ 1862] train: loss: 0.0012511
[Epoch 16; Iter   240/ 1862] train: loss: 0.0017031
[Epoch 16; Iter   270/ 1862] train: loss: 0.0013223
[Epoch 16; Iter   300/ 1862] train: loss: 0.0015955
[Epoch 16; Iter   330/ 1862] train: loss: 0.0012250
[Epoch 16; Iter   360/ 1862] train: loss: 0.0029606
[Epoch 16; Iter   390/ 1862] train: loss: 0.0016698
[Epoch 16; Iter   420/ 1862] train: loss: 0.0017956
[Epoch 16; Iter   450/ 1862] train: loss: 0.0015655
[Epoch 16; Iter   480/ 1862] train: loss: 0.0013996
[Epoch 16; Iter   510/ 1862] train: loss: 0.0010785
[Epoch 16; Iter   540/ 1862] train: loss: 0.0008477
[Epoch 16; Iter   570/ 1862] train: loss: 0.0011487
[Epoch 16; Iter   600/ 1862] train: loss: 0.0010350
[Epoch 16; Iter   630/ 1862] train: loss: 0.0024096
[Epoch 16; Iter   660/ 1862] train: loss: 0.0050936
[Epoch 16; Iter   690/ 1862] train: loss: 0.0028164
[Epoch 16; Iter   720/ 1862] train: loss: 0.0023045
[Epoch 16; Iter   750/ 1862] train: loss: 0.0017240
[Epoch 16; Iter   780/ 1862] train: loss: 0.0821165
[Epoch 16; Iter   810/ 1862] train: loss: 0.0020545
[Epoch 16; Iter   840/ 1862] train: loss: 0.0028598
[Epoch 16; Iter   870/ 1862] train: loss: 0.0017611
[Epoch 16; Iter   900/ 1862] train: loss: 0.0022748
[Epoch 16; Iter   930/ 1862] train: loss: 0.0018212
[Epoch 16; Iter   960/ 1862] train: loss: 0.0016441
[Epoch 16; Iter   990/ 1862] train: loss: 0.0804495
[Epoch 16; Iter  1020/ 1862] train: loss: 0.0036421
[Epoch 16; Iter  1050/ 1862] train: loss: 0.0016483
[Epoch 16; Iter  1080/ 1862] train: loss: 0.0639338
[Epoch 16; Iter  1110/ 1862] train: loss: 0.0018276
[Epoch 16; Iter  1140/ 1862] train: loss: 0.0014565
[Epoch 16; Iter  1170/ 1862] train: loss: 0.0014187
[Epoch 16; Iter  1200/ 1862] train: loss: 0.0012678
[Epoch 16; Iter  1230/ 1862] train: loss: 0.0013053
[Epoch 16; Iter  1260/ 1862] train: loss: 0.0012973
[Epoch 16; Iter  1290/ 1862] train: loss: 0.0017480
[Epoch 16; Iter  1320/ 1862] train: loss: 0.0016207
[Epoch 16; Iter  1350/ 1862] train: loss: 0.0014030
[Epoch 16; Iter  1380/ 1862] train: loss: 0.0013095
[Epoch 16; Iter  1410/ 1862] train: loss: 0.0027505
[Epoch 16; Iter  1440/ 1862] train: loss: 0.0011853
[Epoch 16; Iter  1470/ 1862] train: loss: 0.0580464
[Epoch 16; Iter  1500/ 1862] train: loss: 0.0020000
[Epoch 16; Iter  1530/ 1862] train: loss: 0.0025120
[Epoch 16; Iter  1560/ 1862] train: loss: 0.0020376
[Epoch 16; Iter  1590/ 1862] train: loss: 0.0020909
[Epoch 16; Iter  1620/ 1862] train: loss: 0.0019030
[Epoch 16; Iter  1650/ 1862] train: loss: 0.0014891
[Epoch 16; Iter  1680/ 1862] train: loss: 0.0013516
[Epoch 16; Iter  1710/ 1862] train: loss: 0.0016656
[Epoch 16; Iter  1740/ 1862] train: loss: 0.0021201
[Epoch 16; Iter  1770/ 1862] train: loss: 0.0035145
[Epoch 16; Iter  1800/ 1862] train: loss: 0.0014655
[Epoch 16; Iter  1830/ 1862] train: loss: 0.0028482
[Epoch 16; Iter  1860/ 1862] train: loss: 0.0874193
[Epoch 16] ogbg-molmuv: 0.018255 val loss: 0.013597
[Epoch 16] ogbg-molmuv: 0.055781 test loss: 0.012596
[Epoch 17; Iter    28/ 1862] train: loss: 0.0022506
[Epoch 17; Iter    58/ 1862] train: loss: 0.0019705
[Epoch 17; Iter    88/ 1862] train: loss: 0.0568475
[Epoch 17; Iter   118/ 1862] train: loss: 0.0027520
[Epoch 17; Iter   148/ 1862] train: loss: 0.0023442
[Epoch 17; Iter   178/ 1862] train: loss: 0.0022109
[Epoch 17; Iter   208/ 1862] train: loss: 0.0013927
[Epoch 17; Iter   238/ 1862] train: loss: 0.0019723
[Epoch 17; Iter   268/ 1862] train: loss: 0.0015899
[Epoch 17; Iter   298/ 1862] train: loss: 0.0491973
[Epoch 17; Iter   328/ 1862] train: loss: 0.0018094
[Epoch 17; Iter   358/ 1862] train: loss: 0.0018338
[Epoch 17; Iter   388/ 1862] train: loss: 0.0020745
[Epoch 17; Iter   418/ 1862] train: loss: 0.0032637
[Epoch 17; Iter   448/ 1862] train: loss: 0.0817058
[Epoch 17; Iter   478/ 1862] train: loss: 0.0017877
[Epoch 17; Iter   508/ 1862] train: loss: 0.0018398
[Epoch 17; Iter   538/ 1862] train: loss: 0.0017690
[Epoch 17; Iter   568/ 1862] train: loss: 0.0018877
[Epoch 17; Iter   598/ 1862] train: loss: 0.0031947
[Epoch 17; Iter   628/ 1862] train: loss: 0.0018503
[Epoch 17; Iter   658/ 1862] train: loss: 0.0020899
[Epoch 17; Iter   688/ 1862] train: loss: 0.0018335
[Epoch 17; Iter   718/ 1862] train: loss: 0.0017713
[Epoch 17; Iter   748/ 1862] train: loss: 0.0009271
[Epoch 17; Iter   778/ 1862] train: loss: 0.0013754
[Epoch 17; Iter   808/ 1862] train: loss: 0.0014895
[Epoch 17; Iter   838/ 1862] train: loss: 0.0008679
[Epoch 17; Iter   868/ 1862] train: loss: 0.0345159
[Epoch 17; Iter   898/ 1862] train: loss: 0.0017212
[Epoch 17; Iter   928/ 1862] train: loss: 0.1117159
[Epoch 17; Iter   958/ 1862] train: loss: 0.0013475
[Epoch 17; Iter   988/ 1862] train: loss: 0.0611507
[Epoch 17; Iter  1018/ 1862] train: loss: 0.0011877
[Epoch 17; Iter  1048/ 1862] train: loss: 0.0018432
[Epoch 15; Iter   212/ 1862] train: loss: 0.0030695
[Epoch 15; Iter   242/ 1862] train: loss: 0.0032919
[Epoch 15; Iter   272/ 1862] train: loss: 0.0287298
[Epoch 15; Iter   302/ 1862] train: loss: 0.0016607
[Epoch 15; Iter   332/ 1862] train: loss: 0.0022600
[Epoch 15; Iter   362/ 1862] train: loss: 0.0021793
[Epoch 15; Iter   392/ 1862] train: loss: 0.0020415
[Epoch 15; Iter   422/ 1862] train: loss: 0.0030392
[Epoch 15; Iter   452/ 1862] train: loss: 0.0027436
[Epoch 15; Iter   482/ 1862] train: loss: 0.0014347
[Epoch 15; Iter   512/ 1862] train: loss: 0.0680909
[Epoch 15; Iter   542/ 1862] train: loss: 0.1009838
[Epoch 15; Iter   572/ 1862] train: loss: 0.0024539
[Epoch 15; Iter   602/ 1862] train: loss: 0.0015549
[Epoch 15; Iter   632/ 1862] train: loss: 0.0018392
[Epoch 15; Iter   662/ 1862] train: loss: 0.0024929
[Epoch 15; Iter   692/ 1862] train: loss: 0.0792513
[Epoch 15; Iter   722/ 1862] train: loss: 0.0822514
[Epoch 15; Iter   752/ 1862] train: loss: 0.0024172
[Epoch 15; Iter   782/ 1862] train: loss: 0.0017564
[Epoch 15; Iter   812/ 1862] train: loss: 0.0015416
[Epoch 15; Iter   842/ 1862] train: loss: 0.0021263
[Epoch 15; Iter   872/ 1862] train: loss: 0.0018343
[Epoch 15; Iter   902/ 1862] train: loss: 0.0022358
[Epoch 15; Iter   932/ 1862] train: loss: 0.0024367
[Epoch 15; Iter   962/ 1862] train: loss: 0.0021665
[Epoch 15; Iter   992/ 1862] train: loss: 0.0013749
[Epoch 15; Iter  1022/ 1862] train: loss: 0.0015517
[Epoch 15; Iter  1052/ 1862] train: loss: 0.0026734
[Epoch 15; Iter  1082/ 1862] train: loss: 0.0016206
[Epoch 15; Iter  1112/ 1862] train: loss: 0.0014053
[Epoch 15; Iter  1142/ 1862] train: loss: 0.0649718
[Epoch 15; Iter  1172/ 1862] train: loss: 0.0038607
[Epoch 15; Iter  1202/ 1862] train: loss: 0.0016465
[Epoch 15; Iter  1232/ 1862] train: loss: 0.0019428
[Epoch 15; Iter  1262/ 1862] train: loss: 0.0022463
[Epoch 15; Iter  1292/ 1862] train: loss: 0.0016424
[Epoch 15; Iter  1322/ 1862] train: loss: 0.0021398
[Epoch 15; Iter  1352/ 1862] train: loss: 0.0018226
[Epoch 15; Iter  1382/ 1862] train: loss: 0.0021581
[Epoch 15; Iter  1412/ 1862] train: loss: 0.0036600
[Epoch 15; Iter  1442/ 1862] train: loss: 0.0023093
[Epoch 15; Iter  1472/ 1862] train: loss: 0.0013969
[Epoch 15; Iter  1502/ 1862] train: loss: 0.0020102
[Epoch 15; Iter  1532/ 1862] train: loss: 0.0025191
[Epoch 15; Iter  1562/ 1862] train: loss: 0.0030325
[Epoch 15; Iter  1592/ 1862] train: loss: 0.0022947
[Epoch 15; Iter  1622/ 1862] train: loss: 0.0017514
[Epoch 15; Iter  1652/ 1862] train: loss: 0.0018107
[Epoch 15; Iter  1682/ 1862] train: loss: 0.0014298
[Epoch 15; Iter  1712/ 1862] train: loss: 0.0018804
[Epoch 15; Iter  1742/ 1862] train: loss: 0.0731204
[Epoch 15; Iter  1772/ 1862] train: loss: 0.0015604
[Epoch 15; Iter  1802/ 1862] train: loss: 0.0715679
[Epoch 15; Iter  1832/ 1862] train: loss: 0.0018715
[Epoch 15; Iter  1862/ 1862] train: loss: 0.0039779
[Epoch 15] ogbg-molmuv: 0.015054 val loss: 0.013613
[Epoch 15] ogbg-molmuv: 0.032050 test loss: 0.012281
[Epoch 16; Iter    30/ 1862] train: loss: 0.0014226
[Epoch 16; Iter    60/ 1862] train: loss: 0.0028335
[Epoch 16; Iter    90/ 1862] train: loss: 0.0020200
[Epoch 16; Iter   120/ 1862] train: loss: 0.0022834
[Epoch 16; Iter   150/ 1862] train: loss: 0.0030477
[Epoch 16; Iter   180/ 1862] train: loss: 0.0039955
[Epoch 16; Iter   210/ 1862] train: loss: 0.0017475
[Epoch 16; Iter   240/ 1862] train: loss: 0.0023157
[Epoch 16; Iter   270/ 1862] train: loss: 0.0017140
[Epoch 16; Iter   300/ 1862] train: loss: 0.0014813
[Epoch 16; Iter   330/ 1862] train: loss: 0.0018036
[Epoch 16; Iter   360/ 1862] train: loss: 0.0019410
[Epoch 16; Iter   390/ 1862] train: loss: 0.0010684
[Epoch 16; Iter   420/ 1862] train: loss: 0.0016687
[Epoch 16; Iter   450/ 1862] train: loss: 0.0013443
[Epoch 16; Iter   480/ 1862] train: loss: 0.0016318
[Epoch 16; Iter   510/ 1862] train: loss: 0.0023290
[Epoch 16; Iter   540/ 1862] train: loss: 0.0012467
[Epoch 16; Iter   570/ 1862] train: loss: 0.0020006
[Epoch 16; Iter   600/ 1862] train: loss: 0.0017396
[Epoch 16; Iter   630/ 1862] train: loss: 0.0021461
[Epoch 16; Iter   660/ 1862] train: loss: 0.0011615
[Epoch 16; Iter   690/ 1862] train: loss: 0.0015602
[Epoch 16; Iter   720/ 1862] train: loss: 0.0012027
[Epoch 16; Iter   750/ 1862] train: loss: 0.0014497
[Epoch 16; Iter   780/ 1862] train: loss: 0.0018785
[Epoch 16; Iter   810/ 1862] train: loss: 0.0016080
[Epoch 16; Iter   840/ 1862] train: loss: 0.0024018
[Epoch 16; Iter   870/ 1862] train: loss: 0.0024226
[Epoch 16; Iter   900/ 1862] train: loss: 0.0620857
[Epoch 16; Iter   930/ 1862] train: loss: 0.0011225
[Epoch 16; Iter   960/ 1862] train: loss: 0.0019227
[Epoch 16; Iter   990/ 1862] train: loss: 0.0632383
[Epoch 16; Iter  1020/ 1862] train: loss: 0.0012158
[Epoch 16; Iter  1050/ 1862] train: loss: 0.0011328
[Epoch 16; Iter  1080/ 1862] train: loss: 0.0012653
[Epoch 16; Iter  1110/ 1862] train: loss: 0.0014136
[Epoch 16; Iter  1140/ 1862] train: loss: 0.0015162
[Epoch 16; Iter  1170/ 1862] train: loss: 0.0016481
[Epoch 16; Iter  1200/ 1862] train: loss: 0.0009774
[Epoch 16; Iter  1230/ 1862] train: loss: 0.0014280
[Epoch 16; Iter  1260/ 1862] train: loss: 0.0019842
[Epoch 16; Iter  1290/ 1862] train: loss: 0.0013571
[Epoch 16; Iter  1320/ 1862] train: loss: 0.0017129
[Epoch 16; Iter  1350/ 1862] train: loss: 0.0018936
[Epoch 16; Iter  1380/ 1862] train: loss: 0.0028745
[Epoch 16; Iter  1410/ 1862] train: loss: 0.0019692
[Epoch 16; Iter  1440/ 1862] train: loss: 0.0023307
[Epoch 16; Iter  1470/ 1862] train: loss: 0.0024701
[Epoch 16; Iter  1500/ 1862] train: loss: 0.0554398
[Epoch 16; Iter  1530/ 1862] train: loss: 0.0708979
[Epoch 16; Iter  1560/ 1862] train: loss: 0.0022624
[Epoch 16; Iter  1590/ 1862] train: loss: 0.0015342
[Epoch 16; Iter  1620/ 1862] train: loss: 0.0646779
[Epoch 16; Iter  1650/ 1862] train: loss: 0.0021705
[Epoch 16; Iter  1680/ 1862] train: loss: 0.0017156
[Epoch 16; Iter  1710/ 1862] train: loss: 0.0023850
[Epoch 16; Iter  1740/ 1862] train: loss: 0.0874220
[Epoch 16; Iter  1770/ 1862] train: loss: 0.0597400
[Epoch 16; Iter  1800/ 1862] train: loss: 0.0021123
[Epoch 16; Iter  1830/ 1862] train: loss: 0.0031850
[Epoch 16; Iter  1860/ 1862] train: loss: 0.0028366
[Epoch 16] ogbg-molmuv: 0.014705 val loss: 0.013833
[Epoch 16] ogbg-molmuv: 0.018432 test loss: 0.012657
[Epoch 17; Iter    28/ 1862] train: loss: 0.0018967
[Epoch 17; Iter    58/ 1862] train: loss: 0.0912694
[Epoch 17; Iter    88/ 1862] train: loss: 0.0022128
[Epoch 17; Iter   118/ 1862] train: loss: 0.0016294
[Epoch 17; Iter   148/ 1862] train: loss: 0.0646266
[Epoch 17; Iter   178/ 1862] train: loss: 0.0041016
[Epoch 17; Iter   208/ 1862] train: loss: 0.0029446
[Epoch 17; Iter   238/ 1862] train: loss: 0.0020166
[Epoch 17; Iter   268/ 1862] train: loss: 0.0020808
[Epoch 17; Iter   298/ 1862] train: loss: 0.0616221
[Epoch 17; Iter   328/ 1862] train: loss: 0.0016532
[Epoch 17; Iter   358/ 1862] train: loss: 0.0015755
[Epoch 17; Iter   388/ 1862] train: loss: 0.0014420
[Epoch 17; Iter   418/ 1862] train: loss: 0.0018630
[Epoch 17; Iter   448/ 1862] train: loss: 0.0016119
[Epoch 17; Iter   478/ 1862] train: loss: 0.0017446
[Epoch 17; Iter   508/ 1862] train: loss: 0.0019385
[Epoch 17; Iter   538/ 1862] train: loss: 0.0027057
[Epoch 17; Iter   568/ 1862] train: loss: 0.0021552
[Epoch 17; Iter   598/ 1862] train: loss: 0.0018938
[Epoch 17; Iter   628/ 1862] train: loss: 0.0018315
[Epoch 17; Iter   658/ 1862] train: loss: 0.0015957
[Epoch 17; Iter   688/ 1862] train: loss: 0.0016505
[Epoch 17; Iter   718/ 1862] train: loss: 0.0025981
[Epoch 17; Iter   748/ 1862] train: loss: 0.0014285
[Epoch 17; Iter   778/ 1862] train: loss: 0.0019748
[Epoch 17; Iter   808/ 1862] train: loss: 0.0018355
[Epoch 17; Iter   838/ 1862] train: loss: 0.0018564
[Epoch 17; Iter   868/ 1862] train: loss: 0.0015802
[Epoch 17; Iter   898/ 1862] train: loss: 0.0016489
[Epoch 17; Iter   928/ 1862] train: loss: 0.0026949
[Epoch 17; Iter   958/ 1862] train: loss: 0.0017501
[Epoch 17; Iter   988/ 1862] train: loss: 0.0045441
[Epoch 17; Iter  1018/ 1862] train: loss: 0.0014619
[Epoch 17; Iter  1048/ 1862] train: loss: 0.0013448
[Epoch 15; Iter   212/ 1862] train: loss: 0.0019979
[Epoch 15; Iter   242/ 1862] train: loss: 0.0016063
[Epoch 15; Iter   272/ 1862] train: loss: 0.0020853
[Epoch 15; Iter   302/ 1862] train: loss: 0.0021323
[Epoch 15; Iter   332/ 1862] train: loss: 0.0693988
[Epoch 15; Iter   362/ 1862] train: loss: 0.0031547
[Epoch 15; Iter   392/ 1862] train: loss: 0.0019604
[Epoch 15; Iter   422/ 1862] train: loss: 0.0014321
[Epoch 15; Iter   452/ 1862] train: loss: 0.0017736
[Epoch 15; Iter   482/ 1862] train: loss: 0.0016017
[Epoch 15; Iter   512/ 1862] train: loss: 0.0013563
[Epoch 15; Iter   542/ 1862] train: loss: 0.0808779
[Epoch 15; Iter   572/ 1862] train: loss: 0.0012913
[Epoch 15; Iter   602/ 1862] train: loss: 0.0015408
[Epoch 15; Iter   632/ 1862] train: loss: 0.0024161
[Epoch 15; Iter   662/ 1862] train: loss: 0.0017311
[Epoch 15; Iter   692/ 1862] train: loss: 0.0743361
[Epoch 15; Iter   722/ 1862] train: loss: 0.0025462
[Epoch 15; Iter   752/ 1862] train: loss: 0.0019019
[Epoch 15; Iter   782/ 1862] train: loss: 0.0019068
[Epoch 15; Iter   812/ 1862] train: loss: 0.0025375
[Epoch 15; Iter   842/ 1862] train: loss: 0.0011068
[Epoch 15; Iter   872/ 1862] train: loss: 0.0017041
[Epoch 15; Iter   902/ 1862] train: loss: 0.0024818
[Epoch 15; Iter   932/ 1862] train: loss: 0.0346635
[Epoch 15; Iter   962/ 1862] train: loss: 0.0021686
[Epoch 15; Iter   992/ 1862] train: loss: 0.0020952
[Epoch 15; Iter  1022/ 1862] train: loss: 0.0020453
[Epoch 15; Iter  1052/ 1862] train: loss: 0.0019886
[Epoch 15; Iter  1082/ 1862] train: loss: 0.0014786
[Epoch 15; Iter  1112/ 1862] train: loss: 0.0017415
[Epoch 15; Iter  1142/ 1862] train: loss: 0.0015071
[Epoch 15; Iter  1172/ 1862] train: loss: 0.0021861
[Epoch 15; Iter  1202/ 1862] train: loss: 0.0019649
[Epoch 15; Iter  1232/ 1862] train: loss: 0.0013444
[Epoch 15; Iter  1262/ 1862] train: loss: 0.0018998
[Epoch 15; Iter  1292/ 1862] train: loss: 0.0052270
[Epoch 15; Iter  1322/ 1862] train: loss: 0.0031958
[Epoch 15; Iter  1352/ 1862] train: loss: 0.0021639
[Epoch 15; Iter  1382/ 1862] train: loss: 0.0025403
[Epoch 15; Iter  1412/ 1862] train: loss: 0.0030387
[Epoch 15; Iter  1442/ 1862] train: loss: 0.0034014
[Epoch 15; Iter  1472/ 1862] train: loss: 0.0031561
[Epoch 15; Iter  1502/ 1862] train: loss: 0.0031932
[Epoch 15; Iter  1532/ 1862] train: loss: 0.0019568
[Epoch 15; Iter  1562/ 1862] train: loss: 0.0017966
[Epoch 15; Iter  1592/ 1862] train: loss: 0.0015149
[Epoch 15; Iter  1622/ 1862] train: loss: 0.0017591
[Epoch 15; Iter  1652/ 1862] train: loss: 0.0018657
[Epoch 15; Iter  1682/ 1862] train: loss: 0.0018249
[Epoch 15; Iter  1712/ 1862] train: loss: 0.0023704
[Epoch 15; Iter  1742/ 1862] train: loss: 0.0015957
[Epoch 15; Iter  1772/ 1862] train: loss: 0.0024004
[Epoch 15; Iter  1802/ 1862] train: loss: 0.0023791
[Epoch 15; Iter  1832/ 1862] train: loss: 0.0017309
[Epoch 15; Iter  1862/ 1862] train: loss: 0.0024046
[Epoch 15] ogbg-molmuv: 0.011922 val loss: 0.013660
[Epoch 15] ogbg-molmuv: 0.012513 test loss: 0.012457
[Epoch 16; Iter    30/ 1862] train: loss: 0.0010894
[Epoch 16; Iter    60/ 1862] train: loss: 0.0014027
[Epoch 16; Iter    90/ 1862] train: loss: 0.0024216
[Epoch 16; Iter   120/ 1862] train: loss: 0.0021581
[Epoch 16; Iter   150/ 1862] train: loss: 0.0014544
[Epoch 16; Iter   180/ 1862] train: loss: 0.0010404
[Epoch 16; Iter   210/ 1862] train: loss: 0.0009697
[Epoch 16; Iter   240/ 1862] train: loss: 0.0011267
[Epoch 16; Iter   270/ 1862] train: loss: 0.0010266
[Epoch 16; Iter   300/ 1862] train: loss: 0.0714080
[Epoch 16; Iter   330/ 1862] train: loss: 0.0017366
[Epoch 16; Iter   360/ 1862] train: loss: 0.0022455
[Epoch 16; Iter   390/ 1862] train: loss: 0.1000619
[Epoch 16; Iter   420/ 1862] train: loss: 0.0014567
[Epoch 16; Iter   450/ 1862] train: loss: 0.0028041
[Epoch 16; Iter   480/ 1862] train: loss: 0.0016916
[Epoch 16; Iter   510/ 1862] train: loss: 0.0021341
[Epoch 16; Iter   540/ 1862] train: loss: 0.0012902
[Epoch 16; Iter   570/ 1862] train: loss: 0.0016223
[Epoch 16; Iter   600/ 1862] train: loss: 0.0866159
[Epoch 16; Iter   630/ 1862] train: loss: 0.0017317
[Epoch 16; Iter   660/ 1862] train: loss: 0.0015338
[Epoch 16; Iter   690/ 1862] train: loss: 0.0027145
[Epoch 16; Iter   720/ 1862] train: loss: 0.0039438
[Epoch 16; Iter   750/ 1862] train: loss: 0.0657869
[Epoch 16; Iter   780/ 1862] train: loss: 0.0036632
[Epoch 16; Iter   810/ 1862] train: loss: 0.0026330
[Epoch 16; Iter   840/ 1862] train: loss: 0.0020579
[Epoch 16; Iter   870/ 1862] train: loss: 0.0019125
[Epoch 16; Iter   900/ 1862] train: loss: 0.0022236
[Epoch 16; Iter   930/ 1862] train: loss: 0.0016347
[Epoch 16; Iter   960/ 1862] train: loss: 0.0023549
[Epoch 16; Iter   990/ 1862] train: loss: 0.0016934
[Epoch 16; Iter  1020/ 1862] train: loss: 0.0023374
[Epoch 16; Iter  1050/ 1862] train: loss: 0.0013877
[Epoch 16; Iter  1080/ 1862] train: loss: 0.0013674
[Epoch 16; Iter  1110/ 1862] train: loss: 0.0022642
[Epoch 16; Iter  1140/ 1862] train: loss: 0.0013782
[Epoch 16; Iter  1170/ 1862] train: loss: 0.0848373
[Epoch 16; Iter  1200/ 1862] train: loss: 0.0027833
[Epoch 16; Iter  1230/ 1862] train: loss: 0.0022880
[Epoch 16; Iter  1260/ 1862] train: loss: 0.0023115
[Epoch 16; Iter  1290/ 1862] train: loss: 0.0016647
[Epoch 16; Iter  1320/ 1862] train: loss: 0.0017844
[Epoch 16; Iter  1350/ 1862] train: loss: 0.0017718
[Epoch 16; Iter  1380/ 1862] train: loss: 0.0016780
[Epoch 16; Iter  1410/ 1862] train: loss: 0.0011752
[Epoch 16; Iter  1440/ 1862] train: loss: 0.0018909
[Epoch 16; Iter  1470/ 1862] train: loss: 0.0022130
[Epoch 16; Iter  1500/ 1862] train: loss: 0.0035388
[Epoch 16; Iter  1530/ 1862] train: loss: 0.0022494
[Epoch 16; Iter  1560/ 1862] train: loss: 0.0685143
[Epoch 16; Iter  1590/ 1862] train: loss: 0.1311259
[Epoch 16; Iter  1620/ 1862] train: loss: 0.0017966
[Epoch 16; Iter  1650/ 1862] train: loss: 0.0019215
[Epoch 16; Iter  1680/ 1862] train: loss: 0.0013833
[Epoch 16; Iter  1710/ 1862] train: loss: 0.0031956
[Epoch 16; Iter  1740/ 1862] train: loss: 0.0016492
[Epoch 16; Iter  1770/ 1862] train: loss: 0.0848461
[Epoch 16; Iter  1800/ 1862] train: loss: 0.0023236
[Epoch 16; Iter  1830/ 1862] train: loss: 0.0016221
[Epoch 16; Iter  1860/ 1862] train: loss: 0.0021635
[Epoch 16] ogbg-molmuv: 0.018273 val loss: 0.013216
[Epoch 16] ogbg-molmuv: 0.020667 test loss: 0.012088
[Epoch 17; Iter    28/ 1862] train: loss: 0.0019442
[Epoch 17; Iter    58/ 1862] train: loss: 0.0016460
[Epoch 17; Iter    88/ 1862] train: loss: 0.0017365
[Epoch 17; Iter   118/ 1862] train: loss: 0.0022484
[Epoch 17; Iter   148/ 1862] train: loss: 0.0500565
[Epoch 17; Iter   178/ 1862] train: loss: 0.0019968
[Epoch 17; Iter   208/ 1862] train: loss: 0.0026496
[Epoch 17; Iter   238/ 1862] train: loss: 0.0021357
[Epoch 17; Iter   268/ 1862] train: loss: 0.0021074
[Epoch 17; Iter   298/ 1862] train: loss: 0.0029305
[Epoch 17; Iter   328/ 1862] train: loss: 0.0018960
[Epoch 17; Iter   358/ 1862] train: loss: 0.0020003
[Epoch 17; Iter   388/ 1862] train: loss: 0.0022370
[Epoch 17; Iter   418/ 1862] train: loss: 0.0020715
[Epoch 17; Iter   448/ 1862] train: loss: 0.0016694
[Epoch 17; Iter   478/ 1862] train: loss: 0.0018413
[Epoch 17; Iter   508/ 1862] train: loss: 0.0015077
[Epoch 17; Iter   538/ 1862] train: loss: 0.0015429
[Epoch 17; Iter   568/ 1862] train: loss: 0.0019309
[Epoch 17; Iter   598/ 1862] train: loss: 0.0015846
[Epoch 17; Iter   628/ 1862] train: loss: 0.0877896
[Epoch 17; Iter   658/ 1862] train: loss: 0.0018714
[Epoch 17; Iter   688/ 1862] train: loss: 0.0019236
[Epoch 17; Iter   718/ 1862] train: loss: 0.0790741
[Epoch 17; Iter   748/ 1862] train: loss: 0.0030175
[Epoch 17; Iter   778/ 1862] train: loss: 0.0020871
[Epoch 17; Iter   808/ 1862] train: loss: 0.0022903
[Epoch 17; Iter   838/ 1862] train: loss: 0.0016365
[Epoch 17; Iter   868/ 1862] train: loss: 0.0017653
[Epoch 17; Iter   898/ 1862] train: loss: 0.0017806
[Epoch 17; Iter   928/ 1862] train: loss: 0.0021215
[Epoch 17; Iter   958/ 1862] train: loss: 0.0017088
[Epoch 17; Iter   988/ 1862] train: loss: 0.0014631
[Epoch 17; Iter  1018/ 1862] train: loss: 0.0018819
[Epoch 17; Iter  1048/ 1862] train: loss: 0.0017236
[Epoch 15; Iter   642/ 2172] train: loss: 0.0015854
[Epoch 15; Iter   672/ 2172] train: loss: 0.0010687
[Epoch 15; Iter   702/ 2172] train: loss: 0.0011249
[Epoch 15; Iter   732/ 2172] train: loss: 0.0014972
[Epoch 15; Iter   762/ 2172] train: loss: 0.0029403
[Epoch 15; Iter   792/ 2172] train: loss: 0.0012939
[Epoch 15; Iter   822/ 2172] train: loss: 0.0025210
[Epoch 15; Iter   852/ 2172] train: loss: 0.0019168
[Epoch 15; Iter   882/ 2172] train: loss: 0.0039627
[Epoch 15; Iter   912/ 2172] train: loss: 0.0016509
[Epoch 15; Iter   942/ 2172] train: loss: 0.0390887
[Epoch 15; Iter   972/ 2172] train: loss: 0.0040698
[Epoch 15; Iter  1002/ 2172] train: loss: 0.0020339
[Epoch 15; Iter  1032/ 2172] train: loss: 0.0857170
[Epoch 15; Iter  1062/ 2172] train: loss: 0.0027260
[Epoch 15; Iter  1092/ 2172] train: loss: 0.0028012
[Epoch 15; Iter  1122/ 2172] train: loss: 0.0019100
[Epoch 15; Iter  1152/ 2172] train: loss: 0.0018041
[Epoch 15; Iter  1182/ 2172] train: loss: 0.0656481
[Epoch 15; Iter  1212/ 2172] train: loss: 0.0012476
[Epoch 15; Iter  1242/ 2172] train: loss: 0.1537416
[Epoch 15; Iter  1272/ 2172] train: loss: 0.0029219
[Epoch 15; Iter  1302/ 2172] train: loss: 0.0017199
[Epoch 15; Iter  1332/ 2172] train: loss: 0.0026552
[Epoch 15; Iter  1362/ 2172] train: loss: 0.0641014
[Epoch 15; Iter  1392/ 2172] train: loss: 0.1286680
[Epoch 15; Iter  1422/ 2172] train: loss: 0.0017320
[Epoch 15; Iter  1452/ 2172] train: loss: 0.0014815
[Epoch 15; Iter  1482/ 2172] train: loss: 0.0011734
[Epoch 15; Iter  1512/ 2172] train: loss: 0.0751002
[Epoch 15; Iter  1542/ 2172] train: loss: 0.0025813
[Epoch 15; Iter  1572/ 2172] train: loss: 0.0015505
[Epoch 15; Iter  1602/ 2172] train: loss: 0.0864986
[Epoch 15; Iter  1632/ 2172] train: loss: 0.0044547
[Epoch 15; Iter  1662/ 2172] train: loss: 0.0015232
[Epoch 15; Iter  1692/ 2172] train: loss: 0.0019630
[Epoch 15; Iter  1722/ 2172] train: loss: 0.0016969
[Epoch 15; Iter  1752/ 2172] train: loss: 0.0011762
[Epoch 15; Iter  1782/ 2172] train: loss: 0.0012465
[Epoch 15; Iter  1812/ 2172] train: loss: 0.0016494
[Epoch 15; Iter  1842/ 2172] train: loss: 0.0378929
[Epoch 15; Iter  1872/ 2172] train: loss: 0.0017920
[Epoch 15; Iter  1902/ 2172] train: loss: 0.0622421
[Epoch 15; Iter  1932/ 2172] train: loss: 0.0018207
[Epoch 15; Iter  1962/ 2172] train: loss: 0.0018429
[Epoch 15; Iter  1992/ 2172] train: loss: 0.0780466
[Epoch 15; Iter  2022/ 2172] train: loss: 0.0023214
[Epoch 15; Iter  2052/ 2172] train: loss: 0.0012479
[Epoch 15; Iter  2082/ 2172] train: loss: 0.0013890
[Epoch 15; Iter  2112/ 2172] train: loss: 0.0013421
[Epoch 15; Iter  2142/ 2172] train: loss: 0.0013527
[Epoch 15; Iter  2172/ 2172] train: loss: 0.0015681
[Epoch 15] ogbg-molmuv: 0.053308 val loss: 0.025439
[Epoch 15] ogbg-molmuv: 0.104791 test loss: 0.015948
[Epoch 16; Iter    30/ 2172] train: loss: 0.0013856
[Epoch 16; Iter    60/ 2172] train: loss: 0.0029965
[Epoch 16; Iter    90/ 2172] train: loss: 0.0012244
[Epoch 16; Iter   120/ 2172] train: loss: 0.0007525
[Epoch 16; Iter   150/ 2172] train: loss: 0.0017996
[Epoch 16; Iter   180/ 2172] train: loss: 0.0008643
[Epoch 16; Iter   210/ 2172] train: loss: 0.0009262
[Epoch 16; Iter   240/ 2172] train: loss: 0.0023357
[Epoch 16; Iter   270/ 2172] train: loss: 0.0015966
[Epoch 16; Iter   300/ 2172] train: loss: 0.0014402
[Epoch 16; Iter   330/ 2172] train: loss: 0.0010838
[Epoch 16; Iter   360/ 2172] train: loss: 0.0016485
[Epoch 16; Iter   390/ 2172] train: loss: 0.0010397
[Epoch 16; Iter   420/ 2172] train: loss: 0.0013441
[Epoch 16; Iter   450/ 2172] train: loss: 0.0015747
[Epoch 16; Iter   480/ 2172] train: loss: 0.0015813
[Epoch 16; Iter   510/ 2172] train: loss: 0.0017887
[Epoch 16; Iter   540/ 2172] train: loss: 0.0017328
[Epoch 16; Iter   570/ 2172] train: loss: 0.0020452
[Epoch 16; Iter   600/ 2172] train: loss: 0.0777579
[Epoch 16; Iter   630/ 2172] train: loss: 0.0016453
[Epoch 16; Iter   660/ 2172] train: loss: 0.0009845
[Epoch 16; Iter   690/ 2172] train: loss: 0.0016202
[Epoch 16; Iter   720/ 2172] train: loss: 0.0012847
[Epoch 16; Iter   750/ 2172] train: loss: 0.0015865
[Epoch 16; Iter   780/ 2172] train: loss: 0.0021179
[Epoch 16; Iter   810/ 2172] train: loss: 0.0014165
[Epoch 16; Iter   840/ 2172] train: loss: 0.0017038
[Epoch 16; Iter   870/ 2172] train: loss: 0.0626337
[Epoch 16; Iter   900/ 2172] train: loss: 0.0013810
[Epoch 16; Iter   930/ 2172] train: loss: 0.0013711
[Epoch 16; Iter   960/ 2172] train: loss: 0.0048710
[Epoch 16; Iter   990/ 2172] train: loss: 0.0463184
[Epoch 16; Iter  1020/ 2172] train: loss: 0.0022044
[Epoch 16; Iter  1050/ 2172] train: loss: 0.0023555
[Epoch 16; Iter  1080/ 2172] train: loss: 0.0029329
[Epoch 16; Iter  1110/ 2172] train: loss: 0.0881468
[Epoch 16; Iter  1140/ 2172] train: loss: 0.0016023
[Epoch 16; Iter  1170/ 2172] train: loss: 0.0509558
[Epoch 16; Iter  1200/ 2172] train: loss: 0.0931973
[Epoch 16; Iter  1230/ 2172] train: loss: 0.0014249
[Epoch 16; Iter  1260/ 2172] train: loss: 0.0021781
[Epoch 16; Iter  1290/ 2172] train: loss: 0.0024266
[Epoch 16; Iter  1320/ 2172] train: loss: 0.0641199
[Epoch 16; Iter  1350/ 2172] train: loss: 0.0014174
[Epoch 16; Iter  1380/ 2172] train: loss: 0.0020249
[Epoch 16; Iter  1410/ 2172] train: loss: 0.0566818
[Epoch 16; Iter  1440/ 2172] train: loss: 0.0021283
[Epoch 16; Iter  1470/ 2172] train: loss: 0.0039892
[Epoch 16; Iter  1500/ 2172] train: loss: 0.0016447
[Epoch 16; Iter  1530/ 2172] train: loss: 0.0011466
[Epoch 16; Iter  1560/ 2172] train: loss: 0.0012356
[Epoch 16; Iter  1590/ 2172] train: loss: 0.0020631
[Epoch 16; Iter  1620/ 2172] train: loss: 0.0026405
[Epoch 16; Iter  1650/ 2172] train: loss: 0.0013886
[Epoch 16; Iter  1680/ 2172] train: loss: 0.0012008
[Epoch 16; Iter  1710/ 2172] train: loss: 0.0013254
[Epoch 16; Iter  1740/ 2172] train: loss: 0.0020490
[Epoch 16; Iter  1770/ 2172] train: loss: 0.0010951
[Epoch 16; Iter  1800/ 2172] train: loss: 0.0013958
[Epoch 16; Iter  1830/ 2172] train: loss: 0.0017886
[Epoch 16; Iter  1860/ 2172] train: loss: 0.0016811
[Epoch 16; Iter  1890/ 2172] train: loss: 0.0977766
[Epoch 16; Iter  1920/ 2172] train: loss: 0.0058022
[Epoch 16; Iter  1950/ 2172] train: loss: 0.0828192
[Epoch 16; Iter  1980/ 2172] train: loss: 0.0026319
[Epoch 16; Iter  2010/ 2172] train: loss: 0.0012424
[Epoch 16; Iter  2040/ 2172] train: loss: 0.0027474
[Epoch 16; Iter  2070/ 2172] train: loss: 0.0034571
[Epoch 16; Iter  2100/ 2172] train: loss: 0.0029311
[Epoch 16; Iter  2130/ 2172] train: loss: 0.0014102
[Epoch 16; Iter  2160/ 2172] train: loss: 0.0016982
[Epoch 16] ogbg-molmuv: 0.062695 val loss: 0.011629
[Epoch 16] ogbg-molmuv: 0.097147 test loss: 0.012605
[Epoch 17; Iter    18/ 2172] train: loss: 0.0013344
[Epoch 17; Iter    48/ 2172] train: loss: 0.0012497
[Epoch 17; Iter    78/ 2172] train: loss: 0.0012012
[Epoch 17; Iter   108/ 2172] train: loss: 0.0011084
[Epoch 17; Iter   138/ 2172] train: loss: 0.0007375
[Epoch 17; Iter   168/ 2172] train: loss: 0.0009151
[Epoch 17; Iter   198/ 2172] train: loss: 0.0013367
[Epoch 17; Iter   228/ 2172] train: loss: 0.0014015
[Epoch 17; Iter   258/ 2172] train: loss: 0.0012696
[Epoch 17; Iter   288/ 2172] train: loss: 0.0016960
[Epoch 17; Iter   318/ 2172] train: loss: 0.0015327
[Epoch 17; Iter   348/ 2172] train: loss: 0.0010453
[Epoch 17; Iter   378/ 2172] train: loss: 0.0018994
[Epoch 17; Iter   408/ 2172] train: loss: 0.0012855
[Epoch 17; Iter   438/ 2172] train: loss: 0.0014445
[Epoch 17; Iter   468/ 2172] train: loss: 0.0580576
[Epoch 17; Iter   498/ 2172] train: loss: 0.0011816
[Epoch 17; Iter   528/ 2172] train: loss: 0.0014808
[Epoch 17; Iter   558/ 2172] train: loss: 0.0021052
[Epoch 17; Iter   588/ 2172] train: loss: 0.0830558
[Epoch 17; Iter   618/ 2172] train: loss: 0.0019470
[Epoch 17; Iter   648/ 2172] train: loss: 0.0025207
[Epoch 17; Iter   678/ 2172] train: loss: 0.0021042
[Epoch 17; Iter   708/ 2172] train: loss: 0.0018852
[Epoch 17; Iter   738/ 2172] train: loss: 0.0017432
[Epoch 17; Iter   768/ 2172] train: loss: 0.0022062
[Epoch 17; Iter   798/ 2172] train: loss: 0.0019710
[Epoch 17; Iter   828/ 2172] train: loss: 0.0919054
[Epoch 17; Iter   858/ 2172] train: loss: 0.0012394
[Epoch 15; Iter   642/ 2172] train: loss: 0.0024444
[Epoch 15; Iter   672/ 2172] train: loss: 0.0018039
[Epoch 15; Iter   702/ 2172] train: loss: 0.0027282
[Epoch 15; Iter   732/ 2172] train: loss: 0.0022525
[Epoch 15; Iter   762/ 2172] train: loss: 0.0033103
[Epoch 15; Iter   792/ 2172] train: loss: 0.0018903
[Epoch 15; Iter   822/ 2172] train: loss: 0.0607902
[Epoch 15; Iter   852/ 2172] train: loss: 0.0027988
[Epoch 15; Iter   882/ 2172] train: loss: 0.0014584
[Epoch 15; Iter   912/ 2172] train: loss: 0.0015167
[Epoch 15; Iter   942/ 2172] train: loss: 0.0020540
[Epoch 15; Iter   972/ 2172] train: loss: 0.0036370
[Epoch 15; Iter  1002/ 2172] train: loss: 0.0020081
[Epoch 15; Iter  1032/ 2172] train: loss: 0.0021825
[Epoch 15; Iter  1062/ 2172] train: loss: 0.0013039
[Epoch 15; Iter  1092/ 2172] train: loss: 0.0017584
[Epoch 15; Iter  1122/ 2172] train: loss: 0.0794685
[Epoch 15; Iter  1152/ 2172] train: loss: 0.0017325
[Epoch 15; Iter  1182/ 2172] train: loss: 0.0872426
[Epoch 15; Iter  1212/ 2172] train: loss: 0.0788892
[Epoch 15; Iter  1242/ 2172] train: loss: 0.0016210
[Epoch 15; Iter  1272/ 2172] train: loss: 0.0016328
[Epoch 15; Iter  1302/ 2172] train: loss: 0.0017336
[Epoch 15; Iter  1332/ 2172] train: loss: 0.0015817
[Epoch 15; Iter  1362/ 2172] train: loss: 0.0022561
[Epoch 15; Iter  1392/ 2172] train: loss: 0.0023223
[Epoch 15; Iter  1422/ 2172] train: loss: 0.0024163
[Epoch 15; Iter  1452/ 2172] train: loss: 0.0024990
[Epoch 15; Iter  1482/ 2172] train: loss: 0.1108148
[Epoch 15; Iter  1512/ 2172] train: loss: 0.0033630
[Epoch 15; Iter  1542/ 2172] train: loss: 0.0579272
[Epoch 15; Iter  1572/ 2172] train: loss: 0.0030182
[Epoch 15; Iter  1602/ 2172] train: loss: 0.0023804
[Epoch 15; Iter  1632/ 2172] train: loss: 0.0024171
[Epoch 15; Iter  1662/ 2172] train: loss: 0.0029812
[Epoch 15; Iter  1692/ 2172] train: loss: 0.0516115
[Epoch 15; Iter  1722/ 2172] train: loss: 0.0018866
[Epoch 15; Iter  1752/ 2172] train: loss: 0.0015154
[Epoch 15; Iter  1782/ 2172] train: loss: 0.0016047
[Epoch 15; Iter  1812/ 2172] train: loss: 0.0015391
[Epoch 15; Iter  1842/ 2172] train: loss: 0.0018038
[Epoch 15; Iter  1872/ 2172] train: loss: 0.0753639
[Epoch 15; Iter  1902/ 2172] train: loss: 0.0723200
[Epoch 15; Iter  1932/ 2172] train: loss: 0.0023935
[Epoch 15; Iter  1962/ 2172] train: loss: 0.0020988
[Epoch 15; Iter  1992/ 2172] train: loss: 0.0013658
[Epoch 15; Iter  2022/ 2172] train: loss: 0.0014052
[Epoch 15; Iter  2052/ 2172] train: loss: 0.0016560
[Epoch 15; Iter  2082/ 2172] train: loss: 0.0027537
[Epoch 15; Iter  2112/ 2172] train: loss: 0.0021072
[Epoch 15; Iter  2142/ 2172] train: loss: 0.0015684
[Epoch 15; Iter  2172/ 2172] train: loss: 0.0012779
[Epoch 15] ogbg-molmuv: 0.029574 val loss: 0.011860
[Epoch 15] ogbg-molmuv: 0.019152 test loss: 0.013401
[Epoch 16; Iter    30/ 2172] train: loss: 0.0019562
[Epoch 16; Iter    60/ 2172] train: loss: 0.0017309
[Epoch 16; Iter    90/ 2172] train: loss: 0.0014163
[Epoch 16; Iter   120/ 2172] train: loss: 0.0012585
[Epoch 16; Iter   150/ 2172] train: loss: 0.0016488
[Epoch 16; Iter   180/ 2172] train: loss: 0.0018755
[Epoch 16; Iter   210/ 2172] train: loss: 0.0019602
[Epoch 16; Iter   240/ 2172] train: loss: 0.0017382
[Epoch 16; Iter   270/ 2172] train: loss: 0.0016119
[Epoch 16; Iter   300/ 2172] train: loss: 0.0010894
[Epoch 16; Iter   330/ 2172] train: loss: 0.0018073
[Epoch 16; Iter   360/ 2172] train: loss: 0.0019727
[Epoch 16; Iter   390/ 2172] train: loss: 0.0024050
[Epoch 16; Iter   420/ 2172] train: loss: 0.0022645
[Epoch 16; Iter   450/ 2172] train: loss: 0.0750259
[Epoch 16; Iter   480/ 2172] train: loss: 0.0015396
[Epoch 16; Iter   510/ 2172] train: loss: 0.0020648
[Epoch 16; Iter   540/ 2172] train: loss: 0.0016418
[Epoch 16; Iter   570/ 2172] train: loss: 0.0925604
[Epoch 16; Iter   600/ 2172] train: loss: 0.0028677
[Epoch 16; Iter   630/ 2172] train: loss: 0.0780442
[Epoch 16; Iter   660/ 2172] train: loss: 0.0019127
[Epoch 16; Iter   690/ 2172] train: loss: 0.0017765
[Epoch 16; Iter   720/ 2172] train: loss: 0.0020025
[Epoch 16; Iter   750/ 2172] train: loss: 0.0017986
[Epoch 16; Iter   780/ 2172] train: loss: 0.0019207
[Epoch 16; Iter   810/ 2172] train: loss: 0.0022594
[Epoch 16; Iter   840/ 2172] train: loss: 0.0736520
[Epoch 16; Iter   870/ 2172] train: loss: 0.0021421
[Epoch 16; Iter   900/ 2172] train: loss: 0.0020767
[Epoch 16; Iter   930/ 2172] train: loss: 0.0630244
[Epoch 16; Iter   960/ 2172] train: loss: 0.0015153
[Epoch 16; Iter   990/ 2172] train: loss: 0.0020594
[Epoch 16; Iter  1020/ 2172] train: loss: 0.0017744
[Epoch 16; Iter  1050/ 2172] train: loss: 0.0018170
[Epoch 16; Iter  1080/ 2172] train: loss: 0.0014214
[Epoch 16; Iter  1110/ 2172] train: loss: 0.0995168
[Epoch 16; Iter  1140/ 2172] train: loss: 0.0017169
[Epoch 16; Iter  1170/ 2172] train: loss: 0.0023206
[Epoch 16; Iter  1200/ 2172] train: loss: 0.0712902
[Epoch 16; Iter  1230/ 2172] train: loss: 0.0017009
[Epoch 16; Iter  1260/ 2172] train: loss: 0.0025634
[Epoch 16; Iter  1290/ 2172] train: loss: 0.0018596
[Epoch 16; Iter  1320/ 2172] train: loss: 0.0012702
[Epoch 16; Iter  1350/ 2172] train: loss: 0.0016849
[Epoch 16; Iter  1380/ 2172] train: loss: 0.0025419
[Epoch 16; Iter  1410/ 2172] train: loss: 0.0527010
[Epoch 16; Iter  1440/ 2172] train: loss: 0.0033818
[Epoch 16; Iter  1470/ 2172] train: loss: 0.0029546
[Epoch 16; Iter  1500/ 2172] train: loss: 0.0012897
[Epoch 16; Iter  1530/ 2172] train: loss: 0.0023362
[Epoch 16; Iter  1560/ 2172] train: loss: 0.0842620
[Epoch 16; Iter  1590/ 2172] train: loss: 0.0110218
[Epoch 16; Iter  1620/ 2172] train: loss: 0.0024531
[Epoch 16; Iter  1650/ 2172] train: loss: 0.0465005
[Epoch 16; Iter  1680/ 2172] train: loss: 0.0024513
[Epoch 16; Iter  1710/ 2172] train: loss: 0.0022785
[Epoch 16; Iter  1740/ 2172] train: loss: 0.0018018
[Epoch 16; Iter  1770/ 2172] train: loss: 0.0015227
[Epoch 16; Iter  1800/ 2172] train: loss: 0.0016912
[Epoch 16; Iter  1830/ 2172] train: loss: 0.0030562
[Epoch 16; Iter  1860/ 2172] train: loss: 0.0017497
[Epoch 16; Iter  1890/ 2172] train: loss: 0.0018444
[Epoch 16; Iter  1920/ 2172] train: loss: 0.0019619
[Epoch 16; Iter  1950/ 2172] train: loss: 0.0023569
[Epoch 16; Iter  1980/ 2172] train: loss: 0.0025151
[Epoch 16; Iter  2010/ 2172] train: loss: 0.0026120
[Epoch 16; Iter  2040/ 2172] train: loss: 0.0032859
[Epoch 16; Iter  2070/ 2172] train: loss: 0.0019151
[Epoch 16; Iter  2100/ 2172] train: loss: 0.0021149
[Epoch 16; Iter  2130/ 2172] train: loss: 0.0058958
[Epoch 16; Iter  2160/ 2172] train: loss: 0.0023656
[Epoch 16] ogbg-molmuv: 0.040485 val loss: 0.011652
[Epoch 16] ogbg-molmuv: 0.025571 test loss: 0.013130
[Epoch 17; Iter    18/ 2172] train: loss: 0.0014291
[Epoch 17; Iter    48/ 2172] train: loss: 0.0017340
[Epoch 17; Iter    78/ 2172] train: loss: 0.0888585
[Epoch 17; Iter   108/ 2172] train: loss: 0.1199516
[Epoch 17; Iter   138/ 2172] train: loss: 0.0015430
[Epoch 17; Iter   168/ 2172] train: loss: 0.0019239
[Epoch 17; Iter   198/ 2172] train: loss: 0.0030863
[Epoch 17; Iter   228/ 2172] train: loss: 0.0018397
[Epoch 17; Iter   258/ 2172] train: loss: 0.0024637
[Epoch 17; Iter   288/ 2172] train: loss: 0.0021713
[Epoch 17; Iter   318/ 2172] train: loss: 0.0014323
[Epoch 17; Iter   348/ 2172] train: loss: 0.0016150
[Epoch 17; Iter   378/ 2172] train: loss: 0.0016930
[Epoch 17; Iter   408/ 2172] train: loss: 0.0028541
[Epoch 17; Iter   438/ 2172] train: loss: 0.0014300
[Epoch 17; Iter   468/ 2172] train: loss: 0.0010028
[Epoch 17; Iter   498/ 2172] train: loss: 0.0014904
[Epoch 17; Iter   528/ 2172] train: loss: 0.0015735
[Epoch 17; Iter   558/ 2172] train: loss: 0.0026300
[Epoch 17; Iter   588/ 2172] train: loss: 0.0016469
[Epoch 17; Iter   618/ 2172] train: loss: 0.0020831
[Epoch 17; Iter   648/ 2172] train: loss: 0.0747757
[Epoch 17; Iter   678/ 2172] train: loss: 0.0826495
[Epoch 17; Iter   708/ 2172] train: loss: 0.0018664
[Epoch 17; Iter   738/ 2172] train: loss: 0.0014587
[Epoch 17; Iter   768/ 2172] train: loss: 0.0022177
[Epoch 17; Iter   798/ 2172] train: loss: 0.0018306
[Epoch 17; Iter   828/ 2172] train: loss: 0.0035168
[Epoch 17; Iter   858/ 2172] train: loss: 0.0760342
[Epoch 15; Iter   642/ 2172] train: loss: 0.0012656
[Epoch 15; Iter   672/ 2172] train: loss: 0.0016458
[Epoch 15; Iter   702/ 2172] train: loss: 0.0017932
[Epoch 15; Iter   732/ 2172] train: loss: 0.0016888
[Epoch 15; Iter   762/ 2172] train: loss: 0.0019137
[Epoch 15; Iter   792/ 2172] train: loss: 0.0677943
[Epoch 15; Iter   822/ 2172] train: loss: 0.0022491
[Epoch 15; Iter   852/ 2172] train: loss: 0.0048295
[Epoch 15; Iter   882/ 2172] train: loss: 0.0026784
[Epoch 15; Iter   912/ 2172] train: loss: 0.0021744
[Epoch 15; Iter   942/ 2172] train: loss: 0.0017211
[Epoch 15; Iter   972/ 2172] train: loss: 0.0014829
[Epoch 15; Iter  1002/ 2172] train: loss: 0.0015654
[Epoch 15; Iter  1032/ 2172] train: loss: 0.0014783
[Epoch 15; Iter  1062/ 2172] train: loss: 0.0010149
[Epoch 15; Iter  1092/ 2172] train: loss: 0.0022235
[Epoch 15; Iter  1122/ 2172] train: loss: 0.0017357
[Epoch 15; Iter  1152/ 2172] train: loss: 0.1078898
[Epoch 15; Iter  1182/ 2172] train: loss: 0.0012237
[Epoch 15; Iter  1212/ 2172] train: loss: 0.0579335
[Epoch 15; Iter  1242/ 2172] train: loss: 0.0018728
[Epoch 15; Iter  1272/ 2172] train: loss: 0.0027761
[Epoch 15; Iter  1302/ 2172] train: loss: 0.0020787
[Epoch 15; Iter  1332/ 2172] train: loss: 0.0018746
[Epoch 15; Iter  1362/ 2172] train: loss: 0.0018962
[Epoch 15; Iter  1392/ 2172] train: loss: 0.0011277
[Epoch 15; Iter  1422/ 2172] train: loss: 0.0010875
[Epoch 15; Iter  1452/ 2172] train: loss: 0.0014076
[Epoch 15; Iter  1482/ 2172] train: loss: 0.0011069
[Epoch 15; Iter  1512/ 2172] train: loss: 0.0011769
[Epoch 15; Iter  1542/ 2172] train: loss: 0.0012177
[Epoch 15; Iter  1572/ 2172] train: loss: 0.0564856
[Epoch 15; Iter  1602/ 2172] train: loss: 0.0020766
[Epoch 15; Iter  1632/ 2172] train: loss: 0.0026894
[Epoch 15; Iter  1662/ 2172] train: loss: 0.0014237
[Epoch 15; Iter  1692/ 2172] train: loss: 0.0015214
[Epoch 15; Iter  1722/ 2172] train: loss: 0.0012312
[Epoch 15; Iter  1752/ 2172] train: loss: 0.0013471
[Epoch 15; Iter  1782/ 2172] train: loss: 0.0529418
[Epoch 15; Iter  1812/ 2172] train: loss: 0.0743946
[Epoch 15; Iter  1842/ 2172] train: loss: 0.0020183
[Epoch 15; Iter  1872/ 2172] train: loss: 0.0014609
[Epoch 15; Iter  1902/ 2172] train: loss: 0.0013348
[Epoch 15; Iter  1932/ 2172] train: loss: 0.0535179
[Epoch 15; Iter  1962/ 2172] train: loss: 0.0573104
[Epoch 15; Iter  1992/ 2172] train: loss: 0.0015855
[Epoch 15; Iter  2022/ 2172] train: loss: 0.0017195
[Epoch 15; Iter  2052/ 2172] train: loss: 0.0380879
[Epoch 15; Iter  2082/ 2172] train: loss: 0.0016976
[Epoch 15; Iter  2112/ 2172] train: loss: 0.0016166
[Epoch 15; Iter  2142/ 2172] train: loss: 0.0012727
[Epoch 15; Iter  2172/ 2172] train: loss: 0.0017249
[Epoch 15] ogbg-molmuv: 0.054523 val loss: 0.014477
[Epoch 15] ogbg-molmuv: 0.065016 test loss: 0.013727
[Epoch 16; Iter    30/ 2172] train: loss: 0.0011761
[Epoch 16; Iter    60/ 2172] train: loss: 0.0014197
[Epoch 16; Iter    90/ 2172] train: loss: 0.0013776
[Epoch 16; Iter   120/ 2172] train: loss: 0.0014901
[Epoch 16; Iter   150/ 2172] train: loss: 0.0013423
[Epoch 16; Iter   180/ 2172] train: loss: 0.0012876
[Epoch 16; Iter   210/ 2172] train: loss: 0.0014224
[Epoch 16; Iter   240/ 2172] train: loss: 0.0016159
[Epoch 16; Iter   270/ 2172] train: loss: 0.1301971
[Epoch 16; Iter   300/ 2172] train: loss: 0.0018490
[Epoch 16; Iter   330/ 2172] train: loss: 0.0017254
[Epoch 16; Iter   360/ 2172] train: loss: 0.2281163
[Epoch 16; Iter   390/ 2172] train: loss: 0.0025376
[Epoch 16; Iter   420/ 2172] train: loss: 0.0019650
[Epoch 16; Iter   450/ 2172] train: loss: 0.0016495
[Epoch 16; Iter   480/ 2172] train: loss: 0.0017107
[Epoch 16; Iter   510/ 2172] train: loss: 0.0016662
[Epoch 16; Iter   540/ 2172] train: loss: 0.0025797
[Epoch 16; Iter   570/ 2172] train: loss: 0.0022886
[Epoch 16; Iter   600/ 2172] train: loss: 0.0023857
[Epoch 16; Iter   630/ 2172] train: loss: 0.0036253
[Epoch 16; Iter   660/ 2172] train: loss: 0.0018683
[Epoch 16; Iter   690/ 2172] train: loss: 0.0014690
[Epoch 16; Iter   720/ 2172] train: loss: 0.0016476
[Epoch 16; Iter   750/ 2172] train: loss: 0.0665694
[Epoch 16; Iter   780/ 2172] train: loss: 0.0020735
[Epoch 16; Iter   810/ 2172] train: loss: 0.0017209
[Epoch 16; Iter   840/ 2172] train: loss: 0.0015857
[Epoch 16; Iter   870/ 2172] train: loss: 0.0015382
[Epoch 16; Iter   900/ 2172] train: loss: 0.0023196
[Epoch 16; Iter   930/ 2172] train: loss: 0.0018353
[Epoch 16; Iter   960/ 2172] train: loss: 0.0015926
[Epoch 16; Iter   990/ 2172] train: loss: 0.0017620
[Epoch 16; Iter  1020/ 2172] train: loss: 0.0674976
[Epoch 16; Iter  1050/ 2172] train: loss: 0.0017805
[Epoch 16; Iter  1080/ 2172] train: loss: 0.0014423
[Epoch 16; Iter  1110/ 2172] train: loss: 0.0015604
[Epoch 16; Iter  1140/ 2172] train: loss: 0.0692620
[Epoch 16; Iter  1170/ 2172] train: loss: 0.0015565
[Epoch 16; Iter  1200/ 2172] train: loss: 0.0026536
[Epoch 16; Iter  1230/ 2172] train: loss: 0.0072572
[Epoch 16; Iter  1260/ 2172] train: loss: 0.0028056
[Epoch 16; Iter  1290/ 2172] train: loss: 0.0012526
[Epoch 16; Iter  1320/ 2172] train: loss: 0.0021904
[Epoch 16; Iter  1350/ 2172] train: loss: 0.0023099
[Epoch 16; Iter  1380/ 2172] train: loss: 0.0068502
[Epoch 16; Iter  1410/ 2172] train: loss: 0.0931132
[Epoch 16; Iter  1440/ 2172] train: loss: 0.0792949
[Epoch 16; Iter  1470/ 2172] train: loss: 0.0060790
[Epoch 16; Iter  1500/ 2172] train: loss: 0.0042532
[Epoch 16; Iter  1530/ 2172] train: loss: 0.0020472
[Epoch 16; Iter  1560/ 2172] train: loss: 0.0021434
[Epoch 16; Iter  1590/ 2172] train: loss: 0.0018389
[Epoch 16; Iter  1620/ 2172] train: loss: 0.1053429
[Epoch 16; Iter  1650/ 2172] train: loss: 0.0014954
[Epoch 16; Iter  1680/ 2172] train: loss: 0.0014887
[Epoch 16; Iter  1710/ 2172] train: loss: 0.0022297
[Epoch 16; Iter  1740/ 2172] train: loss: 0.0015984
[Epoch 16; Iter  1770/ 2172] train: loss: 0.0014351
[Epoch 16; Iter  1800/ 2172] train: loss: 0.0012463
[Epoch 16; Iter  1830/ 2172] train: loss: 0.0014230
[Epoch 16; Iter  1860/ 2172] train: loss: 0.0023444
[Epoch 16; Iter  1890/ 2172] train: loss: 0.0018616
[Epoch 16; Iter  1920/ 2172] train: loss: 0.1038373
[Epoch 16; Iter  1950/ 2172] train: loss: 0.0471160
[Epoch 16; Iter  1980/ 2172] train: loss: 0.0021499
[Epoch 16; Iter  2010/ 2172] train: loss: 0.0014521
[Epoch 16; Iter  2040/ 2172] train: loss: 0.0029785
[Epoch 16; Iter  2070/ 2172] train: loss: 0.0011998
[Epoch 16; Iter  2100/ 2172] train: loss: 0.0011935
[Epoch 16; Iter  2130/ 2172] train: loss: 0.0010403
[Epoch 16; Iter  2160/ 2172] train: loss: 0.0019737
[Epoch 16] ogbg-molmuv: 0.030207 val loss: 0.013438
[Epoch 16] ogbg-molmuv: 0.085699 test loss: 0.012624
[Epoch 17; Iter    18/ 2172] train: loss: 0.0017948
[Epoch 17; Iter    48/ 2172] train: loss: 0.0022053
[Epoch 17; Iter    78/ 2172] train: loss: 0.0012974
[Epoch 17; Iter   108/ 2172] train: loss: 0.0018651
[Epoch 17; Iter   138/ 2172] train: loss: 0.0014894
[Epoch 17; Iter   168/ 2172] train: loss: 0.0017804
[Epoch 17; Iter   198/ 2172] train: loss: 0.0017503
[Epoch 17; Iter   228/ 2172] train: loss: 0.0016495
[Epoch 17; Iter   258/ 2172] train: loss: 0.0041437
[Epoch 17; Iter   288/ 2172] train: loss: 0.0023088
[Epoch 17; Iter   318/ 2172] train: loss: 0.0014232
[Epoch 17; Iter   348/ 2172] train: loss: 0.0015831
[Epoch 17; Iter   378/ 2172] train: loss: 0.0013712
[Epoch 17; Iter   408/ 2172] train: loss: 0.0015455
[Epoch 17; Iter   438/ 2172] train: loss: 0.0011713
[Epoch 17; Iter   468/ 2172] train: loss: 0.0015308
[Epoch 17; Iter   498/ 2172] train: loss: 0.0012242
[Epoch 17; Iter   528/ 2172] train: loss: 0.0016887
[Epoch 17; Iter   558/ 2172] train: loss: 0.0015996
[Epoch 17; Iter   588/ 2172] train: loss: 0.0020221
[Epoch 17; Iter   618/ 2172] train: loss: 0.0024602
[Epoch 17; Iter   648/ 2172] train: loss: 0.0014158
[Epoch 17; Iter   678/ 2172] train: loss: 0.0017459
[Epoch 17; Iter   708/ 2172] train: loss: 0.0018803
[Epoch 17; Iter   738/ 2172] train: loss: 0.0017370
[Epoch 17; Iter   768/ 2172] train: loss: 0.0016432
[Epoch 17; Iter   798/ 2172] train: loss: 0.0015946
[Epoch 17; Iter   828/ 2172] train: loss: 0.0028229
[Epoch 17; Iter   858/ 2172] train: loss: 0.0037681
[Epoch 15; Iter  1028/ 2483] train: loss: 0.0012135
[Epoch 15; Iter  1058/ 2483] train: loss: 0.0011823
[Epoch 15; Iter  1088/ 2483] train: loss: 0.0017008
[Epoch 15; Iter  1118/ 2483] train: loss: 0.0013614
[Epoch 15; Iter  1148/ 2483] train: loss: 0.0015157
[Epoch 15; Iter  1178/ 2483] train: loss: 0.0023489
[Epoch 15; Iter  1208/ 2483] train: loss: 0.0017093
[Epoch 15; Iter  1238/ 2483] train: loss: 0.0013911
[Epoch 15; Iter  1268/ 2483] train: loss: 0.0017752
[Epoch 15; Iter  1298/ 2483] train: loss: 0.0014293
[Epoch 15; Iter  1328/ 2483] train: loss: 0.0009800
[Epoch 15; Iter  1358/ 2483] train: loss: 0.0009309
[Epoch 15; Iter  1388/ 2483] train: loss: 0.0014751
[Epoch 15; Iter  1418/ 2483] train: loss: 0.0013950
[Epoch 15; Iter  1448/ 2483] train: loss: 0.0063182
[Epoch 15; Iter  1478/ 2483] train: loss: 0.0030655
[Epoch 15; Iter  1508/ 2483] train: loss: 0.1518910
[Epoch 15; Iter  1538/ 2483] train: loss: 0.0043857
[Epoch 15; Iter  1568/ 2483] train: loss: 0.0030046
[Epoch 15; Iter  1598/ 2483] train: loss: 0.0761962
[Epoch 15; Iter  1628/ 2483] train: loss: 0.0036362
[Epoch 15; Iter  1658/ 2483] train: loss: 0.0019698
[Epoch 15; Iter  1688/ 2483] train: loss: 0.0017227
[Epoch 15; Iter  1718/ 2483] train: loss: 0.0015128
[Epoch 15; Iter  1748/ 2483] train: loss: 0.0012840
[Epoch 15; Iter  1778/ 2483] train: loss: 0.0696860
[Epoch 15; Iter  1808/ 2483] train: loss: 0.0020325
[Epoch 15; Iter  1838/ 2483] train: loss: 0.0017540
[Epoch 15; Iter  1868/ 2483] train: loss: 0.0016380
[Epoch 15; Iter  1898/ 2483] train: loss: 0.0014885
[Epoch 15; Iter  1928/ 2483] train: loss: 0.0013101
[Epoch 15; Iter  1958/ 2483] train: loss: 0.0031873
[Epoch 15; Iter  1988/ 2483] train: loss: 0.0014469
[Epoch 15; Iter  2018/ 2483] train: loss: 0.0016283
[Epoch 15; Iter  2048/ 2483] train: loss: 0.0020662
[Epoch 15; Iter  2078/ 2483] train: loss: 0.0015631
[Epoch 15; Iter  2108/ 2483] train: loss: 0.0833288
[Epoch 15; Iter  2138/ 2483] train: loss: 0.0027307
[Epoch 15; Iter  2168/ 2483] train: loss: 0.0016187
[Epoch 15; Iter  2198/ 2483] train: loss: 0.0548985
[Epoch 15; Iter  2228/ 2483] train: loss: 0.0016378
[Epoch 15; Iter  2258/ 2483] train: loss: 0.0013704
[Epoch 15; Iter  2288/ 2483] train: loss: 0.0012468
[Epoch 15; Iter  2318/ 2483] train: loss: 0.0016467
[Epoch 15; Iter  2348/ 2483] train: loss: 0.0019739
[Epoch 15; Iter  2378/ 2483] train: loss: 0.0812353
[Epoch 15; Iter  2408/ 2483] train: loss: 0.0014260
[Epoch 15; Iter  2438/ 2483] train: loss: 0.0025634
[Epoch 15; Iter  2468/ 2483] train: loss: 0.0013637
[Epoch 15] ogbg-molmuv: 0.066609 val loss: 0.040457
[Epoch 15] ogbg-molmuv: 0.063370 test loss: 0.059383
[Epoch 16; Iter    15/ 2483] train: loss: 0.0017058
[Epoch 16; Iter    45/ 2483] train: loss: 0.0014707
[Epoch 16; Iter    75/ 2483] train: loss: 0.0014545
[Epoch 16; Iter   105/ 2483] train: loss: 0.0017499
[Epoch 16; Iter   135/ 2483] train: loss: 0.0017164
[Epoch 16; Iter   165/ 2483] train: loss: 0.0017328
[Epoch 16; Iter   195/ 2483] train: loss: 0.0012083
[Epoch 16; Iter   225/ 2483] train: loss: 0.0013229
[Epoch 16; Iter   255/ 2483] train: loss: 0.0957062
[Epoch 16; Iter   285/ 2483] train: loss: 0.0011120
[Epoch 16; Iter   315/ 2483] train: loss: 0.0014207
[Epoch 16; Iter   345/ 2483] train: loss: 0.0014429
[Epoch 16; Iter   375/ 2483] train: loss: 0.0016260
[Epoch 16; Iter   405/ 2483] train: loss: 0.0015362
[Epoch 16; Iter   435/ 2483] train: loss: 0.0016804
[Epoch 16; Iter   465/ 2483] train: loss: 0.0019052
[Epoch 16; Iter   495/ 2483] train: loss: 0.0016647
[Epoch 16; Iter   525/ 2483] train: loss: 0.0015856
[Epoch 16; Iter   555/ 2483] train: loss: 0.0017636
[Epoch 16; Iter   585/ 2483] train: loss: 0.1094062
[Epoch 16; Iter   615/ 2483] train: loss: 0.0016721
[Epoch 16; Iter   645/ 2483] train: loss: 0.0013343
[Epoch 16; Iter   675/ 2483] train: loss: 0.0018063
[Epoch 16; Iter   705/ 2483] train: loss: 0.0017432
[Epoch 16; Iter   735/ 2483] train: loss: 0.0081907
[Epoch 16; Iter   765/ 2483] train: loss: 0.0016386
[Epoch 16; Iter   795/ 2483] train: loss: 0.0012132
[Epoch 16; Iter   825/ 2483] train: loss: 0.0014730
[Epoch 16; Iter   855/ 2483] train: loss: 0.0021389
[Epoch 16; Iter   885/ 2483] train: loss: 0.0017743
[Epoch 16; Iter   915/ 2483] train: loss: 0.0012619
[Epoch 16; Iter   945/ 2483] train: loss: 0.0013594
[Epoch 16; Iter   975/ 2483] train: loss: 0.0787970
[Epoch 16; Iter  1005/ 2483] train: loss: 0.0019055
[Epoch 16; Iter  1035/ 2483] train: loss: 0.0606278
[Epoch 16; Iter  1065/ 2483] train: loss: 0.0028096
[Epoch 16; Iter  1095/ 2483] train: loss: 0.0018216
[Epoch 16; Iter  1125/ 2483] train: loss: 0.0021409
[Epoch 16; Iter  1155/ 2483] train: loss: 0.0029153
[Epoch 16; Iter  1185/ 2483] train: loss: 0.0043285
[Epoch 16; Iter  1215/ 2483] train: loss: 0.0756512
[Epoch 16; Iter  1245/ 2483] train: loss: 0.0017610
[Epoch 16; Iter  1275/ 2483] train: loss: 0.1089238
[Epoch 16; Iter  1305/ 2483] train: loss: 0.0017619
[Epoch 16; Iter  1335/ 2483] train: loss: 0.0020289
[Epoch 16; Iter  1365/ 2483] train: loss: 0.0426279
[Epoch 16; Iter  1395/ 2483] train: loss: 0.0038166
[Epoch 16; Iter  1425/ 2483] train: loss: 0.0029402
[Epoch 16; Iter  1455/ 2483] train: loss: 0.0019014
[Epoch 16; Iter  1485/ 2483] train: loss: 0.0015575
[Epoch 16; Iter  1515/ 2483] train: loss: 0.0022572
[Epoch 16; Iter  1545/ 2483] train: loss: 0.0020479
[Epoch 16; Iter  1575/ 2483] train: loss: 0.0030780
[Epoch 16; Iter  1605/ 2483] train: loss: 0.0018670
[Epoch 16; Iter  1635/ 2483] train: loss: 0.0017871
[Epoch 16; Iter  1665/ 2483] train: loss: 0.0014604
[Epoch 16; Iter  1695/ 2483] train: loss: 0.0018276
[Epoch 16; Iter  1725/ 2483] train: loss: 0.0013426
[Epoch 16; Iter  1755/ 2483] train: loss: 0.0015480
[Epoch 16; Iter  1785/ 2483] train: loss: 0.0013810
[Epoch 16; Iter  1815/ 2483] train: loss: 0.0016809
[Epoch 16; Iter  1845/ 2483] train: loss: 0.0017826
[Epoch 16; Iter  1875/ 2483] train: loss: 0.0016593
[Epoch 16; Iter  1905/ 2483] train: loss: 0.0626782
[Epoch 16; Iter  1935/ 2483] train: loss: 0.0017774
[Epoch 16; Iter  1965/ 2483] train: loss: 0.0837569
[Epoch 16; Iter  1995/ 2483] train: loss: 0.0012714
[Epoch 16; Iter  2025/ 2483] train: loss: 0.0029566
[Epoch 16; Iter  2055/ 2483] train: loss: 0.0861691
[Epoch 16; Iter  2085/ 2483] train: loss: 0.0014751
[Epoch 16; Iter  2115/ 2483] train: loss: 0.0015310
[Epoch 16; Iter  2145/ 2483] train: loss: 0.1651607
[Epoch 16; Iter  2175/ 2483] train: loss: 0.0021019
[Epoch 16; Iter  2205/ 2483] train: loss: 0.0030188
[Epoch 16; Iter  2235/ 2483] train: loss: 0.0021823
[Epoch 16; Iter  2265/ 2483] train: loss: 0.0145934
[Epoch 16; Iter  2295/ 2483] train: loss: 0.0020143
[Epoch 16; Iter  2325/ 2483] train: loss: 0.0014847
[Epoch 16; Iter  2355/ 2483] train: loss: 0.0021342
[Epoch 16; Iter  2385/ 2483] train: loss: 0.0020782
[Epoch 16; Iter  2415/ 2483] train: loss: 0.0020510
[Epoch 16; Iter  2445/ 2483] train: loss: 0.0017355
[Epoch 16; Iter  2475/ 2483] train: loss: 0.0014411
[Epoch 16] ogbg-molmuv: 0.056458 val loss: 0.020879
[Epoch 16] ogbg-molmuv: 0.112310 test loss: 0.019150
[Epoch 17; Iter    22/ 2483] train: loss: 0.0022141
[Epoch 17; Iter    52/ 2483] train: loss: 0.0017329
[Epoch 17; Iter    82/ 2483] train: loss: 0.0040787
[Epoch 17; Iter   112/ 2483] train: loss: 0.0016343
[Epoch 17; Iter   142/ 2483] train: loss: 0.0020276
[Epoch 17; Iter   172/ 2483] train: loss: 0.0897086
[Epoch 17; Iter   202/ 2483] train: loss: 0.0023106
[Epoch 17; Iter   232/ 2483] train: loss: 0.0015845
[Epoch 17; Iter   262/ 2483] train: loss: 0.0033296
[Epoch 17; Iter   292/ 2483] train: loss: 0.0037184
[Epoch 17; Iter   322/ 2483] train: loss: 0.0022057
[Epoch 17; Iter   352/ 2483] train: loss: 0.0033636
[Epoch 17; Iter   382/ 2483] train: loss: 0.0023334
[Epoch 17; Iter   412/ 2483] train: loss: 0.0025021
[Epoch 17; Iter   442/ 2483] train: loss: 0.0023970
[Epoch 17; Iter   472/ 2483] train: loss: 0.0017495
[Epoch 17; Iter   502/ 2483] train: loss: 0.0046412
[Epoch 17; Iter   532/ 2483] train: loss: 0.0022505
[Epoch 17; Iter   562/ 2483] train: loss: 0.0025211
[Epoch 17; Iter   592/ 2483] train: loss: 0.0833579
[Epoch 17; Iter   622/ 2483] train: loss: 0.0020270
[Epoch 15; Iter  1028/ 2483] train: loss: 0.2428258
[Epoch 15; Iter  1058/ 2483] train: loss: 0.0019258
[Epoch 15; Iter  1088/ 2483] train: loss: 0.0931917
[Epoch 15; Iter  1118/ 2483] train: loss: 0.0636314
[Epoch 15; Iter  1148/ 2483] train: loss: 0.0022939
[Epoch 15; Iter  1178/ 2483] train: loss: 0.0021377
[Epoch 15; Iter  1208/ 2483] train: loss: 0.0023935
[Epoch 15; Iter  1238/ 2483] train: loss: 0.0021686
[Epoch 15; Iter  1268/ 2483] train: loss: 0.0017495
[Epoch 15; Iter  1298/ 2483] train: loss: 0.0680600
[Epoch 15; Iter  1328/ 2483] train: loss: 0.0018712
[Epoch 15; Iter  1358/ 2483] train: loss: 0.0020850
[Epoch 15; Iter  1388/ 2483] train: loss: 0.0025334
[Epoch 15; Iter  1418/ 2483] train: loss: 0.0022074
[Epoch 15; Iter  1448/ 2483] train: loss: 0.0017599
[Epoch 15; Iter  1478/ 2483] train: loss: 0.0724735
[Epoch 15; Iter  1508/ 2483] train: loss: 0.0013360
[Epoch 15; Iter  1538/ 2483] train: loss: 0.0627587
[Epoch 15; Iter  1568/ 2483] train: loss: 0.0015094
[Epoch 15; Iter  1598/ 2483] train: loss: 0.0020294
[Epoch 15; Iter  1628/ 2483] train: loss: 0.0014099
[Epoch 15; Iter  1658/ 2483] train: loss: 0.0025776
[Epoch 15; Iter  1688/ 2483] train: loss: 0.0017459
[Epoch 15; Iter  1718/ 2483] train: loss: 0.0016254
[Epoch 15; Iter  1748/ 2483] train: loss: 0.0019061
[Epoch 15; Iter  1778/ 2483] train: loss: 0.0016529
[Epoch 15; Iter  1808/ 2483] train: loss: 0.0020032
[Epoch 15; Iter  1838/ 2483] train: loss: 0.0014581
[Epoch 15; Iter  1868/ 2483] train: loss: 0.0023579
[Epoch 15; Iter  1898/ 2483] train: loss: 0.0705977
[Epoch 15; Iter  1928/ 2483] train: loss: 0.0024279
[Epoch 15; Iter  1958/ 2483] train: loss: 0.0025361
[Epoch 15; Iter  1988/ 2483] train: loss: 0.0018429
[Epoch 15; Iter  2018/ 2483] train: loss: 0.0030434
[Epoch 15; Iter  2048/ 2483] train: loss: 0.0019304
[Epoch 15; Iter  2078/ 2483] train: loss: 0.0018066
[Epoch 15; Iter  2108/ 2483] train: loss: 0.1040465
[Epoch 15; Iter  2138/ 2483] train: loss: 0.0018129
[Epoch 15; Iter  2168/ 2483] train: loss: 0.0017526
[Epoch 15; Iter  2198/ 2483] train: loss: 0.0014103
[Epoch 15; Iter  2228/ 2483] train: loss: 0.0023176
[Epoch 15; Iter  2258/ 2483] train: loss: 0.0017022
[Epoch 15; Iter  2288/ 2483] train: loss: 0.0022936
[Epoch 15; Iter  2318/ 2483] train: loss: 0.0024221
[Epoch 15; Iter  2348/ 2483] train: loss: 0.0017930
[Epoch 15; Iter  2378/ 2483] train: loss: 0.0032495
[Epoch 15; Iter  2408/ 2483] train: loss: 0.0015984
[Epoch 15; Iter  2438/ 2483] train: loss: 0.0937459
[Epoch 15; Iter  2468/ 2483] train: loss: 0.0016000
[Epoch 15] ogbg-molmuv: 0.084410 val loss: 0.010925
[Epoch 15] ogbg-molmuv: 0.126498 test loss: 0.014300
[Epoch 16; Iter    15/ 2483] train: loss: 0.0021271
[Epoch 16; Iter    45/ 2483] train: loss: 0.0024057
[Epoch 16; Iter    75/ 2483] train: loss: 0.0016898
[Epoch 16; Iter   105/ 2483] train: loss: 0.0019100
[Epoch 16; Iter   135/ 2483] train: loss: 0.0017294
[Epoch 16; Iter   165/ 2483] train: loss: 0.0022016
[Epoch 16; Iter   195/ 2483] train: loss: 0.0034673
[Epoch 16; Iter   225/ 2483] train: loss: 0.0020051
[Epoch 16; Iter   255/ 2483] train: loss: 0.0019755
[Epoch 16; Iter   285/ 2483] train: loss: 0.0011203
[Epoch 16; Iter   315/ 2483] train: loss: 0.0009214
[Epoch 16; Iter   345/ 2483] train: loss: 0.0016633
[Epoch 16; Iter   375/ 2483] train: loss: 0.1055259
[Epoch 16; Iter   405/ 2483] train: loss: 0.0011198
[Epoch 16; Iter   435/ 2483] train: loss: 0.0014732
[Epoch 16; Iter   465/ 2483] train: loss: 0.0016885
[Epoch 16; Iter   495/ 2483] train: loss: 0.0015143
[Epoch 16; Iter   525/ 2483] train: loss: 0.0024427
[Epoch 16; Iter   555/ 2483] train: loss: 0.0022619
[Epoch 16; Iter   585/ 2483] train: loss: 0.0019253
[Epoch 16; Iter   615/ 2483] train: loss: 0.0015701
[Epoch 16; Iter   645/ 2483] train: loss: 0.0013751
[Epoch 16; Iter   675/ 2483] train: loss: 0.0017863
[Epoch 16; Iter   705/ 2483] train: loss: 0.0018782
[Epoch 16; Iter   735/ 2483] train: loss: 0.0020258
[Epoch 16; Iter   765/ 2483] train: loss: 0.0022294
[Epoch 16; Iter   795/ 2483] train: loss: 0.0014597
[Epoch 16; Iter   825/ 2483] train: loss: 0.0021416
[Epoch 16; Iter   855/ 2483] train: loss: 0.0015144
[Epoch 16; Iter   885/ 2483] train: loss: 0.0017950
[Epoch 16; Iter   915/ 2483] train: loss: 0.0015972
[Epoch 16; Iter   945/ 2483] train: loss: 0.0014669
[Epoch 16; Iter   975/ 2483] train: loss: 0.0011489
[Epoch 16; Iter  1005/ 2483] train: loss: 0.0036505
[Epoch 16; Iter  1035/ 2483] train: loss: 0.0028671
[Epoch 16; Iter  1065/ 2483] train: loss: 0.0020162
[Epoch 16; Iter  1095/ 2483] train: loss: 0.0013794
[Epoch 16; Iter  1125/ 2483] train: loss: 0.0017666
[Epoch 16; Iter  1155/ 2483] train: loss: 0.0025362
[Epoch 16; Iter  1185/ 2483] train: loss: 0.0026104
[Epoch 16; Iter  1215/ 2483] train: loss: 0.0682473
[Epoch 16; Iter  1245/ 2483] train: loss: 0.0019289
[Epoch 16; Iter  1275/ 2483] train: loss: 0.0020183
[Epoch 16; Iter  1305/ 2483] train: loss: 0.0518349
[Epoch 16; Iter  1335/ 2483] train: loss: 0.0028096
[Epoch 16; Iter  1365/ 2483] train: loss: 0.0025167
[Epoch 16; Iter  1395/ 2483] train: loss: 0.0019973
[Epoch 16; Iter  1425/ 2483] train: loss: 0.0847411
[Epoch 16; Iter  1455/ 2483] train: loss: 0.0015762
[Epoch 16; Iter  1485/ 2483] train: loss: 0.0020542
[Epoch 16; Iter  1515/ 2483] train: loss: 0.0017851
[Epoch 16; Iter  1545/ 2483] train: loss: 0.0018604
[Epoch 16; Iter  1575/ 2483] train: loss: 0.0022328
[Epoch 16; Iter  1605/ 2483] train: loss: 0.0037425
[Epoch 16; Iter  1635/ 2483] train: loss: 0.0024176
[Epoch 16; Iter  1665/ 2483] train: loss: 0.0014704
[Epoch 16; Iter  1695/ 2483] train: loss: 0.0012082
[Epoch 16; Iter  1725/ 2483] train: loss: 0.0025477
[Epoch 16; Iter  1755/ 2483] train: loss: 0.0016566
[Epoch 16; Iter  1785/ 2483] train: loss: 0.0031997
[Epoch 16; Iter  1815/ 2483] train: loss: 0.0019600
[Epoch 16; Iter  1845/ 2483] train: loss: 0.0012755
[Epoch 16; Iter  1875/ 2483] train: loss: 0.0021051
[Epoch 16; Iter  1905/ 2483] train: loss: 0.0018761
[Epoch 16; Iter  1935/ 2483] train: loss: 0.0021151
[Epoch 16; Iter  1965/ 2483] train: loss: 0.0021050
[Epoch 16; Iter  1995/ 2483] train: loss: 0.0012867
[Epoch 16; Iter  2025/ 2483] train: loss: 0.0016189
[Epoch 16; Iter  2055/ 2483] train: loss: 0.0013671
[Epoch 16; Iter  2085/ 2483] train: loss: 0.0010238
[Epoch 16; Iter  2115/ 2483] train: loss: 0.0019455
[Epoch 16; Iter  2145/ 2483] train: loss: 0.0087760
[Epoch 16; Iter  2175/ 2483] train: loss: 0.0017394
[Epoch 16; Iter  2205/ 2483] train: loss: 0.0016779
[Epoch 16; Iter  2235/ 2483] train: loss: 0.0014167
[Epoch 16; Iter  2265/ 2483] train: loss: 0.0036095
[Epoch 16; Iter  2295/ 2483] train: loss: 0.0023763
[Epoch 16; Iter  2325/ 2483] train: loss: 0.0021826
[Epoch 16; Iter  2355/ 2483] train: loss: 0.0024329
[Epoch 16; Iter  2385/ 2483] train: loss: 0.0019076
[Epoch 16; Iter  2415/ 2483] train: loss: 0.0013004
[Epoch 16; Iter  2445/ 2483] train: loss: 0.0852831
[Epoch 16; Iter  2475/ 2483] train: loss: 0.0021122
[Epoch 16] ogbg-molmuv: 0.054481 val loss: 0.017838
[Epoch 16] ogbg-molmuv: 0.106510 test loss: 0.016753
[Epoch 17; Iter    22/ 2483] train: loss: 0.0021721
[Epoch 17; Iter    52/ 2483] train: loss: 0.0021403
[Epoch 17; Iter    82/ 2483] train: loss: 0.0023075
[Epoch 17; Iter   112/ 2483] train: loss: 0.0621800
[Epoch 17; Iter   142/ 2483] train: loss: 0.0032289
[Epoch 17; Iter   172/ 2483] train: loss: 0.0053852
[Epoch 17; Iter   202/ 2483] train: loss: 0.0066310
[Epoch 17; Iter   232/ 2483] train: loss: 0.0024184
[Epoch 17; Iter   262/ 2483] train: loss: 0.0533024
[Epoch 17; Iter   292/ 2483] train: loss: 0.0656937
[Epoch 17; Iter   322/ 2483] train: loss: 0.0024771
[Epoch 17; Iter   352/ 2483] train: loss: 0.0019892
[Epoch 17; Iter   382/ 2483] train: loss: 0.0018589
[Epoch 17; Iter   412/ 2483] train: loss: 0.0025364
[Epoch 17; Iter   442/ 2483] train: loss: 0.0014398
[Epoch 17; Iter   472/ 2483] train: loss: 0.0024134
[Epoch 17; Iter   502/ 2483] train: loss: 0.0952971
[Epoch 17; Iter   532/ 2483] train: loss: 0.0024786
[Epoch 17; Iter   562/ 2483] train: loss: 0.0015814
[Epoch 17; Iter   592/ 2483] train: loss: 0.0021085
[Epoch 17; Iter   622/ 2483] train: loss: 0.0015942
[Epoch 15; Iter  1028/ 2483] train: loss: 0.0020108
[Epoch 15; Iter  1058/ 2483] train: loss: 0.0018117
[Epoch 15; Iter  1088/ 2483] train: loss: 0.0018811
[Epoch 15; Iter  1118/ 2483] train: loss: 0.0014926
[Epoch 15; Iter  1148/ 2483] train: loss: 0.0025838
[Epoch 15; Iter  1178/ 2483] train: loss: 0.0018574
[Epoch 15; Iter  1208/ 2483] train: loss: 0.0014377
[Epoch 15; Iter  1238/ 2483] train: loss: 0.0020302
[Epoch 15; Iter  1268/ 2483] train: loss: 0.0015726
[Epoch 15; Iter  1298/ 2483] train: loss: 0.0016094
[Epoch 15; Iter  1328/ 2483] train: loss: 0.0732911
[Epoch 15; Iter  1358/ 2483] train: loss: 0.0015976
[Epoch 15; Iter  1388/ 2483] train: loss: 0.0013867
[Epoch 15; Iter  1418/ 2483] train: loss: 0.0590923
[Epoch 15; Iter  1448/ 2483] train: loss: 0.0056431
[Epoch 15; Iter  1478/ 2483] train: loss: 0.0661332
[Epoch 15; Iter  1508/ 2483] train: loss: 0.0014712
[Epoch 15; Iter  1538/ 2483] train: loss: 0.0948866
[Epoch 15; Iter  1568/ 2483] train: loss: 0.1003306
[Epoch 15; Iter  1598/ 2483] train: loss: 0.0673762
[Epoch 15; Iter  1628/ 2483] train: loss: 0.0015964
[Epoch 15; Iter  1658/ 2483] train: loss: 0.0029617
[Epoch 15; Iter  1688/ 2483] train: loss: 0.0024505
[Epoch 15; Iter  1718/ 2483] train: loss: 0.0019519
[Epoch 15; Iter  1748/ 2483] train: loss: 0.0023884
[Epoch 15; Iter  1778/ 2483] train: loss: 0.0016152
[Epoch 15; Iter  1808/ 2483] train: loss: 0.0020077
[Epoch 15; Iter  1838/ 2483] train: loss: 0.0016371
[Epoch 15; Iter  1868/ 2483] train: loss: 0.0328673
[Epoch 15; Iter  1898/ 2483] train: loss: 0.1354385
[Epoch 15; Iter  1928/ 2483] train: loss: 0.0026225
[Epoch 15; Iter  1958/ 2483] train: loss: 0.0026072
[Epoch 15; Iter  1988/ 2483] train: loss: 0.0022110
[Epoch 15; Iter  2018/ 2483] train: loss: 0.0017778
[Epoch 15; Iter  2048/ 2483] train: loss: 0.0018562
[Epoch 15; Iter  2078/ 2483] train: loss: 0.0014162
[Epoch 15; Iter  2108/ 2483] train: loss: 0.0698299
[Epoch 15; Iter  2138/ 2483] train: loss: 0.0016315
[Epoch 15; Iter  2168/ 2483] train: loss: 0.0019700
[Epoch 15; Iter  2198/ 2483] train: loss: 0.0018587
[Epoch 15; Iter  2228/ 2483] train: loss: 0.0240704
[Epoch 15; Iter  2258/ 2483] train: loss: 0.0021529
[Epoch 15; Iter  2288/ 2483] train: loss: 0.0049044
[Epoch 15; Iter  2318/ 2483] train: loss: 0.0012220
[Epoch 15; Iter  2348/ 2483] train: loss: 0.0016295
[Epoch 15; Iter  2378/ 2483] train: loss: 0.0771304
[Epoch 15; Iter  2408/ 2483] train: loss: 0.0033995
[Epoch 15; Iter  2438/ 2483] train: loss: 0.0014523
[Epoch 15; Iter  2468/ 2483] train: loss: 0.0017797
[Epoch 15] ogbg-molmuv: 0.067573 val loss: 0.010002
[Epoch 15] ogbg-molmuv: 0.065681 test loss: 0.087851
[Epoch 16; Iter    15/ 2483] train: loss: 0.0795993
[Epoch 16; Iter    45/ 2483] train: loss: 0.0035116
[Epoch 16; Iter    75/ 2483] train: loss: 0.0014967
[Epoch 16; Iter   105/ 2483] train: loss: 0.0024894
[Epoch 16; Iter   135/ 2483] train: loss: 0.0744380
[Epoch 16; Iter   165/ 2483] train: loss: 0.0043569
[Epoch 16; Iter   195/ 2483] train: loss: 0.0021319
[Epoch 16; Iter   225/ 2483] train: loss: 0.0018330
[Epoch 16; Iter   255/ 2483] train: loss: 0.0162470
[Epoch 16; Iter   285/ 2483] train: loss: 0.0016063
[Epoch 16; Iter   315/ 2483] train: loss: 0.0029358
[Epoch 16; Iter   345/ 2483] train: loss: 0.0021227
[Epoch 16; Iter   375/ 2483] train: loss: 0.0084200
[Epoch 16; Iter   405/ 2483] train: loss: 0.0041069
[Epoch 16; Iter   435/ 2483] train: loss: 0.0021332
[Epoch 16; Iter   465/ 2483] train: loss: 0.0015652
[Epoch 16; Iter   495/ 2483] train: loss: 0.0642786
[Epoch 16; Iter   525/ 2483] train: loss: 0.0012127
[Epoch 16; Iter   555/ 2483] train: loss: 0.0020546
[Epoch 16; Iter   585/ 2483] train: loss: 0.0021215
[Epoch 16; Iter   615/ 2483] train: loss: 0.0704683
[Epoch 16; Iter   645/ 2483] train: loss: 0.0023625
[Epoch 16; Iter   675/ 2483] train: loss: 0.0028636
[Epoch 16; Iter   705/ 2483] train: loss: 0.0016242
[Epoch 16; Iter   735/ 2483] train: loss: 0.0011330
[Epoch 16; Iter   765/ 2483] train: loss: 0.0013081
[Epoch 16; Iter   795/ 2483] train: loss: 0.0018107
[Epoch 16; Iter   825/ 2483] train: loss: 0.0014075
[Epoch 16; Iter   855/ 2483] train: loss: 0.0017338
[Epoch 16; Iter   885/ 2483] train: loss: 0.0016969
[Epoch 16; Iter   915/ 2483] train: loss: 0.0012575
[Epoch 16; Iter   945/ 2483] train: loss: 0.0017362
[Epoch 16; Iter   975/ 2483] train: loss: 0.0011286
[Epoch 16; Iter  1005/ 2483] train: loss: 0.0016627
[Epoch 16; Iter  1035/ 2483] train: loss: 0.0017766
[Epoch 16; Iter  1065/ 2483] train: loss: 0.0024821
[Epoch 16; Iter  1095/ 2483] train: loss: 0.0021575
[Epoch 16; Iter  1125/ 2483] train: loss: 0.0029385
[Epoch 16; Iter  1155/ 2483] train: loss: 0.0012037
[Epoch 16; Iter  1185/ 2483] train: loss: 0.0861204
[Epoch 16; Iter  1215/ 2483] train: loss: 0.0017187
[Epoch 16; Iter  1245/ 2483] train: loss: 0.0020020
[Epoch 16; Iter  1275/ 2483] train: loss: 0.0010705
[Epoch 16; Iter  1305/ 2483] train: loss: 0.0022800
[Epoch 16; Iter  1335/ 2483] train: loss: 0.0018484
[Epoch 16; Iter  1365/ 2483] train: loss: 0.0013624
[Epoch 16; Iter  1395/ 2483] train: loss: 0.0011688
[Epoch 16; Iter  1425/ 2483] train: loss: 0.0022145
[Epoch 16; Iter  1455/ 2483] train: loss: 0.0650116
[Epoch 16; Iter  1485/ 2483] train: loss: 0.0021788
[Epoch 16; Iter  1515/ 2483] train: loss: 0.0025386
[Epoch 16; Iter  1545/ 2483] train: loss: 0.0016064
[Epoch 16; Iter  1575/ 2483] train: loss: 0.0027895
[Epoch 16; Iter  1605/ 2483] train: loss: 0.0013444
[Epoch 16; Iter  1635/ 2483] train: loss: 0.0010260
[Epoch 16; Iter  1665/ 2483] train: loss: 0.0024672
[Epoch 16; Iter  1695/ 2483] train: loss: 0.0012293
[Epoch 16; Iter  1725/ 2483] train: loss: 0.0014310
[Epoch 16; Iter  1755/ 2483] train: loss: 0.0011297
[Epoch 16; Iter  1785/ 2483] train: loss: 0.0009290
[Epoch 16; Iter  1815/ 2483] train: loss: 0.0010319
[Epoch 16; Iter  1845/ 2483] train: loss: 0.0012158
[Epoch 16; Iter  1875/ 2483] train: loss: 0.0012805
[Epoch 16; Iter  1905/ 2483] train: loss: 0.0656729
[Epoch 16; Iter  1935/ 2483] train: loss: 0.0021819
[Epoch 16; Iter  1965/ 2483] train: loss: 0.0018559
[Epoch 16; Iter  1995/ 2483] train: loss: 0.0015203
[Epoch 16; Iter  2025/ 2483] train: loss: 0.0028457
[Epoch 16; Iter  2055/ 2483] train: loss: 0.0015717
[Epoch 16; Iter  2085/ 2483] train: loss: 0.0018911
[Epoch 16; Iter  2115/ 2483] train: loss: 0.0016717
[Epoch 16; Iter  2145/ 2483] train: loss: 0.0029369
[Epoch 16; Iter  2175/ 2483] train: loss: 0.0025539
[Epoch 16; Iter  2205/ 2483] train: loss: 0.0066000
[Epoch 16; Iter  2235/ 2483] train: loss: 0.0018937
[Epoch 16; Iter  2265/ 2483] train: loss: 0.0017208
[Epoch 16; Iter  2295/ 2483] train: loss: 0.0021528
[Epoch 16; Iter  2325/ 2483] train: loss: 0.0010504
[Epoch 16; Iter  2355/ 2483] train: loss: 0.0020567
[Epoch 16; Iter  2385/ 2483] train: loss: 0.0013261
[Epoch 16; Iter  2415/ 2483] train: loss: 0.0016178
[Epoch 16; Iter  2445/ 2483] train: loss: 0.0017816
[Epoch 16; Iter  2475/ 2483] train: loss: 0.0018945
[Epoch 16] ogbg-molmuv: 0.088191 val loss: 0.009929
[Epoch 16] ogbg-molmuv: 0.136889 test loss: 0.013778
[Epoch 17; Iter    22/ 2483] train: loss: 0.0024864
[Epoch 17; Iter    52/ 2483] train: loss: 0.0025270
[Epoch 17; Iter    82/ 2483] train: loss: 0.0016571
[Epoch 17; Iter   112/ 2483] train: loss: 0.1409297
[Epoch 17; Iter   142/ 2483] train: loss: 0.0023475
[Epoch 17; Iter   172/ 2483] train: loss: 0.0015363
[Epoch 17; Iter   202/ 2483] train: loss: 0.0014302
[Epoch 17; Iter   232/ 2483] train: loss: 0.0023906
[Epoch 17; Iter   262/ 2483] train: loss: 0.0015436
[Epoch 17; Iter   292/ 2483] train: loss: 0.0011557
[Epoch 17; Iter   322/ 2483] train: loss: 0.0019342
[Epoch 17; Iter   352/ 2483] train: loss: 0.0016921
[Epoch 17; Iter   382/ 2483] train: loss: 0.0014771
[Epoch 17; Iter   412/ 2483] train: loss: 0.0018262
[Epoch 17; Iter   442/ 2483] train: loss: 0.0045069
[Epoch 17; Iter   472/ 2483] train: loss: 0.0485560
[Epoch 17; Iter   502/ 2483] train: loss: 0.0017190
[Epoch 17; Iter   532/ 2483] train: loss: 0.0018431
[Epoch 17; Iter   562/ 2483] train: loss: 0.0015447
[Epoch 17; Iter   592/ 2483] train: loss: 0.0019146
[Epoch 17; Iter   622/ 2483] train: loss: 0.0034566
[Epoch 17; Iter  1078/ 1862] train: loss: 0.0404366
[Epoch 17; Iter  1108/ 1862] train: loss: 0.0777530
[Epoch 17; Iter  1138/ 1862] train: loss: 0.0403299
[Epoch 17; Iter  1168/ 1862] train: loss: 0.0754072
[Epoch 17; Iter  1198/ 1862] train: loss: 0.0018318
[Epoch 17; Iter  1228/ 1862] train: loss: 0.0015220
[Epoch 17; Iter  1258/ 1862] train: loss: 0.0013012
[Epoch 17; Iter  1288/ 1862] train: loss: 0.0018301
[Epoch 17; Iter  1318/ 1862] train: loss: 0.0017040
[Epoch 17; Iter  1348/ 1862] train: loss: 0.0016117
[Epoch 17; Iter  1378/ 1862] train: loss: 0.0010618
[Epoch 17; Iter  1408/ 1862] train: loss: 0.0015203
[Epoch 17; Iter  1438/ 1862] train: loss: 0.0015080
[Epoch 17; Iter  1468/ 1862] train: loss: 0.0014323
[Epoch 17; Iter  1498/ 1862] train: loss: 0.0012218
[Epoch 17; Iter  1528/ 1862] train: loss: 0.0028361
[Epoch 17; Iter  1558/ 1862] train: loss: 0.0874442
[Epoch 17; Iter  1588/ 1862] train: loss: 0.0019176
[Epoch 17; Iter  1618/ 1862] train: loss: 0.0017232
[Epoch 17; Iter  1648/ 1862] train: loss: 0.0015756
[Epoch 17; Iter  1678/ 1862] train: loss: 0.0016190
[Epoch 17; Iter  1708/ 1862] train: loss: 0.0038814
[Epoch 17; Iter  1738/ 1862] train: loss: 0.0021549
[Epoch 17; Iter  1768/ 1862] train: loss: 0.0544282
[Epoch 17; Iter  1798/ 1862] train: loss: 0.0018625
[Epoch 17; Iter  1828/ 1862] train: loss: 0.0854620
[Epoch 17; Iter  1858/ 1862] train: loss: 0.0776787
[Epoch 17] ogbg-molmuv: 0.024651 val loss: 0.013824
[Epoch 17] ogbg-molmuv: 0.052554 test loss: 0.012915
[Epoch 18; Iter    26/ 1862] train: loss: 0.0670853
[Epoch 18; Iter    56/ 1862] train: loss: 0.0013773
[Epoch 18; Iter    86/ 1862] train: loss: 0.0020878
[Epoch 18; Iter   116/ 1862] train: loss: 0.0765871
[Epoch 18; Iter   146/ 1862] train: loss: 0.0023159
[Epoch 18; Iter   176/ 1862] train: loss: 0.0031784
[Epoch 18; Iter   206/ 1862] train: loss: 0.0025622
[Epoch 18; Iter   236/ 1862] train: loss: 0.0023274
[Epoch 18; Iter   266/ 1862] train: loss: 0.0036736
[Epoch 18; Iter   296/ 1862] train: loss: 0.0033104
[Epoch 18; Iter   326/ 1862] train: loss: 0.0031238
[Epoch 18; Iter   356/ 1862] train: loss: 0.0018980
[Epoch 18; Iter   386/ 1862] train: loss: 0.0015375
[Epoch 18; Iter   416/ 1862] train: loss: 0.0010765
[Epoch 18; Iter   446/ 1862] train: loss: 0.0012396
[Epoch 18; Iter   476/ 1862] train: loss: 0.0494070
[Epoch 18; Iter   506/ 1862] train: loss: 0.0018012
[Epoch 18; Iter   536/ 1862] train: loss: 0.0034399
[Epoch 18; Iter   566/ 1862] train: loss: 0.0021912
[Epoch 18; Iter   596/ 1862] train: loss: 0.1011191
[Epoch 18; Iter   626/ 1862] train: loss: 0.0016570
[Epoch 18; Iter   656/ 1862] train: loss: 0.0016257
[Epoch 18; Iter   686/ 1862] train: loss: 0.0022456
[Epoch 18; Iter   716/ 1862] train: loss: 0.0019657
[Epoch 18; Iter   746/ 1862] train: loss: 0.0768171
[Epoch 18; Iter   776/ 1862] train: loss: 0.0738750
[Epoch 18; Iter   806/ 1862] train: loss: 0.0021125
[Epoch 18; Iter   836/ 1862] train: loss: 0.0022061
[Epoch 18; Iter   866/ 1862] train: loss: 0.0016363
[Epoch 18; Iter   896/ 1862] train: loss: 0.0403058
[Epoch 18; Iter   926/ 1862] train: loss: 0.0015002
[Epoch 18; Iter   956/ 1862] train: loss: 0.0597728
[Epoch 18; Iter   986/ 1862] train: loss: 0.0027028
[Epoch 18; Iter  1016/ 1862] train: loss: 0.0014156
[Epoch 18; Iter  1046/ 1862] train: loss: 0.0015910
[Epoch 18; Iter  1076/ 1862] train: loss: 0.0014635
[Epoch 18; Iter  1106/ 1862] train: loss: 0.0016618
[Epoch 18; Iter  1136/ 1862] train: loss: 0.0019103
[Epoch 18; Iter  1166/ 1862] train: loss: 0.0013684
[Epoch 18; Iter  1196/ 1862] train: loss: 0.0029811
[Epoch 18; Iter  1226/ 1862] train: loss: 0.0014934
[Epoch 18; Iter  1256/ 1862] train: loss: 0.0011222
[Epoch 18; Iter  1286/ 1862] train: loss: 0.0013953
[Epoch 18; Iter  1316/ 1862] train: loss: 0.0015617
[Epoch 18; Iter  1346/ 1862] train: loss: 0.0009000
[Epoch 18; Iter  1376/ 1862] train: loss: 0.0864030
[Epoch 18; Iter  1406/ 1862] train: loss: 0.0012219
[Epoch 18; Iter  1436/ 1862] train: loss: 0.0010323
[Epoch 18; Iter  1466/ 1862] train: loss: 0.0012051
[Epoch 18; Iter  1496/ 1862] train: loss: 0.0016948
[Epoch 18; Iter  1526/ 1862] train: loss: 0.0012776
[Epoch 18; Iter  1556/ 1862] train: loss: 0.0786759
[Epoch 18; Iter  1586/ 1862] train: loss: 0.0017845
[Epoch 18; Iter  1616/ 1862] train: loss: 0.0017502
[Epoch 18; Iter  1646/ 1862] train: loss: 0.0026762
[Epoch 18; Iter  1676/ 1862] train: loss: 0.0018791
[Epoch 18; Iter  1706/ 1862] train: loss: 0.0017548
[Epoch 18; Iter  1736/ 1862] train: loss: 0.0034313
[Epoch 18; Iter  1766/ 1862] train: loss: 0.0015886
[Epoch 18; Iter  1796/ 1862] train: loss: 0.0033269
[Epoch 18; Iter  1826/ 1862] train: loss: 0.0025390
[Epoch 18; Iter  1856/ 1862] train: loss: 0.0024523
[Epoch 18] ogbg-molmuv: 0.025415 val loss: 0.503909
[Epoch 18] ogbg-molmuv: 0.045566 test loss: 0.272982
[Epoch 19; Iter    24/ 1862] train: loss: 0.0016512
[Epoch 19; Iter    54/ 1862] train: loss: 0.0012674
[Epoch 19; Iter    84/ 1862] train: loss: 0.0663708
[Epoch 19; Iter   114/ 1862] train: loss: 0.0015025
[Epoch 19; Iter   144/ 1862] train: loss: 0.0012242
[Epoch 19; Iter   174/ 1862] train: loss: 0.0512080
[Epoch 19; Iter   204/ 1862] train: loss: 0.0019894
[Epoch 19; Iter   234/ 1862] train: loss: 0.0021086
[Epoch 19; Iter   264/ 1862] train: loss: 0.1130860
[Epoch 19; Iter   294/ 1862] train: loss: 0.0021862
[Epoch 19; Iter   324/ 1862] train: loss: 0.0024009
[Epoch 19; Iter   354/ 1862] train: loss: 0.0020684
[Epoch 19; Iter   384/ 1862] train: loss: 0.0759704
[Epoch 19; Iter   414/ 1862] train: loss: 0.0794369
[Epoch 19; Iter   444/ 1862] train: loss: 0.0018478
[Epoch 19; Iter   474/ 1862] train: loss: 0.0028307
[Epoch 19; Iter   504/ 1862] train: loss: 0.0019594
[Epoch 19; Iter   534/ 1862] train: loss: 0.0010695
[Epoch 19; Iter   564/ 1862] train: loss: 0.0018069
[Epoch 19; Iter   594/ 1862] train: loss: 0.0024876
[Epoch 19; Iter   624/ 1862] train: loss: 0.0016315
[Epoch 19; Iter   654/ 1862] train: loss: 0.0017456
[Epoch 19; Iter   684/ 1862] train: loss: 0.0136164
[Epoch 19; Iter   714/ 1862] train: loss: 0.0018340
[Epoch 19; Iter   744/ 1862] train: loss: 0.0018403
[Epoch 19; Iter   774/ 1862] train: loss: 0.0021448
[Epoch 19; Iter   804/ 1862] train: loss: 0.0024192
[Epoch 19; Iter   834/ 1862] train: loss: 0.0037445
[Epoch 19; Iter   864/ 1862] train: loss: 0.0016315
[Epoch 19; Iter   894/ 1862] train: loss: 0.0579534
[Epoch 19; Iter   924/ 1862] train: loss: 0.0012862
[Epoch 19; Iter   954/ 1862] train: loss: 0.0012623
[Epoch 19; Iter   984/ 1862] train: loss: 0.0553493
[Epoch 19; Iter  1014/ 1862] train: loss: 0.0287734
[Epoch 19; Iter  1044/ 1862] train: loss: 0.0039192
[Epoch 19; Iter  1074/ 1862] train: loss: 0.0019739
[Epoch 19; Iter  1104/ 1862] train: loss: 0.0020904
[Epoch 19; Iter  1134/ 1862] train: loss: 0.0016348
[Epoch 19; Iter  1164/ 1862] train: loss: 0.0017570
[Epoch 19; Iter  1194/ 1862] train: loss: 0.0017191
[Epoch 19; Iter  1224/ 1862] train: loss: 0.0015354
[Epoch 19; Iter  1254/ 1862] train: loss: 0.0016945
[Epoch 19; Iter  1284/ 1862] train: loss: 0.0025854
[Epoch 19; Iter  1314/ 1862] train: loss: 0.0012180
[Epoch 19; Iter  1344/ 1862] train: loss: 0.0173762
[Epoch 19; Iter  1374/ 1862] train: loss: 0.0018866
[Epoch 19; Iter  1404/ 1862] train: loss: 0.0019390
[Epoch 19; Iter  1434/ 1862] train: loss: 0.0012566
[Epoch 19; Iter  1464/ 1862] train: loss: 0.0687155
[Epoch 19; Iter  1494/ 1862] train: loss: 0.0726034
[Epoch 19; Iter  1524/ 1862] train: loss: 0.0019326
[Epoch 19; Iter  1554/ 1862] train: loss: 0.1054025
[Epoch 19; Iter  1584/ 1862] train: loss: 0.0264640
[Epoch 19; Iter  1614/ 1862] train: loss: 0.0955263
[Epoch 19; Iter  1644/ 1862] train: loss: 0.1036241
[Epoch 19; Iter  1674/ 1862] train: loss: 0.0017122
[Epoch 19; Iter  1704/ 1862] train: loss: 0.0014676
[Epoch 19; Iter  1734/ 1862] train: loss: 0.0011010
[Epoch 19; Iter  1764/ 1862] train: loss: 0.0019758
[Epoch 19; Iter  1794/ 1862] train: loss: 0.0434957
[Epoch 19; Iter  1824/ 1862] train: loss: 0.0021235
[Epoch 19; Iter  1854/ 1862] train: loss: 0.0017330
[Epoch 19] ogbg-molmuv: 0.032218 val loss: 0.014576
[Epoch 19] ogbg-molmuv: 0.079265 test loss: 0.015663
[Epoch 17; Iter   888/ 2172] train: loss: 0.0022868
[Epoch 17; Iter   918/ 2172] train: loss: 0.0016571
[Epoch 17; Iter   948/ 2172] train: loss: 0.0031129
[Epoch 17; Iter   978/ 2172] train: loss: 0.0996754
[Epoch 17; Iter  1008/ 2172] train: loss: 0.0023975
[Epoch 17; Iter  1038/ 2172] train: loss: 0.0017855
[Epoch 17; Iter  1068/ 2172] train: loss: 0.0012959
[Epoch 17; Iter  1098/ 2172] train: loss: 0.0014441
[Epoch 17; Iter  1128/ 2172] train: loss: 0.0017271
[Epoch 17; Iter  1158/ 2172] train: loss: 0.0019538
[Epoch 17; Iter  1188/ 2172] train: loss: 0.0016754
[Epoch 17; Iter  1218/ 2172] train: loss: 0.0015427
[Epoch 17; Iter  1248/ 2172] train: loss: 0.0024968
[Epoch 17; Iter  1278/ 2172] train: loss: 0.0019987
[Epoch 17; Iter  1308/ 2172] train: loss: 0.0020065
[Epoch 17; Iter  1338/ 2172] train: loss: 0.0023106
[Epoch 17; Iter  1368/ 2172] train: loss: 0.0010676
[Epoch 17; Iter  1398/ 2172] train: loss: 0.0867204
[Epoch 17; Iter  1428/ 2172] train: loss: 0.0155127
[Epoch 17; Iter  1458/ 2172] train: loss: 0.0108711
[Epoch 17; Iter  1488/ 2172] train: loss: 0.0010990
[Epoch 17; Iter  1518/ 2172] train: loss: 0.0013460
[Epoch 17; Iter  1548/ 2172] train: loss: 0.0014883
[Epoch 17; Iter  1578/ 2172] train: loss: 0.0011876
[Epoch 17; Iter  1608/ 2172] train: loss: 0.0919209
[Epoch 17; Iter  1638/ 2172] train: loss: 0.0018989
[Epoch 17; Iter  1668/ 2172] train: loss: 0.0025997
[Epoch 17; Iter  1698/ 2172] train: loss: 0.0022262
[Epoch 17; Iter  1728/ 2172] train: loss: 0.0015830
[Epoch 17; Iter  1758/ 2172] train: loss: 0.0017252
[Epoch 17; Iter  1788/ 2172] train: loss: 0.0323960
[Epoch 17; Iter  1818/ 2172] train: loss: 0.0448975
[Epoch 17; Iter  1848/ 2172] train: loss: 0.0013455
[Epoch 17; Iter  1878/ 2172] train: loss: 0.0011906
[Epoch 17; Iter  1908/ 2172] train: loss: 0.0017990
[Epoch 17; Iter  1938/ 2172] train: loss: 0.0221740
[Epoch 17; Iter  1968/ 2172] train: loss: 0.0019197
[Epoch 17; Iter  1998/ 2172] train: loss: 0.0022975
[Epoch 17; Iter  2028/ 2172] train: loss: 0.0894644
[Epoch 17; Iter  2058/ 2172] train: loss: 0.0016342
[Epoch 17; Iter  2088/ 2172] train: loss: 0.0034575
[Epoch 17; Iter  2118/ 2172] train: loss: 0.0014706
[Epoch 17; Iter  2148/ 2172] train: loss: 0.0011580
[Epoch 17] ogbg-molmuv: 0.071637 val loss: 0.011179
[Epoch 17] ogbg-molmuv: 0.121981 test loss: 0.012742
[Epoch 18; Iter     6/ 2172] train: loss: 0.0017160
[Epoch 18; Iter    36/ 2172] train: loss: 0.0013930
[Epoch 18; Iter    66/ 2172] train: loss: 0.0016303
[Epoch 18; Iter    96/ 2172] train: loss: 0.0626194
[Epoch 18; Iter   126/ 2172] train: loss: 0.0042224
[Epoch 18; Iter   156/ 2172] train: loss: 0.0015150
[Epoch 18; Iter   186/ 2172] train: loss: 0.0858259
[Epoch 18; Iter   216/ 2172] train: loss: 0.0046137
[Epoch 18; Iter   246/ 2172] train: loss: 0.0025121
[Epoch 18; Iter   276/ 2172] train: loss: 0.0008102
[Epoch 18; Iter   306/ 2172] train: loss: 0.0017331
[Epoch 18; Iter   336/ 2172] train: loss: 0.0013320
[Epoch 18; Iter   366/ 2172] train: loss: 0.0013919
[Epoch 18; Iter   396/ 2172] train: loss: 0.0032094
[Epoch 18; Iter   426/ 2172] train: loss: 0.0013535
[Epoch 18; Iter   456/ 2172] train: loss: 0.0049374
[Epoch 18; Iter   486/ 2172] train: loss: 0.0022331
[Epoch 18; Iter   516/ 2172] train: loss: 0.0021607
[Epoch 18; Iter   546/ 2172] train: loss: 0.0017297
[Epoch 18; Iter   576/ 2172] train: loss: 0.0898232
[Epoch 18; Iter   606/ 2172] train: loss: 0.1066820
[Epoch 18; Iter   636/ 2172] train: loss: 0.0014280
[Epoch 18; Iter   666/ 2172] train: loss: 0.0190351
[Epoch 18; Iter   696/ 2172] train: loss: 0.0043300
[Epoch 18; Iter   726/ 2172] train: loss: 0.0015993
[Epoch 18; Iter   756/ 2172] train: loss: 0.0018834
[Epoch 18; Iter   786/ 2172] train: loss: 0.0010382
[Epoch 18; Iter   816/ 2172] train: loss: 0.0017650
[Epoch 18; Iter   846/ 2172] train: loss: 0.0015196
[Epoch 18; Iter   876/ 2172] train: loss: 0.0011699
[Epoch 18; Iter   906/ 2172] train: loss: 0.0016244
[Epoch 18; Iter   936/ 2172] train: loss: 0.0012481
[Epoch 18; Iter   966/ 2172] train: loss: 0.0015416
[Epoch 18; Iter   996/ 2172] train: loss: 0.0015126
[Epoch 18; Iter  1026/ 2172] train: loss: 0.0009469
[Epoch 18; Iter  1056/ 2172] train: loss: 0.0015403
[Epoch 18; Iter  1086/ 2172] train: loss: 0.0021104
[Epoch 18; Iter  1116/ 2172] train: loss: 0.0015125
[Epoch 18; Iter  1146/ 2172] train: loss: 0.0019845
[Epoch 18; Iter  1176/ 2172] train: loss: 0.0015483
[Epoch 18; Iter  1206/ 2172] train: loss: 0.0013775
[Epoch 18; Iter  1236/ 2172] train: loss: 0.0013441
[Epoch 18; Iter  1266/ 2172] train: loss: 0.0019637
[Epoch 18; Iter  1296/ 2172] train: loss: 0.0035751
[Epoch 18; Iter  1326/ 2172] train: loss: 0.0778609
[Epoch 18; Iter  1356/ 2172] train: loss: 0.0017763
[Epoch 18; Iter  1386/ 2172] train: loss: 0.0019248
[Epoch 18; Iter  1416/ 2172] train: loss: 0.0853629
[Epoch 18; Iter  1446/ 2172] train: loss: 0.0013910
[Epoch 18; Iter  1476/ 2172] train: loss: 0.0029790
[Epoch 18; Iter  1506/ 2172] train: loss: 0.0013829
[Epoch 18; Iter  1536/ 2172] train: loss: 0.0018657
[Epoch 18; Iter  1566/ 2172] train: loss: 0.0019061
[Epoch 18; Iter  1596/ 2172] train: loss: 0.0014451
[Epoch 18; Iter  1626/ 2172] train: loss: 0.0019828
[Epoch 18; Iter  1656/ 2172] train: loss: 0.0016029
[Epoch 18; Iter  1686/ 2172] train: loss: 0.0020192
[Epoch 18; Iter  1716/ 2172] train: loss: 0.0014826
[Epoch 18; Iter  1746/ 2172] train: loss: 0.0023934
[Epoch 18; Iter  1776/ 2172] train: loss: 0.0027854
[Epoch 18; Iter  1806/ 2172] train: loss: 0.0020712
[Epoch 18; Iter  1836/ 2172] train: loss: 0.0012523
[Epoch 18; Iter  1866/ 2172] train: loss: 0.0018250
[Epoch 18; Iter  1896/ 2172] train: loss: 0.0022217
[Epoch 18; Iter  1926/ 2172] train: loss: 0.0016789
[Epoch 18; Iter  1956/ 2172] train: loss: 0.0287991
[Epoch 18; Iter  1986/ 2172] train: loss: 0.0013533
[Epoch 18; Iter  2016/ 2172] train: loss: 0.0019716
[Epoch 18; Iter  2046/ 2172] train: loss: 0.0023088
[Epoch 18; Iter  2076/ 2172] train: loss: 0.0706482
[Epoch 18; Iter  2106/ 2172] train: loss: 0.0009970
[Epoch 18; Iter  2136/ 2172] train: loss: 0.0015405
[Epoch 18; Iter  2166/ 2172] train: loss: 0.0690921
[Epoch 18] ogbg-molmuv: 0.059481 val loss: 0.012136
[Epoch 18] ogbg-molmuv: 0.051372 test loss: 0.013961
[Epoch 19; Iter    24/ 2172] train: loss: 0.0019320
[Epoch 19; Iter    54/ 2172] train: loss: 0.0014380
[Epoch 19; Iter    84/ 2172] train: loss: 0.0010964
[Epoch 19; Iter   114/ 2172] train: loss: 0.0027405
[Epoch 19; Iter   144/ 2172] train: loss: 0.0014888
[Epoch 19; Iter   174/ 2172] train: loss: 0.0018099
[Epoch 19; Iter   204/ 2172] train: loss: 0.0015724
[Epoch 19; Iter   234/ 2172] train: loss: 0.0027950
[Epoch 19; Iter   264/ 2172] train: loss: 0.0015111
[Epoch 19; Iter   294/ 2172] train: loss: 0.0014953
[Epoch 19; Iter   324/ 2172] train: loss: 0.0009031
[Epoch 19; Iter   354/ 2172] train: loss: 0.0024481
[Epoch 19; Iter   384/ 2172] train: loss: 0.0018951
[Epoch 19; Iter   414/ 2172] train: loss: 0.0032459
[Epoch 19; Iter   444/ 2172] train: loss: 0.0020221
[Epoch 19; Iter   474/ 2172] train: loss: 0.0020897
[Epoch 19; Iter   504/ 2172] train: loss: 0.0629755
[Epoch 19; Iter   534/ 2172] train: loss: 0.0019074
[Epoch 19; Iter   564/ 2172] train: loss: 0.0010633
[Epoch 19; Iter   594/ 2172] train: loss: 0.0008779
[Epoch 19; Iter   624/ 2172] train: loss: 0.0015220
[Epoch 19; Iter   654/ 2172] train: loss: 0.0014252
[Epoch 19; Iter   684/ 2172] train: loss: 0.0033049
[Epoch 19; Iter   714/ 2172] train: loss: 0.0021944
[Epoch 19; Iter   744/ 2172] train: loss: 0.0012787
[Epoch 19; Iter   774/ 2172] train: loss: 0.0045384
[Epoch 19; Iter   804/ 2172] train: loss: 0.0033504
[Epoch 19; Iter   834/ 2172] train: loss: 0.0027773
[Epoch 19; Iter   864/ 2172] train: loss: 0.0010291
[Epoch 19; Iter   894/ 2172] train: loss: 0.0019914
[Epoch 19; Iter   924/ 2172] train: loss: 0.0693038
[Epoch 19; Iter   954/ 2172] train: loss: 0.0762737
[Epoch 19; Iter   984/ 2172] train: loss: 0.0010189
[Epoch 19; Iter  1014/ 2172] train: loss: 0.0012162
[Epoch 19; Iter  1044/ 2172] train: loss: 0.0014079
[Epoch 19; Iter  1074/ 2172] train: loss: 0.0034920
[Epoch 19; Iter  1104/ 2172] train: loss: 0.0019159
[Epoch 17; Iter  1078/ 1862] train: loss: 0.0028618
[Epoch 17; Iter  1108/ 1862] train: loss: 0.0012337
[Epoch 17; Iter  1138/ 1862] train: loss: 0.0012104
[Epoch 17; Iter  1168/ 1862] train: loss: 0.0011977
[Epoch 17; Iter  1198/ 1862] train: loss: 0.0013610
[Epoch 17; Iter  1228/ 1862] train: loss: 0.0014474
[Epoch 17; Iter  1258/ 1862] train: loss: 0.0015736
[Epoch 17; Iter  1288/ 1862] train: loss: 0.0017734
[Epoch 17; Iter  1318/ 1862] train: loss: 0.0013578
[Epoch 17; Iter  1348/ 1862] train: loss: 0.0010275
[Epoch 17; Iter  1378/ 1862] train: loss: 0.0012661
[Epoch 17; Iter  1408/ 1862] train: loss: 0.0515545
[Epoch 17; Iter  1438/ 1862] train: loss: 0.0019098
[Epoch 17; Iter  1468/ 1862] train: loss: 0.0035795
[Epoch 17; Iter  1498/ 1862] train: loss: 0.0014339
[Epoch 17; Iter  1528/ 1862] train: loss: 0.0025749
[Epoch 17; Iter  1558/ 1862] train: loss: 0.0014253
[Epoch 17; Iter  1588/ 1862] train: loss: 0.0013081
[Epoch 17; Iter  1618/ 1862] train: loss: 0.0012041
[Epoch 17; Iter  1648/ 1862] train: loss: 0.0013203
[Epoch 17; Iter  1678/ 1862] train: loss: 0.1293646
[Epoch 17; Iter  1708/ 1862] train: loss: 0.0749051
[Epoch 17; Iter  1738/ 1862] train: loss: 0.0022008
[Epoch 17; Iter  1768/ 1862] train: loss: 0.0022071
[Epoch 17; Iter  1798/ 1862] train: loss: 0.0015634
[Epoch 17; Iter  1828/ 1862] train: loss: 0.0017491
[Epoch 17; Iter  1858/ 1862] train: loss: 0.0015882
[Epoch 17] ogbg-molmuv: 0.012326 val loss: 0.014794
[Epoch 17] ogbg-molmuv: 0.022438 test loss: 0.020593
[Epoch 18; Iter    26/ 1862] train: loss: 0.0022537
[Epoch 18; Iter    56/ 1862] train: loss: 0.0018530
[Epoch 18; Iter    86/ 1862] train: loss: 0.0440802
[Epoch 18; Iter   116/ 1862] train: loss: 0.0718838
[Epoch 18; Iter   146/ 1862] train: loss: 0.0015840
[Epoch 18; Iter   176/ 1862] train: loss: 0.0610686
[Epoch 18; Iter   206/ 1862] train: loss: 0.0043688
[Epoch 18; Iter   236/ 1862] train: loss: 0.0014091
[Epoch 18; Iter   266/ 1862] train: loss: 0.0010447
[Epoch 18; Iter   296/ 1862] train: loss: 0.0017091
[Epoch 18; Iter   326/ 1862] train: loss: 0.0054895
[Epoch 18; Iter   356/ 1862] train: loss: 0.0624368
[Epoch 18; Iter   386/ 1862] train: loss: 0.0698754
[Epoch 18; Iter   416/ 1862] train: loss: 0.0015505
[Epoch 18; Iter   446/ 1862] train: loss: 0.0018595
[Epoch 18; Iter   476/ 1862] train: loss: 0.0015510
[Epoch 18; Iter   506/ 1862] train: loss: 0.0020934
[Epoch 18; Iter   536/ 1862] train: loss: 0.0033979
[Epoch 18; Iter   566/ 1862] train: loss: 0.0015408
[Epoch 18; Iter   596/ 1862] train: loss: 0.0743914
[Epoch 18; Iter   626/ 1862] train: loss: 0.0018655
[Epoch 18; Iter   656/ 1862] train: loss: 0.0017183
[Epoch 18; Iter   686/ 1862] train: loss: 0.0537961
[Epoch 18; Iter   716/ 1862] train: loss: 0.0024440
[Epoch 18; Iter   746/ 1862] train: loss: 0.0023943
[Epoch 18; Iter   776/ 1862] train: loss: 0.0023567
[Epoch 18; Iter   806/ 1862] train: loss: 0.0015214
[Epoch 18; Iter   836/ 1862] train: loss: 0.0016658
[Epoch 18; Iter   866/ 1862] train: loss: 0.0015417
[Epoch 18; Iter   896/ 1862] train: loss: 0.0022432
[Epoch 18; Iter   926/ 1862] train: loss: 0.0014099
[Epoch 18; Iter   956/ 1862] train: loss: 0.0249559
[Epoch 18; Iter   986/ 1862] train: loss: 0.0020705
[Epoch 18; Iter  1016/ 1862] train: loss: 0.0018852
[Epoch 18; Iter  1046/ 1862] train: loss: 0.0018536
[Epoch 18; Iter  1076/ 1862] train: loss: 0.0030635
[Epoch 18; Iter  1106/ 1862] train: loss: 0.0012807
[Epoch 18; Iter  1136/ 1862] train: loss: 0.0686182
[Epoch 18; Iter  1166/ 1862] train: loss: 0.0012781
[Epoch 18; Iter  1196/ 1862] train: loss: 0.0024141
[Epoch 18; Iter  1226/ 1862] train: loss: 0.0013631
[Epoch 18; Iter  1256/ 1862] train: loss: 0.0016464
[Epoch 18; Iter  1286/ 1862] train: loss: 0.0014451
[Epoch 18; Iter  1316/ 1862] train: loss: 0.0012840
[Epoch 18; Iter  1346/ 1862] train: loss: 0.0018578
[Epoch 18; Iter  1376/ 1862] train: loss: 0.0020339
[Epoch 18; Iter  1406/ 1862] train: loss: 0.0435010
[Epoch 18; Iter  1436/ 1862] train: loss: 0.0016828
[Epoch 18; Iter  1466/ 1862] train: loss: 0.0013611
[Epoch 18; Iter  1496/ 1862] train: loss: 0.0009988
[Epoch 18; Iter  1526/ 1862] train: loss: 0.0014567
[Epoch 18; Iter  1556/ 1862] train: loss: 0.0011936
[Epoch 18; Iter  1586/ 1862] train: loss: 0.0019279
[Epoch 18; Iter  1616/ 1862] train: loss: 0.0021332
[Epoch 18; Iter  1646/ 1862] train: loss: 0.0859747
[Epoch 18; Iter  1676/ 1862] train: loss: 0.0905192
[Epoch 18; Iter  1706/ 1862] train: loss: 0.0016752
[Epoch 18; Iter  1736/ 1862] train: loss: 0.0024998
[Epoch 18; Iter  1766/ 1862] train: loss: 0.0089211
[Epoch 18; Iter  1796/ 1862] train: loss: 0.0019578
[Epoch 18; Iter  1826/ 1862] train: loss: 0.0046242
[Epoch 18; Iter  1856/ 1862] train: loss: 0.0018904
[Epoch 18] ogbg-molmuv: 0.016712 val loss: 0.013896
[Epoch 18] ogbg-molmuv: 0.049961 test loss: 0.012487
[Epoch 19; Iter    24/ 1862] train: loss: 0.0582822
[Epoch 19; Iter    54/ 1862] train: loss: 0.0011914
[Epoch 19; Iter    84/ 1862] train: loss: 0.0013049
[Epoch 19; Iter   114/ 1862] train: loss: 0.0975478
[Epoch 19; Iter   144/ 1862] train: loss: 0.0017275
[Epoch 19; Iter   174/ 1862] train: loss: 0.0014187
[Epoch 19; Iter   204/ 1862] train: loss: 0.0013564
[Epoch 19; Iter   234/ 1862] train: loss: 0.0010969
[Epoch 19; Iter   264/ 1862] train: loss: 0.0013983
[Epoch 19; Iter   294/ 1862] train: loss: 0.0259094
[Epoch 19; Iter   324/ 1862] train: loss: 0.1429175
[Epoch 19; Iter   354/ 1862] train: loss: 0.0025779
[Epoch 19; Iter   384/ 1862] train: loss: 0.0021168
[Epoch 19; Iter   414/ 1862] train: loss: 0.0011656
[Epoch 19; Iter   444/ 1862] train: loss: 0.0013343
[Epoch 19; Iter   474/ 1862] train: loss: 0.0011290
[Epoch 19; Iter   504/ 1862] train: loss: 0.0013061
[Epoch 19; Iter   534/ 1862] train: loss: 0.0015170
[Epoch 19; Iter   564/ 1862] train: loss: 0.0021538
[Epoch 19; Iter   594/ 1862] train: loss: 0.0014842
[Epoch 19; Iter   624/ 1862] train: loss: 0.0014774
[Epoch 19; Iter   654/ 1862] train: loss: 0.0012271
[Epoch 19; Iter   684/ 1862] train: loss: 0.0018572
[Epoch 19; Iter   714/ 1862] train: loss: 0.0771484
[Epoch 19; Iter   744/ 1862] train: loss: 0.0016131
[Epoch 19; Iter   774/ 1862] train: loss: 0.0018936
[Epoch 19; Iter   804/ 1862] train: loss: 0.0015080
[Epoch 19; Iter   834/ 1862] train: loss: 0.0011773
[Epoch 19; Iter   864/ 1862] train: loss: 0.0912424
[Epoch 19; Iter   894/ 1862] train: loss: 0.0025055
[Epoch 19; Iter   924/ 1862] train: loss: 0.0016938
[Epoch 19; Iter   954/ 1862] train: loss: 0.0019515
[Epoch 19; Iter   984/ 1862] train: loss: 0.0606402
[Epoch 19; Iter  1014/ 1862] train: loss: 0.0033580
[Epoch 19; Iter  1044/ 1862] train: loss: 0.0025983
[Epoch 19; Iter  1074/ 1862] train: loss: 0.0705758
[Epoch 19; Iter  1104/ 1862] train: loss: 0.0017027
[Epoch 19; Iter  1134/ 1862] train: loss: 0.0022045
[Epoch 19; Iter  1164/ 1862] train: loss: 0.0016039
[Epoch 19; Iter  1194/ 1862] train: loss: 0.0022668
[Epoch 19; Iter  1224/ 1862] train: loss: 0.0034125
[Epoch 19; Iter  1254/ 1862] train: loss: 0.0019802
[Epoch 19; Iter  1284/ 1862] train: loss: 0.0020998
[Epoch 19; Iter  1314/ 1862] train: loss: 0.0014880
[Epoch 19; Iter  1344/ 1862] train: loss: 0.0010406
[Epoch 19; Iter  1374/ 1862] train: loss: 0.0013251
[Epoch 19; Iter  1404/ 1862] train: loss: 0.0017623
[Epoch 19; Iter  1434/ 1862] train: loss: 0.0253113
[Epoch 19; Iter  1464/ 1862] train: loss: 0.0020347
[Epoch 19; Iter  1494/ 1862] train: loss: 0.0026330
[Epoch 19; Iter  1524/ 1862] train: loss: 0.0011676
[Epoch 19; Iter  1554/ 1862] train: loss: 0.0031552
[Epoch 19; Iter  1584/ 1862] train: loss: 0.0560271
[Epoch 19; Iter  1614/ 1862] train: loss: 0.0017276
[Epoch 19; Iter  1644/ 1862] train: loss: 0.0020574
[Epoch 19; Iter  1674/ 1862] train: loss: 0.0013493
[Epoch 19; Iter  1704/ 1862] train: loss: 0.0012574
[Epoch 19; Iter  1734/ 1862] train: loss: 0.0018854
[Epoch 19; Iter  1764/ 1862] train: loss: 0.0013673
[Epoch 19; Iter  1794/ 1862] train: loss: 0.0016856
[Epoch 19; Iter  1824/ 1862] train: loss: 0.0664671
[Epoch 19; Iter  1854/ 1862] train: loss: 0.0014091
[Epoch 19] ogbg-molmuv: 0.036533 val loss: 0.013844
[Epoch 19] ogbg-molmuv: 0.027769 test loss: 0.012428
[Epoch 17; Iter   888/ 2172] train: loss: 0.0022068
[Epoch 17; Iter   918/ 2172] train: loss: 0.0030871
[Epoch 17; Iter   948/ 2172] train: loss: 0.0017706
[Epoch 17; Iter   978/ 2172] train: loss: 0.0020442
[Epoch 17; Iter  1008/ 2172] train: loss: 0.0021814
[Epoch 17; Iter  1038/ 2172] train: loss: 0.0017289
[Epoch 17; Iter  1068/ 2172] train: loss: 0.0800813
[Epoch 17; Iter  1098/ 2172] train: loss: 0.0018493
[Epoch 17; Iter  1128/ 2172] train: loss: 0.0015976
[Epoch 17; Iter  1158/ 2172] train: loss: 0.0021917
[Epoch 17; Iter  1188/ 2172] train: loss: 0.0020532
[Epoch 17; Iter  1218/ 2172] train: loss: 0.0017775
[Epoch 17; Iter  1248/ 2172] train: loss: 0.0020252
[Epoch 17; Iter  1278/ 2172] train: loss: 0.0018555
[Epoch 17; Iter  1308/ 2172] train: loss: 0.0017437
[Epoch 17; Iter  1338/ 2172] train: loss: 0.0014058
[Epoch 17; Iter  1368/ 2172] train: loss: 0.0015486
[Epoch 17; Iter  1398/ 2172] train: loss: 0.0018049
[Epoch 17; Iter  1428/ 2172] train: loss: 0.0010654
[Epoch 17; Iter  1458/ 2172] train: loss: 0.0016462
[Epoch 17; Iter  1488/ 2172] train: loss: 0.0027529
[Epoch 17; Iter  1518/ 2172] train: loss: 0.0023583
[Epoch 17; Iter  1548/ 2172] train: loss: 0.0033646
[Epoch 17; Iter  1578/ 2172] train: loss: 0.0017284
[Epoch 17; Iter  1608/ 2172] train: loss: 0.0022117
[Epoch 17; Iter  1638/ 2172] train: loss: 0.1422585
[Epoch 17; Iter  1668/ 2172] train: loss: 0.0023673
[Epoch 17; Iter  1698/ 2172] train: loss: 0.0019872
[Epoch 17; Iter  1728/ 2172] train: loss: 0.0020821
[Epoch 17; Iter  1758/ 2172] train: loss: 0.0024454
[Epoch 17; Iter  1788/ 2172] train: loss: 0.0018264
[Epoch 17; Iter  1818/ 2172] train: loss: 0.0016253
[Epoch 17; Iter  1848/ 2172] train: loss: 0.0021316
[Epoch 17; Iter  1878/ 2172] train: loss: 0.0016031
[Epoch 17; Iter  1908/ 2172] train: loss: 0.0012261
[Epoch 17; Iter  1938/ 2172] train: loss: 0.0012361
[Epoch 17; Iter  1968/ 2172] train: loss: 0.0293508
[Epoch 17; Iter  1998/ 2172] train: loss: 0.0014999
[Epoch 17; Iter  2028/ 2172] train: loss: 0.0014401
[Epoch 17; Iter  2058/ 2172] train: loss: 0.0015233
[Epoch 17; Iter  2088/ 2172] train: loss: 0.0014688
[Epoch 17; Iter  2118/ 2172] train: loss: 0.0027940
[Epoch 17; Iter  2148/ 2172] train: loss: 0.0028320
[Epoch 17] ogbg-molmuv: 0.039393 val loss: 0.014599
[Epoch 17] ogbg-molmuv: 0.023439 test loss: 0.013888
[Epoch 18; Iter     6/ 2172] train: loss: 0.0018564
[Epoch 18; Iter    36/ 2172] train: loss: 0.0019231
[Epoch 18; Iter    66/ 2172] train: loss: 0.0024715
[Epoch 18; Iter    96/ 2172] train: loss: 0.0016665
[Epoch 18; Iter   126/ 2172] train: loss: 0.0021604
[Epoch 18; Iter   156/ 2172] train: loss: 0.0019310
[Epoch 18; Iter   186/ 2172] train: loss: 0.0014629
[Epoch 18; Iter   216/ 2172] train: loss: 0.0016737
[Epoch 18; Iter   246/ 2172] train: loss: 0.0649131
[Epoch 18; Iter   276/ 2172] train: loss: 0.0015046
[Epoch 18; Iter   306/ 2172] train: loss: 0.0023023
[Epoch 18; Iter   336/ 2172] train: loss: 0.0013597
[Epoch 18; Iter   366/ 2172] train: loss: 0.0014310
[Epoch 18; Iter   396/ 2172] train: loss: 0.0015832
[Epoch 18; Iter   426/ 2172] train: loss: 0.0013427
[Epoch 18; Iter   456/ 2172] train: loss: 0.0014327
[Epoch 18; Iter   486/ 2172] train: loss: 0.0014429
[Epoch 18; Iter   516/ 2172] train: loss: 0.0013380
[Epoch 18; Iter   546/ 2172] train: loss: 0.0021028
[Epoch 18; Iter   576/ 2172] train: loss: 0.0055473
[Epoch 18; Iter   606/ 2172] train: loss: 0.0023522
[Epoch 18; Iter   636/ 2172] train: loss: 0.0021372
[Epoch 18; Iter   666/ 2172] train: loss: 0.0023911
[Epoch 18; Iter   696/ 2172] train: loss: 0.0013270
[Epoch 18; Iter   726/ 2172] train: loss: 0.0016586
[Epoch 18; Iter   756/ 2172] train: loss: 0.0697665
[Epoch 18; Iter   786/ 2172] train: loss: 0.0028405
[Epoch 18; Iter   816/ 2172] train: loss: 0.0015111
[Epoch 18; Iter   846/ 2172] train: loss: 0.0025062
[Epoch 18; Iter   876/ 2172] train: loss: 0.0030976
[Epoch 18; Iter   906/ 2172] train: loss: 0.0027097
[Epoch 18; Iter   936/ 2172] train: loss: 0.0013341
[Epoch 18; Iter   966/ 2172] train: loss: 0.0732460
[Epoch 18; Iter   996/ 2172] train: loss: 0.0013260
[Epoch 18; Iter  1026/ 2172] train: loss: 0.0022484
[Epoch 18; Iter  1056/ 2172] train: loss: 0.0017035
[Epoch 18; Iter  1086/ 2172] train: loss: 0.0013834
[Epoch 18; Iter  1116/ 2172] train: loss: 0.0024205
[Epoch 18; Iter  1146/ 2172] train: loss: 0.0018195
[Epoch 18; Iter  1176/ 2172] train: loss: 0.0021440
[Epoch 18; Iter  1206/ 2172] train: loss: 0.0016709
[Epoch 18; Iter  1236/ 2172] train: loss: 0.0017800
[Epoch 18; Iter  1266/ 2172] train: loss: 0.0020074
[Epoch 18; Iter  1296/ 2172] train: loss: 0.0707222
[Epoch 18; Iter  1326/ 2172] train: loss: 0.0023110
[Epoch 18; Iter  1356/ 2172] train: loss: 0.0021751
[Epoch 18; Iter  1386/ 2172] train: loss: 0.0025908
[Epoch 18; Iter  1416/ 2172] train: loss: 0.0026949
[Epoch 18; Iter  1446/ 2172] train: loss: 0.0030546
[Epoch 18; Iter  1476/ 2172] train: loss: 0.0017394
[Epoch 18; Iter  1506/ 2172] train: loss: 0.0025073
[Epoch 18; Iter  1536/ 2172] train: loss: 0.0016966
[Epoch 18; Iter  1566/ 2172] train: loss: 0.0015405
[Epoch 18; Iter  1596/ 2172] train: loss: 0.0837936
[Epoch 18; Iter  1626/ 2172] train: loss: 0.0019305
[Epoch 18; Iter  1656/ 2172] train: loss: 0.0021707
[Epoch 18; Iter  1686/ 2172] train: loss: 0.0019567
[Epoch 18; Iter  1716/ 2172] train: loss: 0.0025637
[Epoch 18; Iter  1746/ 2172] train: loss: 0.0022016
[Epoch 18; Iter  1776/ 2172] train: loss: 0.0017881
[Epoch 18; Iter  1806/ 2172] train: loss: 0.0016034
[Epoch 18; Iter  1836/ 2172] train: loss: 0.0019003
[Epoch 18; Iter  1866/ 2172] train: loss: 0.0019120
[Epoch 18; Iter  1896/ 2172] train: loss: 0.0014945
[Epoch 18; Iter  1926/ 2172] train: loss: 0.0018783
[Epoch 18; Iter  1956/ 2172] train: loss: 0.0568920
[Epoch 18; Iter  1986/ 2172] train: loss: 0.0021881
[Epoch 18; Iter  2016/ 2172] train: loss: 0.0015594
[Epoch 18; Iter  2046/ 2172] train: loss: 0.0021213
[Epoch 18; Iter  2076/ 2172] train: loss: 0.0674492
[Epoch 18; Iter  2106/ 2172] train: loss: 0.0024578
[Epoch 18; Iter  2136/ 2172] train: loss: 0.0016852
[Epoch 18; Iter  2166/ 2172] train: loss: 0.0023354
[Epoch 18] ogbg-molmuv: 0.026198 val loss: 0.053842
[Epoch 18] ogbg-molmuv: 0.039620 test loss: 0.037118
[Epoch 19; Iter    24/ 2172] train: loss: 0.0011272
[Epoch 19; Iter    54/ 2172] train: loss: 0.0540150
[Epoch 19; Iter    84/ 2172] train: loss: 0.0016381
[Epoch 19; Iter   114/ 2172] train: loss: 0.0016746
[Epoch 19; Iter   144/ 2172] train: loss: 0.0016052
[Epoch 19; Iter   174/ 2172] train: loss: 0.0021822
[Epoch 19; Iter   204/ 2172] train: loss: 0.0019955
[Epoch 19; Iter   234/ 2172] train: loss: 0.0645346
[Epoch 19; Iter   264/ 2172] train: loss: 0.0946408
[Epoch 19; Iter   294/ 2172] train: loss: 0.0015727
[Epoch 19; Iter   324/ 2172] train: loss: 0.0014183
[Epoch 19; Iter   354/ 2172] train: loss: 0.0026660
[Epoch 19; Iter   384/ 2172] train: loss: 0.0037345
[Epoch 19; Iter   414/ 2172] train: loss: 0.0016151
[Epoch 19; Iter   444/ 2172] train: loss: 0.0521011
[Epoch 19; Iter   474/ 2172] train: loss: 0.0692365
[Epoch 19; Iter   504/ 2172] train: loss: 0.0017404
[Epoch 19; Iter   534/ 2172] train: loss: 0.1622041
[Epoch 19; Iter   564/ 2172] train: loss: 0.0018257
[Epoch 19; Iter   594/ 2172] train: loss: 0.0919437
[Epoch 19; Iter   624/ 2172] train: loss: 0.0027862
[Epoch 19; Iter   654/ 2172] train: loss: 0.1192758
[Epoch 19; Iter   684/ 2172] train: loss: 0.0020172
[Epoch 19; Iter   714/ 2172] train: loss: 0.0023770
[Epoch 19; Iter   744/ 2172] train: loss: 0.0029615
[Epoch 19; Iter   774/ 2172] train: loss: 0.0801688
[Epoch 19; Iter   804/ 2172] train: loss: 0.0018969
[Epoch 19; Iter   834/ 2172] train: loss: 0.0016348
[Epoch 19; Iter   864/ 2172] train: loss: 0.0983468
[Epoch 19; Iter   894/ 2172] train: loss: 0.0014124
[Epoch 19; Iter   924/ 2172] train: loss: 0.0010082
[Epoch 19; Iter   954/ 2172] train: loss: 0.0015890
[Epoch 19; Iter   984/ 2172] train: loss: 0.0012313
[Epoch 19; Iter  1014/ 2172] train: loss: 0.0012701
[Epoch 19; Iter  1044/ 2172] train: loss: 0.0018477
[Epoch 19; Iter  1074/ 2172] train: loss: 0.0013343
[Epoch 19; Iter  1104/ 2172] train: loss: 0.0822602
[Epoch 17; Iter   888/ 2172] train: loss: 0.0018527
[Epoch 17; Iter   918/ 2172] train: loss: 0.0017336
[Epoch 17; Iter   948/ 2172] train: loss: 0.0012578
[Epoch 17; Iter   978/ 2172] train: loss: 0.0011914
[Epoch 17; Iter  1008/ 2172] train: loss: 0.0019226
[Epoch 17; Iter  1038/ 2172] train: loss: 0.0057106
[Epoch 17; Iter  1068/ 2172] train: loss: 0.0523083
[Epoch 17; Iter  1098/ 2172] train: loss: 0.0016838
[Epoch 17; Iter  1128/ 2172] train: loss: 0.0014013
[Epoch 17; Iter  1158/ 2172] train: loss: 0.0014647
[Epoch 17; Iter  1188/ 2172] train: loss: 0.0019597
[Epoch 17; Iter  1218/ 2172] train: loss: 0.0050593
[Epoch 17; Iter  1248/ 2172] train: loss: 0.0021586
[Epoch 17; Iter  1278/ 2172] train: loss: 0.0050390
[Epoch 17; Iter  1308/ 2172] train: loss: 0.0882227
[Epoch 17; Iter  1338/ 2172] train: loss: 0.0983551
[Epoch 17; Iter  1368/ 2172] train: loss: 0.0046492
[Epoch 17; Iter  1398/ 2172] train: loss: 0.0028975
[Epoch 17; Iter  1428/ 2172] train: loss: 0.0017125
[Epoch 17; Iter  1458/ 2172] train: loss: 0.0022633
[Epoch 17; Iter  1488/ 2172] train: loss: 0.1213713
[Epoch 17; Iter  1518/ 2172] train: loss: 0.0021339
[Epoch 17; Iter  1548/ 2172] train: loss: 0.0022016
[Epoch 17; Iter  1578/ 2172] train: loss: 0.0012286
[Epoch 17; Iter  1608/ 2172] train: loss: 0.0014490
[Epoch 17; Iter  1638/ 2172] train: loss: 0.0010877
[Epoch 17; Iter  1668/ 2172] train: loss: 0.0024177
[Epoch 17; Iter  1698/ 2172] train: loss: 0.0023586
[Epoch 17; Iter  1728/ 2172] train: loss: 0.0018706
[Epoch 17; Iter  1758/ 2172] train: loss: 0.0012811
[Epoch 17; Iter  1788/ 2172] train: loss: 0.0010426
[Epoch 17; Iter  1818/ 2172] train: loss: 0.0017618
[Epoch 17; Iter  1848/ 2172] train: loss: 0.0009926
[Epoch 17; Iter  1878/ 2172] train: loss: 0.1034591
[Epoch 17; Iter  1908/ 2172] train: loss: 0.2063087
[Epoch 17; Iter  1938/ 2172] train: loss: 0.0012649
[Epoch 17; Iter  1968/ 2172] train: loss: 0.0034076
[Epoch 17; Iter  1998/ 2172] train: loss: 0.0019687
[Epoch 17; Iter  2028/ 2172] train: loss: 0.0031033
[Epoch 17; Iter  2058/ 2172] train: loss: 0.0020177
[Epoch 17; Iter  2088/ 2172] train: loss: 0.0017454
[Epoch 17; Iter  2118/ 2172] train: loss: 0.0028538
[Epoch 17; Iter  2148/ 2172] train: loss: 0.0018128
[Epoch 17] ogbg-molmuv: 0.032826 val loss: 0.011974
[Epoch 17] ogbg-molmuv: 0.102956 test loss: 0.012410
[Epoch 18; Iter     6/ 2172] train: loss: 0.0629440
[Epoch 18; Iter    36/ 2172] train: loss: 0.0500758
[Epoch 18; Iter    66/ 2172] train: loss: 0.0346609
[Epoch 18; Iter    96/ 2172] train: loss: 0.0073515
[Epoch 18; Iter   126/ 2172] train: loss: 0.0015287
[Epoch 18; Iter   156/ 2172] train: loss: 0.0042211
[Epoch 18; Iter   186/ 2172] train: loss: 0.0017685
[Epoch 18; Iter   216/ 2172] train: loss: 0.0015565
[Epoch 18; Iter   246/ 2172] train: loss: 0.0014309
[Epoch 18; Iter   276/ 2172] train: loss: 0.0017062
[Epoch 18; Iter   306/ 2172] train: loss: 0.0015509
[Epoch 18; Iter   336/ 2172] train: loss: 0.0015888
[Epoch 18; Iter   366/ 2172] train: loss: 0.0016334
[Epoch 18; Iter   396/ 2172] train: loss: 0.0011748
[Epoch 18; Iter   426/ 2172] train: loss: 0.0015772
[Epoch 18; Iter   456/ 2172] train: loss: 0.0010197
[Epoch 18; Iter   486/ 2172] train: loss: 0.0863561
[Epoch 18; Iter   516/ 2172] train: loss: 0.0011081
[Epoch 18; Iter   546/ 2172] train: loss: 0.0012735
[Epoch 18; Iter   576/ 2172] train: loss: 0.0018137
[Epoch 18; Iter   606/ 2172] train: loss: 0.0019483
[Epoch 18; Iter   636/ 2172] train: loss: 0.0012370
[Epoch 18; Iter   666/ 2172] train: loss: 0.0043479
[Epoch 18; Iter   696/ 2172] train: loss: 0.0009942
[Epoch 18; Iter   726/ 2172] train: loss: 0.0008777
[Epoch 18; Iter   756/ 2172] train: loss: 0.0011615
[Epoch 18; Iter   786/ 2172] train: loss: 0.0022803
[Epoch 18; Iter   816/ 2172] train: loss: 0.0011094
[Epoch 18; Iter   846/ 2172] train: loss: 0.0011865
[Epoch 18; Iter   876/ 2172] train: loss: 0.0019117
[Epoch 18; Iter   906/ 2172] train: loss: 0.0016519
[Epoch 18; Iter   936/ 2172] train: loss: 0.0014742
[Epoch 18; Iter   966/ 2172] train: loss: 0.0014311
[Epoch 18; Iter   996/ 2172] train: loss: 0.0018022
[Epoch 18; Iter  1026/ 2172] train: loss: 0.0509766
[Epoch 18; Iter  1056/ 2172] train: loss: 0.0036181
[Epoch 18; Iter  1086/ 2172] train: loss: 0.0611126
[Epoch 18; Iter  1116/ 2172] train: loss: 0.0025169
[Epoch 18; Iter  1146/ 2172] train: loss: 0.0025873
[Epoch 18; Iter  1176/ 2172] train: loss: 0.0016472
[Epoch 18; Iter  1206/ 2172] train: loss: 0.0012082
[Epoch 18; Iter  1236/ 2172] train: loss: 0.0013478
[Epoch 18; Iter  1266/ 2172] train: loss: 0.0016981
[Epoch 18; Iter  1296/ 2172] train: loss: 0.0016516
[Epoch 18; Iter  1326/ 2172] train: loss: 0.1935565
[Epoch 18; Iter  1356/ 2172] train: loss: 0.0018740
[Epoch 18; Iter  1386/ 2172] train: loss: 0.0012354
[Epoch 18; Iter  1416/ 2172] train: loss: 0.0017374
[Epoch 18; Iter  1446/ 2172] train: loss: 0.0015573
[Epoch 18; Iter  1476/ 2172] train: loss: 0.0015967
[Epoch 18; Iter  1506/ 2172] train: loss: 0.0014926
[Epoch 18; Iter  1536/ 2172] train: loss: 0.0022931
[Epoch 18; Iter  1566/ 2172] train: loss: 0.0017050
[Epoch 18; Iter  1596/ 2172] train: loss: 0.0026920
[Epoch 18; Iter  1626/ 2172] train: loss: 0.0017792
[Epoch 18; Iter  1656/ 2172] train: loss: 0.0016260
[Epoch 18; Iter  1686/ 2172] train: loss: 0.0030601
[Epoch 18; Iter  1716/ 2172] train: loss: 0.0021604
[Epoch 18; Iter  1746/ 2172] train: loss: 0.0016768
[Epoch 18; Iter  1776/ 2172] train: loss: 0.0012926
[Epoch 18; Iter  1806/ 2172] train: loss: 0.0018241
[Epoch 18; Iter  1836/ 2172] train: loss: 0.1639033
[Epoch 18; Iter  1866/ 2172] train: loss: 0.0014964
[Epoch 18; Iter  1896/ 2172] train: loss: 0.0029331
[Epoch 18; Iter  1926/ 2172] train: loss: 0.0021993
[Epoch 18; Iter  1956/ 2172] train: loss: 0.0018176
[Epoch 18; Iter  1986/ 2172] train: loss: 0.0027118
[Epoch 18; Iter  2016/ 2172] train: loss: 0.0765708
[Epoch 18; Iter  2046/ 2172] train: loss: 0.0023966
[Epoch 18; Iter  2076/ 2172] train: loss: 0.0015193
[Epoch 18; Iter  2106/ 2172] train: loss: 0.0035011
[Epoch 18; Iter  2136/ 2172] train: loss: 0.0016095
[Epoch 18; Iter  2166/ 2172] train: loss: 0.0020519
[Epoch 18] ogbg-molmuv: 0.047944 val loss: 0.013431
[Epoch 18] ogbg-molmuv: 0.120469 test loss: 0.013210
[Epoch 19; Iter    24/ 2172] train: loss: 0.0022530
[Epoch 19; Iter    54/ 2172] train: loss: 0.0021927
[Epoch 19; Iter    84/ 2172] train: loss: 0.0023139
[Epoch 19; Iter   114/ 2172] train: loss: 0.0020668
[Epoch 19; Iter   144/ 2172] train: loss: 0.0010744
[Epoch 19; Iter   174/ 2172] train: loss: 0.0749704
[Epoch 19; Iter   204/ 2172] train: loss: 0.0583590
[Epoch 19; Iter   234/ 2172] train: loss: 0.0049123
[Epoch 19; Iter   264/ 2172] train: loss: 0.0015157
[Epoch 19; Iter   294/ 2172] train: loss: 0.0020583
[Epoch 19; Iter   324/ 2172] train: loss: 0.0017517
[Epoch 19; Iter   354/ 2172] train: loss: 0.0046378
[Epoch 19; Iter   384/ 2172] train: loss: 0.0961943
[Epoch 19; Iter   414/ 2172] train: loss: 0.0014537
[Epoch 19; Iter   444/ 2172] train: loss: 0.0019219
[Epoch 19; Iter   474/ 2172] train: loss: 0.0579483
[Epoch 19; Iter   504/ 2172] train: loss: 0.0012494
[Epoch 19; Iter   534/ 2172] train: loss: 0.0014420
[Epoch 19; Iter   564/ 2172] train: loss: 0.0012571
[Epoch 19; Iter   594/ 2172] train: loss: 0.0018987
[Epoch 19; Iter   624/ 2172] train: loss: 0.0013604
[Epoch 19; Iter   654/ 2172] train: loss: 0.0010844
[Epoch 19; Iter   684/ 2172] train: loss: 0.0020861
[Epoch 19; Iter   714/ 2172] train: loss: 0.0013808
[Epoch 19; Iter   744/ 2172] train: loss: 0.0013445
[Epoch 19; Iter   774/ 2172] train: loss: 0.0824733
[Epoch 19; Iter   804/ 2172] train: loss: 0.0015013
[Epoch 19; Iter   834/ 2172] train: loss: 0.0016136
[Epoch 19; Iter   864/ 2172] train: loss: 0.0013502
[Epoch 19; Iter   894/ 2172] train: loss: 0.0009116
[Epoch 19; Iter   924/ 2172] train: loss: 0.0794481
[Epoch 19; Iter   954/ 2172] train: loss: 0.0014676
[Epoch 19; Iter   984/ 2172] train: loss: 0.0025172
[Epoch 19; Iter  1014/ 2172] train: loss: 0.0010276
[Epoch 19; Iter  1044/ 2172] train: loss: 0.0011209
[Epoch 19; Iter  1074/ 2172] train: loss: 0.0040543
[Epoch 19; Iter  1104/ 2172] train: loss: 0.0013248
[Epoch 17; Iter  1078/ 1862] train: loss: 0.0012870
[Epoch 17; Iter  1108/ 1862] train: loss: 0.0013206
[Epoch 17; Iter  1138/ 1862] train: loss: 0.0015389
[Epoch 17; Iter  1168/ 1862] train: loss: 0.0028469
[Epoch 17; Iter  1198/ 1862] train: loss: 0.0017371
[Epoch 17; Iter  1228/ 1862] train: loss: 0.0891628
[Epoch 17; Iter  1258/ 1862] train: loss: 0.0036274
[Epoch 17; Iter  1288/ 1862] train: loss: 0.0017631
[Epoch 17; Iter  1318/ 1862] train: loss: 0.0056759
[Epoch 17; Iter  1348/ 1862] train: loss: 0.0015103
[Epoch 17; Iter  1378/ 1862] train: loss: 0.0012031
[Epoch 17; Iter  1408/ 1862] train: loss: 0.0016905
[Epoch 17; Iter  1438/ 1862] train: loss: 0.0021301
[Epoch 17; Iter  1468/ 1862] train: loss: 0.0016201
[Epoch 17; Iter  1498/ 1862] train: loss: 0.0019130
[Epoch 17; Iter  1528/ 1862] train: loss: 0.0785563
[Epoch 17; Iter  1558/ 1862] train: loss: 0.0022073
[Epoch 17; Iter  1588/ 1862] train: loss: 0.0014702
[Epoch 17; Iter  1618/ 1862] train: loss: 0.0021712
[Epoch 17; Iter  1648/ 1862] train: loss: 0.0011830
[Epoch 17; Iter  1678/ 1862] train: loss: 0.0021540
[Epoch 17; Iter  1708/ 1862] train: loss: 0.0019128
[Epoch 17; Iter  1738/ 1862] train: loss: 0.0018348
[Epoch 17; Iter  1768/ 1862] train: loss: 0.0025059
[Epoch 17; Iter  1798/ 1862] train: loss: 0.0020848
[Epoch 17; Iter  1828/ 1862] train: loss: 0.0017123
[Epoch 17; Iter  1858/ 1862] train: loss: 0.0635641
[Epoch 17] ogbg-molmuv: 0.013478 val loss: 0.013250
[Epoch 17] ogbg-molmuv: 0.016772 test loss: 0.012159
[Epoch 18; Iter    26/ 1862] train: loss: 0.0019798
[Epoch 18; Iter    56/ 1862] train: loss: 0.0017010
[Epoch 18; Iter    86/ 1862] train: loss: 0.0016655
[Epoch 18; Iter   116/ 1862] train: loss: 0.0014281
[Epoch 18; Iter   146/ 1862] train: loss: 0.0015248
[Epoch 18; Iter   176/ 1862] train: loss: 0.0018680
[Epoch 18; Iter   206/ 1862] train: loss: 0.0016703
[Epoch 18; Iter   236/ 1862] train: loss: 0.0938195
[Epoch 18; Iter   266/ 1862] train: loss: 0.0018199
[Epoch 18; Iter   296/ 1862] train: loss: 0.0023480
[Epoch 18; Iter   326/ 1862] train: loss: 0.0737656
[Epoch 18; Iter   356/ 1862] train: loss: 0.0018041
[Epoch 18; Iter   386/ 1862] train: loss: 0.0020855
[Epoch 18; Iter   416/ 1862] train: loss: 0.0021803
[Epoch 18; Iter   446/ 1862] train: loss: 0.0017499
[Epoch 18; Iter   476/ 1862] train: loss: 0.0040896
[Epoch 18; Iter   506/ 1862] train: loss: 0.0059544
[Epoch 18; Iter   536/ 1862] train: loss: 0.0019293
[Epoch 18; Iter   566/ 1862] train: loss: 0.0023169
[Epoch 18; Iter   596/ 1862] train: loss: 0.0021276
[Epoch 18; Iter   626/ 1862] train: loss: 0.0021560
[Epoch 18; Iter   656/ 1862] train: loss: 0.0015546
[Epoch 18; Iter   686/ 1862] train: loss: 0.0008852
[Epoch 18; Iter   716/ 1862] train: loss: 0.0017378
[Epoch 18; Iter   746/ 1862] train: loss: 0.0014239
[Epoch 18; Iter   776/ 1862] train: loss: 0.0013026
[Epoch 18; Iter   806/ 1862] train: loss: 0.0018407
[Epoch 18; Iter   836/ 1862] train: loss: 0.0034784
[Epoch 18; Iter   866/ 1862] train: loss: 0.0016396
[Epoch 18; Iter   896/ 1862] train: loss: 0.0030124
[Epoch 18; Iter   926/ 1862] train: loss: 0.0048232
[Epoch 18; Iter   956/ 1862] train: loss: 0.0031479
[Epoch 18; Iter   986/ 1862] train: loss: 0.0026631
[Epoch 18; Iter  1016/ 1862] train: loss: 0.0026522
[Epoch 18; Iter  1046/ 1862] train: loss: 0.0024343
[Epoch 18; Iter  1076/ 1862] train: loss: 0.0014551
[Epoch 18; Iter  1106/ 1862] train: loss: 0.0548163
[Epoch 18; Iter  1136/ 1862] train: loss: 0.0020379
[Epoch 18; Iter  1166/ 1862] train: loss: 0.0009622
[Epoch 18; Iter  1196/ 1862] train: loss: 0.0012903
[Epoch 18; Iter  1226/ 1862] train: loss: 0.0017594
[Epoch 18; Iter  1256/ 1862] train: loss: 0.0009346
[Epoch 18; Iter  1286/ 1862] train: loss: 0.0019897
[Epoch 18; Iter  1316/ 1862] train: loss: 0.0017580
[Epoch 18; Iter  1346/ 1862] train: loss: 0.0027277
[Epoch 18; Iter  1376/ 1862] train: loss: 0.0015771
[Epoch 18; Iter  1406/ 1862] train: loss: 0.0010500
[Epoch 18; Iter  1436/ 1862] train: loss: 0.0501961
[Epoch 18; Iter  1466/ 1862] train: loss: 0.0023987
[Epoch 18; Iter  1496/ 1862] train: loss: 0.0018413
[Epoch 18; Iter  1526/ 1862] train: loss: 0.0020118
[Epoch 18; Iter  1556/ 1862] train: loss: 0.0019200
[Epoch 18; Iter  1586/ 1862] train: loss: 0.0012812
[Epoch 18; Iter  1616/ 1862] train: loss: 0.0019139
[Epoch 18; Iter  1646/ 1862] train: loss: 0.0014386
[Epoch 18; Iter  1676/ 1862] train: loss: 0.0735075
[Epoch 18; Iter  1706/ 1862] train: loss: 0.0015221
[Epoch 18; Iter  1736/ 1862] train: loss: 0.0868281
[Epoch 18; Iter  1766/ 1862] train: loss: 0.0021561
[Epoch 18; Iter  1796/ 1862] train: loss: 0.0030384
[Epoch 18; Iter  1826/ 1862] train: loss: 0.0014153
[Epoch 18; Iter  1856/ 1862] train: loss: 0.0016439
[Epoch 18] ogbg-molmuv: 0.038796 val loss: 0.012558
[Epoch 18] ogbg-molmuv: 0.044591 test loss: 0.011767
[Epoch 19; Iter    24/ 1862] train: loss: 0.0539004
[Epoch 19; Iter    54/ 1862] train: loss: 0.0020463
[Epoch 19; Iter    84/ 1862] train: loss: 0.0012424
[Epoch 19; Iter   114/ 1862] train: loss: 0.0023674
[Epoch 19; Iter   144/ 1862] train: loss: 0.0010817
[Epoch 19; Iter   174/ 1862] train: loss: 0.0017143
[Epoch 19; Iter   204/ 1862] train: loss: 0.0026995
[Epoch 19; Iter   234/ 1862] train: loss: 0.0823561
[Epoch 19; Iter   264/ 1862] train: loss: 0.0019396
[Epoch 19; Iter   294/ 1862] train: loss: 0.0033953
[Epoch 19; Iter   324/ 1862] train: loss: 0.0020698
[Epoch 19; Iter   354/ 1862] train: loss: 0.0463223
[Epoch 19; Iter   384/ 1862] train: loss: 0.0020805
[Epoch 19; Iter   414/ 1862] train: loss: 0.0025564
[Epoch 19; Iter   444/ 1862] train: loss: 0.0548341
[Epoch 19; Iter   474/ 1862] train: loss: 0.0025084
[Epoch 19; Iter   504/ 1862] train: loss: 0.0020554
[Epoch 19; Iter   534/ 1862] train: loss: 0.0719660
[Epoch 19; Iter   564/ 1862] train: loss: 0.1089934
[Epoch 19; Iter   594/ 1862] train: loss: 0.0026299
[Epoch 19; Iter   624/ 1862] train: loss: 0.0025313
[Epoch 19; Iter   654/ 1862] train: loss: 0.0017682
[Epoch 19; Iter   684/ 1862] train: loss: 0.0024086
[Epoch 19; Iter   714/ 1862] train: loss: 0.0690319
[Epoch 19; Iter   744/ 1862] train: loss: 0.0026035
[Epoch 19; Iter   774/ 1862] train: loss: 0.0039619
[Epoch 19; Iter   804/ 1862] train: loss: 0.0032492
[Epoch 19; Iter   834/ 1862] train: loss: 0.0021618
[Epoch 19; Iter   864/ 1862] train: loss: 0.0016347
[Epoch 19; Iter   894/ 1862] train: loss: 0.0011010
[Epoch 19; Iter   924/ 1862] train: loss: 0.0013527
[Epoch 19; Iter   954/ 1862] train: loss: 0.0015340
[Epoch 19; Iter   984/ 1862] train: loss: 0.0014566
[Epoch 19; Iter  1014/ 1862] train: loss: 0.0017089
[Epoch 19; Iter  1044/ 1862] train: loss: 0.0011714
[Epoch 19; Iter  1074/ 1862] train: loss: 0.0011670
[Epoch 19; Iter  1104/ 1862] train: loss: 0.0017061
[Epoch 19; Iter  1134/ 1862] train: loss: 0.0016273
[Epoch 19; Iter  1164/ 1862] train: loss: 0.0021066
[Epoch 19; Iter  1194/ 1862] train: loss: 0.0021573
[Epoch 19; Iter  1224/ 1862] train: loss: 0.0023721
[Epoch 19; Iter  1254/ 1862] train: loss: 0.0012064
[Epoch 19; Iter  1284/ 1862] train: loss: 0.0011785
[Epoch 19; Iter  1314/ 1862] train: loss: 0.0019827
[Epoch 19; Iter  1344/ 1862] train: loss: 0.0009528
[Epoch 19; Iter  1374/ 1862] train: loss: 0.0012773
[Epoch 19; Iter  1404/ 1862] train: loss: 0.0666545
[Epoch 19; Iter  1434/ 1862] train: loss: 0.0015777
[Epoch 19; Iter  1464/ 1862] train: loss: 0.0616830
[Epoch 19; Iter  1494/ 1862] train: loss: 0.0027467
[Epoch 19; Iter  1524/ 1862] train: loss: 0.0027680
[Epoch 19; Iter  1554/ 1862] train: loss: 0.0033278
[Epoch 19; Iter  1584/ 1862] train: loss: 0.0017225
[Epoch 19; Iter  1614/ 1862] train: loss: 0.0012515
[Epoch 19; Iter  1644/ 1862] train: loss: 0.0017795
[Epoch 19; Iter  1674/ 1862] train: loss: 0.0008854
[Epoch 19; Iter  1704/ 1862] train: loss: 0.0011506
[Epoch 19; Iter  1734/ 1862] train: loss: 0.0044615
[Epoch 19; Iter  1764/ 1862] train: loss: 0.0016240
[Epoch 19; Iter  1794/ 1862] train: loss: 0.0017814
[Epoch 19; Iter  1824/ 1862] train: loss: 0.0018882
[Epoch 19; Iter  1854/ 1862] train: loss: 0.0018705
[Epoch 19] ogbg-molmuv: 0.037465 val loss: 0.012691
[Epoch 19] ogbg-molmuv: 0.071669 test loss: 0.011612
[Epoch 17; Iter   652/ 2483] train: loss: 0.0019177
[Epoch 17; Iter   682/ 2483] train: loss: 0.0010174
[Epoch 17; Iter   712/ 2483] train: loss: 0.0020362
[Epoch 17; Iter   742/ 2483] train: loss: 0.0012682
[Epoch 17; Iter   772/ 2483] train: loss: 0.0014051
[Epoch 17; Iter   802/ 2483] train: loss: 0.0021050
[Epoch 17; Iter   832/ 2483] train: loss: 0.0776877
[Epoch 17; Iter   862/ 2483] train: loss: 0.0014810
[Epoch 17; Iter   892/ 2483] train: loss: 0.0012400
[Epoch 17; Iter   922/ 2483] train: loss: 0.0014811
[Epoch 17; Iter   952/ 2483] train: loss: 0.0014257
[Epoch 17; Iter   982/ 2483] train: loss: 0.0014511
[Epoch 17; Iter  1012/ 2483] train: loss: 0.0017607
[Epoch 17; Iter  1042/ 2483] train: loss: 0.0749602
[Epoch 17; Iter  1072/ 2483] train: loss: 0.0014858
[Epoch 17; Iter  1102/ 2483] train: loss: 0.0730286
[Epoch 17; Iter  1132/ 2483] train: loss: 0.0015022
[Epoch 17; Iter  1162/ 2483] train: loss: 0.0010177
[Epoch 17; Iter  1192/ 2483] train: loss: 0.0014663
[Epoch 17; Iter  1222/ 2483] train: loss: 0.0041627
[Epoch 17; Iter  1252/ 2483] train: loss: 0.0063139
[Epoch 17; Iter  1282/ 2483] train: loss: 0.0028143
[Epoch 17; Iter  1312/ 2483] train: loss: 0.0041544
[Epoch 17; Iter  1342/ 2483] train: loss: 0.0016616
[Epoch 17; Iter  1372/ 2483] train: loss: 0.1678077
[Epoch 17; Iter  1402/ 2483] train: loss: 0.0012850
[Epoch 17; Iter  1432/ 2483] train: loss: 0.0019156
[Epoch 17; Iter  1462/ 2483] train: loss: 0.0024428
[Epoch 17; Iter  1492/ 2483] train: loss: 0.0014685
[Epoch 17; Iter  1522/ 2483] train: loss: 0.0031386
[Epoch 17; Iter  1552/ 2483] train: loss: 0.0023271
[Epoch 17; Iter  1582/ 2483] train: loss: 0.0026892
[Epoch 17; Iter  1612/ 2483] train: loss: 0.0017918
[Epoch 17; Iter  1642/ 2483] train: loss: 0.0024763
[Epoch 17; Iter  1672/ 2483] train: loss: 0.0018416
[Epoch 17; Iter  1702/ 2483] train: loss: 0.0017809
[Epoch 17; Iter  1732/ 2483] train: loss: 0.0019510
[Epoch 17; Iter  1762/ 2483] train: loss: 0.0019872
[Epoch 17; Iter  1792/ 2483] train: loss: 0.0021129
[Epoch 17; Iter  1822/ 2483] train: loss: 0.0015821
[Epoch 17; Iter  1852/ 2483] train: loss: 0.0649511
[Epoch 17; Iter  1882/ 2483] train: loss: 0.0014712
[Epoch 17; Iter  1912/ 2483] train: loss: 0.0014835
[Epoch 17; Iter  1942/ 2483] train: loss: 0.0013739
[Epoch 17; Iter  1972/ 2483] train: loss: 0.0015787
[Epoch 17; Iter  2002/ 2483] train: loss: 0.0016782
[Epoch 17; Iter  2032/ 2483] train: loss: 0.0017893
[Epoch 17; Iter  2062/ 2483] train: loss: 0.0013679
[Epoch 17; Iter  2092/ 2483] train: loss: 0.0013370
[Epoch 17; Iter  2122/ 2483] train: loss: 0.0015181
[Epoch 17; Iter  2152/ 2483] train: loss: 0.0013553
[Epoch 17; Iter  2182/ 2483] train: loss: 0.0013531
[Epoch 17; Iter  2212/ 2483] train: loss: 0.1143321
[Epoch 17; Iter  2242/ 2483] train: loss: 0.0567938
[Epoch 17; Iter  2272/ 2483] train: loss: 0.0016526
[Epoch 17; Iter  2302/ 2483] train: loss: 0.0014371
[Epoch 17; Iter  2332/ 2483] train: loss: 0.0017783
[Epoch 17; Iter  2362/ 2483] train: loss: 0.0014879
[Epoch 17; Iter  2392/ 2483] train: loss: 0.0014131
[Epoch 17; Iter  2422/ 2483] train: loss: 0.0015844
[Epoch 17; Iter  2452/ 2483] train: loss: 0.0024164
[Epoch 17; Iter  2482/ 2483] train: loss: 0.0023763
[Epoch 17] ogbg-molmuv: 0.113300 val loss: 0.015271
[Epoch 17] ogbg-molmuv: 0.139002 test loss: 0.013931
[Epoch 18; Iter    29/ 2483] train: loss: 0.0018818
[Epoch 18; Iter    59/ 2483] train: loss: 0.0030459
[Epoch 18; Iter    89/ 2483] train: loss: 0.0462786
[Epoch 18; Iter   119/ 2483] train: loss: 0.0016172
[Epoch 18; Iter   149/ 2483] train: loss: 0.0010139
[Epoch 18; Iter   179/ 2483] train: loss: 0.0011945
[Epoch 18; Iter   209/ 2483] train: loss: 0.0017247
[Epoch 18; Iter   239/ 2483] train: loss: 0.0023756
[Epoch 18; Iter   269/ 2483] train: loss: 0.0013553
[Epoch 18; Iter   299/ 2483] train: loss: 0.0034538
[Epoch 18; Iter   329/ 2483] train: loss: 0.0014403
[Epoch 18; Iter   359/ 2483] train: loss: 0.0016313
[Epoch 18; Iter   389/ 2483] train: loss: 0.0015139
[Epoch 18; Iter   419/ 2483] train: loss: 0.0795596
[Epoch 18; Iter   449/ 2483] train: loss: 0.0013922
[Epoch 18; Iter   479/ 2483] train: loss: 0.0468622
[Epoch 18; Iter   509/ 2483] train: loss: 0.0021774
[Epoch 18; Iter   539/ 2483] train: loss: 0.0029669
[Epoch 18; Iter   569/ 2483] train: loss: 0.0021647
[Epoch 18; Iter   599/ 2483] train: loss: 0.0020934
[Epoch 18; Iter   629/ 2483] train: loss: 0.0034801
[Epoch 18; Iter   659/ 2483] train: loss: 0.0024043
[Epoch 18; Iter   689/ 2483] train: loss: 0.0033131
[Epoch 18; Iter   719/ 2483] train: loss: 0.0020274
[Epoch 18; Iter   749/ 2483] train: loss: 0.0017770
[Epoch 18; Iter   779/ 2483] train: loss: 0.0898184
[Epoch 18; Iter   809/ 2483] train: loss: 0.0014152
[Epoch 18; Iter   839/ 2483] train: loss: 0.0018068
[Epoch 18; Iter   869/ 2483] train: loss: 0.0015903
[Epoch 18; Iter   899/ 2483] train: loss: 0.0015644
[Epoch 18; Iter   929/ 2483] train: loss: 0.0025335
[Epoch 18; Iter   959/ 2483] train: loss: 0.0018027
[Epoch 18; Iter   989/ 2483] train: loss: 0.0723197
[Epoch 18; Iter  1019/ 2483] train: loss: 0.0018481
[Epoch 18; Iter  1049/ 2483] train: loss: 0.0017929
[Epoch 18; Iter  1079/ 2483] train: loss: 0.0014131
[Epoch 18; Iter  1109/ 2483] train: loss: 0.0014563
[Epoch 18; Iter  1139/ 2483] train: loss: 0.0023462
[Epoch 18; Iter  1169/ 2483] train: loss: 0.0013844
[Epoch 18; Iter  1199/ 2483] train: loss: 0.0018341
[Epoch 18; Iter  1229/ 2483] train: loss: 0.0703991
[Epoch 18; Iter  1259/ 2483] train: loss: 0.0031452
[Epoch 18; Iter  1289/ 2483] train: loss: 0.0734506
[Epoch 18; Iter  1319/ 2483] train: loss: 0.0015262
[Epoch 18; Iter  1349/ 2483] train: loss: 0.0016461
[Epoch 18; Iter  1379/ 2483] train: loss: 0.0016794
[Epoch 18; Iter  1409/ 2483] train: loss: 0.0018561
[Epoch 18; Iter  1439/ 2483] train: loss: 0.0025748
[Epoch 18; Iter  1469/ 2483] train: loss: 0.0020577
[Epoch 18; Iter  1499/ 2483] train: loss: 0.0347303
[Epoch 18; Iter  1529/ 2483] train: loss: 0.0022124
[Epoch 18; Iter  1559/ 2483] train: loss: 0.0020611
[Epoch 18; Iter  1589/ 2483] train: loss: 0.0016156
[Epoch 18; Iter  1619/ 2483] train: loss: 0.0532488
[Epoch 18; Iter  1649/ 2483] train: loss: 0.0015483
[Epoch 18; Iter  1679/ 2483] train: loss: 0.0016246
[Epoch 18; Iter  1709/ 2483] train: loss: 0.0025543
[Epoch 18; Iter  1739/ 2483] train: loss: 0.0011592
[Epoch 18; Iter  1769/ 2483] train: loss: 0.0028600
[Epoch 18; Iter  1799/ 2483] train: loss: 0.0024442
[Epoch 18; Iter  1829/ 2483] train: loss: 0.0018260
[Epoch 18; Iter  1859/ 2483] train: loss: 0.0034014
[Epoch 18; Iter  1889/ 2483] train: loss: 0.0021324
[Epoch 18; Iter  1919/ 2483] train: loss: 0.0016125
[Epoch 18; Iter  1949/ 2483] train: loss: 0.0024563
[Epoch 18; Iter  1979/ 2483] train: loss: 0.0016977
[Epoch 18; Iter  2009/ 2483] train: loss: 0.0556360
[Epoch 18; Iter  2039/ 2483] train: loss: 0.0013202
[Epoch 18; Iter  2069/ 2483] train: loss: 0.0014017
[Epoch 18; Iter  2099/ 2483] train: loss: 0.0023108
[Epoch 18; Iter  2129/ 2483] train: loss: 0.0010391
[Epoch 18; Iter  2159/ 2483] train: loss: 0.0014499
[Epoch 18; Iter  2189/ 2483] train: loss: 0.0016871
[Epoch 18; Iter  2219/ 2483] train: loss: 0.0926137
[Epoch 18; Iter  2249/ 2483] train: loss: 0.0014214
[Epoch 18; Iter  2279/ 2483] train: loss: 0.0011897
[Epoch 18; Iter  2309/ 2483] train: loss: 0.0010209
[Epoch 18; Iter  2339/ 2483] train: loss: 0.0011261
[Epoch 18; Iter  2369/ 2483] train: loss: 0.0024150
[Epoch 18; Iter  2399/ 2483] train: loss: 0.0013267
[Epoch 18; Iter  2429/ 2483] train: loss: 0.0013022
[Epoch 18; Iter  2459/ 2483] train: loss: 0.0015546
[Epoch 18] ogbg-molmuv: 0.098881 val loss: 0.011051
[Epoch 18] ogbg-molmuv: 0.140390 test loss: 0.014100
[Epoch 19; Iter     6/ 2483] train: loss: 0.0009357
[Epoch 19; Iter    36/ 2483] train: loss: 0.0009797
[Epoch 19; Iter    66/ 2483] train: loss: 0.0009014
[Epoch 19; Iter    96/ 2483] train: loss: 0.0012735
[Epoch 19; Iter   126/ 2483] train: loss: 0.0016254
[Epoch 19; Iter   156/ 2483] train: loss: 0.0723376
[Epoch 19; Iter   186/ 2483] train: loss: 0.0276580
[Epoch 19; Iter   216/ 2483] train: loss: 0.0643583
[Epoch 19; Iter   246/ 2483] train: loss: 0.0035320
[Epoch 17; Iter   652/ 2483] train: loss: 0.0018781
[Epoch 17; Iter   682/ 2483] train: loss: 0.0017569
[Epoch 17; Iter   712/ 2483] train: loss: 0.0015804
[Epoch 17; Iter   742/ 2483] train: loss: 0.0361094
[Epoch 17; Iter   772/ 2483] train: loss: 0.0015696
[Epoch 17; Iter   802/ 2483] train: loss: 0.0014800
[Epoch 17; Iter   832/ 2483] train: loss: 0.0012947
[Epoch 17; Iter   862/ 2483] train: loss: 0.0017697
[Epoch 17; Iter   892/ 2483] train: loss: 0.0012076
[Epoch 17; Iter   922/ 2483] train: loss: 0.1205277
[Epoch 17; Iter   952/ 2483] train: loss: 0.0015868
[Epoch 17; Iter   982/ 2483] train: loss: 0.0014706
[Epoch 17; Iter  1012/ 2483] train: loss: 0.0700985
[Epoch 17; Iter  1042/ 2483] train: loss: 0.0020230
[Epoch 17; Iter  1072/ 2483] train: loss: 0.0010431
[Epoch 17; Iter  1102/ 2483] train: loss: 0.0012600
[Epoch 17; Iter  1132/ 2483] train: loss: 0.0010488
[Epoch 17; Iter  1162/ 2483] train: loss: 0.0132060
[Epoch 17; Iter  1192/ 2483] train: loss: 0.0027015
[Epoch 17; Iter  1222/ 2483] train: loss: 0.0019029
[Epoch 17; Iter  1252/ 2483] train: loss: 0.0019984
[Epoch 17; Iter  1282/ 2483] train: loss: 0.0028859
[Epoch 17; Iter  1312/ 2483] train: loss: 0.0015937
[Epoch 17; Iter  1342/ 2483] train: loss: 0.0014888
[Epoch 17; Iter  1372/ 2483] train: loss: 0.0027485
[Epoch 17; Iter  1402/ 2483] train: loss: 0.0015454
[Epoch 17; Iter  1432/ 2483] train: loss: 0.0012524
[Epoch 17; Iter  1462/ 2483] train: loss: 0.0015037
[Epoch 17; Iter  1492/ 2483] train: loss: 0.0832527
[Epoch 17; Iter  1522/ 2483] train: loss: 0.0012501
[Epoch 17; Iter  1552/ 2483] train: loss: 0.0020188
[Epoch 17; Iter  1582/ 2483] train: loss: 0.0015850
[Epoch 17; Iter  1612/ 2483] train: loss: 0.0019233
[Epoch 17; Iter  1642/ 2483] train: loss: 0.0011370
[Epoch 17; Iter  1672/ 2483] train: loss: 0.0016974
[Epoch 17; Iter  1702/ 2483] train: loss: 0.0014968
[Epoch 17; Iter  1732/ 2483] train: loss: 0.0017036
[Epoch 17; Iter  1762/ 2483] train: loss: 0.0017547
[Epoch 17; Iter  1792/ 2483] train: loss: 0.0020006
[Epoch 17; Iter  1822/ 2483] train: loss: 0.0019261
[Epoch 17; Iter  1852/ 2483] train: loss: 0.0014138
[Epoch 17; Iter  1882/ 2483] train: loss: 0.0040151
[Epoch 17; Iter  1912/ 2483] train: loss: 0.0018305
[Epoch 17; Iter  1942/ 2483] train: loss: 0.0016290
[Epoch 17; Iter  1972/ 2483] train: loss: 0.0881654
[Epoch 17; Iter  2002/ 2483] train: loss: 0.0014690
[Epoch 17; Iter  2032/ 2483] train: loss: 0.0011168
[Epoch 17; Iter  2062/ 2483] train: loss: 0.0015858
[Epoch 17; Iter  2092/ 2483] train: loss: 0.0622852
[Epoch 17; Iter  2122/ 2483] train: loss: 0.0957264
[Epoch 17; Iter  2152/ 2483] train: loss: 0.0022427
[Epoch 17; Iter  2182/ 2483] train: loss: 0.0012898
[Epoch 17; Iter  2212/ 2483] train: loss: 0.0014484
[Epoch 17; Iter  2242/ 2483] train: loss: 0.0017759
[Epoch 17; Iter  2272/ 2483] train: loss: 0.0015963
[Epoch 17; Iter  2302/ 2483] train: loss: 0.0018711
[Epoch 17; Iter  2332/ 2483] train: loss: 0.0018891
[Epoch 17; Iter  2362/ 2483] train: loss: 0.0013438
[Epoch 17; Iter  2392/ 2483] train: loss: 0.0018920
[Epoch 17; Iter  2422/ 2483] train: loss: 0.0018818
[Epoch 17; Iter  2452/ 2483] train: loss: 0.0014702
[Epoch 17; Iter  2482/ 2483] train: loss: 0.0011743
[Epoch 17] ogbg-molmuv: 0.066158 val loss: 0.011765
[Epoch 17] ogbg-molmuv: 0.040797 test loss: 0.015982
[Epoch 18; Iter    29/ 2483] train: loss: 0.0013309
[Epoch 18; Iter    59/ 2483] train: loss: 0.0013153
[Epoch 18; Iter    89/ 2483] train: loss: 0.0562667
[Epoch 18; Iter   119/ 2483] train: loss: 0.0806323
[Epoch 18; Iter   149/ 2483] train: loss: 0.0617006
[Epoch 18; Iter   179/ 2483] train: loss: 0.0014014
[Epoch 18; Iter   209/ 2483] train: loss: 0.0012304
[Epoch 18; Iter   239/ 2483] train: loss: 0.0013557
[Epoch 18; Iter   269/ 2483] train: loss: 0.0014128
[Epoch 18; Iter   299/ 2483] train: loss: 0.1225415
[Epoch 18; Iter   329/ 2483] train: loss: 0.0018165
[Epoch 18; Iter   359/ 2483] train: loss: 0.0015144
[Epoch 18; Iter   389/ 2483] train: loss: 0.0016813
[Epoch 18; Iter   419/ 2483] train: loss: 0.0017533
[Epoch 18; Iter   449/ 2483] train: loss: 0.0022657
[Epoch 18; Iter   479/ 2483] train: loss: 0.0022550
[Epoch 18; Iter   509/ 2483] train: loss: 0.0015026
[Epoch 18; Iter   539/ 2483] train: loss: 0.0018706
[Epoch 18; Iter   569/ 2483] train: loss: 0.0017637
[Epoch 18; Iter   599/ 2483] train: loss: 0.0506820
[Epoch 18; Iter   629/ 2483] train: loss: 0.0018883
[Epoch 18; Iter   659/ 2483] train: loss: 0.0020135
[Epoch 18; Iter   689/ 2483] train: loss: 0.0015758
[Epoch 18; Iter   719/ 2483] train: loss: 0.0014304
[Epoch 18; Iter   749/ 2483] train: loss: 0.0027712
[Epoch 18; Iter   779/ 2483] train: loss: 0.0015355
[Epoch 18; Iter   809/ 2483] train: loss: 0.0021675
[Epoch 18; Iter   839/ 2483] train: loss: 0.0031065
[Epoch 18; Iter   869/ 2483] train: loss: 0.0019351
[Epoch 18; Iter   899/ 2483] train: loss: 0.0014307
[Epoch 18; Iter   929/ 2483] train: loss: 0.0014721
[Epoch 18; Iter   959/ 2483] train: loss: 0.0019908
[Epoch 18; Iter   989/ 2483] train: loss: 0.0016683
[Epoch 18; Iter  1019/ 2483] train: loss: 0.0016497
[Epoch 18; Iter  1049/ 2483] train: loss: 0.0014863
[Epoch 18; Iter  1079/ 2483] train: loss: 0.0914345
[Epoch 18; Iter  1109/ 2483] train: loss: 0.0528589
[Epoch 18; Iter  1139/ 2483] train: loss: 0.0019971
[Epoch 18; Iter  1169/ 2483] train: loss: 0.0724111
[Epoch 18; Iter  1199/ 2483] train: loss: 0.0017062
[Epoch 18; Iter  1229/ 2483] train: loss: 0.0014010
[Epoch 18; Iter  1259/ 2483] train: loss: 0.0020975
[Epoch 18; Iter  1289/ 2483] train: loss: 0.0739658
[Epoch 18; Iter  1319/ 2483] train: loss: 0.0020001
[Epoch 18; Iter  1349/ 2483] train: loss: 0.0016271
[Epoch 18; Iter  1379/ 2483] train: loss: 0.0020420
[Epoch 18; Iter  1409/ 2483] train: loss: 0.0692493
[Epoch 18; Iter  1439/ 2483] train: loss: 0.0019742
[Epoch 18; Iter  1469/ 2483] train: loss: 0.0019737
[Epoch 18; Iter  1499/ 2483] train: loss: 0.0019081
[Epoch 18; Iter  1529/ 2483] train: loss: 0.0517198
[Epoch 18; Iter  1559/ 2483] train: loss: 0.0026222
[Epoch 18; Iter  1589/ 2483] train: loss: 0.0018092
[Epoch 18; Iter  1619/ 2483] train: loss: 0.0014457
[Epoch 18; Iter  1649/ 2483] train: loss: 0.0014266
[Epoch 18; Iter  1679/ 2483] train: loss: 0.0015591
[Epoch 18; Iter  1709/ 2483] train: loss: 0.0012905
[Epoch 18; Iter  1739/ 2483] train: loss: 0.1912730
[Epoch 18; Iter  1769/ 2483] train: loss: 0.1083090
[Epoch 18; Iter  1799/ 2483] train: loss: 0.0051543
[Epoch 18; Iter  1829/ 2483] train: loss: 0.0025159
[Epoch 18; Iter  1859/ 2483] train: loss: 0.0509301
[Epoch 18; Iter  1889/ 2483] train: loss: 0.0013914
[Epoch 18; Iter  1919/ 2483] train: loss: 0.0037262
[Epoch 18; Iter  1949/ 2483] train: loss: 0.0016681
[Epoch 18; Iter  1979/ 2483] train: loss: 0.0703538
[Epoch 18; Iter  2009/ 2483] train: loss: 0.0014514
[Epoch 18; Iter  2039/ 2483] train: loss: 0.0022525
[Epoch 18; Iter  2069/ 2483] train: loss: 0.0020371
[Epoch 18; Iter  2099/ 2483] train: loss: 0.0013844
[Epoch 18; Iter  2129/ 2483] train: loss: 0.0020108
[Epoch 18; Iter  2159/ 2483] train: loss: 0.0022590
[Epoch 18; Iter  2189/ 2483] train: loss: 0.0905148
[Epoch 18; Iter  2219/ 2483] train: loss: 0.0013765
[Epoch 18; Iter  2249/ 2483] train: loss: 0.0022232
[Epoch 18; Iter  2279/ 2483] train: loss: 0.0014856
[Epoch 18; Iter  2309/ 2483] train: loss: 0.0018752
[Epoch 18; Iter  2339/ 2483] train: loss: 0.0024127
[Epoch 18; Iter  2369/ 2483] train: loss: 0.0025290
[Epoch 18; Iter  2399/ 2483] train: loss: 0.0013586
[Epoch 18; Iter  2429/ 2483] train: loss: 0.0017979
[Epoch 18; Iter  2459/ 2483] train: loss: 0.0021289
[Epoch 18] ogbg-molmuv: 0.088092 val loss: 0.029470
[Epoch 18] ogbg-molmuv: 0.074495 test loss: 0.018567
[Epoch 19; Iter     6/ 2483] train: loss: 0.0579866
[Epoch 19; Iter    36/ 2483] train: loss: 0.0016013
[Epoch 19; Iter    66/ 2483] train: loss: 0.0026705
[Epoch 19; Iter    96/ 2483] train: loss: 0.0012898
[Epoch 19; Iter   126/ 2483] train: loss: 0.0011116
[Epoch 19; Iter   156/ 2483] train: loss: 0.0017964
[Epoch 19; Iter   186/ 2483] train: loss: 0.0014337
[Epoch 19; Iter   216/ 2483] train: loss: 0.0014739
[Epoch 19; Iter   246/ 2483] train: loss: 0.0011066
[Epoch 17; Iter   652/ 2483] train: loss: 0.0813294
[Epoch 17; Iter   682/ 2483] train: loss: 0.1080453
[Epoch 17; Iter   712/ 2483] train: loss: 0.0544966
[Epoch 17; Iter   742/ 2483] train: loss: 0.0769067
[Epoch 17; Iter   772/ 2483] train: loss: 0.0019148
[Epoch 17; Iter   802/ 2483] train: loss: 0.0014459
[Epoch 17; Iter   832/ 2483] train: loss: 0.0014126
[Epoch 17; Iter   862/ 2483] train: loss: 0.0017593
[Epoch 17; Iter   892/ 2483] train: loss: 0.0019603
[Epoch 17; Iter   922/ 2483] train: loss: 0.0027140
[Epoch 17; Iter   952/ 2483] train: loss: 0.0033440
[Epoch 17; Iter   982/ 2483] train: loss: 0.0029725
[Epoch 17; Iter  1012/ 2483] train: loss: 0.0015693
[Epoch 17; Iter  1042/ 2483] train: loss: 0.0017347
[Epoch 17; Iter  1072/ 2483] train: loss: 0.0316691
[Epoch 17; Iter  1102/ 2483] train: loss: 0.0011914
[Epoch 17; Iter  1132/ 2483] train: loss: 0.0011921
[Epoch 17; Iter  1162/ 2483] train: loss: 0.0015634
[Epoch 17; Iter  1192/ 2483] train: loss: 0.0016012
[Epoch 17; Iter  1222/ 2483] train: loss: 0.0014935
[Epoch 17; Iter  1252/ 2483] train: loss: 0.0017276
[Epoch 17; Iter  1282/ 2483] train: loss: 0.0016023
[Epoch 17; Iter  1312/ 2483] train: loss: 0.0030510
[Epoch 17; Iter  1342/ 2483] train: loss: 0.0016770
[Epoch 17; Iter  1372/ 2483] train: loss: 0.0023747
[Epoch 17; Iter  1402/ 2483] train: loss: 0.0039186
[Epoch 17; Iter  1432/ 2483] train: loss: 0.0017369
[Epoch 17; Iter  1462/ 2483] train: loss: 0.0019914
[Epoch 17; Iter  1492/ 2483] train: loss: 0.0018141
[Epoch 17; Iter  1522/ 2483] train: loss: 0.0018622
[Epoch 17; Iter  1552/ 2483] train: loss: 0.0022281
[Epoch 17; Iter  1582/ 2483] train: loss: 0.0019546
[Epoch 17; Iter  1612/ 2483] train: loss: 0.0465928
[Epoch 17; Iter  1642/ 2483] train: loss: 0.0048217
[Epoch 17; Iter  1672/ 2483] train: loss: 0.0014392
[Epoch 17; Iter  1702/ 2483] train: loss: 0.0901976
[Epoch 17; Iter  1732/ 2483] train: loss: 0.0011805
[Epoch 17; Iter  1762/ 2483] train: loss: 0.1499468
[Epoch 17; Iter  1792/ 2483] train: loss: 0.0024376
[Epoch 17; Iter  1822/ 2483] train: loss: 0.0072560
[Epoch 17; Iter  1852/ 2483] train: loss: 0.0018770
[Epoch 17; Iter  1882/ 2483] train: loss: 0.0019911
[Epoch 17; Iter  1912/ 2483] train: loss: 0.0017711
[Epoch 17; Iter  1942/ 2483] train: loss: 0.0020958
[Epoch 17; Iter  1972/ 2483] train: loss: 0.0014639
[Epoch 17; Iter  2002/ 2483] train: loss: 0.0016857
[Epoch 17; Iter  2032/ 2483] train: loss: 0.0047688
[Epoch 17; Iter  2062/ 2483] train: loss: 0.0022203
[Epoch 17; Iter  2092/ 2483] train: loss: 0.0025117
[Epoch 17; Iter  2122/ 2483] train: loss: 0.0633157
[Epoch 17; Iter  2152/ 2483] train: loss: 0.0040206
[Epoch 17; Iter  2182/ 2483] train: loss: 0.0018703
[Epoch 17; Iter  2212/ 2483] train: loss: 0.0018510
[Epoch 17; Iter  2242/ 2483] train: loss: 0.0019058
[Epoch 17; Iter  2272/ 2483] train: loss: 0.0657702
[Epoch 17; Iter  2302/ 2483] train: loss: 0.0015520
[Epoch 17; Iter  2332/ 2483] train: loss: 0.0011164
[Epoch 17; Iter  2362/ 2483] train: loss: 0.0017181
[Epoch 17; Iter  2392/ 2483] train: loss: 0.0012674
[Epoch 17; Iter  2422/ 2483] train: loss: 0.0013245
[Epoch 17; Iter  2452/ 2483] train: loss: 0.0027432
[Epoch 17; Iter  2482/ 2483] train: loss: 0.0519278
[Epoch 17] ogbg-molmuv: 0.085695 val loss: 0.010318
[Epoch 17] ogbg-molmuv: 0.123994 test loss: 0.014224
[Epoch 18; Iter    29/ 2483] train: loss: 0.0014491
[Epoch 18; Iter    59/ 2483] train: loss: 0.0012023
[Epoch 18; Iter    89/ 2483] train: loss: 0.0010848
[Epoch 18; Iter   119/ 2483] train: loss: 0.0020428
[Epoch 18; Iter   149/ 2483] train: loss: 0.0017564
[Epoch 18; Iter   179/ 2483] train: loss: 0.0018167
[Epoch 18; Iter   209/ 2483] train: loss: 0.0302924
[Epoch 18; Iter   239/ 2483] train: loss: 0.0014741
[Epoch 18; Iter   269/ 2483] train: loss: 0.0016187
[Epoch 18; Iter   299/ 2483] train: loss: 0.0021340
[Epoch 18; Iter   329/ 2483] train: loss: 0.0023603
[Epoch 18; Iter   359/ 2483] train: loss: 0.0020732
[Epoch 18; Iter   389/ 2483] train: loss: 0.0012604
[Epoch 18; Iter   419/ 2483] train: loss: 0.0034214
[Epoch 18; Iter   449/ 2483] train: loss: 0.0013292
[Epoch 18; Iter   479/ 2483] train: loss: 0.0013343
[Epoch 18; Iter   509/ 2483] train: loss: 0.0016958
[Epoch 18; Iter   539/ 2483] train: loss: 0.0014728
[Epoch 18; Iter   569/ 2483] train: loss: 0.0013867
[Epoch 18; Iter   599/ 2483] train: loss: 0.0016714
[Epoch 18; Iter   629/ 2483] train: loss: 0.0013640
[Epoch 18; Iter   659/ 2483] train: loss: 0.0016223
[Epoch 18; Iter   689/ 2483] train: loss: 0.0012353
[Epoch 18; Iter   719/ 2483] train: loss: 0.1069702
[Epoch 18; Iter   749/ 2483] train: loss: 0.0166263
[Epoch 18; Iter   779/ 2483] train: loss: 0.0026048
[Epoch 18; Iter   809/ 2483] train: loss: 0.1046842
[Epoch 18; Iter   839/ 2483] train: loss: 0.0017852
[Epoch 18; Iter   869/ 2483] train: loss: 0.1609998
[Epoch 18; Iter   899/ 2483] train: loss: 0.0636531
[Epoch 18; Iter   929/ 2483] train: loss: 0.0016245
[Epoch 18; Iter   959/ 2483] train: loss: 0.0024759
[Epoch 18; Iter   989/ 2483] train: loss: 0.0017030
[Epoch 18; Iter  1019/ 2483] train: loss: 0.0022010
[Epoch 18; Iter  1049/ 2483] train: loss: 0.0016944
[Epoch 18; Iter  1079/ 2483] train: loss: 0.0019303
[Epoch 18; Iter  1109/ 2483] train: loss: 0.0916063
[Epoch 18; Iter  1139/ 2483] train: loss: 0.0754853
[Epoch 18; Iter  1169/ 2483] train: loss: 0.0018542
[Epoch 18; Iter  1199/ 2483] train: loss: 0.0023158
[Epoch 18; Iter  1229/ 2483] train: loss: 0.0027906
[Epoch 18; Iter  1259/ 2483] train: loss: 0.0022684
[Epoch 18; Iter  1289/ 2483] train: loss: 0.0012314
[Epoch 18; Iter  1319/ 2483] train: loss: 0.0043587
[Epoch 18; Iter  1349/ 2483] train: loss: 0.0019068
[Epoch 18; Iter  1379/ 2483] train: loss: 0.0019107
[Epoch 18; Iter  1409/ 2483] train: loss: 0.0032777
[Epoch 18; Iter  1439/ 2483] train: loss: 0.0015999
[Epoch 18; Iter  1469/ 2483] train: loss: 0.0015886
[Epoch 18; Iter  1499/ 2483] train: loss: 0.0010565
[Epoch 18; Iter  1529/ 2483] train: loss: 0.0014754
[Epoch 18; Iter  1559/ 2483] train: loss: 0.0012691
[Epoch 18; Iter  1589/ 2483] train: loss: 0.0016689
[Epoch 18; Iter  1619/ 2483] train: loss: 0.0013018
[Epoch 18; Iter  1649/ 2483] train: loss: 0.0014486
[Epoch 18; Iter  1679/ 2483] train: loss: 0.0010833
[Epoch 18; Iter  1709/ 2483] train: loss: 0.0011479
[Epoch 18; Iter  1739/ 2483] train: loss: 0.0048725
[Epoch 18; Iter  1769/ 2483] train: loss: 0.0016284
[Epoch 18; Iter  1799/ 2483] train: loss: 0.0715189
[Epoch 18; Iter  1829/ 2483] train: loss: 0.0014488
[Epoch 18; Iter  1859/ 2483] train: loss: 0.0048611
[Epoch 18; Iter  1889/ 2483] train: loss: 0.0015842
[Epoch 18; Iter  1919/ 2483] train: loss: 0.0019340
[Epoch 18; Iter  1949/ 2483] train: loss: 0.0022877
[Epoch 18; Iter  1979/ 2483] train: loss: 0.0015109
[Epoch 18; Iter  2009/ 2483] train: loss: 0.0015865
[Epoch 18; Iter  2039/ 2483] train: loss: 0.0022261
[Epoch 18; Iter  2069/ 2483] train: loss: 0.1052990
[Epoch 18; Iter  2099/ 2483] train: loss: 0.0020576
[Epoch 18; Iter  2129/ 2483] train: loss: 0.0033079
[Epoch 18; Iter  2159/ 2483] train: loss: 0.0848934
[Epoch 18; Iter  2189/ 2483] train: loss: 0.0472956
[Epoch 18; Iter  2219/ 2483] train: loss: 0.0014873
[Epoch 18; Iter  2249/ 2483] train: loss: 0.0026127
[Epoch 18; Iter  2279/ 2483] train: loss: 0.0015306
[Epoch 18; Iter  2309/ 2483] train: loss: 0.0019275
[Epoch 18; Iter  2339/ 2483] train: loss: 0.0023919
[Epoch 18; Iter  2369/ 2483] train: loss: 0.0024508
[Epoch 18; Iter  2399/ 2483] train: loss: 0.0019164
[Epoch 18; Iter  2429/ 2483] train: loss: 0.0025147
[Epoch 18; Iter  2459/ 2483] train: loss: 0.0735579
[Epoch 18] ogbg-molmuv: 0.062663 val loss: 0.010315
[Epoch 18] ogbg-molmuv: 0.089618 test loss: 0.014224
[Epoch 19; Iter     6/ 2483] train: loss: 0.0813859
[Epoch 19; Iter    36/ 2483] train: loss: 0.0034196
[Epoch 19; Iter    66/ 2483] train: loss: 0.0030505
[Epoch 19; Iter    96/ 2483] train: loss: 0.0023802
[Epoch 19; Iter   126/ 2483] train: loss: 0.0655580
[Epoch 19; Iter   156/ 2483] train: loss: 0.0025520
[Epoch 19; Iter   186/ 2483] train: loss: 0.0017849
[Epoch 19; Iter   216/ 2483] train: loss: 0.0029976
[Epoch 19; Iter   246/ 2483] train: loss: 0.0564470
[Epoch 20; Iter    22/ 1862] train: loss: 0.0012635
[Epoch 20; Iter    52/ 1862] train: loss: 0.0014007
[Epoch 20; Iter    82/ 1862] train: loss: 0.0014905
[Epoch 20; Iter   112/ 1862] train: loss: 0.0012799
[Epoch 20; Iter   142/ 1862] train: loss: 0.0022937
[Epoch 20; Iter   172/ 1862] train: loss: 0.0019538
[Epoch 20; Iter   202/ 1862] train: loss: 0.0018239
[Epoch 20; Iter   232/ 1862] train: loss: 0.0026731
[Epoch 20; Iter   262/ 1862] train: loss: 0.0019354
[Epoch 20; Iter   292/ 1862] train: loss: 0.0015953
[Epoch 20; Iter   322/ 1862] train: loss: 0.0035527
[Epoch 20; Iter   352/ 1862] train: loss: 0.0030594
[Epoch 20; Iter   382/ 1862] train: loss: 0.0024322
[Epoch 20; Iter   412/ 1862] train: loss: 0.0020041
[Epoch 20; Iter   442/ 1862] train: loss: 0.0023603
[Epoch 20; Iter   472/ 1862] train: loss: 0.0014577
[Epoch 20; Iter   502/ 1862] train: loss: 0.0012680
[Epoch 20; Iter   532/ 1862] train: loss: 0.0013255
[Epoch 20; Iter   562/ 1862] train: loss: 0.0014355
[Epoch 20; Iter   592/ 1862] train: loss: 0.0016022
[Epoch 20; Iter   622/ 1862] train: loss: 0.0023594
[Epoch 20; Iter   652/ 1862] train: loss: 0.0033869
[Epoch 20; Iter   682/ 1862] train: loss: 0.0010670
[Epoch 20; Iter   712/ 1862] train: loss: 0.0024805
[Epoch 20; Iter   742/ 1862] train: loss: 0.0030702
[Epoch 20; Iter   772/ 1862] train: loss: 0.0011317
[Epoch 20; Iter   802/ 1862] train: loss: 0.0577430
[Epoch 20; Iter   832/ 1862] train: loss: 0.0372011
[Epoch 20; Iter   862/ 1862] train: loss: 0.0017383
[Epoch 20; Iter   892/ 1862] train: loss: 0.0021358
[Epoch 20; Iter   922/ 1862] train: loss: 0.0015377
[Epoch 20; Iter   952/ 1862] train: loss: 0.0031790
[Epoch 20; Iter   982/ 1862] train: loss: 0.0034407
[Epoch 20; Iter  1012/ 1862] train: loss: 0.0020326
[Epoch 20; Iter  1042/ 1862] train: loss: 0.0012081
[Epoch 20; Iter  1072/ 1862] train: loss: 0.0017092
[Epoch 20; Iter  1102/ 1862] train: loss: 0.0019678
[Epoch 20; Iter  1132/ 1862] train: loss: 0.0017045
[Epoch 20; Iter  1162/ 1862] train: loss: 0.0012454
[Epoch 20; Iter  1192/ 1862] train: loss: 0.0012423
[Epoch 20; Iter  1222/ 1862] train: loss: 0.0017073
[Epoch 20; Iter  1252/ 1862] train: loss: 0.0011599
[Epoch 20; Iter  1282/ 1862] train: loss: 0.0020658
[Epoch 20; Iter  1312/ 1862] train: loss: 0.0024859
[Epoch 20; Iter  1342/ 1862] train: loss: 0.0794969
[Epoch 20; Iter  1372/ 1862] train: loss: 0.0016684
[Epoch 20; Iter  1402/ 1862] train: loss: 0.0018554
[Epoch 20; Iter  1432/ 1862] train: loss: 0.0559153
[Epoch 20; Iter  1462/ 1862] train: loss: 0.0015518
[Epoch 20; Iter  1492/ 1862] train: loss: 0.0809228
[Epoch 20; Iter  1522/ 1862] train: loss: 0.0015659
[Epoch 20; Iter  1552/ 1862] train: loss: 0.0621312
[Epoch 20; Iter  1582/ 1862] train: loss: 0.0019313
[Epoch 20; Iter  1612/ 1862] train: loss: 0.0012252
[Epoch 20; Iter  1642/ 1862] train: loss: 0.0296618
[Epoch 20; Iter  1672/ 1862] train: loss: 0.1227146
[Epoch 20; Iter  1702/ 1862] train: loss: 0.0013070
[Epoch 20; Iter  1732/ 1862] train: loss: 0.0016947
[Epoch 20; Iter  1762/ 1862] train: loss: 0.0016222
[Epoch 20; Iter  1792/ 1862] train: loss: 0.0032017
[Epoch 20; Iter  1822/ 1862] train: loss: 0.0016331
[Epoch 20; Iter  1852/ 1862] train: loss: 0.0013017
[Epoch 20] ogbg-molmuv: 0.042543 val loss: 0.020355
[Epoch 20] ogbg-molmuv: 0.074119 test loss: 0.012368
[Epoch 21; Iter    20/ 1862] train: loss: 0.0022369
[Epoch 21; Iter    50/ 1862] train: loss: 0.0019947
[Epoch 21; Iter    80/ 1862] train: loss: 0.0019277
[Epoch 21; Iter   110/ 1862] train: loss: 0.0022202
[Epoch 21; Iter   140/ 1862] train: loss: 0.0018873
[Epoch 21; Iter   170/ 1862] train: loss: 0.0019551
[Epoch 21; Iter   200/ 1862] train: loss: 0.0412000
[Epoch 21; Iter   230/ 1862] train: loss: 0.0010762
[Epoch 21; Iter   260/ 1862] train: loss: 0.0016581
[Epoch 21; Iter   290/ 1862] train: loss: 0.0009637
[Epoch 21; Iter   320/ 1862] train: loss: 0.0013325
[Epoch 21; Iter   350/ 1862] train: loss: 0.0017983
[Epoch 21; Iter   380/ 1862] train: loss: 0.0020227
[Epoch 21; Iter   410/ 1862] train: loss: 0.0022556
[Epoch 21; Iter   440/ 1862] train: loss: 0.0734607
[Epoch 21; Iter   470/ 1862] train: loss: 0.0505997
[Epoch 21; Iter   500/ 1862] train: loss: 0.0680737
[Epoch 21; Iter   530/ 1862] train: loss: 0.0069463
[Epoch 21; Iter   560/ 1862] train: loss: 0.0023530
[Epoch 21; Iter   590/ 1862] train: loss: 0.0021692
[Epoch 21; Iter   620/ 1862] train: loss: 0.0015990
[Epoch 21; Iter   650/ 1862] train: loss: 0.0014110
[Epoch 21; Iter   680/ 1862] train: loss: 0.0017497
[Epoch 21; Iter   710/ 1862] train: loss: 0.0019123
[Epoch 21; Iter   740/ 1862] train: loss: 0.0010670
[Epoch 21; Iter   770/ 1862] train: loss: 0.0014015
[Epoch 21; Iter   800/ 1862] train: loss: 0.0011620
[Epoch 21; Iter   830/ 1862] train: loss: 0.0009498
[Epoch 21; Iter   860/ 1862] train: loss: 0.0011975
[Epoch 21; Iter   890/ 1862] train: loss: 0.0013303
[Epoch 21; Iter   920/ 1862] train: loss: 0.0017236
[Epoch 21; Iter   950/ 1862] train: loss: 0.0021420
[Epoch 21; Iter   980/ 1862] train: loss: 0.0022174
[Epoch 21; Iter  1010/ 1862] train: loss: 0.0018313
[Epoch 21; Iter  1040/ 1862] train: loss: 0.0017000
[Epoch 21; Iter  1070/ 1862] train: loss: 0.0014746
[Epoch 21; Iter  1100/ 1862] train: loss: 0.0038208
[Epoch 21; Iter  1130/ 1862] train: loss: 0.0038487
[Epoch 21; Iter  1160/ 1862] train: loss: 0.0020251
[Epoch 21; Iter  1190/ 1862] train: loss: 0.0036044
[Epoch 21; Iter  1220/ 1862] train: loss: 0.0012594
[Epoch 21; Iter  1250/ 1862] train: loss: 0.0024332
[Epoch 21; Iter  1280/ 1862] train: loss: 0.0812946
[Epoch 21; Iter  1310/ 1862] train: loss: 0.0015413
[Epoch 21; Iter  1340/ 1862] train: loss: 0.0025585
[Epoch 21; Iter  1370/ 1862] train: loss: 0.0009666
[Epoch 21; Iter  1400/ 1862] train: loss: 0.0010485
[Epoch 21; Iter  1430/ 1862] train: loss: 0.0828217
[Epoch 21; Iter  1460/ 1862] train: loss: 0.0035883
[Epoch 21; Iter  1490/ 1862] train: loss: 0.0025732
[Epoch 21; Iter  1520/ 1862] train: loss: 0.0014875
[Epoch 21; Iter  1550/ 1862] train: loss: 0.0015491
[Epoch 21; Iter  1580/ 1862] train: loss: 0.0031047
[Epoch 21; Iter  1610/ 1862] train: loss: 0.0019040
[Epoch 21; Iter  1640/ 1862] train: loss: 0.0010340
[Epoch 21; Iter  1670/ 1862] train: loss: 0.0017226
[Epoch 21; Iter  1700/ 1862] train: loss: 0.0015178
[Epoch 21; Iter  1730/ 1862] train: loss: 0.0020513
[Epoch 21; Iter  1760/ 1862] train: loss: 0.0007435
[Epoch 21; Iter  1790/ 1862] train: loss: 0.0010763
[Epoch 21; Iter  1820/ 1862] train: loss: 0.0020645
[Epoch 21; Iter  1850/ 1862] train: loss: 0.0656417
[Epoch 21] ogbg-molmuv: 0.049412 val loss: 0.019858
[Epoch 21] ogbg-molmuv: 0.077539 test loss: 0.012865
[Epoch 22; Iter    18/ 1862] train: loss: 0.0017254
[Epoch 22; Iter    48/ 1862] train: loss: 0.0016894
[Epoch 22; Iter    78/ 1862] train: loss: 0.0013953
[Epoch 22; Iter   108/ 1862] train: loss: 0.0012715
[Epoch 22; Iter   138/ 1862] train: loss: 0.0008715
[Epoch 22; Iter   168/ 1862] train: loss: 0.0013842
[Epoch 22; Iter   198/ 1862] train: loss: 0.0009663
[Epoch 22; Iter   228/ 1862] train: loss: 0.0552267
[Epoch 22; Iter   258/ 1862] train: loss: 0.0023138
[Epoch 22; Iter   288/ 1862] train: loss: 0.0029863
[Epoch 22; Iter   318/ 1862] train: loss: 0.0039302
[Epoch 22; Iter   348/ 1862] train: loss: 0.0556990
[Epoch 22; Iter   378/ 1862] train: loss: 0.0017090
[Epoch 22; Iter   408/ 1862] train: loss: 0.0016793
[Epoch 22; Iter   438/ 1862] train: loss: 0.0012287
[Epoch 22; Iter   468/ 1862] train: loss: 0.0007339
[Epoch 22; Iter   498/ 1862] train: loss: 0.0019893
[Epoch 22; Iter   528/ 1862] train: loss: 0.0017503
[Epoch 22; Iter   558/ 1862] train: loss: 0.0852375
[Epoch 22; Iter   588/ 1862] train: loss: 0.0013226
[Epoch 22; Iter   618/ 1862] train: loss: 0.0015625
[Epoch 22; Iter   648/ 1862] train: loss: 0.0018427
[Epoch 22; Iter   678/ 1862] train: loss: 0.0010448
[Epoch 22; Iter   708/ 1862] train: loss: 0.0706544
[Epoch 22; Iter   738/ 1862] train: loss: 0.0020542
[Epoch 22; Iter   768/ 1862] train: loss: 0.0018830
[Epoch 22; Iter   798/ 1862] train: loss: 0.0014341
[Epoch 22; Iter   828/ 1862] train: loss: 0.0020996
[Epoch 22; Iter   858/ 1862] train: loss: 0.0023315
[Epoch 19; Iter   276/ 2483] train: loss: 0.0013884
[Epoch 19; Iter   306/ 2483] train: loss: 0.0012199
[Epoch 19; Iter   336/ 2483] train: loss: 0.0010731
[Epoch 19; Iter   366/ 2483] train: loss: 0.0621001
[Epoch 19; Iter   396/ 2483] train: loss: 0.0023540
[Epoch 19; Iter   426/ 2483] train: loss: 0.0802668
[Epoch 19; Iter   456/ 2483] train: loss: 0.0014588
[Epoch 19; Iter   486/ 2483] train: loss: 0.0014736
[Epoch 19; Iter   516/ 2483] train: loss: 0.0016606
[Epoch 19; Iter   546/ 2483] train: loss: 0.0017355
[Epoch 19; Iter   576/ 2483] train: loss: 0.0012870
[Epoch 19; Iter   606/ 2483] train: loss: 0.0639035
[Epoch 19; Iter   636/ 2483] train: loss: 0.0010284
[Epoch 19; Iter   666/ 2483] train: loss: 0.0019091
[Epoch 19; Iter   696/ 2483] train: loss: 0.0015184
[Epoch 19; Iter   726/ 2483] train: loss: 0.0012889
[Epoch 19; Iter   756/ 2483] train: loss: 0.0039207
[Epoch 19; Iter   786/ 2483] train: loss: 0.0015405
[Epoch 19; Iter   816/ 2483] train: loss: 0.0014003
[Epoch 19; Iter   846/ 2483] train: loss: 0.0015942
[Epoch 19; Iter   876/ 2483] train: loss: 0.0015683
[Epoch 19; Iter   906/ 2483] train: loss: 0.0017747
[Epoch 19; Iter   936/ 2483] train: loss: 0.0011424
[Epoch 19; Iter   966/ 2483] train: loss: 0.0013838
[Epoch 19; Iter   996/ 2483] train: loss: 0.0018743
[Epoch 19; Iter  1026/ 2483] train: loss: 0.0016391
[Epoch 19; Iter  1056/ 2483] train: loss: 0.0020532
[Epoch 19; Iter  1086/ 2483] train: loss: 0.0013055
[Epoch 19; Iter  1116/ 2483] train: loss: 0.0016924
[Epoch 19; Iter  1146/ 2483] train: loss: 0.0024800
[Epoch 19; Iter  1176/ 2483] train: loss: 0.0021049
[Epoch 19; Iter  1206/ 2483] train: loss: 0.0019759
[Epoch 19; Iter  1236/ 2483] train: loss: 0.0025362
[Epoch 19; Iter  1266/ 2483] train: loss: 0.0024199
[Epoch 19; Iter  1296/ 2483] train: loss: 0.0023126
[Epoch 19; Iter  1326/ 2483] train: loss: 0.0018653
[Epoch 19; Iter  1356/ 2483] train: loss: 0.0014742
[Epoch 19; Iter  1386/ 2483] train: loss: 0.0016762
[Epoch 19; Iter  1416/ 2483] train: loss: 0.0010425
[Epoch 19; Iter  1446/ 2483] train: loss: 0.0014654
[Epoch 19; Iter  1476/ 2483] train: loss: 0.0436166
[Epoch 19; Iter  1506/ 2483] train: loss: 0.0014274
[Epoch 19; Iter  1536/ 2483] train: loss: 0.0019742
[Epoch 19; Iter  1566/ 2483] train: loss: 0.0016568
[Epoch 19; Iter  1596/ 2483] train: loss: 0.0015322
[Epoch 19; Iter  1626/ 2483] train: loss: 0.0022872
[Epoch 19; Iter  1656/ 2483] train: loss: 0.0534854
[Epoch 19; Iter  1686/ 2483] train: loss: 0.0382279
[Epoch 19; Iter  1716/ 2483] train: loss: 0.0018884
[Epoch 19; Iter  1746/ 2483] train: loss: 0.0015497
[Epoch 19; Iter  1776/ 2483] train: loss: 0.0018628
[Epoch 19; Iter  1806/ 2483] train: loss: 0.0490651
[Epoch 19; Iter  1836/ 2483] train: loss: 0.0018366
[Epoch 19; Iter  1866/ 2483] train: loss: 0.0588780
[Epoch 19; Iter  1896/ 2483] train: loss: 0.0022130
[Epoch 19; Iter  1926/ 2483] train: loss: 0.0032863
[Epoch 19; Iter  1956/ 2483] train: loss: 0.0043458
[Epoch 19; Iter  1986/ 2483] train: loss: 0.0017858
[Epoch 19; Iter  2016/ 2483] train: loss: 0.0020444
[Epoch 19; Iter  2046/ 2483] train: loss: 0.0022594
[Epoch 19; Iter  2076/ 2483] train: loss: 0.0018163
[Epoch 19; Iter  2106/ 2483] train: loss: 0.0700470
[Epoch 19; Iter  2136/ 2483] train: loss: 0.0749972
[Epoch 19; Iter  2166/ 2483] train: loss: 0.0041209
[Epoch 19; Iter  2196/ 2483] train: loss: 0.0015797
[Epoch 19; Iter  2226/ 2483] train: loss: 0.0021229
[Epoch 19; Iter  2256/ 2483] train: loss: 0.0018699
[Epoch 19; Iter  2286/ 2483] train: loss: 0.0014496
[Epoch 19; Iter  2316/ 2483] train: loss: 0.0013094
[Epoch 19; Iter  2346/ 2483] train: loss: 0.0885689
[Epoch 19; Iter  2376/ 2483] train: loss: 0.0030589
[Epoch 19; Iter  2406/ 2483] train: loss: 0.0826605
[Epoch 19; Iter  2436/ 2483] train: loss: 0.0017643
[Epoch 19; Iter  2466/ 2483] train: loss: 0.0018278
[Epoch 19] ogbg-molmuv: 0.059332 val loss: 0.011502
[Epoch 19] ogbg-molmuv: 0.074420 test loss: 0.013611
[Epoch 20; Iter    13/ 2483] train: loss: 0.0662764
[Epoch 20; Iter    43/ 2483] train: loss: 0.0014017
[Epoch 20; Iter    73/ 2483] train: loss: 0.0017180
[Epoch 20; Iter   103/ 2483] train: loss: 0.0018286
[Epoch 20; Iter   133/ 2483] train: loss: 0.0010671
[Epoch 20; Iter   163/ 2483] train: loss: 0.0015372
[Epoch 20; Iter   193/ 2483] train: loss: 0.0013904
[Epoch 20; Iter   223/ 2483] train: loss: 0.0015189
[Epoch 20; Iter   253/ 2483] train: loss: 0.0013330
[Epoch 20; Iter   283/ 2483] train: loss: 0.0825729
[Epoch 20; Iter   313/ 2483] train: loss: 0.0014828
[Epoch 20; Iter   343/ 2483] train: loss: 0.0011828
[Epoch 20; Iter   373/ 2483] train: loss: 0.0019672
[Epoch 20; Iter   403/ 2483] train: loss: 0.0865618
[Epoch 20; Iter   433/ 2483] train: loss: 0.0012334
[Epoch 20; Iter   463/ 2483] train: loss: 0.0026151
[Epoch 20; Iter   493/ 2483] train: loss: 0.0016166
[Epoch 20; Iter   523/ 2483] train: loss: 0.0011802
[Epoch 20; Iter   553/ 2483] train: loss: 0.0009070
[Epoch 20; Iter   583/ 2483] train: loss: 0.0014065
[Epoch 20; Iter   613/ 2483] train: loss: 0.0014962
[Epoch 20; Iter   643/ 2483] train: loss: 0.0014977
[Epoch 20; Iter   673/ 2483] train: loss: 0.0023604
[Epoch 20; Iter   703/ 2483] train: loss: 0.0678699
[Epoch 20; Iter   733/ 2483] train: loss: 0.0020563
[Epoch 20; Iter   763/ 2483] train: loss: 0.0025933
[Epoch 20; Iter   793/ 2483] train: loss: 0.0027090
[Epoch 20; Iter   823/ 2483] train: loss: 0.0039101
[Epoch 20; Iter   853/ 2483] train: loss: 0.0021150
[Epoch 20; Iter   883/ 2483] train: loss: 0.0014616
[Epoch 20; Iter   913/ 2483] train: loss: 0.0020929
[Epoch 20; Iter   943/ 2483] train: loss: 0.0018102
[Epoch 20; Iter   973/ 2483] train: loss: 0.0732998
[Epoch 20; Iter  1003/ 2483] train: loss: 0.0054565
[Epoch 20; Iter  1033/ 2483] train: loss: 0.0023322
[Epoch 20; Iter  1063/ 2483] train: loss: 0.0026479
[Epoch 20; Iter  1093/ 2483] train: loss: 0.0016809
[Epoch 20; Iter  1123/ 2483] train: loss: 0.0025676
[Epoch 20; Iter  1153/ 2483] train: loss: 0.0013221
[Epoch 20; Iter  1183/ 2483] train: loss: 0.0020973
[Epoch 20; Iter  1213/ 2483] train: loss: 0.0015944
[Epoch 20; Iter  1243/ 2483] train: loss: 0.0020734
[Epoch 20; Iter  1273/ 2483] train: loss: 0.0018489
[Epoch 20; Iter  1303/ 2483] train: loss: 0.0017206
[Epoch 20; Iter  1333/ 2483] train: loss: 0.0094847
[Epoch 20; Iter  1363/ 2483] train: loss: 0.0011672
[Epoch 20; Iter  1393/ 2483] train: loss: 0.0013514
[Epoch 20; Iter  1423/ 2483] train: loss: 0.0021963
[Epoch 20; Iter  1453/ 2483] train: loss: 0.0012586
[Epoch 20; Iter  1483/ 2483] train: loss: 0.0369692
[Epoch 20; Iter  1513/ 2483] train: loss: 0.0023115
[Epoch 20; Iter  1543/ 2483] train: loss: 0.0019744
[Epoch 20; Iter  1573/ 2483] train: loss: 0.0024379
[Epoch 20; Iter  1603/ 2483] train: loss: 0.0020990
[Epoch 20; Iter  1633/ 2483] train: loss: 0.0018386
[Epoch 20; Iter  1663/ 2483] train: loss: 0.0019372
[Epoch 20; Iter  1693/ 2483] train: loss: 0.0033219
[Epoch 20; Iter  1723/ 2483] train: loss: 0.0016295
[Epoch 20; Iter  1753/ 2483] train: loss: 0.1076391
[Epoch 20; Iter  1783/ 2483] train: loss: 0.1169892
[Epoch 20; Iter  1813/ 2483] train: loss: 0.0034717
[Epoch 20; Iter  1843/ 2483] train: loss: 0.0476115
[Epoch 20; Iter  1873/ 2483] train: loss: 0.0019102
[Epoch 20; Iter  1903/ 2483] train: loss: 0.0020890
[Epoch 20; Iter  1933/ 2483] train: loss: 0.0014260
[Epoch 20; Iter  1963/ 2483] train: loss: 0.1016142
[Epoch 20; Iter  1993/ 2483] train: loss: 0.0790859
[Epoch 20; Iter  2023/ 2483] train: loss: 0.0018768
[Epoch 20; Iter  2053/ 2483] train: loss: 0.0017956
[Epoch 20; Iter  2083/ 2483] train: loss: 0.0020443
[Epoch 20; Iter  2113/ 2483] train: loss: 0.0012473
[Epoch 20; Iter  2143/ 2483] train: loss: 0.0018354
[Epoch 20; Iter  2173/ 2483] train: loss: 0.0025520
[Epoch 20; Iter  2203/ 2483] train: loss: 0.0015223
[Epoch 20; Iter  2233/ 2483] train: loss: 0.0016344
[Epoch 20; Iter  2263/ 2483] train: loss: 0.0015350
[Epoch 20; Iter  2293/ 2483] train: loss: 0.0038389
[Epoch 20; Iter  2323/ 2483] train: loss: 0.0012419
[Epoch 20; Iter  2353/ 2483] train: loss: 0.0017474
[Epoch 20; Iter  2383/ 2483] train: loss: 0.0013023
[Epoch 20; Iter  2413/ 2483] train: loss: 0.0012616
[Epoch 19; Iter  1134/ 2172] train: loss: 0.0016863
[Epoch 19; Iter  1164/ 2172] train: loss: 0.0012579
[Epoch 19; Iter  1194/ 2172] train: loss: 0.0674641
[Epoch 19; Iter  1224/ 2172] train: loss: 0.0014756
[Epoch 19; Iter  1254/ 2172] train: loss: 0.0016604
[Epoch 19; Iter  1284/ 2172] train: loss: 0.0012359
[Epoch 19; Iter  1314/ 2172] train: loss: 0.0566952
[Epoch 19; Iter  1344/ 2172] train: loss: 0.0033554
[Epoch 19; Iter  1374/ 2172] train: loss: 0.0750450
[Epoch 19; Iter  1404/ 2172] train: loss: 0.0020384
[Epoch 19; Iter  1434/ 2172] train: loss: 0.0019819
[Epoch 19; Iter  1464/ 2172] train: loss: 0.0025069
[Epoch 19; Iter  1494/ 2172] train: loss: 0.0012617
[Epoch 19; Iter  1524/ 2172] train: loss: 0.0016007
[Epoch 19; Iter  1554/ 2172] train: loss: 0.0012840
[Epoch 19; Iter  1584/ 2172] train: loss: 0.0011610
[Epoch 19; Iter  1614/ 2172] train: loss: 0.0031469
[Epoch 19; Iter  1644/ 2172] train: loss: 0.0015068
[Epoch 19; Iter  1674/ 2172] train: loss: 0.0526654
[Epoch 19; Iter  1704/ 2172] train: loss: 0.0012220
[Epoch 19; Iter  1734/ 2172] train: loss: 0.0026155
[Epoch 19; Iter  1764/ 2172] train: loss: 0.0011989
[Epoch 19; Iter  1794/ 2172] train: loss: 0.0019299
[Epoch 19; Iter  1824/ 2172] train: loss: 0.0014733
[Epoch 19; Iter  1854/ 2172] train: loss: 0.0489894
[Epoch 19; Iter  1884/ 2172] train: loss: 0.0013763
[Epoch 19; Iter  1914/ 2172] train: loss: 0.0031991
[Epoch 19; Iter  1944/ 2172] train: loss: 0.0011625
[Epoch 19; Iter  1974/ 2172] train: loss: 0.0016938
[Epoch 19; Iter  2004/ 2172] train: loss: 0.0036203
[Epoch 19; Iter  2034/ 2172] train: loss: 0.0014059
[Epoch 19; Iter  2064/ 2172] train: loss: 0.1459147
[Epoch 19; Iter  2094/ 2172] train: loss: 0.0013788
[Epoch 19; Iter  2124/ 2172] train: loss: 0.0012879
[Epoch 19; Iter  2154/ 2172] train: loss: 0.0030778
[Epoch 19] ogbg-molmuv: 0.057021 val loss: 0.205141
[Epoch 19] ogbg-molmuv: 0.080720 test loss: 0.434242
[Epoch 20; Iter    12/ 2172] train: loss: 0.0014195
[Epoch 20; Iter    42/ 2172] train: loss: 0.0009712
[Epoch 20; Iter    72/ 2172] train: loss: 0.0017866
[Epoch 20; Iter   102/ 2172] train: loss: 0.0013202
[Epoch 20; Iter   132/ 2172] train: loss: 0.0016613
[Epoch 20; Iter   162/ 2172] train: loss: 0.0010366
[Epoch 20; Iter   192/ 2172] train: loss: 0.0017129
[Epoch 20; Iter   222/ 2172] train: loss: 0.0012323
[Epoch 20; Iter   252/ 2172] train: loss: 0.0016478
[Epoch 20; Iter   282/ 2172] train: loss: 0.0021170
[Epoch 20; Iter   312/ 2172] train: loss: 0.0011364
[Epoch 20; Iter   342/ 2172] train: loss: 0.0033611
[Epoch 20; Iter   372/ 2172] train: loss: 0.0009614
[Epoch 20; Iter   402/ 2172] train: loss: 0.0018783
[Epoch 20; Iter   432/ 2172] train: loss: 0.0010187
[Epoch 20; Iter   462/ 2172] train: loss: 0.0010302
[Epoch 20; Iter   492/ 2172] train: loss: 0.0785537
[Epoch 20; Iter   522/ 2172] train: loss: 0.0017981
[Epoch 20; Iter   552/ 2172] train: loss: 0.0012842
[Epoch 20; Iter   582/ 2172] train: loss: 0.0010320
[Epoch 20; Iter   612/ 2172] train: loss: 0.0011794
[Epoch 20; Iter   642/ 2172] train: loss: 0.0010354
[Epoch 20; Iter   672/ 2172] train: loss: 0.0016196
[Epoch 20; Iter   702/ 2172] train: loss: 0.0013193
[Epoch 20; Iter   732/ 2172] train: loss: 0.0011388
[Epoch 20; Iter   762/ 2172] train: loss: 0.0547272
[Epoch 20; Iter   792/ 2172] train: loss: 0.0277270
[Epoch 20; Iter   822/ 2172] train: loss: 0.0010414
[Epoch 20; Iter   852/ 2172] train: loss: 0.1044444
[Epoch 20; Iter   882/ 2172] train: loss: 0.0016288
[Epoch 20; Iter   912/ 2172] train: loss: 0.0022242
[Epoch 20; Iter   942/ 2172] train: loss: 0.0017204
[Epoch 20; Iter   972/ 2172] train: loss: 0.0215377
[Epoch 20; Iter  1002/ 2172] train: loss: 0.0008683
[Epoch 20; Iter  1032/ 2172] train: loss: 0.0013483
[Epoch 20; Iter  1062/ 2172] train: loss: 0.0011722
[Epoch 20; Iter  1092/ 2172] train: loss: 0.0011851
[Epoch 20; Iter  1122/ 2172] train: loss: 0.0012801
[Epoch 20; Iter  1152/ 2172] train: loss: 0.0012402
[Epoch 20; Iter  1182/ 2172] train: loss: 0.0009276
[Epoch 20; Iter  1212/ 2172] train: loss: 0.0020568
[Epoch 20; Iter  1242/ 2172] train: loss: 0.0011552
[Epoch 20; Iter  1272/ 2172] train: loss: 0.0026814
[Epoch 20; Iter  1302/ 2172] train: loss: 0.0016252
[Epoch 20; Iter  1332/ 2172] train: loss: 0.0018453
[Epoch 20; Iter  1362/ 2172] train: loss: 0.0019996
[Epoch 20; Iter  1392/ 2172] train: loss: 0.0014870
[Epoch 20; Iter  1422/ 2172] train: loss: 0.0014428
[Epoch 20; Iter  1452/ 2172] train: loss: 0.0285241
[Epoch 20; Iter  1482/ 2172] train: loss: 0.0036318
[Epoch 20; Iter  1512/ 2172] train: loss: 0.0017474
[Epoch 20; Iter  1542/ 2172] train: loss: 0.0009209
[Epoch 20; Iter  1572/ 2172] train: loss: 0.0025427
[Epoch 20; Iter  1602/ 2172] train: loss: 0.0023126
[Epoch 20; Iter  1632/ 2172] train: loss: 0.0017614
[Epoch 20; Iter  1662/ 2172] train: loss: 0.0050049
[Epoch 20; Iter  1692/ 2172] train: loss: 0.0015567
[Epoch 20; Iter  1722/ 2172] train: loss: 0.0012094
[Epoch 20; Iter  1752/ 2172] train: loss: 0.0024241
[Epoch 20; Iter  1782/ 2172] train: loss: 0.0012281
[Epoch 20; Iter  1812/ 2172] train: loss: 0.0014566
[Epoch 20; Iter  1842/ 2172] train: loss: 0.0039933
[Epoch 20; Iter  1872/ 2172] train: loss: 0.0049373
[Epoch 20; Iter  1902/ 2172] train: loss: 0.0011699
[Epoch 20; Iter  1932/ 2172] train: loss: 0.0017176
[Epoch 20; Iter  1962/ 2172] train: loss: 0.0015286
[Epoch 20; Iter  1992/ 2172] train: loss: 0.0862998
[Epoch 20; Iter  2022/ 2172] train: loss: 0.0012139
[Epoch 20; Iter  2052/ 2172] train: loss: 0.0016692
[Epoch 20; Iter  2082/ 2172] train: loss: 0.0694984
[Epoch 20; Iter  2112/ 2172] train: loss: 0.0014997
[Epoch 20; Iter  2142/ 2172] train: loss: 0.0026583
[Epoch 20; Iter  2172/ 2172] train: loss: 0.0017245
[Epoch 20] ogbg-molmuv: 0.059062 val loss: 0.013586
[Epoch 20] ogbg-molmuv: 0.120421 test loss: 0.019359
[Epoch 21; Iter    30/ 2172] train: loss: 0.0015832
[Epoch 21; Iter    60/ 2172] train: loss: 0.0019067
[Epoch 21; Iter    90/ 2172] train: loss: 0.0018760
[Epoch 21; Iter   120/ 2172] train: loss: 0.0041361
[Epoch 21; Iter   150/ 2172] train: loss: 0.0014144
[Epoch 21; Iter   180/ 2172] train: loss: 0.0019281
[Epoch 21; Iter   210/ 2172] train: loss: 0.0012394
[Epoch 21; Iter   240/ 2172] train: loss: 0.0014892
[Epoch 21; Iter   270/ 2172] train: loss: 0.0009532
[Epoch 21; Iter   300/ 2172] train: loss: 0.0016035
[Epoch 21; Iter   330/ 2172] train: loss: 0.0035698
[Epoch 21; Iter   360/ 2172] train: loss: 0.0015257
[Epoch 21; Iter   390/ 2172] train: loss: 0.0025330
[Epoch 21; Iter   420/ 2172] train: loss: 0.0888942
[Epoch 21; Iter   450/ 2172] train: loss: 0.0015660
[Epoch 21; Iter   480/ 2172] train: loss: 0.0018957
[Epoch 21; Iter   510/ 2172] train: loss: 0.0015703
[Epoch 21; Iter   540/ 2172] train: loss: 0.0043249
[Epoch 21; Iter   570/ 2172] train: loss: 0.0016684
[Epoch 21; Iter   600/ 2172] train: loss: 0.0014100
[Epoch 21; Iter   630/ 2172] train: loss: 0.0009927
[Epoch 21; Iter   660/ 2172] train: loss: 0.0010327
[Epoch 21; Iter   690/ 2172] train: loss: 0.0016583
[Epoch 21; Iter   720/ 2172] train: loss: 0.0017953
[Epoch 21; Iter   750/ 2172] train: loss: 0.0015245
[Epoch 21; Iter   780/ 2172] train: loss: 0.0013960
[Epoch 21; Iter   810/ 2172] train: loss: 0.0011529
[Epoch 21; Iter   840/ 2172] train: loss: 0.0020434
[Epoch 21; Iter   870/ 2172] train: loss: 0.0049423
[Epoch 21; Iter   900/ 2172] train: loss: 0.0019130
[Epoch 21; Iter   930/ 2172] train: loss: 0.0017447
[Epoch 21; Iter   960/ 2172] train: loss: 0.0010015
[Epoch 21; Iter   990/ 2172] train: loss: 0.0012419
[Epoch 21; Iter  1020/ 2172] train: loss: 0.0009332
[Epoch 21; Iter  1050/ 2172] train: loss: 0.0024689
[Epoch 21; Iter  1080/ 2172] train: loss: 0.0025520
[Epoch 21; Iter  1110/ 2172] train: loss: 0.0013639
[Epoch 21; Iter  1140/ 2172] train: loss: 0.0032415
[Epoch 21; Iter  1170/ 2172] train: loss: 0.0229855
[Epoch 21; Iter  1200/ 2172] train: loss: 0.0013771
[Epoch 21; Iter  1230/ 2172] train: loss: 0.0012223
[Epoch 21; Iter  1260/ 2172] train: loss: 0.0035576
[Epoch 21; Iter  1290/ 2172] train: loss: 0.1280022
[Epoch 21; Iter  1320/ 2172] train: loss: 0.0028599
[Epoch 21; Iter  1350/ 2172] train: loss: 0.0011866
[Epoch 19; Iter   276/ 2483] train: loss: 0.0011924
[Epoch 19; Iter   306/ 2483] train: loss: 0.0018144
[Epoch 19; Iter   336/ 2483] train: loss: 0.0027990
[Epoch 19; Iter   366/ 2483] train: loss: 0.0014502
[Epoch 19; Iter   396/ 2483] train: loss: 0.0013969
[Epoch 19; Iter   426/ 2483] train: loss: 0.0780346
[Epoch 19; Iter   456/ 2483] train: loss: 0.1017548
[Epoch 19; Iter   486/ 2483] train: loss: 0.0016327
[Epoch 19; Iter   516/ 2483] train: loss: 0.0022879
[Epoch 19; Iter   546/ 2483] train: loss: 0.0016303
[Epoch 19; Iter   576/ 2483] train: loss: 0.0013298
[Epoch 19; Iter   606/ 2483] train: loss: 0.0015842
[Epoch 19; Iter   636/ 2483] train: loss: 0.0022409
[Epoch 19; Iter   666/ 2483] train: loss: 0.0519784
[Epoch 19; Iter   696/ 2483] train: loss: 0.0020884
[Epoch 19; Iter   726/ 2483] train: loss: 0.0021921
[Epoch 19; Iter   756/ 2483] train: loss: 0.0019256
[Epoch 19; Iter   786/ 2483] train: loss: 0.0027779
[Epoch 19; Iter   816/ 2483] train: loss: 0.0011459
[Epoch 19; Iter   846/ 2483] train: loss: 0.0015042
[Epoch 19; Iter   876/ 2483] train: loss: 0.0016484
[Epoch 19; Iter   906/ 2483] train: loss: 0.0013841
[Epoch 19; Iter   936/ 2483] train: loss: 0.0019571
[Epoch 19; Iter   966/ 2483] train: loss: 0.0340268
[Epoch 19; Iter   996/ 2483] train: loss: 0.0021195
[Epoch 19; Iter  1026/ 2483] train: loss: 0.0019739
[Epoch 19; Iter  1056/ 2483] train: loss: 0.0023784
[Epoch 19; Iter  1086/ 2483] train: loss: 0.0188514
[Epoch 19; Iter  1116/ 2483] train: loss: 0.0019384
[Epoch 19; Iter  1146/ 2483] train: loss: 0.0023941
[Epoch 19; Iter  1176/ 2483] train: loss: 0.0020999
[Epoch 19; Iter  1206/ 2483] train: loss: 0.0016995
[Epoch 19; Iter  1236/ 2483] train: loss: 0.0020280
[Epoch 19; Iter  1266/ 2483] train: loss: 0.0014015
[Epoch 19; Iter  1296/ 2483] train: loss: 0.0017470
[Epoch 19; Iter  1326/ 2483] train: loss: 0.0014814
[Epoch 19; Iter  1356/ 2483] train: loss: 0.0898268
[Epoch 19; Iter  1386/ 2483] train: loss: 0.0023009
[Epoch 19; Iter  1416/ 2483] train: loss: 0.0047455
[Epoch 19; Iter  1446/ 2483] train: loss: 0.0663249
[Epoch 19; Iter  1476/ 2483] train: loss: 0.0900198
[Epoch 19; Iter  1506/ 2483] train: loss: 0.0017705
[Epoch 19; Iter  1536/ 2483] train: loss: 0.0026751
[Epoch 19; Iter  1566/ 2483] train: loss: 0.0033210
[Epoch 19; Iter  1596/ 2483] train: loss: 0.0016822
[Epoch 19; Iter  1626/ 2483] train: loss: 0.0552575
[Epoch 19; Iter  1656/ 2483] train: loss: 0.0016831
[Epoch 19; Iter  1686/ 2483] train: loss: 0.0014167
[Epoch 19; Iter  1716/ 2483] train: loss: 0.0663961
[Epoch 19; Iter  1746/ 2483] train: loss: 0.0013941
[Epoch 19; Iter  1776/ 2483] train: loss: 0.0013200
[Epoch 19; Iter  1806/ 2483] train: loss: 0.0015474
[Epoch 19; Iter  1836/ 2483] train: loss: 0.1382629
[Epoch 19; Iter  1866/ 2483] train: loss: 0.0351546
[Epoch 19; Iter  1896/ 2483] train: loss: 0.0023760
[Epoch 19; Iter  1926/ 2483] train: loss: 0.0016889
[Epoch 19; Iter  1956/ 2483] train: loss: 0.0014012
[Epoch 19; Iter  1986/ 2483] train: loss: 0.1112090
[Epoch 19; Iter  2016/ 2483] train: loss: 0.0019089
[Epoch 19; Iter  2046/ 2483] train: loss: 0.0031641
[Epoch 19; Iter  2076/ 2483] train: loss: 0.0017584
[Epoch 19; Iter  2106/ 2483] train: loss: 0.0011923
[Epoch 19; Iter  2136/ 2483] train: loss: 0.0015467
[Epoch 19; Iter  2166/ 2483] train: loss: 0.0425896
[Epoch 19; Iter  2196/ 2483] train: loss: 0.0019566
[Epoch 19; Iter  2226/ 2483] train: loss: 0.0639503
[Epoch 19; Iter  2256/ 2483] train: loss: 0.0028943
[Epoch 19; Iter  2286/ 2483] train: loss: 0.0018264
[Epoch 19; Iter  2316/ 2483] train: loss: 0.0016183
[Epoch 19; Iter  2346/ 2483] train: loss: 0.1081264
[Epoch 19; Iter  2376/ 2483] train: loss: 0.0015847
[Epoch 19; Iter  2406/ 2483] train: loss: 0.0014891
[Epoch 19; Iter  2436/ 2483] train: loss: 0.0014573
[Epoch 19; Iter  2466/ 2483] train: loss: 0.0016965
[Epoch 19] ogbg-molmuv: 0.132435 val loss: 0.010041
[Epoch 19] ogbg-molmuv: 0.132885 test loss: 0.013804
[Epoch 20; Iter    13/ 2483] train: loss: 0.0015525
[Epoch 20; Iter    43/ 2483] train: loss: 0.0027070
[Epoch 20; Iter    73/ 2483] train: loss: 0.0022430
[Epoch 20; Iter   103/ 2483] train: loss: 0.0017220
[Epoch 20; Iter   133/ 2483] train: loss: 0.0790986
[Epoch 20; Iter   163/ 2483] train: loss: 0.0017566
[Epoch 20; Iter   193/ 2483] train: loss: 0.0018948
[Epoch 20; Iter   223/ 2483] train: loss: 0.0021867
[Epoch 20; Iter   253/ 2483] train: loss: 0.0025792
[Epoch 20; Iter   283/ 2483] train: loss: 0.0027870
[Epoch 20; Iter   313/ 2483] train: loss: 0.0020842
[Epoch 20; Iter   343/ 2483] train: loss: 0.0037774
[Epoch 20; Iter   373/ 2483] train: loss: 0.0023400
[Epoch 20; Iter   403/ 2483] train: loss: 0.0009821
[Epoch 20; Iter   433/ 2483] train: loss: 0.0967231
[Epoch 20; Iter   463/ 2483] train: loss: 0.0878183
[Epoch 20; Iter   493/ 2483] train: loss: 0.0014499
[Epoch 20; Iter   523/ 2483] train: loss: 0.0021296
[Epoch 20; Iter   553/ 2483] train: loss: 0.0026616
[Epoch 20; Iter   583/ 2483] train: loss: 0.0043035
[Epoch 20; Iter   613/ 2483] train: loss: 0.0026582
[Epoch 20; Iter   643/ 2483] train: loss: 0.0022932
[Epoch 20; Iter   673/ 2483] train: loss: 0.0011962
[Epoch 20; Iter   703/ 2483] train: loss: 0.0029766
[Epoch 20; Iter   733/ 2483] train: loss: 0.0012785
[Epoch 20; Iter   763/ 2483] train: loss: 0.0020152
[Epoch 20; Iter   793/ 2483] train: loss: 0.0013151
[Epoch 20; Iter   823/ 2483] train: loss: 0.0014520
[Epoch 20; Iter   853/ 2483] train: loss: 0.0017916
[Epoch 20; Iter   883/ 2483] train: loss: 0.0014875
[Epoch 20; Iter   913/ 2483] train: loss: 0.0015153
[Epoch 20; Iter   943/ 2483] train: loss: 0.0013079
[Epoch 20; Iter   973/ 2483] train: loss: 0.0012080
[Epoch 20; Iter  1003/ 2483] train: loss: 0.0767568
[Epoch 20; Iter  1033/ 2483] train: loss: 0.0015454
[Epoch 20; Iter  1063/ 2483] train: loss: 0.0015455
[Epoch 20; Iter  1093/ 2483] train: loss: 0.0322357
[Epoch 20; Iter  1123/ 2483] train: loss: 0.0023238
[Epoch 20; Iter  1153/ 2483] train: loss: 0.0026868
[Epoch 20; Iter  1183/ 2483] train: loss: 0.0018976
[Epoch 20; Iter  1213/ 2483] train: loss: 0.0016564
[Epoch 20; Iter  1243/ 2483] train: loss: 0.0011716
[Epoch 20; Iter  1273/ 2483] train: loss: 0.0958226
[Epoch 20; Iter  1303/ 2483] train: loss: 0.0011170
[Epoch 20; Iter  1333/ 2483] train: loss: 0.0017993
[Epoch 20; Iter  1363/ 2483] train: loss: 0.0978498
[Epoch 20; Iter  1393/ 2483] train: loss: 0.0917527
[Epoch 20; Iter  1423/ 2483] train: loss: 0.0235928
[Epoch 20; Iter  1453/ 2483] train: loss: 0.0041953
[Epoch 20; Iter  1483/ 2483] train: loss: 0.0017360
[Epoch 20; Iter  1513/ 2483] train: loss: 0.0021620
[Epoch 20; Iter  1543/ 2483] train: loss: 0.0016199
[Epoch 20; Iter  1573/ 2483] train: loss: 0.0036873
[Epoch 20; Iter  1603/ 2483] train: loss: 0.0894084
[Epoch 20; Iter  1633/ 2483] train: loss: 0.0013046
[Epoch 20; Iter  1663/ 2483] train: loss: 0.0013636
[Epoch 20; Iter  1693/ 2483] train: loss: 0.0019712
[Epoch 20; Iter  1723/ 2483] train: loss: 0.0015311
[Epoch 20; Iter  1753/ 2483] train: loss: 0.0011238
[Epoch 20; Iter  1783/ 2483] train: loss: 0.0011682
[Epoch 20; Iter  1813/ 2483] train: loss: 0.0017133
[Epoch 20; Iter  1843/ 2483] train: loss: 0.1086490
[Epoch 20; Iter  1873/ 2483] train: loss: 0.0017055
[Epoch 20; Iter  1903/ 2483] train: loss: 0.0012905
[Epoch 20; Iter  1933/ 2483] train: loss: 0.0039698
[Epoch 20; Iter  1963/ 2483] train: loss: 0.0017297
[Epoch 20; Iter  1993/ 2483] train: loss: 0.0011173
[Epoch 20; Iter  2023/ 2483] train: loss: 0.0009253
[Epoch 20; Iter  2053/ 2483] train: loss: 0.0018155
[Epoch 20; Iter  2083/ 2483] train: loss: 0.0538741
[Epoch 20; Iter  2113/ 2483] train: loss: 0.0010504
[Epoch 20; Iter  2143/ 2483] train: loss: 0.0010490
[Epoch 20; Iter  2173/ 2483] train: loss: 0.1161937
[Epoch 20; Iter  2203/ 2483] train: loss: 0.0021285
[Epoch 20; Iter  2233/ 2483] train: loss: 0.0014337
[Epoch 20; Iter  2263/ 2483] train: loss: 0.0909487
[Epoch 20; Iter  2293/ 2483] train: loss: 0.0024113
[Epoch 20; Iter  2323/ 2483] train: loss: 0.0025057
[Epoch 20; Iter  2353/ 2483] train: loss: 0.0019751
[Epoch 20; Iter  2383/ 2483] train: loss: 0.0015477
[Epoch 20; Iter  2413/ 2483] train: loss: 0.0015685
[Epoch 19; Iter  1134/ 2172] train: loss: 0.0014648
[Epoch 19; Iter  1164/ 2172] train: loss: 0.0016688
[Epoch 19; Iter  1194/ 2172] train: loss: 0.0008795
[Epoch 19; Iter  1224/ 2172] train: loss: 0.0010563
[Epoch 19; Iter  1254/ 2172] train: loss: 0.0010093
[Epoch 19; Iter  1284/ 2172] train: loss: 0.0011395
[Epoch 19; Iter  1314/ 2172] train: loss: 0.0010753
[Epoch 19; Iter  1344/ 2172] train: loss: 0.0017070
[Epoch 19; Iter  1374/ 2172] train: loss: 0.0023445
[Epoch 19; Iter  1404/ 2172] train: loss: 0.0027701
[Epoch 19; Iter  1434/ 2172] train: loss: 0.0019317
[Epoch 19; Iter  1464/ 2172] train: loss: 0.0015206
[Epoch 19; Iter  1494/ 2172] train: loss: 0.0018871
[Epoch 19; Iter  1524/ 2172] train: loss: 0.0019286
[Epoch 19; Iter  1554/ 2172] train: loss: 0.0022646
[Epoch 19; Iter  1584/ 2172] train: loss: 0.0010098
[Epoch 19; Iter  1614/ 2172] train: loss: 0.0018190
[Epoch 19; Iter  1644/ 2172] train: loss: 0.0015802
[Epoch 19; Iter  1674/ 2172] train: loss: 0.0017119
[Epoch 19; Iter  1704/ 2172] train: loss: 0.0015722
[Epoch 19; Iter  1734/ 2172] train: loss: 0.0015502
[Epoch 19; Iter  1764/ 2172] train: loss: 0.0008874
[Epoch 19; Iter  1794/ 2172] train: loss: 0.0024340
[Epoch 19; Iter  1824/ 2172] train: loss: 0.0014927
[Epoch 19; Iter  1854/ 2172] train: loss: 0.0443182
[Epoch 19; Iter  1884/ 2172] train: loss: 0.0016642
[Epoch 19; Iter  1914/ 2172] train: loss: 0.0008460
[Epoch 19; Iter  1944/ 2172] train: loss: 0.0017288
[Epoch 19; Iter  1974/ 2172] train: loss: 0.0016775
[Epoch 19; Iter  2004/ 2172] train: loss: 0.0490057
[Epoch 19; Iter  2034/ 2172] train: loss: 0.0017098
[Epoch 19; Iter  2064/ 2172] train: loss: 0.0013504
[Epoch 19; Iter  2094/ 2172] train: loss: 0.0014781
[Epoch 19; Iter  2124/ 2172] train: loss: 0.0666430
[Epoch 19; Iter  2154/ 2172] train: loss: 0.0015008
[Epoch 19] ogbg-molmuv: 0.050650 val loss: 0.011757
[Epoch 19] ogbg-molmuv: 0.110161 test loss: 0.012543
[Epoch 20; Iter    12/ 2172] train: loss: 0.0010338
[Epoch 20; Iter    42/ 2172] train: loss: 0.0018522
[Epoch 20; Iter    72/ 2172] train: loss: 0.0027935
[Epoch 20; Iter   102/ 2172] train: loss: 0.0023969
[Epoch 20; Iter   132/ 2172] train: loss: 0.0014838
[Epoch 20; Iter   162/ 2172] train: loss: 0.0027734
[Epoch 20; Iter   192/ 2172] train: loss: 0.0017926
[Epoch 20; Iter   222/ 2172] train: loss: 0.0012250
[Epoch 20; Iter   252/ 2172] train: loss: 0.0012733
[Epoch 20; Iter   282/ 2172] train: loss: 0.0014931
[Epoch 20; Iter   312/ 2172] train: loss: 0.0013417
[Epoch 20; Iter   342/ 2172] train: loss: 0.0018507
[Epoch 20; Iter   372/ 2172] train: loss: 0.0018248
[Epoch 20; Iter   402/ 2172] train: loss: 0.0015755
[Epoch 20; Iter   432/ 2172] train: loss: 0.0018194
[Epoch 20; Iter   462/ 2172] train: loss: 0.0015403
[Epoch 20; Iter   492/ 2172] train: loss: 0.0024988
[Epoch 20; Iter   522/ 2172] train: loss: 0.0018771
[Epoch 20; Iter   552/ 2172] train: loss: 0.0015501
[Epoch 20; Iter   582/ 2172] train: loss: 0.0015493
[Epoch 20; Iter   612/ 2172] train: loss: 0.0016907
[Epoch 20; Iter   642/ 2172] train: loss: 0.0010369
[Epoch 20; Iter   672/ 2172] train: loss: 0.0022678
[Epoch 20; Iter   702/ 2172] train: loss: 0.0014946
[Epoch 20; Iter   732/ 2172] train: loss: 0.0322591
[Epoch 20; Iter   762/ 2172] train: loss: 0.0021320
[Epoch 20; Iter   792/ 2172] train: loss: 0.0021022
[Epoch 20; Iter   822/ 2172] train: loss: 0.0019073
[Epoch 20; Iter   852/ 2172] train: loss: 0.0010741
[Epoch 20; Iter   882/ 2172] train: loss: 0.0026232
[Epoch 20; Iter   912/ 2172] train: loss: 0.0012259
[Epoch 20; Iter   942/ 2172] train: loss: 0.0549080
[Epoch 20; Iter   972/ 2172] train: loss: 0.0706186
[Epoch 20; Iter  1002/ 2172] train: loss: 0.0025397
[Epoch 20; Iter  1032/ 2172] train: loss: 0.0019123
[Epoch 20; Iter  1062/ 2172] train: loss: 0.0024674
[Epoch 20; Iter  1092/ 2172] train: loss: 0.0011389
[Epoch 20; Iter  1122/ 2172] train: loss: 0.0020294
[Epoch 20; Iter  1152/ 2172] train: loss: 0.0012544
[Epoch 20; Iter  1182/ 2172] train: loss: 0.0016488
[Epoch 20; Iter  1212/ 2172] train: loss: 0.0017247
[Epoch 20; Iter  1242/ 2172] train: loss: 0.0023809
[Epoch 20; Iter  1272/ 2172] train: loss: 0.0020800
[Epoch 20; Iter  1302/ 2172] train: loss: 0.0011739
[Epoch 20; Iter  1332/ 2172] train: loss: 0.0018603
[Epoch 20; Iter  1362/ 2172] train: loss: 0.0023171
[Epoch 20; Iter  1392/ 2172] train: loss: 0.0019859
[Epoch 20; Iter  1422/ 2172] train: loss: 0.0033096
[Epoch 20; Iter  1452/ 2172] train: loss: 0.0021360
[Epoch 20; Iter  1482/ 2172] train: loss: 0.0018994
[Epoch 20; Iter  1512/ 2172] train: loss: 0.0012498
[Epoch 20; Iter  1542/ 2172] train: loss: 0.0508441
[Epoch 20; Iter  1572/ 2172] train: loss: 0.0016494
[Epoch 20; Iter  1602/ 2172] train: loss: 0.0022496
[Epoch 20; Iter  1632/ 2172] train: loss: 0.0023185
[Epoch 20; Iter  1662/ 2172] train: loss: 0.0024913
[Epoch 20; Iter  1692/ 2172] train: loss: 0.0022668
[Epoch 20; Iter  1722/ 2172] train: loss: 0.0007450
[Epoch 20; Iter  1752/ 2172] train: loss: 0.0020523
[Epoch 20; Iter  1782/ 2172] train: loss: 0.0014794
[Epoch 20; Iter  1812/ 2172] train: loss: 0.0018721
[Epoch 20; Iter  1842/ 2172] train: loss: 0.0013832
[Epoch 20; Iter  1872/ 2172] train: loss: 0.0078130
[Epoch 20; Iter  1902/ 2172] train: loss: 0.0018388
[Epoch 20; Iter  1932/ 2172] train: loss: 0.0016886
[Epoch 20; Iter  1962/ 2172] train: loss: 0.0011242
[Epoch 20; Iter  1992/ 2172] train: loss: 0.0021231
[Epoch 20; Iter  2022/ 2172] train: loss: 0.0012681
[Epoch 20; Iter  2052/ 2172] train: loss: 0.0016209
[Epoch 20; Iter  2082/ 2172] train: loss: 0.1397121
[Epoch 20; Iter  2112/ 2172] train: loss: 0.0723470
[Epoch 20; Iter  2142/ 2172] train: loss: 0.0039915
[Epoch 20; Iter  2172/ 2172] train: loss: 0.0014232
[Epoch 20] ogbg-molmuv: 0.046532 val loss: 0.012315
[Epoch 20] ogbg-molmuv: 0.086206 test loss: 0.024583
[Epoch 21; Iter    30/ 2172] train: loss: 0.0019049
[Epoch 21; Iter    60/ 2172] train: loss: 0.0740520
[Epoch 21; Iter    90/ 2172] train: loss: 0.0011519
[Epoch 21; Iter   120/ 2172] train: loss: 0.0014081
[Epoch 21; Iter   150/ 2172] train: loss: 0.0036786
[Epoch 21; Iter   180/ 2172] train: loss: 0.0011429
[Epoch 21; Iter   210/ 2172] train: loss: 0.0011647
[Epoch 21; Iter   240/ 2172] train: loss: 0.0451731
[Epoch 21; Iter   270/ 2172] train: loss: 0.0020913
[Epoch 21; Iter   300/ 2172] train: loss: 0.0016310
[Epoch 21; Iter   330/ 2172] train: loss: 0.0025376
[Epoch 21; Iter   360/ 2172] train: loss: 0.0012058
[Epoch 21; Iter   390/ 2172] train: loss: 0.0023411
[Epoch 21; Iter   420/ 2172] train: loss: 0.0014964
[Epoch 21; Iter   450/ 2172] train: loss: 0.0012211
[Epoch 21; Iter   480/ 2172] train: loss: 0.0014546
[Epoch 21; Iter   510/ 2172] train: loss: 0.0016714
[Epoch 21; Iter   540/ 2172] train: loss: 0.0014291
[Epoch 21; Iter   570/ 2172] train: loss: 0.0952059
[Epoch 21; Iter   600/ 2172] train: loss: 0.0011341
[Epoch 21; Iter   630/ 2172] train: loss: 0.0017101
[Epoch 21; Iter   660/ 2172] train: loss: 0.0009650
[Epoch 21; Iter   690/ 2172] train: loss: 0.0015916
[Epoch 21; Iter   720/ 2172] train: loss: 0.0686440
[Epoch 21; Iter   750/ 2172] train: loss: 0.0011336
[Epoch 21; Iter   780/ 2172] train: loss: 0.0018816
[Epoch 21; Iter   810/ 2172] train: loss: 0.0017153
[Epoch 21; Iter   840/ 2172] train: loss: 0.0026557
[Epoch 21; Iter   870/ 2172] train: loss: 0.0022691
[Epoch 21; Iter   900/ 2172] train: loss: 0.0029544
[Epoch 21; Iter   930/ 2172] train: loss: 0.0024452
[Epoch 21; Iter   960/ 2172] train: loss: 0.0459875
[Epoch 21; Iter   990/ 2172] train: loss: 0.0011628
[Epoch 21; Iter  1020/ 2172] train: loss: 0.0033652
[Epoch 21; Iter  1050/ 2172] train: loss: 0.0017335
[Epoch 21; Iter  1080/ 2172] train: loss: 0.0012235
[Epoch 21; Iter  1110/ 2172] train: loss: 0.0794538
[Epoch 21; Iter  1140/ 2172] train: loss: 0.0017039
[Epoch 21; Iter  1170/ 2172] train: loss: 0.0020125
[Epoch 21; Iter  1200/ 2172] train: loss: 0.0043650
[Epoch 21; Iter  1230/ 2172] train: loss: 0.0013292
[Epoch 21; Iter  1260/ 2172] train: loss: 0.0029289
[Epoch 21; Iter  1290/ 2172] train: loss: 0.0018695
[Epoch 21; Iter  1320/ 2172] train: loss: 0.0015859
[Epoch 21; Iter  1350/ 2172] train: loss: 0.0013654
[Epoch 19; Iter  1134/ 2172] train: loss: 0.0009499
[Epoch 19; Iter  1164/ 2172] train: loss: 0.0012005
[Epoch 19; Iter  1194/ 2172] train: loss: 0.0027041
[Epoch 19; Iter  1224/ 2172] train: loss: 0.0010579
[Epoch 19; Iter  1254/ 2172] train: loss: 0.0013541
[Epoch 19; Iter  1284/ 2172] train: loss: 0.0726355
[Epoch 19; Iter  1314/ 2172] train: loss: 0.0041943
[Epoch 19; Iter  1344/ 2172] train: loss: 0.0096711
[Epoch 19; Iter  1374/ 2172] train: loss: 0.0014563
[Epoch 19; Iter  1404/ 2172] train: loss: 0.0017316
[Epoch 19; Iter  1434/ 2172] train: loss: 0.0016822
[Epoch 19; Iter  1464/ 2172] train: loss: 0.0023609
[Epoch 19; Iter  1494/ 2172] train: loss: 0.0020183
[Epoch 19; Iter  1524/ 2172] train: loss: 0.0014271
[Epoch 19; Iter  1554/ 2172] train: loss: 0.1888537
[Epoch 19; Iter  1584/ 2172] train: loss: 0.0015058
[Epoch 19; Iter  1614/ 2172] train: loss: 0.0016239
[Epoch 19; Iter  1644/ 2172] train: loss: 0.0015791
[Epoch 19; Iter  1674/ 2172] train: loss: 0.0009143
[Epoch 19; Iter  1704/ 2172] train: loss: 0.0017526
[Epoch 19; Iter  1734/ 2172] train: loss: 0.0018066
[Epoch 19; Iter  1764/ 2172] train: loss: 0.0664673
[Epoch 19; Iter  1794/ 2172] train: loss: 0.0607387
[Epoch 19; Iter  1824/ 2172] train: loss: 0.0017326
[Epoch 19; Iter  1854/ 2172] train: loss: 0.0024417
[Epoch 19; Iter  1884/ 2172] train: loss: 0.0016471
[Epoch 19; Iter  1914/ 2172] train: loss: 0.0025737
[Epoch 19; Iter  1944/ 2172] train: loss: 0.0020264
[Epoch 19; Iter  1974/ 2172] train: loss: 0.0012954
[Epoch 19; Iter  2004/ 2172] train: loss: 0.0017409
[Epoch 19; Iter  2034/ 2172] train: loss: 0.0010838
[Epoch 19; Iter  2064/ 2172] train: loss: 0.0016932
[Epoch 19; Iter  2094/ 2172] train: loss: 0.0015551
[Epoch 19; Iter  2124/ 2172] train: loss: 0.0019514
[Epoch 19; Iter  2154/ 2172] train: loss: 0.0604463
[Epoch 19] ogbg-molmuv: 0.050126 val loss: 0.012130
[Epoch 19] ogbg-molmuv: 0.048192 test loss: 0.014656
[Epoch 20; Iter    12/ 2172] train: loss: 0.0042762
[Epoch 20; Iter    42/ 2172] train: loss: 0.0022310
[Epoch 20; Iter    72/ 2172] train: loss: 0.0022637
[Epoch 20; Iter   102/ 2172] train: loss: 0.0019067
[Epoch 20; Iter   132/ 2172] train: loss: 0.0735634
[Epoch 20; Iter   162/ 2172] train: loss: 0.0020063
[Epoch 20; Iter   192/ 2172] train: loss: 0.0017794
[Epoch 20; Iter   222/ 2172] train: loss: 0.0021312
[Epoch 20; Iter   252/ 2172] train: loss: 0.0017557
[Epoch 20; Iter   282/ 2172] train: loss: 0.0016975
[Epoch 20; Iter   312/ 2172] train: loss: 0.0753722
[Epoch 20; Iter   342/ 2172] train: loss: 0.0013032
[Epoch 20; Iter   372/ 2172] train: loss: 0.0014446
[Epoch 20; Iter   402/ 2172] train: loss: 0.0531966
[Epoch 20; Iter   432/ 2172] train: loss: 0.0012397
[Epoch 20; Iter   462/ 2172] train: loss: 0.0010550
[Epoch 20; Iter   492/ 2172] train: loss: 0.0804093
[Epoch 20; Iter   522/ 2172] train: loss: 0.0018600
[Epoch 20; Iter   552/ 2172] train: loss: 0.0011936
[Epoch 20; Iter   582/ 2172] train: loss: 0.0017078
[Epoch 20; Iter   612/ 2172] train: loss: 0.0027181
[Epoch 20; Iter   642/ 2172] train: loss: 0.0024165
[Epoch 20; Iter   672/ 2172] train: loss: 0.0014204
[Epoch 20; Iter   702/ 2172] train: loss: 0.0017774
[Epoch 20; Iter   732/ 2172] train: loss: 0.0023399
[Epoch 20; Iter   762/ 2172] train: loss: 0.0932758
[Epoch 20; Iter   792/ 2172] train: loss: 0.0018586
[Epoch 20; Iter   822/ 2172] train: loss: 0.0028855
[Epoch 20; Iter   852/ 2172] train: loss: 0.0027923
[Epoch 20; Iter   882/ 2172] train: loss: 0.0986248
[Epoch 20; Iter   912/ 2172] train: loss: 0.0706437
[Epoch 20; Iter   942/ 2172] train: loss: 0.0023660
[Epoch 20; Iter   972/ 2172] train: loss: 0.0030349
[Epoch 20; Iter  1002/ 2172] train: loss: 0.0014129
[Epoch 20; Iter  1032/ 2172] train: loss: 0.0016179
[Epoch 20; Iter  1062/ 2172] train: loss: 0.0015095
[Epoch 20; Iter  1092/ 2172] train: loss: 0.0021737
[Epoch 20; Iter  1122/ 2172] train: loss: 0.0021192
[Epoch 20; Iter  1152/ 2172] train: loss: 0.0777025
[Epoch 20; Iter  1182/ 2172] train: loss: 0.0016985
[Epoch 20; Iter  1212/ 2172] train: loss: 0.0015461
[Epoch 20; Iter  1242/ 2172] train: loss: 0.0016798
[Epoch 20; Iter  1272/ 2172] train: loss: 0.0652063
[Epoch 20; Iter  1302/ 2172] train: loss: 0.0014267
[Epoch 20; Iter  1332/ 2172] train: loss: 0.0029011
[Epoch 20; Iter  1362/ 2172] train: loss: 0.0044631
[Epoch 20; Iter  1392/ 2172] train: loss: 0.0018057
[Epoch 20; Iter  1422/ 2172] train: loss: 0.0041258
[Epoch 20; Iter  1452/ 2172] train: loss: 0.0059376
[Epoch 20; Iter  1482/ 2172] train: loss: 0.0017961
[Epoch 20; Iter  1512/ 2172] train: loss: 0.0028367
[Epoch 20; Iter  1542/ 2172] train: loss: 0.0013273
[Epoch 20; Iter  1572/ 2172] train: loss: 0.0015531
[Epoch 20; Iter  1602/ 2172] train: loss: 0.0019421
[Epoch 20; Iter  1632/ 2172] train: loss: 0.0021718
[Epoch 20; Iter  1662/ 2172] train: loss: 0.0819020
[Epoch 20; Iter  1692/ 2172] train: loss: 0.0015243
[Epoch 20; Iter  1722/ 2172] train: loss: 0.0020330
[Epoch 20; Iter  1752/ 2172] train: loss: 0.0020621
[Epoch 20; Iter  1782/ 2172] train: loss: 0.0016968
[Epoch 20; Iter  1812/ 2172] train: loss: 0.0019793
[Epoch 20; Iter  1842/ 2172] train: loss: 0.0019370
[Epoch 20; Iter  1872/ 2172] train: loss: 0.0455844
[Epoch 20; Iter  1902/ 2172] train: loss: 0.0018772
[Epoch 20; Iter  1932/ 2172] train: loss: 0.0014033
[Epoch 20; Iter  1962/ 2172] train: loss: 0.0010380
[Epoch 20; Iter  1992/ 2172] train: loss: 0.0015468
[Epoch 20; Iter  2022/ 2172] train: loss: 0.0015475
[Epoch 20; Iter  2052/ 2172] train: loss: 0.0714743
[Epoch 20; Iter  2082/ 2172] train: loss: 0.0025428
[Epoch 20; Iter  2112/ 2172] train: loss: 0.0011764
[Epoch 20; Iter  2142/ 2172] train: loss: 0.0018850
[Epoch 20; Iter  2172/ 2172] train: loss: 0.0014437
[Epoch 20] ogbg-molmuv: 0.051707 val loss: 0.023228
[Epoch 20] ogbg-molmuv: 0.067302 test loss: 0.015040
[Epoch 21; Iter    30/ 2172] train: loss: 0.0017546
[Epoch 21; Iter    60/ 2172] train: loss: 0.0013604
[Epoch 21; Iter    90/ 2172] train: loss: 0.0016578
[Epoch 21; Iter   120/ 2172] train: loss: 0.0643493
[Epoch 21; Iter   150/ 2172] train: loss: 0.0014310
[Epoch 21; Iter   180/ 2172] train: loss: 0.0022601
[Epoch 21; Iter   210/ 2172] train: loss: 0.0017196
[Epoch 21; Iter   240/ 2172] train: loss: 0.0112657
[Epoch 21; Iter   270/ 2172] train: loss: 0.0020494
[Epoch 21; Iter   300/ 2172] train: loss: 0.0018552
[Epoch 21; Iter   330/ 2172] train: loss: 0.0014996
[Epoch 21; Iter   360/ 2172] train: loss: 0.0017170
[Epoch 21; Iter   390/ 2172] train: loss: 0.0012201
[Epoch 21; Iter   420/ 2172] train: loss: 0.0026915
[Epoch 21; Iter   450/ 2172] train: loss: 0.0014525
[Epoch 21; Iter   480/ 2172] train: loss: 0.0014449
[Epoch 21; Iter   510/ 2172] train: loss: 0.0025462
[Epoch 21; Iter   540/ 2172] train: loss: 0.0041594
[Epoch 21; Iter   570/ 2172] train: loss: 0.0023155
[Epoch 21; Iter   600/ 2172] train: loss: 0.0013463
[Epoch 21; Iter   630/ 2172] train: loss: 0.0012553
[Epoch 21; Iter   660/ 2172] train: loss: 0.0014739
[Epoch 21; Iter   690/ 2172] train: loss: 0.0013570
[Epoch 21; Iter   720/ 2172] train: loss: 0.0017600
[Epoch 21; Iter   750/ 2172] train: loss: 0.0017285
[Epoch 21; Iter   780/ 2172] train: loss: 0.0016301
[Epoch 21; Iter   810/ 2172] train: loss: 0.0026770
[Epoch 21; Iter   840/ 2172] train: loss: 0.0014899
[Epoch 21; Iter   870/ 2172] train: loss: 0.0022270
[Epoch 21; Iter   900/ 2172] train: loss: 0.0010883
[Epoch 21; Iter   930/ 2172] train: loss: 0.0937858
[Epoch 21; Iter   960/ 2172] train: loss: 0.0017034
[Epoch 21; Iter   990/ 2172] train: loss: 0.0014617
[Epoch 21; Iter  1020/ 2172] train: loss: 0.0418277
[Epoch 21; Iter  1050/ 2172] train: loss: 0.0024753
[Epoch 21; Iter  1080/ 2172] train: loss: 0.0017404
[Epoch 21; Iter  1110/ 2172] train: loss: 0.0016702
[Epoch 21; Iter  1140/ 2172] train: loss: 0.0017267
[Epoch 21; Iter  1170/ 2172] train: loss: 0.0018250
[Epoch 21; Iter  1200/ 2172] train: loss: 0.0014145
[Epoch 21; Iter  1230/ 2172] train: loss: 0.0608314
[Epoch 21; Iter  1260/ 2172] train: loss: 0.0737708
[Epoch 21; Iter  1290/ 2172] train: loss: 0.0018091
[Epoch 21; Iter  1320/ 2172] train: loss: 0.0242033
[Epoch 21; Iter  1350/ 2172] train: loss: 0.0018493
[Epoch 20; Iter    22/ 1862] train: loss: 0.0016509
[Epoch 20; Iter    52/ 1862] train: loss: 0.0020191
[Epoch 20; Iter    82/ 1862] train: loss: 0.0028197
[Epoch 20; Iter   112/ 1862] train: loss: 0.0929750
[Epoch 20; Iter   142/ 1862] train: loss: 0.0030111
[Epoch 20; Iter   172/ 1862] train: loss: 0.0017562
[Epoch 20; Iter   202/ 1862] train: loss: 0.0018004
[Epoch 20; Iter   232/ 1862] train: loss: 0.0045645
[Epoch 20; Iter   262/ 1862] train: loss: 0.0012160
[Epoch 20; Iter   292/ 1862] train: loss: 0.0025620
[Epoch 20; Iter   322/ 1862] train: loss: 0.0014849
[Epoch 20; Iter   352/ 1862] train: loss: 0.0018153
[Epoch 20; Iter   382/ 1862] train: loss: 0.0022752
[Epoch 20; Iter   412/ 1862] train: loss: 0.0017464
[Epoch 20; Iter   442/ 1862] train: loss: 0.0011111
[Epoch 20; Iter   472/ 1862] train: loss: 0.0016671
[Epoch 20; Iter   502/ 1862] train: loss: 0.0316226
[Epoch 20; Iter   532/ 1862] train: loss: 0.0020866
[Epoch 20; Iter   562/ 1862] train: loss: 0.0026736
[Epoch 20; Iter   592/ 1862] train: loss: 0.0017330
[Epoch 20; Iter   622/ 1862] train: loss: 0.0016917
[Epoch 20; Iter   652/ 1862] train: loss: 0.0624698
[Epoch 20; Iter   682/ 1862] train: loss: 0.0012881
[Epoch 20; Iter   712/ 1862] train: loss: 0.0016373
[Epoch 20; Iter   742/ 1862] train: loss: 0.0022162
[Epoch 20; Iter   772/ 1862] train: loss: 0.0014967
[Epoch 20; Iter   802/ 1862] train: loss: 0.0021934
[Epoch 20; Iter   832/ 1862] train: loss: 0.0031699
[Epoch 20; Iter   862/ 1862] train: loss: 0.0370744
[Epoch 20; Iter   892/ 1862] train: loss: 0.0021581
[Epoch 20; Iter   922/ 1862] train: loss: 0.0013583
[Epoch 20; Iter   952/ 1862] train: loss: 0.0015730
[Epoch 20; Iter   982/ 1862] train: loss: 0.0012341
[Epoch 20; Iter  1012/ 1862] train: loss: 0.0011239
[Epoch 20; Iter  1042/ 1862] train: loss: 0.0008762
[Epoch 20; Iter  1072/ 1862] train: loss: 0.0014124
[Epoch 20; Iter  1102/ 1862] train: loss: 0.0021278
[Epoch 20; Iter  1132/ 1862] train: loss: 0.0012093
[Epoch 20; Iter  1162/ 1862] train: loss: 0.0015308
[Epoch 20; Iter  1192/ 1862] train: loss: 0.0009224
[Epoch 20; Iter  1222/ 1862] train: loss: 0.0023557
[Epoch 20; Iter  1252/ 1862] train: loss: 0.0021434
[Epoch 20; Iter  1282/ 1862] train: loss: 0.0015010
[Epoch 20; Iter  1312/ 1862] train: loss: 0.0013455
[Epoch 20; Iter  1342/ 1862] train: loss: 0.0017886
[Epoch 20; Iter  1372/ 1862] train: loss: 0.0017651
[Epoch 20; Iter  1402/ 1862] train: loss: 0.0015738
[Epoch 20; Iter  1432/ 1862] train: loss: 0.0027496
[Epoch 20; Iter  1462/ 1862] train: loss: 0.0020330
[Epoch 20; Iter  1492/ 1862] train: loss: 0.0017985
[Epoch 20; Iter  1522/ 1862] train: loss: 0.0015305
[Epoch 20; Iter  1552/ 1862] train: loss: 0.0022603
[Epoch 20; Iter  1582/ 1862] train: loss: 0.0015811
[Epoch 20; Iter  1612/ 1862] train: loss: 0.0019957
[Epoch 20; Iter  1642/ 1862] train: loss: 0.0017285
[Epoch 20; Iter  1672/ 1862] train: loss: 0.0011187
[Epoch 20; Iter  1702/ 1862] train: loss: 0.0015732
[Epoch 20; Iter  1732/ 1862] train: loss: 0.0011985
[Epoch 20; Iter  1762/ 1862] train: loss: 0.0024749
[Epoch 20; Iter  1792/ 1862] train: loss: 0.0013042
[Epoch 20; Iter  1822/ 1862] train: loss: 0.0014026
[Epoch 20; Iter  1852/ 1862] train: loss: 0.0017000
[Epoch 20] ogbg-molmuv: 0.022343 val loss: 0.013506
[Epoch 20] ogbg-molmuv: 0.038827 test loss: 0.012109
[Epoch 21; Iter    20/ 1862] train: loss: 0.0009713
[Epoch 21; Iter    50/ 1862] train: loss: 0.0019267
[Epoch 21; Iter    80/ 1862] train: loss: 0.0015352
[Epoch 21; Iter   110/ 1862] train: loss: 0.0021028
[Epoch 21; Iter   140/ 1862] train: loss: 0.0020121
[Epoch 21; Iter   170/ 1862] train: loss: 0.0021360
[Epoch 21; Iter   200/ 1862] train: loss: 0.0578080
[Epoch 21; Iter   230/ 1862] train: loss: 0.0023147
[Epoch 21; Iter   260/ 1862] train: loss: 0.0023176
[Epoch 21; Iter   290/ 1862] train: loss: 0.0014823
[Epoch 21; Iter   320/ 1862] train: loss: 0.0017981
[Epoch 21; Iter   350/ 1862] train: loss: 0.0027897
[Epoch 21; Iter   380/ 1862] train: loss: 0.0031871
[Epoch 21; Iter   410/ 1862] train: loss: 0.0012575
[Epoch 21; Iter   440/ 1862] train: loss: 0.0107696
[Epoch 21; Iter   470/ 1862] train: loss: 0.0017163
[Epoch 21; Iter   500/ 1862] train: loss: 0.0014021
[Epoch 21; Iter   530/ 1862] train: loss: 0.0020432
[Epoch 21; Iter   560/ 1862] train: loss: 0.0325267
[Epoch 21; Iter   590/ 1862] train: loss: 0.0010052
[Epoch 21; Iter   620/ 1862] train: loss: 0.0017184
[Epoch 21; Iter   650/ 1862] train: loss: 0.0017292
[Epoch 21; Iter   680/ 1862] train: loss: 0.0021335
[Epoch 21; Iter   710/ 1862] train: loss: 0.0024103
[Epoch 21; Iter   740/ 1862] train: loss: 0.0054721
[Epoch 21; Iter   770/ 1862] train: loss: 0.0021045
[Epoch 21; Iter   800/ 1862] train: loss: 0.0022888
[Epoch 21; Iter   830/ 1862] train: loss: 0.0743168
[Epoch 21; Iter   860/ 1862] train: loss: 0.0009960
[Epoch 21; Iter   890/ 1862] train: loss: 0.0011187
[Epoch 21; Iter   920/ 1862] train: loss: 0.0014211
[Epoch 21; Iter   950/ 1862] train: loss: 0.0015098
[Epoch 21; Iter   980/ 1862] train: loss: 0.0062941
[Epoch 21; Iter  1010/ 1862] train: loss: 0.0019607
[Epoch 21; Iter  1040/ 1862] train: loss: 0.0013735
[Epoch 21; Iter  1070/ 1862] train: loss: 0.0012906
[Epoch 21; Iter  1100/ 1862] train: loss: 0.0012941
[Epoch 21; Iter  1130/ 1862] train: loss: 0.0047556
[Epoch 21; Iter  1160/ 1862] train: loss: 0.0773394
[Epoch 21; Iter  1190/ 1862] train: loss: 0.0008687
[Epoch 21; Iter  1220/ 1862] train: loss: 0.0013968
[Epoch 21; Iter  1250/ 1862] train: loss: 0.0009446
[Epoch 21; Iter  1280/ 1862] train: loss: 0.0013326
[Epoch 21; Iter  1310/ 1862] train: loss: 0.0014802
[Epoch 21; Iter  1340/ 1862] train: loss: 0.0015324
[Epoch 21; Iter  1370/ 1862] train: loss: 0.0012873
[Epoch 21; Iter  1400/ 1862] train: loss: 0.0015173
[Epoch 21; Iter  1430/ 1862] train: loss: 0.0029057
[Epoch 21; Iter  1460/ 1862] train: loss: 0.0868743
[Epoch 21; Iter  1490/ 1862] train: loss: 0.0017864
[Epoch 21; Iter  1520/ 1862] train: loss: 0.0024233
[Epoch 21; Iter  1550/ 1862] train: loss: 0.0022205
[Epoch 21; Iter  1580/ 1862] train: loss: 0.0015759
[Epoch 21; Iter  1610/ 1862] train: loss: 0.0014990
[Epoch 21; Iter  1640/ 1862] train: loss: 0.0686205
[Epoch 21; Iter  1670/ 1862] train: loss: 0.0016777
[Epoch 21; Iter  1700/ 1862] train: loss: 0.0011838
[Epoch 21; Iter  1730/ 1862] train: loss: 0.0015426
[Epoch 21; Iter  1760/ 1862] train: loss: 0.0017675
[Epoch 21; Iter  1790/ 1862] train: loss: 0.0012048
[Epoch 21; Iter  1820/ 1862] train: loss: 0.0016645
[Epoch 21; Iter  1850/ 1862] train: loss: 0.0900163
[Epoch 21] ogbg-molmuv: 0.043313 val loss: 0.013349
[Epoch 21] ogbg-molmuv: 0.032408 test loss: 0.012266
[Epoch 22; Iter    18/ 1862] train: loss: 0.0028769
[Epoch 22; Iter    48/ 1862] train: loss: 0.0018863
[Epoch 22; Iter    78/ 1862] train: loss: 0.0288822
[Epoch 22; Iter   108/ 1862] train: loss: 0.0016961
[Epoch 22; Iter   138/ 1862] train: loss: 0.0337818
[Epoch 22; Iter   168/ 1862] train: loss: 0.0038462
[Epoch 22; Iter   198/ 1862] train: loss: 0.0049770
[Epoch 22; Iter   228/ 1862] train: loss: 0.0033298
[Epoch 22; Iter   258/ 1862] train: loss: 0.0015127
[Epoch 22; Iter   288/ 1862] train: loss: 0.0013301
[Epoch 22; Iter   318/ 1862] train: loss: 0.0012499
[Epoch 22; Iter   348/ 1862] train: loss: 0.0551583
[Epoch 22; Iter   378/ 1862] train: loss: 0.0022830
[Epoch 22; Iter   408/ 1862] train: loss: 0.0021719
[Epoch 22; Iter   438/ 1862] train: loss: 0.0020359
[Epoch 22; Iter   468/ 1862] train: loss: 0.0018839
[Epoch 22; Iter   498/ 1862] train: loss: 0.0013156
[Epoch 22; Iter   528/ 1862] train: loss: 0.0011264
[Epoch 22; Iter   558/ 1862] train: loss: 0.0023677
[Epoch 22; Iter   588/ 1862] train: loss: 0.0023606
[Epoch 22; Iter   618/ 1862] train: loss: 0.0014878
[Epoch 22; Iter   648/ 1862] train: loss: 0.0585124
[Epoch 22; Iter   678/ 1862] train: loss: 0.0013087
[Epoch 22; Iter   708/ 1862] train: loss: 0.0012507
[Epoch 22; Iter   738/ 1862] train: loss: 0.0011697
[Epoch 22; Iter   768/ 1862] train: loss: 0.0015990
[Epoch 22; Iter   798/ 1862] train: loss: 0.0009999
[Epoch 22; Iter   828/ 1862] train: loss: 0.0014261
[Epoch 22; Iter   858/ 1862] train: loss: 0.0028147
[Epoch 20; Iter    22/ 1862] train: loss: 0.0015089
[Epoch 20; Iter    52/ 1862] train: loss: 0.0019340
[Epoch 20; Iter    82/ 1862] train: loss: 0.0035176
[Epoch 20; Iter   112/ 1862] train: loss: 0.0013304
[Epoch 20; Iter   142/ 1862] train: loss: 0.0012161
[Epoch 20; Iter   172/ 1862] train: loss: 0.0023287
[Epoch 20; Iter   202/ 1862] train: loss: 0.0014624
[Epoch 20; Iter   232/ 1862] train: loss: 0.0012422
[Epoch 20; Iter   262/ 1862] train: loss: 0.0016374
[Epoch 20; Iter   292/ 1862] train: loss: 0.0661586
[Epoch 20; Iter   322/ 1862] train: loss: 0.0017104
[Epoch 20; Iter   352/ 1862] train: loss: 0.0013039
[Epoch 20; Iter   382/ 1862] train: loss: 0.0713244
[Epoch 20; Iter   412/ 1862] train: loss: 0.0010794
[Epoch 20; Iter   442/ 1862] train: loss: 0.1034017
[Epoch 20; Iter   472/ 1862] train: loss: 0.0016546
[Epoch 20; Iter   502/ 1862] train: loss: 0.0017358
[Epoch 20; Iter   532/ 1862] train: loss: 0.0019331
[Epoch 20; Iter   562/ 1862] train: loss: 0.0008353
[Epoch 20; Iter   592/ 1862] train: loss: 0.0049803
[Epoch 20; Iter   622/ 1862] train: loss: 0.0019378
[Epoch 20; Iter   652/ 1862] train: loss: 0.0015255
[Epoch 20; Iter   682/ 1862] train: loss: 0.0016099
[Epoch 20; Iter   712/ 1862] train: loss: 0.0468711
[Epoch 20; Iter   742/ 1862] train: loss: 0.0013913
[Epoch 20; Iter   772/ 1862] train: loss: 0.0744895
[Epoch 20; Iter   802/ 1862] train: loss: 0.0009715
[Epoch 20; Iter   832/ 1862] train: loss: 0.0013338
[Epoch 20; Iter   862/ 1862] train: loss: 0.0008338
[Epoch 20; Iter   892/ 1862] train: loss: 0.0022314
[Epoch 20; Iter   922/ 1862] train: loss: 0.0014392
[Epoch 20; Iter   952/ 1862] train: loss: 0.0014591
[Epoch 20; Iter   982/ 1862] train: loss: 0.0013225
[Epoch 20; Iter  1012/ 1862] train: loss: 0.0012161
[Epoch 20; Iter  1042/ 1862] train: loss: 0.0069753
[Epoch 20; Iter  1072/ 1862] train: loss: 0.0009783
[Epoch 20; Iter  1102/ 1862] train: loss: 0.0019163
[Epoch 20; Iter  1132/ 1862] train: loss: 0.0018581
[Epoch 20; Iter  1162/ 1862] train: loss: 0.0022913
[Epoch 20; Iter  1192/ 1862] train: loss: 0.0026159
[Epoch 20; Iter  1222/ 1862] train: loss: 0.0026851
[Epoch 20; Iter  1252/ 1862] train: loss: 0.0017341
[Epoch 20; Iter  1282/ 1862] train: loss: 0.0021758
[Epoch 20; Iter  1312/ 1862] train: loss: 0.1138303
[Epoch 20; Iter  1342/ 1862] train: loss: 0.0028155
[Epoch 20; Iter  1372/ 1862] train: loss: 0.0024203
[Epoch 20; Iter  1402/ 1862] train: loss: 0.0013669
[Epoch 20; Iter  1432/ 1862] train: loss: 0.0018978
[Epoch 20; Iter  1462/ 1862] train: loss: 0.0023784
[Epoch 20; Iter  1492/ 1862] train: loss: 0.0016863
[Epoch 20; Iter  1522/ 1862] train: loss: 0.0497461
[Epoch 20; Iter  1552/ 1862] train: loss: 0.0022886
[Epoch 20; Iter  1582/ 1862] train: loss: 0.0019950
[Epoch 20; Iter  1612/ 1862] train: loss: 0.0022779
[Epoch 20; Iter  1642/ 1862] train: loss: 0.0022115
[Epoch 20; Iter  1672/ 1862] train: loss: 0.0016534
[Epoch 20; Iter  1702/ 1862] train: loss: 0.0017116
[Epoch 20; Iter  1732/ 1862] train: loss: 0.0028049
[Epoch 20; Iter  1762/ 1862] train: loss: 0.0017535
[Epoch 20; Iter  1792/ 1862] train: loss: 0.0010422
[Epoch 20; Iter  1822/ 1862] train: loss: 0.0019100
[Epoch 20; Iter  1852/ 1862] train: loss: 0.0016816
[Epoch 20] ogbg-molmuv: 0.033844 val loss: 0.013386
[Epoch 20] ogbg-molmuv: 0.029415 test loss: 0.012359
[Epoch 21; Iter    20/ 1862] train: loss: 0.0011906
[Epoch 21; Iter    50/ 1862] train: loss: 0.0017392
[Epoch 21; Iter    80/ 1862] train: loss: 0.0018235
[Epoch 21; Iter   110/ 1862] train: loss: 0.0017964
[Epoch 21; Iter   140/ 1862] train: loss: 0.0020042
[Epoch 21; Iter   170/ 1862] train: loss: 0.0028641
[Epoch 21; Iter   200/ 1862] train: loss: 0.0016132
[Epoch 21; Iter   230/ 1862] train: loss: 0.0011163
[Epoch 21; Iter   260/ 1862] train: loss: 0.0213038
[Epoch 21; Iter   290/ 1862] train: loss: 0.0829866
[Epoch 21; Iter   320/ 1862] train: loss: 0.0011803
[Epoch 21; Iter   350/ 1862] train: loss: 0.0819632
[Epoch 21; Iter   380/ 1862] train: loss: 0.0020366
[Epoch 21; Iter   410/ 1862] train: loss: 0.0021722
[Epoch 21; Iter   440/ 1862] train: loss: 0.0041516
[Epoch 21; Iter   470/ 1862] train: loss: 0.0033497
[Epoch 21; Iter   500/ 1862] train: loss: 0.0018664
[Epoch 21; Iter   530/ 1862] train: loss: 0.0017638
[Epoch 21; Iter   560/ 1862] train: loss: 0.0734873
[Epoch 21; Iter   590/ 1862] train: loss: 0.0017491
[Epoch 21; Iter   620/ 1862] train: loss: 0.0026038
[Epoch 21; Iter   650/ 1862] train: loss: 0.0017540
[Epoch 21; Iter   680/ 1862] train: loss: 0.0013293
[Epoch 21; Iter   710/ 1862] train: loss: 0.0008377
[Epoch 21; Iter   740/ 1862] train: loss: 0.0849216
[Epoch 21; Iter   770/ 1862] train: loss: 0.0020470
[Epoch 21; Iter   800/ 1862] train: loss: 0.0014664
[Epoch 21; Iter   830/ 1862] train: loss: 0.0018529
[Epoch 21; Iter   860/ 1862] train: loss: 0.0399928
[Epoch 21; Iter   890/ 1862] train: loss: 0.0019684
[Epoch 21; Iter   920/ 1862] train: loss: 0.0038769
[Epoch 21; Iter   950/ 1862] train: loss: 0.0096589
[Epoch 21; Iter   980/ 1862] train: loss: 0.0023296
[Epoch 21; Iter  1010/ 1862] train: loss: 0.0017883
[Epoch 21; Iter  1040/ 1862] train: loss: 0.0009506
[Epoch 21; Iter  1070/ 1862] train: loss: 0.0020931
[Epoch 21; Iter  1100/ 1862] train: loss: 0.0009590
[Epoch 21; Iter  1130/ 1862] train: loss: 0.0916011
[Epoch 21; Iter  1160/ 1862] train: loss: 0.0013424
[Epoch 21; Iter  1190/ 1862] train: loss: 0.0013218
[Epoch 21; Iter  1220/ 1862] train: loss: 0.0860837
[Epoch 21; Iter  1250/ 1862] train: loss: 0.0026434
[Epoch 21; Iter  1280/ 1862] train: loss: 0.0022364
[Epoch 21; Iter  1310/ 1862] train: loss: 0.1049600
[Epoch 21; Iter  1340/ 1862] train: loss: 0.0027870
[Epoch 21; Iter  1370/ 1862] train: loss: 0.0025512
[Epoch 21; Iter  1400/ 1862] train: loss: 0.0022263
[Epoch 21; Iter  1430/ 1862] train: loss: 0.0014807
[Epoch 21; Iter  1460/ 1862] train: loss: 0.0022195
[Epoch 21; Iter  1490/ 1862] train: loss: 0.0025904
[Epoch 21; Iter  1520/ 1862] train: loss: 0.0011885
[Epoch 21; Iter  1550/ 1862] train: loss: 0.0013562
[Epoch 21; Iter  1580/ 1862] train: loss: 0.0021124
[Epoch 21; Iter  1610/ 1862] train: loss: 0.0030958
[Epoch 21; Iter  1640/ 1862] train: loss: 0.0081864
[Epoch 21; Iter  1670/ 1862] train: loss: 0.0012658
[Epoch 21; Iter  1700/ 1862] train: loss: 0.0016067
[Epoch 21; Iter  1730/ 1862] train: loss: 0.0879744
[Epoch 21; Iter  1760/ 1862] train: loss: 0.1115656
[Epoch 21; Iter  1790/ 1862] train: loss: 0.0020419
[Epoch 21; Iter  1820/ 1862] train: loss: 0.0023623
[Epoch 21; Iter  1850/ 1862] train: loss: 0.0031622
[Epoch 21] ogbg-molmuv: 0.033424 val loss: 0.012861
[Epoch 21] ogbg-molmuv: 0.079189 test loss: 0.011728
[Epoch 22; Iter    18/ 1862] train: loss: 0.0722107
[Epoch 22; Iter    48/ 1862] train: loss: 0.0274589
[Epoch 22; Iter    78/ 1862] train: loss: 0.0018759
[Epoch 22; Iter   108/ 1862] train: loss: 0.0025977
[Epoch 22; Iter   138/ 1862] train: loss: 0.0010596
[Epoch 22; Iter   168/ 1862] train: loss: 0.0021465
[Epoch 22; Iter   198/ 1862] train: loss: 0.0017592
[Epoch 22; Iter   228/ 1862] train: loss: 0.0037964
[Epoch 22; Iter   258/ 1862] train: loss: 0.0028159
[Epoch 22; Iter   288/ 1862] train: loss: 0.0017483
[Epoch 22; Iter   318/ 1862] train: loss: 0.0018263
[Epoch 22; Iter   348/ 1862] train: loss: 0.0016148
[Epoch 22; Iter   378/ 1862] train: loss: 0.0018992
[Epoch 22; Iter   408/ 1862] train: loss: 0.0010434
[Epoch 22; Iter   438/ 1862] train: loss: 0.0600596
[Epoch 22; Iter   468/ 1862] train: loss: 0.0017532
[Epoch 22; Iter   498/ 1862] train: loss: 0.0389332
[Epoch 22; Iter   528/ 1862] train: loss: 0.0010076
[Epoch 22; Iter   558/ 1862] train: loss: 0.0090331
[Epoch 22; Iter   588/ 1862] train: loss: 0.0007904
[Epoch 22; Iter   618/ 1862] train: loss: 0.0026928
[Epoch 22; Iter   648/ 1862] train: loss: 0.0040195
[Epoch 22; Iter   678/ 1862] train: loss: 0.0009953
[Epoch 22; Iter   708/ 1862] train: loss: 0.0021565
[Epoch 22; Iter   738/ 1862] train: loss: 0.0044737
[Epoch 22; Iter   768/ 1862] train: loss: 0.0026915
[Epoch 22; Iter   798/ 1862] train: loss: 0.0017917
[Epoch 22; Iter   828/ 1862] train: loss: 0.0019420
[Epoch 22; Iter   858/ 1862] train: loss: 0.0019768
[Epoch 19; Iter   276/ 2483] train: loss: 0.0028198
[Epoch 19; Iter   306/ 2483] train: loss: 0.0033861
[Epoch 19; Iter   336/ 2483] train: loss: 0.0505562
[Epoch 19; Iter   366/ 2483] train: loss: 0.0020126
[Epoch 19; Iter   396/ 2483] train: loss: 0.0017872
[Epoch 19; Iter   426/ 2483] train: loss: 0.0702043
[Epoch 19; Iter   456/ 2483] train: loss: 0.0902188
[Epoch 19; Iter   486/ 2483] train: loss: 0.0708334
[Epoch 19; Iter   516/ 2483] train: loss: 0.0020273
[Epoch 19; Iter   546/ 2483] train: loss: 0.0021088
[Epoch 19; Iter   576/ 2483] train: loss: 0.0017705
[Epoch 19; Iter   606/ 2483] train: loss: 0.0015314
[Epoch 19; Iter   636/ 2483] train: loss: 0.0015040
[Epoch 19; Iter   666/ 2483] train: loss: 0.0015424
[Epoch 19; Iter   696/ 2483] train: loss: 0.0014287
[Epoch 19; Iter   726/ 2483] train: loss: 0.0013196
[Epoch 19; Iter   756/ 2483] train: loss: 0.0025185
[Epoch 19; Iter   786/ 2483] train: loss: 0.0022571
[Epoch 19; Iter   816/ 2483] train: loss: 0.0023599
[Epoch 19; Iter   846/ 2483] train: loss: 0.0014066
[Epoch 19; Iter   876/ 2483] train: loss: 0.0024057
[Epoch 19; Iter   906/ 2483] train: loss: 0.0015539
[Epoch 19; Iter   936/ 2483] train: loss: 0.0014971
[Epoch 19; Iter   966/ 2483] train: loss: 0.0016307
[Epoch 19; Iter   996/ 2483] train: loss: 0.0016544
[Epoch 19; Iter  1026/ 2483] train: loss: 0.0013677
[Epoch 19; Iter  1056/ 2483] train: loss: 0.0014145
[Epoch 19; Iter  1086/ 2483] train: loss: 0.0014199
[Epoch 19; Iter  1116/ 2483] train: loss: 0.0012401
[Epoch 19; Iter  1146/ 2483] train: loss: 0.0015699
[Epoch 19; Iter  1176/ 2483] train: loss: 0.0019757
[Epoch 19; Iter  1206/ 2483] train: loss: 0.0008480
[Epoch 19; Iter  1236/ 2483] train: loss: 0.0009458
[Epoch 19; Iter  1266/ 2483] train: loss: 0.0015845
[Epoch 19; Iter  1296/ 2483] train: loss: 0.0017089
[Epoch 19; Iter  1326/ 2483] train: loss: 0.0014422
[Epoch 19; Iter  1356/ 2483] train: loss: 0.0013286
[Epoch 19; Iter  1386/ 2483] train: loss: 0.0016490
[Epoch 19; Iter  1416/ 2483] train: loss: 0.0014326
[Epoch 19; Iter  1446/ 2483] train: loss: 0.0018028
[Epoch 19; Iter  1476/ 2483] train: loss: 0.0020119
[Epoch 19; Iter  1506/ 2483] train: loss: 0.0012690
[Epoch 19; Iter  1536/ 2483] train: loss: 0.0013929
[Epoch 19; Iter  1566/ 2483] train: loss: 0.0013013
[Epoch 19; Iter  1596/ 2483] train: loss: 0.0014035
[Epoch 19; Iter  1626/ 2483] train: loss: 0.0012022
[Epoch 19; Iter  1656/ 2483] train: loss: 0.0042760
[Epoch 19; Iter  1686/ 2483] train: loss: 0.0012036
[Epoch 19; Iter  1716/ 2483] train: loss: 0.0013545
[Epoch 19; Iter  1746/ 2483] train: loss: 0.0014772
[Epoch 19; Iter  1776/ 2483] train: loss: 0.0766627
[Epoch 19; Iter  1806/ 2483] train: loss: 0.0021294
[Epoch 19; Iter  1836/ 2483] train: loss: 0.0012611
[Epoch 19; Iter  1866/ 2483] train: loss: 0.0016321
[Epoch 19; Iter  1896/ 2483] train: loss: 0.0008762
[Epoch 19; Iter  1926/ 2483] train: loss: 0.0018488
[Epoch 19; Iter  1956/ 2483] train: loss: 0.0012305
[Epoch 19; Iter  1986/ 2483] train: loss: 0.0017128
[Epoch 19; Iter  2016/ 2483] train: loss: 0.0649419
[Epoch 19; Iter  2046/ 2483] train: loss: 0.0028321
[Epoch 19; Iter  2076/ 2483] train: loss: 0.0028635
[Epoch 19; Iter  2106/ 2483] train: loss: 0.0013696
[Epoch 19; Iter  2136/ 2483] train: loss: 0.0015099
[Epoch 19; Iter  2166/ 2483] train: loss: 0.0027557
[Epoch 19; Iter  2196/ 2483] train: loss: 0.0019036
[Epoch 19; Iter  2226/ 2483] train: loss: 0.0013543
[Epoch 19; Iter  2256/ 2483] train: loss: 0.0546861
[Epoch 19; Iter  2286/ 2483] train: loss: 0.0020689
[Epoch 19; Iter  2316/ 2483] train: loss: 0.0081980
[Epoch 19; Iter  2346/ 2483] train: loss: 0.0753921
[Epoch 19; Iter  2376/ 2483] train: loss: 0.0841147
[Epoch 19; Iter  2406/ 2483] train: loss: 0.0015013
[Epoch 19; Iter  2436/ 2483] train: loss: 0.0014720
[Epoch 19; Iter  2466/ 2483] train: loss: 0.0016303
[Epoch 19] ogbg-molmuv: 0.089867 val loss: 0.014136
[Epoch 19] ogbg-molmuv: 0.146403 test loss: 0.014137
[Epoch 20; Iter    13/ 2483] train: loss: 0.0012842
[Epoch 20; Iter    43/ 2483] train: loss: 0.0014872
[Epoch 20; Iter    73/ 2483] train: loss: 0.0014102
[Epoch 20; Iter   103/ 2483] train: loss: 0.0019780
[Epoch 20; Iter   133/ 2483] train: loss: 0.0018170
[Epoch 20; Iter   163/ 2483] train: loss: 0.0754643
[Epoch 20; Iter   193/ 2483] train: loss: 0.0013735
[Epoch 20; Iter   223/ 2483] train: loss: 0.0018168
[Epoch 20; Iter   253/ 2483] train: loss: 0.0621826
[Epoch 20; Iter   283/ 2483] train: loss: 0.0021880
[Epoch 20; Iter   313/ 2483] train: loss: 0.0015172
[Epoch 20; Iter   343/ 2483] train: loss: 0.0016446
[Epoch 20; Iter   373/ 2483] train: loss: 0.0023109
[Epoch 20; Iter   403/ 2483] train: loss: 0.0033598
[Epoch 20; Iter   433/ 2483] train: loss: 0.0014590
[Epoch 20; Iter   463/ 2483] train: loss: 0.0791807
[Epoch 20; Iter   493/ 2483] train: loss: 0.0019782
[Epoch 20; Iter   523/ 2483] train: loss: 0.0025072
[Epoch 20; Iter   553/ 2483] train: loss: 0.0019975
[Epoch 20; Iter   583/ 2483] train: loss: 0.0013942
[Epoch 20; Iter   613/ 2483] train: loss: 0.0012400
[Epoch 20; Iter   643/ 2483] train: loss: 0.0021872
[Epoch 20; Iter   673/ 2483] train: loss: 0.0012594
[Epoch 20; Iter   703/ 2483] train: loss: 0.0020682
[Epoch 20; Iter   733/ 2483] train: loss: 0.0013399
[Epoch 20; Iter   763/ 2483] train: loss: 0.0015832
[Epoch 20; Iter   793/ 2483] train: loss: 0.0009623
[Epoch 20; Iter   823/ 2483] train: loss: 0.0017379
[Epoch 20; Iter   853/ 2483] train: loss: 0.0010244
[Epoch 20; Iter   883/ 2483] train: loss: 0.0012050
[Epoch 20; Iter   913/ 2483] train: loss: 0.0017255
[Epoch 20; Iter   943/ 2483] train: loss: 0.0017786
[Epoch 20; Iter   973/ 2483] train: loss: 0.0016248
[Epoch 20; Iter  1003/ 2483] train: loss: 0.0466041
[Epoch 20; Iter  1033/ 2483] train: loss: 0.0025652
[Epoch 20; Iter  1063/ 2483] train: loss: 0.0014056
[Epoch 20; Iter  1093/ 2483] train: loss: 0.0014101
[Epoch 20; Iter  1123/ 2483] train: loss: 0.0015326
[Epoch 20; Iter  1153/ 2483] train: loss: 0.0781871
[Epoch 20; Iter  1183/ 2483] train: loss: 0.0032116
[Epoch 20; Iter  1213/ 2483] train: loss: 0.0016012
[Epoch 20; Iter  1243/ 2483] train: loss: 0.0013551
[Epoch 20; Iter  1273/ 2483] train: loss: 0.0030347
[Epoch 20; Iter  1303/ 2483] train: loss: 0.0023229
[Epoch 20; Iter  1333/ 2483] train: loss: 0.0020659
[Epoch 20; Iter  1363/ 2483] train: loss: 0.0024495
[Epoch 20; Iter  1393/ 2483] train: loss: 0.0041749
[Epoch 20; Iter  1423/ 2483] train: loss: 0.1296934
[Epoch 20; Iter  1453/ 2483] train: loss: 0.0016881
[Epoch 20; Iter  1483/ 2483] train: loss: 0.0054701
[Epoch 20; Iter  1513/ 2483] train: loss: 0.0021117
[Epoch 20; Iter  1543/ 2483] train: loss: 0.0020990
[Epoch 20; Iter  1573/ 2483] train: loss: 0.0020157
[Epoch 20; Iter  1603/ 2483] train: loss: 0.0016519
[Epoch 20; Iter  1633/ 2483] train: loss: 0.0685862
[Epoch 20; Iter  1663/ 2483] train: loss: 0.0934133
[Epoch 20; Iter  1693/ 2483] train: loss: 0.0016570
[Epoch 20; Iter  1723/ 2483] train: loss: 0.0017429
[Epoch 20; Iter  1753/ 2483] train: loss: 0.0030803
[Epoch 20; Iter  1783/ 2483] train: loss: 0.0013672
[Epoch 20; Iter  1813/ 2483] train: loss: 0.0019089
[Epoch 20; Iter  1843/ 2483] train: loss: 0.0013768
[Epoch 20; Iter  1873/ 2483] train: loss: 0.0017988
[Epoch 20; Iter  1903/ 2483] train: loss: 0.0019251
[Epoch 20; Iter  1933/ 2483] train: loss: 0.0011965
[Epoch 20; Iter  1963/ 2483] train: loss: 0.0025121
[Epoch 20; Iter  1993/ 2483] train: loss: 0.0402477
[Epoch 20; Iter  2023/ 2483] train: loss: 0.0016811
[Epoch 20; Iter  2053/ 2483] train: loss: 0.0017268
[Epoch 20; Iter  2083/ 2483] train: loss: 0.0020668
[Epoch 20; Iter  2113/ 2483] train: loss: 0.0018444
[Epoch 20; Iter  2143/ 2483] train: loss: 0.0017855
[Epoch 20; Iter  2173/ 2483] train: loss: 0.0018494
[Epoch 20; Iter  2203/ 2483] train: loss: 0.0022522
[Epoch 20; Iter  2233/ 2483] train: loss: 0.0011943
[Epoch 20; Iter  2263/ 2483] train: loss: 0.0014304
[Epoch 20; Iter  2293/ 2483] train: loss: 0.0012008
[Epoch 20; Iter  2323/ 2483] train: loss: 0.0012118
[Epoch 20; Iter  2353/ 2483] train: loss: 0.0025287
[Epoch 20; Iter  2383/ 2483] train: loss: 0.0012875
[Epoch 20; Iter  2413/ 2483] train: loss: 0.0772002
[Epoch 20; Iter  2443/ 2483] train: loss: 0.0665861
[Epoch 20; Iter  2473/ 2483] train: loss: 0.0018111
[Epoch 20] ogbg-molmuv: 0.106018 val loss: 0.017780
[Epoch 20] ogbg-molmuv: 0.116005 test loss: 0.041981
[Epoch 21; Iter    20/ 2483] train: loss: 0.0388461
[Epoch 21; Iter    50/ 2483] train: loss: 0.0016370
[Epoch 21; Iter    80/ 2483] train: loss: 0.0014136
[Epoch 21; Iter   110/ 2483] train: loss: 0.0628985
[Epoch 21; Iter   140/ 2483] train: loss: 0.0009577
[Epoch 21; Iter   170/ 2483] train: loss: 0.0010172
[Epoch 21; Iter   200/ 2483] train: loss: 0.0011825
[Epoch 21; Iter   230/ 2483] train: loss: 0.0717318
[Epoch 21; Iter   260/ 2483] train: loss: 0.0011976
[Epoch 21; Iter   290/ 2483] train: loss: 0.0010755
[Epoch 21; Iter   320/ 2483] train: loss: 0.0522024
[Epoch 21; Iter   350/ 2483] train: loss: 0.0035986
[Epoch 21; Iter   380/ 2483] train: loss: 0.0015638
[Epoch 21; Iter   410/ 2483] train: loss: 0.0016696
[Epoch 21; Iter   440/ 2483] train: loss: 0.0013689
[Epoch 21; Iter   470/ 2483] train: loss: 0.0015982
[Epoch 21; Iter   500/ 2483] train: loss: 0.0017155
[Epoch 21; Iter   530/ 2483] train: loss: 0.0011451
[Epoch 21; Iter   560/ 2483] train: loss: 0.0022405
[Epoch 21; Iter   590/ 2483] train: loss: 0.0020711
[Epoch 21; Iter   620/ 2483] train: loss: 0.0053266
[Epoch 21; Iter   650/ 2483] train: loss: 0.0029552
[Epoch 21; Iter   680/ 2483] train: loss: 0.0618243
[Epoch 21; Iter   710/ 2483] train: loss: 0.0012427
[Epoch 21; Iter   740/ 2483] train: loss: 0.0010741
[Epoch 21; Iter   770/ 2483] train: loss: 0.0012306
[Epoch 21; Iter   800/ 2483] train: loss: 0.0012339
[Epoch 21; Iter   830/ 2483] train: loss: 0.0013719
[Epoch 21; Iter   860/ 2483] train: loss: 0.0021902
[Epoch 21; Iter   890/ 2483] train: loss: 0.0019695
[Epoch 21; Iter   920/ 2483] train: loss: 0.0017393
[Epoch 21; Iter   950/ 2483] train: loss: 0.0020516
[Epoch 21; Iter   980/ 2483] train: loss: 0.0015449
[Epoch 21; Iter  1010/ 2483] train: loss: 0.0020943
[Epoch 21; Iter  1040/ 2483] train: loss: 0.0016892
[Epoch 21; Iter  1070/ 2483] train: loss: 0.0015601
[Epoch 21; Iter  1100/ 2483] train: loss: 0.0008764
[Epoch 21; Iter  1130/ 2483] train: loss: 0.0010173
[Epoch 21; Iter  1160/ 2483] train: loss: 0.1505747
[Epoch 21; Iter  1190/ 2483] train: loss: 0.0012106
[Epoch 21; Iter  1220/ 2483] train: loss: 0.0029269
[Epoch 21; Iter  1250/ 2483] train: loss: 0.0457202
[Epoch 21; Iter  1280/ 2483] train: loss: 0.0020613
[Epoch 21; Iter  1310/ 2483] train: loss: 0.0699725
[Epoch 21; Iter  1340/ 2483] train: loss: 0.0039607
[Epoch 21; Iter  1370/ 2483] train: loss: 0.0020705
[Epoch 21; Iter  1400/ 2483] train: loss: 0.0015013
[Epoch 21; Iter  1430/ 2483] train: loss: 0.0686437
[Epoch 21; Iter  1460/ 2483] train: loss: 0.0022311
[Epoch 21; Iter  1490/ 2483] train: loss: 0.0014627
[Epoch 21; Iter  1520/ 2483] train: loss: 0.0877419
[Epoch 21; Iter  1550/ 2483] train: loss: 0.0024564
[Epoch 21; Iter  1580/ 2483] train: loss: 0.1344010
[Epoch 21; Iter  1610/ 2483] train: loss: 0.0038696
[Epoch 21; Iter  1640/ 2483] train: loss: 0.0018170
[Epoch 21; Iter  1670/ 2483] train: loss: 0.0015343
[Epoch 21; Iter  1700/ 2483] train: loss: 0.0013220
[Epoch 21; Iter  1730/ 2483] train: loss: 0.0022411
[Epoch 21; Iter  1760/ 2483] train: loss: 0.0027117
[Epoch 21; Iter  1790/ 2483] train: loss: 0.0067350
[Epoch 21; Iter  1820/ 2483] train: loss: 0.0035936
[Epoch 21; Iter  1850/ 2483] train: loss: 0.0020015
[Epoch 21; Iter  1880/ 2483] train: loss: 0.0016912
[Epoch 21; Iter  1910/ 2483] train: loss: 0.0014610
[Epoch 21; Iter  1940/ 2483] train: loss: 0.0020945
[Epoch 21; Iter  1970/ 2483] train: loss: 0.0012445
[Epoch 21; Iter  2000/ 2483] train: loss: 0.0013496
[Epoch 21; Iter  2030/ 2483] train: loss: 0.0893789
[Epoch 21; Iter  2060/ 2483] train: loss: 0.0015414
[Epoch 21; Iter  2090/ 2483] train: loss: 0.0012073
[Epoch 21; Iter  2120/ 2483] train: loss: 0.0024285
[Epoch 21; Iter  2150/ 2483] train: loss: 0.0024583
[Epoch 21; Iter  2180/ 2483] train: loss: 0.0025877
[Epoch 21; Iter  2210/ 2483] train: loss: 0.0021264
[Epoch 21; Iter  2240/ 2483] train: loss: 0.0011049
[Epoch 21; Iter  2270/ 2483] train: loss: 0.0018029
[Epoch 21; Iter  2300/ 2483] train: loss: 0.0024493
[Epoch 21; Iter  2330/ 2483] train: loss: 0.0013292
[Epoch 21; Iter  2360/ 2483] train: loss: 0.0014547
[Epoch 21; Iter  2390/ 2483] train: loss: 0.0012371
[Epoch 21; Iter  2420/ 2483] train: loss: 0.1804118
[Epoch 21; Iter  2450/ 2483] train: loss: 0.0016608
[Epoch 21; Iter  2480/ 2483] train: loss: 0.0019161
[Epoch 21] ogbg-molmuv: 0.106612 val loss: 0.035792
[Epoch 21] ogbg-molmuv: 0.086586 test loss: 0.056224
[Epoch 22; Iter    27/ 2483] train: loss: 0.0016858
[Epoch 22; Iter    57/ 2483] train: loss: 0.0024013
[Epoch 22; Iter    87/ 2483] train: loss: 0.0015326
[Epoch 22; Iter   117/ 2483] train: loss: 0.0014050
[Epoch 22; Iter   147/ 2483] train: loss: 0.0539766
[Epoch 22; Iter   177/ 2483] train: loss: 0.0022179
[Epoch 22; Iter   207/ 2483] train: loss: 0.0027620
[Epoch 22; Iter   237/ 2483] train: loss: 0.0012157
[Epoch 22; Iter   267/ 2483] train: loss: 0.0705503
[Epoch 22; Iter   297/ 2483] train: loss: 0.0014587
[Epoch 22; Iter   327/ 2483] train: loss: 0.0014865
[Epoch 22; Iter   357/ 2483] train: loss: 0.0014829
[Epoch 22; Iter   387/ 2483] train: loss: 0.0015119
[Epoch 22; Iter   417/ 2483] train: loss: 0.0016330
[Epoch 22; Iter   447/ 2483] train: loss: 0.0791191
[Epoch 22; Iter   477/ 2483] train: loss: 0.0015136
[Epoch 22; Iter   507/ 2483] train: loss: 0.0014962
[Epoch 22; Iter   537/ 2483] train: loss: 0.0019295
[Epoch 22; Iter   567/ 2483] train: loss: 0.0016003
[Epoch 22; Iter   597/ 2483] train: loss: 0.0020635
[Epoch 22; Iter   627/ 2483] train: loss: 0.0600270
[Epoch 22; Iter   657/ 2483] train: loss: 0.0013975
[Epoch 22; Iter   687/ 2483] train: loss: 0.0018003
[Epoch 22; Iter   717/ 2483] train: loss: 0.0018967
[Epoch 22; Iter   747/ 2483] train: loss: 0.0021441
[Epoch 22; Iter   777/ 2483] train: loss: 0.0010981
[Epoch 22; Iter   807/ 2483] train: loss: 0.0499046
[Epoch 22; Iter   837/ 2483] train: loss: 0.0675805
[Epoch 22; Iter   867/ 2483] train: loss: 0.0012214
[Epoch 22; Iter   897/ 2483] train: loss: 0.0012299
[Epoch 22; Iter   927/ 2483] train: loss: 0.0040855
[Epoch 22; Iter   957/ 2483] train: loss: 0.0018688
[Epoch 22; Iter   987/ 2483] train: loss: 0.0021580
[Epoch 22; Iter  1017/ 2483] train: loss: 0.0009090
[Epoch 22; Iter  1047/ 2483] train: loss: 0.0013358
[Epoch 22; Iter  1077/ 2483] train: loss: 0.0009026
[Epoch 22; Iter  1107/ 2483] train: loss: 0.0755673
[Epoch 22; Iter  1137/ 2483] train: loss: 0.0017593
[Epoch 22; Iter  1167/ 2483] train: loss: 0.0014792
[Epoch 22; Iter  1197/ 2483] train: loss: 0.0015183
[Epoch 22; Iter  1227/ 2483] train: loss: 0.0012290
[Epoch 22; Iter  1257/ 2483] train: loss: 0.0020398
[Epoch 22; Iter  1287/ 2483] train: loss: 0.0017022
[Epoch 22; Iter  1317/ 2483] train: loss: 0.0834404
[Epoch 22; Iter  1347/ 2483] train: loss: 0.0062258
[Epoch 22; Iter  1377/ 2483] train: loss: 0.0013064
[Epoch 22; Iter  1407/ 2483] train: loss: 0.0013111
[Epoch 22; Iter  1437/ 2483] train: loss: 0.0632971
[Epoch 22; Iter  1467/ 2483] train: loss: 0.0015582
[Epoch 22; Iter  1497/ 2483] train: loss: 0.0011119
[Epoch 22; Iter  1527/ 2483] train: loss: 0.0016192
[Epoch 22; Iter  1557/ 2483] train: loss: 0.0017115
[Epoch 22; Iter  1587/ 2483] train: loss: 0.0043853
[Epoch 22; Iter  1617/ 2483] train: loss: 0.0873452
[Epoch 22; Iter  1647/ 2483] train: loss: 0.0013298
[Epoch 22; Iter  1677/ 2483] train: loss: 0.0012041
[Epoch 22; Iter  1707/ 2483] train: loss: 0.0028379
[Epoch 22; Iter  1737/ 2483] train: loss: 0.0746666
[Epoch 22; Iter  1767/ 2483] train: loss: 0.0975849
[Epoch 22; Iter  1797/ 2483] train: loss: 0.0015426
[Epoch 22; Iter  1827/ 2483] train: loss: 0.0018166
[Epoch 22; Iter  1857/ 2483] train: loss: 0.0495790
[Epoch 22; Iter  1887/ 2483] train: loss: 0.0016727
[Epoch 22; Iter  1917/ 2483] train: loss: 0.0016006
[Epoch 22; Iter  1947/ 2483] train: loss: 0.0023368
[Epoch 22; Iter  1977/ 2483] train: loss: 0.0023136
[Epoch 22; Iter  2007/ 2483] train: loss: 0.0019284
[Epoch 22; Iter  2037/ 2483] train: loss: 0.0015170
[Epoch 20; Iter  2443/ 2483] train: loss: 0.0014838
[Epoch 20; Iter  2473/ 2483] train: loss: 0.0026329
[Epoch 20] ogbg-molmuv: 0.089595 val loss: 0.010598
[Epoch 20] ogbg-molmuv: 0.113016 test loss: 0.014640
[Epoch 21; Iter    20/ 2483] train: loss: 0.0024426
[Epoch 21; Iter    50/ 2483] train: loss: 0.0017327
[Epoch 21; Iter    80/ 2483] train: loss: 0.0015398
[Epoch 21; Iter   110/ 2483] train: loss: 0.0023449
[Epoch 21; Iter   140/ 2483] train: loss: 0.0025439
[Epoch 21; Iter   170/ 2483] train: loss: 0.0017386
[Epoch 21; Iter   200/ 2483] train: loss: 0.0024410
[Epoch 21; Iter   230/ 2483] train: loss: 0.0018390
[Epoch 21; Iter   260/ 2483] train: loss: 0.0016171
[Epoch 21; Iter   290/ 2483] train: loss: 0.0013459
[Epoch 21; Iter   320/ 2483] train: loss: 0.0013248
[Epoch 21; Iter   350/ 2483] train: loss: 0.0016058
[Epoch 21; Iter   380/ 2483] train: loss: 0.0182463
[Epoch 21; Iter   410/ 2483] train: loss: 0.0659563
[Epoch 21; Iter   440/ 2483] train: loss: 0.0018824
[Epoch 21; Iter   470/ 2483] train: loss: 0.0012853
[Epoch 21; Iter   500/ 2483] train: loss: 0.0025189
[Epoch 21; Iter   530/ 2483] train: loss: 0.0017544
[Epoch 21; Iter   560/ 2483] train: loss: 0.0023552
[Epoch 21; Iter   590/ 2483] train: loss: 0.0055601
[Epoch 21; Iter   620/ 2483] train: loss: 0.0015052
[Epoch 21; Iter   650/ 2483] train: loss: 0.0016236
[Epoch 21; Iter   680/ 2483] train: loss: 0.0011584
[Epoch 21; Iter   710/ 2483] train: loss: 0.0014475
[Epoch 21; Iter   740/ 2483] train: loss: 0.0025796
[Epoch 21; Iter   770/ 2483] train: loss: 0.0202335
[Epoch 21; Iter   800/ 2483] train: loss: 0.0033379
[Epoch 21; Iter   830/ 2483] train: loss: 0.0025072
[Epoch 21; Iter   860/ 2483] train: loss: 0.0012630
[Epoch 21; Iter   890/ 2483] train: loss: 0.0020196
[Epoch 21; Iter   920/ 2483] train: loss: 0.0054502
[Epoch 21; Iter   950/ 2483] train: loss: 0.0877694
[Epoch 21; Iter   980/ 2483] train: loss: 0.0017898
[Epoch 21; Iter  1010/ 2483] train: loss: 0.0711034
[Epoch 21; Iter  1040/ 2483] train: loss: 0.0020813
[Epoch 21; Iter  1070/ 2483] train: loss: 0.0014012
[Epoch 21; Iter  1100/ 2483] train: loss: 0.0019478
[Epoch 21; Iter  1130/ 2483] train: loss: 0.0021488
[Epoch 21; Iter  1160/ 2483] train: loss: 0.0011894
[Epoch 21; Iter  1190/ 2483] train: loss: 0.0023383
[Epoch 21; Iter  1220/ 2483] train: loss: 0.0018276
[Epoch 21; Iter  1250/ 2483] train: loss: 0.0641236
[Epoch 21; Iter  1280/ 2483] train: loss: 0.0012233
[Epoch 21; Iter  1310/ 2483] train: loss: 0.0013810
[Epoch 21; Iter  1340/ 2483] train: loss: 0.0017160
[Epoch 21; Iter  1370/ 2483] train: loss: 0.0018126
[Epoch 21; Iter  1400/ 2483] train: loss: 0.0022176
[Epoch 21; Iter  1430/ 2483] train: loss: 0.0017919
[Epoch 21; Iter  1460/ 2483] train: loss: 0.0014295
[Epoch 21; Iter  1490/ 2483] train: loss: 0.0012584
[Epoch 21; Iter  1520/ 2483] train: loss: 0.0015546
[Epoch 21; Iter  1550/ 2483] train: loss: 0.0014429
[Epoch 21; Iter  1580/ 2483] train: loss: 0.0011209
[Epoch 21; Iter  1610/ 2483] train: loss: 0.0013949
[Epoch 21; Iter  1640/ 2483] train: loss: 0.0016681
[Epoch 21; Iter  1670/ 2483] train: loss: 0.0010900
[Epoch 21; Iter  1700/ 2483] train: loss: 0.0010042
[Epoch 21; Iter  1730/ 2483] train: loss: 0.0011550
[Epoch 21; Iter  1760/ 2483] train: loss: 0.0015603
[Epoch 21; Iter  1790/ 2483] train: loss: 0.0014459
[Epoch 21; Iter  1820/ 2483] train: loss: 0.0400859
[Epoch 21; Iter  1850/ 2483] train: loss: 0.0027806
[Epoch 21; Iter  1880/ 2483] train: loss: 0.0016415
[Epoch 21; Iter  1910/ 2483] train: loss: 0.0013618
[Epoch 21; Iter  1940/ 2483] train: loss: 0.0021238
[Epoch 21; Iter  1970/ 2483] train: loss: 0.0026077
[Epoch 21; Iter  2000/ 2483] train: loss: 0.0022803
[Epoch 21; Iter  2030/ 2483] train: loss: 0.0014896
[Epoch 21; Iter  2060/ 2483] train: loss: 0.0015360
[Epoch 21; Iter  2090/ 2483] train: loss: 0.0007012
[Epoch 21; Iter  2120/ 2483] train: loss: 0.0012773
[Epoch 21; Iter  2150/ 2483] train: loss: 0.0026577
[Epoch 21; Iter  2180/ 2483] train: loss: 0.0012134
[Epoch 21; Iter  2210/ 2483] train: loss: 0.0013456
[Epoch 21; Iter  2240/ 2483] train: loss: 0.0018098
[Epoch 21; Iter  2270/ 2483] train: loss: 0.0009686
[Epoch 21; Iter  2300/ 2483] train: loss: 0.0011823
[Epoch 21; Iter  2330/ 2483] train: loss: 0.0011509
[Epoch 21; Iter  2360/ 2483] train: loss: 0.0699012
[Epoch 21; Iter  2390/ 2483] train: loss: 0.0013420
[Epoch 21; Iter  2420/ 2483] train: loss: 0.0011897
[Epoch 21; Iter  2450/ 2483] train: loss: 0.0051238
[Epoch 21; Iter  2480/ 2483] train: loss: 0.0012907
[Epoch 21] ogbg-molmuv: 0.099800 val loss: 0.011277
[Epoch 21] ogbg-molmuv: 0.153459 test loss: 0.013799
[Epoch 22; Iter    27/ 2483] train: loss: 0.0014847
[Epoch 22; Iter    57/ 2483] train: loss: 0.0020602
[Epoch 22; Iter    87/ 2483] train: loss: 0.0017740
[Epoch 22; Iter   117/ 2483] train: loss: 0.0016554
[Epoch 22; Iter   147/ 2483] train: loss: 0.0014878
[Epoch 22; Iter   177/ 2483] train: loss: 0.0013443
[Epoch 22; Iter   207/ 2483] train: loss: 0.0668188
[Epoch 22; Iter   237/ 2483] train: loss: 0.0020271
[Epoch 22; Iter   267/ 2483] train: loss: 0.0091888
[Epoch 22; Iter   297/ 2483] train: loss: 0.0022520
[Epoch 22; Iter   327/ 2483] train: loss: 0.0673017
[Epoch 22; Iter   357/ 2483] train: loss: 0.0029688
[Epoch 22; Iter   387/ 2483] train: loss: 0.0013851
[Epoch 22; Iter   417/ 2483] train: loss: 0.0020665
[Epoch 22; Iter   447/ 2483] train: loss: 0.0015428
[Epoch 22; Iter   477/ 2483] train: loss: 0.0014676
[Epoch 22; Iter   507/ 2483] train: loss: 0.0024763
[Epoch 22; Iter   537/ 2483] train: loss: 0.0014755
[Epoch 22; Iter   567/ 2483] train: loss: 0.0020806
[Epoch 22; Iter   597/ 2483] train: loss: 0.0027542
[Epoch 22; Iter   627/ 2483] train: loss: 0.0014134
[Epoch 22; Iter   657/ 2483] train: loss: 0.0863916
[Epoch 22; Iter   687/ 2483] train: loss: 0.0012241
[Epoch 22; Iter   717/ 2483] train: loss: 0.0016271
[Epoch 22; Iter   747/ 2483] train: loss: 0.0016061
[Epoch 22; Iter   777/ 2483] train: loss: 0.0892079
[Epoch 22; Iter   807/ 2483] train: loss: 0.0013390
[Epoch 22; Iter   837/ 2483] train: loss: 0.0018537
[Epoch 22; Iter   867/ 2483] train: loss: 0.0022067
[Epoch 22; Iter   897/ 2483] train: loss: 0.0012265
[Epoch 22; Iter   927/ 2483] train: loss: 0.0016461
[Epoch 22; Iter   957/ 2483] train: loss: 0.0024956
[Epoch 22; Iter   987/ 2483] train: loss: 0.0009988
[Epoch 22; Iter  1017/ 2483] train: loss: 0.0012655
[Epoch 22; Iter  1047/ 2483] train: loss: 0.0018278
[Epoch 22; Iter  1077/ 2483] train: loss: 0.0030133
[Epoch 22; Iter  1107/ 2483] train: loss: 0.0014020
[Epoch 22; Iter  1137/ 2483] train: loss: 0.0032579
[Epoch 22; Iter  1167/ 2483] train: loss: 0.0012358
[Epoch 22; Iter  1197/ 2483] train: loss: 0.0024019
[Epoch 22; Iter  1227/ 2483] train: loss: 0.0366545
[Epoch 22; Iter  1257/ 2483] train: loss: 0.0431146
[Epoch 22; Iter  1287/ 2483] train: loss: 0.0019284
[Epoch 22; Iter  1317/ 2483] train: loss: 0.0010629
[Epoch 22; Iter  1347/ 2483] train: loss: 0.0012501
[Epoch 22; Iter  1377/ 2483] train: loss: 0.0995646
[Epoch 22; Iter  1407/ 2483] train: loss: 0.0032474
[Epoch 22; Iter  1437/ 2483] train: loss: 0.0021631
[Epoch 22; Iter  1467/ 2483] train: loss: 0.0015006
[Epoch 22; Iter  1497/ 2483] train: loss: 0.0011016
[Epoch 22; Iter  1527/ 2483] train: loss: 0.0021746
[Epoch 22; Iter  1557/ 2483] train: loss: 0.0008738
[Epoch 22; Iter  1587/ 2483] train: loss: 0.1000345
[Epoch 22; Iter  1617/ 2483] train: loss: 0.0012443
[Epoch 22; Iter  1647/ 2483] train: loss: 0.0016879
[Epoch 22; Iter  1677/ 2483] train: loss: 0.0012677
[Epoch 22; Iter  1707/ 2483] train: loss: 0.0014309
[Epoch 22; Iter  1737/ 2483] train: loss: 0.0015297
[Epoch 22; Iter  1767/ 2483] train: loss: 0.0019707
[Epoch 22; Iter  1797/ 2483] train: loss: 0.0011382
[Epoch 22; Iter  1827/ 2483] train: loss: 0.0014113
[Epoch 22; Iter  1857/ 2483] train: loss: 0.0025017
[Epoch 22; Iter  1887/ 2483] train: loss: 0.0043525
[Epoch 22; Iter  1917/ 2483] train: loss: 0.0015156
[Epoch 22; Iter  1947/ 2483] train: loss: 0.0013604
[Epoch 22; Iter  1977/ 2483] train: loss: 0.0183547
[Epoch 22; Iter  2007/ 2483] train: loss: 0.0013646
[Epoch 22; Iter  2037/ 2483] train: loss: 0.0013317
[Epoch 21; Iter  1380/ 2172] train: loss: 0.0012076
[Epoch 21; Iter  1410/ 2172] train: loss: 0.0014398
[Epoch 21; Iter  1440/ 2172] train: loss: 0.0013857
[Epoch 21; Iter  1470/ 2172] train: loss: 0.0015656
[Epoch 21; Iter  1500/ 2172] train: loss: 0.0011230
[Epoch 21; Iter  1530/ 2172] train: loss: 0.0016963
[Epoch 21; Iter  1560/ 2172] train: loss: 0.0020557
[Epoch 21; Iter  1590/ 2172] train: loss: 0.0014577
[Epoch 21; Iter  1620/ 2172] train: loss: 0.0016515
[Epoch 21; Iter  1650/ 2172] train: loss: 0.0013388
[Epoch 21; Iter  1680/ 2172] train: loss: 0.0020529
[Epoch 21; Iter  1710/ 2172] train: loss: 0.0033865
[Epoch 21; Iter  1740/ 2172] train: loss: 0.1242318
[Epoch 21; Iter  1770/ 2172] train: loss: 0.0070203
[Epoch 21; Iter  1800/ 2172] train: loss: 0.0020250
[Epoch 21; Iter  1830/ 2172] train: loss: 0.0013251
[Epoch 21; Iter  1860/ 2172] train: loss: 0.0028837
[Epoch 21; Iter  1890/ 2172] train: loss: 0.0016789
[Epoch 21; Iter  1920/ 2172] train: loss: 0.0012295
[Epoch 21; Iter  1950/ 2172] train: loss: 0.0054826
[Epoch 21; Iter  1980/ 2172] train: loss: 0.0020470
[Epoch 21; Iter  2010/ 2172] train: loss: 0.0010349
[Epoch 21; Iter  2040/ 2172] train: loss: 0.0014518
[Epoch 21; Iter  2070/ 2172] train: loss: 0.0014147
[Epoch 21; Iter  2100/ 2172] train: loss: 0.0037715
[Epoch 21; Iter  2130/ 2172] train: loss: 0.0016455
[Epoch 21; Iter  2160/ 2172] train: loss: 0.0015473
[Epoch 21] ogbg-molmuv: 0.055707 val loss: 0.051117
[Epoch 21] ogbg-molmuv: 0.090357 test loss: 0.098504
[Epoch 22; Iter    18/ 2172] train: loss: 0.0018538
[Epoch 22; Iter    48/ 2172] train: loss: 0.0014666
[Epoch 22; Iter    78/ 2172] train: loss: 0.0010843
[Epoch 22; Iter   108/ 2172] train: loss: 0.0010919
[Epoch 22; Iter   138/ 2172] train: loss: 0.0011093
[Epoch 22; Iter   168/ 2172] train: loss: 0.0013507
[Epoch 22; Iter   198/ 2172] train: loss: 0.0633824
[Epoch 22; Iter   228/ 2172] train: loss: 0.0023330
[Epoch 22; Iter   258/ 2172] train: loss: 0.0012438
[Epoch 22; Iter   288/ 2172] train: loss: 0.0011040
[Epoch 22; Iter   318/ 2172] train: loss: 0.0020835
[Epoch 22; Iter   348/ 2172] train: loss: 0.0014092
[Epoch 22; Iter   378/ 2172] train: loss: 0.0015419
[Epoch 22; Iter   408/ 2172] train: loss: 0.0019029
[Epoch 22; Iter   438/ 2172] train: loss: 0.0025376
[Epoch 22; Iter   468/ 2172] train: loss: 0.0020536
[Epoch 22; Iter   498/ 2172] train: loss: 0.0016049
[Epoch 22; Iter   528/ 2172] train: loss: 0.0011898
[Epoch 22; Iter   558/ 2172] train: loss: 0.0019692
[Epoch 22; Iter   588/ 2172] train: loss: 0.0195413
[Epoch 22; Iter   618/ 2172] train: loss: 0.0008925
[Epoch 22; Iter   648/ 2172] train: loss: 0.0015942
[Epoch 22; Iter   678/ 2172] train: loss: 0.0024630
[Epoch 22; Iter   708/ 2172] train: loss: 0.0763656
[Epoch 22; Iter   738/ 2172] train: loss: 0.0064341
[Epoch 22; Iter   768/ 2172] train: loss: 0.0025391
[Epoch 22; Iter   798/ 2172] train: loss: 0.0008712
[Epoch 22; Iter   828/ 2172] train: loss: 0.0018829
[Epoch 22; Iter   858/ 2172] train: loss: 0.0011490
[Epoch 22; Iter   888/ 2172] train: loss: 0.0015779
[Epoch 22; Iter   918/ 2172] train: loss: 0.0017239
[Epoch 22; Iter   948/ 2172] train: loss: 0.0023415
[Epoch 22; Iter   978/ 2172] train: loss: 0.0037821
[Epoch 22; Iter  1008/ 2172] train: loss: 0.0046597
[Epoch 22; Iter  1038/ 2172] train: loss: 0.0030882
[Epoch 22; Iter  1068/ 2172] train: loss: 0.0014787
[Epoch 22; Iter  1098/ 2172] train: loss: 0.0035682
[Epoch 22; Iter  1128/ 2172] train: loss: 0.0019239
[Epoch 22; Iter  1158/ 2172] train: loss: 0.0011115
[Epoch 22; Iter  1188/ 2172] train: loss: 0.0033061
[Epoch 22; Iter  1218/ 2172] train: loss: 0.0015871
[Epoch 22; Iter  1248/ 2172] train: loss: 0.0315600
[Epoch 22; Iter  1278/ 2172] train: loss: 0.0028078
[Epoch 22; Iter  1308/ 2172] train: loss: 0.0517639
[Epoch 22; Iter  1338/ 2172] train: loss: 0.0035163
[Epoch 22; Iter  1368/ 2172] train: loss: 0.0025575
[Epoch 22; Iter  1398/ 2172] train: loss: 0.0018761
[Epoch 22; Iter  1428/ 2172] train: loss: 0.1053707
[Epoch 22; Iter  1458/ 2172] train: loss: 0.0015367
[Epoch 22; Iter  1488/ 2172] train: loss: 0.0014539
[Epoch 22; Iter  1518/ 2172] train: loss: 0.0020572
[Epoch 22; Iter  1548/ 2172] train: loss: 0.0015918
[Epoch 22; Iter  1578/ 2172] train: loss: 0.0034995
[Epoch 22; Iter  1608/ 2172] train: loss: 0.0017895
[Epoch 22; Iter  1638/ 2172] train: loss: 0.0025826
[Epoch 22; Iter  1668/ 2172] train: loss: 0.0020020
[Epoch 22; Iter  1698/ 2172] train: loss: 0.0015478
[Epoch 22; Iter  1728/ 2172] train: loss: 0.0653789
[Epoch 22; Iter  1758/ 2172] train: loss: 0.0012746
[Epoch 22; Iter  1788/ 2172] train: loss: 0.0014534
[Epoch 22; Iter  1818/ 2172] train: loss: 0.0020463
[Epoch 22; Iter  1848/ 2172] train: loss: 0.0017172
[Epoch 22; Iter  1878/ 2172] train: loss: 0.0022983
[Epoch 22; Iter  1908/ 2172] train: loss: 0.0014081
[Epoch 22; Iter  1938/ 2172] train: loss: 0.0009799
[Epoch 22; Iter  1968/ 2172] train: loss: 0.0912045
[Epoch 22; Iter  1998/ 2172] train: loss: 0.0014467
[Epoch 22; Iter  2028/ 2172] train: loss: 0.0013146
[Epoch 22; Iter  2058/ 2172] train: loss: 0.0018143
[Epoch 22; Iter  2088/ 2172] train: loss: 0.0018368
[Epoch 22; Iter  2118/ 2172] train: loss: 0.0013398
[Epoch 22; Iter  2148/ 2172] train: loss: 0.0011445
[Epoch 22] ogbg-molmuv: 0.057059 val loss: 0.170518
[Epoch 22] ogbg-molmuv: 0.107536 test loss: 0.157330
[Epoch 23; Iter     6/ 2172] train: loss: 0.0016101
[Epoch 23; Iter    36/ 2172] train: loss: 0.0017632
[Epoch 23; Iter    66/ 2172] train: loss: 0.0022011
[Epoch 23; Iter    96/ 2172] train: loss: 0.0794537
[Epoch 23; Iter   126/ 2172] train: loss: 0.0032209
[Epoch 23; Iter   156/ 2172] train: loss: 0.0024512
[Epoch 23; Iter   186/ 2172] train: loss: 0.0316998
[Epoch 23; Iter   216/ 2172] train: loss: 0.0013703
[Epoch 23; Iter   246/ 2172] train: loss: 0.0569426
[Epoch 23; Iter   276/ 2172] train: loss: 0.0019655
[Epoch 23; Iter   306/ 2172] train: loss: 0.0016646
[Epoch 23; Iter   336/ 2172] train: loss: 0.0014077
[Epoch 23; Iter   366/ 2172] train: loss: 0.0014921
[Epoch 23; Iter   396/ 2172] train: loss: 0.0018518
[Epoch 23; Iter   426/ 2172] train: loss: 0.0012475
[Epoch 23; Iter   456/ 2172] train: loss: 0.0012966
[Epoch 23; Iter   486/ 2172] train: loss: 0.0012185
[Epoch 23; Iter   516/ 2172] train: loss: 0.0014062
[Epoch 23; Iter   546/ 2172] train: loss: 0.0010261
[Epoch 23; Iter   576/ 2172] train: loss: 0.0023160
[Epoch 23; Iter   606/ 2172] train: loss: 0.0564294
[Epoch 23; Iter   636/ 2172] train: loss: 0.0040365
[Epoch 23; Iter   666/ 2172] train: loss: 0.0018557
[Epoch 23; Iter   696/ 2172] train: loss: 0.0010199
[Epoch 23; Iter   726/ 2172] train: loss: 0.0006227
[Epoch 23; Iter   756/ 2172] train: loss: 0.0011751
[Epoch 23; Iter   786/ 2172] train: loss: 0.0011287
[Epoch 23; Iter   816/ 2172] train: loss: 0.0022940
[Epoch 23; Iter   846/ 2172] train: loss: 0.0844351
[Epoch 23; Iter   876/ 2172] train: loss: 0.0012906
[Epoch 23; Iter   906/ 2172] train: loss: 0.0009901
[Epoch 23; Iter   936/ 2172] train: loss: 0.0565887
[Epoch 23; Iter   966/ 2172] train: loss: 0.0038372
[Epoch 23; Iter   996/ 2172] train: loss: 0.0016772
[Epoch 23; Iter  1026/ 2172] train: loss: 0.0010421
[Epoch 23; Iter  1056/ 2172] train: loss: 0.0009449
[Epoch 23; Iter  1086/ 2172] train: loss: 0.0708932
[Epoch 23; Iter  1116/ 2172] train: loss: 0.0016738
[Epoch 23; Iter  1146/ 2172] train: loss: 0.0046831
[Epoch 23; Iter  1176/ 2172] train: loss: 0.0016394
[Epoch 23; Iter  1206/ 2172] train: loss: 0.0024070
[Epoch 23; Iter  1236/ 2172] train: loss: 0.0025325
[Epoch 23; Iter  1266/ 2172] train: loss: 0.0016328
[Epoch 23; Iter  1296/ 2172] train: loss: 0.0014403
[Epoch 23; Iter  1326/ 2172] train: loss: 0.0016736
[Epoch 23; Iter  1356/ 2172] train: loss: 0.0009658
[Epoch 23; Iter  1386/ 2172] train: loss: 0.0015615
[Epoch 23; Iter  1416/ 2172] train: loss: 0.0016545
[Epoch 23; Iter  1446/ 2172] train: loss: 0.0012143
[Epoch 23; Iter  1476/ 2172] train: loss: 0.0593301
[Epoch 23; Iter  1506/ 2172] train: loss: 0.0015610
[Epoch 23; Iter  1536/ 2172] train: loss: 0.0011168
[Epoch 23; Iter  1566/ 2172] train: loss: 0.0011719
[Epoch 23; Iter  1596/ 2172] train: loss: 0.0019512
[Epoch 22; Iter   888/ 1862] train: loss: 0.0014578
[Epoch 22; Iter   918/ 1862] train: loss: 0.0015677
[Epoch 22; Iter   948/ 1862] train: loss: 0.0013718
[Epoch 22; Iter   978/ 1862] train: loss: 0.0771664
[Epoch 22; Iter  1008/ 1862] train: loss: 0.0009393
[Epoch 22; Iter  1038/ 1862] train: loss: 0.0010863
[Epoch 22; Iter  1068/ 1862] train: loss: 0.0761487
[Epoch 22; Iter  1098/ 1862] train: loss: 0.0020966
[Epoch 22; Iter  1128/ 1862] train: loss: 0.0306007
[Epoch 22; Iter  1158/ 1862] train: loss: 0.0415079
[Epoch 22; Iter  1188/ 1862] train: loss: 0.0022945
[Epoch 22; Iter  1218/ 1862] train: loss: 0.0016590
[Epoch 22; Iter  1248/ 1862] train: loss: 0.0018565
[Epoch 22; Iter  1278/ 1862] train: loss: 0.0014101
[Epoch 22; Iter  1308/ 1862] train: loss: 0.0028300
[Epoch 22; Iter  1338/ 1862] train: loss: 0.0049503
[Epoch 22; Iter  1368/ 1862] train: loss: 0.0014251
[Epoch 22; Iter  1398/ 1862] train: loss: 0.0015757
[Epoch 22; Iter  1428/ 1862] train: loss: 0.0014736
[Epoch 22; Iter  1458/ 1862] train: loss: 0.0013859
[Epoch 22; Iter  1488/ 1862] train: loss: 0.0012572
[Epoch 22; Iter  1518/ 1862] train: loss: 0.0403736
[Epoch 22; Iter  1548/ 1862] train: loss: 0.0011432
[Epoch 22; Iter  1578/ 1862] train: loss: 0.0014841
[Epoch 22; Iter  1608/ 1862] train: loss: 0.0025381
[Epoch 22; Iter  1638/ 1862] train: loss: 0.0019620
[Epoch 22; Iter  1668/ 1862] train: loss: 0.0031111
[Epoch 22; Iter  1698/ 1862] train: loss: 0.0034664
[Epoch 22; Iter  1728/ 1862] train: loss: 0.0954795
[Epoch 22; Iter  1758/ 1862] train: loss: 0.0011722
[Epoch 22; Iter  1788/ 1862] train: loss: 0.0017181
[Epoch 22; Iter  1818/ 1862] train: loss: 0.0021573
[Epoch 22; Iter  1848/ 1862] train: loss: 0.0058973
[Epoch 22] ogbg-molmuv: 0.028673 val loss: 0.012998
[Epoch 22] ogbg-molmuv: 0.058714 test loss: 0.012130
[Epoch 23; Iter    16/ 1862] train: loss: 0.0011442
[Epoch 23; Iter    46/ 1862] train: loss: 0.0023903
[Epoch 23; Iter    76/ 1862] train: loss: 0.0017632
[Epoch 23; Iter   106/ 1862] train: loss: 0.0021477
[Epoch 23; Iter   136/ 1862] train: loss: 0.0009268
[Epoch 23; Iter   166/ 1862] train: loss: 0.0011379
[Epoch 23; Iter   196/ 1862] train: loss: 0.0009701
[Epoch 23; Iter   226/ 1862] train: loss: 0.0013934
[Epoch 23; Iter   256/ 1862] train: loss: 0.0012452
[Epoch 23; Iter   286/ 1862] train: loss: 0.0012805
[Epoch 23; Iter   316/ 1862] train: loss: 0.0021413
[Epoch 23; Iter   346/ 1862] train: loss: 0.0016550
[Epoch 23; Iter   376/ 1862] train: loss: 0.0690884
[Epoch 23; Iter   406/ 1862] train: loss: 0.0026597
[Epoch 23; Iter   436/ 1862] train: loss: 0.0032099
[Epoch 23; Iter   466/ 1862] train: loss: 0.0017883
[Epoch 23; Iter   496/ 1862] train: loss: 0.0018731
[Epoch 23; Iter   526/ 1862] train: loss: 0.0507779
[Epoch 23; Iter   556/ 1862] train: loss: 0.0027382
[Epoch 23; Iter   586/ 1862] train: loss: 0.0012803
[Epoch 23; Iter   616/ 1862] train: loss: 0.0012280
[Epoch 23; Iter   646/ 1862] train: loss: 0.0009696
[Epoch 23; Iter   676/ 1862] train: loss: 0.0019117
[Epoch 23; Iter   706/ 1862] train: loss: 0.0026040
[Epoch 23; Iter   736/ 1862] train: loss: 0.0016993
[Epoch 23; Iter   766/ 1862] train: loss: 0.0017161
[Epoch 23; Iter   796/ 1862] train: loss: 0.0015655
[Epoch 23; Iter   826/ 1862] train: loss: 0.0028943
[Epoch 23; Iter   856/ 1862] train: loss: 0.0016185
[Epoch 23; Iter   886/ 1862] train: loss: 0.0028445
[Epoch 23; Iter   916/ 1862] train: loss: 0.0011238
[Epoch 23; Iter   946/ 1862] train: loss: 0.0009512
[Epoch 23; Iter   976/ 1862] train: loss: 0.0013059
[Epoch 23; Iter  1006/ 1862] train: loss: 0.0061061
[Epoch 23; Iter  1036/ 1862] train: loss: 0.0011036
[Epoch 23; Iter  1066/ 1862] train: loss: 0.0015128
[Epoch 23; Iter  1096/ 1862] train: loss: 0.0017682
[Epoch 23; Iter  1126/ 1862] train: loss: 0.0013732
[Epoch 23; Iter  1156/ 1862] train: loss: 0.0013273
[Epoch 23; Iter  1186/ 1862] train: loss: 0.0016236
[Epoch 23; Iter  1216/ 1862] train: loss: 0.0065288
[Epoch 23; Iter  1246/ 1862] train: loss: 0.0015533
[Epoch 23; Iter  1276/ 1862] train: loss: 0.0010516
[Epoch 23; Iter  1306/ 1862] train: loss: 0.0030335
[Epoch 23; Iter  1336/ 1862] train: loss: 0.0012793
[Epoch 23; Iter  1366/ 1862] train: loss: 0.0011876
[Epoch 23; Iter  1396/ 1862] train: loss: 0.0013111
[Epoch 23; Iter  1426/ 1862] train: loss: 0.0024492
[Epoch 23; Iter  1456/ 1862] train: loss: 0.0012640
[Epoch 23; Iter  1486/ 1862] train: loss: 0.1334856
[Epoch 23; Iter  1516/ 1862] train: loss: 0.0016791
[Epoch 23; Iter  1546/ 1862] train: loss: 0.0047416
[Epoch 23; Iter  1576/ 1862] train: loss: 0.0013987
[Epoch 23; Iter  1606/ 1862] train: loss: 0.0014464
[Epoch 23; Iter  1636/ 1862] train: loss: 0.0018314
[Epoch 23; Iter  1666/ 1862] train: loss: 0.0011620
[Epoch 23; Iter  1696/ 1862] train: loss: 0.0011906
[Epoch 23; Iter  1726/ 1862] train: loss: 0.0016063
[Epoch 23; Iter  1756/ 1862] train: loss: 0.0627586
[Epoch 23; Iter  1786/ 1862] train: loss: 0.0042900
[Epoch 23; Iter  1816/ 1862] train: loss: 0.0770234
[Epoch 23; Iter  1846/ 1862] train: loss: 0.0063934
[Epoch 23] ogbg-molmuv: 0.060112 val loss: 0.013004
[Epoch 23] ogbg-molmuv: 0.079261 test loss: 0.012119
[Epoch 24; Iter    14/ 1862] train: loss: 0.0013340
[Epoch 24; Iter    44/ 1862] train: loss: 0.0012890
[Epoch 24; Iter    74/ 1862] train: loss: 0.0803473
[Epoch 24; Iter   104/ 1862] train: loss: 0.0016944
[Epoch 24; Iter   134/ 1862] train: loss: 0.0019012
[Epoch 24; Iter   164/ 1862] train: loss: 0.0016612
[Epoch 24; Iter   194/ 1862] train: loss: 0.0023295
[Epoch 24; Iter   224/ 1862] train: loss: 0.0352126
[Epoch 24; Iter   254/ 1862] train: loss: 0.0395712
[Epoch 24; Iter   284/ 1862] train: loss: 0.0029116
[Epoch 24; Iter   314/ 1862] train: loss: 0.0662194
[Epoch 24; Iter   344/ 1862] train: loss: 0.0019846
[Epoch 24; Iter   374/ 1862] train: loss: 0.0016034
[Epoch 24; Iter   404/ 1862] train: loss: 0.0012450
[Epoch 24; Iter   434/ 1862] train: loss: 0.0568179
[Epoch 24; Iter   464/ 1862] train: loss: 0.0580594
[Epoch 24; Iter   494/ 1862] train: loss: 0.0017006
[Epoch 24; Iter   524/ 1862] train: loss: 0.0014421
[Epoch 24; Iter   554/ 1862] train: loss: 0.0025948
[Epoch 24; Iter   584/ 1862] train: loss: 0.0013081
[Epoch 24; Iter   614/ 1862] train: loss: 0.0025035
[Epoch 24; Iter   644/ 1862] train: loss: 0.0022252
[Epoch 24; Iter   674/ 1862] train: loss: 0.0502454
[Epoch 24; Iter   704/ 1862] train: loss: 0.0037349
[Epoch 24; Iter   734/ 1862] train: loss: 0.0016282
[Epoch 24; Iter   764/ 1862] train: loss: 0.0881803
[Epoch 24; Iter   794/ 1862] train: loss: 0.0015718
[Epoch 24; Iter   824/ 1862] train: loss: 0.0012041
[Epoch 24; Iter   854/ 1862] train: loss: 0.0011228
[Epoch 24; Iter   884/ 1862] train: loss: 0.0019707
[Epoch 24; Iter   914/ 1862] train: loss: 0.0022404
[Epoch 24; Iter   944/ 1862] train: loss: 0.0018023
[Epoch 24; Iter   974/ 1862] train: loss: 0.0018168
[Epoch 24; Iter  1004/ 1862] train: loss: 0.0013181
[Epoch 24; Iter  1034/ 1862] train: loss: 0.0940650
[Epoch 24; Iter  1064/ 1862] train: loss: 0.0012004
[Epoch 24; Iter  1094/ 1862] train: loss: 0.0048130
[Epoch 24; Iter  1124/ 1862] train: loss: 0.0486252
[Epoch 24; Iter  1154/ 1862] train: loss: 0.0012929
[Epoch 24; Iter  1184/ 1862] train: loss: 0.0021055
[Epoch 24; Iter  1214/ 1862] train: loss: 0.0014796
[Epoch 24; Iter  1244/ 1862] train: loss: 0.0021649
[Epoch 24; Iter  1274/ 1862] train: loss: 0.0621219
[Epoch 24; Iter  1304/ 1862] train: loss: 0.0012749
[Epoch 24; Iter  1334/ 1862] train: loss: 0.0016278
[Epoch 24; Iter  1364/ 1862] train: loss: 0.0016443
[Epoch 24; Iter  1394/ 1862] train: loss: 0.0014009
[Epoch 24; Iter  1424/ 1862] train: loss: 0.0490014
[Epoch 24; Iter  1454/ 1862] train: loss: 0.0032320
[Epoch 24; Iter  1484/ 1862] train: loss: 0.0021833
[Epoch 24; Iter  1514/ 1862] train: loss: 0.0025093
[Epoch 24; Iter  1544/ 1862] train: loss: 0.0008829
[Epoch 24; Iter  1574/ 1862] train: loss: 0.0013401
[Epoch 24; Iter  1604/ 1862] train: loss: 0.0034761
[Epoch 24; Iter  1634/ 1862] train: loss: 0.0026829
[Epoch 24; Iter  1664/ 1862] train: loss: 0.0011287
[Epoch 24; Iter  1694/ 1862] train: loss: 0.0019232
[Epoch 24; Iter  1724/ 1862] train: loss: 0.0012338
[Epoch 21; Iter  1380/ 2172] train: loss: 0.0051523
[Epoch 21; Iter  1410/ 2172] train: loss: 0.0020099
[Epoch 21; Iter  1440/ 2172] train: loss: 0.0015733
[Epoch 21; Iter  1470/ 2172] train: loss: 0.0019251
[Epoch 21; Iter  1500/ 2172] train: loss: 0.0012866
[Epoch 21; Iter  1530/ 2172] train: loss: 0.0016676
[Epoch 21; Iter  1560/ 2172] train: loss: 0.0011455
[Epoch 21; Iter  1590/ 2172] train: loss: 0.0029054
[Epoch 21; Iter  1620/ 2172] train: loss: 0.0013851
[Epoch 21; Iter  1650/ 2172] train: loss: 0.0014963
[Epoch 21; Iter  1680/ 2172] train: loss: 0.0023990
[Epoch 21; Iter  1710/ 2172] train: loss: 0.0013758
[Epoch 21; Iter  1740/ 2172] train: loss: 0.0486543
[Epoch 21; Iter  1770/ 2172] train: loss: 0.0011134
[Epoch 21; Iter  1800/ 2172] train: loss: 0.0012381
[Epoch 21; Iter  1830/ 2172] train: loss: 0.0016359
[Epoch 21; Iter  1860/ 2172] train: loss: 0.0013761
[Epoch 21; Iter  1890/ 2172] train: loss: 0.0016719
[Epoch 21; Iter  1920/ 2172] train: loss: 0.0015197
[Epoch 21; Iter  1950/ 2172] train: loss: 0.0033153
[Epoch 21; Iter  1980/ 2172] train: loss: 0.0017191
[Epoch 21; Iter  2010/ 2172] train: loss: 0.0012049
[Epoch 21; Iter  2040/ 2172] train: loss: 0.0007986
[Epoch 21; Iter  2070/ 2172] train: loss: 0.0018108
[Epoch 21; Iter  2100/ 2172] train: loss: 0.0015764
[Epoch 21; Iter  2130/ 2172] train: loss: 0.0095862
[Epoch 21; Iter  2160/ 2172] train: loss: 0.0013827
[Epoch 21] ogbg-molmuv: 0.033024 val loss: 0.016666
[Epoch 21] ogbg-molmuv: 0.088029 test loss: 0.028363
[Epoch 22; Iter    18/ 2172] train: loss: 0.0010021
[Epoch 22; Iter    48/ 2172] train: loss: 0.0011309
[Epoch 22; Iter    78/ 2172] train: loss: 0.0009860
[Epoch 22; Iter   108/ 2172] train: loss: 0.0021954
[Epoch 22; Iter   138/ 2172] train: loss: 0.0020824
[Epoch 22; Iter   168/ 2172] train: loss: 0.0047953
[Epoch 22; Iter   198/ 2172] train: loss: 0.0023639
[Epoch 22; Iter   228/ 2172] train: loss: 0.0014349
[Epoch 22; Iter   258/ 2172] train: loss: 0.0011119
[Epoch 22; Iter   288/ 2172] train: loss: 0.0021819
[Epoch 22; Iter   318/ 2172] train: loss: 0.0015239
[Epoch 22; Iter   348/ 2172] train: loss: 0.0070720
[Epoch 22; Iter   378/ 2172] train: loss: 0.0015861
[Epoch 22; Iter   408/ 2172] train: loss: 0.0016799
[Epoch 22; Iter   438/ 2172] train: loss: 0.0012177
[Epoch 22; Iter   468/ 2172] train: loss: 0.0012762
[Epoch 22; Iter   498/ 2172] train: loss: 0.0015606
[Epoch 22; Iter   528/ 2172] train: loss: 0.0683122
[Epoch 22; Iter   558/ 2172] train: loss: 0.0021214
[Epoch 22; Iter   588/ 2172] train: loss: 0.0021952
[Epoch 22; Iter   618/ 2172] train: loss: 0.0023412
[Epoch 22; Iter   648/ 2172] train: loss: 0.0012937
[Epoch 22; Iter   678/ 2172] train: loss: 0.0028112
[Epoch 22; Iter   708/ 2172] train: loss: 0.0009521
[Epoch 22; Iter   738/ 2172] train: loss: 0.0011014
[Epoch 22; Iter   768/ 2172] train: loss: 0.0017661
[Epoch 22; Iter   798/ 2172] train: loss: 0.0731211
[Epoch 22; Iter   828/ 2172] train: loss: 0.0014042
[Epoch 22; Iter   858/ 2172] train: loss: 0.0008136
[Epoch 22; Iter   888/ 2172] train: loss: 0.0020774
[Epoch 22; Iter   918/ 2172] train: loss: 0.0012300
[Epoch 22; Iter   948/ 2172] train: loss: 0.0011479
[Epoch 22; Iter   978/ 2172] train: loss: 0.0010497
[Epoch 22; Iter  1008/ 2172] train: loss: 0.0013835
[Epoch 22; Iter  1038/ 2172] train: loss: 0.0015120
[Epoch 22; Iter  1068/ 2172] train: loss: 0.0021977
[Epoch 22; Iter  1098/ 2172] train: loss: 0.0018900
[Epoch 22; Iter  1128/ 2172] train: loss: 0.0011446
[Epoch 22; Iter  1158/ 2172] train: loss: 0.1204442
[Epoch 22; Iter  1188/ 2172] train: loss: 0.0010162
[Epoch 22; Iter  1218/ 2172] train: loss: 0.0011580
[Epoch 22; Iter  1248/ 2172] train: loss: 0.0012934
[Epoch 22; Iter  1278/ 2172] train: loss: 0.0019452
[Epoch 22; Iter  1308/ 2172] train: loss: 0.0011666
[Epoch 22; Iter  1338/ 2172] train: loss: 0.0409443
[Epoch 22; Iter  1368/ 2172] train: loss: 0.0024812
[Epoch 22; Iter  1398/ 2172] train: loss: 0.0021510
[Epoch 22; Iter  1428/ 2172] train: loss: 0.0013662
[Epoch 22; Iter  1458/ 2172] train: loss: 0.0010672
[Epoch 22; Iter  1488/ 2172] train: loss: 0.0020649
[Epoch 22; Iter  1518/ 2172] train: loss: 0.0012320
[Epoch 22; Iter  1548/ 2172] train: loss: 0.0012076
[Epoch 22; Iter  1578/ 2172] train: loss: 0.0014215
[Epoch 22; Iter  1608/ 2172] train: loss: 0.0010041
[Epoch 22; Iter  1638/ 2172] train: loss: 0.0017842
[Epoch 22; Iter  1668/ 2172] train: loss: 0.0011973
[Epoch 22; Iter  1698/ 2172] train: loss: 0.0014792
[Epoch 22; Iter  1728/ 2172] train: loss: 0.0909217
[Epoch 22; Iter  1758/ 2172] train: loss: 0.0020042
[Epoch 22; Iter  1788/ 2172] train: loss: 0.0014737
[Epoch 22; Iter  1818/ 2172] train: loss: 0.0642255
[Epoch 22; Iter  1848/ 2172] train: loss: 0.0886419
[Epoch 22; Iter  1878/ 2172] train: loss: 0.0033183
[Epoch 22; Iter  1908/ 2172] train: loss: 0.0020562
[Epoch 22; Iter  1938/ 2172] train: loss: 0.0012686
[Epoch 22; Iter  1968/ 2172] train: loss: 0.0011652
[Epoch 22; Iter  1998/ 2172] train: loss: 0.0021242
[Epoch 22; Iter  2028/ 2172] train: loss: 0.0021998
[Epoch 22; Iter  2058/ 2172] train: loss: 0.0025868
[Epoch 22; Iter  2088/ 2172] train: loss: 0.0614540
[Epoch 22; Iter  2118/ 2172] train: loss: 0.0025001
[Epoch 22; Iter  2148/ 2172] train: loss: 0.0370081
[Epoch 22] ogbg-molmuv: 0.050184 val loss: 0.073923
[Epoch 22] ogbg-molmuv: 0.125096 test loss: 0.043592
[Epoch 23; Iter     6/ 2172] train: loss: 0.0022520
[Epoch 23; Iter    36/ 2172] train: loss: 0.0017444
[Epoch 23; Iter    66/ 2172] train: loss: 0.0012185
[Epoch 23; Iter    96/ 2172] train: loss: 0.0014175
[Epoch 23; Iter   126/ 2172] train: loss: 0.0016891
[Epoch 23; Iter   156/ 2172] train: loss: 0.0016834
[Epoch 23; Iter   186/ 2172] train: loss: 0.0032476
[Epoch 23; Iter   216/ 2172] train: loss: 0.0012907
[Epoch 23; Iter   246/ 2172] train: loss: 0.0707038
[Epoch 23; Iter   276/ 2172] train: loss: 0.0011887
[Epoch 23; Iter   306/ 2172] train: loss: 0.0022953
[Epoch 23; Iter   336/ 2172] train: loss: 0.0023571
[Epoch 23; Iter   366/ 2172] train: loss: 0.0012573
[Epoch 23; Iter   396/ 2172] train: loss: 0.0018311
[Epoch 23; Iter   426/ 2172] train: loss: 0.0012861
[Epoch 23; Iter   456/ 2172] train: loss: 0.0010581
[Epoch 23; Iter   486/ 2172] train: loss: 0.0011069
[Epoch 23; Iter   516/ 2172] train: loss: 0.0013275
[Epoch 23; Iter   546/ 2172] train: loss: 0.0010524
[Epoch 23; Iter   576/ 2172] train: loss: 0.0012361
[Epoch 23; Iter   606/ 2172] train: loss: 0.0166588
[Epoch 23; Iter   636/ 2172] train: loss: 0.0015222
[Epoch 23; Iter   666/ 2172] train: loss: 0.0551214
[Epoch 23; Iter   696/ 2172] train: loss: 0.0567505
[Epoch 23; Iter   726/ 2172] train: loss: 0.0025338
[Epoch 23; Iter   756/ 2172] train: loss: 0.0030740
[Epoch 23; Iter   786/ 2172] train: loss: 0.0016163
[Epoch 23; Iter   816/ 2172] train: loss: 0.0024225
[Epoch 23; Iter   846/ 2172] train: loss: 0.0017034
[Epoch 23; Iter   876/ 2172] train: loss: 0.0015766
[Epoch 23; Iter   906/ 2172] train: loss: 0.0011964
[Epoch 23; Iter   936/ 2172] train: loss: 0.0013787
[Epoch 23; Iter   966/ 2172] train: loss: 0.0007456
[Epoch 23; Iter   996/ 2172] train: loss: 0.0013208
[Epoch 23; Iter  1026/ 2172] train: loss: 0.0013098
[Epoch 23; Iter  1056/ 2172] train: loss: 0.0016552
[Epoch 23; Iter  1086/ 2172] train: loss: 0.0012237
[Epoch 23; Iter  1116/ 2172] train: loss: 0.0017614
[Epoch 23; Iter  1146/ 2172] train: loss: 0.0485492
[Epoch 23; Iter  1176/ 2172] train: loss: 0.0030417
[Epoch 23; Iter  1206/ 2172] train: loss: 0.0025549
[Epoch 23; Iter  1236/ 2172] train: loss: 0.0022248
[Epoch 23; Iter  1266/ 2172] train: loss: 0.0022005
[Epoch 23; Iter  1296/ 2172] train: loss: 0.0020437
[Epoch 23; Iter  1326/ 2172] train: loss: 0.0035124
[Epoch 23; Iter  1356/ 2172] train: loss: 0.0019558
[Epoch 23; Iter  1386/ 2172] train: loss: 0.0016374
[Epoch 23; Iter  1416/ 2172] train: loss: 0.0018803
[Epoch 23; Iter  1446/ 2172] train: loss: 0.0013060
[Epoch 23; Iter  1476/ 2172] train: loss: 0.0040663
[Epoch 23; Iter  1506/ 2172] train: loss: 0.0028865
[Epoch 23; Iter  1536/ 2172] train: loss: 0.0016607
[Epoch 23; Iter  1566/ 2172] train: loss: 0.0023218
[Epoch 23; Iter  1596/ 2172] train: loss: 0.0538752
[Epoch 21; Iter  1380/ 2172] train: loss: 0.0016433
[Epoch 21; Iter  1410/ 2172] train: loss: 0.0014679
[Epoch 21; Iter  1440/ 2172] train: loss: 0.0812497
[Epoch 21; Iter  1470/ 2172] train: loss: 0.0021121
[Epoch 21; Iter  1500/ 2172] train: loss: 0.0018301
[Epoch 21; Iter  1530/ 2172] train: loss: 0.0010977
[Epoch 21; Iter  1560/ 2172] train: loss: 0.0755879
[Epoch 21; Iter  1590/ 2172] train: loss: 0.0018273
[Epoch 21; Iter  1620/ 2172] train: loss: 0.0013760
[Epoch 21; Iter  1650/ 2172] train: loss: 0.0014128
[Epoch 21; Iter  1680/ 2172] train: loss: 0.0009060
[Epoch 21; Iter  1710/ 2172] train: loss: 0.0018372
[Epoch 21; Iter  1740/ 2172] train: loss: 0.0015360
[Epoch 21; Iter  1770/ 2172] train: loss: 0.0010559
[Epoch 21; Iter  1800/ 2172] train: loss: 0.0796728
[Epoch 21; Iter  1830/ 2172] train: loss: 0.0514425
[Epoch 21; Iter  1860/ 2172] train: loss: 0.0033954
[Epoch 21; Iter  1890/ 2172] train: loss: 0.0020390
[Epoch 21; Iter  1920/ 2172] train: loss: 0.0023396
[Epoch 21; Iter  1950/ 2172] train: loss: 0.0042003
[Epoch 21; Iter  1980/ 2172] train: loss: 0.0015794
[Epoch 21; Iter  2010/ 2172] train: loss: 0.0013217
[Epoch 21; Iter  2040/ 2172] train: loss: 0.0020411
[Epoch 21; Iter  2070/ 2172] train: loss: 0.0016867
[Epoch 21; Iter  2100/ 2172] train: loss: 0.0015957
[Epoch 21; Iter  2130/ 2172] train: loss: 0.0965761
[Epoch 21; Iter  2160/ 2172] train: loss: 0.0028687
[Epoch 21] ogbg-molmuv: 0.046246 val loss: 0.093221
[Epoch 21] ogbg-molmuv: 0.095499 test loss: 0.023450
[Epoch 22; Iter    18/ 2172] train: loss: 0.0017210
[Epoch 22; Iter    48/ 2172] train: loss: 0.0028502
[Epoch 22; Iter    78/ 2172] train: loss: 0.0011304
[Epoch 22; Iter   108/ 2172] train: loss: 0.0018606
[Epoch 22; Iter   138/ 2172] train: loss: 0.0019407
[Epoch 22; Iter   168/ 2172] train: loss: 0.0031905
[Epoch 22; Iter   198/ 2172] train: loss: 0.0013171
[Epoch 22; Iter   228/ 2172] train: loss: 0.0016708
[Epoch 22; Iter   258/ 2172] train: loss: 0.0023350
[Epoch 22; Iter   288/ 2172] train: loss: 0.0015907
[Epoch 22; Iter   318/ 2172] train: loss: 0.0015361
[Epoch 22; Iter   348/ 2172] train: loss: 0.0024052
[Epoch 22; Iter   378/ 2172] train: loss: 0.0025067
[Epoch 22; Iter   408/ 2172] train: loss: 0.0019411
[Epoch 22; Iter   438/ 2172] train: loss: 0.0025425
[Epoch 22; Iter   468/ 2172] train: loss: 0.0605565
[Epoch 22; Iter   498/ 2172] train: loss: 0.0013070
[Epoch 22; Iter   528/ 2172] train: loss: 0.0026306
[Epoch 22; Iter   558/ 2172] train: loss: 0.0014145
[Epoch 22; Iter   588/ 2172] train: loss: 0.0028811
[Epoch 22; Iter   618/ 2172] train: loss: 0.0015302
[Epoch 22; Iter   648/ 2172] train: loss: 0.0015692
[Epoch 22; Iter   678/ 2172] train: loss: 0.0012779
[Epoch 22; Iter   708/ 2172] train: loss: 0.0693518
[Epoch 22; Iter   738/ 2172] train: loss: 0.0017114
[Epoch 22; Iter   768/ 2172] train: loss: 0.0022150
[Epoch 22; Iter   798/ 2172] train: loss: 0.0017131
[Epoch 22; Iter   828/ 2172] train: loss: 0.0024448
[Epoch 22; Iter   858/ 2172] train: loss: 0.0020745
[Epoch 22; Iter   888/ 2172] train: loss: 0.0022098
[Epoch 22; Iter   918/ 2172] train: loss: 0.0016586
[Epoch 22; Iter   948/ 2172] train: loss: 0.0010866
[Epoch 22; Iter   978/ 2172] train: loss: 0.0010007
[Epoch 22; Iter  1008/ 2172] train: loss: 0.0014456
[Epoch 22; Iter  1038/ 2172] train: loss: 0.0739750
[Epoch 22; Iter  1068/ 2172] train: loss: 0.0010013
[Epoch 22; Iter  1098/ 2172] train: loss: 0.0016694
[Epoch 22; Iter  1128/ 2172] train: loss: 0.0675431
[Epoch 22; Iter  1158/ 2172] train: loss: 0.0810549
[Epoch 22; Iter  1188/ 2172] train: loss: 0.0019926
[Epoch 22; Iter  1218/ 2172] train: loss: 0.0019701
[Epoch 22; Iter  1248/ 2172] train: loss: 0.0016252
[Epoch 22; Iter  1278/ 2172] train: loss: 0.0020122
[Epoch 22; Iter  1308/ 2172] train: loss: 0.0023091
[Epoch 22; Iter  1338/ 2172] train: loss: 0.0724924
[Epoch 22; Iter  1368/ 2172] train: loss: 0.0025794
[Epoch 22; Iter  1398/ 2172] train: loss: 0.0013058
[Epoch 22; Iter  1428/ 2172] train: loss: 0.0032605
[Epoch 22; Iter  1458/ 2172] train: loss: 0.0026754
[Epoch 22; Iter  1488/ 2172] train: loss: 0.0013131
[Epoch 22; Iter  1518/ 2172] train: loss: 0.0012040
[Epoch 22; Iter  1548/ 2172] train: loss: 0.0015713
[Epoch 22; Iter  1578/ 2172] train: loss: 0.0014672
[Epoch 22; Iter  1608/ 2172] train: loss: 0.0017169
[Epoch 22; Iter  1638/ 2172] train: loss: 0.0011663
[Epoch 22; Iter  1668/ 2172] train: loss: 0.0021635
[Epoch 22; Iter  1698/ 2172] train: loss: 0.0020344
[Epoch 22; Iter  1728/ 2172] train: loss: 0.0019605
[Epoch 22; Iter  1758/ 2172] train: loss: 0.0016638
[Epoch 22; Iter  1788/ 2172] train: loss: 0.0029860
[Epoch 22; Iter  1818/ 2172] train: loss: 0.0426017
[Epoch 22; Iter  1848/ 2172] train: loss: 0.0019030
[Epoch 22; Iter  1878/ 2172] train: loss: 0.0020876
[Epoch 22; Iter  1908/ 2172] train: loss: 0.0131423
[Epoch 22; Iter  1938/ 2172] train: loss: 0.0027576
[Epoch 22; Iter  1968/ 2172] train: loss: 0.0019775
[Epoch 22; Iter  1998/ 2172] train: loss: 0.0020651
[Epoch 22; Iter  2028/ 2172] train: loss: 0.0016224
[Epoch 22; Iter  2058/ 2172] train: loss: 0.0829426
[Epoch 22; Iter  2088/ 2172] train: loss: 0.0016926
[Epoch 22; Iter  2118/ 2172] train: loss: 0.0012337
[Epoch 22; Iter  2148/ 2172] train: loss: 0.0013228
[Epoch 22] ogbg-molmuv: 0.029808 val loss: 0.214122
[Epoch 22] ogbg-molmuv: 0.081329 test loss: 0.105895
[Epoch 23; Iter     6/ 2172] train: loss: 0.0013924
[Epoch 23; Iter    36/ 2172] train: loss: 0.0016973
[Epoch 23; Iter    66/ 2172] train: loss: 0.0021088
[Epoch 23; Iter    96/ 2172] train: loss: 0.0016280
[Epoch 23; Iter   126/ 2172] train: loss: 0.0014507
[Epoch 23; Iter   156/ 2172] train: loss: 0.0020746
[Epoch 23; Iter   186/ 2172] train: loss: 0.0612835
[Epoch 23; Iter   216/ 2172] train: loss: 0.0420595
[Epoch 23; Iter   246/ 2172] train: loss: 0.0029008
[Epoch 23; Iter   276/ 2172] train: loss: 0.0014054
[Epoch 23; Iter   306/ 2172] train: loss: 0.0015837
[Epoch 23; Iter   336/ 2172] train: loss: 0.0023749
[Epoch 23; Iter   366/ 2172] train: loss: 0.0031122
[Epoch 23; Iter   396/ 2172] train: loss: 0.0446221
[Epoch 23; Iter   426/ 2172] train: loss: 0.0017998
[Epoch 23; Iter   456/ 2172] train: loss: 0.0014093
[Epoch 23; Iter   486/ 2172] train: loss: 0.0019825
[Epoch 23; Iter   516/ 2172] train: loss: 0.0681106
[Epoch 23; Iter   546/ 2172] train: loss: 0.0013480
[Epoch 23; Iter   576/ 2172] train: loss: 0.0015121
[Epoch 23; Iter   606/ 2172] train: loss: 0.0021111
[Epoch 23; Iter   636/ 2172] train: loss: 0.0016270
[Epoch 23; Iter   666/ 2172] train: loss: 0.0023929
[Epoch 23; Iter   696/ 2172] train: loss: 0.0014686
[Epoch 23; Iter   726/ 2172] train: loss: 0.0061107
[Epoch 23; Iter   756/ 2172] train: loss: 0.0162739
[Epoch 23; Iter   786/ 2172] train: loss: 0.0016355
[Epoch 23; Iter   816/ 2172] train: loss: 0.0015319
[Epoch 23; Iter   846/ 2172] train: loss: 0.0020021
[Epoch 23; Iter   876/ 2172] train: loss: 0.0019591
[Epoch 23; Iter   906/ 2172] train: loss: 0.0017289
[Epoch 23; Iter   936/ 2172] train: loss: 0.0012468
[Epoch 23; Iter   966/ 2172] train: loss: 0.0010840
[Epoch 23; Iter   996/ 2172] train: loss: 0.0615363
[Epoch 23; Iter  1026/ 2172] train: loss: 0.0021548
[Epoch 23; Iter  1056/ 2172] train: loss: 0.0529949
[Epoch 23; Iter  1086/ 2172] train: loss: 0.0024704
[Epoch 23; Iter  1116/ 2172] train: loss: 0.0018229
[Epoch 23; Iter  1146/ 2172] train: loss: 0.0021879
[Epoch 23; Iter  1176/ 2172] train: loss: 0.0014682
[Epoch 23; Iter  1206/ 2172] train: loss: 0.0012282
[Epoch 23; Iter  1236/ 2172] train: loss: 0.0010567
[Epoch 23; Iter  1266/ 2172] train: loss: 0.0016568
[Epoch 23; Iter  1296/ 2172] train: loss: 0.0014016
[Epoch 23; Iter  1326/ 2172] train: loss: 0.0013849
[Epoch 23; Iter  1356/ 2172] train: loss: 0.0009295
[Epoch 23; Iter  1386/ 2172] train: loss: 0.0010046
[Epoch 23; Iter  1416/ 2172] train: loss: 0.0012895
[Epoch 23; Iter  1446/ 2172] train: loss: 0.0009575
[Epoch 23; Iter  1476/ 2172] train: loss: 0.0013084
[Epoch 23; Iter  1506/ 2172] train: loss: 0.0014546
[Epoch 23; Iter  1536/ 2172] train: loss: 0.0019074
[Epoch 23; Iter  1566/ 2172] train: loss: 0.0013766
[Epoch 23; Iter  1596/ 2172] train: loss: 0.0034502
[Epoch 20; Iter  2443/ 2483] train: loss: 0.0085785
[Epoch 20; Iter  2473/ 2483] train: loss: 0.0633020
[Epoch 20] ogbg-molmuv: 0.108572 val loss: 0.009398
[Epoch 20] ogbg-molmuv: 0.124305 test loss: 0.013811
[Epoch 21; Iter    20/ 2483] train: loss: 0.0028022
[Epoch 21; Iter    50/ 2483] train: loss: 0.0016258
[Epoch 21; Iter    80/ 2483] train: loss: 0.0013849
[Epoch 21; Iter   110/ 2483] train: loss: 0.0018650
[Epoch 21; Iter   140/ 2483] train: loss: 0.0024123
[Epoch 21; Iter   170/ 2483] train: loss: 0.0020214
[Epoch 21; Iter   200/ 2483] train: loss: 0.0048983
[Epoch 21; Iter   230/ 2483] train: loss: 0.0707541
[Epoch 21; Iter   260/ 2483] train: loss: 0.0017909
[Epoch 21; Iter   290/ 2483] train: loss: 0.0518620
[Epoch 21; Iter   320/ 2483] train: loss: 0.0018682
[Epoch 21; Iter   350/ 2483] train: loss: 0.0472218
[Epoch 21; Iter   380/ 2483] train: loss: 0.0023996
[Epoch 21; Iter   410/ 2483] train: loss: 0.0027465
[Epoch 21; Iter   440/ 2483] train: loss: 0.0019683
[Epoch 21; Iter   470/ 2483] train: loss: 0.0011297
[Epoch 21; Iter   500/ 2483] train: loss: 0.0251373
[Epoch 21; Iter   530/ 2483] train: loss: 0.0012780
[Epoch 21; Iter   560/ 2483] train: loss: 0.0559216
[Epoch 21; Iter   590/ 2483] train: loss: 0.0029330
[Epoch 21; Iter   620/ 2483] train: loss: 0.0011616
[Epoch 21; Iter   650/ 2483] train: loss: 0.0010293
[Epoch 21; Iter   680/ 2483] train: loss: 0.0017012
[Epoch 21; Iter   710/ 2483] train: loss: 0.0954412
[Epoch 21; Iter   740/ 2483] train: loss: 0.0019019
[Epoch 21; Iter   770/ 2483] train: loss: 0.0016951
[Epoch 21; Iter   800/ 2483] train: loss: 0.0027363
[Epoch 21; Iter   830/ 2483] train: loss: 0.0714967
[Epoch 21; Iter   860/ 2483] train: loss: 0.0062265
[Epoch 21; Iter   890/ 2483] train: loss: 0.0010989
[Epoch 21; Iter   920/ 2483] train: loss: 0.0017079
[Epoch 21; Iter   950/ 2483] train: loss: 0.0018370
[Epoch 21; Iter   980/ 2483] train: loss: 0.0922734
[Epoch 21; Iter  1010/ 2483] train: loss: 0.0011770
[Epoch 21; Iter  1040/ 2483] train: loss: 0.0016868
[Epoch 21; Iter  1070/ 2483] train: loss: 0.0010931
[Epoch 21; Iter  1100/ 2483] train: loss: 0.0019837
[Epoch 21; Iter  1130/ 2483] train: loss: 0.0012994
[Epoch 21; Iter  1160/ 2483] train: loss: 0.0762308
[Epoch 21; Iter  1190/ 2483] train: loss: 0.0015207
[Epoch 21; Iter  1220/ 2483] train: loss: 0.0080140
[Epoch 21; Iter  1250/ 2483] train: loss: 0.0027145
[Epoch 21; Iter  1280/ 2483] train: loss: 0.0017701
[Epoch 21; Iter  1310/ 2483] train: loss: 0.0014543
[Epoch 21; Iter  1340/ 2483] train: loss: 0.0013431
[Epoch 21; Iter  1370/ 2483] train: loss: 0.0015640
[Epoch 21; Iter  1400/ 2483] train: loss: 0.0012504
[Epoch 21; Iter  1430/ 2483] train: loss: 0.0014895
[Epoch 21; Iter  1460/ 2483] train: loss: 0.0011117
[Epoch 21; Iter  1490/ 2483] train: loss: 0.0018397
[Epoch 21; Iter  1520/ 2483] train: loss: 0.0015064
[Epoch 21; Iter  1550/ 2483] train: loss: 0.0012331
[Epoch 21; Iter  1580/ 2483] train: loss: 0.0016122
[Epoch 21; Iter  1610/ 2483] train: loss: 0.0020537
[Epoch 21; Iter  1640/ 2483] train: loss: 0.0025434
[Epoch 21; Iter  1670/ 2483] train: loss: 0.0022116
[Epoch 21; Iter  1700/ 2483] train: loss: 0.0013261
[Epoch 21; Iter  1730/ 2483] train: loss: 0.0020757
[Epoch 21; Iter  1760/ 2483] train: loss: 0.0607848
[Epoch 21; Iter  1790/ 2483] train: loss: 0.0678016
[Epoch 21; Iter  1820/ 2483] train: loss: 0.0016764
[Epoch 21; Iter  1850/ 2483] train: loss: 0.0018103
[Epoch 21; Iter  1880/ 2483] train: loss: 0.0526001
[Epoch 21; Iter  1910/ 2483] train: loss: 0.0018489
[Epoch 21; Iter  1940/ 2483] train: loss: 0.0008950
[Epoch 21; Iter  1970/ 2483] train: loss: 0.0011028
[Epoch 21; Iter  2000/ 2483] train: loss: 0.0013259
[Epoch 21; Iter  2030/ 2483] train: loss: 0.0014998
[Epoch 21; Iter  2060/ 2483] train: loss: 0.0014275
[Epoch 21; Iter  2090/ 2483] train: loss: 0.0024236
[Epoch 21; Iter  2120/ 2483] train: loss: 0.0028143
[Epoch 21; Iter  2150/ 2483] train: loss: 0.0012246
[Epoch 21; Iter  2180/ 2483] train: loss: 0.0013734
[Epoch 21; Iter  2210/ 2483] train: loss: 0.0016331
[Epoch 21; Iter  2240/ 2483] train: loss: 0.0010560
[Epoch 21; Iter  2270/ 2483] train: loss: 0.0011188
[Epoch 21; Iter  2300/ 2483] train: loss: 0.0016861
[Epoch 21; Iter  2330/ 2483] train: loss: 0.0021912
[Epoch 21; Iter  2360/ 2483] train: loss: 0.0019662
[Epoch 21; Iter  2390/ 2483] train: loss: 0.0017711
[Epoch 21; Iter  2420/ 2483] train: loss: 0.0012761
[Epoch 21; Iter  2450/ 2483] train: loss: 0.0028269
[Epoch 21; Iter  2480/ 2483] train: loss: 0.0022171
[Epoch 21] ogbg-molmuv: 0.130746 val loss: 0.009752
[Epoch 21] ogbg-molmuv: 0.133551 test loss: 0.013578
[Epoch 22; Iter    27/ 2483] train: loss: 0.0042846
[Epoch 22; Iter    57/ 2483] train: loss: 0.0016512
[Epoch 22; Iter    87/ 2483] train: loss: 0.0024119
[Epoch 22; Iter   117/ 2483] train: loss: 0.0013923
[Epoch 22; Iter   147/ 2483] train: loss: 0.0017973
[Epoch 22; Iter   177/ 2483] train: loss: 0.0876868
[Epoch 22; Iter   207/ 2483] train: loss: 0.0013427
[Epoch 22; Iter   237/ 2483] train: loss: 0.0013593
[Epoch 22; Iter   267/ 2483] train: loss: 0.0642101
[Epoch 22; Iter   297/ 2483] train: loss: 0.0015619
[Epoch 22; Iter   327/ 2483] train: loss: 0.0007799
[Epoch 22; Iter   357/ 2483] train: loss: 0.0009166
[Epoch 22; Iter   387/ 2483] train: loss: 0.0008142
[Epoch 22; Iter   417/ 2483] train: loss: 0.0755459
[Epoch 22; Iter   447/ 2483] train: loss: 0.0225658
[Epoch 22; Iter   477/ 2483] train: loss: 0.0021174
[Epoch 22; Iter   507/ 2483] train: loss: 0.0007756
[Epoch 22; Iter   537/ 2483] train: loss: 0.0013023
[Epoch 22; Iter   567/ 2483] train: loss: 0.0009694
[Epoch 22; Iter   597/ 2483] train: loss: 0.0043522
[Epoch 22; Iter   627/ 2483] train: loss: 0.0013751
[Epoch 22; Iter   657/ 2483] train: loss: 0.0018829
[Epoch 22; Iter   687/ 2483] train: loss: 0.0048753
[Epoch 22; Iter   717/ 2483] train: loss: 0.0009355
[Epoch 22; Iter   747/ 2483] train: loss: 0.0011730
[Epoch 22; Iter   777/ 2483] train: loss: 0.0012398
[Epoch 22; Iter   807/ 2483] train: loss: 0.0753665
[Epoch 22; Iter   837/ 2483] train: loss: 0.0012872
[Epoch 22; Iter   867/ 2483] train: loss: 0.0011325
[Epoch 22; Iter   897/ 2483] train: loss: 0.1079019
[Epoch 22; Iter   927/ 2483] train: loss: 0.0016424
[Epoch 22; Iter   957/ 2483] train: loss: 0.0019345
[Epoch 22; Iter   987/ 2483] train: loss: 0.0015253
[Epoch 22; Iter  1017/ 2483] train: loss: 0.0016669
[Epoch 22; Iter  1047/ 2483] train: loss: 0.0015684
[Epoch 22; Iter  1077/ 2483] train: loss: 0.0015326
[Epoch 22; Iter  1107/ 2483] train: loss: 0.0017389
[Epoch 22; Iter  1137/ 2483] train: loss: 0.0012488
[Epoch 22; Iter  1167/ 2483] train: loss: 0.0580611
[Epoch 22; Iter  1197/ 2483] train: loss: 0.0016865
[Epoch 22; Iter  1227/ 2483] train: loss: 0.0010057
[Epoch 22; Iter  1257/ 2483] train: loss: 0.0011494
[Epoch 22; Iter  1287/ 2483] train: loss: 0.0011787
[Epoch 22; Iter  1317/ 2483] train: loss: 0.0010358
[Epoch 22; Iter  1347/ 2483] train: loss: 0.0010744
[Epoch 22; Iter  1377/ 2483] train: loss: 0.0021910
[Epoch 22; Iter  1407/ 2483] train: loss: 0.0574127
[Epoch 22; Iter  1437/ 2483] train: loss: 0.0013032
[Epoch 22; Iter  1467/ 2483] train: loss: 0.0019160
[Epoch 22; Iter  1497/ 2483] train: loss: 0.0019472
[Epoch 22; Iter  1527/ 2483] train: loss: 0.0013549
[Epoch 22; Iter  1557/ 2483] train: loss: 0.0011683
[Epoch 22; Iter  1587/ 2483] train: loss: 0.0013768
[Epoch 22; Iter  1617/ 2483] train: loss: 0.0011440
[Epoch 22; Iter  1647/ 2483] train: loss: 0.0023546
[Epoch 22; Iter  1677/ 2483] train: loss: 0.0016661
[Epoch 22; Iter  1707/ 2483] train: loss: 0.0018501
[Epoch 22; Iter  1737/ 2483] train: loss: 0.0027506
[Epoch 22; Iter  1767/ 2483] train: loss: 0.0020621
[Epoch 22; Iter  1797/ 2483] train: loss: 0.0033305
[Epoch 22; Iter  1827/ 2483] train: loss: 0.0046299
[Epoch 22; Iter  1857/ 2483] train: loss: 0.0019619
[Epoch 22; Iter  1887/ 2483] train: loss: 0.0019859
[Epoch 22; Iter  1917/ 2483] train: loss: 0.0278404
[Epoch 22; Iter  1947/ 2483] train: loss: 0.0067015
[Epoch 22; Iter  1977/ 2483] train: loss: 0.0014229
[Epoch 22; Iter  2007/ 2483] train: loss: 0.0018525
[Epoch 22; Iter  2037/ 2483] train: loss: 0.0014937
[Epoch 22; Iter   888/ 1862] train: loss: 0.0021703
[Epoch 22; Iter   918/ 1862] train: loss: 0.0016430
[Epoch 22; Iter   948/ 1862] train: loss: 0.0012048
[Epoch 22; Iter   978/ 1862] train: loss: 0.1015850
[Epoch 22; Iter  1008/ 1862] train: loss: 0.0015275
[Epoch 22; Iter  1038/ 1862] train: loss: 0.0019360
[Epoch 22; Iter  1068/ 1862] train: loss: 0.0022607
[Epoch 22; Iter  1098/ 1862] train: loss: 0.0029087
[Epoch 22; Iter  1128/ 1862] train: loss: 0.0013046
[Epoch 22; Iter  1158/ 1862] train: loss: 0.0015014
[Epoch 22; Iter  1188/ 1862] train: loss: 0.0571052
[Epoch 22; Iter  1218/ 1862] train: loss: 0.0037029
[Epoch 22; Iter  1248/ 1862] train: loss: 0.0019000
[Epoch 22; Iter  1278/ 1862] train: loss: 0.0021791
[Epoch 22; Iter  1308/ 1862] train: loss: 0.0027273
[Epoch 22; Iter  1338/ 1862] train: loss: 0.0022255
[Epoch 22; Iter  1368/ 1862] train: loss: 0.0029248
[Epoch 22; Iter  1398/ 1862] train: loss: 0.0028609
[Epoch 22; Iter  1428/ 1862] train: loss: 0.0017990
[Epoch 22; Iter  1458/ 1862] train: loss: 0.0012481
[Epoch 22; Iter  1488/ 1862] train: loss: 0.0010997
[Epoch 22; Iter  1518/ 1862] train: loss: 0.0015248
[Epoch 22; Iter  1548/ 1862] train: loss: 0.0020783
[Epoch 22; Iter  1578/ 1862] train: loss: 0.0025289
[Epoch 22; Iter  1608/ 1862] train: loss: 0.0025286
[Epoch 22; Iter  1638/ 1862] train: loss: 0.0020127
[Epoch 22; Iter  1668/ 1862] train: loss: 0.0022792
[Epoch 22; Iter  1698/ 1862] train: loss: 0.0032235
[Epoch 22; Iter  1728/ 1862] train: loss: 0.0018118
[Epoch 22; Iter  1758/ 1862] train: loss: 0.0014566
[Epoch 22; Iter  1788/ 1862] train: loss: 0.0009946
[Epoch 22; Iter  1818/ 1862] train: loss: 0.0018340
[Epoch 22; Iter  1848/ 1862] train: loss: 0.0014549
[Epoch 22] ogbg-molmuv: 0.026016 val loss: 0.013913
[Epoch 22] ogbg-molmuv: 0.048342 test loss: 0.016263
[Epoch 23; Iter    16/ 1862] train: loss: 0.0012646
[Epoch 23; Iter    46/ 1862] train: loss: 0.0489433
[Epoch 23; Iter    76/ 1862] train: loss: 0.0018599
[Epoch 23; Iter   106/ 1862] train: loss: 0.0015483
[Epoch 23; Iter   136/ 1862] train: loss: 0.0035559
[Epoch 23; Iter   166/ 1862] train: loss: 0.0070015
[Epoch 23; Iter   196/ 1862] train: loss: 0.0016874
[Epoch 23; Iter   226/ 1862] train: loss: 0.0017470
[Epoch 23; Iter   256/ 1862] train: loss: 0.0009943
[Epoch 23; Iter   286/ 1862] train: loss: 0.0457538
[Epoch 23; Iter   316/ 1862] train: loss: 0.0020786
[Epoch 23; Iter   346/ 1862] train: loss: 0.0022863
[Epoch 23; Iter   376/ 1862] train: loss: 0.0018323
[Epoch 23; Iter   406/ 1862] train: loss: 0.0016971
[Epoch 23; Iter   436/ 1862] train: loss: 0.0010886
[Epoch 23; Iter   466/ 1862] train: loss: 0.0039450
[Epoch 23; Iter   496/ 1862] train: loss: 0.0015655
[Epoch 23; Iter   526/ 1862] train: loss: 0.0762616
[Epoch 23; Iter   556/ 1862] train: loss: 0.0473858
[Epoch 23; Iter   586/ 1862] train: loss: 0.0013751
[Epoch 23; Iter   616/ 1862] train: loss: 0.1012187
[Epoch 23; Iter   646/ 1862] train: loss: 0.0018992
[Epoch 23; Iter   676/ 1862] train: loss: 0.0010377
[Epoch 23; Iter   706/ 1862] train: loss: 0.0020541
[Epoch 23; Iter   736/ 1862] train: loss: 0.0045762
[Epoch 23; Iter   766/ 1862] train: loss: 0.0023451
[Epoch 23; Iter   796/ 1862] train: loss: 0.0929609
[Epoch 23; Iter   826/ 1862] train: loss: 0.0056967
[Epoch 23; Iter   856/ 1862] train: loss: 0.0011557
[Epoch 23; Iter   886/ 1862] train: loss: 0.0014828
[Epoch 23; Iter   916/ 1862] train: loss: 0.0009659
[Epoch 23; Iter   946/ 1862] train: loss: 0.0038675
[Epoch 23; Iter   976/ 1862] train: loss: 0.0404846
[Epoch 23; Iter  1006/ 1862] train: loss: 0.0016599
[Epoch 23; Iter  1036/ 1862] train: loss: 0.0500617
[Epoch 23; Iter  1066/ 1862] train: loss: 0.0032639
[Epoch 23; Iter  1096/ 1862] train: loss: 0.0019353
[Epoch 23; Iter  1126/ 1862] train: loss: 0.0018612
[Epoch 23; Iter  1156/ 1862] train: loss: 0.0018931
[Epoch 23; Iter  1186/ 1862] train: loss: 0.0031206
[Epoch 23; Iter  1216/ 1862] train: loss: 0.0033778
[Epoch 23; Iter  1246/ 1862] train: loss: 0.0023104
[Epoch 23; Iter  1276/ 1862] train: loss: 0.0009723
[Epoch 23; Iter  1306/ 1862] train: loss: 0.0014229
[Epoch 23; Iter  1336/ 1862] train: loss: 0.0014680
[Epoch 23; Iter  1366/ 1862] train: loss: 0.0017828
[Epoch 23; Iter  1396/ 1862] train: loss: 0.0673678
[Epoch 23; Iter  1426/ 1862] train: loss: 0.0014366
[Epoch 23; Iter  1456/ 1862] train: loss: 0.0020513
[Epoch 23; Iter  1486/ 1862] train: loss: 0.0012110
[Epoch 23; Iter  1516/ 1862] train: loss: 0.0021946
[Epoch 23; Iter  1546/ 1862] train: loss: 0.0018252
[Epoch 23; Iter  1576/ 1862] train: loss: 0.0014637
[Epoch 23; Iter  1606/ 1862] train: loss: 0.0625953
[Epoch 23; Iter  1636/ 1862] train: loss: 0.0021337
[Epoch 23; Iter  1666/ 1862] train: loss: 0.0691716
[Epoch 23; Iter  1696/ 1862] train: loss: 0.0016450
[Epoch 23; Iter  1726/ 1862] train: loss: 0.0018037
[Epoch 23; Iter  1756/ 1862] train: loss: 0.0188500
[Epoch 23; Iter  1786/ 1862] train: loss: 0.0027618
[Epoch 23; Iter  1816/ 1862] train: loss: 0.0010037
[Epoch 23; Iter  1846/ 1862] train: loss: 0.0016434
[Epoch 23] ogbg-molmuv: 0.032760 val loss: 0.013564
[Epoch 23] ogbg-molmuv: 0.035143 test loss: 0.027671
[Epoch 24; Iter    14/ 1862] train: loss: 0.0024838
[Epoch 24; Iter    44/ 1862] train: loss: 0.0016045
[Epoch 24; Iter    74/ 1862] train: loss: 0.0018736
[Epoch 24; Iter   104/ 1862] train: loss: 0.0017665
[Epoch 24; Iter   134/ 1862] train: loss: 0.0017706
[Epoch 24; Iter   164/ 1862] train: loss: 0.0017505
[Epoch 24; Iter   194/ 1862] train: loss: 0.0017142
[Epoch 24; Iter   224/ 1862] train: loss: 0.0729100
[Epoch 24; Iter   254/ 1862] train: loss: 0.0013570
[Epoch 24; Iter   284/ 1862] train: loss: 0.0011524
[Epoch 24; Iter   314/ 1862] train: loss: 0.0013919
[Epoch 24; Iter   344/ 1862] train: loss: 0.0016908
[Epoch 24; Iter   374/ 1862] train: loss: 0.0020275
[Epoch 24; Iter   404/ 1862] train: loss: 0.0679197
[Epoch 24; Iter   434/ 1862] train: loss: 0.0027346
[Epoch 24; Iter   464/ 1862] train: loss: 0.0016675
[Epoch 24; Iter   494/ 1862] train: loss: 0.0013180
[Epoch 24; Iter   524/ 1862] train: loss: 0.0023682
[Epoch 24; Iter   554/ 1862] train: loss: 0.0011154
[Epoch 24; Iter   584/ 1862] train: loss: 0.0022374
[Epoch 24; Iter   614/ 1862] train: loss: 0.0026376
[Epoch 24; Iter   644/ 1862] train: loss: 0.0015646
[Epoch 24; Iter   674/ 1862] train: loss: 0.0649956
[Epoch 24; Iter   704/ 1862] train: loss: 0.0014423
[Epoch 24; Iter   734/ 1862] train: loss: 0.0024485
[Epoch 24; Iter   764/ 1862] train: loss: 0.0015252
[Epoch 24; Iter   794/ 1862] train: loss: 0.0019959
[Epoch 24; Iter   824/ 1862] train: loss: 0.0015455
[Epoch 24; Iter   854/ 1862] train: loss: 0.0014920
[Epoch 24; Iter   884/ 1862] train: loss: 0.0025871
[Epoch 24; Iter   914/ 1862] train: loss: 0.0014828
[Epoch 24; Iter   944/ 1862] train: loss: 0.0012709
[Epoch 24; Iter   974/ 1862] train: loss: 0.0777696
[Epoch 24; Iter  1004/ 1862] train: loss: 0.0149377
[Epoch 24; Iter  1034/ 1862] train: loss: 0.0483771
[Epoch 24; Iter  1064/ 1862] train: loss: 0.0042040
[Epoch 24; Iter  1094/ 1862] train: loss: 0.0029810
[Epoch 24; Iter  1124/ 1862] train: loss: 0.0034016
[Epoch 24; Iter  1154/ 1862] train: loss: 0.0011265
[Epoch 24; Iter  1184/ 1862] train: loss: 0.0598780
[Epoch 24; Iter  1214/ 1862] train: loss: 0.0013466
[Epoch 24; Iter  1244/ 1862] train: loss: 0.0127180
[Epoch 24; Iter  1274/ 1862] train: loss: 0.0011663
[Epoch 24; Iter  1304/ 1862] train: loss: 0.0022476
[Epoch 24; Iter  1334/ 1862] train: loss: 0.0012955
[Epoch 24; Iter  1364/ 1862] train: loss: 0.0013037
[Epoch 24; Iter  1394/ 1862] train: loss: 0.0015702
[Epoch 24; Iter  1424/ 1862] train: loss: 0.0018401
[Epoch 24; Iter  1454/ 1862] train: loss: 0.0017160
[Epoch 24; Iter  1484/ 1862] train: loss: 0.0023293
[Epoch 24; Iter  1514/ 1862] train: loss: 0.0012174
[Epoch 24; Iter  1544/ 1862] train: loss: 0.0014853
[Epoch 24; Iter  1574/ 1862] train: loss: 0.0024780
[Epoch 24; Iter  1604/ 1862] train: loss: 0.0012989
[Epoch 24; Iter  1634/ 1862] train: loss: 0.0014984
[Epoch 24; Iter  1664/ 1862] train: loss: 0.0014148
[Epoch 24; Iter  1694/ 1862] train: loss: 0.0018362
[Epoch 24; Iter  1724/ 1862] train: loss: 0.0019708
[Epoch 22; Iter   888/ 1862] train: loss: 0.0011519
[Epoch 22; Iter   918/ 1862] train: loss: 0.0016586
[Epoch 22; Iter   948/ 1862] train: loss: 0.0019843
[Epoch 22; Iter   978/ 1862] train: loss: 0.0013555
[Epoch 22; Iter  1008/ 1862] train: loss: 0.0012156
[Epoch 22; Iter  1038/ 1862] train: loss: 0.0010942
[Epoch 22; Iter  1068/ 1862] train: loss: 0.0010330
[Epoch 22; Iter  1098/ 1862] train: loss: 0.0883989
[Epoch 22; Iter  1128/ 1862] train: loss: 0.0032441
[Epoch 22; Iter  1158/ 1862] train: loss: 0.0032200
[Epoch 22; Iter  1188/ 1862] train: loss: 0.0640120
[Epoch 22; Iter  1218/ 1862] train: loss: 0.0019485
[Epoch 22; Iter  1248/ 1862] train: loss: 0.0638536
[Epoch 22; Iter  1278/ 1862] train: loss: 0.0021937
[Epoch 22; Iter  1308/ 1862] train: loss: 0.0027530
[Epoch 22; Iter  1338/ 1862] train: loss: 0.0016811
[Epoch 22; Iter  1368/ 1862] train: loss: 0.0030228
[Epoch 22; Iter  1398/ 1862] train: loss: 0.0030705
[Epoch 22; Iter  1428/ 1862] train: loss: 0.0021701
[Epoch 22; Iter  1458/ 1862] train: loss: 0.0017947
[Epoch 22; Iter  1488/ 1862] train: loss: 0.0017924
[Epoch 22; Iter  1518/ 1862] train: loss: 0.0013572
[Epoch 22; Iter  1548/ 1862] train: loss: 0.0012306
[Epoch 22; Iter  1578/ 1862] train: loss: 0.0015414
[Epoch 22; Iter  1608/ 1862] train: loss: 0.0012477
[Epoch 22; Iter  1638/ 1862] train: loss: 0.0016481
[Epoch 22; Iter  1668/ 1862] train: loss: 0.0733844
[Epoch 22; Iter  1698/ 1862] train: loss: 0.0015887
[Epoch 22; Iter  1728/ 1862] train: loss: 0.0072022
[Epoch 22; Iter  1758/ 1862] train: loss: 0.0018451
[Epoch 22; Iter  1788/ 1862] train: loss: 0.0011430
[Epoch 22; Iter  1818/ 1862] train: loss: 0.0859872
[Epoch 22; Iter  1848/ 1862] train: loss: 0.0029985
[Epoch 22] ogbg-molmuv: 0.052044 val loss: 0.012809
[Epoch 22] ogbg-molmuv: 0.066723 test loss: 0.011609
[Epoch 23; Iter    16/ 1862] train: loss: 0.0024118
[Epoch 23; Iter    46/ 1862] train: loss: 0.0010860
[Epoch 23; Iter    76/ 1862] train: loss: 0.0009878
[Epoch 23; Iter   106/ 1862] train: loss: 0.0013167
[Epoch 23; Iter   136/ 1862] train: loss: 0.0010337
[Epoch 23; Iter   166/ 1862] train: loss: 0.0012850
[Epoch 23; Iter   196/ 1862] train: loss: 0.0012095
[Epoch 23; Iter   226/ 1862] train: loss: 0.0020063
[Epoch 23; Iter   256/ 1862] train: loss: 0.0407528
[Epoch 23; Iter   286/ 1862] train: loss: 0.0024154
[Epoch 23; Iter   316/ 1862] train: loss: 0.0015851
[Epoch 23; Iter   346/ 1862] train: loss: 0.0010514
[Epoch 23; Iter   376/ 1862] train: loss: 0.0013934
[Epoch 23; Iter   406/ 1862] train: loss: 0.0014047
[Epoch 23; Iter   436/ 1862] train: loss: 0.0022654
[Epoch 23; Iter   466/ 1862] train: loss: 0.0021462
[Epoch 23; Iter   496/ 1862] train: loss: 0.0020865
[Epoch 23; Iter   526/ 1862] train: loss: 0.0013428
[Epoch 23; Iter   556/ 1862] train: loss: 0.0012043
[Epoch 23; Iter   586/ 1862] train: loss: 0.0015138
[Epoch 23; Iter   616/ 1862] train: loss: 0.0023525
[Epoch 23; Iter   646/ 1862] train: loss: 0.0025873
[Epoch 23; Iter   676/ 1862] train: loss: 0.0025141
[Epoch 23; Iter   706/ 1862] train: loss: 0.0030711
[Epoch 23; Iter   736/ 1862] train: loss: 0.0041088
[Epoch 23; Iter   766/ 1862] train: loss: 0.0011026
[Epoch 23; Iter   796/ 1862] train: loss: 0.0009865
[Epoch 23; Iter   826/ 1862] train: loss: 0.0016432
[Epoch 23; Iter   856/ 1862] train: loss: 0.0014625
[Epoch 23; Iter   886/ 1862] train: loss: 0.0015698
[Epoch 23; Iter   916/ 1862] train: loss: 0.0028811
[Epoch 23; Iter   946/ 1862] train: loss: 0.0011777
[Epoch 23; Iter   976/ 1862] train: loss: 0.0017666
[Epoch 23; Iter  1006/ 1862] train: loss: 0.0773869
[Epoch 23; Iter  1036/ 1862] train: loss: 0.0031858
[Epoch 23; Iter  1066/ 1862] train: loss: 0.0014970
[Epoch 23; Iter  1096/ 1862] train: loss: 0.0013431
[Epoch 23; Iter  1126/ 1862] train: loss: 0.0016124
[Epoch 23; Iter  1156/ 1862] train: loss: 0.0015120
[Epoch 23; Iter  1186/ 1862] train: loss: 0.0011081
[Epoch 23; Iter  1216/ 1862] train: loss: 0.0019350
[Epoch 23; Iter  1246/ 1862] train: loss: 0.0081527
[Epoch 23; Iter  1276/ 1862] train: loss: 0.0017479
[Epoch 23; Iter  1306/ 1862] train: loss: 0.0015205
[Epoch 23; Iter  1336/ 1862] train: loss: 0.0858437
[Epoch 23; Iter  1366/ 1862] train: loss: 0.0015243
[Epoch 23; Iter  1396/ 1862] train: loss: 0.0016908
[Epoch 23; Iter  1426/ 1862] train: loss: 0.0012745
[Epoch 23; Iter  1456/ 1862] train: loss: 0.0011073
[Epoch 23; Iter  1486/ 1862] train: loss: 0.0012523
[Epoch 23; Iter  1516/ 1862] train: loss: 0.0011665
[Epoch 23; Iter  1546/ 1862] train: loss: 0.0013442
[Epoch 23; Iter  1576/ 1862] train: loss: 0.0013498
[Epoch 23; Iter  1606/ 1862] train: loss: 0.0017928
[Epoch 23; Iter  1636/ 1862] train: loss: 0.0013530
[Epoch 23; Iter  1666/ 1862] train: loss: 0.0018735
[Epoch 23; Iter  1696/ 1862] train: loss: 0.0958564
[Epoch 23; Iter  1726/ 1862] train: loss: 0.0028283
[Epoch 23; Iter  1756/ 1862] train: loss: 0.0958378
[Epoch 23; Iter  1786/ 1862] train: loss: 0.0019537
[Epoch 23; Iter  1816/ 1862] train: loss: 0.0039269
[Epoch 23; Iter  1846/ 1862] train: loss: 0.0024041
[Epoch 23] ogbg-molmuv: 0.045892 val loss: 0.013689
[Epoch 23] ogbg-molmuv: 0.081588 test loss: 0.012343
[Epoch 24; Iter    14/ 1862] train: loss: 0.0021265
[Epoch 24; Iter    44/ 1862] train: loss: 0.0038255
[Epoch 24; Iter    74/ 1862] train: loss: 0.0016473
[Epoch 24; Iter   104/ 1862] train: loss: 0.0015960
[Epoch 24; Iter   134/ 1862] train: loss: 0.0031517
[Epoch 24; Iter   164/ 1862] train: loss: 0.0733068
[Epoch 24; Iter   194/ 1862] train: loss: 0.0018797
[Epoch 24; Iter   224/ 1862] train: loss: 0.0018615
[Epoch 24; Iter   254/ 1862] train: loss: 0.0015630
[Epoch 24; Iter   284/ 1862] train: loss: 0.0012269
[Epoch 24; Iter   314/ 1862] train: loss: 0.0010340
[Epoch 24; Iter   344/ 1862] train: loss: 0.0015815
[Epoch 24; Iter   374/ 1862] train: loss: 0.0111775
[Epoch 24; Iter   404/ 1862] train: loss: 0.0022385
[Epoch 24; Iter   434/ 1862] train: loss: 0.0019714
[Epoch 24; Iter   464/ 1862] train: loss: 0.0027443
[Epoch 24; Iter   494/ 1862] train: loss: 0.0015562
[Epoch 24; Iter   524/ 1862] train: loss: 0.0703528
[Epoch 24; Iter   554/ 1862] train: loss: 0.0019997
[Epoch 24; Iter   584/ 1862] train: loss: 0.0013855
[Epoch 24; Iter   614/ 1862] train: loss: 0.0024008
[Epoch 24; Iter   644/ 1862] train: loss: 0.0017432
[Epoch 24; Iter   674/ 1862] train: loss: 0.0592915
[Epoch 24; Iter   704/ 1862] train: loss: 0.0015456
[Epoch 24; Iter   734/ 1862] train: loss: 0.0723567
[Epoch 24; Iter   764/ 1862] train: loss: 0.0013586
[Epoch 24; Iter   794/ 1862] train: loss: 0.0022668
[Epoch 24; Iter   824/ 1862] train: loss: 0.0986447
[Epoch 24; Iter   854/ 1862] train: loss: 0.0012211
[Epoch 24; Iter   884/ 1862] train: loss: 0.0017102
[Epoch 24; Iter   914/ 1862] train: loss: 0.0027414
[Epoch 24; Iter   944/ 1862] train: loss: 0.0017564
[Epoch 24; Iter   974/ 1862] train: loss: 0.0017525
[Epoch 24; Iter  1004/ 1862] train: loss: 0.0028506
[Epoch 24; Iter  1034/ 1862] train: loss: 0.0022010
[Epoch 24; Iter  1064/ 1862] train: loss: 0.0015747
[Epoch 24; Iter  1094/ 1862] train: loss: 0.0993081
[Epoch 24; Iter  1124/ 1862] train: loss: 0.0018566
[Epoch 24; Iter  1154/ 1862] train: loss: 0.0015690
[Epoch 24; Iter  1184/ 1862] train: loss: 0.0014658
[Epoch 24; Iter  1214/ 1862] train: loss: 0.0017933
[Epoch 24; Iter  1244/ 1862] train: loss: 0.0015345
[Epoch 24; Iter  1274/ 1862] train: loss: 0.0012221
[Epoch 24; Iter  1304/ 1862] train: loss: 0.0030377
[Epoch 24; Iter  1334/ 1862] train: loss: 0.0014238
[Epoch 24; Iter  1364/ 1862] train: loss: 0.0014603
[Epoch 24; Iter  1394/ 1862] train: loss: 0.0688796
[Epoch 24; Iter  1424/ 1862] train: loss: 0.1021115
[Epoch 24; Iter  1454/ 1862] train: loss: 0.0030042
[Epoch 24; Iter  1484/ 1862] train: loss: 0.0013304
[Epoch 24; Iter  1514/ 1862] train: loss: 0.0020547
[Epoch 24; Iter  1544/ 1862] train: loss: 0.0015039
[Epoch 24; Iter  1574/ 1862] train: loss: 0.0062534
[Epoch 24; Iter  1604/ 1862] train: loss: 0.0015209
[Epoch 24; Iter  1634/ 1862] train: loss: 0.0013142
[Epoch 24; Iter  1664/ 1862] train: loss: 0.0016291
[Epoch 24; Iter  1694/ 1862] train: loss: 0.0011368
[Epoch 24; Iter  1724/ 1862] train: loss: 0.0021997
[Epoch 22; Iter  2067/ 2483] train: loss: 0.0012648
[Epoch 22; Iter  2097/ 2483] train: loss: 0.0027057
[Epoch 22; Iter  2127/ 2483] train: loss: 0.0013700
[Epoch 22; Iter  2157/ 2483] train: loss: 0.0038768
[Epoch 22; Iter  2187/ 2483] train: loss: 0.0015284
[Epoch 22; Iter  2217/ 2483] train: loss: 0.0012793
[Epoch 22; Iter  2247/ 2483] train: loss: 0.0013354
[Epoch 22; Iter  2277/ 2483] train: loss: 0.0021724
[Epoch 22; Iter  2307/ 2483] train: loss: 0.0015281
[Epoch 22; Iter  2337/ 2483] train: loss: 0.0014565
[Epoch 22; Iter  2367/ 2483] train: loss: 0.0021682
[Epoch 22; Iter  2397/ 2483] train: loss: 0.0015270
[Epoch 22; Iter  2427/ 2483] train: loss: 0.0013268
[Epoch 22; Iter  2457/ 2483] train: loss: 0.0018501
[Epoch 22] ogbg-molmuv: 0.113835 val loss: 0.024879
[Epoch 22] ogbg-molmuv: 0.122977 test loss: 0.035963
[Epoch 23; Iter     4/ 2483] train: loss: 0.0019655
[Epoch 23; Iter    34/ 2483] train: loss: 0.0214493
[Epoch 23; Iter    64/ 2483] train: loss: 0.0489039
[Epoch 23; Iter    94/ 2483] train: loss: 0.0032103
[Epoch 23; Iter   124/ 2483] train: loss: 0.1011409
[Epoch 23; Iter   154/ 2483] train: loss: 0.0025458
[Epoch 23; Iter   184/ 2483] train: loss: 0.0028985
[Epoch 23; Iter   214/ 2483] train: loss: 0.0015207
[Epoch 23; Iter   244/ 2483] train: loss: 0.0597729
[Epoch 23; Iter   274/ 2483] train: loss: 0.0029193
[Epoch 23; Iter   304/ 2483] train: loss: 0.0036785
[Epoch 23; Iter   334/ 2483] train: loss: 0.0074860
[Epoch 23; Iter   364/ 2483] train: loss: 0.0012611
[Epoch 23; Iter   394/ 2483] train: loss: 0.0021186
[Epoch 23; Iter   424/ 2483] train: loss: 0.0050630
[Epoch 23; Iter   454/ 2483] train: loss: 0.0013845
[Epoch 23; Iter   484/ 2483] train: loss: 0.0013786
[Epoch 23; Iter   514/ 2483] train: loss: 0.0018023
[Epoch 23; Iter   544/ 2483] train: loss: 0.0017562
[Epoch 23; Iter   574/ 2483] train: loss: 0.0024546
[Epoch 23; Iter   604/ 2483] train: loss: 0.0019652
[Epoch 23; Iter   634/ 2483] train: loss: 0.0018586
[Epoch 23; Iter   664/ 2483] train: loss: 0.0012900
[Epoch 23; Iter   694/ 2483] train: loss: 0.0027727
[Epoch 23; Iter   724/ 2483] train: loss: 0.0017073
[Epoch 23; Iter   754/ 2483] train: loss: 0.0539827
[Epoch 23; Iter   784/ 2483] train: loss: 0.0014697
[Epoch 23; Iter   814/ 2483] train: loss: 0.0013350
[Epoch 23; Iter   844/ 2483] train: loss: 0.0024202
[Epoch 23; Iter   874/ 2483] train: loss: 0.0013468
[Epoch 23; Iter   904/ 2483] train: loss: 0.0876953
[Epoch 23; Iter   934/ 2483] train: loss: 0.0512376
[Epoch 23; Iter   964/ 2483] train: loss: 0.0013496
[Epoch 23; Iter   994/ 2483] train: loss: 0.0861351
[Epoch 23; Iter  1024/ 2483] train: loss: 0.0013427
[Epoch 23; Iter  1054/ 2483] train: loss: 0.0634879
[Epoch 23; Iter  1084/ 2483] train: loss: 0.0020487
[Epoch 23; Iter  1114/ 2483] train: loss: 0.0024837
[Epoch 23; Iter  1144/ 2483] train: loss: 0.0015518
[Epoch 23; Iter  1174/ 2483] train: loss: 0.0603777
[Epoch 23; Iter  1204/ 2483] train: loss: 0.0009768
[Epoch 23; Iter  1234/ 2483] train: loss: 0.0016353
[Epoch 23; Iter  1264/ 2483] train: loss: 0.0062400
[Epoch 23; Iter  1294/ 2483] train: loss: 0.0017185
[Epoch 23; Iter  1324/ 2483] train: loss: 0.0759564
[Epoch 23; Iter  1354/ 2483] train: loss: 0.0026761
[Epoch 23; Iter  1384/ 2483] train: loss: 0.0022447
[Epoch 23; Iter  1414/ 2483] train: loss: 0.0015573
[Epoch 23; Iter  1444/ 2483] train: loss: 0.0012147
[Epoch 23; Iter  1474/ 2483] train: loss: 0.0011200
[Epoch 23; Iter  1504/ 2483] train: loss: 0.0641279
[Epoch 23; Iter  1534/ 2483] train: loss: 0.0018967
[Epoch 23; Iter  1564/ 2483] train: loss: 0.0874582
[Epoch 23; Iter  1594/ 2483] train: loss: 0.0019059
[Epoch 23; Iter  1624/ 2483] train: loss: 0.0018224
[Epoch 23; Iter  1654/ 2483] train: loss: 0.0018107
[Epoch 23; Iter  1684/ 2483] train: loss: 0.0018807
[Epoch 23; Iter  1714/ 2483] train: loss: 0.0018600
[Epoch 23; Iter  1744/ 2483] train: loss: 0.0013959
[Epoch 23; Iter  1774/ 2483] train: loss: 0.0014613
[Epoch 23; Iter  1804/ 2483] train: loss: 0.0014001
[Epoch 23; Iter  1834/ 2483] train: loss: 0.0015763
[Epoch 23; Iter  1864/ 2483] train: loss: 0.0012903
[Epoch 23; Iter  1894/ 2483] train: loss: 0.0633100
[Epoch 23; Iter  1924/ 2483] train: loss: 0.0040330
[Epoch 23; Iter  1954/ 2483] train: loss: 0.0048013
[Epoch 23; Iter  1984/ 2483] train: loss: 0.0019861
[Epoch 23; Iter  2014/ 2483] train: loss: 0.0012733
[Epoch 23; Iter  2044/ 2483] train: loss: 0.0030775
[Epoch 23; Iter  2074/ 2483] train: loss: 0.0025194
[Epoch 23; Iter  2104/ 2483] train: loss: 0.0011340
[Epoch 23; Iter  2134/ 2483] train: loss: 0.0020570
[Epoch 23; Iter  2164/ 2483] train: loss: 0.0023511
[Epoch 23; Iter  2194/ 2483] train: loss: 0.0009852
[Epoch 23; Iter  2224/ 2483] train: loss: 0.0892471
[Epoch 23; Iter  2254/ 2483] train: loss: 0.0018012
[Epoch 23; Iter  2284/ 2483] train: loss: 0.0507373
[Epoch 23; Iter  2314/ 2483] train: loss: 0.0023681
[Epoch 23; Iter  2344/ 2483] train: loss: 0.0017431
[Epoch 23; Iter  2374/ 2483] train: loss: 0.0023830
[Epoch 23; Iter  2404/ 2483] train: loss: 0.0024594
[Epoch 23; Iter  2434/ 2483] train: loss: 0.0014565
[Epoch 23; Iter  2464/ 2483] train: loss: 0.0012302
[Epoch 23] ogbg-molmuv: 0.126918 val loss: 0.009562
[Epoch 23] ogbg-molmuv: 0.129442 test loss: 0.019062
[Epoch 24; Iter    11/ 2483] train: loss: 0.0019708
[Epoch 24; Iter    41/ 2483] train: loss: 0.0040005
[Epoch 24; Iter    71/ 2483] train: loss: 0.0008839
[Epoch 24; Iter   101/ 2483] train: loss: 0.0015743
[Epoch 24; Iter   131/ 2483] train: loss: 0.0012436
[Epoch 24; Iter   161/ 2483] train: loss: 0.0016781
[Epoch 24; Iter   191/ 2483] train: loss: 0.0049242
[Epoch 24; Iter   221/ 2483] train: loss: 0.0011836
[Epoch 24; Iter   251/ 2483] train: loss: 0.0020554
[Epoch 24; Iter   281/ 2483] train: loss: 0.0023305
[Epoch 24; Iter   311/ 2483] train: loss: 0.0058258
[Epoch 24; Iter   341/ 2483] train: loss: 0.0023707
[Epoch 24; Iter   371/ 2483] train: loss: 0.0013598
[Epoch 24; Iter   401/ 2483] train: loss: 0.0030783
[Epoch 24; Iter   431/ 2483] train: loss: 0.1005606
[Epoch 24; Iter   461/ 2483] train: loss: 0.0754020
[Epoch 24; Iter   491/ 2483] train: loss: 0.0018763
[Epoch 24; Iter   521/ 2483] train: loss: 0.0009078
[Epoch 24; Iter   551/ 2483] train: loss: 0.0012428
[Epoch 24; Iter   581/ 2483] train: loss: 0.0020318
[Epoch 24; Iter   611/ 2483] train: loss: 0.0007612
[Epoch 24; Iter   641/ 2483] train: loss: 0.0009193
[Epoch 24; Iter   671/ 2483] train: loss: 0.0019198
[Epoch 24; Iter   701/ 2483] train: loss: 0.0012023
[Epoch 24; Iter   731/ 2483] train: loss: 0.0010869
[Epoch 24; Iter   761/ 2483] train: loss: 0.0016668
[Epoch 24; Iter   791/ 2483] train: loss: 0.0493826
[Epoch 24; Iter   821/ 2483] train: loss: 0.0027209
[Epoch 24; Iter   851/ 2483] train: loss: 0.0018962
[Epoch 24; Iter   881/ 2483] train: loss: 0.0013058
[Epoch 24; Iter   911/ 2483] train: loss: 0.0010531
[Epoch 24; Iter   941/ 2483] train: loss: 0.0032442
[Epoch 24; Iter   971/ 2483] train: loss: 0.1225455
[Epoch 24; Iter  1001/ 2483] train: loss: 0.0016684
[Epoch 24; Iter  1031/ 2483] train: loss: 0.1314340
[Epoch 24; Iter  1061/ 2483] train: loss: 0.0682015
[Epoch 24; Iter  1091/ 2483] train: loss: 0.0050030
[Epoch 24; Iter  1121/ 2483] train: loss: 0.0016377
[Epoch 24; Iter  1151/ 2483] train: loss: 0.0015886
[Epoch 24; Iter  1181/ 2483] train: loss: 0.0636408
[Epoch 24; Iter  1211/ 2483] train: loss: 0.0016014
[Epoch 24; Iter  1241/ 2483] train: loss: 0.0010086
[Epoch 24; Iter  1271/ 2483] train: loss: 0.0034162
[Epoch 24; Iter  1301/ 2483] train: loss: 0.0013075
[Epoch 24; Iter  1331/ 2483] train: loss: 0.0018977
[Epoch 24; Iter  1361/ 2483] train: loss: 0.0040197
[Epoch 24; Iter  1391/ 2483] train: loss: 0.0010706
[Epoch 24; Iter  1421/ 2483] train: loss: 0.0594508
[Epoch 24; Iter  1451/ 2483] train: loss: 0.0018123
[Epoch 24; Iter  1481/ 2483] train: loss: 0.0029438
[Epoch 24; Iter  1511/ 2483] train: loss: 0.0071174
[Epoch 24; Iter  1541/ 2483] train: loss: 0.0019334
[Epoch 24; Iter  1571/ 2483] train: loss: 0.0013725
[Epoch 24; Iter  1601/ 2483] train: loss: 0.0007695
[Epoch 24; Iter  1631/ 2483] train: loss: 0.0012520
[Epoch 24; Iter  1661/ 2483] train: loss: 0.0743892
[Epoch 22; Iter  2067/ 2483] train: loss: 0.0012099
[Epoch 22; Iter  2097/ 2483] train: loss: 0.0019424
[Epoch 22; Iter  2127/ 2483] train: loss: 0.0792451
[Epoch 22; Iter  2157/ 2483] train: loss: 0.0015232
[Epoch 22; Iter  2187/ 2483] train: loss: 0.0018368
[Epoch 22; Iter  2217/ 2483] train: loss: 0.0011106
[Epoch 22; Iter  2247/ 2483] train: loss: 0.0009081
[Epoch 22; Iter  2277/ 2483] train: loss: 0.0012772
[Epoch 22; Iter  2307/ 2483] train: loss: 0.0013733
[Epoch 22; Iter  2337/ 2483] train: loss: 0.0015574
[Epoch 22; Iter  2367/ 2483] train: loss: 0.1047906
[Epoch 22; Iter  2397/ 2483] train: loss: 0.0557758
[Epoch 22; Iter  2427/ 2483] train: loss: 0.0468119
[Epoch 22; Iter  2457/ 2483] train: loss: 0.0020309
[Epoch 22] ogbg-molmuv: 0.110371 val loss: 0.010446
[Epoch 22] ogbg-molmuv: 0.148747 test loss: 0.014745
[Epoch 23; Iter     4/ 2483] train: loss: 0.0023552
[Epoch 23; Iter    34/ 2483] train: loss: 0.0031787
[Epoch 23; Iter    64/ 2483] train: loss: 0.0095964
[Epoch 23; Iter    94/ 2483] train: loss: 0.0020710
[Epoch 23; Iter   124/ 2483] train: loss: 0.0013621
[Epoch 23; Iter   154/ 2483] train: loss: 0.0010642
[Epoch 23; Iter   184/ 2483] train: loss: 0.0013704
[Epoch 23; Iter   214/ 2483] train: loss: 0.0013444
[Epoch 23; Iter   244/ 2483] train: loss: 0.0665294
[Epoch 23; Iter   274/ 2483] train: loss: 0.0023926
[Epoch 23; Iter   304/ 2483] train: loss: 0.0027181
[Epoch 23; Iter   334/ 2483] train: loss: 0.0016026
[Epoch 23; Iter   364/ 2483] train: loss: 0.0018046
[Epoch 23; Iter   394/ 2483] train: loss: 0.0009669
[Epoch 23; Iter   424/ 2483] train: loss: 0.0016977
[Epoch 23; Iter   454/ 2483] train: loss: 0.0017572
[Epoch 23; Iter   484/ 2483] train: loss: 0.0463151
[Epoch 23; Iter   514/ 2483] train: loss: 0.0013886
[Epoch 23; Iter   544/ 2483] train: loss: 0.0017386
[Epoch 23; Iter   574/ 2483] train: loss: 0.0012138
[Epoch 23; Iter   604/ 2483] train: loss: 0.0024961
[Epoch 23; Iter   634/ 2483] train: loss: 0.0021058
[Epoch 23; Iter   664/ 2483] train: loss: 0.0013758
[Epoch 23; Iter   694/ 2483] train: loss: 0.0012938
[Epoch 23; Iter   724/ 2483] train: loss: 0.0010026
[Epoch 23; Iter   754/ 2483] train: loss: 0.0013519
[Epoch 23; Iter   784/ 2483] train: loss: 0.0015541
[Epoch 23; Iter   814/ 2483] train: loss: 0.0018011
[Epoch 23; Iter   844/ 2483] train: loss: 0.0014237
[Epoch 23; Iter   874/ 2483] train: loss: 0.0074734
[Epoch 23; Iter   904/ 2483] train: loss: 0.0032737
[Epoch 23; Iter   934/ 2483] train: loss: 0.0014794
[Epoch 23; Iter   964/ 2483] train: loss: 0.0717852
[Epoch 23; Iter   994/ 2483] train: loss: 0.0014294
[Epoch 23; Iter  1024/ 2483] train: loss: 0.0014064
[Epoch 23; Iter  1054/ 2483] train: loss: 0.0674950
[Epoch 23; Iter  1084/ 2483] train: loss: 0.0033591
[Epoch 23; Iter  1114/ 2483] train: loss: 0.0025510
[Epoch 23; Iter  1144/ 2483] train: loss: 0.0020123
[Epoch 23; Iter  1174/ 2483] train: loss: 0.0014390
[Epoch 23; Iter  1204/ 2483] train: loss: 0.0010362
[Epoch 23; Iter  1234/ 2483] train: loss: 0.0014271
[Epoch 23; Iter  1264/ 2483] train: loss: 0.0013661
[Epoch 23; Iter  1294/ 2483] train: loss: 0.0011701
[Epoch 23; Iter  1324/ 2483] train: loss: 0.0018535
[Epoch 23; Iter  1354/ 2483] train: loss: 0.0039626
[Epoch 23; Iter  1384/ 2483] train: loss: 0.0026886
[Epoch 23; Iter  1414/ 2483] train: loss: 0.0028140
[Epoch 23; Iter  1444/ 2483] train: loss: 0.0019762
[Epoch 23; Iter  1474/ 2483] train: loss: 0.0123632
[Epoch 23; Iter  1504/ 2483] train: loss: 0.0606694
[Epoch 23; Iter  1534/ 2483] train: loss: 0.0824486
[Epoch 23; Iter  1564/ 2483] train: loss: 0.0713391
[Epoch 23; Iter  1594/ 2483] train: loss: 0.0014743
[Epoch 23; Iter  1624/ 2483] train: loss: 0.0017288
[Epoch 23; Iter  1654/ 2483] train: loss: 0.0012706
[Epoch 23; Iter  1684/ 2483] train: loss: 0.0013898
[Epoch 23; Iter  1714/ 2483] train: loss: 0.0787836
[Epoch 23; Iter  1744/ 2483] train: loss: 0.0022317
[Epoch 23; Iter  1774/ 2483] train: loss: 0.0020068
[Epoch 23; Iter  1804/ 2483] train: loss: 0.0014225
[Epoch 23; Iter  1834/ 2483] train: loss: 0.0014919
[Epoch 23; Iter  1864/ 2483] train: loss: 0.0017802
[Epoch 23; Iter  1894/ 2483] train: loss: 0.0022919
[Epoch 23; Iter  1924/ 2483] train: loss: 0.0021942
[Epoch 23; Iter  1954/ 2483] train: loss: 0.0015695
[Epoch 23; Iter  1984/ 2483] train: loss: 0.0011350
[Epoch 23; Iter  2014/ 2483] train: loss: 0.0860669
[Epoch 23; Iter  2044/ 2483] train: loss: 0.0024039
[Epoch 23; Iter  2074/ 2483] train: loss: 0.0013370
[Epoch 23; Iter  2104/ 2483] train: loss: 0.0034547
[Epoch 23; Iter  2134/ 2483] train: loss: 0.0020843
[Epoch 23; Iter  2164/ 2483] train: loss: 0.0021634
[Epoch 23; Iter  2194/ 2483] train: loss: 0.0024102
[Epoch 23; Iter  2224/ 2483] train: loss: 0.0616953
[Epoch 23; Iter  2254/ 2483] train: loss: 0.0639213
[Epoch 23; Iter  2284/ 2483] train: loss: 0.0898316
[Epoch 23; Iter  2314/ 2483] train: loss: 0.1207482
[Epoch 23; Iter  2344/ 2483] train: loss: 0.0031091
[Epoch 23; Iter  2374/ 2483] train: loss: 0.0034046
[Epoch 23; Iter  2404/ 2483] train: loss: 0.0014865
[Epoch 23; Iter  2434/ 2483] train: loss: 0.0023369
[Epoch 23; Iter  2464/ 2483] train: loss: 0.0025507
[Epoch 23] ogbg-molmuv: 0.115508 val loss: 0.011852
[Epoch 23] ogbg-molmuv: 0.127742 test loss: 0.015268
[Epoch 24; Iter    11/ 2483] train: loss: 0.0020272
[Epoch 24; Iter    41/ 2483] train: loss: 0.0023430
[Epoch 24; Iter    71/ 2483] train: loss: 0.0019163
[Epoch 24; Iter   101/ 2483] train: loss: 0.0018721
[Epoch 24; Iter   131/ 2483] train: loss: 0.0020044
[Epoch 24; Iter   161/ 2483] train: loss: 0.0016204
[Epoch 24; Iter   191/ 2483] train: loss: 0.0020599
[Epoch 24; Iter   221/ 2483] train: loss: 0.0587742
[Epoch 24; Iter   251/ 2483] train: loss: 0.0016871
[Epoch 24; Iter   281/ 2483] train: loss: 0.0014428
[Epoch 24; Iter   311/ 2483] train: loss: 0.0012989
[Epoch 24; Iter   341/ 2483] train: loss: 0.0017701
[Epoch 24; Iter   371/ 2483] train: loss: 0.0032447
[Epoch 24; Iter   401/ 2483] train: loss: 0.0020653
[Epoch 24; Iter   431/ 2483] train: loss: 0.0015265
[Epoch 24; Iter   461/ 2483] train: loss: 0.0018603
[Epoch 24; Iter   491/ 2483] train: loss: 0.0013451
[Epoch 24; Iter   521/ 2483] train: loss: 0.0017845
[Epoch 24; Iter   551/ 2483] train: loss: 0.0017218
[Epoch 24; Iter   581/ 2483] train: loss: 0.0020793
[Epoch 24; Iter   611/ 2483] train: loss: 0.0016189
[Epoch 24; Iter   641/ 2483] train: loss: 0.0024118
[Epoch 24; Iter   671/ 2483] train: loss: 0.0018156
[Epoch 24; Iter   701/ 2483] train: loss: 0.0027395
[Epoch 24; Iter   731/ 2483] train: loss: 0.0011906
[Epoch 24; Iter   761/ 2483] train: loss: 0.0611321
[Epoch 24; Iter   791/ 2483] train: loss: 0.0017384
[Epoch 24; Iter   821/ 2483] train: loss: 0.0018256
[Epoch 24; Iter   851/ 2483] train: loss: 0.0010592
[Epoch 24; Iter   881/ 2483] train: loss: 0.0020792
[Epoch 24; Iter   911/ 2483] train: loss: 0.1828791
[Epoch 24; Iter   941/ 2483] train: loss: 0.0012351
[Epoch 24; Iter   971/ 2483] train: loss: 0.0019633
[Epoch 24; Iter  1001/ 2483] train: loss: 0.0018111
[Epoch 24; Iter  1031/ 2483] train: loss: 0.0011421
[Epoch 24; Iter  1061/ 2483] train: loss: 0.0554373
[Epoch 24; Iter  1091/ 2483] train: loss: 0.0015114
[Epoch 24; Iter  1121/ 2483] train: loss: 0.0008508
[Epoch 24; Iter  1151/ 2483] train: loss: 0.0016423
[Epoch 24; Iter  1181/ 2483] train: loss: 0.0227360
[Epoch 24; Iter  1211/ 2483] train: loss: 0.0012519
[Epoch 24; Iter  1241/ 2483] train: loss: 0.0019412
[Epoch 24; Iter  1271/ 2483] train: loss: 0.0017395
[Epoch 24; Iter  1301/ 2483] train: loss: 0.0022101
[Epoch 24; Iter  1331/ 2483] train: loss: 0.0009241
[Epoch 24; Iter  1361/ 2483] train: loss: 0.0017923
[Epoch 24; Iter  1391/ 2483] train: loss: 0.0017577
[Epoch 24; Iter  1421/ 2483] train: loss: 0.0024121
[Epoch 24; Iter  1451/ 2483] train: loss: 0.0015548
[Epoch 24; Iter  1481/ 2483] train: loss: 0.0344090
[Epoch 24; Iter  1511/ 2483] train: loss: 0.0023175
[Epoch 24; Iter  1541/ 2483] train: loss: 0.0032209
[Epoch 24; Iter  1571/ 2483] train: loss: 0.0490334
[Epoch 24; Iter  1601/ 2483] train: loss: 0.0027995
[Epoch 24; Iter  1631/ 2483] train: loss: 0.0021229
[Epoch 24; Iter  1661/ 2483] train: loss: 0.0016367
[Epoch 23; Iter  1626/ 2172] train: loss: 0.0121181
[Epoch 23; Iter  1656/ 2172] train: loss: 0.0058316
[Epoch 23; Iter  1686/ 2172] train: loss: 0.0579129
[Epoch 23; Iter  1716/ 2172] train: loss: 0.0017328
[Epoch 23; Iter  1746/ 2172] train: loss: 0.0019536
[Epoch 23; Iter  1776/ 2172] train: loss: 0.0017131
[Epoch 23; Iter  1806/ 2172] train: loss: 0.0016236
[Epoch 23; Iter  1836/ 2172] train: loss: 0.0497927
[Epoch 23; Iter  1866/ 2172] train: loss: 0.0023615
[Epoch 23; Iter  1896/ 2172] train: loss: 0.0029944
[Epoch 23; Iter  1926/ 2172] train: loss: 0.0027519
[Epoch 23; Iter  1956/ 2172] train: loss: 0.0016284
[Epoch 23; Iter  1986/ 2172] train: loss: 0.0012307
[Epoch 23; Iter  2016/ 2172] train: loss: 0.0015848
[Epoch 23; Iter  2046/ 2172] train: loss: 0.0011981
[Epoch 23; Iter  2076/ 2172] train: loss: 0.0015628
[Epoch 23; Iter  2106/ 2172] train: loss: 0.0014647
[Epoch 23; Iter  2136/ 2172] train: loss: 0.0016767
[Epoch 23; Iter  2166/ 2172] train: loss: 0.0017066
[Epoch 23] ogbg-molmuv: 0.069438 val loss: 0.134869
[Epoch 23] ogbg-molmuv: 0.089326 test loss: 0.075623
[Epoch 24; Iter    24/ 2172] train: loss: 0.0015914
[Epoch 24; Iter    54/ 2172] train: loss: 0.0015744
[Epoch 24; Iter    84/ 2172] train: loss: 0.0013300
[Epoch 24; Iter   114/ 2172] train: loss: 0.0018145
[Epoch 24; Iter   144/ 2172] train: loss: 0.0017853
[Epoch 24; Iter   174/ 2172] train: loss: 0.0016826
[Epoch 24; Iter   204/ 2172] train: loss: 0.0017640
[Epoch 24; Iter   234/ 2172] train: loss: 0.0039411
[Epoch 24; Iter   264/ 2172] train: loss: 0.0018356
[Epoch 24; Iter   294/ 2172] train: loss: 0.1060881
[Epoch 24; Iter   324/ 2172] train: loss: 0.0008576
[Epoch 24; Iter   354/ 2172] train: loss: 0.0637382
[Epoch 24; Iter   384/ 2172] train: loss: 0.0011444
[Epoch 24; Iter   414/ 2172] train: loss: 0.0010419
[Epoch 24; Iter   444/ 2172] train: loss: 0.0022094
[Epoch 24; Iter   474/ 2172] train: loss: 0.0018895
[Epoch 24; Iter   504/ 2172] train: loss: 0.0023103
[Epoch 24; Iter   534/ 2172] train: loss: 0.0017770
[Epoch 24; Iter   564/ 2172] train: loss: 0.0009616
[Epoch 24; Iter   594/ 2172] train: loss: 0.0014238
[Epoch 24; Iter   624/ 2172] train: loss: 0.0023190
[Epoch 24; Iter   654/ 2172] train: loss: 0.0702087
[Epoch 24; Iter   684/ 2172] train: loss: 0.0017185
[Epoch 24; Iter   714/ 2172] train: loss: 0.0023191
[Epoch 24; Iter   744/ 2172] train: loss: 0.0014784
[Epoch 24; Iter   774/ 2172] train: loss: 0.0672126
[Epoch 24; Iter   804/ 2172] train: loss: 0.0013132
[Epoch 24; Iter   834/ 2172] train: loss: 0.0018869
[Epoch 24; Iter   864/ 2172] train: loss: 0.0033025
[Epoch 24; Iter   894/ 2172] train: loss: 0.0437842
[Epoch 24; Iter   924/ 2172] train: loss: 0.0030234
[Epoch 24; Iter   954/ 2172] train: loss: 0.0015095
[Epoch 24; Iter   984/ 2172] train: loss: 0.0015989
[Epoch 24; Iter  1014/ 2172] train: loss: 0.0024303
[Epoch 24; Iter  1044/ 2172] train: loss: 0.0019774
[Epoch 24; Iter  1074/ 2172] train: loss: 0.0568642
[Epoch 24; Iter  1104/ 2172] train: loss: 0.0027209
[Epoch 24; Iter  1134/ 2172] train: loss: 0.0075789
[Epoch 24; Iter  1164/ 2172] train: loss: 0.0096305
[Epoch 24; Iter  1194/ 2172] train: loss: 0.0028501
[Epoch 24; Iter  1224/ 2172] train: loss: 0.0014167
[Epoch 24; Iter  1254/ 2172] train: loss: 0.0027247
[Epoch 24; Iter  1284/ 2172] train: loss: 0.0015722
[Epoch 24; Iter  1314/ 2172] train: loss: 0.0011610
[Epoch 24; Iter  1344/ 2172] train: loss: 0.0520954
[Epoch 24; Iter  1374/ 2172] train: loss: 0.0016022
[Epoch 24; Iter  1404/ 2172] train: loss: 0.0044169
[Epoch 24; Iter  1434/ 2172] train: loss: 0.0035591
[Epoch 24; Iter  1464/ 2172] train: loss: 0.0020039
[Epoch 24; Iter  1494/ 2172] train: loss: 0.0038247
[Epoch 24; Iter  1524/ 2172] train: loss: 0.0007625
[Epoch 24; Iter  1554/ 2172] train: loss: 0.0028356
[Epoch 24; Iter  1584/ 2172] train: loss: 0.0023013
[Epoch 24; Iter  1614/ 2172] train: loss: 0.0016693
[Epoch 24; Iter  1644/ 2172] train: loss: 0.0025219
[Epoch 24; Iter  1674/ 2172] train: loss: 0.0064936
[Epoch 24; Iter  1704/ 2172] train: loss: 0.0021072
[Epoch 24; Iter  1734/ 2172] train: loss: 0.0016393
[Epoch 24; Iter  1764/ 2172] train: loss: 0.0038653
[Epoch 24; Iter  1794/ 2172] train: loss: 0.0014119
[Epoch 24; Iter  1824/ 2172] train: loss: 0.0294752
[Epoch 24; Iter  1854/ 2172] train: loss: 0.0165603
[Epoch 24; Iter  1884/ 2172] train: loss: 0.0012425
[Epoch 24; Iter  1914/ 2172] train: loss: 0.0015021
[Epoch 24; Iter  1944/ 2172] train: loss: 0.0010812
[Epoch 24; Iter  1974/ 2172] train: loss: 0.0007621
[Epoch 24; Iter  2004/ 2172] train: loss: 0.0029868
[Epoch 24; Iter  2034/ 2172] train: loss: 0.0737289
[Epoch 24; Iter  2064/ 2172] train: loss: 0.0011556
[Epoch 24; Iter  2094/ 2172] train: loss: 0.0008970
[Epoch 24; Iter  2124/ 2172] train: loss: 0.0028645
[Epoch 24; Iter  2154/ 2172] train: loss: 0.0470649
[Epoch 24] ogbg-molmuv: 0.073733 val loss: 0.013311
[Epoch 24] ogbg-molmuv: 0.134550 test loss: 0.012882
[Epoch 25; Iter    12/ 2172] train: loss: 0.0021199
[Epoch 25; Iter    42/ 2172] train: loss: 0.0018127
[Epoch 25; Iter    72/ 2172] train: loss: 0.0827262
[Epoch 25; Iter   102/ 2172] train: loss: 0.0750729
[Epoch 25; Iter   132/ 2172] train: loss: 0.0063367
[Epoch 25; Iter   162/ 2172] train: loss: 0.0008031
[Epoch 25; Iter   192/ 2172] train: loss: 0.0030266
[Epoch 25; Iter   222/ 2172] train: loss: 0.0018133
[Epoch 25; Iter   252/ 2172] train: loss: 0.0019054
[Epoch 25; Iter   282/ 2172] train: loss: 0.0015456
[Epoch 25; Iter   312/ 2172] train: loss: 0.0017119
[Epoch 25; Iter   342/ 2172] train: loss: 0.0017194
[Epoch 25; Iter   372/ 2172] train: loss: 0.0257983
[Epoch 25; Iter   402/ 2172] train: loss: 0.0738397
[Epoch 25; Iter   432/ 2172] train: loss: 0.0015357
[Epoch 25; Iter   462/ 2172] train: loss: 0.0015050
[Epoch 25; Iter   492/ 2172] train: loss: 0.0557478
[Epoch 25; Iter   522/ 2172] train: loss: 0.0017523
[Epoch 25; Iter   552/ 2172] train: loss: 0.0012883
[Epoch 25; Iter   582/ 2172] train: loss: 0.0009969
[Epoch 25; Iter   612/ 2172] train: loss: 0.0015281
[Epoch 25; Iter   642/ 2172] train: loss: 0.0012006
[Epoch 25; Iter   672/ 2172] train: loss: 0.0010940
[Epoch 25; Iter   702/ 2172] train: loss: 0.0012513
[Epoch 25; Iter   732/ 2172] train: loss: 0.0382926
[Epoch 25; Iter   762/ 2172] train: loss: 0.0014709
[Epoch 25; Iter   792/ 2172] train: loss: 0.0053259
[Epoch 25; Iter   822/ 2172] train: loss: 0.0012192
[Epoch 25; Iter   852/ 2172] train: loss: 0.1250659
[Epoch 25; Iter   882/ 2172] train: loss: 0.0016141
[Epoch 25; Iter   912/ 2172] train: loss: 0.0011430
[Epoch 25; Iter   942/ 2172] train: loss: 0.0013403
[Epoch 25; Iter   972/ 2172] train: loss: 0.0266504
[Epoch 25; Iter  1002/ 2172] train: loss: 0.0013783
[Epoch 25; Iter  1032/ 2172] train: loss: 0.0477529
[Epoch 25; Iter  1062/ 2172] train: loss: 0.0011542
[Epoch 25; Iter  1092/ 2172] train: loss: 0.0012526
[Epoch 25; Iter  1122/ 2172] train: loss: 0.0013614
[Epoch 25; Iter  1152/ 2172] train: loss: 0.0021063
[Epoch 25; Iter  1182/ 2172] train: loss: 0.0018310
[Epoch 25; Iter  1212/ 2172] train: loss: 0.0018551
[Epoch 25; Iter  1242/ 2172] train: loss: 0.0016977
[Epoch 25; Iter  1272/ 2172] train: loss: 0.0013274
[Epoch 25; Iter  1302/ 2172] train: loss: 0.0018534
[Epoch 25; Iter  1332/ 2172] train: loss: 0.0029091
[Epoch 25; Iter  1362/ 2172] train: loss: 0.0043952
[Epoch 25; Iter  1392/ 2172] train: loss: 0.0542426
[Epoch 25; Iter  1422/ 2172] train: loss: 0.0018362
[Epoch 25; Iter  1452/ 2172] train: loss: 0.0014304
[Epoch 25; Iter  1482/ 2172] train: loss: 0.0775023
[Epoch 25; Iter  1512/ 2172] train: loss: 0.0034309
[Epoch 25; Iter  1542/ 2172] train: loss: 0.0014857
[Epoch 25; Iter  1572/ 2172] train: loss: 0.0008735
[Epoch 25; Iter  1602/ 2172] train: loss: 0.0008521
[Epoch 25; Iter  1632/ 2172] train: loss: 0.0012454
[Epoch 25; Iter  1662/ 2172] train: loss: 0.0008491
[Epoch 25; Iter  1692/ 2172] train: loss: 0.0025220
[Epoch 25; Iter  1722/ 2172] train: loss: 0.0009213
[Epoch 25; Iter  1752/ 2172] train: loss: 0.0009044
[Epoch 25; Iter  1782/ 2172] train: loss: 0.0032931
[Epoch 25; Iter  1812/ 2172] train: loss: 0.0027927
[Epoch 25; Iter  1842/ 2172] train: loss: 0.0006195
[Epoch 23; Iter  1626/ 2172] train: loss: 0.0023525
[Epoch 23; Iter  1656/ 2172] train: loss: 0.0012852
[Epoch 23; Iter  1686/ 2172] train: loss: 0.0020040
[Epoch 23; Iter  1716/ 2172] train: loss: 0.0020992
[Epoch 23; Iter  1746/ 2172] train: loss: 0.0432949
[Epoch 23; Iter  1776/ 2172] train: loss: 0.0095325
[Epoch 23; Iter  1806/ 2172] train: loss: 0.0017882
[Epoch 23; Iter  1836/ 2172] train: loss: 0.0009515
[Epoch 23; Iter  1866/ 2172] train: loss: 0.0016902
[Epoch 23; Iter  1896/ 2172] train: loss: 0.0710004
[Epoch 23; Iter  1926/ 2172] train: loss: 0.0014276
[Epoch 23; Iter  1956/ 2172] train: loss: 0.0010191
[Epoch 23; Iter  1986/ 2172] train: loss: 0.0019464
[Epoch 23; Iter  2016/ 2172] train: loss: 0.0019117
[Epoch 23; Iter  2046/ 2172] train: loss: 0.0014371
[Epoch 23; Iter  2076/ 2172] train: loss: 0.0014742
[Epoch 23; Iter  2106/ 2172] train: loss: 0.0013596
[Epoch 23; Iter  2136/ 2172] train: loss: 0.0964904
[Epoch 23; Iter  2166/ 2172] train: loss: 0.0015745
[Epoch 23] ogbg-molmuv: 0.031160 val loss: 0.280631
[Epoch 23] ogbg-molmuv: 0.089183 test loss: 0.086789
[Epoch 24; Iter    24/ 2172] train: loss: 0.0011188
[Epoch 24; Iter    54/ 2172] train: loss: 0.0020718
[Epoch 24; Iter    84/ 2172] train: loss: 0.0010985
[Epoch 24; Iter   114/ 2172] train: loss: 0.1099600
[Epoch 24; Iter   144/ 2172] train: loss: 0.0009256
[Epoch 24; Iter   174/ 2172] train: loss: 0.0866124
[Epoch 24; Iter   204/ 2172] train: loss: 0.0022501
[Epoch 24; Iter   234/ 2172] train: loss: 0.0010029
[Epoch 24; Iter   264/ 2172] train: loss: 0.0977146
[Epoch 24; Iter   294/ 2172] train: loss: 0.0014616
[Epoch 24; Iter   324/ 2172] train: loss: 0.0015178
[Epoch 24; Iter   354/ 2172] train: loss: 0.0016456
[Epoch 24; Iter   384/ 2172] train: loss: 0.0020518
[Epoch 24; Iter   414/ 2172] train: loss: 0.0015139
[Epoch 24; Iter   444/ 2172] train: loss: 0.0009358
[Epoch 24; Iter   474/ 2172] train: loss: 0.0015433
[Epoch 24; Iter   504/ 2172] train: loss: 0.0845881
[Epoch 24; Iter   534/ 2172] train: loss: 0.0869114
[Epoch 24; Iter   564/ 2172] train: loss: 0.0403332
[Epoch 24; Iter   594/ 2172] train: loss: 0.0014826
[Epoch 24; Iter   624/ 2172] train: loss: 0.0013264
[Epoch 24; Iter   654/ 2172] train: loss: 0.0014061
[Epoch 24; Iter   684/ 2172] train: loss: 0.0015167
[Epoch 24; Iter   714/ 2172] train: loss: 0.0015123
[Epoch 24; Iter   744/ 2172] train: loss: 0.0008543
[Epoch 24; Iter   774/ 2172] train: loss: 0.0012696
[Epoch 24; Iter   804/ 2172] train: loss: 0.0017094
[Epoch 24; Iter   834/ 2172] train: loss: 0.0013288
[Epoch 24; Iter   864/ 2172] train: loss: 0.0017808
[Epoch 24; Iter   894/ 2172] train: loss: 0.0671210
[Epoch 24; Iter   924/ 2172] train: loss: 0.0012950
[Epoch 24; Iter   954/ 2172] train: loss: 0.0816997
[Epoch 24; Iter   984/ 2172] train: loss: 0.0019108
[Epoch 24; Iter  1014/ 2172] train: loss: 0.0016744
[Epoch 24; Iter  1044/ 2172] train: loss: 0.0021473
[Epoch 24; Iter  1074/ 2172] train: loss: 0.0021016
[Epoch 24; Iter  1104/ 2172] train: loss: 0.0016208
[Epoch 24; Iter  1134/ 2172] train: loss: 0.0013836
[Epoch 24; Iter  1164/ 2172] train: loss: 0.0011836
[Epoch 24; Iter  1194/ 2172] train: loss: 0.0010030
[Epoch 24; Iter  1224/ 2172] train: loss: 0.0019625
[Epoch 24; Iter  1254/ 2172] train: loss: 0.0018215
[Epoch 24; Iter  1284/ 2172] train: loss: 0.0035373
[Epoch 24; Iter  1314/ 2172] train: loss: 0.0014026
[Epoch 24; Iter  1344/ 2172] train: loss: 0.0016033
[Epoch 24; Iter  1374/ 2172] train: loss: 0.0788600
[Epoch 24; Iter  1404/ 2172] train: loss: 0.0023824
[Epoch 24; Iter  1434/ 2172] train: loss: 0.0940064
[Epoch 24; Iter  1464/ 2172] train: loss: 0.0034189
[Epoch 24; Iter  1494/ 2172] train: loss: 0.0013186
[Epoch 24; Iter  1524/ 2172] train: loss: 0.0775786
[Epoch 24; Iter  1554/ 2172] train: loss: 0.0016651
[Epoch 24; Iter  1584/ 2172] train: loss: 0.0261693
[Epoch 24; Iter  1614/ 2172] train: loss: 0.0024240
[Epoch 24; Iter  1644/ 2172] train: loss: 0.0013659
[Epoch 24; Iter  1674/ 2172] train: loss: 0.0033888
[Epoch 24; Iter  1704/ 2172] train: loss: 0.0014375
[Epoch 24; Iter  1734/ 2172] train: loss: 0.0083963
[Epoch 24; Iter  1764/ 2172] train: loss: 0.0807695
[Epoch 24; Iter  1794/ 2172] train: loss: 0.0033049
[Epoch 24; Iter  1824/ 2172] train: loss: 0.0019654
[Epoch 24; Iter  1854/ 2172] train: loss: 0.0018627
[Epoch 24; Iter  1884/ 2172] train: loss: 0.0027755
[Epoch 24; Iter  1914/ 2172] train: loss: 0.0016199
[Epoch 24; Iter  1944/ 2172] train: loss: 0.0012530
[Epoch 24; Iter  1974/ 2172] train: loss: 0.0020045
[Epoch 24; Iter  2004/ 2172] train: loss: 0.0012977
[Epoch 24; Iter  2034/ 2172] train: loss: 0.0016604
[Epoch 24; Iter  2064/ 2172] train: loss: 0.0032086
[Epoch 24; Iter  2094/ 2172] train: loss: 0.0013333
[Epoch 24; Iter  2124/ 2172] train: loss: 0.0899787
[Epoch 24; Iter  2154/ 2172] train: loss: 0.0015620
[Epoch 24] ogbg-molmuv: 0.038376 val loss: 0.012082
[Epoch 24] ogbg-molmuv: 0.100852 test loss: 0.017945
[Epoch 25; Iter    12/ 2172] train: loss: 0.0021476
[Epoch 25; Iter    42/ 2172] train: loss: 0.0012771
[Epoch 25; Iter    72/ 2172] train: loss: 0.0339704
[Epoch 25; Iter   102/ 2172] train: loss: 0.0016388
[Epoch 25; Iter   132/ 2172] train: loss: 0.0030723
[Epoch 25; Iter   162/ 2172] train: loss: 0.0011356
[Epoch 25; Iter   192/ 2172] train: loss: 0.0020960
[Epoch 25; Iter   222/ 2172] train: loss: 0.0024058
[Epoch 25; Iter   252/ 2172] train: loss: 0.0540870
[Epoch 25; Iter   282/ 2172] train: loss: 0.0019478
[Epoch 25; Iter   312/ 2172] train: loss: 0.0027765
[Epoch 25; Iter   342/ 2172] train: loss: 0.0020822
[Epoch 25; Iter   372/ 2172] train: loss: 0.1385065
[Epoch 25; Iter   402/ 2172] train: loss: 0.0011759
[Epoch 25; Iter   432/ 2172] train: loss: 0.0013176
[Epoch 25; Iter   462/ 2172] train: loss: 0.0036482
[Epoch 25; Iter   492/ 2172] train: loss: 0.0013255
[Epoch 25; Iter   522/ 2172] train: loss: 0.0016771
[Epoch 25; Iter   552/ 2172] train: loss: 0.0017140
[Epoch 25; Iter   582/ 2172] train: loss: 0.0022799
[Epoch 25; Iter   612/ 2172] train: loss: 0.0012468
[Epoch 25; Iter   642/ 2172] train: loss: 0.0014774
[Epoch 25; Iter   672/ 2172] train: loss: 0.0597659
[Epoch 25; Iter   702/ 2172] train: loss: 0.0010153
[Epoch 25; Iter   732/ 2172] train: loss: 0.0009238
[Epoch 25; Iter   762/ 2172] train: loss: 0.0012080
[Epoch 25; Iter   792/ 2172] train: loss: 0.0008480
[Epoch 25; Iter   822/ 2172] train: loss: 0.0011223
[Epoch 25; Iter   852/ 2172] train: loss: 0.0012163
[Epoch 25; Iter   882/ 2172] train: loss: 0.0010993
[Epoch 25; Iter   912/ 2172] train: loss: 0.0018603
[Epoch 25; Iter   942/ 2172] train: loss: 0.0034769
[Epoch 25; Iter   972/ 2172] train: loss: 0.0014036
[Epoch 25; Iter  1002/ 2172] train: loss: 0.0033816
[Epoch 25; Iter  1032/ 2172] train: loss: 0.0019237
[Epoch 25; Iter  1062/ 2172] train: loss: 0.0014838
[Epoch 25; Iter  1092/ 2172] train: loss: 0.0023073
[Epoch 25; Iter  1122/ 2172] train: loss: 0.0012115
[Epoch 25; Iter  1152/ 2172] train: loss: 0.0010114
[Epoch 25; Iter  1182/ 2172] train: loss: 0.0010418
[Epoch 25; Iter  1212/ 2172] train: loss: 0.0013506
[Epoch 25; Iter  1242/ 2172] train: loss: 0.1128080
[Epoch 25; Iter  1272/ 2172] train: loss: 0.0019732
[Epoch 25; Iter  1302/ 2172] train: loss: 0.0010797
[Epoch 25; Iter  1332/ 2172] train: loss: 0.0012722
[Epoch 25; Iter  1362/ 2172] train: loss: 0.0017993
[Epoch 25; Iter  1392/ 2172] train: loss: 0.0962630
[Epoch 25; Iter  1422/ 2172] train: loss: 0.0017679
[Epoch 25; Iter  1452/ 2172] train: loss: 0.0022396
[Epoch 25; Iter  1482/ 2172] train: loss: 0.0020277
[Epoch 25; Iter  1512/ 2172] train: loss: 0.0017673
[Epoch 25; Iter  1542/ 2172] train: loss: 0.0012296
[Epoch 25; Iter  1572/ 2172] train: loss: 0.0013267
[Epoch 25; Iter  1602/ 2172] train: loss: 0.0014679
[Epoch 25; Iter  1632/ 2172] train: loss: 0.0012704
[Epoch 25; Iter  1662/ 2172] train: loss: 0.0017520
[Epoch 25; Iter  1692/ 2172] train: loss: 0.0013781
[Epoch 25; Iter  1722/ 2172] train: loss: 0.0010994
[Epoch 25; Iter  1752/ 2172] train: loss: 0.0020275
[Epoch 25; Iter  1782/ 2172] train: loss: 0.0039781
[Epoch 25; Iter  1812/ 2172] train: loss: 0.0492805
[Epoch 25; Iter  1842/ 2172] train: loss: 0.0634287
[Epoch 22; Iter  2067/ 2483] train: loss: 0.0017482
[Epoch 22; Iter  2097/ 2483] train: loss: 0.0014160
[Epoch 22; Iter  2127/ 2483] train: loss: 0.0010287
[Epoch 22; Iter  2157/ 2483] train: loss: 0.0017795
[Epoch 22; Iter  2187/ 2483] train: loss: 0.0030093
[Epoch 22; Iter  2217/ 2483] train: loss: 0.0018885
[Epoch 22; Iter  2247/ 2483] train: loss: 0.0321418
[Epoch 22; Iter  2277/ 2483] train: loss: 0.0019358
[Epoch 22; Iter  2307/ 2483] train: loss: 0.0024189
[Epoch 22; Iter  2337/ 2483] train: loss: 0.0014611
[Epoch 22; Iter  2367/ 2483] train: loss: 0.0794267
[Epoch 22; Iter  2397/ 2483] train: loss: 0.0639104
[Epoch 22; Iter  2427/ 2483] train: loss: 0.0013847
[Epoch 22; Iter  2457/ 2483] train: loss: 0.0015422
[Epoch 22] ogbg-molmuv: 0.116254 val loss: 0.009855
[Epoch 22] ogbg-molmuv: 0.123350 test loss: 0.014282
[Epoch 23; Iter     4/ 2483] train: loss: 0.0510684
[Epoch 23; Iter    34/ 2483] train: loss: 0.0013100
[Epoch 23; Iter    64/ 2483] train: loss: 0.1015420
[Epoch 23; Iter    94/ 2483] train: loss: 0.0011193
[Epoch 23; Iter   124/ 2483] train: loss: 0.0022251
[Epoch 23; Iter   154/ 2483] train: loss: 0.0011750
[Epoch 23; Iter   184/ 2483] train: loss: 0.0818883
[Epoch 23; Iter   214/ 2483] train: loss: 0.0017898
[Epoch 23; Iter   244/ 2483] train: loss: 0.0018298
[Epoch 23; Iter   274/ 2483] train: loss: 0.0019869
[Epoch 23; Iter   304/ 2483] train: loss: 0.0019754
[Epoch 23; Iter   334/ 2483] train: loss: 0.0024984
[Epoch 23; Iter   364/ 2483] train: loss: 0.0017995
[Epoch 23; Iter   394/ 2483] train: loss: 0.0018592
[Epoch 23; Iter   424/ 2483] train: loss: 0.0020788
[Epoch 23; Iter   454/ 2483] train: loss: 0.0011581
[Epoch 23; Iter   484/ 2483] train: loss: 0.0015280
[Epoch 23; Iter   514/ 2483] train: loss: 0.0021723
[Epoch 23; Iter   544/ 2483] train: loss: 0.0025031
[Epoch 23; Iter   574/ 2483] train: loss: 0.0030105
[Epoch 23; Iter   604/ 2483] train: loss: 0.0017516
[Epoch 23; Iter   634/ 2483] train: loss: 0.0015402
[Epoch 23; Iter   664/ 2483] train: loss: 0.0016830
[Epoch 23; Iter   694/ 2483] train: loss: 0.0010783
[Epoch 23; Iter   724/ 2483] train: loss: 0.0844546
[Epoch 23; Iter   754/ 2483] train: loss: 0.0015769
[Epoch 23; Iter   784/ 2483] train: loss: 0.0034779
[Epoch 23; Iter   814/ 2483] train: loss: 0.0014228
[Epoch 23; Iter   844/ 2483] train: loss: 0.0013395
[Epoch 23; Iter   874/ 2483] train: loss: 0.0021342
[Epoch 23; Iter   904/ 2483] train: loss: 0.0040528
[Epoch 23; Iter   934/ 2483] train: loss: 0.0018250
[Epoch 23; Iter   964/ 2483] train: loss: 0.0017260
[Epoch 23; Iter   994/ 2483] train: loss: 0.0021308
[Epoch 23; Iter  1024/ 2483] train: loss: 0.0015799
[Epoch 23; Iter  1054/ 2483] train: loss: 0.0014883
[Epoch 23; Iter  1084/ 2483] train: loss: 0.0009853
[Epoch 23; Iter  1114/ 2483] train: loss: 0.0011335
[Epoch 23; Iter  1144/ 2483] train: loss: 0.0018733
[Epoch 23; Iter  1174/ 2483] train: loss: 0.0015188
[Epoch 23; Iter  1204/ 2483] train: loss: 0.0628446
[Epoch 23; Iter  1234/ 2483] train: loss: 0.0023745
[Epoch 23; Iter  1264/ 2483] train: loss: 0.0011693
[Epoch 23; Iter  1294/ 2483] train: loss: 0.0012204
[Epoch 23; Iter  1324/ 2483] train: loss: 0.0029180
[Epoch 23; Iter  1354/ 2483] train: loss: 0.0032044
[Epoch 23; Iter  1384/ 2483] train: loss: 0.0016584
[Epoch 23; Iter  1414/ 2483] train: loss: 0.0024116
[Epoch 23; Iter  1444/ 2483] train: loss: 0.0020371
[Epoch 23; Iter  1474/ 2483] train: loss: 0.0029416
[Epoch 23; Iter  1504/ 2483] train: loss: 0.0763314
[Epoch 23; Iter  1534/ 2483] train: loss: 0.0016898
[Epoch 23; Iter  1564/ 2483] train: loss: 0.0108290
[Epoch 23; Iter  1594/ 2483] train: loss: 0.0014428
[Epoch 23; Iter  1624/ 2483] train: loss: 0.0020537
[Epoch 23; Iter  1654/ 2483] train: loss: 0.0014043
[Epoch 23; Iter  1684/ 2483] train: loss: 0.0018134
[Epoch 23; Iter  1714/ 2483] train: loss: 0.0018636
[Epoch 23; Iter  1744/ 2483] train: loss: 0.0019174
[Epoch 23; Iter  1774/ 2483] train: loss: 0.0014411
[Epoch 23; Iter  1804/ 2483] train: loss: 0.0012567
[Epoch 23; Iter  1834/ 2483] train: loss: 0.0011305
[Epoch 23; Iter  1864/ 2483] train: loss: 0.0012972
[Epoch 23; Iter  1894/ 2483] train: loss: 0.0700194
[Epoch 23; Iter  1924/ 2483] train: loss: 0.0021169
[Epoch 23; Iter  1954/ 2483] train: loss: 0.0015499
[Epoch 23; Iter  1984/ 2483] train: loss: 0.0015712
[Epoch 23; Iter  2014/ 2483] train: loss: 0.0015080
[Epoch 23; Iter  2044/ 2483] train: loss: 0.0012746
[Epoch 23; Iter  2074/ 2483] train: loss: 0.0014378
[Epoch 23; Iter  2104/ 2483] train: loss: 0.0015606
[Epoch 23; Iter  2134/ 2483] train: loss: 0.0017497
[Epoch 23; Iter  2164/ 2483] train: loss: 0.0017160
[Epoch 23; Iter  2194/ 2483] train: loss: 0.0019629
[Epoch 23; Iter  2224/ 2483] train: loss: 0.0011186
[Epoch 23; Iter  2254/ 2483] train: loss: 0.0020766
[Epoch 23; Iter  2284/ 2483] train: loss: 0.0705978
[Epoch 23; Iter  2314/ 2483] train: loss: 0.0015269
[Epoch 23; Iter  2344/ 2483] train: loss: 0.0012580
[Epoch 23; Iter  2374/ 2483] train: loss: 0.0011740
[Epoch 23; Iter  2404/ 2483] train: loss: 0.0023664
[Epoch 23; Iter  2434/ 2483] train: loss: 0.0013002
[Epoch 23; Iter  2464/ 2483] train: loss: 0.0011558
[Epoch 23] ogbg-molmuv: 0.131899 val loss: 0.009465
[Epoch 23] ogbg-molmuv: 0.137326 test loss: 0.013435
[Epoch 24; Iter    11/ 2483] train: loss: 0.0014172
[Epoch 24; Iter    41/ 2483] train: loss: 0.0017279
[Epoch 24; Iter    71/ 2483] train: loss: 0.0013344
[Epoch 24; Iter   101/ 2483] train: loss: 0.0021997
[Epoch 24; Iter   131/ 2483] train: loss: 0.0432349
[Epoch 24; Iter   161/ 2483] train: loss: 0.0030803
[Epoch 24; Iter   191/ 2483] train: loss: 0.0021765
[Epoch 24; Iter   221/ 2483] train: loss: 0.0021898
[Epoch 24; Iter   251/ 2483] train: loss: 0.0027603
[Epoch 24; Iter   281/ 2483] train: loss: 0.0015496
[Epoch 24; Iter   311/ 2483] train: loss: 0.0014138
[Epoch 24; Iter   341/ 2483] train: loss: 0.0024977
[Epoch 24; Iter   371/ 2483] train: loss: 0.0018144
[Epoch 24; Iter   401/ 2483] train: loss: 0.0022222
[Epoch 24; Iter   431/ 2483] train: loss: 0.0752418
[Epoch 24; Iter   461/ 2483] train: loss: 0.0797532
[Epoch 24; Iter   491/ 2483] train: loss: 0.0010850
[Epoch 24; Iter   521/ 2483] train: loss: 0.0799732
[Epoch 24; Iter   551/ 2483] train: loss: 0.0976826
[Epoch 24; Iter   581/ 2483] train: loss: 0.0019905
[Epoch 24; Iter   611/ 2483] train: loss: 0.0017365
[Epoch 24; Iter   641/ 2483] train: loss: 0.0020915
[Epoch 24; Iter   671/ 2483] train: loss: 0.0010380
[Epoch 24; Iter   701/ 2483] train: loss: 0.0010929
[Epoch 24; Iter   731/ 2483] train: loss: 0.0011021
[Epoch 24; Iter   761/ 2483] train: loss: 0.0190826
[Epoch 24; Iter   791/ 2483] train: loss: 0.0014903
[Epoch 24; Iter   821/ 2483] train: loss: 0.0032696
[Epoch 24; Iter   851/ 2483] train: loss: 0.0012134
[Epoch 24; Iter   881/ 2483] train: loss: 0.1539117
[Epoch 24; Iter   911/ 2483] train: loss: 0.0019545
[Epoch 24; Iter   941/ 2483] train: loss: 0.0014013
[Epoch 24; Iter   971/ 2483] train: loss: 0.0011642
[Epoch 24; Iter  1001/ 2483] train: loss: 0.0017547
[Epoch 24; Iter  1031/ 2483] train: loss: 0.0894483
[Epoch 24; Iter  1061/ 2483] train: loss: 0.0012666
[Epoch 24; Iter  1091/ 2483] train: loss: 0.0613657
[Epoch 24; Iter  1121/ 2483] train: loss: 0.0017066
[Epoch 24; Iter  1151/ 2483] train: loss: 0.0016869
[Epoch 24; Iter  1181/ 2483] train: loss: 0.0015457
[Epoch 24; Iter  1211/ 2483] train: loss: 0.0016810
[Epoch 24; Iter  1241/ 2483] train: loss: 0.0855500
[Epoch 24; Iter  1271/ 2483] train: loss: 0.0014989
[Epoch 24; Iter  1301/ 2483] train: loss: 0.0021552
[Epoch 24; Iter  1331/ 2483] train: loss: 0.0604853
[Epoch 24; Iter  1361/ 2483] train: loss: 0.0023398
[Epoch 24; Iter  1391/ 2483] train: loss: 0.0020928
[Epoch 24; Iter  1421/ 2483] train: loss: 0.0011948
[Epoch 24; Iter  1451/ 2483] train: loss: 0.0009991
[Epoch 24; Iter  1481/ 2483] train: loss: 0.0008914
[Epoch 24; Iter  1511/ 2483] train: loss: 0.0007793
[Epoch 24; Iter  1541/ 2483] train: loss: 0.0012280
[Epoch 24; Iter  1571/ 2483] train: loss: 0.0239605
[Epoch 24; Iter  1601/ 2483] train: loss: 0.0011373
[Epoch 24; Iter  1631/ 2483] train: loss: 0.0019526
[Epoch 24; Iter  1661/ 2483] train: loss: 0.0720885
[Epoch 23; Iter  1626/ 2172] train: loss: 0.0018810
[Epoch 23; Iter  1656/ 2172] train: loss: 0.0035331
[Epoch 23; Iter  1686/ 2172] train: loss: 0.0019832
[Epoch 23; Iter  1716/ 2172] train: loss: 0.0017255
[Epoch 23; Iter  1746/ 2172] train: loss: 0.0016728
[Epoch 23; Iter  1776/ 2172] train: loss: 0.0012371
[Epoch 23; Iter  1806/ 2172] train: loss: 0.0012298
[Epoch 23; Iter  1836/ 2172] train: loss: 0.0008900
[Epoch 23; Iter  1866/ 2172] train: loss: 0.0021575
[Epoch 23; Iter  1896/ 2172] train: loss: 0.0824971
[Epoch 23; Iter  1926/ 2172] train: loss: 0.0009296
[Epoch 23; Iter  1956/ 2172] train: loss: 0.0018101
[Epoch 23; Iter  1986/ 2172] train: loss: 0.0014783
[Epoch 23; Iter  2016/ 2172] train: loss: 0.1440917
[Epoch 23; Iter  2046/ 2172] train: loss: 0.0013853
[Epoch 23; Iter  2076/ 2172] train: loss: 0.0982637
[Epoch 23; Iter  2106/ 2172] train: loss: 0.0017266
[Epoch 23; Iter  2136/ 2172] train: loss: 0.0016826
[Epoch 23; Iter  2166/ 2172] train: loss: 0.0798943
[Epoch 23] ogbg-molmuv: 0.039074 val loss: 0.019206
[Epoch 23] ogbg-molmuv: 0.088790 test loss: 0.026771
[Epoch 24; Iter    24/ 2172] train: loss: 0.0015925
[Epoch 24; Iter    54/ 2172] train: loss: 0.0039608
[Epoch 24; Iter    84/ 2172] train: loss: 0.0018745
[Epoch 24; Iter   114/ 2172] train: loss: 0.0013706
[Epoch 24; Iter   144/ 2172] train: loss: 0.0021207
[Epoch 24; Iter   174/ 2172] train: loss: 0.0052113
[Epoch 24; Iter   204/ 2172] train: loss: 0.0026654
[Epoch 24; Iter   234/ 2172] train: loss: 0.0030824
[Epoch 24; Iter   264/ 2172] train: loss: 0.0018415
[Epoch 24; Iter   294/ 2172] train: loss: 0.0013254
[Epoch 24; Iter   324/ 2172] train: loss: 0.0882680
[Epoch 24; Iter   354/ 2172] train: loss: 0.0017577
[Epoch 24; Iter   384/ 2172] train: loss: 0.0210164
[Epoch 24; Iter   414/ 2172] train: loss: 0.0021798
[Epoch 24; Iter   444/ 2172] train: loss: 0.0010014
[Epoch 24; Iter   474/ 2172] train: loss: 0.0012863
[Epoch 24; Iter   504/ 2172] train: loss: 0.0459143
[Epoch 24; Iter   534/ 2172] train: loss: 0.0011816
[Epoch 24; Iter   564/ 2172] train: loss: 0.0083738
[Epoch 24; Iter   594/ 2172] train: loss: 0.0365816
[Epoch 24; Iter   624/ 2172] train: loss: 0.0012958
[Epoch 24; Iter   654/ 2172] train: loss: 0.0014536
[Epoch 24; Iter   684/ 2172] train: loss: 0.0014125
[Epoch 24; Iter   714/ 2172] train: loss: 0.0010228
[Epoch 24; Iter   744/ 2172] train: loss: 0.0012672
[Epoch 24; Iter   774/ 2172] train: loss: 0.0014659
[Epoch 24; Iter   804/ 2172] train: loss: 0.0010374
[Epoch 24; Iter   834/ 2172] train: loss: 0.0013211
[Epoch 24; Iter   864/ 2172] train: loss: 0.0017751
[Epoch 24; Iter   894/ 2172] train: loss: 0.0013414
[Epoch 24; Iter   924/ 2172] train: loss: 0.0018126
[Epoch 24; Iter   954/ 2172] train: loss: 0.0015886
[Epoch 24; Iter   984/ 2172] train: loss: 0.1023263
[Epoch 24; Iter  1014/ 2172] train: loss: 0.0033397
[Epoch 24; Iter  1044/ 2172] train: loss: 0.0015907
[Epoch 24; Iter  1074/ 2172] train: loss: 0.0513536
[Epoch 24; Iter  1104/ 2172] train: loss: 0.0017373
[Epoch 24; Iter  1134/ 2172] train: loss: 0.0015838
[Epoch 24; Iter  1164/ 2172] train: loss: 0.0015041
[Epoch 24; Iter  1194/ 2172] train: loss: 0.0704526
[Epoch 24; Iter  1224/ 2172] train: loss: 0.0012659
[Epoch 24; Iter  1254/ 2172] train: loss: 0.0015573
[Epoch 24; Iter  1284/ 2172] train: loss: 0.0427272
[Epoch 24; Iter  1314/ 2172] train: loss: 0.0016540
[Epoch 24; Iter  1344/ 2172] train: loss: 0.0012486
[Epoch 24; Iter  1374/ 2172] train: loss: 0.0011923
[Epoch 24; Iter  1404/ 2172] train: loss: 0.0017162
[Epoch 24; Iter  1434/ 2172] train: loss: 0.0100373
[Epoch 24; Iter  1464/ 2172] train: loss: 0.0014775
[Epoch 24; Iter  1494/ 2172] train: loss: 0.0037966
[Epoch 24; Iter  1524/ 2172] train: loss: 0.0014892
[Epoch 24; Iter  1554/ 2172] train: loss: 0.0019741
[Epoch 24; Iter  1584/ 2172] train: loss: 0.0013198
[Epoch 24; Iter  1614/ 2172] train: loss: 0.0050552
[Epoch 24; Iter  1644/ 2172] train: loss: 0.0014952
[Epoch 24; Iter  1674/ 2172] train: loss: 0.0736428
[Epoch 24; Iter  1704/ 2172] train: loss: 0.0017973
[Epoch 24; Iter  1734/ 2172] train: loss: 0.0025281
[Epoch 24; Iter  1764/ 2172] train: loss: 0.0014142
[Epoch 24; Iter  1794/ 2172] train: loss: 0.0848201
[Epoch 24; Iter  1824/ 2172] train: loss: 0.0018098
[Epoch 24; Iter  1854/ 2172] train: loss: 0.0030049
[Epoch 24; Iter  1884/ 2172] train: loss: 0.0013049
[Epoch 24; Iter  1914/ 2172] train: loss: 0.0022923
[Epoch 24; Iter  1944/ 2172] train: loss: 0.0020334
[Epoch 24; Iter  1974/ 2172] train: loss: 0.0152955
[Epoch 24; Iter  2004/ 2172] train: loss: 0.0019622
[Epoch 24; Iter  2034/ 2172] train: loss: 0.0022050
[Epoch 24; Iter  2064/ 2172] train: loss: 0.0048029
[Epoch 24; Iter  2094/ 2172] train: loss: 0.0014607
[Epoch 24; Iter  2124/ 2172] train: loss: 0.0014469
[Epoch 24; Iter  2154/ 2172] train: loss: 0.0021141
[Epoch 24] ogbg-molmuv: 0.046690 val loss: 0.012921
[Epoch 24] ogbg-molmuv: 0.102982 test loss: 0.030807
[Epoch 25; Iter    12/ 2172] train: loss: 0.0019741
[Epoch 25; Iter    42/ 2172] train: loss: 0.0016026
[Epoch 25; Iter    72/ 2172] train: loss: 0.0679470
[Epoch 25; Iter   102/ 2172] train: loss: 0.0030463
[Epoch 25; Iter   132/ 2172] train: loss: 0.0692577
[Epoch 25; Iter   162/ 2172] train: loss: 0.0022252
[Epoch 25; Iter   192/ 2172] train: loss: 0.0013452
[Epoch 25; Iter   222/ 2172] train: loss: 0.0035804
[Epoch 25; Iter   252/ 2172] train: loss: 0.0018587
[Epoch 25; Iter   282/ 2172] train: loss: 0.0017190
[Epoch 25; Iter   312/ 2172] train: loss: 0.0025191
[Epoch 25; Iter   342/ 2172] train: loss: 0.0024823
[Epoch 25; Iter   372/ 2172] train: loss: 0.0028586
[Epoch 25; Iter   402/ 2172] train: loss: 0.0020232
[Epoch 25; Iter   432/ 2172] train: loss: 0.0012756
[Epoch 25; Iter   462/ 2172] train: loss: 0.0013096
[Epoch 25; Iter   492/ 2172] train: loss: 0.0017107
[Epoch 25; Iter   522/ 2172] train: loss: 0.0449066
[Epoch 25; Iter   552/ 2172] train: loss: 0.0020030
[Epoch 25; Iter   582/ 2172] train: loss: 0.0133481
[Epoch 25; Iter   612/ 2172] train: loss: 0.0013398
[Epoch 25; Iter   642/ 2172] train: loss: 0.0011940
[Epoch 25; Iter   672/ 2172] train: loss: 0.0013033
[Epoch 25; Iter   702/ 2172] train: loss: 0.0012395
[Epoch 25; Iter   732/ 2172] train: loss: 0.0010629
[Epoch 25; Iter   762/ 2172] train: loss: 0.0021316
[Epoch 25; Iter   792/ 2172] train: loss: 0.0013208
[Epoch 25; Iter   822/ 2172] train: loss: 0.0207199
[Epoch 25; Iter   852/ 2172] train: loss: 0.0033071
[Epoch 25; Iter   882/ 2172] train: loss: 0.0317315
[Epoch 25; Iter   912/ 2172] train: loss: 0.0027391
[Epoch 25; Iter   942/ 2172] train: loss: 0.0027609
[Epoch 25; Iter   972/ 2172] train: loss: 0.0021858
[Epoch 25; Iter  1002/ 2172] train: loss: 0.0015446
[Epoch 25; Iter  1032/ 2172] train: loss: 0.0015825
[Epoch 25; Iter  1062/ 2172] train: loss: 0.0011767
[Epoch 25; Iter  1092/ 2172] train: loss: 0.0019240
[Epoch 25; Iter  1122/ 2172] train: loss: 0.0838137
[Epoch 25; Iter  1152/ 2172] train: loss: 0.0721181
[Epoch 25; Iter  1182/ 2172] train: loss: 0.1778697
[Epoch 25; Iter  1212/ 2172] train: loss: 0.0412014
[Epoch 25; Iter  1242/ 2172] train: loss: 0.0013325
[Epoch 25; Iter  1272/ 2172] train: loss: 0.0552436
[Epoch 25; Iter  1302/ 2172] train: loss: 0.0016583
[Epoch 25; Iter  1332/ 2172] train: loss: 0.0015925
[Epoch 25; Iter  1362/ 2172] train: loss: 0.0010710
[Epoch 25; Iter  1392/ 2172] train: loss: 0.0016642
[Epoch 25; Iter  1422/ 2172] train: loss: 0.0010064
[Epoch 25; Iter  1452/ 2172] train: loss: 0.0016294
[Epoch 25; Iter  1482/ 2172] train: loss: 0.0022956
[Epoch 25; Iter  1512/ 2172] train: loss: 0.0018648
[Epoch 25; Iter  1542/ 2172] train: loss: 0.0013731
[Epoch 25; Iter  1572/ 2172] train: loss: 0.0024247
[Epoch 25; Iter  1602/ 2172] train: loss: 0.0993583
[Epoch 25; Iter  1632/ 2172] train: loss: 0.0019873
[Epoch 25; Iter  1662/ 2172] train: loss: 0.0022098
[Epoch 25; Iter  1692/ 2172] train: loss: 0.0530987
[Epoch 25; Iter  1722/ 2172] train: loss: 0.0014673
[Epoch 25; Iter  1752/ 2172] train: loss: 0.0018029
[Epoch 25; Iter  1782/ 2172] train: loss: 0.0015097
[Epoch 25; Iter  1812/ 2172] train: loss: 0.0020328
[Epoch 25; Iter  1842/ 2172] train: loss: 0.0022691
[Epoch 24; Iter  1754/ 1862] train: loss: 0.0010716
[Epoch 24; Iter  1784/ 1862] train: loss: 0.0015378
[Epoch 24; Iter  1814/ 1862] train: loss: 0.0013526
[Epoch 24; Iter  1844/ 1862] train: loss: 0.0374550
[Epoch 24] ogbg-molmuv: 0.086040 val loss: 0.012993
[Epoch 24] ogbg-molmuv: 0.084167 test loss: 0.012271
[Epoch 25; Iter    12/ 1862] train: loss: 0.0010663
[Epoch 25; Iter    42/ 1862] train: loss: 0.0020710
[Epoch 25; Iter    72/ 1862] train: loss: 0.0013679
[Epoch 25; Iter   102/ 1862] train: loss: 0.0016522
[Epoch 25; Iter   132/ 1862] train: loss: 0.0014602
[Epoch 25; Iter   162/ 1862] train: loss: 0.0012543
[Epoch 25; Iter   192/ 1862] train: loss: 0.0037186
[Epoch 25; Iter   222/ 1862] train: loss: 0.0404251
[Epoch 25; Iter   252/ 1862] train: loss: 0.0014774
[Epoch 25; Iter   282/ 1862] train: loss: 0.0041433
[Epoch 25; Iter   312/ 1862] train: loss: 0.0009648
[Epoch 25; Iter   342/ 1862] train: loss: 0.0020344
[Epoch 25; Iter   372/ 1862] train: loss: 0.0024161
[Epoch 25; Iter   402/ 1862] train: loss: 0.0019407
[Epoch 25; Iter   432/ 1862] train: loss: 0.0022818
[Epoch 25; Iter   462/ 1862] train: loss: 0.0010971
[Epoch 25; Iter   492/ 1862] train: loss: 0.0014842
[Epoch 25; Iter   522/ 1862] train: loss: 0.0051595
[Epoch 25; Iter   552/ 1862] train: loss: 0.0012954
[Epoch 25; Iter   582/ 1862] train: loss: 0.0032406
[Epoch 25; Iter   612/ 1862] train: loss: 0.0023983
[Epoch 25; Iter   642/ 1862] train: loss: 0.0014195
[Epoch 25; Iter   672/ 1862] train: loss: 0.0034633
[Epoch 25; Iter   702/ 1862] train: loss: 0.0009646
[Epoch 25; Iter   732/ 1862] train: loss: 0.0035089
[Epoch 25; Iter   762/ 1862] train: loss: 0.0013342
[Epoch 25; Iter   792/ 1862] train: loss: 0.0013323
[Epoch 25; Iter   822/ 1862] train: loss: 0.0013792
[Epoch 25; Iter   852/ 1862] train: loss: 0.0273012
[Epoch 25; Iter   882/ 1862] train: loss: 0.0023814
[Epoch 25; Iter   912/ 1862] train: loss: 0.0009567
[Epoch 25; Iter   942/ 1862] train: loss: 0.0016459
[Epoch 25; Iter   972/ 1862] train: loss: 0.0030894
[Epoch 25; Iter  1002/ 1862] train: loss: 0.0013800
[Epoch 25; Iter  1032/ 1862] train: loss: 0.0011830
[Epoch 25; Iter  1062/ 1862] train: loss: 0.0009309
[Epoch 25; Iter  1092/ 1862] train: loss: 0.0014922
[Epoch 25; Iter  1122/ 1862] train: loss: 0.0009435
[Epoch 25; Iter  1152/ 1862] train: loss: 0.0015157
[Epoch 25; Iter  1182/ 1862] train: loss: 0.0018071
[Epoch 25; Iter  1212/ 1862] train: loss: 0.0012284
[Epoch 25; Iter  1242/ 1862] train: loss: 0.0287691
[Epoch 25; Iter  1272/ 1862] train: loss: 0.0020936
[Epoch 25; Iter  1302/ 1862] train: loss: 0.0018678
[Epoch 25; Iter  1332/ 1862] train: loss: 0.0021463
[Epoch 25; Iter  1362/ 1862] train: loss: 0.0018910
[Epoch 25; Iter  1392/ 1862] train: loss: 0.0016556
[Epoch 25; Iter  1422/ 1862] train: loss: 0.0015649
[Epoch 25; Iter  1452/ 1862] train: loss: 0.0022187
[Epoch 25; Iter  1482/ 1862] train: loss: 0.0664866
[Epoch 25; Iter  1512/ 1862] train: loss: 0.0012507
[Epoch 25; Iter  1542/ 1862] train: loss: 0.0012252
[Epoch 25; Iter  1572/ 1862] train: loss: 0.0009423
[Epoch 25; Iter  1602/ 1862] train: loss: 0.0014464
[Epoch 25; Iter  1632/ 1862] train: loss: 0.0013153
[Epoch 25; Iter  1662/ 1862] train: loss: 0.0030491
[Epoch 25; Iter  1692/ 1862] train: loss: 0.0020282
[Epoch 25; Iter  1722/ 1862] train: loss: 0.0618266
[Epoch 25; Iter  1752/ 1862] train: loss: 0.0010893
[Epoch 25; Iter  1782/ 1862] train: loss: 0.0023943
[Epoch 25; Iter  1812/ 1862] train: loss: 0.0022407
[Epoch 25; Iter  1842/ 1862] train: loss: 0.0014214
[Epoch 25] ogbg-molmuv: 0.081229 val loss: 0.012932
[Epoch 25] ogbg-molmuv: 0.125809 test loss: 0.011457
[Epoch 26; Iter    10/ 1862] train: loss: 0.0039495
[Epoch 26; Iter    40/ 1862] train: loss: 0.1068550
[Epoch 26; Iter    70/ 1862] train: loss: 0.0025011
[Epoch 26; Iter   100/ 1862] train: loss: 0.0014208
[Epoch 26; Iter   130/ 1862] train: loss: 0.0023941
[Epoch 26; Iter   160/ 1862] train: loss: 0.0016557
[Epoch 26; Iter   190/ 1862] train: loss: 0.0019752
[Epoch 26; Iter   220/ 1862] train: loss: 0.0019383
[Epoch 26; Iter   250/ 1862] train: loss: 0.0026519
[Epoch 26; Iter   280/ 1862] train: loss: 0.0014426
[Epoch 26; Iter   310/ 1862] train: loss: 0.0009161
[Epoch 26; Iter   340/ 1862] train: loss: 0.0020883
[Epoch 26; Iter   370/ 1862] train: loss: 0.0013523
[Epoch 26; Iter   400/ 1862] train: loss: 0.0010597
[Epoch 26; Iter   430/ 1862] train: loss: 0.0790255
[Epoch 26; Iter   460/ 1862] train: loss: 0.0012719
[Epoch 26; Iter   490/ 1862] train: loss: 0.0010494
[Epoch 26; Iter   520/ 1862] train: loss: 0.0020904
[Epoch 26; Iter   550/ 1862] train: loss: 0.0033253
[Epoch 26; Iter   580/ 1862] train: loss: 0.0405634
[Epoch 26; Iter   610/ 1862] train: loss: 0.0022007
[Epoch 26; Iter   640/ 1862] train: loss: 0.0022995
[Epoch 26; Iter   670/ 1862] train: loss: 0.0798865
[Epoch 26; Iter   700/ 1862] train: loss: 0.0707043
[Epoch 26; Iter   730/ 1862] train: loss: 0.0032379
[Epoch 26; Iter   760/ 1862] train: loss: 0.0009934
[Epoch 26; Iter   790/ 1862] train: loss: 0.0015630
[Epoch 26; Iter   820/ 1862] train: loss: 0.0012658
[Epoch 26; Iter   850/ 1862] train: loss: 0.0011425
[Epoch 26; Iter   880/ 1862] train: loss: 0.0735804
[Epoch 26; Iter   910/ 1862] train: loss: 0.0012306
[Epoch 26; Iter   940/ 1862] train: loss: 0.0012461
[Epoch 26; Iter   970/ 1862] train: loss: 0.1085332
[Epoch 26; Iter  1000/ 1862] train: loss: 0.0018773
[Epoch 26; Iter  1030/ 1862] train: loss: 0.0016592
[Epoch 26; Iter  1060/ 1862] train: loss: 0.0014168
[Epoch 26; Iter  1090/ 1862] train: loss: 0.0017865
[Epoch 26; Iter  1120/ 1862] train: loss: 0.0043866
[Epoch 26; Iter  1150/ 1862] train: loss: 0.0435659
[Epoch 26; Iter  1180/ 1862] train: loss: 0.0009120
[Epoch 26; Iter  1210/ 1862] train: loss: 0.0019399
[Epoch 26; Iter  1240/ 1862] train: loss: 0.0772116
[Epoch 26; Iter  1270/ 1862] train: loss: 0.0018432
[Epoch 26; Iter  1300/ 1862] train: loss: 0.0018703
[Epoch 26; Iter  1330/ 1862] train: loss: 0.0012583
[Epoch 26; Iter  1360/ 1862] train: loss: 0.0019760
[Epoch 26; Iter  1390/ 1862] train: loss: 0.0245762
[Epoch 26; Iter  1420/ 1862] train: loss: 0.0258434
[Epoch 26; Iter  1450/ 1862] train: loss: 0.0009876
[Epoch 26; Iter  1480/ 1862] train: loss: 0.0015336
[Epoch 26; Iter  1510/ 1862] train: loss: 0.0012709
[Epoch 26; Iter  1540/ 1862] train: loss: 0.0011771
[Epoch 26; Iter  1570/ 1862] train: loss: 0.0018661
[Epoch 26; Iter  1600/ 1862] train: loss: 0.0008827
[Epoch 26; Iter  1630/ 1862] train: loss: 0.0014280
[Epoch 26; Iter  1660/ 1862] train: loss: 0.0012474
[Epoch 26; Iter  1690/ 1862] train: loss: 0.1223585
[Epoch 26; Iter  1720/ 1862] train: loss: 0.0020200
[Epoch 26; Iter  1750/ 1862] train: loss: 0.0013900
[Epoch 26; Iter  1780/ 1862] train: loss: 0.0014748
[Epoch 26; Iter  1810/ 1862] train: loss: 0.0712740
[Epoch 26; Iter  1840/ 1862] train: loss: 0.0653538
[Epoch 26] ogbg-molmuv: 0.039384 val loss: 0.347663
[Epoch 26] ogbg-molmuv: 0.077548 test loss: 0.133613
[Epoch 27; Iter     8/ 1862] train: loss: 0.0019788
[Epoch 27; Iter    38/ 1862] train: loss: 0.0028682
[Epoch 27; Iter    68/ 1862] train: loss: 0.0633354
[Epoch 27; Iter    98/ 1862] train: loss: 0.0026176
[Epoch 27; Iter   128/ 1862] train: loss: 0.0014435
[Epoch 27; Iter   158/ 1862] train: loss: 0.0016103
[Epoch 27; Iter   188/ 1862] train: loss: 0.0016349
[Epoch 27; Iter   218/ 1862] train: loss: 0.0013206
[Epoch 27; Iter   248/ 1862] train: loss: 0.0011246
[Epoch 27; Iter   278/ 1862] train: loss: 0.0013920
[Epoch 27; Iter   308/ 1862] train: loss: 0.0712443
[Epoch 27; Iter   338/ 1862] train: loss: 0.0035378
[Epoch 27; Iter   368/ 1862] train: loss: 0.0015608
[Epoch 27; Iter   398/ 1862] train: loss: 0.0948001
[Epoch 27; Iter   428/ 1862] train: loss: 0.0863075
[Epoch 27; Iter   458/ 1862] train: loss: 0.0014076
[Epoch 27; Iter   488/ 1862] train: loss: 0.0016481
[Epoch 27; Iter   518/ 1862] train: loss: 0.0391676
[Epoch 27; Iter   548/ 1862] train: loss: 0.0009509
[Epoch 27; Iter   578/ 1862] train: loss: 0.0016135
[Epoch 27; Iter   608/ 1862] train: loss: 0.0015299
[Epoch 27; Iter   638/ 1862] train: loss: 0.0013458
[Epoch 27; Iter   668/ 1862] train: loss: 0.0017518
[Epoch 24; Iter  1754/ 1862] train: loss: 0.0017546
[Epoch 24; Iter  1784/ 1862] train: loss: 0.0018446
[Epoch 24; Iter  1814/ 1862] train: loss: 0.0016571
[Epoch 24; Iter  1844/ 1862] train: loss: 0.0012800
[Epoch 24] ogbg-molmuv: 0.035906 val loss: 0.013965
[Epoch 24] ogbg-molmuv: 0.031066 test loss: 0.012614
[Epoch 25; Iter    12/ 1862] train: loss: 0.0017957
[Epoch 25; Iter    42/ 1862] train: loss: 0.0031598
[Epoch 25; Iter    72/ 1862] train: loss: 0.0054860
[Epoch 25; Iter   102/ 1862] train: loss: 0.0618240
[Epoch 25; Iter   132/ 1862] train: loss: 0.0022107
[Epoch 25; Iter   162/ 1862] train: loss: 0.0022101
[Epoch 25; Iter   192/ 1862] train: loss: 0.0020146
[Epoch 25; Iter   222/ 1862] train: loss: 0.0019611
[Epoch 25; Iter   252/ 1862] train: loss: 0.0011866
[Epoch 25; Iter   282/ 1862] train: loss: 0.0864280
[Epoch 25; Iter   312/ 1862] train: loss: 0.0014190
[Epoch 25; Iter   342/ 1862] train: loss: 0.0025018
[Epoch 25; Iter   372/ 1862] train: loss: 0.0063260
[Epoch 25; Iter   402/ 1862] train: loss: 0.0024847
[Epoch 25; Iter   432/ 1862] train: loss: 0.0015294
[Epoch 25; Iter   462/ 1862] train: loss: 0.0018500
[Epoch 25; Iter   492/ 1862] train: loss: 0.0019193
[Epoch 25; Iter   522/ 1862] train: loss: 0.0019452
[Epoch 25; Iter   552/ 1862] train: loss: 0.0668270
[Epoch 25; Iter   582/ 1862] train: loss: 0.0016046
[Epoch 25; Iter   612/ 1862] train: loss: 0.0009237
[Epoch 25; Iter   642/ 1862] train: loss: 0.1097432
[Epoch 25; Iter   672/ 1862] train: loss: 0.0012967
[Epoch 25; Iter   702/ 1862] train: loss: 0.0013209
[Epoch 25; Iter   732/ 1862] train: loss: 0.0012879
[Epoch 25; Iter   762/ 1862] train: loss: 0.0012056
[Epoch 25; Iter   792/ 1862] train: loss: 0.0025332
[Epoch 25; Iter   822/ 1862] train: loss: 0.0358071
[Epoch 25; Iter   852/ 1862] train: loss: 0.0022267
[Epoch 25; Iter   882/ 1862] train: loss: 0.0016987
[Epoch 25; Iter   912/ 1862] train: loss: 0.0018643
[Epoch 25; Iter   942/ 1862] train: loss: 0.0012264
[Epoch 25; Iter   972/ 1862] train: loss: 0.0910914
[Epoch 25; Iter  1002/ 1862] train: loss: 0.0016308
[Epoch 25; Iter  1032/ 1862] train: loss: 0.0013540
[Epoch 25; Iter  1062/ 1862] train: loss: 0.0658640
[Epoch 25; Iter  1092/ 1862] train: loss: 0.0013828
[Epoch 25; Iter  1122/ 1862] train: loss: 0.0042271
[Epoch 25; Iter  1152/ 1862] train: loss: 0.0015686
[Epoch 25; Iter  1182/ 1862] train: loss: 0.0020632
[Epoch 25; Iter  1212/ 1862] train: loss: 0.0534845
[Epoch 25; Iter  1242/ 1862] train: loss: 0.0013763
[Epoch 25; Iter  1272/ 1862] train: loss: 0.0042264
[Epoch 25; Iter  1302/ 1862] train: loss: 0.0019795
[Epoch 25; Iter  1332/ 1862] train: loss: 0.0012643
[Epoch 25; Iter  1362/ 1862] train: loss: 0.0019756
[Epoch 25; Iter  1392/ 1862] train: loss: 0.0016659
[Epoch 25; Iter  1422/ 1862] train: loss: 0.0017188
[Epoch 25; Iter  1452/ 1862] train: loss: 0.0012871
[Epoch 25; Iter  1482/ 1862] train: loss: 0.0038561
[Epoch 25; Iter  1512/ 1862] train: loss: 0.0015630
[Epoch 25; Iter  1542/ 1862] train: loss: 0.0014874
[Epoch 25; Iter  1572/ 1862] train: loss: 0.0016691
[Epoch 25; Iter  1602/ 1862] train: loss: 0.0016975
[Epoch 25; Iter  1632/ 1862] train: loss: 0.0010894
[Epoch 25; Iter  1662/ 1862] train: loss: 0.0014308
[Epoch 25; Iter  1692/ 1862] train: loss: 0.0041882
[Epoch 25; Iter  1722/ 1862] train: loss: 0.0015960
[Epoch 25; Iter  1752/ 1862] train: loss: 0.0016227
[Epoch 25; Iter  1782/ 1862] train: loss: 0.0422492
[Epoch 25; Iter  1812/ 1862] train: loss: 0.0014648
[Epoch 25; Iter  1842/ 1862] train: loss: 0.0016038
[Epoch 25] ogbg-molmuv: 0.020947 val loss: 0.040440
[Epoch 25] ogbg-molmuv: 0.028086 test loss: 0.071618
[Epoch 26; Iter    10/ 1862] train: loss: 0.0014113
[Epoch 26; Iter    40/ 1862] train: loss: 0.0013661
[Epoch 26; Iter    70/ 1862] train: loss: 0.0013284
[Epoch 26; Iter   100/ 1862] train: loss: 0.0013218
[Epoch 26; Iter   130/ 1862] train: loss: 0.0743178
[Epoch 26; Iter   160/ 1862] train: loss: 0.0027947
[Epoch 26; Iter   190/ 1862] train: loss: 0.0010798
[Epoch 26; Iter   220/ 1862] train: loss: 0.0015430
[Epoch 26; Iter   250/ 1862] train: loss: 0.0010784
[Epoch 26; Iter   280/ 1862] train: loss: 0.0012296
[Epoch 26; Iter   310/ 1862] train: loss: 0.0017626
[Epoch 26; Iter   340/ 1862] train: loss: 0.0009936
[Epoch 26; Iter   370/ 1862] train: loss: 0.0022299
[Epoch 26; Iter   400/ 1862] train: loss: 0.0242845
[Epoch 26; Iter   430/ 1862] train: loss: 0.0013812
[Epoch 26; Iter   460/ 1862] train: loss: 0.0011808
[Epoch 26; Iter   490/ 1862] train: loss: 0.0012579
[Epoch 26; Iter   520/ 1862] train: loss: 0.0009315
[Epoch 26; Iter   550/ 1862] train: loss: 0.0157685
[Epoch 26; Iter   580/ 1862] train: loss: 0.0011954
[Epoch 26; Iter   610/ 1862] train: loss: 0.0849117
[Epoch 26; Iter   640/ 1862] train: loss: 0.0846557
[Epoch 26; Iter   670/ 1862] train: loss: 0.1202557
[Epoch 26; Iter   700/ 1862] train: loss: 0.0011640
[Epoch 26; Iter   730/ 1862] train: loss: 0.0010732
[Epoch 26; Iter   760/ 1862] train: loss: 0.0041714
[Epoch 26; Iter   790/ 1862] train: loss: 0.0647642
[Epoch 26; Iter   820/ 1862] train: loss: 0.0030529
[Epoch 26; Iter   850/ 1862] train: loss: 0.0703173
[Epoch 26; Iter   880/ 1862] train: loss: 0.0027169
[Epoch 26; Iter   910/ 1862] train: loss: 0.0025229
[Epoch 26; Iter   940/ 1862] train: loss: 0.0022087
[Epoch 26; Iter   970/ 1862] train: loss: 0.0031420
[Epoch 26; Iter  1000/ 1862] train: loss: 0.0017172
[Epoch 26; Iter  1030/ 1862] train: loss: 0.0013909
[Epoch 26; Iter  1060/ 1862] train: loss: 0.0065889
[Epoch 26; Iter  1090/ 1862] train: loss: 0.0020114
[Epoch 26; Iter  1120/ 1862] train: loss: 0.0014687
[Epoch 26; Iter  1150/ 1862] train: loss: 0.0013268
[Epoch 26; Iter  1180/ 1862] train: loss: 0.0023746
[Epoch 26; Iter  1210/ 1862] train: loss: 0.0010315
[Epoch 26; Iter  1240/ 1862] train: loss: 0.0535211
[Epoch 26; Iter  1270/ 1862] train: loss: 0.0014386
[Epoch 26; Iter  1300/ 1862] train: loss: 0.0319829
[Epoch 26; Iter  1330/ 1862] train: loss: 0.0023078
[Epoch 26; Iter  1360/ 1862] train: loss: 0.0013419
[Epoch 26; Iter  1390/ 1862] train: loss: 0.0016567
[Epoch 26; Iter  1420/ 1862] train: loss: 0.0012966
[Epoch 26; Iter  1450/ 1862] train: loss: 0.0340129
[Epoch 26; Iter  1480/ 1862] train: loss: 0.0019678
[Epoch 26; Iter  1510/ 1862] train: loss: 0.0013107
[Epoch 26; Iter  1540/ 1862] train: loss: 0.0010491
[Epoch 26; Iter  1570/ 1862] train: loss: 0.0016161
[Epoch 26; Iter  1600/ 1862] train: loss: 0.0018907
[Epoch 26; Iter  1630/ 1862] train: loss: 0.0019297
[Epoch 26; Iter  1660/ 1862] train: loss: 0.0029077
[Epoch 26; Iter  1690/ 1862] train: loss: 0.0020959
[Epoch 26; Iter  1720/ 1862] train: loss: 0.0024299
[Epoch 26; Iter  1750/ 1862] train: loss: 0.0013370
[Epoch 26; Iter  1780/ 1862] train: loss: 0.0014197
[Epoch 26; Iter  1810/ 1862] train: loss: 0.0014997
[Epoch 26; Iter  1840/ 1862] train: loss: 0.0019039
[Epoch 26] ogbg-molmuv: 0.027016 val loss: 0.152420
[Epoch 26] ogbg-molmuv: 0.034136 test loss: 0.121501
[Epoch 27; Iter     8/ 1862] train: loss: 0.0016493
[Epoch 27; Iter    38/ 1862] train: loss: 0.0010798
[Epoch 27; Iter    68/ 1862] train: loss: 0.0012998
[Epoch 27; Iter    98/ 1862] train: loss: 0.0016122
[Epoch 27; Iter   128/ 1862] train: loss: 0.0046697
[Epoch 27; Iter   158/ 1862] train: loss: 0.0017201
[Epoch 27; Iter   188/ 1862] train: loss: 0.0037499
[Epoch 27; Iter   218/ 1862] train: loss: 0.0873062
[Epoch 27; Iter   248/ 1862] train: loss: 0.0021158
[Epoch 27; Iter   278/ 1862] train: loss: 0.0134143
[Epoch 27; Iter   308/ 1862] train: loss: 0.0014817
[Epoch 27; Iter   338/ 1862] train: loss: 0.0730068
[Epoch 27; Iter   368/ 1862] train: loss: 0.0020155
[Epoch 27; Iter   398/ 1862] train: loss: 0.0020246
[Epoch 27; Iter   428/ 1862] train: loss: 0.0017583
[Epoch 27; Iter   458/ 1862] train: loss: 0.0017447
[Epoch 27; Iter   488/ 1862] train: loss: 0.0053523
[Epoch 27; Iter   518/ 1862] train: loss: 0.0011027
[Epoch 27; Iter   548/ 1862] train: loss: 0.0697585
[Epoch 27; Iter   578/ 1862] train: loss: 0.0017943
[Epoch 27; Iter   608/ 1862] train: loss: 0.0025089
[Epoch 27; Iter   638/ 1862] train: loss: 0.0020762
[Epoch 27; Iter   668/ 1862] train: loss: 0.0034108
[Epoch 24; Iter  1754/ 1862] train: loss: 0.0016877
[Epoch 24; Iter  1784/ 1862] train: loss: 0.0015807
[Epoch 24; Iter  1814/ 1862] train: loss: 0.0795479
[Epoch 24; Iter  1844/ 1862] train: loss: 0.1196998
[Epoch 24] ogbg-molmuv: 0.036559 val loss: 0.013690
[Epoch 24] ogbg-molmuv: 0.065364 test loss: 0.012297
[Epoch 25; Iter    12/ 1862] train: loss: 0.0014443
[Epoch 25; Iter    42/ 1862] train: loss: 0.0821760
[Epoch 25; Iter    72/ 1862] train: loss: 0.0027489
[Epoch 25; Iter   102/ 1862] train: loss: 0.0014614
[Epoch 25; Iter   132/ 1862] train: loss: 0.0014091
[Epoch 25; Iter   162/ 1862] train: loss: 0.0012746
[Epoch 25; Iter   192/ 1862] train: loss: 0.0013643
[Epoch 25; Iter   222/ 1862] train: loss: 0.0010382
[Epoch 25; Iter   252/ 1862] train: loss: 0.0024890
[Epoch 25; Iter   282/ 1862] train: loss: 0.0020033
[Epoch 25; Iter   312/ 1862] train: loss: 0.0019564
[Epoch 25; Iter   342/ 1862] train: loss: 0.0950614
[Epoch 25; Iter   372/ 1862] train: loss: 0.0009821
[Epoch 25; Iter   402/ 1862] train: loss: 0.0011570
[Epoch 25; Iter   432/ 1862] train: loss: 0.0015282
[Epoch 25; Iter   462/ 1862] train: loss: 0.0013552
[Epoch 25; Iter   492/ 1862] train: loss: 0.0012302
[Epoch 25; Iter   522/ 1862] train: loss: 0.0019498
[Epoch 25; Iter   552/ 1862] train: loss: 0.0016270
[Epoch 25; Iter   582/ 1862] train: loss: 0.0011679
[Epoch 25; Iter   612/ 1862] train: loss: 0.0026221
[Epoch 25; Iter   642/ 1862] train: loss: 0.0032209
[Epoch 25; Iter   672/ 1862] train: loss: 0.0021713
[Epoch 25; Iter   702/ 1862] train: loss: 0.0027283
[Epoch 25; Iter   732/ 1862] train: loss: 0.0544479
[Epoch 25; Iter   762/ 1862] train: loss: 0.0017061
[Epoch 25; Iter   792/ 1862] train: loss: 0.0070999
[Epoch 25; Iter   822/ 1862] train: loss: 0.0375979
[Epoch 25; Iter   852/ 1862] train: loss: 0.0034300
[Epoch 25; Iter   882/ 1862] train: loss: 0.0012614
[Epoch 25; Iter   912/ 1862] train: loss: 0.0018652
[Epoch 25; Iter   942/ 1862] train: loss: 0.0021164
[Epoch 25; Iter   972/ 1862] train: loss: 0.0012987
[Epoch 25; Iter  1002/ 1862] train: loss: 0.0021473
[Epoch 25; Iter  1032/ 1862] train: loss: 0.0013483
[Epoch 25; Iter  1062/ 1862] train: loss: 0.0025485
[Epoch 25; Iter  1092/ 1862] train: loss: 0.0023384
[Epoch 25; Iter  1122/ 1862] train: loss: 0.0015914
[Epoch 25; Iter  1152/ 1862] train: loss: 0.0016436
[Epoch 25; Iter  1182/ 1862] train: loss: 0.0016660
[Epoch 25; Iter  1212/ 1862] train: loss: 0.0009561
[Epoch 25; Iter  1242/ 1862] train: loss: 0.0802301
[Epoch 25; Iter  1272/ 1862] train: loss: 0.0013328
[Epoch 25; Iter  1302/ 1862] train: loss: 0.0013374
[Epoch 25; Iter  1332/ 1862] train: loss: 0.0017669
[Epoch 25; Iter  1362/ 1862] train: loss: 0.0862377
[Epoch 25; Iter  1392/ 1862] train: loss: 0.0020189
[Epoch 25; Iter  1422/ 1862] train: loss: 0.0016044
[Epoch 25; Iter  1452/ 1862] train: loss: 0.0021977
[Epoch 25; Iter  1482/ 1862] train: loss: 0.0012523
[Epoch 25; Iter  1512/ 1862] train: loss: 0.0013216
[Epoch 25; Iter  1542/ 1862] train: loss: 0.1197497
[Epoch 25; Iter  1572/ 1862] train: loss: 0.0012069
[Epoch 25; Iter  1602/ 1862] train: loss: 0.0017760
[Epoch 25; Iter  1632/ 1862] train: loss: 0.0013993
[Epoch 25; Iter  1662/ 1862] train: loss: 0.0016796
[Epoch 25; Iter  1692/ 1862] train: loss: 0.0018263
[Epoch 25; Iter  1722/ 1862] train: loss: 0.0019713
[Epoch 25; Iter  1752/ 1862] train: loss: 0.0028664
[Epoch 25; Iter  1782/ 1862] train: loss: 0.0506597
[Epoch 25; Iter  1812/ 1862] train: loss: 0.0024413
[Epoch 25; Iter  1842/ 1862] train: loss: 0.0864704
[Epoch 25] ogbg-molmuv: 0.046138 val loss: 0.014420
[Epoch 25] ogbg-molmuv: 0.078336 test loss: 0.012607
[Epoch 26; Iter    10/ 1862] train: loss: 0.0020801
[Epoch 26; Iter    40/ 1862] train: loss: 0.0018113
[Epoch 26; Iter    70/ 1862] train: loss: 0.0031826
[Epoch 26; Iter   100/ 1862] train: loss: 0.0017763
[Epoch 26; Iter   130/ 1862] train: loss: 0.0026110
[Epoch 26; Iter   160/ 1862] train: loss: 0.0011242
[Epoch 26; Iter   190/ 1862] train: loss: 0.0009877
[Epoch 26; Iter   220/ 1862] train: loss: 0.0051791
[Epoch 26; Iter   250/ 1862] train: loss: 0.0012541
[Epoch 26; Iter   280/ 1862] train: loss: 0.0015777
[Epoch 26; Iter   310/ 1862] train: loss: 0.0080709
[Epoch 26; Iter   340/ 1862] train: loss: 0.0355450
[Epoch 26; Iter   370/ 1862] train: loss: 0.0014246
[Epoch 26; Iter   400/ 1862] train: loss: 0.0018700
[Epoch 26; Iter   430/ 1862] train: loss: 0.0014717
[Epoch 26; Iter   460/ 1862] train: loss: 0.1063328
[Epoch 26; Iter   490/ 1862] train: loss: 0.0013762
[Epoch 26; Iter   520/ 1862] train: loss: 0.0031658
[Epoch 26; Iter   550/ 1862] train: loss: 0.0006860
[Epoch 26; Iter   580/ 1862] train: loss: 0.0015268
[Epoch 26; Iter   610/ 1862] train: loss: 0.0013044
[Epoch 26; Iter   640/ 1862] train: loss: 0.0014623
[Epoch 26; Iter   670/ 1862] train: loss: 0.0013703
[Epoch 26; Iter   700/ 1862] train: loss: 0.0049571
[Epoch 26; Iter   730/ 1862] train: loss: 0.0015624
[Epoch 26; Iter   760/ 1862] train: loss: 0.0010204
[Epoch 26; Iter   790/ 1862] train: loss: 0.0038483
[Epoch 26; Iter   820/ 1862] train: loss: 0.0821160
[Epoch 26; Iter   850/ 1862] train: loss: 0.0017425
[Epoch 26; Iter   880/ 1862] train: loss: 0.0031408
[Epoch 26; Iter   910/ 1862] train: loss: 0.0017242
[Epoch 26; Iter   940/ 1862] train: loss: 0.0053747
[Epoch 26; Iter   970/ 1862] train: loss: 0.0020515
[Epoch 26; Iter  1000/ 1862] train: loss: 0.0910330
[Epoch 26; Iter  1030/ 1862] train: loss: 0.0012748
[Epoch 26; Iter  1060/ 1862] train: loss: 0.0016030
[Epoch 26; Iter  1090/ 1862] train: loss: 0.0043682
[Epoch 26; Iter  1120/ 1862] train: loss: 0.0018537
[Epoch 26; Iter  1150/ 1862] train: loss: 0.0019759
[Epoch 26; Iter  1180/ 1862] train: loss: 0.0011454
[Epoch 26; Iter  1210/ 1862] train: loss: 0.0014210
[Epoch 26; Iter  1240/ 1862] train: loss: 0.0024042
[Epoch 26; Iter  1270/ 1862] train: loss: 0.0012120
[Epoch 26; Iter  1300/ 1862] train: loss: 0.0013481
[Epoch 26; Iter  1330/ 1862] train: loss: 0.0019845
[Epoch 26; Iter  1360/ 1862] train: loss: 0.0013361
[Epoch 26; Iter  1390/ 1862] train: loss: 0.0521459
[Epoch 26; Iter  1420/ 1862] train: loss: 0.0015193
[Epoch 26; Iter  1450/ 1862] train: loss: 0.0018818
[Epoch 26; Iter  1480/ 1862] train: loss: 0.0022729
[Epoch 26; Iter  1510/ 1862] train: loss: 0.0020980
[Epoch 26; Iter  1540/ 1862] train: loss: 0.0022978
[Epoch 26; Iter  1570/ 1862] train: loss: 0.0023839
[Epoch 26; Iter  1600/ 1862] train: loss: 0.0019125
[Epoch 26; Iter  1630/ 1862] train: loss: 0.0015810
[Epoch 26; Iter  1660/ 1862] train: loss: 0.0012593
[Epoch 26; Iter  1690/ 1862] train: loss: 0.0019550
[Epoch 26; Iter  1720/ 1862] train: loss: 0.0008888
[Epoch 26; Iter  1750/ 1862] train: loss: 0.0044947
[Epoch 26; Iter  1780/ 1862] train: loss: 0.0011308
[Epoch 26; Iter  1810/ 1862] train: loss: 0.0576615
[Epoch 26; Iter  1840/ 1862] train: loss: 0.0031529
[Epoch 26] ogbg-molmuv: 0.041594 val loss: 0.012849
[Epoch 26] ogbg-molmuv: 0.058075 test loss: 0.011769
[Epoch 27; Iter     8/ 1862] train: loss: 0.0012326
[Epoch 27; Iter    38/ 1862] train: loss: 0.0033510
[Epoch 27; Iter    68/ 1862] train: loss: 0.0013310
[Epoch 27; Iter    98/ 1862] train: loss: 0.0009375
[Epoch 27; Iter   128/ 1862] train: loss: 0.0013913
[Epoch 27; Iter   158/ 1862] train: loss: 0.0014722
[Epoch 27; Iter   188/ 1862] train: loss: 0.0015207
[Epoch 27; Iter   218/ 1862] train: loss: 0.0014159
[Epoch 27; Iter   248/ 1862] train: loss: 0.0015803
[Epoch 27; Iter   278/ 1862] train: loss: 0.0902273
[Epoch 27; Iter   308/ 1862] train: loss: 0.0015146
[Epoch 27; Iter   338/ 1862] train: loss: 0.0114425
[Epoch 27; Iter   368/ 1862] train: loss: 0.0012702
[Epoch 27; Iter   398/ 1862] train: loss: 0.0459209
[Epoch 27; Iter   428/ 1862] train: loss: 0.0012027
[Epoch 27; Iter   458/ 1862] train: loss: 0.0026384
[Epoch 27; Iter   488/ 1862] train: loss: 0.0018337
[Epoch 27; Iter   518/ 1862] train: loss: 0.0886001
[Epoch 27; Iter   548/ 1862] train: loss: 0.0023054
[Epoch 27; Iter   578/ 1862] train: loss: 0.0044319
[Epoch 27; Iter   608/ 1862] train: loss: 0.0026122
[Epoch 27; Iter   638/ 1862] train: loss: 0.0015472
[Epoch 27; Iter   668/ 1862] train: loss: 0.0016894
[Epoch 24; Iter  1691/ 2483] train: loss: 0.0023463
[Epoch 24; Iter  1721/ 2483] train: loss: 0.0033534
[Epoch 24; Iter  1751/ 2483] train: loss: 0.0081267
[Epoch 24; Iter  1781/ 2483] train: loss: 0.0022998
[Epoch 24; Iter  1811/ 2483] train: loss: 0.0024192
[Epoch 24; Iter  1841/ 2483] train: loss: 0.0022492
[Epoch 24; Iter  1871/ 2483] train: loss: 0.0574878
[Epoch 24; Iter  1901/ 2483] train: loss: 0.0014491
[Epoch 24; Iter  1931/ 2483] train: loss: 0.0012741
[Epoch 24; Iter  1961/ 2483] train: loss: 0.0425732
[Epoch 24; Iter  1991/ 2483] train: loss: 0.0028495
[Epoch 24; Iter  2021/ 2483] train: loss: 0.0017982
[Epoch 24; Iter  2051/ 2483] train: loss: 0.0504685
[Epoch 24; Iter  2081/ 2483] train: loss: 0.0017859
[Epoch 24; Iter  2111/ 2483] train: loss: 0.0013683
[Epoch 24; Iter  2141/ 2483] train: loss: 0.0015631
[Epoch 24; Iter  2171/ 2483] train: loss: 0.0009813
[Epoch 24; Iter  2201/ 2483] train: loss: 0.0012050
[Epoch 24; Iter  2231/ 2483] train: loss: 0.0024980
[Epoch 24; Iter  2261/ 2483] train: loss: 0.0954041
[Epoch 24; Iter  2291/ 2483] train: loss: 0.0017757
[Epoch 24; Iter  2321/ 2483] train: loss: 0.0016958
[Epoch 24; Iter  2351/ 2483] train: loss: 0.0024363
[Epoch 24; Iter  2381/ 2483] train: loss: 0.0167208
[Epoch 24; Iter  2411/ 2483] train: loss: 0.0013222
[Epoch 24; Iter  2441/ 2483] train: loss: 0.0010337
[Epoch 24; Iter  2471/ 2483] train: loss: 0.0009123
[Epoch 24] ogbg-molmuv: 0.123546 val loss: 0.015492
[Epoch 24] ogbg-molmuv: 0.119327 test loss: 0.015309
[Epoch 25; Iter    18/ 2483] train: loss: 0.0018916
[Epoch 25; Iter    48/ 2483] train: loss: 0.0029777
[Epoch 25; Iter    78/ 2483] train: loss: 0.0020654
[Epoch 25; Iter   108/ 2483] train: loss: 0.0017954
[Epoch 25; Iter   138/ 2483] train: loss: 0.0012818
[Epoch 25; Iter   168/ 2483] train: loss: 0.0012839
[Epoch 25; Iter   198/ 2483] train: loss: 0.0789226
[Epoch 25; Iter   228/ 2483] train: loss: 0.0026636
[Epoch 25; Iter   258/ 2483] train: loss: 0.0012311
[Epoch 25; Iter   288/ 2483] train: loss: 0.0551479
[Epoch 25; Iter   318/ 2483] train: loss: 0.0015505
[Epoch 25; Iter   348/ 2483] train: loss: 0.0017107
[Epoch 25; Iter   378/ 2483] train: loss: 0.0531362
[Epoch 25; Iter   408/ 2483] train: loss: 0.0034943
[Epoch 25; Iter   438/ 2483] train: loss: 0.0013942
[Epoch 25; Iter   468/ 2483] train: loss: 0.0010405
[Epoch 25; Iter   498/ 2483] train: loss: 0.0901821
[Epoch 25; Iter   528/ 2483] train: loss: 0.0009538
[Epoch 25; Iter   558/ 2483] train: loss: 0.0010385
[Epoch 25; Iter   588/ 2483] train: loss: 0.0010855
[Epoch 25; Iter   618/ 2483] train: loss: 0.0019707
[Epoch 25; Iter   648/ 2483] train: loss: 0.0010296
[Epoch 25; Iter   678/ 2483] train: loss: 0.0022169
[Epoch 25; Iter   708/ 2483] train: loss: 0.0029883
[Epoch 25; Iter   738/ 2483] train: loss: 0.0616122
[Epoch 25; Iter   768/ 2483] train: loss: 0.0016296
[Epoch 25; Iter   798/ 2483] train: loss: 0.0018069
[Epoch 25; Iter   828/ 2483] train: loss: 0.0016243
[Epoch 25; Iter   858/ 2483] train: loss: 0.0021534
[Epoch 25; Iter   888/ 2483] train: loss: 0.0036006
[Epoch 25; Iter   918/ 2483] train: loss: 0.0027435
[Epoch 25; Iter   948/ 2483] train: loss: 0.0393548
[Epoch 25; Iter   978/ 2483] train: loss: 0.0658319
[Epoch 25; Iter  1008/ 2483] train: loss: 0.0014177
[Epoch 25; Iter  1038/ 2483] train: loss: 0.0020797
[Epoch 25; Iter  1068/ 2483] train: loss: 0.0014835
[Epoch 25; Iter  1098/ 2483] train: loss: 0.0017051
[Epoch 25; Iter  1128/ 2483] train: loss: 0.0020816
[Epoch 25; Iter  1158/ 2483] train: loss: 0.0018437
[Epoch 25; Iter  1188/ 2483] train: loss: 0.0021512
[Epoch 25; Iter  1218/ 2483] train: loss: 0.0019541
[Epoch 25; Iter  1248/ 2483] train: loss: 0.0015555
[Epoch 25; Iter  1278/ 2483] train: loss: 0.0013853
[Epoch 25; Iter  1308/ 2483] train: loss: 0.0010931
[Epoch 25; Iter  1338/ 2483] train: loss: 0.0010343
[Epoch 25; Iter  1368/ 2483] train: loss: 0.0020169
[Epoch 25; Iter  1398/ 2483] train: loss: 0.0009646
[Epoch 25; Iter  1428/ 2483] train: loss: 0.0012375
[Epoch 25; Iter  1458/ 2483] train: loss: 0.0011798
[Epoch 25; Iter  1488/ 2483] train: loss: 0.0014584
[Epoch 25; Iter  1518/ 2483] train: loss: 0.0026096
[Epoch 25; Iter  1548/ 2483] train: loss: 0.0015950
[Epoch 25; Iter  1578/ 2483] train: loss: 0.0010314
[Epoch 25; Iter  1608/ 2483] train: loss: 0.0071595
[Epoch 25; Iter  1638/ 2483] train: loss: 0.0016842
[Epoch 25; Iter  1668/ 2483] train: loss: 0.0009871
[Epoch 25; Iter  1698/ 2483] train: loss: 0.0019425
[Epoch 25; Iter  1728/ 2483] train: loss: 0.0079666
[Epoch 25; Iter  1758/ 2483] train: loss: 0.0047747
[Epoch 25; Iter  1788/ 2483] train: loss: 0.0016171
[Epoch 25; Iter  1818/ 2483] train: loss: 0.0014195
[Epoch 25; Iter  1848/ 2483] train: loss: 0.0040173
[Epoch 25; Iter  1878/ 2483] train: loss: 0.0020449
[Epoch 25; Iter  1908/ 2483] train: loss: 0.0015773
[Epoch 25; Iter  1938/ 2483] train: loss: 0.0026547
[Epoch 25; Iter  1968/ 2483] train: loss: 0.0017030
[Epoch 25; Iter  1998/ 2483] train: loss: 0.0013923
[Epoch 25; Iter  2028/ 2483] train: loss: 0.0016380
[Epoch 25; Iter  2058/ 2483] train: loss: 0.0014966
[Epoch 25; Iter  2088/ 2483] train: loss: 0.0551948
[Epoch 25; Iter  2118/ 2483] train: loss: 0.0677528
[Epoch 25; Iter  2148/ 2483] train: loss: 0.0019503
[Epoch 25; Iter  2178/ 2483] train: loss: 0.0017777
[Epoch 25; Iter  2208/ 2483] train: loss: 0.0014430
[Epoch 25; Iter  2238/ 2483] train: loss: 0.0010633
[Epoch 25; Iter  2268/ 2483] train: loss: 0.0013895
[Epoch 25; Iter  2298/ 2483] train: loss: 0.0015166
[Epoch 25; Iter  2328/ 2483] train: loss: 0.0020373
[Epoch 25; Iter  2358/ 2483] train: loss: 0.0023614
[Epoch 25; Iter  2388/ 2483] train: loss: 0.0207346
[Epoch 25; Iter  2418/ 2483] train: loss: 0.0029524
[Epoch 25; Iter  2448/ 2483] train: loss: 0.0021141
[Epoch 25; Iter  2478/ 2483] train: loss: 0.0037912
[Epoch 25] ogbg-molmuv: 0.130988 val loss: 0.009139
[Epoch 25] ogbg-molmuv: 0.132388 test loss: 0.014336
[Epoch 26; Iter    25/ 2483] train: loss: 0.0013247
[Epoch 26; Iter    55/ 2483] train: loss: 0.0820477
[Epoch 26; Iter    85/ 2483] train: loss: 0.0011183
[Epoch 26; Iter   115/ 2483] train: loss: 0.0016205
[Epoch 26; Iter   145/ 2483] train: loss: 0.0011325
[Epoch 26; Iter   175/ 2483] train: loss: 0.0011245
[Epoch 26; Iter   205/ 2483] train: loss: 0.0016173
[Epoch 26; Iter   235/ 2483] train: loss: 0.0015535
[Epoch 26; Iter   265/ 2483] train: loss: 0.0604727
[Epoch 26; Iter   295/ 2483] train: loss: 0.0500411
[Epoch 26; Iter   325/ 2483] train: loss: 0.0161692
[Epoch 26; Iter   355/ 2483] train: loss: 0.0015070
[Epoch 26; Iter   385/ 2483] train: loss: 0.0010020
[Epoch 26; Iter   415/ 2483] train: loss: 0.0128408
[Epoch 26; Iter   445/ 2483] train: loss: 0.0015980
[Epoch 26; Iter   475/ 2483] train: loss: 0.0015896
[Epoch 26; Iter   505/ 2483] train: loss: 0.0010776
[Epoch 26; Iter   535/ 2483] train: loss: 0.0519063
[Epoch 26; Iter   565/ 2483] train: loss: 0.0774153
[Epoch 26; Iter   595/ 2483] train: loss: 0.0018565
[Epoch 26; Iter   625/ 2483] train: loss: 0.0057741
[Epoch 26; Iter   655/ 2483] train: loss: 0.0027850
[Epoch 26; Iter   685/ 2483] train: loss: 0.0087500
[Epoch 26; Iter   715/ 2483] train: loss: 0.0021065
[Epoch 26; Iter   745/ 2483] train: loss: 0.0027097
[Epoch 26; Iter   775/ 2483] train: loss: 0.0012185
[Epoch 26; Iter   805/ 2483] train: loss: 0.0013022
[Epoch 26; Iter   835/ 2483] train: loss: 0.0014578
[Epoch 26; Iter   865/ 2483] train: loss: 0.0009910
[Epoch 26; Iter   895/ 2483] train: loss: 0.0013588
[Epoch 26; Iter   925/ 2483] train: loss: 0.0014823
[Epoch 26; Iter   955/ 2483] train: loss: 0.0012347
[Epoch 26; Iter   985/ 2483] train: loss: 0.0063439
[Epoch 26; Iter  1015/ 2483] train: loss: 0.0074150
[Epoch 26; Iter  1045/ 2483] train: loss: 0.0019212
[Epoch 26; Iter  1075/ 2483] train: loss: 0.0024972
[Epoch 26; Iter  1105/ 2483] train: loss: 0.0013308
[Epoch 26; Iter  1135/ 2483] train: loss: 0.0016725
[Epoch 26; Iter  1165/ 2483] train: loss: 0.0016096
[Epoch 26; Iter  1195/ 2483] train: loss: 0.0021363
[Epoch 26; Iter  1225/ 2483] train: loss: 0.0019819
[Epoch 26; Iter  1255/ 2483] train: loss: 0.0012405
[Epoch 26; Iter  1285/ 2483] train: loss: 0.0013906
[Epoch 24; Iter  1691/ 2483] train: loss: 0.0011254
[Epoch 24; Iter  1721/ 2483] train: loss: 0.0014733
[Epoch 24; Iter  1751/ 2483] train: loss: 0.0012799
[Epoch 24; Iter  1781/ 2483] train: loss: 0.1286178
[Epoch 24; Iter  1811/ 2483] train: loss: 0.0042513
[Epoch 24; Iter  1841/ 2483] train: loss: 0.0020851
[Epoch 24; Iter  1871/ 2483] train: loss: 0.0032119
[Epoch 24; Iter  1901/ 2483] train: loss: 0.0017555
[Epoch 24; Iter  1931/ 2483] train: loss: 0.0012990
[Epoch 24; Iter  1961/ 2483] train: loss: 0.0020431
[Epoch 24; Iter  1991/ 2483] train: loss: 0.0444184
[Epoch 24; Iter  2021/ 2483] train: loss: 0.0014353
[Epoch 24; Iter  2051/ 2483] train: loss: 0.0047806
[Epoch 24; Iter  2081/ 2483] train: loss: 0.0014885
[Epoch 24; Iter  2111/ 2483] train: loss: 0.0014124
[Epoch 24; Iter  2141/ 2483] train: loss: 0.0013490
[Epoch 24; Iter  2171/ 2483] train: loss: 0.0009704
[Epoch 24; Iter  2201/ 2483] train: loss: 0.0018739
[Epoch 24; Iter  2231/ 2483] train: loss: 0.0010014
[Epoch 24; Iter  2261/ 2483] train: loss: 0.0020052
[Epoch 24; Iter  2291/ 2483] train: loss: 0.0050164
[Epoch 24; Iter  2321/ 2483] train: loss: 0.0019470
[Epoch 24; Iter  2351/ 2483] train: loss: 0.0013319
[Epoch 24; Iter  2381/ 2483] train: loss: 0.0016288
[Epoch 24; Iter  2411/ 2483] train: loss: 0.0012595
[Epoch 24; Iter  2441/ 2483] train: loss: 0.0011196
[Epoch 24; Iter  2471/ 2483] train: loss: 0.0015528
[Epoch 24] ogbg-molmuv: 0.131119 val loss: 0.012827
[Epoch 24] ogbg-molmuv: 0.155790 test loss: 0.015166
[Epoch 25; Iter    18/ 2483] train: loss: 0.0024883
[Epoch 25; Iter    48/ 2483] train: loss: 0.0032310
[Epoch 25; Iter    78/ 2483] train: loss: 0.0017288
[Epoch 25; Iter   108/ 2483] train: loss: 0.0023363
[Epoch 25; Iter   138/ 2483] train: loss: 0.0027729
[Epoch 25; Iter   168/ 2483] train: loss: 0.0716351
[Epoch 25; Iter   198/ 2483] train: loss: 0.0014887
[Epoch 25; Iter   228/ 2483] train: loss: 0.0428936
[Epoch 25; Iter   258/ 2483] train: loss: 0.0013285
[Epoch 25; Iter   288/ 2483] train: loss: 0.0730973
[Epoch 25; Iter   318/ 2483] train: loss: 0.0019844
[Epoch 25; Iter   348/ 2483] train: loss: 0.0011346
[Epoch 25; Iter   378/ 2483] train: loss: 0.0013411
[Epoch 25; Iter   408/ 2483] train: loss: 0.0030859
[Epoch 25; Iter   438/ 2483] train: loss: 0.0012527
[Epoch 25; Iter   468/ 2483] train: loss: 0.0019076
[Epoch 25; Iter   498/ 2483] train: loss: 0.0017354
[Epoch 25; Iter   528/ 2483] train: loss: 0.0017131
[Epoch 25; Iter   558/ 2483] train: loss: 0.0032863
[Epoch 25; Iter   588/ 2483] train: loss: 0.0019969
[Epoch 25; Iter   618/ 2483] train: loss: 0.0038176
[Epoch 25; Iter   648/ 2483] train: loss: 0.0013380
[Epoch 25; Iter   678/ 2483] train: loss: 0.0016632
[Epoch 25; Iter   708/ 2483] train: loss: 0.0641732
[Epoch 25; Iter   738/ 2483] train: loss: 0.0021508
[Epoch 25; Iter   768/ 2483] train: loss: 0.0011711
[Epoch 25; Iter   798/ 2483] train: loss: 0.0013064
[Epoch 25; Iter   828/ 2483] train: loss: 0.0021468
[Epoch 25; Iter   858/ 2483] train: loss: 0.0015370
[Epoch 25; Iter   888/ 2483] train: loss: 0.0036630
[Epoch 25; Iter   918/ 2483] train: loss: 0.0052861
[Epoch 25; Iter   948/ 2483] train: loss: 0.0018033
[Epoch 25; Iter   978/ 2483] train: loss: 0.0594047
[Epoch 25; Iter  1008/ 2483] train: loss: 0.0236819
[Epoch 25; Iter  1038/ 2483] train: loss: 0.0013710
[Epoch 25; Iter  1068/ 2483] train: loss: 0.0009033
[Epoch 25; Iter  1098/ 2483] train: loss: 0.0009873
[Epoch 25; Iter  1128/ 2483] train: loss: 0.0010589
[Epoch 25; Iter  1158/ 2483] train: loss: 0.0036308
[Epoch 25; Iter  1188/ 2483] train: loss: 0.0018458
[Epoch 25; Iter  1218/ 2483] train: loss: 0.0598286
[Epoch 25; Iter  1248/ 2483] train: loss: 0.0014054
[Epoch 25; Iter  1278/ 2483] train: loss: 0.0008601
[Epoch 25; Iter  1308/ 2483] train: loss: 0.0014597
[Epoch 25; Iter  1338/ 2483] train: loss: 0.0015559
[Epoch 25; Iter  1368/ 2483] train: loss: 0.0014306
[Epoch 25; Iter  1398/ 2483] train: loss: 0.0012160
[Epoch 25; Iter  1428/ 2483] train: loss: 0.0027837
[Epoch 25; Iter  1458/ 2483] train: loss: 0.0021322
[Epoch 25; Iter  1488/ 2483] train: loss: 0.0022872
[Epoch 25; Iter  1518/ 2483] train: loss: 0.0012176
[Epoch 25; Iter  1548/ 2483] train: loss: 0.0013541
[Epoch 25; Iter  1578/ 2483] train: loss: 0.0019374
[Epoch 25; Iter  1608/ 2483] train: loss: 0.0010997
[Epoch 25; Iter  1638/ 2483] train: loss: 0.0009169
[Epoch 25; Iter  1668/ 2483] train: loss: 0.0012466
[Epoch 25; Iter  1698/ 2483] train: loss: 0.0014467
[Epoch 25; Iter  1728/ 2483] train: loss: 0.0018112
[Epoch 25; Iter  1758/ 2483] train: loss: 0.0199827
[Epoch 25; Iter  1788/ 2483] train: loss: 0.0022337
[Epoch 25; Iter  1818/ 2483] train: loss: 0.0021010
[Epoch 25; Iter  1848/ 2483] train: loss: 0.0011177
[Epoch 25; Iter  1878/ 2483] train: loss: 0.0019729
[Epoch 25; Iter  1908/ 2483] train: loss: 0.0013092
[Epoch 25; Iter  1938/ 2483] train: loss: 0.0019871
[Epoch 25; Iter  1968/ 2483] train: loss: 0.0481811
[Epoch 25; Iter  1998/ 2483] train: loss: 0.0014543
[Epoch 25; Iter  2028/ 2483] train: loss: 0.0008818
[Epoch 25; Iter  2058/ 2483] train: loss: 0.0040429
[Epoch 25; Iter  2088/ 2483] train: loss: 0.0019707
[Epoch 25; Iter  2118/ 2483] train: loss: 0.0014226
[Epoch 25; Iter  2148/ 2483] train: loss: 0.0009326
[Epoch 25; Iter  2178/ 2483] train: loss: 0.0009338
[Epoch 25; Iter  2208/ 2483] train: loss: 0.0020847
[Epoch 25; Iter  2238/ 2483] train: loss: 0.0011503
[Epoch 25; Iter  2268/ 2483] train: loss: 0.0014265
[Epoch 25; Iter  2298/ 2483] train: loss: 0.0018539
[Epoch 25; Iter  2328/ 2483] train: loss: 0.0022357
[Epoch 25; Iter  2358/ 2483] train: loss: 0.0011890
[Epoch 25; Iter  2388/ 2483] train: loss: 0.0011114
[Epoch 25; Iter  2418/ 2483] train: loss: 0.0010206
[Epoch 25; Iter  2448/ 2483] train: loss: 0.0601346
[Epoch 25; Iter  2478/ 2483] train: loss: 0.0012390
[Epoch 25] ogbg-molmuv: 0.108033 val loss: 0.009920
[Epoch 25] ogbg-molmuv: 0.130344 test loss: 0.014347
[Epoch 26; Iter    25/ 2483] train: loss: 0.0017582
[Epoch 26; Iter    55/ 2483] train: loss: 0.0019850
[Epoch 26; Iter    85/ 2483] train: loss: 0.0048047
[Epoch 26; Iter   115/ 2483] train: loss: 0.0021707
[Epoch 26; Iter   145/ 2483] train: loss: 0.0016150
[Epoch 26; Iter   175/ 2483] train: loss: 0.0015367
[Epoch 26; Iter   205/ 2483] train: loss: 0.0012112
[Epoch 26; Iter   235/ 2483] train: loss: 0.0019881
[Epoch 26; Iter   265/ 2483] train: loss: 0.0018004
[Epoch 26; Iter   295/ 2483] train: loss: 0.0014296
[Epoch 26; Iter   325/ 2483] train: loss: 0.0012917
[Epoch 26; Iter   355/ 2483] train: loss: 0.0693182
[Epoch 26; Iter   385/ 2483] train: loss: 0.0060432
[Epoch 26; Iter   415/ 2483] train: loss: 0.0022740
[Epoch 26; Iter   445/ 2483] train: loss: 0.0017820
[Epoch 26; Iter   475/ 2483] train: loss: 0.0015052
[Epoch 26; Iter   505/ 2483] train: loss: 0.0035690
[Epoch 26; Iter   535/ 2483] train: loss: 0.0018772
[Epoch 26; Iter   565/ 2483] train: loss: 0.0018434
[Epoch 26; Iter   595/ 2483] train: loss: 0.0015637
[Epoch 26; Iter   625/ 2483] train: loss: 0.0009091
[Epoch 26; Iter   655/ 2483] train: loss: 0.0591218
[Epoch 26; Iter   685/ 2483] train: loss: 0.0041325
[Epoch 26; Iter   715/ 2483] train: loss: 0.0017097
[Epoch 26; Iter   745/ 2483] train: loss: 0.0079269
[Epoch 26; Iter   775/ 2483] train: loss: 0.1170395
[Epoch 26; Iter   805/ 2483] train: loss: 0.0019448
[Epoch 26; Iter   835/ 2483] train: loss: 0.0007873
[Epoch 26; Iter   865/ 2483] train: loss: 0.0020285
[Epoch 26; Iter   895/ 2483] train: loss: 0.0014135
[Epoch 26; Iter   925/ 2483] train: loss: 0.0024509
[Epoch 26; Iter   955/ 2483] train: loss: 0.0024027
[Epoch 26; Iter   985/ 2483] train: loss: 0.0012743
[Epoch 26; Iter  1015/ 2483] train: loss: 0.0020512
[Epoch 26; Iter  1045/ 2483] train: loss: 0.0012028
[Epoch 26; Iter  1075/ 2483] train: loss: 0.0014781
[Epoch 26; Iter  1105/ 2483] train: loss: 0.0015558
[Epoch 26; Iter  1135/ 2483] train: loss: 0.0014336
[Epoch 26; Iter  1165/ 2483] train: loss: 0.0012308
[Epoch 26; Iter  1195/ 2483] train: loss: 0.0011206
[Epoch 26; Iter  1225/ 2483] train: loss: 0.0013105
[Epoch 26; Iter  1255/ 2483] train: loss: 0.0032321
[Epoch 26; Iter  1285/ 2483] train: loss: 0.0018769
[Epoch 25; Iter  1872/ 2172] train: loss: 0.0013424
[Epoch 25; Iter  1902/ 2172] train: loss: 0.0006737
[Epoch 25; Iter  1932/ 2172] train: loss: 0.0007795
[Epoch 25; Iter  1962/ 2172] train: loss: 0.0008097
[Epoch 25; Iter  1992/ 2172] train: loss: 0.0007641
[Epoch 25; Iter  2022/ 2172] train: loss: 0.0010067
[Epoch 25; Iter  2052/ 2172] train: loss: 0.0016635
[Epoch 25; Iter  2082/ 2172] train: loss: 0.0009127
[Epoch 25; Iter  2112/ 2172] train: loss: 0.0014278
[Epoch 25; Iter  2142/ 2172] train: loss: 0.0014393
[Epoch 25; Iter  2172/ 2172] train: loss: 0.0041244
[Epoch 25] ogbg-molmuv: 0.083453 val loss: 0.041223
[Epoch 25] ogbg-molmuv: 0.109182 test loss: 0.023721
[Epoch 26; Iter    30/ 2172] train: loss: 0.1195144
[Epoch 26; Iter    60/ 2172] train: loss: 0.0017088
[Epoch 26; Iter    90/ 2172] train: loss: 0.0010404
[Epoch 26; Iter   120/ 2172] train: loss: 0.0018273
[Epoch 26; Iter   150/ 2172] train: loss: 0.0015284
[Epoch 26; Iter   180/ 2172] train: loss: 0.0010704
[Epoch 26; Iter   210/ 2172] train: loss: 0.0019780
[Epoch 26; Iter   240/ 2172] train: loss: 0.0021642
[Epoch 26; Iter   270/ 2172] train: loss: 0.0022328
[Epoch 26; Iter   300/ 2172] train: loss: 0.0597190
[Epoch 26; Iter   330/ 2172] train: loss: 0.0097587
[Epoch 26; Iter   360/ 2172] train: loss: 0.0019541
[Epoch 26; Iter   390/ 2172] train: loss: 0.0706530
[Epoch 26; Iter   420/ 2172] train: loss: 0.0009747
[Epoch 26; Iter   450/ 2172] train: loss: 0.0013280
[Epoch 26; Iter   480/ 2172] train: loss: 0.0010253
[Epoch 26; Iter   510/ 2172] train: loss: 0.0017766
[Epoch 26; Iter   540/ 2172] train: loss: 0.0012194
[Epoch 26; Iter   570/ 2172] train: loss: 0.0011425
[Epoch 26; Iter   600/ 2172] train: loss: 0.0015054
[Epoch 26; Iter   630/ 2172] train: loss: 0.0012015
[Epoch 26; Iter   660/ 2172] train: loss: 0.0009978
[Epoch 26; Iter   690/ 2172] train: loss: 0.0016971
[Epoch 26; Iter   720/ 2172] train: loss: 0.0006998
[Epoch 26; Iter   750/ 2172] train: loss: 0.0010398
[Epoch 26; Iter   780/ 2172] train: loss: 0.0018433
[Epoch 26; Iter   810/ 2172] train: loss: 0.0664262
[Epoch 26; Iter   840/ 2172] train: loss: 0.0019289
[Epoch 26; Iter   870/ 2172] train: loss: 0.0012812
[Epoch 26; Iter   900/ 2172] train: loss: 0.0024139
[Epoch 26; Iter   930/ 2172] train: loss: 0.0585331
[Epoch 26; Iter   960/ 2172] train: loss: 0.0011639
[Epoch 26; Iter   990/ 2172] train: loss: 0.0012600
[Epoch 26; Iter  1020/ 2172] train: loss: 0.0020440
[Epoch 26; Iter  1050/ 2172] train: loss: 0.0006589
[Epoch 26; Iter  1080/ 2172] train: loss: 0.0009923
[Epoch 26; Iter  1110/ 2172] train: loss: 0.0010117
[Epoch 26; Iter  1140/ 2172] train: loss: 0.0056029
[Epoch 26; Iter  1170/ 2172] train: loss: 0.0013349
[Epoch 26; Iter  1200/ 2172] train: loss: 0.0010115
[Epoch 26; Iter  1230/ 2172] train: loss: 0.0013948
[Epoch 26; Iter  1260/ 2172] train: loss: 0.0013922
[Epoch 26; Iter  1290/ 2172] train: loss: 0.0032039
[Epoch 26; Iter  1320/ 2172] train: loss: 0.0012035
[Epoch 26; Iter  1350/ 2172] train: loss: 0.0013426
[Epoch 26; Iter  1380/ 2172] train: loss: 0.0658944
[Epoch 26; Iter  1410/ 2172] train: loss: 0.0568700
[Epoch 26; Iter  1440/ 2172] train: loss: 0.0010912
[Epoch 26; Iter  1470/ 2172] train: loss: 0.0017040
[Epoch 26; Iter  1500/ 2172] train: loss: 0.0021882
[Epoch 26; Iter  1530/ 2172] train: loss: 0.0010275
[Epoch 26; Iter  1560/ 2172] train: loss: 0.0023440
[Epoch 26; Iter  1590/ 2172] train: loss: 0.0012135
[Epoch 26; Iter  1620/ 2172] train: loss: 0.0013855
[Epoch 26; Iter  1650/ 2172] train: loss: 0.0011922
[Epoch 26; Iter  1680/ 2172] train: loss: 0.0015191
[Epoch 26; Iter  1710/ 2172] train: loss: 0.0027431
[Epoch 26; Iter  1740/ 2172] train: loss: 0.0715452
[Epoch 26; Iter  1770/ 2172] train: loss: 0.0010459
[Epoch 26; Iter  1800/ 2172] train: loss: 0.0426452
[Epoch 26; Iter  1830/ 2172] train: loss: 0.0010352
[Epoch 26; Iter  1860/ 2172] train: loss: 0.0017040
[Epoch 26; Iter  1890/ 2172] train: loss: 0.0907969
[Epoch 26; Iter  1920/ 2172] train: loss: 0.0011464
[Epoch 26; Iter  1950/ 2172] train: loss: 0.0010857
[Epoch 26; Iter  1980/ 2172] train: loss: 0.0012894
[Epoch 26; Iter  2010/ 2172] train: loss: 0.0011665
[Epoch 26; Iter  2040/ 2172] train: loss: 0.0012010
[Epoch 26; Iter  2070/ 2172] train: loss: 0.0015495
[Epoch 26; Iter  2100/ 2172] train: loss: 0.0010409
[Epoch 26; Iter  2130/ 2172] train: loss: 0.0015206
[Epoch 26; Iter  2160/ 2172] train: loss: 0.0014074
[Epoch 26] ogbg-molmuv: 0.069473 val loss: 0.066791
[Epoch 26] ogbg-molmuv: 0.132210 test loss: 0.072817
[Epoch 27; Iter    18/ 2172] train: loss: 0.0011322
[Epoch 27; Iter    48/ 2172] train: loss: 0.0024614
[Epoch 27; Iter    78/ 2172] train: loss: 0.0018558
[Epoch 27; Iter   108/ 2172] train: loss: 0.0008662
[Epoch 27; Iter   138/ 2172] train: loss: 0.0010802
[Epoch 27; Iter   168/ 2172] train: loss: 0.0024322
[Epoch 27; Iter   198/ 2172] train: loss: 0.0016254
[Epoch 27; Iter   228/ 2172] train: loss: 0.0010521
[Epoch 27; Iter   258/ 2172] train: loss: 0.0015083
[Epoch 27; Iter   288/ 2172] train: loss: 0.0024082
[Epoch 27; Iter   318/ 2172] train: loss: 0.0007404
[Epoch 27; Iter   348/ 2172] train: loss: 0.0006985
[Epoch 27; Iter   378/ 2172] train: loss: 0.0010028
[Epoch 27; Iter   408/ 2172] train: loss: 0.0015332
[Epoch 27; Iter   438/ 2172] train: loss: 0.0011784
[Epoch 27; Iter   468/ 2172] train: loss: 0.0013868
[Epoch 27; Iter   498/ 2172] train: loss: 0.0017778
[Epoch 27; Iter   528/ 2172] train: loss: 0.0025667
[Epoch 27; Iter   558/ 2172] train: loss: 0.1134065
[Epoch 27; Iter   588/ 2172] train: loss: 0.0009269
[Epoch 27; Iter   618/ 2172] train: loss: 0.0009573
[Epoch 27; Iter   648/ 2172] train: loss: 0.0016415
[Epoch 27; Iter   678/ 2172] train: loss: 0.0602338
[Epoch 27; Iter   708/ 2172] train: loss: 0.0038540
[Epoch 27; Iter   738/ 2172] train: loss: 0.0013030
[Epoch 27; Iter   768/ 2172] train: loss: 0.0007576
[Epoch 27; Iter   798/ 2172] train: loss: 0.0024607
[Epoch 27; Iter   828/ 2172] train: loss: 0.0012633
[Epoch 27; Iter   858/ 2172] train: loss: 0.0018891
[Epoch 27; Iter   888/ 2172] train: loss: 0.0008305
[Epoch 27; Iter   918/ 2172] train: loss: 0.0908614
[Epoch 27; Iter   948/ 2172] train: loss: 0.0005937
[Epoch 27; Iter   978/ 2172] train: loss: 0.0021399
[Epoch 27; Iter  1008/ 2172] train: loss: 0.0154763
[Epoch 27; Iter  1038/ 2172] train: loss: 0.0009248
[Epoch 27; Iter  1068/ 2172] train: loss: 0.0066291
[Epoch 27; Iter  1098/ 2172] train: loss: 0.0023859
[Epoch 27; Iter  1128/ 2172] train: loss: 0.0021026
[Epoch 27; Iter  1158/ 2172] train: loss: 0.0014037
[Epoch 27; Iter  1188/ 2172] train: loss: 0.0017294
[Epoch 27; Iter  1218/ 2172] train: loss: 0.0018108
[Epoch 27; Iter  1248/ 2172] train: loss: 0.0514235
[Epoch 27; Iter  1278/ 2172] train: loss: 0.0021012
[Epoch 27; Iter  1308/ 2172] train: loss: 0.0013578
[Epoch 27; Iter  1338/ 2172] train: loss: 0.0015851
[Epoch 27; Iter  1368/ 2172] train: loss: 0.0008725
[Epoch 27; Iter  1398/ 2172] train: loss: 0.0392985
[Epoch 27; Iter  1428/ 2172] train: loss: 0.0028776
[Epoch 27; Iter  1458/ 2172] train: loss: 0.0047308
[Epoch 27; Iter  1488/ 2172] train: loss: 0.0200263
[Epoch 27; Iter  1518/ 2172] train: loss: 0.0025640
[Epoch 27; Iter  1548/ 2172] train: loss: 0.0018241
[Epoch 27; Iter  1578/ 2172] train: loss: 0.0019188
[Epoch 27; Iter  1608/ 2172] train: loss: 0.0021842
[Epoch 27; Iter  1638/ 2172] train: loss: 0.0013086
[Epoch 27; Iter  1668/ 2172] train: loss: 0.0011399
[Epoch 27; Iter  1698/ 2172] train: loss: 0.0017209
[Epoch 27; Iter  1728/ 2172] train: loss: 0.0029634
[Epoch 27; Iter  1758/ 2172] train: loss: 0.0009632
[Epoch 27; Iter  1788/ 2172] train: loss: 0.0011393
[Epoch 27; Iter  1818/ 2172] train: loss: 0.0010208
[Epoch 27; Iter  1848/ 2172] train: loss: 0.0637072
[Epoch 27; Iter  1878/ 2172] train: loss: 0.0929075
[Epoch 27; Iter  1908/ 2172] train: loss: 0.0010409
[Epoch 27; Iter  1938/ 2172] train: loss: 0.0009803
[Epoch 27; Iter  1968/ 2172] train: loss: 0.0009388
[Epoch 27; Iter  1998/ 2172] train: loss: 0.0011232
[Epoch 27; Iter  2028/ 2172] train: loss: 0.0016251
[Epoch 27; Iter  2058/ 2172] train: loss: 0.0018375
[Epoch 27; Iter  2088/ 2172] train: loss: 0.0008993
[Epoch 24; Iter  1691/ 2483] train: loss: 0.0017687
[Epoch 24; Iter  1721/ 2483] train: loss: 0.0013809
[Epoch 24; Iter  1751/ 2483] train: loss: 0.1623182
[Epoch 24; Iter  1781/ 2483] train: loss: 0.0032671
[Epoch 24; Iter  1811/ 2483] train: loss: 0.0074467
[Epoch 24; Iter  1841/ 2483] train: loss: 0.0021528
[Epoch 24; Iter  1871/ 2483] train: loss: 0.0476785
[Epoch 24; Iter  1901/ 2483] train: loss: 0.0017191
[Epoch 24; Iter  1931/ 2483] train: loss: 0.0729708
[Epoch 24; Iter  1961/ 2483] train: loss: 0.0014415
[Epoch 24; Iter  1991/ 2483] train: loss: 0.0011916
[Epoch 24; Iter  2021/ 2483] train: loss: 0.0015856
[Epoch 24; Iter  2051/ 2483] train: loss: 0.0022744
[Epoch 24; Iter  2081/ 2483] train: loss: 0.0016035
[Epoch 24; Iter  2111/ 2483] train: loss: 0.0018592
[Epoch 24; Iter  2141/ 2483] train: loss: 0.0015818
[Epoch 24; Iter  2171/ 2483] train: loss: 0.0010497
[Epoch 24; Iter  2201/ 2483] train: loss: 0.0013908
[Epoch 24; Iter  2231/ 2483] train: loss: 0.0017482
[Epoch 24; Iter  2261/ 2483] train: loss: 0.0016506
[Epoch 24; Iter  2291/ 2483] train: loss: 0.0016519
[Epoch 24; Iter  2321/ 2483] train: loss: 0.0023689
[Epoch 24; Iter  2351/ 2483] train: loss: 0.0014432
[Epoch 24; Iter  2381/ 2483] train: loss: 0.0034063
[Epoch 24; Iter  2411/ 2483] train: loss: 0.0010226
[Epoch 24; Iter  2441/ 2483] train: loss: 0.0015639
[Epoch 24; Iter  2471/ 2483] train: loss: 0.0016797
[Epoch 24] ogbg-molmuv: 0.120498 val loss: 0.010097
[Epoch 24] ogbg-molmuv: 0.138042 test loss: 0.013695
[Epoch 25; Iter    18/ 2483] train: loss: 0.0012624
[Epoch 25; Iter    48/ 2483] train: loss: 0.0655116
[Epoch 25; Iter    78/ 2483] train: loss: 0.0015467
[Epoch 25; Iter   108/ 2483] train: loss: 0.0011145
[Epoch 25; Iter   138/ 2483] train: loss: 0.0018353
[Epoch 25; Iter   168/ 2483] train: loss: 0.0021677
[Epoch 25; Iter   198/ 2483] train: loss: 0.0038011
[Epoch 25; Iter   228/ 2483] train: loss: 0.0028236
[Epoch 25; Iter   258/ 2483] train: loss: 0.0014382
[Epoch 25; Iter   288/ 2483] train: loss: 0.0019406
[Epoch 25; Iter   318/ 2483] train: loss: 0.0007859
[Epoch 25; Iter   348/ 2483] train: loss: 0.0020129
[Epoch 25; Iter   378/ 2483] train: loss: 0.0013760
[Epoch 25; Iter   408/ 2483] train: loss: 0.1149048
[Epoch 25; Iter   438/ 2483] train: loss: 0.0030801
[Epoch 25; Iter   468/ 2483] train: loss: 0.0034300
[Epoch 25; Iter   498/ 2483] train: loss: 0.0030773
[Epoch 25; Iter   528/ 2483] train: loss: 0.0021126
[Epoch 25; Iter   558/ 2483] train: loss: 0.0025792
[Epoch 25; Iter   588/ 2483] train: loss: 0.0424807
[Epoch 25; Iter   618/ 2483] train: loss: 0.0031207
[Epoch 25; Iter   648/ 2483] train: loss: 0.0009891
[Epoch 25; Iter   678/ 2483] train: loss: 0.0014280
[Epoch 25; Iter   708/ 2483] train: loss: 0.0007665
[Epoch 25; Iter   738/ 2483] train: loss: 0.0649075
[Epoch 25; Iter   768/ 2483] train: loss: 0.0585886
[Epoch 25; Iter   798/ 2483] train: loss: 0.0007121
[Epoch 25; Iter   828/ 2483] train: loss: 0.0011794
[Epoch 25; Iter   858/ 2483] train: loss: 0.0013785
[Epoch 25; Iter   888/ 2483] train: loss: 0.0237832
[Epoch 25; Iter   918/ 2483] train: loss: 0.0013120
[Epoch 25; Iter   948/ 2483] train: loss: 0.0016798
[Epoch 25; Iter   978/ 2483] train: loss: 0.0047851
[Epoch 25; Iter  1008/ 2483] train: loss: 0.0013795
[Epoch 25; Iter  1038/ 2483] train: loss: 0.0016855
[Epoch 25; Iter  1068/ 2483] train: loss: 0.1392846
[Epoch 25; Iter  1098/ 2483] train: loss: 0.0013942
[Epoch 25; Iter  1128/ 2483] train: loss: 0.0027497
[Epoch 25; Iter  1158/ 2483] train: loss: 0.0571474
[Epoch 25; Iter  1188/ 2483] train: loss: 0.0011957
[Epoch 25; Iter  1218/ 2483] train: loss: 0.0008981
[Epoch 25; Iter  1248/ 2483] train: loss: 0.0011143
[Epoch 25; Iter  1278/ 2483] train: loss: 0.0009514
[Epoch 25; Iter  1308/ 2483] train: loss: 0.0021350
[Epoch 25; Iter  1338/ 2483] train: loss: 0.0008113
[Epoch 25; Iter  1368/ 2483] train: loss: 0.0841697
[Epoch 25; Iter  1398/ 2483] train: loss: 0.0012684
[Epoch 25; Iter  1428/ 2483] train: loss: 0.0010673
[Epoch 25; Iter  1458/ 2483] train: loss: 0.0010651
[Epoch 25; Iter  1488/ 2483] train: loss: 0.1031845
[Epoch 25; Iter  1518/ 2483] train: loss: 0.0009609
[Epoch 25; Iter  1548/ 2483] train: loss: 0.0210310
[Epoch 25; Iter  1578/ 2483] train: loss: 0.0024440
[Epoch 25; Iter  1608/ 2483] train: loss: 0.0019089
[Epoch 25; Iter  1638/ 2483] train: loss: 0.0762103
[Epoch 25; Iter  1668/ 2483] train: loss: 0.1022236
[Epoch 25; Iter  1698/ 2483] train: loss: 0.0493995
[Epoch 25; Iter  1728/ 2483] train: loss: 0.0011224
[Epoch 25; Iter  1758/ 2483] train: loss: 0.0012317
[Epoch 25; Iter  1788/ 2483] train: loss: 0.0014165
[Epoch 25; Iter  1818/ 2483] train: loss: 0.0016394
[Epoch 25; Iter  1848/ 2483] train: loss: 0.0049652
[Epoch 25; Iter  1878/ 2483] train: loss: 0.0019010
[Epoch 25; Iter  1908/ 2483] train: loss: 0.0030215
[Epoch 25; Iter  1938/ 2483] train: loss: 0.0550454
[Epoch 25; Iter  1968/ 2483] train: loss: 0.0018883
[Epoch 25; Iter  1998/ 2483] train: loss: 0.0037396
[Epoch 25; Iter  2028/ 2483] train: loss: 0.0027045
[Epoch 25; Iter  2058/ 2483] train: loss: 0.0024541
[Epoch 25; Iter  2088/ 2483] train: loss: 0.0787596
[Epoch 25; Iter  2118/ 2483] train: loss: 0.0011725
[Epoch 25; Iter  2148/ 2483] train: loss: 0.0009454
[Epoch 25; Iter  2178/ 2483] train: loss: 0.0020594
[Epoch 25; Iter  2208/ 2483] train: loss: 0.0014231
[Epoch 25; Iter  2238/ 2483] train: loss: 0.0016160
[Epoch 25; Iter  2268/ 2483] train: loss: 0.0014178
[Epoch 25; Iter  2298/ 2483] train: loss: 0.0013900
[Epoch 25; Iter  2328/ 2483] train: loss: 0.0022508
[Epoch 25; Iter  2358/ 2483] train: loss: 0.0018261
[Epoch 25; Iter  2388/ 2483] train: loss: 0.0037940
[Epoch 25; Iter  2418/ 2483] train: loss: 0.0014381
[Epoch 25; Iter  2448/ 2483] train: loss: 0.0020415
[Epoch 25; Iter  2478/ 2483] train: loss: 0.0043087
[Epoch 25] ogbg-molmuv: 0.136572 val loss: 0.009645
[Epoch 25] ogbg-molmuv: 0.166082 test loss: 0.013906
[Epoch 26; Iter    25/ 2483] train: loss: 0.0015448
[Epoch 26; Iter    55/ 2483] train: loss: 0.0016839
[Epoch 26; Iter    85/ 2483] train: loss: 0.0868565
[Epoch 26; Iter   115/ 2483] train: loss: 0.0440720
[Epoch 26; Iter   145/ 2483] train: loss: 0.0155731
[Epoch 26; Iter   175/ 2483] train: loss: 0.0302329
[Epoch 26; Iter   205/ 2483] train: loss: 0.0192123
[Epoch 26; Iter   235/ 2483] train: loss: 0.0019054
[Epoch 26; Iter   265/ 2483] train: loss: 0.0924736
[Epoch 26; Iter   295/ 2483] train: loss: 0.0027440
[Epoch 26; Iter   325/ 2483] train: loss: 0.0020618
[Epoch 26; Iter   355/ 2483] train: loss: 0.0013906
[Epoch 26; Iter   385/ 2483] train: loss: 0.0019913
[Epoch 26; Iter   415/ 2483] train: loss: 0.0024265
[Epoch 26; Iter   445/ 2483] train: loss: 0.0020822
[Epoch 26; Iter   475/ 2483] train: loss: 0.0014271
[Epoch 26; Iter   505/ 2483] train: loss: 0.0012039
[Epoch 26; Iter   535/ 2483] train: loss: 0.0023756
[Epoch 26; Iter   565/ 2483] train: loss: 0.0011746
[Epoch 26; Iter   595/ 2483] train: loss: 0.0811974
[Epoch 26; Iter   625/ 2483] train: loss: 0.0026390
[Epoch 26; Iter   655/ 2483] train: loss: 0.0019532
[Epoch 26; Iter   685/ 2483] train: loss: 0.0021328
[Epoch 26; Iter   715/ 2483] train: loss: 0.0029257
[Epoch 26; Iter   745/ 2483] train: loss: 0.0026781
[Epoch 26; Iter   775/ 2483] train: loss: 0.0913125
[Epoch 26; Iter   805/ 2483] train: loss: 0.0015438
[Epoch 26; Iter   835/ 2483] train: loss: 0.0015953
[Epoch 26; Iter   865/ 2483] train: loss: 0.0743731
[Epoch 26; Iter   895/ 2483] train: loss: 0.0013195
[Epoch 26; Iter   925/ 2483] train: loss: 0.0009751
[Epoch 26; Iter   955/ 2483] train: loss: 0.1536616
[Epoch 26; Iter   985/ 2483] train: loss: 0.0019043
[Epoch 26; Iter  1015/ 2483] train: loss: 0.0187440
[Epoch 26; Iter  1045/ 2483] train: loss: 0.0012756
[Epoch 26; Iter  1075/ 2483] train: loss: 0.0031805
[Epoch 26; Iter  1105/ 2483] train: loss: 0.0016223
[Epoch 26; Iter  1135/ 2483] train: loss: 0.0023181
[Epoch 26; Iter  1165/ 2483] train: loss: 0.0576487
[Epoch 26; Iter  1195/ 2483] train: loss: 0.0015714
[Epoch 26; Iter  1225/ 2483] train: loss: 0.0013142
[Epoch 26; Iter  1255/ 2483] train: loss: 0.0018578
[Epoch 26; Iter  1285/ 2483] train: loss: 0.0017452
[Epoch 25; Iter  1872/ 2172] train: loss: 0.0011218
[Epoch 25; Iter  1902/ 2172] train: loss: 0.0010567
[Epoch 25; Iter  1932/ 2172] train: loss: 0.0015511
[Epoch 25; Iter  1962/ 2172] train: loss: 0.0012166
[Epoch 25; Iter  1992/ 2172] train: loss: 0.0010663
[Epoch 25; Iter  2022/ 2172] train: loss: 0.0011653
[Epoch 25; Iter  2052/ 2172] train: loss: 0.0009238
[Epoch 25; Iter  2082/ 2172] train: loss: 0.0008394
[Epoch 25; Iter  2112/ 2172] train: loss: 0.0017332
[Epoch 25; Iter  2142/ 2172] train: loss: 0.0962884
[Epoch 25; Iter  2172/ 2172] train: loss: 0.0016998
[Epoch 25] ogbg-molmuv: 0.043718 val loss: 0.027147
[Epoch 25] ogbg-molmuv: 0.102959 test loss: 0.028085
[Epoch 26; Iter    30/ 2172] train: loss: 0.0031475
[Epoch 26; Iter    60/ 2172] train: loss: 0.0018022
[Epoch 26; Iter    90/ 2172] train: loss: 0.0014866
[Epoch 26; Iter   120/ 2172] train: loss: 0.0021103
[Epoch 26; Iter   150/ 2172] train: loss: 0.0026769
[Epoch 26; Iter   180/ 2172] train: loss: 0.0014713
[Epoch 26; Iter   210/ 2172] train: loss: 0.0011833
[Epoch 26; Iter   240/ 2172] train: loss: 0.0007894
[Epoch 26; Iter   270/ 2172] train: loss: 0.0010701
[Epoch 26; Iter   300/ 2172] train: loss: 0.0012193
[Epoch 26; Iter   330/ 2172] train: loss: 0.0621277
[Epoch 26; Iter   360/ 2172] train: loss: 0.0020396
[Epoch 26; Iter   390/ 2172] train: loss: 0.0011861
[Epoch 26; Iter   420/ 2172] train: loss: 0.0012442
[Epoch 26; Iter   450/ 2172] train: loss: 0.0456068
[Epoch 26; Iter   480/ 2172] train: loss: 0.0026560
[Epoch 26; Iter   510/ 2172] train: loss: 0.0021518
[Epoch 26; Iter   540/ 2172] train: loss: 0.0012993
[Epoch 26; Iter   570/ 2172] train: loss: 0.0023015
[Epoch 26; Iter   600/ 2172] train: loss: 0.0012378
[Epoch 26; Iter   630/ 2172] train: loss: 0.0018898
[Epoch 26; Iter   660/ 2172] train: loss: 0.0041317
[Epoch 26; Iter   690/ 2172] train: loss: 0.0014204
[Epoch 26; Iter   720/ 2172] train: loss: 0.0672083
[Epoch 26; Iter   750/ 2172] train: loss: 0.0012518
[Epoch 26; Iter   780/ 2172] train: loss: 0.0026543
[Epoch 26; Iter   810/ 2172] train: loss: 0.0019653
[Epoch 26; Iter   840/ 2172] train: loss: 0.0026103
[Epoch 26; Iter   870/ 2172] train: loss: 0.0015399
[Epoch 26; Iter   900/ 2172] train: loss: 0.0770741
[Epoch 26; Iter   930/ 2172] train: loss: 0.0017323
[Epoch 26; Iter   960/ 2172] train: loss: 0.0011782
[Epoch 26; Iter   990/ 2172] train: loss: 0.0021044
[Epoch 26; Iter  1020/ 2172] train: loss: 0.0025455
[Epoch 26; Iter  1050/ 2172] train: loss: 0.0026434
[Epoch 26; Iter  1080/ 2172] train: loss: 0.0010556
[Epoch 26; Iter  1110/ 2172] train: loss: 0.0017788
[Epoch 26; Iter  1140/ 2172] train: loss: 0.0014548
[Epoch 26; Iter  1170/ 2172] train: loss: 0.0016345
[Epoch 26; Iter  1200/ 2172] train: loss: 0.0013211
[Epoch 26; Iter  1230/ 2172] train: loss: 0.0009446
[Epoch 26; Iter  1260/ 2172] train: loss: 0.0026235
[Epoch 26; Iter  1290/ 2172] train: loss: 0.0273545
[Epoch 26; Iter  1320/ 2172] train: loss: 0.0014354
[Epoch 26; Iter  1350/ 2172] train: loss: 0.0010130
[Epoch 26; Iter  1380/ 2172] train: loss: 0.0012644
[Epoch 26; Iter  1410/ 2172] train: loss: 0.0020756
[Epoch 26; Iter  1440/ 2172] train: loss: 0.0012185
[Epoch 26; Iter  1470/ 2172] train: loss: 0.0012918
[Epoch 26; Iter  1500/ 2172] train: loss: 0.0402536
[Epoch 26; Iter  1530/ 2172] train: loss: 0.0007133
[Epoch 26; Iter  1560/ 2172] train: loss: 0.0034738
[Epoch 26; Iter  1590/ 2172] train: loss: 0.0045055
[Epoch 26; Iter  1620/ 2172] train: loss: 0.0010667
[Epoch 26; Iter  1650/ 2172] train: loss: 0.0022905
[Epoch 26; Iter  1680/ 2172] train: loss: 0.0009807
[Epoch 26; Iter  1710/ 2172] train: loss: 0.0011949
[Epoch 26; Iter  1740/ 2172] train: loss: 0.0332399
[Epoch 26; Iter  1770/ 2172] train: loss: 0.0014891
[Epoch 26; Iter  1800/ 2172] train: loss: 0.0911354
[Epoch 26; Iter  1830/ 2172] train: loss: 0.0010841
[Epoch 26; Iter  1860/ 2172] train: loss: 0.0013816
[Epoch 26; Iter  1890/ 2172] train: loss: 0.0010676
[Epoch 26; Iter  1920/ 2172] train: loss: 0.0010974
[Epoch 26; Iter  1950/ 2172] train: loss: 0.0010619
[Epoch 26; Iter  1980/ 2172] train: loss: 0.0024371
[Epoch 26; Iter  2010/ 2172] train: loss: 0.0023290
[Epoch 26; Iter  2040/ 2172] train: loss: 0.0014573
[Epoch 26; Iter  2070/ 2172] train: loss: 0.0062124
[Epoch 26; Iter  2100/ 2172] train: loss: 0.0024027
[Epoch 26; Iter  2130/ 2172] train: loss: 0.0016421
[Epoch 26; Iter  2160/ 2172] train: loss: 0.0014053
[Epoch 26] ogbg-molmuv: 0.042678 val loss: 0.075770
[Epoch 26] ogbg-molmuv: 0.095750 test loss: 0.047675
[Epoch 27; Iter    18/ 2172] train: loss: 0.0024411
[Epoch 27; Iter    48/ 2172] train: loss: 0.0025639
[Epoch 27; Iter    78/ 2172] train: loss: 0.0505947
[Epoch 27; Iter   108/ 2172] train: loss: 0.0020331
[Epoch 27; Iter   138/ 2172] train: loss: 0.0021916
[Epoch 27; Iter   168/ 2172] train: loss: 0.0020126
[Epoch 27; Iter   198/ 2172] train: loss: 0.0009993
[Epoch 27; Iter   228/ 2172] train: loss: 0.0019948
[Epoch 27; Iter   258/ 2172] train: loss: 0.0273181
[Epoch 27; Iter   288/ 2172] train: loss: 0.0014583
[Epoch 27; Iter   318/ 2172] train: loss: 0.0012180
[Epoch 27; Iter   348/ 2172] train: loss: 0.0012313
[Epoch 27; Iter   378/ 2172] train: loss: 0.0017050
[Epoch 27; Iter   408/ 2172] train: loss: 0.0015793
[Epoch 27; Iter   438/ 2172] train: loss: 0.0019968
[Epoch 27; Iter   468/ 2172] train: loss: 0.0027141
[Epoch 27; Iter   498/ 2172] train: loss: 0.0008021
[Epoch 27; Iter   528/ 2172] train: loss: 0.0014114
[Epoch 27; Iter   558/ 2172] train: loss: 0.0026161
[Epoch 27; Iter   588/ 2172] train: loss: 0.0029258
[Epoch 27; Iter   618/ 2172] train: loss: 0.0018337
[Epoch 27; Iter   648/ 2172] train: loss: 0.0024147
[Epoch 27; Iter   678/ 2172] train: loss: 0.0016036
[Epoch 27; Iter   708/ 2172] train: loss: 0.0859557
[Epoch 27; Iter   738/ 2172] train: loss: 0.0016105
[Epoch 27; Iter   768/ 2172] train: loss: 0.0010585
[Epoch 27; Iter   798/ 2172] train: loss: 0.0013483
[Epoch 27; Iter   828/ 2172] train: loss: 0.0015721
[Epoch 27; Iter   858/ 2172] train: loss: 0.0011025
[Epoch 27; Iter   888/ 2172] train: loss: 0.0011362
[Epoch 27; Iter   918/ 2172] train: loss: 0.0730283
[Epoch 27; Iter   948/ 2172] train: loss: 0.0808504
[Epoch 27; Iter   978/ 2172] train: loss: 0.0011833
[Epoch 27; Iter  1008/ 2172] train: loss: 0.0016344
[Epoch 27; Iter  1038/ 2172] train: loss: 0.0011931
[Epoch 27; Iter  1068/ 2172] train: loss: 0.0016759
[Epoch 27; Iter  1098/ 2172] train: loss: 0.0959074
[Epoch 27; Iter  1128/ 2172] train: loss: 0.0018646
[Epoch 27; Iter  1158/ 2172] train: loss: 0.0009968
[Epoch 27; Iter  1188/ 2172] train: loss: 0.0010138
[Epoch 27; Iter  1218/ 2172] train: loss: 0.0007310
[Epoch 27; Iter  1248/ 2172] train: loss: 0.0018466
[Epoch 27; Iter  1278/ 2172] train: loss: 0.0506764
[Epoch 27; Iter  1308/ 2172] train: loss: 0.0023526
[Epoch 27; Iter  1338/ 2172] train: loss: 0.0025676
[Epoch 27; Iter  1368/ 2172] train: loss: 0.0117046
[Epoch 27; Iter  1398/ 2172] train: loss: 0.0012412
[Epoch 27; Iter  1428/ 2172] train: loss: 0.0014453
[Epoch 27; Iter  1458/ 2172] train: loss: 0.0009813
[Epoch 27; Iter  1488/ 2172] train: loss: 0.0017157
[Epoch 27; Iter  1518/ 2172] train: loss: 0.0017337
[Epoch 27; Iter  1548/ 2172] train: loss: 0.0009739
[Epoch 27; Iter  1578/ 2172] train: loss: 0.0023247
[Epoch 27; Iter  1608/ 2172] train: loss: 0.0019151
[Epoch 27; Iter  1638/ 2172] train: loss: 0.0598340
[Epoch 27; Iter  1668/ 2172] train: loss: 0.0018440
[Epoch 27; Iter  1698/ 2172] train: loss: 0.0015764
[Epoch 27; Iter  1728/ 2172] train: loss: 0.0028786
[Epoch 27; Iter  1758/ 2172] train: loss: 0.0010751
[Epoch 27; Iter  1788/ 2172] train: loss: 0.0008821
[Epoch 27; Iter  1818/ 2172] train: loss: 0.0015988
[Epoch 27; Iter  1848/ 2172] train: loss: 0.0137751
[Epoch 27; Iter  1878/ 2172] train: loss: 0.0014013
[Epoch 27; Iter  1908/ 2172] train: loss: 0.0008420
[Epoch 27; Iter  1938/ 2172] train: loss: 0.0007555
[Epoch 27; Iter  1968/ 2172] train: loss: 0.1793757
[Epoch 27; Iter  1998/ 2172] train: loss: 0.0019454
[Epoch 27; Iter  2028/ 2172] train: loss: 0.0029117
[Epoch 27; Iter  2058/ 2172] train: loss: 0.0012051
[Epoch 27; Iter  2088/ 2172] train: loss: 0.0017040
[Epoch 25; Iter  1872/ 2172] train: loss: 0.0022521
[Epoch 25; Iter  1902/ 2172] train: loss: 0.0026550
[Epoch 25; Iter  1932/ 2172] train: loss: 0.0566182
[Epoch 25; Iter  1962/ 2172] train: loss: 0.0018970
[Epoch 25; Iter  1992/ 2172] train: loss: 0.0018354
[Epoch 25; Iter  2022/ 2172] train: loss: 0.0017184
[Epoch 25; Iter  2052/ 2172] train: loss: 0.0021499
[Epoch 25; Iter  2082/ 2172] train: loss: 0.0037117
[Epoch 25; Iter  2112/ 2172] train: loss: 0.0018040
[Epoch 25; Iter  2142/ 2172] train: loss: 0.0021749
[Epoch 25; Iter  2172/ 2172] train: loss: 0.0012450
[Epoch 25] ogbg-molmuv: 0.051158 val loss: 0.012308
[Epoch 25] ogbg-molmuv: 0.105684 test loss: 0.022765
[Epoch 26; Iter    30/ 2172] train: loss: 0.0018363
[Epoch 26; Iter    60/ 2172] train: loss: 0.0013024
[Epoch 26; Iter    90/ 2172] train: loss: 0.0010550
[Epoch 26; Iter   120/ 2172] train: loss: 0.0014506
[Epoch 26; Iter   150/ 2172] train: loss: 0.0760510
[Epoch 26; Iter   180/ 2172] train: loss: 0.0014645
[Epoch 26; Iter   210/ 2172] train: loss: 0.0014923
[Epoch 26; Iter   240/ 2172] train: loss: 0.0413478
[Epoch 26; Iter   270/ 2172] train: loss: 0.0012837
[Epoch 26; Iter   300/ 2172] train: loss: 0.0764325
[Epoch 26; Iter   330/ 2172] train: loss: 0.0014224
[Epoch 26; Iter   360/ 2172] train: loss: 0.0020991
[Epoch 26; Iter   390/ 2172] train: loss: 0.0017010
[Epoch 26; Iter   420/ 2172] train: loss: 0.0016351
[Epoch 26; Iter   450/ 2172] train: loss: 0.0012943
[Epoch 26; Iter   480/ 2172] train: loss: 0.0019889
[Epoch 26; Iter   510/ 2172] train: loss: 0.0707391
[Epoch 26; Iter   540/ 2172] train: loss: 0.0033170
[Epoch 26; Iter   570/ 2172] train: loss: 0.0023035
[Epoch 26; Iter   600/ 2172] train: loss: 0.0019588
[Epoch 26; Iter   630/ 2172] train: loss: 0.0692519
[Epoch 26; Iter   660/ 2172] train: loss: 0.0619320
[Epoch 26; Iter   690/ 2172] train: loss: 0.0015601
[Epoch 26; Iter   720/ 2172] train: loss: 0.0582236
[Epoch 26; Iter   750/ 2172] train: loss: 0.0039197
[Epoch 26; Iter   780/ 2172] train: loss: 0.0782593
[Epoch 26; Iter   810/ 2172] train: loss: 0.0026147
[Epoch 26; Iter   840/ 2172] train: loss: 0.0023515
[Epoch 26; Iter   870/ 2172] train: loss: 0.0015010
[Epoch 26; Iter   900/ 2172] train: loss: 0.0015030
[Epoch 26; Iter   930/ 2172] train: loss: 0.0014755
[Epoch 26; Iter   960/ 2172] train: loss: 0.0017835
[Epoch 26; Iter   990/ 2172] train: loss: 0.0011381
[Epoch 26; Iter  1020/ 2172] train: loss: 0.0036540
[Epoch 26; Iter  1050/ 2172] train: loss: 0.0015560
[Epoch 26; Iter  1080/ 2172] train: loss: 0.0011295
[Epoch 26; Iter  1110/ 2172] train: loss: 0.0022117
[Epoch 26; Iter  1140/ 2172] train: loss: 0.0015473
[Epoch 26; Iter  1170/ 2172] train: loss: 0.0009039
[Epoch 26; Iter  1200/ 2172] train: loss: 0.0013487
[Epoch 26; Iter  1230/ 2172] train: loss: 0.0158502
[Epoch 26; Iter  1260/ 2172] train: loss: 0.0018108
[Epoch 26; Iter  1290/ 2172] train: loss: 0.0011741
[Epoch 26; Iter  1320/ 2172] train: loss: 0.0036240
[Epoch 26; Iter  1350/ 2172] train: loss: 0.0044369
[Epoch 26; Iter  1380/ 2172] train: loss: 0.0009343
[Epoch 26; Iter  1410/ 2172] train: loss: 0.0015856
[Epoch 26; Iter  1440/ 2172] train: loss: 0.0016325
[Epoch 26; Iter  1470/ 2172] train: loss: 0.0035356
[Epoch 26; Iter  1500/ 2172] train: loss: 0.0012956
[Epoch 26; Iter  1530/ 2172] train: loss: 0.0010954
[Epoch 26; Iter  1560/ 2172] train: loss: 0.1023623
[Epoch 26; Iter  1590/ 2172] train: loss: 0.0011922
[Epoch 26; Iter  1620/ 2172] train: loss: 0.0012805
[Epoch 26; Iter  1650/ 2172] train: loss: 0.0334655
[Epoch 26; Iter  1680/ 2172] train: loss: 0.0014667
[Epoch 26; Iter  1710/ 2172] train: loss: 0.0016018
[Epoch 26; Iter  1740/ 2172] train: loss: 0.0020655
[Epoch 26; Iter  1770/ 2172] train: loss: 0.0024840
[Epoch 26; Iter  1800/ 2172] train: loss: 0.0568918
[Epoch 26; Iter  1830/ 2172] train: loss: 0.0033635
[Epoch 26; Iter  1860/ 2172] train: loss: 0.0026282
[Epoch 26; Iter  1890/ 2172] train: loss: 0.0019610
[Epoch 26; Iter  1920/ 2172] train: loss: 0.0010842
[Epoch 26; Iter  1950/ 2172] train: loss: 0.0028253
[Epoch 26; Iter  1980/ 2172] train: loss: 0.0019791
[Epoch 26; Iter  2010/ 2172] train: loss: 0.0017689
[Epoch 26; Iter  2040/ 2172] train: loss: 0.0732715
[Epoch 26; Iter  2070/ 2172] train: loss: 0.0008034
[Epoch 26; Iter  2100/ 2172] train: loss: 0.0034466
[Epoch 26; Iter  2130/ 2172] train: loss: 0.0011731
[Epoch 26; Iter  2160/ 2172] train: loss: 0.0018607
[Epoch 26] ogbg-molmuv: 0.110997 val loss: 0.027079
[Epoch 26] ogbg-molmuv: 0.051563 test loss: 0.034976
[Epoch 27; Iter    18/ 2172] train: loss: 0.0041615
[Epoch 27; Iter    48/ 2172] train: loss: 0.0019792
[Epoch 27; Iter    78/ 2172] train: loss: 0.0025390
[Epoch 27; Iter   108/ 2172] train: loss: 0.0012511
[Epoch 27; Iter   138/ 2172] train: loss: 0.0054086
[Epoch 27; Iter   168/ 2172] train: loss: 0.0016114
[Epoch 27; Iter   198/ 2172] train: loss: 0.0015543
[Epoch 27; Iter   228/ 2172] train: loss: 0.0016137
[Epoch 27; Iter   258/ 2172] train: loss: 0.0023810
[Epoch 27; Iter   288/ 2172] train: loss: 0.0545107
[Epoch 27; Iter   318/ 2172] train: loss: 0.0020406
[Epoch 27; Iter   348/ 2172] train: loss: 0.0011742
[Epoch 27; Iter   378/ 2172] train: loss: 0.0011952
[Epoch 27; Iter   408/ 2172] train: loss: 0.0013191
[Epoch 27; Iter   438/ 2172] train: loss: 0.0856504
[Epoch 27; Iter   468/ 2172] train: loss: 0.0005482
[Epoch 27; Iter   498/ 2172] train: loss: 0.0009866
[Epoch 27; Iter   528/ 2172] train: loss: 0.0033226
[Epoch 27; Iter   558/ 2172] train: loss: 0.0018512
[Epoch 27; Iter   588/ 2172] train: loss: 0.0010584
[Epoch 27; Iter   618/ 2172] train: loss: 0.0016152
[Epoch 27; Iter   648/ 2172] train: loss: 0.0014005
[Epoch 27; Iter   678/ 2172] train: loss: 0.0823011
[Epoch 27; Iter   708/ 2172] train: loss: 0.0011769
[Epoch 27; Iter   738/ 2172] train: loss: 0.0018127
[Epoch 27; Iter   768/ 2172] train: loss: 0.0010417
[Epoch 27; Iter   798/ 2172] train: loss: 0.0020812
[Epoch 27; Iter   828/ 2172] train: loss: 0.0009189
[Epoch 27; Iter   858/ 2172] train: loss: 0.0009282
[Epoch 27; Iter   888/ 2172] train: loss: 0.0017482
[Epoch 27; Iter   918/ 2172] train: loss: 0.0012070
[Epoch 27; Iter   948/ 2172] train: loss: 0.0016010
[Epoch 27; Iter   978/ 2172] train: loss: 0.0018282
[Epoch 27; Iter  1008/ 2172] train: loss: 0.0018457
[Epoch 27; Iter  1038/ 2172] train: loss: 0.0017841
[Epoch 27; Iter  1068/ 2172] train: loss: 0.0022134
[Epoch 27; Iter  1098/ 2172] train: loss: 0.0014204
[Epoch 27; Iter  1128/ 2172] train: loss: 0.0027243
[Epoch 27; Iter  1158/ 2172] train: loss: 0.0029491
[Epoch 27; Iter  1188/ 2172] train: loss: 0.0024742
[Epoch 27; Iter  1218/ 2172] train: loss: 0.0489451
[Epoch 27; Iter  1248/ 2172] train: loss: 0.0014865
[Epoch 27; Iter  1278/ 2172] train: loss: 0.0020863
[Epoch 27; Iter  1308/ 2172] train: loss: 0.0019634
[Epoch 27; Iter  1338/ 2172] train: loss: 0.0021195
[Epoch 27; Iter  1368/ 2172] train: loss: 0.0017143
[Epoch 27; Iter  1398/ 2172] train: loss: 0.0013890
[Epoch 27; Iter  1428/ 2172] train: loss: 0.0022677
[Epoch 27; Iter  1458/ 2172] train: loss: 0.0074860
[Epoch 27; Iter  1488/ 2172] train: loss: 0.0011052
[Epoch 27; Iter  1518/ 2172] train: loss: 0.0713190
[Epoch 27; Iter  1548/ 2172] train: loss: 0.0018145
[Epoch 27; Iter  1578/ 2172] train: loss: 0.0018184
[Epoch 27; Iter  1608/ 2172] train: loss: 0.0020723
[Epoch 27; Iter  1638/ 2172] train: loss: 0.0019147
[Epoch 27; Iter  1668/ 2172] train: loss: 0.0010957
[Epoch 27; Iter  1698/ 2172] train: loss: 0.0303315
[Epoch 27; Iter  1728/ 2172] train: loss: 0.0030685
[Epoch 27; Iter  1758/ 2172] train: loss: 0.0411378
[Epoch 27; Iter  1788/ 2172] train: loss: 0.0023907
[Epoch 27; Iter  1818/ 2172] train: loss: 0.0027404
[Epoch 27; Iter  1848/ 2172] train: loss: 0.0016816
[Epoch 27; Iter  1878/ 2172] train: loss: 0.0056467
[Epoch 27; Iter  1908/ 2172] train: loss: 0.0014851
[Epoch 27; Iter  1938/ 2172] train: loss: 0.0013202
[Epoch 27; Iter  1968/ 2172] train: loss: 0.0014570
[Epoch 27; Iter  1998/ 2172] train: loss: 0.0037442
[Epoch 27; Iter  2028/ 2172] train: loss: 0.0017092
[Epoch 27; Iter  2058/ 2172] train: loss: 0.0013602
[Epoch 27; Iter  2088/ 2172] train: loss: 0.0011296
[Epoch 27; Iter   698/ 1862] train: loss: 0.0026499
[Epoch 27; Iter   728/ 1862] train: loss: 0.0017410
[Epoch 27; Iter   758/ 1862] train: loss: 0.0011213
[Epoch 27; Iter   788/ 1862] train: loss: 0.0015672
[Epoch 27; Iter   818/ 1862] train: loss: 0.1917067
[Epoch 27; Iter   848/ 1862] train: loss: 0.0025905
[Epoch 27; Iter   878/ 1862] train: loss: 0.0013455
[Epoch 27; Iter   908/ 1862] train: loss: 0.0024572
[Epoch 27; Iter   938/ 1862] train: loss: 0.0014150
[Epoch 27; Iter   968/ 1862] train: loss: 0.0014647
[Epoch 27; Iter   998/ 1862] train: loss: 0.0013219
[Epoch 27; Iter  1028/ 1862] train: loss: 0.0015208
[Epoch 27; Iter  1058/ 1862] train: loss: 0.0013230
[Epoch 27; Iter  1088/ 1862] train: loss: 0.0015119
[Epoch 27; Iter  1118/ 1862] train: loss: 0.0011840
[Epoch 27; Iter  1148/ 1862] train: loss: 0.0709921
[Epoch 27; Iter  1178/ 1862] train: loss: 0.0015581
[Epoch 27; Iter  1208/ 1862] train: loss: 0.0020959
[Epoch 27; Iter  1238/ 1862] train: loss: 0.0016903
[Epoch 27; Iter  1268/ 1862] train: loss: 0.0014690
[Epoch 27; Iter  1298/ 1862] train: loss: 0.0013847
[Epoch 27; Iter  1328/ 1862] train: loss: 0.0743376
[Epoch 27; Iter  1358/ 1862] train: loss: 0.0020120
[Epoch 27; Iter  1388/ 1862] train: loss: 0.0054940
[Epoch 27; Iter  1418/ 1862] train: loss: 0.0038860
[Epoch 27; Iter  1448/ 1862] train: loss: 0.0013243
[Epoch 27; Iter  1478/ 1862] train: loss: 0.0017830
[Epoch 27; Iter  1508/ 1862] train: loss: 0.0016204
[Epoch 27; Iter  1538/ 1862] train: loss: 0.0019792
[Epoch 27; Iter  1568/ 1862] train: loss: 0.0023887
[Epoch 27; Iter  1598/ 1862] train: loss: 0.0016304
[Epoch 27; Iter  1628/ 1862] train: loss: 0.0026128
[Epoch 27; Iter  1658/ 1862] train: loss: 0.0012071
[Epoch 27; Iter  1688/ 1862] train: loss: 0.0011114
[Epoch 27; Iter  1718/ 1862] train: loss: 0.0009427
[Epoch 27; Iter  1748/ 1862] train: loss: 0.0011957
[Epoch 27; Iter  1778/ 1862] train: loss: 0.0009025
[Epoch 27; Iter  1808/ 1862] train: loss: 0.0011848
[Epoch 27; Iter  1838/ 1862] train: loss: 0.0012746
[Epoch 27] ogbg-molmuv: 0.040897 val loss: 0.013583
[Epoch 27] ogbg-molmuv: 0.076042 test loss: 0.012614
[Epoch 28; Iter     6/ 1862] train: loss: 0.0015594
[Epoch 28; Iter    36/ 1862] train: loss: 0.0614386
[Epoch 28; Iter    66/ 1862] train: loss: 0.0017756
[Epoch 28; Iter    96/ 1862] train: loss: 0.0015823
[Epoch 28; Iter   126/ 1862] train: loss: 0.0011717
[Epoch 28; Iter   156/ 1862] train: loss: 0.0013117
[Epoch 28; Iter   186/ 1862] train: loss: 0.0015178
[Epoch 28; Iter   216/ 1862] train: loss: 0.0018754
[Epoch 28; Iter   246/ 1862] train: loss: 0.0022717
[Epoch 28; Iter   276/ 1862] train: loss: 0.0586036
[Epoch 28; Iter   306/ 1862] train: loss: 0.0013378
[Epoch 28; Iter   336/ 1862] train: loss: 0.0021859
[Epoch 28; Iter   366/ 1862] train: loss: 0.0008586
[Epoch 28; Iter   396/ 1862] train: loss: 0.0011540
[Epoch 28; Iter   426/ 1862] train: loss: 0.0010597
[Epoch 28; Iter   456/ 1862] train: loss: 0.0006742
[Epoch 28; Iter   486/ 1862] train: loss: 0.0007103
[Epoch 28; Iter   516/ 1862] train: loss: 0.0009812
[Epoch 28; Iter   546/ 1862] train: loss: 0.0007368
[Epoch 28; Iter   576/ 1862] train: loss: 0.0007346
[Epoch 28; Iter   606/ 1862] train: loss: 0.0011065
[Epoch 28; Iter   636/ 1862] train: loss: 0.0030750
[Epoch 28; Iter   666/ 1862] train: loss: 0.0070238
[Epoch 28; Iter   696/ 1862] train: loss: 0.0645607
[Epoch 28; Iter   726/ 1862] train: loss: 0.0018265
[Epoch 28; Iter   756/ 1862] train: loss: 0.0024119
[Epoch 28; Iter   786/ 1862] train: loss: 0.0016610
[Epoch 28; Iter   816/ 1862] train: loss: 0.0026949
[Epoch 28; Iter   846/ 1862] train: loss: 0.0010568
[Epoch 28; Iter   876/ 1862] train: loss: 0.0021126
[Epoch 28; Iter   906/ 1862] train: loss: 0.1020972
[Epoch 28; Iter   936/ 1862] train: loss: 0.0934867
[Epoch 28; Iter   966/ 1862] train: loss: 0.0013732
[Epoch 28; Iter   996/ 1862] train: loss: 0.0013837
[Epoch 28; Iter  1026/ 1862] train: loss: 0.0011103
[Epoch 28; Iter  1056/ 1862] train: loss: 0.0021380
[Epoch 28; Iter  1086/ 1862] train: loss: 0.0022431
[Epoch 28; Iter  1116/ 1862] train: loss: 0.1130841
[Epoch 28; Iter  1146/ 1862] train: loss: 0.0026657
[Epoch 28; Iter  1176/ 1862] train: loss: 0.0015506
[Epoch 28; Iter  1206/ 1862] train: loss: 0.0023067
[Epoch 28; Iter  1236/ 1862] train: loss: 0.0009777
[Epoch 28; Iter  1266/ 1862] train: loss: 0.0019175
[Epoch 28; Iter  1296/ 1862] train: loss: 0.0374994
[Epoch 28; Iter  1326/ 1862] train: loss: 0.0015807
[Epoch 28; Iter  1356/ 1862] train: loss: 0.0034904
[Epoch 28; Iter  1386/ 1862] train: loss: 0.0027703
[Epoch 28; Iter  1416/ 1862] train: loss: 0.0021216
[Epoch 28; Iter  1446/ 1862] train: loss: 0.0015672
[Epoch 28; Iter  1476/ 1862] train: loss: 0.0011158
[Epoch 28; Iter  1506/ 1862] train: loss: 0.0011443
[Epoch 28; Iter  1536/ 1862] train: loss: 0.0009854
[Epoch 28; Iter  1566/ 1862] train: loss: 0.0014570
[Epoch 28; Iter  1596/ 1862] train: loss: 0.0022295
[Epoch 28; Iter  1626/ 1862] train: loss: 0.0019449
[Epoch 28; Iter  1656/ 1862] train: loss: 0.0020435
[Epoch 28; Iter  1686/ 1862] train: loss: 0.0013223
[Epoch 28; Iter  1716/ 1862] train: loss: 0.0012514
[Epoch 28; Iter  1746/ 1862] train: loss: 0.0101326
[Epoch 28; Iter  1776/ 1862] train: loss: 0.0015975
[Epoch 28; Iter  1806/ 1862] train: loss: 0.0014623
[Epoch 28; Iter  1836/ 1862] train: loss: 0.0016355
[Epoch 28] ogbg-molmuv: 0.036410 val loss: 0.013524
[Epoch 28] ogbg-molmuv: 0.092149 test loss: 0.011563
[Epoch 29; Iter     4/ 1862] train: loss: 0.0010880
[Epoch 29; Iter    34/ 1862] train: loss: 0.0019448
[Epoch 29; Iter    64/ 1862] train: loss: 0.0009351
[Epoch 29; Iter    94/ 1862] train: loss: 0.0014099
[Epoch 29; Iter   124/ 1862] train: loss: 0.0669052
[Epoch 29; Iter   154/ 1862] train: loss: 0.0016115
[Epoch 29; Iter   184/ 1862] train: loss: 0.0035804
[Epoch 29; Iter   214/ 1862] train: loss: 0.0016208
[Epoch 29; Iter   244/ 1862] train: loss: 0.0014318
[Epoch 29; Iter   274/ 1862] train: loss: 0.0019185
[Epoch 29; Iter   304/ 1862] train: loss: 0.0013145
[Epoch 29; Iter   334/ 1862] train: loss: 0.0077627
[Epoch 29; Iter   364/ 1862] train: loss: 0.0024237
[Epoch 29; Iter   394/ 1862] train: loss: 0.0014105
[Epoch 29; Iter   424/ 1862] train: loss: 0.0011654
[Epoch 29; Iter   454/ 1862] train: loss: 0.0017216
[Epoch 29; Iter   484/ 1862] train: loss: 0.0237392
[Epoch 29; Iter   514/ 1862] train: loss: 0.0013424
[Epoch 29; Iter   544/ 1862] train: loss: 0.0019068
[Epoch 29; Iter   574/ 1862] train: loss: 0.0016186
[Epoch 29; Iter   604/ 1862] train: loss: 0.0011124
[Epoch 29; Iter   634/ 1862] train: loss: 0.0014066
[Epoch 29; Iter   664/ 1862] train: loss: 0.0022662
[Epoch 29; Iter   694/ 1862] train: loss: 0.0012727
[Epoch 29; Iter   724/ 1862] train: loss: 0.0695673
[Epoch 29; Iter   754/ 1862] train: loss: 0.0020117
[Epoch 29; Iter   784/ 1862] train: loss: 0.0014338
[Epoch 29; Iter   814/ 1862] train: loss: 0.0035532
[Epoch 29; Iter   844/ 1862] train: loss: 0.0013538
[Epoch 29; Iter   874/ 1862] train: loss: 0.0013024
[Epoch 29; Iter   904/ 1862] train: loss: 0.0010185
[Epoch 29; Iter   934/ 1862] train: loss: 0.0306404
[Epoch 29; Iter   964/ 1862] train: loss: 0.0016463
[Epoch 29; Iter   994/ 1862] train: loss: 0.0009650
[Epoch 29; Iter  1024/ 1862] train: loss: 0.0011076
[Epoch 29; Iter  1054/ 1862] train: loss: 0.0012134
[Epoch 29; Iter  1084/ 1862] train: loss: 0.0011298
[Epoch 29; Iter  1114/ 1862] train: loss: 0.0023205
[Epoch 29; Iter  1144/ 1862] train: loss: 0.0015226
[Epoch 29; Iter  1174/ 1862] train: loss: 0.0014140
[Epoch 29; Iter  1204/ 1862] train: loss: 0.0030392
[Epoch 29; Iter  1234/ 1862] train: loss: 0.0013082
[Epoch 29; Iter  1264/ 1862] train: loss: 0.0007192
[Epoch 29; Iter  1294/ 1862] train: loss: 0.0009873
[Epoch 29; Iter  1324/ 1862] train: loss: 0.0008277
[Epoch 29; Iter  1354/ 1862] train: loss: 0.0008725
[Epoch 29; Iter  1384/ 1862] train: loss: 0.0014392
[Epoch 29; Iter  1414/ 1862] train: loss: 0.0046607
[Epoch 29; Iter  1444/ 1862] train: loss: 0.0019324
[Epoch 29; Iter  1474/ 1862] train: loss: 0.0019718
[Epoch 29; Iter  1504/ 1862] train: loss: 0.0638540
[Epoch 29; Iter  1534/ 1862] train: loss: 0.0037351
[Epoch 27; Iter   698/ 1862] train: loss: 0.0021594
[Epoch 27; Iter   728/ 1862] train: loss: 0.0015996
[Epoch 27; Iter   758/ 1862] train: loss: 0.0017287
[Epoch 27; Iter   788/ 1862] train: loss: 0.0027034
[Epoch 27; Iter   818/ 1862] train: loss: 0.0020754
[Epoch 27; Iter   848/ 1862] train: loss: 0.0024352
[Epoch 27; Iter   878/ 1862] train: loss: 0.0022679
[Epoch 27; Iter   908/ 1862] train: loss: 0.0013277
[Epoch 27; Iter   938/ 1862] train: loss: 0.0013869
[Epoch 27; Iter   968/ 1862] train: loss: 0.0012310
[Epoch 27; Iter   998/ 1862] train: loss: 0.0019709
[Epoch 27; Iter  1028/ 1862] train: loss: 0.0368395
[Epoch 27; Iter  1058/ 1862] train: loss: 0.0011082
[Epoch 27; Iter  1088/ 1862] train: loss: 0.0010722
[Epoch 27; Iter  1118/ 1862] train: loss: 0.0017522
[Epoch 27; Iter  1148/ 1862] train: loss: 0.0056710
[Epoch 27; Iter  1178/ 1862] train: loss: 0.0021468
[Epoch 27; Iter  1208/ 1862] train: loss: 0.0023031
[Epoch 27; Iter  1238/ 1862] train: loss: 0.0015871
[Epoch 27; Iter  1268/ 1862] train: loss: 0.0012357
[Epoch 27; Iter  1298/ 1862] train: loss: 0.0019066
[Epoch 27; Iter  1328/ 1862] train: loss: 0.0013221
[Epoch 27; Iter  1358/ 1862] train: loss: 0.0016395
[Epoch 27; Iter  1388/ 1862] train: loss: 0.0014220
[Epoch 27; Iter  1418/ 1862] train: loss: 0.0023366
[Epoch 27; Iter  1448/ 1862] train: loss: 0.0021827
[Epoch 27; Iter  1478/ 1862] train: loss: 0.0034194
[Epoch 27; Iter  1508/ 1862] train: loss: 0.0080271
[Epoch 27; Iter  1538/ 1862] train: loss: 0.0521438
[Epoch 27; Iter  1568/ 1862] train: loss: 0.0070144
[Epoch 27; Iter  1598/ 1862] train: loss: 0.0014904
[Epoch 27; Iter  1628/ 1862] train: loss: 0.0565570
[Epoch 27; Iter  1658/ 1862] train: loss: 0.0013915
[Epoch 27; Iter  1688/ 1862] train: loss: 0.0014984
[Epoch 27; Iter  1718/ 1862] train: loss: 0.0015961
[Epoch 27; Iter  1748/ 1862] train: loss: 0.0012688
[Epoch 27; Iter  1778/ 1862] train: loss: 0.0011738
[Epoch 27; Iter  1808/ 1862] train: loss: 0.0049102
[Epoch 27; Iter  1838/ 1862] train: loss: 0.0011849
[Epoch 27] ogbg-molmuv: 0.035000 val loss: 0.013288
[Epoch 27] ogbg-molmuv: 0.058875 test loss: 0.012168
[Epoch 28; Iter     6/ 1862] train: loss: 0.0684615
[Epoch 28; Iter    36/ 1862] train: loss: 0.0009482
[Epoch 28; Iter    66/ 1862] train: loss: 0.0009285
[Epoch 28; Iter    96/ 1862] train: loss: 0.0010154
[Epoch 28; Iter   126/ 1862] train: loss: 0.0013939
[Epoch 28; Iter   156/ 1862] train: loss: 0.0011863
[Epoch 28; Iter   186/ 1862] train: loss: 0.0028586
[Epoch 28; Iter   216/ 1862] train: loss: 0.0023668
[Epoch 28; Iter   246/ 1862] train: loss: 0.0019372
[Epoch 28; Iter   276/ 1862] train: loss: 0.0014564
[Epoch 28; Iter   306/ 1862] train: loss: 0.0018203
[Epoch 28; Iter   336/ 1862] train: loss: 0.0012866
[Epoch 28; Iter   366/ 1862] train: loss: 0.0021192
[Epoch 28; Iter   396/ 1862] train: loss: 0.0013821
[Epoch 28; Iter   426/ 1862] train: loss: 0.0010055
[Epoch 28; Iter   456/ 1862] train: loss: 0.0011920
[Epoch 28; Iter   486/ 1862] train: loss: 0.0027051
[Epoch 28; Iter   516/ 1862] train: loss: 0.0017593
[Epoch 28; Iter   546/ 1862] train: loss: 0.0012130
[Epoch 28; Iter   576/ 1862] train: loss: 0.0013142
[Epoch 28; Iter   606/ 1862] train: loss: 0.0011035
[Epoch 28; Iter   636/ 1862] train: loss: 0.0008890
[Epoch 28; Iter   666/ 1862] train: loss: 0.0011802
[Epoch 28; Iter   696/ 1862] train: loss: 0.0047598
[Epoch 28; Iter   726/ 1862] train: loss: 0.0201722
[Epoch 28; Iter   756/ 1862] train: loss: 0.0015270
[Epoch 28; Iter   786/ 1862] train: loss: 0.0010035
[Epoch 28; Iter   816/ 1862] train: loss: 0.0013915
[Epoch 28; Iter   846/ 1862] train: loss: 0.0012606
[Epoch 28; Iter   876/ 1862] train: loss: 0.0019224
[Epoch 28; Iter   906/ 1862] train: loss: 0.0891463
[Epoch 28; Iter   936/ 1862] train: loss: 0.0011705
[Epoch 28; Iter   966/ 1862] train: loss: 0.0014687
[Epoch 28; Iter   996/ 1862] train: loss: 0.0013670
[Epoch 28; Iter  1026/ 1862] train: loss: 0.0023295
[Epoch 28; Iter  1056/ 1862] train: loss: 0.0026690
[Epoch 28; Iter  1086/ 1862] train: loss: 0.0015439
[Epoch 28; Iter  1116/ 1862] train: loss: 0.0017434
[Epoch 28; Iter  1146/ 1862] train: loss: 0.0012805
[Epoch 28; Iter  1176/ 1862] train: loss: 0.0012113
[Epoch 28; Iter  1206/ 1862] train: loss: 0.0943307
[Epoch 28; Iter  1236/ 1862] train: loss: 0.0007356
[Epoch 28; Iter  1266/ 1862] train: loss: 0.0014491
[Epoch 28; Iter  1296/ 1862] train: loss: 0.0013669
[Epoch 28; Iter  1326/ 1862] train: loss: 0.0030862
[Epoch 28; Iter  1356/ 1862] train: loss: 0.0053113
[Epoch 28; Iter  1386/ 1862] train: loss: 0.0695513
[Epoch 28; Iter  1416/ 1862] train: loss: 0.0016696
[Epoch 28; Iter  1446/ 1862] train: loss: 0.0019780
[Epoch 28; Iter  1476/ 1862] train: loss: 0.0012729
[Epoch 28; Iter  1506/ 1862] train: loss: 0.0014381
[Epoch 28; Iter  1536/ 1862] train: loss: 0.0874365
[Epoch 28; Iter  1566/ 1862] train: loss: 0.0033134
[Epoch 28; Iter  1596/ 1862] train: loss: 0.0020225
[Epoch 28; Iter  1626/ 1862] train: loss: 0.0020204
[Epoch 28; Iter  1656/ 1862] train: loss: 0.0035112
[Epoch 28; Iter  1686/ 1862] train: loss: 0.0024833
[Epoch 28; Iter  1716/ 1862] train: loss: 0.0017109
[Epoch 28; Iter  1746/ 1862] train: loss: 0.0013052
[Epoch 28; Iter  1776/ 1862] train: loss: 0.0009850
[Epoch 28; Iter  1806/ 1862] train: loss: 0.0017760
[Epoch 28; Iter  1836/ 1862] train: loss: 0.0018621
[Epoch 28] ogbg-molmuv: 0.027728 val loss: 0.022412
[Epoch 28] ogbg-molmuv: 0.030883 test loss: 0.020572
[Epoch 29; Iter     4/ 1862] train: loss: 0.0023307
[Epoch 29; Iter    34/ 1862] train: loss: 0.0958578
[Epoch 29; Iter    64/ 1862] train: loss: 0.0015778
[Epoch 29; Iter    94/ 1862] train: loss: 0.0407796
[Epoch 29; Iter   124/ 1862] train: loss: 0.0022099
[Epoch 29; Iter   154/ 1862] train: loss: 0.0013112
[Epoch 29; Iter   184/ 1862] train: loss: 0.0013137
[Epoch 29; Iter   214/ 1862] train: loss: 0.0010720
[Epoch 29; Iter   244/ 1862] train: loss: 0.0445307
[Epoch 29; Iter   274/ 1862] train: loss: 0.0022001
[Epoch 29; Iter   304/ 1862] train: loss: 0.0012090
[Epoch 29; Iter   334/ 1862] train: loss: 0.0018955
[Epoch 29; Iter   364/ 1862] train: loss: 0.0041680
[Epoch 29; Iter   394/ 1862] train: loss: 0.0015622
[Epoch 29; Iter   424/ 1862] train: loss: 0.0412806
[Epoch 29; Iter   454/ 1862] train: loss: 0.0043656
[Epoch 29; Iter   484/ 1862] train: loss: 0.0017366
[Epoch 29; Iter   514/ 1862] train: loss: 0.0019423
[Epoch 29; Iter   544/ 1862] train: loss: 0.0012052
[Epoch 29; Iter   574/ 1862] train: loss: 0.0018401
[Epoch 29; Iter   604/ 1862] train: loss: 0.0010021
[Epoch 29; Iter   634/ 1862] train: loss: 0.0017014
[Epoch 29; Iter   664/ 1862] train: loss: 0.0026248
[Epoch 29; Iter   694/ 1862] train: loss: 0.0009166
[Epoch 29; Iter   724/ 1862] train: loss: 0.0013392
[Epoch 29; Iter   754/ 1862] train: loss: 0.0008777
[Epoch 29; Iter   784/ 1862] train: loss: 0.0013895
[Epoch 29; Iter   814/ 1862] train: loss: 0.0011414
[Epoch 29; Iter   844/ 1862] train: loss: 0.0013594
[Epoch 29; Iter   874/ 1862] train: loss: 0.0012643
[Epoch 29; Iter   904/ 1862] train: loss: 0.0013356
[Epoch 29; Iter   934/ 1862] train: loss: 0.0293378
[Epoch 29; Iter   964/ 1862] train: loss: 0.0007811
[Epoch 29; Iter   994/ 1862] train: loss: 0.0007397
[Epoch 29; Iter  1024/ 1862] train: loss: 0.0009268
[Epoch 29; Iter  1054/ 1862] train: loss: 0.0015775
[Epoch 29; Iter  1084/ 1862] train: loss: 0.0022093
[Epoch 29; Iter  1114/ 1862] train: loss: 0.0017916
[Epoch 29; Iter  1144/ 1862] train: loss: 0.0015379
[Epoch 29; Iter  1174/ 1862] train: loss: 0.0592132
[Epoch 29; Iter  1204/ 1862] train: loss: 0.0011666
[Epoch 29; Iter  1234/ 1862] train: loss: 0.0011652
[Epoch 29; Iter  1264/ 1862] train: loss: 0.0009439
[Epoch 29; Iter  1294/ 1862] train: loss: 0.0011397
[Epoch 29; Iter  1324/ 1862] train: loss: 0.0009329
[Epoch 29; Iter  1354/ 1862] train: loss: 0.0013881
[Epoch 29; Iter  1384/ 1862] train: loss: 0.0015105
[Epoch 29; Iter  1414/ 1862] train: loss: 0.0418117
[Epoch 29; Iter  1444/ 1862] train: loss: 0.0029967
[Epoch 29; Iter  1474/ 1862] train: loss: 0.0015045
[Epoch 29; Iter  1504/ 1862] train: loss: 0.0010812
[Epoch 29; Iter  1534/ 1862] train: loss: 0.0013183
[Epoch 27; Iter   698/ 1862] train: loss: 0.0015383
[Epoch 27; Iter   728/ 1862] train: loss: 0.0009742
[Epoch 27; Iter   758/ 1862] train: loss: 0.0012794
[Epoch 27; Iter   788/ 1862] train: loss: 0.0056393
[Epoch 27; Iter   818/ 1862] train: loss: 0.0009029
[Epoch 27; Iter   848/ 1862] train: loss: 0.0008119
[Epoch 27; Iter   878/ 1862] train: loss: 0.0013673
[Epoch 27; Iter   908/ 1862] train: loss: 0.0012868
[Epoch 27; Iter   938/ 1862] train: loss: 0.0700047
[Epoch 27; Iter   968/ 1862] train: loss: 0.0022131
[Epoch 27; Iter   998/ 1862] train: loss: 0.0010379
[Epoch 27; Iter  1028/ 1862] train: loss: 0.0015675
[Epoch 27; Iter  1058/ 1862] train: loss: 0.0021693
[Epoch 27; Iter  1088/ 1862] train: loss: 0.0020505
[Epoch 27; Iter  1118/ 1862] train: loss: 0.0033529
[Epoch 27; Iter  1148/ 1862] train: loss: 0.0019186
[Epoch 27; Iter  1178/ 1862] train: loss: 0.0010461
[Epoch 27; Iter  1208/ 1862] train: loss: 0.0031762
[Epoch 27; Iter  1238/ 1862] train: loss: 0.0044532
[Epoch 27; Iter  1268/ 1862] train: loss: 0.0017535
[Epoch 27; Iter  1298/ 1862] train: loss: 0.0013729
[Epoch 27; Iter  1328/ 1862] train: loss: 0.0019441
[Epoch 27; Iter  1358/ 1862] train: loss: 0.0638710
[Epoch 27; Iter  1388/ 1862] train: loss: 0.0014762
[Epoch 27; Iter  1418/ 1862] train: loss: 0.0015226
[Epoch 27; Iter  1448/ 1862] train: loss: 0.0017521
[Epoch 27; Iter  1478/ 1862] train: loss: 0.0011615
[Epoch 27; Iter  1508/ 1862] train: loss: 0.0019878
[Epoch 27; Iter  1538/ 1862] train: loss: 0.0013570
[Epoch 27; Iter  1568/ 1862] train: loss: 0.0012946
[Epoch 27; Iter  1598/ 1862] train: loss: 0.0011058
[Epoch 27; Iter  1628/ 1862] train: loss: 0.0010997
[Epoch 27; Iter  1658/ 1862] train: loss: 0.0012386
[Epoch 27; Iter  1688/ 1862] train: loss: 0.0013075
[Epoch 27; Iter  1718/ 1862] train: loss: 0.0009158
[Epoch 27; Iter  1748/ 1862] train: loss: 0.0032117
[Epoch 27; Iter  1778/ 1862] train: loss: 0.0017923
[Epoch 27; Iter  1808/ 1862] train: loss: 0.0722849
[Epoch 27; Iter  1838/ 1862] train: loss: 0.0009126
[Epoch 27] ogbg-molmuv: 0.041895 val loss: 0.039917
[Epoch 27] ogbg-molmuv: 0.060502 test loss: 0.032575
[Epoch 28; Iter     6/ 1862] train: loss: 0.0018939
[Epoch 28; Iter    36/ 1862] train: loss: 0.0009942
[Epoch 28; Iter    66/ 1862] train: loss: 0.0014853
[Epoch 28; Iter    96/ 1862] train: loss: 0.0012613
[Epoch 28; Iter   126/ 1862] train: loss: 0.0012488
[Epoch 28; Iter   156/ 1862] train: loss: 0.0012526
[Epoch 28; Iter   186/ 1862] train: loss: 0.0007124
[Epoch 28; Iter   216/ 1862] train: loss: 0.0009454
[Epoch 28; Iter   246/ 1862] train: loss: 0.0009113
[Epoch 28; Iter   276/ 1862] train: loss: 0.0008656
[Epoch 28; Iter   306/ 1862] train: loss: 0.0011408
[Epoch 28; Iter   336/ 1862] train: loss: 0.0009939
[Epoch 28; Iter   366/ 1862] train: loss: 0.0020240
[Epoch 28; Iter   396/ 1862] train: loss: 0.0018344
[Epoch 28; Iter   426/ 1862] train: loss: 0.0017105
[Epoch 28; Iter   456/ 1862] train: loss: 0.0624298
[Epoch 28; Iter   486/ 1862] train: loss: 0.0020506
[Epoch 28; Iter   516/ 1862] train: loss: 0.0838642
[Epoch 28; Iter   546/ 1862] train: loss: 0.0021588
[Epoch 28; Iter   576/ 1862] train: loss: 0.0010606
[Epoch 28; Iter   606/ 1862] train: loss: 0.0019248
[Epoch 28; Iter   636/ 1862] train: loss: 0.0010870
[Epoch 28; Iter   666/ 1862] train: loss: 0.0011227
[Epoch 28; Iter   696/ 1862] train: loss: 0.0010355
[Epoch 28; Iter   726/ 1862] train: loss: 0.0015804
[Epoch 28; Iter   756/ 1862] train: loss: 0.0019605
[Epoch 28; Iter   786/ 1862] train: loss: 0.0026666
[Epoch 28; Iter   816/ 1862] train: loss: 0.0063321
[Epoch 28; Iter   846/ 1862] train: loss: 0.0043843
[Epoch 28; Iter   876/ 1862] train: loss: 0.0017453
[Epoch 28; Iter   906/ 1862] train: loss: 0.0010191
[Epoch 28; Iter   936/ 1862] train: loss: 0.0010225
[Epoch 28; Iter   966/ 1862] train: loss: 0.0014916
[Epoch 28; Iter   996/ 1862] train: loss: 0.0025396
[Epoch 28; Iter  1026/ 1862] train: loss: 0.0017642
[Epoch 28; Iter  1056/ 1862] train: loss: 0.0010577
[Epoch 28; Iter  1086/ 1862] train: loss: 0.0012692
[Epoch 28; Iter  1116/ 1862] train: loss: 0.0010417
[Epoch 28; Iter  1146/ 1862] train: loss: 0.0014495
[Epoch 28; Iter  1176/ 1862] train: loss: 0.0010159
[Epoch 28; Iter  1206/ 1862] train: loss: 0.0008028
[Epoch 28; Iter  1236/ 1862] train: loss: 0.0011032
[Epoch 28; Iter  1266/ 1862] train: loss: 0.0822380
[Epoch 28; Iter  1296/ 1862] train: loss: 0.0016504
[Epoch 28; Iter  1326/ 1862] train: loss: 0.0017296
[Epoch 28; Iter  1356/ 1862] train: loss: 0.0017867
[Epoch 28; Iter  1386/ 1862] train: loss: 0.0010501
[Epoch 28; Iter  1416/ 1862] train: loss: 0.0749643
[Epoch 28; Iter  1446/ 1862] train: loss: 0.0110466
[Epoch 28; Iter  1476/ 1862] train: loss: 0.0023771
[Epoch 28; Iter  1506/ 1862] train: loss: 0.0028928
[Epoch 28; Iter  1536/ 1862] train: loss: 0.0019187
[Epoch 28; Iter  1566/ 1862] train: loss: 0.0015811
[Epoch 28; Iter  1596/ 1862] train: loss: 0.0016475
[Epoch 28; Iter  1626/ 1862] train: loss: 0.0012308
[Epoch 28; Iter  1656/ 1862] train: loss: 0.0590431
[Epoch 28; Iter  1686/ 1862] train: loss: 0.0013491
[Epoch 28; Iter  1716/ 1862] train: loss: 0.1289410
[Epoch 28; Iter  1746/ 1862] train: loss: 0.0007395
[Epoch 28; Iter  1776/ 1862] train: loss: 0.0017597
[Epoch 28; Iter  1806/ 1862] train: loss: 0.0027489
[Epoch 28; Iter  1836/ 1862] train: loss: 0.0020632
[Epoch 28] ogbg-molmuv: 0.053766 val loss: 0.014148
[Epoch 28] ogbg-molmuv: 0.057640 test loss: 0.013722
[Epoch 29; Iter     4/ 1862] train: loss: 0.0014524
[Epoch 29; Iter    34/ 1862] train: loss: 0.0013001
[Epoch 29; Iter    64/ 1862] train: loss: 0.0018617
[Epoch 29; Iter    94/ 1862] train: loss: 0.0026969
[Epoch 29; Iter   124/ 1862] train: loss: 0.0017184
[Epoch 29; Iter   154/ 1862] train: loss: 0.0013994
[Epoch 29; Iter   184/ 1862] train: loss: 0.0014184
[Epoch 29; Iter   214/ 1862] train: loss: 0.0020931
[Epoch 29; Iter   244/ 1862] train: loss: 0.0017885
[Epoch 29; Iter   274/ 1862] train: loss: 0.0411965
[Epoch 29; Iter   304/ 1862] train: loss: 0.0010126
[Epoch 29; Iter   334/ 1862] train: loss: 0.0016072
[Epoch 29; Iter   364/ 1862] train: loss: 0.0024291
[Epoch 29; Iter   394/ 1862] train: loss: 0.0010125
[Epoch 29; Iter   424/ 1862] train: loss: 0.0014163
[Epoch 29; Iter   454/ 1862] train: loss: 0.0015043
[Epoch 29; Iter   484/ 1862] train: loss: 0.0024229
[Epoch 29; Iter   514/ 1862] train: loss: 0.0013058
[Epoch 29; Iter   544/ 1862] train: loss: 0.0618061
[Epoch 29; Iter   574/ 1862] train: loss: 0.0015604
[Epoch 29; Iter   604/ 1862] train: loss: 0.0014825
[Epoch 29; Iter   634/ 1862] train: loss: 0.0010913
[Epoch 29; Iter   664/ 1862] train: loss: 0.0011283
[Epoch 29; Iter   694/ 1862] train: loss: 0.0018295
[Epoch 29; Iter   724/ 1862] train: loss: 0.0786096
[Epoch 29; Iter   754/ 1862] train: loss: 0.0014311
[Epoch 29; Iter   784/ 1862] train: loss: 0.0017675
[Epoch 29; Iter   814/ 1862] train: loss: 0.0851624
[Epoch 29; Iter   844/ 1862] train: loss: 0.0010067
[Epoch 29; Iter   874/ 1862] train: loss: 0.0018011
[Epoch 29; Iter   904/ 1862] train: loss: 0.0010685
[Epoch 29; Iter   934/ 1862] train: loss: 0.0010681
[Epoch 29; Iter   964/ 1862] train: loss: 0.0415431
[Epoch 29; Iter   994/ 1862] train: loss: 0.0033905
[Epoch 29; Iter  1024/ 1862] train: loss: 0.0500077
[Epoch 29; Iter  1054/ 1862] train: loss: 0.0019773
[Epoch 29; Iter  1084/ 1862] train: loss: 0.0035056
[Epoch 29; Iter  1114/ 1862] train: loss: 0.0014902
[Epoch 29; Iter  1144/ 1862] train: loss: 0.0022624
[Epoch 29; Iter  1174/ 1862] train: loss: 0.0013539
[Epoch 29; Iter  1204/ 1862] train: loss: 0.1059436
[Epoch 29; Iter  1234/ 1862] train: loss: 0.0021110
[Epoch 29; Iter  1264/ 1862] train: loss: 0.0021345
[Epoch 29; Iter  1294/ 1862] train: loss: 0.0817094
[Epoch 29; Iter  1324/ 1862] train: loss: 0.0015043
[Epoch 29; Iter  1354/ 1862] train: loss: 0.0009550
[Epoch 29; Iter  1384/ 1862] train: loss: 0.0604388
[Epoch 29; Iter  1414/ 1862] train: loss: 0.0010093
[Epoch 29; Iter  1444/ 1862] train: loss: 0.0023118
[Epoch 29; Iter  1474/ 1862] train: loss: 0.0017756
[Epoch 29; Iter  1504/ 1862] train: loss: 0.0008912
[Epoch 29; Iter  1534/ 1862] train: loss: 0.0010731
[Epoch 26; Iter  1315/ 2483] train: loss: 0.0017266
[Epoch 26; Iter  1345/ 2483] train: loss: 0.0019978
[Epoch 26; Iter  1375/ 2483] train: loss: 0.0075447
[Epoch 26; Iter  1405/ 2483] train: loss: 0.0371748
[Epoch 26; Iter  1435/ 2483] train: loss: 0.0170002
[Epoch 26; Iter  1465/ 2483] train: loss: 0.0019119
[Epoch 26; Iter  1495/ 2483] train: loss: 0.0024837
[Epoch 26; Iter  1525/ 2483] train: loss: 0.0033321
[Epoch 26; Iter  1555/ 2483] train: loss: 0.0033063
[Epoch 26; Iter  1585/ 2483] train: loss: 0.0014638
[Epoch 26; Iter  1615/ 2483] train: loss: 0.0019724
[Epoch 26; Iter  1645/ 2483] train: loss: 0.0016476
[Epoch 26; Iter  1675/ 2483] train: loss: 0.0709240
[Epoch 26; Iter  1705/ 2483] train: loss: 0.0012955
[Epoch 26; Iter  1735/ 2483] train: loss: 0.0019258
[Epoch 26; Iter  1765/ 2483] train: loss: 0.0015443
[Epoch 26; Iter  1795/ 2483] train: loss: 0.0029720
[Epoch 26; Iter  1825/ 2483] train: loss: 0.0016024
[Epoch 26; Iter  1855/ 2483] train: loss: 0.0050297
[Epoch 26; Iter  1885/ 2483] train: loss: 0.0031000
[Epoch 26; Iter  1915/ 2483] train: loss: 0.0014242
[Epoch 26; Iter  1945/ 2483] train: loss: 0.0015185
[Epoch 26; Iter  1975/ 2483] train: loss: 0.0008179
[Epoch 26; Iter  2005/ 2483] train: loss: 0.0016694
[Epoch 26; Iter  2035/ 2483] train: loss: 0.0013337
[Epoch 26; Iter  2065/ 2483] train: loss: 0.0761275
[Epoch 26; Iter  2095/ 2483] train: loss: 0.0014382
[Epoch 26; Iter  2125/ 2483] train: loss: 0.0013531
[Epoch 26; Iter  2155/ 2483] train: loss: 0.0009912
[Epoch 26; Iter  2185/ 2483] train: loss: 0.0009151
[Epoch 26; Iter  2215/ 2483] train: loss: 0.0012312
[Epoch 26; Iter  2245/ 2483] train: loss: 0.0599382
[Epoch 26; Iter  2275/ 2483] train: loss: 0.0011936
[Epoch 26; Iter  2305/ 2483] train: loss: 0.0015564
[Epoch 26; Iter  2335/ 2483] train: loss: 0.0020750
[Epoch 26; Iter  2365/ 2483] train: loss: 0.0019517
[Epoch 26; Iter  2395/ 2483] train: loss: 0.0016791
[Epoch 26; Iter  2425/ 2483] train: loss: 0.0029488
[Epoch 26; Iter  2455/ 2483] train: loss: 0.0017617
[Epoch 26] ogbg-molmuv: 0.123018 val loss: 0.042794
[Epoch 26] ogbg-molmuv: 0.125623 test loss: 0.167664
[Epoch 27; Iter     2/ 2483] train: loss: 0.0016720
[Epoch 27; Iter    32/ 2483] train: loss: 0.0014985
[Epoch 27; Iter    62/ 2483] train: loss: 0.0521092
[Epoch 27; Iter    92/ 2483] train: loss: 0.0018281
[Epoch 27; Iter   122/ 2483] train: loss: 0.0294960
[Epoch 27; Iter   152/ 2483] train: loss: 0.0301221
[Epoch 27; Iter   182/ 2483] train: loss: 0.0600082
[Epoch 27; Iter   212/ 2483] train: loss: 0.0016067
[Epoch 27; Iter   242/ 2483] train: loss: 0.0019998
[Epoch 27; Iter   272/ 2483] train: loss: 0.0010813
[Epoch 27; Iter   302/ 2483] train: loss: 0.0018239
[Epoch 27; Iter   332/ 2483] train: loss: 0.0009176
[Epoch 27; Iter   362/ 2483] train: loss: 0.0009215
[Epoch 27; Iter   392/ 2483] train: loss: 0.0013638
[Epoch 27; Iter   422/ 2483] train: loss: 0.0018476
[Epoch 27; Iter   452/ 2483] train: loss: 0.0011888
[Epoch 27; Iter   482/ 2483] train: loss: 0.0029141
[Epoch 27; Iter   512/ 2483] train: loss: 0.0029437
[Epoch 27; Iter   542/ 2483] train: loss: 0.0018708
[Epoch 27; Iter   572/ 2483] train: loss: 0.0025971
[Epoch 27; Iter   602/ 2483] train: loss: 0.0108429
[Epoch 27; Iter   632/ 2483] train: loss: 0.0021377
[Epoch 27; Iter   662/ 2483] train: loss: 0.0018370
[Epoch 27; Iter   692/ 2483] train: loss: 0.0015102
[Epoch 27; Iter   722/ 2483] train: loss: 0.0013701
[Epoch 27; Iter   752/ 2483] train: loss: 0.0030523
[Epoch 27; Iter   782/ 2483] train: loss: 0.0010586
[Epoch 27; Iter   812/ 2483] train: loss: 0.0032527
[Epoch 27; Iter   842/ 2483] train: loss: 0.0019323
[Epoch 27; Iter   872/ 2483] train: loss: 0.0020217
[Epoch 27; Iter   902/ 2483] train: loss: 0.0017302
[Epoch 27; Iter   932/ 2483] train: loss: 0.0012261
[Epoch 27; Iter   962/ 2483] train: loss: 0.0015244
[Epoch 27; Iter   992/ 2483] train: loss: 0.0016342
[Epoch 27; Iter  1022/ 2483] train: loss: 0.0036186
[Epoch 27; Iter  1052/ 2483] train: loss: 0.0802887
[Epoch 27; Iter  1082/ 2483] train: loss: 0.0039828
[Epoch 27; Iter  1112/ 2483] train: loss: 0.0019084
[Epoch 27; Iter  1142/ 2483] train: loss: 0.0023238
[Epoch 27; Iter  1172/ 2483] train: loss: 0.0021407
[Epoch 27; Iter  1202/ 2483] train: loss: 0.0045607
[Epoch 27; Iter  1232/ 2483] train: loss: 0.0016465
[Epoch 27; Iter  1262/ 2483] train: loss: 0.0017324
[Epoch 27; Iter  1292/ 2483] train: loss: 0.0029076
[Epoch 27; Iter  1322/ 2483] train: loss: 0.0012174
[Epoch 27; Iter  1352/ 2483] train: loss: 0.0012848
[Epoch 27; Iter  1382/ 2483] train: loss: 0.0012011
[Epoch 27; Iter  1412/ 2483] train: loss: 0.0013069
[Epoch 27; Iter  1442/ 2483] train: loss: 0.0017352
[Epoch 27; Iter  1472/ 2483] train: loss: 0.0013366
[Epoch 27; Iter  1502/ 2483] train: loss: 0.0015508
[Epoch 27; Iter  1532/ 2483] train: loss: 0.0017242
[Epoch 27; Iter  1562/ 2483] train: loss: 0.0016416
[Epoch 27; Iter  1592/ 2483] train: loss: 0.0024972
[Epoch 27; Iter  1622/ 2483] train: loss: 0.0030432
[Epoch 27; Iter  1652/ 2483] train: loss: 0.0019830
[Epoch 27; Iter  1682/ 2483] train: loss: 0.0033622
[Epoch 27; Iter  1712/ 2483] train: loss: 0.0627762
[Epoch 27; Iter  1742/ 2483] train: loss: 0.0043729
[Epoch 27; Iter  1772/ 2483] train: loss: 0.0013138
[Epoch 27; Iter  1802/ 2483] train: loss: 0.0019142
[Epoch 27; Iter  1832/ 2483] train: loss: 0.0019914
[Epoch 27; Iter  1862/ 2483] train: loss: 0.0019520
[Epoch 27; Iter  1892/ 2483] train: loss: 0.0014068
[Epoch 27; Iter  1922/ 2483] train: loss: 0.0015702
[Epoch 27; Iter  1952/ 2483] train: loss: 0.0490919
[Epoch 27; Iter  1982/ 2483] train: loss: 0.0089972
[Epoch 27; Iter  2012/ 2483] train: loss: 0.0014735
[Epoch 27; Iter  2042/ 2483] train: loss: 0.0009422
[Epoch 27; Iter  2072/ 2483] train: loss: 0.0631793
[Epoch 27; Iter  2102/ 2483] train: loss: 0.0009258
[Epoch 27; Iter  2132/ 2483] train: loss: 0.0009465
[Epoch 27; Iter  2162/ 2483] train: loss: 0.0009742
[Epoch 27; Iter  2192/ 2483] train: loss: 0.0012798
[Epoch 27; Iter  2222/ 2483] train: loss: 0.0015046
[Epoch 27; Iter  2252/ 2483] train: loss: 0.0019069
[Epoch 27; Iter  2282/ 2483] train: loss: 0.0012826
[Epoch 27; Iter  2312/ 2483] train: loss: 0.0016596
[Epoch 27; Iter  2342/ 2483] train: loss: 0.0015774
[Epoch 27; Iter  2372/ 2483] train: loss: 0.0016568
[Epoch 27; Iter  2402/ 2483] train: loss: 0.0009456
[Epoch 27; Iter  2432/ 2483] train: loss: 0.0011135
[Epoch 27; Iter  2462/ 2483] train: loss: 0.0013331
[Epoch 27] ogbg-molmuv: 0.132938 val loss: 0.009805
[Epoch 27] ogbg-molmuv: 0.105168 test loss: 0.072561
[Epoch 28; Iter     9/ 2483] train: loss: 0.0008244
[Epoch 28; Iter    39/ 2483] train: loss: 0.0015206
[Epoch 28; Iter    69/ 2483] train: loss: 0.0012442
[Epoch 28; Iter    99/ 2483] train: loss: 0.0016635
[Epoch 28; Iter   129/ 2483] train: loss: 0.0017934
[Epoch 28; Iter   159/ 2483] train: loss: 0.0017808
[Epoch 28; Iter   189/ 2483] train: loss: 0.0013890
[Epoch 28; Iter   219/ 2483] train: loss: 0.0040826
[Epoch 28; Iter   249/ 2483] train: loss: 0.0015916
[Epoch 28; Iter   279/ 2483] train: loss: 0.0024712
[Epoch 28; Iter   309/ 2483] train: loss: 0.0019068
[Epoch 28; Iter   339/ 2483] train: loss: 0.0013530
[Epoch 28; Iter   369/ 2483] train: loss: 0.0030651
[Epoch 28; Iter   399/ 2483] train: loss: 0.0012890
[Epoch 28; Iter   429/ 2483] train: loss: 0.0023889
[Epoch 28; Iter   459/ 2483] train: loss: 0.0012473
[Epoch 28; Iter   489/ 2483] train: loss: 0.0015553
[Epoch 28; Iter   519/ 2483] train: loss: 0.0014162
[Epoch 28; Iter   549/ 2483] train: loss: 0.0012377
[Epoch 28; Iter   579/ 2483] train: loss: 0.0014459
[Epoch 28; Iter   609/ 2483] train: loss: 0.0247210
[Epoch 28; Iter   639/ 2483] train: loss: 0.0014239
[Epoch 28; Iter   669/ 2483] train: loss: 0.0026090
[Epoch 28; Iter   699/ 2483] train: loss: 0.0102960
[Epoch 28; Iter   729/ 2483] train: loss: 0.0026672
[Epoch 28; Iter   759/ 2483] train: loss: 0.1010440
[Epoch 28; Iter   789/ 2483] train: loss: 0.0007418
[Epoch 28; Iter   819/ 2483] train: loss: 0.0011278
[Epoch 28; Iter   849/ 2483] train: loss: 0.0013745
[Epoch 28; Iter   879/ 2483] train: loss: 0.0012816
[Epoch 28; Iter   909/ 2483] train: loss: 0.0018105
[Epoch 26; Iter  1315/ 2483] train: loss: 0.0017360
[Epoch 26; Iter  1345/ 2483] train: loss: 0.0019727
[Epoch 26; Iter  1375/ 2483] train: loss: 0.2278802
[Epoch 26; Iter  1405/ 2483] train: loss: 0.0018537
[Epoch 26; Iter  1435/ 2483] train: loss: 0.0018736
[Epoch 26; Iter  1465/ 2483] train: loss: 0.0013426
[Epoch 26; Iter  1495/ 2483] train: loss: 0.0014718
[Epoch 26; Iter  1525/ 2483] train: loss: 0.0013692
[Epoch 26; Iter  1555/ 2483] train: loss: 0.0016829
[Epoch 26; Iter  1585/ 2483] train: loss: 0.0010294
[Epoch 26; Iter  1615/ 2483] train: loss: 0.0009451
[Epoch 26; Iter  1645/ 2483] train: loss: 0.0012187
[Epoch 26; Iter  1675/ 2483] train: loss: 0.0618321
[Epoch 26; Iter  1705/ 2483] train: loss: 0.0019788
[Epoch 26; Iter  1735/ 2483] train: loss: 0.0013754
[Epoch 26; Iter  1765/ 2483] train: loss: 0.0009713
[Epoch 26; Iter  1795/ 2483] train: loss: 0.0420931
[Epoch 26; Iter  1825/ 2483] train: loss: 0.0010870
[Epoch 26; Iter  1855/ 2483] train: loss: 0.0014527
[Epoch 26; Iter  1885/ 2483] train: loss: 0.0006360
[Epoch 26; Iter  1915/ 2483] train: loss: 0.0014608
[Epoch 26; Iter  1945/ 2483] train: loss: 0.0017194
[Epoch 26; Iter  1975/ 2483] train: loss: 0.0011316
[Epoch 26; Iter  2005/ 2483] train: loss: 0.0017274
[Epoch 26; Iter  2035/ 2483] train: loss: 0.0009143
[Epoch 26; Iter  2065/ 2483] train: loss: 0.0012689
[Epoch 26; Iter  2095/ 2483] train: loss: 0.0014136
[Epoch 26; Iter  2125/ 2483] train: loss: 0.0012925
[Epoch 26; Iter  2155/ 2483] train: loss: 0.0021362
[Epoch 26; Iter  2185/ 2483] train: loss: 0.0016246
[Epoch 26; Iter  2215/ 2483] train: loss: 0.0024938
[Epoch 26; Iter  2245/ 2483] train: loss: 0.0023437
[Epoch 26; Iter  2275/ 2483] train: loss: 0.0015806
[Epoch 26; Iter  2305/ 2483] train: loss: 0.0012305
[Epoch 26; Iter  2335/ 2483] train: loss: 0.0009612
[Epoch 26; Iter  2365/ 2483] train: loss: 0.0018105
[Epoch 26; Iter  2395/ 2483] train: loss: 0.0023137
[Epoch 26; Iter  2425/ 2483] train: loss: 0.0016444
[Epoch 26; Iter  2455/ 2483] train: loss: 0.0021283
[Epoch 26] ogbg-molmuv: 0.122986 val loss: 0.009828
[Epoch 26] ogbg-molmuv: 0.164598 test loss: 0.013747
[Epoch 27; Iter     2/ 2483] train: loss: 0.0012026
[Epoch 27; Iter    32/ 2483] train: loss: 0.0131365
[Epoch 27; Iter    62/ 2483] train: loss: 0.0009475
[Epoch 27; Iter    92/ 2483] train: loss: 0.0018815
[Epoch 27; Iter   122/ 2483] train: loss: 0.0019242
[Epoch 27; Iter   152/ 2483] train: loss: 0.0020090
[Epoch 27; Iter   182/ 2483] train: loss: 0.0026768
[Epoch 27; Iter   212/ 2483] train: loss: 0.0018838
[Epoch 27; Iter   242/ 2483] train: loss: 0.0025822
[Epoch 27; Iter   272/ 2483] train: loss: 0.0922748
[Epoch 27; Iter   302/ 2483] train: loss: 0.0024118
[Epoch 27; Iter   332/ 2483] train: loss: 0.0012569
[Epoch 27; Iter   362/ 2483] train: loss: 0.0647732
[Epoch 27; Iter   392/ 2483] train: loss: 0.1159213
[Epoch 27; Iter   422/ 2483] train: loss: 0.0015492
[Epoch 27; Iter   452/ 2483] train: loss: 0.0275701
[Epoch 27; Iter   482/ 2483] train: loss: 0.0016144
[Epoch 27; Iter   512/ 2483] train: loss: 0.0008090
[Epoch 27; Iter   542/ 2483] train: loss: 0.0012778
[Epoch 27; Iter   572/ 2483] train: loss: 0.0018591
[Epoch 27; Iter   602/ 2483] train: loss: 0.0010269
[Epoch 27; Iter   632/ 2483] train: loss: 0.0015882
[Epoch 27; Iter   662/ 2483] train: loss: 0.0016628
[Epoch 27; Iter   692/ 2483] train: loss: 0.0014828
[Epoch 27; Iter   722/ 2483] train: loss: 0.0019069
[Epoch 27; Iter   752/ 2483] train: loss: 0.0022050
[Epoch 27; Iter   782/ 2483] train: loss: 0.0036235
[Epoch 27; Iter   812/ 2483] train: loss: 0.0013103
[Epoch 27; Iter   842/ 2483] train: loss: 0.0013470
[Epoch 27; Iter   872/ 2483] train: loss: 0.0030092
[Epoch 27; Iter   902/ 2483] train: loss: 0.0884725
[Epoch 27; Iter   932/ 2483] train: loss: 0.0019518
[Epoch 27; Iter   962/ 2483] train: loss: 0.0017000
[Epoch 27; Iter   992/ 2483] train: loss: 0.0012280
[Epoch 27; Iter  1022/ 2483] train: loss: 0.0308967
[Epoch 27; Iter  1052/ 2483] train: loss: 0.0016451
[Epoch 27; Iter  1082/ 2483] train: loss: 0.0020255
[Epoch 27; Iter  1112/ 2483] train: loss: 0.0010116
[Epoch 27; Iter  1142/ 2483] train: loss: 0.0818171
[Epoch 27; Iter  1172/ 2483] train: loss: 0.0012351
[Epoch 27; Iter  1202/ 2483] train: loss: 0.0012173
[Epoch 27; Iter  1232/ 2483] train: loss: 0.0014202
[Epoch 27; Iter  1262/ 2483] train: loss: 0.0012653
[Epoch 27; Iter  1292/ 2483] train: loss: 0.0009804
[Epoch 27; Iter  1322/ 2483] train: loss: 0.0018599
[Epoch 27; Iter  1352/ 2483] train: loss: 0.0016972
[Epoch 27; Iter  1382/ 2483] train: loss: 0.0014204
[Epoch 27; Iter  1412/ 2483] train: loss: 0.0015949
[Epoch 27; Iter  1442/ 2483] train: loss: 0.0545151
[Epoch 27; Iter  1472/ 2483] train: loss: 0.0010612
[Epoch 27; Iter  1502/ 2483] train: loss: 0.0017284
[Epoch 27; Iter  1532/ 2483] train: loss: 0.0011539
[Epoch 27; Iter  1562/ 2483] train: loss: 0.0018764
[Epoch 27; Iter  1592/ 2483] train: loss: 0.0015582
[Epoch 27; Iter  1622/ 2483] train: loss: 0.0060673
[Epoch 27; Iter  1652/ 2483] train: loss: 0.0013642
[Epoch 27; Iter  1682/ 2483] train: loss: 0.0008675
[Epoch 27; Iter  1712/ 2483] train: loss: 0.0019282
[Epoch 27; Iter  1742/ 2483] train: loss: 0.0009160
[Epoch 27; Iter  1772/ 2483] train: loss: 0.0013255
[Epoch 27; Iter  1802/ 2483] train: loss: 0.0667489
[Epoch 27; Iter  1832/ 2483] train: loss: 0.0021128
[Epoch 27; Iter  1862/ 2483] train: loss: 0.0019409
[Epoch 27; Iter  1892/ 2483] train: loss: 0.0015222
[Epoch 27; Iter  1922/ 2483] train: loss: 0.0013139
[Epoch 27; Iter  1952/ 2483] train: loss: 0.0016493
[Epoch 27; Iter  1982/ 2483] train: loss: 0.0014272
[Epoch 27; Iter  2012/ 2483] train: loss: 0.0014501
[Epoch 27; Iter  2042/ 2483] train: loss: 0.0011175
[Epoch 27; Iter  2072/ 2483] train: loss: 0.0023294
[Epoch 27; Iter  2102/ 2483] train: loss: 0.0014240
[Epoch 27; Iter  2132/ 2483] train: loss: 0.0017407
[Epoch 27; Iter  2162/ 2483] train: loss: 0.0012479
[Epoch 27; Iter  2192/ 2483] train: loss: 0.0686837
[Epoch 27; Iter  2222/ 2483] train: loss: 0.0012783
[Epoch 27; Iter  2252/ 2483] train: loss: 0.0017297
[Epoch 27; Iter  2282/ 2483] train: loss: 0.0019032
[Epoch 27; Iter  2312/ 2483] train: loss: 0.0780447
[Epoch 27; Iter  2342/ 2483] train: loss: 0.0508693
[Epoch 27; Iter  2372/ 2483] train: loss: 0.0015616
[Epoch 27; Iter  2402/ 2483] train: loss: 0.0035898
[Epoch 27; Iter  2432/ 2483] train: loss: 0.0016072
[Epoch 27; Iter  2462/ 2483] train: loss: 0.0022686
[Epoch 27] ogbg-molmuv: 0.114233 val loss: 0.009640
[Epoch 27] ogbg-molmuv: 0.172498 test loss: 0.013755
[Epoch 28; Iter     9/ 2483] train: loss: 0.0015228
[Epoch 28; Iter    39/ 2483] train: loss: 0.0014167
[Epoch 28; Iter    69/ 2483] train: loss: 0.0021572
[Epoch 28; Iter    99/ 2483] train: loss: 0.0014825
[Epoch 28; Iter   129/ 2483] train: loss: 0.0019351
[Epoch 28; Iter   159/ 2483] train: loss: 0.0010456
[Epoch 28; Iter   189/ 2483] train: loss: 0.0009219
[Epoch 28; Iter   219/ 2483] train: loss: 0.0011260
[Epoch 28; Iter   249/ 2483] train: loss: 0.0877309
[Epoch 28; Iter   279/ 2483] train: loss: 0.0016019
[Epoch 28; Iter   309/ 2483] train: loss: 0.0040120
[Epoch 28; Iter   339/ 2483] train: loss: 0.0012801
[Epoch 28; Iter   369/ 2483] train: loss: 0.0020327
[Epoch 28; Iter   399/ 2483] train: loss: 0.0020289
[Epoch 28; Iter   429/ 2483] train: loss: 0.0022657
[Epoch 28; Iter   459/ 2483] train: loss: 0.0013148
[Epoch 28; Iter   489/ 2483] train: loss: 0.0016767
[Epoch 28; Iter   519/ 2483] train: loss: 0.0023729
[Epoch 28; Iter   549/ 2483] train: loss: 0.0021899
[Epoch 28; Iter   579/ 2483] train: loss: 0.0017417
[Epoch 28; Iter   609/ 2483] train: loss: 0.0024017
[Epoch 28; Iter   639/ 2483] train: loss: 0.0040022
[Epoch 28; Iter   669/ 2483] train: loss: 0.0011557
[Epoch 28; Iter   699/ 2483] train: loss: 0.0012025
[Epoch 28; Iter   729/ 2483] train: loss: 0.0011464
[Epoch 28; Iter   759/ 2483] train: loss: 0.0011138
[Epoch 28; Iter   789/ 2483] train: loss: 0.0015836
[Epoch 28; Iter   819/ 2483] train: loss: 0.0013700
[Epoch 28; Iter   849/ 2483] train: loss: 0.0013282
[Epoch 28; Iter   879/ 2483] train: loss: 0.0062145
[Epoch 28; Iter   909/ 2483] train: loss: 0.0654008
[Epoch 26; Iter  1315/ 2483] train: loss: 0.0011835
[Epoch 26; Iter  1345/ 2483] train: loss: 0.0010095
[Epoch 26; Iter  1375/ 2483] train: loss: 0.0008923
[Epoch 26; Iter  1405/ 2483] train: loss: 0.0020313
[Epoch 26; Iter  1435/ 2483] train: loss: 0.0041087
[Epoch 26; Iter  1465/ 2483] train: loss: 0.0011621
[Epoch 26; Iter  1495/ 2483] train: loss: 0.0079462
[Epoch 26; Iter  1525/ 2483] train: loss: 0.0013831
[Epoch 26; Iter  1555/ 2483] train: loss: 0.0014071
[Epoch 26; Iter  1585/ 2483] train: loss: 0.0015926
[Epoch 26; Iter  1615/ 2483] train: loss: 0.0908352
[Epoch 26; Iter  1645/ 2483] train: loss: 0.1326556
[Epoch 26; Iter  1675/ 2483] train: loss: 0.0018770
[Epoch 26; Iter  1705/ 2483] train: loss: 0.0012972
[Epoch 26; Iter  1735/ 2483] train: loss: 0.0015710
[Epoch 26; Iter  1765/ 2483] train: loss: 0.0012446
[Epoch 26; Iter  1795/ 2483] train: loss: 0.0020955
[Epoch 26; Iter  1825/ 2483] train: loss: 0.0014354
[Epoch 26; Iter  1855/ 2483] train: loss: 0.0009582
[Epoch 26; Iter  1885/ 2483] train: loss: 0.0013061
[Epoch 26; Iter  1915/ 2483] train: loss: 0.0013054
[Epoch 26; Iter  1945/ 2483] train: loss: 0.0623103
[Epoch 26; Iter  1975/ 2483] train: loss: 0.0026731
[Epoch 26; Iter  2005/ 2483] train: loss: 0.0010896
[Epoch 26; Iter  2035/ 2483] train: loss: 0.0014074
[Epoch 26; Iter  2065/ 2483] train: loss: 0.0016462
[Epoch 26; Iter  2095/ 2483] train: loss: 0.0565824
[Epoch 26; Iter  2125/ 2483] train: loss: 0.0026928
[Epoch 26; Iter  2155/ 2483] train: loss: 0.0012488
[Epoch 26; Iter  2185/ 2483] train: loss: 0.0011383
[Epoch 26; Iter  2215/ 2483] train: loss: 0.0014917
[Epoch 26; Iter  2245/ 2483] train: loss: 0.0009719
[Epoch 26; Iter  2275/ 2483] train: loss: 0.0013770
[Epoch 26; Iter  2305/ 2483] train: loss: 0.0047948
[Epoch 26; Iter  2335/ 2483] train: loss: 0.0016345
[Epoch 26; Iter  2365/ 2483] train: loss: 0.0008246
[Epoch 26; Iter  2395/ 2483] train: loss: 0.0014331
[Epoch 26; Iter  2425/ 2483] train: loss: 0.0010955
[Epoch 26; Iter  2455/ 2483] train: loss: 0.0534987
[Epoch 26] ogbg-molmuv: 0.130913 val loss: 0.009362
[Epoch 26] ogbg-molmuv: 0.141687 test loss: 0.013578
[Epoch 27; Iter     2/ 2483] train: loss: 0.0018299
[Epoch 27; Iter    32/ 2483] train: loss: 0.0011084
[Epoch 27; Iter    62/ 2483] train: loss: 0.0018440
[Epoch 27; Iter    92/ 2483] train: loss: 0.1104122
[Epoch 27; Iter   122/ 2483] train: loss: 0.0009628
[Epoch 27; Iter   152/ 2483] train: loss: 0.0014576
[Epoch 27; Iter   182/ 2483] train: loss: 0.0016464
[Epoch 27; Iter   212/ 2483] train: loss: 0.0332340
[Epoch 27; Iter   242/ 2483] train: loss: 0.0026862
[Epoch 27; Iter   272/ 2483] train: loss: 0.0015299
[Epoch 27; Iter   302/ 2483] train: loss: 0.0615670
[Epoch 27; Iter   332/ 2483] train: loss: 0.0030380
[Epoch 27; Iter   362/ 2483] train: loss: 0.0021915
[Epoch 27; Iter   392/ 2483] train: loss: 0.0016480
[Epoch 27; Iter   422/ 2483] train: loss: 0.0008547
[Epoch 27; Iter   452/ 2483] train: loss: 0.0009567
[Epoch 27; Iter   482/ 2483] train: loss: 0.0017344
[Epoch 27; Iter   512/ 2483] train: loss: 0.0010358
[Epoch 27; Iter   542/ 2483] train: loss: 0.0008998
[Epoch 27; Iter   572/ 2483] train: loss: 0.1071845
[Epoch 27; Iter   602/ 2483] train: loss: 0.0010958
[Epoch 27; Iter   632/ 2483] train: loss: 0.0013018
[Epoch 27; Iter   662/ 2483] train: loss: 0.0012790
[Epoch 27; Iter   692/ 2483] train: loss: 0.0016950
[Epoch 27; Iter   722/ 2483] train: loss: 0.0013870
[Epoch 27; Iter   752/ 2483] train: loss: 0.0462758
[Epoch 27; Iter   782/ 2483] train: loss: 0.0014292
[Epoch 27; Iter   812/ 2483] train: loss: 0.0802036
[Epoch 27; Iter   842/ 2483] train: loss: 0.0117136
[Epoch 27; Iter   872/ 2483] train: loss: 0.0009384
[Epoch 27; Iter   902/ 2483] train: loss: 0.0013538
[Epoch 27; Iter   932/ 2483] train: loss: 0.0024911
[Epoch 27; Iter   962/ 2483] train: loss: 0.0019188
[Epoch 27; Iter   992/ 2483] train: loss: 0.0017006
[Epoch 27; Iter  1022/ 2483] train: loss: 0.0012667
[Epoch 27; Iter  1052/ 2483] train: loss: 0.0017491
[Epoch 27; Iter  1082/ 2483] train: loss: 0.0016250
[Epoch 27; Iter  1112/ 2483] train: loss: 0.0012682
[Epoch 27; Iter  1142/ 2483] train: loss: 0.0019000
[Epoch 27; Iter  1172/ 2483] train: loss: 0.0018902
[Epoch 27; Iter  1202/ 2483] train: loss: 0.0017836
[Epoch 27; Iter  1232/ 2483] train: loss: 0.0076925
[Epoch 27; Iter  1262/ 2483] train: loss: 0.0010153
[Epoch 27; Iter  1292/ 2483] train: loss: 0.0022558
[Epoch 27; Iter  1322/ 2483] train: loss: 0.0028462
[Epoch 27; Iter  1352/ 2483] train: loss: 0.0021185
[Epoch 27; Iter  1382/ 2483] train: loss: 0.0018116
[Epoch 27; Iter  1412/ 2483] train: loss: 0.0010603
[Epoch 27; Iter  1442/ 2483] train: loss: 0.0011963
[Epoch 27; Iter  1472/ 2483] train: loss: 0.0022621
[Epoch 27; Iter  1502/ 2483] train: loss: 0.0021074
[Epoch 27; Iter  1532/ 2483] train: loss: 0.0020899
[Epoch 27; Iter  1562/ 2483] train: loss: 0.0009752
[Epoch 27; Iter  1592/ 2483] train: loss: 0.0011148
[Epoch 27; Iter  1622/ 2483] train: loss: 0.0014102
[Epoch 27; Iter  1652/ 2483] train: loss: 0.0861384
[Epoch 27; Iter  1682/ 2483] train: loss: 0.0910998
[Epoch 27; Iter  1712/ 2483] train: loss: 0.0020988
[Epoch 27; Iter  1742/ 2483] train: loss: 0.0017112
[Epoch 27; Iter  1772/ 2483] train: loss: 0.0694865
[Epoch 27; Iter  1802/ 2483] train: loss: 0.0891012
[Epoch 27; Iter  1832/ 2483] train: loss: 0.0019340
[Epoch 27; Iter  1862/ 2483] train: loss: 0.0014268
[Epoch 27; Iter  1892/ 2483] train: loss: 0.0012952
[Epoch 27; Iter  1922/ 2483] train: loss: 0.0039551
[Epoch 27; Iter  1952/ 2483] train: loss: 0.0031766
[Epoch 27; Iter  1982/ 2483] train: loss: 0.0017110
[Epoch 27; Iter  2012/ 2483] train: loss: 0.0016245
[Epoch 27; Iter  2042/ 2483] train: loss: 0.0013822
[Epoch 27; Iter  2072/ 2483] train: loss: 0.0167195
[Epoch 27; Iter  2102/ 2483] train: loss: 0.0018163
[Epoch 27; Iter  2132/ 2483] train: loss: 0.0027149
[Epoch 27; Iter  2162/ 2483] train: loss: 0.0017433
[Epoch 27; Iter  2192/ 2483] train: loss: 0.0015099
[Epoch 27; Iter  2222/ 2483] train: loss: 0.0022575
[Epoch 27; Iter  2252/ 2483] train: loss: 0.0011900
[Epoch 27; Iter  2282/ 2483] train: loss: 0.0019237
[Epoch 27; Iter  2312/ 2483] train: loss: 0.0009419
[Epoch 27; Iter  2342/ 2483] train: loss: 0.0010532
[Epoch 27; Iter  2372/ 2483] train: loss: 0.0018186
[Epoch 27; Iter  2402/ 2483] train: loss: 0.0013314
[Epoch 27; Iter  2432/ 2483] train: loss: 0.0015595
[Epoch 27; Iter  2462/ 2483] train: loss: 0.0017145
[Epoch 27] ogbg-molmuv: 0.106409 val loss: 0.069760
[Epoch 27] ogbg-molmuv: 0.147343 test loss: 0.034924
[Epoch 28; Iter     9/ 2483] train: loss: 0.0015554
[Epoch 28; Iter    39/ 2483] train: loss: 0.0016308
[Epoch 28; Iter    69/ 2483] train: loss: 0.0022807
[Epoch 28; Iter    99/ 2483] train: loss: 0.0009307
[Epoch 28; Iter   129/ 2483] train: loss: 0.0320924
[Epoch 28; Iter   159/ 2483] train: loss: 0.0776057
[Epoch 28; Iter   189/ 2483] train: loss: 0.0030145
[Epoch 28; Iter   219/ 2483] train: loss: 0.0014379
[Epoch 28; Iter   249/ 2483] train: loss: 0.0734124
[Epoch 28; Iter   279/ 2483] train: loss: 0.0009827
[Epoch 28; Iter   309/ 2483] train: loss: 0.0020156
[Epoch 28; Iter   339/ 2483] train: loss: 0.0024069
[Epoch 28; Iter   369/ 2483] train: loss: 0.0874427
[Epoch 28; Iter   399/ 2483] train: loss: 0.0024049
[Epoch 28; Iter   429/ 2483] train: loss: 0.0012627
[Epoch 28; Iter   459/ 2483] train: loss: 0.0030718
[Epoch 28; Iter   489/ 2483] train: loss: 0.0771799
[Epoch 28; Iter   519/ 2483] train: loss: 0.0014970
[Epoch 28; Iter   549/ 2483] train: loss: 0.0722401
[Epoch 28; Iter   579/ 2483] train: loss: 0.0014264
[Epoch 28; Iter   609/ 2483] train: loss: 0.0634253
[Epoch 28; Iter   639/ 2483] train: loss: 0.0014524
[Epoch 28; Iter   669/ 2483] train: loss: 0.0018119
[Epoch 28; Iter   699/ 2483] train: loss: 0.0763289
[Epoch 28; Iter   729/ 2483] train: loss: 0.0015946
[Epoch 28; Iter   759/ 2483] train: loss: 0.0037684
[Epoch 28; Iter   789/ 2483] train: loss: 0.0591509
[Epoch 28; Iter   819/ 2483] train: loss: 0.0043864
[Epoch 28; Iter   849/ 2483] train: loss: 0.0018399
[Epoch 28; Iter   879/ 2483] train: loss: 0.0022005
[Epoch 28; Iter   909/ 2483] train: loss: 0.0831123
[Epoch 27; Iter  2118/ 2172] train: loss: 0.0013606
[Epoch 27; Iter  2148/ 2172] train: loss: 0.0020772
[Epoch 27] ogbg-molmuv: 0.074218 val loss: 0.026316
[Epoch 27] ogbg-molmuv: 0.110988 test loss: 0.043876
[Epoch 28; Iter     6/ 2172] train: loss: 0.0020454
[Epoch 28; Iter    36/ 2172] train: loss: 0.0013898
[Epoch 28; Iter    66/ 2172] train: loss: 0.0018725
[Epoch 28; Iter    96/ 2172] train: loss: 0.0014330
[Epoch 28; Iter   126/ 2172] train: loss: 0.0016360
[Epoch 28; Iter   156/ 2172] train: loss: 0.0649659
[Epoch 28; Iter   186/ 2172] train: loss: 0.0393066
[Epoch 28; Iter   216/ 2172] train: loss: 0.0010998
[Epoch 28; Iter   246/ 2172] train: loss: 0.0017653
[Epoch 28; Iter   276/ 2172] train: loss: 0.0012717
[Epoch 28; Iter   306/ 2172] train: loss: 0.0014953
[Epoch 28; Iter   336/ 2172] train: loss: 0.0028100
[Epoch 28; Iter   366/ 2172] train: loss: 0.0022986
[Epoch 28; Iter   396/ 2172] train: loss: 0.0019917
[Epoch 28; Iter   426/ 2172] train: loss: 0.0012465
[Epoch 28; Iter   456/ 2172] train: loss: 0.0016824
[Epoch 28; Iter   486/ 2172] train: loss: 0.0006448
[Epoch 28; Iter   516/ 2172] train: loss: 0.0009977
[Epoch 28; Iter   546/ 2172] train: loss: 0.0613185
[Epoch 28; Iter   576/ 2172] train: loss: 0.0016938
[Epoch 28; Iter   606/ 2172] train: loss: 0.0013795
[Epoch 28; Iter   636/ 2172] train: loss: 0.0612206
[Epoch 28; Iter   666/ 2172] train: loss: 0.0028333
[Epoch 28; Iter   696/ 2172] train: loss: 0.0019288
[Epoch 28; Iter   726/ 2172] train: loss: 0.0016420
[Epoch 28; Iter   756/ 2172] train: loss: 0.0037424
[Epoch 28; Iter   786/ 2172] train: loss: 0.0011698
[Epoch 28; Iter   816/ 2172] train: loss: 0.0010934
[Epoch 28; Iter   846/ 2172] train: loss: 0.0018174
[Epoch 28; Iter   876/ 2172] train: loss: 0.0019288
[Epoch 28; Iter   906/ 2172] train: loss: 0.0741693
[Epoch 28; Iter   936/ 2172] train: loss: 0.0025884
[Epoch 28; Iter   966/ 2172] train: loss: 0.0024361
[Epoch 28; Iter   996/ 2172] train: loss: 0.0013249
[Epoch 28; Iter  1026/ 2172] train: loss: 0.0012368
[Epoch 28; Iter  1056/ 2172] train: loss: 0.0009028
[Epoch 28; Iter  1086/ 2172] train: loss: 0.0784427
[Epoch 28; Iter  1116/ 2172] train: loss: 0.0014798
[Epoch 28; Iter  1146/ 2172] train: loss: 0.0015904
[Epoch 28; Iter  1176/ 2172] train: loss: 0.0009478
[Epoch 28; Iter  1206/ 2172] train: loss: 0.0008661
[Epoch 28; Iter  1236/ 2172] train: loss: 0.0009135
[Epoch 28; Iter  1266/ 2172] train: loss: 0.0013575
[Epoch 28; Iter  1296/ 2172] train: loss: 0.0049853
[Epoch 28; Iter  1326/ 2172] train: loss: 0.0020960
[Epoch 28; Iter  1356/ 2172] train: loss: 0.0012294
[Epoch 28; Iter  1386/ 2172] train: loss: 0.0012577
[Epoch 28; Iter  1416/ 2172] train: loss: 0.0009284
[Epoch 28; Iter  1446/ 2172] train: loss: 0.0049555
[Epoch 28; Iter  1476/ 2172] train: loss: 0.0026757
[Epoch 28; Iter  1506/ 2172] train: loss: 0.0014701
[Epoch 28; Iter  1536/ 2172] train: loss: 0.0012452
[Epoch 28; Iter  1566/ 2172] train: loss: 0.0314061
[Epoch 28; Iter  1596/ 2172] train: loss: 0.0018798
[Epoch 28; Iter  1626/ 2172] train: loss: 0.0020549
[Epoch 28; Iter  1656/ 2172] train: loss: 0.0366391
[Epoch 28; Iter  1686/ 2172] train: loss: 0.1587067
[Epoch 28; Iter  1716/ 2172] train: loss: 0.0030797
[Epoch 28; Iter  1746/ 2172] train: loss: 0.0017745
[Epoch 28; Iter  1776/ 2172] train: loss: 0.0005692
[Epoch 28; Iter  1806/ 2172] train: loss: 0.0015165
[Epoch 28; Iter  1836/ 2172] train: loss: 0.0014235
[Epoch 28; Iter  1866/ 2172] train: loss: 0.0018340
[Epoch 28; Iter  1896/ 2172] train: loss: 0.0015700
[Epoch 28; Iter  1926/ 2172] train: loss: 0.0007187
[Epoch 28; Iter  1956/ 2172] train: loss: 0.0009534
[Epoch 28; Iter  1986/ 2172] train: loss: 0.0551441
[Epoch 28; Iter  2016/ 2172] train: loss: 0.0013755
[Epoch 28; Iter  2046/ 2172] train: loss: 0.0047486
[Epoch 28; Iter  2076/ 2172] train: loss: 0.0012437
[Epoch 28; Iter  2106/ 2172] train: loss: 0.0068111
[Epoch 28; Iter  2136/ 2172] train: loss: 0.0012842
[Epoch 28; Iter  2166/ 2172] train: loss: 0.0010330
[Epoch 28] ogbg-molmuv: 0.088649 val loss: 0.011772
[Epoch 28] ogbg-molmuv: 0.130759 test loss: 0.012941
[Epoch 29; Iter    24/ 2172] train: loss: 0.0012072
[Epoch 29; Iter    54/ 2172] train: loss: 0.0027111
[Epoch 29; Iter    84/ 2172] train: loss: 0.0009862
[Epoch 29; Iter   114/ 2172] train: loss: 0.0014896
[Epoch 29; Iter   144/ 2172] train: loss: 0.0030866
[Epoch 29; Iter   174/ 2172] train: loss: 0.0015950
[Epoch 29; Iter   204/ 2172] train: loss: 0.0020590
[Epoch 29; Iter   234/ 2172] train: loss: 0.0013087
[Epoch 29; Iter   264/ 2172] train: loss: 0.0803386
[Epoch 29; Iter   294/ 2172] train: loss: 0.0008462
[Epoch 29; Iter   324/ 2172] train: loss: 0.0015118
[Epoch 29; Iter   354/ 2172] train: loss: 0.0012467
[Epoch 29; Iter   384/ 2172] train: loss: 0.0013112
[Epoch 29; Iter   414/ 2172] train: loss: 0.0007300
[Epoch 29; Iter   444/ 2172] train: loss: 0.0020987
[Epoch 29; Iter   474/ 2172] train: loss: 0.0010891
[Epoch 29; Iter   504/ 2172] train: loss: 0.0726091
[Epoch 29; Iter   534/ 2172] train: loss: 0.0022818
[Epoch 29; Iter   564/ 2172] train: loss: 0.0021314
[Epoch 29; Iter   594/ 2172] train: loss: 0.0015110
[Epoch 29; Iter   624/ 2172] train: loss: 0.0009827
[Epoch 29; Iter   654/ 2172] train: loss: 0.0015160
[Epoch 29; Iter   684/ 2172] train: loss: 0.0027562
[Epoch 29; Iter   714/ 2172] train: loss: 0.0013014
[Epoch 29; Iter   744/ 2172] train: loss: 0.0011175
[Epoch 29; Iter   774/ 2172] train: loss: 0.0044135
[Epoch 29; Iter   804/ 2172] train: loss: 0.0008408
[Epoch 29; Iter   834/ 2172] train: loss: 0.0019681
[Epoch 29; Iter   864/ 2172] train: loss: 0.0016190
[Epoch 29; Iter   894/ 2172] train: loss: 0.0011869
[Epoch 29; Iter   924/ 2172] train: loss: 0.0397632
[Epoch 29; Iter   954/ 2172] train: loss: 0.0008769
[Epoch 29; Iter   984/ 2172] train: loss: 0.0013345
[Epoch 29; Iter  1014/ 2172] train: loss: 0.0017797
[Epoch 29; Iter  1044/ 2172] train: loss: 0.0015757
[Epoch 29; Iter  1074/ 2172] train: loss: 0.0009093
[Epoch 29; Iter  1104/ 2172] train: loss: 0.0054665
[Epoch 29; Iter  1134/ 2172] train: loss: 0.0014665
[Epoch 29; Iter  1164/ 2172] train: loss: 0.0021260
[Epoch 29; Iter  1194/ 2172] train: loss: 0.0007185
[Epoch 29; Iter  1224/ 2172] train: loss: 0.0016234
[Epoch 29; Iter  1254/ 2172] train: loss: 0.0006599
[Epoch 29; Iter  1284/ 2172] train: loss: 0.0009669
[Epoch 29; Iter  1314/ 2172] train: loss: 0.0010468
[Epoch 29; Iter  1344/ 2172] train: loss: 0.0008805
[Epoch 29; Iter  1374/ 2172] train: loss: 0.0741977
[Epoch 29; Iter  1404/ 2172] train: loss: 0.0018763
[Epoch 29; Iter  1434/ 2172] train: loss: 0.0011844
[Epoch 29; Iter  1464/ 2172] train: loss: 0.0009081
[Epoch 29; Iter  1494/ 2172] train: loss: 0.0029984
[Epoch 29; Iter  1524/ 2172] train: loss: 0.0019403
[Epoch 29; Iter  1554/ 2172] train: loss: 0.0020665
[Epoch 29; Iter  1584/ 2172] train: loss: 0.0018626
[Epoch 29; Iter  1614/ 2172] train: loss: 0.0015372
[Epoch 29; Iter  1644/ 2172] train: loss: 0.0049072
[Epoch 29; Iter  1674/ 2172] train: loss: 0.0013036
[Epoch 29; Iter  1704/ 2172] train: loss: 0.0011596
[Epoch 29; Iter  1734/ 2172] train: loss: 0.0009135
[Epoch 29; Iter  1764/ 2172] train: loss: 0.0010947
[Epoch 29; Iter  1794/ 2172] train: loss: 0.0101852
[Epoch 29; Iter  1824/ 2172] train: loss: 0.0016296
[Epoch 29; Iter  1854/ 2172] train: loss: 0.0008293
[Epoch 29; Iter  1884/ 2172] train: loss: 0.0014474
[Epoch 29; Iter  1914/ 2172] train: loss: 0.0015355
[Epoch 29; Iter  1944/ 2172] train: loss: 0.0826354
[Epoch 29; Iter  1974/ 2172] train: loss: 0.0011682
[Epoch 29; Iter  2004/ 2172] train: loss: 0.0018978
[Epoch 29; Iter  2034/ 2172] train: loss: 0.0017355
[Epoch 29; Iter  2064/ 2172] train: loss: 0.0019338
[Epoch 29; Iter  2094/ 2172] train: loss: 0.0029026
[Epoch 29; Iter  2124/ 2172] train: loss: 0.0011013
[Epoch 29; Iter  2154/ 2172] train: loss: 0.0013549
[Epoch 29] ogbg-molmuv: 0.083434 val loss: 0.011572
[Epoch 29] ogbg-molmuv: 0.142888 test loss: 0.013184
[Epoch 30; Iter    12/ 2172] train: loss: 0.0014598
[Epoch 30; Iter    42/ 2172] train: loss: 0.0013220
[Epoch 30; Iter    72/ 2172] train: loss: 0.0024656
[Epoch 30; Iter   102/ 2172] train: loss: 0.0015396
[Epoch 27; Iter  2118/ 2172] train: loss: 0.0022159
[Epoch 27; Iter  2148/ 2172] train: loss: 0.0017815
[Epoch 27] ogbg-molmuv: 0.071705 val loss: 0.012409
[Epoch 27] ogbg-molmuv: 0.134633 test loss: 0.017691
[Epoch 28; Iter     6/ 2172] train: loss: 0.0008208
[Epoch 28; Iter    36/ 2172] train: loss: 0.0042910
[Epoch 28; Iter    66/ 2172] train: loss: 0.0401288
[Epoch 28; Iter    96/ 2172] train: loss: 0.0889822
[Epoch 28; Iter   126/ 2172] train: loss: 0.0012311
[Epoch 28; Iter   156/ 2172] train: loss: 0.0669179
[Epoch 28; Iter   186/ 2172] train: loss: 0.0063334
[Epoch 28; Iter   216/ 2172] train: loss: 0.0072550
[Epoch 28; Iter   246/ 2172] train: loss: 0.0015493
[Epoch 28; Iter   276/ 2172] train: loss: 0.0622461
[Epoch 28; Iter   306/ 2172] train: loss: 0.0006111
[Epoch 28; Iter   336/ 2172] train: loss: 0.0012284
[Epoch 28; Iter   366/ 2172] train: loss: 0.0009598
[Epoch 28; Iter   396/ 2172] train: loss: 0.0017942
[Epoch 28; Iter   426/ 2172] train: loss: 0.0024156
[Epoch 28; Iter   456/ 2172] train: loss: 0.0018485
[Epoch 28; Iter   486/ 2172] train: loss: 0.0012036
[Epoch 28; Iter   516/ 2172] train: loss: 0.0015666
[Epoch 28; Iter   546/ 2172] train: loss: 0.0008982
[Epoch 28; Iter   576/ 2172] train: loss: 0.0018343
[Epoch 28; Iter   606/ 2172] train: loss: 0.0007888
[Epoch 28; Iter   636/ 2172] train: loss: 0.0015645
[Epoch 28; Iter   666/ 2172] train: loss: 0.0021954
[Epoch 28; Iter   696/ 2172] train: loss: 0.0010477
[Epoch 28; Iter   726/ 2172] train: loss: 0.0313631
[Epoch 28; Iter   756/ 2172] train: loss: 0.0022743
[Epoch 28; Iter   786/ 2172] train: loss: 0.0010748
[Epoch 28; Iter   816/ 2172] train: loss: 0.0678335
[Epoch 28; Iter   846/ 2172] train: loss: 0.0018912
[Epoch 28; Iter   876/ 2172] train: loss: 0.0012383
[Epoch 28; Iter   906/ 2172] train: loss: 0.0431787
[Epoch 28; Iter   936/ 2172] train: loss: 0.0020190
[Epoch 28; Iter   966/ 2172] train: loss: 0.0036084
[Epoch 28; Iter   996/ 2172] train: loss: 0.0017194
[Epoch 28; Iter  1026/ 2172] train: loss: 0.0022540
[Epoch 28; Iter  1056/ 2172] train: loss: 0.0009313
[Epoch 28; Iter  1086/ 2172] train: loss: 0.0009349
[Epoch 28; Iter  1116/ 2172] train: loss: 0.0013178
[Epoch 28; Iter  1146/ 2172] train: loss: 0.0015645
[Epoch 28; Iter  1176/ 2172] train: loss: 0.0020954
[Epoch 28; Iter  1206/ 2172] train: loss: 0.0009961
[Epoch 28; Iter  1236/ 2172] train: loss: 0.0657082
[Epoch 28; Iter  1266/ 2172] train: loss: 0.0015536
[Epoch 28; Iter  1296/ 2172] train: loss: 0.0009930
[Epoch 28; Iter  1326/ 2172] train: loss: 0.0008989
[Epoch 28; Iter  1356/ 2172] train: loss: 0.0016999
[Epoch 28; Iter  1386/ 2172] train: loss: 0.0011681
[Epoch 28; Iter  1416/ 2172] train: loss: 0.0047798
[Epoch 28; Iter  1446/ 2172] train: loss: 0.0012938
[Epoch 28; Iter  1476/ 2172] train: loss: 0.0841292
[Epoch 28; Iter  1506/ 2172] train: loss: 0.0011133
[Epoch 28; Iter  1536/ 2172] train: loss: 0.0018720
[Epoch 28; Iter  1566/ 2172] train: loss: 0.0016065
[Epoch 28; Iter  1596/ 2172] train: loss: 0.0012225
[Epoch 28; Iter  1626/ 2172] train: loss: 0.0017942
[Epoch 28; Iter  1656/ 2172] train: loss: 0.1069247
[Epoch 28; Iter  1686/ 2172] train: loss: 0.0014086
[Epoch 28; Iter  1716/ 2172] train: loss: 0.0941158
[Epoch 28; Iter  1746/ 2172] train: loss: 0.0008393
[Epoch 28; Iter  1776/ 2172] train: loss: 0.0018202
[Epoch 28; Iter  1806/ 2172] train: loss: 0.0021244
[Epoch 28; Iter  1836/ 2172] train: loss: 0.0013208
[Epoch 28; Iter  1866/ 2172] train: loss: 0.0020073
[Epoch 28; Iter  1896/ 2172] train: loss: 0.0051810
[Epoch 28; Iter  1926/ 2172] train: loss: 0.0020925
[Epoch 28; Iter  1956/ 2172] train: loss: 0.0644810
[Epoch 28; Iter  1986/ 2172] train: loss: 0.0010400
[Epoch 28; Iter  2016/ 2172] train: loss: 0.0688048
[Epoch 28; Iter  2046/ 2172] train: loss: 0.0517154
[Epoch 28; Iter  2076/ 2172] train: loss: 0.0014664
[Epoch 28; Iter  2106/ 2172] train: loss: 0.0022284
[Epoch 28; Iter  2136/ 2172] train: loss: 0.0016227
[Epoch 28; Iter  2166/ 2172] train: loss: 0.0020339
[Epoch 28] ogbg-molmuv: 0.071314 val loss: 0.012308
[Epoch 28] ogbg-molmuv: 0.136072 test loss: 0.019630
[Epoch 29; Iter    24/ 2172] train: loss: 0.0017321
[Epoch 29; Iter    54/ 2172] train: loss: 0.0810349
[Epoch 29; Iter    84/ 2172] train: loss: 0.0012037
[Epoch 29; Iter   114/ 2172] train: loss: 0.0009272
[Epoch 29; Iter   144/ 2172] train: loss: 0.0025718
[Epoch 29; Iter   174/ 2172] train: loss: 0.0013120
[Epoch 29; Iter   204/ 2172] train: loss: 0.0771498
[Epoch 29; Iter   234/ 2172] train: loss: 0.0009428
[Epoch 29; Iter   264/ 2172] train: loss: 0.0030760
[Epoch 29; Iter   294/ 2172] train: loss: 0.0018916
[Epoch 29; Iter   324/ 2172] train: loss: 0.0077132
[Epoch 29; Iter   354/ 2172] train: loss: 0.0010158
[Epoch 29; Iter   384/ 2172] train: loss: 0.0475548
[Epoch 29; Iter   414/ 2172] train: loss: 0.0010356
[Epoch 29; Iter   444/ 2172] train: loss: 0.0012243
[Epoch 29; Iter   474/ 2172] train: loss: 0.0755754
[Epoch 29; Iter   504/ 2172] train: loss: 0.0030545
[Epoch 29; Iter   534/ 2172] train: loss: 0.0017527
[Epoch 29; Iter   564/ 2172] train: loss: 0.0087833
[Epoch 29; Iter   594/ 2172] train: loss: 0.0015447
[Epoch 29; Iter   624/ 2172] train: loss: 0.0016317
[Epoch 29; Iter   654/ 2172] train: loss: 0.0015256
[Epoch 29; Iter   684/ 2172] train: loss: 0.0017620
[Epoch 29; Iter   714/ 2172] train: loss: 0.1488461
[Epoch 29; Iter   744/ 2172] train: loss: 0.0016447
[Epoch 29; Iter   774/ 2172] train: loss: 0.0023148
[Epoch 29; Iter   804/ 2172] train: loss: 0.0050472
[Epoch 29; Iter   834/ 2172] train: loss: 0.0011301
[Epoch 29; Iter   864/ 2172] train: loss: 0.0013702
[Epoch 29; Iter   894/ 2172] train: loss: 0.0012600
[Epoch 29; Iter   924/ 2172] train: loss: 0.0831806
[Epoch 29; Iter   954/ 2172] train: loss: 0.0011050
[Epoch 29; Iter   984/ 2172] train: loss: 0.0010907
[Epoch 29; Iter  1014/ 2172] train: loss: 0.0012810
[Epoch 29; Iter  1044/ 2172] train: loss: 0.0016020
[Epoch 29; Iter  1074/ 2172] train: loss: 0.0012151
[Epoch 29; Iter  1104/ 2172] train: loss: 0.0013613
[Epoch 29; Iter  1134/ 2172] train: loss: 0.0050668
[Epoch 29; Iter  1164/ 2172] train: loss: 0.0017228
[Epoch 29; Iter  1194/ 2172] train: loss: 0.0013919
[Epoch 29; Iter  1224/ 2172] train: loss: 0.0433879
[Epoch 29; Iter  1254/ 2172] train: loss: 0.0014683
[Epoch 29; Iter  1284/ 2172] train: loss: 0.0017795
[Epoch 29; Iter  1314/ 2172] train: loss: 0.0006888
[Epoch 29; Iter  1344/ 2172] train: loss: 0.0025514
[Epoch 29; Iter  1374/ 2172] train: loss: 0.0027739
[Epoch 29; Iter  1404/ 2172] train: loss: 0.0016782
[Epoch 29; Iter  1434/ 2172] train: loss: 0.0013038
[Epoch 29; Iter  1464/ 2172] train: loss: 0.0012711
[Epoch 29; Iter  1494/ 2172] train: loss: 0.0013529
[Epoch 29; Iter  1524/ 2172] train: loss: 0.0020076
[Epoch 29; Iter  1554/ 2172] train: loss: 0.0018956
[Epoch 29; Iter  1584/ 2172] train: loss: 0.0016386
[Epoch 29; Iter  1614/ 2172] train: loss: 0.0009568
[Epoch 29; Iter  1644/ 2172] train: loss: 0.0013312
[Epoch 29; Iter  1674/ 2172] train: loss: 0.0677318
[Epoch 29; Iter  1704/ 2172] train: loss: 0.0014082
[Epoch 29; Iter  1734/ 2172] train: loss: 0.0006994
[Epoch 29; Iter  1764/ 2172] train: loss: 0.0011715
[Epoch 29; Iter  1794/ 2172] train: loss: 0.0020573
[Epoch 29; Iter  1824/ 2172] train: loss: 0.0612176
[Epoch 29; Iter  1854/ 2172] train: loss: 0.0403912
[Epoch 29; Iter  1884/ 2172] train: loss: 0.0027893
[Epoch 29; Iter  1914/ 2172] train: loss: 0.0040411
[Epoch 29; Iter  1944/ 2172] train: loss: 0.0064367
[Epoch 29; Iter  1974/ 2172] train: loss: 0.0030107
[Epoch 29; Iter  2004/ 2172] train: loss: 0.0012276
[Epoch 29; Iter  2034/ 2172] train: loss: 0.0028733
[Epoch 29; Iter  2064/ 2172] train: loss: 0.0013151
[Epoch 29; Iter  2094/ 2172] train: loss: 0.0010479
[Epoch 29; Iter  2124/ 2172] train: loss: 0.0013539
[Epoch 29; Iter  2154/ 2172] train: loss: 0.0010099
[Epoch 29] ogbg-molmuv: 0.055691 val loss: 0.012045
[Epoch 29] ogbg-molmuv: 0.113480 test loss: 0.020502
[Epoch 30; Iter    12/ 2172] train: loss: 0.0008476
[Epoch 30; Iter    42/ 2172] train: loss: 0.0794877
[Epoch 30; Iter    72/ 2172] train: loss: 0.0008530
[Epoch 30; Iter   102/ 2172] train: loss: 0.0013805
[Epoch 27; Iter  2118/ 2172] train: loss: 0.0015900
[Epoch 27; Iter  2148/ 2172] train: loss: 0.0029738
[Epoch 27] ogbg-molmuv: 0.038244 val loss: 0.105094
[Epoch 27] ogbg-molmuv: 0.067786 test loss: 0.033503
[Epoch 28; Iter     6/ 2172] train: loss: 0.0018369
[Epoch 28; Iter    36/ 2172] train: loss: 0.0021459
[Epoch 28; Iter    66/ 2172] train: loss: 0.0582595
[Epoch 28; Iter    96/ 2172] train: loss: 0.0017063
[Epoch 28; Iter   126/ 2172] train: loss: 0.0013453
[Epoch 28; Iter   156/ 2172] train: loss: 0.0011591
[Epoch 28; Iter   186/ 2172] train: loss: 0.0016504
[Epoch 28; Iter   216/ 2172] train: loss: 0.0014204
[Epoch 28; Iter   246/ 2172] train: loss: 0.0013646
[Epoch 28; Iter   276/ 2172] train: loss: 0.0022936
[Epoch 28; Iter   306/ 2172] train: loss: 0.0065694
[Epoch 28; Iter   336/ 2172] train: loss: 0.0014757
[Epoch 28; Iter   366/ 2172] train: loss: 0.0013706
[Epoch 28; Iter   396/ 2172] train: loss: 0.0017095
[Epoch 28; Iter   426/ 2172] train: loss: 0.0008892
[Epoch 28; Iter   456/ 2172] train: loss: 0.0009510
[Epoch 28; Iter   486/ 2172] train: loss: 0.0012157
[Epoch 28; Iter   516/ 2172] train: loss: 0.0020790
[Epoch 28; Iter   546/ 2172] train: loss: 0.0013517
[Epoch 28; Iter   576/ 2172] train: loss: 0.0011743
[Epoch 28; Iter   606/ 2172] train: loss: 0.0014936
[Epoch 28; Iter   636/ 2172] train: loss: 0.0018438
[Epoch 28; Iter   666/ 2172] train: loss: 0.0623536
[Epoch 28; Iter   696/ 2172] train: loss: 0.0013143
[Epoch 28; Iter   726/ 2172] train: loss: 0.0024588
[Epoch 28; Iter   756/ 2172] train: loss: 0.0012128
[Epoch 28; Iter   786/ 2172] train: loss: 0.0019100
[Epoch 28; Iter   816/ 2172] train: loss: 0.0018803
[Epoch 28; Iter   846/ 2172] train: loss: 0.0013444
[Epoch 28; Iter   876/ 2172] train: loss: 0.0566098
[Epoch 28; Iter   906/ 2172] train: loss: 0.0015786
[Epoch 28; Iter   936/ 2172] train: loss: 0.0008152
[Epoch 28; Iter   966/ 2172] train: loss: 0.0018050
[Epoch 28; Iter   996/ 2172] train: loss: 0.0012965
[Epoch 28; Iter  1026/ 2172] train: loss: 0.0019126
[Epoch 28; Iter  1056/ 2172] train: loss: 0.0012163
[Epoch 28; Iter  1086/ 2172] train: loss: 0.0021183
[Epoch 28; Iter  1116/ 2172] train: loss: 0.0029835
[Epoch 28; Iter  1146/ 2172] train: loss: 0.0019710
[Epoch 28; Iter  1176/ 2172] train: loss: 0.0012264
[Epoch 28; Iter  1206/ 2172] train: loss: 0.0029351
[Epoch 28; Iter  1236/ 2172] train: loss: 0.0176415
[Epoch 28; Iter  1266/ 2172] train: loss: 0.0011088
[Epoch 28; Iter  1296/ 2172] train: loss: 0.0637125
[Epoch 28; Iter  1326/ 2172] train: loss: 0.0614363
[Epoch 28; Iter  1356/ 2172] train: loss: 0.0472539
[Epoch 28; Iter  1386/ 2172] train: loss: 0.0014228
[Epoch 28; Iter  1416/ 2172] train: loss: 0.0019055
[Epoch 28; Iter  1446/ 2172] train: loss: 0.0011507
[Epoch 28; Iter  1476/ 2172] train: loss: 0.0014779
[Epoch 28; Iter  1506/ 2172] train: loss: 0.0783401
[Epoch 28; Iter  1536/ 2172] train: loss: 0.0725106
[Epoch 28; Iter  1566/ 2172] train: loss: 0.0015847
[Epoch 28; Iter  1596/ 2172] train: loss: 0.0014401
[Epoch 28; Iter  1626/ 2172] train: loss: 0.0020243
[Epoch 28; Iter  1656/ 2172] train: loss: 0.0013106
[Epoch 28; Iter  1686/ 2172] train: loss: 0.0014593
[Epoch 28; Iter  1716/ 2172] train: loss: 0.0022819
[Epoch 28; Iter  1746/ 2172] train: loss: 0.0051297
[Epoch 28; Iter  1776/ 2172] train: loss: 0.0018601
[Epoch 28; Iter  1806/ 2172] train: loss: 0.0010475
[Epoch 28; Iter  1836/ 2172] train: loss: 0.0013747
[Epoch 28; Iter  1866/ 2172] train: loss: 0.0814628
[Epoch 28; Iter  1896/ 2172] train: loss: 0.0020524
[Epoch 28; Iter  1926/ 2172] train: loss: 0.0020944
[Epoch 28; Iter  1956/ 2172] train: loss: 0.0025496
[Epoch 28; Iter  1986/ 2172] train: loss: 0.0017152
[Epoch 28; Iter  2016/ 2172] train: loss: 0.0016401
[Epoch 28; Iter  2046/ 2172] train: loss: 0.0017452
[Epoch 28; Iter  2076/ 2172] train: loss: 0.0034209
[Epoch 28; Iter  2106/ 2172] train: loss: 0.0019080
[Epoch 28; Iter  2136/ 2172] train: loss: 0.0018397
[Epoch 28; Iter  2166/ 2172] train: loss: 0.0018365
[Epoch 28] ogbg-molmuv: 0.041743 val loss: 0.218841
[Epoch 28] ogbg-molmuv: 0.062085 test loss: 0.299625
[Epoch 29; Iter    24/ 2172] train: loss: 0.0010178
[Epoch 29; Iter    54/ 2172] train: loss: 0.0011436
[Epoch 29; Iter    84/ 2172] train: loss: 0.0076154
[Epoch 29; Iter   114/ 2172] train: loss: 0.0008489
[Epoch 29; Iter   144/ 2172] train: loss: 0.0016561
[Epoch 29; Iter   174/ 2172] train: loss: 0.0669419
[Epoch 29; Iter   204/ 2172] train: loss: 0.0013240
[Epoch 29; Iter   234/ 2172] train: loss: 0.0020283
[Epoch 29; Iter   264/ 2172] train: loss: 0.0016327
[Epoch 29; Iter   294/ 2172] train: loss: 0.0011004
[Epoch 29; Iter   324/ 2172] train: loss: 0.0011607
[Epoch 29; Iter   354/ 2172] train: loss: 0.0019017
[Epoch 29; Iter   384/ 2172] train: loss: 0.0018492
[Epoch 29; Iter   414/ 2172] train: loss: 0.0011662
[Epoch 29; Iter   444/ 2172] train: loss: 0.0014813
[Epoch 29; Iter   474/ 2172] train: loss: 0.0018160
[Epoch 29; Iter   504/ 2172] train: loss: 0.0015930
[Epoch 29; Iter   534/ 2172] train: loss: 0.0013561
[Epoch 29; Iter   564/ 2172] train: loss: 0.0010662
[Epoch 29; Iter   594/ 2172] train: loss: 0.0016148
[Epoch 29; Iter   624/ 2172] train: loss: 0.0022108
[Epoch 29; Iter   654/ 2172] train: loss: 0.0008166
[Epoch 29; Iter   684/ 2172] train: loss: 0.0010075
[Epoch 29; Iter   714/ 2172] train: loss: 0.0012598
[Epoch 29; Iter   744/ 2172] train: loss: 0.0848449
[Epoch 29; Iter   774/ 2172] train: loss: 0.0603068
[Epoch 29; Iter   804/ 2172] train: loss: 0.0011967
[Epoch 29; Iter   834/ 2172] train: loss: 0.0709615
[Epoch 29; Iter   864/ 2172] train: loss: 0.0013294
[Epoch 29; Iter   894/ 2172] train: loss: 0.0047278
[Epoch 29; Iter   924/ 2172] train: loss: 0.0015768
[Epoch 29; Iter   954/ 2172] train: loss: 0.0010030
[Epoch 29; Iter   984/ 2172] train: loss: 0.0027820
[Epoch 29; Iter  1014/ 2172] train: loss: 0.0009934
[Epoch 29; Iter  1044/ 2172] train: loss: 0.0022566
[Epoch 29; Iter  1074/ 2172] train: loss: 0.0025644
[Epoch 29; Iter  1104/ 2172] train: loss: 0.0029785
[Epoch 29; Iter  1134/ 2172] train: loss: 0.0008594
[Epoch 29; Iter  1164/ 2172] train: loss: 0.0032060
[Epoch 29; Iter  1194/ 2172] train: loss: 0.0009840
[Epoch 29; Iter  1224/ 2172] train: loss: 0.0015699
[Epoch 29; Iter  1254/ 2172] train: loss: 0.0022082
[Epoch 29; Iter  1284/ 2172] train: loss: 0.0370647
[Epoch 29; Iter  1314/ 2172] train: loss: 0.0013483
[Epoch 29; Iter  1344/ 2172] train: loss: 0.0022996
[Epoch 29; Iter  1374/ 2172] train: loss: 0.0025525
[Epoch 29; Iter  1404/ 2172] train: loss: 0.0016435
[Epoch 29; Iter  1434/ 2172] train: loss: 0.0019970
[Epoch 29; Iter  1464/ 2172] train: loss: 0.0012314
[Epoch 29; Iter  1494/ 2172] train: loss: 0.0734377
[Epoch 29; Iter  1524/ 2172] train: loss: 0.0032495
[Epoch 29; Iter  1554/ 2172] train: loss: 0.0024307
[Epoch 29; Iter  1584/ 2172] train: loss: 0.0018055
[Epoch 29; Iter  1614/ 2172] train: loss: 0.0012970
[Epoch 29; Iter  1644/ 2172] train: loss: 0.0014663
[Epoch 29; Iter  1674/ 2172] train: loss: 0.0029241
[Epoch 29; Iter  1704/ 2172] train: loss: 0.0018435
[Epoch 29; Iter  1734/ 2172] train: loss: 0.0006761
[Epoch 29; Iter  1764/ 2172] train: loss: 0.0014178
[Epoch 29; Iter  1794/ 2172] train: loss: 0.0088359
[Epoch 29; Iter  1824/ 2172] train: loss: 0.0023496
[Epoch 29; Iter  1854/ 2172] train: loss: 0.0541937
[Epoch 29; Iter  1884/ 2172] train: loss: 0.0019717
[Epoch 29; Iter  1914/ 2172] train: loss: 0.0014682
[Epoch 29; Iter  1944/ 2172] train: loss: 0.0017624
[Epoch 29; Iter  1974/ 2172] train: loss: 0.0558410
[Epoch 29; Iter  2004/ 2172] train: loss: 0.0011394
[Epoch 29; Iter  2034/ 2172] train: loss: 0.0023500
[Epoch 29; Iter  2064/ 2172] train: loss: 0.0027369
[Epoch 29; Iter  2094/ 2172] train: loss: 0.0653173
[Epoch 29; Iter  2124/ 2172] train: loss: 0.0016872
[Epoch 29; Iter  2154/ 2172] train: loss: 0.0019389
[Epoch 29] ogbg-molmuv: 0.140468 val loss: 0.021031
[Epoch 29] ogbg-molmuv: 0.082064 test loss: 0.036801
[Epoch 30; Iter    12/ 2172] train: loss: 0.0019926
[Epoch 30; Iter    42/ 2172] train: loss: 0.0011802
[Epoch 30; Iter    72/ 2172] train: loss: 0.0011885
[Epoch 30; Iter   102/ 2172] train: loss: 0.0012494
[Epoch 29; Iter  1564/ 1862] train: loss: 0.0014130
[Epoch 29; Iter  1594/ 1862] train: loss: 0.0007911
[Epoch 29; Iter  1624/ 1862] train: loss: 0.0723836
[Epoch 29; Iter  1654/ 1862] train: loss: 0.0015073
[Epoch 29; Iter  1684/ 1862] train: loss: 0.0012959
[Epoch 29; Iter  1714/ 1862] train: loss: 0.0082382
[Epoch 29; Iter  1744/ 1862] train: loss: 0.0009095
[Epoch 29; Iter  1774/ 1862] train: loss: 0.0017659
[Epoch 29; Iter  1804/ 1862] train: loss: 0.0026938
[Epoch 29; Iter  1834/ 1862] train: loss: 0.0015900
[Epoch 29] ogbg-molmuv: 0.072612 val loss: 0.012527
[Epoch 29] ogbg-molmuv: 0.094391 test loss: 0.011523
[Epoch 30; Iter     2/ 1862] train: loss: 0.0012640
[Epoch 30; Iter    32/ 1862] train: loss: 0.0018508
[Epoch 30; Iter    62/ 1862] train: loss: 0.0579369
[Epoch 30; Iter    92/ 1862] train: loss: 0.0742175
[Epoch 30; Iter   122/ 1862] train: loss: 0.0022586
[Epoch 30; Iter   152/ 1862] train: loss: 0.0009131
[Epoch 30; Iter   182/ 1862] train: loss: 0.0875364
[Epoch 30; Iter   212/ 1862] train: loss: 0.0024085
[Epoch 30; Iter   242/ 1862] train: loss: 0.0020882
[Epoch 30; Iter   272/ 1862] train: loss: 0.0016748
[Epoch 30; Iter   302/ 1862] train: loss: 0.0011627
[Epoch 30; Iter   332/ 1862] train: loss: 0.0011689
[Epoch 30; Iter   362/ 1862] train: loss: 0.0021917
[Epoch 30; Iter   392/ 1862] train: loss: 0.0024898
[Epoch 30; Iter   422/ 1862] train: loss: 0.0013203
[Epoch 30; Iter   452/ 1862] train: loss: 0.0016459
[Epoch 30; Iter   482/ 1862] train: loss: 0.0284930
[Epoch 30; Iter   512/ 1862] train: loss: 0.0019984
[Epoch 30; Iter   542/ 1862] train: loss: 0.0502711
[Epoch 30; Iter   572/ 1862] train: loss: 0.0696004
[Epoch 30; Iter   602/ 1862] train: loss: 0.0009430
[Epoch 30; Iter   632/ 1862] train: loss: 0.0010898
[Epoch 30; Iter   662/ 1862] train: loss: 0.0017561
[Epoch 30; Iter   692/ 1862] train: loss: 0.0011371
[Epoch 30; Iter   722/ 1862] train: loss: 0.0014018
[Epoch 30; Iter   752/ 1862] train: loss: 0.0014384
[Epoch 30; Iter   782/ 1862] train: loss: 0.0019278
[Epoch 30; Iter   812/ 1862] train: loss: 0.0012333
[Epoch 30; Iter   842/ 1862] train: loss: 0.0020610
[Epoch 30; Iter   872/ 1862] train: loss: 0.0049202
[Epoch 30; Iter   902/ 1862] train: loss: 0.0010323
[Epoch 30; Iter   932/ 1862] train: loss: 0.0012700
[Epoch 30; Iter   962/ 1862] train: loss: 0.0021059
[Epoch 30; Iter   992/ 1862] train: loss: 0.0008868
[Epoch 30; Iter  1022/ 1862] train: loss: 0.0016912
[Epoch 30; Iter  1052/ 1862] train: loss: 0.0012292
[Epoch 30; Iter  1082/ 1862] train: loss: 0.0012201
[Epoch 30; Iter  1112/ 1862] train: loss: 0.1136327
[Epoch 30; Iter  1142/ 1862] train: loss: 0.0050611
[Epoch 30; Iter  1172/ 1862] train: loss: 0.0013297
[Epoch 30; Iter  1202/ 1862] train: loss: 0.0009529
[Epoch 30; Iter  1232/ 1862] train: loss: 0.0007773
[Epoch 30; Iter  1262/ 1862] train: loss: 0.0016161
[Epoch 30; Iter  1292/ 1862] train: loss: 0.0007273
[Epoch 30; Iter  1322/ 1862] train: loss: 0.0108873
[Epoch 30; Iter  1352/ 1862] train: loss: 0.0010110
[Epoch 30; Iter  1382/ 1862] train: loss: 0.0013180
[Epoch 30; Iter  1412/ 1862] train: loss: 0.0020914
[Epoch 30; Iter  1442/ 1862] train: loss: 0.0013149
[Epoch 30; Iter  1472/ 1862] train: loss: 0.1083058
[Epoch 30; Iter  1502/ 1862] train: loss: 0.0009193
[Epoch 30; Iter  1532/ 1862] train: loss: 0.0019909
[Epoch 30; Iter  1562/ 1862] train: loss: 0.0027187
[Epoch 30; Iter  1592/ 1862] train: loss: 0.0020138
[Epoch 30; Iter  1622/ 1862] train: loss: 0.0022195
[Epoch 30; Iter  1652/ 1862] train: loss: 0.0013419
[Epoch 30; Iter  1682/ 1862] train: loss: 0.0015692
[Epoch 30; Iter  1712/ 1862] train: loss: 0.0014423
[Epoch 30; Iter  1742/ 1862] train: loss: 0.0037898
[Epoch 30; Iter  1772/ 1862] train: loss: 0.0013129
[Epoch 30; Iter  1802/ 1862] train: loss: 0.0676957
[Epoch 30; Iter  1832/ 1862] train: loss: 0.0033544
[Epoch 30; Iter  1862/ 1862] train: loss: 0.0009640
[Epoch 30] ogbg-molmuv: 0.087541 val loss: 0.012705
[Epoch 30] ogbg-molmuv: 0.113127 test loss: 0.011324
[Epoch 31; Iter    30/ 1862] train: loss: 0.0015356
[Epoch 31; Iter    60/ 1862] train: loss: 0.0019930
[Epoch 31; Iter    90/ 1862] train: loss: 0.0014135
[Epoch 31; Iter   120/ 1862] train: loss: 0.0015690
[Epoch 31; Iter   150/ 1862] train: loss: 0.0124755
[Epoch 31; Iter   180/ 1862] train: loss: 0.0093279
[Epoch 31; Iter   210/ 1862] train: loss: 0.0015045
[Epoch 31; Iter   240/ 1862] train: loss: 0.0016019
[Epoch 31; Iter   270/ 1862] train: loss: 0.0680367
[Epoch 31; Iter   300/ 1862] train: loss: 0.0014373
[Epoch 31; Iter   330/ 1862] train: loss: 0.0014032
[Epoch 31; Iter   360/ 1862] train: loss: 0.0014227
[Epoch 31; Iter   390/ 1862] train: loss: 0.0010100
[Epoch 31; Iter   420/ 1862] train: loss: 0.0036238
[Epoch 31; Iter   450/ 1862] train: loss: 0.0011152
[Epoch 31; Iter   480/ 1862] train: loss: 0.0265451
[Epoch 31; Iter   510/ 1862] train: loss: 0.0952893
[Epoch 31; Iter   540/ 1862] train: loss: 0.0015707
[Epoch 31; Iter   570/ 1862] train: loss: 0.0530019
[Epoch 31; Iter   600/ 1862] train: loss: 0.0010354
[Epoch 31; Iter   630/ 1862] train: loss: 0.0008811
[Epoch 31; Iter   660/ 1862] train: loss: 0.0014889
[Epoch 31; Iter   690/ 1862] train: loss: 0.0027377
[Epoch 31; Iter   720/ 1862] train: loss: 0.0010924
[Epoch 31; Iter   750/ 1862] train: loss: 0.1072377
[Epoch 31; Iter   780/ 1862] train: loss: 0.0042304
[Epoch 31; Iter   810/ 1862] train: loss: 0.0016748
[Epoch 31; Iter   840/ 1862] train: loss: 0.0029196
[Epoch 31; Iter   870/ 1862] train: loss: 0.0012520
[Epoch 31; Iter   900/ 1862] train: loss: 0.0016932
[Epoch 31; Iter   930/ 1862] train: loss: 0.0320026
[Epoch 31; Iter   960/ 1862] train: loss: 0.0021887
[Epoch 31; Iter   990/ 1862] train: loss: 0.0016080
[Epoch 31; Iter  1020/ 1862] train: loss: 0.0032944
[Epoch 31; Iter  1050/ 1862] train: loss: 0.0267167
[Epoch 31; Iter  1080/ 1862] train: loss: 0.0078884
[Epoch 31; Iter  1110/ 1862] train: loss: 0.0079747
[Epoch 31; Iter  1140/ 1862] train: loss: 0.0622473
[Epoch 31; Iter  1170/ 1862] train: loss: 0.1256501
[Epoch 31; Iter  1200/ 1862] train: loss: 0.0030137
[Epoch 31; Iter  1230/ 1862] train: loss: 0.0012982
[Epoch 31; Iter  1260/ 1862] train: loss: 0.0014287
[Epoch 31; Iter  1290/ 1862] train: loss: 0.0013091
[Epoch 31; Iter  1320/ 1862] train: loss: 0.0010529
[Epoch 31; Iter  1350/ 1862] train: loss: 0.0019898
[Epoch 31; Iter  1380/ 1862] train: loss: 0.0751812
[Epoch 31; Iter  1410/ 1862] train: loss: 0.0010536
[Epoch 31; Iter  1440/ 1862] train: loss: 0.0014094
[Epoch 31; Iter  1470/ 1862] train: loss: 0.0018345
[Epoch 31; Iter  1500/ 1862] train: loss: 0.0460164
[Epoch 31; Iter  1530/ 1862] train: loss: 0.0949123
[Epoch 31; Iter  1560/ 1862] train: loss: 0.0017697
[Epoch 31; Iter  1590/ 1862] train: loss: 0.0011260
[Epoch 31; Iter  1620/ 1862] train: loss: 0.0017049
[Epoch 31; Iter  1650/ 1862] train: loss: 0.0016039
[Epoch 31; Iter  1680/ 1862] train: loss: 0.0024445
[Epoch 31; Iter  1710/ 1862] train: loss: 0.0014728
[Epoch 31; Iter  1740/ 1862] train: loss: 0.0021354
[Epoch 31; Iter  1770/ 1862] train: loss: 0.0014271
[Epoch 31; Iter  1800/ 1862] train: loss: 0.0014134
[Epoch 31; Iter  1830/ 1862] train: loss: 0.0008052
[Epoch 31; Iter  1860/ 1862] train: loss: 0.0020138
[Epoch 31] ogbg-molmuv: 0.078388 val loss: 0.012880
[Epoch 31] ogbg-molmuv: 0.096807 test loss: 0.011681
[Epoch 32; Iter    28/ 1862] train: loss: 0.0018290
[Epoch 32; Iter    58/ 1862] train: loss: 0.0007264
[Epoch 32; Iter    88/ 1862] train: loss: 0.0011221
[Epoch 32; Iter   118/ 1862] train: loss: 0.0011170
[Epoch 32; Iter   148/ 1862] train: loss: 0.0014369
[Epoch 32; Iter   178/ 1862] train: loss: 0.0026990
[Epoch 32; Iter   208/ 1862] train: loss: 0.0025138
[Epoch 32; Iter   238/ 1862] train: loss: 0.0714302
[Epoch 32; Iter   268/ 1862] train: loss: 0.0017914
[Epoch 32; Iter   298/ 1862] train: loss: 0.0010260
[Epoch 32; Iter   328/ 1862] train: loss: 0.0017050
[Epoch 32; Iter   358/ 1862] train: loss: 0.0012628
[Epoch 32; Iter   388/ 1862] train: loss: 0.0011285
[Epoch 32; Iter   418/ 1862] train: loss: 0.0010154
[Epoch 32; Iter   448/ 1862] train: loss: 0.0508999
[Epoch 32; Iter   478/ 1862] train: loss: 0.0015442
[Epoch 29; Iter  1564/ 1862] train: loss: 0.0600858
[Epoch 29; Iter  1594/ 1862] train: loss: 0.0009639
[Epoch 29; Iter  1624/ 1862] train: loss: 0.0017192
[Epoch 29; Iter  1654/ 1862] train: loss: 0.0013395
[Epoch 29; Iter  1684/ 1862] train: loss: 0.0034601
[Epoch 29; Iter  1714/ 1862] train: loss: 0.0018861
[Epoch 29; Iter  1744/ 1862] train: loss: 0.0025670
[Epoch 29; Iter  1774/ 1862] train: loss: 0.0025558
[Epoch 29; Iter  1804/ 1862] train: loss: 0.0012527
[Epoch 29; Iter  1834/ 1862] train: loss: 0.0008523
[Epoch 29] ogbg-molmuv: 0.054963 val loss: 0.013897
[Epoch 29] ogbg-molmuv: 0.069034 test loss: 0.012930
[Epoch 30; Iter     2/ 1862] train: loss: 0.0024514
[Epoch 30; Iter    32/ 1862] train: loss: 0.0013563
[Epoch 30; Iter    62/ 1862] train: loss: 0.0015987
[Epoch 30; Iter    92/ 1862] train: loss: 0.0012492
[Epoch 30; Iter   122/ 1862] train: loss: 0.0435340
[Epoch 30; Iter   152/ 1862] train: loss: 0.0451644
[Epoch 30; Iter   182/ 1862] train: loss: 0.0016729
[Epoch 30; Iter   212/ 1862] train: loss: 0.0014745
[Epoch 30; Iter   242/ 1862] train: loss: 0.0022459
[Epoch 30; Iter   272/ 1862] train: loss: 0.0011504
[Epoch 30; Iter   302/ 1862] train: loss: 0.0016441
[Epoch 30; Iter   332/ 1862] train: loss: 0.0017317
[Epoch 30; Iter   362/ 1862] train: loss: 0.0691045
[Epoch 30; Iter   392/ 1862] train: loss: 0.0030491
[Epoch 30; Iter   422/ 1862] train: loss: 0.0010532
[Epoch 30; Iter   452/ 1862] train: loss: 0.0045939
[Epoch 30; Iter   482/ 1862] train: loss: 0.0021321
[Epoch 30; Iter   512/ 1862] train: loss: 0.0012958
[Epoch 30; Iter   542/ 1862] train: loss: 0.0013641
[Epoch 30; Iter   572/ 1862] train: loss: 0.0760848
[Epoch 30; Iter   602/ 1862] train: loss: 0.0016690
[Epoch 30; Iter   632/ 1862] train: loss: 0.0024665
[Epoch 30; Iter   662/ 1862] train: loss: 0.0156619
[Epoch 30; Iter   692/ 1862] train: loss: 0.0019743
[Epoch 30; Iter   722/ 1862] train: loss: 0.0018070
[Epoch 30; Iter   752/ 1862] train: loss: 0.0011347
[Epoch 30; Iter   782/ 1862] train: loss: 0.0019509
[Epoch 30; Iter   812/ 1862] train: loss: 0.0014659
[Epoch 30; Iter   842/ 1862] train: loss: 0.0725754
[Epoch 30; Iter   872/ 1862] train: loss: 0.0030659
[Epoch 30; Iter   902/ 1862] train: loss: 0.0010078
[Epoch 30; Iter   932/ 1862] train: loss: 0.0013184
[Epoch 30; Iter   962/ 1862] train: loss: 0.0018845
[Epoch 30; Iter   992/ 1862] train: loss: 0.0020519
[Epoch 30; Iter  1022/ 1862] train: loss: 0.0564932
[Epoch 30; Iter  1052/ 1862] train: loss: 0.0011121
[Epoch 30; Iter  1082/ 1862] train: loss: 0.0040149
[Epoch 30; Iter  1112/ 1862] train: loss: 0.0008620
[Epoch 30; Iter  1142/ 1862] train: loss: 0.0016762
[Epoch 30; Iter  1172/ 1862] train: loss: 0.0010865
[Epoch 30; Iter  1202/ 1862] train: loss: 0.0011110
[Epoch 30; Iter  1232/ 1862] train: loss: 0.0062719
[Epoch 30; Iter  1262/ 1862] train: loss: 0.0011800
[Epoch 30; Iter  1292/ 1862] train: loss: 0.0014162
[Epoch 30; Iter  1322/ 1862] train: loss: 0.0885194
[Epoch 30; Iter  1352/ 1862] train: loss: 0.0012073
[Epoch 30; Iter  1382/ 1862] train: loss: 0.0017869
[Epoch 30; Iter  1412/ 1862] train: loss: 0.0018100
[Epoch 30; Iter  1442/ 1862] train: loss: 0.0027334
[Epoch 30; Iter  1472/ 1862] train: loss: 0.0009016
[Epoch 30; Iter  1502/ 1862] train: loss: 0.0017799
[Epoch 30; Iter  1532/ 1862] train: loss: 0.0014098
[Epoch 30; Iter  1562/ 1862] train: loss: 0.0013618
[Epoch 30; Iter  1592/ 1862] train: loss: 0.0045347
[Epoch 30; Iter  1622/ 1862] train: loss: 0.0021385
[Epoch 30; Iter  1652/ 1862] train: loss: 0.0032812
[Epoch 30; Iter  1682/ 1862] train: loss: 0.0031465
[Epoch 30; Iter  1712/ 1862] train: loss: 0.0028647
[Epoch 30; Iter  1742/ 1862] train: loss: 0.0014647
[Epoch 30; Iter  1772/ 1862] train: loss: 0.0560867
[Epoch 30; Iter  1802/ 1862] train: loss: 0.0017599
[Epoch 30; Iter  1832/ 1862] train: loss: 0.0014099
[Epoch 30; Iter  1862/ 1862] train: loss: 0.0016194
[Epoch 30] ogbg-molmuv: 0.051043 val loss: 0.017258
[Epoch 30] ogbg-molmuv: 0.058986 test loss: 0.012778
[Epoch 31; Iter    30/ 1862] train: loss: 0.0058904
[Epoch 31; Iter    60/ 1862] train: loss: 0.0015731
[Epoch 31; Iter    90/ 1862] train: loss: 0.0015420
[Epoch 31; Iter   120/ 1862] train: loss: 0.0017055
[Epoch 31; Iter   150/ 1862] train: loss: 0.0021126
[Epoch 31; Iter   180/ 1862] train: loss: 0.0026488
[Epoch 31; Iter   210/ 1862] train: loss: 0.0044088
[Epoch 31; Iter   240/ 1862] train: loss: 0.0015528
[Epoch 31; Iter   270/ 1862] train: loss: 0.1036202
[Epoch 31; Iter   300/ 1862] train: loss: 0.0012130
[Epoch 31; Iter   330/ 1862] train: loss: 0.0009927
[Epoch 31; Iter   360/ 1862] train: loss: 0.0010771
[Epoch 31; Iter   390/ 1862] train: loss: 0.0012601
[Epoch 31; Iter   420/ 1862] train: loss: 0.0020184
[Epoch 31; Iter   450/ 1862] train: loss: 0.0017746
[Epoch 31; Iter   480/ 1862] train: loss: 0.0018097
[Epoch 31; Iter   510/ 1862] train: loss: 0.0014629
[Epoch 31; Iter   540/ 1862] train: loss: 0.0017169
[Epoch 31; Iter   570/ 1862] train: loss: 0.0013304
[Epoch 31; Iter   600/ 1862] train: loss: 0.0068236
[Epoch 31; Iter   630/ 1862] train: loss: 0.0771552
[Epoch 31; Iter   660/ 1862] train: loss: 0.0012704
[Epoch 31; Iter   690/ 1862] train: loss: 0.0008762
[Epoch 31; Iter   720/ 1862] train: loss: 0.0015259
[Epoch 31; Iter   750/ 1862] train: loss: 0.0013428
[Epoch 31; Iter   780/ 1862] train: loss: 0.0009019
[Epoch 31; Iter   810/ 1862] train: loss: 0.0009812
[Epoch 31; Iter   840/ 1862] train: loss: 0.0009986
[Epoch 31; Iter   870/ 1862] train: loss: 0.0010148
[Epoch 31; Iter   900/ 1862] train: loss: 0.0980942
[Epoch 31; Iter   930/ 1862] train: loss: 0.1118617
[Epoch 31; Iter   960/ 1862] train: loss: 0.0521305
[Epoch 31; Iter   990/ 1862] train: loss: 0.0740864
[Epoch 31; Iter  1020/ 1862] train: loss: 0.0010654
[Epoch 31; Iter  1050/ 1862] train: loss: 0.0024213
[Epoch 31; Iter  1080/ 1862] train: loss: 0.0017000
[Epoch 31; Iter  1110/ 1862] train: loss: 0.0007746
[Epoch 31; Iter  1140/ 1862] train: loss: 0.0012602
[Epoch 31; Iter  1170/ 1862] train: loss: 0.0013648
[Epoch 31; Iter  1200/ 1862] train: loss: 0.0973943
[Epoch 31; Iter  1230/ 1862] train: loss: 0.0020088
[Epoch 31; Iter  1260/ 1862] train: loss: 0.0546884
[Epoch 31; Iter  1290/ 1862] train: loss: 0.0013208
[Epoch 31; Iter  1320/ 1862] train: loss: 0.0010658
[Epoch 31; Iter  1350/ 1862] train: loss: 0.0017493
[Epoch 31; Iter  1380/ 1862] train: loss: 0.0013056
[Epoch 31; Iter  1410/ 1862] train: loss: 0.0814508
[Epoch 31; Iter  1440/ 1862] train: loss: 0.0015376
[Epoch 31; Iter  1470/ 1862] train: loss: 0.0011976
[Epoch 31; Iter  1500/ 1862] train: loss: 0.0020032
[Epoch 31; Iter  1530/ 1862] train: loss: 0.0639448
[Epoch 31; Iter  1560/ 1862] train: loss: 0.0016892
[Epoch 31; Iter  1590/ 1862] train: loss: 0.0156231
[Epoch 31; Iter  1620/ 1862] train: loss: 0.0016623
[Epoch 31; Iter  1650/ 1862] train: loss: 0.0568107
[Epoch 31; Iter  1680/ 1862] train: loss: 0.0055271
[Epoch 31; Iter  1710/ 1862] train: loss: 0.0021787
[Epoch 31; Iter  1740/ 1862] train: loss: 0.0011937
[Epoch 31; Iter  1770/ 1862] train: loss: 0.0027551
[Epoch 31; Iter  1800/ 1862] train: loss: 0.0012003
[Epoch 31; Iter  1830/ 1862] train: loss: 0.0011714
[Epoch 31; Iter  1860/ 1862] train: loss: 0.0673285
[Epoch 31] ogbg-molmuv: 0.038884 val loss: 0.013648
[Epoch 31] ogbg-molmuv: 0.063701 test loss: 0.012719
[Epoch 32; Iter    28/ 1862] train: loss: 0.0010919
[Epoch 32; Iter    58/ 1862] train: loss: 0.1617677
[Epoch 32; Iter    88/ 1862] train: loss: 0.0011816
[Epoch 32; Iter   118/ 1862] train: loss: 0.0021363
[Epoch 32; Iter   148/ 1862] train: loss: 0.0898062
[Epoch 32; Iter   178/ 1862] train: loss: 0.0007964
[Epoch 32; Iter   208/ 1862] train: loss: 0.0014263
[Epoch 32; Iter   238/ 1862] train: loss: 0.0013969
[Epoch 32; Iter   268/ 1862] train: loss: 0.0016665
[Epoch 32; Iter   298/ 1862] train: loss: 0.0012504
[Epoch 32; Iter   328/ 1862] train: loss: 0.0023789
[Epoch 32; Iter   358/ 1862] train: loss: 0.0011281
[Epoch 32; Iter   388/ 1862] train: loss: 0.0014587
[Epoch 32; Iter   418/ 1862] train: loss: 0.0408878
[Epoch 32; Iter   448/ 1862] train: loss: 0.0018521
[Epoch 32; Iter   478/ 1862] train: loss: 0.0013456
[Epoch 28; Iter   939/ 2483] train: loss: 0.0012324
[Epoch 28; Iter   969/ 2483] train: loss: 0.0015975
[Epoch 28; Iter   999/ 2483] train: loss: 0.0752326
[Epoch 28; Iter  1029/ 2483] train: loss: 0.0016285
[Epoch 28; Iter  1059/ 2483] train: loss: 0.0013936
[Epoch 28; Iter  1089/ 2483] train: loss: 0.0040883
[Epoch 28; Iter  1119/ 2483] train: loss: 0.0018448
[Epoch 28; Iter  1149/ 2483] train: loss: 0.0426844
[Epoch 28; Iter  1179/ 2483] train: loss: 0.0017789
[Epoch 28; Iter  1209/ 2483] train: loss: 0.0025695
[Epoch 28; Iter  1239/ 2483] train: loss: 0.0024362
[Epoch 28; Iter  1269/ 2483] train: loss: 0.0019842
[Epoch 28; Iter  1299/ 2483] train: loss: 0.0555671
[Epoch 28; Iter  1329/ 2483] train: loss: 0.0023720
[Epoch 28; Iter  1359/ 2483] train: loss: 0.0034067
[Epoch 28; Iter  1389/ 2483] train: loss: 0.0023064
[Epoch 28; Iter  1419/ 2483] train: loss: 0.0578258
[Epoch 28; Iter  1449/ 2483] train: loss: 0.0040826
[Epoch 28; Iter  1479/ 2483] train: loss: 0.0012481
[Epoch 28; Iter  1509/ 2483] train: loss: 0.0475205
[Epoch 28; Iter  1539/ 2483] train: loss: 0.0014252
[Epoch 28; Iter  1569/ 2483] train: loss: 0.0073203
[Epoch 28; Iter  1599/ 2483] train: loss: 0.0024036
[Epoch 28; Iter  1629/ 2483] train: loss: 0.0013436
[Epoch 28; Iter  1659/ 2483] train: loss: 0.0011329
[Epoch 28; Iter  1689/ 2483] train: loss: 0.0021356
[Epoch 28; Iter  1719/ 2483] train: loss: 0.0503705
[Epoch 28; Iter  1749/ 2483] train: loss: 0.0012937
[Epoch 28; Iter  1779/ 2483] train: loss: 0.0018522
[Epoch 28; Iter  1809/ 2483] train: loss: 0.0769910
[Epoch 28; Iter  1839/ 2483] train: loss: 0.0049794
[Epoch 28; Iter  1869/ 2483] train: loss: 0.0011776
[Epoch 28; Iter  1899/ 2483] train: loss: 0.0009319
[Epoch 28; Iter  1929/ 2483] train: loss: 0.0011741
[Epoch 28; Iter  1959/ 2483] train: loss: 0.0766845
[Epoch 28; Iter  1989/ 2483] train: loss: 0.0018274
[Epoch 28; Iter  2019/ 2483] train: loss: 0.0020957
[Epoch 28; Iter  2049/ 2483] train: loss: 0.0582729
[Epoch 28; Iter  2079/ 2483] train: loss: 0.0017722
[Epoch 28; Iter  2109/ 2483] train: loss: 0.0759756
[Epoch 28; Iter  2139/ 2483] train: loss: 0.0018895
[Epoch 28; Iter  2169/ 2483] train: loss: 0.0018129
[Epoch 28; Iter  2199/ 2483] train: loss: 0.0757176
[Epoch 28; Iter  2229/ 2483] train: loss: 0.0011698
[Epoch 28; Iter  2259/ 2483] train: loss: 0.0505244
[Epoch 28; Iter  2289/ 2483] train: loss: 0.0034505
[Epoch 28; Iter  2319/ 2483] train: loss: 0.0016321
[Epoch 28; Iter  2349/ 2483] train: loss: 0.0017599
[Epoch 28; Iter  2379/ 2483] train: loss: 0.0018424
[Epoch 28; Iter  2409/ 2483] train: loss: 0.0013330
[Epoch 28; Iter  2439/ 2483] train: loss: 0.0022008
[Epoch 28; Iter  2469/ 2483] train: loss: 0.0015177
[Epoch 28] ogbg-molmuv: 0.153702 val loss: 0.042564
[Epoch 28] ogbg-molmuv: 0.122752 test loss: 0.014773
[Epoch 29; Iter    16/ 2483] train: loss: 0.0016711
[Epoch 29; Iter    46/ 2483] train: loss: 0.0017257
[Epoch 29; Iter    76/ 2483] train: loss: 0.0023293
[Epoch 29; Iter   106/ 2483] train: loss: 0.0036576
[Epoch 29; Iter   136/ 2483] train: loss: 0.0018107
[Epoch 29; Iter   166/ 2483] train: loss: 0.0515140
[Epoch 29; Iter   196/ 2483] train: loss: 0.0016155
[Epoch 29; Iter   226/ 2483] train: loss: 0.0011454
[Epoch 29; Iter   256/ 2483] train: loss: 0.0649410
[Epoch 29; Iter   286/ 2483] train: loss: 0.0026869
[Epoch 29; Iter   316/ 2483] train: loss: 0.0826653
[Epoch 29; Iter   346/ 2483] train: loss: 0.0018319
[Epoch 29; Iter   376/ 2483] train: loss: 0.0022431
[Epoch 29; Iter   406/ 2483] train: loss: 0.0010461
[Epoch 29; Iter   436/ 2483] train: loss: 0.0014048
[Epoch 29; Iter   466/ 2483] train: loss: 0.0010701
[Epoch 29; Iter   496/ 2483] train: loss: 0.0010996
[Epoch 29; Iter   526/ 2483] train: loss: 0.0013555
[Epoch 29; Iter   556/ 2483] train: loss: 0.0030483
[Epoch 29; Iter   586/ 2483] train: loss: 0.0025169
[Epoch 29; Iter   616/ 2483] train: loss: 0.0016858
[Epoch 29; Iter   646/ 2483] train: loss: 0.0648724
[Epoch 29; Iter   676/ 2483] train: loss: 0.0017095
[Epoch 29; Iter   706/ 2483] train: loss: 0.0017025
[Epoch 29; Iter   736/ 2483] train: loss: 0.1072563
[Epoch 29; Iter   766/ 2483] train: loss: 0.0020819
[Epoch 29; Iter   796/ 2483] train: loss: 0.0027676
[Epoch 29; Iter   826/ 2483] train: loss: 0.0020230
[Epoch 29; Iter   856/ 2483] train: loss: 0.0010323
[Epoch 29; Iter   886/ 2483] train: loss: 0.0016724
[Epoch 29; Iter   916/ 2483] train: loss: 0.0016899
[Epoch 29; Iter   946/ 2483] train: loss: 0.0009845
[Epoch 29; Iter   976/ 2483] train: loss: 0.0009314
[Epoch 29; Iter  1006/ 2483] train: loss: 0.0015079
[Epoch 29; Iter  1036/ 2483] train: loss: 0.0018591
[Epoch 29; Iter  1066/ 2483] train: loss: 0.0014777
[Epoch 29; Iter  1096/ 2483] train: loss: 0.0015812
[Epoch 29; Iter  1126/ 2483] train: loss: 0.0014712
[Epoch 29; Iter  1156/ 2483] train: loss: 0.0014809
[Epoch 29; Iter  1186/ 2483] train: loss: 0.0016638
[Epoch 29; Iter  1216/ 2483] train: loss: 0.0582051
[Epoch 29; Iter  1246/ 2483] train: loss: 0.0029669
[Epoch 29; Iter  1276/ 2483] train: loss: 0.0018680
[Epoch 29; Iter  1306/ 2483] train: loss: 0.0011739
[Epoch 29; Iter  1336/ 2483] train: loss: 0.0013130
[Epoch 29; Iter  1366/ 2483] train: loss: 0.0013544
[Epoch 29; Iter  1396/ 2483] train: loss: 0.0013615
[Epoch 29; Iter  1426/ 2483] train: loss: 0.0017673
[Epoch 29; Iter  1456/ 2483] train: loss: 0.0274853
[Epoch 29; Iter  1486/ 2483] train: loss: 0.0015103
[Epoch 29; Iter  1516/ 2483] train: loss: 0.0051829
[Epoch 29; Iter  1546/ 2483] train: loss: 0.0012425
[Epoch 29; Iter  1576/ 2483] train: loss: 0.0685827
[Epoch 29; Iter  1606/ 2483] train: loss: 0.0847760
[Epoch 29; Iter  1636/ 2483] train: loss: 0.0011946
[Epoch 29; Iter  1666/ 2483] train: loss: 0.0018102
[Epoch 29; Iter  1696/ 2483] train: loss: 0.0083212
[Epoch 29; Iter  1726/ 2483] train: loss: 0.0015258
[Epoch 29; Iter  1756/ 2483] train: loss: 0.0237881
[Epoch 29; Iter  1786/ 2483] train: loss: 0.0020906
[Epoch 29; Iter  1816/ 2483] train: loss: 0.0056877
[Epoch 29; Iter  1846/ 2483] train: loss: 0.0010351
[Epoch 29; Iter  1876/ 2483] train: loss: 0.0028056
[Epoch 29; Iter  1906/ 2483] train: loss: 0.0008444
[Epoch 29; Iter  1936/ 2483] train: loss: 0.0008055
[Epoch 29; Iter  1966/ 2483] train: loss: 0.0012352
[Epoch 29; Iter  1996/ 2483] train: loss: 0.0022888
[Epoch 29; Iter  2026/ 2483] train: loss: 0.0010539
[Epoch 29; Iter  2056/ 2483] train: loss: 0.0011767
[Epoch 29; Iter  2086/ 2483] train: loss: 0.0013667
[Epoch 29; Iter  2116/ 2483] train: loss: 0.0013695
[Epoch 29; Iter  2146/ 2483] train: loss: 0.0019879
[Epoch 29; Iter  2176/ 2483] train: loss: 0.0010138
[Epoch 29; Iter  2206/ 2483] train: loss: 0.0011435
[Epoch 29; Iter  2236/ 2483] train: loss: 0.0014080
[Epoch 29; Iter  2266/ 2483] train: loss: 0.0231152
[Epoch 29; Iter  2296/ 2483] train: loss: 0.0018626
[Epoch 29; Iter  2326/ 2483] train: loss: 0.0018183
[Epoch 29; Iter  2356/ 2483] train: loss: 0.0035422
[Epoch 29; Iter  2386/ 2483] train: loss: 0.0012254
[Epoch 29; Iter  2416/ 2483] train: loss: 0.0009687
[Epoch 29; Iter  2446/ 2483] train: loss: 0.0012025
[Epoch 29; Iter  2476/ 2483] train: loss: 0.0017351
[Epoch 29] ogbg-molmuv: 0.142108 val loss: 0.011130
[Epoch 29] ogbg-molmuv: 0.133719 test loss: 0.014132
[Epoch 30; Iter    23/ 2483] train: loss: 0.0013815
[Epoch 30; Iter    53/ 2483] train: loss: 0.0033220
[Epoch 30; Iter    83/ 2483] train: loss: 0.0727771
[Epoch 30; Iter   113/ 2483] train: loss: 0.0012853
[Epoch 30; Iter   143/ 2483] train: loss: 0.0420658
[Epoch 30; Iter   173/ 2483] train: loss: 0.0155261
[Epoch 30; Iter   203/ 2483] train: loss: 0.0016253
[Epoch 30; Iter   233/ 2483] train: loss: 0.0024455
[Epoch 30; Iter   263/ 2483] train: loss: 0.0009900
[Epoch 30; Iter   293/ 2483] train: loss: 0.0013770
[Epoch 30; Iter   323/ 2483] train: loss: 0.0013178
[Epoch 30; Iter   353/ 2483] train: loss: 0.0054594
[Epoch 30; Iter   383/ 2483] train: loss: 0.0015868
[Epoch 30; Iter   413/ 2483] train: loss: 0.0049325
[Epoch 30; Iter   443/ 2483] train: loss: 0.0010332
[Epoch 30; Iter   473/ 2483] train: loss: 0.0036626
[Epoch 30; Iter   503/ 2483] train: loss: 0.0014387
[Epoch 30; Iter   533/ 2483] train: loss: 0.0014138
[Epoch 28; Iter   939/ 2483] train: loss: 0.0383595
[Epoch 28; Iter   969/ 2483] train: loss: 0.0013903
[Epoch 28; Iter   999/ 2483] train: loss: 0.0014999
[Epoch 28; Iter  1029/ 2483] train: loss: 0.0016948
[Epoch 28; Iter  1059/ 2483] train: loss: 0.0013899
[Epoch 28; Iter  1089/ 2483] train: loss: 0.0011217
[Epoch 28; Iter  1119/ 2483] train: loss: 0.0010720
[Epoch 28; Iter  1149/ 2483] train: loss: 0.0581896
[Epoch 28; Iter  1179/ 2483] train: loss: 0.0015930
[Epoch 28; Iter  1209/ 2483] train: loss: 0.0013713
[Epoch 28; Iter  1239/ 2483] train: loss: 0.0020944
[Epoch 28; Iter  1269/ 2483] train: loss: 0.0014756
[Epoch 28; Iter  1299/ 2483] train: loss: 0.0006784
[Epoch 28; Iter  1329/ 2483] train: loss: 0.0019917
[Epoch 28; Iter  1359/ 2483] train: loss: 0.0030867
[Epoch 28; Iter  1389/ 2483] train: loss: 0.0054507
[Epoch 28; Iter  1419/ 2483] train: loss: 0.0016167
[Epoch 28; Iter  1449/ 2483] train: loss: 0.0030007
[Epoch 28; Iter  1479/ 2483] train: loss: 0.0017205
[Epoch 28; Iter  1509/ 2483] train: loss: 0.1025324
[Epoch 28; Iter  1539/ 2483] train: loss: 0.0016318
[Epoch 28; Iter  1569/ 2483] train: loss: 0.0011958
[Epoch 28; Iter  1599/ 2483] train: loss: 0.0038263
[Epoch 28; Iter  1629/ 2483] train: loss: 0.0025587
[Epoch 28; Iter  1659/ 2483] train: loss: 0.0016057
[Epoch 28; Iter  1689/ 2483] train: loss: 0.0010407
[Epoch 28; Iter  1719/ 2483] train: loss: 0.0015260
[Epoch 28; Iter  1749/ 2483] train: loss: 0.0017116
[Epoch 28; Iter  1779/ 2483] train: loss: 0.0019425
[Epoch 28; Iter  1809/ 2483] train: loss: 0.0012862
[Epoch 28; Iter  1839/ 2483] train: loss: 0.0010473
[Epoch 28; Iter  1869/ 2483] train: loss: 0.0022905
[Epoch 28; Iter  1899/ 2483] train: loss: 0.0336701
[Epoch 28; Iter  1929/ 2483] train: loss: 0.0035084
[Epoch 28; Iter  1959/ 2483] train: loss: 0.0011656
[Epoch 28; Iter  1989/ 2483] train: loss: 0.0007770
[Epoch 28; Iter  2019/ 2483] train: loss: 0.0036560
[Epoch 28; Iter  2049/ 2483] train: loss: 0.0012216
[Epoch 28; Iter  2079/ 2483] train: loss: 0.0012838
[Epoch 28; Iter  2109/ 2483] train: loss: 0.0400852
[Epoch 28; Iter  2139/ 2483] train: loss: 0.0024965
[Epoch 28; Iter  2169/ 2483] train: loss: 0.0015476
[Epoch 28; Iter  2199/ 2483] train: loss: 0.0012642
[Epoch 28; Iter  2229/ 2483] train: loss: 0.0034683
[Epoch 28; Iter  2259/ 2483] train: loss: 0.0016266
[Epoch 28; Iter  2289/ 2483] train: loss: 0.0008726
[Epoch 28; Iter  2319/ 2483] train: loss: 0.0012573
[Epoch 28; Iter  2349/ 2483] train: loss: 0.0808092
[Epoch 28; Iter  2379/ 2483] train: loss: 0.0014158
[Epoch 28; Iter  2409/ 2483] train: loss: 0.0021246
[Epoch 28; Iter  2439/ 2483] train: loss: 0.0022287
[Epoch 28; Iter  2469/ 2483] train: loss: 0.0010831
[Epoch 28] ogbg-molmuv: 0.106424 val loss: 0.013430
[Epoch 28] ogbg-molmuv: 0.176796 test loss: 0.049122
[Epoch 29; Iter    16/ 2483] train: loss: 0.0546722
[Epoch 29; Iter    46/ 2483] train: loss: 0.0014808
[Epoch 29; Iter    76/ 2483] train: loss: 0.0616626
[Epoch 29; Iter   106/ 2483] train: loss: 0.0011389
[Epoch 29; Iter   136/ 2483] train: loss: 0.0008897
[Epoch 29; Iter   166/ 2483] train: loss: 0.0014493
[Epoch 29; Iter   196/ 2483] train: loss: 0.0006791
[Epoch 29; Iter   226/ 2483] train: loss: 0.0021326
[Epoch 29; Iter   256/ 2483] train: loss: 0.0012380
[Epoch 29; Iter   286/ 2483] train: loss: 0.0012601
[Epoch 29; Iter   316/ 2483] train: loss: 0.0011110
[Epoch 29; Iter   346/ 2483] train: loss: 0.0014542
[Epoch 29; Iter   376/ 2483] train: loss: 0.0021362
[Epoch 29; Iter   406/ 2483] train: loss: 0.0017489
[Epoch 29; Iter   436/ 2483] train: loss: 0.0020609
[Epoch 29; Iter   466/ 2483] train: loss: 0.0736737
[Epoch 29; Iter   496/ 2483] train: loss: 0.0035063
[Epoch 29; Iter   526/ 2483] train: loss: 0.0014308
[Epoch 29; Iter   556/ 2483] train: loss: 0.0025060
[Epoch 29; Iter   586/ 2483] train: loss: 0.0522695
[Epoch 29; Iter   616/ 2483] train: loss: 0.0012872
[Epoch 29; Iter   646/ 2483] train: loss: 0.0012430
[Epoch 29; Iter   676/ 2483] train: loss: 0.0014410
[Epoch 29; Iter   706/ 2483] train: loss: 0.0029432
[Epoch 29; Iter   736/ 2483] train: loss: 0.0018027
[Epoch 29; Iter   766/ 2483] train: loss: 0.0012056
[Epoch 29; Iter   796/ 2483] train: loss: 0.0012487
[Epoch 29; Iter   826/ 2483] train: loss: 0.0012402
[Epoch 29; Iter   856/ 2483] train: loss: 0.0016451
[Epoch 29; Iter   886/ 2483] train: loss: 0.0630218
[Epoch 29; Iter   916/ 2483] train: loss: 0.0015823
[Epoch 29; Iter   946/ 2483] train: loss: 0.0017677
[Epoch 29; Iter   976/ 2483] train: loss: 0.0011599
[Epoch 29; Iter  1006/ 2483] train: loss: 0.0013026
[Epoch 29; Iter  1036/ 2483] train: loss: 0.0324600
[Epoch 29; Iter  1066/ 2483] train: loss: 0.0014262
[Epoch 29; Iter  1096/ 2483] train: loss: 0.0040971
[Epoch 29; Iter  1126/ 2483] train: loss: 0.0013233
[Epoch 29; Iter  1156/ 2483] train: loss: 0.0016854
[Epoch 29; Iter  1186/ 2483] train: loss: 0.0016323
[Epoch 29; Iter  1216/ 2483] train: loss: 0.0018804
[Epoch 29; Iter  1246/ 2483] train: loss: 0.1779407
[Epoch 29; Iter  1276/ 2483] train: loss: 0.0017475
[Epoch 29; Iter  1306/ 2483] train: loss: 0.0016545
[Epoch 29; Iter  1336/ 2483] train: loss: 0.0020602
[Epoch 29; Iter  1366/ 2483] train: loss: 0.0009878
[Epoch 29; Iter  1396/ 2483] train: loss: 0.0012326
[Epoch 29; Iter  1426/ 2483] train: loss: 0.0017802
[Epoch 29; Iter  1456/ 2483] train: loss: 0.0028773
[Epoch 29; Iter  1486/ 2483] train: loss: 0.0151424
[Epoch 29; Iter  1516/ 2483] train: loss: 0.0012823
[Epoch 29; Iter  1546/ 2483] train: loss: 0.0020067
[Epoch 29; Iter  1576/ 2483] train: loss: 0.0019114
[Epoch 29; Iter  1606/ 2483] train: loss: 0.0012890
[Epoch 29; Iter  1636/ 2483] train: loss: 0.0016962
[Epoch 29; Iter  1666/ 2483] train: loss: 0.1054467
[Epoch 29; Iter  1696/ 2483] train: loss: 0.0038354
[Epoch 29; Iter  1726/ 2483] train: loss: 0.0022140
[Epoch 29; Iter  1756/ 2483] train: loss: 0.0009900
[Epoch 29; Iter  1786/ 2483] train: loss: 0.0012102
[Epoch 29; Iter  1816/ 2483] train: loss: 0.0025836
[Epoch 29; Iter  1846/ 2483] train: loss: 0.0016958
[Epoch 29; Iter  1876/ 2483] train: loss: 0.0006929
[Epoch 29; Iter  1906/ 2483] train: loss: 0.0013513
[Epoch 29; Iter  1936/ 2483] train: loss: 0.0020852
[Epoch 29; Iter  1966/ 2483] train: loss: 0.0013527
[Epoch 29; Iter  1996/ 2483] train: loss: 0.0331860
[Epoch 29; Iter  2026/ 2483] train: loss: 0.0009421
[Epoch 29; Iter  2056/ 2483] train: loss: 0.0024833
[Epoch 29; Iter  2086/ 2483] train: loss: 0.0018480
[Epoch 29; Iter  2116/ 2483] train: loss: 0.0009075
[Epoch 29; Iter  2146/ 2483] train: loss: 0.0022393
[Epoch 29; Iter  2176/ 2483] train: loss: 0.0017122
[Epoch 29; Iter  2206/ 2483] train: loss: 0.0020821
[Epoch 29; Iter  2236/ 2483] train: loss: 0.0020586
[Epoch 29; Iter  2266/ 2483] train: loss: 0.0020850
[Epoch 29; Iter  2296/ 2483] train: loss: 0.0011827
[Epoch 29; Iter  2326/ 2483] train: loss: 0.0015275
[Epoch 29; Iter  2356/ 2483] train: loss: 0.0017783
[Epoch 29; Iter  2386/ 2483] train: loss: 0.0030187
[Epoch 29; Iter  2416/ 2483] train: loss: 0.0028171
[Epoch 29; Iter  2446/ 2483] train: loss: 0.0063419
[Epoch 29; Iter  2476/ 2483] train: loss: 0.0016776
[Epoch 29] ogbg-molmuv: 0.121276 val loss: 0.027304
[Epoch 29] ogbg-molmuv: 0.147150 test loss: 0.052226
[Epoch 30; Iter    23/ 2483] train: loss: 0.0025670
[Epoch 30; Iter    53/ 2483] train: loss: 0.0020414
[Epoch 30; Iter    83/ 2483] train: loss: 0.0016832
[Epoch 30; Iter   113/ 2483] train: loss: 0.0529328
[Epoch 30; Iter   143/ 2483] train: loss: 0.0792690
[Epoch 30; Iter   173/ 2483] train: loss: 0.0028874
[Epoch 30; Iter   203/ 2483] train: loss: 0.0207516
[Epoch 30; Iter   233/ 2483] train: loss: 0.0018456
[Epoch 30; Iter   263/ 2483] train: loss: 0.0017534
[Epoch 30; Iter   293/ 2483] train: loss: 0.0009517
[Epoch 30; Iter   323/ 2483] train: loss: 0.0018147
[Epoch 30; Iter   353/ 2483] train: loss: 0.0025044
[Epoch 30; Iter   383/ 2483] train: loss: 0.0040288
[Epoch 30; Iter   413/ 2483] train: loss: 0.0016232
[Epoch 30; Iter   443/ 2483] train: loss: 0.0013183
[Epoch 30; Iter   473/ 2483] train: loss: 0.0043645
[Epoch 30; Iter   503/ 2483] train: loss: 0.0012680
[Epoch 30; Iter   533/ 2483] train: loss: 0.0014937
[Epoch 29; Iter  1564/ 1862] train: loss: 0.0017598
[Epoch 29; Iter  1594/ 1862] train: loss: 0.0013269
[Epoch 29; Iter  1624/ 1862] train: loss: 0.0043270
[Epoch 29; Iter  1654/ 1862] train: loss: 0.0742617
[Epoch 29; Iter  1684/ 1862] train: loss: 0.0879237
[Epoch 29; Iter  1714/ 1862] train: loss: 0.0017448
[Epoch 29; Iter  1744/ 1862] train: loss: 0.0521807
[Epoch 29; Iter  1774/ 1862] train: loss: 0.0008926
[Epoch 29; Iter  1804/ 1862] train: loss: 0.0013668
[Epoch 29; Iter  1834/ 1862] train: loss: 0.0011828
[Epoch 29] ogbg-molmuv: 0.048318 val loss: 0.013715
[Epoch 29] ogbg-molmuv: 0.069758 test loss: 0.012689
[Epoch 30; Iter     2/ 1862] train: loss: 0.0008679
[Epoch 30; Iter    32/ 1862] train: loss: 0.0012301
[Epoch 30; Iter    62/ 1862] train: loss: 0.0011333
[Epoch 30; Iter    92/ 1862] train: loss: 0.0014158
[Epoch 30; Iter   122/ 1862] train: loss: 0.0017764
[Epoch 30; Iter   152/ 1862] train: loss: 0.0011983
[Epoch 30; Iter   182/ 1862] train: loss: 0.0012340
[Epoch 30; Iter   212/ 1862] train: loss: 0.0020169
[Epoch 30; Iter   242/ 1862] train: loss: 0.0846171
[Epoch 30; Iter   272/ 1862] train: loss: 0.0011006
[Epoch 30; Iter   302/ 1862] train: loss: 0.0011827
[Epoch 30; Iter   332/ 1862] train: loss: 0.0088842
[Epoch 30; Iter   362/ 1862] train: loss: 0.0011762
[Epoch 30; Iter   392/ 1862] train: loss: 0.0010721
[Epoch 30; Iter   422/ 1862] train: loss: 0.0014246
[Epoch 30; Iter   452/ 1862] train: loss: 0.0009982
[Epoch 30; Iter   482/ 1862] train: loss: 0.0499208
[Epoch 30; Iter   512/ 1862] train: loss: 0.0014945
[Epoch 30; Iter   542/ 1862] train: loss: 0.0018183
[Epoch 30; Iter   572/ 1862] train: loss: 0.0565861
[Epoch 30; Iter   602/ 1862] train: loss: 0.0012753
[Epoch 30; Iter   632/ 1862] train: loss: 0.0026694
[Epoch 30; Iter   662/ 1862] train: loss: 0.0443427
[Epoch 30; Iter   692/ 1862] train: loss: 0.0015660
[Epoch 30; Iter   722/ 1862] train: loss: 0.0021245
[Epoch 30; Iter   752/ 1862] train: loss: 0.0017184
[Epoch 30; Iter   782/ 1862] train: loss: 0.0022494
[Epoch 30; Iter   812/ 1862] train: loss: 0.0009014
[Epoch 30; Iter   842/ 1862] train: loss: 0.0028161
[Epoch 30; Iter   872/ 1862] train: loss: 0.0018011
[Epoch 30; Iter   902/ 1862] train: loss: 0.0018445
[Epoch 30; Iter   932/ 1862] train: loss: 0.0011588
[Epoch 30; Iter   962/ 1862] train: loss: 0.0016160
[Epoch 30; Iter   992/ 1862] train: loss: 0.0822730
[Epoch 30; Iter  1022/ 1862] train: loss: 0.0032446
[Epoch 30; Iter  1052/ 1862] train: loss: 0.0011709
[Epoch 30; Iter  1082/ 1862] train: loss: 0.0669537
[Epoch 30; Iter  1112/ 1862] train: loss: 0.0023396
[Epoch 30; Iter  1142/ 1862] train: loss: 0.0020518
[Epoch 30; Iter  1172/ 1862] train: loss: 0.0018789
[Epoch 30; Iter  1202/ 1862] train: loss: 0.0663975
[Epoch 30; Iter  1232/ 1862] train: loss: 0.0022119
[Epoch 30; Iter  1262/ 1862] train: loss: 0.0490873
[Epoch 30; Iter  1292/ 1862] train: loss: 0.0016753
[Epoch 30; Iter  1322/ 1862] train: loss: 0.0036160
[Epoch 30; Iter  1352/ 1862] train: loss: 0.0029076
[Epoch 30; Iter  1382/ 1862] train: loss: 0.0015873
[Epoch 30; Iter  1412/ 1862] train: loss: 0.0026442
[Epoch 30; Iter  1442/ 1862] train: loss: 0.0014543
[Epoch 30; Iter  1472/ 1862] train: loss: 0.0011211
[Epoch 30; Iter  1502/ 1862] train: loss: 0.0008578
[Epoch 30; Iter  1532/ 1862] train: loss: 0.0008663
[Epoch 30; Iter  1562/ 1862] train: loss: 0.0022465
[Epoch 30; Iter  1592/ 1862] train: loss: 0.0620132
[Epoch 30; Iter  1622/ 1862] train: loss: 0.0011023
[Epoch 30; Iter  1652/ 1862] train: loss: 0.0052858
[Epoch 30; Iter  1682/ 1862] train: loss: 0.0051754
[Epoch 30; Iter  1712/ 1862] train: loss: 0.0016420
[Epoch 30; Iter  1742/ 1862] train: loss: 0.0009839
[Epoch 30; Iter  1772/ 1862] train: loss: 0.0010866
[Epoch 30; Iter  1802/ 1862] train: loss: 0.0707704
[Epoch 30; Iter  1832/ 1862] train: loss: 0.0518307
[Epoch 30; Iter  1862/ 1862] train: loss: 0.0014162
[Epoch 30] ogbg-molmuv: 0.032163 val loss: 0.103516
[Epoch 30] ogbg-molmuv: 0.055531 test loss: 0.065757
[Epoch 31; Iter    30/ 1862] train: loss: 0.0010613
[Epoch 31; Iter    60/ 1862] train: loss: 0.0018210
[Epoch 31; Iter    90/ 1862] train: loss: 0.0029339
[Epoch 31; Iter   120/ 1862] train: loss: 0.0015326
[Epoch 31; Iter   150/ 1862] train: loss: 0.0018834
[Epoch 31; Iter   180/ 1862] train: loss: 0.0510111
[Epoch 31; Iter   210/ 1862] train: loss: 0.0013888
[Epoch 31; Iter   240/ 1862] train: loss: 0.0014736
[Epoch 31; Iter   270/ 1862] train: loss: 0.0870820
[Epoch 31; Iter   300/ 1862] train: loss: 0.0028365
[Epoch 31; Iter   330/ 1862] train: loss: 0.0014615
[Epoch 31; Iter   360/ 1862] train: loss: 0.0010461
[Epoch 31; Iter   390/ 1862] train: loss: 0.0362266
[Epoch 31; Iter   420/ 1862] train: loss: 0.0006959
[Epoch 31; Iter   450/ 1862] train: loss: 0.0011024
[Epoch 31; Iter   480/ 1862] train: loss: 0.0010214
[Epoch 31; Iter   510/ 1862] train: loss: 0.0014925
[Epoch 31; Iter   540/ 1862] train: loss: 0.0016186
[Epoch 31; Iter   570/ 1862] train: loss: 0.0017086
[Epoch 31; Iter   600/ 1862] train: loss: 0.0022180
[Epoch 31; Iter   630/ 1862] train: loss: 0.0009775
[Epoch 31; Iter   660/ 1862] train: loss: 0.0013312
[Epoch 31; Iter   690/ 1862] train: loss: 0.0015300
[Epoch 31; Iter   720/ 1862] train: loss: 0.0025457
[Epoch 31; Iter   750/ 1862] train: loss: 0.0012008
[Epoch 31; Iter   780/ 1862] train: loss: 0.0487208
[Epoch 31; Iter   810/ 1862] train: loss: 0.0009347
[Epoch 31; Iter   840/ 1862] train: loss: 0.0012091
[Epoch 31; Iter   870/ 1862] train: loss: 0.0007445
[Epoch 31; Iter   900/ 1862] train: loss: 0.0014823
[Epoch 31; Iter   930/ 1862] train: loss: 0.0145648
[Epoch 31; Iter   960/ 1862] train: loss: 0.0035698
[Epoch 31; Iter   990/ 1862] train: loss: 0.0037738
[Epoch 31; Iter  1020/ 1862] train: loss: 0.0013938
[Epoch 31; Iter  1050/ 1862] train: loss: 0.0019198
[Epoch 31; Iter  1080/ 1862] train: loss: 0.0020579
[Epoch 31; Iter  1110/ 1862] train: loss: 0.0012046
[Epoch 31; Iter  1140/ 1862] train: loss: 0.0015665
[Epoch 31; Iter  1170/ 1862] train: loss: 0.0010468
[Epoch 31; Iter  1200/ 1862] train: loss: 0.0762425
[Epoch 31; Iter  1230/ 1862] train: loss: 0.0023333
[Epoch 31; Iter  1260/ 1862] train: loss: 0.0787479
[Epoch 31; Iter  1290/ 1862] train: loss: 0.0014308
[Epoch 31; Iter  1320/ 1862] train: loss: 0.0009983
[Epoch 31; Iter  1350/ 1862] train: loss: 0.0009601
[Epoch 31; Iter  1380/ 1862] train: loss: 0.0676747
[Epoch 31; Iter  1410/ 1862] train: loss: 0.0010170
[Epoch 31; Iter  1440/ 1862] train: loss: 0.0008665
[Epoch 31; Iter  1470/ 1862] train: loss: 0.0642212
[Epoch 31; Iter  1500/ 1862] train: loss: 0.0010200
[Epoch 31; Iter  1530/ 1862] train: loss: 0.0011003
[Epoch 31; Iter  1560/ 1862] train: loss: 0.0842262
[Epoch 31; Iter  1590/ 1862] train: loss: 0.0018780
[Epoch 31; Iter  1620/ 1862] train: loss: 0.0017230
[Epoch 31; Iter  1650/ 1862] train: loss: 0.0016803
[Epoch 31; Iter  1680/ 1862] train: loss: 0.0012968
[Epoch 31; Iter  1710/ 1862] train: loss: 0.0012712
[Epoch 31; Iter  1740/ 1862] train: loss: 0.0023273
[Epoch 31; Iter  1770/ 1862] train: loss: 0.0014633
[Epoch 31; Iter  1800/ 1862] train: loss: 0.0012240
[Epoch 31; Iter  1830/ 1862] train: loss: 0.0014890
[Epoch 31; Iter  1860/ 1862] train: loss: 0.0024913
[Epoch 31] ogbg-molmuv: 0.039794 val loss: 0.014546
[Epoch 31] ogbg-molmuv: 0.087091 test loss: 0.012473
[Epoch 32; Iter    28/ 1862] train: loss: 0.0052978
[Epoch 32; Iter    58/ 1862] train: loss: 0.0010031
[Epoch 32; Iter    88/ 1862] train: loss: 0.0012208
[Epoch 32; Iter   118/ 1862] train: loss: 0.0019799
[Epoch 32; Iter   148/ 1862] train: loss: 0.0016936
[Epoch 32; Iter   178/ 1862] train: loss: 0.0016254
[Epoch 32; Iter   208/ 1862] train: loss: 0.0016295
[Epoch 32; Iter   238/ 1862] train: loss: 0.0012255
[Epoch 32; Iter   268/ 1862] train: loss: 0.0013932
[Epoch 32; Iter   298/ 1862] train: loss: 0.0013590
[Epoch 32; Iter   328/ 1862] train: loss: 0.0015805
[Epoch 32; Iter   358/ 1862] train: loss: 0.0010274
[Epoch 32; Iter   388/ 1862] train: loss: 0.0012719
[Epoch 32; Iter   418/ 1862] train: loss: 0.0013858
[Epoch 32; Iter   448/ 1862] train: loss: 0.0014817
[Epoch 32; Iter   478/ 1862] train: loss: 0.0010524
[Epoch 28; Iter   939/ 2483] train: loss: 0.0022020
[Epoch 28; Iter   969/ 2483] train: loss: 0.0013476
[Epoch 28; Iter   999/ 2483] train: loss: 0.0055281
[Epoch 28; Iter  1029/ 2483] train: loss: 0.0013038
[Epoch 28; Iter  1059/ 2483] train: loss: 0.0018635
[Epoch 28; Iter  1089/ 2483] train: loss: 0.0013119
[Epoch 28; Iter  1119/ 2483] train: loss: 0.0008835
[Epoch 28; Iter  1149/ 2483] train: loss: 0.0023673
[Epoch 28; Iter  1179/ 2483] train: loss: 0.0038121
[Epoch 28; Iter  1209/ 2483] train: loss: 0.0016051
[Epoch 28; Iter  1239/ 2483] train: loss: 0.0014649
[Epoch 28; Iter  1269/ 2483] train: loss: 0.0012837
[Epoch 28; Iter  1299/ 2483] train: loss: 0.0018713
[Epoch 28; Iter  1329/ 2483] train: loss: 0.0013303
[Epoch 28; Iter  1359/ 2483] train: loss: 0.0015529
[Epoch 28; Iter  1389/ 2483] train: loss: 0.0007192
[Epoch 28; Iter  1419/ 2483] train: loss: 0.0269572
[Epoch 28; Iter  1449/ 2483] train: loss: 0.0019499
[Epoch 28; Iter  1479/ 2483] train: loss: 0.0018955
[Epoch 28; Iter  1509/ 2483] train: loss: 0.0013972
[Epoch 28; Iter  1539/ 2483] train: loss: 0.0015142
[Epoch 28; Iter  1569/ 2483] train: loss: 0.0034625
[Epoch 28; Iter  1599/ 2483] train: loss: 0.0014789
[Epoch 28; Iter  1629/ 2483] train: loss: 0.0040940
[Epoch 28; Iter  1659/ 2483] train: loss: 0.0014995
[Epoch 28; Iter  1689/ 2483] train: loss: 0.0011780
[Epoch 28; Iter  1719/ 2483] train: loss: 0.0026593
[Epoch 28; Iter  1749/ 2483] train: loss: 0.0014764
[Epoch 28; Iter  1779/ 2483] train: loss: 0.0385291
[Epoch 28; Iter  1809/ 2483] train: loss: 0.0013218
[Epoch 28; Iter  1839/ 2483] train: loss: 0.0018333
[Epoch 28; Iter  1869/ 2483] train: loss: 0.0018250
[Epoch 28; Iter  1899/ 2483] train: loss: 0.0009986
[Epoch 28; Iter  1929/ 2483] train: loss: 0.0011344
[Epoch 28; Iter  1959/ 2483] train: loss: 0.0016380
[Epoch 28; Iter  1989/ 2483] train: loss: 0.0014071
[Epoch 28; Iter  2019/ 2483] train: loss: 0.0018068
[Epoch 28; Iter  2049/ 2483] train: loss: 0.0023296
[Epoch 28; Iter  2079/ 2483] train: loss: 0.0009622
[Epoch 28; Iter  2109/ 2483] train: loss: 0.0015511
[Epoch 28; Iter  2139/ 2483] train: loss: 0.0673377
[Epoch 28; Iter  2169/ 2483] train: loss: 0.0017374
[Epoch 28; Iter  2199/ 2483] train: loss: 0.0012435
[Epoch 28; Iter  2229/ 2483] train: loss: 0.0030827
[Epoch 28; Iter  2259/ 2483] train: loss: 0.0019560
[Epoch 28; Iter  2289/ 2483] train: loss: 0.0010920
[Epoch 28; Iter  2319/ 2483] train: loss: 0.0007209
[Epoch 28; Iter  2349/ 2483] train: loss: 0.0012366
[Epoch 28; Iter  2379/ 2483] train: loss: 0.0036525
[Epoch 28; Iter  2409/ 2483] train: loss: 0.0039651
[Epoch 28; Iter  2439/ 2483] train: loss: 0.0020161
[Epoch 28; Iter  2469/ 2483] train: loss: 0.0015830
[Epoch 28] ogbg-molmuv: 0.137660 val loss: 0.009718
[Epoch 28] ogbg-molmuv: 0.145397 test loss: 0.050574
[Epoch 29; Iter    16/ 2483] train: loss: 0.0840675
[Epoch 29; Iter    46/ 2483] train: loss: 0.0015533
[Epoch 29; Iter    76/ 2483] train: loss: 0.0040942
[Epoch 29; Iter   106/ 2483] train: loss: 0.0656396
[Epoch 29; Iter   136/ 2483] train: loss: 0.0008926
[Epoch 29; Iter   166/ 2483] train: loss: 0.0018787
[Epoch 29; Iter   196/ 2483] train: loss: 0.0025334
[Epoch 29; Iter   226/ 2483] train: loss: 0.0015875
[Epoch 29; Iter   256/ 2483] train: loss: 0.0011347
[Epoch 29; Iter   286/ 2483] train: loss: 0.0012522
[Epoch 29; Iter   316/ 2483] train: loss: 0.0012696
[Epoch 29; Iter   346/ 2483] train: loss: 0.0013819
[Epoch 29; Iter   376/ 2483] train: loss: 0.0017408
[Epoch 29; Iter   406/ 2483] train: loss: 0.0015987
[Epoch 29; Iter   436/ 2483] train: loss: 0.0024446
[Epoch 29; Iter   466/ 2483] train: loss: 0.0010196
[Epoch 29; Iter   496/ 2483] train: loss: 0.0636970
[Epoch 29; Iter   526/ 2483] train: loss: 0.0068610
[Epoch 29; Iter   556/ 2483] train: loss: 0.0025579
[Epoch 29; Iter   586/ 2483] train: loss: 0.0722201
[Epoch 29; Iter   616/ 2483] train: loss: 0.0015058
[Epoch 29; Iter   646/ 2483] train: loss: 0.0037809
[Epoch 29; Iter   676/ 2483] train: loss: 0.0010384
[Epoch 29; Iter   706/ 2483] train: loss: 0.0013296
[Epoch 29; Iter   736/ 2483] train: loss: 0.0011486
[Epoch 29; Iter   766/ 2483] train: loss: 0.0013198
[Epoch 29; Iter   796/ 2483] train: loss: 0.0014361
[Epoch 29; Iter   826/ 2483] train: loss: 0.0015536
[Epoch 29; Iter   856/ 2483] train: loss: 0.0016943
[Epoch 29; Iter   886/ 2483] train: loss: 0.0016581
[Epoch 29; Iter   916/ 2483] train: loss: 0.0016929
[Epoch 29; Iter   946/ 2483] train: loss: 0.0911166
[Epoch 29; Iter   976/ 2483] train: loss: 0.0013437
[Epoch 29; Iter  1006/ 2483] train: loss: 0.0014078
[Epoch 29; Iter  1036/ 2483] train: loss: 0.0922788
[Epoch 29; Iter  1066/ 2483] train: loss: 0.0019561
[Epoch 29; Iter  1096/ 2483] train: loss: 0.0029591
[Epoch 29; Iter  1126/ 2483] train: loss: 0.0019672
[Epoch 29; Iter  1156/ 2483] train: loss: 0.0024355
[Epoch 29; Iter  1186/ 2483] train: loss: 0.0012635
[Epoch 29; Iter  1216/ 2483] train: loss: 0.0021995
[Epoch 29; Iter  1246/ 2483] train: loss: 0.0016008
[Epoch 29; Iter  1276/ 2483] train: loss: 0.0011543
[Epoch 29; Iter  1306/ 2483] train: loss: 0.0018998
[Epoch 29; Iter  1336/ 2483] train: loss: 0.0013564
[Epoch 29; Iter  1366/ 2483] train: loss: 0.0023359
[Epoch 29; Iter  1396/ 2483] train: loss: 0.0563596
[Epoch 29; Iter  1426/ 2483] train: loss: 0.0050377
[Epoch 29; Iter  1456/ 2483] train: loss: 0.0011566
[Epoch 29; Iter  1486/ 2483] train: loss: 0.0008960
[Epoch 29; Iter  1516/ 2483] train: loss: 0.0013031
[Epoch 29; Iter  1546/ 2483] train: loss: 0.1321703
[Epoch 29; Iter  1576/ 2483] train: loss: 0.0016263
[Epoch 29; Iter  1606/ 2483] train: loss: 0.0321184
[Epoch 29; Iter  1636/ 2483] train: loss: 0.0012090
[Epoch 29; Iter  1666/ 2483] train: loss: 0.0013376
[Epoch 29; Iter  1696/ 2483] train: loss: 0.0016239
[Epoch 29; Iter  1726/ 2483] train: loss: 0.0200699
[Epoch 29; Iter  1756/ 2483] train: loss: 0.0012839
[Epoch 29; Iter  1786/ 2483] train: loss: 0.0013743
[Epoch 29; Iter  1816/ 2483] train: loss: 0.0012321
[Epoch 29; Iter  1846/ 2483] train: loss: 0.0634078
[Epoch 29; Iter  1876/ 2483] train: loss: 0.0020180
[Epoch 29; Iter  1906/ 2483] train: loss: 0.0011451
[Epoch 29; Iter  1936/ 2483] train: loss: 0.0016596
[Epoch 29; Iter  1966/ 2483] train: loss: 0.0020928
[Epoch 29; Iter  1996/ 2483] train: loss: 0.1100536
[Epoch 29; Iter  2026/ 2483] train: loss: 0.0016880
[Epoch 29; Iter  2056/ 2483] train: loss: 0.0012404
[Epoch 29; Iter  2086/ 2483] train: loss: 0.0018808
[Epoch 29; Iter  2116/ 2483] train: loss: 0.0013583
[Epoch 29; Iter  2146/ 2483] train: loss: 0.0016853
[Epoch 29; Iter  2176/ 2483] train: loss: 0.0013893
[Epoch 29; Iter  2206/ 2483] train: loss: 0.0009049
[Epoch 29; Iter  2236/ 2483] train: loss: 0.0013485
[Epoch 29; Iter  2266/ 2483] train: loss: 0.0014130
[Epoch 29; Iter  2296/ 2483] train: loss: 0.0019798
[Epoch 29; Iter  2326/ 2483] train: loss: 0.0498349
[Epoch 29; Iter  2356/ 2483] train: loss: 0.0019052
[Epoch 29; Iter  2386/ 2483] train: loss: 0.0012336
[Epoch 29; Iter  2416/ 2483] train: loss: 0.0026375
[Epoch 29; Iter  2446/ 2483] train: loss: 0.0028634
[Epoch 29; Iter  2476/ 2483] train: loss: 0.0018522
[Epoch 29] ogbg-molmuv: 0.141202 val loss: 0.009913
[Epoch 29] ogbg-molmuv: 0.157684 test loss: 0.015982
[Epoch 30; Iter    23/ 2483] train: loss: 0.0313449
[Epoch 30; Iter    53/ 2483] train: loss: 0.0015417
[Epoch 30; Iter    83/ 2483] train: loss: 0.0015950
[Epoch 30; Iter   113/ 2483] train: loss: 0.0011068
[Epoch 30; Iter   143/ 2483] train: loss: 0.0022088
[Epoch 30; Iter   173/ 2483] train: loss: 0.0011332
[Epoch 30; Iter   203/ 2483] train: loss: 0.0026810
[Epoch 30; Iter   233/ 2483] train: loss: 0.0011419
[Epoch 30; Iter   263/ 2483] train: loss: 0.0003990
[Epoch 30; Iter   293/ 2483] train: loss: 0.0013113
[Epoch 30; Iter   323/ 2483] train: loss: 0.0012751
[Epoch 30; Iter   353/ 2483] train: loss: 0.0284706
[Epoch 30; Iter   383/ 2483] train: loss: 0.0831511
[Epoch 30; Iter   413/ 2483] train: loss: 0.0018451
[Epoch 30; Iter   443/ 2483] train: loss: 0.0019189
[Epoch 30; Iter   473/ 2483] train: loss: 0.0015812
[Epoch 30; Iter   503/ 2483] train: loss: 0.0461825
[Epoch 30; Iter   533/ 2483] train: loss: 0.0015794
[Epoch 30; Iter   132/ 2172] train: loss: 0.0009480
[Epoch 30; Iter   162/ 2172] train: loss: 0.0009372
[Epoch 30; Iter   192/ 2172] train: loss: 0.0013312
[Epoch 30; Iter   222/ 2172] train: loss: 0.0616190
[Epoch 30; Iter   252/ 2172] train: loss: 0.0010080
[Epoch 30; Iter   282/ 2172] train: loss: 0.0017822
[Epoch 30; Iter   312/ 2172] train: loss: 0.0013017
[Epoch 30; Iter   342/ 2172] train: loss: 0.0014575
[Epoch 30; Iter   372/ 2172] train: loss: 0.0016073
[Epoch 30; Iter   402/ 2172] train: loss: 0.0411898
[Epoch 30; Iter   432/ 2172] train: loss: 0.0017913
[Epoch 30; Iter   462/ 2172] train: loss: 0.0009528
[Epoch 30; Iter   492/ 2172] train: loss: 0.0011277
[Epoch 30; Iter   522/ 2172] train: loss: 0.0012763
[Epoch 30; Iter   552/ 2172] train: loss: 0.0012505
[Epoch 30; Iter   582/ 2172] train: loss: 0.0012378
[Epoch 30; Iter   612/ 2172] train: loss: 0.0035272
[Epoch 30; Iter   642/ 2172] train: loss: 0.0473482
[Epoch 30; Iter   672/ 2172] train: loss: 0.0294252
[Epoch 30; Iter   702/ 2172] train: loss: 0.0007486
[Epoch 30; Iter   732/ 2172] train: loss: 0.0080956
[Epoch 30; Iter   762/ 2172] train: loss: 0.0011202
[Epoch 30; Iter   792/ 2172] train: loss: 0.0630592
[Epoch 30; Iter   822/ 2172] train: loss: 0.0057211
[Epoch 30; Iter   852/ 2172] train: loss: 0.0021134
[Epoch 30; Iter   882/ 2172] train: loss: 0.0009451
[Epoch 30; Iter   912/ 2172] train: loss: 0.0287405
[Epoch 30; Iter   942/ 2172] train: loss: 0.0479716
[Epoch 30; Iter   972/ 2172] train: loss: 0.0023829
[Epoch 30; Iter  1002/ 2172] train: loss: 0.0037747
[Epoch 30; Iter  1032/ 2172] train: loss: 0.0012248
[Epoch 30; Iter  1062/ 2172] train: loss: 0.0786178
[Epoch 30; Iter  1092/ 2172] train: loss: 0.0011711
[Epoch 30; Iter  1122/ 2172] train: loss: 0.0022923
[Epoch 30; Iter  1152/ 2172] train: loss: 0.0010929
[Epoch 30; Iter  1182/ 2172] train: loss: 0.0595901
[Epoch 30; Iter  1212/ 2172] train: loss: 0.0024548
[Epoch 30; Iter  1242/ 2172] train: loss: 0.0014435
[Epoch 30; Iter  1272/ 2172] train: loss: 0.0023481
[Epoch 30; Iter  1302/ 2172] train: loss: 0.0008013
[Epoch 30; Iter  1332/ 2172] train: loss: 0.0038885
[Epoch 30; Iter  1362/ 2172] train: loss: 0.0015230
[Epoch 30; Iter  1392/ 2172] train: loss: 0.0029218
[Epoch 30; Iter  1422/ 2172] train: loss: 0.0235762
[Epoch 30; Iter  1452/ 2172] train: loss: 0.0013137
[Epoch 30; Iter  1482/ 2172] train: loss: 0.0013721
[Epoch 30; Iter  1512/ 2172] train: loss: 0.0017172
[Epoch 30; Iter  1542/ 2172] train: loss: 0.0015735
[Epoch 30; Iter  1572/ 2172] train: loss: 0.0488277
[Epoch 30; Iter  1602/ 2172] train: loss: 0.0025105
[Epoch 30; Iter  1632/ 2172] train: loss: 0.0013646
[Epoch 30; Iter  1662/ 2172] train: loss: 0.0014991
[Epoch 30; Iter  1692/ 2172] train: loss: 0.0014930
[Epoch 30; Iter  1722/ 2172] train: loss: 0.0013424
[Epoch 30; Iter  1752/ 2172] train: loss: 0.0010171
[Epoch 30; Iter  1782/ 2172] train: loss: 0.0021986
[Epoch 30; Iter  1812/ 2172] train: loss: 0.0010115
[Epoch 30; Iter  1842/ 2172] train: loss: 0.0010561
[Epoch 30; Iter  1872/ 2172] train: loss: 0.0013020
[Epoch 30; Iter  1902/ 2172] train: loss: 0.0016940
[Epoch 30; Iter  1932/ 2172] train: loss: 0.0008745
[Epoch 30; Iter  1962/ 2172] train: loss: 0.0574755
[Epoch 30; Iter  1992/ 2172] train: loss: 0.0188458
[Epoch 30; Iter  2022/ 2172] train: loss: 0.0008612
[Epoch 30; Iter  2052/ 2172] train: loss: 0.0330468
[Epoch 30; Iter  2082/ 2172] train: loss: 0.0014553
[Epoch 30; Iter  2112/ 2172] train: loss: 0.0012367
[Epoch 30; Iter  2142/ 2172] train: loss: 0.0040407
[Epoch 30; Iter  2172/ 2172] train: loss: 0.0008175
[Epoch 30] ogbg-molmuv: 0.080257 val loss: 0.059139
[Epoch 30] ogbg-molmuv: 0.111264 test loss: 0.166355
[Epoch 31; Iter    30/ 2172] train: loss: 0.0009567
[Epoch 31; Iter    60/ 2172] train: loss: 0.0540086
[Epoch 31; Iter    90/ 2172] train: loss: 0.0010380
[Epoch 31; Iter   120/ 2172] train: loss: 0.0013338
[Epoch 31; Iter   150/ 2172] train: loss: 0.0006665
[Epoch 31; Iter   180/ 2172] train: loss: 0.0016839
[Epoch 31; Iter   210/ 2172] train: loss: 0.0013211
[Epoch 31; Iter   240/ 2172] train: loss: 0.0011767
[Epoch 31; Iter   270/ 2172] train: loss: 0.0029882
[Epoch 31; Iter   300/ 2172] train: loss: 0.0012455
[Epoch 31; Iter   330/ 2172] train: loss: 0.0018117
[Epoch 31; Iter   360/ 2172] train: loss: 0.0009048
[Epoch 31; Iter   390/ 2172] train: loss: 0.0014490
[Epoch 31; Iter   420/ 2172] train: loss: 0.0022889
[Epoch 31; Iter   450/ 2172] train: loss: 0.0010829
[Epoch 31; Iter   480/ 2172] train: loss: 0.0009129
[Epoch 31; Iter   510/ 2172] train: loss: 0.0704081
[Epoch 31; Iter   540/ 2172] train: loss: 0.0022606
[Epoch 31; Iter   570/ 2172] train: loss: 0.0044187
[Epoch 31; Iter   600/ 2172] train: loss: 0.0020429
[Epoch 31; Iter   630/ 2172] train: loss: 0.0011158
[Epoch 31; Iter   660/ 2172] train: loss: 0.0021641
[Epoch 31; Iter   690/ 2172] train: loss: 0.0035005
[Epoch 31; Iter   720/ 2172] train: loss: 0.0014978
[Epoch 31; Iter   750/ 2172] train: loss: 0.0013284
[Epoch 31; Iter   780/ 2172] train: loss: 0.0052399
[Epoch 31; Iter   810/ 2172] train: loss: 0.0013150
[Epoch 31; Iter   840/ 2172] train: loss: 0.0016702
[Epoch 31; Iter   870/ 2172] train: loss: 0.0007906
[Epoch 31; Iter   900/ 2172] train: loss: 0.0094274
[Epoch 31; Iter   930/ 2172] train: loss: 0.0010582
[Epoch 31; Iter   960/ 2172] train: loss: 0.0007497
[Epoch 31; Iter   990/ 2172] train: loss: 0.0018127
[Epoch 31; Iter  1020/ 2172] train: loss: 0.1063745
[Epoch 31; Iter  1050/ 2172] train: loss: 0.0053197
[Epoch 31; Iter  1080/ 2172] train: loss: 0.0716999
[Epoch 31; Iter  1110/ 2172] train: loss: 0.0009028
[Epoch 31; Iter  1140/ 2172] train: loss: 0.0021192
[Epoch 31; Iter  1170/ 2172] train: loss: 0.0019779
[Epoch 31; Iter  1200/ 2172] train: loss: 0.0011364
[Epoch 31; Iter  1230/ 2172] train: loss: 0.0017199
[Epoch 31; Iter  1260/ 2172] train: loss: 0.0012144
[Epoch 31; Iter  1290/ 2172] train: loss: 0.0020700
[Epoch 31; Iter  1320/ 2172] train: loss: 0.0009684
[Epoch 31; Iter  1350/ 2172] train: loss: 0.0013034
[Epoch 31; Iter  1380/ 2172] train: loss: 0.0643962
[Epoch 31; Iter  1410/ 2172] train: loss: 0.0011305
[Epoch 31; Iter  1440/ 2172] train: loss: 0.0022454
[Epoch 31; Iter  1470/ 2172] train: loss: 0.0014183
[Epoch 31; Iter  1500/ 2172] train: loss: 0.0012245
[Epoch 31; Iter  1530/ 2172] train: loss: 0.0033716
[Epoch 31; Iter  1560/ 2172] train: loss: 0.0014889
[Epoch 31; Iter  1590/ 2172] train: loss: 0.0015580
[Epoch 31; Iter  1620/ 2172] train: loss: 0.0011460
[Epoch 31; Iter  1650/ 2172] train: loss: 0.0008490
[Epoch 31; Iter  1680/ 2172] train: loss: 0.0018204
[Epoch 31; Iter  1710/ 2172] train: loss: 0.0797202
[Epoch 31; Iter  1740/ 2172] train: loss: 0.0005016
[Epoch 31; Iter  1770/ 2172] train: loss: 0.0028218
[Epoch 31; Iter  1800/ 2172] train: loss: 0.0011816
[Epoch 31; Iter  1830/ 2172] train: loss: 0.0018791
[Epoch 31; Iter  1860/ 2172] train: loss: 0.0012693
[Epoch 31; Iter  1890/ 2172] train: loss: 0.0017410
[Epoch 31; Iter  1920/ 2172] train: loss: 0.0010760
[Epoch 31; Iter  1950/ 2172] train: loss: 0.0020152
[Epoch 31; Iter  1980/ 2172] train: loss: 0.0006659
[Epoch 31; Iter  2010/ 2172] train: loss: 0.0940060
[Epoch 31; Iter  2040/ 2172] train: loss: 0.0443965
[Epoch 31; Iter  2070/ 2172] train: loss: 0.0010476
[Epoch 31; Iter  2100/ 2172] train: loss: 0.0064595
[Epoch 31; Iter  2130/ 2172] train: loss: 0.0017098
[Epoch 31; Iter  2160/ 2172] train: loss: 0.0024326
[Epoch 31] ogbg-molmuv: 0.084787 val loss: 0.011890
[Epoch 31] ogbg-molmuv: 0.107248 test loss: 0.036554
[Epoch 32; Iter    18/ 2172] train: loss: 0.0009133
[Epoch 32; Iter    48/ 2172] train: loss: 0.0229466
[Epoch 32; Iter    78/ 2172] train: loss: 0.0009005
[Epoch 32; Iter   108/ 2172] train: loss: 0.0016166
[Epoch 32; Iter   138/ 2172] train: loss: 0.0012352
[Epoch 32; Iter   168/ 2172] train: loss: 0.0009579
[Epoch 32; Iter   198/ 2172] train: loss: 0.0014118
[Epoch 32; Iter   228/ 2172] train: loss: 0.0013318
[Epoch 32; Iter   258/ 2172] train: loss: 0.0011518
[Epoch 32; Iter   288/ 2172] train: loss: 0.0012374
[Epoch 32; Iter   318/ 2172] train: loss: 0.0009241
[Epoch 32; Iter   348/ 2172] train: loss: 0.0011249
[Epoch 30; Iter   132/ 2172] train: loss: 0.0795311
[Epoch 30; Iter   162/ 2172] train: loss: 0.0020855
[Epoch 30; Iter   192/ 2172] train: loss: 0.0017442
[Epoch 30; Iter   222/ 2172] train: loss: 0.0014701
[Epoch 30; Iter   252/ 2172] train: loss: 0.0554723
[Epoch 30; Iter   282/ 2172] train: loss: 0.0036917
[Epoch 30; Iter   312/ 2172] train: loss: 0.0010566
[Epoch 30; Iter   342/ 2172] train: loss: 0.0015960
[Epoch 30; Iter   372/ 2172] train: loss: 0.0008204
[Epoch 30; Iter   402/ 2172] train: loss: 0.0017791
[Epoch 30; Iter   432/ 2172] train: loss: 0.0008337
[Epoch 30; Iter   462/ 2172] train: loss: 0.0010477
[Epoch 30; Iter   492/ 2172] train: loss: 0.0012069
[Epoch 30; Iter   522/ 2172] train: loss: 0.0031450
[Epoch 30; Iter   552/ 2172] train: loss: 0.0065763
[Epoch 30; Iter   582/ 2172] train: loss: 0.0011644
[Epoch 30; Iter   612/ 2172] train: loss: 0.0009608
[Epoch 30; Iter   642/ 2172] train: loss: 0.0431794
[Epoch 30; Iter   672/ 2172] train: loss: 0.0635655
[Epoch 30; Iter   702/ 2172] train: loss: 0.0243144
[Epoch 30; Iter   732/ 2172] train: loss: 0.0355400
[Epoch 30; Iter   762/ 2172] train: loss: 0.0525938
[Epoch 30; Iter   792/ 2172] train: loss: 0.0027083
[Epoch 30; Iter   822/ 2172] train: loss: 0.0022271
[Epoch 30; Iter   852/ 2172] train: loss: 0.0021210
[Epoch 30; Iter   882/ 2172] train: loss: 0.0317562
[Epoch 30; Iter   912/ 2172] train: loss: 0.0012637
[Epoch 30; Iter   942/ 2172] train: loss: 0.0023887
[Epoch 30; Iter   972/ 2172] train: loss: 0.0008308
[Epoch 30; Iter  1002/ 2172] train: loss: 0.0009637
[Epoch 30; Iter  1032/ 2172] train: loss: 0.0008433
[Epoch 30; Iter  1062/ 2172] train: loss: 0.0018261
[Epoch 30; Iter  1092/ 2172] train: loss: 0.0018308
[Epoch 30; Iter  1122/ 2172] train: loss: 0.0673280
[Epoch 30; Iter  1152/ 2172] train: loss: 0.0011804
[Epoch 30; Iter  1182/ 2172] train: loss: 0.0023611
[Epoch 30; Iter  1212/ 2172] train: loss: 0.0013998
[Epoch 30; Iter  1242/ 2172] train: loss: 0.0015890
[Epoch 30; Iter  1272/ 2172] train: loss: 0.0015028
[Epoch 30; Iter  1302/ 2172] train: loss: 0.0023848
[Epoch 30; Iter  1332/ 2172] train: loss: 0.0716083
[Epoch 30; Iter  1362/ 2172] train: loss: 0.0025434
[Epoch 30; Iter  1392/ 2172] train: loss: 0.0012355
[Epoch 30; Iter  1422/ 2172] train: loss: 0.0011287
[Epoch 30; Iter  1452/ 2172] train: loss: 0.0013750
[Epoch 30; Iter  1482/ 2172] train: loss: 0.0008921
[Epoch 30; Iter  1512/ 2172] train: loss: 0.0023947
[Epoch 30; Iter  1542/ 2172] train: loss: 0.0017478
[Epoch 30; Iter  1572/ 2172] train: loss: 0.0007688
[Epoch 30; Iter  1602/ 2172] train: loss: 0.0009659
[Epoch 30; Iter  1632/ 2172] train: loss: 0.0492058
[Epoch 30; Iter  1662/ 2172] train: loss: 0.0589228
[Epoch 30; Iter  1692/ 2172] train: loss: 0.0007690
[Epoch 30; Iter  1722/ 2172] train: loss: 0.0014285
[Epoch 30; Iter  1752/ 2172] train: loss: 0.0014522
[Epoch 30; Iter  1782/ 2172] train: loss: 0.0025192
[Epoch 30; Iter  1812/ 2172] train: loss: 0.0025312
[Epoch 30; Iter  1842/ 2172] train: loss: 0.0015442
[Epoch 30; Iter  1872/ 2172] train: loss: 0.0023996
[Epoch 30; Iter  1902/ 2172] train: loss: 0.0030079
[Epoch 30; Iter  1932/ 2172] train: loss: 0.0027594
[Epoch 30; Iter  1962/ 2172] train: loss: 0.0522691
[Epoch 30; Iter  1992/ 2172] train: loss: 0.0014844
[Epoch 30; Iter  2022/ 2172] train: loss: 0.0020320
[Epoch 30; Iter  2052/ 2172] train: loss: 0.0016280
[Epoch 30; Iter  2082/ 2172] train: loss: 0.0011588
[Epoch 30; Iter  2112/ 2172] train: loss: 0.0016648
[Epoch 30; Iter  2142/ 2172] train: loss: 0.0130818
[Epoch 30; Iter  2172/ 2172] train: loss: 0.0745679
[Epoch 30] ogbg-molmuv: 0.061535 val loss: 0.011949
[Epoch 30] ogbg-molmuv: 0.115323 test loss: 0.014468
[Epoch 31; Iter    30/ 2172] train: loss: 0.0009839
[Epoch 31; Iter    60/ 2172] train: loss: 0.0009139
[Epoch 31; Iter    90/ 2172] train: loss: 0.0011261
[Epoch 31; Iter   120/ 2172] train: loss: 0.0019422
[Epoch 31; Iter   150/ 2172] train: loss: 0.0013572
[Epoch 31; Iter   180/ 2172] train: loss: 0.0017524
[Epoch 31; Iter   210/ 2172] train: loss: 0.0011022
[Epoch 31; Iter   240/ 2172] train: loss: 0.0033000
[Epoch 31; Iter   270/ 2172] train: loss: 0.0415434
[Epoch 31; Iter   300/ 2172] train: loss: 0.0010648
[Epoch 31; Iter   330/ 2172] train: loss: 0.0011808
[Epoch 31; Iter   360/ 2172] train: loss: 0.0013020
[Epoch 31; Iter   390/ 2172] train: loss: 0.0245007
[Epoch 31; Iter   420/ 2172] train: loss: 0.0014966
[Epoch 31; Iter   450/ 2172] train: loss: 0.0011863
[Epoch 31; Iter   480/ 2172] train: loss: 0.0016290
[Epoch 31; Iter   510/ 2172] train: loss: 0.0012680
[Epoch 31; Iter   540/ 2172] train: loss: 0.0453656
[Epoch 31; Iter   570/ 2172] train: loss: 0.0621667
[Epoch 31; Iter   600/ 2172] train: loss: 0.0015070
[Epoch 31; Iter   630/ 2172] train: loss: 0.0025865
[Epoch 31; Iter   660/ 2172] train: loss: 0.0008919
[Epoch 31; Iter   690/ 2172] train: loss: 0.0009456
[Epoch 31; Iter   720/ 2172] train: loss: 0.0028327
[Epoch 31; Iter   750/ 2172] train: loss: 0.0046269
[Epoch 31; Iter   780/ 2172] train: loss: 0.0018792
[Epoch 31; Iter   810/ 2172] train: loss: 0.0019574
[Epoch 31; Iter   840/ 2172] train: loss: 0.0007078
[Epoch 31; Iter   870/ 2172] train: loss: 0.0011423
[Epoch 31; Iter   900/ 2172] train: loss: 0.0011289
[Epoch 31; Iter   930/ 2172] train: loss: 0.0008737
[Epoch 31; Iter   960/ 2172] train: loss: 0.0006720
[Epoch 31; Iter   990/ 2172] train: loss: 0.0697105
[Epoch 31; Iter  1020/ 2172] train: loss: 0.0017242
[Epoch 31; Iter  1050/ 2172] train: loss: 0.0009080
[Epoch 31; Iter  1080/ 2172] train: loss: 0.0015633
[Epoch 31; Iter  1110/ 2172] train: loss: 0.0020428
[Epoch 31; Iter  1140/ 2172] train: loss: 0.0022629
[Epoch 31; Iter  1170/ 2172] train: loss: 0.0017165
[Epoch 31; Iter  1200/ 2172] train: loss: 0.0012546
[Epoch 31; Iter  1230/ 2172] train: loss: 0.0543619
[Epoch 31; Iter  1260/ 2172] train: loss: 0.0024583
[Epoch 31; Iter  1290/ 2172] train: loss: 0.0022027
[Epoch 31; Iter  1320/ 2172] train: loss: 0.0026533
[Epoch 31; Iter  1350/ 2172] train: loss: 0.0047251
[Epoch 31; Iter  1380/ 2172] train: loss: 0.0017758
[Epoch 31; Iter  1410/ 2172] train: loss: 0.0011068
[Epoch 31; Iter  1440/ 2172] train: loss: 0.0012070
[Epoch 31; Iter  1470/ 2172] train: loss: 0.0011877
[Epoch 31; Iter  1500/ 2172] train: loss: 0.0921664
[Epoch 31; Iter  1530/ 2172] train: loss: 0.0015246
[Epoch 31; Iter  1560/ 2172] train: loss: 0.0456070
[Epoch 31; Iter  1590/ 2172] train: loss: 0.0018987
[Epoch 31; Iter  1620/ 2172] train: loss: 0.0020182
[Epoch 31; Iter  1650/ 2172] train: loss: 0.0016553
[Epoch 31; Iter  1680/ 2172] train: loss: 0.0013397
[Epoch 31; Iter  1710/ 2172] train: loss: 0.0323395
[Epoch 31; Iter  1740/ 2172] train: loss: 0.0033229
[Epoch 31; Iter  1770/ 2172] train: loss: 0.0012363
[Epoch 31; Iter  1800/ 2172] train: loss: 0.0015717
[Epoch 31; Iter  1830/ 2172] train: loss: 0.0024058
[Epoch 31; Iter  1860/ 2172] train: loss: 0.0637407
[Epoch 31; Iter  1890/ 2172] train: loss: 0.0014300
[Epoch 31; Iter  1920/ 2172] train: loss: 0.0010680
[Epoch 31; Iter  1950/ 2172] train: loss: 0.0011358
[Epoch 31; Iter  1980/ 2172] train: loss: 0.0026270
[Epoch 31; Iter  2010/ 2172] train: loss: 0.0096677
[Epoch 31; Iter  2040/ 2172] train: loss: 0.0397813
[Epoch 31; Iter  2070/ 2172] train: loss: 0.0018879
[Epoch 31; Iter  2100/ 2172] train: loss: 0.0021001
[Epoch 31; Iter  2130/ 2172] train: loss: 0.0639398
[Epoch 31; Iter  2160/ 2172] train: loss: 0.0018710
[Epoch 31] ogbg-molmuv: 0.049973 val loss: 0.062329
[Epoch 31] ogbg-molmuv: 0.104539 test loss: 0.015724
[Epoch 32; Iter    18/ 2172] train: loss: 0.0038059
[Epoch 32; Iter    48/ 2172] train: loss: 0.0013860
[Epoch 32; Iter    78/ 2172] train: loss: 0.0017825
[Epoch 32; Iter   108/ 2172] train: loss: 0.0466984
[Epoch 32; Iter   138/ 2172] train: loss: 0.0012732
[Epoch 32; Iter   168/ 2172] train: loss: 0.0956125
[Epoch 32; Iter   198/ 2172] train: loss: 0.0023985
[Epoch 32; Iter   228/ 2172] train: loss: 0.0599407
[Epoch 32; Iter   258/ 2172] train: loss: 0.0013952
[Epoch 32; Iter   288/ 2172] train: loss: 0.0011252
[Epoch 32; Iter   318/ 2172] train: loss: 0.0009500
[Epoch 32; Iter   348/ 2172] train: loss: 0.0169678
[Epoch 30; Iter   132/ 2172] train: loss: 0.0030772
[Epoch 30; Iter   162/ 2172] train: loss: 0.0027671
[Epoch 30; Iter   192/ 2172] train: loss: 0.0022765
[Epoch 30; Iter   222/ 2172] train: loss: 0.0024496
[Epoch 30; Iter   252/ 2172] train: loss: 0.0021390
[Epoch 30; Iter   282/ 2172] train: loss: 0.0019600
[Epoch 30; Iter   312/ 2172] train: loss: 0.0018084
[Epoch 30; Iter   342/ 2172] train: loss: 0.0604198
[Epoch 30; Iter   372/ 2172] train: loss: 0.0304498
[Epoch 30; Iter   402/ 2172] train: loss: 0.0041859
[Epoch 30; Iter   432/ 2172] train: loss: 0.0011373
[Epoch 30; Iter   462/ 2172] train: loss: 0.0012180
[Epoch 30; Iter   492/ 2172] train: loss: 0.0011098
[Epoch 30; Iter   522/ 2172] train: loss: 0.0974338
[Epoch 30; Iter   552/ 2172] train: loss: 0.0009815
[Epoch 30; Iter   582/ 2172] train: loss: 0.0010024
[Epoch 30; Iter   612/ 2172] train: loss: 0.0008433
[Epoch 30; Iter   642/ 2172] train: loss: 0.0013801
[Epoch 30; Iter   672/ 2172] train: loss: 0.0746232
[Epoch 30; Iter   702/ 2172] train: loss: 0.0421660
[Epoch 30; Iter   732/ 2172] train: loss: 0.0009270
[Epoch 30; Iter   762/ 2172] train: loss: 0.0019375
[Epoch 30; Iter   792/ 2172] train: loss: 0.0032089
[Epoch 30; Iter   822/ 2172] train: loss: 0.0769063
[Epoch 30; Iter   852/ 2172] train: loss: 0.0050071
[Epoch 30; Iter   882/ 2172] train: loss: 0.0020615
[Epoch 30; Iter   912/ 2172] train: loss: 0.0017570
[Epoch 30; Iter   942/ 2172] train: loss: 0.0023332
[Epoch 30; Iter   972/ 2172] train: loss: 0.0021801
[Epoch 30; Iter  1002/ 2172] train: loss: 0.0012371
[Epoch 30; Iter  1032/ 2172] train: loss: 0.0021008
[Epoch 30; Iter  1062/ 2172] train: loss: 0.0009702
[Epoch 30; Iter  1092/ 2172] train: loss: 0.0018628
[Epoch 30; Iter  1122/ 2172] train: loss: 0.0507353
[Epoch 30; Iter  1152/ 2172] train: loss: 0.0007593
[Epoch 30; Iter  1182/ 2172] train: loss: 0.0014505
[Epoch 30; Iter  1212/ 2172] train: loss: 0.0844696
[Epoch 30; Iter  1242/ 2172] train: loss: 0.0013964
[Epoch 30; Iter  1272/ 2172] train: loss: 0.0012897
[Epoch 30; Iter  1302/ 2172] train: loss: 0.0009053
[Epoch 30; Iter  1332/ 2172] train: loss: 0.0014272
[Epoch 30; Iter  1362/ 2172] train: loss: 0.0022196
[Epoch 30; Iter  1392/ 2172] train: loss: 0.0010713
[Epoch 30; Iter  1422/ 2172] train: loss: 0.0013534
[Epoch 30; Iter  1452/ 2172] train: loss: 0.0008112
[Epoch 30; Iter  1482/ 2172] train: loss: 0.0017003
[Epoch 30; Iter  1512/ 2172] train: loss: 0.0017006
[Epoch 30; Iter  1542/ 2172] train: loss: 0.0013909
[Epoch 30; Iter  1572/ 2172] train: loss: 0.0010188
[Epoch 30; Iter  1602/ 2172] train: loss: 0.0011033
[Epoch 30; Iter  1632/ 2172] train: loss: 0.0013239
[Epoch 30; Iter  1662/ 2172] train: loss: 0.0016579
[Epoch 30; Iter  1692/ 2172] train: loss: 0.0008920
[Epoch 30; Iter  1722/ 2172] train: loss: 0.0014484
[Epoch 30; Iter  1752/ 2172] train: loss: 0.0022624
[Epoch 30; Iter  1782/ 2172] train: loss: 0.0499736
[Epoch 30; Iter  1812/ 2172] train: loss: 0.0009652
[Epoch 30; Iter  1842/ 2172] train: loss: 0.0010882
[Epoch 30; Iter  1872/ 2172] train: loss: 0.0017018
[Epoch 30; Iter  1902/ 2172] train: loss: 0.0018690
[Epoch 30; Iter  1932/ 2172] train: loss: 0.0727899
[Epoch 30; Iter  1962/ 2172] train: loss: 0.0019945
[Epoch 30; Iter  1992/ 2172] train: loss: 0.0843577
[Epoch 30; Iter  2022/ 2172] train: loss: 0.0024970
[Epoch 30; Iter  2052/ 2172] train: loss: 0.0027370
[Epoch 30; Iter  2082/ 2172] train: loss: 0.0024829
[Epoch 30; Iter  2112/ 2172] train: loss: 0.0016990
[Epoch 30; Iter  2142/ 2172] train: loss: 0.0017991
[Epoch 30; Iter  2172/ 2172] train: loss: 0.0013711
[Epoch 30] ogbg-molmuv: 0.084842 val loss: 0.020883
[Epoch 30] ogbg-molmuv: 0.097966 test loss: 0.015318
[Epoch 31; Iter    30/ 2172] train: loss: 0.0011303
[Epoch 31; Iter    60/ 2172] train: loss: 0.0021377
[Epoch 31; Iter    90/ 2172] train: loss: 0.0024987
[Epoch 31; Iter   120/ 2172] train: loss: 0.0022954
[Epoch 31; Iter   150/ 2172] train: loss: 0.0024041
[Epoch 31; Iter   180/ 2172] train: loss: 0.0025071
[Epoch 31; Iter   210/ 2172] train: loss: 0.0018298
[Epoch 31; Iter   240/ 2172] train: loss: 0.0033263
[Epoch 31; Iter   270/ 2172] train: loss: 0.0013303
[Epoch 31; Iter   300/ 2172] train: loss: 0.0020949
[Epoch 31; Iter   330/ 2172] train: loss: 0.0017647
[Epoch 31; Iter   360/ 2172] train: loss: 0.0014024
[Epoch 31; Iter   390/ 2172] train: loss: 0.0560730
[Epoch 31; Iter   420/ 2172] train: loss: 0.0013421
[Epoch 31; Iter   450/ 2172] train: loss: 0.0051731
[Epoch 31; Iter   480/ 2172] train: loss: 0.0018488
[Epoch 31; Iter   510/ 2172] train: loss: 0.0012036
[Epoch 31; Iter   540/ 2172] train: loss: 0.0328873
[Epoch 31; Iter   570/ 2172] train: loss: 0.0022553
[Epoch 31; Iter   600/ 2172] train: loss: 0.0021883
[Epoch 31; Iter   630/ 2172] train: loss: 0.0020714
[Epoch 31; Iter   660/ 2172] train: loss: 0.0015439
[Epoch 31; Iter   690/ 2172] train: loss: 0.0016651
[Epoch 31; Iter   720/ 2172] train: loss: 0.0016326
[Epoch 31; Iter   750/ 2172] train: loss: 0.0012162
[Epoch 31; Iter   780/ 2172] train: loss: 0.0010103
[Epoch 31; Iter   810/ 2172] train: loss: 0.0695086
[Epoch 31; Iter   840/ 2172] train: loss: 0.0015150
[Epoch 31; Iter   870/ 2172] train: loss: 0.0013335
[Epoch 31; Iter   900/ 2172] train: loss: 0.0025886
[Epoch 31; Iter   930/ 2172] train: loss: 0.0035618
[Epoch 31; Iter   960/ 2172] train: loss: 0.0012795
[Epoch 31; Iter   990/ 2172] train: loss: 0.0014305
[Epoch 31; Iter  1020/ 2172] train: loss: 0.0016045
[Epoch 31; Iter  1050/ 2172] train: loss: 0.0016117
[Epoch 31; Iter  1080/ 2172] train: loss: 0.0007552
[Epoch 31; Iter  1110/ 2172] train: loss: 0.0017942
[Epoch 31; Iter  1140/ 2172] train: loss: 0.0011168
[Epoch 31; Iter  1170/ 2172] train: loss: 0.0028295
[Epoch 31; Iter  1200/ 2172] train: loss: 0.0010955
[Epoch 31; Iter  1230/ 2172] train: loss: 0.0013342
[Epoch 31; Iter  1260/ 2172] train: loss: 0.1762618
[Epoch 31; Iter  1290/ 2172] train: loss: 0.0010937
[Epoch 31; Iter  1320/ 2172] train: loss: 0.0015798
[Epoch 31; Iter  1350/ 2172] train: loss: 0.0020646
[Epoch 31; Iter  1380/ 2172] train: loss: 0.0019322
[Epoch 31; Iter  1410/ 2172] train: loss: 0.0022165
[Epoch 31; Iter  1440/ 2172] train: loss: 0.0025394
[Epoch 31; Iter  1470/ 2172] train: loss: 0.0014507
[Epoch 31; Iter  1500/ 2172] train: loss: 0.0009153
[Epoch 31; Iter  1530/ 2172] train: loss: 0.0009385
[Epoch 31; Iter  1560/ 2172] train: loss: 0.0016679
[Epoch 31; Iter  1590/ 2172] train: loss: 0.0014152
[Epoch 31; Iter  1620/ 2172] train: loss: 0.0008896
[Epoch 31; Iter  1650/ 2172] train: loss: 0.0018591
[Epoch 31; Iter  1680/ 2172] train: loss: 0.0848593
[Epoch 31; Iter  1710/ 2172] train: loss: 0.0011106
[Epoch 31; Iter  1740/ 2172] train: loss: 0.0852153
[Epoch 31; Iter  1770/ 2172] train: loss: 0.0037288
[Epoch 31; Iter  1800/ 2172] train: loss: 0.0013855
[Epoch 31; Iter  1830/ 2172] train: loss: 0.0015464
[Epoch 31; Iter  1860/ 2172] train: loss: 0.0019117
[Epoch 31; Iter  1890/ 2172] train: loss: 0.0013507
[Epoch 31; Iter  1920/ 2172] train: loss: 0.0018461
[Epoch 31; Iter  1950/ 2172] train: loss: 0.0014832
[Epoch 31; Iter  1980/ 2172] train: loss: 0.0016012
[Epoch 31; Iter  2010/ 2172] train: loss: 0.0014370
[Epoch 31; Iter  2040/ 2172] train: loss: 0.0220381
[Epoch 31; Iter  2070/ 2172] train: loss: 0.0014464
[Epoch 31; Iter  2100/ 2172] train: loss: 0.0009208
[Epoch 31; Iter  2130/ 2172] train: loss: 0.0009884
[Epoch 31; Iter  2160/ 2172] train: loss: 0.0012775
[Epoch 31] ogbg-molmuv: 0.098223 val loss: 0.332182
[Epoch 31] ogbg-molmuv: 0.078411 test loss: 0.116393
[Epoch 32; Iter    18/ 2172] train: loss: 0.0010794
[Epoch 32; Iter    48/ 2172] train: loss: 0.0019908
[Epoch 32; Iter    78/ 2172] train: loss: 0.0008003
[Epoch 32; Iter   108/ 2172] train: loss: 0.0025129
[Epoch 32; Iter   138/ 2172] train: loss: 0.0012037
[Epoch 32; Iter   168/ 2172] train: loss: 0.0010832
[Epoch 32; Iter   198/ 2172] train: loss: 0.0033894
[Epoch 32; Iter   228/ 2172] train: loss: 0.0010909
[Epoch 32; Iter   258/ 2172] train: loss: 0.0670598
[Epoch 32; Iter   288/ 2172] train: loss: 0.0091999
[Epoch 32; Iter   318/ 2172] train: loss: 0.0332073
[Epoch 32; Iter   348/ 2172] train: loss: 0.0022391
[Epoch 30; Iter   563/ 2483] train: loss: 0.0014738
[Epoch 30; Iter   593/ 2483] train: loss: 0.0017792
[Epoch 30; Iter   623/ 2483] train: loss: 0.0012666
[Epoch 30; Iter   653/ 2483] train: loss: 0.0007102
[Epoch 30; Iter   683/ 2483] train: loss: 0.0011716
[Epoch 30; Iter   713/ 2483] train: loss: 0.0021721
[Epoch 30; Iter   743/ 2483] train: loss: 0.0016636
[Epoch 30; Iter   773/ 2483] train: loss: 0.0025769
[Epoch 30; Iter   803/ 2483] train: loss: 0.0022291
[Epoch 30; Iter   833/ 2483] train: loss: 0.0012703
[Epoch 30; Iter   863/ 2483] train: loss: 0.0020127
[Epoch 30; Iter   893/ 2483] train: loss: 0.0016548
[Epoch 30; Iter   923/ 2483] train: loss: 0.0015529
[Epoch 30; Iter   953/ 2483] train: loss: 0.0066964
[Epoch 30; Iter   983/ 2483] train: loss: 0.0658735
[Epoch 30; Iter  1013/ 2483] train: loss: 0.0020012
[Epoch 30; Iter  1043/ 2483] train: loss: 0.0031570
[Epoch 30; Iter  1073/ 2483] train: loss: 0.0559701
[Epoch 30; Iter  1103/ 2483] train: loss: 0.0034147
[Epoch 30; Iter  1133/ 2483] train: loss: 0.0019152
[Epoch 30; Iter  1163/ 2483] train: loss: 0.0022482
[Epoch 30; Iter  1193/ 2483] train: loss: 0.0011641
[Epoch 30; Iter  1223/ 2483] train: loss: 0.0018558
[Epoch 30; Iter  1253/ 2483] train: loss: 0.0015835
[Epoch 30; Iter  1283/ 2483] train: loss: 0.0016813
[Epoch 30; Iter  1313/ 2483] train: loss: 0.0019917
[Epoch 30; Iter  1343/ 2483] train: loss: 0.0007726
[Epoch 30; Iter  1373/ 2483] train: loss: 0.0510651
[Epoch 30; Iter  1403/ 2483] train: loss: 0.0008391
[Epoch 30; Iter  1433/ 2483] train: loss: 0.0010590
[Epoch 30; Iter  1463/ 2483] train: loss: 0.0015813
[Epoch 30; Iter  1493/ 2483] train: loss: 0.0006620
[Epoch 30; Iter  1523/ 2483] train: loss: 0.0017017
[Epoch 30; Iter  1553/ 2483] train: loss: 0.0021217
[Epoch 30; Iter  1583/ 2483] train: loss: 0.0818156
[Epoch 30; Iter  1613/ 2483] train: loss: 0.0029771
[Epoch 30; Iter  1643/ 2483] train: loss: 0.0016292
[Epoch 30; Iter  1673/ 2483] train: loss: 0.0010356
[Epoch 30; Iter  1703/ 2483] train: loss: 0.0015934
[Epoch 30; Iter  1733/ 2483] train: loss: 0.0528255
[Epoch 30; Iter  1763/ 2483] train: loss: 0.0014734
[Epoch 30; Iter  1793/ 2483] train: loss: 0.0016338
[Epoch 30; Iter  1823/ 2483] train: loss: 0.0015274
[Epoch 30; Iter  1853/ 2483] train: loss: 0.0018476
[Epoch 30; Iter  1883/ 2483] train: loss: 0.0016005
[Epoch 30; Iter  1913/ 2483] train: loss: 0.0019553
[Epoch 30; Iter  1943/ 2483] train: loss: 0.0635900
[Epoch 30; Iter  1973/ 2483] train: loss: 0.0026591
[Epoch 30; Iter  2003/ 2483] train: loss: 0.0018608
[Epoch 30; Iter  2033/ 2483] train: loss: 0.0625888
[Epoch 30; Iter  2063/ 2483] train: loss: 0.0014284
[Epoch 30; Iter  2093/ 2483] train: loss: 0.0381756
[Epoch 30; Iter  2123/ 2483] train: loss: 0.0013127
[Epoch 30; Iter  2153/ 2483] train: loss: 0.0018556
[Epoch 30; Iter  2183/ 2483] train: loss: 0.0027826
[Epoch 30; Iter  2213/ 2483] train: loss: 0.0009799
[Epoch 30; Iter  2243/ 2483] train: loss: 0.0007133
[Epoch 30; Iter  2273/ 2483] train: loss: 0.0466340
[Epoch 30; Iter  2303/ 2483] train: loss: 0.0632275
[Epoch 30; Iter  2333/ 2483] train: loss: 0.0010172
[Epoch 30; Iter  2363/ 2483] train: loss: 0.0035107
[Epoch 30; Iter  2393/ 2483] train: loss: 0.0023361
[Epoch 30; Iter  2423/ 2483] train: loss: 0.0200957
[Epoch 30; Iter  2453/ 2483] train: loss: 0.0006459
[Epoch 30; Iter  2483/ 2483] train: loss: 0.0008590
[Epoch 30] ogbg-molmuv: 0.114928 val loss: 0.047139
[Epoch 30] ogbg-molmuv: 0.127522 test loss: 0.027988
[Epoch 31; Iter    30/ 2483] train: loss: 0.0010458
[Epoch 31; Iter    60/ 2483] train: loss: 0.0016837
[Epoch 31; Iter    90/ 2483] train: loss: 0.0007477
[Epoch 31; Iter   120/ 2483] train: loss: 0.0020980
[Epoch 31; Iter   150/ 2483] train: loss: 0.0036759
[Epoch 31; Iter   180/ 2483] train: loss: 0.0312584
[Epoch 31; Iter   210/ 2483] train: loss: 0.0013427
[Epoch 31; Iter   240/ 2483] train: loss: 0.0016826
[Epoch 31; Iter   270/ 2483] train: loss: 0.0019372
[Epoch 31; Iter   300/ 2483] train: loss: 0.0027771
[Epoch 31; Iter   330/ 2483] train: loss: 0.0010950
[Epoch 31; Iter   360/ 2483] train: loss: 0.0014265
[Epoch 31; Iter   390/ 2483] train: loss: 0.0006642
[Epoch 31; Iter   420/ 2483] train: loss: 0.0018715
[Epoch 31; Iter   450/ 2483] train: loss: 0.0015267
[Epoch 31; Iter   480/ 2483] train: loss: 0.0020076
[Epoch 31; Iter   510/ 2483] train: loss: 0.0007586
[Epoch 31; Iter   540/ 2483] train: loss: 0.0015742
[Epoch 31; Iter   570/ 2483] train: loss: 0.0010421
[Epoch 31; Iter   600/ 2483] train: loss: 0.0010116
[Epoch 31; Iter   630/ 2483] train: loss: 0.0022150
[Epoch 31; Iter   660/ 2483] train: loss: 0.0749485
[Epoch 31; Iter   690/ 2483] train: loss: 0.0059690
[Epoch 31; Iter   720/ 2483] train: loss: 0.0023692
[Epoch 31; Iter   750/ 2483] train: loss: 0.0025939
[Epoch 31; Iter   780/ 2483] train: loss: 0.0016618
[Epoch 31; Iter   810/ 2483] train: loss: 0.0018220
[Epoch 31; Iter   840/ 2483] train: loss: 0.0054883
[Epoch 31; Iter   870/ 2483] train: loss: 0.0021867
[Epoch 31; Iter   900/ 2483] train: loss: 0.0030086
[Epoch 31; Iter   930/ 2483] train: loss: 0.0772131
[Epoch 31; Iter   960/ 2483] train: loss: 0.0016543
[Epoch 31; Iter   990/ 2483] train: loss: 0.0018339
[Epoch 31; Iter  1020/ 2483] train: loss: 0.0013150
[Epoch 31; Iter  1050/ 2483] train: loss: 0.0021463
[Epoch 31; Iter  1080/ 2483] train: loss: 0.0020499
[Epoch 31; Iter  1110/ 2483] train: loss: 0.0013633
[Epoch 31; Iter  1140/ 2483] train: loss: 0.0009503
[Epoch 31; Iter  1170/ 2483] train: loss: 0.0029764
[Epoch 31; Iter  1200/ 2483] train: loss: 0.0014735
[Epoch 31; Iter  1230/ 2483] train: loss: 0.0014646
[Epoch 31; Iter  1260/ 2483] train: loss: 0.0016805
[Epoch 31; Iter  1290/ 2483] train: loss: 0.0017381
[Epoch 31; Iter  1320/ 2483] train: loss: 0.0735964
[Epoch 31; Iter  1350/ 2483] train: loss: 0.0062143
[Epoch 31; Iter  1380/ 2483] train: loss: 0.0031894
[Epoch 31; Iter  1410/ 2483] train: loss: 0.0010201
[Epoch 31; Iter  1440/ 2483] train: loss: 0.0274524
[Epoch 31; Iter  1470/ 2483] train: loss: 0.0124589
[Epoch 31; Iter  1500/ 2483] train: loss: 0.0020929
[Epoch 31; Iter  1530/ 2483] train: loss: 0.0014395
[Epoch 31; Iter  1560/ 2483] train: loss: 0.0015054
[Epoch 31; Iter  1590/ 2483] train: loss: 0.0034770
[Epoch 31; Iter  1620/ 2483] train: loss: 0.0009722
[Epoch 31; Iter  1650/ 2483] train: loss: 0.0020690
[Epoch 31; Iter  1680/ 2483] train: loss: 0.0024147
[Epoch 31; Iter  1710/ 2483] train: loss: 0.0714662
[Epoch 31; Iter  1740/ 2483] train: loss: 0.0012780
[Epoch 31; Iter  1770/ 2483] train: loss: 0.0009596
[Epoch 31; Iter  1800/ 2483] train: loss: 0.0028257
[Epoch 31; Iter  1830/ 2483] train: loss: 0.0011820
[Epoch 31; Iter  1860/ 2483] train: loss: 0.0014873
[Epoch 31; Iter  1890/ 2483] train: loss: 0.0010891
[Epoch 31; Iter  1920/ 2483] train: loss: 0.0015962
[Epoch 31; Iter  1950/ 2483] train: loss: 0.0020517
[Epoch 31; Iter  1980/ 2483] train: loss: 0.0013006
[Epoch 31; Iter  2010/ 2483] train: loss: 0.0037711
[Epoch 31; Iter  2040/ 2483] train: loss: 0.0011073
[Epoch 31; Iter  2070/ 2483] train: loss: 0.0014686
[Epoch 31; Iter  2100/ 2483] train: loss: 0.0006859
[Epoch 31; Iter  2130/ 2483] train: loss: 0.0022592
[Epoch 31; Iter  2160/ 2483] train: loss: 0.0007823
[Epoch 31; Iter  2190/ 2483] train: loss: 0.0016950
[Epoch 31; Iter  2220/ 2483] train: loss: 0.0018104
[Epoch 31; Iter  2250/ 2483] train: loss: 0.0015365
[Epoch 31; Iter  2280/ 2483] train: loss: 0.0021931
[Epoch 31; Iter  2310/ 2483] train: loss: 0.0668989
[Epoch 31; Iter  2340/ 2483] train: loss: 0.0017255
[Epoch 31; Iter  2370/ 2483] train: loss: 0.0010294
[Epoch 31; Iter  2400/ 2483] train: loss: 0.0009545
[Epoch 31; Iter  2430/ 2483] train: loss: 0.0046549
[Epoch 31; Iter  2460/ 2483] train: loss: 0.0012700
[Epoch 31] ogbg-molmuv: 0.150404 val loss: 0.022352
[Epoch 31] ogbg-molmuv: 0.150981 test loss: 0.022545
[Epoch 32; Iter     7/ 2483] train: loss: 0.0011743
[Epoch 32; Iter    37/ 2483] train: loss: 0.0021069
[Epoch 32; Iter    67/ 2483] train: loss: 0.0009103
[Epoch 32; Iter    97/ 2483] train: loss: 0.0305576
[Epoch 32; Iter   127/ 2483] train: loss: 0.0014121
[Epoch 32; Iter   157/ 2483] train: loss: 0.0016362
[Epoch 32; Iter   508/ 1862] train: loss: 0.0009595
[Epoch 32; Iter   538/ 1862] train: loss: 0.0029660
[Epoch 32; Iter   568/ 1862] train: loss: 0.0014414
[Epoch 32; Iter   598/ 1862] train: loss: 0.0016058
[Epoch 32; Iter   628/ 1862] train: loss: 0.0022236
[Epoch 32; Iter   658/ 1862] train: loss: 0.0012277
[Epoch 32; Iter   688/ 1862] train: loss: 0.0020231
[Epoch 32; Iter   718/ 1862] train: loss: 0.0077813
[Epoch 32; Iter   748/ 1862] train: loss: 0.0031547
[Epoch 32; Iter   778/ 1862] train: loss: 0.0090745
[Epoch 32; Iter   808/ 1862] train: loss: 0.0014631
[Epoch 32; Iter   838/ 1862] train: loss: 0.0027848
[Epoch 32; Iter   868/ 1862] train: loss: 0.0010746
[Epoch 32; Iter   898/ 1862] train: loss: 0.0022220
[Epoch 32; Iter   928/ 1862] train: loss: 0.0012771
[Epoch 32; Iter   958/ 1862] train: loss: 0.0459425
[Epoch 32; Iter   988/ 1862] train: loss: 0.0010910
[Epoch 32; Iter  1018/ 1862] train: loss: 0.0011556
[Epoch 32; Iter  1048/ 1862] train: loss: 0.0012317
[Epoch 32; Iter  1078/ 1862] train: loss: 0.0012079
[Epoch 32; Iter  1108/ 1862] train: loss: 0.0015146
[Epoch 32; Iter  1138/ 1862] train: loss: 0.0018196
[Epoch 32; Iter  1168/ 1862] train: loss: 0.0014391
[Epoch 32; Iter  1198/ 1862] train: loss: 0.0016545
[Epoch 32; Iter  1228/ 1862] train: loss: 0.0014625
[Epoch 32; Iter  1258/ 1862] train: loss: 0.0018272
[Epoch 32; Iter  1288/ 1862] train: loss: 0.0017108
[Epoch 32; Iter  1318/ 1862] train: loss: 0.0010364
[Epoch 32; Iter  1348/ 1862] train: loss: 0.0537861
[Epoch 32; Iter  1378/ 1862] train: loss: 0.0024575
[Epoch 32; Iter  1408/ 1862] train: loss: 0.0477352
[Epoch 32; Iter  1438/ 1862] train: loss: 0.0025073
[Epoch 32; Iter  1468/ 1862] train: loss: 0.0007997
[Epoch 32; Iter  1498/ 1862] train: loss: 0.0020463
[Epoch 32; Iter  1528/ 1862] train: loss: 0.0009992
[Epoch 32; Iter  1558/ 1862] train: loss: 0.0038064
[Epoch 32; Iter  1588/ 1862] train: loss: 0.0009111
[Epoch 32; Iter  1618/ 1862] train: loss: 0.0017995
[Epoch 32; Iter  1648/ 1862] train: loss: 0.2219043
[Epoch 32; Iter  1678/ 1862] train: loss: 0.0403397
[Epoch 32; Iter  1708/ 1862] train: loss: 0.0752925
[Epoch 32; Iter  1738/ 1862] train: loss: 0.0016874
[Epoch 32; Iter  1768/ 1862] train: loss: 0.0013544
[Epoch 32; Iter  1798/ 1862] train: loss: 0.0022070
[Epoch 32; Iter  1828/ 1862] train: loss: 0.0668539
[Epoch 32; Iter  1858/ 1862] train: loss: 0.0010145
[Epoch 32] ogbg-molmuv: 0.068831 val loss: 0.014988
[Epoch 32] ogbg-molmuv: 0.100485 test loss: 0.012425
[Epoch 33; Iter    26/ 1862] train: loss: 0.0023381
[Epoch 33; Iter    56/ 1862] train: loss: 0.0019834
[Epoch 33; Iter    86/ 1862] train: loss: 0.0013473
[Epoch 33; Iter   116/ 1862] train: loss: 0.0010496
[Epoch 33; Iter   146/ 1862] train: loss: 0.0370841
[Epoch 33; Iter   176/ 1862] train: loss: 0.0024798
[Epoch 33; Iter   206/ 1862] train: loss: 0.0017874
[Epoch 33; Iter   236/ 1862] train: loss: 0.0013622
[Epoch 33; Iter   266/ 1862] train: loss: 0.0014319
[Epoch 33; Iter   296/ 1862] train: loss: 0.0012953
[Epoch 33; Iter   326/ 1862] train: loss: 0.0012074
[Epoch 33; Iter   356/ 1862] train: loss: 0.0007541
[Epoch 33; Iter   386/ 1862] train: loss: 0.0021248
[Epoch 33; Iter   416/ 1862] train: loss: 0.0046314
[Epoch 33; Iter   446/ 1862] train: loss: 0.0010901
[Epoch 33; Iter   476/ 1862] train: loss: 0.0011024
[Epoch 33; Iter   506/ 1862] train: loss: 0.0034073
[Epoch 33; Iter   536/ 1862] train: loss: 0.0305273
[Epoch 33; Iter   566/ 1862] train: loss: 0.0012028
[Epoch 33; Iter   596/ 1862] train: loss: 0.0016567
[Epoch 33; Iter   626/ 1862] train: loss: 0.0009775
[Epoch 33; Iter   656/ 1862] train: loss: 0.0009120
[Epoch 33; Iter   686/ 1862] train: loss: 0.0389836
[Epoch 33; Iter   716/ 1862] train: loss: 0.0021044
[Epoch 33; Iter   746/ 1862] train: loss: 0.0009536
[Epoch 33; Iter   776/ 1862] train: loss: 0.0175464
[Epoch 33; Iter   806/ 1862] train: loss: 0.0070397
[Epoch 33; Iter   836/ 1862] train: loss: 0.0018327
[Epoch 33; Iter   866/ 1862] train: loss: 0.0013172
[Epoch 33; Iter   896/ 1862] train: loss: 0.0011734
[Epoch 33; Iter   926/ 1862] train: loss: 0.0029644
[Epoch 33; Iter   956/ 1862] train: loss: 0.0018083
[Epoch 33; Iter   986/ 1862] train: loss: 0.0014887
[Epoch 33; Iter  1016/ 1862] train: loss: 0.0005795
[Epoch 33; Iter  1046/ 1862] train: loss: 0.0032148
[Epoch 33; Iter  1076/ 1862] train: loss: 0.0004669
[Epoch 33; Iter  1106/ 1862] train: loss: 0.0019991
[Epoch 33; Iter  1136/ 1862] train: loss: 0.0013923
[Epoch 33; Iter  1166/ 1862] train: loss: 0.0024536
[Epoch 33; Iter  1196/ 1862] train: loss: 0.0010118
[Epoch 33; Iter  1226/ 1862] train: loss: 0.0010144
[Epoch 33; Iter  1256/ 1862] train: loss: 0.0012619
[Epoch 33; Iter  1286/ 1862] train: loss: 0.0634429
[Epoch 33; Iter  1316/ 1862] train: loss: 0.0042365
[Epoch 33; Iter  1346/ 1862] train: loss: 0.0406855
[Epoch 33; Iter  1376/ 1862] train: loss: 0.0909556
[Epoch 33; Iter  1406/ 1862] train: loss: 0.0015658
[Epoch 33; Iter  1436/ 1862] train: loss: 0.0196324
[Epoch 33; Iter  1466/ 1862] train: loss: 0.0008899
[Epoch 33; Iter  1496/ 1862] train: loss: 0.0855748
[Epoch 33; Iter  1526/ 1862] train: loss: 0.0015806
[Epoch 33; Iter  1556/ 1862] train: loss: 0.0013008
[Epoch 33; Iter  1586/ 1862] train: loss: 0.0011859
[Epoch 33; Iter  1616/ 1862] train: loss: 0.0030654
[Epoch 33; Iter  1646/ 1862] train: loss: 0.0009692
[Epoch 33; Iter  1676/ 1862] train: loss: 0.0008375
[Epoch 33; Iter  1706/ 1862] train: loss: 0.0101326
[Epoch 33; Iter  1736/ 1862] train: loss: 0.0027972
[Epoch 33; Iter  1766/ 1862] train: loss: 0.0017749
[Epoch 33; Iter  1796/ 1862] train: loss: 0.0007596
[Epoch 33; Iter  1826/ 1862] train: loss: 0.0013260
[Epoch 33; Iter  1856/ 1862] train: loss: 0.0023053
[Epoch 33] ogbg-molmuv: 0.049710 val loss: 0.015011
[Epoch 33] ogbg-molmuv: 0.069868 test loss: 0.013636
[Epoch 34; Iter    24/ 1862] train: loss: 0.0081291
[Epoch 34; Iter    54/ 1862] train: loss: 0.0006711
[Epoch 34; Iter    84/ 1862] train: loss: 0.0020456
[Epoch 34; Iter   114/ 1862] train: loss: 0.0009141
[Epoch 34; Iter   144/ 1862] train: loss: 0.0017364
[Epoch 34; Iter   174/ 1862] train: loss: 0.0007375
[Epoch 34; Iter   204/ 1862] train: loss: 0.0007946
[Epoch 34; Iter   234/ 1862] train: loss: 0.0024197
[Epoch 34; Iter   264/ 1862] train: loss: 0.0011692
[Epoch 34; Iter   294/ 1862] train: loss: 0.0880187
[Epoch 34; Iter   324/ 1862] train: loss: 0.0055068
[Epoch 34; Iter   354/ 1862] train: loss: 0.0013756
[Epoch 34; Iter   384/ 1862] train: loss: 0.0016394
[Epoch 34; Iter   414/ 1862] train: loss: 0.0496269
[Epoch 34; Iter   444/ 1862] train: loss: 0.0587465
[Epoch 34; Iter   474/ 1862] train: loss: 0.0379895
[Epoch 34; Iter   504/ 1862] train: loss: 0.0010862
[Epoch 34; Iter   534/ 1862] train: loss: 0.0022513
[Epoch 34; Iter   564/ 1862] train: loss: 0.0026594
[Epoch 34; Iter   594/ 1862] train: loss: 0.0218636
[Epoch 34; Iter   624/ 1862] train: loss: 0.0012398
[Epoch 34; Iter   654/ 1862] train: loss: 0.0023157
[Epoch 34; Iter   684/ 1862] train: loss: 0.0020809
[Epoch 34; Iter   714/ 1862] train: loss: 0.0009556
[Epoch 34; Iter   744/ 1862] train: loss: 0.0022196
[Epoch 34; Iter   774/ 1862] train: loss: 0.0053508
[Epoch 34; Iter   804/ 1862] train: loss: 0.0013274
[Epoch 34; Iter   834/ 1862] train: loss: 0.0009994
[Epoch 34; Iter   864/ 1862] train: loss: 0.0010662
[Epoch 34; Iter   894/ 1862] train: loss: 0.0007194
[Epoch 34; Iter   924/ 1862] train: loss: 0.0010717
[Epoch 34; Iter   954/ 1862] train: loss: 0.0019525
[Epoch 34; Iter   984/ 1862] train: loss: 0.0012048
[Epoch 34; Iter  1014/ 1862] train: loss: 0.0907129
[Epoch 34; Iter  1044/ 1862] train: loss: 0.0038822
[Epoch 34; Iter  1074/ 1862] train: loss: 0.0837856
[Epoch 34; Iter  1104/ 1862] train: loss: 0.0004615
[Epoch 34; Iter  1134/ 1862] train: loss: 0.0014942
[Epoch 34; Iter  1164/ 1862] train: loss: 0.0810662
[Epoch 34; Iter  1194/ 1862] train: loss: 0.0007535
[Epoch 34; Iter  1224/ 1862] train: loss: 0.0013669
[Epoch 34; Iter  1254/ 1862] train: loss: 0.0008072
[Epoch 34; Iter  1284/ 1862] train: loss: 0.0008695
[Epoch 34; Iter  1314/ 1862] train: loss: 0.0012535
[Epoch 34; Iter  1344/ 1862] train: loss: 0.0020066
[Epoch 30; Iter   563/ 2483] train: loss: 0.0591103
[Epoch 30; Iter   593/ 2483] train: loss: 0.0016344
[Epoch 30; Iter   623/ 2483] train: loss: 0.0009306
[Epoch 30; Iter   653/ 2483] train: loss: 0.0014033
[Epoch 30; Iter   683/ 2483] train: loss: 0.0684271
[Epoch 30; Iter   713/ 2483] train: loss: 0.0009625
[Epoch 30; Iter   743/ 2483] train: loss: 0.0135331
[Epoch 30; Iter   773/ 2483] train: loss: 0.0019901
[Epoch 30; Iter   803/ 2483] train: loss: 0.0047730
[Epoch 30; Iter   833/ 2483] train: loss: 0.0017162
[Epoch 30; Iter   863/ 2483] train: loss: 0.0019350
[Epoch 30; Iter   893/ 2483] train: loss: 0.0011300
[Epoch 30; Iter   923/ 2483] train: loss: 0.0662222
[Epoch 30; Iter   953/ 2483] train: loss: 0.0021782
[Epoch 30; Iter   983/ 2483] train: loss: 0.0016190
[Epoch 30; Iter  1013/ 2483] train: loss: 0.0010266
[Epoch 30; Iter  1043/ 2483] train: loss: 0.0012893
[Epoch 30; Iter  1073/ 2483] train: loss: 0.0009609
[Epoch 30; Iter  1103/ 2483] train: loss: 0.0023944
[Epoch 30; Iter  1133/ 2483] train: loss: 0.0019934
[Epoch 30; Iter  1163/ 2483] train: loss: 0.0012805
[Epoch 30; Iter  1193/ 2483] train: loss: 0.0017860
[Epoch 30; Iter  1223/ 2483] train: loss: 0.0043952
[Epoch 30; Iter  1253/ 2483] train: loss: 0.0014256
[Epoch 30; Iter  1283/ 2483] train: loss: 0.0009807
[Epoch 30; Iter  1313/ 2483] train: loss: 0.0018426
[Epoch 30; Iter  1343/ 2483] train: loss: 0.0016780
[Epoch 30; Iter  1373/ 2483] train: loss: 0.0024748
[Epoch 30; Iter  1403/ 2483] train: loss: 0.0012212
[Epoch 30; Iter  1433/ 2483] train: loss: 0.0019667
[Epoch 30; Iter  1463/ 2483] train: loss: 0.0020094
[Epoch 30; Iter  1493/ 2483] train: loss: 0.0012069
[Epoch 30; Iter  1523/ 2483] train: loss: 0.0010511
[Epoch 30; Iter  1553/ 2483] train: loss: 0.0014428
[Epoch 30; Iter  1583/ 2483] train: loss: 0.0047140
[Epoch 30; Iter  1613/ 2483] train: loss: 0.0012233
[Epoch 30; Iter  1643/ 2483] train: loss: 0.0013123
[Epoch 30; Iter  1673/ 2483] train: loss: 0.0014989
[Epoch 30; Iter  1703/ 2483] train: loss: 0.0012166
[Epoch 30; Iter  1733/ 2483] train: loss: 0.0023319
[Epoch 30; Iter  1763/ 2483] train: loss: 0.0031953
[Epoch 30; Iter  1793/ 2483] train: loss: 0.0011992
[Epoch 30; Iter  1823/ 2483] train: loss: 0.0015837
[Epoch 30; Iter  1853/ 2483] train: loss: 0.0019177
[Epoch 30; Iter  1883/ 2483] train: loss: 0.0019297
[Epoch 30; Iter  1913/ 2483] train: loss: 0.0018841
[Epoch 30; Iter  1943/ 2483] train: loss: 0.0017409
[Epoch 30; Iter  1973/ 2483] train: loss: 0.0029809
[Epoch 30; Iter  2003/ 2483] train: loss: 0.0021205
[Epoch 30; Iter  2033/ 2483] train: loss: 0.0008567
[Epoch 30; Iter  2063/ 2483] train: loss: 0.0014026
[Epoch 30; Iter  2093/ 2483] train: loss: 0.0023965
[Epoch 30; Iter  2123/ 2483] train: loss: 0.0024541
[Epoch 30; Iter  2153/ 2483] train: loss: 0.0015315
[Epoch 30; Iter  2183/ 2483] train: loss: 0.0214951
[Epoch 30; Iter  2213/ 2483] train: loss: 0.0099313
[Epoch 30; Iter  2243/ 2483] train: loss: 0.0165677
[Epoch 30; Iter  2273/ 2483] train: loss: 0.0011897
[Epoch 30; Iter  2303/ 2483] train: loss: 0.0017334
[Epoch 30; Iter  2333/ 2483] train: loss: 0.0264028
[Epoch 30; Iter  2363/ 2483] train: loss: 0.0298444
[Epoch 30; Iter  2393/ 2483] train: loss: 0.0520615
[Epoch 30; Iter  2423/ 2483] train: loss: 0.0027168
[Epoch 30; Iter  2453/ 2483] train: loss: 0.0021900
[Epoch 30; Iter  2483/ 2483] train: loss: 0.0012537
[Epoch 30] ogbg-molmuv: 0.103809 val loss: 0.018064
[Epoch 30] ogbg-molmuv: 0.186806 test loss: 0.030175
[Epoch 31; Iter    30/ 2483] train: loss: 0.0014209
[Epoch 31; Iter    60/ 2483] train: loss: 0.0687819
[Epoch 31; Iter    90/ 2483] train: loss: 0.0013297
[Epoch 31; Iter   120/ 2483] train: loss: 0.0017173
[Epoch 31; Iter   150/ 2483] train: loss: 0.0009213
[Epoch 31; Iter   180/ 2483] train: loss: 0.0015107
[Epoch 31; Iter   210/ 2483] train: loss: 0.0069857
[Epoch 31; Iter   240/ 2483] train: loss: 0.0010124
[Epoch 31; Iter   270/ 2483] train: loss: 0.0011261
[Epoch 31; Iter   300/ 2483] train: loss: 0.0017160
[Epoch 31; Iter   330/ 2483] train: loss: 0.0020218
[Epoch 31; Iter   360/ 2483] train: loss: 0.0010621
[Epoch 31; Iter   390/ 2483] train: loss: 0.0924590
[Epoch 31; Iter   420/ 2483] train: loss: 0.0014764
[Epoch 31; Iter   450/ 2483] train: loss: 0.0015697
[Epoch 31; Iter   480/ 2483] train: loss: 0.0013630
[Epoch 31; Iter   510/ 2483] train: loss: 0.0016547
[Epoch 31; Iter   540/ 2483] train: loss: 0.0013573
[Epoch 31; Iter   570/ 2483] train: loss: 0.0008971
[Epoch 31; Iter   600/ 2483] train: loss: 0.0008891
[Epoch 31; Iter   630/ 2483] train: loss: 0.0009314
[Epoch 31; Iter   660/ 2483] train: loss: 0.0125193
[Epoch 31; Iter   690/ 2483] train: loss: 0.0015256
[Epoch 31; Iter   720/ 2483] train: loss: 0.0015510
[Epoch 31; Iter   750/ 2483] train: loss: 0.0013049
[Epoch 31; Iter   780/ 2483] train: loss: 0.0012624
[Epoch 31; Iter   810/ 2483] train: loss: 0.0017684
[Epoch 31; Iter   840/ 2483] train: loss: 0.0009463
[Epoch 31; Iter   870/ 2483] train: loss: 0.0017597
[Epoch 31; Iter   900/ 2483] train: loss: 0.0018835
[Epoch 31; Iter   930/ 2483] train: loss: 0.0723834
[Epoch 31; Iter   960/ 2483] train: loss: 0.0009113
[Epoch 31; Iter   990/ 2483] train: loss: 0.0012176
[Epoch 31; Iter  1020/ 2483] train: loss: 0.0011636
[Epoch 31; Iter  1050/ 2483] train: loss: 0.0012415
[Epoch 31; Iter  1080/ 2483] train: loss: 0.0013104
[Epoch 31; Iter  1110/ 2483] train: loss: 0.0020870
[Epoch 31; Iter  1140/ 2483] train: loss: 0.0012869
[Epoch 31; Iter  1170/ 2483] train: loss: 0.0026501
[Epoch 31; Iter  1200/ 2483] train: loss: 0.0049593
[Epoch 31; Iter  1230/ 2483] train: loss: 0.0134697
[Epoch 31; Iter  1260/ 2483] train: loss: 0.0011607
[Epoch 31; Iter  1290/ 2483] train: loss: 0.0016044
[Epoch 31; Iter  1320/ 2483] train: loss: 0.0014813
[Epoch 31; Iter  1350/ 2483] train: loss: 0.0704615
[Epoch 31; Iter  1380/ 2483] train: loss: 0.0009529
[Epoch 31; Iter  1410/ 2483] train: loss: 0.0018742
[Epoch 31; Iter  1440/ 2483] train: loss: 0.0016916
[Epoch 31; Iter  1470/ 2483] train: loss: 0.0028661
[Epoch 31; Iter  1500/ 2483] train: loss: 0.0018016
[Epoch 31; Iter  1530/ 2483] train: loss: 0.0013399
[Epoch 31; Iter  1560/ 2483] train: loss: 0.0027153
[Epoch 31; Iter  1590/ 2483] train: loss: 0.0015947
[Epoch 31; Iter  1620/ 2483] train: loss: 0.0014530
[Epoch 31; Iter  1650/ 2483] train: loss: 0.0029324
[Epoch 31; Iter  1680/ 2483] train: loss: 0.0012808
[Epoch 31; Iter  1710/ 2483] train: loss: 0.0022148
[Epoch 31; Iter  1740/ 2483] train: loss: 0.0017941
[Epoch 31; Iter  1770/ 2483] train: loss: 0.0009318
[Epoch 31; Iter  1800/ 2483] train: loss: 0.0011510
[Epoch 31; Iter  1830/ 2483] train: loss: 0.0021008
[Epoch 31; Iter  1860/ 2483] train: loss: 0.0010814
[Epoch 31; Iter  1890/ 2483] train: loss: 0.0011928
[Epoch 31; Iter  1920/ 2483] train: loss: 0.0108263
[Epoch 31; Iter  1950/ 2483] train: loss: 0.0009386
[Epoch 31; Iter  1980/ 2483] train: loss: 0.0011505
[Epoch 31; Iter  2010/ 2483] train: loss: 0.0011666
[Epoch 31; Iter  2040/ 2483] train: loss: 0.0037453
[Epoch 31; Iter  2070/ 2483] train: loss: 0.0010413
[Epoch 31; Iter  2100/ 2483] train: loss: 0.0463633
[Epoch 31; Iter  2130/ 2483] train: loss: 0.0009214
[Epoch 31; Iter  2160/ 2483] train: loss: 0.0009041
[Epoch 31; Iter  2190/ 2483] train: loss: 0.0013783
[Epoch 31; Iter  2220/ 2483] train: loss: 0.0020859
[Epoch 31; Iter  2250/ 2483] train: loss: 0.0021592
[Epoch 31; Iter  2280/ 2483] train: loss: 0.0016337
[Epoch 31; Iter  2310/ 2483] train: loss: 0.0010181
[Epoch 31; Iter  2340/ 2483] train: loss: 0.0017361
[Epoch 31; Iter  2370/ 2483] train: loss: 0.0012344
[Epoch 31; Iter  2400/ 2483] train: loss: 0.0011065
[Epoch 31; Iter  2430/ 2483] train: loss: 0.0010487
[Epoch 31; Iter  2460/ 2483] train: loss: 0.0317696
[Epoch 31] ogbg-molmuv: 0.113460 val loss: 0.009875
[Epoch 31] ogbg-molmuv: 0.162859 test loss: 0.054887
[Epoch 32; Iter     7/ 2483] train: loss: 0.0062240
[Epoch 32; Iter    37/ 2483] train: loss: 0.0013357
[Epoch 32; Iter    67/ 2483] train: loss: 0.0015032
[Epoch 32; Iter    97/ 2483] train: loss: 0.0012364
[Epoch 32; Iter   127/ 2483] train: loss: 0.0026800
[Epoch 32; Iter   157/ 2483] train: loss: 0.0016341
[Epoch 32; Iter   508/ 1862] train: loss: 0.0045894
[Epoch 32; Iter   538/ 1862] train: loss: 0.0705812
[Epoch 32; Iter   568/ 1862] train: loss: 0.0021462
[Epoch 32; Iter   598/ 1862] train: loss: 0.0014263
[Epoch 32; Iter   628/ 1862] train: loss: 0.0492630
[Epoch 32; Iter   658/ 1862] train: loss: 0.0016877
[Epoch 32; Iter   688/ 1862] train: loss: 0.0012583
[Epoch 32; Iter   718/ 1862] train: loss: 0.0013152
[Epoch 32; Iter   748/ 1862] train: loss: 0.0494245
[Epoch 32; Iter   778/ 1862] train: loss: 0.0013274
[Epoch 32; Iter   808/ 1862] train: loss: 0.0015718
[Epoch 32; Iter   838/ 1862] train: loss: 0.0656126
[Epoch 32; Iter   868/ 1862] train: loss: 0.0024550
[Epoch 32; Iter   898/ 1862] train: loss: 0.0010300
[Epoch 32; Iter   928/ 1862] train: loss: 0.0012260
[Epoch 32; Iter   958/ 1862] train: loss: 0.0026939
[Epoch 32; Iter   988/ 1862] train: loss: 0.0016785
[Epoch 32; Iter  1018/ 1862] train: loss: 0.0012137
[Epoch 32; Iter  1048/ 1862] train: loss: 0.0011206
[Epoch 32; Iter  1078/ 1862] train: loss: 0.0011696
[Epoch 32; Iter  1108/ 1862] train: loss: 0.0009369
[Epoch 32; Iter  1138/ 1862] train: loss: 0.0012107
[Epoch 32; Iter  1168/ 1862] train: loss: 0.0088016
[Epoch 32; Iter  1198/ 1862] train: loss: 0.0016761
[Epoch 32; Iter  1228/ 1862] train: loss: 0.0029866
[Epoch 32; Iter  1258/ 1862] train: loss: 0.0015053
[Epoch 32; Iter  1288/ 1862] train: loss: 0.0015244
[Epoch 32; Iter  1318/ 1862] train: loss: 0.0024898
[Epoch 32; Iter  1348/ 1862] train: loss: 0.0020661
[Epoch 32; Iter  1378/ 1862] train: loss: 0.0012183
[Epoch 32; Iter  1408/ 1862] train: loss: 0.0010566
[Epoch 32; Iter  1438/ 1862] train: loss: 0.0030783
[Epoch 32; Iter  1468/ 1862] train: loss: 0.0014174
[Epoch 32; Iter  1498/ 1862] train: loss: 0.0030560
[Epoch 32; Iter  1528/ 1862] train: loss: 0.0010577
[Epoch 32; Iter  1558/ 1862] train: loss: 0.0013872
[Epoch 32; Iter  1588/ 1862] train: loss: 0.0007577
[Epoch 32; Iter  1618/ 1862] train: loss: 0.0015331
[Epoch 32; Iter  1648/ 1862] train: loss: 0.0008334
[Epoch 32; Iter  1678/ 1862] train: loss: 0.0608978
[Epoch 32; Iter  1708/ 1862] train: loss: 0.0015927
[Epoch 32; Iter  1738/ 1862] train: loss: 0.0021067
[Epoch 32; Iter  1768/ 1862] train: loss: 0.0011766
[Epoch 32; Iter  1798/ 1862] train: loss: 0.0015837
[Epoch 32; Iter  1828/ 1862] train: loss: 0.0664912
[Epoch 32; Iter  1858/ 1862] train: loss: 0.0024311
[Epoch 32] ogbg-molmuv: 0.082257 val loss: 0.013450
[Epoch 32] ogbg-molmuv: 0.086803 test loss: 0.012347
[Epoch 33; Iter    26/ 1862] train: loss: 0.0021115
[Epoch 33; Iter    56/ 1862] train: loss: 0.0016429
[Epoch 33; Iter    86/ 1862] train: loss: 0.0020942
[Epoch 33; Iter   116/ 1862] train: loss: 0.0009730
[Epoch 33; Iter   146/ 1862] train: loss: 0.0010307
[Epoch 33; Iter   176/ 1862] train: loss: 0.0632693
[Epoch 33; Iter   206/ 1862] train: loss: 0.0015690
[Epoch 33; Iter   236/ 1862] train: loss: 0.0059916
[Epoch 33; Iter   266/ 1862] train: loss: 0.0089694
[Epoch 33; Iter   296/ 1862] train: loss: 0.0009649
[Epoch 33; Iter   326/ 1862] train: loss: 0.0017027
[Epoch 33; Iter   356/ 1862] train: loss: 0.0167797
[Epoch 33; Iter   386/ 1862] train: loss: 0.0026092
[Epoch 33; Iter   416/ 1862] train: loss: 0.0200461
[Epoch 33; Iter   446/ 1862] train: loss: 0.0068389
[Epoch 33; Iter   476/ 1862] train: loss: 0.0013079
[Epoch 33; Iter   506/ 1862] train: loss: 0.0007564
[Epoch 33; Iter   536/ 1862] train: loss: 0.0010205
[Epoch 33; Iter   566/ 1862] train: loss: 0.0766302
[Epoch 33; Iter   596/ 1862] train: loss: 0.0166384
[Epoch 33; Iter   626/ 1862] train: loss: 0.0041943
[Epoch 33; Iter   656/ 1862] train: loss: 0.0015337
[Epoch 33; Iter   686/ 1862] train: loss: 0.0017584
[Epoch 33; Iter   716/ 1862] train: loss: 0.0014556
[Epoch 33; Iter   746/ 1862] train: loss: 0.0376705
[Epoch 33; Iter   776/ 1862] train: loss: 0.0137737
[Epoch 33; Iter   806/ 1862] train: loss: 0.0015207
[Epoch 33; Iter   836/ 1862] train: loss: 0.0013451
[Epoch 33; Iter   866/ 1862] train: loss: 0.0103063
[Epoch 33; Iter   896/ 1862] train: loss: 0.0847336
[Epoch 33; Iter   926/ 1862] train: loss: 0.0013761
[Epoch 33; Iter   956/ 1862] train: loss: 0.0031817
[Epoch 33; Iter   986/ 1862] train: loss: 0.0553569
[Epoch 33; Iter  1016/ 1862] train: loss: 0.0046753
[Epoch 33; Iter  1046/ 1862] train: loss: 0.0472927
[Epoch 33; Iter  1076/ 1862] train: loss: 0.0012237
[Epoch 33; Iter  1106/ 1862] train: loss: 0.0009901
[Epoch 33; Iter  1136/ 1862] train: loss: 0.0010539
[Epoch 33; Iter  1166/ 1862] train: loss: 0.0010566
[Epoch 33; Iter  1196/ 1862] train: loss: 0.0509978
[Epoch 33; Iter  1226/ 1862] train: loss: 0.0036808
[Epoch 33; Iter  1256/ 1862] train: loss: 0.0016173
[Epoch 33; Iter  1286/ 1862] train: loss: 0.0009353
[Epoch 33; Iter  1316/ 1862] train: loss: 0.0007898
[Epoch 33; Iter  1346/ 1862] train: loss: 0.0011984
[Epoch 33; Iter  1376/ 1862] train: loss: 0.0008304
[Epoch 33; Iter  1406/ 1862] train: loss: 0.0024423
[Epoch 33; Iter  1436/ 1862] train: loss: 0.0014237
[Epoch 33; Iter  1466/ 1862] train: loss: 0.0013388
[Epoch 33; Iter  1496/ 1862] train: loss: 0.0006204
[Epoch 33; Iter  1526/ 1862] train: loss: 0.0017894
[Epoch 33; Iter  1556/ 1862] train: loss: 0.0011913
[Epoch 33; Iter  1586/ 1862] train: loss: 0.0012684
[Epoch 33; Iter  1616/ 1862] train: loss: 0.0010784
[Epoch 33; Iter  1646/ 1862] train: loss: 0.0011906
[Epoch 33; Iter  1676/ 1862] train: loss: 0.0024593
[Epoch 33; Iter  1706/ 1862] train: loss: 0.0010866
[Epoch 33; Iter  1736/ 1862] train: loss: 0.0012035
[Epoch 33; Iter  1766/ 1862] train: loss: 0.0020351
[Epoch 33; Iter  1796/ 1862] train: loss: 0.0026696
[Epoch 33; Iter  1826/ 1862] train: loss: 0.0008923
[Epoch 33; Iter  1856/ 1862] train: loss: 0.0045262
[Epoch 33] ogbg-molmuv: 0.054071 val loss: 0.068924
[Epoch 33] ogbg-molmuv: 0.057472 test loss: 0.079108
[Epoch 34; Iter    24/ 1862] train: loss: 0.0017887
[Epoch 34; Iter    54/ 1862] train: loss: 0.0012287
[Epoch 34; Iter    84/ 1862] train: loss: 0.0052776
[Epoch 34; Iter   114/ 1862] train: loss: 0.0014817
[Epoch 34; Iter   144/ 1862] train: loss: 0.1082404
[Epoch 34; Iter   174/ 1862] train: loss: 0.0012197
[Epoch 34; Iter   204/ 1862] train: loss: 0.0034962
[Epoch 34; Iter   234/ 1862] train: loss: 0.0014451
[Epoch 34; Iter   264/ 1862] train: loss: 0.0020632
[Epoch 34; Iter   294/ 1862] train: loss: 0.0012765
[Epoch 34; Iter   324/ 1862] train: loss: 0.0007478
[Epoch 34; Iter   354/ 1862] train: loss: 0.0017128
[Epoch 34; Iter   384/ 1862] train: loss: 0.0009194
[Epoch 34; Iter   414/ 1862] train: loss: 0.0017103
[Epoch 34; Iter   444/ 1862] train: loss: 0.0028385
[Epoch 34; Iter   474/ 1862] train: loss: 0.0020873
[Epoch 34; Iter   504/ 1862] train: loss: 0.0015230
[Epoch 34; Iter   534/ 1862] train: loss: 0.0011075
[Epoch 34; Iter   564/ 1862] train: loss: 0.0010577
[Epoch 34; Iter   594/ 1862] train: loss: 0.0018997
[Epoch 34; Iter   624/ 1862] train: loss: 0.0012561
[Epoch 34; Iter   654/ 1862] train: loss: 0.0015984
[Epoch 34; Iter   684/ 1862] train: loss: 0.0033681
[Epoch 34; Iter   714/ 1862] train: loss: 0.0010945
[Epoch 34; Iter   744/ 1862] train: loss: 0.0523427
[Epoch 34; Iter   774/ 1862] train: loss: 0.0014692
[Epoch 34; Iter   804/ 1862] train: loss: 0.0017759
[Epoch 34; Iter   834/ 1862] train: loss: 0.0041560
[Epoch 34; Iter   864/ 1862] train: loss: 0.0011102
[Epoch 34; Iter   894/ 1862] train: loss: 0.0015588
[Epoch 34; Iter   924/ 1862] train: loss: 0.0015448
[Epoch 34; Iter   954/ 1862] train: loss: 0.0604551
[Epoch 34; Iter   984/ 1862] train: loss: 0.0007136
[Epoch 34; Iter  1014/ 1862] train: loss: 0.0876570
[Epoch 34; Iter  1044/ 1862] train: loss: 0.0022507
[Epoch 34; Iter  1074/ 1862] train: loss: 0.0018268
[Epoch 34; Iter  1104/ 1862] train: loss: 0.0006762
[Epoch 34; Iter  1134/ 1862] train: loss: 0.0012773
[Epoch 34; Iter  1164/ 1862] train: loss: 0.0023022
[Epoch 34; Iter  1194/ 1862] train: loss: 0.0014524
[Epoch 34; Iter  1224/ 1862] train: loss: 0.0014952
[Epoch 34; Iter  1254/ 1862] train: loss: 0.0441089
[Epoch 34; Iter  1284/ 1862] train: loss: 0.0355897
[Epoch 34; Iter  1314/ 1862] train: loss: 0.0013067
[Epoch 34; Iter  1344/ 1862] train: loss: 0.0020400
[Epoch 30; Iter   563/ 2483] train: loss: 0.0009251
[Epoch 30; Iter   593/ 2483] train: loss: 0.0008264
[Epoch 30; Iter   623/ 2483] train: loss: 0.0518715
[Epoch 30; Iter   653/ 2483] train: loss: 0.0015035
[Epoch 30; Iter   683/ 2483] train: loss: 0.0016121
[Epoch 30; Iter   713/ 2483] train: loss: 0.0918794
[Epoch 30; Iter   743/ 2483] train: loss: 0.0015159
[Epoch 30; Iter   773/ 2483] train: loss: 0.0023544
[Epoch 30; Iter   803/ 2483] train: loss: 0.0035033
[Epoch 30; Iter   833/ 2483] train: loss: 0.0095711
[Epoch 30; Iter   863/ 2483] train: loss: 0.0013454
[Epoch 30; Iter   893/ 2483] train: loss: 0.0400837
[Epoch 30; Iter   923/ 2483] train: loss: 0.0015257
[Epoch 30; Iter   953/ 2483] train: loss: 0.0019896
[Epoch 30; Iter   983/ 2483] train: loss: 0.0009870
[Epoch 30; Iter  1013/ 2483] train: loss: 0.0011846
[Epoch 30; Iter  1043/ 2483] train: loss: 0.0854520
[Epoch 30; Iter  1073/ 2483] train: loss: 0.0019691
[Epoch 30; Iter  1103/ 2483] train: loss: 0.0011959
[Epoch 30; Iter  1133/ 2483] train: loss: 0.0014093
[Epoch 30; Iter  1163/ 2483] train: loss: 0.0016829
[Epoch 30; Iter  1193/ 2483] train: loss: 0.0023018
[Epoch 30; Iter  1223/ 2483] train: loss: 0.0012278
[Epoch 30; Iter  1253/ 2483] train: loss: 0.0006589
[Epoch 30; Iter  1283/ 2483] train: loss: 0.0025898
[Epoch 30; Iter  1313/ 2483] train: loss: 0.0012468
[Epoch 30; Iter  1343/ 2483] train: loss: 0.0013810
[Epoch 30; Iter  1373/ 2483] train: loss: 0.0769329
[Epoch 30; Iter  1403/ 2483] train: loss: 0.0511599
[Epoch 30; Iter  1433/ 2483] train: loss: 0.0029993
[Epoch 30; Iter  1463/ 2483] train: loss: 0.0012938
[Epoch 30; Iter  1493/ 2483] train: loss: 0.0018576
[Epoch 30; Iter  1523/ 2483] train: loss: 0.0016677
[Epoch 30; Iter  1553/ 2483] train: loss: 0.0025387
[Epoch 30; Iter  1583/ 2483] train: loss: 0.0740420
[Epoch 30; Iter  1613/ 2483] train: loss: 0.0024451
[Epoch 30; Iter  1643/ 2483] train: loss: 0.0024531
[Epoch 30; Iter  1673/ 2483] train: loss: 0.0007579
[Epoch 30; Iter  1703/ 2483] train: loss: 0.0018206
[Epoch 30; Iter  1733/ 2483] train: loss: 0.0029159
[Epoch 30; Iter  1763/ 2483] train: loss: 0.0084598
[Epoch 30; Iter  1793/ 2483] train: loss: 0.0011423
[Epoch 30; Iter  1823/ 2483] train: loss: 0.0014261
[Epoch 30; Iter  1853/ 2483] train: loss: 0.0015859
[Epoch 30; Iter  1883/ 2483] train: loss: 0.0698842
[Epoch 30; Iter  1913/ 2483] train: loss: 0.0009497
[Epoch 30; Iter  1943/ 2483] train: loss: 0.0013532
[Epoch 30; Iter  1973/ 2483] train: loss: 0.1003071
[Epoch 30; Iter  2003/ 2483] train: loss: 0.0014275
[Epoch 30; Iter  2033/ 2483] train: loss: 0.0019606
[Epoch 30; Iter  2063/ 2483] train: loss: 0.0013342
[Epoch 30; Iter  2093/ 2483] train: loss: 0.0012277
[Epoch 30; Iter  2123/ 2483] train: loss: 0.0014690
[Epoch 30; Iter  2153/ 2483] train: loss: 0.0013581
[Epoch 30; Iter  2183/ 2483] train: loss: 0.0011035
[Epoch 30; Iter  2213/ 2483] train: loss: 0.0017832
[Epoch 30; Iter  2243/ 2483] train: loss: 0.0558136
[Epoch 30; Iter  2273/ 2483] train: loss: 0.0014403
[Epoch 30; Iter  2303/ 2483] train: loss: 0.0853252
[Epoch 30; Iter  2333/ 2483] train: loss: 0.0015836
[Epoch 30; Iter  2363/ 2483] train: loss: 0.0007878
[Epoch 30; Iter  2393/ 2483] train: loss: 0.0011164
[Epoch 30; Iter  2423/ 2483] train: loss: 0.0006903
[Epoch 30; Iter  2453/ 2483] train: loss: 0.0011118
[Epoch 30; Iter  2483/ 2483] train: loss: 0.0012146
[Epoch 30] ogbg-molmuv: 0.121996 val loss: 0.010595
[Epoch 30] ogbg-molmuv: 0.135578 test loss: 0.014299
[Epoch 31; Iter    30/ 2483] train: loss: 0.0011266
[Epoch 31; Iter    60/ 2483] train: loss: 0.0006155
[Epoch 31; Iter    90/ 2483] train: loss: 0.0014113
[Epoch 31; Iter   120/ 2483] train: loss: 0.0860975
[Epoch 31; Iter   150/ 2483] train: loss: 0.0020724
[Epoch 31; Iter   180/ 2483] train: loss: 0.0013108
[Epoch 31; Iter   210/ 2483] train: loss: 0.0021577
[Epoch 31; Iter   240/ 2483] train: loss: 0.0036336
[Epoch 31; Iter   270/ 2483] train: loss: 0.0485887
[Epoch 31; Iter   300/ 2483] train: loss: 0.0032056
[Epoch 31; Iter   330/ 2483] train: loss: 0.0013781
[Epoch 31; Iter   360/ 2483] train: loss: 0.0722893
[Epoch 31; Iter   390/ 2483] train: loss: 0.0557861
[Epoch 31; Iter   420/ 2483] train: loss: 0.0016953
[Epoch 31; Iter   450/ 2483] train: loss: 0.0019622
[Epoch 31; Iter   480/ 2483] train: loss: 0.0038335
[Epoch 31; Iter   510/ 2483] train: loss: 0.0822140
[Epoch 31; Iter   540/ 2483] train: loss: 0.0014067
[Epoch 31; Iter   570/ 2483] train: loss: 0.0415341
[Epoch 31; Iter   600/ 2483] train: loss: 0.0022421
[Epoch 31; Iter   630/ 2483] train: loss: 0.0010243
[Epoch 31; Iter   660/ 2483] train: loss: 0.0018969
[Epoch 31; Iter   690/ 2483] train: loss: 0.0011994
[Epoch 31; Iter   720/ 2483] train: loss: 0.0008943
[Epoch 31; Iter   750/ 2483] train: loss: 0.0016324
[Epoch 31; Iter   780/ 2483] train: loss: 0.0013039
[Epoch 31; Iter   810/ 2483] train: loss: 0.0019771
[Epoch 31; Iter   840/ 2483] train: loss: 0.0048699
[Epoch 31; Iter   870/ 2483] train: loss: 0.0421634
[Epoch 31; Iter   900/ 2483] train: loss: 0.0007943
[Epoch 31; Iter   930/ 2483] train: loss: 0.0807473
[Epoch 31; Iter   960/ 2483] train: loss: 0.0681027
[Epoch 31; Iter   990/ 2483] train: loss: 0.0010073
[Epoch 31; Iter  1020/ 2483] train: loss: 0.0013048
[Epoch 31; Iter  1050/ 2483] train: loss: 0.0013394
[Epoch 31; Iter  1080/ 2483] train: loss: 0.0007782
[Epoch 31; Iter  1110/ 2483] train: loss: 0.0012683
[Epoch 31; Iter  1140/ 2483] train: loss: 0.0018516
[Epoch 31; Iter  1170/ 2483] train: loss: 0.0016555
[Epoch 31; Iter  1200/ 2483] train: loss: 0.0022055
[Epoch 31; Iter  1230/ 2483] train: loss: 0.0015739
[Epoch 31; Iter  1260/ 2483] train: loss: 0.1496931
[Epoch 31; Iter  1290/ 2483] train: loss: 0.0018689
[Epoch 31; Iter  1320/ 2483] train: loss: 0.0022396
[Epoch 31; Iter  1350/ 2483] train: loss: 0.0744138
[Epoch 31; Iter  1380/ 2483] train: loss: 0.0022933
[Epoch 31; Iter  1410/ 2483] train: loss: 0.0015148
[Epoch 31; Iter  1440/ 2483] train: loss: 0.0012568
[Epoch 31; Iter  1470/ 2483] train: loss: 0.0013409
[Epoch 31; Iter  1500/ 2483] train: loss: 0.0013618
[Epoch 31; Iter  1530/ 2483] train: loss: 0.0024758
[Epoch 31; Iter  1560/ 2483] train: loss: 0.0034832
[Epoch 31; Iter  1590/ 2483] train: loss: 0.0016245
[Epoch 31; Iter  1620/ 2483] train: loss: 0.0007589
[Epoch 31; Iter  1650/ 2483] train: loss: 0.0541261
[Epoch 31; Iter  1680/ 2483] train: loss: 0.0018728
[Epoch 31; Iter  1710/ 2483] train: loss: 0.0017459
[Epoch 31; Iter  1740/ 2483] train: loss: 0.0016978
[Epoch 31; Iter  1770/ 2483] train: loss: 0.0636426
[Epoch 31; Iter  1800/ 2483] train: loss: 0.0009113
[Epoch 31; Iter  1830/ 2483] train: loss: 0.0012531
[Epoch 31; Iter  1860/ 2483] train: loss: 0.0014981
[Epoch 31; Iter  1890/ 2483] train: loss: 0.0010246
[Epoch 31; Iter  1920/ 2483] train: loss: 0.0013301
[Epoch 31; Iter  1950/ 2483] train: loss: 0.0144371
[Epoch 31; Iter  1980/ 2483] train: loss: 0.0712281
[Epoch 31; Iter  2010/ 2483] train: loss: 0.0009812
[Epoch 31; Iter  2040/ 2483] train: loss: 0.0018539
[Epoch 31; Iter  2070/ 2483] train: loss: 0.0010125
[Epoch 31; Iter  2100/ 2483] train: loss: 0.0010421
[Epoch 31; Iter  2130/ 2483] train: loss: 0.0010435
[Epoch 31; Iter  2160/ 2483] train: loss: 0.0011694
[Epoch 31; Iter  2190/ 2483] train: loss: 0.0010205
[Epoch 31; Iter  2220/ 2483] train: loss: 0.0011564
[Epoch 31; Iter  2250/ 2483] train: loss: 0.0011102
[Epoch 31; Iter  2280/ 2483] train: loss: 0.0014597
[Epoch 31; Iter  2310/ 2483] train: loss: 0.0115375
[Epoch 31; Iter  2340/ 2483] train: loss: 0.0006747
[Epoch 31; Iter  2370/ 2483] train: loss: 0.0050164
[Epoch 31; Iter  2400/ 2483] train: loss: 0.0013056
[Epoch 31; Iter  2430/ 2483] train: loss: 0.0015919
[Epoch 31; Iter  2460/ 2483] train: loss: 0.0990261
[Epoch 31] ogbg-molmuv: 0.098344 val loss: 0.070187
[Epoch 31] ogbg-molmuv: 0.123287 test loss: 0.089033
[Epoch 32; Iter     7/ 2483] train: loss: 0.0013688
[Epoch 32; Iter    37/ 2483] train: loss: 0.0046240
[Epoch 32; Iter    67/ 2483] train: loss: 0.0020198
[Epoch 32; Iter    97/ 2483] train: loss: 0.0016376
[Epoch 32; Iter   127/ 2483] train: loss: 0.0031527
[Epoch 32; Iter   157/ 2483] train: loss: 0.0015773
[Epoch 32; Iter   508/ 1862] train: loss: 0.0016535
[Epoch 32; Iter   538/ 1862] train: loss: 0.0008436
[Epoch 32; Iter   568/ 1862] train: loss: 0.0456232
[Epoch 32; Iter   598/ 1862] train: loss: 0.0011558
[Epoch 32; Iter   628/ 1862] train: loss: 0.0025896
[Epoch 32; Iter   658/ 1862] train: loss: 0.0017898
[Epoch 32; Iter   688/ 1862] train: loss: 0.0008650
[Epoch 32; Iter   718/ 1862] train: loss: 0.0438332
[Epoch 32; Iter   748/ 1862] train: loss: 0.0007393
[Epoch 32; Iter   778/ 1862] train: loss: 0.0014098
[Epoch 32; Iter   808/ 1862] train: loss: 0.0014946
[Epoch 32; Iter   838/ 1862] train: loss: 0.0767764
[Epoch 32; Iter   868/ 1862] train: loss: 0.0014582
[Epoch 32; Iter   898/ 1862] train: loss: 0.0009878
[Epoch 32; Iter   928/ 1862] train: loss: 0.0010596
[Epoch 32; Iter   958/ 1862] train: loss: 0.0012098
[Epoch 32; Iter   988/ 1862] train: loss: 0.0776484
[Epoch 32; Iter  1018/ 1862] train: loss: 0.0021270
[Epoch 32; Iter  1048/ 1862] train: loss: 0.0034668
[Epoch 32; Iter  1078/ 1862] train: loss: 0.0014266
[Epoch 32; Iter  1108/ 1862] train: loss: 0.0011395
[Epoch 32; Iter  1138/ 1862] train: loss: 0.1037721
[Epoch 32; Iter  1168/ 1862] train: loss: 0.0026619
[Epoch 32; Iter  1198/ 1862] train: loss: 0.0040130
[Epoch 32; Iter  1228/ 1862] train: loss: 0.0012074
[Epoch 32; Iter  1258/ 1862] train: loss: 0.0643395
[Epoch 32; Iter  1288/ 1862] train: loss: 0.0028328
[Epoch 32; Iter  1318/ 1862] train: loss: 0.0028128
[Epoch 32; Iter  1348/ 1862] train: loss: 0.0009008
[Epoch 32; Iter  1378/ 1862] train: loss: 0.0029772
[Epoch 32; Iter  1408/ 1862] train: loss: 0.0024859
[Epoch 32; Iter  1438/ 1862] train: loss: 0.0030385
[Epoch 32; Iter  1468/ 1862] train: loss: 0.0015394
[Epoch 32; Iter  1498/ 1862] train: loss: 0.0023682
[Epoch 32; Iter  1528/ 1862] train: loss: 0.0027405
[Epoch 32; Iter  1558/ 1862] train: loss: 0.0266999
[Epoch 32; Iter  1588/ 1862] train: loss: 0.0016228
[Epoch 32; Iter  1618/ 1862] train: loss: 0.0010692
[Epoch 32; Iter  1648/ 1862] train: loss: 0.0017612
[Epoch 32; Iter  1678/ 1862] train: loss: 0.0019505
[Epoch 32; Iter  1708/ 1862] train: loss: 0.0013450
[Epoch 32; Iter  1738/ 1862] train: loss: 0.0031089
[Epoch 32; Iter  1768/ 1862] train: loss: 0.0025171
[Epoch 32; Iter  1798/ 1862] train: loss: 0.0008877
[Epoch 32; Iter  1828/ 1862] train: loss: 0.0022616
[Epoch 32; Iter  1858/ 1862] train: loss: 0.0011857
[Epoch 32] ogbg-molmuv: 0.056841 val loss: 0.015279
[Epoch 32] ogbg-molmuv: 0.117945 test loss: 0.014245
[Epoch 33; Iter    26/ 1862] train: loss: 0.0016558
[Epoch 33; Iter    56/ 1862] train: loss: 0.0032994
[Epoch 33; Iter    86/ 1862] train: loss: 0.0013201
[Epoch 33; Iter   116/ 1862] train: loss: 0.0009818
[Epoch 33; Iter   146/ 1862] train: loss: 0.0013919
[Epoch 33; Iter   176/ 1862] train: loss: 0.0019132
[Epoch 33; Iter   206/ 1862] train: loss: 0.0015064
[Epoch 33; Iter   236/ 1862] train: loss: 0.0012736
[Epoch 33; Iter   266/ 1862] train: loss: 0.0910214
[Epoch 33; Iter   296/ 1862] train: loss: 0.0029942
[Epoch 33; Iter   326/ 1862] train: loss: 0.0013627
[Epoch 33; Iter   356/ 1862] train: loss: 0.0009793
[Epoch 33; Iter   386/ 1862] train: loss: 0.0094950
[Epoch 33; Iter   416/ 1862] train: loss: 0.0029419
[Epoch 33; Iter   446/ 1862] train: loss: 0.0020365
[Epoch 33; Iter   476/ 1862] train: loss: 0.0037137
[Epoch 33; Iter   506/ 1862] train: loss: 0.0015365
[Epoch 33; Iter   536/ 1862] train: loss: 0.0010320
[Epoch 33; Iter   566/ 1862] train: loss: 0.0087212
[Epoch 33; Iter   596/ 1862] train: loss: 0.0022496
[Epoch 33; Iter   626/ 1862] train: loss: 0.0010825
[Epoch 33; Iter   656/ 1862] train: loss: 0.0021567
[Epoch 33; Iter   686/ 1862] train: loss: 0.0013086
[Epoch 33; Iter   716/ 1862] train: loss: 0.0010023
[Epoch 33; Iter   746/ 1862] train: loss: 0.0009459
[Epoch 33; Iter   776/ 1862] train: loss: 0.0013119
[Epoch 33; Iter   806/ 1862] train: loss: 0.0599098
[Epoch 33; Iter   836/ 1862] train: loss: 0.0395905
[Epoch 33; Iter   866/ 1862] train: loss: 0.0014104
[Epoch 33; Iter   896/ 1862] train: loss: 0.0016357
[Epoch 33; Iter   926/ 1862] train: loss: 0.0018423
[Epoch 33; Iter   956/ 1862] train: loss: 0.0013778
[Epoch 33; Iter   986/ 1862] train: loss: 0.0015943
[Epoch 33; Iter  1016/ 1862] train: loss: 0.0010238
[Epoch 33; Iter  1046/ 1862] train: loss: 0.0026088
[Epoch 33; Iter  1076/ 1862] train: loss: 0.0038707
[Epoch 33; Iter  1106/ 1862] train: loss: 0.0012849
[Epoch 33; Iter  1136/ 1862] train: loss: 0.0013265
[Epoch 33; Iter  1166/ 1862] train: loss: 0.0012131
[Epoch 33; Iter  1196/ 1862] train: loss: 0.0012893
[Epoch 33; Iter  1226/ 1862] train: loss: 0.0016032
[Epoch 33; Iter  1256/ 1862] train: loss: 0.0013718
[Epoch 33; Iter  1286/ 1862] train: loss: 0.0010886
[Epoch 33; Iter  1316/ 1862] train: loss: 0.0021918
[Epoch 33; Iter  1346/ 1862] train: loss: 0.0012027
[Epoch 33; Iter  1376/ 1862] train: loss: 0.0012231
[Epoch 33; Iter  1406/ 1862] train: loss: 0.0009890
[Epoch 33; Iter  1436/ 1862] train: loss: 0.0015635
[Epoch 33; Iter  1466/ 1862] train: loss: 0.0027271
[Epoch 33; Iter  1496/ 1862] train: loss: 0.0013995
[Epoch 33; Iter  1526/ 1862] train: loss: 0.0011059
[Epoch 33; Iter  1556/ 1862] train: loss: 0.0032764
[Epoch 33; Iter  1586/ 1862] train: loss: 0.0009420
[Epoch 33; Iter  1616/ 1862] train: loss: 0.0307202
[Epoch 33; Iter  1646/ 1862] train: loss: 0.0094241
[Epoch 33; Iter  1676/ 1862] train: loss: 0.0028943
[Epoch 33; Iter  1706/ 1862] train: loss: 0.0010644
[Epoch 33; Iter  1736/ 1862] train: loss: 0.0014020
[Epoch 33; Iter  1766/ 1862] train: loss: 0.0668895
[Epoch 33; Iter  1796/ 1862] train: loss: 0.0015662
[Epoch 33; Iter  1826/ 1862] train: loss: 0.0043862
[Epoch 33; Iter  1856/ 1862] train: loss: 0.0021429
[Epoch 33] ogbg-molmuv: 0.071980 val loss: 0.014219
[Epoch 33] ogbg-molmuv: 0.121766 test loss: 0.011912
[Epoch 34; Iter    24/ 1862] train: loss: 0.1080675
[Epoch 34; Iter    54/ 1862] train: loss: 0.0010145
[Epoch 34; Iter    84/ 1862] train: loss: 0.0012734
[Epoch 34; Iter   114/ 1862] train: loss: 0.0012072
[Epoch 34; Iter   144/ 1862] train: loss: 0.0009594
[Epoch 34; Iter   174/ 1862] train: loss: 0.0035257
[Epoch 34; Iter   204/ 1862] train: loss: 0.0016981
[Epoch 34; Iter   234/ 1862] train: loss: 0.0025134
[Epoch 34; Iter   264/ 1862] train: loss: 0.0017308
[Epoch 34; Iter   294/ 1862] train: loss: 0.0014272
[Epoch 34; Iter   324/ 1862] train: loss: 0.0021906
[Epoch 34; Iter   354/ 1862] train: loss: 0.0014948
[Epoch 34; Iter   384/ 1862] train: loss: 0.0018970
[Epoch 34; Iter   414/ 1862] train: loss: 0.0124997
[Epoch 34; Iter   444/ 1862] train: loss: 0.0009846
[Epoch 34; Iter   474/ 1862] train: loss: 0.0012111
[Epoch 34; Iter   504/ 1862] train: loss: 0.0013883
[Epoch 34; Iter   534/ 1862] train: loss: 0.0009827
[Epoch 34; Iter   564/ 1862] train: loss: 0.0021437
[Epoch 34; Iter   594/ 1862] train: loss: 0.0037553
[Epoch 34; Iter   624/ 1862] train: loss: 0.0012658
[Epoch 34; Iter   654/ 1862] train: loss: 0.0018264
[Epoch 34; Iter   684/ 1862] train: loss: 0.0015287
[Epoch 34; Iter   714/ 1862] train: loss: 0.0018154
[Epoch 34; Iter   744/ 1862] train: loss: 0.0013806
[Epoch 34; Iter   774/ 1862] train: loss: 0.0020930
[Epoch 34; Iter   804/ 1862] train: loss: 0.0013030
[Epoch 34; Iter   834/ 1862] train: loss: 0.0008992
[Epoch 34; Iter   864/ 1862] train: loss: 0.0015876
[Epoch 34; Iter   894/ 1862] train: loss: 0.0008447
[Epoch 34; Iter   924/ 1862] train: loss: 0.0008966
[Epoch 34; Iter   954/ 1862] train: loss: 0.0015180
[Epoch 34; Iter   984/ 1862] train: loss: 0.0015297
[Epoch 34; Iter  1014/ 1862] train: loss: 0.0009665
[Epoch 34; Iter  1044/ 1862] train: loss: 0.0012303
[Epoch 34; Iter  1074/ 1862] train: loss: 0.0013949
[Epoch 34; Iter  1104/ 1862] train: loss: 0.0012312
[Epoch 34; Iter  1134/ 1862] train: loss: 0.0014093
[Epoch 34; Iter  1164/ 1862] train: loss: 0.0018968
[Epoch 34; Iter  1194/ 1862] train: loss: 0.0012651
[Epoch 34; Iter  1224/ 1862] train: loss: 0.0016683
[Epoch 34; Iter  1254/ 1862] train: loss: 0.0102308
[Epoch 34; Iter  1284/ 1862] train: loss: 0.0019881
[Epoch 34; Iter  1314/ 1862] train: loss: 0.0009818
[Epoch 34; Iter  1344/ 1862] train: loss: 0.0010910
[Epoch 32; Iter   378/ 2172] train: loss: 0.0015181
[Epoch 32; Iter   408/ 2172] train: loss: 0.0096575
[Epoch 32; Iter   438/ 2172] train: loss: 0.0009556
[Epoch 32; Iter   468/ 2172] train: loss: 0.0007963
[Epoch 32; Iter   498/ 2172] train: loss: 0.0024204
[Epoch 32; Iter   528/ 2172] train: loss: 0.0012515
[Epoch 32; Iter   558/ 2172] train: loss: 0.0007745
[Epoch 32; Iter   588/ 2172] train: loss: 0.0900329
[Epoch 32; Iter   618/ 2172] train: loss: 0.0013526
[Epoch 32; Iter   648/ 2172] train: loss: 0.0008346
[Epoch 32; Iter   678/ 2172] train: loss: 0.0011307
[Epoch 32; Iter   708/ 2172] train: loss: 0.0026420
[Epoch 32; Iter   738/ 2172] train: loss: 0.0990059
[Epoch 32; Iter   768/ 2172] train: loss: 0.0045680
[Epoch 32; Iter   798/ 2172] train: loss: 0.0042721
[Epoch 32; Iter   828/ 2172] train: loss: 0.0279970
[Epoch 32; Iter   858/ 2172] train: loss: 0.0010411
[Epoch 32; Iter   888/ 2172] train: loss: 0.0008859
[Epoch 32; Iter   918/ 2172] train: loss: 0.0021975
[Epoch 32; Iter   948/ 2172] train: loss: 0.0528874
[Epoch 32; Iter   978/ 2172] train: loss: 0.0005964
[Epoch 32; Iter  1008/ 2172] train: loss: 0.0014708
[Epoch 32; Iter  1038/ 2172] train: loss: 0.1481233
[Epoch 32; Iter  1068/ 2172] train: loss: 0.0010026
[Epoch 32; Iter  1098/ 2172] train: loss: 0.0016786
[Epoch 32; Iter  1128/ 2172] train: loss: 0.0010605
[Epoch 32; Iter  1158/ 2172] train: loss: 0.0032916
[Epoch 32; Iter  1188/ 2172] train: loss: 0.0009054
[Epoch 32; Iter  1218/ 2172] train: loss: 0.0577461
[Epoch 32; Iter  1248/ 2172] train: loss: 0.0435413
[Epoch 32; Iter  1278/ 2172] train: loss: 0.0011969
[Epoch 32; Iter  1308/ 2172] train: loss: 0.0037641
[Epoch 32; Iter  1338/ 2172] train: loss: 0.0014074
[Epoch 32; Iter  1368/ 2172] train: loss: 0.0011124
[Epoch 32; Iter  1398/ 2172] train: loss: 0.0007767
[Epoch 32; Iter  1428/ 2172] train: loss: 0.0012706
[Epoch 32; Iter  1458/ 2172] train: loss: 0.0010193
[Epoch 32; Iter  1488/ 2172] train: loss: 0.0013325
[Epoch 32; Iter  1518/ 2172] train: loss: 0.0009476
[Epoch 32; Iter  1548/ 2172] train: loss: 0.0010200
[Epoch 32; Iter  1578/ 2172] train: loss: 0.0010248
[Epoch 32; Iter  1608/ 2172] train: loss: 0.0007911
[Epoch 32; Iter  1638/ 2172] train: loss: 0.0022521
[Epoch 32; Iter  1668/ 2172] train: loss: 0.0007893
[Epoch 32; Iter  1698/ 2172] train: loss: 0.0035346
[Epoch 32; Iter  1728/ 2172] train: loss: 0.0021223
[Epoch 32; Iter  1758/ 2172] train: loss: 0.0014325
[Epoch 32; Iter  1788/ 2172] train: loss: 0.0012691
[Epoch 32; Iter  1818/ 2172] train: loss: 0.0022911
[Epoch 32; Iter  1848/ 2172] train: loss: 0.0014534
[Epoch 32; Iter  1878/ 2172] train: loss: 0.0008704
[Epoch 32; Iter  1908/ 2172] train: loss: 0.0022059
[Epoch 32; Iter  1938/ 2172] train: loss: 0.0011249
[Epoch 32; Iter  1968/ 2172] train: loss: 0.0012415
[Epoch 32; Iter  1998/ 2172] train: loss: 0.0009881
[Epoch 32; Iter  2028/ 2172] train: loss: 0.0010150
[Epoch 32; Iter  2058/ 2172] train: loss: 0.0016928
[Epoch 32; Iter  2088/ 2172] train: loss: 0.0005766
[Epoch 32; Iter  2118/ 2172] train: loss: 0.0013537
[Epoch 32; Iter  2148/ 2172] train: loss: 0.0010120
[Epoch 32] ogbg-molmuv: 0.112300 val loss: 0.013129
[Epoch 32] ogbg-molmuv: 0.126301 test loss: 0.067840
[Epoch 33; Iter     6/ 2172] train: loss: 0.0026346
[Epoch 33; Iter    36/ 2172] train: loss: 0.0018444
[Epoch 33; Iter    66/ 2172] train: loss: 0.0011452
[Epoch 33; Iter    96/ 2172] train: loss: 0.0009226
[Epoch 33; Iter   126/ 2172] train: loss: 0.0044686
[Epoch 33; Iter   156/ 2172] train: loss: 0.0006209
[Epoch 33; Iter   186/ 2172] train: loss: 0.0014986
[Epoch 33; Iter   216/ 2172] train: loss: 0.0005382
[Epoch 33; Iter   246/ 2172] train: loss: 0.0151195
[Epoch 33; Iter   276/ 2172] train: loss: 0.0018403
[Epoch 33; Iter   306/ 2172] train: loss: 0.0010231
[Epoch 33; Iter   336/ 2172] train: loss: 0.0007666
[Epoch 33; Iter   366/ 2172] train: loss: 0.0008548
[Epoch 33; Iter   396/ 2172] train: loss: 0.0006333
[Epoch 33; Iter   426/ 2172] train: loss: 0.0004315
[Epoch 33; Iter   456/ 2172] train: loss: 0.0675069
[Epoch 33; Iter   486/ 2172] train: loss: 0.0018798
[Epoch 33; Iter   516/ 2172] train: loss: 0.0008501
[Epoch 33; Iter   546/ 2172] train: loss: 0.0012103
[Epoch 33; Iter   576/ 2172] train: loss: 0.0009015
[Epoch 33; Iter   606/ 2172] train: loss: 0.0007229
[Epoch 33; Iter   636/ 2172] train: loss: 0.0020459
[Epoch 33; Iter   666/ 2172] train: loss: 0.0010634
[Epoch 33; Iter   696/ 2172] train: loss: 0.0008764
[Epoch 33; Iter   726/ 2172] train: loss: 0.0013611
[Epoch 33; Iter   756/ 2172] train: loss: 0.0017919
[Epoch 33; Iter   786/ 2172] train: loss: 0.0651020
[Epoch 33; Iter   816/ 2172] train: loss: 0.0010968
[Epoch 33; Iter   846/ 2172] train: loss: 0.0006819
[Epoch 33; Iter   876/ 2172] train: loss: 0.0265149
[Epoch 33; Iter   906/ 2172] train: loss: 0.0146007
[Epoch 33; Iter   936/ 2172] train: loss: 0.0026646
[Epoch 33; Iter   966/ 2172] train: loss: 0.0029591
[Epoch 33; Iter   996/ 2172] train: loss: 0.0035929
[Epoch 33; Iter  1026/ 2172] train: loss: 0.0015461
[Epoch 33; Iter  1056/ 2172] train: loss: 0.0018706
[Epoch 33; Iter  1086/ 2172] train: loss: 0.0209694
[Epoch 33; Iter  1116/ 2172] train: loss: 0.0011517
[Epoch 33; Iter  1146/ 2172] train: loss: 0.0013644
[Epoch 33; Iter  1176/ 2172] train: loss: 0.0020615
[Epoch 33; Iter  1206/ 2172] train: loss: 0.0006432
[Epoch 33; Iter  1236/ 2172] train: loss: 0.0007920
[Epoch 33; Iter  1266/ 2172] train: loss: 0.0011137
[Epoch 33; Iter  1296/ 2172] train: loss: 0.0020841
[Epoch 33; Iter  1326/ 2172] train: loss: 0.0013373
[Epoch 33; Iter  1356/ 2172] train: loss: 0.0013799
[Epoch 33; Iter  1386/ 2172] train: loss: 0.0003941
[Epoch 33; Iter  1416/ 2172] train: loss: 0.0011718
[Epoch 33; Iter  1446/ 2172] train: loss: 0.0021199
[Epoch 33; Iter  1476/ 2172] train: loss: 0.0005050
[Epoch 33; Iter  1506/ 2172] train: loss: 0.0009017
[Epoch 33; Iter  1536/ 2172] train: loss: 0.0014336
[Epoch 33; Iter  1566/ 2172] train: loss: 0.0006190
[Epoch 33; Iter  1596/ 2172] train: loss: 0.0008372
[Epoch 33; Iter  1626/ 2172] train: loss: 0.0011566
[Epoch 33; Iter  1656/ 2172] train: loss: 0.0832810
[Epoch 33; Iter  1686/ 2172] train: loss: 0.0011922
[Epoch 33; Iter  1716/ 2172] train: loss: 0.0007984
[Epoch 33; Iter  1746/ 2172] train: loss: 0.0017592
[Epoch 33; Iter  1776/ 2172] train: loss: 0.0038585
[Epoch 33; Iter  1806/ 2172] train: loss: 0.0167685
[Epoch 33; Iter  1836/ 2172] train: loss: 0.0013932
[Epoch 33; Iter  1866/ 2172] train: loss: 0.0024322
[Epoch 33; Iter  1896/ 2172] train: loss: 0.0013939
[Epoch 33; Iter  1926/ 2172] train: loss: 0.0080797
[Epoch 33; Iter  1956/ 2172] train: loss: 0.0012347
[Epoch 33; Iter  1986/ 2172] train: loss: 0.0007912
[Epoch 33; Iter  2016/ 2172] train: loss: 0.0017070
[Epoch 33; Iter  2046/ 2172] train: loss: 0.0129051
[Epoch 33; Iter  2076/ 2172] train: loss: 0.0010338
[Epoch 33; Iter  2106/ 2172] train: loss: 0.0006081
[Epoch 33; Iter  2136/ 2172] train: loss: 0.0023279
[Epoch 33; Iter  2166/ 2172] train: loss: 0.0017723
[Epoch 33] ogbg-molmuv: 0.083268 val loss: 0.012847
[Epoch 33] ogbg-molmuv: 0.096640 test loss: 0.016830
[Epoch 34; Iter    24/ 2172] train: loss: 0.0764354
[Epoch 34; Iter    54/ 2172] train: loss: 0.0280885
[Epoch 34; Iter    84/ 2172] train: loss: 0.0009240
[Epoch 34; Iter   114/ 2172] train: loss: 0.0014096
[Epoch 34; Iter   144/ 2172] train: loss: 0.0006903
[Epoch 34; Iter   174/ 2172] train: loss: 0.0007999
[Epoch 34; Iter   204/ 2172] train: loss: 0.0047580
[Epoch 34; Iter   234/ 2172] train: loss: 0.0005431
[Epoch 34; Iter   264/ 2172] train: loss: 0.0015315
[Epoch 34; Iter   294/ 2172] train: loss: 0.0007280
[Epoch 34; Iter   324/ 2172] train: loss: 0.0014567
[Epoch 34; Iter   354/ 2172] train: loss: 0.0022239
[Epoch 34; Iter   384/ 2172] train: loss: 0.0022149
[Epoch 34; Iter   414/ 2172] train: loss: 0.0020159
[Epoch 34; Iter   444/ 2172] train: loss: 0.0019595
[Epoch 34; Iter   474/ 2172] train: loss: 0.0009691
[Epoch 34; Iter   504/ 2172] train: loss: 0.0020123
[Epoch 34; Iter   534/ 2172] train: loss: 0.0009228
[Epoch 34; Iter   564/ 2172] train: loss: 0.0015290
[Epoch 34; Iter   594/ 2172] train: loss: 0.0021416
[Epoch 32; Iter   378/ 2172] train: loss: 0.0014655
[Epoch 32; Iter   408/ 2172] train: loss: 0.0014036
[Epoch 32; Iter   438/ 2172] train: loss: 0.0008060
[Epoch 32; Iter   468/ 2172] train: loss: 0.0808153
[Epoch 32; Iter   498/ 2172] train: loss: 0.0678414
[Epoch 32; Iter   528/ 2172] train: loss: 0.0010655
[Epoch 32; Iter   558/ 2172] train: loss: 0.0012415
[Epoch 32; Iter   588/ 2172] train: loss: 0.0010388
[Epoch 32; Iter   618/ 2172] train: loss: 0.0015235
[Epoch 32; Iter   648/ 2172] train: loss: 0.0074749
[Epoch 32; Iter   678/ 2172] train: loss: 0.0767377
[Epoch 32; Iter   708/ 2172] train: loss: 0.0090477
[Epoch 32; Iter   738/ 2172] train: loss: 0.0009726
[Epoch 32; Iter   768/ 2172] train: loss: 0.0013721
[Epoch 32; Iter   798/ 2172] train: loss: 0.0014576
[Epoch 32; Iter   828/ 2172] train: loss: 0.0010641
[Epoch 32; Iter   858/ 2172] train: loss: 0.0017260
[Epoch 32; Iter   888/ 2172] train: loss: 0.0011182
[Epoch 32; Iter   918/ 2172] train: loss: 0.0017744
[Epoch 32; Iter   948/ 2172] train: loss: 0.0637054
[Epoch 32; Iter   978/ 2172] train: loss: 0.0013904
[Epoch 32; Iter  1008/ 2172] train: loss: 0.0010127
[Epoch 32; Iter  1038/ 2172] train: loss: 0.0010046
[Epoch 32; Iter  1068/ 2172] train: loss: 0.0006140
[Epoch 32; Iter  1098/ 2172] train: loss: 0.0013755
[Epoch 32; Iter  1128/ 2172] train: loss: 0.0434686
[Epoch 32; Iter  1158/ 2172] train: loss: 0.0008951
[Epoch 32; Iter  1188/ 2172] train: loss: 0.0384659
[Epoch 32; Iter  1218/ 2172] train: loss: 0.0019988
[Epoch 32; Iter  1248/ 2172] train: loss: 0.0006810
[Epoch 32; Iter  1278/ 2172] train: loss: 0.1507566
[Epoch 32; Iter  1308/ 2172] train: loss: 0.0028046
[Epoch 32; Iter  1338/ 2172] train: loss: 0.0460450
[Epoch 32; Iter  1368/ 2172] train: loss: 0.0019457
[Epoch 32; Iter  1398/ 2172] train: loss: 0.0021995
[Epoch 32; Iter  1428/ 2172] train: loss: 0.0011632
[Epoch 32; Iter  1458/ 2172] train: loss: 0.0343997
[Epoch 32; Iter  1488/ 2172] train: loss: 0.0016016
[Epoch 32; Iter  1518/ 2172] train: loss: 0.0023614
[Epoch 32; Iter  1548/ 2172] train: loss: 0.0008081
[Epoch 32; Iter  1578/ 2172] train: loss: 0.0020600
[Epoch 32; Iter  1608/ 2172] train: loss: 0.0011712
[Epoch 32; Iter  1638/ 2172] train: loss: 0.0017996
[Epoch 32; Iter  1668/ 2172] train: loss: 0.0011265
[Epoch 32; Iter  1698/ 2172] train: loss: 0.0019533
[Epoch 32; Iter  1728/ 2172] train: loss: 0.0013114
[Epoch 32; Iter  1758/ 2172] train: loss: 0.0252230
[Epoch 32; Iter  1788/ 2172] train: loss: 0.0008079
[Epoch 32; Iter  1818/ 2172] train: loss: 0.0015082
[Epoch 32; Iter  1848/ 2172] train: loss: 0.0015603
[Epoch 32; Iter  1878/ 2172] train: loss: 0.0897295
[Epoch 32; Iter  1908/ 2172] train: loss: 0.0015077
[Epoch 32; Iter  1938/ 2172] train: loss: 0.0023402
[Epoch 32; Iter  1968/ 2172] train: loss: 0.0028218
[Epoch 32; Iter  1998/ 2172] train: loss: 0.0021972
[Epoch 32; Iter  2028/ 2172] train: loss: 0.0760239
[Epoch 32; Iter  2058/ 2172] train: loss: 0.0020191
[Epoch 32; Iter  2088/ 2172] train: loss: 0.0013743
[Epoch 32; Iter  2118/ 2172] train: loss: 0.0008253
[Epoch 32; Iter  2148/ 2172] train: loss: 0.0197994
[Epoch 32] ogbg-molmuv: 0.076787 val loss: 0.011856
[Epoch 32] ogbg-molmuv: 0.134328 test loss: 0.017943
[Epoch 33; Iter     6/ 2172] train: loss: 0.0028459
[Epoch 33; Iter    36/ 2172] train: loss: 0.0219619
[Epoch 33; Iter    66/ 2172] train: loss: 0.0019625
[Epoch 33; Iter    96/ 2172] train: loss: 0.0483487
[Epoch 33; Iter   126/ 2172] train: loss: 0.0874838
[Epoch 33; Iter   156/ 2172] train: loss: 0.0015253
[Epoch 33; Iter   186/ 2172] train: loss: 0.0508285
[Epoch 33; Iter   216/ 2172] train: loss: 0.0012840
[Epoch 33; Iter   246/ 2172] train: loss: 0.0020189
[Epoch 33; Iter   276/ 2172] train: loss: 0.0011134
[Epoch 33; Iter   306/ 2172] train: loss: 0.0012220
[Epoch 33; Iter   336/ 2172] train: loss: 0.0016957
[Epoch 33; Iter   366/ 2172] train: loss: 0.0011712
[Epoch 33; Iter   396/ 2172] train: loss: 0.0181035
[Epoch 33; Iter   426/ 2172] train: loss: 0.0018581
[Epoch 33; Iter   456/ 2172] train: loss: 0.0009713
[Epoch 33; Iter   486/ 2172] train: loss: 0.0684646
[Epoch 33; Iter   516/ 2172] train: loss: 0.0014481
[Epoch 33; Iter   546/ 2172] train: loss: 0.0021563
[Epoch 33; Iter   576/ 2172] train: loss: 0.0015683
[Epoch 33; Iter   606/ 2172] train: loss: 0.0006707
[Epoch 33; Iter   636/ 2172] train: loss: 0.0870048
[Epoch 33; Iter   666/ 2172] train: loss: 0.0014403
[Epoch 33; Iter   696/ 2172] train: loss: 0.0007659
[Epoch 33; Iter   726/ 2172] train: loss: 0.0371202
[Epoch 33; Iter   756/ 2172] train: loss: 0.0017110
[Epoch 33; Iter   786/ 2172] train: loss: 0.0012971
[Epoch 33; Iter   816/ 2172] train: loss: 0.0019941
[Epoch 33; Iter   846/ 2172] train: loss: 0.0009542
[Epoch 33; Iter   876/ 2172] train: loss: 0.0016075
[Epoch 33; Iter   906/ 2172] train: loss: 0.0012613
[Epoch 33; Iter   936/ 2172] train: loss: 0.0011823
[Epoch 33; Iter   966/ 2172] train: loss: 0.0012726
[Epoch 33; Iter   996/ 2172] train: loss: 0.0013325
[Epoch 33; Iter  1026/ 2172] train: loss: 0.0019359
[Epoch 33; Iter  1056/ 2172] train: loss: 0.0027620
[Epoch 33; Iter  1086/ 2172] train: loss: 0.0010822
[Epoch 33; Iter  1116/ 2172] train: loss: 0.0013323
[Epoch 33; Iter  1146/ 2172] train: loss: 0.0021217
[Epoch 33; Iter  1176/ 2172] train: loss: 0.0012514
[Epoch 33; Iter  1206/ 2172] train: loss: 0.0013782
[Epoch 33; Iter  1236/ 2172] train: loss: 0.0228838
[Epoch 33; Iter  1266/ 2172] train: loss: 0.0011636
[Epoch 33; Iter  1296/ 2172] train: loss: 0.0018560
[Epoch 33; Iter  1326/ 2172] train: loss: 0.0012814
[Epoch 33; Iter  1356/ 2172] train: loss: 0.0011674
[Epoch 33; Iter  1386/ 2172] train: loss: 0.0013182
[Epoch 33; Iter  1416/ 2172] train: loss: 0.0009448
[Epoch 33; Iter  1446/ 2172] train: loss: 0.0193576
[Epoch 33; Iter  1476/ 2172] train: loss: 0.0039208
[Epoch 33; Iter  1506/ 2172] train: loss: 0.0009030
[Epoch 33; Iter  1536/ 2172] train: loss: 0.0023769
[Epoch 33; Iter  1566/ 2172] train: loss: 0.0010732
[Epoch 33; Iter  1596/ 2172] train: loss: 0.0769997
[Epoch 33; Iter  1626/ 2172] train: loss: 0.0014252
[Epoch 33; Iter  1656/ 2172] train: loss: 0.0018571
[Epoch 33; Iter  1686/ 2172] train: loss: 0.0018596
[Epoch 33; Iter  1716/ 2172] train: loss: 0.0008144
[Epoch 33; Iter  1746/ 2172] train: loss: 0.0006080
[Epoch 33; Iter  1776/ 2172] train: loss: 0.0008569
[Epoch 33; Iter  1806/ 2172] train: loss: 0.0008021
[Epoch 33; Iter  1836/ 2172] train: loss: 0.0014283
[Epoch 33; Iter  1866/ 2172] train: loss: 0.0012770
[Epoch 33; Iter  1896/ 2172] train: loss: 0.0006366
[Epoch 33; Iter  1926/ 2172] train: loss: 0.0012701
[Epoch 33; Iter  1956/ 2172] train: loss: 0.0646522
[Epoch 33; Iter  1986/ 2172] train: loss: 0.0086350
[Epoch 33; Iter  2016/ 2172] train: loss: 0.0016947
[Epoch 33; Iter  2046/ 2172] train: loss: 0.0056993
[Epoch 33; Iter  2076/ 2172] train: loss: 0.0014574
[Epoch 33; Iter  2106/ 2172] train: loss: 0.0014503
[Epoch 33; Iter  2136/ 2172] train: loss: 0.0107301
[Epoch 33; Iter  2166/ 2172] train: loss: 0.0011393
[Epoch 33] ogbg-molmuv: 0.075545 val loss: 0.020184
[Epoch 33] ogbg-molmuv: 0.118519 test loss: 0.013118
[Epoch 34; Iter    24/ 2172] train: loss: 0.0005689
[Epoch 34; Iter    54/ 2172] train: loss: 0.0010722
[Epoch 34; Iter    84/ 2172] train: loss: 0.0006568
[Epoch 34; Iter   114/ 2172] train: loss: 0.0010937
[Epoch 34; Iter   144/ 2172] train: loss: 0.0010151
[Epoch 34; Iter   174/ 2172] train: loss: 0.0009009
[Epoch 34; Iter   204/ 2172] train: loss: 0.0011265
[Epoch 34; Iter   234/ 2172] train: loss: 0.0017297
[Epoch 34; Iter   264/ 2172] train: loss: 0.0007119
[Epoch 34; Iter   294/ 2172] train: loss: 0.0011994
[Epoch 34; Iter   324/ 2172] train: loss: 0.0011881
[Epoch 34; Iter   354/ 2172] train: loss: 0.0013785
[Epoch 34; Iter   384/ 2172] train: loss: 0.0016430
[Epoch 34; Iter   414/ 2172] train: loss: 0.0008421
[Epoch 34; Iter   444/ 2172] train: loss: 0.0673274
[Epoch 34; Iter   474/ 2172] train: loss: 0.0153396
[Epoch 34; Iter   504/ 2172] train: loss: 0.0016433
[Epoch 34; Iter   534/ 2172] train: loss: 0.0012219
[Epoch 34; Iter   564/ 2172] train: loss: 0.0048633
[Epoch 34; Iter   594/ 2172] train: loss: 0.0112657
