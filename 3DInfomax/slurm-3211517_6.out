>>> Starting run for dataset: tox21
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_random=0.8_4_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.8
logdir: runs/split/GraphCL/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930819
[Epoch 1; Iter    60/  209] train: loss: 0.6928445
[Epoch 1; Iter    90/  209] train: loss: 0.6931478
[Epoch 1; Iter   120/  209] train: loss: 0.6925783
[Epoch 1; Iter   150/  209] train: loss: 0.6924648
[Epoch 1; Iter   180/  209] train: loss: 0.6923455
[Epoch 1] ogbg-moltox21: 0.496915 val loss: 0.692364
[Epoch 1] ogbg-moltox21: 0.503841 test loss: 0.692483
[Epoch 2; Iter     1/  209] train: loss: 0.6927668
[Epoch 2; Iter    31/  209] train: loss: 0.6924518
[Epoch 2; Iter    61/  209] train: loss: 0.6924627
[Epoch 2; Iter    91/  209] train: loss: 0.6919147
[Epoch 2; Iter   121/  209] train: loss: 0.6912045
[Epoch 2; Iter   151/  209] train: loss: 0.6916237
[Epoch 2; Iter   181/  209] train: loss: 0.6916931
[Epoch 2] ogbg-moltox21: 0.499719 val loss: 0.690717
[Epoch 2] ogbg-moltox21: 0.508411 test loss: 0.690797
[Epoch 3; Iter     2/  209] train: loss: 0.6909513
[Epoch 3; Iter    32/  209] train: loss: 0.6897563
[Epoch 3; Iter    62/  209] train: loss: 0.6908516
[Epoch 3; Iter    92/  209] train: loss: 0.6898881
[Epoch 3; Iter   122/  209] train: loss: 0.6892156
[Epoch 3; Iter   152/  209] train: loss: 0.6888705
[Epoch 3; Iter   182/  209] train: loss: 0.6885452
[Epoch 3] ogbg-moltox21: 0.501648 val loss: 0.688036
[Epoch 3] ogbg-moltox21: 0.511088 test loss: 0.688070
[Epoch 4; Iter     3/  209] train: loss: 0.6889498
[Epoch 4; Iter    33/  209] train: loss: 0.6876054
[Epoch 4; Iter    63/  209] train: loss: 0.6857605
[Epoch 4; Iter    93/  209] train: loss: 0.6801779
[Epoch 4; Iter   123/  209] train: loss: 0.6564348
[Epoch 4; Iter   153/  209] train: loss: 0.6266348
[Epoch 4; Iter   183/  209] train: loss: 0.5872428
[Epoch 4] ogbg-moltox21: 0.736578 val loss: 0.538120
[Epoch 4] ogbg-moltox21: 0.739711 test loss: 0.534986
[Epoch 5; Iter     4/  209] train: loss: 0.5355501
[Epoch 5; Iter    34/  209] train: loss: 0.4885992
[Epoch 5; Iter    64/  209] train: loss: 0.4639895
[Epoch 5; Iter    94/  209] train: loss: 0.3718699
[Epoch 5; Iter   124/  209] train: loss: 0.3349384
[Epoch 5; Iter   154/  209] train: loss: 0.2517943
[Epoch 5; Iter   184/  209] train: loss: 0.2418283
[Epoch 5] ogbg-moltox21: 0.759059 val loss: 0.264121
[Epoch 5] ogbg-moltox21: 0.759900 test loss: 0.252379
[Epoch 6; Iter     5/  209] train: loss: 0.3214065
[Epoch 6; Iter    35/  209] train: loss: 0.2455339
[Epoch 6; Iter    65/  209] train: loss: 0.1988481
[Epoch 6; Iter    95/  209] train: loss: 0.1595469
[Epoch 6; Iter   125/  209] train: loss: 0.2054142
[Epoch 6; Iter   155/  209] train: loss: 0.2193238
[Epoch 6; Iter   185/  209] train: loss: 0.1948433
[Epoch 6] ogbg-moltox21: 0.778187 val loss: 0.252045
[Epoch 6] ogbg-moltox21: 0.775930 test loss: 0.231300
[Epoch 7; Iter     6/  209] train: loss: 0.3756148
[Epoch 7; Iter    36/  209] train: loss: 0.3189181
[Epoch 7; Iter    66/  209] train: loss: 0.2936942
[Epoch 7; Iter    96/  209] train: loss: 0.1837793
[Epoch 7; Iter   126/  209] train: loss: 0.2215872
[Epoch 7; Iter   156/  209] train: loss: 0.1856809
[Epoch 7; Iter   186/  209] train: loss: 0.1821019
[Epoch 7] ogbg-moltox21: 0.801867 val loss: 0.232092
[Epoch 7] ogbg-moltox21: 0.797428 test loss: 0.218534
[Epoch 8; Iter     7/  209] train: loss: 0.1747441
[Epoch 8; Iter    37/  209] train: loss: 0.2492542
[Epoch 8; Iter    67/  209] train: loss: 0.2461746
[Epoch 8; Iter    97/  209] train: loss: 0.1838871
[Epoch 8; Iter   127/  209] train: loss: 0.1690231
[Epoch 8; Iter   157/  209] train: loss: 0.1845125
[Epoch 8; Iter   187/  209] train: loss: 0.2332552
[Epoch 8] ogbg-moltox21: 0.774379 val loss: 0.331868
[Epoch 8] ogbg-moltox21: 0.756544 test loss: 0.394444
[Epoch 9; Iter     8/  209] train: loss: 0.1786800
[Epoch 9; Iter    38/  209] train: loss: 0.1134409
[Epoch 9; Iter    68/  209] train: loss: 0.2367575
[Epoch 9; Iter    98/  209] train: loss: 0.1567569
[Epoch 9; Iter   128/  209] train: loss: 0.1861611
[Epoch 9; Iter   158/  209] train: loss: 0.1518204
[Epoch 9; Iter   188/  209] train: loss: 0.1865265
[Epoch 9] ogbg-moltox21: 0.812131 val loss: 0.242271
[Epoch 9] ogbg-moltox21: 0.807990 test loss: 0.221970
[Epoch 10; Iter     9/  209] train: loss: 0.2157740
[Epoch 10; Iter    39/  209] train: loss: 0.2634323
[Epoch 10; Iter    69/  209] train: loss: 0.2269790
[Epoch 10; Iter    99/  209] train: loss: 0.2652794
[Epoch 10; Iter   129/  209] train: loss: 0.2993853
[Epoch 10; Iter   159/  209] train: loss: 0.1854320
[Epoch 10; Iter   189/  209] train: loss: 0.1945087
[Epoch 10] ogbg-moltox21: 0.810301 val loss: 0.229980
[Epoch 10] ogbg-moltox21: 0.764338 test loss: 0.226509
[Epoch 11; Iter    10/  209] train: loss: 0.2001188
[Epoch 11; Iter    40/  209] train: loss: 0.2653030
[Epoch 11; Iter    70/  209] train: loss: 0.2125554
[Epoch 11; Iter   100/  209] train: loss: 0.1660136
[Epoch 11; Iter   130/  209] train: loss: 0.2175176
[Epoch 11; Iter   160/  209] train: loss: 0.1896657
[Epoch 11; Iter   190/  209] train: loss: 0.2219277
[Epoch 11] ogbg-moltox21: 0.833888 val loss: 0.226099
[Epoch 11] ogbg-moltox21: 0.810956 test loss: 0.212723
[Epoch 12; Iter    11/  209] train: loss: 0.2243222
[Epoch 12; Iter    41/  209] train: loss: 0.2309543
[Epoch 12; Iter    71/  209] train: loss: 0.1601049
[Epoch 12; Iter   101/  209] train: loss: 0.1731874
[Epoch 12; Iter   131/  209] train: loss: 0.2049688
[Epoch 12; Iter   161/  209] train: loss: 0.1712444
[Epoch 12; Iter   191/  209] train: loss: 0.1263660
[Epoch 12] ogbg-moltox21: 0.832035 val loss: 0.216742
[Epoch 12] ogbg-moltox21: 0.800035 test loss: 0.210394
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_random=0.8_5_26-05_09-40-41
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.8
logdir: runs/split/GraphCL/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6919622
[Epoch 1; Iter    60/  209] train: loss: 0.6927071
[Epoch 1; Iter    90/  209] train: loss: 0.6925168
[Epoch 1; Iter   120/  209] train: loss: 0.6925079
[Epoch 1; Iter   150/  209] train: loss: 0.6924787
[Epoch 1; Iter   180/  209] train: loss: 0.6910225
[Epoch 1] ogbg-moltox21: 0.501705 val loss: 0.692339
[Epoch 1] ogbg-moltox21: 0.532773 test loss: 0.691869
[Epoch 2; Iter     1/  209] train: loss: 0.6924937
[Epoch 2; Iter    31/  209] train: loss: 0.6921274
[Epoch 2; Iter    61/  209] train: loss: 0.6912321
[Epoch 2; Iter    91/  209] train: loss: 0.6917896
[Epoch 2; Iter   121/  209] train: loss: 0.6911862
[Epoch 2; Iter   151/  209] train: loss: 0.6905956
[Epoch 2; Iter   181/  209] train: loss: 0.6909769
[Epoch 2] ogbg-moltox21: 0.500871 val loss: 0.690800
[Epoch 2] ogbg-moltox21: 0.533636 test loss: 0.690306
[Epoch 3; Iter     2/  209] train: loss: 0.6906719
[Epoch 3; Iter    32/  209] train: loss: 0.6904523
[Epoch 3; Iter    62/  209] train: loss: 0.6897470
[Epoch 3; Iter    92/  209] train: loss: 0.6893778
[Epoch 3; Iter   122/  209] train: loss: 0.6895431
[Epoch 3; Iter   152/  209] train: loss: 0.6879198
[Epoch 3; Iter   182/  209] train: loss: 0.6878291
[Epoch 3] ogbg-moltox21: 0.513150 val loss: 0.687687
[Epoch 3] ogbg-moltox21: 0.542841 test loss: 0.687129
[Epoch 4; Iter     3/  209] train: loss: 0.6880952
[Epoch 4; Iter    33/  209] train: loss: 0.6874099
[Epoch 4; Iter    63/  209] train: loss: 0.6857311
[Epoch 4; Iter    93/  209] train: loss: 0.6811842
[Epoch 4; Iter   123/  209] train: loss: 0.6626953
[Epoch 4; Iter   153/  209] train: loss: 0.6166002
[Epoch 4; Iter   183/  209] train: loss: 0.5847651
[Epoch 4] ogbg-moltox21: 0.732658 val loss: 0.580103
[Epoch 4] ogbg-moltox21: 0.746002 test loss: 0.575429
[Epoch 5; Iter     4/  209] train: loss: 0.5327530
[Epoch 5; Iter    34/  209] train: loss: 0.4679475
[Epoch 5; Iter    64/  209] train: loss: 0.4291229
[Epoch 5; Iter    94/  209] train: loss: 0.3862740
[Epoch 5; Iter   124/  209] train: loss: 0.3079259
[Epoch 5; Iter   154/  209] train: loss: 0.2990015
[Epoch 5; Iter   184/  209] train: loss: 0.2555194
[Epoch 5] ogbg-moltox21: 0.750432 val loss: 0.264391
[Epoch 5] ogbg-moltox21: 0.741790 test loss: 0.257664
[Epoch 6; Iter     5/  209] train: loss: 0.1978346
[Epoch 6; Iter    35/  209] train: loss: 0.2684424
[Epoch 6; Iter    65/  209] train: loss: 0.3213717
[Epoch 6; Iter    95/  209] train: loss: 0.3003567
[Epoch 6; Iter   125/  209] train: loss: 0.2048395
[Epoch 6; Iter   155/  209] train: loss: 0.1569030
[Epoch 6; Iter   185/  209] train: loss: 0.2171038
[Epoch 6] ogbg-moltox21: 0.762292 val loss: 0.251982
[Epoch 6] ogbg-moltox21: 0.751791 test loss: 0.234294
[Epoch 7; Iter     6/  209] train: loss: 0.1630153
[Epoch 7; Iter    36/  209] train: loss: 0.1847598
[Epoch 7; Iter    66/  209] train: loss: 0.1902731
[Epoch 7; Iter    96/  209] train: loss: 0.1728982
[Epoch 7; Iter   126/  209] train: loss: 0.1175513
[Epoch 7; Iter   156/  209] train: loss: 0.1526792
[Epoch 7; Iter   186/  209] train: loss: 0.1860739
[Epoch 7] ogbg-moltox21: 0.796202 val loss: 0.240608
[Epoch 7] ogbg-moltox21: 0.778212 test loss: 0.225035
[Epoch 8; Iter     7/  209] train: loss: 0.2959868
[Epoch 8; Iter    37/  209] train: loss: 0.1995767
[Epoch 8; Iter    67/  209] train: loss: 0.1140497
[Epoch 8; Iter    97/  209] train: loss: 0.2725116
[Epoch 8; Iter   127/  209] train: loss: 0.2766958
[Epoch 8; Iter   157/  209] train: loss: 0.3028749
[Epoch 8; Iter   187/  209] train: loss: 0.1362344
[Epoch 8] ogbg-moltox21: 0.776622 val loss: 0.238200
[Epoch 8] ogbg-moltox21: 0.757719 test loss: 0.230069
[Epoch 9; Iter     8/  209] train: loss: 0.2556160
[Epoch 9; Iter    38/  209] train: loss: 0.1734118
[Epoch 9; Iter    68/  209] train: loss: 0.2815730
[Epoch 9; Iter    98/  209] train: loss: 0.2414238
[Epoch 9; Iter   128/  209] train: loss: 0.1911398
[Epoch 9; Iter   158/  209] train: loss: 0.3404626
[Epoch 9; Iter   188/  209] train: loss: 0.2211467
[Epoch 9] ogbg-moltox21: 0.808902 val loss: 0.257962
[Epoch 9] ogbg-moltox21: 0.771043 test loss: 0.226245
[Epoch 10; Iter     9/  209] train: loss: 0.2078790
[Epoch 10; Iter    39/  209] train: loss: 0.1781346
[Epoch 10; Iter    69/  209] train: loss: 0.2458637
[Epoch 10; Iter    99/  209] train: loss: 0.2236964
[Epoch 10; Iter   129/  209] train: loss: 0.2906420
[Epoch 10; Iter   159/  209] train: loss: 0.2945499
[Epoch 10; Iter   189/  209] train: loss: 0.2989950
[Epoch 10] ogbg-moltox21: 0.817065 val loss: 0.226315
[Epoch 10] ogbg-moltox21: 0.797457 test loss: 0.216965
[Epoch 11; Iter    10/  209] train: loss: 0.3453119
[Epoch 11; Iter    40/  209] train: loss: 0.1999865
[Epoch 11; Iter    70/  209] train: loss: 0.2119248
[Epoch 11; Iter   100/  209] train: loss: 0.2450651
[Epoch 11; Iter   130/  209] train: loss: 0.2603406
[Epoch 11; Iter   160/  209] train: loss: 0.2343056
[Epoch 11; Iter   190/  209] train: loss: 0.1832482
[Epoch 11] ogbg-moltox21: 0.819363 val loss: 0.383283
[Epoch 11] ogbg-moltox21: 0.808211 test loss: 0.311613
[Epoch 12; Iter    11/  209] train: loss: 0.1927136
[Epoch 12; Iter    41/  209] train: loss: 0.2084066
[Epoch 12; Iter    71/  209] train: loss: 0.1595551
[Epoch 12; Iter   101/  209] train: loss: 0.1142501
[Epoch 12; Iter   131/  209] train: loss: 0.2622200
[Epoch 12; Iter   161/  209] train: loss: 0.1648677
[Epoch 12; Iter   191/  209] train: loss: 0.2771206
[Epoch 12] ogbg-moltox21: 0.817801 val loss: 0.220720
[Epoch 12] ogbg-moltox21: 0.830619 test loss: 0.208562
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_random=0.8_6_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.8
logdir: runs/split/GraphCL/tox21/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6926673
[Epoch 1; Iter    60/  209] train: loss: 0.6922866
[Epoch 1; Iter    90/  209] train: loss: 0.6918536
[Epoch 1; Iter   120/  209] train: loss: 0.6922449
[Epoch 1; Iter   150/  209] train: loss: 0.6923298
[Epoch 1; Iter   180/  209] train: loss: 0.6910536
[Epoch 1] ogbg-moltox21: 0.561305 val loss: 0.691667
[Epoch 1] ogbg-moltox21: 0.528146 test loss: 0.691887
[Epoch 2; Iter     1/  209] train: loss: 0.6923296
[Epoch 2; Iter    31/  209] train: loss: 0.6924141
[Epoch 2; Iter    61/  209] train: loss: 0.6911312
[Epoch 2; Iter    91/  209] train: loss: 0.6921089
[Epoch 2; Iter   121/  209] train: loss: 0.6915502
[Epoch 2; Iter   151/  209] train: loss: 0.6904123
[Epoch 2; Iter   181/  209] train: loss: 0.6910818
[Epoch 2] ogbg-moltox21: 0.565659 val loss: 0.690187
[Epoch 2] ogbg-moltox21: 0.534175 test loss: 0.690408
[Epoch 3; Iter     2/  209] train: loss: 0.6904824
[Epoch 3; Iter    32/  209] train: loss: 0.6900316
[Epoch 3; Iter    62/  209] train: loss: 0.6898704
[Epoch 3; Iter    92/  209] train: loss: 0.6894029
[Epoch 3; Iter   122/  209] train: loss: 0.6888326
[Epoch 3; Iter   152/  209] train: loss: 0.6879090
[Epoch 3; Iter   182/  209] train: loss: 0.6882553
[Epoch 3] ogbg-moltox21: 0.570837 val loss: 0.687741
[Epoch 3] ogbg-moltox21: 0.541410 test loss: 0.687932
[Epoch 4; Iter     3/  209] train: loss: 0.6876309
[Epoch 4; Iter    33/  209] train: loss: 0.6870911
[Epoch 4; Iter    63/  209] train: loss: 0.6874019
[Epoch 4; Iter    93/  209] train: loss: 0.6803306
[Epoch 4; Iter   123/  209] train: loss: 0.6557751
[Epoch 4; Iter   153/  209] train: loss: 0.6338183
[Epoch 4; Iter   183/  209] train: loss: 0.5834530
[Epoch 4] ogbg-moltox21: 0.737513 val loss: 0.531304
[Epoch 4] ogbg-moltox21: 0.739580 test loss: 0.525606
[Epoch 5; Iter     4/  209] train: loss: 0.5382134
[Epoch 5; Iter    34/  209] train: loss: 0.4997884
[Epoch 5; Iter    64/  209] train: loss: 0.4545748
[Epoch 5; Iter    94/  209] train: loss: 0.3742475
[Epoch 5; Iter   124/  209] train: loss: 0.3302367
[Epoch 5; Iter   154/  209] train: loss: 0.3644152
[Epoch 5; Iter   184/  209] train: loss: 0.2596565
[Epoch 5] ogbg-moltox21: 0.727039 val loss: 0.276213
[Epoch 5] ogbg-moltox21: 0.715827 test loss: 0.267708
[Epoch 6; Iter     5/  209] train: loss: 0.2693304
[Epoch 6; Iter    35/  209] train: loss: 0.2856566
[Epoch 6; Iter    65/  209] train: loss: 0.2407312
[Epoch 6; Iter    95/  209] train: loss: 0.1558815
[Epoch 6; Iter   125/  209] train: loss: 0.2478287
[Epoch 6; Iter   155/  209] train: loss: 0.2372098
[Epoch 6; Iter   185/  209] train: loss: 0.2562629
[Epoch 6] ogbg-moltox21: 0.770358 val loss: 0.254528
[Epoch 6] ogbg-moltox21: 0.737366 test loss: 0.291605
[Epoch 7; Iter     6/  209] train: loss: 0.2894292
[Epoch 7; Iter    36/  209] train: loss: 0.2452928
[Epoch 7; Iter    66/  209] train: loss: 0.1838328
[Epoch 7; Iter    96/  209] train: loss: 0.1657429
[Epoch 7; Iter   126/  209] train: loss: 0.1613568
[Epoch 7; Iter   156/  209] train: loss: 0.1772269
[Epoch 7; Iter   186/  209] train: loss: 0.1991884
[Epoch 7] ogbg-moltox21: 0.788955 val loss: 0.238163
[Epoch 7] ogbg-moltox21: 0.774882 test loss: 0.219812
[Epoch 8; Iter     7/  209] train: loss: 0.1733671
[Epoch 8; Iter    37/  209] train: loss: 0.3035592
[Epoch 8; Iter    67/  209] train: loss: 0.2528056
[Epoch 8; Iter    97/  209] train: loss: 0.2314254
[Epoch 8; Iter   127/  209] train: loss: 0.1886143
[Epoch 8; Iter   157/  209] train: loss: 0.2973864
[Epoch 8; Iter   187/  209] train: loss: 0.2749538
[Epoch 8] ogbg-moltox21: 0.783102 val loss: 0.270940
[Epoch 8] ogbg-moltox21: 0.774075 test loss: 0.299040
[Epoch 9; Iter     8/  209] train: loss: 0.2994217
[Epoch 9; Iter    38/  209] train: loss: 0.2150775
[Epoch 9; Iter    68/  209] train: loss: 0.2170906
[Epoch 9; Iter    98/  209] train: loss: 0.2764907
[Epoch 9; Iter   128/  209] train: loss: 0.1890932
[Epoch 9; Iter   158/  209] train: loss: 0.2084071
[Epoch 9; Iter   188/  209] train: loss: 0.1259170
[Epoch 9] ogbg-moltox21: 0.801024 val loss: 0.225709
[Epoch 9] ogbg-moltox21: 0.778759 test loss: 0.214630
[Epoch 10; Iter     9/  209] train: loss: 0.1379230
[Epoch 10; Iter    39/  209] train: loss: 0.2256438
[Epoch 10; Iter    69/  209] train: loss: 0.2178455
[Epoch 10; Iter    99/  209] train: loss: 0.1565415
[Epoch 10; Iter   129/  209] train: loss: 0.2419603
[Epoch 10; Iter   159/  209] train: loss: 0.1562758
[Epoch 10; Iter   189/  209] train: loss: 0.2573715
[Epoch 10] ogbg-moltox21: 0.803004 val loss: 0.229733
[Epoch 10] ogbg-moltox21: 0.794366 test loss: 0.215557
[Epoch 11; Iter    10/  209] train: loss: 0.2085515
[Epoch 11; Iter    40/  209] train: loss: 0.1981610
[Epoch 11; Iter    70/  209] train: loss: 0.1577047
[Epoch 11; Iter   100/  209] train: loss: 0.2274065
[Epoch 11; Iter   130/  209] train: loss: 0.1812854
[Epoch 11; Iter   160/  209] train: loss: 0.2665776
[Epoch 11; Iter   190/  209] train: loss: 0.2416251
[Epoch 11] ogbg-moltox21: 0.815915 val loss: 0.223285
[Epoch 11] ogbg-moltox21: 0.808411 test loss: 0.209787
[Epoch 12; Iter    11/  209] train: loss: 0.2530721
[Epoch 12; Iter    41/  209] train: loss: 0.2537410
[Epoch 12; Iter    71/  209] train: loss: 0.2804997
[Epoch 12; Iter   101/  209] train: loss: 0.1539248
[Epoch 12; Iter   131/  209] train: loss: 0.1594795
[Epoch 12; Iter   161/  209] train: loss: 0.1533475
[Epoch 12; Iter   191/  209] train: loss: 0.1074254
[Epoch 12] ogbg-moltox21: 0.829136 val loss: 0.215108
[Epoch 12] ogbg-moltox21: 0.812887 test loss: 0.244153
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_random=0.7_6_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.7
logdir: runs/split/GraphCL/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6920159
[Epoch 1; Iter    60/  183] train: loss: 0.6930611
[Epoch 1; Iter    90/  183] train: loss: 0.6916767
[Epoch 1; Iter   120/  183] train: loss: 0.6929762
[Epoch 1; Iter   150/  183] train: loss: 0.6927158
[Epoch 1; Iter   180/  183] train: loss: 0.6925485
[Epoch 1] ogbg-moltox21: 0.544834 val loss: 0.692255
[Epoch 1] ogbg-moltox21: 0.542629 test loss: 0.692113
[Epoch 2; Iter    27/  183] train: loss: 0.6932434
[Epoch 2; Iter    57/  183] train: loss: 0.6926697
[Epoch 2; Iter    87/  183] train: loss: 0.6916273
[Epoch 2; Iter   117/  183] train: loss: 0.6912675
[Epoch 2; Iter   147/  183] train: loss: 0.6910391
[Epoch 2; Iter   177/  183] train: loss: 0.6903581
[Epoch 2] ogbg-moltox21: 0.545640 val loss: 0.691082
[Epoch 2] ogbg-moltox21: 0.544814 test loss: 0.690951
[Epoch 3; Iter    24/  183] train: loss: 0.6909955
[Epoch 3; Iter    54/  183] train: loss: 0.6904220
[Epoch 3; Iter    84/  183] train: loss: 0.6907879
[Epoch 3; Iter   114/  183] train: loss: 0.6898488
[Epoch 3; Iter   144/  183] train: loss: 0.6890332
[Epoch 3; Iter   174/  183] train: loss: 0.6899665
[Epoch 3] ogbg-moltox21: 0.549743 val loss: 0.688965
[Epoch 3] ogbg-moltox21: 0.547294 test loss: 0.688807
[Epoch 4; Iter    21/  183] train: loss: 0.6893407
[Epoch 4; Iter    51/  183] train: loss: 0.6892676
[Epoch 4; Iter    81/  183] train: loss: 0.6880098
[Epoch 4; Iter   111/  183] train: loss: 0.6879596
[Epoch 4; Iter   141/  183] train: loss: 0.6862331
[Epoch 4; Iter   171/  183] train: loss: 0.6809068
[Epoch 4] ogbg-moltox21: 0.679470 val loss: 0.682727
[Epoch 4] ogbg-moltox21: 0.707158 test loss: 0.682174
[Epoch 5; Iter    18/  183] train: loss: 0.6689401
[Epoch 5; Iter    48/  183] train: loss: 0.6169836
[Epoch 5; Iter    78/  183] train: loss: 0.5935356
[Epoch 5; Iter   108/  183] train: loss: 0.5448055
[Epoch 5; Iter   138/  183] train: loss: 0.4749833
[Epoch 5; Iter   168/  183] train: loss: 0.4318983
[Epoch 5] ogbg-moltox21: 0.738294 val loss: 0.383937
[Epoch 5] ogbg-moltox21: 0.770346 test loss: 0.383205
[Epoch 6; Iter    15/  183] train: loss: 0.3894921
[Epoch 6; Iter    45/  183] train: loss: 0.3769962
[Epoch 6; Iter    75/  183] train: loss: 0.2807301
[Epoch 6; Iter   105/  183] train: loss: 0.2458403
[Epoch 6; Iter   135/  183] train: loss: 0.2476082
[Epoch 6; Iter   165/  183] train: loss: 0.1997546
[Epoch 6] ogbg-moltox21: 0.754419 val loss: 0.243682
[Epoch 6] ogbg-moltox21: 0.777630 test loss: 0.245364
[Epoch 7; Iter    12/  183] train: loss: 0.3165565
[Epoch 7; Iter    42/  183] train: loss: 0.2067639
[Epoch 7; Iter    72/  183] train: loss: 0.2612726
[Epoch 7; Iter   102/  183] train: loss: 0.2398645
[Epoch 7; Iter   132/  183] train: loss: 0.3017017
[Epoch 7; Iter   162/  183] train: loss: 0.1705863
[Epoch 7] ogbg-moltox21: 0.764353 val loss: 0.226984
[Epoch 7] ogbg-moltox21: 0.782140 test loss: 0.230721
[Epoch 8; Iter     9/  183] train: loss: 0.1873852
[Epoch 8; Iter    39/  183] train: loss: 0.2620725
[Epoch 8; Iter    69/  183] train: loss: 0.2416796
[Epoch 8; Iter    99/  183] train: loss: 0.1779986
[Epoch 8; Iter   129/  183] train: loss: 0.1780313
[Epoch 8; Iter   159/  183] train: loss: 0.2260603
[Epoch 8] ogbg-moltox21: 0.769040 val loss: 0.220527
[Epoch 8] ogbg-moltox21: 0.784282 test loss: 0.223156
[Epoch 9; Iter     6/  183] train: loss: 0.1801909
[Epoch 9; Iter    36/  183] train: loss: 0.2445494
[Epoch 9; Iter    66/  183] train: loss: 0.1803396
[Epoch 9; Iter    96/  183] train: loss: 0.2096082
[Epoch 9; Iter   126/  183] train: loss: 0.2018632
[Epoch 9; Iter   156/  183] train: loss: 0.2390062
[Epoch 9] ogbg-moltox21: 0.733706 val loss: 0.228994
[Epoch 9] ogbg-moltox21: 0.773152 test loss: 0.231296
[Epoch 10; Iter     3/  183] train: loss: 0.2614734
[Epoch 10; Iter    33/  183] train: loss: 0.2916554
[Epoch 10; Iter    63/  183] train: loss: 0.1815410
[Epoch 10; Iter    93/  183] train: loss: 0.2175557
[Epoch 10; Iter   123/  183] train: loss: 0.2599975
[Epoch 10; Iter   153/  183] train: loss: 0.1973116
[Epoch 10; Iter   183/  183] train: loss: 0.2974607
[Epoch 10] ogbg-moltox21: 0.734523 val loss: 0.229470
[Epoch 10] ogbg-moltox21: 0.778846 test loss: 0.230142
[Epoch 11; Iter    30/  183] train: loss: 0.2569924
[Epoch 11; Iter    60/  183] train: loss: 0.2268688
[Epoch 11; Iter    90/  183] train: loss: 0.1498617
[Epoch 11; Iter   120/  183] train: loss: 0.1994591
[Epoch 11; Iter   150/  183] train: loss: 0.2042461
[Epoch 11; Iter   180/  183] train: loss: 0.2021997
[Epoch 11] ogbg-moltox21: 0.777357 val loss: 0.218610
[Epoch 11] ogbg-moltox21: 0.801470 test loss: 0.220119
[Epoch 12; Iter    27/  183] train: loss: 0.2426491
[Epoch 12; Iter    57/  183] train: loss: 0.2655669
[Epoch 12; Iter    87/  183] train: loss: 0.1710910
[Epoch 12; Iter   117/  183] train: loss: 0.1721980
[Epoch 12; Iter   147/  183] train: loss: 0.1685781
[Epoch 12; Iter   177/  183] train: loss: 0.2500214
[Epoch 12] ogbg-moltox21: 0.792962 val loss: 0.214117
[Epoch 12] ogbg-moltox21: 0.809309 test loss: 0.213001
[Epoch 13; Iter    24/  183] train: loss: 0.1816012
[Epoch 13; Iter    54/  183] train: loss: 0.1896110
[Epoch 13; Iter    84/  183] train: loss: 0.1555033
[Epoch 13; Iter   114/  183] train: loss: 0.1979193
[Epoch 13; Iter   144/  183] train: loss: 0.2047956
[Epoch 13; Iter   174/  183] train: loss: 0.2268928
[Epoch 13] ogbg-moltox21: 0.785612 val loss: 0.209640
[Epoch 13] ogbg-moltox21: 0.833958 test loss: 0.202237
[Epoch 14; Iter    21/  183] train: loss: 0.1740161
[Epoch 14; Iter    51/  183] train: loss: 0.1528646
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_random=0.7_5_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.7
logdir: runs/split/GraphCL/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6931599
[Epoch 1; Iter    60/  183] train: loss: 0.6923080
[Epoch 1; Iter    90/  183] train: loss: 0.6930201
[Epoch 1; Iter   120/  183] train: loss: 0.6937870
[Epoch 1; Iter   150/  183] train: loss: 0.6919071
[Epoch 1; Iter   180/  183] train: loss: 0.6925665
[Epoch 1] ogbg-moltox21: 0.487478 val loss: 0.692375
[Epoch 1] ogbg-moltox21: 0.528686 test loss: 0.692217
[Epoch 2; Iter    27/  183] train: loss: 0.6927454
[Epoch 2; Iter    57/  183] train: loss: 0.6915115
[Epoch 2; Iter    87/  183] train: loss: 0.6919515
[Epoch 2; Iter   117/  183] train: loss: 0.6911238
[Epoch 2; Iter   147/  183] train: loss: 0.6922193
[Epoch 2; Iter   177/  183] train: loss: 0.6915988
[Epoch 2] ogbg-moltox21: 0.493593 val loss: 0.690923
[Epoch 2] ogbg-moltox21: 0.535894 test loss: 0.690756
[Epoch 3; Iter    24/  183] train: loss: 0.6911239
[Epoch 3; Iter    54/  183] train: loss: 0.6903283
[Epoch 3; Iter    84/  183] train: loss: 0.6898457
[Epoch 3; Iter   114/  183] train: loss: 0.6894932
[Epoch 3; Iter   144/  183] train: loss: 0.6894872
[Epoch 3; Iter   174/  183] train: loss: 0.6897270
[Epoch 3] ogbg-moltox21: 0.496561 val loss: 0.688732
[Epoch 3] ogbg-moltox21: 0.538183 test loss: 0.688591
[Epoch 4; Iter    21/  183] train: loss: 0.6877400
[Epoch 4; Iter    51/  183] train: loss: 0.6882887
[Epoch 4; Iter    81/  183] train: loss: 0.6869648
[Epoch 4; Iter   111/  183] train: loss: 0.6874490
[Epoch 4; Iter   141/  183] train: loss: 0.6868467
[Epoch 4; Iter   171/  183] train: loss: 0.6821457
[Epoch 4] ogbg-moltox21: 0.672530 val loss: 0.673689
[Epoch 4] ogbg-moltox21: 0.707684 test loss: 0.673452
[Epoch 5; Iter    18/  183] train: loss: 0.6589487
[Epoch 5; Iter    48/  183] train: loss: 0.6221122
[Epoch 5; Iter    78/  183] train: loss: 0.5672482
[Epoch 5; Iter   108/  183] train: loss: 0.5094641
[Epoch 5; Iter   138/  183] train: loss: 0.4762644
[Epoch 5; Iter   168/  183] train: loss: 0.4349420
[Epoch 5] ogbg-moltox21: 0.707235 val loss: 0.387784
[Epoch 5] ogbg-moltox21: 0.745648 test loss: 0.388061
[Epoch 6; Iter    15/  183] train: loss: 0.3559534
[Epoch 6; Iter    45/  183] train: loss: 0.3122374
[Epoch 6; Iter    75/  183] train: loss: 0.2908899
[Epoch 6; Iter   105/  183] train: loss: 0.2792213
[Epoch 6; Iter   135/  183] train: loss: 0.2596473
[Epoch 6; Iter   165/  183] train: loss: 0.3025941
[Epoch 6] ogbg-moltox21: 0.737086 val loss: 0.239687
[Epoch 6] ogbg-moltox21: 0.765921 test loss: 0.241964
[Epoch 7; Iter    12/  183] train: loss: 0.2771088
[Epoch 7; Iter    42/  183] train: loss: 0.1673590
[Epoch 7; Iter    72/  183] train: loss: 0.2460422
[Epoch 7; Iter   102/  183] train: loss: 0.1484225
[Epoch 7; Iter   132/  183] train: loss: 0.2659873
[Epoch 7; Iter   162/  183] train: loss: 0.2879810
[Epoch 7] ogbg-moltox21: 0.734658 val loss: 0.231399
[Epoch 7] ogbg-moltox21: 0.756264 test loss: 0.236093
[Epoch 8; Iter     9/  183] train: loss: 0.1552617
[Epoch 8; Iter    39/  183] train: loss: 0.2019994
[Epoch 8; Iter    69/  183] train: loss: 0.2913097
[Epoch 8; Iter    99/  183] train: loss: 0.2005953
[Epoch 8; Iter   129/  183] train: loss: 0.3092490
[Epoch 8; Iter   159/  183] train: loss: 0.2477522
[Epoch 8] ogbg-moltox21: 0.739519 val loss: 0.335381
[Epoch 8] ogbg-moltox21: 0.762734 test loss: 0.267697
[Epoch 9; Iter     6/  183] train: loss: 0.1990011
[Epoch 9; Iter    36/  183] train: loss: 0.2107638
[Epoch 9; Iter    66/  183] train: loss: 0.2848307
[Epoch 9; Iter    96/  183] train: loss: 0.1713368
[Epoch 9; Iter   126/  183] train: loss: 0.1538034
[Epoch 9; Iter   156/  183] train: loss: 0.2163446
[Epoch 9] ogbg-moltox21: 0.778896 val loss: 0.225799
[Epoch 9] ogbg-moltox21: 0.795878 test loss: 0.229564
[Epoch 10; Iter     3/  183] train: loss: 0.2211221
[Epoch 10; Iter    33/  183] train: loss: 0.1628877
[Epoch 10; Iter    63/  183] train: loss: 0.2412617
[Epoch 10; Iter    93/  183] train: loss: 0.2101915
[Epoch 10; Iter   123/  183] train: loss: 0.1223590
[Epoch 10; Iter   153/  183] train: loss: 0.2168332
[Epoch 10; Iter   183/  183] train: loss: 0.2037604
[Epoch 10] ogbg-moltox21: 0.714020 val loss: 0.266021
[Epoch 10] ogbg-moltox21: 0.740879 test loss: 0.266001
[Epoch 11; Iter    30/  183] train: loss: 0.2280788
[Epoch 11; Iter    60/  183] train: loss: 0.2440559
[Epoch 11; Iter    90/  183] train: loss: 0.1482394
[Epoch 11; Iter   120/  183] train: loss: 0.1890007
[Epoch 11; Iter   150/  183] train: loss: 0.1458077
[Epoch 11; Iter   180/  183] train: loss: 0.2091889
[Epoch 11] ogbg-moltox21: 0.763419 val loss: 0.223304
[Epoch 11] ogbg-moltox21: 0.794153 test loss: 0.223857
[Epoch 12; Iter    27/  183] train: loss: 0.2207905
[Epoch 12; Iter    57/  183] train: loss: 0.1754494
[Epoch 12; Iter    87/  183] train: loss: 0.2822019
[Epoch 12; Iter   117/  183] train: loss: 0.1524699
[Epoch 12; Iter   147/  183] train: loss: 0.2303798
[Epoch 12; Iter   177/  183] train: loss: 0.1518341
[Epoch 12] ogbg-moltox21: 0.776842 val loss: 0.228419
[Epoch 12] ogbg-moltox21: 0.795978 test loss: 0.223408
[Epoch 13; Iter    24/  183] train: loss: 0.2664893
[Epoch 13; Iter    54/  183] train: loss: 0.2212886
[Epoch 13; Iter    84/  183] train: loss: 0.1649243
[Epoch 13; Iter   114/  183] train: loss: 0.2157101
[Epoch 13; Iter   144/  183] train: loss: 0.1661742
[Epoch 13; Iter   174/  183] train: loss: 0.2069957
[Epoch 13] ogbg-moltox21: 0.777702 val loss: 0.230406
[Epoch 13] ogbg-moltox21: 0.825557 test loss: 0.213065
[Epoch 14; Iter    21/  183] train: loss: 0.2148449
[Epoch 14; Iter    51/  183] train: loss: 0.2001328
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_random=0.7_4_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.7
logdir: runs/split/GraphCL/tox21/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6921321
[Epoch 1; Iter    60/  183] train: loss: 0.6928390
[Epoch 1; Iter    90/  183] train: loss: 0.6934904
[Epoch 1; Iter   120/  183] train: loss: 0.6923547
[Epoch 1; Iter   150/  183] train: loss: 0.6921992
[Epoch 1; Iter   180/  183] train: loss: 0.6927178
[Epoch 1] ogbg-moltox21: 0.488960 val loss: 0.692718
[Epoch 1] ogbg-moltox21: 0.495466 test loss: 0.692652
[Epoch 2; Iter    27/  183] train: loss: 0.6917160
[Epoch 2; Iter    57/  183] train: loss: 0.6922321
[Epoch 2; Iter    87/  183] train: loss: 0.6925005
[Epoch 2; Iter   117/  183] train: loss: 0.6921487
[Epoch 2; Iter   147/  183] train: loss: 0.6914065
[Epoch 2; Iter   177/  183] train: loss: 0.6915209
[Epoch 2] ogbg-moltox21: 0.490247 val loss: 0.691444
[Epoch 2] ogbg-moltox21: 0.499905 test loss: 0.691354
[Epoch 3; Iter    24/  183] train: loss: 0.6905524
[Epoch 3; Iter    54/  183] train: loss: 0.6908915
[Epoch 3; Iter    84/  183] train: loss: 0.6901784
[Epoch 3; Iter   114/  183] train: loss: 0.6897656
[Epoch 3; Iter   144/  183] train: loss: 0.6896825
[Epoch 3; Iter   174/  183] train: loss: 0.6901821
[Epoch 3] ogbg-moltox21: 0.494922 val loss: 0.689271
[Epoch 3] ogbg-moltox21: 0.501870 test loss: 0.689231
[Epoch 4; Iter    21/  183] train: loss: 0.6888394
[Epoch 4; Iter    51/  183] train: loss: 0.6879172
[Epoch 4; Iter    81/  183] train: loss: 0.6883587
[Epoch 4; Iter   111/  183] train: loss: 0.6873398
[Epoch 4; Iter   141/  183] train: loss: 0.6861814
[Epoch 4; Iter   171/  183] train: loss: 0.6823879
[Epoch 4] ogbg-moltox21: 0.682014 val loss: 0.679381
[Epoch 4] ogbg-moltox21: 0.718003 test loss: 0.679203
[Epoch 5; Iter    18/  183] train: loss: 0.6626067
[Epoch 5; Iter    48/  183] train: loss: 0.6126316
[Epoch 5; Iter    78/  183] train: loss: 0.5813954
[Epoch 5; Iter   108/  183] train: loss: 0.5222020
[Epoch 5; Iter   138/  183] train: loss: 0.4772953
[Epoch 5; Iter   168/  183] train: loss: 0.4262211
[Epoch 5] ogbg-moltox21: 0.727744 val loss: 0.368881
[Epoch 5] ogbg-moltox21: 0.758507 test loss: 0.369808
[Epoch 6; Iter    15/  183] train: loss: 0.3619145
[Epoch 6; Iter    45/  183] train: loss: 0.3400696
[Epoch 6; Iter    75/  183] train: loss: 0.2884724
[Epoch 6; Iter   105/  183] train: loss: 0.2952546
[Epoch 6; Iter   135/  183] train: loss: 0.3050954
[Epoch 6; Iter   165/  183] train: loss: 0.2282449
[Epoch 6] ogbg-moltox21: 0.730706 val loss: 0.237737
[Epoch 6] ogbg-moltox21: 0.764516 test loss: 0.240092
[Epoch 7; Iter    12/  183] train: loss: 0.2485027
[Epoch 7; Iter    42/  183] train: loss: 0.1588837
[Epoch 7; Iter    72/  183] train: loss: 0.2137494
[Epoch 7; Iter   102/  183] train: loss: 0.3747945
[Epoch 7; Iter   132/  183] train: loss: 0.1671695
[Epoch 7; Iter   162/  183] train: loss: 0.2268669
[Epoch 7] ogbg-moltox21: 0.744128 val loss: 0.229758
[Epoch 7] ogbg-moltox21: 0.766589 test loss: 0.232540
[Epoch 8; Iter     9/  183] train: loss: 0.1886362
[Epoch 8; Iter    39/  183] train: loss: 0.2768991
[Epoch 8; Iter    69/  183] train: loss: 0.2109970
[Epoch 8; Iter    99/  183] train: loss: 0.2419985
[Epoch 8; Iter   129/  183] train: loss: 0.2251460
[Epoch 8; Iter   159/  183] train: loss: 0.1876818
[Epoch 8] ogbg-moltox21: 0.777108 val loss: 0.230406
[Epoch 8] ogbg-moltox21: 0.794520 test loss: 0.222513
[Epoch 9; Iter     6/  183] train: loss: 0.2763128
[Epoch 9; Iter    36/  183] train: loss: 0.1740642
[Epoch 9; Iter    66/  183] train: loss: 0.1801941
[Epoch 9; Iter    96/  183] train: loss: 0.1280775
[Epoch 9; Iter   126/  183] train: loss: 0.2032648
[Epoch 9; Iter   156/  183] train: loss: 0.2641541
[Epoch 9] ogbg-moltox21: 0.752607 val loss: 0.242025
[Epoch 9] ogbg-moltox21: 0.770985 test loss: 0.256333
[Epoch 10; Iter     3/  183] train: loss: 0.2216142
[Epoch 10; Iter    33/  183] train: loss: 0.1713802
[Epoch 10; Iter    63/  183] train: loss: 0.2090612
[Epoch 10; Iter    93/  183] train: loss: 0.2083307
[Epoch 10; Iter   123/  183] train: loss: 0.1754187
[Epoch 10; Iter   153/  183] train: loss: 0.1930339
[Epoch 10; Iter   183/  183] train: loss: 0.1946949
[Epoch 10] ogbg-moltox21: 0.754815 val loss: 0.222378
[Epoch 10] ogbg-moltox21: 0.801351 test loss: 0.219040
[Epoch 11; Iter    30/  183] train: loss: 0.2205983
[Epoch 11; Iter    60/  183] train: loss: 0.1834324
[Epoch 11; Iter    90/  183] train: loss: 0.1546528
[Epoch 11; Iter   120/  183] train: loss: 0.2013022
[Epoch 11; Iter   150/  183] train: loss: 0.1622555
[Epoch 11; Iter   180/  183] train: loss: 0.1721926
[Epoch 11] ogbg-moltox21: 0.779157 val loss: 0.228763
[Epoch 11] ogbg-moltox21: 0.822351 test loss: 0.224213
[Epoch 12; Iter    27/  183] train: loss: 0.2831355
[Epoch 12; Iter    57/  183] train: loss: 0.3091365
[Epoch 12; Iter    87/  183] train: loss: 0.1185519
[Epoch 12; Iter   117/  183] train: loss: 0.2047228
[Epoch 12; Iter   147/  183] train: loss: 0.1702886
[Epoch 12; Iter   177/  183] train: loss: 0.3234670
[Epoch 12] ogbg-moltox21: 0.792384 val loss: 0.210050
[Epoch 12] ogbg-moltox21: 0.819037 test loss: 0.208326
[Epoch 13; Iter    24/  183] train: loss: 0.2393212
[Epoch 13; Iter    54/  183] train: loss: 0.2369764
[Epoch 13; Iter    84/  183] train: loss: 0.1210755
[Epoch 13; Iter   114/  183] train: loss: 0.2613955
[Epoch 13; Iter   144/  183] train: loss: 0.2476136
[Epoch 13; Iter   174/  183] train: loss: 0.2222736
[Epoch 13] ogbg-moltox21: 0.784974 val loss: 0.213303
[Epoch 13] ogbg-moltox21: 0.808953 test loss: 0.215914
[Epoch 14; Iter    21/  183] train: loss: 0.2192881
[Epoch 14; Iter    51/  183] train: loss: 0.2106006
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_random=0.6_5_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.6
logdir: runs/split/GraphCL/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6932243
[Epoch 1; Iter    60/  157] train: loss: 0.6935286
[Epoch 1; Iter    90/  157] train: loss: 0.6923620
[Epoch 1; Iter   120/  157] train: loss: 0.6933888
[Epoch 1; Iter   150/  157] train: loss: 0.6922870
[Epoch 1] ogbg-moltox21: 0.505833 val loss: 0.692427
[Epoch 1] ogbg-moltox21: 0.514165 test loss: 0.692391
[Epoch 2; Iter    23/  157] train: loss: 0.6923742
[Epoch 2; Iter    53/  157] train: loss: 0.6919528
[Epoch 2; Iter    83/  157] train: loss: 0.6924034
[Epoch 2; Iter   113/  157] train: loss: 0.6919705
[Epoch 2; Iter   143/  157] train: loss: 0.6917940
[Epoch 2] ogbg-moltox21: 0.507175 val loss: 0.691442
[Epoch 2] ogbg-moltox21: 0.516385 test loss: 0.691404
[Epoch 3; Iter    16/  157] train: loss: 0.6909819
[Epoch 3; Iter    46/  157] train: loss: 0.6916397
[Epoch 3; Iter    76/  157] train: loss: 0.6912270
[Epoch 3; Iter   106/  157] train: loss: 0.6905238
[Epoch 3; Iter   136/  157] train: loss: 0.6902686
[Epoch 3] ogbg-moltox21: 0.513124 val loss: 0.689719
[Epoch 3] ogbg-moltox21: 0.519966 test loss: 0.689729
[Epoch 4; Iter     9/  157] train: loss: 0.6891043
[Epoch 4; Iter    39/  157] train: loss: 0.6895496
[Epoch 4; Iter    69/  157] train: loss: 0.6890132
[Epoch 4; Iter    99/  157] train: loss: 0.6883513
[Epoch 4; Iter   129/  157] train: loss: 0.6884189
[Epoch 4] ogbg-moltox21: 0.518633 val loss: 0.687256
[Epoch 4] ogbg-moltox21: 0.524744 test loss: 0.687319
[Epoch 5; Iter     2/  157] train: loss: 0.6881440
[Epoch 5; Iter    32/  157] train: loss: 0.6866744
[Epoch 5; Iter    62/  157] train: loss: 0.6861211
[Epoch 5; Iter    92/  157] train: loss: 0.6834281
[Epoch 5; Iter   122/  157] train: loss: 0.6586566
[Epoch 5; Iter   152/  157] train: loss: 0.6258574
[Epoch 5] ogbg-moltox21: 0.723674 val loss: 0.590664
[Epoch 5] ogbg-moltox21: 0.722792 test loss: 0.593935
[Epoch 6; Iter    25/  157] train: loss: 0.5967347
[Epoch 6; Iter    55/  157] train: loss: 0.5262825
[Epoch 6; Iter    85/  157] train: loss: 0.4868354
[Epoch 6; Iter   115/  157] train: loss: 0.4109485
[Epoch 6; Iter   145/  157] train: loss: 0.4265809
[Epoch 6] ogbg-moltox21: 0.759368 val loss: 0.343762
[Epoch 6] ogbg-moltox21: 0.777057 test loss: 0.352627
[Epoch 7; Iter    18/  157] train: loss: 0.3325060
[Epoch 7; Iter    48/  157] train: loss: 0.2850221
[Epoch 7; Iter    78/  157] train: loss: 0.2654216
[Epoch 7; Iter   108/  157] train: loss: 0.2784578
[Epoch 7; Iter   138/  157] train: loss: 0.2640253
[Epoch 7] ogbg-moltox21: 0.746137 val loss: 0.239089
[Epoch 7] ogbg-moltox21: 0.757834 test loss: 0.254511
[Epoch 8; Iter    11/  157] train: loss: 0.2222136
[Epoch 8; Iter    41/  157] train: loss: 0.2752676
[Epoch 8; Iter    71/  157] train: loss: 0.2242370
[Epoch 8; Iter   101/  157] train: loss: 0.1968441
[Epoch 8; Iter   131/  157] train: loss: 0.1675851
[Epoch 8] ogbg-moltox21: 0.764776 val loss: 0.226920
[Epoch 8] ogbg-moltox21: 0.767527 test loss: 0.239707
[Epoch 9; Iter     4/  157] train: loss: 0.1864880
[Epoch 9; Iter    34/  157] train: loss: 0.1845883
[Epoch 9; Iter    64/  157] train: loss: 0.1801552
[Epoch 9; Iter    94/  157] train: loss: 0.1906378
[Epoch 9; Iter   124/  157] train: loss: 0.2212931
[Epoch 9; Iter   154/  157] train: loss: 0.1880446
[Epoch 9] ogbg-moltox21: 0.771687 val loss: 0.216734
[Epoch 9] ogbg-moltox21: 0.789575 test loss: 0.224455
[Epoch 10; Iter    27/  157] train: loss: 0.2010741
[Epoch 10; Iter    57/  157] train: loss: 0.2358633
[Epoch 10; Iter    87/  157] train: loss: 0.2454369
[Epoch 10; Iter   117/  157] train: loss: 0.2112163
[Epoch 10; Iter   147/  157] train: loss: 0.2402884
[Epoch 10] ogbg-moltox21: 0.717100 val loss: 0.376044
[Epoch 10] ogbg-moltox21: 0.695282 test loss: 0.392832
[Epoch 11; Iter    20/  157] train: loss: 0.2093788
[Epoch 11; Iter    50/  157] train: loss: 0.2060263
[Epoch 11; Iter    80/  157] train: loss: 0.1652865
[Epoch 11; Iter   110/  157] train: loss: 0.1932649
[Epoch 11; Iter   140/  157] train: loss: 0.1851703
[Epoch 11] ogbg-moltox21: 0.726000 val loss: 0.333287
[Epoch 11] ogbg-moltox21: 0.766270 test loss: 0.296648
[Epoch 12; Iter    13/  157] train: loss: 0.1580934
[Epoch 12; Iter    43/  157] train: loss: 0.3441217
[Epoch 12; Iter    73/  157] train: loss: 0.2371679
[Epoch 12; Iter   103/  157] train: loss: 0.1701952
[Epoch 12; Iter   133/  157] train: loss: 0.2076814
[Epoch 12] ogbg-moltox21: 0.762624 val loss: 0.231813
[Epoch 12] ogbg-moltox21: 0.781855 test loss: 0.236899
[Epoch 13; Iter     6/  157] train: loss: 0.2603602
[Epoch 13; Iter    36/  157] train: loss: 0.2653306
[Epoch 13; Iter    66/  157] train: loss: 0.1955731
[Epoch 13; Iter    96/  157] train: loss: 0.1690959
[Epoch 13; Iter   126/  157] train: loss: 0.1836889
[Epoch 13; Iter   156/  157] train: loss: 0.2864303
[Epoch 13] ogbg-moltox21: 0.778672 val loss: 0.204966
[Epoch 13] ogbg-moltox21: 0.808362 test loss: 0.223803
[Epoch 14; Iter    29/  157] train: loss: 0.1817937
[Epoch 14; Iter    59/  157] train: loss: 0.1786284
[Epoch 14; Iter    89/  157] train: loss: 0.1877596
[Epoch 14; Iter   119/  157] train: loss: 0.2579659
[Epoch 14; Iter   149/  157] train: loss: 0.3124903
[Epoch 14] ogbg-moltox21: 0.797204 val loss: 0.198036
[Epoch 14] ogbg-moltox21: 0.817309 test loss: 0.212484
[Epoch 15; Iter    22/  157] train: loss: 0.1402844
[Epoch 15; Iter    52/  157] train: loss: 0.2482816
[Epoch 15; Iter    82/  157] train: loss: 0.2636533
[Epoch 15; Iter   112/  157] train: loss: 0.2657578
[Epoch 15; Iter   142/  157] train: loss: 0.1533894
[Epoch 15] ogbg-moltox21: 0.793545 val loss: 0.213573
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_random=0.6_6_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.6
logdir: runs/split/GraphCL/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6913924
[Epoch 1; Iter    60/  157] train: loss: 0.6930900
[Epoch 1; Iter    90/  157] train: loss: 0.6924469
[Epoch 1; Iter   120/  157] train: loss: 0.6931106
[Epoch 1; Iter   150/  157] train: loss: 0.6929696
[Epoch 1] ogbg-moltox21: 0.544311 val loss: 0.692358
[Epoch 1] ogbg-moltox21: 0.548512 test loss: 0.692176
[Epoch 2; Iter    23/  157] train: loss: 0.6914881
[Epoch 2; Iter    53/  157] train: loss: 0.6922944
[Epoch 2; Iter    83/  157] train: loss: 0.6920842
[Epoch 2; Iter   113/  157] train: loss: 0.6916886
[Epoch 2; Iter   143/  157] train: loss: 0.6916848
[Epoch 2] ogbg-moltox21: 0.541033 val loss: 0.691356
[Epoch 2] ogbg-moltox21: 0.549732 test loss: 0.691202
[Epoch 3; Iter    16/  157] train: loss: 0.6912640
[Epoch 3; Iter    46/  157] train: loss: 0.6900223
[Epoch 3; Iter    76/  157] train: loss: 0.6911275
[Epoch 3; Iter   106/  157] train: loss: 0.6904968
[Epoch 3; Iter   136/  157] train: loss: 0.6902695
[Epoch 3] ogbg-moltox21: 0.547419 val loss: 0.689993
[Epoch 3] ogbg-moltox21: 0.554608 test loss: 0.689884
[Epoch 4; Iter     9/  157] train: loss: 0.6887914
[Epoch 4; Iter    39/  157] train: loss: 0.6897812
[Epoch 4; Iter    69/  157] train: loss: 0.6887406
[Epoch 4; Iter    99/  157] train: loss: 0.6876348
[Epoch 4; Iter   129/  157] train: loss: 0.6884416
[Epoch 4] ogbg-moltox21: 0.551040 val loss: 0.687778
[Epoch 4] ogbg-moltox21: 0.558168 test loss: 0.687734
[Epoch 5; Iter     2/  157] train: loss: 0.6874653
[Epoch 5; Iter    32/  157] train: loss: 0.6860803
[Epoch 5; Iter    62/  157] train: loss: 0.6871322
[Epoch 5; Iter    92/  157] train: loss: 0.6807301
[Epoch 5; Iter   122/  157] train: loss: 0.6582664
[Epoch 5; Iter   152/  157] train: loss: 0.6359482
[Epoch 5] ogbg-moltox21: 0.739109 val loss: 0.593636
[Epoch 5] ogbg-moltox21: 0.736551 test loss: 0.595691
[Epoch 6; Iter    25/  157] train: loss: 0.5754267
[Epoch 6; Iter    55/  157] train: loss: 0.5364785
[Epoch 6; Iter    85/  157] train: loss: 0.4867786
[Epoch 6; Iter   115/  157] train: loss: 0.4296935
[Epoch 6; Iter   145/  157] train: loss: 0.4661788
[Epoch 6] ogbg-moltox21: 0.755225 val loss: 0.369695
[Epoch 6] ogbg-moltox21: 0.765815 test loss: 0.376415
[Epoch 7; Iter    18/  157] train: loss: 0.3105188
[Epoch 7; Iter    48/  157] train: loss: 0.2534881
[Epoch 7; Iter    78/  157] train: loss: 0.2776670
[Epoch 7; Iter   108/  157] train: loss: 0.2652467
[Epoch 7; Iter   138/  157] train: loss: 0.2569721
[Epoch 7] ogbg-moltox21: 0.761502 val loss: 0.250636
[Epoch 7] ogbg-moltox21: 0.762755 test loss: 0.256202
[Epoch 8; Iter    11/  157] train: loss: 0.1684014
[Epoch 8; Iter    41/  157] train: loss: 0.2244709
[Epoch 8; Iter    71/  157] train: loss: 0.2155667
[Epoch 8; Iter   101/  157] train: loss: 0.3091424
[Epoch 8; Iter   131/  157] train: loss: 0.1703896
[Epoch 8] ogbg-moltox21: 0.767655 val loss: 0.223274
[Epoch 8] ogbg-moltox21: 0.771104 test loss: 0.235968
[Epoch 9; Iter     4/  157] train: loss: 0.2972981
[Epoch 9; Iter    34/  157] train: loss: 0.1857026
[Epoch 9; Iter    64/  157] train: loss: 0.2314064
[Epoch 9; Iter    94/  157] train: loss: 0.2398162
[Epoch 9; Iter   124/  157] train: loss: 0.1691136
[Epoch 9; Iter   154/  157] train: loss: 0.2629571
[Epoch 9] ogbg-moltox21: 0.765758 val loss: 0.213903
[Epoch 9] ogbg-moltox21: 0.766418 test loss: 0.242112
[Epoch 10; Iter    27/  157] train: loss: 0.2880727
[Epoch 10; Iter    57/  157] train: loss: 0.1622442
[Epoch 10; Iter    87/  157] train: loss: 0.1651208
[Epoch 10; Iter   117/  157] train: loss: 0.1744155
[Epoch 10; Iter   147/  157] train: loss: 0.1478651
[Epoch 10] ogbg-moltox21: 0.744896 val loss: 0.215314
[Epoch 10] ogbg-moltox21: 0.740563 test loss: 0.238201
[Epoch 11; Iter    20/  157] train: loss: 0.1452930
[Epoch 11; Iter    50/  157] train: loss: 0.2715824
[Epoch 11; Iter    80/  157] train: loss: 0.2040977
[Epoch 11; Iter   110/  157] train: loss: 0.2813189
[Epoch 11; Iter   140/  157] train: loss: 0.3169675
[Epoch 11] ogbg-moltox21: 0.764438 val loss: 0.256640
[Epoch 11] ogbg-moltox21: 0.773585 test loss: 0.240704
[Epoch 12; Iter    13/  157] train: loss: 0.0976992
[Epoch 12; Iter    43/  157] train: loss: 0.1510431
[Epoch 12; Iter    73/  157] train: loss: 0.1635161
[Epoch 12; Iter   103/  157] train: loss: 0.2039065
[Epoch 12; Iter   133/  157] train: loss: 0.1315185
[Epoch 12] ogbg-moltox21: 0.716209 val loss: 0.216555
[Epoch 12] ogbg-moltox21: 0.732102 test loss: 0.238448
[Epoch 13; Iter     6/  157] train: loss: 0.1491409
[Epoch 13; Iter    36/  157] train: loss: 0.1702198
[Epoch 13; Iter    66/  157] train: loss: 0.2231409
[Epoch 13; Iter    96/  157] train: loss: 0.2167744
[Epoch 13; Iter   126/  157] train: loss: 0.1802578
[Epoch 13; Iter   156/  157] train: loss: 0.1583028
[Epoch 13] ogbg-moltox21: 0.770353 val loss: 0.209698
[Epoch 13] ogbg-moltox21: 0.797652 test loss: 0.221467
[Epoch 14; Iter    29/  157] train: loss: 0.2219026
[Epoch 14; Iter    59/  157] train: loss: 0.2020980
[Epoch 14; Iter    89/  157] train: loss: 0.1570362
[Epoch 14; Iter   119/  157] train: loss: 0.1797640
[Epoch 14; Iter   149/  157] train: loss: 0.3032146
[Epoch 14] ogbg-moltox21: 0.779727 val loss: 0.207929
[Epoch 14] ogbg-moltox21: 0.792573 test loss: 0.232224
[Epoch 15; Iter    22/  157] train: loss: 0.2053003
[Epoch 15; Iter    52/  157] train: loss: 0.1572097
[Epoch 15; Iter    82/  157] train: loss: 0.2088832
[Epoch 15; Iter   112/  157] train: loss: 0.1785315
[Epoch 15; Iter   142/  157] train: loss: 0.1603785
[Epoch 15] ogbg-moltox21: 0.785774 val loss: 0.201021
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/random/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_random=0.6_4_26-05_09-40-42
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_random=0.6
logdir: runs/split/GraphCL/tox21/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6929719
[Epoch 1; Iter    60/  157] train: loss: 0.6928368
[Epoch 1; Iter    90/  157] train: loss: 0.6926988
[Epoch 1; Iter   120/  157] train: loss: 0.6928607
[Epoch 1; Iter   150/  157] train: loss: 0.6923284
[Epoch 1] ogbg-moltox21: 0.478659 val loss: 0.692844
[Epoch 1] ogbg-moltox21: 0.500673 test loss: 0.692710
[Epoch 2; Iter    23/  157] train: loss: 0.6924545
[Epoch 2; Iter    53/  157] train: loss: 0.6923419
[Epoch 2; Iter    83/  157] train: loss: 0.6918975
[Epoch 2; Iter   113/  157] train: loss: 0.6916926
[Epoch 2; Iter   143/  157] train: loss: 0.6923547
[Epoch 2] ogbg-moltox21: 0.481702 val loss: 0.691855
[Epoch 2] ogbg-moltox21: 0.503690 test loss: 0.691714
[Epoch 3; Iter    16/  157] train: loss: 0.6912234
[Epoch 3; Iter    46/  157] train: loss: 0.6923105
[Epoch 3; Iter    76/  157] train: loss: 0.6911228
[Epoch 3; Iter   106/  157] train: loss: 0.6909263
[Epoch 3; Iter   136/  157] train: loss: 0.6905023
[Epoch 3] ogbg-moltox21: 0.481027 val loss: 0.690307
[Epoch 3] ogbg-moltox21: 0.502220 test loss: 0.690200
[Epoch 4; Iter     9/  157] train: loss: 0.6901699
[Epoch 4; Iter    39/  157] train: loss: 0.6879213
[Epoch 4; Iter    69/  157] train: loss: 0.6887838
[Epoch 4; Iter    99/  157] train: loss: 0.6888526
[Epoch 4; Iter   129/  157] train: loss: 0.6885019
[Epoch 4] ogbg-moltox21: 0.488076 val loss: 0.688136
[Epoch 4] ogbg-moltox21: 0.509184 test loss: 0.688062
[Epoch 5; Iter     2/  157] train: loss: 0.6871593
[Epoch 5; Iter    32/  157] train: loss: 0.6872025
[Epoch 5; Iter    62/  157] train: loss: 0.6867769
[Epoch 5; Iter    92/  157] train: loss: 0.6800333
[Epoch 5; Iter   122/  157] train: loss: 0.6602880
[Epoch 5; Iter   152/  157] train: loss: 0.6170353
[Epoch 5] ogbg-moltox21: 0.722419 val loss: 0.607979
[Epoch 5] ogbg-moltox21: 0.716642 test loss: 0.610660
[Epoch 6; Iter    25/  157] train: loss: 0.5838784
[Epoch 6; Iter    55/  157] train: loss: 0.5615761
[Epoch 6; Iter    85/  157] train: loss: 0.5045827
[Epoch 6; Iter   115/  157] train: loss: 0.4148327
[Epoch 6; Iter   145/  157] train: loss: 0.4027557
[Epoch 6] ogbg-moltox21: 0.764795 val loss: 0.332327
[Epoch 6] ogbg-moltox21: 0.765628 test loss: 0.340928
[Epoch 7; Iter    18/  157] train: loss: 0.3314497
[Epoch 7; Iter    48/  157] train: loss: 0.2741515
[Epoch 7; Iter    78/  157] train: loss: 0.2489027
[Epoch 7; Iter   108/  157] train: loss: 0.2742290
[Epoch 7; Iter   138/  157] train: loss: 0.2696057
[Epoch 7] ogbg-moltox21: 0.754478 val loss: 0.247087
[Epoch 7] ogbg-moltox21: 0.752853 test loss: 0.251173
[Epoch 8; Iter    11/  157] train: loss: 0.2696571
[Epoch 8; Iter    41/  157] train: loss: 0.2764958
[Epoch 8; Iter    71/  157] train: loss: 0.3077651
[Epoch 8; Iter   101/  157] train: loss: 0.1674834
[Epoch 8; Iter   131/  157] train: loss: 0.1748422
[Epoch 8] ogbg-moltox21: 0.766991 val loss: 0.229726
[Epoch 8] ogbg-moltox21: 0.768724 test loss: 0.233627
[Epoch 9; Iter     4/  157] train: loss: 0.2297364
[Epoch 9; Iter    34/  157] train: loss: 0.1572188
[Epoch 9; Iter    64/  157] train: loss: 0.2275425
[Epoch 9; Iter    94/  157] train: loss: 0.2767365
[Epoch 9; Iter   124/  157] train: loss: 0.2294822
[Epoch 9; Iter   154/  157] train: loss: 0.2857704
[Epoch 9] ogbg-moltox21: 0.770828 val loss: 0.235093
[Epoch 9] ogbg-moltox21: 0.785815 test loss: 0.231630
[Epoch 10; Iter    27/  157] train: loss: 0.2326037
[Epoch 10; Iter    57/  157] train: loss: 0.2278379
[Epoch 10; Iter    87/  157] train: loss: 0.2912159
[Epoch 10; Iter   117/  157] train: loss: 0.1508625
[Epoch 10; Iter   147/  157] train: loss: 0.2233917
[Epoch 10] ogbg-moltox21: 0.775229 val loss: 0.217055
[Epoch 10] ogbg-moltox21: 0.791278 test loss: 0.228647
[Epoch 11; Iter    20/  157] train: loss: 0.2110637
[Epoch 11; Iter    50/  157] train: loss: 0.2282116
[Epoch 11; Iter    80/  157] train: loss: 0.1585678
[Epoch 11; Iter   110/  157] train: loss: 0.2085664
[Epoch 11; Iter   140/  157] train: loss: 0.3179106
[Epoch 11] ogbg-moltox21: 0.763624 val loss: 0.213464
[Epoch 11] ogbg-moltox21: 0.780387 test loss: 0.235919
[Epoch 12; Iter    13/  157] train: loss: 0.2139113
[Epoch 12; Iter    43/  157] train: loss: 0.3046099
[Epoch 12; Iter    73/  157] train: loss: 0.2914480
[Epoch 12; Iter   103/  157] train: loss: 0.1336045
[Epoch 12; Iter   133/  157] train: loss: 0.1584694
[Epoch 12] ogbg-moltox21: 0.741458 val loss: 6.324672
[Epoch 12] ogbg-moltox21: 0.748487 test loss: 3.764983
[Epoch 13; Iter     6/  157] train: loss: 0.2211516
[Epoch 13; Iter    36/  157] train: loss: 0.2278362
[Epoch 13; Iter    66/  157] train: loss: 0.2166583
[Epoch 13; Iter    96/  157] train: loss: 0.2309042
[Epoch 13; Iter   126/  157] train: loss: 0.1866044
[Epoch 13; Iter   156/  157] train: loss: 0.2155686
[Epoch 13] ogbg-moltox21: 0.784137 val loss: 0.206076
[Epoch 13] ogbg-moltox21: 0.810610 test loss: 0.218883
[Epoch 14; Iter    29/  157] train: loss: 0.2400969
[Epoch 14; Iter    59/  157] train: loss: 0.1529080
[Epoch 14; Iter    89/  157] train: loss: 0.1691835
[Epoch 14; Iter   119/  157] train: loss: 0.2109465
[Epoch 14; Iter   149/  157] train: loss: 0.2309196
[Epoch 14] ogbg-moltox21: 0.785544 val loss: 0.203144
[Epoch 14] ogbg-moltox21: 0.811944 test loss: 0.226490
[Epoch 15; Iter    22/  157] train: loss: 0.2382346
[Epoch 15; Iter    52/  157] train: loss: 0.1782444
[Epoch 15; Iter    82/  157] train: loss: 0.2090369
[Epoch 15; Iter   112/  157] train: loss: 0.1684042
[Epoch 15; Iter   142/  157] train: loss: 0.3653130
[Epoch 15] ogbg-moltox21: 0.796048 val loss: 0.204649
[Epoch 13; Iter    12/  209] train: loss: 0.1696708
[Epoch 13; Iter    42/  209] train: loss: 0.1639726
[Epoch 13; Iter    72/  209] train: loss: 0.1599083
[Epoch 13; Iter   102/  209] train: loss: 0.2584036
[Epoch 13; Iter   132/  209] train: loss: 0.1651728
[Epoch 13; Iter   162/  209] train: loss: 0.1914355
[Epoch 13; Iter   192/  209] train: loss: 0.1915150
[Epoch 13] ogbg-moltox21: 0.824553 val loss: 0.219915
[Epoch 13] ogbg-moltox21: 0.816374 test loss: 0.212237
[Epoch 14; Iter    13/  209] train: loss: 0.1374469
[Epoch 14; Iter    43/  209] train: loss: 0.1360001
[Epoch 14; Iter    73/  209] train: loss: 0.1866515
[Epoch 14; Iter   103/  209] train: loss: 0.2071770
[Epoch 14; Iter   133/  209] train: loss: 0.1564713
[Epoch 14; Iter   163/  209] train: loss: 0.1405275
[Epoch 14; Iter   193/  209] train: loss: 0.3110277
[Epoch 14] ogbg-moltox21: 0.801424 val loss: 0.231615
[Epoch 14] ogbg-moltox21: 0.815871 test loss: 0.223054
[Epoch 15; Iter    14/  209] train: loss: 0.1698980
[Epoch 15; Iter    44/  209] train: loss: 0.2267673
[Epoch 15; Iter    74/  209] train: loss: 0.1961459
[Epoch 15; Iter   104/  209] train: loss: 0.2629456
[Epoch 15; Iter   134/  209] train: loss: 0.1003616
[Epoch 15; Iter   164/  209] train: loss: 0.2402697
[Epoch 15; Iter   194/  209] train: loss: 0.1327860
[Epoch 15] ogbg-moltox21: 0.840532 val loss: 0.206906
[Epoch 15] ogbg-moltox21: 0.843757 test loss: 0.193958
[Epoch 16; Iter    15/  209] train: loss: 0.2018339
[Epoch 16; Iter    45/  209] train: loss: 0.1797817
[Epoch 16; Iter    75/  209] train: loss: 0.1360988
[Epoch 16; Iter   105/  209] train: loss: 0.1903958
[Epoch 16; Iter   135/  209] train: loss: 0.1890104
[Epoch 16; Iter   165/  209] train: loss: 0.1719022
[Epoch 16; Iter   195/  209] train: loss: 0.2359799
[Epoch 16] ogbg-moltox21: 0.829490 val loss: 0.210018
[Epoch 16] ogbg-moltox21: 0.820054 test loss: 0.204737
[Epoch 17; Iter    16/  209] train: loss: 0.1957540
[Epoch 17; Iter    46/  209] train: loss: 0.1342157
[Epoch 17; Iter    76/  209] train: loss: 0.1417488
[Epoch 17; Iter   106/  209] train: loss: 0.1414004
[Epoch 17; Iter   136/  209] train: loss: 0.1626513
[Epoch 17; Iter   166/  209] train: loss: 0.1979657
[Epoch 17; Iter   196/  209] train: loss: 0.1633025
[Epoch 17] ogbg-moltox21: 0.843412 val loss: 0.208315
[Epoch 17] ogbg-moltox21: 0.848032 test loss: 0.194138
[Epoch 18; Iter    17/  209] train: loss: 0.2193380
[Epoch 18; Iter    47/  209] train: loss: 0.1951670
[Epoch 18; Iter    77/  209] train: loss: 0.2377653
[Epoch 18; Iter   107/  209] train: loss: 0.1400093
[Epoch 18; Iter   137/  209] train: loss: 0.1453777
[Epoch 18; Iter   167/  209] train: loss: 0.2241671
[Epoch 18; Iter   197/  209] train: loss: 0.2204090
[Epoch 18] ogbg-moltox21: 0.845868 val loss: 0.204977
[Epoch 18] ogbg-moltox21: 0.829665 test loss: 0.201643
[Epoch 19; Iter    18/  209] train: loss: 0.2144913
[Epoch 19; Iter    48/  209] train: loss: 0.2534499
[Epoch 19; Iter    78/  209] train: loss: 0.1532781
[Epoch 19; Iter   108/  209] train: loss: 0.2708289
[Epoch 19; Iter   138/  209] train: loss: 0.2285687
[Epoch 19; Iter   168/  209] train: loss: 0.1587891
[Epoch 19; Iter   198/  209] train: loss: 0.1751370
[Epoch 19] ogbg-moltox21: 0.827274 val loss: 0.212581
[Epoch 19] ogbg-moltox21: 0.825840 test loss: 0.207926
[Epoch 20; Iter    19/  209] train: loss: 0.2088169
[Epoch 20; Iter    49/  209] train: loss: 0.1564909
[Epoch 20; Iter    79/  209] train: loss: 0.1430979
[Epoch 20; Iter   109/  209] train: loss: 0.2076074
[Epoch 20; Iter   139/  209] train: loss: 0.2226313
[Epoch 20; Iter   169/  209] train: loss: 0.1820054
[Epoch 20; Iter   199/  209] train: loss: 0.1800226
[Epoch 20] ogbg-moltox21: 0.842117 val loss: 0.205012
[Epoch 20] ogbg-moltox21: 0.841871 test loss: 0.191539
[Epoch 21; Iter    20/  209] train: loss: 0.1444077
[Epoch 21; Iter    50/  209] train: loss: 0.1643775
[Epoch 21; Iter    80/  209] train: loss: 0.1347849
[Epoch 21; Iter   110/  209] train: loss: 0.1364505
[Epoch 21; Iter   140/  209] train: loss: 0.2091010
[Epoch 21; Iter   170/  209] train: loss: 0.1797940
[Epoch 21; Iter   200/  209] train: loss: 0.2131456
[Epoch 21] ogbg-moltox21: 0.855269 val loss: 0.202332
[Epoch 21] ogbg-moltox21: 0.839303 test loss: 0.204634
[Epoch 22; Iter    21/  209] train: loss: 0.1906029
[Epoch 22; Iter    51/  209] train: loss: 0.1182998
[Epoch 22; Iter    81/  209] train: loss: 0.1687048
[Epoch 22; Iter   111/  209] train: loss: 0.1913630
[Epoch 22; Iter   141/  209] train: loss: 0.1658285
[Epoch 22; Iter   171/  209] train: loss: 0.2274128
[Epoch 22; Iter   201/  209] train: loss: 0.1240482
[Epoch 22] ogbg-moltox21: 0.846126 val loss: 0.201267
[Epoch 22] ogbg-moltox21: 0.828258 test loss: 0.197282
[Epoch 23; Iter    22/  209] train: loss: 0.1602901
[Epoch 23; Iter    52/  209] train: loss: 0.1810344
[Epoch 23; Iter    82/  209] train: loss: 0.2418624
[Epoch 23; Iter   112/  209] train: loss: 0.1603297
[Epoch 23; Iter   142/  209] train: loss: 0.1345945
[Epoch 23; Iter   172/  209] train: loss: 0.1320010
[Epoch 23; Iter   202/  209] train: loss: 0.2060567
[Epoch 23] ogbg-moltox21: 0.868021 val loss: 0.198154
[Epoch 23] ogbg-moltox21: 0.851890 test loss: 0.191790
[Epoch 24; Iter    23/  209] train: loss: 0.1335382
[Epoch 24; Iter    53/  209] train: loss: 0.1407190
[Epoch 24; Iter    83/  209] train: loss: 0.1652170
[Epoch 24; Iter   113/  209] train: loss: 0.1732645
[Epoch 24; Iter   143/  209] train: loss: 0.2342235
[Epoch 24; Iter   173/  209] train: loss: 0.1280082
[Epoch 24; Iter   203/  209] train: loss: 0.1811164
[Epoch 24] ogbg-moltox21: 0.846214 val loss: 0.204467
[Epoch 24] ogbg-moltox21: 0.830683 test loss: 0.204374
[Epoch 25; Iter    24/  209] train: loss: 0.1962351
[Epoch 25; Iter    54/  209] train: loss: 0.1479652
[Epoch 25; Iter    84/  209] train: loss: 0.1371952
[Epoch 25; Iter   114/  209] train: loss: 0.2247883
[Epoch 25; Iter   144/  209] train: loss: 0.1573413
[Epoch 25; Iter   174/  209] train: loss: 0.1832706
[Epoch 25; Iter   204/  209] train: loss: 0.1630663
[Epoch 25] ogbg-moltox21: 0.849427 val loss: 0.200341
[Epoch 25] ogbg-moltox21: 0.837207 test loss: 0.196595
[Epoch 26; Iter    25/  209] train: loss: 0.1261165
[Epoch 26; Iter    55/  209] train: loss: 0.1984199
[Epoch 26; Iter    85/  209] train: loss: 0.0814401
[Epoch 26; Iter   115/  209] train: loss: 0.2045000
[Epoch 26; Iter   145/  209] train: loss: 0.1280284
[Epoch 26; Iter   175/  209] train: loss: 0.3458775
[Epoch 26; Iter   205/  209] train: loss: 0.1863229
[Epoch 26] ogbg-moltox21: 0.857848 val loss: 0.195783
[Epoch 26] ogbg-moltox21: 0.846450 test loss: 0.192293
[Epoch 27; Iter    26/  209] train: loss: 0.1989187
[Epoch 27; Iter    56/  209] train: loss: 0.2005927
[Epoch 27; Iter    86/  209] train: loss: 0.1536399
[Epoch 27; Iter   116/  209] train: loss: 0.1580043
[Epoch 27; Iter   146/  209] train: loss: 0.1229132
[Epoch 27; Iter   176/  209] train: loss: 0.1346049
[Epoch 27; Iter   206/  209] train: loss: 0.1694047
[Epoch 27] ogbg-moltox21: 0.855727 val loss: 0.197212
[Epoch 27] ogbg-moltox21: 0.844672 test loss: 0.186473
[Epoch 28; Iter    27/  209] train: loss: 0.1793346
[Epoch 28; Iter    57/  209] train: loss: 0.1286738
[Epoch 28; Iter    87/  209] train: loss: 0.1081107
[Epoch 28; Iter   117/  209] train: loss: 0.2578234
[Epoch 28; Iter   147/  209] train: loss: 0.1416626
[Epoch 28; Iter   177/  209] train: loss: 0.1683370
[Epoch 28; Iter   207/  209] train: loss: 0.1288639
[Epoch 28] ogbg-moltox21: 0.858561 val loss: 0.199099
[Epoch 28] ogbg-moltox21: 0.842698 test loss: 0.196057
[Epoch 29; Iter    28/  209] train: loss: 0.1188336
[Epoch 29; Iter    58/  209] train: loss: 0.2086170
[Epoch 29; Iter    88/  209] train: loss: 0.1505063
[Epoch 29; Iter   118/  209] train: loss: 0.1984469
[Epoch 29; Iter   148/  209] train: loss: 0.1190299
[Epoch 29; Iter   178/  209] train: loss: 0.2249722
[Epoch 29; Iter   208/  209] train: loss: 0.1749105
[Epoch 29] ogbg-moltox21: 0.853437 val loss: 0.199390
[Epoch 29] ogbg-moltox21: 0.841912 test loss: 0.195092
[Epoch 30; Iter    29/  209] train: loss: 0.1061937
[Epoch 30; Iter    59/  209] train: loss: 0.1002459
[Epoch 13; Iter    12/  209] train: loss: 0.2136412
[Epoch 13; Iter    42/  209] train: loss: 0.1456888
[Epoch 13; Iter    72/  209] train: loss: 0.2039944
[Epoch 13; Iter   102/  209] train: loss: 0.3173443
[Epoch 13; Iter   132/  209] train: loss: 0.1449520
[Epoch 13; Iter   162/  209] train: loss: 0.1883352
[Epoch 13; Iter   192/  209] train: loss: 0.1608262
[Epoch 13] ogbg-moltox21: 0.840009 val loss: 0.212482
[Epoch 13] ogbg-moltox21: 0.816906 test loss: 0.210946
[Epoch 14; Iter    13/  209] train: loss: 0.1693919
[Epoch 14; Iter    43/  209] train: loss: 0.1651581
[Epoch 14; Iter    73/  209] train: loss: 0.2948222
[Epoch 14; Iter   103/  209] train: loss: 0.2164767
[Epoch 14; Iter   133/  209] train: loss: 0.1565817
[Epoch 14; Iter   163/  209] train: loss: 0.1774700
[Epoch 14; Iter   193/  209] train: loss: 0.1785831
[Epoch 14] ogbg-moltox21: 0.835077 val loss: 0.221558
[Epoch 14] ogbg-moltox21: 0.823831 test loss: 0.207726
[Epoch 15; Iter    14/  209] train: loss: 0.1198594
[Epoch 15; Iter    44/  209] train: loss: 0.1970411
[Epoch 15; Iter    74/  209] train: loss: 0.1993276
[Epoch 15; Iter   104/  209] train: loss: 0.3267360
[Epoch 15; Iter   134/  209] train: loss: 0.1976450
[Epoch 15; Iter   164/  209] train: loss: 0.1798167
[Epoch 15; Iter   194/  209] train: loss: 0.1327784
[Epoch 15] ogbg-moltox21: 0.836110 val loss: 0.234322
[Epoch 15] ogbg-moltox21: 0.822736 test loss: 0.234205
[Epoch 16; Iter    15/  209] train: loss: 0.1379500
[Epoch 16; Iter    45/  209] train: loss: 0.2313848
[Epoch 16; Iter    75/  209] train: loss: 0.1262830
[Epoch 16; Iter   105/  209] train: loss: 0.1668174
[Epoch 16; Iter   135/  209] train: loss: 0.1334479
[Epoch 16; Iter   165/  209] train: loss: 0.2028388
[Epoch 16; Iter   195/  209] train: loss: 0.1658817
[Epoch 16] ogbg-moltox21: 0.849950 val loss: 0.204764
[Epoch 16] ogbg-moltox21: 0.818884 test loss: 0.212972
[Epoch 17; Iter    16/  209] train: loss: 0.1698024
[Epoch 17; Iter    46/  209] train: loss: 0.2059497
[Epoch 17; Iter    76/  209] train: loss: 0.1834823
[Epoch 17; Iter   106/  209] train: loss: 0.1848895
[Epoch 17; Iter   136/  209] train: loss: 0.1222172
[Epoch 17; Iter   166/  209] train: loss: 0.1702401
[Epoch 17; Iter   196/  209] train: loss: 0.1264492
[Epoch 17] ogbg-moltox21: 0.846668 val loss: 0.205053
[Epoch 17] ogbg-moltox21: 0.835149 test loss: 0.202738
[Epoch 18; Iter    17/  209] train: loss: 0.1906294
[Epoch 18; Iter    47/  209] train: loss: 0.1250069
[Epoch 18; Iter    77/  209] train: loss: 0.2182628
[Epoch 18; Iter   107/  209] train: loss: 0.1722717
[Epoch 18; Iter   137/  209] train: loss: 0.1847217
[Epoch 18; Iter   167/  209] train: loss: 0.1694722
[Epoch 18; Iter   197/  209] train: loss: 0.1736830
[Epoch 18] ogbg-moltox21: 0.843177 val loss: 0.204712
[Epoch 18] ogbg-moltox21: 0.831804 test loss: 0.197585
[Epoch 19; Iter    18/  209] train: loss: 0.1565246
[Epoch 19; Iter    48/  209] train: loss: 0.1241989
[Epoch 19; Iter    78/  209] train: loss: 0.2614147
[Epoch 19; Iter   108/  209] train: loss: 0.1138045
[Epoch 19; Iter   138/  209] train: loss: 0.1805846
[Epoch 19; Iter   168/  209] train: loss: 0.2714245
[Epoch 19; Iter   198/  209] train: loss: 0.1902044
[Epoch 19] ogbg-moltox21: 0.849041 val loss: 0.201457
[Epoch 19] ogbg-moltox21: 0.832363 test loss: 0.208775
[Epoch 20; Iter    19/  209] train: loss: 0.1736440
[Epoch 20; Iter    49/  209] train: loss: 0.2013914
[Epoch 20; Iter    79/  209] train: loss: 0.1926023
[Epoch 20; Iter   109/  209] train: loss: 0.1651839
[Epoch 20; Iter   139/  209] train: loss: 0.1951500
[Epoch 20; Iter   169/  209] train: loss: 0.1250278
[Epoch 20; Iter   199/  209] train: loss: 0.1702836
[Epoch 20] ogbg-moltox21: 0.846203 val loss: 0.205879
[Epoch 20] ogbg-moltox21: 0.839208 test loss: 0.196871
[Epoch 21; Iter    20/  209] train: loss: 0.1379786
[Epoch 21; Iter    50/  209] train: loss: 0.1979034
[Epoch 21; Iter    80/  209] train: loss: 0.2998061
[Epoch 21; Iter   110/  209] train: loss: 0.1719014
[Epoch 21; Iter   140/  209] train: loss: 0.1600033
[Epoch 21; Iter   170/  209] train: loss: 0.1572686
[Epoch 21; Iter   200/  209] train: loss: 0.2261829
[Epoch 21] ogbg-moltox21: 0.849719 val loss: 0.199535
[Epoch 21] ogbg-moltox21: 0.839195 test loss: 0.195675
[Epoch 22; Iter    21/  209] train: loss: 0.1422090
[Epoch 22; Iter    51/  209] train: loss: 0.1296455
[Epoch 22; Iter    81/  209] train: loss: 0.1776209
[Epoch 22; Iter   111/  209] train: loss: 0.1418015
[Epoch 22; Iter   141/  209] train: loss: 0.1393060
[Epoch 22; Iter   171/  209] train: loss: 0.2002388
[Epoch 22; Iter   201/  209] train: loss: 0.0980104
[Epoch 22] ogbg-moltox21: 0.854472 val loss: 0.268128
[Epoch 22] ogbg-moltox21: 0.855012 test loss: 0.203075
[Epoch 23; Iter    22/  209] train: loss: 0.1534692
[Epoch 23; Iter    52/  209] train: loss: 0.2076159
[Epoch 23; Iter    82/  209] train: loss: 0.1482345
[Epoch 23; Iter   112/  209] train: loss: 0.1816214
[Epoch 23; Iter   142/  209] train: loss: 0.1726546
[Epoch 23; Iter   172/  209] train: loss: 0.1276319
[Epoch 23; Iter   202/  209] train: loss: 0.1756059
[Epoch 23] ogbg-moltox21: 0.865950 val loss: 0.195099
[Epoch 23] ogbg-moltox21: 0.840998 test loss: 0.191768
[Epoch 24; Iter    23/  209] train: loss: 0.1868197
[Epoch 24; Iter    53/  209] train: loss: 0.1731813
[Epoch 24; Iter    83/  209] train: loss: 0.1748673
[Epoch 24; Iter   113/  209] train: loss: 0.1694850
[Epoch 24; Iter   143/  209] train: loss: 0.2762303
[Epoch 24; Iter   173/  209] train: loss: 0.1766612
[Epoch 24; Iter   203/  209] train: loss: 0.1418031
[Epoch 24] ogbg-moltox21: 0.838269 val loss: 0.219390
[Epoch 24] ogbg-moltox21: 0.826581 test loss: 0.213062
[Epoch 25; Iter    24/  209] train: loss: 0.1455366
[Epoch 25; Iter    54/  209] train: loss: 0.1255190
[Epoch 25; Iter    84/  209] train: loss: 0.3069521
[Epoch 25; Iter   114/  209] train: loss: 0.1629213
[Epoch 25; Iter   144/  209] train: loss: 0.1573814
[Epoch 25; Iter   174/  209] train: loss: 0.1414761
[Epoch 25; Iter   204/  209] train: loss: 0.1654534
[Epoch 25] ogbg-moltox21: 0.857591 val loss: 0.204430
[Epoch 25] ogbg-moltox21: 0.835133 test loss: 0.206460
[Epoch 26; Iter    25/  209] train: loss: 0.2695783
[Epoch 26; Iter    55/  209] train: loss: 0.2289601
[Epoch 26; Iter    85/  209] train: loss: 0.1604305
[Epoch 26; Iter   115/  209] train: loss: 0.2525982
[Epoch 26; Iter   145/  209] train: loss: 0.1352990
[Epoch 26; Iter   175/  209] train: loss: 0.1488726
[Epoch 26; Iter   205/  209] train: loss: 0.1274967
[Epoch 26] ogbg-moltox21: 0.866138 val loss: 0.196818
[Epoch 26] ogbg-moltox21: 0.844987 test loss: 0.190470
[Epoch 27; Iter    26/  209] train: loss: 0.1474845
[Epoch 27; Iter    56/  209] train: loss: 0.1299372
[Epoch 27; Iter    86/  209] train: loss: 0.2070543
[Epoch 27; Iter   116/  209] train: loss: 0.1746965
[Epoch 27; Iter   146/  209] train: loss: 0.1703563
[Epoch 27; Iter   176/  209] train: loss: 0.2366377
[Epoch 27; Iter   206/  209] train: loss: 0.1269477
[Epoch 27] ogbg-moltox21: 0.861972 val loss: 0.199355
[Epoch 27] ogbg-moltox21: 0.842448 test loss: 0.191616
[Epoch 28; Iter    27/  209] train: loss: 0.1323613
[Epoch 28; Iter    57/  209] train: loss: 0.2086414
[Epoch 28; Iter    87/  209] train: loss: 0.1264121
[Epoch 28; Iter   117/  209] train: loss: 0.1733682
[Epoch 28; Iter   147/  209] train: loss: 0.1325837
[Epoch 28; Iter   177/  209] train: loss: 0.1545061
[Epoch 28; Iter   207/  209] train: loss: 0.1696501
[Epoch 28] ogbg-moltox21: 0.847392 val loss: 0.217493
[Epoch 28] ogbg-moltox21: 0.842167 test loss: 0.204217
[Epoch 29; Iter    28/  209] train: loss: 0.1223248
[Epoch 29; Iter    58/  209] train: loss: 0.1907538
[Epoch 29; Iter    88/  209] train: loss: 0.1539019
[Epoch 29; Iter   118/  209] train: loss: 0.2466285
[Epoch 29; Iter   148/  209] train: loss: 0.1509649
[Epoch 29; Iter   178/  209] train: loss: 0.1596908
[Epoch 29; Iter   208/  209] train: loss: 0.0933583
[Epoch 29] ogbg-moltox21: 0.868458 val loss: 0.194621
[Epoch 29] ogbg-moltox21: 0.841627 test loss: 0.199141
[Epoch 30; Iter    29/  209] train: loss: 0.1769516
[Epoch 30; Iter    59/  209] train: loss: 0.1433615
[Epoch 13; Iter    12/  209] train: loss: 0.1583564
[Epoch 13; Iter    42/  209] train: loss: 0.1809954
[Epoch 13; Iter    72/  209] train: loss: 0.1271771
[Epoch 13; Iter   102/  209] train: loss: 0.2064414
[Epoch 13; Iter   132/  209] train: loss: 0.1676679
[Epoch 13; Iter   162/  209] train: loss: 0.2134552
[Epoch 13; Iter   192/  209] train: loss: 0.2622870
[Epoch 13] ogbg-moltox21: 0.830319 val loss: 0.211020
[Epoch 13] ogbg-moltox21: 0.803450 test loss: 0.280767
[Epoch 14; Iter    13/  209] train: loss: 0.1401171
[Epoch 14; Iter    43/  209] train: loss: 0.0796076
[Epoch 14; Iter    73/  209] train: loss: 0.2521118
[Epoch 14; Iter   103/  209] train: loss: 0.1799085
[Epoch 14; Iter   133/  209] train: loss: 0.2188837
[Epoch 14; Iter   163/  209] train: loss: 0.1684474
[Epoch 14; Iter   193/  209] train: loss: 0.2227766
[Epoch 14] ogbg-moltox21: 0.817346 val loss: 0.215094
[Epoch 14] ogbg-moltox21: 0.817087 test loss: 0.202776
[Epoch 15; Iter    14/  209] train: loss: 0.2027676
[Epoch 15; Iter    44/  209] train: loss: 0.2079456
[Epoch 15; Iter    74/  209] train: loss: 0.1215653
[Epoch 15; Iter   104/  209] train: loss: 0.1399789
[Epoch 15; Iter   134/  209] train: loss: 0.1788672
[Epoch 15; Iter   164/  209] train: loss: 0.1343790
[Epoch 15; Iter   194/  209] train: loss: 0.2564373
[Epoch 15] ogbg-moltox21: 0.839600 val loss: 0.209008
[Epoch 15] ogbg-moltox21: 0.839460 test loss: 0.195627
[Epoch 16; Iter    15/  209] train: loss: 0.2370020
[Epoch 16; Iter    45/  209] train: loss: 0.1495726
[Epoch 16; Iter    75/  209] train: loss: 0.1537383
[Epoch 16; Iter   105/  209] train: loss: 0.1890716
[Epoch 16; Iter   135/  209] train: loss: 0.2128907
[Epoch 16; Iter   165/  209] train: loss: 0.1151351
[Epoch 16; Iter   195/  209] train: loss: 0.1912754
[Epoch 16] ogbg-moltox21: 0.816531 val loss: 0.218968
[Epoch 16] ogbg-moltox21: 0.805494 test loss: 0.229740
[Epoch 17; Iter    16/  209] train: loss: 0.1688340
[Epoch 17; Iter    46/  209] train: loss: 0.2618490
[Epoch 17; Iter    76/  209] train: loss: 0.1881272
[Epoch 17; Iter   106/  209] train: loss: 0.1439905
[Epoch 17; Iter   136/  209] train: loss: 0.1716374
[Epoch 17; Iter   166/  209] train: loss: 0.1448524
[Epoch 17; Iter   196/  209] train: loss: 0.2366897
[Epoch 17] ogbg-moltox21: 0.841482 val loss: 0.214782
[Epoch 17] ogbg-moltox21: 0.827114 test loss: 0.206492
[Epoch 18; Iter    17/  209] train: loss: 0.1468409
[Epoch 18; Iter    47/  209] train: loss: 0.1512345
[Epoch 18; Iter    77/  209] train: loss: 0.2143151
[Epoch 18; Iter   107/  209] train: loss: 0.2389587
[Epoch 18; Iter   137/  209] train: loss: 0.2319222
[Epoch 18; Iter   167/  209] train: loss: 0.2077205
[Epoch 18; Iter   197/  209] train: loss: 0.1493494
[Epoch 18] ogbg-moltox21: 0.840746 val loss: 0.207571
[Epoch 18] ogbg-moltox21: 0.824404 test loss: 0.197875
[Epoch 19; Iter    18/  209] train: loss: 0.1866072
[Epoch 19; Iter    48/  209] train: loss: 0.1504676
[Epoch 19; Iter    78/  209] train: loss: 0.1507521
[Epoch 19; Iter   108/  209] train: loss: 0.0970893
[Epoch 19; Iter   138/  209] train: loss: 0.2026060
[Epoch 19; Iter   168/  209] train: loss: 0.1302601
[Epoch 19; Iter   198/  209] train: loss: 0.1757282
[Epoch 19] ogbg-moltox21: 0.851213 val loss: 0.196737
[Epoch 19] ogbg-moltox21: 0.827209 test loss: 0.202369
[Epoch 20; Iter    19/  209] train: loss: 0.1800941
[Epoch 20; Iter    49/  209] train: loss: 0.1558776
[Epoch 20; Iter    79/  209] train: loss: 0.2400886
[Epoch 20; Iter   109/  209] train: loss: 0.2788176
[Epoch 20; Iter   139/  209] train: loss: 0.1375915
[Epoch 20; Iter   169/  209] train: loss: 0.1686940
[Epoch 20; Iter   199/  209] train: loss: 0.2173999
[Epoch 20] ogbg-moltox21: 0.856702 val loss: 0.194193
[Epoch 20] ogbg-moltox21: 0.814996 test loss: 0.200296
[Epoch 21; Iter    20/  209] train: loss: 0.1517573
[Epoch 21; Iter    50/  209] train: loss: 0.1580938
[Epoch 21; Iter    80/  209] train: loss: 0.1197744
[Epoch 21; Iter   110/  209] train: loss: 0.2463196
[Epoch 21; Iter   140/  209] train: loss: 0.1371573
[Epoch 21; Iter   170/  209] train: loss: 0.1810882
[Epoch 21; Iter   200/  209] train: loss: 0.1634085
[Epoch 21] ogbg-moltox21: 0.851618 val loss: 0.198565
[Epoch 21] ogbg-moltox21: 0.836010 test loss: 0.192845
[Epoch 22; Iter    21/  209] train: loss: 0.0942994
[Epoch 22; Iter    51/  209] train: loss: 0.1898382
[Epoch 22; Iter    81/  209] train: loss: 0.1968966
[Epoch 22; Iter   111/  209] train: loss: 0.1756862
[Epoch 22; Iter   141/  209] train: loss: 0.1572357
[Epoch 22; Iter   171/  209] train: loss: 0.1363373
[Epoch 22; Iter   201/  209] train: loss: 0.1803027
[Epoch 22] ogbg-moltox21: 0.856462 val loss: 0.277498
[Epoch 22] ogbg-moltox21: 0.829949 test loss: 0.305940
[Epoch 23; Iter    22/  209] train: loss: 0.1247923
[Epoch 23; Iter    52/  209] train: loss: 0.1807071
[Epoch 23; Iter    82/  209] train: loss: 0.1135399
[Epoch 23; Iter   112/  209] train: loss: 0.1075660
[Epoch 23; Iter   142/  209] train: loss: 0.2316582
[Epoch 23; Iter   172/  209] train: loss: 0.1776048
[Epoch 23; Iter   202/  209] train: loss: 0.2285185
[Epoch 23] ogbg-moltox21: 0.838842 val loss: 0.379051
[Epoch 23] ogbg-moltox21: 0.822311 test loss: 0.318148
[Epoch 24; Iter    23/  209] train: loss: 0.2036020
[Epoch 24; Iter    53/  209] train: loss: 0.2412925
[Epoch 24; Iter    83/  209] train: loss: 0.1328051
[Epoch 24; Iter   113/  209] train: loss: 0.1570846
[Epoch 24; Iter   143/  209] train: loss: 0.1818983
[Epoch 24; Iter   173/  209] train: loss: 0.2274844
[Epoch 24; Iter   203/  209] train: loss: 0.1188910
[Epoch 24] ogbg-moltox21: 0.847244 val loss: 0.206831
[Epoch 24] ogbg-moltox21: 0.841418 test loss: 0.267722
[Epoch 25; Iter    24/  209] train: loss: 0.2061151
[Epoch 25; Iter    54/  209] train: loss: 0.1550396
[Epoch 25; Iter    84/  209] train: loss: 0.2210711
[Epoch 25; Iter   114/  209] train: loss: 0.1819254
[Epoch 25; Iter   144/  209] train: loss: 0.0839199
[Epoch 25; Iter   174/  209] train: loss: 0.1863496
[Epoch 25; Iter   204/  209] train: loss: 0.1170956
[Epoch 25] ogbg-moltox21: 0.861229 val loss: 0.196190
[Epoch 25] ogbg-moltox21: 0.825876 test loss: 0.282900
[Epoch 26; Iter    25/  209] train: loss: 0.1458658
[Epoch 26; Iter    55/  209] train: loss: 0.1122138
[Epoch 26; Iter    85/  209] train: loss: 0.1463896
[Epoch 26; Iter   115/  209] train: loss: 0.1635567
[Epoch 26; Iter   145/  209] train: loss: 0.1244404
[Epoch 26; Iter   175/  209] train: loss: 0.2388918
[Epoch 26; Iter   205/  209] train: loss: 0.1128701
[Epoch 26] ogbg-moltox21: 0.857812 val loss: 0.215459
[Epoch 26] ogbg-moltox21: 0.832840 test loss: 0.209212
[Epoch 27; Iter    26/  209] train: loss: 0.1013643
[Epoch 27; Iter    56/  209] train: loss: 0.1050351
[Epoch 27; Iter    86/  209] train: loss: 0.1026084
[Epoch 27; Iter   116/  209] train: loss: 0.2550364
[Epoch 27; Iter   146/  209] train: loss: 0.0952722
[Epoch 27; Iter   176/  209] train: loss: 0.1378845
[Epoch 27; Iter   206/  209] train: loss: 0.1578097
[Epoch 27] ogbg-moltox21: 0.863417 val loss: 0.244058
[Epoch 27] ogbg-moltox21: 0.833461 test loss: 0.302426
[Epoch 28; Iter    27/  209] train: loss: 0.1857526
[Epoch 28; Iter    57/  209] train: loss: 0.2662432
[Epoch 28; Iter    87/  209] train: loss: 0.1611803
[Epoch 28; Iter   117/  209] train: loss: 0.1701562
[Epoch 28; Iter   147/  209] train: loss: 0.1597393
[Epoch 28; Iter   177/  209] train: loss: 0.1183101
[Epoch 28; Iter   207/  209] train: loss: 0.1752613
[Epoch 28] ogbg-moltox21: 0.863578 val loss: 0.199471
[Epoch 28] ogbg-moltox21: 0.835755 test loss: 0.780621
[Epoch 29; Iter    28/  209] train: loss: 0.1390178
[Epoch 29; Iter    58/  209] train: loss: 0.1870684
[Epoch 29; Iter    88/  209] train: loss: 0.1344741
[Epoch 29; Iter   118/  209] train: loss: 0.2382569
[Epoch 29; Iter   148/  209] train: loss: 0.1489365
[Epoch 29; Iter   178/  209] train: loss: 0.1482264
[Epoch 29; Iter   208/  209] train: loss: 0.0980348
[Epoch 29] ogbg-moltox21: 0.862214 val loss: 0.198708
[Epoch 29] ogbg-moltox21: 0.832608 test loss: 0.192993
[Epoch 30; Iter    29/  209] train: loss: 0.1302972
[Epoch 30; Iter    59/  209] train: loss: 0.1308663
[Epoch 14; Iter    81/  183] train: loss: 0.2018944
[Epoch 14; Iter   111/  183] train: loss: 0.1812067
[Epoch 14; Iter   141/  183] train: loss: 0.1946583
[Epoch 14; Iter   171/  183] train: loss: 0.1542521
[Epoch 14] ogbg-moltox21: 0.801539 val loss: 0.206961
[Epoch 14] ogbg-moltox21: 0.829211 test loss: 0.205324
[Epoch 15; Iter    18/  183] train: loss: 0.3142806
[Epoch 15; Iter    48/  183] train: loss: 0.1729805
[Epoch 15; Iter    78/  183] train: loss: 0.1597721
[Epoch 15; Iter   108/  183] train: loss: 0.2372424
[Epoch 15; Iter   138/  183] train: loss: 0.1804406
[Epoch 15; Iter   168/  183] train: loss: 0.1510120
[Epoch 15] ogbg-moltox21: 0.810557 val loss: 0.206287
[Epoch 15] ogbg-moltox21: 0.831873 test loss: 0.202825
[Epoch 16; Iter    15/  183] train: loss: 0.1140704
[Epoch 16; Iter    45/  183] train: loss: 0.2051035
[Epoch 16; Iter    75/  183] train: loss: 0.1397737
[Epoch 16; Iter   105/  183] train: loss: 0.1280951
[Epoch 16; Iter   135/  183] train: loss: 0.1200640
[Epoch 16; Iter   165/  183] train: loss: 0.1863960
[Epoch 16] ogbg-moltox21: 0.821041 val loss: 0.198834
[Epoch 16] ogbg-moltox21: 0.843292 test loss: 0.197792
[Epoch 17; Iter    12/  183] train: loss: 0.2316958
[Epoch 17; Iter    42/  183] train: loss: 0.3510599
[Epoch 17; Iter    72/  183] train: loss: 0.1829163
[Epoch 17; Iter   102/  183] train: loss: 0.1964693
[Epoch 17; Iter   132/  183] train: loss: 0.2469021
[Epoch 17; Iter   162/  183] train: loss: 0.1725596
[Epoch 17] ogbg-moltox21: 0.809896 val loss: 0.207214
[Epoch 17] ogbg-moltox21: 0.844388 test loss: 0.201700
[Epoch 18; Iter     9/  183] train: loss: 0.1146790
[Epoch 18; Iter    39/  183] train: loss: 0.1252071
[Epoch 18; Iter    69/  183] train: loss: 0.3335539
[Epoch 18; Iter    99/  183] train: loss: 0.1786261
[Epoch 18; Iter   129/  183] train: loss: 0.3134809
[Epoch 18; Iter   159/  183] train: loss: 0.1947789
[Epoch 18] ogbg-moltox21: 0.814929 val loss: 0.201779
[Epoch 18] ogbg-moltox21: 0.837147 test loss: 0.202042
[Epoch 19; Iter     6/  183] train: loss: 0.1583168
[Epoch 19; Iter    36/  183] train: loss: 0.2544085
[Epoch 19; Iter    66/  183] train: loss: 0.1083307
[Epoch 19; Iter    96/  183] train: loss: 0.2124954
[Epoch 19; Iter   126/  183] train: loss: 0.1717943
[Epoch 19; Iter   156/  183] train: loss: 0.1889783
[Epoch 19] ogbg-moltox21: 0.821590 val loss: 0.201957
[Epoch 19] ogbg-moltox21: 0.843809 test loss: 0.200614
[Epoch 20; Iter     3/  183] train: loss: 0.1540534
[Epoch 20; Iter    33/  183] train: loss: 0.1399799
[Epoch 20; Iter    63/  183] train: loss: 0.1102992
[Epoch 20; Iter    93/  183] train: loss: 0.1239420
[Epoch 20; Iter   123/  183] train: loss: 0.1216543
[Epoch 20; Iter   153/  183] train: loss: 0.1591330
[Epoch 20; Iter   183/  183] train: loss: 0.2100974
[Epoch 20] ogbg-moltox21: 0.827205 val loss: 0.195696
[Epoch 20] ogbg-moltox21: 0.842438 test loss: 0.196068
[Epoch 21; Iter    30/  183] train: loss: 0.2473039
[Epoch 21; Iter    60/  183] train: loss: 0.1599564
[Epoch 21; Iter    90/  183] train: loss: 0.2438673
[Epoch 21; Iter   120/  183] train: loss: 0.1911188
[Epoch 21; Iter   150/  183] train: loss: 0.1585812
[Epoch 21; Iter   180/  183] train: loss: 0.1637198
[Epoch 21] ogbg-moltox21: 0.777269 val loss: 0.229146
[Epoch 21] ogbg-moltox21: 0.811923 test loss: 0.225767
[Epoch 22; Iter    27/  183] train: loss: 0.0995694
[Epoch 22; Iter    57/  183] train: loss: 0.1731373
[Epoch 22; Iter    87/  183] train: loss: 0.2145484
[Epoch 22; Iter   117/  183] train: loss: 0.1974010
[Epoch 22; Iter   147/  183] train: loss: 0.1915651
[Epoch 22; Iter   177/  183] train: loss: 0.1623593
[Epoch 22] ogbg-moltox21: 0.823238 val loss: 0.203309
[Epoch 22] ogbg-moltox21: 0.834822 test loss: 0.205405
[Epoch 23; Iter    24/  183] train: loss: 0.2022594
[Epoch 23; Iter    54/  183] train: loss: 0.2010016
[Epoch 23; Iter    84/  183] train: loss: 0.1923374
[Epoch 23; Iter   114/  183] train: loss: 0.1343998
[Epoch 23; Iter   144/  183] train: loss: 0.2015741
[Epoch 23; Iter   174/  183] train: loss: 0.2703463
[Epoch 23] ogbg-moltox21: 0.817153 val loss: 0.202343
[Epoch 23] ogbg-moltox21: 0.834586 test loss: 0.202054
[Epoch 24; Iter    21/  183] train: loss: 0.1713140
[Epoch 24; Iter    51/  183] train: loss: 0.1272416
[Epoch 24; Iter    81/  183] train: loss: 0.1987553
[Epoch 24; Iter   111/  183] train: loss: 0.1343849
[Epoch 24; Iter   141/  183] train: loss: 0.1982831
[Epoch 24; Iter   171/  183] train: loss: 0.1997050
[Epoch 24] ogbg-moltox21: 0.816528 val loss: 0.234354
[Epoch 24] ogbg-moltox21: 0.833358 test loss: 0.227019
[Epoch 25; Iter    18/  183] train: loss: 0.2565871
[Epoch 25; Iter    48/  183] train: loss: 0.1574390
[Epoch 25; Iter    78/  183] train: loss: 0.1635559
[Epoch 25; Iter   108/  183] train: loss: 0.1396252
[Epoch 25; Iter   138/  183] train: loss: 0.1762448
[Epoch 25; Iter   168/  183] train: loss: 0.1709985
[Epoch 25] ogbg-moltox21: 0.833015 val loss: 0.196247
[Epoch 25] ogbg-moltox21: 0.843733 test loss: 0.200195
[Epoch 26; Iter    15/  183] train: loss: 0.2059219
[Epoch 26; Iter    45/  183] train: loss: 0.1399502
[Epoch 26; Iter    75/  183] train: loss: 0.1180481
[Epoch 26; Iter   105/  183] train: loss: 0.1400740
[Epoch 26; Iter   135/  183] train: loss: 0.2471545
[Epoch 26; Iter   165/  183] train: loss: 0.1230465
[Epoch 26] ogbg-moltox21: 0.716677 val loss: 0.286368
[Epoch 26] ogbg-moltox21: 0.744739 test loss: 0.283165
[Epoch 27; Iter    12/  183] train: loss: 0.2379479
[Epoch 27; Iter    42/  183] train: loss: 0.2466035
[Epoch 27; Iter    72/  183] train: loss: 0.1714259
[Epoch 27; Iter   102/  183] train: loss: 0.1534079
[Epoch 27; Iter   132/  183] train: loss: 0.2774185
[Epoch 27; Iter   162/  183] train: loss: 0.1562674
[Epoch 27] ogbg-moltox21: 0.789510 val loss: 0.214777
[Epoch 27] ogbg-moltox21: 0.818451 test loss: 0.214231
[Epoch 28; Iter     9/  183] train: loss: 0.2712429
[Epoch 28; Iter    39/  183] train: loss: 0.2670130
[Epoch 28; Iter    69/  183] train: loss: 0.1408493
[Epoch 28; Iter    99/  183] train: loss: 0.1117426
[Epoch 28; Iter   129/  183] train: loss: 0.1615436
[Epoch 28; Iter   159/  183] train: loss: 0.1970602
[Epoch 28] ogbg-moltox21: 0.826797 val loss: 0.207977
[Epoch 28] ogbg-moltox21: 0.834060 test loss: 0.206457
[Epoch 29; Iter     6/  183] train: loss: 0.2015383
[Epoch 29; Iter    36/  183] train: loss: 0.2337470
[Epoch 29; Iter    66/  183] train: loss: 0.1361940
[Epoch 29; Iter    96/  183] train: loss: 0.2350009
[Epoch 29; Iter   126/  183] train: loss: 0.1716697
[Epoch 29; Iter   156/  183] train: loss: 0.1417455
[Epoch 29] ogbg-moltox21: 0.834632 val loss: 0.206038
[Epoch 29] ogbg-moltox21: 0.837859 test loss: 0.202032
[Epoch 30; Iter     3/  183] train: loss: 0.1775506
[Epoch 30; Iter    33/  183] train: loss: 0.2037751
[Epoch 30; Iter    63/  183] train: loss: 0.2033810
[Epoch 30; Iter    93/  183] train: loss: 0.1846700
[Epoch 30; Iter   123/  183] train: loss: 0.1500116
[Epoch 30; Iter   153/  183] train: loss: 0.1943245
[Epoch 30; Iter   183/  183] train: loss: 0.2195375
[Epoch 30] ogbg-moltox21: 0.818919 val loss: 0.210821
[Epoch 30] ogbg-moltox21: 0.838434 test loss: 0.205679
[Epoch 31; Iter    30/  183] train: loss: 0.2614129
[Epoch 31; Iter    60/  183] train: loss: 0.1505453
[Epoch 31; Iter    90/  183] train: loss: 0.1261363
[Epoch 31; Iter   120/  183] train: loss: 0.3094646
[Epoch 31; Iter   150/  183] train: loss: 0.1181437
[Epoch 31; Iter   180/  183] train: loss: 0.1863123
[Epoch 31] ogbg-moltox21: 0.826701 val loss: 0.232160
[Epoch 31] ogbg-moltox21: 0.840619 test loss: 0.202719
[Epoch 32; Iter    27/  183] train: loss: 0.1912258
[Epoch 32; Iter    57/  183] train: loss: 0.2256195
[Epoch 32; Iter    87/  183] train: loss: 0.1421270
[Epoch 32; Iter   117/  183] train: loss: 0.1958946
[Epoch 32; Iter   147/  183] train: loss: 0.2499506
[Epoch 32; Iter   177/  183] train: loss: 0.1921939
[Epoch 32] ogbg-moltox21: 0.797953 val loss: 0.213449
[Epoch 32] ogbg-moltox21: 0.820527 test loss: 0.212886
[Epoch 33; Iter    24/  183] train: loss: 0.1892419
[Epoch 33; Iter    54/  183] train: loss: 0.1586190
[Epoch 33; Iter    84/  183] train: loss: 0.2045913
[Epoch 14; Iter    81/  183] train: loss: 0.1582460
[Epoch 14; Iter   111/  183] train: loss: 0.2350734
[Epoch 14; Iter   141/  183] train: loss: 0.2377160
[Epoch 14; Iter   171/  183] train: loss: 0.2121250
[Epoch 14] ogbg-moltox21: 0.792006 val loss: 0.212460
[Epoch 14] ogbg-moltox21: 0.815471 test loss: 0.213350
[Epoch 15; Iter    18/  183] train: loss: 0.1532781
[Epoch 15; Iter    48/  183] train: loss: 0.1680457
[Epoch 15; Iter    78/  183] train: loss: 0.1515491
[Epoch 15; Iter   108/  183] train: loss: 0.1881126
[Epoch 15; Iter   138/  183] train: loss: 0.2307432
[Epoch 15; Iter   168/  183] train: loss: 0.2114336
[Epoch 15] ogbg-moltox21: 0.803966 val loss: 0.209126
[Epoch 15] ogbg-moltox21: 0.826411 test loss: 0.210460
[Epoch 16; Iter    15/  183] train: loss: 0.1584660
[Epoch 16; Iter    45/  183] train: loss: 0.2138312
[Epoch 16; Iter    75/  183] train: loss: 0.1726592
[Epoch 16; Iter   105/  183] train: loss: 0.1370138
[Epoch 16; Iter   135/  183] train: loss: 0.1341866
[Epoch 16; Iter   165/  183] train: loss: 0.2016090
[Epoch 16] ogbg-moltox21: 0.794176 val loss: 0.241643
[Epoch 16] ogbg-moltox21: 0.806911 test loss: 0.223843
[Epoch 17; Iter    12/  183] train: loss: 0.1581338
[Epoch 17; Iter    42/  183] train: loss: 0.2033524
[Epoch 17; Iter    72/  183] train: loss: 0.1474131
[Epoch 17; Iter   102/  183] train: loss: 0.2471841
[Epoch 17; Iter   132/  183] train: loss: 0.2100971
[Epoch 17; Iter   162/  183] train: loss: 0.1850615
[Epoch 17] ogbg-moltox21: 0.780176 val loss: 0.217631
[Epoch 17] ogbg-moltox21: 0.817456 test loss: 0.213524
[Epoch 18; Iter     9/  183] train: loss: 0.2461230
[Epoch 18; Iter    39/  183] train: loss: 0.2637801
[Epoch 18; Iter    69/  183] train: loss: 0.1717502
[Epoch 18; Iter    99/  183] train: loss: 0.2596112
[Epoch 18; Iter   129/  183] train: loss: 0.1340813
[Epoch 18; Iter   159/  183] train: loss: 0.2042212
[Epoch 18] ogbg-moltox21: 0.788476 val loss: 0.209239
[Epoch 18] ogbg-moltox21: 0.830486 test loss: 0.203513
[Epoch 19; Iter     6/  183] train: loss: 0.2159789
[Epoch 19; Iter    36/  183] train: loss: 0.2087088
[Epoch 19; Iter    66/  183] train: loss: 0.2314935
[Epoch 19; Iter    96/  183] train: loss: 0.2166523
[Epoch 19; Iter   126/  183] train: loss: 0.1361855
[Epoch 19; Iter   156/  183] train: loss: 0.2005420
[Epoch 19] ogbg-moltox21: 0.761572 val loss: 0.305033
[Epoch 19] ogbg-moltox21: 0.799715 test loss: 0.217210
[Epoch 20; Iter     3/  183] train: loss: 0.2424694
[Epoch 20; Iter    33/  183] train: loss: 0.2717419
[Epoch 20; Iter    63/  183] train: loss: 0.1487726
[Epoch 20; Iter    93/  183] train: loss: 0.1884287
[Epoch 20; Iter   123/  183] train: loss: 0.2263355
[Epoch 20; Iter   153/  183] train: loss: 0.2359871
[Epoch 20; Iter   183/  183] train: loss: 0.2632500
[Epoch 20] ogbg-moltox21: 0.807027 val loss: 0.204093
[Epoch 20] ogbg-moltox21: 0.833501 test loss: 0.205816
[Epoch 21; Iter    30/  183] train: loss: 0.1352453
[Epoch 21; Iter    60/  183] train: loss: 0.1593660
[Epoch 21; Iter    90/  183] train: loss: 0.1949934
[Epoch 21; Iter   120/  183] train: loss: 0.2041385
[Epoch 21; Iter   150/  183] train: loss: 0.2049795
[Epoch 21; Iter   180/  183] train: loss: 0.2128004
[Epoch 21] ogbg-moltox21: 0.816313 val loss: 0.335891
[Epoch 21] ogbg-moltox21: 0.824136 test loss: 0.213352
[Epoch 22; Iter    27/  183] train: loss: 0.2486990
[Epoch 22; Iter    57/  183] train: loss: 0.1690807
[Epoch 22; Iter    87/  183] train: loss: 0.1946367
[Epoch 22; Iter   117/  183] train: loss: 0.1651948
[Epoch 22; Iter   147/  183] train: loss: 0.1794001
[Epoch 22; Iter   177/  183] train: loss: 0.2047417
[Epoch 22] ogbg-moltox21: 0.822424 val loss: 0.201678
[Epoch 22] ogbg-moltox21: 0.837293 test loss: 0.201906
[Epoch 23; Iter    24/  183] train: loss: 0.1871479
[Epoch 23; Iter    54/  183] train: loss: 0.1252870
[Epoch 23; Iter    84/  183] train: loss: 0.1938117
[Epoch 23; Iter   114/  183] train: loss: 0.2126502
[Epoch 23; Iter   144/  183] train: loss: 0.1994945
[Epoch 23; Iter   174/  183] train: loss: 0.1238521
[Epoch 23] ogbg-moltox21: 0.821245 val loss: 0.200401
[Epoch 23] ogbg-moltox21: 0.836158 test loss: 0.202128
[Epoch 24; Iter    21/  183] train: loss: 0.1343483
[Epoch 24; Iter    51/  183] train: loss: 0.1959874
[Epoch 24; Iter    81/  183] train: loss: 0.2075066
[Epoch 24; Iter   111/  183] train: loss: 0.1969869
[Epoch 24; Iter   141/  183] train: loss: 0.1346386
[Epoch 24; Iter   171/  183] train: loss: 0.1482435
[Epoch 24] ogbg-moltox21: 0.831464 val loss: 0.198215
[Epoch 24] ogbg-moltox21: 0.842065 test loss: 0.201042
[Epoch 25; Iter    18/  183] train: loss: 0.1408617
[Epoch 25; Iter    48/  183] train: loss: 0.0919646
[Epoch 25; Iter    78/  183] train: loss: 0.1863933
[Epoch 25; Iter   108/  183] train: loss: 0.2005070
[Epoch 25; Iter   138/  183] train: loss: 0.1081116
[Epoch 25; Iter   168/  183] train: loss: 0.2432211
[Epoch 25] ogbg-moltox21: 0.823230 val loss: 0.202941
[Epoch 25] ogbg-moltox21: 0.837289 test loss: 0.204390
[Epoch 26; Iter    15/  183] train: loss: 0.1424556
[Epoch 26; Iter    45/  183] train: loss: 0.1981055
[Epoch 26; Iter    75/  183] train: loss: 0.1461235
[Epoch 26; Iter   105/  183] train: loss: 0.2190349
[Epoch 26; Iter   135/  183] train: loss: 0.1450378
[Epoch 26; Iter   165/  183] train: loss: 0.1409333
[Epoch 26] ogbg-moltox21: 0.825559 val loss: 0.197812
[Epoch 26] ogbg-moltox21: 0.848213 test loss: 0.199385
[Epoch 27; Iter    12/  183] train: loss: 0.2462033
[Epoch 27; Iter    42/  183] train: loss: 0.1559306
[Epoch 27; Iter    72/  183] train: loss: 0.1318697
[Epoch 27; Iter   102/  183] train: loss: 0.1678976
[Epoch 27; Iter   132/  183] train: loss: 0.1883818
[Epoch 27; Iter   162/  183] train: loss: 0.1141799
[Epoch 27] ogbg-moltox21: 0.829471 val loss: 0.196522
[Epoch 27] ogbg-moltox21: 0.842831 test loss: 0.197748
[Epoch 28; Iter     9/  183] train: loss: 0.1403551
[Epoch 28; Iter    39/  183] train: loss: 0.1842201
[Epoch 28; Iter    69/  183] train: loss: 0.1619203
[Epoch 28; Iter    99/  183] train: loss: 0.3222067
[Epoch 28; Iter   129/  183] train: loss: 0.2231326
[Epoch 28; Iter   159/  183] train: loss: 0.0871666
[Epoch 28] ogbg-moltox21: 0.832373 val loss: 0.195271
[Epoch 28] ogbg-moltox21: 0.839886 test loss: 0.203603
[Epoch 29; Iter     6/  183] train: loss: 0.1697456
[Epoch 29; Iter    36/  183] train: loss: 0.1167338
[Epoch 29; Iter    66/  183] train: loss: 0.1114898
[Epoch 29; Iter    96/  183] train: loss: 0.2716339
[Epoch 29; Iter   126/  183] train: loss: 0.1757420
[Epoch 29; Iter   156/  183] train: loss: 0.1411606
[Epoch 29] ogbg-moltox21: 0.831778 val loss: 0.197413
[Epoch 29] ogbg-moltox21: 0.847567 test loss: 0.202539
[Epoch 30; Iter     3/  183] train: loss: 0.1541663
[Epoch 30; Iter    33/  183] train: loss: 0.1760589
[Epoch 30; Iter    63/  183] train: loss: 0.1841534
[Epoch 30; Iter    93/  183] train: loss: 0.2176062
[Epoch 30; Iter   123/  183] train: loss: 0.2534866
[Epoch 30; Iter   153/  183] train: loss: 0.1403504
[Epoch 30; Iter   183/  183] train: loss: 0.1935261
[Epoch 30] ogbg-moltox21: 0.829696 val loss: 0.196999
[Epoch 30] ogbg-moltox21: 0.850309 test loss: 0.195932
[Epoch 31; Iter    30/  183] train: loss: 0.1356443
[Epoch 31; Iter    60/  183] train: loss: 0.1327150
[Epoch 31; Iter    90/  183] train: loss: 0.1389553
[Epoch 31; Iter   120/  183] train: loss: 0.1402782
[Epoch 31; Iter   150/  183] train: loss: 0.1529745
[Epoch 31; Iter   180/  183] train: loss: 0.1717207
[Epoch 31] ogbg-moltox21: 0.825301 val loss: 0.200107
[Epoch 31] ogbg-moltox21: 0.841483 test loss: 0.204479
[Epoch 32; Iter    27/  183] train: loss: 0.1558754
[Epoch 32; Iter    57/  183] train: loss: 0.3410609
[Epoch 32; Iter    87/  183] train: loss: 0.1382941
[Epoch 32; Iter   117/  183] train: loss: 0.1350184
[Epoch 32; Iter   147/  183] train: loss: 0.2008437
[Epoch 32; Iter   177/  183] train: loss: 0.1465680
[Epoch 32] ogbg-moltox21: 0.830447 val loss: 0.201608
[Epoch 32] ogbg-moltox21: 0.843929 test loss: 0.199045
[Epoch 33; Iter    24/  183] train: loss: 0.1866341
[Epoch 33; Iter    54/  183] train: loss: 0.1029439
[Epoch 33; Iter    84/  183] train: loss: 0.1944642
[Epoch 14; Iter    81/  183] train: loss: 0.1903642
[Epoch 14; Iter   111/  183] train: loss: 0.1953317
[Epoch 14; Iter   141/  183] train: loss: 0.1676617
[Epoch 14; Iter   171/  183] train: loss: 0.2033331
[Epoch 14] ogbg-moltox21: 0.791481 val loss: 0.220410
[Epoch 14] ogbg-moltox21: 0.821299 test loss: 0.218312
[Epoch 15; Iter    18/  183] train: loss: 0.1978683
[Epoch 15; Iter    48/  183] train: loss: 0.1267809
[Epoch 15; Iter    78/  183] train: loss: 0.1913365
[Epoch 15; Iter   108/  183] train: loss: 0.1392034
[Epoch 15; Iter   138/  183] train: loss: 0.1179312
[Epoch 15; Iter   168/  183] train: loss: 0.2033319
[Epoch 15] ogbg-moltox21: 0.802492 val loss: 0.210899
[Epoch 15] ogbg-moltox21: 0.827320 test loss: 0.210964
[Epoch 16; Iter    15/  183] train: loss: 0.1411861
[Epoch 16; Iter    45/  183] train: loss: 0.1451042
[Epoch 16; Iter    75/  183] train: loss: 0.2587222
[Epoch 16; Iter   105/  183] train: loss: 0.1576489
[Epoch 16; Iter   135/  183] train: loss: 0.1611625
[Epoch 16; Iter   165/  183] train: loss: 0.2244328
[Epoch 16] ogbg-moltox21: 0.804864 val loss: 0.204995
[Epoch 16] ogbg-moltox21: 0.828928 test loss: 0.205415
[Epoch 17; Iter    12/  183] train: loss: 0.1605208
[Epoch 17; Iter    42/  183] train: loss: 0.1633777
[Epoch 17; Iter    72/  183] train: loss: 0.1426290
[Epoch 17; Iter   102/  183] train: loss: 0.2863297
[Epoch 17; Iter   132/  183] train: loss: 0.2549377
[Epoch 17; Iter   162/  183] train: loss: 0.2610747
[Epoch 17] ogbg-moltox21: 0.820749 val loss: 0.199420
[Epoch 17] ogbg-moltox21: 0.828273 test loss: 0.203216
[Epoch 18; Iter     9/  183] train: loss: 0.2330212
[Epoch 18; Iter    39/  183] train: loss: 0.1522999
[Epoch 18; Iter    69/  183] train: loss: 0.1425932
[Epoch 18; Iter    99/  183] train: loss: 0.1421899
[Epoch 18; Iter   129/  183] train: loss: 0.2340489
[Epoch 18; Iter   159/  183] train: loss: 0.1935976
[Epoch 18] ogbg-moltox21: 0.810560 val loss: 0.213383
[Epoch 18] ogbg-moltox21: 0.827294 test loss: 0.212441
[Epoch 19; Iter     6/  183] train: loss: 0.1359743
[Epoch 19; Iter    36/  183] train: loss: 0.1965533
[Epoch 19; Iter    66/  183] train: loss: 0.2544221
[Epoch 19; Iter    96/  183] train: loss: 0.1683786
[Epoch 19; Iter   126/  183] train: loss: 0.1709101
[Epoch 19; Iter   156/  183] train: loss: 0.1642267
[Epoch 19] ogbg-moltox21: 0.818098 val loss: 0.201046
[Epoch 19] ogbg-moltox21: 0.844436 test loss: 0.203010
[Epoch 20; Iter     3/  183] train: loss: 0.1863131
[Epoch 20; Iter    33/  183] train: loss: 0.1768173
[Epoch 20; Iter    63/  183] train: loss: 0.1621814
[Epoch 20; Iter    93/  183] train: loss: 0.2056065
[Epoch 20; Iter   123/  183] train: loss: 0.2043711
[Epoch 20; Iter   153/  183] train: loss: 0.1749288
[Epoch 20; Iter   183/  183] train: loss: 0.1979157
[Epoch 20] ogbg-moltox21: 0.816464 val loss: 0.198686
[Epoch 20] ogbg-moltox21: 0.832592 test loss: 0.198272
[Epoch 21; Iter    30/  183] train: loss: 0.1343924
[Epoch 21; Iter    60/  183] train: loss: 0.1657375
[Epoch 21; Iter    90/  183] train: loss: 0.1621655
[Epoch 21; Iter   120/  183] train: loss: 0.1437089
[Epoch 21; Iter   150/  183] train: loss: 0.2065890
[Epoch 21; Iter   180/  183] train: loss: 0.2134814
[Epoch 21] ogbg-moltox21: 0.822380 val loss: 0.201359
[Epoch 21] ogbg-moltox21: 0.830440 test loss: 0.204521
[Epoch 22; Iter    27/  183] train: loss: 0.1150608
[Epoch 22; Iter    57/  183] train: loss: 0.1855269
[Epoch 22; Iter    87/  183] train: loss: 0.2008573
[Epoch 22; Iter   117/  183] train: loss: 0.1961728
[Epoch 22; Iter   147/  183] train: loss: 0.1983016
[Epoch 22; Iter   177/  183] train: loss: 0.2917093
[Epoch 22] ogbg-moltox21: 0.830035 val loss: 0.196953
[Epoch 22] ogbg-moltox21: 0.846639 test loss: 0.195701
[Epoch 23; Iter    24/  183] train: loss: 0.2720283
[Epoch 23; Iter    54/  183] train: loss: 0.1852920
[Epoch 23; Iter    84/  183] train: loss: 0.1825136
[Epoch 23; Iter   114/  183] train: loss: 0.1717566
[Epoch 23; Iter   144/  183] train: loss: 0.1634108
[Epoch 23; Iter   174/  183] train: loss: 0.1771152
[Epoch 23] ogbg-moltox21: 0.830039 val loss: 0.193955
[Epoch 23] ogbg-moltox21: 0.849316 test loss: 0.195539
[Epoch 24; Iter    21/  183] train: loss: 0.1899459
[Epoch 24; Iter    51/  183] train: loss: 0.1802221
[Epoch 24; Iter    81/  183] train: loss: 0.2186011
[Epoch 24; Iter   111/  183] train: loss: 0.2026411
[Epoch 24; Iter   141/  183] train: loss: 0.1599362
[Epoch 24; Iter   171/  183] train: loss: 0.1356297
[Epoch 24] ogbg-moltox21: 0.827667 val loss: 0.201468
[Epoch 24] ogbg-moltox21: 0.850261 test loss: 0.197953
[Epoch 25; Iter    18/  183] train: loss: 0.1884999
[Epoch 25; Iter    48/  183] train: loss: 0.1853598
[Epoch 25; Iter    78/  183] train: loss: 0.1333307
[Epoch 25; Iter   108/  183] train: loss: 0.2859002
[Epoch 25; Iter   138/  183] train: loss: 0.1665469
[Epoch 25; Iter   168/  183] train: loss: 0.1965327
[Epoch 25] ogbg-moltox21: 0.835422 val loss: 0.195885
[Epoch 25] ogbg-moltox21: 0.851918 test loss: 0.228400
[Epoch 26; Iter    15/  183] train: loss: 0.1608623
[Epoch 26; Iter    45/  183] train: loss: 0.1848117
[Epoch 26; Iter    75/  183] train: loss: 0.1714839
[Epoch 26; Iter   105/  183] train: loss: 0.2182548
[Epoch 26; Iter   135/  183] train: loss: 0.1509966
[Epoch 26; Iter   165/  183] train: loss: 0.1604172
[Epoch 26] ogbg-moltox21: 0.828745 val loss: 0.195971
[Epoch 26] ogbg-moltox21: 0.838342 test loss: 0.197008
[Epoch 27; Iter    12/  183] train: loss: 0.1341985
[Epoch 27; Iter    42/  183] train: loss: 0.1930341
[Epoch 27; Iter    72/  183] train: loss: 0.1776373
[Epoch 27; Iter   102/  183] train: loss: 0.2044306
[Epoch 27; Iter   132/  183] train: loss: 0.2113480
[Epoch 27; Iter   162/  183] train: loss: 0.1234589
[Epoch 27] ogbg-moltox21: 0.828264 val loss: 0.194262
[Epoch 27] ogbg-moltox21: 0.845572 test loss: 0.194076
[Epoch 28; Iter     9/  183] train: loss: 0.1978175
[Epoch 28; Iter    39/  183] train: loss: 0.2622702
[Epoch 28; Iter    69/  183] train: loss: 0.1791941
[Epoch 28; Iter    99/  183] train: loss: 0.1503039
[Epoch 28; Iter   129/  183] train: loss: 0.2620598
[Epoch 28; Iter   159/  183] train: loss: 0.0949254
[Epoch 28] ogbg-moltox21: 0.832534 val loss: 0.197502
[Epoch 28] ogbg-moltox21: 0.851187 test loss: 0.194717
[Epoch 29; Iter     6/  183] train: loss: 0.2394916
[Epoch 29; Iter    36/  183] train: loss: 0.1337120
[Epoch 29; Iter    66/  183] train: loss: 0.1502218
[Epoch 29; Iter    96/  183] train: loss: 0.1421257
[Epoch 29; Iter   126/  183] train: loss: 0.1623443
[Epoch 29; Iter   156/  183] train: loss: 0.1719590
[Epoch 29] ogbg-moltox21: 0.842414 val loss: 0.192895
[Epoch 29] ogbg-moltox21: 0.853414 test loss: 0.189314
[Epoch 30; Iter     3/  183] train: loss: 0.1163796
[Epoch 30; Iter    33/  183] train: loss: 0.1074099
[Epoch 30; Iter    63/  183] train: loss: 0.1836363
[Epoch 30; Iter    93/  183] train: loss: 0.2253573
[Epoch 30; Iter   123/  183] train: loss: 0.1847870
[Epoch 30; Iter   153/  183] train: loss: 0.2445294
[Epoch 30; Iter   183/  183] train: loss: 0.1242395
[Epoch 30] ogbg-moltox21: 0.825841 val loss: 0.197212
[Epoch 30] ogbg-moltox21: 0.840135 test loss: 0.281364
[Epoch 31; Iter    30/  183] train: loss: 0.1079333
[Epoch 31; Iter    60/  183] train: loss: 0.1523893
[Epoch 31; Iter    90/  183] train: loss: 0.1732707
[Epoch 31; Iter   120/  183] train: loss: 0.1978318
[Epoch 31; Iter   150/  183] train: loss: 0.1963280
[Epoch 31; Iter   180/  183] train: loss: 0.1755418
[Epoch 31] ogbg-moltox21: 0.829033 val loss: 0.197724
[Epoch 31] ogbg-moltox21: 0.847940 test loss: 0.194856
[Epoch 32; Iter    27/  183] train: loss: 0.1702642
[Epoch 32; Iter    57/  183] train: loss: 0.1142167
[Epoch 32; Iter    87/  183] train: loss: 0.1974192
[Epoch 32; Iter   117/  183] train: loss: 0.1329404
[Epoch 32; Iter   147/  183] train: loss: 0.1318762
[Epoch 32; Iter   177/  183] train: loss: 0.1116785
[Epoch 32] ogbg-moltox21: 0.833001 val loss: 0.201428
[Epoch 32] ogbg-moltox21: 0.847966 test loss: 0.193696
[Epoch 33; Iter    24/  183] train: loss: 0.1658510
[Epoch 33; Iter    54/  183] train: loss: 0.2384581
[Epoch 33; Iter    84/  183] train: loss: 0.1573878
[Epoch 15] ogbg-moltox21: 0.798528 test loss: 0.218145
[Epoch 16; Iter    15/  157] train: loss: 0.1706848
[Epoch 16; Iter    45/  157] train: loss: 0.1414450
[Epoch 16; Iter    75/  157] train: loss: 0.2690371
[Epoch 16; Iter   105/  157] train: loss: 0.1796589
[Epoch 16; Iter   135/  157] train: loss: 0.2181544
[Epoch 16] ogbg-moltox21: 0.801063 val loss: 0.200934
[Epoch 16] ogbg-moltox21: 0.818154 test loss: 0.211252
[Epoch 17; Iter     8/  157] train: loss: 0.1786644
[Epoch 17; Iter    38/  157] train: loss: 0.1556478
[Epoch 17; Iter    68/  157] train: loss: 0.2691685
[Epoch 17; Iter    98/  157] train: loss: 0.1801489
[Epoch 17; Iter   128/  157] train: loss: 0.1392289
[Epoch 17] ogbg-moltox21: 0.803132 val loss: 0.197728
[Epoch 17] ogbg-moltox21: 0.818601 test loss: 0.212571
[Epoch 18; Iter     1/  157] train: loss: 0.2127968
[Epoch 18; Iter    31/  157] train: loss: 0.1120367
[Epoch 18; Iter    61/  157] train: loss: 0.2349109
[Epoch 18; Iter    91/  157] train: loss: 0.1548572
[Epoch 18; Iter   121/  157] train: loss: 0.1163825
[Epoch 18; Iter   151/  157] train: loss: 0.1573110
[Epoch 18] ogbg-moltox21: 0.804663 val loss: 0.196505
[Epoch 18] ogbg-moltox21: 0.833267 test loss: 0.204404
[Epoch 19; Iter    24/  157] train: loss: 0.1510482
[Epoch 19; Iter    54/  157] train: loss: 0.1665991
[Epoch 19; Iter    84/  157] train: loss: 0.1668936
[Epoch 19; Iter   114/  157] train: loss: 0.2479828
[Epoch 19; Iter   144/  157] train: loss: 0.2407549
[Epoch 19] ogbg-moltox21: 0.799152 val loss: 0.198267
[Epoch 19] ogbg-moltox21: 0.816237 test loss: 0.216248
[Epoch 20; Iter    17/  157] train: loss: 0.1751105
[Epoch 20; Iter    47/  157] train: loss: 0.1353028
[Epoch 20; Iter    77/  157] train: loss: 0.1708407
[Epoch 20; Iter   107/  157] train: loss: 0.1765689
[Epoch 20; Iter   137/  157] train: loss: 0.1820785
[Epoch 20] ogbg-moltox21: 0.811545 val loss: 0.191793
[Epoch 20] ogbg-moltox21: 0.824839 test loss: 0.205540
[Epoch 21; Iter    10/  157] train: loss: 0.2519784
[Epoch 21; Iter    40/  157] train: loss: 0.1880997
[Epoch 21; Iter    70/  157] train: loss: 0.2183285
[Epoch 21; Iter   100/  157] train: loss: 0.1909698
[Epoch 21; Iter   130/  157] train: loss: 0.1112149
[Epoch 21] ogbg-moltox21: 0.815672 val loss: 0.199221
[Epoch 21] ogbg-moltox21: 0.836039 test loss: 0.224873
[Epoch 22; Iter     3/  157] train: loss: 0.1510709
[Epoch 22; Iter    33/  157] train: loss: 0.2436215
[Epoch 22; Iter    63/  157] train: loss: 0.2391733
[Epoch 22; Iter    93/  157] train: loss: 0.2072308
[Epoch 22; Iter   123/  157] train: loss: 0.2130817
[Epoch 22; Iter   153/  157] train: loss: 0.1237757
[Epoch 22] ogbg-moltox21: 0.827616 val loss: 0.189438
[Epoch 22] ogbg-moltox21: 0.843976 test loss: 0.199028
[Epoch 23; Iter    26/  157] train: loss: 0.2191355
[Epoch 23; Iter    56/  157] train: loss: 0.2179838
[Epoch 23; Iter    86/  157] train: loss: 0.1267898
[Epoch 23; Iter   116/  157] train: loss: 0.3402507
[Epoch 23; Iter   146/  157] train: loss: 0.2196716
[Epoch 23] ogbg-moltox21: 0.815222 val loss: 0.191292
[Epoch 23] ogbg-moltox21: 0.839673 test loss: 0.202007
[Epoch 24; Iter    19/  157] train: loss: 0.2839062
[Epoch 24; Iter    49/  157] train: loss: 0.2174264
[Epoch 24; Iter    79/  157] train: loss: 0.1741134
[Epoch 24; Iter   109/  157] train: loss: 0.1572425
[Epoch 24; Iter   139/  157] train: loss: 0.1707609
[Epoch 24] ogbg-moltox21: 0.806509 val loss: 0.200081
[Epoch 24] ogbg-moltox21: 0.819031 test loss: 0.212177
[Epoch 25; Iter    12/  157] train: loss: 0.1678942
[Epoch 25; Iter    42/  157] train: loss: 0.1232274
[Epoch 25; Iter    72/  157] train: loss: 0.1522316
[Epoch 25; Iter   102/  157] train: loss: 0.1827157
[Epoch 25; Iter   132/  157] train: loss: 0.2215982
[Epoch 25] ogbg-moltox21: 0.812093 val loss: 0.190897
[Epoch 25] ogbg-moltox21: 0.835232 test loss: 0.204476
[Epoch 26; Iter     5/  157] train: loss: 0.1507120
[Epoch 26; Iter    35/  157] train: loss: 0.2416713
[Epoch 26; Iter    65/  157] train: loss: 0.2365088
[Epoch 26; Iter    95/  157] train: loss: 0.1683188
[Epoch 26; Iter   125/  157] train: loss: 0.1274644
[Epoch 26; Iter   155/  157] train: loss: 0.2416488
[Epoch 26] ogbg-moltox21: 0.821139 val loss: 0.187109
[Epoch 26] ogbg-moltox21: 0.841276 test loss: 0.198304
[Epoch 27; Iter    28/  157] train: loss: 0.1272502
[Epoch 27; Iter    58/  157] train: loss: 0.2409579
[Epoch 27; Iter    88/  157] train: loss: 0.1163372
[Epoch 27; Iter   118/  157] train: loss: 0.1489288
[Epoch 27; Iter   148/  157] train: loss: 0.1735480
[Epoch 27] ogbg-moltox21: 0.823477 val loss: 0.188326
[Epoch 27] ogbg-moltox21: 0.845969 test loss: 0.199434
[Epoch 28; Iter    21/  157] train: loss: 0.2607381
[Epoch 28; Iter    51/  157] train: loss: 0.1483104
[Epoch 28; Iter    81/  157] train: loss: 0.0994320
[Epoch 28; Iter   111/  157] train: loss: 0.1594763
[Epoch 28; Iter   141/  157] train: loss: 0.1926790
[Epoch 28] ogbg-moltox21: 0.825333 val loss: 0.187668
[Epoch 28] ogbg-moltox21: 0.839884 test loss: 0.198775
[Epoch 29; Iter    14/  157] train: loss: 0.2037914
[Epoch 29; Iter    44/  157] train: loss: 0.2356413
[Epoch 29; Iter    74/  157] train: loss: 0.1181283
[Epoch 29; Iter   104/  157] train: loss: 0.2036705
[Epoch 29; Iter   134/  157] train: loss: 0.1271133
[Epoch 29] ogbg-moltox21: 0.820554 val loss: 0.201937
[Epoch 29] ogbg-moltox21: 0.840013 test loss: 0.206261
[Epoch 30; Iter     7/  157] train: loss: 0.1288575
[Epoch 30; Iter    37/  157] train: loss: 0.1134834
[Epoch 30; Iter    67/  157] train: loss: 0.2836356
[Epoch 30; Iter    97/  157] train: loss: 0.1432535
[Epoch 30; Iter   127/  157] train: loss: 0.2419950
[Epoch 30; Iter   157/  157] train: loss: 0.2622266
[Epoch 30] ogbg-moltox21: 0.829336 val loss: 0.190411
[Epoch 30] ogbg-moltox21: 0.848459 test loss: 0.223037
[Epoch 31; Iter    30/  157] train: loss: 0.1289236
[Epoch 31; Iter    60/  157] train: loss: 0.1294631
[Epoch 31; Iter    90/  157] train: loss: 0.1699145
[Epoch 31; Iter   120/  157] train: loss: 0.2048968
[Epoch 31; Iter   150/  157] train: loss: 0.1316031
[Epoch 31] ogbg-moltox21: 0.816700 val loss: 0.188747
[Epoch 31] ogbg-moltox21: 0.841839 test loss: 0.203190
[Epoch 32; Iter    23/  157] train: loss: 0.1885244
[Epoch 32; Iter    53/  157] train: loss: 0.2111803
[Epoch 32; Iter    83/  157] train: loss: 0.2029526
[Epoch 32; Iter   113/  157] train: loss: 0.1535866
[Epoch 32; Iter   143/  157] train: loss: 0.1277134
[Epoch 32] ogbg-moltox21: 0.829629 val loss: 0.194123
[Epoch 32] ogbg-moltox21: 0.844793 test loss: 0.201430
[Epoch 33; Iter    16/  157] train: loss: 0.1961447
[Epoch 33; Iter    46/  157] train: loss: 0.1110259
[Epoch 33; Iter    76/  157] train: loss: 0.2149016
[Epoch 33; Iter   106/  157] train: loss: 0.1928405
[Epoch 33; Iter   136/  157] train: loss: 0.1481270
[Epoch 33] ogbg-moltox21: 0.830936 val loss: 0.195359
[Epoch 33] ogbg-moltox21: 0.849857 test loss: 0.198437
[Epoch 34; Iter     9/  157] train: loss: 0.1813475
[Epoch 34; Iter    39/  157] train: loss: 0.1558959
[Epoch 34; Iter    69/  157] train: loss: 0.1338953
[Epoch 34; Iter    99/  157] train: loss: 0.1029636
[Epoch 34; Iter   129/  157] train: loss: 0.1063863
[Epoch 34] ogbg-moltox21: 0.830264 val loss: 0.187870
[Epoch 34] ogbg-moltox21: 0.838892 test loss: 0.207635
[Epoch 35; Iter     2/  157] train: loss: 0.1131075
[Epoch 35; Iter    32/  157] train: loss: 0.2369316
[Epoch 35; Iter    62/  157] train: loss: 0.1492961
[Epoch 35; Iter    92/  157] train: loss: 0.1303949
[Epoch 35; Iter   122/  157] train: loss: 0.1231710
[Epoch 35; Iter   152/  157] train: loss: 0.2053604
[Epoch 35] ogbg-moltox21: 0.839961 val loss: 0.183902
[Epoch 35] ogbg-moltox21: 0.850214 test loss: 0.193593
[Epoch 36; Iter    25/  157] train: loss: 0.2408891
[Epoch 36; Iter    55/  157] train: loss: 0.2297476
[Epoch 36; Iter    85/  157] train: loss: 0.0999954
[Epoch 36; Iter   115/  157] train: loss: 0.1551165
[Epoch 36; Iter   145/  157] train: loss: 0.1164793
[Epoch 36] ogbg-moltox21: 0.827282 val loss: 0.217884
[Epoch 36] ogbg-moltox21: 0.840780 test loss: 0.218663
[Epoch 37; Iter    18/  157] train: loss: 0.1166422
[Epoch 37; Iter    48/  157] train: loss: 0.1213933
[Epoch 15] ogbg-moltox21: 0.822135 test loss: 0.211428
[Epoch 16; Iter    15/  157] train: loss: 0.1743782
[Epoch 16; Iter    45/  157] train: loss: 0.1329030
[Epoch 16; Iter    75/  157] train: loss: 0.1983108
[Epoch 16; Iter   105/  157] train: loss: 0.2020716
[Epoch 16; Iter   135/  157] train: loss: 0.2794475
[Epoch 16] ogbg-moltox21: 0.803133 val loss: 0.198465
[Epoch 16] ogbg-moltox21: 0.819357 test loss: 0.212935
[Epoch 17; Iter     8/  157] train: loss: 0.1111462
[Epoch 17; Iter    38/  157] train: loss: 0.1836759
[Epoch 17; Iter    68/  157] train: loss: 0.3095343
[Epoch 17; Iter    98/  157] train: loss: 0.2992015
[Epoch 17; Iter   128/  157] train: loss: 0.2000449
[Epoch 17] ogbg-moltox21: 0.809837 val loss: 0.192935
[Epoch 17] ogbg-moltox21: 0.830202 test loss: 0.205591
[Epoch 18; Iter     1/  157] train: loss: 0.1122710
[Epoch 18; Iter    31/  157] train: loss: 0.1765751
[Epoch 18; Iter    61/  157] train: loss: 0.2746975
[Epoch 18; Iter    91/  157] train: loss: 0.1827900
[Epoch 18; Iter   121/  157] train: loss: 0.2836618
[Epoch 18; Iter   151/  157] train: loss: 0.1819703
[Epoch 18] ogbg-moltox21: 0.783479 val loss: 0.206859
[Epoch 18] ogbg-moltox21: 0.813356 test loss: 0.216162
[Epoch 19; Iter    24/  157] train: loss: 0.1314552
[Epoch 19; Iter    54/  157] train: loss: 0.1777369
[Epoch 19; Iter    84/  157] train: loss: 0.1575094
[Epoch 19; Iter   114/  157] train: loss: 0.2146819
[Epoch 19; Iter   144/  157] train: loss: 0.1823015
[Epoch 19] ogbg-moltox21: 0.794908 val loss: 0.198938
[Epoch 19] ogbg-moltox21: 0.819828 test loss: 0.214818
[Epoch 20; Iter    17/  157] train: loss: 0.1890028
[Epoch 20; Iter    47/  157] train: loss: 0.1462155
[Epoch 20; Iter    77/  157] train: loss: 0.2832504
[Epoch 20; Iter   107/  157] train: loss: 0.2300898
[Epoch 20; Iter   137/  157] train: loss: 0.1530403
[Epoch 20] ogbg-moltox21: 0.815840 val loss: 0.193247
[Epoch 20] ogbg-moltox21: 0.832652 test loss: 0.207617
[Epoch 21; Iter    10/  157] train: loss: 0.1781971
[Epoch 21; Iter    40/  157] train: loss: 0.3401360
[Epoch 21; Iter    70/  157] train: loss: 0.1870063
[Epoch 21; Iter   100/  157] train: loss: 0.1784015
[Epoch 21; Iter   130/  157] train: loss: 0.1696520
[Epoch 21] ogbg-moltox21: 0.816520 val loss: 0.188658
[Epoch 21] ogbg-moltox21: 0.834946 test loss: 0.203144
[Epoch 22; Iter     3/  157] train: loss: 0.1878358
[Epoch 22; Iter    33/  157] train: loss: 0.2291962
[Epoch 22; Iter    63/  157] train: loss: 0.1471107
[Epoch 22; Iter    93/  157] train: loss: 0.1809306
[Epoch 22; Iter   123/  157] train: loss: 0.1609602
[Epoch 22; Iter   153/  157] train: loss: 0.1580366
[Epoch 22] ogbg-moltox21: 0.810280 val loss: 0.189787
[Epoch 22] ogbg-moltox21: 0.826399 test loss: 0.205279
[Epoch 23; Iter    26/  157] train: loss: 0.1605372
[Epoch 23; Iter    56/  157] train: loss: 0.2269043
[Epoch 23; Iter    86/  157] train: loss: 0.1684908
[Epoch 23; Iter   116/  157] train: loss: 0.2234912
[Epoch 23; Iter   146/  157] train: loss: 0.1245680
[Epoch 23] ogbg-moltox21: 0.802641 val loss: 0.199264
[Epoch 23] ogbg-moltox21: 0.825936 test loss: 0.215950
[Epoch 24; Iter    19/  157] train: loss: 0.1535386
[Epoch 24; Iter    49/  157] train: loss: 0.2422039
[Epoch 24; Iter    79/  157] train: loss: 0.2661439
[Epoch 24; Iter   109/  157] train: loss: 0.1519161
[Epoch 24; Iter   139/  157] train: loss: 0.2290813
[Epoch 24] ogbg-moltox21: 0.832359 val loss: 0.184406
[Epoch 24] ogbg-moltox21: 0.838118 test loss: 0.201820
[Epoch 25; Iter    12/  157] train: loss: 0.2299838
[Epoch 25; Iter    42/  157] train: loss: 0.1788462
[Epoch 25; Iter    72/  157] train: loss: 0.2122458
[Epoch 25; Iter   102/  157] train: loss: 0.1753577
[Epoch 25; Iter   132/  157] train: loss: 0.1961752
[Epoch 25] ogbg-moltox21: 0.814556 val loss: 0.191428
[Epoch 25] ogbg-moltox21: 0.835441 test loss: 0.202057
[Epoch 26; Iter     5/  157] train: loss: 0.2077541
[Epoch 26; Iter    35/  157] train: loss: 0.1606556
[Epoch 26; Iter    65/  157] train: loss: 0.1553896
[Epoch 26; Iter    95/  157] train: loss: 0.3331402
[Epoch 26; Iter   125/  157] train: loss: 0.1563255
[Epoch 26; Iter   155/  157] train: loss: 0.1357892
[Epoch 26] ogbg-moltox21: 0.832592 val loss: 0.184118
[Epoch 26] ogbg-moltox21: 0.833535 test loss: 0.203237
[Epoch 27; Iter    28/  157] train: loss: 0.1056250
[Epoch 27; Iter    58/  157] train: loss: 0.1567929
[Epoch 27; Iter    88/  157] train: loss: 0.1860976
[Epoch 27; Iter   118/  157] train: loss: 0.1568863
[Epoch 27; Iter   148/  157] train: loss: 0.2285515
[Epoch 27] ogbg-moltox21: 0.815808 val loss: 0.195330
[Epoch 27] ogbg-moltox21: 0.832889 test loss: 0.204415
[Epoch 28; Iter    21/  157] train: loss: 0.1220429
[Epoch 28; Iter    51/  157] train: loss: 0.2355792
[Epoch 28; Iter    81/  157] train: loss: 0.2154317
[Epoch 28; Iter   111/  157] train: loss: 0.2139556
[Epoch 28; Iter   141/  157] train: loss: 0.1655754
[Epoch 28] ogbg-moltox21: 0.816745 val loss: 0.222477
[Epoch 28] ogbg-moltox21: 0.840032 test loss: 0.209389
[Epoch 29; Iter    14/  157] train: loss: 0.1271319
[Epoch 29; Iter    44/  157] train: loss: 0.1773555
[Epoch 29; Iter    74/  157] train: loss: 0.1330132
[Epoch 29; Iter   104/  157] train: loss: 0.2063146
[Epoch 29; Iter   134/  157] train: loss: 0.1636659
[Epoch 29] ogbg-moltox21: 0.824816 val loss: 0.195615
[Epoch 29] ogbg-moltox21: 0.842020 test loss: 0.197778
[Epoch 30; Iter     7/  157] train: loss: 0.1914334
[Epoch 30; Iter    37/  157] train: loss: 0.1133000
[Epoch 30; Iter    67/  157] train: loss: 0.1758768
[Epoch 30; Iter    97/  157] train: loss: 0.1849648
[Epoch 30; Iter   127/  157] train: loss: 0.1909769
[Epoch 30; Iter   157/  157] train: loss: 0.1181024
[Epoch 30] ogbg-moltox21: 0.823812 val loss: 0.193578
[Epoch 30] ogbg-moltox21: 0.834956 test loss: 0.202304
[Epoch 31; Iter    30/  157] train: loss: 0.1844689
[Epoch 31; Iter    60/  157] train: loss: 0.1447809
[Epoch 31; Iter    90/  157] train: loss: 0.1360686
[Epoch 31; Iter   120/  157] train: loss: 0.1261951
[Epoch 31; Iter   150/  157] train: loss: 0.2055950
[Epoch 31] ogbg-moltox21: 0.828586 val loss: 0.231005
[Epoch 31] ogbg-moltox21: 0.835945 test loss: 0.208650
[Epoch 32; Iter    23/  157] train: loss: 0.1667864
[Epoch 32; Iter    53/  157] train: loss: 0.1688308
[Epoch 32; Iter    83/  157] train: loss: 0.2034609
[Epoch 32; Iter   113/  157] train: loss: 0.1640988
[Epoch 32; Iter   143/  157] train: loss: 0.2237766
[Epoch 32] ogbg-moltox21: 0.832116 val loss: 0.194370
[Epoch 32] ogbg-moltox21: 0.840441 test loss: 0.201145
[Epoch 33; Iter    16/  157] train: loss: 0.1223712
[Epoch 33; Iter    46/  157] train: loss: 0.0995636
[Epoch 33; Iter    76/  157] train: loss: 0.1262801
[Epoch 33; Iter   106/  157] train: loss: 0.1431329
[Epoch 33; Iter   136/  157] train: loss: 0.1952878
[Epoch 33] ogbg-moltox21: 0.830568 val loss: 0.194660
[Epoch 33] ogbg-moltox21: 0.842159 test loss: 0.203831
[Epoch 34; Iter     9/  157] train: loss: 0.1398254
[Epoch 34; Iter    39/  157] train: loss: 0.1454573
[Epoch 34; Iter    69/  157] train: loss: 0.1777841
[Epoch 34; Iter    99/  157] train: loss: 0.1507141
[Epoch 34; Iter   129/  157] train: loss: 0.1387186
[Epoch 34] ogbg-moltox21: 0.833014 val loss: 0.211813
[Epoch 34] ogbg-moltox21: 0.840688 test loss: 0.207103
[Epoch 35; Iter     2/  157] train: loss: 0.1485350
[Epoch 35; Iter    32/  157] train: loss: 0.2111833
[Epoch 35; Iter    62/  157] train: loss: 0.2687110
[Epoch 35; Iter    92/  157] train: loss: 0.1219647
[Epoch 35; Iter   122/  157] train: loss: 0.1926049
[Epoch 35; Iter   152/  157] train: loss: 0.1838404
[Epoch 35] ogbg-moltox21: 0.828678 val loss: 0.194619
[Epoch 35] ogbg-moltox21: 0.833682 test loss: 0.201285
[Epoch 36; Iter    25/  157] train: loss: 0.2226272
[Epoch 36; Iter    55/  157] train: loss: 0.1687961
[Epoch 36; Iter    85/  157] train: loss: 0.2250473
[Epoch 36; Iter   115/  157] train: loss: 0.1647868
[Epoch 36; Iter   145/  157] train: loss: 0.1390582
[Epoch 36] ogbg-moltox21: 0.827159 val loss: 0.189702
[Epoch 36] ogbg-moltox21: 0.830835 test loss: 0.212242
[Epoch 37; Iter    18/  157] train: loss: 0.1138748
[Epoch 37; Iter    48/  157] train: loss: 0.1756172
[Epoch 15] ogbg-moltox21: 0.803105 test loss: 0.218267
[Epoch 16; Iter    15/  157] train: loss: 0.2418722
[Epoch 16; Iter    45/  157] train: loss: 0.1140714
[Epoch 16; Iter    75/  157] train: loss: 0.2683207
[Epoch 16; Iter   105/  157] train: loss: 0.1844113
[Epoch 16; Iter   135/  157] train: loss: 0.1898654
[Epoch 16] ogbg-moltox21: 0.794375 val loss: 0.202359
[Epoch 16] ogbg-moltox21: 0.812731 test loss: 0.222377
[Epoch 17; Iter     8/  157] train: loss: 0.1982056
[Epoch 17; Iter    38/  157] train: loss: 0.1621924
[Epoch 17; Iter    68/  157] train: loss: 0.2317719
[Epoch 17; Iter    98/  157] train: loss: 0.2801415
[Epoch 17; Iter   128/  157] train: loss: 0.2569348
[Epoch 17] ogbg-moltox21: 0.782303 val loss: 0.258911
[Epoch 17] ogbg-moltox21: 0.802014 test loss: 0.241436
[Epoch 18; Iter     1/  157] train: loss: 0.2403979
[Epoch 18; Iter    31/  157] train: loss: 0.1252825
[Epoch 18; Iter    61/  157] train: loss: 0.1717155
[Epoch 18; Iter    91/  157] train: loss: 0.1238117
[Epoch 18; Iter   121/  157] train: loss: 0.3070259
[Epoch 18; Iter   151/  157] train: loss: 0.1609925
[Epoch 18] ogbg-moltox21: 0.800958 val loss: 0.200216
[Epoch 18] ogbg-moltox21: 0.819620 test loss: 0.216677
[Epoch 19; Iter    24/  157] train: loss: 0.3562623
[Epoch 19; Iter    54/  157] train: loss: 0.1795579
[Epoch 19; Iter    84/  157] train: loss: 0.1535065
[Epoch 19; Iter   114/  157] train: loss: 0.2648870
[Epoch 19; Iter   144/  157] train: loss: 0.1098059
[Epoch 19] ogbg-moltox21: 0.806318 val loss: 0.196182
[Epoch 19] ogbg-moltox21: 0.823912 test loss: 0.214265
[Epoch 20; Iter    17/  157] train: loss: 0.1823459
[Epoch 20; Iter    47/  157] train: loss: 0.2094742
[Epoch 20; Iter    77/  157] train: loss: 0.2566766
[Epoch 20; Iter   107/  157] train: loss: 0.2141239
[Epoch 20; Iter   137/  157] train: loss: 0.1492649
[Epoch 20] ogbg-moltox21: 0.798665 val loss: 0.196773
[Epoch 20] ogbg-moltox21: 0.817624 test loss: 0.225876
[Epoch 21; Iter    10/  157] train: loss: 0.2087038
[Epoch 21; Iter    40/  157] train: loss: 0.2399023
[Epoch 21; Iter    70/  157] train: loss: 0.2117808
[Epoch 21; Iter   100/  157] train: loss: 0.2418464
[Epoch 21; Iter   130/  157] train: loss: 0.2313486
[Epoch 21] ogbg-moltox21: 0.809920 val loss: 0.194027
[Epoch 21] ogbg-moltox21: 0.833680 test loss: 0.226644
[Epoch 22; Iter     3/  157] train: loss: 0.1660956
[Epoch 22; Iter    33/  157] train: loss: 0.1749378
[Epoch 22; Iter    63/  157] train: loss: 0.1571963
[Epoch 22; Iter    93/  157] train: loss: 0.1564126
[Epoch 22; Iter   123/  157] train: loss: 0.1820725
[Epoch 22; Iter   153/  157] train: loss: 0.2003151
[Epoch 22] ogbg-moltox21: 0.809529 val loss: 0.198765
[Epoch 22] ogbg-moltox21: 0.828439 test loss: 0.210967
[Epoch 23; Iter    26/  157] train: loss: 0.1987676
[Epoch 23; Iter    56/  157] train: loss: 0.1681915
[Epoch 23; Iter    86/  157] train: loss: 0.2301206
[Epoch 23; Iter   116/  157] train: loss: 0.1756690
[Epoch 23; Iter   146/  157] train: loss: 0.1726168
[Epoch 23] ogbg-moltox21: 0.812540 val loss: 0.192668
[Epoch 23] ogbg-moltox21: 0.821374 test loss: 0.214466
[Epoch 24; Iter    19/  157] train: loss: 0.2643404
[Epoch 24; Iter    49/  157] train: loss: 0.2452509
[Epoch 24; Iter    79/  157] train: loss: 0.1865766
[Epoch 24; Iter   109/  157] train: loss: 0.1360358
[Epoch 24; Iter   139/  157] train: loss: 0.2389383
[Epoch 24] ogbg-moltox21: 0.818509 val loss: 0.190816
[Epoch 24] ogbg-moltox21: 0.824497 test loss: 0.213285
[Epoch 25; Iter    12/  157] train: loss: 0.1323307
[Epoch 25; Iter    42/  157] train: loss: 0.2296418
[Epoch 25; Iter    72/  157] train: loss: 0.1992850
[Epoch 25; Iter   102/  157] train: loss: 0.1550041
[Epoch 25; Iter   132/  157] train: loss: 0.3271044
[Epoch 25] ogbg-moltox21: 0.814604 val loss: 0.207083
[Epoch 25] ogbg-moltox21: 0.829269 test loss: 0.210846
[Epoch 26; Iter     5/  157] train: loss: 0.1470298
[Epoch 26; Iter    35/  157] train: loss: 0.2057504
[Epoch 26; Iter    65/  157] train: loss: 0.1822372
[Epoch 26; Iter    95/  157] train: loss: 0.1612481
[Epoch 26; Iter   125/  157] train: loss: 0.1752648
[Epoch 26; Iter   155/  157] train: loss: 0.1331371
[Epoch 26] ogbg-moltox21: 0.805901 val loss: 0.207599
[Epoch 26] ogbg-moltox21: 0.813726 test loss: 0.228807
[Epoch 27; Iter    28/  157] train: loss: 0.2372105
[Epoch 27; Iter    58/  157] train: loss: 0.1771824
[Epoch 27; Iter    88/  157] train: loss: 0.1651569
[Epoch 27; Iter   118/  157] train: loss: 0.1270050
[Epoch 27; Iter   148/  157] train: loss: 0.1829433
[Epoch 27] ogbg-moltox21: 0.821506 val loss: 0.192784
[Epoch 27] ogbg-moltox21: 0.835308 test loss: 0.211848
[Epoch 28; Iter    21/  157] train: loss: 0.1518807
[Epoch 28; Iter    51/  157] train: loss: 0.1822643
[Epoch 28; Iter    81/  157] train: loss: 0.1533949
[Epoch 28; Iter   111/  157] train: loss: 0.2855672
[Epoch 28; Iter   141/  157] train: loss: 0.1798008
[Epoch 28] ogbg-moltox21: 0.770934 val loss: 0.207359
[Epoch 28] ogbg-moltox21: 0.771338 test loss: 0.226465
[Epoch 29; Iter    14/  157] train: loss: 0.1544360
[Epoch 29; Iter    44/  157] train: loss: 0.1861536
[Epoch 29; Iter    74/  157] train: loss: 0.1644346
[Epoch 29; Iter   104/  157] train: loss: 0.2826264
[Epoch 29; Iter   134/  157] train: loss: 0.1498967
[Epoch 29] ogbg-moltox21: 0.804533 val loss: 0.200054
[Epoch 29] ogbg-moltox21: 0.807861 test loss: 0.218524
[Epoch 30; Iter     7/  157] train: loss: 0.2361928
[Epoch 30; Iter    37/  157] train: loss: 0.2182940
[Epoch 30; Iter    67/  157] train: loss: 0.1968315
[Epoch 30; Iter    97/  157] train: loss: 0.3017248
[Epoch 30; Iter   127/  157] train: loss: 0.1617953
[Epoch 30; Iter   157/  157] train: loss: 0.2383877
[Epoch 30] ogbg-moltox21: 0.799655 val loss: 0.215414
[Epoch 30] ogbg-moltox21: 0.810332 test loss: 0.214664
[Epoch 31; Iter    30/  157] train: loss: 0.1875978
[Epoch 31; Iter    60/  157] train: loss: 0.1742200
[Epoch 31; Iter    90/  157] train: loss: 0.1758184
[Epoch 31; Iter   120/  157] train: loss: 0.1458479
[Epoch 31; Iter   150/  157] train: loss: 0.1496833
[Epoch 31] ogbg-moltox21: 0.822350 val loss: 0.376155
[Epoch 31] ogbg-moltox21: 0.828301 test loss: 0.304355
[Epoch 32; Iter    23/  157] train: loss: 0.1373131
[Epoch 32; Iter    53/  157] train: loss: 0.1870686
[Epoch 32; Iter    83/  157] train: loss: 0.1614627
[Epoch 32; Iter   113/  157] train: loss: 0.1546229
[Epoch 32; Iter   143/  157] train: loss: 0.1739141
[Epoch 32] ogbg-moltox21: 0.831038 val loss: 0.187022
[Epoch 32] ogbg-moltox21: 0.844642 test loss: 0.203074
[Epoch 33; Iter    16/  157] train: loss: 0.1469359
[Epoch 33; Iter    46/  157] train: loss: 0.1303624
[Epoch 33; Iter    76/  157] train: loss: 0.1501999
[Epoch 33; Iter   106/  157] train: loss: 0.2385683
[Epoch 33; Iter   136/  157] train: loss: 0.2244510
[Epoch 33] ogbg-moltox21: 0.828742 val loss: 0.208326
[Epoch 33] ogbg-moltox21: 0.837287 test loss: 0.211359
[Epoch 34; Iter     9/  157] train: loss: 0.2110773
[Epoch 34; Iter    39/  157] train: loss: 0.2276174
[Epoch 34; Iter    69/  157] train: loss: 0.1628828
[Epoch 34; Iter    99/  157] train: loss: 0.2122244
[Epoch 34; Iter   129/  157] train: loss: 0.2120578
[Epoch 34] ogbg-moltox21: 0.830801 val loss: 0.194017
[Epoch 34] ogbg-moltox21: 0.842871 test loss: 0.200414
[Epoch 35; Iter     2/  157] train: loss: 0.1117758
[Epoch 35; Iter    32/  157] train: loss: 0.1281819
[Epoch 35; Iter    62/  157] train: loss: 0.2092147
[Epoch 35; Iter    92/  157] train: loss: 0.0952167
[Epoch 35; Iter   122/  157] train: loss: 0.1438421
[Epoch 35; Iter   152/  157] train: loss: 0.2570361
[Epoch 35] ogbg-moltox21: 0.806435 val loss: 0.371320
[Epoch 35] ogbg-moltox21: 0.806945 test loss: 0.366305
[Epoch 36; Iter    25/  157] train: loss: 0.2671922
[Epoch 36; Iter    55/  157] train: loss: 0.2050584
[Epoch 36; Iter    85/  157] train: loss: 0.2185154
[Epoch 36; Iter   115/  157] train: loss: 0.1673483
[Epoch 36; Iter   145/  157] train: loss: 0.1089153
[Epoch 36] ogbg-moltox21: 0.813799 val loss: 0.340684
[Epoch 36] ogbg-moltox21: 0.821957 test loss: 0.600930
[Epoch 37; Iter    18/  157] train: loss: 0.2146308
[Epoch 37; Iter    48/  157] train: loss: 0.2877946
[Epoch 30; Iter    89/  209] train: loss: 0.1322972
[Epoch 30; Iter   119/  209] train: loss: 0.2982522
[Epoch 30; Iter   149/  209] train: loss: 0.2332709
[Epoch 30; Iter   179/  209] train: loss: 0.1469456
[Epoch 30; Iter   209/  209] train: loss: 0.1603619
[Epoch 30] ogbg-moltox21: 0.860855 val loss: 0.207584
[Epoch 30] ogbg-moltox21: 0.857858 test loss: 0.189094
[Epoch 31; Iter    30/  209] train: loss: 0.1071582
[Epoch 31; Iter    60/  209] train: loss: 0.1098979
[Epoch 31; Iter    90/  209] train: loss: 0.1880037
[Epoch 31; Iter   120/  209] train: loss: 0.1079299
[Epoch 31; Iter   150/  209] train: loss: 0.2223678
[Epoch 31; Iter   180/  209] train: loss: 0.2101049
[Epoch 31] ogbg-moltox21: 0.862310 val loss: 0.198469
[Epoch 31] ogbg-moltox21: 0.846782 test loss: 0.213065
[Epoch 32; Iter     1/  209] train: loss: 0.1609206
[Epoch 32; Iter    31/  209] train: loss: 0.1134897
[Epoch 32; Iter    61/  209] train: loss: 0.2543573
[Epoch 32; Iter    91/  209] train: loss: 0.2136854
[Epoch 32; Iter   121/  209] train: loss: 0.1961733
[Epoch 32; Iter   151/  209] train: loss: 0.1655700
[Epoch 32; Iter   181/  209] train: loss: 0.1818708
[Epoch 32] ogbg-moltox21: 0.859323 val loss: 0.206338
[Epoch 32] ogbg-moltox21: 0.827441 test loss: 0.206276
[Epoch 33; Iter     2/  209] train: loss: 0.2064326
[Epoch 33; Iter    32/  209] train: loss: 0.1194370
[Epoch 33; Iter    62/  209] train: loss: 0.1409702
[Epoch 33; Iter    92/  209] train: loss: 0.1255264
[Epoch 33; Iter   122/  209] train: loss: 0.1308157
[Epoch 33; Iter   152/  209] train: loss: 0.1683937
[Epoch 33; Iter   182/  209] train: loss: 0.1410417
[Epoch 33] ogbg-moltox21: 0.861410 val loss: 0.199037
[Epoch 33] ogbg-moltox21: 0.843994 test loss: 0.196140
[Epoch 34; Iter     3/  209] train: loss: 0.1538699
[Epoch 34; Iter    33/  209] train: loss: 0.2094774
[Epoch 34; Iter    63/  209] train: loss: 0.1771509
[Epoch 34; Iter    93/  209] train: loss: 0.1294086
[Epoch 34; Iter   123/  209] train: loss: 0.1635388
[Epoch 34; Iter   153/  209] train: loss: 0.1288358
[Epoch 34; Iter   183/  209] train: loss: 0.1002405
[Epoch 34] ogbg-moltox21: 0.854096 val loss: 0.203081
[Epoch 34] ogbg-moltox21: 0.840367 test loss: 0.199845
[Epoch 35; Iter     4/  209] train: loss: 0.1681459
[Epoch 35; Iter    34/  209] train: loss: 0.1482060
[Epoch 35; Iter    64/  209] train: loss: 0.1081130
[Epoch 35; Iter    94/  209] train: loss: 0.2918902
[Epoch 35; Iter   124/  209] train: loss: 0.1766305
[Epoch 35; Iter   154/  209] train: loss: 0.1607044
[Epoch 35; Iter   184/  209] train: loss: 0.2001095
[Epoch 35] ogbg-moltox21: 0.868133 val loss: 0.197507
[Epoch 35] ogbg-moltox21: 0.848369 test loss: 0.286858
[Epoch 36; Iter     5/  209] train: loss: 0.1814348
[Epoch 36; Iter    35/  209] train: loss: 0.2518982
[Epoch 36; Iter    65/  209] train: loss: 0.1819592
[Epoch 36; Iter    95/  209] train: loss: 0.1109441
[Epoch 36; Iter   125/  209] train: loss: 0.1813734
[Epoch 36; Iter   155/  209] train: loss: 0.1932977
[Epoch 36; Iter   185/  209] train: loss: 0.2703369
[Epoch 36] ogbg-moltox21: 0.854462 val loss: 0.199390
[Epoch 36] ogbg-moltox21: 0.836728 test loss: 0.195905
[Epoch 37; Iter     6/  209] train: loss: 0.1401811
[Epoch 37; Iter    36/  209] train: loss: 0.1382257
[Epoch 37; Iter    66/  209] train: loss: 0.1252360
[Epoch 37; Iter    96/  209] train: loss: 0.1213262
[Epoch 37; Iter   126/  209] train: loss: 0.1151490
[Epoch 37; Iter   156/  209] train: loss: 0.1071562
[Epoch 37; Iter   186/  209] train: loss: 0.1561770
[Epoch 37] ogbg-moltox21: 0.866300 val loss: 0.196644
[Epoch 37] ogbg-moltox21: 0.858366 test loss: 0.186724
[Epoch 38; Iter     7/  209] train: loss: 0.1419912
[Epoch 38; Iter    37/  209] train: loss: 0.1869113
[Epoch 38; Iter    67/  209] train: loss: 0.0926521
[Epoch 38; Iter    97/  209] train: loss: 0.1455660
[Epoch 38; Iter   127/  209] train: loss: 0.2134563
[Epoch 38; Iter   157/  209] train: loss: 0.1030663
[Epoch 38; Iter   187/  209] train: loss: 0.0939121
[Epoch 38] ogbg-moltox21: 0.867562 val loss: 0.193073
[Epoch 38] ogbg-moltox21: 0.861383 test loss: 0.182558
[Epoch 39; Iter     8/  209] train: loss: 0.1375192
[Epoch 39; Iter    38/  209] train: loss: 0.1548922
[Epoch 39; Iter    68/  209] train: loss: 0.1566732
[Epoch 39; Iter    98/  209] train: loss: 0.1668527
[Epoch 39; Iter   128/  209] train: loss: 0.1110532
[Epoch 39; Iter   158/  209] train: loss: 0.1614019
[Epoch 39; Iter   188/  209] train: loss: 0.1191199
[Epoch 39] ogbg-moltox21: 0.863876 val loss: 0.198317
[Epoch 39] ogbg-moltox21: 0.862948 test loss: 0.187520
[Epoch 40; Iter     9/  209] train: loss: 0.1559598
[Epoch 40; Iter    39/  209] train: loss: 0.0965891
[Epoch 40; Iter    69/  209] train: loss: 0.1098739
[Epoch 40; Iter    99/  209] train: loss: 0.1375582
[Epoch 40; Iter   129/  209] train: loss: 0.1441448
[Epoch 40; Iter   159/  209] train: loss: 0.2314695
[Epoch 40; Iter   189/  209] train: loss: 0.2117576
[Epoch 40] ogbg-moltox21: 0.861177 val loss: 0.198804
[Epoch 40] ogbg-moltox21: 0.851732 test loss: 0.186544
[Epoch 41; Iter    10/  209] train: loss: 0.1319583
[Epoch 41; Iter    40/  209] train: loss: 0.1541114
[Epoch 41; Iter    70/  209] train: loss: 0.1518798
[Epoch 41; Iter   100/  209] train: loss: 0.1103630
[Epoch 41; Iter   130/  209] train: loss: 0.1487279
[Epoch 41; Iter   160/  209] train: loss: 0.2148924
[Epoch 41; Iter   190/  209] train: loss: 0.1158643
[Epoch 41] ogbg-moltox21: 0.858608 val loss: 0.211989
[Epoch 41] ogbg-moltox21: 0.844908 test loss: 0.201618
[Epoch 42; Iter    11/  209] train: loss: 0.1815151
[Epoch 42; Iter    41/  209] train: loss: 0.2194168
[Epoch 42; Iter    71/  209] train: loss: 0.1434054
[Epoch 42; Iter   101/  209] train: loss: 0.1459520
[Epoch 42; Iter   131/  209] train: loss: 0.1486799
[Epoch 42; Iter   161/  209] train: loss: 0.1990698
[Epoch 42; Iter   191/  209] train: loss: 0.1677833
[Epoch 42] ogbg-moltox21: 0.859240 val loss: 0.206430
[Epoch 42] ogbg-moltox21: 0.843792 test loss: 0.189838
[Epoch 43; Iter    12/  209] train: loss: 0.1094234
[Epoch 43; Iter    42/  209] train: loss: 0.1236882
[Epoch 43; Iter    72/  209] train: loss: 0.1516346
[Epoch 43; Iter   102/  209] train: loss: 0.1784841
[Epoch 43; Iter   132/  209] train: loss: 0.1077863
[Epoch 43; Iter   162/  209] train: loss: 0.1899270
[Epoch 43; Iter   192/  209] train: loss: 0.1349238
[Epoch 43] ogbg-moltox21: 0.847249 val loss: 0.209237
[Epoch 43] ogbg-moltox21: 0.850489 test loss: 0.191638
[Epoch 44; Iter    13/  209] train: loss: 0.1564771
[Epoch 44; Iter    43/  209] train: loss: 0.1227988
[Epoch 44; Iter    73/  209] train: loss: 0.1342072
[Epoch 44; Iter   103/  209] train: loss: 0.1112090
[Epoch 44; Iter   133/  209] train: loss: 0.1034616
[Epoch 44; Iter   163/  209] train: loss: 0.1557907
[Epoch 44; Iter   193/  209] train: loss: 0.1114511
[Epoch 44] ogbg-moltox21: 0.856295 val loss: 0.210700
[Epoch 44] ogbg-moltox21: 0.853572 test loss: 0.188592
[Epoch 45; Iter    14/  209] train: loss: 0.1517106
[Epoch 45; Iter    44/  209] train: loss: 0.1427289
[Epoch 45; Iter    74/  209] train: loss: 0.0911339
[Epoch 45; Iter   104/  209] train: loss: 0.0990452
[Epoch 45; Iter   134/  209] train: loss: 0.1080927
[Epoch 45; Iter   164/  209] train: loss: 0.0964485
[Epoch 45; Iter   194/  209] train: loss: 0.1322598
[Epoch 45] ogbg-moltox21: 0.862566 val loss: 0.204123
[Epoch 45] ogbg-moltox21: 0.857580 test loss: 0.188488
[Epoch 46; Iter    15/  209] train: loss: 0.1656709
[Epoch 46; Iter    45/  209] train: loss: 0.1109830
[Epoch 46; Iter    75/  209] train: loss: 0.1321914
[Epoch 46; Iter   105/  209] train: loss: 0.1041932
[Epoch 46; Iter   135/  209] train: loss: 0.1571479
[Epoch 46; Iter   165/  209] train: loss: 0.1944464
[Epoch 46; Iter   195/  209] train: loss: 0.1130127
[Epoch 46] ogbg-moltox21: 0.853890 val loss: 0.208099
[Epoch 46] ogbg-moltox21: 0.856146 test loss: 0.193890
[Epoch 47; Iter    16/  209] train: loss: 0.1298172
[Epoch 47; Iter    46/  209] train: loss: 0.1275049
[Epoch 47; Iter    76/  209] train: loss: 0.1079872
[Epoch 47; Iter   106/  209] train: loss: 0.1047422
[Epoch 47; Iter   136/  209] train: loss: 0.1582093
[Epoch 30; Iter    89/  209] train: loss: 0.1937283
[Epoch 30; Iter   119/  209] train: loss: 0.0988065
[Epoch 30; Iter   149/  209] train: loss: 0.1639689
[Epoch 30; Iter   179/  209] train: loss: 0.1321006
[Epoch 30; Iter   209/  209] train: loss: 0.2991691
[Epoch 30] ogbg-moltox21: 0.861517 val loss: 0.207109
[Epoch 30] ogbg-moltox21: 0.838235 test loss: 0.194033
[Epoch 31; Iter    30/  209] train: loss: 0.1317073
[Epoch 31; Iter    60/  209] train: loss: 0.1118058
[Epoch 31; Iter    90/  209] train: loss: 0.1666637
[Epoch 31; Iter   120/  209] train: loss: 0.2069013
[Epoch 31; Iter   150/  209] train: loss: 0.1551151
[Epoch 31; Iter   180/  209] train: loss: 0.2408388
[Epoch 31] ogbg-moltox21: 0.863166 val loss: 0.197341
[Epoch 31] ogbg-moltox21: 0.842334 test loss: 0.192497
[Epoch 32; Iter     1/  209] train: loss: 0.1320073
[Epoch 32; Iter    31/  209] train: loss: 0.1145941
[Epoch 32; Iter    61/  209] train: loss: 0.1256737
[Epoch 32; Iter    91/  209] train: loss: 0.1133178
[Epoch 32; Iter   121/  209] train: loss: 0.1231214
[Epoch 32; Iter   151/  209] train: loss: 0.1236117
[Epoch 32; Iter   181/  209] train: loss: 0.1360492
[Epoch 32] ogbg-moltox21: 0.849010 val loss: 0.378980
[Epoch 32] ogbg-moltox21: 0.834870 test loss: 0.190250
[Epoch 33; Iter     2/  209] train: loss: 0.1013755
[Epoch 33; Iter    32/  209] train: loss: 0.1905430
[Epoch 33; Iter    62/  209] train: loss: 0.1633490
[Epoch 33; Iter    92/  209] train: loss: 0.1537663
[Epoch 33; Iter   122/  209] train: loss: 0.2096291
[Epoch 33; Iter   152/  209] train: loss: 0.2449120
[Epoch 33; Iter   182/  209] train: loss: 0.3104440
[Epoch 33] ogbg-moltox21: 0.853976 val loss: 0.201321
[Epoch 33] ogbg-moltox21: 0.835614 test loss: 0.197058
[Epoch 34; Iter     3/  209] train: loss: 0.1586812
[Epoch 34; Iter    33/  209] train: loss: 0.2293360
[Epoch 34; Iter    63/  209] train: loss: 0.1166570
[Epoch 34; Iter    93/  209] train: loss: 0.1337941
[Epoch 34; Iter   123/  209] train: loss: 0.1393940
[Epoch 34; Iter   153/  209] train: loss: 0.1631377
[Epoch 34; Iter   183/  209] train: loss: 0.1369985
[Epoch 34] ogbg-moltox21: 0.854168 val loss: 0.204984
[Epoch 34] ogbg-moltox21: 0.841597 test loss: 0.189381
[Epoch 35; Iter     4/  209] train: loss: 0.1983594
[Epoch 35; Iter    34/  209] train: loss: 0.2357976
[Epoch 35; Iter    64/  209] train: loss: 0.1593456
[Epoch 35; Iter    94/  209] train: loss: 0.1544017
[Epoch 35; Iter   124/  209] train: loss: 0.2013908
[Epoch 35; Iter   154/  209] train: loss: 0.1439268
[Epoch 35; Iter   184/  209] train: loss: 0.1526846
[Epoch 35] ogbg-moltox21: 0.858411 val loss: 0.205400
[Epoch 35] ogbg-moltox21: 0.851185 test loss: 0.189779
[Epoch 36; Iter     5/  209] train: loss: 0.1965515
[Epoch 36; Iter    35/  209] train: loss: 0.1290744
[Epoch 36; Iter    65/  209] train: loss: 0.1390911
[Epoch 36; Iter    95/  209] train: loss: 0.1642624
[Epoch 36; Iter   125/  209] train: loss: 0.1845388
[Epoch 36; Iter   155/  209] train: loss: 0.2478837
[Epoch 36; Iter   185/  209] train: loss: 0.1515783
[Epoch 36] ogbg-moltox21: 0.864501 val loss: 0.195818
[Epoch 36] ogbg-moltox21: 0.849188 test loss: 0.187348
[Epoch 37; Iter     6/  209] train: loss: 0.1193495
[Epoch 37; Iter    36/  209] train: loss: 0.1436821
[Epoch 37; Iter    66/  209] train: loss: 0.1766337
[Epoch 37; Iter    96/  209] train: loss: 0.1454901
[Epoch 37; Iter   126/  209] train: loss: 0.1401012
[Epoch 37; Iter   156/  209] train: loss: 0.2337614
[Epoch 37; Iter   186/  209] train: loss: 0.1255948
[Epoch 37] ogbg-moltox21: 0.854840 val loss: 0.198888
[Epoch 37] ogbg-moltox21: 0.849731 test loss: 0.187750
[Epoch 38; Iter     7/  209] train: loss: 0.2057576
[Epoch 38; Iter    37/  209] train: loss: 0.1544953
[Epoch 38; Iter    67/  209] train: loss: 0.1700488
[Epoch 38; Iter    97/  209] train: loss: 0.1180623
[Epoch 38; Iter   127/  209] train: loss: 0.1025491
[Epoch 38; Iter   157/  209] train: loss: 0.1034281
[Epoch 38; Iter   187/  209] train: loss: 0.1057298
[Epoch 38] ogbg-moltox21: 0.864623 val loss: 0.194880
[Epoch 38] ogbg-moltox21: 0.853590 test loss: 0.188658
[Epoch 39; Iter     8/  209] train: loss: 0.2423503
[Epoch 39; Iter    38/  209] train: loss: 0.0934922
[Epoch 39; Iter    68/  209] train: loss: 0.1635269
[Epoch 39; Iter    98/  209] train: loss: 0.1171230
[Epoch 39; Iter   128/  209] train: loss: 0.1668601
[Epoch 39; Iter   158/  209] train: loss: 0.2440315
[Epoch 39; Iter   188/  209] train: loss: 0.1456113
[Epoch 39] ogbg-moltox21: 0.849130 val loss: 0.198822
[Epoch 39] ogbg-moltox21: 0.838912 test loss: 0.194173
[Epoch 40; Iter     9/  209] train: loss: 0.1114436
[Epoch 40; Iter    39/  209] train: loss: 0.1153469
[Epoch 40; Iter    69/  209] train: loss: 0.1784824
[Epoch 40; Iter    99/  209] train: loss: 0.1044623
[Epoch 40; Iter   129/  209] train: loss: 0.1401991
[Epoch 40; Iter   159/  209] train: loss: 0.0935299
[Epoch 40; Iter   189/  209] train: loss: 0.1589195
[Epoch 40] ogbg-moltox21: 0.853174 val loss: 0.216252
[Epoch 40] ogbg-moltox21: 0.839459 test loss: 0.199378
[Epoch 41; Iter    10/  209] train: loss: 0.1658621
[Epoch 41; Iter    40/  209] train: loss: 0.1432492
[Epoch 41; Iter    70/  209] train: loss: 0.1380265
[Epoch 41; Iter   100/  209] train: loss: 0.1343004
[Epoch 41; Iter   130/  209] train: loss: 0.1291261
[Epoch 41; Iter   160/  209] train: loss: 0.1447053
[Epoch 41; Iter   190/  209] train: loss: 0.1100741
[Epoch 41] ogbg-moltox21: 0.858019 val loss: 0.205582
[Epoch 41] ogbg-moltox21: 0.851691 test loss: 0.189932
[Epoch 42; Iter    11/  209] train: loss: 0.1686026
[Epoch 42; Iter    41/  209] train: loss: 0.1033651
[Epoch 42; Iter    71/  209] train: loss: 0.1551726
[Epoch 42; Iter   101/  209] train: loss: 0.1163518
[Epoch 42; Iter   131/  209] train: loss: 0.1391486
[Epoch 42; Iter   161/  209] train: loss: 0.1677188
[Epoch 42; Iter   191/  209] train: loss: 0.1314193
[Epoch 42] ogbg-moltox21: 0.846669 val loss: 0.210899
[Epoch 42] ogbg-moltox21: 0.835227 test loss: 0.198069
[Epoch 43; Iter    12/  209] train: loss: 0.1297801
[Epoch 43; Iter    42/  209] train: loss: 0.1668484
[Epoch 43; Iter    72/  209] train: loss: 0.1359965
[Epoch 43; Iter   102/  209] train: loss: 0.1244715
[Epoch 43; Iter   132/  209] train: loss: 0.1399226
[Epoch 43; Iter   162/  209] train: loss: 0.1509914
[Epoch 43; Iter   192/  209] train: loss: 0.1658424
[Epoch 43] ogbg-moltox21: 0.857209 val loss: 0.205902
[Epoch 43] ogbg-moltox21: 0.847531 test loss: 0.194952
[Epoch 44; Iter    13/  209] train: loss: 0.1276171
[Epoch 44; Iter    43/  209] train: loss: 0.1333232
[Epoch 44; Iter    73/  209] train: loss: 0.1178379
[Epoch 44; Iter   103/  209] train: loss: 0.1290137
[Epoch 44; Iter   133/  209] train: loss: 0.1720423
[Epoch 44; Iter   163/  209] train: loss: 0.1090081
[Epoch 44; Iter   193/  209] train: loss: 0.2003872
[Epoch 44] ogbg-moltox21: 0.852093 val loss: 0.218185
[Epoch 44] ogbg-moltox21: 0.841671 test loss: 0.206062
[Epoch 45; Iter    14/  209] train: loss: 0.0973850
[Epoch 45; Iter    44/  209] train: loss: 0.1256756
[Epoch 45; Iter    74/  209] train: loss: 0.1459130
[Epoch 45; Iter   104/  209] train: loss: 0.1188283
[Epoch 45; Iter   134/  209] train: loss: 0.1738122
[Epoch 45; Iter   164/  209] train: loss: 0.1202184
[Epoch 45; Iter   194/  209] train: loss: 0.2196762
[Epoch 45] ogbg-moltox21: 0.851145 val loss: 0.208178
[Epoch 45] ogbg-moltox21: 0.832974 test loss: 0.214725
[Epoch 46; Iter    15/  209] train: loss: 0.1948929
[Epoch 46; Iter    45/  209] train: loss: 0.0804549
[Epoch 46; Iter    75/  209] train: loss: 0.1111003
[Epoch 46; Iter   105/  209] train: loss: 0.1410979
[Epoch 46; Iter   135/  209] train: loss: 0.0950560
[Epoch 46; Iter   165/  209] train: loss: 0.1308045
[Epoch 46; Iter   195/  209] train: loss: 0.0906296
[Epoch 46] ogbg-moltox21: 0.849270 val loss: 0.209415
[Epoch 46] ogbg-moltox21: 0.841758 test loss: 0.200571
[Epoch 47; Iter    16/  209] train: loss: 0.1297253
[Epoch 47; Iter    46/  209] train: loss: 0.1106116
[Epoch 47; Iter    76/  209] train: loss: 0.1330950
[Epoch 47; Iter   106/  209] train: loss: 0.1631262
[Epoch 47; Iter   136/  209] train: loss: 0.1470733
[Epoch 30; Iter    89/  209] train: loss: 0.1489460
[Epoch 30; Iter   119/  209] train: loss: 0.1769387
[Epoch 30; Iter   149/  209] train: loss: 0.1182091
[Epoch 30; Iter   179/  209] train: loss: 0.1967313
[Epoch 30; Iter   209/  209] train: loss: 0.1289885
[Epoch 30] ogbg-moltox21: 0.852218 val loss: 0.194934
[Epoch 30] ogbg-moltox21: 0.823385 test loss: 0.198252
[Epoch 31; Iter    30/  209] train: loss: 0.1571588
[Epoch 31; Iter    60/  209] train: loss: 0.2224904
[Epoch 31; Iter    90/  209] train: loss: 0.1183958
[Epoch 31; Iter   120/  209] train: loss: 0.1396747
[Epoch 31; Iter   150/  209] train: loss: 0.1057712
[Epoch 31; Iter   180/  209] train: loss: 0.2030000
[Epoch 31] ogbg-moltox21: 0.852241 val loss: 0.204682
[Epoch 31] ogbg-moltox21: 0.831074 test loss: 0.199232
[Epoch 32; Iter     1/  209] train: loss: 0.1152092
[Epoch 32; Iter    31/  209] train: loss: 0.1595899
[Epoch 32; Iter    61/  209] train: loss: 0.1593020
[Epoch 32; Iter    91/  209] train: loss: 0.1885655
[Epoch 32; Iter   121/  209] train: loss: 0.1326094
[Epoch 32; Iter   151/  209] train: loss: 0.1726655
[Epoch 32; Iter   181/  209] train: loss: 0.1165905
[Epoch 32] ogbg-moltox21: 0.862684 val loss: 0.196374
[Epoch 32] ogbg-moltox21: 0.838412 test loss: 0.192390
[Epoch 33; Iter     2/  209] train: loss: 0.1707251
[Epoch 33; Iter    32/  209] train: loss: 0.1126987
[Epoch 33; Iter    62/  209] train: loss: 0.1791921
[Epoch 33; Iter    92/  209] train: loss: 0.1348373
[Epoch 33; Iter   122/  209] train: loss: 0.2198012
[Epoch 33; Iter   152/  209] train: loss: 0.1453950
[Epoch 33; Iter   182/  209] train: loss: 0.1486217
[Epoch 33] ogbg-moltox21: 0.857223 val loss: 0.202443
[Epoch 33] ogbg-moltox21: 0.839008 test loss: 0.195284
[Epoch 34; Iter     3/  209] train: loss: 0.1302817
[Epoch 34; Iter    33/  209] train: loss: 0.1649039
[Epoch 34; Iter    63/  209] train: loss: 0.1673781
[Epoch 34; Iter    93/  209] train: loss: 0.1643049
[Epoch 34; Iter   123/  209] train: loss: 0.1701054
[Epoch 34; Iter   153/  209] train: loss: 0.1972508
[Epoch 34; Iter   183/  209] train: loss: 0.1841021
[Epoch 34] ogbg-moltox21: 0.864808 val loss: 0.197249
[Epoch 34] ogbg-moltox21: 0.847670 test loss: 0.189371
[Epoch 35; Iter     4/  209] train: loss: 0.1400489
[Epoch 35; Iter    34/  209] train: loss: 0.2274188
[Epoch 35; Iter    64/  209] train: loss: 0.2150974
[Epoch 35; Iter    94/  209] train: loss: 0.1493565
[Epoch 35; Iter   124/  209] train: loss: 0.0940938
[Epoch 35; Iter   154/  209] train: loss: 0.1822035
[Epoch 35; Iter   184/  209] train: loss: 0.1475859
[Epoch 35] ogbg-moltox21: 0.870752 val loss: 0.198996
[Epoch 35] ogbg-moltox21: 0.851834 test loss: 0.196558
[Epoch 36; Iter     5/  209] train: loss: 0.1175870
[Epoch 36; Iter    35/  209] train: loss: 0.1088252
[Epoch 36; Iter    65/  209] train: loss: 0.1187698
[Epoch 36; Iter    95/  209] train: loss: 0.1151878
[Epoch 36; Iter   125/  209] train: loss: 0.1448036
[Epoch 36; Iter   155/  209] train: loss: 0.1034537
[Epoch 36; Iter   185/  209] train: loss: 0.1433572
[Epoch 36] ogbg-moltox21: 0.868636 val loss: 0.195719
[Epoch 36] ogbg-moltox21: 0.843757 test loss: 0.192592
[Epoch 37; Iter     6/  209] train: loss: 0.2019971
[Epoch 37; Iter    36/  209] train: loss: 0.1504123
[Epoch 37; Iter    66/  209] train: loss: 0.1445920
[Epoch 37; Iter    96/  209] train: loss: 0.1407227
[Epoch 37; Iter   126/  209] train: loss: 0.1178050
[Epoch 37; Iter   156/  209] train: loss: 0.1651653
[Epoch 37; Iter   186/  209] train: loss: 0.1255921
[Epoch 37] ogbg-moltox21: 0.867412 val loss: 0.199818
[Epoch 37] ogbg-moltox21: 0.852901 test loss: 0.186745
[Epoch 38; Iter     7/  209] train: loss: 0.1372648
[Epoch 38; Iter    37/  209] train: loss: 0.1060281
[Epoch 38; Iter    67/  209] train: loss: 0.1042631
[Epoch 38; Iter    97/  209] train: loss: 0.1615581
[Epoch 38; Iter   127/  209] train: loss: 0.0915895
[Epoch 38; Iter   157/  209] train: loss: 0.2301964
[Epoch 38; Iter   187/  209] train: loss: 0.1075207
[Epoch 38] ogbg-moltox21: 0.867832 val loss: 0.198847
[Epoch 38] ogbg-moltox21: 0.848658 test loss: 0.186821
[Epoch 39; Iter     8/  209] train: loss: 0.1132714
[Epoch 39; Iter    38/  209] train: loss: 0.1165319
[Epoch 39; Iter    68/  209] train: loss: 0.2346238
[Epoch 39; Iter    98/  209] train: loss: 0.0984397
[Epoch 39; Iter   128/  209] train: loss: 0.1645802
[Epoch 39; Iter   158/  209] train: loss: 0.1132648
[Epoch 39; Iter   188/  209] train: loss: 0.1105575
[Epoch 39] ogbg-moltox21: 0.861651 val loss: 0.203397
[Epoch 39] ogbg-moltox21: 0.854955 test loss: 0.179715
[Epoch 40; Iter     9/  209] train: loss: 0.0968690
[Epoch 40; Iter    39/  209] train: loss: 0.1373153
[Epoch 40; Iter    69/  209] train: loss: 0.1734889
[Epoch 40; Iter    99/  209] train: loss: 0.1379350
[Epoch 40; Iter   129/  209] train: loss: 0.1036821
[Epoch 40; Iter   159/  209] train: loss: 0.1778881
[Epoch 40; Iter   189/  209] train: loss: 0.0999563
[Epoch 40] ogbg-moltox21: 0.852780 val loss: 0.204882
[Epoch 40] ogbg-moltox21: 0.848930 test loss: 0.185904
[Epoch 41; Iter    10/  209] train: loss: 0.1484847
[Epoch 41; Iter    40/  209] train: loss: 0.1400407
[Epoch 41; Iter    70/  209] train: loss: 0.1720333
[Epoch 41; Iter   100/  209] train: loss: 0.1148901
[Epoch 41; Iter   130/  209] train: loss: 0.1346197
[Epoch 41; Iter   160/  209] train: loss: 0.1063926
[Epoch 41; Iter   190/  209] train: loss: 0.1745761
[Epoch 41] ogbg-moltox21: 0.862234 val loss: 0.597849
[Epoch 41] ogbg-moltox21: 0.840231 test loss: 0.667371
[Epoch 42; Iter    11/  209] train: loss: 0.1374329
[Epoch 42; Iter    41/  209] train: loss: 0.1486983
[Epoch 42; Iter    71/  209] train: loss: 0.1396055
[Epoch 42; Iter   101/  209] train: loss: 0.1456355
[Epoch 42; Iter   131/  209] train: loss: 0.1707056
[Epoch 42; Iter   161/  209] train: loss: 0.1234019
[Epoch 42; Iter   191/  209] train: loss: 0.1349895
[Epoch 42] ogbg-moltox21: 0.863375 val loss: 0.205966
[Epoch 42] ogbg-moltox21: 0.845839 test loss: 0.189956
[Epoch 43; Iter    12/  209] train: loss: 0.1468099
[Epoch 43; Iter    42/  209] train: loss: 0.1278762
[Epoch 43; Iter    72/  209] train: loss: 0.1110898
[Epoch 43; Iter   102/  209] train: loss: 0.0969461
[Epoch 43; Iter   132/  209] train: loss: 0.0764368
[Epoch 43; Iter   162/  209] train: loss: 0.1406985
[Epoch 43; Iter   192/  209] train: loss: 0.1497204
[Epoch 43] ogbg-moltox21: 0.862187 val loss: 0.205557
[Epoch 43] ogbg-moltox21: 0.846220 test loss: 0.187285
[Epoch 44; Iter    13/  209] train: loss: 0.1374697
[Epoch 44; Iter    43/  209] train: loss: 0.1870890
[Epoch 44; Iter    73/  209] train: loss: 0.1337897
[Epoch 44; Iter   103/  209] train: loss: 0.1247535
[Epoch 44; Iter   133/  209] train: loss: 0.1170693
[Epoch 44; Iter   163/  209] train: loss: 0.2016765
[Epoch 44; Iter   193/  209] train: loss: 0.1391198
[Epoch 44] ogbg-moltox21: 0.866414 val loss: 0.198294
[Epoch 44] ogbg-moltox21: 0.845185 test loss: 0.186049
[Epoch 45; Iter    14/  209] train: loss: 0.1481441
[Epoch 45; Iter    44/  209] train: loss: 0.1235733
[Epoch 45; Iter    74/  209] train: loss: 0.1211070
[Epoch 45; Iter   104/  209] train: loss: 0.0905100
[Epoch 45; Iter   134/  209] train: loss: 0.1002972
[Epoch 45; Iter   164/  209] train: loss: 0.1307612
[Epoch 45; Iter   194/  209] train: loss: 0.1053647
[Epoch 45] ogbg-moltox21: 0.862571 val loss: 0.199930
[Epoch 45] ogbg-moltox21: 0.831598 test loss: 0.195327
[Epoch 46; Iter    15/  209] train: loss: 0.1051757
[Epoch 46; Iter    45/  209] train: loss: 0.1454041
[Epoch 46; Iter    75/  209] train: loss: 0.1445339
[Epoch 46; Iter   105/  209] train: loss: 0.1877630
[Epoch 46; Iter   135/  209] train: loss: 0.1493466
[Epoch 46; Iter   165/  209] train: loss: 0.0994456
[Epoch 46; Iter   195/  209] train: loss: 0.1955910
[Epoch 46] ogbg-moltox21: 0.856779 val loss: 0.212468
[Epoch 46] ogbg-moltox21: 0.840238 test loss: 0.190225
[Epoch 47; Iter    16/  209] train: loss: 0.1373552
[Epoch 47; Iter    46/  209] train: loss: 0.1320870
[Epoch 47; Iter    76/  209] train: loss: 0.1326994
[Epoch 47; Iter   106/  209] train: loss: 0.1007163
[Epoch 47; Iter   136/  209] train: loss: 0.0824673
[Epoch 33; Iter   114/  183] train: loss: 0.1572522
[Epoch 33; Iter   144/  183] train: loss: 0.2039208
[Epoch 33; Iter   174/  183] train: loss: 0.1416042
[Epoch 33] ogbg-moltox21: 0.837558 val loss: 0.193668
[Epoch 33] ogbg-moltox21: 0.851753 test loss: 0.191271
[Epoch 34; Iter    21/  183] train: loss: 0.1157558
[Epoch 34; Iter    51/  183] train: loss: 0.1707113
[Epoch 34; Iter    81/  183] train: loss: 0.0825153
[Epoch 34; Iter   111/  183] train: loss: 0.1173466
[Epoch 34; Iter   141/  183] train: loss: 0.1711161
[Epoch 34; Iter   171/  183] train: loss: 0.2194867
[Epoch 34] ogbg-moltox21: 0.835055 val loss: 0.196570
[Epoch 34] ogbg-moltox21: 0.858926 test loss: 0.191120
[Epoch 35; Iter    18/  183] train: loss: 0.1671252
[Epoch 35; Iter    48/  183] train: loss: 0.1469795
[Epoch 35; Iter    78/  183] train: loss: 0.1427430
[Epoch 35; Iter   108/  183] train: loss: 0.1751245
[Epoch 35; Iter   138/  183] train: loss: 0.2854739
[Epoch 35; Iter   168/  183] train: loss: 0.1602575
[Epoch 35] ogbg-moltox21: 0.809040 val loss: 0.206137
[Epoch 35] ogbg-moltox21: 0.841153 test loss: 0.200952
[Epoch 36; Iter    15/  183] train: loss: 0.2381020
[Epoch 36; Iter    45/  183] train: loss: 0.1796681
[Epoch 36; Iter    75/  183] train: loss: 0.2291931
[Epoch 36; Iter   105/  183] train: loss: 0.1723485
[Epoch 36; Iter   135/  183] train: loss: 0.1738833
[Epoch 36; Iter   165/  183] train: loss: 0.1188536
[Epoch 36] ogbg-moltox21: 0.837268 val loss: 0.195372
[Epoch 36] ogbg-moltox21: 0.858677 test loss: 0.193583
[Epoch 37; Iter    12/  183] train: loss: 0.2407815
[Epoch 37; Iter    42/  183] train: loss: 0.1962795
[Epoch 37; Iter    72/  183] train: loss: 0.1304861
[Epoch 37; Iter   102/  183] train: loss: 0.1454119
[Epoch 37; Iter   132/  183] train: loss: 0.0993359
[Epoch 37; Iter   162/  183] train: loss: 0.2605265
[Epoch 37] ogbg-moltox21: 0.837692 val loss: 0.189432
[Epoch 37] ogbg-moltox21: 0.854962 test loss: 0.188265
[Epoch 38; Iter     9/  183] train: loss: 0.1388706
[Epoch 38; Iter    39/  183] train: loss: 0.1562488
[Epoch 38; Iter    69/  183] train: loss: 0.1248209
[Epoch 38; Iter    99/  183] train: loss: 0.1101535
[Epoch 38; Iter   129/  183] train: loss: 0.1334753
[Epoch 38; Iter   159/  183] train: loss: 0.1925342
[Epoch 38] ogbg-moltox21: 0.843291 val loss: 0.188032
[Epoch 38] ogbg-moltox21: 0.856149 test loss: 0.191820
[Epoch 39; Iter     6/  183] train: loss: 0.1419399
[Epoch 39; Iter    36/  183] train: loss: 0.1133261
[Epoch 39; Iter    66/  183] train: loss: 0.1196277
[Epoch 39; Iter    96/  183] train: loss: 0.1359244
[Epoch 39; Iter   126/  183] train: loss: 0.2045430
[Epoch 39; Iter   156/  183] train: loss: 0.1418590
[Epoch 39] ogbg-moltox21: 0.841636 val loss: 0.189160
[Epoch 39] ogbg-moltox21: 0.850000 test loss: 0.188147
[Epoch 40; Iter     3/  183] train: loss: 0.1289148
[Epoch 40; Iter    33/  183] train: loss: 0.1275654
[Epoch 40; Iter    63/  183] train: loss: 0.1670342
[Epoch 40; Iter    93/  183] train: loss: 0.1571834
[Epoch 40; Iter   123/  183] train: loss: 0.1245477
[Epoch 40; Iter   153/  183] train: loss: 0.1552634
[Epoch 40; Iter   183/  183] train: loss: 0.1487539
[Epoch 40] ogbg-moltox21: 0.837950 val loss: 0.189205
[Epoch 40] ogbg-moltox21: 0.849923 test loss: 0.190977
[Epoch 41; Iter    30/  183] train: loss: 0.1757743
[Epoch 41; Iter    60/  183] train: loss: 0.1854617
[Epoch 41; Iter    90/  183] train: loss: 0.1418824
[Epoch 41; Iter   120/  183] train: loss: 0.1873218
[Epoch 41; Iter   150/  183] train: loss: 0.1163755
[Epoch 41; Iter   180/  183] train: loss: 0.1466596
[Epoch 41] ogbg-moltox21: 0.843406 val loss: 0.191155
[Epoch 41] ogbg-moltox21: 0.852942 test loss: 0.190149
[Epoch 42; Iter    27/  183] train: loss: 0.1828090
[Epoch 42; Iter    57/  183] train: loss: 0.1090707
[Epoch 42; Iter    87/  183] train: loss: 0.1735214
[Epoch 42; Iter   117/  183] train: loss: 0.1100584
[Epoch 42; Iter   147/  183] train: loss: 0.1352540
[Epoch 42; Iter   177/  183] train: loss: 0.1869967
[Epoch 42] ogbg-moltox21: 0.842715 val loss: 0.188319
[Epoch 42] ogbg-moltox21: 0.852049 test loss: 0.190495
[Epoch 43; Iter    24/  183] train: loss: 0.1973943
[Epoch 43; Iter    54/  183] train: loss: 0.1502555
[Epoch 43; Iter    84/  183] train: loss: 0.1287739
[Epoch 43; Iter   114/  183] train: loss: 0.1716529
[Epoch 43; Iter   144/  183] train: loss: 0.1396606
[Epoch 43; Iter   174/  183] train: loss: 0.0803446
[Epoch 43] ogbg-moltox21: 0.845592 val loss: 0.192457
[Epoch 43] ogbg-moltox21: 0.849599 test loss: 0.190459
[Epoch 44; Iter    21/  183] train: loss: 0.1232461
[Epoch 44; Iter    51/  183] train: loss: 0.1370690
[Epoch 44; Iter    81/  183] train: loss: 0.1349273
[Epoch 44; Iter   111/  183] train: loss: 0.0893562
[Epoch 44; Iter   141/  183] train: loss: 0.1059780
[Epoch 44; Iter   171/  183] train: loss: 0.0782830
[Epoch 44] ogbg-moltox21: 0.843756 val loss: 0.190727
[Epoch 44] ogbg-moltox21: 0.853477 test loss: 0.188497
[Epoch 45; Iter    18/  183] train: loss: 0.1659200
[Epoch 45; Iter    48/  183] train: loss: 0.1604424
[Epoch 45; Iter    78/  183] train: loss: 0.1416485
[Epoch 45; Iter   108/  183] train: loss: 0.1664341
[Epoch 45; Iter   138/  183] train: loss: 0.1023574
[Epoch 45; Iter   168/  183] train: loss: 0.1493409
[Epoch 45] ogbg-moltox21: 0.841976 val loss: 0.193593
[Epoch 45] ogbg-moltox21: 0.846412 test loss: 0.193596
[Epoch 46; Iter    15/  183] train: loss: 0.1024097
[Epoch 46; Iter    45/  183] train: loss: 0.0592858
[Epoch 46; Iter    75/  183] train: loss: 0.1083256
[Epoch 46; Iter   105/  183] train: loss: 0.1169036
[Epoch 46; Iter   135/  183] train: loss: 0.1321739
[Epoch 46; Iter   165/  183] train: loss: 0.1408301
[Epoch 46] ogbg-moltox21: 0.839348 val loss: 0.194529
[Epoch 46] ogbg-moltox21: 0.852813 test loss: 0.192671
[Epoch 47; Iter    12/  183] train: loss: 0.1726040
[Epoch 47; Iter    42/  183] train: loss: 0.2305075
[Epoch 47; Iter    72/  183] train: loss: 0.1196665
[Epoch 47; Iter   102/  183] train: loss: 0.1282597
[Epoch 47; Iter   132/  183] train: loss: 0.0729565
[Epoch 47; Iter   162/  183] train: loss: 0.1332152
[Epoch 47] ogbg-moltox21: 0.837620 val loss: 0.194747
[Epoch 47] ogbg-moltox21: 0.848513 test loss: 0.193516
[Epoch 48; Iter     9/  183] train: loss: 0.1147448
[Epoch 48; Iter    39/  183] train: loss: 0.1262877
[Epoch 48; Iter    69/  183] train: loss: 0.0870483
[Epoch 48; Iter    99/  183] train: loss: 0.1220418
[Epoch 48; Iter   129/  183] train: loss: 0.0927432
[Epoch 48; Iter   159/  183] train: loss: 0.0971859
[Epoch 48] ogbg-moltox21: 0.837020 val loss: 0.195461
[Epoch 48] ogbg-moltox21: 0.839552 test loss: 0.197109
[Epoch 49; Iter     6/  183] train: loss: 0.1854601
[Epoch 49; Iter    36/  183] train: loss: 0.0923742
[Epoch 49; Iter    66/  183] train: loss: 0.1311587
[Epoch 49; Iter    96/  183] train: loss: 0.2184647
[Epoch 49; Iter   126/  183] train: loss: 0.1512789
[Epoch 49; Iter   156/  183] train: loss: 0.2215782
[Epoch 49] ogbg-moltox21: 0.828835 val loss: 0.201172
[Epoch 49] ogbg-moltox21: 0.838819 test loss: 0.201607
[Epoch 50; Iter     3/  183] train: loss: 0.1823726
[Epoch 50; Iter    33/  183] train: loss: 0.1120517
[Epoch 50; Iter    63/  183] train: loss: 0.1005543
[Epoch 50; Iter    93/  183] train: loss: 0.1750815
[Epoch 50; Iter   123/  183] train: loss: 0.1264546
[Epoch 50; Iter   153/  183] train: loss: 0.1451567
[Epoch 50; Iter   183/  183] train: loss: 0.1232761
[Epoch 50] ogbg-moltox21: 0.828355 val loss: 0.201163
[Epoch 50] ogbg-moltox21: 0.835351 test loss: 0.201195
[Epoch 51; Iter    30/  183] train: loss: 0.0926570
[Epoch 51; Iter    60/  183] train: loss: 0.1231950
[Epoch 51; Iter    90/  183] train: loss: 0.0749613
[Epoch 51; Iter   120/  183] train: loss: 0.1101377
[Epoch 51; Iter   150/  183] train: loss: 0.0672053
[Epoch 51; Iter   180/  183] train: loss: 0.1206298
[Epoch 51] ogbg-moltox21: 0.834212 val loss: 0.201330
[Epoch 51] ogbg-moltox21: 0.834943 test loss: 0.205066
[Epoch 52; Iter    27/  183] train: loss: 0.1456698
[Epoch 52; Iter    57/  183] train: loss: 0.1325111
[Epoch 52; Iter    87/  183] train: loss: 0.1231152
[Epoch 52; Iter   117/  183] train: loss: 0.1649982
[Epoch 33; Iter   114/  183] train: loss: 0.2166471
[Epoch 33; Iter   144/  183] train: loss: 0.1633333
[Epoch 33; Iter   174/  183] train: loss: 0.2168576
[Epoch 33] ogbg-moltox21: 0.822923 val loss: 0.216304
[Epoch 33] ogbg-moltox21: 0.844354 test loss: 0.205632
[Epoch 34; Iter    21/  183] train: loss: 0.2149995
[Epoch 34; Iter    51/  183] train: loss: 0.1286452
[Epoch 34; Iter    81/  183] train: loss: 0.2105146
[Epoch 34; Iter   111/  183] train: loss: 0.2685084
[Epoch 34; Iter   141/  183] train: loss: 0.1548728
[Epoch 34; Iter   171/  183] train: loss: 0.1238734
[Epoch 34] ogbg-moltox21: 0.831609 val loss: 0.201977
[Epoch 34] ogbg-moltox21: 0.839801 test loss: 0.222824
[Epoch 35; Iter    18/  183] train: loss: 0.1235624
[Epoch 35; Iter    48/  183] train: loss: 0.1899149
[Epoch 35; Iter    78/  183] train: loss: 0.1623700
[Epoch 35; Iter   108/  183] train: loss: 0.2456304
[Epoch 35; Iter   138/  183] train: loss: 0.2802759
[Epoch 35; Iter   168/  183] train: loss: 0.1604554
[Epoch 35] ogbg-moltox21: 0.807881 val loss: 0.241651
[Epoch 35] ogbg-moltox21: 0.836593 test loss: 0.207385
[Epoch 36; Iter    15/  183] train: loss: 0.2290775
[Epoch 36; Iter    45/  183] train: loss: 0.1895072
[Epoch 36; Iter    75/  183] train: loss: 0.2244685
[Epoch 36; Iter   105/  183] train: loss: 0.1475486
[Epoch 36; Iter   135/  183] train: loss: 0.1729681
[Epoch 36; Iter   165/  183] train: loss: 0.1351230
[Epoch 36] ogbg-moltox21: 0.832763 val loss: 0.198124
[Epoch 36] ogbg-moltox21: 0.845433 test loss: 0.201050
[Epoch 37; Iter    12/  183] train: loss: 0.1544117
[Epoch 37; Iter    42/  183] train: loss: 0.1275771
[Epoch 37; Iter    72/  183] train: loss: 0.1907152
[Epoch 37; Iter   102/  183] train: loss: 0.2216443
[Epoch 37; Iter   132/  183] train: loss: 0.1985887
[Epoch 37; Iter   162/  183] train: loss: 0.1616965
[Epoch 37] ogbg-moltox21: 0.838092 val loss: 0.203865
[Epoch 37] ogbg-moltox21: 0.846748 test loss: 0.202838
[Epoch 38; Iter     9/  183] train: loss: 0.1602549
[Epoch 38; Iter    39/  183] train: loss: 0.1715541
[Epoch 38; Iter    69/  183] train: loss: 0.2172854
[Epoch 38; Iter    99/  183] train: loss: 0.1088705
[Epoch 38; Iter   129/  183] train: loss: 0.1820119
[Epoch 38; Iter   159/  183] train: loss: 0.1232458
[Epoch 38] ogbg-moltox21: 0.829448 val loss: 13.685980
[Epoch 38] ogbg-moltox21: 0.848602 test loss: 1.756916
[Epoch 39; Iter     6/  183] train: loss: 0.1603896
[Epoch 39; Iter    36/  183] train: loss: 0.1363535
[Epoch 39; Iter    66/  183] train: loss: 0.2315304
[Epoch 39; Iter    96/  183] train: loss: 0.2962427
[Epoch 39; Iter   126/  183] train: loss: 0.1719591
[Epoch 39; Iter   156/  183] train: loss: 0.2156860
[Epoch 39] ogbg-moltox21: 0.842519 val loss: 0.244061
[Epoch 39] ogbg-moltox21: 0.851500 test loss: 0.208126
[Epoch 40; Iter     3/  183] train: loss: 0.2247980
[Epoch 40; Iter    33/  183] train: loss: 0.2553695
[Epoch 40; Iter    63/  183] train: loss: 0.2359730
[Epoch 40; Iter    93/  183] train: loss: 0.2785040
[Epoch 40; Iter   123/  183] train: loss: 0.2207909
[Epoch 40; Iter   153/  183] train: loss: 0.1181654
[Epoch 40; Iter   183/  183] train: loss: 0.1320503
[Epoch 40] ogbg-moltox21: 0.840929 val loss: 0.210718
[Epoch 40] ogbg-moltox21: 0.845530 test loss: 0.246374
[Epoch 41; Iter    30/  183] train: loss: 0.2019192
[Epoch 41; Iter    60/  183] train: loss: 0.1954322
[Epoch 41; Iter    90/  183] train: loss: 0.2455121
[Epoch 41; Iter   120/  183] train: loss: 0.1370259
[Epoch 41; Iter   150/  183] train: loss: 0.2627763
[Epoch 41; Iter   180/  183] train: loss: 0.2648076
[Epoch 41] ogbg-moltox21: 0.837837 val loss: 0.199143
[Epoch 41] ogbg-moltox21: 0.843798 test loss: 0.203411
[Epoch 42; Iter    27/  183] train: loss: 0.1402093
[Epoch 42; Iter    57/  183] train: loss: 0.1354790
[Epoch 42; Iter    87/  183] train: loss: 0.1485062
[Epoch 42; Iter   117/  183] train: loss: 0.2075856
[Epoch 42; Iter   147/  183] train: loss: 0.1593314
[Epoch 42; Iter   177/  183] train: loss: 0.1500574
[Epoch 42] ogbg-moltox21: 0.836261 val loss: 0.194982
[Epoch 42] ogbg-moltox21: 0.845435 test loss: 0.197606
[Epoch 43; Iter    24/  183] train: loss: 0.1667940
[Epoch 43; Iter    54/  183] train: loss: 0.1912412
[Epoch 43; Iter    84/  183] train: loss: 0.1688796
[Epoch 43; Iter   114/  183] train: loss: 0.1881939
[Epoch 43; Iter   144/  183] train: loss: 0.1223581
[Epoch 43; Iter   174/  183] train: loss: 0.1403495
[Epoch 43] ogbg-moltox21: 0.844856 val loss: 0.194360
[Epoch 43] ogbg-moltox21: 0.851358 test loss: 0.229411
[Epoch 44; Iter    21/  183] train: loss: 0.1520905
[Epoch 44; Iter    51/  183] train: loss: 0.2284291
[Epoch 44; Iter    81/  183] train: loss: 0.1694507
[Epoch 44; Iter   111/  183] train: loss: 0.1090678
[Epoch 44; Iter   141/  183] train: loss: 0.1504405
[Epoch 44; Iter   171/  183] train: loss: 0.2213111
[Epoch 44] ogbg-moltox21: 0.837970 val loss: 0.219495
[Epoch 44] ogbg-moltox21: 0.852495 test loss: 0.204125
[Epoch 45; Iter    18/  183] train: loss: 0.1908741
[Epoch 45; Iter    48/  183] train: loss: 0.1678784
[Epoch 45; Iter    78/  183] train: loss: 0.1369482
[Epoch 45; Iter   108/  183] train: loss: 0.1693712
[Epoch 45; Iter   138/  183] train: loss: 0.1804823
[Epoch 45; Iter   168/  183] train: loss: 0.1363187
[Epoch 45] ogbg-moltox21: 0.839475 val loss: 0.194478
[Epoch 45] ogbg-moltox21: 0.845558 test loss: 0.195279
[Epoch 46; Iter    15/  183] train: loss: 0.1202871
[Epoch 46; Iter    45/  183] train: loss: 0.1859227
[Epoch 46; Iter    75/  183] train: loss: 0.1752302
[Epoch 46; Iter   105/  183] train: loss: 0.1705772
[Epoch 46; Iter   135/  183] train: loss: 0.1466304
[Epoch 46; Iter   165/  183] train: loss: 0.1920855
[Epoch 46] ogbg-moltox21: 0.837938 val loss: 0.193809
[Epoch 46] ogbg-moltox21: 0.843278 test loss: 0.212712
[Epoch 47; Iter    12/  183] train: loss: 0.1341099
[Epoch 47; Iter    42/  183] train: loss: 0.0758337
[Epoch 47; Iter    72/  183] train: loss: 0.1269370
[Epoch 47; Iter   102/  183] train: loss: 0.1750835
[Epoch 47; Iter   132/  183] train: loss: 0.2072105
[Epoch 47; Iter   162/  183] train: loss: 0.1374569
[Epoch 47] ogbg-moltox21: 0.838924 val loss: 0.194652
[Epoch 47] ogbg-moltox21: 0.856251 test loss: 0.190683
[Epoch 48; Iter     9/  183] train: loss: 0.1420252
[Epoch 48; Iter    39/  183] train: loss: 0.0768973
[Epoch 48; Iter    69/  183] train: loss: 0.1545205
[Epoch 48; Iter    99/  183] train: loss: 0.1419181
[Epoch 48; Iter   129/  183] train: loss: 0.1805667
[Epoch 48; Iter   159/  183] train: loss: 0.1840625
[Epoch 48] ogbg-moltox21: 0.842144 val loss: 0.191030
[Epoch 48] ogbg-moltox21: 0.850064 test loss: 0.196256
[Epoch 49; Iter     6/  183] train: loss: 0.2127954
[Epoch 49; Iter    36/  183] train: loss: 0.1937381
[Epoch 49; Iter    66/  183] train: loss: 0.1446868
[Epoch 49; Iter    96/  183] train: loss: 0.1858752
[Epoch 49; Iter   126/  183] train: loss: 0.1421999
[Epoch 49; Iter   156/  183] train: loss: 0.1501289
[Epoch 49] ogbg-moltox21: 0.846069 val loss: 0.209697
[Epoch 49] ogbg-moltox21: 0.852841 test loss: 0.190839
[Epoch 50; Iter     3/  183] train: loss: 0.1455680
[Epoch 50; Iter    33/  183] train: loss: 0.0894786
[Epoch 50; Iter    63/  183] train: loss: 0.1315627
[Epoch 50; Iter    93/  183] train: loss: 0.1319648
[Epoch 50; Iter   123/  183] train: loss: 0.1391845
[Epoch 50; Iter   153/  183] train: loss: 0.1886537
[Epoch 50; Iter   183/  183] train: loss: 0.2830878
[Epoch 50] ogbg-moltox21: 0.842323 val loss: 0.200910
[Epoch 50] ogbg-moltox21: 0.846514 test loss: 0.193991
[Epoch 51; Iter    30/  183] train: loss: 0.1273292
[Epoch 51; Iter    60/  183] train: loss: 0.1706408
[Epoch 51; Iter    90/  183] train: loss: 0.1486045
[Epoch 51; Iter   120/  183] train: loss: 0.1029951
[Epoch 51; Iter   150/  183] train: loss: 0.1091418
[Epoch 51; Iter   180/  183] train: loss: 0.1136786
[Epoch 51] ogbg-moltox21: 0.846382 val loss: 0.193771
[Epoch 51] ogbg-moltox21: 0.847427 test loss: 0.194575
[Epoch 52; Iter    27/  183] train: loss: 0.1412107
[Epoch 52; Iter    57/  183] train: loss: 0.1383079
[Epoch 52; Iter    87/  183] train: loss: 0.1314092
[Epoch 52; Iter   117/  183] train: loss: 0.2083800
[Epoch 33; Iter   114/  183] train: loss: 0.1601967
[Epoch 33; Iter   144/  183] train: loss: 0.1556056
[Epoch 33; Iter   174/  183] train: loss: 0.0719181
[Epoch 33] ogbg-moltox21: 0.830396 val loss: 0.199330
[Epoch 33] ogbg-moltox21: 0.843839 test loss: 0.201235
[Epoch 34; Iter    21/  183] train: loss: 0.1619987
[Epoch 34; Iter    51/  183] train: loss: 0.1108030
[Epoch 34; Iter    81/  183] train: loss: 0.1787498
[Epoch 34; Iter   111/  183] train: loss: 0.1219440
[Epoch 34; Iter   141/  183] train: loss: 0.1635026
[Epoch 34; Iter   171/  183] train: loss: 0.1862617
[Epoch 34] ogbg-moltox21: 0.836861 val loss: 0.196080
[Epoch 34] ogbg-moltox21: 0.850377 test loss: 0.197047
[Epoch 35; Iter    18/  183] train: loss: 0.1340480
[Epoch 35; Iter    48/  183] train: loss: 0.1808935
[Epoch 35; Iter    78/  183] train: loss: 0.1681802
[Epoch 35; Iter   108/  183] train: loss: 0.1517393
[Epoch 35; Iter   138/  183] train: loss: 0.1589605
[Epoch 35; Iter   168/  183] train: loss: 0.1548181
[Epoch 35] ogbg-moltox21: 0.829356 val loss: 0.203984
[Epoch 35] ogbg-moltox21: 0.833901 test loss: 0.209367
[Epoch 36; Iter    15/  183] train: loss: 0.2115399
[Epoch 36; Iter    45/  183] train: loss: 0.1688191
[Epoch 36; Iter    75/  183] train: loss: 0.2535333
[Epoch 36; Iter   105/  183] train: loss: 0.2196918
[Epoch 36; Iter   135/  183] train: loss: 0.2476284
[Epoch 36; Iter   165/  183] train: loss: 0.1083677
[Epoch 36] ogbg-moltox21: 0.831854 val loss: 0.193154
[Epoch 36] ogbg-moltox21: 0.845755 test loss: 0.196901
[Epoch 37; Iter    12/  183] train: loss: 0.1463176
[Epoch 37; Iter    42/  183] train: loss: 0.1337212
[Epoch 37; Iter    72/  183] train: loss: 0.1689354
[Epoch 37; Iter   102/  183] train: loss: 0.1027867
[Epoch 37; Iter   132/  183] train: loss: 0.1034412
[Epoch 37; Iter   162/  183] train: loss: 0.0966710
[Epoch 37] ogbg-moltox21: 0.836785 val loss: 0.190365
[Epoch 37] ogbg-moltox21: 0.854022 test loss: 0.193597
[Epoch 38; Iter     9/  183] train: loss: 0.0965108
[Epoch 38; Iter    39/  183] train: loss: 0.1095799
[Epoch 38; Iter    69/  183] train: loss: 0.1418530
[Epoch 38; Iter    99/  183] train: loss: 0.1617167
[Epoch 38; Iter   129/  183] train: loss: 0.1416048
[Epoch 38; Iter   159/  183] train: loss: 0.1568747
[Epoch 38] ogbg-moltox21: 0.839422 val loss: 0.189490
[Epoch 38] ogbg-moltox21: 0.856135 test loss: 0.189848
[Epoch 39; Iter     6/  183] train: loss: 0.1296466
[Epoch 39; Iter    36/  183] train: loss: 0.1336816
[Epoch 39; Iter    66/  183] train: loss: 0.1310122
[Epoch 39; Iter    96/  183] train: loss: 0.1201752
[Epoch 39; Iter   126/  183] train: loss: 0.0914938
[Epoch 39; Iter   156/  183] train: loss: 0.1414661
[Epoch 39] ogbg-moltox21: 0.842435 val loss: 0.188634
[Epoch 39] ogbg-moltox21: 0.851484 test loss: 0.192710
[Epoch 40; Iter     3/  183] train: loss: 0.1066176
[Epoch 40; Iter    33/  183] train: loss: 0.1444844
[Epoch 40; Iter    63/  183] train: loss: 0.1939889
[Epoch 40; Iter    93/  183] train: loss: 0.1034268
[Epoch 40; Iter   123/  183] train: loss: 0.1925334
[Epoch 40; Iter   153/  183] train: loss: 0.1575923
[Epoch 40; Iter   183/  183] train: loss: 0.2539735
[Epoch 40] ogbg-moltox21: 0.834904 val loss: 0.193237
[Epoch 40] ogbg-moltox21: 0.850446 test loss: 0.192183
[Epoch 41; Iter    30/  183] train: loss: 0.0937731
[Epoch 41; Iter    60/  183] train: loss: 0.1622496
[Epoch 41; Iter    90/  183] train: loss: 0.2063014
[Epoch 41; Iter   120/  183] train: loss: 0.0945710
[Epoch 41; Iter   150/  183] train: loss: 0.1932336
[Epoch 41; Iter   180/  183] train: loss: 0.1754466
[Epoch 41] ogbg-moltox21: 0.839682 val loss: 0.190084
[Epoch 41] ogbg-moltox21: 0.844470 test loss: 0.196130
[Epoch 42; Iter    27/  183] train: loss: 0.1482855
[Epoch 42; Iter    57/  183] train: loss: 0.1336474
[Epoch 42; Iter    87/  183] train: loss: 0.1402763
[Epoch 42; Iter   117/  183] train: loss: 0.1355331
[Epoch 42; Iter   147/  183] train: loss: 0.1685366
[Epoch 42; Iter   177/  183] train: loss: 0.0829305
[Epoch 42] ogbg-moltox21: 0.832975 val loss: 0.191560
[Epoch 42] ogbg-moltox21: 0.843931 test loss: 0.192285
[Epoch 43; Iter    24/  183] train: loss: 0.0757290
[Epoch 43; Iter    54/  183] train: loss: 0.1072398
[Epoch 43; Iter    84/  183] train: loss: 0.1448528
[Epoch 43; Iter   114/  183] train: loss: 0.0772394
[Epoch 43; Iter   144/  183] train: loss: 0.1246179
[Epoch 43; Iter   174/  183] train: loss: 0.1653659
[Epoch 43] ogbg-moltox21: 0.834249 val loss: 0.193328
[Epoch 43] ogbg-moltox21: 0.842458 test loss: 0.195843
[Epoch 44; Iter    21/  183] train: loss: 0.1141336
[Epoch 44; Iter    51/  183] train: loss: 0.1419417
[Epoch 44; Iter    81/  183] train: loss: 0.1096648
[Epoch 44; Iter   111/  183] train: loss: 0.1250461
[Epoch 44; Iter   141/  183] train: loss: 0.1759028
[Epoch 44; Iter   171/  183] train: loss: 0.1291090
[Epoch 44] ogbg-moltox21: 0.836135 val loss: 0.192728
[Epoch 44] ogbg-moltox21: 0.837016 test loss: 0.200121
[Epoch 45; Iter    18/  183] train: loss: 0.0732382
[Epoch 45; Iter    48/  183] train: loss: 0.1551501
[Epoch 45; Iter    78/  183] train: loss: 0.1257843
[Epoch 45; Iter   108/  183] train: loss: 0.0624461
[Epoch 45; Iter   138/  183] train: loss: 0.0925526
[Epoch 45; Iter   168/  183] train: loss: 0.1617384
[Epoch 45] ogbg-moltox21: 0.832839 val loss: 0.198593
[Epoch 45] ogbg-moltox21: 0.843335 test loss: 0.198336
[Epoch 46; Iter    15/  183] train: loss: 0.1192326
[Epoch 46; Iter    45/  183] train: loss: 0.1718863
[Epoch 46; Iter    75/  183] train: loss: 0.1228374
[Epoch 46; Iter   105/  183] train: loss: 0.1292876
[Epoch 46; Iter   135/  183] train: loss: 0.1238404
[Epoch 46; Iter   165/  183] train: loss: 0.1040803
[Epoch 46] ogbg-moltox21: 0.831050 val loss: 0.198686
[Epoch 46] ogbg-moltox21: 0.837160 test loss: 0.203396
[Epoch 47; Iter    12/  183] train: loss: 0.0989127
[Epoch 47; Iter    42/  183] train: loss: 0.1010494
[Epoch 47; Iter    72/  183] train: loss: 0.0955811
[Epoch 47; Iter   102/  183] train: loss: 0.0842149
[Epoch 47; Iter   132/  183] train: loss: 0.1418846
[Epoch 47; Iter   162/  183] train: loss: 0.1842634
[Epoch 47] ogbg-moltox21: 0.832226 val loss: 0.198829
[Epoch 47] ogbg-moltox21: 0.839400 test loss: 0.203625
[Epoch 48; Iter     9/  183] train: loss: 0.1153374
[Epoch 48; Iter    39/  183] train: loss: 0.1726221
[Epoch 48; Iter    69/  183] train: loss: 0.1800233
[Epoch 48; Iter    99/  183] train: loss: 0.1276674
[Epoch 48; Iter   129/  183] train: loss: 0.1362888
[Epoch 48; Iter   159/  183] train: loss: 0.0998645
[Epoch 48] ogbg-moltox21: 0.832095 val loss: 0.204023
[Epoch 48] ogbg-moltox21: 0.838422 test loss: 0.209885
[Epoch 49; Iter     6/  183] train: loss: 0.1247036
[Epoch 49; Iter    36/  183] train: loss: 0.1666695
[Epoch 49; Iter    66/  183] train: loss: 0.1522641
[Epoch 49; Iter    96/  183] train: loss: 0.1484654
[Epoch 49; Iter   126/  183] train: loss: 0.1627181
[Epoch 49; Iter   156/  183] train: loss: 0.0867777
[Epoch 49] ogbg-moltox21: 0.830011 val loss: 0.199605
[Epoch 49] ogbg-moltox21: 0.842994 test loss: 0.200367
[Epoch 50; Iter     3/  183] train: loss: 0.1021377
[Epoch 50; Iter    33/  183] train: loss: 0.1314366
[Epoch 50; Iter    63/  183] train: loss: 0.0750513
[Epoch 50; Iter    93/  183] train: loss: 0.0815945
[Epoch 50; Iter   123/  183] train: loss: 0.1216300
[Epoch 50; Iter   153/  183] train: loss: 0.1097132
[Epoch 50; Iter   183/  183] train: loss: 0.1452433
[Epoch 50] ogbg-moltox21: 0.832116 val loss: 0.201215
[Epoch 50] ogbg-moltox21: 0.843656 test loss: 0.203154
[Epoch 51; Iter    30/  183] train: loss: 0.0720703
[Epoch 51; Iter    60/  183] train: loss: 0.1171438
[Epoch 51; Iter    90/  183] train: loss: 0.1034666
[Epoch 51; Iter   120/  183] train: loss: 0.1391270
[Epoch 51; Iter   150/  183] train: loss: 0.1024967
[Epoch 51; Iter   180/  183] train: loss: 0.1024146
[Epoch 51] ogbg-moltox21: 0.826095 val loss: 0.206355
[Epoch 51] ogbg-moltox21: 0.835002 test loss: 0.207811
[Epoch 52; Iter    27/  183] train: loss: 0.0888569
[Epoch 52; Iter    57/  183] train: loss: 0.1515629
[Epoch 52; Iter    87/  183] train: loss: 0.0835191
[Epoch 52; Iter   117/  183] train: loss: 0.1413945
[Epoch 37; Iter    78/  157] train: loss: 0.1289514
[Epoch 37; Iter   108/  157] train: loss: 0.1225861
[Epoch 37; Iter   138/  157] train: loss: 0.1439020
[Epoch 37] ogbg-moltox21: 0.832688 val loss: 0.187015
[Epoch 37] ogbg-moltox21: 0.853447 test loss: 0.196622
[Epoch 38; Iter    11/  157] train: loss: 0.1580768
[Epoch 38; Iter    41/  157] train: loss: 0.1224516
[Epoch 38; Iter    71/  157] train: loss: 0.1311406
[Epoch 38; Iter   101/  157] train: loss: 0.2334139
[Epoch 38; Iter   131/  157] train: loss: 0.1409060
[Epoch 38] ogbg-moltox21: 0.809533 val loss: 0.336041
[Epoch 38] ogbg-moltox21: 0.833706 test loss: 0.346928
[Epoch 39; Iter     4/  157] train: loss: 0.1748565
[Epoch 39; Iter    34/  157] train: loss: 0.1401140
[Epoch 39; Iter    64/  157] train: loss: 0.1267133
[Epoch 39; Iter    94/  157] train: loss: 0.1021486
[Epoch 39; Iter   124/  157] train: loss: 0.1492952
[Epoch 39; Iter   154/  157] train: loss: 0.1351395
[Epoch 39] ogbg-moltox21: 0.828044 val loss: 0.187809
[Epoch 39] ogbg-moltox21: 0.852450 test loss: 0.194303
[Epoch 40; Iter    27/  157] train: loss: 0.0933246
[Epoch 40; Iter    57/  157] train: loss: 0.1447981
[Epoch 40; Iter    87/  157] train: loss: 0.1346551
[Epoch 40; Iter   117/  157] train: loss: 0.1520334
[Epoch 40; Iter   147/  157] train: loss: 0.1416520
[Epoch 40] ogbg-moltox21: 0.834452 val loss: 0.202572
[Epoch 40] ogbg-moltox21: 0.854202 test loss: 0.209284
[Epoch 41; Iter    20/  157] train: loss: 0.1469092
[Epoch 41; Iter    50/  157] train: loss: 0.2018812
[Epoch 41; Iter    80/  157] train: loss: 0.1354735
[Epoch 41; Iter   110/  157] train: loss: 0.1696643
[Epoch 41; Iter   140/  157] train: loss: 0.1153838
[Epoch 41] ogbg-moltox21: 0.830227 val loss: 0.188922
[Epoch 41] ogbg-moltox21: 0.847512 test loss: 0.198507
[Epoch 42; Iter    13/  157] train: loss: 0.1321718
[Epoch 42; Iter    43/  157] train: loss: 0.2117477
[Epoch 42; Iter    73/  157] train: loss: 0.1497975
[Epoch 42; Iter   103/  157] train: loss: 0.1117468
[Epoch 42; Iter   133/  157] train: loss: 0.1295570
[Epoch 42] ogbg-moltox21: 0.833483 val loss: 0.184842
[Epoch 42] ogbg-moltox21: 0.844396 test loss: 0.199973
[Epoch 43; Iter     6/  157] train: loss: 0.1285992
[Epoch 43; Iter    36/  157] train: loss: 0.0909827
[Epoch 43; Iter    66/  157] train: loss: 0.1127384
[Epoch 43; Iter    96/  157] train: loss: 0.1919086
[Epoch 43; Iter   126/  157] train: loss: 0.1686588
[Epoch 43; Iter   156/  157] train: loss: 0.1207084
[Epoch 43] ogbg-moltox21: 0.831204 val loss: 0.188441
[Epoch 43] ogbg-moltox21: 0.852228 test loss: 0.197441
[Epoch 44; Iter    29/  157] train: loss: 0.1364684
[Epoch 44; Iter    59/  157] train: loss: 0.1692216
[Epoch 44; Iter    89/  157] train: loss: 0.1789004
[Epoch 44; Iter   119/  157] train: loss: 0.1315099
[Epoch 44; Iter   149/  157] train: loss: 0.1353822
[Epoch 44] ogbg-moltox21: 0.836330 val loss: 0.188415
[Epoch 44] ogbg-moltox21: 0.851103 test loss: 0.200875
[Epoch 45; Iter    22/  157] train: loss: 0.0960004
[Epoch 45; Iter    52/  157] train: loss: 0.1303092
[Epoch 45; Iter    82/  157] train: loss: 0.1573009
[Epoch 45; Iter   112/  157] train: loss: 0.1041934
[Epoch 45; Iter   142/  157] train: loss: 0.1986918
[Epoch 45] ogbg-moltox21: 0.820638 val loss: 0.205806
[Epoch 45] ogbg-moltox21: 0.848038 test loss: 0.202706
[Epoch 46; Iter    15/  157] train: loss: 0.1571675
[Epoch 46; Iter    45/  157] train: loss: 0.1695561
[Epoch 46; Iter    75/  157] train: loss: 0.1238406
[Epoch 46; Iter   105/  157] train: loss: 0.1477438
[Epoch 46; Iter   135/  157] train: loss: 0.1388445
[Epoch 46] ogbg-moltox21: 0.824097 val loss: 0.195434
[Epoch 46] ogbg-moltox21: 0.847220 test loss: 0.200235
[Epoch 47; Iter     8/  157] train: loss: 0.1105286
[Epoch 47; Iter    38/  157] train: loss: 0.1791083
[Epoch 47; Iter    68/  157] train: loss: 0.1495124
[Epoch 47; Iter    98/  157] train: loss: 0.1559476
[Epoch 47; Iter   128/  157] train: loss: 0.1103713
[Epoch 47] ogbg-moltox21: 0.822059 val loss: 0.195611
[Epoch 47] ogbg-moltox21: 0.844548 test loss: 0.204126
[Epoch 48; Iter     1/  157] train: loss: 0.1012672
[Epoch 48; Iter    31/  157] train: loss: 0.0958372
[Epoch 48; Iter    61/  157] train: loss: 0.1779739
[Epoch 48; Iter    91/  157] train: loss: 0.1767737
[Epoch 48; Iter   121/  157] train: loss: 0.1616087
[Epoch 48; Iter   151/  157] train: loss: 0.1831657
[Epoch 48] ogbg-moltox21: 0.821047 val loss: 0.281889
[Epoch 48] ogbg-moltox21: 0.835510 test loss: 0.208550
[Epoch 49; Iter    24/  157] train: loss: 0.2143975
[Epoch 49; Iter    54/  157] train: loss: 0.1896422
[Epoch 49; Iter    84/  157] train: loss: 0.0991228
[Epoch 49; Iter   114/  157] train: loss: 0.1210522
[Epoch 49; Iter   144/  157] train: loss: 0.1154141
[Epoch 49] ogbg-moltox21: 0.830996 val loss: 0.244917
[Epoch 49] ogbg-moltox21: 0.845569 test loss: 0.205107
[Epoch 50; Iter    17/  157] train: loss: 0.1271576
[Epoch 50; Iter    47/  157] train: loss: 0.1589919
[Epoch 50; Iter    77/  157] train: loss: 0.1256844
[Epoch 50; Iter   107/  157] train: loss: 0.0777570
[Epoch 50; Iter   137/  157] train: loss: 0.2729973
[Epoch 50] ogbg-moltox21: 0.828132 val loss: 0.253668
[Epoch 50] ogbg-moltox21: 0.844103 test loss: 0.207050
[Epoch 51; Iter    10/  157] train: loss: 0.2570478
[Epoch 51; Iter    40/  157] train: loss: 0.1610656
[Epoch 51; Iter    70/  157] train: loss: 0.0932280
[Epoch 51; Iter   100/  157] train: loss: 0.0683975
[Epoch 51; Iter   130/  157] train: loss: 0.1342533
[Epoch 51] ogbg-moltox21: 0.826697 val loss: 0.227304
[Epoch 51] ogbg-moltox21: 0.839890 test loss: 0.205891
[Epoch 52; Iter     3/  157] train: loss: 0.1183467
[Epoch 52; Iter    33/  157] train: loss: 0.1755419
[Epoch 52; Iter    63/  157] train: loss: 0.0986913
[Epoch 52; Iter    93/  157] train: loss: 0.1337444
[Epoch 52; Iter   123/  157] train: loss: 0.1577806
[Epoch 52; Iter   153/  157] train: loss: 0.1606937
[Epoch 52] ogbg-moltox21: 0.826595 val loss: 0.215442
[Epoch 52] ogbg-moltox21: 0.835613 test loss: 0.210333
[Epoch 53; Iter    26/  157] train: loss: 0.1097477
[Epoch 53; Iter    56/  157] train: loss: 0.1783136
[Epoch 53; Iter    86/  157] train: loss: 0.1208940
[Epoch 53; Iter   116/  157] train: loss: 0.0881216
[Epoch 53; Iter   146/  157] train: loss: 0.1856795
[Epoch 53] ogbg-moltox21: 0.820541 val loss: 0.237090
[Epoch 53] ogbg-moltox21: 0.827567 test loss: 0.213016
[Epoch 54; Iter    19/  157] train: loss: 0.1365091
[Epoch 54; Iter    49/  157] train: loss: 0.1266133
[Epoch 54; Iter    79/  157] train: loss: 0.0913318
[Epoch 54; Iter   109/  157] train: loss: 0.0967306
[Epoch 54; Iter   139/  157] train: loss: 0.1019473
[Epoch 54] ogbg-moltox21: 0.824372 val loss: 0.210056
[Epoch 54] ogbg-moltox21: 0.840207 test loss: 0.210025
[Epoch 55; Iter    12/  157] train: loss: 0.0904431
[Epoch 55; Iter    42/  157] train: loss: 0.1720785
[Epoch 55; Iter    72/  157] train: loss: 0.1358979
[Epoch 55; Iter   102/  157] train: loss: 0.1880386
[Epoch 55; Iter   132/  157] train: loss: 0.1711966
[Epoch 55] ogbg-moltox21: 0.823503 val loss: 0.201682
[Epoch 55] ogbg-moltox21: 0.838654 test loss: 0.212487
[Epoch 56; Iter     5/  157] train: loss: 0.1708675
[Epoch 56; Iter    35/  157] train: loss: 0.1035019
[Epoch 56; Iter    65/  157] train: loss: 0.1057827
[Epoch 56; Iter    95/  157] train: loss: 0.1266286
[Epoch 56; Iter   125/  157] train: loss: 0.0859959
[Epoch 56; Iter   155/  157] train: loss: 0.1107518
[Epoch 56] ogbg-moltox21: 0.821604 val loss: 0.200237
[Epoch 56] ogbg-moltox21: 0.833136 test loss: 0.214425
[Epoch 57; Iter    28/  157] train: loss: 0.1402453
[Epoch 57; Iter    58/  157] train: loss: 0.1651231
[Epoch 57; Iter    88/  157] train: loss: 0.1068899
[Epoch 57; Iter   118/  157] train: loss: 0.1792332
[Epoch 57; Iter   148/  157] train: loss: 0.0809950
[Epoch 57] ogbg-moltox21: 0.816088 val loss: 0.205030
[Epoch 57] ogbg-moltox21: 0.832564 test loss: 0.216155
[Epoch 58; Iter    21/  157] train: loss: 0.1317246
[Epoch 58; Iter    51/  157] train: loss: 0.1018013
[Epoch 58; Iter    81/  157] train: loss: 0.1428902
[Epoch 58; Iter   111/  157] train: loss: 0.0739521
[Epoch 58; Iter   141/  157] train: loss: 0.1372589
[Epoch 37; Iter    78/  157] train: loss: 0.2002499
[Epoch 37; Iter   108/  157] train: loss: 0.1910006
[Epoch 37; Iter   138/  157] train: loss: 0.1978567
[Epoch 37] ogbg-moltox21: 0.821662 val loss: 0.238036
[Epoch 37] ogbg-moltox21: 0.834983 test loss: 0.307950
[Epoch 38; Iter    11/  157] train: loss: 0.1550718
[Epoch 38; Iter    41/  157] train: loss: 0.2029372
[Epoch 38; Iter    71/  157] train: loss: 0.2027617
[Epoch 38; Iter   101/  157] train: loss: 0.2369396
[Epoch 38; Iter   131/  157] train: loss: 0.1218018
[Epoch 38] ogbg-moltox21: 0.828910 val loss: 0.188846
[Epoch 38] ogbg-moltox21: 0.836779 test loss: 0.205715
[Epoch 39; Iter     4/  157] train: loss: 0.1373805
[Epoch 39; Iter    34/  157] train: loss: 0.1582945
[Epoch 39; Iter    64/  157] train: loss: 0.1461555
[Epoch 39; Iter    94/  157] train: loss: 0.1955888
[Epoch 39; Iter   124/  157] train: loss: 0.1361961
[Epoch 39; Iter   154/  157] train: loss: 0.1833476
[Epoch 39] ogbg-moltox21: 0.827288 val loss: 0.267236
[Epoch 39] ogbg-moltox21: 0.836781 test loss: 0.371412
[Epoch 40; Iter    27/  157] train: loss: 0.2084040
[Epoch 40; Iter    57/  157] train: loss: 0.1393201
[Epoch 40; Iter    87/  157] train: loss: 0.1417731
[Epoch 40; Iter   117/  157] train: loss: 0.2611564
[Epoch 40; Iter   147/  157] train: loss: 0.1733127
[Epoch 40] ogbg-moltox21: 0.833581 val loss: 0.185037
[Epoch 40] ogbg-moltox21: 0.835376 test loss: 0.369618
[Epoch 41; Iter    20/  157] train: loss: 0.1132897
[Epoch 41; Iter    50/  157] train: loss: 0.2598657
[Epoch 41; Iter    80/  157] train: loss: 0.2345078
[Epoch 41; Iter   110/  157] train: loss: 0.1841123
[Epoch 41; Iter   140/  157] train: loss: 0.1646035
[Epoch 41] ogbg-moltox21: 0.834404 val loss: 0.213334
[Epoch 41] ogbg-moltox21: 0.835416 test loss: 0.345196
[Epoch 42; Iter    13/  157] train: loss: 0.1048448
[Epoch 42; Iter    43/  157] train: loss: 0.2272705
[Epoch 42; Iter    73/  157] train: loss: 0.1533415
[Epoch 42; Iter   103/  157] train: loss: 0.1473681
[Epoch 42; Iter   133/  157] train: loss: 0.2086661
[Epoch 42] ogbg-moltox21: 0.837266 val loss: 0.228328
[Epoch 42] ogbg-moltox21: 0.842082 test loss: 0.301270
[Epoch 43; Iter     6/  157] train: loss: 0.0835823
[Epoch 43; Iter    36/  157] train: loss: 0.1669481
[Epoch 43; Iter    66/  157] train: loss: 0.1485340
[Epoch 43; Iter    96/  157] train: loss: 0.1641715
[Epoch 43; Iter   126/  157] train: loss: 0.2346210
[Epoch 43; Iter   156/  157] train: loss: 0.1138184
[Epoch 43] ogbg-moltox21: 0.839032 val loss: 0.209550
[Epoch 43] ogbg-moltox21: 0.842211 test loss: 0.254065
[Epoch 44; Iter    29/  157] train: loss: 0.1482836
[Epoch 44; Iter    59/  157] train: loss: 0.1165445
[Epoch 44; Iter    89/  157] train: loss: 0.1838607
[Epoch 44; Iter   119/  157] train: loss: 0.1734522
[Epoch 44; Iter   149/  157] train: loss: 0.1951345
[Epoch 44] ogbg-moltox21: 0.836751 val loss: 0.188327
[Epoch 44] ogbg-moltox21: 0.840574 test loss: 0.298877
[Epoch 45; Iter    22/  157] train: loss: 0.2189603
[Epoch 45; Iter    52/  157] train: loss: 0.1598152
[Epoch 45; Iter    82/  157] train: loss: 0.1978944
[Epoch 45; Iter   112/  157] train: loss: 0.1079653
[Epoch 45; Iter   142/  157] train: loss: 0.1694141
[Epoch 45] ogbg-moltox21: 0.838580 val loss: 0.245809
[Epoch 45] ogbg-moltox21: 0.843849 test loss: 0.368451
[Epoch 46; Iter    15/  157] train: loss: 0.1341942
[Epoch 46; Iter    45/  157] train: loss: 0.2768394
[Epoch 46; Iter    75/  157] train: loss: 0.3019854
[Epoch 46; Iter   105/  157] train: loss: 0.2339459
[Epoch 46; Iter   135/  157] train: loss: 0.1442081
[Epoch 46] ogbg-moltox21: 0.840364 val loss: 0.215909
[Epoch 46] ogbg-moltox21: 0.839973 test loss: 0.355984
[Epoch 47; Iter     8/  157] train: loss: 0.1785744
[Epoch 47; Iter    38/  157] train: loss: 0.1489333
[Epoch 47; Iter    68/  157] train: loss: 0.1169040
[Epoch 47; Iter    98/  157] train: loss: 0.1193598
[Epoch 47; Iter   128/  157] train: loss: 0.1344391
[Epoch 47] ogbg-moltox21: 0.836365 val loss: 0.317425
[Epoch 47] ogbg-moltox21: 0.844145 test loss: 0.429207
[Epoch 48; Iter     1/  157] train: loss: 0.0821641
[Epoch 48; Iter    31/  157] train: loss: 0.1304551
[Epoch 48; Iter    61/  157] train: loss: 0.2422021
[Epoch 48; Iter    91/  157] train: loss: 0.1186312
[Epoch 48; Iter   121/  157] train: loss: 0.2952224
[Epoch 48; Iter   151/  157] train: loss: 0.2314970
[Epoch 48] ogbg-moltox21: 0.840850 val loss: 0.191230
[Epoch 48] ogbg-moltox21: 0.847562 test loss: 0.305462
[Epoch 49; Iter    24/  157] train: loss: 0.1352335
[Epoch 49; Iter    54/  157] train: loss: 0.2358833
[Epoch 49; Iter    84/  157] train: loss: 0.1461725
[Epoch 49; Iter   114/  157] train: loss: 0.2053594
[Epoch 49; Iter   144/  157] train: loss: 0.2075070
[Epoch 49] ogbg-moltox21: 0.833913 val loss: 0.289166
[Epoch 49] ogbg-moltox21: 0.844202 test loss: 0.512906
[Epoch 50; Iter    17/  157] train: loss: 0.1964900
[Epoch 50; Iter    47/  157] train: loss: 0.1337786
[Epoch 50; Iter    77/  157] train: loss: 0.1892471
[Epoch 50; Iter   107/  157] train: loss: 0.1496399
[Epoch 50; Iter   137/  157] train: loss: 0.1374980
[Epoch 50] ogbg-moltox21: 0.837257 val loss: 0.188344
[Epoch 50] ogbg-moltox21: 0.848274 test loss: 0.229027
[Epoch 51; Iter    10/  157] train: loss: 0.2004613
[Epoch 51; Iter    40/  157] train: loss: 0.1397614
[Epoch 51; Iter    70/  157] train: loss: 0.2063131
[Epoch 51; Iter   100/  157] train: loss: 0.0922093
[Epoch 51; Iter   130/  157] train: loss: 0.1663461
[Epoch 51] ogbg-moltox21: 0.837199 val loss: 0.185547
[Epoch 51] ogbg-moltox21: 0.845314 test loss: 0.238827
[Epoch 52; Iter     3/  157] train: loss: 0.1879593
[Epoch 52; Iter    33/  157] train: loss: 0.2554512
[Epoch 52; Iter    63/  157] train: loss: 0.1527686
[Epoch 52; Iter    93/  157] train: loss: 0.1551902
[Epoch 52; Iter   123/  157] train: loss: 0.0958498
[Epoch 52; Iter   153/  157] train: loss: 0.2312085
[Epoch 52] ogbg-moltox21: 0.830852 val loss: 0.193546
[Epoch 52] ogbg-moltox21: 0.839553 test loss: 0.223954
[Epoch 53; Iter    26/  157] train: loss: 0.1483578
[Epoch 53; Iter    56/  157] train: loss: 0.1317625
[Epoch 53; Iter    86/  157] train: loss: 0.0949351
[Epoch 53; Iter   116/  157] train: loss: 0.1318585
[Epoch 53; Iter   146/  157] train: loss: 0.1680714
[Epoch 53] ogbg-moltox21: 0.824530 val loss: 0.270075
[Epoch 53] ogbg-moltox21: 0.835084 test loss: 0.252358
[Epoch 54; Iter    19/  157] train: loss: 0.1940123
[Epoch 54; Iter    49/  157] train: loss: 0.1815467
[Epoch 54; Iter    79/  157] train: loss: 0.1500976
[Epoch 54; Iter   109/  157] train: loss: 0.1519374
[Epoch 54; Iter   139/  157] train: loss: 0.0958095
[Epoch 54] ogbg-moltox21: 0.838055 val loss: 0.199635
[Epoch 54] ogbg-moltox21: 0.846011 test loss: 0.253669
[Epoch 55; Iter    12/  157] train: loss: 0.1498741
[Epoch 55; Iter    42/  157] train: loss: 0.2324430
[Epoch 55; Iter    72/  157] train: loss: 0.1621830
[Epoch 55; Iter   102/  157] train: loss: 0.1135406
[Epoch 55; Iter   132/  157] train: loss: 0.0987769
[Epoch 55] ogbg-moltox21: 0.835755 val loss: 0.185578
[Epoch 55] ogbg-moltox21: 0.843612 test loss: 0.260877
[Epoch 56; Iter     5/  157] train: loss: 0.1338498
[Epoch 56; Iter    35/  157] train: loss: 0.0996375
[Epoch 56; Iter    65/  157] train: loss: 0.1335563
[Epoch 56; Iter    95/  157] train: loss: 0.1455420
[Epoch 56; Iter   125/  157] train: loss: 0.1183571
[Epoch 56; Iter   155/  157] train: loss: 0.1180082
[Epoch 56] ogbg-moltox21: 0.835398 val loss: 0.266469
[Epoch 56] ogbg-moltox21: 0.836794 test loss: 0.369208
[Epoch 57; Iter    28/  157] train: loss: 0.1207326
[Epoch 57; Iter    58/  157] train: loss: 0.1583502
[Epoch 57; Iter    88/  157] train: loss: 0.1544502
[Epoch 57; Iter   118/  157] train: loss: 0.1791532
[Epoch 57; Iter   148/  157] train: loss: 0.0969414
[Epoch 57] ogbg-moltox21: 0.831571 val loss: 0.501446
[Epoch 57] ogbg-moltox21: 0.832028 test loss: 0.286636
[Epoch 58; Iter    21/  157] train: loss: 0.1377857
[Epoch 58; Iter    51/  157] train: loss: 0.1355556
[Epoch 58; Iter    81/  157] train: loss: 0.1429287
[Epoch 58; Iter   111/  157] train: loss: 0.0985248
[Epoch 58; Iter   141/  157] train: loss: 0.1089644
[Epoch 37; Iter    78/  157] train: loss: 0.1475639
[Epoch 37; Iter   108/  157] train: loss: 0.1511737
[Epoch 37; Iter   138/  157] train: loss: 0.1579138
[Epoch 37] ogbg-moltox21: 0.808091 val loss: 0.509350
[Epoch 37] ogbg-moltox21: 0.799760 test loss: 0.415812
[Epoch 38; Iter    11/  157] train: loss: 0.2107226
[Epoch 38; Iter    41/  157] train: loss: 0.1081626
[Epoch 38; Iter    71/  157] train: loss: 0.1324744
[Epoch 38; Iter   101/  157] train: loss: 0.1261404
[Epoch 38; Iter   131/  157] train: loss: 0.1306790
[Epoch 38] ogbg-moltox21: 0.828829 val loss: 0.265504
[Epoch 38] ogbg-moltox21: 0.837054 test loss: 0.222207
[Epoch 39; Iter     4/  157] train: loss: 0.1177285
[Epoch 39; Iter    34/  157] train: loss: 0.1499697
[Epoch 39; Iter    64/  157] train: loss: 0.1125975
[Epoch 39; Iter    94/  157] train: loss: 0.1298036
[Epoch 39; Iter   124/  157] train: loss: 0.1994479
[Epoch 39; Iter   154/  157] train: loss: 0.1650918
[Epoch 39] ogbg-moltox21: 0.842508 val loss: 0.180374
[Epoch 39] ogbg-moltox21: 0.845306 test loss: 0.196493
[Epoch 40; Iter    27/  157] train: loss: 0.1134968
[Epoch 40; Iter    57/  157] train: loss: 0.1202322
[Epoch 40; Iter    87/  157] train: loss: 0.1654431
[Epoch 40; Iter   117/  157] train: loss: 0.2809022
[Epoch 40; Iter   147/  157] train: loss: 0.1381026
[Epoch 40] ogbg-moltox21: 0.833490 val loss: 0.198403
[Epoch 40] ogbg-moltox21: 0.839752 test loss: 0.210196
[Epoch 41; Iter    20/  157] train: loss: 0.1253968
[Epoch 41; Iter    50/  157] train: loss: 0.1041253
[Epoch 41; Iter    80/  157] train: loss: 0.1896876
[Epoch 41; Iter   110/  157] train: loss: 0.1282720
[Epoch 41; Iter   140/  157] train: loss: 0.1112528
[Epoch 41] ogbg-moltox21: 0.840146 val loss: 0.183637
[Epoch 41] ogbg-moltox21: 0.843934 test loss: 0.197828
[Epoch 42; Iter    13/  157] train: loss: 0.1544998
[Epoch 42; Iter    43/  157] train: loss: 0.0686733
[Epoch 42; Iter    73/  157] train: loss: 0.2574194
[Epoch 42; Iter   103/  157] train: loss: 0.1160560
[Epoch 42; Iter   133/  157] train: loss: 0.1220458
[Epoch 42] ogbg-moltox21: 0.835019 val loss: 0.184046
[Epoch 42] ogbg-moltox21: 0.835394 test loss: 0.240129
[Epoch 43; Iter     6/  157] train: loss: 0.1231673
[Epoch 43; Iter    36/  157] train: loss: 0.0700739
[Epoch 43; Iter    66/  157] train: loss: 0.1210315
[Epoch 43; Iter    96/  157] train: loss: 0.1880052
[Epoch 43; Iter   126/  157] train: loss: 0.1173701
[Epoch 43; Iter   156/  157] train: loss: 0.1397569
[Epoch 43] ogbg-moltox21: 0.841342 val loss: 0.186846
[Epoch 43] ogbg-moltox21: 0.842839 test loss: 0.208420
[Epoch 44; Iter    29/  157] train: loss: 0.0980785
[Epoch 44; Iter    59/  157] train: loss: 0.1641110
[Epoch 44; Iter    89/  157] train: loss: 0.2331065
[Epoch 44; Iter   119/  157] train: loss: 0.0800850
[Epoch 44; Iter   149/  157] train: loss: 0.1853799
[Epoch 44] ogbg-moltox21: 0.839482 val loss: 0.182330
[Epoch 44] ogbg-moltox21: 0.837349 test loss: 0.199962
[Epoch 45; Iter    22/  157] train: loss: 0.1491423
[Epoch 45; Iter    52/  157] train: loss: 0.1369571
[Epoch 45; Iter    82/  157] train: loss: 0.2231240
[Epoch 45; Iter   112/  157] train: loss: 0.1595522
[Epoch 45; Iter   142/  157] train: loss: 0.0800754
[Epoch 45] ogbg-moltox21: 0.836428 val loss: 0.184109
[Epoch 45] ogbg-moltox21: 0.835187 test loss: 0.205217
[Epoch 46; Iter    15/  157] train: loss: 0.1266238
[Epoch 46; Iter    45/  157] train: loss: 0.1207437
[Epoch 46; Iter    75/  157] train: loss: 0.1414147
[Epoch 46; Iter   105/  157] train: loss: 0.0839438
[Epoch 46; Iter   135/  157] train: loss: 0.1955829
[Epoch 46] ogbg-moltox21: 0.839531 val loss: 0.192825
[Epoch 46] ogbg-moltox21: 0.843685 test loss: 0.248989
[Epoch 47; Iter     8/  157] train: loss: 0.1273021
[Epoch 47; Iter    38/  157] train: loss: 0.1103180
[Epoch 47; Iter    68/  157] train: loss: 0.1228330
[Epoch 47; Iter    98/  157] train: loss: 0.0961347
[Epoch 47; Iter   128/  157] train: loss: 0.1462543
[Epoch 47] ogbg-moltox21: 0.840890 val loss: 0.186161
[Epoch 47] ogbg-moltox21: 0.838471 test loss: 0.237073
[Epoch 48; Iter     1/  157] train: loss: 0.2614554
[Epoch 48; Iter    31/  157] train: loss: 0.0843091
[Epoch 48; Iter    61/  157] train: loss: 0.0982290
[Epoch 48; Iter    91/  157] train: loss: 0.1827363
[Epoch 48; Iter   121/  157] train: loss: 0.1279212
[Epoch 48; Iter   151/  157] train: loss: 0.1277605
[Epoch 48] ogbg-moltox21: 0.838469 val loss: 0.196605
[Epoch 48] ogbg-moltox21: 0.831853 test loss: 0.239346
[Epoch 49; Iter    24/  157] train: loss: 0.1190546
[Epoch 49; Iter    54/  157] train: loss: 0.1340479
[Epoch 49; Iter    84/  157] train: loss: 0.1341401
[Epoch 49; Iter   114/  157] train: loss: 0.1100942
[Epoch 49; Iter   144/  157] train: loss: 0.1367693
[Epoch 49] ogbg-moltox21: 0.841874 val loss: 0.187074
[Epoch 49] ogbg-moltox21: 0.835694 test loss: 0.213337
[Epoch 50; Iter    17/  157] train: loss: 0.0999015
[Epoch 50; Iter    47/  157] train: loss: 0.1832976
[Epoch 50; Iter    77/  157] train: loss: 0.1621681
[Epoch 50; Iter   107/  157] train: loss: 0.0821840
[Epoch 50; Iter   137/  157] train: loss: 0.0952800
[Epoch 50] ogbg-moltox21: 0.833061 val loss: 0.191218
[Epoch 50] ogbg-moltox21: 0.827543 test loss: 0.218555
[Epoch 51; Iter    10/  157] train: loss: 0.1365657
[Epoch 51; Iter    40/  157] train: loss: 0.1087169
[Epoch 51; Iter    70/  157] train: loss: 0.0957707
[Epoch 51; Iter   100/  157] train: loss: 0.1059335
[Epoch 51; Iter   130/  157] train: loss: 0.1893799
[Epoch 51] ogbg-moltox21: 0.831392 val loss: 0.187885
[Epoch 51] ogbg-moltox21: 0.831742 test loss: 0.208857
[Epoch 52; Iter     3/  157] train: loss: 0.1512559
[Epoch 52; Iter    33/  157] train: loss: 0.1269776
[Epoch 52; Iter    63/  157] train: loss: 0.1012006
[Epoch 52; Iter    93/  157] train: loss: 0.1168030
[Epoch 52; Iter   123/  157] train: loss: 0.0979650
[Epoch 52; Iter   153/  157] train: loss: 0.1223751
[Epoch 52] ogbg-moltox21: 0.829175 val loss: 0.193274
[Epoch 52] ogbg-moltox21: 0.836311 test loss: 0.211988
[Epoch 53; Iter    26/  157] train: loss: 0.1083260
[Epoch 53; Iter    56/  157] train: loss: 0.0760429
[Epoch 53; Iter    86/  157] train: loss: 0.1622861
[Epoch 53; Iter   116/  157] train: loss: 0.0784522
[Epoch 53; Iter   146/  157] train: loss: 0.1120521
[Epoch 53] ogbg-moltox21: 0.834582 val loss: 0.200953
[Epoch 53] ogbg-moltox21: 0.832850 test loss: 0.230090
[Epoch 54; Iter    19/  157] train: loss: 0.1531651
[Epoch 54; Iter    49/  157] train: loss: 0.0827656
[Epoch 54; Iter    79/  157] train: loss: 0.1067326
[Epoch 54; Iter   109/  157] train: loss: 0.1220092
[Epoch 54; Iter   139/  157] train: loss: 0.0701644
[Epoch 54] ogbg-moltox21: 0.837302 val loss: 0.190473
[Epoch 54] ogbg-moltox21: 0.835519 test loss: 0.222752
[Epoch 55; Iter    12/  157] train: loss: 0.1291875
[Epoch 55; Iter    42/  157] train: loss: 0.0847751
[Epoch 55; Iter    72/  157] train: loss: 0.1597844
[Epoch 55; Iter   102/  157] train: loss: 0.0971502
[Epoch 55; Iter   132/  157] train: loss: 0.1906261
[Epoch 55] ogbg-moltox21: 0.833071 val loss: 0.190321
[Epoch 55] ogbg-moltox21: 0.830455 test loss: 0.211564
[Epoch 56; Iter     5/  157] train: loss: 0.1081069
[Epoch 56; Iter    35/  157] train: loss: 0.1233380
[Epoch 56; Iter    65/  157] train: loss: 0.1199534
[Epoch 56; Iter    95/  157] train: loss: 0.0704787
[Epoch 56; Iter   125/  157] train: loss: 0.1113713
[Epoch 56; Iter   155/  157] train: loss: 0.1188591
[Epoch 56] ogbg-moltox21: 0.836301 val loss: 0.192226
[Epoch 56] ogbg-moltox21: 0.829431 test loss: 0.221030
[Epoch 57; Iter    28/  157] train: loss: 0.0813184
[Epoch 57; Iter    58/  157] train: loss: 0.0939482
[Epoch 57; Iter    88/  157] train: loss: 0.1454451
[Epoch 57; Iter   118/  157] train: loss: 0.1696205
[Epoch 57; Iter   148/  157] train: loss: 0.1116913
[Epoch 57] ogbg-moltox21: 0.836231 val loss: 0.202344
[Epoch 57] ogbg-moltox21: 0.839144 test loss: 0.251796
[Epoch 58; Iter    21/  157] train: loss: 0.1402272
[Epoch 58; Iter    51/  157] train: loss: 0.0870637
[Epoch 58; Iter    81/  157] train: loss: 0.1078962
[Epoch 58; Iter   111/  157] train: loss: 0.0896448
[Epoch 58; Iter   141/  157] train: loss: 0.0729353
[Epoch 47; Iter   166/  209] train: loss: 0.2009636
[Epoch 47; Iter   196/  209] train: loss: 0.1219856
[Epoch 47] ogbg-moltox21: 0.848271 val loss: 0.216122
[Epoch 47] ogbg-moltox21: 0.843592 test loss: 0.197945
[Epoch 48; Iter    17/  209] train: loss: 0.1779778
[Epoch 48; Iter    47/  209] train: loss: 0.1631436
[Epoch 48; Iter    77/  209] train: loss: 0.1186539
[Epoch 48; Iter   107/  209] train: loss: 0.1002825
[Epoch 48; Iter   137/  209] train: loss: 0.1240008
[Epoch 48; Iter   167/  209] train: loss: 0.1153206
[Epoch 48; Iter   197/  209] train: loss: 0.1452285
[Epoch 48] ogbg-moltox21: 0.857228 val loss: 0.209554
[Epoch 48] ogbg-moltox21: 0.856206 test loss: 0.190289
[Epoch 49; Iter    18/  209] train: loss: 0.1548896
[Epoch 49; Iter    48/  209] train: loss: 0.1582568
[Epoch 49; Iter    78/  209] train: loss: 0.1121540
[Epoch 49; Iter   108/  209] train: loss: 0.0788323
[Epoch 49; Iter   138/  209] train: loss: 0.1153041
[Epoch 49; Iter   168/  209] train: loss: 0.1862246
[Epoch 49; Iter   198/  209] train: loss: 0.0922181
[Epoch 49] ogbg-moltox21: 0.861477 val loss: 0.208457
[Epoch 49] ogbg-moltox21: 0.853886 test loss: 0.195973
[Epoch 50; Iter    19/  209] train: loss: 0.1518851
[Epoch 50; Iter    49/  209] train: loss: 0.1623202
[Epoch 50; Iter    79/  209] train: loss: 0.1613205
[Epoch 50; Iter   109/  209] train: loss: 0.0828745
[Epoch 50; Iter   139/  209] train: loss: 0.0949598
[Epoch 50; Iter   169/  209] train: loss: 0.1576748
[Epoch 50; Iter   199/  209] train: loss: 0.1320249
[Epoch 50] ogbg-moltox21: 0.860564 val loss: 0.209733
[Epoch 50] ogbg-moltox21: 0.847025 test loss: 0.197092
[Epoch 51; Iter    20/  209] train: loss: 0.0927765
[Epoch 51; Iter    50/  209] train: loss: 0.1456441
[Epoch 51; Iter    80/  209] train: loss: 0.0849212
[Epoch 51; Iter   110/  209] train: loss: 0.1387428
[Epoch 51; Iter   140/  209] train: loss: 0.1588374
[Epoch 51; Iter   170/  209] train: loss: 0.1673134
[Epoch 51; Iter   200/  209] train: loss: 0.1480455
[Epoch 51] ogbg-moltox21: 0.856669 val loss: 0.209984
[Epoch 51] ogbg-moltox21: 0.841381 test loss: 0.207621
[Epoch 52; Iter    21/  209] train: loss: 0.1056909
[Epoch 52; Iter    51/  209] train: loss: 0.1271300
[Epoch 52; Iter    81/  209] train: loss: 0.0975814
[Epoch 52; Iter   111/  209] train: loss: 0.1124209
[Epoch 52; Iter   141/  209] train: loss: 0.1154190
[Epoch 52; Iter   171/  209] train: loss: 0.0878693
[Epoch 52; Iter   201/  209] train: loss: 0.1209518
[Epoch 52] ogbg-moltox21: 0.843127 val loss: 0.226931
[Epoch 52] ogbg-moltox21: 0.841643 test loss: 0.206835
[Epoch 53; Iter    22/  209] train: loss: 0.1089469
[Epoch 53; Iter    52/  209] train: loss: 0.0973032
[Epoch 53; Iter    82/  209] train: loss: 0.1303933
[Epoch 53; Iter   112/  209] train: loss: 0.2172362
[Epoch 53; Iter   142/  209] train: loss: 0.0616950
[Epoch 53; Iter   172/  209] train: loss: 0.1414786
[Epoch 53; Iter   202/  209] train: loss: 0.0859595
[Epoch 53] ogbg-moltox21: 0.852173 val loss: 0.220336
[Epoch 53] ogbg-moltox21: 0.845906 test loss: 0.202203
[Epoch 54; Iter    23/  209] train: loss: 0.1030807
[Epoch 54; Iter    53/  209] train: loss: 0.0774632
[Epoch 54; Iter    83/  209] train: loss: 0.1440693
[Epoch 54; Iter   113/  209] train: loss: 0.1288597
[Epoch 54; Iter   143/  209] train: loss: 0.0840506
[Epoch 54; Iter   173/  209] train: loss: 0.1198133
[Epoch 54; Iter   203/  209] train: loss: 0.1004595
[Epoch 54] ogbg-moltox21: 0.846952 val loss: 0.221554
[Epoch 54] ogbg-moltox21: 0.835999 test loss: 0.213077
[Epoch 55; Iter    24/  209] train: loss: 0.1074484
[Epoch 55; Iter    54/  209] train: loss: 0.1058326
[Epoch 55; Iter    84/  209] train: loss: 0.1127210
[Epoch 55; Iter   114/  209] train: loss: 0.1488753
[Epoch 55; Iter   144/  209] train: loss: 0.1275459
[Epoch 55; Iter   174/  209] train: loss: 0.1011763
[Epoch 55; Iter   204/  209] train: loss: 0.1568321
[Epoch 55] ogbg-moltox21: 0.850410 val loss: 0.212371
[Epoch 55] ogbg-moltox21: 0.835334 test loss: 0.216961
[Epoch 56; Iter    25/  209] train: loss: 0.1145651
[Epoch 56; Iter    55/  209] train: loss: 0.2122144
[Epoch 56; Iter    85/  209] train: loss: 0.1102825
[Epoch 56; Iter   115/  209] train: loss: 0.1491660
[Epoch 56; Iter   145/  209] train: loss: 0.0917771
[Epoch 56; Iter   175/  209] train: loss: 0.1327720
[Epoch 56; Iter   205/  209] train: loss: 0.1029298
[Epoch 56] ogbg-moltox21: 0.843947 val loss: 0.225614
[Epoch 56] ogbg-moltox21: 0.838645 test loss: 0.221739
[Epoch 57; Iter    26/  209] train: loss: 0.0711321
[Epoch 57; Iter    56/  209] train: loss: 0.1194258
[Epoch 57; Iter    86/  209] train: loss: 0.0727628
[Epoch 57; Iter   116/  209] train: loss: 0.0920808
[Epoch 57; Iter   146/  209] train: loss: 0.0785447
[Epoch 57; Iter   176/  209] train: loss: 0.1006691
[Epoch 57; Iter   206/  209] train: loss: 0.1212275
[Epoch 57] ogbg-moltox21: 0.849126 val loss: 0.224527
[Epoch 57] ogbg-moltox21: 0.840890 test loss: 0.216351
[Epoch 58; Iter    27/  209] train: loss: 0.0763658
[Epoch 58; Iter    57/  209] train: loss: 0.0686912
[Epoch 58; Iter    87/  209] train: loss: 0.1068930
[Epoch 58; Iter   117/  209] train: loss: 0.1331826
[Epoch 58; Iter   147/  209] train: loss: 0.1100370
[Epoch 58; Iter   177/  209] train: loss: 0.1308417
[Epoch 58; Iter   207/  209] train: loss: 0.0983851
[Epoch 58] ogbg-moltox21: 0.855601 val loss: 0.228557
[Epoch 58] ogbg-moltox21: 0.855734 test loss: 0.205733
[Epoch 59; Iter    28/  209] train: loss: 0.0866029
[Epoch 59; Iter    58/  209] train: loss: 0.0920571
[Epoch 59; Iter    88/  209] train: loss: 0.0811358
[Epoch 59; Iter   118/  209] train: loss: 0.1237478
[Epoch 59; Iter   148/  209] train: loss: 0.0965647
[Epoch 59; Iter   178/  209] train: loss: 0.0829989
[Epoch 59; Iter   208/  209] train: loss: 0.0719882
[Epoch 59] ogbg-moltox21: 0.857109 val loss: 0.217105
[Epoch 59] ogbg-moltox21: 0.849501 test loss: 0.211751
[Epoch 60; Iter    29/  209] train: loss: 0.0840243
[Epoch 60; Iter    59/  209] train: loss: 0.1117637
[Epoch 60; Iter    89/  209] train: loss: 0.1294154
[Epoch 60; Iter   119/  209] train: loss: 0.0877998
[Epoch 60; Iter   149/  209] train: loss: 0.0894319
[Epoch 60; Iter   179/  209] train: loss: 0.1072648
[Epoch 60; Iter   209/  209] train: loss: 0.1040591
[Epoch 60] ogbg-moltox21: 0.849412 val loss: 0.222054
[Epoch 60] ogbg-moltox21: 0.844011 test loss: 0.211222
[Epoch 61; Iter    30/  209] train: loss: 0.1094294
[Epoch 61; Iter    60/  209] train: loss: 0.0828457
[Epoch 61; Iter    90/  209] train: loss: 0.1133078
[Epoch 61; Iter   120/  209] train: loss: 0.0986450
[Epoch 61; Iter   150/  209] train: loss: 0.1375022
[Epoch 61; Iter   180/  209] train: loss: 0.1410334
[Epoch 61] ogbg-moltox21: 0.845551 val loss: 0.235162
[Epoch 61] ogbg-moltox21: 0.843454 test loss: 0.223880
[Epoch 62; Iter     1/  209] train: loss: 0.0819733
[Epoch 62; Iter    31/  209] train: loss: 0.1461241
[Epoch 62; Iter    61/  209] train: loss: 0.1266942
[Epoch 62; Iter    91/  209] train: loss: 0.0926697
[Epoch 62; Iter   121/  209] train: loss: 0.0888305
[Epoch 62; Iter   151/  209] train: loss: 0.1117127
[Epoch 62; Iter   181/  209] train: loss: 0.1054812
[Epoch 62] ogbg-moltox21: 0.858176 val loss: 0.216350
[Epoch 62] ogbg-moltox21: 0.834381 test loss: 0.221094
[Epoch 63; Iter     2/  209] train: loss: 0.1306253
[Epoch 63; Iter    32/  209] train: loss: 0.0760141
[Epoch 63; Iter    62/  209] train: loss: 0.0585547
[Epoch 63; Iter    92/  209] train: loss: 0.0766923
[Epoch 63; Iter   122/  209] train: loss: 0.0735665
[Epoch 63; Iter   152/  209] train: loss: 0.1038413
[Epoch 63; Iter   182/  209] train: loss: 0.0761853
[Epoch 63] ogbg-moltox21: 0.854694 val loss: 0.230027
[Epoch 63] ogbg-moltox21: 0.848701 test loss: 0.216426
[Epoch 64; Iter     3/  209] train: loss: 0.0931739
[Epoch 64; Iter    33/  209] train: loss: 0.0950720
[Epoch 64; Iter    63/  209] train: loss: 0.1046102
[Epoch 64; Iter    93/  209] train: loss: 0.0503142
[Epoch 64; Iter   123/  209] train: loss: 0.0819632
[Epoch 64; Iter   153/  209] train: loss: 0.1042580
[Epoch 64; Iter   183/  209] train: loss: 0.0784963
[Epoch 64] ogbg-moltox21: 0.852558 val loss: 0.230923
[Epoch 47; Iter   166/  209] train: loss: 0.1550845
[Epoch 47; Iter   196/  209] train: loss: 0.0710420
[Epoch 47] ogbg-moltox21: 0.855547 val loss: 0.203793
[Epoch 47] ogbg-moltox21: 0.849492 test loss: 0.192645
[Epoch 48; Iter    17/  209] train: loss: 0.1167219
[Epoch 48; Iter    47/  209] train: loss: 0.1223769
[Epoch 48; Iter    77/  209] train: loss: 0.1734732
[Epoch 48; Iter   107/  209] train: loss: 0.1871454
[Epoch 48; Iter   137/  209] train: loss: 0.1508296
[Epoch 48; Iter   167/  209] train: loss: 0.1201841
[Epoch 48; Iter   197/  209] train: loss: 0.1035653
[Epoch 48] ogbg-moltox21: 0.850562 val loss: 0.208782
[Epoch 48] ogbg-moltox21: 0.840927 test loss: 0.196097
[Epoch 49; Iter    18/  209] train: loss: 0.1229564
[Epoch 49; Iter    48/  209] train: loss: 0.1578717
[Epoch 49; Iter    78/  209] train: loss: 0.0813534
[Epoch 49; Iter   108/  209] train: loss: 0.0814555
[Epoch 49; Iter   138/  209] train: loss: 0.0923607
[Epoch 49; Iter   168/  209] train: loss: 0.0965941
[Epoch 49; Iter   198/  209] train: loss: 0.1176163
[Epoch 49] ogbg-moltox21: 0.857287 val loss: 0.212802
[Epoch 49] ogbg-moltox21: 0.844454 test loss: 0.199426
[Epoch 50; Iter    19/  209] train: loss: 0.0851834
[Epoch 50; Iter    49/  209] train: loss: 0.0886038
[Epoch 50; Iter    79/  209] train: loss: 0.0750796
[Epoch 50; Iter   109/  209] train: loss: 0.1441899
[Epoch 50; Iter   139/  209] train: loss: 0.1058396
[Epoch 50; Iter   169/  209] train: loss: 0.1063888
[Epoch 50; Iter   199/  209] train: loss: 0.1241955
[Epoch 50] ogbg-moltox21: 0.850666 val loss: 0.212693
[Epoch 50] ogbg-moltox21: 0.837661 test loss: 0.206239
[Epoch 51; Iter    20/  209] train: loss: 0.1371910
[Epoch 51; Iter    50/  209] train: loss: 0.1412807
[Epoch 51; Iter    80/  209] train: loss: 0.1778465
[Epoch 51; Iter   110/  209] train: loss: 0.1484234
[Epoch 51; Iter   140/  209] train: loss: 0.1139907
[Epoch 51; Iter   170/  209] train: loss: 0.1796947
[Epoch 51; Iter   200/  209] train: loss: 0.1375906
[Epoch 51] ogbg-moltox21: 0.852733 val loss: 0.217396
[Epoch 51] ogbg-moltox21: 0.847752 test loss: 0.209176
[Epoch 52; Iter    21/  209] train: loss: 0.1359605
[Epoch 52; Iter    51/  209] train: loss: 0.1377845
[Epoch 52; Iter    81/  209] train: loss: 0.2089353
[Epoch 52; Iter   111/  209] train: loss: 0.0783757
[Epoch 52; Iter   141/  209] train: loss: 0.1026312
[Epoch 52; Iter   171/  209] train: loss: 0.0988232
[Epoch 52; Iter   201/  209] train: loss: 0.0914198
[Epoch 52] ogbg-moltox21: 0.855392 val loss: 0.209470
[Epoch 52] ogbg-moltox21: 0.851198 test loss: 0.209788
[Epoch 53; Iter    22/  209] train: loss: 0.1390048
[Epoch 53; Iter    52/  209] train: loss: 0.0844825
[Epoch 53; Iter    82/  209] train: loss: 0.1000317
[Epoch 53; Iter   112/  209] train: loss: 0.1304549
[Epoch 53; Iter   142/  209] train: loss: 0.0711267
[Epoch 53; Iter   172/  209] train: loss: 0.2060702
[Epoch 53; Iter   202/  209] train: loss: 0.1139000
[Epoch 53] ogbg-moltox21: 0.847574 val loss: 0.210631
[Epoch 53] ogbg-moltox21: 0.844222 test loss: 0.205781
[Epoch 54; Iter    23/  209] train: loss: 0.1346738
[Epoch 54; Iter    53/  209] train: loss: 0.0964672
[Epoch 54; Iter    83/  209] train: loss: 0.0953493
[Epoch 54; Iter   113/  209] train: loss: 0.0730578
[Epoch 54; Iter   143/  209] train: loss: 0.1328544
[Epoch 54; Iter   173/  209] train: loss: 0.0801500
[Epoch 54; Iter   203/  209] train: loss: 0.2034470
[Epoch 54] ogbg-moltox21: 0.836375 val loss: 0.231561
[Epoch 54] ogbg-moltox21: 0.832270 test loss: 0.213826
[Epoch 55; Iter    24/  209] train: loss: 0.0979850
[Epoch 55; Iter    54/  209] train: loss: 0.0937015
[Epoch 55; Iter    84/  209] train: loss: 0.0929692
[Epoch 55; Iter   114/  209] train: loss: 0.0839965
[Epoch 55; Iter   144/  209] train: loss: 0.1050041
[Epoch 55; Iter   174/  209] train: loss: 0.1651563
[Epoch 55; Iter   204/  209] train: loss: 0.1006369
[Epoch 55] ogbg-moltox21: 0.849024 val loss: 0.217416
[Epoch 55] ogbg-moltox21: 0.831412 test loss: 0.214883
[Epoch 56; Iter    25/  209] train: loss: 0.1292760
[Epoch 56; Iter    55/  209] train: loss: 0.1094918
[Epoch 56; Iter    85/  209] train: loss: 0.1347866
[Epoch 56; Iter   115/  209] train: loss: 0.1172941
[Epoch 56; Iter   145/  209] train: loss: 0.1953426
[Epoch 56; Iter   175/  209] train: loss: 0.1360678
[Epoch 56; Iter   205/  209] train: loss: 0.0961700
[Epoch 56] ogbg-moltox21: 0.835605 val loss: 0.228314
[Epoch 56] ogbg-moltox21: 0.837354 test loss: 0.215087
[Epoch 57; Iter    26/  209] train: loss: 0.1260770
[Epoch 57; Iter    56/  209] train: loss: 0.1706396
[Epoch 57; Iter    86/  209] train: loss: 0.0928407
[Epoch 57; Iter   116/  209] train: loss: 0.1539313
[Epoch 57; Iter   146/  209] train: loss: 0.1046518
[Epoch 57; Iter   176/  209] train: loss: 0.1844418
[Epoch 57; Iter   206/  209] train: loss: 0.1062241
[Epoch 57] ogbg-moltox21: 0.843662 val loss: 0.223719
[Epoch 57] ogbg-moltox21: 0.845589 test loss: 0.209440
[Epoch 58; Iter    27/  209] train: loss: 0.0879173
[Epoch 58; Iter    57/  209] train: loss: 0.0872593
[Epoch 58; Iter    87/  209] train: loss: 0.0818367
[Epoch 58; Iter   117/  209] train: loss: 0.0998472
[Epoch 58; Iter   147/  209] train: loss: 0.0519359
[Epoch 58; Iter   177/  209] train: loss: 0.1787039
[Epoch 58; Iter   207/  209] train: loss: 0.1048662
[Epoch 58] ogbg-moltox21: 0.840086 val loss: 0.242030
[Epoch 58] ogbg-moltox21: 0.835208 test loss: 0.239607
[Epoch 59; Iter    28/  209] train: loss: 0.1098019
[Epoch 59; Iter    58/  209] train: loss: 0.0924494
[Epoch 59; Iter    88/  209] train: loss: 0.1479220
[Epoch 59; Iter   118/  209] train: loss: 0.0862685
[Epoch 59; Iter   148/  209] train: loss: 0.1115672
[Epoch 59; Iter   178/  209] train: loss: 0.1354288
[Epoch 59; Iter   208/  209] train: loss: 0.1507914
[Epoch 59] ogbg-moltox21: 0.843774 val loss: 0.232954
[Epoch 59] ogbg-moltox21: 0.847587 test loss: 0.217541
[Epoch 60; Iter    29/  209] train: loss: 0.1369464
[Epoch 60; Iter    59/  209] train: loss: 0.0965010
[Epoch 60; Iter    89/  209] train: loss: 0.0909467
[Epoch 60; Iter   119/  209] train: loss: 0.1366196
[Epoch 60; Iter   149/  209] train: loss: 0.0821854
[Epoch 60; Iter   179/  209] train: loss: 0.0941047
[Epoch 60; Iter   209/  209] train: loss: 0.1026261
[Epoch 60] ogbg-moltox21: 0.837083 val loss: 0.235623
[Epoch 60] ogbg-moltox21: 0.834992 test loss: 0.231419
[Epoch 61; Iter    30/  209] train: loss: 0.0941482
[Epoch 61; Iter    60/  209] train: loss: 0.0854763
[Epoch 61; Iter    90/  209] train: loss: 0.1149981
[Epoch 61; Iter   120/  209] train: loss: 0.0745672
[Epoch 61; Iter   150/  209] train: loss: 0.1145903
[Epoch 61; Iter   180/  209] train: loss: 0.1108961
[Epoch 61] ogbg-moltox21: 0.834711 val loss: 0.454757
[Epoch 61] ogbg-moltox21: 0.838826 test loss: 0.580367
[Epoch 62; Iter     1/  209] train: loss: 0.0884297
[Epoch 62; Iter    31/  209] train: loss: 0.0977563
[Epoch 62; Iter    61/  209] train: loss: 0.1192475
[Epoch 62; Iter    91/  209] train: loss: 0.0738321
[Epoch 62; Iter   121/  209] train: loss: 0.0438412
[Epoch 62; Iter   151/  209] train: loss: 0.0864242
[Epoch 62; Iter   181/  209] train: loss: 0.1710812
[Epoch 62] ogbg-moltox21: 0.835128 val loss: 0.233989
[Epoch 62] ogbg-moltox21: 0.836254 test loss: 0.225240
[Epoch 63; Iter     2/  209] train: loss: 0.1215201
[Epoch 63; Iter    32/  209] train: loss: 0.0980728
[Epoch 63; Iter    62/  209] train: loss: 0.0938001
[Epoch 63; Iter    92/  209] train: loss: 0.0977224
[Epoch 63; Iter   122/  209] train: loss: 0.1378673
[Epoch 63; Iter   152/  209] train: loss: 0.1153077
[Epoch 63; Iter   182/  209] train: loss: 0.1095909
[Epoch 63] ogbg-moltox21: 0.832250 val loss: 0.246547
[Epoch 63] ogbg-moltox21: 0.829720 test loss: 0.234442
[Epoch 64; Iter     3/  209] train: loss: 0.1113343
[Epoch 64; Iter    33/  209] train: loss: 0.0779638
[Epoch 64; Iter    63/  209] train: loss: 0.0922838
[Epoch 64; Iter    93/  209] train: loss: 0.1008191
[Epoch 64; Iter   123/  209] train: loss: 0.0600163
[Epoch 64; Iter   153/  209] train: loss: 0.0737446
[Epoch 64; Iter   183/  209] train: loss: 0.1308136
[Epoch 64] ogbg-moltox21: 0.837437 val loss: 0.260608
[Epoch 47; Iter   166/  209] train: loss: 0.1160221
[Epoch 47; Iter   196/  209] train: loss: 0.1269851
[Epoch 47] ogbg-moltox21: 0.858939 val loss: 0.209990
[Epoch 47] ogbg-moltox21: 0.835996 test loss: 0.193243
[Epoch 48; Iter    17/  209] train: loss: 0.1441392
[Epoch 48; Iter    47/  209] train: loss: 0.1138578
[Epoch 48; Iter    77/  209] train: loss: 0.1319832
[Epoch 48; Iter   107/  209] train: loss: 0.1156285
[Epoch 48; Iter   137/  209] train: loss: 0.1011801
[Epoch 48; Iter   167/  209] train: loss: 0.1489109
[Epoch 48; Iter   197/  209] train: loss: 0.0905552
[Epoch 48] ogbg-moltox21: 0.856129 val loss: 0.208174
[Epoch 48] ogbg-moltox21: 0.835021 test loss: 0.198720
[Epoch 49; Iter    18/  209] train: loss: 0.1354326
[Epoch 49; Iter    48/  209] train: loss: 0.1689028
[Epoch 49; Iter    78/  209] train: loss: 0.1395099
[Epoch 49; Iter   108/  209] train: loss: 0.1857608
[Epoch 49; Iter   138/  209] train: loss: 0.0736663
[Epoch 49; Iter   168/  209] train: loss: 0.1330878
[Epoch 49; Iter   198/  209] train: loss: 0.1031255
[Epoch 49] ogbg-moltox21: 0.854848 val loss: 0.206686
[Epoch 49] ogbg-moltox21: 0.833693 test loss: 0.193759
[Epoch 50; Iter    19/  209] train: loss: 0.1247573
[Epoch 50; Iter    49/  209] train: loss: 0.1127397
[Epoch 50; Iter    79/  209] train: loss: 0.1002869
[Epoch 50; Iter   109/  209] train: loss: 0.0913701
[Epoch 50; Iter   139/  209] train: loss: 0.1269503
[Epoch 50; Iter   169/  209] train: loss: 0.1251121
[Epoch 50; Iter   199/  209] train: loss: 0.2129063
[Epoch 50] ogbg-moltox21: 0.858844 val loss: 0.212445
[Epoch 50] ogbg-moltox21: 0.840499 test loss: 0.193870
[Epoch 51; Iter    20/  209] train: loss: 0.1160426
[Epoch 51; Iter    50/  209] train: loss: 0.0911420
[Epoch 51; Iter    80/  209] train: loss: 0.1677625
[Epoch 51; Iter   110/  209] train: loss: 0.1072097
[Epoch 51; Iter   140/  209] train: loss: 0.0967893
[Epoch 51; Iter   170/  209] train: loss: 0.1135093
[Epoch 51; Iter   200/  209] train: loss: 0.1311552
[Epoch 51] ogbg-moltox21: 0.853038 val loss: 0.212500
[Epoch 51] ogbg-moltox21: 0.838120 test loss: 0.195779
[Epoch 52; Iter    21/  209] train: loss: 0.1098312
[Epoch 52; Iter    51/  209] train: loss: 0.1535906
[Epoch 52; Iter    81/  209] train: loss: 0.1085440
[Epoch 52; Iter   111/  209] train: loss: 0.0838663
[Epoch 52; Iter   141/  209] train: loss: 0.1004700
[Epoch 52; Iter   171/  209] train: loss: 0.1522419
[Epoch 52; Iter   201/  209] train: loss: 0.1568192
[Epoch 52] ogbg-moltox21: 0.858799 val loss: 0.211648
[Epoch 52] ogbg-moltox21: 0.842444 test loss: 0.197233
[Epoch 53; Iter    22/  209] train: loss: 0.1099547
[Epoch 53; Iter    52/  209] train: loss: 0.1132682
[Epoch 53; Iter    82/  209] train: loss: 0.1081196
[Epoch 53; Iter   112/  209] train: loss: 0.1065183
[Epoch 53; Iter   142/  209] train: loss: 0.1092658
[Epoch 53; Iter   172/  209] train: loss: 0.1672999
[Epoch 53; Iter   202/  209] train: loss: 0.1027564
[Epoch 53] ogbg-moltox21: 0.858550 val loss: 0.212113
[Epoch 53] ogbg-moltox21: 0.838874 test loss: 0.201763
[Epoch 54; Iter    23/  209] train: loss: 0.1351891
[Epoch 54; Iter    53/  209] train: loss: 0.0782174
[Epoch 54; Iter    83/  209] train: loss: 0.0925587
[Epoch 54; Iter   113/  209] train: loss: 0.1573547
[Epoch 54; Iter   143/  209] train: loss: 0.1192261
[Epoch 54; Iter   173/  209] train: loss: 0.1238986
[Epoch 54; Iter   203/  209] train: loss: 0.1138075
[Epoch 54] ogbg-moltox21: 0.854851 val loss: 0.213253
[Epoch 54] ogbg-moltox21: 0.834852 test loss: 0.204156
[Epoch 55; Iter    24/  209] train: loss: 0.1094131
[Epoch 55; Iter    54/  209] train: loss: 0.1495824
[Epoch 55; Iter    84/  209] train: loss: 0.0912571
[Epoch 55; Iter   114/  209] train: loss: 0.1526187
[Epoch 55; Iter   144/  209] train: loss: 0.0907397
[Epoch 55; Iter   174/  209] train: loss: 0.0944001
[Epoch 55; Iter   204/  209] train: loss: 0.1472683
[Epoch 55] ogbg-moltox21: 0.856595 val loss: 0.211716
[Epoch 55] ogbg-moltox21: 0.843290 test loss: 0.196528
[Epoch 56; Iter    25/  209] train: loss: 0.1315388
[Epoch 56; Iter    55/  209] train: loss: 0.2397029
[Epoch 56; Iter    85/  209] train: loss: 0.1119401
[Epoch 56; Iter   115/  209] train: loss: 0.1174942
[Epoch 56; Iter   145/  209] train: loss: 0.0880190
[Epoch 56; Iter   175/  209] train: loss: 0.1106849
[Epoch 56; Iter   205/  209] train: loss: 0.1077196
[Epoch 56] ogbg-moltox21: 0.848007 val loss: 0.220657
[Epoch 56] ogbg-moltox21: 0.840297 test loss: 0.200594
[Epoch 57; Iter    26/  209] train: loss: 0.0875601
[Epoch 57; Iter    56/  209] train: loss: 0.1072626
[Epoch 57; Iter    86/  209] train: loss: 0.1448927
[Epoch 57; Iter   116/  209] train: loss: 0.1025167
[Epoch 57; Iter   146/  209] train: loss: 0.1237578
[Epoch 57; Iter   176/  209] train: loss: 0.0729438
[Epoch 57; Iter   206/  209] train: loss: 0.1394836
[Epoch 57] ogbg-moltox21: 0.848975 val loss: 0.219839
[Epoch 57] ogbg-moltox21: 0.832159 test loss: 0.200765
[Epoch 58; Iter    27/  209] train: loss: 0.1350391
[Epoch 58; Iter    57/  209] train: loss: 0.1293819
[Epoch 58; Iter    87/  209] train: loss: 0.1010715
[Epoch 58; Iter   117/  209] train: loss: 0.1230279
[Epoch 58; Iter   147/  209] train: loss: 0.0996707
[Epoch 58; Iter   177/  209] train: loss: 0.0814432
[Epoch 58; Iter   207/  209] train: loss: 0.0891455
[Epoch 58] ogbg-moltox21: 0.848410 val loss: 0.219125
[Epoch 58] ogbg-moltox21: 0.829317 test loss: 0.209384
[Epoch 59; Iter    28/  209] train: loss: 0.1837347
[Epoch 59; Iter    58/  209] train: loss: 0.0665241
[Epoch 59; Iter    88/  209] train: loss: 0.0830128
[Epoch 59; Iter   118/  209] train: loss: 0.1111522
[Epoch 59; Iter   148/  209] train: loss: 0.0960517
[Epoch 59; Iter   178/  209] train: loss: 0.0957115
[Epoch 59; Iter   208/  209] train: loss: 0.0874310
[Epoch 59] ogbg-moltox21: 0.845582 val loss: 0.223557
[Epoch 59] ogbg-moltox21: 0.832320 test loss: 0.206131
[Epoch 60; Iter    29/  209] train: loss: 0.0809937
[Epoch 60; Iter    59/  209] train: loss: 0.1606034
[Epoch 60; Iter    89/  209] train: loss: 0.1041338
[Epoch 60; Iter   119/  209] train: loss: 0.1304977
[Epoch 60; Iter   149/  209] train: loss: 0.0776458
[Epoch 60; Iter   179/  209] train: loss: 0.0723737
[Epoch 60; Iter   209/  209] train: loss: 0.0806554
[Epoch 60] ogbg-moltox21: 0.845422 val loss: 0.228068
[Epoch 60] ogbg-moltox21: 0.833688 test loss: 0.205666
[Epoch 61; Iter    30/  209] train: loss: 0.0936244
[Epoch 61; Iter    60/  209] train: loss: 0.0927266
[Epoch 61; Iter    90/  209] train: loss: 0.0599761
[Epoch 61; Iter   120/  209] train: loss: 0.0793376
[Epoch 61; Iter   150/  209] train: loss: 0.1188819
[Epoch 61; Iter   180/  209] train: loss: 0.1068562
[Epoch 61] ogbg-moltox21: 0.851529 val loss: 0.223756
[Epoch 61] ogbg-moltox21: 0.828817 test loss: 0.207052
[Epoch 62; Iter     1/  209] train: loss: 0.1033285
[Epoch 62; Iter    31/  209] train: loss: 0.1142783
[Epoch 62; Iter    61/  209] train: loss: 0.0778709
[Epoch 62; Iter    91/  209] train: loss: 0.0979604
[Epoch 62; Iter   121/  209] train: loss: 0.1128764
[Epoch 62; Iter   151/  209] train: loss: 0.0991061
[Epoch 62; Iter   181/  209] train: loss: 0.0990958
[Epoch 62] ogbg-moltox21: 0.849877 val loss: 0.227493
[Epoch 62] ogbg-moltox21: 0.831402 test loss: 0.200960
[Epoch 63; Iter     2/  209] train: loss: 0.1186715
[Epoch 63; Iter    32/  209] train: loss: 0.0965625
[Epoch 63; Iter    62/  209] train: loss: 0.0813494
[Epoch 63; Iter    92/  209] train: loss: 0.1257549
[Epoch 63; Iter   122/  209] train: loss: 0.1141775
[Epoch 63; Iter   152/  209] train: loss: 0.1047337
[Epoch 63; Iter   182/  209] train: loss: 0.1179589
[Epoch 63] ogbg-moltox21: 0.852864 val loss: 0.222685
[Epoch 63] ogbg-moltox21: 0.830635 test loss: 0.201623
[Epoch 64; Iter     3/  209] train: loss: 0.0656989
[Epoch 64; Iter    33/  209] train: loss: 0.1221666
[Epoch 64; Iter    63/  209] train: loss: 0.0626699
[Epoch 64; Iter    93/  209] train: loss: 0.0868090
[Epoch 64; Iter   123/  209] train: loss: 0.0827214
[Epoch 64; Iter   153/  209] train: loss: 0.0772867
[Epoch 64; Iter   183/  209] train: loss: 0.0730092
[Epoch 64] ogbg-moltox21: 0.851114 val loss: 0.222918
[Epoch 52; Iter   147/  183] train: loss: 0.1418972
[Epoch 52; Iter   177/  183] train: loss: 0.1288181
[Epoch 52] ogbg-moltox21: 0.842490 val loss: 0.213541
[Epoch 52] ogbg-moltox21: 0.842709 test loss: 0.202866
[Epoch 53; Iter    24/  183] train: loss: 0.1200010
[Epoch 53; Iter    54/  183] train: loss: 0.1169497
[Epoch 53; Iter    84/  183] train: loss: 0.1315344
[Epoch 53; Iter   114/  183] train: loss: 0.1483808
[Epoch 53; Iter   144/  183] train: loss: 0.1380529
[Epoch 53; Iter   174/  183] train: loss: 0.2160406
[Epoch 53] ogbg-moltox21: 0.842972 val loss: 0.193450
[Epoch 53] ogbg-moltox21: 0.847696 test loss: 0.192655
[Epoch 54; Iter    21/  183] train: loss: 0.1504768
[Epoch 54; Iter    51/  183] train: loss: 0.1743790
[Epoch 54; Iter    81/  183] train: loss: 0.1080855
[Epoch 54; Iter   111/  183] train: loss: 0.1358680
[Epoch 54; Iter   141/  183] train: loss: 0.1408412
[Epoch 54; Iter   171/  183] train: loss: 0.1123830
[Epoch 54] ogbg-moltox21: 0.836744 val loss: 0.194061
[Epoch 54] ogbg-moltox21: 0.847656 test loss: 0.195770
[Epoch 55; Iter    18/  183] train: loss: 0.1190552
[Epoch 55; Iter    48/  183] train: loss: 0.1374178
[Epoch 55; Iter    78/  183] train: loss: 0.1086362
[Epoch 55; Iter   108/  183] train: loss: 0.2077088
[Epoch 55; Iter   138/  183] train: loss: 0.1556105
[Epoch 55; Iter   168/  183] train: loss: 0.1258400
[Epoch 55] ogbg-moltox21: 0.838311 val loss: 0.204365
[Epoch 55] ogbg-moltox21: 0.847870 test loss: 0.195679
[Epoch 56; Iter    15/  183] train: loss: 0.0826270
[Epoch 56; Iter    45/  183] train: loss: 0.1348050
[Epoch 56; Iter    75/  183] train: loss: 0.0959366
[Epoch 56; Iter   105/  183] train: loss: 0.1104373
[Epoch 56; Iter   135/  183] train: loss: 0.1407123
[Epoch 56; Iter   165/  183] train: loss: 0.1574048
[Epoch 56] ogbg-moltox21: 0.838515 val loss: 0.191954
[Epoch 56] ogbg-moltox21: 0.846619 test loss: 0.193863
[Epoch 57; Iter    12/  183] train: loss: 0.1158003
[Epoch 57; Iter    42/  183] train: loss: 0.1001685
[Epoch 57; Iter    72/  183] train: loss: 0.1040266
[Epoch 57; Iter   102/  183] train: loss: 0.1095588
[Epoch 57; Iter   132/  183] train: loss: 0.1280865
[Epoch 57; Iter   162/  183] train: loss: 0.1553879
[Epoch 57] ogbg-moltox21: 0.830565 val loss: 0.263492
[Epoch 57] ogbg-moltox21: 0.844902 test loss: 0.204962
[Epoch 58; Iter     9/  183] train: loss: 0.0936661
[Epoch 58; Iter    39/  183] train: loss: 0.1040592
[Epoch 58; Iter    69/  183] train: loss: 0.1406471
[Epoch 58; Iter    99/  183] train: loss: 0.1090553
[Epoch 58; Iter   129/  183] train: loss: 0.1213222
[Epoch 58; Iter   159/  183] train: loss: 0.1236903
[Epoch 58] ogbg-moltox21: 0.836841 val loss: 0.205572
[Epoch 58] ogbg-moltox21: 0.845351 test loss: 0.204482
[Epoch 59; Iter     6/  183] train: loss: 0.1916470
[Epoch 59; Iter    36/  183] train: loss: 0.1547983
[Epoch 59; Iter    66/  183] train: loss: 0.1064478
[Epoch 59; Iter    96/  183] train: loss: 0.2147298
[Epoch 59; Iter   126/  183] train: loss: 0.1932602
[Epoch 59; Iter   156/  183] train: loss: 0.2318091
[Epoch 59] ogbg-moltox21: 0.839895 val loss: 0.218118
[Epoch 59] ogbg-moltox21: 0.848364 test loss: 0.198032
[Epoch 60; Iter     3/  183] train: loss: 0.1637813
[Epoch 60; Iter    33/  183] train: loss: 0.1455460
[Epoch 60; Iter    63/  183] train: loss: 0.0953879
[Epoch 60; Iter    93/  183] train: loss: 0.1461308
[Epoch 60; Iter   123/  183] train: loss: 0.1480161
[Epoch 60; Iter   153/  183] train: loss: 0.1119040
[Epoch 60; Iter   183/  183] train: loss: 0.0947608
[Epoch 60] ogbg-moltox21: 0.845985 val loss: 0.197873
[Epoch 60] ogbg-moltox21: 0.850026 test loss: 0.198810
[Epoch 61; Iter    30/  183] train: loss: 0.1183827
[Epoch 61; Iter    60/  183] train: loss: 0.0748354
[Epoch 61; Iter    90/  183] train: loss: 0.1244992
[Epoch 61; Iter   120/  183] train: loss: 0.1641013
[Epoch 61; Iter   150/  183] train: loss: 0.0822272
[Epoch 61; Iter   180/  183] train: loss: 0.1404806
[Epoch 61] ogbg-moltox21: 0.839887 val loss: 0.200054
[Epoch 61] ogbg-moltox21: 0.847908 test loss: 0.195694
[Epoch 62; Iter    27/  183] train: loss: 0.0771535
[Epoch 62; Iter    57/  183] train: loss: 0.0783156
[Epoch 62; Iter    87/  183] train: loss: 0.1345773
[Epoch 62; Iter   117/  183] train: loss: 0.1505055
[Epoch 62; Iter   147/  183] train: loss: 0.1669761
[Epoch 62; Iter   177/  183] train: loss: 0.1435505
[Epoch 62] ogbg-moltox21: 0.838591 val loss: 0.198261
[Epoch 62] ogbg-moltox21: 0.844169 test loss: 0.206432
[Epoch 63; Iter    24/  183] train: loss: 0.1424352
[Epoch 63; Iter    54/  183] train: loss: 0.1071034
[Epoch 63; Iter    84/  183] train: loss: 0.1274872
[Epoch 63; Iter   114/  183] train: loss: 0.1686179
[Epoch 63; Iter   144/  183] train: loss: 0.1276235
[Epoch 63; Iter   174/  183] train: loss: 0.1026909
[Epoch 63] ogbg-moltox21: 0.831398 val loss: 0.264065
[Epoch 63] ogbg-moltox21: 0.841590 test loss: 0.216722
[Epoch 64; Iter    21/  183] train: loss: 0.1040746
[Epoch 64; Iter    51/  183] train: loss: 0.1465035
[Epoch 64; Iter    81/  183] train: loss: 0.0925833
[Epoch 64; Iter   111/  183] train: loss: 0.0894803
[Epoch 64; Iter   141/  183] train: loss: 0.1904869
[Epoch 64; Iter   171/  183] train: loss: 0.1226461
[Epoch 64] ogbg-moltox21: 0.837441 val loss: 0.229992
[Epoch 64] ogbg-moltox21: 0.847665 test loss: 0.199791
[Epoch 65; Iter    18/  183] train: loss: 0.1190111
[Epoch 65; Iter    48/  183] train: loss: 0.1555491
[Epoch 65; Iter    78/  183] train: loss: 0.1175188
[Epoch 65; Iter   108/  183] train: loss: 0.1349884
[Epoch 65; Iter   138/  183] train: loss: 0.1340225
[Epoch 65; Iter   168/  183] train: loss: 0.1502843
[Epoch 65] ogbg-moltox21: 0.832767 val loss: 0.204435
[Epoch 65] ogbg-moltox21: 0.838923 test loss: 0.204947
[Epoch 66; Iter    15/  183] train: loss: 0.1654214
[Epoch 66; Iter    45/  183] train: loss: 0.1245723
[Epoch 66; Iter    75/  183] train: loss: 0.1843490
[Epoch 66; Iter   105/  183] train: loss: 0.1351938
[Epoch 66; Iter   135/  183] train: loss: 0.1096335
[Epoch 66; Iter   165/  183] train: loss: 0.0941739
[Epoch 66] ogbg-moltox21: 0.840590 val loss: 0.202220
[Epoch 66] ogbg-moltox21: 0.846145 test loss: 0.200682
[Epoch 67; Iter    12/  183] train: loss: 0.1153103
[Epoch 67; Iter    42/  183] train: loss: 0.1003614
[Epoch 67; Iter    72/  183] train: loss: 0.1090898
[Epoch 67; Iter   102/  183] train: loss: 0.1866642
[Epoch 67; Iter   132/  183] train: loss: 0.1302637
[Epoch 67; Iter   162/  183] train: loss: 0.1578968
[Epoch 67] ogbg-moltox21: 0.831062 val loss: 0.221231
[Epoch 67] ogbg-moltox21: 0.837007 test loss: 0.213622
[Epoch 68; Iter     9/  183] train: loss: 0.1024359
[Epoch 68; Iter    39/  183] train: loss: 0.0777685
[Epoch 68; Iter    69/  183] train: loss: 0.2164166
[Epoch 68; Iter    99/  183] train: loss: 0.1398547
[Epoch 68; Iter   129/  183] train: loss: 0.1572669
[Epoch 68; Iter   159/  183] train: loss: 0.1358409
[Epoch 68] ogbg-moltox21: 0.841060 val loss: 0.206332
[Epoch 68] ogbg-moltox21: 0.845080 test loss: 0.201525
[Epoch 69; Iter     6/  183] train: loss: 0.1965534
[Epoch 69; Iter    36/  183] train: loss: 0.1727479
[Epoch 69; Iter    66/  183] train: loss: 0.0840601
[Epoch 69; Iter    96/  183] train: loss: 0.1024318
[Epoch 69; Iter   126/  183] train: loss: 0.0637470
[Epoch 69; Iter   156/  183] train: loss: 0.0973631
[Epoch 69] ogbg-moltox21: 0.830540 val loss: 0.233218
[Epoch 69] ogbg-moltox21: 0.837808 test loss: 0.211017
[Epoch 70; Iter     3/  183] train: loss: 0.1189364
[Epoch 70; Iter    33/  183] train: loss: 0.1381707
[Epoch 70; Iter    63/  183] train: loss: 0.0936716
[Epoch 70; Iter    93/  183] train: loss: 0.1418635
[Epoch 70; Iter   123/  183] train: loss: 0.1714296
[Epoch 70; Iter   153/  183] train: loss: 0.1215558
[Epoch 70; Iter   183/  183] train: loss: 0.1644205
[Epoch 70] ogbg-moltox21: 0.834213 val loss: 0.214932
[Epoch 70] ogbg-moltox21: 0.842652 test loss: 0.207721
[Epoch 71; Iter    30/  183] train: loss: 0.1068295
[Epoch 71; Iter    60/  183] train: loss: 0.1514698
[Epoch 71; Iter    90/  183] train: loss: 0.0724451
[Epoch 71; Iter   120/  183] train: loss: 0.0716197
[Epoch 71; Iter   150/  183] train: loss: 0.1094352
[Epoch 52; Iter   147/  183] train: loss: 0.1568593
[Epoch 52; Iter   177/  183] train: loss: 0.0742271
[Epoch 52] ogbg-moltox21: 0.837436 val loss: 0.198803
[Epoch 52] ogbg-moltox21: 0.840923 test loss: 0.203691
[Epoch 53; Iter    24/  183] train: loss: 0.1615114
[Epoch 53; Iter    54/  183] train: loss: 0.1039434
[Epoch 53; Iter    84/  183] train: loss: 0.0972036
[Epoch 53; Iter   114/  183] train: loss: 0.1460740
[Epoch 53; Iter   144/  183] train: loss: 0.0916582
[Epoch 53; Iter   174/  183] train: loss: 0.0961224
[Epoch 53] ogbg-moltox21: 0.835580 val loss: 0.198551
[Epoch 53] ogbg-moltox21: 0.842451 test loss: 0.199640
[Epoch 54; Iter    21/  183] train: loss: 0.0919474
[Epoch 54; Iter    51/  183] train: loss: 0.1248976
[Epoch 54; Iter    81/  183] train: loss: 0.1043415
[Epoch 54; Iter   111/  183] train: loss: 0.0898096
[Epoch 54; Iter   141/  183] train: loss: 0.1333721
[Epoch 54; Iter   171/  183] train: loss: 0.0718471
[Epoch 54] ogbg-moltox21: 0.832384 val loss: 0.203579
[Epoch 54] ogbg-moltox21: 0.834645 test loss: 0.207003
[Epoch 55; Iter    18/  183] train: loss: 0.0988079
[Epoch 55; Iter    48/  183] train: loss: 0.1345279
[Epoch 55; Iter    78/  183] train: loss: 0.0841825
[Epoch 55; Iter   108/  183] train: loss: 0.1198454
[Epoch 55; Iter   138/  183] train: loss: 0.1112706
[Epoch 55; Iter   168/  183] train: loss: 0.0853621
[Epoch 55] ogbg-moltox21: 0.825972 val loss: 0.206684
[Epoch 55] ogbg-moltox21: 0.828758 test loss: 0.209301
[Epoch 56; Iter    15/  183] train: loss: 0.1512433
[Epoch 56; Iter    45/  183] train: loss: 0.1069914
[Epoch 56; Iter    75/  183] train: loss: 0.1230931
[Epoch 56; Iter   105/  183] train: loss: 0.0796273
[Epoch 56; Iter   135/  183] train: loss: 0.1351241
[Epoch 56; Iter   165/  183] train: loss: 0.1100259
[Epoch 56] ogbg-moltox21: 0.824200 val loss: 0.207904
[Epoch 56] ogbg-moltox21: 0.829783 test loss: 0.211105
[Epoch 57; Iter    12/  183] train: loss: 0.1408920
[Epoch 57; Iter    42/  183] train: loss: 0.1091560
[Epoch 57; Iter    72/  183] train: loss: 0.1357430
[Epoch 57; Iter   102/  183] train: loss: 0.1476942
[Epoch 57; Iter   132/  183] train: loss: 0.0536384
[Epoch 57; Iter   162/  183] train: loss: 0.1487579
[Epoch 57] ogbg-moltox21: 0.832155 val loss: 0.212462
[Epoch 57] ogbg-moltox21: 0.826973 test loss: 0.216640
[Epoch 58; Iter     9/  183] train: loss: 0.0838909
[Epoch 58; Iter    39/  183] train: loss: 0.1921931
[Epoch 58; Iter    69/  183] train: loss: 0.1268884
[Epoch 58; Iter    99/  183] train: loss: 0.0920635
[Epoch 58; Iter   129/  183] train: loss: 0.1423058
[Epoch 58; Iter   159/  183] train: loss: 0.0996644
[Epoch 58] ogbg-moltox21: 0.831636 val loss: 0.207401
[Epoch 58] ogbg-moltox21: 0.830932 test loss: 0.213315
[Epoch 59; Iter     6/  183] train: loss: 0.1051746
[Epoch 59; Iter    36/  183] train: loss: 0.0719616
[Epoch 59; Iter    66/  183] train: loss: 0.1224580
[Epoch 59; Iter    96/  183] train: loss: 0.1316956
[Epoch 59; Iter   126/  183] train: loss: 0.0799765
[Epoch 59; Iter   156/  183] train: loss: 0.1524835
[Epoch 59] ogbg-moltox21: 0.822486 val loss: 0.216901
[Epoch 59] ogbg-moltox21: 0.819708 test loss: 0.230563
[Epoch 60; Iter     3/  183] train: loss: 0.0789495
[Epoch 60; Iter    33/  183] train: loss: 0.1286516
[Epoch 60; Iter    63/  183] train: loss: 0.0741175
[Epoch 60; Iter    93/  183] train: loss: 0.1134917
[Epoch 60; Iter   123/  183] train: loss: 0.1584943
[Epoch 60; Iter   153/  183] train: loss: 0.1008543
[Epoch 60; Iter   183/  183] train: loss: 0.1611784
[Epoch 60] ogbg-moltox21: 0.827258 val loss: 0.222296
[Epoch 60] ogbg-moltox21: 0.834867 test loss: 0.216526
[Epoch 61; Iter    30/  183] train: loss: 0.1566248
[Epoch 61; Iter    60/  183] train: loss: 0.1093336
[Epoch 61; Iter    90/  183] train: loss: 0.1678213
[Epoch 61; Iter   120/  183] train: loss: 0.1540466
[Epoch 61; Iter   150/  183] train: loss: 0.1367316
[Epoch 61; Iter   180/  183] train: loss: 0.1487391
[Epoch 61] ogbg-moltox21: 0.827927 val loss: 0.217747
[Epoch 61] ogbg-moltox21: 0.839672 test loss: 0.215125
[Epoch 62; Iter    27/  183] train: loss: 0.0900732
[Epoch 62; Iter    57/  183] train: loss: 0.1243904
[Epoch 62; Iter    87/  183] train: loss: 0.0731052
[Epoch 62; Iter   117/  183] train: loss: 0.0933744
[Epoch 62; Iter   147/  183] train: loss: 0.1021702
[Epoch 62; Iter   177/  183] train: loss: 0.0955946
[Epoch 62] ogbg-moltox21: 0.823983 val loss: 0.219511
[Epoch 62] ogbg-moltox21: 0.827506 test loss: 0.218674
[Epoch 63; Iter    24/  183] train: loss: 0.1297111
[Epoch 63; Iter    54/  183] train: loss: 0.1048712
[Epoch 63; Iter    84/  183] train: loss: 0.0833498
[Epoch 63; Iter   114/  183] train: loss: 0.1300917
[Epoch 63; Iter   144/  183] train: loss: 0.1170150
[Epoch 63; Iter   174/  183] train: loss: 0.0710910
[Epoch 63] ogbg-moltox21: 0.829148 val loss: 0.213721
[Epoch 63] ogbg-moltox21: 0.829907 test loss: 0.215593
[Epoch 64; Iter    21/  183] train: loss: 0.0826630
[Epoch 64; Iter    51/  183] train: loss: 0.0981840
[Epoch 64; Iter    81/  183] train: loss: 0.0676081
[Epoch 64; Iter   111/  183] train: loss: 0.0654636
[Epoch 64; Iter   141/  183] train: loss: 0.0638048
[Epoch 64; Iter   171/  183] train: loss: 0.0429518
[Epoch 64] ogbg-moltox21: 0.834689 val loss: 0.210091
[Epoch 64] ogbg-moltox21: 0.832843 test loss: 0.217778
[Epoch 65; Iter    18/  183] train: loss: 0.1329535
[Epoch 65; Iter    48/  183] train: loss: 0.0880584
[Epoch 65; Iter    78/  183] train: loss: 0.0986205
[Epoch 65; Iter   108/  183] train: loss: 0.0633224
[Epoch 65; Iter   138/  183] train: loss: 0.0603217
[Epoch 65; Iter   168/  183] train: loss: 0.1001354
[Epoch 65] ogbg-moltox21: 0.828124 val loss: 0.214492
[Epoch 65] ogbg-moltox21: 0.828788 test loss: 0.220976
[Epoch 66; Iter    15/  183] train: loss: 0.0655789
[Epoch 66; Iter    45/  183] train: loss: 0.0986992
[Epoch 66; Iter    75/  183] train: loss: 0.1076548
[Epoch 66; Iter   105/  183] train: loss: 0.0624211
[Epoch 66; Iter   135/  183] train: loss: 0.0625926
[Epoch 66; Iter   165/  183] train: loss: 0.1105412
[Epoch 66] ogbg-moltox21: 0.824309 val loss: 0.218968
[Epoch 66] ogbg-moltox21: 0.818784 test loss: 0.227600
[Epoch 67; Iter    12/  183] train: loss: 0.1344829
[Epoch 67; Iter    42/  183] train: loss: 0.1088021
[Epoch 67; Iter    72/  183] train: loss: 0.1228874
[Epoch 67; Iter   102/  183] train: loss: 0.0742667
[Epoch 67; Iter   132/  183] train: loss: 0.0798594
[Epoch 67; Iter   162/  183] train: loss: 0.0978100
[Epoch 67] ogbg-moltox21: 0.826187 val loss: 0.220064
[Epoch 67] ogbg-moltox21: 0.833140 test loss: 0.221184
[Epoch 68; Iter     9/  183] train: loss: 0.1009597
[Epoch 68; Iter    39/  183] train: loss: 0.0972383
[Epoch 68; Iter    69/  183] train: loss: 0.0802499
[Epoch 68; Iter    99/  183] train: loss: 0.0865496
[Epoch 68; Iter   129/  183] train: loss: 0.1106490
[Epoch 68; Iter   159/  183] train: loss: 0.0654124
[Epoch 68] ogbg-moltox21: 0.821307 val loss: 0.225927
[Epoch 68] ogbg-moltox21: 0.821529 test loss: 0.232437
[Epoch 69; Iter     6/  183] train: loss: 0.0876302
[Epoch 69; Iter    36/  183] train: loss: 0.0563904
[Epoch 69; Iter    66/  183] train: loss: 0.0836331
[Epoch 69; Iter    96/  183] train: loss: 0.0837026
[Epoch 69; Iter   126/  183] train: loss: 0.0670751
[Epoch 69; Iter   156/  183] train: loss: 0.0483063
[Epoch 69] ogbg-moltox21: 0.820218 val loss: 0.229484
[Epoch 69] ogbg-moltox21: 0.824479 test loss: 0.232372
[Epoch 70; Iter     3/  183] train: loss: 0.0686368
[Epoch 70; Iter    33/  183] train: loss: 0.0998267
[Epoch 70; Iter    63/  183] train: loss: 0.0929848
[Epoch 70; Iter    93/  183] train: loss: 0.0784820
[Epoch 70; Iter   123/  183] train: loss: 0.1518245
[Epoch 70; Iter   153/  183] train: loss: 0.1354764
[Epoch 70; Iter   183/  183] train: loss: 0.1234538
[Epoch 70] ogbg-moltox21: 0.826514 val loss: 0.225348
[Epoch 70] ogbg-moltox21: 0.825534 test loss: 0.229019
[Epoch 71; Iter    30/  183] train: loss: 0.1112314
[Epoch 71; Iter    60/  183] train: loss: 0.0767916
[Epoch 71; Iter    90/  183] train: loss: 0.0606583
[Epoch 71; Iter   120/  183] train: loss: 0.0982752
[Epoch 71; Iter   150/  183] train: loss: 0.1058163
[Epoch 52; Iter   147/  183] train: loss: 0.1357088
[Epoch 52; Iter   177/  183] train: loss: 0.1286317
[Epoch 52] ogbg-moltox21: 0.828642 val loss: 0.200835
[Epoch 52] ogbg-moltox21: 0.836829 test loss: 0.202995
[Epoch 53; Iter    24/  183] train: loss: 0.0808544
[Epoch 53; Iter    54/  183] train: loss: 0.1045562
[Epoch 53; Iter    84/  183] train: loss: 0.1034392
[Epoch 53; Iter   114/  183] train: loss: 0.1459050
[Epoch 53; Iter   144/  183] train: loss: 0.1423955
[Epoch 53; Iter   174/  183] train: loss: 0.0957552
[Epoch 53] ogbg-moltox21: 0.824695 val loss: 0.211208
[Epoch 53] ogbg-moltox21: 0.829858 test loss: 0.212705
[Epoch 54; Iter    21/  183] train: loss: 0.0705528
[Epoch 54; Iter    51/  183] train: loss: 0.0922712
[Epoch 54; Iter    81/  183] train: loss: 0.0776552
[Epoch 54; Iter   111/  183] train: loss: 0.1146699
[Epoch 54; Iter   141/  183] train: loss: 0.0726811
[Epoch 54; Iter   171/  183] train: loss: 0.1211334
[Epoch 54] ogbg-moltox21: 0.826693 val loss: 0.204332
[Epoch 54] ogbg-moltox21: 0.841415 test loss: 0.203037
[Epoch 55; Iter    18/  183] train: loss: 0.0923150
[Epoch 55; Iter    48/  183] train: loss: 0.1011072
[Epoch 55; Iter    78/  183] train: loss: 0.0898068
[Epoch 55; Iter   108/  183] train: loss: 0.0889752
[Epoch 55; Iter   138/  183] train: loss: 0.1083899
[Epoch 55; Iter   168/  183] train: loss: 0.1048698
[Epoch 55] ogbg-moltox21: 0.826878 val loss: 0.206164
[Epoch 55] ogbg-moltox21: 0.841918 test loss: 0.208194
[Epoch 56; Iter    15/  183] train: loss: 0.0870833
[Epoch 56; Iter    45/  183] train: loss: 0.0773485
[Epoch 56; Iter    75/  183] train: loss: 0.1241822
[Epoch 56; Iter   105/  183] train: loss: 0.1585700
[Epoch 56; Iter   135/  183] train: loss: 0.1268187
[Epoch 56; Iter   165/  183] train: loss: 0.1175735
[Epoch 56] ogbg-moltox21: 0.831930 val loss: 0.207313
[Epoch 56] ogbg-moltox21: 0.840613 test loss: 0.208788
[Epoch 57; Iter    12/  183] train: loss: 0.1168999
[Epoch 57; Iter    42/  183] train: loss: 0.1091962
[Epoch 57; Iter    72/  183] train: loss: 0.1737938
[Epoch 57; Iter   102/  183] train: loss: 0.1159525
[Epoch 57; Iter   132/  183] train: loss: 0.1527012
[Epoch 57; Iter   162/  183] train: loss: 0.0998643
[Epoch 57] ogbg-moltox21: 0.826945 val loss: 0.214529
[Epoch 57] ogbg-moltox21: 0.837722 test loss: 0.210742
[Epoch 58; Iter     9/  183] train: loss: 0.1170187
[Epoch 58; Iter    39/  183] train: loss: 0.0942204
[Epoch 58; Iter    69/  183] train: loss: 0.1633844
[Epoch 58; Iter    99/  183] train: loss: 0.1466591
[Epoch 58; Iter   129/  183] train: loss: 0.0847278
[Epoch 58; Iter   159/  183] train: loss: 0.0777627
[Epoch 58] ogbg-moltox21: 0.817573 val loss: 0.214331
[Epoch 58] ogbg-moltox21: 0.835695 test loss: 0.216095
[Epoch 59; Iter     6/  183] train: loss: 0.1399564
[Epoch 59; Iter    36/  183] train: loss: 0.0780400
[Epoch 59; Iter    66/  183] train: loss: 0.1150805
[Epoch 59; Iter    96/  183] train: loss: 0.1070337
[Epoch 59; Iter   126/  183] train: loss: 0.1161819
[Epoch 59; Iter   156/  183] train: loss: 0.0918009
[Epoch 59] ogbg-moltox21: 0.823521 val loss: 0.220054
[Epoch 59] ogbg-moltox21: 0.836659 test loss: 0.219223
[Epoch 60; Iter     3/  183] train: loss: 0.0739308
[Epoch 60; Iter    33/  183] train: loss: 0.1507132
[Epoch 60; Iter    63/  183] train: loss: 0.1024183
[Epoch 60; Iter    93/  183] train: loss: 0.0729819
[Epoch 60; Iter   123/  183] train: loss: 0.1067987
[Epoch 60; Iter   153/  183] train: loss: 0.1178993
[Epoch 60; Iter   183/  183] train: loss: 0.1072386
[Epoch 60] ogbg-moltox21: 0.818713 val loss: 0.213751
[Epoch 60] ogbg-moltox21: 0.833676 test loss: 0.214270
[Epoch 61; Iter    30/  183] train: loss: 0.0777928
[Epoch 61; Iter    60/  183] train: loss: 0.1200283
[Epoch 61; Iter    90/  183] train: loss: 0.1325040
[Epoch 61; Iter   120/  183] train: loss: 0.0758055
[Epoch 61; Iter   150/  183] train: loss: 0.0704372
[Epoch 61; Iter   180/  183] train: loss: 0.0977917
[Epoch 61] ogbg-moltox21: 0.817745 val loss: 0.212155
[Epoch 61] ogbg-moltox21: 0.825504 test loss: 0.221570
[Epoch 62; Iter    27/  183] train: loss: 0.1091106
[Epoch 62; Iter    57/  183] train: loss: 0.1048983
[Epoch 62; Iter    87/  183] train: loss: 0.1272369
[Epoch 62; Iter   117/  183] train: loss: 0.0925371
[Epoch 62; Iter   147/  183] train: loss: 0.1282329
[Epoch 62; Iter   177/  183] train: loss: 0.0975064
[Epoch 62] ogbg-moltox21: 0.819795 val loss: 0.216181
[Epoch 62] ogbg-moltox21: 0.828354 test loss: 0.221323
[Epoch 63; Iter    24/  183] train: loss: 0.0809196
[Epoch 63; Iter    54/  183] train: loss: 0.1002661
[Epoch 63; Iter    84/  183] train: loss: 0.1270514
[Epoch 63; Iter   114/  183] train: loss: 0.0736928
[Epoch 63; Iter   144/  183] train: loss: 0.0700487
[Epoch 63; Iter   174/  183] train: loss: 0.1713252
[Epoch 63] ogbg-moltox21: 0.821557 val loss: 0.215799
[Epoch 63] ogbg-moltox21: 0.832870 test loss: 0.216523
[Epoch 64; Iter    21/  183] train: loss: 0.0565950
[Epoch 64; Iter    51/  183] train: loss: 0.0914830
[Epoch 64; Iter    81/  183] train: loss: 0.0875984
[Epoch 64; Iter   111/  183] train: loss: 0.0789689
[Epoch 64; Iter   141/  183] train: loss: 0.0936833
[Epoch 64; Iter   171/  183] train: loss: 0.0878363
[Epoch 64] ogbg-moltox21: 0.820434 val loss: 0.220757
[Epoch 64] ogbg-moltox21: 0.829234 test loss: 0.221834
[Epoch 65; Iter    18/  183] train: loss: 0.0901517
[Epoch 65; Iter    48/  183] train: loss: 0.1281827
[Epoch 65; Iter    78/  183] train: loss: 0.1234337
[Epoch 65; Iter   108/  183] train: loss: 0.0980338
[Epoch 65; Iter   138/  183] train: loss: 0.1047483
[Epoch 65; Iter   168/  183] train: loss: 0.0905529
[Epoch 65] ogbg-moltox21: 0.826136 val loss: 0.218865
[Epoch 65] ogbg-moltox21: 0.830585 test loss: 0.218728
[Epoch 66; Iter    15/  183] train: loss: 0.1113721
[Epoch 66; Iter    45/  183] train: loss: 0.0480364
[Epoch 66; Iter    75/  183] train: loss: 0.0626662
[Epoch 66; Iter   105/  183] train: loss: 0.0860066
[Epoch 66; Iter   135/  183] train: loss: 0.1157845
[Epoch 66; Iter   165/  183] train: loss: 0.1137529
[Epoch 66] ogbg-moltox21: 0.816083 val loss: 0.228594
[Epoch 66] ogbg-moltox21: 0.829680 test loss: 0.223860
[Epoch 67; Iter    12/  183] train: loss: 0.0549170
[Epoch 67; Iter    42/  183] train: loss: 0.0981504
[Epoch 67; Iter    72/  183] train: loss: 0.0935907
[Epoch 67; Iter   102/  183] train: loss: 0.1375443
[Epoch 67; Iter   132/  183] train: loss: 0.0756194
[Epoch 67; Iter   162/  183] train: loss: 0.0794242
[Epoch 67] ogbg-moltox21: 0.818457 val loss: 0.229972
[Epoch 67] ogbg-moltox21: 0.826303 test loss: 0.232771
[Epoch 68; Iter     9/  183] train: loss: 0.1041251
[Epoch 68; Iter    39/  183] train: loss: 0.1032431
[Epoch 68; Iter    69/  183] train: loss: 0.0924971
[Epoch 68; Iter    99/  183] train: loss: 0.1119080
[Epoch 68; Iter   129/  183] train: loss: 0.0926974
[Epoch 68; Iter   159/  183] train: loss: 0.1059463
[Epoch 68] ogbg-moltox21: 0.818063 val loss: 0.228235
[Epoch 68] ogbg-moltox21: 0.827667 test loss: 0.232817
[Epoch 69; Iter     6/  183] train: loss: 0.0808364
[Epoch 69; Iter    36/  183] train: loss: 0.0485159
[Epoch 69; Iter    66/  183] train: loss: 0.0937505
[Epoch 69; Iter    96/  183] train: loss: 0.1297124
[Epoch 69; Iter   126/  183] train: loss: 0.0819732
[Epoch 69; Iter   156/  183] train: loss: 0.1120179
[Epoch 69] ogbg-moltox21: 0.814613 val loss: 0.227316
[Epoch 69] ogbg-moltox21: 0.820741 test loss: 0.232945
[Epoch 70; Iter     3/  183] train: loss: 0.0627502
[Epoch 70; Iter    33/  183] train: loss: 0.0624900
[Epoch 70; Iter    63/  183] train: loss: 0.0669272
[Epoch 70; Iter    93/  183] train: loss: 0.0685087
[Epoch 70; Iter   123/  183] train: loss: 0.0957792
[Epoch 70; Iter   153/  183] train: loss: 0.0768520
[Epoch 70; Iter   183/  183] train: loss: 0.0592964
[Epoch 70] ogbg-moltox21: 0.818881 val loss: 0.226741
[Epoch 70] ogbg-moltox21: 0.827962 test loss: 0.230762
[Epoch 71; Iter    30/  183] train: loss: 0.1255618
[Epoch 71; Iter    60/  183] train: loss: 0.0774048
[Epoch 71; Iter    90/  183] train: loss: 0.0793715
[Epoch 71; Iter   120/  183] train: loss: 0.0701239
[Epoch 71; Iter   150/  183] train: loss: 0.0437527
[Epoch 58] ogbg-moltox21: 0.826957 val loss: 0.208389
[Epoch 58] ogbg-moltox21: 0.842684 test loss: 0.345280
[Epoch 59; Iter    14/  157] train: loss: 0.2031795
[Epoch 59; Iter    44/  157] train: loss: 0.1118397
[Epoch 59; Iter    74/  157] train: loss: 0.1749691
[Epoch 59; Iter   104/  157] train: loss: 0.1124577
[Epoch 59; Iter   134/  157] train: loss: 0.1613692
[Epoch 59] ogbg-moltox21: 0.832999 val loss: 0.201185
[Epoch 59] ogbg-moltox21: 0.846417 test loss: 0.252113
[Epoch 60; Iter     7/  157] train: loss: 0.1959240
[Epoch 60; Iter    37/  157] train: loss: 0.2078460
[Epoch 60; Iter    67/  157] train: loss: 0.1382014
[Epoch 60; Iter    97/  157] train: loss: 0.1396835
[Epoch 60; Iter   127/  157] train: loss: 0.1688440
[Epoch 60; Iter   157/  157] train: loss: 0.1993462
[Epoch 60] ogbg-moltox21: 0.838283 val loss: 0.185821
[Epoch 60] ogbg-moltox21: 0.841644 test loss: 0.207507
[Epoch 61; Iter    30/  157] train: loss: 0.0902650
[Epoch 61; Iter    60/  157] train: loss: 0.1716228
[Epoch 61; Iter    90/  157] train: loss: 0.2136244
[Epoch 61; Iter   120/  157] train: loss: 0.1141983
[Epoch 61; Iter   150/  157] train: loss: 0.1551853
[Epoch 61] ogbg-moltox21: 0.841718 val loss: 0.181681
[Epoch 61] ogbg-moltox21: 0.847640 test loss: 0.206259
[Epoch 62; Iter    23/  157] train: loss: 0.2052457
[Epoch 62; Iter    53/  157] train: loss: 0.1730342
[Epoch 62; Iter    83/  157] train: loss: 0.1812512
[Epoch 62; Iter   113/  157] train: loss: 0.2121947
[Epoch 62; Iter   143/  157] train: loss: 0.1957754
[Epoch 62] ogbg-moltox21: 0.828176 val loss: 0.292399
[Epoch 62] ogbg-moltox21: 0.833441 test loss: 0.286088
[Epoch 63; Iter    16/  157] train: loss: 0.1718833
[Epoch 63; Iter    46/  157] train: loss: 0.1849719
[Epoch 63; Iter    76/  157] train: loss: 0.1153002
[Epoch 63; Iter   106/  157] train: loss: 0.1865739
[Epoch 63; Iter   136/  157] train: loss: 0.0935366
[Epoch 63] ogbg-moltox21: 0.838878 val loss: 0.185155
[Epoch 63] ogbg-moltox21: 0.846713 test loss: 0.276084
[Epoch 64; Iter     9/  157] train: loss: 0.1137361
[Epoch 64; Iter    39/  157] train: loss: 0.1104680
[Epoch 64; Iter    69/  157] train: loss: 0.1109841
[Epoch 64; Iter    99/  157] train: loss: 0.2028444
[Epoch 64; Iter   129/  157] train: loss: 0.1007788
[Epoch 64] ogbg-moltox21: 0.835033 val loss: 0.203802
[Epoch 64] ogbg-moltox21: 0.843698 test loss: 0.316450
[Epoch 65; Iter     2/  157] train: loss: 0.1106155
[Epoch 65; Iter    32/  157] train: loss: 0.1292614
[Epoch 65; Iter    62/  157] train: loss: 0.0967933
[Epoch 65; Iter    92/  157] train: loss: 0.1025194
[Epoch 65; Iter   122/  157] train: loss: 0.1973642
[Epoch 65; Iter   152/  157] train: loss: 0.1339549
[Epoch 65] ogbg-moltox21: 0.834983 val loss: 0.269348
[Epoch 65] ogbg-moltox21: 0.837843 test loss: 0.399397
[Epoch 66; Iter    25/  157] train: loss: 0.1746196
[Epoch 66; Iter    55/  157] train: loss: 0.1026550
[Epoch 66; Iter    85/  157] train: loss: 0.1228691
[Epoch 66; Iter   115/  157] train: loss: 0.1172728
[Epoch 66; Iter   145/  157] train: loss: 0.1464499
[Epoch 66] ogbg-moltox21: 0.838374 val loss: 0.184196
[Epoch 66] ogbg-moltox21: 0.844193 test loss: 0.267376
[Epoch 67; Iter    18/  157] train: loss: 0.1220343
[Epoch 67; Iter    48/  157] train: loss: 0.1158287
[Epoch 67; Iter    78/  157] train: loss: 0.1182748
[Epoch 67; Iter   108/  157] train: loss: 0.1703536
[Epoch 67; Iter   138/  157] train: loss: 0.1384486
[Epoch 67] ogbg-moltox21: 0.833103 val loss: 0.223720
[Epoch 67] ogbg-moltox21: 0.839161 test loss: 0.272390
[Epoch 68; Iter    11/  157] train: loss: 0.0960075
[Epoch 68; Iter    41/  157] train: loss: 0.1307231
[Epoch 68; Iter    71/  157] train: loss: 0.1133701
[Epoch 68; Iter   101/  157] train: loss: 0.1077177
[Epoch 68; Iter   131/  157] train: loss: 0.0869933
[Epoch 68] ogbg-moltox21: 0.836590 val loss: 0.187643
[Epoch 68] ogbg-moltox21: 0.849024 test loss: 0.207363
[Epoch 69; Iter     4/  157] train: loss: 0.1168191
[Epoch 69; Iter    34/  157] train: loss: 0.1330350
[Epoch 69; Iter    64/  157] train: loss: 0.1134040
[Epoch 69; Iter    94/  157] train: loss: 0.0893811
[Epoch 69; Iter   124/  157] train: loss: 0.1537790
[Epoch 69; Iter   154/  157] train: loss: 0.1374841
[Epoch 69] ogbg-moltox21: 0.834369 val loss: 0.208506
[Epoch 69] ogbg-moltox21: 0.845646 test loss: 0.265441
[Epoch 70; Iter    27/  157] train: loss: 0.0753425
[Epoch 70; Iter    57/  157] train: loss: 0.1132701
[Epoch 70; Iter    87/  157] train: loss: 0.1499972
[Epoch 70; Iter   117/  157] train: loss: 0.0921447
[Epoch 70; Iter   147/  157] train: loss: 0.1238871
[Epoch 70] ogbg-moltox21: 0.832138 val loss: 0.198333
[Epoch 70] ogbg-moltox21: 0.843997 test loss: 0.323830
[Epoch 71; Iter    20/  157] train: loss: 0.1131207
[Epoch 71; Iter    50/  157] train: loss: 0.1292168
[Epoch 71; Iter    80/  157] train: loss: 0.1324394
[Epoch 71; Iter   110/  157] train: loss: 0.1295907
[Epoch 71; Iter   140/  157] train: loss: 0.1018941
[Epoch 71] ogbg-moltox21: 0.836666 val loss: 0.188112
[Epoch 71] ogbg-moltox21: 0.841672 test loss: 0.253001
[Epoch 72; Iter    13/  157] train: loss: 0.1811719
[Epoch 72; Iter    43/  157] train: loss: 0.1104300
[Epoch 72; Iter    73/  157] train: loss: 0.1024879
[Epoch 72; Iter   103/  157] train: loss: 0.1467863
[Epoch 72; Iter   133/  157] train: loss: 0.1393004
[Epoch 72] ogbg-moltox21: 0.829206 val loss: 0.220075
[Epoch 72] ogbg-moltox21: 0.836126 test loss: 0.255725
[Epoch 73; Iter     6/  157] train: loss: 0.1501402
[Epoch 73; Iter    36/  157] train: loss: 0.1375762
[Epoch 73; Iter    66/  157] train: loss: 0.1423292
[Epoch 73; Iter    96/  157] train: loss: 0.1316929
[Epoch 73; Iter   126/  157] train: loss: 0.2090906
[Epoch 73; Iter   156/  157] train: loss: 0.2057595
[Epoch 73] ogbg-moltox21: 0.824684 val loss: 0.231668
[Epoch 73] ogbg-moltox21: 0.830734 test loss: 0.282461
[Epoch 74; Iter    29/  157] train: loss: 0.0702493
[Epoch 74; Iter    59/  157] train: loss: 0.1449410
[Epoch 74; Iter    89/  157] train: loss: 0.0675635
[Epoch 74; Iter   119/  157] train: loss: 0.1878824
[Epoch 74; Iter   149/  157] train: loss: 0.1067032
[Epoch 74] ogbg-moltox21: 0.830093 val loss: 0.218572
[Epoch 74] ogbg-moltox21: 0.839298 test loss: 0.283893
[Epoch 75; Iter    22/  157] train: loss: 0.1505923
[Epoch 75; Iter    52/  157] train: loss: 0.0841339
[Epoch 75; Iter    82/  157] train: loss: 0.1547814
[Epoch 75; Iter   112/  157] train: loss: 0.1616432
[Epoch 75; Iter   142/  157] train: loss: 0.1224029
[Epoch 75] ogbg-moltox21: 0.831656 val loss: 0.226859
[Epoch 75] ogbg-moltox21: 0.839510 test loss: 0.250903
[Epoch 76; Iter    15/  157] train: loss: 0.1161064
[Epoch 76; Iter    45/  157] train: loss: 0.1062887
[Epoch 76; Iter    75/  157] train: loss: 0.1130763
[Epoch 76; Iter   105/  157] train: loss: 0.0935145
[Epoch 76; Iter   135/  157] train: loss: 0.1659318
[Epoch 76] ogbg-moltox21: 0.832618 val loss: 0.207442
[Epoch 76] ogbg-moltox21: 0.840317 test loss: 0.230311
[Epoch 77; Iter     8/  157] train: loss: 0.1034733
[Epoch 77; Iter    38/  157] train: loss: 0.1015717
[Epoch 77; Iter    68/  157] train: loss: 0.1416093
[Epoch 77; Iter    98/  157] train: loss: 0.1123187
[Epoch 77; Iter   128/  157] train: loss: 0.1101499
[Epoch 77] ogbg-moltox21: 0.826930 val loss: 0.232350
[Epoch 77] ogbg-moltox21: 0.836811 test loss: 0.329033
[Epoch 78; Iter     1/  157] train: loss: 0.1974567
[Epoch 78; Iter    31/  157] train: loss: 0.1868039
[Epoch 78; Iter    61/  157] train: loss: 0.0903968
[Epoch 78; Iter    91/  157] train: loss: 0.1423490
[Epoch 78; Iter   121/  157] train: loss: 0.1345242
[Epoch 78; Iter   151/  157] train: loss: 0.1271136
[Epoch 78] ogbg-moltox21: 0.827840 val loss: 0.193394
[Epoch 78] ogbg-moltox21: 0.843712 test loss: 0.219587
[Epoch 79; Iter    24/  157] train: loss: 0.1559064
[Epoch 79; Iter    54/  157] train: loss: 0.1388097
[Epoch 79; Iter    84/  157] train: loss: 0.1223216
[Epoch 79; Iter   114/  157] train: loss: 0.1180976
[Epoch 79; Iter   144/  157] train: loss: 0.1158121
[Epoch 79] ogbg-moltox21: 0.829945 val loss: 0.244840
[Epoch 79] ogbg-moltox21: 0.843452 test loss: 0.285699
[Epoch 80; Iter    17/  157] train: loss: 0.1919290
[Epoch 58] ogbg-moltox21: 0.837654 val loss: 0.197680
[Epoch 58] ogbg-moltox21: 0.835096 test loss: 0.218405
[Epoch 59; Iter    14/  157] train: loss: 0.0957428
[Epoch 59; Iter    44/  157] train: loss: 0.0897686
[Epoch 59; Iter    74/  157] train: loss: 0.1245531
[Epoch 59; Iter   104/  157] train: loss: 0.1103529
[Epoch 59; Iter   134/  157] train: loss: 0.1809238
[Epoch 59] ogbg-moltox21: 0.835928 val loss: 0.195952
[Epoch 59] ogbg-moltox21: 0.826798 test loss: 0.223531
[Epoch 60; Iter     7/  157] train: loss: 0.1085048
[Epoch 60; Iter    37/  157] train: loss: 0.1212103
[Epoch 60; Iter    67/  157] train: loss: 0.0814507
[Epoch 60; Iter    97/  157] train: loss: 0.1124841
[Epoch 60; Iter   127/  157] train: loss: 0.0833428
[Epoch 60; Iter   157/  157] train: loss: 0.0721475
[Epoch 60] ogbg-moltox21: 0.830830 val loss: 0.204993
[Epoch 60] ogbg-moltox21: 0.828817 test loss: 0.228857
[Epoch 61; Iter    30/  157] train: loss: 0.0917539
[Epoch 61; Iter    60/  157] train: loss: 0.1235747
[Epoch 61; Iter    90/  157] train: loss: 0.0815518
[Epoch 61; Iter   120/  157] train: loss: 0.0804597
[Epoch 61; Iter   150/  157] train: loss: 0.1037169
[Epoch 61] ogbg-moltox21: 0.828139 val loss: 0.204123
[Epoch 61] ogbg-moltox21: 0.825174 test loss: 0.226670
[Epoch 62; Iter    23/  157] train: loss: 0.1345346
[Epoch 62; Iter    53/  157] train: loss: 0.1052699
[Epoch 62; Iter    83/  157] train: loss: 0.1205370
[Epoch 62; Iter   113/  157] train: loss: 0.1010774
[Epoch 62; Iter   143/  157] train: loss: 0.1093722
[Epoch 62] ogbg-moltox21: 0.824126 val loss: 0.204715
[Epoch 62] ogbg-moltox21: 0.830875 test loss: 0.226878
[Epoch 63; Iter    16/  157] train: loss: 0.0848848
[Epoch 63; Iter    46/  157] train: loss: 0.0857058
[Epoch 63; Iter    76/  157] train: loss: 0.1245847
[Epoch 63; Iter   106/  157] train: loss: 0.1100450
[Epoch 63; Iter   136/  157] train: loss: 0.1279426
[Epoch 63] ogbg-moltox21: 0.827708 val loss: 0.206005
[Epoch 63] ogbg-moltox21: 0.828621 test loss: 0.228905
[Epoch 64; Iter     9/  157] train: loss: 0.0685277
[Epoch 64; Iter    39/  157] train: loss: 0.0692691
[Epoch 64; Iter    69/  157] train: loss: 0.1255646
[Epoch 64; Iter    99/  157] train: loss: 0.0954462
[Epoch 64; Iter   129/  157] train: loss: 0.1344801
[Epoch 64] ogbg-moltox21: 0.838344 val loss: 0.213251
[Epoch 64] ogbg-moltox21: 0.832909 test loss: 0.238716
[Epoch 65; Iter     2/  157] train: loss: 0.0798794
[Epoch 65; Iter    32/  157] train: loss: 0.0673188
[Epoch 65; Iter    62/  157] train: loss: 0.1821697
[Epoch 65; Iter    92/  157] train: loss: 0.1265163
[Epoch 65; Iter   122/  157] train: loss: 0.1469062
[Epoch 65; Iter   152/  157] train: loss: 0.0752427
[Epoch 65] ogbg-moltox21: 0.834599 val loss: 0.200218
[Epoch 65] ogbg-moltox21: 0.827074 test loss: 0.230750
[Epoch 66; Iter    25/  157] train: loss: 0.0759158
[Epoch 66; Iter    55/  157] train: loss: 0.0337774
[Epoch 66; Iter    85/  157] train: loss: 0.1121983
[Epoch 66; Iter   115/  157] train: loss: 0.0661189
[Epoch 66; Iter   145/  157] train: loss: 0.0602614
[Epoch 66] ogbg-moltox21: 0.832385 val loss: 0.207207
[Epoch 66] ogbg-moltox21: 0.825040 test loss: 0.236888
[Epoch 67; Iter    18/  157] train: loss: 0.0793798
[Epoch 67; Iter    48/  157] train: loss: 0.0578418
[Epoch 67; Iter    78/  157] train: loss: 0.0855669
[Epoch 67; Iter   108/  157] train: loss: 0.1230005
[Epoch 67; Iter   138/  157] train: loss: 0.0800972
[Epoch 67] ogbg-moltox21: 0.823582 val loss: 0.210096
[Epoch 67] ogbg-moltox21: 0.820092 test loss: 0.238302
[Epoch 68; Iter    11/  157] train: loss: 0.0647192
[Epoch 68; Iter    41/  157] train: loss: 0.0591293
[Epoch 68; Iter    71/  157] train: loss: 0.1110181
[Epoch 68; Iter   101/  157] train: loss: 0.0621137
[Epoch 68; Iter   131/  157] train: loss: 0.1068305
[Epoch 68] ogbg-moltox21: 0.826408 val loss: 0.212947
[Epoch 68] ogbg-moltox21: 0.825387 test loss: 0.239569
[Epoch 69; Iter     4/  157] train: loss: 0.0894769
[Epoch 69; Iter    34/  157] train: loss: 0.2255857
[Epoch 69; Iter    64/  157] train: loss: 0.0635424
[Epoch 69; Iter    94/  157] train: loss: 0.0909939
[Epoch 69; Iter   124/  157] train: loss: 0.1098195
[Epoch 69; Iter   154/  157] train: loss: 0.0562963
[Epoch 69] ogbg-moltox21: 0.827022 val loss: 0.213090
[Epoch 69] ogbg-moltox21: 0.822091 test loss: 0.239258
[Epoch 70; Iter    27/  157] train: loss: 0.0579849
[Epoch 70; Iter    57/  157] train: loss: 0.0858907
[Epoch 70; Iter    87/  157] train: loss: 0.0740298
[Epoch 70; Iter   117/  157] train: loss: 0.0587953
[Epoch 70; Iter   147/  157] train: loss: 0.0903418
[Epoch 70] ogbg-moltox21: 0.820332 val loss: 0.214222
[Epoch 70] ogbg-moltox21: 0.815793 test loss: 0.241812
[Epoch 71; Iter    20/  157] train: loss: 0.0749012
[Epoch 71; Iter    50/  157] train: loss: 0.0554439
[Epoch 71; Iter    80/  157] train: loss: 0.0527913
[Epoch 71; Iter   110/  157] train: loss: 0.0610442
[Epoch 71; Iter   140/  157] train: loss: 0.0682138
[Epoch 71] ogbg-moltox21: 0.819991 val loss: 0.219951
[Epoch 71] ogbg-moltox21: 0.818063 test loss: 0.250663
[Epoch 72; Iter    13/  157] train: loss: 0.0642109
[Epoch 72; Iter    43/  157] train: loss: 0.1009864
[Epoch 72; Iter    73/  157] train: loss: 0.0684874
[Epoch 72; Iter   103/  157] train: loss: 0.1221232
[Epoch 72; Iter   133/  157] train: loss: 0.0825560
[Epoch 72] ogbg-moltox21: 0.821676 val loss: 0.225278
[Epoch 72] ogbg-moltox21: 0.818094 test loss: 0.252089
[Epoch 73; Iter     6/  157] train: loss: 0.0983384
[Epoch 73; Iter    36/  157] train: loss: 0.0569265
[Epoch 73; Iter    66/  157] train: loss: 0.1055837
[Epoch 73; Iter    96/  157] train: loss: 0.0917806
[Epoch 73; Iter   126/  157] train: loss: 0.0544548
[Epoch 73; Iter   156/  157] train: loss: 0.0800573
[Epoch 73] ogbg-moltox21: 0.818482 val loss: 0.223404
[Epoch 73] ogbg-moltox21: 0.814323 test loss: 0.251296
[Epoch 74; Iter    29/  157] train: loss: 0.1034390
[Epoch 74; Iter    59/  157] train: loss: 0.0768083
[Epoch 74; Iter    89/  157] train: loss: 0.0469178
[Epoch 74; Iter   119/  157] train: loss: 0.1026273
[Epoch 74; Iter   149/  157] train: loss: 0.0941528
[Epoch 74] ogbg-moltox21: 0.820276 val loss: 0.222512
[Epoch 74] ogbg-moltox21: 0.821132 test loss: 0.251006
[Epoch 75; Iter    22/  157] train: loss: 0.0799456
[Epoch 75; Iter    52/  157] train: loss: 0.1606732
[Epoch 75; Iter    82/  157] train: loss: 0.0426175
[Epoch 75; Iter   112/  157] train: loss: 0.0686542
[Epoch 75; Iter   142/  157] train: loss: 0.1211454
[Epoch 75] ogbg-moltox21: 0.816621 val loss: 0.228065
[Epoch 75] ogbg-moltox21: 0.812785 test loss: 0.256590
[Epoch 76; Iter    15/  157] train: loss: 0.0751474
[Epoch 76; Iter    45/  157] train: loss: 0.1793113
[Epoch 76; Iter    75/  157] train: loss: 0.0874508
[Epoch 76; Iter   105/  157] train: loss: 0.0351578
[Epoch 76; Iter   135/  157] train: loss: 0.0512774
[Epoch 76] ogbg-moltox21: 0.819457 val loss: 0.230110
[Epoch 76] ogbg-moltox21: 0.815472 test loss: 0.262745
[Epoch 77; Iter     8/  157] train: loss: 0.0708346
[Epoch 77; Iter    38/  157] train: loss: 0.0959543
[Epoch 77; Iter    68/  157] train: loss: 0.0926910
[Epoch 77; Iter    98/  157] train: loss: 0.0594189
[Epoch 77; Iter   128/  157] train: loss: 0.0404578
[Epoch 77] ogbg-moltox21: 0.813892 val loss: 0.231483
[Epoch 77] ogbg-moltox21: 0.808239 test loss: 0.271018
[Epoch 78; Iter     1/  157] train: loss: 0.0571735
[Epoch 78; Iter    31/  157] train: loss: 0.0634967
[Epoch 78; Iter    61/  157] train: loss: 0.0416823
[Epoch 78; Iter    91/  157] train: loss: 0.0409484
[Epoch 78; Iter   121/  157] train: loss: 0.0949049
[Epoch 78; Iter   151/  157] train: loss: 0.0309075
[Epoch 78] ogbg-moltox21: 0.822978 val loss: 0.231537
[Epoch 78] ogbg-moltox21: 0.817573 test loss: 0.272068
[Epoch 79; Iter    24/  157] train: loss: 0.0921368
[Epoch 79; Iter    54/  157] train: loss: 0.0878989
[Epoch 79; Iter    84/  157] train: loss: 0.0630455
[Epoch 79; Iter   114/  157] train: loss: 0.0918719
[Epoch 79; Iter   144/  157] train: loss: 0.0677694
[Epoch 79] ogbg-moltox21: 0.815415 val loss: 0.235788
[Epoch 79] ogbg-moltox21: 0.819828 test loss: 0.262909
[Epoch 80; Iter    17/  157] train: loss: 0.0423415
[Epoch 58] ogbg-moltox21: 0.822882 val loss: 0.201255
[Epoch 58] ogbg-moltox21: 0.837967 test loss: 0.210449
[Epoch 59; Iter    14/  157] train: loss: 0.0807560
[Epoch 59; Iter    44/  157] train: loss: 0.1824183
[Epoch 59; Iter    74/  157] train: loss: 0.1209910
[Epoch 59; Iter   104/  157] train: loss: 0.1727782
[Epoch 59; Iter   134/  157] train: loss: 0.1407809
[Epoch 59] ogbg-moltox21: 0.820781 val loss: 0.205213
[Epoch 59] ogbg-moltox21: 0.833896 test loss: 0.215344
[Epoch 60; Iter     7/  157] train: loss: 0.1053166
[Epoch 60; Iter    37/  157] train: loss: 0.1049048
[Epoch 60; Iter    67/  157] train: loss: 0.1053025
[Epoch 60; Iter    97/  157] train: loss: 0.1203825
[Epoch 60; Iter   127/  157] train: loss: 0.1403635
[Epoch 60; Iter   157/  157] train: loss: 0.1254478
[Epoch 60] ogbg-moltox21: 0.821802 val loss: 0.215656
[Epoch 60] ogbg-moltox21: 0.833232 test loss: 0.212929
[Epoch 61; Iter    30/  157] train: loss: 0.0947256
[Epoch 61; Iter    60/  157] train: loss: 0.0953963
[Epoch 61; Iter    90/  157] train: loss: 0.1052223
[Epoch 61; Iter   120/  157] train: loss: 0.0949733
[Epoch 61; Iter   150/  157] train: loss: 0.0772444
[Epoch 61] ogbg-moltox21: 0.818588 val loss: 0.205843
[Epoch 61] ogbg-moltox21: 0.825436 test loss: 0.220904
[Epoch 62; Iter    23/  157] train: loss: 0.1603472
[Epoch 62; Iter    53/  157] train: loss: 0.1688122
[Epoch 62; Iter    83/  157] train: loss: 0.1133366
[Epoch 62; Iter   113/  157] train: loss: 0.0916980
[Epoch 62; Iter   143/  157] train: loss: 0.1476789
[Epoch 62] ogbg-moltox21: 0.808033 val loss: 0.212873
[Epoch 62] ogbg-moltox21: 0.820629 test loss: 0.225732
[Epoch 63; Iter    16/  157] train: loss: 0.1034454
[Epoch 63; Iter    46/  157] train: loss: 0.1053875
[Epoch 63; Iter    76/  157] train: loss: 0.1092594
[Epoch 63; Iter   106/  157] train: loss: 0.1149508
[Epoch 63; Iter   136/  157] train: loss: 0.1256964
[Epoch 63] ogbg-moltox21: 0.816643 val loss: 0.223868
[Epoch 63] ogbg-moltox21: 0.827856 test loss: 0.221429
[Epoch 64; Iter     9/  157] train: loss: 0.1023582
[Epoch 64; Iter    39/  157] train: loss: 0.0904339
[Epoch 64; Iter    69/  157] train: loss: 0.1077246
[Epoch 64; Iter    99/  157] train: loss: 0.0726188
[Epoch 64; Iter   129/  157] train: loss: 0.0920555
[Epoch 64] ogbg-moltox21: 0.813611 val loss: 0.215960
[Epoch 64] ogbg-moltox21: 0.821794 test loss: 0.228862
[Epoch 65; Iter     2/  157] train: loss: 0.0828328
[Epoch 65; Iter    32/  157] train: loss: 0.0977058
[Epoch 65; Iter    62/  157] train: loss: 0.0808067
[Epoch 65; Iter    92/  157] train: loss: 0.0891520
[Epoch 65; Iter   122/  157] train: loss: 0.0798369
[Epoch 65; Iter   152/  157] train: loss: 0.1301189
[Epoch 65] ogbg-moltox21: 0.822067 val loss: 0.206169
[Epoch 65] ogbg-moltox21: 0.829403 test loss: 0.219054
[Epoch 66; Iter    25/  157] train: loss: 0.1358909
[Epoch 66; Iter    55/  157] train: loss: 0.0730690
[Epoch 66; Iter    85/  157] train: loss: 0.0895284
[Epoch 66; Iter   115/  157] train: loss: 0.1088070
[Epoch 66; Iter   145/  157] train: loss: 0.0818888
[Epoch 66] ogbg-moltox21: 0.823040 val loss: 0.205502
[Epoch 66] ogbg-moltox21: 0.834236 test loss: 0.233712
[Epoch 67; Iter    18/  157] train: loss: 0.0930774
[Epoch 67; Iter    48/  157] train: loss: 0.0706691
[Epoch 67; Iter    78/  157] train: loss: 0.0917990
[Epoch 67; Iter   108/  157] train: loss: 0.0573798
[Epoch 67; Iter   138/  157] train: loss: 0.0948949
[Epoch 67] ogbg-moltox21: 0.811842 val loss: 0.216687
[Epoch 67] ogbg-moltox21: 0.826941 test loss: 0.228411
[Epoch 68; Iter    11/  157] train: loss: 0.0999640
[Epoch 68; Iter    41/  157] train: loss: 0.1400036
[Epoch 68; Iter    71/  157] train: loss: 0.0843208
[Epoch 68; Iter   101/  157] train: loss: 0.1084023
[Epoch 68; Iter   131/  157] train: loss: 0.0637982
[Epoch 68] ogbg-moltox21: 0.818907 val loss: 0.214248
[Epoch 68] ogbg-moltox21: 0.828594 test loss: 0.232003
[Epoch 69; Iter     4/  157] train: loss: 0.0616746
[Epoch 69; Iter    34/  157] train: loss: 0.0858134
[Epoch 69; Iter    64/  157] train: loss: 0.1166155
[Epoch 69; Iter    94/  157] train: loss: 0.0924689
[Epoch 69; Iter   124/  157] train: loss: 0.0895952
[Epoch 69; Iter   154/  157] train: loss: 0.0578130
[Epoch 69] ogbg-moltox21: 0.809412 val loss: 0.214673
[Epoch 69] ogbg-moltox21: 0.824358 test loss: 0.234746
[Epoch 70; Iter    27/  157] train: loss: 0.0603912
[Epoch 70; Iter    57/  157] train: loss: 0.0912202
[Epoch 70; Iter    87/  157] train: loss: 0.0789942
[Epoch 70; Iter   117/  157] train: loss: 0.0932685
[Epoch 70; Iter   147/  157] train: loss: 0.0687236
[Epoch 70] ogbg-moltox21: 0.808949 val loss: 0.216156
[Epoch 70] ogbg-moltox21: 0.821716 test loss: 0.231206
[Epoch 71; Iter    20/  157] train: loss: 0.1009171
[Epoch 71; Iter    50/  157] train: loss: 0.1027733
[Epoch 71; Iter    80/  157] train: loss: 0.0503710
[Epoch 71; Iter   110/  157] train: loss: 0.0824255
[Epoch 71; Iter   140/  157] train: loss: 0.1168069
[Epoch 71] ogbg-moltox21: 0.807133 val loss: 0.233289
[Epoch 71] ogbg-moltox21: 0.822715 test loss: 0.236223
[Epoch 72; Iter    13/  157] train: loss: 0.0470407
[Epoch 72; Iter    43/  157] train: loss: 0.1058195
[Epoch 72; Iter    73/  157] train: loss: 0.1436414
[Epoch 72; Iter   103/  157] train: loss: 0.0733020
[Epoch 72; Iter   133/  157] train: loss: 0.0594567
[Epoch 72] ogbg-moltox21: 0.811702 val loss: 0.223397
[Epoch 72] ogbg-moltox21: 0.824051 test loss: 0.234481
[Epoch 73; Iter     6/  157] train: loss: 0.0891579
[Epoch 73; Iter    36/  157] train: loss: 0.0833460
[Epoch 73; Iter    66/  157] train: loss: 0.1283111
[Epoch 73; Iter    96/  157] train: loss: 0.0958154
[Epoch 73; Iter   126/  157] train: loss: 0.0618376
[Epoch 73; Iter   156/  157] train: loss: 0.1132277
[Epoch 73] ogbg-moltox21: 0.812657 val loss: 0.231645
[Epoch 73] ogbg-moltox21: 0.829530 test loss: 0.234880
[Epoch 74; Iter    29/  157] train: loss: 0.2098222
[Epoch 74; Iter    59/  157] train: loss: 0.0856992
[Epoch 74; Iter    89/  157] train: loss: 0.0827580
[Epoch 74; Iter   119/  157] train: loss: 0.1500092
[Epoch 74; Iter   149/  157] train: loss: 0.0710221
[Epoch 74] ogbg-moltox21: 0.801906 val loss: 0.290105
[Epoch 74] ogbg-moltox21: 0.816411 test loss: 0.255896
[Epoch 75; Iter    22/  157] train: loss: 0.0444152
[Epoch 75; Iter    52/  157] train: loss: 0.0814368
[Epoch 75; Iter    82/  157] train: loss: 0.0790957
[Epoch 75; Iter   112/  157] train: loss: 0.1335057
[Epoch 75; Iter   142/  157] train: loss: 0.0806981
[Epoch 75] ogbg-moltox21: 0.813727 val loss: 0.231508
[Epoch 75] ogbg-moltox21: 0.821854 test loss: 0.242053
[Epoch 76; Iter    15/  157] train: loss: 0.0673261
[Epoch 76; Iter    45/  157] train: loss: 0.0544650
[Epoch 76; Iter    75/  157] train: loss: 0.1325394
[Epoch 76; Iter   105/  157] train: loss: 0.0757024
[Epoch 76; Iter   135/  157] train: loss: 0.0821406
[Epoch 76] ogbg-moltox21: 0.807124 val loss: 0.289410
[Epoch 76] ogbg-moltox21: 0.823816 test loss: 0.246150
[Epoch 77; Iter     8/  157] train: loss: 0.0509033
[Epoch 77; Iter    38/  157] train: loss: 0.0977609
[Epoch 77; Iter    68/  157] train: loss: 0.1506406
[Epoch 77; Iter    98/  157] train: loss: 0.0799931
[Epoch 77; Iter   128/  157] train: loss: 0.0692535
[Epoch 77] ogbg-moltox21: 0.810600 val loss: 0.278829
[Epoch 77] ogbg-moltox21: 0.827663 test loss: 0.243150
[Epoch 78; Iter     1/  157] train: loss: 0.0923331
[Epoch 78; Iter    31/  157] train: loss: 0.0861317
[Epoch 78; Iter    61/  157] train: loss: 0.0597244
[Epoch 78; Iter    91/  157] train: loss: 0.0958519
[Epoch 78; Iter   121/  157] train: loss: 0.0880173
[Epoch 78; Iter   151/  157] train: loss: 0.0632545
[Epoch 78] ogbg-moltox21: 0.811898 val loss: 0.227257
[Epoch 78] ogbg-moltox21: 0.827801 test loss: 0.237916
[Epoch 79; Iter    24/  157] train: loss: 0.1111287
[Epoch 79; Iter    54/  157] train: loss: 0.0404035
[Epoch 79; Iter    84/  157] train: loss: 0.0609246
[Epoch 79; Iter   114/  157] train: loss: 0.1237566
[Epoch 79; Iter   144/  157] train: loss: 0.1240555
[Epoch 79] ogbg-moltox21: 0.805354 val loss: 0.284335
[Epoch 79] ogbg-moltox21: 0.821957 test loss: 0.251772
[Epoch 80; Iter    17/  157] train: loss: 0.0439965
[Epoch 64] ogbg-moltox21: 0.836074 test loss: 0.231431
[Epoch 65; Iter     4/  209] train: loss: 0.0605730
[Epoch 65; Iter    34/  209] train: loss: 0.1227983
[Epoch 65; Iter    64/  209] train: loss: 0.0916667
[Epoch 65; Iter    94/  209] train: loss: 0.0833616
[Epoch 65; Iter   124/  209] train: loss: 0.0639656
[Epoch 65; Iter   154/  209] train: loss: 0.0963406
[Epoch 65; Iter   184/  209] train: loss: 0.0916523
[Epoch 65] ogbg-moltox21: 0.856784 val loss: 0.223861
[Epoch 65] ogbg-moltox21: 0.842315 test loss: 0.225411
[Epoch 66; Iter     5/  209] train: loss: 0.0925326
[Epoch 66; Iter    35/  209] train: loss: 0.0969910
[Epoch 66; Iter    65/  209] train: loss: 0.1067993
[Epoch 66; Iter    95/  209] train: loss: 0.0705582
[Epoch 66; Iter   125/  209] train: loss: 0.0964166
[Epoch 66; Iter   155/  209] train: loss: 0.1184576
[Epoch 66; Iter   185/  209] train: loss: 0.0474057
[Epoch 66] ogbg-moltox21: 0.853817 val loss: 0.232978
[Epoch 66] ogbg-moltox21: 0.845636 test loss: 0.223215
[Epoch 67; Iter     6/  209] train: loss: 0.0675006
[Epoch 67; Iter    36/  209] train: loss: 0.1054318
[Epoch 67; Iter    66/  209] train: loss: 0.0690914
[Epoch 67; Iter    96/  209] train: loss: 0.0732671
[Epoch 67; Iter   126/  209] train: loss: 0.1395252
[Epoch 67; Iter   156/  209] train: loss: 0.1235695
[Epoch 67; Iter   186/  209] train: loss: 0.0947476
[Epoch 67] ogbg-moltox21: 0.847940 val loss: 0.232312
[Epoch 67] ogbg-moltox21: 0.842427 test loss: 0.220946
[Epoch 68; Iter     7/  209] train: loss: 0.0567361
[Epoch 68; Iter    37/  209] train: loss: 0.1348172
[Epoch 68; Iter    67/  209] train: loss: 0.0996969
[Epoch 68; Iter    97/  209] train: loss: 0.0889563
[Epoch 68; Iter   127/  209] train: loss: 0.0883112
[Epoch 68; Iter   157/  209] train: loss: 0.0535068
[Epoch 68; Iter   187/  209] train: loss: 0.0648569
[Epoch 68] ogbg-moltox21: 0.846934 val loss: 0.240128
[Epoch 68] ogbg-moltox21: 0.837945 test loss: 0.232812
[Epoch 69; Iter     8/  209] train: loss: 0.1626655
[Epoch 69; Iter    38/  209] train: loss: 0.0784025
[Epoch 69; Iter    68/  209] train: loss: 0.1133923
[Epoch 69; Iter    98/  209] train: loss: 0.0651081
[Epoch 69; Iter   128/  209] train: loss: 0.0928646
[Epoch 69; Iter   158/  209] train: loss: 0.0887194
[Epoch 69; Iter   188/  209] train: loss: 0.0599176
[Epoch 69] ogbg-moltox21: 0.846287 val loss: 0.241652
[Epoch 69] ogbg-moltox21: 0.839264 test loss: 0.232611
[Epoch 70; Iter     9/  209] train: loss: 0.1135006
[Epoch 70; Iter    39/  209] train: loss: 0.0860118
[Epoch 70; Iter    69/  209] train: loss: 0.0661036
[Epoch 70; Iter    99/  209] train: loss: 0.0688985
[Epoch 70; Iter   129/  209] train: loss: 0.1063555
[Epoch 70; Iter   159/  209] train: loss: 0.0662939
[Epoch 70; Iter   189/  209] train: loss: 0.0527219
[Epoch 70] ogbg-moltox21: 0.847446 val loss: 0.240440
[Epoch 70] ogbg-moltox21: 0.846056 test loss: 0.230104
[Epoch 71; Iter    10/  209] train: loss: 0.0622882
[Epoch 71; Iter    40/  209] train: loss: 0.1463844
[Epoch 71; Iter    70/  209] train: loss: 0.1497603
[Epoch 71; Iter   100/  209] train: loss: 0.0783599
[Epoch 71; Iter   130/  209] train: loss: 0.0578883
[Epoch 71; Iter   160/  209] train: loss: 0.0772481
[Epoch 71; Iter   190/  209] train: loss: 0.0770268
[Epoch 71] ogbg-moltox21: 0.850087 val loss: 0.253391
[Epoch 71] ogbg-moltox21: 0.835992 test loss: 0.240312
[Epoch 72; Iter    11/  209] train: loss: 0.0721544
[Epoch 72; Iter    41/  209] train: loss: 0.1007686
[Epoch 72; Iter    71/  209] train: loss: 0.0819931
[Epoch 72; Iter   101/  209] train: loss: 0.0739949
[Epoch 72; Iter   131/  209] train: loss: 0.0968930
[Epoch 72; Iter   161/  209] train: loss: 0.0651747
[Epoch 72; Iter   191/  209] train: loss: 0.1242476
[Epoch 72] ogbg-moltox21: 0.849427 val loss: 0.244881
[Epoch 72] ogbg-moltox21: 0.840333 test loss: 0.233885
[Epoch 73; Iter    12/  209] train: loss: 0.0758521
[Epoch 73; Iter    42/  209] train: loss: 0.0613058
[Epoch 73; Iter    72/  209] train: loss: 0.0735430
[Epoch 73; Iter   102/  209] train: loss: 0.0725459
[Epoch 73; Iter   132/  209] train: loss: 0.0484596
[Epoch 73; Iter   162/  209] train: loss: 0.0595311
[Epoch 73; Iter   192/  209] train: loss: 0.1068181
[Epoch 73] ogbg-moltox21: 0.847381 val loss: 0.251735
[Epoch 73] ogbg-moltox21: 0.834321 test loss: 0.242515
[Epoch 74; Iter    13/  209] train: loss: 0.0507366
[Epoch 74; Iter    43/  209] train: loss: 0.1484696
[Epoch 74; Iter    73/  209] train: loss: 0.0577377
[Epoch 74; Iter   103/  209] train: loss: 0.0681374
[Epoch 74; Iter   133/  209] train: loss: 0.0913588
[Epoch 74; Iter   163/  209] train: loss: 0.0838164
[Epoch 74; Iter   193/  209] train: loss: 0.0620851
[Epoch 74] ogbg-moltox21: 0.849989 val loss: 0.254077
[Epoch 74] ogbg-moltox21: 0.834653 test loss: 0.237401
[Epoch 75; Iter    14/  209] train: loss: 0.1203175
[Epoch 75; Iter    44/  209] train: loss: 0.0559745
[Epoch 75; Iter    74/  209] train: loss: 0.0630260
[Epoch 75; Iter   104/  209] train: loss: 0.0649374
[Epoch 75; Iter   134/  209] train: loss: 0.0647950
[Epoch 75; Iter   164/  209] train: loss: 0.0920874
[Epoch 75; Iter   194/  209] train: loss: 0.0803997
[Epoch 75] ogbg-moltox21: 0.846176 val loss: 0.261227
[Epoch 75] ogbg-moltox21: 0.834709 test loss: 0.245237
[Epoch 76; Iter    15/  209] train: loss: 0.1149109
[Epoch 76; Iter    45/  209] train: loss: 0.0745108
[Epoch 76; Iter    75/  209] train: loss: 0.0544639
[Epoch 76; Iter   105/  209] train: loss: 0.0627236
[Epoch 76; Iter   135/  209] train: loss: 0.0713501
[Epoch 76; Iter   165/  209] train: loss: 0.1063116
[Epoch 76; Iter   195/  209] train: loss: 0.0749116
[Epoch 76] ogbg-moltox21: 0.844371 val loss: 0.261080
[Epoch 76] ogbg-moltox21: 0.829884 test loss: 0.248067
[Epoch 77; Iter    16/  209] train: loss: 0.1284026
[Epoch 77; Iter    46/  209] train: loss: 0.0947594
[Epoch 77; Iter    76/  209] train: loss: 0.0540696
[Epoch 77; Iter   106/  209] train: loss: 0.0611698
[Epoch 77; Iter   136/  209] train: loss: 0.0502544
[Epoch 77; Iter   166/  209] train: loss: 0.0698341
[Epoch 77; Iter   196/  209] train: loss: 0.0523590
[Epoch 77] ogbg-moltox21: 0.841837 val loss: 0.254685
[Epoch 77] ogbg-moltox21: 0.829352 test loss: 0.250803
[Epoch 78; Iter    17/  209] train: loss: 0.1091473
[Epoch 78; Iter    47/  209] train: loss: 0.1174059
[Epoch 78; Iter    77/  209] train: loss: 0.1346386
[Epoch 78; Iter   107/  209] train: loss: 0.0677648
[Epoch 78; Iter   137/  209] train: loss: 0.0693927
[Epoch 78; Iter   167/  209] train: loss: 0.0956230
[Epoch 78; Iter   197/  209] train: loss: 0.0745916
[Epoch 78] ogbg-moltox21: 0.852046 val loss: 0.260777
[Epoch 78] ogbg-moltox21: 0.837640 test loss: 0.250720
[Epoch 79; Iter    18/  209] train: loss: 0.0559407
[Epoch 79; Iter    48/  209] train: loss: 0.0715397
[Epoch 79; Iter    78/  209] train: loss: 0.1456336
[Epoch 79; Iter   108/  209] train: loss: 0.0527000
[Epoch 79; Iter   138/  209] train: loss: 0.0683323
[Epoch 79; Iter   168/  209] train: loss: 0.0858935
[Epoch 79; Iter   198/  209] train: loss: 0.0412111
[Epoch 79] ogbg-moltox21: 0.844008 val loss: 0.259685
[Epoch 79] ogbg-moltox21: 0.836142 test loss: 0.248724
[Epoch 80; Iter    19/  209] train: loss: 0.0809775
[Epoch 80; Iter    49/  209] train: loss: 0.0713446
[Epoch 80; Iter    79/  209] train: loss: 0.0558690
[Epoch 80; Iter   109/  209] train: loss: 0.0726388
[Epoch 80; Iter   139/  209] train: loss: 0.0489534
[Epoch 80; Iter   169/  209] train: loss: 0.0568333
[Epoch 80; Iter   199/  209] train: loss: 0.0495146
[Epoch 80] ogbg-moltox21: 0.846427 val loss: 0.259354
[Epoch 80] ogbg-moltox21: 0.833740 test loss: 0.248397
[Epoch 81; Iter    20/  209] train: loss: 0.0893771
[Epoch 81; Iter    50/  209] train: loss: 0.1041412
[Epoch 81; Iter    80/  209] train: loss: 0.0681289
[Epoch 81; Iter   110/  209] train: loss: 0.0963456
[Epoch 81; Iter   140/  209] train: loss: 0.0848903
[Epoch 81; Iter   170/  209] train: loss: 0.1138997
[Epoch 81; Iter   200/  209] train: loss: 0.0756430
[Epoch 81] ogbg-moltox21: 0.840317 val loss: 0.263383
[Epoch 81] ogbg-moltox21: 0.831460 test loss: 0.249902
[Epoch 82; Iter    21/  209] train: loss: 0.0624624
[Epoch 64] ogbg-moltox21: 0.837713 test loss: 0.232541
[Epoch 65; Iter     4/  209] train: loss: 0.1427189
[Epoch 65; Iter    34/  209] train: loss: 0.1452183
[Epoch 65; Iter    64/  209] train: loss: 0.1076623
[Epoch 65; Iter    94/  209] train: loss: 0.1351473
[Epoch 65; Iter   124/  209] train: loss: 0.0766454
[Epoch 65; Iter   154/  209] train: loss: 0.0998959
[Epoch 65; Iter   184/  209] train: loss: 0.1275385
[Epoch 65] ogbg-moltox21: 0.826796 val loss: 0.244165
[Epoch 65] ogbg-moltox21: 0.828150 test loss: 0.239219
[Epoch 66; Iter     5/  209] train: loss: 0.0769921
[Epoch 66; Iter    35/  209] train: loss: 0.0725685
[Epoch 66; Iter    65/  209] train: loss: 0.2298446
[Epoch 66; Iter    95/  209] train: loss: 0.1429339
[Epoch 66; Iter   125/  209] train: loss: 0.0632055
[Epoch 66; Iter   155/  209] train: loss: 0.0816814
[Epoch 66; Iter   185/  209] train: loss: 0.0623617
[Epoch 66] ogbg-moltox21: 0.834718 val loss: 0.252007
[Epoch 66] ogbg-moltox21: 0.829856 test loss: 0.231890
[Epoch 67; Iter     6/  209] train: loss: 0.1562598
[Epoch 67; Iter    36/  209] train: loss: 0.0732441
[Epoch 67; Iter    66/  209] train: loss: 0.1451712
[Epoch 67; Iter    96/  209] train: loss: 0.0944027
[Epoch 67; Iter   126/  209] train: loss: 0.1332526
[Epoch 67; Iter   156/  209] train: loss: 0.0913139
[Epoch 67; Iter   186/  209] train: loss: 0.0660740
[Epoch 67] ogbg-moltox21: 0.834959 val loss: 0.244333
[Epoch 67] ogbg-moltox21: 0.839071 test loss: 0.230823
[Epoch 68; Iter     7/  209] train: loss: 0.0735881
[Epoch 68; Iter    37/  209] train: loss: 0.1156549
[Epoch 68; Iter    67/  209] train: loss: 0.0935242
[Epoch 68; Iter    97/  209] train: loss: 0.0730524
[Epoch 68; Iter   127/  209] train: loss: 0.0823766
[Epoch 68; Iter   157/  209] train: loss: 0.0874703
[Epoch 68; Iter   187/  209] train: loss: 0.0764455
[Epoch 68] ogbg-moltox21: 0.833257 val loss: 0.252773
[Epoch 68] ogbg-moltox21: 0.835663 test loss: 0.234285
[Epoch 69; Iter     8/  209] train: loss: 0.0996409
[Epoch 69; Iter    38/  209] train: loss: 0.1028213
[Epoch 69; Iter    68/  209] train: loss: 0.1162639
[Epoch 69; Iter    98/  209] train: loss: 0.1204848
[Epoch 69; Iter   128/  209] train: loss: 0.1310897
[Epoch 69; Iter   158/  209] train: loss: 0.0631095
[Epoch 69; Iter   188/  209] train: loss: 0.0610902
[Epoch 69] ogbg-moltox21: 0.837386 val loss: 0.250652
[Epoch 69] ogbg-moltox21: 0.831535 test loss: 0.238049
[Epoch 70; Iter     9/  209] train: loss: 0.0911751
[Epoch 70; Iter    39/  209] train: loss: 0.0839275
[Epoch 70; Iter    69/  209] train: loss: 0.0629950
[Epoch 70; Iter    99/  209] train: loss: 0.0867337
[Epoch 70; Iter   129/  209] train: loss: 0.0823280
[Epoch 70; Iter   159/  209] train: loss: 0.0636814
[Epoch 70; Iter   189/  209] train: loss: 0.1034557
[Epoch 70] ogbg-moltox21: 0.838922 val loss: 0.244830
[Epoch 70] ogbg-moltox21: 0.836234 test loss: 0.235933
[Epoch 71; Iter    10/  209] train: loss: 0.1014349
[Epoch 71; Iter    40/  209] train: loss: 0.0575748
[Epoch 71; Iter    70/  209] train: loss: 0.0876533
[Epoch 71; Iter   100/  209] train: loss: 0.0926591
[Epoch 71; Iter   130/  209] train: loss: 0.0607681
[Epoch 71; Iter   160/  209] train: loss: 0.1016922
[Epoch 71; Iter   190/  209] train: loss: 0.0826578
[Epoch 71] ogbg-moltox21: 0.838746 val loss: 0.258337
[Epoch 71] ogbg-moltox21: 0.837600 test loss: 0.246015
[Epoch 72; Iter    11/  209] train: loss: 0.0696421
[Epoch 72; Iter    41/  209] train: loss: 0.0476599
[Epoch 72; Iter    71/  209] train: loss: 0.0623510
[Epoch 72; Iter   101/  209] train: loss: 0.0839590
[Epoch 72; Iter   131/  209] train: loss: 0.0529408
[Epoch 72; Iter   161/  209] train: loss: 0.1228472
[Epoch 72; Iter   191/  209] train: loss: 0.0678844
[Epoch 72] ogbg-moltox21: 0.831926 val loss: 0.258576
[Epoch 72] ogbg-moltox21: 0.825322 test loss: 0.249258
[Epoch 73; Iter    12/  209] train: loss: 0.0621749
[Epoch 73; Iter    42/  209] train: loss: 0.0849911
[Epoch 73; Iter    72/  209] train: loss: 0.0851415
[Epoch 73; Iter   102/  209] train: loss: 0.0875604
[Epoch 73; Iter   132/  209] train: loss: 0.0422273
[Epoch 73; Iter   162/  209] train: loss: 0.0937948
[Epoch 73; Iter   192/  209] train: loss: 0.1248263
[Epoch 73] ogbg-moltox21: 0.832851 val loss: 0.258616
[Epoch 73] ogbg-moltox21: 0.837190 test loss: 0.244062
[Epoch 74; Iter    13/  209] train: loss: 0.0818437
[Epoch 74; Iter    43/  209] train: loss: 0.0902268
[Epoch 74; Iter    73/  209] train: loss: 0.0957804
[Epoch 74; Iter   103/  209] train: loss: 0.0993517
[Epoch 74; Iter   133/  209] train: loss: 0.0764955
[Epoch 74; Iter   163/  209] train: loss: 0.0732104
[Epoch 74; Iter   193/  209] train: loss: 0.0566477
[Epoch 74] ogbg-moltox21: 0.840602 val loss: 0.256737
[Epoch 74] ogbg-moltox21: 0.831765 test loss: 0.242604
[Epoch 75; Iter    14/  209] train: loss: 0.0757529
[Epoch 75; Iter    44/  209] train: loss: 0.0956377
[Epoch 75; Iter    74/  209] train: loss: 0.1083241
[Epoch 75; Iter   104/  209] train: loss: 0.0622987
[Epoch 75; Iter   134/  209] train: loss: 0.0963283
[Epoch 75; Iter   164/  209] train: loss: 0.0842390
[Epoch 75; Iter   194/  209] train: loss: 0.0567946
[Epoch 75] ogbg-moltox21: 0.834251 val loss: 0.262327
[Epoch 75] ogbg-moltox21: 0.830343 test loss: 0.246702
[Epoch 76; Iter    15/  209] train: loss: 0.0638088
[Epoch 76; Iter    45/  209] train: loss: 0.0886902
[Epoch 76; Iter    75/  209] train: loss: 0.0762739
[Epoch 76; Iter   105/  209] train: loss: 0.0671237
[Epoch 76; Iter   135/  209] train: loss: 0.1249534
[Epoch 76; Iter   165/  209] train: loss: 0.1199728
[Epoch 76; Iter   195/  209] train: loss: 0.0655799
[Epoch 76] ogbg-moltox21: 0.840394 val loss: 0.268673
[Epoch 76] ogbg-moltox21: 0.837469 test loss: 0.250672
[Epoch 77; Iter    16/  209] train: loss: 0.0801738
[Epoch 77; Iter    46/  209] train: loss: 0.0618333
[Epoch 77; Iter    76/  209] train: loss: 0.0819873
[Epoch 77; Iter   106/  209] train: loss: 0.0568586
[Epoch 77; Iter   136/  209] train: loss: 0.0968244
[Epoch 77; Iter   166/  209] train: loss: 0.0667086
[Epoch 77; Iter   196/  209] train: loss: 0.0637487
[Epoch 77] ogbg-moltox21: 0.841425 val loss: 0.261539
[Epoch 77] ogbg-moltox21: 0.833095 test loss: 0.246617
[Epoch 78; Iter    17/  209] train: loss: 0.0594318
[Epoch 78; Iter    47/  209] train: loss: 0.0588362
[Epoch 78; Iter    77/  209] train: loss: 0.0588700
[Epoch 78; Iter   107/  209] train: loss: 0.0349953
[Epoch 78; Iter   137/  209] train: loss: 0.0650547
[Epoch 78; Iter   167/  209] train: loss: 0.0514175
[Epoch 78; Iter   197/  209] train: loss: 0.0736394
[Epoch 78] ogbg-moltox21: 0.834472 val loss: 0.277494
[Epoch 78] ogbg-moltox21: 0.833622 test loss: 0.243763
[Epoch 79; Iter    18/  209] train: loss: 0.0499021
[Epoch 79; Iter    48/  209] train: loss: 0.1125686
[Epoch 79; Iter    78/  209] train: loss: 0.0246063
[Epoch 79; Iter   108/  209] train: loss: 0.0790642
[Epoch 79; Iter   138/  209] train: loss: 0.0774330
[Epoch 79; Iter   168/  209] train: loss: 0.0493625
[Epoch 79; Iter   198/  209] train: loss: 0.0810737
[Epoch 79] ogbg-moltox21: 0.831257 val loss: 0.267649
[Epoch 79] ogbg-moltox21: 0.831634 test loss: 0.247289
[Epoch 80; Iter    19/  209] train: loss: 0.0632100
[Epoch 80; Iter    49/  209] train: loss: 0.0953340
[Epoch 80; Iter    79/  209] train: loss: 0.0695347
[Epoch 80; Iter   109/  209] train: loss: 0.0890367
[Epoch 80; Iter   139/  209] train: loss: 0.0972227
[Epoch 80; Iter   169/  209] train: loss: 0.0571759
[Epoch 80; Iter   199/  209] train: loss: 0.0603800
[Epoch 80] ogbg-moltox21: 0.831012 val loss: 0.270363
[Epoch 80] ogbg-moltox21: 0.828405 test loss: 0.249333
[Epoch 81; Iter    20/  209] train: loss: 0.0994915
[Epoch 81; Iter    50/  209] train: loss: 0.1436130
[Epoch 81; Iter    80/  209] train: loss: 0.0802439
[Epoch 81; Iter   110/  209] train: loss: 0.0910539
[Epoch 81; Iter   140/  209] train: loss: 0.1030095
[Epoch 81; Iter   170/  209] train: loss: 0.0696824
[Epoch 81; Iter   200/  209] train: loss: 0.0614466
[Epoch 81] ogbg-moltox21: 0.827068 val loss: 0.280798
[Epoch 81] ogbg-moltox21: 0.826718 test loss: 0.257571
[Epoch 82; Iter    21/  209] train: loss: 0.0824473
[Epoch 64] ogbg-moltox21: 0.828931 test loss: 0.204436
[Epoch 65; Iter     4/  209] train: loss: 0.0835192
[Epoch 65; Iter    34/  209] train: loss: 0.0747412
[Epoch 65; Iter    64/  209] train: loss: 0.0651253
[Epoch 65; Iter    94/  209] train: loss: 0.1351276
[Epoch 65; Iter   124/  209] train: loss: 0.1179225
[Epoch 65; Iter   154/  209] train: loss: 0.0936692
[Epoch 65; Iter   184/  209] train: loss: 0.1219412
[Epoch 65] ogbg-moltox21: 0.850351 val loss: 0.225867
[Epoch 65] ogbg-moltox21: 0.829372 test loss: 0.210244
[Epoch 66; Iter     5/  209] train: loss: 0.1438466
[Epoch 66; Iter    35/  209] train: loss: 0.1104625
[Epoch 66; Iter    65/  209] train: loss: 0.0930323
[Epoch 66; Iter    95/  209] train: loss: 0.0891621
[Epoch 66; Iter   125/  209] train: loss: 0.1421259
[Epoch 66; Iter   155/  209] train: loss: 0.0660167
[Epoch 66; Iter   185/  209] train: loss: 0.1316449
[Epoch 66] ogbg-moltox21: 0.843196 val loss: 0.232704
[Epoch 66] ogbg-moltox21: 0.823882 test loss: 0.213524
[Epoch 67; Iter     6/  209] train: loss: 0.1150303
[Epoch 67; Iter    36/  209] train: loss: 0.0904808
[Epoch 67; Iter    66/  209] train: loss: 0.0855361
[Epoch 67; Iter    96/  209] train: loss: 0.0608916
[Epoch 67; Iter   126/  209] train: loss: 0.0836900
[Epoch 67; Iter   156/  209] train: loss: 0.0674008
[Epoch 67; Iter   186/  209] train: loss: 0.0678739
[Epoch 67] ogbg-moltox21: 0.854628 val loss: 0.227705
[Epoch 67] ogbg-moltox21: 0.823417 test loss: 0.215513
[Epoch 68; Iter     7/  209] train: loss: 0.0583960
[Epoch 68; Iter    37/  209] train: loss: 0.0717555
[Epoch 68; Iter    67/  209] train: loss: 0.1230416
[Epoch 68; Iter    97/  209] train: loss: 0.0576362
[Epoch 68; Iter   127/  209] train: loss: 0.1077922
[Epoch 68; Iter   157/  209] train: loss: 0.0987069
[Epoch 68; Iter   187/  209] train: loss: 0.1156130
[Epoch 68] ogbg-moltox21: 0.847889 val loss: 0.234884
[Epoch 68] ogbg-moltox21: 0.826910 test loss: 0.222521
[Epoch 69; Iter     8/  209] train: loss: 0.1060852
[Epoch 69; Iter    38/  209] train: loss: 0.0979602
[Epoch 69; Iter    68/  209] train: loss: 0.1099812
[Epoch 69; Iter    98/  209] train: loss: 0.0936394
[Epoch 69; Iter   128/  209] train: loss: 0.1132521
[Epoch 69; Iter   158/  209] train: loss: 0.1372524
[Epoch 69; Iter   188/  209] train: loss: 0.0696606
[Epoch 69] ogbg-moltox21: 0.845697 val loss: 0.237074
[Epoch 69] ogbg-moltox21: 0.825387 test loss: 0.217077
[Epoch 70; Iter     9/  209] train: loss: 0.0996928
[Epoch 70; Iter    39/  209] train: loss: 0.0791270
[Epoch 70; Iter    69/  209] train: loss: 0.0952504
[Epoch 70; Iter    99/  209] train: loss: 0.1532518
[Epoch 70; Iter   129/  209] train: loss: 0.0604216
[Epoch 70; Iter   159/  209] train: loss: 0.0701697
[Epoch 70; Iter   189/  209] train: loss: 0.1479486
[Epoch 70] ogbg-moltox21: 0.847933 val loss: 0.241918
[Epoch 70] ogbg-moltox21: 0.821966 test loss: 0.222965
[Epoch 71; Iter    10/  209] train: loss: 0.0583977
[Epoch 71; Iter    40/  209] train: loss: 0.0898013
[Epoch 71; Iter    70/  209] train: loss: 0.0931030
[Epoch 71; Iter   100/  209] train: loss: 0.0927660
[Epoch 71; Iter   130/  209] train: loss: 0.0901872
[Epoch 71; Iter   160/  209] train: loss: 0.0969875
[Epoch 71; Iter   190/  209] train: loss: 0.0997910
[Epoch 71] ogbg-moltox21: 0.842207 val loss: 0.242325
[Epoch 71] ogbg-moltox21: 0.822071 test loss: 0.218497
[Epoch 72; Iter    11/  209] train: loss: 0.1100676
[Epoch 72; Iter    41/  209] train: loss: 0.0789466
[Epoch 72; Iter    71/  209] train: loss: 0.0856861
[Epoch 72; Iter   101/  209] train: loss: 0.0666281
[Epoch 72; Iter   131/  209] train: loss: 0.0886106
[Epoch 72; Iter   161/  209] train: loss: 0.0506103
[Epoch 72; Iter   191/  209] train: loss: 0.0860905
[Epoch 72] ogbg-moltox21: 0.840530 val loss: 0.246321
[Epoch 72] ogbg-moltox21: 0.819256 test loss: 0.223886
[Epoch 73; Iter    12/  209] train: loss: 0.0857578
[Epoch 73; Iter    42/  209] train: loss: 0.0822749
[Epoch 73; Iter    72/  209] train: loss: 0.0688293
[Epoch 73; Iter   102/  209] train: loss: 0.0462355
[Epoch 73; Iter   132/  209] train: loss: 0.0502531
[Epoch 73; Iter   162/  209] train: loss: 0.0627307
[Epoch 73; Iter   192/  209] train: loss: 0.0722107
[Epoch 73] ogbg-moltox21: 0.837145 val loss: 0.248730
[Epoch 73] ogbg-moltox21: 0.815297 test loss: 0.226743
[Epoch 74; Iter    13/  209] train: loss: 0.0817927
[Epoch 74; Iter    43/  209] train: loss: 0.0838114
[Epoch 74; Iter    73/  209] train: loss: 0.0917295
[Epoch 74; Iter   103/  209] train: loss: 0.0880202
[Epoch 74; Iter   133/  209] train: loss: 0.0914361
[Epoch 74; Iter   163/  209] train: loss: 0.0682257
[Epoch 74; Iter   193/  209] train: loss: 0.0820128
[Epoch 74] ogbg-moltox21: 0.836680 val loss: 0.249487
[Epoch 74] ogbg-moltox21: 0.816207 test loss: 0.227908
[Epoch 75; Iter    14/  209] train: loss: 0.0596667
[Epoch 75; Iter    44/  209] train: loss: 0.0898856
[Epoch 75; Iter    74/  209] train: loss: 0.0965346
[Epoch 75; Iter   104/  209] train: loss: 0.1049397
[Epoch 75; Iter   134/  209] train: loss: 0.0833411
[Epoch 75; Iter   164/  209] train: loss: 0.0736620
[Epoch 75; Iter   194/  209] train: loss: 0.0963718
[Epoch 75] ogbg-moltox21: 0.844186 val loss: 0.250541
[Epoch 75] ogbg-moltox21: 0.820899 test loss: 0.224547
[Epoch 76; Iter    15/  209] train: loss: 0.0627113
[Epoch 76; Iter    45/  209] train: loss: 0.0602000
[Epoch 76; Iter    75/  209] train: loss: 0.0870366
[Epoch 76; Iter   105/  209] train: loss: 0.1315297
[Epoch 76; Iter   135/  209] train: loss: 0.0593438
[Epoch 76; Iter   165/  209] train: loss: 0.1071261
[Epoch 76; Iter   195/  209] train: loss: 0.1398828
[Epoch 76] ogbg-moltox21: 0.836998 val loss: 0.256541
[Epoch 76] ogbg-moltox21: 0.826013 test loss: 0.226260
[Epoch 77; Iter    16/  209] train: loss: 0.0471665
[Epoch 77; Iter    46/  209] train: loss: 0.1025207
[Epoch 77; Iter    76/  209] train: loss: 0.1260094
[Epoch 77; Iter   106/  209] train: loss: 0.0698333
[Epoch 77; Iter   136/  209] train: loss: 0.1141806
[Epoch 77; Iter   166/  209] train: loss: 0.0741903
[Epoch 77; Iter   196/  209] train: loss: 0.1509252
[Epoch 77] ogbg-moltox21: 0.835833 val loss: 0.255405
[Epoch 77] ogbg-moltox21: 0.815422 test loss: 0.227997
[Epoch 78; Iter    17/  209] train: loss: 0.0663490
[Epoch 78; Iter    47/  209] train: loss: 0.0873983
[Epoch 78; Iter    77/  209] train: loss: 0.0734515
[Epoch 78; Iter   107/  209] train: loss: 0.0890516
[Epoch 78; Iter   137/  209] train: loss: 0.0705990
[Epoch 78; Iter   167/  209] train: loss: 0.1397678
[Epoch 78; Iter   197/  209] train: loss: 0.0550698
[Epoch 78] ogbg-moltox21: 0.836820 val loss: 0.247968
[Epoch 78] ogbg-moltox21: 0.811702 test loss: 0.233381
[Epoch 79; Iter    18/  209] train: loss: 0.0379379
[Epoch 79; Iter    48/  209] train: loss: 0.0678644
[Epoch 79; Iter    78/  209] train: loss: 0.0717159
[Epoch 79; Iter   108/  209] train: loss: 0.0844266
[Epoch 79; Iter   138/  209] train: loss: 0.1486219
[Epoch 79; Iter   168/  209] train: loss: 0.0651505
[Epoch 79; Iter   198/  209] train: loss: 0.0848208
[Epoch 79] ogbg-moltox21: 0.835153 val loss: 0.260122
[Epoch 79] ogbg-moltox21: 0.816815 test loss: 0.233283
[Epoch 80; Iter    19/  209] train: loss: 0.1115985
[Epoch 80; Iter    49/  209] train: loss: 0.0850517
[Epoch 80; Iter    79/  209] train: loss: 0.0560394
[Epoch 80; Iter   109/  209] train: loss: 0.1067691
[Epoch 80; Iter   139/  209] train: loss: 0.0583168
[Epoch 80; Iter   169/  209] train: loss: 0.0795391
[Epoch 80; Iter   199/  209] train: loss: 0.0551293
[Epoch 80] ogbg-moltox21: 0.835567 val loss: 0.264184
[Epoch 80] ogbg-moltox21: 0.819983 test loss: 0.233267
[Epoch 81; Iter    20/  209] train: loss: 0.0721014
[Epoch 81; Iter    50/  209] train: loss: 0.0730658
[Epoch 81; Iter    80/  209] train: loss: 0.0926104
[Epoch 81; Iter   110/  209] train: loss: 0.1658616
[Epoch 81; Iter   140/  209] train: loss: 0.0686853
[Epoch 81; Iter   170/  209] train: loss: 0.0630103
[Epoch 81; Iter   200/  209] train: loss: 0.0686205
[Epoch 81] ogbg-moltox21: 0.840596 val loss: 0.252897
[Epoch 81] ogbg-moltox21: 0.819646 test loss: 0.231792
[Epoch 82; Iter    21/  209] train: loss: 0.0659004
[Epoch 71; Iter   180/  183] train: loss: 0.0985389
[Epoch 71] ogbg-moltox21: 0.822822 val loss: 0.223514
[Epoch 71] ogbg-moltox21: 0.825070 test loss: 0.255099
[Epoch 72; Iter    27/  183] train: loss: 0.0610187
[Epoch 72; Iter    57/  183] train: loss: 0.1047227
[Epoch 72; Iter    87/  183] train: loss: 0.1243988
[Epoch 72; Iter   117/  183] train: loss: 0.0558566
[Epoch 72; Iter   147/  183] train: loss: 0.1619167
[Epoch 72; Iter   177/  183] train: loss: 0.0882527
[Epoch 72] ogbg-moltox21: 0.825958 val loss: 0.226063
[Epoch 72] ogbg-moltox21: 0.820677 test loss: 0.230699
[Epoch 73; Iter    24/  183] train: loss: 0.0797217
[Epoch 73; Iter    54/  183] train: loss: 0.0745341
[Epoch 73; Iter    84/  183] train: loss: 0.1027501
[Epoch 73; Iter   114/  183] train: loss: 0.0650251
[Epoch 73; Iter   144/  183] train: loss: 0.1051531
[Epoch 73; Iter   174/  183] train: loss: 0.0667526
[Epoch 73] ogbg-moltox21: 0.824941 val loss: 0.302678
[Epoch 73] ogbg-moltox21: 0.822711 test loss: 0.246608
[Epoch 74; Iter    21/  183] train: loss: 0.0803726
[Epoch 74; Iter    51/  183] train: loss: 0.0735755
[Epoch 74; Iter    81/  183] train: loss: 0.0349179
[Epoch 74; Iter   111/  183] train: loss: 0.1110560
[Epoch 74; Iter   141/  183] train: loss: 0.0795816
[Epoch 74; Iter   171/  183] train: loss: 0.0805565
[Epoch 74] ogbg-moltox21: 0.823146 val loss: 0.234381
[Epoch 74] ogbg-moltox21: 0.821177 test loss: 0.235494
[Epoch 75; Iter    18/  183] train: loss: 0.0710006
[Epoch 75; Iter    48/  183] train: loss: 0.0711085
[Epoch 75; Iter    78/  183] train: loss: 0.0838334
[Epoch 75; Iter   108/  183] train: loss: 0.0859912
[Epoch 75; Iter   138/  183] train: loss: 0.2166691
[Epoch 75; Iter   168/  183] train: loss: 0.0902176
[Epoch 75] ogbg-moltox21: 0.823604 val loss: 0.230810
[Epoch 75] ogbg-moltox21: 0.822057 test loss: 0.232327
[Epoch 76; Iter    15/  183] train: loss: 0.0785749
[Epoch 76; Iter    45/  183] train: loss: 0.0680037
[Epoch 76; Iter    75/  183] train: loss: 0.0825988
[Epoch 76; Iter   105/  183] train: loss: 0.0434899
[Epoch 76; Iter   135/  183] train: loss: 0.0593954
[Epoch 76; Iter   165/  183] train: loss: 0.1180061
[Epoch 76] ogbg-moltox21: 0.824251 val loss: 0.237774
[Epoch 76] ogbg-moltox21: 0.822060 test loss: 0.238083
[Epoch 77; Iter    12/  183] train: loss: 0.0671113
[Epoch 77; Iter    42/  183] train: loss: 0.0983676
[Epoch 77; Iter    72/  183] train: loss: 0.0566164
[Epoch 77; Iter   102/  183] train: loss: 0.0725128
[Epoch 77; Iter   132/  183] train: loss: 0.1601131
[Epoch 77; Iter   162/  183] train: loss: 0.0590766
[Epoch 77] ogbg-moltox21: 0.819019 val loss: 0.238977
[Epoch 77] ogbg-moltox21: 0.817151 test loss: 0.240371
[Epoch 78; Iter     9/  183] train: loss: 0.0691687
[Epoch 78; Iter    39/  183] train: loss: 0.0707791
[Epoch 78; Iter    69/  183] train: loss: 0.0842700
[Epoch 78; Iter    99/  183] train: loss: 0.0843851
[Epoch 78; Iter   129/  183] train: loss: 0.0862616
[Epoch 78; Iter   159/  183] train: loss: 0.0730081
[Epoch 78] ogbg-moltox21: 0.820195 val loss: 0.240317
[Epoch 78] ogbg-moltox21: 0.822627 test loss: 0.242971
[Epoch 79; Iter     6/  183] train: loss: 0.0847726
[Epoch 79; Iter    36/  183] train: loss: 0.0857560
[Epoch 79; Iter    66/  183] train: loss: 0.0939516
[Epoch 79; Iter    96/  183] train: loss: 0.0980473
[Epoch 79; Iter   126/  183] train: loss: 0.0704617
[Epoch 79; Iter   156/  183] train: loss: 0.0964150
[Epoch 79] ogbg-moltox21: 0.822333 val loss: 0.237147
[Epoch 79] ogbg-moltox21: 0.826172 test loss: 0.237683
[Epoch 80; Iter     3/  183] train: loss: 0.0815005
[Epoch 80; Iter    33/  183] train: loss: 0.0318987
[Epoch 80; Iter    63/  183] train: loss: 0.0609817
[Epoch 80; Iter    93/  183] train: loss: 0.0415936
[Epoch 80; Iter   123/  183] train: loss: 0.0654458
[Epoch 80; Iter   153/  183] train: loss: 0.0896252
[Epoch 80; Iter   183/  183] train: loss: 0.0581478
[Epoch 80] ogbg-moltox21: 0.820816 val loss: 0.258841
[Epoch 80] ogbg-moltox21: 0.821795 test loss: 0.252685
[Epoch 81; Iter    30/  183] train: loss: 0.0537990
[Epoch 81; Iter    60/  183] train: loss: 0.0561389
[Epoch 81; Iter    90/  183] train: loss: 0.0883414
[Epoch 81; Iter   120/  183] train: loss: 0.0436109
[Epoch 81; Iter   150/  183] train: loss: 0.0825602
[Epoch 81; Iter   180/  183] train: loss: 0.1159026
[Epoch 81] ogbg-moltox21: 0.817941 val loss: 0.270845
[Epoch 81] ogbg-moltox21: 0.818231 test loss: 0.258433
[Epoch 82; Iter    27/  183] train: loss: 0.0870258
[Epoch 82; Iter    57/  183] train: loss: 0.0733021
[Epoch 82; Iter    87/  183] train: loss: 0.0668683
[Epoch 82; Iter   117/  183] train: loss: 0.0709981
[Epoch 82; Iter   147/  183] train: loss: 0.0865335
[Epoch 82; Iter   177/  183] train: loss: 0.0758255
[Epoch 82] ogbg-moltox21: 0.822198 val loss: 0.248000
[Epoch 82] ogbg-moltox21: 0.822897 test loss: 0.250237
[Epoch 83; Iter    24/  183] train: loss: 0.0823586
[Epoch 83; Iter    54/  183] train: loss: 0.0550143
[Epoch 83; Iter    84/  183] train: loss: 0.0768144
[Epoch 83; Iter   114/  183] train: loss: 0.0550856
[Epoch 83; Iter   144/  183] train: loss: 0.0755552
[Epoch 83; Iter   174/  183] train: loss: 0.0469106
[Epoch 83] ogbg-moltox21: 0.819871 val loss: 0.240844
[Epoch 83] ogbg-moltox21: 0.818236 test loss: 0.258261
[Epoch 84; Iter    21/  183] train: loss: 0.0634945
[Epoch 84; Iter    51/  183] train: loss: 0.0614355
[Epoch 84; Iter    81/  183] train: loss: 0.0698242
[Epoch 84; Iter   111/  183] train: loss: 0.0695670
[Epoch 84; Iter   141/  183] train: loss: 0.0848461
[Epoch 84; Iter   171/  183] train: loss: 0.0968063
[Epoch 84] ogbg-moltox21: 0.812703 val loss: 0.282248
[Epoch 84] ogbg-moltox21: 0.817505 test loss: 0.260714
[Epoch 85; Iter    18/  183] train: loss: 0.0742587
[Epoch 85; Iter    48/  183] train: loss: 0.1004889
[Epoch 85; Iter    78/  183] train: loss: 0.0820798
[Epoch 85; Iter   108/  183] train: loss: 0.0989383
[Epoch 85; Iter   138/  183] train: loss: 0.0762495
[Epoch 85; Iter   168/  183] train: loss: 0.0435303
[Epoch 85] ogbg-moltox21: 0.811466 val loss: 0.244168
[Epoch 85] ogbg-moltox21: 0.810303 test loss: 0.269735
[Epoch 86; Iter    15/  183] train: loss: 0.0441791
[Epoch 86; Iter    45/  183] train: loss: 0.0507688
[Epoch 86; Iter    75/  183] train: loss: 0.0653981
[Epoch 86; Iter   105/  183] train: loss: 0.1111125
[Epoch 86; Iter   135/  183] train: loss: 0.1014949
[Epoch 86; Iter   165/  183] train: loss: 0.0380381
[Epoch 86] ogbg-moltox21: 0.822149 val loss: 0.250302
[Epoch 86] ogbg-moltox21: 0.821110 test loss: 0.260846
[Epoch 87; Iter    12/  183] train: loss: 0.0543935
[Epoch 87; Iter    42/  183] train: loss: 0.0386189
[Epoch 87; Iter    72/  183] train: loss: 0.1278925
[Epoch 87; Iter   102/  183] train: loss: 0.0301342
[Epoch 87; Iter   132/  183] train: loss: 0.0661353
[Epoch 87; Iter   162/  183] train: loss: 0.0585601
[Epoch 87] ogbg-moltox21: 0.823393 val loss: 0.246115
[Epoch 87] ogbg-moltox21: 0.824066 test loss: 0.254135
[Epoch 88; Iter     9/  183] train: loss: 0.0935870
[Epoch 88; Iter    39/  183] train: loss: 0.0914991
[Epoch 88; Iter    69/  183] train: loss: 0.0434430
[Epoch 88; Iter    99/  183] train: loss: 0.0698718
[Epoch 88; Iter   129/  183] train: loss: 0.0889659
[Epoch 88; Iter   159/  183] train: loss: 0.0492313
[Epoch 88] ogbg-moltox21: 0.822002 val loss: 0.256323
[Epoch 88] ogbg-moltox21: 0.814980 test loss: 0.267865
[Epoch 89; Iter     6/  183] train: loss: 0.0495285
[Epoch 89; Iter    36/  183] train: loss: 0.0490010
[Epoch 89; Iter    66/  183] train: loss: 0.0768275
[Epoch 89; Iter    96/  183] train: loss: 0.0517927
[Epoch 89; Iter   126/  183] train: loss: 0.0482250
[Epoch 89; Iter   156/  183] train: loss: 0.0830303
[Epoch 89] ogbg-moltox21: 0.817009 val loss: 0.256574
[Epoch 89] ogbg-moltox21: 0.819042 test loss: 0.260279
[Epoch 90; Iter     3/  183] train: loss: 0.0595754
[Epoch 90; Iter    33/  183] train: loss: 0.0624921
[Epoch 90; Iter    63/  183] train: loss: 0.0759047
[Epoch 90; Iter    93/  183] train: loss: 0.0691859
[Epoch 90; Iter   123/  183] train: loss: 0.0493704
[Epoch 90; Iter   153/  183] train: loss: 0.0474429
[Epoch 90; Iter   183/  183] train: loss: 0.0911536
[Epoch 71; Iter   180/  183] train: loss: 0.1019533
[Epoch 71] ogbg-moltox21: 0.830316 val loss: 0.240780
[Epoch 71] ogbg-moltox21: 0.842619 test loss: 0.215830
[Epoch 72; Iter    27/  183] train: loss: 0.1334598
[Epoch 72; Iter    57/  183] train: loss: 0.0914597
[Epoch 72; Iter    87/  183] train: loss: 0.1446245
[Epoch 72; Iter   117/  183] train: loss: 0.1295551
[Epoch 72; Iter   147/  183] train: loss: 0.1336003
[Epoch 72; Iter   177/  183] train: loss: 0.1125419
[Epoch 72] ogbg-moltox21: 0.832428 val loss: 0.220526
[Epoch 72] ogbg-moltox21: 0.842550 test loss: 0.207885
[Epoch 73; Iter    24/  183] train: loss: 0.1192054
[Epoch 73; Iter    54/  183] train: loss: 0.1345983
[Epoch 73; Iter    84/  183] train: loss: 0.1067014
[Epoch 73; Iter   114/  183] train: loss: 0.1402578
[Epoch 73; Iter   144/  183] train: loss: 0.0890313
[Epoch 73; Iter   174/  183] train: loss: 0.1353805
[Epoch 73] ogbg-moltox21: 0.835408 val loss: 0.212245
[Epoch 73] ogbg-moltox21: 0.837731 test loss: 0.211569
[Epoch 74; Iter    21/  183] train: loss: 0.0604072
[Epoch 74; Iter    51/  183] train: loss: 0.1129376
[Epoch 74; Iter    81/  183] train: loss: 0.1011705
[Epoch 74; Iter   111/  183] train: loss: 0.1249752
[Epoch 74; Iter   141/  183] train: loss: 0.1280859
[Epoch 74; Iter   171/  183] train: loss: 0.1263659
[Epoch 74] ogbg-moltox21: 0.825012 val loss: 0.219945
[Epoch 74] ogbg-moltox21: 0.841111 test loss: 0.215494
[Epoch 75; Iter    18/  183] train: loss: 0.1121355
[Epoch 75; Iter    48/  183] train: loss: 0.1057582
[Epoch 75; Iter    78/  183] train: loss: 0.1090319
[Epoch 75; Iter   108/  183] train: loss: 0.0794448
[Epoch 75; Iter   138/  183] train: loss: 0.1299893
[Epoch 75; Iter   168/  183] train: loss: 0.1253161
[Epoch 75] ogbg-moltox21: 0.833004 val loss: 0.222654
[Epoch 75] ogbg-moltox21: 0.837483 test loss: 0.219360
[Epoch 76; Iter    15/  183] train: loss: 0.0637157
[Epoch 76; Iter    45/  183] train: loss: 0.1049850
[Epoch 76; Iter    75/  183] train: loss: 0.1161164
[Epoch 76; Iter   105/  183] train: loss: 0.0667923
[Epoch 76; Iter   135/  183] train: loss: 0.1453636
[Epoch 76; Iter   165/  183] train: loss: 0.0859220
[Epoch 76] ogbg-moltox21: 0.828925 val loss: 0.218887
[Epoch 76] ogbg-moltox21: 0.837239 test loss: 0.221379
[Epoch 77; Iter    12/  183] train: loss: 0.1145700
[Epoch 77; Iter    42/  183] train: loss: 0.1486652
[Epoch 77; Iter    72/  183] train: loss: 0.1160459
[Epoch 77; Iter   102/  183] train: loss: 0.1228919
[Epoch 77; Iter   132/  183] train: loss: 0.0763943
[Epoch 77; Iter   162/  183] train: loss: 0.1380471
[Epoch 77] ogbg-moltox21: 0.827611 val loss: 0.221929
[Epoch 77] ogbg-moltox21: 0.825360 test loss: 0.223450
[Epoch 78; Iter     9/  183] train: loss: 0.1225334
[Epoch 78; Iter    39/  183] train: loss: 0.0879626
[Epoch 78; Iter    69/  183] train: loss: 0.1200599
[Epoch 78; Iter    99/  183] train: loss: 0.0945854
[Epoch 78; Iter   129/  183] train: loss: 0.0973373
[Epoch 78; Iter   159/  183] train: loss: 0.1009342
[Epoch 78] ogbg-moltox21: 0.825869 val loss: 0.221679
[Epoch 78] ogbg-moltox21: 0.835777 test loss: 0.225500
[Epoch 79; Iter     6/  183] train: loss: 0.0722020
[Epoch 79; Iter    36/  183] train: loss: 0.0955178
[Epoch 79; Iter    66/  183] train: loss: 0.0736411
[Epoch 79; Iter    96/  183] train: loss: 0.0755808
[Epoch 79; Iter   126/  183] train: loss: 0.0881247
[Epoch 79; Iter   156/  183] train: loss: 0.0794373
[Epoch 79] ogbg-moltox21: 0.831150 val loss: 0.220806
[Epoch 79] ogbg-moltox21: 0.840347 test loss: 0.216804
[Epoch 80; Iter     3/  183] train: loss: 0.0933158
[Epoch 80; Iter    33/  183] train: loss: 0.1141003
[Epoch 80; Iter    63/  183] train: loss: 0.0937425
[Epoch 80; Iter    93/  183] train: loss: 0.1183980
[Epoch 80; Iter   123/  183] train: loss: 0.0938036
[Epoch 80; Iter   153/  183] train: loss: 0.1001227
[Epoch 80; Iter   183/  183] train: loss: 0.0482881
[Epoch 80] ogbg-moltox21: 0.826112 val loss: 0.303919
[Epoch 80] ogbg-moltox21: 0.839931 test loss: 0.222052
[Epoch 81; Iter    30/  183] train: loss: 0.0890864
[Epoch 81; Iter    60/  183] train: loss: 0.1305658
[Epoch 81; Iter    90/  183] train: loss: 0.1174015
[Epoch 81; Iter   120/  183] train: loss: 0.0947956
[Epoch 81; Iter   150/  183] train: loss: 0.0885309
[Epoch 81; Iter   180/  183] train: loss: 0.1111412
[Epoch 81] ogbg-moltox21: 0.830978 val loss: 0.240656
[Epoch 81] ogbg-moltox21: 0.835761 test loss: 0.222818
[Epoch 82; Iter    27/  183] train: loss: 0.0906699
[Epoch 82; Iter    57/  183] train: loss: 0.1342507
[Epoch 82; Iter    87/  183] train: loss: 0.1174302
[Epoch 82; Iter   117/  183] train: loss: 0.0589363
[Epoch 82; Iter   147/  183] train: loss: 0.0748238
[Epoch 82; Iter   177/  183] train: loss: 0.0682464
[Epoch 82] ogbg-moltox21: 0.822498 val loss: 0.337677
[Epoch 82] ogbg-moltox21: 0.832661 test loss: 0.244674
[Epoch 83; Iter    24/  183] train: loss: 0.1096191
[Epoch 83; Iter    54/  183] train: loss: 0.0894599
[Epoch 83; Iter    84/  183] train: loss: 0.0750747
[Epoch 83; Iter   114/  183] train: loss: 0.0818093
[Epoch 83; Iter   144/  183] train: loss: 0.1146944
[Epoch 83; Iter   174/  183] train: loss: 0.0861645
[Epoch 83] ogbg-moltox21: 0.832265 val loss: 0.226475
[Epoch 83] ogbg-moltox21: 0.833208 test loss: 0.224940
[Epoch 84; Iter    21/  183] train: loss: 0.0590858
[Epoch 84; Iter    51/  183] train: loss: 0.0934455
[Epoch 84; Iter    81/  183] train: loss: 0.0521484
[Epoch 84; Iter   111/  183] train: loss: 0.0792297
[Epoch 84; Iter   141/  183] train: loss: 0.0572111
[Epoch 84; Iter   171/  183] train: loss: 0.0975083
[Epoch 84] ogbg-moltox21: 0.827436 val loss: 0.317385
[Epoch 84] ogbg-moltox21: 0.833868 test loss: 0.233959
[Epoch 85; Iter    18/  183] train: loss: 0.0727078
[Epoch 85; Iter    48/  183] train: loss: 0.0809540
[Epoch 85; Iter    78/  183] train: loss: 0.0893782
[Epoch 85; Iter   108/  183] train: loss: 0.1033813
[Epoch 85; Iter   138/  183] train: loss: 0.1124844
[Epoch 85; Iter   168/  183] train: loss: 0.0589145
[Epoch 85] ogbg-moltox21: 0.825248 val loss: 0.227168
[Epoch 85] ogbg-moltox21: 0.834016 test loss: 0.226960
[Epoch 86; Iter    15/  183] train: loss: 0.0722644
[Epoch 86; Iter    45/  183] train: loss: 0.0560311
[Epoch 86; Iter    75/  183] train: loss: 0.0810096
[Epoch 86; Iter   105/  183] train: loss: 0.1259200
[Epoch 86; Iter   135/  183] train: loss: 0.0897977
[Epoch 86; Iter   165/  183] train: loss: 0.1459539
[Epoch 86] ogbg-moltox21: 0.827134 val loss: 0.224109
[Epoch 86] ogbg-moltox21: 0.835713 test loss: 0.223651
[Epoch 87; Iter    12/  183] train: loss: 0.0990487
[Epoch 87; Iter    42/  183] train: loss: 0.0969209
[Epoch 87; Iter    72/  183] train: loss: 0.1165977
[Epoch 87; Iter   102/  183] train: loss: 0.0985325
[Epoch 87; Iter   132/  183] train: loss: 0.0858453
[Epoch 87; Iter   162/  183] train: loss: 0.1344647
[Epoch 87] ogbg-moltox21: 0.825224 val loss: 0.226512
[Epoch 87] ogbg-moltox21: 0.832731 test loss: 0.229147
[Epoch 88; Iter     9/  183] train: loss: 0.1043824
[Epoch 88; Iter    39/  183] train: loss: 0.0490664
[Epoch 88; Iter    69/  183] train: loss: 0.1670082
[Epoch 88; Iter    99/  183] train: loss: 0.1225916
[Epoch 88; Iter   129/  183] train: loss: 0.1113787
[Epoch 88; Iter   159/  183] train: loss: 0.0854179
[Epoch 88] ogbg-moltox21: 0.826516 val loss: 0.258282
[Epoch 88] ogbg-moltox21: 0.835067 test loss: 0.234552
[Epoch 89; Iter     6/  183] train: loss: 0.0889448
[Epoch 89; Iter    36/  183] train: loss: 0.0957955
[Epoch 89; Iter    66/  183] train: loss: 0.0514920
[Epoch 89; Iter    96/  183] train: loss: 0.0743457
[Epoch 89; Iter   126/  183] train: loss: 0.0768686
[Epoch 89; Iter   156/  183] train: loss: 0.1489400
[Epoch 89] ogbg-moltox21: 0.823834 val loss: 0.231965
[Epoch 89] ogbg-moltox21: 0.839647 test loss: 0.226687
[Epoch 90; Iter     3/  183] train: loss: 0.0960427
[Epoch 90; Iter    33/  183] train: loss: 0.0562935
[Epoch 90; Iter    63/  183] train: loss: 0.0785248
[Epoch 90; Iter    93/  183] train: loss: 0.1153491
[Epoch 90; Iter   123/  183] train: loss: 0.0768350
[Epoch 90; Iter   153/  183] train: loss: 0.0899679
[Epoch 90; Iter   183/  183] train: loss: 0.1155964
[Epoch 71; Iter   180/  183] train: loss: 0.0562869
[Epoch 71] ogbg-moltox21: 0.815758 val loss: 0.231748
[Epoch 71] ogbg-moltox21: 0.821956 test loss: 0.237383
[Epoch 72; Iter    27/  183] train: loss: 0.0547334
[Epoch 72; Iter    57/  183] train: loss: 0.1044631
[Epoch 72; Iter    87/  183] train: loss: 0.0717398
[Epoch 72; Iter   117/  183] train: loss: 0.0758441
[Epoch 72; Iter   147/  183] train: loss: 0.0579986
[Epoch 72; Iter   177/  183] train: loss: 0.0658053
[Epoch 72] ogbg-moltox21: 0.814912 val loss: 0.232277
[Epoch 72] ogbg-moltox21: 0.823307 test loss: 0.237834
[Epoch 73; Iter    24/  183] train: loss: 0.0770070
[Epoch 73; Iter    54/  183] train: loss: 0.0716942
[Epoch 73; Iter    84/  183] train: loss: 0.0825957
[Epoch 73; Iter   114/  183] train: loss: 0.1319539
[Epoch 73; Iter   144/  183] train: loss: 0.0787970
[Epoch 73; Iter   174/  183] train: loss: 0.0394591
[Epoch 73] ogbg-moltox21: 0.819215 val loss: 0.240453
[Epoch 73] ogbg-moltox21: 0.825562 test loss: 0.245200
[Epoch 74; Iter    21/  183] train: loss: 0.0890585
[Epoch 74; Iter    51/  183] train: loss: 0.0935226
[Epoch 74; Iter    81/  183] train: loss: 0.0680303
[Epoch 74; Iter   111/  183] train: loss: 0.0869300
[Epoch 74; Iter   141/  183] train: loss: 0.0317117
[Epoch 74; Iter   171/  183] train: loss: 0.0644500
[Epoch 74] ogbg-moltox21: 0.806599 val loss: 0.238634
[Epoch 74] ogbg-moltox21: 0.818622 test loss: 0.240089
[Epoch 75; Iter    18/  183] train: loss: 0.0712577
[Epoch 75; Iter    48/  183] train: loss: 0.0759239
[Epoch 75; Iter    78/  183] train: loss: 0.0914317
[Epoch 75; Iter   108/  183] train: loss: 0.0808615
[Epoch 75; Iter   138/  183] train: loss: 0.0806484
[Epoch 75; Iter   168/  183] train: loss: 0.0708385
[Epoch 75] ogbg-moltox21: 0.807052 val loss: 0.245442
[Epoch 75] ogbg-moltox21: 0.816989 test loss: 0.248766
[Epoch 76; Iter    15/  183] train: loss: 0.1051115
[Epoch 76; Iter    45/  183] train: loss: 0.0808954
[Epoch 76; Iter    75/  183] train: loss: 0.1093678
[Epoch 76; Iter   105/  183] train: loss: 0.0568319
[Epoch 76; Iter   135/  183] train: loss: 0.0799882
[Epoch 76; Iter   165/  183] train: loss: 0.0508382
[Epoch 76] ogbg-moltox21: 0.805397 val loss: 0.247562
[Epoch 76] ogbg-moltox21: 0.816763 test loss: 0.254910
[Epoch 77; Iter    12/  183] train: loss: 0.0721224
[Epoch 77; Iter    42/  183] train: loss: 0.1065649
[Epoch 77; Iter    72/  183] train: loss: 0.0506371
[Epoch 77; Iter   102/  183] train: loss: 0.0822406
[Epoch 77; Iter   132/  183] train: loss: 0.0714037
[Epoch 77; Iter   162/  183] train: loss: 0.0791028
[Epoch 77] ogbg-moltox21: 0.808103 val loss: 0.245633
[Epoch 77] ogbg-moltox21: 0.820039 test loss: 0.253907
[Epoch 78; Iter     9/  183] train: loss: 0.1248911
[Epoch 78; Iter    39/  183] train: loss: 0.0792955
[Epoch 78; Iter    69/  183] train: loss: 0.0739328
[Epoch 78; Iter    99/  183] train: loss: 0.0808115
[Epoch 78; Iter   129/  183] train: loss: 0.0762317
[Epoch 78; Iter   159/  183] train: loss: 0.0946170
[Epoch 78] ogbg-moltox21: 0.809942 val loss: 0.250260
[Epoch 78] ogbg-moltox21: 0.817673 test loss: 0.257448
[Epoch 79; Iter     6/  183] train: loss: 0.0726307
[Epoch 79; Iter    36/  183] train: loss: 0.0748262
[Epoch 79; Iter    66/  183] train: loss: 0.0658280
[Epoch 79; Iter    96/  183] train: loss: 0.0692463
[Epoch 79; Iter   126/  183] train: loss: 0.0875777
[Epoch 79; Iter   156/  183] train: loss: 0.0884179
[Epoch 79] ogbg-moltox21: 0.817470 val loss: 0.244916
[Epoch 79] ogbg-moltox21: 0.821018 test loss: 0.258584
[Epoch 80; Iter     3/  183] train: loss: 0.0801005
[Epoch 80; Iter    33/  183] train: loss: 0.0472815
[Epoch 80; Iter    63/  183] train: loss: 0.0890918
[Epoch 80; Iter    93/  183] train: loss: 0.0843598
[Epoch 80; Iter   123/  183] train: loss: 0.0470890
[Epoch 80; Iter   153/  183] train: loss: 0.1113133
[Epoch 80; Iter   183/  183] train: loss: 0.1540818
[Epoch 80] ogbg-moltox21: 0.813902 val loss: 0.250528
[Epoch 80] ogbg-moltox21: 0.820062 test loss: 0.256771
[Epoch 81; Iter    30/  183] train: loss: 0.0551390
[Epoch 81; Iter    60/  183] train: loss: 0.0665909
[Epoch 81; Iter    90/  183] train: loss: 0.1123176
[Epoch 81; Iter   120/  183] train: loss: 0.0589753
[Epoch 81; Iter   150/  183] train: loss: 0.0661334
[Epoch 81; Iter   180/  183] train: loss: 0.0895422
[Epoch 81] ogbg-moltox21: 0.812347 val loss: 0.252273
[Epoch 81] ogbg-moltox21: 0.820294 test loss: 0.256495
[Epoch 82; Iter    27/  183] train: loss: 0.0647673
[Epoch 82; Iter    57/  183] train: loss: 0.0521070
[Epoch 82; Iter    87/  183] train: loss: 0.0783016
[Epoch 82; Iter   117/  183] train: loss: 0.1017432
[Epoch 82; Iter   147/  183] train: loss: 0.1352890
[Epoch 82; Iter   177/  183] train: loss: 0.0606900
[Epoch 82] ogbg-moltox21: 0.809914 val loss: 0.253681
[Epoch 82] ogbg-moltox21: 0.815428 test loss: 0.255967
[Epoch 83; Iter    24/  183] train: loss: 0.0491076
[Epoch 83; Iter    54/  183] train: loss: 0.0646375
[Epoch 83; Iter    84/  183] train: loss: 0.0751574
[Epoch 83; Iter   114/  183] train: loss: 0.0412949
[Epoch 83; Iter   144/  183] train: loss: 0.0899831
[Epoch 83; Iter   174/  183] train: loss: 0.1061984
[Epoch 83] ogbg-moltox21: 0.803522 val loss: 0.254973
[Epoch 83] ogbg-moltox21: 0.820638 test loss: 0.252442
[Epoch 84; Iter    21/  183] train: loss: 0.0759246
[Epoch 84; Iter    51/  183] train: loss: 0.0698477
[Epoch 84; Iter    81/  183] train: loss: 0.0844431
[Epoch 84; Iter   111/  183] train: loss: 0.0678252
[Epoch 84; Iter   141/  183] train: loss: 0.0953358
[Epoch 84; Iter   171/  183] train: loss: 0.0911512
[Epoch 84] ogbg-moltox21: 0.808149 val loss: 0.256297
[Epoch 84] ogbg-moltox21: 0.821800 test loss: 0.255804
[Epoch 85; Iter    18/  183] train: loss: 0.0648741
[Epoch 85; Iter    48/  183] train: loss: 0.0575134
[Epoch 85; Iter    78/  183] train: loss: 0.0729432
[Epoch 85; Iter   108/  183] train: loss: 0.0759661
[Epoch 85; Iter   138/  183] train: loss: 0.0745964
[Epoch 85; Iter   168/  183] train: loss: 0.0527704
[Epoch 85] ogbg-moltox21: 0.803654 val loss: 0.260100
[Epoch 85] ogbg-moltox21: 0.815426 test loss: 0.264799
[Epoch 86; Iter    15/  183] train: loss: 0.0610993
[Epoch 86; Iter    45/  183] train: loss: 0.0762436
[Epoch 86; Iter    75/  183] train: loss: 0.0469056
[Epoch 86; Iter   105/  183] train: loss: 0.0708504
[Epoch 86; Iter   135/  183] train: loss: 0.0565082
[Epoch 86; Iter   165/  183] train: loss: 0.0639088
[Epoch 86] ogbg-moltox21: 0.807319 val loss: 0.257364
[Epoch 86] ogbg-moltox21: 0.820008 test loss: 0.258705
[Epoch 87; Iter    12/  183] train: loss: 0.1029594
[Epoch 87; Iter    42/  183] train: loss: 0.0795272
[Epoch 87; Iter    72/  183] train: loss: 0.0809933
[Epoch 87; Iter   102/  183] train: loss: 0.0982188
[Epoch 87; Iter   132/  183] train: loss: 0.0939702
[Epoch 87; Iter   162/  183] train: loss: 0.0573093
[Epoch 87] ogbg-moltox21: 0.798850 val loss: 0.263709
[Epoch 87] ogbg-moltox21: 0.807812 test loss: 0.269406
[Epoch 88; Iter     9/  183] train: loss: 0.1179808
[Epoch 88; Iter    39/  183] train: loss: 0.0764583
[Epoch 88; Iter    69/  183] train: loss: 0.0632360
[Epoch 88; Iter    99/  183] train: loss: 0.0266009
[Epoch 88; Iter   129/  183] train: loss: 0.0596107
[Epoch 88; Iter   159/  183] train: loss: 0.0604783
[Epoch 88] ogbg-moltox21: 0.809402 val loss: 0.267783
[Epoch 88] ogbg-moltox21: 0.819919 test loss: 0.267976
[Epoch 89; Iter     6/  183] train: loss: 0.0359783
[Epoch 89; Iter    36/  183] train: loss: 0.0365875
[Epoch 89; Iter    66/  183] train: loss: 0.0826592
[Epoch 89; Iter    96/  183] train: loss: 0.0694679
[Epoch 89; Iter   126/  183] train: loss: 0.1114837
[Epoch 89; Iter   156/  183] train: loss: 0.0374208
[Epoch 89] ogbg-moltox21: 0.804735 val loss: 0.265899
[Epoch 89] ogbg-moltox21: 0.813266 test loss: 0.268359
[Epoch 90; Iter     3/  183] train: loss: 0.0338944
[Epoch 90; Iter    33/  183] train: loss: 0.0407457
[Epoch 90; Iter    63/  183] train: loss: 0.0549635
[Epoch 90; Iter    93/  183] train: loss: 0.0553194
[Epoch 90; Iter   123/  183] train: loss: 0.0832154
[Epoch 90; Iter   153/  183] train: loss: 0.0853772
[Epoch 90; Iter   183/  183] train: loss: 0.0375478
[Epoch 80; Iter    47/  157] train: loss: 0.1060138
[Epoch 80; Iter    77/  157] train: loss: 0.1225037
[Epoch 80; Iter   107/  157] train: loss: 0.1268095
[Epoch 80; Iter   137/  157] train: loss: 0.0777408
[Epoch 80] ogbg-moltox21: 0.831224 val loss: 0.192945
[Epoch 80] ogbg-moltox21: 0.844306 test loss: 0.216158
[Epoch 81; Iter    10/  157] train: loss: 0.1269440
[Epoch 81; Iter    40/  157] train: loss: 0.1488445
[Epoch 81; Iter    70/  157] train: loss: 0.1352545
[Epoch 81; Iter   100/  157] train: loss: 0.1510656
[Epoch 81; Iter   130/  157] train: loss: 0.1311121
[Epoch 81] ogbg-moltox21: 0.831854 val loss: 0.189882
[Epoch 81] ogbg-moltox21: 0.842995 test loss: 0.229629
[Epoch 82; Iter     3/  157] train: loss: 0.1718500
[Epoch 82; Iter    33/  157] train: loss: 0.0856585
[Epoch 82; Iter    63/  157] train: loss: 0.1736029
[Epoch 82; Iter    93/  157] train: loss: 0.1801960
[Epoch 82; Iter   123/  157] train: loss: 0.1018491
[Epoch 82; Iter   153/  157] train: loss: 0.1184713
[Epoch 82] ogbg-moltox21: 0.833112 val loss: 0.533313
[Epoch 82] ogbg-moltox21: 0.832419 test loss: 0.269789
[Epoch 83; Iter    26/  157] train: loss: 0.1066874
[Epoch 83; Iter    56/  157] train: loss: 0.1282134
[Epoch 83; Iter    86/  157] train: loss: 0.1035582
[Epoch 83; Iter   116/  157] train: loss: 0.1581521
[Epoch 83; Iter   146/  157] train: loss: 0.0862728
[Epoch 83] ogbg-moltox21: 0.828466 val loss: 0.229529
[Epoch 83] ogbg-moltox21: 0.831643 test loss: 0.264494
[Epoch 84; Iter    19/  157] train: loss: 0.0774661
[Epoch 84; Iter    49/  157] train: loss: 0.1389046
[Epoch 84; Iter    79/  157] train: loss: 0.1249361
[Epoch 84; Iter   109/  157] train: loss: 0.0846907
[Epoch 84; Iter   139/  157] train: loss: 0.1311365
[Epoch 84] ogbg-moltox21: 0.832968 val loss: 0.193462
[Epoch 84] ogbg-moltox21: 0.837905 test loss: 0.227048
[Epoch 85; Iter    12/  157] train: loss: 0.1038828
[Epoch 85; Iter    42/  157] train: loss: 0.2583394
[Epoch 85; Iter    72/  157] train: loss: 0.1117666
[Epoch 85; Iter   102/  157] train: loss: 0.0768839
[Epoch 85; Iter   132/  157] train: loss: 0.1021725
[Epoch 85] ogbg-moltox21: 0.826681 val loss: 0.227171
[Epoch 85] ogbg-moltox21: 0.833236 test loss: 0.252942
[Epoch 86; Iter     5/  157] train: loss: 0.1217378
[Epoch 86; Iter    35/  157] train: loss: 0.1031759
[Epoch 86; Iter    65/  157] train: loss: 0.1318311
[Epoch 86; Iter    95/  157] train: loss: 0.1787751
[Epoch 86; Iter   125/  157] train: loss: 0.1094390
[Epoch 86; Iter   155/  157] train: loss: 0.1131639
[Epoch 86] ogbg-moltox21: 0.828972 val loss: 0.201338
[Epoch 86] ogbg-moltox21: 0.840780 test loss: 0.243126
[Epoch 87; Iter    28/  157] train: loss: 0.1103995
[Epoch 87; Iter    58/  157] train: loss: 0.1204687
[Epoch 87; Iter    88/  157] train: loss: 0.1470420
[Epoch 87; Iter   118/  157] train: loss: 0.1558546
[Epoch 87; Iter   148/  157] train: loss: 0.0967514
[Epoch 87] ogbg-moltox21: 0.827905 val loss: 0.202244
[Epoch 87] ogbg-moltox21: 0.831459 test loss: 0.233689
[Epoch 88; Iter    21/  157] train: loss: 0.1571534
[Epoch 88; Iter    51/  157] train: loss: 0.1008811
[Epoch 88; Iter    81/  157] train: loss: 0.1415697
[Epoch 88; Iter   111/  157] train: loss: 0.1512057
[Epoch 88; Iter   141/  157] train: loss: 0.1740420
[Epoch 88] ogbg-moltox21: 0.838584 val loss: 0.201870
[Epoch 88] ogbg-moltox21: 0.835619 test loss: 0.240916
[Epoch 89; Iter    14/  157] train: loss: 0.0894891
[Epoch 89; Iter    44/  157] train: loss: 0.1260405
[Epoch 89; Iter    74/  157] train: loss: 0.1327347
[Epoch 89; Iter   104/  157] train: loss: 0.1457661
[Epoch 89; Iter   134/  157] train: loss: 0.1420324
[Epoch 89] ogbg-moltox21: 0.827632 val loss: 0.205858
[Epoch 89] ogbg-moltox21: 0.837886 test loss: 0.226656
[Epoch 90; Iter     7/  157] train: loss: 0.1028795
[Epoch 90; Iter    37/  157] train: loss: 0.1163841
[Epoch 90; Iter    67/  157] train: loss: 0.1574446
[Epoch 90; Iter    97/  157] train: loss: 0.1275942
[Epoch 90; Iter   127/  157] train: loss: 0.1064064
[Epoch 90; Iter   157/  157] train: loss: 0.1344524
[Epoch 90] ogbg-moltox21: 0.831401 val loss: 1.446446
[Epoch 90] ogbg-moltox21: 0.823225 test loss: 0.271584
[Epoch 91; Iter    30/  157] train: loss: 0.1155182
[Epoch 91; Iter    60/  157] train: loss: 0.1007538
[Epoch 91; Iter    90/  157] train: loss: 0.1211329
[Epoch 91; Iter   120/  157] train: loss: 0.1381929
[Epoch 91; Iter   150/  157] train: loss: 0.1212573
[Epoch 91] ogbg-moltox21: 0.833167 val loss: 0.196089
[Epoch 91] ogbg-moltox21: 0.833246 test loss: 0.230963
[Epoch 92; Iter    23/  157] train: loss: 0.1152026
[Epoch 92; Iter    53/  157] train: loss: 0.1543455
[Epoch 92; Iter    83/  157] train: loss: 0.1171287
[Epoch 92; Iter   113/  157] train: loss: 0.1055677
[Epoch 92; Iter   143/  157] train: loss: 0.0781635
[Epoch 92] ogbg-moltox21: 0.828458 val loss: 0.200114
[Epoch 92] ogbg-moltox21: 0.833616 test loss: 0.252693
[Epoch 93; Iter    16/  157] train: loss: 0.1285573
[Epoch 93; Iter    46/  157] train: loss: 0.1245318
[Epoch 93; Iter    76/  157] train: loss: 0.1660627
[Epoch 93; Iter   106/  157] train: loss: 0.1766019
[Epoch 93; Iter   136/  157] train: loss: 0.1341360
[Epoch 93] ogbg-moltox21: 0.833796 val loss: 0.198950
[Epoch 93] ogbg-moltox21: 0.840458 test loss: 0.227726
[Epoch 94; Iter     9/  157] train: loss: 0.0960485
[Epoch 94; Iter    39/  157] train: loss: 0.0882839
[Epoch 94; Iter    69/  157] train: loss: 0.1194374
[Epoch 94; Iter    99/  157] train: loss: 0.1169937
[Epoch 94; Iter   129/  157] train: loss: 0.1660826
[Epoch 94] ogbg-moltox21: 0.825273 val loss: 0.201134
[Epoch 94] ogbg-moltox21: 0.838301 test loss: 0.222657
[Epoch 95; Iter     2/  157] train: loss: 0.1247228
[Epoch 95; Iter    32/  157] train: loss: 0.0797772
[Epoch 95; Iter    62/  157] train: loss: 0.1114690
[Epoch 95; Iter    92/  157] train: loss: 0.0554183
[Epoch 95; Iter   122/  157] train: loss: 0.0739112
[Epoch 95; Iter   152/  157] train: loss: 0.1021608
[Epoch 95] ogbg-moltox21: 0.829887 val loss: 0.197267
[Epoch 95] ogbg-moltox21: 0.840354 test loss: 0.227847
[Epoch 96; Iter    25/  157] train: loss: 0.1454948
[Epoch 96; Iter    55/  157] train: loss: 0.0914819
[Epoch 96; Iter    85/  157] train: loss: 0.1186523
[Epoch 96; Iter   115/  157] train: loss: 0.1016579
[Epoch 96; Iter   145/  157] train: loss: 0.0715221
[Epoch 96] ogbg-moltox21: 0.830046 val loss: 0.200832
[Epoch 96] ogbg-moltox21: 0.838817 test loss: 0.226808
[Epoch 97; Iter    18/  157] train: loss: 0.0583929
[Epoch 97; Iter    48/  157] train: loss: 0.1278787
[Epoch 97; Iter    78/  157] train: loss: 0.0619371
[Epoch 97; Iter   108/  157] train: loss: 0.1282412
[Epoch 97; Iter   138/  157] train: loss: 0.0783538
[Epoch 97] ogbg-moltox21: 0.823034 val loss: 0.247943
[Epoch 97] ogbg-moltox21: 0.830656 test loss: 0.254756
[Epoch 98; Iter    11/  157] train: loss: 0.0911753
[Epoch 98; Iter    41/  157] train: loss: 0.1504089
[Epoch 98; Iter    71/  157] train: loss: 0.1024696
[Epoch 98; Iter   101/  157] train: loss: 0.0689310
[Epoch 98; Iter   131/  157] train: loss: 0.0996273
[Epoch 98] ogbg-moltox21: 0.824585 val loss: 0.263983
[Epoch 98] ogbg-moltox21: 0.830445 test loss: 0.247439
[Epoch 99; Iter     4/  157] train: loss: 0.0697154
[Epoch 99; Iter    34/  157] train: loss: 0.0923570
[Epoch 99; Iter    64/  157] train: loss: 0.0843762
[Epoch 99; Iter    94/  157] train: loss: 0.1556302
[Epoch 99; Iter   124/  157] train: loss: 0.1139849
[Epoch 99; Iter   154/  157] train: loss: 0.0966281
[Epoch 99] ogbg-moltox21: 0.822595 val loss: 0.209836
[Epoch 99] ogbg-moltox21: 0.829286 test loss: 0.230440
[Epoch 100; Iter    27/  157] train: loss: 0.0657598
[Epoch 100; Iter    57/  157] train: loss: 0.1488952
[Epoch 100; Iter    87/  157] train: loss: 0.0815002
[Epoch 100; Iter   117/  157] train: loss: 0.1432561
[Epoch 100; Iter   147/  157] train: loss: 0.1508947
[Epoch 100] ogbg-moltox21: 0.833991 val loss: 0.201633
[Epoch 100] ogbg-moltox21: 0.832232 test loss: 0.246718
[Epoch 101; Iter    20/  157] train: loss: 0.0779977
[Epoch 101; Iter    50/  157] train: loss: 0.1135925
[Epoch 101; Iter    80/  157] train: loss: 0.1180433
[Epoch 101; Iter   110/  157] train: loss: 0.0628352
[Epoch 80; Iter    47/  157] train: loss: 0.0810458
[Epoch 80; Iter    77/  157] train: loss: 0.0672371
[Epoch 80; Iter   107/  157] train: loss: 0.0670294
[Epoch 80; Iter   137/  157] train: loss: 0.0812758
[Epoch 80] ogbg-moltox21: 0.818974 val loss: 0.240166
[Epoch 80] ogbg-moltox21: 0.821400 test loss: 0.265629
[Epoch 81; Iter    10/  157] train: loss: 0.1302238
[Epoch 81; Iter    40/  157] train: loss: 0.0431649
[Epoch 81; Iter    70/  157] train: loss: 0.0548551
[Epoch 81; Iter   100/  157] train: loss: 0.0864637
[Epoch 81; Iter   130/  157] train: loss: 0.0855979
[Epoch 81] ogbg-moltox21: 0.811771 val loss: 0.237759
[Epoch 81] ogbg-moltox21: 0.811055 test loss: 0.268058
[Epoch 82; Iter     3/  157] train: loss: 0.0447476
[Epoch 82; Iter    33/  157] train: loss: 0.0549654
[Epoch 82; Iter    63/  157] train: loss: 0.0582852
[Epoch 82; Iter    93/  157] train: loss: 0.0467855
[Epoch 82; Iter   123/  157] train: loss: 0.0858097
[Epoch 82; Iter   153/  157] train: loss: 0.0418881
[Epoch 82] ogbg-moltox21: 0.812732 val loss: 0.238949
[Epoch 82] ogbg-moltox21: 0.813273 test loss: 0.270613
[Epoch 83; Iter    26/  157] train: loss: 0.0650122
[Epoch 83; Iter    56/  157] train: loss: 0.1104867
[Epoch 83; Iter    86/  157] train: loss: 0.0946829
[Epoch 83; Iter   116/  157] train: loss: 0.0591893
[Epoch 83; Iter   146/  157] train: loss: 0.0328323
[Epoch 83] ogbg-moltox21: 0.812450 val loss: 0.242026
[Epoch 83] ogbg-moltox21: 0.811819 test loss: 0.276728
[Epoch 84; Iter    19/  157] train: loss: 0.0696377
[Epoch 84; Iter    49/  157] train: loss: 0.0525129
[Epoch 84; Iter    79/  157] train: loss: 0.0854793
[Epoch 84; Iter   109/  157] train: loss: 0.1208715
[Epoch 84; Iter   139/  157] train: loss: 0.0671705
[Epoch 84] ogbg-moltox21: 0.813462 val loss: 0.242083
[Epoch 84] ogbg-moltox21: 0.814109 test loss: 0.269139
[Epoch 85; Iter    12/  157] train: loss: 0.0507590
[Epoch 85; Iter    42/  157] train: loss: 0.0672648
[Epoch 85; Iter    72/  157] train: loss: 0.0351227
[Epoch 85; Iter   102/  157] train: loss: 0.0645268
[Epoch 85; Iter   132/  157] train: loss: 0.0438768
[Epoch 85] ogbg-moltox21: 0.812449 val loss: 0.244656
[Epoch 85] ogbg-moltox21: 0.818115 test loss: 0.272955
[Epoch 86; Iter     5/  157] train: loss: 0.0717798
[Epoch 86; Iter    35/  157] train: loss: 0.0502790
[Epoch 86; Iter    65/  157] train: loss: 0.0598918
[Epoch 86; Iter    95/  157] train: loss: 0.0479204
[Epoch 86; Iter   125/  157] train: loss: 0.0707504
[Epoch 86; Iter   155/  157] train: loss: 0.0691302
[Epoch 86] ogbg-moltox21: 0.809305 val loss: 0.250113
[Epoch 86] ogbg-moltox21: 0.816450 test loss: 0.274587
[Epoch 87; Iter    28/  157] train: loss: 0.0472375
[Epoch 87; Iter    58/  157] train: loss: 0.0603651
[Epoch 87; Iter    88/  157] train: loss: 0.0644317
[Epoch 87; Iter   118/  157] train: loss: 0.0535500
[Epoch 87; Iter   148/  157] train: loss: 0.0555505
[Epoch 87] ogbg-moltox21: 0.809434 val loss: 0.248694
[Epoch 87] ogbg-moltox21: 0.809157 test loss: 0.278600
[Epoch 88; Iter    21/  157] train: loss: 0.0774339
[Epoch 88; Iter    51/  157] train: loss: 0.0611630
[Epoch 88; Iter    81/  157] train: loss: 0.0710159
[Epoch 88; Iter   111/  157] train: loss: 0.0666313
[Epoch 88; Iter   141/  157] train: loss: 0.0879198
[Epoch 88] ogbg-moltox21: 0.808951 val loss: 0.247839
[Epoch 88] ogbg-moltox21: 0.813313 test loss: 0.282196
[Epoch 89; Iter    14/  157] train: loss: 0.0657104
[Epoch 89; Iter    44/  157] train: loss: 0.0582501
[Epoch 89; Iter    74/  157] train: loss: 0.0522465
[Epoch 89; Iter   104/  157] train: loss: 0.0533576
[Epoch 89; Iter   134/  157] train: loss: 0.0534327
[Epoch 89] ogbg-moltox21: 0.816445 val loss: 0.247582
[Epoch 89] ogbg-moltox21: 0.813314 test loss: 0.280785
[Epoch 90; Iter     7/  157] train: loss: 0.0565327
[Epoch 90; Iter    37/  157] train: loss: 0.0523597
[Epoch 90; Iter    67/  157] train: loss: 0.0957145
[Epoch 90; Iter    97/  157] train: loss: 0.0539123
[Epoch 90; Iter   127/  157] train: loss: 0.0889664
[Epoch 90; Iter   157/  157] train: loss: 0.0757861
[Epoch 90] ogbg-moltox21: 0.810037 val loss: 0.261613
[Epoch 90] ogbg-moltox21: 0.812956 test loss: 0.287803
[Epoch 91; Iter    30/  157] train: loss: 0.0549219
[Epoch 91; Iter    60/  157] train: loss: 0.0823415
[Epoch 91; Iter    90/  157] train: loss: 0.0430713
[Epoch 91; Iter   120/  157] train: loss: 0.0755950
[Epoch 91; Iter   150/  157] train: loss: 0.0573344
[Epoch 91] ogbg-moltox21: 0.811155 val loss: 0.254347
[Epoch 91] ogbg-moltox21: 0.813669 test loss: 0.284156
[Epoch 92; Iter    23/  157] train: loss: 0.0632222
[Epoch 92; Iter    53/  157] train: loss: 0.0420015
[Epoch 92; Iter    83/  157] train: loss: 0.0568287
[Epoch 92; Iter   113/  157] train: loss: 0.0594846
[Epoch 92; Iter   143/  157] train: loss: 0.0769136
[Epoch 92] ogbg-moltox21: 0.811890 val loss: 0.251330
[Epoch 92] ogbg-moltox21: 0.814589 test loss: 0.280025
[Epoch 93; Iter    16/  157] train: loss: 0.0529708
[Epoch 93; Iter    46/  157] train: loss: 0.0395918
[Epoch 93; Iter    76/  157] train: loss: 0.0483831
[Epoch 93; Iter   106/  157] train: loss: 0.0511141
[Epoch 93; Iter   136/  157] train: loss: 0.0549785
[Epoch 93] ogbg-moltox21: 0.811931 val loss: 0.255249
[Epoch 93] ogbg-moltox21: 0.812141 test loss: 0.289566
[Epoch 94; Iter     9/  157] train: loss: 0.0711430
[Epoch 94; Iter    39/  157] train: loss: 0.0294157
[Epoch 94; Iter    69/  157] train: loss: 0.0461008
[Epoch 94; Iter    99/  157] train: loss: 0.0414024
[Epoch 94; Iter   129/  157] train: loss: 0.0526848
[Epoch 94] ogbg-moltox21: 0.806424 val loss: 0.258508
[Epoch 94] ogbg-moltox21: 0.807682 test loss: 0.297226
[Epoch 95; Iter     2/  157] train: loss: 0.0406870
[Epoch 95; Iter    32/  157] train: loss: 0.0634271
[Epoch 95; Iter    62/  157] train: loss: 0.0431460
[Epoch 95; Iter    92/  157] train: loss: 0.0662483
[Epoch 95; Iter   122/  157] train: loss: 0.0804052
[Epoch 95; Iter   152/  157] train: loss: 0.0568753
[Epoch 95] ogbg-moltox21: 0.806697 val loss: 0.257826
[Epoch 95] ogbg-moltox21: 0.808598 test loss: 0.290855
[Epoch 96; Iter    25/  157] train: loss: 0.0423116
[Epoch 96; Iter    55/  157] train: loss: 0.0444640
[Epoch 96; Iter    85/  157] train: loss: 0.0482271
[Epoch 96; Iter   115/  157] train: loss: 0.0357397
[Epoch 96; Iter   145/  157] train: loss: 0.0608616
[Epoch 96] ogbg-moltox21: 0.807767 val loss: 0.264301
[Epoch 96] ogbg-moltox21: 0.809703 test loss: 0.296957
[Epoch 97; Iter    18/  157] train: loss: 0.0565069
[Epoch 97; Iter    48/  157] train: loss: 0.0563160
[Epoch 97; Iter    78/  157] train: loss: 0.0806586
[Epoch 97; Iter   108/  157] train: loss: 0.0221470
[Epoch 97; Iter   138/  157] train: loss: 0.0546735
[Epoch 97] ogbg-moltox21: 0.805666 val loss: 0.261250
[Epoch 97] ogbg-moltox21: 0.813890 test loss: 0.287246
[Epoch 98; Iter    11/  157] train: loss: 0.0735818
[Epoch 98; Iter    41/  157] train: loss: 0.0314311
[Epoch 98; Iter    71/  157] train: loss: 0.0579020
[Epoch 98; Iter   101/  157] train: loss: 0.0638781
[Epoch 98; Iter   131/  157] train: loss: 0.0487817
[Epoch 98] ogbg-moltox21: 0.808602 val loss: 0.263215
[Epoch 98] ogbg-moltox21: 0.808212 test loss: 0.294959
[Epoch 99; Iter     4/  157] train: loss: 0.0490429
[Epoch 99; Iter    34/  157] train: loss: 0.0498979
[Epoch 99; Iter    64/  157] train: loss: 0.0468187
[Epoch 99; Iter    94/  157] train: loss: 0.0586769
[Epoch 99; Iter   124/  157] train: loss: 0.0626953
[Epoch 99; Iter   154/  157] train: loss: 0.0441390
[Epoch 99] ogbg-moltox21: 0.802660 val loss: 0.269572
[Epoch 99] ogbg-moltox21: 0.808840 test loss: 0.299652
[Epoch 100; Iter    27/  157] train: loss: 0.0501975
[Epoch 100; Iter    57/  157] train: loss: 0.0458258
[Epoch 100; Iter    87/  157] train: loss: 0.0231541
[Epoch 100; Iter   117/  157] train: loss: 0.0611218
[Epoch 100; Iter   147/  157] train: loss: 0.0617920
[Epoch 100] ogbg-moltox21: 0.807706 val loss: 0.266378
[Epoch 100] ogbg-moltox21: 0.807804 test loss: 0.295906
[Epoch 101; Iter    20/  157] train: loss: 0.0486416
[Epoch 101; Iter    50/  157] train: loss: 0.0254705
[Epoch 101; Iter    80/  157] train: loss: 0.0350737
[Epoch 101; Iter   110/  157] train: loss: 0.0901853
[Epoch 80; Iter    47/  157] train: loss: 0.0735605
[Epoch 80; Iter    77/  157] train: loss: 0.0778312
[Epoch 80; Iter   107/  157] train: loss: 0.0607360
[Epoch 80; Iter   137/  157] train: loss: 0.1105372
[Epoch 80] ogbg-moltox21: 0.802108 val loss: 0.241554
[Epoch 80] ogbg-moltox21: 0.813478 test loss: 0.256541
[Epoch 81; Iter    10/  157] train: loss: 0.0932378
[Epoch 81; Iter    40/  157] train: loss: 0.0918352
[Epoch 81; Iter    70/  157] train: loss: 0.1126012
[Epoch 81; Iter   100/  157] train: loss: 0.0786585
[Epoch 81; Iter   130/  157] train: loss: 0.0880830
[Epoch 81] ogbg-moltox21: 0.806434 val loss: 0.244038
[Epoch 81] ogbg-moltox21: 0.817790 test loss: 0.252676
[Epoch 82; Iter     3/  157] train: loss: 0.0330776
[Epoch 82; Iter    33/  157] train: loss: 0.0674274
[Epoch 82; Iter    63/  157] train: loss: 0.0763975
[Epoch 82; Iter    93/  157] train: loss: 0.0962807
[Epoch 82; Iter   123/  157] train: loss: 0.0813438
[Epoch 82; Iter   153/  157] train: loss: 0.0842536
[Epoch 82] ogbg-moltox21: 0.804979 val loss: 0.257161
[Epoch 82] ogbg-moltox21: 0.817190 test loss: 0.256605
[Epoch 83; Iter    26/  157] train: loss: 0.0826805
[Epoch 83; Iter    56/  157] train: loss: 0.0863305
[Epoch 83; Iter    86/  157] train: loss: 0.0411797
[Epoch 83; Iter   116/  157] train: loss: 0.0694069
[Epoch 83; Iter   146/  157] train: loss: 0.0660135
[Epoch 83] ogbg-moltox21: 0.804106 val loss: 0.246816
[Epoch 83] ogbg-moltox21: 0.817393 test loss: 0.256228
[Epoch 84; Iter    19/  157] train: loss: 0.0686766
[Epoch 84; Iter    49/  157] train: loss: 0.0407242
[Epoch 84; Iter    79/  157] train: loss: 0.0940258
[Epoch 84; Iter   109/  157] train: loss: 0.0918088
[Epoch 84; Iter   139/  157] train: loss: 0.0774522
[Epoch 84] ogbg-moltox21: 0.802347 val loss: 0.236297
[Epoch 84] ogbg-moltox21: 0.812065 test loss: 0.259524
[Epoch 85; Iter    12/  157] train: loss: 0.0854217
[Epoch 85; Iter    42/  157] train: loss: 0.1483562
[Epoch 85; Iter    72/  157] train: loss: 0.0892810
[Epoch 85; Iter   102/  157] train: loss: 0.0772087
[Epoch 85; Iter   132/  157] train: loss: 0.1957158
[Epoch 85] ogbg-moltox21: 0.806289 val loss: 0.292992
[Epoch 85] ogbg-moltox21: 0.816252 test loss: 0.266117
[Epoch 86; Iter     5/  157] train: loss: 0.0687845
[Epoch 86; Iter    35/  157] train: loss: 0.0822189
[Epoch 86; Iter    65/  157] train: loss: 0.0742788
[Epoch 86; Iter    95/  157] train: loss: 0.1002329
[Epoch 86; Iter   125/  157] train: loss: 0.0710355
[Epoch 86; Iter   155/  157] train: loss: 0.0901430
[Epoch 86] ogbg-moltox21: 0.812102 val loss: 0.237604
[Epoch 86] ogbg-moltox21: 0.814953 test loss: 0.260069
[Epoch 87; Iter    28/  157] train: loss: 0.0644165
[Epoch 87; Iter    58/  157] train: loss: 0.0622693
[Epoch 87; Iter    88/  157] train: loss: 0.0841858
[Epoch 87; Iter   118/  157] train: loss: 0.1291237
[Epoch 87; Iter   148/  157] train: loss: 0.0816529
[Epoch 87] ogbg-moltox21: 0.802936 val loss: 0.334537
[Epoch 87] ogbg-moltox21: 0.817789 test loss: 0.262471
[Epoch 88; Iter    21/  157] train: loss: 0.0639153
[Epoch 88; Iter    51/  157] train: loss: 0.0603619
[Epoch 88; Iter    81/  157] train: loss: 0.1121322
[Epoch 88; Iter   111/  157] train: loss: 0.0574782
[Epoch 88; Iter   141/  157] train: loss: 0.0770037
[Epoch 88] ogbg-moltox21: 0.803922 val loss: 0.266717
[Epoch 88] ogbg-moltox21: 0.815550 test loss: 0.260031
[Epoch 89; Iter    14/  157] train: loss: 0.0448289
[Epoch 89; Iter    44/  157] train: loss: 0.1307038
[Epoch 89; Iter    74/  157] train: loss: 0.0947400
[Epoch 89; Iter   104/  157] train: loss: 0.0597217
[Epoch 89; Iter   134/  157] train: loss: 0.0426137
[Epoch 89] ogbg-moltox21: 0.801238 val loss: 0.350702
[Epoch 89] ogbg-moltox21: 0.815571 test loss: 0.270692
[Epoch 90; Iter     7/  157] train: loss: 0.0589937
[Epoch 90; Iter    37/  157] train: loss: 0.0649292
[Epoch 90; Iter    67/  157] train: loss: 0.0570837
[Epoch 90; Iter    97/  157] train: loss: 0.0637105
[Epoch 90; Iter   127/  157] train: loss: 0.0832629
[Epoch 90; Iter   157/  157] train: loss: 0.0285047
[Epoch 90] ogbg-moltox21: 0.804501 val loss: 0.244694
[Epoch 90] ogbg-moltox21: 0.818111 test loss: 0.262132
[Epoch 91; Iter    30/  157] train: loss: 0.0604520
[Epoch 91; Iter    60/  157] train: loss: 0.0548528
[Epoch 91; Iter    90/  157] train: loss: 0.0547562
[Epoch 91; Iter   120/  157] train: loss: 0.0726451
[Epoch 91; Iter   150/  157] train: loss: 0.0509250
[Epoch 91] ogbg-moltox21: 0.805999 val loss: 0.250088
[Epoch 91] ogbg-moltox21: 0.819314 test loss: 0.261180
[Epoch 92; Iter    23/  157] train: loss: 0.0792964
[Epoch 92; Iter    53/  157] train: loss: 0.0619021
[Epoch 92; Iter    83/  157] train: loss: 0.0688849
[Epoch 92; Iter   113/  157] train: loss: 0.0994891
[Epoch 92; Iter   143/  157] train: loss: 0.0599332
[Epoch 92] ogbg-moltox21: 0.803961 val loss: 0.245448
[Epoch 92] ogbg-moltox21: 0.816433 test loss: 0.263590
[Epoch 93; Iter    16/  157] train: loss: 0.0542132
[Epoch 93; Iter    46/  157] train: loss: 0.0308718
[Epoch 93; Iter    76/  157] train: loss: 0.0556744
[Epoch 93; Iter   106/  157] train: loss: 0.0571572
[Epoch 93; Iter   136/  157] train: loss: 0.0506101
[Epoch 93] ogbg-moltox21: 0.801077 val loss: 0.257118
[Epoch 93] ogbg-moltox21: 0.813207 test loss: 0.268344
[Epoch 94; Iter     9/  157] train: loss: 0.0595876
[Epoch 94; Iter    39/  157] train: loss: 0.0771533
[Epoch 94; Iter    69/  157] train: loss: 0.0724286
[Epoch 94; Iter    99/  157] train: loss: 0.0767892
[Epoch 94; Iter   129/  157] train: loss: 0.0310377
[Epoch 94] ogbg-moltox21: 0.801621 val loss: 0.250708
[Epoch 94] ogbg-moltox21: 0.813910 test loss: 0.271265
[Epoch 95; Iter     2/  157] train: loss: 0.0838592
[Epoch 95; Iter    32/  157] train: loss: 0.0678986
[Epoch 95; Iter    62/  157] train: loss: 0.0515045
[Epoch 95; Iter    92/  157] train: loss: 0.0398284
[Epoch 95; Iter   122/  157] train: loss: 0.1116581
[Epoch 95; Iter   152/  157] train: loss: 0.1043801
[Epoch 95] ogbg-moltox21: 0.803638 val loss: 0.251491
[Epoch 95] ogbg-moltox21: 0.815031 test loss: 0.269331
[Epoch 96; Iter    25/  157] train: loss: 0.0605960
[Epoch 96; Iter    55/  157] train: loss: 0.0375792
[Epoch 96; Iter    85/  157] train: loss: 0.0665300
[Epoch 96; Iter   115/  157] train: loss: 0.1518374
[Epoch 96; Iter   145/  157] train: loss: 0.0448366
[Epoch 96] ogbg-moltox21: 0.803097 val loss: 0.322003
[Epoch 96] ogbg-moltox21: 0.813457 test loss: 0.275195
[Epoch 97; Iter    18/  157] train: loss: 0.0538357
[Epoch 97; Iter    48/  157] train: loss: 0.0634992
[Epoch 97; Iter    78/  157] train: loss: 0.0834852
[Epoch 97; Iter   108/  157] train: loss: 0.0695274
[Epoch 97; Iter   138/  157] train: loss: 0.0573530
[Epoch 97] ogbg-moltox21: 0.804190 val loss: 0.254496
[Epoch 97] ogbg-moltox21: 0.815051 test loss: 0.273468
[Epoch 98; Iter    11/  157] train: loss: 0.0733097
[Epoch 98; Iter    41/  157] train: loss: 0.0461288
[Epoch 98; Iter    71/  157] train: loss: 0.0925858
[Epoch 98; Iter   101/  157] train: loss: 0.0424292
[Epoch 98; Iter   131/  157] train: loss: 0.0305777
[Epoch 98] ogbg-moltox21: 0.803372 val loss: 0.312082
[Epoch 98] ogbg-moltox21: 0.812446 test loss: 0.276836
[Epoch 99; Iter     4/  157] train: loss: 0.0409313
[Epoch 99; Iter    34/  157] train: loss: 0.0658715
[Epoch 99; Iter    64/  157] train: loss: 0.0444849
[Epoch 99; Iter    94/  157] train: loss: 0.0442855
[Epoch 99; Iter   124/  157] train: loss: 0.0321899
[Epoch 99; Iter   154/  157] train: loss: 0.0387365
[Epoch 99] ogbg-moltox21: 0.801442 val loss: 0.255676
[Epoch 99] ogbg-moltox21: 0.810909 test loss: 0.276377
[Epoch 100; Iter    27/  157] train: loss: 0.0609878
[Epoch 100; Iter    57/  157] train: loss: 0.0423173
[Epoch 100; Iter    87/  157] train: loss: 0.0652008
[Epoch 100; Iter   117/  157] train: loss: 0.0349524
[Epoch 100; Iter   147/  157] train: loss: 0.0763053
[Epoch 100] ogbg-moltox21: 0.804137 val loss: 0.288394
[Epoch 100] ogbg-moltox21: 0.816688 test loss: 0.273518
[Epoch 101; Iter    20/  157] train: loss: 0.1047956
[Epoch 101; Iter    50/  157] train: loss: 0.0434647
[Epoch 101; Iter    80/  157] train: loss: 0.0551030
[Epoch 101; Iter   110/  157] train: loss: 0.0705908
[Epoch 82; Iter    51/  209] train: loss: 0.0846701
[Epoch 82; Iter    81/  209] train: loss: 0.0686472
[Epoch 82; Iter   111/  209] train: loss: 0.0501730
[Epoch 82; Iter   141/  209] train: loss: 0.1135600
[Epoch 82; Iter   171/  209] train: loss: 0.0751911
[Epoch 82; Iter   201/  209] train: loss: 0.0618486
[Epoch 82] ogbg-moltox21: 0.847172 val loss: 0.263566
[Epoch 82] ogbg-moltox21: 0.836935 test loss: 0.258052
[Epoch 83; Iter    22/  209] train: loss: 0.0621612
[Epoch 83; Iter    52/  209] train: loss: 0.0568275
[Epoch 83; Iter    82/  209] train: loss: 0.0362522
[Epoch 83; Iter   112/  209] train: loss: 0.0685019
[Epoch 83; Iter   142/  209] train: loss: 0.1048670
[Epoch 83; Iter   172/  209] train: loss: 0.0992505
[Epoch 83; Iter   202/  209] train: loss: 0.0411013
[Epoch 83] ogbg-moltox21: 0.844409 val loss: 0.253857
[Epoch 83] ogbg-moltox21: 0.826647 test loss: 0.258925
[Epoch 84; Iter    23/  209] train: loss: 0.0721735
[Epoch 84; Iter    53/  209] train: loss: 0.0808993
[Epoch 84; Iter    83/  209] train: loss: 0.1203562
[Epoch 84; Iter   113/  209] train: loss: 0.1135019
[Epoch 84; Iter   143/  209] train: loss: 0.1264893
[Epoch 84; Iter   173/  209] train: loss: 0.0489809
[Epoch 84; Iter   203/  209] train: loss: 0.0695059
[Epoch 84] ogbg-moltox21: 0.841111 val loss: 0.271016
[Epoch 84] ogbg-moltox21: 0.833965 test loss: 0.253293
[Epoch 85; Iter    24/  209] train: loss: 0.0671370
[Epoch 85; Iter    54/  209] train: loss: 0.0498834
[Epoch 85; Iter    84/  209] train: loss: 0.0472933
[Epoch 85; Iter   114/  209] train: loss: 0.1126313
[Epoch 85; Iter   144/  209] train: loss: 0.1376140
[Epoch 85; Iter   174/  209] train: loss: 0.0328242
[Epoch 85; Iter   204/  209] train: loss: 0.0485804
[Epoch 85] ogbg-moltox21: 0.839474 val loss: 0.274429
[Epoch 85] ogbg-moltox21: 0.824427 test loss: 0.273077
[Epoch 86; Iter    25/  209] train: loss: 0.0506362
[Epoch 86; Iter    55/  209] train: loss: 0.0972105
[Epoch 86; Iter    85/  209] train: loss: 0.0590459
[Epoch 86; Iter   115/  209] train: loss: 0.0479077
[Epoch 86; Iter   145/  209] train: loss: 0.0856108
[Epoch 86; Iter   175/  209] train: loss: 0.0468252
[Epoch 86; Iter   205/  209] train: loss: 0.0914680
[Epoch 86] ogbg-moltox21: 0.844379 val loss: 0.277565
[Epoch 86] ogbg-moltox21: 0.828880 test loss: 0.273321
[Epoch 87; Iter    26/  209] train: loss: 0.0393876
[Epoch 87; Iter    56/  209] train: loss: 0.0458142
[Epoch 87; Iter    86/  209] train: loss: 0.0992670
[Epoch 87; Iter   116/  209] train: loss: 0.0313263
[Epoch 87; Iter   146/  209] train: loss: 0.0765176
[Epoch 87; Iter   176/  209] train: loss: 0.1006583
[Epoch 87; Iter   206/  209] train: loss: 0.0784364
[Epoch 87] ogbg-moltox21: 0.841274 val loss: 0.298527
[Epoch 87] ogbg-moltox21: 0.829638 test loss: 0.263039
[Epoch 88; Iter    27/  209] train: loss: 0.0697706
[Epoch 88; Iter    57/  209] train: loss: 0.0578047
[Epoch 88; Iter    87/  209] train: loss: 0.0515708
[Epoch 88; Iter   117/  209] train: loss: 0.0623312
[Epoch 88; Iter   147/  209] train: loss: 0.0833816
[Epoch 88; Iter   177/  209] train: loss: 0.0808011
[Epoch 88; Iter   207/  209] train: loss: 0.0888236
[Epoch 88] ogbg-moltox21: 0.843957 val loss: 0.286965
[Epoch 88] ogbg-moltox21: 0.841006 test loss: 0.261914
[Epoch 89; Iter    28/  209] train: loss: 0.0559490
[Epoch 89; Iter    58/  209] train: loss: 0.0404709
[Epoch 89; Iter    88/  209] train: loss: 0.0955748
[Epoch 89; Iter   118/  209] train: loss: 0.0626687
[Epoch 89; Iter   148/  209] train: loss: 0.0646153
[Epoch 89; Iter   178/  209] train: loss: 0.1189482
[Epoch 89; Iter   208/  209] train: loss: 0.0525724
[Epoch 89] ogbg-moltox21: 0.844842 val loss: 0.282448
[Epoch 89] ogbg-moltox21: 0.832204 test loss: 0.266891
[Epoch 90; Iter    29/  209] train: loss: 0.0462141
[Epoch 90; Iter    59/  209] train: loss: 0.0605087
[Epoch 90; Iter    89/  209] train: loss: 0.0488032
[Epoch 90; Iter   119/  209] train: loss: 0.0429388
[Epoch 90; Iter   149/  209] train: loss: 0.0410932
[Epoch 90; Iter   179/  209] train: loss: 0.0650083
[Epoch 90; Iter   209/  209] train: loss: 0.0672975
[Epoch 90] ogbg-moltox21: 0.840141 val loss: 0.286208
[Epoch 90] ogbg-moltox21: 0.836241 test loss: 0.261291
[Epoch 91; Iter    30/  209] train: loss: 0.0716755
[Epoch 91; Iter    60/  209] train: loss: 0.0679185
[Epoch 91; Iter    90/  209] train: loss: 0.0853976
[Epoch 91; Iter   120/  209] train: loss: 0.0490803
[Epoch 91; Iter   150/  209] train: loss: 0.0431087
[Epoch 91; Iter   180/  209] train: loss: 0.0505188
[Epoch 91] ogbg-moltox21: 0.841846 val loss: 0.302454
[Epoch 91] ogbg-moltox21: 0.831399 test loss: 0.267331
[Epoch 92; Iter     1/  209] train: loss: 0.0652887
[Epoch 92; Iter    31/  209] train: loss: 0.0463977
[Epoch 92; Iter    61/  209] train: loss: 0.0369661
[Epoch 92; Iter    91/  209] train: loss: 0.0572164
[Epoch 92; Iter   121/  209] train: loss: 0.0661211
[Epoch 92; Iter   151/  209] train: loss: 0.0633932
[Epoch 92; Iter   181/  209] train: loss: 0.0676457
[Epoch 92] ogbg-moltox21: 0.844286 val loss: 0.288630
[Epoch 92] ogbg-moltox21: 0.833152 test loss: 0.273351
[Epoch 93; Iter     2/  209] train: loss: 0.0639710
[Epoch 93; Iter    32/  209] train: loss: 0.0505726
[Epoch 93; Iter    62/  209] train: loss: 0.0704255
[Epoch 93; Iter    92/  209] train: loss: 0.0497675
[Epoch 93; Iter   122/  209] train: loss: 0.0718946
[Epoch 93; Iter   152/  209] train: loss: 0.0814526
[Epoch 93; Iter   182/  209] train: loss: 0.0308025
[Epoch 93] ogbg-moltox21: 0.836983 val loss: 0.307727
[Epoch 93] ogbg-moltox21: 0.827296 test loss: 0.283671
[Epoch 94; Iter     3/  209] train: loss: 0.0440504
[Epoch 94; Iter    33/  209] train: loss: 0.0718397
[Epoch 94; Iter    63/  209] train: loss: 0.0542446
[Epoch 94; Iter    93/  209] train: loss: 0.0266018
[Epoch 94; Iter   123/  209] train: loss: 0.0416744
[Epoch 94; Iter   153/  209] train: loss: 0.0757552
[Epoch 94; Iter   183/  209] train: loss: 0.0910276
[Epoch 94] ogbg-moltox21: 0.838850 val loss: 0.316578
[Epoch 94] ogbg-moltox21: 0.831115 test loss: 0.270476
[Epoch 95; Iter     4/  209] train: loss: 0.0251034
[Epoch 95; Iter    34/  209] train: loss: 0.0363159
[Epoch 95; Iter    64/  209] train: loss: 0.0655954
[Epoch 95; Iter    94/  209] train: loss: 0.0651036
[Epoch 95; Iter   124/  209] train: loss: 0.0558733
[Epoch 95; Iter   154/  209] train: loss: 0.0708640
[Epoch 95; Iter   184/  209] train: loss: 0.0569744
[Epoch 95] ogbg-moltox21: 0.840532 val loss: 0.306138
[Epoch 95] ogbg-moltox21: 0.832359 test loss: 0.276493
[Epoch 96; Iter     5/  209] train: loss: 0.0368383
[Epoch 96; Iter    35/  209] train: loss: 0.0299739
[Epoch 96; Iter    65/  209] train: loss: 0.0663363
[Epoch 96; Iter    95/  209] train: loss: 0.0356857
[Epoch 96; Iter   125/  209] train: loss: 0.0504486
[Epoch 96; Iter   155/  209] train: loss: 0.0443098
[Epoch 96; Iter   185/  209] train: loss: 0.0452046
[Epoch 96] ogbg-moltox21: 0.837972 val loss: 0.297365
[Epoch 96] ogbg-moltox21: 0.832058 test loss: 0.276108
[Epoch 97; Iter     6/  209] train: loss: 0.0503175
[Epoch 97; Iter    36/  209] train: loss: 0.0449308
[Epoch 97; Iter    66/  209] train: loss: 0.0514668
[Epoch 97; Iter    96/  209] train: loss: 0.0419650
[Epoch 97; Iter   126/  209] train: loss: 0.0332176
[Epoch 97; Iter   156/  209] train: loss: 0.0521283
[Epoch 97; Iter   186/  209] train: loss: 0.0339423
[Epoch 97] ogbg-moltox21: 0.835807 val loss: 0.300529
[Epoch 97] ogbg-moltox21: 0.830689 test loss: 0.277660
[Epoch 98; Iter     7/  209] train: loss: 0.0294724
[Epoch 98; Iter    37/  209] train: loss: 0.0475282
[Epoch 98; Iter    67/  209] train: loss: 0.0606010
[Epoch 98; Iter    97/  209] train: loss: 0.0789102
[Epoch 98; Iter   127/  209] train: loss: 0.0516603
[Epoch 98; Iter   157/  209] train: loss: 0.0386888
[Epoch 98; Iter   187/  209] train: loss: 0.0387066
[Epoch 98] ogbg-moltox21: 0.834504 val loss: 0.323891
[Epoch 98] ogbg-moltox21: 0.821992 test loss: 0.290075
[Epoch 99; Iter     8/  209] train: loss: 0.0312727
[Epoch 99; Iter    38/  209] train: loss: 0.0991535
[Epoch 99; Iter    68/  209] train: loss: 0.0473081
[Epoch 99; Iter    98/  209] train: loss: 0.0557983
[Epoch 82; Iter    51/  209] train: loss: 0.0962641
[Epoch 82; Iter    81/  209] train: loss: 0.0481617
[Epoch 82; Iter   111/  209] train: loss: 0.0362970
[Epoch 82; Iter   141/  209] train: loss: 0.0829606
[Epoch 82; Iter   171/  209] train: loss: 0.1004835
[Epoch 82; Iter   201/  209] train: loss: 0.0525587
[Epoch 82] ogbg-moltox21: 0.826505 val loss: 0.287494
[Epoch 82] ogbg-moltox21: 0.825172 test loss: 0.257191
[Epoch 83; Iter    22/  209] train: loss: 0.0794824
[Epoch 83; Iter    52/  209] train: loss: 0.0652951
[Epoch 83; Iter    82/  209] train: loss: 0.0644133
[Epoch 83; Iter   112/  209] train: loss: 0.0743546
[Epoch 83; Iter   142/  209] train: loss: 0.0544018
[Epoch 83; Iter   172/  209] train: loss: 0.0850203
[Epoch 83; Iter   202/  209] train: loss: 0.0512168
[Epoch 83] ogbg-moltox21: 0.829450 val loss: 0.292637
[Epoch 83] ogbg-moltox21: 0.834228 test loss: 0.255684
[Epoch 84; Iter    23/  209] train: loss: 0.0922221
[Epoch 84; Iter    53/  209] train: loss: 0.0833506
[Epoch 84; Iter    83/  209] train: loss: 0.1101290
[Epoch 84; Iter   113/  209] train: loss: 0.0518032
[Epoch 84; Iter   143/  209] train: loss: 0.0428428
[Epoch 84; Iter   173/  209] train: loss: 0.0557202
[Epoch 84; Iter   203/  209] train: loss: 0.0787797
[Epoch 84] ogbg-moltox21: 0.837068 val loss: 0.281908
[Epoch 84] ogbg-moltox21: 0.836640 test loss: 0.256838
[Epoch 85; Iter    24/  209] train: loss: 0.0567961
[Epoch 85; Iter    54/  209] train: loss: 0.0740586
[Epoch 85; Iter    84/  209] train: loss: 0.0756462
[Epoch 85; Iter   114/  209] train: loss: 0.0563489
[Epoch 85; Iter   144/  209] train: loss: 0.0767195
[Epoch 85; Iter   174/  209] train: loss: 0.0998787
[Epoch 85; Iter   204/  209] train: loss: 0.0443761
[Epoch 85] ogbg-moltox21: 0.831904 val loss: 0.290476
[Epoch 85] ogbg-moltox21: 0.830459 test loss: 0.260468
[Epoch 86; Iter    25/  209] train: loss: 0.0386377
[Epoch 86; Iter    55/  209] train: loss: 0.0757769
[Epoch 86; Iter    85/  209] train: loss: 0.0666774
[Epoch 86; Iter   115/  209] train: loss: 0.0501779
[Epoch 86; Iter   145/  209] train: loss: 0.0850347
[Epoch 86; Iter   175/  209] train: loss: 0.0806308
[Epoch 86; Iter   205/  209] train: loss: 0.0732209
[Epoch 86] ogbg-moltox21: 0.826612 val loss: 0.289828
[Epoch 86] ogbg-moltox21: 0.828872 test loss: 0.255671
[Epoch 87; Iter    26/  209] train: loss: 0.0446425
[Epoch 87; Iter    56/  209] train: loss: 0.0526119
[Epoch 87; Iter    86/  209] train: loss: 0.1102193
[Epoch 87; Iter   116/  209] train: loss: 0.0970955
[Epoch 87; Iter   146/  209] train: loss: 0.0531651
[Epoch 87; Iter   176/  209] train: loss: 0.0607850
[Epoch 87; Iter   206/  209] train: loss: 0.0758341
[Epoch 87] ogbg-moltox21: 0.837288 val loss: 0.285830
[Epoch 87] ogbg-moltox21: 0.828208 test loss: 0.272199
[Epoch 88; Iter    27/  209] train: loss: 0.0310377
[Epoch 88; Iter    57/  209] train: loss: 0.0745857
[Epoch 88; Iter    87/  209] train: loss: 0.0994665
[Epoch 88; Iter   117/  209] train: loss: 0.0492595
[Epoch 88; Iter   147/  209] train: loss: 0.0794942
[Epoch 88; Iter   177/  209] train: loss: 0.0476582
[Epoch 88; Iter   207/  209] train: loss: 0.0656288
[Epoch 88] ogbg-moltox21: 0.836117 val loss: 0.279375
[Epoch 88] ogbg-moltox21: 0.830886 test loss: 0.260874
[Epoch 89; Iter    28/  209] train: loss: 0.0463212
[Epoch 89; Iter    58/  209] train: loss: 0.0980930
[Epoch 89; Iter    88/  209] train: loss: 0.0721864
[Epoch 89; Iter   118/  209] train: loss: 0.0559560
[Epoch 89; Iter   148/  209] train: loss: 0.0581556
[Epoch 89; Iter   178/  209] train: loss: 0.0579451
[Epoch 89; Iter   208/  209] train: loss: 0.1221167
[Epoch 89] ogbg-moltox21: 0.829653 val loss: 0.291069
[Epoch 89] ogbg-moltox21: 0.819211 test loss: 0.272668
[Epoch 90; Iter    29/  209] train: loss: 0.0618266
[Epoch 90; Iter    59/  209] train: loss: 0.0735204
[Epoch 90; Iter    89/  209] train: loss: 0.0734695
[Epoch 90; Iter   119/  209] train: loss: 0.0560073
[Epoch 90; Iter   149/  209] train: loss: 0.0760387
[Epoch 90; Iter   179/  209] train: loss: 0.0689514
[Epoch 90; Iter   209/  209] train: loss: 0.0606579
[Epoch 90] ogbg-moltox21: 0.830859 val loss: 0.291332
[Epoch 90] ogbg-moltox21: 0.812784 test loss: 0.278297
[Epoch 91; Iter    30/  209] train: loss: 0.0947277
[Epoch 91; Iter    60/  209] train: loss: 0.0609642
[Epoch 91; Iter    90/  209] train: loss: 0.0491567
[Epoch 91; Iter   120/  209] train: loss: 0.0769710
[Epoch 91; Iter   150/  209] train: loss: 0.0587826
[Epoch 91; Iter   180/  209] train: loss: 0.1138449
[Epoch 91] ogbg-moltox21: 0.833631 val loss: 0.285978
[Epoch 91] ogbg-moltox21: 0.824450 test loss: 0.274826
[Epoch 92; Iter     1/  209] train: loss: 0.0663266
[Epoch 92; Iter    31/  209] train: loss: 0.0727309
[Epoch 92; Iter    61/  209] train: loss: 0.0647461
[Epoch 92; Iter    91/  209] train: loss: 0.0663561
[Epoch 92; Iter   121/  209] train: loss: 0.0586782
[Epoch 92; Iter   151/  209] train: loss: 0.0634641
[Epoch 92; Iter   181/  209] train: loss: 0.0433830
[Epoch 92] ogbg-moltox21: 0.830011 val loss: 0.292811
[Epoch 92] ogbg-moltox21: 0.821150 test loss: 0.281372
[Epoch 93; Iter     2/  209] train: loss: 0.0711994
[Epoch 93; Iter    32/  209] train: loss: 0.0841632
[Epoch 93; Iter    62/  209] train: loss: 0.0450001
[Epoch 93; Iter    92/  209] train: loss: 0.0537425
[Epoch 93; Iter   122/  209] train: loss: 0.0624882
[Epoch 93; Iter   152/  209] train: loss: 0.0727668
[Epoch 93; Iter   182/  209] train: loss: 0.0794790
[Epoch 93] ogbg-moltox21: 0.832405 val loss: 0.289076
[Epoch 93] ogbg-moltox21: 0.820992 test loss: 0.267795
[Epoch 94; Iter     3/  209] train: loss: 0.0502434
[Epoch 94; Iter    33/  209] train: loss: 0.0645829
[Epoch 94; Iter    63/  209] train: loss: 0.0440236
[Epoch 94; Iter    93/  209] train: loss: 0.0578695
[Epoch 94; Iter   123/  209] train: loss: 0.0535770
[Epoch 94; Iter   153/  209] train: loss: 0.0649634
[Epoch 94; Iter   183/  209] train: loss: 0.0370806
[Epoch 94] ogbg-moltox21: 0.830634 val loss: 0.295120
[Epoch 94] ogbg-moltox21: 0.821124 test loss: 0.269866
[Epoch 95; Iter     4/  209] train: loss: 0.0833134
[Epoch 95; Iter    34/  209] train: loss: 0.0736604
[Epoch 95; Iter    64/  209] train: loss: 0.0827601
[Epoch 95; Iter    94/  209] train: loss: 0.0896610
[Epoch 95; Iter   124/  209] train: loss: 0.0501759
[Epoch 95; Iter   154/  209] train: loss: 0.0543170
[Epoch 95; Iter   184/  209] train: loss: 0.0502234
[Epoch 95] ogbg-moltox21: 0.832024 val loss: 0.294946
[Epoch 95] ogbg-moltox21: 0.821062 test loss: 0.273022
[Epoch 96; Iter     5/  209] train: loss: 0.0494057
[Epoch 96; Iter    35/  209] train: loss: 0.0468431
[Epoch 96; Iter    65/  209] train: loss: 0.0701245
[Epoch 96; Iter    95/  209] train: loss: 0.0399551
[Epoch 96; Iter   125/  209] train: loss: 0.0637815
[Epoch 96; Iter   155/  209] train: loss: 0.0496294
[Epoch 96; Iter   185/  209] train: loss: 0.0559882
[Epoch 96] ogbg-moltox21: 0.824640 val loss: 0.303369
[Epoch 96] ogbg-moltox21: 0.807154 test loss: 0.285568
[Epoch 97; Iter     6/  209] train: loss: 0.0601931
[Epoch 97; Iter    36/  209] train: loss: 0.0450520
[Epoch 97; Iter    66/  209] train: loss: 0.0518033
[Epoch 97; Iter    96/  209] train: loss: 0.0478359
[Epoch 97; Iter   126/  209] train: loss: 0.0714070
[Epoch 97; Iter   156/  209] train: loss: 0.0451861
[Epoch 97; Iter   186/  209] train: loss: 0.0758198
[Epoch 97] ogbg-moltox21: 0.832054 val loss: 0.299785
[Epoch 97] ogbg-moltox21: 0.815987 test loss: 0.287841
[Epoch 98; Iter     7/  209] train: loss: 0.0437878
[Epoch 98; Iter    37/  209] train: loss: 0.0481808
[Epoch 98; Iter    67/  209] train: loss: 0.0431643
[Epoch 98; Iter    97/  209] train: loss: 0.0490344
[Epoch 98; Iter   127/  209] train: loss: 0.0225083
[Epoch 98; Iter   157/  209] train: loss: 0.0877778
[Epoch 98; Iter   187/  209] train: loss: 0.0523925
[Epoch 98] ogbg-moltox21: 0.826819 val loss: 0.306559
[Epoch 98] ogbg-moltox21: 0.817454 test loss: 0.284088
[Epoch 99; Iter     8/  209] train: loss: 0.0265785
[Epoch 99; Iter    38/  209] train: loss: 0.0361155
[Epoch 99; Iter    68/  209] train: loss: 0.0799782
[Epoch 99; Iter    98/  209] train: loss: 0.0757077
[Epoch 82; Iter    51/  209] train: loss: 0.1114031
[Epoch 82; Iter    81/  209] train: loss: 0.0832744
[Epoch 82; Iter   111/  209] train: loss: 0.0676014
[Epoch 82; Iter   141/  209] train: loss: 0.0881437
[Epoch 82; Iter   171/  209] train: loss: 0.1270090
[Epoch 82; Iter   201/  209] train: loss: 0.1168301
[Epoch 82] ogbg-moltox21: 0.833504 val loss: 0.263646
[Epoch 82] ogbg-moltox21: 0.812773 test loss: 0.238333
[Epoch 83; Iter    22/  209] train: loss: 0.1096193
[Epoch 83; Iter    52/  209] train: loss: 0.0690152
[Epoch 83; Iter    82/  209] train: loss: 0.1163844
[Epoch 83; Iter   112/  209] train: loss: 0.1379241
[Epoch 83; Iter   142/  209] train: loss: 0.0600983
[Epoch 83; Iter   172/  209] train: loss: 0.0427831
[Epoch 83; Iter   202/  209] train: loss: 0.0566041
[Epoch 83] ogbg-moltox21: 0.839477 val loss: 0.255956
[Epoch 83] ogbg-moltox21: 0.810963 test loss: 0.239393
[Epoch 84; Iter    23/  209] train: loss: 0.0554655
[Epoch 84; Iter    53/  209] train: loss: 0.0670321
[Epoch 84; Iter    83/  209] train: loss: 0.1235733
[Epoch 84; Iter   113/  209] train: loss: 0.0436760
[Epoch 84; Iter   143/  209] train: loss: 0.0392905
[Epoch 84; Iter   173/  209] train: loss: 0.0849934
[Epoch 84; Iter   203/  209] train: loss: 0.1705229
[Epoch 84] ogbg-moltox21: 0.838653 val loss: 0.261673
[Epoch 84] ogbg-moltox21: 0.816875 test loss: 0.233473
[Epoch 85; Iter    24/  209] train: loss: 0.0793045
[Epoch 85; Iter    54/  209] train: loss: 0.1394539
[Epoch 85; Iter    84/  209] train: loss: 0.0526123
[Epoch 85; Iter   114/  209] train: loss: 0.1000198
[Epoch 85; Iter   144/  209] train: loss: 0.0540500
[Epoch 85; Iter   174/  209] train: loss: 0.0790716
[Epoch 85; Iter   204/  209] train: loss: 0.0952111
[Epoch 85] ogbg-moltox21: 0.828369 val loss: 0.267073
[Epoch 85] ogbg-moltox21: 0.811021 test loss: 0.237732
[Epoch 86; Iter    25/  209] train: loss: 0.0973004
[Epoch 86; Iter    55/  209] train: loss: 0.0671329
[Epoch 86; Iter    85/  209] train: loss: 0.0591469
[Epoch 86; Iter   115/  209] train: loss: 0.1387823
[Epoch 86; Iter   145/  209] train: loss: 0.0762139
[Epoch 86; Iter   175/  209] train: loss: 0.0786270
[Epoch 86; Iter   205/  209] train: loss: 0.0824886
[Epoch 86] ogbg-moltox21: 0.842285 val loss: 0.258532
[Epoch 86] ogbg-moltox21: 0.816570 test loss: 0.236115
[Epoch 87; Iter    26/  209] train: loss: 0.0640559
[Epoch 87; Iter    56/  209] train: loss: 0.0506180
[Epoch 87; Iter    86/  209] train: loss: 0.0942325
[Epoch 87; Iter   116/  209] train: loss: 0.0461580
[Epoch 87; Iter   146/  209] train: loss: 0.0814446
[Epoch 87; Iter   176/  209] train: loss: 0.0730072
[Epoch 87; Iter   206/  209] train: loss: 0.0677232
[Epoch 87] ogbg-moltox21: 0.832416 val loss: 0.274223
[Epoch 87] ogbg-moltox21: 0.810175 test loss: 0.248271
[Epoch 88; Iter    27/  209] train: loss: 0.0603679
[Epoch 88; Iter    57/  209] train: loss: 0.0601604
[Epoch 88; Iter    87/  209] train: loss: 0.0701778
[Epoch 88; Iter   117/  209] train: loss: 0.0653590
[Epoch 88; Iter   147/  209] train: loss: 0.0662332
[Epoch 88; Iter   177/  209] train: loss: 0.0672213
[Epoch 88; Iter   207/  209] train: loss: 0.0774770
[Epoch 88] ogbg-moltox21: 0.834931 val loss: 0.267895
[Epoch 88] ogbg-moltox21: 0.821401 test loss: 0.239934
[Epoch 89; Iter    28/  209] train: loss: 0.0595847
[Epoch 89; Iter    58/  209] train: loss: 0.0529454
[Epoch 89; Iter    88/  209] train: loss: 0.0594260
[Epoch 89; Iter   118/  209] train: loss: 0.0573992
[Epoch 89; Iter   148/  209] train: loss: 0.0522185
[Epoch 89; Iter   178/  209] train: loss: 0.1093990
[Epoch 89; Iter   208/  209] train: loss: 0.0855748
[Epoch 89] ogbg-moltox21: 0.826520 val loss: 0.278260
[Epoch 89] ogbg-moltox21: 0.810780 test loss: 0.248145
[Epoch 90; Iter    29/  209] train: loss: 0.0444273
[Epoch 90; Iter    59/  209] train: loss: 0.0848766
[Epoch 90; Iter    89/  209] train: loss: 0.0628080
[Epoch 90; Iter   119/  209] train: loss: 0.0734113
[Epoch 90; Iter   149/  209] train: loss: 0.0599790
[Epoch 90; Iter   179/  209] train: loss: 0.0759739
[Epoch 90; Iter   209/  209] train: loss: 0.0560233
[Epoch 90] ogbg-moltox21: 0.833412 val loss: 0.268209
[Epoch 90] ogbg-moltox21: 0.819186 test loss: 0.240507
[Epoch 91; Iter    30/  209] train: loss: 0.0569914
[Epoch 91; Iter    60/  209] train: loss: 0.0681578
[Epoch 91; Iter    90/  209] train: loss: 0.0544981
[Epoch 91; Iter   120/  209] train: loss: 0.0560520
[Epoch 91; Iter   150/  209] train: loss: 0.0615824
[Epoch 91; Iter   180/  209] train: loss: 0.1104800
[Epoch 91] ogbg-moltox21: 0.835333 val loss: 0.269820
[Epoch 91] ogbg-moltox21: 0.817364 test loss: 0.244620
[Epoch 92; Iter     1/  209] train: loss: 0.0860037
[Epoch 92; Iter    31/  209] train: loss: 0.0766698
[Epoch 92; Iter    61/  209] train: loss: 0.0532454
[Epoch 92; Iter    91/  209] train: loss: 0.0590091
[Epoch 92; Iter   121/  209] train: loss: 0.0739265
[Epoch 92; Iter   151/  209] train: loss: 0.0466534
[Epoch 92; Iter   181/  209] train: loss: 0.0996234
[Epoch 92] ogbg-moltox21: 0.827383 val loss: 0.281256
[Epoch 92] ogbg-moltox21: 0.809735 test loss: 0.248841
[Epoch 93; Iter     2/  209] train: loss: 0.0971960
[Epoch 93; Iter    32/  209] train: loss: 0.0633245
[Epoch 93; Iter    62/  209] train: loss: 0.0464335
[Epoch 93; Iter    92/  209] train: loss: 0.0895843
[Epoch 93; Iter   122/  209] train: loss: 0.0467439
[Epoch 93; Iter   152/  209] train: loss: 0.0638156
[Epoch 93; Iter   182/  209] train: loss: 0.0519814
[Epoch 93] ogbg-moltox21: 0.830424 val loss: 0.280311
[Epoch 93] ogbg-moltox21: 0.815067 test loss: 0.246619
[Epoch 94; Iter     3/  209] train: loss: 0.0694120
[Epoch 94; Iter    33/  209] train: loss: 0.0414293
[Epoch 94; Iter    63/  209] train: loss: 0.1298674
[Epoch 94; Iter    93/  209] train: loss: 0.0559569
[Epoch 94; Iter   123/  209] train: loss: 0.0645331
[Epoch 94; Iter   153/  209] train: loss: 0.0402350
[Epoch 94; Iter   183/  209] train: loss: 0.0789997
[Epoch 94] ogbg-moltox21: 0.832698 val loss: 0.283198
[Epoch 94] ogbg-moltox21: 0.810861 test loss: 0.252312
[Epoch 95; Iter     4/  209] train: loss: 0.0459352
[Epoch 95; Iter    34/  209] train: loss: 0.0639344
[Epoch 95; Iter    64/  209] train: loss: 0.0521788
[Epoch 95; Iter    94/  209] train: loss: 0.0589586
[Epoch 95; Iter   124/  209] train: loss: 0.0490724
[Epoch 95; Iter   154/  209] train: loss: 0.0477000
[Epoch 95; Iter   184/  209] train: loss: 0.0767147
[Epoch 95] ogbg-moltox21: 0.834195 val loss: 0.277288
[Epoch 95] ogbg-moltox21: 0.810522 test loss: 0.252801
[Epoch 96; Iter     5/  209] train: loss: 0.0642854
[Epoch 96; Iter    35/  209] train: loss: 0.0404947
[Epoch 96; Iter    65/  209] train: loss: 0.0975820
[Epoch 96; Iter    95/  209] train: loss: 0.0572449
[Epoch 96; Iter   125/  209] train: loss: 0.0529353
[Epoch 96; Iter   155/  209] train: loss: 0.1059640
[Epoch 96; Iter   185/  209] train: loss: 0.0945443
[Epoch 96] ogbg-moltox21: 0.832509 val loss: 0.278883
[Epoch 96] ogbg-moltox21: 0.810293 test loss: 0.254299
[Epoch 97; Iter     6/  209] train: loss: 0.0920894
[Epoch 97; Iter    36/  209] train: loss: 0.0876326
[Epoch 97; Iter    66/  209] train: loss: 0.0977229
[Epoch 97; Iter    96/  209] train: loss: 0.0679893
[Epoch 97; Iter   126/  209] train: loss: 0.0659112
[Epoch 97; Iter   156/  209] train: loss: 0.0771148
[Epoch 97; Iter   186/  209] train: loss: 0.0751195
[Epoch 97] ogbg-moltox21: 0.832849 val loss: 0.280895
[Epoch 97] ogbg-moltox21: 0.811501 test loss: 0.252459
[Epoch 98; Iter     7/  209] train: loss: 0.0447497
[Epoch 98; Iter    37/  209] train: loss: 0.0825236
[Epoch 98; Iter    67/  209] train: loss: 0.0325698
[Epoch 98; Iter    97/  209] train: loss: 0.0611203
[Epoch 98; Iter   127/  209] train: loss: 0.0378962
[Epoch 98; Iter   157/  209] train: loss: 0.0970416
[Epoch 98; Iter   187/  209] train: loss: 0.0637566
[Epoch 98] ogbg-moltox21: 0.827227 val loss: 0.284147
[Epoch 98] ogbg-moltox21: 0.810551 test loss: 0.255248
[Epoch 99; Iter     8/  209] train: loss: 0.0484856
[Epoch 99; Iter    38/  209] train: loss: 0.0600868
[Epoch 99; Iter    68/  209] train: loss: 0.0428114
[Epoch 99; Iter    98/  209] train: loss: 0.0360626
[Epoch 90] ogbg-moltox21: 0.824714 val loss: 0.296160
[Epoch 90] ogbg-moltox21: 0.834588 test loss: 0.238792
[Epoch 91; Iter    30/  183] train: loss: 0.0964833
[Epoch 91; Iter    60/  183] train: loss: 0.0938800
[Epoch 91; Iter    90/  183] train: loss: 0.0700441
[Epoch 91; Iter   120/  183] train: loss: 0.0372721
[Epoch 91; Iter   150/  183] train: loss: 0.0613163
[Epoch 91; Iter   180/  183] train: loss: 0.0779913
[Epoch 91] ogbg-moltox21: 0.822122 val loss: 0.237819
[Epoch 91] ogbg-moltox21: 0.832054 test loss: 0.232045
[Epoch 92; Iter    27/  183] train: loss: 0.1010657
[Epoch 92; Iter    57/  183] train: loss: 0.1295095
[Epoch 92; Iter    87/  183] train: loss: 0.0821973
[Epoch 92; Iter   117/  183] train: loss: 0.0698161
[Epoch 92; Iter   147/  183] train: loss: 0.0761529
[Epoch 92; Iter   177/  183] train: loss: 0.0816670
[Epoch 92] ogbg-moltox21: 0.820174 val loss: 0.246367
[Epoch 92] ogbg-moltox21: 0.827328 test loss: 0.243443
[Epoch 93; Iter    24/  183] train: loss: 0.1330990
[Epoch 93; Iter    54/  183] train: loss: 0.1145082
[Epoch 93; Iter    84/  183] train: loss: 0.0873988
[Epoch 93; Iter   114/  183] train: loss: 0.0947685
[Epoch 93; Iter   144/  183] train: loss: 0.0735718
[Epoch 93; Iter   174/  183] train: loss: 0.1443256
[Epoch 93] ogbg-moltox21: 0.821893 val loss: 0.257343
[Epoch 93] ogbg-moltox21: 0.830801 test loss: 0.243606
[Epoch 94; Iter    21/  183] train: loss: 0.0858913
[Epoch 94; Iter    51/  183] train: loss: 0.0706252
[Epoch 94; Iter    81/  183] train: loss: 0.0714649
[Epoch 94; Iter   111/  183] train: loss: 0.0783845
[Epoch 94; Iter   141/  183] train: loss: 0.0557439
[Epoch 94; Iter   171/  183] train: loss: 0.1445563
[Epoch 94] ogbg-moltox21: 0.823277 val loss: 0.272388
[Epoch 94] ogbg-moltox21: 0.827004 test loss: 0.248711
[Epoch 95; Iter    18/  183] train: loss: 0.1101440
[Epoch 95; Iter    48/  183] train: loss: 0.0832909
[Epoch 95; Iter    78/  183] train: loss: 0.0768439
[Epoch 95; Iter   108/  183] train: loss: 0.0930469
[Epoch 95; Iter   138/  183] train: loss: 0.0852848
[Epoch 95; Iter   168/  183] train: loss: 0.0571547
[Epoch 95] ogbg-moltox21: 0.817819 val loss: 0.347509
[Epoch 95] ogbg-moltox21: 0.826650 test loss: 0.263988
[Epoch 96; Iter    15/  183] train: loss: 0.0667343
[Epoch 96; Iter    45/  183] train: loss: 0.0673708
[Epoch 96; Iter    75/  183] train: loss: 0.0707224
[Epoch 96; Iter   105/  183] train: loss: 0.0536124
[Epoch 96; Iter   135/  183] train: loss: 0.0846869
[Epoch 96; Iter   165/  183] train: loss: 0.1027707
[Epoch 96] ogbg-moltox21: 0.826581 val loss: 0.339915
[Epoch 96] ogbg-moltox21: 0.828594 test loss: 0.271741
[Epoch 97; Iter    12/  183] train: loss: 0.0661646
[Epoch 97; Iter    42/  183] train: loss: 0.0468134
[Epoch 97; Iter    72/  183] train: loss: 0.0741252
[Epoch 97; Iter   102/  183] train: loss: 0.1095320
[Epoch 97; Iter   132/  183] train: loss: 0.0893993
[Epoch 97; Iter   162/  183] train: loss: 0.0820472
[Epoch 97] ogbg-moltox21: 0.814419 val loss: 0.278753
[Epoch 97] ogbg-moltox21: 0.820962 test loss: 0.252126
[Epoch 98; Iter     9/  183] train: loss: 0.0355645
[Epoch 98; Iter    39/  183] train: loss: 0.1062939
[Epoch 98; Iter    69/  183] train: loss: 0.0932098
[Epoch 98; Iter    99/  183] train: loss: 0.0497761
[Epoch 98; Iter   129/  183] train: loss: 0.1104927
[Epoch 98; Iter   159/  183] train: loss: 0.0852411
[Epoch 98] ogbg-moltox21: 0.814145 val loss: 0.256359
[Epoch 98] ogbg-moltox21: 0.821784 test loss: 0.253270
[Epoch 99; Iter     6/  183] train: loss: 0.0733359
[Epoch 99; Iter    36/  183] train: loss: 0.0869347
[Epoch 99; Iter    66/  183] train: loss: 0.0951797
[Epoch 99; Iter    96/  183] train: loss: 0.0733229
[Epoch 99; Iter   126/  183] train: loss: 0.0519478
[Epoch 99; Iter   156/  183] train: loss: 0.1419564
[Epoch 99] ogbg-moltox21: 0.823280 val loss: 0.252812
[Epoch 99] ogbg-moltox21: 0.830034 test loss: 0.252560
[Epoch 100; Iter     3/  183] train: loss: 0.0481746
[Epoch 100; Iter    33/  183] train: loss: 0.0673986
[Epoch 100; Iter    63/  183] train: loss: 0.0447644
[Epoch 100; Iter    93/  183] train: loss: 0.0499185
[Epoch 100; Iter   123/  183] train: loss: 0.0945130
[Epoch 100; Iter   153/  183] train: loss: 0.0896893
[Epoch 100; Iter   183/  183] train: loss: 0.1186881
[Epoch 100] ogbg-moltox21: 0.822792 val loss: 0.313367
[Epoch 100] ogbg-moltox21: 0.829807 test loss: 0.254355
[Epoch 101; Iter    30/  183] train: loss: 0.0444913
[Epoch 101; Iter    60/  183] train: loss: 0.0860637
[Epoch 101; Iter    90/  183] train: loss: 0.0399201
[Epoch 101; Iter   120/  183] train: loss: 0.0837862
[Epoch 101; Iter   150/  183] train: loss: 0.0950158
[Epoch 101; Iter   180/  183] train: loss: 0.0640110
[Epoch 101] ogbg-moltox21: 0.816966 val loss: 0.270030
[Epoch 101] ogbg-moltox21: 0.828023 test loss: 0.253630
[Epoch 102; Iter    27/  183] train: loss: 0.0528490
[Epoch 102; Iter    57/  183] train: loss: 0.0974862
[Epoch 102; Iter    87/  183] train: loss: 0.0590156
[Epoch 102; Iter   117/  183] train: loss: 0.0918895
[Epoch 102; Iter   147/  183] train: loss: 0.0495554
[Epoch 102; Iter   177/  183] train: loss: 0.0938269
[Epoch 102] ogbg-moltox21: 0.821856 val loss: 0.303901
[Epoch 102] ogbg-moltox21: 0.830677 test loss: 0.253965
[Epoch 103; Iter    24/  183] train: loss: 0.0559769
[Epoch 103; Iter    54/  183] train: loss: 0.1138606
[Epoch 103; Iter    84/  183] train: loss: 0.0469723
[Epoch 103; Iter   114/  183] train: loss: 0.0851004
[Epoch 103; Iter   144/  183] train: loss: 0.0503698
[Epoch 103; Iter   174/  183] train: loss: 0.1053499
[Epoch 103] ogbg-moltox21: 0.817542 val loss: 0.295917
[Epoch 103] ogbg-moltox21: 0.827143 test loss: 0.263578
[Epoch 104; Iter    21/  183] train: loss: 0.0609637
[Epoch 104; Iter    51/  183] train: loss: 0.0405362
[Epoch 104; Iter    81/  183] train: loss: 0.0936382
[Epoch 104; Iter   111/  183] train: loss: 0.0538479
[Epoch 104; Iter   141/  183] train: loss: 0.0494050
[Epoch 104; Iter   171/  183] train: loss: 0.0746676
[Epoch 104] ogbg-moltox21: 0.819739 val loss: 0.277676
[Epoch 104] ogbg-moltox21: 0.826286 test loss: 0.262182
[Epoch 105; Iter    18/  183] train: loss: 0.0616422
[Epoch 105; Iter    48/  183] train: loss: 0.0495724
[Epoch 105; Iter    78/  183] train: loss: 0.0972629
[Epoch 105; Iter   108/  183] train: loss: 0.2199934
[Epoch 105; Iter   138/  183] train: loss: 0.0795308
[Epoch 105; Iter   168/  183] train: loss: 0.0543384
[Epoch 105] ogbg-moltox21: 0.818801 val loss: 0.276783
[Epoch 105] ogbg-moltox21: 0.826570 test loss: 0.259907
[Epoch 106; Iter    15/  183] train: loss: 0.0993852
[Epoch 106; Iter    45/  183] train: loss: 0.0621913
[Epoch 106; Iter    75/  183] train: loss: 0.1290438
[Epoch 106; Iter   105/  183] train: loss: 0.0813324
[Epoch 106; Iter   135/  183] train: loss: 0.0608279
[Epoch 106; Iter   165/  183] train: loss: 0.0560828
[Epoch 106] ogbg-moltox21: 0.816509 val loss: 0.305798
[Epoch 106] ogbg-moltox21: 0.824058 test loss: 0.267197
[Epoch 107; Iter    12/  183] train: loss: 0.1623080
[Epoch 107; Iter    42/  183] train: loss: 0.0462847
[Epoch 107; Iter    72/  183] train: loss: 0.0787515
[Epoch 107; Iter   102/  183] train: loss: 0.0608832
[Epoch 107; Iter   132/  183] train: loss: 0.0523583
[Epoch 107; Iter   162/  183] train: loss: 0.0584949
[Epoch 107] ogbg-moltox21: 0.818583 val loss: 0.306330
[Epoch 107] ogbg-moltox21: 0.825007 test loss: 0.264971
[Epoch 108; Iter     9/  183] train: loss: 0.0838694
[Epoch 108; Iter    39/  183] train: loss: 0.0412429
[Epoch 108; Iter    69/  183] train: loss: 0.0512323
[Epoch 108; Iter    99/  183] train: loss: 0.0659491
[Epoch 108; Iter   129/  183] train: loss: 0.0581733
[Epoch 108; Iter   159/  183] train: loss: 0.0551048
[Epoch 108] ogbg-moltox21: 0.818278 val loss: 0.292179
[Epoch 108] ogbg-moltox21: 0.828086 test loss: 0.268198
[Epoch 109; Iter     6/  183] train: loss: 0.0487589
[Epoch 109; Iter    36/  183] train: loss: 0.0688812
[Epoch 109; Iter    66/  183] train: loss: 0.1116636
[Epoch 109; Iter    96/  183] train: loss: 0.1398900
[Epoch 109; Iter   126/  183] train: loss: 0.0761907
[Epoch 109; Iter   156/  183] train: loss: 0.0550874
[Epoch 109] ogbg-moltox21: 0.818702 val loss: 0.287295
[Epoch 90] ogbg-moltox21: 0.818066 val loss: 0.250146
[Epoch 90] ogbg-moltox21: 0.819460 test loss: 0.261721
[Epoch 91; Iter    30/  183] train: loss: 0.0611719
[Epoch 91; Iter    60/  183] train: loss: 0.1053911
[Epoch 91; Iter    90/  183] train: loss: 0.0957414
[Epoch 91; Iter   120/  183] train: loss: 0.0523499
[Epoch 91; Iter   150/  183] train: loss: 0.0360246
[Epoch 91; Iter   180/  183] train: loss: 0.0636826
[Epoch 91] ogbg-moltox21: 0.809741 val loss: 0.263164
[Epoch 91] ogbg-moltox21: 0.814886 test loss: 0.266096
[Epoch 92; Iter    27/  183] train: loss: 0.0782444
[Epoch 92; Iter    57/  183] train: loss: 0.0563533
[Epoch 92; Iter    87/  183] train: loss: 0.0487253
[Epoch 92; Iter   117/  183] train: loss: 0.0423138
[Epoch 92; Iter   147/  183] train: loss: 0.0542419
[Epoch 92; Iter   177/  183] train: loss: 0.0641263
[Epoch 92] ogbg-moltox21: 0.815204 val loss: 0.260357
[Epoch 92] ogbg-moltox21: 0.819977 test loss: 0.262078
[Epoch 93; Iter    24/  183] train: loss: 0.0445316
[Epoch 93; Iter    54/  183] train: loss: 0.0635599
[Epoch 93; Iter    84/  183] train: loss: 0.0488146
[Epoch 93; Iter   114/  183] train: loss: 0.0814466
[Epoch 93; Iter   144/  183] train: loss: 0.0747417
[Epoch 93; Iter   174/  183] train: loss: 0.0902494
[Epoch 93] ogbg-moltox21: 0.813127 val loss: 0.258286
[Epoch 93] ogbg-moltox21: 0.813063 test loss: 0.269186
[Epoch 94; Iter    21/  183] train: loss: 0.0460206
[Epoch 94; Iter    51/  183] train: loss: 0.0262425
[Epoch 94; Iter    81/  183] train: loss: 0.0601291
[Epoch 94; Iter   111/  183] train: loss: 0.0384144
[Epoch 94; Iter   141/  183] train: loss: 0.0350561
[Epoch 94; Iter   171/  183] train: loss: 0.0352710
[Epoch 94] ogbg-moltox21: 0.815398 val loss: 0.259478
[Epoch 94] ogbg-moltox21: 0.814872 test loss: 0.269137
[Epoch 95; Iter    18/  183] train: loss: 0.0857508
[Epoch 95; Iter    48/  183] train: loss: 0.0714854
[Epoch 95; Iter    78/  183] train: loss: 0.0626509
[Epoch 95; Iter   108/  183] train: loss: 0.0925771
[Epoch 95; Iter   138/  183] train: loss: 0.0903277
[Epoch 95; Iter   168/  183] train: loss: 0.1012175
[Epoch 95] ogbg-moltox21: 0.815500 val loss: 0.268666
[Epoch 95] ogbg-moltox21: 0.817141 test loss: 0.268586
[Epoch 96; Iter    15/  183] train: loss: 0.0419357
[Epoch 96; Iter    45/  183] train: loss: 0.0593968
[Epoch 96; Iter    75/  183] train: loss: 0.0330481
[Epoch 96; Iter   105/  183] train: loss: 0.0394466
[Epoch 96; Iter   135/  183] train: loss: 0.0519525
[Epoch 96; Iter   165/  183] train: loss: 0.0575480
[Epoch 96] ogbg-moltox21: 0.818068 val loss: 0.303800
[Epoch 96] ogbg-moltox21: 0.813870 test loss: 0.285842
[Epoch 97; Iter    12/  183] train: loss: 0.0673327
[Epoch 97; Iter    42/  183] train: loss: 0.0481892
[Epoch 97; Iter    72/  183] train: loss: 0.0627673
[Epoch 97; Iter   102/  183] train: loss: 0.0507195
[Epoch 97; Iter   132/  183] train: loss: 0.0341655
[Epoch 97; Iter   162/  183] train: loss: 0.0596898
[Epoch 97] ogbg-moltox21: 0.814071 val loss: 0.268700
[Epoch 97] ogbg-moltox21: 0.817138 test loss: 0.275711
[Epoch 98; Iter     9/  183] train: loss: 0.0406081
[Epoch 98; Iter    39/  183] train: loss: 0.0257005
[Epoch 98; Iter    69/  183] train: loss: 0.0844087
[Epoch 98; Iter    99/  183] train: loss: 0.0746293
[Epoch 98; Iter   129/  183] train: loss: 0.0908125
[Epoch 98; Iter   159/  183] train: loss: 0.0455235
[Epoch 98] ogbg-moltox21: 0.812651 val loss: 0.261816
[Epoch 98] ogbg-moltox21: 0.808565 test loss: 0.281373
[Epoch 99; Iter     6/  183] train: loss: 0.0781920
[Epoch 99; Iter    36/  183] train: loss: 0.0956898
[Epoch 99; Iter    66/  183] train: loss: 0.0455175
[Epoch 99; Iter    96/  183] train: loss: 0.0982180
[Epoch 99; Iter   126/  183] train: loss: 0.0537049
[Epoch 99; Iter   156/  183] train: loss: 0.0762250
[Epoch 99] ogbg-moltox21: 0.812067 val loss: 0.263107
[Epoch 99] ogbg-moltox21: 0.808948 test loss: 0.282855
[Epoch 100; Iter     3/  183] train: loss: 0.0539592
[Epoch 100; Iter    33/  183] train: loss: 0.0825384
[Epoch 100; Iter    63/  183] train: loss: 0.0335300
[Epoch 100; Iter    93/  183] train: loss: 0.0313340
[Epoch 100; Iter   123/  183] train: loss: 0.0632511
[Epoch 100; Iter   153/  183] train: loss: 0.0667241
[Epoch 100; Iter   183/  183] train: loss: 0.0849680
[Epoch 100] ogbg-moltox21: 0.815346 val loss: 0.275277
[Epoch 100] ogbg-moltox21: 0.814979 test loss: 0.280294
[Epoch 101; Iter    30/  183] train: loss: 0.0414586
[Epoch 101; Iter    60/  183] train: loss: 0.0562482
[Epoch 101; Iter    90/  183] train: loss: 0.0496279
[Epoch 101; Iter   120/  183] train: loss: 0.0406378
[Epoch 101; Iter   150/  183] train: loss: 0.0366303
[Epoch 101; Iter   180/  183] train: loss: 0.0429168
[Epoch 101] ogbg-moltox21: 0.814181 val loss: 0.264965
[Epoch 101] ogbg-moltox21: 0.813289 test loss: 0.281900
[Epoch 102; Iter    27/  183] train: loss: 0.0470579
[Epoch 102; Iter    57/  183] train: loss: 0.0926584
[Epoch 102; Iter    87/  183] train: loss: 0.0512413
[Epoch 102; Iter   117/  183] train: loss: 0.0494691
[Epoch 102; Iter   147/  183] train: loss: 0.0611448
[Epoch 102; Iter   177/  183] train: loss: 0.0568902
[Epoch 102] ogbg-moltox21: 0.815646 val loss: 0.261168
[Epoch 102] ogbg-moltox21: 0.815292 test loss: 0.279550
[Epoch 103; Iter    24/  183] train: loss: 0.0866430
[Epoch 103; Iter    54/  183] train: loss: 0.0586772
[Epoch 103; Iter    84/  183] train: loss: 0.0551723
[Epoch 103; Iter   114/  183] train: loss: 0.0581612
[Epoch 103; Iter   144/  183] train: loss: 0.0258025
[Epoch 103; Iter   174/  183] train: loss: 0.0691764
[Epoch 103] ogbg-moltox21: 0.816528 val loss: 0.267320
[Epoch 103] ogbg-moltox21: 0.821202 test loss: 0.275525
[Epoch 104; Iter    21/  183] train: loss: 0.0540853
[Epoch 104; Iter    51/  183] train: loss: 0.0526581
[Epoch 104; Iter    81/  183] train: loss: 0.0938376
[Epoch 104; Iter   111/  183] train: loss: 0.0329376
[Epoch 104; Iter   141/  183] train: loss: 0.0346935
[Epoch 104; Iter   171/  183] train: loss: 0.0741301
[Epoch 104] ogbg-moltox21: 0.810263 val loss: 0.267330
[Epoch 104] ogbg-moltox21: 0.810004 test loss: 0.280880
[Epoch 105; Iter    18/  183] train: loss: 0.0400517
[Epoch 105; Iter    48/  183] train: loss: 0.0742910
[Epoch 105; Iter    78/  183] train: loss: 0.0507415
[Epoch 105; Iter   108/  183] train: loss: 0.0561653
[Epoch 105; Iter   138/  183] train: loss: 0.0630442
[Epoch 105; Iter   168/  183] train: loss: 0.1105753
[Epoch 105] ogbg-moltox21: 0.814118 val loss: 0.269139
[Epoch 105] ogbg-moltox21: 0.816895 test loss: 0.279727
[Epoch 106; Iter    15/  183] train: loss: 0.0471028
[Epoch 106; Iter    45/  183] train: loss: 0.0563999
[Epoch 106; Iter    75/  183] train: loss: 0.0680220
[Epoch 106; Iter   105/  183] train: loss: 0.0447161
[Epoch 106; Iter   135/  183] train: loss: 0.0438396
[Epoch 106; Iter   165/  183] train: loss: 0.0387519
[Epoch 106] ogbg-moltox21: 0.812810 val loss: 0.270553
[Epoch 106] ogbg-moltox21: 0.816737 test loss: 0.283519
[Epoch 107; Iter    12/  183] train: loss: 0.0328224
[Epoch 107; Iter    42/  183] train: loss: 0.0587588
[Epoch 107; Iter    72/  183] train: loss: 0.0849639
[Epoch 107; Iter   102/  183] train: loss: 0.0411860
[Epoch 107; Iter   132/  183] train: loss: 0.0414358
[Epoch 107; Iter   162/  183] train: loss: 0.0438544
[Epoch 107] ogbg-moltox21: 0.818733 val loss: 0.310976
[Epoch 107] ogbg-moltox21: 0.815279 test loss: 0.291869
[Epoch 108; Iter     9/  183] train: loss: 0.0713205
[Epoch 108; Iter    39/  183] train: loss: 0.0371637
[Epoch 108; Iter    69/  183] train: loss: 0.0587946
[Epoch 108; Iter    99/  183] train: loss: 0.0383186
[Epoch 108; Iter   129/  183] train: loss: 0.0734781
[Epoch 108; Iter   159/  183] train: loss: 0.0559448
[Epoch 108] ogbg-moltox21: 0.812653 val loss: 0.276289
[Epoch 108] ogbg-moltox21: 0.810834 test loss: 0.289481
[Epoch 109; Iter     6/  183] train: loss: 0.0429632
[Epoch 109; Iter    36/  183] train: loss: 0.0499730
[Epoch 109; Iter    66/  183] train: loss: 0.0678004
[Epoch 109; Iter    96/  183] train: loss: 0.0320625
[Epoch 109; Iter   126/  183] train: loss: 0.0449824
[Epoch 109; Iter   156/  183] train: loss: 0.0966437
[Epoch 109] ogbg-moltox21: 0.812655 val loss: 0.275412
[Epoch 90] ogbg-moltox21: 0.806627 val loss: 0.272408
[Epoch 90] ogbg-moltox21: 0.814899 test loss: 0.272656
[Epoch 91; Iter    30/  183] train: loss: 0.0317477
[Epoch 91; Iter    60/  183] train: loss: 0.0478057
[Epoch 91; Iter    90/  183] train: loss: 0.1081919
[Epoch 91; Iter   120/  183] train: loss: 0.0363636
[Epoch 91; Iter   150/  183] train: loss: 0.0851169
[Epoch 91; Iter   180/  183] train: loss: 0.0437073
[Epoch 91] ogbg-moltox21: 0.803698 val loss: 0.270122
[Epoch 91] ogbg-moltox21: 0.817071 test loss: 0.271367
[Epoch 92; Iter    27/  183] train: loss: 0.0838992
[Epoch 92; Iter    57/  183] train: loss: 0.0590645
[Epoch 92; Iter    87/  183] train: loss: 0.0308758
[Epoch 92; Iter   117/  183] train: loss: 0.0618074
[Epoch 92; Iter   147/  183] train: loss: 0.0375455
[Epoch 92; Iter   177/  183] train: loss: 0.0533962
[Epoch 92] ogbg-moltox21: 0.804541 val loss: 0.262983
[Epoch 92] ogbg-moltox21: 0.815465 test loss: 0.270537
[Epoch 93; Iter    24/  183] train: loss: 0.0571983
[Epoch 93; Iter    54/  183] train: loss: 0.0900534
[Epoch 93; Iter    84/  183] train: loss: 0.0788019
[Epoch 93; Iter   114/  183] train: loss: 0.0612227
[Epoch 93; Iter   144/  183] train: loss: 0.0449015
[Epoch 93; Iter   174/  183] train: loss: 0.0463988
[Epoch 93] ogbg-moltox21: 0.804416 val loss: 0.274682
[Epoch 93] ogbg-moltox21: 0.813831 test loss: 0.280739
[Epoch 94; Iter    21/  183] train: loss: 0.0534474
[Epoch 94; Iter    51/  183] train: loss: 0.0636119
[Epoch 94; Iter    81/  183] train: loss: 0.0621069
[Epoch 94; Iter   111/  183] train: loss: 0.0471245
[Epoch 94; Iter   141/  183] train: loss: 0.0541218
[Epoch 94; Iter   171/  183] train: loss: 0.0374045
[Epoch 94] ogbg-moltox21: 0.801404 val loss: 0.275865
[Epoch 94] ogbg-moltox21: 0.817587 test loss: 0.276120
[Epoch 95; Iter    18/  183] train: loss: 0.0265631
[Epoch 95; Iter    48/  183] train: loss: 0.0701658
[Epoch 95; Iter    78/  183] train: loss: 0.0965259
[Epoch 95; Iter   108/  183] train: loss: 0.0567318
[Epoch 95; Iter   138/  183] train: loss: 0.0649362
[Epoch 95; Iter   168/  183] train: loss: 0.0322922
[Epoch 95] ogbg-moltox21: 0.808670 val loss: 0.269260
[Epoch 95] ogbg-moltox21: 0.818213 test loss: 0.272013
[Epoch 96; Iter    15/  183] train: loss: 0.0340924
[Epoch 96; Iter    45/  183] train: loss: 0.0468562
[Epoch 96; Iter    75/  183] train: loss: 0.0398081
[Epoch 96; Iter   105/  183] train: loss: 0.0907715
[Epoch 96; Iter   135/  183] train: loss: 0.1069979
[Epoch 96; Iter   165/  183] train: loss: 0.0836682
[Epoch 96] ogbg-moltox21: 0.805806 val loss: 0.271036
[Epoch 96] ogbg-moltox21: 0.819959 test loss: 0.273075
[Epoch 97; Iter    12/  183] train: loss: 0.0534143
[Epoch 97; Iter    42/  183] train: loss: 0.0329092
[Epoch 97; Iter    72/  183] train: loss: 0.0582343
[Epoch 97; Iter   102/  183] train: loss: 0.0601366
[Epoch 97; Iter   132/  183] train: loss: 0.0337208
[Epoch 97; Iter   162/  183] train: loss: 0.0359188
[Epoch 97] ogbg-moltox21: 0.807020 val loss: 0.274322
[Epoch 97] ogbg-moltox21: 0.818320 test loss: 0.278429
[Epoch 98; Iter     9/  183] train: loss: 0.0552515
[Epoch 98; Iter    39/  183] train: loss: 0.0575141
[Epoch 98; Iter    69/  183] train: loss: 0.0777851
[Epoch 98; Iter    99/  183] train: loss: 0.0467902
[Epoch 98; Iter   129/  183] train: loss: 0.0361880
[Epoch 98; Iter   159/  183] train: loss: 0.0405406
[Epoch 98] ogbg-moltox21: 0.808428 val loss: 0.274146
[Epoch 98] ogbg-moltox21: 0.819139 test loss: 0.275401
[Epoch 99; Iter     6/  183] train: loss: 0.0568954
[Epoch 99; Iter    36/  183] train: loss: 0.0586010
[Epoch 99; Iter    66/  183] train: loss: 0.0589209
[Epoch 99; Iter    96/  183] train: loss: 0.0906274
[Epoch 99; Iter   126/  183] train: loss: 0.0675773
[Epoch 99; Iter   156/  183] train: loss: 0.0584022
[Epoch 99] ogbg-moltox21: 0.805970 val loss: 0.270778
[Epoch 99] ogbg-moltox21: 0.818993 test loss: 0.274451
[Epoch 100; Iter     3/  183] train: loss: 0.0492129
[Epoch 100; Iter    33/  183] train: loss: 0.0727915
[Epoch 100; Iter    63/  183] train: loss: 0.0531426
[Epoch 100; Iter    93/  183] train: loss: 0.0450160
[Epoch 100; Iter   123/  183] train: loss: 0.0482453
[Epoch 100; Iter   153/  183] train: loss: 0.0768046
[Epoch 100; Iter   183/  183] train: loss: 0.0678805
[Epoch 100] ogbg-moltox21: 0.801828 val loss: 0.279508
[Epoch 100] ogbg-moltox21: 0.815912 test loss: 0.283430
[Epoch 101; Iter    30/  183] train: loss: 0.0654851
[Epoch 101; Iter    60/  183] train: loss: 0.0750241
[Epoch 101; Iter    90/  183] train: loss: 0.0595628
[Epoch 101; Iter   120/  183] train: loss: 0.0618541
[Epoch 101; Iter   150/  183] train: loss: 0.0714926
[Epoch 101; Iter   180/  183] train: loss: 0.0717671
[Epoch 101] ogbg-moltox21: 0.803398 val loss: 0.275065
[Epoch 101] ogbg-moltox21: 0.814745 test loss: 0.282383
[Epoch 102; Iter    27/  183] train: loss: 0.0557932
[Epoch 102; Iter    57/  183] train: loss: 0.0374475
[Epoch 102; Iter    87/  183] train: loss: 0.0579407
[Epoch 102; Iter   117/  183] train: loss: 0.0683372
[Epoch 102; Iter   147/  183] train: loss: 0.0496169
[Epoch 102; Iter   177/  183] train: loss: 0.0535786
[Epoch 102] ogbg-moltox21: 0.803360 val loss: 0.283703
[Epoch 102] ogbg-moltox21: 0.814953 test loss: 0.288490
[Epoch 103; Iter    24/  183] train: loss: 0.0656997
[Epoch 103; Iter    54/  183] train: loss: 0.0273143
[Epoch 103; Iter    84/  183] train: loss: 0.0297055
[Epoch 103; Iter   114/  183] train: loss: 0.0333142
[Epoch 103; Iter   144/  183] train: loss: 0.0468232
[Epoch 103; Iter   174/  183] train: loss: 0.0805038
[Epoch 103] ogbg-moltox21: 0.798229 val loss: 0.289653
[Epoch 103] ogbg-moltox21: 0.807452 test loss: 0.289676
[Epoch 104; Iter    21/  183] train: loss: 0.0404199
[Epoch 104; Iter    51/  183] train: loss: 0.0265178
[Epoch 104; Iter    81/  183] train: loss: 0.0697374
[Epoch 104; Iter   111/  183] train: loss: 0.0405574
[Epoch 104; Iter   141/  183] train: loss: 0.0405841
[Epoch 104; Iter   171/  183] train: loss: 0.0837334
[Epoch 104] ogbg-moltox21: 0.806281 val loss: 0.281779
[Epoch 104] ogbg-moltox21: 0.811080 test loss: 0.287543
[Epoch 105; Iter    18/  183] train: loss: 0.0521045
[Epoch 105; Iter    48/  183] train: loss: 0.0285435
[Epoch 105; Iter    78/  183] train: loss: 0.0424784
[Epoch 105; Iter   108/  183] train: loss: 0.0456531
[Epoch 105; Iter   138/  183] train: loss: 0.0791576
[Epoch 105; Iter   168/  183] train: loss: 0.0387105
[Epoch 105] ogbg-moltox21: 0.804725 val loss: 0.285835
[Epoch 105] ogbg-moltox21: 0.816760 test loss: 0.286084
[Epoch 106; Iter    15/  183] train: loss: 0.0249447
[Epoch 106; Iter    45/  183] train: loss: 0.0557680
[Epoch 106; Iter    75/  183] train: loss: 0.0388837
[Epoch 106; Iter   105/  183] train: loss: 0.0552675
[Epoch 106; Iter   135/  183] train: loss: 0.0394596
[Epoch 106; Iter   165/  183] train: loss: 0.0432586
[Epoch 106] ogbg-moltox21: 0.803301 val loss: 0.280973
[Epoch 106] ogbg-moltox21: 0.811316 test loss: 0.289990
[Epoch 107; Iter    12/  183] train: loss: 0.0402882
[Epoch 107; Iter    42/  183] train: loss: 0.0459856
[Epoch 107; Iter    72/  183] train: loss: 0.0604913
[Epoch 107; Iter   102/  183] train: loss: 0.0822972
[Epoch 107; Iter   132/  183] train: loss: 0.0407352
[Epoch 107; Iter   162/  183] train: loss: 0.0709132
[Epoch 107] ogbg-moltox21: 0.802562 val loss: 0.282856
[Epoch 107] ogbg-moltox21: 0.812685 test loss: 0.288561
[Epoch 108; Iter     9/  183] train: loss: 0.0623612
[Epoch 108; Iter    39/  183] train: loss: 0.0475277
[Epoch 108; Iter    69/  183] train: loss: 0.0326623
[Epoch 108; Iter    99/  183] train: loss: 0.0512775
[Epoch 108; Iter   129/  183] train: loss: 0.0603476
[Epoch 108; Iter   159/  183] train: loss: 0.0493524
[Epoch 108] ogbg-moltox21: 0.802038 val loss: 0.288740
[Epoch 108] ogbg-moltox21: 0.807174 test loss: 0.297862
[Epoch 109; Iter     6/  183] train: loss: 0.0771356
[Epoch 109; Iter    36/  183] train: loss: 0.0443715
[Epoch 109; Iter    66/  183] train: loss: 0.0596559
[Epoch 109; Iter    96/  183] train: loss: 0.0395656
[Epoch 109; Iter   126/  183] train: loss: 0.0446857
[Epoch 109; Iter   156/  183] train: loss: 0.0817585
[Epoch 109] ogbg-moltox21: 0.792509 val loss: 0.293818
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0652885
[Epoch 101] ogbg-moltox21: 0.796506 val loss: 0.268193
[Epoch 101] ogbg-moltox21: 0.807506 test loss: 0.278224
[Epoch 102; Iter    13/  157] train: loss: 0.0517282
[Epoch 102; Iter    43/  157] train: loss: 0.0544971
[Epoch 102; Iter    73/  157] train: loss: 0.0546917
[Epoch 102; Iter   103/  157] train: loss: 0.1127904
[Epoch 102; Iter   133/  157] train: loss: 0.0469617
[Epoch 102] ogbg-moltox21: 0.801704 val loss: 0.268248
[Epoch 102] ogbg-moltox21: 0.814185 test loss: 0.281488
[Epoch 103; Iter     6/  157] train: loss: 0.0347351
[Epoch 103; Iter    36/  157] train: loss: 0.0453207
[Epoch 103; Iter    66/  157] train: loss: 0.0469568
[Epoch 103; Iter    96/  157] train: loss: 0.0471459
[Epoch 103; Iter   126/  157] train: loss: 0.0372158
[Epoch 103; Iter   156/  157] train: loss: 0.0620728
[Epoch 103] ogbg-moltox21: 0.801982 val loss: 0.262919
[Epoch 103] ogbg-moltox21: 0.814935 test loss: 0.276722
[Epoch 104; Iter    29/  157] train: loss: 0.0433132
[Epoch 104; Iter    59/  157] train: loss: 0.0528286
[Epoch 104; Iter    89/  157] train: loss: 0.0380275
[Epoch 104; Iter   119/  157] train: loss: 0.0479597
[Epoch 104; Iter   149/  157] train: loss: 0.0905215
[Epoch 104] ogbg-moltox21: 0.803651 val loss: 0.265389
[Epoch 104] ogbg-moltox21: 0.815343 test loss: 0.282708
[Epoch 105; Iter    22/  157] train: loss: 0.0499308
[Epoch 105; Iter    52/  157] train: loss: 0.0380182
[Epoch 105; Iter    82/  157] train: loss: 0.0297619
[Epoch 105; Iter   112/  157] train: loss: 0.0532464
[Epoch 105; Iter   142/  157] train: loss: 0.0587094
[Epoch 105] ogbg-moltox21: 0.801737 val loss: 0.266088
[Epoch 105] ogbg-moltox21: 0.809597 test loss: 0.282932
[Epoch 106; Iter    15/  157] train: loss: 0.0378164
[Epoch 106; Iter    45/  157] train: loss: 0.0367358
[Epoch 106; Iter    75/  157] train: loss: 0.0407223
[Epoch 106; Iter   105/  157] train: loss: 0.0690418
[Epoch 106; Iter   135/  157] train: loss: 0.0468287
[Epoch 106] ogbg-moltox21: 0.801824 val loss: 0.258614
[Epoch 106] ogbg-moltox21: 0.808611 test loss: 0.282034
[Epoch 107; Iter     8/  157] train: loss: 0.0301550
[Epoch 107; Iter    38/  157] train: loss: 0.0684220
[Epoch 107; Iter    68/  157] train: loss: 0.0542528
[Epoch 107; Iter    98/  157] train: loss: 0.0365339
[Epoch 107; Iter   128/  157] train: loss: 0.0435227
[Epoch 107] ogbg-moltox21: 0.803622 val loss: 0.261182
[Epoch 107] ogbg-moltox21: 0.813554 test loss: 0.284881
[Epoch 108; Iter     1/  157] train: loss: 0.0589097
[Epoch 108; Iter    31/  157] train: loss: 0.0390191
[Epoch 108; Iter    61/  157] train: loss: 0.1010535
[Epoch 108; Iter    91/  157] train: loss: 0.0735934
[Epoch 108; Iter   121/  157] train: loss: 0.0554546
[Epoch 108; Iter   151/  157] train: loss: 0.0321365
[Epoch 108] ogbg-moltox21: 0.799714 val loss: 0.274781
[Epoch 108] ogbg-moltox21: 0.809306 test loss: 0.286243
[Epoch 109; Iter    24/  157] train: loss: 0.0401493
[Epoch 109; Iter    54/  157] train: loss: 0.0961553
[Epoch 109; Iter    84/  157] train: loss: 0.0275440
[Epoch 109; Iter   114/  157] train: loss: 0.0633692
[Epoch 109; Iter   144/  157] train: loss: 0.0434249
[Epoch 109] ogbg-moltox21: 0.800434 val loss: 0.281562
[Epoch 109] ogbg-moltox21: 0.812353 test loss: 0.289408
[Epoch 110; Iter    17/  157] train: loss: 0.0454914
[Epoch 110; Iter    47/  157] train: loss: 0.0474966
[Epoch 110; Iter    77/  157] train: loss: 0.0528797
[Epoch 110; Iter   107/  157] train: loss: 0.0474192
[Epoch 110; Iter   137/  157] train: loss: 0.0542350
[Epoch 110] ogbg-moltox21: 0.801038 val loss: 0.284406
[Epoch 110] ogbg-moltox21: 0.807118 test loss: 0.295870
[Epoch 111; Iter    10/  157] train: loss: 0.0333045
[Epoch 111; Iter    40/  157] train: loss: 0.0394288
[Epoch 111; Iter    70/  157] train: loss: 0.0403857
[Epoch 111; Iter   100/  157] train: loss: 0.1089158
[Epoch 111; Iter   130/  157] train: loss: 0.0477614
[Epoch 111] ogbg-moltox21: 0.802626 val loss: 0.290222
[Epoch 111] ogbg-moltox21: 0.812537 test loss: 0.290929
[Epoch 112; Iter     3/  157] train: loss: 0.0464600
[Epoch 112; Iter    33/  157] train: loss: 0.0473059
[Epoch 112; Iter    63/  157] train: loss: 0.0501093
[Epoch 112; Iter    93/  157] train: loss: 0.0559285
[Epoch 112; Iter   123/  157] train: loss: 0.0631480
[Epoch 112; Iter   153/  157] train: loss: 0.0385228
[Epoch 112] ogbg-moltox21: 0.804078 val loss: 0.275483
[Epoch 112] ogbg-moltox21: 0.812833 test loss: 0.289759
[Epoch 113; Iter    26/  157] train: loss: 0.0399877
[Epoch 113; Iter    56/  157] train: loss: 0.0539799
[Epoch 113; Iter    86/  157] train: loss: 0.0500095
[Epoch 113; Iter   116/  157] train: loss: 0.0461869
[Epoch 113; Iter   146/  157] train: loss: 0.0547334
[Epoch 113] ogbg-moltox21: 0.798922 val loss: 0.274088
[Epoch 113] ogbg-moltox21: 0.808469 test loss: 0.297728
[Epoch 114; Iter    19/  157] train: loss: 0.0527475
[Epoch 114; Iter    49/  157] train: loss: 0.0248155
[Epoch 114; Iter    79/  157] train: loss: 0.0454901
[Epoch 114; Iter   109/  157] train: loss: 0.1047411
[Epoch 114; Iter   139/  157] train: loss: 0.0250789
[Epoch 114] ogbg-moltox21: 0.801511 val loss: 0.288808
[Epoch 114] ogbg-moltox21: 0.811599 test loss: 0.295668
[Epoch 115; Iter    12/  157] train: loss: 0.0477876
[Epoch 115; Iter    42/  157] train: loss: 0.0641928
[Epoch 115; Iter    72/  157] train: loss: 0.0258923
[Epoch 115; Iter   102/  157] train: loss: 0.0428535
[Epoch 115; Iter   132/  157] train: loss: 0.0451962
[Epoch 115] ogbg-moltox21: 0.795834 val loss: 0.299747
[Epoch 115] ogbg-moltox21: 0.807653 test loss: 0.300198
[Epoch 116; Iter     5/  157] train: loss: 0.0665549
[Epoch 116; Iter    35/  157] train: loss: 0.0518435
[Epoch 116; Iter    65/  157] train: loss: 0.0306434
[Epoch 116; Iter    95/  157] train: loss: 0.0467549
[Epoch 116; Iter   125/  157] train: loss: 0.0186975
[Epoch 116; Iter   155/  157] train: loss: 0.0664072
[Epoch 116] ogbg-moltox21: 0.799018 val loss: 0.324495
[Epoch 116] ogbg-moltox21: 0.810314 test loss: 0.295059
[Epoch 117; Iter    28/  157] train: loss: 0.0279246
[Epoch 117; Iter    58/  157] train: loss: 0.0379232
[Epoch 117; Iter    88/  157] train: loss: 0.0746449
[Epoch 117; Iter   118/  157] train: loss: 0.0287908
[Epoch 117; Iter   148/  157] train: loss: 0.0414836
[Epoch 117] ogbg-moltox21: 0.801193 val loss: 0.273540
[Epoch 117] ogbg-moltox21: 0.809920 test loss: 0.297095
[Epoch 118; Iter    21/  157] train: loss: 0.0384022
[Epoch 118; Iter    51/  157] train: loss: 0.0547865
[Epoch 118; Iter    81/  157] train: loss: 0.0343519
[Epoch 118; Iter   111/  157] train: loss: 0.0674702
[Epoch 118; Iter   141/  157] train: loss: 0.0454655
[Epoch 118] ogbg-moltox21: 0.802243 val loss: 0.332329
[Epoch 118] ogbg-moltox21: 0.814055 test loss: 0.295073
[Epoch 119; Iter    14/  157] train: loss: 0.0438398
[Epoch 119; Iter    44/  157] train: loss: 0.0493064
[Epoch 119; Iter    74/  157] train: loss: 0.0545930
[Epoch 119; Iter   104/  157] train: loss: 0.0395398
[Epoch 119; Iter   134/  157] train: loss: 0.0653706
[Epoch 119] ogbg-moltox21: 0.800618 val loss: 0.294650
[Epoch 119] ogbg-moltox21: 0.810928 test loss: 0.293219
[Epoch 120; Iter     7/  157] train: loss: 0.0290929
[Epoch 120; Iter    37/  157] train: loss: 0.0264057
[Epoch 120; Iter    67/  157] train: loss: 0.0441109
[Epoch 120; Iter    97/  157] train: loss: 0.0314523
[Epoch 120; Iter   127/  157] train: loss: 0.0555715
[Epoch 120; Iter   157/  157] train: loss: 0.0455160
[Epoch 120] ogbg-moltox21: 0.799317 val loss: 0.292607
[Epoch 120] ogbg-moltox21: 0.810926 test loss: 0.297081
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -3.6133410930633545
std_pred: 2.0135254859924316
mean_targets: nan
std_targets: nan
prcauc: 0.4301372675128941
rocauc: 0.8399612880039488
ogbg-moltox21: 0.8399612880039488
OGBNanLabelBCEWithLogitsLoss: 0.18390193525350318
Statistics on  test
mean_pred: -3.6375410556793213
std_pred: 2.5972836017608643
mean_targets: nan
std_targets: nan
prcauc: 0.4686767543058974
rocauc: 0.8502143496466901
ogbg-moltox21: 0.8502143496466901
[Epoch 101; Iter   140/  157] train: loss: 0.1197760
[Epoch 101] ogbg-moltox21: 0.832726 val loss: 0.204683
[Epoch 101] ogbg-moltox21: 0.832482 test loss: 0.237756
[Epoch 102; Iter    13/  157] train: loss: 0.1102065
[Epoch 102; Iter    43/  157] train: loss: 0.0871259
[Epoch 102; Iter    73/  157] train: loss: 0.1144996
[Epoch 102; Iter   103/  157] train: loss: 0.1129242
[Epoch 102; Iter   133/  157] train: loss: 0.0871508
[Epoch 102] ogbg-moltox21: 0.828516 val loss: 0.213263
[Epoch 102] ogbg-moltox21: 0.827999 test loss: 0.239741
[Epoch 103; Iter     6/  157] train: loss: 0.0821618
[Epoch 103; Iter    36/  157] train: loss: 0.1613321
[Epoch 103; Iter    66/  157] train: loss: 0.1493587
[Epoch 103; Iter    96/  157] train: loss: 0.0650938
[Epoch 103; Iter   126/  157] train: loss: 0.0921108
[Epoch 103; Iter   156/  157] train: loss: 0.0961338
[Epoch 103] ogbg-moltox21: 0.833100 val loss: 0.206753
[Epoch 103] ogbg-moltox21: 0.834098 test loss: 0.239160
[Epoch 104; Iter    29/  157] train: loss: 0.1018546
[Epoch 104; Iter    59/  157] train: loss: 0.1221718
[Epoch 104; Iter    89/  157] train: loss: 0.0788194
[Epoch 104; Iter   119/  157] train: loss: 0.1627674
[Epoch 104; Iter   149/  157] train: loss: 0.1389741
[Epoch 104] ogbg-moltox21: 0.830607 val loss: 0.204087
[Epoch 104] ogbg-moltox21: 0.825419 test loss: 0.239721
[Epoch 105; Iter    22/  157] train: loss: 0.0883015
[Epoch 105; Iter    52/  157] train: loss: 0.0980997
[Epoch 105; Iter    82/  157] train: loss: 0.0691939
[Epoch 105; Iter   112/  157] train: loss: 0.1019926
[Epoch 105; Iter   142/  157] train: loss: 0.0858272
[Epoch 105] ogbg-moltox21: 0.828992 val loss: 0.202355
[Epoch 105] ogbg-moltox21: 0.829001 test loss: 0.235299
[Epoch 106; Iter    15/  157] train: loss: 0.1184324
[Epoch 106; Iter    45/  157] train: loss: 0.0506659
[Epoch 106; Iter    75/  157] train: loss: 0.1644790
[Epoch 106; Iter   105/  157] train: loss: 0.1274882
[Epoch 106; Iter   135/  157] train: loss: 0.0944423
[Epoch 106] ogbg-moltox21: 0.831371 val loss: 0.204024
[Epoch 106] ogbg-moltox21: 0.830569 test loss: 0.230457
[Epoch 107; Iter     8/  157] train: loss: 0.0834677
[Epoch 107; Iter    38/  157] train: loss: 0.1301071
[Epoch 107; Iter    68/  157] train: loss: 0.0877873
[Epoch 107; Iter    98/  157] train: loss: 0.0617325
[Epoch 107; Iter   128/  157] train: loss: 0.1147628
[Epoch 107] ogbg-moltox21: 0.836421 val loss: 2.006948
[Epoch 107] ogbg-moltox21: 0.829643 test loss: 0.270438
[Epoch 108; Iter     1/  157] train: loss: 0.0742162
[Epoch 108; Iter    31/  157] train: loss: 0.0935216
[Epoch 108; Iter    61/  157] train: loss: 0.1024378
[Epoch 108; Iter    91/  157] train: loss: 0.0875310
[Epoch 108; Iter   121/  157] train: loss: 0.1400788
[Epoch 108; Iter   151/  157] train: loss: 0.0672697
[Epoch 108] ogbg-moltox21: 0.834636 val loss: 0.382766
[Epoch 108] ogbg-moltox21: 0.827370 test loss: 0.366245
[Epoch 109; Iter    24/  157] train: loss: 0.0776882
[Epoch 109; Iter    54/  157] train: loss: 0.1136882
[Epoch 109; Iter    84/  157] train: loss: 0.0788750
[Epoch 109; Iter   114/  157] train: loss: 0.0868889
[Epoch 109; Iter   144/  157] train: loss: 0.1118499
[Epoch 109] ogbg-moltox21: 0.830932 val loss: 0.347768
[Epoch 109] ogbg-moltox21: 0.823592 test loss: 0.370834
[Epoch 110; Iter    17/  157] train: loss: 0.0813322
[Epoch 110; Iter    47/  157] train: loss: 0.0702566
[Epoch 110; Iter    77/  157] train: loss: 0.0673459
[Epoch 110; Iter   107/  157] train: loss: 0.0851583
[Epoch 110; Iter   137/  157] train: loss: 0.0878632
[Epoch 110] ogbg-moltox21: 0.827952 val loss: 0.211226
[Epoch 110] ogbg-moltox21: 0.828935 test loss: 0.253779
[Epoch 111; Iter    10/  157] train: loss: 0.1183637
[Epoch 111; Iter    40/  157] train: loss: 0.1103422
[Epoch 111; Iter    70/  157] train: loss: 0.0851762
[Epoch 111; Iter   100/  157] train: loss: 0.1788576
[Epoch 111; Iter   130/  157] train: loss: 0.0736375
[Epoch 111] ogbg-moltox21: 0.818347 val loss: 0.243899
[Epoch 111] ogbg-moltox21: 0.820481 test loss: 0.346535
[Epoch 112; Iter     3/  157] train: loss: 0.0894244
[Epoch 112; Iter    33/  157] train: loss: 0.0832696
[Epoch 112; Iter    63/  157] train: loss: 0.0989351
[Epoch 112; Iter    93/  157] train: loss: 0.1013076
[Epoch 112; Iter   123/  157] train: loss: 0.0973938
[Epoch 112; Iter   153/  157] train: loss: 0.0936508
[Epoch 112] ogbg-moltox21: 0.829494 val loss: 1.252167
[Epoch 112] ogbg-moltox21: 0.822508 test loss: 0.282573
[Epoch 113; Iter    26/  157] train: loss: 0.0644403
[Epoch 113; Iter    56/  157] train: loss: 0.0769815
[Epoch 113; Iter    86/  157] train: loss: 0.0635487
[Epoch 113; Iter   116/  157] train: loss: 0.0915304
[Epoch 113; Iter   146/  157] train: loss: 0.0900916
[Epoch 113] ogbg-moltox21: 0.831801 val loss: 1.456996
[Epoch 113] ogbg-moltox21: 0.823823 test loss: 0.307036
[Epoch 114; Iter    19/  157] train: loss: 0.0835784
[Epoch 114; Iter    49/  157] train: loss: 0.1447628
[Epoch 114; Iter    79/  157] train: loss: 0.0926460
[Epoch 114; Iter   109/  157] train: loss: 0.0860793
[Epoch 114; Iter   139/  157] train: loss: 0.1092556
[Epoch 114] ogbg-moltox21: 0.826592 val loss: 0.539060
[Epoch 114] ogbg-moltox21: 0.826315 test loss: 0.237896
[Epoch 115; Iter    12/  157] train: loss: 0.1223108
[Epoch 115; Iter    42/  157] train: loss: 0.1082073
[Epoch 115; Iter    72/  157] train: loss: 0.0806069
[Epoch 115; Iter   102/  157] train: loss: 0.1333822
[Epoch 115; Iter   132/  157] train: loss: 0.0932433
[Epoch 115] ogbg-moltox21: 0.829595 val loss: 1.073049
[Epoch 115] ogbg-moltox21: 0.823502 test loss: 0.319378
[Epoch 116; Iter     5/  157] train: loss: 0.0762673
[Epoch 116; Iter    35/  157] train: loss: 0.1025733
[Epoch 116; Iter    65/  157] train: loss: 0.0862914
[Epoch 116; Iter    95/  157] train: loss: 0.1486805
[Epoch 116; Iter   125/  157] train: loss: 0.0808299
[Epoch 116; Iter   155/  157] train: loss: 0.1191800
[Epoch 116] ogbg-moltox21: 0.825125 val loss: 0.210781
[Epoch 116] ogbg-moltox21: 0.827396 test loss: 0.293944
[Epoch 117; Iter    28/  157] train: loss: 0.0968481
[Epoch 117; Iter    58/  157] train: loss: 0.0949819
[Epoch 117; Iter    88/  157] train: loss: 0.1021010
[Epoch 117; Iter   118/  157] train: loss: 0.1073750
[Epoch 117; Iter   148/  157] train: loss: 0.1269106
[Epoch 117] ogbg-moltox21: 0.824421 val loss: 0.280039
[Epoch 117] ogbg-moltox21: 0.824122 test loss: 0.373791
[Epoch 118; Iter    21/  157] train: loss: 0.1033068
[Epoch 118; Iter    51/  157] train: loss: 0.0902511
[Epoch 118; Iter    81/  157] train: loss: 0.0859412
[Epoch 118; Iter   111/  157] train: loss: 0.1340068
[Epoch 118; Iter   141/  157] train: loss: 0.0874059
[Epoch 118] ogbg-moltox21: 0.829756 val loss: 1.177673
[Epoch 118] ogbg-moltox21: 0.823055 test loss: 0.391212
[Epoch 119; Iter    14/  157] train: loss: 0.0602962
[Epoch 119; Iter    44/  157] train: loss: 0.0936002
[Epoch 119; Iter    74/  157] train: loss: 0.0855403
[Epoch 119; Iter   104/  157] train: loss: 0.1049686
[Epoch 119; Iter   134/  157] train: loss: 0.0563732
[Epoch 119] ogbg-moltox21: 0.823413 val loss: 0.472125
[Epoch 119] ogbg-moltox21: 0.822088 test loss: 0.276952
[Epoch 120; Iter     7/  157] train: loss: 0.0995637
[Epoch 120; Iter    37/  157] train: loss: 0.0775446
[Epoch 120; Iter    67/  157] train: loss: 0.0582309
[Epoch 120; Iter    97/  157] train: loss: 0.0919519
[Epoch 120; Iter   127/  157] train: loss: 0.1157282
[Epoch 120; Iter   157/  157] train: loss: 0.0826822
[Epoch 120] ogbg-moltox21: 0.823756 val loss: 0.215081
[Epoch 120] ogbg-moltox21: 0.824305 test loss: 0.342138
[Epoch 121; Iter    30/  157] train: loss: 0.0480492
[Epoch 121; Iter    60/  157] train: loss: 0.0915358
[Epoch 121; Iter    90/  157] train: loss: 0.0819092
[Epoch 121; Iter   120/  157] train: loss: 0.0332572
[Epoch 121; Iter   150/  157] train: loss: 0.0990466
[Epoch 121] ogbg-moltox21: 0.824972 val loss: 6.395256
[Epoch 121] ogbg-moltox21: 0.820077 test loss: 0.345184
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 121 epochs. Best model checkpoint was in epoch 61.
Statistics on  val_best_checkpoint
mean_pred: -4.032779216766357
std_pred: 2.278951406478882
OGBNanLabelBCEWithLogitsLoss: 0.1935933090324672
Statistics on  train
mean_pred: -3.611621856689453
std_pred: 2.6862473487854004
mean_targets: nan
std_targets: nan
prcauc: 0.562512574845954
rocauc: 0.9024631842447038
ogbg-moltox21: 0.9024631842447038
OGBNanLabelBCEWithLogitsLoss: 0.15743954332580992
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0668164
[Epoch 101] ogbg-moltox21: 0.807113 val loss: 0.269610
[Epoch 101] ogbg-moltox21: 0.807834 test loss: 0.304760
[Epoch 102; Iter    13/  157] train: loss: 0.0324272
[Epoch 102; Iter    43/  157] train: loss: 0.0719578
[Epoch 102; Iter    73/  157] train: loss: 0.0325623
[Epoch 102; Iter   103/  157] train: loss: 0.0615611
[Epoch 102; Iter   133/  157] train: loss: 0.0292147
[Epoch 102] ogbg-moltox21: 0.805432 val loss: 0.266535
[Epoch 102] ogbg-moltox21: 0.807747 test loss: 0.303756
[Epoch 103; Iter     6/  157] train: loss: 0.0476666
[Epoch 103; Iter    36/  157] train: loss: 0.0388117
[Epoch 103; Iter    66/  157] train: loss: 0.0323101
[Epoch 103; Iter    96/  157] train: loss: 0.0451991
[Epoch 103; Iter   126/  157] train: loss: 0.0278198
[Epoch 103; Iter   156/  157] train: loss: 0.0559681
[Epoch 103] ogbg-moltox21: 0.806569 val loss: 0.274352
[Epoch 103] ogbg-moltox21: 0.809354 test loss: 0.309814
[Epoch 104; Iter    29/  157] train: loss: 0.0358548
[Epoch 104; Iter    59/  157] train: loss: 0.0179552
[Epoch 104; Iter    89/  157] train: loss: 0.0497201
[Epoch 104; Iter   119/  157] train: loss: 0.0410376
[Epoch 104; Iter   149/  157] train: loss: 0.0454189
[Epoch 104] ogbg-moltox21: 0.804607 val loss: 0.272905
[Epoch 104] ogbg-moltox21: 0.805840 test loss: 0.305885
[Epoch 105; Iter    22/  157] train: loss: 0.0570998
[Epoch 105; Iter    52/  157] train: loss: 0.0356287
[Epoch 105; Iter    82/  157] train: loss: 0.0935039
[Epoch 105; Iter   112/  157] train: loss: 0.0236686
[Epoch 105; Iter   142/  157] train: loss: 0.0467103
[Epoch 105] ogbg-moltox21: 0.805735 val loss: 0.270608
[Epoch 105] ogbg-moltox21: 0.809962 test loss: 0.302001
[Epoch 106; Iter    15/  157] train: loss: 0.0420457
[Epoch 106; Iter    45/  157] train: loss: 0.0443453
[Epoch 106; Iter    75/  157] train: loss: 0.0642536
[Epoch 106; Iter   105/  157] train: loss: 0.0468156
[Epoch 106; Iter   135/  157] train: loss: 0.0518133
[Epoch 106] ogbg-moltox21: 0.801890 val loss: 0.277051
[Epoch 106] ogbg-moltox21: 0.807752 test loss: 0.306753
[Epoch 107; Iter     8/  157] train: loss: 0.0446178
[Epoch 107; Iter    38/  157] train: loss: 0.0571625
[Epoch 107; Iter    68/  157] train: loss: 0.0396193
[Epoch 107; Iter    98/  157] train: loss: 0.0467713
[Epoch 107; Iter   128/  157] train: loss: 0.0464455
[Epoch 107] ogbg-moltox21: 0.802808 val loss: 0.276919
[Epoch 107] ogbg-moltox21: 0.805576 test loss: 0.313675
[Epoch 108; Iter     1/  157] train: loss: 0.0260880
[Epoch 108; Iter    31/  157] train: loss: 0.0483699
[Epoch 108; Iter    61/  157] train: loss: 0.0359328
[Epoch 108; Iter    91/  157] train: loss: 0.0295072
[Epoch 108; Iter   121/  157] train: loss: 0.0228657
[Epoch 108; Iter   151/  157] train: loss: 0.0349834
[Epoch 108] ogbg-moltox21: 0.804084 val loss: 0.277211
[Epoch 108] ogbg-moltox21: 0.806792 test loss: 0.312061
[Epoch 109; Iter    24/  157] train: loss: 0.0456057
[Epoch 109; Iter    54/  157] train: loss: 0.0272554
[Epoch 109; Iter    84/  157] train: loss: 0.0392829
[Epoch 109; Iter   114/  157] train: loss: 0.0508090
[Epoch 109; Iter   144/  157] train: loss: 0.0495223
[Epoch 109] ogbg-moltox21: 0.801964 val loss: 0.279009
[Epoch 109] ogbg-moltox21: 0.809401 test loss: 0.308892
[Epoch 110; Iter    17/  157] train: loss: 0.0416930
[Epoch 110; Iter    47/  157] train: loss: 0.0381256
[Epoch 110; Iter    77/  157] train: loss: 0.0313347
[Epoch 110; Iter   107/  157] train: loss: 0.0284268
[Epoch 110; Iter   137/  157] train: loss: 0.0569924
[Epoch 110] ogbg-moltox21: 0.803705 val loss: 0.280243
[Epoch 110] ogbg-moltox21: 0.806497 test loss: 0.319251
[Epoch 111; Iter    10/  157] train: loss: 0.0554066
[Epoch 111; Iter    40/  157] train: loss: 0.0328270
[Epoch 111; Iter    70/  157] train: loss: 0.0477755
[Epoch 111; Iter   100/  157] train: loss: 0.0380136
[Epoch 111; Iter   130/  157] train: loss: 0.0376068
[Epoch 111] ogbg-moltox21: 0.800376 val loss: 0.286724
[Epoch 111] ogbg-moltox21: 0.808703 test loss: 0.317044
[Epoch 112; Iter     3/  157] train: loss: 0.0337310
[Epoch 112; Iter    33/  157] train: loss: 0.0433662
[Epoch 112; Iter    63/  157] train: loss: 0.0902479
[Epoch 112; Iter    93/  157] train: loss: 0.0764818
[Epoch 112; Iter   123/  157] train: loss: 0.0597438
[Epoch 112; Iter   153/  157] train: loss: 0.0460175
[Epoch 112] ogbg-moltox21: 0.808072 val loss: 0.280485
[Epoch 112] ogbg-moltox21: 0.811331 test loss: 0.316916
[Epoch 113; Iter    26/  157] train: loss: 0.0227038
[Epoch 113; Iter    56/  157] train: loss: 0.0415008
[Epoch 113; Iter    86/  157] train: loss: 0.0546130
[Epoch 113; Iter   116/  157] train: loss: 0.0328879
[Epoch 113; Iter   146/  157] train: loss: 0.0506794
[Epoch 113] ogbg-moltox21: 0.801203 val loss: 0.285433
[Epoch 113] ogbg-moltox21: 0.803615 test loss: 0.326295
[Epoch 114; Iter    19/  157] train: loss: 0.0935375
[Epoch 114; Iter    49/  157] train: loss: 0.0895826
[Epoch 114; Iter    79/  157] train: loss: 0.0613998
[Epoch 114; Iter   109/  157] train: loss: 0.0330640
[Epoch 114; Iter   139/  157] train: loss: 0.0630777
[Epoch 114] ogbg-moltox21: 0.801276 val loss: 0.282465
[Epoch 114] ogbg-moltox21: 0.804444 test loss: 0.315328
[Epoch 115; Iter    12/  157] train: loss: 0.0398960
[Epoch 115; Iter    42/  157] train: loss: 0.0519893
[Epoch 115; Iter    72/  157] train: loss: 0.0335118
[Epoch 115; Iter   102/  157] train: loss: 0.0307620
[Epoch 115; Iter   132/  157] train: loss: 0.0358816
[Epoch 115] ogbg-moltox21: 0.800882 val loss: 0.287995
[Epoch 115] ogbg-moltox21: 0.803159 test loss: 0.324283
[Epoch 116; Iter     5/  157] train: loss: 0.0662555
[Epoch 116; Iter    35/  157] train: loss: 0.0311013
[Epoch 116; Iter    65/  157] train: loss: 0.0208587
[Epoch 116; Iter    95/  157] train: loss: 0.0470080
[Epoch 116; Iter   125/  157] train: loss: 0.0400363
[Epoch 116; Iter   155/  157] train: loss: 0.0420794
[Epoch 116] ogbg-moltox21: 0.799772 val loss: 0.295008
[Epoch 116] ogbg-moltox21: 0.805645 test loss: 0.345317
[Epoch 117; Iter    28/  157] train: loss: 0.0298014
[Epoch 117; Iter    58/  157] train: loss: 0.0338413
[Epoch 117; Iter    88/  157] train: loss: 0.0529933
[Epoch 117; Iter   118/  157] train: loss: 0.0374463
[Epoch 117; Iter   148/  157] train: loss: 0.0314214
[Epoch 117] ogbg-moltox21: 0.805953 val loss: 0.283957
[Epoch 117] ogbg-moltox21: 0.810945 test loss: 0.316483
[Epoch 118; Iter    21/  157] train: loss: 0.0237860
[Epoch 118; Iter    51/  157] train: loss: 0.0309316
[Epoch 118; Iter    81/  157] train: loss: 0.0736962
[Epoch 118; Iter   111/  157] train: loss: 0.0406316
[Epoch 118; Iter   141/  157] train: loss: 0.0201226
[Epoch 118] ogbg-moltox21: 0.805867 val loss: 0.288271
[Epoch 118] ogbg-moltox21: 0.811331 test loss: 0.321322
[Epoch 119; Iter    14/  157] train: loss: 0.0212458
[Epoch 119; Iter    44/  157] train: loss: 0.0435860
[Epoch 119; Iter    74/  157] train: loss: 0.0313299
[Epoch 119; Iter   104/  157] train: loss: 0.0320223
[Epoch 119; Iter   134/  157] train: loss: 0.0281827
[Epoch 119] ogbg-moltox21: 0.802187 val loss: 0.290120
[Epoch 119] ogbg-moltox21: 0.809911 test loss: 0.322121
[Epoch 120; Iter     7/  157] train: loss: 0.0272573
[Epoch 120; Iter    37/  157] train: loss: 0.0224291
[Epoch 120; Iter    67/  157] train: loss: 0.0297292
[Epoch 120; Iter    97/  157] train: loss: 0.0384918
[Epoch 120; Iter   127/  157] train: loss: 0.0312865
[Epoch 120; Iter   157/  157] train: loss: 0.0429208
[Epoch 120] ogbg-moltox21: 0.802494 val loss: 0.289674
[Epoch 120] ogbg-moltox21: 0.806177 test loss: 0.322714
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -3.765827178955078
std_pred: 2.201429843902588
mean_targets: nan
std_targets: nan
prcauc: 0.4584650997493114
rocauc: 0.8425084149919903
ogbg-moltox21: 0.8425084149919903
OGBNanLabelBCEWithLogitsLoss: 0.18037379786091032
Statistics on  test
mean_pred: -3.7254865169525146
std_pred: 2.203630208969116
mean_targets: nan
std_targets: nan
prcauc: 0.48475987965757583
rocauc: 0.8453063826770709
ogbg-moltox21: 0.8453063826770709
mean_targets: nan
std_targets: nan
prcauc: 0.4607135000308143
rocauc: 0.841717881395049
ogbg-moltox21: 0.841717881395049
OGBNanLabelBCEWithLogitsLoss: 0.18168071868284694
Statistics on  test
mean_pred: -4.010002613067627
std_pred: 2.3544209003448486
mean_targets: nan
std_targets: nan
prcauc: 0.4443213417743201
rocauc: 0.847640369253687
ogbg-moltox21: 0.847640369253687
OGBNanLabelBCEWithLogitsLoss: 0.20625893462379025
Statistics on  train
mean_pred: -3.940033197402954
std_pred: 2.996554136276245
mean_targets: nan
std_targets: nan
prcauc: 0.6009527129122517
rocauc: 0.9223674997866776
ogbg-moltox21: 0.9223674997866776
OGBNanLabelBCEWithLogitsLoss: 0.18050568213888035
OGBNanLabelBCEWithLogitsLoss: 0.1964929903734405
Statistics on  train
mean_pred: -3.706115961074829
std_pred: 2.352674961090088
mean_targets: nan
std_targets: nan
prcauc: 0.6335653375609249
rocauc: 0.9241647160339056
ogbg-moltox21: 0.9241647160339056
OGBNanLabelBCEWithLogitsLoss: 0.14875994800667094
All runs completed.
[Epoch 99; Iter   128/  209] train: loss: 0.0392773
[Epoch 99; Iter   158/  209] train: loss: 0.0722329
[Epoch 99; Iter   188/  209] train: loss: 0.0613922
[Epoch 99] ogbg-moltox21: 0.841711 val loss: 0.316395
[Epoch 99] ogbg-moltox21: 0.827341 test loss: 0.281584
[Epoch 100; Iter     9/  209] train: loss: 0.0315063
[Epoch 100; Iter    39/  209] train: loss: 0.0676339
[Epoch 100; Iter    69/  209] train: loss: 0.0437407
[Epoch 100; Iter    99/  209] train: loss: 0.0590963
[Epoch 100; Iter   129/  209] train: loss: 0.0936301
[Epoch 100; Iter   159/  209] train: loss: 0.0401092
[Epoch 100; Iter   189/  209] train: loss: 0.0450845
[Epoch 100] ogbg-moltox21: 0.837952 val loss: 0.306758
[Epoch 100] ogbg-moltox21: 0.831554 test loss: 0.278164
[Epoch 101; Iter    10/  209] train: loss: 0.0388722
[Epoch 101; Iter    40/  209] train: loss: 0.0705338
[Epoch 101; Iter    70/  209] train: loss: 0.0755853
[Epoch 101; Iter   100/  209] train: loss: 0.0326037
[Epoch 101; Iter   130/  209] train: loss: 0.0775966
[Epoch 101; Iter   160/  209] train: loss: 0.0448435
[Epoch 101; Iter   190/  209] train: loss: 0.0407757
[Epoch 101] ogbg-moltox21: 0.835711 val loss: 0.315124
[Epoch 101] ogbg-moltox21: 0.828170 test loss: 0.287447
[Epoch 102; Iter    11/  209] train: loss: 0.0480508
[Epoch 102; Iter    41/  209] train: loss: 0.0509449
[Epoch 102; Iter    71/  209] train: loss: 0.0395012
[Epoch 102; Iter   101/  209] train: loss: 0.0666339
[Epoch 102; Iter   131/  209] train: loss: 0.0398834
[Epoch 102; Iter   161/  209] train: loss: 0.0387498
[Epoch 102; Iter   191/  209] train: loss: 0.0464990
[Epoch 102] ogbg-moltox21: 0.839525 val loss: 0.309286
[Epoch 102] ogbg-moltox21: 0.828963 test loss: 0.289803
[Epoch 103; Iter    12/  209] train: loss: 0.0437709
[Epoch 103; Iter    42/  209] train: loss: 0.0975914
[Epoch 103; Iter    72/  209] train: loss: 0.0485890
[Epoch 103; Iter   102/  209] train: loss: 0.0351645
[Epoch 103; Iter   132/  209] train: loss: 0.0749942
[Epoch 103; Iter   162/  209] train: loss: 0.0944258
[Epoch 103; Iter   192/  209] train: loss: 0.0327988
[Epoch 103] ogbg-moltox21: 0.838080 val loss: 0.315426
[Epoch 103] ogbg-moltox21: 0.831501 test loss: 0.289910
[Epoch 104; Iter    13/  209] train: loss: 0.0520377
[Epoch 104; Iter    43/  209] train: loss: 0.0422939
[Epoch 104; Iter    73/  209] train: loss: 0.0600202
[Epoch 104; Iter   103/  209] train: loss: 0.0544105
[Epoch 104; Iter   133/  209] train: loss: 0.0425957
[Epoch 104; Iter   163/  209] train: loss: 0.0369851
[Epoch 104; Iter   193/  209] train: loss: 0.1282289
[Epoch 104] ogbg-moltox21: 0.841944 val loss: 0.321934
[Epoch 104] ogbg-moltox21: 0.832881 test loss: 0.283064
[Epoch 105; Iter    14/  209] train: loss: 0.0632893
[Epoch 105; Iter    44/  209] train: loss: 0.0513423
[Epoch 105; Iter    74/  209] train: loss: 0.0471614
[Epoch 105; Iter   104/  209] train: loss: 0.0485409
[Epoch 105; Iter   134/  209] train: loss: 0.0561885
[Epoch 105; Iter   164/  209] train: loss: 0.0695982
[Epoch 105; Iter   194/  209] train: loss: 0.0363029
[Epoch 105] ogbg-moltox21: 0.838269 val loss: 0.310084
[Epoch 105] ogbg-moltox21: 0.831633 test loss: 0.290540
[Epoch 106; Iter    15/  209] train: loss: 0.0676080
[Epoch 106; Iter    45/  209] train: loss: 0.0705472
[Epoch 106; Iter    75/  209] train: loss: 0.0607103
[Epoch 106; Iter   105/  209] train: loss: 0.0484206
[Epoch 106; Iter   135/  209] train: loss: 0.0678516
[Epoch 106; Iter   165/  209] train: loss: 0.0323693
[Epoch 106; Iter   195/  209] train: loss: 0.0629346
[Epoch 106] ogbg-moltox21: 0.837491 val loss: 0.334579
[Epoch 106] ogbg-moltox21: 0.831819 test loss: 0.287387
[Epoch 107; Iter    16/  209] train: loss: 0.0306438
[Epoch 107; Iter    46/  209] train: loss: 0.0562554
[Epoch 107; Iter    76/  209] train: loss: 0.0619202
[Epoch 107; Iter   106/  209] train: loss: 0.0700752
[Epoch 107; Iter   136/  209] train: loss: 0.0328781
[Epoch 107; Iter   166/  209] train: loss: 0.0621662
[Epoch 107; Iter   196/  209] train: loss: 0.0534088
[Epoch 107] ogbg-moltox21: 0.838792 val loss: 0.314071
[Epoch 107] ogbg-moltox21: 0.825492 test loss: 0.294004
[Epoch 108; Iter    17/  209] train: loss: 0.0430242
[Epoch 108; Iter    47/  209] train: loss: 0.0544928
[Epoch 108; Iter    77/  209] train: loss: 0.0470183
[Epoch 108; Iter   107/  209] train: loss: 0.0544398
[Epoch 108; Iter   137/  209] train: loss: 0.0268211
[Epoch 108; Iter   167/  209] train: loss: 0.0486744
[Epoch 108; Iter   197/  209] train: loss: 0.0990503
[Epoch 108] ogbg-moltox21: 0.836789 val loss: 0.309422
[Epoch 108] ogbg-moltox21: 0.826851 test loss: 0.289807
[Epoch 109; Iter    18/  209] train: loss: 0.0680153
[Epoch 109; Iter    48/  209] train: loss: 0.0227558
[Epoch 109; Iter    78/  209] train: loss: 0.0449944
[Epoch 109; Iter   108/  209] train: loss: 0.0393127
[Epoch 109; Iter   138/  209] train: loss: 0.0566097
[Epoch 109; Iter   168/  209] train: loss: 0.0324102
[Epoch 109; Iter   198/  209] train: loss: 0.0481718
[Epoch 109] ogbg-moltox21: 0.836228 val loss: 0.313921
[Epoch 109] ogbg-moltox21: 0.828924 test loss: 0.302303
[Epoch 110; Iter    19/  209] train: loss: 0.0594256
[Epoch 110; Iter    49/  209] train: loss: 0.0510368
[Epoch 110; Iter    79/  209] train: loss: 0.0286893
[Epoch 110; Iter   109/  209] train: loss: 0.0482683
[Epoch 110; Iter   139/  209] train: loss: 0.0632911
[Epoch 110; Iter   169/  209] train: loss: 0.0970116
[Epoch 110; Iter   199/  209] train: loss: 0.0911002
[Epoch 110] ogbg-moltox21: 0.834838 val loss: 0.330709
[Epoch 110] ogbg-moltox21: 0.827413 test loss: 0.293318
[Epoch 111; Iter    20/  209] train: loss: 0.0643003
[Epoch 111; Iter    50/  209] train: loss: 0.0789766
[Epoch 111; Iter    80/  209] train: loss: 0.0348080
[Epoch 111; Iter   110/  209] train: loss: 0.0777248
[Epoch 111; Iter   140/  209] train: loss: 0.1060169
[Epoch 111; Iter   170/  209] train: loss: 0.0542169
[Epoch 111; Iter   200/  209] train: loss: 0.0341779
[Epoch 111] ogbg-moltox21: 0.836388 val loss: 0.323902
[Epoch 111] ogbg-moltox21: 0.828661 test loss: 0.293653
[Epoch 112; Iter    21/  209] train: loss: 0.0617786
[Epoch 112; Iter    51/  209] train: loss: 0.0528781
[Epoch 112; Iter    81/  209] train: loss: 0.1290451
[Epoch 112; Iter   111/  209] train: loss: 0.0731832
[Epoch 112; Iter   141/  209] train: loss: 0.0445324
[Epoch 112; Iter   171/  209] train: loss: 0.0363773
[Epoch 112; Iter   201/  209] train: loss: 0.0216902
[Epoch 112] ogbg-moltox21: 0.837628 val loss: 0.307557
[Epoch 112] ogbg-moltox21: 0.829422 test loss: 0.303533
[Epoch 113; Iter    22/  209] train: loss: 0.0461466
[Epoch 113; Iter    52/  209] train: loss: 0.0165918
[Epoch 113; Iter    82/  209] train: loss: 0.0855737
[Epoch 113; Iter   112/  209] train: loss: 0.0262557
[Epoch 113; Iter   142/  209] train: loss: 0.0543031
[Epoch 113; Iter   172/  209] train: loss: 0.0540489
[Epoch 113; Iter   202/  209] train: loss: 0.0518704
[Epoch 113] ogbg-moltox21: 0.839125 val loss: 0.344280
[Epoch 113] ogbg-moltox21: 0.828031 test loss: 0.293097
[Epoch 114; Iter    23/  209] train: loss: 0.0605392
[Epoch 114; Iter    53/  209] train: loss: 0.0294807
[Epoch 114; Iter    83/  209] train: loss: 0.0706360
[Epoch 114; Iter   113/  209] train: loss: 0.0482801
[Epoch 114; Iter   143/  209] train: loss: 0.0401709
[Epoch 114; Iter   173/  209] train: loss: 0.0495828
[Epoch 114; Iter   203/  209] train: loss: 0.0528614
[Epoch 114] ogbg-moltox21: 0.840154 val loss: 0.355540
[Epoch 114] ogbg-moltox21: 0.828273 test loss: 0.304522
[Epoch 115; Iter    24/  209] train: loss: 0.0589665
[Epoch 115; Iter    54/  209] train: loss: 0.0514295
[Epoch 115; Iter    84/  209] train: loss: 0.0467460
[Epoch 115; Iter   114/  209] train: loss: 0.0619305
[Epoch 115; Iter   144/  209] train: loss: 0.0344911
[Epoch 115; Iter   174/  209] train: loss: 0.0357862
[Epoch 115; Iter   204/  209] train: loss: 0.0270569
[Epoch 115] ogbg-moltox21: 0.832285 val loss: 0.353106
[Epoch 115] ogbg-moltox21: 0.831023 test loss: 0.303012
[Epoch 116; Iter    25/  209] train: loss: 0.0314040
[Epoch 116; Iter    55/  209] train: loss: 0.0386065
[Epoch 116; Iter    85/  209] train: loss: 0.0391432
[Epoch 116; Iter   115/  209] train: loss: 0.0351150
[Epoch 99; Iter   128/  209] train: loss: 0.0818646
[Epoch 99; Iter   158/  209] train: loss: 0.0843023
[Epoch 99; Iter   188/  209] train: loss: 0.0355423
[Epoch 99] ogbg-moltox21: 0.829774 val loss: 0.309754
[Epoch 99] ogbg-moltox21: 0.813873 test loss: 0.293347
[Epoch 100; Iter     9/  209] train: loss: 0.0408678
[Epoch 100; Iter    39/  209] train: loss: 0.0456644
[Epoch 100; Iter    69/  209] train: loss: 0.0470033
[Epoch 100; Iter    99/  209] train: loss: 0.0906068
[Epoch 100; Iter   129/  209] train: loss: 0.0622244
[Epoch 100; Iter   159/  209] train: loss: 0.0554202
[Epoch 100; Iter   189/  209] train: loss: 0.0537584
[Epoch 100] ogbg-moltox21: 0.828356 val loss: 0.304118
[Epoch 100] ogbg-moltox21: 0.808999 test loss: 0.298649
[Epoch 101; Iter    10/  209] train: loss: 0.0417519
[Epoch 101; Iter    40/  209] train: loss: 0.0601321
[Epoch 101; Iter    70/  209] train: loss: 0.0553615
[Epoch 101; Iter   100/  209] train: loss: 0.0872692
[Epoch 101; Iter   130/  209] train: loss: 0.0528066
[Epoch 101; Iter   160/  209] train: loss: 0.0266921
[Epoch 101; Iter   190/  209] train: loss: 0.0799732
[Epoch 101] ogbg-moltox21: 0.824626 val loss: 0.312251
[Epoch 101] ogbg-moltox21: 0.809060 test loss: 0.299236
[Epoch 102; Iter    11/  209] train: loss: 0.0323723
[Epoch 102; Iter    41/  209] train: loss: 0.0700567
[Epoch 102; Iter    71/  209] train: loss: 0.0558470
[Epoch 102; Iter   101/  209] train: loss: 0.0720298
[Epoch 102; Iter   131/  209] train: loss: 0.0234107
[Epoch 102; Iter   161/  209] train: loss: 0.0736053
[Epoch 102; Iter   191/  209] train: loss: 0.0533507
[Epoch 102] ogbg-moltox21: 0.828818 val loss: 0.310097
[Epoch 102] ogbg-moltox21: 0.815282 test loss: 0.288997
[Epoch 103; Iter    12/  209] train: loss: 0.0464285
[Epoch 103; Iter    42/  209] train: loss: 0.0520189
[Epoch 103; Iter    72/  209] train: loss: 0.0730695
[Epoch 103; Iter   102/  209] train: loss: 0.0650389
[Epoch 103; Iter   132/  209] train: loss: 0.0541833
[Epoch 103; Iter   162/  209] train: loss: 0.0299935
[Epoch 103; Iter   192/  209] train: loss: 0.0705193
[Epoch 103] ogbg-moltox21: 0.827519 val loss: 0.309528
[Epoch 103] ogbg-moltox21: 0.814504 test loss: 0.296232
[Epoch 104; Iter    13/  209] train: loss: 0.1335125
[Epoch 104; Iter    43/  209] train: loss: 0.0583670
[Epoch 104; Iter    73/  209] train: loss: 0.0704047
[Epoch 104; Iter   103/  209] train: loss: 0.0310204
[Epoch 104; Iter   133/  209] train: loss: 0.0742586
[Epoch 104; Iter   163/  209] train: loss: 0.0488770
[Epoch 104; Iter   193/  209] train: loss: 0.0593190
[Epoch 104] ogbg-moltox21: 0.826631 val loss: 0.313611
[Epoch 104] ogbg-moltox21: 0.814359 test loss: 0.299660
[Epoch 105; Iter    14/  209] train: loss: 0.0552369
[Epoch 105; Iter    44/  209] train: loss: 0.0712391
[Epoch 105; Iter    74/  209] train: loss: 0.0730195
[Epoch 105; Iter   104/  209] train: loss: 0.0611944
[Epoch 105; Iter   134/  209] train: loss: 0.0401897
[Epoch 105; Iter   164/  209] train: loss: 0.0616859
[Epoch 105; Iter   194/  209] train: loss: 0.0595086
[Epoch 105] ogbg-moltox21: 0.824402 val loss: 0.316612
[Epoch 105] ogbg-moltox21: 0.810191 test loss: 0.299367
[Epoch 106; Iter    15/  209] train: loss: 0.0225468
[Epoch 106; Iter    45/  209] train: loss: 0.0562713
[Epoch 106; Iter    75/  209] train: loss: 0.1364183
[Epoch 106; Iter   105/  209] train: loss: 0.0370102
[Epoch 106; Iter   135/  209] train: loss: 0.1307193
[Epoch 106; Iter   165/  209] train: loss: 0.0360145
[Epoch 106; Iter   195/  209] train: loss: 0.0497834
[Epoch 106] ogbg-moltox21: 0.830351 val loss: 0.310372
[Epoch 106] ogbg-moltox21: 0.818142 test loss: 0.291949
[Epoch 107; Iter    16/  209] train: loss: 0.0547260
[Epoch 107; Iter    46/  209] train: loss: 0.0595597
[Epoch 107; Iter    76/  209] train: loss: 0.0696194
[Epoch 107; Iter   106/  209] train: loss: 0.0377273
[Epoch 107; Iter   136/  209] train: loss: 0.0638210
[Epoch 107; Iter   166/  209] train: loss: 0.0578503
[Epoch 107; Iter   196/  209] train: loss: 0.0321015
[Epoch 107] ogbg-moltox21: 0.826744 val loss: 0.310626
[Epoch 107] ogbg-moltox21: 0.813108 test loss: 0.301373
[Epoch 108; Iter    17/  209] train: loss: 0.0475626
[Epoch 108; Iter    47/  209] train: loss: 0.0335369
[Epoch 108; Iter    77/  209] train: loss: 0.1040752
[Epoch 108; Iter   107/  209] train: loss: 0.0551673
[Epoch 108; Iter   137/  209] train: loss: 0.0272047
[Epoch 108; Iter   167/  209] train: loss: 0.0485128
[Epoch 108; Iter   197/  209] train: loss: 0.0432253
[Epoch 108] ogbg-moltox21: 0.833525 val loss: 0.315146
[Epoch 108] ogbg-moltox21: 0.823074 test loss: 0.295460
[Epoch 109; Iter    18/  209] train: loss: 0.0399992
[Epoch 109; Iter    48/  209] train: loss: 0.0336509
[Epoch 109; Iter    78/  209] train: loss: 0.0307267
[Epoch 109; Iter   108/  209] train: loss: 0.0420524
[Epoch 109; Iter   138/  209] train: loss: 0.0292779
[Epoch 109; Iter   168/  209] train: loss: 0.0542940
[Epoch 109; Iter   198/  209] train: loss: 0.0382295
[Epoch 109] ogbg-moltox21: 0.825518 val loss: 0.313978
[Epoch 109] ogbg-moltox21: 0.809813 test loss: 0.312041
[Epoch 110; Iter    19/  209] train: loss: 0.0494679
[Epoch 110; Iter    49/  209] train: loss: 0.0636559
[Epoch 110; Iter    79/  209] train: loss: 0.0649166
[Epoch 110; Iter   109/  209] train: loss: 0.0386136
[Epoch 110; Iter   139/  209] train: loss: 0.0264996
[Epoch 110; Iter   169/  209] train: loss: 0.0491972
[Epoch 110; Iter   199/  209] train: loss: 0.0410164
[Epoch 110] ogbg-moltox21: 0.831924 val loss: 0.315106
[Epoch 110] ogbg-moltox21: 0.822328 test loss: 0.291190
[Epoch 111; Iter    20/  209] train: loss: 0.0435024
[Epoch 111; Iter    50/  209] train: loss: 0.0361722
[Epoch 111; Iter    80/  209] train: loss: 0.0466720
[Epoch 111; Iter   110/  209] train: loss: 0.0364504
[Epoch 111; Iter   140/  209] train: loss: 0.0388926
[Epoch 111; Iter   170/  209] train: loss: 0.0470189
[Epoch 111; Iter   200/  209] train: loss: 0.0471105
[Epoch 111] ogbg-moltox21: 0.828786 val loss: 0.326524
[Epoch 111] ogbg-moltox21: 0.815652 test loss: 0.307822
[Epoch 112; Iter    21/  209] train: loss: 0.0644424
[Epoch 112; Iter    51/  209] train: loss: 0.0323633
[Epoch 112; Iter    81/  209] train: loss: 0.0379691
[Epoch 112; Iter   111/  209] train: loss: 0.0300391
[Epoch 112; Iter   141/  209] train: loss: 0.0975049
[Epoch 112; Iter   171/  209] train: loss: 0.0404149
[Epoch 112; Iter   201/  209] train: loss: 0.0781357
[Epoch 112] ogbg-moltox21: 0.832330 val loss: 0.314484
[Epoch 112] ogbg-moltox21: 0.817039 test loss: 0.303533
[Epoch 113; Iter    22/  209] train: loss: 0.0475501
[Epoch 113; Iter    52/  209] train: loss: 0.0279522
[Epoch 113; Iter    82/  209] train: loss: 0.0688114
[Epoch 113; Iter   112/  209] train: loss: 0.0654613
[Epoch 113; Iter   142/  209] train: loss: 0.0642571
[Epoch 113; Iter   172/  209] train: loss: 0.0411013
[Epoch 113; Iter   202/  209] train: loss: 0.0406062
[Epoch 113] ogbg-moltox21: 0.830500 val loss: 0.323875
[Epoch 113] ogbg-moltox21: 0.816890 test loss: 0.300471
[Epoch 114; Iter    23/  209] train: loss: 0.0792482
[Epoch 114; Iter    53/  209] train: loss: 0.0451364
[Epoch 114; Iter    83/  209] train: loss: 0.0685337
[Epoch 114; Iter   113/  209] train: loss: 0.0510786
[Epoch 114; Iter   143/  209] train: loss: 0.0502635
[Epoch 114; Iter   173/  209] train: loss: 0.0434462
[Epoch 114; Iter   203/  209] train: loss: 0.0689129
[Epoch 114] ogbg-moltox21: 0.833624 val loss: 0.314574
[Epoch 114] ogbg-moltox21: 0.817255 test loss: 0.299196
[Epoch 115; Iter    24/  209] train: loss: 0.0314035
[Epoch 115; Iter    54/  209] train: loss: 0.0472270
[Epoch 115; Iter    84/  209] train: loss: 0.0322055
[Epoch 115; Iter   114/  209] train: loss: 0.0377067
[Epoch 115; Iter   144/  209] train: loss: 0.0446111
[Epoch 115; Iter   174/  209] train: loss: 0.0341885
[Epoch 115; Iter   204/  209] train: loss: 0.0764921
[Epoch 115] ogbg-moltox21: 0.822320 val loss: 0.334506
[Epoch 115] ogbg-moltox21: 0.815906 test loss: 0.310959
[Epoch 116; Iter    25/  209] train: loss: 0.0333599
[Epoch 116; Iter    55/  209] train: loss: 0.0579563
[Epoch 116; Iter    85/  209] train: loss: 0.0434889
[Epoch 116; Iter   115/  209] train: loss: 0.0442350
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109] ogbg-moltox21: 0.826274 test loss: 0.269362
[Epoch 110; Iter     3/  183] train: loss: 0.0633535
[Epoch 110; Iter    33/  183] train: loss: 0.0676392
[Epoch 110; Iter    63/  183] train: loss: 0.0620913
[Epoch 110; Iter    93/  183] train: loss: 0.0561148
[Epoch 110; Iter   123/  183] train: loss: 0.0584575
[Epoch 110; Iter   153/  183] train: loss: 0.0697337
[Epoch 110; Iter   183/  183] train: loss: 0.0854213
[Epoch 110] ogbg-moltox21: 0.818523 val loss: 0.311640
[Epoch 110] ogbg-moltox21: 0.823799 test loss: 0.274354
[Epoch 111; Iter    30/  183] train: loss: 0.0371177
[Epoch 111; Iter    60/  183] train: loss: 0.0886841
[Epoch 111; Iter    90/  183] train: loss: 0.0820766
[Epoch 111; Iter   120/  183] train: loss: 0.0523603
[Epoch 111; Iter   150/  183] train: loss: 0.0470607
[Epoch 111; Iter   180/  183] train: loss: 0.0418048
[Epoch 111] ogbg-moltox21: 0.815704 val loss: 0.285098
[Epoch 111] ogbg-moltox21: 0.822933 test loss: 0.271468
[Epoch 112; Iter    27/  183] train: loss: 0.0440563
[Epoch 112; Iter    57/  183] train: loss: 0.0510309
[Epoch 112; Iter    87/  183] train: loss: 0.0709290
[Epoch 112; Iter   117/  183] train: loss: 0.1067984
[Epoch 112; Iter   147/  183] train: loss: 0.0778469
[Epoch 112; Iter   177/  183] train: loss: 0.0416152
[Epoch 112] ogbg-moltox21: 0.820680 val loss: 0.281546
[Epoch 112] ogbg-moltox21: 0.824024 test loss: 0.269470
[Epoch 113; Iter    24/  183] train: loss: 0.0471224
[Epoch 113; Iter    54/  183] train: loss: 0.0440493
[Epoch 113; Iter    84/  183] train: loss: 0.0881991
[Epoch 113; Iter   114/  183] train: loss: 0.0788664
[Epoch 113; Iter   144/  183] train: loss: 0.0612219
[Epoch 113; Iter   174/  183] train: loss: 0.0289638
[Epoch 113] ogbg-moltox21: 0.820766 val loss: 0.266828
[Epoch 113] ogbg-moltox21: 0.829623 test loss: 0.268883
[Epoch 114; Iter    21/  183] train: loss: 0.0490382
[Epoch 114; Iter    51/  183] train: loss: 0.0380640
[Epoch 114; Iter    81/  183] train: loss: 0.0254214
[Epoch 114; Iter   111/  183] train: loss: 0.0628874
[Epoch 114; Iter   141/  183] train: loss: 0.0569370
[Epoch 114; Iter   171/  183] train: loss: 0.0448301
[Epoch 114] ogbg-moltox21: 0.815733 val loss: 0.270552
[Epoch 114] ogbg-moltox21: 0.826850 test loss: 0.266080
[Epoch 115; Iter    18/  183] train: loss: 0.0971988
[Epoch 115; Iter    48/  183] train: loss: 0.0619119
[Epoch 115; Iter    78/  183] train: loss: 0.0591300
[Epoch 115; Iter   108/  183] train: loss: 0.0518606
[Epoch 115; Iter   138/  183] train: loss: 0.0373988
[Epoch 115; Iter   168/  183] train: loss: 0.0688353
[Epoch 115] ogbg-moltox21: 0.816256 val loss: 0.312467
[Epoch 115] ogbg-moltox21: 0.822465 test loss: 0.270423
[Epoch 116; Iter    15/  183] train: loss: 0.0729843
[Epoch 116; Iter    45/  183] train: loss: 0.1043669
[Epoch 116; Iter    75/  183] train: loss: 0.0683216
[Epoch 116; Iter   105/  183] train: loss: 0.0860668
[Epoch 116; Iter   135/  183] train: loss: 0.0363550
[Epoch 116; Iter   165/  183] train: loss: 0.0572177
[Epoch 116] ogbg-moltox21: 0.814672 val loss: 0.303293
[Epoch 116] ogbg-moltox21: 0.819460 test loss: 0.278797
[Epoch 117; Iter    12/  183] train: loss: 0.0822503
[Epoch 117; Iter    42/  183] train: loss: 0.0748894
[Epoch 117; Iter    72/  183] train: loss: 0.0956957
[Epoch 117; Iter   102/  183] train: loss: 0.0737497
[Epoch 117; Iter   132/  183] train: loss: 0.0605395
[Epoch 117; Iter   162/  183] train: loss: 0.1023503
[Epoch 117] ogbg-moltox21: 0.816535 val loss: 0.275225
[Epoch 117] ogbg-moltox21: 0.819807 test loss: 0.273414
[Epoch 118; Iter     9/  183] train: loss: 0.0368149
[Epoch 118; Iter    39/  183] train: loss: 0.0605325
[Epoch 118; Iter    69/  183] train: loss: 0.0827790
[Epoch 118; Iter    99/  183] train: loss: 0.0392137
[Epoch 118; Iter   129/  183] train: loss: 0.0441723
[Epoch 118; Iter   159/  183] train: loss: 0.0563679
[Epoch 118] ogbg-moltox21: 0.816120 val loss: 0.287785
[Epoch 118] ogbg-moltox21: 0.823094 test loss: 0.278363
[Epoch 119; Iter     6/  183] train: loss: 0.0418422
[Epoch 119; Iter    36/  183] train: loss: 0.0729607
[Epoch 119; Iter    66/  183] train: loss: 0.0507760
[Epoch 119; Iter    96/  183] train: loss: 0.0870010
[Epoch 119; Iter   126/  183] train: loss: 0.0843021
[Epoch 119; Iter   156/  183] train: loss: 0.0439527
[Epoch 119] ogbg-moltox21: 0.815505 val loss: 0.288013
[Epoch 119] ogbg-moltox21: 0.824290 test loss: 0.278073
[Epoch 120; Iter     3/  183] train: loss: 0.0540144
[Epoch 120; Iter    33/  183] train: loss: 0.0631106
[Epoch 120; Iter    63/  183] train: loss: 0.0593255
[Epoch 120; Iter    93/  183] train: loss: 0.0836715
[Epoch 120; Iter   123/  183] train: loss: 0.0759244
[Epoch 120; Iter   153/  183] train: loss: 0.0729136
[Epoch 120; Iter   183/  183] train: loss: 0.0322454
[Epoch 120] ogbg-moltox21: 0.818342 val loss: 0.309474
[Epoch 120] ogbg-moltox21: 0.821642 test loss: 0.286287
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 51.
Statistics on  val_best_checkpoint
mean_pred: -3.9443910121917725
std_pred: 3.370673656463623
mean_targets: nan
std_targets: nan
prcauc: 0.4441489252762853
rocauc: 0.8463822177952455
ogbg-moltox21: 0.8463822177952455
OGBNanLabelBCEWithLogitsLoss: 0.19377148970961572
Statistics on  test
mean_pred: -3.957740306854248
std_pred: 2.3078324794769287
mean_targets: nan
std_targets: nan
prcauc: 0.48181439410741395
rocauc: 0.8474267616498717
ogbg-moltox21: 0.8474267616498717
OGBNanLabelBCEWithLogitsLoss: 0.19457454234361649
Statistics on  train
mean_pred: -3.9891653060913086
std_pred: 3.2258169651031494
mean_targets: nan
std_targets: nan
prcauc: 0.5956761048800616
rocauc: 0.9137311157679301
ogbg-moltox21: 0.9137311157679301
OGBNanLabelBCEWithLogitsLoss: 0.17039969563484192
[Epoch 99; Iter   128/  209] train: loss: 0.0762531
[Epoch 99; Iter   158/  209] train: loss: 0.0568802
[Epoch 99; Iter   188/  209] train: loss: 0.0537742
[Epoch 99] ogbg-moltox21: 0.829596 val loss: 0.281478
[Epoch 99] ogbg-moltox21: 0.809487 test loss: 0.255978
[Epoch 100; Iter     9/  209] train: loss: 0.0305359
[Epoch 100; Iter    39/  209] train: loss: 0.0344647
[Epoch 100; Iter    69/  209] train: loss: 0.0536361
[Epoch 100; Iter    99/  209] train: loss: 0.0419064
[Epoch 100; Iter   129/  209] train: loss: 0.0576752
[Epoch 100; Iter   159/  209] train: loss: 0.0646584
[Epoch 100; Iter   189/  209] train: loss: 0.0488499
[Epoch 100] ogbg-moltox21: 0.828620 val loss: 0.289843
[Epoch 100] ogbg-moltox21: 0.812938 test loss: 0.255918
[Epoch 101; Iter    10/  209] train: loss: 0.0671648
[Epoch 101; Iter    40/  209] train: loss: 0.0478991
[Epoch 101; Iter    70/  209] train: loss: 0.0488251
[Epoch 101; Iter   100/  209] train: loss: 0.0576826
[Epoch 101; Iter   130/  209] train: loss: 0.1036611
[Epoch 101; Iter   160/  209] train: loss: 0.1048645
[Epoch 101; Iter   190/  209] train: loss: 0.0555275
[Epoch 101] ogbg-moltox21: 0.829878 val loss: 0.290948
[Epoch 101] ogbg-moltox21: 0.809578 test loss: 0.261159
[Epoch 102; Iter    11/  209] train: loss: 0.0722492
[Epoch 102; Iter    41/  209] train: loss: 0.0887342
[Epoch 102; Iter    71/  209] train: loss: 0.0889152
[Epoch 102; Iter   101/  209] train: loss: 0.0577425
[Epoch 102; Iter   131/  209] train: loss: 0.0517179
[Epoch 102; Iter   161/  209] train: loss: 0.1089306
[Epoch 102; Iter   191/  209] train: loss: 0.0655107
[Epoch 102] ogbg-moltox21: 0.830422 val loss: 0.286385
[Epoch 102] ogbg-moltox21: 0.813758 test loss: 0.255572
[Epoch 103; Iter    12/  209] train: loss: 0.0487517
[Epoch 103; Iter    42/  209] train: loss: 0.0460181
[Epoch 103; Iter    72/  209] train: loss: 0.0656662
[Epoch 103; Iter   102/  209] train: loss: 0.1261213
[Epoch 103; Iter   132/  209] train: loss: 0.0755996
[Epoch 103; Iter   162/  209] train: loss: 0.0652232
[Epoch 103; Iter   192/  209] train: loss: 0.0273515
[Epoch 103] ogbg-moltox21: 0.826787 val loss: 0.292897
[Epoch 103] ogbg-moltox21: 0.809774 test loss: 0.259644
[Epoch 104; Iter    13/  209] train: loss: 0.0383352
[Epoch 104; Iter    43/  209] train: loss: 0.0605783
[Epoch 104; Iter    73/  209] train: loss: 0.0419674
[Epoch 104; Iter   103/  209] train: loss: 0.0698850
[Epoch 104; Iter   133/  209] train: loss: 0.0584630
[Epoch 104; Iter   163/  209] train: loss: 0.0406755
[Epoch 104; Iter   193/  209] train: loss: 0.0745066
[Epoch 104] ogbg-moltox21: 0.822077 val loss: 0.292790
[Epoch 104] ogbg-moltox21: 0.805662 test loss: 0.265770
[Epoch 105; Iter    14/  209] train: loss: 0.0667441
[Epoch 105; Iter    44/  209] train: loss: 0.0358484
[Epoch 105; Iter    74/  209] train: loss: 0.0737733
[Epoch 105; Iter   104/  209] train: loss: 0.0468323
[Epoch 105; Iter   134/  209] train: loss: 0.0587200
[Epoch 105; Iter   164/  209] train: loss: 0.0712937
[Epoch 105; Iter   194/  209] train: loss: 0.0675971
[Epoch 105] ogbg-moltox21: 0.822785 val loss: 0.299269
[Epoch 105] ogbg-moltox21: 0.812182 test loss: 0.258305
[Epoch 106; Iter    15/  209] train: loss: 0.0362386
[Epoch 106; Iter    45/  209] train: loss: 0.0874544
[Epoch 106; Iter    75/  209] train: loss: 0.0457465
[Epoch 106; Iter   105/  209] train: loss: 0.0716433
[Epoch 106; Iter   135/  209] train: loss: 0.0612519
[Epoch 106; Iter   165/  209] train: loss: 0.0488975
[Epoch 106; Iter   195/  209] train: loss: 0.0900961
[Epoch 106] ogbg-moltox21: 0.833153 val loss: 0.285164
[Epoch 106] ogbg-moltox21: 0.812614 test loss: 0.259775
[Epoch 107; Iter    16/  209] train: loss: 0.0421692
[Epoch 107; Iter    46/  209] train: loss: 0.0503361
[Epoch 107; Iter    76/  209] train: loss: 0.0519767
[Epoch 107; Iter   106/  209] train: loss: 0.0512308
[Epoch 107; Iter   136/  209] train: loss: 0.0513640
[Epoch 107; Iter   166/  209] train: loss: 0.0507491
[Epoch 107; Iter   196/  209] train: loss: 0.0756476
[Epoch 107] ogbg-moltox21: 0.829203 val loss: 0.297427
[Epoch 107] ogbg-moltox21: 0.810821 test loss: 0.265748
[Epoch 108; Iter    17/  209] train: loss: 0.0355311
[Epoch 108; Iter    47/  209] train: loss: 0.0715352
[Epoch 108; Iter    77/  209] train: loss: 0.0933624
[Epoch 108; Iter   107/  209] train: loss: 0.0403084
[Epoch 108; Iter   137/  209] train: loss: 0.0789088
[Epoch 108; Iter   167/  209] train: loss: 0.0523844
[Epoch 108; Iter   197/  209] train: loss: 0.0744328
[Epoch 108] ogbg-moltox21: 0.826082 val loss: 0.300399
[Epoch 108] ogbg-moltox21: 0.804078 test loss: 0.269046
[Epoch 109; Iter    18/  209] train: loss: 0.0526007
[Epoch 109; Iter    48/  209] train: loss: 0.1058010
[Epoch 109; Iter    78/  209] train: loss: 0.1043225
[Epoch 109; Iter   108/  209] train: loss: 0.0479185
[Epoch 109; Iter   138/  209] train: loss: 0.0634647
[Epoch 109; Iter   168/  209] train: loss: 0.0484591
[Epoch 109; Iter   198/  209] train: loss: 0.0591711
[Epoch 109] ogbg-moltox21: 0.828887 val loss: 0.296577
[Epoch 109] ogbg-moltox21: 0.811517 test loss: 0.259614
[Epoch 110; Iter    19/  209] train: loss: 0.0263327
[Epoch 110; Iter    49/  209] train: loss: 0.0436610
[Epoch 110; Iter    79/  209] train: loss: 0.0623979
[Epoch 110; Iter   109/  209] train: loss: 0.0589229
[Epoch 110; Iter   139/  209] train: loss: 0.0542986
[Epoch 110; Iter   169/  209] train: loss: 0.0317664
[Epoch 110; Iter   199/  209] train: loss: 0.0959251
[Epoch 110] ogbg-moltox21: 0.822492 val loss: 0.306044
[Epoch 110] ogbg-moltox21: 0.807860 test loss: 0.267525
[Epoch 111; Iter    20/  209] train: loss: 0.0587849
[Epoch 111; Iter    50/  209] train: loss: 0.0865722
[Epoch 111; Iter    80/  209] train: loss: 0.0283461
[Epoch 111; Iter   110/  209] train: loss: 0.1161470
[Epoch 111; Iter   140/  209] train: loss: 0.0369263
[Epoch 111; Iter   170/  209] train: loss: 0.0419389
[Epoch 111; Iter   200/  209] train: loss: 0.0511857
[Epoch 111] ogbg-moltox21: 0.828403 val loss: 0.312413
[Epoch 111] ogbg-moltox21: 0.812049 test loss: 0.273890
[Epoch 112; Iter    21/  209] train: loss: 0.0795074
[Epoch 112; Iter    51/  209] train: loss: 0.0518402
[Epoch 112; Iter    81/  209] train: loss: 0.0620710
[Epoch 112; Iter   111/  209] train: loss: 0.0392831
[Epoch 112; Iter   141/  209] train: loss: 0.0561464
[Epoch 112; Iter   171/  209] train: loss: 0.0631472
[Epoch 112; Iter   201/  209] train: loss: 0.0539362
[Epoch 112] ogbg-moltox21: 0.825598 val loss: 0.307169
[Epoch 112] ogbg-moltox21: 0.805668 test loss: 0.272016
[Epoch 113; Iter    22/  209] train: loss: 0.0310266
[Epoch 113; Iter    52/  209] train: loss: 0.0315217
[Epoch 113; Iter    82/  209] train: loss: 0.0580171
[Epoch 113; Iter   112/  209] train: loss: 0.0789732
[Epoch 113; Iter   142/  209] train: loss: 0.0650374
[Epoch 113; Iter   172/  209] train: loss: 0.0740184
[Epoch 113; Iter   202/  209] train: loss: 0.0510887
[Epoch 113] ogbg-moltox21: 0.826551 val loss: 0.305512
[Epoch 113] ogbg-moltox21: 0.807995 test loss: 0.270271
[Epoch 114; Iter    23/  209] train: loss: 0.0601351
[Epoch 114; Iter    53/  209] train: loss: 0.0987290
[Epoch 114; Iter    83/  209] train: loss: 0.0813689
[Epoch 114; Iter   113/  209] train: loss: 0.0398401
[Epoch 114; Iter   143/  209] train: loss: 0.0493230
[Epoch 114; Iter   173/  209] train: loss: 0.0526075
[Epoch 114; Iter   203/  209] train: loss: 0.0437561
[Epoch 114] ogbg-moltox21: 0.826388 val loss: 0.298975
[Epoch 114] ogbg-moltox21: 0.804017 test loss: 0.273185
[Epoch 115; Iter    24/  209] train: loss: 0.0385896
[Epoch 115; Iter    54/  209] train: loss: 0.0812900
[Epoch 115; Iter    84/  209] train: loss: 0.0747684
[Epoch 115; Iter   114/  209] train: loss: 0.0329336
[Epoch 115; Iter   144/  209] train: loss: 0.0528949
[Epoch 115; Iter   174/  209] train: loss: 0.0439117
[Epoch 115; Iter   204/  209] train: loss: 0.0324731
[Epoch 115] ogbg-moltox21: 0.825119 val loss: 0.303788
[Epoch 115] ogbg-moltox21: 0.809056 test loss: 0.270535
[Epoch 116; Iter    25/  209] train: loss: 0.0448347
[Epoch 116; Iter    55/  209] train: loss: 0.0304834
[Epoch 116; Iter    85/  209] train: loss: 0.0592480
[Epoch 116; Iter   115/  209] train: loss: 0.0391702
[Epoch 109] ogbg-moltox21: 0.807721 test loss: 0.298455
[Epoch 110; Iter     3/  183] train: loss: 0.0767269
[Epoch 110; Iter    33/  183] train: loss: 0.0387902
[Epoch 110; Iter    63/  183] train: loss: 0.0327589
[Epoch 110; Iter    93/  183] train: loss: 0.0249235
[Epoch 110; Iter   123/  183] train: loss: 0.0426482
[Epoch 110; Iter   153/  183] train: loss: 0.0273227
[Epoch 110; Iter   183/  183] train: loss: 0.1168893
[Epoch 110] ogbg-moltox21: 0.798439 val loss: 0.289689
[Epoch 110] ogbg-moltox21: 0.810248 test loss: 0.292723
[Epoch 111; Iter    30/  183] train: loss: 0.0584975
[Epoch 111; Iter    60/  183] train: loss: 0.0399004
[Epoch 111; Iter    90/  183] train: loss: 0.0244178
[Epoch 111; Iter   120/  183] train: loss: 0.0468415
[Epoch 111; Iter   150/  183] train: loss: 0.0523678
[Epoch 111; Iter   180/  183] train: loss: 0.0391869
[Epoch 111] ogbg-moltox21: 0.799462 val loss: 0.297555
[Epoch 111] ogbg-moltox21: 0.809260 test loss: 0.305351
[Epoch 112; Iter    27/  183] train: loss: 0.0270666
[Epoch 112; Iter    57/  183] train: loss: 0.0555471
[Epoch 112; Iter    87/  183] train: loss: 0.0384684
[Epoch 112; Iter   117/  183] train: loss: 0.0634019
[Epoch 112; Iter   147/  183] train: loss: 0.0749222
[Epoch 112; Iter   177/  183] train: loss: 0.0593148
[Epoch 112] ogbg-moltox21: 0.800991 val loss: 0.297165
[Epoch 112] ogbg-moltox21: 0.814988 test loss: 0.297977
[Epoch 113; Iter    24/  183] train: loss: 0.0420674
[Epoch 113; Iter    54/  183] train: loss: 0.0443976
[Epoch 113; Iter    84/  183] train: loss: 0.0219994
[Epoch 113; Iter   114/  183] train: loss: 0.0373384
[Epoch 113; Iter   144/  183] train: loss: 0.0522064
[Epoch 113; Iter   174/  183] train: loss: 0.0746971
[Epoch 113] ogbg-moltox21: 0.799496 val loss: 0.294985
[Epoch 113] ogbg-moltox21: 0.812980 test loss: 0.303187
[Epoch 114; Iter    21/  183] train: loss: 0.0385723
[Epoch 114; Iter    51/  183] train: loss: 0.0364864
[Epoch 114; Iter    81/  183] train: loss: 0.0665699
[Epoch 114; Iter   111/  183] train: loss: 0.0358014
[Epoch 114; Iter   141/  183] train: loss: 0.0559965
[Epoch 114; Iter   171/  183] train: loss: 0.0577135
[Epoch 114] ogbg-moltox21: 0.806279 val loss: 0.292470
[Epoch 114] ogbg-moltox21: 0.815716 test loss: 0.298319
[Epoch 115; Iter    18/  183] train: loss: 0.0356077
[Epoch 115; Iter    48/  183] train: loss: 0.0445189
[Epoch 115; Iter    78/  183] train: loss: 0.0391767
[Epoch 115; Iter   108/  183] train: loss: 0.0395589
[Epoch 115; Iter   138/  183] train: loss: 0.0369960
[Epoch 115; Iter   168/  183] train: loss: 0.0335417
[Epoch 115] ogbg-moltox21: 0.801215 val loss: 0.299813
[Epoch 115] ogbg-moltox21: 0.810209 test loss: 0.311434
[Epoch 116; Iter    15/  183] train: loss: 0.0455758
[Epoch 116; Iter    45/  183] train: loss: 0.0724806
[Epoch 116; Iter    75/  183] train: loss: 0.0782184
[Epoch 116; Iter   105/  183] train: loss: 0.0243955
[Epoch 116; Iter   135/  183] train: loss: 0.0400928
[Epoch 116; Iter   165/  183] train: loss: 0.0337716
[Epoch 116] ogbg-moltox21: 0.803645 val loss: 0.297391
[Epoch 116] ogbg-moltox21: 0.812328 test loss: 0.305301
[Epoch 117; Iter    12/  183] train: loss: 0.0563199
[Epoch 117; Iter    42/  183] train: loss: 0.0220026
[Epoch 117; Iter    72/  183] train: loss: 0.0609313
[Epoch 117; Iter   102/  183] train: loss: 0.0322626
[Epoch 117; Iter   132/  183] train: loss: 0.0400093
[Epoch 117; Iter   162/  183] train: loss: 0.0347896
[Epoch 117] ogbg-moltox21: 0.799742 val loss: 0.296550
[Epoch 117] ogbg-moltox21: 0.809811 test loss: 0.307869
[Epoch 118; Iter     9/  183] train: loss: 0.0315569
[Epoch 118; Iter    39/  183] train: loss: 0.0546023
[Epoch 118; Iter    69/  183] train: loss: 0.0373014
[Epoch 118; Iter    99/  183] train: loss: 0.0327817
[Epoch 118; Iter   129/  183] train: loss: 0.0964890
[Epoch 118; Iter   159/  183] train: loss: 0.0403348
[Epoch 118] ogbg-moltox21: 0.802867 val loss: 0.297884
[Epoch 118] ogbg-moltox21: 0.815838 test loss: 0.300855
[Epoch 119; Iter     6/  183] train: loss: 0.0723928
[Epoch 119; Iter    36/  183] train: loss: 0.0313205
[Epoch 119; Iter    66/  183] train: loss: 0.0268597
[Epoch 119; Iter    96/  183] train: loss: 0.0315016
[Epoch 119; Iter   126/  183] train: loss: 0.0833732
[Epoch 119; Iter   156/  183] train: loss: 0.0310799
[Epoch 119] ogbg-moltox21: 0.802378 val loss: 0.301087
[Epoch 119] ogbg-moltox21: 0.814344 test loss: 0.307622
[Epoch 120; Iter     3/  183] train: loss: 0.0835457
[Epoch 120; Iter    33/  183] train: loss: 0.0323010
[Epoch 120; Iter    63/  183] train: loss: 0.0429069
[Epoch 120; Iter    93/  183] train: loss: 0.0468790
[Epoch 120; Iter   123/  183] train: loss: 0.0376262
[Epoch 120; Iter   153/  183] train: loss: 0.0258846
[Epoch 120; Iter   183/  183] train: loss: 0.0629654
[Epoch 120] ogbg-moltox21: 0.802262 val loss: 0.298366
[Epoch 120] ogbg-moltox21: 0.811937 test loss: 0.304398
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -3.940870761871338
std_pred: 2.2911508083343506
mean_targets: nan
std_targets: nan
prcauc: 0.4959203021038307
rocauc: 0.8424349800603532
ogbg-moltox21: 0.8424349800603532
OGBNanLabelBCEWithLogitsLoss: 0.18863442204892636
Statistics on  test
mean_pred: -3.9249930381774902
std_pred: 2.3372714519500732
mean_targets: nan
std_targets: nan
prcauc: 0.49058252812610187
rocauc: 0.8514843800127605
ogbg-moltox21: 0.8514843800127605
OGBNanLabelBCEWithLogitsLoss: 0.19271025490015745
Statistics on  train
mean_pred: -3.9441306591033936
std_pred: 2.350691080093384
mean_targets: nan
std_targets: nan
prcauc: 0.6610628289673731
rocauc: 0.9266859772160062
ogbg-moltox21: 0.9266859772160062
OGBNanLabelBCEWithLogitsLoss: 0.13381542202309182
[Epoch 109] ogbg-moltox21: 0.806054 test loss: 0.299421
[Epoch 110; Iter     3/  183] train: loss: 0.0596653
[Epoch 110; Iter    33/  183] train: loss: 0.0286839
[Epoch 110; Iter    63/  183] train: loss: 0.0966955
[Epoch 110; Iter    93/  183] train: loss: 0.0661267
[Epoch 110; Iter   123/  183] train: loss: 0.0428025
[Epoch 110; Iter   153/  183] train: loss: 0.0630174
[Epoch 110; Iter   183/  183] train: loss: 0.0771431
[Epoch 110] ogbg-moltox21: 0.815823 val loss: 0.273721
[Epoch 110] ogbg-moltox21: 0.815132 test loss: 0.291759
[Epoch 111; Iter    30/  183] train: loss: 0.0528122
[Epoch 111; Iter    60/  183] train: loss: 0.0533101
[Epoch 111; Iter    90/  183] train: loss: 0.0389811
[Epoch 111; Iter   120/  183] train: loss: 0.0521125
[Epoch 111; Iter   150/  183] train: loss: 0.0632109
[Epoch 111; Iter   180/  183] train: loss: 0.0446421
[Epoch 111] ogbg-moltox21: 0.809953 val loss: 0.280800
[Epoch 111] ogbg-moltox21: 0.811722 test loss: 0.292301
[Epoch 112; Iter    27/  183] train: loss: 0.0698457
[Epoch 112; Iter    57/  183] train: loss: 0.0418847
[Epoch 112; Iter    87/  183] train: loss: 0.0281208
[Epoch 112; Iter   117/  183] train: loss: 0.0436535
[Epoch 112; Iter   147/  183] train: loss: 0.0609320
[Epoch 112; Iter   177/  183] train: loss: 0.0480676
[Epoch 112] ogbg-moltox21: 0.811685 val loss: 0.291345
[Epoch 112] ogbg-moltox21: 0.811854 test loss: 0.294764
[Epoch 113; Iter    24/  183] train: loss: 0.0500159
[Epoch 113; Iter    54/  183] train: loss: 0.0461050
[Epoch 113; Iter    84/  183] train: loss: 0.0610063
[Epoch 113; Iter   114/  183] train: loss: 0.0661362
[Epoch 113; Iter   144/  183] train: loss: 0.0281665
[Epoch 113; Iter   174/  183] train: loss: 0.0878836
[Epoch 113] ogbg-moltox21: 0.814067 val loss: 0.276691
[Epoch 113] ogbg-moltox21: 0.814912 test loss: 0.290423
[Epoch 114; Iter    21/  183] train: loss: 0.1967164
[Epoch 114; Iter    51/  183] train: loss: 0.0488134
[Epoch 114; Iter    81/  183] train: loss: 0.0450814
[Epoch 114; Iter   111/  183] train: loss: 0.1047369
[Epoch 114; Iter   141/  183] train: loss: 0.0502016
[Epoch 114; Iter   171/  183] train: loss: 0.0333949
[Epoch 114] ogbg-moltox21: 0.812645 val loss: 0.279228
[Epoch 114] ogbg-moltox21: 0.813163 test loss: 0.293409
[Epoch 115; Iter    18/  183] train: loss: 0.0359609
[Epoch 115; Iter    48/  183] train: loss: 0.0500539
[Epoch 115; Iter    78/  183] train: loss: 0.0259418
[Epoch 115; Iter   108/  183] train: loss: 0.0388237
[Epoch 115; Iter   138/  183] train: loss: 0.0897046
[Epoch 115; Iter   168/  183] train: loss: 0.0834218
[Epoch 115] ogbg-moltox21: 0.809631 val loss: 0.280244
[Epoch 115] ogbg-moltox21: 0.810282 test loss: 0.298864
[Epoch 116; Iter    15/  183] train: loss: 0.0263615
[Epoch 116; Iter    45/  183] train: loss: 0.0570532
[Epoch 116; Iter    75/  183] train: loss: 0.0463271
[Epoch 116; Iter   105/  183] train: loss: 0.0210344
[Epoch 116; Iter   135/  183] train: loss: 0.0458495
[Epoch 116; Iter   165/  183] train: loss: 0.0371500
[Epoch 116] ogbg-moltox21: 0.812498 val loss: 0.277321
[Epoch 116] ogbg-moltox21: 0.814578 test loss: 0.292691
[Epoch 117; Iter    12/  183] train: loss: 0.0643752
[Epoch 117; Iter    42/  183] train: loss: 0.0471712
[Epoch 117; Iter    72/  183] train: loss: 0.0935072
[Epoch 117; Iter   102/  183] train: loss: 0.0897116
[Epoch 117; Iter   132/  183] train: loss: 0.0490831
[Epoch 117; Iter   162/  183] train: loss: 0.0403984
[Epoch 117] ogbg-moltox21: 0.812201 val loss: 0.279424
[Epoch 117] ogbg-moltox21: 0.817728 test loss: 0.291143
[Epoch 118; Iter     9/  183] train: loss: 0.0334041
[Epoch 118; Iter    39/  183] train: loss: 0.0681799
[Epoch 118; Iter    69/  183] train: loss: 0.0895968
[Epoch 118; Iter    99/  183] train: loss: 0.0592333
[Epoch 118; Iter   129/  183] train: loss: 0.0726575
[Epoch 118; Iter   159/  183] train: loss: 0.0700790
[Epoch 118] ogbg-moltox21: 0.811274 val loss: 0.283838
[Epoch 118] ogbg-moltox21: 0.813804 test loss: 0.302338
[Epoch 119; Iter     6/  183] train: loss: 0.0907404
[Epoch 119; Iter    36/  183] train: loss: 0.1000424
[Epoch 119; Iter    66/  183] train: loss: 0.0401339
[Epoch 119; Iter    96/  183] train: loss: 0.0348265
[Epoch 119; Iter   126/  183] train: loss: 0.0688068
[Epoch 119; Iter   156/  183] train: loss: 0.0366770
[Epoch 119] ogbg-moltox21: 0.811943 val loss: 0.281485
[Epoch 119] ogbg-moltox21: 0.812527 test loss: 0.300934
[Epoch 120; Iter     3/  183] train: loss: 0.0294527
[Epoch 120; Iter    33/  183] train: loss: 0.0401943
[Epoch 120; Iter    63/  183] train: loss: 0.0405929
[Epoch 120; Iter    93/  183] train: loss: 0.0269874
[Epoch 120; Iter   123/  183] train: loss: 0.0474236
[Epoch 120; Iter   153/  183] train: loss: 0.0274564
[Epoch 120; Iter   183/  183] train: loss: 0.0652866
[Epoch 120] ogbg-moltox21: 0.809699 val loss: 0.282782
[Epoch 120] ogbg-moltox21: 0.806133 test loss: 0.302862
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 43.
Statistics on  val_best_checkpoint
mean_pred: -4.150450229644775
std_pred: 2.4508984088897705
mean_targets: nan
std_targets: nan
prcauc: 0.47571759701371635
rocauc: 0.8455922727423729
ogbg-moltox21: 0.8455922727423729
OGBNanLabelBCEWithLogitsLoss: 0.19245677758008242
Statistics on  test
mean_pred: -4.073094367980957
std_pred: 2.461026430130005
mean_targets: nan
std_targets: nan
prcauc: 0.4960259205050748
rocauc: 0.8495993145957325
ogbg-moltox21: 0.8495993145957325
OGBNanLabelBCEWithLogitsLoss: 0.1904594086110592
Statistics on  train
mean_pred: -4.1376848220825195
std_pred: 2.660503625869751
mean_targets: nan
std_targets: nan
prcauc: 0.6926850058598356
rocauc: 0.93282282819911
ogbg-moltox21: 0.93282282819911
OGBNanLabelBCEWithLogitsLoss: 0.12818076876831835
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0348884
[Epoch 116; Iter   175/  209] train: loss: 0.0473673
[Epoch 116; Iter   205/  209] train: loss: 0.0567583
[Epoch 116] ogbg-moltox21: 0.836669 val loss: 0.343739
[Epoch 116] ogbg-moltox21: 0.827770 test loss: 0.304446
[Epoch 117; Iter    26/  209] train: loss: 0.0369233
[Epoch 117; Iter    56/  209] train: loss: 0.0432276
[Epoch 117; Iter    86/  209] train: loss: 0.0460661
[Epoch 117; Iter   116/  209] train: loss: 0.0397829
[Epoch 117; Iter   146/  209] train: loss: 0.0553837
[Epoch 117; Iter   176/  209] train: loss: 0.0539671
[Epoch 117; Iter   206/  209] train: loss: 0.0305513
[Epoch 117] ogbg-moltox21: 0.836960 val loss: 0.329080
[Epoch 117] ogbg-moltox21: 0.831540 test loss: 0.301664
[Epoch 118; Iter    27/  209] train: loss: 0.0619137
[Epoch 118; Iter    57/  209] train: loss: 0.0492305
[Epoch 118; Iter    87/  209] train: loss: 0.0305661
[Epoch 118; Iter   117/  209] train: loss: 0.0328753
[Epoch 118; Iter   147/  209] train: loss: 0.0587790
[Epoch 118; Iter   177/  209] train: loss: 0.0284165
[Epoch 118; Iter   207/  209] train: loss: 0.0601705
[Epoch 118] ogbg-moltox21: 0.836073 val loss: 0.376678
[Epoch 118] ogbg-moltox21: 0.829021 test loss: 0.303700
[Epoch 119; Iter    28/  209] train: loss: 0.0543137
[Epoch 119; Iter    58/  209] train: loss: 0.0315452
[Epoch 119; Iter    88/  209] train: loss: 0.0351314
[Epoch 119; Iter   118/  209] train: loss: 0.0411345
[Epoch 119; Iter   148/  209] train: loss: 0.0214079
[Epoch 119; Iter   178/  209] train: loss: 0.0390738
[Epoch 119; Iter   208/  209] train: loss: 0.0517870
[Epoch 119] ogbg-moltox21: 0.829778 val loss: 0.344422
[Epoch 119] ogbg-moltox21: 0.825533 test loss: 0.315011
[Epoch 120; Iter    29/  209] train: loss: 0.0443697
[Epoch 120; Iter    59/  209] train: loss: 0.0676964
[Epoch 120; Iter    89/  209] train: loss: 0.0923507
[Epoch 120; Iter   119/  209] train: loss: 0.0433726
[Epoch 120; Iter   149/  209] train: loss: 0.0490857
[Epoch 120; Iter   179/  209] train: loss: 0.0470735
[Epoch 120; Iter   209/  209] train: loss: 0.0588220
[Epoch 120] ogbg-moltox21: 0.833254 val loss: 0.376313
[Epoch 120] ogbg-moltox21: 0.827578 test loss: 0.307693
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 29.
Statistics on  val_best_checkpoint
mean_pred: -3.8233437538146973
std_pred: 2.304321527481079
mean_targets: nan
std_targets: nan
prcauc: 0.4953033605594823
rocauc: 0.8684584002889807
ogbg-moltox21: 0.8684584002889807
OGBNanLabelBCEWithLogitsLoss: 0.1946211283405622
Statistics on  test
mean_pred: -3.8788037300109863
std_pred: 2.726015329360962
mean_targets: nan
std_targets: nan
prcauc: 0.42861361428759276
rocauc: 0.8416267656936279
ogbg-moltox21: 0.8416267656936279
OGBNanLabelBCEWithLogitsLoss: 0.1991409209591371
Statistics on  train
mean_pred: -3.778783082962036
std_pred: 7.914516448974609
mean_targets: nan
std_targets: nan
prcauc: 0.5303672711123545
rocauc: 0.8952075578766444
ogbg-moltox21: 0.8952075578766444
OGBNanLabelBCEWithLogitsLoss: 0.21760246924093465
[Epoch 116; Iter   145/  209] train: loss: 0.0768902
[Epoch 116; Iter   175/  209] train: loss: 0.0765502
[Epoch 116; Iter   205/  209] train: loss: 0.0371642
[Epoch 116] ogbg-moltox21: 0.823752 val loss: 0.326377
[Epoch 116] ogbg-moltox21: 0.810876 test loss: 0.311170
[Epoch 117; Iter    26/  209] train: loss: 0.0269400
[Epoch 117; Iter    56/  209] train: loss: 0.0537910
[Epoch 117; Iter    86/  209] train: loss: 0.0692672
[Epoch 117; Iter   116/  209] train: loss: 0.0383330
[Epoch 117; Iter   146/  209] train: loss: 0.1005884
[Epoch 117; Iter   176/  209] train: loss: 0.0434426
[Epoch 117; Iter   206/  209] train: loss: 0.0464492
[Epoch 117] ogbg-moltox21: 0.825958 val loss: 0.326915
[Epoch 117] ogbg-moltox21: 0.819205 test loss: 0.299919
[Epoch 118; Iter    27/  209] train: loss: 0.0318641
[Epoch 118; Iter    57/  209] train: loss: 0.0340989
[Epoch 118; Iter    87/  209] train: loss: 0.0405468
[Epoch 118; Iter   117/  209] train: loss: 0.0333493
[Epoch 118; Iter   147/  209] train: loss: 0.0674607
[Epoch 118; Iter   177/  209] train: loss: 0.0491602
[Epoch 118; Iter   207/  209] train: loss: 0.0705694
[Epoch 118] ogbg-moltox21: 0.826031 val loss: 0.322115
[Epoch 118] ogbg-moltox21: 0.813013 test loss: 0.312778
[Epoch 119; Iter    28/  209] train: loss: 0.0363089
[Epoch 119; Iter    58/  209] train: loss: 0.0300098
[Epoch 119; Iter    88/  209] train: loss: 0.0388682
[Epoch 119; Iter   118/  209] train: loss: 0.0435330
[Epoch 119; Iter   148/  209] train: loss: 0.0463521
[Epoch 119; Iter   178/  209] train: loss: 0.0362181
[Epoch 119; Iter   208/  209] train: loss: 0.0348698
[Epoch 119] ogbg-moltox21: 0.827821 val loss: 0.320164
[Epoch 119] ogbg-moltox21: 0.816308 test loss: 0.304912
[Epoch 120; Iter    29/  209] train: loss: 0.0231593
[Epoch 120; Iter    59/  209] train: loss: 0.0221980
[Epoch 120; Iter    89/  209] train: loss: 0.0415868
[Epoch 120; Iter   119/  209] train: loss: 0.0430406
[Epoch 120; Iter   149/  209] train: loss: 0.0271183
[Epoch 120; Iter   179/  209] train: loss: 0.0268877
[Epoch 120; Iter   209/  209] train: loss: 0.0471870
[Epoch 120] ogbg-moltox21: 0.826067 val loss: 0.325111
[Epoch 120] ogbg-moltox21: 0.812620 test loss: 0.315061
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -3.5876827239990234
std_pred: 1.860356330871582
mean_targets: nan
std_targets: nan
prcauc: 0.48245106564835977
rocauc: 0.8680207852862019
ogbg-moltox21: 0.8680207852862019
OGBNanLabelBCEWithLogitsLoss: 0.1981544800930553
Statistics on  test
mean_pred: -3.659071683883667
std_pred: 1.9020617008209229
mean_targets: nan
std_targets: nan
prcauc: 0.4332439519624629
rocauc: 0.8518903845254343
ogbg-moltox21: 0.8518903845254343
OGBNanLabelBCEWithLogitsLoss: 0.1917903475739338
Statistics on  train
mean_pred: -3.611323595046997
std_pred: 2.663468837738037
mean_targets: nan
std_targets: nan
prcauc: 0.46725371303678026
rocauc: 0.8740065259299482
ogbg-moltox21: 0.8740065259299482
OGBNanLabelBCEWithLogitsLoss: 0.18618957500494837
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0659816
[Epoch 116; Iter   175/  209] train: loss: 0.0525241
[Epoch 116; Iter   205/  209] train: loss: 0.0683137
[Epoch 116] ogbg-moltox21: 0.826505 val loss: 0.306550
[Epoch 116] ogbg-moltox21: 0.809964 test loss: 0.272136
[Epoch 117; Iter    26/  209] train: loss: 0.0668415
[Epoch 117; Iter    56/  209] train: loss: 0.0436444
[Epoch 117; Iter    86/  209] train: loss: 0.0469453
[Epoch 117; Iter   116/  209] train: loss: 0.1164815
[Epoch 117; Iter   146/  209] train: loss: 0.0763679
[Epoch 117; Iter   176/  209] train: loss: 0.0387232
[Epoch 117; Iter   206/  209] train: loss: 0.0354042
[Epoch 117] ogbg-moltox21: 0.825905 val loss: 0.308284
[Epoch 117] ogbg-moltox21: 0.807780 test loss: 0.272388
[Epoch 118; Iter    27/  209] train: loss: 0.0499576
[Epoch 118; Iter    57/  209] train: loss: 0.0407476
[Epoch 118; Iter    87/  209] train: loss: 0.0873968
[Epoch 118; Iter   117/  209] train: loss: 0.0659942
[Epoch 118; Iter   147/  209] train: loss: 0.0362955
[Epoch 118; Iter   177/  209] train: loss: 0.0446787
[Epoch 118; Iter   207/  209] train: loss: 0.0475121
[Epoch 118] ogbg-moltox21: 0.825876 val loss: 0.311903
[Epoch 118] ogbg-moltox21: 0.806874 test loss: 0.275093
[Epoch 119; Iter    28/  209] train: loss: 0.1305987
[Epoch 119; Iter    58/  209] train: loss: 0.0480985
[Epoch 119; Iter    88/  209] train: loss: 0.0286015
[Epoch 119; Iter   118/  209] train: loss: 0.0644876
[Epoch 119; Iter   148/  209] train: loss: 0.0492780
[Epoch 119; Iter   178/  209] train: loss: 0.0498143
[Epoch 119; Iter   208/  209] train: loss: 0.0352001
[Epoch 119] ogbg-moltox21: 0.827862 val loss: 0.314029
[Epoch 119] ogbg-moltox21: 0.804882 test loss: 0.279690
[Epoch 120; Iter    29/  209] train: loss: 0.0362891
[Epoch 120; Iter    59/  209] train: loss: 0.0335621
[Epoch 120; Iter    89/  209] train: loss: 0.0531532
[Epoch 120; Iter   119/  209] train: loss: 0.0813504
[Epoch 120; Iter   149/  209] train: loss: 0.0427293
[Epoch 120; Iter   179/  209] train: loss: 0.0730324
[Epoch 120; Iter   209/  209] train: loss: 0.0765769
[Epoch 120] ogbg-moltox21: 0.825708 val loss: 0.312721
[Epoch 120] ogbg-moltox21: 0.805622 test loss: 0.276821
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -3.908801555633545
std_pred: 2.294163227081299
mean_targets: nan
std_targets: nan
prcauc: 0.5195021387139932
rocauc: 0.8707522693329607
ogbg-moltox21: 0.8707522693329607
OGBNanLabelBCEWithLogitsLoss: 0.19899613244665992
Statistics on  test
mean_pred: -3.8085439205169678
std_pred: 4.406820774078369
mean_targets: nan
std_targets: nan
prcauc: 0.45673831741426935
rocauc: 0.8518335875737774
ogbg-moltox21: 0.8518335875737774
OGBNanLabelBCEWithLogitsLoss: 0.19655833200172143
Statistics on  train
mean_pred: -3.8980252742767334
std_pred: 2.618962287902832
mean_targets: nan
std_targets: nan
prcauc: 0.5635217537494244
rocauc: 0.9040202362879627
ogbg-moltox21: 0.9040202362879627
OGBNanLabelBCEWithLogitsLoss: 0.16049174504559577
All runs completed.
