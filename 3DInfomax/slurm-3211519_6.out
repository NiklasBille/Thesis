>>> Starting run for dataset: tox21
Running configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.05/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.05_4_26-05_10-54-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.05
logdir: runs/static_noise/GraphCL/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6931759
[Epoch 1; Iter    60/  209] train: loss: 0.6931651
[Epoch 1; Iter    90/  209] train: loss: 0.6930323
[Epoch 1; Iter   120/  209] train: loss: 0.6938909
[Epoch 1; Iter   150/  209] train: loss: 0.6930727
[Epoch 1; Iter   180/  209] train: loss: 0.6930759
[Epoch 1] ogbg-moltox21: 0.490282 val loss: 0.689745
[Epoch 1] ogbg-moltox21: 0.504746 test loss: 0.689731
[Epoch 2; Iter     1/  209] train: loss: 0.6913245
[Epoch 2; Iter    31/  209] train: loss: 0.6926515
[Epoch 2; Iter    61/  209] train: loss: 0.6924016
[Epoch 2; Iter    91/  209] train: loss: 0.6915247
[Epoch 2; Iter   121/  209] train: loss: 0.6923643
[Epoch 2; Iter   151/  209] train: loss: 0.6915639
[Epoch 2; Iter   181/  209] train: loss: 0.6912505
[Epoch 2] ogbg-moltox21: 0.491979 val loss: 0.688758
[Epoch 2] ogbg-moltox21: 0.506202 test loss: 0.688820
[Epoch 3; Iter     2/  209] train: loss: 0.6906571
[Epoch 3; Iter    32/  209] train: loss: 0.6895931
[Epoch 3; Iter    62/  209] train: loss: 0.6905897
[Epoch 3; Iter    92/  209] train: loss: 0.6903296
[Epoch 3; Iter   122/  209] train: loss: 0.6893408
[Epoch 3; Iter   152/  209] train: loss: 0.6889117
[Epoch 3; Iter   182/  209] train: loss: 0.6877819
[Epoch 3] ogbg-moltox21: 0.493431 val loss: 0.686138
[Epoch 3] ogbg-moltox21: 0.506708 test loss: 0.686178
[Epoch 4; Iter     3/  209] train: loss: 0.6880633
[Epoch 4; Iter    33/  209] train: loss: 0.6877986
[Epoch 4; Iter    63/  209] train: loss: 0.6873786
[Epoch 4; Iter    93/  209] train: loss: 0.6819183
[Epoch 4; Iter   123/  209] train: loss: 0.6595467
[Epoch 4; Iter   153/  209] train: loss: 0.6306702
[Epoch 4; Iter   183/  209] train: loss: 0.5855430
[Epoch 4] ogbg-moltox21: 0.686404 val loss: 0.722886
[Epoch 4] ogbg-moltox21: 0.665020 test loss: 0.715747
[Epoch 5; Iter     4/  209] train: loss: 0.5283819
[Epoch 5; Iter    34/  209] train: loss: 0.4664435
[Epoch 5; Iter    64/  209] train: loss: 0.4302645
[Epoch 5; Iter    94/  209] train: loss: 0.3871970
[Epoch 5; Iter   124/  209] train: loss: 0.3991301
[Epoch 5; Iter   154/  209] train: loss: 0.2370300
[Epoch 5; Iter   184/  209] train: loss: 0.2336646
[Epoch 5] ogbg-moltox21: 0.712066 val loss: 0.321354
[Epoch 5] ogbg-moltox21: 0.694373 test loss: 0.326503
[Epoch 6; Iter     5/  209] train: loss: 0.2128730
[Epoch 6; Iter    35/  209] train: loss: 0.2211406
[Epoch 6; Iter    65/  209] train: loss: 0.2289498
[Epoch 6; Iter    95/  209] train: loss: 0.2386971
[Epoch 6; Iter   125/  209] train: loss: 0.3259935
[Epoch 6; Iter   155/  209] train: loss: 0.2573944
[Epoch 6; Iter   185/  209] train: loss: 0.2622765
[Epoch 6] ogbg-moltox21: 0.680685 val loss: 0.295855
[Epoch 6] ogbg-moltox21: 0.662394 test loss: 0.295773
[Epoch 7; Iter     6/  209] train: loss: 0.3155412
[Epoch 7; Iter    36/  209] train: loss: 0.2076406
[Epoch 7; Iter    66/  209] train: loss: 0.2591455
[Epoch 7; Iter    96/  209] train: loss: 0.2093846
[Epoch 7; Iter   126/  209] train: loss: 0.1963375
[Epoch 7; Iter   156/  209] train: loss: 0.2267590
[Epoch 7; Iter   186/  209] train: loss: 0.1903594
[Epoch 7] ogbg-moltox21: 0.700152 val loss: 0.331665
[Epoch 7] ogbg-moltox21: 0.671174 test loss: 0.313972
[Epoch 8; Iter     7/  209] train: loss: 0.1294310
[Epoch 8; Iter    37/  209] train: loss: 0.2164044
[Epoch 8; Iter    67/  209] train: loss: 0.2858524
[Epoch 8; Iter    97/  209] train: loss: 0.1806525
[Epoch 8; Iter   127/  209] train: loss: 0.2836817
[Epoch 8; Iter   157/  209] train: loss: 0.1633950
[Epoch 8; Iter   187/  209] train: loss: 0.2092288
[Epoch 8] ogbg-moltox21: 0.729286 val loss: 0.559776
[Epoch 8] ogbg-moltox21: 0.716356 test loss: 0.310300
[Epoch 9; Iter     8/  209] train: loss: 0.2663731
[Epoch 9; Iter    38/  209] train: loss: 0.1478980
[Epoch 9; Iter    68/  209] train: loss: 0.2239442
[Epoch 9; Iter    98/  209] train: loss: 0.1839350
[Epoch 9; Iter   128/  209] train: loss: 0.1749136
[Epoch 9; Iter   158/  209] train: loss: 0.1870492
[Epoch 9; Iter   188/  209] train: loss: 0.2308474
[Epoch 9] ogbg-moltox21: 0.746995 val loss: 0.992423
[Epoch 9] ogbg-moltox21: 0.719391 test loss: 1.211813
[Epoch 10; Iter     9/  209] train: loss: 0.2415584
[Epoch 10; Iter    39/  209] train: loss: 0.1954322
[Epoch 10; Iter    69/  209] train: loss: 0.2199941
[Epoch 10; Iter    99/  209] train: loss: 0.2284307
[Epoch 10; Iter   129/  209] train: loss: 0.2299470
[Epoch 10; Iter   159/  209] train: loss: 0.1794106
[Epoch 10; Iter   189/  209] train: loss: 0.2347158
[Epoch 10] ogbg-moltox21: 0.703285 val loss: 0.712190
[Epoch 10] ogbg-moltox21: 0.638460 test loss: 0.562951
[Epoch 11; Iter    10/  209] train: loss: 0.2182117
[Epoch 11; Iter    40/  209] train: loss: 0.1823366
[Epoch 11; Iter    70/  209] train: loss: 0.1917735
[Epoch 11; Iter   100/  209] train: loss: 0.3393833
[Epoch 11; Iter   130/  209] train: loss: 0.2045394
[Epoch 11; Iter   160/  209] train: loss: 0.2539032
[Epoch 11; Iter   190/  209] train: loss: 0.1647218
[Epoch 11] ogbg-moltox21: 0.734125 val loss: 0.298289
[Epoch 11] ogbg-moltox21: 0.711230 test loss: 0.290875
[Epoch 12; Iter    11/  209] train: loss: 0.1899728
[Epoch 12; Iter    41/  209] train: loss: 0.1146379
[Epoch 12; Iter    71/  209] train: loss: 0.3424864
[Epoch 12; Iter   101/  209] train: loss: 0.1823456
[Epoch 12; Iter   131/  209] train: loss: 0.2074632
[Epoch 12; Iter   161/  209] train: loss: 0.1876710
[Epoch 12; Iter   191/  209] train: loss: 0.1349830
[Epoch 12] ogbg-moltox21: 0.765684 val loss: 0.272893
[Epoch 12] ogbg-moltox21: 0.743977 test loss: 0.312064
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.0/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.0_6_26-05_10-52-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.0
logdir: runs/static_noise/GraphCL/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6922127
[Epoch 1; Iter    60/  209] train: loss: 0.6928524
[Epoch 1; Iter    90/  209] train: loss: 0.6915375
[Epoch 1; Iter   120/  209] train: loss: 0.6925225
[Epoch 1; Iter   150/  209] train: loss: 0.6921127
[Epoch 1; Iter   180/  209] train: loss: 0.6922696
[Epoch 1] ogbg-moltox21: 0.512113 val loss: 0.693809
[Epoch 1] ogbg-moltox21: 0.516141 test loss: 0.693827
[Epoch 2; Iter     1/  209] train: loss: 0.6923199
[Epoch 2; Iter    31/  209] train: loss: 0.6914638
[Epoch 2; Iter    61/  209] train: loss: 0.6915285
[Epoch 2; Iter    91/  209] train: loss: 0.6910518
[Epoch 2; Iter   121/  209] train: loss: 0.6913453
[Epoch 2; Iter   151/  209] train: loss: 0.6911838
[Epoch 2; Iter   181/  209] train: loss: 0.6907817
[Epoch 2] ogbg-moltox21: 0.516011 val loss: 0.692696
[Epoch 2] ogbg-moltox21: 0.518969 test loss: 0.692779
[Epoch 3; Iter     2/  209] train: loss: 0.6907580
[Epoch 3; Iter    32/  209] train: loss: 0.6901095
[Epoch 3; Iter    62/  209] train: loss: 0.6904997
[Epoch 3; Iter    92/  209] train: loss: 0.6897749
[Epoch 3; Iter   122/  209] train: loss: 0.6894065
[Epoch 3; Iter   152/  209] train: loss: 0.6888785
[Epoch 3; Iter   182/  209] train: loss: 0.6880506
[Epoch 3] ogbg-moltox21: 0.521126 val loss: 0.690990
[Epoch 3] ogbg-moltox21: 0.523207 test loss: 0.691106
[Epoch 4; Iter     3/  209] train: loss: 0.6867489
[Epoch 4; Iter    33/  209] train: loss: 0.6882828
[Epoch 4; Iter    63/  209] train: loss: 0.6871916
[Epoch 4; Iter    93/  209] train: loss: 0.6826128
[Epoch 4; Iter   123/  209] train: loss: 0.6591492
[Epoch 4; Iter   153/  209] train: loss: 0.6244155
[Epoch 4; Iter   183/  209] train: loss: 0.6199212
[Epoch 4] ogbg-moltox21: 0.693792 val loss: 0.714371
[Epoch 4] ogbg-moltox21: 0.670754 test loss: 0.717872
[Epoch 5; Iter     4/  209] train: loss: 0.5404229
[Epoch 5; Iter    34/  209] train: loss: 0.4817697
[Epoch 5; Iter    64/  209] train: loss: 0.4193895
[Epoch 5; Iter    94/  209] train: loss: 0.3926287
[Epoch 5; Iter   124/  209] train: loss: 0.3492918
[Epoch 5; Iter   154/  209] train: loss: 0.2838778
[Epoch 5; Iter   184/  209] train: loss: 0.2301665
[Epoch 5] ogbg-moltox21: 0.713291 val loss: 0.310429
[Epoch 5] ogbg-moltox21: 0.688656 test loss: 0.316785
[Epoch 6; Iter     5/  209] train: loss: 0.2098856
[Epoch 6; Iter    35/  209] train: loss: 0.1653824
[Epoch 6; Iter    65/  209] train: loss: 0.1881145
[Epoch 6; Iter    95/  209] train: loss: 0.2066678
[Epoch 6; Iter   125/  209] train: loss: 0.1546907
[Epoch 6; Iter   155/  209] train: loss: 0.2086152
[Epoch 6; Iter   185/  209] train: loss: 0.1752985
[Epoch 6] ogbg-moltox21: 0.712669 val loss: 0.273542
[Epoch 6] ogbg-moltox21: 0.706720 test loss: 0.278564
[Epoch 7; Iter     6/  209] train: loss: 0.1629451
[Epoch 7; Iter    36/  209] train: loss: 0.2424981
[Epoch 7; Iter    66/  209] train: loss: 0.1582917
[Epoch 7; Iter    96/  209] train: loss: 0.2376407
[Epoch 7; Iter   126/  209] train: loss: 0.1741127
[Epoch 7; Iter   156/  209] train: loss: 0.2312238
[Epoch 7; Iter   186/  209] train: loss: 0.2245636
[Epoch 7] ogbg-moltox21: 0.745329 val loss: 0.311519
[Epoch 7] ogbg-moltox21: 0.706244 test loss: 0.310481
[Epoch 8; Iter     7/  209] train: loss: 0.1817769
[Epoch 8; Iter    37/  209] train: loss: 0.2224823
[Epoch 8; Iter    67/  209] train: loss: 0.1540713
[Epoch 8; Iter    97/  209] train: loss: 0.2647148
[Epoch 8; Iter   127/  209] train: loss: 0.2692756
[Epoch 8; Iter   157/  209] train: loss: 0.1812462
[Epoch 8; Iter   187/  209] train: loss: 0.2384749
[Epoch 8] ogbg-moltox21: 0.735776 val loss: 0.292614
[Epoch 8] ogbg-moltox21: 0.693061 test loss: 0.298521
[Epoch 9; Iter     8/  209] train: loss: 0.2452450
[Epoch 9; Iter    38/  209] train: loss: 0.1833333
[Epoch 9; Iter    68/  209] train: loss: 0.1593675
[Epoch 9; Iter    98/  209] train: loss: 0.2732981
[Epoch 9; Iter   128/  209] train: loss: 0.2128541
[Epoch 9; Iter   158/  209] train: loss: 0.1710173
[Epoch 9; Iter   188/  209] train: loss: 0.1688803
[Epoch 9] ogbg-moltox21: 0.673865 val loss: 0.323986
[Epoch 9] ogbg-moltox21: 0.674192 test loss: 0.312673
[Epoch 10; Iter     9/  209] train: loss: 0.2144847
[Epoch 10; Iter    39/  209] train: loss: 0.1840178
[Epoch 10; Iter    69/  209] train: loss: 0.1865500
[Epoch 10; Iter    99/  209] train: loss: 0.1649740
[Epoch 10; Iter   129/  209] train: loss: 0.1544321
[Epoch 10; Iter   159/  209] train: loss: 0.1190250
[Epoch 10; Iter   189/  209] train: loss: 0.1705356
[Epoch 10] ogbg-moltox21: 0.746458 val loss: 0.277480
[Epoch 10] ogbg-moltox21: 0.688494 test loss: 0.297549
[Epoch 11; Iter    10/  209] train: loss: 0.2168321
[Epoch 11; Iter    40/  209] train: loss: 0.2256817
[Epoch 11; Iter    70/  209] train: loss: 0.2076673
[Epoch 11; Iter   100/  209] train: loss: 0.2568990
[Epoch 11; Iter   130/  209] train: loss: 0.1929624
[Epoch 11; Iter   160/  209] train: loss: 0.1859512
[Epoch 11; Iter   190/  209] train: loss: 0.1435591
[Epoch 11] ogbg-moltox21: 0.786081 val loss: 0.754816
[Epoch 11] ogbg-moltox21: 0.699905 test loss: 0.572044
[Epoch 12; Iter    11/  209] train: loss: 0.1246083
[Epoch 12; Iter    41/  209] train: loss: 0.2777481
[Epoch 12; Iter    71/  209] train: loss: 0.1644553
[Epoch 12; Iter   101/  209] train: loss: 0.2031347
[Epoch 12; Iter   131/  209] train: loss: 0.1900952
[Epoch 12; Iter   161/  209] train: loss: 0.2194532
[Epoch 12; Iter   191/  209] train: loss: 0.1444472
[Epoch 12] ogbg-moltox21: 0.789755 val loss: 0.248817
[Epoch 12] ogbg-moltox21: 0.720601 test loss: 0.274838
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.0/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.0_4_26-05_10-52-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.0
logdir: runs/static_noise/GraphCL/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930513
[Epoch 1; Iter    60/  209] train: loss: 0.6932298
[Epoch 1; Iter    90/  209] train: loss: 0.6928320
[Epoch 1; Iter   120/  209] train: loss: 0.6937398
[Epoch 1; Iter   150/  209] train: loss: 0.6926974
[Epoch 1; Iter   180/  209] train: loss: 0.6927426
[Epoch 1] ogbg-moltox21: 0.488268 val loss: 0.691392
[Epoch 1] ogbg-moltox21: 0.515376 test loss: 0.691490
[Epoch 2; Iter     1/  209] train: loss: 0.6913806
[Epoch 2; Iter    31/  209] train: loss: 0.6927036
[Epoch 2; Iter    61/  209] train: loss: 0.6921554
[Epoch 2; Iter    91/  209] train: loss: 0.6918639
[Epoch 2; Iter   121/  209] train: loss: 0.6923195
[Epoch 2; Iter   151/  209] train: loss: 0.6915021
[Epoch 2; Iter   181/  209] train: loss: 0.6912195
[Epoch 2] ogbg-moltox21: 0.487954 val loss: 0.690391
[Epoch 2] ogbg-moltox21: 0.515316 test loss: 0.690534
[Epoch 3; Iter     2/  209] train: loss: 0.6905911
[Epoch 3; Iter    32/  209] train: loss: 0.6898279
[Epoch 3; Iter    62/  209] train: loss: 0.6909522
[Epoch 3; Iter    92/  209] train: loss: 0.6900539
[Epoch 3; Iter   122/  209] train: loss: 0.6891491
[Epoch 3; Iter   152/  209] train: loss: 0.6885039
[Epoch 3; Iter   182/  209] train: loss: 0.6881315
[Epoch 3] ogbg-moltox21: 0.492307 val loss: 0.687908
[Epoch 3] ogbg-moltox21: 0.518842 test loss: 0.688071
[Epoch 4; Iter     3/  209] train: loss: 0.6881874
[Epoch 4; Iter    33/  209] train: loss: 0.6875826
[Epoch 4; Iter    63/  209] train: loss: 0.6875308
[Epoch 4; Iter    93/  209] train: loss: 0.6810486
[Epoch 4; Iter   123/  209] train: loss: 0.6593581
[Epoch 4; Iter   153/  209] train: loss: 0.6309950
[Epoch 4; Iter   183/  209] train: loss: 0.5847374
[Epoch 4] ogbg-moltox21: 0.685408 val loss: 0.696322
[Epoch 4] ogbg-moltox21: 0.661513 test loss: 0.695340
[Epoch 5; Iter     4/  209] train: loss: 0.5290123
[Epoch 5; Iter    34/  209] train: loss: 0.4660520
[Epoch 5; Iter    64/  209] train: loss: 0.4400271
[Epoch 5; Iter    94/  209] train: loss: 0.3741885
[Epoch 5; Iter   124/  209] train: loss: 0.3899929
[Epoch 5; Iter   154/  209] train: loss: 0.2379459
[Epoch 5; Iter   184/  209] train: loss: 0.2301288
[Epoch 5] ogbg-moltox21: 0.702141 val loss: 0.316147
[Epoch 5] ogbg-moltox21: 0.680764 test loss: 0.319559
[Epoch 6; Iter     5/  209] train: loss: 0.2132916
[Epoch 6; Iter    35/  209] train: loss: 0.2173021
[Epoch 6; Iter    65/  209] train: loss: 0.2234228
[Epoch 6; Iter    95/  209] train: loss: 0.2333672
[Epoch 6; Iter   125/  209] train: loss: 0.3127131
[Epoch 6; Iter   155/  209] train: loss: 0.2447008
[Epoch 6; Iter   185/  209] train: loss: 0.2563261
[Epoch 6] ogbg-moltox21: 0.724703 val loss: 0.280399
[Epoch 6] ogbg-moltox21: 0.709127 test loss: 0.277245
[Epoch 7; Iter     6/  209] train: loss: 0.3061304
[Epoch 7; Iter    36/  209] train: loss: 0.1934687
[Epoch 7; Iter    66/  209] train: loss: 0.2573374
[Epoch 7; Iter    96/  209] train: loss: 0.2074975
[Epoch 7; Iter   126/  209] train: loss: 0.1844997
[Epoch 7; Iter   156/  209] train: loss: 0.2152909
[Epoch 7; Iter   186/  209] train: loss: 0.1924327
[Epoch 7] ogbg-moltox21: 0.752449 val loss: 0.311196
[Epoch 7] ogbg-moltox21: 0.718256 test loss: 0.319943
[Epoch 8; Iter     7/  209] train: loss: 0.1337785
[Epoch 8; Iter    37/  209] train: loss: 0.2328913
[Epoch 8; Iter    67/  209] train: loss: 0.2834444
[Epoch 8; Iter    97/  209] train: loss: 0.1800573
[Epoch 8; Iter   127/  209] train: loss: 0.2857223
[Epoch 8; Iter   157/  209] train: loss: 0.1556678
[Epoch 8; Iter   187/  209] train: loss: 0.2231929
[Epoch 8] ogbg-moltox21: 0.731762 val loss: 0.275037
[Epoch 8] ogbg-moltox21: 0.692827 test loss: 0.279796
[Epoch 9; Iter     8/  209] train: loss: 0.2571332
[Epoch 9; Iter    38/  209] train: loss: 0.1517459
[Epoch 9; Iter    68/  209] train: loss: 0.2265967
[Epoch 9; Iter    98/  209] train: loss: 0.1989620
[Epoch 9; Iter   128/  209] train: loss: 0.1728555
[Epoch 9; Iter   158/  209] train: loss: 0.1884810
[Epoch 9; Iter   188/  209] train: loss: 0.2536185
[Epoch 9] ogbg-moltox21: 0.772529 val loss: 0.262384
[Epoch 9] ogbg-moltox21: 0.727804 test loss: 0.275599
[Epoch 10; Iter     9/  209] train: loss: 0.2259904
[Epoch 10; Iter    39/  209] train: loss: 0.2066337
[Epoch 10; Iter    69/  209] train: loss: 0.1989910
[Epoch 10; Iter    99/  209] train: loss: 0.2152107
[Epoch 10; Iter   129/  209] train: loss: 0.2188326
[Epoch 10; Iter   159/  209] train: loss: 0.1823864
[Epoch 10; Iter   189/  209] train: loss: 0.2186593
[Epoch 10] ogbg-moltox21: 0.640810 val loss: 3.213034
[Epoch 10] ogbg-moltox21: 0.572733 test loss: 3.139734
[Epoch 11; Iter    10/  209] train: loss: 0.2187484
[Epoch 11; Iter    40/  209] train: loss: 0.1812762
[Epoch 11; Iter    70/  209] train: loss: 0.1762019
[Epoch 11; Iter   100/  209] train: loss: 0.3332092
[Epoch 11; Iter   130/  209] train: loss: 0.1879229
[Epoch 11; Iter   160/  209] train: loss: 0.2412698
[Epoch 11; Iter   190/  209] train: loss: 0.1637310
[Epoch 11] ogbg-moltox21: 0.745639 val loss: 0.266882
[Epoch 11] ogbg-moltox21: 0.723345 test loss: 0.268262
[Epoch 12; Iter    11/  209] train: loss: 0.1891798
[Epoch 12; Iter    41/  209] train: loss: 0.1069884
[Epoch 12; Iter    71/  209] train: loss: 0.3170941
[Epoch 12; Iter   101/  209] train: loss: 0.1750933
[Epoch 12; Iter   131/  209] train: loss: 0.2111291
[Epoch 12; Iter   161/  209] train: loss: 0.1671594
[Epoch 12; Iter   191/  209] train: loss: 0.1094209
[Epoch 12] ogbg-moltox21: 0.776992 val loss: 0.253405
[Epoch 12] ogbg-moltox21: 0.723077 test loss: 0.269813
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.05/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.05_6_26-05_10-54-16
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.05
logdir: runs/static_noise/GraphCL/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6927029
[Epoch 1; Iter    60/  209] train: loss: 0.6929868
[Epoch 1; Iter    90/  209] train: loss: 0.6915619
[Epoch 1; Iter   120/  209] train: loss: 0.6923268
[Epoch 1; Iter   150/  209] train: loss: 0.6922335
[Epoch 1; Iter   180/  209] train: loss: 0.6921710
[Epoch 1] ogbg-moltox21: 0.524336 val loss: 0.698354
[Epoch 1] ogbg-moltox21: 0.525578 test loss: 0.698170
[Epoch 2; Iter     1/  209] train: loss: 0.6923613
[Epoch 2; Iter    31/  209] train: loss: 0.6914256
[Epoch 2; Iter    61/  209] train: loss: 0.6919913
[Epoch 2; Iter    91/  209] train: loss: 0.6913896
[Epoch 2; Iter   121/  209] train: loss: 0.6919733
[Epoch 2; Iter   151/  209] train: loss: 0.6909838
[Epoch 2; Iter   181/  209] train: loss: 0.6907174
[Epoch 2] ogbg-moltox21: 0.529151 val loss: 0.697376
[Epoch 2] ogbg-moltox21: 0.527221 test loss: 0.697266
[Epoch 3; Iter     2/  209] train: loss: 0.6907378
[Epoch 3; Iter    32/  209] train: loss: 0.6898230
[Epoch 3; Iter    62/  209] train: loss: 0.6906973
[Epoch 3; Iter    92/  209] train: loss: 0.6896793
[Epoch 3; Iter   122/  209] train: loss: 0.6897318
[Epoch 3; Iter   152/  209] train: loss: 0.6892551
[Epoch 3; Iter   182/  209] train: loss: 0.6880408
[Epoch 3] ogbg-moltox21: 0.529453 val loss: 0.695676
[Epoch 3] ogbg-moltox21: 0.529430 test loss: 0.695582
[Epoch 4; Iter     3/  209] train: loss: 0.6873187
[Epoch 4; Iter    33/  209] train: loss: 0.6880542
[Epoch 4; Iter    63/  209] train: loss: 0.6870164
[Epoch 4; Iter    93/  209] train: loss: 0.6827502
[Epoch 4; Iter   123/  209] train: loss: 0.6598986
[Epoch 4; Iter   153/  209] train: loss: 0.6262661
[Epoch 4; Iter   183/  209] train: loss: 0.6130036
[Epoch 4] ogbg-moltox21: 0.674591 val loss: 0.749702
[Epoch 4] ogbg-moltox21: 0.652849 test loss: 0.752280
[Epoch 5; Iter     4/  209] train: loss: 0.5450509
[Epoch 5; Iter    34/  209] train: loss: 0.4844883
[Epoch 5; Iter    64/  209] train: loss: 0.4225108
[Epoch 5; Iter    94/  209] train: loss: 0.4088061
[Epoch 5; Iter   124/  209] train: loss: 0.3546466
[Epoch 5; Iter   154/  209] train: loss: 0.2848103
[Epoch 5; Iter   184/  209] train: loss: 0.2280133
[Epoch 5] ogbg-moltox21: 0.704410 val loss: 0.323025
[Epoch 5] ogbg-moltox21: 0.692301 test loss: 0.322934
[Epoch 6; Iter     5/  209] train: loss: 0.2108895
[Epoch 6; Iter    35/  209] train: loss: 0.1764572
[Epoch 6; Iter    65/  209] train: loss: 0.1927993
[Epoch 6; Iter    95/  209] train: loss: 0.2173118
[Epoch 6; Iter   125/  209] train: loss: 0.1600387
[Epoch 6; Iter   155/  209] train: loss: 0.2114079
[Epoch 6; Iter   185/  209] train: loss: 0.1757233
[Epoch 6] ogbg-moltox21: 0.725506 val loss: 0.292215
[Epoch 6] ogbg-moltox21: 0.697986 test loss: 0.295197
[Epoch 7; Iter     6/  209] train: loss: 0.1719273
[Epoch 7; Iter    36/  209] train: loss: 0.2460559
[Epoch 7; Iter    66/  209] train: loss: 0.1738063
[Epoch 7; Iter    96/  209] train: loss: 0.2567513
[Epoch 7; Iter   126/  209] train: loss: 0.1935363
[Epoch 7; Iter   156/  209] train: loss: 0.2377070
[Epoch 7; Iter   186/  209] train: loss: 0.2354141
[Epoch 7] ogbg-moltox21: 0.761553 val loss: 1.084247
[Epoch 7] ogbg-moltox21: 0.710667 test loss: 0.819453
[Epoch 8; Iter     7/  209] train: loss: 0.1789852
[Epoch 8; Iter    37/  209] train: loss: 0.1913880
[Epoch 8; Iter    67/  209] train: loss: 0.1643613
[Epoch 8; Iter    97/  209] train: loss: 0.2176941
[Epoch 8; Iter   127/  209] train: loss: 0.2630373
[Epoch 8; Iter   157/  209] train: loss: 0.1681736
[Epoch 8; Iter   187/  209] train: loss: 0.2324001
[Epoch 8] ogbg-moltox21: 0.751962 val loss: 0.277543
[Epoch 8] ogbg-moltox21: 0.706253 test loss: 0.291402
[Epoch 9; Iter     8/  209] train: loss: 0.2499564
[Epoch 9; Iter    38/  209] train: loss: 0.1753088
[Epoch 9; Iter    68/  209] train: loss: 0.1616628
[Epoch 9; Iter    98/  209] train: loss: 0.2561569
[Epoch 9; Iter   128/  209] train: loss: 0.2317481
[Epoch 9; Iter   158/  209] train: loss: 0.1616803
[Epoch 9; Iter   188/  209] train: loss: 0.1611115
[Epoch 9] ogbg-moltox21: 0.757426 val loss: 0.264198
[Epoch 9] ogbg-moltox21: 0.725566 test loss: 0.269356
[Epoch 10; Iter     9/  209] train: loss: 0.2196708
[Epoch 10; Iter    39/  209] train: loss: 0.1711584
[Epoch 10; Iter    69/  209] train: loss: 0.1861182
[Epoch 10; Iter    99/  209] train: loss: 0.1689619
[Epoch 10; Iter   129/  209] train: loss: 0.1420251
[Epoch 10; Iter   159/  209] train: loss: 0.1235908
[Epoch 10; Iter   189/  209] train: loss: 0.1704212
[Epoch 10] ogbg-moltox21: 0.766363 val loss: 0.258634
[Epoch 10] ogbg-moltox21: 0.718472 test loss: 0.272854
[Epoch 11; Iter    10/  209] train: loss: 0.2246296
[Epoch 11; Iter    40/  209] train: loss: 0.2378636
[Epoch 11; Iter    70/  209] train: loss: 0.2023763
[Epoch 11; Iter   100/  209] train: loss: 0.2552607
[Epoch 11; Iter   130/  209] train: loss: 0.1912230
[Epoch 11; Iter   160/  209] train: loss: 0.1956242
[Epoch 11; Iter   190/  209] train: loss: 0.1534608
[Epoch 11] ogbg-moltox21: 0.774391 val loss: 0.254542
[Epoch 11] ogbg-moltox21: 0.736496 test loss: 0.264489
[Epoch 12; Iter    11/  209] train: loss: 0.1228105
[Epoch 12; Iter    41/  209] train: loss: 0.2775562
[Epoch 12; Iter    71/  209] train: loss: 0.1638891
[Epoch 12; Iter   101/  209] train: loss: 0.2181807
[Epoch 12; Iter   131/  209] train: loss: 0.1867443
[Epoch 12; Iter   161/  209] train: loss: 0.2031334
[Epoch 12; Iter   191/  209] train: loss: 0.1592178
[Epoch 12] ogbg-moltox21: 0.782674 val loss: 0.281641
[Epoch 12] ogbg-moltox21: 0.735253 test loss: 0.379563
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.0/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.0_5_26-05_10-52-13
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.0
logdir: runs/static_noise/GraphCL/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6925769
[Epoch 1; Iter    60/  209] train: loss: 0.6934115
[Epoch 1; Iter    90/  209] train: loss: 0.6918342
[Epoch 1; Iter   120/  209] train: loss: 0.6921923
[Epoch 1; Iter   150/  209] train: loss: 0.6927478
[Epoch 1; Iter   180/  209] train: loss: 0.6925935
[Epoch 1] ogbg-moltox21: 0.516602 val loss: 0.692146
[Epoch 1] ogbg-moltox21: 0.491652 test loss: 0.692197
[Epoch 2; Iter     1/  209] train: loss: 0.6920728
[Epoch 2; Iter    31/  209] train: loss: 0.6930675
[Epoch 2; Iter    61/  209] train: loss: 0.6914427
[Epoch 2; Iter    91/  209] train: loss: 0.6918743
[Epoch 2; Iter   121/  209] train: loss: 0.6910730
[Epoch 2; Iter   151/  209] train: loss: 0.6905196
[Epoch 2; Iter   181/  209] train: loss: 0.6907665
[Epoch 2] ogbg-moltox21: 0.525036 val loss: 0.690667
[Epoch 2] ogbg-moltox21: 0.497612 test loss: 0.690749
[Epoch 3; Iter     2/  209] train: loss: 0.6900764
[Epoch 3; Iter    32/  209] train: loss: 0.6899894
[Epoch 3; Iter    62/  209] train: loss: 0.6898114
[Epoch 3; Iter    92/  209] train: loss: 0.6890856
[Epoch 3; Iter   122/  209] train: loss: 0.6884488
[Epoch 3; Iter   152/  209] train: loss: 0.6892733
[Epoch 3; Iter   182/  209] train: loss: 0.6876254
[Epoch 3] ogbg-moltox21: 0.529574 val loss: 0.688181
[Epoch 3] ogbg-moltox21: 0.499922 test loss: 0.688333
[Epoch 4; Iter     3/  209] train: loss: 0.6888004
[Epoch 4; Iter    33/  209] train: loss: 0.6865941
[Epoch 4; Iter    63/  209] train: loss: 0.6861590
[Epoch 4; Iter    93/  209] train: loss: 0.6794155
[Epoch 4; Iter   123/  209] train: loss: 0.6586559
[Epoch 4; Iter   153/  209] train: loss: 0.6249622
[Epoch 4; Iter   183/  209] train: loss: 0.5890962
[Epoch 4] ogbg-moltox21: 0.646006 val loss: 0.640774
[Epoch 4] ogbg-moltox21: 0.658710 test loss: 0.638694
[Epoch 5; Iter     4/  209] train: loss: 0.5337171
[Epoch 5; Iter    34/  209] train: loss: 0.4720433
[Epoch 5; Iter    64/  209] train: loss: 0.4131840
[Epoch 5; Iter    94/  209] train: loss: 0.3521744
[Epoch 5; Iter   124/  209] train: loss: 0.3071619
[Epoch 5; Iter   154/  209] train: loss: 0.3111199
[Epoch 5; Iter   184/  209] train: loss: 0.2566398
[Epoch 5] ogbg-moltox21: 0.683670 val loss: 0.320903
[Epoch 5] ogbg-moltox21: 0.665804 test loss: 0.322122
[Epoch 6; Iter     5/  209] train: loss: 0.2771541
[Epoch 6; Iter    35/  209] train: loss: 0.2205903
[Epoch 6; Iter    65/  209] train: loss: 0.2392009
[Epoch 6; Iter    95/  209] train: loss: 0.1584488
[Epoch 6; Iter   125/  209] train: loss: 0.2611514
[Epoch 6; Iter   155/  209] train: loss: 0.2319890
[Epoch 6; Iter   185/  209] train: loss: 0.1752612
[Epoch 6] ogbg-moltox21: 0.677662 val loss: 0.295081
[Epoch 6] ogbg-moltox21: 0.648006 test loss: 0.302197
[Epoch 7; Iter     6/  209] train: loss: 0.1589395
[Epoch 7; Iter    36/  209] train: loss: 0.1550723
[Epoch 7; Iter    66/  209] train: loss: 0.2141547
[Epoch 7; Iter    96/  209] train: loss: 0.2497334
[Epoch 7; Iter   126/  209] train: loss: 0.3212533
[Epoch 7; Iter   156/  209] train: loss: 0.1722968
[Epoch 7; Iter   186/  209] train: loss: 0.1802453
[Epoch 7] ogbg-moltox21: 0.691444 val loss: 0.343391
[Epoch 7] ogbg-moltox21: 0.685579 test loss: 0.335893
[Epoch 8; Iter     7/  209] train: loss: 0.2276868
[Epoch 8; Iter    37/  209] train: loss: 0.1566515
[Epoch 8; Iter    67/  209] train: loss: 0.1423099
[Epoch 8; Iter    97/  209] train: loss: 0.2030294
[Epoch 8; Iter   127/  209] train: loss: 0.2497001
[Epoch 8; Iter   157/  209] train: loss: 0.1095153
[Epoch 8; Iter   187/  209] train: loss: 0.3161566
[Epoch 8] ogbg-moltox21: 0.692829 val loss: 0.491732
[Epoch 8] ogbg-moltox21: 0.690583 test loss: 0.463035
[Epoch 9; Iter     8/  209] train: loss: 0.1837315
[Epoch 9; Iter    38/  209] train: loss: 0.2256686
[Epoch 9; Iter    68/  209] train: loss: 0.0942934
[Epoch 9; Iter    98/  209] train: loss: 0.1947921
[Epoch 9; Iter   128/  209] train: loss: 0.2194395
[Epoch 9; Iter   158/  209] train: loss: 0.1464103
[Epoch 9; Iter   188/  209] train: loss: 0.2136557
[Epoch 9] ogbg-moltox21: 0.743749 val loss: 0.267746
[Epoch 9] ogbg-moltox21: 0.717549 test loss: 0.272200
[Epoch 10; Iter     9/  209] train: loss: 0.1515135
[Epoch 10; Iter    39/  209] train: loss: 0.2367504
[Epoch 10; Iter    69/  209] train: loss: 0.2838928
[Epoch 10; Iter    99/  209] train: loss: 0.1677250
[Epoch 10; Iter   129/  209] train: loss: 0.1837388
[Epoch 10; Iter   159/  209] train: loss: 0.2430761
[Epoch 10; Iter   189/  209] train: loss: 0.1744719
[Epoch 10] ogbg-moltox21: 0.717703 val loss: 0.281105
[Epoch 10] ogbg-moltox21: 0.694031 test loss: 0.285349
[Epoch 11; Iter    10/  209] train: loss: 0.2081070
[Epoch 11; Iter    40/  209] train: loss: 0.1994221
[Epoch 11; Iter    70/  209] train: loss: 0.1423335
[Epoch 11; Iter   100/  209] train: loss: 0.1840357
[Epoch 11; Iter   130/  209] train: loss: 0.2092510
[Epoch 11; Iter   160/  209] train: loss: 0.2230725
[Epoch 11; Iter   190/  209] train: loss: 0.1882197
[Epoch 11] ogbg-moltox21: 0.753667 val loss: 0.266719
[Epoch 11] ogbg-moltox21: 0.731627 test loss: 0.282757
[Epoch 12; Iter    11/  209] train: loss: 0.2055283
[Epoch 12; Iter    41/  209] train: loss: 0.2294356
[Epoch 12; Iter    71/  209] train: loss: 0.1891649
[Epoch 12; Iter   101/  209] train: loss: 0.1499263
[Epoch 12; Iter   131/  209] train: loss: 0.2608311
[Epoch 12; Iter   161/  209] train: loss: 0.2131430
[Epoch 12; Iter   191/  209] train: loss: 0.2417375
[Epoch 12] ogbg-moltox21: 0.772704 val loss: 0.257672
[Epoch 12] ogbg-moltox21: 0.740866 test loss: 0.281989
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.1/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.1_5_26-05_10-54-38
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.1
logdir: runs/static_noise/GraphCL/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6927401
[Epoch 1; Iter    60/  209] train: loss: 0.6936407
[Epoch 1; Iter    90/  209] train: loss: 0.6923856
[Epoch 1; Iter   120/  209] train: loss: 0.6922128
[Epoch 1; Iter   150/  209] train: loss: 0.6929915
[Epoch 1; Iter   180/  209] train: loss: 0.6922326
[Epoch 1] ogbg-moltox21: 0.508814 val loss: 0.692477
[Epoch 1] ogbg-moltox21: 0.501806 test loss: 0.692830
[Epoch 2; Iter     1/  209] train: loss: 0.6923119
[Epoch 2; Iter    31/  209] train: loss: 0.6931423
[Epoch 2; Iter    61/  209] train: loss: 0.6915123
[Epoch 2; Iter    91/  209] train: loss: 0.6917313
[Epoch 2; Iter   121/  209] train: loss: 0.6909611
[Epoch 2; Iter   151/  209] train: loss: 0.6909581
[Epoch 2; Iter   181/  209] train: loss: 0.6909391
[Epoch 2] ogbg-moltox21: 0.513838 val loss: 0.690736
[Epoch 2] ogbg-moltox21: 0.507252 test loss: 0.691091
[Epoch 3; Iter     2/  209] train: loss: 0.6904710
[Epoch 3; Iter    32/  209] train: loss: 0.6902971
[Epoch 3; Iter    62/  209] train: loss: 0.6898836
[Epoch 3; Iter    92/  209] train: loss: 0.6889684
[Epoch 3; Iter   122/  209] train: loss: 0.6883543
[Epoch 3; Iter   152/  209] train: loss: 0.6890395
[Epoch 3; Iter   182/  209] train: loss: 0.6883957
[Epoch 3] ogbg-moltox21: 0.518152 val loss: 0.688075
[Epoch 3] ogbg-moltox21: 0.509315 test loss: 0.688443
[Epoch 4; Iter     3/  209] train: loss: 0.6883194
[Epoch 4; Iter    33/  209] train: loss: 0.6867660
[Epoch 4; Iter    63/  209] train: loss: 0.6863727
[Epoch 4; Iter    93/  209] train: loss: 0.6804318
[Epoch 4; Iter   123/  209] train: loss: 0.6593263
[Epoch 4; Iter   153/  209] train: loss: 0.6271706
[Epoch 4; Iter   183/  209] train: loss: 0.5935241
[Epoch 4] ogbg-moltox21: 0.625978 val loss: 0.668346
[Epoch 4] ogbg-moltox21: 0.634686 test loss: 0.664843
[Epoch 5; Iter     4/  209] train: loss: 0.5324234
[Epoch 5; Iter    34/  209] train: loss: 0.4709946
[Epoch 5; Iter    64/  209] train: loss: 0.4115177
[Epoch 5; Iter    94/  209] train: loss: 0.3487249
[Epoch 5; Iter   124/  209] train: loss: 0.3080956
[Epoch 5; Iter   154/  209] train: loss: 0.3156180
[Epoch 5; Iter   184/  209] train: loss: 0.2521371
[Epoch 5] ogbg-moltox21: 0.684917 val loss: 0.371995
[Epoch 5] ogbg-moltox21: 0.668997 test loss: 0.364151
[Epoch 6; Iter     5/  209] train: loss: 0.3061072
[Epoch 6; Iter    35/  209] train: loss: 0.2222328
[Epoch 6; Iter    65/  209] train: loss: 0.2761284
[Epoch 6; Iter    95/  209] train: loss: 0.1633431
[Epoch 6; Iter   125/  209] train: loss: 0.2728603
[Epoch 6; Iter   155/  209] train: loss: 0.2447346
[Epoch 6; Iter   185/  209] train: loss: 0.1823485
[Epoch 6] ogbg-moltox21: 0.661643 val loss: 1.099184
[Epoch 6] ogbg-moltox21: 0.645468 test loss: 1.232105
[Epoch 7; Iter     6/  209] train: loss: 0.1632025
[Epoch 7; Iter    36/  209] train: loss: 0.1581857
[Epoch 7; Iter    66/  209] train: loss: 0.2011554
[Epoch 7; Iter    96/  209] train: loss: 0.2570592
[Epoch 7; Iter   126/  209] train: loss: 0.3336419
[Epoch 7; Iter   156/  209] train: loss: 0.1892579
[Epoch 7; Iter   186/  209] train: loss: 0.1845665
[Epoch 7] ogbg-moltox21: 0.638223 val loss: 0.470857
[Epoch 7] ogbg-moltox21: 0.639595 test loss: 0.728367
[Epoch 8; Iter     7/  209] train: loss: 0.2475709
[Epoch 8; Iter    37/  209] train: loss: 0.1671822
[Epoch 8; Iter    67/  209] train: loss: 0.1409864
[Epoch 8; Iter    97/  209] train: loss: 0.2011335
[Epoch 8; Iter   127/  209] train: loss: 0.2655484
[Epoch 8; Iter   157/  209] train: loss: 0.1208677
[Epoch 8; Iter   187/  209] train: loss: 0.3546997
[Epoch 8] ogbg-moltox21: 0.646694 val loss: 0.534932
[Epoch 8] ogbg-moltox21: 0.656863 test loss: 0.463097
[Epoch 9; Iter     8/  209] train: loss: 0.1983205
[Epoch 9; Iter    38/  209] train: loss: 0.2450306
[Epoch 9; Iter    68/  209] train: loss: 0.0886427
[Epoch 9; Iter    98/  209] train: loss: 0.1927480
[Epoch 9; Iter   128/  209] train: loss: 0.2177847
[Epoch 9; Iter   158/  209] train: loss: 0.1574873
[Epoch 9; Iter   188/  209] train: loss: 0.2209755
[Epoch 9] ogbg-moltox21: 0.719586 val loss: 0.282732
[Epoch 9] ogbg-moltox21: 0.703606 test loss: 0.282089
[Epoch 10; Iter     9/  209] train: loss: 0.1600729
[Epoch 10; Iter    39/  209] train: loss: 0.2433429
[Epoch 10; Iter    69/  209] train: loss: 0.2775383
[Epoch 10; Iter    99/  209] train: loss: 0.1696031
[Epoch 10; Iter   129/  209] train: loss: 0.1463866
[Epoch 10; Iter   159/  209] train: loss: 0.2296467
[Epoch 10; Iter   189/  209] train: loss: 0.1777334
[Epoch 10] ogbg-moltox21: 0.775180 val loss: 0.541196
[Epoch 10] ogbg-moltox21: 0.730585 test loss: 0.820262
[Epoch 11; Iter    10/  209] train: loss: 0.1901223
[Epoch 11; Iter    40/  209] train: loss: 0.1793214
[Epoch 11; Iter    70/  209] train: loss: 0.1467584
[Epoch 11; Iter   100/  209] train: loss: 0.1610525
[Epoch 11; Iter   130/  209] train: loss: 0.2095136
[Epoch 11; Iter   160/  209] train: loss: 0.1810065
[Epoch 11; Iter   190/  209] train: loss: 0.1941951
[Epoch 11] ogbg-moltox21: 0.781896 val loss: 0.509228
[Epoch 11] ogbg-moltox21: 0.744010 test loss: 0.812241
[Epoch 12; Iter    11/  209] train: loss: 0.2032587
[Epoch 12; Iter    41/  209] train: loss: 0.2338465
[Epoch 12; Iter    71/  209] train: loss: 0.2207055
[Epoch 12; Iter   101/  209] train: loss: 0.1564556
[Epoch 12; Iter   131/  209] train: loss: 0.2456073
[Epoch 12; Iter   161/  209] train: loss: 0.2175889
[Epoch 12; Iter   191/  209] train: loss: 0.2393185
[Epoch 12] ogbg-moltox21: 0.758286 val loss: 2.753532
[Epoch 12] ogbg-moltox21: 0.730794 test loss: 3.893145
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.05/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.05_5_26-05_10-54-14
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.05
logdir: runs/static_noise/GraphCL/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6928365
[Epoch 1; Iter    60/  209] train: loss: 0.6933476
[Epoch 1; Iter    90/  209] train: loss: 0.6921182
[Epoch 1; Iter   120/  209] train: loss: 0.6921924
[Epoch 1; Iter   150/  209] train: loss: 0.6929727
[Epoch 1; Iter   180/  209] train: loss: 0.6922800
[Epoch 1] ogbg-moltox21: 0.514446 val loss: 0.692435
[Epoch 1] ogbg-moltox21: 0.495579 test loss: 0.692676
[Epoch 2; Iter     1/  209] train: loss: 0.6920727
[Epoch 2; Iter    31/  209] train: loss: 0.6929100
[Epoch 2; Iter    61/  209] train: loss: 0.6914539
[Epoch 2; Iter    91/  209] train: loss: 0.6914195
[Epoch 2; Iter   121/  209] train: loss: 0.6913090
[Epoch 2; Iter   151/  209] train: loss: 0.6907032
[Epoch 2; Iter   181/  209] train: loss: 0.6909513
[Epoch 2] ogbg-moltox21: 0.519593 val loss: 0.690769
[Epoch 2] ogbg-moltox21: 0.501289 test loss: 0.691034
[Epoch 3; Iter     2/  209] train: loss: 0.6902872
[Epoch 3; Iter    32/  209] train: loss: 0.6899342
[Epoch 3; Iter    62/  209] train: loss: 0.6899705
[Epoch 3; Iter    92/  209] train: loss: 0.6891610
[Epoch 3; Iter   122/  209] train: loss: 0.6884310
[Epoch 3; Iter   152/  209] train: loss: 0.6890646
[Epoch 3; Iter   182/  209] train: loss: 0.6879862
[Epoch 3] ogbg-moltox21: 0.525299 val loss: 0.688099
[Epoch 3] ogbg-moltox21: 0.502658 test loss: 0.688374
[Epoch 4; Iter     3/  209] train: loss: 0.6885597
[Epoch 4; Iter    33/  209] train: loss: 0.6866955
[Epoch 4; Iter    63/  209] train: loss: 0.6862922
[Epoch 4; Iter    93/  209] train: loss: 0.6800651
[Epoch 4; Iter   123/  209] train: loss: 0.6586565
[Epoch 4; Iter   153/  209] train: loss: 0.6257667
[Epoch 4; Iter   183/  209] train: loss: 0.5967453
[Epoch 4] ogbg-moltox21: 0.694802 val loss: 0.594954
[Epoch 4] ogbg-moltox21: 0.686081 test loss: 0.594012
[Epoch 5; Iter     4/  209] train: loss: 0.5342141
[Epoch 5; Iter    34/  209] train: loss: 0.4751284
[Epoch 5; Iter    64/  209] train: loss: 0.4110814
[Epoch 5; Iter    94/  209] train: loss: 0.3497779
[Epoch 5; Iter   124/  209] train: loss: 0.3062726
[Epoch 5; Iter   154/  209] train: loss: 0.3123845
[Epoch 5; Iter   184/  209] train: loss: 0.2556625
[Epoch 5] ogbg-moltox21: 0.694946 val loss: 0.380836
[Epoch 5] ogbg-moltox21: 0.683903 test loss: 0.382239
[Epoch 6; Iter     5/  209] train: loss: 0.2983581
[Epoch 6; Iter    35/  209] train: loss: 0.2278270
[Epoch 6; Iter    65/  209] train: loss: 0.2497010
[Epoch 6; Iter    95/  209] train: loss: 0.1577670
[Epoch 6; Iter   125/  209] train: loss: 0.2643917
[Epoch 6; Iter   155/  209] train: loss: 0.2249458
[Epoch 6; Iter   185/  209] train: loss: 0.1878068
[Epoch 6] ogbg-moltox21: 0.693845 val loss: 0.354256
[Epoch 6] ogbg-moltox21: 0.653833 test loss: 0.345204
[Epoch 7; Iter     6/  209] train: loss: 0.1673153
[Epoch 7; Iter    36/  209] train: loss: 0.1543759
[Epoch 7; Iter    66/  209] train: loss: 0.2071846
[Epoch 7; Iter    96/  209] train: loss: 0.2437807
[Epoch 7; Iter   126/  209] train: loss: 0.3192233
[Epoch 7; Iter   156/  209] train: loss: 0.1869500
[Epoch 7; Iter   186/  209] train: loss: 0.1753553
[Epoch 7] ogbg-moltox21: 0.620103 val loss: 0.344731
[Epoch 7] ogbg-moltox21: 0.628116 test loss: 0.336760
[Epoch 8; Iter     7/  209] train: loss: 0.2354082
[Epoch 8; Iter    37/  209] train: loss: 0.1617325
[Epoch 8; Iter    67/  209] train: loss: 0.1443730
[Epoch 8; Iter    97/  209] train: loss: 0.2064024
[Epoch 8; Iter   127/  209] train: loss: 0.2421805
[Epoch 8; Iter   157/  209] train: loss: 0.1266784
[Epoch 8; Iter   187/  209] train: loss: 0.3240383
[Epoch 8] ogbg-moltox21: 0.728464 val loss: 2.522651
[Epoch 8] ogbg-moltox21: 0.699833 test loss: 4.375952
[Epoch 9; Iter     8/  209] train: loss: 0.1937683
[Epoch 9; Iter    38/  209] train: loss: 0.2162417
[Epoch 9; Iter    68/  209] train: loss: 0.0908583
[Epoch 9; Iter    98/  209] train: loss: 0.1844697
[Epoch 9; Iter   128/  209] train: loss: 0.2163351
[Epoch 9; Iter   158/  209] train: loss: 0.1558447
[Epoch 9; Iter   188/  209] train: loss: 0.2082393
[Epoch 9] ogbg-moltox21: 0.715026 val loss: 0.278518
[Epoch 9] ogbg-moltox21: 0.682164 test loss: 0.290822
[Epoch 10; Iter     9/  209] train: loss: 0.1467585
[Epoch 10; Iter    39/  209] train: loss: 0.2355204
[Epoch 10; Iter    69/  209] train: loss: 0.2613192
[Epoch 10; Iter    99/  209] train: loss: 0.1767623
[Epoch 10; Iter   129/  209] train: loss: 0.1519995
[Epoch 10; Iter   159/  209] train: loss: 0.2156733
[Epoch 10; Iter   189/  209] train: loss: 0.1729043
[Epoch 10] ogbg-moltox21: 0.773559 val loss: 0.749167
[Epoch 10] ogbg-moltox21: 0.732595 test loss: 0.587362
[Epoch 11; Iter    10/  209] train: loss: 0.1963633
[Epoch 11; Iter    40/  209] train: loss: 0.2019096
[Epoch 11; Iter    70/  209] train: loss: 0.1349103
[Epoch 11; Iter   100/  209] train: loss: 0.1776606
[Epoch 11; Iter   130/  209] train: loss: 0.2082075
[Epoch 11; Iter   160/  209] train: loss: 0.1827360
[Epoch 11; Iter   190/  209] train: loss: 0.1917326
[Epoch 11] ogbg-moltox21: 0.748359 val loss: 0.312851
[Epoch 11] ogbg-moltox21: 0.729988 test loss: 0.288945
[Epoch 12; Iter    11/  209] train: loss: 0.2134551
[Epoch 12; Iter    41/  209] train: loss: 0.2209186
[Epoch 12; Iter    71/  209] train: loss: 0.2227634
[Epoch 12; Iter   101/  209] train: loss: 0.1309820
[Epoch 12; Iter   131/  209] train: loss: 0.2429062
[Epoch 12; Iter   161/  209] train: loss: 0.2337508
[Epoch 12; Iter   191/  209] train: loss: 0.2281851
[Epoch 12] ogbg-moltox21: 0.759444 val loss: 0.825690
[Epoch 12] ogbg-moltox21: 0.732686 test loss: 0.522239
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.1/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.1_4_26-05_10-54-36
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.1
logdir: runs/static_noise/GraphCL/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6934849
[Epoch 1; Iter    60/  209] train: loss: 0.6929498
[Epoch 1; Iter    90/  209] train: loss: 0.6932725
[Epoch 1; Iter   120/  209] train: loss: 0.6936693
[Epoch 1; Iter   150/  209] train: loss: 0.6931385
[Epoch 1; Iter   180/  209] train: loss: 0.6928124
[Epoch 1] ogbg-moltox21: 0.486394 val loss: 0.688883
[Epoch 1] ogbg-moltox21: 0.500290 test loss: 0.688825
[Epoch 2; Iter     1/  209] train: loss: 0.6917036
[Epoch 2; Iter    31/  209] train: loss: 0.6924939
[Epoch 2; Iter    61/  209] train: loss: 0.6922904
[Epoch 2; Iter    91/  209] train: loss: 0.6919678
[Epoch 2; Iter   121/  209] train: loss: 0.6922465
[Epoch 2; Iter   151/  209] train: loss: 0.6912967
[Epoch 2; Iter   181/  209] train: loss: 0.6914828
[Epoch 2] ogbg-moltox21: 0.488492 val loss: 0.688034
[Epoch 2] ogbg-moltox21: 0.503248 test loss: 0.688058
[Epoch 3; Iter     2/  209] train: loss: 0.6909992
[Epoch 3; Iter    32/  209] train: loss: 0.6899270
[Epoch 3; Iter    62/  209] train: loss: 0.6908369
[Epoch 3; Iter    92/  209] train: loss: 0.6904704
[Epoch 3; Iter   122/  209] train: loss: 0.6892917
[Epoch 3; Iter   152/  209] train: loss: 0.6888351
[Epoch 3; Iter   182/  209] train: loss: 0.6879913
[Epoch 3] ogbg-moltox21: 0.490626 val loss: 0.685274
[Epoch 3] ogbg-moltox21: 0.502327 test loss: 0.685262
[Epoch 4; Iter     3/  209] train: loss: 0.6880340
[Epoch 4; Iter    33/  209] train: loss: 0.6876522
[Epoch 4; Iter    63/  209] train: loss: 0.6869572
[Epoch 4; Iter    93/  209] train: loss: 0.6815020
[Epoch 4; Iter   123/  209] train: loss: 0.6590302
[Epoch 4; Iter   153/  209] train: loss: 0.6290231
[Epoch 4; Iter   183/  209] train: loss: 0.5861071
[Epoch 4] ogbg-moltox21: 0.648317 val loss: 0.731472
[Epoch 4] ogbg-moltox21: 0.630925 test loss: 0.730361
[Epoch 5; Iter     4/  209] train: loss: 0.5311222
[Epoch 5; Iter    34/  209] train: loss: 0.4609157
[Epoch 5; Iter    64/  209] train: loss: 0.4305488
[Epoch 5; Iter    94/  209] train: loss: 0.3813217
[Epoch 5; Iter   124/  209] train: loss: 0.3923289
[Epoch 5; Iter   154/  209] train: loss: 0.2382986
[Epoch 5; Iter   184/  209] train: loss: 0.2375322
[Epoch 5] ogbg-moltox21: 0.691198 val loss: 0.345738
[Epoch 5] ogbg-moltox21: 0.671166 test loss: 0.362583
[Epoch 6; Iter     5/  209] train: loss: 0.2134971
[Epoch 6; Iter    35/  209] train: loss: 0.2193570
[Epoch 6; Iter    65/  209] train: loss: 0.2316267
[Epoch 6; Iter    95/  209] train: loss: 0.2451590
[Epoch 6; Iter   125/  209] train: loss: 0.3200233
[Epoch 6; Iter   155/  209] train: loss: 0.2594658
[Epoch 6; Iter   185/  209] train: loss: 0.2633806
[Epoch 6] ogbg-moltox21: 0.667407 val loss: 0.323398
[Epoch 6] ogbg-moltox21: 0.656113 test loss: 0.350913
[Epoch 7; Iter     6/  209] train: loss: 0.3186533
[Epoch 7; Iter    36/  209] train: loss: 0.2029317
[Epoch 7; Iter    66/  209] train: loss: 0.2597660
[Epoch 7; Iter    96/  209] train: loss: 0.2148709
[Epoch 7; Iter   126/  209] train: loss: 0.1975761
[Epoch 7; Iter   156/  209] train: loss: 0.2275298
[Epoch 7; Iter   186/  209] train: loss: 0.1916630
[Epoch 7] ogbg-moltox21: 0.689440 val loss: 0.335526
[Epoch 7] ogbg-moltox21: 0.662949 test loss: 0.337491
[Epoch 8; Iter     7/  209] train: loss: 0.1250424
[Epoch 8; Iter    37/  209] train: loss: 0.2187289
[Epoch 8; Iter    67/  209] train: loss: 0.3046320
[Epoch 8; Iter    97/  209] train: loss: 0.1940066
[Epoch 8; Iter   127/  209] train: loss: 0.2776881
[Epoch 8; Iter   157/  209] train: loss: 0.1705835
[Epoch 8; Iter   187/  209] train: loss: 0.2054197
[Epoch 8] ogbg-moltox21: 0.738486 val loss: 0.350634
[Epoch 8] ogbg-moltox21: 0.702697 test loss: 0.373866
[Epoch 9; Iter     8/  209] train: loss: 0.2768952
[Epoch 9; Iter    38/  209] train: loss: 0.1654229
[Epoch 9; Iter    68/  209] train: loss: 0.2343246
[Epoch 9; Iter    98/  209] train: loss: 0.1973174
[Epoch 9; Iter   128/  209] train: loss: 0.1903388
[Epoch 9; Iter   158/  209] train: loss: 0.2106538
[Epoch 9; Iter   188/  209] train: loss: 0.2293558
[Epoch 9] ogbg-moltox21: 0.711815 val loss: 0.754994
[Epoch 9] ogbg-moltox21: 0.674520 test loss: 0.706844
[Epoch 10; Iter     9/  209] train: loss: 0.2524078
[Epoch 10; Iter    39/  209] train: loss: 0.2096823
[Epoch 10; Iter    69/  209] train: loss: 0.2052142
[Epoch 10; Iter    99/  209] train: loss: 0.2029765
[Epoch 10; Iter   129/  209] train: loss: 0.2310636
[Epoch 10; Iter   159/  209] train: loss: 0.1951400
[Epoch 10; Iter   189/  209] train: loss: 0.2399136
[Epoch 10] ogbg-moltox21: 0.658630 val loss: 0.374712
[Epoch 10] ogbg-moltox21: 0.681433 test loss: 0.338596
[Epoch 11; Iter    10/  209] train: loss: 0.2433971
[Epoch 11; Iter    40/  209] train: loss: 0.1690082
[Epoch 11; Iter    70/  209] train: loss: 0.1950582
[Epoch 11; Iter   100/  209] train: loss: 0.3246629
[Epoch 11; Iter   130/  209] train: loss: 0.2064209
[Epoch 11; Iter   160/  209] train: loss: 0.2191704
[Epoch 11; Iter   190/  209] train: loss: 0.1783137
[Epoch 11] ogbg-moltox21: 0.740405 val loss: 0.335245
[Epoch 11] ogbg-moltox21: 0.708614 test loss: 0.339074
[Epoch 12; Iter    11/  209] train: loss: 0.1970105
[Epoch 12; Iter    41/  209] train: loss: 0.1062963
[Epoch 12; Iter    71/  209] train: loss: 0.3017188
[Epoch 12; Iter   101/  209] train: loss: 0.1745265
[Epoch 12; Iter   131/  209] train: loss: 0.1977042
[Epoch 12; Iter   161/  209] train: loss: 0.1838966
[Epoch 12; Iter   191/  209] train: loss: 0.1244086
[Epoch 12] ogbg-moltox21: 0.753538 val loss: 0.265540
[Epoch 12] ogbg-moltox21: 0.722659 test loss: 0.278878
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.1/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.1_6_26-05_10-54-39
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.1
logdir: runs/static_noise/GraphCL/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6926515
[Epoch 1; Iter    60/  209] train: loss: 0.6928267
[Epoch 1; Iter    90/  209] train: loss: 0.6914811
[Epoch 1; Iter   120/  209] train: loss: 0.6927372
[Epoch 1; Iter   150/  209] train: loss: 0.6925905
[Epoch 1; Iter   180/  209] train: loss: 0.6922092
[Epoch 1] ogbg-moltox21: 0.522635 val loss: 0.700346
[Epoch 1] ogbg-moltox21: 0.526109 test loss: 0.700129
[Epoch 2; Iter     1/  209] train: loss: 0.6932023
[Epoch 2; Iter    31/  209] train: loss: 0.6916099
[Epoch 2; Iter    61/  209] train: loss: 0.6918846
[Epoch 2; Iter    91/  209] train: loss: 0.6915997
[Epoch 2; Iter   121/  209] train: loss: 0.6917898
[Epoch 2; Iter   151/  209] train: loss: 0.6912631
[Epoch 2; Iter   181/  209] train: loss: 0.6910298
[Epoch 2] ogbg-moltox21: 0.524701 val loss: 0.699399
[Epoch 2] ogbg-moltox21: 0.529260 test loss: 0.699230
[Epoch 3; Iter     2/  209] train: loss: 0.6903391
[Epoch 3; Iter    32/  209] train: loss: 0.6903080
[Epoch 3; Iter    62/  209] train: loss: 0.6907392
[Epoch 3; Iter    92/  209] train: loss: 0.6900041
[Epoch 3; Iter   122/  209] train: loss: 0.6898665
[Epoch 3; Iter   152/  209] train: loss: 0.6892369
[Epoch 3; Iter   182/  209] train: loss: 0.6880506
[Epoch 3] ogbg-moltox21: 0.527701 val loss: 0.697701
[Epoch 3] ogbg-moltox21: 0.528503 test loss: 0.697582
[Epoch 4; Iter     3/  209] train: loss: 0.6874205
[Epoch 4; Iter    33/  209] train: loss: 0.6879687
[Epoch 4; Iter    63/  209] train: loss: 0.6876703
[Epoch 4; Iter    93/  209] train: loss: 0.6827649
[Epoch 4; Iter   123/  209] train: loss: 0.6589375
[Epoch 4; Iter   153/  209] train: loss: 0.6265251
[Epoch 4; Iter   183/  209] train: loss: 0.6128861
[Epoch 4] ogbg-moltox21: 0.662122 val loss: 0.721596
[Epoch 4] ogbg-moltox21: 0.647555 test loss: 0.723054
[Epoch 5; Iter     4/  209] train: loss: 0.5427380
[Epoch 5; Iter    34/  209] train: loss: 0.4880221
[Epoch 5; Iter    64/  209] train: loss: 0.4327846
[Epoch 5; Iter    94/  209] train: loss: 0.4158021
[Epoch 5; Iter   124/  209] train: loss: 0.3505193
[Epoch 5; Iter   154/  209] train: loss: 0.2837260
[Epoch 5; Iter   184/  209] train: loss: 0.2326372
[Epoch 5] ogbg-moltox21: 0.701352 val loss: 0.317072
[Epoch 5] ogbg-moltox21: 0.680182 test loss: 0.316592
[Epoch 6; Iter     5/  209] train: loss: 0.2225562
[Epoch 6; Iter    35/  209] train: loss: 0.1658710
[Epoch 6; Iter    65/  209] train: loss: 0.1927176
[Epoch 6; Iter    95/  209] train: loss: 0.2201877
[Epoch 6; Iter   125/  209] train: loss: 0.1592525
[Epoch 6; Iter   155/  209] train: loss: 0.2218239
[Epoch 6; Iter   185/  209] train: loss: 0.1772632
[Epoch 6] ogbg-moltox21: 0.713212 val loss: 0.277223
[Epoch 6] ogbg-moltox21: 0.699057 test loss: 0.277484
[Epoch 7; Iter     6/  209] train: loss: 0.1796900
[Epoch 7; Iter    36/  209] train: loss: 0.2468024
[Epoch 7; Iter    66/  209] train: loss: 0.1808501
[Epoch 7; Iter    96/  209] train: loss: 0.2645911
[Epoch 7; Iter   126/  209] train: loss: 0.1915657
[Epoch 7; Iter   156/  209] train: loss: 0.2515158
[Epoch 7; Iter   186/  209] train: loss: 0.2236821
[Epoch 7] ogbg-moltox21: 0.736811 val loss: 0.327236
[Epoch 7] ogbg-moltox21: 0.700262 test loss: 0.307185
[Epoch 8; Iter     7/  209] train: loss: 0.1899665
[Epoch 8; Iter    37/  209] train: loss: 0.2120541
[Epoch 8; Iter    67/  209] train: loss: 0.1677952
[Epoch 8; Iter    97/  209] train: loss: 0.2404361
[Epoch 8; Iter   127/  209] train: loss: 0.2738554
[Epoch 8; Iter   157/  209] train: loss: 0.1582645
[Epoch 8; Iter   187/  209] train: loss: 0.2468472
[Epoch 8] ogbg-moltox21: 0.742995 val loss: 0.314612
[Epoch 8] ogbg-moltox21: 0.719202 test loss: 0.295204
[Epoch 9; Iter     8/  209] train: loss: 0.2532497
[Epoch 9; Iter    38/  209] train: loss: 0.1786722
[Epoch 9; Iter    68/  209] train: loss: 0.1720985
[Epoch 9; Iter    98/  209] train: loss: 0.2613947
[Epoch 9; Iter   128/  209] train: loss: 0.1995651
[Epoch 9; Iter   158/  209] train: loss: 0.1572150
[Epoch 9; Iter   188/  209] train: loss: 0.1706591
[Epoch 9] ogbg-moltox21: 0.752976 val loss: 0.273592
[Epoch 9] ogbg-moltox21: 0.698418 test loss: 0.355110
[Epoch 10; Iter     9/  209] train: loss: 0.2258241
[Epoch 10; Iter    39/  209] train: loss: 0.1693024
[Epoch 10; Iter    69/  209] train: loss: 0.1869714
[Epoch 10; Iter    99/  209] train: loss: 0.1755472
[Epoch 10; Iter   129/  209] train: loss: 0.1535584
[Epoch 10; Iter   159/  209] train: loss: 0.1329375
[Epoch 10; Iter   189/  209] train: loss: 0.1793714
[Epoch 10] ogbg-moltox21: 0.747524 val loss: 0.876916
[Epoch 10] ogbg-moltox21: 0.714744 test loss: 1.754420
[Epoch 11; Iter    10/  209] train: loss: 0.2392101
[Epoch 11; Iter    40/  209] train: loss: 0.1968727
[Epoch 11; Iter    70/  209] train: loss: 0.2157284
[Epoch 11; Iter   100/  209] train: loss: 0.2545113
[Epoch 11; Iter   130/  209] train: loss: 0.1889483
[Epoch 11; Iter   160/  209] train: loss: 0.1900149
[Epoch 11; Iter   190/  209] train: loss: 0.1594223
[Epoch 11] ogbg-moltox21: 0.773471 val loss: 0.395204
[Epoch 11] ogbg-moltox21: 0.716071 test loss: 0.412885
[Epoch 12; Iter    11/  209] train: loss: 0.0988333
[Epoch 12; Iter    41/  209] train: loss: 0.2750968
[Epoch 12; Iter    71/  209] train: loss: 0.1762619
[Epoch 12; Iter   101/  209] train: loss: 0.1874363
[Epoch 12; Iter   131/  209] train: loss: 0.1925758
[Epoch 12; Iter   161/  209] train: loss: 0.2123342
[Epoch 12; Iter   191/  209] train: loss: 0.1559523
[Epoch 12] ogbg-moltox21: 0.782635 val loss: 0.275204
[Epoch 12] ogbg-moltox21: 0.718123 test loss: 0.327793
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.2/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.2_5_26-05_10-55-02
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.2
logdir: runs/static_noise/GraphCL/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6927948
[Epoch 1; Iter    60/  209] train: loss: 0.6933439
[Epoch 1; Iter    90/  209] train: loss: 0.6927009
[Epoch 1; Iter   120/  209] train: loss: 0.6923534
[Epoch 1; Iter   150/  209] train: loss: 0.6927810
[Epoch 1; Iter   180/  209] train: loss: 0.6927280
[Epoch 1] ogbg-moltox21: 0.511992 val loss: 0.692798
[Epoch 1] ogbg-moltox21: 0.510308 test loss: 0.693416
[Epoch 2; Iter     1/  209] train: loss: 0.6924002
[Epoch 2; Iter    31/  209] train: loss: 0.6930745
[Epoch 2; Iter    61/  209] train: loss: 0.6918743
[Epoch 2; Iter    91/  209] train: loss: 0.6917437
[Epoch 2; Iter   121/  209] train: loss: 0.6910920
[Epoch 2; Iter   151/  209] train: loss: 0.6909918
[Epoch 2; Iter   181/  209] train: loss: 0.6908298
[Epoch 2] ogbg-moltox21: 0.513872 val loss: 0.690830
[Epoch 2] ogbg-moltox21: 0.514040 test loss: 0.691411
[Epoch 3; Iter     2/  209] train: loss: 0.6903028
[Epoch 3; Iter    32/  209] train: loss: 0.6903640
[Epoch 3; Iter    62/  209] train: loss: 0.6900576
[Epoch 3; Iter    92/  209] train: loss: 0.6895320
[Epoch 3; Iter   122/  209] train: loss: 0.6883240
[Epoch 3; Iter   152/  209] train: loss: 0.6888502
[Epoch 3; Iter   182/  209] train: loss: 0.6886947
[Epoch 3] ogbg-moltox21: 0.517479 val loss: 0.688598
[Epoch 3] ogbg-moltox21: 0.512924 test loss: 0.689252
[Epoch 4; Iter     3/  209] train: loss: 0.6881372
[Epoch 4; Iter    33/  209] train: loss: 0.6869308
[Epoch 4; Iter    63/  209] train: loss: 0.6863363
[Epoch 4; Iter    93/  209] train: loss: 0.6800420
[Epoch 4; Iter   123/  209] train: loss: 0.6588184
[Epoch 4; Iter   153/  209] train: loss: 0.6249311
[Epoch 4; Iter   183/  209] train: loss: 0.5952430
[Epoch 4] ogbg-moltox21: 0.638308 val loss: 0.906255
[Epoch 4] ogbg-moltox21: 0.626955 test loss: 0.994909
[Epoch 5; Iter     4/  209] train: loss: 0.5323989
[Epoch 5; Iter    34/  209] train: loss: 0.4754465
[Epoch 5; Iter    64/  209] train: loss: 0.4124451
[Epoch 5; Iter    94/  209] train: loss: 0.3540601
[Epoch 5; Iter   124/  209] train: loss: 0.3073778
[Epoch 5; Iter   154/  209] train: loss: 0.3112967
[Epoch 5; Iter   184/  209] train: loss: 0.2627828
[Epoch 5] ogbg-moltox21: 0.604556 val loss: 0.478795
[Epoch 5] ogbg-moltox21: 0.625382 test loss: 0.548074
[Epoch 6; Iter     5/  209] train: loss: 0.2987384
[Epoch 6; Iter    35/  209] train: loss: 0.2301717
[Epoch 6; Iter    65/  209] train: loss: 0.2762012
[Epoch 6; Iter    95/  209] train: loss: 0.1604816
[Epoch 6; Iter   125/  209] train: loss: 0.2668595
[Epoch 6; Iter   155/  209] train: loss: 0.2338565
[Epoch 6; Iter   185/  209] train: loss: 0.1844640
[Epoch 6] ogbg-moltox21: 0.642274 val loss: 0.413086
[Epoch 6] ogbg-moltox21: 0.606202 test loss: 0.398256
[Epoch 7; Iter     6/  209] train: loss: 0.1789481
[Epoch 7; Iter    36/  209] train: loss: 0.1603179
[Epoch 7; Iter    66/  209] train: loss: 0.2026388
[Epoch 7; Iter    96/  209] train: loss: 0.2474397
[Epoch 7; Iter   126/  209] train: loss: 0.3404230
[Epoch 7; Iter   156/  209] train: loss: 0.2054051
[Epoch 7; Iter   186/  209] train: loss: 0.1823606
[Epoch 7] ogbg-moltox21: 0.645286 val loss: 2.638073
[Epoch 7] ogbg-moltox21: 0.638030 test loss: 2.808509
[Epoch 8; Iter     7/  209] train: loss: 0.2510471
[Epoch 8; Iter    37/  209] train: loss: 0.1718449
[Epoch 8; Iter    67/  209] train: loss: 0.1534619
[Epoch 8; Iter    97/  209] train: loss: 0.2119580
[Epoch 8; Iter   127/  209] train: loss: 0.2749966
[Epoch 8; Iter   157/  209] train: loss: 0.1283691
[Epoch 8; Iter   187/  209] train: loss: 0.3609933
[Epoch 8] ogbg-moltox21: 0.687557 val loss: 8.302325
[Epoch 8] ogbg-moltox21: 0.635090 test loss: 9.842052
[Epoch 9; Iter     8/  209] train: loss: 0.2065609
[Epoch 9; Iter    38/  209] train: loss: 0.2515314
[Epoch 9; Iter    68/  209] train: loss: 0.0952614
[Epoch 9; Iter    98/  209] train: loss: 0.2063138
[Epoch 9; Iter   128/  209] train: loss: 0.2134800
[Epoch 9; Iter   158/  209] train: loss: 0.1724848
[Epoch 9; Iter   188/  209] train: loss: 0.2507484
[Epoch 9] ogbg-moltox21: 0.716738 val loss: 0.447979
[Epoch 9] ogbg-moltox21: 0.684201 test loss: 0.445112
[Epoch 10; Iter     9/  209] train: loss: 0.1626947
[Epoch 10; Iter    39/  209] train: loss: 0.2737916
[Epoch 10; Iter    69/  209] train: loss: 0.2699963
[Epoch 10; Iter    99/  209] train: loss: 0.1885348
[Epoch 10; Iter   129/  209] train: loss: 0.1755628
[Epoch 10; Iter   159/  209] train: loss: 0.2378198
[Epoch 10; Iter   189/  209] train: loss: 0.1631122
[Epoch 10] ogbg-moltox21: 0.731360 val loss: 0.308704
[Epoch 10] ogbg-moltox21: 0.695987 test loss: 0.325847
[Epoch 11; Iter    10/  209] train: loss: 0.1985493
[Epoch 11; Iter    40/  209] train: loss: 0.2001196
[Epoch 11; Iter    70/  209] train: loss: 0.1543898
[Epoch 11; Iter   100/  209] train: loss: 0.2048975
[Epoch 11; Iter   130/  209] train: loss: 0.1966074
[Epoch 11; Iter   160/  209] train: loss: 0.1985518
[Epoch 11; Iter   190/  209] train: loss: 0.1925077
[Epoch 11] ogbg-moltox21: 0.743882 val loss: 0.284688
[Epoch 11] ogbg-moltox21: 0.710264 test loss: 0.340647
[Epoch 12; Iter    11/  209] train: loss: 0.2350359
[Epoch 12; Iter    41/  209] train: loss: 0.2344817
[Epoch 12; Iter    71/  209] train: loss: 0.2264901
[Epoch 12; Iter   101/  209] train: loss: 0.1532366
[Epoch 12; Iter   131/  209] train: loss: 0.2528850
[Epoch 12; Iter   161/  209] train: loss: 0.2271371
[Epoch 12; Iter   191/  209] train: loss: 0.2449316
[Epoch 12] ogbg-moltox21: 0.733536 val loss: 0.298278
[Epoch 12] ogbg-moltox21: 0.697314 test loss: 0.335182
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.2/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.2_4_26-05_10-55-09
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.2
logdir: runs/static_noise/GraphCL/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935415
[Epoch 1; Iter    60/  209] train: loss: 0.6932541
[Epoch 1; Iter    90/  209] train: loss: 0.6937351
[Epoch 1; Iter   120/  209] train: loss: 0.6931234
[Epoch 1; Iter   150/  209] train: loss: 0.6930662
[Epoch 1; Iter   180/  209] train: loss: 0.6926628
[Epoch 1] ogbg-moltox21: 0.485206 val loss: 0.688066
[Epoch 1] ogbg-moltox21: 0.496598 test loss: 0.688083
[Epoch 2; Iter     1/  209] train: loss: 0.6918402
[Epoch 2; Iter    31/  209] train: loss: 0.6926043
[Epoch 2; Iter    61/  209] train: loss: 0.6920909
[Epoch 2; Iter    91/  209] train: loss: 0.6918309
[Epoch 2; Iter   121/  209] train: loss: 0.6921631
[Epoch 2; Iter   151/  209] train: loss: 0.6915807
[Epoch 2; Iter   181/  209] train: loss: 0.6917721
[Epoch 2] ogbg-moltox21: 0.486702 val loss: 0.687064
[Epoch 2] ogbg-moltox21: 0.497811 test loss: 0.687143
[Epoch 3; Iter     2/  209] train: loss: 0.6905962
[Epoch 3; Iter    32/  209] train: loss: 0.6899775
[Epoch 3; Iter    62/  209] train: loss: 0.6908827
[Epoch 3; Iter    92/  209] train: loss: 0.6902623
[Epoch 3; Iter   122/  209] train: loss: 0.6893492
[Epoch 3; Iter   152/  209] train: loss: 0.6890032
[Epoch 3; Iter   182/  209] train: loss: 0.6880161
[Epoch 3] ogbg-moltox21: 0.489403 val loss: 0.684700
[Epoch 3] ogbg-moltox21: 0.498108 test loss: 0.684775
[Epoch 4; Iter     3/  209] train: loss: 0.6883428
[Epoch 4; Iter    33/  209] train: loss: 0.6872163
[Epoch 4; Iter    63/  209] train: loss: 0.6865205
[Epoch 4; Iter    93/  209] train: loss: 0.6817745
[Epoch 4; Iter   123/  209] train: loss: 0.6590727
[Epoch 4; Iter   153/  209] train: loss: 0.6311933
[Epoch 4; Iter   183/  209] train: loss: 0.5868177
[Epoch 4] ogbg-moltox21: 0.676438 val loss: 0.737214
[Epoch 4] ogbg-moltox21: 0.647113 test loss: 0.734696
[Epoch 5; Iter     4/  209] train: loss: 0.5405495
[Epoch 5; Iter    34/  209] train: loss: 0.4602146
[Epoch 5; Iter    64/  209] train: loss: 0.4343562
[Epoch 5; Iter    94/  209] train: loss: 0.3763526
[Epoch 5; Iter   124/  209] train: loss: 0.4035688
[Epoch 5; Iter   154/  209] train: loss: 0.2401581
[Epoch 5; Iter   184/  209] train: loss: 0.2451093
[Epoch 5] ogbg-moltox21: 0.676474 val loss: 0.934364
[Epoch 5] ogbg-moltox21: 0.657531 test loss: 0.749734
[Epoch 6; Iter     5/  209] train: loss: 0.2229799
[Epoch 6; Iter    35/  209] train: loss: 0.2134389
[Epoch 6; Iter    65/  209] train: loss: 0.2288796
[Epoch 6; Iter    95/  209] train: loss: 0.2397013
[Epoch 6; Iter   125/  209] train: loss: 0.3288676
[Epoch 6; Iter   155/  209] train: loss: 0.2575687
[Epoch 6; Iter   185/  209] train: loss: 0.2602471
[Epoch 6] ogbg-moltox21: 0.691403 val loss: 1.414537
[Epoch 6] ogbg-moltox21: 0.651289 test loss: 1.096858
[Epoch 7; Iter     6/  209] train: loss: 0.3261772
[Epoch 7; Iter    36/  209] train: loss: 0.2057272
[Epoch 7; Iter    66/  209] train: loss: 0.2795177
[Epoch 7; Iter    96/  209] train: loss: 0.2105141
[Epoch 7; Iter   126/  209] train: loss: 0.1918605
[Epoch 7; Iter   156/  209] train: loss: 0.2388890
[Epoch 7; Iter   186/  209] train: loss: 0.1871933
[Epoch 7] ogbg-moltox21: 0.712652 val loss: 2.475909
[Epoch 7] ogbg-moltox21: 0.682834 test loss: 1.516476
[Epoch 8; Iter     7/  209] train: loss: 0.1275555
[Epoch 8; Iter    37/  209] train: loss: 0.2246335
[Epoch 8; Iter    67/  209] train: loss: 0.3046453
[Epoch 8; Iter    97/  209] train: loss: 0.2012856
[Epoch 8; Iter   127/  209] train: loss: 0.2795894
[Epoch 8; Iter   157/  209] train: loss: 0.1795070
[Epoch 8; Iter   187/  209] train: loss: 0.2231946
[Epoch 8] ogbg-moltox21: 0.675191 val loss: 1.331437
[Epoch 8] ogbg-moltox21: 0.679304 test loss: 0.945614
[Epoch 9; Iter     8/  209] train: loss: 0.2837740
[Epoch 9; Iter    38/  209] train: loss: 0.1646027
[Epoch 9; Iter    68/  209] train: loss: 0.2568811
[Epoch 9; Iter    98/  209] train: loss: 0.2068809
[Epoch 9; Iter   128/  209] train: loss: 0.1942938
[Epoch 9; Iter   158/  209] train: loss: 0.2013163
[Epoch 9; Iter   188/  209] train: loss: 0.2261815
[Epoch 9] ogbg-moltox21: 0.624954 val loss: 1.642897
[Epoch 9] ogbg-moltox21: 0.647902 test loss: 1.274074
[Epoch 10; Iter     9/  209] train: loss: 0.2649252
[Epoch 10; Iter    39/  209] train: loss: 0.1936409
[Epoch 10; Iter    69/  209] train: loss: 0.2126702
[Epoch 10; Iter    99/  209] train: loss: 0.2391254
[Epoch 10; Iter   129/  209] train: loss: 0.2354113
[Epoch 10; Iter   159/  209] train: loss: 0.1647892
[Epoch 10; Iter   189/  209] train: loss: 0.2348610
[Epoch 10] ogbg-moltox21: 0.733458 val loss: 0.329640
[Epoch 10] ogbg-moltox21: 0.712984 test loss: 0.277903
[Epoch 11; Iter    10/  209] train: loss: 0.1829108
[Epoch 11; Iter    40/  209] train: loss: 0.1940352
[Epoch 11; Iter    70/  209] train: loss: 0.2005164
[Epoch 11; Iter   100/  209] train: loss: 0.3442988
[Epoch 11; Iter   130/  209] train: loss: 0.2324919
[Epoch 11; Iter   160/  209] train: loss: 0.2589985
[Epoch 11; Iter   190/  209] train: loss: 0.1938017
[Epoch 11] ogbg-moltox21: 0.737830 val loss: 0.841188
[Epoch 11] ogbg-moltox21: 0.705227 test loss: 0.661760
[Epoch 12; Iter    11/  209] train: loss: 0.2194852
[Epoch 12; Iter    41/  209] train: loss: 0.1118808
[Epoch 12; Iter    71/  209] train: loss: 0.3183842
[Epoch 12; Iter   101/  209] train: loss: 0.1844142
[Epoch 12; Iter   131/  209] train: loss: 0.2087775
[Epoch 12; Iter   161/  209] train: loss: 0.1897950
[Epoch 12; Iter   191/  209] train: loss: 0.1378439
[Epoch 12] ogbg-moltox21: 0.763541 val loss: 0.258931
[Epoch 12] ogbg-moltox21: 0.731881 test loss: 0.266565
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/tox21/noise=0.2/PNA_ogbg-moltox21_GraphCL_tox21_static_noise=0.2_6_26-05_10-55-08
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_static_noise=0.2
logdir: runs/static_noise/GraphCL/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935025
[Epoch 1; Iter    60/  209] train: loss: 0.6926348
[Epoch 1; Iter    90/  209] train: loss: 0.6915196
[Epoch 1; Iter   120/  209] train: loss: 0.6927838
[Epoch 1; Iter   150/  209] train: loss: 0.6927536
[Epoch 1; Iter   180/  209] train: loss: 0.6918002
[Epoch 1] ogbg-moltox21: 0.513231 val loss: 0.701746
[Epoch 1] ogbg-moltox21: 0.518130 test loss: 0.701339
[Epoch 2; Iter     1/  209] train: loss: 0.6931603
[Epoch 2; Iter    31/  209] train: loss: 0.6915101
[Epoch 2; Iter    61/  209] train: loss: 0.6922522
[Epoch 2; Iter    91/  209] train: loss: 0.6909485
[Epoch 2; Iter   121/  209] train: loss: 0.6912537
[Epoch 2; Iter   151/  209] train: loss: 0.6908015
[Epoch 2; Iter   181/  209] train: loss: 0.6908938
[Epoch 2] ogbg-moltox21: 0.514549 val loss: 0.701054
[Epoch 2] ogbg-moltox21: 0.521223 test loss: 0.700678
[Epoch 3; Iter     2/  209] train: loss: 0.6908175
[Epoch 3; Iter    32/  209] train: loss: 0.6903338
[Epoch 3; Iter    62/  209] train: loss: 0.6904037
[Epoch 3; Iter    92/  209] train: loss: 0.6901366
[Epoch 3; Iter   122/  209] train: loss: 0.6899749
[Epoch 3; Iter   152/  209] train: loss: 0.6902910
[Epoch 3; Iter   182/  209] train: loss: 0.6878982
[Epoch 3] ogbg-moltox21: 0.517622 val loss: 0.699509
[Epoch 3] ogbg-moltox21: 0.523411 test loss: 0.699173
[Epoch 4; Iter     3/  209] train: loss: 0.6876739
[Epoch 4; Iter    33/  209] train: loss: 0.6878094
[Epoch 4; Iter    63/  209] train: loss: 0.6870332
[Epoch 4; Iter    93/  209] train: loss: 0.6832051
[Epoch 4; Iter   123/  209] train: loss: 0.6553438
[Epoch 4; Iter   153/  209] train: loss: 0.6271692
[Epoch 4; Iter   183/  209] train: loss: 0.6212293
[Epoch 4] ogbg-moltox21: 0.644784 val loss: 0.778780
[Epoch 4] ogbg-moltox21: 0.643259 test loss: 0.778396
[Epoch 5; Iter     4/  209] train: loss: 0.5443966
[Epoch 5; Iter    34/  209] train: loss: 0.4927329
[Epoch 5; Iter    64/  209] train: loss: 0.4325246
[Epoch 5; Iter    94/  209] train: loss: 0.4167696
[Epoch 5; Iter   124/  209] train: loss: 0.3582297
[Epoch 5; Iter   154/  209] train: loss: 0.2906198
[Epoch 5; Iter   184/  209] train: loss: 0.2390004
[Epoch 5] ogbg-moltox21: 0.666877 val loss: 0.422585
[Epoch 5] ogbg-moltox21: 0.660718 test loss: 0.380423
[Epoch 6; Iter     5/  209] train: loss: 0.2267600
[Epoch 6; Iter    35/  209] train: loss: 0.1603042
[Epoch 6; Iter    65/  209] train: loss: 0.2038687
[Epoch 6; Iter    95/  209] train: loss: 0.2099544
[Epoch 6; Iter   125/  209] train: loss: 0.1627776
[Epoch 6; Iter   155/  209] train: loss: 0.2221290
[Epoch 6; Iter   185/  209] train: loss: 0.1799819
[Epoch 6] ogbg-moltox21: 0.713993 val loss: 0.321117
[Epoch 6] ogbg-moltox21: 0.696991 test loss: 0.303969
[Epoch 7; Iter     6/  209] train: loss: 0.1703246
[Epoch 7; Iter    36/  209] train: loss: 0.2481568
[Epoch 7; Iter    66/  209] train: loss: 0.1887097
[Epoch 7; Iter    96/  209] train: loss: 0.2917385
[Epoch 7; Iter   126/  209] train: loss: 0.1848509
[Epoch 7; Iter   156/  209] train: loss: 0.2359257
[Epoch 7; Iter   186/  209] train: loss: 0.2324425
[Epoch 7] ogbg-moltox21: 0.747137 val loss: 0.549671
[Epoch 7] ogbg-moltox21: 0.710966 test loss: 0.443580
[Epoch 8; Iter     7/  209] train: loss: 0.1958815
[Epoch 8; Iter    37/  209] train: loss: 0.2101021
[Epoch 8; Iter    67/  209] train: loss: 0.1709441
[Epoch 8; Iter    97/  209] train: loss: 0.2224504
[Epoch 8; Iter   127/  209] train: loss: 0.2803347
[Epoch 8; Iter   157/  209] train: loss: 0.1623303
[Epoch 8; Iter   187/  209] train: loss: 0.2208949
[Epoch 8] ogbg-moltox21: 0.716812 val loss: 0.474381
[Epoch 8] ogbg-moltox21: 0.696693 test loss: 0.515498
[Epoch 9; Iter     8/  209] train: loss: 0.2464313
[Epoch 9; Iter    38/  209] train: loss: 0.1724907
[Epoch 9; Iter    68/  209] train: loss: 0.1756011
[Epoch 9; Iter    98/  209] train: loss: 0.2794409
[Epoch 9; Iter   128/  209] train: loss: 0.2019887
[Epoch 9; Iter   158/  209] train: loss: 0.1707173
[Epoch 9; Iter   188/  209] train: loss: 0.1845727
[Epoch 9] ogbg-moltox21: 0.710552 val loss: 0.642077
[Epoch 9] ogbg-moltox21: 0.682653 test loss: 0.568180
[Epoch 10; Iter     9/  209] train: loss: 0.2039253
[Epoch 10; Iter    39/  209] train: loss: 0.1848512
[Epoch 10; Iter    69/  209] train: loss: 0.2095961
[Epoch 10; Iter    99/  209] train: loss: 0.1639331
[Epoch 10; Iter   129/  209] train: loss: 0.1473247
[Epoch 10; Iter   159/  209] train: loss: 0.1239724
[Epoch 10; Iter   189/  209] train: loss: 0.1809393
[Epoch 10] ogbg-moltox21: 0.740207 val loss: 0.656980
[Epoch 10] ogbg-moltox21: 0.701500 test loss: 0.651741
[Epoch 11; Iter    10/  209] train: loss: 0.2318689
[Epoch 11; Iter    40/  209] train: loss: 0.2015851
[Epoch 11; Iter    70/  209] train: loss: 0.2037527
[Epoch 11; Iter   100/  209] train: loss: 0.2603953
[Epoch 11; Iter   130/  209] train: loss: 0.2195471
[Epoch 11; Iter   160/  209] train: loss: 0.1846162
[Epoch 11; Iter   190/  209] train: loss: 0.1548888
[Epoch 11] ogbg-moltox21: 0.734071 val loss: 0.541065
[Epoch 11] ogbg-moltox21: 0.689237 test loss: 0.752539
[Epoch 12; Iter    11/  209] train: loss: 0.1106378
[Epoch 12; Iter    41/  209] train: loss: 0.2829423
[Epoch 12; Iter    71/  209] train: loss: 0.1877560
[Epoch 12; Iter   101/  209] train: loss: 0.2210777
[Epoch 12; Iter   131/  209] train: loss: 0.2046369
[Epoch 12; Iter   161/  209] train: loss: 0.2119559
[Epoch 12; Iter   191/  209] train: loss: 0.1691075
[Epoch 12] ogbg-moltox21: 0.723552 val loss: 0.672286
[Epoch 12] ogbg-moltox21: 0.703276 test loss: 0.820421
[Epoch 13; Iter    12/  209] train: loss: 0.2255994
[Epoch 13; Iter    42/  209] train: loss: 0.2120249
[Epoch 13; Iter    72/  209] train: loss: 0.2222133
[Epoch 13; Iter   102/  209] train: loss: 0.1872850
[Epoch 13; Iter   132/  209] train: loss: 0.1481897
[Epoch 13; Iter   162/  209] train: loss: 0.2016615
[Epoch 13; Iter   192/  209] train: loss: 0.1924183
[Epoch 13] ogbg-moltox21: 0.779525 val loss: 0.263819
[Epoch 13] ogbg-moltox21: 0.734782 test loss: 0.495903
[Epoch 14; Iter    13/  209] train: loss: 0.1758162
[Epoch 14; Iter    43/  209] train: loss: 0.1941867
[Epoch 14; Iter    73/  209] train: loss: 0.2141055
[Epoch 14; Iter   103/  209] train: loss: 0.1786963
[Epoch 14; Iter   133/  209] train: loss: 0.1994026
[Epoch 14; Iter   163/  209] train: loss: 0.1483388
[Epoch 14; Iter   193/  209] train: loss: 0.2567888
[Epoch 14] ogbg-moltox21: 0.780680 val loss: 0.259711
[Epoch 14] ogbg-moltox21: 0.752358 test loss: 0.410304
[Epoch 15; Iter    14/  209] train: loss: 0.2126891
[Epoch 15; Iter    44/  209] train: loss: 0.1841534
[Epoch 15; Iter    74/  209] train: loss: 0.1463719
[Epoch 15; Iter   104/  209] train: loss: 0.2359619
[Epoch 15; Iter   134/  209] train: loss: 0.1544974
[Epoch 15; Iter   164/  209] train: loss: 0.1471858
[Epoch 15; Iter   194/  209] train: loss: 0.1480297
[Epoch 15] ogbg-moltox21: 0.787772 val loss: 0.252694
[Epoch 15] ogbg-moltox21: 0.738712 test loss: 0.272107
[Epoch 16; Iter    15/  209] train: loss: 0.1463246
[Epoch 16; Iter    45/  209] train: loss: 0.1953643
[Epoch 16; Iter    75/  209] train: loss: 0.2306918
[Epoch 16; Iter   105/  209] train: loss: 0.2370540
[Epoch 16; Iter   135/  209] train: loss: 0.1809565
[Epoch 16; Iter   165/  209] train: loss: 0.1291882
[Epoch 16; Iter   195/  209] train: loss: 0.1786074
[Epoch 16] ogbg-moltox21: 0.770345 val loss: 0.274890
[Epoch 16] ogbg-moltox21: 0.728765 test loss: 0.411371
[Epoch 17; Iter    16/  209] train: loss: 0.2120712
[Epoch 17; Iter    46/  209] train: loss: 0.2261012
[Epoch 17; Iter    76/  209] train: loss: 0.1678640
[Epoch 17; Iter   106/  209] train: loss: 0.2095908
[Epoch 17; Iter   136/  209] train: loss: 0.0962334
[Epoch 17; Iter   166/  209] train: loss: 0.1721726
[Epoch 17; Iter   196/  209] train: loss: 0.2032274
[Epoch 17] ogbg-moltox21: 0.764966 val loss: 1.173587
[Epoch 17] ogbg-moltox21: 0.712802 test loss: 1.645652
[Epoch 18; Iter    17/  209] train: loss: 0.1771774
[Epoch 18; Iter    47/  209] train: loss: 0.1450436
[Epoch 18; Iter    77/  209] train: loss: 0.2116497
[Epoch 18; Iter   107/  209] train: loss: 0.2424913
[Epoch 18; Iter   137/  209] train: loss: 0.1170860
[Epoch 18; Iter   167/  209] train: loss: 0.1613333
[Epoch 18; Iter   197/  209] train: loss: 0.1470419
[Epoch 18] ogbg-moltox21: 0.797691 val loss: 0.256980
[Epoch 18] ogbg-moltox21: 0.741256 test loss: 0.283123
[Epoch 19; Iter    18/  209] train: loss: 0.1595779
[Epoch 19; Iter    48/  209] train: loss: 0.1346592
[Epoch 19; Iter    78/  209] train: loss: 0.1916974
[Epoch 19; Iter   108/  209] train: loss: 0.1842628
[Epoch 19; Iter   138/  209] train: loss: 0.1897308
[Epoch 19; Iter   168/  209] train: loss: 0.1915686
[Epoch 19; Iter   198/  209] train: loss: 0.1428809
[Epoch 19] ogbg-moltox21: 0.777472 val loss: 0.346886
[Epoch 19] ogbg-moltox21: 0.725857 test loss: 0.277761
[Epoch 20; Iter    19/  209] train: loss: 0.1914831
[Epoch 20; Iter    49/  209] train: loss: 0.1362694
[Epoch 20; Iter    79/  209] train: loss: 0.1406607
[Epoch 20; Iter   109/  209] train: loss: 0.1325174
[Epoch 20; Iter   139/  209] train: loss: 0.1757607
[Epoch 20; Iter   169/  209] train: loss: 0.1887570
[Epoch 20; Iter   199/  209] train: loss: 0.1857486
[Epoch 20] ogbg-moltox21: 0.785097 val loss: 0.468515
[Epoch 20] ogbg-moltox21: 0.730892 test loss: 1.384473
[Epoch 21; Iter    20/  209] train: loss: 0.1845974
[Epoch 21; Iter    50/  209] train: loss: 0.2057921
[Epoch 21; Iter    80/  209] train: loss: 0.1524834
[Epoch 21; Iter   110/  209] train: loss: 0.3324085
[Epoch 21; Iter   140/  209] train: loss: 0.2039928
[Epoch 21; Iter   170/  209] train: loss: 0.2049460
[Epoch 21; Iter   200/  209] train: loss: 0.1565827
[Epoch 21] ogbg-moltox21: 0.796990 val loss: 0.247380
[Epoch 21] ogbg-moltox21: 0.735116 test loss: 0.466500
[Epoch 22; Iter    21/  209] train: loss: 0.1005928
[Epoch 22; Iter    51/  209] train: loss: 0.2093240
[Epoch 22; Iter    81/  209] train: loss: 0.1504360
[Epoch 22; Iter   111/  209] train: loss: 0.2300916
[Epoch 22; Iter   141/  209] train: loss: 0.1470104
[Epoch 22; Iter   171/  209] train: loss: 0.1803444
[Epoch 22; Iter   201/  209] train: loss: 0.1737372
[Epoch 22] ogbg-moltox21: 0.782032 val loss: 0.265756
[Epoch 22] ogbg-moltox21: 0.739343 test loss: 0.307608
[Epoch 23; Iter    22/  209] train: loss: 0.1358641
[Epoch 23; Iter    52/  209] train: loss: 0.1154299
[Epoch 23; Iter    82/  209] train: loss: 0.1617543
[Epoch 23; Iter   112/  209] train: loss: 0.1661066
[Epoch 23; Iter   142/  209] train: loss: 0.1527446
[Epoch 23; Iter   172/  209] train: loss: 0.1791525
[Epoch 23; Iter   202/  209] train: loss: 0.1334992
[Epoch 23] ogbg-moltox21: 0.808577 val loss: 0.308135
[Epoch 23] ogbg-moltox21: 0.734924 test loss: 0.554163
[Epoch 24; Iter    23/  209] train: loss: 0.1400049
[Epoch 24; Iter    53/  209] train: loss: 0.1773447
[Epoch 24; Iter    83/  209] train: loss: 0.1562148
[Epoch 24; Iter   113/  209] train: loss: 0.1281448
[Epoch 24; Iter   143/  209] train: loss: 0.1428542
[Epoch 24; Iter   173/  209] train: loss: 0.1544920
[Epoch 24; Iter   203/  209] train: loss: 0.1862940
[Epoch 24] ogbg-moltox21: 0.785795 val loss: 0.367588
[Epoch 24] ogbg-moltox21: 0.731750 test loss: 0.588449
[Epoch 25; Iter    24/  209] train: loss: 0.1452897
[Epoch 25; Iter    54/  209] train: loss: 0.0942199
[Epoch 25; Iter    84/  209] train: loss: 0.1066915
[Epoch 25; Iter   114/  209] train: loss: 0.1517672
[Epoch 25; Iter   144/  209] train: loss: 0.2199185
[Epoch 25; Iter   174/  209] train: loss: 0.1224898
[Epoch 25; Iter   204/  209] train: loss: 0.1301609
[Epoch 25] ogbg-moltox21: 0.794022 val loss: 0.364702
[Epoch 25] ogbg-moltox21: 0.726383 test loss: 0.667599
[Epoch 26; Iter    25/  209] train: loss: 0.1034119
[Epoch 26; Iter    55/  209] train: loss: 0.1978133
[Epoch 26; Iter    85/  209] train: loss: 0.2253529
[Epoch 26; Iter   115/  209] train: loss: 0.1457122
[Epoch 26; Iter   145/  209] train: loss: 0.1288922
[Epoch 26; Iter   175/  209] train: loss: 0.1351636
[Epoch 26; Iter   205/  209] train: loss: 0.1320199
[Epoch 26] ogbg-moltox21: 0.800207 val loss: 0.288901
[Epoch 26] ogbg-moltox21: 0.734202 test loss: 0.491840
[Epoch 27; Iter    26/  209] train: loss: 0.1658419
[Epoch 27; Iter    56/  209] train: loss: 0.1001094
[Epoch 27; Iter    86/  209] train: loss: 0.1679501
[Epoch 27; Iter   116/  209] train: loss: 0.1229696
[Epoch 27; Iter   146/  209] train: loss: 0.1589929
[Epoch 27; Iter   176/  209] train: loss: 0.1957933
[Epoch 27; Iter   206/  209] train: loss: 0.1241201
[Epoch 27] ogbg-moltox21: 0.790990 val loss: 0.294676
[Epoch 27] ogbg-moltox21: 0.734994 test loss: 0.310015
[Epoch 28; Iter    27/  209] train: loss: 0.1031280
[Epoch 28; Iter    57/  209] train: loss: 0.2263548
[Epoch 28; Iter    87/  209] train: loss: 0.1688246
[Epoch 28; Iter   117/  209] train: loss: 0.1254783
[Epoch 28; Iter   147/  209] train: loss: 0.1576839
[Epoch 28; Iter   177/  209] train: loss: 0.1740753
[Epoch 28; Iter   207/  209] train: loss: 0.1094956
[Epoch 28] ogbg-moltox21: 0.799438 val loss: 0.285909
[Epoch 28] ogbg-moltox21: 0.726906 test loss: 0.878120
[Epoch 29; Iter    28/  209] train: loss: 0.1068615
[Epoch 29; Iter    58/  209] train: loss: 0.1101687
[Epoch 29; Iter    88/  209] train: loss: 0.1417830
[Epoch 29; Iter   118/  209] train: loss: 0.1871271
[Epoch 29; Iter   148/  209] train: loss: 0.1232996
[Epoch 29; Iter   178/  209] train: loss: 0.0792197
[Epoch 29; Iter   208/  209] train: loss: 0.1332878
[Epoch 29] ogbg-moltox21: 0.797384 val loss: 0.301551
[Epoch 29] ogbg-moltox21: 0.745911 test loss: 0.376290
[Epoch 30; Iter    29/  209] train: loss: 0.1422225
[Epoch 30; Iter    59/  209] train: loss: 0.1187611
[Epoch 13; Iter    12/  209] train: loss: 0.1654293
[Epoch 13; Iter    42/  209] train: loss: 0.1768184
[Epoch 13; Iter    72/  209] train: loss: 0.1689885
[Epoch 13; Iter   102/  209] train: loss: 0.2151336
[Epoch 13; Iter   132/  209] train: loss: 0.1820691
[Epoch 13; Iter   162/  209] train: loss: 0.2837394
[Epoch 13; Iter   192/  209] train: loss: 0.2254037
[Epoch 13] ogbg-moltox21: 0.767584 val loss: 0.269753
[Epoch 13] ogbg-moltox21: 0.735838 test loss: 0.282780
[Epoch 14; Iter    13/  209] train: loss: 0.1221611
[Epoch 14; Iter    43/  209] train: loss: 0.1824358
[Epoch 14; Iter    73/  209] train: loss: 0.1580031
[Epoch 14; Iter   103/  209] train: loss: 0.3014829
[Epoch 14; Iter   133/  209] train: loss: 0.1909029
[Epoch 14; Iter   163/  209] train: loss: 0.2217761
[Epoch 14; Iter   193/  209] train: loss: 0.2464039
[Epoch 14] ogbg-moltox21: 0.768984 val loss: 0.269100
[Epoch 14] ogbg-moltox21: 0.732009 test loss: 0.288722
[Epoch 15; Iter    14/  209] train: loss: 0.1229199
[Epoch 15; Iter    44/  209] train: loss: 0.1584297
[Epoch 15; Iter    74/  209] train: loss: 0.2289694
[Epoch 15; Iter   104/  209] train: loss: 0.1606205
[Epoch 15; Iter   134/  209] train: loss: 0.1312108
[Epoch 15; Iter   164/  209] train: loss: 0.1540343
[Epoch 15; Iter   194/  209] train: loss: 0.1728936
[Epoch 15] ogbg-moltox21: 0.772064 val loss: 0.273697
[Epoch 15] ogbg-moltox21: 0.740498 test loss: 0.284964
[Epoch 16; Iter    15/  209] train: loss: 0.1346011
[Epoch 16; Iter    45/  209] train: loss: 0.2019494
[Epoch 16; Iter    75/  209] train: loss: 0.2656645
[Epoch 16; Iter   105/  209] train: loss: 0.2899455
[Epoch 16; Iter   135/  209] train: loss: 0.2683984
[Epoch 16; Iter   165/  209] train: loss: 0.3089050
[Epoch 16; Iter   195/  209] train: loss: 0.2143732
[Epoch 16] ogbg-moltox21: 0.766942 val loss: 0.263768
[Epoch 16] ogbg-moltox21: 0.727388 test loss: 0.281432
[Epoch 17; Iter    16/  209] train: loss: 0.1918159
[Epoch 17; Iter    46/  209] train: loss: 0.2666166
[Epoch 17; Iter    76/  209] train: loss: 0.2758909
[Epoch 17; Iter   106/  209] train: loss: 0.2717084
[Epoch 17; Iter   136/  209] train: loss: 0.3220959
[Epoch 17; Iter   166/  209] train: loss: 0.2525144
[Epoch 17; Iter   196/  209] train: loss: 0.1862575
[Epoch 17] ogbg-moltox21: 0.745314 val loss: 0.389773
[Epoch 17] ogbg-moltox21: 0.722111 test loss: 0.276552
[Epoch 18; Iter    17/  209] train: loss: 0.1636734
[Epoch 18; Iter    47/  209] train: loss: 0.1520789
[Epoch 18; Iter    77/  209] train: loss: 0.2551896
[Epoch 18; Iter   107/  209] train: loss: 0.1775235
[Epoch 18; Iter   137/  209] train: loss: 0.1360842
[Epoch 18; Iter   167/  209] train: loss: 0.1820238
[Epoch 18; Iter   197/  209] train: loss: 0.2072132
[Epoch 18] ogbg-moltox21: 0.767991 val loss: 0.268688
[Epoch 18] ogbg-moltox21: 0.741066 test loss: 0.277675
[Epoch 19; Iter    18/  209] train: loss: 0.1790939
[Epoch 19; Iter    48/  209] train: loss: 0.1159259
[Epoch 19; Iter    78/  209] train: loss: 0.2705480
[Epoch 19; Iter   108/  209] train: loss: 0.1618447
[Epoch 19; Iter   138/  209] train: loss: 0.2031409
[Epoch 19; Iter   168/  209] train: loss: 0.2148624
[Epoch 19; Iter   198/  209] train: loss: 0.2667121
[Epoch 19] ogbg-moltox21: 0.761495 val loss: 0.345558
[Epoch 19] ogbg-moltox21: 0.734422 test loss: 0.309581
[Epoch 20; Iter    19/  209] train: loss: 0.2086228
[Epoch 20; Iter    49/  209] train: loss: 0.1342374
[Epoch 20; Iter    79/  209] train: loss: 0.1788324
[Epoch 20; Iter   109/  209] train: loss: 0.2204517
[Epoch 20; Iter   139/  209] train: loss: 0.1495240
[Epoch 20; Iter   169/  209] train: loss: 0.1956667
[Epoch 20; Iter   199/  209] train: loss: 0.2469185
[Epoch 20] ogbg-moltox21: 0.776360 val loss: 0.349471
[Epoch 20] ogbg-moltox21: 0.745960 test loss: 0.297515
[Epoch 21; Iter    20/  209] train: loss: 0.1935149
[Epoch 21; Iter    50/  209] train: loss: 0.2317697
[Epoch 21; Iter    80/  209] train: loss: 0.1544820
[Epoch 21; Iter   110/  209] train: loss: 0.1897447
[Epoch 21; Iter   140/  209] train: loss: 0.1008142
[Epoch 21; Iter   170/  209] train: loss: 0.1671314
[Epoch 21; Iter   200/  209] train: loss: 0.1367747
[Epoch 21] ogbg-moltox21: 0.779681 val loss: 0.332279
[Epoch 21] ogbg-moltox21: 0.738379 test loss: 0.272600
[Epoch 22; Iter    21/  209] train: loss: 0.2145875
[Epoch 22; Iter    51/  209] train: loss: 0.1996702
[Epoch 22; Iter    81/  209] train: loss: 0.1062789
[Epoch 22; Iter   111/  209] train: loss: 0.1554156
[Epoch 22; Iter   141/  209] train: loss: 0.1981884
[Epoch 22; Iter   171/  209] train: loss: 0.2301791
[Epoch 22; Iter   201/  209] train: loss: 0.2406629
[Epoch 22] ogbg-moltox21: 0.781086 val loss: 0.274352
[Epoch 22] ogbg-moltox21: 0.721033 test loss: 0.303998
[Epoch 23; Iter    22/  209] train: loss: 0.1811789
[Epoch 23; Iter    52/  209] train: loss: 0.2101647
[Epoch 23; Iter    82/  209] train: loss: 0.1875431
[Epoch 23; Iter   112/  209] train: loss: 0.1564731
[Epoch 23; Iter   142/  209] train: loss: 0.1783767
[Epoch 23; Iter   172/  209] train: loss: 0.1851938
[Epoch 23; Iter   202/  209] train: loss: 0.1937302
[Epoch 23] ogbg-moltox21: 0.769340 val loss: 0.266024
[Epoch 23] ogbg-moltox21: 0.732228 test loss: 0.305997
[Epoch 24; Iter    23/  209] train: loss: 0.2045697
[Epoch 24; Iter    53/  209] train: loss: 0.2286540
[Epoch 24; Iter    83/  209] train: loss: 0.2440167
[Epoch 24; Iter   113/  209] train: loss: 0.1588050
[Epoch 24; Iter   143/  209] train: loss: 0.1909742
[Epoch 24; Iter   173/  209] train: loss: 0.1525388
[Epoch 24; Iter   203/  209] train: loss: 0.2089865
[Epoch 24] ogbg-moltox21: 0.746374 val loss: 0.357972
[Epoch 24] ogbg-moltox21: 0.718056 test loss: 0.345453
[Epoch 25; Iter    24/  209] train: loss: 0.2350759
[Epoch 25; Iter    54/  209] train: loss: 0.2526346
[Epoch 25; Iter    84/  209] train: loss: 0.1261497
[Epoch 25; Iter   114/  209] train: loss: 0.2287705
[Epoch 25; Iter   144/  209] train: loss: 0.1133815
[Epoch 25; Iter   174/  209] train: loss: 0.2771137
[Epoch 25; Iter   204/  209] train: loss: 0.1563676
[Epoch 25] ogbg-moltox21: 0.759366 val loss: 0.314147
[Epoch 25] ogbg-moltox21: 0.722845 test loss: 0.354888
[Epoch 26; Iter    25/  209] train: loss: 0.1393968
[Epoch 26; Iter    55/  209] train: loss: 0.1427989
[Epoch 26; Iter    85/  209] train: loss: 0.2144863
[Epoch 26; Iter   115/  209] train: loss: 0.1309565
[Epoch 26; Iter   145/  209] train: loss: 0.1718763
[Epoch 26; Iter   175/  209] train: loss: 0.1902148
[Epoch 26; Iter   205/  209] train: loss: 0.3090470
[Epoch 26] ogbg-moltox21: 0.776661 val loss: 0.322186
[Epoch 26] ogbg-moltox21: 0.728846 test loss: 0.514832
[Epoch 27; Iter    26/  209] train: loss: 0.1349224
[Epoch 27; Iter    56/  209] train: loss: 0.1023029
[Epoch 27; Iter    86/  209] train: loss: 0.1847219
[Epoch 27; Iter   116/  209] train: loss: 0.2210133
[Epoch 27; Iter   146/  209] train: loss: 0.1353467
[Epoch 27; Iter   176/  209] train: loss: 0.2207052
[Epoch 27; Iter   206/  209] train: loss: 0.2409417
[Epoch 27] ogbg-moltox21: 0.774336 val loss: 0.534468
[Epoch 27] ogbg-moltox21: 0.737645 test loss: 0.438196
[Epoch 28; Iter    27/  209] train: loss: 0.2374656
[Epoch 28; Iter    57/  209] train: loss: 0.1334266
[Epoch 28; Iter    87/  209] train: loss: 0.2052546
[Epoch 28; Iter   117/  209] train: loss: 0.2102075
[Epoch 28; Iter   147/  209] train: loss: 0.2573685
[Epoch 28; Iter   177/  209] train: loss: 0.2117529
[Epoch 28; Iter   207/  209] train: loss: 0.1129408
[Epoch 28] ogbg-moltox21: 0.790499 val loss: 0.279397
[Epoch 28] ogbg-moltox21: 0.741456 test loss: 0.281324
[Epoch 29; Iter    28/  209] train: loss: 0.1703946
[Epoch 29; Iter    58/  209] train: loss: 0.1856394
[Epoch 29; Iter    88/  209] train: loss: 0.1886608
[Epoch 29; Iter   118/  209] train: loss: 0.1305121
[Epoch 29; Iter   148/  209] train: loss: 0.2493687
[Epoch 29; Iter   178/  209] train: loss: 0.1763835
[Epoch 29; Iter   208/  209] train: loss: 0.2283957
[Epoch 29] ogbg-moltox21: 0.793684 val loss: 0.306217
[Epoch 29] ogbg-moltox21: 0.743784 test loss: 0.286958
[Epoch 30; Iter    29/  209] train: loss: 0.1635242
[Epoch 30; Iter    59/  209] train: loss: 0.2211698
[Epoch 13; Iter    12/  209] train: loss: 0.1940990
[Epoch 13; Iter    42/  209] train: loss: 0.1582597
[Epoch 13; Iter    72/  209] train: loss: 0.2889813
[Epoch 13; Iter   102/  209] train: loss: 0.1598581
[Epoch 13; Iter   132/  209] train: loss: 0.2815126
[Epoch 13; Iter   162/  209] train: loss: 0.2468895
[Epoch 13; Iter   192/  209] train: loss: 0.1913188
[Epoch 13] ogbg-moltox21: 0.780343 val loss: 0.466808
[Epoch 13] ogbg-moltox21: 0.734447 test loss: 0.765871
[Epoch 14; Iter    13/  209] train: loss: 0.2093271
[Epoch 14; Iter    43/  209] train: loss: 0.1635968
[Epoch 14; Iter    73/  209] train: loss: 0.1792038
[Epoch 14; Iter   103/  209] train: loss: 0.1923605
[Epoch 14; Iter   133/  209] train: loss: 0.2563880
[Epoch 14; Iter   163/  209] train: loss: 0.1968345
[Epoch 14; Iter   193/  209] train: loss: 0.1943579
[Epoch 14] ogbg-moltox21: 0.776893 val loss: 0.314934
[Epoch 14] ogbg-moltox21: 0.698782 test loss: 0.473362
[Epoch 15; Iter    14/  209] train: loss: 0.1598611
[Epoch 15; Iter    44/  209] train: loss: 0.2411372
[Epoch 15; Iter    74/  209] train: loss: 0.1589304
[Epoch 15; Iter   104/  209] train: loss: 0.2288237
[Epoch 15; Iter   134/  209] train: loss: 0.1668887
[Epoch 15; Iter   164/  209] train: loss: 0.1640109
[Epoch 15; Iter   194/  209] train: loss: 0.2152044
[Epoch 15] ogbg-moltox21: 0.779817 val loss: 0.286602
[Epoch 15] ogbg-moltox21: 0.716387 test loss: 0.341322
[Epoch 16; Iter    15/  209] train: loss: 0.1896213
[Epoch 16; Iter    45/  209] train: loss: 0.1656665
[Epoch 16; Iter    75/  209] train: loss: 0.2245391
[Epoch 16; Iter   105/  209] train: loss: 0.1774243
[Epoch 16; Iter   135/  209] train: loss: 0.2015320
[Epoch 16; Iter   165/  209] train: loss: 0.1843645
[Epoch 16; Iter   195/  209] train: loss: 0.1718081
[Epoch 16] ogbg-moltox21: 0.775679 val loss: 0.596901
[Epoch 16] ogbg-moltox21: 0.733626 test loss: 1.050477
[Epoch 17; Iter    16/  209] train: loss: 0.1511797
[Epoch 17; Iter    46/  209] train: loss: 0.1331424
[Epoch 17; Iter    76/  209] train: loss: 0.1330825
[Epoch 17; Iter   106/  209] train: loss: 0.1976363
[Epoch 17; Iter   136/  209] train: loss: 0.1501594
[Epoch 17; Iter   166/  209] train: loss: 0.1673492
[Epoch 17; Iter   196/  209] train: loss: 0.1420806
[Epoch 17] ogbg-moltox21: 0.790272 val loss: 0.462216
[Epoch 17] ogbg-moltox21: 0.732747 test loss: 0.704342
[Epoch 18; Iter    17/  209] train: loss: 0.1160001
[Epoch 18; Iter    47/  209] train: loss: 0.1840391
[Epoch 18; Iter    77/  209] train: loss: 0.2231050
[Epoch 18; Iter   107/  209] train: loss: 0.2141812
[Epoch 18; Iter   137/  209] train: loss: 0.1543934
[Epoch 18; Iter   167/  209] train: loss: 0.1557387
[Epoch 18; Iter   197/  209] train: loss: 0.1187295
[Epoch 18] ogbg-moltox21: 0.787438 val loss: 0.259747
[Epoch 18] ogbg-moltox21: 0.735157 test loss: 0.282555
[Epoch 19; Iter    18/  209] train: loss: 0.2547632
[Epoch 19; Iter    48/  209] train: loss: 0.1616354
[Epoch 19; Iter    78/  209] train: loss: 0.1320966
[Epoch 19; Iter   108/  209] train: loss: 0.1615793
[Epoch 19; Iter   138/  209] train: loss: 0.1459410
[Epoch 19; Iter   168/  209] train: loss: 0.1883271
[Epoch 19; Iter   198/  209] train: loss: 0.2735001
[Epoch 19] ogbg-moltox21: 0.783672 val loss: 0.272310
[Epoch 19] ogbg-moltox21: 0.725870 test loss: 0.302965
[Epoch 20; Iter    19/  209] train: loss: 0.1866249
[Epoch 20; Iter    49/  209] train: loss: 0.2055053
[Epoch 20; Iter    79/  209] train: loss: 0.0982957
[Epoch 20; Iter   109/  209] train: loss: 0.1441559
[Epoch 20; Iter   139/  209] train: loss: 0.1705238
[Epoch 20; Iter   169/  209] train: loss: 0.1824676
[Epoch 20; Iter   199/  209] train: loss: 0.1122259
[Epoch 20] ogbg-moltox21: 0.805444 val loss: 0.264655
[Epoch 20] ogbg-moltox21: 0.734658 test loss: 0.294464
[Epoch 21; Iter    20/  209] train: loss: 0.1125911
[Epoch 21; Iter    50/  209] train: loss: 0.2035204
[Epoch 21; Iter    80/  209] train: loss: 0.1654105
[Epoch 21; Iter   110/  209] train: loss: 0.1072381
[Epoch 21; Iter   140/  209] train: loss: 0.1695677
[Epoch 21; Iter   170/  209] train: loss: 0.3218246
[Epoch 21; Iter   200/  209] train: loss: 0.1631001
[Epoch 21] ogbg-moltox21: 0.785482 val loss: 0.324313
[Epoch 21] ogbg-moltox21: 0.732774 test loss: 0.344328
[Epoch 22; Iter    21/  209] train: loss: 0.1279695
[Epoch 22; Iter    51/  209] train: loss: 0.0809127
[Epoch 22; Iter    81/  209] train: loss: 0.1217141
[Epoch 22; Iter   111/  209] train: loss: 0.1123579
[Epoch 22; Iter   141/  209] train: loss: 0.1452479
[Epoch 22; Iter   171/  209] train: loss: 0.1064556
[Epoch 22; Iter   201/  209] train: loss: 0.0976983
[Epoch 22] ogbg-moltox21: 0.785045 val loss: 0.323050
[Epoch 22] ogbg-moltox21: 0.732319 test loss: 0.458831
[Epoch 23; Iter    22/  209] train: loss: 0.1746298
[Epoch 23; Iter    52/  209] train: loss: 0.1878509
[Epoch 23; Iter    82/  209] train: loss: 0.1385632
[Epoch 23; Iter   112/  209] train: loss: 0.1408475
[Epoch 23; Iter   142/  209] train: loss: 0.1504539
[Epoch 23; Iter   172/  209] train: loss: 0.1418554
[Epoch 23; Iter   202/  209] train: loss: 0.1096342
[Epoch 23] ogbg-moltox21: 0.782114 val loss: 0.343611
[Epoch 23] ogbg-moltox21: 0.732221 test loss: 0.428159
[Epoch 24; Iter    23/  209] train: loss: 0.1758064
[Epoch 24; Iter    53/  209] train: loss: 0.0889867
[Epoch 24; Iter    83/  209] train: loss: 0.1739126
[Epoch 24; Iter   113/  209] train: loss: 0.1253683
[Epoch 24; Iter   143/  209] train: loss: 0.0990727
[Epoch 24; Iter   173/  209] train: loss: 0.0986130
[Epoch 24; Iter   203/  209] train: loss: 0.1820582
[Epoch 24] ogbg-moltox21: 0.783819 val loss: 0.708347
[Epoch 24] ogbg-moltox21: 0.733403 test loss: 0.937020
[Epoch 25; Iter    24/  209] train: loss: 0.0929943
[Epoch 25; Iter    54/  209] train: loss: 0.1919986
[Epoch 25; Iter    84/  209] train: loss: 0.0852806
[Epoch 25; Iter   114/  209] train: loss: 0.1460810
[Epoch 25; Iter   144/  209] train: loss: 0.0983772
[Epoch 25; Iter   174/  209] train: loss: 0.1406022
[Epoch 25; Iter   204/  209] train: loss: 0.2026691
[Epoch 25] ogbg-moltox21: 0.789240 val loss: 0.291991
[Epoch 25] ogbg-moltox21: 0.726870 test loss: 0.303419
[Epoch 26; Iter    25/  209] train: loss: 0.1450097
[Epoch 26; Iter    55/  209] train: loss: 0.2193863
[Epoch 26; Iter    85/  209] train: loss: 0.1641857
[Epoch 26; Iter   115/  209] train: loss: 0.0758592
[Epoch 26; Iter   145/  209] train: loss: 0.1124019
[Epoch 26; Iter   175/  209] train: loss: 0.1033571
[Epoch 26; Iter   205/  209] train: loss: 0.1561298
[Epoch 26] ogbg-moltox21: 0.775582 val loss: 0.756310
[Epoch 26] ogbg-moltox21: 0.731366 test loss: 1.241578
[Epoch 27; Iter    26/  209] train: loss: 0.1117946
[Epoch 27; Iter    56/  209] train: loss: 0.1994274
[Epoch 27; Iter    86/  209] train: loss: 0.1590393
[Epoch 27; Iter   116/  209] train: loss: 0.1332049
[Epoch 27; Iter   146/  209] train: loss: 0.1071346
[Epoch 27; Iter   176/  209] train: loss: 0.0930305
[Epoch 27; Iter   206/  209] train: loss: 0.1271250
[Epoch 27] ogbg-moltox21: 0.778070 val loss: 0.320559
[Epoch 27] ogbg-moltox21: 0.731408 test loss: 0.379511
[Epoch 28; Iter    27/  209] train: loss: 0.1068655
[Epoch 28; Iter    57/  209] train: loss: 0.0885822
[Epoch 28; Iter    87/  209] train: loss: 0.1259139
[Epoch 28; Iter   117/  209] train: loss: 0.1403357
[Epoch 28; Iter   147/  209] train: loss: 0.1325913
[Epoch 28; Iter   177/  209] train: loss: 0.1047692
[Epoch 28; Iter   207/  209] train: loss: 0.1189777
[Epoch 28] ogbg-moltox21: 0.779712 val loss: 0.314115
[Epoch 28] ogbg-moltox21: 0.719175 test loss: 0.364033
[Epoch 29; Iter    28/  209] train: loss: 0.1072356
[Epoch 29; Iter    58/  209] train: loss: 0.1183152
[Epoch 29; Iter    88/  209] train: loss: 0.1303599
[Epoch 29; Iter   118/  209] train: loss: 0.1880414
[Epoch 29; Iter   148/  209] train: loss: 0.1135877
[Epoch 29; Iter   178/  209] train: loss: 0.0687861
[Epoch 29; Iter   208/  209] train: loss: 0.0841753
[Epoch 29] ogbg-moltox21: 0.759712 val loss: 0.314637
[Epoch 29] ogbg-moltox21: 0.708691 test loss: 0.344294
[Epoch 30; Iter    29/  209] train: loss: 0.1170581
[Epoch 30; Iter    59/  209] train: loss: 0.0958178
[Epoch 13; Iter    12/  209] train: loss: 0.1945636
[Epoch 13; Iter    42/  209] train: loss: 0.1390011
[Epoch 13; Iter    72/  209] train: loss: 0.2620456
[Epoch 13; Iter   102/  209] train: loss: 0.1517274
[Epoch 13; Iter   132/  209] train: loss: 0.2822686
[Epoch 13; Iter   162/  209] train: loss: 0.2417287
[Epoch 13; Iter   192/  209] train: loss: 0.1762576
[Epoch 13] ogbg-moltox21: 0.776739 val loss: 0.464426
[Epoch 13] ogbg-moltox21: 0.750428 test loss: 0.625283
[Epoch 14; Iter    13/  209] train: loss: 0.2211283
[Epoch 14; Iter    43/  209] train: loss: 0.1886469
[Epoch 14; Iter    73/  209] train: loss: 0.1873876
[Epoch 14; Iter   103/  209] train: loss: 0.1884454
[Epoch 14; Iter   133/  209] train: loss: 0.2317614
[Epoch 14; Iter   163/  209] train: loss: 0.1980186
[Epoch 14; Iter   193/  209] train: loss: 0.1853006
[Epoch 14] ogbg-moltox21: 0.773145 val loss: 0.248924
[Epoch 14] ogbg-moltox21: 0.715711 test loss: 0.266068
[Epoch 15; Iter    14/  209] train: loss: 0.1529455
[Epoch 15; Iter    44/  209] train: loss: 0.2290891
[Epoch 15; Iter    74/  209] train: loss: 0.1685638
[Epoch 15; Iter   104/  209] train: loss: 0.2364613
[Epoch 15; Iter   134/  209] train: loss: 0.1662775
[Epoch 15; Iter   164/  209] train: loss: 0.1700656
[Epoch 15; Iter   194/  209] train: loss: 0.2066005
[Epoch 15] ogbg-moltox21: 0.779262 val loss: 0.249743
[Epoch 15] ogbg-moltox21: 0.739924 test loss: 0.265741
[Epoch 16; Iter    15/  209] train: loss: 0.2156957
[Epoch 16; Iter    45/  209] train: loss: 0.1599882
[Epoch 16; Iter    75/  209] train: loss: 0.2025392
[Epoch 16; Iter   105/  209] train: loss: 0.1775092
[Epoch 16; Iter   135/  209] train: loss: 0.2120397
[Epoch 16; Iter   165/  209] train: loss: 0.1921916
[Epoch 16; Iter   195/  209] train: loss: 0.1935418
[Epoch 16] ogbg-moltox21: 0.788058 val loss: 0.246979
[Epoch 16] ogbg-moltox21: 0.756835 test loss: 0.261977
[Epoch 17; Iter    16/  209] train: loss: 0.1665805
[Epoch 17; Iter    46/  209] train: loss: 0.1277248
[Epoch 17; Iter    76/  209] train: loss: 0.1129895
[Epoch 17; Iter   106/  209] train: loss: 0.1926541
[Epoch 17; Iter   136/  209] train: loss: 0.1427979
[Epoch 17; Iter   166/  209] train: loss: 0.1506336
[Epoch 17; Iter   196/  209] train: loss: 0.1215935
[Epoch 17] ogbg-moltox21: 0.795642 val loss: 0.240126
[Epoch 17] ogbg-moltox21: 0.738231 test loss: 0.264513
[Epoch 18; Iter    17/  209] train: loss: 0.1143092
[Epoch 18; Iter    47/  209] train: loss: 0.1847877
[Epoch 18; Iter    77/  209] train: loss: 0.2448302
[Epoch 18; Iter   107/  209] train: loss: 0.2515151
[Epoch 18; Iter   137/  209] train: loss: 0.1709330
[Epoch 18; Iter   167/  209] train: loss: 0.1435685
[Epoch 18; Iter   197/  209] train: loss: 0.1186582
[Epoch 18] ogbg-moltox21: 0.797510 val loss: 0.241221
[Epoch 18] ogbg-moltox21: 0.747094 test loss: 0.259793
[Epoch 19; Iter    18/  209] train: loss: 0.2557922
[Epoch 19; Iter    48/  209] train: loss: 0.1473669
[Epoch 19; Iter    78/  209] train: loss: 0.1228523
[Epoch 19; Iter   108/  209] train: loss: 0.1418867
[Epoch 19; Iter   138/  209] train: loss: 0.1224552
[Epoch 19; Iter   168/  209] train: loss: 0.1587584
[Epoch 19; Iter   198/  209] train: loss: 0.2730575
[Epoch 19] ogbg-moltox21: 0.791857 val loss: 0.248560
[Epoch 19] ogbg-moltox21: 0.745414 test loss: 0.312053
[Epoch 20; Iter    19/  209] train: loss: 0.1918563
[Epoch 20; Iter    49/  209] train: loss: 0.2132220
[Epoch 20; Iter    79/  209] train: loss: 0.0992279
[Epoch 20; Iter   109/  209] train: loss: 0.1200703
[Epoch 20; Iter   139/  209] train: loss: 0.2174592
[Epoch 20; Iter   169/  209] train: loss: 0.2312510
[Epoch 20; Iter   199/  209] train: loss: 0.1079385
[Epoch 20] ogbg-moltox21: 0.784133 val loss: 0.248912
[Epoch 20] ogbg-moltox21: 0.746339 test loss: 0.271647
[Epoch 21; Iter    20/  209] train: loss: 0.1224873
[Epoch 21; Iter    50/  209] train: loss: 0.1946177
[Epoch 21; Iter    80/  209] train: loss: 0.1632669
[Epoch 21; Iter   110/  209] train: loss: 0.0879199
[Epoch 21; Iter   140/  209] train: loss: 0.2132493
[Epoch 21; Iter   170/  209] train: loss: 0.3298547
[Epoch 21; Iter   200/  209] train: loss: 0.1482161
[Epoch 21] ogbg-moltox21: 0.786262 val loss: 0.252183
[Epoch 21] ogbg-moltox21: 0.740541 test loss: 0.269850
[Epoch 22; Iter    21/  209] train: loss: 0.1512159
[Epoch 22; Iter    51/  209] train: loss: 0.0716300
[Epoch 22; Iter    81/  209] train: loss: 0.1179835
[Epoch 22; Iter   111/  209] train: loss: 0.1260425
[Epoch 22; Iter   141/  209] train: loss: 0.1559003
[Epoch 22; Iter   171/  209] train: loss: 0.1057313
[Epoch 22; Iter   201/  209] train: loss: 0.1211074
[Epoch 22] ogbg-moltox21: 0.790295 val loss: 0.256257
[Epoch 22] ogbg-moltox21: 0.743421 test loss: 0.277178
[Epoch 23; Iter    22/  209] train: loss: 0.1693948
[Epoch 23; Iter    52/  209] train: loss: 0.1632385
[Epoch 23; Iter    82/  209] train: loss: 0.1325283
[Epoch 23; Iter   112/  209] train: loss: 0.1384344
[Epoch 23; Iter   142/  209] train: loss: 0.1292124
[Epoch 23; Iter   172/  209] train: loss: 0.1301232
[Epoch 23; Iter   202/  209] train: loss: 0.1382165
[Epoch 23] ogbg-moltox21: 0.791879 val loss: 0.258335
[Epoch 23] ogbg-moltox21: 0.743320 test loss: 0.279469
[Epoch 24; Iter    23/  209] train: loss: 0.2001153
[Epoch 24; Iter    53/  209] train: loss: 0.0844752
[Epoch 24; Iter    83/  209] train: loss: 0.1997306
[Epoch 24; Iter   113/  209] train: loss: 0.1253678
[Epoch 24; Iter   143/  209] train: loss: 0.0871671
[Epoch 24; Iter   173/  209] train: loss: 0.1214840
[Epoch 24; Iter   203/  209] train: loss: 0.1733608
[Epoch 24] ogbg-moltox21: 0.772363 val loss: 0.275394
[Epoch 24] ogbg-moltox21: 0.742824 test loss: 0.267720
[Epoch 25; Iter    24/  209] train: loss: 0.0960667
[Epoch 25; Iter    54/  209] train: loss: 0.2077035
[Epoch 25; Iter    84/  209] train: loss: 0.1069530
[Epoch 25; Iter   114/  209] train: loss: 0.1510543
[Epoch 25; Iter   144/  209] train: loss: 0.1217138
[Epoch 25; Iter   174/  209] train: loss: 0.1601767
[Epoch 25; Iter   204/  209] train: loss: 0.2084139
[Epoch 25] ogbg-moltox21: 0.779022 val loss: 0.259573
[Epoch 25] ogbg-moltox21: 0.745937 test loss: 0.270709
[Epoch 26; Iter    25/  209] train: loss: 0.1644181
[Epoch 26; Iter    55/  209] train: loss: 0.2100679
[Epoch 26; Iter    85/  209] train: loss: 0.1730782
[Epoch 26; Iter   115/  209] train: loss: 0.0904741
[Epoch 26; Iter   145/  209] train: loss: 0.1315582
[Epoch 26; Iter   175/  209] train: loss: 0.0988476
[Epoch 26; Iter   205/  209] train: loss: 0.1649657
[Epoch 26] ogbg-moltox21: 0.775648 val loss: 0.265014
[Epoch 26] ogbg-moltox21: 0.733001 test loss: 0.280811
[Epoch 27; Iter    26/  209] train: loss: 0.1256461
[Epoch 27; Iter    56/  209] train: loss: 0.2313457
[Epoch 27; Iter    86/  209] train: loss: 0.1308729
[Epoch 27; Iter   116/  209] train: loss: 0.1347114
[Epoch 27; Iter   146/  209] train: loss: 0.1160013
[Epoch 27; Iter   176/  209] train: loss: 0.1101631
[Epoch 27; Iter   206/  209] train: loss: 0.1547236
[Epoch 27] ogbg-moltox21: 0.778000 val loss: 0.258373
[Epoch 27] ogbg-moltox21: 0.733610 test loss: 0.278387
[Epoch 28; Iter    27/  209] train: loss: 0.1222684
[Epoch 28; Iter    57/  209] train: loss: 0.1248370
[Epoch 28; Iter    87/  209] train: loss: 0.1270287
[Epoch 28; Iter   117/  209] train: loss: 0.1487832
[Epoch 28; Iter   147/  209] train: loss: 0.1251645
[Epoch 28; Iter   177/  209] train: loss: 0.1401053
[Epoch 28; Iter   207/  209] train: loss: 0.1385142
[Epoch 28] ogbg-moltox21: 0.780530 val loss: 0.334813
[Epoch 28] ogbg-moltox21: 0.743565 test loss: 0.280888
[Epoch 29; Iter    28/  209] train: loss: 0.0931539
[Epoch 29; Iter    58/  209] train: loss: 0.1189861
[Epoch 29; Iter    88/  209] train: loss: 0.1409895
[Epoch 29; Iter   118/  209] train: loss: 0.2071699
[Epoch 29; Iter   148/  209] train: loss: 0.1182940
[Epoch 29; Iter   178/  209] train: loss: 0.0994464
[Epoch 29; Iter   208/  209] train: loss: 0.0952698
[Epoch 29] ogbg-moltox21: 0.771023 val loss: 0.281065
[Epoch 29] ogbg-moltox21: 0.728502 test loss: 0.390438
[Epoch 30; Iter    29/  209] train: loss: 0.1244362
[Epoch 30; Iter    59/  209] train: loss: 0.1008437
[Epoch 13; Iter    12/  209] train: loss: 0.1783609
[Epoch 13; Iter    42/  209] train: loss: 0.1728554
[Epoch 13; Iter    72/  209] train: loss: 0.1888274
[Epoch 13; Iter   102/  209] train: loss: 0.2035120
[Epoch 13; Iter   132/  209] train: loss: 0.1801796
[Epoch 13; Iter   162/  209] train: loss: 0.2810015
[Epoch 13; Iter   192/  209] train: loss: 0.2119604
[Epoch 13] ogbg-moltox21: 0.749599 val loss: 0.276237
[Epoch 13] ogbg-moltox21: 0.722502 test loss: 0.280254
[Epoch 14; Iter    13/  209] train: loss: 0.1159465
[Epoch 14; Iter    43/  209] train: loss: 0.1798140
[Epoch 14; Iter    73/  209] train: loss: 0.1553390
[Epoch 14; Iter   103/  209] train: loss: 0.2970739
[Epoch 14; Iter   133/  209] train: loss: 0.2117884
[Epoch 14; Iter   163/  209] train: loss: 0.2187641
[Epoch 14; Iter   193/  209] train: loss: 0.2298208
[Epoch 14] ogbg-moltox21: 0.753172 val loss: 0.270239
[Epoch 14] ogbg-moltox21: 0.727590 test loss: 0.275252
[Epoch 15; Iter    14/  209] train: loss: 0.1251468
[Epoch 15; Iter    44/  209] train: loss: 0.1551081
[Epoch 15; Iter    74/  209] train: loss: 0.2101331
[Epoch 15; Iter   104/  209] train: loss: 0.1907121
[Epoch 15; Iter   134/  209] train: loss: 0.1450153
[Epoch 15; Iter   164/  209] train: loss: 0.1551149
[Epoch 15; Iter   194/  209] train: loss: 0.1807832
[Epoch 15] ogbg-moltox21: 0.696109 val loss: 2.105173
[Epoch 15] ogbg-moltox21: 0.651977 test loss: 2.798291
[Epoch 16; Iter    15/  209] train: loss: 0.1680786
[Epoch 16; Iter    45/  209] train: loss: 0.2010622
[Epoch 16; Iter    75/  209] train: loss: 0.2733701
[Epoch 16; Iter   105/  209] train: loss: 0.2863331
[Epoch 16; Iter   135/  209] train: loss: 0.2813272
[Epoch 16; Iter   165/  209] train: loss: 0.3255150
[Epoch 16; Iter   195/  209] train: loss: 0.2250689
[Epoch 16] ogbg-moltox21: 0.751558 val loss: 0.291513
[Epoch 16] ogbg-moltox21: 0.715082 test loss: 0.293316
[Epoch 17; Iter    16/  209] train: loss: 0.1993655
[Epoch 17; Iter    46/  209] train: loss: 0.2352229
[Epoch 17; Iter    76/  209] train: loss: 0.2466707
[Epoch 17; Iter   106/  209] train: loss: 0.2053796
[Epoch 17; Iter   136/  209] train: loss: 0.3279414
[Epoch 17; Iter   166/  209] train: loss: 0.2465443
[Epoch 17; Iter   196/  209] train: loss: 0.1745195
[Epoch 17] ogbg-moltox21: 0.769182 val loss: 0.261657
[Epoch 17] ogbg-moltox21: 0.726178 test loss: 0.275497
[Epoch 18; Iter    17/  209] train: loss: 0.1504413
[Epoch 18; Iter    47/  209] train: loss: 0.1627966
[Epoch 18; Iter    77/  209] train: loss: 0.2357034
[Epoch 18; Iter   107/  209] train: loss: 0.1595263
[Epoch 18; Iter   137/  209] train: loss: 0.1379191
[Epoch 18; Iter   167/  209] train: loss: 0.1718898
[Epoch 18; Iter   197/  209] train: loss: 0.2028374
[Epoch 18] ogbg-moltox21: 0.771173 val loss: 0.267460
[Epoch 18] ogbg-moltox21: 0.727376 test loss: 0.283140
[Epoch 19; Iter    18/  209] train: loss: 0.1574771
[Epoch 19; Iter    48/  209] train: loss: 0.1200833
[Epoch 19; Iter    78/  209] train: loss: 0.2501998
[Epoch 19; Iter   108/  209] train: loss: 0.1398276
[Epoch 19; Iter   138/  209] train: loss: 0.2014534
[Epoch 19; Iter   168/  209] train: loss: 0.2131003
[Epoch 19; Iter   198/  209] train: loss: 0.2793198
[Epoch 19] ogbg-moltox21: 0.763676 val loss: 0.269102
[Epoch 19] ogbg-moltox21: 0.717056 test loss: 0.286531
[Epoch 20; Iter    19/  209] train: loss: 0.2055190
[Epoch 20; Iter    49/  209] train: loss: 0.1205345
[Epoch 20; Iter    79/  209] train: loss: 0.1671693
[Epoch 20; Iter   109/  209] train: loss: 0.1965705
[Epoch 20; Iter   139/  209] train: loss: 0.1333927
[Epoch 20; Iter   169/  209] train: loss: 0.2101180
[Epoch 20; Iter   199/  209] train: loss: 0.2371199
[Epoch 20] ogbg-moltox21: 0.768494 val loss: 0.267665
[Epoch 20] ogbg-moltox21: 0.714936 test loss: 0.290326
[Epoch 21; Iter    20/  209] train: loss: 0.1511997
[Epoch 21; Iter    50/  209] train: loss: 0.1918447
[Epoch 21; Iter    80/  209] train: loss: 0.1489137
[Epoch 21; Iter   110/  209] train: loss: 0.2034346
[Epoch 21; Iter   140/  209] train: loss: 0.1171340
[Epoch 21; Iter   170/  209] train: loss: 0.1896344
[Epoch 21; Iter   200/  209] train: loss: 0.1245781
[Epoch 21] ogbg-moltox21: 0.730846 val loss: 0.291866
[Epoch 21] ogbg-moltox21: 0.687485 test loss: 0.308791
[Epoch 22; Iter    21/  209] train: loss: 0.2186673
[Epoch 22; Iter    51/  209] train: loss: 0.1448715
[Epoch 22; Iter    81/  209] train: loss: 0.0931751
[Epoch 22; Iter   111/  209] train: loss: 0.1458020
[Epoch 22; Iter   141/  209] train: loss: 0.1382501
[Epoch 22; Iter   171/  209] train: loss: 0.2159637
[Epoch 22; Iter   201/  209] train: loss: 0.1917688
[Epoch 22] ogbg-moltox21: 0.761556 val loss: 0.265658
[Epoch 22] ogbg-moltox21: 0.711265 test loss: 0.285973
[Epoch 23; Iter    22/  209] train: loss: 0.1242564
[Epoch 23; Iter    52/  209] train: loss: 0.2081772
[Epoch 23; Iter    82/  209] train: loss: 0.1859886
[Epoch 23; Iter   112/  209] train: loss: 0.1472816
[Epoch 23; Iter   142/  209] train: loss: 0.1389826
[Epoch 23; Iter   172/  209] train: loss: 0.1943713
[Epoch 23; Iter   202/  209] train: loss: 0.1869995
[Epoch 23] ogbg-moltox21: 0.744858 val loss: 0.277953
[Epoch 23] ogbg-moltox21: 0.695598 test loss: 0.297560
[Epoch 24; Iter    23/  209] train: loss: 0.2181841
[Epoch 24; Iter    53/  209] train: loss: 0.2232884
[Epoch 24; Iter    83/  209] train: loss: 0.1988084
[Epoch 24; Iter   113/  209] train: loss: 0.1305223
[Epoch 24; Iter   143/  209] train: loss: 0.1713290
[Epoch 24; Iter   173/  209] train: loss: 0.1374784
[Epoch 24; Iter   203/  209] train: loss: 0.1959110
[Epoch 24] ogbg-moltox21: 0.744579 val loss: 0.419259
[Epoch 24] ogbg-moltox21: 0.702501 test loss: 0.307204
[Epoch 25; Iter    24/  209] train: loss: 0.2035319
[Epoch 25; Iter    54/  209] train: loss: 0.2099050
[Epoch 25; Iter    84/  209] train: loss: 0.1371307
[Epoch 25; Iter   114/  209] train: loss: 0.2069167
[Epoch 25; Iter   144/  209] train: loss: 0.1201242
[Epoch 25; Iter   174/  209] train: loss: 0.2232813
[Epoch 25; Iter   204/  209] train: loss: 0.1030356
[Epoch 25] ogbg-moltox21: 0.749475 val loss: 0.325746
[Epoch 25] ogbg-moltox21: 0.703947 test loss: 0.288286
[Epoch 26; Iter    25/  209] train: loss: 0.1009747
[Epoch 26; Iter    55/  209] train: loss: 0.1252885
[Epoch 26; Iter    85/  209] train: loss: 0.1927878
[Epoch 26; Iter   115/  209] train: loss: 0.1265024
[Epoch 26; Iter   145/  209] train: loss: 0.1306484
[Epoch 26; Iter   175/  209] train: loss: 0.1371170
[Epoch 26; Iter   205/  209] train: loss: 0.2823822
[Epoch 26] ogbg-moltox21: 0.734401 val loss: 0.305244
[Epoch 26] ogbg-moltox21: 0.707772 test loss: 0.331004
[Epoch 27; Iter    26/  209] train: loss: 0.1214963
[Epoch 27; Iter    56/  209] train: loss: 0.0774905
[Epoch 27; Iter    86/  209] train: loss: 0.1603684
[Epoch 27; Iter   116/  209] train: loss: 0.1992705
[Epoch 27; Iter   146/  209] train: loss: 0.1391653
[Epoch 27; Iter   176/  209] train: loss: 0.1995910
[Epoch 27; Iter   206/  209] train: loss: 0.2528470
[Epoch 27] ogbg-moltox21: 0.730899 val loss: 0.322285
[Epoch 27] ogbg-moltox21: 0.685877 test loss: 0.340277
[Epoch 28; Iter    27/  209] train: loss: 0.2026700
[Epoch 28; Iter    57/  209] train: loss: 0.0939108
[Epoch 28; Iter    87/  209] train: loss: 0.2139240
[Epoch 28; Iter   117/  209] train: loss: 0.1800518
[Epoch 28; Iter   147/  209] train: loss: 0.2083637
[Epoch 28; Iter   177/  209] train: loss: 0.1597382
[Epoch 28; Iter   207/  209] train: loss: 0.1100313
[Epoch 28] ogbg-moltox21: 0.743433 val loss: 0.295606
[Epoch 28] ogbg-moltox21: 0.692223 test loss: 0.317434
[Epoch 29; Iter    28/  209] train: loss: 0.1505680
[Epoch 29; Iter    58/  209] train: loss: 0.1285934
[Epoch 29; Iter    88/  209] train: loss: 0.1455579
[Epoch 29; Iter   118/  209] train: loss: 0.1180264
[Epoch 29; Iter   148/  209] train: loss: 0.2140776
[Epoch 29; Iter   178/  209] train: loss: 0.1393242
[Epoch 29; Iter   208/  209] train: loss: 0.1917550
[Epoch 29] ogbg-moltox21: 0.723816 val loss: 0.279908
[Epoch 29] ogbg-moltox21: 0.677842 test loss: 0.300915
[Epoch 30; Iter    29/  209] train: loss: 0.1254694
[Epoch 30; Iter    59/  209] train: loss: 0.2098515
[Epoch 13; Iter    12/  209] train: loss: 0.2602774
[Epoch 13; Iter    42/  209] train: loss: 0.2049980
[Epoch 13; Iter    72/  209] train: loss: 0.2300320
[Epoch 13; Iter   102/  209] train: loss: 0.1939516
[Epoch 13; Iter   132/  209] train: loss: 0.1408670
[Epoch 13; Iter   162/  209] train: loss: 0.2041606
[Epoch 13; Iter   192/  209] train: loss: 0.1706630
[Epoch 13] ogbg-moltox21: 0.778628 val loss: 0.573252
[Epoch 13] ogbg-moltox21: 0.737051 test loss: 0.711657
[Epoch 14; Iter    13/  209] train: loss: 0.1641612
[Epoch 14; Iter    43/  209] train: loss: 0.1916694
[Epoch 14; Iter    73/  209] train: loss: 0.2079202
[Epoch 14; Iter   103/  209] train: loss: 0.1767474
[Epoch 14; Iter   133/  209] train: loss: 0.2129419
[Epoch 14; Iter   163/  209] train: loss: 0.1544898
[Epoch 14; Iter   193/  209] train: loss: 0.2598637
[Epoch 14] ogbg-moltox21: 0.772436 val loss: 0.369595
[Epoch 14] ogbg-moltox21: 0.740617 test loss: 0.530820
[Epoch 15; Iter    14/  209] train: loss: 0.2251129
[Epoch 15; Iter    44/  209] train: loss: 0.1884335
[Epoch 15; Iter    74/  209] train: loss: 0.1459723
[Epoch 15; Iter   104/  209] train: loss: 0.2346635
[Epoch 15; Iter   134/  209] train: loss: 0.1793436
[Epoch 15; Iter   164/  209] train: loss: 0.1402587
[Epoch 15; Iter   194/  209] train: loss: 0.1562987
[Epoch 15] ogbg-moltox21: 0.759170 val loss: 0.254771
[Epoch 15] ogbg-moltox21: 0.721697 test loss: 0.279031
[Epoch 16; Iter    15/  209] train: loss: 0.1424680
[Epoch 16; Iter    45/  209] train: loss: 0.1955708
[Epoch 16; Iter    75/  209] train: loss: 0.2108049
[Epoch 16; Iter   105/  209] train: loss: 0.2395308
[Epoch 16; Iter   135/  209] train: loss: 0.1562262
[Epoch 16; Iter   165/  209] train: loss: 0.1425775
[Epoch 16; Iter   195/  209] train: loss: 0.1719478
[Epoch 16] ogbg-moltox21: 0.785442 val loss: 0.248235
[Epoch 16] ogbg-moltox21: 0.741498 test loss: 0.271982
[Epoch 17; Iter    16/  209] train: loss: 0.1875415
[Epoch 17; Iter    46/  209] train: loss: 0.2254439
[Epoch 17; Iter    76/  209] train: loss: 0.1880015
[Epoch 17; Iter   106/  209] train: loss: 0.2132602
[Epoch 17; Iter   136/  209] train: loss: 0.1088748
[Epoch 17; Iter   166/  209] train: loss: 0.1744458
[Epoch 17; Iter   196/  209] train: loss: 0.2120951
[Epoch 17] ogbg-moltox21: 0.781910 val loss: 0.274678
[Epoch 17] ogbg-moltox21: 0.728694 test loss: 0.492412
[Epoch 18; Iter    17/  209] train: loss: 0.1544986
[Epoch 18; Iter    47/  209] train: loss: 0.1422164
[Epoch 18; Iter    77/  209] train: loss: 0.1810886
[Epoch 18; Iter   107/  209] train: loss: 0.2411103
[Epoch 18; Iter   137/  209] train: loss: 0.1164216
[Epoch 18; Iter   167/  209] train: loss: 0.1649849
[Epoch 18; Iter   197/  209] train: loss: 0.1130171
[Epoch 18] ogbg-moltox21: 0.779952 val loss: 0.277732
[Epoch 18] ogbg-moltox21: 0.746993 test loss: 0.298855
[Epoch 19; Iter    18/  209] train: loss: 0.1657964
[Epoch 19; Iter    48/  209] train: loss: 0.1110157
[Epoch 19; Iter    78/  209] train: loss: 0.1745963
[Epoch 19; Iter   108/  209] train: loss: 0.1730603
[Epoch 19; Iter   138/  209] train: loss: 0.2119708
[Epoch 19; Iter   168/  209] train: loss: 0.1974157
[Epoch 19; Iter   198/  209] train: loss: 0.1305560
[Epoch 19] ogbg-moltox21: 0.774009 val loss: 0.259817
[Epoch 19] ogbg-moltox21: 0.720887 test loss: 0.289220
[Epoch 20; Iter    19/  209] train: loss: 0.1982421
[Epoch 20; Iter    49/  209] train: loss: 0.1340150
[Epoch 20; Iter    79/  209] train: loss: 0.1489735
[Epoch 20; Iter   109/  209] train: loss: 0.1380969
[Epoch 20; Iter   139/  209] train: loss: 0.1736461
[Epoch 20; Iter   169/  209] train: loss: 0.1833880
[Epoch 20; Iter   199/  209] train: loss: 0.1793532
[Epoch 20] ogbg-moltox21: 0.763240 val loss: 0.274157
[Epoch 20] ogbg-moltox21: 0.727042 test loss: 0.296045
[Epoch 21; Iter    20/  209] train: loss: 0.1497462
[Epoch 21; Iter    50/  209] train: loss: 0.1863834
[Epoch 21; Iter    80/  209] train: loss: 0.1441484
[Epoch 21; Iter   110/  209] train: loss: 0.2899675
[Epoch 21; Iter   140/  209] train: loss: 0.1710461
[Epoch 21; Iter   170/  209] train: loss: 0.1798007
[Epoch 21; Iter   200/  209] train: loss: 0.1536568
[Epoch 21] ogbg-moltox21: 0.778614 val loss: 0.251023
[Epoch 21] ogbg-moltox21: 0.720050 test loss: 0.277416
[Epoch 22; Iter    21/  209] train: loss: 0.0983296
[Epoch 22; Iter    51/  209] train: loss: 0.1886622
[Epoch 22; Iter    81/  209] train: loss: 0.1382209
[Epoch 22; Iter   111/  209] train: loss: 0.2049579
[Epoch 22; Iter   141/  209] train: loss: 0.1298474
[Epoch 22; Iter   171/  209] train: loss: 0.1834744
[Epoch 22; Iter   201/  209] train: loss: 0.1409898
[Epoch 22] ogbg-moltox21: 0.775208 val loss: 0.263149
[Epoch 22] ogbg-moltox21: 0.730788 test loss: 0.360772
[Epoch 23; Iter    22/  209] train: loss: 0.1038320
[Epoch 23; Iter    52/  209] train: loss: 0.1062391
[Epoch 23; Iter    82/  209] train: loss: 0.1367208
[Epoch 23; Iter   112/  209] train: loss: 0.1697482
[Epoch 23; Iter   142/  209] train: loss: 0.1390762
[Epoch 23; Iter   172/  209] train: loss: 0.1677266
[Epoch 23; Iter   202/  209] train: loss: 0.1294734
[Epoch 23] ogbg-moltox21: 0.779325 val loss: 0.265134
[Epoch 23] ogbg-moltox21: 0.743255 test loss: 0.285724
[Epoch 24; Iter    23/  209] train: loss: 0.1307871
[Epoch 24; Iter    53/  209] train: loss: 0.1471373
[Epoch 24; Iter    83/  209] train: loss: 0.1290970
[Epoch 24; Iter   113/  209] train: loss: 0.1275230
[Epoch 24; Iter   143/  209] train: loss: 0.1455065
[Epoch 24; Iter   173/  209] train: loss: 0.1426283
[Epoch 24; Iter   203/  209] train: loss: 0.1561434
[Epoch 24] ogbg-moltox21: 0.749733 val loss: 0.281765
[Epoch 24] ogbg-moltox21: 0.716468 test loss: 0.300433
[Epoch 25; Iter    24/  209] train: loss: 0.1155756
[Epoch 25; Iter    54/  209] train: loss: 0.0845866
[Epoch 25; Iter    84/  209] train: loss: 0.0969630
[Epoch 25; Iter   114/  209] train: loss: 0.1323415
[Epoch 25; Iter   144/  209] train: loss: 0.2223680
[Epoch 25; Iter   174/  209] train: loss: 0.1232743
[Epoch 25; Iter   204/  209] train: loss: 0.1111154
[Epoch 25] ogbg-moltox21: 0.783120 val loss: 0.263567
[Epoch 25] ogbg-moltox21: 0.740940 test loss: 0.286531
[Epoch 26; Iter    25/  209] train: loss: 0.1064018
[Epoch 26; Iter    55/  209] train: loss: 0.1565244
[Epoch 26; Iter    85/  209] train: loss: 0.1978235
[Epoch 26; Iter   115/  209] train: loss: 0.1463033
[Epoch 26; Iter   145/  209] train: loss: 0.1277068
[Epoch 26; Iter   175/  209] train: loss: 0.1056014
[Epoch 26; Iter   205/  209] train: loss: 0.1009774
[Epoch 26] ogbg-moltox21: 0.760863 val loss: 0.268835
[Epoch 26] ogbg-moltox21: 0.730142 test loss: 0.288360
[Epoch 27; Iter    26/  209] train: loss: 0.1458215
[Epoch 27; Iter    56/  209] train: loss: 0.0733660
[Epoch 27; Iter    86/  209] train: loss: 0.1640708
[Epoch 27; Iter   116/  209] train: loss: 0.1296033
[Epoch 27; Iter   146/  209] train: loss: 0.1409979
[Epoch 27; Iter   176/  209] train: loss: 0.1806733
[Epoch 27; Iter   206/  209] train: loss: 0.1116059
[Epoch 27] ogbg-moltox21: 0.757213 val loss: 0.314929
[Epoch 27] ogbg-moltox21: 0.734197 test loss: 0.303484
[Epoch 28; Iter    27/  209] train: loss: 0.0717761
[Epoch 28; Iter    57/  209] train: loss: 0.2001394
[Epoch 28; Iter    87/  209] train: loss: 0.1597358
[Epoch 28; Iter   117/  209] train: loss: 0.0987344
[Epoch 28; Iter   147/  209] train: loss: 0.1371869
[Epoch 28; Iter   177/  209] train: loss: 0.1710185
[Epoch 28; Iter   207/  209] train: loss: 0.1022359
[Epoch 28] ogbg-moltox21: 0.765130 val loss: 0.328643
[Epoch 28] ogbg-moltox21: 0.737778 test loss: 0.321476
[Epoch 29; Iter    28/  209] train: loss: 0.1048838
[Epoch 29; Iter    58/  209] train: loss: 0.1187363
[Epoch 29; Iter    88/  209] train: loss: 0.1242178
[Epoch 29; Iter   118/  209] train: loss: 0.1709849
[Epoch 29; Iter   148/  209] train: loss: 0.0861246
[Epoch 29; Iter   178/  209] train: loss: 0.0640270
[Epoch 29; Iter   208/  209] train: loss: 0.1074207
[Epoch 29] ogbg-moltox21: 0.783354 val loss: 0.276468
[Epoch 29] ogbg-moltox21: 0.735335 test loss: 0.290409
[Epoch 30; Iter    29/  209] train: loss: 0.1053326
[Epoch 30; Iter    59/  209] train: loss: 0.1038472
[Epoch 13; Iter    12/  209] train: loss: 0.1625420
[Epoch 13; Iter    42/  209] train: loss: 0.1823784
[Epoch 13; Iter    72/  209] train: loss: 0.1855155
[Epoch 13; Iter   102/  209] train: loss: 0.2073718
[Epoch 13; Iter   132/  209] train: loss: 0.1885900
[Epoch 13; Iter   162/  209] train: loss: 0.2612111
[Epoch 13; Iter   192/  209] train: loss: 0.2301732
[Epoch 13] ogbg-moltox21: 0.740827 val loss: 0.496730
[Epoch 13] ogbg-moltox21: 0.705694 test loss: 0.384423
[Epoch 14; Iter    13/  209] train: loss: 0.1138522
[Epoch 14; Iter    43/  209] train: loss: 0.1708697
[Epoch 14; Iter    73/  209] train: loss: 0.1710967
[Epoch 14; Iter   103/  209] train: loss: 0.2959798
[Epoch 14; Iter   133/  209] train: loss: 0.1935542
[Epoch 14; Iter   163/  209] train: loss: 0.2242113
[Epoch 14; Iter   193/  209] train: loss: 0.2591241
[Epoch 14] ogbg-moltox21: 0.761329 val loss: 0.312956
[Epoch 14] ogbg-moltox21: 0.727985 test loss: 0.287234
[Epoch 15; Iter    14/  209] train: loss: 0.1332995
[Epoch 15; Iter    44/  209] train: loss: 0.1713717
[Epoch 15; Iter    74/  209] train: loss: 0.2260543
[Epoch 15; Iter   104/  209] train: loss: 0.1640402
[Epoch 15; Iter   134/  209] train: loss: 0.1366682
[Epoch 15; Iter   164/  209] train: loss: 0.1527301
[Epoch 15; Iter   194/  209] train: loss: 0.1701579
[Epoch 15] ogbg-moltox21: 0.774261 val loss: 0.257559
[Epoch 15] ogbg-moltox21: 0.737567 test loss: 0.265288
[Epoch 16; Iter    15/  209] train: loss: 0.1442182
[Epoch 16; Iter    45/  209] train: loss: 0.2008193
[Epoch 16; Iter    75/  209] train: loss: 0.2707936
[Epoch 16; Iter   105/  209] train: loss: 0.3120525
[Epoch 16; Iter   135/  209] train: loss: 0.2556946
[Epoch 16; Iter   165/  209] train: loss: 0.3174340
[Epoch 16; Iter   195/  209] train: loss: 0.2266713
[Epoch 16] ogbg-moltox21: 0.778049 val loss: 0.271581
[Epoch 16] ogbg-moltox21: 0.727480 test loss: 0.274198
[Epoch 17; Iter    16/  209] train: loss: 0.1958309
[Epoch 17; Iter    46/  209] train: loss: 0.2308052
[Epoch 17; Iter    76/  209] train: loss: 0.2527845
[Epoch 17; Iter   106/  209] train: loss: 0.2019939
[Epoch 17; Iter   136/  209] train: loss: 0.3343493
[Epoch 17; Iter   166/  209] train: loss: 0.2527265
[Epoch 17; Iter   196/  209] train: loss: 0.1720010
[Epoch 17] ogbg-moltox21: 0.772258 val loss: 0.260697
[Epoch 17] ogbg-moltox21: 0.729126 test loss: 0.272209
[Epoch 18; Iter    17/  209] train: loss: 0.1549084
[Epoch 18; Iter    47/  209] train: loss: 0.1460440
[Epoch 18; Iter    77/  209] train: loss: 0.2345623
[Epoch 18; Iter   107/  209] train: loss: 0.1555478
[Epoch 18; Iter   137/  209] train: loss: 0.1367081
[Epoch 18; Iter   167/  209] train: loss: 0.1830701
[Epoch 18; Iter   197/  209] train: loss: 0.1863260
[Epoch 18] ogbg-moltox21: 0.777528 val loss: 0.249554
[Epoch 18] ogbg-moltox21: 0.738757 test loss: 0.265048
[Epoch 19; Iter    18/  209] train: loss: 0.1634605
[Epoch 19; Iter    48/  209] train: loss: 0.1097744
[Epoch 19; Iter    78/  209] train: loss: 0.2680770
[Epoch 19; Iter   108/  209] train: loss: 0.1428738
[Epoch 19; Iter   138/  209] train: loss: 0.1938341
[Epoch 19; Iter   168/  209] train: loss: 0.1998327
[Epoch 19; Iter   198/  209] train: loss: 0.2798508
[Epoch 19] ogbg-moltox21: 0.771510 val loss: 0.308713
[Epoch 19] ogbg-moltox21: 0.723017 test loss: 0.285598
[Epoch 20; Iter    19/  209] train: loss: 0.2028029
[Epoch 20; Iter    49/  209] train: loss: 0.1569207
[Epoch 20; Iter    79/  209] train: loss: 0.1764387
[Epoch 20; Iter   109/  209] train: loss: 0.2156087
[Epoch 20; Iter   139/  209] train: loss: 0.1414134
[Epoch 20; Iter   169/  209] train: loss: 0.2153971
[Epoch 20; Iter   199/  209] train: loss: 0.2409580
[Epoch 20] ogbg-moltox21: 0.791892 val loss: 0.255568
[Epoch 20] ogbg-moltox21: 0.746901 test loss: 0.271288
[Epoch 21; Iter    20/  209] train: loss: 0.1551075
[Epoch 21; Iter    50/  209] train: loss: 0.2027442
[Epoch 21; Iter    80/  209] train: loss: 0.1411118
[Epoch 21; Iter   110/  209] train: loss: 0.1964427
[Epoch 21; Iter   140/  209] train: loss: 0.0973422
[Epoch 21; Iter   170/  209] train: loss: 0.1484200
[Epoch 21; Iter   200/  209] train: loss: 0.1228709
[Epoch 21] ogbg-moltox21: 0.766245 val loss: 0.255201
[Epoch 21] ogbg-moltox21: 0.712696 test loss: 0.271264
[Epoch 22; Iter    21/  209] train: loss: 0.2018854
[Epoch 22; Iter    51/  209] train: loss: 0.2105182
[Epoch 22; Iter    81/  209] train: loss: 0.0938472
[Epoch 22; Iter   111/  209] train: loss: 0.1462319
[Epoch 22; Iter   141/  209] train: loss: 0.1613064
[Epoch 22; Iter   171/  209] train: loss: 0.2218165
[Epoch 22; Iter   201/  209] train: loss: 0.1990181
[Epoch 22] ogbg-moltox21: 0.785039 val loss: 0.261510
[Epoch 22] ogbg-moltox21: 0.729654 test loss: 0.287083
[Epoch 23; Iter    22/  209] train: loss: 0.1236473
[Epoch 23; Iter    52/  209] train: loss: 0.2166797
[Epoch 23; Iter    82/  209] train: loss: 0.1641040
[Epoch 23; Iter   112/  209] train: loss: 0.1543452
[Epoch 23; Iter   142/  209] train: loss: 0.1495724
[Epoch 23; Iter   172/  209] train: loss: 0.1672556
[Epoch 23; Iter   202/  209] train: loss: 0.2007585
[Epoch 23] ogbg-moltox21: 0.790673 val loss: 0.252351
[Epoch 23] ogbg-moltox21: 0.734437 test loss: 0.275913
[Epoch 24; Iter    23/  209] train: loss: 0.2082788
[Epoch 24; Iter    53/  209] train: loss: 0.2022248
[Epoch 24; Iter    83/  209] train: loss: 0.2293020
[Epoch 24; Iter   113/  209] train: loss: 0.1534379
[Epoch 24; Iter   143/  209] train: loss: 0.1512076
[Epoch 24; Iter   173/  209] train: loss: 0.1220477
[Epoch 24; Iter   203/  209] train: loss: 0.1833363
[Epoch 24] ogbg-moltox21: 0.795968 val loss: 0.263909
[Epoch 24] ogbg-moltox21: 0.743455 test loss: 0.289000
[Epoch 25; Iter    24/  209] train: loss: 0.1906662
[Epoch 25; Iter    54/  209] train: loss: 0.2069272
[Epoch 25; Iter    84/  209] train: loss: 0.1393595
[Epoch 25; Iter   114/  209] train: loss: 0.2011174
[Epoch 25; Iter   144/  209] train: loss: 0.1201937
[Epoch 25; Iter   174/  209] train: loss: 0.2335821
[Epoch 25; Iter   204/  209] train: loss: 0.1389757
[Epoch 25] ogbg-moltox21: 0.797348 val loss: 0.259622
[Epoch 25] ogbg-moltox21: 0.737072 test loss: 0.278467
[Epoch 26; Iter    25/  209] train: loss: 0.1047051
[Epoch 26; Iter    55/  209] train: loss: 0.1446527
[Epoch 26; Iter    85/  209] train: loss: 0.2034730
[Epoch 26; Iter   115/  209] train: loss: 0.1266598
[Epoch 26; Iter   145/  209] train: loss: 0.1683959
[Epoch 26; Iter   175/  209] train: loss: 0.1560927
[Epoch 26; Iter   205/  209] train: loss: 0.2796199
[Epoch 26] ogbg-moltox21: 0.777738 val loss: 0.254567
[Epoch 26] ogbg-moltox21: 0.727480 test loss: 0.275957
[Epoch 27; Iter    26/  209] train: loss: 0.1246289
[Epoch 27; Iter    56/  209] train: loss: 0.1058737
[Epoch 27; Iter    86/  209] train: loss: 0.1548797
[Epoch 27; Iter   116/  209] train: loss: 0.2077995
[Epoch 27; Iter   146/  209] train: loss: 0.1317216
[Epoch 27; Iter   176/  209] train: loss: 0.1827034
[Epoch 27; Iter   206/  209] train: loss: 0.2062547
[Epoch 27] ogbg-moltox21: 0.789132 val loss: 0.251541
[Epoch 27] ogbg-moltox21: 0.740206 test loss: 0.274486
[Epoch 28; Iter    27/  209] train: loss: 0.2259636
[Epoch 28; Iter    57/  209] train: loss: 0.0934087
[Epoch 28; Iter    87/  209] train: loss: 0.1957538
[Epoch 28; Iter   117/  209] train: loss: 0.1817078
[Epoch 28; Iter   147/  209] train: loss: 0.2115623
[Epoch 28; Iter   177/  209] train: loss: 0.1670795
[Epoch 28; Iter   207/  209] train: loss: 0.1218145
[Epoch 28] ogbg-moltox21: 0.768936 val loss: 0.279150
[Epoch 28] ogbg-moltox21: 0.722888 test loss: 0.299201
[Epoch 29; Iter    28/  209] train: loss: 0.1618746
[Epoch 29; Iter    58/  209] train: loss: 0.1691675
[Epoch 29; Iter    88/  209] train: loss: 0.1727556
[Epoch 29; Iter   118/  209] train: loss: 0.1238549
[Epoch 29; Iter   148/  209] train: loss: 0.2098958
[Epoch 29; Iter   178/  209] train: loss: 0.1524163
[Epoch 29; Iter   208/  209] train: loss: 0.1905866
[Epoch 29] ogbg-moltox21: 0.791783 val loss: 0.259215
[Epoch 29] ogbg-moltox21: 0.739006 test loss: 0.274632
[Epoch 30; Iter    29/  209] train: loss: 0.1094541
[Epoch 30; Iter    59/  209] train: loss: 0.2397287
[Epoch 13; Iter    12/  209] train: loss: 0.1819829
[Epoch 13; Iter    42/  209] train: loss: 0.1562547
[Epoch 13; Iter    72/  209] train: loss: 0.2691313
[Epoch 13; Iter   102/  209] train: loss: 0.1688780
[Epoch 13; Iter   132/  209] train: loss: 0.2861136
[Epoch 13; Iter   162/  209] train: loss: 0.2771412
[Epoch 13; Iter   192/  209] train: loss: 0.2274888
[Epoch 13] ogbg-moltox21: 0.762696 val loss: 0.323154
[Epoch 13] ogbg-moltox21: 0.714765 test loss: 0.370001
[Epoch 14; Iter    13/  209] train: loss: 0.2124310
[Epoch 14; Iter    43/  209] train: loss: 0.1845887
[Epoch 14; Iter    73/  209] train: loss: 0.1995800
[Epoch 14; Iter   103/  209] train: loss: 0.1804561
[Epoch 14; Iter   133/  209] train: loss: 0.2392246
[Epoch 14; Iter   163/  209] train: loss: 0.1969614
[Epoch 14; Iter   193/  209] train: loss: 0.2094632
[Epoch 14] ogbg-moltox21: 0.736897 val loss: 0.291969
[Epoch 14] ogbg-moltox21: 0.682082 test loss: 0.379902
[Epoch 15; Iter    14/  209] train: loss: 0.1616770
[Epoch 15; Iter    44/  209] train: loss: 0.2108320
[Epoch 15; Iter    74/  209] train: loss: 0.1690909
[Epoch 15; Iter   104/  209] train: loss: 0.2164168
[Epoch 15; Iter   134/  209] train: loss: 0.1575065
[Epoch 15; Iter   164/  209] train: loss: 0.2002446
[Epoch 15; Iter   194/  209] train: loss: 0.2051235
[Epoch 15] ogbg-moltox21: 0.710477 val loss: 0.312926
[Epoch 15] ogbg-moltox21: 0.655498 test loss: 0.325770
[Epoch 16; Iter    15/  209] train: loss: 0.2074218
[Epoch 16; Iter    45/  209] train: loss: 0.1547857
[Epoch 16; Iter    75/  209] train: loss: 0.2050132
[Epoch 16; Iter   105/  209] train: loss: 0.1859027
[Epoch 16; Iter   135/  209] train: loss: 0.1908255
[Epoch 16; Iter   165/  209] train: loss: 0.1799013
[Epoch 16; Iter   195/  209] train: loss: 0.1802714
[Epoch 16] ogbg-moltox21: 0.763977 val loss: 0.334387
[Epoch 16] ogbg-moltox21: 0.714900 test loss: 0.460163
[Epoch 17; Iter    16/  209] train: loss: 0.1573652
[Epoch 17; Iter    46/  209] train: loss: 0.1521948
[Epoch 17; Iter    76/  209] train: loss: 0.1331367
[Epoch 17; Iter   106/  209] train: loss: 0.1991158
[Epoch 17; Iter   136/  209] train: loss: 0.1433151
[Epoch 17; Iter   166/  209] train: loss: 0.1706374
[Epoch 17; Iter   196/  209] train: loss: 0.1563856
[Epoch 17] ogbg-moltox21: 0.752140 val loss: 0.389621
[Epoch 17] ogbg-moltox21: 0.685000 test loss: 0.633964
[Epoch 18; Iter    17/  209] train: loss: 0.0990305
[Epoch 18; Iter    47/  209] train: loss: 0.1804215
[Epoch 18; Iter    77/  209] train: loss: 0.2208011
[Epoch 18; Iter   107/  209] train: loss: 0.2198533
[Epoch 18; Iter   137/  209] train: loss: 0.1629002
[Epoch 18; Iter   167/  209] train: loss: 0.1320009
[Epoch 18; Iter   197/  209] train: loss: 0.1205914
[Epoch 18] ogbg-moltox21: 0.729457 val loss: 0.295211
[Epoch 18] ogbg-moltox21: 0.681500 test loss: 0.420165
[Epoch 19; Iter    18/  209] train: loss: 0.2739365
[Epoch 19; Iter    48/  209] train: loss: 0.1574837
[Epoch 19; Iter    78/  209] train: loss: 0.1501565
[Epoch 19; Iter   108/  209] train: loss: 0.1331470
[Epoch 19; Iter   138/  209] train: loss: 0.1179719
[Epoch 19; Iter   168/  209] train: loss: 0.1616683
[Epoch 19; Iter   198/  209] train: loss: 0.2279497
[Epoch 19] ogbg-moltox21: 0.704786 val loss: 0.362529
[Epoch 19] ogbg-moltox21: 0.670168 test loss: 0.486642
[Epoch 20; Iter    19/  209] train: loss: 0.1919763
[Epoch 20; Iter    49/  209] train: loss: 0.2369703
[Epoch 20; Iter    79/  209] train: loss: 0.0988418
[Epoch 20; Iter   109/  209] train: loss: 0.1146158
[Epoch 20; Iter   139/  209] train: loss: 0.1982584
[Epoch 20; Iter   169/  209] train: loss: 0.2159331
[Epoch 20; Iter   199/  209] train: loss: 0.1230765
[Epoch 20] ogbg-moltox21: 0.711295 val loss: 0.416226
[Epoch 20] ogbg-moltox21: 0.665547 test loss: 0.500237
[Epoch 21; Iter    20/  209] train: loss: 0.1247337
[Epoch 21; Iter    50/  209] train: loss: 0.1971624
[Epoch 21; Iter    80/  209] train: loss: 0.1845814
[Epoch 21; Iter   110/  209] train: loss: 0.1023690
[Epoch 21; Iter   140/  209] train: loss: 0.2267631
[Epoch 21; Iter   170/  209] train: loss: 0.3779203
[Epoch 21; Iter   200/  209] train: loss: 0.1540969
[Epoch 21] ogbg-moltox21: 0.749662 val loss: 0.304766
[Epoch 21] ogbg-moltox21: 0.702869 test loss: 0.327684
[Epoch 22; Iter    21/  209] train: loss: 0.1141766
[Epoch 22; Iter    51/  209] train: loss: 0.0721761
[Epoch 22; Iter    81/  209] train: loss: 0.1001287
[Epoch 22; Iter   111/  209] train: loss: 0.1159915
[Epoch 22; Iter   141/  209] train: loss: 0.1718356
[Epoch 22; Iter   171/  209] train: loss: 0.1079763
[Epoch 22; Iter   201/  209] train: loss: 0.1114630
[Epoch 22] ogbg-moltox21: 0.715930 val loss: 0.366707
[Epoch 22] ogbg-moltox21: 0.678437 test loss: 0.389231
[Epoch 23; Iter    22/  209] train: loss: 0.1542673
[Epoch 23; Iter    52/  209] train: loss: 0.1679056
[Epoch 23; Iter    82/  209] train: loss: 0.1151228
[Epoch 23; Iter   112/  209] train: loss: 0.1314858
[Epoch 23; Iter   142/  209] train: loss: 0.1605674
[Epoch 23; Iter   172/  209] train: loss: 0.1345149
[Epoch 23; Iter   202/  209] train: loss: 0.1327804
[Epoch 23] ogbg-moltox21: 0.757872 val loss: 0.328486
[Epoch 23] ogbg-moltox21: 0.704552 test loss: 0.355877
[Epoch 24; Iter    23/  209] train: loss: 0.1605756
[Epoch 24; Iter    53/  209] train: loss: 0.0941425
[Epoch 24; Iter    83/  209] train: loss: 0.1837541
[Epoch 24; Iter   113/  209] train: loss: 0.1263527
[Epoch 24; Iter   143/  209] train: loss: 0.0900153
[Epoch 24; Iter   173/  209] train: loss: 0.1173349
[Epoch 24; Iter   203/  209] train: loss: 0.1909184
[Epoch 24] ogbg-moltox21: 0.737221 val loss: 0.321794
[Epoch 24] ogbg-moltox21: 0.696315 test loss: 0.343197
[Epoch 25; Iter    24/  209] train: loss: 0.0991101
[Epoch 25; Iter    54/  209] train: loss: 0.1886511
[Epoch 25; Iter    84/  209] train: loss: 0.0720001
[Epoch 25; Iter   114/  209] train: loss: 0.1325461
[Epoch 25; Iter   144/  209] train: loss: 0.0921784
[Epoch 25; Iter   174/  209] train: loss: 0.1414344
[Epoch 25; Iter   204/  209] train: loss: 0.2110842
[Epoch 25] ogbg-moltox21: 0.733354 val loss: 0.398531
[Epoch 25] ogbg-moltox21: 0.676401 test loss: 0.447245
[Epoch 26; Iter    25/  209] train: loss: 0.1235372
[Epoch 26; Iter    55/  209] train: loss: 0.1957578
[Epoch 26; Iter    85/  209] train: loss: 0.1563722
[Epoch 26; Iter   115/  209] train: loss: 0.0995572
[Epoch 26; Iter   145/  209] train: loss: 0.1005417
[Epoch 26; Iter   175/  209] train: loss: 0.0784640
[Epoch 26; Iter   205/  209] train: loss: 0.1632305
[Epoch 26] ogbg-moltox21: 0.735230 val loss: 0.353414
[Epoch 26] ogbg-moltox21: 0.678552 test loss: 0.386780
[Epoch 27; Iter    26/  209] train: loss: 0.1004403
[Epoch 27; Iter    56/  209] train: loss: 0.1590540
[Epoch 27; Iter    86/  209] train: loss: 0.1239354
[Epoch 27; Iter   116/  209] train: loss: 0.1127405
[Epoch 27; Iter   146/  209] train: loss: 0.1056011
[Epoch 27; Iter   176/  209] train: loss: 0.1038246
[Epoch 27; Iter   206/  209] train: loss: 0.1314607
[Epoch 27] ogbg-moltox21: 0.724812 val loss: 0.370940
[Epoch 27] ogbg-moltox21: 0.695939 test loss: 0.422588
[Epoch 28; Iter    27/  209] train: loss: 0.0995523
[Epoch 28; Iter    57/  209] train: loss: 0.0984875
[Epoch 28; Iter    87/  209] train: loss: 0.1103191
[Epoch 28; Iter   117/  209] train: loss: 0.1340619
[Epoch 28; Iter   147/  209] train: loss: 0.1086298
[Epoch 28; Iter   177/  209] train: loss: 0.1085744
[Epoch 28; Iter   207/  209] train: loss: 0.1020063
[Epoch 28] ogbg-moltox21: 0.712812 val loss: 0.400142
[Epoch 28] ogbg-moltox21: 0.658369 test loss: 0.420030
[Epoch 29; Iter    28/  209] train: loss: 0.1034696
[Epoch 29; Iter    58/  209] train: loss: 0.1166817
[Epoch 29; Iter    88/  209] train: loss: 0.1584498
[Epoch 29; Iter   118/  209] train: loss: 0.1695039
[Epoch 29; Iter   148/  209] train: loss: 0.1039402
[Epoch 29; Iter   178/  209] train: loss: 0.0853892
[Epoch 29; Iter   208/  209] train: loss: 0.0714254
[Epoch 29] ogbg-moltox21: 0.734311 val loss: 0.386010
[Epoch 29] ogbg-moltox21: 0.682710 test loss: 0.405161
[Epoch 30; Iter    29/  209] train: loss: 0.1185240
[Epoch 30; Iter    59/  209] train: loss: 0.0845888
[Epoch 13; Iter    12/  209] train: loss: 0.2636443
[Epoch 13; Iter    42/  209] train: loss: 0.2085693
[Epoch 13; Iter    72/  209] train: loss: 0.2313811
[Epoch 13; Iter   102/  209] train: loss: 0.2178521
[Epoch 13; Iter   132/  209] train: loss: 0.1541479
[Epoch 13; Iter   162/  209] train: loss: 0.1981834
[Epoch 13; Iter   192/  209] train: loss: 0.1551567
[Epoch 13] ogbg-moltox21: 0.720836 val loss: 0.852983
[Epoch 13] ogbg-moltox21: 0.707950 test loss: 0.987943
[Epoch 14; Iter    13/  209] train: loss: 0.1686307
[Epoch 14; Iter    43/  209] train: loss: 0.1834798
[Epoch 14; Iter    73/  209] train: loss: 0.1797956
[Epoch 14; Iter   103/  209] train: loss: 0.1683880
[Epoch 14; Iter   133/  209] train: loss: 0.2515558
[Epoch 14; Iter   163/  209] train: loss: 0.1291736
[Epoch 14; Iter   193/  209] train: loss: 0.2564110
[Epoch 14] ogbg-moltox21: 0.711308 val loss: 0.869679
[Epoch 14] ogbg-moltox21: 0.693222 test loss: 1.104964
[Epoch 15; Iter    14/  209] train: loss: 0.2232642
[Epoch 15; Iter    44/  209] train: loss: 0.2013425
[Epoch 15; Iter    74/  209] train: loss: 0.1700444
[Epoch 15; Iter   104/  209] train: loss: 0.2524438
[Epoch 15; Iter   134/  209] train: loss: 0.1603096
[Epoch 15; Iter   164/  209] train: loss: 0.1431085
[Epoch 15; Iter   194/  209] train: loss: 0.1725857
[Epoch 15] ogbg-moltox21: 0.741988 val loss: 0.412831
[Epoch 15] ogbg-moltox21: 0.714725 test loss: 0.693257
[Epoch 16; Iter    15/  209] train: loss: 0.1856130
[Epoch 16; Iter    45/  209] train: loss: 0.2333440
[Epoch 16; Iter    75/  209] train: loss: 0.2307028
[Epoch 16; Iter   105/  209] train: loss: 0.2336263
[Epoch 16; Iter   135/  209] train: loss: 0.1852847
[Epoch 16; Iter   165/  209] train: loss: 0.1434459
[Epoch 16; Iter   195/  209] train: loss: 0.1727966
[Epoch 16] ogbg-moltox21: 0.742963 val loss: 0.494421
[Epoch 16] ogbg-moltox21: 0.696971 test loss: 0.654900
[Epoch 17; Iter    16/  209] train: loss: 0.1845874
[Epoch 17; Iter    46/  209] train: loss: 0.2085303
[Epoch 17; Iter    76/  209] train: loss: 0.1825870
[Epoch 17; Iter   106/  209] train: loss: 0.2460700
[Epoch 17; Iter   136/  209] train: loss: 0.0919615
[Epoch 17; Iter   166/  209] train: loss: 0.1650087
[Epoch 17; Iter   196/  209] train: loss: 0.2159524
[Epoch 17] ogbg-moltox21: 0.746618 val loss: 0.416137
[Epoch 17] ogbg-moltox21: 0.694820 test loss: 0.506637
[Epoch 18; Iter    17/  209] train: loss: 0.1671936
[Epoch 18; Iter    47/  209] train: loss: 0.1646741
[Epoch 18; Iter    77/  209] train: loss: 0.2194215
[Epoch 18; Iter   107/  209] train: loss: 0.2826891
[Epoch 18; Iter   137/  209] train: loss: 0.1505495
[Epoch 18; Iter   167/  209] train: loss: 0.1658858
[Epoch 18; Iter   197/  209] train: loss: 0.1532489
[Epoch 18] ogbg-moltox21: 0.736143 val loss: 0.444014
[Epoch 18] ogbg-moltox21: 0.700006 test loss: 0.438379
[Epoch 19; Iter    18/  209] train: loss: 0.1704952
[Epoch 19; Iter    48/  209] train: loss: 0.1217545
[Epoch 19; Iter    78/  209] train: loss: 0.2321393
[Epoch 19; Iter   108/  209] train: loss: 0.1785512
[Epoch 19; Iter   138/  209] train: loss: 0.1949076
[Epoch 19; Iter   168/  209] train: loss: 0.2028680
[Epoch 19; Iter   198/  209] train: loss: 0.1530813
[Epoch 19] ogbg-moltox21: 0.743696 val loss: 0.319846
[Epoch 19] ogbg-moltox21: 0.712979 test loss: 0.326928
[Epoch 20; Iter    19/  209] train: loss: 0.2109295
[Epoch 20; Iter    49/  209] train: loss: 0.1464546
[Epoch 20; Iter    79/  209] train: loss: 0.1510707
[Epoch 20; Iter   109/  209] train: loss: 0.1540521
[Epoch 20; Iter   139/  209] train: loss: 0.1809850
[Epoch 20; Iter   169/  209] train: loss: 0.2455131
[Epoch 20; Iter   199/  209] train: loss: 0.1998426
[Epoch 20] ogbg-moltox21: 0.736655 val loss: 0.397957
[Epoch 20] ogbg-moltox21: 0.708311 test loss: 0.437565
[Epoch 21; Iter    20/  209] train: loss: 0.1748749
[Epoch 21; Iter    50/  209] train: loss: 0.1945253
[Epoch 21; Iter    80/  209] train: loss: 0.1696661
[Epoch 21; Iter   110/  209] train: loss: 0.3169652
[Epoch 21; Iter   140/  209] train: loss: 0.1739623
[Epoch 21; Iter   170/  209] train: loss: 0.1997465
[Epoch 21; Iter   200/  209] train: loss: 0.1696277
[Epoch 21] ogbg-moltox21: 0.747242 val loss: 0.355530
[Epoch 21] ogbg-moltox21: 0.716421 test loss: 0.545610
[Epoch 22; Iter    21/  209] train: loss: 0.1124264
[Epoch 22; Iter    51/  209] train: loss: 0.2175324
[Epoch 22; Iter    81/  209] train: loss: 0.1695575
[Epoch 22; Iter   111/  209] train: loss: 0.2404181
[Epoch 22; Iter   141/  209] train: loss: 0.1377252
[Epoch 22; Iter   171/  209] train: loss: 0.2083056
[Epoch 22; Iter   201/  209] train: loss: 0.1789504
[Epoch 22] ogbg-moltox21: 0.727443 val loss: 4.099356
[Epoch 22] ogbg-moltox21: 0.699343 test loss: 8.827688
[Epoch 23; Iter    22/  209] train: loss: 0.1339046
[Epoch 23; Iter    52/  209] train: loss: 0.1327722
[Epoch 23; Iter    82/  209] train: loss: 0.1750332
[Epoch 23; Iter   112/  209] train: loss: 0.1984655
[Epoch 23; Iter   142/  209] train: loss: 0.1720137
[Epoch 23; Iter   172/  209] train: loss: 0.1828825
[Epoch 23; Iter   202/  209] train: loss: 0.1405672
[Epoch 23] ogbg-moltox21: 0.766561 val loss: 0.295531
[Epoch 23] ogbg-moltox21: 0.721853 test loss: 0.320536
[Epoch 24; Iter    23/  209] train: loss: 0.1379994
[Epoch 24; Iter    53/  209] train: loss: 0.1721203
[Epoch 24; Iter    83/  209] train: loss: 0.1824604
[Epoch 24; Iter   113/  209] train: loss: 0.1363309
[Epoch 24; Iter   143/  209] train: loss: 0.1540760
[Epoch 24; Iter   173/  209] train: loss: 0.1562702
[Epoch 24; Iter   203/  209] train: loss: 0.1798654
[Epoch 24] ogbg-moltox21: 0.750482 val loss: 0.308240
[Epoch 24] ogbg-moltox21: 0.700984 test loss: 0.334145
[Epoch 25; Iter    24/  209] train: loss: 0.1192576
[Epoch 25; Iter    54/  209] train: loss: 0.1164957
[Epoch 25; Iter    84/  209] train: loss: 0.1193018
[Epoch 25; Iter   114/  209] train: loss: 0.1650171
[Epoch 25; Iter   144/  209] train: loss: 0.2303312
[Epoch 25; Iter   174/  209] train: loss: 0.1415339
[Epoch 25; Iter   204/  209] train: loss: 0.1136099
[Epoch 25] ogbg-moltox21: 0.751858 val loss: 0.313541
[Epoch 25] ogbg-moltox21: 0.710671 test loss: 0.325633
[Epoch 26; Iter    25/  209] train: loss: 0.1231551
[Epoch 26; Iter    55/  209] train: loss: 0.2094020
[Epoch 26; Iter    85/  209] train: loss: 0.2206946
[Epoch 26; Iter   115/  209] train: loss: 0.1694267
[Epoch 26; Iter   145/  209] train: loss: 0.1393550
[Epoch 26; Iter   175/  209] train: loss: 0.1341809
[Epoch 26; Iter   205/  209] train: loss: 0.1210992
[Epoch 26] ogbg-moltox21: 0.758424 val loss: 0.285643
[Epoch 26] ogbg-moltox21: 0.723467 test loss: 0.301798
[Epoch 27; Iter    26/  209] train: loss: 0.1689056
[Epoch 27; Iter    56/  209] train: loss: 0.0818291
[Epoch 27; Iter    86/  209] train: loss: 0.1672264
[Epoch 27; Iter   116/  209] train: loss: 0.1570284
[Epoch 27; Iter   146/  209] train: loss: 0.1556700
[Epoch 27; Iter   176/  209] train: loss: 0.2405404
[Epoch 27; Iter   206/  209] train: loss: 0.1303698
[Epoch 27] ogbg-moltox21: 0.745362 val loss: 0.327389
[Epoch 27] ogbg-moltox21: 0.702699 test loss: 0.371513
[Epoch 28; Iter    27/  209] train: loss: 0.0896310
[Epoch 28; Iter    57/  209] train: loss: 0.2428414
[Epoch 28; Iter    87/  209] train: loss: 0.1733221
[Epoch 28; Iter   117/  209] train: loss: 0.1147078
[Epoch 28; Iter   147/  209] train: loss: 0.2072555
[Epoch 28; Iter   177/  209] train: loss: 0.1986733
[Epoch 28; Iter   207/  209] train: loss: 0.1274999
[Epoch 28] ogbg-moltox21: 0.766442 val loss: 0.308307
[Epoch 28] ogbg-moltox21: 0.710221 test loss: 0.334676
[Epoch 29; Iter    28/  209] train: loss: 0.1227416
[Epoch 29; Iter    58/  209] train: loss: 0.1190249
[Epoch 29; Iter    88/  209] train: loss: 0.1250375
[Epoch 29; Iter   118/  209] train: loss: 0.1804986
[Epoch 29; Iter   148/  209] train: loss: 0.1143914
[Epoch 29; Iter   178/  209] train: loss: 0.0901586
[Epoch 29; Iter   208/  209] train: loss: 0.1385951
[Epoch 29] ogbg-moltox21: 0.754947 val loss: 0.319205
[Epoch 29] ogbg-moltox21: 0.718866 test loss: 0.333228
[Epoch 30; Iter    29/  209] train: loss: 0.1433587
[Epoch 30; Iter    59/  209] train: loss: 0.1093387
[Epoch 13; Iter    12/  209] train: loss: 0.2124941
[Epoch 13; Iter    42/  209] train: loss: 0.2032512
[Epoch 13; Iter    72/  209] train: loss: 0.2201566
[Epoch 13; Iter   102/  209] train: loss: 0.1695312
[Epoch 13; Iter   132/  209] train: loss: 0.1354659
[Epoch 13; Iter   162/  209] train: loss: 0.1985505
[Epoch 13; Iter   192/  209] train: loss: 0.1848035
[Epoch 13] ogbg-moltox21: 0.776385 val loss: 0.300946
[Epoch 13] ogbg-moltox21: 0.712848 test loss: 0.304763
[Epoch 14; Iter    13/  209] train: loss: 0.1801577
[Epoch 14; Iter    43/  209] train: loss: 0.1823854
[Epoch 14; Iter    73/  209] train: loss: 0.2197323
[Epoch 14; Iter   103/  209] train: loss: 0.1647605
[Epoch 14; Iter   133/  209] train: loss: 0.2152443
[Epoch 14; Iter   163/  209] train: loss: 0.1685762
[Epoch 14; Iter   193/  209] train: loss: 0.2475535
[Epoch 14] ogbg-moltox21: 0.781989 val loss: 0.258829
[Epoch 14] ogbg-moltox21: 0.735960 test loss: 0.279318
[Epoch 15; Iter    14/  209] train: loss: 0.2145008
[Epoch 15; Iter    44/  209] train: loss: 0.1726928
[Epoch 15; Iter    74/  209] train: loss: 0.1398020
[Epoch 15; Iter   104/  209] train: loss: 0.2283903
[Epoch 15; Iter   134/  209] train: loss: 0.1779999
[Epoch 15; Iter   164/  209] train: loss: 0.1354841
[Epoch 15; Iter   194/  209] train: loss: 0.1787256
[Epoch 15] ogbg-moltox21: 0.775911 val loss: 0.273232
[Epoch 15] ogbg-moltox21: 0.726246 test loss: 0.295170
[Epoch 16; Iter    15/  209] train: loss: 0.1414902
[Epoch 16; Iter    45/  209] train: loss: 0.2050663
[Epoch 16; Iter    75/  209] train: loss: 0.2186190
[Epoch 16; Iter   105/  209] train: loss: 0.2468792
[Epoch 16; Iter   135/  209] train: loss: 0.1856182
[Epoch 16; Iter   165/  209] train: loss: 0.1225044
[Epoch 16; Iter   195/  209] train: loss: 0.1540132
[Epoch 16] ogbg-moltox21: 0.702732 val loss: 0.547388
[Epoch 16] ogbg-moltox21: 0.646467 test loss: 0.595012
[Epoch 17; Iter    16/  209] train: loss: 0.2058726
[Epoch 17; Iter    46/  209] train: loss: 0.2782422
[Epoch 17; Iter    76/  209] train: loss: 0.1713716
[Epoch 17; Iter   106/  209] train: loss: 0.2302945
[Epoch 17; Iter   136/  209] train: loss: 0.0955434
[Epoch 17; Iter   166/  209] train: loss: 0.1753909
[Epoch 17; Iter   196/  209] train: loss: 0.2113056
[Epoch 17] ogbg-moltox21: 0.787242 val loss: 0.254818
[Epoch 17] ogbg-moltox21: 0.714783 test loss: 0.281328
[Epoch 18; Iter    17/  209] train: loss: 0.1835150
[Epoch 18; Iter    47/  209] train: loss: 0.1299756
[Epoch 18; Iter    77/  209] train: loss: 0.2133037
[Epoch 18; Iter   107/  209] train: loss: 0.2828603
[Epoch 18; Iter   137/  209] train: loss: 0.1224743
[Epoch 18; Iter   167/  209] train: loss: 0.1332506
[Epoch 18; Iter   197/  209] train: loss: 0.1270457
[Epoch 18] ogbg-moltox21: 0.783133 val loss: 0.250750
[Epoch 18] ogbg-moltox21: 0.710644 test loss: 0.272382
[Epoch 19; Iter    18/  209] train: loss: 0.1597707
[Epoch 19; Iter    48/  209] train: loss: 0.1274651
[Epoch 19; Iter    78/  209] train: loss: 0.1984486
[Epoch 19; Iter   108/  209] train: loss: 0.2011110
[Epoch 19; Iter   138/  209] train: loss: 0.2066234
[Epoch 19; Iter   168/  209] train: loss: 0.2028846
[Epoch 19; Iter   198/  209] train: loss: 0.1413933
[Epoch 19] ogbg-moltox21: 0.785883 val loss: 0.245212
[Epoch 19] ogbg-moltox21: 0.728059 test loss: 0.264925
[Epoch 20; Iter    19/  209] train: loss: 0.2427099
[Epoch 20; Iter    49/  209] train: loss: 0.1442236
[Epoch 20; Iter    79/  209] train: loss: 0.1466081
[Epoch 20; Iter   109/  209] train: loss: 0.1193611
[Epoch 20; Iter   139/  209] train: loss: 0.1768823
[Epoch 20; Iter   169/  209] train: loss: 0.1989746
[Epoch 20; Iter   199/  209] train: loss: 0.1797587
[Epoch 20] ogbg-moltox21: 0.789185 val loss: 0.246791
[Epoch 20] ogbg-moltox21: 0.732149 test loss: 0.267060
[Epoch 21; Iter    20/  209] train: loss: 0.1750567
[Epoch 21; Iter    50/  209] train: loss: 0.2131898
[Epoch 21; Iter    80/  209] train: loss: 0.1686680
[Epoch 21; Iter   110/  209] train: loss: 0.3204890
[Epoch 21; Iter   140/  209] train: loss: 0.1770877
[Epoch 21; Iter   170/  209] train: loss: 0.2111057
[Epoch 21; Iter   200/  209] train: loss: 0.1618318
[Epoch 21] ogbg-moltox21: 0.788725 val loss: 0.248389
[Epoch 21] ogbg-moltox21: 0.740440 test loss: 0.268058
[Epoch 22; Iter    21/  209] train: loss: 0.1048351
[Epoch 22; Iter    51/  209] train: loss: 0.1978688
[Epoch 22; Iter    81/  209] train: loss: 0.1512091
[Epoch 22; Iter   111/  209] train: loss: 0.2299613
[Epoch 22; Iter   141/  209] train: loss: 0.1344929
[Epoch 22; Iter   171/  209] train: loss: 0.1859725
[Epoch 22; Iter   201/  209] train: loss: 0.1836115
[Epoch 22] ogbg-moltox21: 0.803621 val loss: 0.242655
[Epoch 22] ogbg-moltox21: 0.733521 test loss: 0.269085
[Epoch 23; Iter    22/  209] train: loss: 0.1289339
[Epoch 23; Iter    52/  209] train: loss: 0.1313218
[Epoch 23; Iter    82/  209] train: loss: 0.1365864
[Epoch 23; Iter   112/  209] train: loss: 0.1717336
[Epoch 23; Iter   142/  209] train: loss: 0.1723115
[Epoch 23; Iter   172/  209] train: loss: 0.1692409
[Epoch 23; Iter   202/  209] train: loss: 0.1393210
[Epoch 23] ogbg-moltox21: 0.793276 val loss: 0.247322
[Epoch 23] ogbg-moltox21: 0.743447 test loss: 0.261675
[Epoch 24; Iter    23/  209] train: loss: 0.1429068
[Epoch 24; Iter    53/  209] train: loss: 0.2013603
[Epoch 24; Iter    83/  209] train: loss: 0.2119121
[Epoch 24; Iter   113/  209] train: loss: 0.1165531
[Epoch 24; Iter   143/  209] train: loss: 0.1599568
[Epoch 24; Iter   173/  209] train: loss: 0.1622986
[Epoch 24; Iter   203/  209] train: loss: 0.2064712
[Epoch 24] ogbg-moltox21: 0.775349 val loss: 0.257825
[Epoch 24] ogbg-moltox21: 0.736700 test loss: 0.288541
[Epoch 25; Iter    24/  209] train: loss: 0.1617498
[Epoch 25; Iter    54/  209] train: loss: 0.1315373
[Epoch 25; Iter    84/  209] train: loss: 0.1093886
[Epoch 25; Iter   114/  209] train: loss: 0.1720314
[Epoch 25; Iter   144/  209] train: loss: 0.2225095
[Epoch 25; Iter   174/  209] train: loss: 0.1500755
[Epoch 25; Iter   204/  209] train: loss: 0.1492472
[Epoch 25] ogbg-moltox21: 0.770665 val loss: 0.296518
[Epoch 25] ogbg-moltox21: 0.734559 test loss: 0.309805
[Epoch 26; Iter    25/  209] train: loss: 0.1428914
[Epoch 26; Iter    55/  209] train: loss: 0.2052346
[Epoch 26; Iter    85/  209] train: loss: 0.2392906
[Epoch 26; Iter   115/  209] train: loss: 0.1880104
[Epoch 26; Iter   145/  209] train: loss: 0.1422995
[Epoch 26; Iter   175/  209] train: loss: 0.1630445
[Epoch 26; Iter   205/  209] train: loss: 0.1358940
[Epoch 26] ogbg-moltox21: 0.788058 val loss: 0.240778
[Epoch 26] ogbg-moltox21: 0.747993 test loss: 0.258518
[Epoch 27; Iter    26/  209] train: loss: 0.1925090
[Epoch 27; Iter    56/  209] train: loss: 0.0917547
[Epoch 27; Iter    86/  209] train: loss: 0.1809839
[Epoch 27; Iter   116/  209] train: loss: 0.1292967
[Epoch 27; Iter   146/  209] train: loss: 0.1726704
[Epoch 27; Iter   176/  209] train: loss: 0.2001472
[Epoch 27; Iter   206/  209] train: loss: 0.1544758
[Epoch 27] ogbg-moltox21: 0.802895 val loss: 0.265236
[Epoch 27] ogbg-moltox21: 0.749521 test loss: 0.287847
[Epoch 28; Iter    27/  209] train: loss: 0.1165190
[Epoch 28; Iter    57/  209] train: loss: 0.2441442
[Epoch 28; Iter    87/  209] train: loss: 0.1908395
[Epoch 28; Iter   117/  209] train: loss: 0.1401522
[Epoch 28; Iter   147/  209] train: loss: 0.1867532
[Epoch 28; Iter   177/  209] train: loss: 0.1973914
[Epoch 28; Iter   207/  209] train: loss: 0.1269789
[Epoch 28] ogbg-moltox21: 0.800009 val loss: 0.263547
[Epoch 28] ogbg-moltox21: 0.741556 test loss: 0.277882
[Epoch 29; Iter    28/  209] train: loss: 0.1198539
[Epoch 29; Iter    58/  209] train: loss: 0.1390663
[Epoch 29; Iter    88/  209] train: loss: 0.1291973
[Epoch 29; Iter   118/  209] train: loss: 0.2079228
[Epoch 29; Iter   148/  209] train: loss: 0.1273738
[Epoch 29; Iter   178/  209] train: loss: 0.1041414
[Epoch 29; Iter   208/  209] train: loss: 0.1276153
[Epoch 29] ogbg-moltox21: 0.790989 val loss: 0.300820
[Epoch 29] ogbg-moltox21: 0.740868 test loss: 0.316833
[Epoch 30; Iter    29/  209] train: loss: 0.1571800
[Epoch 30; Iter    59/  209] train: loss: 0.1307319
[Epoch 13; Iter    12/  209] train: loss: 0.1622983
[Epoch 13; Iter    42/  209] train: loss: 0.1648276
[Epoch 13; Iter    72/  209] train: loss: 0.1682443
[Epoch 13; Iter   102/  209] train: loss: 0.2007984
[Epoch 13; Iter   132/  209] train: loss: 0.1656102
[Epoch 13; Iter   162/  209] train: loss: 0.2557010
[Epoch 13; Iter   192/  209] train: loss: 0.1998644
[Epoch 13] ogbg-moltox21: 0.779999 val loss: 0.293391
[Epoch 13] ogbg-moltox21: 0.728225 test loss: 0.266540
[Epoch 14; Iter    13/  209] train: loss: 0.1111431
[Epoch 14; Iter    43/  209] train: loss: 0.1644047
[Epoch 14; Iter    73/  209] train: loss: 0.1596328
[Epoch 14; Iter   103/  209] train: loss: 0.2642346
[Epoch 14; Iter   133/  209] train: loss: 0.1998206
[Epoch 14; Iter   163/  209] train: loss: 0.2257109
[Epoch 14; Iter   193/  209] train: loss: 0.2157197
[Epoch 14] ogbg-moltox21: 0.766883 val loss: 0.263388
[Epoch 14] ogbg-moltox21: 0.722399 test loss: 0.272271
[Epoch 15; Iter    14/  209] train: loss: 0.1174744
[Epoch 15; Iter    44/  209] train: loss: 0.1396252
[Epoch 15; Iter    74/  209] train: loss: 0.2016697
[Epoch 15; Iter   104/  209] train: loss: 0.1500491
[Epoch 15; Iter   134/  209] train: loss: 0.1381647
[Epoch 15; Iter   164/  209] train: loss: 0.1412951
[Epoch 15; Iter   194/  209] train: loss: 0.1614808
[Epoch 15] ogbg-moltox21: 0.788025 val loss: 0.252123
[Epoch 15] ogbg-moltox21: 0.742591 test loss: 0.264551
[Epoch 16; Iter    15/  209] train: loss: 0.1413804
[Epoch 16; Iter    45/  209] train: loss: 0.1939676
[Epoch 16; Iter    75/  209] train: loss: 0.2960038
[Epoch 16; Iter   105/  209] train: loss: 0.2594443
[Epoch 16; Iter   135/  209] train: loss: 0.2536795
[Epoch 16; Iter   165/  209] train: loss: 0.2975694
[Epoch 16; Iter   195/  209] train: loss: 0.1925218
[Epoch 16] ogbg-moltox21: 0.782255 val loss: 0.248736
[Epoch 16] ogbg-moltox21: 0.729689 test loss: 0.260825
[Epoch 17; Iter    16/  209] train: loss: 0.1856985
[Epoch 17; Iter    46/  209] train: loss: 0.2318552
[Epoch 17; Iter    76/  209] train: loss: 0.2275069
[Epoch 17; Iter   106/  209] train: loss: 0.1769681
[Epoch 17; Iter   136/  209] train: loss: 0.3313431
[Epoch 17; Iter   166/  209] train: loss: 0.2248583
[Epoch 17; Iter   196/  209] train: loss: 0.1798210
[Epoch 17] ogbg-moltox21: 0.758377 val loss: 0.256527
[Epoch 17] ogbg-moltox21: 0.702363 test loss: 0.273281
[Epoch 18; Iter    17/  209] train: loss: 0.1450660
[Epoch 18; Iter    47/  209] train: loss: 0.1319758
[Epoch 18; Iter    77/  209] train: loss: 0.2242170
[Epoch 18; Iter   107/  209] train: loss: 0.1511947
[Epoch 18; Iter   137/  209] train: loss: 0.1210005
[Epoch 18; Iter   167/  209] train: loss: 0.1491300
[Epoch 18; Iter   197/  209] train: loss: 0.1865116
[Epoch 18] ogbg-moltox21: 0.770144 val loss: 0.261721
[Epoch 18] ogbg-moltox21: 0.742383 test loss: 0.267501
[Epoch 19; Iter    18/  209] train: loss: 0.1442399
[Epoch 19; Iter    48/  209] train: loss: 0.1139817
[Epoch 19; Iter    78/  209] train: loss: 0.2596974
[Epoch 19; Iter   108/  209] train: loss: 0.1572493
[Epoch 19; Iter   138/  209] train: loss: 0.1880471
[Epoch 19; Iter   168/  209] train: loss: 0.1848975
[Epoch 19; Iter   198/  209] train: loss: 0.2429120
[Epoch 19] ogbg-moltox21: 0.784983 val loss: 0.252566
[Epoch 19] ogbg-moltox21: 0.748295 test loss: 0.270713
[Epoch 20; Iter    19/  209] train: loss: 0.1920281
[Epoch 20; Iter    49/  209] train: loss: 0.1393978
[Epoch 20; Iter    79/  209] train: loss: 0.1698354
[Epoch 20; Iter   109/  209] train: loss: 0.1715406
[Epoch 20; Iter   139/  209] train: loss: 0.1469318
[Epoch 20; Iter   169/  209] train: loss: 0.1982461
[Epoch 20; Iter   199/  209] train: loss: 0.2426530
[Epoch 20] ogbg-moltox21: 0.806506 val loss: 0.250057
[Epoch 20] ogbg-moltox21: 0.741834 test loss: 0.269657
[Epoch 21; Iter    20/  209] train: loss: 0.1658893
[Epoch 21; Iter    50/  209] train: loss: 0.2044123
[Epoch 21; Iter    80/  209] train: loss: 0.1481004
[Epoch 21; Iter   110/  209] train: loss: 0.1854311
[Epoch 21; Iter   140/  209] train: loss: 0.1062775
[Epoch 21; Iter   170/  209] train: loss: 0.1404371
[Epoch 21; Iter   200/  209] train: loss: 0.1179708
[Epoch 21] ogbg-moltox21: 0.795907 val loss: 0.253462
[Epoch 21] ogbg-moltox21: 0.757315 test loss: 0.265914
[Epoch 22; Iter    21/  209] train: loss: 0.2055972
[Epoch 22; Iter    51/  209] train: loss: 0.1798846
[Epoch 22; Iter    81/  209] train: loss: 0.0997849
[Epoch 22; Iter   111/  209] train: loss: 0.1491325
[Epoch 22; Iter   141/  209] train: loss: 0.1347250
[Epoch 22; Iter   171/  209] train: loss: 0.2274567
[Epoch 22; Iter   201/  209] train: loss: 0.2129643
[Epoch 22] ogbg-moltox21: 0.787300 val loss: 0.259967
[Epoch 22] ogbg-moltox21: 0.739077 test loss: 0.276356
[Epoch 23; Iter    22/  209] train: loss: 0.1287715
[Epoch 23; Iter    52/  209] train: loss: 0.1909658
[Epoch 23; Iter    82/  209] train: loss: 0.1535776
[Epoch 23; Iter   112/  209] train: loss: 0.1487743
[Epoch 23; Iter   142/  209] train: loss: 0.1652012
[Epoch 23; Iter   172/  209] train: loss: 0.1900658
[Epoch 23; Iter   202/  209] train: loss: 0.1940032
[Epoch 23] ogbg-moltox21: 0.791840 val loss: 0.253042
[Epoch 23] ogbg-moltox21: 0.751282 test loss: 0.264198
[Epoch 24; Iter    23/  209] train: loss: 0.1983234
[Epoch 24; Iter    53/  209] train: loss: 0.2094938
[Epoch 24; Iter    83/  209] train: loss: 0.2221638
[Epoch 24; Iter   113/  209] train: loss: 0.1249840
[Epoch 24; Iter   143/  209] train: loss: 0.1498859
[Epoch 24; Iter   173/  209] train: loss: 0.1089647
[Epoch 24; Iter   203/  209] train: loss: 0.2016530
[Epoch 24] ogbg-moltox21: 0.772277 val loss: 0.271366
[Epoch 24] ogbg-moltox21: 0.731854 test loss: 0.286774
[Epoch 25; Iter    24/  209] train: loss: 0.1916971
[Epoch 25; Iter    54/  209] train: loss: 0.2179223
[Epoch 25; Iter    84/  209] train: loss: 0.1217584
[Epoch 25; Iter   114/  209] train: loss: 0.2106150
[Epoch 25; Iter   144/  209] train: loss: 0.1153094
[Epoch 25; Iter   174/  209] train: loss: 0.1965014
[Epoch 25; Iter   204/  209] train: loss: 0.0991352
[Epoch 25] ogbg-moltox21: 0.799360 val loss: 0.244753
[Epoch 25] ogbg-moltox21: 0.745685 test loss: 0.259434
[Epoch 26; Iter    25/  209] train: loss: 0.1126786
[Epoch 26; Iter    55/  209] train: loss: 0.1415238
[Epoch 26; Iter    85/  209] train: loss: 0.2008780
[Epoch 26; Iter   115/  209] train: loss: 0.1180523
[Epoch 26; Iter   145/  209] train: loss: 0.1433345
[Epoch 26; Iter   175/  209] train: loss: 0.1416907
[Epoch 26; Iter   205/  209] train: loss: 0.2653222
[Epoch 26] ogbg-moltox21: 0.783313 val loss: 0.261742
[Epoch 26] ogbg-moltox21: 0.736431 test loss: 0.269950
[Epoch 27; Iter    26/  209] train: loss: 0.1542247
[Epoch 27; Iter    56/  209] train: loss: 0.0904267
[Epoch 27; Iter    86/  209] train: loss: 0.1580571
[Epoch 27; Iter   116/  209] train: loss: 0.2070246
[Epoch 27; Iter   146/  209] train: loss: 0.1202319
[Epoch 27; Iter   176/  209] train: loss: 0.2318589
[Epoch 27; Iter   206/  209] train: loss: 0.1965995
[Epoch 27] ogbg-moltox21: 0.794165 val loss: 0.240084
[Epoch 27] ogbg-moltox21: 0.751818 test loss: 0.254570
[Epoch 28; Iter    27/  209] train: loss: 0.2170020
[Epoch 28; Iter    57/  209] train: loss: 0.0817956
[Epoch 28; Iter    87/  209] train: loss: 0.1633205
[Epoch 28; Iter   117/  209] train: loss: 0.2008232
[Epoch 28; Iter   147/  209] train: loss: 0.2335551
[Epoch 28; Iter   177/  209] train: loss: 0.1949121
[Epoch 28; Iter   207/  209] train: loss: 0.0984830
[Epoch 28] ogbg-moltox21: 0.793845 val loss: 0.244094
[Epoch 28] ogbg-moltox21: 0.756252 test loss: 0.259424
[Epoch 29; Iter    28/  209] train: loss: 0.1759720
[Epoch 29; Iter    58/  209] train: loss: 0.1288874
[Epoch 29; Iter    88/  209] train: loss: 0.1769748
[Epoch 29; Iter   118/  209] train: loss: 0.1138399
[Epoch 29; Iter   148/  209] train: loss: 0.2103940
[Epoch 29; Iter   178/  209] train: loss: 0.1563746
[Epoch 29; Iter   208/  209] train: loss: 0.2084673
[Epoch 29] ogbg-moltox21: 0.797581 val loss: 0.235381
[Epoch 29] ogbg-moltox21: 0.755795 test loss: 0.253547
[Epoch 30; Iter    29/  209] train: loss: 0.1270831
[Epoch 30; Iter    59/  209] train: loss: 0.1908381
[Epoch 13; Iter    12/  209] train: loss: 0.1781314
[Epoch 13; Iter    42/  209] train: loss: 0.1568458
[Epoch 13; Iter    72/  209] train: loss: 0.2725166
[Epoch 13; Iter   102/  209] train: loss: 0.1565006
[Epoch 13; Iter   132/  209] train: loss: 0.2724932
[Epoch 13; Iter   162/  209] train: loss: 0.2579219
[Epoch 13; Iter   192/  209] train: loss: 0.2103973
[Epoch 13] ogbg-moltox21: 0.712558 val loss: 0.280407
[Epoch 13] ogbg-moltox21: 0.694653 test loss: 0.283176
[Epoch 14; Iter    13/  209] train: loss: 0.2255031
[Epoch 14; Iter    43/  209] train: loss: 0.2135728
[Epoch 14; Iter    73/  209] train: loss: 0.1848388
[Epoch 14; Iter   103/  209] train: loss: 0.1915527
[Epoch 14; Iter   133/  209] train: loss: 0.2836677
[Epoch 14; Iter   163/  209] train: loss: 0.2068438
[Epoch 14; Iter   193/  209] train: loss: 0.2140688
[Epoch 14] ogbg-moltox21: 0.772646 val loss: 0.250047
[Epoch 14] ogbg-moltox21: 0.726323 test loss: 0.262708
[Epoch 15; Iter    14/  209] train: loss: 0.1617270
[Epoch 15; Iter    44/  209] train: loss: 0.2575290
[Epoch 15; Iter    74/  209] train: loss: 0.1698848
[Epoch 15; Iter   104/  209] train: loss: 0.2246681
[Epoch 15; Iter   134/  209] train: loss: 0.1605118
[Epoch 15; Iter   164/  209] train: loss: 0.1699156
[Epoch 15; Iter   194/  209] train: loss: 0.2418436
[Epoch 15] ogbg-moltox21: 0.777147 val loss: 0.253775
[Epoch 15] ogbg-moltox21: 0.728171 test loss: 0.269917
[Epoch 16; Iter    15/  209] train: loss: 0.2011107
[Epoch 16; Iter    45/  209] train: loss: 0.1578066
[Epoch 16; Iter    75/  209] train: loss: 0.2192963
[Epoch 16; Iter   105/  209] train: loss: 0.1751503
[Epoch 16; Iter   135/  209] train: loss: 0.1919432
[Epoch 16; Iter   165/  209] train: loss: 0.2271641
[Epoch 16; Iter   195/  209] train: loss: 0.2019295
[Epoch 16] ogbg-moltox21: 0.775025 val loss: 0.253139
[Epoch 16] ogbg-moltox21: 0.744427 test loss: 0.282687
[Epoch 17; Iter    16/  209] train: loss: 0.1684951
[Epoch 17; Iter    46/  209] train: loss: 0.1334866
[Epoch 17; Iter    76/  209] train: loss: 0.1354406
[Epoch 17; Iter   106/  209] train: loss: 0.2074128
[Epoch 17; Iter   136/  209] train: loss: 0.1501041
[Epoch 17; Iter   166/  209] train: loss: 0.1684007
[Epoch 17; Iter   196/  209] train: loss: 0.1348186
[Epoch 17] ogbg-moltox21: 0.788268 val loss: 0.315147
[Epoch 17] ogbg-moltox21: 0.739815 test loss: 0.266444
[Epoch 18; Iter    17/  209] train: loss: 0.1151810
[Epoch 18; Iter    47/  209] train: loss: 0.1980544
[Epoch 18; Iter    77/  209] train: loss: 0.2532641
[Epoch 18; Iter   107/  209] train: loss: 0.2744066
[Epoch 18; Iter   137/  209] train: loss: 0.1761190
[Epoch 18; Iter   167/  209] train: loss: 0.1592117
[Epoch 18; Iter   197/  209] train: loss: 0.1229423
[Epoch 18] ogbg-moltox21: 0.770470 val loss: 0.302130
[Epoch 18] ogbg-moltox21: 0.746197 test loss: 0.262546
[Epoch 19; Iter    18/  209] train: loss: 0.3043181
[Epoch 19; Iter    48/  209] train: loss: 0.1662158
[Epoch 19; Iter    78/  209] train: loss: 0.1444727
[Epoch 19; Iter   108/  209] train: loss: 0.1534289
[Epoch 19; Iter   138/  209] train: loss: 0.1189674
[Epoch 19; Iter   168/  209] train: loss: 0.1885221
[Epoch 19; Iter   198/  209] train: loss: 0.2785493
[Epoch 19] ogbg-moltox21: 0.790321 val loss: 0.246091
[Epoch 19] ogbg-moltox21: 0.752551 test loss: 0.261039
[Epoch 20; Iter    19/  209] train: loss: 0.2096740
[Epoch 20; Iter    49/  209] train: loss: 0.2506377
[Epoch 20; Iter    79/  209] train: loss: 0.0947395
[Epoch 20; Iter   109/  209] train: loss: 0.1265204
[Epoch 20; Iter   139/  209] train: loss: 0.2459880
[Epoch 20; Iter   169/  209] train: loss: 0.2301650
[Epoch 20; Iter   199/  209] train: loss: 0.1293201
[Epoch 20] ogbg-moltox21: 0.783261 val loss: 0.242862
[Epoch 20] ogbg-moltox21: 0.734103 test loss: 0.266898
[Epoch 21; Iter    20/  209] train: loss: 0.1520030
[Epoch 21; Iter    50/  209] train: loss: 0.2260173
[Epoch 21; Iter    80/  209] train: loss: 0.1754070
[Epoch 21; Iter   110/  209] train: loss: 0.0944986
[Epoch 21; Iter   140/  209] train: loss: 0.2490490
[Epoch 21; Iter   170/  209] train: loss: 0.3389242
[Epoch 21; Iter   200/  209] train: loss: 0.1732703
[Epoch 21] ogbg-moltox21: 0.762740 val loss: 0.253475
[Epoch 21] ogbg-moltox21: 0.733123 test loss: 0.275892
[Epoch 22; Iter    21/  209] train: loss: 0.1536474
[Epoch 22; Iter    51/  209] train: loss: 0.0847549
[Epoch 22; Iter    81/  209] train: loss: 0.1274685
[Epoch 22; Iter   111/  209] train: loss: 0.1239204
[Epoch 22; Iter   141/  209] train: loss: 0.1738831
[Epoch 22; Iter   171/  209] train: loss: 0.1070210
[Epoch 22; Iter   201/  209] train: loss: 0.1089680
[Epoch 22] ogbg-moltox21: 0.800989 val loss: 0.284319
[Epoch 22] ogbg-moltox21: 0.743770 test loss: 0.287542
[Epoch 23; Iter    22/  209] train: loss: 0.1940092
[Epoch 23; Iter    52/  209] train: loss: 0.1759520
[Epoch 23; Iter    82/  209] train: loss: 0.1422903
[Epoch 23; Iter   112/  209] train: loss: 0.1468157
[Epoch 23; Iter   142/  209] train: loss: 0.1590240
[Epoch 23; Iter   172/  209] train: loss: 0.1508810
[Epoch 23; Iter   202/  209] train: loss: 0.1413846
[Epoch 23] ogbg-moltox21: 0.797963 val loss: 0.237318
[Epoch 23] ogbg-moltox21: 0.755415 test loss: 0.258068
[Epoch 24; Iter    23/  209] train: loss: 0.2434499
[Epoch 24; Iter    53/  209] train: loss: 0.1191920
[Epoch 24; Iter    83/  209] train: loss: 0.2041170
[Epoch 24; Iter   113/  209] train: loss: 0.1334229
[Epoch 24; Iter   143/  209] train: loss: 0.0891013
[Epoch 24; Iter   173/  209] train: loss: 0.1248048
[Epoch 24; Iter   203/  209] train: loss: 0.1757288
[Epoch 24] ogbg-moltox21: 0.777312 val loss: 0.250855
[Epoch 24] ogbg-moltox21: 0.738547 test loss: 0.268887
[Epoch 25; Iter    24/  209] train: loss: 0.1354853
[Epoch 25; Iter    54/  209] train: loss: 0.2683455
[Epoch 25; Iter    84/  209] train: loss: 0.1454856
[Epoch 25; Iter   114/  209] train: loss: 0.1693705
[Epoch 25; Iter   144/  209] train: loss: 0.1597880
[Epoch 25; Iter   174/  209] train: loss: 0.1839339
[Epoch 25; Iter   204/  209] train: loss: 0.2463391
[Epoch 25] ogbg-moltox21: 0.801644 val loss: 0.240732
[Epoch 25] ogbg-moltox21: 0.758672 test loss: 0.327044
[Epoch 26; Iter    25/  209] train: loss: 0.1906810
[Epoch 26; Iter    55/  209] train: loss: 0.2600664
[Epoch 26; Iter    85/  209] train: loss: 0.1933201
[Epoch 26; Iter   115/  209] train: loss: 0.1044946
[Epoch 26; Iter   145/  209] train: loss: 0.1666370
[Epoch 26; Iter   175/  209] train: loss: 0.1058966
[Epoch 26; Iter   205/  209] train: loss: 0.2017062
[Epoch 26] ogbg-moltox21: 0.789617 val loss: 0.262226
[Epoch 26] ogbg-moltox21: 0.742963 test loss: 0.361714
[Epoch 27; Iter    26/  209] train: loss: 0.1352930
[Epoch 27; Iter    56/  209] train: loss: 0.2699141
[Epoch 27; Iter    86/  209] train: loss: 0.1857464
[Epoch 27; Iter   116/  209] train: loss: 0.1636292
[Epoch 27; Iter   146/  209] train: loss: 0.1656982
[Epoch 27; Iter   176/  209] train: loss: 0.1251913
[Epoch 27; Iter   206/  209] train: loss: 0.1826591
[Epoch 27] ogbg-moltox21: 0.789609 val loss: 0.275735
[Epoch 27] ogbg-moltox21: 0.752964 test loss: 0.279035
[Epoch 28; Iter    27/  209] train: loss: 0.1235764
[Epoch 28; Iter    57/  209] train: loss: 0.1383883
[Epoch 28; Iter    87/  209] train: loss: 0.1454117
[Epoch 28; Iter   117/  209] train: loss: 0.1523133
[Epoch 28; Iter   147/  209] train: loss: 0.1543234
[Epoch 28; Iter   177/  209] train: loss: 0.1506144
[Epoch 28; Iter   207/  209] train: loss: 0.1325373
[Epoch 28] ogbg-moltox21: 0.790257 val loss: 0.238196
[Epoch 28] ogbg-moltox21: 0.766265 test loss: 0.252996
[Epoch 29; Iter    28/  209] train: loss: 0.1437657
[Epoch 29; Iter    58/  209] train: loss: 0.1418872
[Epoch 29; Iter    88/  209] train: loss: 0.1710959
[Epoch 29; Iter   118/  209] train: loss: 0.2147026
[Epoch 29; Iter   148/  209] train: loss: 0.1947326
[Epoch 29; Iter   178/  209] train: loss: 0.1121670
[Epoch 29; Iter   208/  209] train: loss: 0.1131031
[Epoch 29] ogbg-moltox21: 0.791624 val loss: 0.245960
[Epoch 29] ogbg-moltox21: 0.752122 test loss: 0.259679
[Epoch 30; Iter    29/  209] train: loss: 0.1698518
[Epoch 30; Iter    59/  209] train: loss: 0.1237844
[Epoch 30; Iter    89/  209] train: loss: 0.1115248
[Epoch 30; Iter   119/  209] train: loss: 0.1548395
[Epoch 30; Iter   149/  209] train: loss: 0.1311480
[Epoch 30; Iter   179/  209] train: loss: 0.1782773
[Epoch 30; Iter   209/  209] train: loss: 0.0991086
[Epoch 30] ogbg-moltox21: 0.799963 val loss: 0.286519
[Epoch 30] ogbg-moltox21: 0.742598 test loss: 0.334389
[Epoch 31; Iter    30/  209] train: loss: 0.0900408
[Epoch 31; Iter    60/  209] train: loss: 0.1289302
[Epoch 31; Iter    90/  209] train: loss: 0.1299647
[Epoch 31; Iter   120/  209] train: loss: 0.1086648
[Epoch 31; Iter   150/  209] train: loss: 0.1269796
[Epoch 31; Iter   180/  209] train: loss: 0.2010186
[Epoch 31] ogbg-moltox21: 0.802425 val loss: 0.287110
[Epoch 31] ogbg-moltox21: 0.743492 test loss: 0.323791
[Epoch 32; Iter     1/  209] train: loss: 0.1558411
[Epoch 32; Iter    31/  209] train: loss: 0.1048438
[Epoch 32; Iter    61/  209] train: loss: 0.1644622
[Epoch 32; Iter    91/  209] train: loss: 0.1357209
[Epoch 32; Iter   121/  209] train: loss: 0.1856533
[Epoch 32; Iter   151/  209] train: loss: 0.1332551
[Epoch 32; Iter   181/  209] train: loss: 0.2143287
[Epoch 32] ogbg-moltox21: 0.797303 val loss: 0.310781
[Epoch 32] ogbg-moltox21: 0.736756 test loss: 0.446840
[Epoch 33; Iter     2/  209] train: loss: 0.1018094
[Epoch 33; Iter    32/  209] train: loss: 0.1120657
[Epoch 33; Iter    62/  209] train: loss: 0.1293217
[Epoch 33; Iter    92/  209] train: loss: 0.1494246
[Epoch 33; Iter   122/  209] train: loss: 0.1013998
[Epoch 33; Iter   152/  209] train: loss: 0.0946442
[Epoch 33; Iter   182/  209] train: loss: 0.1166371
[Epoch 33] ogbg-moltox21: 0.798813 val loss: 0.292972
[Epoch 33] ogbg-moltox21: 0.735190 test loss: 0.354869
[Epoch 34; Iter     3/  209] train: loss: 0.0837308
[Epoch 34; Iter    33/  209] train: loss: 0.1008519
[Epoch 34; Iter    63/  209] train: loss: 0.1325073
[Epoch 34; Iter    93/  209] train: loss: 0.1374668
[Epoch 34; Iter   123/  209] train: loss: 0.0960576
[Epoch 34; Iter   153/  209] train: loss: 0.1295767
[Epoch 34; Iter   183/  209] train: loss: 0.1079591
[Epoch 34] ogbg-moltox21: 0.796772 val loss: 0.310251
[Epoch 34] ogbg-moltox21: 0.738808 test loss: 0.630534
[Epoch 35; Iter     4/  209] train: loss: 0.1217341
[Epoch 35; Iter    34/  209] train: loss: 0.1295034
[Epoch 35; Iter    64/  209] train: loss: 0.1548609
[Epoch 35; Iter    94/  209] train: loss: 0.1149798
[Epoch 35; Iter   124/  209] train: loss: 0.1456757
[Epoch 35; Iter   154/  209] train: loss: 0.1072701
[Epoch 35; Iter   184/  209] train: loss: 0.1676074
[Epoch 35] ogbg-moltox21: 0.789907 val loss: 0.364483
[Epoch 35] ogbg-moltox21: 0.720501 test loss: 0.576684
[Epoch 36; Iter     5/  209] train: loss: 0.1232002
[Epoch 36; Iter    35/  209] train: loss: 0.1570638
[Epoch 36; Iter    65/  209] train: loss: 0.1183494
[Epoch 36; Iter    95/  209] train: loss: 0.1476084
[Epoch 36; Iter   125/  209] train: loss: 0.1300531
[Epoch 36; Iter   155/  209] train: loss: 0.0828480
[Epoch 36; Iter   185/  209] train: loss: 0.1450735
[Epoch 36] ogbg-moltox21: 0.794316 val loss: 0.323457
[Epoch 36] ogbg-moltox21: 0.724067 test loss: 0.435608
[Epoch 37; Iter     6/  209] train: loss: 0.1013858
[Epoch 37; Iter    36/  209] train: loss: 0.1216121
[Epoch 37; Iter    66/  209] train: loss: 0.1650338
[Epoch 37; Iter    96/  209] train: loss: 0.1101400
[Epoch 37; Iter   126/  209] train: loss: 0.1241054
[Epoch 37; Iter   156/  209] train: loss: 0.0855122
[Epoch 37; Iter   186/  209] train: loss: 0.1151216
[Epoch 37] ogbg-moltox21: 0.798661 val loss: 0.301565
[Epoch 37] ogbg-moltox21: 0.733114 test loss: 0.337456
[Epoch 38; Iter     7/  209] train: loss: 0.1529422
[Epoch 38; Iter    37/  209] train: loss: 0.1297027
[Epoch 38; Iter    67/  209] train: loss: 0.0929021
[Epoch 38; Iter    97/  209] train: loss: 0.0704673
[Epoch 38; Iter   127/  209] train: loss: 0.0886702
[Epoch 38; Iter   157/  209] train: loss: 0.0893820
[Epoch 38; Iter   187/  209] train: loss: 0.0897989
[Epoch 38] ogbg-moltox21: 0.801181 val loss: 0.343423
[Epoch 38] ogbg-moltox21: 0.734227 test loss: 0.476363
[Epoch 39; Iter     8/  209] train: loss: 0.1118398
[Epoch 39; Iter    38/  209] train: loss: 0.0843953
[Epoch 39; Iter    68/  209] train: loss: 0.0992150
[Epoch 39; Iter    98/  209] train: loss: 0.1092971
[Epoch 39; Iter   128/  209] train: loss: 0.1012003
[Epoch 39; Iter   158/  209] train: loss: 0.1169180
[Epoch 39; Iter   188/  209] train: loss: 0.0860648
[Epoch 39] ogbg-moltox21: 0.791377 val loss: 0.359465
[Epoch 39] ogbg-moltox21: 0.732861 test loss: 0.529250
[Epoch 40; Iter     9/  209] train: loss: 0.0815389
[Epoch 40; Iter    39/  209] train: loss: 0.0857630
[Epoch 40; Iter    69/  209] train: loss: 0.1038529
[Epoch 40; Iter    99/  209] train: loss: 0.1258451
[Epoch 40; Iter   129/  209] train: loss: 0.0886460
[Epoch 40; Iter   159/  209] train: loss: 0.1178102
[Epoch 40; Iter   189/  209] train: loss: 0.1526876
[Epoch 40] ogbg-moltox21: 0.792783 val loss: 0.329798
[Epoch 40] ogbg-moltox21: 0.733358 test loss: 0.412577
[Epoch 41; Iter    10/  209] train: loss: 0.0910241
[Epoch 41; Iter    40/  209] train: loss: 0.1233302
[Epoch 41; Iter    70/  209] train: loss: 0.0934146
[Epoch 41; Iter   100/  209] train: loss: 0.1463795
[Epoch 41; Iter   130/  209] train: loss: 0.1274952
[Epoch 41; Iter   160/  209] train: loss: 0.1153129
[Epoch 41; Iter   190/  209] train: loss: 0.0756973
[Epoch 41] ogbg-moltox21: 0.794171 val loss: 0.308178
[Epoch 41] ogbg-moltox21: 0.747593 test loss: 0.348779
[Epoch 42; Iter    11/  209] train: loss: 0.0977907
[Epoch 42; Iter    41/  209] train: loss: 0.0615020
[Epoch 42; Iter    71/  209] train: loss: 0.0846274
[Epoch 42; Iter   101/  209] train: loss: 0.1495532
[Epoch 42; Iter   131/  209] train: loss: 0.1272808
[Epoch 42; Iter   161/  209] train: loss: 0.0743670
[Epoch 42; Iter   191/  209] train: loss: 0.0600094
[Epoch 42] ogbg-moltox21: 0.799754 val loss: 0.305001
[Epoch 42] ogbg-moltox21: 0.737259 test loss: 0.367015
[Epoch 43; Iter    12/  209] train: loss: 0.1036513
[Epoch 43; Iter    42/  209] train: loss: 0.0878001
[Epoch 43; Iter    72/  209] train: loss: 0.1363296
[Epoch 43; Iter   102/  209] train: loss: 0.0863344
[Epoch 43; Iter   132/  209] train: loss: 0.1359208
[Epoch 43; Iter   162/  209] train: loss: 0.0803097
[Epoch 43; Iter   192/  209] train: loss: 0.0496070
[Epoch 43] ogbg-moltox21: 0.794398 val loss: 0.343211
[Epoch 43] ogbg-moltox21: 0.729119 test loss: 0.457325
[Epoch 44; Iter    13/  209] train: loss: 0.0495133
[Epoch 44; Iter    43/  209] train: loss: 0.0598675
[Epoch 44; Iter    73/  209] train: loss: 0.0515321
[Epoch 44; Iter   103/  209] train: loss: 0.1240108
[Epoch 44; Iter   133/  209] train: loss: 0.0819220
[Epoch 44; Iter   163/  209] train: loss: 0.0939096
[Epoch 44; Iter   193/  209] train: loss: 0.1122167
[Epoch 44] ogbg-moltox21: 0.791238 val loss: 0.389417
[Epoch 44] ogbg-moltox21: 0.738431 test loss: 0.555611
[Epoch 45; Iter    14/  209] train: loss: 0.0747988
[Epoch 45; Iter    44/  209] train: loss: 0.0951935
[Epoch 45; Iter    74/  209] train: loss: 0.0581826
[Epoch 45; Iter   104/  209] train: loss: 0.0857068
[Epoch 45; Iter   134/  209] train: loss: 0.1061422
[Epoch 45; Iter   164/  209] train: loss: 0.0897058
[Epoch 45; Iter   194/  209] train: loss: 0.1073568
[Epoch 45] ogbg-moltox21: 0.786998 val loss: 0.365192
[Epoch 45] ogbg-moltox21: 0.727050 test loss: 0.486322
[Epoch 46; Iter    15/  209] train: loss: 0.0707048
[Epoch 46; Iter    45/  209] train: loss: 0.1046833
[Epoch 46; Iter    75/  209] train: loss: 0.0806372
[Epoch 46; Iter   105/  209] train: loss: 0.0671658
[Epoch 46; Iter   135/  209] train: loss: 0.1150144
[Epoch 46; Iter   165/  209] train: loss: 0.0653599
[Epoch 46; Iter   195/  209] train: loss: 0.1232593
[Epoch 46] ogbg-moltox21: 0.782880 val loss: 0.447042
[Epoch 46] ogbg-moltox21: 0.733555 test loss: 0.622362
[Epoch 47; Iter    16/  209] train: loss: 0.0660225
[Epoch 47; Iter    46/  209] train: loss: 0.0594194
[Epoch 47; Iter    76/  209] train: loss: 0.0551109
[Epoch 47; Iter   106/  209] train: loss: 0.0506507
[Epoch 47; Iter   136/  209] train: loss: 0.0995466
[Epoch 30; Iter    89/  209] train: loss: 0.1125163
[Epoch 30; Iter   119/  209] train: loss: 0.0944513
[Epoch 30; Iter   149/  209] train: loss: 0.2099250
[Epoch 30; Iter   179/  209] train: loss: 0.0905370
[Epoch 30; Iter   209/  209] train: loss: 0.2279385
[Epoch 30] ogbg-moltox21: 0.776758 val loss: 0.303998
[Epoch 30] ogbg-moltox21: 0.732564 test loss: 0.337232
[Epoch 31; Iter    30/  209] train: loss: 0.1158998
[Epoch 31; Iter    60/  209] train: loss: 0.1300562
[Epoch 31; Iter    90/  209] train: loss: 0.1700205
[Epoch 31; Iter   120/  209] train: loss: 0.0849368
[Epoch 31; Iter   150/  209] train: loss: 0.1360308
[Epoch 31; Iter   180/  209] train: loss: 0.1465276
[Epoch 31] ogbg-moltox21: 0.776535 val loss: 0.323074
[Epoch 31] ogbg-moltox21: 0.736994 test loss: 0.342223
[Epoch 32; Iter     1/  209] train: loss: 0.1731922
[Epoch 32; Iter    31/  209] train: loss: 0.0985901
[Epoch 32; Iter    61/  209] train: loss: 0.0549561
[Epoch 32; Iter    91/  209] train: loss: 0.1097429
[Epoch 32; Iter   121/  209] train: loss: 0.1335617
[Epoch 32; Iter   151/  209] train: loss: 0.1738299
[Epoch 32; Iter   181/  209] train: loss: 0.1742266
[Epoch 32] ogbg-moltox21: 0.764582 val loss: 0.370080
[Epoch 32] ogbg-moltox21: 0.733825 test loss: 0.437233
[Epoch 33; Iter     2/  209] train: loss: 0.0673037
[Epoch 33; Iter    32/  209] train: loss: 0.0763081
[Epoch 33; Iter    62/  209] train: loss: 0.1026535
[Epoch 33; Iter    92/  209] train: loss: 0.0814474
[Epoch 33; Iter   122/  209] train: loss: 0.1170071
[Epoch 33; Iter   152/  209] train: loss: 0.2027159
[Epoch 33; Iter   182/  209] train: loss: 0.1764256
[Epoch 33] ogbg-moltox21: 0.753050 val loss: 0.358749
[Epoch 33] ogbg-moltox21: 0.718229 test loss: 0.367354
[Epoch 34; Iter     3/  209] train: loss: 0.0746550
[Epoch 34; Iter    33/  209] train: loss: 0.0943071
[Epoch 34; Iter    63/  209] train: loss: 0.1010608
[Epoch 34; Iter    93/  209] train: loss: 0.0905413
[Epoch 34; Iter   123/  209] train: loss: 0.1061312
[Epoch 34; Iter   153/  209] train: loss: 0.0921049
[Epoch 34; Iter   183/  209] train: loss: 0.1028202
[Epoch 34] ogbg-moltox21: 0.785045 val loss: 0.343653
[Epoch 34] ogbg-moltox21: 0.718647 test loss: 0.384760
[Epoch 35; Iter     4/  209] train: loss: 0.0972489
[Epoch 35; Iter    34/  209] train: loss: 0.0836039
[Epoch 35; Iter    64/  209] train: loss: 0.1077563
[Epoch 35; Iter    94/  209] train: loss: 0.1087571
[Epoch 35; Iter   124/  209] train: loss: 0.1144857
[Epoch 35; Iter   154/  209] train: loss: 0.1100953
[Epoch 35; Iter   184/  209] train: loss: 0.0998708
[Epoch 35] ogbg-moltox21: 0.773521 val loss: 0.331795
[Epoch 35] ogbg-moltox21: 0.722504 test loss: 0.369532
[Epoch 36; Iter     5/  209] train: loss: 0.0948610
[Epoch 36; Iter    35/  209] train: loss: 0.0660008
[Epoch 36; Iter    65/  209] train: loss: 0.1138480
[Epoch 36; Iter    95/  209] train: loss: 0.0613042
[Epoch 36; Iter   125/  209] train: loss: 0.1322205
[Epoch 36; Iter   155/  209] train: loss: 0.0961803
[Epoch 36; Iter   185/  209] train: loss: 0.0958589
[Epoch 36] ogbg-moltox21: 0.780442 val loss: 0.298856
[Epoch 36] ogbg-moltox21: 0.717032 test loss: 0.337400
[Epoch 37; Iter     6/  209] train: loss: 0.0442655
[Epoch 37; Iter    36/  209] train: loss: 0.0900704
[Epoch 37; Iter    66/  209] train: loss: 0.0856068
[Epoch 37; Iter    96/  209] train: loss: 0.0806517
[Epoch 37; Iter   126/  209] train: loss: 0.0578985
[Epoch 37; Iter   156/  209] train: loss: 0.0403458
[Epoch 37; Iter   186/  209] train: loss: 0.1034536
[Epoch 37] ogbg-moltox21: 0.767374 val loss: 0.330270
[Epoch 37] ogbg-moltox21: 0.716491 test loss: 0.371463
[Epoch 38; Iter     7/  209] train: loss: 0.0776204
[Epoch 38; Iter    37/  209] train: loss: 0.0952844
[Epoch 38; Iter    67/  209] train: loss: 0.0663105
[Epoch 38; Iter    97/  209] train: loss: 0.0871277
[Epoch 38; Iter   127/  209] train: loss: 0.0771438
[Epoch 38; Iter   157/  209] train: loss: 0.0839912
[Epoch 38; Iter   187/  209] train: loss: 0.0734341
[Epoch 38] ogbg-moltox21: 0.773570 val loss: 0.333223
[Epoch 38] ogbg-moltox21: 0.711551 test loss: 0.380523
[Epoch 39; Iter     8/  209] train: loss: 0.0547189
[Epoch 39; Iter    38/  209] train: loss: 0.0672361
[Epoch 39; Iter    68/  209] train: loss: 0.0549318
[Epoch 39; Iter    98/  209] train: loss: 0.0730754
[Epoch 39; Iter   128/  209] train: loss: 0.0537582
[Epoch 39; Iter   158/  209] train: loss: 0.0518020
[Epoch 39; Iter   188/  209] train: loss: 0.0539601
[Epoch 39] ogbg-moltox21: 0.764848 val loss: 0.361780
[Epoch 39] ogbg-moltox21: 0.711270 test loss: 0.401988
[Epoch 40; Iter     9/  209] train: loss: 0.0595729
[Epoch 40; Iter    39/  209] train: loss: 0.2369575
[Epoch 40; Iter    69/  209] train: loss: 0.0854944
[Epoch 40; Iter    99/  209] train: loss: 0.0645315
[Epoch 40; Iter   129/  209] train: loss: 0.0531789
[Epoch 40; Iter   159/  209] train: loss: 0.0614099
[Epoch 40; Iter   189/  209] train: loss: 0.0551742
[Epoch 40] ogbg-moltox21: 0.766726 val loss: 0.381848
[Epoch 40] ogbg-moltox21: 0.710897 test loss: 0.436764
[Epoch 41; Iter    10/  209] train: loss: 0.0331576
[Epoch 41; Iter    40/  209] train: loss: 0.0463423
[Epoch 41; Iter    70/  209] train: loss: 0.0563875
[Epoch 41; Iter   100/  209] train: loss: 0.0517930
[Epoch 41; Iter   130/  209] train: loss: 0.0932750
[Epoch 41; Iter   160/  209] train: loss: 0.0900203
[Epoch 41; Iter   190/  209] train: loss: 0.0512126
[Epoch 41] ogbg-moltox21: 0.762141 val loss: 0.357070
[Epoch 41] ogbg-moltox21: 0.703602 test loss: 0.404694
[Epoch 42; Iter    11/  209] train: loss: 0.0597884
[Epoch 42; Iter    41/  209] train: loss: 0.0765342
[Epoch 42; Iter    71/  209] train: loss: 0.0449265
[Epoch 42; Iter   101/  209] train: loss: 0.0420620
[Epoch 42; Iter   131/  209] train: loss: 0.0743326
[Epoch 42; Iter   161/  209] train: loss: 0.0395051
[Epoch 42; Iter   191/  209] train: loss: 0.0605539
[Epoch 42] ogbg-moltox21: 0.773195 val loss: 0.374074
[Epoch 42] ogbg-moltox21: 0.710847 test loss: 0.430299
[Epoch 43; Iter    12/  209] train: loss: 0.0529035
[Epoch 43; Iter    42/  209] train: loss: 0.0519218
[Epoch 43; Iter    72/  209] train: loss: 0.0670841
[Epoch 43; Iter   102/  209] train: loss: 0.1111386
[Epoch 43; Iter   132/  209] train: loss: 0.0747828
[Epoch 43; Iter   162/  209] train: loss: 0.0707342
[Epoch 43; Iter   192/  209] train: loss: 0.0609261
[Epoch 43] ogbg-moltox21: 0.764895 val loss: 0.414214
[Epoch 43] ogbg-moltox21: 0.704457 test loss: 0.472754
[Epoch 44; Iter    13/  209] train: loss: 0.0783445
[Epoch 44; Iter    43/  209] train: loss: 0.0575218
[Epoch 44; Iter    73/  209] train: loss: 0.0519583
[Epoch 44; Iter   103/  209] train: loss: 0.0626289
[Epoch 44; Iter   133/  209] train: loss: 0.0563674
[Epoch 44; Iter   163/  209] train: loss: 0.0486978
[Epoch 44; Iter   193/  209] train: loss: 0.0345990
[Epoch 44] ogbg-moltox21: 0.761672 val loss: 0.387785
[Epoch 44] ogbg-moltox21: 0.693767 test loss: 0.445616
[Epoch 45; Iter    14/  209] train: loss: 0.0671879
[Epoch 45; Iter    44/  209] train: loss: 0.0724294
[Epoch 45; Iter    74/  209] train: loss: 0.0610304
[Epoch 45; Iter   104/  209] train: loss: 0.0366060
[Epoch 45; Iter   134/  209] train: loss: 0.0901957
[Epoch 45; Iter   164/  209] train: loss: 0.0583834
[Epoch 45; Iter   194/  209] train: loss: 0.0398806
[Epoch 45] ogbg-moltox21: 0.762129 val loss: 0.390060
[Epoch 45] ogbg-moltox21: 0.701642 test loss: 0.443887
[Epoch 46; Iter    15/  209] train: loss: 0.0417779
[Epoch 46; Iter    45/  209] train: loss: 0.0618797
[Epoch 46; Iter    75/  209] train: loss: 0.0698132
[Epoch 46; Iter   105/  209] train: loss: 0.0677913
[Epoch 46; Iter   135/  209] train: loss: 0.0650583
[Epoch 46; Iter   165/  209] train: loss: 0.0407257
[Epoch 46; Iter   195/  209] train: loss: 0.0596995
[Epoch 46] ogbg-moltox21: 0.753364 val loss: 0.409049
[Epoch 46] ogbg-moltox21: 0.702436 test loss: 0.452785
[Epoch 47; Iter    16/  209] train: loss: 0.0338418
[Epoch 47; Iter    46/  209] train: loss: 0.0541481
[Epoch 47; Iter    76/  209] train: loss: 0.0366421
[Epoch 47; Iter   106/  209] train: loss: 0.0795518
[Epoch 47; Iter   136/  209] train: loss: 0.0349441
[Epoch 30; Iter    89/  209] train: loss: 0.1959539
[Epoch 30; Iter   119/  209] train: loss: 0.1639455
[Epoch 30; Iter   149/  209] train: loss: 0.1713274
[Epoch 30; Iter   179/  209] train: loss: 0.1595017
[Epoch 30; Iter   209/  209] train: loss: 0.1386534
[Epoch 30] ogbg-moltox21: 0.795398 val loss: 0.391748
[Epoch 30] ogbg-moltox21: 0.755854 test loss: 0.271865
[Epoch 31; Iter    30/  209] train: loss: 0.1994134
[Epoch 31; Iter    60/  209] train: loss: 0.1596429
[Epoch 31; Iter    90/  209] train: loss: 0.1103371
[Epoch 31; Iter   120/  209] train: loss: 0.1648654
[Epoch 31; Iter   150/  209] train: loss: 0.1556874
[Epoch 31; Iter   180/  209] train: loss: 0.1616821
[Epoch 31] ogbg-moltox21: 0.789343 val loss: 0.290495
[Epoch 31] ogbg-moltox21: 0.744082 test loss: 0.306559
[Epoch 32; Iter     1/  209] train: loss: 0.1765897
[Epoch 32; Iter    31/  209] train: loss: 0.1952015
[Epoch 32; Iter    61/  209] train: loss: 0.1508385
[Epoch 32; Iter    91/  209] train: loss: 0.1101544
[Epoch 32; Iter   121/  209] train: loss: 0.1588397
[Epoch 32; Iter   151/  209] train: loss: 0.1272935
[Epoch 32; Iter   181/  209] train: loss: 0.1503735
[Epoch 32] ogbg-moltox21: 0.790258 val loss: 0.280540
[Epoch 32] ogbg-moltox21: 0.728992 test loss: 0.304425
[Epoch 33; Iter     2/  209] train: loss: 0.1426562
[Epoch 33; Iter    32/  209] train: loss: 0.1901392
[Epoch 33; Iter    62/  209] train: loss: 0.2130199
[Epoch 33; Iter    92/  209] train: loss: 0.2173044
[Epoch 33; Iter   122/  209] train: loss: 0.1977454
[Epoch 33; Iter   152/  209] train: loss: 0.1557230
[Epoch 33; Iter   182/  209] train: loss: 0.1327005
[Epoch 33] ogbg-moltox21: 0.780209 val loss: 0.350853
[Epoch 33] ogbg-moltox21: 0.745003 test loss: 0.279946
[Epoch 34; Iter     3/  209] train: loss: 0.1811504
[Epoch 34; Iter    33/  209] train: loss: 0.2445309
[Epoch 34; Iter    63/  209] train: loss: 0.1626328
[Epoch 34; Iter    93/  209] train: loss: 0.1777455
[Epoch 34; Iter   123/  209] train: loss: 0.1324784
[Epoch 34; Iter   153/  209] train: loss: 0.3036751
[Epoch 34; Iter   183/  209] train: loss: 0.1188716
[Epoch 34] ogbg-moltox21: 0.796039 val loss: 0.241883
[Epoch 34] ogbg-moltox21: 0.738131 test loss: 0.274840
[Epoch 35; Iter     4/  209] train: loss: 0.2090421
[Epoch 35; Iter    34/  209] train: loss: 0.1211087
[Epoch 35; Iter    64/  209] train: loss: 0.1827160
[Epoch 35; Iter    94/  209] train: loss: 0.1081150
[Epoch 35; Iter   124/  209] train: loss: 0.3074290
[Epoch 35; Iter   154/  209] train: loss: 0.2125326
[Epoch 35; Iter   184/  209] train: loss: 0.2078807
[Epoch 35] ogbg-moltox21: 0.790701 val loss: 0.262427
[Epoch 35] ogbg-moltox21: 0.751231 test loss: 0.281783
[Epoch 36; Iter     5/  209] train: loss: 0.1614257
[Epoch 36; Iter    35/  209] train: loss: 0.1289140
[Epoch 36; Iter    65/  209] train: loss: 0.1151377
[Epoch 36; Iter    95/  209] train: loss: 0.1520663
[Epoch 36; Iter   125/  209] train: loss: 0.2060783
[Epoch 36; Iter   155/  209] train: loss: 0.1575901
[Epoch 36; Iter   185/  209] train: loss: 0.1375537
[Epoch 36] ogbg-moltox21: 0.779725 val loss: 0.271971
[Epoch 36] ogbg-moltox21: 0.733260 test loss: 0.295729
[Epoch 37; Iter     6/  209] train: loss: 0.1328756
[Epoch 37; Iter    36/  209] train: loss: 0.2058937
[Epoch 37; Iter    66/  209] train: loss: 0.1249205
[Epoch 37; Iter    96/  209] train: loss: 0.1300312
[Epoch 37; Iter   126/  209] train: loss: 0.1439530
[Epoch 37; Iter   156/  209] train: loss: 0.1404395
[Epoch 37; Iter   186/  209] train: loss: 0.1797477
[Epoch 37] ogbg-moltox21: 0.800443 val loss: 0.253928
[Epoch 37] ogbg-moltox21: 0.742204 test loss: 0.278960
[Epoch 38; Iter     7/  209] train: loss: 0.1512905
[Epoch 38; Iter    37/  209] train: loss: 0.1127487
[Epoch 38; Iter    67/  209] train: loss: 0.0952171
[Epoch 38; Iter    97/  209] train: loss: 0.1444672
[Epoch 38; Iter   127/  209] train: loss: 0.2180870
[Epoch 38; Iter   157/  209] train: loss: 0.1549439
[Epoch 38; Iter   187/  209] train: loss: 0.2276040
[Epoch 38] ogbg-moltox21: 0.796987 val loss: 0.260324
[Epoch 38] ogbg-moltox21: 0.744970 test loss: 0.312622
[Epoch 39; Iter     8/  209] train: loss: 0.1286772
[Epoch 39; Iter    38/  209] train: loss: 0.1316540
[Epoch 39; Iter    68/  209] train: loss: 0.1466518
[Epoch 39; Iter    98/  209] train: loss: 0.1455712
[Epoch 39; Iter   128/  209] train: loss: 0.2020237
[Epoch 39; Iter   158/  209] train: loss: 0.1309356
[Epoch 39; Iter   188/  209] train: loss: 0.1059124
[Epoch 39] ogbg-moltox21: 0.794262 val loss: 0.265352
[Epoch 39] ogbg-moltox21: 0.735405 test loss: 0.325577
[Epoch 40; Iter     9/  209] train: loss: 0.1252547
[Epoch 40; Iter    39/  209] train: loss: 0.1212593
[Epoch 40; Iter    69/  209] train: loss: 0.1733894
[Epoch 40; Iter    99/  209] train: loss: 0.1886026
[Epoch 40; Iter   129/  209] train: loss: 0.0980589
[Epoch 40; Iter   159/  209] train: loss: 0.1636095
[Epoch 40; Iter   189/  209] train: loss: 0.1643021
[Epoch 40] ogbg-moltox21: 0.792487 val loss: 0.270256
[Epoch 40] ogbg-moltox21: 0.736651 test loss: 0.295847
[Epoch 41; Iter    10/  209] train: loss: 0.0867624
[Epoch 41; Iter    40/  209] train: loss: 0.1755546
[Epoch 41; Iter    70/  209] train: loss: 0.0799059
[Epoch 41; Iter   100/  209] train: loss: 0.1454014
[Epoch 41; Iter   130/  209] train: loss: 0.2313477
[Epoch 41; Iter   160/  209] train: loss: 0.1865487
[Epoch 41; Iter   190/  209] train: loss: 0.1945101
[Epoch 41] ogbg-moltox21: 0.790959 val loss: 0.255386
[Epoch 41] ogbg-moltox21: 0.736354 test loss: 0.346085
[Epoch 42; Iter    11/  209] train: loss: 0.1460998
[Epoch 42; Iter    41/  209] train: loss: 0.1181209
[Epoch 42; Iter    71/  209] train: loss: 0.1576139
[Epoch 42; Iter   101/  209] train: loss: 0.1353662
[Epoch 42; Iter   131/  209] train: loss: 0.1018690
[Epoch 42; Iter   161/  209] train: loss: 0.1539375
[Epoch 42; Iter   191/  209] train: loss: 0.1262364
[Epoch 42] ogbg-moltox21: 0.772710 val loss: 0.277470
[Epoch 42] ogbg-moltox21: 0.719461 test loss: 0.562473
[Epoch 43; Iter    12/  209] train: loss: 0.1201617
[Epoch 43; Iter    42/  209] train: loss: 0.1323911
[Epoch 43; Iter    72/  209] train: loss: 0.1185609
[Epoch 43; Iter   102/  209] train: loss: 0.1426853
[Epoch 43; Iter   132/  209] train: loss: 0.1194981
[Epoch 43; Iter   162/  209] train: loss: 0.0798030
[Epoch 43; Iter   192/  209] train: loss: 0.1106745
[Epoch 43] ogbg-moltox21: 0.798972 val loss: 0.350614
[Epoch 43] ogbg-moltox21: 0.747713 test loss: 0.737034
[Epoch 44; Iter    13/  209] train: loss: 0.0936541
[Epoch 44; Iter    43/  209] train: loss: 0.1182282
[Epoch 44; Iter    73/  209] train: loss: 0.0980419
[Epoch 44; Iter   103/  209] train: loss: 0.1996160
[Epoch 44; Iter   133/  209] train: loss: 0.1391151
[Epoch 44; Iter   163/  209] train: loss: 0.1435300
[Epoch 44; Iter   193/  209] train: loss: 0.1473928
[Epoch 44] ogbg-moltox21: 0.795087 val loss: 0.275560
[Epoch 44] ogbg-moltox21: 0.743237 test loss: 0.565348
[Epoch 45; Iter    14/  209] train: loss: 0.1406137
[Epoch 45; Iter    44/  209] train: loss: 0.1252986
[Epoch 45; Iter    74/  209] train: loss: 0.1546662
[Epoch 45; Iter   104/  209] train: loss: 0.1239238
[Epoch 45; Iter   134/  209] train: loss: 0.0813238
[Epoch 45; Iter   164/  209] train: loss: 0.1027292
[Epoch 45; Iter   194/  209] train: loss: 0.1057370
[Epoch 45] ogbg-moltox21: 0.796975 val loss: 0.304069
[Epoch 45] ogbg-moltox21: 0.738568 test loss: 0.612787
[Epoch 46; Iter    15/  209] train: loss: 0.1006238
[Epoch 46; Iter    45/  209] train: loss: 0.1541181
[Epoch 46; Iter    75/  209] train: loss: 0.1340908
[Epoch 46; Iter   105/  209] train: loss: 0.1672100
[Epoch 46; Iter   135/  209] train: loss: 0.1648117
[Epoch 46; Iter   165/  209] train: loss: 0.1969418
[Epoch 46; Iter   195/  209] train: loss: 0.1307924
[Epoch 46] ogbg-moltox21: 0.789187 val loss: 0.292057
[Epoch 46] ogbg-moltox21: 0.738902 test loss: 0.618911
[Epoch 47; Iter    16/  209] train: loss: 0.1224997
[Epoch 47; Iter    46/  209] train: loss: 0.0903549
[Epoch 47; Iter    76/  209] train: loss: 0.2120672
[Epoch 47; Iter   106/  209] train: loss: 0.1505186
[Epoch 47; Iter   136/  209] train: loss: 0.1395864
[Epoch 30; Iter    89/  209] train: loss: 0.1180680
[Epoch 30; Iter   119/  209] train: loss: 0.1103353
[Epoch 30; Iter   149/  209] train: loss: 0.1832200
[Epoch 30; Iter   179/  209] train: loss: 0.1019903
[Epoch 30; Iter   209/  209] train: loss: 0.2346060
[Epoch 30] ogbg-moltox21: 0.767648 val loss: 0.311681
[Epoch 30] ogbg-moltox21: 0.731770 test loss: 0.556640
[Epoch 31; Iter    30/  209] train: loss: 0.1250017
[Epoch 31; Iter    60/  209] train: loss: 0.1228849
[Epoch 31; Iter    90/  209] train: loss: 0.1479694
[Epoch 31; Iter   120/  209] train: loss: 0.1103835
[Epoch 31; Iter   150/  209] train: loss: 0.1055739
[Epoch 31; Iter   180/  209] train: loss: 0.1768367
[Epoch 31] ogbg-moltox21: 0.773837 val loss: 0.302130
[Epoch 31] ogbg-moltox21: 0.709682 test loss: 0.485741
[Epoch 32; Iter     1/  209] train: loss: 0.1957030
[Epoch 32; Iter    31/  209] train: loss: 0.1125095
[Epoch 32; Iter    61/  209] train: loss: 0.0619536
[Epoch 32; Iter    91/  209] train: loss: 0.1343322
[Epoch 32; Iter   121/  209] train: loss: 0.1516979
[Epoch 32; Iter   151/  209] train: loss: 0.1761341
[Epoch 32; Iter   181/  209] train: loss: 0.1607190
[Epoch 32] ogbg-moltox21: 0.770471 val loss: 0.281522
[Epoch 32] ogbg-moltox21: 0.735490 test loss: 0.299941
[Epoch 33; Iter     2/  209] train: loss: 0.0932406
[Epoch 33; Iter    32/  209] train: loss: 0.0956552
[Epoch 33; Iter    62/  209] train: loss: 0.1020392
[Epoch 33; Iter    92/  209] train: loss: 0.0762881
[Epoch 33; Iter   122/  209] train: loss: 0.1123674
[Epoch 33; Iter   152/  209] train: loss: 0.1905480
[Epoch 33; Iter   182/  209] train: loss: 0.2192661
[Epoch 33] ogbg-moltox21: 0.760129 val loss: 0.325628
[Epoch 33] ogbg-moltox21: 0.722447 test loss: 0.321780
[Epoch 34; Iter     3/  209] train: loss: 0.0780160
[Epoch 34; Iter    33/  209] train: loss: 0.1277229
[Epoch 34; Iter    63/  209] train: loss: 0.1097357
[Epoch 34; Iter    93/  209] train: loss: 0.0800259
[Epoch 34; Iter   123/  209] train: loss: 0.1404904
[Epoch 34; Iter   153/  209] train: loss: 0.0935084
[Epoch 34; Iter   183/  209] train: loss: 0.1291974
[Epoch 34] ogbg-moltox21: 0.768263 val loss: 0.355454
[Epoch 34] ogbg-moltox21: 0.718183 test loss: 0.694689
[Epoch 35; Iter     4/  209] train: loss: 0.1241394
[Epoch 35; Iter    34/  209] train: loss: 0.0975374
[Epoch 35; Iter    64/  209] train: loss: 0.1257503
[Epoch 35; Iter    94/  209] train: loss: 0.1321113
[Epoch 35; Iter   124/  209] train: loss: 0.1187135
[Epoch 35; Iter   154/  209] train: loss: 0.1245185
[Epoch 35; Iter   184/  209] train: loss: 0.1035381
[Epoch 35] ogbg-moltox21: 0.761011 val loss: 0.301061
[Epoch 35] ogbg-moltox21: 0.713438 test loss: 0.382023
[Epoch 36; Iter     5/  209] train: loss: 0.0985527
[Epoch 36; Iter    35/  209] train: loss: 0.0610127
[Epoch 36; Iter    65/  209] train: loss: 0.1559004
[Epoch 36; Iter    95/  209] train: loss: 0.0813147
[Epoch 36; Iter   125/  209] train: loss: 0.1417472
[Epoch 36; Iter   155/  209] train: loss: 0.0970748
[Epoch 36; Iter   185/  209] train: loss: 0.1368636
[Epoch 36] ogbg-moltox21: 0.779926 val loss: 0.287223
[Epoch 36] ogbg-moltox21: 0.727166 test loss: 0.445789
[Epoch 37; Iter     6/  209] train: loss: 0.0496264
[Epoch 37; Iter    36/  209] train: loss: 0.1110136
[Epoch 37; Iter    66/  209] train: loss: 0.0955465
[Epoch 37; Iter    96/  209] train: loss: 0.1030093
[Epoch 37; Iter   126/  209] train: loss: 0.0548058
[Epoch 37; Iter   156/  209] train: loss: 0.0521522
[Epoch 37; Iter   186/  209] train: loss: 0.1024914
[Epoch 37] ogbg-moltox21: 0.757056 val loss: 0.281415
[Epoch 37] ogbg-moltox21: 0.722379 test loss: 0.391147
[Epoch 38; Iter     7/  209] train: loss: 0.0919918
[Epoch 38; Iter    37/  209] train: loss: 0.1098905
[Epoch 38; Iter    67/  209] train: loss: 0.0751487
[Epoch 38; Iter    97/  209] train: loss: 0.0826360
[Epoch 38; Iter   127/  209] train: loss: 0.1021611
[Epoch 38; Iter   157/  209] train: loss: 0.0798194
[Epoch 38; Iter   187/  209] train: loss: 0.0771611
[Epoch 38] ogbg-moltox21: 0.757473 val loss: 0.404093
[Epoch 38] ogbg-moltox21: 0.731328 test loss: 0.725274
[Epoch 39; Iter     8/  209] train: loss: 0.0777695
[Epoch 39; Iter    38/  209] train: loss: 0.0879346
[Epoch 39; Iter    68/  209] train: loss: 0.0794201
[Epoch 39; Iter    98/  209] train: loss: 0.1123804
[Epoch 39; Iter   128/  209] train: loss: 0.0891826
[Epoch 39; Iter   158/  209] train: loss: 0.0674935
[Epoch 39; Iter   188/  209] train: loss: 0.0672441
[Epoch 39] ogbg-moltox21: 0.759675 val loss: 0.323807
[Epoch 39] ogbg-moltox21: 0.715581 test loss: 0.632725
[Epoch 40; Iter     9/  209] train: loss: 0.0903541
[Epoch 40; Iter    39/  209] train: loss: 0.1894216
[Epoch 40; Iter    69/  209] train: loss: 0.0978332
[Epoch 40; Iter    99/  209] train: loss: 0.0980269
[Epoch 40; Iter   129/  209] train: loss: 0.1008074
[Epoch 40; Iter   159/  209] train: loss: 0.0709685
[Epoch 40; Iter   189/  209] train: loss: 0.0848852
[Epoch 40] ogbg-moltox21: 0.750556 val loss: 0.463550
[Epoch 40] ogbg-moltox21: 0.713925 test loss: 0.738452
[Epoch 41; Iter    10/  209] train: loss: 0.0459369
[Epoch 41; Iter    40/  209] train: loss: 0.0566795
[Epoch 41; Iter    70/  209] train: loss: 0.0609647
[Epoch 41; Iter   100/  209] train: loss: 0.0688159
[Epoch 41; Iter   130/  209] train: loss: 0.0928193
[Epoch 41; Iter   160/  209] train: loss: 0.1083660
[Epoch 41; Iter   190/  209] train: loss: 0.0910989
[Epoch 41] ogbg-moltox21: 0.748532 val loss: 0.313921
[Epoch 41] ogbg-moltox21: 0.710676 test loss: 0.395995
[Epoch 42; Iter    11/  209] train: loss: 0.0970883
[Epoch 42; Iter    41/  209] train: loss: 0.1072512
[Epoch 42; Iter    71/  209] train: loss: 0.0812805
[Epoch 42; Iter   101/  209] train: loss: 0.0589814
[Epoch 42; Iter   131/  209] train: loss: 0.0928717
[Epoch 42; Iter   161/  209] train: loss: 0.0497363
[Epoch 42; Iter   191/  209] train: loss: 0.0771318
[Epoch 42] ogbg-moltox21: 0.758588 val loss: 0.589359
[Epoch 42] ogbg-moltox21: 0.716907 test loss: 0.750772
[Epoch 43; Iter    12/  209] train: loss: 0.0825761
[Epoch 43; Iter    42/  209] train: loss: 0.0724903
[Epoch 43; Iter    72/  209] train: loss: 0.0612297
[Epoch 43; Iter   102/  209] train: loss: 0.1070175
[Epoch 43; Iter   132/  209] train: loss: 0.0875060
[Epoch 43; Iter   162/  209] train: loss: 0.0752342
[Epoch 43; Iter   192/  209] train: loss: 0.0573378
[Epoch 43] ogbg-moltox21: 0.740326 val loss: 0.581831
[Epoch 43] ogbg-moltox21: 0.717363 test loss: 0.413966
[Epoch 44; Iter    13/  209] train: loss: 0.0791684
[Epoch 44; Iter    43/  209] train: loss: 0.0623936
[Epoch 44; Iter    73/  209] train: loss: 0.0743340
[Epoch 44; Iter   103/  209] train: loss: 0.0779219
[Epoch 44; Iter   133/  209] train: loss: 0.0665244
[Epoch 44; Iter   163/  209] train: loss: 0.0692757
[Epoch 44; Iter   193/  209] train: loss: 0.0420847
[Epoch 44] ogbg-moltox21: 0.727792 val loss: 0.689778
[Epoch 44] ogbg-moltox21: 0.696256 test loss: 1.129855
[Epoch 45; Iter    14/  209] train: loss: 0.0856421
[Epoch 45; Iter    44/  209] train: loss: 0.0602093
[Epoch 45; Iter    74/  209] train: loss: 0.0790669
[Epoch 45; Iter   104/  209] train: loss: 0.0654078
[Epoch 45; Iter   134/  209] train: loss: 0.1081798
[Epoch 45; Iter   164/  209] train: loss: 0.0615015
[Epoch 45; Iter   194/  209] train: loss: 0.0669768
[Epoch 45] ogbg-moltox21: 0.727757 val loss: 0.676592
[Epoch 45] ogbg-moltox21: 0.709756 test loss: 0.986550
[Epoch 46; Iter    15/  209] train: loss: 0.0475289
[Epoch 46; Iter    45/  209] train: loss: 0.0774454
[Epoch 46; Iter    75/  209] train: loss: 0.1133687
[Epoch 46; Iter   105/  209] train: loss: 0.1022571
[Epoch 46; Iter   135/  209] train: loss: 0.1024648
[Epoch 46; Iter   165/  209] train: loss: 0.0389192
[Epoch 46; Iter   195/  209] train: loss: 0.0651111
[Epoch 46] ogbg-moltox21: 0.743356 val loss: 0.484730
[Epoch 46] ogbg-moltox21: 0.715801 test loss: 0.788613
[Epoch 47; Iter    16/  209] train: loss: 0.0648219
[Epoch 47; Iter    46/  209] train: loss: 0.0662095
[Epoch 47; Iter    76/  209] train: loss: 0.0711430
[Epoch 47; Iter   106/  209] train: loss: 0.1379615
[Epoch 47; Iter   136/  209] train: loss: 0.0579882
[Epoch 30; Iter    89/  209] train: loss: 0.1388370
[Epoch 30; Iter   119/  209] train: loss: 0.1222772
[Epoch 30; Iter   149/  209] train: loss: 0.1164996
[Epoch 30; Iter   179/  209] train: loss: 0.1257324
[Epoch 30; Iter   209/  209] train: loss: 0.1221927
[Epoch 30] ogbg-moltox21: 0.751744 val loss: 0.280035
[Epoch 30] ogbg-moltox21: 0.719568 test loss: 0.297181
[Epoch 31; Iter    30/  209] train: loss: 0.1367211
[Epoch 31; Iter    60/  209] train: loss: 0.1108913
[Epoch 31; Iter    90/  209] train: loss: 0.1112123
[Epoch 31; Iter   120/  209] train: loss: 0.1209752
[Epoch 31; Iter   150/  209] train: loss: 0.1521390
[Epoch 31; Iter   180/  209] train: loss: 0.1216212
[Epoch 31] ogbg-moltox21: 0.735388 val loss: 0.294103
[Epoch 31] ogbg-moltox21: 0.701483 test loss: 0.311286
[Epoch 32; Iter     1/  209] train: loss: 0.1490548
[Epoch 32; Iter    31/  209] train: loss: 0.1594330
[Epoch 32; Iter    61/  209] train: loss: 0.1144168
[Epoch 32; Iter    91/  209] train: loss: 0.0834641
[Epoch 32; Iter   121/  209] train: loss: 0.1218673
[Epoch 32; Iter   151/  209] train: loss: 0.1347592
[Epoch 32; Iter   181/  209] train: loss: 0.1214299
[Epoch 32] ogbg-moltox21: 0.704459 val loss: 0.332481
[Epoch 32] ogbg-moltox21: 0.678872 test loss: 0.355231
[Epoch 33; Iter     2/  209] train: loss: 0.1123757
[Epoch 33; Iter    32/  209] train: loss: 0.1214727
[Epoch 33; Iter    62/  209] train: loss: 0.1805018
[Epoch 33; Iter    92/  209] train: loss: 0.1684703
[Epoch 33; Iter   122/  209] train: loss: 0.2164542
[Epoch 33; Iter   152/  209] train: loss: 0.1091510
[Epoch 33; Iter   182/  209] train: loss: 0.1080086
[Epoch 33] ogbg-moltox21: 0.719177 val loss: 0.291585
[Epoch 33] ogbg-moltox21: 0.706298 test loss: 0.302678
[Epoch 34; Iter     3/  209] train: loss: 0.1651704
[Epoch 34; Iter    33/  209] train: loss: 0.1828547
[Epoch 34; Iter    63/  209] train: loss: 0.0969848
[Epoch 34; Iter    93/  209] train: loss: 0.1210266
[Epoch 34; Iter   123/  209] train: loss: 0.1349701
[Epoch 34; Iter   153/  209] train: loss: 0.2137858
[Epoch 34; Iter   183/  209] train: loss: 0.1119759
[Epoch 34] ogbg-moltox21: 0.706685 val loss: 0.315067
[Epoch 34] ogbg-moltox21: 0.683551 test loss: 0.333233
[Epoch 35; Iter     4/  209] train: loss: 0.1380228
[Epoch 35; Iter    34/  209] train: loss: 0.0980666
[Epoch 35; Iter    64/  209] train: loss: 0.1198584
[Epoch 35; Iter    94/  209] train: loss: 0.0834997
[Epoch 35; Iter   124/  209] train: loss: 0.2407753
[Epoch 35; Iter   154/  209] train: loss: 0.1526515
[Epoch 35; Iter   184/  209] train: loss: 0.1370727
[Epoch 35] ogbg-moltox21: 0.730580 val loss: 0.303544
[Epoch 35] ogbg-moltox21: 0.711891 test loss: 0.320893
[Epoch 36; Iter     5/  209] train: loss: 0.0989056
[Epoch 36; Iter    35/  209] train: loss: 0.0743866
[Epoch 36; Iter    65/  209] train: loss: 0.0824886
[Epoch 36; Iter    95/  209] train: loss: 0.0943882
[Epoch 36; Iter   125/  209] train: loss: 0.1466607
[Epoch 36; Iter   155/  209] train: loss: 0.1026576
[Epoch 36; Iter   185/  209] train: loss: 0.1057829
[Epoch 36] ogbg-moltox21: 0.735981 val loss: 0.309625
[Epoch 36] ogbg-moltox21: 0.702459 test loss: 0.338191
[Epoch 37; Iter     6/  209] train: loss: 0.0819109
[Epoch 37; Iter    36/  209] train: loss: 0.1457565
[Epoch 37; Iter    66/  209] train: loss: 0.0940584
[Epoch 37; Iter    96/  209] train: loss: 0.0749289
[Epoch 37; Iter   126/  209] train: loss: 0.0838736
[Epoch 37; Iter   156/  209] train: loss: 0.1177045
[Epoch 37; Iter   186/  209] train: loss: 0.1623770
[Epoch 37] ogbg-moltox21: 0.697668 val loss: 0.352169
[Epoch 37] ogbg-moltox21: 0.671771 test loss: 0.378303
[Epoch 38; Iter     7/  209] train: loss: 0.1037550
[Epoch 38; Iter    37/  209] train: loss: 0.0921736
[Epoch 38; Iter    67/  209] train: loss: 0.0786781
[Epoch 38; Iter    97/  209] train: loss: 0.0884558
[Epoch 38; Iter   127/  209] train: loss: 0.1219197
[Epoch 38; Iter   157/  209] train: loss: 0.0950851
[Epoch 38; Iter   187/  209] train: loss: 0.1783071
[Epoch 38] ogbg-moltox21: 0.713146 val loss: 0.346258
[Epoch 38] ogbg-moltox21: 0.693567 test loss: 0.367104
[Epoch 39; Iter     8/  209] train: loss: 0.0937064
[Epoch 39; Iter    38/  209] train: loss: 0.0857561
[Epoch 39; Iter    68/  209] train: loss: 0.1027092
[Epoch 39; Iter    98/  209] train: loss: 0.0834509
[Epoch 39; Iter   128/  209] train: loss: 0.1477670
[Epoch 39; Iter   158/  209] train: loss: 0.0821638
[Epoch 39; Iter   188/  209] train: loss: 0.0814236
[Epoch 39] ogbg-moltox21: 0.715833 val loss: 0.368922
[Epoch 39] ogbg-moltox21: 0.692003 test loss: 0.392785
[Epoch 40; Iter     9/  209] train: loss: 0.0753862
[Epoch 40; Iter    39/  209] train: loss: 0.0868084
[Epoch 40; Iter    69/  209] train: loss: 0.1264041
[Epoch 40; Iter    99/  209] train: loss: 0.0908297
[Epoch 40; Iter   129/  209] train: loss: 0.0471183
[Epoch 40; Iter   159/  209] train: loss: 0.1251050
[Epoch 40; Iter   189/  209] train: loss: 0.1394397
[Epoch 40] ogbg-moltox21: 0.701847 val loss: 0.355555
[Epoch 40] ogbg-moltox21: 0.687493 test loss: 0.376489
[Epoch 41; Iter    10/  209] train: loss: 0.0617003
[Epoch 41; Iter    40/  209] train: loss: 0.1052112
[Epoch 41; Iter    70/  209] train: loss: 0.0481254
[Epoch 41; Iter   100/  209] train: loss: 0.0999126
[Epoch 41; Iter   130/  209] train: loss: 0.1683283
[Epoch 41; Iter   160/  209] train: loss: 0.1183093
[Epoch 41; Iter   190/  209] train: loss: 0.1353307
[Epoch 41] ogbg-moltox21: 0.725123 val loss: 0.345242
[Epoch 41] ogbg-moltox21: 0.696701 test loss: 0.369406
[Epoch 42; Iter    11/  209] train: loss: 0.0928119
[Epoch 42; Iter    41/  209] train: loss: 0.0644472
[Epoch 42; Iter    71/  209] train: loss: 0.1067861
[Epoch 42; Iter   101/  209] train: loss: 0.0716558
[Epoch 42; Iter   131/  209] train: loss: 0.0662103
[Epoch 42; Iter   161/  209] train: loss: 0.1239673
[Epoch 42; Iter   191/  209] train: loss: 0.0906470
[Epoch 42] ogbg-moltox21: 0.721380 val loss: 0.342089
[Epoch 42] ogbg-moltox21: 0.693865 test loss: 0.372404
[Epoch 43; Iter    12/  209] train: loss: 0.0781216
[Epoch 43; Iter    42/  209] train: loss: 0.0869032
[Epoch 43; Iter    72/  209] train: loss: 0.0836493
[Epoch 43; Iter   102/  209] train: loss: 0.0722509
[Epoch 43; Iter   132/  209] train: loss: 0.0594138
[Epoch 43; Iter   162/  209] train: loss: 0.0697601
[Epoch 43; Iter   192/  209] train: loss: 0.0738359
[Epoch 43] ogbg-moltox21: 0.696376 val loss: 0.394182
[Epoch 43] ogbg-moltox21: 0.661315 test loss: 0.419959
[Epoch 44; Iter    13/  209] train: loss: 0.0660793
[Epoch 44; Iter    43/  209] train: loss: 0.0944225
[Epoch 44; Iter    73/  209] train: loss: 0.0801970
[Epoch 44; Iter   103/  209] train: loss: 0.1045770
[Epoch 44; Iter   133/  209] train: loss: 0.1012829
[Epoch 44; Iter   163/  209] train: loss: 0.0829350
[Epoch 44; Iter   193/  209] train: loss: 0.1028066
[Epoch 44] ogbg-moltox21: 0.719892 val loss: 0.354832
[Epoch 44] ogbg-moltox21: 0.693055 test loss: 0.384303
[Epoch 45; Iter    14/  209] train: loss: 0.0761048
[Epoch 45; Iter    44/  209] train: loss: 0.0852201
[Epoch 45; Iter    74/  209] train: loss: 0.1090115
[Epoch 45; Iter   104/  209] train: loss: 0.0760836
[Epoch 45; Iter   134/  209] train: loss: 0.0643708
[Epoch 45; Iter   164/  209] train: loss: 0.0615295
[Epoch 45; Iter   194/  209] train: loss: 0.1089717
[Epoch 45] ogbg-moltox21: 0.709721 val loss: 0.360368
[Epoch 45] ogbg-moltox21: 0.685858 test loss: 0.383508
[Epoch 46; Iter    15/  209] train: loss: 0.0559205
[Epoch 46; Iter    45/  209] train: loss: 0.0938322
[Epoch 46; Iter    75/  209] train: loss: 0.0750293
[Epoch 46; Iter   105/  209] train: loss: 0.0609995
[Epoch 46; Iter   135/  209] train: loss: 0.1076149
[Epoch 46; Iter   165/  209] train: loss: 0.1693802
[Epoch 46; Iter   195/  209] train: loss: 0.0766834
[Epoch 46] ogbg-moltox21: 0.711983 val loss: 0.390641
[Epoch 46] ogbg-moltox21: 0.683008 test loss: 0.417897
[Epoch 47; Iter    16/  209] train: loss: 0.0594781
[Epoch 47; Iter    46/  209] train: loss: 0.0577330
[Epoch 47; Iter    76/  209] train: loss: 0.1563275
[Epoch 47; Iter   106/  209] train: loss: 0.1062691
[Epoch 47; Iter   136/  209] train: loss: 0.0837703
[Epoch 30; Iter    89/  209] train: loss: 0.1167634
[Epoch 30; Iter   119/  209] train: loss: 0.1033988
[Epoch 30; Iter   149/  209] train: loss: 0.1475154
[Epoch 30; Iter   179/  209] train: loss: 0.0854743
[Epoch 30; Iter   209/  209] train: loss: 0.2026120
[Epoch 30] ogbg-moltox21: 0.700052 val loss: 0.478923
[Epoch 30] ogbg-moltox21: 0.660754 test loss: 0.500827
[Epoch 31; Iter    30/  209] train: loss: 0.1111621
[Epoch 31; Iter    60/  209] train: loss: 0.1169627
[Epoch 31; Iter    90/  209] train: loss: 0.1070304
[Epoch 31; Iter   120/  209] train: loss: 0.0901152
[Epoch 31; Iter   150/  209] train: loss: 0.1011411
[Epoch 31; Iter   180/  209] train: loss: 0.1655970
[Epoch 31] ogbg-moltox21: 0.730883 val loss: 0.401906
[Epoch 31] ogbg-moltox21: 0.693872 test loss: 0.418729
[Epoch 32; Iter     1/  209] train: loss: 0.1563518
[Epoch 32; Iter    31/  209] train: loss: 0.1089533
[Epoch 32; Iter    61/  209] train: loss: 0.0453656
[Epoch 32; Iter    91/  209] train: loss: 0.1206205
[Epoch 32; Iter   121/  209] train: loss: 0.1014098
[Epoch 32; Iter   151/  209] train: loss: 0.1416909
[Epoch 32; Iter   181/  209] train: loss: 0.1767399
[Epoch 32] ogbg-moltox21: 0.724333 val loss: 0.422431
[Epoch 32] ogbg-moltox21: 0.673961 test loss: 0.448246
[Epoch 33; Iter     2/  209] train: loss: 0.0907648
[Epoch 33; Iter    32/  209] train: loss: 0.0947520
[Epoch 33; Iter    62/  209] train: loss: 0.1124700
[Epoch 33; Iter    92/  209] train: loss: 0.1119687
[Epoch 33; Iter   122/  209] train: loss: 0.1063159
[Epoch 33; Iter   152/  209] train: loss: 0.1907704
[Epoch 33; Iter   182/  209] train: loss: 0.1736923
[Epoch 33] ogbg-moltox21: 0.729056 val loss: 0.416080
[Epoch 33] ogbg-moltox21: 0.681127 test loss: 0.448275
[Epoch 34; Iter     3/  209] train: loss: 0.0749462
[Epoch 34; Iter    33/  209] train: loss: 0.1038867
[Epoch 34; Iter    63/  209] train: loss: 0.1167330
[Epoch 34; Iter    93/  209] train: loss: 0.0682581
[Epoch 34; Iter   123/  209] train: loss: 0.0913852
[Epoch 34; Iter   153/  209] train: loss: 0.0892586
[Epoch 34; Iter   183/  209] train: loss: 0.0869459
[Epoch 34] ogbg-moltox21: 0.691329 val loss: 0.493448
[Epoch 34] ogbg-moltox21: 0.676611 test loss: 0.502589
[Epoch 35; Iter     4/  209] train: loss: 0.1112848
[Epoch 35; Iter    34/  209] train: loss: 0.0662669
[Epoch 35; Iter    64/  209] train: loss: 0.1165809
[Epoch 35; Iter    94/  209] train: loss: 0.1502829
[Epoch 35; Iter   124/  209] train: loss: 0.0990884
[Epoch 35; Iter   154/  209] train: loss: 0.1107795
[Epoch 35; Iter   184/  209] train: loss: 0.0930272
[Epoch 35] ogbg-moltox21: 0.729351 val loss: 0.432749
[Epoch 35] ogbg-moltox21: 0.702741 test loss: 0.477651
[Epoch 36; Iter     5/  209] train: loss: 0.1059954
[Epoch 36; Iter    35/  209] train: loss: 0.0604153
[Epoch 36; Iter    65/  209] train: loss: 0.1256981
[Epoch 36; Iter    95/  209] train: loss: 0.0664346
[Epoch 36; Iter   125/  209] train: loss: 0.1152152
[Epoch 36; Iter   155/  209] train: loss: 0.0787859
[Epoch 36; Iter   185/  209] train: loss: 0.0951038
[Epoch 36] ogbg-moltox21: 0.738420 val loss: 0.495056
[Epoch 36] ogbg-moltox21: 0.694330 test loss: 0.534801
[Epoch 37; Iter     6/  209] train: loss: 0.0581526
[Epoch 37; Iter    36/  209] train: loss: 0.1124846
[Epoch 37; Iter    66/  209] train: loss: 0.0778176
[Epoch 37; Iter    96/  209] train: loss: 0.0983691
[Epoch 37; Iter   126/  209] train: loss: 0.0602156
[Epoch 37; Iter   156/  209] train: loss: 0.0770668
[Epoch 37; Iter   186/  209] train: loss: 0.1028166
[Epoch 37] ogbg-moltox21: 0.688945 val loss: 0.503702
[Epoch 37] ogbg-moltox21: 0.653693 test loss: 0.513197
[Epoch 38; Iter     7/  209] train: loss: 0.0879576
[Epoch 38; Iter    37/  209] train: loss: 0.1159647
[Epoch 38; Iter    67/  209] train: loss: 0.0538477
[Epoch 38; Iter    97/  209] train: loss: 0.0833649
[Epoch 38; Iter   127/  209] train: loss: 0.0709741
[Epoch 38; Iter   157/  209] train: loss: 0.0867817
[Epoch 38; Iter   187/  209] train: loss: 0.0713808
[Epoch 38] ogbg-moltox21: 0.684897 val loss: 0.912442
[Epoch 38] ogbg-moltox21: 0.676206 test loss: 1.399882
[Epoch 39; Iter     8/  209] train: loss: 0.0813510
[Epoch 39; Iter    38/  209] train: loss: 0.0839135
[Epoch 39; Iter    68/  209] train: loss: 0.0691238
[Epoch 39; Iter    98/  209] train: loss: 0.1197330
[Epoch 39; Iter   128/  209] train: loss: 0.0725431
[Epoch 39; Iter   158/  209] train: loss: 0.0560052
[Epoch 39; Iter   188/  209] train: loss: 0.0599495
[Epoch 39] ogbg-moltox21: 0.721024 val loss: 0.518536
[Epoch 39] ogbg-moltox21: 0.696988 test loss: 0.606060
[Epoch 40; Iter     9/  209] train: loss: 0.0930477
[Epoch 40; Iter    39/  209] train: loss: 0.2032757
[Epoch 40; Iter    69/  209] train: loss: 0.0671231
[Epoch 40; Iter    99/  209] train: loss: 0.0681858
[Epoch 40; Iter   129/  209] train: loss: 0.0889112
[Epoch 40; Iter   159/  209] train: loss: 0.1052361
[Epoch 40; Iter   189/  209] train: loss: 0.0689879
[Epoch 40] ogbg-moltox21: 0.757358 val loss: 0.492421
[Epoch 40] ogbg-moltox21: 0.713464 test loss: 0.648624
[Epoch 41; Iter    10/  209] train: loss: 0.0362077
[Epoch 41; Iter    40/  209] train: loss: 0.0583301
[Epoch 41; Iter    70/  209] train: loss: 0.0577221
[Epoch 41; Iter   100/  209] train: loss: 0.0736458
[Epoch 41; Iter   130/  209] train: loss: 0.0861374
[Epoch 41; Iter   160/  209] train: loss: 0.0968770
[Epoch 41; Iter   190/  209] train: loss: 0.0691648
[Epoch 41] ogbg-moltox21: 0.706491 val loss: 0.598269
[Epoch 41] ogbg-moltox21: 0.675436 test loss: 0.722608
[Epoch 42; Iter    11/  209] train: loss: 0.0928287
[Epoch 42; Iter    41/  209] train: loss: 0.0971657
[Epoch 42; Iter    71/  209] train: loss: 0.0736643
[Epoch 42; Iter   101/  209] train: loss: 0.0683928
[Epoch 42; Iter   131/  209] train: loss: 0.1022386
[Epoch 42; Iter   161/  209] train: loss: 0.0429076
[Epoch 42; Iter   191/  209] train: loss: 0.0686984
[Epoch 42] ogbg-moltox21: 0.701647 val loss: 0.615805
[Epoch 42] ogbg-moltox21: 0.662450 test loss: 0.734749
[Epoch 43; Iter    12/  209] train: loss: 0.0620156
[Epoch 43; Iter    42/  209] train: loss: 0.0693413
[Epoch 43; Iter    72/  209] train: loss: 0.0701145
[Epoch 43; Iter   102/  209] train: loss: 0.1004328
[Epoch 43; Iter   132/  209] train: loss: 0.0828350
[Epoch 43; Iter   162/  209] train: loss: 0.0696862
[Epoch 43; Iter   192/  209] train: loss: 0.0665195
[Epoch 43] ogbg-moltox21: 0.711106 val loss: 0.561202
[Epoch 43] ogbg-moltox21: 0.685355 test loss: 0.571209
[Epoch 44; Iter    13/  209] train: loss: 0.0901221
[Epoch 44; Iter    43/  209] train: loss: 0.0549201
[Epoch 44; Iter    73/  209] train: loss: 0.0705097
[Epoch 44; Iter   103/  209] train: loss: 0.0678714
[Epoch 44; Iter   133/  209] train: loss: 0.0665083
[Epoch 44; Iter   163/  209] train: loss: 0.0684902
[Epoch 44; Iter   193/  209] train: loss: 0.0487550
[Epoch 44] ogbg-moltox21: 0.727279 val loss: 0.582127
[Epoch 44] ogbg-moltox21: 0.680567 test loss: 0.701553
[Epoch 45; Iter    14/  209] train: loss: 0.0686240
[Epoch 45; Iter    44/  209] train: loss: 0.0665872
[Epoch 45; Iter    74/  209] train: loss: 0.0874058
[Epoch 45; Iter   104/  209] train: loss: 0.0742277
[Epoch 45; Iter   134/  209] train: loss: 0.1287629
[Epoch 45; Iter   164/  209] train: loss: 0.0717005
[Epoch 45; Iter   194/  209] train: loss: 0.0737967
[Epoch 45] ogbg-moltox21: 0.713525 val loss: 0.560787
[Epoch 45] ogbg-moltox21: 0.686964 test loss: 0.658120
[Epoch 46; Iter    15/  209] train: loss: 0.0663005
[Epoch 46; Iter    45/  209] train: loss: 0.0750955
[Epoch 46; Iter    75/  209] train: loss: 0.1059448
[Epoch 46; Iter   105/  209] train: loss: 0.0789306
[Epoch 46; Iter   135/  209] train: loss: 0.0559487
[Epoch 46; Iter   165/  209] train: loss: 0.0370040
[Epoch 46; Iter   195/  209] train: loss: 0.0649908
[Epoch 46] ogbg-moltox21: 0.713025 val loss: 0.677846
[Epoch 46] ogbg-moltox21: 0.678651 test loss: 0.814166
[Epoch 47; Iter    16/  209] train: loss: 0.0422380
[Epoch 47; Iter    46/  209] train: loss: 0.0560932
[Epoch 47; Iter    76/  209] train: loss: 0.0698465
[Epoch 47; Iter   106/  209] train: loss: 0.0927174
[Epoch 47; Iter   136/  209] train: loss: 0.0468372
[Epoch 30; Iter    89/  209] train: loss: 0.0926990
[Epoch 30; Iter   119/  209] train: loss: 0.1326131
[Epoch 30; Iter   149/  209] train: loss: 0.1066711
[Epoch 30; Iter   179/  209] train: loss: 0.1787266
[Epoch 30; Iter   209/  209] train: loss: 0.0891307
[Epoch 30] ogbg-moltox21: 0.765045 val loss: 0.338141
[Epoch 30] ogbg-moltox21: 0.736579 test loss: 0.309297
[Epoch 31; Iter    30/  209] train: loss: 0.0638784
[Epoch 31; Iter    60/  209] train: loss: 0.0866522
[Epoch 31; Iter    90/  209] train: loss: 0.1128328
[Epoch 31; Iter   120/  209] train: loss: 0.1039764
[Epoch 31; Iter   150/  209] train: loss: 0.1340980
[Epoch 31; Iter   180/  209] train: loss: 0.1687630
[Epoch 31] ogbg-moltox21: 0.748749 val loss: 0.376029
[Epoch 31] ogbg-moltox21: 0.704645 test loss: 0.492519
[Epoch 32; Iter     1/  209] train: loss: 0.1089601
[Epoch 32; Iter    31/  209] train: loss: 0.0748867
[Epoch 32; Iter    61/  209] train: loss: 0.1536252
[Epoch 32; Iter    91/  209] train: loss: 0.0938258
[Epoch 32; Iter   121/  209] train: loss: 0.1200811
[Epoch 32; Iter   151/  209] train: loss: 0.1219979
[Epoch 32; Iter   181/  209] train: loss: 0.2083091
[Epoch 32] ogbg-moltox21: 0.742508 val loss: 0.288428
[Epoch 32] ogbg-moltox21: 0.709735 test loss: 0.315314
[Epoch 33; Iter     2/  209] train: loss: 0.1113663
[Epoch 33; Iter    32/  209] train: loss: 0.0984796
[Epoch 33; Iter    62/  209] train: loss: 0.0684035
[Epoch 33; Iter    92/  209] train: loss: 0.1485557
[Epoch 33; Iter   122/  209] train: loss: 0.0888588
[Epoch 33; Iter   152/  209] train: loss: 0.1053105
[Epoch 33; Iter   182/  209] train: loss: 0.0923063
[Epoch 33] ogbg-moltox21: 0.761905 val loss: 0.355865
[Epoch 33] ogbg-moltox21: 0.717912 test loss: 0.345380
[Epoch 34; Iter     3/  209] train: loss: 0.0598162
[Epoch 34; Iter    33/  209] train: loss: 0.0885507
[Epoch 34; Iter    63/  209] train: loss: 0.1203704
[Epoch 34; Iter    93/  209] train: loss: 0.1545399
[Epoch 34; Iter   123/  209] train: loss: 0.0828560
[Epoch 34; Iter   153/  209] train: loss: 0.1131137
[Epoch 34; Iter   183/  209] train: loss: 0.0825833
[Epoch 34] ogbg-moltox21: 0.761370 val loss: 0.339180
[Epoch 34] ogbg-moltox21: 0.729544 test loss: 0.324326
[Epoch 35; Iter     4/  209] train: loss: 0.1120197
[Epoch 35; Iter    34/  209] train: loss: 0.1277871
[Epoch 35; Iter    64/  209] train: loss: 0.1264489
[Epoch 35; Iter    94/  209] train: loss: 0.0790903
[Epoch 35; Iter   124/  209] train: loss: 0.1038275
[Epoch 35; Iter   154/  209] train: loss: 0.0857035
[Epoch 35; Iter   184/  209] train: loss: 0.1362441
[Epoch 35] ogbg-moltox21: 0.773165 val loss: 0.319902
[Epoch 35] ogbg-moltox21: 0.724028 test loss: 0.348660
[Epoch 36; Iter     5/  209] train: loss: 0.1374017
[Epoch 36; Iter    35/  209] train: loss: 0.1118363
[Epoch 36; Iter    65/  209] train: loss: 0.0985493
[Epoch 36; Iter    95/  209] train: loss: 0.1154448
[Epoch 36; Iter   125/  209] train: loss: 0.1239444
[Epoch 36; Iter   155/  209] train: loss: 0.0929244
[Epoch 36; Iter   185/  209] train: loss: 0.1364684
[Epoch 36] ogbg-moltox21: 0.752053 val loss: 0.453084
[Epoch 36] ogbg-moltox21: 0.716845 test loss: 0.419878
[Epoch 37; Iter     6/  209] train: loss: 0.0957961
[Epoch 37; Iter    36/  209] train: loss: 0.0967084
[Epoch 37; Iter    66/  209] train: loss: 0.1437711
[Epoch 37; Iter    96/  209] train: loss: 0.0989103
[Epoch 37; Iter   126/  209] train: loss: 0.1047486
[Epoch 37; Iter   156/  209] train: loss: 0.0995756
[Epoch 37; Iter   186/  209] train: loss: 0.1085754
[Epoch 37] ogbg-moltox21: 0.760575 val loss: 0.293826
[Epoch 37] ogbg-moltox21: 0.718834 test loss: 0.319713
[Epoch 38; Iter     7/  209] train: loss: 0.1517396
[Epoch 38; Iter    37/  209] train: loss: 0.1255809
[Epoch 38; Iter    67/  209] train: loss: 0.0884037
[Epoch 38; Iter    97/  209] train: loss: 0.0969252
[Epoch 38; Iter   127/  209] train: loss: 0.0893331
[Epoch 38; Iter   157/  209] train: loss: 0.1030398
[Epoch 38; Iter   187/  209] train: loss: 0.0633222
[Epoch 38] ogbg-moltox21: 0.778627 val loss: 1.873306
[Epoch 38] ogbg-moltox21: 0.728410 test loss: 1.764092
[Epoch 39; Iter     8/  209] train: loss: 0.0841487
[Epoch 39; Iter    38/  209] train: loss: 0.0812364
[Epoch 39; Iter    68/  209] train: loss: 0.1048885
[Epoch 39; Iter    98/  209] train: loss: 0.1314730
[Epoch 39; Iter   128/  209] train: loss: 0.0865128
[Epoch 39; Iter   158/  209] train: loss: 0.0730495
[Epoch 39; Iter   188/  209] train: loss: 0.0948199
[Epoch 39] ogbg-moltox21: 0.768114 val loss: 0.323296
[Epoch 39] ogbg-moltox21: 0.737509 test loss: 0.353422
[Epoch 40; Iter     9/  209] train: loss: 0.1151618
[Epoch 40; Iter    39/  209] train: loss: 0.0855751
[Epoch 40; Iter    69/  209] train: loss: 0.0854867
[Epoch 40; Iter    99/  209] train: loss: 0.1115482
[Epoch 40; Iter   129/  209] train: loss: 0.0700222
[Epoch 40; Iter   159/  209] train: loss: 0.0951445
[Epoch 40; Iter   189/  209] train: loss: 0.1330737
[Epoch 40] ogbg-moltox21: 0.761251 val loss: 0.437780
[Epoch 40] ogbg-moltox21: 0.727199 test loss: 0.351748
[Epoch 41; Iter    10/  209] train: loss: 0.0591118
[Epoch 41; Iter    40/  209] train: loss: 0.1211895
[Epoch 41; Iter    70/  209] train: loss: 0.1046136
[Epoch 41; Iter   100/  209] train: loss: 0.1279851
[Epoch 41; Iter   130/  209] train: loss: 0.0989508
[Epoch 41; Iter   160/  209] train: loss: 0.1111918
[Epoch 41; Iter   190/  209] train: loss: 0.0629703
[Epoch 41] ogbg-moltox21: 0.744094 val loss: 0.422129
[Epoch 41] ogbg-moltox21: 0.717247 test loss: 0.398679
[Epoch 42; Iter    11/  209] train: loss: 0.1032852
[Epoch 42; Iter    41/  209] train: loss: 0.0767556
[Epoch 42; Iter    71/  209] train: loss: 0.0850930
[Epoch 42; Iter   101/  209] train: loss: 0.0939700
[Epoch 42; Iter   131/  209] train: loss: 0.1062423
[Epoch 42; Iter   161/  209] train: loss: 0.0475204
[Epoch 42; Iter   191/  209] train: loss: 0.0299945
[Epoch 42] ogbg-moltox21: 0.747225 val loss: 0.370566
[Epoch 42] ogbg-moltox21: 0.715202 test loss: 0.493292
[Epoch 43; Iter    12/  209] train: loss: 0.1028144
[Epoch 43; Iter    42/  209] train: loss: 0.0650494
[Epoch 43; Iter    72/  209] train: loss: 0.1501254
[Epoch 43; Iter   102/  209] train: loss: 0.1017686
[Epoch 43; Iter   132/  209] train: loss: 0.1022689
[Epoch 43; Iter   162/  209] train: loss: 0.0562805
[Epoch 43; Iter   192/  209] train: loss: 0.0829668
[Epoch 43] ogbg-moltox21: 0.752480 val loss: 0.633292
[Epoch 43] ogbg-moltox21: 0.721825 test loss: 0.616208
[Epoch 44; Iter    13/  209] train: loss: 0.0496138
[Epoch 44; Iter    43/  209] train: loss: 0.0725008
[Epoch 44; Iter    73/  209] train: loss: 0.0570835
[Epoch 44; Iter   103/  209] train: loss: 0.1056075
[Epoch 44; Iter   133/  209] train: loss: 0.0627026
[Epoch 44; Iter   163/  209] train: loss: 0.0746528
[Epoch 44; Iter   193/  209] train: loss: 0.1061955
[Epoch 44] ogbg-moltox21: 0.741690 val loss: 0.514648
[Epoch 44] ogbg-moltox21: 0.709092 test loss: 0.590721
[Epoch 45; Iter    14/  209] train: loss: 0.0793279
[Epoch 45; Iter    44/  209] train: loss: 0.0573893
[Epoch 45; Iter    74/  209] train: loss: 0.0554906
[Epoch 45; Iter   104/  209] train: loss: 0.0714477
[Epoch 45; Iter   134/  209] train: loss: 0.0790473
[Epoch 45; Iter   164/  209] train: loss: 0.0613230
[Epoch 45; Iter   194/  209] train: loss: 0.0951542
[Epoch 45] ogbg-moltox21: 0.755865 val loss: 0.350501
[Epoch 45] ogbg-moltox21: 0.714823 test loss: 0.418109
[Epoch 46; Iter    15/  209] train: loss: 0.0822983
[Epoch 46; Iter    45/  209] train: loss: 0.0959535
[Epoch 46; Iter    75/  209] train: loss: 0.0542750
[Epoch 46; Iter   105/  209] train: loss: 0.0829233
[Epoch 46; Iter   135/  209] train: loss: 0.0808009
[Epoch 46; Iter   165/  209] train: loss: 0.0550223
[Epoch 46; Iter   195/  209] train: loss: 0.1198188
[Epoch 46] ogbg-moltox21: 0.755068 val loss: 0.410462
[Epoch 46] ogbg-moltox21: 0.725030 test loss: 0.535537
[Epoch 47; Iter    16/  209] train: loss: 0.0542405
[Epoch 47; Iter    46/  209] train: loss: 0.0419065
[Epoch 47; Iter    76/  209] train: loss: 0.0727061
[Epoch 47; Iter   106/  209] train: loss: 0.0566355
[Epoch 47; Iter   136/  209] train: loss: 0.0918876
[Epoch 30; Iter    89/  209] train: loss: 0.1698321
[Epoch 30; Iter   119/  209] train: loss: 0.1481023
[Epoch 30; Iter   149/  209] train: loss: 0.1449955
[Epoch 30; Iter   179/  209] train: loss: 0.1330909
[Epoch 30; Iter   209/  209] train: loss: 0.1773718
[Epoch 30] ogbg-moltox21: 0.765483 val loss: 0.453765
[Epoch 30] ogbg-moltox21: 0.730174 test loss: 0.309087
[Epoch 31; Iter    30/  209] train: loss: 0.1837231
[Epoch 31; Iter    60/  209] train: loss: 0.1610275
[Epoch 31; Iter    90/  209] train: loss: 0.1069571
[Epoch 31; Iter   120/  209] train: loss: 0.1414310
[Epoch 31; Iter   150/  209] train: loss: 0.1643365
[Epoch 31; Iter   180/  209] train: loss: 0.1846242
[Epoch 31] ogbg-moltox21: 0.778336 val loss: 0.262376
[Epoch 31] ogbg-moltox21: 0.746356 test loss: 0.282383
[Epoch 32; Iter     1/  209] train: loss: 0.1774347
[Epoch 32; Iter    31/  209] train: loss: 0.1932462
[Epoch 32; Iter    61/  209] train: loss: 0.1297737
[Epoch 32; Iter    91/  209] train: loss: 0.1037710
[Epoch 32; Iter   121/  209] train: loss: 0.1534884
[Epoch 32; Iter   151/  209] train: loss: 0.1312004
[Epoch 32; Iter   181/  209] train: loss: 0.1450257
[Epoch 32] ogbg-moltox21: 0.787387 val loss: 0.276056
[Epoch 32] ogbg-moltox21: 0.743173 test loss: 0.281375
[Epoch 33; Iter     2/  209] train: loss: 0.1417929
[Epoch 33; Iter    32/  209] train: loss: 0.1662013
[Epoch 33; Iter    62/  209] train: loss: 0.2035599
[Epoch 33; Iter    92/  209] train: loss: 0.1859013
[Epoch 33; Iter   122/  209] train: loss: 0.2238209
[Epoch 33; Iter   152/  209] train: loss: 0.1359390
[Epoch 33; Iter   182/  209] train: loss: 0.1120007
[Epoch 33] ogbg-moltox21: 0.768953 val loss: 0.271749
[Epoch 33] ogbg-moltox21: 0.723576 test loss: 0.290618
[Epoch 34; Iter     3/  209] train: loss: 0.1619961
[Epoch 34; Iter    33/  209] train: loss: 0.2198197
[Epoch 34; Iter    63/  209] train: loss: 0.1627475
[Epoch 34; Iter    93/  209] train: loss: 0.1746186
[Epoch 34; Iter   123/  209] train: loss: 0.1351413
[Epoch 34; Iter   153/  209] train: loss: 0.2348241
[Epoch 34; Iter   183/  209] train: loss: 0.1103713
[Epoch 34] ogbg-moltox21: 0.764833 val loss: 0.285094
[Epoch 34] ogbg-moltox21: 0.721321 test loss: 0.304303
[Epoch 35; Iter     4/  209] train: loss: 0.1611485
[Epoch 35; Iter    34/  209] train: loss: 0.1329901
[Epoch 35; Iter    64/  209] train: loss: 0.1576302
[Epoch 35; Iter    94/  209] train: loss: 0.1187985
[Epoch 35; Iter   124/  209] train: loss: 0.2785753
[Epoch 35; Iter   154/  209] train: loss: 0.1735219
[Epoch 35; Iter   184/  209] train: loss: 0.1986763
[Epoch 35] ogbg-moltox21: 0.772136 val loss: 0.275825
[Epoch 35] ogbg-moltox21: 0.727564 test loss: 0.299918
[Epoch 36; Iter     5/  209] train: loss: 0.1429422
[Epoch 36; Iter    35/  209] train: loss: 0.1318974
[Epoch 36; Iter    65/  209] train: loss: 0.1052729
[Epoch 36; Iter    95/  209] train: loss: 0.1627798
[Epoch 36; Iter   125/  209] train: loss: 0.1940822
[Epoch 36; Iter   155/  209] train: loss: 0.1399458
[Epoch 36; Iter   185/  209] train: loss: 0.1244852
[Epoch 36] ogbg-moltox21: 0.760862 val loss: 0.325916
[Epoch 36] ogbg-moltox21: 0.718450 test loss: 0.315576
[Epoch 37; Iter     6/  209] train: loss: 0.1147973
[Epoch 37; Iter    36/  209] train: loss: 0.1834704
[Epoch 37; Iter    66/  209] train: loss: 0.1124589
[Epoch 37; Iter    96/  209] train: loss: 0.1164470
[Epoch 37; Iter   126/  209] train: loss: 0.1457551
[Epoch 37; Iter   156/  209] train: loss: 0.1348257
[Epoch 37; Iter   186/  209] train: loss: 0.2041879
[Epoch 37] ogbg-moltox21: 0.762704 val loss: 0.274902
[Epoch 37] ogbg-moltox21: 0.722039 test loss: 0.292519
[Epoch 38; Iter     7/  209] train: loss: 0.1370362
[Epoch 38; Iter    37/  209] train: loss: 0.0974220
[Epoch 38; Iter    67/  209] train: loss: 0.0952662
[Epoch 38; Iter    97/  209] train: loss: 0.1066631
[Epoch 38; Iter   127/  209] train: loss: 0.1616288
[Epoch 38; Iter   157/  209] train: loss: 0.1298562
[Epoch 38; Iter   187/  209] train: loss: 0.2007312
[Epoch 38] ogbg-moltox21: 0.748777 val loss: 0.296307
[Epoch 38] ogbg-moltox21: 0.705671 test loss: 0.315236
[Epoch 39; Iter     8/  209] train: loss: 0.1183908
[Epoch 39; Iter    38/  209] train: loss: 0.1054195
[Epoch 39; Iter    68/  209] train: loss: 0.1140596
[Epoch 39; Iter    98/  209] train: loss: 0.1063725
[Epoch 39; Iter   128/  209] train: loss: 0.1841098
[Epoch 39; Iter   158/  209] train: loss: 0.1054182
[Epoch 39; Iter   188/  209] train: loss: 0.0869059
[Epoch 39] ogbg-moltox21: 0.762135 val loss: 0.299219
[Epoch 39] ogbg-moltox21: 0.717506 test loss: 0.317808
[Epoch 40; Iter     9/  209] train: loss: 0.1239575
[Epoch 40; Iter    39/  209] train: loss: 0.1125043
[Epoch 40; Iter    69/  209] train: loss: 0.1630928
[Epoch 40; Iter    99/  209] train: loss: 0.1179780
[Epoch 40; Iter   129/  209] train: loss: 0.0777872
[Epoch 40; Iter   159/  209] train: loss: 0.1498551
[Epoch 40; Iter   189/  209] train: loss: 0.1790846
[Epoch 40] ogbg-moltox21: 0.764429 val loss: 0.306342
[Epoch 40] ogbg-moltox21: 0.720585 test loss: 0.319270
[Epoch 41; Iter    10/  209] train: loss: 0.0893575
[Epoch 41; Iter    40/  209] train: loss: 0.1510682
[Epoch 41; Iter    70/  209] train: loss: 0.0783900
[Epoch 41; Iter   100/  209] train: loss: 0.1225944
[Epoch 41; Iter   130/  209] train: loss: 0.1872245
[Epoch 41; Iter   160/  209] train: loss: 0.1543272
[Epoch 41; Iter   190/  209] train: loss: 0.1967739
[Epoch 41] ogbg-moltox21: 0.749811 val loss: 0.310628
[Epoch 41] ogbg-moltox21: 0.711700 test loss: 0.342439
[Epoch 42; Iter    11/  209] train: loss: 0.1185007
[Epoch 42; Iter    41/  209] train: loss: 0.0919143
[Epoch 42; Iter    71/  209] train: loss: 0.1267898
[Epoch 42; Iter   101/  209] train: loss: 0.0875042
[Epoch 42; Iter   131/  209] train: loss: 0.0788521
[Epoch 42; Iter   161/  209] train: loss: 0.1384810
[Epoch 42; Iter   191/  209] train: loss: 0.1276335
[Epoch 42] ogbg-moltox21: 0.743158 val loss: 0.319580
[Epoch 42] ogbg-moltox21: 0.715226 test loss: 0.339596
[Epoch 43; Iter    12/  209] train: loss: 0.1012422
[Epoch 43; Iter    42/  209] train: loss: 0.1254160
[Epoch 43; Iter    72/  209] train: loss: 0.1071074
[Epoch 43; Iter   102/  209] train: loss: 0.1322349
[Epoch 43; Iter   132/  209] train: loss: 0.0996860
[Epoch 43; Iter   162/  209] train: loss: 0.0722719
[Epoch 43; Iter   192/  209] train: loss: 0.0937271
[Epoch 43] ogbg-moltox21: 0.743510 val loss: 0.303852
[Epoch 43] ogbg-moltox21: 0.707565 test loss: 0.326052
[Epoch 44; Iter    13/  209] train: loss: 0.0813495
[Epoch 44; Iter    43/  209] train: loss: 0.1066812
[Epoch 44; Iter    73/  209] train: loss: 0.0729251
[Epoch 44; Iter   103/  209] train: loss: 0.1626028
[Epoch 44; Iter   133/  209] train: loss: 0.1359154
[Epoch 44; Iter   163/  209] train: loss: 0.1451573
[Epoch 44; Iter   193/  209] train: loss: 0.1339810
[Epoch 44] ogbg-moltox21: 0.748573 val loss: 0.314469
[Epoch 44] ogbg-moltox21: 0.712731 test loss: 0.345751
[Epoch 45; Iter    14/  209] train: loss: 0.1242053
[Epoch 45; Iter    44/  209] train: loss: 0.0898320
[Epoch 45; Iter    74/  209] train: loss: 0.1351060
[Epoch 45; Iter   104/  209] train: loss: 0.1088363
[Epoch 45; Iter   134/  209] train: loss: 0.0821781
[Epoch 45; Iter   164/  209] train: loss: 0.0897039
[Epoch 45; Iter   194/  209] train: loss: 0.1077974
[Epoch 45] ogbg-moltox21: 0.749790 val loss: 0.318487
[Epoch 45] ogbg-moltox21: 0.715396 test loss: 0.350242
[Epoch 46; Iter    15/  209] train: loss: 0.0687920
[Epoch 46; Iter    45/  209] train: loss: 0.1081311
[Epoch 46; Iter    75/  209] train: loss: 0.1118422
[Epoch 46; Iter   105/  209] train: loss: 0.1075025
[Epoch 46; Iter   135/  209] train: loss: 0.1555174
[Epoch 46; Iter   165/  209] train: loss: 0.2084353
[Epoch 46; Iter   195/  209] train: loss: 0.1178174
[Epoch 46] ogbg-moltox21: 0.739570 val loss: 0.306905
[Epoch 46] ogbg-moltox21: 0.708854 test loss: 0.325202
[Epoch 47; Iter    16/  209] train: loss: 0.1038416
[Epoch 47; Iter    46/  209] train: loss: 0.0711893
[Epoch 47; Iter    76/  209] train: loss: 0.1648883
[Epoch 47; Iter   106/  209] train: loss: 0.1258442
[Epoch 47; Iter   136/  209] train: loss: 0.1111804
[Epoch 30; Iter    89/  209] train: loss: 0.1273844
[Epoch 30; Iter   119/  209] train: loss: 0.1428817
[Epoch 30; Iter   149/  209] train: loss: 0.1253250
[Epoch 30; Iter   179/  209] train: loss: 0.2271982
[Epoch 30; Iter   209/  209] train: loss: 0.0990517
[Epoch 30] ogbg-moltox21: 0.766068 val loss: 0.303801
[Epoch 30] ogbg-moltox21: 0.728329 test loss: 0.318965
[Epoch 31; Iter    30/  209] train: loss: 0.1010589
[Epoch 31; Iter    60/  209] train: loss: 0.1303774
[Epoch 31; Iter    90/  209] train: loss: 0.1056741
[Epoch 31; Iter   120/  209] train: loss: 0.1495386
[Epoch 31; Iter   150/  209] train: loss: 0.1287812
[Epoch 31; Iter   180/  209] train: loss: 0.2073405
[Epoch 31] ogbg-moltox21: 0.721687 val loss: 0.387700
[Epoch 31] ogbg-moltox21: 0.675876 test loss: 0.525577
[Epoch 32; Iter     1/  209] train: loss: 0.1574115
[Epoch 32; Iter    31/  209] train: loss: 0.1060854
[Epoch 32; Iter    61/  209] train: loss: 0.1828176
[Epoch 32; Iter    91/  209] train: loss: 0.0991609
[Epoch 32; Iter   121/  209] train: loss: 0.1433562
[Epoch 32; Iter   151/  209] train: loss: 0.1494410
[Epoch 32; Iter   181/  209] train: loss: 0.1906273
[Epoch 32] ogbg-moltox21: 0.756567 val loss: 0.315691
[Epoch 32] ogbg-moltox21: 0.715223 test loss: 0.338457
[Epoch 33; Iter     2/  209] train: loss: 0.1148991
[Epoch 33; Iter    32/  209] train: loss: 0.1116926
[Epoch 33; Iter    62/  209] train: loss: 0.1085287
[Epoch 33; Iter    92/  209] train: loss: 0.1683888
[Epoch 33; Iter   122/  209] train: loss: 0.0942854
[Epoch 33; Iter   152/  209] train: loss: 0.0915105
[Epoch 33; Iter   182/  209] train: loss: 0.1066145
[Epoch 33] ogbg-moltox21: 0.748336 val loss: 0.328993
[Epoch 33] ogbg-moltox21: 0.721129 test loss: 0.348896
[Epoch 34; Iter     3/  209] train: loss: 0.0727337
[Epoch 34; Iter    33/  209] train: loss: 0.1067614
[Epoch 34; Iter    63/  209] train: loss: 0.1223562
[Epoch 34; Iter    93/  209] train: loss: 0.1732398
[Epoch 34; Iter   123/  209] train: loss: 0.0947362
[Epoch 34; Iter   153/  209] train: loss: 0.1700425
[Epoch 34; Iter   183/  209] train: loss: 0.0906290
[Epoch 34] ogbg-moltox21: 0.760053 val loss: 0.405002
[Epoch 34] ogbg-moltox21: 0.720028 test loss: 0.378329
[Epoch 35; Iter     4/  209] train: loss: 0.1546929
[Epoch 35; Iter    34/  209] train: loss: 0.1272362
[Epoch 35; Iter    64/  209] train: loss: 0.1650438
[Epoch 35; Iter    94/  209] train: loss: 0.1081901
[Epoch 35; Iter   124/  209] train: loss: 0.1526881
[Epoch 35; Iter   154/  209] train: loss: 0.1098004
[Epoch 35; Iter   184/  209] train: loss: 0.1861723
[Epoch 35] ogbg-moltox21: 0.732129 val loss: 0.456619
[Epoch 35] ogbg-moltox21: 0.707337 test loss: 0.418822
[Epoch 36; Iter     5/  209] train: loss: 0.1285944
[Epoch 36; Iter    35/  209] train: loss: 0.1492517
[Epoch 36; Iter    65/  209] train: loss: 0.1207063
[Epoch 36; Iter    95/  209] train: loss: 0.1468621
[Epoch 36; Iter   125/  209] train: loss: 0.1290913
[Epoch 36; Iter   155/  209] train: loss: 0.1190116
[Epoch 36; Iter   185/  209] train: loss: 0.1339009
[Epoch 36] ogbg-moltox21: 0.743932 val loss: 0.355865
[Epoch 36] ogbg-moltox21: 0.714855 test loss: 0.371627
[Epoch 37; Iter     6/  209] train: loss: 0.1057013
[Epoch 37; Iter    36/  209] train: loss: 0.1345786
[Epoch 37; Iter    66/  209] train: loss: 0.1378162
[Epoch 37; Iter    96/  209] train: loss: 0.1080210
[Epoch 37; Iter   126/  209] train: loss: 0.1213958
[Epoch 37; Iter   156/  209] train: loss: 0.0902380
[Epoch 37; Iter   186/  209] train: loss: 0.1111271
[Epoch 37] ogbg-moltox21: 0.762875 val loss: 0.379593
[Epoch 37] ogbg-moltox21: 0.719356 test loss: 0.406330
[Epoch 38; Iter     7/  209] train: loss: 0.1575227
[Epoch 38; Iter    37/  209] train: loss: 0.1362109
[Epoch 38; Iter    67/  209] train: loss: 0.1116682
[Epoch 38; Iter    97/  209] train: loss: 0.0735066
[Epoch 38; Iter   127/  209] train: loss: 0.0773780
[Epoch 38; Iter   157/  209] train: loss: 0.1132422
[Epoch 38; Iter   187/  209] train: loss: 0.0769714
[Epoch 38] ogbg-moltox21: 0.752669 val loss: 0.477308
[Epoch 38] ogbg-moltox21: 0.713943 test loss: 0.464148
[Epoch 39; Iter     8/  209] train: loss: 0.0742998
[Epoch 39; Iter    38/  209] train: loss: 0.0827745
[Epoch 39; Iter    68/  209] train: loss: 0.0985187
[Epoch 39; Iter    98/  209] train: loss: 0.1145409
[Epoch 39; Iter   128/  209] train: loss: 0.0903781
[Epoch 39; Iter   158/  209] train: loss: 0.0903852
[Epoch 39; Iter   188/  209] train: loss: 0.1002735
[Epoch 39] ogbg-moltox21: 0.758814 val loss: 0.387940
[Epoch 39] ogbg-moltox21: 0.718963 test loss: 0.414002
[Epoch 40; Iter     9/  209] train: loss: 0.0810679
[Epoch 40; Iter    39/  209] train: loss: 0.0783461
[Epoch 40; Iter    69/  209] train: loss: 0.0792602
[Epoch 40; Iter    99/  209] train: loss: 0.0870573
[Epoch 40; Iter   129/  209] train: loss: 0.0696558
[Epoch 40; Iter   159/  209] train: loss: 0.0844067
[Epoch 40; Iter   189/  209] train: loss: 0.1147722
[Epoch 40] ogbg-moltox21: 0.746514 val loss: 0.485109
[Epoch 40] ogbg-moltox21: 0.718282 test loss: 0.473779
[Epoch 41; Iter    10/  209] train: loss: 0.0882177
[Epoch 41; Iter    40/  209] train: loss: 0.1301028
[Epoch 41; Iter    70/  209] train: loss: 0.1328822
[Epoch 41; Iter   100/  209] train: loss: 0.1714960
[Epoch 41; Iter   130/  209] train: loss: 0.0962931
[Epoch 41; Iter   160/  209] train: loss: 0.0880892
[Epoch 41; Iter   190/  209] train: loss: 0.0744603
[Epoch 41] ogbg-moltox21: 0.746747 val loss: 0.453746
[Epoch 41] ogbg-moltox21: 0.707669 test loss: 0.446988
[Epoch 42; Iter    11/  209] train: loss: 0.0950348
[Epoch 42; Iter    41/  209] train: loss: 0.0660833
[Epoch 42; Iter    71/  209] train: loss: 0.0945613
[Epoch 42; Iter   101/  209] train: loss: 0.1153953
[Epoch 42; Iter   131/  209] train: loss: 0.1281433
[Epoch 42; Iter   161/  209] train: loss: 0.0536203
[Epoch 42; Iter   191/  209] train: loss: 0.0467467
[Epoch 42] ogbg-moltox21: 0.750343 val loss: 0.410192
[Epoch 42] ogbg-moltox21: 0.714057 test loss: 0.431970
[Epoch 43; Iter    12/  209] train: loss: 0.0780238
[Epoch 43; Iter    42/  209] train: loss: 0.0853027
[Epoch 43; Iter    72/  209] train: loss: 0.1416579
[Epoch 43; Iter   102/  209] train: loss: 0.1067296
[Epoch 43; Iter   132/  209] train: loss: 0.0928862
[Epoch 43; Iter   162/  209] train: loss: 0.0655865
[Epoch 43; Iter   192/  209] train: loss: 0.0544498
[Epoch 43] ogbg-moltox21: 0.753579 val loss: 0.434203
[Epoch 43] ogbg-moltox21: 0.716614 test loss: 0.419346
[Epoch 44; Iter    13/  209] train: loss: 0.0444860
[Epoch 44; Iter    43/  209] train: loss: 0.0721894
[Epoch 44; Iter    73/  209] train: loss: 0.0536982
[Epoch 44; Iter   103/  209] train: loss: 0.1090091
[Epoch 44; Iter   133/  209] train: loss: 0.0677167
[Epoch 44; Iter   163/  209] train: loss: 0.0770913
[Epoch 44; Iter   193/  209] train: loss: 0.1188224
[Epoch 44] ogbg-moltox21: 0.744042 val loss: 0.446035
[Epoch 44] ogbg-moltox21: 0.714324 test loss: 0.470163
[Epoch 45; Iter    14/  209] train: loss: 0.0728004
[Epoch 45; Iter    44/  209] train: loss: 0.0629683
[Epoch 45; Iter    74/  209] train: loss: 0.0684076
[Epoch 45; Iter   104/  209] train: loss: 0.0854679
[Epoch 45; Iter   134/  209] train: loss: 0.1027978
[Epoch 45; Iter   164/  209] train: loss: 0.0729852
[Epoch 45; Iter   194/  209] train: loss: 0.0754329
[Epoch 45] ogbg-moltox21: 0.757954 val loss: 0.418661
[Epoch 45] ogbg-moltox21: 0.717279 test loss: 0.455390
[Epoch 46; Iter    15/  209] train: loss: 0.0770323
[Epoch 46; Iter    45/  209] train: loss: 0.1039478
[Epoch 46; Iter    75/  209] train: loss: 0.0708510
[Epoch 46; Iter   105/  209] train: loss: 0.0709910
[Epoch 46; Iter   135/  209] train: loss: 0.1105031
[Epoch 46; Iter   165/  209] train: loss: 0.0553780
[Epoch 46; Iter   195/  209] train: loss: 0.1184616
[Epoch 46] ogbg-moltox21: 0.761037 val loss: 0.413278
[Epoch 46] ogbg-moltox21: 0.705890 test loss: 0.454649
[Epoch 47; Iter    16/  209] train: loss: 0.0591715
[Epoch 47; Iter    46/  209] train: loss: 0.0498752
[Epoch 47; Iter    76/  209] train: loss: 0.0732898
[Epoch 47; Iter   106/  209] train: loss: 0.0489268
[Epoch 47; Iter   136/  209] train: loss: 0.0999992
[Epoch 30; Iter    89/  209] train: loss: 0.1477000
[Epoch 30; Iter   119/  209] train: loss: 0.1644742
[Epoch 30; Iter   149/  209] train: loss: 0.1568861
[Epoch 30; Iter   179/  209] train: loss: 0.2283808
[Epoch 30; Iter   209/  209] train: loss: 0.1115657
[Epoch 30] ogbg-moltox21: 0.812446 val loss: 0.247302
[Epoch 30] ogbg-moltox21: 0.758561 test loss: 0.268800
[Epoch 31; Iter    30/  209] train: loss: 0.1021949
[Epoch 31; Iter    60/  209] train: loss: 0.1120013
[Epoch 31; Iter    90/  209] train: loss: 0.1534823
[Epoch 31; Iter   120/  209] train: loss: 0.1218826
[Epoch 31; Iter   150/  209] train: loss: 0.1438671
[Epoch 31; Iter   180/  209] train: loss: 0.2005885
[Epoch 31] ogbg-moltox21: 0.791315 val loss: 0.261778
[Epoch 31] ogbg-moltox21: 0.742307 test loss: 0.375516
[Epoch 32; Iter     1/  209] train: loss: 0.1648425
[Epoch 32; Iter    31/  209] train: loss: 0.1122508
[Epoch 32; Iter    61/  209] train: loss: 0.2057685
[Epoch 32; Iter    91/  209] train: loss: 0.1748234
[Epoch 32; Iter   121/  209] train: loss: 0.1934103
[Epoch 32; Iter   151/  209] train: loss: 0.1892139
[Epoch 32; Iter   181/  209] train: loss: 0.2644940
[Epoch 32] ogbg-moltox21: 0.792068 val loss: 0.253185
[Epoch 32] ogbg-moltox21: 0.755249 test loss: 0.269233
[Epoch 33; Iter     2/  209] train: loss: 0.1455433
[Epoch 33; Iter    32/  209] train: loss: 0.1187417
[Epoch 33; Iter    62/  209] train: loss: 0.1533946
[Epoch 33; Iter    92/  209] train: loss: 0.1639631
[Epoch 33; Iter   122/  209] train: loss: 0.0907349
[Epoch 33; Iter   152/  209] train: loss: 0.1077293
[Epoch 33; Iter   182/  209] train: loss: 0.1181713
[Epoch 33] ogbg-moltox21: 0.802245 val loss: 0.245780
[Epoch 33] ogbg-moltox21: 0.753814 test loss: 0.262470
[Epoch 34; Iter     3/  209] train: loss: 0.0939306
[Epoch 34; Iter    33/  209] train: loss: 0.1280762
[Epoch 34; Iter    63/  209] train: loss: 0.1509240
[Epoch 34; Iter    93/  209] train: loss: 0.1784656
[Epoch 34; Iter   123/  209] train: loss: 0.1047645
[Epoch 34; Iter   153/  209] train: loss: 0.1581388
[Epoch 34; Iter   183/  209] train: loss: 0.1258428
[Epoch 34] ogbg-moltox21: 0.798142 val loss: 0.249818
[Epoch 34] ogbg-moltox21: 0.756526 test loss: 0.286471
[Epoch 35; Iter     4/  209] train: loss: 0.1785123
[Epoch 35; Iter    34/  209] train: loss: 0.1757457
[Epoch 35; Iter    64/  209] train: loss: 0.1594818
[Epoch 35; Iter    94/  209] train: loss: 0.1283702
[Epoch 35; Iter   124/  209] train: loss: 0.1476903
[Epoch 35; Iter   154/  209] train: loss: 0.1288017
[Epoch 35; Iter   184/  209] train: loss: 0.2088730
[Epoch 35] ogbg-moltox21: 0.802437 val loss: 0.265658
[Epoch 35] ogbg-moltox21: 0.762003 test loss: 0.285887
[Epoch 36; Iter     5/  209] train: loss: 0.1519642
[Epoch 36; Iter    35/  209] train: loss: 0.1980737
[Epoch 36; Iter    65/  209] train: loss: 0.1420926
[Epoch 36; Iter    95/  209] train: loss: 0.1799313
[Epoch 36; Iter   125/  209] train: loss: 0.1865780
[Epoch 36; Iter   155/  209] train: loss: 0.1265157
[Epoch 36; Iter   185/  209] train: loss: 0.1475448
[Epoch 36] ogbg-moltox21: 0.799650 val loss: 0.259137
[Epoch 36] ogbg-moltox21: 0.763441 test loss: 0.285244
[Epoch 37; Iter     6/  209] train: loss: 0.1182235
[Epoch 37; Iter    36/  209] train: loss: 0.1716320
[Epoch 37; Iter    66/  209] train: loss: 0.1708413
[Epoch 37; Iter    96/  209] train: loss: 0.1259496
[Epoch 37; Iter   126/  209] train: loss: 0.1638982
[Epoch 37; Iter   156/  209] train: loss: 0.1211989
[Epoch 37; Iter   186/  209] train: loss: 0.1408956
[Epoch 37] ogbg-moltox21: 0.800737 val loss: 0.244096
[Epoch 37] ogbg-moltox21: 0.757711 test loss: 0.277542
[Epoch 38; Iter     7/  209] train: loss: 0.2102100
[Epoch 38; Iter    37/  209] train: loss: 0.1729636
[Epoch 38; Iter    67/  209] train: loss: 0.1120211
[Epoch 38; Iter    97/  209] train: loss: 0.1124964
[Epoch 38; Iter   127/  209] train: loss: 0.0916187
[Epoch 38; Iter   157/  209] train: loss: 0.1278631
[Epoch 38; Iter   187/  209] train: loss: 0.1126699
[Epoch 38] ogbg-moltox21: 0.800115 val loss: 0.324640
[Epoch 38] ogbg-moltox21: 0.760361 test loss: 0.397851
[Epoch 39; Iter     8/  209] train: loss: 0.1472326
[Epoch 39; Iter    38/  209] train: loss: 0.1032637
[Epoch 39; Iter    68/  209] train: loss: 0.1408696
[Epoch 39; Iter    98/  209] train: loss: 0.1398710
[Epoch 39; Iter   128/  209] train: loss: 0.1220746
[Epoch 39; Iter   158/  209] train: loss: 0.1439468
[Epoch 39; Iter   188/  209] train: loss: 0.1218626
[Epoch 39] ogbg-moltox21: 0.802279 val loss: 0.252607
[Epoch 39] ogbg-moltox21: 0.755638 test loss: 0.270801
[Epoch 40; Iter     9/  209] train: loss: 0.0968417
[Epoch 40; Iter    39/  209] train: loss: 0.1052817
[Epoch 40; Iter    69/  209] train: loss: 0.1475676
[Epoch 40; Iter    99/  209] train: loss: 0.1505210
[Epoch 40; Iter   129/  209] train: loss: 0.0968151
[Epoch 40; Iter   159/  209] train: loss: 0.1193765
[Epoch 40; Iter   189/  209] train: loss: 0.1975942
[Epoch 40] ogbg-moltox21: 0.798319 val loss: 0.323584
[Epoch 40] ogbg-moltox21: 0.760680 test loss: 0.385298
[Epoch 41; Iter    10/  209] train: loss: 0.1062868
[Epoch 41; Iter    40/  209] train: loss: 0.1650251
[Epoch 41; Iter    70/  209] train: loss: 0.1197105
[Epoch 41; Iter   100/  209] train: loss: 0.2052442
[Epoch 41; Iter   130/  209] train: loss: 0.1374611
[Epoch 41; Iter   160/  209] train: loss: 0.1564444
[Epoch 41; Iter   190/  209] train: loss: 0.1126876
[Epoch 41] ogbg-moltox21: 0.799662 val loss: 0.279054
[Epoch 41] ogbg-moltox21: 0.760629 test loss: 0.326068
[Epoch 42; Iter    11/  209] train: loss: 0.1259931
[Epoch 42; Iter    41/  209] train: loss: 0.0958461
[Epoch 42; Iter    71/  209] train: loss: 0.0975739
[Epoch 42; Iter   101/  209] train: loss: 0.1929215
[Epoch 42; Iter   131/  209] train: loss: 0.1510225
[Epoch 42; Iter   161/  209] train: loss: 0.0853753
[Epoch 42; Iter   191/  209] train: loss: 0.0577312
[Epoch 42] ogbg-moltox21: 0.792565 val loss: 0.271661
[Epoch 42] ogbg-moltox21: 0.760012 test loss: 0.310370
[Epoch 43; Iter    12/  209] train: loss: 0.1273579
[Epoch 43; Iter    42/  209] train: loss: 0.0983548
[Epoch 43; Iter    72/  209] train: loss: 0.1837264
[Epoch 43; Iter   102/  209] train: loss: 0.1702045
[Epoch 43; Iter   132/  209] train: loss: 0.1593043
[Epoch 43; Iter   162/  209] train: loss: 0.1181340
[Epoch 43; Iter   192/  209] train: loss: 0.0900279
[Epoch 43] ogbg-moltox21: 0.798487 val loss: 0.269388
[Epoch 43] ogbg-moltox21: 0.767647 test loss: 0.297506
[Epoch 44; Iter    13/  209] train: loss: 0.0955341
[Epoch 44; Iter    43/  209] train: loss: 0.0888018
[Epoch 44; Iter    73/  209] train: loss: 0.0733832
[Epoch 44; Iter   103/  209] train: loss: 0.2106149
[Epoch 44; Iter   133/  209] train: loss: 0.1313561
[Epoch 44; Iter   163/  209] train: loss: 0.1094604
[Epoch 44; Iter   193/  209] train: loss: 0.1449910
[Epoch 44] ogbg-moltox21: 0.801411 val loss: 0.252781
[Epoch 44] ogbg-moltox21: 0.768386 test loss: 0.270889
[Epoch 45; Iter    14/  209] train: loss: 0.1186268
[Epoch 45; Iter    44/  209] train: loss: 0.1436605
[Epoch 45; Iter    74/  209] train: loss: 0.1006786
[Epoch 45; Iter   104/  209] train: loss: 0.1253514
[Epoch 45; Iter   134/  209] train: loss: 0.1387887
[Epoch 45; Iter   164/  209] train: loss: 0.1025059
[Epoch 45; Iter   194/  209] train: loss: 0.1610576
[Epoch 45] ogbg-moltox21: 0.797691 val loss: 0.266141
[Epoch 45] ogbg-moltox21: 0.760907 test loss: 0.282778
[Epoch 46; Iter    15/  209] train: loss: 0.0840534
[Epoch 46; Iter    45/  209] train: loss: 0.1755820
[Epoch 46; Iter    75/  209] train: loss: 0.1206893
[Epoch 46; Iter   105/  209] train: loss: 0.0879574
[Epoch 46; Iter   135/  209] train: loss: 0.1754207
[Epoch 46; Iter   165/  209] train: loss: 0.0736303
[Epoch 46; Iter   195/  209] train: loss: 0.1599055
[Epoch 46] ogbg-moltox21: 0.797542 val loss: 0.393736
[Epoch 46] ogbg-moltox21: 0.773938 test loss: 0.509603
[Epoch 47; Iter    16/  209] train: loss: 0.0941715
[Epoch 47; Iter    46/  209] train: loss: 0.0857592
[Epoch 47; Iter    76/  209] train: loss: 0.1160773
[Epoch 47; Iter   106/  209] train: loss: 0.0807716
[Epoch 47; Iter   136/  209] train: loss: 0.1483069
[Epoch 30; Iter    89/  209] train: loss: 0.1224147
[Epoch 30; Iter   119/  209] train: loss: 0.1457242
[Epoch 30; Iter   149/  209] train: loss: 0.2123370
[Epoch 30; Iter   179/  209] train: loss: 0.1155644
[Epoch 30; Iter   209/  209] train: loss: 0.2364495
[Epoch 30] ogbg-moltox21: 0.795221 val loss: 0.243492
[Epoch 30] ogbg-moltox21: 0.752620 test loss: 0.260026
[Epoch 31; Iter    30/  209] train: loss: 0.1633060
[Epoch 31; Iter    60/  209] train: loss: 0.1735555
[Epoch 31; Iter    90/  209] train: loss: 0.1861417
[Epoch 31; Iter   120/  209] train: loss: 0.1230997
[Epoch 31; Iter   150/  209] train: loss: 0.1044679
[Epoch 31; Iter   180/  209] train: loss: 0.2074080
[Epoch 31] ogbg-moltox21: 0.803291 val loss: 0.242818
[Epoch 31] ogbg-moltox21: 0.758521 test loss: 0.261727
[Epoch 32; Iter     1/  209] train: loss: 0.2137122
[Epoch 32; Iter    31/  209] train: loss: 0.1272694
[Epoch 32; Iter    61/  209] train: loss: 0.0855184
[Epoch 32; Iter    91/  209] train: loss: 0.1849321
[Epoch 32; Iter   121/  209] train: loss: 0.1684620
[Epoch 32; Iter   151/  209] train: loss: 0.2568490
[Epoch 32; Iter   181/  209] train: loss: 0.2006419
[Epoch 32] ogbg-moltox21: 0.785766 val loss: 0.252279
[Epoch 32] ogbg-moltox21: 0.762879 test loss: 0.268826
[Epoch 33; Iter     2/  209] train: loss: 0.1103980
[Epoch 33; Iter    32/  209] train: loss: 0.1191845
[Epoch 33; Iter    62/  209] train: loss: 0.1195129
[Epoch 33; Iter    92/  209] train: loss: 0.1196826
[Epoch 33; Iter   122/  209] train: loss: 0.1522615
[Epoch 33; Iter   152/  209] train: loss: 0.2223448
[Epoch 33; Iter   182/  209] train: loss: 0.2293432
[Epoch 33] ogbg-moltox21: 0.793481 val loss: 0.252815
[Epoch 33] ogbg-moltox21: 0.766240 test loss: 0.266886
[Epoch 34; Iter     3/  209] train: loss: 0.1015419
[Epoch 34; Iter    33/  209] train: loss: 0.1620918
[Epoch 34; Iter    63/  209] train: loss: 0.1648026
[Epoch 34; Iter    93/  209] train: loss: 0.0863155
[Epoch 34; Iter   123/  209] train: loss: 0.1461048
[Epoch 34; Iter   153/  209] train: loss: 0.1059206
[Epoch 34; Iter   183/  209] train: loss: 0.1421909
[Epoch 34] ogbg-moltox21: 0.800997 val loss: 0.247254
[Epoch 34] ogbg-moltox21: 0.759805 test loss: 0.265579
[Epoch 35; Iter     4/  209] train: loss: 0.1803083
[Epoch 35; Iter    34/  209] train: loss: 0.1339176
[Epoch 35; Iter    64/  209] train: loss: 0.1522807
[Epoch 35; Iter    94/  209] train: loss: 0.1911875
[Epoch 35; Iter   124/  209] train: loss: 0.2190392
[Epoch 35; Iter   154/  209] train: loss: 0.1809826
[Epoch 35; Iter   184/  209] train: loss: 0.1261663
[Epoch 35] ogbg-moltox21: 0.801757 val loss: 0.246833
[Epoch 35] ogbg-moltox21: 0.753363 test loss: 0.305454
[Epoch 36; Iter     5/  209] train: loss: 0.1350143
[Epoch 36; Iter    35/  209] train: loss: 0.1117993
[Epoch 36; Iter    65/  209] train: loss: 0.1929459
[Epoch 36; Iter    95/  209] train: loss: 0.1268607
[Epoch 36; Iter   125/  209] train: loss: 0.2407677
[Epoch 36; Iter   155/  209] train: loss: 0.1250998
[Epoch 36; Iter   185/  209] train: loss: 0.1520507
[Epoch 36] ogbg-moltox21: 0.802230 val loss: 0.268866
[Epoch 36] ogbg-moltox21: 0.765827 test loss: 0.323468
[Epoch 37; Iter     6/  209] train: loss: 0.0805647
[Epoch 37; Iter    36/  209] train: loss: 0.1613425
[Epoch 37; Iter    66/  209] train: loss: 0.1349742
[Epoch 37; Iter    96/  209] train: loss: 0.1611369
[Epoch 37; Iter   126/  209] train: loss: 0.0884457
[Epoch 37; Iter   156/  209] train: loss: 0.0954600
[Epoch 37; Iter   186/  209] train: loss: 0.1421354
[Epoch 37] ogbg-moltox21: 0.773612 val loss: 0.253793
[Epoch 37] ogbg-moltox21: 0.740695 test loss: 0.319187
[Epoch 38; Iter     7/  209] train: loss: 0.1383151
[Epoch 38; Iter    37/  209] train: loss: 0.1600878
[Epoch 38; Iter    67/  209] train: loss: 0.1124929
[Epoch 38; Iter    97/  209] train: loss: 0.1369359
[Epoch 38; Iter   127/  209] train: loss: 0.1579656
[Epoch 38; Iter   157/  209] train: loss: 0.1103786
[Epoch 38; Iter   187/  209] train: loss: 0.1299660
[Epoch 38] ogbg-moltox21: 0.788689 val loss: 0.251544
[Epoch 38] ogbg-moltox21: 0.756913 test loss: 0.268213
[Epoch 39; Iter     8/  209] train: loss: 0.1548382
[Epoch 39; Iter    38/  209] train: loss: 0.1489869
[Epoch 39; Iter    68/  209] train: loss: 0.1646644
[Epoch 39; Iter    98/  209] train: loss: 0.1384147
[Epoch 39; Iter   128/  209] train: loss: 0.0977937
[Epoch 39; Iter   158/  209] train: loss: 0.1322260
[Epoch 39; Iter   188/  209] train: loss: 0.0897976
[Epoch 39] ogbg-moltox21: 0.789759 val loss: 0.262248
[Epoch 39] ogbg-moltox21: 0.746624 test loss: 0.291233
[Epoch 40; Iter     9/  209] train: loss: 0.1652956
[Epoch 40; Iter    39/  209] train: loss: 0.3048211
[Epoch 40; Iter    69/  209] train: loss: 0.1096555
[Epoch 40; Iter    99/  209] train: loss: 0.1079138
[Epoch 40; Iter   129/  209] train: loss: 0.1310809
[Epoch 40; Iter   159/  209] train: loss: 0.1136202
[Epoch 40; Iter   189/  209] train: loss: 0.1471188
[Epoch 40] ogbg-moltox21: 0.800627 val loss: 0.247586
[Epoch 40] ogbg-moltox21: 0.758975 test loss: 0.268543
[Epoch 41; Iter    10/  209] train: loss: 0.1123801
[Epoch 41; Iter    40/  209] train: loss: 0.0773277
[Epoch 41; Iter    70/  209] train: loss: 0.0930680
[Epoch 41; Iter   100/  209] train: loss: 0.1237271
[Epoch 41; Iter   130/  209] train: loss: 0.1460051
[Epoch 41; Iter   160/  209] train: loss: 0.1550782
[Epoch 41; Iter   190/  209] train: loss: 0.1203188
[Epoch 41] ogbg-moltox21: 0.797558 val loss: 0.246320
[Epoch 41] ogbg-moltox21: 0.761329 test loss: 0.270052
[Epoch 42; Iter    11/  209] train: loss: 0.0958586
[Epoch 42; Iter    41/  209] train: loss: 0.1259599
[Epoch 42; Iter    71/  209] train: loss: 0.0987325
[Epoch 42; Iter   101/  209] train: loss: 0.1011397
[Epoch 42; Iter   131/  209] train: loss: 0.1579317
[Epoch 42; Iter   161/  209] train: loss: 0.1133389
[Epoch 42; Iter   191/  209] train: loss: 0.1124027
[Epoch 42] ogbg-moltox21: 0.792708 val loss: 0.249122
[Epoch 42] ogbg-moltox21: 0.749595 test loss: 0.274751
[Epoch 43; Iter    12/  209] train: loss: 0.1172036
[Epoch 43; Iter    42/  209] train: loss: 0.1316524
[Epoch 43; Iter    72/  209] train: loss: 0.1348281
[Epoch 43; Iter   102/  209] train: loss: 0.1689749
[Epoch 43; Iter   132/  209] train: loss: 0.1241916
[Epoch 43; Iter   162/  209] train: loss: 0.1180764
[Epoch 43; Iter   192/  209] train: loss: 0.1177044
[Epoch 43] ogbg-moltox21: 0.787615 val loss: 0.252893
[Epoch 43] ogbg-moltox21: 0.756155 test loss: 0.273916
[Epoch 44; Iter    13/  209] train: loss: 0.1395439
[Epoch 44; Iter    43/  209] train: loss: 0.1414660
[Epoch 44; Iter    73/  209] train: loss: 0.1127993
[Epoch 44; Iter   103/  209] train: loss: 0.1061898
[Epoch 44; Iter   133/  209] train: loss: 0.1217894
[Epoch 44; Iter   163/  209] train: loss: 0.1297831
[Epoch 44; Iter   193/  209] train: loss: 0.1026212
[Epoch 44] ogbg-moltox21: 0.791461 val loss: 0.252652
[Epoch 44] ogbg-moltox21: 0.765601 test loss: 0.271763
[Epoch 45; Iter    14/  209] train: loss: 0.1301605
[Epoch 45; Iter    44/  209] train: loss: 0.1253755
[Epoch 45; Iter    74/  209] train: loss: 0.1474719
[Epoch 45; Iter   104/  209] train: loss: 0.1284124
[Epoch 45; Iter   134/  209] train: loss: 0.1677926
[Epoch 45; Iter   164/  209] train: loss: 0.0852560
[Epoch 45; Iter   194/  209] train: loss: 0.1399619
[Epoch 45] ogbg-moltox21: 0.795779 val loss: 0.254290
[Epoch 45] ogbg-moltox21: 0.764819 test loss: 0.270159
[Epoch 46; Iter    15/  209] train: loss: 0.0961325
[Epoch 46; Iter    45/  209] train: loss: 0.1461239
[Epoch 46; Iter    75/  209] train: loss: 0.1821452
[Epoch 46; Iter   105/  209] train: loss: 0.1492317
[Epoch 46; Iter   135/  209] train: loss: 0.1714189
[Epoch 46; Iter   165/  209] train: loss: 0.0603805
[Epoch 46; Iter   195/  209] train: loss: 0.1028215
[Epoch 46] ogbg-moltox21: 0.792971 val loss: 0.257440
[Epoch 46] ogbg-moltox21: 0.760101 test loss: 0.273213
[Epoch 47; Iter    16/  209] train: loss: 0.0863658
[Epoch 47; Iter    46/  209] train: loss: 0.1244077
[Epoch 47; Iter    76/  209] train: loss: 0.1276679
[Epoch 47; Iter   106/  209] train: loss: 0.1730247
[Epoch 47; Iter   136/  209] train: loss: 0.1167646
[Epoch 30; Iter    89/  209] train: loss: 0.1950374
[Epoch 30; Iter   119/  209] train: loss: 0.1329285
[Epoch 30; Iter   149/  209] train: loss: 0.1643902
[Epoch 30; Iter   179/  209] train: loss: 0.1333665
[Epoch 30; Iter   209/  209] train: loss: 0.1109126
[Epoch 30] ogbg-moltox21: 0.802584 val loss: 0.245035
[Epoch 30] ogbg-moltox21: 0.749584 test loss: 0.265102
[Epoch 31; Iter    30/  209] train: loss: 0.1808579
[Epoch 31; Iter    60/  209] train: loss: 0.1767810
[Epoch 31; Iter    90/  209] train: loss: 0.0984000
[Epoch 31; Iter   120/  209] train: loss: 0.1289428
[Epoch 31; Iter   150/  209] train: loss: 0.1465364
[Epoch 31; Iter   180/  209] train: loss: 0.1649605
[Epoch 31] ogbg-moltox21: 0.794252 val loss: 0.248160
[Epoch 31] ogbg-moltox21: 0.743828 test loss: 0.266214
[Epoch 32; Iter     1/  209] train: loss: 0.1697904
[Epoch 32; Iter    31/  209] train: loss: 0.1870783
[Epoch 32; Iter    61/  209] train: loss: 0.1356433
[Epoch 32; Iter    91/  209] train: loss: 0.0914631
[Epoch 32; Iter   121/  209] train: loss: 0.1609940
[Epoch 32; Iter   151/  209] train: loss: 0.1164473
[Epoch 32; Iter   181/  209] train: loss: 0.1445033
[Epoch 32] ogbg-moltox21: 0.808603 val loss: 0.238874
[Epoch 32] ogbg-moltox21: 0.761830 test loss: 0.256590
[Epoch 33; Iter     2/  209] train: loss: 0.1560691
[Epoch 33; Iter    32/  209] train: loss: 0.1778641
[Epoch 33; Iter    62/  209] train: loss: 0.2021190
[Epoch 33; Iter    92/  209] train: loss: 0.2235446
[Epoch 33; Iter   122/  209] train: loss: 0.2204451
[Epoch 33; Iter   152/  209] train: loss: 0.1269699
[Epoch 33; Iter   182/  209] train: loss: 0.1243128
[Epoch 33] ogbg-moltox21: 0.783664 val loss: 0.246638
[Epoch 33] ogbg-moltox21: 0.741283 test loss: 0.257604
[Epoch 34; Iter     3/  209] train: loss: 0.1514002
[Epoch 34; Iter    33/  209] train: loss: 0.2021028
[Epoch 34; Iter    63/  209] train: loss: 0.1456101
[Epoch 34; Iter    93/  209] train: loss: 0.1799064
[Epoch 34; Iter   123/  209] train: loss: 0.1230356
[Epoch 34; Iter   153/  209] train: loss: 0.2628301
[Epoch 34; Iter   183/  209] train: loss: 0.0977787
[Epoch 34] ogbg-moltox21: 0.802505 val loss: 0.246242
[Epoch 34] ogbg-moltox21: 0.765535 test loss: 0.260036
[Epoch 35; Iter     4/  209] train: loss: 0.1525503
[Epoch 35; Iter    34/  209] train: loss: 0.1069411
[Epoch 35; Iter    64/  209] train: loss: 0.1587112
[Epoch 35; Iter    94/  209] train: loss: 0.1096599
[Epoch 35; Iter   124/  209] train: loss: 0.3301362
[Epoch 35; Iter   154/  209] train: loss: 0.1952478
[Epoch 35; Iter   184/  209] train: loss: 0.2117538
[Epoch 35] ogbg-moltox21: 0.796995 val loss: 0.257787
[Epoch 35] ogbg-moltox21: 0.757967 test loss: 0.274796
[Epoch 36; Iter     5/  209] train: loss: 0.1494745
[Epoch 36; Iter    35/  209] train: loss: 0.0859538
[Epoch 36; Iter    65/  209] train: loss: 0.0869069
[Epoch 36; Iter    95/  209] train: loss: 0.1401533
[Epoch 36; Iter   125/  209] train: loss: 0.1967318
[Epoch 36; Iter   155/  209] train: loss: 0.1555033
[Epoch 36; Iter   185/  209] train: loss: 0.1188706
[Epoch 36] ogbg-moltox21: 0.800151 val loss: 0.247913
[Epoch 36] ogbg-moltox21: 0.758006 test loss: 0.265263
[Epoch 37; Iter     6/  209] train: loss: 0.1154333
[Epoch 37; Iter    36/  209] train: loss: 0.2062608
[Epoch 37; Iter    66/  209] train: loss: 0.1161181
[Epoch 37; Iter    96/  209] train: loss: 0.1292591
[Epoch 37; Iter   126/  209] train: loss: 0.1400245
[Epoch 37; Iter   156/  209] train: loss: 0.1545921
[Epoch 37; Iter   186/  209] train: loss: 0.1700966
[Epoch 37] ogbg-moltox21: 0.793306 val loss: 0.243670
[Epoch 37] ogbg-moltox21: 0.763988 test loss: 0.255226
[Epoch 38; Iter     7/  209] train: loss: 0.1430785
[Epoch 38; Iter    37/  209] train: loss: 0.1125011
[Epoch 38; Iter    67/  209] train: loss: 0.0999240
[Epoch 38; Iter    97/  209] train: loss: 0.1475637
[Epoch 38; Iter   127/  209] train: loss: 0.2005658
[Epoch 38; Iter   157/  209] train: loss: 0.1439097
[Epoch 38; Iter   187/  209] train: loss: 0.2206721
[Epoch 38] ogbg-moltox21: 0.800432 val loss: 0.240360
[Epoch 38] ogbg-moltox21: 0.763396 test loss: 0.254655
[Epoch 39; Iter     8/  209] train: loss: 0.1110658
[Epoch 39; Iter    38/  209] train: loss: 0.1031342
[Epoch 39; Iter    68/  209] train: loss: 0.1165551
[Epoch 39; Iter    98/  209] train: loss: 0.1316621
[Epoch 39; Iter   128/  209] train: loss: 0.2249385
[Epoch 39; Iter   158/  209] train: loss: 0.1341032
[Epoch 39; Iter   188/  209] train: loss: 0.0899588
[Epoch 39] ogbg-moltox21: 0.808200 val loss: 0.243940
[Epoch 39] ogbg-moltox21: 0.759981 test loss: 0.263288
[Epoch 40; Iter     9/  209] train: loss: 0.1314216
[Epoch 40; Iter    39/  209] train: loss: 0.1443600
[Epoch 40; Iter    69/  209] train: loss: 0.1712291
[Epoch 40; Iter    99/  209] train: loss: 0.1328151
[Epoch 40; Iter   129/  209] train: loss: 0.0872918
[Epoch 40; Iter   159/  209] train: loss: 0.1589024
[Epoch 40; Iter   189/  209] train: loss: 0.1679071
[Epoch 40] ogbg-moltox21: 0.802199 val loss: 0.244851
[Epoch 40] ogbg-moltox21: 0.758307 test loss: 0.263013
[Epoch 41; Iter    10/  209] train: loss: 0.0892836
[Epoch 41; Iter    40/  209] train: loss: 0.1723720
[Epoch 41; Iter    70/  209] train: loss: 0.0750336
[Epoch 41; Iter   100/  209] train: loss: 0.1408062
[Epoch 41; Iter   130/  209] train: loss: 0.2458893
[Epoch 41; Iter   160/  209] train: loss: 0.1922338
[Epoch 41; Iter   190/  209] train: loss: 0.2060825
[Epoch 41] ogbg-moltox21: 0.798120 val loss: 0.245836
[Epoch 41] ogbg-moltox21: 0.763292 test loss: 0.259824
[Epoch 42; Iter    11/  209] train: loss: 0.1441340
[Epoch 42; Iter    41/  209] train: loss: 0.1015227
[Epoch 42; Iter    71/  209] train: loss: 0.1445870
[Epoch 42; Iter   101/  209] train: loss: 0.1170244
[Epoch 42; Iter   131/  209] train: loss: 0.1002911
[Epoch 42; Iter   161/  209] train: loss: 0.1452514
[Epoch 42; Iter   191/  209] train: loss: 0.1129788
[Epoch 42] ogbg-moltox21: 0.807228 val loss: 0.238886
[Epoch 42] ogbg-moltox21: 0.761104 test loss: 0.259852
[Epoch 43; Iter    12/  209] train: loss: 0.1001011
[Epoch 43; Iter    42/  209] train: loss: 0.1223054
[Epoch 43; Iter    72/  209] train: loss: 0.1133027
[Epoch 43; Iter   102/  209] train: loss: 0.1324799
[Epoch 43; Iter   132/  209] train: loss: 0.1211797
[Epoch 43; Iter   162/  209] train: loss: 0.0798351
[Epoch 43; Iter   192/  209] train: loss: 0.1046491
[Epoch 43] ogbg-moltox21: 0.799054 val loss: 0.253880
[Epoch 43] ogbg-moltox21: 0.750713 test loss: 0.271269
[Epoch 44; Iter    13/  209] train: loss: 0.1137097
[Epoch 44; Iter    43/  209] train: loss: 0.1228677
[Epoch 44; Iter    73/  209] train: loss: 0.0857305
[Epoch 44; Iter   103/  209] train: loss: 0.1709096
[Epoch 44; Iter   133/  209] train: loss: 0.1474401
[Epoch 44; Iter   163/  209] train: loss: 0.1192385
[Epoch 44; Iter   193/  209] train: loss: 0.1312309
[Epoch 44] ogbg-moltox21: 0.807471 val loss: 0.253394
[Epoch 44] ogbg-moltox21: 0.761147 test loss: 0.273004
[Epoch 45; Iter    14/  209] train: loss: 0.1230652
[Epoch 45; Iter    44/  209] train: loss: 0.1266724
[Epoch 45; Iter    74/  209] train: loss: 0.1572965
[Epoch 45; Iter   104/  209] train: loss: 0.1297867
[Epoch 45; Iter   134/  209] train: loss: 0.0760897
[Epoch 45; Iter   164/  209] train: loss: 0.1227237
[Epoch 45; Iter   194/  209] train: loss: 0.1171053
[Epoch 45] ogbg-moltox21: 0.808223 val loss: 0.244593
[Epoch 45] ogbg-moltox21: 0.769280 test loss: 0.265185
[Epoch 46; Iter    15/  209] train: loss: 0.1071134
[Epoch 46; Iter    45/  209] train: loss: 0.1218822
[Epoch 46; Iter    75/  209] train: loss: 0.1317247
[Epoch 46; Iter   105/  209] train: loss: 0.1520549
[Epoch 46; Iter   135/  209] train: loss: 0.1656185
[Epoch 46; Iter   165/  209] train: loss: 0.2337572
[Epoch 46; Iter   195/  209] train: loss: 0.1815055
[Epoch 46] ogbg-moltox21: 0.802181 val loss: 0.254345
[Epoch 46] ogbg-moltox21: 0.759460 test loss: 0.274789
[Epoch 47; Iter    16/  209] train: loss: 0.1051305
[Epoch 47; Iter    46/  209] train: loss: 0.0965150
[Epoch 47; Iter    76/  209] train: loss: 0.2031133
[Epoch 47; Iter   106/  209] train: loss: 0.1469428
[Epoch 47; Iter   136/  209] train: loss: 0.1532522
[Epoch 47; Iter   166/  209] train: loss: 0.0859809
[Epoch 47; Iter   196/  209] train: loss: 0.0825460
[Epoch 47] ogbg-moltox21: 0.795407 val loss: 0.367604
[Epoch 47] ogbg-moltox21: 0.742203 test loss: 0.515896
[Epoch 48; Iter    17/  209] train: loss: 0.0927391
[Epoch 48; Iter    47/  209] train: loss: 0.0717755
[Epoch 48; Iter    77/  209] train: loss: 0.0890765
[Epoch 48; Iter   107/  209] train: loss: 0.0661680
[Epoch 48; Iter   137/  209] train: loss: 0.1361663
[Epoch 48; Iter   167/  209] train: loss: 0.0733013
[Epoch 48; Iter   197/  209] train: loss: 0.0678166
[Epoch 48] ogbg-moltox21: 0.798359 val loss: 0.348700
[Epoch 48] ogbg-moltox21: 0.745159 test loss: 0.400815
[Epoch 49; Iter    18/  209] train: loss: 0.1135645
[Epoch 49; Iter    48/  209] train: loss: 0.0983283
[Epoch 49; Iter    78/  209] train: loss: 0.0547327
[Epoch 49; Iter   108/  209] train: loss: 0.0713971
[Epoch 49; Iter   138/  209] train: loss: 0.1219661
[Epoch 49; Iter   168/  209] train: loss: 0.0800733
[Epoch 49; Iter   198/  209] train: loss: 0.0741075
[Epoch 49] ogbg-moltox21: 0.793713 val loss: 0.355847
[Epoch 49] ogbg-moltox21: 0.741480 test loss: 0.422570
[Epoch 50; Iter    19/  209] train: loss: 0.0728574
[Epoch 50; Iter    49/  209] train: loss: 0.0523614
[Epoch 50; Iter    79/  209] train: loss: 0.0758370
[Epoch 50; Iter   109/  209] train: loss: 0.0835598
[Epoch 50; Iter   139/  209] train: loss: 0.0983936
[Epoch 50; Iter   169/  209] train: loss: 0.0828887
[Epoch 50; Iter   199/  209] train: loss: 0.0985746
[Epoch 50] ogbg-moltox21: 0.782058 val loss: 0.375237
[Epoch 50] ogbg-moltox21: 0.738036 test loss: 0.466296
[Epoch 51; Iter    20/  209] train: loss: 0.0779716
[Epoch 51; Iter    50/  209] train: loss: 0.0816169
[Epoch 51; Iter    80/  209] train: loss: 0.0538625
[Epoch 51; Iter   110/  209] train: loss: 0.0872729
[Epoch 51; Iter   140/  209] train: loss: 0.0915028
[Epoch 51; Iter   170/  209] train: loss: 0.0847686
[Epoch 51; Iter   200/  209] train: loss: 0.0515448
[Epoch 51] ogbg-moltox21: 0.789047 val loss: 0.402432
[Epoch 51] ogbg-moltox21: 0.748418 test loss: 0.506544
[Epoch 52; Iter    21/  209] train: loss: 0.1230667
[Epoch 52; Iter    51/  209] train: loss: 0.0660215
[Epoch 52; Iter    81/  209] train: loss: 0.0470303
[Epoch 52; Iter   111/  209] train: loss: 0.0967237
[Epoch 52; Iter   141/  209] train: loss: 0.0463751
[Epoch 52; Iter   171/  209] train: loss: 0.0856917
[Epoch 52; Iter   201/  209] train: loss: 0.1151802
[Epoch 52] ogbg-moltox21: 0.789508 val loss: 0.362019
[Epoch 52] ogbg-moltox21: 0.740687 test loss: 0.477721
[Epoch 53; Iter    22/  209] train: loss: 0.0754789
[Epoch 53; Iter    52/  209] train: loss: 0.0579865
[Epoch 53; Iter    82/  209] train: loss: 0.0750882
[Epoch 53; Iter   112/  209] train: loss: 0.0418394
[Epoch 53; Iter   142/  209] train: loss: 0.0842480
[Epoch 53; Iter   172/  209] train: loss: 0.0587588
[Epoch 53; Iter   202/  209] train: loss: 0.1253692
[Epoch 53] ogbg-moltox21: 0.793577 val loss: 0.358260
[Epoch 53] ogbg-moltox21: 0.748004 test loss: 0.435938
[Epoch 54; Iter    23/  209] train: loss: 0.0544145
[Epoch 54; Iter    53/  209] train: loss: 0.0652048
[Epoch 54; Iter    83/  209] train: loss: 0.0729203
[Epoch 54; Iter   113/  209] train: loss: 0.0869009
[Epoch 54; Iter   143/  209] train: loss: 0.1245581
[Epoch 54; Iter   173/  209] train: loss: 0.1032786
[Epoch 54; Iter   203/  209] train: loss: 0.0500630
[Epoch 54] ogbg-moltox21: 0.793626 val loss: 0.366183
[Epoch 54] ogbg-moltox21: 0.747208 test loss: 0.445711
[Epoch 55; Iter    24/  209] train: loss: 0.0627397
[Epoch 55; Iter    54/  209] train: loss: 0.0524202
[Epoch 55; Iter    84/  209] train: loss: 0.0367125
[Epoch 55; Iter   114/  209] train: loss: 0.0723422
[Epoch 55; Iter   144/  209] train: loss: 0.0533120
[Epoch 55; Iter   174/  209] train: loss: 0.0485195
[Epoch 55; Iter   204/  209] train: loss: 0.0399512
[Epoch 55] ogbg-moltox21: 0.794428 val loss: 0.360705
[Epoch 55] ogbg-moltox21: 0.745233 test loss: 0.432095
[Epoch 56; Iter    25/  209] train: loss: 0.0556428
[Epoch 56; Iter    55/  209] train: loss: 0.0660190
[Epoch 56; Iter    85/  209] train: loss: 0.0413367
[Epoch 56; Iter   115/  209] train: loss: 0.0394717
[Epoch 56; Iter   145/  209] train: loss: 0.0400943
[Epoch 56; Iter   175/  209] train: loss: 0.0584386
[Epoch 56; Iter   205/  209] train: loss: 0.0800101
[Epoch 56] ogbg-moltox21: 0.781894 val loss: 0.379620
[Epoch 56] ogbg-moltox21: 0.745664 test loss: 0.436923
[Epoch 57; Iter    26/  209] train: loss: 0.0452137
[Epoch 57; Iter    56/  209] train: loss: 0.0675130
[Epoch 57; Iter    86/  209] train: loss: 0.0648036
[Epoch 57; Iter   116/  209] train: loss: 0.0655232
[Epoch 57; Iter   146/  209] train: loss: 0.0881285
[Epoch 57; Iter   176/  209] train: loss: 0.0606719
[Epoch 57; Iter   206/  209] train: loss: 0.0525419
[Epoch 57] ogbg-moltox21: 0.795468 val loss: 0.428735
[Epoch 57] ogbg-moltox21: 0.756461 test loss: 0.468318
[Epoch 58; Iter    27/  209] train: loss: 0.0565884
[Epoch 58; Iter    57/  209] train: loss: 0.0316589
[Epoch 58; Iter    87/  209] train: loss: 0.0334312
[Epoch 58; Iter   117/  209] train: loss: 0.0855607
[Epoch 58; Iter   147/  209] train: loss: 0.0601265
[Epoch 58; Iter   177/  209] train: loss: 0.0500471
[Epoch 58; Iter   207/  209] train: loss: 0.0287958
[Epoch 58] ogbg-moltox21: 0.777958 val loss: 0.391650
[Epoch 58] ogbg-moltox21: 0.741230 test loss: 0.447461
[Epoch 59; Iter    28/  209] train: loss: 0.0663417
[Epoch 59; Iter    58/  209] train: loss: 0.0374865
[Epoch 59; Iter    88/  209] train: loss: 0.0553880
[Epoch 59; Iter   118/  209] train: loss: 0.0436160
[Epoch 59; Iter   148/  209] train: loss: 0.0770503
[Epoch 59; Iter   178/  209] train: loss: 0.0927126
[Epoch 59; Iter   208/  209] train: loss: 0.0512589
[Epoch 59] ogbg-moltox21: 0.793560 val loss: 0.379445
[Epoch 59] ogbg-moltox21: 0.740817 test loss: 0.458536
[Epoch 60; Iter    29/  209] train: loss: 0.0410583
[Epoch 60; Iter    59/  209] train: loss: 0.0302635
[Epoch 60; Iter    89/  209] train: loss: 0.0727317
[Epoch 60; Iter   119/  209] train: loss: 0.0648985
[Epoch 60; Iter   149/  209] train: loss: 0.0455935
[Epoch 60; Iter   179/  209] train: loss: 0.0483505
[Epoch 60; Iter   209/  209] train: loss: 0.0620701
[Epoch 60] ogbg-moltox21: 0.797167 val loss: 0.383515
[Epoch 60] ogbg-moltox21: 0.746637 test loss: 0.476295
[Epoch 61; Iter    30/  209] train: loss: 0.0732494
[Epoch 61; Iter    60/  209] train: loss: 0.0435931
[Epoch 61; Iter    90/  209] train: loss: 0.0739963
[Epoch 61; Iter   120/  209] train: loss: 0.0533201
[Epoch 61; Iter   150/  209] train: loss: 0.1091258
[Epoch 61; Iter   180/  209] train: loss: 0.1107323
[Epoch 61] ogbg-moltox21: 0.783034 val loss: 0.420202
[Epoch 61] ogbg-moltox21: 0.746186 test loss: 0.456198
[Epoch 62; Iter     1/  209] train: loss: 0.0771063
[Epoch 62; Iter    31/  209] train: loss: 0.0344547
[Epoch 62; Iter    61/  209] train: loss: 0.0211172
[Epoch 62; Iter    91/  209] train: loss: 0.0560933
[Epoch 62; Iter   121/  209] train: loss: 0.0579596
[Epoch 62; Iter   151/  209] train: loss: 0.0527430
[Epoch 62; Iter   181/  209] train: loss: 0.0505634
[Epoch 62] ogbg-moltox21: 0.786087 val loss: 0.401874
[Epoch 62] ogbg-moltox21: 0.758520 test loss: 0.427907
[Epoch 63; Iter     2/  209] train: loss: 0.0555102
[Epoch 63; Iter    32/  209] train: loss: 0.0531101
[Epoch 63; Iter    62/  209] train: loss: 0.0310881
[Epoch 63; Iter    92/  209] train: loss: 0.0352291
[Epoch 63; Iter   122/  209] train: loss: 0.0623942
[Epoch 63; Iter   152/  209] train: loss: 0.0397029
[Epoch 63; Iter   182/  209] train: loss: 0.0547237
[Epoch 63] ogbg-moltox21: 0.788973 val loss: 0.382089
[Epoch 63] ogbg-moltox21: 0.758515 test loss: 0.453173
[Epoch 64; Iter     3/  209] train: loss: 0.0401757
[Epoch 64; Iter    33/  209] train: loss: 0.0273254
[Epoch 64; Iter    63/  209] train: loss: 0.0334078
[Epoch 64; Iter    93/  209] train: loss: 0.0466974
[Epoch 64; Iter   123/  209] train: loss: 0.0777668
[Epoch 64; Iter   153/  209] train: loss: 0.0543626
[Epoch 64; Iter   183/  209] train: loss: 0.1004041
[Epoch 64] ogbg-moltox21: 0.796128 val loss: 0.391017
[Epoch 47; Iter   166/  209] train: loss: 0.0978195
[Epoch 47; Iter   196/  209] train: loss: 0.1391782
[Epoch 47] ogbg-moltox21: 0.792659 val loss: 0.268511
[Epoch 47] ogbg-moltox21: 0.749211 test loss: 0.578597
[Epoch 48; Iter    17/  209] train: loss: 0.0981412
[Epoch 48; Iter    47/  209] train: loss: 0.1506145
[Epoch 48; Iter    77/  209] train: loss: 0.1068952
[Epoch 48; Iter   107/  209] train: loss: 0.0852842
[Epoch 48; Iter   137/  209] train: loss: 0.1527901
[Epoch 48; Iter   167/  209] train: loss: 0.1423415
[Epoch 48; Iter   197/  209] train: loss: 0.0675495
[Epoch 48] ogbg-moltox21: 0.784086 val loss: 0.408312
[Epoch 48] ogbg-moltox21: 0.735625 test loss: 0.425973
[Epoch 49; Iter    18/  209] train: loss: 0.1085746
[Epoch 49; Iter    48/  209] train: loss: 0.1164420
[Epoch 49; Iter    78/  209] train: loss: 0.1609656
[Epoch 49; Iter   108/  209] train: loss: 0.1588623
[Epoch 49; Iter   138/  209] train: loss: 0.1479344
[Epoch 49; Iter   168/  209] train: loss: 0.0875860
[Epoch 49; Iter   198/  209] train: loss: 0.1756818
[Epoch 49] ogbg-moltox21: 0.779121 val loss: 0.286399
[Epoch 49] ogbg-moltox21: 0.734871 test loss: 0.590777
[Epoch 50; Iter    19/  209] train: loss: 0.1011069
[Epoch 50; Iter    49/  209] train: loss: 0.1033329
[Epoch 50; Iter    79/  209] train: loss: 0.1018955
[Epoch 50; Iter   109/  209] train: loss: 0.1278503
[Epoch 50; Iter   139/  209] train: loss: 0.1334351
[Epoch 50; Iter   169/  209] train: loss: 0.1060212
[Epoch 50; Iter   199/  209] train: loss: 0.1298943
[Epoch 50] ogbg-moltox21: 0.792545 val loss: 0.443912
[Epoch 50] ogbg-moltox21: 0.749414 test loss: 0.893076
[Epoch 51; Iter    20/  209] train: loss: 0.1092571
[Epoch 51; Iter    50/  209] train: loss: 0.1406786
[Epoch 51; Iter    80/  209] train: loss: 0.0710500
[Epoch 51; Iter   110/  209] train: loss: 0.1254104
[Epoch 51; Iter   140/  209] train: loss: 0.1213674
[Epoch 51; Iter   170/  209] train: loss: 0.1122086
[Epoch 51; Iter   200/  209] train: loss: 0.1361627
[Epoch 51] ogbg-moltox21: 0.779011 val loss: 0.420579
[Epoch 51] ogbg-moltox21: 0.747916 test loss: 0.786361
[Epoch 52; Iter    21/  209] train: loss: 0.1061367
[Epoch 52; Iter    51/  209] train: loss: 0.1121934
[Epoch 52; Iter    81/  209] train: loss: 0.1328685
[Epoch 52; Iter   111/  209] train: loss: 0.0936207
[Epoch 52; Iter   141/  209] train: loss: 0.0611765
[Epoch 52; Iter   171/  209] train: loss: 0.1485641
[Epoch 52; Iter   201/  209] train: loss: 0.1142779
[Epoch 52] ogbg-moltox21: 0.767532 val loss: 0.368328
[Epoch 52] ogbg-moltox21: 0.735377 test loss: 0.422942
[Epoch 53; Iter    22/  209] train: loss: 0.1408696
[Epoch 53; Iter    52/  209] train: loss: 0.1627982
[Epoch 53; Iter    82/  209] train: loss: 0.0630658
[Epoch 53; Iter   112/  209] train: loss: 0.1782918
[Epoch 53; Iter   142/  209] train: loss: 0.1382439
[Epoch 53; Iter   172/  209] train: loss: 0.1045915
[Epoch 53; Iter   202/  209] train: loss: 0.1047672
[Epoch 53] ogbg-moltox21: 0.783766 val loss: 0.345643
[Epoch 53] ogbg-moltox21: 0.737526 test loss: 0.680730
[Epoch 54; Iter    23/  209] train: loss: 0.1233442
[Epoch 54; Iter    53/  209] train: loss: 0.0932830
[Epoch 54; Iter    83/  209] train: loss: 0.0810558
[Epoch 54; Iter   113/  209] train: loss: 0.0983979
[Epoch 54; Iter   143/  209] train: loss: 0.1342350
[Epoch 54; Iter   173/  209] train: loss: 0.1355399
[Epoch 54; Iter   203/  209] train: loss: 0.1134733
[Epoch 54] ogbg-moltox21: 0.788905 val loss: 0.678738
[Epoch 54] ogbg-moltox21: 0.743872 test loss: 0.839001
[Epoch 55; Iter    24/  209] train: loss: 0.0988008
[Epoch 55; Iter    54/  209] train: loss: 0.0876537
[Epoch 55; Iter    84/  209] train: loss: 0.1264930
[Epoch 55; Iter   114/  209] train: loss: 0.0706013
[Epoch 55; Iter   144/  209] train: loss: 0.1142033
[Epoch 55; Iter   174/  209] train: loss: 0.1109931
[Epoch 55; Iter   204/  209] train: loss: 0.0742614
[Epoch 55] ogbg-moltox21: 0.776894 val loss: 0.366201
[Epoch 55] ogbg-moltox21: 0.739120 test loss: 0.609395
[Epoch 56; Iter    25/  209] train: loss: 0.1312776
[Epoch 56; Iter    55/  209] train: loss: 0.1251320
[Epoch 56; Iter    85/  209] train: loss: 0.1234436
[Epoch 56; Iter   115/  209] train: loss: 0.1113149
[Epoch 56; Iter   145/  209] train: loss: 0.0893017
[Epoch 56; Iter   175/  209] train: loss: 0.0673770
[Epoch 56; Iter   205/  209] train: loss: 0.1109877
[Epoch 56] ogbg-moltox21: 0.775902 val loss: 0.318685
[Epoch 56] ogbg-moltox21: 0.739409 test loss: 0.517154
[Epoch 57; Iter    26/  209] train: loss: 0.0851321
[Epoch 57; Iter    56/  209] train: loss: 0.0873336
[Epoch 57; Iter    86/  209] train: loss: 0.1658024
[Epoch 57; Iter   116/  209] train: loss: 0.0928639
[Epoch 57; Iter   146/  209] train: loss: 0.1129987
[Epoch 57; Iter   176/  209] train: loss: 0.0842194
[Epoch 57; Iter   206/  209] train: loss: 0.1124951
[Epoch 57] ogbg-moltox21: 0.767757 val loss: 0.314193
[Epoch 57] ogbg-moltox21: 0.741600 test loss: 0.485792
[Epoch 58; Iter    27/  209] train: loss: 0.1002888
[Epoch 58; Iter    57/  209] train: loss: 0.0920887
[Epoch 58; Iter    87/  209] train: loss: 0.1013847
[Epoch 58; Iter   117/  209] train: loss: 0.0780524
[Epoch 58; Iter   147/  209] train: loss: 0.1345721
[Epoch 58; Iter   177/  209] train: loss: 0.1074114
[Epoch 58; Iter   207/  209] train: loss: 0.0922270
[Epoch 58] ogbg-moltox21: 0.767588 val loss: 0.364529
[Epoch 58] ogbg-moltox21: 0.737064 test loss: 0.532443
[Epoch 59; Iter    28/  209] train: loss: 0.0952922
[Epoch 59; Iter    58/  209] train: loss: 0.0919935
[Epoch 59; Iter    88/  209] train: loss: 0.1506337
[Epoch 59; Iter   118/  209] train: loss: 0.1297997
[Epoch 59; Iter   148/  209] train: loss: 0.1075187
[Epoch 59; Iter   178/  209] train: loss: 0.0634697
[Epoch 59; Iter   208/  209] train: loss: 0.1121134
[Epoch 59] ogbg-moltox21: 0.769311 val loss: 0.383183
[Epoch 59] ogbg-moltox21: 0.743694 test loss: 0.489435
[Epoch 60; Iter    29/  209] train: loss: 0.1221793
[Epoch 60; Iter    59/  209] train: loss: 0.0789134
[Epoch 60; Iter    89/  209] train: loss: 0.0633815
[Epoch 60; Iter   119/  209] train: loss: 0.1176948
[Epoch 60; Iter   149/  209] train: loss: 0.0764621
[Epoch 60; Iter   179/  209] train: loss: 0.1944345
[Epoch 60; Iter   209/  209] train: loss: 0.1151630
[Epoch 60] ogbg-moltox21: 0.778879 val loss: 0.330212
[Epoch 60] ogbg-moltox21: 0.748385 test loss: 0.527116
[Epoch 61; Iter    30/  209] train: loss: 0.0864142
[Epoch 61; Iter    60/  209] train: loss: 0.1094390
[Epoch 61; Iter    90/  209] train: loss: 0.1239993
[Epoch 61; Iter   120/  209] train: loss: 0.1067708
[Epoch 61; Iter   150/  209] train: loss: 0.0873719
[Epoch 61; Iter   180/  209] train: loss: 0.0907720
[Epoch 61] ogbg-moltox21: 0.764634 val loss: 0.302790
[Epoch 61] ogbg-moltox21: 0.741851 test loss: 0.493728
[Epoch 62; Iter     1/  209] train: loss: 0.0493275
[Epoch 62; Iter    31/  209] train: loss: 0.0806386
[Epoch 62; Iter    61/  209] train: loss: 0.1176220
[Epoch 62; Iter    91/  209] train: loss: 0.0831858
[Epoch 62; Iter   121/  209] train: loss: 0.1318334
[Epoch 62; Iter   151/  209] train: loss: 0.0738002
[Epoch 62; Iter   181/  209] train: loss: 0.0945912
[Epoch 62] ogbg-moltox21: 0.754337 val loss: 0.364721
[Epoch 62] ogbg-moltox21: 0.738142 test loss: 0.485064
[Epoch 63; Iter     2/  209] train: loss: 0.0959912
[Epoch 63; Iter    32/  209] train: loss: 0.1443927
[Epoch 63; Iter    62/  209] train: loss: 0.0884399
[Epoch 63; Iter    92/  209] train: loss: 0.0761268
[Epoch 63; Iter   122/  209] train: loss: 0.1012961
[Epoch 63; Iter   152/  209] train: loss: 0.1021325
[Epoch 63; Iter   182/  209] train: loss: 0.1014252
[Epoch 63] ogbg-moltox21: 0.769901 val loss: 0.366378
[Epoch 63] ogbg-moltox21: 0.746883 test loss: 0.458429
[Epoch 64; Iter     3/  209] train: loss: 0.0859822
[Epoch 64; Iter    33/  209] train: loss: 0.0686346
[Epoch 64; Iter    63/  209] train: loss: 0.0710634
[Epoch 64; Iter    93/  209] train: loss: 0.0628689
[Epoch 64; Iter   123/  209] train: loss: 0.1083001
[Epoch 64; Iter   153/  209] train: loss: 0.0618565
[Epoch 64; Iter   183/  209] train: loss: 0.0887905
[Epoch 64] ogbg-moltox21: 0.770053 val loss: 0.325738
[Epoch 47; Iter   166/  209] train: loss: 0.0497219
[Epoch 47; Iter   196/  209] train: loss: 0.0536919
[Epoch 47] ogbg-moltox21: 0.754516 val loss: 0.412153
[Epoch 47] ogbg-moltox21: 0.700417 test loss: 0.472528
[Epoch 48; Iter    17/  209] train: loss: 0.0865149
[Epoch 48; Iter    47/  209] train: loss: 0.0318959
[Epoch 48; Iter    77/  209] train: loss: 0.0312842
[Epoch 48; Iter   107/  209] train: loss: 0.0791047
[Epoch 48; Iter   137/  209] train: loss: 0.0463163
[Epoch 48; Iter   167/  209] train: loss: 0.0559952
[Epoch 48; Iter   197/  209] train: loss: 0.0480515
[Epoch 48] ogbg-moltox21: 0.769425 val loss: 0.408038
[Epoch 48] ogbg-moltox21: 0.711436 test loss: 0.470765
[Epoch 49; Iter    18/  209] train: loss: 0.0609656
[Epoch 49; Iter    48/  209] train: loss: 0.0291798
[Epoch 49; Iter    78/  209] train: loss: 0.0309495
[Epoch 49; Iter   108/  209] train: loss: 0.0319133
[Epoch 49; Iter   138/  209] train: loss: 0.0729924
[Epoch 49; Iter   168/  209] train: loss: 0.0879185
[Epoch 49; Iter   198/  209] train: loss: 0.0665642
[Epoch 49] ogbg-moltox21: 0.759097 val loss: 0.405782
[Epoch 49] ogbg-moltox21: 0.694959 test loss: 0.461384
[Epoch 50; Iter    19/  209] train: loss: 0.1036589
[Epoch 50; Iter    49/  209] train: loss: 0.0471615
[Epoch 50; Iter    79/  209] train: loss: 0.0474827
[Epoch 50; Iter   109/  209] train: loss: 0.0517497
[Epoch 50; Iter   139/  209] train: loss: 0.0733429
[Epoch 50; Iter   169/  209] train: loss: 0.0321122
[Epoch 50; Iter   199/  209] train: loss: 0.0254744
[Epoch 50] ogbg-moltox21: 0.772764 val loss: 0.401538
[Epoch 50] ogbg-moltox21: 0.715284 test loss: 0.457906
[Epoch 51; Iter    20/  209] train: loss: 0.0505777
[Epoch 51; Iter    50/  209] train: loss: 0.0522203
[Epoch 51; Iter    80/  209] train: loss: 0.0234714
[Epoch 51; Iter   110/  209] train: loss: 0.0340045
[Epoch 51; Iter   140/  209] train: loss: 0.0435732
[Epoch 51; Iter   170/  209] train: loss: 0.0404539
[Epoch 51; Iter   200/  209] train: loss: 0.0479646
[Epoch 51] ogbg-moltox21: 0.768483 val loss: 0.439088
[Epoch 51] ogbg-moltox21: 0.700506 test loss: 0.511781
[Epoch 52; Iter    21/  209] train: loss: 0.0266635
[Epoch 52; Iter    51/  209] train: loss: 0.0299338
[Epoch 52; Iter    81/  209] train: loss: 0.0410031
[Epoch 52; Iter   111/  209] train: loss: 0.0619513
[Epoch 52; Iter   141/  209] train: loss: 0.0435121
[Epoch 52; Iter   171/  209] train: loss: 0.0639826
[Epoch 52; Iter   201/  209] train: loss: 0.0336965
[Epoch 52] ogbg-moltox21: 0.757772 val loss: 0.469519
[Epoch 52] ogbg-moltox21: 0.708627 test loss: 0.474524
[Epoch 53; Iter    22/  209] train: loss: 0.0661400
[Epoch 53; Iter    52/  209] train: loss: 0.0491658
[Epoch 53; Iter    82/  209] train: loss: 0.0498639
[Epoch 53; Iter   112/  209] train: loss: 0.0435413
[Epoch 53; Iter   142/  209] train: loss: 0.0550513
[Epoch 53; Iter   172/  209] train: loss: 0.0240011
[Epoch 53; Iter   202/  209] train: loss: 0.0414453
[Epoch 53] ogbg-moltox21: 0.759106 val loss: 0.434766
[Epoch 53] ogbg-moltox21: 0.701948 test loss: 0.488255
[Epoch 54; Iter    23/  209] train: loss: 0.0449720
[Epoch 54; Iter    53/  209] train: loss: 0.0566350
[Epoch 54; Iter    83/  209] train: loss: 0.0331235
[Epoch 54; Iter   113/  209] train: loss: 0.0382944
[Epoch 54; Iter   143/  209] train: loss: 0.0452266
[Epoch 54; Iter   173/  209] train: loss: 0.0723729
[Epoch 54; Iter   203/  209] train: loss: 0.0675830
[Epoch 54] ogbg-moltox21: 0.761214 val loss: 0.452296
[Epoch 54] ogbg-moltox21: 0.701828 test loss: 0.512769
[Epoch 55; Iter    24/  209] train: loss: 0.0371998
[Epoch 55; Iter    54/  209] train: loss: 0.0246477
[Epoch 55; Iter    84/  209] train: loss: 0.0468333
[Epoch 55; Iter   114/  209] train: loss: 0.0536953
[Epoch 55; Iter   144/  209] train: loss: 0.0574475
[Epoch 55; Iter   174/  209] train: loss: 0.0280148
[Epoch 55; Iter   204/  209] train: loss: 0.0214744
[Epoch 55] ogbg-moltox21: 0.764641 val loss: 0.448391
[Epoch 55] ogbg-moltox21: 0.701705 test loss: 0.512817
[Epoch 56; Iter    25/  209] train: loss: 0.0304968
[Epoch 56; Iter    55/  209] train: loss: 0.0538021
[Epoch 56; Iter    85/  209] train: loss: 0.0248388
[Epoch 56; Iter   115/  209] train: loss: 0.0250987
[Epoch 56; Iter   145/  209] train: loss: 0.0553522
[Epoch 56; Iter   175/  209] train: loss: 0.0283070
[Epoch 56; Iter   205/  209] train: loss: 0.0326289
[Epoch 56] ogbg-moltox21: 0.767721 val loss: 0.486132
[Epoch 56] ogbg-moltox21: 0.714823 test loss: 0.536013
[Epoch 57; Iter    26/  209] train: loss: 0.0297243
[Epoch 57; Iter    56/  209] train: loss: 0.0381733
[Epoch 57; Iter    86/  209] train: loss: 0.0386571
[Epoch 57; Iter   116/  209] train: loss: 0.0279749
[Epoch 57; Iter   146/  209] train: loss: 0.0255371
[Epoch 57; Iter   176/  209] train: loss: 0.0517888
[Epoch 57; Iter   206/  209] train: loss: 0.0438957
[Epoch 57] ogbg-moltox21: 0.763999 val loss: 0.490125
[Epoch 57] ogbg-moltox21: 0.697859 test loss: 0.520355
[Epoch 58; Iter    27/  209] train: loss: 0.0219848
[Epoch 58; Iter    57/  209] train: loss: 0.0159415
[Epoch 58; Iter    87/  209] train: loss: 0.0589432
[Epoch 58; Iter   117/  209] train: loss: 0.0285370
[Epoch 58; Iter   147/  209] train: loss: 0.0413722
[Epoch 58; Iter   177/  209] train: loss: 0.0503627
[Epoch 58; Iter   207/  209] train: loss: 0.0437327
[Epoch 58] ogbg-moltox21: 0.761010 val loss: 0.539229
[Epoch 58] ogbg-moltox21: 0.708107 test loss: 0.541564
[Epoch 59; Iter    28/  209] train: loss: 0.0477255
[Epoch 59; Iter    58/  209] train: loss: 0.0857305
[Epoch 59; Iter    88/  209] train: loss: 0.0331502
[Epoch 59; Iter   118/  209] train: loss: 0.0388675
[Epoch 59; Iter   148/  209] train: loss: 0.0434639
[Epoch 59; Iter   178/  209] train: loss: 0.0406306
[Epoch 59; Iter   208/  209] train: loss: 0.0568907
[Epoch 59] ogbg-moltox21: 0.758788 val loss: 0.471361
[Epoch 59] ogbg-moltox21: 0.692205 test loss: 0.533159
[Epoch 60; Iter    29/  209] train: loss: 0.0263558
[Epoch 60; Iter    59/  209] train: loss: 0.0216442
[Epoch 60; Iter    89/  209] train: loss: 0.0420443
[Epoch 60; Iter   119/  209] train: loss: 0.0285568
[Epoch 60; Iter   149/  209] train: loss: 0.0273956
[Epoch 60; Iter   179/  209] train: loss: 0.0273217
[Epoch 60; Iter   209/  209] train: loss: 0.0625427
[Epoch 60] ogbg-moltox21: 0.760132 val loss: 0.545608
[Epoch 60] ogbg-moltox21: 0.715452 test loss: 0.570294
[Epoch 61; Iter    30/  209] train: loss: 0.0257736
[Epoch 61; Iter    60/  209] train: loss: 0.0284674
[Epoch 61; Iter    90/  209] train: loss: 0.0232787
[Epoch 61; Iter   120/  209] train: loss: 0.0228725
[Epoch 61; Iter   150/  209] train: loss: 0.0575675
[Epoch 61; Iter   180/  209] train: loss: 0.0458314
[Epoch 61] ogbg-moltox21: 0.749422 val loss: 0.532207
[Epoch 61] ogbg-moltox21: 0.689671 test loss: 0.577346
[Epoch 62; Iter     1/  209] train: loss: 0.0331881
[Epoch 62; Iter    31/  209] train: loss: 0.0278494
[Epoch 62; Iter    61/  209] train: loss: 0.0248940
[Epoch 62; Iter    91/  209] train: loss: 0.0250702
[Epoch 62; Iter   121/  209] train: loss: 0.0290178
[Epoch 62; Iter   151/  209] train: loss: 0.0337863
[Epoch 62; Iter   181/  209] train: loss: 0.0549968
[Epoch 62] ogbg-moltox21: 0.762866 val loss: 0.552161
[Epoch 62] ogbg-moltox21: 0.692078 test loss: 0.555555
[Epoch 63; Iter     2/  209] train: loss: 0.0335842
[Epoch 63; Iter    32/  209] train: loss: 0.1099342
[Epoch 63; Iter    62/  209] train: loss: 0.0223782
[Epoch 63; Iter    92/  209] train: loss: 0.0326267
[Epoch 63; Iter   122/  209] train: loss: 0.0272119
[Epoch 63; Iter   152/  209] train: loss: 0.0277976
[Epoch 63; Iter   182/  209] train: loss: 0.0131925
[Epoch 63] ogbg-moltox21: 0.763355 val loss: 0.556159
[Epoch 63] ogbg-moltox21: 0.691374 test loss: 0.580731
[Epoch 64; Iter     3/  209] train: loss: 0.0111535
[Epoch 64; Iter    33/  209] train: loss: 0.0160077
[Epoch 64; Iter    63/  209] train: loss: 0.0378051
[Epoch 64; Iter    93/  209] train: loss: 0.0268250
[Epoch 64; Iter   123/  209] train: loss: 0.0216329
[Epoch 64; Iter   153/  209] train: loss: 0.0399334
[Epoch 64; Iter   183/  209] train: loss: 0.0093615
[Epoch 64] ogbg-moltox21: 0.764347 val loss: 0.540658
[Epoch 47; Iter   166/  209] train: loss: 0.0687813
[Epoch 47; Iter   196/  209] train: loss: 0.0778167
[Epoch 47] ogbg-moltox21: 0.709527 val loss: 0.404809
[Epoch 47] ogbg-moltox21: 0.689102 test loss: 0.431502
[Epoch 48; Iter    17/  209] train: loss: 0.0730882
[Epoch 48; Iter    47/  209] train: loss: 0.0897831
[Epoch 48; Iter    77/  209] train: loss: 0.0467937
[Epoch 48; Iter   107/  209] train: loss: 0.0449515
[Epoch 48; Iter   137/  209] train: loss: 0.1035808
[Epoch 48; Iter   167/  209] train: loss: 0.0845750
[Epoch 48; Iter   197/  209] train: loss: 0.0384035
[Epoch 48] ogbg-moltox21: 0.702868 val loss: 0.403760
[Epoch 48] ogbg-moltox21: 0.687739 test loss: 0.427285
[Epoch 49; Iter    18/  209] train: loss: 0.0473841
[Epoch 49; Iter    48/  209] train: loss: 0.0741739
[Epoch 49; Iter    78/  209] train: loss: 0.0715759
[Epoch 49; Iter   108/  209] train: loss: 0.1368785
[Epoch 49; Iter   138/  209] train: loss: 0.0850476
[Epoch 49; Iter   168/  209] train: loss: 0.0640777
[Epoch 49; Iter   198/  209] train: loss: 0.1082067
[Epoch 49] ogbg-moltox21: 0.707330 val loss: 0.416690
[Epoch 49] ogbg-moltox21: 0.691003 test loss: 0.440652
[Epoch 50; Iter    19/  209] train: loss: 0.0442184
[Epoch 50; Iter    49/  209] train: loss: 0.0590583
[Epoch 50; Iter    79/  209] train: loss: 0.0709297
[Epoch 50; Iter   109/  209] train: loss: 0.0662588
[Epoch 50; Iter   139/  209] train: loss: 0.0616937
[Epoch 50; Iter   169/  209] train: loss: 0.0577020
[Epoch 50; Iter   199/  209] train: loss: 0.0977359
[Epoch 50] ogbg-moltox21: 0.712377 val loss: 0.410032
[Epoch 50] ogbg-moltox21: 0.695013 test loss: 0.437088
[Epoch 51; Iter    20/  209] train: loss: 0.0677613
[Epoch 51; Iter    50/  209] train: loss: 0.0825215
[Epoch 51; Iter    80/  209] train: loss: 0.0401943
[Epoch 51; Iter   110/  209] train: loss: 0.0779352
[Epoch 51; Iter   140/  209] train: loss: 0.0866328
[Epoch 51; Iter   170/  209] train: loss: 0.0756003
[Epoch 51; Iter   200/  209] train: loss: 0.0905855
[Epoch 51] ogbg-moltox21: 0.704247 val loss: 0.481307
[Epoch 51] ogbg-moltox21: 0.688147 test loss: 0.505219
[Epoch 52; Iter    21/  209] train: loss: 0.0581134
[Epoch 52; Iter    51/  209] train: loss: 0.0589816
[Epoch 52; Iter    81/  209] train: loss: 0.0456539
[Epoch 52; Iter   111/  209] train: loss: 0.0545532
[Epoch 52; Iter   141/  209] train: loss: 0.0475628
[Epoch 52; Iter   171/  209] train: loss: 0.0675155
[Epoch 52; Iter   201/  209] train: loss: 0.0557657
[Epoch 52] ogbg-moltox21: 0.721998 val loss: 0.393262
[Epoch 52] ogbg-moltox21: 0.696644 test loss: 0.421629
[Epoch 53; Iter    22/  209] train: loss: 0.0679094
[Epoch 53; Iter    52/  209] train: loss: 0.0712772
[Epoch 53; Iter    82/  209] train: loss: 0.0385893
[Epoch 53; Iter   112/  209] train: loss: 0.1037679
[Epoch 53; Iter   142/  209] train: loss: 0.0728548
[Epoch 53; Iter   172/  209] train: loss: 0.0511543
[Epoch 53; Iter   202/  209] train: loss: 0.0536596
[Epoch 53] ogbg-moltox21: 0.700518 val loss: 0.436753
[Epoch 53] ogbg-moltox21: 0.684145 test loss: 0.459207
[Epoch 54; Iter    23/  209] train: loss: 0.0770418
[Epoch 54; Iter    53/  209] train: loss: 0.0397421
[Epoch 54; Iter    83/  209] train: loss: 0.0517433
[Epoch 54; Iter   113/  209] train: loss: 0.0709054
[Epoch 54; Iter   143/  209] train: loss: 0.0966629
[Epoch 54; Iter   173/  209] train: loss: 0.0883447
[Epoch 54; Iter   203/  209] train: loss: 0.0558799
[Epoch 54] ogbg-moltox21: 0.696157 val loss: 0.440819
[Epoch 54] ogbg-moltox21: 0.690189 test loss: 0.456810
[Epoch 55; Iter    24/  209] train: loss: 0.0530514
[Epoch 55; Iter    54/  209] train: loss: 0.0689184
[Epoch 55; Iter    84/  209] train: loss: 0.0488980
[Epoch 55; Iter   114/  209] train: loss: 0.0484972
[Epoch 55; Iter   144/  209] train: loss: 0.0592396
[Epoch 55; Iter   174/  209] train: loss: 0.0701753
[Epoch 55; Iter   204/  209] train: loss: 0.0489273
[Epoch 55] ogbg-moltox21: 0.698247 val loss: 0.441439
[Epoch 55] ogbg-moltox21: 0.688485 test loss: 0.470420
[Epoch 56; Iter    25/  209] train: loss: 0.0699739
[Epoch 56; Iter    55/  209] train: loss: 0.0592320
[Epoch 56; Iter    85/  209] train: loss: 0.0639939
[Epoch 56; Iter   115/  209] train: loss: 0.0613527
[Epoch 56; Iter   145/  209] train: loss: 0.0365778
[Epoch 56; Iter   175/  209] train: loss: 0.0295910
[Epoch 56; Iter   205/  209] train: loss: 0.0550404
[Epoch 56] ogbg-moltox21: 0.699437 val loss: 0.459317
[Epoch 56] ogbg-moltox21: 0.682176 test loss: 0.484297
[Epoch 57; Iter    26/  209] train: loss: 0.0432045
[Epoch 57; Iter    56/  209] train: loss: 0.0460770
[Epoch 57; Iter    86/  209] train: loss: 0.0815088
[Epoch 57; Iter   116/  209] train: loss: 0.0520460
[Epoch 57; Iter   146/  209] train: loss: 0.0550291
[Epoch 57; Iter   176/  209] train: loss: 0.0281262
[Epoch 57; Iter   206/  209] train: loss: 0.0615988
[Epoch 57] ogbg-moltox21: 0.701816 val loss: 0.460680
[Epoch 57] ogbg-moltox21: 0.696403 test loss: 0.478777
[Epoch 58; Iter    27/  209] train: loss: 0.0422788
[Epoch 58; Iter    57/  209] train: loss: 0.0472835
[Epoch 58; Iter    87/  209] train: loss: 0.0854892
[Epoch 58; Iter   117/  209] train: loss: 0.0536454
[Epoch 58; Iter   147/  209] train: loss: 0.0609160
[Epoch 58; Iter   177/  209] train: loss: 0.0512610
[Epoch 58; Iter   207/  209] train: loss: 0.0538634
[Epoch 58] ogbg-moltox21: 0.694545 val loss: 0.445149
[Epoch 58] ogbg-moltox21: 0.690305 test loss: 0.464208
[Epoch 59; Iter    28/  209] train: loss: 0.0569056
[Epoch 59; Iter    58/  209] train: loss: 0.0432945
[Epoch 59; Iter    88/  209] train: loss: 0.0681409
[Epoch 59; Iter   118/  209] train: loss: 0.0631086
[Epoch 59; Iter   148/  209] train: loss: 0.0429985
[Epoch 59; Iter   178/  209] train: loss: 0.0339836
[Epoch 59; Iter   208/  209] train: loss: 0.0463853
[Epoch 59] ogbg-moltox21: 0.674608 val loss: 0.508728
[Epoch 59] ogbg-moltox21: 0.686522 test loss: 0.505355
[Epoch 60; Iter    29/  209] train: loss: 0.0420976
[Epoch 60; Iter    59/  209] train: loss: 0.0341592
[Epoch 60; Iter    89/  209] train: loss: 0.0330254
[Epoch 60; Iter   119/  209] train: loss: 0.0602745
[Epoch 60; Iter   149/  209] train: loss: 0.0688818
[Epoch 60; Iter   179/  209] train: loss: 0.0885343
[Epoch 60; Iter   209/  209] train: loss: 0.0550091
[Epoch 60] ogbg-moltox21: 0.704943 val loss: 0.435145
[Epoch 60] ogbg-moltox21: 0.699319 test loss: 0.455823
[Epoch 61; Iter    30/  209] train: loss: 0.0436056
[Epoch 61; Iter    60/  209] train: loss: 0.0547220
[Epoch 61; Iter    90/  209] train: loss: 0.0634319
[Epoch 61; Iter   120/  209] train: loss: 0.0485629
[Epoch 61; Iter   150/  209] train: loss: 0.0316838
[Epoch 61; Iter   180/  209] train: loss: 0.0397842
[Epoch 61] ogbg-moltox21: 0.685690 val loss: 0.467552
[Epoch 61] ogbg-moltox21: 0.689030 test loss: 0.487402
[Epoch 62; Iter     1/  209] train: loss: 0.0222965
[Epoch 62; Iter    31/  209] train: loss: 0.0227009
[Epoch 62; Iter    61/  209] train: loss: 0.0345522
[Epoch 62; Iter    91/  209] train: loss: 0.0299210
[Epoch 62; Iter   121/  209] train: loss: 0.0533077
[Epoch 62; Iter   151/  209] train: loss: 0.0415186
[Epoch 62; Iter   181/  209] train: loss: 0.0374783
[Epoch 62] ogbg-moltox21: 0.683271 val loss: 0.481210
[Epoch 62] ogbg-moltox21: 0.692247 test loss: 0.485522
[Epoch 63; Iter     2/  209] train: loss: 0.0263983
[Epoch 63; Iter    32/  209] train: loss: 0.0498564
[Epoch 63; Iter    62/  209] train: loss: 0.0385930
[Epoch 63; Iter    92/  209] train: loss: 0.0239177
[Epoch 63; Iter   122/  209] train: loss: 0.0470129
[Epoch 63; Iter   152/  209] train: loss: 0.0375503
[Epoch 63; Iter   182/  209] train: loss: 0.0305840
[Epoch 63] ogbg-moltox21: 0.696802 val loss: 0.496463
[Epoch 63] ogbg-moltox21: 0.695394 test loss: 0.505664
[Epoch 64; Iter     3/  209] train: loss: 0.0275065
[Epoch 64; Iter    33/  209] train: loss: 0.0444025
[Epoch 64; Iter    63/  209] train: loss: 0.0259990
[Epoch 64; Iter    93/  209] train: loss: 0.0263291
[Epoch 64; Iter   123/  209] train: loss: 0.0425802
[Epoch 64; Iter   153/  209] train: loss: 0.0360916
[Epoch 64; Iter   183/  209] train: loss: 0.0406406
[Epoch 64] ogbg-moltox21: 0.691106 val loss: 0.507344
[Epoch 47; Iter   166/  209] train: loss: 0.0754730
[Epoch 47; Iter   196/  209] train: loss: 0.0476323
[Epoch 47] ogbg-moltox21: 0.745716 val loss: 0.674430
[Epoch 47] ogbg-moltox21: 0.724243 test loss: 0.646289
[Epoch 48; Iter    17/  209] train: loss: 0.0969995
[Epoch 48; Iter    47/  209] train: loss: 0.0576658
[Epoch 48; Iter    77/  209] train: loss: 0.0723284
[Epoch 48; Iter   107/  209] train: loss: 0.0773491
[Epoch 48; Iter   137/  209] train: loss: 0.0555430
[Epoch 48; Iter   167/  209] train: loss: 0.0861528
[Epoch 48; Iter   197/  209] train: loss: 0.0594926
[Epoch 48] ogbg-moltox21: 0.725921 val loss: 0.447619
[Epoch 48] ogbg-moltox21: 0.711890 test loss: 0.695983
[Epoch 49; Iter    18/  209] train: loss: 0.0508504
[Epoch 49; Iter    48/  209] train: loss: 0.0513335
[Epoch 49; Iter    78/  209] train: loss: 0.0566989
[Epoch 49; Iter   108/  209] train: loss: 0.0435870
[Epoch 49; Iter   138/  209] train: loss: 0.0967827
[Epoch 49; Iter   168/  209] train: loss: 0.0573228
[Epoch 49; Iter   198/  209] train: loss: 0.0591881
[Epoch 49] ogbg-moltox21: 0.755703 val loss: 0.425086
[Epoch 49] ogbg-moltox21: 0.709076 test loss: 0.665261
[Epoch 50; Iter    19/  209] train: loss: 0.1063926
[Epoch 50; Iter    49/  209] train: loss: 0.0554951
[Epoch 50; Iter    79/  209] train: loss: 0.0550797
[Epoch 50; Iter   109/  209] train: loss: 0.0618159
[Epoch 50; Iter   139/  209] train: loss: 0.0679949
[Epoch 50; Iter   169/  209] train: loss: 0.0584824
[Epoch 50; Iter   199/  209] train: loss: 0.0282330
[Epoch 50] ogbg-moltox21: 0.744789 val loss: 0.585376
[Epoch 50] ogbg-moltox21: 0.722929 test loss: 0.383887
[Epoch 51; Iter    20/  209] train: loss: 0.0872874
[Epoch 51; Iter    50/  209] train: loss: 0.0657720
[Epoch 51; Iter    80/  209] train: loss: 0.0356538
[Epoch 51; Iter   110/  209] train: loss: 0.0441019
[Epoch 51; Iter   140/  209] train: loss: 0.0671541
[Epoch 51; Iter   170/  209] train: loss: 0.0511288
[Epoch 51; Iter   200/  209] train: loss: 0.0766986
[Epoch 51] ogbg-moltox21: 0.756193 val loss: 0.793450
[Epoch 51] ogbg-moltox21: 0.725236 test loss: 0.409711
[Epoch 52; Iter    21/  209] train: loss: 0.0577368
[Epoch 52; Iter    51/  209] train: loss: 0.0463176
[Epoch 52; Iter    81/  209] train: loss: 0.0822005
[Epoch 52; Iter   111/  209] train: loss: 0.0935359
[Epoch 52; Iter   141/  209] train: loss: 0.0527007
[Epoch 52; Iter   171/  209] train: loss: 0.0560963
[Epoch 52; Iter   201/  209] train: loss: 0.0475963
[Epoch 52] ogbg-moltox21: 0.739515 val loss: 0.579929
[Epoch 52] ogbg-moltox21: 0.726842 test loss: 0.400069
[Epoch 53; Iter    22/  209] train: loss: 0.0759773
[Epoch 53; Iter    52/  209] train: loss: 0.0588091
[Epoch 53; Iter    82/  209] train: loss: 0.0594413
[Epoch 53; Iter   112/  209] train: loss: 0.0478185
[Epoch 53; Iter   142/  209] train: loss: 0.0530477
[Epoch 53; Iter   172/  209] train: loss: 0.0536453
[Epoch 53; Iter   202/  209] train: loss: 0.0619194
[Epoch 53] ogbg-moltox21: 0.735514 val loss: 0.923253
[Epoch 53] ogbg-moltox21: 0.730435 test loss: 0.412141
[Epoch 54; Iter    23/  209] train: loss: 0.0474140
[Epoch 54; Iter    53/  209] train: loss: 0.0678100
[Epoch 54; Iter    83/  209] train: loss: 0.0549704
[Epoch 54; Iter   113/  209] train: loss: 0.0557386
[Epoch 54; Iter   143/  209] train: loss: 0.0681073
[Epoch 54; Iter   173/  209] train: loss: 0.0942718
[Epoch 54; Iter   203/  209] train: loss: 0.0591201
[Epoch 54] ogbg-moltox21: 0.736862 val loss: 0.446630
[Epoch 54] ogbg-moltox21: 0.719823 test loss: 0.405889
[Epoch 55; Iter    24/  209] train: loss: 0.0411077
[Epoch 55; Iter    54/  209] train: loss: 0.0386299
[Epoch 55; Iter    84/  209] train: loss: 0.0513550
[Epoch 55; Iter   114/  209] train: loss: 0.0731562
[Epoch 55; Iter   144/  209] train: loss: 0.0814120
[Epoch 55; Iter   174/  209] train: loss: 0.0468938
[Epoch 55; Iter   204/  209] train: loss: 0.0468685
[Epoch 55] ogbg-moltox21: 0.738274 val loss: 0.778373
[Epoch 55] ogbg-moltox21: 0.720797 test loss: 0.422727
[Epoch 56; Iter    25/  209] train: loss: 0.0551665
[Epoch 56; Iter    55/  209] train: loss: 0.0841764
[Epoch 56; Iter    85/  209] train: loss: 0.0364488
[Epoch 56; Iter   115/  209] train: loss: 0.0318263
[Epoch 56; Iter   145/  209] train: loss: 0.0784474
[Epoch 56; Iter   175/  209] train: loss: 0.0505202
[Epoch 56; Iter   205/  209] train: loss: 0.0581467
[Epoch 56] ogbg-moltox21: 0.738612 val loss: 0.655080
[Epoch 56] ogbg-moltox21: 0.724187 test loss: 0.404354
[Epoch 57; Iter    26/  209] train: loss: 0.0380162
[Epoch 57; Iter    56/  209] train: loss: 0.0598246
[Epoch 57; Iter    86/  209] train: loss: 0.0654092
[Epoch 57; Iter   116/  209] train: loss: 0.0391828
[Epoch 57; Iter   146/  209] train: loss: 0.0528529
[Epoch 57; Iter   176/  209] train: loss: 0.0847153
[Epoch 57; Iter   206/  209] train: loss: 0.0587669
[Epoch 57] ogbg-moltox21: 0.746725 val loss: 0.871123
[Epoch 57] ogbg-moltox21: 0.728155 test loss: 0.424127
[Epoch 58; Iter    27/  209] train: loss: 0.0639834
[Epoch 58; Iter    57/  209] train: loss: 0.0246720
[Epoch 58; Iter    87/  209] train: loss: 0.0895711
[Epoch 58; Iter   117/  209] train: loss: 0.0404508
[Epoch 58; Iter   147/  209] train: loss: 0.0511010
[Epoch 58; Iter   177/  209] train: loss: 0.0480568
[Epoch 58; Iter   207/  209] train: loss: 0.0488983
[Epoch 58] ogbg-moltox21: 0.749193 val loss: 1.064465
[Epoch 58] ogbg-moltox21: 0.734525 test loss: 0.431151
[Epoch 59; Iter    28/  209] train: loss: 0.0768662
[Epoch 59; Iter    58/  209] train: loss: 0.0930435
[Epoch 59; Iter    88/  209] train: loss: 0.0645153
[Epoch 59; Iter   118/  209] train: loss: 0.0543062
[Epoch 59; Iter   148/  209] train: loss: 0.0501540
[Epoch 59; Iter   178/  209] train: loss: 0.0632724
[Epoch 59; Iter   208/  209] train: loss: 0.0796062
[Epoch 59] ogbg-moltox21: 0.741368 val loss: 1.015048
[Epoch 59] ogbg-moltox21: 0.722748 test loss: 0.429236
[Epoch 60; Iter    29/  209] train: loss: 0.0302462
[Epoch 60; Iter    59/  209] train: loss: 0.0322991
[Epoch 60; Iter    89/  209] train: loss: 0.0350425
[Epoch 60; Iter   119/  209] train: loss: 0.0233959
[Epoch 60; Iter   149/  209] train: loss: 0.0543876
[Epoch 60; Iter   179/  209] train: loss: 0.0420183
[Epoch 60; Iter   209/  209] train: loss: 0.0706209
[Epoch 60] ogbg-moltox21: 0.752435 val loss: 0.718471
[Epoch 60] ogbg-moltox21: 0.726731 test loss: 0.444286
[Epoch 61; Iter    30/  209] train: loss: 0.0526978
[Epoch 61; Iter    60/  209] train: loss: 0.0530294
[Epoch 61; Iter    90/  209] train: loss: 0.0357428
[Epoch 61; Iter   120/  209] train: loss: 0.0422135
[Epoch 61; Iter   150/  209] train: loss: 0.0816886
[Epoch 61; Iter   180/  209] train: loss: 0.0667511
[Epoch 61] ogbg-moltox21: 0.744915 val loss: 1.401238
[Epoch 61] ogbg-moltox21: 0.726309 test loss: 0.446621
[Epoch 62; Iter     1/  209] train: loss: 0.0627487
[Epoch 62; Iter    31/  209] train: loss: 0.0448197
[Epoch 62; Iter    61/  209] train: loss: 0.0301581
[Epoch 62; Iter    91/  209] train: loss: 0.0427393
[Epoch 62; Iter   121/  209] train: loss: 0.0283352
[Epoch 62; Iter   151/  209] train: loss: 0.0363688
[Epoch 62; Iter   181/  209] train: loss: 0.0546301
[Epoch 62] ogbg-moltox21: 0.748875 val loss: 0.811454
[Epoch 62] ogbg-moltox21: 0.726130 test loss: 0.434369
[Epoch 63; Iter     2/  209] train: loss: 0.0779476
[Epoch 63; Iter    32/  209] train: loss: 0.1184968
[Epoch 63; Iter    62/  209] train: loss: 0.0322384
[Epoch 63; Iter    92/  209] train: loss: 0.0543085
[Epoch 63; Iter   122/  209] train: loss: 0.0250636
[Epoch 63; Iter   152/  209] train: loss: 0.0436101
[Epoch 63; Iter   182/  209] train: loss: 0.0236988
[Epoch 63] ogbg-moltox21: 0.752233 val loss: 1.207706
[Epoch 63] ogbg-moltox21: 0.730836 test loss: 0.433400
[Epoch 64; Iter     3/  209] train: loss: 0.0327133
[Epoch 64; Iter    33/  209] train: loss: 0.0276898
[Epoch 64; Iter    63/  209] train: loss: 0.0410453
[Epoch 64; Iter    93/  209] train: loss: 0.0338021
[Epoch 64; Iter   123/  209] train: loss: 0.0598479
[Epoch 64; Iter   153/  209] train: loss: 0.0472821
[Epoch 64; Iter   183/  209] train: loss: 0.0419471
[Epoch 64] ogbg-moltox21: 0.750878 val loss: 0.748264
[Epoch 47; Iter   166/  209] train: loss: 0.0545321
[Epoch 47; Iter   196/  209] train: loss: 0.0433650
[Epoch 47] ogbg-moltox21: 0.699964 val loss: 0.662515
[Epoch 47] ogbg-moltox21: 0.668595 test loss: 0.667352
[Epoch 48; Iter    17/  209] train: loss: 0.0829280
[Epoch 48; Iter    47/  209] train: loss: 0.0493171
[Epoch 48; Iter    77/  209] train: loss: 0.0585145
[Epoch 48; Iter   107/  209] train: loss: 0.0562447
[Epoch 48; Iter   137/  209] train: loss: 0.0379209
[Epoch 48; Iter   167/  209] train: loss: 0.0650211
[Epoch 48; Iter   197/  209] train: loss: 0.0509405
[Epoch 48] ogbg-moltox21: 0.709879 val loss: 0.634524
[Epoch 48] ogbg-moltox21: 0.681039 test loss: 0.754052
[Epoch 49; Iter    18/  209] train: loss: 0.0672793
[Epoch 49; Iter    48/  209] train: loss: 0.0608486
[Epoch 49; Iter    78/  209] train: loss: 0.0440952
[Epoch 49; Iter   108/  209] train: loss: 0.0368337
[Epoch 49; Iter   138/  209] train: loss: 0.0705991
[Epoch 49; Iter   168/  209] train: loss: 0.0575185
[Epoch 49; Iter   198/  209] train: loss: 0.0462325
[Epoch 49] ogbg-moltox21: 0.710804 val loss: 0.602076
[Epoch 49] ogbg-moltox21: 0.672423 test loss: 0.650288
[Epoch 50; Iter    19/  209] train: loss: 0.1073316
[Epoch 50; Iter    49/  209] train: loss: 0.0575042
[Epoch 50; Iter    79/  209] train: loss: 0.0483674
[Epoch 50; Iter   109/  209] train: loss: 0.0360109
[Epoch 50; Iter   139/  209] train: loss: 0.0753276
[Epoch 50; Iter   169/  209] train: loss: 0.0382094
[Epoch 50; Iter   199/  209] train: loss: 0.0341783
[Epoch 50] ogbg-moltox21: 0.716735 val loss: 0.717158
[Epoch 50] ogbg-moltox21: 0.678157 test loss: 0.916198
[Epoch 51; Iter    20/  209] train: loss: 0.0687733
[Epoch 51; Iter    50/  209] train: loss: 0.0491635
[Epoch 51; Iter    80/  209] train: loss: 0.0425515
[Epoch 51; Iter   110/  209] train: loss: 0.0628097
[Epoch 51; Iter   140/  209] train: loss: 0.0704377
[Epoch 51; Iter   170/  209] train: loss: 0.0519739
[Epoch 51; Iter   200/  209] train: loss: 0.0750097
[Epoch 51] ogbg-moltox21: 0.701091 val loss: 0.715752
[Epoch 51] ogbg-moltox21: 0.660776 test loss: 0.853199
[Epoch 52; Iter    21/  209] train: loss: 0.0248140
[Epoch 52; Iter    51/  209] train: loss: 0.0354901
[Epoch 52; Iter    81/  209] train: loss: 0.0740690
[Epoch 52; Iter   111/  209] train: loss: 0.0713681
[Epoch 52; Iter   141/  209] train: loss: 0.0390011
[Epoch 52; Iter   171/  209] train: loss: 0.0664534
[Epoch 52; Iter   201/  209] train: loss: 0.0516754
[Epoch 52] ogbg-moltox21: 0.704878 val loss: 0.820650
[Epoch 52] ogbg-moltox21: 0.673975 test loss: 0.997643
[Epoch 53; Iter    22/  209] train: loss: 0.0574189
[Epoch 53; Iter    52/  209] train: loss: 0.0711936
[Epoch 53; Iter    82/  209] train: loss: 0.0637550
[Epoch 53; Iter   112/  209] train: loss: 0.0395096
[Epoch 53; Iter   142/  209] train: loss: 0.0610237
[Epoch 53; Iter   172/  209] train: loss: 0.0585352
[Epoch 53; Iter   202/  209] train: loss: 0.0483948
[Epoch 53] ogbg-moltox21: 0.710448 val loss: 0.796673
[Epoch 53] ogbg-moltox21: 0.666491 test loss: 0.766964
[Epoch 54; Iter    23/  209] train: loss: 0.0434833
[Epoch 54; Iter    53/  209] train: loss: 0.0527858
[Epoch 54; Iter    83/  209] train: loss: 0.0411662
[Epoch 54; Iter   113/  209] train: loss: 0.0303023
[Epoch 54; Iter   143/  209] train: loss: 0.0402489
[Epoch 54; Iter   173/  209] train: loss: 0.0766445
[Epoch 54; Iter   203/  209] train: loss: 0.0486246
[Epoch 54] ogbg-moltox21: 0.688234 val loss: 0.785402
[Epoch 54] ogbg-moltox21: 0.663434 test loss: 0.822727
[Epoch 55; Iter    24/  209] train: loss: 0.0367621
[Epoch 55; Iter    54/  209] train: loss: 0.0265307
[Epoch 55; Iter    84/  209] train: loss: 0.0689778
[Epoch 55; Iter   114/  209] train: loss: 0.0614421
[Epoch 55; Iter   144/  209] train: loss: 0.0644798
[Epoch 55; Iter   174/  209] train: loss: 0.0345050
[Epoch 55; Iter   204/  209] train: loss: 0.0478858
[Epoch 55] ogbg-moltox21: 0.723038 val loss: 0.792823
[Epoch 55] ogbg-moltox21: 0.690177 test loss: 0.898429
[Epoch 56; Iter    25/  209] train: loss: 0.0294975
[Epoch 56; Iter    55/  209] train: loss: 0.0825903
[Epoch 56; Iter    85/  209] train: loss: 0.0321930
[Epoch 56; Iter   115/  209] train: loss: 0.0207548
[Epoch 56; Iter   145/  209] train: loss: 0.0559063
[Epoch 56; Iter   175/  209] train: loss: 0.0460652
[Epoch 56; Iter   205/  209] train: loss: 0.0318258
[Epoch 56] ogbg-moltox21: 0.721975 val loss: 0.729599
[Epoch 56] ogbg-moltox21: 0.695628 test loss: 0.849630
[Epoch 57; Iter    26/  209] train: loss: 0.0351110
[Epoch 57; Iter    56/  209] train: loss: 0.0404130
[Epoch 57; Iter    86/  209] train: loss: 0.0601211
[Epoch 57; Iter   116/  209] train: loss: 0.0277388
[Epoch 57; Iter   146/  209] train: loss: 0.0364643
[Epoch 57; Iter   176/  209] train: loss: 0.0452959
[Epoch 57; Iter   206/  209] train: loss: 0.0556766
[Epoch 57] ogbg-moltox21: 0.708504 val loss: 0.745706
[Epoch 57] ogbg-moltox21: 0.672956 test loss: 0.830715
[Epoch 58; Iter    27/  209] train: loss: 0.0258512
[Epoch 58; Iter    57/  209] train: loss: 0.0271324
[Epoch 58; Iter    87/  209] train: loss: 0.0473611
[Epoch 58; Iter   117/  209] train: loss: 0.0283750
[Epoch 58; Iter   147/  209] train: loss: 0.0486578
[Epoch 58; Iter   177/  209] train: loss: 0.0478644
[Epoch 58; Iter   207/  209] train: loss: 0.0498826
[Epoch 58] ogbg-moltox21: 0.704390 val loss: 0.741451
[Epoch 58] ogbg-moltox21: 0.662470 test loss: 0.830673
[Epoch 59; Iter    28/  209] train: loss: 0.0568063
[Epoch 59; Iter    58/  209] train: loss: 0.0987818
[Epoch 59; Iter    88/  209] train: loss: 0.0485092
[Epoch 59; Iter   118/  209] train: loss: 0.0345135
[Epoch 59; Iter   148/  209] train: loss: 0.0358211
[Epoch 59; Iter   178/  209] train: loss: 0.0363392
[Epoch 59; Iter   208/  209] train: loss: 0.0507448
[Epoch 59] ogbg-moltox21: 0.726255 val loss: 0.710397
[Epoch 59] ogbg-moltox21: 0.674202 test loss: 0.835155
[Epoch 60; Iter    29/  209] train: loss: 0.0270430
[Epoch 60; Iter    59/  209] train: loss: 0.0279783
[Epoch 60; Iter    89/  209] train: loss: 0.0327611
[Epoch 60; Iter   119/  209] train: loss: 0.0241145
[Epoch 60; Iter   149/  209] train: loss: 0.0391711
[Epoch 60; Iter   179/  209] train: loss: 0.0468206
[Epoch 60; Iter   209/  209] train: loss: 0.0693504
[Epoch 60] ogbg-moltox21: 0.723772 val loss: 0.631409
[Epoch 60] ogbg-moltox21: 0.698911 test loss: 0.736674
[Epoch 61; Iter    30/  209] train: loss: 0.0258164
[Epoch 61; Iter    60/  209] train: loss: 0.0362341
[Epoch 61; Iter    90/  209] train: loss: 0.0259105
[Epoch 61; Iter   120/  209] train: loss: 0.0264765
[Epoch 61; Iter   150/  209] train: loss: 0.0379771
[Epoch 61; Iter   180/  209] train: loss: 0.0643540
[Epoch 61] ogbg-moltox21: 0.726649 val loss: 0.617590
[Epoch 61] ogbg-moltox21: 0.680260 test loss: 0.703549
[Epoch 62; Iter     1/  209] train: loss: 0.0345040
[Epoch 62; Iter    31/  209] train: loss: 0.0355786
[Epoch 62; Iter    61/  209] train: loss: 0.0278105
[Epoch 62; Iter    91/  209] train: loss: 0.0319647
[Epoch 62; Iter   121/  209] train: loss: 0.0397287
[Epoch 62; Iter   151/  209] train: loss: 0.0248995
[Epoch 62; Iter   181/  209] train: loss: 0.0633356
[Epoch 62] ogbg-moltox21: 0.703791 val loss: 0.850233
[Epoch 62] ogbg-moltox21: 0.668860 test loss: 1.092669
[Epoch 63; Iter     2/  209] train: loss: 0.0939396
[Epoch 63; Iter    32/  209] train: loss: 0.1756386
[Epoch 63; Iter    62/  209] train: loss: 0.0378464
[Epoch 63; Iter    92/  209] train: loss: 0.0437249
[Epoch 63; Iter   122/  209] train: loss: 0.0326297
[Epoch 63; Iter   152/  209] train: loss: 0.0462123
[Epoch 63; Iter   182/  209] train: loss: 0.0059080
[Epoch 63] ogbg-moltox21: 0.713652 val loss: 0.685886
[Epoch 63] ogbg-moltox21: 0.665266 test loss: 0.746301
[Epoch 64; Iter     3/  209] train: loss: 0.0244584
[Epoch 64; Iter    33/  209] train: loss: 0.0274717
[Epoch 64; Iter    63/  209] train: loss: 0.0330230
[Epoch 64; Iter    93/  209] train: loss: 0.0193751
[Epoch 64; Iter   123/  209] train: loss: 0.0504600
[Epoch 64; Iter   153/  209] train: loss: 0.0443935
[Epoch 64; Iter   183/  209] train: loss: 0.0265717
[Epoch 64] ogbg-moltox21: 0.730845 val loss: 0.688221
[Epoch 47; Iter   166/  209] train: loss: 0.0638769
[Epoch 47; Iter   196/  209] train: loss: 0.0920031
[Epoch 47] ogbg-moltox21: 0.753228 val loss: 0.374126
[Epoch 47] ogbg-moltox21: 0.709676 test loss: 0.415803
[Epoch 48; Iter    17/  209] train: loss: 0.0704892
[Epoch 48; Iter    47/  209] train: loss: 0.0431462
[Epoch 48; Iter    77/  209] train: loss: 0.0787219
[Epoch 48; Iter   107/  209] train: loss: 0.0733769
[Epoch 48; Iter   137/  209] train: loss: 0.0759304
[Epoch 48; Iter   167/  209] train: loss: 0.0867398
[Epoch 48; Iter   197/  209] train: loss: 0.0666450
[Epoch 48] ogbg-moltox21: 0.762481 val loss: 0.438909
[Epoch 48] ogbg-moltox21: 0.732717 test loss: 0.621703
[Epoch 49; Iter    18/  209] train: loss: 0.1000432
[Epoch 49; Iter    48/  209] train: loss: 0.0622435
[Epoch 49; Iter    78/  209] train: loss: 0.0517510
[Epoch 49; Iter   108/  209] train: loss: 0.0557026
[Epoch 49; Iter   138/  209] train: loss: 0.0807147
[Epoch 49; Iter   168/  209] train: loss: 0.0750965
[Epoch 49; Iter   198/  209] train: loss: 0.0444784
[Epoch 49] ogbg-moltox21: 0.752907 val loss: 0.379924
[Epoch 49] ogbg-moltox21: 0.716611 test loss: 0.413540
[Epoch 50; Iter    19/  209] train: loss: 0.0733076
[Epoch 50; Iter    49/  209] train: loss: 0.0749626
[Epoch 50; Iter    79/  209] train: loss: 0.0711526
[Epoch 50; Iter   109/  209] train: loss: 0.0614470
[Epoch 50; Iter   139/  209] train: loss: 0.0653176
[Epoch 50; Iter   169/  209] train: loss: 0.0433214
[Epoch 50; Iter   199/  209] train: loss: 0.0855863
[Epoch 50] ogbg-moltox21: 0.749770 val loss: 0.416256
[Epoch 50] ogbg-moltox21: 0.722109 test loss: 0.580358
[Epoch 51; Iter    20/  209] train: loss: 0.0624678
[Epoch 51; Iter    50/  209] train: loss: 0.0685672
[Epoch 51; Iter    80/  209] train: loss: 0.0417364
[Epoch 51; Iter   110/  209] train: loss: 0.0792045
[Epoch 51; Iter   140/  209] train: loss: 0.0724443
[Epoch 51; Iter   170/  209] train: loss: 0.0503819
[Epoch 51; Iter   200/  209] train: loss: 0.0412910
[Epoch 51] ogbg-moltox21: 0.745287 val loss: 0.429584
[Epoch 51] ogbg-moltox21: 0.717354 test loss: 0.469498
[Epoch 52; Iter    21/  209] train: loss: 0.0998350
[Epoch 52; Iter    51/  209] train: loss: 0.0422050
[Epoch 52; Iter    81/  209] train: loss: 0.0349718
[Epoch 52; Iter   111/  209] train: loss: 0.0683613
[Epoch 52; Iter   141/  209] train: loss: 0.0932150
[Epoch 52; Iter   171/  209] train: loss: 0.0571776
[Epoch 52; Iter   201/  209] train: loss: 0.1157688
[Epoch 52] ogbg-moltox21: 0.744532 val loss: 0.551107
[Epoch 52] ogbg-moltox21: 0.709120 test loss: 0.532611
[Epoch 53; Iter    22/  209] train: loss: 0.0291203
[Epoch 53; Iter    52/  209] train: loss: 0.0565054
[Epoch 53; Iter    82/  209] train: loss: 0.0401889
[Epoch 53; Iter   112/  209] train: loss: 0.0354345
[Epoch 53; Iter   142/  209] train: loss: 0.0798133
[Epoch 53; Iter   172/  209] train: loss: 0.0557599
[Epoch 53; Iter   202/  209] train: loss: 0.1161845
[Epoch 53] ogbg-moltox21: 0.752637 val loss: 0.572996
[Epoch 53] ogbg-moltox21: 0.719710 test loss: 0.698534
[Epoch 54; Iter    23/  209] train: loss: 0.0494632
[Epoch 54; Iter    53/  209] train: loss: 0.0425052
[Epoch 54; Iter    83/  209] train: loss: 0.0774140
[Epoch 54; Iter   113/  209] train: loss: 0.0662081
[Epoch 54; Iter   143/  209] train: loss: 0.1051143
[Epoch 54; Iter   173/  209] train: loss: 0.0842084
[Epoch 54; Iter   203/  209] train: loss: 0.0491914
[Epoch 54] ogbg-moltox21: 0.744245 val loss: 0.432952
[Epoch 54] ogbg-moltox21: 0.712375 test loss: 0.441962
[Epoch 55; Iter    24/  209] train: loss: 0.0500466
[Epoch 55; Iter    54/  209] train: loss: 0.0515134
[Epoch 55; Iter    84/  209] train: loss: 0.0493660
[Epoch 55; Iter   114/  209] train: loss: 0.0607601
[Epoch 55; Iter   144/  209] train: loss: 0.0643727
[Epoch 55; Iter   174/  209] train: loss: 0.0420454
[Epoch 55; Iter   204/  209] train: loss: 0.0309832
[Epoch 55] ogbg-moltox21: 0.743136 val loss: 0.470150
[Epoch 55] ogbg-moltox21: 0.712289 test loss: 0.456069
[Epoch 56; Iter    25/  209] train: loss: 0.0418258
[Epoch 56; Iter    55/  209] train: loss: 0.0394552
[Epoch 56; Iter    85/  209] train: loss: 0.0352774
[Epoch 56; Iter   115/  209] train: loss: 0.0556654
[Epoch 56; Iter   145/  209] train: loss: 0.0544920
[Epoch 56; Iter   175/  209] train: loss: 0.0527354
[Epoch 56; Iter   205/  209] train: loss: 0.0875253
[Epoch 56] ogbg-moltox21: 0.752852 val loss: 0.472779
[Epoch 56] ogbg-moltox21: 0.718796 test loss: 0.525072
[Epoch 57; Iter    26/  209] train: loss: 0.0591103
[Epoch 57; Iter    56/  209] train: loss: 0.0810217
[Epoch 57; Iter    86/  209] train: loss: 0.0555639
[Epoch 57; Iter   116/  209] train: loss: 0.0377510
[Epoch 57; Iter   146/  209] train: loss: 0.0726259
[Epoch 57; Iter   176/  209] train: loss: 0.0559026
[Epoch 57; Iter   206/  209] train: loss: 0.0521019
[Epoch 57] ogbg-moltox21: 0.754120 val loss: 0.440640
[Epoch 57] ogbg-moltox21: 0.711533 test loss: 0.563740
[Epoch 58; Iter    27/  209] train: loss: 0.0323710
[Epoch 58; Iter    57/  209] train: loss: 0.0256504
[Epoch 58; Iter    87/  209] train: loss: 0.0345355
[Epoch 58; Iter   117/  209] train: loss: 0.0554115
[Epoch 58; Iter   147/  209] train: loss: 0.0607047
[Epoch 58; Iter   177/  209] train: loss: 0.0330015
[Epoch 58; Iter   207/  209] train: loss: 0.0361390
[Epoch 58] ogbg-moltox21: 0.756524 val loss: 0.419806
[Epoch 58] ogbg-moltox21: 0.719870 test loss: 0.575096
[Epoch 59; Iter    28/  209] train: loss: 0.0433206
[Epoch 59; Iter    58/  209] train: loss: 0.0420540
[Epoch 59; Iter    88/  209] train: loss: 0.0434201
[Epoch 59; Iter   118/  209] train: loss: 0.0208854
[Epoch 59; Iter   148/  209] train: loss: 0.0860877
[Epoch 59; Iter   178/  209] train: loss: 0.0571100
[Epoch 59; Iter   208/  209] train: loss: 0.0338434
[Epoch 59] ogbg-moltox21: 0.745857 val loss: 0.442282
[Epoch 59] ogbg-moltox21: 0.720036 test loss: 0.518518
[Epoch 60; Iter    29/  209] train: loss: 0.0326977
[Epoch 60; Iter    59/  209] train: loss: 0.0210150
[Epoch 60; Iter    89/  209] train: loss: 0.0666257
[Epoch 60; Iter   119/  209] train: loss: 0.0535711
[Epoch 60; Iter   149/  209] train: loss: 0.0254298
[Epoch 60; Iter   179/  209] train: loss: 0.0421037
[Epoch 60; Iter   209/  209] train: loss: 0.0797212
[Epoch 60] ogbg-moltox21: 0.751887 val loss: 0.493846
[Epoch 60] ogbg-moltox21: 0.714270 test loss: 0.720930
[Epoch 61; Iter    30/  209] train: loss: 0.0301684
[Epoch 61; Iter    60/  209] train: loss: 0.0519126
[Epoch 61; Iter    90/  209] train: loss: 0.0596950
[Epoch 61; Iter   120/  209] train: loss: 0.0574826
[Epoch 61; Iter   150/  209] train: loss: 0.0806354
[Epoch 61; Iter   180/  209] train: loss: 0.0875633
[Epoch 61] ogbg-moltox21: 0.743499 val loss: 0.440359
[Epoch 61] ogbg-moltox21: 0.707067 test loss: 0.481611
[Epoch 62; Iter     1/  209] train: loss: 0.0527825
[Epoch 62; Iter    31/  209] train: loss: 0.0276661
[Epoch 62; Iter    61/  209] train: loss: 0.0165256
[Epoch 62; Iter    91/  209] train: loss: 0.0503740
[Epoch 62; Iter   121/  209] train: loss: 0.0584138
[Epoch 62; Iter   151/  209] train: loss: 0.0586179
[Epoch 62; Iter   181/  209] train: loss: 0.0397801
[Epoch 62] ogbg-moltox21: 0.746961 val loss: 0.460981
[Epoch 62] ogbg-moltox21: 0.723430 test loss: 0.501155
[Epoch 63; Iter     2/  209] train: loss: 0.0361525
[Epoch 63; Iter    32/  209] train: loss: 0.0506019
[Epoch 63; Iter    62/  209] train: loss: 0.0368348
[Epoch 63; Iter    92/  209] train: loss: 0.0261734
[Epoch 63; Iter   122/  209] train: loss: 0.0429816
[Epoch 63; Iter   152/  209] train: loss: 0.0443316
[Epoch 63; Iter   182/  209] train: loss: 0.0659185
[Epoch 63] ogbg-moltox21: 0.750176 val loss: 0.505546
[Epoch 63] ogbg-moltox21: 0.711559 test loss: 0.563736
[Epoch 64; Iter     3/  209] train: loss: 0.0489340
[Epoch 64; Iter    33/  209] train: loss: 0.0500163
[Epoch 64; Iter    63/  209] train: loss: 0.0354777
[Epoch 64; Iter    93/  209] train: loss: 0.0448511
[Epoch 64; Iter   123/  209] train: loss: 0.0954947
[Epoch 64; Iter   153/  209] train: loss: 0.0695668
[Epoch 64; Iter   183/  209] train: loss: 0.1258522
[Epoch 64] ogbg-moltox21: 0.748590 val loss: 0.489766
[Epoch 47; Iter   166/  209] train: loss: 0.0946297
[Epoch 47; Iter   196/  209] train: loss: 0.1167040
[Epoch 47] ogbg-moltox21: 0.760789 val loss: 0.332562
[Epoch 47] ogbg-moltox21: 0.724213 test loss: 0.328005
[Epoch 48; Iter    17/  209] train: loss: 0.0664830
[Epoch 48; Iter    47/  209] train: loss: 0.1331045
[Epoch 48; Iter    77/  209] train: loss: 0.1041245
[Epoch 48; Iter   107/  209] train: loss: 0.0770787
[Epoch 48; Iter   137/  209] train: loss: 0.1203658
[Epoch 48; Iter   167/  209] train: loss: 0.1061977
[Epoch 48; Iter   197/  209] train: loss: 0.0580472
[Epoch 48] ogbg-moltox21: 0.747231 val loss: 0.338042
[Epoch 48] ogbg-moltox21: 0.709965 test loss: 0.371916
[Epoch 49; Iter    18/  209] train: loss: 0.0971868
[Epoch 49; Iter    48/  209] train: loss: 0.1024226
[Epoch 49; Iter    78/  209] train: loss: 0.1040884
[Epoch 49; Iter   108/  209] train: loss: 0.1479722
[Epoch 49; Iter   138/  209] train: loss: 0.1058327
[Epoch 49; Iter   168/  209] train: loss: 0.0745428
[Epoch 49; Iter   198/  209] train: loss: 0.1441422
[Epoch 49] ogbg-moltox21: 0.738497 val loss: 0.358891
[Epoch 49] ogbg-moltox21: 0.704683 test loss: 0.366746
[Epoch 50; Iter    19/  209] train: loss: 0.0881499
[Epoch 50; Iter    49/  209] train: loss: 0.0800390
[Epoch 50; Iter    79/  209] train: loss: 0.0944576
[Epoch 50; Iter   109/  209] train: loss: 0.0941694
[Epoch 50; Iter   139/  209] train: loss: 0.1027057
[Epoch 50; Iter   169/  209] train: loss: 0.0821486
[Epoch 50; Iter   199/  209] train: loss: 0.1317786
[Epoch 50] ogbg-moltox21: 0.748451 val loss: 0.345537
[Epoch 50] ogbg-moltox21: 0.719540 test loss: 0.364661
[Epoch 51; Iter    20/  209] train: loss: 0.0883363
[Epoch 51; Iter    50/  209] train: loss: 0.1092469
[Epoch 51; Iter    80/  209] train: loss: 0.0637126
[Epoch 51; Iter   110/  209] train: loss: 0.0989612
[Epoch 51; Iter   140/  209] train: loss: 0.1003774
[Epoch 51; Iter   170/  209] train: loss: 0.1166908
[Epoch 51; Iter   200/  209] train: loss: 0.1387377
[Epoch 51] ogbg-moltox21: 0.736859 val loss: 0.358010
[Epoch 51] ogbg-moltox21: 0.705354 test loss: 0.378053
[Epoch 52; Iter    21/  209] train: loss: 0.0870986
[Epoch 52; Iter    51/  209] train: loss: 0.1016895
[Epoch 52; Iter    81/  209] train: loss: 0.0761802
[Epoch 52; Iter   111/  209] train: loss: 0.0889400
[Epoch 52; Iter   141/  209] train: loss: 0.0528417
[Epoch 52; Iter   171/  209] train: loss: 0.1129948
[Epoch 52; Iter   201/  209] train: loss: 0.0826724
[Epoch 52] ogbg-moltox21: 0.740390 val loss: 0.342002
[Epoch 52] ogbg-moltox21: 0.717428 test loss: 0.374784
[Epoch 53; Iter    22/  209] train: loss: 0.1167347
[Epoch 53; Iter    52/  209] train: loss: 0.1235029
[Epoch 53; Iter    82/  209] train: loss: 0.0433669
[Epoch 53; Iter   112/  209] train: loss: 0.1437792
[Epoch 53; Iter   142/  209] train: loss: 0.1168265
[Epoch 53; Iter   172/  209] train: loss: 0.0743095
[Epoch 53; Iter   202/  209] train: loss: 0.0778995
[Epoch 53] ogbg-moltox21: 0.723451 val loss: 0.346968
[Epoch 53] ogbg-moltox21: 0.707624 test loss: 0.359000
[Epoch 54; Iter    23/  209] train: loss: 0.1106323
[Epoch 54; Iter    53/  209] train: loss: 0.0512630
[Epoch 54; Iter    83/  209] train: loss: 0.0668407
[Epoch 54; Iter   113/  209] train: loss: 0.0686208
[Epoch 54; Iter   143/  209] train: loss: 0.1333147
[Epoch 54; Iter   173/  209] train: loss: 0.1087698
[Epoch 54; Iter   203/  209] train: loss: 0.0882102
[Epoch 54] ogbg-moltox21: 0.730120 val loss: 0.470271
[Epoch 54] ogbg-moltox21: 0.712444 test loss: 0.382756
[Epoch 55; Iter    24/  209] train: loss: 0.0726889
[Epoch 55; Iter    54/  209] train: loss: 0.0732079
[Epoch 55; Iter    84/  209] train: loss: 0.1043971
[Epoch 55; Iter   114/  209] train: loss: 0.0756584
[Epoch 55; Iter   144/  209] train: loss: 0.0913458
[Epoch 55; Iter   174/  209] train: loss: 0.0911161
[Epoch 55; Iter   204/  209] train: loss: 0.0827200
[Epoch 55] ogbg-moltox21: 0.735976 val loss: 0.429738
[Epoch 55] ogbg-moltox21: 0.704548 test loss: 0.392518
[Epoch 56; Iter    25/  209] train: loss: 0.1157349
[Epoch 56; Iter    55/  209] train: loss: 0.0851298
[Epoch 56; Iter    85/  209] train: loss: 0.0943019
[Epoch 56; Iter   115/  209] train: loss: 0.0841954
[Epoch 56; Iter   145/  209] train: loss: 0.0625480
[Epoch 56; Iter   175/  209] train: loss: 0.0517218
[Epoch 56; Iter   205/  209] train: loss: 0.0888918
[Epoch 56] ogbg-moltox21: 0.728787 val loss: 0.373771
[Epoch 56] ogbg-moltox21: 0.708783 test loss: 0.369051
[Epoch 57; Iter    26/  209] train: loss: 0.0708305
[Epoch 57; Iter    56/  209] train: loss: 0.0944673
[Epoch 57; Iter    86/  209] train: loss: 0.1219928
[Epoch 57; Iter   116/  209] train: loss: 0.0699906
[Epoch 57; Iter   146/  209] train: loss: 0.0997102
[Epoch 57; Iter   176/  209] train: loss: 0.0595471
[Epoch 57; Iter   206/  209] train: loss: 0.0955907
[Epoch 57] ogbg-moltox21: 0.745161 val loss: 0.373096
[Epoch 57] ogbg-moltox21: 0.715549 test loss: 0.383839
[Epoch 58; Iter    27/  209] train: loss: 0.0847547
[Epoch 58; Iter    57/  209] train: loss: 0.0520081
[Epoch 58; Iter    87/  209] train: loss: 0.1176209
[Epoch 58; Iter   117/  209] train: loss: 0.0586349
[Epoch 58; Iter   147/  209] train: loss: 0.0993171
[Epoch 58; Iter   177/  209] train: loss: 0.0578798
[Epoch 58; Iter   207/  209] train: loss: 0.0579858
[Epoch 58] ogbg-moltox21: 0.727038 val loss: 0.364078
[Epoch 58] ogbg-moltox21: 0.700321 test loss: 0.379233
[Epoch 59; Iter    28/  209] train: loss: 0.0777301
[Epoch 59; Iter    58/  209] train: loss: 0.0699321
[Epoch 59; Iter    88/  209] train: loss: 0.1227857
[Epoch 59; Iter   118/  209] train: loss: 0.0902738
[Epoch 59; Iter   148/  209] train: loss: 0.0922559
[Epoch 59; Iter   178/  209] train: loss: 0.0753846
[Epoch 59; Iter   208/  209] train: loss: 0.0905677
[Epoch 59] ogbg-moltox21: 0.732654 val loss: 0.436636
[Epoch 59] ogbg-moltox21: 0.711918 test loss: 0.411366
[Epoch 60; Iter    29/  209] train: loss: 0.0694040
[Epoch 60; Iter    59/  209] train: loss: 0.0726101
[Epoch 60; Iter    89/  209] train: loss: 0.0617108
[Epoch 60; Iter   119/  209] train: loss: 0.0981314
[Epoch 60; Iter   149/  209] train: loss: 0.0712595
[Epoch 60; Iter   179/  209] train: loss: 0.1461889
[Epoch 60; Iter   209/  209] train: loss: 0.0773240
[Epoch 60] ogbg-moltox21: 0.709768 val loss: 0.388511
[Epoch 60] ogbg-moltox21: 0.695891 test loss: 0.403269
[Epoch 61; Iter    30/  209] train: loss: 0.0786406
[Epoch 61; Iter    60/  209] train: loss: 0.0735721
[Epoch 61; Iter    90/  209] train: loss: 0.1186630
[Epoch 61; Iter   120/  209] train: loss: 0.0983087
[Epoch 61; Iter   150/  209] train: loss: 0.0499142
[Epoch 61; Iter   180/  209] train: loss: 0.0610345
[Epoch 61] ogbg-moltox21: 0.723177 val loss: 0.385965
[Epoch 61] ogbg-moltox21: 0.704752 test loss: 0.414937
[Epoch 62; Iter     1/  209] train: loss: 0.0281547
[Epoch 62; Iter    31/  209] train: loss: 0.0614838
[Epoch 62; Iter    61/  209] train: loss: 0.0604694
[Epoch 62; Iter    91/  209] train: loss: 0.0535272
[Epoch 62; Iter   121/  209] train: loss: 0.0839283
[Epoch 62; Iter   151/  209] train: loss: 0.0486272
[Epoch 62; Iter   181/  209] train: loss: 0.0752829
[Epoch 62] ogbg-moltox21: 0.718826 val loss: 0.417935
[Epoch 62] ogbg-moltox21: 0.701159 test loss: 0.428252
[Epoch 63; Iter     2/  209] train: loss: 0.0735409
[Epoch 63; Iter    32/  209] train: loss: 0.1044212
[Epoch 63; Iter    62/  209] train: loss: 0.0878597
[Epoch 63; Iter    92/  209] train: loss: 0.0763090
[Epoch 63; Iter   122/  209] train: loss: 0.0769287
[Epoch 63; Iter   152/  209] train: loss: 0.0725206
[Epoch 63; Iter   182/  209] train: loss: 0.0648492
[Epoch 63] ogbg-moltox21: 0.725044 val loss: 0.375440
[Epoch 63] ogbg-moltox21: 0.705044 test loss: 0.413293
[Epoch 64; Iter     3/  209] train: loss: 0.0708455
[Epoch 64; Iter    33/  209] train: loss: 0.0701240
[Epoch 64; Iter    63/  209] train: loss: 0.0727917
[Epoch 64; Iter    93/  209] train: loss: 0.0629709
[Epoch 64; Iter   123/  209] train: loss: 0.0818440
[Epoch 64; Iter   153/  209] train: loss: 0.0618045
[Epoch 64; Iter   183/  209] train: loss: 0.0784800
[Epoch 64] ogbg-moltox21: 0.717837 val loss: 0.391327
[Epoch 47; Iter   166/  209] train: loss: 0.0404910
[Epoch 47; Iter   196/  209] train: loss: 0.0701847
[Epoch 47] ogbg-moltox21: 0.743688 val loss: 0.468406
[Epoch 47] ogbg-moltox21: 0.708682 test loss: 0.500522
[Epoch 48; Iter    17/  209] train: loss: 0.0887890
[Epoch 48; Iter    47/  209] train: loss: 0.0438257
[Epoch 48; Iter    77/  209] train: loss: 0.0786195
[Epoch 48; Iter   107/  209] train: loss: 0.0939857
[Epoch 48; Iter   137/  209] train: loss: 0.1239370
[Epoch 48; Iter   167/  209] train: loss: 0.0795626
[Epoch 48; Iter   197/  209] train: loss: 0.0736669
[Epoch 48] ogbg-moltox21: 0.752454 val loss: 0.505333
[Epoch 48] ogbg-moltox21: 0.709084 test loss: 0.542764
[Epoch 49; Iter    18/  209] train: loss: 0.1237149
[Epoch 49; Iter    48/  209] train: loss: 0.0811581
[Epoch 49; Iter    78/  209] train: loss: 0.0587322
[Epoch 49; Iter   108/  209] train: loss: 0.0541619
[Epoch 49; Iter   138/  209] train: loss: 0.1055695
[Epoch 49; Iter   168/  209] train: loss: 0.0811704
[Epoch 49; Iter   198/  209] train: loss: 0.0699547
[Epoch 49] ogbg-moltox21: 0.749632 val loss: 0.471889
[Epoch 49] ogbg-moltox21: 0.707261 test loss: 0.510729
[Epoch 50; Iter    19/  209] train: loss: 0.0679879
[Epoch 50; Iter    49/  209] train: loss: 0.0431679
[Epoch 50; Iter    79/  209] train: loss: 0.0914282
[Epoch 50; Iter   109/  209] train: loss: 0.0747685
[Epoch 50; Iter   139/  209] train: loss: 0.0489646
[Epoch 50; Iter   169/  209] train: loss: 0.0470820
[Epoch 50; Iter   199/  209] train: loss: 0.1063641
[Epoch 50] ogbg-moltox21: 0.739211 val loss: 0.513184
[Epoch 50] ogbg-moltox21: 0.715508 test loss: 0.549324
[Epoch 51; Iter    20/  209] train: loss: 0.0853185
[Epoch 51; Iter    50/  209] train: loss: 0.0632306
[Epoch 51; Iter    80/  209] train: loss: 0.0462937
[Epoch 51; Iter   110/  209] train: loss: 0.0646090
[Epoch 51; Iter   140/  209] train: loss: 0.0687803
[Epoch 51; Iter   170/  209] train: loss: 0.0614588
[Epoch 51; Iter   200/  209] train: loss: 0.0546070
[Epoch 51] ogbg-moltox21: 0.732107 val loss: 0.466998
[Epoch 51] ogbg-moltox21: 0.696679 test loss: 0.501214
[Epoch 52; Iter    21/  209] train: loss: 0.1098433
[Epoch 52; Iter    51/  209] train: loss: 0.0442667
[Epoch 52; Iter    81/  209] train: loss: 0.0523265
[Epoch 52; Iter   111/  209] train: loss: 0.0803899
[Epoch 52; Iter   141/  209] train: loss: 0.0531050
[Epoch 52; Iter   171/  209] train: loss: 0.0760125
[Epoch 52; Iter   201/  209] train: loss: 0.0973379
[Epoch 52] ogbg-moltox21: 0.737819 val loss: 0.519441
[Epoch 52] ogbg-moltox21: 0.695425 test loss: 0.552433
[Epoch 53; Iter    22/  209] train: loss: 0.0540934
[Epoch 53; Iter    52/  209] train: loss: 0.0676290
[Epoch 53; Iter    82/  209] train: loss: 0.0592426
[Epoch 53; Iter   112/  209] train: loss: 0.0368817
[Epoch 53; Iter   142/  209] train: loss: 0.0766455
[Epoch 53; Iter   172/  209] train: loss: 0.0542603
[Epoch 53; Iter   202/  209] train: loss: 0.1038803
[Epoch 53] ogbg-moltox21: 0.748121 val loss: 0.543109
[Epoch 53] ogbg-moltox21: 0.707450 test loss: 0.586403
[Epoch 54; Iter    23/  209] train: loss: 0.0614545
[Epoch 54; Iter    53/  209] train: loss: 0.0311838
[Epoch 54; Iter    83/  209] train: loss: 0.0543461
[Epoch 54; Iter   113/  209] train: loss: 0.0659508
[Epoch 54; Iter   143/  209] train: loss: 0.0676234
[Epoch 54; Iter   173/  209] train: loss: 0.0699224
[Epoch 54; Iter   203/  209] train: loss: 0.0539748
[Epoch 54] ogbg-moltox21: 0.740609 val loss: 0.613946
[Epoch 54] ogbg-moltox21: 0.699739 test loss: 0.674500
[Epoch 55; Iter    24/  209] train: loss: 0.0432598
[Epoch 55; Iter    54/  209] train: loss: 0.0399355
[Epoch 55; Iter    84/  209] train: loss: 0.0577622
[Epoch 55; Iter   114/  209] train: loss: 0.0684016
[Epoch 55; Iter   144/  209] train: loss: 0.0459283
[Epoch 55; Iter   174/  209] train: loss: 0.0482043
[Epoch 55; Iter   204/  209] train: loss: 0.0395464
[Epoch 55] ogbg-moltox21: 0.734075 val loss: 0.531456
[Epoch 55] ogbg-moltox21: 0.704320 test loss: 0.566909
[Epoch 56; Iter    25/  209] train: loss: 0.0489739
[Epoch 56; Iter    55/  209] train: loss: 0.0529554
[Epoch 56; Iter    85/  209] train: loss: 0.0393270
[Epoch 56; Iter   115/  209] train: loss: 0.0365351
[Epoch 56; Iter   145/  209] train: loss: 0.0455488
[Epoch 56; Iter   175/  209] train: loss: 0.0507050
[Epoch 56; Iter   205/  209] train: loss: 0.0642887
[Epoch 56] ogbg-moltox21: 0.742942 val loss: 0.496880
[Epoch 56] ogbg-moltox21: 0.702576 test loss: 0.542529
[Epoch 57; Iter    26/  209] train: loss: 0.0621320
[Epoch 57; Iter    56/  209] train: loss: 0.0723515
[Epoch 57; Iter    86/  209] train: loss: 0.0887752
[Epoch 57; Iter   116/  209] train: loss: 0.0386734
[Epoch 57; Iter   146/  209] train: loss: 0.0871232
[Epoch 57; Iter   176/  209] train: loss: 0.0385566
[Epoch 57; Iter   206/  209] train: loss: 0.0698913
[Epoch 57] ogbg-moltox21: 0.746855 val loss: 0.554334
[Epoch 57] ogbg-moltox21: 0.697145 test loss: 0.608418
[Epoch 58; Iter    27/  209] train: loss: 0.0585755
[Epoch 58; Iter    57/  209] train: loss: 0.0237074
[Epoch 58; Iter    87/  209] train: loss: 0.0426276
[Epoch 58; Iter   117/  209] train: loss: 0.0714265
[Epoch 58; Iter   147/  209] train: loss: 0.0642117
[Epoch 58; Iter   177/  209] train: loss: 0.0551922
[Epoch 58; Iter   207/  209] train: loss: 0.0289951
[Epoch 58] ogbg-moltox21: 0.741074 val loss: 0.569282
[Epoch 58] ogbg-moltox21: 0.694143 test loss: 0.634109
[Epoch 59; Iter    28/  209] train: loss: 0.0584908
[Epoch 59; Iter    58/  209] train: loss: 0.0396955
[Epoch 59; Iter    88/  209] train: loss: 0.0675917
[Epoch 59; Iter   118/  209] train: loss: 0.0304355
[Epoch 59; Iter   148/  209] train: loss: 0.1325166
[Epoch 59; Iter   178/  209] train: loss: 0.0583280
[Epoch 59; Iter   208/  209] train: loss: 0.0456222
[Epoch 59] ogbg-moltox21: 0.740093 val loss: 0.594860
[Epoch 59] ogbg-moltox21: 0.697486 test loss: 0.638949
[Epoch 60; Iter    29/  209] train: loss: 0.0275541
[Epoch 60; Iter    59/  209] train: loss: 0.0186650
[Epoch 60; Iter    89/  209] train: loss: 0.0721702
[Epoch 60; Iter   119/  209] train: loss: 0.0528255
[Epoch 60; Iter   149/  209] train: loss: 0.0361767
[Epoch 60; Iter   179/  209] train: loss: 0.0537357
[Epoch 60; Iter   209/  209] train: loss: 0.0681732
[Epoch 60] ogbg-moltox21: 0.739930 val loss: 0.623113
[Epoch 60] ogbg-moltox21: 0.698660 test loss: 0.647150
[Epoch 61; Iter    30/  209] train: loss: 0.0387809
[Epoch 61; Iter    60/  209] train: loss: 0.0346664
[Epoch 61; Iter    90/  209] train: loss: 0.0824648
[Epoch 61; Iter   120/  209] train: loss: 0.0464685
[Epoch 61; Iter   150/  209] train: loss: 0.1120779
[Epoch 61; Iter   180/  209] train: loss: 0.0976659
[Epoch 61] ogbg-moltox21: 0.728958 val loss: 0.646055
[Epoch 61] ogbg-moltox21: 0.689065 test loss: 0.688300
[Epoch 62; Iter     1/  209] train: loss: 0.0691128
[Epoch 62; Iter    31/  209] train: loss: 0.0230376
[Epoch 62; Iter    61/  209] train: loss: 0.0316517
[Epoch 62; Iter    91/  209] train: loss: 0.0372946
[Epoch 62; Iter   121/  209] train: loss: 0.0458984
[Epoch 62; Iter   151/  209] train: loss: 0.0463283
[Epoch 62; Iter   181/  209] train: loss: 0.0537003
[Epoch 62] ogbg-moltox21: 0.750977 val loss: 0.582202
[Epoch 62] ogbg-moltox21: 0.703558 test loss: 0.637052
[Epoch 63; Iter     2/  209] train: loss: 0.0234144
[Epoch 63; Iter    32/  209] train: loss: 0.0528049
[Epoch 63; Iter    62/  209] train: loss: 0.0388238
[Epoch 63; Iter    92/  209] train: loss: 0.0268057
[Epoch 63; Iter   122/  209] train: loss: 0.0356673
[Epoch 63; Iter   152/  209] train: loss: 0.0311255
[Epoch 63; Iter   182/  209] train: loss: 0.0479025
[Epoch 63] ogbg-moltox21: 0.744506 val loss: 0.583851
[Epoch 63] ogbg-moltox21: 0.701829 test loss: 0.637024
[Epoch 64; Iter     3/  209] train: loss: 0.0495436
[Epoch 64; Iter    33/  209] train: loss: 0.0349518
[Epoch 64; Iter    63/  209] train: loss: 0.0340522
[Epoch 64; Iter    93/  209] train: loss: 0.0423605
[Epoch 64; Iter   123/  209] train: loss: 0.0701215
[Epoch 64; Iter   153/  209] train: loss: 0.0524772
[Epoch 64; Iter   183/  209] train: loss: 0.0927489
[Epoch 64] ogbg-moltox21: 0.735204 val loss: 0.631684
[Epoch 47; Iter   166/  209] train: loss: 0.0749846
[Epoch 47; Iter   196/  209] train: loss: 0.1562106
[Epoch 47] ogbg-moltox21: 0.796670 val loss: 0.252888
[Epoch 47] ogbg-moltox21: 0.766682 test loss: 0.265848
[Epoch 48; Iter    17/  209] train: loss: 0.1601429
[Epoch 48; Iter    47/  209] train: loss: 0.1161615
[Epoch 48; Iter    77/  209] train: loss: 0.1381131
[Epoch 48; Iter   107/  209] train: loss: 0.1449893
[Epoch 48; Iter   137/  209] train: loss: 0.1485489
[Epoch 48; Iter   167/  209] train: loss: 0.1172305
[Epoch 48; Iter   197/  209] train: loss: 0.0942169
[Epoch 48] ogbg-moltox21: 0.802051 val loss: 0.257548
[Epoch 48] ogbg-moltox21: 0.772026 test loss: 0.271512
[Epoch 49; Iter    18/  209] train: loss: 0.1630658
[Epoch 49; Iter    48/  209] train: loss: 0.1418868
[Epoch 49; Iter    78/  209] train: loss: 0.0845249
[Epoch 49; Iter   108/  209] train: loss: 0.0807628
[Epoch 49; Iter   138/  209] train: loss: 0.1338396
[Epoch 49; Iter   168/  209] train: loss: 0.1789716
[Epoch 49; Iter   198/  209] train: loss: 0.1222323
[Epoch 49] ogbg-moltox21: 0.790473 val loss: 0.263697
[Epoch 49] ogbg-moltox21: 0.763484 test loss: 0.272184
[Epoch 50; Iter    19/  209] train: loss: 0.1231716
[Epoch 50; Iter    49/  209] train: loss: 0.0903154
[Epoch 50; Iter    79/  209] train: loss: 0.1639350
[Epoch 50; Iter   109/  209] train: loss: 0.1434245
[Epoch 50; Iter   139/  209] train: loss: 0.1074981
[Epoch 50; Iter   169/  209] train: loss: 0.1110453
[Epoch 50; Iter   199/  209] train: loss: 0.1592904
[Epoch 50] ogbg-moltox21: 0.799926 val loss: 0.256974
[Epoch 50] ogbg-moltox21: 0.771758 test loss: 0.264580
[Epoch 51; Iter    20/  209] train: loss: 0.1226407
[Epoch 51; Iter    50/  209] train: loss: 0.1078256
[Epoch 51; Iter    80/  209] train: loss: 0.0783533
[Epoch 51; Iter   110/  209] train: loss: 0.1569154
[Epoch 51; Iter   140/  209] train: loss: 0.1689419
[Epoch 51; Iter   170/  209] train: loss: 0.1568357
[Epoch 51; Iter   200/  209] train: loss: 0.0707461
[Epoch 51] ogbg-moltox21: 0.789104 val loss: 0.271364
[Epoch 51] ogbg-moltox21: 0.766185 test loss: 0.279986
[Epoch 52; Iter    21/  209] train: loss: 0.1629350
[Epoch 52; Iter    51/  209] train: loss: 0.0955402
[Epoch 52; Iter    81/  209] train: loss: 0.1057242
[Epoch 52; Iter   111/  209] train: loss: 0.1392273
[Epoch 52; Iter   141/  209] train: loss: 0.0858879
[Epoch 52; Iter   171/  209] train: loss: 0.1060015
[Epoch 52; Iter   201/  209] train: loss: 0.1740113
[Epoch 52] ogbg-moltox21: 0.801121 val loss: 0.263348
[Epoch 52] ogbg-moltox21: 0.779511 test loss: 0.270989
[Epoch 53; Iter    22/  209] train: loss: 0.1025965
[Epoch 53; Iter    52/  209] train: loss: 0.0925927
[Epoch 53; Iter    82/  209] train: loss: 0.1645389
[Epoch 53; Iter   112/  209] train: loss: 0.0743422
[Epoch 53; Iter   142/  209] train: loss: 0.1049977
[Epoch 53; Iter   172/  209] train: loss: 0.1183515
[Epoch 53; Iter   202/  209] train: loss: 0.1731521
[Epoch 53] ogbg-moltox21: 0.799791 val loss: 0.271337
[Epoch 53] ogbg-moltox21: 0.772987 test loss: 0.288853
[Epoch 54; Iter    23/  209] train: loss: 0.1041216
[Epoch 54; Iter    53/  209] train: loss: 0.0903605
[Epoch 54; Iter    83/  209] train: loss: 0.1104095
[Epoch 54; Iter   113/  209] train: loss: 0.1431894
[Epoch 54; Iter   143/  209] train: loss: 0.1471011
[Epoch 54; Iter   173/  209] train: loss: 0.1344637
[Epoch 54; Iter   203/  209] train: loss: 0.0946545
[Epoch 54] ogbg-moltox21: 0.790218 val loss: 0.283350
[Epoch 54] ogbg-moltox21: 0.766988 test loss: 0.288627
[Epoch 55; Iter    24/  209] train: loss: 0.0918364
[Epoch 55; Iter    54/  209] train: loss: 0.0933632
[Epoch 55; Iter    84/  209] train: loss: 0.0877763
[Epoch 55; Iter   114/  209] train: loss: 0.1233264
[Epoch 55; Iter   144/  209] train: loss: 0.0953674
[Epoch 55; Iter   174/  209] train: loss: 0.0870247
[Epoch 55; Iter   204/  209] train: loss: 0.0649903
[Epoch 55] ogbg-moltox21: 0.784050 val loss: 0.272266
[Epoch 55] ogbg-moltox21: 0.775751 test loss: 0.276199
[Epoch 56; Iter    25/  209] train: loss: 0.1471756
[Epoch 56; Iter    55/  209] train: loss: 0.0895719
[Epoch 56; Iter    85/  209] train: loss: 0.1053852
[Epoch 56; Iter   115/  209] train: loss: 0.0893493
[Epoch 56; Iter   145/  209] train: loss: 0.0461742
[Epoch 56; Iter   175/  209] train: loss: 0.1096080
[Epoch 56; Iter   205/  209] train: loss: 0.1309292
[Epoch 56] ogbg-moltox21: 0.789865 val loss: 0.280520
[Epoch 56] ogbg-moltox21: 0.770244 test loss: 0.297590
[Epoch 57; Iter    26/  209] train: loss: 0.1202179
[Epoch 57; Iter    56/  209] train: loss: 0.1236680
[Epoch 57; Iter    86/  209] train: loss: 0.1542256
[Epoch 57; Iter   116/  209] train: loss: 0.0932014
[Epoch 57; Iter   146/  209] train: loss: 0.1364357
[Epoch 57; Iter   176/  209] train: loss: 0.1346852
[Epoch 57; Iter   206/  209] train: loss: 0.1083331
[Epoch 57] ogbg-moltox21: 0.793685 val loss: 0.283326
[Epoch 57] ogbg-moltox21: 0.773700 test loss: 0.289168
[Epoch 58; Iter    27/  209] train: loss: 0.0978794
[Epoch 58; Iter    57/  209] train: loss: 0.0572169
[Epoch 58; Iter    87/  209] train: loss: 0.0987532
[Epoch 58; Iter   117/  209] train: loss: 0.1354851
[Epoch 58; Iter   147/  209] train: loss: 0.1015423
[Epoch 58; Iter   177/  209] train: loss: 0.0832051
[Epoch 58; Iter   207/  209] train: loss: 0.1214055
[Epoch 58] ogbg-moltox21: 0.787912 val loss: 0.278715
[Epoch 58] ogbg-moltox21: 0.771079 test loss: 0.289250
[Epoch 59; Iter    28/  209] train: loss: 0.1371959
[Epoch 59; Iter    58/  209] train: loss: 0.0761793
[Epoch 59; Iter    88/  209] train: loss: 0.1086374
[Epoch 59; Iter   118/  209] train: loss: 0.0724959
[Epoch 59; Iter   148/  209] train: loss: 0.1636084
[Epoch 59; Iter   178/  209] train: loss: 0.1249985
[Epoch 59; Iter   208/  209] train: loss: 0.1011601
[Epoch 59] ogbg-moltox21: 0.798760 val loss: 0.269924
[Epoch 59] ogbg-moltox21: 0.777536 test loss: 0.283098
[Epoch 60; Iter    29/  209] train: loss: 0.0801022
[Epoch 60; Iter    59/  209] train: loss: 0.0707713
[Epoch 60; Iter    89/  209] train: loss: 0.1139976
[Epoch 60; Iter   119/  209] train: loss: 0.1006480
[Epoch 60; Iter   149/  209] train: loss: 0.1019732
[Epoch 60; Iter   179/  209] train: loss: 0.0925014
[Epoch 60; Iter   209/  209] train: loss: 0.1117259
[Epoch 60] ogbg-moltox21: 0.784998 val loss: 0.275501
[Epoch 60] ogbg-moltox21: 0.764458 test loss: 0.289208
[Epoch 61; Iter    30/  209] train: loss: 0.0977165
[Epoch 61; Iter    60/  209] train: loss: 0.1241033
[Epoch 61; Iter    90/  209] train: loss: 0.1438774
[Epoch 61; Iter   120/  209] train: loss: 0.0882875
[Epoch 61; Iter   150/  209] train: loss: 0.1809478
[Epoch 61; Iter   180/  209] train: loss: 0.1674892
[Epoch 61] ogbg-moltox21: 0.786408 val loss: 0.309560
[Epoch 61] ogbg-moltox21: 0.769546 test loss: 0.296693
[Epoch 62; Iter     1/  209] train: loss: 0.1440432
[Epoch 62; Iter    31/  209] train: loss: 0.0602954
[Epoch 62; Iter    61/  209] train: loss: 0.0551077
[Epoch 62; Iter    91/  209] train: loss: 0.1120326
[Epoch 62; Iter   121/  209] train: loss: 0.1135693
[Epoch 62; Iter   151/  209] train: loss: 0.0698829
[Epoch 62; Iter   181/  209] train: loss: 0.0734346
[Epoch 62] ogbg-moltox21: 0.798827 val loss: 0.271863
[Epoch 62] ogbg-moltox21: 0.779236 test loss: 0.280240
[Epoch 63; Iter     2/  209] train: loss: 0.1007599
[Epoch 63; Iter    32/  209] train: loss: 0.1196746
[Epoch 63; Iter    62/  209] train: loss: 0.0855590
[Epoch 63; Iter    92/  209] train: loss: 0.1022096
[Epoch 63; Iter   122/  209] train: loss: 0.0908536
[Epoch 63; Iter   152/  209] train: loss: 0.0777135
[Epoch 63; Iter   182/  209] train: loss: 0.0694356
[Epoch 63] ogbg-moltox21: 0.793949 val loss: 0.290231
[Epoch 63] ogbg-moltox21: 0.771522 test loss: 0.303780
[Epoch 64; Iter     3/  209] train: loss: 0.1224229
[Epoch 64; Iter    33/  209] train: loss: 0.1008731
[Epoch 64; Iter    63/  209] train: loss: 0.0969410
[Epoch 64; Iter    93/  209] train: loss: 0.0973246
[Epoch 64; Iter   123/  209] train: loss: 0.1323050
[Epoch 64; Iter   153/  209] train: loss: 0.0900481
[Epoch 64; Iter   183/  209] train: loss: 0.1549830
[Epoch 64] ogbg-moltox21: 0.788340 val loss: 0.298017
[Epoch 47; Iter   166/  209] train: loss: 0.1247554
[Epoch 47; Iter   196/  209] train: loss: 0.0947461
[Epoch 47] ogbg-moltox21: 0.794285 val loss: 0.258325
[Epoch 47] ogbg-moltox21: 0.761934 test loss: 0.274004
[Epoch 48; Iter    17/  209] train: loss: 0.1616188
[Epoch 48; Iter    47/  209] train: loss: 0.1134106
[Epoch 48; Iter    77/  209] train: loss: 0.1310697
[Epoch 48; Iter   107/  209] train: loss: 0.1234487
[Epoch 48; Iter   137/  209] train: loss: 0.1463749
[Epoch 48; Iter   167/  209] train: loss: 0.1611100
[Epoch 48; Iter   197/  209] train: loss: 0.1108677
[Epoch 48] ogbg-moltox21: 0.800149 val loss: 0.259583
[Epoch 48] ogbg-moltox21: 0.766959 test loss: 0.278882
[Epoch 49; Iter    18/  209] train: loss: 0.1026259
[Epoch 49; Iter    48/  209] train: loss: 0.0820967
[Epoch 49; Iter    78/  209] train: loss: 0.1018353
[Epoch 49; Iter   108/  209] train: loss: 0.1064309
[Epoch 49; Iter   138/  209] train: loss: 0.1328312
[Epoch 49; Iter   168/  209] train: loss: 0.1616674
[Epoch 49; Iter   198/  209] train: loss: 0.1394102
[Epoch 49] ogbg-moltox21: 0.791482 val loss: 0.256008
[Epoch 49] ogbg-moltox21: 0.754013 test loss: 0.279370
[Epoch 50; Iter    19/  209] train: loss: 0.1945646
[Epoch 50; Iter    49/  209] train: loss: 0.0726315
[Epoch 50; Iter    79/  209] train: loss: 0.0899358
[Epoch 50; Iter   109/  209] train: loss: 0.1218607
[Epoch 50; Iter   139/  209] train: loss: 0.0860796
[Epoch 50; Iter   169/  209] train: loss: 0.0867175
[Epoch 50; Iter   199/  209] train: loss: 0.0715370
[Epoch 50] ogbg-moltox21: 0.798981 val loss: 0.258995
[Epoch 50] ogbg-moltox21: 0.755125 test loss: 0.278629
[Epoch 51; Iter    20/  209] train: loss: 0.1411200
[Epoch 51; Iter    50/  209] train: loss: 0.1055000
[Epoch 51; Iter    80/  209] train: loss: 0.0724384
[Epoch 51; Iter   110/  209] train: loss: 0.0830922
[Epoch 51; Iter   140/  209] train: loss: 0.1236017
[Epoch 51; Iter   170/  209] train: loss: 0.1238120
[Epoch 51; Iter   200/  209] train: loss: 0.1282129
[Epoch 51] ogbg-moltox21: 0.799517 val loss: 0.260779
[Epoch 51] ogbg-moltox21: 0.760814 test loss: 0.285446
[Epoch 52; Iter    21/  209] train: loss: 0.1246748
[Epoch 52; Iter    51/  209] train: loss: 0.1093812
[Epoch 52; Iter    81/  209] train: loss: 0.1643715
[Epoch 52; Iter   111/  209] train: loss: 0.1595833
[Epoch 52; Iter   141/  209] train: loss: 0.0925660
[Epoch 52; Iter   171/  209] train: loss: 0.1002057
[Epoch 52; Iter   201/  209] train: loss: 0.1336611
[Epoch 52] ogbg-moltox21: 0.792068 val loss: 0.265335
[Epoch 52] ogbg-moltox21: 0.754123 test loss: 0.283191
[Epoch 53; Iter    22/  209] train: loss: 0.1125186
[Epoch 53; Iter    52/  209] train: loss: 0.0884290
[Epoch 53; Iter    82/  209] train: loss: 0.1308524
[Epoch 53; Iter   112/  209] train: loss: 0.0848740
[Epoch 53; Iter   142/  209] train: loss: 0.0792607
[Epoch 53; Iter   172/  209] train: loss: 0.1119487
[Epoch 53; Iter   202/  209] train: loss: 0.1020775
[Epoch 53] ogbg-moltox21: 0.781654 val loss: 0.269366
[Epoch 53] ogbg-moltox21: 0.747137 test loss: 0.289811
[Epoch 54; Iter    23/  209] train: loss: 0.1063977
[Epoch 54; Iter    53/  209] train: loss: 0.1343933
[Epoch 54; Iter    83/  209] train: loss: 0.0891018
[Epoch 54; Iter   113/  209] train: loss: 0.1072244
[Epoch 54; Iter   143/  209] train: loss: 0.1332627
[Epoch 54; Iter   173/  209] train: loss: 0.1374802
[Epoch 54; Iter   203/  209] train: loss: 0.1124232
[Epoch 54] ogbg-moltox21: 0.792564 val loss: 0.274174
[Epoch 54] ogbg-moltox21: 0.751276 test loss: 0.292015
[Epoch 55; Iter    24/  209] train: loss: 0.1030609
[Epoch 55; Iter    54/  209] train: loss: 0.1019890
[Epoch 55; Iter    84/  209] train: loss: 0.1168526
[Epoch 55; Iter   114/  209] train: loss: 0.1290234
[Epoch 55; Iter   144/  209] train: loss: 0.1430221
[Epoch 55; Iter   174/  209] train: loss: 0.1016130
[Epoch 55; Iter   204/  209] train: loss: 0.0720824
[Epoch 55] ogbg-moltox21: 0.784165 val loss: 0.276879
[Epoch 55] ogbg-moltox21: 0.743418 test loss: 0.301863
[Epoch 56; Iter    25/  209] train: loss: 0.1419020
[Epoch 56; Iter    55/  209] train: loss: 0.1149282
[Epoch 56; Iter    85/  209] train: loss: 0.1003136
[Epoch 56; Iter   115/  209] train: loss: 0.1269504
[Epoch 56; Iter   145/  209] train: loss: 0.1504386
[Epoch 56; Iter   175/  209] train: loss: 0.1360828
[Epoch 56; Iter   205/  209] train: loss: 0.0930049
[Epoch 56] ogbg-moltox21: 0.785092 val loss: 0.284085
[Epoch 56] ogbg-moltox21: 0.760860 test loss: 0.297937
[Epoch 57; Iter    26/  209] train: loss: 0.0810087
[Epoch 57; Iter    56/  209] train: loss: 0.1344152
[Epoch 57; Iter    86/  209] train: loss: 0.1528144
[Epoch 57; Iter   116/  209] train: loss: 0.0464303
[Epoch 57; Iter   146/  209] train: loss: 0.0880145
[Epoch 57; Iter   176/  209] train: loss: 0.1808199
[Epoch 57; Iter   206/  209] train: loss: 0.1484459
[Epoch 57] ogbg-moltox21: 0.791056 val loss: 0.271228
[Epoch 57] ogbg-moltox21: 0.750635 test loss: 0.299893
[Epoch 58; Iter    27/  209] train: loss: 0.0889210
[Epoch 58; Iter    57/  209] train: loss: 0.0587472
[Epoch 58; Iter    87/  209] train: loss: 0.1355461
[Epoch 58; Iter   117/  209] train: loss: 0.0636747
[Epoch 58; Iter   147/  209] train: loss: 0.0836216
[Epoch 58; Iter   177/  209] train: loss: 0.0794847
[Epoch 58; Iter   207/  209] train: loss: 0.1096053
[Epoch 58] ogbg-moltox21: 0.793479 val loss: 0.282588
[Epoch 58] ogbg-moltox21: 0.748705 test loss: 0.304709
[Epoch 59; Iter    28/  209] train: loss: 0.1763225
[Epoch 59; Iter    58/  209] train: loss: 0.1634491
[Epoch 59; Iter    88/  209] train: loss: 0.1098707
[Epoch 59; Iter   118/  209] train: loss: 0.0921515
[Epoch 59; Iter   148/  209] train: loss: 0.1200300
[Epoch 59; Iter   178/  209] train: loss: 0.1469053
[Epoch 59; Iter   208/  209] train: loss: 0.1331240
[Epoch 59] ogbg-moltox21: 0.781692 val loss: 0.273777
[Epoch 59] ogbg-moltox21: 0.746795 test loss: 0.296244
[Epoch 60; Iter    29/  209] train: loss: 0.0970290
[Epoch 60; Iter    59/  209] train: loss: 0.0630239
[Epoch 60; Iter    89/  209] train: loss: 0.0758814
[Epoch 60; Iter   119/  209] train: loss: 0.1070068
[Epoch 60; Iter   149/  209] train: loss: 0.1034948
[Epoch 60; Iter   179/  209] train: loss: 0.0955141
[Epoch 60; Iter   209/  209] train: loss: 0.1936533
[Epoch 60] ogbg-moltox21: 0.787391 val loss: 0.285404
[Epoch 60] ogbg-moltox21: 0.745870 test loss: 0.311771
[Epoch 61; Iter    30/  209] train: loss: 0.1084253
[Epoch 61; Iter    60/  209] train: loss: 0.1083430
[Epoch 61; Iter    90/  209] train: loss: 0.0756442
[Epoch 61; Iter   120/  209] train: loss: 0.1148922
[Epoch 61; Iter   150/  209] train: loss: 0.1367266
[Epoch 61; Iter   180/  209] train: loss: 0.1145673
[Epoch 61] ogbg-moltox21: 0.783601 val loss: 0.299311
[Epoch 61] ogbg-moltox21: 0.736391 test loss: 0.329875
[Epoch 62; Iter     1/  209] train: loss: 0.0932567
[Epoch 62; Iter    31/  209] train: loss: 0.0948118
[Epoch 62; Iter    61/  209] train: loss: 0.0844309
[Epoch 62; Iter    91/  209] train: loss: 0.1300767
[Epoch 62; Iter   121/  209] train: loss: 0.0988833
[Epoch 62; Iter   151/  209] train: loss: 0.1225337
[Epoch 62; Iter   181/  209] train: loss: 0.1197695
[Epoch 62] ogbg-moltox21: 0.782283 val loss: 0.283086
[Epoch 62] ogbg-moltox21: 0.739893 test loss: 0.316116
[Epoch 63; Iter     2/  209] train: loss: 0.1179197
[Epoch 63; Iter    32/  209] train: loss: 0.1986160
[Epoch 63; Iter    62/  209] train: loss: 0.1084091
[Epoch 63; Iter    92/  209] train: loss: 0.0764371
[Epoch 63; Iter   122/  209] train: loss: 0.1152202
[Epoch 63; Iter   152/  209] train: loss: 0.1018760
[Epoch 63; Iter   182/  209] train: loss: 0.0708698
[Epoch 63] ogbg-moltox21: 0.779873 val loss: 0.295105
[Epoch 63] ogbg-moltox21: 0.743608 test loss: 0.320320
[Epoch 64; Iter     3/  209] train: loss: 0.0821141
[Epoch 64; Iter    33/  209] train: loss: 0.1028473
[Epoch 64; Iter    63/  209] train: loss: 0.1176662
[Epoch 64; Iter    93/  209] train: loss: 0.0733822
[Epoch 64; Iter   123/  209] train: loss: 0.1518519
[Epoch 64; Iter   153/  209] train: loss: 0.1950446
[Epoch 64; Iter   183/  209] train: loss: 0.1026371
[Epoch 64] ogbg-moltox21: 0.789605 val loss: 0.294816
[Epoch 47; Iter   166/  209] train: loss: 0.1137387
[Epoch 47; Iter   196/  209] train: loss: 0.1423750
[Epoch 47] ogbg-moltox21: 0.792572 val loss: 0.249177
[Epoch 47] ogbg-moltox21: 0.757933 test loss: 0.263954
[Epoch 48; Iter    17/  209] train: loss: 0.1120187
[Epoch 48; Iter    47/  209] train: loss: 0.1335494
[Epoch 48; Iter    77/  209] train: loss: 0.1142477
[Epoch 48; Iter   107/  209] train: loss: 0.0809634
[Epoch 48; Iter   137/  209] train: loss: 0.1734364
[Epoch 48; Iter   167/  209] train: loss: 0.1196777
[Epoch 48; Iter   197/  209] train: loss: 0.0688173
[Epoch 48] ogbg-moltox21: 0.801981 val loss: 0.251584
[Epoch 48] ogbg-moltox21: 0.761762 test loss: 0.267952
[Epoch 49; Iter    18/  209] train: loss: 0.1182378
[Epoch 49; Iter    48/  209] train: loss: 0.1143518
[Epoch 49; Iter    78/  209] train: loss: 0.1605288
[Epoch 49; Iter   108/  209] train: loss: 0.1791905
[Epoch 49; Iter   138/  209] train: loss: 0.1044399
[Epoch 49; Iter   168/  209] train: loss: 0.1145616
[Epoch 49; Iter   198/  209] train: loss: 0.1823270
[Epoch 49] ogbg-moltox21: 0.796756 val loss: 0.271725
[Epoch 49] ogbg-moltox21: 0.759843 test loss: 0.283663
[Epoch 50; Iter    19/  209] train: loss: 0.0983291
[Epoch 50; Iter    49/  209] train: loss: 0.1187318
[Epoch 50; Iter    79/  209] train: loss: 0.0935309
[Epoch 50; Iter   109/  209] train: loss: 0.1311110
[Epoch 50; Iter   139/  209] train: loss: 0.1600639
[Epoch 50; Iter   169/  209] train: loss: 0.1152149
[Epoch 50; Iter   199/  209] train: loss: 0.1439957
[Epoch 50] ogbg-moltox21: 0.797975 val loss: 0.251801
[Epoch 50] ogbg-moltox21: 0.751411 test loss: 0.271885
[Epoch 51; Iter    20/  209] train: loss: 0.1200497
[Epoch 51; Iter    50/  209] train: loss: 0.1606304
[Epoch 51; Iter    80/  209] train: loss: 0.0783325
[Epoch 51; Iter   110/  209] train: loss: 0.1232741
[Epoch 51; Iter   140/  209] train: loss: 0.1403126
[Epoch 51; Iter   170/  209] train: loss: 0.1419874
[Epoch 51; Iter   200/  209] train: loss: 0.1507840
[Epoch 51] ogbg-moltox21: 0.795001 val loss: 0.260484
[Epoch 51] ogbg-moltox21: 0.764764 test loss: 0.276222
[Epoch 52; Iter    21/  209] train: loss: 0.1021592
[Epoch 52; Iter    51/  209] train: loss: 0.1150521
[Epoch 52; Iter    81/  209] train: loss: 0.1138158
[Epoch 52; Iter   111/  209] train: loss: 0.1133675
[Epoch 52; Iter   141/  209] train: loss: 0.0683706
[Epoch 52; Iter   171/  209] train: loss: 0.1513376
[Epoch 52; Iter   201/  209] train: loss: 0.0934363
[Epoch 52] ogbg-moltox21: 0.805234 val loss: 0.261844
[Epoch 52] ogbg-moltox21: 0.753744 test loss: 0.288356
[Epoch 53; Iter    22/  209] train: loss: 0.1254078
[Epoch 53; Iter    52/  209] train: loss: 0.1460659
[Epoch 53; Iter    82/  209] train: loss: 0.0659577
[Epoch 53; Iter   112/  209] train: loss: 0.1866011
[Epoch 53; Iter   142/  209] train: loss: 0.1256967
[Epoch 53; Iter   172/  209] train: loss: 0.0849802
[Epoch 53; Iter   202/  209] train: loss: 0.1318101
[Epoch 53] ogbg-moltox21: 0.804704 val loss: 0.252194
[Epoch 53] ogbg-moltox21: 0.754306 test loss: 0.275425
[Epoch 54; Iter    23/  209] train: loss: 0.1395939
[Epoch 54; Iter    53/  209] train: loss: 0.0840251
[Epoch 54; Iter    83/  209] train: loss: 0.0879550
[Epoch 54; Iter   113/  209] train: loss: 0.0891511
[Epoch 54; Iter   143/  209] train: loss: 0.1835766
[Epoch 54; Iter   173/  209] train: loss: 0.1006122
[Epoch 54; Iter   203/  209] train: loss: 0.1561936
[Epoch 54] ogbg-moltox21: 0.799963 val loss: 0.257773
[Epoch 54] ogbg-moltox21: 0.756670 test loss: 0.271154
[Epoch 55; Iter    24/  209] train: loss: 0.1032270
[Epoch 55; Iter    54/  209] train: loss: 0.1079574
[Epoch 55; Iter    84/  209] train: loss: 0.1211628
[Epoch 55; Iter   114/  209] train: loss: 0.0851304
[Epoch 55; Iter   144/  209] train: loss: 0.1334883
[Epoch 55; Iter   174/  209] train: loss: 0.1572275
[Epoch 55; Iter   204/  209] train: loss: 0.0977513
[Epoch 55] ogbg-moltox21: 0.800777 val loss: 0.258367
[Epoch 55] ogbg-moltox21: 0.766817 test loss: 0.269489
[Epoch 56; Iter    25/  209] train: loss: 0.1526307
[Epoch 56; Iter    55/  209] train: loss: 0.1255544
[Epoch 56; Iter    85/  209] train: loss: 0.1386022
[Epoch 56; Iter   115/  209] train: loss: 0.1117283
[Epoch 56; Iter   145/  209] train: loss: 0.0933305
[Epoch 56; Iter   175/  209] train: loss: 0.0747995
[Epoch 56; Iter   205/  209] train: loss: 0.1154257
[Epoch 56] ogbg-moltox21: 0.797266 val loss: 0.255107
[Epoch 56] ogbg-moltox21: 0.762555 test loss: 0.273504
[Epoch 57; Iter    26/  209] train: loss: 0.0675808
[Epoch 57; Iter    56/  209] train: loss: 0.0940124
[Epoch 57; Iter    86/  209] train: loss: 0.1440952
[Epoch 57; Iter   116/  209] train: loss: 0.0768694
[Epoch 57; Iter   146/  209] train: loss: 0.1180681
[Epoch 57; Iter   176/  209] train: loss: 0.1130180
[Epoch 57; Iter   206/  209] train: loss: 0.1035222
[Epoch 57] ogbg-moltox21: 0.789435 val loss: 0.275184
[Epoch 57] ogbg-moltox21: 0.753827 test loss: 0.301566
[Epoch 58; Iter    27/  209] train: loss: 0.1117142
[Epoch 58; Iter    57/  209] train: loss: 0.0913930
[Epoch 58; Iter    87/  209] train: loss: 0.1001210
[Epoch 58; Iter   117/  209] train: loss: 0.0953195
[Epoch 58; Iter   147/  209] train: loss: 0.1203426
[Epoch 58; Iter   177/  209] train: loss: 0.1059474
[Epoch 58; Iter   207/  209] train: loss: 0.0819014
[Epoch 58] ogbg-moltox21: 0.790525 val loss: 0.265300
[Epoch 58] ogbg-moltox21: 0.751967 test loss: 0.281804
[Epoch 59; Iter    28/  209] train: loss: 0.0992327
[Epoch 59; Iter    58/  209] train: loss: 0.0816407
[Epoch 59; Iter    88/  209] train: loss: 0.1483413
[Epoch 59; Iter   118/  209] train: loss: 0.1404247
[Epoch 59; Iter   148/  209] train: loss: 0.1385026
[Epoch 59; Iter   178/  209] train: loss: 0.0618189
[Epoch 59; Iter   208/  209] train: loss: 0.1174094
[Epoch 59] ogbg-moltox21: 0.798039 val loss: 0.276963
[Epoch 59] ogbg-moltox21: 0.764962 test loss: 0.286082
[Epoch 60; Iter    29/  209] train: loss: 0.1441683
[Epoch 60; Iter    59/  209] train: loss: 0.0901906
[Epoch 60; Iter    89/  209] train: loss: 0.0730303
[Epoch 60; Iter   119/  209] train: loss: 0.1238561
[Epoch 60; Iter   149/  209] train: loss: 0.1209468
[Epoch 60; Iter   179/  209] train: loss: 0.2153251
[Epoch 60; Iter   209/  209] train: loss: 0.1152999
[Epoch 60] ogbg-moltox21: 0.794750 val loss: 0.267134
[Epoch 60] ogbg-moltox21: 0.759564 test loss: 0.284203
[Epoch 61; Iter    30/  209] train: loss: 0.0896512
[Epoch 61; Iter    60/  209] train: loss: 0.1131461
[Epoch 61; Iter    90/  209] train: loss: 0.1830376
[Epoch 61; Iter   120/  209] train: loss: 0.1086389
[Epoch 61; Iter   150/  209] train: loss: 0.1095622
[Epoch 61; Iter   180/  209] train: loss: 0.0954863
[Epoch 61] ogbg-moltox21: 0.795562 val loss: 0.269113
[Epoch 61] ogbg-moltox21: 0.760639 test loss: 0.289266
[Epoch 62; Iter     1/  209] train: loss: 0.0650493
[Epoch 62; Iter    31/  209] train: loss: 0.0867330
[Epoch 62; Iter    61/  209] train: loss: 0.0959015
[Epoch 62; Iter    91/  209] train: loss: 0.0871279
[Epoch 62; Iter   121/  209] train: loss: 0.1535941
[Epoch 62; Iter   151/  209] train: loss: 0.0776808
[Epoch 62; Iter   181/  209] train: loss: 0.1004841
[Epoch 62] ogbg-moltox21: 0.794520 val loss: 0.266487
[Epoch 62] ogbg-moltox21: 0.748139 test loss: 0.293122
[Epoch 63; Iter     2/  209] train: loss: 0.0995338
[Epoch 63; Iter    32/  209] train: loss: 0.1425606
[Epoch 63; Iter    62/  209] train: loss: 0.0827945
[Epoch 63; Iter    92/  209] train: loss: 0.0908979
[Epoch 63; Iter   122/  209] train: loss: 0.1021537
[Epoch 63; Iter   152/  209] train: loss: 0.0997436
[Epoch 63; Iter   182/  209] train: loss: 0.0992925
[Epoch 63] ogbg-moltox21: 0.792011 val loss: 0.276702
[Epoch 63] ogbg-moltox21: 0.758943 test loss: 0.289561
[Epoch 64; Iter     3/  209] train: loss: 0.0759877
[Epoch 64; Iter    33/  209] train: loss: 0.0923801
[Epoch 64; Iter    63/  209] train: loss: 0.0978626
[Epoch 64; Iter    93/  209] train: loss: 0.0864033
[Epoch 64; Iter   123/  209] train: loss: 0.1224849
[Epoch 64; Iter   153/  209] train: loss: 0.0812825
[Epoch 64; Iter   183/  209] train: loss: 0.1093712
[Epoch 64] ogbg-moltox21: 0.788955 val loss: 0.271465
[Epoch 64] ogbg-moltox21: 0.754787 test loss: 0.476011
[Epoch 65; Iter     4/  209] train: loss: 0.0380783
[Epoch 65; Iter    34/  209] train: loss: 0.0480850
[Epoch 65; Iter    64/  209] train: loss: 0.0430110
[Epoch 65; Iter    94/  209] train: loss: 0.0639047
[Epoch 65; Iter   124/  209] train: loss: 0.0317879
[Epoch 65; Iter   154/  209] train: loss: 0.0299981
[Epoch 65; Iter   184/  209] train: loss: 0.0479118
[Epoch 65] ogbg-moltox21: 0.790234 val loss: 0.392414
[Epoch 65] ogbg-moltox21: 0.752224 test loss: 0.452950
[Epoch 66; Iter     5/  209] train: loss: 0.0272591
[Epoch 66; Iter    35/  209] train: loss: 0.0422587
[Epoch 66; Iter    65/  209] train: loss: 0.0275064
[Epoch 66; Iter    95/  209] train: loss: 0.0338204
[Epoch 66; Iter   125/  209] train: loss: 0.0331329
[Epoch 66; Iter   155/  209] train: loss: 0.0333246
[Epoch 66; Iter   185/  209] train: loss: 0.0279462
[Epoch 66] ogbg-moltox21: 0.786664 val loss: 0.419347
[Epoch 66] ogbg-moltox21: 0.751981 test loss: 0.455815
[Epoch 67; Iter     6/  209] train: loss: 0.0249025
[Epoch 67; Iter    36/  209] train: loss: 0.0471668
[Epoch 67; Iter    66/  209] train: loss: 0.0345788
[Epoch 67; Iter    96/  209] train: loss: 0.0291511
[Epoch 67; Iter   126/  209] train: loss: 0.0196642
[Epoch 67; Iter   156/  209] train: loss: 0.0220598
[Epoch 67; Iter   186/  209] train: loss: 0.0424787
[Epoch 67] ogbg-moltox21: 0.783412 val loss: 0.412576
[Epoch 67] ogbg-moltox21: 0.746699 test loss: 0.445680
[Epoch 68; Iter     7/  209] train: loss: 0.0293598
[Epoch 68; Iter    37/  209] train: loss: 0.0211000
[Epoch 68; Iter    67/  209] train: loss: 0.0562258
[Epoch 68; Iter    97/  209] train: loss: 0.0321102
[Epoch 68; Iter   127/  209] train: loss: 0.0398432
[Epoch 68; Iter   157/  209] train: loss: 0.0389697
[Epoch 68; Iter   187/  209] train: loss: 0.0395953
[Epoch 68] ogbg-moltox21: 0.794254 val loss: 0.393876
[Epoch 68] ogbg-moltox21: 0.750140 test loss: 0.492201
[Epoch 69; Iter     8/  209] train: loss: 0.0461297
[Epoch 69; Iter    38/  209] train: loss: 0.0376527
[Epoch 69; Iter    68/  209] train: loss: 0.0365148
[Epoch 69; Iter    98/  209] train: loss: 0.0368624
[Epoch 69; Iter   128/  209] train: loss: 0.0350068
[Epoch 69; Iter   158/  209] train: loss: 0.0291135
[Epoch 69; Iter   188/  209] train: loss: 0.0415244
[Epoch 69] ogbg-moltox21: 0.787331 val loss: 0.421684
[Epoch 69] ogbg-moltox21: 0.744607 test loss: 0.481301
[Epoch 70; Iter     9/  209] train: loss: 0.0249378
[Epoch 70; Iter    39/  209] train: loss: 0.0371474
[Epoch 70; Iter    69/  209] train: loss: 0.0624354
[Epoch 70; Iter    99/  209] train: loss: 0.0421530
[Epoch 70; Iter   129/  209] train: loss: 0.0299973
[Epoch 70; Iter   159/  209] train: loss: 0.0378525
[Epoch 70; Iter   189/  209] train: loss: 0.0284598
[Epoch 70] ogbg-moltox21: 0.790005 val loss: 0.416208
[Epoch 70] ogbg-moltox21: 0.747830 test loss: 0.501900
[Epoch 71; Iter    10/  209] train: loss: 0.0143476
[Epoch 71; Iter    40/  209] train: loss: 0.0300117
[Epoch 71; Iter    70/  209] train: loss: 0.0321019
[Epoch 71; Iter   100/  209] train: loss: 0.0444690
[Epoch 71; Iter   130/  209] train: loss: 0.0297549
[Epoch 71; Iter   160/  209] train: loss: 0.0450835
[Epoch 71; Iter   190/  209] train: loss: 0.0275036
[Epoch 71] ogbg-moltox21: 0.792472 val loss: 0.419325
[Epoch 71] ogbg-moltox21: 0.742835 test loss: 0.533975
[Epoch 72; Iter    11/  209] train: loss: 0.0474823
[Epoch 72; Iter    41/  209] train: loss: 0.0132870
[Epoch 72; Iter    71/  209] train: loss: 0.0340608
[Epoch 72; Iter   101/  209] train: loss: 0.0217674
[Epoch 72; Iter   131/  209] train: loss: 0.0235001
[Epoch 72; Iter   161/  209] train: loss: 0.0411548
[Epoch 72; Iter   191/  209] train: loss: 0.0554598
[Epoch 72] ogbg-moltox21: 0.787486 val loss: 0.428586
[Epoch 72] ogbg-moltox21: 0.746237 test loss: 0.519813
[Epoch 73; Iter    12/  209] train: loss: 0.0146132
[Epoch 73; Iter    42/  209] train: loss: 0.0327806
[Epoch 73; Iter    72/  209] train: loss: 0.0259176
[Epoch 73; Iter   102/  209] train: loss: 0.0229017
[Epoch 73; Iter   132/  209] train: loss: 0.0436427
[Epoch 73; Iter   162/  209] train: loss: 0.0147662
[Epoch 73; Iter   192/  209] train: loss: 0.0206168
[Epoch 73] ogbg-moltox21: 0.780457 val loss: 0.437802
[Epoch 73] ogbg-moltox21: 0.740213 test loss: 0.502458
[Epoch 74; Iter    13/  209] train: loss: 0.0217396
[Epoch 74; Iter    43/  209] train: loss: 0.0326893
[Epoch 74; Iter    73/  209] train: loss: 0.0747010
[Epoch 74; Iter   103/  209] train: loss: 0.0300068
[Epoch 74; Iter   133/  209] train: loss: 0.0331773
[Epoch 74; Iter   163/  209] train: loss: 0.0693298
[Epoch 74; Iter   193/  209] train: loss: 0.0333574
[Epoch 74] ogbg-moltox21: 0.788284 val loss: 0.433684
[Epoch 74] ogbg-moltox21: 0.739673 test loss: 0.543342
[Epoch 75; Iter    14/  209] train: loss: 0.0233012
[Epoch 75; Iter    44/  209] train: loss: 0.0300756
[Epoch 75; Iter    74/  209] train: loss: 0.0342343
[Epoch 75; Iter   104/  209] train: loss: 0.0410213
[Epoch 75; Iter   134/  209] train: loss: 0.0630894
[Epoch 75; Iter   164/  209] train: loss: 0.0255870
[Epoch 75; Iter   194/  209] train: loss: 0.0221849
[Epoch 75] ogbg-moltox21: 0.783134 val loss: 0.454302
[Epoch 75] ogbg-moltox21: 0.737389 test loss: 0.551143
[Epoch 76; Iter    15/  209] train: loss: 0.0422350
[Epoch 76; Iter    45/  209] train: loss: 0.0266958
[Epoch 76; Iter    75/  209] train: loss: 0.0295257
[Epoch 76; Iter   105/  209] train: loss: 0.0487843
[Epoch 76; Iter   135/  209] train: loss: 0.0312332
[Epoch 76; Iter   165/  209] train: loss: 0.0303248
[Epoch 76; Iter   195/  209] train: loss: 0.0214053
[Epoch 76] ogbg-moltox21: 0.785375 val loss: 0.441980
[Epoch 76] ogbg-moltox21: 0.745959 test loss: 0.559846
[Epoch 77; Iter    16/  209] train: loss: 0.0212785
[Epoch 77; Iter    46/  209] train: loss: 0.0161685
[Epoch 77; Iter    76/  209] train: loss: 0.0121871
[Epoch 77; Iter   106/  209] train: loss: 0.0299141
[Epoch 77; Iter   136/  209] train: loss: 0.0225575
[Epoch 77; Iter   166/  209] train: loss: 0.0481205
[Epoch 77; Iter   196/  209] train: loss: 0.0183301
[Epoch 77] ogbg-moltox21: 0.789926 val loss: 0.435011
[Epoch 77] ogbg-moltox21: 0.747902 test loss: 0.497518
[Epoch 78; Iter    17/  209] train: loss: 0.0575593
[Epoch 78; Iter    47/  209] train: loss: 0.0246515
[Epoch 78; Iter    77/  209] train: loss: 0.0992988
[Epoch 78; Iter   107/  209] train: loss: 0.0470164
[Epoch 78; Iter   137/  209] train: loss: 0.0221930
[Epoch 78; Iter   167/  209] train: loss: 0.0254649
[Epoch 78; Iter   197/  209] train: loss: 0.0199501
[Epoch 78] ogbg-moltox21: 0.791342 val loss: 0.433398
[Epoch 78] ogbg-moltox21: 0.743698 test loss: 0.544243
[Epoch 79; Iter    18/  209] train: loss: 0.0406156
[Epoch 79; Iter    48/  209] train: loss: 0.0319905
[Epoch 79; Iter    78/  209] train: loss: 0.0489766
[Epoch 79; Iter   108/  209] train: loss: 0.0266850
[Epoch 79; Iter   138/  209] train: loss: 0.0522249
[Epoch 79; Iter   168/  209] train: loss: 0.0320868
[Epoch 79; Iter   198/  209] train: loss: 0.0274665
[Epoch 79] ogbg-moltox21: 0.785049 val loss: 0.439528
[Epoch 79] ogbg-moltox21: 0.740006 test loss: 0.554636
[Epoch 80; Iter    19/  209] train: loss: 0.0396546
[Epoch 80; Iter    49/  209] train: loss: 0.0274570
[Epoch 80; Iter    79/  209] train: loss: 0.0399005
[Epoch 80; Iter   109/  209] train: loss: 0.0460562
[Epoch 80; Iter   139/  209] train: loss: 0.0505602
[Epoch 80; Iter   169/  209] train: loss: 0.0117572
[Epoch 80; Iter   199/  209] train: loss: 0.0316739
[Epoch 80] ogbg-moltox21: 0.782459 val loss: 0.462678
[Epoch 80] ogbg-moltox21: 0.739288 test loss: 0.571626
[Epoch 81; Iter    20/  209] train: loss: 0.0386750
[Epoch 81; Iter    50/  209] train: loss: 0.0230494
[Epoch 81; Iter    80/  209] train: loss: 0.0247339
[Epoch 81; Iter   110/  209] train: loss: 0.0394235
[Epoch 81; Iter   140/  209] train: loss: 0.0084436
[Epoch 81; Iter   170/  209] train: loss: 0.0168901
[Epoch 81; Iter   200/  209] train: loss: 0.0281027
[Epoch 81] ogbg-moltox21: 0.786559 val loss: 0.473198
[Epoch 81] ogbg-moltox21: 0.743363 test loss: 0.581444
[Epoch 82; Iter    21/  209] train: loss: 0.0179213
[Epoch 64] ogbg-moltox21: 0.695199 test loss: 0.572266
[Epoch 65; Iter     4/  209] train: loss: 0.0261744
[Epoch 65; Iter    34/  209] train: loss: 0.0297690
[Epoch 65; Iter    64/  209] train: loss: 0.0092215
[Epoch 65; Iter    94/  209] train: loss: 0.0703657
[Epoch 65; Iter   124/  209] train: loss: 0.0352569
[Epoch 65; Iter   154/  209] train: loss: 0.0177325
[Epoch 65; Iter   184/  209] train: loss: 0.0227822
[Epoch 65] ogbg-moltox21: 0.768110 val loss: 0.573513
[Epoch 65] ogbg-moltox21: 0.698561 test loss: 0.577227
[Epoch 66; Iter     5/  209] train: loss: 0.0299425
[Epoch 66; Iter    35/  209] train: loss: 0.0147738
[Epoch 66; Iter    65/  209] train: loss: 0.0055759
[Epoch 66; Iter    95/  209] train: loss: 0.0197942
[Epoch 66; Iter   125/  209] train: loss: 0.0213198
[Epoch 66; Iter   155/  209] train: loss: 0.0229708
[Epoch 66; Iter   185/  209] train: loss: 0.0201769
[Epoch 66] ogbg-moltox21: 0.761016 val loss: 0.568543
[Epoch 66] ogbg-moltox21: 0.698818 test loss: 0.575100
[Epoch 67; Iter     6/  209] train: loss: 0.0287530
[Epoch 67; Iter    36/  209] train: loss: 0.0093541
[Epoch 67; Iter    66/  209] train: loss: 0.0113242
[Epoch 67; Iter    96/  209] train: loss: 0.0161309
[Epoch 67; Iter   126/  209] train: loss: 0.0314112
[Epoch 67; Iter   156/  209] train: loss: 0.0146484
[Epoch 67; Iter   186/  209] train: loss: 0.0245480
[Epoch 67] ogbg-moltox21: 0.761511 val loss: 0.566982
[Epoch 67] ogbg-moltox21: 0.693152 test loss: 0.600955
[Epoch 68; Iter     7/  209] train: loss: 0.0191607
[Epoch 68; Iter    37/  209] train: loss: 0.0140031
[Epoch 68; Iter    67/  209] train: loss: 0.0141557
[Epoch 68; Iter    97/  209] train: loss: 0.0209632
[Epoch 68; Iter   127/  209] train: loss: 0.0232187
[Epoch 68; Iter   157/  209] train: loss: 0.0209896
[Epoch 68; Iter   187/  209] train: loss: 0.0217879
[Epoch 68] ogbg-moltox21: 0.760473 val loss: 0.509896
[Epoch 68] ogbg-moltox21: 0.691055 test loss: 0.586775
[Epoch 69; Iter     8/  209] train: loss: 0.0234728
[Epoch 69; Iter    38/  209] train: loss: 0.0251165
[Epoch 69; Iter    68/  209] train: loss: 0.0156492
[Epoch 69; Iter    98/  209] train: loss: 0.0120561
[Epoch 69; Iter   128/  209] train: loss: 0.0208523
[Epoch 69; Iter   158/  209] train: loss: 0.0420926
[Epoch 69; Iter   188/  209] train: loss: 0.0103609
[Epoch 69] ogbg-moltox21: 0.760980 val loss: 0.566073
[Epoch 69] ogbg-moltox21: 0.696014 test loss: 0.590188
[Epoch 70; Iter     9/  209] train: loss: 0.0140209
[Epoch 70; Iter    39/  209] train: loss: 0.0164103
[Epoch 70; Iter    69/  209] train: loss: 0.0122617
[Epoch 70; Iter    99/  209] train: loss: 0.0176956
[Epoch 70; Iter   129/  209] train: loss: 0.0160852
[Epoch 70; Iter   159/  209] train: loss: 0.0437891
[Epoch 70; Iter   189/  209] train: loss: 0.0161456
[Epoch 70] ogbg-moltox21: 0.760575 val loss: 0.603013
[Epoch 70] ogbg-moltox21: 0.692253 test loss: 0.629086
[Epoch 71; Iter    10/  209] train: loss: 0.0095688
[Epoch 71; Iter    40/  209] train: loss: 0.0077255
[Epoch 71; Iter    70/  209] train: loss: 0.0135000
[Epoch 71; Iter   100/  209] train: loss: 0.0240040
[Epoch 71; Iter   130/  209] train: loss: 0.0194191
[Epoch 71; Iter   160/  209] train: loss: 0.0131187
[Epoch 71; Iter   190/  209] train: loss: 0.0215149
[Epoch 71] ogbg-moltox21: 0.761652 val loss: 0.600424
[Epoch 71] ogbg-moltox21: 0.693824 test loss: 0.603567
[Epoch 72; Iter    11/  209] train: loss: 0.0299456
[Epoch 72; Iter    41/  209] train: loss: 0.0368255
[Epoch 72; Iter    71/  209] train: loss: 0.0221798
[Epoch 72; Iter   101/  209] train: loss: 0.0104104
[Epoch 72; Iter   131/  209] train: loss: 0.0196635
[Epoch 72; Iter   161/  209] train: loss: 0.0241769
[Epoch 72; Iter   191/  209] train: loss: 0.0350132
[Epoch 72] ogbg-moltox21: 0.755771 val loss: 0.653874
[Epoch 72] ogbg-moltox21: 0.692916 test loss: 0.632536
[Epoch 73; Iter    12/  209] train: loss: 0.0360648
[Epoch 73; Iter    42/  209] train: loss: 0.0105225
[Epoch 73; Iter    72/  209] train: loss: 0.0107347
[Epoch 73; Iter   102/  209] train: loss: 0.0131064
[Epoch 73; Iter   132/  209] train: loss: 0.0168829
[Epoch 73; Iter   162/  209] train: loss: 0.0362465
[Epoch 73; Iter   192/  209] train: loss: 0.0394327
[Epoch 73] ogbg-moltox21: 0.757868 val loss: 0.617154
[Epoch 73] ogbg-moltox21: 0.689192 test loss: 0.636505
[Epoch 74; Iter    13/  209] train: loss: 0.0316856
[Epoch 74; Iter    43/  209] train: loss: 0.0215996
[Epoch 74; Iter    73/  209] train: loss: 0.0241066
[Epoch 74; Iter   103/  209] train: loss: 0.0085263
[Epoch 74; Iter   133/  209] train: loss: 0.0409935
[Epoch 74; Iter   163/  209] train: loss: 0.0136817
[Epoch 74; Iter   193/  209] train: loss: 0.0108185
[Epoch 74] ogbg-moltox21: 0.760603 val loss: 0.662051
[Epoch 74] ogbg-moltox21: 0.701361 test loss: 0.653335
[Epoch 75; Iter    14/  209] train: loss: 0.0067449
[Epoch 75; Iter    44/  209] train: loss: 0.0068590
[Epoch 75; Iter    74/  209] train: loss: 0.0213157
[Epoch 75; Iter   104/  209] train: loss: 0.0507437
[Epoch 75; Iter   134/  209] train: loss: 0.0095512
[Epoch 75; Iter   164/  209] train: loss: 0.0205185
[Epoch 75; Iter   194/  209] train: loss: 0.0141704
[Epoch 75] ogbg-moltox21: 0.754767 val loss: 0.604121
[Epoch 75] ogbg-moltox21: 0.693683 test loss: 0.627244
[Epoch 76; Iter    15/  209] train: loss: 0.0203951
[Epoch 76; Iter    45/  209] train: loss: 0.0103916
[Epoch 76; Iter    75/  209] train: loss: 0.0161397
[Epoch 76; Iter   105/  209] train: loss: 0.0082747
[Epoch 76; Iter   135/  209] train: loss: 0.0268645
[Epoch 76; Iter   165/  209] train: loss: 0.0185205
[Epoch 76; Iter   195/  209] train: loss: 0.0089789
[Epoch 76] ogbg-moltox21: 0.761018 val loss: 0.594259
[Epoch 76] ogbg-moltox21: 0.702106 test loss: 0.628835
[Epoch 77; Iter    16/  209] train: loss: 0.0435314
[Epoch 77; Iter    46/  209] train: loss: 0.0106723
[Epoch 77; Iter    76/  209] train: loss: 0.0169025
[Epoch 77; Iter   106/  209] train: loss: 0.0086715
[Epoch 77; Iter   136/  209] train: loss: 0.0288666
[Epoch 77; Iter   166/  209] train: loss: 0.0117141
[Epoch 77; Iter   196/  209] train: loss: 0.0269471
[Epoch 77] ogbg-moltox21: 0.754124 val loss: 0.546633
[Epoch 77] ogbg-moltox21: 0.695127 test loss: 0.625580
[Epoch 78; Iter    17/  209] train: loss: 0.0220053
[Epoch 78; Iter    47/  209] train: loss: 0.0039578
[Epoch 78; Iter    77/  209] train: loss: 0.0158435
[Epoch 78; Iter   107/  209] train: loss: 0.0114726
[Epoch 78; Iter   137/  209] train: loss: 0.0248659
[Epoch 78; Iter   167/  209] train: loss: 0.0159255
[Epoch 78; Iter   197/  209] train: loss: 0.0502463
[Epoch 78] ogbg-moltox21: 0.760120 val loss: 0.578705
[Epoch 78] ogbg-moltox21: 0.704335 test loss: 0.652611
[Epoch 79; Iter    18/  209] train: loss: 0.0134910
[Epoch 79; Iter    48/  209] train: loss: 0.0275524
[Epoch 79; Iter    78/  209] train: loss: 0.0115020
[Epoch 79; Iter   108/  209] train: loss: 0.0277214
[Epoch 79; Iter   138/  209] train: loss: 0.0169762
[Epoch 79; Iter   168/  209] train: loss: 0.0139770
[Epoch 79; Iter   198/  209] train: loss: 0.0120231
[Epoch 79] ogbg-moltox21: 0.761773 val loss: 0.594282
[Epoch 79] ogbg-moltox21: 0.698020 test loss: 0.635997
[Epoch 80; Iter    19/  209] train: loss: 0.0108383
[Epoch 80; Iter    49/  209] train: loss: 0.0174526
[Epoch 80; Iter    79/  209] train: loss: 0.0055526
[Epoch 80; Iter   109/  209] train: loss: 0.0091977
[Epoch 80; Iter   139/  209] train: loss: 0.0111518
[Epoch 80; Iter   169/  209] train: loss: 0.0115969
[Epoch 80; Iter   199/  209] train: loss: 0.0485877
[Epoch 80] ogbg-moltox21: 0.756735 val loss: 0.572235
[Epoch 80] ogbg-moltox21: 0.697866 test loss: 0.637884
[Epoch 81; Iter    20/  209] train: loss: 0.0216260
[Epoch 81; Iter    50/  209] train: loss: 0.0107118
[Epoch 81; Iter    80/  209] train: loss: 0.0146050
[Epoch 81; Iter   110/  209] train: loss: 0.0162682
[Epoch 81; Iter   140/  209] train: loss: 0.0284293
[Epoch 81; Iter   170/  209] train: loss: 0.0246203
[Epoch 81; Iter   200/  209] train: loss: 0.0107031
[Epoch 81] ogbg-moltox21: 0.759843 val loss: 0.605586
[Epoch 81] ogbg-moltox21: 0.695484 test loss: 0.676850
[Epoch 82; Iter    21/  209] train: loss: 0.0077227
[Epoch 64] ogbg-moltox21: 0.744434 test loss: 0.561463
[Epoch 65; Iter     4/  209] train: loss: 0.1061846
[Epoch 65; Iter    34/  209] train: loss: 0.0685837
[Epoch 65; Iter    64/  209] train: loss: 0.0902242
[Epoch 65; Iter    94/  209] train: loss: 0.0954570
[Epoch 65; Iter   124/  209] train: loss: 0.0589576
[Epoch 65; Iter   154/  209] train: loss: 0.1064746
[Epoch 65; Iter   184/  209] train: loss: 0.1272441
[Epoch 65] ogbg-moltox21: 0.769792 val loss: 0.409286
[Epoch 65] ogbg-moltox21: 0.746894 test loss: 0.570959
[Epoch 66; Iter     5/  209] train: loss: 0.0651606
[Epoch 66; Iter    35/  209] train: loss: 0.0604759
[Epoch 66; Iter    65/  209] train: loss: 0.0896142
[Epoch 66; Iter    95/  209] train: loss: 0.0860933
[Epoch 66; Iter   125/  209] train: loss: 0.0704284
[Epoch 66; Iter   155/  209] train: loss: 0.0763991
[Epoch 66; Iter   185/  209] train: loss: 0.0471159
[Epoch 66] ogbg-moltox21: 0.771417 val loss: 0.325439
[Epoch 66] ogbg-moltox21: 0.748674 test loss: 0.592961
[Epoch 67; Iter     6/  209] train: loss: 0.1287943
[Epoch 67; Iter    36/  209] train: loss: 0.0964939
[Epoch 67; Iter    66/  209] train: loss: 0.0932871
[Epoch 67; Iter    96/  209] train: loss: 0.0946535
[Epoch 67; Iter   126/  209] train: loss: 0.0552433
[Epoch 67; Iter   156/  209] train: loss: 0.0725621
[Epoch 67; Iter   186/  209] train: loss: 0.0748989
[Epoch 67] ogbg-moltox21: 0.767224 val loss: 0.349803
[Epoch 67] ogbg-moltox21: 0.746911 test loss: 0.541700
[Epoch 68; Iter     7/  209] train: loss: 0.0799361
[Epoch 68; Iter    37/  209] train: loss: 0.0893947
[Epoch 68; Iter    67/  209] train: loss: 0.0924845
[Epoch 68; Iter    97/  209] train: loss: 0.0967659
[Epoch 68; Iter   127/  209] train: loss: 0.0942971
[Epoch 68; Iter   157/  209] train: loss: 0.0714957
[Epoch 68; Iter   187/  209] train: loss: 0.0582150
[Epoch 68] ogbg-moltox21: 0.770207 val loss: 0.343505
[Epoch 68] ogbg-moltox21: 0.744839 test loss: 0.429810
[Epoch 69; Iter     8/  209] train: loss: 0.0673341
[Epoch 69; Iter    38/  209] train: loss: 0.0744015
[Epoch 69; Iter    68/  209] train: loss: 0.0884430
[Epoch 69; Iter    98/  209] train: loss: 0.0772211
[Epoch 69; Iter   128/  209] train: loss: 0.0675209
[Epoch 69; Iter   158/  209] train: loss: 0.0584804
[Epoch 69; Iter   188/  209] train: loss: 0.0810445
[Epoch 69] ogbg-moltox21: 0.776500 val loss: 0.337353
[Epoch 69] ogbg-moltox21: 0.744826 test loss: 0.530345
[Epoch 70; Iter     9/  209] train: loss: 0.0887886
[Epoch 70; Iter    39/  209] train: loss: 0.0448689
[Epoch 70; Iter    69/  209] train: loss: 0.1224431
[Epoch 70; Iter    99/  209] train: loss: 0.0920438
[Epoch 70; Iter   129/  209] train: loss: 0.0979422
[Epoch 70; Iter   159/  209] train: loss: 0.0841511
[Epoch 70; Iter   189/  209] train: loss: 0.0751534
[Epoch 70] ogbg-moltox21: 0.759585 val loss: 0.418914
[Epoch 70] ogbg-moltox21: 0.743323 test loss: 0.547198
[Epoch 71; Iter    10/  209] train: loss: 0.1026082
[Epoch 71; Iter    40/  209] train: loss: 0.1057201
[Epoch 71; Iter    70/  209] train: loss: 0.0817834
[Epoch 71; Iter   100/  209] train: loss: 0.1068365
[Epoch 71; Iter   130/  209] train: loss: 0.0678424
[Epoch 71; Iter   160/  209] train: loss: 0.0629577
[Epoch 71; Iter   190/  209] train: loss: 0.0790704
[Epoch 71] ogbg-moltox21: 0.758072 val loss: 0.345012
[Epoch 71] ogbg-moltox21: 0.736339 test loss: 0.349464
[Epoch 72; Iter    11/  209] train: loss: 0.0751661
[Epoch 72; Iter    41/  209] train: loss: 0.0693918
[Epoch 72; Iter    71/  209] train: loss: 0.1154148
[Epoch 72; Iter   101/  209] train: loss: 0.0664613
[Epoch 72; Iter   131/  209] train: loss: 0.1166110
[Epoch 72; Iter   161/  209] train: loss: 0.0971780
[Epoch 72; Iter   191/  209] train: loss: 0.0473945
[Epoch 72] ogbg-moltox21: 0.757999 val loss: 0.363336
[Epoch 72] ogbg-moltox21: 0.741049 test loss: 0.520017
[Epoch 73; Iter    12/  209] train: loss: 0.0824141
[Epoch 73; Iter    42/  209] train: loss: 0.0651711
[Epoch 73; Iter    72/  209] train: loss: 0.0445595
[Epoch 73; Iter   102/  209] train: loss: 0.0728310
[Epoch 73; Iter   132/  209] train: loss: 0.0825465
[Epoch 73; Iter   162/  209] train: loss: 0.0476097
[Epoch 73; Iter   192/  209] train: loss: 0.0945712
[Epoch 73] ogbg-moltox21: 0.762554 val loss: 0.345693
[Epoch 73] ogbg-moltox21: 0.746507 test loss: 0.415656
[Epoch 74; Iter    13/  209] train: loss: 0.0705961
[Epoch 74; Iter    43/  209] train: loss: 0.1008423
[Epoch 74; Iter    73/  209] train: loss: 0.0519251
[Epoch 74; Iter   103/  209] train: loss: 0.0626088
[Epoch 74; Iter   133/  209] train: loss: 0.0687313
[Epoch 74; Iter   163/  209] train: loss: 0.0761305
[Epoch 74; Iter   193/  209] train: loss: 0.0479484
[Epoch 74] ogbg-moltox21: 0.761802 val loss: 0.378511
[Epoch 74] ogbg-moltox21: 0.740080 test loss: 0.602450
[Epoch 75; Iter    14/  209] train: loss: 0.0664999
[Epoch 75; Iter    44/  209] train: loss: 0.1122005
[Epoch 75; Iter    74/  209] train: loss: 0.0771350
[Epoch 75; Iter   104/  209] train: loss: 0.0809433
[Epoch 75; Iter   134/  209] train: loss: 0.0456130
[Epoch 75; Iter   164/  209] train: loss: 0.0495096
[Epoch 75; Iter   194/  209] train: loss: 0.0825261
[Epoch 75] ogbg-moltox21: 0.763023 val loss: 0.350023
[Epoch 75] ogbg-moltox21: 0.746901 test loss: 0.752076
[Epoch 76; Iter    15/  209] train: loss: 0.0834908
[Epoch 76; Iter    45/  209] train: loss: 0.0436427
[Epoch 76; Iter    75/  209] train: loss: 0.0639445
[Epoch 76; Iter   105/  209] train: loss: 0.0488665
[Epoch 76; Iter   135/  209] train: loss: 0.0570360
[Epoch 76; Iter   165/  209] train: loss: 0.0445216
[Epoch 76; Iter   195/  209] train: loss: 0.0730099
[Epoch 76] ogbg-moltox21: 0.762513 val loss: 0.383123
[Epoch 76] ogbg-moltox21: 0.741338 test loss: 0.524169
[Epoch 77; Iter    16/  209] train: loss: 0.0869846
[Epoch 77; Iter    46/  209] train: loss: 0.0655434
[Epoch 77; Iter    76/  209] train: loss: 0.0616008
[Epoch 77; Iter   106/  209] train: loss: 0.0728956
[Epoch 77; Iter   136/  209] train: loss: 0.0765161
[Epoch 77; Iter   166/  209] train: loss: 0.0680681
[Epoch 77; Iter   196/  209] train: loss: 0.0633904
[Epoch 77] ogbg-moltox21: 0.755026 val loss: 0.355567
[Epoch 77] ogbg-moltox21: 0.739689 test loss: 0.575087
[Epoch 78; Iter    17/  209] train: loss: 0.0433613
[Epoch 78; Iter    47/  209] train: loss: 0.0576473
[Epoch 78; Iter    77/  209] train: loss: 0.0561128
[Epoch 78; Iter   107/  209] train: loss: 0.1273668
[Epoch 78; Iter   137/  209] train: loss: 0.0928216
[Epoch 78; Iter   167/  209] train: loss: 0.1388309
[Epoch 78; Iter   197/  209] train: loss: 0.0559118
[Epoch 78] ogbg-moltox21: 0.760510 val loss: 0.393312
[Epoch 78] ogbg-moltox21: 0.743977 test loss: 0.563943
[Epoch 79; Iter    18/  209] train: loss: 0.1256273
[Epoch 79; Iter    48/  209] train: loss: 0.0664685
[Epoch 79; Iter    78/  209] train: loss: 0.0436602
[Epoch 79; Iter   108/  209] train: loss: 0.0488894
[Epoch 79; Iter   138/  209] train: loss: 0.0620886
[Epoch 79; Iter   168/  209] train: loss: 0.0704439
[Epoch 79; Iter   198/  209] train: loss: 0.0624248
[Epoch 79] ogbg-moltox21: 0.761427 val loss: 0.401863
[Epoch 79] ogbg-moltox21: 0.740337 test loss: 0.479871
[Epoch 80; Iter    19/  209] train: loss: 0.1173088
[Epoch 80; Iter    49/  209] train: loss: 0.0681705
[Epoch 80; Iter    79/  209] train: loss: 0.0222731
[Epoch 80; Iter   109/  209] train: loss: 0.0546059
[Epoch 80; Iter   139/  209] train: loss: 0.0469113
[Epoch 80; Iter   169/  209] train: loss: 0.0929806
[Epoch 80; Iter   199/  209] train: loss: 0.0737802
[Epoch 80] ogbg-moltox21: 0.756499 val loss: 0.375782
[Epoch 80] ogbg-moltox21: 0.742097 test loss: 0.565932
[Epoch 81; Iter    20/  209] train: loss: 0.0500858
[Epoch 81; Iter    50/  209] train: loss: 0.0383435
[Epoch 81; Iter    80/  209] train: loss: 0.0701615
[Epoch 81; Iter   110/  209] train: loss: 0.0614506
[Epoch 81; Iter   140/  209] train: loss: 0.0373425
[Epoch 81; Iter   170/  209] train: loss: 0.0644513
[Epoch 81; Iter   200/  209] train: loss: 0.0637156
[Epoch 81] ogbg-moltox21: 0.760707 val loss: 0.360148
[Epoch 81] ogbg-moltox21: 0.745667 test loss: 0.438688
[Epoch 82; Iter    21/  209] train: loss: 0.0520799
[Epoch 64] ogbg-moltox21: 0.696335 test loss: 0.520588
[Epoch 65; Iter     4/  209] train: loss: 0.0397466
[Epoch 65; Iter    34/  209] train: loss: 0.0188238
[Epoch 65; Iter    64/  209] train: loss: 0.0336551
[Epoch 65; Iter    94/  209] train: loss: 0.0386790
[Epoch 65; Iter   124/  209] train: loss: 0.0312571
[Epoch 65; Iter   154/  209] train: loss: 0.0387524
[Epoch 65; Iter   184/  209] train: loss: 0.0762141
[Epoch 65] ogbg-moltox21: 0.687096 val loss: 0.516388
[Epoch 65] ogbg-moltox21: 0.690037 test loss: 0.536011
[Epoch 66; Iter     5/  209] train: loss: 0.0352354
[Epoch 66; Iter    35/  209] train: loss: 0.0276138
[Epoch 66; Iter    65/  209] train: loss: 0.0379803
[Epoch 66; Iter    95/  209] train: loss: 0.0267242
[Epoch 66; Iter   125/  209] train: loss: 0.0233810
[Epoch 66; Iter   155/  209] train: loss: 0.0264230
[Epoch 66; Iter   185/  209] train: loss: 0.0169341
[Epoch 66] ogbg-moltox21: 0.692522 val loss: 0.524780
[Epoch 66] ogbg-moltox21: 0.691333 test loss: 0.545232
[Epoch 67; Iter     6/  209] train: loss: 0.0534359
[Epoch 67; Iter    36/  209] train: loss: 0.0416762
[Epoch 67; Iter    66/  209] train: loss: 0.0283222
[Epoch 67; Iter    96/  209] train: loss: 0.0325357
[Epoch 67; Iter   126/  209] train: loss: 0.0152582
[Epoch 67; Iter   156/  209] train: loss: 0.0240535
[Epoch 67; Iter   186/  209] train: loss: 0.0401217
[Epoch 67] ogbg-moltox21: 0.671251 val loss: 0.564921
[Epoch 67] ogbg-moltox21: 0.680185 test loss: 0.543801
[Epoch 68; Iter     7/  209] train: loss: 0.0434142
[Epoch 68; Iter    37/  209] train: loss: 0.0385263
[Epoch 68; Iter    67/  209] train: loss: 0.0436108
[Epoch 68; Iter    97/  209] train: loss: 0.0364757
[Epoch 68; Iter   127/  209] train: loss: 0.0371288
[Epoch 68; Iter   157/  209] train: loss: 0.0155672
[Epoch 68; Iter   187/  209] train: loss: 0.0136107
[Epoch 68] ogbg-moltox21: 0.689636 val loss: 0.547042
[Epoch 68] ogbg-moltox21: 0.693022 test loss: 0.561667
[Epoch 69; Iter     8/  209] train: loss: 0.0295547
[Epoch 69; Iter    38/  209] train: loss: 0.0141714
[Epoch 69; Iter    68/  209] train: loss: 0.0350828
[Epoch 69; Iter    98/  209] train: loss: 0.0200382
[Epoch 69; Iter   128/  209] train: loss: 0.0259267
[Epoch 69; Iter   158/  209] train: loss: 0.0582310
[Epoch 69; Iter   188/  209] train: loss: 0.0287869
[Epoch 69] ogbg-moltox21: 0.690785 val loss: 0.562480
[Epoch 69] ogbg-moltox21: 0.695171 test loss: 0.550959
[Epoch 70; Iter     9/  209] train: loss: 0.0158006
[Epoch 70; Iter    39/  209] train: loss: 0.0208845
[Epoch 70; Iter    69/  209] train: loss: 0.0576206
[Epoch 70; Iter    99/  209] train: loss: 0.0291244
[Epoch 70; Iter   129/  209] train: loss: 0.0179311
[Epoch 70; Iter   159/  209] train: loss: 0.0180614
[Epoch 70; Iter   189/  209] train: loss: 0.0308940
[Epoch 70] ogbg-moltox21: 0.685629 val loss: 0.651044
[Epoch 70] ogbg-moltox21: 0.695826 test loss: 0.607702
[Epoch 71; Iter    10/  209] train: loss: 0.0378343
[Epoch 71; Iter    40/  209] train: loss: 0.0576008
[Epoch 71; Iter    70/  209] train: loss: 0.0299482
[Epoch 71; Iter   100/  209] train: loss: 0.0236558
[Epoch 71; Iter   130/  209] train: loss: 0.0289779
[Epoch 71; Iter   160/  209] train: loss: 0.0169678
[Epoch 71; Iter   190/  209] train: loss: 0.0267222
[Epoch 71] ogbg-moltox21: 0.684465 val loss: 0.590219
[Epoch 71] ogbg-moltox21: 0.696841 test loss: 0.598927
[Epoch 72; Iter    11/  209] train: loss: 0.0307111
[Epoch 72; Iter    41/  209] train: loss: 0.0438832
[Epoch 72; Iter    71/  209] train: loss: 0.0484752
[Epoch 72; Iter   101/  209] train: loss: 0.0350144
[Epoch 72; Iter   131/  209] train: loss: 0.0398232
[Epoch 72; Iter   161/  209] train: loss: 0.0260592
[Epoch 72; Iter   191/  209] train: loss: 0.0283712
[Epoch 72] ogbg-moltox21: 0.696725 val loss: 0.539090
[Epoch 72] ogbg-moltox21: 0.695308 test loss: 0.560029
[Epoch 73; Iter    12/  209] train: loss: 0.0211611
[Epoch 73; Iter    42/  209] train: loss: 0.0094033
[Epoch 73; Iter    72/  209] train: loss: 0.0151176
[Epoch 73; Iter   102/  209] train: loss: 0.0198683
[Epoch 73; Iter   132/  209] train: loss: 0.0150164
[Epoch 73; Iter   162/  209] train: loss: 0.0227215
[Epoch 73; Iter   192/  209] train: loss: 0.0369648
[Epoch 73] ogbg-moltox21: 0.697163 val loss: 0.559500
[Epoch 73] ogbg-moltox21: 0.701542 test loss: 0.573761
[Epoch 74; Iter    13/  209] train: loss: 0.0220460
[Epoch 74; Iter    43/  209] train: loss: 0.0382487
[Epoch 74; Iter    73/  209] train: loss: 0.0181537
[Epoch 74; Iter   103/  209] train: loss: 0.0237392
[Epoch 74; Iter   133/  209] train: loss: 0.0228456
[Epoch 74; Iter   163/  209] train: loss: 0.0203419
[Epoch 74; Iter   193/  209] train: loss: 0.0370909
[Epoch 74] ogbg-moltox21: 0.681327 val loss: 0.585860
[Epoch 74] ogbg-moltox21: 0.688999 test loss: 0.594884
[Epoch 75; Iter    14/  209] train: loss: 0.0241274
[Epoch 75; Iter    44/  209] train: loss: 0.0319484
[Epoch 75; Iter    74/  209] train: loss: 0.0400732
[Epoch 75; Iter   104/  209] train: loss: 0.0268617
[Epoch 75; Iter   134/  209] train: loss: 0.0342338
[Epoch 75; Iter   164/  209] train: loss: 0.0176442
[Epoch 75; Iter   194/  209] train: loss: 0.0206257
[Epoch 75] ogbg-moltox21: 0.681779 val loss: 0.581954
[Epoch 75] ogbg-moltox21: 0.686822 test loss: 0.607846
[Epoch 76; Iter    15/  209] train: loss: 0.0327146
[Epoch 76; Iter    45/  209] train: loss: 0.0175998
[Epoch 76; Iter    75/  209] train: loss: 0.0185664
[Epoch 76; Iter   105/  209] train: loss: 0.0134704
[Epoch 76; Iter   135/  209] train: loss: 0.0183302
[Epoch 76; Iter   165/  209] train: loss: 0.0178179
[Epoch 76; Iter   195/  209] train: loss: 0.0373593
[Epoch 76] ogbg-moltox21: 0.682757 val loss: 0.617105
[Epoch 76] ogbg-moltox21: 0.695067 test loss: 0.616576
[Epoch 77; Iter    16/  209] train: loss: 0.0249935
[Epoch 77; Iter    46/  209] train: loss: 0.0361036
[Epoch 77; Iter    76/  209] train: loss: 0.0229203
[Epoch 77; Iter   106/  209] train: loss: 0.0151678
[Epoch 77; Iter   136/  209] train: loss: 0.0343700
[Epoch 77; Iter   166/  209] train: loss: 0.0338894
[Epoch 77; Iter   196/  209] train: loss: 0.0324665
[Epoch 77] ogbg-moltox21: 0.681845 val loss: 0.603507
[Epoch 77] ogbg-moltox21: 0.688522 test loss: 0.606106
[Epoch 78; Iter    17/  209] train: loss: 0.0254528
[Epoch 78; Iter    47/  209] train: loss: 0.0154427
[Epoch 78; Iter    77/  209] train: loss: 0.0398922
[Epoch 78; Iter   107/  209] train: loss: 0.0585489
[Epoch 78; Iter   137/  209] train: loss: 0.0399895
[Epoch 78; Iter   167/  209] train: loss: 0.0620687
[Epoch 78; Iter   197/  209] train: loss: 0.0108715
[Epoch 78] ogbg-moltox21: 0.694395 val loss: 0.567757
[Epoch 78] ogbg-moltox21: 0.705455 test loss: 0.571877
[Epoch 79; Iter    18/  209] train: loss: 0.0726882
[Epoch 79; Iter    48/  209] train: loss: 0.0201641
[Epoch 79; Iter    78/  209] train: loss: 0.0086450
[Epoch 79; Iter   108/  209] train: loss: 0.0299402
[Epoch 79; Iter   138/  209] train: loss: 0.0319158
[Epoch 79; Iter   168/  209] train: loss: 0.0192985
[Epoch 79; Iter   198/  209] train: loss: 0.0194776
[Epoch 79] ogbg-moltox21: 0.694996 val loss: 0.628064
[Epoch 79] ogbg-moltox21: 0.695387 test loss: 0.598445
[Epoch 80; Iter    19/  209] train: loss: 0.0644686
[Epoch 80; Iter    49/  209] train: loss: 0.0263703
[Epoch 80; Iter    79/  209] train: loss: 0.0114445
[Epoch 80; Iter   109/  209] train: loss: 0.0168934
[Epoch 80; Iter   139/  209] train: loss: 0.0144780
[Epoch 80; Iter   169/  209] train: loss: 0.0227308
[Epoch 80; Iter   199/  209] train: loss: 0.0110125
[Epoch 80] ogbg-moltox21: 0.693697 val loss: 0.595265
[Epoch 80] ogbg-moltox21: 0.687539 test loss: 0.611825
[Epoch 81; Iter    20/  209] train: loss: 0.0094652
[Epoch 81; Iter    50/  209] train: loss: 0.0233271
[Epoch 81; Iter    80/  209] train: loss: 0.0380986
[Epoch 81; Iter   110/  209] train: loss: 0.0145523
[Epoch 81; Iter   140/  209] train: loss: 0.0218091
[Epoch 81; Iter   170/  209] train: loss: 0.0297384
[Epoch 81; Iter   200/  209] train: loss: 0.0185474
[Epoch 81] ogbg-moltox21: 0.693671 val loss: 0.594385
[Epoch 81] ogbg-moltox21: 0.697874 test loss: 0.604790
[Epoch 82; Iter    21/  209] train: loss: 0.0153966
[Epoch 64] ogbg-moltox21: 0.686522 test loss: 0.841600
[Epoch 65; Iter     4/  209] train: loss: 0.0310681
[Epoch 65; Iter    34/  209] train: loss: 0.0385446
[Epoch 65; Iter    64/  209] train: loss: 0.0273866
[Epoch 65; Iter    94/  209] train: loss: 0.0541105
[Epoch 65; Iter   124/  209] train: loss: 0.0720203
[Epoch 65; Iter   154/  209] train: loss: 0.0255207
[Epoch 65; Iter   184/  209] train: loss: 0.0333815
[Epoch 65] ogbg-moltox21: 0.720024 val loss: 0.762044
[Epoch 65] ogbg-moltox21: 0.678113 test loss: 0.895497
[Epoch 66; Iter     5/  209] train: loss: 0.0141870
[Epoch 66; Iter    35/  209] train: loss: 0.0120356
[Epoch 66; Iter    65/  209] train: loss: 0.0073158
[Epoch 66; Iter    95/  209] train: loss: 0.0217625
[Epoch 66; Iter   125/  209] train: loss: 0.0169950
[Epoch 66; Iter   155/  209] train: loss: 0.0306351
[Epoch 66; Iter   185/  209] train: loss: 0.0262407
[Epoch 66] ogbg-moltox21: 0.714944 val loss: 0.731522
[Epoch 66] ogbg-moltox21: 0.677588 test loss: 0.842815
[Epoch 67; Iter     6/  209] train: loss: 0.0185591
[Epoch 67; Iter    36/  209] train: loss: 0.0112007
[Epoch 67; Iter    66/  209] train: loss: 0.0081574
[Epoch 67; Iter    96/  209] train: loss: 0.0232391
[Epoch 67; Iter   126/  209] train: loss: 0.0207052
[Epoch 67; Iter   156/  209] train: loss: 0.0135453
[Epoch 67; Iter   186/  209] train: loss: 0.0203146
[Epoch 67] ogbg-moltox21: 0.716807 val loss: 0.742358
[Epoch 67] ogbg-moltox21: 0.682204 test loss: 0.839453
[Epoch 68; Iter     7/  209] train: loss: 0.0159064
[Epoch 68; Iter    37/  209] train: loss: 0.0129094
[Epoch 68; Iter    67/  209] train: loss: 0.0131203
[Epoch 68; Iter    97/  209] train: loss: 0.0266255
[Epoch 68; Iter   127/  209] train: loss: 0.0288023
[Epoch 68; Iter   157/  209] train: loss: 0.0259347
[Epoch 68; Iter   187/  209] train: loss: 0.0175336
[Epoch 68] ogbg-moltox21: 0.696990 val loss: 0.861049
[Epoch 68] ogbg-moltox21: 0.656671 test loss: 0.925932
[Epoch 69; Iter     8/  209] train: loss: 0.0329033
[Epoch 69; Iter    38/  209] train: loss: 0.0133874
[Epoch 69; Iter    68/  209] train: loss: 0.0179232
[Epoch 69; Iter    98/  209] train: loss: 0.0097395
[Epoch 69; Iter   128/  209] train: loss: 0.0111979
[Epoch 69; Iter   158/  209] train: loss: 0.0327230
[Epoch 69; Iter   188/  209] train: loss: 0.0084959
[Epoch 69] ogbg-moltox21: 0.719741 val loss: 0.735198
[Epoch 69] ogbg-moltox21: 0.674945 test loss: 0.799524
[Epoch 70; Iter     9/  209] train: loss: 0.0104006
[Epoch 70; Iter    39/  209] train: loss: 0.0147707
[Epoch 70; Iter    69/  209] train: loss: 0.0054838
[Epoch 70; Iter    99/  209] train: loss: 0.0141588
[Epoch 70; Iter   129/  209] train: loss: 0.0188350
[Epoch 70; Iter   159/  209] train: loss: 0.0250934
[Epoch 70; Iter   189/  209] train: loss: 0.0150405
[Epoch 70] ogbg-moltox21: 0.707561 val loss: 0.793204
[Epoch 70] ogbg-moltox21: 0.667911 test loss: 0.872111
[Epoch 71; Iter    10/  209] train: loss: 0.0102703
[Epoch 71; Iter    40/  209] train: loss: 0.0088714
[Epoch 71; Iter    70/  209] train: loss: 0.0156655
[Epoch 71; Iter   100/  209] train: loss: 0.0188042
[Epoch 71; Iter   130/  209] train: loss: 0.0164794
[Epoch 71; Iter   160/  209] train: loss: 0.0144500
[Epoch 71; Iter   190/  209] train: loss: 0.0115013
[Epoch 71] ogbg-moltox21: 0.709340 val loss: 0.837057
[Epoch 71] ogbg-moltox21: 0.665326 test loss: 0.931949
[Epoch 72; Iter    11/  209] train: loss: 0.0171355
[Epoch 72; Iter    41/  209] train: loss: 0.0087818
[Epoch 72; Iter    71/  209] train: loss: 0.0142488
[Epoch 72; Iter   101/  209] train: loss: 0.0084854
[Epoch 72; Iter   131/  209] train: loss: 0.0145514
[Epoch 72; Iter   161/  209] train: loss: 0.0133888
[Epoch 72; Iter   191/  209] train: loss: 0.0384469
[Epoch 72] ogbg-moltox21: 0.721990 val loss: 0.752710
[Epoch 72] ogbg-moltox21: 0.683300 test loss: 0.858979
[Epoch 73; Iter    12/  209] train: loss: 0.0288040
[Epoch 73; Iter    42/  209] train: loss: 0.0092852
[Epoch 73; Iter    72/  209] train: loss: 0.0094817
[Epoch 73; Iter   102/  209] train: loss: 0.0093290
[Epoch 73; Iter   132/  209] train: loss: 0.0078267
[Epoch 73; Iter   162/  209] train: loss: 0.0089727
[Epoch 73; Iter   192/  209] train: loss: 0.0389945
[Epoch 73] ogbg-moltox21: 0.713252 val loss: 0.808484
[Epoch 73] ogbg-moltox21: 0.667351 test loss: 0.859042
[Epoch 74; Iter    13/  209] train: loss: 0.0238066
[Epoch 74; Iter    43/  209] train: loss: 0.0231776
[Epoch 74; Iter    73/  209] train: loss: 0.0258580
[Epoch 74; Iter   103/  209] train: loss: 0.0106414
[Epoch 74; Iter   133/  209] train: loss: 0.0431073
[Epoch 74; Iter   163/  209] train: loss: 0.0210071
[Epoch 74; Iter   193/  209] train: loss: 0.0176847
[Epoch 74] ogbg-moltox21: 0.712710 val loss: 0.813808
[Epoch 74] ogbg-moltox21: 0.679765 test loss: 0.879159
[Epoch 75; Iter    14/  209] train: loss: 0.0117124
[Epoch 75; Iter    44/  209] train: loss: 0.0164317
[Epoch 75; Iter    74/  209] train: loss: 0.0105768
[Epoch 75; Iter   104/  209] train: loss: 0.0285255
[Epoch 75; Iter   134/  209] train: loss: 0.0076477
[Epoch 75; Iter   164/  209] train: loss: 0.0337956
[Epoch 75; Iter   194/  209] train: loss: 0.0092653
[Epoch 75] ogbg-moltox21: 0.705471 val loss: 0.902117
[Epoch 75] ogbg-moltox21: 0.666054 test loss: 0.963124
[Epoch 76; Iter    15/  209] train: loss: 0.0093364
[Epoch 76; Iter    45/  209] train: loss: 0.0238229
[Epoch 76; Iter    75/  209] train: loss: 0.0146687
[Epoch 76; Iter   105/  209] train: loss: 0.0116945
[Epoch 76; Iter   135/  209] train: loss: 0.0169148
[Epoch 76; Iter   165/  209] train: loss: 0.0123459
[Epoch 76; Iter   195/  209] train: loss: 0.0039381
[Epoch 76] ogbg-moltox21: 0.710259 val loss: 0.876420
[Epoch 76] ogbg-moltox21: 0.670827 test loss: 0.924439
[Epoch 77; Iter    16/  209] train: loss: 0.0159710
[Epoch 77; Iter    46/  209] train: loss: 0.0198471
[Epoch 77; Iter    76/  209] train: loss: 0.0218074
[Epoch 77; Iter   106/  209] train: loss: 0.0119765
[Epoch 77; Iter   136/  209] train: loss: 0.0191249
[Epoch 77; Iter   166/  209] train: loss: 0.0140779
[Epoch 77; Iter   196/  209] train: loss: 0.0304953
[Epoch 77] ogbg-moltox21: 0.718635 val loss: 0.752884
[Epoch 77] ogbg-moltox21: 0.681813 test loss: 0.834697
[Epoch 78; Iter    17/  209] train: loss: 0.0109846
[Epoch 78; Iter    47/  209] train: loss: 0.0175232
[Epoch 78; Iter    77/  209] train: loss: 0.0082550
[Epoch 78; Iter   107/  209] train: loss: 0.0045152
[Epoch 78; Iter   137/  209] train: loss: 0.0144681
[Epoch 78; Iter   167/  209] train: loss: 0.0054275
[Epoch 78; Iter   197/  209] train: loss: 0.0224833
[Epoch 78] ogbg-moltox21: 0.695818 val loss: 0.941630
[Epoch 78] ogbg-moltox21: 0.660763 test loss: 1.012771
[Epoch 79; Iter    18/  209] train: loss: 0.0051869
[Epoch 79; Iter    48/  209] train: loss: 0.0112950
[Epoch 79; Iter    78/  209] train: loss: 0.0060497
[Epoch 79; Iter   108/  209] train: loss: 0.0093831
[Epoch 79; Iter   138/  209] train: loss: 0.0071629
[Epoch 79; Iter   168/  209] train: loss: 0.0253635
[Epoch 79; Iter   198/  209] train: loss: 0.0103486
[Epoch 79] ogbg-moltox21: 0.701717 val loss: 0.864699
[Epoch 79] ogbg-moltox21: 0.660006 test loss: 0.919281
[Epoch 80; Iter    19/  209] train: loss: 0.0097566
[Epoch 80; Iter    49/  209] train: loss: 0.0100008
[Epoch 80; Iter    79/  209] train: loss: 0.0098593
[Epoch 80; Iter   109/  209] train: loss: 0.0145352
[Epoch 80; Iter   139/  209] train: loss: 0.0116745
[Epoch 80; Iter   169/  209] train: loss: 0.0121522
[Epoch 80; Iter   199/  209] train: loss: 0.0519387
[Epoch 80] ogbg-moltox21: 0.711087 val loss: 0.847048
[Epoch 80] ogbg-moltox21: 0.666130 test loss: 0.915418
[Epoch 81; Iter    20/  209] train: loss: 0.0206781
[Epoch 81; Iter    50/  209] train: loss: 0.0047124
[Epoch 81; Iter    80/  209] train: loss: 0.0253697
[Epoch 81; Iter   110/  209] train: loss: 0.0197467
[Epoch 81; Iter   140/  209] train: loss: 0.0272556
[Epoch 81; Iter   170/  209] train: loss: 0.0257273
[Epoch 81; Iter   200/  209] train: loss: 0.0111193
[Epoch 81] ogbg-moltox21: 0.712987 val loss: 0.986740
[Epoch 81] ogbg-moltox21: 0.668998 test loss: 1.043849
[Epoch 82; Iter    21/  209] train: loss: 0.0062268
[Epoch 64] ogbg-moltox21: 0.711389 test loss: 0.560991
[Epoch 65; Iter     4/  209] train: loss: 0.0366884
[Epoch 65; Iter    34/  209] train: loss: 0.0442347
[Epoch 65; Iter    64/  209] train: loss: 0.0328844
[Epoch 65; Iter    94/  209] train: loss: 0.0312221
[Epoch 65; Iter   124/  209] train: loss: 0.0316561
[Epoch 65; Iter   154/  209] train: loss: 0.0215541
[Epoch 65; Iter   184/  209] train: loss: 0.0444730
[Epoch 65] ogbg-moltox21: 0.742751 val loss: 0.506404
[Epoch 65] ogbg-moltox21: 0.703290 test loss: 0.561896
[Epoch 66; Iter     5/  209] train: loss: 0.0355311
[Epoch 66; Iter    35/  209] train: loss: 0.0360173
[Epoch 66; Iter    65/  209] train: loss: 0.0220223
[Epoch 66; Iter    95/  209] train: loss: 0.0390058
[Epoch 66; Iter   125/  209] train: loss: 0.0426705
[Epoch 66; Iter   155/  209] train: loss: 0.0614945
[Epoch 66; Iter   185/  209] train: loss: 0.0263832
[Epoch 66] ogbg-moltox21: 0.740676 val loss: 0.501555
[Epoch 66] ogbg-moltox21: 0.702532 test loss: 0.548019
[Epoch 67; Iter     6/  209] train: loss: 0.0166963
[Epoch 67; Iter    36/  209] train: loss: 0.0237532
[Epoch 67; Iter    66/  209] train: loss: 0.0698449
[Epoch 67; Iter    96/  209] train: loss: 0.0149027
[Epoch 67; Iter   126/  209] train: loss: 0.0280189
[Epoch 67; Iter   156/  209] train: loss: 0.0408271
[Epoch 67; Iter   186/  209] train: loss: 0.0493655
[Epoch 67] ogbg-moltox21: 0.751716 val loss: 0.497716
[Epoch 67] ogbg-moltox21: 0.701552 test loss: 0.586301
[Epoch 68; Iter     7/  209] train: loss: 0.0217855
[Epoch 68; Iter    37/  209] train: loss: 0.0201134
[Epoch 68; Iter    67/  209] train: loss: 0.0970505
[Epoch 68; Iter    97/  209] train: loss: 0.0273054
[Epoch 68; Iter   127/  209] train: loss: 0.0227661
[Epoch 68; Iter   157/  209] train: loss: 0.0639483
[Epoch 68; Iter   187/  209] train: loss: 0.0360200
[Epoch 68] ogbg-moltox21: 0.761856 val loss: 0.471952
[Epoch 68] ogbg-moltox21: 0.712920 test loss: 0.570119
[Epoch 69; Iter     8/  209] train: loss: 0.0373826
[Epoch 69; Iter    38/  209] train: loss: 0.0534438
[Epoch 69; Iter    68/  209] train: loss: 0.0261869
[Epoch 69; Iter    98/  209] train: loss: 0.0424082
[Epoch 69; Iter   128/  209] train: loss: 0.0352572
[Epoch 69; Iter   158/  209] train: loss: 0.0262221
[Epoch 69; Iter   188/  209] train: loss: 0.0278255
[Epoch 69] ogbg-moltox21: 0.740366 val loss: 0.520408
[Epoch 69] ogbg-moltox21: 0.702410 test loss: 0.600281
[Epoch 70; Iter     9/  209] train: loss: 0.0298934
[Epoch 70; Iter    39/  209] train: loss: 0.0517028
[Epoch 70; Iter    69/  209] train: loss: 0.0622043
[Epoch 70; Iter    99/  209] train: loss: 0.0481402
[Epoch 70; Iter   129/  209] train: loss: 0.0367252
[Epoch 70; Iter   159/  209] train: loss: 0.0304228
[Epoch 70; Iter   189/  209] train: loss: 0.0382452
[Epoch 70] ogbg-moltox21: 0.744362 val loss: 0.499863
[Epoch 70] ogbg-moltox21: 0.700084 test loss: 0.550128
[Epoch 71; Iter    10/  209] train: loss: 0.0188305
[Epoch 71; Iter    40/  209] train: loss: 0.0312117
[Epoch 71; Iter    70/  209] train: loss: 0.0191968
[Epoch 71; Iter   100/  209] train: loss: 0.0386540
[Epoch 71; Iter   130/  209] train: loss: 0.0644194
[Epoch 71; Iter   160/  209] train: loss: 0.0239424
[Epoch 71; Iter   190/  209] train: loss: 0.0255820
[Epoch 71] ogbg-moltox21: 0.749978 val loss: 0.497077
[Epoch 71] ogbg-moltox21: 0.705055 test loss: 0.577754
[Epoch 72; Iter    11/  209] train: loss: 0.0411702
[Epoch 72; Iter    41/  209] train: loss: 0.0245088
[Epoch 72; Iter    71/  209] train: loss: 0.0456358
[Epoch 72; Iter   101/  209] train: loss: 0.0357045
[Epoch 72; Iter   131/  209] train: loss: 0.0180012
[Epoch 72; Iter   161/  209] train: loss: 0.0644750
[Epoch 72; Iter   191/  209] train: loss: 0.0584472
[Epoch 72] ogbg-moltox21: 0.762625 val loss: 0.503486
[Epoch 72] ogbg-moltox21: 0.715547 test loss: 0.576045
[Epoch 73; Iter    12/  209] train: loss: 0.0461052
[Epoch 73; Iter    42/  209] train: loss: 0.0252492
[Epoch 73; Iter    72/  209] train: loss: 0.0308342
[Epoch 73; Iter   102/  209] train: loss: 0.0226529
[Epoch 73; Iter   132/  209] train: loss: 0.0428014
[Epoch 73; Iter   162/  209] train: loss: 0.0272712
[Epoch 73; Iter   192/  209] train: loss: 0.0275027
[Epoch 73] ogbg-moltox21: 0.738512 val loss: 0.516415
[Epoch 73] ogbg-moltox21: 0.706582 test loss: 0.568288
[Epoch 74; Iter    13/  209] train: loss: 0.0274826
[Epoch 74; Iter    43/  209] train: loss: 0.0337335
[Epoch 74; Iter    73/  209] train: loss: 0.0625238
[Epoch 74; Iter   103/  209] train: loss: 0.0271891
[Epoch 74; Iter   133/  209] train: loss: 0.0604778
[Epoch 74; Iter   163/  209] train: loss: 0.0634895
[Epoch 74; Iter   193/  209] train: loss: 0.0198944
[Epoch 74] ogbg-moltox21: 0.737902 val loss: 0.564019
[Epoch 74] ogbg-moltox21: 0.704005 test loss: 0.630645
[Epoch 75; Iter    14/  209] train: loss: 0.0269984
[Epoch 75; Iter    44/  209] train: loss: 0.0314532
[Epoch 75; Iter    74/  209] train: loss: 0.0285203
[Epoch 75; Iter   104/  209] train: loss: 0.0650134
[Epoch 75; Iter   134/  209] train: loss: 0.0296093
[Epoch 75; Iter   164/  209] train: loss: 0.0284740
[Epoch 75; Iter   194/  209] train: loss: 0.0333787
[Epoch 75] ogbg-moltox21: 0.759832 val loss: 0.526602
[Epoch 75] ogbg-moltox21: 0.712026 test loss: 0.828134
[Epoch 76; Iter    15/  209] train: loss: 0.0347588
[Epoch 76; Iter    45/  209] train: loss: 0.0382117
[Epoch 76; Iter    75/  209] train: loss: 0.0263775
[Epoch 76; Iter   105/  209] train: loss: 0.0456581
[Epoch 76; Iter   135/  209] train: loss: 0.0297555
[Epoch 76; Iter   165/  209] train: loss: 0.0576579
[Epoch 76; Iter   195/  209] train: loss: 0.0211278
[Epoch 76] ogbg-moltox21: 0.754246 val loss: 0.516332
[Epoch 76] ogbg-moltox21: 0.711947 test loss: 0.595770
[Epoch 77; Iter    16/  209] train: loss: 0.0108634
[Epoch 77; Iter    46/  209] train: loss: 0.0099790
[Epoch 77; Iter    76/  209] train: loss: 0.0284446
[Epoch 77; Iter   106/  209] train: loss: 0.0361666
[Epoch 77; Iter   136/  209] train: loss: 0.0423792
[Epoch 77; Iter   166/  209] train: loss: 0.0885955
[Epoch 77; Iter   196/  209] train: loss: 0.0218109
[Epoch 77] ogbg-moltox21: 0.760865 val loss: 0.545328
[Epoch 77] ogbg-moltox21: 0.714178 test loss: 0.642632
[Epoch 78; Iter    17/  209] train: loss: 0.0367695
[Epoch 78; Iter    47/  209] train: loss: 0.0371271
[Epoch 78; Iter    77/  209] train: loss: 0.1069996
[Epoch 78; Iter   107/  209] train: loss: 0.0374789
[Epoch 78; Iter   137/  209] train: loss: 0.0370014
[Epoch 78; Iter   167/  209] train: loss: 0.0625576
[Epoch 78; Iter   197/  209] train: loss: 0.0303155
[Epoch 78] ogbg-moltox21: 0.756556 val loss: 0.531483
[Epoch 78] ogbg-moltox21: 0.704804 test loss: 0.607562
[Epoch 79; Iter    18/  209] train: loss: 0.0251538
[Epoch 79; Iter    48/  209] train: loss: 0.0432929
[Epoch 79; Iter    78/  209] train: loss: 0.0433331
[Epoch 79; Iter   108/  209] train: loss: 0.0450717
[Epoch 79; Iter   138/  209] train: loss: 0.0284937
[Epoch 79; Iter   168/  209] train: loss: 0.0135949
[Epoch 79; Iter   198/  209] train: loss: 0.0176556
[Epoch 79] ogbg-moltox21: 0.744471 val loss: 0.565682
[Epoch 79] ogbg-moltox21: 0.706864 test loss: 0.636968
[Epoch 80; Iter    19/  209] train: loss: 0.0112743
[Epoch 80; Iter    49/  209] train: loss: 0.0337911
[Epoch 80; Iter    79/  209] train: loss: 0.0243924
[Epoch 80; Iter   109/  209] train: loss: 0.0470917
[Epoch 80; Iter   139/  209] train: loss: 0.0273015
[Epoch 80; Iter   169/  209] train: loss: 0.0094681
[Epoch 80; Iter   199/  209] train: loss: 0.0511308
[Epoch 80] ogbg-moltox21: 0.747289 val loss: 0.569696
[Epoch 80] ogbg-moltox21: 0.710301 test loss: 0.654748
[Epoch 81; Iter    20/  209] train: loss: 0.0209743
[Epoch 81; Iter    50/  209] train: loss: 0.0249252
[Epoch 81; Iter    80/  209] train: loss: 0.0241433
[Epoch 81; Iter   110/  209] train: loss: 0.0211664
[Epoch 81; Iter   140/  209] train: loss: 0.0141811
[Epoch 81; Iter   170/  209] train: loss: 0.0302458
[Epoch 81; Iter   200/  209] train: loss: 0.0387316
[Epoch 81] ogbg-moltox21: 0.759497 val loss: 0.537065
[Epoch 81] ogbg-moltox21: 0.714604 test loss: 0.816082
[Epoch 82; Iter    21/  209] train: loss: 0.0415841
[Epoch 64] ogbg-moltox21: 0.732281 test loss: 0.439450
[Epoch 65; Iter     4/  209] train: loss: 0.0347316
[Epoch 65; Iter    34/  209] train: loss: 0.0689450
[Epoch 65; Iter    64/  209] train: loss: 0.0322101
[Epoch 65; Iter    94/  209] train: loss: 0.0828296
[Epoch 65; Iter   124/  209] train: loss: 0.0633792
[Epoch 65; Iter   154/  209] train: loss: 0.0461399
[Epoch 65; Iter   184/  209] train: loss: 0.0480587
[Epoch 65] ogbg-moltox21: 0.747275 val loss: 0.983197
[Epoch 65] ogbg-moltox21: 0.733338 test loss: 0.457974
[Epoch 66; Iter     5/  209] train: loss: 0.0456406
[Epoch 66; Iter    35/  209] train: loss: 0.0177112
[Epoch 66; Iter    65/  209] train: loss: 0.0257402
[Epoch 66; Iter    95/  209] train: loss: 0.0332338
[Epoch 66; Iter   125/  209] train: loss: 0.0434023
[Epoch 66; Iter   155/  209] train: loss: 0.0437056
[Epoch 66; Iter   185/  209] train: loss: 0.0353569
[Epoch 66] ogbg-moltox21: 0.723030 val loss: 0.729532
[Epoch 66] ogbg-moltox21: 0.718712 test loss: 0.460196
[Epoch 67; Iter     6/  209] train: loss: 0.0381814
[Epoch 67; Iter    36/  209] train: loss: 0.0205095
[Epoch 67; Iter    66/  209] train: loss: 0.0279374
[Epoch 67; Iter    96/  209] train: loss: 0.0425301
[Epoch 67; Iter   126/  209] train: loss: 0.0433829
[Epoch 67; Iter   156/  209] train: loss: 0.0395290
[Epoch 67; Iter   186/  209] train: loss: 0.0513671
[Epoch 67] ogbg-moltox21: 0.753792 val loss: 1.315607
[Epoch 67] ogbg-moltox21: 0.735182 test loss: 0.461856
[Epoch 68; Iter     7/  209] train: loss: 0.0222175
[Epoch 68; Iter    37/  209] train: loss: 0.0210776
[Epoch 68; Iter    67/  209] train: loss: 0.0332996
[Epoch 68; Iter    97/  209] train: loss: 0.0308948
[Epoch 68; Iter   127/  209] train: loss: 0.0407847
[Epoch 68; Iter   157/  209] train: loss: 0.0249475
[Epoch 68; Iter   187/  209] train: loss: 0.0386508
[Epoch 68] ogbg-moltox21: 0.741980 val loss: 1.088437
[Epoch 68] ogbg-moltox21: 0.733512 test loss: 0.465372
[Epoch 69; Iter     8/  209] train: loss: 0.0263296
[Epoch 69; Iter    38/  209] train: loss: 0.0271381
[Epoch 69; Iter    68/  209] train: loss: 0.0257909
[Epoch 69; Iter    98/  209] train: loss: 0.0301679
[Epoch 69; Iter   128/  209] train: loss: 0.0165406
[Epoch 69; Iter   158/  209] train: loss: 0.0539315
[Epoch 69; Iter   188/  209] train: loss: 0.0207261
[Epoch 69] ogbg-moltox21: 0.747203 val loss: 1.091239
[Epoch 69] ogbg-moltox21: 0.724333 test loss: 0.502668
[Epoch 70; Iter     9/  209] train: loss: 0.0185482
[Epoch 70; Iter    39/  209] train: loss: 0.0177723
[Epoch 70; Iter    69/  209] train: loss: 0.0201276
[Epoch 70; Iter    99/  209] train: loss: 0.0234712
[Epoch 70; Iter   129/  209] train: loss: 0.0445880
[Epoch 70; Iter   159/  209] train: loss: 0.0591434
[Epoch 70; Iter   189/  209] train: loss: 0.0323744
[Epoch 70] ogbg-moltox21: 0.744398 val loss: 0.708326
[Epoch 70] ogbg-moltox21: 0.724042 test loss: 0.492824
[Epoch 71; Iter    10/  209] train: loss: 0.0233988
[Epoch 71; Iter    40/  209] train: loss: 0.0301904
[Epoch 71; Iter    70/  209] train: loss: 0.0327993
[Epoch 71; Iter   100/  209] train: loss: 0.0326157
[Epoch 71; Iter   130/  209] train: loss: 0.0282858
[Epoch 71; Iter   160/  209] train: loss: 0.0258515
[Epoch 71; Iter   190/  209] train: loss: 0.0249417
[Epoch 71] ogbg-moltox21: 0.745143 val loss: 1.279438
[Epoch 71] ogbg-moltox21: 0.722744 test loss: 0.494865
[Epoch 72; Iter    11/  209] train: loss: 0.0335156
[Epoch 72; Iter    41/  209] train: loss: 0.0383269
[Epoch 72; Iter    71/  209] train: loss: 0.0329756
[Epoch 72; Iter   101/  209] train: loss: 0.0208540
[Epoch 72; Iter   131/  209] train: loss: 0.0362708
[Epoch 72; Iter   161/  209] train: loss: 0.0365371
[Epoch 72; Iter   191/  209] train: loss: 0.0584384
[Epoch 72] ogbg-moltox21: 0.736122 val loss: 1.149162
[Epoch 72] ogbg-moltox21: 0.735852 test loss: 0.471828
[Epoch 73; Iter    12/  209] train: loss: 0.0318424
[Epoch 73; Iter    42/  209] train: loss: 0.0313498
[Epoch 73; Iter    72/  209] train: loss: 0.0276318
[Epoch 73; Iter   102/  209] train: loss: 0.0177265
[Epoch 73; Iter   132/  209] train: loss: 0.0359176
[Epoch 73; Iter   162/  209] train: loss: 0.0286766
[Epoch 73; Iter   192/  209] train: loss: 0.0694579
[Epoch 73] ogbg-moltox21: 0.736079 val loss: 1.222076
[Epoch 73] ogbg-moltox21: 0.718877 test loss: 0.506628
[Epoch 74; Iter    13/  209] train: loss: 0.0306133
[Epoch 74; Iter    43/  209] train: loss: 0.0309494
[Epoch 74; Iter    73/  209] train: loss: 0.0473627
[Epoch 74; Iter   103/  209] train: loss: 0.0246879
[Epoch 74; Iter   133/  209] train: loss: 0.0397412
[Epoch 74; Iter   163/  209] train: loss: 0.0251157
[Epoch 74; Iter   193/  209] train: loss: 0.0282541
[Epoch 74] ogbg-moltox21: 0.742172 val loss: 1.176645
[Epoch 74] ogbg-moltox21: 0.720861 test loss: 0.509750
[Epoch 75; Iter    14/  209] train: loss: 0.0092025
[Epoch 75; Iter    44/  209] train: loss: 0.0139786
[Epoch 75; Iter    74/  209] train: loss: 0.0265789
[Epoch 75; Iter   104/  209] train: loss: 0.0841647
[Epoch 75; Iter   134/  209] train: loss: 0.0158354
[Epoch 75; Iter   164/  209] train: loss: 0.0292135
[Epoch 75; Iter   194/  209] train: loss: 0.0244970
[Epoch 75] ogbg-moltox21: 0.735692 val loss: 1.021369
[Epoch 75] ogbg-moltox21: 0.720716 test loss: 0.517093
[Epoch 76; Iter    15/  209] train: loss: 0.0288121
[Epoch 76; Iter    45/  209] train: loss: 0.0209201
[Epoch 76; Iter    75/  209] train: loss: 0.0306287
[Epoch 76; Iter   105/  209] train: loss: 0.0176215
[Epoch 76; Iter   135/  209] train: loss: 0.0283522
[Epoch 76; Iter   165/  209] train: loss: 0.0159070
[Epoch 76; Iter   195/  209] train: loss: 0.0186914
[Epoch 76] ogbg-moltox21: 0.735451 val loss: 1.406919
[Epoch 76] ogbg-moltox21: 0.719135 test loss: 0.518276
[Epoch 77; Iter    16/  209] train: loss: 0.0541027
[Epoch 77; Iter    46/  209] train: loss: 0.0145660
[Epoch 77; Iter    76/  209] train: loss: 0.0242374
[Epoch 77; Iter   106/  209] train: loss: 0.0180146
[Epoch 77; Iter   136/  209] train: loss: 0.0377440
[Epoch 77; Iter   166/  209] train: loss: 0.0258878
[Epoch 77; Iter   196/  209] train: loss: 0.0489265
[Epoch 77] ogbg-moltox21: 0.728868 val loss: 1.414215
[Epoch 77] ogbg-moltox21: 0.710631 test loss: 0.522184
[Epoch 78; Iter    17/  209] train: loss: 0.0147385
[Epoch 78; Iter    47/  209] train: loss: 0.0115209
[Epoch 78; Iter    77/  209] train: loss: 0.0298467
[Epoch 78; Iter   107/  209] train: loss: 0.0127049
[Epoch 78; Iter   137/  209] train: loss: 0.0336605
[Epoch 78; Iter   167/  209] train: loss: 0.0259950
[Epoch 78; Iter   197/  209] train: loss: 0.0178999
[Epoch 78] ogbg-moltox21: 0.742176 val loss: 0.995030
[Epoch 78] ogbg-moltox21: 0.721417 test loss: 0.533515
[Epoch 79; Iter    18/  209] train: loss: 0.0195129
[Epoch 79; Iter    48/  209] train: loss: 0.0223006
[Epoch 79; Iter    78/  209] train: loss: 0.0288261
[Epoch 79; Iter   108/  209] train: loss: 0.0233809
[Epoch 79; Iter   138/  209] train: loss: 0.0231807
[Epoch 79; Iter   168/  209] train: loss: 0.0272968
[Epoch 79; Iter   198/  209] train: loss: 0.0147425
[Epoch 79] ogbg-moltox21: 0.733651 val loss: 0.997433
[Epoch 79] ogbg-moltox21: 0.712167 test loss: 0.545249
[Epoch 80; Iter    19/  209] train: loss: 0.0105185
[Epoch 80; Iter    49/  209] train: loss: 0.0325310
[Epoch 80; Iter    79/  209] train: loss: 0.0118291
[Epoch 80; Iter   109/  209] train: loss: 0.0160487
[Epoch 80; Iter   139/  209] train: loss: 0.0182855
[Epoch 80; Iter   169/  209] train: loss: 0.0224396
[Epoch 80; Iter   199/  209] train: loss: 0.0669405
[Epoch 80] ogbg-moltox21: 0.741426 val loss: 1.067610
[Epoch 80] ogbg-moltox21: 0.722401 test loss: 0.537792
[Epoch 81; Iter    20/  209] train: loss: 0.0218556
[Epoch 81; Iter    50/  209] train: loss: 0.0141864
[Epoch 81; Iter    80/  209] train: loss: 0.0268130
[Epoch 81; Iter   110/  209] train: loss: 0.0294412
[Epoch 81; Iter   140/  209] train: loss: 0.0469850
[Epoch 81; Iter   170/  209] train: loss: 0.0414105
[Epoch 81; Iter   200/  209] train: loss: 0.0220089
[Epoch 81] ogbg-moltox21: 0.748637 val loss: 0.698725
[Epoch 81] ogbg-moltox21: 0.722068 test loss: 0.525147
[Epoch 82; Iter    21/  209] train: loss: 0.0134240
[Epoch 64] ogbg-moltox21: 0.706546 test loss: 0.417231
[Epoch 65; Iter     4/  209] train: loss: 0.0772524
[Epoch 65; Iter    34/  209] train: loss: 0.0344984
[Epoch 65; Iter    64/  209] train: loss: 0.0686801
[Epoch 65; Iter    94/  209] train: loss: 0.0591121
[Epoch 65; Iter   124/  209] train: loss: 0.0565090
[Epoch 65; Iter   154/  209] train: loss: 0.0748859
[Epoch 65; Iter   184/  209] train: loss: 0.0975603
[Epoch 65] ogbg-moltox21: 0.721472 val loss: 0.427309
[Epoch 65] ogbg-moltox21: 0.717604 test loss: 0.486379
[Epoch 66; Iter     5/  209] train: loss: 0.0471874
[Epoch 66; Iter    35/  209] train: loss: 0.0405975
[Epoch 66; Iter    65/  209] train: loss: 0.0685696
[Epoch 66; Iter    95/  209] train: loss: 0.0685487
[Epoch 66; Iter   125/  209] train: loss: 0.0479491
[Epoch 66; Iter   155/  209] train: loss: 0.0741339
[Epoch 66; Iter   185/  209] train: loss: 0.0586650
[Epoch 66] ogbg-moltox21: 0.723471 val loss: 0.385404
[Epoch 66] ogbg-moltox21: 0.707320 test loss: 0.430588
[Epoch 67; Iter     6/  209] train: loss: 0.1047457
[Epoch 67; Iter    36/  209] train: loss: 0.0808249
[Epoch 67; Iter    66/  209] train: loss: 0.0492177
[Epoch 67; Iter    96/  209] train: loss: 0.0617462
[Epoch 67; Iter   126/  209] train: loss: 0.0274510
[Epoch 67; Iter   156/  209] train: loss: 0.0580978
[Epoch 67; Iter   186/  209] train: loss: 0.0742666
[Epoch 67] ogbg-moltox21: 0.721956 val loss: 0.422130
[Epoch 67] ogbg-moltox21: 0.710012 test loss: 0.466193
[Epoch 68; Iter     7/  209] train: loss: 0.0581646
[Epoch 68; Iter    37/  209] train: loss: 0.0685023
[Epoch 68; Iter    67/  209] train: loss: 0.0559191
[Epoch 68; Iter    97/  209] train: loss: 0.0577925
[Epoch 68; Iter   127/  209] train: loss: 0.0733414
[Epoch 68; Iter   157/  209] train: loss: 0.0382323
[Epoch 68; Iter   187/  209] train: loss: 0.0370078
[Epoch 68] ogbg-moltox21: 0.710810 val loss: 0.422512
[Epoch 68] ogbg-moltox21: 0.705394 test loss: 0.465382
[Epoch 69; Iter     8/  209] train: loss: 0.0506953
[Epoch 69; Iter    38/  209] train: loss: 0.0432821
[Epoch 69; Iter    68/  209] train: loss: 0.0457377
[Epoch 69; Iter    98/  209] train: loss: 0.0458783
[Epoch 69; Iter   128/  209] train: loss: 0.0439197
[Epoch 69; Iter   158/  209] train: loss: 0.0512400
[Epoch 69; Iter   188/  209] train: loss: 0.0500117
[Epoch 69] ogbg-moltox21: 0.724508 val loss: 0.396627
[Epoch 69] ogbg-moltox21: 0.711706 test loss: 0.439442
[Epoch 70; Iter     9/  209] train: loss: 0.0552146
[Epoch 70; Iter    39/  209] train: loss: 0.0329973
[Epoch 70; Iter    69/  209] train: loss: 0.0676029
[Epoch 70; Iter    99/  209] train: loss: 0.0740483
[Epoch 70; Iter   129/  209] train: loss: 0.0320096
[Epoch 70; Iter   159/  209] train: loss: 0.0561582
[Epoch 70; Iter   189/  209] train: loss: 0.0538134
[Epoch 70] ogbg-moltox21: 0.712843 val loss: 0.433165
[Epoch 70] ogbg-moltox21: 0.701513 test loss: 0.444781
[Epoch 71; Iter    10/  209] train: loss: 0.0601401
[Epoch 71; Iter    40/  209] train: loss: 0.0865836
[Epoch 71; Iter    70/  209] train: loss: 0.0405777
[Epoch 71; Iter   100/  209] train: loss: 0.0713256
[Epoch 71; Iter   130/  209] train: loss: 0.0390597
[Epoch 71; Iter   160/  209] train: loss: 0.0597813
[Epoch 71; Iter   190/  209] train: loss: 0.0418337
[Epoch 71] ogbg-moltox21: 0.712507 val loss: 0.424349
[Epoch 71] ogbg-moltox21: 0.703435 test loss: 0.457080
[Epoch 72; Iter    11/  209] train: loss: 0.0476345
[Epoch 72; Iter    41/  209] train: loss: 0.0521368
[Epoch 72; Iter    71/  209] train: loss: 0.0858190
[Epoch 72; Iter   101/  209] train: loss: 0.0442491
[Epoch 72; Iter   131/  209] train: loss: 0.0674313
[Epoch 72; Iter   161/  209] train: loss: 0.0640515
[Epoch 72; Iter   191/  209] train: loss: 0.0485004
[Epoch 72] ogbg-moltox21: 0.714122 val loss: 0.422545
[Epoch 72] ogbg-moltox21: 0.705420 test loss: 0.447645
[Epoch 73; Iter    12/  209] train: loss: 0.0614772
[Epoch 73; Iter    42/  209] train: loss: 0.0374530
[Epoch 73; Iter    72/  209] train: loss: 0.0318342
[Epoch 73; Iter   102/  209] train: loss: 0.0633294
[Epoch 73; Iter   132/  209] train: loss: 0.0550116
[Epoch 73; Iter   162/  209] train: loss: 0.0508702
[Epoch 73; Iter   192/  209] train: loss: 0.0779982
[Epoch 73] ogbg-moltox21: 0.721352 val loss: 0.427190
[Epoch 73] ogbg-moltox21: 0.709327 test loss: 0.460503
[Epoch 74; Iter    13/  209] train: loss: 0.0465644
[Epoch 74; Iter    43/  209] train: loss: 0.0878957
[Epoch 74; Iter    73/  209] train: loss: 0.0369509
[Epoch 74; Iter   103/  209] train: loss: 0.0383486
[Epoch 74; Iter   133/  209] train: loss: 0.0337065
[Epoch 74; Iter   163/  209] train: loss: 0.0434329
[Epoch 74; Iter   193/  209] train: loss: 0.0459586
[Epoch 74] ogbg-moltox21: 0.709590 val loss: 0.437314
[Epoch 74] ogbg-moltox21: 0.706888 test loss: 0.470686
[Epoch 75; Iter    14/  209] train: loss: 0.0404638
[Epoch 75; Iter    44/  209] train: loss: 0.0729876
[Epoch 75; Iter    74/  209] train: loss: 0.0410513
[Epoch 75; Iter   104/  209] train: loss: 0.0330124
[Epoch 75; Iter   134/  209] train: loss: 0.0398652
[Epoch 75; Iter   164/  209] train: loss: 0.0497988
[Epoch 75; Iter   194/  209] train: loss: 0.0470449
[Epoch 75] ogbg-moltox21: 0.718388 val loss: 0.426492
[Epoch 75] ogbg-moltox21: 0.710755 test loss: 0.465176
[Epoch 76; Iter    15/  209] train: loss: 0.0562796
[Epoch 76; Iter    45/  209] train: loss: 0.0238105
[Epoch 76; Iter    75/  209] train: loss: 0.0332193
[Epoch 76; Iter   105/  209] train: loss: 0.0383859
[Epoch 76; Iter   135/  209] train: loss: 0.0342605
[Epoch 76; Iter   165/  209] train: loss: 0.0366609
[Epoch 76; Iter   195/  209] train: loss: 0.0515909
[Epoch 76] ogbg-moltox21: 0.728497 val loss: 0.439979
[Epoch 76] ogbg-moltox21: 0.713778 test loss: 0.532634
[Epoch 77; Iter    16/  209] train: loss: 0.0457120
[Epoch 77; Iter    46/  209] train: loss: 0.0433335
[Epoch 77; Iter    76/  209] train: loss: 0.0502569
[Epoch 77; Iter   106/  209] train: loss: 0.0367774
[Epoch 77; Iter   136/  209] train: loss: 0.0604309
[Epoch 77; Iter   166/  209] train: loss: 0.0531635
[Epoch 77; Iter   196/  209] train: loss: 0.0524304
[Epoch 77] ogbg-moltox21: 0.718248 val loss: 0.453730
[Epoch 77] ogbg-moltox21: 0.712048 test loss: 0.477220
[Epoch 78; Iter    17/  209] train: loss: 0.0372233
[Epoch 78; Iter    47/  209] train: loss: 0.0557334
[Epoch 78; Iter    77/  209] train: loss: 0.0308447
[Epoch 78; Iter   107/  209] train: loss: 0.1067159
[Epoch 78; Iter   137/  209] train: loss: 0.0524716
[Epoch 78; Iter   167/  209] train: loss: 0.1000636
[Epoch 78; Iter   197/  209] train: loss: 0.0257351
[Epoch 78] ogbg-moltox21: 0.708913 val loss: 0.435358
[Epoch 78] ogbg-moltox21: 0.700096 test loss: 0.472881
[Epoch 79; Iter    18/  209] train: loss: 0.1130260
[Epoch 79; Iter    48/  209] train: loss: 0.0482095
[Epoch 79; Iter    78/  209] train: loss: 0.0288081
[Epoch 79; Iter   108/  209] train: loss: 0.0587626
[Epoch 79; Iter   138/  209] train: loss: 0.0452193
[Epoch 79; Iter   168/  209] train: loss: 0.0372794
[Epoch 79; Iter   198/  209] train: loss: 0.0493892
[Epoch 79] ogbg-moltox21: 0.716248 val loss: 0.530674
[Epoch 79] ogbg-moltox21: 0.718632 test loss: 0.526407
[Epoch 80; Iter    19/  209] train: loss: 0.0883276
[Epoch 80; Iter    49/  209] train: loss: 0.0411880
[Epoch 80; Iter    79/  209] train: loss: 0.0272449
[Epoch 80; Iter   109/  209] train: loss: 0.0273325
[Epoch 80; Iter   139/  209] train: loss: 0.0289879
[Epoch 80; Iter   169/  209] train: loss: 0.0681448
[Epoch 80; Iter   199/  209] train: loss: 0.0416408
[Epoch 80] ogbg-moltox21: 0.706764 val loss: 0.475516
[Epoch 80] ogbg-moltox21: 0.703875 test loss: 0.492716
[Epoch 81; Iter    20/  209] train: loss: 0.0356802
[Epoch 81; Iter    50/  209] train: loss: 0.0348245
[Epoch 81; Iter    80/  209] train: loss: 0.0453565
[Epoch 81; Iter   110/  209] train: loss: 0.0302588
[Epoch 81; Iter   140/  209] train: loss: 0.0495294
[Epoch 81; Iter   170/  209] train: loss: 0.0407771
[Epoch 81; Iter   200/  209] train: loss: 0.0546140
[Epoch 81] ogbg-moltox21: 0.719461 val loss: 0.461470
[Epoch 81] ogbg-moltox21: 0.711311 test loss: 0.495354
[Epoch 82; Iter    21/  209] train: loss: 0.0362024
[Epoch 64] ogbg-moltox21: 0.696101 test loss: 0.676096
[Epoch 65; Iter     4/  209] train: loss: 0.0273398
[Epoch 65; Iter    34/  209] train: loss: 0.0450190
[Epoch 65; Iter    64/  209] train: loss: 0.0238615
[Epoch 65; Iter    94/  209] train: loss: 0.0275145
[Epoch 65; Iter   124/  209] train: loss: 0.0234016
[Epoch 65; Iter   154/  209] train: loss: 0.0232765
[Epoch 65; Iter   184/  209] train: loss: 0.0411611
[Epoch 65] ogbg-moltox21: 0.746437 val loss: 0.618288
[Epoch 65] ogbg-moltox21: 0.705787 test loss: 0.666806
[Epoch 66; Iter     5/  209] train: loss: 0.0192877
[Epoch 66; Iter    35/  209] train: loss: 0.0236348
[Epoch 66; Iter    65/  209] train: loss: 0.0264036
[Epoch 66; Iter    95/  209] train: loss: 0.0373949
[Epoch 66; Iter   125/  209] train: loss: 0.0230792
[Epoch 66; Iter   155/  209] train: loss: 0.0264228
[Epoch 66; Iter   185/  209] train: loss: 0.0219521
[Epoch 66] ogbg-moltox21: 0.746898 val loss: 0.605426
[Epoch 66] ogbg-moltox21: 0.710457 test loss: 0.652684
[Epoch 67; Iter     6/  209] train: loss: 0.0162894
[Epoch 67; Iter    36/  209] train: loss: 0.0294967
[Epoch 67; Iter    66/  209] train: loss: 0.0205766
[Epoch 67; Iter    96/  209] train: loss: 0.0252663
[Epoch 67; Iter   126/  209] train: loss: 0.0190122
[Epoch 67; Iter   156/  209] train: loss: 0.0232506
[Epoch 67; Iter   186/  209] train: loss: 0.0248952
[Epoch 67] ogbg-moltox21: 0.745075 val loss: 0.623358
[Epoch 67] ogbg-moltox21: 0.706367 test loss: 0.678740
[Epoch 68; Iter     7/  209] train: loss: 0.0189117
[Epoch 68; Iter    37/  209] train: loss: 0.0202532
[Epoch 68; Iter    67/  209] train: loss: 0.0662005
[Epoch 68; Iter    97/  209] train: loss: 0.0188911
[Epoch 68; Iter   127/  209] train: loss: 0.0209250
[Epoch 68; Iter   157/  209] train: loss: 0.0372543
[Epoch 68; Iter   187/  209] train: loss: 0.0372304
[Epoch 68] ogbg-moltox21: 0.746125 val loss: 0.637508
[Epoch 68] ogbg-moltox21: 0.702714 test loss: 0.687958
[Epoch 69; Iter     8/  209] train: loss: 0.0211590
[Epoch 69; Iter    38/  209] train: loss: 0.0520429
[Epoch 69; Iter    68/  209] train: loss: 0.0272337
[Epoch 69; Iter    98/  209] train: loss: 0.0206149
[Epoch 69; Iter   128/  209] train: loss: 0.0192397
[Epoch 69; Iter   158/  209] train: loss: 0.0288506
[Epoch 69; Iter   188/  209] train: loss: 0.0328600
[Epoch 69] ogbg-moltox21: 0.743768 val loss: 0.633851
[Epoch 69] ogbg-moltox21: 0.699605 test loss: 0.694059
[Epoch 70; Iter     9/  209] train: loss: 0.0212608
[Epoch 70; Iter    39/  209] train: loss: 0.0308820
[Epoch 70; Iter    69/  209] train: loss: 0.0506452
[Epoch 70; Iter    99/  209] train: loss: 0.0524837
[Epoch 70; Iter   129/  209] train: loss: 0.0247941
[Epoch 70; Iter   159/  209] train: loss: 0.0243930
[Epoch 70; Iter   189/  209] train: loss: 0.0306654
[Epoch 70] ogbg-moltox21: 0.746632 val loss: 0.669682
[Epoch 70] ogbg-moltox21: 0.701959 test loss: 0.728679
[Epoch 71; Iter    10/  209] train: loss: 0.0116487
[Epoch 71; Iter    40/  209] train: loss: 0.0278784
[Epoch 71; Iter    70/  209] train: loss: 0.0191187
[Epoch 71; Iter   100/  209] train: loss: 0.0341411
[Epoch 71; Iter   130/  209] train: loss: 0.0256363
[Epoch 71; Iter   160/  209] train: loss: 0.0277077
[Epoch 71; Iter   190/  209] train: loss: 0.0211537
[Epoch 71] ogbg-moltox21: 0.745954 val loss: 0.625772
[Epoch 71] ogbg-moltox21: 0.705645 test loss: 0.678573
[Epoch 72; Iter    11/  209] train: loss: 0.0258130
[Epoch 72; Iter    41/  209] train: loss: 0.0079394
[Epoch 72; Iter    71/  209] train: loss: 0.0201908
[Epoch 72; Iter   101/  209] train: loss: 0.0138181
[Epoch 72; Iter   131/  209] train: loss: 0.0385008
[Epoch 72; Iter   161/  209] train: loss: 0.0344607
[Epoch 72; Iter   191/  209] train: loss: 0.0573130
[Epoch 72] ogbg-moltox21: 0.740905 val loss: 0.642491
[Epoch 72] ogbg-moltox21: 0.700547 test loss: 0.701928
[Epoch 73; Iter    12/  209] train: loss: 0.0190798
[Epoch 73; Iter    42/  209] train: loss: 0.0344210
[Epoch 73; Iter    72/  209] train: loss: 0.0120226
[Epoch 73; Iter   102/  209] train: loss: 0.0315943
[Epoch 73; Iter   132/  209] train: loss: 0.0320326
[Epoch 73; Iter   162/  209] train: loss: 0.0166160
[Epoch 73; Iter   192/  209] train: loss: 0.0172902
[Epoch 73] ogbg-moltox21: 0.739862 val loss: 0.706073
[Epoch 73] ogbg-moltox21: 0.700896 test loss: 0.772985
[Epoch 74; Iter    13/  209] train: loss: 0.0137207
[Epoch 74; Iter    43/  209] train: loss: 0.0306653
[Epoch 74; Iter    73/  209] train: loss: 0.0487560
[Epoch 74; Iter   103/  209] train: loss: 0.0158962
[Epoch 74; Iter   133/  209] train: loss: 0.0195284
[Epoch 74; Iter   163/  209] train: loss: 0.0477746
[Epoch 74; Iter   193/  209] train: loss: 0.0301144
[Epoch 74] ogbg-moltox21: 0.735234 val loss: 0.737631
[Epoch 74] ogbg-moltox21: 0.699598 test loss: 0.789871
[Epoch 75; Iter    14/  209] train: loss: 0.0263257
[Epoch 75; Iter    44/  209] train: loss: 0.0145842
[Epoch 75; Iter    74/  209] train: loss: 0.0140426
[Epoch 75; Iter   104/  209] train: loss: 0.0419739
[Epoch 75; Iter   134/  209] train: loss: 0.0580507
[Epoch 75; Iter   164/  209] train: loss: 0.0154375
[Epoch 75; Iter   194/  209] train: loss: 0.0174496
[Epoch 75] ogbg-moltox21: 0.740599 val loss: 0.706159
[Epoch 75] ogbg-moltox21: 0.702683 test loss: 0.764846
[Epoch 76; Iter    15/  209] train: loss: 0.0218412
[Epoch 76; Iter    45/  209] train: loss: 0.0460315
[Epoch 76; Iter    75/  209] train: loss: 0.0276915
[Epoch 76; Iter   105/  209] train: loss: 0.0290223
[Epoch 76; Iter   135/  209] train: loss: 0.0264890
[Epoch 76; Iter   165/  209] train: loss: 0.0302316
[Epoch 76; Iter   195/  209] train: loss: 0.0199128
[Epoch 76] ogbg-moltox21: 0.740763 val loss: 0.739549
[Epoch 76] ogbg-moltox21: 0.699769 test loss: 0.798158
[Epoch 77; Iter    16/  209] train: loss: 0.0118762
[Epoch 77; Iter    46/  209] train: loss: 0.0096154
[Epoch 77; Iter    76/  209] train: loss: 0.0127470
[Epoch 77; Iter   106/  209] train: loss: 0.0266898
[Epoch 77; Iter   136/  209] train: loss: 0.0409911
[Epoch 77; Iter   166/  209] train: loss: 0.0436540
[Epoch 77; Iter   196/  209] train: loss: 0.0171096
[Epoch 77] ogbg-moltox21: 0.738819 val loss: 0.696007
[Epoch 77] ogbg-moltox21: 0.704491 test loss: 0.752995
[Epoch 78; Iter    17/  209] train: loss: 0.0406185
[Epoch 78; Iter    47/  209] train: loss: 0.0201935
[Epoch 78; Iter    77/  209] train: loss: 0.0826825
[Epoch 78; Iter   107/  209] train: loss: 0.0386637
[Epoch 78; Iter   137/  209] train: loss: 0.0253691
[Epoch 78; Iter   167/  209] train: loss: 0.0202140
[Epoch 78; Iter   197/  209] train: loss: 0.0224207
[Epoch 78] ogbg-moltox21: 0.735577 val loss: 0.739498
[Epoch 78] ogbg-moltox21: 0.693282 test loss: 0.803347
[Epoch 79; Iter    18/  209] train: loss: 0.0255976
[Epoch 79; Iter    48/  209] train: loss: 0.0369753
[Epoch 79; Iter    78/  209] train: loss: 0.0429019
[Epoch 79; Iter   108/  209] train: loss: 0.0462313
[Epoch 79; Iter   138/  209] train: loss: 0.0309770
[Epoch 79; Iter   168/  209] train: loss: 0.0172241
[Epoch 79; Iter   198/  209] train: loss: 0.0182402
[Epoch 79] ogbg-moltox21: 0.743819 val loss: 0.746810
[Epoch 79] ogbg-moltox21: 0.698520 test loss: 0.818359
[Epoch 80; Iter    19/  209] train: loss: 0.0243420
[Epoch 80; Iter    49/  209] train: loss: 0.0235608
[Epoch 80; Iter    79/  209] train: loss: 0.0481369
[Epoch 80; Iter   109/  209] train: loss: 0.0221801
[Epoch 80; Iter   139/  209] train: loss: 0.0306044
[Epoch 80; Iter   169/  209] train: loss: 0.0113645
[Epoch 80; Iter   199/  209] train: loss: 0.0345214
[Epoch 80] ogbg-moltox21: 0.733749 val loss: 0.733220
[Epoch 80] ogbg-moltox21: 0.694761 test loss: 0.789428
[Epoch 81; Iter    20/  209] train: loss: 0.0366255
[Epoch 81; Iter    50/  209] train: loss: 0.0213707
[Epoch 81; Iter    80/  209] train: loss: 0.0204513
[Epoch 81; Iter   110/  209] train: loss: 0.0274623
[Epoch 81; Iter   140/  209] train: loss: 0.0247813
[Epoch 81; Iter   170/  209] train: loss: 0.0193799
[Epoch 81; Iter   200/  209] train: loss: 0.0214095
[Epoch 81] ogbg-moltox21: 0.747114 val loss: 0.730135
[Epoch 81] ogbg-moltox21: 0.703790 test loss: 0.807043
[Epoch 82; Iter    21/  209] train: loss: 0.0322346
[Epoch 82; Iter    51/  209] train: loss: 0.0149952
[Epoch 82; Iter    81/  209] train: loss: 0.0260669
[Epoch 82; Iter   111/  209] train: loss: 0.0245515
[Epoch 82; Iter   141/  209] train: loss: 0.0376258
[Epoch 82; Iter   171/  209] train: loss: 0.0212649
[Epoch 82; Iter   201/  209] train: loss: 0.0976602
[Epoch 82] ogbg-moltox21: 0.787410 val loss: 0.482645
[Epoch 82] ogbg-moltox21: 0.749249 test loss: 0.581851
[Epoch 83; Iter    22/  209] train: loss: 0.0116710
[Epoch 83; Iter    52/  209] train: loss: 0.0335810
[Epoch 83; Iter    82/  209] train: loss: 0.0207694
[Epoch 83; Iter   112/  209] train: loss: 0.0154966
[Epoch 83; Iter   142/  209] train: loss: 0.0281664
[Epoch 83; Iter   172/  209] train: loss: 0.0416692
[Epoch 83; Iter   202/  209] train: loss: 0.0294437
[Epoch 83] ogbg-moltox21: 0.779436 val loss: 0.483414
[Epoch 83] ogbg-moltox21: 0.739067 test loss: 0.588370
[Epoch 84; Iter    23/  209] train: loss: 0.0102728
[Epoch 84; Iter    53/  209] train: loss: 0.0192053
[Epoch 84; Iter    83/  209] train: loss: 0.0135773
[Epoch 84; Iter   113/  209] train: loss: 0.0189969
[Epoch 84; Iter   143/  209] train: loss: 0.0161445
[Epoch 84; Iter   173/  209] train: loss: 0.0196123
[Epoch 84; Iter   203/  209] train: loss: 0.0201954
[Epoch 84] ogbg-moltox21: 0.786649 val loss: 0.469874
[Epoch 84] ogbg-moltox21: 0.745807 test loss: 0.554667
[Epoch 85; Iter    24/  209] train: loss: 0.0256669
[Epoch 85; Iter    54/  209] train: loss: 0.0705366
[Epoch 85; Iter    84/  209] train: loss: 0.0240558
[Epoch 85; Iter   114/  209] train: loss: 0.0232828
[Epoch 85; Iter   144/  209] train: loss: 0.0169002
[Epoch 85; Iter   174/  209] train: loss: 0.0397140
[Epoch 85; Iter   204/  209] train: loss: 0.0169836
[Epoch 85] ogbg-moltox21: 0.788370 val loss: 0.473809
[Epoch 85] ogbg-moltox21: 0.738046 test loss: 0.620195
[Epoch 86; Iter    25/  209] train: loss: 0.0125428
[Epoch 86; Iter    55/  209] train: loss: 0.0283634
[Epoch 86; Iter    85/  209] train: loss: 0.0154622
[Epoch 86; Iter   115/  209] train: loss: 0.0070349
[Epoch 86; Iter   145/  209] train: loss: 0.0342236
[Epoch 86; Iter   175/  209] train: loss: 0.0216147
[Epoch 86; Iter   205/  209] train: loss: 0.0391623
[Epoch 86] ogbg-moltox21: 0.785654 val loss: 0.474635
[Epoch 86] ogbg-moltox21: 0.742103 test loss: 0.597665
[Epoch 87; Iter    26/  209] train: loss: 0.0064351
[Epoch 87; Iter    56/  209] train: loss: 0.0248311
[Epoch 87; Iter    86/  209] train: loss: 0.0339161
[Epoch 87; Iter   116/  209] train: loss: 0.0243117
[Epoch 87; Iter   146/  209] train: loss: 0.0323258
[Epoch 87; Iter   176/  209] train: loss: 0.0345230
[Epoch 87; Iter   206/  209] train: loss: 0.0485827
[Epoch 87] ogbg-moltox21: 0.787878 val loss: 0.472055
[Epoch 87] ogbg-moltox21: 0.747127 test loss: 0.523530
[Epoch 88; Iter    27/  209] train: loss: 0.0267980
[Epoch 88; Iter    57/  209] train: loss: 0.0271321
[Epoch 88; Iter    87/  209] train: loss: 0.0243819
[Epoch 88; Iter   117/  209] train: loss: 0.0114432
[Epoch 88; Iter   147/  209] train: loss: 0.0126023
[Epoch 88; Iter   177/  209] train: loss: 0.0167503
[Epoch 88; Iter   207/  209] train: loss: 0.0162391
[Epoch 88] ogbg-moltox21: 0.781799 val loss: 0.465556
[Epoch 88] ogbg-moltox21: 0.741885 test loss: 0.532842
[Epoch 89; Iter    28/  209] train: loss: 0.0171123
[Epoch 89; Iter    58/  209] train: loss: 0.0161286
[Epoch 89; Iter    88/  209] train: loss: 0.0261792
[Epoch 89; Iter   118/  209] train: loss: 0.0250381
[Epoch 89; Iter   148/  209] train: loss: 0.0178897
[Epoch 89; Iter   178/  209] train: loss: 0.0183327
[Epoch 89; Iter   208/  209] train: loss: 0.0170587
[Epoch 89] ogbg-moltox21: 0.786993 val loss: 0.467805
[Epoch 89] ogbg-moltox21: 0.747588 test loss: 0.545621
[Epoch 90; Iter    29/  209] train: loss: 0.0274839
[Epoch 90; Iter    59/  209] train: loss: 0.0204511
[Epoch 90; Iter    89/  209] train: loss: 0.0236004
[Epoch 90; Iter   119/  209] train: loss: 0.0153190
[Epoch 90; Iter   149/  209] train: loss: 0.0077694
[Epoch 90; Iter   179/  209] train: loss: 0.0276692
[Epoch 90; Iter   209/  209] train: loss: 0.0135895
[Epoch 90] ogbg-moltox21: 0.783157 val loss: 0.466910
[Epoch 90] ogbg-moltox21: 0.741948 test loss: 0.596164
[Epoch 91; Iter    30/  209] train: loss: 0.0160321
[Epoch 91; Iter    60/  209] train: loss: 0.0147352
[Epoch 91; Iter    90/  209] train: loss: 0.1118475
[Epoch 91; Iter   120/  209] train: loss: 0.0183346
[Epoch 91; Iter   150/  209] train: loss: 0.0150647
[Epoch 91; Iter   180/  209] train: loss: 0.0256568
[Epoch 91] ogbg-moltox21: 0.783457 val loss: 0.479446
[Epoch 91] ogbg-moltox21: 0.741005 test loss: 0.588519
[Epoch 92; Iter     1/  209] train: loss: 0.0187884
[Epoch 92; Iter    31/  209] train: loss: 0.0202425
[Epoch 92; Iter    61/  209] train: loss: 0.0094267
[Epoch 92; Iter    91/  209] train: loss: 0.0208253
[Epoch 92; Iter   121/  209] train: loss: 0.0223506
[Epoch 92; Iter   151/  209] train: loss: 0.0074808
[Epoch 92; Iter   181/  209] train: loss: 0.0203746
[Epoch 92] ogbg-moltox21: 0.789357 val loss: 0.465166
[Epoch 92] ogbg-moltox21: 0.740594 test loss: 0.570397
[Epoch 93; Iter     2/  209] train: loss: 0.0200207
[Epoch 93; Iter    32/  209] train: loss: 0.0436397
[Epoch 93; Iter    62/  209] train: loss: 0.0208196
[Epoch 93; Iter    92/  209] train: loss: 0.0202995
[Epoch 93; Iter   122/  209] train: loss: 0.0084337
[Epoch 93; Iter   152/  209] train: loss: 0.0127987
[Epoch 93; Iter   182/  209] train: loss: 0.0178667
[Epoch 93] ogbg-moltox21: 0.785771 val loss: 0.492992
[Epoch 93] ogbg-moltox21: 0.735079 test loss: 0.692886
[Epoch 94; Iter     3/  209] train: loss: 0.0258794
[Epoch 94; Iter    33/  209] train: loss: 0.0087544
[Epoch 94; Iter    63/  209] train: loss: 0.0087567
[Epoch 94; Iter    93/  209] train: loss: 0.0174532
[Epoch 94; Iter   123/  209] train: loss: 0.0204051
[Epoch 94; Iter   153/  209] train: loss: 0.0132767
[Epoch 94; Iter   183/  209] train: loss: 0.0233249
[Epoch 94] ogbg-moltox21: 0.786948 val loss: 0.478616
[Epoch 94] ogbg-moltox21: 0.739269 test loss: 0.600377
[Epoch 95; Iter     4/  209] train: loss: 0.0282952
[Epoch 95; Iter    34/  209] train: loss: 0.0102867
[Epoch 95; Iter    64/  209] train: loss: 0.0150932
[Epoch 95; Iter    94/  209] train: loss: 0.0094780
[Epoch 95; Iter   124/  209] train: loss: 0.0373316
[Epoch 95; Iter   154/  209] train: loss: 0.0139586
[Epoch 95; Iter   184/  209] train: loss: 0.0260513
[Epoch 95] ogbg-moltox21: 0.789625 val loss: 0.469961
[Epoch 95] ogbg-moltox21: 0.741098 test loss: 0.584757
[Epoch 96; Iter     5/  209] train: loss: 0.0117138
[Epoch 96; Iter    35/  209] train: loss: 0.0072496
[Epoch 96; Iter    65/  209] train: loss: 0.0164465
[Epoch 96; Iter    95/  209] train: loss: 0.0343469
[Epoch 96; Iter   125/  209] train: loss: 0.0184323
[Epoch 96; Iter   155/  209] train: loss: 0.0227940
[Epoch 96; Iter   185/  209] train: loss: 0.0400953
[Epoch 96] ogbg-moltox21: 0.789028 val loss: 0.468966
[Epoch 96] ogbg-moltox21: 0.739281 test loss: 0.636960
[Epoch 97; Iter     6/  209] train: loss: 0.0265602
[Epoch 97; Iter    36/  209] train: loss: 0.0220462
[Epoch 97; Iter    66/  209] train: loss: 0.0160249
[Epoch 97; Iter    96/  209] train: loss: 0.0204467
[Epoch 97; Iter   126/  209] train: loss: 0.0089055
[Epoch 97; Iter   156/  209] train: loss: 0.0458129
[Epoch 97; Iter   186/  209] train: loss: 0.0209047
[Epoch 97] ogbg-moltox21: 0.790552 val loss: 0.499737
[Epoch 97] ogbg-moltox21: 0.742544 test loss: 0.601939
[Epoch 98; Iter     7/  209] train: loss: 0.0124116
[Epoch 98; Iter    37/  209] train: loss: 0.0172394
[Epoch 98; Iter    67/  209] train: loss: 0.0077737
[Epoch 98; Iter    97/  209] train: loss: 0.0375473
[Epoch 98; Iter   127/  209] train: loss: 0.0078265
[Epoch 98; Iter   157/  209] train: loss: 0.0130304
[Epoch 98; Iter   187/  209] train: loss: 0.0141840
[Epoch 98] ogbg-moltox21: 0.783811 val loss: 0.501194
[Epoch 98] ogbg-moltox21: 0.738852 test loss: 0.633100
[Epoch 99; Iter     8/  209] train: loss: 0.0167497
[Epoch 99; Iter    38/  209] train: loss: 0.0059626
[Epoch 99; Iter    68/  209] train: loss: 0.0239855
[Epoch 99; Iter    98/  209] train: loss: 0.0155779
[Epoch 82; Iter    51/  209] train: loss: 0.0503024
[Epoch 82; Iter    81/  209] train: loss: 0.0573128
[Epoch 82; Iter   111/  209] train: loss: 0.1034198
[Epoch 82; Iter   141/  209] train: loss: 0.0297356
[Epoch 82; Iter   171/  209] train: loss: 0.0443537
[Epoch 82; Iter   201/  209] train: loss: 0.0439773
[Epoch 82] ogbg-moltox21: 0.749256 val loss: 0.384503
[Epoch 82] ogbg-moltox21: 0.741001 test loss: 0.566694
[Epoch 83; Iter    22/  209] train: loss: 0.0546818
[Epoch 83; Iter    52/  209] train: loss: 0.1311014
[Epoch 83; Iter    82/  209] train: loss: 0.0876979
[Epoch 83; Iter   112/  209] train: loss: 0.0749265
[Epoch 83; Iter   142/  209] train: loss: 0.0616139
[Epoch 83; Iter   172/  209] train: loss: 0.0497577
[Epoch 83; Iter   202/  209] train: loss: 0.0783481
[Epoch 83] ogbg-moltox21: 0.759511 val loss: 0.370176
[Epoch 83] ogbg-moltox21: 0.746680 test loss: 0.575213
[Epoch 84; Iter    23/  209] train: loss: 0.0418398
[Epoch 84; Iter    53/  209] train: loss: 0.0387398
[Epoch 84; Iter    83/  209] train: loss: 0.0555195
[Epoch 84; Iter   113/  209] train: loss: 0.0969960
[Epoch 84; Iter   143/  209] train: loss: 0.0710300
[Epoch 84; Iter   173/  209] train: loss: 0.0614598
[Epoch 84; Iter   203/  209] train: loss: 0.0284930
[Epoch 84] ogbg-moltox21: 0.746609 val loss: 0.370219
[Epoch 84] ogbg-moltox21: 0.734842 test loss: 0.927696
[Epoch 85; Iter    24/  209] train: loss: 0.0390795
[Epoch 85; Iter    54/  209] train: loss: 0.0459301
[Epoch 85; Iter    84/  209] train: loss: 0.0663624
[Epoch 85; Iter   114/  209] train: loss: 0.1297169
[Epoch 85; Iter   144/  209] train: loss: 0.0385164
[Epoch 85; Iter   174/  209] train: loss: 0.0774826
[Epoch 85; Iter   204/  209] train: loss: 0.0698146
[Epoch 85] ogbg-moltox21: 0.754928 val loss: 0.407155
[Epoch 85] ogbg-moltox21: 0.731246 test loss: 0.828902
[Epoch 86; Iter    25/  209] train: loss: 0.0449296
[Epoch 86; Iter    55/  209] train: loss: 0.0501967
[Epoch 86; Iter    85/  209] train: loss: 0.0679248
[Epoch 86; Iter   115/  209] train: loss: 0.0639991
[Epoch 86; Iter   145/  209] train: loss: 0.0264301
[Epoch 86; Iter   175/  209] train: loss: 0.0562549
[Epoch 86; Iter   205/  209] train: loss: 0.1249135
[Epoch 86] ogbg-moltox21: 0.755637 val loss: 0.374829
[Epoch 86] ogbg-moltox21: 0.740167 test loss: 0.688257
[Epoch 87; Iter    26/  209] train: loss: 0.0694947
[Epoch 87; Iter    56/  209] train: loss: 0.0542108
[Epoch 87; Iter    86/  209] train: loss: 0.0428045
[Epoch 87; Iter   116/  209] train: loss: 0.0390899
[Epoch 87; Iter   146/  209] train: loss: 0.0575958
[Epoch 87; Iter   176/  209] train: loss: 0.0615057
[Epoch 87; Iter   206/  209] train: loss: 0.0339022
[Epoch 87] ogbg-moltox21: 0.759530 val loss: 0.399247
[Epoch 87] ogbg-moltox21: 0.740763 test loss: 0.724390
[Epoch 88; Iter    27/  209] train: loss: 0.0760564
[Epoch 88; Iter    57/  209] train: loss: 0.0520736
[Epoch 88; Iter    87/  209] train: loss: 0.0405715
[Epoch 88; Iter   117/  209] train: loss: 0.0691826
[Epoch 88; Iter   147/  209] train: loss: 0.0337282
[Epoch 88; Iter   177/  209] train: loss: 0.0370579
[Epoch 88; Iter   207/  209] train: loss: 0.0446609
[Epoch 88] ogbg-moltox21: 0.741274 val loss: 0.428409
[Epoch 88] ogbg-moltox21: 0.740721 test loss: 0.805643
[Epoch 89; Iter    28/  209] train: loss: 0.0378586
[Epoch 89; Iter    58/  209] train: loss: 0.0861520
[Epoch 89; Iter    88/  209] train: loss: 0.0665271
[Epoch 89; Iter   118/  209] train: loss: 0.0455858
[Epoch 89; Iter   148/  209] train: loss: 0.0518446
[Epoch 89; Iter   178/  209] train: loss: 0.0845812
[Epoch 89; Iter   208/  209] train: loss: 0.0577472
[Epoch 89] ogbg-moltox21: 0.752022 val loss: 0.395259
[Epoch 89] ogbg-moltox21: 0.738435 test loss: 0.677655
[Epoch 90; Iter    29/  209] train: loss: 0.0432941
[Epoch 90; Iter    59/  209] train: loss: 0.0283264
[Epoch 90; Iter    89/  209] train: loss: 0.0488408
[Epoch 90; Iter   119/  209] train: loss: 0.0389582
[Epoch 90; Iter   149/  209] train: loss: 0.0517487
[Epoch 90; Iter   179/  209] train: loss: 0.0348005
[Epoch 90; Iter   209/  209] train: loss: 0.1047071
[Epoch 90] ogbg-moltox21: 0.753715 val loss: 0.391895
[Epoch 90] ogbg-moltox21: 0.740588 test loss: 0.617027
[Epoch 91; Iter    30/  209] train: loss: 0.0436666
[Epoch 91; Iter    60/  209] train: loss: 0.0304058
[Epoch 91; Iter    90/  209] train: loss: 0.0375139
[Epoch 91; Iter   120/  209] train: loss: 0.0597717
[Epoch 91; Iter   150/  209] train: loss: 0.0545155
[Epoch 91; Iter   180/  209] train: loss: 0.0426368
[Epoch 91] ogbg-moltox21: 0.750470 val loss: 0.391954
[Epoch 91] ogbg-moltox21: 0.735456 test loss: 0.682207
[Epoch 92; Iter     1/  209] train: loss: 0.0344396
[Epoch 92; Iter    31/  209] train: loss: 0.0506684
[Epoch 92; Iter    61/  209] train: loss: 0.0431090
[Epoch 92; Iter    91/  209] train: loss: 0.0434587
[Epoch 92; Iter   121/  209] train: loss: 0.0347278
[Epoch 92; Iter   151/  209] train: loss: 0.0177884
[Epoch 92; Iter   181/  209] train: loss: 0.0216431
[Epoch 92] ogbg-moltox21: 0.760838 val loss: 0.407748
[Epoch 92] ogbg-moltox21: 0.750134 test loss: 0.650374
[Epoch 93; Iter     2/  209] train: loss: 0.0581957
[Epoch 93; Iter    32/  209] train: loss: 0.0446596
[Epoch 93; Iter    62/  209] train: loss: 0.0424040
[Epoch 93; Iter    92/  209] train: loss: 0.0511953
[Epoch 93; Iter   122/  209] train: loss: 0.0418321
[Epoch 93; Iter   152/  209] train: loss: 0.0473328
[Epoch 93; Iter   182/  209] train: loss: 0.0265427
[Epoch 93] ogbg-moltox21: 0.747667 val loss: 0.404777
[Epoch 93] ogbg-moltox21: 0.740728 test loss: 0.611093
[Epoch 94; Iter     3/  209] train: loss: 0.0396455
[Epoch 94; Iter    33/  209] train: loss: 0.0486660
[Epoch 94; Iter    63/  209] train: loss: 0.0258379
[Epoch 94; Iter    93/  209] train: loss: 0.0686211
[Epoch 94; Iter   123/  209] train: loss: 0.0499427
[Epoch 94; Iter   153/  209] train: loss: 0.0350747
[Epoch 94; Iter   183/  209] train: loss: 0.0516574
[Epoch 94] ogbg-moltox21: 0.750760 val loss: 0.409118
[Epoch 94] ogbg-moltox21: 0.741857 test loss: 0.661118
[Epoch 95; Iter     4/  209] train: loss: 0.0516057
[Epoch 95; Iter    34/  209] train: loss: 0.0760453
[Epoch 95; Iter    64/  209] train: loss: 0.0313417
[Epoch 95; Iter    94/  209] train: loss: 0.0427763
[Epoch 95; Iter   124/  209] train: loss: 0.0643631
[Epoch 95; Iter   154/  209] train: loss: 0.0604555
[Epoch 95; Iter   184/  209] train: loss: 0.0463565
[Epoch 95] ogbg-moltox21: 0.755048 val loss: 0.413428
[Epoch 95] ogbg-moltox21: 0.742909 test loss: 0.604091
[Epoch 96; Iter     5/  209] train: loss: 0.0855747
[Epoch 96; Iter    35/  209] train: loss: 0.0371866
[Epoch 96; Iter    65/  209] train: loss: 0.0459499
[Epoch 96; Iter    95/  209] train: loss: 0.0390229
[Epoch 96; Iter   125/  209] train: loss: 0.0181355
[Epoch 96; Iter   155/  209] train: loss: 0.0398745
[Epoch 96; Iter   185/  209] train: loss: 0.0365661
[Epoch 96] ogbg-moltox21: 0.756964 val loss: 0.419182
[Epoch 96] ogbg-moltox21: 0.745241 test loss: 0.542911
[Epoch 97; Iter     6/  209] train: loss: 0.0359476
[Epoch 97; Iter    36/  209] train: loss: 0.0326082
[Epoch 97; Iter    66/  209] train: loss: 0.0527954
[Epoch 97; Iter    96/  209] train: loss: 0.0481736
[Epoch 97; Iter   126/  209] train: loss: 0.0618888
[Epoch 97; Iter   156/  209] train: loss: 0.0374569
[Epoch 97; Iter   186/  209] train: loss: 0.0305315
[Epoch 97] ogbg-moltox21: 0.752961 val loss: 0.412558
[Epoch 97] ogbg-moltox21: 0.743160 test loss: 0.666970
[Epoch 98; Iter     7/  209] train: loss: 0.0333917
[Epoch 98; Iter    37/  209] train: loss: 0.0261766
[Epoch 98; Iter    67/  209] train: loss: 0.0364882
[Epoch 98; Iter    97/  209] train: loss: 0.0525312
[Epoch 98; Iter   127/  209] train: loss: 0.0698481
[Epoch 98; Iter   157/  209] train: loss: 0.0550055
[Epoch 98; Iter   187/  209] train: loss: 0.0295071
[Epoch 98] ogbg-moltox21: 0.748493 val loss: 0.419118
[Epoch 98] ogbg-moltox21: 0.738759 test loss: 0.627484
[Epoch 99; Iter     8/  209] train: loss: 0.0817077
[Epoch 99; Iter    38/  209] train: loss: 0.0644454
[Epoch 99; Iter    68/  209] train: loss: 0.0955780
[Epoch 99; Iter    98/  209] train: loss: 0.0736521
[Epoch 82; Iter    51/  209] train: loss: 0.0297997
[Epoch 82; Iter    81/  209] train: loss: 0.0251867
[Epoch 82; Iter   111/  209] train: loss: 0.0263882
[Epoch 82; Iter   141/  209] train: loss: 0.0420316
[Epoch 82; Iter   171/  209] train: loss: 0.0277563
[Epoch 82; Iter   201/  209] train: loss: 0.0824990
[Epoch 82] ogbg-moltox21: 0.737194 val loss: 0.597659
[Epoch 82] ogbg-moltox21: 0.706296 test loss: 0.702388
[Epoch 83; Iter    22/  209] train: loss: 0.0103463
[Epoch 83; Iter    52/  209] train: loss: 0.0362030
[Epoch 83; Iter    82/  209] train: loss: 0.0242642
[Epoch 83; Iter   112/  209] train: loss: 0.0570053
[Epoch 83; Iter   142/  209] train: loss: 0.0475190
[Epoch 83; Iter   172/  209] train: loss: 0.0536798
[Epoch 83; Iter   202/  209] train: loss: 0.0321284
[Epoch 83] ogbg-moltox21: 0.754627 val loss: 0.567393
[Epoch 83] ogbg-moltox21: 0.706498 test loss: 0.646196
[Epoch 84; Iter    23/  209] train: loss: 0.0256304
[Epoch 84; Iter    53/  209] train: loss: 0.0199916
[Epoch 84; Iter    83/  209] train: loss: 0.0279606
[Epoch 84; Iter   113/  209] train: loss: 0.0283517
[Epoch 84; Iter   143/  209] train: loss: 0.0290347
[Epoch 84; Iter   173/  209] train: loss: 0.0080443
[Epoch 84; Iter   203/  209] train: loss: 0.0308387
[Epoch 84] ogbg-moltox21: 0.741471 val loss: 0.600306
[Epoch 84] ogbg-moltox21: 0.698789 test loss: 0.707148
[Epoch 85; Iter    24/  209] train: loss: 0.0260205
[Epoch 85; Iter    54/  209] train: loss: 0.1125837
[Epoch 85; Iter    84/  209] train: loss: 0.0181353
[Epoch 85; Iter   114/  209] train: loss: 0.0183129
[Epoch 85; Iter   144/  209] train: loss: 0.0136377
[Epoch 85; Iter   174/  209] train: loss: 0.0424591
[Epoch 85; Iter   204/  209] train: loss: 0.0122321
[Epoch 85] ogbg-moltox21: 0.751792 val loss: 0.593980
[Epoch 85] ogbg-moltox21: 0.699128 test loss: 0.725039
[Epoch 86; Iter    25/  209] train: loss: 0.0218804
[Epoch 86; Iter    55/  209] train: loss: 0.0158139
[Epoch 86; Iter    85/  209] train: loss: 0.0146837
[Epoch 86; Iter   115/  209] train: loss: 0.0199915
[Epoch 86; Iter   145/  209] train: loss: 0.0190745
[Epoch 86; Iter   175/  209] train: loss: 0.0111196
[Epoch 86; Iter   205/  209] train: loss: 0.0264907
[Epoch 86] ogbg-moltox21: 0.741072 val loss: 0.571712
[Epoch 86] ogbg-moltox21: 0.697605 test loss: 0.652359
[Epoch 87; Iter    26/  209] train: loss: 0.0109133
[Epoch 87; Iter    56/  209] train: loss: 0.0246332
[Epoch 87; Iter    86/  209] train: loss: 0.0258876
[Epoch 87; Iter   116/  209] train: loss: 0.0251360
[Epoch 87; Iter   146/  209] train: loss: 0.0157594
[Epoch 87; Iter   176/  209] train: loss: 0.0373676
[Epoch 87; Iter   206/  209] train: loss: 0.0260571
[Epoch 87] ogbg-moltox21: 0.754452 val loss: 0.541916
[Epoch 87] ogbg-moltox21: 0.705375 test loss: 0.629240
[Epoch 88; Iter    27/  209] train: loss: 0.0208337
[Epoch 88; Iter    57/  209] train: loss: 0.0249077
[Epoch 88; Iter    87/  209] train: loss: 0.0295093
[Epoch 88; Iter   117/  209] train: loss: 0.0153932
[Epoch 88; Iter   147/  209] train: loss: 0.0304443
[Epoch 88; Iter   177/  209] train: loss: 0.0353235
[Epoch 88; Iter   207/  209] train: loss: 0.0367163
[Epoch 88] ogbg-moltox21: 0.747546 val loss: 0.601720
[Epoch 88] ogbg-moltox21: 0.714110 test loss: 0.673148
[Epoch 89; Iter    28/  209] train: loss: 0.0246154
[Epoch 89; Iter    58/  209] train: loss: 0.0165873
[Epoch 89; Iter    88/  209] train: loss: 0.0047212
[Epoch 89; Iter   118/  209] train: loss: 0.0287832
[Epoch 89; Iter   148/  209] train: loss: 0.0421355
[Epoch 89; Iter   178/  209] train: loss: 0.0387693
[Epoch 89; Iter   208/  209] train: loss: 0.0185444
[Epoch 89] ogbg-moltox21: 0.755281 val loss: 0.597945
[Epoch 89] ogbg-moltox21: 0.714904 test loss: 0.672660
[Epoch 90; Iter    29/  209] train: loss: 0.0137310
[Epoch 90; Iter    59/  209] train: loss: 0.0118298
[Epoch 90; Iter    89/  209] train: loss: 0.0132562
[Epoch 90; Iter   119/  209] train: loss: 0.0162965
[Epoch 90; Iter   149/  209] train: loss: 0.0094706
[Epoch 90; Iter   179/  209] train: loss: 0.0324842
[Epoch 90; Iter   209/  209] train: loss: 0.0193166
[Epoch 90] ogbg-moltox21: 0.748882 val loss: 0.631182
[Epoch 90] ogbg-moltox21: 0.711609 test loss: 0.709116
[Epoch 91; Iter    30/  209] train: loss: 0.0311746
[Epoch 91; Iter    60/  209] train: loss: 0.0165293
[Epoch 91; Iter    90/  209] train: loss: 0.0697285
[Epoch 91; Iter   120/  209] train: loss: 0.0369172
[Epoch 91; Iter   150/  209] train: loss: 0.0227006
[Epoch 91; Iter   180/  209] train: loss: 0.0530309
[Epoch 91] ogbg-moltox21: 0.749729 val loss: 0.623367
[Epoch 91] ogbg-moltox21: 0.708270 test loss: 0.721652
[Epoch 92; Iter     1/  209] train: loss: 0.0246481
[Epoch 92; Iter    31/  209] train: loss: 0.0138745
[Epoch 92; Iter    61/  209] train: loss: 0.0243443
[Epoch 92; Iter    91/  209] train: loss: 0.0276122
[Epoch 92; Iter   121/  209] train: loss: 0.0089610
[Epoch 92; Iter   151/  209] train: loss: 0.0179789
[Epoch 92; Iter   181/  209] train: loss: 0.0161200
[Epoch 92] ogbg-moltox21: 0.747902 val loss: 0.586298
[Epoch 92] ogbg-moltox21: 0.699261 test loss: 0.678381
[Epoch 93; Iter     2/  209] train: loss: 0.0273251
[Epoch 93; Iter    32/  209] train: loss: 0.0377447
[Epoch 93; Iter    62/  209] train: loss: 0.0105827
[Epoch 93; Iter    92/  209] train: loss: 0.0209022
[Epoch 93; Iter   122/  209] train: loss: 0.0281581
[Epoch 93; Iter   152/  209] train: loss: 0.0326578
[Epoch 93; Iter   182/  209] train: loss: 0.0129848
[Epoch 93] ogbg-moltox21: 0.734906 val loss: 0.631918
[Epoch 93] ogbg-moltox21: 0.704840 test loss: 0.723013
[Epoch 94; Iter     3/  209] train: loss: 0.0239187
[Epoch 94; Iter    33/  209] train: loss: 0.0077987
[Epoch 94; Iter    63/  209] train: loss: 0.0121008
[Epoch 94; Iter    93/  209] train: loss: 0.0253957
[Epoch 94; Iter   123/  209] train: loss: 0.0344002
[Epoch 94; Iter   153/  209] train: loss: 0.0371812
[Epoch 94; Iter   183/  209] train: loss: 0.0419560
[Epoch 94] ogbg-moltox21: 0.747815 val loss: 0.604590
[Epoch 94] ogbg-moltox21: 0.711854 test loss: 0.713818
[Epoch 95; Iter     4/  209] train: loss: 0.0360423
[Epoch 95; Iter    34/  209] train: loss: 0.0095022
[Epoch 95; Iter    64/  209] train: loss: 0.0133662
[Epoch 95; Iter    94/  209] train: loss: 0.0067250
[Epoch 95; Iter   124/  209] train: loss: 0.0313976
[Epoch 95; Iter   154/  209] train: loss: 0.0091484
[Epoch 95; Iter   184/  209] train: loss: 0.0324065
[Epoch 95] ogbg-moltox21: 0.758391 val loss: 0.593367
[Epoch 95] ogbg-moltox21: 0.704930 test loss: 0.740865
[Epoch 96; Iter     5/  209] train: loss: 0.0147987
[Epoch 96; Iter    35/  209] train: loss: 0.0130194
[Epoch 96; Iter    65/  209] train: loss: 0.0208390
[Epoch 96; Iter    95/  209] train: loss: 0.0234480
[Epoch 96; Iter   125/  209] train: loss: 0.0164923
[Epoch 96; Iter   155/  209] train: loss: 0.0393503
[Epoch 96; Iter   185/  209] train: loss: 0.0176863
[Epoch 96] ogbg-moltox21: 0.761050 val loss: 0.582696
[Epoch 96] ogbg-moltox21: 0.719965 test loss: 0.764037
[Epoch 97; Iter     6/  209] train: loss: 0.0334766
[Epoch 97; Iter    36/  209] train: loss: 0.0113406
[Epoch 97; Iter    66/  209] train: loss: 0.0358966
[Epoch 97; Iter    96/  209] train: loss: 0.0168139
[Epoch 97; Iter   126/  209] train: loss: 0.0273816
[Epoch 97; Iter   156/  209] train: loss: 0.0592262
[Epoch 97; Iter   186/  209] train: loss: 0.0149056
[Epoch 97] ogbg-moltox21: 0.762729 val loss: 0.601406
[Epoch 97] ogbg-moltox21: 0.721228 test loss: 0.701036
[Epoch 98; Iter     7/  209] train: loss: 0.0181927
[Epoch 98; Iter    37/  209] train: loss: 0.0165837
[Epoch 98; Iter    67/  209] train: loss: 0.0080680
[Epoch 98; Iter    97/  209] train: loss: 0.0375824
[Epoch 98; Iter   127/  209] train: loss: 0.0176680
[Epoch 98; Iter   157/  209] train: loss: 0.0170387
[Epoch 98; Iter   187/  209] train: loss: 0.0065503
[Epoch 98] ogbg-moltox21: 0.744232 val loss: 0.668250
[Epoch 98] ogbg-moltox21: 0.707801 test loss: 0.786459
[Epoch 99; Iter     8/  209] train: loss: 0.0175700
[Epoch 99; Iter    38/  209] train: loss: 0.0049199
[Epoch 99; Iter    68/  209] train: loss: 0.0536231
[Epoch 99; Iter    98/  209] train: loss: 0.0070723
[Epoch 82; Iter    51/  209] train: loss: 0.0074102
[Epoch 82; Iter    81/  209] train: loss: 0.0287064
[Epoch 82; Iter   111/  209] train: loss: 0.0143195
[Epoch 82; Iter   141/  209] train: loss: 0.0201663
[Epoch 82; Iter   171/  209] train: loss: 0.0149466
[Epoch 82; Iter   201/  209] train: loss: 0.0067899
[Epoch 82] ogbg-moltox21: 0.724169 val loss: 0.895102
[Epoch 82] ogbg-moltox21: 0.684567 test loss: 1.019365
[Epoch 83; Iter    22/  209] train: loss: 0.0601265
[Epoch 83; Iter    52/  209] train: loss: 0.0288527
[Epoch 83; Iter    82/  209] train: loss: 0.0073972
[Epoch 83; Iter   112/  209] train: loss: 0.0280013
[Epoch 83; Iter   142/  209] train: loss: 0.0159835
[Epoch 83; Iter   172/  209] train: loss: 0.0068980
[Epoch 83; Iter   202/  209] train: loss: 0.0262992
[Epoch 83] ogbg-moltox21: 0.714065 val loss: 0.928940
[Epoch 83] ogbg-moltox21: 0.682409 test loss: 1.005124
[Epoch 84; Iter    23/  209] train: loss: 0.0093355
[Epoch 84; Iter    53/  209] train: loss: 0.0109602
[Epoch 84; Iter    83/  209] train: loss: 0.0063246
[Epoch 84; Iter   113/  209] train: loss: 0.0057600
[Epoch 84; Iter   143/  209] train: loss: 0.0040016
[Epoch 84; Iter   173/  209] train: loss: 0.0100728
[Epoch 84; Iter   203/  209] train: loss: 0.0328282
[Epoch 84] ogbg-moltox21: 0.718124 val loss: 0.872059
[Epoch 84] ogbg-moltox21: 0.668731 test loss: 0.941879
[Epoch 85; Iter    24/  209] train: loss: 0.0099377
[Epoch 85; Iter    54/  209] train: loss: 0.0203535
[Epoch 85; Iter    84/  209] train: loss: 0.0044837
[Epoch 85; Iter   114/  209] train: loss: 0.0264296
[Epoch 85; Iter   144/  209] train: loss: 0.0305171
[Epoch 85; Iter   174/  209] train: loss: 0.0085121
[Epoch 85; Iter   204/  209] train: loss: 0.0113051
[Epoch 85] ogbg-moltox21: 0.710403 val loss: 0.918442
[Epoch 85] ogbg-moltox21: 0.671962 test loss: 0.950583
[Epoch 86; Iter    25/  209] train: loss: 0.0072012
[Epoch 86; Iter    55/  209] train: loss: 0.0055836
[Epoch 86; Iter    85/  209] train: loss: 0.0101950
[Epoch 86; Iter   115/  209] train: loss: 0.0081966
[Epoch 86; Iter   145/  209] train: loss: 0.0087865
[Epoch 86; Iter   175/  209] train: loss: 0.0097709
[Epoch 86; Iter   205/  209] train: loss: 0.0090410
[Epoch 86] ogbg-moltox21: 0.717088 val loss: 0.984744
[Epoch 86] ogbg-moltox21: 0.672386 test loss: 1.077098
[Epoch 87; Iter    26/  209] train: loss: 0.0042873
[Epoch 87; Iter    56/  209] train: loss: 0.0058577
[Epoch 87; Iter    86/  209] train: loss: 0.0047059
[Epoch 87; Iter   116/  209] train: loss: 0.0077539
[Epoch 87; Iter   146/  209] train: loss: 0.0307956
[Epoch 87; Iter   176/  209] train: loss: 0.0043049
[Epoch 87; Iter   206/  209] train: loss: 0.0468891
[Epoch 87] ogbg-moltox21: 0.722657 val loss: 0.928387
[Epoch 87] ogbg-moltox21: 0.685081 test loss: 0.994959
[Epoch 88; Iter    27/  209] train: loss: 0.0095371
[Epoch 88; Iter    57/  209] train: loss: 0.0076552
[Epoch 88; Iter    87/  209] train: loss: 0.0180377
[Epoch 88; Iter   117/  209] train: loss: 0.0089770
[Epoch 88; Iter   147/  209] train: loss: 0.0044047
[Epoch 88; Iter   177/  209] train: loss: 0.0127514
[Epoch 88; Iter   207/  209] train: loss: 0.0106662
[Epoch 88] ogbg-moltox21: 0.716906 val loss: 1.028044
[Epoch 88] ogbg-moltox21: 0.681496 test loss: 1.185813
[Epoch 89; Iter    28/  209] train: loss: 0.0026649
[Epoch 89; Iter    58/  209] train: loss: 0.0053450
[Epoch 89; Iter    88/  209] train: loss: 0.0097394
[Epoch 89; Iter   118/  209] train: loss: 0.0089310
[Epoch 89; Iter   148/  209] train: loss: 0.0203205
[Epoch 89; Iter   178/  209] train: loss: 0.0099238
[Epoch 89; Iter   208/  209] train: loss: 0.0107327
[Epoch 89] ogbg-moltox21: 0.712558 val loss: 0.959458
[Epoch 89] ogbg-moltox21: 0.676347 test loss: 1.095328
[Epoch 90; Iter    29/  209] train: loss: 0.0054564
[Epoch 90; Iter    59/  209] train: loss: 0.0065149
[Epoch 90; Iter    89/  209] train: loss: 0.0185018
[Epoch 90; Iter   119/  209] train: loss: 0.0492607
[Epoch 90; Iter   149/  209] train: loss: 0.0051501
[Epoch 90; Iter   179/  209] train: loss: 0.0120314
[Epoch 90; Iter   209/  209] train: loss: 0.0099024
[Epoch 90] ogbg-moltox21: 0.711409 val loss: 1.155608
[Epoch 90] ogbg-moltox21: 0.681989 test loss: 1.104181
[Epoch 91; Iter    30/  209] train: loss: 0.0178987
[Epoch 91; Iter    60/  209] train: loss: 0.0116963
[Epoch 91; Iter    90/  209] train: loss: 0.0100739
[Epoch 91; Iter   120/  209] train: loss: 0.0108015
[Epoch 91; Iter   150/  209] train: loss: 0.0055813
[Epoch 91; Iter   180/  209] train: loss: 0.0051390
[Epoch 91] ogbg-moltox21: 0.718215 val loss: 1.035160
[Epoch 91] ogbg-moltox21: 0.680946 test loss: 1.169649
[Epoch 92; Iter     1/  209] train: loss: 0.0045598
[Epoch 92; Iter    31/  209] train: loss: 0.0033958
[Epoch 92; Iter    61/  209] train: loss: 0.0052208
[Epoch 92; Iter    91/  209] train: loss: 0.0071723
[Epoch 92; Iter   121/  209] train: loss: 0.0022267
[Epoch 92; Iter   151/  209] train: loss: 0.0028418
[Epoch 92; Iter   181/  209] train: loss: 0.0030120
[Epoch 92] ogbg-moltox21: 0.719303 val loss: 1.008187
[Epoch 92] ogbg-moltox21: 0.680981 test loss: 1.120969
[Epoch 93; Iter     2/  209] train: loss: 0.0025634
[Epoch 93; Iter    32/  209] train: loss: 0.0125219
[Epoch 93; Iter    62/  209] train: loss: 0.0033571
[Epoch 93; Iter    92/  209] train: loss: 0.0031676
[Epoch 93; Iter   122/  209] train: loss: 0.0078884
[Epoch 93; Iter   152/  209] train: loss: 0.0011966
[Epoch 93; Iter   182/  209] train: loss: 0.0044012
[Epoch 93] ogbg-moltox21: 0.718853 val loss: 1.004551
[Epoch 93] ogbg-moltox21: 0.677055 test loss: 1.125911
[Epoch 94; Iter     3/  209] train: loss: 0.0025277
[Epoch 94; Iter    33/  209] train: loss: 0.0025796
[Epoch 94; Iter    63/  209] train: loss: 0.0032660
[Epoch 94; Iter    93/  209] train: loss: 0.0014913
[Epoch 94; Iter   123/  209] train: loss: 0.0032529
[Epoch 94; Iter   153/  209] train: loss: 0.0023337
[Epoch 94; Iter   183/  209] train: loss: 0.0055979
[Epoch 94] ogbg-moltox21: 0.723302 val loss: 0.987187
[Epoch 94] ogbg-moltox21: 0.688076 test loss: 1.123755
[Epoch 95; Iter     4/  209] train: loss: 0.0059899
[Epoch 95; Iter    34/  209] train: loss: 0.0023401
[Epoch 95; Iter    64/  209] train: loss: 0.0036514
[Epoch 95; Iter    94/  209] train: loss: 0.0054283
[Epoch 95; Iter   124/  209] train: loss: 0.0016302
[Epoch 95; Iter   154/  209] train: loss: 0.0068071
[Epoch 95; Iter   184/  209] train: loss: 0.0083881
[Epoch 95] ogbg-moltox21: 0.720490 val loss: 1.032360
[Epoch 95] ogbg-moltox21: 0.679956 test loss: 1.181626
[Epoch 96; Iter     5/  209] train: loss: 0.0062306
[Epoch 96; Iter    35/  209] train: loss: 0.0043232
[Epoch 96; Iter    65/  209] train: loss: 0.0094890
[Epoch 96; Iter    95/  209] train: loss: 0.0018022
[Epoch 96; Iter   125/  209] train: loss: 0.0015455
[Epoch 96; Iter   155/  209] train: loss: 0.0050309
[Epoch 96; Iter   185/  209] train: loss: 0.0089377
[Epoch 96] ogbg-moltox21: 0.719937 val loss: 1.060584
[Epoch 96] ogbg-moltox21: 0.688186 test loss: 1.208426
[Epoch 97; Iter     6/  209] train: loss: 0.0042279
[Epoch 97; Iter    36/  209] train: loss: 0.0061156
[Epoch 97; Iter    66/  209] train: loss: 0.0020214
[Epoch 97; Iter    96/  209] train: loss: 0.0034167
[Epoch 97; Iter   126/  209] train: loss: 0.0037325
[Epoch 97; Iter   156/  209] train: loss: 0.0051890
[Epoch 97; Iter   186/  209] train: loss: 0.0089335
[Epoch 97] ogbg-moltox21: 0.720571 val loss: 1.064087
[Epoch 97] ogbg-moltox21: 0.682623 test loss: 1.203429
[Epoch 98; Iter     7/  209] train: loss: 0.0158298
[Epoch 98; Iter    37/  209] train: loss: 0.0053572
[Epoch 98; Iter    67/  209] train: loss: 0.0062108
[Epoch 98; Iter    97/  209] train: loss: 0.0036175
[Epoch 98; Iter   127/  209] train: loss: 0.0087392
[Epoch 98; Iter   157/  209] train: loss: 0.0067221
[Epoch 98; Iter   187/  209] train: loss: 0.0054353
[Epoch 98] ogbg-moltox21: 0.711743 val loss: 1.007832
[Epoch 98] ogbg-moltox21: 0.674200 test loss: 1.088379
[Epoch 99; Iter     8/  209] train: loss: 0.0053559
[Epoch 99; Iter    38/  209] train: loss: 0.0016207
[Epoch 99; Iter    68/  209] train: loss: 0.0037611
[Epoch 99; Iter    98/  209] train: loss: 0.0020125
[Epoch 82; Iter    51/  209] train: loss: 0.0262111
[Epoch 82; Iter    81/  209] train: loss: 0.0231017
[Epoch 82; Iter   111/  209] train: loss: 0.0661978
[Epoch 82; Iter   141/  209] train: loss: 0.0191407
[Epoch 82; Iter   171/  209] train: loss: 0.0188647
[Epoch 82; Iter   201/  209] train: loss: 0.0197188
[Epoch 82] ogbg-moltox21: 0.692614 val loss: 0.612985
[Epoch 82] ogbg-moltox21: 0.692162 test loss: 0.628243
[Epoch 83; Iter    22/  209] train: loss: 0.0193354
[Epoch 83; Iter    52/  209] train: loss: 0.0402483
[Epoch 83; Iter    82/  209] train: loss: 0.0355293
[Epoch 83; Iter   112/  209] train: loss: 0.0280120
[Epoch 83; Iter   142/  209] train: loss: 0.0117947
[Epoch 83; Iter   172/  209] train: loss: 0.0195127
[Epoch 83; Iter   202/  209] train: loss: 0.0284890
[Epoch 83] ogbg-moltox21: 0.701169 val loss: 0.585861
[Epoch 83] ogbg-moltox21: 0.701486 test loss: 0.601566
[Epoch 84; Iter    23/  209] train: loss: 0.0137577
[Epoch 84; Iter    53/  209] train: loss: 0.0353800
[Epoch 84; Iter    83/  209] train: loss: 0.0200060
[Epoch 84; Iter   113/  209] train: loss: 0.0359484
[Epoch 84; Iter   143/  209] train: loss: 0.0137951
[Epoch 84; Iter   173/  209] train: loss: 0.0224446
[Epoch 84; Iter   203/  209] train: loss: 0.0137176
[Epoch 84] ogbg-moltox21: 0.695987 val loss: 0.621202
[Epoch 84] ogbg-moltox21: 0.695937 test loss: 0.632561
[Epoch 85; Iter    24/  209] train: loss: 0.0198418
[Epoch 85; Iter    54/  209] train: loss: 0.0233641
[Epoch 85; Iter    84/  209] train: loss: 0.0121925
[Epoch 85; Iter   114/  209] train: loss: 0.0613687
[Epoch 85; Iter   144/  209] train: loss: 0.0235315
[Epoch 85; Iter   174/  209] train: loss: 0.0441329
[Epoch 85; Iter   204/  209] train: loss: 0.0152854
[Epoch 85] ogbg-moltox21: 0.689842 val loss: 0.645347
[Epoch 85] ogbg-moltox21: 0.690857 test loss: 0.652385
[Epoch 86; Iter    25/  209] train: loss: 0.0241166
[Epoch 86; Iter    55/  209] train: loss: 0.0147096
[Epoch 86; Iter    85/  209] train: loss: 0.0244150
[Epoch 86; Iter   115/  209] train: loss: 0.0325290
[Epoch 86; Iter   145/  209] train: loss: 0.0108309
[Epoch 86; Iter   175/  209] train: loss: 0.0202917
[Epoch 86; Iter   205/  209] train: loss: 0.0526725
[Epoch 86] ogbg-moltox21: 0.691693 val loss: 0.608841
[Epoch 86] ogbg-moltox21: 0.697732 test loss: 0.615565
[Epoch 87; Iter    26/  209] train: loss: 0.0131530
[Epoch 87; Iter    56/  209] train: loss: 0.0127054
[Epoch 87; Iter    86/  209] train: loss: 0.0165156
[Epoch 87; Iter   116/  209] train: loss: 0.0112991
[Epoch 87; Iter   146/  209] train: loss: 0.0134360
[Epoch 87; Iter   176/  209] train: loss: 0.0294967
[Epoch 87; Iter   206/  209] train: loss: 0.0266001
[Epoch 87] ogbg-moltox21: 0.687092 val loss: 0.629869
[Epoch 87] ogbg-moltox21: 0.691409 test loss: 0.637649
[Epoch 88; Iter    27/  209] train: loss: 0.0228493
[Epoch 88; Iter    57/  209] train: loss: 0.0300571
[Epoch 88; Iter    87/  209] train: loss: 0.0159132
[Epoch 88; Iter   117/  209] train: loss: 0.0293299
[Epoch 88; Iter   147/  209] train: loss: 0.0073756
[Epoch 88; Iter   177/  209] train: loss: 0.0184606
[Epoch 88; Iter   207/  209] train: loss: 0.0171142
[Epoch 88] ogbg-moltox21: 0.689543 val loss: 0.626744
[Epoch 88] ogbg-moltox21: 0.695038 test loss: 0.637279
[Epoch 89; Iter    28/  209] train: loss: 0.0096369
[Epoch 89; Iter    58/  209] train: loss: 0.0236999
[Epoch 89; Iter    88/  209] train: loss: 0.0094491
[Epoch 89; Iter   118/  209] train: loss: 0.0106994
[Epoch 89; Iter   148/  209] train: loss: 0.0193555
[Epoch 89; Iter   178/  209] train: loss: 0.0275448
[Epoch 89; Iter   208/  209] train: loss: 0.0136766
[Epoch 89] ogbg-moltox21: 0.693410 val loss: 0.623881
[Epoch 89] ogbg-moltox21: 0.700172 test loss: 0.636302
[Epoch 90; Iter    29/  209] train: loss: 0.0188654
[Epoch 90; Iter    59/  209] train: loss: 0.0112613
[Epoch 90; Iter    89/  209] train: loss: 0.0070507
[Epoch 90; Iter   119/  209] train: loss: 0.0050596
[Epoch 90; Iter   149/  209] train: loss: 0.0132164
[Epoch 90; Iter   179/  209] train: loss: 0.0051998
[Epoch 90; Iter   209/  209] train: loss: 0.0528242
[Epoch 90] ogbg-moltox21: 0.697592 val loss: 0.620778
[Epoch 90] ogbg-moltox21: 0.702204 test loss: 0.638138
[Epoch 91; Iter    30/  209] train: loss: 0.0109060
[Epoch 91; Iter    60/  209] train: loss: 0.0108933
[Epoch 91; Iter    90/  209] train: loss: 0.0082101
[Epoch 91; Iter   120/  209] train: loss: 0.0183509
[Epoch 91; Iter   150/  209] train: loss: 0.0162812
[Epoch 91; Iter   180/  209] train: loss: 0.0062694
[Epoch 91] ogbg-moltox21: 0.691910 val loss: 0.628859
[Epoch 91] ogbg-moltox21: 0.694617 test loss: 0.651871
[Epoch 92; Iter     1/  209] train: loss: 0.0143262
[Epoch 92; Iter    31/  209] train: loss: 0.0098485
[Epoch 92; Iter    61/  209] train: loss: 0.0109232
[Epoch 92; Iter    91/  209] train: loss: 0.0100917
[Epoch 92; Iter   121/  209] train: loss: 0.0070375
[Epoch 92; Iter   151/  209] train: loss: 0.0060451
[Epoch 92; Iter   181/  209] train: loss: 0.0075625
[Epoch 92] ogbg-moltox21: 0.692972 val loss: 0.614295
[Epoch 92] ogbg-moltox21: 0.696105 test loss: 0.628400
[Epoch 93; Iter     2/  209] train: loss: 0.0196397
[Epoch 93; Iter    32/  209] train: loss: 0.0076699
[Epoch 93; Iter    62/  209] train: loss: 0.0167994
[Epoch 93; Iter    92/  209] train: loss: 0.0180748
[Epoch 93; Iter   122/  209] train: loss: 0.0103786
[Epoch 93; Iter   152/  209] train: loss: 0.0179454
[Epoch 93; Iter   182/  209] train: loss: 0.0085386
[Epoch 93] ogbg-moltox21: 0.693548 val loss: 0.624178
[Epoch 93] ogbg-moltox21: 0.689420 test loss: 0.644120
[Epoch 94; Iter     3/  209] train: loss: 0.0212434
[Epoch 94; Iter    33/  209] train: loss: 0.0111565
[Epoch 94; Iter    63/  209] train: loss: 0.0163638
[Epoch 94; Iter    93/  209] train: loss: 0.0118261
[Epoch 94; Iter   123/  209] train: loss: 0.0194767
[Epoch 94; Iter   153/  209] train: loss: 0.0103253
[Epoch 94; Iter   183/  209] train: loss: 0.0133998
[Epoch 94] ogbg-moltox21: 0.691844 val loss: 0.655790
[Epoch 94] ogbg-moltox21: 0.691905 test loss: 0.670801
[Epoch 95; Iter     4/  209] train: loss: 0.0078292
[Epoch 95; Iter    34/  209] train: loss: 0.0205272
[Epoch 95; Iter    64/  209] train: loss: 0.0105864
[Epoch 95; Iter    94/  209] train: loss: 0.0129094
[Epoch 95; Iter   124/  209] train: loss: 0.0088615
[Epoch 95; Iter   154/  209] train: loss: 0.0190556
[Epoch 95; Iter   184/  209] train: loss: 0.0128401
[Epoch 95] ogbg-moltox21: 0.696204 val loss: 0.645010
[Epoch 95] ogbg-moltox21: 0.697427 test loss: 0.661978
[Epoch 96; Iter     5/  209] train: loss: 0.0278989
[Epoch 96; Iter    35/  209] train: loss: 0.0090191
[Epoch 96; Iter    65/  209] train: loss: 0.0144556
[Epoch 96; Iter    95/  209] train: loss: 0.0086774
[Epoch 96; Iter   125/  209] train: loss: 0.0057149
[Epoch 96; Iter   155/  209] train: loss: 0.0068977
[Epoch 96; Iter   185/  209] train: loss: 0.0093647
[Epoch 96] ogbg-moltox21: 0.699263 val loss: 0.655268
[Epoch 96] ogbg-moltox21: 0.701259 test loss: 0.669786
[Epoch 97; Iter     6/  209] train: loss: 0.0068332
[Epoch 97; Iter    36/  209] train: loss: 0.0067620
[Epoch 97; Iter    66/  209] train: loss: 0.0077847
[Epoch 97; Iter    96/  209] train: loss: 0.0073138
[Epoch 97; Iter   126/  209] train: loss: 0.0301035
[Epoch 97; Iter   156/  209] train: loss: 0.0159924
[Epoch 97; Iter   186/  209] train: loss: 0.0059090
[Epoch 97] ogbg-moltox21: 0.694236 val loss: 0.640641
[Epoch 97] ogbg-moltox21: 0.694585 test loss: 0.657370
[Epoch 98; Iter     7/  209] train: loss: 0.0124764
[Epoch 98; Iter    37/  209] train: loss: 0.0077983
[Epoch 98; Iter    67/  209] train: loss: 0.0091211
[Epoch 98; Iter    97/  209] train: loss: 0.0196929
[Epoch 98; Iter   127/  209] train: loss: 0.0315168
[Epoch 98; Iter   157/  209] train: loss: 0.0108940
[Epoch 98; Iter   187/  209] train: loss: 0.0116574
[Epoch 98] ogbg-moltox21: 0.692084 val loss: 0.657194
[Epoch 98] ogbg-moltox21: 0.694922 test loss: 0.677710
[Epoch 99; Iter     8/  209] train: loss: 0.0182704
[Epoch 99; Iter    38/  209] train: loss: 0.0179617
[Epoch 99; Iter    68/  209] train: loss: 0.0158872
[Epoch 99; Iter    98/  209] train: loss: 0.0342035
[Epoch 82; Iter    51/  209] train: loss: 0.0179877
[Epoch 82; Iter    81/  209] train: loss: 0.0141438
[Epoch 82; Iter   111/  209] train: loss: 0.0209078
[Epoch 82; Iter   141/  209] train: loss: 0.0295578
[Epoch 82; Iter   171/  209] train: loss: 0.0079501
[Epoch 82; Iter   201/  209] train: loss: 0.0099696
[Epoch 82] ogbg-moltox21: 0.757921 val loss: 0.562718
[Epoch 82] ogbg-moltox21: 0.695913 test loss: 0.640444
[Epoch 83; Iter    22/  209] train: loss: 0.0273299
[Epoch 83; Iter    52/  209] train: loss: 0.0515109
[Epoch 83; Iter    82/  209] train: loss: 0.0163779
[Epoch 83; Iter   112/  209] train: loss: 0.0295847
[Epoch 83; Iter   142/  209] train: loss: 0.0309525
[Epoch 83; Iter   172/  209] train: loss: 0.0071765
[Epoch 83; Iter   202/  209] train: loss: 0.0251968
[Epoch 83] ogbg-moltox21: 0.757377 val loss: 0.595974
[Epoch 83] ogbg-moltox21: 0.697182 test loss: 0.669836
[Epoch 84; Iter    23/  209] train: loss: 0.0132375
[Epoch 84; Iter    53/  209] train: loss: 0.0065222
[Epoch 84; Iter    83/  209] train: loss: 0.0086753
[Epoch 84; Iter   113/  209] train: loss: 0.0080341
[Epoch 84; Iter   143/  209] train: loss: 0.0097669
[Epoch 84; Iter   173/  209] train: loss: 0.0181520
[Epoch 84; Iter   203/  209] train: loss: 0.0267734
[Epoch 84] ogbg-moltox21: 0.758340 val loss: 0.587723
[Epoch 84] ogbg-moltox21: 0.698322 test loss: 0.668869
[Epoch 85; Iter    24/  209] train: loss: 0.0121654
[Epoch 85; Iter    54/  209] train: loss: 0.0245375
[Epoch 85; Iter    84/  209] train: loss: 0.0069279
[Epoch 85; Iter   114/  209] train: loss: 0.0429207
[Epoch 85; Iter   144/  209] train: loss: 0.0301814
[Epoch 85; Iter   174/  209] train: loss: 0.0091600
[Epoch 85; Iter   204/  209] train: loss: 0.0107333
[Epoch 85] ogbg-moltox21: 0.751264 val loss: 0.606726
[Epoch 85] ogbg-moltox21: 0.694268 test loss: 0.692008
[Epoch 86; Iter    25/  209] train: loss: 0.0033394
[Epoch 86; Iter    55/  209] train: loss: 0.0059792
[Epoch 86; Iter    85/  209] train: loss: 0.0120736
[Epoch 86; Iter   115/  209] train: loss: 0.0135969
[Epoch 86; Iter   145/  209] train: loss: 0.0089437
[Epoch 86; Iter   175/  209] train: loss: 0.0117759
[Epoch 86; Iter   205/  209] train: loss: 0.0075209
[Epoch 86] ogbg-moltox21: 0.763147 val loss: 0.576654
[Epoch 86] ogbg-moltox21: 0.694985 test loss: 0.672696
[Epoch 87; Iter    26/  209] train: loss: 0.0048694
[Epoch 87; Iter    56/  209] train: loss: 0.0161941
[Epoch 87; Iter    86/  209] train: loss: 0.0098980
[Epoch 87; Iter   116/  209] train: loss: 0.0107191
[Epoch 87; Iter   146/  209] train: loss: 0.0433287
[Epoch 87; Iter   176/  209] train: loss: 0.0099808
[Epoch 87; Iter   206/  209] train: loss: 0.0340666
[Epoch 87] ogbg-moltox21: 0.754281 val loss: 0.634431
[Epoch 87] ogbg-moltox21: 0.690755 test loss: 0.718698
[Epoch 88; Iter    27/  209] train: loss: 0.0072694
[Epoch 88; Iter    57/  209] train: loss: 0.0049948
[Epoch 88; Iter    87/  209] train: loss: 0.0120809
[Epoch 88; Iter   117/  209] train: loss: 0.0095901
[Epoch 88; Iter   147/  209] train: loss: 0.0079152
[Epoch 88; Iter   177/  209] train: loss: 0.0121125
[Epoch 88; Iter   207/  209] train: loss: 0.0118903
[Epoch 88] ogbg-moltox21: 0.755152 val loss: 0.621897
[Epoch 88] ogbg-moltox21: 0.697208 test loss: 0.684145
[Epoch 89; Iter    28/  209] train: loss: 0.0066216
[Epoch 89; Iter    58/  209] train: loss: 0.0116528
[Epoch 89; Iter    88/  209] train: loss: 0.0189212
[Epoch 89; Iter   118/  209] train: loss: 0.0051392
[Epoch 89; Iter   148/  209] train: loss: 0.0207796
[Epoch 89; Iter   178/  209] train: loss: 0.0085294
[Epoch 89; Iter   208/  209] train: loss: 0.0053895
[Epoch 89] ogbg-moltox21: 0.756656 val loss: 0.628305
[Epoch 89] ogbg-moltox21: 0.694775 test loss: 0.677132
[Epoch 90; Iter    29/  209] train: loss: 0.0151328
[Epoch 90; Iter    59/  209] train: loss: 0.0084889
[Epoch 90; Iter    89/  209] train: loss: 0.0109031
[Epoch 90; Iter   119/  209] train: loss: 0.0400968
[Epoch 90; Iter   149/  209] train: loss: 0.0072817
[Epoch 90; Iter   179/  209] train: loss: 0.0103060
[Epoch 90; Iter   209/  209] train: loss: 0.0058294
[Epoch 90] ogbg-moltox21: 0.757558 val loss: 0.607103
[Epoch 90] ogbg-moltox21: 0.694851 test loss: 0.694067
[Epoch 91; Iter    30/  209] train: loss: 0.0067040
[Epoch 91; Iter    60/  209] train: loss: 0.0108317
[Epoch 91; Iter    90/  209] train: loss: 0.0067044
[Epoch 91; Iter   120/  209] train: loss: 0.0138895
[Epoch 91; Iter   150/  209] train: loss: 0.0106115
[Epoch 91; Iter   180/  209] train: loss: 0.0106061
[Epoch 91] ogbg-moltox21: 0.758663 val loss: 0.610027
[Epoch 91] ogbg-moltox21: 0.700475 test loss: 0.689055
[Epoch 92; Iter     1/  209] train: loss: 0.0085255
[Epoch 92; Iter    31/  209] train: loss: 0.0050155
[Epoch 92; Iter    61/  209] train: loss: 0.0040766
[Epoch 92; Iter    91/  209] train: loss: 0.0128314
[Epoch 92; Iter   121/  209] train: loss: 0.0058431
[Epoch 92; Iter   151/  209] train: loss: 0.0059407
[Epoch 92; Iter   181/  209] train: loss: 0.0096552
[Epoch 92] ogbg-moltox21: 0.756275 val loss: 0.610828
[Epoch 92] ogbg-moltox21: 0.695999 test loss: 0.694069
[Epoch 93; Iter     2/  209] train: loss: 0.0045111
[Epoch 93; Iter    32/  209] train: loss: 0.0180696
[Epoch 93; Iter    62/  209] train: loss: 0.0106788
[Epoch 93; Iter    92/  209] train: loss: 0.0073842
[Epoch 93; Iter   122/  209] train: loss: 0.0084159
[Epoch 93; Iter   152/  209] train: loss: 0.0076296
[Epoch 93; Iter   182/  209] train: loss: 0.0029183
[Epoch 93] ogbg-moltox21: 0.754943 val loss: 0.654640
[Epoch 93] ogbg-moltox21: 0.691663 test loss: 0.700819
[Epoch 94; Iter     3/  209] train: loss: 0.0096691
[Epoch 94; Iter    33/  209] train: loss: 0.0045815
[Epoch 94; Iter    63/  209] train: loss: 0.0042597
[Epoch 94; Iter    93/  209] train: loss: 0.0040305
[Epoch 94; Iter   123/  209] train: loss: 0.0191959
[Epoch 94; Iter   153/  209] train: loss: 0.0058306
[Epoch 94; Iter   183/  209] train: loss: 0.0118137
[Epoch 94] ogbg-moltox21: 0.754997 val loss: 0.664296
[Epoch 94] ogbg-moltox21: 0.693265 test loss: 0.712593
[Epoch 95; Iter     4/  209] train: loss: 0.0073851
[Epoch 95; Iter    34/  209] train: loss: 0.0065469
[Epoch 95; Iter    64/  209] train: loss: 0.0049684
[Epoch 95; Iter    94/  209] train: loss: 0.0160963
[Epoch 95; Iter   124/  209] train: loss: 0.0068683
[Epoch 95; Iter   154/  209] train: loss: 0.0146640
[Epoch 95; Iter   184/  209] train: loss: 0.0104124
[Epoch 95] ogbg-moltox21: 0.753114 val loss: 0.658436
[Epoch 95] ogbg-moltox21: 0.692199 test loss: 0.722007
[Epoch 96; Iter     5/  209] train: loss: 0.0059598
[Epoch 96; Iter    35/  209] train: loss: 0.0129988
[Epoch 96; Iter    65/  209] train: loss: 0.0073183
[Epoch 96; Iter    95/  209] train: loss: 0.0048863
[Epoch 96; Iter   125/  209] train: loss: 0.0073775
[Epoch 96; Iter   155/  209] train: loss: 0.0038248
[Epoch 96; Iter   185/  209] train: loss: 0.0091791
[Epoch 96] ogbg-moltox21: 0.753657 val loss: 0.639033
[Epoch 96] ogbg-moltox21: 0.693060 test loss: 0.709057
[Epoch 97; Iter     6/  209] train: loss: 0.0111597
[Epoch 97; Iter    36/  209] train: loss: 0.0065167
[Epoch 97; Iter    66/  209] train: loss: 0.0067874
[Epoch 97; Iter    96/  209] train: loss: 0.0034778
[Epoch 97; Iter   126/  209] train: loss: 0.0079853
[Epoch 97; Iter   156/  209] train: loss: 0.0098100
[Epoch 97; Iter   186/  209] train: loss: 0.0069852
[Epoch 97] ogbg-moltox21: 0.758107 val loss: 0.630551
[Epoch 97] ogbg-moltox21: 0.697726 test loss: 0.702252
[Epoch 98; Iter     7/  209] train: loss: 0.0245624
[Epoch 98; Iter    37/  209] train: loss: 0.0036931
[Epoch 98; Iter    67/  209] train: loss: 0.0144046
[Epoch 98; Iter    97/  209] train: loss: 0.0056242
[Epoch 98; Iter   127/  209] train: loss: 0.0071627
[Epoch 98; Iter   157/  209] train: loss: 0.0127019
[Epoch 98; Iter   187/  209] train: loss: 0.0081184
[Epoch 98] ogbg-moltox21: 0.750807 val loss: 0.613559
[Epoch 98] ogbg-moltox21: 0.694730 test loss: 0.692232
[Epoch 99; Iter     8/  209] train: loss: 0.0125366
[Epoch 99; Iter    38/  209] train: loss: 0.0030707
[Epoch 99; Iter    68/  209] train: loss: 0.0066067
[Epoch 99; Iter    98/  209] train: loss: 0.0027510
[Epoch 82; Iter    51/  209] train: loss: 0.0268481
[Epoch 82; Iter    81/  209] train: loss: 0.0418759
[Epoch 82; Iter   111/  209] train: loss: 0.0189298
[Epoch 82; Iter   141/  209] train: loss: 0.0430044
[Epoch 82; Iter   171/  209] train: loss: 0.0116070
[Epoch 82; Iter   201/  209] train: loss: 0.0103532
[Epoch 82] ogbg-moltox21: 0.731396 val loss: 0.885019
[Epoch 82] ogbg-moltox21: 0.715537 test loss: 0.540084
[Epoch 83; Iter    22/  209] train: loss: 0.0354837
[Epoch 83; Iter    52/  209] train: loss: 0.0566620
[Epoch 83; Iter    82/  209] train: loss: 0.0151512
[Epoch 83; Iter   112/  209] train: loss: 0.0338670
[Epoch 83; Iter   142/  209] train: loss: 0.0571755
[Epoch 83; Iter   172/  209] train: loss: 0.0109742
[Epoch 83; Iter   202/  209] train: loss: 0.0530479
[Epoch 83] ogbg-moltox21: 0.739503 val loss: 1.089633
[Epoch 83] ogbg-moltox21: 0.723052 test loss: 0.528108
[Epoch 84; Iter    23/  209] train: loss: 0.0282464
[Epoch 84; Iter    53/  209] train: loss: 0.0258168
[Epoch 84; Iter    83/  209] train: loss: 0.0151841
[Epoch 84; Iter   113/  209] train: loss: 0.0138991
[Epoch 84; Iter   143/  209] train: loss: 0.0239341
[Epoch 84; Iter   173/  209] train: loss: 0.0275382
[Epoch 84; Iter   203/  209] train: loss: 0.0460535
[Epoch 84] ogbg-moltox21: 0.747914 val loss: 0.996361
[Epoch 84] ogbg-moltox21: 0.720879 test loss: 0.559247
[Epoch 85; Iter    24/  209] train: loss: 0.0278100
[Epoch 85; Iter    54/  209] train: loss: 0.0409460
[Epoch 85; Iter    84/  209] train: loss: 0.0099344
[Epoch 85; Iter   114/  209] train: loss: 0.0620389
[Epoch 85; Iter   144/  209] train: loss: 0.0552480
[Epoch 85; Iter   174/  209] train: loss: 0.0260027
[Epoch 85; Iter   204/  209] train: loss: 0.0153058
[Epoch 85] ogbg-moltox21: 0.735407 val loss: 1.029988
[Epoch 85] ogbg-moltox21: 0.713239 test loss: 0.547701
[Epoch 86; Iter    25/  209] train: loss: 0.0088011
[Epoch 86; Iter    55/  209] train: loss: 0.0112146
[Epoch 86; Iter    85/  209] train: loss: 0.0134625
[Epoch 86; Iter   115/  209] train: loss: 0.0169289
[Epoch 86; Iter   145/  209] train: loss: 0.0238899
[Epoch 86; Iter   175/  209] train: loss: 0.0130106
[Epoch 86; Iter   205/  209] train: loss: 0.0124346
[Epoch 86] ogbg-moltox21: 0.744782 val loss: 1.147830
[Epoch 86] ogbg-moltox21: 0.719234 test loss: 0.534914
[Epoch 87; Iter    26/  209] train: loss: 0.0059140
[Epoch 87; Iter    56/  209] train: loss: 0.0299467
[Epoch 87; Iter    86/  209] train: loss: 0.0113447
[Epoch 87; Iter   116/  209] train: loss: 0.0278838
[Epoch 87; Iter   146/  209] train: loss: 0.0567360
[Epoch 87; Iter   176/  209] train: loss: 0.0178777
[Epoch 87; Iter   206/  209] train: loss: 0.0307317
[Epoch 87] ogbg-moltox21: 0.745142 val loss: 1.162529
[Epoch 87] ogbg-moltox21: 0.715443 test loss: 0.559178
[Epoch 88; Iter    27/  209] train: loss: 0.0258219
[Epoch 88; Iter    57/  209] train: loss: 0.0271969
[Epoch 88; Iter    87/  209] train: loss: 0.0297987
[Epoch 88; Iter   117/  209] train: loss: 0.0111355
[Epoch 88; Iter   147/  209] train: loss: 0.0105721
[Epoch 88; Iter   177/  209] train: loss: 0.0125927
[Epoch 88; Iter   207/  209] train: loss: 0.0196012
[Epoch 88] ogbg-moltox21: 0.746808 val loss: 1.278425
[Epoch 88] ogbg-moltox21: 0.720335 test loss: 0.561294
[Epoch 89; Iter    28/  209] train: loss: 0.0077870
[Epoch 89; Iter    58/  209] train: loss: 0.0202543
[Epoch 89; Iter    88/  209] train: loss: 0.0221550
[Epoch 89; Iter   118/  209] train: loss: 0.0102937
[Epoch 89; Iter   148/  209] train: loss: 0.0366135
[Epoch 89; Iter   178/  209] train: loss: 0.0148136
[Epoch 89; Iter   208/  209] train: loss: 0.0230332
[Epoch 89] ogbg-moltox21: 0.736347 val loss: 1.203694
[Epoch 89] ogbg-moltox21: 0.717092 test loss: 0.563907
[Epoch 90; Iter    29/  209] train: loss: 0.0296247
[Epoch 90; Iter    59/  209] train: loss: 0.0229426
[Epoch 90; Iter    89/  209] train: loss: 0.0134175
[Epoch 90; Iter   119/  209] train: loss: 0.0558027
[Epoch 90; Iter   149/  209] train: loss: 0.0154502
[Epoch 90; Iter   179/  209] train: loss: 0.0250460
[Epoch 90; Iter   209/  209] train: loss: 0.0274394
[Epoch 90] ogbg-moltox21: 0.737859 val loss: 1.207359
[Epoch 90] ogbg-moltox21: 0.713384 test loss: 0.581178
[Epoch 91; Iter    30/  209] train: loss: 0.0100478
[Epoch 91; Iter    60/  209] train: loss: 0.0248573
[Epoch 91; Iter    90/  209] train: loss: 0.0124815
[Epoch 91; Iter   120/  209] train: loss: 0.0261536
[Epoch 91; Iter   150/  209] train: loss: 0.0179479
[Epoch 91; Iter   180/  209] train: loss: 0.0227280
[Epoch 91] ogbg-moltox21: 0.744419 val loss: 1.210898
[Epoch 91] ogbg-moltox21: 0.723112 test loss: 0.562877
[Epoch 92; Iter     1/  209] train: loss: 0.0139985
[Epoch 92; Iter    31/  209] train: loss: 0.0077386
[Epoch 92; Iter    61/  209] train: loss: 0.0079679
[Epoch 92; Iter    91/  209] train: loss: 0.0219805
[Epoch 92; Iter   121/  209] train: loss: 0.0139378
[Epoch 92; Iter   151/  209] train: loss: 0.0131573
[Epoch 92; Iter   181/  209] train: loss: 0.0126970
[Epoch 92] ogbg-moltox21: 0.732191 val loss: 1.211897
[Epoch 92] ogbg-moltox21: 0.717491 test loss: 0.567937
[Epoch 93; Iter     2/  209] train: loss: 0.0223786
[Epoch 93; Iter    32/  209] train: loss: 0.0289494
[Epoch 93; Iter    62/  209] train: loss: 0.0089460
[Epoch 93; Iter    92/  209] train: loss: 0.0127957
[Epoch 93; Iter   122/  209] train: loss: 0.0128239
[Epoch 93; Iter   152/  209] train: loss: 0.0121193
[Epoch 93; Iter   182/  209] train: loss: 0.0142202
[Epoch 93] ogbg-moltox21: 0.737255 val loss: 1.180631
[Epoch 93] ogbg-moltox21: 0.713526 test loss: 0.588785
[Epoch 94; Iter     3/  209] train: loss: 0.0099482
[Epoch 94; Iter    33/  209] train: loss: 0.0048952
[Epoch 94; Iter    63/  209] train: loss: 0.0072515
[Epoch 94; Iter    93/  209] train: loss: 0.0054728
[Epoch 94; Iter   123/  209] train: loss: 0.0225891
[Epoch 94; Iter   153/  209] train: loss: 0.0054710
[Epoch 94; Iter   183/  209] train: loss: 0.0171198
[Epoch 94] ogbg-moltox21: 0.735921 val loss: 1.086066
[Epoch 94] ogbg-moltox21: 0.714313 test loss: 0.580466
[Epoch 95; Iter     4/  209] train: loss: 0.0070344
[Epoch 95; Iter    34/  209] train: loss: 0.0096522
[Epoch 95; Iter    64/  209] train: loss: 0.0114665
[Epoch 95; Iter    94/  209] train: loss: 0.0202090
[Epoch 95; Iter   124/  209] train: loss: 0.0090171
[Epoch 95; Iter   154/  209] train: loss: 0.0258787
[Epoch 95; Iter   184/  209] train: loss: 0.0185479
[Epoch 95] ogbg-moltox21: 0.732237 val loss: 1.014304
[Epoch 95] ogbg-moltox21: 0.708924 test loss: 0.590333
[Epoch 96; Iter     5/  209] train: loss: 0.0134920
[Epoch 96; Iter    35/  209] train: loss: 0.0176652
[Epoch 96; Iter    65/  209] train: loss: 0.0090880
[Epoch 96; Iter    95/  209] train: loss: 0.0101254
[Epoch 96; Iter   125/  209] train: loss: 0.0156803
[Epoch 96; Iter   155/  209] train: loss: 0.0142153
[Epoch 96; Iter   185/  209] train: loss: 0.0177203
[Epoch 96] ogbg-moltox21: 0.727838 val loss: 1.131904
[Epoch 96] ogbg-moltox21: 0.712296 test loss: 0.594239
[Epoch 97; Iter     6/  209] train: loss: 0.0138896
[Epoch 97; Iter    36/  209] train: loss: 0.0154180
[Epoch 97; Iter    66/  209] train: loss: 0.0160814
[Epoch 97; Iter    96/  209] train: loss: 0.0090790
[Epoch 97; Iter   126/  209] train: loss: 0.0366424
[Epoch 97; Iter   156/  209] train: loss: 0.0094931
[Epoch 97; Iter   186/  209] train: loss: 0.0111705
[Epoch 97] ogbg-moltox21: 0.732255 val loss: 1.080869
[Epoch 97] ogbg-moltox21: 0.712497 test loss: 0.616161
[Epoch 98; Iter     7/  209] train: loss: 0.0332995
[Epoch 98; Iter    37/  209] train: loss: 0.0063287
[Epoch 98; Iter    67/  209] train: loss: 0.0310189
[Epoch 98; Iter    97/  209] train: loss: 0.0116947
[Epoch 98; Iter   127/  209] train: loss: 0.0125864
[Epoch 98; Iter   157/  209] train: loss: 0.0137938
[Epoch 98; Iter   187/  209] train: loss: 0.0175277
[Epoch 98] ogbg-moltox21: 0.732672 val loss: 1.200225
[Epoch 98] ogbg-moltox21: 0.709959 test loss: 0.618509
[Epoch 99; Iter     8/  209] train: loss: 0.0232960
[Epoch 99; Iter    38/  209] train: loss: 0.0116314
[Epoch 99; Iter    68/  209] train: loss: 0.0138145
[Epoch 99; Iter    98/  209] train: loss: 0.0071141
[Epoch 82; Iter    51/  209] train: loss: 0.0356559
[Epoch 82; Iter    81/  209] train: loss: 0.0282911
[Epoch 82; Iter   111/  209] train: loss: 0.0968453
[Epoch 82; Iter   141/  209] train: loss: 0.0307638
[Epoch 82; Iter   171/  209] train: loss: 0.0451552
[Epoch 82; Iter   201/  209] train: loss: 0.0380457
[Epoch 82] ogbg-moltox21: 0.712880 val loss: 0.466836
[Epoch 82] ogbg-moltox21: 0.711998 test loss: 0.492137
[Epoch 83; Iter    22/  209] train: loss: 0.0477375
[Epoch 83; Iter    52/  209] train: loss: 0.0884161
[Epoch 83; Iter    82/  209] train: loss: 0.0475988
[Epoch 83; Iter   112/  209] train: loss: 0.0538638
[Epoch 83; Iter   142/  209] train: loss: 0.0362610
[Epoch 83; Iter   172/  209] train: loss: 0.0271544
[Epoch 83; Iter   202/  209] train: loss: 0.0490394
[Epoch 83] ogbg-moltox21: 0.713084 val loss: 0.485928
[Epoch 83] ogbg-moltox21: 0.704466 test loss: 0.517684
[Epoch 84; Iter    23/  209] train: loss: 0.0280386
[Epoch 84; Iter    53/  209] train: loss: 0.0270412
[Epoch 84; Iter    83/  209] train: loss: 0.0394503
[Epoch 84; Iter   113/  209] train: loss: 0.0656610
[Epoch 84; Iter   143/  209] train: loss: 0.0396750
[Epoch 84; Iter   173/  209] train: loss: 0.0370350
[Epoch 84; Iter   203/  209] train: loss: 0.0486188
[Epoch 84] ogbg-moltox21: 0.708997 val loss: 0.494889
[Epoch 84] ogbg-moltox21: 0.704052 test loss: 0.511697
[Epoch 85; Iter    24/  209] train: loss: 0.0255339
[Epoch 85; Iter    54/  209] train: loss: 0.0364874
[Epoch 85; Iter    84/  209] train: loss: 0.0518572
[Epoch 85; Iter   114/  209] train: loss: 0.0757432
[Epoch 85; Iter   144/  209] train: loss: 0.0425645
[Epoch 85; Iter   174/  209] train: loss: 0.0644804
[Epoch 85; Iter   204/  209] train: loss: 0.0541901
[Epoch 85] ogbg-moltox21: 0.716268 val loss: 0.508220
[Epoch 85] ogbg-moltox21: 0.706070 test loss: 0.523544
[Epoch 86; Iter    25/  209] train: loss: 0.0464674
[Epoch 86; Iter    55/  209] train: loss: 0.0362909
[Epoch 86; Iter    85/  209] train: loss: 0.0320393
[Epoch 86; Iter   115/  209] train: loss: 0.0352478
[Epoch 86; Iter   145/  209] train: loss: 0.0134147
[Epoch 86; Iter   175/  209] train: loss: 0.0314024
[Epoch 86; Iter   205/  209] train: loss: 0.0878844
[Epoch 86] ogbg-moltox21: 0.716960 val loss: 0.477390
[Epoch 86] ogbg-moltox21: 0.708404 test loss: 0.511738
[Epoch 87; Iter    26/  209] train: loss: 0.0234547
[Epoch 87; Iter    56/  209] train: loss: 0.0270215
[Epoch 87; Iter    86/  209] train: loss: 0.0289135
[Epoch 87; Iter   116/  209] train: loss: 0.0229861
[Epoch 87; Iter   146/  209] train: loss: 0.0402334
[Epoch 87; Iter   176/  209] train: loss: 0.0466575
[Epoch 87; Iter   206/  209] train: loss: 0.0342335
[Epoch 87] ogbg-moltox21: 0.723792 val loss: 0.515928
[Epoch 87] ogbg-moltox21: 0.708490 test loss: 0.564630
[Epoch 88; Iter    27/  209] train: loss: 0.0533829
[Epoch 88; Iter    57/  209] train: loss: 0.0384739
[Epoch 88; Iter    87/  209] train: loss: 0.0232778
[Epoch 88; Iter   117/  209] train: loss: 0.0461114
[Epoch 88; Iter   147/  209] train: loss: 0.0171637
[Epoch 88; Iter   177/  209] train: loss: 0.0318294
[Epoch 88; Iter   207/  209] train: loss: 0.0537768
[Epoch 88] ogbg-moltox21: 0.720950 val loss: 0.493569
[Epoch 88] ogbg-moltox21: 0.711721 test loss: 0.517191
[Epoch 89; Iter    28/  209] train: loss: 0.0270036
[Epoch 89; Iter    58/  209] train: loss: 0.0615570
[Epoch 89; Iter    88/  209] train: loss: 0.0306496
[Epoch 89; Iter   118/  209] train: loss: 0.0224035
[Epoch 89; Iter   148/  209] train: loss: 0.0383849
[Epoch 89; Iter   178/  209] train: loss: 0.0590423
[Epoch 89; Iter   208/  209] train: loss: 0.0251363
[Epoch 89] ogbg-moltox21: 0.720227 val loss: 0.489771
[Epoch 89] ogbg-moltox21: 0.710828 test loss: 0.520346
[Epoch 90; Iter    29/  209] train: loss: 0.0326624
[Epoch 90; Iter    59/  209] train: loss: 0.0196437
[Epoch 90; Iter    89/  209] train: loss: 0.0352190
[Epoch 90; Iter   119/  209] train: loss: 0.0249988
[Epoch 90; Iter   149/  209] train: loss: 0.0246237
[Epoch 90; Iter   179/  209] train: loss: 0.0144281
[Epoch 90; Iter   209/  209] train: loss: 0.0744172
[Epoch 90] ogbg-moltox21: 0.716378 val loss: 0.496802
[Epoch 90] ogbg-moltox21: 0.706984 test loss: 0.536996
[Epoch 91; Iter    30/  209] train: loss: 0.0225991
[Epoch 91; Iter    60/  209] train: loss: 0.0135811
[Epoch 91; Iter    90/  209] train: loss: 0.0157932
[Epoch 91; Iter   120/  209] train: loss: 0.0236825
[Epoch 91; Iter   150/  209] train: loss: 0.0368516
[Epoch 91; Iter   180/  209] train: loss: 0.0113502
[Epoch 91] ogbg-moltox21: 0.717164 val loss: 0.479952
[Epoch 91] ogbg-moltox21: 0.711980 test loss: 0.518283
[Epoch 92; Iter     1/  209] train: loss: 0.0272616
[Epoch 92; Iter    31/  209] train: loss: 0.0233283
[Epoch 92; Iter    61/  209] train: loss: 0.0284967
[Epoch 92; Iter    91/  209] train: loss: 0.0408337
[Epoch 92; Iter   121/  209] train: loss: 0.0103233
[Epoch 92; Iter   151/  209] train: loss: 0.0174125
[Epoch 92; Iter   181/  209] train: loss: 0.0155738
[Epoch 92] ogbg-moltox21: 0.716500 val loss: 0.504732
[Epoch 92] ogbg-moltox21: 0.708290 test loss: 0.543040
[Epoch 93; Iter     2/  209] train: loss: 0.0389474
[Epoch 93; Iter    32/  209] train: loss: 0.0233322
[Epoch 93; Iter    62/  209] train: loss: 0.0389395
[Epoch 93; Iter    92/  209] train: loss: 0.0289151
[Epoch 93; Iter   122/  209] train: loss: 0.0407270
[Epoch 93; Iter   152/  209] train: loss: 0.0418261
[Epoch 93; Iter   182/  209] train: loss: 0.0164583
[Epoch 93] ogbg-moltox21: 0.712103 val loss: 0.512191
[Epoch 93] ogbg-moltox21: 0.710617 test loss: 0.543316
[Epoch 94; Iter     3/  209] train: loss: 0.0291606
[Epoch 94; Iter    33/  209] train: loss: 0.0213939
[Epoch 94; Iter    63/  209] train: loss: 0.0237374
[Epoch 94; Iter    93/  209] train: loss: 0.0232751
[Epoch 94; Iter   123/  209] train: loss: 0.0477573
[Epoch 94; Iter   153/  209] train: loss: 0.0172784
[Epoch 94; Iter   183/  209] train: loss: 0.0210178
[Epoch 94] ogbg-moltox21: 0.714227 val loss: 0.491876
[Epoch 94] ogbg-moltox21: 0.712015 test loss: 0.523502
[Epoch 95; Iter     4/  209] train: loss: 0.0226619
[Epoch 95; Iter    34/  209] train: loss: 0.0413965
[Epoch 95; Iter    64/  209] train: loss: 0.0174026
[Epoch 95; Iter    94/  209] train: loss: 0.0279715
[Epoch 95; Iter   124/  209] train: loss: 0.0331986
[Epoch 95; Iter   154/  209] train: loss: 0.0325543
[Epoch 95; Iter   184/  209] train: loss: 0.0348260
[Epoch 95] ogbg-moltox21: 0.714073 val loss: 0.498147
[Epoch 95] ogbg-moltox21: 0.705628 test loss: 0.534517
[Epoch 96; Iter     5/  209] train: loss: 0.0407530
[Epoch 96; Iter    35/  209] train: loss: 0.0272384
[Epoch 96; Iter    65/  209] train: loss: 0.0342331
[Epoch 96; Iter    95/  209] train: loss: 0.0267599
[Epoch 96; Iter   125/  209] train: loss: 0.0201859
[Epoch 96; Iter   155/  209] train: loss: 0.0256973
[Epoch 96; Iter   185/  209] train: loss: 0.0192662
[Epoch 96] ogbg-moltox21: 0.712208 val loss: 0.510958
[Epoch 96] ogbg-moltox21: 0.704259 test loss: 0.543884
[Epoch 97; Iter     6/  209] train: loss: 0.0200885
[Epoch 97; Iter    36/  209] train: loss: 0.0164938
[Epoch 97; Iter    66/  209] train: loss: 0.0410310
[Epoch 97; Iter    96/  209] train: loss: 0.0371218
[Epoch 97; Iter   126/  209] train: loss: 0.0302915
[Epoch 97; Iter   156/  209] train: loss: 0.0195137
[Epoch 97; Iter   186/  209] train: loss: 0.0156163
[Epoch 97] ogbg-moltox21: 0.712184 val loss: 0.503238
[Epoch 97] ogbg-moltox21: 0.702233 test loss: 0.540168
[Epoch 98; Iter     7/  209] train: loss: 0.0231674
[Epoch 98; Iter    37/  209] train: loss: 0.0223198
[Epoch 98; Iter    67/  209] train: loss: 0.0201382
[Epoch 98; Iter    97/  209] train: loss: 0.0366344
[Epoch 98; Iter   127/  209] train: loss: 0.0416612
[Epoch 98; Iter   157/  209] train: loss: 0.0209770
[Epoch 98; Iter   187/  209] train: loss: 0.0211093
[Epoch 98] ogbg-moltox21: 0.710362 val loss: 0.534137
[Epoch 98] ogbg-moltox21: 0.706608 test loss: 0.526787
[Epoch 99; Iter     8/  209] train: loss: 0.0609954
[Epoch 99; Iter    38/  209] train: loss: 0.0472103
[Epoch 99; Iter    68/  209] train: loss: 0.0418780
[Epoch 99; Iter    98/  209] train: loss: 0.0799305
[Epoch 82; Iter    51/  209] train: loss: 0.0170159
[Epoch 82; Iter    81/  209] train: loss: 0.0107683
[Epoch 82; Iter   111/  209] train: loss: 0.0386040
[Epoch 82; Iter   141/  209] train: loss: 0.0315915
[Epoch 82; Iter   171/  209] train: loss: 0.0141852
[Epoch 82; Iter   201/  209] train: loss: 0.0711885
[Epoch 82] ogbg-moltox21: 0.742352 val loss: 0.740446
[Epoch 82] ogbg-moltox21: 0.704522 test loss: 0.804400
[Epoch 83; Iter    22/  209] train: loss: 0.0090465
[Epoch 83; Iter    52/  209] train: loss: 0.0440324
[Epoch 83; Iter    82/  209] train: loss: 0.0230653
[Epoch 83; Iter   112/  209] train: loss: 0.0249939
[Epoch 83; Iter   142/  209] train: loss: 0.0377523
[Epoch 83; Iter   172/  209] train: loss: 0.0358797
[Epoch 83; Iter   202/  209] train: loss: 0.0277745
[Epoch 83] ogbg-moltox21: 0.742449 val loss: 0.786144
[Epoch 83] ogbg-moltox21: 0.703564 test loss: 0.852985
[Epoch 84; Iter    23/  209] train: loss: 0.0148722
[Epoch 84; Iter    53/  209] train: loss: 0.0229156
[Epoch 84; Iter    83/  209] train: loss: 0.0146950
[Epoch 84; Iter   113/  209] train: loss: 0.0292045
[Epoch 84; Iter   143/  209] train: loss: 0.0184571
[Epoch 84; Iter   173/  209] train: loss: 0.0086868
[Epoch 84; Iter   203/  209] train: loss: 0.0162901
[Epoch 84] ogbg-moltox21: 0.741226 val loss: 0.785635
[Epoch 84] ogbg-moltox21: 0.697023 test loss: 0.852906
[Epoch 85; Iter    24/  209] train: loss: 0.0210365
[Epoch 85; Iter    54/  209] train: loss: 0.0709399
[Epoch 85; Iter    84/  209] train: loss: 0.0206723
[Epoch 85; Iter   114/  209] train: loss: 0.0230343
[Epoch 85; Iter   144/  209] train: loss: 0.0099981
[Epoch 85; Iter   174/  209] train: loss: 0.0265744
[Epoch 85; Iter   204/  209] train: loss: 0.0203999
[Epoch 85] ogbg-moltox21: 0.739464 val loss: 0.821544
[Epoch 85] ogbg-moltox21: 0.699019 test loss: 0.892220
[Epoch 86; Iter    25/  209] train: loss: 0.0112241
[Epoch 86; Iter    55/  209] train: loss: 0.0362031
[Epoch 86; Iter    85/  209] train: loss: 0.0123292
[Epoch 86; Iter   115/  209] train: loss: 0.0080548
[Epoch 86; Iter   145/  209] train: loss: 0.0545380
[Epoch 86; Iter   175/  209] train: loss: 0.0174543
[Epoch 86; Iter   205/  209] train: loss: 0.0253988
[Epoch 86] ogbg-moltox21: 0.742615 val loss: 0.758328
[Epoch 86] ogbg-moltox21: 0.696811 test loss: 0.827456
[Epoch 87; Iter    26/  209] train: loss: 0.0121152
[Epoch 87; Iter    56/  209] train: loss: 0.0245411
[Epoch 87; Iter    86/  209] train: loss: 0.0337049
[Epoch 87; Iter   116/  209] train: loss: 0.0207292
[Epoch 87; Iter   146/  209] train: loss: 0.0214162
[Epoch 87; Iter   176/  209] train: loss: 0.0337519
[Epoch 87; Iter   206/  209] train: loss: 0.0279655
[Epoch 87] ogbg-moltox21: 0.743989 val loss: 0.777796
[Epoch 87] ogbg-moltox21: 0.699590 test loss: 0.852236
[Epoch 88; Iter    27/  209] train: loss: 0.0125856
[Epoch 88; Iter    57/  209] train: loss: 0.0135421
[Epoch 88; Iter    87/  209] train: loss: 0.0266321
[Epoch 88; Iter   117/  209] train: loss: 0.0265950
[Epoch 88; Iter   147/  209] train: loss: 0.0104677
[Epoch 88; Iter   177/  209] train: loss: 0.0094688
[Epoch 88; Iter   207/  209] train: loss: 0.0313495
[Epoch 88] ogbg-moltox21: 0.744158 val loss: 0.768737
[Epoch 88] ogbg-moltox21: 0.697714 test loss: 0.841248
[Epoch 89; Iter    28/  209] train: loss: 0.0104441
[Epoch 89; Iter    58/  209] train: loss: 0.0063675
[Epoch 89; Iter    88/  209] train: loss: 0.0178839
[Epoch 89; Iter   118/  209] train: loss: 0.0153572
[Epoch 89; Iter   148/  209] train: loss: 0.0184477
[Epoch 89; Iter   178/  209] train: loss: 0.0201416
[Epoch 89; Iter   208/  209] train: loss: 0.0177049
[Epoch 89] ogbg-moltox21: 0.740567 val loss: 0.832840
[Epoch 89] ogbg-moltox21: 0.701459 test loss: 0.895273
[Epoch 90; Iter    29/  209] train: loss: 0.0162925
[Epoch 90; Iter    59/  209] train: loss: 0.0091117
[Epoch 90; Iter    89/  209] train: loss: 0.0129487
[Epoch 90; Iter   119/  209] train: loss: 0.0215392
[Epoch 90; Iter   149/  209] train: loss: 0.0112914
[Epoch 90; Iter   179/  209] train: loss: 0.0061304
[Epoch 90; Iter   209/  209] train: loss: 0.0130718
[Epoch 90] ogbg-moltox21: 0.743783 val loss: 0.810399
[Epoch 90] ogbg-moltox21: 0.701022 test loss: 0.882558
[Epoch 91; Iter    30/  209] train: loss: 0.0101313
[Epoch 91; Iter    60/  209] train: loss: 0.0167783
[Epoch 91; Iter    90/  209] train: loss: 0.1068299
[Epoch 91; Iter   120/  209] train: loss: 0.0123422
[Epoch 91; Iter   150/  209] train: loss: 0.0129702
[Epoch 91; Iter   180/  209] train: loss: 0.0256181
[Epoch 91] ogbg-moltox21: 0.740587 val loss: 0.799503
[Epoch 91] ogbg-moltox21: 0.699917 test loss: 0.873944
[Epoch 92; Iter     1/  209] train: loss: 0.0168353
[Epoch 92; Iter    31/  209] train: loss: 0.0071907
[Epoch 92; Iter    61/  209] train: loss: 0.0056946
[Epoch 92; Iter    91/  209] train: loss: 0.0193674
[Epoch 92; Iter   121/  209] train: loss: 0.0150868
[Epoch 92; Iter   151/  209] train: loss: 0.0019203
[Epoch 92; Iter   181/  209] train: loss: 0.0207013
[Epoch 92] ogbg-moltox21: 0.740406 val loss: 0.792512
[Epoch 92] ogbg-moltox21: 0.703996 test loss: 0.855821
[Epoch 93; Iter     2/  209] train: loss: 0.0141063
[Epoch 93; Iter    32/  209] train: loss: 0.0270808
[Epoch 93; Iter    62/  209] train: loss: 0.0084920
[Epoch 93; Iter    92/  209] train: loss: 0.0137421
[Epoch 93; Iter   122/  209] train: loss: 0.0286607
[Epoch 93; Iter   152/  209] train: loss: 0.0105271
[Epoch 93; Iter   182/  209] train: loss: 0.0114045
[Epoch 93] ogbg-moltox21: 0.743755 val loss: 0.810169
[Epoch 93] ogbg-moltox21: 0.703789 test loss: 0.884130
[Epoch 94; Iter     3/  209] train: loss: 0.0110292
[Epoch 94; Iter    33/  209] train: loss: 0.0124560
[Epoch 94; Iter    63/  209] train: loss: 0.0092762
[Epoch 94; Iter    93/  209] train: loss: 0.0064723
[Epoch 94; Iter   123/  209] train: loss: 0.0133341
[Epoch 94; Iter   153/  209] train: loss: 0.0125322
[Epoch 94; Iter   183/  209] train: loss: 0.0138025
[Epoch 94] ogbg-moltox21: 0.741682 val loss: 0.796726
[Epoch 94] ogbg-moltox21: 0.699666 test loss: 0.872627
[Epoch 95; Iter     4/  209] train: loss: 0.0380978
[Epoch 95; Iter    34/  209] train: loss: 0.0087250
[Epoch 95; Iter    64/  209] train: loss: 0.0172769
[Epoch 95; Iter    94/  209] train: loss: 0.0108959
[Epoch 95; Iter   124/  209] train: loss: 0.0230565
[Epoch 95; Iter   154/  209] train: loss: 0.0110300
[Epoch 95; Iter   184/  209] train: loss: 0.0310485
[Epoch 95] ogbg-moltox21: 0.736240 val loss: 0.818795
[Epoch 95] ogbg-moltox21: 0.699906 test loss: 0.887781
[Epoch 96; Iter     5/  209] train: loss: 0.0073015
[Epoch 96; Iter    35/  209] train: loss: 0.0182088
[Epoch 96; Iter    65/  209] train: loss: 0.0116157
[Epoch 96; Iter    95/  209] train: loss: 0.0107538
[Epoch 96; Iter   125/  209] train: loss: 0.0141253
[Epoch 96; Iter   155/  209] train: loss: 0.0154710
[Epoch 96; Iter   185/  209] train: loss: 0.0340166
[Epoch 96] ogbg-moltox21: 0.739527 val loss: 0.845374
[Epoch 96] ogbg-moltox21: 0.699715 test loss: 0.915799
[Epoch 97; Iter     6/  209] train: loss: 0.0155158
[Epoch 97; Iter    36/  209] train: loss: 0.0083019
[Epoch 97; Iter    66/  209] train: loss: 0.0228470
[Epoch 97; Iter    96/  209] train: loss: 0.0066364
[Epoch 97; Iter   126/  209] train: loss: 0.0101005
[Epoch 97; Iter   156/  209] train: loss: 0.0530899
[Epoch 97; Iter   186/  209] train: loss: 0.0169013
[Epoch 97] ogbg-moltox21: 0.746615 val loss: 0.772276
[Epoch 97] ogbg-moltox21: 0.704744 test loss: 0.853519
[Epoch 98; Iter     7/  209] train: loss: 0.0051646
[Epoch 98; Iter    37/  209] train: loss: 0.0247393
[Epoch 98; Iter    67/  209] train: loss: 0.0086862
[Epoch 98; Iter    97/  209] train: loss: 0.0305959
[Epoch 98; Iter   127/  209] train: loss: 0.0058529
[Epoch 98; Iter   157/  209] train: loss: 0.0228286
[Epoch 98; Iter   187/  209] train: loss: 0.0139668
[Epoch 98] ogbg-moltox21: 0.738119 val loss: 0.813812
[Epoch 98] ogbg-moltox21: 0.699988 test loss: 0.873805
[Epoch 99; Iter     8/  209] train: loss: 0.0100947
[Epoch 99; Iter    38/  209] train: loss: 0.0072826
[Epoch 99; Iter    68/  209] train: loss: 0.0078649
[Epoch 99; Iter    98/  209] train: loss: 0.0095013
[Epoch 64] ogbg-moltox21: 0.772163 test loss: 0.298392
[Epoch 65; Iter     4/  209] train: loss: 0.0811621
[Epoch 65; Iter    34/  209] train: loss: 0.1150599
[Epoch 65; Iter    64/  209] train: loss: 0.0925080
[Epoch 65; Iter    94/  209] train: loss: 0.0717239
[Epoch 65; Iter   124/  209] train: loss: 0.0827449
[Epoch 65; Iter   154/  209] train: loss: 0.0815150
[Epoch 65; Iter   184/  209] train: loss: 0.1074177
[Epoch 65] ogbg-moltox21: 0.788779 val loss: 0.294938
[Epoch 65] ogbg-moltox21: 0.774823 test loss: 0.301889
[Epoch 66; Iter     5/  209] train: loss: 0.0648482
[Epoch 66; Iter    35/  209] train: loss: 0.1053273
[Epoch 66; Iter    65/  209] train: loss: 0.0846441
[Epoch 66; Iter    95/  209] train: loss: 0.1005673
[Epoch 66; Iter   125/  209] train: loss: 0.0904093
[Epoch 66; Iter   155/  209] train: loss: 0.1049762
[Epoch 66; Iter   185/  209] train: loss: 0.0888275
[Epoch 66] ogbg-moltox21: 0.782372 val loss: 0.311347
[Epoch 66] ogbg-moltox21: 0.764461 test loss: 0.319119
[Epoch 67; Iter     6/  209] train: loss: 0.0636739
[Epoch 67; Iter    36/  209] train: loss: 0.0596301
[Epoch 67; Iter    66/  209] train: loss: 0.0943289
[Epoch 67; Iter    96/  209] train: loss: 0.0910291
[Epoch 67; Iter   126/  209] train: loss: 0.0713055
[Epoch 67; Iter   156/  209] train: loss: 0.0667171
[Epoch 67; Iter   186/  209] train: loss: 0.1008963
[Epoch 67] ogbg-moltox21: 0.781841 val loss: 0.295038
[Epoch 67] ogbg-moltox21: 0.765225 test loss: 0.300710
[Epoch 68; Iter     7/  209] train: loss: 0.0492189
[Epoch 68; Iter    37/  209] train: loss: 0.0648641
[Epoch 68; Iter    67/  209] train: loss: 0.1533103
[Epoch 68; Iter    97/  209] train: loss: 0.0800820
[Epoch 68; Iter   127/  209] train: loss: 0.0725459
[Epoch 68; Iter   157/  209] train: loss: 0.0914698
[Epoch 68; Iter   187/  209] train: loss: 0.0991542
[Epoch 68] ogbg-moltox21: 0.780700 val loss: 0.296471
[Epoch 68] ogbg-moltox21: 0.768601 test loss: 0.309338
[Epoch 69; Iter     8/  209] train: loss: 0.0990219
[Epoch 69; Iter    38/  209] train: loss: 0.0787109
[Epoch 69; Iter    68/  209] train: loss: 0.0613195
[Epoch 69; Iter    98/  209] train: loss: 0.0854767
[Epoch 69; Iter   128/  209] train: loss: 0.1164204
[Epoch 69; Iter   158/  209] train: loss: 0.0855528
[Epoch 69; Iter   188/  209] train: loss: 0.1180691
[Epoch 69] ogbg-moltox21: 0.776939 val loss: 0.304117
[Epoch 69] ogbg-moltox21: 0.767529 test loss: 0.309697
[Epoch 70; Iter     9/  209] train: loss: 0.1074903
[Epoch 70; Iter    39/  209] train: loss: 0.1236578
[Epoch 70; Iter    69/  209] train: loss: 0.1080669
[Epoch 70; Iter    99/  209] train: loss: 0.1328303
[Epoch 70; Iter   129/  209] train: loss: 0.0861978
[Epoch 70; Iter   159/  209] train: loss: 0.0795206
[Epoch 70; Iter   189/  209] train: loss: 0.0884275
[Epoch 70] ogbg-moltox21: 0.772663 val loss: 0.312869
[Epoch 70] ogbg-moltox21: 0.756808 test loss: 0.317951
[Epoch 71; Iter    10/  209] train: loss: 0.0888337
[Epoch 71; Iter    40/  209] train: loss: 0.0937945
[Epoch 71; Iter    70/  209] train: loss: 0.0662974
[Epoch 71; Iter   100/  209] train: loss: 0.1342110
[Epoch 71; Iter   130/  209] train: loss: 0.0968272
[Epoch 71; Iter   160/  209] train: loss: 0.0674646
[Epoch 71; Iter   190/  209] train: loss: 0.1115573
[Epoch 71] ogbg-moltox21: 0.780256 val loss: 0.305270
[Epoch 71] ogbg-moltox21: 0.769133 test loss: 0.310960
[Epoch 72; Iter    11/  209] train: loss: 0.0966053
[Epoch 72; Iter    41/  209] train: loss: 0.0631169
[Epoch 72; Iter    71/  209] train: loss: 0.0635919
[Epoch 72; Iter   101/  209] train: loss: 0.0875588
[Epoch 72; Iter   131/  209] train: loss: 0.0807547
[Epoch 72; Iter   161/  209] train: loss: 0.1239404
[Epoch 72; Iter   191/  209] train: loss: 0.1256282
[Epoch 72] ogbg-moltox21: 0.782070 val loss: 0.311283
[Epoch 72] ogbg-moltox21: 0.768669 test loss: 0.322917
[Epoch 73; Iter    12/  209] train: loss: 0.0653535
[Epoch 73; Iter    42/  209] train: loss: 0.0875355
[Epoch 73; Iter    72/  209] train: loss: 0.0856852
[Epoch 73; Iter   102/  209] train: loss: 0.0664119
[Epoch 73; Iter   132/  209] train: loss: 0.0987883
[Epoch 73; Iter   162/  209] train: loss: 0.0716350
[Epoch 73; Iter   192/  209] train: loss: 0.0686661
[Epoch 73] ogbg-moltox21: 0.782474 val loss: 0.314070
[Epoch 73] ogbg-moltox21: 0.767795 test loss: 0.323235
[Epoch 74; Iter    13/  209] train: loss: 0.0651105
[Epoch 74; Iter    43/  209] train: loss: 0.0909328
[Epoch 74; Iter    73/  209] train: loss: 0.1481095
[Epoch 74; Iter   103/  209] train: loss: 0.0831550
[Epoch 74; Iter   133/  209] train: loss: 0.0721669
[Epoch 74; Iter   163/  209] train: loss: 0.1410436
[Epoch 74; Iter   193/  209] train: loss: 0.1156828
[Epoch 74] ogbg-moltox21: 0.776115 val loss: 0.319749
[Epoch 74] ogbg-moltox21: 0.761247 test loss: 0.325645
[Epoch 75; Iter    14/  209] train: loss: 0.0686630
[Epoch 75; Iter    44/  209] train: loss: 0.0491833
[Epoch 75; Iter    74/  209] train: loss: 0.0777270
[Epoch 75; Iter   104/  209] train: loss: 0.1262566
[Epoch 75; Iter   134/  209] train: loss: 0.0978206
[Epoch 75; Iter   164/  209] train: loss: 0.0677631
[Epoch 75; Iter   194/  209] train: loss: 0.0999787
[Epoch 75] ogbg-moltox21: 0.777337 val loss: 0.324757
[Epoch 75] ogbg-moltox21: 0.766743 test loss: 0.327121
[Epoch 76; Iter    15/  209] train: loss: 0.0896992
[Epoch 76; Iter    45/  209] train: loss: 0.0903970
[Epoch 76; Iter    75/  209] train: loss: 0.0926845
[Epoch 76; Iter   105/  209] train: loss: 0.1290367
[Epoch 76; Iter   135/  209] train: loss: 0.0879259
[Epoch 76; Iter   165/  209] train: loss: 0.0973170
[Epoch 76; Iter   195/  209] train: loss: 0.0488307
[Epoch 76] ogbg-moltox21: 0.780516 val loss: 0.331467
[Epoch 76] ogbg-moltox21: 0.773702 test loss: 0.325907
[Epoch 77; Iter    16/  209] train: loss: 0.0384178
[Epoch 77; Iter    46/  209] train: loss: 0.0679878
[Epoch 77; Iter    76/  209] train: loss: 0.0640521
[Epoch 77; Iter   106/  209] train: loss: 0.0963613
[Epoch 77; Iter   136/  209] train: loss: 0.0920012
[Epoch 77; Iter   166/  209] train: loss: 0.1193934
[Epoch 77; Iter   196/  209] train: loss: 0.0493553
[Epoch 77] ogbg-moltox21: 0.776379 val loss: 0.325245
[Epoch 77] ogbg-moltox21: 0.768507 test loss: 0.328341
[Epoch 78; Iter    17/  209] train: loss: 0.1426908
[Epoch 78; Iter    47/  209] train: loss: 0.0700928
[Epoch 78; Iter    77/  209] train: loss: 0.1744438
[Epoch 78; Iter   107/  209] train: loss: 0.1202051
[Epoch 78; Iter   137/  209] train: loss: 0.0671909
[Epoch 78; Iter   167/  209] train: loss: 0.0865481
[Epoch 78; Iter   197/  209] train: loss: 0.0709208
[Epoch 78] ogbg-moltox21: 0.770653 val loss: 0.317771
[Epoch 78] ogbg-moltox21: 0.772989 test loss: 0.318480
[Epoch 79; Iter    18/  209] train: loss: 0.0816251
[Epoch 79; Iter    48/  209] train: loss: 0.1031811
[Epoch 79; Iter    78/  209] train: loss: 0.1381235
[Epoch 79; Iter   108/  209] train: loss: 0.0773794
[Epoch 79; Iter   138/  209] train: loss: 0.0745377
[Epoch 79; Iter   168/  209] train: loss: 0.0854273
[Epoch 79; Iter   198/  209] train: loss: 0.0402447
[Epoch 79] ogbg-moltox21: 0.776150 val loss: 0.324918
[Epoch 79] ogbg-moltox21: 0.767777 test loss: 0.326454
[Epoch 80; Iter    19/  209] train: loss: 0.0768287
[Epoch 80; Iter    49/  209] train: loss: 0.0621777
[Epoch 80; Iter    79/  209] train: loss: 0.1604195
[Epoch 80; Iter   109/  209] train: loss: 0.0692630
[Epoch 80; Iter   139/  209] train: loss: 0.0699807
[Epoch 80; Iter   169/  209] train: loss: 0.0468337
[Epoch 80; Iter   199/  209] train: loss: 0.0806893
[Epoch 80] ogbg-moltox21: 0.773117 val loss: 0.328717
[Epoch 80] ogbg-moltox21: 0.764947 test loss: 0.323554
[Epoch 81; Iter    20/  209] train: loss: 0.0556744
[Epoch 81; Iter    50/  209] train: loss: 0.0853332
[Epoch 81; Iter    80/  209] train: loss: 0.0691710
[Epoch 81; Iter   110/  209] train: loss: 0.0867031
[Epoch 81; Iter   140/  209] train: loss: 0.0465706
[Epoch 81; Iter   170/  209] train: loss: 0.0717552
[Epoch 81; Iter   200/  209] train: loss: 0.0689805
[Epoch 81] ogbg-moltox21: 0.764952 val loss: 0.689778
[Epoch 81] ogbg-moltox21: 0.762327 test loss: 0.466765
[Epoch 82; Iter    21/  209] train: loss: 0.0682491
[Epoch 64] ogbg-moltox21: 0.757825 test loss: 0.285396
[Epoch 65; Iter     4/  209] train: loss: 0.0840775
[Epoch 65; Iter    34/  209] train: loss: 0.0589088
[Epoch 65; Iter    64/  209] train: loss: 0.1051222
[Epoch 65; Iter    94/  209] train: loss: 0.1095036
[Epoch 65; Iter   124/  209] train: loss: 0.1077058
[Epoch 65; Iter   154/  209] train: loss: 0.1243718
[Epoch 65; Iter   184/  209] train: loss: 0.1358284
[Epoch 65] ogbg-moltox21: 0.794812 val loss: 0.274181
[Epoch 65] ogbg-moltox21: 0.761799 test loss: 0.289289
[Epoch 66; Iter     5/  209] train: loss: 0.0874579
[Epoch 66; Iter    35/  209] train: loss: 0.0657366
[Epoch 66; Iter    65/  209] train: loss: 0.0924138
[Epoch 66; Iter    95/  209] train: loss: 0.0879692
[Epoch 66; Iter   125/  209] train: loss: 0.0898246
[Epoch 66; Iter   155/  209] train: loss: 0.0874360
[Epoch 66; Iter   185/  209] train: loss: 0.0570118
[Epoch 66] ogbg-moltox21: 0.797451 val loss: 0.285176
[Epoch 66] ogbg-moltox21: 0.759634 test loss: 0.298506
[Epoch 67; Iter     6/  209] train: loss: 0.1194090
[Epoch 67; Iter    36/  209] train: loss: 0.1241570
[Epoch 67; Iter    66/  209] train: loss: 0.1119860
[Epoch 67; Iter    96/  209] train: loss: 0.0773443
[Epoch 67; Iter   126/  209] train: loss: 0.0563201
[Epoch 67; Iter   156/  209] train: loss: 0.0777467
[Epoch 67; Iter   186/  209] train: loss: 0.0905894
[Epoch 67] ogbg-moltox21: 0.782806 val loss: 0.291121
[Epoch 67] ogbg-moltox21: 0.752952 test loss: 0.301359
[Epoch 68; Iter     7/  209] train: loss: 0.1052166
[Epoch 68; Iter    37/  209] train: loss: 0.1092834
[Epoch 68; Iter    67/  209] train: loss: 0.1141135
[Epoch 68; Iter    97/  209] train: loss: 0.0790499
[Epoch 68; Iter   127/  209] train: loss: 0.1006432
[Epoch 68; Iter   157/  209] train: loss: 0.0690693
[Epoch 68; Iter   187/  209] train: loss: 0.0608569
[Epoch 68] ogbg-moltox21: 0.788805 val loss: 0.285026
[Epoch 68] ogbg-moltox21: 0.762005 test loss: 0.297789
[Epoch 69; Iter     8/  209] train: loss: 0.1011483
[Epoch 69; Iter    38/  209] train: loss: 0.0685707
[Epoch 69; Iter    68/  209] train: loss: 0.1045329
[Epoch 69; Iter    98/  209] train: loss: 0.0614107
[Epoch 69; Iter   128/  209] train: loss: 0.0745731
[Epoch 69; Iter   158/  209] train: loss: 0.0841849
[Epoch 69; Iter   188/  209] train: loss: 0.0843571
[Epoch 69] ogbg-moltox21: 0.796858 val loss: 0.282105
[Epoch 69] ogbg-moltox21: 0.758745 test loss: 0.299705
[Epoch 70; Iter     9/  209] train: loss: 0.1100840
[Epoch 70; Iter    39/  209] train: loss: 0.0579002
[Epoch 70; Iter    69/  209] train: loss: 0.1429666
[Epoch 70; Iter    99/  209] train: loss: 0.1029134
[Epoch 70; Iter   129/  209] train: loss: 0.0941054
[Epoch 70; Iter   159/  209] train: loss: 0.1121222
[Epoch 70; Iter   189/  209] train: loss: 0.0947382
[Epoch 70] ogbg-moltox21: 0.784352 val loss: 0.290633
[Epoch 70] ogbg-moltox21: 0.756629 test loss: 0.304777
[Epoch 71; Iter    10/  209] train: loss: 0.0962383
[Epoch 71; Iter    40/  209] train: loss: 0.1070649
[Epoch 71; Iter    70/  209] train: loss: 0.1108689
[Epoch 71; Iter   100/  209] train: loss: 0.1030807
[Epoch 71; Iter   130/  209] train: loss: 0.0670896
[Epoch 71; Iter   160/  209] train: loss: 0.0789992
[Epoch 71; Iter   190/  209] train: loss: 0.1037902
[Epoch 71] ogbg-moltox21: 0.778685 val loss: 0.298084
[Epoch 71] ogbg-moltox21: 0.754349 test loss: 0.308463
[Epoch 72; Iter    11/  209] train: loss: 0.1026693
[Epoch 72; Iter    41/  209] train: loss: 0.1167380
[Epoch 72; Iter    71/  209] train: loss: 0.1352474
[Epoch 72; Iter   101/  209] train: loss: 0.0741142
[Epoch 72; Iter   131/  209] train: loss: 0.1210393
[Epoch 72; Iter   161/  209] train: loss: 0.1247765
[Epoch 72; Iter   191/  209] train: loss: 0.0730821
[Epoch 72] ogbg-moltox21: 0.785080 val loss: 0.295449
[Epoch 72] ogbg-moltox21: 0.752211 test loss: 0.308552
[Epoch 73; Iter    12/  209] train: loss: 0.0944663
[Epoch 73; Iter    42/  209] train: loss: 0.0749312
[Epoch 73; Iter    72/  209] train: loss: 0.0741624
[Epoch 73; Iter   102/  209] train: loss: 0.0897731
[Epoch 73; Iter   132/  209] train: loss: 0.1118567
[Epoch 73; Iter   162/  209] train: loss: 0.0444035
[Epoch 73; Iter   192/  209] train: loss: 0.1009211
[Epoch 73] ogbg-moltox21: 0.785776 val loss: 0.305805
[Epoch 73] ogbg-moltox21: 0.756119 test loss: 0.321126
[Epoch 74; Iter    13/  209] train: loss: 0.0896161
[Epoch 74; Iter    43/  209] train: loss: 0.1107091
[Epoch 74; Iter    73/  209] train: loss: 0.0864902
[Epoch 74; Iter   103/  209] train: loss: 0.0809481
[Epoch 74; Iter   133/  209] train: loss: 0.0770059
[Epoch 74; Iter   163/  209] train: loss: 0.0606410
[Epoch 74; Iter   193/  209] train: loss: 0.0948112
[Epoch 74] ogbg-moltox21: 0.782826 val loss: 0.301474
[Epoch 74] ogbg-moltox21: 0.754247 test loss: 0.312116
[Epoch 75; Iter    14/  209] train: loss: 0.0562010
[Epoch 75; Iter    44/  209] train: loss: 0.1276693
[Epoch 75; Iter    74/  209] train: loss: 0.0881927
[Epoch 75; Iter   104/  209] train: loss: 0.0999934
[Epoch 75; Iter   134/  209] train: loss: 0.0638464
[Epoch 75; Iter   164/  209] train: loss: 0.0784110
[Epoch 75; Iter   194/  209] train: loss: 0.0844556
[Epoch 75] ogbg-moltox21: 0.779880 val loss: 0.307675
[Epoch 75] ogbg-moltox21: 0.756938 test loss: 0.322285
[Epoch 76; Iter    15/  209] train: loss: 0.1303268
[Epoch 76; Iter    45/  209] train: loss: 0.0546288
[Epoch 76; Iter    75/  209] train: loss: 0.0732944
[Epoch 76; Iter   105/  209] train: loss: 0.0683055
[Epoch 76; Iter   135/  209] train: loss: 0.0721842
[Epoch 76; Iter   165/  209] train: loss: 0.0703562
[Epoch 76; Iter   195/  209] train: loss: 0.0849935
[Epoch 76] ogbg-moltox21: 0.776240 val loss: 0.309318
[Epoch 76] ogbg-moltox21: 0.749077 test loss: 0.326972
[Epoch 77; Iter    16/  209] train: loss: 0.1068430
[Epoch 77; Iter    46/  209] train: loss: 0.1023484
[Epoch 77; Iter    76/  209] train: loss: 0.0682937
[Epoch 77; Iter   106/  209] train: loss: 0.0670656
[Epoch 77; Iter   136/  209] train: loss: 0.1250524
[Epoch 77; Iter   166/  209] train: loss: 0.0927442
[Epoch 77; Iter   196/  209] train: loss: 0.0956762
[Epoch 77] ogbg-moltox21: 0.775231 val loss: 0.315858
[Epoch 77] ogbg-moltox21: 0.749892 test loss: 0.327115
[Epoch 78; Iter    17/  209] train: loss: 0.0512324
[Epoch 78; Iter    47/  209] train: loss: 0.0815684
[Epoch 78; Iter    77/  209] train: loss: 0.0785332
[Epoch 78; Iter   107/  209] train: loss: 0.1149389
[Epoch 78; Iter   137/  209] train: loss: 0.0948211
[Epoch 78; Iter   167/  209] train: loss: 0.1569668
[Epoch 78; Iter   197/  209] train: loss: 0.0678259
[Epoch 78] ogbg-moltox21: 0.786033 val loss: 0.312839
[Epoch 78] ogbg-moltox21: 0.748389 test loss: 0.331743
[Epoch 79; Iter    18/  209] train: loss: 0.1561453
[Epoch 79; Iter    48/  209] train: loss: 0.0816758
[Epoch 79; Iter    78/  209] train: loss: 0.0447278
[Epoch 79; Iter   108/  209] train: loss: 0.0701105
[Epoch 79; Iter   138/  209] train: loss: 0.0774279
[Epoch 79; Iter   168/  209] train: loss: 0.0917956
[Epoch 79; Iter   198/  209] train: loss: 0.0683121
[Epoch 79] ogbg-moltox21: 0.782678 val loss: 0.318255
[Epoch 79] ogbg-moltox21: 0.747738 test loss: 0.334562
[Epoch 80; Iter    19/  209] train: loss: 0.1500098
[Epoch 80; Iter    49/  209] train: loss: 0.0862720
[Epoch 80; Iter    79/  209] train: loss: 0.0377129
[Epoch 80; Iter   109/  209] train: loss: 0.0603257
[Epoch 80; Iter   139/  209] train: loss: 0.0573037
[Epoch 80; Iter   169/  209] train: loss: 0.1277293
[Epoch 80; Iter   199/  209] train: loss: 0.0826935
[Epoch 80] ogbg-moltox21: 0.777915 val loss: 0.311926
[Epoch 80] ogbg-moltox21: 0.744722 test loss: 0.326556
[Epoch 81; Iter    20/  209] train: loss: 0.0800008
[Epoch 81; Iter    50/  209] train: loss: 0.0589289
[Epoch 81; Iter    80/  209] train: loss: 0.1098764
[Epoch 81; Iter   110/  209] train: loss: 0.0701606
[Epoch 81; Iter   140/  209] train: loss: 0.0955315
[Epoch 81; Iter   170/  209] train: loss: 0.0687575
[Epoch 81; Iter   200/  209] train: loss: 0.0859965
[Epoch 81] ogbg-moltox21: 0.779723 val loss: 0.323146
[Epoch 81] ogbg-moltox21: 0.745527 test loss: 0.331584
[Epoch 82; Iter    21/  209] train: loss: 0.0613019
[Epoch 64] ogbg-moltox21: 0.746399 test loss: 0.323469
[Epoch 65; Iter     4/  209] train: loss: 0.0997154
[Epoch 65; Iter    34/  209] train: loss: 0.1132022
[Epoch 65; Iter    64/  209] train: loss: 0.0993785
[Epoch 65; Iter    94/  209] train: loss: 0.1353499
[Epoch 65; Iter   124/  209] train: loss: 0.1836767
[Epoch 65; Iter   154/  209] train: loss: 0.0568825
[Epoch 65; Iter   184/  209] train: loss: 0.1016164
[Epoch 65] ogbg-moltox21: 0.792473 val loss: 0.287148
[Epoch 65] ogbg-moltox21: 0.754288 test loss: 0.312749
[Epoch 66; Iter     5/  209] train: loss: 0.1174975
[Epoch 66; Iter    35/  209] train: loss: 0.0871820
[Epoch 66; Iter    65/  209] train: loss: 0.0549857
[Epoch 66; Iter    95/  209] train: loss: 0.0676143
[Epoch 66; Iter   125/  209] train: loss: 0.1484127
[Epoch 66; Iter   155/  209] train: loss: 0.1008180
[Epoch 66; Iter   185/  209] train: loss: 0.0842371
[Epoch 66] ogbg-moltox21: 0.783102 val loss: 0.285286
[Epoch 66] ogbg-moltox21: 0.754295 test loss: 0.311179
[Epoch 67; Iter     6/  209] train: loss: 0.0767290
[Epoch 67; Iter    36/  209] train: loss: 0.0691107
[Epoch 67; Iter    66/  209] train: loss: 0.0673464
[Epoch 67; Iter    96/  209] train: loss: 0.0770824
[Epoch 67; Iter   126/  209] train: loss: 0.1243457
[Epoch 67; Iter   156/  209] train: loss: 0.1146289
[Epoch 67; Iter   186/  209] train: loss: 0.1161471
[Epoch 67] ogbg-moltox21: 0.788611 val loss: 0.293205
[Epoch 67] ogbg-moltox21: 0.754288 test loss: 0.317846
[Epoch 68; Iter     7/  209] train: loss: 0.0676781
[Epoch 68; Iter    37/  209] train: loss: 0.0750926
[Epoch 68; Iter    67/  209] train: loss: 0.0917404
[Epoch 68; Iter    97/  209] train: loss: 0.0996570
[Epoch 68; Iter   127/  209] train: loss: 0.1063825
[Epoch 68; Iter   157/  209] train: loss: 0.0872022
[Epoch 68; Iter   187/  209] train: loss: 0.0903237
[Epoch 68] ogbg-moltox21: 0.790795 val loss: 0.302736
[Epoch 68] ogbg-moltox21: 0.760183 test loss: 0.323250
[Epoch 69; Iter     8/  209] train: loss: 0.0775772
[Epoch 69; Iter    38/  209] train: loss: 0.0574333
[Epoch 69; Iter    68/  209] train: loss: 0.0695618
[Epoch 69; Iter    98/  209] train: loss: 0.0902067
[Epoch 69; Iter   128/  209] train: loss: 0.1026157
[Epoch 69; Iter   158/  209] train: loss: 0.1616921
[Epoch 69; Iter   188/  209] train: loss: 0.0778985
[Epoch 69] ogbg-moltox21: 0.784479 val loss: 0.303402
[Epoch 69] ogbg-moltox21: 0.756397 test loss: 0.327082
[Epoch 70; Iter     9/  209] train: loss: 0.0809763
[Epoch 70; Iter    39/  209] train: loss: 0.0869696
[Epoch 70; Iter    69/  209] train: loss: 0.0765678
[Epoch 70; Iter    99/  209] train: loss: 0.0567788
[Epoch 70; Iter   129/  209] train: loss: 0.1161402
[Epoch 70; Iter   159/  209] train: loss: 0.1157206
[Epoch 70; Iter   189/  209] train: loss: 0.0962108
[Epoch 70] ogbg-moltox21: 0.780984 val loss: 0.304945
[Epoch 70] ogbg-moltox21: 0.756637 test loss: 0.325458
[Epoch 71; Iter    10/  209] train: loss: 0.0650197
[Epoch 71; Iter    40/  209] train: loss: 0.0871762
[Epoch 71; Iter    70/  209] train: loss: 0.1066309
[Epoch 71; Iter   100/  209] train: loss: 0.0849112
[Epoch 71; Iter   130/  209] train: loss: 0.1127116
[Epoch 71; Iter   160/  209] train: loss: 0.0790514
[Epoch 71; Iter   190/  209] train: loss: 0.0934868
[Epoch 71] ogbg-moltox21: 0.786328 val loss: 0.302827
[Epoch 71] ogbg-moltox21: 0.753261 test loss: 0.327653
[Epoch 72; Iter    11/  209] train: loss: 0.1287740
[Epoch 72; Iter    41/  209] train: loss: 0.0852048
[Epoch 72; Iter    71/  209] train: loss: 0.1083862
[Epoch 72; Iter   101/  209] train: loss: 0.0585781
[Epoch 72; Iter   131/  209] train: loss: 0.1025632
[Epoch 72; Iter   161/  209] train: loss: 0.0775665
[Epoch 72; Iter   191/  209] train: loss: 0.1011406
[Epoch 72] ogbg-moltox21: 0.779044 val loss: 0.309024
[Epoch 72] ogbg-moltox21: 0.749072 test loss: 0.334926
[Epoch 73; Iter    12/  209] train: loss: 0.0749827
[Epoch 73; Iter    42/  209] train: loss: 0.0667474
[Epoch 73; Iter    72/  209] train: loss: 0.0898505
[Epoch 73; Iter   102/  209] train: loss: 0.0747183
[Epoch 73; Iter   132/  209] train: loss: 0.1031322
[Epoch 73; Iter   162/  209] train: loss: 0.1234500
[Epoch 73; Iter   192/  209] train: loss: 0.1361378
[Epoch 73] ogbg-moltox21: 0.784090 val loss: 0.313816
[Epoch 73] ogbg-moltox21: 0.749500 test loss: 0.338103
[Epoch 74; Iter    13/  209] train: loss: 0.1335998
[Epoch 74; Iter    43/  209] train: loss: 0.0946149
[Epoch 74; Iter    73/  209] train: loss: 0.1045331
[Epoch 74; Iter   103/  209] train: loss: 0.0548866
[Epoch 74; Iter   133/  209] train: loss: 0.1415004
[Epoch 74; Iter   163/  209] train: loss: 0.0945833
[Epoch 74; Iter   193/  209] train: loss: 0.1338191
[Epoch 74] ogbg-moltox21: 0.777901 val loss: 0.319890
[Epoch 74] ogbg-moltox21: 0.748062 test loss: 0.344566
[Epoch 75; Iter    14/  209] train: loss: 0.0571887
[Epoch 75; Iter    44/  209] train: loss: 0.1055290
[Epoch 75; Iter    74/  209] train: loss: 0.0977580
[Epoch 75; Iter   104/  209] train: loss: 0.1078808
[Epoch 75; Iter   134/  209] train: loss: 0.0717943
[Epoch 75; Iter   164/  209] train: loss: 0.1075590
[Epoch 75; Iter   194/  209] train: loss: 0.0537301
[Epoch 75] ogbg-moltox21: 0.778079 val loss: 0.325275
[Epoch 75] ogbg-moltox21: 0.742807 test loss: 0.345941
[Epoch 76; Iter    15/  209] train: loss: 0.0682229
[Epoch 76; Iter    45/  209] train: loss: 0.0725312
[Epoch 76; Iter    75/  209] train: loss: 0.0894898
[Epoch 76; Iter   105/  209] train: loss: 0.0797956
[Epoch 76; Iter   135/  209] train: loss: 0.1255530
[Epoch 76; Iter   165/  209] train: loss: 0.0614755
[Epoch 76; Iter   195/  209] train: loss: 0.0777269
[Epoch 76] ogbg-moltox21: 0.778890 val loss: 0.320053
[Epoch 76] ogbg-moltox21: 0.753676 test loss: 0.349406
[Epoch 77; Iter    16/  209] train: loss: 0.0952116
[Epoch 77; Iter    46/  209] train: loss: 0.0660486
[Epoch 77; Iter    76/  209] train: loss: 0.0561037
[Epoch 77; Iter   106/  209] train: loss: 0.0951093
[Epoch 77; Iter   136/  209] train: loss: 0.1049268
[Epoch 77; Iter   166/  209] train: loss: 0.0949037
[Epoch 77; Iter   196/  209] train: loss: 0.1197780
[Epoch 77] ogbg-moltox21: 0.780680 val loss: 0.314099
[Epoch 77] ogbg-moltox21: 0.748719 test loss: 0.342929
[Epoch 78; Iter    17/  209] train: loss: 0.0479707
[Epoch 78; Iter    47/  209] train: loss: 0.0568461
[Epoch 78; Iter    77/  209] train: loss: 0.0661269
[Epoch 78; Iter   107/  209] train: loss: 0.0590220
[Epoch 78; Iter   137/  209] train: loss: 0.0458856
[Epoch 78; Iter   167/  209] train: loss: 0.0882349
[Epoch 78; Iter   197/  209] train: loss: 0.0773118
[Epoch 78] ogbg-moltox21: 0.784143 val loss: 0.321805
[Epoch 78] ogbg-moltox21: 0.748186 test loss: 0.347566
[Epoch 79; Iter    18/  209] train: loss: 0.0588850
[Epoch 79; Iter    48/  209] train: loss: 0.0741968
[Epoch 79; Iter    78/  209] train: loss: 0.0937565
[Epoch 79; Iter   108/  209] train: loss: 0.0801119
[Epoch 79; Iter   138/  209] train: loss: 0.0594431
[Epoch 79; Iter   168/  209] train: loss: 0.0858400
[Epoch 79; Iter   198/  209] train: loss: 0.0488722
[Epoch 79] ogbg-moltox21: 0.771879 val loss: 0.322312
[Epoch 79] ogbg-moltox21: 0.743665 test loss: 0.354821
[Epoch 80; Iter    19/  209] train: loss: 0.0671048
[Epoch 80; Iter    49/  209] train: loss: 0.0928551
[Epoch 80; Iter    79/  209] train: loss: 0.0476695
[Epoch 80; Iter   109/  209] train: loss: 0.0827222
[Epoch 80; Iter   139/  209] train: loss: 0.0530785
[Epoch 80; Iter   169/  209] train: loss: 0.0802910
[Epoch 80; Iter   199/  209] train: loss: 0.1391534
[Epoch 80] ogbg-moltox21: 0.779522 val loss: 0.333606
[Epoch 80] ogbg-moltox21: 0.750829 test loss: 0.363225
[Epoch 81; Iter    20/  209] train: loss: 0.1028610
[Epoch 81; Iter    50/  209] train: loss: 0.0693557
[Epoch 81; Iter    80/  209] train: loss: 0.0893275
[Epoch 81; Iter   110/  209] train: loss: 0.0938047
[Epoch 81; Iter   140/  209] train: loss: 0.1488461
[Epoch 81; Iter   170/  209] train: loss: 0.1012971
[Epoch 81; Iter   200/  209] train: loss: 0.0604008
[Epoch 81] ogbg-moltox21: 0.785379 val loss: 0.334051
[Epoch 81] ogbg-moltox21: 0.744596 test loss: 0.368324
[Epoch 82; Iter    21/  209] train: loss: 0.0664215
[Epoch 99; Iter   128/  209] train: loss: 0.0182794
[Epoch 99; Iter   158/  209] train: loss: 0.0169295
[Epoch 99; Iter   188/  209] train: loss: 0.0139080
[Epoch 99] ogbg-moltox21: 0.787681 val loss: 0.511890
[Epoch 99] ogbg-moltox21: 0.742022 test loss: 0.646970
[Epoch 100; Iter     9/  209] train: loss: 0.0095256
[Epoch 100; Iter    39/  209] train: loss: 0.0233880
[Epoch 100; Iter    69/  209] train: loss: 0.0179448
[Epoch 100; Iter    99/  209] train: loss: 0.0267698
[Epoch 100; Iter   129/  209] train: loss: 0.0166400
[Epoch 100; Iter   159/  209] train: loss: 0.0064792
[Epoch 100; Iter   189/  209] train: loss: 0.0109048
[Epoch 100] ogbg-moltox21: 0.786120 val loss: 0.505143
[Epoch 100] ogbg-moltox21: 0.736127 test loss: 0.739040
[Epoch 101; Iter    10/  209] train: loss: 0.0133091
[Epoch 101; Iter    40/  209] train: loss: 0.0092358
[Epoch 101; Iter    70/  209] train: loss: 0.0137375
[Epoch 101; Iter   100/  209] train: loss: 0.0082212
[Epoch 101; Iter   130/  209] train: loss: 0.0076646
[Epoch 101; Iter   160/  209] train: loss: 0.0152761
[Epoch 101; Iter   190/  209] train: loss: 0.0121848
[Epoch 101] ogbg-moltox21: 0.786842 val loss: 0.489575
[Epoch 101] ogbg-moltox21: 0.739138 test loss: 0.752508
[Epoch 102; Iter    11/  209] train: loss: 0.0197829
[Epoch 102; Iter    41/  209] train: loss: 0.0077541
[Epoch 102; Iter    71/  209] train: loss: 0.0104587
[Epoch 102; Iter   101/  209] train: loss: 0.0087259
[Epoch 102; Iter   131/  209] train: loss: 0.0184531
[Epoch 102; Iter   161/  209] train: loss: 0.0227633
[Epoch 102; Iter   191/  209] train: loss: 0.0197808
[Epoch 102] ogbg-moltox21: 0.781177 val loss: 0.508625
[Epoch 102] ogbg-moltox21: 0.736571 test loss: 0.659857
[Epoch 103; Iter    12/  209] train: loss: 0.0088576
[Epoch 103; Iter    42/  209] train: loss: 0.0082082
[Epoch 103; Iter    72/  209] train: loss: 0.0103604
[Epoch 103; Iter   102/  209] train: loss: 0.0104233
[Epoch 103; Iter   132/  209] train: loss: 0.0194739
[Epoch 103; Iter   162/  209] train: loss: 0.0960354
[Epoch 103; Iter   192/  209] train: loss: 0.0110712
[Epoch 103] ogbg-moltox21: 0.783579 val loss: 0.492906
[Epoch 103] ogbg-moltox21: 0.740774 test loss: 0.642950
[Epoch 104; Iter    13/  209] train: loss: 0.0138467
[Epoch 104; Iter    43/  209] train: loss: 0.0099950
[Epoch 104; Iter    73/  209] train: loss: 0.0074721
[Epoch 104; Iter   103/  209] train: loss: 0.0138351
[Epoch 104; Iter   133/  209] train: loss: 0.0067965
[Epoch 104; Iter   163/  209] train: loss: 0.0156473
[Epoch 104; Iter   193/  209] train: loss: 0.0119629
[Epoch 104] ogbg-moltox21: 0.786890 val loss: 0.500047
[Epoch 104] ogbg-moltox21: 0.738968 test loss: 0.670022
[Epoch 105; Iter    14/  209] train: loss: 0.0108275
[Epoch 105; Iter    44/  209] train: loss: 0.0142169
[Epoch 105; Iter    74/  209] train: loss: 0.0094002
[Epoch 105; Iter   104/  209] train: loss: 0.0121257
[Epoch 105; Iter   134/  209] train: loss: 0.0185726
[Epoch 105; Iter   164/  209] train: loss: 0.0094005
[Epoch 105; Iter   194/  209] train: loss: 0.0050736
[Epoch 105] ogbg-moltox21: 0.786972 val loss: 0.498872
[Epoch 105] ogbg-moltox21: 0.739153 test loss: 0.600671
[Epoch 106; Iter    15/  209] train: loss: 0.0079750
[Epoch 106; Iter    45/  209] train: loss: 0.0091641
[Epoch 106; Iter    75/  209] train: loss: 0.0123355
[Epoch 106; Iter   105/  209] train: loss: 0.0118937
[Epoch 106; Iter   135/  209] train: loss: 0.0153239
[Epoch 106; Iter   165/  209] train: loss: 0.0111648
[Epoch 106; Iter   195/  209] train: loss: 0.0058382
[Epoch 106] ogbg-moltox21: 0.783057 val loss: 0.511845
[Epoch 106] ogbg-moltox21: 0.737375 test loss: 0.639447
[Epoch 107; Iter    16/  209] train: loss: 0.0123095
[Epoch 107; Iter    46/  209] train: loss: 0.0082508
[Epoch 107; Iter    76/  209] train: loss: 0.0255550
[Epoch 107; Iter   106/  209] train: loss: 0.0076232
[Epoch 107; Iter   136/  209] train: loss: 0.0098241
[Epoch 107; Iter   166/  209] train: loss: 0.0095962
[Epoch 107; Iter   196/  209] train: loss: 0.0106388
[Epoch 107] ogbg-moltox21: 0.785519 val loss: 0.500388
[Epoch 107] ogbg-moltox21: 0.734227 test loss: 0.682577
[Epoch 108; Iter    17/  209] train: loss: 0.0183632
[Epoch 108; Iter    47/  209] train: loss: 0.0314185
[Epoch 108; Iter    77/  209] train: loss: 0.0086109
[Epoch 108; Iter   107/  209] train: loss: 0.0228242
[Epoch 108; Iter   137/  209] train: loss: 0.0110269
[Epoch 108; Iter   167/  209] train: loss: 0.0174940
[Epoch 108; Iter   197/  209] train: loss: 0.0249894
[Epoch 108] ogbg-moltox21: 0.785535 val loss: 0.510203
[Epoch 108] ogbg-moltox21: 0.733648 test loss: 0.650581
[Epoch 109; Iter    18/  209] train: loss: 0.0053501
[Epoch 109; Iter    48/  209] train: loss: 0.0062287
[Epoch 109; Iter    78/  209] train: loss: 0.0110282
[Epoch 109; Iter   108/  209] train: loss: 0.0135997
[Epoch 109; Iter   138/  209] train: loss: 0.0099543
[Epoch 109; Iter   168/  209] train: loss: 0.0117259
[Epoch 109; Iter   198/  209] train: loss: 0.0068519
[Epoch 109] ogbg-moltox21: 0.782579 val loss: 0.534652
[Epoch 109] ogbg-moltox21: 0.733476 test loss: 0.660242
[Epoch 110; Iter    19/  209] train: loss: 0.0051896
[Epoch 110; Iter    49/  209] train: loss: 0.0069244
[Epoch 110; Iter    79/  209] train: loss: 0.0201925
[Epoch 110; Iter   109/  209] train: loss: 0.0108835
[Epoch 110; Iter   139/  209] train: loss: 0.0145391
[Epoch 110; Iter   169/  209] train: loss: 0.0098752
[Epoch 110; Iter   199/  209] train: loss: 0.0369976
[Epoch 110] ogbg-moltox21: 0.786269 val loss: 0.504718
[Epoch 110] ogbg-moltox21: 0.737882 test loss: 0.644620
[Epoch 111; Iter    20/  209] train: loss: 0.0091784
[Epoch 111; Iter    50/  209] train: loss: 0.0083693
[Epoch 111; Iter    80/  209] train: loss: 0.0100566
[Epoch 111; Iter   110/  209] train: loss: 0.0168890
[Epoch 111; Iter   140/  209] train: loss: 0.0167619
[Epoch 111; Iter   170/  209] train: loss: 0.0073754
[Epoch 111; Iter   200/  209] train: loss: 0.0298105
[Epoch 111] ogbg-moltox21: 0.787747 val loss: 0.504749
[Epoch 111] ogbg-moltox21: 0.735811 test loss: 0.649552
[Epoch 112; Iter    21/  209] train: loss: 0.0092459
[Epoch 112; Iter    51/  209] train: loss: 0.0177308
[Epoch 112; Iter    81/  209] train: loss: 0.0067123
[Epoch 112; Iter   111/  209] train: loss: 0.0165218
[Epoch 112; Iter   141/  209] train: loss: 0.0192036
[Epoch 112; Iter   171/  209] train: loss: 0.0215547
[Epoch 112; Iter   201/  209] train: loss: 0.0165164
[Epoch 112] ogbg-moltox21: 0.784192 val loss: 0.509023
[Epoch 112] ogbg-moltox21: 0.737782 test loss: 0.614981
[Epoch 113; Iter    22/  209] train: loss: 0.0153180
[Epoch 113; Iter    52/  209] train: loss: 0.0113330
[Epoch 113; Iter    82/  209] train: loss: 0.0112982
[Epoch 113; Iter   112/  209] train: loss: 0.0030362
[Epoch 113; Iter   142/  209] train: loss: 0.0101138
[Epoch 113; Iter   172/  209] train: loss: 0.0186932
[Epoch 113; Iter   202/  209] train: loss: 0.0158467
[Epoch 113] ogbg-moltox21: 0.789156 val loss: 0.511228
[Epoch 113] ogbg-moltox21: 0.739491 test loss: 0.609598
[Epoch 114; Iter    23/  209] train: loss: 0.0116210
[Epoch 114; Iter    53/  209] train: loss: 0.0160815
[Epoch 114; Iter    83/  209] train: loss: 0.0084415
[Epoch 114; Iter   113/  209] train: loss: 0.0155820
[Epoch 114; Iter   143/  209] train: loss: 0.0073168
[Epoch 114; Iter   173/  209] train: loss: 0.0065688
[Epoch 114; Iter   203/  209] train: loss: 0.0116759
[Epoch 114] ogbg-moltox21: 0.782524 val loss: 0.524219
[Epoch 114] ogbg-moltox21: 0.736246 test loss: 0.622787
[Epoch 115; Iter    24/  209] train: loss: 0.0082587
[Epoch 115; Iter    54/  209] train: loss: 0.0091312
[Epoch 115; Iter    84/  209] train: loss: 0.0159705
[Epoch 115; Iter   114/  209] train: loss: 0.0066891
[Epoch 115; Iter   144/  209] train: loss: 0.0079845
[Epoch 115; Iter   174/  209] train: loss: 0.0111383
[Epoch 115; Iter   204/  209] train: loss: 0.0269485
[Epoch 115] ogbg-moltox21: 0.783706 val loss: 0.520609
[Epoch 115] ogbg-moltox21: 0.736019 test loss: 0.616619
[Epoch 116; Iter    25/  209] train: loss: 0.0073229
[Epoch 116; Iter    55/  209] train: loss: 0.0152978
[Epoch 116; Iter    85/  209] train: loss: 0.0235312
[Epoch 116; Iter   115/  209] train: loss: 0.0099145
[Epoch 99; Iter   128/  209] train: loss: 0.0334126
[Epoch 99; Iter   158/  209] train: loss: 0.0241069
[Epoch 99; Iter   188/  209] train: loss: 0.0745134
[Epoch 99] ogbg-moltox21: 0.755780 val loss: 0.428671
[Epoch 99] ogbg-moltox21: 0.745639 test loss: 0.657239
[Epoch 100; Iter     9/  209] train: loss: 0.0531177
[Epoch 100; Iter    39/  209] train: loss: 0.0452944
[Epoch 100; Iter    69/  209] train: loss: 0.0414783
[Epoch 100; Iter    99/  209] train: loss: 0.0466032
[Epoch 100; Iter   129/  209] train: loss: 0.0614846
[Epoch 100; Iter   159/  209] train: loss: 0.0291854
[Epoch 100; Iter   189/  209] train: loss: 0.0444986
[Epoch 100] ogbg-moltox21: 0.753296 val loss: 0.429292
[Epoch 100] ogbg-moltox21: 0.739204 test loss: 0.590799
[Epoch 101; Iter    10/  209] train: loss: 0.0328815
[Epoch 101; Iter    40/  209] train: loss: 0.0682976
[Epoch 101; Iter    70/  209] train: loss: 0.0299572
[Epoch 101; Iter   100/  209] train: loss: 0.0206687
[Epoch 101; Iter   130/  209] train: loss: 0.0377840
[Epoch 101; Iter   160/  209] train: loss: 0.0346357
[Epoch 101; Iter   190/  209] train: loss: 0.0278012
[Epoch 101] ogbg-moltox21: 0.754613 val loss: 0.428807
[Epoch 101] ogbg-moltox21: 0.734512 test loss: 0.734964
[Epoch 102; Iter    11/  209] train: loss: 0.0222660
[Epoch 102; Iter    41/  209] train: loss: 0.0488730
[Epoch 102; Iter    71/  209] train: loss: 0.0155297
[Epoch 102; Iter   101/  209] train: loss: 0.0274010
[Epoch 102; Iter   131/  209] train: loss: 0.0678418
[Epoch 102; Iter   161/  209] train: loss: 0.0542315
[Epoch 102; Iter   191/  209] train: loss: 0.0373116
[Epoch 102] ogbg-moltox21: 0.746969 val loss: 0.419144
[Epoch 102] ogbg-moltox21: 0.735635 test loss: 0.426165
[Epoch 103; Iter    12/  209] train: loss: 0.0532071
[Epoch 103; Iter    42/  209] train: loss: 0.0476481
[Epoch 103; Iter    72/  209] train: loss: 0.0476982
[Epoch 103; Iter   102/  209] train: loss: 0.0261836
[Epoch 103; Iter   132/  209] train: loss: 0.0570169
[Epoch 103; Iter   162/  209] train: loss: 0.0541261
[Epoch 103; Iter   192/  209] train: loss: 0.0493054
[Epoch 103] ogbg-moltox21: 0.746344 val loss: 0.427763
[Epoch 103] ogbg-moltox21: 0.731473 test loss: 0.431453
[Epoch 104; Iter    13/  209] train: loss: 0.0396254
[Epoch 104; Iter    43/  209] train: loss: 0.0627845
[Epoch 104; Iter    73/  209] train: loss: 0.0399796
[Epoch 104; Iter   103/  209] train: loss: 0.0383448
[Epoch 104; Iter   133/  209] train: loss: 0.0402718
[Epoch 104; Iter   163/  209] train: loss: 0.0168751
[Epoch 104; Iter   193/  209] train: loss: 0.0638300
[Epoch 104] ogbg-moltox21: 0.754614 val loss: 0.426680
[Epoch 104] ogbg-moltox21: 0.744716 test loss: 0.423354
[Epoch 105; Iter    14/  209] train: loss: 0.0622946
[Epoch 105; Iter    44/  209] train: loss: 0.0395317
[Epoch 105; Iter    74/  209] train: loss: 0.0506460
[Epoch 105; Iter   104/  209] train: loss: 0.0315478
[Epoch 105; Iter   134/  209] train: loss: 0.0318468
[Epoch 105; Iter   164/  209] train: loss: 0.0331592
[Epoch 105; Iter   194/  209] train: loss: 0.0424168
[Epoch 105] ogbg-moltox21: 0.756205 val loss: 0.431213
[Epoch 105] ogbg-moltox21: 0.743465 test loss: 0.473405
[Epoch 106; Iter    15/  209] train: loss: 0.0234409
[Epoch 106; Iter    45/  209] train: loss: 0.0419248
[Epoch 106; Iter    75/  209] train: loss: 0.0376207
[Epoch 106; Iter   105/  209] train: loss: 0.0825606
[Epoch 106; Iter   135/  209] train: loss: 0.0316232
[Epoch 106; Iter   165/  209] train: loss: 0.0479730
[Epoch 106; Iter   195/  209] train: loss: 0.0305756
[Epoch 106] ogbg-moltox21: 0.746247 val loss: 0.445624
[Epoch 106] ogbg-moltox21: 0.739585 test loss: 0.647927
[Epoch 107; Iter    16/  209] train: loss: 0.0409674
[Epoch 107; Iter    46/  209] train: loss: 0.0509329
[Epoch 107; Iter    76/  209] train: loss: 0.0328820
[Epoch 107; Iter   106/  209] train: loss: 0.0417772
[Epoch 107; Iter   136/  209] train: loss: 0.0450011
[Epoch 107; Iter   166/  209] train: loss: 0.0396282
[Epoch 107; Iter   196/  209] train: loss: 0.0250267
[Epoch 107] ogbg-moltox21: 0.751982 val loss: 0.434531
[Epoch 107] ogbg-moltox21: 0.739690 test loss: 0.437663
[Epoch 108; Iter    17/  209] train: loss: 0.0472370
[Epoch 108; Iter    47/  209] train: loss: 0.0306191
[Epoch 108; Iter    77/  209] train: loss: 0.0455847
[Epoch 108; Iter   107/  209] train: loss: 0.0383068
[Epoch 108; Iter   137/  209] train: loss: 0.0189332
[Epoch 108; Iter   167/  209] train: loss: 0.0540576
[Epoch 108; Iter   197/  209] train: loss: 0.0315781
[Epoch 108] ogbg-moltox21: 0.747674 val loss: 0.425068
[Epoch 108] ogbg-moltox21: 0.741651 test loss: 0.421512
[Epoch 109; Iter    18/  209] train: loss: 0.0583067
[Epoch 109; Iter    48/  209] train: loss: 0.0527312
[Epoch 109; Iter    78/  209] train: loss: 0.0293566
[Epoch 109; Iter   108/  209] train: loss: 0.0417269
[Epoch 109; Iter   138/  209] train: loss: 0.0262891
[Epoch 109; Iter   168/  209] train: loss: 0.0300256
[Epoch 109; Iter   198/  209] train: loss: 0.0536683
[Epoch 109] ogbg-moltox21: 0.749776 val loss: 0.431370
[Epoch 109] ogbg-moltox21: 0.741981 test loss: 0.434062
[Epoch 110; Iter    19/  209] train: loss: 0.0489568
[Epoch 110; Iter    49/  209] train: loss: 0.0266936
[Epoch 110; Iter    79/  209] train: loss: 0.0423468
[Epoch 110; Iter   109/  209] train: loss: 0.0481045
[Epoch 110; Iter   139/  209] train: loss: 0.0680405
[Epoch 110; Iter   169/  209] train: loss: 0.0173763
[Epoch 110; Iter   199/  209] train: loss: 0.0368875
[Epoch 110] ogbg-moltox21: 0.752629 val loss: 0.434700
[Epoch 110] ogbg-moltox21: 0.744099 test loss: 0.439284
[Epoch 111; Iter    20/  209] train: loss: 0.0540273
[Epoch 111; Iter    50/  209] train: loss: 0.0202372
[Epoch 111; Iter    80/  209] train: loss: 0.0357138
[Epoch 111; Iter   110/  209] train: loss: 0.0627536
[Epoch 111; Iter   140/  209] train: loss: 0.0273925
[Epoch 111; Iter   170/  209] train: loss: 0.0618848
[Epoch 111; Iter   200/  209] train: loss: 0.0130648
[Epoch 111] ogbg-moltox21: 0.751521 val loss: 0.451875
[Epoch 111] ogbg-moltox21: 0.739398 test loss: 0.450596
[Epoch 112; Iter    21/  209] train: loss: 0.0273619
[Epoch 112; Iter    51/  209] train: loss: 0.0312279
[Epoch 112; Iter    81/  209] train: loss: 0.0345842
[Epoch 112; Iter   111/  209] train: loss: 0.0490530
[Epoch 112; Iter   141/  209] train: loss: 0.0271150
[Epoch 112; Iter   171/  209] train: loss: 0.0309044
[Epoch 112; Iter   201/  209] train: loss: 0.0297596
[Epoch 112] ogbg-moltox21: 0.745011 val loss: 0.467299
[Epoch 112] ogbg-moltox21: 0.740891 test loss: 0.469444
[Epoch 113; Iter    22/  209] train: loss: 0.1083174
[Epoch 113; Iter    52/  209] train: loss: 0.0307885
[Epoch 113; Iter    82/  209] train: loss: 0.0687491
[Epoch 113; Iter   112/  209] train: loss: 0.0537232
[Epoch 113; Iter   142/  209] train: loss: 0.0412300
[Epoch 113; Iter   172/  209] train: loss: 0.0261733
[Epoch 113; Iter   202/  209] train: loss: 0.0431966
[Epoch 113] ogbg-moltox21: 0.748517 val loss: 0.441117
[Epoch 113] ogbg-moltox21: 0.737029 test loss: 0.445989
[Epoch 114; Iter    23/  209] train: loss: 0.1361612
[Epoch 114; Iter    53/  209] train: loss: 0.0349277
[Epoch 114; Iter    83/  209] train: loss: 0.0489355
[Epoch 114; Iter   113/  209] train: loss: 0.0278869
[Epoch 114; Iter   143/  209] train: loss: 0.0407022
[Epoch 114; Iter   173/  209] train: loss: 0.0375900
[Epoch 114; Iter   203/  209] train: loss: 0.0505008
[Epoch 114] ogbg-moltox21: 0.737611 val loss: 0.452217
[Epoch 114] ogbg-moltox21: 0.734263 test loss: 0.444064
[Epoch 115; Iter    24/  209] train: loss: 0.0358991
[Epoch 115; Iter    54/  209] train: loss: 0.0258112
[Epoch 115; Iter    84/  209] train: loss: 0.0431973
[Epoch 115; Iter   114/  209] train: loss: 0.0175600
[Epoch 115; Iter   144/  209] train: loss: 0.0254479
[Epoch 115; Iter   174/  209] train: loss: 0.0336829
[Epoch 115; Iter   204/  209] train: loss: 0.0181097
[Epoch 115] ogbg-moltox21: 0.753187 val loss: 0.442209
[Epoch 115] ogbg-moltox21: 0.739241 test loss: 0.444918
[Epoch 116; Iter    25/  209] train: loss: 0.0669816
[Epoch 116; Iter    55/  209] train: loss: 0.0181339
[Epoch 116; Iter    85/  209] train: loss: 0.0372543
[Epoch 116; Iter   115/  209] train: loss: 0.0265866
[Epoch 99; Iter   128/  209] train: loss: 0.0028961
[Epoch 99; Iter   158/  209] train: loss: 0.0059543
[Epoch 99; Iter   188/  209] train: loss: 0.0042148
[Epoch 99] ogbg-moltox21: 0.715270 val loss: 0.985437
[Epoch 99] ogbg-moltox21: 0.672900 test loss: 1.066037
[Epoch 100; Iter     9/  209] train: loss: 0.0032460
[Epoch 100; Iter    39/  209] train: loss: 0.0019880
[Epoch 100; Iter    69/  209] train: loss: 0.0102089
[Epoch 100; Iter    99/  209] train: loss: 0.0019369
[Epoch 100; Iter   129/  209] train: loss: 0.0019189
[Epoch 100; Iter   159/  209] train: loss: 0.0042030
[Epoch 100; Iter   189/  209] train: loss: 0.0015954
[Epoch 100] ogbg-moltox21: 0.714062 val loss: 1.009884
[Epoch 100] ogbg-moltox21: 0.684983 test loss: 1.115247
[Epoch 101; Iter    10/  209] train: loss: 0.0178513
[Epoch 101; Iter    40/  209] train: loss: 0.0016195
[Epoch 101; Iter    70/  209] train: loss: 0.0042490
[Epoch 101; Iter   100/  209] train: loss: 0.0064881
[Epoch 101; Iter   130/  209] train: loss: 0.0050819
[Epoch 101; Iter   160/  209] train: loss: 0.0044273
[Epoch 101; Iter   190/  209] train: loss: 0.0023964
[Epoch 101] ogbg-moltox21: 0.716741 val loss: 1.053845
[Epoch 101] ogbg-moltox21: 0.685840 test loss: 1.175922
[Epoch 102; Iter    11/  209] train: loss: 0.0021854
[Epoch 102; Iter    41/  209] train: loss: 0.0015600
[Epoch 102; Iter    71/  209] train: loss: 0.0012123
[Epoch 102; Iter   101/  209] train: loss: 0.0042844
[Epoch 102; Iter   131/  209] train: loss: 0.0085078
[Epoch 102; Iter   161/  209] train: loss: 0.0029339
[Epoch 102; Iter   191/  209] train: loss: 0.0023322
[Epoch 102] ogbg-moltox21: 0.710405 val loss: 1.048311
[Epoch 102] ogbg-moltox21: 0.678325 test loss: 1.152432
[Epoch 103; Iter    12/  209] train: loss: 0.0084327
[Epoch 103; Iter    42/  209] train: loss: 0.0130457
[Epoch 103; Iter    72/  209] train: loss: 0.0039542
[Epoch 103; Iter   102/  209] train: loss: 0.0014606
[Epoch 103; Iter   132/  209] train: loss: 0.0033867
[Epoch 103; Iter   162/  209] train: loss: 0.0082766
[Epoch 103; Iter   192/  209] train: loss: 0.0014600
[Epoch 103] ogbg-moltox21: 0.718086 val loss: 1.013968
[Epoch 103] ogbg-moltox21: 0.674806 test loss: 1.149763
[Epoch 104; Iter    13/  209] train: loss: 0.0049249
[Epoch 104; Iter    43/  209] train: loss: 0.0021991
[Epoch 104; Iter    73/  209] train: loss: 0.0040124
[Epoch 104; Iter   103/  209] train: loss: 0.0007370
[Epoch 104; Iter   133/  209] train: loss: 0.0070546
[Epoch 104; Iter   163/  209] train: loss: 0.0121440
[Epoch 104; Iter   193/  209] train: loss: 0.0028273
[Epoch 104] ogbg-moltox21: 0.717804 val loss: 1.062080
[Epoch 104] ogbg-moltox21: 0.676865 test loss: 1.222314
[Epoch 105; Iter    14/  209] train: loss: 0.0012571
[Epoch 105; Iter    44/  209] train: loss: 0.0013408
[Epoch 105; Iter    74/  209] train: loss: 0.0024940
[Epoch 105; Iter   104/  209] train: loss: 0.0019004
[Epoch 105; Iter   134/  209] train: loss: 0.0041050
[Epoch 105; Iter   164/  209] train: loss: 0.0048654
[Epoch 105; Iter   194/  209] train: loss: 0.0015956
[Epoch 105] ogbg-moltox21: 0.722620 val loss: 0.999348
[Epoch 105] ogbg-moltox21: 0.678905 test loss: 1.124398
[Epoch 106; Iter    15/  209] train: loss: 0.0035487
[Epoch 106; Iter    45/  209] train: loss: 0.0016835
[Epoch 106; Iter    75/  209] train: loss: 0.0036384
[Epoch 106; Iter   105/  209] train: loss: 0.0098130
[Epoch 106; Iter   135/  209] train: loss: 0.0073449
[Epoch 106; Iter   165/  209] train: loss: 0.0024107
[Epoch 106; Iter   195/  209] train: loss: 0.0019457
[Epoch 106] ogbg-moltox21: 0.725224 val loss: 1.077956
[Epoch 106] ogbg-moltox21: 0.670881 test loss: 1.256460
[Epoch 107; Iter    16/  209] train: loss: 0.0042939
[Epoch 107; Iter    46/  209] train: loss: 0.0060339
[Epoch 107; Iter    76/  209] train: loss: 0.0068351
[Epoch 107; Iter   106/  209] train: loss: 0.0028810
[Epoch 107; Iter   136/  209] train: loss: 0.0019539
[Epoch 107; Iter   166/  209] train: loss: 0.0040552
[Epoch 107; Iter   196/  209] train: loss: 0.0066177
[Epoch 107] ogbg-moltox21: 0.715221 val loss: 1.133653
[Epoch 107] ogbg-moltox21: 0.671575 test loss: 1.275235
[Epoch 108; Iter    17/  209] train: loss: 0.0040636
[Epoch 108; Iter    47/  209] train: loss: 0.0015508
[Epoch 108; Iter    77/  209] train: loss: 0.0014256
[Epoch 108; Iter   107/  209] train: loss: 0.0042187
[Epoch 108; Iter   137/  209] train: loss: 0.0088391
[Epoch 108; Iter   167/  209] train: loss: 0.0020583
[Epoch 108; Iter   197/  209] train: loss: 0.0035985
[Epoch 108] ogbg-moltox21: 0.717133 val loss: 1.091751
[Epoch 108] ogbg-moltox21: 0.675727 test loss: 1.216855
[Epoch 109; Iter    18/  209] train: loss: 0.0041329
[Epoch 109; Iter    48/  209] train: loss: 0.0018142
[Epoch 109; Iter    78/  209] train: loss: 0.0015841
[Epoch 109; Iter   108/  209] train: loss: 0.0052347
[Epoch 109; Iter   138/  209] train: loss: 0.0016033
[Epoch 109; Iter   168/  209] train: loss: 0.0067180
[Epoch 109; Iter   198/  209] train: loss: 0.0096367
[Epoch 109] ogbg-moltox21: 0.710916 val loss: 1.116782
[Epoch 109] ogbg-moltox21: 0.675442 test loss: 1.230325
[Epoch 110; Iter    19/  209] train: loss: 0.0008880
[Epoch 110; Iter    49/  209] train: loss: 0.0030304
[Epoch 110; Iter    79/  209] train: loss: 0.0035963
[Epoch 110; Iter   109/  209] train: loss: 0.0048500
[Epoch 110; Iter   139/  209] train: loss: 0.0066614
[Epoch 110; Iter   169/  209] train: loss: 0.0044902
[Epoch 110; Iter   199/  209] train: loss: 0.0024547
[Epoch 110] ogbg-moltox21: 0.719820 val loss: 1.052515
[Epoch 110] ogbg-moltox21: 0.681127 test loss: 1.197830
[Epoch 111; Iter    20/  209] train: loss: 0.0256932
[Epoch 111; Iter    50/  209] train: loss: 0.0044734
[Epoch 111; Iter    80/  209] train: loss: 0.0054073
[Epoch 111; Iter   110/  209] train: loss: 0.0027502
[Epoch 111; Iter   140/  209] train: loss: 0.0042418
[Epoch 111; Iter   170/  209] train: loss: 0.0058546
[Epoch 111; Iter   200/  209] train: loss: 0.0135693
[Epoch 111] ogbg-moltox21: 0.714538 val loss: 1.096401
[Epoch 111] ogbg-moltox21: 0.674105 test loss: 1.250877
[Epoch 112; Iter    21/  209] train: loss: 0.0026114
[Epoch 112; Iter    51/  209] train: loss: 0.0029061
[Epoch 112; Iter    81/  209] train: loss: 0.0019269
[Epoch 112; Iter   111/  209] train: loss: 0.0051385
[Epoch 112; Iter   141/  209] train: loss: 0.0061238
[Epoch 112; Iter   171/  209] train: loss: 0.0061673
[Epoch 112; Iter   201/  209] train: loss: 0.0037578
[Epoch 112] ogbg-moltox21: 0.714291 val loss: 1.129540
[Epoch 112] ogbg-moltox21: 0.673593 test loss: 1.254579
[Epoch 113; Iter    22/  209] train: loss: 0.0009576
[Epoch 113; Iter    52/  209] train: loss: 0.0044473
[Epoch 113; Iter    82/  209] train: loss: 0.0031097
[Epoch 113; Iter   112/  209] train: loss: 0.0101830
[Epoch 113; Iter   142/  209] train: loss: 0.0106612
[Epoch 113; Iter   172/  209] train: loss: 0.0051120
[Epoch 113; Iter   202/  209] train: loss: 0.0024462
[Epoch 113] ogbg-moltox21: 0.711379 val loss: 1.228656
[Epoch 113] ogbg-moltox21: 0.670575 test loss: 1.389723
[Epoch 114; Iter    23/  209] train: loss: 0.0013815
[Epoch 114; Iter    53/  209] train: loss: 0.0019297
[Epoch 114; Iter    83/  209] train: loss: 0.0071900
[Epoch 114; Iter   113/  209] train: loss: 0.0047078
[Epoch 114; Iter   143/  209] train: loss: 0.0024548
[Epoch 114; Iter   173/  209] train: loss: 0.0018487
[Epoch 114; Iter   203/  209] train: loss: 0.0029970
[Epoch 114] ogbg-moltox21: 0.708139 val loss: 1.175778
[Epoch 114] ogbg-moltox21: 0.664864 test loss: 1.356920
[Epoch 115; Iter    24/  209] train: loss: 0.0006245
[Epoch 115; Iter    54/  209] train: loss: 0.0016265
[Epoch 115; Iter    84/  209] train: loss: 0.0018982
[Epoch 115; Iter   114/  209] train: loss: 0.0036348
[Epoch 115; Iter   144/  209] train: loss: 0.0019866
[Epoch 115; Iter   174/  209] train: loss: 0.0124629
[Epoch 115; Iter   204/  209] train: loss: 0.0033764
[Epoch 115] ogbg-moltox21: 0.714850 val loss: 1.173063
[Epoch 115] ogbg-moltox21: 0.675682 test loss: 1.330297
[Epoch 116; Iter    25/  209] train: loss: 0.0175002
[Epoch 116; Iter    55/  209] train: loss: 0.0039384
[Epoch 116; Iter    85/  209] train: loss: 0.0020915
[Epoch 116; Iter   115/  209] train: loss: 0.0019418
[Epoch 99; Iter   128/  209] train: loss: 0.0215772
[Epoch 99; Iter   158/  209] train: loss: 0.0212801
[Epoch 99; Iter   188/  209] train: loss: 0.0268380
[Epoch 99] ogbg-moltox21: 0.750129 val loss: 0.673415
[Epoch 99] ogbg-moltox21: 0.718623 test loss: 0.800535
[Epoch 100; Iter     9/  209] train: loss: 0.0089155
[Epoch 100; Iter    39/  209] train: loss: 0.0338146
[Epoch 100; Iter    69/  209] train: loss: 0.0137994
[Epoch 100; Iter    99/  209] train: loss: 0.0475835
[Epoch 100; Iter   129/  209] train: loss: 0.0213948
[Epoch 100; Iter   159/  209] train: loss: 0.0342701
[Epoch 100; Iter   189/  209] train: loss: 0.0182968
[Epoch 100] ogbg-moltox21: 0.747361 val loss: 0.672042
[Epoch 100] ogbg-moltox21: 0.706771 test loss: 0.770861
[Epoch 101; Iter    10/  209] train: loss: 0.0110965
[Epoch 101; Iter    40/  209] train: loss: 0.0116464
[Epoch 101; Iter    70/  209] train: loss: 0.0093392
[Epoch 101; Iter   100/  209] train: loss: 0.0227797
[Epoch 101; Iter   130/  209] train: loss: 0.0238791
[Epoch 101; Iter   160/  209] train: loss: 0.0181292
[Epoch 101; Iter   190/  209] train: loss: 0.0216301
[Epoch 101] ogbg-moltox21: 0.742741 val loss: 0.621869
[Epoch 101] ogbg-moltox21: 0.707827 test loss: 0.721274
[Epoch 102; Iter    11/  209] train: loss: 0.0148992
[Epoch 102; Iter    41/  209] train: loss: 0.0273542
[Epoch 102; Iter    71/  209] train: loss: 0.0150429
[Epoch 102; Iter   101/  209] train: loss: 0.0142911
[Epoch 102; Iter   131/  209] train: loss: 0.0119948
[Epoch 102; Iter   161/  209] train: loss: 0.0197980
[Epoch 102; Iter   191/  209] train: loss: 0.0130592
[Epoch 102] ogbg-moltox21: 0.737350 val loss: 0.640718
[Epoch 102] ogbg-moltox21: 0.717023 test loss: 0.713092
[Epoch 103; Iter    12/  209] train: loss: 0.0174733
[Epoch 103; Iter    42/  209] train: loss: 0.0124897
[Epoch 103; Iter    72/  209] train: loss: 0.0143249
[Epoch 103; Iter   102/  209] train: loss: 0.0116028
[Epoch 103; Iter   132/  209] train: loss: 0.0382940
[Epoch 103; Iter   162/  209] train: loss: 0.0641726
[Epoch 103; Iter   192/  209] train: loss: 0.0097744
[Epoch 103] ogbg-moltox21: 0.749777 val loss: 0.636201
[Epoch 103] ogbg-moltox21: 0.710372 test loss: 0.788579
[Epoch 104; Iter    13/  209] train: loss: 0.0104447
[Epoch 104; Iter    43/  209] train: loss: 0.0246875
[Epoch 104; Iter    73/  209] train: loss: 0.0105744
[Epoch 104; Iter   103/  209] train: loss: 0.0245361
[Epoch 104; Iter   133/  209] train: loss: 0.0108605
[Epoch 104; Iter   163/  209] train: loss: 0.0239795
[Epoch 104; Iter   193/  209] train: loss: 0.0182813
[Epoch 104] ogbg-moltox21: 0.753018 val loss: 0.644883
[Epoch 104] ogbg-moltox21: 0.716055 test loss: 0.773187
[Epoch 105; Iter    14/  209] train: loss: 0.0127397
[Epoch 105; Iter    44/  209] train: loss: 0.0170919
[Epoch 105; Iter    74/  209] train: loss: 0.0199407
[Epoch 105; Iter   104/  209] train: loss: 0.0338047
[Epoch 105; Iter   134/  209] train: loss: 0.0179060
[Epoch 105; Iter   164/  209] train: loss: 0.0206651
[Epoch 105; Iter   194/  209] train: loss: 0.0259364
[Epoch 105] ogbg-moltox21: 0.746719 val loss: 0.632082
[Epoch 105] ogbg-moltox21: 0.712016 test loss: 0.731401
[Epoch 106; Iter    15/  209] train: loss: 0.0077873
[Epoch 106; Iter    45/  209] train: loss: 0.0188303
[Epoch 106; Iter    75/  209] train: loss: 0.0187646
[Epoch 106; Iter   105/  209] train: loss: 0.0067896
[Epoch 106; Iter   135/  209] train: loss: 0.0441744
[Epoch 106; Iter   165/  209] train: loss: 0.0097613
[Epoch 106; Iter   195/  209] train: loss: 0.0092254
[Epoch 106] ogbg-moltox21: 0.744664 val loss: 0.680487
[Epoch 106] ogbg-moltox21: 0.715083 test loss: 0.767477
[Epoch 107; Iter    16/  209] train: loss: 0.0115829
[Epoch 107; Iter    46/  209] train: loss: 0.0076216
[Epoch 107; Iter    76/  209] train: loss: 0.0637278
[Epoch 107; Iter   106/  209] train: loss: 0.0066064
[Epoch 107; Iter   136/  209] train: loss: 0.0028044
[Epoch 107; Iter   166/  209] train: loss: 0.0409920
[Epoch 107; Iter   196/  209] train: loss: 0.0040119
[Epoch 107] ogbg-moltox21: 0.742433 val loss: 0.620426
[Epoch 107] ogbg-moltox21: 0.716639 test loss: 0.699796
[Epoch 108; Iter    17/  209] train: loss: 0.0188390
[Epoch 108; Iter    47/  209] train: loss: 0.0170464
[Epoch 108; Iter    77/  209] train: loss: 0.0066775
[Epoch 108; Iter   107/  209] train: loss: 0.0238616
[Epoch 108; Iter   137/  209] train: loss: 0.0291380
[Epoch 108; Iter   167/  209] train: loss: 0.0240067
[Epoch 108; Iter   197/  209] train: loss: 0.0102361
[Epoch 108] ogbg-moltox21: 0.754103 val loss: 0.651888
[Epoch 108] ogbg-moltox21: 0.716896 test loss: 0.775656
[Epoch 109; Iter    18/  209] train: loss: 0.0211122
[Epoch 109; Iter    48/  209] train: loss: 0.0038178
[Epoch 109; Iter    78/  209] train: loss: 0.0184262
[Epoch 109; Iter   108/  209] train: loss: 0.0201614
[Epoch 109; Iter   138/  209] train: loss: 0.0068352
[Epoch 109; Iter   168/  209] train: loss: 0.0052107
[Epoch 109; Iter   198/  209] train: loss: 0.0176486
[Epoch 109] ogbg-moltox21: 0.746719 val loss: 0.673739
[Epoch 109] ogbg-moltox21: 0.717695 test loss: 0.757639
[Epoch 110; Iter    19/  209] train: loss: 0.0047725
[Epoch 110; Iter    49/  209] train: loss: 0.0152556
[Epoch 110; Iter    79/  209] train: loss: 0.0087801
[Epoch 110; Iter   109/  209] train: loss: 0.0320292
[Epoch 110; Iter   139/  209] train: loss: 0.0246406
[Epoch 110; Iter   169/  209] train: loss: 0.0164503
[Epoch 110; Iter   199/  209] train: loss: 0.0118937
[Epoch 110] ogbg-moltox21: 0.746152 val loss: 0.666757
[Epoch 110] ogbg-moltox21: 0.713632 test loss: 0.755368
[Epoch 111; Iter    20/  209] train: loss: 0.0243936
[Epoch 111; Iter    50/  209] train: loss: 0.0300318
[Epoch 111; Iter    80/  209] train: loss: 0.0087640
[Epoch 111; Iter   110/  209] train: loss: 0.0200741
[Epoch 111; Iter   140/  209] train: loss: 0.0235578
[Epoch 111; Iter   170/  209] train: loss: 0.0123490
[Epoch 111; Iter   200/  209] train: loss: 0.0174353
[Epoch 111] ogbg-moltox21: 0.753315 val loss: 0.692255
[Epoch 111] ogbg-moltox21: 0.719341 test loss: 0.776433
[Epoch 112; Iter    21/  209] train: loss: 0.0064849
[Epoch 112; Iter    51/  209] train: loss: 0.0163991
[Epoch 112; Iter    81/  209] train: loss: 0.0111220
[Epoch 112; Iter   111/  209] train: loss: 0.0251404
[Epoch 112; Iter   141/  209] train: loss: 0.0140535
[Epoch 112; Iter   171/  209] train: loss: 0.0092789
[Epoch 112; Iter   201/  209] train: loss: 0.0423543
[Epoch 112] ogbg-moltox21: 0.745271 val loss: 0.684337
[Epoch 112] ogbg-moltox21: 0.716434 test loss: 0.744557
[Epoch 113; Iter    22/  209] train: loss: 0.0189477
[Epoch 113; Iter    52/  209] train: loss: 0.0068058
[Epoch 113; Iter    82/  209] train: loss: 0.0109930
[Epoch 113; Iter   112/  209] train: loss: 0.0210508
[Epoch 113; Iter   142/  209] train: loss: 0.0144912
[Epoch 113; Iter   172/  209] train: loss: 0.0265658
[Epoch 113; Iter   202/  209] train: loss: 0.0090404
[Epoch 113] ogbg-moltox21: 0.757297 val loss: 0.674117
[Epoch 113] ogbg-moltox21: 0.715129 test loss: 0.794081
[Epoch 114; Iter    23/  209] train: loss: 0.0110310
[Epoch 114; Iter    53/  209] train: loss: 0.0156188
[Epoch 114; Iter    83/  209] train: loss: 0.0111018
[Epoch 114; Iter   113/  209] train: loss: 0.0234878
[Epoch 114; Iter   143/  209] train: loss: 0.0133604
[Epoch 114; Iter   173/  209] train: loss: 0.0073401
[Epoch 114; Iter   203/  209] train: loss: 0.0219470
[Epoch 114] ogbg-moltox21: 0.764138 val loss: 0.694121
[Epoch 114] ogbg-moltox21: 0.723691 test loss: 0.829133
[Epoch 115; Iter    24/  209] train: loss: 0.0097918
[Epoch 115; Iter    54/  209] train: loss: 0.0057899
[Epoch 115; Iter    84/  209] train: loss: 0.0304177
[Epoch 115; Iter   114/  209] train: loss: 0.0134567
[Epoch 115; Iter   144/  209] train: loss: 0.0094497
[Epoch 115; Iter   174/  209] train: loss: 0.0420710
[Epoch 115; Iter   204/  209] train: loss: 0.0338758
[Epoch 115] ogbg-moltox21: 0.750222 val loss: 0.699987
[Epoch 115] ogbg-moltox21: 0.715924 test loss: 0.825528
[Epoch 116; Iter    25/  209] train: loss: 0.0223427
[Epoch 116; Iter    55/  209] train: loss: 0.0256592
[Epoch 116; Iter    85/  209] train: loss: 0.0465710
[Epoch 116; Iter   115/  209] train: loss: 0.0207350
[Epoch 99; Iter   128/  209] train: loss: 0.0086332
[Epoch 99; Iter   158/  209] train: loss: 0.0072723
[Epoch 99; Iter   188/  209] train: loss: 0.0293760
[Epoch 99] ogbg-moltox21: 0.698704 val loss: 0.676499
[Epoch 99] ogbg-moltox21: 0.699339 test loss: 0.704040
[Epoch 100; Iter     9/  209] train: loss: 0.0187214
[Epoch 100; Iter    39/  209] train: loss: 0.0220546
[Epoch 100; Iter    69/  209] train: loss: 0.0161367
[Epoch 100; Iter    99/  209] train: loss: 0.0109834
[Epoch 100; Iter   129/  209] train: loss: 0.0222428
[Epoch 100; Iter   159/  209] train: loss: 0.0085742
[Epoch 100; Iter   189/  209] train: loss: 0.0164461
[Epoch 100] ogbg-moltox21: 0.693164 val loss: 0.702378
[Epoch 100] ogbg-moltox21: 0.693775 test loss: 0.709220
[Epoch 101; Iter    10/  209] train: loss: 0.0159453
[Epoch 101; Iter    40/  209] train: loss: 0.0121530
[Epoch 101; Iter    70/  209] train: loss: 0.0115770
[Epoch 101; Iter   100/  209] train: loss: 0.0108805
[Epoch 101; Iter   130/  209] train: loss: 0.0065034
[Epoch 101; Iter   160/  209] train: loss: 0.0156123
[Epoch 101; Iter   190/  209] train: loss: 0.0143947
[Epoch 101] ogbg-moltox21: 0.690123 val loss: 0.676332
[Epoch 101] ogbg-moltox21: 0.690411 test loss: 0.701248
[Epoch 102; Iter    11/  209] train: loss: 0.0139426
[Epoch 102; Iter    41/  209] train: loss: 0.0145219
[Epoch 102; Iter    71/  209] train: loss: 0.0089574
[Epoch 102; Iter   101/  209] train: loss: 0.0095472
[Epoch 102; Iter   131/  209] train: loss: 0.0189200
[Epoch 102; Iter   161/  209] train: loss: 0.0176161
[Epoch 102; Iter   191/  209] train: loss: 0.0109988
[Epoch 102] ogbg-moltox21: 0.686223 val loss: 0.644735
[Epoch 102] ogbg-moltox21: 0.694467 test loss: 0.658996
[Epoch 103; Iter    12/  209] train: loss: 0.0123875
[Epoch 103; Iter    42/  209] train: loss: 0.0137107
[Epoch 103; Iter    72/  209] train: loss: 0.0196006
[Epoch 103; Iter   102/  209] train: loss: 0.0057831
[Epoch 103; Iter   132/  209] train: loss: 0.0127604
[Epoch 103; Iter   162/  209] train: loss: 0.0130964
[Epoch 103; Iter   192/  209] train: loss: 0.0106482
[Epoch 103] ogbg-moltox21: 0.692132 val loss: 0.664733
[Epoch 103] ogbg-moltox21: 0.697741 test loss: 0.677558
[Epoch 104; Iter    13/  209] train: loss: 0.0109740
[Epoch 104; Iter    43/  209] train: loss: 0.0204246
[Epoch 104; Iter    73/  209] train: loss: 0.0087997
[Epoch 104; Iter   103/  209] train: loss: 0.0088144
[Epoch 104; Iter   133/  209] train: loss: 0.0085854
[Epoch 104; Iter   163/  209] train: loss: 0.0073172
[Epoch 104; Iter   193/  209] train: loss: 0.0113166
[Epoch 104] ogbg-moltox21: 0.684819 val loss: 0.711106
[Epoch 104] ogbg-moltox21: 0.690685 test loss: 0.686427
[Epoch 105; Iter    14/  209] train: loss: 0.0259521
[Epoch 105; Iter    44/  209] train: loss: 0.0098388
[Epoch 105; Iter    74/  209] train: loss: 0.0163136
[Epoch 105; Iter   104/  209] train: loss: 0.0230937
[Epoch 105; Iter   134/  209] train: loss: 0.0129564
[Epoch 105; Iter   164/  209] train: loss: 0.0087788
[Epoch 105; Iter   194/  209] train: loss: 0.0201300
[Epoch 105] ogbg-moltox21: 0.684692 val loss: 0.712322
[Epoch 105] ogbg-moltox21: 0.688386 test loss: 0.737289
[Epoch 106; Iter    15/  209] train: loss: 0.0116632
[Epoch 106; Iter    45/  209] train: loss: 0.0276094
[Epoch 106; Iter    75/  209] train: loss: 0.0022204
[Epoch 106; Iter   105/  209] train: loss: 0.0314793
[Epoch 106; Iter   135/  209] train: loss: 0.0091210
[Epoch 106; Iter   165/  209] train: loss: 0.0098920
[Epoch 106; Iter   195/  209] train: loss: 0.0039032
[Epoch 106] ogbg-moltox21: 0.690636 val loss: 0.691480
[Epoch 106] ogbg-moltox21: 0.693058 test loss: 0.712757
[Epoch 107; Iter    16/  209] train: loss: 0.0088345
[Epoch 107; Iter    46/  209] train: loss: 0.0104034
[Epoch 107; Iter    76/  209] train: loss: 0.0064366
[Epoch 107; Iter   106/  209] train: loss: 0.0147215
[Epoch 107; Iter   136/  209] train: loss: 0.0258322
[Epoch 107; Iter   166/  209] train: loss: 0.0225387
[Epoch 107; Iter   196/  209] train: loss: 0.0230226
[Epoch 107] ogbg-moltox21: 0.688954 val loss: 0.683982
[Epoch 107] ogbg-moltox21: 0.693166 test loss: 0.702629
[Epoch 108; Iter    17/  209] train: loss: 0.0262938
[Epoch 108; Iter    47/  209] train: loss: 0.0086080
[Epoch 108; Iter    77/  209] train: loss: 0.0202671
[Epoch 108; Iter   107/  209] train: loss: 0.0209272
[Epoch 108; Iter   137/  209] train: loss: 0.0097326
[Epoch 108; Iter   167/  209] train: loss: 0.0177404
[Epoch 108; Iter   197/  209] train: loss: 0.0077524
[Epoch 108] ogbg-moltox21: 0.688881 val loss: 0.684873
[Epoch 108] ogbg-moltox21: 0.691029 test loss: 0.707516
[Epoch 109; Iter    18/  209] train: loss: 0.0122664
[Epoch 109; Iter    48/  209] train: loss: 0.0250513
[Epoch 109; Iter    78/  209] train: loss: 0.0300972
[Epoch 109; Iter   108/  209] train: loss: 0.0150119
[Epoch 109; Iter   138/  209] train: loss: 0.0126154
[Epoch 109; Iter   168/  209] train: loss: 0.0114119
[Epoch 109; Iter   198/  209] train: loss: 0.0173623
[Epoch 109] ogbg-moltox21: 0.680934 val loss: 0.744491
[Epoch 109] ogbg-moltox21: 0.686193 test loss: 0.727426
[Epoch 110; Iter    19/  209] train: loss: 0.0079319
[Epoch 110; Iter    49/  209] train: loss: 0.0118249
[Epoch 110; Iter    79/  209] train: loss: 0.0086751
[Epoch 110; Iter   109/  209] train: loss: 0.0118511
[Epoch 110; Iter   139/  209] train: loss: 0.0203083
[Epoch 110; Iter   169/  209] train: loss: 0.0083785
[Epoch 110; Iter   199/  209] train: loss: 0.0210124
[Epoch 110] ogbg-moltox21: 0.683157 val loss: 0.702515
[Epoch 110] ogbg-moltox21: 0.690523 test loss: 0.693126
[Epoch 111; Iter    20/  209] train: loss: 0.0106339
[Epoch 111; Iter    50/  209] train: loss: 0.0065361
[Epoch 111; Iter    80/  209] train: loss: 0.0041881
[Epoch 111; Iter   110/  209] train: loss: 0.0222310
[Epoch 111; Iter   140/  209] train: loss: 0.0079123
[Epoch 111; Iter   170/  209] train: loss: 0.0253444
[Epoch 111; Iter   200/  209] train: loss: 0.0076595
[Epoch 111] ogbg-moltox21: 0.688723 val loss: 0.684935
[Epoch 111] ogbg-moltox21: 0.692862 test loss: 0.697472
[Epoch 112; Iter    21/  209] train: loss: 0.0044128
[Epoch 112; Iter    51/  209] train: loss: 0.0127026
[Epoch 112; Iter    81/  209] train: loss: 0.0102118
[Epoch 112; Iter   111/  209] train: loss: 0.0094575
[Epoch 112; Iter   141/  209] train: loss: 0.0147336
[Epoch 112; Iter   171/  209] train: loss: 0.0118516
[Epoch 112; Iter   201/  209] train: loss: 0.0051659
[Epoch 112] ogbg-moltox21: 0.691363 val loss: 0.796802
[Epoch 112] ogbg-moltox21: 0.691439 test loss: 0.760755
[Epoch 113; Iter    22/  209] train: loss: 0.0208111
[Epoch 113; Iter    52/  209] train: loss: 0.0041991
[Epoch 113; Iter    82/  209] train: loss: 0.0105837
[Epoch 113; Iter   112/  209] train: loss: 0.0299908
[Epoch 113; Iter   142/  209] train: loss: 0.0092677
[Epoch 113; Iter   172/  209] train: loss: 0.0076360
[Epoch 113; Iter   202/  209] train: loss: 0.0241629
[Epoch 113] ogbg-moltox21: 0.692609 val loss: 0.769180
[Epoch 113] ogbg-moltox21: 0.700134 test loss: 0.704739
[Epoch 114; Iter    23/  209] train: loss: 0.0460011
[Epoch 114; Iter    53/  209] train: loss: 0.0171091
[Epoch 114; Iter    83/  209] train: loss: 0.0177389
[Epoch 114; Iter   113/  209] train: loss: 0.0146367
[Epoch 114; Iter   143/  209] train: loss: 0.0102936
[Epoch 114; Iter   173/  209] train: loss: 0.0032909
[Epoch 114; Iter   203/  209] train: loss: 0.0068418
[Epoch 114] ogbg-moltox21: 0.688402 val loss: 0.822174
[Epoch 114] ogbg-moltox21: 0.693109 test loss: 0.743488
[Epoch 115; Iter    24/  209] train: loss: 0.0081131
[Epoch 115; Iter    54/  209] train: loss: 0.0139532
[Epoch 115; Iter    84/  209] train: loss: 0.0088069
[Epoch 115; Iter   114/  209] train: loss: 0.0024996
[Epoch 115; Iter   144/  209] train: loss: 0.0111185
[Epoch 115; Iter   174/  209] train: loss: 0.0043486
[Epoch 115; Iter   204/  209] train: loss: 0.0025114
[Epoch 115] ogbg-moltox21: 0.684997 val loss: 0.757646
[Epoch 115] ogbg-moltox21: 0.694734 test loss: 0.705650
[Epoch 116; Iter    25/  209] train: loss: 0.0247794
[Epoch 116; Iter    55/  209] train: loss: 0.0107480
[Epoch 116; Iter    85/  209] train: loss: 0.0069227
[Epoch 116; Iter   115/  209] train: loss: 0.0094450
[Epoch 99; Iter   128/  209] train: loss: 0.0057971
[Epoch 99; Iter   158/  209] train: loss: 0.0068257
[Epoch 99; Iter   188/  209] train: loss: 0.0031752
[Epoch 99] ogbg-moltox21: 0.756710 val loss: 0.636044
[Epoch 99] ogbg-moltox21: 0.694970 test loss: 0.701109
[Epoch 100; Iter     9/  209] train: loss: 0.0038050
[Epoch 100; Iter    39/  209] train: loss: 0.0054712
[Epoch 100; Iter    69/  209] train: loss: 0.0155630
[Epoch 100; Iter    99/  209] train: loss: 0.0029330
[Epoch 100; Iter   129/  209] train: loss: 0.0031186
[Epoch 100; Iter   159/  209] train: loss: 0.0027987
[Epoch 100; Iter   189/  209] train: loss: 0.0136014
[Epoch 100] ogbg-moltox21: 0.761765 val loss: 0.606792
[Epoch 100] ogbg-moltox21: 0.697643 test loss: 0.706234
[Epoch 101; Iter    10/  209] train: loss: 0.0234718
[Epoch 101; Iter    40/  209] train: loss: 0.0052774
[Epoch 101; Iter    70/  209] train: loss: 0.0065317
[Epoch 101; Iter   100/  209] train: loss: 0.0077182
[Epoch 101; Iter   130/  209] train: loss: 0.0097886
[Epoch 101; Iter   160/  209] train: loss: 0.0228576
[Epoch 101; Iter   190/  209] train: loss: 0.0062357
[Epoch 101] ogbg-moltox21: 0.759485 val loss: 0.650896
[Epoch 101] ogbg-moltox21: 0.699634 test loss: 0.695441
[Epoch 102; Iter    11/  209] train: loss: 0.0086752
[Epoch 102; Iter    41/  209] train: loss: 0.0030076
[Epoch 102; Iter    71/  209] train: loss: 0.0028008
[Epoch 102; Iter   101/  209] train: loss: 0.0150837
[Epoch 102; Iter   131/  209] train: loss: 0.0049976
[Epoch 102; Iter   161/  209] train: loss: 0.0048735
[Epoch 102; Iter   191/  209] train: loss: 0.0055526
[Epoch 102] ogbg-moltox21: 0.755316 val loss: 0.625631
[Epoch 102] ogbg-moltox21: 0.699120 test loss: 0.708314
[Epoch 103; Iter    12/  209] train: loss: 0.0132177
[Epoch 103; Iter    42/  209] train: loss: 0.0169730
[Epoch 103; Iter    72/  209] train: loss: 0.0092048
[Epoch 103; Iter   102/  209] train: loss: 0.0044011
[Epoch 103; Iter   132/  209] train: loss: 0.0064102
[Epoch 103; Iter   162/  209] train: loss: 0.0087333
[Epoch 103; Iter   192/  209] train: loss: 0.0073714
[Epoch 103] ogbg-moltox21: 0.758633 val loss: 0.616557
[Epoch 103] ogbg-moltox21: 0.696472 test loss: 0.729070
[Epoch 104; Iter    13/  209] train: loss: 0.0148575
[Epoch 104; Iter    43/  209] train: loss: 0.0048092
[Epoch 104; Iter    73/  209] train: loss: 0.0073098
[Epoch 104; Iter   103/  209] train: loss: 0.0035777
[Epoch 104; Iter   133/  209] train: loss: 0.0067857
[Epoch 104; Iter   163/  209] train: loss: 0.0309691
[Epoch 104; Iter   193/  209] train: loss: 0.0135226
[Epoch 104] ogbg-moltox21: 0.757547 val loss: 0.638267
[Epoch 104] ogbg-moltox21: 0.698289 test loss: 0.727028
[Epoch 105; Iter    14/  209] train: loss: 0.0041534
[Epoch 105; Iter    44/  209] train: loss: 0.0055327
[Epoch 105; Iter    74/  209] train: loss: 0.0090040
[Epoch 105; Iter   104/  209] train: loss: 0.0085590
[Epoch 105; Iter   134/  209] train: loss: 0.0061902
[Epoch 105; Iter   164/  209] train: loss: 0.0268202
[Epoch 105; Iter   194/  209] train: loss: 0.0069078
[Epoch 105] ogbg-moltox21: 0.760049 val loss: 0.666074
[Epoch 105] ogbg-moltox21: 0.701159 test loss: 0.717957
[Epoch 106; Iter    15/  209] train: loss: 0.0070049
[Epoch 106; Iter    45/  209] train: loss: 0.0025698
[Epoch 106; Iter    75/  209] train: loss: 0.0214734
[Epoch 106; Iter   105/  209] train: loss: 0.0041854
[Epoch 106; Iter   135/  209] train: loss: 0.0023507
[Epoch 106; Iter   165/  209] train: loss: 0.0040976
[Epoch 106; Iter   195/  209] train: loss: 0.0028104
[Epoch 106] ogbg-moltox21: 0.758660 val loss: 0.624970
[Epoch 106] ogbg-moltox21: 0.698654 test loss: 0.718429
[Epoch 107; Iter    16/  209] train: loss: 0.0063756
[Epoch 107; Iter    46/  209] train: loss: 0.0062504
[Epoch 107; Iter    76/  209] train: loss: 0.0055182
[Epoch 107; Iter   106/  209] train: loss: 0.0092873
[Epoch 107; Iter   136/  209] train: loss: 0.0084021
[Epoch 107; Iter   166/  209] train: loss: 0.0050613
[Epoch 107; Iter   196/  209] train: loss: 0.0051569
[Epoch 107] ogbg-moltox21: 0.754239 val loss: 0.609966
[Epoch 107] ogbg-moltox21: 0.695959 test loss: 0.703796
[Epoch 108; Iter    17/  209] train: loss: 0.0064670
[Epoch 108; Iter    47/  209] train: loss: 0.0066150
[Epoch 108; Iter    77/  209] train: loss: 0.0027745
[Epoch 108; Iter   107/  209] train: loss: 0.0154247
[Epoch 108; Iter   137/  209] train: loss: 0.0104372
[Epoch 108; Iter   167/  209] train: loss: 0.0046565
[Epoch 108; Iter   197/  209] train: loss: 0.0102311
[Epoch 108] ogbg-moltox21: 0.753751 val loss: 0.617398
[Epoch 108] ogbg-moltox21: 0.697167 test loss: 0.692941
[Epoch 109; Iter    18/  209] train: loss: 0.0090975
[Epoch 109; Iter    48/  209] train: loss: 0.0030664
[Epoch 109; Iter    78/  209] train: loss: 0.0026050
[Epoch 109; Iter   108/  209] train: loss: 0.0094416
[Epoch 109; Iter   138/  209] train: loss: 0.0051051
[Epoch 109; Iter   168/  209] train: loss: 0.0109457
[Epoch 109; Iter   198/  209] train: loss: 0.0172937
[Epoch 109] ogbg-moltox21: 0.754593 val loss: 0.626187
[Epoch 109] ogbg-moltox21: 0.695804 test loss: 0.703904
[Epoch 110; Iter    19/  209] train: loss: 0.0033259
[Epoch 110; Iter    49/  209] train: loss: 0.0040773
[Epoch 110; Iter    79/  209] train: loss: 0.0173273
[Epoch 110; Iter   109/  209] train: loss: 0.0068063
[Epoch 110; Iter   139/  209] train: loss: 0.0030972
[Epoch 110; Iter   169/  209] train: loss: 0.0081694
[Epoch 110; Iter   199/  209] train: loss: 0.0061841
[Epoch 110] ogbg-moltox21: 0.757799 val loss: 0.681187
[Epoch 110] ogbg-moltox21: 0.702062 test loss: 0.744974
[Epoch 111; Iter    20/  209] train: loss: 0.0147817
[Epoch 111; Iter    50/  209] train: loss: 0.0062620
[Epoch 111; Iter    80/  209] train: loss: 0.0056518
[Epoch 111; Iter   110/  209] train: loss: 0.0080318
[Epoch 111; Iter   140/  209] train: loss: 0.0090546
[Epoch 111; Iter   170/  209] train: loss: 0.0027024
[Epoch 111; Iter   200/  209] train: loss: 0.0177819
[Epoch 111] ogbg-moltox21: 0.754492 val loss: 0.696817
[Epoch 111] ogbg-moltox21: 0.700231 test loss: 0.731530
[Epoch 112; Iter    21/  209] train: loss: 0.0031798
[Epoch 112; Iter    51/  209] train: loss: 0.0105687
[Epoch 112; Iter    81/  209] train: loss: 0.0068073
[Epoch 112; Iter   111/  209] train: loss: 0.0106475
[Epoch 112; Iter   141/  209] train: loss: 0.0065322
[Epoch 112; Iter   171/  209] train: loss: 0.0059472
[Epoch 112; Iter   201/  209] train: loss: 0.0093405
[Epoch 112] ogbg-moltox21: 0.758468 val loss: 0.699854
[Epoch 112] ogbg-moltox21: 0.698377 test loss: 0.742372
[Epoch 113; Iter    22/  209] train: loss: 0.0058847
[Epoch 113; Iter    52/  209] train: loss: 0.0062132
[Epoch 113; Iter    82/  209] train: loss: 0.0042224
[Epoch 113; Iter   112/  209] train: loss: 0.0161161
[Epoch 113; Iter   142/  209] train: loss: 0.0125643
[Epoch 113; Iter   172/  209] train: loss: 0.0142578
[Epoch 113; Iter   202/  209] train: loss: 0.0040799
[Epoch 113] ogbg-moltox21: 0.752150 val loss: 0.654964
[Epoch 113] ogbg-moltox21: 0.694791 test loss: 0.745063
[Epoch 114; Iter    23/  209] train: loss: 0.0049899
[Epoch 114; Iter    53/  209] train: loss: 0.0049762
[Epoch 114; Iter    83/  209] train: loss: 0.0061475
[Epoch 114; Iter   113/  209] train: loss: 0.0055687
[Epoch 114; Iter   143/  209] train: loss: 0.0100919
[Epoch 114; Iter   173/  209] train: loss: 0.0021104
[Epoch 114; Iter   203/  209] train: loss: 0.0072810
[Epoch 114] ogbg-moltox21: 0.756871 val loss: 0.719518
[Epoch 114] ogbg-moltox21: 0.698432 test loss: 0.752836
[Epoch 115; Iter    24/  209] train: loss: 0.0039813
[Epoch 115; Iter    54/  209] train: loss: 0.0078193
[Epoch 115; Iter    84/  209] train: loss: 0.0023876
[Epoch 115; Iter   114/  209] train: loss: 0.0037168
[Epoch 115; Iter   144/  209] train: loss: 0.0067786
[Epoch 115; Iter   174/  209] train: loss: 0.0088010
[Epoch 115; Iter   204/  209] train: loss: 0.0035191
[Epoch 115] ogbg-moltox21: 0.754558 val loss: 0.680877
[Epoch 115] ogbg-moltox21: 0.694541 test loss: 0.772559
[Epoch 116; Iter    25/  209] train: loss: 0.0096185
[Epoch 116; Iter    55/  209] train: loss: 0.0028601
[Epoch 116; Iter    85/  209] train: loss: 0.0064674
[Epoch 116; Iter   115/  209] train: loss: 0.0083080
[Epoch 99; Iter   128/  209] train: loss: 0.0091910
[Epoch 99; Iter   158/  209] train: loss: 0.0166169
[Epoch 99; Iter   188/  209] train: loss: 0.0199253
[Epoch 99] ogbg-moltox21: 0.741991 val loss: 1.166172
[Epoch 99] ogbg-moltox21: 0.718222 test loss: 0.603282
[Epoch 100; Iter     9/  209] train: loss: 0.0075557
[Epoch 100; Iter    39/  209] train: loss: 0.0164490
[Epoch 100; Iter    69/  209] train: loss: 0.0364695
[Epoch 100; Iter    99/  209] train: loss: 0.0127670
[Epoch 100; Iter   129/  209] train: loss: 0.0104190
[Epoch 100; Iter   159/  209] train: loss: 0.0079489
[Epoch 100; Iter   189/  209] train: loss: 0.0104921
[Epoch 100] ogbg-moltox21: 0.734044 val loss: 1.172695
[Epoch 100] ogbg-moltox21: 0.713402 test loss: 0.598534
[Epoch 101; Iter    10/  209] train: loss: 0.0466462
[Epoch 101; Iter    40/  209] train: loss: 0.0055323
[Epoch 101; Iter    70/  209] train: loss: 0.0142180
[Epoch 101; Iter   100/  209] train: loss: 0.0220026
[Epoch 101; Iter   130/  209] train: loss: 0.0179862
[Epoch 101; Iter   160/  209] train: loss: 0.0267881
[Epoch 101; Iter   190/  209] train: loss: 0.0124735
[Epoch 101] ogbg-moltox21: 0.741060 val loss: 1.116485
[Epoch 101] ogbg-moltox21: 0.721719 test loss: 0.595374
[Epoch 102; Iter    11/  209] train: loss: 0.0095799
[Epoch 102; Iter    41/  209] train: loss: 0.0061780
[Epoch 102; Iter    71/  209] train: loss: 0.0217421
[Epoch 102; Iter   101/  209] train: loss: 0.0307421
[Epoch 102; Iter   131/  209] train: loss: 0.0152220
[Epoch 102; Iter   161/  209] train: loss: 0.0091310
[Epoch 102; Iter   191/  209] train: loss: 0.0124246
[Epoch 102] ogbg-moltox21: 0.737262 val loss: 1.114749
[Epoch 102] ogbg-moltox21: 0.714272 test loss: 0.608285
[Epoch 103; Iter    12/  209] train: loss: 0.0109630
[Epoch 103; Iter    42/  209] train: loss: 0.0172304
[Epoch 103; Iter    72/  209] train: loss: 0.0190063
[Epoch 103; Iter   102/  209] train: loss: 0.0058850
[Epoch 103; Iter   132/  209] train: loss: 0.0199493
[Epoch 103; Iter   162/  209] train: loss: 0.0130841
[Epoch 103; Iter   192/  209] train: loss: 0.0176685
[Epoch 103] ogbg-moltox21: 0.735194 val loss: 1.019483
[Epoch 103] ogbg-moltox21: 0.714682 test loss: 0.601144
[Epoch 104; Iter    13/  209] train: loss: 0.0216640
[Epoch 104; Iter    43/  209] train: loss: 0.0137539
[Epoch 104; Iter    73/  209] train: loss: 0.0058579
[Epoch 104; Iter   103/  209] train: loss: 0.0124098
[Epoch 104; Iter   133/  209] train: loss: 0.0198262
[Epoch 104; Iter   163/  209] train: loss: 0.0407722
[Epoch 104; Iter   193/  209] train: loss: 0.0163974
[Epoch 104] ogbg-moltox21: 0.748559 val loss: 1.065300
[Epoch 104] ogbg-moltox21: 0.720336 test loss: 0.620953
[Epoch 105; Iter    14/  209] train: loss: 0.0124170
[Epoch 105; Iter    44/  209] train: loss: 0.0152051
[Epoch 105; Iter    74/  209] train: loss: 0.0097071
[Epoch 105; Iter   104/  209] train: loss: 0.0067229
[Epoch 105; Iter   134/  209] train: loss: 0.0112165
[Epoch 105; Iter   164/  209] train: loss: 0.0352969
[Epoch 105; Iter   194/  209] train: loss: 0.0033471
[Epoch 105] ogbg-moltox21: 0.733025 val loss: 1.268127
[Epoch 105] ogbg-moltox21: 0.712987 test loss: 0.618753
[Epoch 106; Iter    15/  209] train: loss: 0.0263905
[Epoch 106; Iter    45/  209] train: loss: 0.0089015
[Epoch 106; Iter    75/  209] train: loss: 0.0118297
[Epoch 106; Iter   105/  209] train: loss: 0.0090271
[Epoch 106; Iter   135/  209] train: loss: 0.0091005
[Epoch 106; Iter   165/  209] train: loss: 0.0112656
[Epoch 106; Iter   195/  209] train: loss: 0.0145173
[Epoch 106] ogbg-moltox21: 0.745421 val loss: 1.164114
[Epoch 106] ogbg-moltox21: 0.719717 test loss: 0.623525
[Epoch 107; Iter    16/  209] train: loss: 0.0132355
[Epoch 107; Iter    46/  209] train: loss: 0.0108663
[Epoch 107; Iter    76/  209] train: loss: 0.0053752
[Epoch 107; Iter   106/  209] train: loss: 0.0117829
[Epoch 107; Iter   136/  209] train: loss: 0.0179314
[Epoch 107; Iter   166/  209] train: loss: 0.0082522
[Epoch 107; Iter   196/  209] train: loss: 0.0119244
[Epoch 107] ogbg-moltox21: 0.737580 val loss: 1.254893
[Epoch 107] ogbg-moltox21: 0.711191 test loss: 0.610455
[Epoch 108; Iter    17/  209] train: loss: 0.0069786
[Epoch 108; Iter    47/  209] train: loss: 0.0158089
[Epoch 108; Iter    77/  209] train: loss: 0.0068920
[Epoch 108; Iter   107/  209] train: loss: 0.0437638
[Epoch 108; Iter   137/  209] train: loss: 0.0133622
[Epoch 108; Iter   167/  209] train: loss: 0.0206876
[Epoch 108; Iter   197/  209] train: loss: 0.0089645
[Epoch 108] ogbg-moltox21: 0.735764 val loss: 1.049494
[Epoch 108] ogbg-moltox21: 0.714245 test loss: 0.620864
[Epoch 109; Iter    18/  209] train: loss: 0.0135030
[Epoch 109; Iter    48/  209] train: loss: 0.0053891
[Epoch 109; Iter    78/  209] train: loss: 0.0050326
[Epoch 109; Iter   108/  209] train: loss: 0.0131845
[Epoch 109; Iter   138/  209] train: loss: 0.0152285
[Epoch 109; Iter   168/  209] train: loss: 0.0279829
[Epoch 109; Iter   198/  209] train: loss: 0.0348547
[Epoch 109] ogbg-moltox21: 0.741223 val loss: 1.255529
[Epoch 109] ogbg-moltox21: 0.716757 test loss: 0.614980
[Epoch 110; Iter    19/  209] train: loss: 0.0076688
[Epoch 110; Iter    49/  209] train: loss: 0.0104570
[Epoch 110; Iter    79/  209] train: loss: 0.0123139
[Epoch 110; Iter   109/  209] train: loss: 0.0186038
[Epoch 110; Iter   139/  209] train: loss: 0.0221415
[Epoch 110; Iter   169/  209] train: loss: 0.0123473
[Epoch 110; Iter   199/  209] train: loss: 0.0098339
[Epoch 110] ogbg-moltox21: 0.732217 val loss: 1.314212
[Epoch 110] ogbg-moltox21: 0.707381 test loss: 0.626260
[Epoch 111; Iter    20/  209] train: loss: 0.0318109
[Epoch 111; Iter    50/  209] train: loss: 0.0131319
[Epoch 111; Iter    80/  209] train: loss: 0.0097659
[Epoch 111; Iter   110/  209] train: loss: 0.0107185
[Epoch 111; Iter   140/  209] train: loss: 0.0170050
[Epoch 111; Iter   170/  209] train: loss: 0.0220914
[Epoch 111; Iter   200/  209] train: loss: 0.0235424
[Epoch 111] ogbg-moltox21: 0.742907 val loss: 1.278015
[Epoch 111] ogbg-moltox21: 0.712807 test loss: 0.628750
[Epoch 112; Iter    21/  209] train: loss: 0.0063315
[Epoch 112; Iter    51/  209] train: loss: 0.0151464
[Epoch 112; Iter    81/  209] train: loss: 0.0135393
[Epoch 112; Iter   111/  209] train: loss: 0.0191801
[Epoch 112; Iter   141/  209] train: loss: 0.0160165
[Epoch 112; Iter   171/  209] train: loss: 0.0089475
[Epoch 112; Iter   201/  209] train: loss: 0.0118582
[Epoch 112] ogbg-moltox21: 0.741908 val loss: 1.234484
[Epoch 112] ogbg-moltox21: 0.712003 test loss: 0.624217
[Epoch 113; Iter    22/  209] train: loss: 0.0112049
[Epoch 113; Iter    52/  209] train: loss: 0.0248966
[Epoch 113; Iter    82/  209] train: loss: 0.0142053
[Epoch 113; Iter   112/  209] train: loss: 0.0174820
[Epoch 113; Iter   142/  209] train: loss: 0.0194003
[Epoch 113; Iter   172/  209] train: loss: 0.0097625
[Epoch 113; Iter   202/  209] train: loss: 0.0066139
[Epoch 113] ogbg-moltox21: 0.729997 val loss: 1.177559
[Epoch 113] ogbg-moltox21: 0.716178 test loss: 0.630604
[Epoch 114; Iter    23/  209] train: loss: 0.0072396
[Epoch 114; Iter    53/  209] train: loss: 0.0063482
[Epoch 114; Iter    83/  209] train: loss: 0.0081775
[Epoch 114; Iter   113/  209] train: loss: 0.0111550
[Epoch 114; Iter   143/  209] train: loss: 0.0105520
[Epoch 114; Iter   173/  209] train: loss: 0.0140935
[Epoch 114; Iter   203/  209] train: loss: 0.0064965
[Epoch 114] ogbg-moltox21: 0.730700 val loss: 1.171389
[Epoch 114] ogbg-moltox21: 0.713352 test loss: 0.631407
[Epoch 115; Iter    24/  209] train: loss: 0.0089045
[Epoch 115; Iter    54/  209] train: loss: 0.0162246
[Epoch 115; Iter    84/  209] train: loss: 0.0057590
[Epoch 115; Iter   114/  209] train: loss: 0.0107158
[Epoch 115; Iter   144/  209] train: loss: 0.0062056
[Epoch 115; Iter   174/  209] train: loss: 0.0316854
[Epoch 115; Iter   204/  209] train: loss: 0.0174372
[Epoch 115] ogbg-moltox21: 0.735493 val loss: 1.161528
[Epoch 115] ogbg-moltox21: 0.713659 test loss: 0.635907
[Epoch 116; Iter    25/  209] train: loss: 0.0352584
[Epoch 116; Iter    55/  209] train: loss: 0.0143305
[Epoch 116; Iter    85/  209] train: loss: 0.0075657
[Epoch 116; Iter   115/  209] train: loss: 0.0084453
[Epoch 99; Iter   128/  209] train: loss: 0.0219997
[Epoch 99; Iter   158/  209] train: loss: 0.0199970
[Epoch 99; Iter   188/  209] train: loss: 0.0573341
[Epoch 99] ogbg-moltox21: 0.713924 val loss: 0.504952
[Epoch 99] ogbg-moltox21: 0.708411 test loss: 0.536000
[Epoch 100; Iter     9/  209] train: loss: 0.0203632
[Epoch 100; Iter    39/  209] train: loss: 0.0248545
[Epoch 100; Iter    69/  209] train: loss: 0.0373411
[Epoch 100; Iter    99/  209] train: loss: 0.0171739
[Epoch 100; Iter   129/  209] train: loss: 0.0378475
[Epoch 100; Iter   159/  209] train: loss: 0.0229851
[Epoch 100; Iter   189/  209] train: loss: 0.0196807
[Epoch 100] ogbg-moltox21: 0.713014 val loss: 0.509408
[Epoch 100] ogbg-moltox21: 0.706627 test loss: 0.539748
[Epoch 101; Iter    10/  209] train: loss: 0.0319745
[Epoch 101; Iter    40/  209] train: loss: 0.0290453
[Epoch 101; Iter    70/  209] train: loss: 0.0290121
[Epoch 101; Iter   100/  209] train: loss: 0.0137263
[Epoch 101; Iter   130/  209] train: loss: 0.0182994
[Epoch 101; Iter   160/  209] train: loss: 0.0100826
[Epoch 101; Iter   190/  209] train: loss: 0.0114968
[Epoch 101] ogbg-moltox21: 0.717429 val loss: 0.520529
[Epoch 101] ogbg-moltox21: 0.701732 test loss: 0.558536
[Epoch 102; Iter    11/  209] train: loss: 0.0139514
[Epoch 102; Iter    41/  209] train: loss: 0.0165242
[Epoch 102; Iter    71/  209] train: loss: 0.0240566
[Epoch 102; Iter   101/  209] train: loss: 0.0235914
[Epoch 102; Iter   131/  209] train: loss: 0.0405515
[Epoch 102; Iter   161/  209] train: loss: 0.0304316
[Epoch 102; Iter   191/  209] train: loss: 0.0224734
[Epoch 102] ogbg-moltox21: 0.709843 val loss: 0.522664
[Epoch 102] ogbg-moltox21: 0.707428 test loss: 0.555409
[Epoch 103; Iter    12/  209] train: loss: 0.0246896
[Epoch 103; Iter    42/  209] train: loss: 0.0172037
[Epoch 103; Iter    72/  209] train: loss: 0.0550593
[Epoch 103; Iter   102/  209] train: loss: 0.0179518
[Epoch 103; Iter   132/  209] train: loss: 0.0376025
[Epoch 103; Iter   162/  209] train: loss: 0.0337282
[Epoch 103; Iter   192/  209] train: loss: 0.0226333
[Epoch 103] ogbg-moltox21: 0.710498 val loss: 0.526244
[Epoch 103] ogbg-moltox21: 0.702075 test loss: 0.556254
[Epoch 104; Iter    13/  209] train: loss: 0.0190261
[Epoch 104; Iter    43/  209] train: loss: 0.0283584
[Epoch 104; Iter    73/  209] train: loss: 0.0142431
[Epoch 104; Iter   103/  209] train: loss: 0.0253729
[Epoch 104; Iter   133/  209] train: loss: 0.0272643
[Epoch 104; Iter   163/  209] train: loss: 0.0151449
[Epoch 104; Iter   193/  209] train: loss: 0.0295216
[Epoch 104] ogbg-moltox21: 0.715706 val loss: 0.531381
[Epoch 104] ogbg-moltox21: 0.706441 test loss: 0.564708
[Epoch 105; Iter    14/  209] train: loss: 0.0336212
[Epoch 105; Iter    44/  209] train: loss: 0.0189827
[Epoch 105; Iter    74/  209] train: loss: 0.0314111
[Epoch 105; Iter   104/  209] train: loss: 0.0196724
[Epoch 105; Iter   134/  209] train: loss: 0.0169760
[Epoch 105; Iter   164/  209] train: loss: 0.0127638
[Epoch 105; Iter   194/  209] train: loss: 0.0470427
[Epoch 105] ogbg-moltox21: 0.714366 val loss: 0.540070
[Epoch 105] ogbg-moltox21: 0.706756 test loss: 0.575715
[Epoch 106; Iter    15/  209] train: loss: 0.0120698
[Epoch 106; Iter    45/  209] train: loss: 0.0172244
[Epoch 106; Iter    75/  209] train: loss: 0.0156571
[Epoch 106; Iter   105/  209] train: loss: 0.0682170
[Epoch 106; Iter   135/  209] train: loss: 0.0199518
[Epoch 106; Iter   165/  209] train: loss: 0.0379192
[Epoch 106; Iter   195/  209] train: loss: 0.0165768
[Epoch 106] ogbg-moltox21: 0.711074 val loss: 0.539981
[Epoch 106] ogbg-moltox21: 0.703198 test loss: 0.575201
[Epoch 107; Iter    16/  209] train: loss: 0.0229222
[Epoch 107; Iter    46/  209] train: loss: 0.0342951
[Epoch 107; Iter    76/  209] train: loss: 0.0159646
[Epoch 107; Iter   106/  209] train: loss: 0.0171480
[Epoch 107; Iter   136/  209] train: loss: 0.0343206
[Epoch 107; Iter   166/  209] train: loss: 0.0229460
[Epoch 107; Iter   196/  209] train: loss: 0.0127055
[Epoch 107] ogbg-moltox21: 0.717005 val loss: 0.536714
[Epoch 107] ogbg-moltox21: 0.705072 test loss: 0.562331
[Epoch 108; Iter    17/  209] train: loss: 0.0379721
[Epoch 108; Iter    47/  209] train: loss: 0.0193402
[Epoch 108; Iter    77/  209] train: loss: 0.0414356
[Epoch 108; Iter   107/  209] train: loss: 0.0453686
[Epoch 108; Iter   137/  209] train: loss: 0.0228090
[Epoch 108; Iter   167/  209] train: loss: 0.0236205
[Epoch 108; Iter   197/  209] train: loss: 0.0145439
[Epoch 108] ogbg-moltox21: 0.713230 val loss: 0.554338
[Epoch 108] ogbg-moltox21: 0.705731 test loss: 0.584852
[Epoch 109; Iter    18/  209] train: loss: 0.0221313
[Epoch 109; Iter    48/  209] train: loss: 0.0443904
[Epoch 109; Iter    78/  209] train: loss: 0.0221536
[Epoch 109; Iter   108/  209] train: loss: 0.0290690
[Epoch 109; Iter   138/  209] train: loss: 0.0126000
[Epoch 109; Iter   168/  209] train: loss: 0.0313423
[Epoch 109; Iter   198/  209] train: loss: 0.0299082
[Epoch 109] ogbg-moltox21: 0.715901 val loss: 0.535425
[Epoch 109] ogbg-moltox21: 0.709011 test loss: 0.572321
[Epoch 110; Iter    19/  209] train: loss: 0.0205159
[Epoch 110; Iter    49/  209] train: loss: 0.0177982
[Epoch 110; Iter    79/  209] train: loss: 0.0165912
[Epoch 110; Iter   109/  209] train: loss: 0.0211765
[Epoch 110; Iter   139/  209] train: loss: 0.0309661
[Epoch 110; Iter   169/  209] train: loss: 0.0092113
[Epoch 110; Iter   199/  209] train: loss: 0.0276350
[Epoch 110] ogbg-moltox21: 0.720712 val loss: 0.548208
[Epoch 110] ogbg-moltox21: 0.711305 test loss: 0.580466
[Epoch 111; Iter    20/  209] train: loss: 0.0357243
[Epoch 111; Iter    50/  209] train: loss: 0.0118898
[Epoch 111; Iter    80/  209] train: loss: 0.0304315
[Epoch 111; Iter   110/  209] train: loss: 0.0383632
[Epoch 111; Iter   140/  209] train: loss: 0.0487979
[Epoch 111; Iter   170/  209] train: loss: 0.0466524
[Epoch 111; Iter   200/  209] train: loss: 0.0114913
[Epoch 111] ogbg-moltox21: 0.711806 val loss: 0.544326
[Epoch 111] ogbg-moltox21: 0.704185 test loss: 0.590214
[Epoch 112; Iter    21/  209] train: loss: 0.0239699
[Epoch 112; Iter    51/  209] train: loss: 0.0422945
[Epoch 112; Iter    81/  209] train: loss: 0.0117147
[Epoch 112; Iter   111/  209] train: loss: 0.0350671
[Epoch 112; Iter   141/  209] train: loss: 0.0145227
[Epoch 112; Iter   171/  209] train: loss: 0.0126975
[Epoch 112; Iter   201/  209] train: loss: 0.0110262
[Epoch 112] ogbg-moltox21: 0.717480 val loss: 0.572840
[Epoch 112] ogbg-moltox21: 0.701936 test loss: 0.594360
[Epoch 113; Iter    22/  209] train: loss: 0.0597090
[Epoch 113; Iter    52/  209] train: loss: 0.0163903
[Epoch 113; Iter    82/  209] train: loss: 0.0367192
[Epoch 113; Iter   112/  209] train: loss: 0.0278294
[Epoch 113; Iter   142/  209] train: loss: 0.0402155
[Epoch 113; Iter   172/  209] train: loss: 0.0127522
[Epoch 113; Iter   202/  209] train: loss: 0.0308003
[Epoch 113] ogbg-moltox21: 0.721301 val loss: 0.533024
[Epoch 113] ogbg-moltox21: 0.704684 test loss: 0.587778
[Epoch 114; Iter    23/  209] train: loss: 0.0810218
[Epoch 114; Iter    53/  209] train: loss: 0.0209896
[Epoch 114; Iter    83/  209] train: loss: 0.0193629
[Epoch 114; Iter   113/  209] train: loss: 0.0145020
[Epoch 114; Iter   143/  209] train: loss: 0.0175684
[Epoch 114; Iter   173/  209] train: loss: 0.0126256
[Epoch 114; Iter   203/  209] train: loss: 0.0266569
[Epoch 114] ogbg-moltox21: 0.712081 val loss: 0.540823
[Epoch 114] ogbg-moltox21: 0.702914 test loss: 0.584569
[Epoch 115; Iter    24/  209] train: loss: 0.0261609
[Epoch 115; Iter    54/  209] train: loss: 0.0114959
[Epoch 115; Iter    84/  209] train: loss: 0.0234387
[Epoch 115; Iter   114/  209] train: loss: 0.0056178
[Epoch 115; Iter   144/  209] train: loss: 0.0166389
[Epoch 115; Iter   174/  209] train: loss: 0.0126503
[Epoch 115; Iter   204/  209] train: loss: 0.0134226
[Epoch 115] ogbg-moltox21: 0.717956 val loss: 0.539526
[Epoch 115] ogbg-moltox21: 0.704465 test loss: 0.591200
[Epoch 116; Iter    25/  209] train: loss: 0.0369364
[Epoch 116; Iter    55/  209] train: loss: 0.0148016
[Epoch 116; Iter    85/  209] train: loss: 0.0232190
[Epoch 116; Iter   115/  209] train: loss: 0.0264833
[Epoch 99; Iter   128/  209] train: loss: 0.0095187
[Epoch 99; Iter   158/  209] train: loss: 0.0122411
[Epoch 99; Iter   188/  209] train: loss: 0.0241361
[Epoch 99] ogbg-moltox21: 0.740033 val loss: 0.800497
[Epoch 99] ogbg-moltox21: 0.701445 test loss: 0.878306
[Epoch 100; Iter     9/  209] train: loss: 0.0123567
[Epoch 100; Iter    39/  209] train: loss: 0.0283475
[Epoch 100; Iter    69/  209] train: loss: 0.0087041
[Epoch 100; Iter    99/  209] train: loss: 0.0325870
[Epoch 100; Iter   129/  209] train: loss: 0.0146655
[Epoch 100; Iter   159/  209] train: loss: 0.0101275
[Epoch 100; Iter   189/  209] train: loss: 0.0071989
[Epoch 100] ogbg-moltox21: 0.735880 val loss: 0.805010
[Epoch 100] ogbg-moltox21: 0.698759 test loss: 0.878893
[Epoch 101; Iter    10/  209] train: loss: 0.0094179
[Epoch 101; Iter    40/  209] train: loss: 0.0079987
[Epoch 101; Iter    70/  209] train: loss: 0.0064588
[Epoch 101; Iter   100/  209] train: loss: 0.0182299
[Epoch 101; Iter   130/  209] train: loss: 0.0042834
[Epoch 101; Iter   160/  209] train: loss: 0.0049953
[Epoch 101; Iter   190/  209] train: loss: 0.0099762
[Epoch 101] ogbg-moltox21: 0.734467 val loss: 0.832517
[Epoch 101] ogbg-moltox21: 0.695007 test loss: 0.902992
[Epoch 102; Iter    11/  209] train: loss: 0.0295106
[Epoch 102; Iter    41/  209] train: loss: 0.0128607
[Epoch 102; Iter    71/  209] train: loss: 0.0028584
[Epoch 102; Iter   101/  209] train: loss: 0.0099353
[Epoch 102; Iter   131/  209] train: loss: 0.0116693
[Epoch 102; Iter   161/  209] train: loss: 0.0080089
[Epoch 102; Iter   191/  209] train: loss: 0.0109832
[Epoch 102] ogbg-moltox21: 0.737655 val loss: 0.829456
[Epoch 102] ogbg-moltox21: 0.693806 test loss: 0.901149
[Epoch 103; Iter    12/  209] train: loss: 0.0089771
[Epoch 103; Iter    42/  209] train: loss: 0.0078785
[Epoch 103; Iter    72/  209] train: loss: 0.0065307
[Epoch 103; Iter   102/  209] train: loss: 0.0081672
[Epoch 103; Iter   132/  209] train: loss: 0.0119340
[Epoch 103; Iter   162/  209] train: loss: 0.0650790
[Epoch 103; Iter   192/  209] train: loss: 0.0190436
[Epoch 103] ogbg-moltox21: 0.733581 val loss: 0.828266
[Epoch 103] ogbg-moltox21: 0.693384 test loss: 0.892874
[Epoch 104; Iter    13/  209] train: loss: 0.0117714
[Epoch 104; Iter    43/  209] train: loss: 0.0055212
[Epoch 104; Iter    73/  209] train: loss: 0.0051744
[Epoch 104; Iter   103/  209] train: loss: 0.0105250
[Epoch 104; Iter   133/  209] train: loss: 0.0031185
[Epoch 104; Iter   163/  209] train: loss: 0.0140269
[Epoch 104; Iter   193/  209] train: loss: 0.0059737
[Epoch 104] ogbg-moltox21: 0.740428 val loss: 0.847898
[Epoch 104] ogbg-moltox21: 0.696227 test loss: 0.921295
[Epoch 105; Iter    14/  209] train: loss: 0.0092556
[Epoch 105; Iter    44/  209] train: loss: 0.0042559
[Epoch 105; Iter    74/  209] train: loss: 0.0068765
[Epoch 105; Iter   104/  209] train: loss: 0.0149441
[Epoch 105; Iter   134/  209] train: loss: 0.0071178
[Epoch 105; Iter   164/  209] train: loss: 0.0077454
[Epoch 105; Iter   194/  209] train: loss: 0.0053980
[Epoch 105] ogbg-moltox21: 0.738555 val loss: 0.863213
[Epoch 105] ogbg-moltox21: 0.692228 test loss: 0.937019
[Epoch 106; Iter    15/  209] train: loss: 0.0095642
[Epoch 106; Iter    45/  209] train: loss: 0.0064665
[Epoch 106; Iter    75/  209] train: loss: 0.0167551
[Epoch 106; Iter   105/  209] train: loss: 0.0118808
[Epoch 106; Iter   135/  209] train: loss: 0.0268149
[Epoch 106; Iter   165/  209] train: loss: 0.0083437
[Epoch 106; Iter   195/  209] train: loss: 0.0037432
[Epoch 106] ogbg-moltox21: 0.740153 val loss: 0.843212
[Epoch 106] ogbg-moltox21: 0.697027 test loss: 0.917014
[Epoch 107; Iter    16/  209] train: loss: 0.0097709
[Epoch 107; Iter    46/  209] train: loss: 0.0050779
[Epoch 107; Iter    76/  209] train: loss: 0.0336521
[Epoch 107; Iter   106/  209] train: loss: 0.0031106
[Epoch 107; Iter   136/  209] train: loss: 0.0054576
[Epoch 107; Iter   166/  209] train: loss: 0.0157352
[Epoch 107; Iter   196/  209] train: loss: 0.0087173
[Epoch 107] ogbg-moltox21: 0.745275 val loss: 0.833580
[Epoch 107] ogbg-moltox21: 0.699462 test loss: 0.912277
[Epoch 108; Iter    17/  209] train: loss: 0.0120757
[Epoch 108; Iter    47/  209] train: loss: 0.0261533
[Epoch 108; Iter    77/  209] train: loss: 0.0044708
[Epoch 108; Iter   107/  209] train: loss: 0.0313342
[Epoch 108; Iter   137/  209] train: loss: 0.0092591
[Epoch 108; Iter   167/  209] train: loss: 0.0142433
[Epoch 108; Iter   197/  209] train: loss: 0.0106146
[Epoch 108] ogbg-moltox21: 0.746173 val loss: 0.858504
[Epoch 108] ogbg-moltox21: 0.699292 test loss: 0.944447
[Epoch 109; Iter    18/  209] train: loss: 0.0055127
[Epoch 109; Iter    48/  209] train: loss: 0.0043184
[Epoch 109; Iter    78/  209] train: loss: 0.0071803
[Epoch 109; Iter   108/  209] train: loss: 0.0059497
[Epoch 109; Iter   138/  209] train: loss: 0.0067447
[Epoch 109; Iter   168/  209] train: loss: 0.0038632
[Epoch 109; Iter   198/  209] train: loss: 0.0078917
[Epoch 109] ogbg-moltox21: 0.738324 val loss: 0.855832
[Epoch 109] ogbg-moltox21: 0.693120 test loss: 0.931891
[Epoch 110; Iter    19/  209] train: loss: 0.0031688
[Epoch 110; Iter    49/  209] train: loss: 0.0083328
[Epoch 110; Iter    79/  209] train: loss: 0.0062277
[Epoch 110; Iter   109/  209] train: loss: 0.0080186
[Epoch 110; Iter   139/  209] train: loss: 0.0164619
[Epoch 110; Iter   169/  209] train: loss: 0.0186789
[Epoch 110; Iter   199/  209] train: loss: 0.0183827
[Epoch 110] ogbg-moltox21: 0.740064 val loss: 0.877576
[Epoch 110] ogbg-moltox21: 0.695775 test loss: 0.941428
[Epoch 111; Iter    20/  209] train: loss: 0.0182877
[Epoch 111; Iter    50/  209] train: loss: 0.0127019
[Epoch 111; Iter    80/  209] train: loss: 0.0131550
[Epoch 111; Iter   110/  209] train: loss: 0.0134629
[Epoch 111; Iter   140/  209] train: loss: 0.0093054
[Epoch 111; Iter   170/  209] train: loss: 0.0051560
[Epoch 111; Iter   200/  209] train: loss: 0.0096671
[Epoch 111] ogbg-moltox21: 0.737565 val loss: 0.875026
[Epoch 111] ogbg-moltox21: 0.692803 test loss: 0.933489
[Epoch 112; Iter    21/  209] train: loss: 0.0087755
[Epoch 112; Iter    51/  209] train: loss: 0.0076004
[Epoch 112; Iter    81/  209] train: loss: 0.0041202
[Epoch 112; Iter   111/  209] train: loss: 0.0111296
[Epoch 112; Iter   141/  209] train: loss: 0.0090338
[Epoch 112; Iter   171/  209] train: loss: 0.0158584
[Epoch 112; Iter   201/  209] train: loss: 0.0167514
[Epoch 112] ogbg-moltox21: 0.737928 val loss: 0.860272
[Epoch 112] ogbg-moltox21: 0.694452 test loss: 0.923835
[Epoch 113; Iter    22/  209] train: loss: 0.0098471
[Epoch 113; Iter    52/  209] train: loss: 0.0040003
[Epoch 113; Iter    82/  209] train: loss: 0.0124447
[Epoch 113; Iter   112/  209] train: loss: 0.0055216
[Epoch 113; Iter   142/  209] train: loss: 0.0185606
[Epoch 113; Iter   172/  209] train: loss: 0.0121896
[Epoch 113; Iter   202/  209] train: loss: 0.0146721
[Epoch 113] ogbg-moltox21: 0.742507 val loss: 0.855621
[Epoch 113] ogbg-moltox21: 0.695370 test loss: 0.929429
[Epoch 114; Iter    23/  209] train: loss: 0.0055347
[Epoch 114; Iter    53/  209] train: loss: 0.0087986
[Epoch 114; Iter    83/  209] train: loss: 0.0080091
[Epoch 114; Iter   113/  209] train: loss: 0.0145642
[Epoch 114; Iter   143/  209] train: loss: 0.0098696
[Epoch 114; Iter   173/  209] train: loss: 0.0085872
[Epoch 114; Iter   203/  209] train: loss: 0.0112097
[Epoch 114] ogbg-moltox21: 0.742167 val loss: 0.859771
[Epoch 114] ogbg-moltox21: 0.695084 test loss: 0.928656
[Epoch 115; Iter    24/  209] train: loss: 0.0058419
[Epoch 115; Iter    54/  209] train: loss: 0.0045032
[Epoch 115; Iter    84/  209] train: loss: 0.0174899
[Epoch 115; Iter   114/  209] train: loss: 0.0092809
[Epoch 115; Iter   144/  209] train: loss: 0.0040389
[Epoch 115; Iter   174/  209] train: loss: 0.0103937
[Epoch 115; Iter   204/  209] train: loss: 0.0265039
[Epoch 115] ogbg-moltox21: 0.738996 val loss: 0.851823
[Epoch 115] ogbg-moltox21: 0.696394 test loss: 0.915389
[Epoch 116; Iter    25/  209] train: loss: 0.0090791
[Epoch 116; Iter    55/  209] train: loss: 0.0187136
[Epoch 116; Iter    85/  209] train: loss: 0.0315464
[Epoch 116; Iter   115/  209] train: loss: 0.0058355
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0137828
[Epoch 116; Iter   175/  209] train: loss: 0.0070308
[Epoch 116; Iter   205/  209] train: loss: 0.0116847
[Epoch 116] ogbg-moltox21: 0.783298 val loss: 0.527810
[Epoch 116] ogbg-moltox21: 0.737913 test loss: 0.624921
[Epoch 117; Iter    26/  209] train: loss: 0.0203398
[Epoch 117; Iter    56/  209] train: loss: 0.0062716
[Epoch 117; Iter    86/  209] train: loss: 0.0114074
[Epoch 117; Iter   116/  209] train: loss: 0.0102438
[Epoch 117; Iter   146/  209] train: loss: 0.0112880
[Epoch 117; Iter   176/  209] train: loss: 0.0061967
[Epoch 117; Iter   206/  209] train: loss: 0.0099621
[Epoch 117] ogbg-moltox21: 0.784927 val loss: 0.525285
[Epoch 117] ogbg-moltox21: 0.738814 test loss: 0.645311
[Epoch 118; Iter    27/  209] train: loss: 0.0044221
[Epoch 118; Iter    57/  209] train: loss: 0.0188114
[Epoch 118; Iter    87/  209] train: loss: 0.0105939
[Epoch 118; Iter   117/  209] train: loss: 0.0143351
[Epoch 118; Iter   147/  209] train: loss: 0.0070950
[Epoch 118; Iter   177/  209] train: loss: 0.0232791
[Epoch 118; Iter   207/  209] train: loss: 0.0097349
[Epoch 118] ogbg-moltox21: 0.785378 val loss: 0.514674
[Epoch 118] ogbg-moltox21: 0.733711 test loss: 0.656162
[Epoch 119; Iter    28/  209] train: loss: 0.0125461
[Epoch 119; Iter    58/  209] train: loss: 0.0158820
[Epoch 119; Iter    88/  209] train: loss: 0.0084810
[Epoch 119; Iter   118/  209] train: loss: 0.0045109
[Epoch 119; Iter   148/  209] train: loss: 0.0048972
[Epoch 119; Iter   178/  209] train: loss: 0.0168036
[Epoch 119; Iter   208/  209] train: loss: 0.0040613
[Epoch 119] ogbg-moltox21: 0.786787 val loss: 0.534915
[Epoch 119] ogbg-moltox21: 0.732489 test loss: 0.664301
[Epoch 120; Iter    29/  209] train: loss: 0.0119660
[Epoch 120; Iter    59/  209] train: loss: 0.0040730
[Epoch 120; Iter    89/  209] train: loss: 0.0056580
[Epoch 120; Iter   119/  209] train: loss: 0.0100620
[Epoch 120; Iter   149/  209] train: loss: 0.0501813
[Epoch 120; Iter   179/  209] train: loss: 0.0105508
[Epoch 120; Iter   209/  209] train: loss: 0.0116564
[Epoch 120] ogbg-moltox21: 0.785017 val loss: 0.540718
[Epoch 120] ogbg-moltox21: 0.738388 test loss: 0.668096
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -4.000935077667236
std_pred: 26.46295738220215
mean_targets: nan
std_targets: nan
prcauc: 0.38605836591976384
rocauc: 0.8085765000455232
ogbg-moltox21: 0.8085765000455232
OGBNanLabelBCEWithLogitsLoss: 0.30813499388319476
Statistics on  test
mean_pred: -4.8686442375183105
std_pred: 38.78636169433594
mean_targets: nan
std_targets: nan
prcauc: 0.34112958169741875
rocauc: 0.7349235442175909
ogbg-moltox21: 0.7349235442175909
OGBNanLabelBCEWithLogitsLoss: 0.554162992923348
Statistics on  train
mean_pred: -4.016194820404053
std_pred: 2.3259143829345703
mean_targets: nan
std_targets: nan
prcauc: 0.5633986193682435
rocauc: 0.9013483097631991
ogbg-moltox21: 0.9013483097631991
OGBNanLabelBCEWithLogitsLoss: 0.14993338793088373
[Epoch 116; Iter   145/  209] train: loss: 0.0432541
[Epoch 116; Iter   175/  209] train: loss: 0.0203421
[Epoch 116; Iter   205/  209] train: loss: 0.0247275
[Epoch 116] ogbg-moltox21: 0.748812 val loss: 0.446526
[Epoch 116] ogbg-moltox21: 0.738365 test loss: 0.448861
[Epoch 117; Iter    26/  209] train: loss: 0.0139159
[Epoch 117; Iter    56/  209] train: loss: 0.0114264
[Epoch 117; Iter    86/  209] train: loss: 0.0330490
[Epoch 117; Iter   116/  209] train: loss: 0.0346981
[Epoch 117; Iter   146/  209] train: loss: 0.0283739
[Epoch 117; Iter   176/  209] train: loss: 0.0352109
[Epoch 117; Iter   206/  209] train: loss: 0.0205553
[Epoch 117] ogbg-moltox21: 0.740979 val loss: 0.448008
[Epoch 117] ogbg-moltox21: 0.735540 test loss: 0.442833
[Epoch 118; Iter    27/  209] train: loss: 0.0250722
[Epoch 118; Iter    57/  209] train: loss: 0.0207097
[Epoch 118; Iter    87/  209] train: loss: 0.0230492
[Epoch 118; Iter   117/  209] train: loss: 0.0399422
[Epoch 118; Iter   147/  209] train: loss: 0.0432556
[Epoch 118; Iter   177/  209] train: loss: 0.0216026
[Epoch 118; Iter   207/  209] train: loss: 0.0274834
[Epoch 118] ogbg-moltox21: 0.743446 val loss: 0.456241
[Epoch 118] ogbg-moltox21: 0.736265 test loss: 0.455160
[Epoch 119; Iter    28/  209] train: loss: 0.0532396
[Epoch 119; Iter    58/  209] train: loss: 0.0287287
[Epoch 119; Iter    88/  209] train: loss: 0.0374229
[Epoch 119; Iter   118/  209] train: loss: 0.0182195
[Epoch 119; Iter   148/  209] train: loss: 0.0263305
[Epoch 119; Iter   178/  209] train: loss: 0.0539942
[Epoch 119; Iter   208/  209] train: loss: 0.0333800
[Epoch 119] ogbg-moltox21: 0.749361 val loss: 0.449241
[Epoch 119] ogbg-moltox21: 0.742677 test loss: 0.445579
[Epoch 120; Iter    29/  209] train: loss: 0.0200674
[Epoch 120; Iter    59/  209] train: loss: 0.0280860
[Epoch 120; Iter    89/  209] train: loss: 0.0305041
[Epoch 120; Iter   119/  209] train: loss: 0.0261312
[Epoch 120; Iter   149/  209] train: loss: 0.0295255
[Epoch 120; Iter   179/  209] train: loss: 0.0152445
[Epoch 120; Iter   209/  209] train: loss: 0.0308817
[Epoch 120] ogbg-moltox21: 0.749441 val loss: 0.450895
[Epoch 120] ogbg-moltox21: 0.742913 test loss: 0.442968
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 37.
Statistics on  val_best_checkpoint
mean_pred: -2.712954044342041
std_pred: 1.9769126176834106
mean_targets: nan
std_targets: nan
prcauc: 0.3915727539885556
rocauc: 0.8004428345830753
ogbg-moltox21: 0.8004428345830753
OGBNanLabelBCEWithLogitsLoss: 0.25392768614821964
Statistics on  test
mean_pred: -2.729372024536133
std_pred: 2.0170555114746094
mean_targets: nan
std_targets: nan
prcauc: 0.3422662917384463
rocauc: 0.7422041562658693
ogbg-moltox21: 0.7422041562658693
OGBNanLabelBCEWithLogitsLoss: 0.27896048459741807
Statistics on  train
mean_pred: -3.7112343311309814
std_pred: 2.092095136642456
mean_targets: nan
std_targets: nan
prcauc: 0.6194066307706864
rocauc: 0.9127172374469498
ogbg-moltox21: 0.9127172374469498
OGBNanLabelBCEWithLogitsLoss: 0.13936239327682834
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0121447
[Epoch 116; Iter   175/  209] train: loss: 0.0072481
[Epoch 116; Iter   205/  209] train: loss: 0.0064551
[Epoch 116] ogbg-moltox21: 0.688605 val loss: 0.745917
[Epoch 116] ogbg-moltox21: 0.692536 test loss: 0.726061
[Epoch 117; Iter    26/  209] train: loss: 0.0046911
[Epoch 117; Iter    56/  209] train: loss: 0.0080243
[Epoch 117; Iter    86/  209] train: loss: 0.0089402
[Epoch 117; Iter   116/  209] train: loss: 0.0050107
[Epoch 117; Iter   146/  209] train: loss: 0.0157265
[Epoch 117; Iter   176/  209] train: loss: 0.0148269
[Epoch 117; Iter   206/  209] train: loss: 0.0043751
[Epoch 117] ogbg-moltox21: 0.688743 val loss: 0.718143
[Epoch 117] ogbg-moltox21: 0.691447 test loss: 0.712239
[Epoch 118; Iter    27/  209] train: loss: 0.0041801
[Epoch 118; Iter    57/  209] train: loss: 0.0048459
[Epoch 118; Iter    87/  209] train: loss: 0.0080369
[Epoch 118; Iter   117/  209] train: loss: 0.0050857
[Epoch 118; Iter   147/  209] train: loss: 0.0186837
[Epoch 118; Iter   177/  209] train: loss: 0.0166714
[Epoch 118; Iter   207/  209] train: loss: 0.0088678
[Epoch 118] ogbg-moltox21: 0.688811 val loss: 0.791486
[Epoch 118] ogbg-moltox21: 0.691968 test loss: 0.722414
[Epoch 119; Iter    28/  209] train: loss: 0.0104781
[Epoch 119; Iter    58/  209] train: loss: 0.0027838
[Epoch 119; Iter    88/  209] train: loss: 0.0095289
[Epoch 119; Iter   118/  209] train: loss: 0.0041198
[Epoch 119; Iter   148/  209] train: loss: 0.0125285
[Epoch 119; Iter   178/  209] train: loss: 0.0033533
[Epoch 119; Iter   208/  209] train: loss: 0.0090034
[Epoch 119] ogbg-moltox21: 0.688634 val loss: 0.821829
[Epoch 119] ogbg-moltox21: 0.693109 test loss: 0.729573
[Epoch 120; Iter    29/  209] train: loss: 0.0076950
[Epoch 120; Iter    59/  209] train: loss: 0.0037200
[Epoch 120; Iter    89/  209] train: loss: 0.0074901
[Epoch 120; Iter   119/  209] train: loss: 0.0041752
[Epoch 120; Iter   149/  209] train: loss: 0.0082879
[Epoch 120; Iter   179/  209] train: loss: 0.0033487
[Epoch 120; Iter   209/  209] train: loss: 0.0065604
[Epoch 120] ogbg-moltox21: 0.687977 val loss: 0.781998
[Epoch 120] ogbg-moltox21: 0.692807 test loss: 0.715765
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 18.
Statistics on  val_best_checkpoint
mean_pred: -2.834455966949463
std_pred: 1.8962936401367188
mean_targets: nan
std_targets: nan
prcauc: 0.3158498712756306
rocauc: 0.7711732954057186
ogbg-moltox21: 0.7711732954057186
OGBNanLabelBCEWithLogitsLoss: 0.2674599414070447
Statistics on  test
mean_pred: -2.7973504066467285
std_pred: 1.7968933582305908
mean_targets: nan
std_targets: nan
prcauc: 0.2786791034160424
rocauc: 0.7273758935994598
ogbg-moltox21: 0.7273758935994598
OGBNanLabelBCEWithLogitsLoss: 0.28313979120166216
Statistics on  train
mean_pred: -3.3018980026245117
std_pred: 1.4961705207824707
mean_targets: nan
std_targets: nan
prcauc: 0.40552423914009195
rocauc: 0.8543167576051794
ogbg-moltox21: 0.8543167576051794
OGBNanLabelBCEWithLogitsLoss: 0.17740045559178128
[Epoch 116; Iter   145/  209] train: loss: 0.0032032
[Epoch 116; Iter   175/  209] train: loss: 0.0197699
[Epoch 116; Iter   205/  209] train: loss: 0.0099169
[Epoch 116] ogbg-moltox21: 0.739429 val loss: 1.213246
[Epoch 116] ogbg-moltox21: 0.717672 test loss: 0.634620
[Epoch 117; Iter    26/  209] train: loss: 0.0087100
[Epoch 117; Iter    56/  209] train: loss: 0.0136611
[Epoch 117; Iter    86/  209] train: loss: 0.0118706
[Epoch 117; Iter   116/  209] train: loss: 0.0055924
[Epoch 117; Iter   146/  209] train: loss: 0.0089580
[Epoch 117; Iter   176/  209] train: loss: 0.0120749
[Epoch 117; Iter   206/  209] train: loss: 0.0140074
[Epoch 117] ogbg-moltox21: 0.736554 val loss: 1.087361
[Epoch 117] ogbg-moltox21: 0.714500 test loss: 0.628032
[Epoch 118; Iter    27/  209] train: loss: 0.0078885
[Epoch 118; Iter    57/  209] train: loss: 0.0130946
[Epoch 118; Iter    87/  209] train: loss: 0.0128318
[Epoch 118; Iter   117/  209] train: loss: 0.0051171
[Epoch 118; Iter   147/  209] train: loss: 0.0072610
[Epoch 118; Iter   177/  209] train: loss: 0.0106409
[Epoch 118; Iter   207/  209] train: loss: 0.0069923
[Epoch 118] ogbg-moltox21: 0.743678 val loss: 1.176369
[Epoch 118] ogbg-moltox21: 0.715287 test loss: 0.630248
[Epoch 119; Iter    28/  209] train: loss: 0.0072542
[Epoch 119; Iter    58/  209] train: loss: 0.0174462
[Epoch 119; Iter    88/  209] train: loss: 0.0073820
[Epoch 119; Iter   118/  209] train: loss: 0.0163955
[Epoch 119; Iter   148/  209] train: loss: 0.0088364
[Epoch 119; Iter   178/  209] train: loss: 0.0073029
[Epoch 119; Iter   208/  209] train: loss: 0.0129905
[Epoch 119] ogbg-moltox21: 0.738253 val loss: 1.114200
[Epoch 119] ogbg-moltox21: 0.712040 test loss: 0.636846
[Epoch 120; Iter    29/  209] train: loss: 0.0045367
[Epoch 120; Iter    59/  209] train: loss: 0.0183371
[Epoch 120; Iter    89/  209] train: loss: 0.0097318
[Epoch 120; Iter   119/  209] train: loss: 0.0080481
[Epoch 120; Iter   149/  209] train: loss: 0.0137742
[Epoch 120; Iter   179/  209] train: loss: 0.0059678
[Epoch 120; Iter   209/  209] train: loss: 0.0291058
[Epoch 120] ogbg-moltox21: 0.735430 val loss: 1.131667
[Epoch 120] ogbg-moltox21: 0.712236 test loss: 0.632081
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 18.
Statistics on  val_best_checkpoint
mean_pred: -3.25032639503479
std_pred: 1.6111804246902466
mean_targets: nan
std_targets: nan
prcauc: 0.3907252660201274
rocauc: 0.7975102936718051
ogbg-moltox21: 0.7975102936718051
OGBNanLabelBCEWithLogitsLoss: 0.24122139066457748
Statistics on  test
mean_pred: -3.2252516746520996
std_pred: 1.6446945667266846
mean_targets: nan
std_targets: nan
prcauc: 0.33833406179993136
rocauc: 0.7470944194110221
ogbg-moltox21: 0.7470944194110221
OGBNanLabelBCEWithLogitsLoss: 0.259793210360739
Statistics on  train
mean_pred: -3.7691683769226074
std_pred: 1.7861007452011108
mean_targets: nan
std_targets: nan
prcauc: 0.5307394108155886
rocauc: 0.8943895693813046
ogbg-moltox21: 0.8943895693813046
OGBNanLabelBCEWithLogitsLoss: 0.15620766733394284
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
[Epoch 116; Iter   145/  209] train: loss: 0.0006029
[Epoch 116; Iter   175/  209] train: loss: 0.0084315
[Epoch 116; Iter   205/  209] train: loss: 0.0012624
[Epoch 116] ogbg-moltox21: 0.709230 val loss: 1.147217
[Epoch 116] ogbg-moltox21: 0.670912 test loss: 1.276858
[Epoch 117; Iter    26/  209] train: loss: 0.0032699
[Epoch 117; Iter    56/  209] train: loss: 0.0109936
[Epoch 117; Iter    86/  209] train: loss: 0.0036241
[Epoch 117; Iter   116/  209] train: loss: 0.0014874
[Epoch 117; Iter   146/  209] train: loss: 0.0070625
[Epoch 117; Iter   176/  209] train: loss: 0.0021602
[Epoch 117; Iter   206/  209] train: loss: 0.0044415
[Epoch 117] ogbg-moltox21: 0.712116 val loss: 1.162357
[Epoch 117] ogbg-moltox21: 0.676413 test loss: 1.347478
[Epoch 118; Iter    27/  209] train: loss: 0.0006310
[Epoch 118; Iter    57/  209] train: loss: 0.0033136
[Epoch 118; Iter    87/  209] train: loss: 0.0031891
[Epoch 118; Iter   117/  209] train: loss: 0.0012253
[Epoch 118; Iter   147/  209] train: loss: 0.0015673
[Epoch 118; Iter   177/  209] train: loss: 0.0009741
[Epoch 118; Iter   207/  209] train: loss: 0.0028439
[Epoch 118] ogbg-moltox21: 0.712056 val loss: 1.186695
[Epoch 118] ogbg-moltox21: 0.675907 test loss: 1.363872
[Epoch 119; Iter    28/  209] train: loss: 0.0014293
[Epoch 119; Iter    58/  209] train: loss: 0.0024021
[Epoch 119; Iter    88/  209] train: loss: 0.0012427
[Epoch 119; Iter   118/  209] train: loss: 0.0022087
[Epoch 119; Iter   148/  209] train: loss: 0.0054635
[Epoch 119; Iter   178/  209] train: loss: 0.0038623
[Epoch 119; Iter   208/  209] train: loss: 0.0017180
[Epoch 119] ogbg-moltox21: 0.706169 val loss: 1.224135
[Epoch 119] ogbg-moltox21: 0.669114 test loss: 1.403495
[Epoch 120; Iter    29/  209] train: loss: 0.0019435
[Epoch 120; Iter    59/  209] train: loss: 0.0008309
[Epoch 120; Iter    89/  209] train: loss: 0.0051287
[Epoch 120; Iter   119/  209] train: loss: 0.0013118
[Epoch 120; Iter   149/  209] train: loss: 0.0011989
[Epoch 120; Iter   179/  209] train: loss: 0.0015088
[Epoch 120; Iter   209/  209] train: loss: 0.0024923
[Epoch 120] ogbg-moltox21: 0.709707 val loss: 1.148681
[Epoch 120] ogbg-moltox21: 0.668336 test loss: 1.306602
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 16.
Statistics on  val_best_checkpoint
mean_pred: -3.4672181606292725
std_pred: 5.117690086364746
mean_targets: nan
std_targets: nan
prcauc: 0.32405817171555745
rocauc: 0.763977185762688
ogbg-moltox21: 0.763977185762688
OGBNanLabelBCEWithLogitsLoss: 0.334387451686241
Statistics on  test
mean_pred: -3.572185754776001
std_pred: 7.108961582183838
mean_targets: nan
std_targets: nan
prcauc: 0.2879264127321541
rocauc: 0.7148997715198152
ogbg-moltox21: 0.7148997715198152
OGBNanLabelBCEWithLogitsLoss: 0.46016256842348313
Statistics on  train
mean_pred: -3.5157315731048584
std_pred: 1.6778181791305542
mean_targets: nan
std_targets: nan
prcauc: 0.4412266417073061
rocauc: 0.8694843945462338
ogbg-moltox21: 0.8694843945462338
OGBNanLabelBCEWithLogitsLoss: 0.17605108439779737
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0046376
[Epoch 116; Iter   175/  209] train: loss: 0.0144212
[Epoch 116; Iter   205/  209] train: loss: 0.0078623
[Epoch 116] ogbg-moltox21: 0.753542 val loss: 0.693930
[Epoch 116] ogbg-moltox21: 0.693322 test loss: 0.755408
[Epoch 117; Iter    26/  209] train: loss: 0.0077993
[Epoch 117; Iter    56/  209] train: loss: 0.0087843
[Epoch 117; Iter    86/  209] train: loss: 0.0067219
[Epoch 117; Iter   116/  209] train: loss: 0.0033031
[Epoch 117; Iter   146/  209] train: loss: 0.0061656
[Epoch 117; Iter   176/  209] train: loss: 0.0037411
[Epoch 117; Iter   206/  209] train: loss: 0.0093394
[Epoch 117] ogbg-moltox21: 0.754022 val loss: 0.702278
[Epoch 117] ogbg-moltox21: 0.691299 test loss: 0.750740
[Epoch 118; Iter    27/  209] train: loss: 0.0054811
[Epoch 118; Iter    57/  209] train: loss: 0.0051917
[Epoch 118; Iter    87/  209] train: loss: 0.0079738
[Epoch 118; Iter   117/  209] train: loss: 0.0037528
[Epoch 118; Iter   147/  209] train: loss: 0.0048339
[Epoch 118; Iter   177/  209] train: loss: 0.0043447
[Epoch 118; Iter   207/  209] train: loss: 0.0062339
[Epoch 118] ogbg-moltox21: 0.753373 val loss: 0.718869
[Epoch 118] ogbg-moltox21: 0.691121 test loss: 0.766233
[Epoch 119; Iter    28/  209] train: loss: 0.0049462
[Epoch 119; Iter    58/  209] train: loss: 0.0072782
[Epoch 119; Iter    88/  209] train: loss: 0.0034036
[Epoch 119; Iter   118/  209] train: loss: 0.0071853
[Epoch 119; Iter   148/  209] train: loss: 0.0091156
[Epoch 119; Iter   178/  209] train: loss: 0.0093142
[Epoch 119; Iter   208/  209] train: loss: 0.0064602
[Epoch 119] ogbg-moltox21: 0.755233 val loss: 0.719519
[Epoch 119] ogbg-moltox21: 0.693831 test loss: 0.760280
[Epoch 120; Iter    29/  209] train: loss: 0.0024795
[Epoch 120; Iter    59/  209] train: loss: 0.0036138
[Epoch 120; Iter    89/  209] train: loss: 0.0064369
[Epoch 120; Iter   119/  209] train: loss: 0.0059551
[Epoch 120; Iter   149/  209] train: loss: 0.0039600
[Epoch 120; Iter   179/  209] train: loss: 0.0022632
[Epoch 120; Iter   209/  209] train: loss: 0.0105668
[Epoch 120] ogbg-moltox21: 0.755833 val loss: 0.672906
[Epoch 120] ogbg-moltox21: 0.695754 test loss: 0.736577
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 20.
Statistics on  val_best_checkpoint
mean_pred: -3.2805099487304688
std_pred: 2.077491044998169
mean_targets: nan
std_targets: nan
prcauc: 0.37858397799525595
rocauc: 0.8054444519911249
ogbg-moltox21: 0.8054444519911249
OGBNanLabelBCEWithLogitsLoss: 0.2646549097089856
Statistics on  test
mean_pred: -3.297330856323242
std_pred: 2.1233267784118652
mean_targets: nan
std_targets: nan
prcauc: 0.3255941130258031
rocauc: 0.7346579524942718
ogbg-moltox21: 0.7346579524942718
OGBNanLabelBCEWithLogitsLoss: 0.2944642625473164
Statistics on  train
mean_pred: -3.9306766986846924
std_pred: 2.019169330596924
mean_targets: nan
std_targets: nan
prcauc: 0.5709276075635233
rocauc: 0.9094164073693901
ogbg-moltox21: 0.9094164073693901
OGBNanLabelBCEWithLogitsLoss: 0.14623041511580134
[Epoch 116; Iter   145/  209] train: loss: 0.0243792
[Epoch 116; Iter   175/  209] train: loss: 0.0044008
[Epoch 116; Iter   205/  209] train: loss: 0.0199672
[Epoch 116] ogbg-moltox21: 0.753890 val loss: 0.705029
[Epoch 116] ogbg-moltox21: 0.708717 test loss: 0.911693
[Epoch 117; Iter    26/  209] train: loss: 0.0123651
[Epoch 117; Iter    56/  209] train: loss: 0.0104371
[Epoch 117; Iter    86/  209] train: loss: 0.0247723
[Epoch 117; Iter   116/  209] train: loss: 0.0024922
[Epoch 117; Iter   146/  209] train: loss: 0.0123351
[Epoch 117; Iter   176/  209] train: loss: 0.0159750
[Epoch 117; Iter   206/  209] train: loss: 0.0253710
[Epoch 117] ogbg-moltox21: 0.749013 val loss: 0.690651
[Epoch 117] ogbg-moltox21: 0.708203 test loss: 0.784008
[Epoch 118; Iter    27/  209] train: loss: 0.0257464
[Epoch 118; Iter    57/  209] train: loss: 0.0316689
[Epoch 118; Iter    87/  209] train: loss: 0.0203460
[Epoch 118; Iter   117/  209] train: loss: 0.0130346
[Epoch 118; Iter   147/  209] train: loss: 0.0245532
[Epoch 118; Iter   177/  209] train: loss: 0.0116868
[Epoch 118; Iter   207/  209] train: loss: 0.0111909
[Epoch 118] ogbg-moltox21: 0.760753 val loss: 0.630818
[Epoch 118] ogbg-moltox21: 0.710460 test loss: 0.771532
[Epoch 119; Iter    28/  209] train: loss: 0.0250089
[Epoch 119; Iter    58/  209] train: loss: 0.0409624
[Epoch 119; Iter    88/  209] train: loss: 0.0156557
[Epoch 119; Iter   118/  209] train: loss: 0.0149230
[Epoch 119; Iter   148/  209] train: loss: 0.0045501
[Epoch 119; Iter   178/  209] train: loss: 0.0254501
[Epoch 119; Iter   208/  209] train: loss: 0.0042824
[Epoch 119] ogbg-moltox21: 0.745682 val loss: 0.650976
[Epoch 119] ogbg-moltox21: 0.710253 test loss: 0.725917
[Epoch 120; Iter    29/  209] train: loss: 0.0126372
[Epoch 120; Iter    59/  209] train: loss: 0.0063224
[Epoch 120; Iter    89/  209] train: loss: 0.0103292
[Epoch 120; Iter   119/  209] train: loss: 0.0060912
[Epoch 120; Iter   149/  209] train: loss: 0.0235658
[Epoch 120; Iter   179/  209] train: loss: 0.0061506
[Epoch 120; Iter   209/  209] train: loss: 0.0124649
[Epoch 120] ogbg-moltox21: 0.750210 val loss: 0.685643
[Epoch 120] ogbg-moltox21: 0.716265 test loss: 0.952291
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 16.
Statistics on  val_best_checkpoint
mean_pred: -2.9154207706451416
std_pred: 1.702826976776123
mean_targets: nan
std_targets: nan
prcauc: 0.37256699568227886
rocauc: 0.7854421529370007
ogbg-moltox21: 0.7854421529370007
OGBNanLabelBCEWithLogitsLoss: 0.24823485825348784
Statistics on  test
mean_pred: -2.9489707946777344
std_pred: 1.7139503955841064
mean_targets: nan
std_targets: nan
prcauc: 0.29096317624253126
rocauc: 0.7414977576508966
ogbg-moltox21: 0.7414977576508966
OGBNanLabelBCEWithLogitsLoss: 0.2719822034791664
Statistics on  train
mean_pred: -3.2662436962127686
std_pred: 1.6429638862609863
mean_targets: nan
std_targets: nan
prcauc: 0.4307820947089414
rocauc: 0.8705240403258041
ogbg-moltox21: 0.8705240403258041
OGBNanLabelBCEWithLogitsLoss: 0.17418968820115596
[Epoch 116; Iter   145/  209] train: loss: 0.0208718
[Epoch 116; Iter   175/  209] train: loss: 0.0100563
[Epoch 116; Iter   205/  209] train: loss: 0.0117906
[Epoch 116] ogbg-moltox21: 0.717067 val loss: 0.541030
[Epoch 116] ogbg-moltox21: 0.707844 test loss: 0.589963
[Epoch 117; Iter    26/  209] train: loss: 0.0105012
[Epoch 117; Iter    56/  209] train: loss: 0.0158472
[Epoch 117; Iter    86/  209] train: loss: 0.0146455
[Epoch 117; Iter   116/  209] train: loss: 0.0165228
[Epoch 117; Iter   146/  209] train: loss: 0.0130672
[Epoch 117; Iter   176/  209] train: loss: 0.0190097
[Epoch 117; Iter   206/  209] train: loss: 0.0127411
[Epoch 117] ogbg-moltox21: 0.716587 val loss: 0.553513
[Epoch 117] ogbg-moltox21: 0.706870 test loss: 0.591167
[Epoch 118; Iter    27/  209] train: loss: 0.0167086
[Epoch 118; Iter    57/  209] train: loss: 0.0084296
[Epoch 118; Iter    87/  209] train: loss: 0.0269794
[Epoch 118; Iter   117/  209] train: loss: 0.0197695
[Epoch 118; Iter   147/  209] train: loss: 0.0365891
[Epoch 118; Iter   177/  209] train: loss: 0.0101641
[Epoch 118; Iter   207/  209] train: loss: 0.0146254
[Epoch 118] ogbg-moltox21: 0.717512 val loss: 0.558412
[Epoch 118] ogbg-moltox21: 0.708205 test loss: 0.589194
[Epoch 119; Iter    28/  209] train: loss: 0.0433264
[Epoch 119; Iter    58/  209] train: loss: 0.0134991
[Epoch 119; Iter    88/  209] train: loss: 0.0188881
[Epoch 119; Iter   118/  209] train: loss: 0.0185553
[Epoch 119; Iter   148/  209] train: loss: 0.0259865
[Epoch 119; Iter   178/  209] train: loss: 0.0145413
[Epoch 119; Iter   208/  209] train: loss: 0.0104242
[Epoch 119] ogbg-moltox21: 0.715685 val loss: 0.556340
[Epoch 119] ogbg-moltox21: 0.709262 test loss: 0.588462
[Epoch 120; Iter    29/  209] train: loss: 0.0172021
[Epoch 120; Iter    59/  209] train: loss: 0.0134486
[Epoch 120; Iter    89/  209] train: loss: 0.0168872
[Epoch 120; Iter   119/  209] train: loss: 0.0099610
[Epoch 120; Iter   149/  209] train: loss: 0.0079576
[Epoch 120; Iter   179/  209] train: loss: 0.0078954
[Epoch 120; Iter   209/  209] train: loss: 0.0091408
[Epoch 120] ogbg-moltox21: 0.715860 val loss: 0.551983
[Epoch 120] ogbg-moltox21: 0.707676 test loss: 0.589455
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 25.
Statistics on  val_best_checkpoint
mean_pred: -2.6360108852386475
std_pred: 1.8789385557174683
mean_targets: nan
std_targets: nan
prcauc: 0.3614528924639087
rocauc: 0.7973484527015455
ogbg-moltox21: 0.7973484527015455
OGBNanLabelBCEWithLogitsLoss: 0.25962190495596993
Statistics on  test
mean_pred: -2.7690951824188232
std_pred: 4.9669013023376465
mean_targets: nan
std_targets: nan
prcauc: 0.3332338103474202
rocauc: 0.7370723338290213
ogbg-moltox21: 0.7370723338290213
OGBNanLabelBCEWithLogitsLoss: 0.27846708452260055
Statistics on  train
mean_pred: -2.9727330207824707
std_pred: 2.1781651973724365
mean_targets: nan
std_targets: nan
prcauc: 0.4548502971003594
rocauc: 0.8773461251752152
ogbg-moltox21: 0.8773461251752152
OGBNanLabelBCEWithLogitsLoss: 0.18416595177359557
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
[Epoch 116; Iter   145/  209] train: loss: 0.0129384
[Epoch 116; Iter   175/  209] train: loss: 0.0104513
[Epoch 116; Iter   205/  209] train: loss: 0.0102166
[Epoch 116] ogbg-moltox21: 0.736250 val loss: 0.877777
[Epoch 116] ogbg-moltox21: 0.692980 test loss: 0.948929
[Epoch 117; Iter    26/  209] train: loss: 0.0078279
[Epoch 117; Iter    56/  209] train: loss: 0.0035230
[Epoch 117; Iter    86/  209] train: loss: 0.0186203
[Epoch 117; Iter   116/  209] train: loss: 0.0041210
[Epoch 117; Iter   146/  209] train: loss: 0.0117136
[Epoch 117; Iter   176/  209] train: loss: 0.0085996
[Epoch 117; Iter   206/  209] train: loss: 0.0062951
[Epoch 117] ogbg-moltox21: 0.740026 val loss: 0.882231
[Epoch 117] ogbg-moltox21: 0.696342 test loss: 0.949440
[Epoch 118; Iter    27/  209] train: loss: 0.0035337
[Epoch 118; Iter    57/  209] train: loss: 0.0186853
[Epoch 118; Iter    87/  209] train: loss: 0.0111681
[Epoch 118; Iter   117/  209] train: loss: 0.0069652
[Epoch 118; Iter   147/  209] train: loss: 0.0052804
[Epoch 118; Iter   177/  209] train: loss: 0.0116656
[Epoch 118; Iter   207/  209] train: loss: 0.0059148
[Epoch 118] ogbg-moltox21: 0.741013 val loss: 0.899633
[Epoch 118] ogbg-moltox21: 0.696603 test loss: 0.971107
[Epoch 119; Iter    28/  209] train: loss: 0.0032934
[Epoch 119; Iter    58/  209] train: loss: 0.0250391
[Epoch 119; Iter    88/  209] train: loss: 0.0093819
[Epoch 119; Iter   118/  209] train: loss: 0.0048709
[Epoch 119; Iter   148/  209] train: loss: 0.0080940
[Epoch 119; Iter   178/  209] train: loss: 0.0067741
[Epoch 119; Iter   208/  209] train: loss: 0.0060429
[Epoch 119] ogbg-moltox21: 0.739130 val loss: 0.885705
[Epoch 119] ogbg-moltox21: 0.695794 test loss: 0.957478
[Epoch 120; Iter    29/  209] train: loss: 0.0106656
[Epoch 120; Iter    59/  209] train: loss: 0.0040604
[Epoch 120; Iter    89/  209] train: loss: 0.0059456
[Epoch 120; Iter   119/  209] train: loss: 0.0053508
[Epoch 120; Iter   149/  209] train: loss: 0.0464864
[Epoch 120; Iter   179/  209] train: loss: 0.0163596
[Epoch 120; Iter   209/  209] train: loss: 0.0051867
[Epoch 120] ogbg-moltox21: 0.743422 val loss: 0.886242
[Epoch 120] ogbg-moltox21: 0.699453 test loss: 0.959331
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -4.419583797454834
std_pred: 2.0803885459899902
mean_targets: nan
std_targets: nan
prcauc: 0.3572425731571049
rocauc: 0.7665607824365664
ogbg-moltox21: 0.7665607824365664
OGBNanLabelBCEWithLogitsLoss: 0.29553127068060414
Statistics on  test
mean_pred: -4.48988151550293
std_pred: 2.266721487045288
mean_targets: nan
std_targets: nan
prcauc: 0.3134686598777863
rocauc: 0.7218527641352916
ogbg-moltox21: 0.7218527641352916
OGBNanLabelBCEWithLogitsLoss: 0.3205356752430951
Statistics on  train
mean_pred: -3.8714747428894043
std_pred: 1.790982961654663
mean_targets: nan
std_targets: nan
prcauc: 0.5192669790247862
rocauc: 0.8904675724996284
ogbg-moltox21: 0.8904675724996284
OGBNanLabelBCEWithLogitsLoss: 0.15914546830232063
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 82; Iter    51/  209] train: loss: 0.0725430
[Epoch 82; Iter    81/  209] train: loss: 0.1001963
[Epoch 82; Iter   111/  209] train: loss: 0.0640790
[Epoch 82; Iter   141/  209] train: loss: 0.0810324
[Epoch 82; Iter   171/  209] train: loss: 0.0459613
[Epoch 82; Iter   201/  209] train: loss: 0.0798600
[Epoch 82] ogbg-moltox21: 0.776220 val loss: 0.338951
[Epoch 82] ogbg-moltox21: 0.749628 test loss: 0.367478
[Epoch 83; Iter    22/  209] train: loss: 0.0973993
[Epoch 83; Iter    52/  209] train: loss: 0.1233302
[Epoch 83; Iter    82/  209] train: loss: 0.0570335
[Epoch 83; Iter   112/  209] train: loss: 0.0839100
[Epoch 83; Iter   142/  209] train: loss: 0.1435740
[Epoch 83; Iter   172/  209] train: loss: 0.0749003
[Epoch 83; Iter   202/  209] train: loss: 0.1121935
[Epoch 83] ogbg-moltox21: 0.781361 val loss: 0.340148
[Epoch 83] ogbg-moltox21: 0.749689 test loss: 0.363355
[Epoch 84; Iter    23/  209] train: loss: 0.0738801
[Epoch 84; Iter    53/  209] train: loss: 0.0684646
[Epoch 84; Iter    83/  209] train: loss: 0.0694140
[Epoch 84; Iter   113/  209] train: loss: 0.0757102
[Epoch 84; Iter   143/  209] train: loss: 0.0747226
[Epoch 84; Iter   173/  209] train: loss: 0.0785628
[Epoch 84; Iter   203/  209] train: loss: 0.0960058
[Epoch 84] ogbg-moltox21: 0.769940 val loss: 0.341672
[Epoch 84] ogbg-moltox21: 0.747655 test loss: 0.369646
[Epoch 85; Iter    24/  209] train: loss: 0.0693527
[Epoch 85; Iter    54/  209] train: loss: 0.1054951
[Epoch 85; Iter    84/  209] train: loss: 0.0577356
[Epoch 85; Iter   114/  209] train: loss: 0.1157345
[Epoch 85; Iter   144/  209] train: loss: 0.1212536
[Epoch 85; Iter   174/  209] train: loss: 0.0508360
[Epoch 85; Iter   204/  209] train: loss: 0.0794405
[Epoch 85] ogbg-moltox21: 0.772469 val loss: 0.342305
[Epoch 85] ogbg-moltox21: 0.744684 test loss: 0.361814
[Epoch 86; Iter    25/  209] train: loss: 0.0513361
[Epoch 86; Iter    55/  209] train: loss: 0.0634019
[Epoch 86; Iter    85/  209] train: loss: 0.0831763
[Epoch 86; Iter   115/  209] train: loss: 0.0877816
[Epoch 86; Iter   145/  209] train: loss: 0.0815408
[Epoch 86; Iter   175/  209] train: loss: 0.0718493
[Epoch 86; Iter   205/  209] train: loss: 0.0680002
[Epoch 86] ogbg-moltox21: 0.771605 val loss: 0.343459
[Epoch 86] ogbg-moltox21: 0.746402 test loss: 0.372777
[Epoch 87; Iter    26/  209] train: loss: 0.0463718
[Epoch 87; Iter    56/  209] train: loss: 0.0710163
[Epoch 87; Iter    86/  209] train: loss: 0.0767013
[Epoch 87; Iter   116/  209] train: loss: 0.0657540
[Epoch 87; Iter   146/  209] train: loss: 0.1248367
[Epoch 87; Iter   176/  209] train: loss: 0.0611162
[Epoch 87; Iter   206/  209] train: loss: 0.0935860
[Epoch 87] ogbg-moltox21: 0.773232 val loss: 0.345482
[Epoch 87] ogbg-moltox21: 0.748620 test loss: 0.372243
[Epoch 88; Iter    27/  209] train: loss: 0.0616939
[Epoch 88; Iter    57/  209] train: loss: 0.0832247
[Epoch 88; Iter    87/  209] train: loss: 0.0772208
[Epoch 88; Iter   117/  209] train: loss: 0.0803495
[Epoch 88; Iter   147/  209] train: loss: 0.0559605
[Epoch 88; Iter   177/  209] train: loss: 0.0794011
[Epoch 88; Iter   207/  209] train: loss: 0.0555957
[Epoch 88] ogbg-moltox21: 0.769948 val loss: 0.352331
[Epoch 88] ogbg-moltox21: 0.736323 test loss: 0.376895
[Epoch 89; Iter    28/  209] train: loss: 0.0422733
[Epoch 89; Iter    58/  209] train: loss: 0.0922243
[Epoch 89; Iter    88/  209] train: loss: 0.0560595
[Epoch 89; Iter   118/  209] train: loss: 0.0616500
[Epoch 89; Iter   148/  209] train: loss: 0.0847750
[Epoch 89; Iter   178/  209] train: loss: 0.0685400
[Epoch 89; Iter   208/  209] train: loss: 0.0726958
[Epoch 89] ogbg-moltox21: 0.770875 val loss: 0.351931
[Epoch 89] ogbg-moltox21: 0.743543 test loss: 0.386681
[Epoch 90; Iter    29/  209] train: loss: 0.0756674
[Epoch 90; Iter    59/  209] train: loss: 0.0668129
[Epoch 90; Iter    89/  209] train: loss: 0.0656482
[Epoch 90; Iter   119/  209] train: loss: 0.1430505
[Epoch 90; Iter   149/  209] train: loss: 0.0913606
[Epoch 90; Iter   179/  209] train: loss: 0.0764447
[Epoch 90; Iter   209/  209] train: loss: 0.0462351
[Epoch 90] ogbg-moltox21: 0.768265 val loss: 0.366032
[Epoch 90] ogbg-moltox21: 0.741995 test loss: 0.395670
[Epoch 91; Iter    30/  209] train: loss: 0.0629349
[Epoch 91; Iter    60/  209] train: loss: 0.0525088
[Epoch 91; Iter    90/  209] train: loss: 0.0765087
[Epoch 91; Iter   120/  209] train: loss: 0.0695508
[Epoch 91; Iter   150/  209] train: loss: 0.1078240
[Epoch 91; Iter   180/  209] train: loss: 0.0546276
[Epoch 91] ogbg-moltox21: 0.771477 val loss: 0.362664
[Epoch 91] ogbg-moltox21: 0.742825 test loss: 0.382549
[Epoch 92; Iter     1/  209] train: loss: 0.0526578
[Epoch 92; Iter    31/  209] train: loss: 0.0541139
[Epoch 92; Iter    61/  209] train: loss: 0.0419573
[Epoch 92; Iter    91/  209] train: loss: 0.0610373
[Epoch 92; Iter   121/  209] train: loss: 0.0493302
[Epoch 92; Iter   151/  209] train: loss: 0.0474447
[Epoch 92; Iter   181/  209] train: loss: 0.0427838
[Epoch 92] ogbg-moltox21: 0.770400 val loss: 0.360758
[Epoch 92] ogbg-moltox21: 0.747257 test loss: 0.388154
[Epoch 93; Iter     2/  209] train: loss: 0.0538744
[Epoch 93; Iter    32/  209] train: loss: 0.0781176
[Epoch 93; Iter    62/  209] train: loss: 0.0490459
[Epoch 93; Iter    92/  209] train: loss: 0.0692576
[Epoch 93; Iter   122/  209] train: loss: 0.0800414
[Epoch 93; Iter   152/  209] train: loss: 0.0685561
[Epoch 93; Iter   182/  209] train: loss: 0.0589779
[Epoch 93] ogbg-moltox21: 0.774056 val loss: 0.364039
[Epoch 93] ogbg-moltox21: 0.743491 test loss: 0.400879
[Epoch 94; Iter     3/  209] train: loss: 0.0563149
[Epoch 94; Iter    33/  209] train: loss: 0.0563041
[Epoch 94; Iter    63/  209] train: loss: 0.0464282
[Epoch 94; Iter    93/  209] train: loss: 0.0561782
[Epoch 94; Iter   123/  209] train: loss: 0.0660813
[Epoch 94; Iter   153/  209] train: loss: 0.0593694
[Epoch 94; Iter   183/  209] train: loss: 0.0473421
[Epoch 94] ogbg-moltox21: 0.774343 val loss: 0.359076
[Epoch 94] ogbg-moltox21: 0.750329 test loss: 0.387163
[Epoch 95; Iter     4/  209] train: loss: 0.0513791
[Epoch 95; Iter    34/  209] train: loss: 0.0511821
[Epoch 95; Iter    64/  209] train: loss: 0.0502498
[Epoch 95; Iter    94/  209] train: loss: 0.0746909
[Epoch 95; Iter   124/  209] train: loss: 0.0470968
[Epoch 95; Iter   154/  209] train: loss: 0.0817909
[Epoch 95; Iter   184/  209] train: loss: 0.0447591
[Epoch 95] ogbg-moltox21: 0.773014 val loss: 0.376653
[Epoch 95] ogbg-moltox21: 0.747772 test loss: 0.395782
[Epoch 96; Iter     5/  209] train: loss: 0.0560915
[Epoch 96; Iter    35/  209] train: loss: 0.0737975
[Epoch 96; Iter    65/  209] train: loss: 0.0966553
[Epoch 96; Iter    95/  209] train: loss: 0.0361057
[Epoch 96; Iter   125/  209] train: loss: 0.0651964
[Epoch 96; Iter   155/  209] train: loss: 0.0508195
[Epoch 96; Iter   185/  209] train: loss: 0.0830435
[Epoch 96] ogbg-moltox21: 0.768653 val loss: 0.373980
[Epoch 96] ogbg-moltox21: 0.744707 test loss: 0.391925
[Epoch 97; Iter     6/  209] train: loss: 0.0653689
[Epoch 97; Iter    36/  209] train: loss: 0.0700904
[Epoch 97; Iter    66/  209] train: loss: 0.0760252
[Epoch 97; Iter    96/  209] train: loss: 0.0680145
[Epoch 97; Iter   126/  209] train: loss: 0.0509728
[Epoch 97; Iter   156/  209] train: loss: 0.0404661
[Epoch 97; Iter   186/  209] train: loss: 0.0623405
[Epoch 97] ogbg-moltox21: 0.771743 val loss: 0.379014
[Epoch 97] ogbg-moltox21: 0.748438 test loss: 0.396348
[Epoch 98; Iter     7/  209] train: loss: 0.0646457
[Epoch 98; Iter    37/  209] train: loss: 0.0321255
[Epoch 98; Iter    67/  209] train: loss: 0.1140417
[Epoch 98; Iter    97/  209] train: loss: 0.0405468
[Epoch 98; Iter   127/  209] train: loss: 0.0749172
[Epoch 98; Iter   157/  209] train: loss: 0.0620930
[Epoch 98; Iter   187/  209] train: loss: 0.0882907
[Epoch 98] ogbg-moltox21: 0.772868 val loss: 0.365500
[Epoch 98] ogbg-moltox21: 0.743836 test loss: 0.393989
[Epoch 99; Iter     8/  209] train: loss: 0.0756473
[Epoch 99; Iter    38/  209] train: loss: 0.0470370
[Epoch 99; Iter    68/  209] train: loss: 0.0526681
[Epoch 99; Iter    98/  209] train: loss: 0.0418819
[Epoch 82; Iter    51/  209] train: loss: 0.0518330
[Epoch 82; Iter    81/  209] train: loss: 0.0476690
[Epoch 82; Iter   111/  209] train: loss: 0.1599765
[Epoch 82; Iter   141/  209] train: loss: 0.0550101
[Epoch 82; Iter   171/  209] train: loss: 0.0671384
[Epoch 82; Iter   201/  209] train: loss: 0.0738497
[Epoch 82] ogbg-moltox21: 0.788189 val loss: 0.315955
[Epoch 82] ogbg-moltox21: 0.751015 test loss: 0.327963
[Epoch 83; Iter    22/  209] train: loss: 0.0590824
[Epoch 83; Iter    52/  209] train: loss: 0.1308418
[Epoch 83; Iter    82/  209] train: loss: 0.1105067
[Epoch 83; Iter   112/  209] train: loss: 0.0853672
[Epoch 83; Iter   142/  209] train: loss: 0.1270580
[Epoch 83; Iter   172/  209] train: loss: 0.0808368
[Epoch 83; Iter   202/  209] train: loss: 0.0645604
[Epoch 83] ogbg-moltox21: 0.783868 val loss: 0.327448
[Epoch 83] ogbg-moltox21: 0.750983 test loss: 0.337339
[Epoch 84; Iter    23/  209] train: loss: 0.0657102
[Epoch 84; Iter    53/  209] train: loss: 0.0422946
[Epoch 84; Iter    83/  209] train: loss: 0.0647622
[Epoch 84; Iter   113/  209] train: loss: 0.1379002
[Epoch 84; Iter   143/  209] train: loss: 0.0896059
[Epoch 84; Iter   173/  209] train: loss: 0.0939557
[Epoch 84; Iter   203/  209] train: loss: 0.0343904
[Epoch 84] ogbg-moltox21: 0.779321 val loss: 0.324879
[Epoch 84] ogbg-moltox21: 0.745414 test loss: 0.341391
[Epoch 85; Iter    24/  209] train: loss: 0.0627158
[Epoch 85; Iter    54/  209] train: loss: 0.0638127
[Epoch 85; Iter    84/  209] train: loss: 0.0898075
[Epoch 85; Iter   114/  209] train: loss: 0.1315756
[Epoch 85; Iter   144/  209] train: loss: 0.0586398
[Epoch 85; Iter   174/  209] train: loss: 0.1127436
[Epoch 85; Iter   204/  209] train: loss: 0.0840095
[Epoch 85] ogbg-moltox21: 0.777012 val loss: 0.335624
[Epoch 85] ogbg-moltox21: 0.742050 test loss: 0.340411
[Epoch 86; Iter    25/  209] train: loss: 0.0936177
[Epoch 86; Iter    55/  209] train: loss: 0.0596717
[Epoch 86; Iter    85/  209] train: loss: 0.0903697
[Epoch 86; Iter   115/  209] train: loss: 0.0786409
[Epoch 86; Iter   145/  209] train: loss: 0.0731367
[Epoch 86; Iter   175/  209] train: loss: 0.0795867
[Epoch 86; Iter   205/  209] train: loss: 0.1527187
[Epoch 86] ogbg-moltox21: 0.780803 val loss: 0.327317
[Epoch 86] ogbg-moltox21: 0.750491 test loss: 0.332872
[Epoch 87; Iter    26/  209] train: loss: 0.0635654
[Epoch 87; Iter    56/  209] train: loss: 0.0668658
[Epoch 87; Iter    86/  209] train: loss: 0.0512393
[Epoch 87; Iter   116/  209] train: loss: 0.0802464
[Epoch 87; Iter   146/  209] train: loss: 0.0651133
[Epoch 87; Iter   176/  209] train: loss: 0.0336154
[Epoch 87; Iter   206/  209] train: loss: 0.0485437
[Epoch 87] ogbg-moltox21: 0.783752 val loss: 0.335244
[Epoch 87] ogbg-moltox21: 0.742765 test loss: 0.348378
[Epoch 88; Iter    27/  209] train: loss: 0.0855775
[Epoch 88; Iter    57/  209] train: loss: 0.0695783
[Epoch 88; Iter    87/  209] train: loss: 0.0558653
[Epoch 88; Iter   117/  209] train: loss: 0.0685085
[Epoch 88; Iter   147/  209] train: loss: 0.0637626
[Epoch 88; Iter   177/  209] train: loss: 0.0920168
[Epoch 88; Iter   207/  209] train: loss: 0.0684332
[Epoch 88] ogbg-moltox21: 0.776500 val loss: 0.336723
[Epoch 88] ogbg-moltox21: 0.747132 test loss: 0.350569
[Epoch 89; Iter    28/  209] train: loss: 0.0561511
[Epoch 89; Iter    58/  209] train: loss: 0.1159890
[Epoch 89; Iter    88/  209] train: loss: 0.0911083
[Epoch 89; Iter   118/  209] train: loss: 0.0470615
[Epoch 89; Iter   148/  209] train: loss: 0.0801573
[Epoch 89; Iter   178/  209] train: loss: 0.1104171
[Epoch 89; Iter   208/  209] train: loss: 0.0864963
[Epoch 89] ogbg-moltox21: 0.776442 val loss: 0.332175
[Epoch 89] ogbg-moltox21: 0.739200 test loss: 0.350582
[Epoch 90; Iter    29/  209] train: loss: 0.0583174
[Epoch 90; Iter    59/  209] train: loss: 0.0476267
[Epoch 90; Iter    89/  209] train: loss: 0.0748224
[Epoch 90; Iter   119/  209] train: loss: 0.0549550
[Epoch 90; Iter   149/  209] train: loss: 0.0741767
[Epoch 90; Iter   179/  209] train: loss: 0.0503927
[Epoch 90; Iter   209/  209] train: loss: 0.1470942
[Epoch 90] ogbg-moltox21: 0.771295 val loss: 0.331325
[Epoch 90] ogbg-moltox21: 0.744373 test loss: 0.340460
[Epoch 91; Iter    30/  209] train: loss: 0.0605622
[Epoch 91; Iter    60/  209] train: loss: 0.0452064
[Epoch 91; Iter    90/  209] train: loss: 0.0846332
[Epoch 91; Iter   120/  209] train: loss: 0.0470399
[Epoch 91; Iter   150/  209] train: loss: 0.1021818
[Epoch 91; Iter   180/  209] train: loss: 0.0548551
[Epoch 91] ogbg-moltox21: 0.775725 val loss: 0.337135
[Epoch 91] ogbg-moltox21: 0.740098 test loss: 0.351973
[Epoch 92; Iter     1/  209] train: loss: 0.0443281
[Epoch 92; Iter    31/  209] train: loss: 0.0638357
[Epoch 92; Iter    61/  209] train: loss: 0.0759757
[Epoch 92; Iter    91/  209] train: loss: 0.0517408
[Epoch 92; Iter   121/  209] train: loss: 0.0353424
[Epoch 92; Iter   151/  209] train: loss: 0.0613080
[Epoch 92; Iter   181/  209] train: loss: 0.0384340
[Epoch 92] ogbg-moltox21: 0.769797 val loss: 0.339034
[Epoch 92] ogbg-moltox21: 0.742851 test loss: 0.349440
[Epoch 93; Iter     2/  209] train: loss: 0.1162302
[Epoch 93; Iter    32/  209] train: loss: 0.0463293
[Epoch 93; Iter    62/  209] train: loss: 0.0801323
[Epoch 93; Iter    92/  209] train: loss: 0.0805728
[Epoch 93; Iter   122/  209] train: loss: 0.0827856
[Epoch 93; Iter   152/  209] train: loss: 0.0779268
[Epoch 93; Iter   182/  209] train: loss: 0.0523720
[Epoch 93] ogbg-moltox21: 0.773161 val loss: 0.336966
[Epoch 93] ogbg-moltox21: 0.739066 test loss: 0.366017
[Epoch 94; Iter     3/  209] train: loss: 0.0640316
[Epoch 94; Iter    33/  209] train: loss: 0.0920387
[Epoch 94; Iter    63/  209] train: loss: 0.0660039
[Epoch 94; Iter    93/  209] train: loss: 0.0553020
[Epoch 94; Iter   123/  209] train: loss: 0.1022975
[Epoch 94; Iter   153/  209] train: loss: 0.0616077
[Epoch 94; Iter   183/  209] train: loss: 0.0619468
[Epoch 94] ogbg-moltox21: 0.772905 val loss: 0.338361
[Epoch 94] ogbg-moltox21: 0.744057 test loss: 0.346809
[Epoch 95; Iter     4/  209] train: loss: 0.0480378
[Epoch 95; Iter    34/  209] train: loss: 0.1066636
[Epoch 95; Iter    64/  209] train: loss: 0.0605906
[Epoch 95; Iter    94/  209] train: loss: 0.0963643
[Epoch 95; Iter   124/  209] train: loss: 0.0673929
[Epoch 95; Iter   154/  209] train: loss: 0.0860415
[Epoch 95; Iter   184/  209] train: loss: 0.0814834
[Epoch 95] ogbg-moltox21: 0.774998 val loss: 0.350161
[Epoch 95] ogbg-moltox21: 0.737927 test loss: 0.369768
[Epoch 96; Iter     5/  209] train: loss: 0.0810947
[Epoch 96; Iter    35/  209] train: loss: 0.0490266
[Epoch 96; Iter    65/  209] train: loss: 0.0833511
[Epoch 96; Iter    95/  209] train: loss: 0.0506777
[Epoch 96; Iter   125/  209] train: loss: 0.0229500
[Epoch 96; Iter   155/  209] train: loss: 0.0615081
[Epoch 96; Iter   185/  209] train: loss: 0.0534667
[Epoch 96] ogbg-moltox21: 0.771032 val loss: 0.351044
[Epoch 96] ogbg-moltox21: 0.736577 test loss: 0.359026
[Epoch 97; Iter     6/  209] train: loss: 0.0692640
[Epoch 97; Iter    36/  209] train: loss: 0.0450672
[Epoch 97; Iter    66/  209] train: loss: 0.0853652
[Epoch 97; Iter    96/  209] train: loss: 0.0519153
[Epoch 97; Iter   126/  209] train: loss: 0.0540393
[Epoch 97; Iter   156/  209] train: loss: 0.0732790
[Epoch 97; Iter   186/  209] train: loss: 0.0437284
[Epoch 97] ogbg-moltox21: 0.772319 val loss: 0.347580
[Epoch 97] ogbg-moltox21: 0.740779 test loss: 0.357629
[Epoch 98; Iter     7/  209] train: loss: 0.0634156
[Epoch 98; Iter    37/  209] train: loss: 0.0411833
[Epoch 98; Iter    67/  209] train: loss: 0.0577797
[Epoch 98; Iter    97/  209] train: loss: 0.0986756
[Epoch 98; Iter   127/  209] train: loss: 0.0912767
[Epoch 98; Iter   157/  209] train: loss: 0.0648699
[Epoch 98; Iter   187/  209] train: loss: 0.0615620
[Epoch 98] ogbg-moltox21: 0.767680 val loss: 0.348170
[Epoch 98] ogbg-moltox21: 0.735895 test loss: 0.359837
[Epoch 99; Iter     8/  209] train: loss: 0.1213911
[Epoch 99; Iter    38/  209] train: loss: 0.0709353
[Epoch 99; Iter    68/  209] train: loss: 0.0988458
[Epoch 99; Iter    98/  209] train: loss: 0.1081656
[Epoch 82; Iter    51/  209] train: loss: 0.0711572
[Epoch 82; Iter    81/  209] train: loss: 0.0434579
[Epoch 82; Iter   111/  209] train: loss: 0.0784980
[Epoch 82; Iter   141/  209] train: loss: 0.0816679
[Epoch 82; Iter   171/  209] train: loss: 0.0948126
[Epoch 82; Iter   201/  209] train: loss: 0.1848710
[Epoch 82] ogbg-moltox21: 0.760621 val loss: 0.355336
[Epoch 82] ogbg-moltox21: 0.758880 test loss: 0.350897
[Epoch 83; Iter    22/  209] train: loss: 0.0736081
[Epoch 83; Iter    52/  209] train: loss: 0.0785977
[Epoch 83; Iter    82/  209] train: loss: 0.1155188
[Epoch 83; Iter   112/  209] train: loss: 0.0890214
[Epoch 83; Iter   142/  209] train: loss: 0.0829242
[Epoch 83; Iter   172/  209] train: loss: 0.1184005
[Epoch 83; Iter   202/  209] train: loss: 0.0798765
[Epoch 83] ogbg-moltox21: 0.768831 val loss: 0.356080
[Epoch 83] ogbg-moltox21: 0.765064 test loss: 0.349203
[Epoch 84; Iter    23/  209] train: loss: 0.0789064
[Epoch 84; Iter    53/  209] train: loss: 0.0841754
[Epoch 84; Iter    83/  209] train: loss: 0.0714088
[Epoch 84; Iter   113/  209] train: loss: 0.0434340
[Epoch 84; Iter   143/  209] train: loss: 0.0909617
[Epoch 84; Iter   173/  209] train: loss: 0.0660131
[Epoch 84; Iter   203/  209] train: loss: 0.0908091
[Epoch 84] ogbg-moltox21: 0.770165 val loss: 0.361159
[Epoch 84] ogbg-moltox21: 0.761193 test loss: 0.359068
[Epoch 85; Iter    24/  209] train: loss: 0.0680845
[Epoch 85; Iter    54/  209] train: loss: 0.1835221
[Epoch 85; Iter    84/  209] train: loss: 0.0710378
[Epoch 85; Iter   114/  209] train: loss: 0.0749328
[Epoch 85; Iter   144/  209] train: loss: 0.0631102
[Epoch 85; Iter   174/  209] train: loss: 0.1010808
[Epoch 85; Iter   204/  209] train: loss: 0.0648942
[Epoch 85] ogbg-moltox21: 0.780570 val loss: 0.344903
[Epoch 85] ogbg-moltox21: 0.766428 test loss: 0.351404
[Epoch 86; Iter    25/  209] train: loss: 0.0673084
[Epoch 86; Iter    55/  209] train: loss: 0.0848231
[Epoch 86; Iter    85/  209] train: loss: 0.0787998
[Epoch 86; Iter   115/  209] train: loss: 0.0677288
[Epoch 86; Iter   145/  209] train: loss: 0.1369975
[Epoch 86; Iter   175/  209] train: loss: 0.0990342
[Epoch 86; Iter   205/  209] train: loss: 0.0971326
[Epoch 86] ogbg-moltox21: 0.772697 val loss: 0.345940
[Epoch 86] ogbg-moltox21: 0.766738 test loss: 0.338644
[Epoch 87; Iter    26/  209] train: loss: 0.0520504
[Epoch 87; Iter    56/  209] train: loss: 0.1006585
[Epoch 87; Iter    86/  209] train: loss: 0.0796932
[Epoch 87; Iter   116/  209] train: loss: 0.1183368
[Epoch 87; Iter   146/  209] train: loss: 0.0602777
[Epoch 87; Iter   176/  209] train: loss: 0.0940713
[Epoch 87; Iter   206/  209] train: loss: 0.1339129
[Epoch 87] ogbg-moltox21: 0.768448 val loss: 0.379090
[Epoch 87] ogbg-moltox21: 0.762905 test loss: 0.367524
[Epoch 88; Iter    27/  209] train: loss: 0.0646465
[Epoch 88; Iter    57/  209] train: loss: 0.0713324
[Epoch 88; Iter    87/  209] train: loss: 0.0747978
[Epoch 88; Iter   117/  209] train: loss: 0.0430574
[Epoch 88; Iter   147/  209] train: loss: 0.0853402
[Epoch 88; Iter   177/  209] train: loss: 0.0842308
[Epoch 88; Iter   207/  209] train: loss: 0.0875187
[Epoch 88] ogbg-moltox21: 0.770446 val loss: 0.369161
[Epoch 88] ogbg-moltox21: 0.764896 test loss: 0.358944
[Epoch 89; Iter    28/  209] train: loss: 0.0495570
[Epoch 89; Iter    58/  209] train: loss: 0.0635186
[Epoch 89; Iter    88/  209] train: loss: 0.0885821
[Epoch 89; Iter   118/  209] train: loss: 0.0531914
[Epoch 89; Iter   148/  209] train: loss: 0.0580038
[Epoch 89; Iter   178/  209] train: loss: 0.0701002
[Epoch 89; Iter   208/  209] train: loss: 0.0378547
[Epoch 89] ogbg-moltox21: 0.773501 val loss: 0.358735
[Epoch 89] ogbg-moltox21: 0.769806 test loss: 0.350213
[Epoch 90; Iter    29/  209] train: loss: 0.0531718
[Epoch 90; Iter    59/  209] train: loss: 0.0625147
[Epoch 90; Iter    89/  209] train: loss: 0.0530312
[Epoch 90; Iter   119/  209] train: loss: 0.0609180
[Epoch 90; Iter   149/  209] train: loss: 0.0317723
[Epoch 90; Iter   179/  209] train: loss: 0.0559687
[Epoch 90; Iter   209/  209] train: loss: 0.0450224
[Epoch 90] ogbg-moltox21: 0.775727 val loss: 0.367094
[Epoch 90] ogbg-moltox21: 0.764655 test loss: 0.356152
[Epoch 91; Iter    30/  209] train: loss: 0.0939408
[Epoch 91; Iter    60/  209] train: loss: 0.0643748
[Epoch 91; Iter    90/  209] train: loss: 0.1514179
[Epoch 91; Iter   120/  209] train: loss: 0.0897457
[Epoch 91; Iter   150/  209] train: loss: 0.0876110
[Epoch 91; Iter   180/  209] train: loss: 0.1257544
[Epoch 91] ogbg-moltox21: 0.770116 val loss: 0.375591
[Epoch 91] ogbg-moltox21: 0.763245 test loss: 0.369126
[Epoch 92; Iter     1/  209] train: loss: 0.0766895
[Epoch 92; Iter    31/  209] train: loss: 0.0613683
[Epoch 92; Iter    61/  209] train: loss: 0.0588911
[Epoch 92; Iter    91/  209] train: loss: 0.0535021
[Epoch 92; Iter   121/  209] train: loss: 0.0719875
[Epoch 92; Iter   151/  209] train: loss: 0.0519172
[Epoch 92; Iter   181/  209] train: loss: 0.0463073
[Epoch 92] ogbg-moltox21: 0.769365 val loss: 0.366910
[Epoch 92] ogbg-moltox21: 0.761249 test loss: 0.368965
[Epoch 93; Iter     2/  209] train: loss: 0.0908396
[Epoch 93; Iter    32/  209] train: loss: 0.1230486
[Epoch 93; Iter    62/  209] train: loss: 0.0336001
[Epoch 93; Iter    92/  209] train: loss: 0.0770092
[Epoch 93; Iter   122/  209] train: loss: 0.0336309
[Epoch 93; Iter   152/  209] train: loss: 0.0478208
[Epoch 93; Iter   182/  209] train: loss: 0.0431744
[Epoch 93] ogbg-moltox21: 0.765115 val loss: 0.370447
[Epoch 93] ogbg-moltox21: 0.763088 test loss: 0.362778
[Epoch 94; Iter     3/  209] train: loss: 0.0417955
[Epoch 94; Iter    33/  209] train: loss: 0.0497940
[Epoch 94; Iter    63/  209] train: loss: 0.0605540
[Epoch 94; Iter    93/  209] train: loss: 0.0550969
[Epoch 94; Iter   123/  209] train: loss: 0.0518866
[Epoch 94; Iter   153/  209] train: loss: 0.0703200
[Epoch 94; Iter   183/  209] train: loss: 0.0963699
[Epoch 94] ogbg-moltox21: 0.769960 val loss: 0.375084
[Epoch 94] ogbg-moltox21: 0.758171 test loss: 0.368723
[Epoch 95; Iter     4/  209] train: loss: 0.0990727
[Epoch 95; Iter    34/  209] train: loss: 0.0564624
[Epoch 95; Iter    64/  209] train: loss: 0.1001489
[Epoch 95; Iter    94/  209] train: loss: 0.0458311
[Epoch 95; Iter   124/  209] train: loss: 0.0771546
[Epoch 95; Iter   154/  209] train: loss: 0.0627012
[Epoch 95; Iter   184/  209] train: loss: 0.1037417
[Epoch 95] ogbg-moltox21: 0.764414 val loss: 0.367282
[Epoch 95] ogbg-moltox21: 0.764678 test loss: 0.361745
[Epoch 96; Iter     5/  209] train: loss: 0.0441501
[Epoch 96; Iter    35/  209] train: loss: 0.0620599
[Epoch 96; Iter    65/  209] train: loss: 0.0761012
[Epoch 96; Iter    95/  209] train: loss: 0.0818494
[Epoch 96; Iter   125/  209] train: loss: 0.0749135
[Epoch 96; Iter   155/  209] train: loss: 0.0813397
[Epoch 96; Iter   185/  209] train: loss: 0.0623023
[Epoch 96] ogbg-moltox21: 0.765500 val loss: 0.374000
[Epoch 96] ogbg-moltox21: 0.763245 test loss: 0.363665
[Epoch 97; Iter     6/  209] train: loss: 0.0833505
[Epoch 97; Iter    36/  209] train: loss: 0.0719781
[Epoch 97; Iter    66/  209] train: loss: 0.0872677
[Epoch 97; Iter    96/  209] train: loss: 0.0609012
[Epoch 97; Iter   126/  209] train: loss: 0.0553727
[Epoch 97; Iter   156/  209] train: loss: 0.1249456
[Epoch 97; Iter   186/  209] train: loss: 0.0471672
[Epoch 97] ogbg-moltox21: 0.767167 val loss: 0.397149
[Epoch 97] ogbg-moltox21: 0.760779 test loss: 0.378257
[Epoch 98; Iter     7/  209] train: loss: 0.0362921
[Epoch 98; Iter    37/  209] train: loss: 0.0752675
[Epoch 98; Iter    67/  209] train: loss: 0.0562631
[Epoch 98; Iter    97/  209] train: loss: 0.1216699
[Epoch 98; Iter   127/  209] train: loss: 0.0395624
[Epoch 98; Iter   157/  209] train: loss: 0.0647686
[Epoch 98; Iter   187/  209] train: loss: 0.0643078
[Epoch 98] ogbg-moltox21: 0.766037 val loss: 0.377391
[Epoch 98] ogbg-moltox21: 0.760057 test loss: 0.369645
[Epoch 99; Iter     8/  209] train: loss: 0.0400948
[Epoch 99; Iter    38/  209] train: loss: 0.0372867
[Epoch 99; Iter    68/  209] train: loss: 0.0750146
[Epoch 99; Iter    98/  209] train: loss: 0.0636882
[Epoch 99; Iter   128/  209] train: loss: 0.0441263
[Epoch 99; Iter   158/  209] train: loss: 0.0556908
[Epoch 99; Iter   188/  209] train: loss: 0.0675666
[Epoch 99] ogbg-moltox21: 0.771362 val loss: 0.375980
[Epoch 99] ogbg-moltox21: 0.742347 test loss: 0.406782
[Epoch 100; Iter     9/  209] train: loss: 0.0463792
[Epoch 100; Iter    39/  209] train: loss: 0.0560691
[Epoch 100; Iter    69/  209] train: loss: 0.0996337
[Epoch 100; Iter    99/  209] train: loss: 0.0576895
[Epoch 100; Iter   129/  209] train: loss: 0.0498974
[Epoch 100; Iter   159/  209] train: loss: 0.0344322
[Epoch 100; Iter   189/  209] train: loss: 0.0482664
[Epoch 100] ogbg-moltox21: 0.773850 val loss: 0.373836
[Epoch 100] ogbg-moltox21: 0.745053 test loss: 0.402341
[Epoch 101; Iter    10/  209] train: loss: 0.0887212
[Epoch 101; Iter    40/  209] train: loss: 0.0456000
[Epoch 101; Iter    70/  209] train: loss: 0.0590708
[Epoch 101; Iter   100/  209] train: loss: 0.0459037
[Epoch 101; Iter   130/  209] train: loss: 0.0560848
[Epoch 101; Iter   160/  209] train: loss: 0.0790376
[Epoch 101; Iter   190/  209] train: loss: 0.0612523
[Epoch 101] ogbg-moltox21: 0.777634 val loss: 0.377150
[Epoch 101] ogbg-moltox21: 0.747896 test loss: 0.410043
[Epoch 102; Iter    11/  209] train: loss: 0.0374726
[Epoch 102; Iter    41/  209] train: loss: 0.0651359
[Epoch 102; Iter    71/  209] train: loss: 0.0734626
[Epoch 102; Iter   101/  209] train: loss: 0.0797047
[Epoch 102; Iter   131/  209] train: loss: 0.0477794
[Epoch 102; Iter   161/  209] train: loss: 0.0800012
[Epoch 102; Iter   191/  209] train: loss: 0.0545298
[Epoch 102] ogbg-moltox21: 0.770457 val loss: 0.376718
[Epoch 102] ogbg-moltox21: 0.744835 test loss: 0.404013
[Epoch 103; Iter    12/  209] train: loss: 0.0470392
[Epoch 103; Iter    42/  209] train: loss: 0.0569607
[Epoch 103; Iter    72/  209] train: loss: 0.0584774
[Epoch 103; Iter   102/  209] train: loss: 0.0395738
[Epoch 103; Iter   132/  209] train: loss: 0.0916698
[Epoch 103; Iter   162/  209] train: loss: 0.0646775
[Epoch 103; Iter   192/  209] train: loss: 0.0894912
[Epoch 103] ogbg-moltox21: 0.770065 val loss: 0.393506
[Epoch 103] ogbg-moltox21: 0.742894 test loss: 0.423611
[Epoch 104; Iter    13/  209] train: loss: 0.1038368
[Epoch 104; Iter    43/  209] train: loss: 0.0497360
[Epoch 104; Iter    73/  209] train: loss: 0.0507033
[Epoch 104; Iter   103/  209] train: loss: 0.0671088
[Epoch 104; Iter   133/  209] train: loss: 0.0501683
[Epoch 104; Iter   163/  209] train: loss: 0.1236537
[Epoch 104; Iter   193/  209] train: loss: 0.0516699
[Epoch 104] ogbg-moltox21: 0.769666 val loss: 0.387526
[Epoch 104] ogbg-moltox21: 0.746841 test loss: 0.430868
[Epoch 105; Iter    14/  209] train: loss: 0.0361839
[Epoch 105; Iter    44/  209] train: loss: 0.0619164
[Epoch 105; Iter    74/  209] train: loss: 0.0635683
[Epoch 105; Iter   104/  209] train: loss: 0.0597692
[Epoch 105; Iter   134/  209] train: loss: 0.0335892
[Epoch 105; Iter   164/  209] train: loss: 0.1066915
[Epoch 105; Iter   194/  209] train: loss: 0.0636868
[Epoch 105] ogbg-moltox21: 0.768559 val loss: 0.373784
[Epoch 105] ogbg-moltox21: 0.748083 test loss: 0.403156
[Epoch 106; Iter    15/  209] train: loss: 0.0434563
[Epoch 106; Iter    45/  209] train: loss: 0.0441010
[Epoch 106; Iter    75/  209] train: loss: 0.0525239
[Epoch 106; Iter   105/  209] train: loss: 0.0647810
[Epoch 106; Iter   135/  209] train: loss: 0.0609816
[Epoch 106; Iter   165/  209] train: loss: 0.0596300
[Epoch 106; Iter   195/  209] train: loss: 0.0399477
[Epoch 106] ogbg-moltox21: 0.769267 val loss: 0.386608
[Epoch 106] ogbg-moltox21: 0.747822 test loss: 0.418260
[Epoch 107; Iter    16/  209] train: loss: 0.0591182
[Epoch 107; Iter    46/  209] train: loss: 0.0681483
[Epoch 107; Iter    76/  209] train: loss: 0.0435285
[Epoch 107; Iter   106/  209] train: loss: 0.0737525
[Epoch 107; Iter   136/  209] train: loss: 0.0564752
[Epoch 107; Iter   166/  209] train: loss: 0.0522679
[Epoch 107; Iter   196/  209] train: loss: 0.0736990
[Epoch 107] ogbg-moltox21: 0.768918 val loss: 0.391328
[Epoch 107] ogbg-moltox21: 0.743029 test loss: 0.425352
[Epoch 108; Iter    17/  209] train: loss: 0.0449586
[Epoch 108; Iter    47/  209] train: loss: 0.0533151
[Epoch 108; Iter    77/  209] train: loss: 0.0547003
[Epoch 108; Iter   107/  209] train: loss: 0.0643482
[Epoch 108; Iter   137/  209] train: loss: 0.0618367
[Epoch 108; Iter   167/  209] train: loss: 0.0541999
[Epoch 108; Iter   197/  209] train: loss: 0.0650458
[Epoch 108] ogbg-moltox21: 0.766125 val loss: 0.388035
[Epoch 108] ogbg-moltox21: 0.735836 test loss: 0.444097
[Epoch 109; Iter    18/  209] train: loss: 0.0343476
[Epoch 109; Iter    48/  209] train: loss: 0.0459751
[Epoch 109; Iter    78/  209] train: loss: 0.0360144
[Epoch 109; Iter   108/  209] train: loss: 0.0790827
[Epoch 109; Iter   138/  209] train: loss: 0.0610106
[Epoch 109; Iter   168/  209] train: loss: 0.0862281
[Epoch 109; Iter   198/  209] train: loss: 0.0508916
[Epoch 109] ogbg-moltox21: 0.770647 val loss: 0.384400
[Epoch 109] ogbg-moltox21: 0.740018 test loss: 0.439492
[Epoch 110; Iter    19/  209] train: loss: 0.0637634
[Epoch 110; Iter    49/  209] train: loss: 0.0535110
[Epoch 110; Iter    79/  209] train: loss: 0.0800962
[Epoch 110; Iter   109/  209] train: loss: 0.0443691
[Epoch 110; Iter   139/  209] train: loss: 0.0755055
[Epoch 110; Iter   169/  209] train: loss: 0.0711369
[Epoch 110; Iter   199/  209] train: loss: 0.0744185
[Epoch 110] ogbg-moltox21: 0.769882 val loss: 0.396889
[Epoch 110] ogbg-moltox21: 0.737801 test loss: 0.482174
[Epoch 111; Iter    20/  209] train: loss: 0.0828247
[Epoch 111; Iter    50/  209] train: loss: 0.0708097
[Epoch 111; Iter    80/  209] train: loss: 0.0639625
[Epoch 111; Iter   110/  209] train: loss: 0.0460609
[Epoch 111; Iter   140/  209] train: loss: 0.0924375
[Epoch 111; Iter   170/  209] train: loss: 0.0481960
[Epoch 111; Iter   200/  209] train: loss: 0.0544476
[Epoch 111] ogbg-moltox21: 0.768777 val loss: 0.405410
[Epoch 111] ogbg-moltox21: 0.741358 test loss: 0.444089
[Epoch 112; Iter    21/  209] train: loss: 0.0585522
[Epoch 112; Iter    51/  209] train: loss: 0.1014652
[Epoch 112; Iter    81/  209] train: loss: 0.0540382
[Epoch 112; Iter   111/  209] train: loss: 0.0440389
[Epoch 112; Iter   141/  209] train: loss: 0.0361991
[Epoch 112; Iter   171/  209] train: loss: 0.0511475
[Epoch 112; Iter   201/  209] train: loss: 0.0432682
[Epoch 112] ogbg-moltox21: 0.767769 val loss: 0.397750
[Epoch 112] ogbg-moltox21: 0.741814 test loss: 0.424808
[Epoch 113; Iter    22/  209] train: loss: 0.0709133
[Epoch 113; Iter    52/  209] train: loss: 0.0773340
[Epoch 113; Iter    82/  209] train: loss: 0.0752798
[Epoch 113; Iter   112/  209] train: loss: 0.0777504
[Epoch 113; Iter   142/  209] train: loss: 0.0873265
[Epoch 113; Iter   172/  209] train: loss: 0.0938323
[Epoch 113; Iter   202/  209] train: loss: 0.0642778
[Epoch 113] ogbg-moltox21: 0.766212 val loss: 0.393024
[Epoch 113] ogbg-moltox21: 0.742743 test loss: 0.426144
[Epoch 114; Iter    23/  209] train: loss: 0.0535347
[Epoch 114; Iter    53/  209] train: loss: 0.0310354
[Epoch 114; Iter    83/  209] train: loss: 0.0536493
[Epoch 114; Iter   113/  209] train: loss: 0.0513067
[Epoch 114; Iter   143/  209] train: loss: 0.0625342
[Epoch 114; Iter   173/  209] train: loss: 0.0544604
[Epoch 114; Iter   203/  209] train: loss: 0.0700343
[Epoch 114] ogbg-moltox21: 0.766613 val loss: 0.397102
[Epoch 114] ogbg-moltox21: 0.741606 test loss: 0.431012
[Epoch 115; Iter    24/  209] train: loss: 0.0655766
[Epoch 115; Iter    54/  209] train: loss: 0.0834379
[Epoch 115; Iter    84/  209] train: loss: 0.0809078
[Epoch 115; Iter   114/  209] train: loss: 0.0468533
[Epoch 115; Iter   144/  209] train: loss: 0.0754743
[Epoch 115; Iter   174/  209] train: loss: 0.0949403
[Epoch 115; Iter   204/  209] train: loss: 0.0579465
[Epoch 115] ogbg-moltox21: 0.767767 val loss: 0.396692
[Epoch 115] ogbg-moltox21: 0.738398 test loss: 0.435728
[Epoch 116; Iter    25/  209] train: loss: 0.1182524
[Epoch 116; Iter    55/  209] train: loss: 0.0424018
[Epoch 116; Iter    85/  209] train: loss: 0.0417413
[Epoch 116; Iter   115/  209] train: loss: 0.0353635
[Epoch 99; Iter   128/  209] train: loss: 0.0441587
[Epoch 99; Iter   158/  209] train: loss: 0.0627399
[Epoch 99; Iter   188/  209] train: loss: 0.0769472
[Epoch 99] ogbg-moltox21: 0.776178 val loss: 0.351517
[Epoch 99] ogbg-moltox21: 0.742465 test loss: 0.367470
[Epoch 100; Iter     9/  209] train: loss: 0.0665328
[Epoch 100; Iter    39/  209] train: loss: 0.0700250
[Epoch 100; Iter    69/  209] train: loss: 0.0937028
[Epoch 100; Iter    99/  209] train: loss: 0.0551070
[Epoch 100; Iter   129/  209] train: loss: 0.0803414
[Epoch 100; Iter   159/  209] train: loss: 0.0755508
[Epoch 100; Iter   189/  209] train: loss: 0.0714462
[Epoch 100] ogbg-moltox21: 0.770807 val loss: 0.351826
[Epoch 100] ogbg-moltox21: 0.737420 test loss: 0.381128
[Epoch 101; Iter    10/  209] train: loss: 0.0491738
[Epoch 101; Iter    40/  209] train: loss: 0.0902198
[Epoch 101; Iter    70/  209] train: loss: 0.0587606
[Epoch 101; Iter   100/  209] train: loss: 0.0595682
[Epoch 101; Iter   130/  209] train: loss: 0.0351642
[Epoch 101; Iter   160/  209] train: loss: 0.0305823
[Epoch 101; Iter   190/  209] train: loss: 0.0501512
[Epoch 101] ogbg-moltox21: 0.776588 val loss: 0.354394
[Epoch 101] ogbg-moltox21: 0.742926 test loss: 0.362100
[Epoch 102; Iter    11/  209] train: loss: 0.0516402
[Epoch 102; Iter    41/  209] train: loss: 0.0699681
[Epoch 102; Iter    71/  209] train: loss: 0.0343964
[Epoch 102; Iter   101/  209] train: loss: 0.0377688
[Epoch 102; Iter   131/  209] train: loss: 0.1119954
[Epoch 102; Iter   161/  209] train: loss: 0.0882464
[Epoch 102; Iter   191/  209] train: loss: 0.0452086
[Epoch 102] ogbg-moltox21: 0.776204 val loss: 0.353580
[Epoch 102] ogbg-moltox21: 0.744462 test loss: 0.379462
[Epoch 103; Iter    12/  209] train: loss: 0.0724503
[Epoch 103; Iter    42/  209] train: loss: 0.0566988
[Epoch 103; Iter    72/  209] train: loss: 0.0467517
[Epoch 103; Iter   102/  209] train: loss: 0.0472732
[Epoch 103; Iter   132/  209] train: loss: 0.0838247
[Epoch 103; Iter   162/  209] train: loss: 0.0553860
[Epoch 103; Iter   192/  209] train: loss: 0.0788756
[Epoch 103] ogbg-moltox21: 0.771232 val loss: 0.363657
[Epoch 103] ogbg-moltox21: 0.744469 test loss: 0.366643
[Epoch 104; Iter    13/  209] train: loss: 0.0512921
[Epoch 104; Iter    43/  209] train: loss: 0.0788246
[Epoch 104; Iter    73/  209] train: loss: 0.0410033
[Epoch 104; Iter   103/  209] train: loss: 0.0462980
[Epoch 104; Iter   133/  209] train: loss: 0.0613716
[Epoch 104; Iter   163/  209] train: loss: 0.0570497
[Epoch 104; Iter   193/  209] train: loss: 0.0852459
[Epoch 104] ogbg-moltox21: 0.771616 val loss: 0.369172
[Epoch 104] ogbg-moltox21: 0.741447 test loss: 0.376700
[Epoch 105; Iter    14/  209] train: loss: 0.0714449
[Epoch 105; Iter    44/  209] train: loss: 0.0994097
[Epoch 105; Iter    74/  209] train: loss: 0.0683637
[Epoch 105; Iter   104/  209] train: loss: 0.0392043
[Epoch 105; Iter   134/  209] train: loss: 0.0490029
[Epoch 105; Iter   164/  209] train: loss: 0.0526523
[Epoch 105; Iter   194/  209] train: loss: 0.0445407
[Epoch 105] ogbg-moltox21: 0.770840 val loss: 0.362975
[Epoch 105] ogbg-moltox21: 0.744286 test loss: 0.379416
[Epoch 106; Iter    15/  209] train: loss: 0.0434420
[Epoch 106; Iter    45/  209] train: loss: 0.0663174
[Epoch 106; Iter    75/  209] train: loss: 0.0509695
[Epoch 106; Iter   105/  209] train: loss: 0.1568085
[Epoch 106; Iter   135/  209] train: loss: 0.0526438
[Epoch 106; Iter   165/  209] train: loss: 0.0671387
[Epoch 106; Iter   195/  209] train: loss: 0.0360240
[Epoch 106] ogbg-moltox21: 0.767412 val loss: 0.365813
[Epoch 106] ogbg-moltox21: 0.743226 test loss: 0.369688
[Epoch 107; Iter    16/  209] train: loss: 0.0809484
[Epoch 107; Iter    46/  209] train: loss: 0.1061852
[Epoch 107; Iter    76/  209] train: loss: 0.0646984
[Epoch 107; Iter   106/  209] train: loss: 0.0417491
[Epoch 107; Iter   136/  209] train: loss: 0.0745104
[Epoch 107; Iter   166/  209] train: loss: 0.0628205
[Epoch 107; Iter   196/  209] train: loss: 0.0641983
[Epoch 107] ogbg-moltox21: 0.772561 val loss: 0.368446
[Epoch 107] ogbg-moltox21: 0.739839 test loss: 0.378215
[Epoch 108; Iter    17/  209] train: loss: 0.0750799
[Epoch 108; Iter    47/  209] train: loss: 0.0545920
[Epoch 108; Iter    77/  209] train: loss: 0.0657970
[Epoch 108; Iter   107/  209] train: loss: 0.1046040
[Epoch 108; Iter   137/  209] train: loss: 0.0483420
[Epoch 108; Iter   167/  209] train: loss: 0.0767315
[Epoch 108; Iter   197/  209] train: loss: 0.0752937
[Epoch 108] ogbg-moltox21: 0.765423 val loss: 0.366687
[Epoch 108] ogbg-moltox21: 0.741562 test loss: 0.375099
[Epoch 109; Iter    18/  209] train: loss: 0.0832451
[Epoch 109; Iter    48/  209] train: loss: 0.0617771
[Epoch 109; Iter    78/  209] train: loss: 0.0492008
[Epoch 109; Iter   108/  209] train: loss: 0.0794780
[Epoch 109; Iter   138/  209] train: loss: 0.0758737
[Epoch 109; Iter   168/  209] train: loss: 0.0750958
[Epoch 109; Iter   198/  209] train: loss: 0.0617084
[Epoch 109] ogbg-moltox21: 0.771835 val loss: 0.376174
[Epoch 109] ogbg-moltox21: 0.741809 test loss: 0.385484
[Epoch 110; Iter    19/  209] train: loss: 0.0706138
[Epoch 110; Iter    49/  209] train: loss: 0.0508039
[Epoch 110; Iter    79/  209] train: loss: 0.0688825
[Epoch 110; Iter   109/  209] train: loss: 0.0640657
[Epoch 110; Iter   139/  209] train: loss: 0.1005582
[Epoch 110; Iter   169/  209] train: loss: 0.0378611
[Epoch 110; Iter   199/  209] train: loss: 0.0677829
[Epoch 110] ogbg-moltox21: 0.767812 val loss: 0.364369
[Epoch 110] ogbg-moltox21: 0.738238 test loss: 0.373624
[Epoch 111; Iter    20/  209] train: loss: 0.1053819
[Epoch 111; Iter    50/  209] train: loss: 0.0405529
[Epoch 111; Iter    80/  209] train: loss: 0.0602944
[Epoch 111; Iter   110/  209] train: loss: 0.0905235
[Epoch 111; Iter   140/  209] train: loss: 0.0514609
[Epoch 111; Iter   170/  209] train: loss: 0.1106434
[Epoch 111; Iter   200/  209] train: loss: 0.0401308
[Epoch 111] ogbg-moltox21: 0.772097 val loss: 0.383042
[Epoch 111] ogbg-moltox21: 0.740234 test loss: 0.386578
[Epoch 112; Iter    21/  209] train: loss: 0.0575232
[Epoch 112; Iter    51/  209] train: loss: 0.0562587
[Epoch 112; Iter    81/  209] train: loss: 0.0557764
[Epoch 112; Iter   111/  209] train: loss: 0.0802493
[Epoch 112; Iter   141/  209] train: loss: 0.0411451
[Epoch 112; Iter   171/  209] train: loss: 0.0624177
[Epoch 112; Iter   201/  209] train: loss: 0.0604410
[Epoch 112] ogbg-moltox21: 0.769305 val loss: 0.373119
[Epoch 112] ogbg-moltox21: 0.736616 test loss: 0.398562
[Epoch 113; Iter    22/  209] train: loss: 0.0979690
[Epoch 113; Iter    52/  209] train: loss: 0.0478530
[Epoch 113; Iter    82/  209] train: loss: 0.0761964
[Epoch 113; Iter   112/  209] train: loss: 0.0744827
[Epoch 113; Iter   142/  209] train: loss: 0.0823886
[Epoch 113; Iter   172/  209] train: loss: 0.0610171
[Epoch 113; Iter   202/  209] train: loss: 0.0601926
[Epoch 113] ogbg-moltox21: 0.764225 val loss: 0.376083
[Epoch 113] ogbg-moltox21: 0.731179 test loss: 0.391229
[Epoch 114; Iter    23/  209] train: loss: 0.1390830
[Epoch 114; Iter    53/  209] train: loss: 0.0525924
[Epoch 114; Iter    83/  209] train: loss: 0.0761394
[Epoch 114; Iter   113/  209] train: loss: 0.0428763
[Epoch 114; Iter   143/  209] train: loss: 0.0623476
[Epoch 114; Iter   173/  209] train: loss: 0.0404544
[Epoch 114; Iter   203/  209] train: loss: 0.0735969
[Epoch 114] ogbg-moltox21: 0.766422 val loss: 0.377389
[Epoch 114] ogbg-moltox21: 0.738371 test loss: 0.389625
[Epoch 115; Iter    24/  209] train: loss: 0.0653644
[Epoch 115; Iter    54/  209] train: loss: 0.0416708
[Epoch 115; Iter    84/  209] train: loss: 0.0697174
[Epoch 115; Iter   114/  209] train: loss: 0.0322115
[Epoch 115; Iter   144/  209] train: loss: 0.0371240
[Epoch 115; Iter   174/  209] train: loss: 0.0755565
[Epoch 115; Iter   204/  209] train: loss: 0.0272353
[Epoch 115] ogbg-moltox21: 0.769461 val loss: 0.372841
[Epoch 115] ogbg-moltox21: 0.741883 test loss: 0.386638
[Epoch 116; Iter    25/  209] train: loss: 0.0697116
[Epoch 116; Iter    55/  209] train: loss: 0.0458352
[Epoch 116; Iter    85/  209] train: loss: 0.0555013
[Epoch 116; Iter   115/  209] train: loss: 0.0452338
[Epoch 99; Iter   128/  209] train: loss: 0.0591169
[Epoch 99; Iter   158/  209] train: loss: 0.1019996
[Epoch 99; Iter   188/  209] train: loss: 0.0359723
[Epoch 99] ogbg-moltox21: 0.766608 val loss: 0.376704
[Epoch 99] ogbg-moltox21: 0.760912 test loss: 0.369379
[Epoch 100; Iter     9/  209] train: loss: 0.0650032
[Epoch 100; Iter    39/  209] train: loss: 0.0816758
[Epoch 100; Iter    69/  209] train: loss: 0.0636692
[Epoch 100; Iter    99/  209] train: loss: 0.1240366
[Epoch 100; Iter   129/  209] train: loss: 0.1071423
[Epoch 100; Iter   159/  209] train: loss: 0.0785143
[Epoch 100; Iter   189/  209] train: loss: 0.0545183
[Epoch 100] ogbg-moltox21: 0.764357 val loss: 0.375303
[Epoch 100] ogbg-moltox21: 0.757832 test loss: 0.369746
[Epoch 101; Iter    10/  209] train: loss: 0.0477725
[Epoch 101; Iter    40/  209] train: loss: 0.0463722
[Epoch 101; Iter    70/  209] train: loss: 0.0795989
[Epoch 101; Iter   100/  209] train: loss: 0.0788683
[Epoch 101; Iter   130/  209] train: loss: 0.0630960
[Epoch 101; Iter   160/  209] train: loss: 0.0686456
[Epoch 101; Iter   190/  209] train: loss: 0.0504540
[Epoch 101] ogbg-moltox21: 0.764346 val loss: 0.389323
[Epoch 101] ogbg-moltox21: 0.753841 test loss: 0.376646
[Epoch 102; Iter    11/  209] train: loss: 0.0631009
[Epoch 102; Iter    41/  209] train: loss: 0.0607256
[Epoch 102; Iter    71/  209] train: loss: 0.0416654
[Epoch 102; Iter   101/  209] train: loss: 0.0494663
[Epoch 102; Iter   131/  209] train: loss: 0.0803184
[Epoch 102; Iter   161/  209] train: loss: 0.0997620
[Epoch 102; Iter   191/  209] train: loss: 0.0966171
[Epoch 102] ogbg-moltox21: 0.768637 val loss: 0.374520
[Epoch 102] ogbg-moltox21: 0.758476 test loss: 0.369414
[Epoch 103; Iter    12/  209] train: loss: 0.0550865
[Epoch 103; Iter    42/  209] train: loss: 0.0511544
[Epoch 103; Iter    72/  209] train: loss: 0.0537305
[Epoch 103; Iter   102/  209] train: loss: 0.0399553
[Epoch 103; Iter   132/  209] train: loss: 0.0774472
[Epoch 103; Iter   162/  209] train: loss: 0.1531529
[Epoch 103; Iter   192/  209] train: loss: 0.0597090
[Epoch 103] ogbg-moltox21: 0.769011 val loss: 0.378876
[Epoch 103] ogbg-moltox21: 0.758175 test loss: 0.376350
[Epoch 104; Iter    13/  209] train: loss: 0.0627678
[Epoch 104; Iter    43/  209] train: loss: 0.0756791
[Epoch 104; Iter    73/  209] train: loss: 0.0506393
[Epoch 104; Iter   103/  209] train: loss: 0.0788967
[Epoch 104; Iter   133/  209] train: loss: 0.0418640
[Epoch 104; Iter   163/  209] train: loss: 0.0948277
[Epoch 104; Iter   193/  209] train: loss: 0.0484490
[Epoch 104] ogbg-moltox21: 0.766885 val loss: 0.385599
[Epoch 104] ogbg-moltox21: 0.760416 test loss: 0.377094
[Epoch 105; Iter    14/  209] train: loss: 0.0625590
[Epoch 105; Iter    44/  209] train: loss: 0.0316041
[Epoch 105; Iter    74/  209] train: loss: 0.0550877
[Epoch 105; Iter   104/  209] train: loss: 0.0559800
[Epoch 105; Iter   134/  209] train: loss: 0.0473708
[Epoch 105; Iter   164/  209] train: loss: 0.0361824
[Epoch 105; Iter   194/  209] train: loss: 0.0294159
[Epoch 105] ogbg-moltox21: 0.763796 val loss: 0.397204
[Epoch 105] ogbg-moltox21: 0.757064 test loss: 0.387095
[Epoch 106; Iter    15/  209] train: loss: 0.0633689
[Epoch 106; Iter    45/  209] train: loss: 0.0429216
[Epoch 106; Iter    75/  209] train: loss: 0.0825706
[Epoch 106; Iter   105/  209] train: loss: 0.0483992
[Epoch 106; Iter   135/  209] train: loss: 0.0482110
[Epoch 106; Iter   165/  209] train: loss: 0.0461953
[Epoch 106; Iter   195/  209] train: loss: 0.0427769
[Epoch 106] ogbg-moltox21: 0.764322 val loss: 0.392447
[Epoch 106] ogbg-moltox21: 0.752279 test loss: 0.389501
[Epoch 107; Iter    16/  209] train: loss: 0.0358564
[Epoch 107; Iter    46/  209] train: loss: 0.0567690
[Epoch 107; Iter    76/  209] train: loss: 0.1238311
[Epoch 107; Iter   106/  209] train: loss: 0.0572983
[Epoch 107; Iter   136/  209] train: loss: 0.0446369
[Epoch 107; Iter   166/  209] train: loss: 0.0698043
[Epoch 107; Iter   196/  209] train: loss: 0.0467722
[Epoch 107] ogbg-moltox21: 0.757996 val loss: 0.399376
[Epoch 107] ogbg-moltox21: 0.748800 test loss: 0.398188
[Epoch 108; Iter    17/  209] train: loss: 0.0614040
[Epoch 108; Iter    47/  209] train: loss: 0.0982926
[Epoch 108; Iter    77/  209] train: loss: 0.0823819
[Epoch 108; Iter   107/  209] train: loss: 0.0783566
[Epoch 108; Iter   137/  209] train: loss: 0.0501519
[Epoch 108; Iter   167/  209] train: loss: 0.0323332
[Epoch 108; Iter   197/  209] train: loss: 0.0883680
[Epoch 108] ogbg-moltox21: 0.760275 val loss: 0.412528
[Epoch 108] ogbg-moltox21: 0.749237 test loss: 0.401610
[Epoch 109; Iter    18/  209] train: loss: 0.0290564
[Epoch 109; Iter    48/  209] train: loss: 0.0613499
[Epoch 109; Iter    78/  209] train: loss: 0.0489124
[Epoch 109; Iter   108/  209] train: loss: 0.0795978
[Epoch 109; Iter   138/  209] train: loss: 0.0502514
[Epoch 109; Iter   168/  209] train: loss: 0.0506764
[Epoch 109; Iter   198/  209] train: loss: 0.0505854
[Epoch 109] ogbg-moltox21: 0.760700 val loss: 0.399186
[Epoch 109] ogbg-moltox21: 0.749216 test loss: 0.398892
[Epoch 110; Iter    19/  209] train: loss: 0.0423668
[Epoch 110; Iter    49/  209] train: loss: 0.0934837
[Epoch 110; Iter    79/  209] train: loss: 0.0448398
[Epoch 110; Iter   109/  209] train: loss: 0.0492747
[Epoch 110; Iter   139/  209] train: loss: 0.0695533
[Epoch 110; Iter   169/  209] train: loss: 0.0410819
[Epoch 110; Iter   199/  209] train: loss: 0.0592592
[Epoch 110] ogbg-moltox21: 0.761566 val loss: 0.402405
[Epoch 110] ogbg-moltox21: 0.745629 test loss: 0.407648
[Epoch 111; Iter    20/  209] train: loss: 0.0613416
[Epoch 111; Iter    50/  209] train: loss: 0.0552694
[Epoch 111; Iter    80/  209] train: loss: 0.0450261
[Epoch 111; Iter   110/  209] train: loss: 0.0349975
[Epoch 111; Iter   140/  209] train: loss: 0.0746524
[Epoch 111; Iter   170/  209] train: loss: 0.0627106
[Epoch 111; Iter   200/  209] train: loss: 0.0496114
[Epoch 111] ogbg-moltox21: 0.767294 val loss: 0.402675
[Epoch 111] ogbg-moltox21: 0.751114 test loss: 0.397240
[Epoch 112; Iter    21/  209] train: loss: 0.0627171
[Epoch 112; Iter    51/  209] train: loss: 0.0509792
[Epoch 112; Iter    81/  209] train: loss: 0.0453791
[Epoch 112; Iter   111/  209] train: loss: 0.0612628
[Epoch 112; Iter   141/  209] train: loss: 0.0786124
[Epoch 112; Iter   171/  209] train: loss: 0.0724016
[Epoch 112; Iter   201/  209] train: loss: 0.0769618
[Epoch 112] ogbg-moltox21: 0.762196 val loss: 0.430617
[Epoch 112] ogbg-moltox21: 0.754827 test loss: 0.411088
[Epoch 113; Iter    22/  209] train: loss: 0.0775208
[Epoch 113; Iter    52/  209] train: loss: 0.0563148
[Epoch 113; Iter    82/  209] train: loss: 0.0509295
[Epoch 113; Iter   112/  209] train: loss: 0.0362219
[Epoch 113; Iter   142/  209] train: loss: 0.0463965
[Epoch 113; Iter   172/  209] train: loss: 0.0446432
[Epoch 113; Iter   202/  209] train: loss: 0.0619291
[Epoch 113] ogbg-moltox21: 0.764961 val loss: 0.394667
[Epoch 113] ogbg-moltox21: 0.756033 test loss: 0.391478
[Epoch 114; Iter    23/  209] train: loss: 0.0450695
[Epoch 114; Iter    53/  209] train: loss: 0.0505537
[Epoch 114; Iter    83/  209] train: loss: 0.0662534
[Epoch 114; Iter   113/  209] train: loss: 0.0629902
[Epoch 114; Iter   143/  209] train: loss: 0.0762014
[Epoch 114; Iter   173/  209] train: loss: 0.0338065
[Epoch 114; Iter   203/  209] train: loss: 0.0616339
[Epoch 114] ogbg-moltox21: 0.759250 val loss: 0.424181
[Epoch 114] ogbg-moltox21: 0.755074 test loss: 0.407442
[Epoch 115; Iter    24/  209] train: loss: 0.0413686
[Epoch 115; Iter    54/  209] train: loss: 0.0497549
[Epoch 115; Iter    84/  209] train: loss: 0.0804903
[Epoch 115; Iter   114/  209] train: loss: 0.0642007
[Epoch 115; Iter   144/  209] train: loss: 0.0527186
[Epoch 115; Iter   174/  209] train: loss: 0.0463554
[Epoch 115; Iter   204/  209] train: loss: 0.1020568
[Epoch 115] ogbg-moltox21: 0.759783 val loss: 0.409682
[Epoch 115] ogbg-moltox21: 0.753963 test loss: 0.401032
[Epoch 116; Iter    25/  209] train: loss: 0.0271598
[Epoch 116; Iter    55/  209] train: loss: 0.0482095
[Epoch 116; Iter    85/  209] train: loss: 0.0718165
[Epoch 116; Iter   115/  209] train: loss: 0.0372269
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0329239
[Epoch 116; Iter   175/  209] train: loss: 0.0918690
[Epoch 116; Iter   205/  209] train: loss: 0.0561115
[Epoch 116] ogbg-moltox21: 0.770098 val loss: 0.395892
[Epoch 116] ogbg-moltox21: 0.740898 test loss: 0.430816
[Epoch 117; Iter    26/  209] train: loss: 0.0500250
[Epoch 117; Iter    56/  209] train: loss: 0.0433741
[Epoch 117; Iter    86/  209] train: loss: 0.0353029
[Epoch 117; Iter   116/  209] train: loss: 0.0523505
[Epoch 117; Iter   146/  209] train: loss: 0.0427154
[Epoch 117; Iter   176/  209] train: loss: 0.0757991
[Epoch 117; Iter   206/  209] train: loss: 0.0583443
[Epoch 117] ogbg-moltox21: 0.771765 val loss: 0.391881
[Epoch 117] ogbg-moltox21: 0.733926 test loss: 0.430355
[Epoch 118; Iter    27/  209] train: loss: 0.0480694
[Epoch 118; Iter    57/  209] train: loss: 0.0360633
[Epoch 118; Iter    87/  209] train: loss: 0.0857075
[Epoch 118; Iter   117/  209] train: loss: 0.0405781
[Epoch 118; Iter   147/  209] train: loss: 0.0742883
[Epoch 118; Iter   177/  209] train: loss: 0.0411938
[Epoch 118; Iter   207/  209] train: loss: 0.0401109
[Epoch 118] ogbg-moltox21: 0.770593 val loss: 0.406027
[Epoch 118] ogbg-moltox21: 0.742171 test loss: 0.429512
[Epoch 119; Iter    28/  209] train: loss: 0.0681023
[Epoch 119; Iter    58/  209] train: loss: 0.0735594
[Epoch 119; Iter    88/  209] train: loss: 0.0410595
[Epoch 119; Iter   118/  209] train: loss: 0.0809080
[Epoch 119; Iter   148/  209] train: loss: 0.0811838
[Epoch 119; Iter   178/  209] train: loss: 0.0494129
[Epoch 119; Iter   208/  209] train: loss: 0.0466192
[Epoch 119] ogbg-moltox21: 0.771512 val loss: 0.399084
[Epoch 119] ogbg-moltox21: 0.740298 test loss: 0.437619
[Epoch 120; Iter    29/  209] train: loss: 0.0481324
[Epoch 120; Iter    59/  209] train: loss: 0.0508017
[Epoch 120; Iter    89/  209] train: loss: 0.0342197
[Epoch 120; Iter   119/  209] train: loss: 0.0599956
[Epoch 120; Iter   149/  209] train: loss: 0.0550511
[Epoch 120; Iter   179/  209] train: loss: 0.0814690
[Epoch 120; Iter   209/  209] train: loss: 0.0758549
[Epoch 120] ogbg-moltox21: 0.773045 val loss: 0.402878
[Epoch 120] ogbg-moltox21: 0.741513 test loss: 0.438784
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 31.
Statistics on  val_best_checkpoint
mean_pred: -3.153897523880005
std_pred: 1.8536348342895508
mean_targets: nan
std_targets: nan
prcauc: 0.3833430494226157
rocauc: 0.8032908387856055
ogbg-moltox21: 0.8032908387856055
OGBNanLabelBCEWithLogitsLoss: 0.2428183693576742
Statistics on  test
mean_pred: -3.1378397941589355
std_pred: 1.8840110301971436
mean_targets: nan
std_targets: nan
prcauc: 0.34272393997526
rocauc: 0.758521247656596
ogbg-moltox21: 0.758521247656596
OGBNanLabelBCEWithLogitsLoss: 0.2617266398889047
Statistics on  train
mean_pred: -4.008512020111084
std_pred: 5.325438976287842
mean_targets: nan
std_targets: nan
prcauc: 0.5245900607300837
rocauc: 0.8982866538869735
ogbg-moltox21: 0.8982866538869735
OGBNanLabelBCEWithLogitsLoss: 0.19861018137213146
[Epoch 116; Iter   145/  209] train: loss: 0.0636148
[Epoch 116; Iter   175/  209] train: loss: 0.0254003
[Epoch 116; Iter   205/  209] train: loss: 0.0865069
[Epoch 116] ogbg-moltox21: 0.769673 val loss: 0.374271
[Epoch 116] ogbg-moltox21: 0.739233 test loss: 0.396382
[Epoch 117; Iter    26/  209] train: loss: 0.0419580
[Epoch 117; Iter    56/  209] train: loss: 0.0272058
[Epoch 117; Iter    86/  209] train: loss: 0.0326828
[Epoch 117; Iter   116/  209] train: loss: 0.0336984
[Epoch 117; Iter   146/  209] train: loss: 0.0552012
[Epoch 117; Iter   176/  209] train: loss: 0.0691631
[Epoch 117; Iter   206/  209] train: loss: 0.0480585
[Epoch 117] ogbg-moltox21: 0.767767 val loss: 0.375417
[Epoch 117] ogbg-moltox21: 0.736312 test loss: 0.392297
[Epoch 118; Iter    27/  209] train: loss: 0.0579534
[Epoch 118; Iter    57/  209] train: loss: 0.0379110
[Epoch 118; Iter    87/  209] train: loss: 0.0348226
[Epoch 118; Iter   117/  209] train: loss: 0.0556704
[Epoch 118; Iter   147/  209] train: loss: 0.0836798
[Epoch 118; Iter   177/  209] train: loss: 0.0380445
[Epoch 118; Iter   207/  209] train: loss: 0.0426165
[Epoch 118] ogbg-moltox21: 0.768169 val loss: 0.381282
[Epoch 118] ogbg-moltox21: 0.737875 test loss: 0.414883
[Epoch 119; Iter    28/  209] train: loss: 0.0659995
[Epoch 119; Iter    58/  209] train: loss: 0.0556386
[Epoch 119; Iter    88/  209] train: loss: 0.0482107
[Epoch 119; Iter   118/  209] train: loss: 0.0576377
[Epoch 119; Iter   148/  209] train: loss: 0.0428298
[Epoch 119; Iter   178/  209] train: loss: 0.0653933
[Epoch 119; Iter   208/  209] train: loss: 0.0467145
[Epoch 119] ogbg-moltox21: 0.768487 val loss: 0.378340
[Epoch 119] ogbg-moltox21: 0.737721 test loss: 0.395341
[Epoch 120; Iter    29/  209] train: loss: 0.0335128
[Epoch 120; Iter    59/  209] train: loss: 0.0485315
[Epoch 120; Iter    89/  209] train: loss: 0.0484893
[Epoch 120; Iter   119/  209] train: loss: 0.0610164
[Epoch 120; Iter   149/  209] train: loss: 0.0463972
[Epoch 120; Iter   179/  209] train: loss: 0.0392446
[Epoch 120; Iter   209/  209] train: loss: 0.0401385
[Epoch 120] ogbg-moltox21: 0.764510 val loss: 0.377462
[Epoch 120] ogbg-moltox21: 0.737062 test loss: 0.388442
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -3.076075792312622
std_pred: 1.8424298763275146
mean_targets: nan
std_targets: nan
prcauc: 0.3932349957890809
rocauc: 0.8086034209448673
ogbg-moltox21: 0.8086034209448673
OGBNanLabelBCEWithLogitsLoss: 0.2388738344113032
Statistics on  test
mean_pred: -3.0839362144470215
std_pred: 1.8378304243087769
mean_targets: nan
std_targets: nan
prcauc: 0.35599012898542354
rocauc: 0.7618302115620171
ogbg-moltox21: 0.7618302115620171
OGBNanLabelBCEWithLogitsLoss: 0.25658995575375027
Statistics on  train
mean_pred: -3.8454396724700928
std_pred: 1.9855694770812988
mean_targets: nan
std_targets: nan
prcauc: 0.565158952582576
rocauc: 0.8976330347502354
ogbg-moltox21: 0.8976330347502354
OGBNanLabelBCEWithLogitsLoss: 0.149294966715945
[Epoch 116; Iter   145/  209] train: loss: 0.0511157
[Epoch 116; Iter   175/  209] train: loss: 0.0409860
[Epoch 116; Iter   205/  209] train: loss: 0.0583154
[Epoch 116] ogbg-moltox21: 0.764984 val loss: 0.416583
[Epoch 116] ogbg-moltox21: 0.754663 test loss: 0.408387
[Epoch 117; Iter    26/  209] train: loss: 0.0559214
[Epoch 117; Iter    56/  209] train: loss: 0.0343312
[Epoch 117; Iter    86/  209] train: loss: 0.0419309
[Epoch 117; Iter   116/  209] train: loss: 0.0790503
[Epoch 117; Iter   146/  209] train: loss: 0.0328962
[Epoch 117; Iter   176/  209] train: loss: 0.0413019
[Epoch 117; Iter   206/  209] train: loss: 0.0355018
[Epoch 117] ogbg-moltox21: 0.760678 val loss: 0.418472
[Epoch 117] ogbg-moltox21: 0.753993 test loss: 0.404937
[Epoch 118; Iter    27/  209] train: loss: 0.0517397
[Epoch 118; Iter    57/  209] train: loss: 0.0937427
[Epoch 118; Iter    87/  209] train: loss: 0.0644285
[Epoch 118; Iter   117/  209] train: loss: 0.0547261
[Epoch 118; Iter   147/  209] train: loss: 0.0524779
[Epoch 118; Iter   177/  209] train: loss: 0.0415096
[Epoch 118; Iter   207/  209] train: loss: 0.0440609
[Epoch 118] ogbg-moltox21: 0.758990 val loss: 0.428124
[Epoch 118] ogbg-moltox21: 0.754324 test loss: 0.412267
[Epoch 119; Iter    28/  209] train: loss: 0.0642106
[Epoch 119; Iter    58/  209] train: loss: 0.0790412
[Epoch 119; Iter    88/  209] train: loss: 0.0704587
[Epoch 119; Iter   118/  209] train: loss: 0.0352011
[Epoch 119; Iter   148/  209] train: loss: 0.0411411
[Epoch 119; Iter   178/  209] train: loss: 0.0570783
[Epoch 119; Iter   208/  209] train: loss: 0.0274233
[Epoch 119] ogbg-moltox21: 0.758999 val loss: 0.432299
[Epoch 119] ogbg-moltox21: 0.753224 test loss: 0.419015
[Epoch 120; Iter    29/  209] train: loss: 0.0673558
[Epoch 120; Iter    59/  209] train: loss: 0.0394293
[Epoch 120; Iter    89/  209] train: loss: 0.0577982
[Epoch 120; Iter   119/  209] train: loss: 0.0544343
[Epoch 120; Iter   149/  209] train: loss: 0.1487872
[Epoch 120; Iter   179/  209] train: loss: 0.0564059
[Epoch 120; Iter   209/  209] train: loss: 0.0306185
[Epoch 120] ogbg-moltox21: 0.761880 val loss: 0.430468
[Epoch 120] ogbg-moltox21: 0.754986 test loss: 0.414475
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 30.
Statistics on  val_best_checkpoint
mean_pred: -3.0236010551452637
std_pred: 2.0374960899353027
mean_targets: nan
std_targets: nan
prcauc: 0.3837829910980109
rocauc: 0.8124456708584313
ogbg-moltox21: 0.8124456708584313
OGBNanLabelBCEWithLogitsLoss: 0.24730173967502736
Statistics on  test
mean_pred: -3.0742950439453125
std_pred: 2.0911715030670166
mean_targets: nan
std_targets: nan
prcauc: 0.3458601124270224
rocauc: 0.758560892370744
ogbg-moltox21: 0.758560892370744
OGBNanLabelBCEWithLogitsLoss: 0.2687999015605008
Statistics on  train
mean_pred: -3.577279567718506
std_pred: 3.209411382675171
mean_targets: nan
std_targets: nan
prcauc: 0.5486655023614448
rocauc: 0.8956772802549802
ogbg-moltox21: 0.8956772802549802
OGBNanLabelBCEWithLogitsLoss: 0.166879425743265
Starting process for seed 4: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/GraphCL/tox21/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
