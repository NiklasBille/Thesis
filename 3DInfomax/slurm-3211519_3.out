>>> Starting run for dataset: hiv
Running configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.0/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.0_6_26-05_10-45-21
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.0
logdir: runs/static_noise/GraphCL/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6924398
[Epoch 1; Iter    60/ 1097] train: loss: 0.6937245
[Epoch 1; Iter    90/ 1097] train: loss: 0.6929802
[Epoch 1; Iter   120/ 1097] train: loss: 0.6926173
[Epoch 1; Iter   150/ 1097] train: loss: 0.6903778
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913554
[Epoch 1; Iter   210/ 1097] train: loss: 0.6923170
[Epoch 1; Iter   240/ 1097] train: loss: 0.6889518
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889689
[Epoch 1; Iter   300/ 1097] train: loss: 0.6894184
[Epoch 1; Iter   330/ 1097] train: loss: 0.6887161
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856205
[Epoch 1; Iter   390/ 1097] train: loss: 0.6872253
[Epoch 1; Iter   420/ 1097] train: loss: 0.6828896
[Epoch 1; Iter   450/ 1097] train: loss: 0.6836463
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798414
[Epoch 1; Iter   510/ 1097] train: loss: 0.6788148
[Epoch 1; Iter   540/ 1097] train: loss: 0.6819549
[Epoch 1; Iter   570/ 1097] train: loss: 0.6792782
[Epoch 1; Iter   600/ 1097] train: loss: 0.6739925
[Epoch 1; Iter   630/ 1097] train: loss: 0.6743887
[Epoch 1; Iter   660/ 1097] train: loss: 0.6734650
[Epoch 1; Iter   690/ 1097] train: loss: 0.6682705
[Epoch 1; Iter   720/ 1097] train: loss: 0.6613860
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408247
[Epoch 1; Iter   780/ 1097] train: loss: 0.6046227
[Epoch 1; Iter   810/ 1097] train: loss: 0.5671275
[Epoch 1; Iter   840/ 1097] train: loss: 0.5009017
[Epoch 1; Iter   870/ 1097] train: loss: 0.4277585
[Epoch 1; Iter   900/ 1097] train: loss: 0.3530954
[Epoch 1; Iter   930/ 1097] train: loss: 0.3823476
[Epoch 1; Iter   960/ 1097] train: loss: 0.2768924
[Epoch 1; Iter   990/ 1097] train: loss: 0.2198012
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2038995
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1162400
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1367576
[Epoch 1] ogbg-molhiv: 0.676244 val loss: 0.135606
[Epoch 1] ogbg-molhiv: 0.623235 test loss: 0.151724
[Epoch 2; Iter    13/ 1097] train: loss: 0.1506402
[Epoch 2; Iter    43/ 1097] train: loss: 0.2434671
[Epoch 2; Iter    73/ 1097] train: loss: 0.0615244
[Epoch 2; Iter   103/ 1097] train: loss: 0.1199270
[Epoch 2; Iter   133/ 1097] train: loss: 0.1829728
[Epoch 2; Iter   163/ 1097] train: loss: 0.1543179
[Epoch 2; Iter   193/ 1097] train: loss: 0.4037243
[Epoch 2; Iter   223/ 1097] train: loss: 0.1467990
[Epoch 2; Iter   253/ 1097] train: loss: 0.1697625
[Epoch 2; Iter   283/ 1097] train: loss: 0.1509592
[Epoch 2; Iter   313/ 1097] train: loss: 0.1040058
[Epoch 2; Iter   343/ 1097] train: loss: 0.1625375
[Epoch 2; Iter   373/ 1097] train: loss: 0.0409805
[Epoch 2; Iter   403/ 1097] train: loss: 0.0551987
[Epoch 2; Iter   433/ 1097] train: loss: 0.2134995
[Epoch 2; Iter   463/ 1097] train: loss: 0.2475459
[Epoch 2; Iter   493/ 1097] train: loss: 0.1475930
[Epoch 2; Iter   523/ 1097] train: loss: 0.2308328
[Epoch 2; Iter   553/ 1097] train: loss: 0.1532574
[Epoch 2; Iter   583/ 1097] train: loss: 0.0479142
[Epoch 2; Iter   613/ 1097] train: loss: 0.2129393
[Epoch 2; Iter   643/ 1097] train: loss: 0.3584108
[Epoch 2; Iter   673/ 1097] train: loss: 0.1605428
[Epoch 2; Iter   703/ 1097] train: loss: 0.1350318
[Epoch 2; Iter   733/ 1097] train: loss: 0.1590535
[Epoch 2; Iter   763/ 1097] train: loss: 0.0336121
[Epoch 2; Iter   793/ 1097] train: loss: 0.1322553
[Epoch 2; Iter   823/ 1097] train: loss: 0.0334504
[Epoch 2; Iter   853/ 1097] train: loss: 0.5784861
[Epoch 2; Iter   883/ 1097] train: loss: 0.1380894
[Epoch 2; Iter   913/ 1097] train: loss: 0.3771990
[Epoch 2; Iter   943/ 1097] train: loss: 0.2623381
[Epoch 2; Iter   973/ 1097] train: loss: 0.0416774
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1096871
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0322569
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0588145
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1373101
[Epoch 2] ogbg-molhiv: 0.704240 val loss: 0.097777
[Epoch 2] ogbg-molhiv: 0.669225 test loss: 0.154974
[Epoch 3; Iter    26/ 1097] train: loss: 0.2683131
[Epoch 3; Iter    56/ 1097] train: loss: 0.1597379
[Epoch 3; Iter    86/ 1097] train: loss: 0.4968908
[Epoch 3; Iter   116/ 1097] train: loss: 0.1224138
[Epoch 3; Iter   146/ 1097] train: loss: 0.1376788
[Epoch 3; Iter   176/ 1097] train: loss: 0.1454568
[Epoch 3; Iter   206/ 1097] train: loss: 0.0447165
[Epoch 3; Iter   236/ 1097] train: loss: 0.4027977
[Epoch 3; Iter   266/ 1097] train: loss: 0.2838451
[Epoch 3; Iter   296/ 1097] train: loss: 0.1275063
[Epoch 3; Iter   326/ 1097] train: loss: 0.1260833
[Epoch 3; Iter   356/ 1097] train: loss: 0.0404377
[Epoch 3; Iter   386/ 1097] train: loss: 0.0950453
[Epoch 3; Iter   416/ 1097] train: loss: 0.1376323
[Epoch 3; Iter   446/ 1097] train: loss: 0.0436937
[Epoch 3; Iter   476/ 1097] train: loss: 0.1688896
[Epoch 3; Iter   506/ 1097] train: loss: 0.0312726
[Epoch 3; Iter   536/ 1097] train: loss: 0.1354459
[Epoch 3; Iter   566/ 1097] train: loss: 0.5009643
[Epoch 3; Iter   596/ 1097] train: loss: 0.4194025
[Epoch 3; Iter   626/ 1097] train: loss: 0.0325132
[Epoch 3; Iter   656/ 1097] train: loss: 0.0369835
[Epoch 3; Iter   686/ 1097] train: loss: 0.3861223
[Epoch 3; Iter   716/ 1097] train: loss: 0.1053190
[Epoch 3; Iter   746/ 1097] train: loss: 0.0927076
[Epoch 3; Iter   776/ 1097] train: loss: 0.1843278
[Epoch 3; Iter   806/ 1097] train: loss: 0.0476887
[Epoch 3; Iter   836/ 1097] train: loss: 0.2865767
[Epoch 3; Iter   866/ 1097] train: loss: 0.0739542
[Epoch 3; Iter   896/ 1097] train: loss: 0.0907499
[Epoch 3; Iter   926/ 1097] train: loss: 0.0410376
[Epoch 3; Iter   956/ 1097] train: loss: 0.0313632
[Epoch 3; Iter   986/ 1097] train: loss: 0.0395912
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.0/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.0_4_26-05_10-45-20
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.0
logdir: runs/static_noise/GraphCL/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932337
[Epoch 1; Iter    60/ 1097] train: loss: 0.6930318
[Epoch 1; Iter    90/ 1097] train: loss: 0.6948986
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924052
[Epoch 1; Iter   150/ 1097] train: loss: 0.6923461
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913102
[Epoch 1; Iter   210/ 1097] train: loss: 0.6904165
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898558
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888524
[Epoch 1; Iter   300/ 1097] train: loss: 0.6887732
[Epoch 1; Iter   330/ 1097] train: loss: 0.6869187
[Epoch 1; Iter   360/ 1097] train: loss: 0.6860681
[Epoch 1; Iter   390/ 1097] train: loss: 0.6841254
[Epoch 1; Iter   420/ 1097] train: loss: 0.6841123
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810826
[Epoch 1; Iter   480/ 1097] train: loss: 0.6790888
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776734
[Epoch 1; Iter   540/ 1097] train: loss: 0.6758243
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738517
[Epoch 1; Iter   600/ 1097] train: loss: 0.6740881
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721455
[Epoch 1; Iter   660/ 1097] train: loss: 0.6719024
[Epoch 1; Iter   690/ 1097] train: loss: 0.6650224
[Epoch 1; Iter   720/ 1097] train: loss: 0.6625296
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411634
[Epoch 1; Iter   780/ 1097] train: loss: 0.6050566
[Epoch 1; Iter   810/ 1097] train: loss: 0.5548797
[Epoch 1; Iter   840/ 1097] train: loss: 0.4945953
[Epoch 1; Iter   870/ 1097] train: loss: 0.4399142
[Epoch 1; Iter   900/ 1097] train: loss: 0.4088780
[Epoch 1; Iter   930/ 1097] train: loss: 0.3726038
[Epoch 1; Iter   960/ 1097] train: loss: 0.3663881
[Epoch 1; Iter   990/ 1097] train: loss: 0.1864756
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1505080
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1198335
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2121353
[Epoch 1] ogbg-molhiv: 0.706946 val loss: 0.123516
[Epoch 1] ogbg-molhiv: 0.728419 test loss: 0.144008
[Epoch 2; Iter    13/ 1097] train: loss: 0.0884399
[Epoch 2; Iter    43/ 1097] train: loss: 0.1266563
[Epoch 2; Iter    73/ 1097] train: loss: 0.0673797
[Epoch 2; Iter   103/ 1097] train: loss: 0.0563453
[Epoch 2; Iter   133/ 1097] train: loss: 0.0494708
[Epoch 2; Iter   163/ 1097] train: loss: 0.0766103
[Epoch 2; Iter   193/ 1097] train: loss: 0.2575420
[Epoch 2; Iter   223/ 1097] train: loss: 0.1601669
[Epoch 2; Iter   253/ 1097] train: loss: 0.3620630
[Epoch 2; Iter   283/ 1097] train: loss: 0.1461845
[Epoch 2; Iter   313/ 1097] train: loss: 0.6657035
[Epoch 2; Iter   343/ 1097] train: loss: 0.1289547
[Epoch 2; Iter   373/ 1097] train: loss: 0.0474828
[Epoch 2; Iter   403/ 1097] train: loss: 0.0816580
[Epoch 2; Iter   433/ 1097] train: loss: 0.4429979
[Epoch 2; Iter   463/ 1097] train: loss: 0.2993086
[Epoch 2; Iter   493/ 1097] train: loss: 0.2181955
[Epoch 2; Iter   523/ 1097] train: loss: 0.0433473
[Epoch 2; Iter   553/ 1097] train: loss: 0.1072452
[Epoch 2; Iter   583/ 1097] train: loss: 0.1095167
[Epoch 2; Iter   613/ 1097] train: loss: 0.0315071
[Epoch 2; Iter   643/ 1097] train: loss: 0.1772724
[Epoch 2; Iter   673/ 1097] train: loss: 0.1699067
[Epoch 2; Iter   703/ 1097] train: loss: 0.1471341
[Epoch 2; Iter   733/ 1097] train: loss: 0.0403298
[Epoch 2; Iter   763/ 1097] train: loss: 0.1237067
[Epoch 2; Iter   793/ 1097] train: loss: 0.2181662
[Epoch 2; Iter   823/ 1097] train: loss: 0.1570981
[Epoch 2; Iter   853/ 1097] train: loss: 0.0376805
[Epoch 2; Iter   883/ 1097] train: loss: 0.1523675
[Epoch 2; Iter   913/ 1097] train: loss: 0.0330853
[Epoch 2; Iter   943/ 1097] train: loss: 0.2612821
[Epoch 2; Iter   973/ 1097] train: loss: 0.2648103
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0363210
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1361368
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1938251
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3875034
[Epoch 2] ogbg-molhiv: 0.742682 val loss: 0.164315
[Epoch 2] ogbg-molhiv: 0.745267 test loss: 0.134746
[Epoch 3; Iter    26/ 1097] train: loss: 0.0304936
[Epoch 3; Iter    56/ 1097] train: loss: 0.2907247
[Epoch 3; Iter    86/ 1097] train: loss: 0.0387298
[Epoch 3; Iter   116/ 1097] train: loss: 0.1133911
[Epoch 3; Iter   146/ 1097] train: loss: 0.0296965
[Epoch 3; Iter   176/ 1097] train: loss: 0.2060938
[Epoch 3; Iter   206/ 1097] train: loss: 0.1844818
[Epoch 3; Iter   236/ 1097] train: loss: 0.2815030
[Epoch 3; Iter   266/ 1097] train: loss: 0.2734357
[Epoch 3; Iter   296/ 1097] train: loss: 0.1632062
[Epoch 3; Iter   326/ 1097] train: loss: 0.0386477
[Epoch 3; Iter   356/ 1097] train: loss: 0.0374443
[Epoch 3; Iter   386/ 1097] train: loss: 0.0299379
[Epoch 3; Iter   416/ 1097] train: loss: 0.1146769
[Epoch 3; Iter   446/ 1097] train: loss: 0.0440214
[Epoch 3; Iter   476/ 1097] train: loss: 0.0406051
[Epoch 3; Iter   506/ 1097] train: loss: 0.1902243
[Epoch 3; Iter   536/ 1097] train: loss: 0.0581767
[Epoch 3; Iter   566/ 1097] train: loss: 0.0459214
[Epoch 3; Iter   596/ 1097] train: loss: 0.3245722
[Epoch 3; Iter   626/ 1097] train: loss: 0.0425647
[Epoch 3; Iter   656/ 1097] train: loss: 0.0326111
[Epoch 3; Iter   686/ 1097] train: loss: 0.1252044
[Epoch 3; Iter   716/ 1097] train: loss: 0.1007368
[Epoch 3; Iter   746/ 1097] train: loss: 0.0285709
[Epoch 3; Iter   776/ 1097] train: loss: 0.1848589
[Epoch 3; Iter   806/ 1097] train: loss: 0.2672479
[Epoch 3; Iter   836/ 1097] train: loss: 0.0277064
[Epoch 3; Iter   866/ 1097] train: loss: 0.3246000
[Epoch 3; Iter   896/ 1097] train: loss: 0.1412223
[Epoch 3; Iter   926/ 1097] train: loss: 0.0275206
[Epoch 3; Iter   956/ 1097] train: loss: 0.1528415
[Epoch 3; Iter   986/ 1097] train: loss: 0.0444654
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.0/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.0_5_26-05_10-45-21
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.0
logdir: runs/static_noise/GraphCL/hiv/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931755
[Epoch 1; Iter    60/ 1097] train: loss: 0.6942084
[Epoch 1; Iter    90/ 1097] train: loss: 0.6929911
[Epoch 1; Iter   120/ 1097] train: loss: 0.6918162
[Epoch 1; Iter   150/ 1097] train: loss: 0.6939001
[Epoch 1; Iter   180/ 1097] train: loss: 0.6895066
[Epoch 1; Iter   210/ 1097] train: loss: 0.6901151
[Epoch 1; Iter   240/ 1097] train: loss: 0.6893087
[Epoch 1; Iter   270/ 1097] train: loss: 0.6894612
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879230
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868504
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856082
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842889
[Epoch 1; Iter   420/ 1097] train: loss: 0.6833008
[Epoch 1; Iter   450/ 1097] train: loss: 0.6820382
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796904
[Epoch 1; Iter   510/ 1097] train: loss: 0.6787589
[Epoch 1; Iter   540/ 1097] train: loss: 0.6784025
[Epoch 1; Iter   570/ 1097] train: loss: 0.6741951
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721469
[Epoch 1; Iter   630/ 1097] train: loss: 0.6707450
[Epoch 1; Iter   660/ 1097] train: loss: 0.6677958
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654670
[Epoch 1; Iter   720/ 1097] train: loss: 0.6620415
[Epoch 1; Iter   750/ 1097] train: loss: 0.6401908
[Epoch 1; Iter   780/ 1097] train: loss: 0.6050695
[Epoch 1; Iter   810/ 1097] train: loss: 0.5550162
[Epoch 1; Iter   840/ 1097] train: loss: 0.4892600
[Epoch 1; Iter   870/ 1097] train: loss: 0.4509248
[Epoch 1; Iter   900/ 1097] train: loss: 0.3540912
[Epoch 1; Iter   930/ 1097] train: loss: 0.3095623
[Epoch 1; Iter   960/ 1097] train: loss: 0.2254927
[Epoch 1; Iter   990/ 1097] train: loss: 0.3960873
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1868164
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2247887
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1455383
[Epoch 1] ogbg-molhiv: 0.683991 val loss: 0.129704
[Epoch 1] ogbg-molhiv: 0.700315 test loss: 0.147472
[Epoch 2; Iter    13/ 1097] train: loss: 0.0804844
[Epoch 2; Iter    43/ 1097] train: loss: 0.0691999
[Epoch 2; Iter    73/ 1097] train: loss: 0.0600288
[Epoch 2; Iter   103/ 1097] train: loss: 0.0490890
[Epoch 2; Iter   133/ 1097] train: loss: 0.1313455
[Epoch 2; Iter   163/ 1097] train: loss: 0.0532522
[Epoch 2; Iter   193/ 1097] train: loss: 0.2572485
[Epoch 2; Iter   223/ 1097] train: loss: 0.0516699
[Epoch 2; Iter   253/ 1097] train: loss: 0.1418556
[Epoch 2; Iter   283/ 1097] train: loss: 0.1240118
[Epoch 2; Iter   313/ 1097] train: loss: 0.1453543
[Epoch 2; Iter   343/ 1097] train: loss: 0.0446745
[Epoch 2; Iter   373/ 1097] train: loss: 0.2413053
[Epoch 2; Iter   403/ 1097] train: loss: 0.2802446
[Epoch 2; Iter   433/ 1097] train: loss: 0.1230917
[Epoch 2; Iter   463/ 1097] train: loss: 0.2653630
[Epoch 2; Iter   493/ 1097] train: loss: 0.0353132
[Epoch 2; Iter   523/ 1097] train: loss: 0.0894790
[Epoch 2; Iter   553/ 1097] train: loss: 0.1487185
[Epoch 2; Iter   583/ 1097] train: loss: 0.2932422
[Epoch 2; Iter   613/ 1097] train: loss: 0.1842712
[Epoch 2; Iter   643/ 1097] train: loss: 0.2338787
[Epoch 2; Iter   673/ 1097] train: loss: 0.0329444
[Epoch 2; Iter   703/ 1097] train: loss: 0.0533881
[Epoch 2; Iter   733/ 1097] train: loss: 0.3035352
[Epoch 2; Iter   763/ 1097] train: loss: 0.2547830
[Epoch 2; Iter   793/ 1097] train: loss: 0.1473566
[Epoch 2; Iter   823/ 1097] train: loss: 0.2617223
[Epoch 2; Iter   853/ 1097] train: loss: 0.0494754
[Epoch 2; Iter   883/ 1097] train: loss: 0.0283402
[Epoch 2; Iter   913/ 1097] train: loss: 0.1483918
[Epoch 2; Iter   943/ 1097] train: loss: 0.2326534
[Epoch 2; Iter   973/ 1097] train: loss: 0.2520090
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1193909
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2080431
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1926289
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1800380
[Epoch 2] ogbg-molhiv: 0.714267 val loss: 0.092754
[Epoch 2] ogbg-molhiv: 0.706843 test loss: 0.123602
[Epoch 3; Iter    26/ 1097] train: loss: 0.1496565
[Epoch 3; Iter    56/ 1097] train: loss: 0.1600954
[Epoch 3; Iter    86/ 1097] train: loss: 0.4573464
[Epoch 3; Iter   116/ 1097] train: loss: 0.0589555
[Epoch 3; Iter   146/ 1097] train: loss: 0.0359599
[Epoch 3; Iter   176/ 1097] train: loss: 0.2929679
[Epoch 3; Iter   206/ 1097] train: loss: 0.0274384
[Epoch 3; Iter   236/ 1097] train: loss: 0.0286868
[Epoch 3; Iter   266/ 1097] train: loss: 0.0464718
[Epoch 3; Iter   296/ 1097] train: loss: 0.0301224
[Epoch 3; Iter   326/ 1097] train: loss: 0.4044516
[Epoch 3; Iter   356/ 1097] train: loss: 0.0311400
[Epoch 3; Iter   386/ 1097] train: loss: 0.2642212
[Epoch 3; Iter   416/ 1097] train: loss: 0.0358456
[Epoch 3; Iter   446/ 1097] train: loss: 0.0398687
[Epoch 3; Iter   476/ 1097] train: loss: 0.1337685
[Epoch 3; Iter   506/ 1097] train: loss: 0.0545726
[Epoch 3; Iter   536/ 1097] train: loss: 0.0952403
[Epoch 3; Iter   566/ 1097] train: loss: 0.1037974
[Epoch 3; Iter   596/ 1097] train: loss: 0.1360060
[Epoch 3; Iter   626/ 1097] train: loss: 0.0329649
[Epoch 3; Iter   656/ 1097] train: loss: 0.1626728
[Epoch 3; Iter   686/ 1097] train: loss: 0.0356005
[Epoch 3; Iter   716/ 1097] train: loss: 0.2479800
[Epoch 3; Iter   746/ 1097] train: loss: 0.1256966
[Epoch 3; Iter   776/ 1097] train: loss: 0.2831394
[Epoch 3; Iter   806/ 1097] train: loss: 0.2751915
[Epoch 3; Iter   836/ 1097] train: loss: 0.1227056
[Epoch 3; Iter   866/ 1097] train: loss: 0.0426561
[Epoch 3; Iter   896/ 1097] train: loss: 0.0602951
[Epoch 3; Iter   926/ 1097] train: loss: 0.4671741
[Epoch 3; Iter   956/ 1097] train: loss: 0.1521043
[Epoch 3; Iter   986/ 1097] train: loss: 0.2399376
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.05/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.05_6_26-05_10-55-08
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.05
logdir: runs/static_noise/GraphCL/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6933537
[Epoch 1; Iter    60/ 1097] train: loss: 0.6947762
[Epoch 1; Iter    90/ 1097] train: loss: 0.6929570
[Epoch 1; Iter   120/ 1097] train: loss: 0.6921134
[Epoch 1; Iter   150/ 1097] train: loss: 0.6908763
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913596
[Epoch 1; Iter   210/ 1097] train: loss: 0.6913506
[Epoch 1; Iter   240/ 1097] train: loss: 0.6883826
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889776
[Epoch 1; Iter   300/ 1097] train: loss: 0.6900390
[Epoch 1; Iter   330/ 1097] train: loss: 0.6894530
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856558
[Epoch 1; Iter   390/ 1097] train: loss: 0.6876584
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829126
[Epoch 1; Iter   450/ 1097] train: loss: 0.6843367
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798916
[Epoch 1; Iter   510/ 1097] train: loss: 0.6781441
[Epoch 1; Iter   540/ 1097] train: loss: 0.6820099
[Epoch 1; Iter   570/ 1097] train: loss: 0.6792116
[Epoch 1; Iter   600/ 1097] train: loss: 0.6735163
[Epoch 1; Iter   630/ 1097] train: loss: 0.6746079
[Epoch 1; Iter   660/ 1097] train: loss: 0.6741931
[Epoch 1; Iter   690/ 1097] train: loss: 0.6682866
[Epoch 1; Iter   720/ 1097] train: loss: 0.6614547
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408966
[Epoch 1; Iter   780/ 1097] train: loss: 0.6047615
[Epoch 1; Iter   810/ 1097] train: loss: 0.5681116
[Epoch 1; Iter   840/ 1097] train: loss: 0.4988148
[Epoch 1; Iter   870/ 1097] train: loss: 0.4262224
[Epoch 1; Iter   900/ 1097] train: loss: 0.3530891
[Epoch 1; Iter   930/ 1097] train: loss: 0.3797399
[Epoch 1; Iter   960/ 1097] train: loss: 0.2763010
[Epoch 1; Iter   990/ 1097] train: loss: 0.2191628
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1960247
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1164251
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1329107
[Epoch 1] ogbg-molhiv: 0.645867 val loss: 0.127573
[Epoch 1] ogbg-molhiv: 0.668449 test loss: 0.152913
[Epoch 2; Iter    13/ 1097] train: loss: 0.1671421
[Epoch 2; Iter    43/ 1097] train: loss: 0.2509880
[Epoch 2; Iter    73/ 1097] train: loss: 0.0612251
[Epoch 2; Iter   103/ 1097] train: loss: 0.1220599
[Epoch 2; Iter   133/ 1097] train: loss: 0.1703302
[Epoch 2; Iter   163/ 1097] train: loss: 0.1502151
[Epoch 2; Iter   193/ 1097] train: loss: 0.3806845
[Epoch 2; Iter   223/ 1097] train: loss: 0.1455786
[Epoch 2; Iter   253/ 1097] train: loss: 0.2074040
[Epoch 2; Iter   283/ 1097] train: loss: 0.1483535
[Epoch 2; Iter   313/ 1097] train: loss: 0.1203241
[Epoch 2; Iter   343/ 1097] train: loss: 0.1606254
[Epoch 2; Iter   373/ 1097] train: loss: 0.0392392
[Epoch 2; Iter   403/ 1097] train: loss: 0.0480187
[Epoch 2; Iter   433/ 1097] train: loss: 0.2618482
[Epoch 2; Iter   463/ 1097] train: loss: 0.2333562
[Epoch 2; Iter   493/ 1097] train: loss: 0.1356259
[Epoch 2; Iter   523/ 1097] train: loss: 0.2309876
[Epoch 2; Iter   553/ 1097] train: loss: 0.1451211
[Epoch 2; Iter   583/ 1097] train: loss: 0.0428759
[Epoch 2; Iter   613/ 1097] train: loss: 0.2988156
[Epoch 2; Iter   643/ 1097] train: loss: 0.3689872
[Epoch 2; Iter   673/ 1097] train: loss: 0.1522239
[Epoch 2; Iter   703/ 1097] train: loss: 0.1159326
[Epoch 2; Iter   733/ 1097] train: loss: 0.1576733
[Epoch 2; Iter   763/ 1097] train: loss: 0.0324565
[Epoch 2; Iter   793/ 1097] train: loss: 0.1341604
[Epoch 2; Iter   823/ 1097] train: loss: 0.0281369
[Epoch 2; Iter   853/ 1097] train: loss: 0.5581896
[Epoch 2; Iter   883/ 1097] train: loss: 0.1496634
[Epoch 2; Iter   913/ 1097] train: loss: 0.3067358
[Epoch 2; Iter   943/ 1097] train: loss: 0.2527271
[Epoch 2; Iter   973/ 1097] train: loss: 0.0352306
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1110574
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0362428
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0872599
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1382016
[Epoch 2] ogbg-molhiv: 0.664459 val loss: 0.206374
[Epoch 2] ogbg-molhiv: 0.637500 test loss: 0.219538
[Epoch 3; Iter    26/ 1097] train: loss: 0.2411788
[Epoch 3; Iter    56/ 1097] train: loss: 0.1464912
[Epoch 3; Iter    86/ 1097] train: loss: 0.5053457
[Epoch 3; Iter   116/ 1097] train: loss: 0.1784364
[Epoch 3; Iter   146/ 1097] train: loss: 0.1355160
[Epoch 3; Iter   176/ 1097] train: loss: 0.1344544
[Epoch 3; Iter   206/ 1097] train: loss: 0.0506836
[Epoch 3; Iter   236/ 1097] train: loss: 0.3936482
[Epoch 3; Iter   266/ 1097] train: loss: 0.2574592
[Epoch 3; Iter   296/ 1097] train: loss: 0.1962166
[Epoch 3; Iter   326/ 1097] train: loss: 0.1391084
[Epoch 3; Iter   356/ 1097] train: loss: 0.0584497
[Epoch 3; Iter   386/ 1097] train: loss: 0.0800673
[Epoch 3; Iter   416/ 1097] train: loss: 0.1188694
[Epoch 3; Iter   446/ 1097] train: loss: 0.0359732
[Epoch 3; Iter   476/ 1097] train: loss: 0.1423877
[Epoch 3; Iter   506/ 1097] train: loss: 0.0439854
[Epoch 3; Iter   536/ 1097] train: loss: 0.1636681
[Epoch 3; Iter   566/ 1097] train: loss: 0.4286488
[Epoch 3; Iter   596/ 1097] train: loss: 0.4541836
[Epoch 3; Iter   626/ 1097] train: loss: 0.0327786
[Epoch 3; Iter   656/ 1097] train: loss: 0.0400073
[Epoch 3; Iter   686/ 1097] train: loss: 0.3498177
[Epoch 3; Iter   716/ 1097] train: loss: 0.1240502
[Epoch 3; Iter   746/ 1097] train: loss: 0.1107722
[Epoch 3; Iter   776/ 1097] train: loss: 0.2303962
[Epoch 3; Iter   806/ 1097] train: loss: 0.0431443
[Epoch 3; Iter   836/ 1097] train: loss: 0.3013704
[Epoch 3; Iter   866/ 1097] train: loss: 0.1022444
[Epoch 3; Iter   896/ 1097] train: loss: 0.0587233
[Epoch 3; Iter   926/ 1097] train: loss: 0.0382379
[Epoch 3; Iter   956/ 1097] train: loss: 0.0299292
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.05/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.05_4_26-05_10-55-15
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.05
logdir: runs/static_noise/GraphCL/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932102
[Epoch 1; Iter    60/ 1097] train: loss: 0.6930334
[Epoch 1; Iter    90/ 1097] train: loss: 0.6945683
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923959
[Epoch 1; Iter   150/ 1097] train: loss: 0.6919923
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913086
[Epoch 1; Iter   210/ 1097] train: loss: 0.6907522
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898543
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888507
[Epoch 1; Iter   300/ 1097] train: loss: 0.6886489
[Epoch 1; Iter   330/ 1097] train: loss: 0.6872404
[Epoch 1; Iter   360/ 1097] train: loss: 0.6858527
[Epoch 1; Iter   390/ 1097] train: loss: 0.6841136
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829670
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810505
[Epoch 1; Iter   480/ 1097] train: loss: 0.6791469
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776664
[Epoch 1; Iter   540/ 1097] train: loss: 0.6758322
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738473
[Epoch 1; Iter   600/ 1097] train: loss: 0.6743835
[Epoch 1; Iter   630/ 1097] train: loss: 0.6725538
[Epoch 1; Iter   660/ 1097] train: loss: 0.6713730
[Epoch 1; Iter   690/ 1097] train: loss: 0.6650513
[Epoch 1; Iter   720/ 1097] train: loss: 0.6633831
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411022
[Epoch 1; Iter   780/ 1097] train: loss: 0.6046144
[Epoch 1; Iter   810/ 1097] train: loss: 0.5550834
[Epoch 1; Iter   840/ 1097] train: loss: 0.4953309
[Epoch 1; Iter   870/ 1097] train: loss: 0.4406183
[Epoch 1; Iter   900/ 1097] train: loss: 0.4096241
[Epoch 1; Iter   930/ 1097] train: loss: 0.3635519
[Epoch 1; Iter   960/ 1097] train: loss: 0.3631377
[Epoch 1; Iter   990/ 1097] train: loss: 0.1861346
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1502094
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1204883
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1986138
[Epoch 1] ogbg-molhiv: 0.672264 val loss: 0.114805
[Epoch 1] ogbg-molhiv: 0.724342 test loss: 0.141663
[Epoch 2; Iter    13/ 1097] train: loss: 0.0910800
[Epoch 2; Iter    43/ 1097] train: loss: 0.1345156
[Epoch 2; Iter    73/ 1097] train: loss: 0.0749821
[Epoch 2; Iter   103/ 1097] train: loss: 0.0551667
[Epoch 2; Iter   133/ 1097] train: loss: 0.0501190
[Epoch 2; Iter   163/ 1097] train: loss: 0.0724997
[Epoch 2; Iter   193/ 1097] train: loss: 0.2446571
[Epoch 2; Iter   223/ 1097] train: loss: 0.1640693
[Epoch 2; Iter   253/ 1097] train: loss: 0.3547753
[Epoch 2; Iter   283/ 1097] train: loss: 0.1423336
[Epoch 2; Iter   313/ 1097] train: loss: 0.6394795
[Epoch 2; Iter   343/ 1097] train: loss: 0.1340642
[Epoch 2; Iter   373/ 1097] train: loss: 0.0430404
[Epoch 2; Iter   403/ 1097] train: loss: 0.0975979
[Epoch 2; Iter   433/ 1097] train: loss: 0.4164138
[Epoch 2; Iter   463/ 1097] train: loss: 0.2806074
[Epoch 2; Iter   493/ 1097] train: loss: 0.2337500
[Epoch 2; Iter   523/ 1097] train: loss: 0.0403031
[Epoch 2; Iter   553/ 1097] train: loss: 0.1061626
[Epoch 2; Iter   583/ 1097] train: loss: 0.1250598
[Epoch 2; Iter   613/ 1097] train: loss: 0.0362474
[Epoch 2; Iter   643/ 1097] train: loss: 0.1942124
[Epoch 2; Iter   673/ 1097] train: loss: 0.1600593
[Epoch 2; Iter   703/ 1097] train: loss: 0.2005037
[Epoch 2; Iter   733/ 1097] train: loss: 0.0359496
[Epoch 2; Iter   763/ 1097] train: loss: 0.1665870
[Epoch 2; Iter   793/ 1097] train: loss: 0.2092251
[Epoch 2; Iter   823/ 1097] train: loss: 0.1480879
[Epoch 2; Iter   853/ 1097] train: loss: 0.0442465
[Epoch 2; Iter   883/ 1097] train: loss: 0.1584913
[Epoch 2; Iter   913/ 1097] train: loss: 0.0325869
[Epoch 2; Iter   943/ 1097] train: loss: 0.2681592
[Epoch 2; Iter   973/ 1097] train: loss: 0.2792470
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0411753
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1593995
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1791219
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3599529
[Epoch 2] ogbg-molhiv: 0.707406 val loss: 0.320837
[Epoch 2] ogbg-molhiv: 0.675417 test loss: 0.404540
[Epoch 3; Iter    26/ 1097] train: loss: 0.0341333
[Epoch 3; Iter    56/ 1097] train: loss: 0.2608701
[Epoch 3; Iter    86/ 1097] train: loss: 0.0370138
[Epoch 3; Iter   116/ 1097] train: loss: 0.1227201
[Epoch 3; Iter   146/ 1097] train: loss: 0.0296935
[Epoch 3; Iter   176/ 1097] train: loss: 0.2054750
[Epoch 3; Iter   206/ 1097] train: loss: 0.2008426
[Epoch 3; Iter   236/ 1097] train: loss: 0.2899257
[Epoch 3; Iter   266/ 1097] train: loss: 0.2638307
[Epoch 3; Iter   296/ 1097] train: loss: 0.1834861
[Epoch 3; Iter   326/ 1097] train: loss: 0.0322399
[Epoch 3; Iter   356/ 1097] train: loss: 0.0380883
[Epoch 3; Iter   386/ 1097] train: loss: 0.0298550
[Epoch 3; Iter   416/ 1097] train: loss: 0.0987449
[Epoch 3; Iter   446/ 1097] train: loss: 0.0414032
[Epoch 3; Iter   476/ 1097] train: loss: 0.0401894
[Epoch 3; Iter   506/ 1097] train: loss: 0.1957074
[Epoch 3; Iter   536/ 1097] train: loss: 0.0728728
[Epoch 3; Iter   566/ 1097] train: loss: 0.0413236
[Epoch 3; Iter   596/ 1097] train: loss: 0.3377761
[Epoch 3; Iter   626/ 1097] train: loss: 0.0396303
[Epoch 3; Iter   656/ 1097] train: loss: 0.0458029
[Epoch 3; Iter   686/ 1097] train: loss: 0.1412767
[Epoch 3; Iter   716/ 1097] train: loss: 0.1067207
[Epoch 3; Iter   746/ 1097] train: loss: 0.0380543
[Epoch 3; Iter   776/ 1097] train: loss: 0.2997591
[Epoch 3; Iter   806/ 1097] train: loss: 0.2900992
[Epoch 3; Iter   836/ 1097] train: loss: 0.0312435
[Epoch 3; Iter   866/ 1097] train: loss: 0.3153062
[Epoch 3; Iter   896/ 1097] train: loss: 0.1484710
[Epoch 3; Iter   926/ 1097] train: loss: 0.0285216
[Epoch 3; Iter   956/ 1097] train: loss: 0.1618014
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.05/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.05_5_26-05_10-55-16
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.05
logdir: runs/static_noise/GraphCL/hiv/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931751
[Epoch 1; Iter    60/ 1097] train: loss: 0.6942337
[Epoch 1; Iter    90/ 1097] train: loss: 0.6931387
[Epoch 1; Iter   120/ 1097] train: loss: 0.6930579
[Epoch 1; Iter   150/ 1097] train: loss: 0.6949162
[Epoch 1; Iter   180/ 1097] train: loss: 0.6895772
[Epoch 1; Iter   210/ 1097] train: loss: 0.6908736
[Epoch 1; Iter   240/ 1097] train: loss: 0.6890541
[Epoch 1; Iter   270/ 1097] train: loss: 0.6885802
[Epoch 1; Iter   300/ 1097] train: loss: 0.6878985
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868441
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856386
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842784
[Epoch 1; Iter   420/ 1097] train: loss: 0.6836427
[Epoch 1; Iter   450/ 1097] train: loss: 0.6818109
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796908
[Epoch 1; Iter   510/ 1097] train: loss: 0.6792912
[Epoch 1; Iter   540/ 1097] train: loss: 0.6776332
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742077
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721495
[Epoch 1; Iter   630/ 1097] train: loss: 0.6708450
[Epoch 1; Iter   660/ 1097] train: loss: 0.6677778
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654661
[Epoch 1; Iter   720/ 1097] train: loss: 0.6620777
[Epoch 1; Iter   750/ 1097] train: loss: 0.6401436
[Epoch 1; Iter   780/ 1097] train: loss: 0.6049653
[Epoch 1; Iter   810/ 1097] train: loss: 0.5557186
[Epoch 1; Iter   840/ 1097] train: loss: 0.4895552
[Epoch 1; Iter   870/ 1097] train: loss: 0.4559420
[Epoch 1; Iter   900/ 1097] train: loss: 0.3549818
[Epoch 1; Iter   930/ 1097] train: loss: 0.3147020
[Epoch 1; Iter   960/ 1097] train: loss: 0.2262823
[Epoch 1; Iter   990/ 1097] train: loss: 0.4012186
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1869434
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2211387
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1524366
[Epoch 1] ogbg-molhiv: 0.666501 val loss: 0.131007
[Epoch 1] ogbg-molhiv: 0.725207 test loss: 0.149316
[Epoch 2; Iter    13/ 1097] train: loss: 0.0816070
[Epoch 2; Iter    43/ 1097] train: loss: 0.0689067
[Epoch 2; Iter    73/ 1097] train: loss: 0.0623588
[Epoch 2; Iter   103/ 1097] train: loss: 0.0503062
[Epoch 2; Iter   133/ 1097] train: loss: 0.1299923
[Epoch 2; Iter   163/ 1097] train: loss: 0.0563297
[Epoch 2; Iter   193/ 1097] train: loss: 0.2567678
[Epoch 2; Iter   223/ 1097] train: loss: 0.0485003
[Epoch 2; Iter   253/ 1097] train: loss: 0.1337399
[Epoch 2; Iter   283/ 1097] train: loss: 0.1382071
[Epoch 2; Iter   313/ 1097] train: loss: 0.1501081
[Epoch 2; Iter   343/ 1097] train: loss: 0.0434241
[Epoch 2; Iter   373/ 1097] train: loss: 0.2727329
[Epoch 2; Iter   403/ 1097] train: loss: 0.2703992
[Epoch 2; Iter   433/ 1097] train: loss: 0.1344306
[Epoch 2; Iter   463/ 1097] train: loss: 0.2190202
[Epoch 2; Iter   493/ 1097] train: loss: 0.0352564
[Epoch 2; Iter   523/ 1097] train: loss: 0.0720773
[Epoch 2; Iter   553/ 1097] train: loss: 0.1490739
[Epoch 2; Iter   583/ 1097] train: loss: 0.2839662
[Epoch 2; Iter   613/ 1097] train: loss: 0.1716961
[Epoch 2; Iter   643/ 1097] train: loss: 0.2304052
[Epoch 2; Iter   673/ 1097] train: loss: 0.0351606
[Epoch 2; Iter   703/ 1097] train: loss: 0.0665183
[Epoch 2; Iter   733/ 1097] train: loss: 0.2927197
[Epoch 2; Iter   763/ 1097] train: loss: 0.2203090
[Epoch 2; Iter   793/ 1097] train: loss: 0.1489128
[Epoch 2; Iter   823/ 1097] train: loss: 0.2342735
[Epoch 2; Iter   853/ 1097] train: loss: 0.0860488
[Epoch 2; Iter   883/ 1097] train: loss: 0.0347153
[Epoch 2; Iter   913/ 1097] train: loss: 0.1367566
[Epoch 2; Iter   943/ 1097] train: loss: 0.2530216
[Epoch 2; Iter   973/ 1097] train: loss: 0.2263142
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1299252
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2270667
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1701736
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1609717
[Epoch 2] ogbg-molhiv: 0.669101 val loss: 2.970700
[Epoch 2] ogbg-molhiv: 0.628766 test loss: 4.558323
[Epoch 3; Iter    26/ 1097] train: loss: 0.1718164
[Epoch 3; Iter    56/ 1097] train: loss: 0.1780787
[Epoch 3; Iter    86/ 1097] train: loss: 0.4622912
[Epoch 3; Iter   116/ 1097] train: loss: 0.0429268
[Epoch 3; Iter   146/ 1097] train: loss: 0.0421008
[Epoch 3; Iter   176/ 1097] train: loss: 0.2557979
[Epoch 3; Iter   206/ 1097] train: loss: 0.0284330
[Epoch 3; Iter   236/ 1097] train: loss: 0.0324361
[Epoch 3; Iter   266/ 1097] train: loss: 0.0585750
[Epoch 3; Iter   296/ 1097] train: loss: 0.0308361
[Epoch 3; Iter   326/ 1097] train: loss: 0.4228452
[Epoch 3; Iter   356/ 1097] train: loss: 0.0311825
[Epoch 3; Iter   386/ 1097] train: loss: 0.2546353
[Epoch 3; Iter   416/ 1097] train: loss: 0.0343312
[Epoch 3; Iter   446/ 1097] train: loss: 0.0539234
[Epoch 3; Iter   476/ 1097] train: loss: 0.1630340
[Epoch 3; Iter   506/ 1097] train: loss: 0.0943896
[Epoch 3; Iter   536/ 1097] train: loss: 0.1375882
[Epoch 3; Iter   566/ 1097] train: loss: 0.0833443
[Epoch 3; Iter   596/ 1097] train: loss: 0.1213527
[Epoch 3; Iter   626/ 1097] train: loss: 0.0308995
[Epoch 3; Iter   656/ 1097] train: loss: 0.1779509
[Epoch 3; Iter   686/ 1097] train: loss: 0.0355554
[Epoch 3; Iter   716/ 1097] train: loss: 0.2255135
[Epoch 3; Iter   746/ 1097] train: loss: 0.1395375
[Epoch 3; Iter   776/ 1097] train: loss: 0.2765961
[Epoch 3; Iter   806/ 1097] train: loss: 0.2457919
[Epoch 3; Iter   836/ 1097] train: loss: 0.1189042
[Epoch 3; Iter   866/ 1097] train: loss: 0.0452827
[Epoch 3; Iter   896/ 1097] train: loss: 0.0528543
[Epoch 3; Iter   926/ 1097] train: loss: 0.4317294
[Epoch 3; Iter   956/ 1097] train: loss: 0.1717641
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.1/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.1_6_26-05_10-56-55
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.1
logdir: runs/static_noise/GraphCL/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6938061
[Epoch 1; Iter    60/ 1097] train: loss: 0.6942152
[Epoch 1; Iter    90/ 1097] train: loss: 0.6921141
[Epoch 1; Iter   120/ 1097] train: loss: 0.6918569
[Epoch 1; Iter   150/ 1097] train: loss: 0.6916719
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913776
[Epoch 1; Iter   210/ 1097] train: loss: 0.6914893
[Epoch 1; Iter   240/ 1097] train: loss: 0.6894704
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889898
[Epoch 1; Iter   300/ 1097] train: loss: 0.6895365
[Epoch 1; Iter   330/ 1097] train: loss: 0.6887633
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856582
[Epoch 1; Iter   390/ 1097] train: loss: 0.6877370
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829379
[Epoch 1; Iter   450/ 1097] train: loss: 0.6840204
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798841
[Epoch 1; Iter   510/ 1097] train: loss: 0.6775916
[Epoch 1; Iter   540/ 1097] train: loss: 0.6818498
[Epoch 1; Iter   570/ 1097] train: loss: 0.6782066
[Epoch 1; Iter   600/ 1097] train: loss: 0.6744943
[Epoch 1; Iter   630/ 1097] train: loss: 0.6732152
[Epoch 1; Iter   660/ 1097] train: loss: 0.6731644
[Epoch 1; Iter   690/ 1097] train: loss: 0.6680888
[Epoch 1; Iter   720/ 1097] train: loss: 0.6614474
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408687
[Epoch 1; Iter   780/ 1097] train: loss: 0.6042983
[Epoch 1; Iter   810/ 1097] train: loss: 0.5675828
[Epoch 1; Iter   840/ 1097] train: loss: 0.4958760
[Epoch 1; Iter   870/ 1097] train: loss: 0.4278171
[Epoch 1; Iter   900/ 1097] train: loss: 0.3532513
[Epoch 1; Iter   930/ 1097] train: loss: 0.3803166
[Epoch 1; Iter   960/ 1097] train: loss: 0.2767096
[Epoch 1; Iter   990/ 1097] train: loss: 0.2117106
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2038970
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1167354
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1415350
[Epoch 1] ogbg-molhiv: 0.650010 val loss: 0.122012
[Epoch 1] ogbg-molhiv: 0.622333 test loss: 0.148927
[Epoch 2; Iter    13/ 1097] train: loss: 0.1617493
[Epoch 2; Iter    43/ 1097] train: loss: 0.2573297
[Epoch 2; Iter    73/ 1097] train: loss: 0.0608594
[Epoch 2; Iter   103/ 1097] train: loss: 0.1261619
[Epoch 2; Iter   133/ 1097] train: loss: 0.1637984
[Epoch 2; Iter   163/ 1097] train: loss: 0.1504455
[Epoch 2; Iter   193/ 1097] train: loss: 0.3711639
[Epoch 2; Iter   223/ 1097] train: loss: 0.1573756
[Epoch 2; Iter   253/ 1097] train: loss: 0.1823648
[Epoch 2; Iter   283/ 1097] train: loss: 0.1500980
[Epoch 2; Iter   313/ 1097] train: loss: 0.1050397
[Epoch 2; Iter   343/ 1097] train: loss: 0.1572501
[Epoch 2; Iter   373/ 1097] train: loss: 0.0388502
[Epoch 2; Iter   403/ 1097] train: loss: 0.0453394
[Epoch 2; Iter   433/ 1097] train: loss: 0.2448743
[Epoch 2; Iter   463/ 1097] train: loss: 0.2455161
[Epoch 2; Iter   493/ 1097] train: loss: 0.1328942
[Epoch 2; Iter   523/ 1097] train: loss: 0.2501749
[Epoch 2; Iter   553/ 1097] train: loss: 0.1481011
[Epoch 2; Iter   583/ 1097] train: loss: 0.0414474
[Epoch 2; Iter   613/ 1097] train: loss: 0.1945510
[Epoch 2; Iter   643/ 1097] train: loss: 0.3820356
[Epoch 2; Iter   673/ 1097] train: loss: 0.1586183
[Epoch 2; Iter   703/ 1097] train: loss: 0.1244051
[Epoch 2; Iter   733/ 1097] train: loss: 0.1631971
[Epoch 2; Iter   763/ 1097] train: loss: 0.0385191
[Epoch 2; Iter   793/ 1097] train: loss: 0.1078550
[Epoch 2; Iter   823/ 1097] train: loss: 0.0302162
[Epoch 2; Iter   853/ 1097] train: loss: 0.6617401
[Epoch 2; Iter   883/ 1097] train: loss: 0.1373840
[Epoch 2; Iter   913/ 1097] train: loss: 0.3785709
[Epoch 2; Iter   943/ 1097] train: loss: 0.2876914
[Epoch 2; Iter   973/ 1097] train: loss: 0.0397144
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1361160
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0340612
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0615283
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1287583
[Epoch 2] ogbg-molhiv: 0.713297 val loss: 0.193085
[Epoch 2] ogbg-molhiv: 0.666869 test loss: 0.144407
[Epoch 3; Iter    26/ 1097] train: loss: 0.2876790
[Epoch 3; Iter    56/ 1097] train: loss: 0.1525467
[Epoch 3; Iter    86/ 1097] train: loss: 0.5470800
[Epoch 3; Iter   116/ 1097] train: loss: 0.1694821
[Epoch 3; Iter   146/ 1097] train: loss: 0.1144943
[Epoch 3; Iter   176/ 1097] train: loss: 0.1706644
[Epoch 3; Iter   206/ 1097] train: loss: 0.0400631
[Epoch 3; Iter   236/ 1097] train: loss: 0.4126452
[Epoch 3; Iter   266/ 1097] train: loss: 0.2859131
[Epoch 3; Iter   296/ 1097] train: loss: 0.2179354
[Epoch 3; Iter   326/ 1097] train: loss: 0.1181188
[Epoch 3; Iter   356/ 1097] train: loss: 0.0415968
[Epoch 3; Iter   386/ 1097] train: loss: 0.1085204
[Epoch 3; Iter   416/ 1097] train: loss: 0.1214594
[Epoch 3; Iter   446/ 1097] train: loss: 0.0408386
[Epoch 3; Iter   476/ 1097] train: loss: 0.1384774
[Epoch 3; Iter   506/ 1097] train: loss: 0.0373241
[Epoch 3; Iter   536/ 1097] train: loss: 0.1693194
[Epoch 3; Iter   566/ 1097] train: loss: 0.4924679
[Epoch 3; Iter   596/ 1097] train: loss: 0.3954503
[Epoch 3; Iter   626/ 1097] train: loss: 0.0366946
[Epoch 3; Iter   656/ 1097] train: loss: 0.0349682
[Epoch 3; Iter   686/ 1097] train: loss: 0.4456853
[Epoch 3; Iter   716/ 1097] train: loss: 0.1406077
[Epoch 3; Iter   746/ 1097] train: loss: 0.1280140
[Epoch 3; Iter   776/ 1097] train: loss: 0.2223914
[Epoch 3; Iter   806/ 1097] train: loss: 0.0442709
[Epoch 3; Iter   836/ 1097] train: loss: 0.2944357
[Epoch 3; Iter   866/ 1097] train: loss: 0.0466981
[Epoch 3; Iter   896/ 1097] train: loss: 0.1091183
[Epoch 3; Iter   926/ 1097] train: loss: 0.0379757
[Epoch 3; Iter   956/ 1097] train: loss: 0.0372671
[Epoch 3; Iter   986/ 1097] train: loss: 0.0503596
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.1/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.1_5_26-05_10-56-59
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.1
logdir: runs/static_noise/GraphCL/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931696
[Epoch 1; Iter    60/ 1097] train: loss: 0.6941363
[Epoch 1; Iter    90/ 1097] train: loss: 0.6925685
[Epoch 1; Iter   120/ 1097] train: loss: 0.6927581
[Epoch 1; Iter   150/ 1097] train: loss: 0.6945353
[Epoch 1; Iter   180/ 1097] train: loss: 0.6896747
[Epoch 1; Iter   210/ 1097] train: loss: 0.6907828
[Epoch 1; Iter   240/ 1097] train: loss: 0.6888863
[Epoch 1; Iter   270/ 1097] train: loss: 0.6886699
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879048
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868516
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856437
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842815
[Epoch 1; Iter   420/ 1097] train: loss: 0.6834888
[Epoch 1; Iter   450/ 1097] train: loss: 0.6820884
[Epoch 1; Iter   480/ 1097] train: loss: 0.6797054
[Epoch 1; Iter   510/ 1097] train: loss: 0.6790642
[Epoch 1; Iter   540/ 1097] train: loss: 0.6772700
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742083
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721497
[Epoch 1; Iter   630/ 1097] train: loss: 0.6707681
[Epoch 1; Iter   660/ 1097] train: loss: 0.6677966
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654521
[Epoch 1; Iter   720/ 1097] train: loss: 0.6613334
[Epoch 1; Iter   750/ 1097] train: loss: 0.6402808
[Epoch 1; Iter   780/ 1097] train: loss: 0.6048464
[Epoch 1; Iter   810/ 1097] train: loss: 0.5547624
[Epoch 1; Iter   840/ 1097] train: loss: 0.4948514
[Epoch 1; Iter   870/ 1097] train: loss: 0.4488918
[Epoch 1; Iter   900/ 1097] train: loss: 0.3533986
[Epoch 1; Iter   930/ 1097] train: loss: 0.3193237
[Epoch 1; Iter   960/ 1097] train: loss: 0.2253121
[Epoch 1; Iter   990/ 1097] train: loss: 0.3887998
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2025361
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2243635
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1642721
[Epoch 1] ogbg-molhiv: 0.646415 val loss: 0.118637
[Epoch 1] ogbg-molhiv: 0.711912 test loss: 0.144500
[Epoch 2; Iter    13/ 1097] train: loss: 0.0811900
[Epoch 2; Iter    43/ 1097] train: loss: 0.0675189
[Epoch 2; Iter    73/ 1097] train: loss: 0.0691527
[Epoch 2; Iter   103/ 1097] train: loss: 0.0503471
[Epoch 2; Iter   133/ 1097] train: loss: 0.1364326
[Epoch 2; Iter   163/ 1097] train: loss: 0.0539413
[Epoch 2; Iter   193/ 1097] train: loss: 0.2876768
[Epoch 2; Iter   223/ 1097] train: loss: 0.0483328
[Epoch 2; Iter   253/ 1097] train: loss: 0.1487070
[Epoch 2; Iter   283/ 1097] train: loss: 0.1401735
[Epoch 2; Iter   313/ 1097] train: loss: 0.1474747
[Epoch 2; Iter   343/ 1097] train: loss: 0.0447789
[Epoch 2; Iter   373/ 1097] train: loss: 0.2450926
[Epoch 2; Iter   403/ 1097] train: loss: 0.2634982
[Epoch 2; Iter   433/ 1097] train: loss: 0.1441322
[Epoch 2; Iter   463/ 1097] train: loss: 0.2518862
[Epoch 2; Iter   493/ 1097] train: loss: 0.0390048
[Epoch 2; Iter   523/ 1097] train: loss: 0.0767293
[Epoch 2; Iter   553/ 1097] train: loss: 0.1667814
[Epoch 2; Iter   583/ 1097] train: loss: 0.2891523
[Epoch 2; Iter   613/ 1097] train: loss: 0.1656372
[Epoch 2; Iter   643/ 1097] train: loss: 0.2088512
[Epoch 2; Iter   673/ 1097] train: loss: 0.0323073
[Epoch 2; Iter   703/ 1097] train: loss: 0.0677860
[Epoch 2; Iter   733/ 1097] train: loss: 0.3149844
[Epoch 2; Iter   763/ 1097] train: loss: 0.2261940
[Epoch 2; Iter   793/ 1097] train: loss: 0.1375044
[Epoch 2; Iter   823/ 1097] train: loss: 0.2372694
[Epoch 2; Iter   853/ 1097] train: loss: 0.0670306
[Epoch 2; Iter   883/ 1097] train: loss: 0.0288238
[Epoch 2; Iter   913/ 1097] train: loss: 0.1513141
[Epoch 2; Iter   943/ 1097] train: loss: 0.2283960
[Epoch 2; Iter   973/ 1097] train: loss: 0.2608187
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1502854
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2227042
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1734504
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1748956
[Epoch 2] ogbg-molhiv: 0.616001 val loss: 0.308401
[Epoch 2] ogbg-molhiv: 0.645321 test loss: 0.290970
[Epoch 3; Iter    26/ 1097] train: loss: 0.1625774
[Epoch 3; Iter    56/ 1097] train: loss: 0.1503870
[Epoch 3; Iter    86/ 1097] train: loss: 0.4541073
[Epoch 3; Iter   116/ 1097] train: loss: 0.0547278
[Epoch 3; Iter   146/ 1097] train: loss: 0.0431734
[Epoch 3; Iter   176/ 1097] train: loss: 0.2563243
[Epoch 3; Iter   206/ 1097] train: loss: 0.0278090
[Epoch 3; Iter   236/ 1097] train: loss: 0.0381095
[Epoch 3; Iter   266/ 1097] train: loss: 0.0429569
[Epoch 3; Iter   296/ 1097] train: loss: 0.0318112
[Epoch 3; Iter   326/ 1097] train: loss: 0.4286756
[Epoch 3; Iter   356/ 1097] train: loss: 0.0324819
[Epoch 3; Iter   386/ 1097] train: loss: 0.2685592
[Epoch 3; Iter   416/ 1097] train: loss: 0.0357750
[Epoch 3; Iter   446/ 1097] train: loss: 0.0415286
[Epoch 3; Iter   476/ 1097] train: loss: 0.1311139
[Epoch 3; Iter   506/ 1097] train: loss: 0.0370270
[Epoch 3; Iter   536/ 1097] train: loss: 0.1386485
[Epoch 3; Iter   566/ 1097] train: loss: 0.1071596
[Epoch 3; Iter   596/ 1097] train: loss: 0.1198383
[Epoch 3; Iter   626/ 1097] train: loss: 0.0312015
[Epoch 3; Iter   656/ 1097] train: loss: 0.1873012
[Epoch 3; Iter   686/ 1097] train: loss: 0.0311981
[Epoch 3; Iter   716/ 1097] train: loss: 0.2397870
[Epoch 3; Iter   746/ 1097] train: loss: 0.1545693
[Epoch 3; Iter   776/ 1097] train: loss: 0.3071266
[Epoch 3; Iter   806/ 1097] train: loss: 0.2650024
[Epoch 3; Iter   836/ 1097] train: loss: 0.1305814
[Epoch 3; Iter   866/ 1097] train: loss: 0.0346310
[Epoch 3; Iter   896/ 1097] train: loss: 0.0388397
[Epoch 3; Iter   926/ 1097] train: loss: 0.4778110
[Epoch 3; Iter   956/ 1097] train: loss: 0.1940102
[Epoch 3; Iter   986/ 1097] train: loss: 0.3491219
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.1/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.1_4_26-05_10-56-57
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.1
logdir: runs/static_noise/GraphCL/hiv/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931942
[Epoch 1; Iter    60/ 1097] train: loss: 0.6930124
[Epoch 1; Iter    90/ 1097] train: loss: 0.6945128
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923986
[Epoch 1; Iter   150/ 1097] train: loss: 0.6920580
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912894
[Epoch 1; Iter   210/ 1097] train: loss: 0.6911409
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898184
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888456
[Epoch 1; Iter   300/ 1097] train: loss: 0.6884694
[Epoch 1; Iter   330/ 1097] train: loss: 0.6878186
[Epoch 1; Iter   360/ 1097] train: loss: 0.6861065
[Epoch 1; Iter   390/ 1097] train: loss: 0.6841402
[Epoch 1; Iter   420/ 1097] train: loss: 0.6827285
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810934
[Epoch 1; Iter   480/ 1097] train: loss: 0.6801240
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776440
[Epoch 1; Iter   540/ 1097] train: loss: 0.6758328
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738377
[Epoch 1; Iter   600/ 1097] train: loss: 0.6749831
[Epoch 1; Iter   630/ 1097] train: loss: 0.6726962
[Epoch 1; Iter   660/ 1097] train: loss: 0.6711296
[Epoch 1; Iter   690/ 1097] train: loss: 0.6650391
[Epoch 1; Iter   720/ 1097] train: loss: 0.6632565
[Epoch 1; Iter   750/ 1097] train: loss: 0.6405801
[Epoch 1; Iter   780/ 1097] train: loss: 0.6039869
[Epoch 1; Iter   810/ 1097] train: loss: 0.5556533
[Epoch 1; Iter   840/ 1097] train: loss: 0.4942524
[Epoch 1; Iter   870/ 1097] train: loss: 0.4400702
[Epoch 1; Iter   900/ 1097] train: loss: 0.4138914
[Epoch 1; Iter   930/ 1097] train: loss: 0.3732223
[Epoch 1; Iter   960/ 1097] train: loss: 0.3849190
[Epoch 1; Iter   990/ 1097] train: loss: 0.1850978
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1530291
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1215799
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1980412
[Epoch 1] ogbg-molhiv: 0.670171 val loss: 0.110241
[Epoch 1] ogbg-molhiv: 0.698592 test loss: 0.136354
[Epoch 2; Iter    13/ 1097] train: loss: 0.0966046
[Epoch 2; Iter    43/ 1097] train: loss: 0.1483570
[Epoch 2; Iter    73/ 1097] train: loss: 0.0733754
[Epoch 2; Iter   103/ 1097] train: loss: 0.0542564
[Epoch 2; Iter   133/ 1097] train: loss: 0.0491413
[Epoch 2; Iter   163/ 1097] train: loss: 0.0778053
[Epoch 2; Iter   193/ 1097] train: loss: 0.2379199
[Epoch 2; Iter   223/ 1097] train: loss: 0.1565002
[Epoch 2; Iter   253/ 1097] train: loss: 0.3569596
[Epoch 2; Iter   283/ 1097] train: loss: 0.1465818
[Epoch 2; Iter   313/ 1097] train: loss: 0.6141574
[Epoch 2; Iter   343/ 1097] train: loss: 0.1513797
[Epoch 2; Iter   373/ 1097] train: loss: 0.0403374
[Epoch 2; Iter   403/ 1097] train: loss: 0.0987000
[Epoch 2; Iter   433/ 1097] train: loss: 0.4036141
[Epoch 2; Iter   463/ 1097] train: loss: 0.2951680
[Epoch 2; Iter   493/ 1097] train: loss: 0.2092369
[Epoch 2; Iter   523/ 1097] train: loss: 0.0396274
[Epoch 2; Iter   553/ 1097] train: loss: 0.1278457
[Epoch 2; Iter   583/ 1097] train: loss: 0.1202089
[Epoch 2; Iter   613/ 1097] train: loss: 0.0321438
[Epoch 2; Iter   643/ 1097] train: loss: 0.1778364
[Epoch 2; Iter   673/ 1097] train: loss: 0.1791674
[Epoch 2; Iter   703/ 1097] train: loss: 0.1349243
[Epoch 2; Iter   733/ 1097] train: loss: 0.0377244
[Epoch 2; Iter   763/ 1097] train: loss: 0.1591593
[Epoch 2; Iter   793/ 1097] train: loss: 0.2349508
[Epoch 2; Iter   823/ 1097] train: loss: 0.1323561
[Epoch 2; Iter   853/ 1097] train: loss: 0.0376417
[Epoch 2; Iter   883/ 1097] train: loss: 0.1524500
[Epoch 2; Iter   913/ 1097] train: loss: 0.0344633
[Epoch 2; Iter   943/ 1097] train: loss: 0.2675752
[Epoch 2; Iter   973/ 1097] train: loss: 0.2814740
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0406428
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1512982
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1664782
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3410839
[Epoch 2] ogbg-molhiv: 0.622949 val loss: 0.101017
[Epoch 2] ogbg-molhiv: 0.588893 test loss: 0.143239
[Epoch 3; Iter    26/ 1097] train: loss: 0.0297043
[Epoch 3; Iter    56/ 1097] train: loss: 0.2874898
[Epoch 3; Iter    86/ 1097] train: loss: 0.0413939
[Epoch 3; Iter   116/ 1097] train: loss: 0.1110311
[Epoch 3; Iter   146/ 1097] train: loss: 0.0287778
[Epoch 3; Iter   176/ 1097] train: loss: 0.1819553
[Epoch 3; Iter   206/ 1097] train: loss: 0.1500229
[Epoch 3; Iter   236/ 1097] train: loss: 0.3098726
[Epoch 3; Iter   266/ 1097] train: loss: 0.2765535
[Epoch 3; Iter   296/ 1097] train: loss: 0.1556889
[Epoch 3; Iter   326/ 1097] train: loss: 0.0389220
[Epoch 3; Iter   356/ 1097] train: loss: 0.0351841
[Epoch 3; Iter   386/ 1097] train: loss: 0.0332341
[Epoch 3; Iter   416/ 1097] train: loss: 0.1039768
[Epoch 3; Iter   446/ 1097] train: loss: 0.0365563
[Epoch 3; Iter   476/ 1097] train: loss: 0.0397871
[Epoch 3; Iter   506/ 1097] train: loss: 0.2133662
[Epoch 3; Iter   536/ 1097] train: loss: 0.0696057
[Epoch 3; Iter   566/ 1097] train: loss: 0.0383613
[Epoch 3; Iter   596/ 1097] train: loss: 0.3415220
[Epoch 3; Iter   626/ 1097] train: loss: 0.0470232
[Epoch 3; Iter   656/ 1097] train: loss: 0.0473534
[Epoch 3; Iter   686/ 1097] train: loss: 0.1570732
[Epoch 3; Iter   716/ 1097] train: loss: 0.1070203
[Epoch 3; Iter   746/ 1097] train: loss: 0.0456200
[Epoch 3; Iter   776/ 1097] train: loss: 0.2469381
[Epoch 3; Iter   806/ 1097] train: loss: 0.3238686
[Epoch 3; Iter   836/ 1097] train: loss: 0.0297476
[Epoch 3; Iter   866/ 1097] train: loss: 0.3572420
[Epoch 3; Iter   896/ 1097] train: loss: 0.1097244
[Epoch 3; Iter   926/ 1097] train: loss: 0.0286678
[Epoch 3; Iter   956/ 1097] train: loss: 0.2050860
[Epoch 3; Iter   986/ 1097] train: loss: 0.0379963
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.2/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.2_4_26-05_10-59-30
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.2
logdir: runs/static_noise/GraphCL/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931862
[Epoch 1; Iter    60/ 1097] train: loss: 0.6929901
[Epoch 1; Iter    90/ 1097] train: loss: 0.6941925
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924007
[Epoch 1; Iter   150/ 1097] train: loss: 0.6918353
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912850
[Epoch 1; Iter   210/ 1097] train: loss: 0.6914026
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898081
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888323
[Epoch 1; Iter   300/ 1097] train: loss: 0.6895744
[Epoch 1; Iter   330/ 1097] train: loss: 0.6884366
[Epoch 1; Iter   360/ 1097] train: loss: 0.6862234
[Epoch 1; Iter   390/ 1097] train: loss: 0.6841148
[Epoch 1; Iter   420/ 1097] train: loss: 0.6839517
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810642
[Epoch 1; Iter   480/ 1097] train: loss: 0.6811722
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776389
[Epoch 1; Iter   540/ 1097] train: loss: 0.6758211
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738259
[Epoch 1; Iter   600/ 1097] train: loss: 0.6748590
[Epoch 1; Iter   630/ 1097] train: loss: 0.6734058
[Epoch 1; Iter   660/ 1097] train: loss: 0.6718856
[Epoch 1; Iter   690/ 1097] train: loss: 0.6650396
[Epoch 1; Iter   720/ 1097] train: loss: 0.6624916
[Epoch 1; Iter   750/ 1097] train: loss: 0.6409174
[Epoch 1; Iter   780/ 1097] train: loss: 0.6046158
[Epoch 1; Iter   810/ 1097] train: loss: 0.5563042
[Epoch 1; Iter   840/ 1097] train: loss: 0.4945634
[Epoch 1; Iter   870/ 1097] train: loss: 0.4414845
[Epoch 1; Iter   900/ 1097] train: loss: 0.4186148
[Epoch 1; Iter   930/ 1097] train: loss: 0.3712752
[Epoch 1; Iter   960/ 1097] train: loss: 0.3703071
[Epoch 1; Iter   990/ 1097] train: loss: 0.1838363
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1496705
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1216857
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2080276
[Epoch 1] ogbg-molhiv: 0.640879 val loss: 0.124323
[Epoch 1] ogbg-molhiv: 0.701010 test loss: 0.137562
[Epoch 2; Iter    13/ 1097] train: loss: 0.0852059
[Epoch 2; Iter    43/ 1097] train: loss: 0.1352876
[Epoch 2; Iter    73/ 1097] train: loss: 0.0688964
[Epoch 2; Iter   103/ 1097] train: loss: 0.0554080
[Epoch 2; Iter   133/ 1097] train: loss: 0.0504678
[Epoch 2; Iter   163/ 1097] train: loss: 0.0925320
[Epoch 2; Iter   193/ 1097] train: loss: 0.2539157
[Epoch 2; Iter   223/ 1097] train: loss: 0.1657321
[Epoch 2; Iter   253/ 1097] train: loss: 0.3321051
[Epoch 2; Iter   283/ 1097] train: loss: 0.1445608
[Epoch 2; Iter   313/ 1097] train: loss: 0.6423391
[Epoch 2; Iter   343/ 1097] train: loss: 0.1357168
[Epoch 2; Iter   373/ 1097] train: loss: 0.0417827
[Epoch 2; Iter   403/ 1097] train: loss: 0.1142017
[Epoch 2; Iter   433/ 1097] train: loss: 0.4408732
[Epoch 2; Iter   463/ 1097] train: loss: 0.2438493
[Epoch 2; Iter   493/ 1097] train: loss: 0.2123874
[Epoch 2; Iter   523/ 1097] train: loss: 0.0430317
[Epoch 2; Iter   553/ 1097] train: loss: 0.1393399
[Epoch 2; Iter   583/ 1097] train: loss: 0.1179811
[Epoch 2; Iter   613/ 1097] train: loss: 0.0320370
[Epoch 2; Iter   643/ 1097] train: loss: 0.1608276
[Epoch 2; Iter   673/ 1097] train: loss: 0.1592703
[Epoch 2; Iter   703/ 1097] train: loss: 0.1504007
[Epoch 2; Iter   733/ 1097] train: loss: 0.0347064
[Epoch 2; Iter   763/ 1097] train: loss: 0.1576199
[Epoch 2; Iter   793/ 1097] train: loss: 0.2639814
[Epoch 2; Iter   823/ 1097] train: loss: 0.1148949
[Epoch 2; Iter   853/ 1097] train: loss: 0.0401130
[Epoch 2; Iter   883/ 1097] train: loss: 0.1511408
[Epoch 2; Iter   913/ 1097] train: loss: 0.0328529
[Epoch 2; Iter   943/ 1097] train: loss: 0.2857507
[Epoch 2; Iter   973/ 1097] train: loss: 0.2683996
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0389538
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1491253
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1637525
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3854500
[Epoch 2] ogbg-molhiv: 0.690611 val loss: 0.208975
[Epoch 2] ogbg-molhiv: 0.744477 test loss: 0.144462
[Epoch 3; Iter    26/ 1097] train: loss: 0.0337782
[Epoch 3; Iter    56/ 1097] train: loss: 0.2754875
[Epoch 3; Iter    86/ 1097] train: loss: 0.0524326
[Epoch 3; Iter   116/ 1097] train: loss: 0.1089740
[Epoch 3; Iter   146/ 1097] train: loss: 0.0344900
[Epoch 3; Iter   176/ 1097] train: loss: 0.2286511
[Epoch 3; Iter   206/ 1097] train: loss: 0.1781686
[Epoch 3; Iter   236/ 1097] train: loss: 0.2656672
[Epoch 3; Iter   266/ 1097] train: loss: 0.2987179
[Epoch 3; Iter   296/ 1097] train: loss: 0.1454052
[Epoch 3; Iter   326/ 1097] train: loss: 0.0389424
[Epoch 3; Iter   356/ 1097] train: loss: 0.0356995
[Epoch 3; Iter   386/ 1097] train: loss: 0.0358577
[Epoch 3; Iter   416/ 1097] train: loss: 0.0985518
[Epoch 3; Iter   446/ 1097] train: loss: 0.0404922
[Epoch 3; Iter   476/ 1097] train: loss: 0.0376288
[Epoch 3; Iter   506/ 1097] train: loss: 0.2118566
[Epoch 3; Iter   536/ 1097] train: loss: 0.0775029
[Epoch 3; Iter   566/ 1097] train: loss: 0.0390389
[Epoch 3; Iter   596/ 1097] train: loss: 0.3460149
[Epoch 3; Iter   626/ 1097] train: loss: 0.0398324
[Epoch 3; Iter   656/ 1097] train: loss: 0.0590971
[Epoch 3; Iter   686/ 1097] train: loss: 0.1447714
[Epoch 3; Iter   716/ 1097] train: loss: 0.1172876
[Epoch 3; Iter   746/ 1097] train: loss: 0.0384513
[Epoch 3; Iter   776/ 1097] train: loss: 0.2511066
[Epoch 3; Iter   806/ 1097] train: loss: 0.2973526
[Epoch 3; Iter   836/ 1097] train: loss: 0.0304768
[Epoch 3; Iter   866/ 1097] train: loss: 0.3493264
[Epoch 3; Iter   896/ 1097] train: loss: 0.1378173
[Epoch 3; Iter   926/ 1097] train: loss: 0.0307651
[Epoch 3; Iter   956/ 1097] train: loss: 0.2006790
[Epoch 3; Iter   986/ 1097] train: loss: 0.0373777
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.2/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.2_5_26-05_11-00-02
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.2
logdir: runs/static_noise/GraphCL/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931893
[Epoch 1; Iter    60/ 1097] train: loss: 0.6938294
[Epoch 1; Iter    90/ 1097] train: loss: 0.6931650
[Epoch 1; Iter   120/ 1097] train: loss: 0.6921951
[Epoch 1; Iter   150/ 1097] train: loss: 0.6947795
[Epoch 1; Iter   180/ 1097] train: loss: 0.6899673
[Epoch 1; Iter   210/ 1097] train: loss: 0.6915688
[Epoch 1; Iter   240/ 1097] train: loss: 0.6890084
[Epoch 1; Iter   270/ 1097] train: loss: 0.6878772
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879122
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868528
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856436
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842894
[Epoch 1; Iter   420/ 1097] train: loss: 0.6830149
[Epoch 1; Iter   450/ 1097] train: loss: 0.6821224
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796728
[Epoch 1; Iter   510/ 1097] train: loss: 0.6784945
[Epoch 1; Iter   540/ 1097] train: loss: 0.6778468
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742129
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721505
[Epoch 1; Iter   630/ 1097] train: loss: 0.6720501
[Epoch 1; Iter   660/ 1097] train: loss: 0.6677749
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654570
[Epoch 1; Iter   720/ 1097] train: loss: 0.6604008
[Epoch 1; Iter   750/ 1097] train: loss: 0.6401785
[Epoch 1; Iter   780/ 1097] train: loss: 0.6049651
[Epoch 1; Iter   810/ 1097] train: loss: 0.5544209
[Epoch 1; Iter   840/ 1097] train: loss: 0.5019965
[Epoch 1; Iter   870/ 1097] train: loss: 0.4440167
[Epoch 1; Iter   900/ 1097] train: loss: 0.3529820
[Epoch 1; Iter   930/ 1097] train: loss: 0.3136730
[Epoch 1; Iter   960/ 1097] train: loss: 0.2246559
[Epoch 1; Iter   990/ 1097] train: loss: 0.3932985
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1933533
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2400543
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1577248
[Epoch 1] ogbg-molhiv: 0.700532 val loss: 0.253926
[Epoch 1] ogbg-molhiv: 0.660528 test loss: 0.296068
[Epoch 2; Iter    13/ 1097] train: loss: 0.0788851
[Epoch 2; Iter    43/ 1097] train: loss: 0.0670790
[Epoch 2; Iter    73/ 1097] train: loss: 0.0642276
[Epoch 2; Iter   103/ 1097] train: loss: 0.0494744
[Epoch 2; Iter   133/ 1097] train: loss: 0.1373535
[Epoch 2; Iter   163/ 1097] train: loss: 0.0556567
[Epoch 2; Iter   193/ 1097] train: loss: 0.2635757
[Epoch 2; Iter   223/ 1097] train: loss: 0.0557302
[Epoch 2; Iter   253/ 1097] train: loss: 0.1422655
[Epoch 2; Iter   283/ 1097] train: loss: 0.1238054
[Epoch 2; Iter   313/ 1097] train: loss: 0.1327576
[Epoch 2; Iter   343/ 1097] train: loss: 0.0408603
[Epoch 2; Iter   373/ 1097] train: loss: 0.2693980
[Epoch 2; Iter   403/ 1097] train: loss: 0.3063865
[Epoch 2; Iter   433/ 1097] train: loss: 0.1426317
[Epoch 2; Iter   463/ 1097] train: loss: 0.2743779
[Epoch 2; Iter   493/ 1097] train: loss: 0.0385471
[Epoch 2; Iter   523/ 1097] train: loss: 0.0698609
[Epoch 2; Iter   553/ 1097] train: loss: 0.1800683
[Epoch 2; Iter   583/ 1097] train: loss: 0.2821568
[Epoch 2; Iter   613/ 1097] train: loss: 0.1809740
[Epoch 2; Iter   643/ 1097] train: loss: 0.2621744
[Epoch 2; Iter   673/ 1097] train: loss: 0.0368723
[Epoch 2; Iter   703/ 1097] train: loss: 0.0584400
[Epoch 2; Iter   733/ 1097] train: loss: 0.2940007
[Epoch 2; Iter   763/ 1097] train: loss: 0.2320157
[Epoch 2; Iter   793/ 1097] train: loss: 0.1378613
[Epoch 2; Iter   823/ 1097] train: loss: 0.2389994
[Epoch 2; Iter   853/ 1097] train: loss: 0.0490502
[Epoch 2; Iter   883/ 1097] train: loss: 0.0285865
[Epoch 2; Iter   913/ 1097] train: loss: 0.1361463
[Epoch 2; Iter   943/ 1097] train: loss: 0.2326198
[Epoch 2; Iter   973/ 1097] train: loss: 0.2778178
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1416251
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2511589
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1720683
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1938635
[Epoch 2] ogbg-molhiv: 0.610731 val loss: 0.107897
[Epoch 2] ogbg-molhiv: 0.664808 test loss: 0.125929
[Epoch 3; Iter    26/ 1097] train: loss: 0.1640758
[Epoch 3; Iter    56/ 1097] train: loss: 0.1642629
[Epoch 3; Iter    86/ 1097] train: loss: 0.4777392
[Epoch 3; Iter   116/ 1097] train: loss: 0.0809545
[Epoch 3; Iter   146/ 1097] train: loss: 0.0350049
[Epoch 3; Iter   176/ 1097] train: loss: 0.2955090
[Epoch 3; Iter   206/ 1097] train: loss: 0.0281039
[Epoch 3; Iter   236/ 1097] train: loss: 0.0300918
[Epoch 3; Iter   266/ 1097] train: loss: 0.0569810
[Epoch 3; Iter   296/ 1097] train: loss: 0.0309808
[Epoch 3; Iter   326/ 1097] train: loss: 0.4246948
[Epoch 3; Iter   356/ 1097] train: loss: 0.0334232
[Epoch 3; Iter   386/ 1097] train: loss: 0.2588320
[Epoch 3; Iter   416/ 1097] train: loss: 0.0366425
[Epoch 3; Iter   446/ 1097] train: loss: 0.0356547
[Epoch 3; Iter   476/ 1097] train: loss: 0.1446191
[Epoch 3; Iter   506/ 1097] train: loss: 0.0895375
[Epoch 3; Iter   536/ 1097] train: loss: 0.1311243
[Epoch 3; Iter   566/ 1097] train: loss: 0.1171136
[Epoch 3; Iter   596/ 1097] train: loss: 0.1230871
[Epoch 3; Iter   626/ 1097] train: loss: 0.0311309
[Epoch 3; Iter   656/ 1097] train: loss: 0.1750112
[Epoch 3; Iter   686/ 1097] train: loss: 0.0329607
[Epoch 3; Iter   716/ 1097] train: loss: 0.2266221
[Epoch 3; Iter   746/ 1097] train: loss: 0.1207777
[Epoch 3; Iter   776/ 1097] train: loss: 0.2774288
[Epoch 3; Iter   806/ 1097] train: loss: 0.2491876
[Epoch 3; Iter   836/ 1097] train: loss: 0.1427918
[Epoch 3; Iter   866/ 1097] train: loss: 0.0363882
[Epoch 3; Iter   896/ 1097] train: loss: 0.0805624
[Epoch 3; Iter   926/ 1097] train: loss: 0.5149907
[Epoch 3; Iter   956/ 1097] train: loss: 0.1855646
[Epoch 3; Iter   986/ 1097] train: loss: 0.2694363
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/GraphCL/hiv/noise=0.2/PNA_ogbg-molhiv_GraphCL_hiv_static_noise=0.2_6_26-05_11-00-18
config: <_io.TextIOWrapper name='configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_static_noise=0.2
logdir: runs/static_noise/GraphCL/hiv/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6927151
[Epoch 1; Iter    60/ 1097] train: loss: 0.6952334
[Epoch 1; Iter    90/ 1097] train: loss: 0.6922557
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924490
[Epoch 1; Iter   150/ 1097] train: loss: 0.6903377
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913517
[Epoch 1; Iter   210/ 1097] train: loss: 0.6909053
[Epoch 1; Iter   240/ 1097] train: loss: 0.6892263
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889800
[Epoch 1; Iter   300/ 1097] train: loss: 0.6905515
[Epoch 1; Iter   330/ 1097] train: loss: 0.6900719
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856971
[Epoch 1; Iter   390/ 1097] train: loss: 0.6881188
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829247
[Epoch 1; Iter   450/ 1097] train: loss: 0.6842201
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798961
[Epoch 1; Iter   510/ 1097] train: loss: 0.6772300
[Epoch 1; Iter   540/ 1097] train: loss: 0.6823487
[Epoch 1; Iter   570/ 1097] train: loss: 0.6780785
[Epoch 1; Iter   600/ 1097] train: loss: 0.6740048
[Epoch 1; Iter   630/ 1097] train: loss: 0.6742356
[Epoch 1; Iter   660/ 1097] train: loss: 0.6733885
[Epoch 1; Iter   690/ 1097] train: loss: 0.6676334
[Epoch 1; Iter   720/ 1097] train: loss: 0.6614143
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411227
[Epoch 1; Iter   780/ 1097] train: loss: 0.6058139
[Epoch 1; Iter   810/ 1097] train: loss: 0.5649447
[Epoch 1; Iter   840/ 1097] train: loss: 0.4896987
[Epoch 1; Iter   870/ 1097] train: loss: 0.4286764
[Epoch 1; Iter   900/ 1097] train: loss: 0.3529719
[Epoch 1; Iter   930/ 1097] train: loss: 0.3704259
[Epoch 1; Iter   960/ 1097] train: loss: 0.2816935
[Epoch 1; Iter   990/ 1097] train: loss: 0.2146951
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1977061
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1145082
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1454484
[Epoch 1] ogbg-molhiv: 0.635300 val loss: 0.155407
[Epoch 1] ogbg-molhiv: 0.656701 test loss: 0.160896
[Epoch 2; Iter    13/ 1097] train: loss: 0.1540667
[Epoch 2; Iter    43/ 1097] train: loss: 0.2480845
[Epoch 2; Iter    73/ 1097] train: loss: 0.0629589
[Epoch 2; Iter   103/ 1097] train: loss: 0.1463255
[Epoch 2; Iter   133/ 1097] train: loss: 0.1767869
[Epoch 2; Iter   163/ 1097] train: loss: 0.1514380
[Epoch 2; Iter   193/ 1097] train: loss: 0.3626406
[Epoch 2; Iter   223/ 1097] train: loss: 0.1513503
[Epoch 2; Iter   253/ 1097] train: loss: 0.2099844
[Epoch 2; Iter   283/ 1097] train: loss: 0.1263517
[Epoch 2; Iter   313/ 1097] train: loss: 0.1079017
[Epoch 2; Iter   343/ 1097] train: loss: 0.1749516
[Epoch 2; Iter   373/ 1097] train: loss: 0.0369857
[Epoch 2; Iter   403/ 1097] train: loss: 0.0495387
[Epoch 2; Iter   433/ 1097] train: loss: 0.2451912
[Epoch 2; Iter   463/ 1097] train: loss: 0.2478583
[Epoch 2; Iter   493/ 1097] train: loss: 0.1359390
[Epoch 2; Iter   523/ 1097] train: loss: 0.2547135
[Epoch 2; Iter   553/ 1097] train: loss: 0.1383731
[Epoch 2; Iter   583/ 1097] train: loss: 0.0407673
[Epoch 2; Iter   613/ 1097] train: loss: 0.2499084
[Epoch 2; Iter   643/ 1097] train: loss: 0.3766961
[Epoch 2; Iter   673/ 1097] train: loss: 0.1475417
[Epoch 2; Iter   703/ 1097] train: loss: 0.1187588
[Epoch 2; Iter   733/ 1097] train: loss: 0.1782600
[Epoch 2; Iter   763/ 1097] train: loss: 0.0297373
[Epoch 2; Iter   793/ 1097] train: loss: 0.1687861
[Epoch 2; Iter   823/ 1097] train: loss: 0.0355352
[Epoch 2; Iter   853/ 1097] train: loss: 0.6055395
[Epoch 2; Iter   883/ 1097] train: loss: 0.1453428
[Epoch 2; Iter   913/ 1097] train: loss: 0.4247727
[Epoch 2; Iter   943/ 1097] train: loss: 0.3025006
[Epoch 2; Iter   973/ 1097] train: loss: 0.0422301
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1188991
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0352576
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0882312
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1583043
[Epoch 2] ogbg-molhiv: 0.695795 val loss: 0.501410
[Epoch 2] ogbg-molhiv: 0.644750 test loss: 0.225575
[Epoch 3; Iter    26/ 1097] train: loss: 0.2827397
[Epoch 3; Iter    56/ 1097] train: loss: 0.1613939
[Epoch 3; Iter    86/ 1097] train: loss: 0.4152579
[Epoch 3; Iter   116/ 1097] train: loss: 0.1744459
[Epoch 3; Iter   146/ 1097] train: loss: 0.1332189
[Epoch 3; Iter   176/ 1097] train: loss: 0.1615674
[Epoch 3; Iter   206/ 1097] train: loss: 0.0368795
[Epoch 3; Iter   236/ 1097] train: loss: 0.3960006
[Epoch 3; Iter   266/ 1097] train: loss: 0.2530062
[Epoch 3; Iter   296/ 1097] train: loss: 0.1730189
[Epoch 3; Iter   326/ 1097] train: loss: 0.1411276
[Epoch 3; Iter   356/ 1097] train: loss: 0.0430381
[Epoch 3; Iter   386/ 1097] train: loss: 0.1505487
[Epoch 3; Iter   416/ 1097] train: loss: 0.1173557
[Epoch 3; Iter   446/ 1097] train: loss: 0.0482086
[Epoch 3; Iter   476/ 1097] train: loss: 0.1307427
[Epoch 3; Iter   506/ 1097] train: loss: 0.0356250
[Epoch 3; Iter   536/ 1097] train: loss: 0.1613415
[Epoch 3; Iter   566/ 1097] train: loss: 0.4990477
[Epoch 3; Iter   596/ 1097] train: loss: 0.3918169
[Epoch 3; Iter   626/ 1097] train: loss: 0.0340313
[Epoch 3; Iter   656/ 1097] train: loss: 0.0369746
[Epoch 3; Iter   686/ 1097] train: loss: 0.3751445
[Epoch 3; Iter   716/ 1097] train: loss: 0.1449816
[Epoch 3; Iter   746/ 1097] train: loss: 0.1014936
[Epoch 3; Iter   776/ 1097] train: loss: 0.1889875
[Epoch 3; Iter   806/ 1097] train: loss: 0.0379303
[Epoch 3; Iter   836/ 1097] train: loss: 0.2697626
[Epoch 3; Iter   866/ 1097] train: loss: 0.0615872
[Epoch 3; Iter   896/ 1097] train: loss: 0.0953629
[Epoch 3; Iter   926/ 1097] train: loss: 0.0338275
[Epoch 3; Iter   956/ 1097] train: loss: 0.0333253
[Epoch 3; Iter   986/ 1097] train: loss: 0.0421296
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2879734
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0356503
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1131332
[Epoch 3] ogbg-molhiv: 0.732244 val loss: 0.112461
[Epoch 3] ogbg-molhiv: 0.737264 test loss: 0.119073
[Epoch 4; Iter     9/ 1097] train: loss: 0.0747329
[Epoch 4; Iter    39/ 1097] train: loss: 0.0394216
[Epoch 4; Iter    69/ 1097] train: loss: 0.0251545
[Epoch 4; Iter    99/ 1097] train: loss: 0.0263984
[Epoch 4; Iter   129/ 1097] train: loss: 0.2511824
[Epoch 4; Iter   159/ 1097] train: loss: 0.0946443
[Epoch 4; Iter   189/ 1097] train: loss: 0.0432909
[Epoch 4; Iter   219/ 1097] train: loss: 0.0375618
[Epoch 4; Iter   249/ 1097] train: loss: 0.1537941
[Epoch 4; Iter   279/ 1097] train: loss: 0.2498829
[Epoch 4; Iter   309/ 1097] train: loss: 0.0435458
[Epoch 4; Iter   339/ 1097] train: loss: 0.0456140
[Epoch 4; Iter   369/ 1097] train: loss: 0.0662571
[Epoch 4; Iter   399/ 1097] train: loss: 0.2008027
[Epoch 4; Iter   429/ 1097] train: loss: 0.0348333
[Epoch 4; Iter   459/ 1097] train: loss: 0.1368192
[Epoch 4; Iter   489/ 1097] train: loss: 0.0281033
[Epoch 4; Iter   519/ 1097] train: loss: 0.1888455
[Epoch 4; Iter   549/ 1097] train: loss: 0.0427008
[Epoch 4; Iter   579/ 1097] train: loss: 0.1243283
[Epoch 4; Iter   609/ 1097] train: loss: 0.1222722
[Epoch 4; Iter   639/ 1097] train: loss: 0.0881060
[Epoch 4; Iter   669/ 1097] train: loss: 0.2055394
[Epoch 4; Iter   699/ 1097] train: loss: 0.1016146
[Epoch 4; Iter   729/ 1097] train: loss: 0.0385397
[Epoch 4; Iter   759/ 1097] train: loss: 0.0284866
[Epoch 4; Iter   789/ 1097] train: loss: 0.0248681
[Epoch 4; Iter   819/ 1097] train: loss: 0.1487314
[Epoch 4; Iter   849/ 1097] train: loss: 0.0324902
[Epoch 4; Iter   879/ 1097] train: loss: 0.0622596
[Epoch 4; Iter   909/ 1097] train: loss: 0.0351119
[Epoch 4; Iter   939/ 1097] train: loss: 0.3037733
[Epoch 4; Iter   969/ 1097] train: loss: 0.0851412
[Epoch 4; Iter   999/ 1097] train: loss: 0.0401350
[Epoch 4; Iter  1029/ 1097] train: loss: 0.1917348
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1913283
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1751931
[Epoch 4] ogbg-molhiv: 0.766727 val loss: 0.103318
[Epoch 4] ogbg-molhiv: 0.744785 test loss: 0.136097
[Epoch 5; Iter    22/ 1097] train: loss: 0.1033383
[Epoch 5; Iter    52/ 1097] train: loss: 0.1710795
[Epoch 5; Iter    82/ 1097] train: loss: 0.1456616
[Epoch 5; Iter   112/ 1097] train: loss: 0.3403797
[Epoch 5; Iter   142/ 1097] train: loss: 0.2894906
[Epoch 5; Iter   172/ 1097] train: loss: 0.0322463
[Epoch 5; Iter   202/ 1097] train: loss: 0.1837011
[Epoch 5; Iter   232/ 1097] train: loss: 0.1797032
[Epoch 5; Iter   262/ 1097] train: loss: 0.0424503
[Epoch 5; Iter   292/ 1097] train: loss: 0.1907460
[Epoch 5; Iter   322/ 1097] train: loss: 0.0281657
[Epoch 5; Iter   352/ 1097] train: loss: 0.0840359
[Epoch 5; Iter   382/ 1097] train: loss: 0.1588756
[Epoch 5; Iter   412/ 1097] train: loss: 0.3704288
[Epoch 5; Iter   442/ 1097] train: loss: 0.1113095
[Epoch 5; Iter   472/ 1097] train: loss: 0.1400524
[Epoch 5; Iter   502/ 1097] train: loss: 0.1441403
[Epoch 5; Iter   532/ 1097] train: loss: 0.2563429
[Epoch 5; Iter   562/ 1097] train: loss: 0.2414943
[Epoch 5; Iter   592/ 1097] train: loss: 0.0542224
[Epoch 5; Iter   622/ 1097] train: loss: 0.0346543
[Epoch 5; Iter   652/ 1097] train: loss: 0.0825070
[Epoch 5; Iter   682/ 1097] train: loss: 0.1441738
[Epoch 5; Iter   712/ 1097] train: loss: 0.0295033
[Epoch 5; Iter   742/ 1097] train: loss: 0.1918097
[Epoch 5; Iter   772/ 1097] train: loss: 0.2547476
[Epoch 5; Iter   802/ 1097] train: loss: 0.0535526
[Epoch 5; Iter   832/ 1097] train: loss: 0.0540110
[Epoch 5; Iter   862/ 1097] train: loss: 0.0794648
[Epoch 5; Iter   892/ 1097] train: loss: 0.0375636
[Epoch 5; Iter   922/ 1097] train: loss: 0.0385476
[Epoch 5; Iter   952/ 1097] train: loss: 0.0295040
[Epoch 5; Iter   982/ 1097] train: loss: 0.0509876
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0322712
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2062788
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0433830
[Epoch 5] ogbg-molhiv: 0.762239 val loss: 0.101721
[Epoch 5] ogbg-molhiv: 0.759655 test loss: 0.115389
[Epoch 6; Iter     5/ 1097] train: loss: 0.0766389
[Epoch 6; Iter    35/ 1097] train: loss: 0.3060760
[Epoch 6; Iter    65/ 1097] train: loss: 0.0245421
[Epoch 6; Iter    95/ 1097] train: loss: 0.1154330
[Epoch 6; Iter   125/ 1097] train: loss: 0.4262856
[Epoch 6; Iter   155/ 1097] train: loss: 0.3213976
[Epoch 6; Iter   185/ 1097] train: loss: 0.0341989
[Epoch 6; Iter   215/ 1097] train: loss: 0.1328561
[Epoch 6; Iter   245/ 1097] train: loss: 0.2805409
[Epoch 6; Iter   275/ 1097] train: loss: 0.0381625
[Epoch 6; Iter   305/ 1097] train: loss: 0.1912156
[Epoch 6; Iter   335/ 1097] train: loss: 0.0761432
[Epoch 6; Iter   365/ 1097] train: loss: 0.2873353
[Epoch 6; Iter   395/ 1097] train: loss: 0.2705427
[Epoch 6; Iter   425/ 1097] train: loss: 0.0352630
[Epoch 6; Iter   455/ 1097] train: loss: 0.3265480
[Epoch 6; Iter   485/ 1097] train: loss: 0.0337616
[Epoch 6; Iter   515/ 1097] train: loss: 0.0883439
[Epoch 6; Iter   545/ 1097] train: loss: 0.1809455
[Epoch 6; Iter   575/ 1097] train: loss: 0.2238542
[Epoch 6; Iter   605/ 1097] train: loss: 0.0303988
[Epoch 6; Iter   635/ 1097] train: loss: 0.0273117
[Epoch 6; Iter   665/ 1097] train: loss: 0.1720901
[Epoch 6; Iter   695/ 1097] train: loss: 0.1925777
[Epoch 6; Iter   725/ 1097] train: loss: 0.1990484
[Epoch 6; Iter   755/ 1097] train: loss: 0.0388851
[Epoch 6; Iter   785/ 1097] train: loss: 0.0995530
[Epoch 6; Iter   815/ 1097] train: loss: 0.0356800
[Epoch 6; Iter   845/ 1097] train: loss: 0.1033577
[Epoch 6; Iter   875/ 1097] train: loss: 0.1325304
[Epoch 6; Iter   905/ 1097] train: loss: 0.3323328
[Epoch 6; Iter   935/ 1097] train: loss: 0.0328897
[Epoch 6; Iter   965/ 1097] train: loss: 0.0271250
[Epoch 6; Iter   995/ 1097] train: loss: 0.2329697
[Epoch 6; Iter  1025/ 1097] train: loss: 0.2155836
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0369734
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2326777
[Epoch 6] ogbg-molhiv: 0.760294 val loss: 0.096157
[Epoch 6] ogbg-molhiv: 0.697386 test loss: 0.140880
[Epoch 7; Iter    18/ 1097] train: loss: 0.2474813
[Epoch 7; Iter    48/ 1097] train: loss: 0.7672572
[Epoch 7; Iter    78/ 1097] train: loss: 0.3747445
[Epoch 7; Iter   108/ 1097] train: loss: 0.0426883
[Epoch 7; Iter   138/ 1097] train: loss: 0.0257345
[Epoch 7; Iter   168/ 1097] train: loss: 0.0408895
[Epoch 7; Iter   198/ 1097] train: loss: 0.1811229
[Epoch 7; Iter   228/ 1097] train: loss: 0.1524355
[Epoch 7; Iter   258/ 1097] train: loss: 0.1407771
[Epoch 7; Iter   288/ 1097] train: loss: 0.1822060
[Epoch 7; Iter   318/ 1097] train: loss: 0.0335233
[Epoch 7; Iter   348/ 1097] train: loss: 0.0311704
[Epoch 7; Iter   378/ 1097] train: loss: 0.0274625
[Epoch 7; Iter   408/ 1097] train: loss: 0.0405514
[Epoch 7; Iter   438/ 1097] train: loss: 0.0282674
[Epoch 7; Iter   468/ 1097] train: loss: 0.3006254
[Epoch 7; Iter   498/ 1097] train: loss: 0.0352093
[Epoch 7; Iter   528/ 1097] train: loss: 0.0318740
[Epoch 7; Iter   558/ 1097] train: loss: 0.2714717
[Epoch 7; Iter   588/ 1097] train: loss: 0.1683145
[Epoch 7; Iter   618/ 1097] train: loss: 0.2200964
[Epoch 7; Iter   648/ 1097] train: loss: 0.2106451
[Epoch 7; Iter   678/ 1097] train: loss: 0.0801540
[Epoch 7; Iter   708/ 1097] train: loss: 0.0944967
[Epoch 7; Iter   738/ 1097] train: loss: 0.0515511
[Epoch 7; Iter   768/ 1097] train: loss: 0.1195049
[Epoch 7; Iter   798/ 1097] train: loss: 0.2596287
[Epoch 7; Iter   828/ 1097] train: loss: 0.1674988
[Epoch 7; Iter   858/ 1097] train: loss: 0.1636835
[Epoch 7; Iter   888/ 1097] train: loss: 0.1346821
[Epoch 7; Iter   918/ 1097] train: loss: 0.1637997
[Epoch 7; Iter   948/ 1097] train: loss: 0.1785380
[Epoch 7; Iter   978/ 1097] train: loss: 0.0931549
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0274803
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2383915
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0459192
[Epoch 7] ogbg-molhiv: 0.757517 val loss: 0.161497
[Epoch 7] ogbg-molhiv: 0.741611 test loss: 0.181472
[Epoch 8; Iter     1/ 1097] train: loss: 0.1219393
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0438702
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1356005
[Epoch 3; Iter  1076/ 1097] train: loss: 0.3290862
[Epoch 3] ogbg-molhiv: 0.754510 val loss: 0.085237
[Epoch 3] ogbg-molhiv: 0.692205 test loss: 0.127995
[Epoch 4; Iter     9/ 1097] train: loss: 0.2331858
[Epoch 4; Iter    39/ 1097] train: loss: 0.1964575
[Epoch 4; Iter    69/ 1097] train: loss: 0.0452988
[Epoch 4; Iter    99/ 1097] train: loss: 0.3300002
[Epoch 4; Iter   129/ 1097] train: loss: 0.1518773
[Epoch 4; Iter   159/ 1097] train: loss: 0.1166625
[Epoch 4; Iter   189/ 1097] train: loss: 0.2848007
[Epoch 4; Iter   219/ 1097] train: loss: 0.1609160
[Epoch 4; Iter   249/ 1097] train: loss: 0.1767543
[Epoch 4; Iter   279/ 1097] train: loss: 0.1592492
[Epoch 4; Iter   309/ 1097] train: loss: 0.1075662
[Epoch 4; Iter   339/ 1097] train: loss: 0.0257331
[Epoch 4; Iter   369/ 1097] train: loss: 0.1314767
[Epoch 4; Iter   399/ 1097] train: loss: 0.1354958
[Epoch 4; Iter   429/ 1097] train: loss: 0.1625941
[Epoch 4; Iter   459/ 1097] train: loss: 0.0364384
[Epoch 4; Iter   489/ 1097] train: loss: 0.1385746
[Epoch 4; Iter   519/ 1097] train: loss: 0.2908765
[Epoch 4; Iter   549/ 1097] train: loss: 0.1950061
[Epoch 4; Iter   579/ 1097] train: loss: 0.0348369
[Epoch 4; Iter   609/ 1097] train: loss: 0.3115759
[Epoch 4; Iter   639/ 1097] train: loss: 0.3155514
[Epoch 4; Iter   669/ 1097] train: loss: 0.3183367
[Epoch 4; Iter   699/ 1097] train: loss: 0.0365864
[Epoch 4; Iter   729/ 1097] train: loss: 0.2076228
[Epoch 4; Iter   759/ 1097] train: loss: 0.2485455
[Epoch 4; Iter   789/ 1097] train: loss: 0.3904308
[Epoch 4; Iter   819/ 1097] train: loss: 0.1665296
[Epoch 4; Iter   849/ 1097] train: loss: 0.0445720
[Epoch 4; Iter   879/ 1097] train: loss: 0.0329340
[Epoch 4; Iter   909/ 1097] train: loss: 0.3981546
[Epoch 4; Iter   939/ 1097] train: loss: 0.1085851
[Epoch 4; Iter   969/ 1097] train: loss: 0.0411766
[Epoch 4; Iter   999/ 1097] train: loss: 0.1996148
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2883516
[Epoch 4; Iter  1059/ 1097] train: loss: 0.3179044
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0454056
[Epoch 4] ogbg-molhiv: 0.758475 val loss: 0.089559
[Epoch 4] ogbg-molhiv: 0.745646 test loss: 0.118819
[Epoch 5; Iter    22/ 1097] train: loss: 0.3287099
[Epoch 5; Iter    52/ 1097] train: loss: 0.1784368
[Epoch 5; Iter    82/ 1097] train: loss: 0.0863045
[Epoch 5; Iter   112/ 1097] train: loss: 0.0633005
[Epoch 5; Iter   142/ 1097] train: loss: 0.1160640
[Epoch 5; Iter   172/ 1097] train: loss: 0.0351886
[Epoch 5; Iter   202/ 1097] train: loss: 0.1424343
[Epoch 5; Iter   232/ 1097] train: loss: 0.0361848
[Epoch 5; Iter   262/ 1097] train: loss: 0.0434381
[Epoch 5; Iter   292/ 1097] train: loss: 0.1904355
[Epoch 5; Iter   322/ 1097] train: loss: 0.1763391
[Epoch 5; Iter   352/ 1097] train: loss: 0.0581896
[Epoch 5; Iter   382/ 1097] train: loss: 0.2468262
[Epoch 5; Iter   412/ 1097] train: loss: 0.2986820
[Epoch 5; Iter   442/ 1097] train: loss: 0.3040788
[Epoch 5; Iter   472/ 1097] train: loss: 0.1398523
[Epoch 5; Iter   502/ 1097] train: loss: 0.1966238
[Epoch 5; Iter   532/ 1097] train: loss: 0.0656065
[Epoch 5; Iter   562/ 1097] train: loss: 0.0427543
[Epoch 5; Iter   592/ 1097] train: loss: 0.0383438
[Epoch 5; Iter   622/ 1097] train: loss: 0.1260208
[Epoch 5; Iter   652/ 1097] train: loss: 0.1340561
[Epoch 5; Iter   682/ 1097] train: loss: 0.1875018
[Epoch 5; Iter   712/ 1097] train: loss: 0.0255165
[Epoch 5; Iter   742/ 1097] train: loss: 0.1613993
[Epoch 5; Iter   772/ 1097] train: loss: 0.1889832
[Epoch 5; Iter   802/ 1097] train: loss: 0.2244948
[Epoch 5; Iter   832/ 1097] train: loss: 0.0323070
[Epoch 5; Iter   862/ 1097] train: loss: 0.2046985
[Epoch 5; Iter   892/ 1097] train: loss: 0.0462610
[Epoch 5; Iter   922/ 1097] train: loss: 0.2797282
[Epoch 5; Iter   952/ 1097] train: loss: 0.0301262
[Epoch 5; Iter   982/ 1097] train: loss: 0.2793823
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2754315
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2369711
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0540324
[Epoch 5] ogbg-molhiv: 0.765989 val loss: 0.125139
[Epoch 5] ogbg-molhiv: 0.706638 test loss: 0.164657
[Epoch 6; Iter     5/ 1097] train: loss: 0.1075896
[Epoch 6; Iter    35/ 1097] train: loss: 0.0916498
[Epoch 6; Iter    65/ 1097] train: loss: 0.1060894
[Epoch 6; Iter    95/ 1097] train: loss: 0.0417149
[Epoch 6; Iter   125/ 1097] train: loss: 0.1245959
[Epoch 6; Iter   155/ 1097] train: loss: 0.0254557
[Epoch 6; Iter   185/ 1097] train: loss: 0.0305739
[Epoch 6; Iter   215/ 1097] train: loss: 0.3201807
[Epoch 6; Iter   245/ 1097] train: loss: 0.2364873
[Epoch 6; Iter   275/ 1097] train: loss: 0.0320362
[Epoch 6; Iter   305/ 1097] train: loss: 0.0356230
[Epoch 6; Iter   335/ 1097] train: loss: 0.1764380
[Epoch 6; Iter   365/ 1097] train: loss: 0.0623366
[Epoch 6; Iter   395/ 1097] train: loss: 0.2643239
[Epoch 6; Iter   425/ 1097] train: loss: 0.1605420
[Epoch 6; Iter   455/ 1097] train: loss: 0.1065116
[Epoch 6; Iter   485/ 1097] train: loss: 0.1939441
[Epoch 6; Iter   515/ 1097] train: loss: 0.0269550
[Epoch 6; Iter   545/ 1097] train: loss: 0.1340479
[Epoch 6; Iter   575/ 1097] train: loss: 0.0341306
[Epoch 6; Iter   605/ 1097] train: loss: 0.0301356
[Epoch 6; Iter   635/ 1097] train: loss: 0.0336868
[Epoch 6; Iter   665/ 1097] train: loss: 0.0421277
[Epoch 6; Iter   695/ 1097] train: loss: 0.1725646
[Epoch 6; Iter   725/ 1097] train: loss: 0.0343119
[Epoch 6; Iter   755/ 1097] train: loss: 0.0814425
[Epoch 6; Iter   785/ 1097] train: loss: 0.0231887
[Epoch 6; Iter   815/ 1097] train: loss: 0.1568711
[Epoch 6; Iter   845/ 1097] train: loss: 0.1013001
[Epoch 6; Iter   875/ 1097] train: loss: 0.1560525
[Epoch 6; Iter   905/ 1097] train: loss: 0.3677733
[Epoch 6; Iter   935/ 1097] train: loss: 0.1792514
[Epoch 6; Iter   965/ 1097] train: loss: 0.1230064
[Epoch 6; Iter   995/ 1097] train: loss: 0.0346136
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0296949
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0811745
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2134798
[Epoch 6] ogbg-molhiv: 0.778517 val loss: 0.094328
[Epoch 6] ogbg-molhiv: 0.718162 test loss: 0.128051
[Epoch 7; Iter    18/ 1097] train: loss: 0.0360962
[Epoch 7; Iter    48/ 1097] train: loss: 0.0919564
[Epoch 7; Iter    78/ 1097] train: loss: 0.1688641
[Epoch 7; Iter   108/ 1097] train: loss: 0.0332171
[Epoch 7; Iter   138/ 1097] train: loss: 0.0429573
[Epoch 7; Iter   168/ 1097] train: loss: 0.1222860
[Epoch 7; Iter   198/ 1097] train: loss: 0.0727673
[Epoch 7; Iter   228/ 1097] train: loss: 0.0258450
[Epoch 7; Iter   258/ 1097] train: loss: 0.0365817
[Epoch 7; Iter   288/ 1097] train: loss: 0.0851966
[Epoch 7; Iter   318/ 1097] train: loss: 0.0431852
[Epoch 7; Iter   348/ 1097] train: loss: 0.2046417
[Epoch 7; Iter   378/ 1097] train: loss: 0.1571337
[Epoch 7; Iter   408/ 1097] train: loss: 0.1262169
[Epoch 7; Iter   438/ 1097] train: loss: 0.1880025
[Epoch 7; Iter   468/ 1097] train: loss: 0.0426846
[Epoch 7; Iter   498/ 1097] train: loss: 0.0302974
[Epoch 7; Iter   528/ 1097] train: loss: 0.0399580
[Epoch 7; Iter   558/ 1097] train: loss: 0.0298448
[Epoch 7; Iter   588/ 1097] train: loss: 0.2554249
[Epoch 7; Iter   618/ 1097] train: loss: 0.3874366
[Epoch 7; Iter   648/ 1097] train: loss: 0.2388117
[Epoch 7; Iter   678/ 1097] train: loss: 0.0555383
[Epoch 7; Iter   708/ 1097] train: loss: 0.1605940
[Epoch 7; Iter   738/ 1097] train: loss: 0.2129651
[Epoch 7; Iter   768/ 1097] train: loss: 0.0359341
[Epoch 7; Iter   798/ 1097] train: loss: 0.1133877
[Epoch 7; Iter   828/ 1097] train: loss: 0.1398371
[Epoch 7; Iter   858/ 1097] train: loss: 0.0742677
[Epoch 7; Iter   888/ 1097] train: loss: 0.0231141
[Epoch 7; Iter   918/ 1097] train: loss: 0.0606480
[Epoch 7; Iter   948/ 1097] train: loss: 0.1421952
[Epoch 7; Iter   978/ 1097] train: loss: 0.0384683
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1493114
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0272978
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1549985
[Epoch 7] ogbg-molhiv: 0.719690 val loss: 5.200450
[Epoch 7] ogbg-molhiv: 0.643979 test loss: 5.164832
[Epoch 8; Iter     1/ 1097] train: loss: 0.1405453
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0788880
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0646292
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0336451
[Epoch 3] ogbg-molhiv: 0.775873 val loss: 0.099938
[Epoch 3] ogbg-molhiv: 0.743269 test loss: 0.170907
[Epoch 4; Iter     9/ 1097] train: loss: 0.3825997
[Epoch 4; Iter    39/ 1097] train: loss: 0.1076134
[Epoch 4; Iter    69/ 1097] train: loss: 0.1083717
[Epoch 4; Iter    99/ 1097] train: loss: 0.0403102
[Epoch 4; Iter   129/ 1097] train: loss: 0.1245898
[Epoch 4; Iter   159/ 1097] train: loss: 0.4279664
[Epoch 4; Iter   189/ 1097] train: loss: 0.0339354
[Epoch 4; Iter   219/ 1097] train: loss: 0.3778849
[Epoch 4; Iter   249/ 1097] train: loss: 0.0395349
[Epoch 4; Iter   279/ 1097] train: loss: 0.1033115
[Epoch 4; Iter   309/ 1097] train: loss: 0.1527566
[Epoch 4; Iter   339/ 1097] train: loss: 0.0966029
[Epoch 4; Iter   369/ 1097] train: loss: 0.1772719
[Epoch 4; Iter   399/ 1097] train: loss: 0.1468911
[Epoch 4; Iter   429/ 1097] train: loss: 0.0831826
[Epoch 4; Iter   459/ 1097] train: loss: 0.0311560
[Epoch 4; Iter   489/ 1097] train: loss: 0.0315729
[Epoch 4; Iter   519/ 1097] train: loss: 0.0820377
[Epoch 4; Iter   549/ 1097] train: loss: 0.0527844
[Epoch 4; Iter   579/ 1097] train: loss: 0.0335709
[Epoch 4; Iter   609/ 1097] train: loss: 0.2398542
[Epoch 4; Iter   639/ 1097] train: loss: 0.0313362
[Epoch 4; Iter   669/ 1097] train: loss: 0.2534690
[Epoch 4; Iter   699/ 1097] train: loss: 0.0788885
[Epoch 4; Iter   729/ 1097] train: loss: 0.3462230
[Epoch 4; Iter   759/ 1097] train: loss: 0.0593164
[Epoch 4; Iter   789/ 1097] train: loss: 0.3566086
[Epoch 4; Iter   819/ 1097] train: loss: 0.0368048
[Epoch 4; Iter   849/ 1097] train: loss: 0.2279681
[Epoch 4; Iter   879/ 1097] train: loss: 0.1206348
[Epoch 4; Iter   909/ 1097] train: loss: 0.5461442
[Epoch 4; Iter   939/ 1097] train: loss: 0.0355876
[Epoch 4; Iter   969/ 1097] train: loss: 0.0409925
[Epoch 4; Iter   999/ 1097] train: loss: 0.2597575
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2540943
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1840304
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0723448
[Epoch 4] ogbg-molhiv: 0.753800 val loss: 0.086237
[Epoch 4] ogbg-molhiv: 0.762251 test loss: 0.114873
[Epoch 5; Iter    22/ 1097] train: loss: 0.0701154
[Epoch 5; Iter    52/ 1097] train: loss: 0.1404474
[Epoch 5; Iter    82/ 1097] train: loss: 0.3891793
[Epoch 5; Iter   112/ 1097] train: loss: 0.0587011
[Epoch 5; Iter   142/ 1097] train: loss: 0.2969290
[Epoch 5; Iter   172/ 1097] train: loss: 0.2104576
[Epoch 5; Iter   202/ 1097] train: loss: 0.0337742
[Epoch 5; Iter   232/ 1097] train: loss: 0.1096983
[Epoch 5; Iter   262/ 1097] train: loss: 0.1459341
[Epoch 5; Iter   292/ 1097] train: loss: 0.2722644
[Epoch 5; Iter   322/ 1097] train: loss: 0.1630778
[Epoch 5; Iter   352/ 1097] train: loss: 0.2022825
[Epoch 5; Iter   382/ 1097] train: loss: 0.2938483
[Epoch 5; Iter   412/ 1097] train: loss: 0.0314020
[Epoch 5; Iter   442/ 1097] train: loss: 0.1610962
[Epoch 5; Iter   472/ 1097] train: loss: 0.1796293
[Epoch 5; Iter   502/ 1097] train: loss: 0.1033459
[Epoch 5; Iter   532/ 1097] train: loss: 0.0461817
[Epoch 5; Iter   562/ 1097] train: loss: 0.2845807
[Epoch 5; Iter   592/ 1097] train: loss: 0.0764333
[Epoch 5; Iter   622/ 1097] train: loss: 0.1447454
[Epoch 5; Iter   652/ 1097] train: loss: 0.2548845
[Epoch 5; Iter   682/ 1097] train: loss: 0.0252543
[Epoch 5; Iter   712/ 1097] train: loss: 0.1851408
[Epoch 5; Iter   742/ 1097] train: loss: 0.0316458
[Epoch 5; Iter   772/ 1097] train: loss: 0.0383194
[Epoch 5; Iter   802/ 1097] train: loss: 0.1955056
[Epoch 5; Iter   832/ 1097] train: loss: 0.3126516
[Epoch 5; Iter   862/ 1097] train: loss: 0.0469117
[Epoch 5; Iter   892/ 1097] train: loss: 0.1078486
[Epoch 5; Iter   922/ 1097] train: loss: 0.1327555
[Epoch 5; Iter   952/ 1097] train: loss: 0.2081917
[Epoch 5; Iter   982/ 1097] train: loss: 0.0951028
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2826698
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2667184
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0386668
[Epoch 5] ogbg-molhiv: 0.693593 val loss: 0.107077
[Epoch 5] ogbg-molhiv: 0.729589 test loss: 0.125117
[Epoch 6; Iter     5/ 1097] train: loss: 0.2177659
[Epoch 6; Iter    35/ 1097] train: loss: 0.4130965
[Epoch 6; Iter    65/ 1097] train: loss: 0.0446394
[Epoch 6; Iter    95/ 1097] train: loss: 0.1653840
[Epoch 6; Iter   125/ 1097] train: loss: 0.2600326
[Epoch 6; Iter   155/ 1097] train: loss: 0.0611457
[Epoch 6; Iter   185/ 1097] train: loss: 0.1718270
[Epoch 6; Iter   215/ 1097] train: loss: 0.1666387
[Epoch 6; Iter   245/ 1097] train: loss: 0.0624904
[Epoch 6; Iter   275/ 1097] train: loss: 0.1637339
[Epoch 6; Iter   305/ 1097] train: loss: 0.0203369
[Epoch 6; Iter   335/ 1097] train: loss: 0.0290736
[Epoch 6; Iter   365/ 1097] train: loss: 0.0474164
[Epoch 6; Iter   395/ 1097] train: loss: 0.1538301
[Epoch 6; Iter   425/ 1097] train: loss: 0.0528857
[Epoch 6; Iter   455/ 1097] train: loss: 0.2480758
[Epoch 6; Iter   485/ 1097] train: loss: 0.0307957
[Epoch 6; Iter   515/ 1097] train: loss: 0.1279289
[Epoch 6; Iter   545/ 1097] train: loss: 0.1714457
[Epoch 6; Iter   575/ 1097] train: loss: 0.0362473
[Epoch 6; Iter   605/ 1097] train: loss: 0.0564329
[Epoch 6; Iter   635/ 1097] train: loss: 0.2055511
[Epoch 6; Iter   665/ 1097] train: loss: 0.2639779
[Epoch 6; Iter   695/ 1097] train: loss: 0.2519740
[Epoch 6; Iter   725/ 1097] train: loss: 0.3174083
[Epoch 6; Iter   755/ 1097] train: loss: 0.2276277
[Epoch 6; Iter   785/ 1097] train: loss: 0.4343269
[Epoch 6; Iter   815/ 1097] train: loss: 0.0775203
[Epoch 6; Iter   845/ 1097] train: loss: 0.0336775
[Epoch 6; Iter   875/ 1097] train: loss: 0.1191478
[Epoch 6; Iter   905/ 1097] train: loss: 0.1967535
[Epoch 6; Iter   935/ 1097] train: loss: 0.0430976
[Epoch 6; Iter   965/ 1097] train: loss: 0.0757355
[Epoch 6; Iter   995/ 1097] train: loss: 0.0865183
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1506049
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1173077
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1909967
[Epoch 6] ogbg-molhiv: 0.768359 val loss: 0.235072
[Epoch 6] ogbg-molhiv: 0.678041 test loss: 0.127933
[Epoch 7; Iter    18/ 1097] train: loss: 0.0393178
[Epoch 7; Iter    48/ 1097] train: loss: 0.0269978
[Epoch 7; Iter    78/ 1097] train: loss: 0.1650425
[Epoch 7; Iter   108/ 1097] train: loss: 0.3016876
[Epoch 7; Iter   138/ 1097] train: loss: 0.1456693
[Epoch 7; Iter   168/ 1097] train: loss: 0.0257130
[Epoch 7; Iter   198/ 1097] train: loss: 0.2480828
[Epoch 7; Iter   228/ 1097] train: loss: 0.1543343
[Epoch 7; Iter   258/ 1097] train: loss: 0.0222607
[Epoch 7; Iter   288/ 1097] train: loss: 0.0204661
[Epoch 7; Iter   318/ 1097] train: loss: 0.1813026
[Epoch 7; Iter   348/ 1097] train: loss: 0.0285531
[Epoch 7; Iter   378/ 1097] train: loss: 0.2247185
[Epoch 7; Iter   408/ 1097] train: loss: 0.2767946
[Epoch 7; Iter   438/ 1097] train: loss: 0.0701470
[Epoch 7; Iter   468/ 1097] train: loss: 0.0624169
[Epoch 7; Iter   498/ 1097] train: loss: 0.1953679
[Epoch 7; Iter   528/ 1097] train: loss: 0.1270785
[Epoch 7; Iter   558/ 1097] train: loss: 0.0400424
[Epoch 7; Iter   588/ 1097] train: loss: 0.2473297
[Epoch 7; Iter   618/ 1097] train: loss: 0.1033502
[Epoch 7; Iter   648/ 1097] train: loss: 0.1187003
[Epoch 7; Iter   678/ 1097] train: loss: 0.0651564
[Epoch 7; Iter   708/ 1097] train: loss: 0.1884009
[Epoch 7; Iter   738/ 1097] train: loss: 0.1889236
[Epoch 7; Iter   768/ 1097] train: loss: 0.1562417
[Epoch 7; Iter   798/ 1097] train: loss: 0.1784295
[Epoch 7; Iter   828/ 1097] train: loss: 0.0784506
[Epoch 7; Iter   858/ 1097] train: loss: 0.1654945
[Epoch 7; Iter   888/ 1097] train: loss: 0.0313570
[Epoch 7; Iter   918/ 1097] train: loss: 0.1009821
[Epoch 7; Iter   948/ 1097] train: loss: 0.0344614
[Epoch 7; Iter   978/ 1097] train: loss: 0.0581204
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0737622
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0275097
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1583963
[Epoch 7] ogbg-molhiv: 0.747102 val loss: 0.213719
[Epoch 7] ogbg-molhiv: 0.731845 test loss: 0.142829
[Epoch 8; Iter     1/ 1097] train: loss: 0.1877602
[Epoch 3; Iter   986/ 1097] train: loss: 0.0348134
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0432538
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1269588
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2968770
[Epoch 3] ogbg-molhiv: 0.740634 val loss: 0.547219
[Epoch 3] ogbg-molhiv: 0.723320 test loss: 0.184890
[Epoch 4; Iter     9/ 1097] train: loss: 0.2244539
[Epoch 4; Iter    39/ 1097] train: loss: 0.1655093
[Epoch 4; Iter    69/ 1097] train: loss: 0.0386034
[Epoch 4; Iter    99/ 1097] train: loss: 0.2972663
[Epoch 4; Iter   129/ 1097] train: loss: 0.1589742
[Epoch 4; Iter   159/ 1097] train: loss: 0.0954668
[Epoch 4; Iter   189/ 1097] train: loss: 0.2462142
[Epoch 4; Iter   219/ 1097] train: loss: 0.1439205
[Epoch 4; Iter   249/ 1097] train: loss: 0.1788173
[Epoch 4; Iter   279/ 1097] train: loss: 0.1419943
[Epoch 4; Iter   309/ 1097] train: loss: 0.1226516
[Epoch 4; Iter   339/ 1097] train: loss: 0.0242812
[Epoch 4; Iter   369/ 1097] train: loss: 0.1275456
[Epoch 4; Iter   399/ 1097] train: loss: 0.1345513
[Epoch 4; Iter   429/ 1097] train: loss: 0.1762474
[Epoch 4; Iter   459/ 1097] train: loss: 0.0318067
[Epoch 4; Iter   489/ 1097] train: loss: 0.1361573
[Epoch 4; Iter   519/ 1097] train: loss: 0.3083649
[Epoch 4; Iter   549/ 1097] train: loss: 0.1691569
[Epoch 4; Iter   579/ 1097] train: loss: 0.0377121
[Epoch 4; Iter   609/ 1097] train: loss: 0.3353904
[Epoch 4; Iter   639/ 1097] train: loss: 0.2493146
[Epoch 4; Iter   669/ 1097] train: loss: 0.3224525
[Epoch 4; Iter   699/ 1097] train: loss: 0.0294494
[Epoch 4; Iter   729/ 1097] train: loss: 0.1724724
[Epoch 4; Iter   759/ 1097] train: loss: 0.2292469
[Epoch 4; Iter   789/ 1097] train: loss: 0.3724403
[Epoch 4; Iter   819/ 1097] train: loss: 0.1754168
[Epoch 4; Iter   849/ 1097] train: loss: 0.0572438
[Epoch 4; Iter   879/ 1097] train: loss: 0.0338015
[Epoch 4; Iter   909/ 1097] train: loss: 0.3759167
[Epoch 4; Iter   939/ 1097] train: loss: 0.1207970
[Epoch 4; Iter   969/ 1097] train: loss: 0.0614675
[Epoch 4; Iter   999/ 1097] train: loss: 0.1603147
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3727356
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2967814
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0488199
[Epoch 4] ogbg-molhiv: 0.751764 val loss: 0.089954
[Epoch 4] ogbg-molhiv: 0.695859 test loss: 0.130015
[Epoch 5; Iter    22/ 1097] train: loss: 0.4135945
[Epoch 5; Iter    52/ 1097] train: loss: 0.1664118
[Epoch 5; Iter    82/ 1097] train: loss: 0.1204752
[Epoch 5; Iter   112/ 1097] train: loss: 0.0862298
[Epoch 5; Iter   142/ 1097] train: loss: 0.1062031
[Epoch 5; Iter   172/ 1097] train: loss: 0.0324809
[Epoch 5; Iter   202/ 1097] train: loss: 0.1413418
[Epoch 5; Iter   232/ 1097] train: loss: 0.0328484
[Epoch 5; Iter   262/ 1097] train: loss: 0.0519340
[Epoch 5; Iter   292/ 1097] train: loss: 0.2274470
[Epoch 5; Iter   322/ 1097] train: loss: 0.1690599
[Epoch 5; Iter   352/ 1097] train: loss: 0.0782970
[Epoch 5; Iter   382/ 1097] train: loss: 0.2241225
[Epoch 5; Iter   412/ 1097] train: loss: 0.3066721
[Epoch 5; Iter   442/ 1097] train: loss: 0.2911363
[Epoch 5; Iter   472/ 1097] train: loss: 0.1311510
[Epoch 5; Iter   502/ 1097] train: loss: 0.2260036
[Epoch 5; Iter   532/ 1097] train: loss: 0.0596010
[Epoch 5; Iter   562/ 1097] train: loss: 0.0321721
[Epoch 5; Iter   592/ 1097] train: loss: 0.0507801
[Epoch 5; Iter   622/ 1097] train: loss: 0.1112972
[Epoch 5; Iter   652/ 1097] train: loss: 0.1113946
[Epoch 5; Iter   682/ 1097] train: loss: 0.1576963
[Epoch 5; Iter   712/ 1097] train: loss: 0.0277200
[Epoch 5; Iter   742/ 1097] train: loss: 0.1706418
[Epoch 5; Iter   772/ 1097] train: loss: 0.1794945
[Epoch 5; Iter   802/ 1097] train: loss: 0.2132714
[Epoch 5; Iter   832/ 1097] train: loss: 0.0342037
[Epoch 5; Iter   862/ 1097] train: loss: 0.2301190
[Epoch 5; Iter   892/ 1097] train: loss: 0.0433955
[Epoch 5; Iter   922/ 1097] train: loss: 0.3370810
[Epoch 5; Iter   952/ 1097] train: loss: 0.0288569
[Epoch 5; Iter   982/ 1097] train: loss: 0.3056546
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2501624
[Epoch 5; Iter  1042/ 1097] train: loss: 0.1886652
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0366392
[Epoch 5] ogbg-molhiv: 0.748046 val loss: 0.327219
[Epoch 5] ogbg-molhiv: 0.690127 test loss: 0.504100
[Epoch 6; Iter     5/ 1097] train: loss: 0.0721720
[Epoch 6; Iter    35/ 1097] train: loss: 0.0655230
[Epoch 6; Iter    65/ 1097] train: loss: 0.0658634
[Epoch 6; Iter    95/ 1097] train: loss: 0.0702253
[Epoch 6; Iter   125/ 1097] train: loss: 0.1305955
[Epoch 6; Iter   155/ 1097] train: loss: 0.0344402
[Epoch 6; Iter   185/ 1097] train: loss: 0.0348635
[Epoch 6; Iter   215/ 1097] train: loss: 0.3291216
[Epoch 6; Iter   245/ 1097] train: loss: 0.2629352
[Epoch 6; Iter   275/ 1097] train: loss: 0.0289879
[Epoch 6; Iter   305/ 1097] train: loss: 0.0419457
[Epoch 6; Iter   335/ 1097] train: loss: 0.1937955
[Epoch 6; Iter   365/ 1097] train: loss: 0.0517641
[Epoch 6; Iter   395/ 1097] train: loss: 0.3171896
[Epoch 6; Iter   425/ 1097] train: loss: 0.1846368
[Epoch 6; Iter   455/ 1097] train: loss: 0.1467205
[Epoch 6; Iter   485/ 1097] train: loss: 0.1999296
[Epoch 6; Iter   515/ 1097] train: loss: 0.0313036
[Epoch 6; Iter   545/ 1097] train: loss: 0.1489024
[Epoch 6; Iter   575/ 1097] train: loss: 0.0378872
[Epoch 6; Iter   605/ 1097] train: loss: 0.0322013
[Epoch 6; Iter   635/ 1097] train: loss: 0.0242283
[Epoch 6; Iter   665/ 1097] train: loss: 0.0428873
[Epoch 6; Iter   695/ 1097] train: loss: 0.1286980
[Epoch 6; Iter   725/ 1097] train: loss: 0.0388427
[Epoch 6; Iter   755/ 1097] train: loss: 0.1009376
[Epoch 6; Iter   785/ 1097] train: loss: 0.0263234
[Epoch 6; Iter   815/ 1097] train: loss: 0.1135395
[Epoch 6; Iter   845/ 1097] train: loss: 0.0838317
[Epoch 6; Iter   875/ 1097] train: loss: 0.1746081
[Epoch 6; Iter   905/ 1097] train: loss: 0.3034125
[Epoch 6; Iter   935/ 1097] train: loss: 0.1335540
[Epoch 6; Iter   965/ 1097] train: loss: 0.1208441
[Epoch 6; Iter   995/ 1097] train: loss: 0.0391957
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0275981
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1288005
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2347092
[Epoch 6] ogbg-molhiv: 0.761375 val loss: 0.167523
[Epoch 6] ogbg-molhiv: 0.695257 test loss: 0.146192
[Epoch 7; Iter    18/ 1097] train: loss: 0.0347845
[Epoch 7; Iter    48/ 1097] train: loss: 0.0710055
[Epoch 7; Iter    78/ 1097] train: loss: 0.2081688
[Epoch 7; Iter   108/ 1097] train: loss: 0.0322405
[Epoch 7; Iter   138/ 1097] train: loss: 0.0358434
[Epoch 7; Iter   168/ 1097] train: loss: 0.0683412
[Epoch 7; Iter   198/ 1097] train: loss: 0.0843339
[Epoch 7; Iter   228/ 1097] train: loss: 0.0271589
[Epoch 7; Iter   258/ 1097] train: loss: 0.0335571
[Epoch 7; Iter   288/ 1097] train: loss: 0.0971564
[Epoch 7; Iter   318/ 1097] train: loss: 0.0338779
[Epoch 7; Iter   348/ 1097] train: loss: 0.1594683
[Epoch 7; Iter   378/ 1097] train: loss: 0.1423049
[Epoch 7; Iter   408/ 1097] train: loss: 0.1713095
[Epoch 7; Iter   438/ 1097] train: loss: 0.1803527
[Epoch 7; Iter   468/ 1097] train: loss: 0.0319447
[Epoch 7; Iter   498/ 1097] train: loss: 0.0283460
[Epoch 7; Iter   528/ 1097] train: loss: 0.0320595
[Epoch 7; Iter   558/ 1097] train: loss: 0.0382367
[Epoch 7; Iter   588/ 1097] train: loss: 0.2704403
[Epoch 7; Iter   618/ 1097] train: loss: 0.3498276
[Epoch 7; Iter   648/ 1097] train: loss: 0.2640708
[Epoch 7; Iter   678/ 1097] train: loss: 0.0357324
[Epoch 7; Iter   708/ 1097] train: loss: 0.1577457
[Epoch 7; Iter   738/ 1097] train: loss: 0.1484945
[Epoch 7; Iter   768/ 1097] train: loss: 0.0395215
[Epoch 7; Iter   798/ 1097] train: loss: 0.0964851
[Epoch 7; Iter   828/ 1097] train: loss: 0.1454386
[Epoch 7; Iter   858/ 1097] train: loss: 0.0806428
[Epoch 7; Iter   888/ 1097] train: loss: 0.0249920
[Epoch 7; Iter   918/ 1097] train: loss: 0.0678958
[Epoch 7; Iter   948/ 1097] train: loss: 0.1421304
[Epoch 7; Iter   978/ 1097] train: loss: 0.0326312
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1819385
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0289904
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1887530
[Epoch 7] ogbg-molhiv: 0.748068 val loss: 3.707482
[Epoch 7] ogbg-molhiv: 0.713525 test loss: 2.532166
[Epoch 3; Iter   986/ 1097] train: loss: 0.0395094
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2885496
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0318135
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1540540
[Epoch 3] ogbg-molhiv: 0.699230 val loss: 0.104945
[Epoch 3] ogbg-molhiv: 0.711611 test loss: 0.125384
[Epoch 4; Iter     9/ 1097] train: loss: 0.0760338
[Epoch 4; Iter    39/ 1097] train: loss: 0.0340710
[Epoch 4; Iter    69/ 1097] train: loss: 0.0293901
[Epoch 4; Iter    99/ 1097] train: loss: 0.0283693
[Epoch 4; Iter   129/ 1097] train: loss: 0.2901759
[Epoch 4; Iter   159/ 1097] train: loss: 0.1194926
[Epoch 4; Iter   189/ 1097] train: loss: 0.0464027
[Epoch 4; Iter   219/ 1097] train: loss: 0.0329829
[Epoch 4; Iter   249/ 1097] train: loss: 0.1747701
[Epoch 4; Iter   279/ 1097] train: loss: 0.2452135
[Epoch 4; Iter   309/ 1097] train: loss: 0.0732067
[Epoch 4; Iter   339/ 1097] train: loss: 0.0547197
[Epoch 4; Iter   369/ 1097] train: loss: 0.0702479
[Epoch 4; Iter   399/ 1097] train: loss: 0.2498584
[Epoch 4; Iter   429/ 1097] train: loss: 0.0362315
[Epoch 4; Iter   459/ 1097] train: loss: 0.1107123
[Epoch 4; Iter   489/ 1097] train: loss: 0.0274607
[Epoch 4; Iter   519/ 1097] train: loss: 0.1655441
[Epoch 4; Iter   549/ 1097] train: loss: 0.0517615
[Epoch 4; Iter   579/ 1097] train: loss: 0.1181133
[Epoch 4; Iter   609/ 1097] train: loss: 0.1319153
[Epoch 4; Iter   639/ 1097] train: loss: 0.0907069
[Epoch 4; Iter   669/ 1097] train: loss: 0.2418493
[Epoch 4; Iter   699/ 1097] train: loss: 0.0911293
[Epoch 4; Iter   729/ 1097] train: loss: 0.0348803
[Epoch 4; Iter   759/ 1097] train: loss: 0.0296251
[Epoch 4; Iter   789/ 1097] train: loss: 0.0442619
[Epoch 4; Iter   819/ 1097] train: loss: 0.1317692
[Epoch 4; Iter   849/ 1097] train: loss: 0.0259050
[Epoch 4; Iter   879/ 1097] train: loss: 0.0425342
[Epoch 4; Iter   909/ 1097] train: loss: 0.0359428
[Epoch 4; Iter   939/ 1097] train: loss: 0.3246679
[Epoch 4; Iter   969/ 1097] train: loss: 0.0933664
[Epoch 4; Iter   999/ 1097] train: loss: 0.0412599
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2191695
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1244449
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1915349
[Epoch 4] ogbg-molhiv: 0.778032 val loss: 0.123500
[Epoch 4] ogbg-molhiv: 0.755122 test loss: 0.201965
[Epoch 5; Iter    22/ 1097] train: loss: 0.1337725
[Epoch 5; Iter    52/ 1097] train: loss: 0.1743886
[Epoch 5; Iter    82/ 1097] train: loss: 0.1718025
[Epoch 5; Iter   112/ 1097] train: loss: 0.3795511
[Epoch 5; Iter   142/ 1097] train: loss: 0.3766845
[Epoch 5; Iter   172/ 1097] train: loss: 0.0288873
[Epoch 5; Iter   202/ 1097] train: loss: 0.1744110
[Epoch 5; Iter   232/ 1097] train: loss: 0.2019792
[Epoch 5; Iter   262/ 1097] train: loss: 0.0462212
[Epoch 5; Iter   292/ 1097] train: loss: 0.1940292
[Epoch 5; Iter   322/ 1097] train: loss: 0.0344860
[Epoch 5; Iter   352/ 1097] train: loss: 0.0877016
[Epoch 5; Iter   382/ 1097] train: loss: 0.1479137
[Epoch 5; Iter   412/ 1097] train: loss: 0.3440405
[Epoch 5; Iter   442/ 1097] train: loss: 0.1455233
[Epoch 5; Iter   472/ 1097] train: loss: 0.1464622
[Epoch 5; Iter   502/ 1097] train: loss: 0.1873130
[Epoch 5; Iter   532/ 1097] train: loss: 0.2606584
[Epoch 5; Iter   562/ 1097] train: loss: 0.2803873
[Epoch 5; Iter   592/ 1097] train: loss: 0.0480199
[Epoch 5; Iter   622/ 1097] train: loss: 0.0354701
[Epoch 5; Iter   652/ 1097] train: loss: 0.1194890
[Epoch 5; Iter   682/ 1097] train: loss: 0.1229903
[Epoch 5; Iter   712/ 1097] train: loss: 0.0343132
[Epoch 5; Iter   742/ 1097] train: loss: 0.1549321
[Epoch 5; Iter   772/ 1097] train: loss: 0.2791758
[Epoch 5; Iter   802/ 1097] train: loss: 0.0874512
[Epoch 5; Iter   832/ 1097] train: loss: 0.0536542
[Epoch 5; Iter   862/ 1097] train: loss: 0.0698868
[Epoch 5; Iter   892/ 1097] train: loss: 0.0602092
[Epoch 5; Iter   922/ 1097] train: loss: 0.0351608
[Epoch 5; Iter   952/ 1097] train: loss: 0.0388136
[Epoch 5; Iter   982/ 1097] train: loss: 0.0647473
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0364269
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2462723
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0392086
[Epoch 5] ogbg-molhiv: 0.765086 val loss: 0.085365
[Epoch 5] ogbg-molhiv: 0.723508 test loss: 0.125648
[Epoch 6; Iter     5/ 1097] train: loss: 0.0532286
[Epoch 6; Iter    35/ 1097] train: loss: 0.1870202
[Epoch 6; Iter    65/ 1097] train: loss: 0.0405221
[Epoch 6; Iter    95/ 1097] train: loss: 0.0860271
[Epoch 6; Iter   125/ 1097] train: loss: 0.4544684
[Epoch 6; Iter   155/ 1097] train: loss: 0.3825429
[Epoch 6; Iter   185/ 1097] train: loss: 0.0336286
[Epoch 6; Iter   215/ 1097] train: loss: 0.1549088
[Epoch 6; Iter   245/ 1097] train: loss: 0.2742834
[Epoch 6; Iter   275/ 1097] train: loss: 0.0431455
[Epoch 6; Iter   305/ 1097] train: loss: 0.1771599
[Epoch 6; Iter   335/ 1097] train: loss: 0.0601484
[Epoch 6; Iter   365/ 1097] train: loss: 0.2673477
[Epoch 6; Iter   395/ 1097] train: loss: 0.3326257
[Epoch 6; Iter   425/ 1097] train: loss: 0.0350532
[Epoch 6; Iter   455/ 1097] train: loss: 0.2918441
[Epoch 6; Iter   485/ 1097] train: loss: 0.0313504
[Epoch 6; Iter   515/ 1097] train: loss: 0.1065928
[Epoch 6; Iter   545/ 1097] train: loss: 0.1678725
[Epoch 6; Iter   575/ 1097] train: loss: 0.2107466
[Epoch 6; Iter   605/ 1097] train: loss: 0.0415451
[Epoch 6; Iter   635/ 1097] train: loss: 0.0372011
[Epoch 6; Iter   665/ 1097] train: loss: 0.2472681
[Epoch 6; Iter   695/ 1097] train: loss: 0.2093620
[Epoch 6; Iter   725/ 1097] train: loss: 0.1982530
[Epoch 6; Iter   755/ 1097] train: loss: 0.0833432
[Epoch 6; Iter   785/ 1097] train: loss: 0.1323348
[Epoch 6; Iter   815/ 1097] train: loss: 0.0416209
[Epoch 6; Iter   845/ 1097] train: loss: 0.0935712
[Epoch 6; Iter   875/ 1097] train: loss: 0.2020722
[Epoch 6; Iter   905/ 1097] train: loss: 0.3151855
[Epoch 6; Iter   935/ 1097] train: loss: 0.0410392
[Epoch 6; Iter   965/ 1097] train: loss: 0.0305048
[Epoch 6; Iter   995/ 1097] train: loss: 0.1805108
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1704252
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0293664
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2754337
[Epoch 6] ogbg-molhiv: 0.732409 val loss: 0.120234
[Epoch 6] ogbg-molhiv: 0.753614 test loss: 0.130039
[Epoch 7; Iter    18/ 1097] train: loss: 0.1773258
[Epoch 7; Iter    48/ 1097] train: loss: 0.6728979
[Epoch 7; Iter    78/ 1097] train: loss: 0.3516400
[Epoch 7; Iter   108/ 1097] train: loss: 0.0575995
[Epoch 7; Iter   138/ 1097] train: loss: 0.0271296
[Epoch 7; Iter   168/ 1097] train: loss: 0.0545427
[Epoch 7; Iter   198/ 1097] train: loss: 0.1740557
[Epoch 7; Iter   228/ 1097] train: loss: 0.1761448
[Epoch 7; Iter   258/ 1097] train: loss: 0.1406998
[Epoch 7; Iter   288/ 1097] train: loss: 0.1470047
[Epoch 7; Iter   318/ 1097] train: loss: 0.0357804
[Epoch 7; Iter   348/ 1097] train: loss: 0.0594723
[Epoch 7; Iter   378/ 1097] train: loss: 0.0281793
[Epoch 7; Iter   408/ 1097] train: loss: 0.0376806
[Epoch 7; Iter   438/ 1097] train: loss: 0.0308402
[Epoch 7; Iter   468/ 1097] train: loss: 0.2832358
[Epoch 7; Iter   498/ 1097] train: loss: 0.0522909
[Epoch 7; Iter   528/ 1097] train: loss: 0.0296241
[Epoch 7; Iter   558/ 1097] train: loss: 0.2478106
[Epoch 7; Iter   588/ 1097] train: loss: 0.1992293
[Epoch 7; Iter   618/ 1097] train: loss: 0.3436905
[Epoch 7; Iter   648/ 1097] train: loss: 0.1849171
[Epoch 7; Iter   678/ 1097] train: loss: 0.0801002
[Epoch 7; Iter   708/ 1097] train: loss: 0.0633593
[Epoch 7; Iter   738/ 1097] train: loss: 0.0315679
[Epoch 7; Iter   768/ 1097] train: loss: 0.1041704
[Epoch 7; Iter   798/ 1097] train: loss: 0.2170287
[Epoch 7; Iter   828/ 1097] train: loss: 0.1578672
[Epoch 7; Iter   858/ 1097] train: loss: 0.1542079
[Epoch 7; Iter   888/ 1097] train: loss: 0.1405789
[Epoch 7; Iter   918/ 1097] train: loss: 0.1556186
[Epoch 7; Iter   948/ 1097] train: loss: 0.1993787
[Epoch 7; Iter   978/ 1097] train: loss: 0.1146982
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0292298
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2780474
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0392929
[Epoch 7] ogbg-molhiv: 0.788259 val loss: 0.170810
[Epoch 7] ogbg-molhiv: 0.758900 test loss: 0.183180
[Epoch 3; Iter   986/ 1097] train: loss: 0.2437280
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0788827
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0808575
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0311092
[Epoch 3] ogbg-molhiv: 0.771795 val loss: 0.080537
[Epoch 3] ogbg-molhiv: 0.759327 test loss: 0.113059
[Epoch 4; Iter     9/ 1097] train: loss: 0.3989277
[Epoch 4; Iter    39/ 1097] train: loss: 0.1057034
[Epoch 4; Iter    69/ 1097] train: loss: 0.0743959
[Epoch 4; Iter    99/ 1097] train: loss: 0.0450134
[Epoch 4; Iter   129/ 1097] train: loss: 0.1719560
[Epoch 4; Iter   159/ 1097] train: loss: 0.3835869
[Epoch 4; Iter   189/ 1097] train: loss: 0.0292959
[Epoch 4; Iter   219/ 1097] train: loss: 0.3535841
[Epoch 4; Iter   249/ 1097] train: loss: 0.0275523
[Epoch 4; Iter   279/ 1097] train: loss: 0.1665941
[Epoch 4; Iter   309/ 1097] train: loss: 0.1251464
[Epoch 4; Iter   339/ 1097] train: loss: 0.0790910
[Epoch 4; Iter   369/ 1097] train: loss: 0.1183895
[Epoch 4; Iter   399/ 1097] train: loss: 0.1397513
[Epoch 4; Iter   429/ 1097] train: loss: 0.0745948
[Epoch 4; Iter   459/ 1097] train: loss: 0.0336329
[Epoch 4; Iter   489/ 1097] train: loss: 0.0297904
[Epoch 4; Iter   519/ 1097] train: loss: 0.1014540
[Epoch 4; Iter   549/ 1097] train: loss: 0.0356636
[Epoch 4; Iter   579/ 1097] train: loss: 0.0389348
[Epoch 4; Iter   609/ 1097] train: loss: 0.2424575
[Epoch 4; Iter   639/ 1097] train: loss: 0.0342791
[Epoch 4; Iter   669/ 1097] train: loss: 0.2752593
[Epoch 4; Iter   699/ 1097] train: loss: 0.0973973
[Epoch 4; Iter   729/ 1097] train: loss: 0.3965445
[Epoch 4; Iter   759/ 1097] train: loss: 0.0563020
[Epoch 4; Iter   789/ 1097] train: loss: 0.3149139
[Epoch 4; Iter   819/ 1097] train: loss: 0.0334514
[Epoch 4; Iter   849/ 1097] train: loss: 0.2279909
[Epoch 4; Iter   879/ 1097] train: loss: 0.1366579
[Epoch 4; Iter   909/ 1097] train: loss: 0.5094956
[Epoch 4; Iter   939/ 1097] train: loss: 0.0373879
[Epoch 4; Iter   969/ 1097] train: loss: 0.0395312
[Epoch 4; Iter   999/ 1097] train: loss: 0.2779488
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2802096
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1930501
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0595951
[Epoch 4] ogbg-molhiv: 0.741701 val loss: 0.083102
[Epoch 4] ogbg-molhiv: 0.729915 test loss: 0.120107
[Epoch 5; Iter    22/ 1097] train: loss: 0.0567413
[Epoch 5; Iter    52/ 1097] train: loss: 0.1141993
[Epoch 5; Iter    82/ 1097] train: loss: 0.3842657
[Epoch 5; Iter   112/ 1097] train: loss: 0.0461446
[Epoch 5; Iter   142/ 1097] train: loss: 0.2934678
[Epoch 5; Iter   172/ 1097] train: loss: 0.2039345
[Epoch 5; Iter   202/ 1097] train: loss: 0.0355293
[Epoch 5; Iter   232/ 1097] train: loss: 0.1378600
[Epoch 5; Iter   262/ 1097] train: loss: 0.1506714
[Epoch 5; Iter   292/ 1097] train: loss: 0.2562084
[Epoch 5; Iter   322/ 1097] train: loss: 0.1736985
[Epoch 5; Iter   352/ 1097] train: loss: 0.1979645
[Epoch 5; Iter   382/ 1097] train: loss: 0.2549163
[Epoch 5; Iter   412/ 1097] train: loss: 0.0343760
[Epoch 5; Iter   442/ 1097] train: loss: 0.1284656
[Epoch 5; Iter   472/ 1097] train: loss: 0.1379776
[Epoch 5; Iter   502/ 1097] train: loss: 0.1387606
[Epoch 5; Iter   532/ 1097] train: loss: 0.0387225
[Epoch 5; Iter   562/ 1097] train: loss: 0.2527386
[Epoch 5; Iter   592/ 1097] train: loss: 0.0591960
[Epoch 5; Iter   622/ 1097] train: loss: 0.2306064
[Epoch 5; Iter   652/ 1097] train: loss: 0.2365823
[Epoch 5; Iter   682/ 1097] train: loss: 0.0286808
[Epoch 5; Iter   712/ 1097] train: loss: 0.1899710
[Epoch 5; Iter   742/ 1097] train: loss: 0.0324300
[Epoch 5; Iter   772/ 1097] train: loss: 0.0344997
[Epoch 5; Iter   802/ 1097] train: loss: 0.1772996
[Epoch 5; Iter   832/ 1097] train: loss: 0.2787336
[Epoch 5; Iter   862/ 1097] train: loss: 0.0578434
[Epoch 5; Iter   892/ 1097] train: loss: 0.1523130
[Epoch 5; Iter   922/ 1097] train: loss: 0.0770697
[Epoch 5; Iter   952/ 1097] train: loss: 0.2014938
[Epoch 5; Iter   982/ 1097] train: loss: 0.1576454
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2448917
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2719778
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0393617
[Epoch 5] ogbg-molhiv: 0.744035 val loss: 0.131885
[Epoch 5] ogbg-molhiv: 0.755411 test loss: 0.132786
[Epoch 6; Iter     5/ 1097] train: loss: 0.2320545
[Epoch 6; Iter    35/ 1097] train: loss: 0.3662797
[Epoch 6; Iter    65/ 1097] train: loss: 0.0364358
[Epoch 6; Iter    95/ 1097] train: loss: 0.1239888
[Epoch 6; Iter   125/ 1097] train: loss: 0.2906102
[Epoch 6; Iter   155/ 1097] train: loss: 0.0751607
[Epoch 6; Iter   185/ 1097] train: loss: 0.1619753
[Epoch 6; Iter   215/ 1097] train: loss: 0.1341734
[Epoch 6; Iter   245/ 1097] train: loss: 0.0644173
[Epoch 6; Iter   275/ 1097] train: loss: 0.1736868
[Epoch 6; Iter   305/ 1097] train: loss: 0.0296509
[Epoch 6; Iter   335/ 1097] train: loss: 0.0571560
[Epoch 6; Iter   365/ 1097] train: loss: 0.0315835
[Epoch 6; Iter   395/ 1097] train: loss: 0.1302347
[Epoch 6; Iter   425/ 1097] train: loss: 0.0407770
[Epoch 6; Iter   455/ 1097] train: loss: 0.2152824
[Epoch 6; Iter   485/ 1097] train: loss: 0.0347808
[Epoch 6; Iter   515/ 1097] train: loss: 0.0730958
[Epoch 6; Iter   545/ 1097] train: loss: 0.1119515
[Epoch 6; Iter   575/ 1097] train: loss: 0.0368247
[Epoch 6; Iter   605/ 1097] train: loss: 0.0520247
[Epoch 6; Iter   635/ 1097] train: loss: 0.2269643
[Epoch 6; Iter   665/ 1097] train: loss: 0.2468638
[Epoch 6; Iter   695/ 1097] train: loss: 0.2293087
[Epoch 6; Iter   725/ 1097] train: loss: 0.3524569
[Epoch 6; Iter   755/ 1097] train: loss: 0.2058038
[Epoch 6; Iter   785/ 1097] train: loss: 0.3660369
[Epoch 6; Iter   815/ 1097] train: loss: 0.1092560
[Epoch 6; Iter   845/ 1097] train: loss: 0.0333423
[Epoch 6; Iter   875/ 1097] train: loss: 0.0970828
[Epoch 6; Iter   905/ 1097] train: loss: 0.2004513
[Epoch 6; Iter   935/ 1097] train: loss: 0.0628925
[Epoch 6; Iter   965/ 1097] train: loss: 0.0857810
[Epoch 6; Iter   995/ 1097] train: loss: 0.1371107
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1540718
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1357919
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1968275
[Epoch 6] ogbg-molhiv: 0.768264 val loss: 0.087456
[Epoch 6] ogbg-molhiv: 0.727164 test loss: 0.123056
[Epoch 7; Iter    18/ 1097] train: loss: 0.0442511
[Epoch 7; Iter    48/ 1097] train: loss: 0.0278884
[Epoch 7; Iter    78/ 1097] train: loss: 0.1243939
[Epoch 7; Iter   108/ 1097] train: loss: 0.2708899
[Epoch 7; Iter   138/ 1097] train: loss: 0.1754011
[Epoch 7; Iter   168/ 1097] train: loss: 0.0323117
[Epoch 7; Iter   198/ 1097] train: loss: 0.3158747
[Epoch 7; Iter   228/ 1097] train: loss: 0.1440026
[Epoch 7; Iter   258/ 1097] train: loss: 0.0226012
[Epoch 7; Iter   288/ 1097] train: loss: 0.0190293
[Epoch 7; Iter   318/ 1097] train: loss: 0.1390641
[Epoch 7; Iter   348/ 1097] train: loss: 0.0287821
[Epoch 7; Iter   378/ 1097] train: loss: 0.1946235
[Epoch 7; Iter   408/ 1097] train: loss: 0.1805513
[Epoch 7; Iter   438/ 1097] train: loss: 0.0544131
[Epoch 7; Iter   468/ 1097] train: loss: 0.0404812
[Epoch 7; Iter   498/ 1097] train: loss: 0.1657826
[Epoch 7; Iter   528/ 1097] train: loss: 0.0878901
[Epoch 7; Iter   558/ 1097] train: loss: 0.0346688
[Epoch 7; Iter   588/ 1097] train: loss: 0.2416683
[Epoch 7; Iter   618/ 1097] train: loss: 0.1058260
[Epoch 7; Iter   648/ 1097] train: loss: 0.0651465
[Epoch 7; Iter   678/ 1097] train: loss: 0.0377770
[Epoch 7; Iter   708/ 1097] train: loss: 0.1967664
[Epoch 7; Iter   738/ 1097] train: loss: 0.1694535
[Epoch 7; Iter   768/ 1097] train: loss: 0.1532263
[Epoch 7; Iter   798/ 1097] train: loss: 0.1102585
[Epoch 7; Iter   828/ 1097] train: loss: 0.0551126
[Epoch 7; Iter   858/ 1097] train: loss: 0.2060250
[Epoch 7; Iter   888/ 1097] train: loss: 0.0409394
[Epoch 7; Iter   918/ 1097] train: loss: 0.1290209
[Epoch 7; Iter   948/ 1097] train: loss: 0.0419921
[Epoch 7; Iter   978/ 1097] train: loss: 0.0453055
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0662947
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0314157
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1737662
[Epoch 7] ogbg-molhiv: 0.791400 val loss: 0.077749
[Epoch 7] ogbg-molhiv: 0.733141 test loss: 0.120333
[Epoch 3; Iter  1016/ 1097] train: loss: 0.3304092
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0339055
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1730400
[Epoch 3] ogbg-molhiv: 0.717620 val loss: 0.089300
[Epoch 3] ogbg-molhiv: 0.723170 test loss: 0.121478
[Epoch 4; Iter     9/ 1097] train: loss: 0.0871680
[Epoch 4; Iter    39/ 1097] train: loss: 0.0281132
[Epoch 4; Iter    69/ 1097] train: loss: 0.0304870
[Epoch 4; Iter    99/ 1097] train: loss: 0.0296470
[Epoch 4; Iter   129/ 1097] train: loss: 0.2735537
[Epoch 4; Iter   159/ 1097] train: loss: 0.1086842
[Epoch 4; Iter   189/ 1097] train: loss: 0.0403645
[Epoch 4; Iter   219/ 1097] train: loss: 0.0378264
[Epoch 4; Iter   249/ 1097] train: loss: 0.1674881
[Epoch 4; Iter   279/ 1097] train: loss: 0.2342895
[Epoch 4; Iter   309/ 1097] train: loss: 0.0927999
[Epoch 4; Iter   339/ 1097] train: loss: 0.0562523
[Epoch 4; Iter   369/ 1097] train: loss: 0.0681780
[Epoch 4; Iter   399/ 1097] train: loss: 0.2525372
[Epoch 4; Iter   429/ 1097] train: loss: 0.0327105
[Epoch 4; Iter   459/ 1097] train: loss: 0.1474974
[Epoch 4; Iter   489/ 1097] train: loss: 0.0325136
[Epoch 4; Iter   519/ 1097] train: loss: 0.1740960
[Epoch 4; Iter   549/ 1097] train: loss: 0.0435781
[Epoch 4; Iter   579/ 1097] train: loss: 0.1556184
[Epoch 4; Iter   609/ 1097] train: loss: 0.1561037
[Epoch 4; Iter   639/ 1097] train: loss: 0.0967451
[Epoch 4; Iter   669/ 1097] train: loss: 0.2373704
[Epoch 4; Iter   699/ 1097] train: loss: 0.1006799
[Epoch 4; Iter   729/ 1097] train: loss: 0.0345459
[Epoch 4; Iter   759/ 1097] train: loss: 0.0298892
[Epoch 4; Iter   789/ 1097] train: loss: 0.0288866
[Epoch 4; Iter   819/ 1097] train: loss: 0.1316311
[Epoch 4; Iter   849/ 1097] train: loss: 0.0311994
[Epoch 4; Iter   879/ 1097] train: loss: 0.0480297
[Epoch 4; Iter   909/ 1097] train: loss: 0.0346095
[Epoch 4; Iter   939/ 1097] train: loss: 0.3559328
[Epoch 4; Iter   969/ 1097] train: loss: 0.1017942
[Epoch 4; Iter   999/ 1097] train: loss: 0.0308171
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2300353
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1615779
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1679773
[Epoch 4] ogbg-molhiv: 0.757563 val loss: 0.133907
[Epoch 4] ogbg-molhiv: 0.720138 test loss: 0.167127
[Epoch 5; Iter    22/ 1097] train: loss: 0.1271434
[Epoch 5; Iter    52/ 1097] train: loss: 0.1648263
[Epoch 5; Iter    82/ 1097] train: loss: 0.1596314
[Epoch 5; Iter   112/ 1097] train: loss: 0.4001248
[Epoch 5; Iter   142/ 1097] train: loss: 0.3410641
[Epoch 5; Iter   172/ 1097] train: loss: 0.0307745
[Epoch 5; Iter   202/ 1097] train: loss: 0.1975423
[Epoch 5; Iter   232/ 1097] train: loss: 0.2275917
[Epoch 5; Iter   262/ 1097] train: loss: 0.0439258
[Epoch 5; Iter   292/ 1097] train: loss: 0.1716801
[Epoch 5; Iter   322/ 1097] train: loss: 0.0272927
[Epoch 5; Iter   352/ 1097] train: loss: 0.1199374
[Epoch 5; Iter   382/ 1097] train: loss: 0.1285438
[Epoch 5; Iter   412/ 1097] train: loss: 0.3377615
[Epoch 5; Iter   442/ 1097] train: loss: 0.1275509
[Epoch 5; Iter   472/ 1097] train: loss: 0.1582800
[Epoch 5; Iter   502/ 1097] train: loss: 0.1891292
[Epoch 5; Iter   532/ 1097] train: loss: 0.2755935
[Epoch 5; Iter   562/ 1097] train: loss: 0.2473225
[Epoch 5; Iter   592/ 1097] train: loss: 0.0424860
[Epoch 5; Iter   622/ 1097] train: loss: 0.0358199
[Epoch 5; Iter   652/ 1097] train: loss: 0.1665876
[Epoch 5; Iter   682/ 1097] train: loss: 0.1703239
[Epoch 5; Iter   712/ 1097] train: loss: 0.0290502
[Epoch 5; Iter   742/ 1097] train: loss: 0.1607380
[Epoch 5; Iter   772/ 1097] train: loss: 0.2528550
[Epoch 5; Iter   802/ 1097] train: loss: 0.0921515
[Epoch 5; Iter   832/ 1097] train: loss: 0.0501312
[Epoch 5; Iter   862/ 1097] train: loss: 0.0949936
[Epoch 5; Iter   892/ 1097] train: loss: 0.0492553
[Epoch 5; Iter   922/ 1097] train: loss: 0.0447877
[Epoch 5; Iter   952/ 1097] train: loss: 0.0415536
[Epoch 5; Iter   982/ 1097] train: loss: 0.0686149
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0400321
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2402074
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0415710
[Epoch 5] ogbg-molhiv: 0.720667 val loss: 0.480243
[Epoch 5] ogbg-molhiv: 0.724240 test loss: 0.727181
[Epoch 6; Iter     5/ 1097] train: loss: 0.0900411
[Epoch 6; Iter    35/ 1097] train: loss: 0.2932671
[Epoch 6; Iter    65/ 1097] train: loss: 0.0800010
[Epoch 6; Iter    95/ 1097] train: loss: 0.0600718
[Epoch 6; Iter   125/ 1097] train: loss: 0.4426668
[Epoch 6; Iter   155/ 1097] train: loss: 0.3309793
[Epoch 6; Iter   185/ 1097] train: loss: 0.0402829
[Epoch 6; Iter   215/ 1097] train: loss: 0.0895191
[Epoch 6; Iter   245/ 1097] train: loss: 0.3098597
[Epoch 6; Iter   275/ 1097] train: loss: 0.0408362
[Epoch 6; Iter   305/ 1097] train: loss: 0.2405231
[Epoch 6; Iter   335/ 1097] train: loss: 0.0523512
[Epoch 6; Iter   365/ 1097] train: loss: 0.3001451
[Epoch 6; Iter   395/ 1097] train: loss: 0.3805702
[Epoch 6; Iter   425/ 1097] train: loss: 0.0355664
[Epoch 6; Iter   455/ 1097] train: loss: 0.3368496
[Epoch 6; Iter   485/ 1097] train: loss: 0.0446866
[Epoch 6; Iter   515/ 1097] train: loss: 0.1093511
[Epoch 6; Iter   545/ 1097] train: loss: 0.1832650
[Epoch 6; Iter   575/ 1097] train: loss: 0.1686919
[Epoch 6; Iter   605/ 1097] train: loss: 0.0417686
[Epoch 6; Iter   635/ 1097] train: loss: 0.0355557
[Epoch 6; Iter   665/ 1097] train: loss: 0.2275425
[Epoch 6; Iter   695/ 1097] train: loss: 0.1900648
[Epoch 6; Iter   725/ 1097] train: loss: 0.1841863
[Epoch 6; Iter   755/ 1097] train: loss: 0.0401099
[Epoch 6; Iter   785/ 1097] train: loss: 0.1306883
[Epoch 6; Iter   815/ 1097] train: loss: 0.0343127
[Epoch 6; Iter   845/ 1097] train: loss: 0.0904848
[Epoch 6; Iter   875/ 1097] train: loss: 0.1731724
[Epoch 6; Iter   905/ 1097] train: loss: 0.3348285
[Epoch 6; Iter   935/ 1097] train: loss: 0.0465986
[Epoch 6; Iter   965/ 1097] train: loss: 0.0282748
[Epoch 6; Iter   995/ 1097] train: loss: 0.1904151
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1605815
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0279011
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2189803
[Epoch 6] ogbg-molhiv: 0.759290 val loss: 0.105141
[Epoch 6] ogbg-molhiv: 0.707031 test loss: 0.165418
[Epoch 7; Iter    18/ 1097] train: loss: 0.1880330
[Epoch 7; Iter    48/ 1097] train: loss: 0.7633022
[Epoch 7; Iter    78/ 1097] train: loss: 0.3637716
[Epoch 7; Iter   108/ 1097] train: loss: 0.0390667
[Epoch 7; Iter   138/ 1097] train: loss: 0.0250373
[Epoch 7; Iter   168/ 1097] train: loss: 0.0625742
[Epoch 7; Iter   198/ 1097] train: loss: 0.1806764
[Epoch 7; Iter   228/ 1097] train: loss: 0.1874762
[Epoch 7; Iter   258/ 1097] train: loss: 0.1291411
[Epoch 7; Iter   288/ 1097] train: loss: 0.1871476
[Epoch 7; Iter   318/ 1097] train: loss: 0.0386400
[Epoch 7; Iter   348/ 1097] train: loss: 0.0358363
[Epoch 7; Iter   378/ 1097] train: loss: 0.0311386
[Epoch 7; Iter   408/ 1097] train: loss: 0.0557976
[Epoch 7; Iter   438/ 1097] train: loss: 0.0303580
[Epoch 7; Iter   468/ 1097] train: loss: 0.2534817
[Epoch 7; Iter   498/ 1097] train: loss: 0.0508691
[Epoch 7; Iter   528/ 1097] train: loss: 0.0312848
[Epoch 7; Iter   558/ 1097] train: loss: 0.2648880
[Epoch 7; Iter   588/ 1097] train: loss: 0.2161668
[Epoch 7; Iter   618/ 1097] train: loss: 0.2506028
[Epoch 7; Iter   648/ 1097] train: loss: 0.2113072
[Epoch 7; Iter   678/ 1097] train: loss: 0.1404554
[Epoch 7; Iter   708/ 1097] train: loss: 0.0574273
[Epoch 7; Iter   738/ 1097] train: loss: 0.0347871
[Epoch 7; Iter   768/ 1097] train: loss: 0.1091378
[Epoch 7; Iter   798/ 1097] train: loss: 0.2484190
[Epoch 7; Iter   828/ 1097] train: loss: 0.1909928
[Epoch 7; Iter   858/ 1097] train: loss: 0.2326796
[Epoch 7; Iter   888/ 1097] train: loss: 0.1753160
[Epoch 7; Iter   918/ 1097] train: loss: 0.1403202
[Epoch 7; Iter   948/ 1097] train: loss: 0.2139868
[Epoch 7; Iter   978/ 1097] train: loss: 0.1276388
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0288275
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2714287
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0476139
[Epoch 7] ogbg-molhiv: 0.775215 val loss: 0.112374
[Epoch 7] ogbg-molhiv: 0.757693 test loss: 0.116808
[Epoch 8; Iter     1/ 1097] train: loss: 0.1389081
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0564627
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1335151
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2737132
[Epoch 3] ogbg-molhiv: 0.708636 val loss: 0.171097
[Epoch 3] ogbg-molhiv: 0.642102 test loss: 0.164373
[Epoch 4; Iter     9/ 1097] train: loss: 0.2364019
[Epoch 4; Iter    39/ 1097] train: loss: 0.2161308
[Epoch 4; Iter    69/ 1097] train: loss: 0.0468756
[Epoch 4; Iter    99/ 1097] train: loss: 0.3191281
[Epoch 4; Iter   129/ 1097] train: loss: 0.1543059
[Epoch 4; Iter   159/ 1097] train: loss: 0.1121994
[Epoch 4; Iter   189/ 1097] train: loss: 0.3331034
[Epoch 4; Iter   219/ 1097] train: loss: 0.2264787
[Epoch 4; Iter   249/ 1097] train: loss: 0.1574599
[Epoch 4; Iter   279/ 1097] train: loss: 0.1757024
[Epoch 4; Iter   309/ 1097] train: loss: 0.1234756
[Epoch 4; Iter   339/ 1097] train: loss: 0.0278937
[Epoch 4; Iter   369/ 1097] train: loss: 0.1463885
[Epoch 4; Iter   399/ 1097] train: loss: 0.1650235
[Epoch 4; Iter   429/ 1097] train: loss: 0.1899743
[Epoch 4; Iter   459/ 1097] train: loss: 0.0351116
[Epoch 4; Iter   489/ 1097] train: loss: 0.1190081
[Epoch 4; Iter   519/ 1097] train: loss: 0.3309013
[Epoch 4; Iter   549/ 1097] train: loss: 0.1889510
[Epoch 4; Iter   579/ 1097] train: loss: 0.0367732
[Epoch 4; Iter   609/ 1097] train: loss: 0.3669032
[Epoch 4; Iter   639/ 1097] train: loss: 0.2832303
[Epoch 4; Iter   669/ 1097] train: loss: 0.2852240
[Epoch 4; Iter   699/ 1097] train: loss: 0.0387092
[Epoch 4; Iter   729/ 1097] train: loss: 0.2416418
[Epoch 4; Iter   759/ 1097] train: loss: 0.2164608
[Epoch 4; Iter   789/ 1097] train: loss: 0.3754856
[Epoch 4; Iter   819/ 1097] train: loss: 0.1704060
[Epoch 4; Iter   849/ 1097] train: loss: 0.0426934
[Epoch 4; Iter   879/ 1097] train: loss: 0.0368694
[Epoch 4; Iter   909/ 1097] train: loss: 0.3999960
[Epoch 4; Iter   939/ 1097] train: loss: 0.1318488
[Epoch 4; Iter   969/ 1097] train: loss: 0.1125906
[Epoch 4; Iter   999/ 1097] train: loss: 0.1843035
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3327283
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2774036
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0652803
[Epoch 4] ogbg-molhiv: 0.753990 val loss: 0.096780
[Epoch 4] ogbg-molhiv: 0.719597 test loss: 0.158231
[Epoch 5; Iter    22/ 1097] train: loss: 0.3543306
[Epoch 5; Iter    52/ 1097] train: loss: 0.1902555
[Epoch 5; Iter    82/ 1097] train: loss: 0.1518701
[Epoch 5; Iter   112/ 1097] train: loss: 0.1282580
[Epoch 5; Iter   142/ 1097] train: loss: 0.1151104
[Epoch 5; Iter   172/ 1097] train: loss: 0.0377094
[Epoch 5; Iter   202/ 1097] train: loss: 0.1532179
[Epoch 5; Iter   232/ 1097] train: loss: 0.0349163
[Epoch 5; Iter   262/ 1097] train: loss: 0.0404568
[Epoch 5; Iter   292/ 1097] train: loss: 0.1678064
[Epoch 5; Iter   322/ 1097] train: loss: 0.1850468
[Epoch 5; Iter   352/ 1097] train: loss: 0.0817816
[Epoch 5; Iter   382/ 1097] train: loss: 0.2398768
[Epoch 5; Iter   412/ 1097] train: loss: 0.2697317
[Epoch 5; Iter   442/ 1097] train: loss: 0.2669525
[Epoch 5; Iter   472/ 1097] train: loss: 0.1209638
[Epoch 5; Iter   502/ 1097] train: loss: 0.1758267
[Epoch 5; Iter   532/ 1097] train: loss: 0.0664032
[Epoch 5; Iter   562/ 1097] train: loss: 0.0517405
[Epoch 5; Iter   592/ 1097] train: loss: 0.0413426
[Epoch 5; Iter   622/ 1097] train: loss: 0.0864532
[Epoch 5; Iter   652/ 1097] train: loss: 0.1359800
[Epoch 5; Iter   682/ 1097] train: loss: 0.1678898
[Epoch 5; Iter   712/ 1097] train: loss: 0.0307311
[Epoch 5; Iter   742/ 1097] train: loss: 0.2268348
[Epoch 5; Iter   772/ 1097] train: loss: 0.1645261
[Epoch 5; Iter   802/ 1097] train: loss: 0.1691616
[Epoch 5; Iter   832/ 1097] train: loss: 0.0339293
[Epoch 5; Iter   862/ 1097] train: loss: 0.2139875
[Epoch 5; Iter   892/ 1097] train: loss: 0.0425704
[Epoch 5; Iter   922/ 1097] train: loss: 0.3357977
[Epoch 5; Iter   952/ 1097] train: loss: 0.0279749
[Epoch 5; Iter   982/ 1097] train: loss: 0.2865899
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2795708
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2278734
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0353793
[Epoch 5] ogbg-molhiv: 0.743163 val loss: 0.116566
[Epoch 5] ogbg-molhiv: 0.725707 test loss: 0.162633
[Epoch 6; Iter     5/ 1097] train: loss: 0.1067042
[Epoch 6; Iter    35/ 1097] train: loss: 0.1150774
[Epoch 6; Iter    65/ 1097] train: loss: 0.1427617
[Epoch 6; Iter    95/ 1097] train: loss: 0.0460998
[Epoch 6; Iter   125/ 1097] train: loss: 0.1662486
[Epoch 6; Iter   155/ 1097] train: loss: 0.0413585
[Epoch 6; Iter   185/ 1097] train: loss: 0.0509439
[Epoch 6; Iter   215/ 1097] train: loss: 0.3287601
[Epoch 6; Iter   245/ 1097] train: loss: 0.2282236
[Epoch 6; Iter   275/ 1097] train: loss: 0.0447381
[Epoch 6; Iter   305/ 1097] train: loss: 0.0466248
[Epoch 6; Iter   335/ 1097] train: loss: 0.1576947
[Epoch 6; Iter   365/ 1097] train: loss: 0.0478870
[Epoch 6; Iter   395/ 1097] train: loss: 0.2878500
[Epoch 6; Iter   425/ 1097] train: loss: 0.1652516
[Epoch 6; Iter   455/ 1097] train: loss: 0.1352457
[Epoch 6; Iter   485/ 1097] train: loss: 0.1996686
[Epoch 6; Iter   515/ 1097] train: loss: 0.0359894
[Epoch 6; Iter   545/ 1097] train: loss: 0.1591215
[Epoch 6; Iter   575/ 1097] train: loss: 0.0374386
[Epoch 6; Iter   605/ 1097] train: loss: 0.0349126
[Epoch 6; Iter   635/ 1097] train: loss: 0.0313619
[Epoch 6; Iter   665/ 1097] train: loss: 0.0382360
[Epoch 6; Iter   695/ 1097] train: loss: 0.1499741
[Epoch 6; Iter   725/ 1097] train: loss: 0.0371093
[Epoch 6; Iter   755/ 1097] train: loss: 0.1312083
[Epoch 6; Iter   785/ 1097] train: loss: 0.0304499
[Epoch 6; Iter   815/ 1097] train: loss: 0.2123941
[Epoch 6; Iter   845/ 1097] train: loss: 0.1269372
[Epoch 6; Iter   875/ 1097] train: loss: 0.2481838
[Epoch 6; Iter   905/ 1097] train: loss: 0.3694604
[Epoch 6; Iter   935/ 1097] train: loss: 0.2002990
[Epoch 6; Iter   965/ 1097] train: loss: 0.1245479
[Epoch 6; Iter   995/ 1097] train: loss: 0.0324037
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0310040
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0585217
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1861783
[Epoch 6] ogbg-molhiv: 0.739289 val loss: 0.103211
[Epoch 6] ogbg-molhiv: 0.699492 test loss: 0.129139
[Epoch 7; Iter    18/ 1097] train: loss: 0.0403870
[Epoch 7; Iter    48/ 1097] train: loss: 0.1265756
[Epoch 7; Iter    78/ 1097] train: loss: 0.1329373
[Epoch 7; Iter   108/ 1097] train: loss: 0.0400923
[Epoch 7; Iter   138/ 1097] train: loss: 0.0363791
[Epoch 7; Iter   168/ 1097] train: loss: 0.1073776
[Epoch 7; Iter   198/ 1097] train: loss: 0.1263593
[Epoch 7; Iter   228/ 1097] train: loss: 0.0287919
[Epoch 7; Iter   258/ 1097] train: loss: 0.1024796
[Epoch 7; Iter   288/ 1097] train: loss: 0.1386887
[Epoch 7; Iter   318/ 1097] train: loss: 0.0862699
[Epoch 7; Iter   348/ 1097] train: loss: 0.1921700
[Epoch 7; Iter   378/ 1097] train: loss: 0.1515741
[Epoch 7; Iter   408/ 1097] train: loss: 0.1651143
[Epoch 7; Iter   438/ 1097] train: loss: 0.1573017
[Epoch 7; Iter   468/ 1097] train: loss: 0.0308548
[Epoch 7; Iter   498/ 1097] train: loss: 0.0259998
[Epoch 7; Iter   528/ 1097] train: loss: 0.0348704
[Epoch 7; Iter   558/ 1097] train: loss: 0.0501844
[Epoch 7; Iter   588/ 1097] train: loss: 0.2564934
[Epoch 7; Iter   618/ 1097] train: loss: 0.3439760
[Epoch 7; Iter   648/ 1097] train: loss: 0.3482967
[Epoch 7; Iter   678/ 1097] train: loss: 0.0358492
[Epoch 7; Iter   708/ 1097] train: loss: 0.1964630
[Epoch 7; Iter   738/ 1097] train: loss: 0.1955894
[Epoch 7; Iter   768/ 1097] train: loss: 0.0441676
[Epoch 7; Iter   798/ 1097] train: loss: 0.1230751
[Epoch 7; Iter   828/ 1097] train: loss: 0.1249422
[Epoch 7; Iter   858/ 1097] train: loss: 0.0916706
[Epoch 7; Iter   888/ 1097] train: loss: 0.0282848
[Epoch 7; Iter   918/ 1097] train: loss: 0.0570065
[Epoch 7; Iter   948/ 1097] train: loss: 0.1210615
[Epoch 7; Iter   978/ 1097] train: loss: 0.0412669
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1628932
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0319876
[Epoch 7; Iter  1068/ 1097] train: loss: 0.2019384
[Epoch 7] ogbg-molhiv: 0.768497 val loss: 0.093664
[Epoch 7] ogbg-molhiv: 0.665832 test loss: 0.130961
[Epoch 8; Iter     1/ 1097] train: loss: 0.1968142
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0706460
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0929799
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0355043
[Epoch 3] ogbg-molhiv: 0.726270 val loss: 0.676774
[Epoch 3] ogbg-molhiv: 0.736318 test loss: 1.141396
[Epoch 4; Iter     9/ 1097] train: loss: 0.3802458
[Epoch 4; Iter    39/ 1097] train: loss: 0.0967399
[Epoch 4; Iter    69/ 1097] train: loss: 0.0828524
[Epoch 4; Iter    99/ 1097] train: loss: 0.0448750
[Epoch 4; Iter   129/ 1097] train: loss: 0.1706695
[Epoch 4; Iter   159/ 1097] train: loss: 0.4375890
[Epoch 4; Iter   189/ 1097] train: loss: 0.0311764
[Epoch 4; Iter   219/ 1097] train: loss: 0.3802428
[Epoch 4; Iter   249/ 1097] train: loss: 0.0541800
[Epoch 4; Iter   279/ 1097] train: loss: 0.1393875
[Epoch 4; Iter   309/ 1097] train: loss: 0.1502948
[Epoch 4; Iter   339/ 1097] train: loss: 0.1313882
[Epoch 4; Iter   369/ 1097] train: loss: 0.1123978
[Epoch 4; Iter   399/ 1097] train: loss: 0.1373348
[Epoch 4; Iter   429/ 1097] train: loss: 0.0674042
[Epoch 4; Iter   459/ 1097] train: loss: 0.0336068
[Epoch 4; Iter   489/ 1097] train: loss: 0.0292122
[Epoch 4; Iter   519/ 1097] train: loss: 0.0929376
[Epoch 4; Iter   549/ 1097] train: loss: 0.0353404
[Epoch 4; Iter   579/ 1097] train: loss: 0.0444356
[Epoch 4; Iter   609/ 1097] train: loss: 0.2851425
[Epoch 4; Iter   639/ 1097] train: loss: 0.0309069
[Epoch 4; Iter   669/ 1097] train: loss: 0.2861020
[Epoch 4; Iter   699/ 1097] train: loss: 0.0821896
[Epoch 4; Iter   729/ 1097] train: loss: 0.3616756
[Epoch 4; Iter   759/ 1097] train: loss: 0.0593007
[Epoch 4; Iter   789/ 1097] train: loss: 0.2868761
[Epoch 4; Iter   819/ 1097] train: loss: 0.0319020
[Epoch 4; Iter   849/ 1097] train: loss: 0.2033226
[Epoch 4; Iter   879/ 1097] train: loss: 0.1354885
[Epoch 4; Iter   909/ 1097] train: loss: 0.5073417
[Epoch 4; Iter   939/ 1097] train: loss: 0.0345146
[Epoch 4; Iter   969/ 1097] train: loss: 0.0368544
[Epoch 4; Iter   999/ 1097] train: loss: 0.2990444
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2841334
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1929221
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1013873
[Epoch 4] ogbg-molhiv: 0.690216 val loss: 0.427371
[Epoch 4] ogbg-molhiv: 0.731175 test loss: 0.338716
[Epoch 5; Iter    22/ 1097] train: loss: 0.0540919
[Epoch 5; Iter    52/ 1097] train: loss: 0.1181877
[Epoch 5; Iter    82/ 1097] train: loss: 0.3407979
[Epoch 5; Iter   112/ 1097] train: loss: 0.0418863
[Epoch 5; Iter   142/ 1097] train: loss: 0.3300349
[Epoch 5; Iter   172/ 1097] train: loss: 0.1865324
[Epoch 5; Iter   202/ 1097] train: loss: 0.0303037
[Epoch 5; Iter   232/ 1097] train: loss: 0.1135931
[Epoch 5; Iter   262/ 1097] train: loss: 0.1671564
[Epoch 5; Iter   292/ 1097] train: loss: 0.2608546
[Epoch 5; Iter   322/ 1097] train: loss: 0.1873739
[Epoch 5; Iter   352/ 1097] train: loss: 0.1826238
[Epoch 5; Iter   382/ 1097] train: loss: 0.2855094
[Epoch 5; Iter   412/ 1097] train: loss: 0.0355326
[Epoch 5; Iter   442/ 1097] train: loss: 0.1222382
[Epoch 5; Iter   472/ 1097] train: loss: 0.1444827
[Epoch 5; Iter   502/ 1097] train: loss: 0.1214547
[Epoch 5; Iter   532/ 1097] train: loss: 0.0434363
[Epoch 5; Iter   562/ 1097] train: loss: 0.2360956
[Epoch 5; Iter   592/ 1097] train: loss: 0.0709884
[Epoch 5; Iter   622/ 1097] train: loss: 0.1945289
[Epoch 5; Iter   652/ 1097] train: loss: 0.2308890
[Epoch 5; Iter   682/ 1097] train: loss: 0.0284269
[Epoch 5; Iter   712/ 1097] train: loss: 0.1851549
[Epoch 5; Iter   742/ 1097] train: loss: 0.0272318
[Epoch 5; Iter   772/ 1097] train: loss: 0.0335522
[Epoch 5; Iter   802/ 1097] train: loss: 0.2148388
[Epoch 5; Iter   832/ 1097] train: loss: 0.2772859
[Epoch 5; Iter   862/ 1097] train: loss: 0.0472807
[Epoch 5; Iter   892/ 1097] train: loss: 0.1249264
[Epoch 5; Iter   922/ 1097] train: loss: 0.1321852
[Epoch 5; Iter   952/ 1097] train: loss: 0.2372385
[Epoch 5; Iter   982/ 1097] train: loss: 0.1476419
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2762333
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2514702
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0407166
[Epoch 5] ogbg-molhiv: 0.724583 val loss: 0.971843
[Epoch 5] ogbg-molhiv: 0.729361 test loss: 0.376952
[Epoch 6; Iter     5/ 1097] train: loss: 0.2215709
[Epoch 6; Iter    35/ 1097] train: loss: 0.3582001
[Epoch 6; Iter    65/ 1097] train: loss: 0.0486664
[Epoch 6; Iter    95/ 1097] train: loss: 0.1489086
[Epoch 6; Iter   125/ 1097] train: loss: 0.3173650
[Epoch 6; Iter   155/ 1097] train: loss: 0.0795313
[Epoch 6; Iter   185/ 1097] train: loss: 0.1522401
[Epoch 6; Iter   215/ 1097] train: loss: 0.1206521
[Epoch 6; Iter   245/ 1097] train: loss: 0.0848297
[Epoch 6; Iter   275/ 1097] train: loss: 0.1320885
[Epoch 6; Iter   305/ 1097] train: loss: 0.0289883
[Epoch 6; Iter   335/ 1097] train: loss: 0.0399089
[Epoch 6; Iter   365/ 1097] train: loss: 0.0326210
[Epoch 6; Iter   395/ 1097] train: loss: 0.1525653
[Epoch 6; Iter   425/ 1097] train: loss: 0.0700493
[Epoch 6; Iter   455/ 1097] train: loss: 0.2486321
[Epoch 6; Iter   485/ 1097] train: loss: 0.0332946
[Epoch 6; Iter   515/ 1097] train: loss: 0.1219709
[Epoch 6; Iter   545/ 1097] train: loss: 0.1894381
[Epoch 6; Iter   575/ 1097] train: loss: 0.0520878
[Epoch 6; Iter   605/ 1097] train: loss: 0.0537237
[Epoch 6; Iter   635/ 1097] train: loss: 0.2197251
[Epoch 6; Iter   665/ 1097] train: loss: 0.2868825
[Epoch 6; Iter   695/ 1097] train: loss: 0.2934588
[Epoch 6; Iter   725/ 1097] train: loss: 0.2940042
[Epoch 6; Iter   755/ 1097] train: loss: 0.2558068
[Epoch 6; Iter   785/ 1097] train: loss: 0.3490578
[Epoch 6; Iter   815/ 1097] train: loss: 0.0743388
[Epoch 6; Iter   845/ 1097] train: loss: 0.0322379
[Epoch 6; Iter   875/ 1097] train: loss: 0.1079745
[Epoch 6; Iter   905/ 1097] train: loss: 0.2002407
[Epoch 6; Iter   935/ 1097] train: loss: 0.0883470
[Epoch 6; Iter   965/ 1097] train: loss: 0.1273779
[Epoch 6; Iter   995/ 1097] train: loss: 0.1341297
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1216702
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1619269
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2141197
[Epoch 6] ogbg-molhiv: 0.730396 val loss: 0.234480
[Epoch 6] ogbg-molhiv: 0.692149 test loss: 0.313097
[Epoch 7; Iter    18/ 1097] train: loss: 0.0602692
[Epoch 7; Iter    48/ 1097] train: loss: 0.0359993
[Epoch 7; Iter    78/ 1097] train: loss: 0.1850692
[Epoch 7; Iter   108/ 1097] train: loss: 0.2603408
[Epoch 7; Iter   138/ 1097] train: loss: 0.2111518
[Epoch 7; Iter   168/ 1097] train: loss: 0.0307808
[Epoch 7; Iter   198/ 1097] train: loss: 0.2135492
[Epoch 7; Iter   228/ 1097] train: loss: 0.1690045
[Epoch 7; Iter   258/ 1097] train: loss: 0.0240921
[Epoch 7; Iter   288/ 1097] train: loss: 0.0233478
[Epoch 7; Iter   318/ 1097] train: loss: 0.1627260
[Epoch 7; Iter   348/ 1097] train: loss: 0.0324750
[Epoch 7; Iter   378/ 1097] train: loss: 0.2153978
[Epoch 7; Iter   408/ 1097] train: loss: 0.2431458
[Epoch 7; Iter   438/ 1097] train: loss: 0.0786236
[Epoch 7; Iter   468/ 1097] train: loss: 0.0314215
[Epoch 7; Iter   498/ 1097] train: loss: 0.1491030
[Epoch 7; Iter   528/ 1097] train: loss: 0.1253467
[Epoch 7; Iter   558/ 1097] train: loss: 0.0379924
[Epoch 7; Iter   588/ 1097] train: loss: 0.2520582
[Epoch 7; Iter   618/ 1097] train: loss: 0.1401302
[Epoch 7; Iter   648/ 1097] train: loss: 0.1216191
[Epoch 7; Iter   678/ 1097] train: loss: 0.0264742
[Epoch 7; Iter   708/ 1097] train: loss: 0.1743793
[Epoch 7; Iter   738/ 1097] train: loss: 0.1813389
[Epoch 7; Iter   768/ 1097] train: loss: 0.1736252
[Epoch 7; Iter   798/ 1097] train: loss: 0.1441786
[Epoch 7; Iter   828/ 1097] train: loss: 0.0594117
[Epoch 7; Iter   858/ 1097] train: loss: 0.2118506
[Epoch 7; Iter   888/ 1097] train: loss: 0.0373469
[Epoch 7; Iter   918/ 1097] train: loss: 0.1378804
[Epoch 7; Iter   948/ 1097] train: loss: 0.0401093
[Epoch 7; Iter   978/ 1097] train: loss: 0.0509893
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0521589
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0304926
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1717250
[Epoch 7] ogbg-molhiv: 0.728548 val loss: 0.150569
[Epoch 7] ogbg-molhiv: 0.696528 test loss: 0.122275
[Epoch 8; Iter     1/ 1097] train: loss: 0.2446692
[Epoch 3; Iter  1016/ 1097] train: loss: 0.3549678
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0335746
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2022646
[Epoch 3] ogbg-molhiv: 0.685485 val loss: 0.291808
[Epoch 3] ogbg-molhiv: 0.688383 test loss: 0.188404
[Epoch 4; Iter     9/ 1097] train: loss: 0.0809094
[Epoch 4; Iter    39/ 1097] train: loss: 0.0348420
[Epoch 4; Iter    69/ 1097] train: loss: 0.0338322
[Epoch 4; Iter    99/ 1097] train: loss: 0.0280917
[Epoch 4; Iter   129/ 1097] train: loss: 0.2958378
[Epoch 4; Iter   159/ 1097] train: loss: 0.1385794
[Epoch 4; Iter   189/ 1097] train: loss: 0.0421166
[Epoch 4; Iter   219/ 1097] train: loss: 0.0346172
[Epoch 4; Iter   249/ 1097] train: loss: 0.1619731
[Epoch 4; Iter   279/ 1097] train: loss: 0.2433503
[Epoch 4; Iter   309/ 1097] train: loss: 0.1385145
[Epoch 4; Iter   339/ 1097] train: loss: 0.0405067
[Epoch 4; Iter   369/ 1097] train: loss: 0.0581675
[Epoch 4; Iter   399/ 1097] train: loss: 0.2500767
[Epoch 4; Iter   429/ 1097] train: loss: 0.0366334
[Epoch 4; Iter   459/ 1097] train: loss: 0.1193876
[Epoch 4; Iter   489/ 1097] train: loss: 0.0321329
[Epoch 4; Iter   519/ 1097] train: loss: 0.1594183
[Epoch 4; Iter   549/ 1097] train: loss: 0.0585593
[Epoch 4; Iter   579/ 1097] train: loss: 0.1016463
[Epoch 4; Iter   609/ 1097] train: loss: 0.1647305
[Epoch 4; Iter   639/ 1097] train: loss: 0.0870100
[Epoch 4; Iter   669/ 1097] train: loss: 0.2334751
[Epoch 4; Iter   699/ 1097] train: loss: 0.0833629
[Epoch 4; Iter   729/ 1097] train: loss: 0.0349138
[Epoch 4; Iter   759/ 1097] train: loss: 0.0300782
[Epoch 4; Iter   789/ 1097] train: loss: 0.0657238
[Epoch 4; Iter   819/ 1097] train: loss: 0.1288384
[Epoch 4; Iter   849/ 1097] train: loss: 0.0318924
[Epoch 4; Iter   879/ 1097] train: loss: 0.0356660
[Epoch 4; Iter   909/ 1097] train: loss: 0.0352553
[Epoch 4; Iter   939/ 1097] train: loss: 0.3189677
[Epoch 4; Iter   969/ 1097] train: loss: 0.1428413
[Epoch 4; Iter   999/ 1097] train: loss: 0.0407666
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2268975
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1290121
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1855763
[Epoch 4] ogbg-molhiv: 0.720667 val loss: 0.129344
[Epoch 4] ogbg-molhiv: 0.735010 test loss: 0.148144
[Epoch 5; Iter    22/ 1097] train: loss: 0.1300441
[Epoch 5; Iter    52/ 1097] train: loss: 0.1613098
[Epoch 5; Iter    82/ 1097] train: loss: 0.1713717
[Epoch 5; Iter   112/ 1097] train: loss: 0.4500065
[Epoch 5; Iter   142/ 1097] train: loss: 0.3722497
[Epoch 5; Iter   172/ 1097] train: loss: 0.0285027
[Epoch 5; Iter   202/ 1097] train: loss: 0.1731072
[Epoch 5; Iter   232/ 1097] train: loss: 0.1950255
[Epoch 5; Iter   262/ 1097] train: loss: 0.0418513
[Epoch 5; Iter   292/ 1097] train: loss: 0.1701748
[Epoch 5; Iter   322/ 1097] train: loss: 0.0303805
[Epoch 5; Iter   352/ 1097] train: loss: 0.1493773
[Epoch 5; Iter   382/ 1097] train: loss: 0.1517361
[Epoch 5; Iter   412/ 1097] train: loss: 0.3619424
[Epoch 5; Iter   442/ 1097] train: loss: 0.1390311
[Epoch 5; Iter   472/ 1097] train: loss: 0.1456957
[Epoch 5; Iter   502/ 1097] train: loss: 0.2219195
[Epoch 5; Iter   532/ 1097] train: loss: 0.2794406
[Epoch 5; Iter   562/ 1097] train: loss: 0.2297198
[Epoch 5; Iter   592/ 1097] train: loss: 0.0393987
[Epoch 5; Iter   622/ 1097] train: loss: 0.0297871
[Epoch 5; Iter   652/ 1097] train: loss: 0.0858766
[Epoch 5; Iter   682/ 1097] train: loss: 0.1735977
[Epoch 5; Iter   712/ 1097] train: loss: 0.0403647
[Epoch 5; Iter   742/ 1097] train: loss: 0.1025150
[Epoch 5; Iter   772/ 1097] train: loss: 0.2606976
[Epoch 5; Iter   802/ 1097] train: loss: 0.0820923
[Epoch 5; Iter   832/ 1097] train: loss: 0.0507275
[Epoch 5; Iter   862/ 1097] train: loss: 0.1015783
[Epoch 5; Iter   892/ 1097] train: loss: 0.0477028
[Epoch 5; Iter   922/ 1097] train: loss: 0.0357815
[Epoch 5; Iter   952/ 1097] train: loss: 0.0390756
[Epoch 5; Iter   982/ 1097] train: loss: 0.0727294
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0346747
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2628487
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0445407
[Epoch 5] ogbg-molhiv: 0.664790 val loss: 0.125003
[Epoch 5] ogbg-molhiv: 0.701833 test loss: 0.122270
[Epoch 6; Iter     5/ 1097] train: loss: 0.0984873
[Epoch 6; Iter    35/ 1097] train: loss: 0.2280117
[Epoch 6; Iter    65/ 1097] train: loss: 0.0330969
[Epoch 6; Iter    95/ 1097] train: loss: 0.0502247
[Epoch 6; Iter   125/ 1097] train: loss: 0.4877003
[Epoch 6; Iter   155/ 1097] train: loss: 0.3439665
[Epoch 6; Iter   185/ 1097] train: loss: 0.0364019
[Epoch 6; Iter   215/ 1097] train: loss: 0.1322608
[Epoch 6; Iter   245/ 1097] train: loss: 0.2939764
[Epoch 6; Iter   275/ 1097] train: loss: 0.0458944
[Epoch 6; Iter   305/ 1097] train: loss: 0.2196582
[Epoch 6; Iter   335/ 1097] train: loss: 0.0618291
[Epoch 6; Iter   365/ 1097] train: loss: 0.2634087
[Epoch 6; Iter   395/ 1097] train: loss: 0.3299219
[Epoch 6; Iter   425/ 1097] train: loss: 0.0409311
[Epoch 6; Iter   455/ 1097] train: loss: 0.3090989
[Epoch 6; Iter   485/ 1097] train: loss: 0.0394762
[Epoch 6; Iter   515/ 1097] train: loss: 0.1331777
[Epoch 6; Iter   545/ 1097] train: loss: 0.1720253
[Epoch 6; Iter   575/ 1097] train: loss: 0.1848044
[Epoch 6; Iter   605/ 1097] train: loss: 0.0384073
[Epoch 6; Iter   635/ 1097] train: loss: 0.0437722
[Epoch 6; Iter   665/ 1097] train: loss: 0.2494001
[Epoch 6; Iter   695/ 1097] train: loss: 0.1898317
[Epoch 6; Iter   725/ 1097] train: loss: 0.1955189
[Epoch 6; Iter   755/ 1097] train: loss: 0.0604850
[Epoch 6; Iter   785/ 1097] train: loss: 0.1295821
[Epoch 6; Iter   815/ 1097] train: loss: 0.0389374
[Epoch 6; Iter   845/ 1097] train: loss: 0.1520816
[Epoch 6; Iter   875/ 1097] train: loss: 0.2107359
[Epoch 6; Iter   905/ 1097] train: loss: 0.3158735
[Epoch 6; Iter   935/ 1097] train: loss: 0.0416177
[Epoch 6; Iter   965/ 1097] train: loss: 0.0276375
[Epoch 6; Iter   995/ 1097] train: loss: 0.1774583
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1816716
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0296421
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2321794
[Epoch 6] ogbg-molhiv: 0.753916 val loss: 0.108042
[Epoch 6] ogbg-molhiv: 0.747144 test loss: 0.118080
[Epoch 7; Iter    18/ 1097] train: loss: 0.1712027
[Epoch 7; Iter    48/ 1097] train: loss: 0.6922873
[Epoch 7; Iter    78/ 1097] train: loss: 0.4000672
[Epoch 7; Iter   108/ 1097] train: loss: 0.0512754
[Epoch 7; Iter   138/ 1097] train: loss: 0.0259790
[Epoch 7; Iter   168/ 1097] train: loss: 0.0763987
[Epoch 7; Iter   198/ 1097] train: loss: 0.1621103
[Epoch 7; Iter   228/ 1097] train: loss: 0.1638531
[Epoch 7; Iter   258/ 1097] train: loss: 0.0982065
[Epoch 7; Iter   288/ 1097] train: loss: 0.1634515
[Epoch 7; Iter   318/ 1097] train: loss: 0.0427785
[Epoch 7; Iter   348/ 1097] train: loss: 0.0440763
[Epoch 7; Iter   378/ 1097] train: loss: 0.0290036
[Epoch 7; Iter   408/ 1097] train: loss: 0.0374440
[Epoch 7; Iter   438/ 1097] train: loss: 0.0361474
[Epoch 7; Iter   468/ 1097] train: loss: 0.2530034
[Epoch 7; Iter   498/ 1097] train: loss: 0.0751476
[Epoch 7; Iter   528/ 1097] train: loss: 0.0339290
[Epoch 7; Iter   558/ 1097] train: loss: 0.2422346
[Epoch 7; Iter   588/ 1097] train: loss: 0.1768913
[Epoch 7; Iter   618/ 1097] train: loss: 0.2305093
[Epoch 7; Iter   648/ 1097] train: loss: 0.1409534
[Epoch 7; Iter   678/ 1097] train: loss: 0.1319481
[Epoch 7; Iter   708/ 1097] train: loss: 0.0802367
[Epoch 7; Iter   738/ 1097] train: loss: 0.0328686
[Epoch 7; Iter   768/ 1097] train: loss: 0.1419834
[Epoch 7; Iter   798/ 1097] train: loss: 0.2639261
[Epoch 7; Iter   828/ 1097] train: loss: 0.1565013
[Epoch 7; Iter   858/ 1097] train: loss: 0.2357762
[Epoch 7; Iter   888/ 1097] train: loss: 0.1121922
[Epoch 7; Iter   918/ 1097] train: loss: 0.1600600
[Epoch 7; Iter   948/ 1097] train: loss: 0.1855448
[Epoch 7; Iter   978/ 1097] train: loss: 0.1132814
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0283464
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2873753
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0726681
[Epoch 7] ogbg-molhiv: 0.719384 val loss: 0.518302
[Epoch 7] ogbg-molhiv: 0.712928 test loss: 0.324707
[Epoch 8; Iter     1/ 1097] train: loss: 0.1183183
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1215978
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0845135
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0341784
[Epoch 3] ogbg-molhiv: 0.749648 val loss: 0.329109
[Epoch 3] ogbg-molhiv: 0.756863 test loss: 0.685092
[Epoch 4; Iter     9/ 1097] train: loss: 0.3704923
[Epoch 4; Iter    39/ 1097] train: loss: 0.1169385
[Epoch 4; Iter    69/ 1097] train: loss: 0.1071030
[Epoch 4; Iter    99/ 1097] train: loss: 0.0398404
[Epoch 4; Iter   129/ 1097] train: loss: 0.1600574
[Epoch 4; Iter   159/ 1097] train: loss: 0.5161651
[Epoch 4; Iter   189/ 1097] train: loss: 0.0333082
[Epoch 4; Iter   219/ 1097] train: loss: 0.3362122
[Epoch 4; Iter   249/ 1097] train: loss: 0.0451826
[Epoch 4; Iter   279/ 1097] train: loss: 0.1144483
[Epoch 4; Iter   309/ 1097] train: loss: 0.1669279
[Epoch 4; Iter   339/ 1097] train: loss: 0.1164636
[Epoch 4; Iter   369/ 1097] train: loss: 0.1242175
[Epoch 4; Iter   399/ 1097] train: loss: 0.1439607
[Epoch 4; Iter   429/ 1097] train: loss: 0.0502798
[Epoch 4; Iter   459/ 1097] train: loss: 0.0377901
[Epoch 4; Iter   489/ 1097] train: loss: 0.0348406
[Epoch 4; Iter   519/ 1097] train: loss: 0.1099403
[Epoch 4; Iter   549/ 1097] train: loss: 0.0369901
[Epoch 4; Iter   579/ 1097] train: loss: 0.0419979
[Epoch 4; Iter   609/ 1097] train: loss: 0.2510096
[Epoch 4; Iter   639/ 1097] train: loss: 0.0319009
[Epoch 4; Iter   669/ 1097] train: loss: 0.2609192
[Epoch 4; Iter   699/ 1097] train: loss: 0.0863875
[Epoch 4; Iter   729/ 1097] train: loss: 0.3873048
[Epoch 4; Iter   759/ 1097] train: loss: 0.0657872
[Epoch 4; Iter   789/ 1097] train: loss: 0.3008941
[Epoch 4; Iter   819/ 1097] train: loss: 0.0351683
[Epoch 4; Iter   849/ 1097] train: loss: 0.2394013
[Epoch 4; Iter   879/ 1097] train: loss: 0.1028258
[Epoch 4; Iter   909/ 1097] train: loss: 0.6016178
[Epoch 4; Iter   939/ 1097] train: loss: 0.0375614
[Epoch 4; Iter   969/ 1097] train: loss: 0.0369785
[Epoch 4; Iter   999/ 1097] train: loss: 0.3411181
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2879259
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1988645
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1002414
[Epoch 4] ogbg-molhiv: 0.719782 val loss: 0.086525
[Epoch 4] ogbg-molhiv: 0.762025 test loss: 0.119748
[Epoch 5; Iter    22/ 1097] train: loss: 0.0419196
[Epoch 5; Iter    52/ 1097] train: loss: 0.1225128
[Epoch 5; Iter    82/ 1097] train: loss: 0.3554716
[Epoch 5; Iter   112/ 1097] train: loss: 0.0403656
[Epoch 5; Iter   142/ 1097] train: loss: 0.3410065
[Epoch 5; Iter   172/ 1097] train: loss: 0.2158271
[Epoch 5; Iter   202/ 1097] train: loss: 0.0312137
[Epoch 5; Iter   232/ 1097] train: loss: 0.1675805
[Epoch 5; Iter   262/ 1097] train: loss: 0.1543063
[Epoch 5; Iter   292/ 1097] train: loss: 0.2775000
[Epoch 5; Iter   322/ 1097] train: loss: 0.1577803
[Epoch 5; Iter   352/ 1097] train: loss: 0.1645054
[Epoch 5; Iter   382/ 1097] train: loss: 0.3602203
[Epoch 5; Iter   412/ 1097] train: loss: 0.0369021
[Epoch 5; Iter   442/ 1097] train: loss: 0.1484765
[Epoch 5; Iter   472/ 1097] train: loss: 0.1559760
[Epoch 5; Iter   502/ 1097] train: loss: 0.1511073
[Epoch 5; Iter   532/ 1097] train: loss: 0.0359367
[Epoch 5; Iter   562/ 1097] train: loss: 0.2934909
[Epoch 5; Iter   592/ 1097] train: loss: 0.0935496
[Epoch 5; Iter   622/ 1097] train: loss: 0.2261940
[Epoch 5; Iter   652/ 1097] train: loss: 0.2426669
[Epoch 5; Iter   682/ 1097] train: loss: 0.0253760
[Epoch 5; Iter   712/ 1097] train: loss: 0.1913797
[Epoch 5; Iter   742/ 1097] train: loss: 0.0332308
[Epoch 5; Iter   772/ 1097] train: loss: 0.0317731
[Epoch 5; Iter   802/ 1097] train: loss: 0.2429105
[Epoch 5; Iter   832/ 1097] train: loss: 0.3396975
[Epoch 5; Iter   862/ 1097] train: loss: 0.0925670
[Epoch 5; Iter   892/ 1097] train: loss: 0.1211378
[Epoch 5; Iter   922/ 1097] train: loss: 0.1222101
[Epoch 5; Iter   952/ 1097] train: loss: 0.2385723
[Epoch 5; Iter   982/ 1097] train: loss: 0.1359109
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2586737
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2365828
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0358530
[Epoch 5] ogbg-molhiv: 0.739479 val loss: 0.142003
[Epoch 5] ogbg-molhiv: 0.733879 test loss: 0.258530
[Epoch 6; Iter     5/ 1097] train: loss: 0.2276998
[Epoch 6; Iter    35/ 1097] train: loss: 0.3710873
[Epoch 6; Iter    65/ 1097] train: loss: 0.0433991
[Epoch 6; Iter    95/ 1097] train: loss: 0.1421586
[Epoch 6; Iter   125/ 1097] train: loss: 0.2467584
[Epoch 6; Iter   155/ 1097] train: loss: 0.0903146
[Epoch 6; Iter   185/ 1097] train: loss: 0.1623334
[Epoch 6; Iter   215/ 1097] train: loss: 0.1596600
[Epoch 6; Iter   245/ 1097] train: loss: 0.1523477
[Epoch 6; Iter   275/ 1097] train: loss: 0.1675187
[Epoch 6; Iter   305/ 1097] train: loss: 0.0379847
[Epoch 6; Iter   335/ 1097] train: loss: 0.0445128
[Epoch 6; Iter   365/ 1097] train: loss: 0.0318677
[Epoch 6; Iter   395/ 1097] train: loss: 0.1563570
[Epoch 6; Iter   425/ 1097] train: loss: 0.1956425
[Epoch 6; Iter   455/ 1097] train: loss: 0.2010191
[Epoch 6; Iter   485/ 1097] train: loss: 0.0404021
[Epoch 6; Iter   515/ 1097] train: loss: 0.1329623
[Epoch 6; Iter   545/ 1097] train: loss: 0.2033758
[Epoch 6; Iter   575/ 1097] train: loss: 0.0440798
[Epoch 6; Iter   605/ 1097] train: loss: 0.0548263
[Epoch 6; Iter   635/ 1097] train: loss: 0.2017246
[Epoch 6; Iter   665/ 1097] train: loss: 0.2422599
[Epoch 6; Iter   695/ 1097] train: loss: 0.2571995
[Epoch 6; Iter   725/ 1097] train: loss: 0.2654970
[Epoch 6; Iter   755/ 1097] train: loss: 0.2787165
[Epoch 6; Iter   785/ 1097] train: loss: 0.4065209
[Epoch 6; Iter   815/ 1097] train: loss: 0.0617713
[Epoch 6; Iter   845/ 1097] train: loss: 0.0435584
[Epoch 6; Iter   875/ 1097] train: loss: 0.1229936
[Epoch 6; Iter   905/ 1097] train: loss: 0.3369961
[Epoch 6; Iter   935/ 1097] train: loss: 0.1054758
[Epoch 6; Iter   965/ 1097] train: loss: 0.1338068
[Epoch 6; Iter   995/ 1097] train: loss: 0.1010821
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1498592
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1631358
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1953648
[Epoch 6] ogbg-molhiv: 0.742685 val loss: 0.271772
[Epoch 6] ogbg-molhiv: 0.726880 test loss: 1.227510
[Epoch 7; Iter    18/ 1097] train: loss: 0.0377495
[Epoch 7; Iter    48/ 1097] train: loss: 0.0297213
[Epoch 7; Iter    78/ 1097] train: loss: 0.2602980
[Epoch 7; Iter   108/ 1097] train: loss: 0.2490682
[Epoch 7; Iter   138/ 1097] train: loss: 0.2353573
[Epoch 7; Iter   168/ 1097] train: loss: 0.0366353
[Epoch 7; Iter   198/ 1097] train: loss: 0.2684024
[Epoch 7; Iter   228/ 1097] train: loss: 0.2106626
[Epoch 7; Iter   258/ 1097] train: loss: 0.0253031
[Epoch 7; Iter   288/ 1097] train: loss: 0.0256402
[Epoch 7; Iter   318/ 1097] train: loss: 0.1309732
[Epoch 7; Iter   348/ 1097] train: loss: 0.0308268
[Epoch 7; Iter   378/ 1097] train: loss: 0.2255987
[Epoch 7; Iter   408/ 1097] train: loss: 0.2441998
[Epoch 7; Iter   438/ 1097] train: loss: 0.0833599
[Epoch 7; Iter   468/ 1097] train: loss: 0.0425000
[Epoch 7; Iter   498/ 1097] train: loss: 0.1975913
[Epoch 7; Iter   528/ 1097] train: loss: 0.1326370
[Epoch 7; Iter   558/ 1097] train: loss: 0.0470871
[Epoch 7; Iter   588/ 1097] train: loss: 0.2555723
[Epoch 7; Iter   618/ 1097] train: loss: 0.1110085
[Epoch 7; Iter   648/ 1097] train: loss: 0.1343203
[Epoch 7; Iter   678/ 1097] train: loss: 0.0490680
[Epoch 7; Iter   708/ 1097] train: loss: 0.1760676
[Epoch 7; Iter   738/ 1097] train: loss: 0.1534934
[Epoch 7; Iter   768/ 1097] train: loss: 0.1688408
[Epoch 7; Iter   798/ 1097] train: loss: 0.1584095
[Epoch 7; Iter   828/ 1097] train: loss: 0.0853843
[Epoch 7; Iter   858/ 1097] train: loss: 0.1415394
[Epoch 7; Iter   888/ 1097] train: loss: 0.0312597
[Epoch 7; Iter   918/ 1097] train: loss: 0.1633636
[Epoch 7; Iter   948/ 1097] train: loss: 0.0567220
[Epoch 7; Iter   978/ 1097] train: loss: 0.0798383
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0568422
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0332084
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1807269
[Epoch 7] ogbg-molhiv: 0.792879 val loss: 0.652826
[Epoch 7] ogbg-molhiv: 0.728813 test loss: 1.334031
[Epoch 8; Iter     1/ 1097] train: loss: 0.2142533
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0439791
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1464210
[Epoch 3; Iter  1076/ 1097] train: loss: 0.2869386
[Epoch 3] ogbg-molhiv: 0.681110 val loss: 0.092537
[Epoch 3] ogbg-molhiv: 0.625788 test loss: 0.128001
[Epoch 4; Iter     9/ 1097] train: loss: 0.2317606
[Epoch 4; Iter    39/ 1097] train: loss: 0.1764073
[Epoch 4; Iter    69/ 1097] train: loss: 0.0412970
[Epoch 4; Iter    99/ 1097] train: loss: 0.2994697
[Epoch 4; Iter   129/ 1097] train: loss: 0.1505071
[Epoch 4; Iter   159/ 1097] train: loss: 0.0965076
[Epoch 4; Iter   189/ 1097] train: loss: 0.2983664
[Epoch 4; Iter   219/ 1097] train: loss: 0.1881028
[Epoch 4; Iter   249/ 1097] train: loss: 0.1528377
[Epoch 4; Iter   279/ 1097] train: loss: 0.1724476
[Epoch 4; Iter   309/ 1097] train: loss: 0.1709266
[Epoch 4; Iter   339/ 1097] train: loss: 0.0307010
[Epoch 4; Iter   369/ 1097] train: loss: 0.1566385
[Epoch 4; Iter   399/ 1097] train: loss: 0.1381708
[Epoch 4; Iter   429/ 1097] train: loss: 0.1745843
[Epoch 4; Iter   459/ 1097] train: loss: 0.0346047
[Epoch 4; Iter   489/ 1097] train: loss: 0.1419120
[Epoch 4; Iter   519/ 1097] train: loss: 0.3026582
[Epoch 4; Iter   549/ 1097] train: loss: 0.1747002
[Epoch 4; Iter   579/ 1097] train: loss: 0.0349005
[Epoch 4; Iter   609/ 1097] train: loss: 0.3433028
[Epoch 4; Iter   639/ 1097] train: loss: 0.2824764
[Epoch 4; Iter   669/ 1097] train: loss: 0.3017451
[Epoch 4; Iter   699/ 1097] train: loss: 0.0370829
[Epoch 4; Iter   729/ 1097] train: loss: 0.2665114
[Epoch 4; Iter   759/ 1097] train: loss: 0.1800012
[Epoch 4; Iter   789/ 1097] train: loss: 0.3663950
[Epoch 4; Iter   819/ 1097] train: loss: 0.1615825
[Epoch 4; Iter   849/ 1097] train: loss: 0.0421017
[Epoch 4; Iter   879/ 1097] train: loss: 0.0362037
[Epoch 4; Iter   909/ 1097] train: loss: 0.4221295
[Epoch 4; Iter   939/ 1097] train: loss: 0.1695259
[Epoch 4; Iter   969/ 1097] train: loss: 0.1097368
[Epoch 4; Iter   999/ 1097] train: loss: 0.1656245
[Epoch 4; Iter  1029/ 1097] train: loss: 0.3542726
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2527745
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0464531
[Epoch 4] ogbg-molhiv: 0.706254 val loss: 0.086969
[Epoch 4] ogbg-molhiv: 0.713428 test loss: 0.170370
[Epoch 5; Iter    22/ 1097] train: loss: 0.3668290
[Epoch 5; Iter    52/ 1097] train: loss: 0.1863077
[Epoch 5; Iter    82/ 1097] train: loss: 0.1386057
[Epoch 5; Iter   112/ 1097] train: loss: 0.1369940
[Epoch 5; Iter   142/ 1097] train: loss: 0.1073857
[Epoch 5; Iter   172/ 1097] train: loss: 0.0365242
[Epoch 5; Iter   202/ 1097] train: loss: 0.1465426
[Epoch 5; Iter   232/ 1097] train: loss: 0.0416179
[Epoch 5; Iter   262/ 1097] train: loss: 0.0543645
[Epoch 5; Iter   292/ 1097] train: loss: 0.1991235
[Epoch 5; Iter   322/ 1097] train: loss: 0.1991804
[Epoch 5; Iter   352/ 1097] train: loss: 0.0699437
[Epoch 5; Iter   382/ 1097] train: loss: 0.2260097
[Epoch 5; Iter   412/ 1097] train: loss: 0.2748862
[Epoch 5; Iter   442/ 1097] train: loss: 0.2206714
[Epoch 5; Iter   472/ 1097] train: loss: 0.1269267
[Epoch 5; Iter   502/ 1097] train: loss: 0.1625371
[Epoch 5; Iter   532/ 1097] train: loss: 0.0467270
[Epoch 5; Iter   562/ 1097] train: loss: 0.0396627
[Epoch 5; Iter   592/ 1097] train: loss: 0.0410929
[Epoch 5; Iter   622/ 1097] train: loss: 0.1183425
[Epoch 5; Iter   652/ 1097] train: loss: 0.1197965
[Epoch 5; Iter   682/ 1097] train: loss: 0.1827891
[Epoch 5; Iter   712/ 1097] train: loss: 0.0441970
[Epoch 5; Iter   742/ 1097] train: loss: 0.1792926
[Epoch 5; Iter   772/ 1097] train: loss: 0.1616872
[Epoch 5; Iter   802/ 1097] train: loss: 0.1859747
[Epoch 5; Iter   832/ 1097] train: loss: 0.0324001
[Epoch 5; Iter   862/ 1097] train: loss: 0.2030802
[Epoch 5; Iter   892/ 1097] train: loss: 0.0421029
[Epoch 5; Iter   922/ 1097] train: loss: 0.3449562
[Epoch 5; Iter   952/ 1097] train: loss: 0.0304870
[Epoch 5; Iter   982/ 1097] train: loss: 0.2567928
[Epoch 5; Iter  1012/ 1097] train: loss: 0.3054045
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2455429
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0396616
[Epoch 5] ogbg-molhiv: 0.707277 val loss: 0.100289
[Epoch 5] ogbg-molhiv: 0.713505 test loss: 0.127372
[Epoch 6; Iter     5/ 1097] train: loss: 0.0543084
[Epoch 6; Iter    35/ 1097] train: loss: 0.0989890
[Epoch 6; Iter    65/ 1097] train: loss: 0.0969895
[Epoch 6; Iter    95/ 1097] train: loss: 0.0400661
[Epoch 6; Iter   125/ 1097] train: loss: 0.1073057
[Epoch 6; Iter   155/ 1097] train: loss: 0.0293174
[Epoch 6; Iter   185/ 1097] train: loss: 0.0514093
[Epoch 6; Iter   215/ 1097] train: loss: 0.3479394
[Epoch 6; Iter   245/ 1097] train: loss: 0.2254122
[Epoch 6; Iter   275/ 1097] train: loss: 0.0355691
[Epoch 6; Iter   305/ 1097] train: loss: 0.0381294
[Epoch 6; Iter   335/ 1097] train: loss: 0.1637599
[Epoch 6; Iter   365/ 1097] train: loss: 0.0459532
[Epoch 6; Iter   395/ 1097] train: loss: 0.2885057
[Epoch 6; Iter   425/ 1097] train: loss: 0.1501841
[Epoch 6; Iter   455/ 1097] train: loss: 0.1438037
[Epoch 6; Iter   485/ 1097] train: loss: 0.2102506
[Epoch 6; Iter   515/ 1097] train: loss: 0.0371316
[Epoch 6; Iter   545/ 1097] train: loss: 0.1708070
[Epoch 6; Iter   575/ 1097] train: loss: 0.0399067
[Epoch 6; Iter   605/ 1097] train: loss: 0.0324492
[Epoch 6; Iter   635/ 1097] train: loss: 0.0292637
[Epoch 6; Iter   665/ 1097] train: loss: 0.0367628
[Epoch 6; Iter   695/ 1097] train: loss: 0.1502538
[Epoch 6; Iter   725/ 1097] train: loss: 0.0320201
[Epoch 6; Iter   755/ 1097] train: loss: 0.1510396
[Epoch 6; Iter   785/ 1097] train: loss: 0.0315282
[Epoch 6; Iter   815/ 1097] train: loss: 0.2052868
[Epoch 6; Iter   845/ 1097] train: loss: 0.1155642
[Epoch 6; Iter   875/ 1097] train: loss: 0.2294756
[Epoch 6; Iter   905/ 1097] train: loss: 0.3106244
[Epoch 6; Iter   935/ 1097] train: loss: 0.2233412
[Epoch 6; Iter   965/ 1097] train: loss: 0.1483670
[Epoch 6; Iter   995/ 1097] train: loss: 0.0306065
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0382375
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0771714
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2081121
[Epoch 6] ogbg-molhiv: 0.746757 val loss: 0.092622
[Epoch 6] ogbg-molhiv: 0.733094 test loss: 0.122310
[Epoch 7; Iter    18/ 1097] train: loss: 0.0362609
[Epoch 7; Iter    48/ 1097] train: loss: 0.0845441
[Epoch 7; Iter    78/ 1097] train: loss: 0.1363181
[Epoch 7; Iter   108/ 1097] train: loss: 0.0387110
[Epoch 7; Iter   138/ 1097] train: loss: 0.0357641
[Epoch 7; Iter   168/ 1097] train: loss: 0.1021155
[Epoch 7; Iter   198/ 1097] train: loss: 0.1041506
[Epoch 7; Iter   228/ 1097] train: loss: 0.0271679
[Epoch 7; Iter   258/ 1097] train: loss: 0.1081575
[Epoch 7; Iter   288/ 1097] train: loss: 0.0910942
[Epoch 7; Iter   318/ 1097] train: loss: 0.0984853
[Epoch 7; Iter   348/ 1097] train: loss: 0.1990619
[Epoch 7; Iter   378/ 1097] train: loss: 0.1566377
[Epoch 7; Iter   408/ 1097] train: loss: 0.1477223
[Epoch 7; Iter   438/ 1097] train: loss: 0.1367950
[Epoch 7; Iter   468/ 1097] train: loss: 0.0355168
[Epoch 7; Iter   498/ 1097] train: loss: 0.0290264
[Epoch 7; Iter   528/ 1097] train: loss: 0.0453168
[Epoch 7; Iter   558/ 1097] train: loss: 0.0457700
[Epoch 7; Iter   588/ 1097] train: loss: 0.2731561
[Epoch 7; Iter   618/ 1097] train: loss: 0.3444147
[Epoch 7; Iter   648/ 1097] train: loss: 0.3553541
[Epoch 7; Iter   678/ 1097] train: loss: 0.0424726
[Epoch 7; Iter   708/ 1097] train: loss: 0.1729249
[Epoch 7; Iter   738/ 1097] train: loss: 0.2101749
[Epoch 7; Iter   768/ 1097] train: loss: 0.0448797
[Epoch 7; Iter   798/ 1097] train: loss: 0.1481923
[Epoch 7; Iter   828/ 1097] train: loss: 0.1501653
[Epoch 7; Iter   858/ 1097] train: loss: 0.0899007
[Epoch 7; Iter   888/ 1097] train: loss: 0.0279033
[Epoch 7; Iter   918/ 1097] train: loss: 0.0614100
[Epoch 7; Iter   948/ 1097] train: loss: 0.1474052
[Epoch 7; Iter   978/ 1097] train: loss: 0.0398957
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1530861
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0440910
[Epoch 7; Iter  1068/ 1097] train: loss: 0.2294992
[Epoch 7] ogbg-molhiv: 0.753350 val loss: 2.285155
[Epoch 7] ogbg-molhiv: 0.733473 test loss: 1.824510
[Epoch 8; Iter     1/ 1097] train: loss: 0.1241785
[Epoch 8; Iter    31/ 1097] train: loss: 0.1849664
[Epoch 8; Iter    61/ 1097] train: loss: 0.2745106
[Epoch 8; Iter    91/ 1097] train: loss: 0.2495800
[Epoch 8; Iter   121/ 1097] train: loss: 0.0394065
[Epoch 8; Iter   151/ 1097] train: loss: 0.4235139
[Epoch 8; Iter   181/ 1097] train: loss: 0.2254484
[Epoch 8; Iter   211/ 1097] train: loss: 0.2265107
[Epoch 8; Iter   241/ 1097] train: loss: 0.0365202
[Epoch 8; Iter   271/ 1097] train: loss: 0.1285900
[Epoch 8; Iter   301/ 1097] train: loss: 0.0312653
[Epoch 8; Iter   331/ 1097] train: loss: 0.0925892
[Epoch 8; Iter   361/ 1097] train: loss: 0.1404026
[Epoch 8; Iter   391/ 1097] train: loss: 0.0703168
[Epoch 8; Iter   421/ 1097] train: loss: 0.2810739
[Epoch 8; Iter   451/ 1097] train: loss: 0.0310012
[Epoch 8; Iter   481/ 1097] train: loss: 0.1102023
[Epoch 8; Iter   511/ 1097] train: loss: 0.1371619
[Epoch 8; Iter   541/ 1097] train: loss: 0.0345830
[Epoch 8; Iter   571/ 1097] train: loss: 0.4324363
[Epoch 8; Iter   601/ 1097] train: loss: 0.1593647
[Epoch 8; Iter   631/ 1097] train: loss: 0.1029414
[Epoch 8; Iter   661/ 1097] train: loss: 0.0404794
[Epoch 8; Iter   691/ 1097] train: loss: 0.1859093
[Epoch 8; Iter   721/ 1097] train: loss: 0.0794261
[Epoch 8; Iter   751/ 1097] train: loss: 0.0274914
[Epoch 8; Iter   781/ 1097] train: loss: 0.2800406
[Epoch 8; Iter   811/ 1097] train: loss: 0.1089462
[Epoch 8; Iter   841/ 1097] train: loss: 0.0539757
[Epoch 8; Iter   871/ 1097] train: loss: 0.1497059
[Epoch 8; Iter   901/ 1097] train: loss: 0.0263762
[Epoch 8; Iter   931/ 1097] train: loss: 0.0598303
[Epoch 8; Iter   961/ 1097] train: loss: 0.0525968
[Epoch 8; Iter   991/ 1097] train: loss: 0.0307439
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0228598
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0233797
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1660057
[Epoch 8] ogbg-molhiv: 0.793590 val loss: 3.162737
[Epoch 8] ogbg-molhiv: 0.755074 test loss: 0.934756
[Epoch 9; Iter    14/ 1097] train: loss: 0.0247738
[Epoch 9; Iter    44/ 1097] train: loss: 0.0322677
[Epoch 9; Iter    74/ 1097] train: loss: 0.1934455
[Epoch 9; Iter   104/ 1097] train: loss: 0.3341891
[Epoch 9; Iter   134/ 1097] train: loss: 0.2498372
[Epoch 9; Iter   164/ 1097] train: loss: 0.0297502
[Epoch 9; Iter   194/ 1097] train: loss: 0.0555981
[Epoch 9; Iter   224/ 1097] train: loss: 0.0262301
[Epoch 9; Iter   254/ 1097] train: loss: 0.0914674
[Epoch 9; Iter   284/ 1097] train: loss: 0.0460087
[Epoch 9; Iter   314/ 1097] train: loss: 0.0355294
[Epoch 9; Iter   344/ 1097] train: loss: 0.0292979
[Epoch 9; Iter   374/ 1097] train: loss: 0.0351626
[Epoch 9; Iter   404/ 1097] train: loss: 0.1161657
[Epoch 9; Iter   434/ 1097] train: loss: 0.1660279
[Epoch 9; Iter   464/ 1097] train: loss: 0.2389243
[Epoch 9; Iter   494/ 1097] train: loss: 0.1139693
[Epoch 9; Iter   524/ 1097] train: loss: 0.0940626
[Epoch 9; Iter   554/ 1097] train: loss: 0.0368643
[Epoch 9; Iter   584/ 1097] train: loss: 0.2156929
[Epoch 9; Iter   614/ 1097] train: loss: 0.0293990
[Epoch 9; Iter   644/ 1097] train: loss: 0.2076954
[Epoch 9; Iter   674/ 1097] train: loss: 0.0826065
[Epoch 9; Iter   704/ 1097] train: loss: 0.0262673
[Epoch 9; Iter   734/ 1097] train: loss: 0.0845288
[Epoch 9; Iter   764/ 1097] train: loss: 0.0828623
[Epoch 9; Iter   794/ 1097] train: loss: 0.0520356
[Epoch 9; Iter   824/ 1097] train: loss: 0.0292601
[Epoch 9; Iter   854/ 1097] train: loss: 0.0435067
[Epoch 9; Iter   884/ 1097] train: loss: 0.1979960
[Epoch 9; Iter   914/ 1097] train: loss: 0.0255007
[Epoch 9; Iter   944/ 1097] train: loss: 0.1671213
[Epoch 9; Iter   974/ 1097] train: loss: 0.0477376
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1490422
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0892218
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0892090
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0569452
[Epoch 9] ogbg-molhiv: 0.766446 val loss: 2.664117
[Epoch 9] ogbg-molhiv: 0.715097 test loss: 0.464685
[Epoch 10; Iter    27/ 1097] train: loss: 0.1764853
[Epoch 10; Iter    57/ 1097] train: loss: 0.0261538
[Epoch 10; Iter    87/ 1097] train: loss: 0.1810342
[Epoch 10; Iter   117/ 1097] train: loss: 0.0573261
[Epoch 10; Iter   147/ 1097] train: loss: 0.0257723
[Epoch 10; Iter   177/ 1097] train: loss: 0.0234664
[Epoch 10; Iter   207/ 1097] train: loss: 0.0211430
[Epoch 10; Iter   237/ 1097] train: loss: 0.0275225
[Epoch 10; Iter   267/ 1097] train: loss: 0.0226429
[Epoch 10; Iter   297/ 1097] train: loss: 0.0421151
[Epoch 10; Iter   327/ 1097] train: loss: 0.0340120
[Epoch 10; Iter   357/ 1097] train: loss: 0.1071237
[Epoch 10; Iter   387/ 1097] train: loss: 0.1713525
[Epoch 10; Iter   417/ 1097] train: loss: 0.0371353
[Epoch 10; Iter   447/ 1097] train: loss: 0.0617899
[Epoch 10; Iter   477/ 1097] train: loss: 0.0537680
[Epoch 10; Iter   507/ 1097] train: loss: 0.0860073
[Epoch 10; Iter   537/ 1097] train: loss: 0.0273962
[Epoch 10; Iter   567/ 1097] train: loss: 0.1696550
[Epoch 10; Iter   597/ 1097] train: loss: 0.1854842
[Epoch 10; Iter   627/ 1097] train: loss: 0.1924032
[Epoch 10; Iter   657/ 1097] train: loss: 0.0251968
[Epoch 10; Iter   687/ 1097] train: loss: 0.2864646
[Epoch 10; Iter   717/ 1097] train: loss: 0.0685729
[Epoch 10; Iter   747/ 1097] train: loss: 0.3147415
[Epoch 10; Iter   777/ 1097] train: loss: 0.0658140
[Epoch 10; Iter   807/ 1097] train: loss: 0.1217563
[Epoch 10; Iter   837/ 1097] train: loss: 0.0544872
[Epoch 10; Iter   867/ 1097] train: loss: 0.4278553
[Epoch 10; Iter   897/ 1097] train: loss: 0.1789152
[Epoch 10; Iter   927/ 1097] train: loss: 0.3516261
[Epoch 10; Iter   957/ 1097] train: loss: 0.2538254
[Epoch 10; Iter   987/ 1097] train: loss: 0.1935524
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0715510
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1181678
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1575047
[Epoch 10] ogbg-molhiv: 0.812751 val loss: 0.075757
[Epoch 10] ogbg-molhiv: 0.762830 test loss: 0.118350
[Epoch 11; Iter    10/ 1097] train: loss: 0.0419544
[Epoch 11; Iter    40/ 1097] train: loss: 0.0544229
[Epoch 11; Iter    70/ 1097] train: loss: 0.0485531
[Epoch 11; Iter   100/ 1097] train: loss: 0.1528839
[Epoch 11; Iter   130/ 1097] train: loss: 0.0371217
[Epoch 11; Iter   160/ 1097] train: loss: 0.0510791
[Epoch 11; Iter   190/ 1097] train: loss: 0.1385590
[Epoch 11; Iter   220/ 1097] train: loss: 0.0708399
[Epoch 11; Iter   250/ 1097] train: loss: 0.1083435
[Epoch 11; Iter   280/ 1097] train: loss: 0.2147922
[Epoch 11; Iter   310/ 1097] train: loss: 0.1194062
[Epoch 11; Iter   340/ 1097] train: loss: 0.0824846
[Epoch 11; Iter   370/ 1097] train: loss: 0.3025983
[Epoch 11; Iter   400/ 1097] train: loss: 0.0740959
[Epoch 11; Iter   430/ 1097] train: loss: 0.1273252
[Epoch 11; Iter   460/ 1097] train: loss: 0.1478799
[Epoch 11; Iter   490/ 1097] train: loss: 0.1775188
[Epoch 11; Iter   520/ 1097] train: loss: 0.4532506
[Epoch 11; Iter   550/ 1097] train: loss: 0.1330828
[Epoch 11; Iter   580/ 1097] train: loss: 0.1776697
[Epoch 11; Iter   610/ 1097] train: loss: 0.0287806
[Epoch 11; Iter   640/ 1097] train: loss: 0.0505163
[Epoch 11; Iter   670/ 1097] train: loss: 0.0295542
[Epoch 11; Iter   700/ 1097] train: loss: 0.0293865
[Epoch 11; Iter   730/ 1097] train: loss: 0.1363504
[Epoch 11; Iter   760/ 1097] train: loss: 0.0613609
[Epoch 11; Iter   790/ 1097] train: loss: 0.0329289
[Epoch 11; Iter   820/ 1097] train: loss: 0.3066422
[Epoch 11; Iter   850/ 1097] train: loss: 0.2403300
[Epoch 11; Iter   880/ 1097] train: loss: 0.0257838
[Epoch 11; Iter   910/ 1097] train: loss: 0.2181667
[Epoch 11; Iter   940/ 1097] train: loss: 0.2615197
[Epoch 11; Iter   970/ 1097] train: loss: 0.1111398
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0971450
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0704630
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2256851
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3564499
[Epoch 11] ogbg-molhiv: 0.773926 val loss: 0.206455
[Epoch 11] ogbg-molhiv: 0.719703 test loss: 0.186477
[Epoch 12; Iter    23/ 1097] train: loss: 0.1364965
[Epoch 12; Iter    53/ 1097] train: loss: 0.0537320
[Epoch 12; Iter    83/ 1097] train: loss: 0.0470628
[Epoch 12; Iter   113/ 1097] train: loss: 0.0358833
[Epoch 8; Iter    31/ 1097] train: loss: 0.0349498
[Epoch 8; Iter    61/ 1097] train: loss: 0.1568077
[Epoch 8; Iter    91/ 1097] train: loss: 0.1636580
[Epoch 8; Iter   121/ 1097] train: loss: 0.0412644
[Epoch 8; Iter   151/ 1097] train: loss: 0.1342066
[Epoch 8; Iter   181/ 1097] train: loss: 0.0284645
[Epoch 8; Iter   211/ 1097] train: loss: 0.3297805
[Epoch 8; Iter   241/ 1097] train: loss: 0.0871775
[Epoch 8; Iter   271/ 1097] train: loss: 0.2362154
[Epoch 8; Iter   301/ 1097] train: loss: 0.0464942
[Epoch 8; Iter   331/ 1097] train: loss: 0.1159132
[Epoch 8; Iter   361/ 1097] train: loss: 0.0434436
[Epoch 8; Iter   391/ 1097] train: loss: 0.0393097
[Epoch 8; Iter   421/ 1097] train: loss: 0.2240185
[Epoch 8; Iter   451/ 1097] train: loss: 0.0314632
[Epoch 8; Iter   481/ 1097] train: loss: 0.1243376
[Epoch 8; Iter   511/ 1097] train: loss: 0.1537798
[Epoch 8; Iter   541/ 1097] train: loss: 0.0317219
[Epoch 8; Iter   571/ 1097] train: loss: 0.0304441
[Epoch 8; Iter   601/ 1097] train: loss: 0.0664497
[Epoch 8; Iter   631/ 1097] train: loss: 0.0818668
[Epoch 8; Iter   661/ 1097] train: loss: 0.0396093
[Epoch 8; Iter   691/ 1097] train: loss: 0.2958106
[Epoch 8; Iter   721/ 1097] train: loss: 0.0552568
[Epoch 8; Iter   751/ 1097] train: loss: 0.0700534
[Epoch 8; Iter   781/ 1097] train: loss: 0.0564918
[Epoch 8; Iter   811/ 1097] train: loss: 0.0730096
[Epoch 8; Iter   841/ 1097] train: loss: 0.2143699
[Epoch 8; Iter   871/ 1097] train: loss: 0.2730626
[Epoch 8; Iter   901/ 1097] train: loss: 0.0315620
[Epoch 8; Iter   931/ 1097] train: loss: 0.1557425
[Epoch 8; Iter   961/ 1097] train: loss: 0.0280610
[Epoch 8; Iter   991/ 1097] train: loss: 0.0418078
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0389618
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0335048
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3323888
[Epoch 8] ogbg-molhiv: 0.773742 val loss: 0.081520
[Epoch 8] ogbg-molhiv: 0.683482 test loss: 0.128275
[Epoch 9; Iter    14/ 1097] train: loss: 0.0381207
[Epoch 9; Iter    44/ 1097] train: loss: 0.0638344
[Epoch 9; Iter    74/ 1097] train: loss: 0.0311985
[Epoch 9; Iter   104/ 1097] train: loss: 0.0622169
[Epoch 9; Iter   134/ 1097] train: loss: 0.0483983
[Epoch 9; Iter   164/ 1097] train: loss: 0.0288618
[Epoch 9; Iter   194/ 1097] train: loss: 0.0331975
[Epoch 9; Iter   224/ 1097] train: loss: 0.3166423
[Epoch 9; Iter   254/ 1097] train: loss: 0.1017028
[Epoch 9; Iter   284/ 1097] train: loss: 0.1727972
[Epoch 9; Iter   314/ 1097] train: loss: 0.2367662
[Epoch 9; Iter   344/ 1097] train: loss: 0.0256158
[Epoch 9; Iter   374/ 1097] train: loss: 0.1950345
[Epoch 9; Iter   404/ 1097] train: loss: 0.1621456
[Epoch 9; Iter   434/ 1097] train: loss: 0.1558929
[Epoch 9; Iter   464/ 1097] train: loss: 0.0295610
[Epoch 9; Iter   494/ 1097] train: loss: 0.0444648
[Epoch 9; Iter   524/ 1097] train: loss: 0.0275365
[Epoch 9; Iter   554/ 1097] train: loss: 0.0681663
[Epoch 9; Iter   584/ 1097] train: loss: 0.2020202
[Epoch 9; Iter   614/ 1097] train: loss: 0.0481713
[Epoch 9; Iter   644/ 1097] train: loss: 0.1418382
[Epoch 9; Iter   674/ 1097] train: loss: 0.1928413
[Epoch 9; Iter   704/ 1097] train: loss: 0.0240550
[Epoch 9; Iter   734/ 1097] train: loss: 0.0337822
[Epoch 9; Iter   764/ 1097] train: loss: 0.0795303
[Epoch 9; Iter   794/ 1097] train: loss: 0.0497777
[Epoch 9; Iter   824/ 1097] train: loss: 0.0243297
[Epoch 9; Iter   854/ 1097] train: loss: 0.0252355
[Epoch 9; Iter   884/ 1097] train: loss: 0.3112125
[Epoch 9; Iter   914/ 1097] train: loss: 0.0773889
[Epoch 9; Iter   944/ 1097] train: loss: 0.1173320
[Epoch 9; Iter   974/ 1097] train: loss: 0.0257526
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0218025
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0306263
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2026976
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0367845
[Epoch 9] ogbg-molhiv: 0.791762 val loss: 0.130151
[Epoch 9] ogbg-molhiv: 0.733317 test loss: 0.189165
[Epoch 10; Iter    27/ 1097] train: loss: 0.1902384
[Epoch 10; Iter    57/ 1097] train: loss: 0.2712750
[Epoch 10; Iter    87/ 1097] train: loss: 0.0365746
[Epoch 10; Iter   117/ 1097] train: loss: 0.1708677
[Epoch 10; Iter   147/ 1097] train: loss: 0.0341270
[Epoch 10; Iter   177/ 1097] train: loss: 0.4665691
[Epoch 10; Iter   207/ 1097] train: loss: 0.1009249
[Epoch 10; Iter   237/ 1097] train: loss: 0.0392118
[Epoch 10; Iter   267/ 1097] train: loss: 0.0672142
[Epoch 10; Iter   297/ 1097] train: loss: 0.2829100
[Epoch 10; Iter   327/ 1097] train: loss: 0.2392131
[Epoch 10; Iter   357/ 1097] train: loss: 0.0421449
[Epoch 10; Iter   387/ 1097] train: loss: 0.0826768
[Epoch 10; Iter   417/ 1097] train: loss: 0.2397095
[Epoch 10; Iter   447/ 1097] train: loss: 0.1757339
[Epoch 10; Iter   477/ 1097] train: loss: 0.0274179
[Epoch 10; Iter   507/ 1097] train: loss: 0.0351756
[Epoch 10; Iter   537/ 1097] train: loss: 0.1767730
[Epoch 10; Iter   567/ 1097] train: loss: 0.2387819
[Epoch 10; Iter   597/ 1097] train: loss: 0.1612414
[Epoch 10; Iter   627/ 1097] train: loss: 0.0430387
[Epoch 10; Iter   657/ 1097] train: loss: 0.2418785
[Epoch 10; Iter   687/ 1097] train: loss: 0.1524834
[Epoch 10; Iter   717/ 1097] train: loss: 0.3186882
[Epoch 10; Iter   747/ 1097] train: loss: 0.0387576
[Epoch 10; Iter   777/ 1097] train: loss: 0.0192426
[Epoch 10; Iter   807/ 1097] train: loss: 0.3435748
[Epoch 10; Iter   837/ 1097] train: loss: 0.0352121
[Epoch 10; Iter   867/ 1097] train: loss: 0.0269395
[Epoch 10; Iter   897/ 1097] train: loss: 0.0348577
[Epoch 10; Iter   927/ 1097] train: loss: 0.2367079
[Epoch 10; Iter   957/ 1097] train: loss: 0.1392842
[Epoch 10; Iter   987/ 1097] train: loss: 0.5238495
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0259719
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0429022
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2095357
[Epoch 10] ogbg-molhiv: 0.788149 val loss: 0.619461
[Epoch 10] ogbg-molhiv: 0.727874 test loss: 0.472215
[Epoch 11; Iter    10/ 1097] train: loss: 0.2682755
[Epoch 11; Iter    40/ 1097] train: loss: 0.1769015
[Epoch 11; Iter    70/ 1097] train: loss: 0.0922564
[Epoch 11; Iter   100/ 1097] train: loss: 0.0901130
[Epoch 11; Iter   130/ 1097] train: loss: 0.4459998
[Epoch 11; Iter   160/ 1097] train: loss: 0.2781364
[Epoch 11; Iter   190/ 1097] train: loss: 0.0257619
[Epoch 11; Iter   220/ 1097] train: loss: 0.2198393
[Epoch 11; Iter   250/ 1097] train: loss: 0.0378969
[Epoch 11; Iter   280/ 1097] train: loss: 0.1696642
[Epoch 11; Iter   310/ 1097] train: loss: 0.2163035
[Epoch 11; Iter   340/ 1097] train: loss: 0.0492139
[Epoch 11; Iter   370/ 1097] train: loss: 0.0247934
[Epoch 11; Iter   400/ 1097] train: loss: 0.2129883
[Epoch 11; Iter   430/ 1097] train: loss: 0.0391754
[Epoch 11; Iter   460/ 1097] train: loss: 0.1022919
[Epoch 11; Iter   490/ 1097] train: loss: 0.2327241
[Epoch 11; Iter   520/ 1097] train: loss: 0.1801633
[Epoch 11; Iter   550/ 1097] train: loss: 0.0246531
[Epoch 11; Iter   580/ 1097] train: loss: 0.4444907
[Epoch 11; Iter   610/ 1097] train: loss: 0.0258687
[Epoch 11; Iter   640/ 1097] train: loss: 0.0618977
[Epoch 11; Iter   670/ 1097] train: loss: 0.0258082
[Epoch 11; Iter   700/ 1097] train: loss: 0.2184355
[Epoch 11; Iter   730/ 1097] train: loss: 0.1354420
[Epoch 11; Iter   760/ 1097] train: loss: 0.1679691
[Epoch 11; Iter   790/ 1097] train: loss: 0.0730225
[Epoch 11; Iter   820/ 1097] train: loss: 0.0510183
[Epoch 11; Iter   850/ 1097] train: loss: 0.1959767
[Epoch 11; Iter   880/ 1097] train: loss: 0.0205728
[Epoch 11; Iter   910/ 1097] train: loss: 0.0332919
[Epoch 11; Iter   940/ 1097] train: loss: 0.1944764
[Epoch 11; Iter   970/ 1097] train: loss: 0.0310383
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0633238
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1700469
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2160042
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0392326
[Epoch 11] ogbg-molhiv: 0.752324 val loss: 0.285532
[Epoch 11] ogbg-molhiv: 0.712492 test loss: 0.894340
[Epoch 12; Iter    23/ 1097] train: loss: 0.1820326
[Epoch 12; Iter    53/ 1097] train: loss: 0.0285995
[Epoch 12; Iter    83/ 1097] train: loss: 0.0586919
[Epoch 12; Iter   113/ 1097] train: loss: 0.1226663
[Epoch 8; Iter    31/ 1097] train: loss: 0.0599076
[Epoch 8; Iter    61/ 1097] train: loss: 0.0966962
[Epoch 8; Iter    91/ 1097] train: loss: 0.1098513
[Epoch 8; Iter   121/ 1097] train: loss: 0.1375435
[Epoch 8; Iter   151/ 1097] train: loss: 0.0291417
[Epoch 8; Iter   181/ 1097] train: loss: 0.0445882
[Epoch 8; Iter   211/ 1097] train: loss: 0.0593198
[Epoch 8; Iter   241/ 1097] train: loss: 0.0294310
[Epoch 8; Iter   271/ 1097] train: loss: 0.2055052
[Epoch 8; Iter   301/ 1097] train: loss: 0.2444881
[Epoch 8; Iter   331/ 1097] train: loss: 0.1150358
[Epoch 8; Iter   361/ 1097] train: loss: 0.1629579
[Epoch 8; Iter   391/ 1097] train: loss: 0.0261022
[Epoch 8; Iter   421/ 1097] train: loss: 0.2426210
[Epoch 8; Iter   451/ 1097] train: loss: 0.1979771
[Epoch 8; Iter   481/ 1097] train: loss: 0.0520439
[Epoch 8; Iter   511/ 1097] train: loss: 0.0851333
[Epoch 8; Iter   541/ 1097] train: loss: 0.1162724
[Epoch 8; Iter   571/ 1097] train: loss: 0.1146281
[Epoch 8; Iter   601/ 1097] train: loss: 0.3721529
[Epoch 8; Iter   631/ 1097] train: loss: 0.0344837
[Epoch 8; Iter   661/ 1097] train: loss: 0.2158298
[Epoch 8; Iter   691/ 1097] train: loss: 0.1623399
[Epoch 8; Iter   721/ 1097] train: loss: 0.0840657
[Epoch 8; Iter   751/ 1097] train: loss: 0.1036979
[Epoch 8; Iter   781/ 1097] train: loss: 0.1404667
[Epoch 8; Iter   811/ 1097] train: loss: 0.2420972
[Epoch 8; Iter   841/ 1097] train: loss: 0.3912809
[Epoch 8; Iter   871/ 1097] train: loss: 0.1770728
[Epoch 8; Iter   901/ 1097] train: loss: 0.0328443
[Epoch 8; Iter   931/ 1097] train: loss: 0.2129827
[Epoch 8; Iter   961/ 1097] train: loss: 0.0361061
[Epoch 8; Iter   991/ 1097] train: loss: 0.1269547
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3066300
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0443231
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0784969
[Epoch 8] ogbg-molhiv: 0.693930 val loss: 0.093885
[Epoch 8] ogbg-molhiv: 0.716144 test loss: 0.124779
[Epoch 9; Iter    14/ 1097] train: loss: 0.3275427
[Epoch 9; Iter    44/ 1097] train: loss: 0.0313219
[Epoch 9; Iter    74/ 1097] train: loss: 0.0248646
[Epoch 9; Iter   104/ 1097] train: loss: 0.2965274
[Epoch 9; Iter   134/ 1097] train: loss: 0.1163239
[Epoch 9; Iter   164/ 1097] train: loss: 0.1368932
[Epoch 9; Iter   194/ 1097] train: loss: 0.1189302
[Epoch 9; Iter   224/ 1097] train: loss: 0.0328555
[Epoch 9; Iter   254/ 1097] train: loss: 0.3435838
[Epoch 9; Iter   284/ 1097] train: loss: 0.2038841
[Epoch 9; Iter   314/ 1097] train: loss: 0.1153277
[Epoch 9; Iter   344/ 1097] train: loss: 0.4656974
[Epoch 9; Iter   374/ 1097] train: loss: 0.1868710
[Epoch 9; Iter   404/ 1097] train: loss: 0.1643157
[Epoch 9; Iter   434/ 1097] train: loss: 0.0767455
[Epoch 9; Iter   464/ 1097] train: loss: 0.0344466
[Epoch 9; Iter   494/ 1097] train: loss: 0.1671245
[Epoch 9; Iter   524/ 1097] train: loss: 0.0281032
[Epoch 9; Iter   554/ 1097] train: loss: 0.0282622
[Epoch 9; Iter   584/ 1097] train: loss: 0.4540988
[Epoch 9; Iter   614/ 1097] train: loss: 0.1027040
[Epoch 9; Iter   644/ 1097] train: loss: 0.2089064
[Epoch 9; Iter   674/ 1097] train: loss: 0.4820710
[Epoch 9; Iter   704/ 1097] train: loss: 0.1423739
[Epoch 9; Iter   734/ 1097] train: loss: 0.0825968
[Epoch 9; Iter   764/ 1097] train: loss: 0.2397166
[Epoch 9; Iter   794/ 1097] train: loss: 0.1860092
[Epoch 9; Iter   824/ 1097] train: loss: 0.0300120
[Epoch 9; Iter   854/ 1097] train: loss: 0.0380897
[Epoch 9; Iter   884/ 1097] train: loss: 0.0789115
[Epoch 9; Iter   914/ 1097] train: loss: 0.1786043
[Epoch 9; Iter   944/ 1097] train: loss: 0.0644331
[Epoch 9; Iter   974/ 1097] train: loss: 0.0959458
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1949442
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2551372
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2721350
[Epoch 9; Iter  1094/ 1097] train: loss: 0.1974197
[Epoch 9] ogbg-molhiv: 0.711444 val loss: 0.095127
[Epoch 9] ogbg-molhiv: 0.725659 test loss: 0.130139
[Epoch 10; Iter    27/ 1097] train: loss: 0.0271361
[Epoch 10; Iter    57/ 1097] train: loss: 0.0253738
[Epoch 10; Iter    87/ 1097] train: loss: 0.1713828
[Epoch 10; Iter   117/ 1097] train: loss: 0.0363052
[Epoch 10; Iter   147/ 1097] train: loss: 0.3960069
[Epoch 10; Iter   177/ 1097] train: loss: 0.1654475
[Epoch 10; Iter   207/ 1097] train: loss: 0.1150520
[Epoch 10; Iter   237/ 1097] train: loss: 0.0415812
[Epoch 10; Iter   267/ 1097] train: loss: 0.0304475
[Epoch 10; Iter   297/ 1097] train: loss: 0.1617922
[Epoch 10; Iter   327/ 1097] train: loss: 0.0268790
[Epoch 10; Iter   357/ 1097] train: loss: 0.1857859
[Epoch 10; Iter   387/ 1097] train: loss: 0.1017671
[Epoch 10; Iter   417/ 1097] train: loss: 0.1205060
[Epoch 10; Iter   447/ 1097] train: loss: 0.2033481
[Epoch 10; Iter   477/ 1097] train: loss: 0.1831334
[Epoch 10; Iter   507/ 1097] train: loss: 0.1128738
[Epoch 10; Iter   537/ 1097] train: loss: 0.0278244
[Epoch 10; Iter   567/ 1097] train: loss: 0.0241217
[Epoch 10; Iter   597/ 1097] train: loss: 0.0331726
[Epoch 10; Iter   627/ 1097] train: loss: 0.2313109
[Epoch 10; Iter   657/ 1097] train: loss: 0.1694254
[Epoch 10; Iter   687/ 1097] train: loss: 0.0650557
[Epoch 10; Iter   717/ 1097] train: loss: 0.1606689
[Epoch 10; Iter   747/ 1097] train: loss: 0.1792089
[Epoch 10; Iter   777/ 1097] train: loss: 0.2086928
[Epoch 10; Iter   807/ 1097] train: loss: 0.0353555
[Epoch 10; Iter   837/ 1097] train: loss: 0.0275929
[Epoch 10; Iter   867/ 1097] train: loss: 0.0468639
[Epoch 10; Iter   897/ 1097] train: loss: 0.0340713
[Epoch 10; Iter   927/ 1097] train: loss: 0.1451191
[Epoch 10; Iter   957/ 1097] train: loss: 0.0374255
[Epoch 10; Iter   987/ 1097] train: loss: 0.2590704
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2184092
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1619427
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0309255
[Epoch 10] ogbg-molhiv: 0.768457 val loss: 0.140511
[Epoch 10] ogbg-molhiv: 0.744528 test loss: 0.122572
[Epoch 11; Iter    10/ 1097] train: loss: 0.3300678
[Epoch 11; Iter    40/ 1097] train: loss: 0.0388983
[Epoch 11; Iter    70/ 1097] train: loss: 0.1309024
[Epoch 11; Iter   100/ 1097] train: loss: 0.0330652
[Epoch 11; Iter   130/ 1097] train: loss: 0.1625618
[Epoch 11; Iter   160/ 1097] train: loss: 0.0439794
[Epoch 11; Iter   190/ 1097] train: loss: 0.2914239
[Epoch 11; Iter   220/ 1097] train: loss: 0.3522641
[Epoch 11; Iter   250/ 1097] train: loss: 0.1391265
[Epoch 11; Iter   280/ 1097] train: loss: 0.0472808
[Epoch 11; Iter   310/ 1097] train: loss: 0.2246071
[Epoch 11; Iter   340/ 1097] train: loss: 0.0289193
[Epoch 11; Iter   370/ 1097] train: loss: 0.0830326
[Epoch 11; Iter   400/ 1097] train: loss: 0.0456273
[Epoch 11; Iter   430/ 1097] train: loss: 0.2009348
[Epoch 11; Iter   460/ 1097] train: loss: 0.1584232
[Epoch 11; Iter   490/ 1097] train: loss: 0.3154585
[Epoch 11; Iter   520/ 1097] train: loss: 0.1944210
[Epoch 11; Iter   550/ 1097] train: loss: 0.0282850
[Epoch 11; Iter   580/ 1097] train: loss: 0.0490150
[Epoch 11; Iter   610/ 1097] train: loss: 0.0345114
[Epoch 11; Iter   640/ 1097] train: loss: 0.0350717
[Epoch 11; Iter   670/ 1097] train: loss: 0.1636734
[Epoch 11; Iter   700/ 1097] train: loss: 0.1698369
[Epoch 11; Iter   730/ 1097] train: loss: 0.0389054
[Epoch 11; Iter   760/ 1097] train: loss: 0.2296191
[Epoch 11; Iter   790/ 1097] train: loss: 0.1814034
[Epoch 11; Iter   820/ 1097] train: loss: 0.0865659
[Epoch 11; Iter   850/ 1097] train: loss: 0.0664298
[Epoch 11; Iter   880/ 1097] train: loss: 0.2417788
[Epoch 11; Iter   910/ 1097] train: loss: 0.3041646
[Epoch 11; Iter   940/ 1097] train: loss: 0.2414756
[Epoch 11; Iter   970/ 1097] train: loss: 0.2530579
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0462053
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0218793
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1334825
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4952837
[Epoch 11] ogbg-molhiv: 0.764140 val loss: 0.179887
[Epoch 11] ogbg-molhiv: 0.762827 test loss: 0.495461
[Epoch 12; Iter    23/ 1097] train: loss: 0.2384703
[Epoch 12; Iter    53/ 1097] train: loss: 0.0321562
[Epoch 12; Iter    83/ 1097] train: loss: 0.0387156
[Epoch 12; Iter   113/ 1097] train: loss: 0.0580219
[Epoch 8; Iter     1/ 1097] train: loss: 0.1519739
[Epoch 8; Iter    31/ 1097] train: loss: 0.0382320
[Epoch 8; Iter    61/ 1097] train: loss: 0.1613853
[Epoch 8; Iter    91/ 1097] train: loss: 0.2121255
[Epoch 8; Iter   121/ 1097] train: loss: 0.0635078
[Epoch 8; Iter   151/ 1097] train: loss: 0.1341435
[Epoch 8; Iter   181/ 1097] train: loss: 0.0345750
[Epoch 8; Iter   211/ 1097] train: loss: 0.3200028
[Epoch 8; Iter   241/ 1097] train: loss: 0.1024552
[Epoch 8; Iter   271/ 1097] train: loss: 0.1691446
[Epoch 8; Iter   301/ 1097] train: loss: 0.0792387
[Epoch 8; Iter   331/ 1097] train: loss: 0.0928422
[Epoch 8; Iter   361/ 1097] train: loss: 0.0409177
[Epoch 8; Iter   391/ 1097] train: loss: 0.0359107
[Epoch 8; Iter   421/ 1097] train: loss: 0.2952212
[Epoch 8; Iter   451/ 1097] train: loss: 0.0295982
[Epoch 8; Iter   481/ 1097] train: loss: 0.1492597
[Epoch 8; Iter   511/ 1097] train: loss: 0.2261055
[Epoch 8; Iter   541/ 1097] train: loss: 0.0433060
[Epoch 8; Iter   571/ 1097] train: loss: 0.0270319
[Epoch 8; Iter   601/ 1097] train: loss: 0.0387362
[Epoch 8; Iter   631/ 1097] train: loss: 0.0653056
[Epoch 8; Iter   661/ 1097] train: loss: 0.0456699
[Epoch 8; Iter   691/ 1097] train: loss: 0.3053674
[Epoch 8; Iter   721/ 1097] train: loss: 0.0322618
[Epoch 8; Iter   751/ 1097] train: loss: 0.1407315
[Epoch 8; Iter   781/ 1097] train: loss: 0.0688766
[Epoch 8; Iter   811/ 1097] train: loss: 0.0708050
[Epoch 8; Iter   841/ 1097] train: loss: 0.1696605
[Epoch 8; Iter   871/ 1097] train: loss: 0.3096827
[Epoch 8; Iter   901/ 1097] train: loss: 0.0685387
[Epoch 8; Iter   931/ 1097] train: loss: 0.0968734
[Epoch 8; Iter   961/ 1097] train: loss: 0.0319672
[Epoch 8; Iter   991/ 1097] train: loss: 0.0423641
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0312485
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0310174
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3276016
[Epoch 8] ogbg-molhiv: 0.766400 val loss: 0.339227
[Epoch 8] ogbg-molhiv: 0.672686 test loss: 0.642190
[Epoch 9; Iter    14/ 1097] train: loss: 0.0267467
[Epoch 9; Iter    44/ 1097] train: loss: 0.0413772
[Epoch 9; Iter    74/ 1097] train: loss: 0.0551785
[Epoch 9; Iter   104/ 1097] train: loss: 0.0711619
[Epoch 9; Iter   134/ 1097] train: loss: 0.0321225
[Epoch 9; Iter   164/ 1097] train: loss: 0.0322278
[Epoch 9; Iter   194/ 1097] train: loss: 0.0323672
[Epoch 9; Iter   224/ 1097] train: loss: 0.3106564
[Epoch 9; Iter   254/ 1097] train: loss: 0.1265217
[Epoch 9; Iter   284/ 1097] train: loss: 0.1763911
[Epoch 9; Iter   314/ 1097] train: loss: 0.2351690
[Epoch 9; Iter   344/ 1097] train: loss: 0.0277184
[Epoch 9; Iter   374/ 1097] train: loss: 0.1931092
[Epoch 9; Iter   404/ 1097] train: loss: 0.1685140
[Epoch 9; Iter   434/ 1097] train: loss: 0.0890197
[Epoch 9; Iter   464/ 1097] train: loss: 0.0277653
[Epoch 9; Iter   494/ 1097] train: loss: 0.0888351
[Epoch 9; Iter   524/ 1097] train: loss: 0.0275066
[Epoch 9; Iter   554/ 1097] train: loss: 0.0847910
[Epoch 9; Iter   584/ 1097] train: loss: 0.1548830
[Epoch 9; Iter   614/ 1097] train: loss: 0.0385909
[Epoch 9; Iter   644/ 1097] train: loss: 0.1466326
[Epoch 9; Iter   674/ 1097] train: loss: 0.1720048
[Epoch 9; Iter   704/ 1097] train: loss: 0.0269658
[Epoch 9; Iter   734/ 1097] train: loss: 0.0294371
[Epoch 9; Iter   764/ 1097] train: loss: 0.1243937
[Epoch 9; Iter   794/ 1097] train: loss: 0.0463604
[Epoch 9; Iter   824/ 1097] train: loss: 0.0251584
[Epoch 9; Iter   854/ 1097] train: loss: 0.0345851
[Epoch 9; Iter   884/ 1097] train: loss: 0.2853622
[Epoch 9; Iter   914/ 1097] train: loss: 0.0956654
[Epoch 9; Iter   944/ 1097] train: loss: 0.2337411
[Epoch 9; Iter   974/ 1097] train: loss: 0.0252923
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0190016
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0303139
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2808112
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0309865
[Epoch 9] ogbg-molhiv: 0.795540 val loss: 0.313859
[Epoch 9] ogbg-molhiv: 0.732094 test loss: 0.158942
[Epoch 10; Iter    27/ 1097] train: loss: 0.1978027
[Epoch 10; Iter    57/ 1097] train: loss: 0.3562547
[Epoch 10; Iter    87/ 1097] train: loss: 0.0489632
[Epoch 10; Iter   117/ 1097] train: loss: 0.1468966
[Epoch 10; Iter   147/ 1097] train: loss: 0.0314732
[Epoch 10; Iter   177/ 1097] train: loss: 0.5683481
[Epoch 10; Iter   207/ 1097] train: loss: 0.0751765
[Epoch 10; Iter   237/ 1097] train: loss: 0.0313532
[Epoch 10; Iter   267/ 1097] train: loss: 0.0848457
[Epoch 10; Iter   297/ 1097] train: loss: 0.2529134
[Epoch 10; Iter   327/ 1097] train: loss: 0.2530293
[Epoch 10; Iter   357/ 1097] train: loss: 0.0285917
[Epoch 10; Iter   387/ 1097] train: loss: 0.0994437
[Epoch 10; Iter   417/ 1097] train: loss: 0.2397752
[Epoch 10; Iter   447/ 1097] train: loss: 0.1393673
[Epoch 10; Iter   477/ 1097] train: loss: 0.0286370
[Epoch 10; Iter   507/ 1097] train: loss: 0.0380904
[Epoch 10; Iter   537/ 1097] train: loss: 0.1643762
[Epoch 10; Iter   567/ 1097] train: loss: 0.1859817
[Epoch 10; Iter   597/ 1097] train: loss: 0.1323911
[Epoch 10; Iter   627/ 1097] train: loss: 0.0434408
[Epoch 10; Iter   657/ 1097] train: loss: 0.2732152
[Epoch 10; Iter   687/ 1097] train: loss: 0.1879802
[Epoch 10; Iter   717/ 1097] train: loss: 0.3076529
[Epoch 10; Iter   747/ 1097] train: loss: 0.0428181
[Epoch 10; Iter   777/ 1097] train: loss: 0.0220496
[Epoch 10; Iter   807/ 1097] train: loss: 0.3223958
[Epoch 10; Iter   837/ 1097] train: loss: 0.0293652
[Epoch 10; Iter   867/ 1097] train: loss: 0.0323230
[Epoch 10; Iter   897/ 1097] train: loss: 0.0257556
[Epoch 10; Iter   927/ 1097] train: loss: 0.1655124
[Epoch 10; Iter   957/ 1097] train: loss: 0.1433618
[Epoch 10; Iter   987/ 1097] train: loss: 0.5274419
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0250794
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0674405
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1666633
[Epoch 10] ogbg-molhiv: 0.790837 val loss: 0.150346
[Epoch 10] ogbg-molhiv: 0.760395 test loss: 0.160455
[Epoch 11; Iter    10/ 1097] train: loss: 0.3093506
[Epoch 11; Iter    40/ 1097] train: loss: 0.2187167
[Epoch 11; Iter    70/ 1097] train: loss: 0.0825226
[Epoch 11; Iter   100/ 1097] train: loss: 0.0851019
[Epoch 11; Iter   130/ 1097] train: loss: 0.3386532
[Epoch 11; Iter   160/ 1097] train: loss: 0.1968032
[Epoch 11; Iter   190/ 1097] train: loss: 0.0286064
[Epoch 11; Iter   220/ 1097] train: loss: 0.2015253
[Epoch 11; Iter   250/ 1097] train: loss: 0.0471257
[Epoch 11; Iter   280/ 1097] train: loss: 0.1595520
[Epoch 11; Iter   310/ 1097] train: loss: 0.1434154
[Epoch 11; Iter   340/ 1097] train: loss: 0.0358507
[Epoch 11; Iter   370/ 1097] train: loss: 0.0259551
[Epoch 11; Iter   400/ 1097] train: loss: 0.2472750
[Epoch 11; Iter   430/ 1097] train: loss: 0.0284420
[Epoch 11; Iter   460/ 1097] train: loss: 0.1329255
[Epoch 11; Iter   490/ 1097] train: loss: 0.2418198
[Epoch 11; Iter   520/ 1097] train: loss: 0.1133832
[Epoch 11; Iter   550/ 1097] train: loss: 0.0218538
[Epoch 11; Iter   580/ 1097] train: loss: 0.5292808
[Epoch 11; Iter   610/ 1097] train: loss: 0.1053768
[Epoch 11; Iter   640/ 1097] train: loss: 0.0823657
[Epoch 11; Iter   670/ 1097] train: loss: 0.0342944
[Epoch 11; Iter   700/ 1097] train: loss: 0.1774690
[Epoch 11; Iter   730/ 1097] train: loss: 0.1251715
[Epoch 11; Iter   760/ 1097] train: loss: 0.0892156
[Epoch 11; Iter   790/ 1097] train: loss: 0.1317278
[Epoch 11; Iter   820/ 1097] train: loss: 0.0751453
[Epoch 11; Iter   850/ 1097] train: loss: 0.1994296
[Epoch 11; Iter   880/ 1097] train: loss: 0.0360105
[Epoch 11; Iter   910/ 1097] train: loss: 0.0439215
[Epoch 11; Iter   940/ 1097] train: loss: 0.1834089
[Epoch 11; Iter   970/ 1097] train: loss: 0.0283786
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0466776
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1612600
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1873298
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0442179
[Epoch 11] ogbg-molhiv: 0.794974 val loss: 0.214302
[Epoch 11] ogbg-molhiv: 0.723135 test loss: 0.170015
[Epoch 12; Iter    23/ 1097] train: loss: 0.1712534
[Epoch 12; Iter    53/ 1097] train: loss: 0.0300148
[Epoch 12; Iter    83/ 1097] train: loss: 0.0755348
[Epoch 8; Iter     1/ 1097] train: loss: 0.1711420
[Epoch 8; Iter    31/ 1097] train: loss: 0.1914990
[Epoch 8; Iter    61/ 1097] train: loss: 0.2578726
[Epoch 8; Iter    91/ 1097] train: loss: 0.3656135
[Epoch 8; Iter   121/ 1097] train: loss: 0.0326770
[Epoch 8; Iter   151/ 1097] train: loss: 0.4159367
[Epoch 8; Iter   181/ 1097] train: loss: 0.1730832
[Epoch 8; Iter   211/ 1097] train: loss: 0.2347064
[Epoch 8; Iter   241/ 1097] train: loss: 0.0506172
[Epoch 8; Iter   271/ 1097] train: loss: 0.1791028
[Epoch 8; Iter   301/ 1097] train: loss: 0.0300124
[Epoch 8; Iter   331/ 1097] train: loss: 0.0381461
[Epoch 8; Iter   361/ 1097] train: loss: 0.1318931
[Epoch 8; Iter   391/ 1097] train: loss: 0.0913541
[Epoch 8; Iter   421/ 1097] train: loss: 0.2865414
[Epoch 8; Iter   451/ 1097] train: loss: 0.0359783
[Epoch 8; Iter   481/ 1097] train: loss: 0.1419194
[Epoch 8; Iter   511/ 1097] train: loss: 0.1359975
[Epoch 8; Iter   541/ 1097] train: loss: 0.0364945
[Epoch 8; Iter   571/ 1097] train: loss: 0.4059112
[Epoch 8; Iter   601/ 1097] train: loss: 0.1348466
[Epoch 8; Iter   631/ 1097] train: loss: 0.0958022
[Epoch 8; Iter   661/ 1097] train: loss: 0.0376471
[Epoch 8; Iter   691/ 1097] train: loss: 0.1884995
[Epoch 8; Iter   721/ 1097] train: loss: 0.0893441
[Epoch 8; Iter   751/ 1097] train: loss: 0.0289869
[Epoch 8; Iter   781/ 1097] train: loss: 0.1929626
[Epoch 8; Iter   811/ 1097] train: loss: 0.0799180
[Epoch 8; Iter   841/ 1097] train: loss: 0.0518599
[Epoch 8; Iter   871/ 1097] train: loss: 0.1634855
[Epoch 8; Iter   901/ 1097] train: loss: 0.0338672
[Epoch 8; Iter   931/ 1097] train: loss: 0.0576107
[Epoch 8; Iter   961/ 1097] train: loss: 0.0441452
[Epoch 8; Iter   991/ 1097] train: loss: 0.0350493
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0238307
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0214449
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1484495
[Epoch 8] ogbg-molhiv: 0.786256 val loss: 0.080952
[Epoch 8] ogbg-molhiv: 0.736988 test loss: 0.120260
[Epoch 9; Iter    14/ 1097] train: loss: 0.0262453
[Epoch 9; Iter    44/ 1097] train: loss: 0.0347945
[Epoch 9; Iter    74/ 1097] train: loss: 0.1718951
[Epoch 9; Iter   104/ 1097] train: loss: 0.3846547
[Epoch 9; Iter   134/ 1097] train: loss: 0.2204314
[Epoch 9; Iter   164/ 1097] train: loss: 0.0298453
[Epoch 9; Iter   194/ 1097] train: loss: 0.0375829
[Epoch 9; Iter   224/ 1097] train: loss: 0.0319186
[Epoch 9; Iter   254/ 1097] train: loss: 0.1450451
[Epoch 9; Iter   284/ 1097] train: loss: 0.0476695
[Epoch 9; Iter   314/ 1097] train: loss: 0.0332990
[Epoch 9; Iter   344/ 1097] train: loss: 0.0467032
[Epoch 9; Iter   374/ 1097] train: loss: 0.0352271
[Epoch 9; Iter   404/ 1097] train: loss: 0.0830497
[Epoch 9; Iter   434/ 1097] train: loss: 0.1672077
[Epoch 9; Iter   464/ 1097] train: loss: 0.2014075
[Epoch 9; Iter   494/ 1097] train: loss: 0.0952110
[Epoch 9; Iter   524/ 1097] train: loss: 0.0842307
[Epoch 9; Iter   554/ 1097] train: loss: 0.0585814
[Epoch 9; Iter   584/ 1097] train: loss: 0.2124222
[Epoch 9; Iter   614/ 1097] train: loss: 0.0564485
[Epoch 9; Iter   644/ 1097] train: loss: 0.1921361
[Epoch 9; Iter   674/ 1097] train: loss: 0.0762825
[Epoch 9; Iter   704/ 1097] train: loss: 0.0285720
[Epoch 9; Iter   734/ 1097] train: loss: 0.1290477
[Epoch 9; Iter   764/ 1097] train: loss: 0.0896161
[Epoch 9; Iter   794/ 1097] train: loss: 0.0643551
[Epoch 9; Iter   824/ 1097] train: loss: 0.0353038
[Epoch 9; Iter   854/ 1097] train: loss: 0.0382318
[Epoch 9; Iter   884/ 1097] train: loss: 0.2304802
[Epoch 9; Iter   914/ 1097] train: loss: 0.0302701
[Epoch 9; Iter   944/ 1097] train: loss: 0.1636108
[Epoch 9; Iter   974/ 1097] train: loss: 0.0532242
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1690562
[Epoch 9; Iter  1034/ 1097] train: loss: 0.1019954
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0503751
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0407528
[Epoch 9] ogbg-molhiv: 0.764553 val loss: 0.082207
[Epoch 9] ogbg-molhiv: 0.715682 test loss: 0.161738
[Epoch 10; Iter    27/ 1097] train: loss: 0.1363004
[Epoch 10; Iter    57/ 1097] train: loss: 0.0277659
[Epoch 10; Iter    87/ 1097] train: loss: 0.1423200
[Epoch 10; Iter   117/ 1097] train: loss: 0.0711843
[Epoch 10; Iter   147/ 1097] train: loss: 0.0246199
[Epoch 10; Iter   177/ 1097] train: loss: 0.0290649
[Epoch 10; Iter   207/ 1097] train: loss: 0.0197479
[Epoch 10; Iter   237/ 1097] train: loss: 0.0304399
[Epoch 10; Iter   267/ 1097] train: loss: 0.0285813
[Epoch 10; Iter   297/ 1097] train: loss: 0.0235747
[Epoch 10; Iter   327/ 1097] train: loss: 0.0299487
[Epoch 10; Iter   357/ 1097] train: loss: 0.1271796
[Epoch 10; Iter   387/ 1097] train: loss: 0.1858935
[Epoch 10; Iter   417/ 1097] train: loss: 0.0335950
[Epoch 10; Iter   447/ 1097] train: loss: 0.0423948
[Epoch 10; Iter   477/ 1097] train: loss: 0.0464561
[Epoch 10; Iter   507/ 1097] train: loss: 0.1047506
[Epoch 10; Iter   537/ 1097] train: loss: 0.0325507
[Epoch 10; Iter   567/ 1097] train: loss: 0.1236471
[Epoch 10; Iter   597/ 1097] train: loss: 0.1776272
[Epoch 10; Iter   627/ 1097] train: loss: 0.2109929
[Epoch 10; Iter   657/ 1097] train: loss: 0.0209906
[Epoch 10; Iter   687/ 1097] train: loss: 0.2449532
[Epoch 10; Iter   717/ 1097] train: loss: 0.0583968
[Epoch 10; Iter   747/ 1097] train: loss: 0.3505682
[Epoch 10; Iter   777/ 1097] train: loss: 0.0606800
[Epoch 10; Iter   807/ 1097] train: loss: 0.0970755
[Epoch 10; Iter   837/ 1097] train: loss: 0.0723126
[Epoch 10; Iter   867/ 1097] train: loss: 0.3904662
[Epoch 10; Iter   897/ 1097] train: loss: 0.1733982
[Epoch 10; Iter   927/ 1097] train: loss: 0.3929719
[Epoch 10; Iter   957/ 1097] train: loss: 0.2145722
[Epoch 10; Iter   987/ 1097] train: loss: 0.2276873
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0601975
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1103437
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1722723
[Epoch 10] ogbg-molhiv: 0.776529 val loss: 0.103079
[Epoch 10] ogbg-molhiv: 0.748684 test loss: 0.118715
[Epoch 11; Iter    10/ 1097] train: loss: 0.0289109
[Epoch 11; Iter    40/ 1097] train: loss: 0.0254834
[Epoch 11; Iter    70/ 1097] train: loss: 0.0452809
[Epoch 11; Iter   100/ 1097] train: loss: 0.1413890
[Epoch 11; Iter   130/ 1097] train: loss: 0.0316069
[Epoch 11; Iter   160/ 1097] train: loss: 0.0486569
[Epoch 11; Iter   190/ 1097] train: loss: 0.1470043
[Epoch 11; Iter   220/ 1097] train: loss: 0.0586445
[Epoch 11; Iter   250/ 1097] train: loss: 0.1735647
[Epoch 11; Iter   280/ 1097] train: loss: 0.1923151
[Epoch 11; Iter   310/ 1097] train: loss: 0.1034569
[Epoch 11; Iter   340/ 1097] train: loss: 0.0667788
[Epoch 11; Iter   370/ 1097] train: loss: 0.3721581
[Epoch 11; Iter   400/ 1097] train: loss: 0.0480369
[Epoch 11; Iter   430/ 1097] train: loss: 0.1792683
[Epoch 11; Iter   460/ 1097] train: loss: 0.1405389
[Epoch 11; Iter   490/ 1097] train: loss: 0.1813258
[Epoch 11; Iter   520/ 1097] train: loss: 0.4964381
[Epoch 11; Iter   550/ 1097] train: loss: 0.1782513
[Epoch 11; Iter   580/ 1097] train: loss: 0.1265498
[Epoch 11; Iter   610/ 1097] train: loss: 0.0357165
[Epoch 11; Iter   640/ 1097] train: loss: 0.0290113
[Epoch 11; Iter   670/ 1097] train: loss: 0.0335650
[Epoch 11; Iter   700/ 1097] train: loss: 0.0454855
[Epoch 11; Iter   730/ 1097] train: loss: 0.1280043
[Epoch 11; Iter   760/ 1097] train: loss: 0.0569899
[Epoch 11; Iter   790/ 1097] train: loss: 0.0554636
[Epoch 11; Iter   820/ 1097] train: loss: 0.2772038
[Epoch 11; Iter   850/ 1097] train: loss: 0.1808267
[Epoch 11; Iter   880/ 1097] train: loss: 0.0272767
[Epoch 11; Iter   910/ 1097] train: loss: 0.1673903
[Epoch 11; Iter   940/ 1097] train: loss: 0.3384006
[Epoch 11; Iter   970/ 1097] train: loss: 0.1768388
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1662263
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1238443
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2999026
[Epoch 11; Iter  1090/ 1097] train: loss: 0.2977183
[Epoch 11] ogbg-molhiv: 0.788770 val loss: 0.082638
[Epoch 11] ogbg-molhiv: 0.721912 test loss: 0.135056
[Epoch 12; Iter    23/ 1097] train: loss: 0.1167180
[Epoch 12; Iter    53/ 1097] train: loss: 0.0354276
[Epoch 12; Iter    83/ 1097] train: loss: 0.0332982
[Epoch 8; Iter     1/ 1097] train: loss: 0.1641674
[Epoch 8; Iter    31/ 1097] train: loss: 0.0614139
[Epoch 8; Iter    61/ 1097] train: loss: 0.1198001
[Epoch 8; Iter    91/ 1097] train: loss: 0.0887749
[Epoch 8; Iter   121/ 1097] train: loss: 0.0873002
[Epoch 8; Iter   151/ 1097] train: loss: 0.0378170
[Epoch 8; Iter   181/ 1097] train: loss: 0.0622589
[Epoch 8; Iter   211/ 1097] train: loss: 0.0450317
[Epoch 8; Iter   241/ 1097] train: loss: 0.0340128
[Epoch 8; Iter   271/ 1097] train: loss: 0.2005234
[Epoch 8; Iter   301/ 1097] train: loss: 0.2298414
[Epoch 8; Iter   331/ 1097] train: loss: 0.0884211
[Epoch 8; Iter   361/ 1097] train: loss: 0.1140956
[Epoch 8; Iter   391/ 1097] train: loss: 0.0273467
[Epoch 8; Iter   421/ 1097] train: loss: 0.2824016
[Epoch 8; Iter   451/ 1097] train: loss: 0.1808058
[Epoch 8; Iter   481/ 1097] train: loss: 0.0487151
[Epoch 8; Iter   511/ 1097] train: loss: 0.0662166
[Epoch 8; Iter   541/ 1097] train: loss: 0.1627342
[Epoch 8; Iter   571/ 1097] train: loss: 0.1049128
[Epoch 8; Iter   601/ 1097] train: loss: 0.3798802
[Epoch 8; Iter   631/ 1097] train: loss: 0.0391893
[Epoch 8; Iter   661/ 1097] train: loss: 0.2382265
[Epoch 8; Iter   691/ 1097] train: loss: 0.0999848
[Epoch 8; Iter   721/ 1097] train: loss: 0.0669872
[Epoch 8; Iter   751/ 1097] train: loss: 0.0961610
[Epoch 8; Iter   781/ 1097] train: loss: 0.2153327
[Epoch 8; Iter   811/ 1097] train: loss: 0.1998849
[Epoch 8; Iter   841/ 1097] train: loss: 0.3539468
[Epoch 8; Iter   871/ 1097] train: loss: 0.1989059
[Epoch 8; Iter   901/ 1097] train: loss: 0.0233676
[Epoch 8; Iter   931/ 1097] train: loss: 0.2101346
[Epoch 8; Iter   961/ 1097] train: loss: 0.0628793
[Epoch 8; Iter   991/ 1097] train: loss: 0.1520314
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2830766
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0318304
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0874363
[Epoch 8] ogbg-molhiv: 0.724840 val loss: 0.201820
[Epoch 8] ogbg-molhiv: 0.704502 test loss: 0.172606
[Epoch 9; Iter    14/ 1097] train: loss: 0.2607073
[Epoch 9; Iter    44/ 1097] train: loss: 0.0329550
[Epoch 9; Iter    74/ 1097] train: loss: 0.0250950
[Epoch 9; Iter   104/ 1097] train: loss: 0.3531807
[Epoch 9; Iter   134/ 1097] train: loss: 0.0662984
[Epoch 9; Iter   164/ 1097] train: loss: 0.1904248
[Epoch 9; Iter   194/ 1097] train: loss: 0.0971943
[Epoch 9; Iter   224/ 1097] train: loss: 0.0355591
[Epoch 9; Iter   254/ 1097] train: loss: 0.3500611
[Epoch 9; Iter   284/ 1097] train: loss: 0.1770771
[Epoch 9; Iter   314/ 1097] train: loss: 0.1403266
[Epoch 9; Iter   344/ 1097] train: loss: 0.5364948
[Epoch 9; Iter   374/ 1097] train: loss: 0.1518382
[Epoch 9; Iter   404/ 1097] train: loss: 0.1126276
[Epoch 9; Iter   434/ 1097] train: loss: 0.0503399
[Epoch 9; Iter   464/ 1097] train: loss: 0.0356832
[Epoch 9; Iter   494/ 1097] train: loss: 0.0978665
[Epoch 9; Iter   524/ 1097] train: loss: 0.0323206
[Epoch 9; Iter   554/ 1097] train: loss: 0.0387987
[Epoch 9; Iter   584/ 1097] train: loss: 0.4939325
[Epoch 9; Iter   614/ 1097] train: loss: 0.1141492
[Epoch 9; Iter   644/ 1097] train: loss: 0.3396460
[Epoch 9; Iter   674/ 1097] train: loss: 0.4609670
[Epoch 9; Iter   704/ 1097] train: loss: 0.1667812
[Epoch 9; Iter   734/ 1097] train: loss: 0.1149040
[Epoch 9; Iter   764/ 1097] train: loss: 0.2503835
[Epoch 9; Iter   794/ 1097] train: loss: 0.1602528
[Epoch 9; Iter   824/ 1097] train: loss: 0.0348822
[Epoch 9; Iter   854/ 1097] train: loss: 0.0334072
[Epoch 9; Iter   884/ 1097] train: loss: 0.0505057
[Epoch 9; Iter   914/ 1097] train: loss: 0.1767286
[Epoch 9; Iter   944/ 1097] train: loss: 0.0445462
[Epoch 9; Iter   974/ 1097] train: loss: 0.0909328
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2070064
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2522378
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3743965
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2656095
[Epoch 9] ogbg-molhiv: 0.779627 val loss: 0.087306
[Epoch 9] ogbg-molhiv: 0.727339 test loss: 0.118895
[Epoch 10; Iter    27/ 1097] train: loss: 0.0298652
[Epoch 10; Iter    57/ 1097] train: loss: 0.0300255
[Epoch 10; Iter    87/ 1097] train: loss: 0.1375688
[Epoch 10; Iter   117/ 1097] train: loss: 0.0333200
[Epoch 10; Iter   147/ 1097] train: loss: 0.3763167
[Epoch 10; Iter   177/ 1097] train: loss: 0.1609532
[Epoch 10; Iter   207/ 1097] train: loss: 0.1044588
[Epoch 10; Iter   237/ 1097] train: loss: 0.0351943
[Epoch 10; Iter   267/ 1097] train: loss: 0.0263665
[Epoch 10; Iter   297/ 1097] train: loss: 0.1978714
[Epoch 10; Iter   327/ 1097] train: loss: 0.0266484
[Epoch 10; Iter   357/ 1097] train: loss: 0.2258064
[Epoch 10; Iter   387/ 1097] train: loss: 0.1410019
[Epoch 10; Iter   417/ 1097] train: loss: 0.0924049
[Epoch 10; Iter   447/ 1097] train: loss: 0.1824651
[Epoch 10; Iter   477/ 1097] train: loss: 0.1670316
[Epoch 10; Iter   507/ 1097] train: loss: 0.0841914
[Epoch 10; Iter   537/ 1097] train: loss: 0.0217835
[Epoch 10; Iter   567/ 1097] train: loss: 0.0258629
[Epoch 10; Iter   597/ 1097] train: loss: 0.0267708
[Epoch 10; Iter   627/ 1097] train: loss: 0.2119963
[Epoch 10; Iter   657/ 1097] train: loss: 0.1490998
[Epoch 10; Iter   687/ 1097] train: loss: 0.0658841
[Epoch 10; Iter   717/ 1097] train: loss: 0.0418461
[Epoch 10; Iter   747/ 1097] train: loss: 0.2350940
[Epoch 10; Iter   777/ 1097] train: loss: 0.1583836
[Epoch 10; Iter   807/ 1097] train: loss: 0.0286282
[Epoch 10; Iter   837/ 1097] train: loss: 0.0304078
[Epoch 10; Iter   867/ 1097] train: loss: 0.0549764
[Epoch 10; Iter   897/ 1097] train: loss: 0.0333622
[Epoch 10; Iter   927/ 1097] train: loss: 0.1497203
[Epoch 10; Iter   957/ 1097] train: loss: 0.0486592
[Epoch 10; Iter   987/ 1097] train: loss: 0.2577525
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2373168
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1556129
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0387139
[Epoch 10] ogbg-molhiv: 0.772900 val loss: 0.085152
[Epoch 10] ogbg-molhiv: 0.739018 test loss: 0.194463
[Epoch 11; Iter    10/ 1097] train: loss: 0.3058701
[Epoch 11; Iter    40/ 1097] train: loss: 0.0722628
[Epoch 11; Iter    70/ 1097] train: loss: 0.1608557
[Epoch 11; Iter   100/ 1097] train: loss: 0.0266093
[Epoch 11; Iter   130/ 1097] train: loss: 0.1878660
[Epoch 11; Iter   160/ 1097] train: loss: 0.0399535
[Epoch 11; Iter   190/ 1097] train: loss: 0.2355828
[Epoch 11; Iter   220/ 1097] train: loss: 0.3180649
[Epoch 11; Iter   250/ 1097] train: loss: 0.1558486
[Epoch 11; Iter   280/ 1097] train: loss: 0.0563963
[Epoch 11; Iter   310/ 1097] train: loss: 0.2188386
[Epoch 11; Iter   340/ 1097] train: loss: 0.0376161
[Epoch 11; Iter   370/ 1097] train: loss: 0.1070658
[Epoch 11; Iter   400/ 1097] train: loss: 0.0550385
[Epoch 11; Iter   430/ 1097] train: loss: 0.2398737
[Epoch 11; Iter   460/ 1097] train: loss: 0.1152411
[Epoch 11; Iter   490/ 1097] train: loss: 0.2556414
[Epoch 11; Iter   520/ 1097] train: loss: 0.1916733
[Epoch 11; Iter   550/ 1097] train: loss: 0.0284908
[Epoch 11; Iter   580/ 1097] train: loss: 0.0287912
[Epoch 11; Iter   610/ 1097] train: loss: 0.0303675
[Epoch 11; Iter   640/ 1097] train: loss: 0.0232986
[Epoch 11; Iter   670/ 1097] train: loss: 0.1605079
[Epoch 11; Iter   700/ 1097] train: loss: 0.2194911
[Epoch 11; Iter   730/ 1097] train: loss: 0.0313056
[Epoch 11; Iter   760/ 1097] train: loss: 0.1655666
[Epoch 11; Iter   790/ 1097] train: loss: 0.2014546
[Epoch 11; Iter   820/ 1097] train: loss: 0.0947912
[Epoch 11; Iter   850/ 1097] train: loss: 0.0443607
[Epoch 11; Iter   880/ 1097] train: loss: 0.2521049
[Epoch 11; Iter   910/ 1097] train: loss: 0.2540557
[Epoch 11; Iter   940/ 1097] train: loss: 0.2652834
[Epoch 11; Iter   970/ 1097] train: loss: 0.2518083
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0370996
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0526973
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2002846
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4550011
[Epoch 11] ogbg-molhiv: 0.736953 val loss: 0.124061
[Epoch 11] ogbg-molhiv: 0.726126 test loss: 0.132337
[Epoch 12; Iter    23/ 1097] train: loss: 0.1897641
[Epoch 12; Iter    53/ 1097] train: loss: 0.0277142
[Epoch 12; Iter    83/ 1097] train: loss: 0.0341241
[Epoch 8; Iter    31/ 1097] train: loss: 0.1787220
[Epoch 8; Iter    61/ 1097] train: loss: 0.3105674
[Epoch 8; Iter    91/ 1097] train: loss: 0.3406558
[Epoch 8; Iter   121/ 1097] train: loss: 0.0326882
[Epoch 8; Iter   151/ 1097] train: loss: 0.4468352
[Epoch 8; Iter   181/ 1097] train: loss: 0.2038953
[Epoch 8; Iter   211/ 1097] train: loss: 0.2750982
[Epoch 8; Iter   241/ 1097] train: loss: 0.0403917
[Epoch 8; Iter   271/ 1097] train: loss: 0.1537739
[Epoch 8; Iter   301/ 1097] train: loss: 0.0331938
[Epoch 8; Iter   331/ 1097] train: loss: 0.0410976
[Epoch 8; Iter   361/ 1097] train: loss: 0.1285643
[Epoch 8; Iter   391/ 1097] train: loss: 0.0621065
[Epoch 8; Iter   421/ 1097] train: loss: 0.3127846
[Epoch 8; Iter   451/ 1097] train: loss: 0.0355446
[Epoch 8; Iter   481/ 1097] train: loss: 0.1358670
[Epoch 8; Iter   511/ 1097] train: loss: 0.1362328
[Epoch 8; Iter   541/ 1097] train: loss: 0.0341245
[Epoch 8; Iter   571/ 1097] train: loss: 0.3992333
[Epoch 8; Iter   601/ 1097] train: loss: 0.1062460
[Epoch 8; Iter   631/ 1097] train: loss: 0.1070291
[Epoch 8; Iter   661/ 1097] train: loss: 0.0379358
[Epoch 8; Iter   691/ 1097] train: loss: 0.1894427
[Epoch 8; Iter   721/ 1097] train: loss: 0.1180477
[Epoch 8; Iter   751/ 1097] train: loss: 0.0385060
[Epoch 8; Iter   781/ 1097] train: loss: 0.2429613
[Epoch 8; Iter   811/ 1097] train: loss: 0.1020860
[Epoch 8; Iter   841/ 1097] train: loss: 0.0563562
[Epoch 8; Iter   871/ 1097] train: loss: 0.1612423
[Epoch 8; Iter   901/ 1097] train: loss: 0.0326526
[Epoch 8; Iter   931/ 1097] train: loss: 0.0805866
[Epoch 8; Iter   961/ 1097] train: loss: 0.0607769
[Epoch 8; Iter   991/ 1097] train: loss: 0.0336607
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0292469
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0212017
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1203670
[Epoch 8] ogbg-molhiv: 0.744274 val loss: 0.085867
[Epoch 8] ogbg-molhiv: 0.702646 test loss: 0.122992
[Epoch 9; Iter    14/ 1097] train: loss: 0.0284064
[Epoch 9; Iter    44/ 1097] train: loss: 0.0336796
[Epoch 9; Iter    74/ 1097] train: loss: 0.1736864
[Epoch 9; Iter   104/ 1097] train: loss: 0.3782665
[Epoch 9; Iter   134/ 1097] train: loss: 0.2590103
[Epoch 9; Iter   164/ 1097] train: loss: 0.0415545
[Epoch 9; Iter   194/ 1097] train: loss: 0.0615849
[Epoch 9; Iter   224/ 1097] train: loss: 0.0359516
[Epoch 9; Iter   254/ 1097] train: loss: 0.1383374
[Epoch 9; Iter   284/ 1097] train: loss: 0.0498842
[Epoch 9; Iter   314/ 1097] train: loss: 0.0342171
[Epoch 9; Iter   344/ 1097] train: loss: 0.0555155
[Epoch 9; Iter   374/ 1097] train: loss: 0.0272374
[Epoch 9; Iter   404/ 1097] train: loss: 0.1314382
[Epoch 9; Iter   434/ 1097] train: loss: 0.1626736
[Epoch 9; Iter   464/ 1097] train: loss: 0.1930772
[Epoch 9; Iter   494/ 1097] train: loss: 0.0912391
[Epoch 9; Iter   524/ 1097] train: loss: 0.1144668
[Epoch 9; Iter   554/ 1097] train: loss: 0.0418664
[Epoch 9; Iter   584/ 1097] train: loss: 0.2425787
[Epoch 9; Iter   614/ 1097] train: loss: 0.0564089
[Epoch 9; Iter   644/ 1097] train: loss: 0.1951015
[Epoch 9; Iter   674/ 1097] train: loss: 0.0991418
[Epoch 9; Iter   704/ 1097] train: loss: 0.0286931
[Epoch 9; Iter   734/ 1097] train: loss: 0.1476232
[Epoch 9; Iter   764/ 1097] train: loss: 0.0946214
[Epoch 9; Iter   794/ 1097] train: loss: 0.0844302
[Epoch 9; Iter   824/ 1097] train: loss: 0.0468425
[Epoch 9; Iter   854/ 1097] train: loss: 0.0385088
[Epoch 9; Iter   884/ 1097] train: loss: 0.2632188
[Epoch 9; Iter   914/ 1097] train: loss: 0.0271836
[Epoch 9; Iter   944/ 1097] train: loss: 0.1633030
[Epoch 9; Iter   974/ 1097] train: loss: 0.0476802
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1430586
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0918463
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0923106
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0561153
[Epoch 9] ogbg-molhiv: 0.695862 val loss: 0.131443
[Epoch 9] ogbg-molhiv: 0.702719 test loss: 0.129633
[Epoch 10; Iter    27/ 1097] train: loss: 0.1840792
[Epoch 10; Iter    57/ 1097] train: loss: 0.0359231
[Epoch 10; Iter    87/ 1097] train: loss: 0.1789105
[Epoch 10; Iter   117/ 1097] train: loss: 0.0536217
[Epoch 10; Iter   147/ 1097] train: loss: 0.0286200
[Epoch 10; Iter   177/ 1097] train: loss: 0.0291280
[Epoch 10; Iter   207/ 1097] train: loss: 0.0273242
[Epoch 10; Iter   237/ 1097] train: loss: 0.0542020
[Epoch 10; Iter   267/ 1097] train: loss: 0.0449164
[Epoch 10; Iter   297/ 1097] train: loss: 0.0246491
[Epoch 10; Iter   327/ 1097] train: loss: 0.0297120
[Epoch 10; Iter   357/ 1097] train: loss: 0.1531506
[Epoch 10; Iter   387/ 1097] train: loss: 0.1837254
[Epoch 10; Iter   417/ 1097] train: loss: 0.0309486
[Epoch 10; Iter   447/ 1097] train: loss: 0.0492259
[Epoch 10; Iter   477/ 1097] train: loss: 0.0508008
[Epoch 10; Iter   507/ 1097] train: loss: 0.0829825
[Epoch 10; Iter   537/ 1097] train: loss: 0.0422482
[Epoch 10; Iter   567/ 1097] train: loss: 0.1494872
[Epoch 10; Iter   597/ 1097] train: loss: 0.1634328
[Epoch 10; Iter   627/ 1097] train: loss: 0.2059850
[Epoch 10; Iter   657/ 1097] train: loss: 0.0247426
[Epoch 10; Iter   687/ 1097] train: loss: 0.2847196
[Epoch 10; Iter   717/ 1097] train: loss: 0.0491574
[Epoch 10; Iter   747/ 1097] train: loss: 0.3740056
[Epoch 10; Iter   777/ 1097] train: loss: 0.0832342
[Epoch 10; Iter   807/ 1097] train: loss: 0.1025428
[Epoch 10; Iter   837/ 1097] train: loss: 0.0634811
[Epoch 10; Iter   867/ 1097] train: loss: 0.4259799
[Epoch 10; Iter   897/ 1097] train: loss: 0.1445480
[Epoch 10; Iter   927/ 1097] train: loss: 0.3664938
[Epoch 10; Iter   957/ 1097] train: loss: 0.2457881
[Epoch 10; Iter   987/ 1097] train: loss: 0.2864304
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0809943
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1177228
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1539494
[Epoch 10] ogbg-molhiv: 0.782628 val loss: 0.109559
[Epoch 10] ogbg-molhiv: 0.756065 test loss: 0.116159
[Epoch 11; Iter    10/ 1097] train: loss: 0.0314612
[Epoch 11; Iter    40/ 1097] train: loss: 0.0327804
[Epoch 11; Iter    70/ 1097] train: loss: 0.0375812
[Epoch 11; Iter   100/ 1097] train: loss: 0.1669270
[Epoch 11; Iter   130/ 1097] train: loss: 0.0526590
[Epoch 11; Iter   160/ 1097] train: loss: 0.1071543
[Epoch 11; Iter   190/ 1097] train: loss: 0.1378538
[Epoch 11; Iter   220/ 1097] train: loss: 0.0962215
[Epoch 11; Iter   250/ 1097] train: loss: 0.1379714
[Epoch 11; Iter   280/ 1097] train: loss: 0.2546266
[Epoch 11; Iter   310/ 1097] train: loss: 0.1028386
[Epoch 11; Iter   340/ 1097] train: loss: 0.0366314
[Epoch 11; Iter   370/ 1097] train: loss: 0.3857811
[Epoch 11; Iter   400/ 1097] train: loss: 0.0679961
[Epoch 11; Iter   430/ 1097] train: loss: 0.2228495
[Epoch 11; Iter   460/ 1097] train: loss: 0.1563193
[Epoch 11; Iter   490/ 1097] train: loss: 0.1795807
[Epoch 11; Iter   520/ 1097] train: loss: 0.5016147
[Epoch 11; Iter   550/ 1097] train: loss: 0.0923907
[Epoch 11; Iter   580/ 1097] train: loss: 0.1646650
[Epoch 11; Iter   610/ 1097] train: loss: 0.0303598
[Epoch 11; Iter   640/ 1097] train: loss: 0.0287701
[Epoch 11; Iter   670/ 1097] train: loss: 0.0300282
[Epoch 11; Iter   700/ 1097] train: loss: 0.0297848
[Epoch 11; Iter   730/ 1097] train: loss: 0.1458620
[Epoch 11; Iter   760/ 1097] train: loss: 0.0439116
[Epoch 11; Iter   790/ 1097] train: loss: 0.0383901
[Epoch 11; Iter   820/ 1097] train: loss: 0.2267481
[Epoch 11; Iter   850/ 1097] train: loss: 0.2110034
[Epoch 11; Iter   880/ 1097] train: loss: 0.0431684
[Epoch 11; Iter   910/ 1097] train: loss: 0.2901018
[Epoch 11; Iter   940/ 1097] train: loss: 0.2655782
[Epoch 11; Iter   970/ 1097] train: loss: 0.1361928
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1958902
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0863828
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2793500
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4144962
[Epoch 11] ogbg-molhiv: 0.813284 val loss: 0.443844
[Epoch 11] ogbg-molhiv: 0.729970 test loss: 0.140765
[Epoch 12; Iter    23/ 1097] train: loss: 0.1029282
[Epoch 12; Iter    53/ 1097] train: loss: 0.0336276
[Epoch 12; Iter    83/ 1097] train: loss: 0.0371935
[Epoch 12; Iter   113/ 1097] train: loss: 0.0252178
[Epoch 8; Iter    31/ 1097] train: loss: 0.0372266
[Epoch 8; Iter    61/ 1097] train: loss: 0.1886634
[Epoch 8; Iter    91/ 1097] train: loss: 0.1593352
[Epoch 8; Iter   121/ 1097] train: loss: 0.0350815
[Epoch 8; Iter   151/ 1097] train: loss: 0.1238821
[Epoch 8; Iter   181/ 1097] train: loss: 0.0463859
[Epoch 8; Iter   211/ 1097] train: loss: 0.3116761
[Epoch 8; Iter   241/ 1097] train: loss: 0.1159713
[Epoch 8; Iter   271/ 1097] train: loss: 0.2520490
[Epoch 8; Iter   301/ 1097] train: loss: 0.1293562
[Epoch 8; Iter   331/ 1097] train: loss: 0.1300716
[Epoch 8; Iter   361/ 1097] train: loss: 0.0436281
[Epoch 8; Iter   391/ 1097] train: loss: 0.0337751
[Epoch 8; Iter   421/ 1097] train: loss: 0.2497030
[Epoch 8; Iter   451/ 1097] train: loss: 0.0311168
[Epoch 8; Iter   481/ 1097] train: loss: 0.1965615
[Epoch 8; Iter   511/ 1097] train: loss: 0.1606730
[Epoch 8; Iter   541/ 1097] train: loss: 0.0360588
[Epoch 8; Iter   571/ 1097] train: loss: 0.0298984
[Epoch 8; Iter   601/ 1097] train: loss: 0.0374251
[Epoch 8; Iter   631/ 1097] train: loss: 0.0899089
[Epoch 8; Iter   661/ 1097] train: loss: 0.0370973
[Epoch 8; Iter   691/ 1097] train: loss: 0.3319483
[Epoch 8; Iter   721/ 1097] train: loss: 0.0376102
[Epoch 8; Iter   751/ 1097] train: loss: 0.1065805
[Epoch 8; Iter   781/ 1097] train: loss: 0.0490930
[Epoch 8; Iter   811/ 1097] train: loss: 0.0835324
[Epoch 8; Iter   841/ 1097] train: loss: 0.1657844
[Epoch 8; Iter   871/ 1097] train: loss: 0.3468381
[Epoch 8; Iter   901/ 1097] train: loss: 0.0640840
[Epoch 8; Iter   931/ 1097] train: loss: 0.1164942
[Epoch 8; Iter   961/ 1097] train: loss: 0.0323624
[Epoch 8; Iter   991/ 1097] train: loss: 0.0386983
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0422337
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0407052
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3288857
[Epoch 8] ogbg-molhiv: 0.743579 val loss: 0.085203
[Epoch 8] ogbg-molhiv: 0.666900 test loss: 0.128247
[Epoch 9; Iter    14/ 1097] train: loss: 0.0417504
[Epoch 9; Iter    44/ 1097] train: loss: 0.0547197
[Epoch 9; Iter    74/ 1097] train: loss: 0.0584416
[Epoch 9; Iter   104/ 1097] train: loss: 0.0313809
[Epoch 9; Iter   134/ 1097] train: loss: 0.0675386
[Epoch 9; Iter   164/ 1097] train: loss: 0.0361938
[Epoch 9; Iter   194/ 1097] train: loss: 0.0355937
[Epoch 9; Iter   224/ 1097] train: loss: 0.3040242
[Epoch 9; Iter   254/ 1097] train: loss: 0.1445409
[Epoch 9; Iter   284/ 1097] train: loss: 0.1912474
[Epoch 9; Iter   314/ 1097] train: loss: 0.2836005
[Epoch 9; Iter   344/ 1097] train: loss: 0.0309023
[Epoch 9; Iter   374/ 1097] train: loss: 0.1655256
[Epoch 9; Iter   404/ 1097] train: loss: 0.1621205
[Epoch 9; Iter   434/ 1097] train: loss: 0.1044157
[Epoch 9; Iter   464/ 1097] train: loss: 0.0455635
[Epoch 9; Iter   494/ 1097] train: loss: 0.1479684
[Epoch 9; Iter   524/ 1097] train: loss: 0.0255413
[Epoch 9; Iter   554/ 1097] train: loss: 0.0709197
[Epoch 9; Iter   584/ 1097] train: loss: 0.1454996
[Epoch 9; Iter   614/ 1097] train: loss: 0.0388223
[Epoch 9; Iter   644/ 1097] train: loss: 0.1958361
[Epoch 9; Iter   674/ 1097] train: loss: 0.2187643
[Epoch 9; Iter   704/ 1097] train: loss: 0.0295177
[Epoch 9; Iter   734/ 1097] train: loss: 0.0321780
[Epoch 9; Iter   764/ 1097] train: loss: 0.1332718
[Epoch 9; Iter   794/ 1097] train: loss: 0.0451432
[Epoch 9; Iter   824/ 1097] train: loss: 0.0259479
[Epoch 9; Iter   854/ 1097] train: loss: 0.0267555
[Epoch 9; Iter   884/ 1097] train: loss: 0.3149056
[Epoch 9; Iter   914/ 1097] train: loss: 0.0647642
[Epoch 9; Iter   944/ 1097] train: loss: 0.1915157
[Epoch 9; Iter   974/ 1097] train: loss: 0.0315406
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0366652
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0335952
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2703397
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0316344
[Epoch 9] ogbg-molhiv: 0.685234 val loss: 0.113796
[Epoch 9] ogbg-molhiv: 0.698973 test loss: 0.133961
[Epoch 10; Iter    27/ 1097] train: loss: 0.2148806
[Epoch 10; Iter    57/ 1097] train: loss: 0.3331325
[Epoch 10; Iter    87/ 1097] train: loss: 0.0597125
[Epoch 10; Iter   117/ 1097] train: loss: 0.2292923
[Epoch 10; Iter   147/ 1097] train: loss: 0.0441930
[Epoch 10; Iter   177/ 1097] train: loss: 0.5218574
[Epoch 10; Iter   207/ 1097] train: loss: 0.0971769
[Epoch 10; Iter   237/ 1097] train: loss: 0.0435170
[Epoch 10; Iter   267/ 1097] train: loss: 0.1137457
[Epoch 10; Iter   297/ 1097] train: loss: 0.2974398
[Epoch 10; Iter   327/ 1097] train: loss: 0.2460714
[Epoch 10; Iter   357/ 1097] train: loss: 0.0592943
[Epoch 10; Iter   387/ 1097] train: loss: 0.1248136
[Epoch 10; Iter   417/ 1097] train: loss: 0.2850426
[Epoch 10; Iter   447/ 1097] train: loss: 0.1521753
[Epoch 10; Iter   477/ 1097] train: loss: 0.0331392
[Epoch 10; Iter   507/ 1097] train: loss: 0.0287184
[Epoch 10; Iter   537/ 1097] train: loss: 0.1974556
[Epoch 10; Iter   567/ 1097] train: loss: 0.1973558
[Epoch 10; Iter   597/ 1097] train: loss: 0.1288655
[Epoch 10; Iter   627/ 1097] train: loss: 0.0496500
[Epoch 10; Iter   657/ 1097] train: loss: 0.2455935
[Epoch 10; Iter   687/ 1097] train: loss: 0.1522916
[Epoch 10; Iter   717/ 1097] train: loss: 0.3081253
[Epoch 10; Iter   747/ 1097] train: loss: 0.0314416
[Epoch 10; Iter   777/ 1097] train: loss: 0.0304150
[Epoch 10; Iter   807/ 1097] train: loss: 0.3144713
[Epoch 10; Iter   837/ 1097] train: loss: 0.0404225
[Epoch 10; Iter   867/ 1097] train: loss: 0.0353066
[Epoch 10; Iter   897/ 1097] train: loss: 0.0686141
[Epoch 10; Iter   927/ 1097] train: loss: 0.1963056
[Epoch 10; Iter   957/ 1097] train: loss: 0.0998929
[Epoch 10; Iter   987/ 1097] train: loss: 0.5547168
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0275625
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0777567
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1866972
[Epoch 10] ogbg-molhiv: 0.747459 val loss: 0.090617
[Epoch 10] ogbg-molhiv: 0.739613 test loss: 0.123465
[Epoch 11; Iter    10/ 1097] train: loss: 0.3279751
[Epoch 11; Iter    40/ 1097] train: loss: 0.1598402
[Epoch 11; Iter    70/ 1097] train: loss: 0.1018990
[Epoch 11; Iter   100/ 1097] train: loss: 0.0912636
[Epoch 11; Iter   130/ 1097] train: loss: 0.3565854
[Epoch 11; Iter   160/ 1097] train: loss: 0.1535415
[Epoch 11; Iter   190/ 1097] train: loss: 0.0354441
[Epoch 11; Iter   220/ 1097] train: loss: 0.2389396
[Epoch 11; Iter   250/ 1097] train: loss: 0.0396797
[Epoch 11; Iter   280/ 1097] train: loss: 0.1482088
[Epoch 11; Iter   310/ 1097] train: loss: 0.1216077
[Epoch 11; Iter   340/ 1097] train: loss: 0.0408329
[Epoch 11; Iter   370/ 1097] train: loss: 0.0265129
[Epoch 11; Iter   400/ 1097] train: loss: 0.2375425
[Epoch 11; Iter   430/ 1097] train: loss: 0.0329710
[Epoch 11; Iter   460/ 1097] train: loss: 0.0910492
[Epoch 11; Iter   490/ 1097] train: loss: 0.2890419
[Epoch 11; Iter   520/ 1097] train: loss: 0.1144608
[Epoch 11; Iter   550/ 1097] train: loss: 0.0271766
[Epoch 11; Iter   580/ 1097] train: loss: 0.5255173
[Epoch 11; Iter   610/ 1097] train: loss: 0.1909676
[Epoch 11; Iter   640/ 1097] train: loss: 0.1633341
[Epoch 11; Iter   670/ 1097] train: loss: 0.0299098
[Epoch 11; Iter   700/ 1097] train: loss: 0.1475938
[Epoch 11; Iter   730/ 1097] train: loss: 0.1976753
[Epoch 11; Iter   760/ 1097] train: loss: 0.1693004
[Epoch 11; Iter   790/ 1097] train: loss: 0.1843353
[Epoch 11; Iter   820/ 1097] train: loss: 0.1098522
[Epoch 11; Iter   850/ 1097] train: loss: 0.2161581
[Epoch 11; Iter   880/ 1097] train: loss: 0.0317774
[Epoch 11; Iter   910/ 1097] train: loss: 0.0559299
[Epoch 11; Iter   940/ 1097] train: loss: 0.2260659
[Epoch 11; Iter   970/ 1097] train: loss: 0.0287130
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0924330
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1640408
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1868604
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0402989
[Epoch 11] ogbg-molhiv: 0.732005 val loss: 0.154345
[Epoch 11] ogbg-molhiv: 0.672133 test loss: 0.130188
[Epoch 12; Iter    23/ 1097] train: loss: 0.2154695
[Epoch 12; Iter    53/ 1097] train: loss: 0.0324589
[Epoch 12; Iter    83/ 1097] train: loss: 0.1186969
[Epoch 12; Iter   113/ 1097] train: loss: 0.1585730
[Epoch 8; Iter    31/ 1097] train: loss: 0.0568503
[Epoch 8; Iter    61/ 1097] train: loss: 0.0770504
[Epoch 8; Iter    91/ 1097] train: loss: 0.1636009
[Epoch 8; Iter   121/ 1097] train: loss: 0.1467500
[Epoch 8; Iter   151/ 1097] train: loss: 0.0369235
[Epoch 8; Iter   181/ 1097] train: loss: 0.0632619
[Epoch 8; Iter   211/ 1097] train: loss: 0.0517194
[Epoch 8; Iter   241/ 1097] train: loss: 0.0445989
[Epoch 8; Iter   271/ 1097] train: loss: 0.1825008
[Epoch 8; Iter   301/ 1097] train: loss: 0.2244637
[Epoch 8; Iter   331/ 1097] train: loss: 0.0474162
[Epoch 8; Iter   361/ 1097] train: loss: 0.1482891
[Epoch 8; Iter   391/ 1097] train: loss: 0.0249271
[Epoch 8; Iter   421/ 1097] train: loss: 0.2810229
[Epoch 8; Iter   451/ 1097] train: loss: 0.1902758
[Epoch 8; Iter   481/ 1097] train: loss: 0.0430967
[Epoch 8; Iter   511/ 1097] train: loss: 0.1498182
[Epoch 8; Iter   541/ 1097] train: loss: 0.1625153
[Epoch 8; Iter   571/ 1097] train: loss: 0.1128557
[Epoch 8; Iter   601/ 1097] train: loss: 0.3985375
[Epoch 8; Iter   631/ 1097] train: loss: 0.0374036
[Epoch 8; Iter   661/ 1097] train: loss: 0.2631443
[Epoch 8; Iter   691/ 1097] train: loss: 0.1045685
[Epoch 8; Iter   721/ 1097] train: loss: 0.0719802
[Epoch 8; Iter   751/ 1097] train: loss: 0.1209546
[Epoch 8; Iter   781/ 1097] train: loss: 0.2056835
[Epoch 8; Iter   811/ 1097] train: loss: 0.1983646
[Epoch 8; Iter   841/ 1097] train: loss: 0.3244290
[Epoch 8; Iter   871/ 1097] train: loss: 0.2532241
[Epoch 8; Iter   901/ 1097] train: loss: 0.0381008
[Epoch 8; Iter   931/ 1097] train: loss: 0.1757964
[Epoch 8; Iter   961/ 1097] train: loss: 0.0390308
[Epoch 8; Iter   991/ 1097] train: loss: 0.1131080
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2904903
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0356392
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0937853
[Epoch 8] ogbg-molhiv: 0.782380 val loss: 0.142735
[Epoch 8] ogbg-molhiv: 0.674266 test loss: 0.151864
[Epoch 9; Iter    14/ 1097] train: loss: 0.2385674
[Epoch 9; Iter    44/ 1097] train: loss: 0.0304561
[Epoch 9; Iter    74/ 1097] train: loss: 0.0260074
[Epoch 9; Iter   104/ 1097] train: loss: 0.2915013
[Epoch 9; Iter   134/ 1097] train: loss: 0.0899518
[Epoch 9; Iter   164/ 1097] train: loss: 0.1868142
[Epoch 9; Iter   194/ 1097] train: loss: 0.0969824
[Epoch 9; Iter   224/ 1097] train: loss: 0.0351474
[Epoch 9; Iter   254/ 1097] train: loss: 0.3464904
[Epoch 9; Iter   284/ 1097] train: loss: 0.1694883
[Epoch 9; Iter   314/ 1097] train: loss: 0.1240109
[Epoch 9; Iter   344/ 1097] train: loss: 0.5108334
[Epoch 9; Iter   374/ 1097] train: loss: 0.1620530
[Epoch 9; Iter   404/ 1097] train: loss: 0.2163252
[Epoch 9; Iter   434/ 1097] train: loss: 0.0563904
[Epoch 9; Iter   464/ 1097] train: loss: 0.0397623
[Epoch 9; Iter   494/ 1097] train: loss: 0.1718419
[Epoch 9; Iter   524/ 1097] train: loss: 0.0292300
[Epoch 9; Iter   554/ 1097] train: loss: 0.0360568
[Epoch 9; Iter   584/ 1097] train: loss: 0.4766830
[Epoch 9; Iter   614/ 1097] train: loss: 0.0962376
[Epoch 9; Iter   644/ 1097] train: loss: 0.2825446
[Epoch 9; Iter   674/ 1097] train: loss: 0.4605023
[Epoch 9; Iter   704/ 1097] train: loss: 0.1264534
[Epoch 9; Iter   734/ 1097] train: loss: 0.0758393
[Epoch 9; Iter   764/ 1097] train: loss: 0.2335862
[Epoch 9; Iter   794/ 1097] train: loss: 0.1703622
[Epoch 9; Iter   824/ 1097] train: loss: 0.0344317
[Epoch 9; Iter   854/ 1097] train: loss: 0.0417101
[Epoch 9; Iter   884/ 1097] train: loss: 0.1252564
[Epoch 9; Iter   914/ 1097] train: loss: 0.1891305
[Epoch 9; Iter   944/ 1097] train: loss: 0.0653491
[Epoch 9; Iter   974/ 1097] train: loss: 0.0657279
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2107527
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2567781
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3298309
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2685730
[Epoch 9] ogbg-molhiv: 0.719773 val loss: 0.098232
[Epoch 9] ogbg-molhiv: 0.712015 test loss: 0.123155
[Epoch 10; Iter    27/ 1097] train: loss: 0.0329493
[Epoch 10; Iter    57/ 1097] train: loss: 0.0292284
[Epoch 10; Iter    87/ 1097] train: loss: 0.1411125
[Epoch 10; Iter   117/ 1097] train: loss: 0.0370558
[Epoch 10; Iter   147/ 1097] train: loss: 0.4336639
[Epoch 10; Iter   177/ 1097] train: loss: 0.1784294
[Epoch 10; Iter   207/ 1097] train: loss: 0.2570923
[Epoch 10; Iter   237/ 1097] train: loss: 0.0410684
[Epoch 10; Iter   267/ 1097] train: loss: 0.0338408
[Epoch 10; Iter   297/ 1097] train: loss: 0.1949017
[Epoch 10; Iter   327/ 1097] train: loss: 0.0277505
[Epoch 10; Iter   357/ 1097] train: loss: 0.1884570
[Epoch 10; Iter   387/ 1097] train: loss: 0.1378363
[Epoch 10; Iter   417/ 1097] train: loss: 0.1196844
[Epoch 10; Iter   447/ 1097] train: loss: 0.1642013
[Epoch 10; Iter   477/ 1097] train: loss: 0.1534615
[Epoch 10; Iter   507/ 1097] train: loss: 0.1050934
[Epoch 10; Iter   537/ 1097] train: loss: 0.0281977
[Epoch 10; Iter   567/ 1097] train: loss: 0.0374318
[Epoch 10; Iter   597/ 1097] train: loss: 0.0254097
[Epoch 10; Iter   627/ 1097] train: loss: 0.2524976
[Epoch 10; Iter   657/ 1097] train: loss: 0.1405741
[Epoch 10; Iter   687/ 1097] train: loss: 0.0513998
[Epoch 10; Iter   717/ 1097] train: loss: 0.1655097
[Epoch 10; Iter   747/ 1097] train: loss: 0.2603835
[Epoch 10; Iter   777/ 1097] train: loss: 0.2360349
[Epoch 10; Iter   807/ 1097] train: loss: 0.0353345
[Epoch 10; Iter   837/ 1097] train: loss: 0.0333419
[Epoch 10; Iter   867/ 1097] train: loss: 0.0684335
[Epoch 10; Iter   897/ 1097] train: loss: 0.0349516
[Epoch 10; Iter   927/ 1097] train: loss: 0.1626694
[Epoch 10; Iter   957/ 1097] train: loss: 0.0404857
[Epoch 10; Iter   987/ 1097] train: loss: 0.3200453
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2498357
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1661776
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0310615
[Epoch 10] ogbg-molhiv: 0.758485 val loss: 0.415161
[Epoch 10] ogbg-molhiv: 0.668981 test loss: 0.217508
[Epoch 11; Iter    10/ 1097] train: loss: 0.3155675
[Epoch 11; Iter    40/ 1097] train: loss: 0.0397752
[Epoch 11; Iter    70/ 1097] train: loss: 0.1509663
[Epoch 11; Iter   100/ 1097] train: loss: 0.0225931
[Epoch 11; Iter   130/ 1097] train: loss: 0.1808598
[Epoch 11; Iter   160/ 1097] train: loss: 0.0598963
[Epoch 11; Iter   190/ 1097] train: loss: 0.2656153
[Epoch 11; Iter   220/ 1097] train: loss: 0.3070143
[Epoch 11; Iter   250/ 1097] train: loss: 0.1670629
[Epoch 11; Iter   280/ 1097] train: loss: 0.0462620
[Epoch 11; Iter   310/ 1097] train: loss: 0.2511026
[Epoch 11; Iter   340/ 1097] train: loss: 0.0359779
[Epoch 11; Iter   370/ 1097] train: loss: 0.1230808
[Epoch 11; Iter   400/ 1097] train: loss: 0.0379692
[Epoch 11; Iter   430/ 1097] train: loss: 0.2764808
[Epoch 11; Iter   460/ 1097] train: loss: 0.1963241
[Epoch 11; Iter   490/ 1097] train: loss: 0.2589507
[Epoch 11; Iter   520/ 1097] train: loss: 0.1765129
[Epoch 11; Iter   550/ 1097] train: loss: 0.0271601
[Epoch 11; Iter   580/ 1097] train: loss: 0.0413214
[Epoch 11; Iter   610/ 1097] train: loss: 0.0352994
[Epoch 11; Iter   640/ 1097] train: loss: 0.0278192
[Epoch 11; Iter   670/ 1097] train: loss: 0.1795230
[Epoch 11; Iter   700/ 1097] train: loss: 0.2085162
[Epoch 11; Iter   730/ 1097] train: loss: 0.0371262
[Epoch 11; Iter   760/ 1097] train: loss: 0.1781865
[Epoch 11; Iter   790/ 1097] train: loss: 0.1674932
[Epoch 11; Iter   820/ 1097] train: loss: 0.0624223
[Epoch 11; Iter   850/ 1097] train: loss: 0.0419491
[Epoch 11; Iter   880/ 1097] train: loss: 0.2985539
[Epoch 11; Iter   910/ 1097] train: loss: 0.2972180
[Epoch 11; Iter   940/ 1097] train: loss: 0.2846560
[Epoch 11; Iter   970/ 1097] train: loss: 0.2948024
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0566353
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0223680
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2545290
[Epoch 11; Iter  1090/ 1097] train: loss: 0.5209068
[Epoch 11] ogbg-molhiv: 0.787285 val loss: 0.645424
[Epoch 11] ogbg-molhiv: 0.691217 test loss: 0.220095
[Epoch 12; Iter    23/ 1097] train: loss: 0.2146482
[Epoch 12; Iter    53/ 1097] train: loss: 0.0336658
[Epoch 12; Iter    83/ 1097] train: loss: 0.0281329
[Epoch 12; Iter   113/ 1097] train: loss: 0.0579354
[Epoch 8; Iter    31/ 1097] train: loss: 0.2033134
[Epoch 8; Iter    61/ 1097] train: loss: 0.3232028
[Epoch 8; Iter    91/ 1097] train: loss: 0.3632747
[Epoch 8; Iter   121/ 1097] train: loss: 0.0362398
[Epoch 8; Iter   151/ 1097] train: loss: 0.4467430
[Epoch 8; Iter   181/ 1097] train: loss: 0.2313928
[Epoch 8; Iter   211/ 1097] train: loss: 0.2160726
[Epoch 8; Iter   241/ 1097] train: loss: 0.0369030
[Epoch 8; Iter   271/ 1097] train: loss: 0.1979425
[Epoch 8; Iter   301/ 1097] train: loss: 0.0295301
[Epoch 8; Iter   331/ 1097] train: loss: 0.0516758
[Epoch 8; Iter   361/ 1097] train: loss: 0.1037625
[Epoch 8; Iter   391/ 1097] train: loss: 0.0835985
[Epoch 8; Iter   421/ 1097] train: loss: 0.2643563
[Epoch 8; Iter   451/ 1097] train: loss: 0.0237527
[Epoch 8; Iter   481/ 1097] train: loss: 0.1025555
[Epoch 8; Iter   511/ 1097] train: loss: 0.1383184
[Epoch 8; Iter   541/ 1097] train: loss: 0.0351347
[Epoch 8; Iter   571/ 1097] train: loss: 0.3903899
[Epoch 8; Iter   601/ 1097] train: loss: 0.1243466
[Epoch 8; Iter   631/ 1097] train: loss: 0.0657100
[Epoch 8; Iter   661/ 1097] train: loss: 0.0370348
[Epoch 8; Iter   691/ 1097] train: loss: 0.1583113
[Epoch 8; Iter   721/ 1097] train: loss: 0.0809360
[Epoch 8; Iter   751/ 1097] train: loss: 0.0284903
[Epoch 8; Iter   781/ 1097] train: loss: 0.2530824
[Epoch 8; Iter   811/ 1097] train: loss: 0.0914010
[Epoch 8; Iter   841/ 1097] train: loss: 0.0466729
[Epoch 8; Iter   871/ 1097] train: loss: 0.1445017
[Epoch 8; Iter   901/ 1097] train: loss: 0.0354893
[Epoch 8; Iter   931/ 1097] train: loss: 0.0892367
[Epoch 8; Iter   961/ 1097] train: loss: 0.0505048
[Epoch 8; Iter   991/ 1097] train: loss: 0.0320372
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0249794
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0212058
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1358271
[Epoch 8] ogbg-molhiv: 0.725407 val loss: 0.135371
[Epoch 8] ogbg-molhiv: 0.712098 test loss: 0.125849
[Epoch 9; Iter    14/ 1097] train: loss: 0.0269039
[Epoch 9; Iter    44/ 1097] train: loss: 0.0390460
[Epoch 9; Iter    74/ 1097] train: loss: 0.1940593
[Epoch 9; Iter   104/ 1097] train: loss: 0.4477288
[Epoch 9; Iter   134/ 1097] train: loss: 0.2287705
[Epoch 9; Iter   164/ 1097] train: loss: 0.0403800
[Epoch 9; Iter   194/ 1097] train: loss: 0.0364857
[Epoch 9; Iter   224/ 1097] train: loss: 0.0317584
[Epoch 9; Iter   254/ 1097] train: loss: 0.1860769
[Epoch 9; Iter   284/ 1097] train: loss: 0.0486534
[Epoch 9; Iter   314/ 1097] train: loss: 0.0359350
[Epoch 9; Iter   344/ 1097] train: loss: 0.0552567
[Epoch 9; Iter   374/ 1097] train: loss: 0.0321440
[Epoch 9; Iter   404/ 1097] train: loss: 0.0996550
[Epoch 9; Iter   434/ 1097] train: loss: 0.1843560
[Epoch 9; Iter   464/ 1097] train: loss: 0.1884314
[Epoch 9; Iter   494/ 1097] train: loss: 0.1217115
[Epoch 9; Iter   524/ 1097] train: loss: 0.0869865
[Epoch 9; Iter   554/ 1097] train: loss: 0.0393979
[Epoch 9; Iter   584/ 1097] train: loss: 0.1936231
[Epoch 9; Iter   614/ 1097] train: loss: 0.0400128
[Epoch 9; Iter   644/ 1097] train: loss: 0.1822998
[Epoch 9; Iter   674/ 1097] train: loss: 0.0672162
[Epoch 9; Iter   704/ 1097] train: loss: 0.0236279
[Epoch 9; Iter   734/ 1097] train: loss: 0.1893883
[Epoch 9; Iter   764/ 1097] train: loss: 0.0918800
[Epoch 9; Iter   794/ 1097] train: loss: 0.0901714
[Epoch 9; Iter   824/ 1097] train: loss: 0.0350758
[Epoch 9; Iter   854/ 1097] train: loss: 0.0397158
[Epoch 9; Iter   884/ 1097] train: loss: 0.2142241
[Epoch 9; Iter   914/ 1097] train: loss: 0.0301252
[Epoch 9; Iter   944/ 1097] train: loss: 0.1487607
[Epoch 9; Iter   974/ 1097] train: loss: 0.0352763
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1458121
[Epoch 9; Iter  1034/ 1097] train: loss: 0.1062025
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0473391
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0480501
[Epoch 9] ogbg-molhiv: 0.717391 val loss: 0.234183
[Epoch 9] ogbg-molhiv: 0.666944 test loss: 0.174038
[Epoch 10; Iter    27/ 1097] train: loss: 0.1722237
[Epoch 10; Iter    57/ 1097] train: loss: 0.0305819
[Epoch 10; Iter    87/ 1097] train: loss: 0.1270786
[Epoch 10; Iter   117/ 1097] train: loss: 0.0497919
[Epoch 10; Iter   147/ 1097] train: loss: 0.0300198
[Epoch 10; Iter   177/ 1097] train: loss: 0.0307631
[Epoch 10; Iter   207/ 1097] train: loss: 0.0386699
[Epoch 10; Iter   237/ 1097] train: loss: 0.0303946
[Epoch 10; Iter   267/ 1097] train: loss: 0.0276133
[Epoch 10; Iter   297/ 1097] train: loss: 0.0360783
[Epoch 10; Iter   327/ 1097] train: loss: 0.0315360
[Epoch 10; Iter   357/ 1097] train: loss: 0.1673039
[Epoch 10; Iter   387/ 1097] train: loss: 0.2058990
[Epoch 10; Iter   417/ 1097] train: loss: 0.0293085
[Epoch 10; Iter   447/ 1097] train: loss: 0.0472965
[Epoch 10; Iter   477/ 1097] train: loss: 0.0477696
[Epoch 10; Iter   507/ 1097] train: loss: 0.0929137
[Epoch 10; Iter   537/ 1097] train: loss: 0.0387951
[Epoch 10; Iter   567/ 1097] train: loss: 0.1694190
[Epoch 10; Iter   597/ 1097] train: loss: 0.1527404
[Epoch 10; Iter   627/ 1097] train: loss: 0.1998762
[Epoch 10; Iter   657/ 1097] train: loss: 0.0262568
[Epoch 10; Iter   687/ 1097] train: loss: 0.1966647
[Epoch 10; Iter   717/ 1097] train: loss: 0.0610645
[Epoch 10; Iter   747/ 1097] train: loss: 0.3231729
[Epoch 10; Iter   777/ 1097] train: loss: 0.0785916
[Epoch 10; Iter   807/ 1097] train: loss: 0.0941777
[Epoch 10; Iter   837/ 1097] train: loss: 0.0422512
[Epoch 10; Iter   867/ 1097] train: loss: 0.3821048
[Epoch 10; Iter   897/ 1097] train: loss: 0.1558621
[Epoch 10; Iter   927/ 1097] train: loss: 0.2498914
[Epoch 10; Iter   957/ 1097] train: loss: 0.2058794
[Epoch 10; Iter   987/ 1097] train: loss: 0.3017388
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0680555
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1493767
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1740931
[Epoch 10] ogbg-molhiv: 0.621136 val loss: 0.190987
[Epoch 10] ogbg-molhiv: 0.701317 test loss: 0.139039
[Epoch 11; Iter    10/ 1097] train: loss: 0.0312606
[Epoch 11; Iter    40/ 1097] train: loss: 0.0399120
[Epoch 11; Iter    70/ 1097] train: loss: 0.0387033
[Epoch 11; Iter   100/ 1097] train: loss: 0.1357335
[Epoch 11; Iter   130/ 1097] train: loss: 0.0377272
[Epoch 11; Iter   160/ 1097] train: loss: 0.0897730
[Epoch 11; Iter   190/ 1097] train: loss: 0.1134228
[Epoch 11; Iter   220/ 1097] train: loss: 0.0743304
[Epoch 11; Iter   250/ 1097] train: loss: 0.1567334
[Epoch 11; Iter   280/ 1097] train: loss: 0.2468249
[Epoch 11; Iter   310/ 1097] train: loss: 0.1349250
[Epoch 11; Iter   340/ 1097] train: loss: 0.0465707
[Epoch 11; Iter   370/ 1097] train: loss: 0.2914699
[Epoch 11; Iter   400/ 1097] train: loss: 0.0650272
[Epoch 11; Iter   430/ 1097] train: loss: 0.2250197
[Epoch 11; Iter   460/ 1097] train: loss: 0.1721671
[Epoch 11; Iter   490/ 1097] train: loss: 0.1822654
[Epoch 11; Iter   520/ 1097] train: loss: 0.4366928
[Epoch 11; Iter   550/ 1097] train: loss: 0.1210231
[Epoch 11; Iter   580/ 1097] train: loss: 0.1733442
[Epoch 11; Iter   610/ 1097] train: loss: 0.0267227
[Epoch 11; Iter   640/ 1097] train: loss: 0.0262306
[Epoch 11; Iter   670/ 1097] train: loss: 0.0344298
[Epoch 11; Iter   700/ 1097] train: loss: 0.0356475
[Epoch 11; Iter   730/ 1097] train: loss: 0.1412458
[Epoch 11; Iter   760/ 1097] train: loss: 0.0317780
[Epoch 11; Iter   790/ 1097] train: loss: 0.0607546
[Epoch 11; Iter   820/ 1097] train: loss: 0.3012912
[Epoch 11; Iter   850/ 1097] train: loss: 0.1968676
[Epoch 11; Iter   880/ 1097] train: loss: 0.0369416
[Epoch 11; Iter   910/ 1097] train: loss: 0.2823261
[Epoch 11; Iter   940/ 1097] train: loss: 0.3798480
[Epoch 11; Iter   970/ 1097] train: loss: 0.1073839
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1824528
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1123935
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2792886
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3230084
[Epoch 11] ogbg-molhiv: 0.723471 val loss: 0.312514
[Epoch 11] ogbg-molhiv: 0.680537 test loss: 0.182318
[Epoch 12; Iter    23/ 1097] train: loss: 0.0626108
[Epoch 12; Iter    53/ 1097] train: loss: 0.0341938
[Epoch 12; Iter    83/ 1097] train: loss: 0.0374013
[Epoch 12; Iter   113/ 1097] train: loss: 0.0259696
[Epoch 8; Iter    31/ 1097] train: loss: 0.0845051
[Epoch 8; Iter    61/ 1097] train: loss: 0.1387685
[Epoch 8; Iter    91/ 1097] train: loss: 0.2453573
[Epoch 8; Iter   121/ 1097] train: loss: 0.1629252
[Epoch 8; Iter   151/ 1097] train: loss: 0.0286842
[Epoch 8; Iter   181/ 1097] train: loss: 0.0383399
[Epoch 8; Iter   211/ 1097] train: loss: 0.0783037
[Epoch 8; Iter   241/ 1097] train: loss: 0.0307167
[Epoch 8; Iter   271/ 1097] train: loss: 0.2147649
[Epoch 8; Iter   301/ 1097] train: loss: 0.2392608
[Epoch 8; Iter   331/ 1097] train: loss: 0.0673665
[Epoch 8; Iter   361/ 1097] train: loss: 0.1843452
[Epoch 8; Iter   391/ 1097] train: loss: 0.0258893
[Epoch 8; Iter   421/ 1097] train: loss: 0.2881369
[Epoch 8; Iter   451/ 1097] train: loss: 0.2284019
[Epoch 8; Iter   481/ 1097] train: loss: 0.0428109
[Epoch 8; Iter   511/ 1097] train: loss: 0.1435844
[Epoch 8; Iter   541/ 1097] train: loss: 0.1186028
[Epoch 8; Iter   571/ 1097] train: loss: 0.1492572
[Epoch 8; Iter   601/ 1097] train: loss: 0.4112956
[Epoch 8; Iter   631/ 1097] train: loss: 0.0363977
[Epoch 8; Iter   661/ 1097] train: loss: 0.2257399
[Epoch 8; Iter   691/ 1097] train: loss: 0.1296429
[Epoch 8; Iter   721/ 1097] train: loss: 0.0735151
[Epoch 8; Iter   751/ 1097] train: loss: 0.1764874
[Epoch 8; Iter   781/ 1097] train: loss: 0.2482015
[Epoch 8; Iter   811/ 1097] train: loss: 0.2302404
[Epoch 8; Iter   841/ 1097] train: loss: 0.3326834
[Epoch 8; Iter   871/ 1097] train: loss: 0.2164177
[Epoch 8; Iter   901/ 1097] train: loss: 0.0413518
[Epoch 8; Iter   931/ 1097] train: loss: 0.1827054
[Epoch 8; Iter   961/ 1097] train: loss: 0.0320741
[Epoch 8; Iter   991/ 1097] train: loss: 0.1227218
[Epoch 8; Iter  1021/ 1097] train: loss: 0.2589902
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0376825
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1136968
[Epoch 8] ogbg-molhiv: 0.759823 val loss: 1.781314
[Epoch 8] ogbg-molhiv: 0.666083 test loss: 2.836967
[Epoch 9; Iter    14/ 1097] train: loss: 0.2442216
[Epoch 9; Iter    44/ 1097] train: loss: 0.0280467
[Epoch 9; Iter    74/ 1097] train: loss: 0.0276209
[Epoch 9; Iter   104/ 1097] train: loss: 0.3541368
[Epoch 9; Iter   134/ 1097] train: loss: 0.1054018
[Epoch 9; Iter   164/ 1097] train: loss: 0.1763356
[Epoch 9; Iter   194/ 1097] train: loss: 0.0992268
[Epoch 9; Iter   224/ 1097] train: loss: 0.0335946
[Epoch 9; Iter   254/ 1097] train: loss: 0.3378912
[Epoch 9; Iter   284/ 1097] train: loss: 0.1889810
[Epoch 9; Iter   314/ 1097] train: loss: 0.1203737
[Epoch 9; Iter   344/ 1097] train: loss: 0.5019749
[Epoch 9; Iter   374/ 1097] train: loss: 0.1331854
[Epoch 9; Iter   404/ 1097] train: loss: 0.2141980
[Epoch 9; Iter   434/ 1097] train: loss: 0.0945333
[Epoch 9; Iter   464/ 1097] train: loss: 0.0323004
[Epoch 9; Iter   494/ 1097] train: loss: 0.2068875
[Epoch 9; Iter   524/ 1097] train: loss: 0.0293742
[Epoch 9; Iter   554/ 1097] train: loss: 0.0337474
[Epoch 9; Iter   584/ 1097] train: loss: 0.5258266
[Epoch 9; Iter   614/ 1097] train: loss: 0.1200149
[Epoch 9; Iter   644/ 1097] train: loss: 0.2432101
[Epoch 9; Iter   674/ 1097] train: loss: 0.4381481
[Epoch 9; Iter   704/ 1097] train: loss: 0.1313169
[Epoch 9; Iter   734/ 1097] train: loss: 0.1199817
[Epoch 9; Iter   764/ 1097] train: loss: 0.2117273
[Epoch 9; Iter   794/ 1097] train: loss: 0.1646829
[Epoch 9; Iter   824/ 1097] train: loss: 0.0367116
[Epoch 9; Iter   854/ 1097] train: loss: 0.0484328
[Epoch 9; Iter   884/ 1097] train: loss: 0.1059538
[Epoch 9; Iter   914/ 1097] train: loss: 0.1952005
[Epoch 9; Iter   944/ 1097] train: loss: 0.0894962
[Epoch 9; Iter   974/ 1097] train: loss: 0.1193414
[Epoch 9; Iter  1004/ 1097] train: loss: 0.2552078
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2744025
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3081514
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2968633
[Epoch 9] ogbg-molhiv: 0.770007 val loss: 0.236476
[Epoch 9] ogbg-molhiv: 0.667539 test loss: 0.517989
[Epoch 10; Iter    27/ 1097] train: loss: 0.0352908
[Epoch 10; Iter    57/ 1097] train: loss: 0.0316136
[Epoch 10; Iter    87/ 1097] train: loss: 0.2053203
[Epoch 10; Iter   117/ 1097] train: loss: 0.0389370
[Epoch 10; Iter   147/ 1097] train: loss: 0.4322790
[Epoch 10; Iter   177/ 1097] train: loss: 0.2498615
[Epoch 10; Iter   207/ 1097] train: loss: 0.2695621
[Epoch 10; Iter   237/ 1097] train: loss: 0.0342884
[Epoch 10; Iter   267/ 1097] train: loss: 0.0667593
[Epoch 10; Iter   297/ 1097] train: loss: 0.1763335
[Epoch 10; Iter   327/ 1097] train: loss: 0.0272330
[Epoch 10; Iter   357/ 1097] train: loss: 0.2343376
[Epoch 10; Iter   387/ 1097] train: loss: 0.1597679
[Epoch 10; Iter   417/ 1097] train: loss: 0.1165557
[Epoch 10; Iter   447/ 1097] train: loss: 0.1851401
[Epoch 10; Iter   477/ 1097] train: loss: 0.2324127
[Epoch 10; Iter   507/ 1097] train: loss: 0.1496673
[Epoch 10; Iter   537/ 1097] train: loss: 0.0266675
[Epoch 10; Iter   567/ 1097] train: loss: 0.0322189
[Epoch 10; Iter   597/ 1097] train: loss: 0.0270726
[Epoch 10; Iter   627/ 1097] train: loss: 0.1982727
[Epoch 10; Iter   657/ 1097] train: loss: 0.1815921
[Epoch 10; Iter   687/ 1097] train: loss: 0.0789622
[Epoch 10; Iter   717/ 1097] train: loss: 0.1553007
[Epoch 10; Iter   747/ 1097] train: loss: 0.2715979
[Epoch 10; Iter   777/ 1097] train: loss: 0.2108806
[Epoch 10; Iter   807/ 1097] train: loss: 0.0370217
[Epoch 10; Iter   837/ 1097] train: loss: 0.0307123
[Epoch 10; Iter   867/ 1097] train: loss: 0.1274814
[Epoch 10; Iter   897/ 1097] train: loss: 0.0310813
[Epoch 10; Iter   927/ 1097] train: loss: 0.1739047
[Epoch 10; Iter   957/ 1097] train: loss: 0.0369106
[Epoch 10; Iter   987/ 1097] train: loss: 0.2869523
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2203669
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1367154
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0403875
[Epoch 10] ogbg-molhiv: 0.776210 val loss: 1.255918
[Epoch 10] ogbg-molhiv: 0.699444 test loss: 1.335835
[Epoch 11; Iter    10/ 1097] train: loss: 0.3073979
[Epoch 11; Iter    40/ 1097] train: loss: 0.0399401
[Epoch 11; Iter    70/ 1097] train: loss: 0.1450928
[Epoch 11; Iter   100/ 1097] train: loss: 0.0289827
[Epoch 11; Iter   130/ 1097] train: loss: 0.1838804
[Epoch 11; Iter   160/ 1097] train: loss: 0.0411239
[Epoch 11; Iter   190/ 1097] train: loss: 0.3304474
[Epoch 11; Iter   220/ 1097] train: loss: 0.3718055
[Epoch 11; Iter   250/ 1097] train: loss: 0.1380325
[Epoch 11; Iter   280/ 1097] train: loss: 0.0429573
[Epoch 11; Iter   310/ 1097] train: loss: 0.2416587
[Epoch 11; Iter   340/ 1097] train: loss: 0.0375321
[Epoch 11; Iter   370/ 1097] train: loss: 0.1431957
[Epoch 11; Iter   400/ 1097] train: loss: 0.0351707
[Epoch 11; Iter   430/ 1097] train: loss: 0.2608719
[Epoch 11; Iter   460/ 1097] train: loss: 0.1335330
[Epoch 11; Iter   490/ 1097] train: loss: 0.2242523
[Epoch 11; Iter   520/ 1097] train: loss: 0.2042516
[Epoch 11; Iter   550/ 1097] train: loss: 0.0317391
[Epoch 11; Iter   580/ 1097] train: loss: 0.0398770
[Epoch 11; Iter   610/ 1097] train: loss: 0.0315512
[Epoch 11; Iter   640/ 1097] train: loss: 0.0583503
[Epoch 11; Iter   670/ 1097] train: loss: 0.1588439
[Epoch 11; Iter   700/ 1097] train: loss: 0.1596007
[Epoch 11; Iter   730/ 1097] train: loss: 0.0411024
[Epoch 11; Iter   760/ 1097] train: loss: 0.1953584
[Epoch 11; Iter   790/ 1097] train: loss: 0.1812940
[Epoch 11; Iter   820/ 1097] train: loss: 0.0702598
[Epoch 11; Iter   850/ 1097] train: loss: 0.0391651
[Epoch 11; Iter   880/ 1097] train: loss: 0.3298931
[Epoch 11; Iter   910/ 1097] train: loss: 0.2593089
[Epoch 11; Iter   940/ 1097] train: loss: 0.2848031
[Epoch 11; Iter   970/ 1097] train: loss: 0.2462741
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0368173
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0267873
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2975116
[Epoch 11; Iter  1090/ 1097] train: loss: 0.5670012
[Epoch 11] ogbg-molhiv: 0.777837 val loss: 0.385024
[Epoch 11] ogbg-molhiv: 0.701141 test loss: 0.370078
[Epoch 12; Iter    23/ 1097] train: loss: 0.1356909
[Epoch 12; Iter    53/ 1097] train: loss: 0.0266395
[Epoch 12; Iter    83/ 1097] train: loss: 0.0475934
[Epoch 12; Iter   113/ 1097] train: loss: 0.0609049
[Epoch 8; Iter    31/ 1097] train: loss: 0.0369872
[Epoch 8; Iter    61/ 1097] train: loss: 0.1708865
[Epoch 8; Iter    91/ 1097] train: loss: 0.1796500
[Epoch 8; Iter   121/ 1097] train: loss: 0.0338934
[Epoch 8; Iter   151/ 1097] train: loss: 0.1439957
[Epoch 8; Iter   181/ 1097] train: loss: 0.0364220
[Epoch 8; Iter   211/ 1097] train: loss: 0.2690040
[Epoch 8; Iter   241/ 1097] train: loss: 0.1521760
[Epoch 8; Iter   271/ 1097] train: loss: 0.2687108
[Epoch 8; Iter   301/ 1097] train: loss: 0.1052815
[Epoch 8; Iter   331/ 1097] train: loss: 0.1366927
[Epoch 8; Iter   361/ 1097] train: loss: 0.0457367
[Epoch 8; Iter   391/ 1097] train: loss: 0.0323332
[Epoch 8; Iter   421/ 1097] train: loss: 0.2547733
[Epoch 8; Iter   451/ 1097] train: loss: 0.0299070
[Epoch 8; Iter   481/ 1097] train: loss: 0.1948381
[Epoch 8; Iter   511/ 1097] train: loss: 0.1632090
[Epoch 8; Iter   541/ 1097] train: loss: 0.0362900
[Epoch 8; Iter   571/ 1097] train: loss: 0.0348183
[Epoch 8; Iter   601/ 1097] train: loss: 0.0321119
[Epoch 8; Iter   631/ 1097] train: loss: 0.1219045
[Epoch 8; Iter   661/ 1097] train: loss: 0.0396192
[Epoch 8; Iter   691/ 1097] train: loss: 0.3403643
[Epoch 8; Iter   721/ 1097] train: loss: 0.0375652
[Epoch 8; Iter   751/ 1097] train: loss: 0.1216982
[Epoch 8; Iter   781/ 1097] train: loss: 0.0509234
[Epoch 8; Iter   811/ 1097] train: loss: 0.0701369
[Epoch 8; Iter   841/ 1097] train: loss: 0.1667145
[Epoch 8; Iter   871/ 1097] train: loss: 0.2874295
[Epoch 8; Iter   901/ 1097] train: loss: 0.0643633
[Epoch 8; Iter   931/ 1097] train: loss: 0.1007430
[Epoch 8; Iter   961/ 1097] train: loss: 0.0302605
[Epoch 8; Iter   991/ 1097] train: loss: 0.0423433
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0448790
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0332198
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3299449
[Epoch 8] ogbg-molhiv: 0.771207 val loss: 2.602481
[Epoch 8] ogbg-molhiv: 0.725935 test loss: 2.216254
[Epoch 9; Iter    14/ 1097] train: loss: 0.0336544
[Epoch 9; Iter    44/ 1097] train: loss: 0.0487355
[Epoch 9; Iter    74/ 1097] train: loss: 0.0686290
[Epoch 9; Iter   104/ 1097] train: loss: 0.0310250
[Epoch 9; Iter   134/ 1097] train: loss: 0.0658826
[Epoch 9; Iter   164/ 1097] train: loss: 0.0357787
[Epoch 9; Iter   194/ 1097] train: loss: 0.0366733
[Epoch 9; Iter   224/ 1097] train: loss: 0.3480607
[Epoch 9; Iter   254/ 1097] train: loss: 0.1360531
[Epoch 9; Iter   284/ 1097] train: loss: 0.1781526
[Epoch 9; Iter   314/ 1097] train: loss: 0.3107009
[Epoch 9; Iter   344/ 1097] train: loss: 0.0304519
[Epoch 9; Iter   374/ 1097] train: loss: 0.1512965
[Epoch 9; Iter   404/ 1097] train: loss: 0.1317468
[Epoch 9; Iter   434/ 1097] train: loss: 0.1030302
[Epoch 9; Iter   464/ 1097] train: loss: 0.0314532
[Epoch 9; Iter   494/ 1097] train: loss: 0.1758379
[Epoch 9; Iter   524/ 1097] train: loss: 0.0303712
[Epoch 9; Iter   554/ 1097] train: loss: 0.0457847
[Epoch 9; Iter   584/ 1097] train: loss: 0.0895943
[Epoch 9; Iter   614/ 1097] train: loss: 0.0413397
[Epoch 9; Iter   644/ 1097] train: loss: 0.2123224
[Epoch 9; Iter   674/ 1097] train: loss: 0.2165705
[Epoch 9; Iter   704/ 1097] train: loss: 0.0598524
[Epoch 9; Iter   734/ 1097] train: loss: 0.0382204
[Epoch 9; Iter   764/ 1097] train: loss: 0.1427070
[Epoch 9; Iter   794/ 1097] train: loss: 0.0348067
[Epoch 9; Iter   824/ 1097] train: loss: 0.0305765
[Epoch 9; Iter   854/ 1097] train: loss: 0.0312307
[Epoch 9; Iter   884/ 1097] train: loss: 0.2590735
[Epoch 9; Iter   914/ 1097] train: loss: 0.0382158
[Epoch 9; Iter   944/ 1097] train: loss: 0.2018643
[Epoch 9; Iter   974/ 1097] train: loss: 0.0335094
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0345972
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0323294
[Epoch 9; Iter  1064/ 1097] train: loss: 0.3164596
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0406856
[Epoch 9] ogbg-molhiv: 0.764106 val loss: 0.135867
[Epoch 9] ogbg-molhiv: 0.681402 test loss: 0.219552
[Epoch 10; Iter    27/ 1097] train: loss: 0.2095932
[Epoch 10; Iter    57/ 1097] train: loss: 0.3120189
[Epoch 10; Iter    87/ 1097] train: loss: 0.0495819
[Epoch 10; Iter   117/ 1097] train: loss: 0.1707294
[Epoch 10; Iter   147/ 1097] train: loss: 0.0411642
[Epoch 10; Iter   177/ 1097] train: loss: 0.4635596
[Epoch 10; Iter   207/ 1097] train: loss: 0.1130047
[Epoch 10; Iter   237/ 1097] train: loss: 0.0334125
[Epoch 10; Iter   267/ 1097] train: loss: 0.0949181
[Epoch 10; Iter   297/ 1097] train: loss: 0.2555238
[Epoch 10; Iter   327/ 1097] train: loss: 0.2466936
[Epoch 10; Iter   357/ 1097] train: loss: 0.0736554
[Epoch 10; Iter   387/ 1097] train: loss: 0.1392738
[Epoch 10; Iter   417/ 1097] train: loss: 0.2867133
[Epoch 10; Iter   447/ 1097] train: loss: 0.1590305
[Epoch 10; Iter   477/ 1097] train: loss: 0.0310155
[Epoch 10; Iter   507/ 1097] train: loss: 0.0354646
[Epoch 10; Iter   537/ 1097] train: loss: 0.1638447
[Epoch 10; Iter   567/ 1097] train: loss: 0.2469102
[Epoch 10; Iter   597/ 1097] train: loss: 0.1296495
[Epoch 10; Iter   627/ 1097] train: loss: 0.0585670
[Epoch 10; Iter   657/ 1097] train: loss: 0.3631325
[Epoch 10; Iter   687/ 1097] train: loss: 0.0719852
[Epoch 10; Iter   717/ 1097] train: loss: 0.3321848
[Epoch 10; Iter   747/ 1097] train: loss: 0.0324270
[Epoch 10; Iter   777/ 1097] train: loss: 0.0287038
[Epoch 10; Iter   807/ 1097] train: loss: 0.3240116
[Epoch 10; Iter   837/ 1097] train: loss: 0.0403966
[Epoch 10; Iter   867/ 1097] train: loss: 0.0288440
[Epoch 10; Iter   897/ 1097] train: loss: 0.0803639
[Epoch 10; Iter   927/ 1097] train: loss: 0.2176873
[Epoch 10; Iter   957/ 1097] train: loss: 0.1223626
[Epoch 10; Iter   987/ 1097] train: loss: 0.5421495
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0306928
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0486814
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1947950
[Epoch 10] ogbg-molhiv: 0.725217 val loss: 3.395544
[Epoch 10] ogbg-molhiv: 0.743019 test loss: 5.269261
[Epoch 11; Iter    10/ 1097] train: loss: 0.3395719
[Epoch 11; Iter    40/ 1097] train: loss: 0.1339689
[Epoch 11; Iter    70/ 1097] train: loss: 0.1291501
[Epoch 11; Iter   100/ 1097] train: loss: 0.1121983
[Epoch 11; Iter   130/ 1097] train: loss: 0.3991802
[Epoch 11; Iter   160/ 1097] train: loss: 0.1817364
[Epoch 11; Iter   190/ 1097] train: loss: 0.0368652
[Epoch 11; Iter   220/ 1097] train: loss: 0.2496651
[Epoch 11; Iter   250/ 1097] train: loss: 0.0829358
[Epoch 11; Iter   280/ 1097] train: loss: 0.1631334
[Epoch 11; Iter   310/ 1097] train: loss: 0.1461347
[Epoch 11; Iter   340/ 1097] train: loss: 0.0466633
[Epoch 11; Iter   370/ 1097] train: loss: 0.0278550
[Epoch 11; Iter   400/ 1097] train: loss: 0.2587382
[Epoch 11; Iter   430/ 1097] train: loss: 0.0315185
[Epoch 11; Iter   460/ 1097] train: loss: 0.0825886
[Epoch 11; Iter   490/ 1097] train: loss: 0.2504677
[Epoch 11; Iter   520/ 1097] train: loss: 0.1388582
[Epoch 11; Iter   550/ 1097] train: loss: 0.0335841
[Epoch 11; Iter   580/ 1097] train: loss: 0.4608571
[Epoch 11; Iter   610/ 1097] train: loss: 0.1805136
[Epoch 11; Iter   640/ 1097] train: loss: 0.0835415
[Epoch 11; Iter   670/ 1097] train: loss: 0.0271705
[Epoch 11; Iter   700/ 1097] train: loss: 0.1366318
[Epoch 11; Iter   730/ 1097] train: loss: 0.2177420
[Epoch 11; Iter   760/ 1097] train: loss: 0.1827734
[Epoch 11; Iter   790/ 1097] train: loss: 0.1550799
[Epoch 11; Iter   820/ 1097] train: loss: 0.0581525
[Epoch 11; Iter   850/ 1097] train: loss: 0.1988565
[Epoch 11; Iter   880/ 1097] train: loss: 0.0360465
[Epoch 11; Iter   910/ 1097] train: loss: 0.0431477
[Epoch 11; Iter   940/ 1097] train: loss: 0.1667951
[Epoch 11; Iter   970/ 1097] train: loss: 0.0321484
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0849334
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1820215
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2065219
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0335006
[Epoch 11] ogbg-molhiv: 0.701769 val loss: 0.495958
[Epoch 11] ogbg-molhiv: 0.688115 test loss: 0.710166
[Epoch 12; Iter    23/ 1097] train: loss: 0.2204628
[Epoch 12; Iter    53/ 1097] train: loss: 0.0426460
[Epoch 12; Iter    83/ 1097] train: loss: 0.1208799
[Epoch 12; Iter   113/ 1097] train: loss: 0.1432618
[Epoch 12; Iter   113/ 1097] train: loss: 0.0246004
[Epoch 12; Iter   143/ 1097] train: loss: 0.0589876
[Epoch 12; Iter   173/ 1097] train: loss: 0.2896870
[Epoch 12; Iter   203/ 1097] train: loss: 0.1221983
[Epoch 12; Iter   233/ 1097] train: loss: 0.3682524
[Epoch 12; Iter   263/ 1097] train: loss: 0.1694853
[Epoch 12; Iter   293/ 1097] train: loss: 0.1720207
[Epoch 12; Iter   323/ 1097] train: loss: 0.0783163
[Epoch 12; Iter   353/ 1097] train: loss: 0.0411792
[Epoch 12; Iter   383/ 1097] train: loss: 0.1371646
[Epoch 12; Iter   413/ 1097] train: loss: 0.0409970
[Epoch 12; Iter   443/ 1097] train: loss: 0.0788874
[Epoch 12; Iter   473/ 1097] train: loss: 0.0416413
[Epoch 12; Iter   503/ 1097] train: loss: 0.0303522
[Epoch 12; Iter   533/ 1097] train: loss: 0.1733277
[Epoch 12; Iter   563/ 1097] train: loss: 0.1876253
[Epoch 12; Iter   593/ 1097] train: loss: 0.2063067
[Epoch 12; Iter   623/ 1097] train: loss: 0.0365396
[Epoch 12; Iter   653/ 1097] train: loss: 0.0293577
[Epoch 12; Iter   683/ 1097] train: loss: 0.0484526
[Epoch 12; Iter   713/ 1097] train: loss: 0.2317706
[Epoch 12; Iter   743/ 1097] train: loss: 0.0359784
[Epoch 12; Iter   773/ 1097] train: loss: 0.3178241
[Epoch 12; Iter   803/ 1097] train: loss: 0.0748798
[Epoch 12; Iter   833/ 1097] train: loss: 0.0423451
[Epoch 12; Iter   863/ 1097] train: loss: 0.0378260
[Epoch 12; Iter   893/ 1097] train: loss: 0.1331571
[Epoch 12; Iter   923/ 1097] train: loss: 0.0462779
[Epoch 12; Iter   953/ 1097] train: loss: 0.0587614
[Epoch 12; Iter   983/ 1097] train: loss: 0.2016383
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0294961
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2035285
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1506728
[Epoch 12] ogbg-molhiv: 0.763022 val loss: 0.092124
[Epoch 12] ogbg-molhiv: 0.711250 test loss: 0.171268
[Epoch 13; Iter     6/ 1097] train: loss: 0.1025046
[Epoch 13; Iter    36/ 1097] train: loss: 0.0472586
[Epoch 13; Iter    66/ 1097] train: loss: 0.0715613
[Epoch 13; Iter    96/ 1097] train: loss: 0.0681208
[Epoch 13; Iter   126/ 1097] train: loss: 0.0283699
[Epoch 13; Iter   156/ 1097] train: loss: 0.2060040
[Epoch 13; Iter   186/ 1097] train: loss: 0.1249834
[Epoch 13; Iter   216/ 1097] train: loss: 0.1134398
[Epoch 13; Iter   246/ 1097] train: loss: 0.1601397
[Epoch 13; Iter   276/ 1097] train: loss: 0.0320392
[Epoch 13; Iter   306/ 1097] train: loss: 0.0194052
[Epoch 13; Iter   336/ 1097] train: loss: 0.0178627
[Epoch 13; Iter   366/ 1097] train: loss: 0.0178285
[Epoch 13; Iter   396/ 1097] train: loss: 0.2515393
[Epoch 13; Iter   426/ 1097] train: loss: 0.0752645
[Epoch 13; Iter   456/ 1097] train: loss: 0.1515189
[Epoch 13; Iter   486/ 1097] train: loss: 0.0359877
[Epoch 13; Iter   516/ 1097] train: loss: 0.2013170
[Epoch 13; Iter   546/ 1097] train: loss: 0.1922633
[Epoch 13; Iter   576/ 1097] train: loss: 0.2148655
[Epoch 13; Iter   606/ 1097] train: loss: 0.0375432
[Epoch 13; Iter   636/ 1097] train: loss: 0.1930738
[Epoch 13; Iter   666/ 1097] train: loss: 0.0327359
[Epoch 13; Iter   696/ 1097] train: loss: 0.1611070
[Epoch 13; Iter   726/ 1097] train: loss: 0.3054468
[Epoch 13; Iter   756/ 1097] train: loss: 0.1910224
[Epoch 13; Iter   786/ 1097] train: loss: 0.4549683
[Epoch 13; Iter   816/ 1097] train: loss: 0.4371744
[Epoch 13; Iter   846/ 1097] train: loss: 0.0402218
[Epoch 13; Iter   876/ 1097] train: loss: 0.0574915
[Epoch 13; Iter   906/ 1097] train: loss: 0.4688855
[Epoch 13; Iter   936/ 1097] train: loss: 0.0249320
[Epoch 13; Iter   966/ 1097] train: loss: 0.1761744
[Epoch 13; Iter   996/ 1097] train: loss: 0.0719590
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1824142
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0537246
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1886949
[Epoch 13] ogbg-molhiv: 0.726037 val loss: 0.114954
[Epoch 13] ogbg-molhiv: 0.670646 test loss: 0.143994
[Epoch 14; Iter    19/ 1097] train: loss: 0.0692287
[Epoch 14; Iter    49/ 1097] train: loss: 0.0306299
[Epoch 14; Iter    79/ 1097] train: loss: 0.2286903
[Epoch 14; Iter   109/ 1097] train: loss: 0.1897022
[Epoch 14; Iter   139/ 1097] train: loss: 0.1000743
[Epoch 14; Iter   169/ 1097] train: loss: 0.1821871
[Epoch 14; Iter   199/ 1097] train: loss: 0.0246424
[Epoch 14; Iter   229/ 1097] train: loss: 0.1247932
[Epoch 14; Iter   259/ 1097] train: loss: 0.0329804
[Epoch 14; Iter   289/ 1097] train: loss: 0.0958325
[Epoch 14; Iter   319/ 1097] train: loss: 0.1597536
[Epoch 14; Iter   349/ 1097] train: loss: 0.0394700
[Epoch 14; Iter   379/ 1097] train: loss: 0.0446187
[Epoch 14; Iter   409/ 1097] train: loss: 0.0412028
[Epoch 14; Iter   439/ 1097] train: loss: 0.1939094
[Epoch 14; Iter   469/ 1097] train: loss: 0.2461615
[Epoch 14; Iter   499/ 1097] train: loss: 0.0796631
[Epoch 14; Iter   529/ 1097] train: loss: 0.0650309
[Epoch 14; Iter   559/ 1097] train: loss: 0.2339696
[Epoch 14; Iter   589/ 1097] train: loss: 0.0635548
[Epoch 14; Iter   619/ 1097] train: loss: 0.1121849
[Epoch 14; Iter   649/ 1097] train: loss: 0.1337786
[Epoch 14; Iter   679/ 1097] train: loss: 0.0260415
[Epoch 14; Iter   709/ 1097] train: loss: 0.0728525
[Epoch 14; Iter   739/ 1097] train: loss: 0.0646964
[Epoch 14; Iter   769/ 1097] train: loss: 0.0298702
[Epoch 14; Iter   799/ 1097] train: loss: 0.0570966
[Epoch 14; Iter   829/ 1097] train: loss: 0.1849950
[Epoch 14; Iter   859/ 1097] train: loss: 0.1955376
[Epoch 14; Iter   889/ 1097] train: loss: 0.0285470
[Epoch 14; Iter   919/ 1097] train: loss: 0.0198691
[Epoch 14; Iter   949/ 1097] train: loss: 0.0187565
[Epoch 14; Iter   979/ 1097] train: loss: 0.2713521
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0543670
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2845084
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0408493
[Epoch 14] ogbg-molhiv: 0.739418 val loss: 0.275340
[Epoch 14] ogbg-molhiv: 0.659914 test loss: 0.268382
[Epoch 15; Iter     2/ 1097] train: loss: 0.0811223
[Epoch 15; Iter    32/ 1097] train: loss: 0.0289357
[Epoch 15; Iter    62/ 1097] train: loss: 0.1689135
[Epoch 15; Iter    92/ 1097] train: loss: 0.1144326
[Epoch 15; Iter   122/ 1097] train: loss: 0.0334018
[Epoch 15; Iter   152/ 1097] train: loss: 0.1522251
[Epoch 15; Iter   182/ 1097] train: loss: 0.0469613
[Epoch 15; Iter   212/ 1097] train: loss: 0.2100287
[Epoch 15; Iter   242/ 1097] train: loss: 0.0374707
[Epoch 15; Iter   272/ 1097] train: loss: 0.1181965
[Epoch 15; Iter   302/ 1097] train: loss: 0.1841435
[Epoch 15; Iter   332/ 1097] train: loss: 0.0721523
[Epoch 15; Iter   362/ 1097] train: loss: 0.1658588
[Epoch 15; Iter   392/ 1097] train: loss: 0.0632844
[Epoch 15; Iter   422/ 1097] train: loss: 0.0530052
[Epoch 15; Iter   452/ 1097] train: loss: 0.1688622
[Epoch 15; Iter   482/ 1097] train: loss: 0.0435828
[Epoch 15; Iter   512/ 1097] train: loss: 0.2455075
[Epoch 15; Iter   542/ 1097] train: loss: 0.0355421
[Epoch 15; Iter   572/ 1097] train: loss: 0.0676390
[Epoch 15; Iter   602/ 1097] train: loss: 0.0280262
[Epoch 15; Iter   632/ 1097] train: loss: 0.1200319
[Epoch 15; Iter   662/ 1097] train: loss: 0.1506546
[Epoch 15; Iter   692/ 1097] train: loss: 0.0537161
[Epoch 15; Iter   722/ 1097] train: loss: 0.3076953
[Epoch 15; Iter   752/ 1097] train: loss: 0.1194573
[Epoch 15; Iter   782/ 1097] train: loss: 0.1337298
[Epoch 15; Iter   812/ 1097] train: loss: 0.0275914
[Epoch 15; Iter   842/ 1097] train: loss: 0.2138582
[Epoch 15; Iter   872/ 1097] train: loss: 0.0309245
[Epoch 15; Iter   902/ 1097] train: loss: 0.0880499
[Epoch 15; Iter   932/ 1097] train: loss: 0.0281550
[Epoch 15; Iter   962/ 1097] train: loss: 0.0625907
[Epoch 15; Iter   992/ 1097] train: loss: 0.1471224
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5506142
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0294940
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0904578
[Epoch 15] ogbg-molhiv: 0.732455 val loss: 0.146626
[Epoch 15] ogbg-molhiv: 0.693870 test loss: 0.145397
[Epoch 16; Iter    15/ 1097] train: loss: 0.1762732
[Epoch 16; Iter    45/ 1097] train: loss: 0.0913471
[Epoch 16; Iter    75/ 1097] train: loss: 0.0573542
[Epoch 16; Iter   105/ 1097] train: loss: 0.0821455
[Epoch 16; Iter   135/ 1097] train: loss: 0.0638319
[Epoch 16; Iter   165/ 1097] train: loss: 0.4899617
[Epoch 12; Iter   113/ 1097] train: loss: 0.0904201
[Epoch 12; Iter   143/ 1097] train: loss: 0.2487787
[Epoch 12; Iter   173/ 1097] train: loss: 0.0391785
[Epoch 12; Iter   203/ 1097] train: loss: 0.0267423
[Epoch 12; Iter   233/ 1097] train: loss: 0.0297636
[Epoch 12; Iter   263/ 1097] train: loss: 0.0802933
[Epoch 12; Iter   293/ 1097] train: loss: 0.1979608
[Epoch 12; Iter   323/ 1097] train: loss: 0.1454385
[Epoch 12; Iter   353/ 1097] train: loss: 0.2437027
[Epoch 12; Iter   383/ 1097] train: loss: 0.0332215
[Epoch 12; Iter   413/ 1097] train: loss: 0.2465056
[Epoch 12; Iter   443/ 1097] train: loss: 0.3560759
[Epoch 12; Iter   473/ 1097] train: loss: 0.1485572
[Epoch 12; Iter   503/ 1097] train: loss: 0.2034472
[Epoch 12; Iter   533/ 1097] train: loss: 0.2179530
[Epoch 12; Iter   563/ 1097] train: loss: 0.1078912
[Epoch 12; Iter   593/ 1097] train: loss: 0.2678431
[Epoch 12; Iter   623/ 1097] train: loss: 0.2120339
[Epoch 12; Iter   653/ 1097] train: loss: 0.0318174
[Epoch 12; Iter   683/ 1097] train: loss: 0.1796496
[Epoch 12; Iter   713/ 1097] train: loss: 0.0396832
[Epoch 12; Iter   743/ 1097] train: loss: 0.2340017
[Epoch 12; Iter   773/ 1097] train: loss: 0.0446894
[Epoch 12; Iter   803/ 1097] train: loss: 0.2104739
[Epoch 12; Iter   833/ 1097] train: loss: 0.1516385
[Epoch 12; Iter   863/ 1097] train: loss: 0.2820180
[Epoch 12; Iter   893/ 1097] train: loss: 0.0262214
[Epoch 12; Iter   923/ 1097] train: loss: 0.2366012
[Epoch 12; Iter   953/ 1097] train: loss: 0.1979250
[Epoch 12; Iter   983/ 1097] train: loss: 0.0509700
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0407642
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1269391
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1330934
[Epoch 12] ogbg-molhiv: 0.786618 val loss: 2.171514
[Epoch 12] ogbg-molhiv: 0.721402 test loss: 1.151096
[Epoch 13; Iter     6/ 1097] train: loss: 0.0437699
[Epoch 13; Iter    36/ 1097] train: loss: 0.3175136
[Epoch 13; Iter    66/ 1097] train: loss: 0.1600743
[Epoch 13; Iter    96/ 1097] train: loss: 0.0723452
[Epoch 13; Iter   126/ 1097] train: loss: 0.0341890
[Epoch 13; Iter   156/ 1097] train: loss: 0.0240192
[Epoch 13; Iter   186/ 1097] train: loss: 0.1640435
[Epoch 13; Iter   216/ 1097] train: loss: 0.2545637
[Epoch 13; Iter   246/ 1097] train: loss: 0.0233815
[Epoch 13; Iter   276/ 1097] train: loss: 0.0856288
[Epoch 13; Iter   306/ 1097] train: loss: 0.0267941
[Epoch 13; Iter   336/ 1097] train: loss: 0.1391096
[Epoch 13; Iter   366/ 1097] train: loss: 0.1793969
[Epoch 13; Iter   396/ 1097] train: loss: 0.0895182
[Epoch 13; Iter   426/ 1097] train: loss: 0.0220824
[Epoch 13; Iter   456/ 1097] train: loss: 0.0352283
[Epoch 13; Iter   486/ 1097] train: loss: 0.0408347
[Epoch 13; Iter   516/ 1097] train: loss: 0.0357113
[Epoch 13; Iter   546/ 1097] train: loss: 0.0230697
[Epoch 13; Iter   576/ 1097] train: loss: 0.1632854
[Epoch 13; Iter   606/ 1097] train: loss: 0.1081795
[Epoch 13; Iter   636/ 1097] train: loss: 0.2998497
[Epoch 13; Iter   666/ 1097] train: loss: 0.0214639
[Epoch 13; Iter   696/ 1097] train: loss: 0.0494161
[Epoch 13; Iter   726/ 1097] train: loss: 0.1306933
[Epoch 13; Iter   756/ 1097] train: loss: 0.0471119
[Epoch 13; Iter   786/ 1097] train: loss: 0.1429008
[Epoch 13; Iter   816/ 1097] train: loss: 0.0236147
[Epoch 13; Iter   846/ 1097] train: loss: 0.0192714
[Epoch 13; Iter   876/ 1097] train: loss: 0.2459174
[Epoch 13; Iter   906/ 1097] train: loss: 0.2671627
[Epoch 13; Iter   936/ 1097] train: loss: 0.2297631
[Epoch 13; Iter   966/ 1097] train: loss: 0.1509226
[Epoch 13; Iter   996/ 1097] train: loss: 0.0732764
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3136732
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1807572
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1320866
[Epoch 13] ogbg-molhiv: 0.797882 val loss: 0.936885
[Epoch 13] ogbg-molhiv: 0.748207 test loss: 0.213231
[Epoch 14; Iter    19/ 1097] train: loss: 0.0264125
[Epoch 14; Iter    49/ 1097] train: loss: 0.3185053
[Epoch 14; Iter    79/ 1097] train: loss: 0.0258564
[Epoch 14; Iter   109/ 1097] train: loss: 0.0383133
[Epoch 14; Iter   139/ 1097] train: loss: 0.0506165
[Epoch 14; Iter   169/ 1097] train: loss: 0.1551481
[Epoch 14; Iter   199/ 1097] train: loss: 0.1140465
[Epoch 14; Iter   229/ 1097] train: loss: 0.0205940
[Epoch 14; Iter   259/ 1097] train: loss: 0.0794045
[Epoch 14; Iter   289/ 1097] train: loss: 0.0710834
[Epoch 14; Iter   319/ 1097] train: loss: 0.1842687
[Epoch 14; Iter   349/ 1097] train: loss: 0.2525105
[Epoch 14; Iter   379/ 1097] train: loss: 0.1850209
[Epoch 14; Iter   409/ 1097] train: loss: 0.0693208
[Epoch 14; Iter   439/ 1097] train: loss: 0.1312328
[Epoch 14; Iter   469/ 1097] train: loss: 0.1804340
[Epoch 14; Iter   499/ 1097] train: loss: 0.0239290
[Epoch 14; Iter   529/ 1097] train: loss: 0.0527446
[Epoch 14; Iter   559/ 1097] train: loss: 0.2196708
[Epoch 14; Iter   589/ 1097] train: loss: 0.0566185
[Epoch 14; Iter   619/ 1097] train: loss: 0.1028454
[Epoch 14; Iter   649/ 1097] train: loss: 0.0309903
[Epoch 14; Iter   679/ 1097] train: loss: 0.1665843
[Epoch 14; Iter   709/ 1097] train: loss: 0.1441132
[Epoch 14; Iter   739/ 1097] train: loss: 0.0967153
[Epoch 14; Iter   769/ 1097] train: loss: 0.1397363
[Epoch 14; Iter   799/ 1097] train: loss: 0.0363275
[Epoch 14; Iter   829/ 1097] train: loss: 0.1093624
[Epoch 14; Iter   859/ 1097] train: loss: 0.0420501
[Epoch 14; Iter   889/ 1097] train: loss: 0.0311525
[Epoch 14; Iter   919/ 1097] train: loss: 0.1205144
[Epoch 14; Iter   949/ 1097] train: loss: 0.0445532
[Epoch 14; Iter   979/ 1097] train: loss: 0.1703629
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0193450
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0558892
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0759004
[Epoch 14] ogbg-molhiv: 0.745171 val loss: 0.984739
[Epoch 14] ogbg-molhiv: 0.670486 test loss: 0.654961
[Epoch 15; Iter     2/ 1097] train: loss: 0.2160566
[Epoch 15; Iter    32/ 1097] train: loss: 0.0313961
[Epoch 15; Iter    62/ 1097] train: loss: 0.1083213
[Epoch 15; Iter    92/ 1097] train: loss: 0.0266278
[Epoch 15; Iter   122/ 1097] train: loss: 0.2151905
[Epoch 15; Iter   152/ 1097] train: loss: 0.1076011
[Epoch 15; Iter   182/ 1097] train: loss: 0.2629094
[Epoch 15; Iter   212/ 1097] train: loss: 0.0296255
[Epoch 15; Iter   242/ 1097] train: loss: 0.0398448
[Epoch 15; Iter   272/ 1097] train: loss: 0.1327959
[Epoch 15; Iter   302/ 1097] train: loss: 0.1596478
[Epoch 15; Iter   332/ 1097] train: loss: 0.0466188
[Epoch 15; Iter   362/ 1097] train: loss: 0.1427638
[Epoch 15; Iter   392/ 1097] train: loss: 0.1573705
[Epoch 15; Iter   422/ 1097] train: loss: 0.3035317
[Epoch 15; Iter   452/ 1097] train: loss: 0.0457367
[Epoch 15; Iter   482/ 1097] train: loss: 0.0727194
[Epoch 15; Iter   512/ 1097] train: loss: 0.2456062
[Epoch 15; Iter   542/ 1097] train: loss: 0.0268383
[Epoch 15; Iter   572/ 1097] train: loss: 0.0227035
[Epoch 15; Iter   602/ 1097] train: loss: 0.3798552
[Epoch 15; Iter   632/ 1097] train: loss: 0.0264856
[Epoch 15; Iter   662/ 1097] train: loss: 0.1878253
[Epoch 15; Iter   692/ 1097] train: loss: 0.0459215
[Epoch 15; Iter   722/ 1097] train: loss: 0.0659454
[Epoch 15; Iter   752/ 1097] train: loss: 0.1493405
[Epoch 15; Iter   782/ 1097] train: loss: 0.1515264
[Epoch 15; Iter   812/ 1097] train: loss: 0.1880647
[Epoch 15; Iter   842/ 1097] train: loss: 0.0366411
[Epoch 15; Iter   872/ 1097] train: loss: 0.0252733
[Epoch 15; Iter   902/ 1097] train: loss: 0.2194277
[Epoch 15; Iter   932/ 1097] train: loss: 0.0549631
[Epoch 15; Iter   962/ 1097] train: loss: 0.0261178
[Epoch 15; Iter   992/ 1097] train: loss: 0.0841674
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0145570
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1287653
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0260488
[Epoch 15] ogbg-molhiv: 0.811627 val loss: 0.119241
[Epoch 15] ogbg-molhiv: 0.738004 test loss: 0.125032
[Epoch 16; Iter    15/ 1097] train: loss: 0.1233201
[Epoch 16; Iter    45/ 1097] train: loss: 0.0263165
[Epoch 16; Iter    75/ 1097] train: loss: 0.0166185
[Epoch 16; Iter   105/ 1097] train: loss: 0.0357548
[Epoch 16; Iter   135/ 1097] train: loss: 0.0296715
[Epoch 16; Iter   165/ 1097] train: loss: 0.2626465
[Epoch 12; Iter   113/ 1097] train: loss: 0.0785298
[Epoch 12; Iter   143/ 1097] train: loss: 0.2370308
[Epoch 12; Iter   173/ 1097] train: loss: 0.0262329
[Epoch 12; Iter   203/ 1097] train: loss: 0.0984663
[Epoch 12; Iter   233/ 1097] train: loss: 0.0188420
[Epoch 12; Iter   263/ 1097] train: loss: 0.0388324
[Epoch 12; Iter   293/ 1097] train: loss: 0.1918788
[Epoch 12; Iter   323/ 1097] train: loss: 0.1284395
[Epoch 12; Iter   353/ 1097] train: loss: 0.1209638
[Epoch 12; Iter   383/ 1097] train: loss: 0.0280484
[Epoch 12; Iter   413/ 1097] train: loss: 0.0255018
[Epoch 12; Iter   443/ 1097] train: loss: 0.0259375
[Epoch 12; Iter   473/ 1097] train: loss: 0.2324815
[Epoch 12; Iter   503/ 1097] train: loss: 0.1753164
[Epoch 12; Iter   533/ 1097] train: loss: 0.0317657
[Epoch 12; Iter   563/ 1097] train: loss: 0.0897488
[Epoch 12; Iter   593/ 1097] train: loss: 0.1542031
[Epoch 12; Iter   623/ 1097] train: loss: 0.0313027
[Epoch 12; Iter   653/ 1097] train: loss: 0.1154709
[Epoch 12; Iter   683/ 1097] train: loss: 0.2672593
[Epoch 12; Iter   713/ 1097] train: loss: 0.0853557
[Epoch 12; Iter   743/ 1097] train: loss: 0.0346997
[Epoch 12; Iter   773/ 1097] train: loss: 0.2085387
[Epoch 12; Iter   803/ 1097] train: loss: 0.1646545
[Epoch 12; Iter   833/ 1097] train: loss: 0.0649645
[Epoch 12; Iter   863/ 1097] train: loss: 0.0454678
[Epoch 12; Iter   893/ 1097] train: loss: 0.1168229
[Epoch 12; Iter   923/ 1097] train: loss: 0.0347893
[Epoch 12; Iter   953/ 1097] train: loss: 0.2277209
[Epoch 12; Iter   983/ 1097] train: loss: 0.2680546
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0298333
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0288590
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0365970
[Epoch 12] ogbg-molhiv: 0.825274 val loss: 0.422791
[Epoch 12] ogbg-molhiv: 0.749149 test loss: 0.124648
[Epoch 13; Iter     6/ 1097] train: loss: 0.1590928
[Epoch 13; Iter    36/ 1097] train: loss: 0.2071516
[Epoch 13; Iter    66/ 1097] train: loss: 0.1385369
[Epoch 13; Iter    96/ 1097] train: loss: 0.0181168
[Epoch 13; Iter   126/ 1097] train: loss: 0.0460950
[Epoch 13; Iter   156/ 1097] train: loss: 0.2077276
[Epoch 13; Iter   186/ 1097] train: loss: 0.2497057
[Epoch 13; Iter   216/ 1097] train: loss: 0.1368126
[Epoch 13; Iter   246/ 1097] train: loss: 0.0302788
[Epoch 13; Iter   276/ 1097] train: loss: 0.0249075
[Epoch 13; Iter   306/ 1097] train: loss: 0.3199327
[Epoch 13; Iter   336/ 1097] train: loss: 0.1997924
[Epoch 13; Iter   366/ 1097] train: loss: 0.3412556
[Epoch 13; Iter   396/ 1097] train: loss: 0.0645744
[Epoch 13; Iter   426/ 1097] train: loss: 0.0950201
[Epoch 13; Iter   456/ 1097] train: loss: 0.1780101
[Epoch 13; Iter   486/ 1097] train: loss: 0.0383304
[Epoch 13; Iter   516/ 1097] train: loss: 0.1209903
[Epoch 13; Iter   546/ 1097] train: loss: 0.0311712
[Epoch 13; Iter   576/ 1097] train: loss: 0.0930384
[Epoch 13; Iter   606/ 1097] train: loss: 0.2531112
[Epoch 13; Iter   636/ 1097] train: loss: 0.0520040
[Epoch 13; Iter   666/ 1097] train: loss: 0.2022758
[Epoch 13; Iter   696/ 1097] train: loss: 0.3583194
[Epoch 13; Iter   726/ 1097] train: loss: 0.0566578
[Epoch 13; Iter   756/ 1097] train: loss: 0.0533604
[Epoch 13; Iter   786/ 1097] train: loss: 0.1335479
[Epoch 13; Iter   816/ 1097] train: loss: 0.0755308
[Epoch 13; Iter   846/ 1097] train: loss: 0.0368325
[Epoch 13; Iter   876/ 1097] train: loss: 0.2070560
[Epoch 13; Iter   906/ 1097] train: loss: 0.4034191
[Epoch 13; Iter   936/ 1097] train: loss: 0.0433687
[Epoch 13; Iter   966/ 1097] train: loss: 0.0346906
[Epoch 13; Iter   996/ 1097] train: loss: 0.0270748
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0308395
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2117294
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0967813
[Epoch 13] ogbg-molhiv: 0.774872 val loss: 0.132486
[Epoch 13] ogbg-molhiv: 0.725725 test loss: 0.284905
[Epoch 14; Iter    19/ 1097] train: loss: 0.2326881
[Epoch 14; Iter    49/ 1097] train: loss: 0.2176076
[Epoch 14; Iter    79/ 1097] train: loss: 0.0420455
[Epoch 14; Iter   109/ 1097] train: loss: 0.0959067
[Epoch 14; Iter   139/ 1097] train: loss: 0.0283157
[Epoch 14; Iter   169/ 1097] train: loss: 0.1672570
[Epoch 14; Iter   199/ 1097] train: loss: 0.0205234
[Epoch 14; Iter   229/ 1097] train: loss: 0.2325913
[Epoch 14; Iter   259/ 1097] train: loss: 0.2602457
[Epoch 14; Iter   289/ 1097] train: loss: 0.0619421
[Epoch 14; Iter   319/ 1097] train: loss: 0.0398841
[Epoch 14; Iter   349/ 1097] train: loss: 0.0555684
[Epoch 14; Iter   379/ 1097] train: loss: 0.0309660
[Epoch 14; Iter   409/ 1097] train: loss: 0.1188582
[Epoch 14; Iter   439/ 1097] train: loss: 0.1986572
[Epoch 14; Iter   469/ 1097] train: loss: 0.1803596
[Epoch 14; Iter   499/ 1097] train: loss: 0.0258933
[Epoch 14; Iter   529/ 1097] train: loss: 0.1751663
[Epoch 14; Iter   559/ 1097] train: loss: 0.0308685
[Epoch 14; Iter   589/ 1097] train: loss: 0.1084495
[Epoch 14; Iter   619/ 1097] train: loss: 0.2654133
[Epoch 14; Iter   649/ 1097] train: loss: 0.0404068
[Epoch 14; Iter   679/ 1097] train: loss: 0.0348912
[Epoch 14; Iter   709/ 1097] train: loss: 0.2428654
[Epoch 14; Iter   739/ 1097] train: loss: 0.1988359
[Epoch 14; Iter   769/ 1097] train: loss: 0.0314314
[Epoch 14; Iter   799/ 1097] train: loss: 0.0175097
[Epoch 14; Iter   829/ 1097] train: loss: 0.1351030
[Epoch 14; Iter   859/ 1097] train: loss: 0.0381433
[Epoch 14; Iter   889/ 1097] train: loss: 0.0389832
[Epoch 14; Iter   919/ 1097] train: loss: 0.1386957
[Epoch 14; Iter   949/ 1097] train: loss: 0.1947015
[Epoch 14; Iter   979/ 1097] train: loss: 0.1241886
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2298503
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0281579
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0433007
[Epoch 14] ogbg-molhiv: 0.817019 val loss: 0.070724
[Epoch 14] ogbg-molhiv: 0.757587 test loss: 0.120211
[Epoch 15; Iter     2/ 1097] train: loss: 0.1714106
[Epoch 15; Iter    32/ 1097] train: loss: 0.1274783
[Epoch 15; Iter    62/ 1097] train: loss: 0.1021456
[Epoch 15; Iter    92/ 1097] train: loss: 0.0771098
[Epoch 15; Iter   122/ 1097] train: loss: 0.0410227
[Epoch 15; Iter   152/ 1097] train: loss: 0.0249392
[Epoch 15; Iter   182/ 1097] train: loss: 0.0837634
[Epoch 15; Iter   212/ 1097] train: loss: 0.1534680
[Epoch 15; Iter   242/ 1097] train: loss: 0.0754025
[Epoch 15; Iter   272/ 1097] train: loss: 0.3507285
[Epoch 15; Iter   302/ 1097] train: loss: 0.1343765
[Epoch 15; Iter   332/ 1097] train: loss: 0.2898386
[Epoch 15; Iter   362/ 1097] train: loss: 0.1391542
[Epoch 15; Iter   392/ 1097] train: loss: 0.1725719
[Epoch 15; Iter   422/ 1097] train: loss: 0.0518853
[Epoch 15; Iter   452/ 1097] train: loss: 0.0352882
[Epoch 15; Iter   482/ 1097] train: loss: 0.1062855
[Epoch 15; Iter   512/ 1097] train: loss: 0.4042759
[Epoch 15; Iter   542/ 1097] train: loss: 0.0706433
[Epoch 15; Iter   572/ 1097] train: loss: 0.1192986
[Epoch 15; Iter   602/ 1097] train: loss: 0.0308103
[Epoch 15; Iter   632/ 1097] train: loss: 0.1531748
[Epoch 15; Iter   662/ 1097] train: loss: 0.0430326
[Epoch 15; Iter   692/ 1097] train: loss: 0.1461789
[Epoch 15; Iter   722/ 1097] train: loss: 0.0368438
[Epoch 15; Iter   752/ 1097] train: loss: 0.0535578
[Epoch 15; Iter   782/ 1097] train: loss: 0.0389305
[Epoch 15; Iter   812/ 1097] train: loss: 0.0175946
[Epoch 15; Iter   842/ 1097] train: loss: 0.0527092
[Epoch 15; Iter   872/ 1097] train: loss: 0.0356061
[Epoch 15; Iter   902/ 1097] train: loss: 0.0501631
[Epoch 15; Iter   932/ 1097] train: loss: 0.1906843
[Epoch 15; Iter   962/ 1097] train: loss: 0.2695331
[Epoch 15; Iter   992/ 1097] train: loss: 0.0225128
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1299965
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1409536
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0200637
[Epoch 15] ogbg-molhiv: 0.821291 val loss: 2.345056
[Epoch 15] ogbg-molhiv: 0.713504 test loss: 0.229583
[Epoch 16; Iter    15/ 1097] train: loss: 0.0235579
[Epoch 16; Iter    45/ 1097] train: loss: 0.0683013
[Epoch 16; Iter    75/ 1097] train: loss: 0.2521507
[Epoch 16; Iter   105/ 1097] train: loss: 0.0390729
[Epoch 16; Iter   135/ 1097] train: loss: 0.0692599
[Epoch 16; Iter   165/ 1097] train: loss: 0.0346013
[Epoch 12; Iter   143/ 1097] train: loss: 0.0711247
[Epoch 12; Iter   173/ 1097] train: loss: 0.3345416
[Epoch 12; Iter   203/ 1097] train: loss: 0.1458436
[Epoch 12; Iter   233/ 1097] train: loss: 0.3334883
[Epoch 12; Iter   263/ 1097] train: loss: 0.1690890
[Epoch 12; Iter   293/ 1097] train: loss: 0.2073766
[Epoch 12; Iter   323/ 1097] train: loss: 0.0846089
[Epoch 12; Iter   353/ 1097] train: loss: 0.0911500
[Epoch 12; Iter   383/ 1097] train: loss: 0.1569188
[Epoch 12; Iter   413/ 1097] train: loss: 0.0297759
[Epoch 12; Iter   443/ 1097] train: loss: 0.1538636
[Epoch 12; Iter   473/ 1097] train: loss: 0.0320822
[Epoch 12; Iter   503/ 1097] train: loss: 0.0506837
[Epoch 12; Iter   533/ 1097] train: loss: 0.1646707
[Epoch 12; Iter   563/ 1097] train: loss: 0.1510051
[Epoch 12; Iter   593/ 1097] train: loss: 0.3033353
[Epoch 12; Iter   623/ 1097] train: loss: 0.0272251
[Epoch 12; Iter   653/ 1097] train: loss: 0.0310479
[Epoch 12; Iter   683/ 1097] train: loss: 0.0566102
[Epoch 12; Iter   713/ 1097] train: loss: 0.1458284
[Epoch 12; Iter   743/ 1097] train: loss: 0.0430751
[Epoch 12; Iter   773/ 1097] train: loss: 0.3058539
[Epoch 12; Iter   803/ 1097] train: loss: 0.1141977
[Epoch 12; Iter   833/ 1097] train: loss: 0.0400135
[Epoch 12; Iter   863/ 1097] train: loss: 0.0339116
[Epoch 12; Iter   893/ 1097] train: loss: 0.1169232
[Epoch 12; Iter   923/ 1097] train: loss: 0.0320705
[Epoch 12; Iter   953/ 1097] train: loss: 0.1060748
[Epoch 12; Iter   983/ 1097] train: loss: 0.1410422
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0241715
[Epoch 12; Iter  1043/ 1097] train: loss: 0.2200667
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1240008
[Epoch 12] ogbg-molhiv: 0.731944 val loss: 1.387401
[Epoch 12] ogbg-molhiv: 0.726812 test loss: 0.833455
[Epoch 13; Iter     6/ 1097] train: loss: 0.1216792
[Epoch 13; Iter    36/ 1097] train: loss: 0.0421519
[Epoch 13; Iter    66/ 1097] train: loss: 0.0800525
[Epoch 13; Iter    96/ 1097] train: loss: 0.0514387
[Epoch 13; Iter   126/ 1097] train: loss: 0.0334311
[Epoch 13; Iter   156/ 1097] train: loss: 0.3206955
[Epoch 13; Iter   186/ 1097] train: loss: 0.1699066
[Epoch 13; Iter   216/ 1097] train: loss: 0.1976332
[Epoch 13; Iter   246/ 1097] train: loss: 0.1765314
[Epoch 13; Iter   276/ 1097] train: loss: 0.0409999
[Epoch 13; Iter   306/ 1097] train: loss: 0.0248341
[Epoch 13; Iter   336/ 1097] train: loss: 0.0234316
[Epoch 13; Iter   366/ 1097] train: loss: 0.0385934
[Epoch 13; Iter   396/ 1097] train: loss: 0.2257293
[Epoch 13; Iter   426/ 1097] train: loss: 0.0612799
[Epoch 13; Iter   456/ 1097] train: loss: 0.1838823
[Epoch 13; Iter   486/ 1097] train: loss: 0.0259632
[Epoch 13; Iter   516/ 1097] train: loss: 0.1039209
[Epoch 13; Iter   546/ 1097] train: loss: 0.2480110
[Epoch 13; Iter   576/ 1097] train: loss: 0.2121281
[Epoch 13; Iter   606/ 1097] train: loss: 0.0327546
[Epoch 13; Iter   636/ 1097] train: loss: 0.2266134
[Epoch 13; Iter   666/ 1097] train: loss: 0.0428366
[Epoch 13; Iter   696/ 1097] train: loss: 0.1598684
[Epoch 13; Iter   726/ 1097] train: loss: 0.3559629
[Epoch 13; Iter   756/ 1097] train: loss: 0.1548219
[Epoch 13; Iter   786/ 1097] train: loss: 0.4143378
[Epoch 13; Iter   816/ 1097] train: loss: 0.4473796
[Epoch 13; Iter   846/ 1097] train: loss: 0.0569952
[Epoch 13; Iter   876/ 1097] train: loss: 0.0465145
[Epoch 13; Iter   906/ 1097] train: loss: 0.3722776
[Epoch 13; Iter   936/ 1097] train: loss: 0.0250591
[Epoch 13; Iter   966/ 1097] train: loss: 0.0931060
[Epoch 13; Iter   996/ 1097] train: loss: 0.0674762
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1628991
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0792987
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1786911
[Epoch 13] ogbg-molhiv: 0.801296 val loss: 2.705928
[Epoch 13] ogbg-molhiv: 0.711064 test loss: 0.887880
[Epoch 14; Iter    19/ 1097] train: loss: 0.0429814
[Epoch 14; Iter    49/ 1097] train: loss: 0.0450732
[Epoch 14; Iter    79/ 1097] train: loss: 0.2459836
[Epoch 14; Iter   109/ 1097] train: loss: 0.2459774
[Epoch 14; Iter   139/ 1097] train: loss: 0.0668291
[Epoch 14; Iter   169/ 1097] train: loss: 0.1499552
[Epoch 14; Iter   199/ 1097] train: loss: 0.0258642
[Epoch 14; Iter   229/ 1097] train: loss: 0.0602679
[Epoch 14; Iter   259/ 1097] train: loss: 0.0955104
[Epoch 14; Iter   289/ 1097] train: loss: 0.1436347
[Epoch 14; Iter   319/ 1097] train: loss: 0.1577835
[Epoch 14; Iter   349/ 1097] train: loss: 0.0382485
[Epoch 14; Iter   379/ 1097] train: loss: 0.0949484
[Epoch 14; Iter   409/ 1097] train: loss: 0.0337031
[Epoch 14; Iter   439/ 1097] train: loss: 0.1797791
[Epoch 14; Iter   469/ 1097] train: loss: 0.2236560
[Epoch 14; Iter   499/ 1097] train: loss: 0.0734272
[Epoch 14; Iter   529/ 1097] train: loss: 0.1261142
[Epoch 14; Iter   559/ 1097] train: loss: 0.3043395
[Epoch 14; Iter   589/ 1097] train: loss: 0.0872782
[Epoch 14; Iter   619/ 1097] train: loss: 0.1384607
[Epoch 14; Iter   649/ 1097] train: loss: 0.1555894
[Epoch 14; Iter   679/ 1097] train: loss: 0.0282393
[Epoch 14; Iter   709/ 1097] train: loss: 0.0982909
[Epoch 14; Iter   739/ 1097] train: loss: 0.0816078
[Epoch 14; Iter   769/ 1097] train: loss: 0.0331611
[Epoch 14; Iter   799/ 1097] train: loss: 0.0500812
[Epoch 14; Iter   829/ 1097] train: loss: 0.0941506
[Epoch 14; Iter   859/ 1097] train: loss: 0.2351763
[Epoch 14; Iter   889/ 1097] train: loss: 0.0217397
[Epoch 14; Iter   919/ 1097] train: loss: 0.0260976
[Epoch 14; Iter   949/ 1097] train: loss: 0.0245113
[Epoch 14; Iter   979/ 1097] train: loss: 0.2779867
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0579166
[Epoch 14; Iter  1039/ 1097] train: loss: 0.1910945
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0372738
[Epoch 14] ogbg-molhiv: 0.802187 val loss: 0.135090
[Epoch 14] ogbg-molhiv: 0.711201 test loss: 0.162437
[Epoch 15; Iter     2/ 1097] train: loss: 0.0816286
[Epoch 15; Iter    32/ 1097] train: loss: 0.0378744
[Epoch 15; Iter    62/ 1097] train: loss: 0.1520694
[Epoch 15; Iter    92/ 1097] train: loss: 0.1225616
[Epoch 15; Iter   122/ 1097] train: loss: 0.0268526
[Epoch 15; Iter   152/ 1097] train: loss: 0.1962102
[Epoch 15; Iter   182/ 1097] train: loss: 0.0389162
[Epoch 15; Iter   212/ 1097] train: loss: 0.2468704
[Epoch 15; Iter   242/ 1097] train: loss: 0.0635953
[Epoch 15; Iter   272/ 1097] train: loss: 0.0989034
[Epoch 15; Iter   302/ 1097] train: loss: 0.1949153
[Epoch 15; Iter   332/ 1097] train: loss: 0.1090042
[Epoch 15; Iter   362/ 1097] train: loss: 0.1830042
[Epoch 15; Iter   392/ 1097] train: loss: 0.0404906
[Epoch 15; Iter   422/ 1097] train: loss: 0.0345385
[Epoch 15; Iter   452/ 1097] train: loss: 0.3320400
[Epoch 15; Iter   482/ 1097] train: loss: 0.0332346
[Epoch 15; Iter   512/ 1097] train: loss: 0.1897754
[Epoch 15; Iter   542/ 1097] train: loss: 0.0676870
[Epoch 15; Iter   572/ 1097] train: loss: 0.1053740
[Epoch 15; Iter   602/ 1097] train: loss: 0.0309023
[Epoch 15; Iter   632/ 1097] train: loss: 0.0978076
[Epoch 15; Iter   662/ 1097] train: loss: 0.1181127
[Epoch 15; Iter   692/ 1097] train: loss: 0.0409246
[Epoch 15; Iter   722/ 1097] train: loss: 0.3181335
[Epoch 15; Iter   752/ 1097] train: loss: 0.0737386
[Epoch 15; Iter   782/ 1097] train: loss: 0.1384052
[Epoch 15; Iter   812/ 1097] train: loss: 0.0306712
[Epoch 15; Iter   842/ 1097] train: loss: 0.1937992
[Epoch 15; Iter   872/ 1097] train: loss: 0.0558434
[Epoch 15; Iter   902/ 1097] train: loss: 0.1769529
[Epoch 15; Iter   932/ 1097] train: loss: 0.0306674
[Epoch 15; Iter   962/ 1097] train: loss: 0.0989924
[Epoch 15; Iter   992/ 1097] train: loss: 0.0992495
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4946678
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0330131
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0747937
[Epoch 15] ogbg-molhiv: 0.752024 val loss: 2.863791
[Epoch 15] ogbg-molhiv: 0.710249 test loss: 0.659809
[Epoch 16; Iter    15/ 1097] train: loss: 0.2670391
[Epoch 16; Iter    45/ 1097] train: loss: 0.0610447
[Epoch 16; Iter    75/ 1097] train: loss: 0.0813626
[Epoch 16; Iter   105/ 1097] train: loss: 0.1186794
[Epoch 16; Iter   135/ 1097] train: loss: 0.1145356
[Epoch 16; Iter   165/ 1097] train: loss: 0.4319940
[Epoch 16; Iter   195/ 1097] train: loss: 0.0568678
[Epoch 12; Iter   143/ 1097] train: loss: 0.2664515
[Epoch 12; Iter   173/ 1097] train: loss: 0.0760562
[Epoch 12; Iter   203/ 1097] train: loss: 0.0453437
[Epoch 12; Iter   233/ 1097] train: loss: 0.0343898
[Epoch 12; Iter   263/ 1097] train: loss: 0.1108428
[Epoch 12; Iter   293/ 1097] train: loss: 0.1930170
[Epoch 12; Iter   323/ 1097] train: loss: 0.1624133
[Epoch 12; Iter   353/ 1097] train: loss: 0.2589864
[Epoch 12; Iter   383/ 1097] train: loss: 0.0570215
[Epoch 12; Iter   413/ 1097] train: loss: 0.2898384
[Epoch 12; Iter   443/ 1097] train: loss: 0.3246957
[Epoch 12; Iter   473/ 1097] train: loss: 0.1624397
[Epoch 12; Iter   503/ 1097] train: loss: 0.2225074
[Epoch 12; Iter   533/ 1097] train: loss: 0.1913440
[Epoch 12; Iter   563/ 1097] train: loss: 0.1458815
[Epoch 12; Iter   593/ 1097] train: loss: 0.3546680
[Epoch 12; Iter   623/ 1097] train: loss: 0.2782671
[Epoch 12; Iter   653/ 1097] train: loss: 0.0373025
[Epoch 12; Iter   683/ 1097] train: loss: 0.1806525
[Epoch 12; Iter   713/ 1097] train: loss: 0.0439201
[Epoch 12; Iter   743/ 1097] train: loss: 0.2130347
[Epoch 12; Iter   773/ 1097] train: loss: 0.0380129
[Epoch 12; Iter   803/ 1097] train: loss: 0.1782232
[Epoch 12; Iter   833/ 1097] train: loss: 0.2322092
[Epoch 12; Iter   863/ 1097] train: loss: 0.2060790
[Epoch 12; Iter   893/ 1097] train: loss: 0.0392067
[Epoch 12; Iter   923/ 1097] train: loss: 0.1613131
[Epoch 12; Iter   953/ 1097] train: loss: 0.2178246
[Epoch 12; Iter   983/ 1097] train: loss: 0.0439599
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0374451
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1493035
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1458580
[Epoch 12] ogbg-molhiv: 0.681229 val loss: 0.228007
[Epoch 12] ogbg-molhiv: 0.682815 test loss: 0.128785
[Epoch 13; Iter     6/ 1097] train: loss: 0.0939931
[Epoch 13; Iter    36/ 1097] train: loss: 0.3191849
[Epoch 13; Iter    66/ 1097] train: loss: 0.1291556
[Epoch 13; Iter    96/ 1097] train: loss: 0.0559280
[Epoch 13; Iter   126/ 1097] train: loss: 0.0305388
[Epoch 13; Iter   156/ 1097] train: loss: 0.0306738
[Epoch 13; Iter   186/ 1097] train: loss: 0.1684593
[Epoch 13; Iter   216/ 1097] train: loss: 0.3160546
[Epoch 13; Iter   246/ 1097] train: loss: 0.0268311
[Epoch 13; Iter   276/ 1097] train: loss: 0.1532343
[Epoch 13; Iter   306/ 1097] train: loss: 0.0573661
[Epoch 13; Iter   336/ 1097] train: loss: 0.1470240
[Epoch 13; Iter   366/ 1097] train: loss: 0.1905501
[Epoch 13; Iter   396/ 1097] train: loss: 0.1098593
[Epoch 13; Iter   426/ 1097] train: loss: 0.0425488
[Epoch 13; Iter   456/ 1097] train: loss: 0.0456167
[Epoch 13; Iter   486/ 1097] train: loss: 0.0317179
[Epoch 13; Iter   516/ 1097] train: loss: 0.0327113
[Epoch 13; Iter   546/ 1097] train: loss: 0.0335136
[Epoch 13; Iter   576/ 1097] train: loss: 0.1946010
[Epoch 13; Iter   606/ 1097] train: loss: 0.1116410
[Epoch 13; Iter   636/ 1097] train: loss: 0.2877744
[Epoch 13; Iter   666/ 1097] train: loss: 0.0400231
[Epoch 13; Iter   696/ 1097] train: loss: 0.0368052
[Epoch 13; Iter   726/ 1097] train: loss: 0.1455916
[Epoch 13; Iter   756/ 1097] train: loss: 0.0489825
[Epoch 13; Iter   786/ 1097] train: loss: 0.2164167
[Epoch 13; Iter   816/ 1097] train: loss: 0.0309397
[Epoch 13; Iter   846/ 1097] train: loss: 0.0200150
[Epoch 13; Iter   876/ 1097] train: loss: 0.2367490
[Epoch 13; Iter   906/ 1097] train: loss: 0.3930000
[Epoch 13; Iter   936/ 1097] train: loss: 0.1634687
[Epoch 13; Iter   966/ 1097] train: loss: 0.1002418
[Epoch 13; Iter   996/ 1097] train: loss: 0.1116765
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3589482
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1443600
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1798502
[Epoch 13] ogbg-molhiv: 0.691839 val loss: 0.473599
[Epoch 13] ogbg-molhiv: 0.726978 test loss: 0.121357
[Epoch 14; Iter    19/ 1097] train: loss: 0.0353338
[Epoch 14; Iter    49/ 1097] train: loss: 0.2675111
[Epoch 14; Iter    79/ 1097] train: loss: 0.0279313
[Epoch 14; Iter   109/ 1097] train: loss: 0.0377655
[Epoch 14; Iter   139/ 1097] train: loss: 0.1448486
[Epoch 14; Iter   169/ 1097] train: loss: 0.1068429
[Epoch 14; Iter   199/ 1097] train: loss: 0.0723180
[Epoch 14; Iter   229/ 1097] train: loss: 0.0282237
[Epoch 14; Iter   259/ 1097] train: loss: 0.0573252
[Epoch 14; Iter   289/ 1097] train: loss: 0.1256362
[Epoch 14; Iter   319/ 1097] train: loss: 0.2480093
[Epoch 14; Iter   349/ 1097] train: loss: 0.2474445
[Epoch 14; Iter   379/ 1097] train: loss: 0.1924990
[Epoch 14; Iter   409/ 1097] train: loss: 0.0488862
[Epoch 14; Iter   439/ 1097] train: loss: 0.1239987
[Epoch 14; Iter   469/ 1097] train: loss: 0.1077619
[Epoch 14; Iter   499/ 1097] train: loss: 0.0365266
[Epoch 14; Iter   529/ 1097] train: loss: 0.0550634
[Epoch 14; Iter   559/ 1097] train: loss: 0.1985135
[Epoch 14; Iter   589/ 1097] train: loss: 0.0343708
[Epoch 14; Iter   619/ 1097] train: loss: 0.1234760
[Epoch 14; Iter   649/ 1097] train: loss: 0.0301201
[Epoch 14; Iter   679/ 1097] train: loss: 0.1610325
[Epoch 14; Iter   709/ 1097] train: loss: 0.1834316
[Epoch 14; Iter   739/ 1097] train: loss: 0.1157126
[Epoch 14; Iter   769/ 1097] train: loss: 0.1577233
[Epoch 14; Iter   799/ 1097] train: loss: 0.0525708
[Epoch 14; Iter   829/ 1097] train: loss: 0.1366969
[Epoch 14; Iter   859/ 1097] train: loss: 0.0666407
[Epoch 14; Iter   889/ 1097] train: loss: 0.0304232
[Epoch 14; Iter   919/ 1097] train: loss: 0.1059664
[Epoch 14; Iter   949/ 1097] train: loss: 0.0345928
[Epoch 14; Iter   979/ 1097] train: loss: 0.1829305
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0198598
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0571025
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1222507
[Epoch 14] ogbg-molhiv: 0.696334 val loss: 0.377851
[Epoch 14] ogbg-molhiv: 0.655741 test loss: 0.132260
[Epoch 15; Iter     2/ 1097] train: loss: 0.1805086
[Epoch 15; Iter    32/ 1097] train: loss: 0.0341395
[Epoch 15; Iter    62/ 1097] train: loss: 0.2211606
[Epoch 15; Iter    92/ 1097] train: loss: 0.0231658
[Epoch 15; Iter   122/ 1097] train: loss: 0.2159380
[Epoch 15; Iter   152/ 1097] train: loss: 0.1869371
[Epoch 15; Iter   182/ 1097] train: loss: 0.1532458
[Epoch 15; Iter   212/ 1097] train: loss: 0.0458363
[Epoch 15; Iter   242/ 1097] train: loss: 0.0392189
[Epoch 15; Iter   272/ 1097] train: loss: 0.0949645
[Epoch 15; Iter   302/ 1097] train: loss: 0.1828533
[Epoch 15; Iter   332/ 1097] train: loss: 0.0671133
[Epoch 15; Iter   362/ 1097] train: loss: 0.1707900
[Epoch 15; Iter   392/ 1097] train: loss: 0.1880171
[Epoch 15; Iter   422/ 1097] train: loss: 0.2448306
[Epoch 15; Iter   452/ 1097] train: loss: 0.0720113
[Epoch 15; Iter   482/ 1097] train: loss: 0.1207311
[Epoch 15; Iter   512/ 1097] train: loss: 0.3092269
[Epoch 15; Iter   542/ 1097] train: loss: 0.0230071
[Epoch 15; Iter   572/ 1097] train: loss: 0.0364386
[Epoch 15; Iter   602/ 1097] train: loss: 0.3824533
[Epoch 15; Iter   632/ 1097] train: loss: 0.0272132
[Epoch 15; Iter   662/ 1097] train: loss: 0.1771986
[Epoch 15; Iter   692/ 1097] train: loss: 0.0273316
[Epoch 15; Iter   722/ 1097] train: loss: 0.0478087
[Epoch 15; Iter   752/ 1097] train: loss: 0.1601927
[Epoch 15; Iter   782/ 1097] train: loss: 0.1913787
[Epoch 15; Iter   812/ 1097] train: loss: 0.1655271
[Epoch 15; Iter   842/ 1097] train: loss: 0.0612568
[Epoch 15; Iter   872/ 1097] train: loss: 0.0338969
[Epoch 15; Iter   902/ 1097] train: loss: 0.2727674
[Epoch 15; Iter   932/ 1097] train: loss: 0.0484947
[Epoch 15; Iter   962/ 1097] train: loss: 0.0264904
[Epoch 15; Iter   992/ 1097] train: loss: 0.0417771
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0236894
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0854178
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0315621
[Epoch 15] ogbg-molhiv: 0.737801 val loss: 0.434293
[Epoch 15] ogbg-molhiv: 0.730142 test loss: 0.122935
[Epoch 16; Iter    15/ 1097] train: loss: 0.0814215
[Epoch 16; Iter    45/ 1097] train: loss: 0.0290850
[Epoch 16; Iter    75/ 1097] train: loss: 0.0275691
[Epoch 16; Iter   105/ 1097] train: loss: 0.0232583
[Epoch 16; Iter   135/ 1097] train: loss: 0.0334879
[Epoch 16; Iter   165/ 1097] train: loss: 0.3624980
[Epoch 16; Iter   195/ 1097] train: loss: 0.1382857
[Epoch 12; Iter   143/ 1097] train: loss: 0.1629273
[Epoch 12; Iter   173/ 1097] train: loss: 0.0279424
[Epoch 12; Iter   203/ 1097] train: loss: 0.1010337
[Epoch 12; Iter   233/ 1097] train: loss: 0.0268205
[Epoch 12; Iter   263/ 1097] train: loss: 0.0361777
[Epoch 12; Iter   293/ 1097] train: loss: 0.2085811
[Epoch 12; Iter   323/ 1097] train: loss: 0.1831741
[Epoch 12; Iter   353/ 1097] train: loss: 0.0989979
[Epoch 12; Iter   383/ 1097] train: loss: 0.0307503
[Epoch 12; Iter   413/ 1097] train: loss: 0.0319821
[Epoch 12; Iter   443/ 1097] train: loss: 0.0338485
[Epoch 12; Iter   473/ 1097] train: loss: 0.2762555
[Epoch 12; Iter   503/ 1097] train: loss: 0.1687466
[Epoch 12; Iter   533/ 1097] train: loss: 0.0316484
[Epoch 12; Iter   563/ 1097] train: loss: 0.1356167
[Epoch 12; Iter   593/ 1097] train: loss: 0.1479030
[Epoch 12; Iter   623/ 1097] train: loss: 0.0299544
[Epoch 12; Iter   653/ 1097] train: loss: 0.1081814
[Epoch 12; Iter   683/ 1097] train: loss: 0.3535493
[Epoch 12; Iter   713/ 1097] train: loss: 0.1221245
[Epoch 12; Iter   743/ 1097] train: loss: 0.0260451
[Epoch 12; Iter   773/ 1097] train: loss: 0.1554823
[Epoch 12; Iter   803/ 1097] train: loss: 0.1999202
[Epoch 12; Iter   833/ 1097] train: loss: 0.0845551
[Epoch 12; Iter   863/ 1097] train: loss: 0.0701044
[Epoch 12; Iter   893/ 1097] train: loss: 0.1822891
[Epoch 12; Iter   923/ 1097] train: loss: 0.0364338
[Epoch 12; Iter   953/ 1097] train: loss: 0.2437667
[Epoch 12; Iter   983/ 1097] train: loss: 0.3032638
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0278750
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0271357
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0238529
[Epoch 12] ogbg-molhiv: 0.756038 val loss: 0.134453
[Epoch 12] ogbg-molhiv: 0.692903 test loss: 0.185193
[Epoch 13; Iter     6/ 1097] train: loss: 0.1282169
[Epoch 13; Iter    36/ 1097] train: loss: 0.1931545
[Epoch 13; Iter    66/ 1097] train: loss: 0.1802973
[Epoch 13; Iter    96/ 1097] train: loss: 0.0407267
[Epoch 13; Iter   126/ 1097] train: loss: 0.0719898
[Epoch 13; Iter   156/ 1097] train: loss: 0.2490020
[Epoch 13; Iter   186/ 1097] train: loss: 0.2211286
[Epoch 13; Iter   216/ 1097] train: loss: 0.1689023
[Epoch 13; Iter   246/ 1097] train: loss: 0.0507874
[Epoch 13; Iter   276/ 1097] train: loss: 0.0324789
[Epoch 13; Iter   306/ 1097] train: loss: 0.3983690
[Epoch 13; Iter   336/ 1097] train: loss: 0.1369884
[Epoch 13; Iter   366/ 1097] train: loss: 0.3635035
[Epoch 13; Iter   396/ 1097] train: loss: 0.0274115
[Epoch 13; Iter   426/ 1097] train: loss: 0.1379952
[Epoch 13; Iter   456/ 1097] train: loss: 0.1939402
[Epoch 13; Iter   486/ 1097] train: loss: 0.0388886
[Epoch 13; Iter   516/ 1097] train: loss: 0.2481013
[Epoch 13; Iter   546/ 1097] train: loss: 0.0209132
[Epoch 13; Iter   576/ 1097] train: loss: 0.1242503
[Epoch 13; Iter   606/ 1097] train: loss: 0.2328818
[Epoch 13; Iter   636/ 1097] train: loss: 0.0630151
[Epoch 13; Iter   666/ 1097] train: loss: 0.1515695
[Epoch 13; Iter   696/ 1097] train: loss: 0.4082102
[Epoch 13; Iter   726/ 1097] train: loss: 0.0739012
[Epoch 13; Iter   756/ 1097] train: loss: 0.0378204
[Epoch 13; Iter   786/ 1097] train: loss: 0.2470066
[Epoch 13; Iter   816/ 1097] train: loss: 0.0689209
[Epoch 13; Iter   846/ 1097] train: loss: 0.0390418
[Epoch 13; Iter   876/ 1097] train: loss: 0.2017979
[Epoch 13; Iter   906/ 1097] train: loss: 0.3543061
[Epoch 13; Iter   936/ 1097] train: loss: 0.0394100
[Epoch 13; Iter   966/ 1097] train: loss: 0.0491137
[Epoch 13; Iter   996/ 1097] train: loss: 0.0446766
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0323281
[Epoch 13; Iter  1056/ 1097] train: loss: 0.3018499
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1739350
[Epoch 13] ogbg-molhiv: 0.728772 val loss: 0.103528
[Epoch 13] ogbg-molhiv: 0.652230 test loss: 0.135633
[Epoch 14; Iter    19/ 1097] train: loss: 0.2340205
[Epoch 14; Iter    49/ 1097] train: loss: 0.2242837
[Epoch 14; Iter    79/ 1097] train: loss: 0.0389417
[Epoch 14; Iter   109/ 1097] train: loss: 0.0859362
[Epoch 14; Iter   139/ 1097] train: loss: 0.0401064
[Epoch 14; Iter   169/ 1097] train: loss: 0.1814792
[Epoch 14; Iter   199/ 1097] train: loss: 0.0246151
[Epoch 14; Iter   229/ 1097] train: loss: 0.3103957
[Epoch 14; Iter   259/ 1097] train: loss: 0.2183976
[Epoch 14; Iter   289/ 1097] train: loss: 0.1105482
[Epoch 14; Iter   319/ 1097] train: loss: 0.0369331
[Epoch 14; Iter   349/ 1097] train: loss: 0.0297372
[Epoch 14; Iter   379/ 1097] train: loss: 0.0294281
[Epoch 14; Iter   409/ 1097] train: loss: 0.0865785
[Epoch 14; Iter   439/ 1097] train: loss: 0.2354561
[Epoch 14; Iter   469/ 1097] train: loss: 0.2126051
[Epoch 14; Iter   499/ 1097] train: loss: 0.0357093
[Epoch 14; Iter   529/ 1097] train: loss: 0.3501496
[Epoch 14; Iter   559/ 1097] train: loss: 0.0296622
[Epoch 14; Iter   589/ 1097] train: loss: 0.1366584
[Epoch 14; Iter   619/ 1097] train: loss: 0.2618813
[Epoch 14; Iter   649/ 1097] train: loss: 0.0346469
[Epoch 14; Iter   679/ 1097] train: loss: 0.0346133
[Epoch 14; Iter   709/ 1097] train: loss: 0.2886799
[Epoch 14; Iter   739/ 1097] train: loss: 0.1985464
[Epoch 14; Iter   769/ 1097] train: loss: 0.0215527
[Epoch 14; Iter   799/ 1097] train: loss: 0.0221406
[Epoch 14; Iter   829/ 1097] train: loss: 0.0934812
[Epoch 14; Iter   859/ 1097] train: loss: 0.0278309
[Epoch 14; Iter   889/ 1097] train: loss: 0.0516984
[Epoch 14; Iter   919/ 1097] train: loss: 0.1732660
[Epoch 14; Iter   949/ 1097] train: loss: 0.1900307
[Epoch 14; Iter   979/ 1097] train: loss: 0.0980533
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2064080
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0286096
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0578154
[Epoch 14] ogbg-molhiv: 0.747881 val loss: 1.397484
[Epoch 14] ogbg-molhiv: 0.706617 test loss: 2.403267
[Epoch 15; Iter     2/ 1097] train: loss: 0.1479698
[Epoch 15; Iter    32/ 1097] train: loss: 0.1199135
[Epoch 15; Iter    62/ 1097] train: loss: 0.1022021
[Epoch 15; Iter    92/ 1097] train: loss: 0.1063022
[Epoch 15; Iter   122/ 1097] train: loss: 0.0900902
[Epoch 15; Iter   152/ 1097] train: loss: 0.0207753
[Epoch 15; Iter   182/ 1097] train: loss: 0.1653050
[Epoch 15; Iter   212/ 1097] train: loss: 0.1955538
[Epoch 15; Iter   242/ 1097] train: loss: 0.1272646
[Epoch 15; Iter   272/ 1097] train: loss: 0.2927825
[Epoch 15; Iter   302/ 1097] train: loss: 0.1304851
[Epoch 15; Iter   332/ 1097] train: loss: 0.2067966
[Epoch 15; Iter   362/ 1097] train: loss: 0.1359669
[Epoch 15; Iter   392/ 1097] train: loss: 0.1500228
[Epoch 15; Iter   422/ 1097] train: loss: 0.1101016
[Epoch 15; Iter   452/ 1097] train: loss: 0.0407470
[Epoch 15; Iter   482/ 1097] train: loss: 0.1285170
[Epoch 15; Iter   512/ 1097] train: loss: 0.3395154
[Epoch 15; Iter   542/ 1097] train: loss: 0.1334194
[Epoch 15; Iter   572/ 1097] train: loss: 0.1129931
[Epoch 15; Iter   602/ 1097] train: loss: 0.0321698
[Epoch 15; Iter   632/ 1097] train: loss: 0.2520930
[Epoch 15; Iter   662/ 1097] train: loss: 0.0480053
[Epoch 15; Iter   692/ 1097] train: loss: 0.1545208
[Epoch 15; Iter   722/ 1097] train: loss: 0.0671312
[Epoch 15; Iter   752/ 1097] train: loss: 0.0466468
[Epoch 15; Iter   782/ 1097] train: loss: 0.0639449
[Epoch 15; Iter   812/ 1097] train: loss: 0.0439082
[Epoch 15; Iter   842/ 1097] train: loss: 0.0631129
[Epoch 15; Iter   872/ 1097] train: loss: 0.0290907
[Epoch 15; Iter   902/ 1097] train: loss: 0.0678639
[Epoch 15; Iter   932/ 1097] train: loss: 0.1616634
[Epoch 15; Iter   962/ 1097] train: loss: 0.2726168
[Epoch 15; Iter   992/ 1097] train: loss: 0.0244007
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1190011
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1634000
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0316679
[Epoch 15] ogbg-molhiv: 0.763632 val loss: 0.078011
[Epoch 15] ogbg-molhiv: 0.682794 test loss: 0.132325
[Epoch 16; Iter    15/ 1097] train: loss: 0.0250259
[Epoch 16; Iter    45/ 1097] train: loss: 0.1567875
[Epoch 16; Iter    75/ 1097] train: loss: 0.2843536
[Epoch 16; Iter   105/ 1097] train: loss: 0.0305038
[Epoch 16; Iter   135/ 1097] train: loss: 0.0546715
[Epoch 16; Iter   165/ 1097] train: loss: 0.1473634
[Epoch 16; Iter   195/ 1097] train: loss: 0.0238250
[Epoch 12; Iter   143/ 1097] train: loss: 0.1863724
[Epoch 12; Iter   173/ 1097] train: loss: 0.0219386
[Epoch 12; Iter   203/ 1097] train: loss: 0.1649325
[Epoch 12; Iter   233/ 1097] train: loss: 0.0245371
[Epoch 12; Iter   263/ 1097] train: loss: 0.0345294
[Epoch 12; Iter   293/ 1097] train: loss: 0.1816643
[Epoch 12; Iter   323/ 1097] train: loss: 0.1323135
[Epoch 12; Iter   353/ 1097] train: loss: 0.1021066
[Epoch 12; Iter   383/ 1097] train: loss: 0.0288022
[Epoch 12; Iter   413/ 1097] train: loss: 0.0275316
[Epoch 12; Iter   443/ 1097] train: loss: 0.0281635
[Epoch 12; Iter   473/ 1097] train: loss: 0.2330923
[Epoch 12; Iter   503/ 1097] train: loss: 0.1912427
[Epoch 12; Iter   533/ 1097] train: loss: 0.0424478
[Epoch 12; Iter   563/ 1097] train: loss: 0.1348273
[Epoch 12; Iter   593/ 1097] train: loss: 0.2359390
[Epoch 12; Iter   623/ 1097] train: loss: 0.0338436
[Epoch 12; Iter   653/ 1097] train: loss: 0.1071704
[Epoch 12; Iter   683/ 1097] train: loss: 0.3309786
[Epoch 12; Iter   713/ 1097] train: loss: 0.0823386
[Epoch 12; Iter   743/ 1097] train: loss: 0.0293217
[Epoch 12; Iter   773/ 1097] train: loss: 0.1384554
[Epoch 12; Iter   803/ 1097] train: loss: 0.1509715
[Epoch 12; Iter   833/ 1097] train: loss: 0.1058654
[Epoch 12; Iter   863/ 1097] train: loss: 0.0384561
[Epoch 12; Iter   893/ 1097] train: loss: 0.1925237
[Epoch 12; Iter   923/ 1097] train: loss: 0.0281933
[Epoch 12; Iter   953/ 1097] train: loss: 0.1955454
[Epoch 12; Iter   983/ 1097] train: loss: 0.2915509
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0294402
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0288864
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0261738
[Epoch 12] ogbg-molhiv: 0.781905 val loss: 0.079215
[Epoch 12] ogbg-molhiv: 0.767159 test loss: 0.116786
[Epoch 13; Iter     6/ 1097] train: loss: 0.1862923
[Epoch 13; Iter    36/ 1097] train: loss: 0.1884445
[Epoch 13; Iter    66/ 1097] train: loss: 0.1641016
[Epoch 13; Iter    96/ 1097] train: loss: 0.0204678
[Epoch 13; Iter   126/ 1097] train: loss: 0.0494776
[Epoch 13; Iter   156/ 1097] train: loss: 0.1945735
[Epoch 13; Iter   186/ 1097] train: loss: 0.3182196
[Epoch 13; Iter   216/ 1097] train: loss: 0.1805575
[Epoch 13; Iter   246/ 1097] train: loss: 0.0438561
[Epoch 13; Iter   276/ 1097] train: loss: 0.0198011
[Epoch 13; Iter   306/ 1097] train: loss: 0.3497305
[Epoch 13; Iter   336/ 1097] train: loss: 0.1357901
[Epoch 13; Iter   366/ 1097] train: loss: 0.3866086
[Epoch 13; Iter   396/ 1097] train: loss: 0.0480035
[Epoch 13; Iter   426/ 1097] train: loss: 0.1394807
[Epoch 13; Iter   456/ 1097] train: loss: 0.1633095
[Epoch 13; Iter   486/ 1097] train: loss: 0.0342148
[Epoch 13; Iter   516/ 1097] train: loss: 0.1266062
[Epoch 13; Iter   546/ 1097] train: loss: 0.0309132
[Epoch 13; Iter   576/ 1097] train: loss: 0.0877975
[Epoch 13; Iter   606/ 1097] train: loss: 0.2299199
[Epoch 13; Iter   636/ 1097] train: loss: 0.0416265
[Epoch 13; Iter   666/ 1097] train: loss: 0.1865820
[Epoch 13; Iter   696/ 1097] train: loss: 0.4664505
[Epoch 13; Iter   726/ 1097] train: loss: 0.0513465
[Epoch 13; Iter   756/ 1097] train: loss: 0.0526967
[Epoch 13; Iter   786/ 1097] train: loss: 0.1626103
[Epoch 13; Iter   816/ 1097] train: loss: 0.1053592
[Epoch 13; Iter   846/ 1097] train: loss: 0.0293186
[Epoch 13; Iter   876/ 1097] train: loss: 0.1427763
[Epoch 13; Iter   906/ 1097] train: loss: 0.3392392
[Epoch 13; Iter   936/ 1097] train: loss: 0.0543822
[Epoch 13; Iter   966/ 1097] train: loss: 0.0718063
[Epoch 13; Iter   996/ 1097] train: loss: 0.0306144
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0304921
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2754458
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1604206
[Epoch 13] ogbg-molhiv: 0.811676 val loss: 0.079683
[Epoch 13] ogbg-molhiv: 0.762373 test loss: 0.120753
[Epoch 14; Iter    19/ 1097] train: loss: 0.2675349
[Epoch 14; Iter    49/ 1097] train: loss: 0.1779684
[Epoch 14; Iter    79/ 1097] train: loss: 0.0432923
[Epoch 14; Iter   109/ 1097] train: loss: 0.1416485
[Epoch 14; Iter   139/ 1097] train: loss: 0.0385073
[Epoch 14; Iter   169/ 1097] train: loss: 0.1825392
[Epoch 14; Iter   199/ 1097] train: loss: 0.0262051
[Epoch 14; Iter   229/ 1097] train: loss: 0.2572253
[Epoch 14; Iter   259/ 1097] train: loss: 0.3158887
[Epoch 14; Iter   289/ 1097] train: loss: 0.1283868
[Epoch 14; Iter   319/ 1097] train: loss: 0.0383338
[Epoch 14; Iter   349/ 1097] train: loss: 0.0383568
[Epoch 14; Iter   379/ 1097] train: loss: 0.0578261
[Epoch 14; Iter   409/ 1097] train: loss: 0.1182462
[Epoch 14; Iter   439/ 1097] train: loss: 0.2046933
[Epoch 14; Iter   469/ 1097] train: loss: 0.2311062
[Epoch 14; Iter   499/ 1097] train: loss: 0.0318247
[Epoch 14; Iter   529/ 1097] train: loss: 0.2128621
[Epoch 14; Iter   559/ 1097] train: loss: 0.0495720
[Epoch 14; Iter   589/ 1097] train: loss: 0.1253777
[Epoch 14; Iter   619/ 1097] train: loss: 0.3154308
[Epoch 14; Iter   649/ 1097] train: loss: 0.0536076
[Epoch 14; Iter   679/ 1097] train: loss: 0.0388862
[Epoch 14; Iter   709/ 1097] train: loss: 0.3249432
[Epoch 14; Iter   739/ 1097] train: loss: 0.2251606
[Epoch 14; Iter   769/ 1097] train: loss: 0.0315196
[Epoch 14; Iter   799/ 1097] train: loss: 0.0196021
[Epoch 14; Iter   829/ 1097] train: loss: 0.1610709
[Epoch 14; Iter   859/ 1097] train: loss: 0.0370688
[Epoch 14; Iter   889/ 1097] train: loss: 0.1115402
[Epoch 14; Iter   919/ 1097] train: loss: 0.1310521
[Epoch 14; Iter   949/ 1097] train: loss: 0.1695547
[Epoch 14; Iter   979/ 1097] train: loss: 0.0846202
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2419977
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0274039
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0453007
[Epoch 14] ogbg-molhiv: 0.788831 val loss: 0.148331
[Epoch 14] ogbg-molhiv: 0.788627 test loss: 0.206713
[Epoch 15; Iter     2/ 1097] train: loss: 0.1577844
[Epoch 15; Iter    32/ 1097] train: loss: 0.0840824
[Epoch 15; Iter    62/ 1097] train: loss: 0.1120859
[Epoch 15; Iter    92/ 1097] train: loss: 0.1196407
[Epoch 15; Iter   122/ 1097] train: loss: 0.1117734
[Epoch 15; Iter   152/ 1097] train: loss: 0.0221893
[Epoch 15; Iter   182/ 1097] train: loss: 0.1273335
[Epoch 15; Iter   212/ 1097] train: loss: 0.1304387
[Epoch 15; Iter   242/ 1097] train: loss: 0.1536331
[Epoch 15; Iter   272/ 1097] train: loss: 0.3168173
[Epoch 15; Iter   302/ 1097] train: loss: 0.0989928
[Epoch 15; Iter   332/ 1097] train: loss: 0.2146528
[Epoch 15; Iter   362/ 1097] train: loss: 0.1526872
[Epoch 15; Iter   392/ 1097] train: loss: 0.1631243
[Epoch 15; Iter   422/ 1097] train: loss: 0.0497597
[Epoch 15; Iter   452/ 1097] train: loss: 0.0334920
[Epoch 15; Iter   482/ 1097] train: loss: 0.1149869
[Epoch 15; Iter   512/ 1097] train: loss: 0.3907467
[Epoch 15; Iter   542/ 1097] train: loss: 0.0683561
[Epoch 15; Iter   572/ 1097] train: loss: 0.1362863
[Epoch 15; Iter   602/ 1097] train: loss: 0.0360580
[Epoch 15; Iter   632/ 1097] train: loss: 0.2855625
[Epoch 15; Iter   662/ 1097] train: loss: 0.0695735
[Epoch 15; Iter   692/ 1097] train: loss: 0.1229835
[Epoch 15; Iter   722/ 1097] train: loss: 0.0417703
[Epoch 15; Iter   752/ 1097] train: loss: 0.0634154
[Epoch 15; Iter   782/ 1097] train: loss: 0.0824692
[Epoch 15; Iter   812/ 1097] train: loss: 0.0218286
[Epoch 15; Iter   842/ 1097] train: loss: 0.0375416
[Epoch 15; Iter   872/ 1097] train: loss: 0.0306781
[Epoch 15; Iter   902/ 1097] train: loss: 0.0576313
[Epoch 15; Iter   932/ 1097] train: loss: 0.1727364
[Epoch 15; Iter   962/ 1097] train: loss: 0.2382017
[Epoch 15; Iter   992/ 1097] train: loss: 0.0308267
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1673475
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1470315
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0474159
[Epoch 15] ogbg-molhiv: 0.774639 val loss: 0.073294
[Epoch 15] ogbg-molhiv: 0.753741 test loss: 0.123308
[Epoch 16; Iter    15/ 1097] train: loss: 0.0260575
[Epoch 16; Iter    45/ 1097] train: loss: 0.1555945
[Epoch 16; Iter    75/ 1097] train: loss: 0.1921194
[Epoch 16; Iter   105/ 1097] train: loss: 0.0262113
[Epoch 16; Iter   135/ 1097] train: loss: 0.0606379
[Epoch 16; Iter   165/ 1097] train: loss: 0.1426398
[Epoch 16; Iter   195/ 1097] train: loss: 0.0253988
[Epoch 12; Iter   143/ 1097] train: loss: 0.0658806
[Epoch 12; Iter   173/ 1097] train: loss: 0.2798362
[Epoch 12; Iter   203/ 1097] train: loss: 0.1796603
[Epoch 12; Iter   233/ 1097] train: loss: 0.3825198
[Epoch 12; Iter   263/ 1097] train: loss: 0.1955286
[Epoch 12; Iter   293/ 1097] train: loss: 0.1327613
[Epoch 12; Iter   323/ 1097] train: loss: 0.1178028
[Epoch 12; Iter   353/ 1097] train: loss: 0.0383792
[Epoch 12; Iter   383/ 1097] train: loss: 0.1926834
[Epoch 12; Iter   413/ 1097] train: loss: 0.0373802
[Epoch 12; Iter   443/ 1097] train: loss: 0.0714663
[Epoch 12; Iter   473/ 1097] train: loss: 0.0307653
[Epoch 12; Iter   503/ 1097] train: loss: 0.0469896
[Epoch 12; Iter   533/ 1097] train: loss: 0.1511696
[Epoch 12; Iter   563/ 1097] train: loss: 0.1969377
[Epoch 12; Iter   593/ 1097] train: loss: 0.2443122
[Epoch 12; Iter   623/ 1097] train: loss: 0.0281326
[Epoch 12; Iter   653/ 1097] train: loss: 0.0342397
[Epoch 12; Iter   683/ 1097] train: loss: 0.0412104
[Epoch 12; Iter   713/ 1097] train: loss: 0.2658336
[Epoch 12; Iter   743/ 1097] train: loss: 0.0437855
[Epoch 12; Iter   773/ 1097] train: loss: 0.3098374
[Epoch 12; Iter   803/ 1097] train: loss: 0.0743440
[Epoch 12; Iter   833/ 1097] train: loss: 0.0435168
[Epoch 12; Iter   863/ 1097] train: loss: 0.0331383
[Epoch 12; Iter   893/ 1097] train: loss: 0.0859030
[Epoch 12; Iter   923/ 1097] train: loss: 0.0244313
[Epoch 12; Iter   953/ 1097] train: loss: 0.0521734
[Epoch 12; Iter   983/ 1097] train: loss: 0.1694576
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0219287
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1901407
[Epoch 12; Iter  1073/ 1097] train: loss: 0.2200059
[Epoch 12] ogbg-molhiv: 0.780102 val loss: 0.091567
[Epoch 12] ogbg-molhiv: 0.737853 test loss: 0.127402
[Epoch 13; Iter     6/ 1097] train: loss: 0.0791769
[Epoch 13; Iter    36/ 1097] train: loss: 0.0368448
[Epoch 13; Iter    66/ 1097] train: loss: 0.0438902
[Epoch 13; Iter    96/ 1097] train: loss: 0.0968864
[Epoch 13; Iter   126/ 1097] train: loss: 0.0247780
[Epoch 13; Iter   156/ 1097] train: loss: 0.2840361
[Epoch 13; Iter   186/ 1097] train: loss: 0.1480937
[Epoch 13; Iter   216/ 1097] train: loss: 0.1174046
[Epoch 13; Iter   246/ 1097] train: loss: 0.1375506
[Epoch 13; Iter   276/ 1097] train: loss: 0.0436437
[Epoch 13; Iter   306/ 1097] train: loss: 0.0206810
[Epoch 13; Iter   336/ 1097] train: loss: 0.0220153
[Epoch 13; Iter   366/ 1097] train: loss: 0.0249923
[Epoch 13; Iter   396/ 1097] train: loss: 0.2230705
[Epoch 13; Iter   426/ 1097] train: loss: 0.0590422
[Epoch 13; Iter   456/ 1097] train: loss: 0.1795263
[Epoch 13; Iter   486/ 1097] train: loss: 0.0443347
[Epoch 13; Iter   516/ 1097] train: loss: 0.1266099
[Epoch 13; Iter   546/ 1097] train: loss: 0.1632278
[Epoch 13; Iter   576/ 1097] train: loss: 0.1934927
[Epoch 13; Iter   606/ 1097] train: loss: 0.0433864
[Epoch 13; Iter   636/ 1097] train: loss: 0.1926180
[Epoch 13; Iter   666/ 1097] train: loss: 0.0264459
[Epoch 13; Iter   696/ 1097] train: loss: 0.1839136
[Epoch 13; Iter   726/ 1097] train: loss: 0.3321521
[Epoch 13; Iter   756/ 1097] train: loss: 0.1814082
[Epoch 13; Iter   786/ 1097] train: loss: 0.3929790
[Epoch 13; Iter   816/ 1097] train: loss: 0.5006202
[Epoch 13; Iter   846/ 1097] train: loss: 0.0643722
[Epoch 13; Iter   876/ 1097] train: loss: 0.0309861
[Epoch 13; Iter   906/ 1097] train: loss: 0.3798193
[Epoch 13; Iter   936/ 1097] train: loss: 0.0326246
[Epoch 13; Iter   966/ 1097] train: loss: 0.0901835
[Epoch 13; Iter   996/ 1097] train: loss: 0.0535318
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1691800
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0898259
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2039192
[Epoch 13] ogbg-molhiv: 0.818030 val loss: 0.170176
[Epoch 13] ogbg-molhiv: 0.775137 test loss: 0.153620
[Epoch 14; Iter    19/ 1097] train: loss: 0.0384221
[Epoch 14; Iter    49/ 1097] train: loss: 0.0343186
[Epoch 14; Iter    79/ 1097] train: loss: 0.2407191
[Epoch 14; Iter   109/ 1097] train: loss: 0.1967665
[Epoch 14; Iter   139/ 1097] train: loss: 0.1560904
[Epoch 14; Iter   169/ 1097] train: loss: 0.1713554
[Epoch 14; Iter   199/ 1097] train: loss: 0.0184925
[Epoch 14; Iter   229/ 1097] train: loss: 0.1358924
[Epoch 14; Iter   259/ 1097] train: loss: 0.0386679
[Epoch 14; Iter   289/ 1097] train: loss: 0.1137365
[Epoch 14; Iter   319/ 1097] train: loss: 0.1491410
[Epoch 14; Iter   349/ 1097] train: loss: 0.0347640
[Epoch 14; Iter   379/ 1097] train: loss: 0.0936975
[Epoch 14; Iter   409/ 1097] train: loss: 0.0381063
[Epoch 14; Iter   439/ 1097] train: loss: 0.1673706
[Epoch 14; Iter   469/ 1097] train: loss: 0.2128379
[Epoch 14; Iter   499/ 1097] train: loss: 0.1501587
[Epoch 14; Iter   529/ 1097] train: loss: 0.0491461
[Epoch 14; Iter   559/ 1097] train: loss: 0.2305389
[Epoch 14; Iter   589/ 1097] train: loss: 0.1376593
[Epoch 14; Iter   619/ 1097] train: loss: 0.1801910
[Epoch 14; Iter   649/ 1097] train: loss: 0.1635341
[Epoch 14; Iter   679/ 1097] train: loss: 0.0290581
[Epoch 14; Iter   709/ 1097] train: loss: 0.0780925
[Epoch 14; Iter   739/ 1097] train: loss: 0.0559295
[Epoch 14; Iter   769/ 1097] train: loss: 0.0220189
[Epoch 14; Iter   799/ 1097] train: loss: 0.0549468
[Epoch 14; Iter   829/ 1097] train: loss: 0.1514839
[Epoch 14; Iter   859/ 1097] train: loss: 0.2435948
[Epoch 14; Iter   889/ 1097] train: loss: 0.0289837
[Epoch 14; Iter   919/ 1097] train: loss: 0.0277400
[Epoch 14; Iter   949/ 1097] train: loss: 0.0268102
[Epoch 14; Iter   979/ 1097] train: loss: 0.2870754
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0404593
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2614763
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0436694
[Epoch 14] ogbg-molhiv: 0.811232 val loss: 0.112518
[Epoch 14] ogbg-molhiv: 0.752212 test loss: 0.265239
[Epoch 15; Iter     2/ 1097] train: loss: 0.0673245
[Epoch 15; Iter    32/ 1097] train: loss: 0.0325227
[Epoch 15; Iter    62/ 1097] train: loss: 0.0938070
[Epoch 15; Iter    92/ 1097] train: loss: 0.0431547
[Epoch 15; Iter   122/ 1097] train: loss: 0.0293968
[Epoch 15; Iter   152/ 1097] train: loss: 0.1947254
[Epoch 15; Iter   182/ 1097] train: loss: 0.0545088
[Epoch 15; Iter   212/ 1097] train: loss: 0.3050854
[Epoch 15; Iter   242/ 1097] train: loss: 0.0820525
[Epoch 15; Iter   272/ 1097] train: loss: 0.1433301
[Epoch 15; Iter   302/ 1097] train: loss: 0.1744710
[Epoch 15; Iter   332/ 1097] train: loss: 0.0832569
[Epoch 15; Iter   362/ 1097] train: loss: 0.1683030
[Epoch 15; Iter   392/ 1097] train: loss: 0.0650620
[Epoch 15; Iter   422/ 1097] train: loss: 0.0429128
[Epoch 15; Iter   452/ 1097] train: loss: 0.3122780
[Epoch 15; Iter   482/ 1097] train: loss: 0.0305701
[Epoch 15; Iter   512/ 1097] train: loss: 0.2005054
[Epoch 15; Iter   542/ 1097] train: loss: 0.0281114
[Epoch 15; Iter   572/ 1097] train: loss: 0.1320711
[Epoch 15; Iter   602/ 1097] train: loss: 0.0190240
[Epoch 15; Iter   632/ 1097] train: loss: 0.1150647
[Epoch 15; Iter   662/ 1097] train: loss: 0.1604948
[Epoch 15; Iter   692/ 1097] train: loss: 0.0439960
[Epoch 15; Iter   722/ 1097] train: loss: 0.3549605
[Epoch 15; Iter   752/ 1097] train: loss: 0.0820798
[Epoch 15; Iter   782/ 1097] train: loss: 0.1650642
[Epoch 15; Iter   812/ 1097] train: loss: 0.0227952
[Epoch 15; Iter   842/ 1097] train: loss: 0.2540176
[Epoch 15; Iter   872/ 1097] train: loss: 0.0473772
[Epoch 15; Iter   902/ 1097] train: loss: 0.1233071
[Epoch 15; Iter   932/ 1097] train: loss: 0.0311978
[Epoch 15; Iter   962/ 1097] train: loss: 0.1518519
[Epoch 15; Iter   992/ 1097] train: loss: 0.1504143
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5648227
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0346568
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0403694
[Epoch 15] ogbg-molhiv: 0.789854 val loss: 1.578787
[Epoch 15] ogbg-molhiv: 0.753703 test loss: 1.425513
[Epoch 16; Iter    15/ 1097] train: loss: 0.1740887
[Epoch 16; Iter    45/ 1097] train: loss: 0.0815163
[Epoch 16; Iter    75/ 1097] train: loss: 0.1011378
[Epoch 16; Iter   105/ 1097] train: loss: 0.1088720
[Epoch 16; Iter   135/ 1097] train: loss: 0.0459674
[Epoch 16; Iter   165/ 1097] train: loss: 0.5299258
[Epoch 16; Iter   195/ 1097] train: loss: 0.0346419
[Epoch 12; Iter   143/ 1097] train: loss: 0.3065137
[Epoch 12; Iter   173/ 1097] train: loss: 0.0384861
[Epoch 12; Iter   203/ 1097] train: loss: 0.0288897
[Epoch 12; Iter   233/ 1097] train: loss: 0.0280103
[Epoch 12; Iter   263/ 1097] train: loss: 0.0295556
[Epoch 12; Iter   293/ 1097] train: loss: 0.1313785
[Epoch 12; Iter   323/ 1097] train: loss: 0.1540004
[Epoch 12; Iter   353/ 1097] train: loss: 0.2254554
[Epoch 12; Iter   383/ 1097] train: loss: 0.0504222
[Epoch 12; Iter   413/ 1097] train: loss: 0.2147356
[Epoch 12; Iter   443/ 1097] train: loss: 0.3177124
[Epoch 12; Iter   473/ 1097] train: loss: 0.1455223
[Epoch 12; Iter   503/ 1097] train: loss: 0.1769029
[Epoch 12; Iter   533/ 1097] train: loss: 0.1793778
[Epoch 12; Iter   563/ 1097] train: loss: 0.0872539
[Epoch 12; Iter   593/ 1097] train: loss: 0.3306254
[Epoch 12; Iter   623/ 1097] train: loss: 0.1888133
[Epoch 12; Iter   653/ 1097] train: loss: 0.0399960
[Epoch 12; Iter   683/ 1097] train: loss: 0.1679076
[Epoch 12; Iter   713/ 1097] train: loss: 0.0393776
[Epoch 12; Iter   743/ 1097] train: loss: 0.2060149
[Epoch 12; Iter   773/ 1097] train: loss: 0.0272626
[Epoch 12; Iter   803/ 1097] train: loss: 0.1975094
[Epoch 12; Iter   833/ 1097] train: loss: 0.1631453
[Epoch 12; Iter   863/ 1097] train: loss: 0.2591580
[Epoch 12; Iter   893/ 1097] train: loss: 0.0271873
[Epoch 12; Iter   923/ 1097] train: loss: 0.2259042
[Epoch 12; Iter   953/ 1097] train: loss: 0.2360697
[Epoch 12; Iter   983/ 1097] train: loss: 0.0663915
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0554881
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1371213
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0812790
[Epoch 12] ogbg-molhiv: 0.794438 val loss: 0.083972
[Epoch 12] ogbg-molhiv: 0.736799 test loss: 0.126816
[Epoch 13; Iter     6/ 1097] train: loss: 0.0323530
[Epoch 13; Iter    36/ 1097] train: loss: 0.2662985
[Epoch 13; Iter    66/ 1097] train: loss: 0.1519284
[Epoch 13; Iter    96/ 1097] train: loss: 0.0660462
[Epoch 13; Iter   126/ 1097] train: loss: 0.0238777
[Epoch 13; Iter   156/ 1097] train: loss: 0.0225518
[Epoch 13; Iter   186/ 1097] train: loss: 0.1931564
[Epoch 13; Iter   216/ 1097] train: loss: 0.1834909
[Epoch 13; Iter   246/ 1097] train: loss: 0.0259534
[Epoch 13; Iter   276/ 1097] train: loss: 0.0869797
[Epoch 13; Iter   306/ 1097] train: loss: 0.0210993
[Epoch 13; Iter   336/ 1097] train: loss: 0.1362176
[Epoch 13; Iter   366/ 1097] train: loss: 0.1469733
[Epoch 13; Iter   396/ 1097] train: loss: 0.1503223
[Epoch 13; Iter   426/ 1097] train: loss: 0.0462792
[Epoch 13; Iter   456/ 1097] train: loss: 0.0523000
[Epoch 13; Iter   486/ 1097] train: loss: 0.0648877
[Epoch 13; Iter   516/ 1097] train: loss: 0.0286528
[Epoch 13; Iter   546/ 1097] train: loss: 0.0245860
[Epoch 13; Iter   576/ 1097] train: loss: 0.2069490
[Epoch 13; Iter   606/ 1097] train: loss: 0.0727596
[Epoch 13; Iter   636/ 1097] train: loss: 0.2882788
[Epoch 13; Iter   666/ 1097] train: loss: 0.0223179
[Epoch 13; Iter   696/ 1097] train: loss: 0.0285919
[Epoch 13; Iter   726/ 1097] train: loss: 0.0550182
[Epoch 13; Iter   756/ 1097] train: loss: 0.0571426
[Epoch 13; Iter   786/ 1097] train: loss: 0.1907869
[Epoch 13; Iter   816/ 1097] train: loss: 0.0252800
[Epoch 13; Iter   846/ 1097] train: loss: 0.0179501
[Epoch 13; Iter   876/ 1097] train: loss: 0.2171511
[Epoch 13; Iter   906/ 1097] train: loss: 0.2616194
[Epoch 13; Iter   936/ 1097] train: loss: 0.1896343
[Epoch 13; Iter   966/ 1097] train: loss: 0.1281037
[Epoch 13; Iter   996/ 1097] train: loss: 0.1254704
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3260520
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2124580
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1511692
[Epoch 13] ogbg-molhiv: 0.789214 val loss: 0.075752
[Epoch 13] ogbg-molhiv: 0.755996 test loss: 0.114294
[Epoch 14; Iter    19/ 1097] train: loss: 0.0393059
[Epoch 14; Iter    49/ 1097] train: loss: 0.2922467
[Epoch 14; Iter    79/ 1097] train: loss: 0.0316743
[Epoch 14; Iter   109/ 1097] train: loss: 0.0253224
[Epoch 14; Iter   139/ 1097] train: loss: 0.1110432
[Epoch 14; Iter   169/ 1097] train: loss: 0.1356327
[Epoch 14; Iter   199/ 1097] train: loss: 0.0711498
[Epoch 14; Iter   229/ 1097] train: loss: 0.0244768
[Epoch 14; Iter   259/ 1097] train: loss: 0.0547126
[Epoch 14; Iter   289/ 1097] train: loss: 0.0626355
[Epoch 14; Iter   319/ 1097] train: loss: 0.2700351
[Epoch 14; Iter   349/ 1097] train: loss: 0.1809886
[Epoch 14; Iter   379/ 1097] train: loss: 0.1534703
[Epoch 14; Iter   409/ 1097] train: loss: 0.0995839
[Epoch 14; Iter   439/ 1097] train: loss: 0.1552857
[Epoch 14; Iter   469/ 1097] train: loss: 0.1802693
[Epoch 14; Iter   499/ 1097] train: loss: 0.0212649
[Epoch 14; Iter   529/ 1097] train: loss: 0.0216694
[Epoch 14; Iter   559/ 1097] train: loss: 0.1964792
[Epoch 14; Iter   589/ 1097] train: loss: 0.0287423
[Epoch 14; Iter   619/ 1097] train: loss: 0.0428843
[Epoch 14; Iter   649/ 1097] train: loss: 0.0318983
[Epoch 14; Iter   679/ 1097] train: loss: 0.1356522
[Epoch 14; Iter   709/ 1097] train: loss: 0.1998633
[Epoch 14; Iter   739/ 1097] train: loss: 0.0511961
[Epoch 14; Iter   769/ 1097] train: loss: 0.1174506
[Epoch 14; Iter   799/ 1097] train: loss: 0.0539313
[Epoch 14; Iter   829/ 1097] train: loss: 0.0702481
[Epoch 14; Iter   859/ 1097] train: loss: 0.0345807
[Epoch 14; Iter   889/ 1097] train: loss: 0.0277186
[Epoch 14; Iter   919/ 1097] train: loss: 0.0483559
[Epoch 14; Iter   949/ 1097] train: loss: 0.0387508
[Epoch 14; Iter   979/ 1097] train: loss: 0.1709920
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0228538
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0327027
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1320273
[Epoch 14] ogbg-molhiv: 0.782729 val loss: 0.086863
[Epoch 14] ogbg-molhiv: 0.716549 test loss: 0.129087
[Epoch 15; Iter     2/ 1097] train: loss: 0.1725111
[Epoch 15; Iter    32/ 1097] train: loss: 0.0309485
[Epoch 15; Iter    62/ 1097] train: loss: 0.1934611
[Epoch 15; Iter    92/ 1097] train: loss: 0.0253368
[Epoch 15; Iter   122/ 1097] train: loss: 0.1826391
[Epoch 15; Iter   152/ 1097] train: loss: 0.2213352
[Epoch 15; Iter   182/ 1097] train: loss: 0.1955640
[Epoch 15; Iter   212/ 1097] train: loss: 0.0253233
[Epoch 15; Iter   242/ 1097] train: loss: 0.0433426
[Epoch 15; Iter   272/ 1097] train: loss: 0.1506364
[Epoch 15; Iter   302/ 1097] train: loss: 0.1360622
[Epoch 15; Iter   332/ 1097] train: loss: 0.0213783
[Epoch 15; Iter   362/ 1097] train: loss: 0.0546616
[Epoch 15; Iter   392/ 1097] train: loss: 0.1665388
[Epoch 15; Iter   422/ 1097] train: loss: 0.1905185
[Epoch 15; Iter   452/ 1097] train: loss: 0.0754537
[Epoch 15; Iter   482/ 1097] train: loss: 0.1279087
[Epoch 15; Iter   512/ 1097] train: loss: 0.2415869
[Epoch 15; Iter   542/ 1097] train: loss: 0.0615660
[Epoch 15; Iter   572/ 1097] train: loss: 0.0239990
[Epoch 15; Iter   602/ 1097] train: loss: 0.3522414
[Epoch 15; Iter   632/ 1097] train: loss: 0.0261148
[Epoch 15; Iter   662/ 1097] train: loss: 0.1585694
[Epoch 15; Iter   692/ 1097] train: loss: 0.0233887
[Epoch 15; Iter   722/ 1097] train: loss: 0.0821074
[Epoch 15; Iter   752/ 1097] train: loss: 0.2168119
[Epoch 15; Iter   782/ 1097] train: loss: 0.1882240
[Epoch 15; Iter   812/ 1097] train: loss: 0.2238752
[Epoch 15; Iter   842/ 1097] train: loss: 0.0223861
[Epoch 15; Iter   872/ 1097] train: loss: 0.0271212
[Epoch 15; Iter   902/ 1097] train: loss: 0.2316387
[Epoch 15; Iter   932/ 1097] train: loss: 0.0813338
[Epoch 15; Iter   962/ 1097] train: loss: 0.0354338
[Epoch 15; Iter   992/ 1097] train: loss: 0.0383225
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0189922
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0739404
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0244759
[Epoch 15] ogbg-molhiv: 0.776718 val loss: 0.075191
[Epoch 15] ogbg-molhiv: 0.731333 test loss: 0.114418
[Epoch 16; Iter    15/ 1097] train: loss: 0.0457308
[Epoch 16; Iter    45/ 1097] train: loss: 0.0411789
[Epoch 16; Iter    75/ 1097] train: loss: 0.0176926
[Epoch 16; Iter   105/ 1097] train: loss: 0.0248179
[Epoch 16; Iter   135/ 1097] train: loss: 0.0310198
[Epoch 16; Iter   165/ 1097] train: loss: 0.2958682
[Epoch 16; Iter   195/ 1097] train: loss: 0.1045759
[Epoch 12; Iter   143/ 1097] train: loss: 0.1058828
[Epoch 12; Iter   173/ 1097] train: loss: 0.3434388
[Epoch 12; Iter   203/ 1097] train: loss: 0.1387334
[Epoch 12; Iter   233/ 1097] train: loss: 0.3212597
[Epoch 12; Iter   263/ 1097] train: loss: 0.0998679
[Epoch 12; Iter   293/ 1097] train: loss: 0.1311423
[Epoch 12; Iter   323/ 1097] train: loss: 0.0975562
[Epoch 12; Iter   353/ 1097] train: loss: 0.0235641
[Epoch 12; Iter   383/ 1097] train: loss: 0.1463984
[Epoch 12; Iter   413/ 1097] train: loss: 0.0377512
[Epoch 12; Iter   443/ 1097] train: loss: 0.1557199
[Epoch 12; Iter   473/ 1097] train: loss: 0.0289494
[Epoch 12; Iter   503/ 1097] train: loss: 0.0722834
[Epoch 12; Iter   533/ 1097] train: loss: 0.1331142
[Epoch 12; Iter   563/ 1097] train: loss: 0.1334428
[Epoch 12; Iter   593/ 1097] train: loss: 0.2983473
[Epoch 12; Iter   623/ 1097] train: loss: 0.0442070
[Epoch 12; Iter   653/ 1097] train: loss: 0.0315990
[Epoch 12; Iter   683/ 1097] train: loss: 0.0257708
[Epoch 12; Iter   713/ 1097] train: loss: 0.2083045
[Epoch 12; Iter   743/ 1097] train: loss: 0.0354164
[Epoch 12; Iter   773/ 1097] train: loss: 0.3132356
[Epoch 12; Iter   803/ 1097] train: loss: 0.1173797
[Epoch 12; Iter   833/ 1097] train: loss: 0.0403084
[Epoch 12; Iter   863/ 1097] train: loss: 0.0319418
[Epoch 12; Iter   893/ 1097] train: loss: 0.1149894
[Epoch 12; Iter   923/ 1097] train: loss: 0.0319914
[Epoch 12; Iter   953/ 1097] train: loss: 0.0457678
[Epoch 12; Iter   983/ 1097] train: loss: 0.1747380
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0267275
[Epoch 12; Iter  1043/ 1097] train: loss: 0.3070821
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1311550
[Epoch 12] ogbg-molhiv: 0.637520 val loss: 0.147801
[Epoch 12] ogbg-molhiv: 0.691719 test loss: 0.143712
[Epoch 13; Iter     6/ 1097] train: loss: 0.0934942
[Epoch 13; Iter    36/ 1097] train: loss: 0.0444781
[Epoch 13; Iter    66/ 1097] train: loss: 0.1043698
[Epoch 13; Iter    96/ 1097] train: loss: 0.0739318
[Epoch 13; Iter   126/ 1097] train: loss: 0.0394804
[Epoch 13; Iter   156/ 1097] train: loss: 0.2382582
[Epoch 13; Iter   186/ 1097] train: loss: 0.1957119
[Epoch 13; Iter   216/ 1097] train: loss: 0.1670201
[Epoch 13; Iter   246/ 1097] train: loss: 0.1476946
[Epoch 13; Iter   276/ 1097] train: loss: 0.0334595
[Epoch 13; Iter   306/ 1097] train: loss: 0.0375520
[Epoch 13; Iter   336/ 1097] train: loss: 0.0472468
[Epoch 13; Iter   366/ 1097] train: loss: 0.0224179
[Epoch 13; Iter   396/ 1097] train: loss: 0.2478308
[Epoch 13; Iter   426/ 1097] train: loss: 0.0408200
[Epoch 13; Iter   456/ 1097] train: loss: 0.1878307
[Epoch 13; Iter   486/ 1097] train: loss: 0.0307213
[Epoch 13; Iter   516/ 1097] train: loss: 0.1141828
[Epoch 13; Iter   546/ 1097] train: loss: 0.1499971
[Epoch 13; Iter   576/ 1097] train: loss: 0.1549415
[Epoch 13; Iter   606/ 1097] train: loss: 0.0336520
[Epoch 13; Iter   636/ 1097] train: loss: 0.1134598
[Epoch 13; Iter   666/ 1097] train: loss: 0.0320973
[Epoch 13; Iter   696/ 1097] train: loss: 0.1225932
[Epoch 13; Iter   726/ 1097] train: loss: 0.2137109
[Epoch 13; Iter   756/ 1097] train: loss: 0.1930402
[Epoch 13; Iter   786/ 1097] train: loss: 0.3478585
[Epoch 13; Iter   816/ 1097] train: loss: 0.4321413
[Epoch 13; Iter   846/ 1097] train: loss: 0.0581636
[Epoch 13; Iter   876/ 1097] train: loss: 0.0393814
[Epoch 13; Iter   906/ 1097] train: loss: 0.5008566
[Epoch 13; Iter   936/ 1097] train: loss: 0.0244391
[Epoch 13; Iter   966/ 1097] train: loss: 0.0776952
[Epoch 13; Iter   996/ 1097] train: loss: 0.1201729
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1419352
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0976973
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1736692
[Epoch 13] ogbg-molhiv: 0.707568 val loss: 3.228492
[Epoch 13] ogbg-molhiv: 0.701765 test loss: 2.852976
[Epoch 14; Iter    19/ 1097] train: loss: 0.0518516
[Epoch 14; Iter    49/ 1097] train: loss: 0.0359322
[Epoch 14; Iter    79/ 1097] train: loss: 0.2055023
[Epoch 14; Iter   109/ 1097] train: loss: 0.1374308
[Epoch 14; Iter   139/ 1097] train: loss: 0.0242011
[Epoch 14; Iter   169/ 1097] train: loss: 0.1155441
[Epoch 14; Iter   199/ 1097] train: loss: 0.0389747
[Epoch 14; Iter   229/ 1097] train: loss: 0.0854498
[Epoch 14; Iter   259/ 1097] train: loss: 0.0578216
[Epoch 14; Iter   289/ 1097] train: loss: 0.1254962
[Epoch 14; Iter   319/ 1097] train: loss: 0.1840868
[Epoch 14; Iter   349/ 1097] train: loss: 0.0491885
[Epoch 14; Iter   379/ 1097] train: loss: 0.0805960
[Epoch 14; Iter   409/ 1097] train: loss: 0.0264817
[Epoch 14; Iter   439/ 1097] train: loss: 0.1801083
[Epoch 14; Iter   469/ 1097] train: loss: 0.2407222
[Epoch 14; Iter   499/ 1097] train: loss: 0.0721461
[Epoch 14; Iter   529/ 1097] train: loss: 0.1586372
[Epoch 14; Iter   559/ 1097] train: loss: 0.3307680
[Epoch 14; Iter   589/ 1097] train: loss: 0.1532436
[Epoch 14; Iter   619/ 1097] train: loss: 0.1666296
[Epoch 14; Iter   649/ 1097] train: loss: 0.1827134
[Epoch 14; Iter   679/ 1097] train: loss: 0.0293655
[Epoch 14; Iter   709/ 1097] train: loss: 0.0829014
[Epoch 14; Iter   739/ 1097] train: loss: 0.0873739
[Epoch 14; Iter   769/ 1097] train: loss: 0.0778681
[Epoch 14; Iter   799/ 1097] train: loss: 0.0785230
[Epoch 14; Iter   829/ 1097] train: loss: 0.1043637
[Epoch 14; Iter   859/ 1097] train: loss: 0.2807219
[Epoch 14; Iter   889/ 1097] train: loss: 0.0296316
[Epoch 14; Iter   919/ 1097] train: loss: 0.0319514
[Epoch 14; Iter   949/ 1097] train: loss: 0.0550929
[Epoch 14; Iter   979/ 1097] train: loss: 0.1923682
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0605178
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2366448
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0569873
[Epoch 14] ogbg-molhiv: 0.627113 val loss: 0.834232
[Epoch 14] ogbg-molhiv: 0.675021 test loss: 0.778209
[Epoch 15; Iter     2/ 1097] train: loss: 0.0873660
[Epoch 15; Iter    32/ 1097] train: loss: 0.0360838
[Epoch 15; Iter    62/ 1097] train: loss: 0.1275907
[Epoch 15; Iter    92/ 1097] train: loss: 0.0473970
[Epoch 15; Iter   122/ 1097] train: loss: 0.0325830
[Epoch 15; Iter   152/ 1097] train: loss: 0.2499026
[Epoch 15; Iter   182/ 1097] train: loss: 0.0327786
[Epoch 15; Iter   212/ 1097] train: loss: 0.3215897
[Epoch 15; Iter   242/ 1097] train: loss: 0.0490085
[Epoch 15; Iter   272/ 1097] train: loss: 0.0827073
[Epoch 15; Iter   302/ 1097] train: loss: 0.2115872
[Epoch 15; Iter   332/ 1097] train: loss: 0.0700484
[Epoch 15; Iter   362/ 1097] train: loss: 0.2349308
[Epoch 15; Iter   392/ 1097] train: loss: 0.0391884
[Epoch 15; Iter   422/ 1097] train: loss: 0.0491476
[Epoch 15; Iter   452/ 1097] train: loss: 0.3166293
[Epoch 15; Iter   482/ 1097] train: loss: 0.0260141
[Epoch 15; Iter   512/ 1097] train: loss: 0.2356405
[Epoch 15; Iter   542/ 1097] train: loss: 0.0457497
[Epoch 15; Iter   572/ 1097] train: loss: 0.1293248
[Epoch 15; Iter   602/ 1097] train: loss: 0.0242313
[Epoch 15; Iter   632/ 1097] train: loss: 0.1124152
[Epoch 15; Iter   662/ 1097] train: loss: 0.1379820
[Epoch 15; Iter   692/ 1097] train: loss: 0.0374215
[Epoch 15; Iter   722/ 1097] train: loss: 0.2275690
[Epoch 15; Iter   752/ 1097] train: loss: 0.0981627
[Epoch 15; Iter   782/ 1097] train: loss: 0.1267729
[Epoch 15; Iter   812/ 1097] train: loss: 0.0612678
[Epoch 15; Iter   842/ 1097] train: loss: 0.2078605
[Epoch 15; Iter   872/ 1097] train: loss: 0.0481313
[Epoch 15; Iter   902/ 1097] train: loss: 0.1781744
[Epoch 15; Iter   932/ 1097] train: loss: 0.0358535
[Epoch 15; Iter   962/ 1097] train: loss: 0.0968084
[Epoch 15; Iter   992/ 1097] train: loss: 0.1615363
[Epoch 15; Iter  1022/ 1097] train: loss: 0.4684209
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0284963
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0317958
[Epoch 15] ogbg-molhiv: 0.678366 val loss: 0.791399
[Epoch 15] ogbg-molhiv: 0.688524 test loss: 0.248562
[Epoch 16; Iter    15/ 1097] train: loss: 0.0556313
[Epoch 16; Iter    45/ 1097] train: loss: 0.0607689
[Epoch 16; Iter    75/ 1097] train: loss: 0.0708613
[Epoch 16; Iter   105/ 1097] train: loss: 0.1110473
[Epoch 16; Iter   135/ 1097] train: loss: 0.1350536
[Epoch 16; Iter   165/ 1097] train: loss: 0.4602441
[Epoch 16; Iter   195/ 1097] train: loss: 0.0322531
[Epoch 12; Iter   143/ 1097] train: loss: 0.2046336
[Epoch 12; Iter   173/ 1097] train: loss: 0.0499254
[Epoch 12; Iter   203/ 1097] train: loss: 0.1312750
[Epoch 12; Iter   233/ 1097] train: loss: 0.0213206
[Epoch 12; Iter   263/ 1097] train: loss: 0.0372570
[Epoch 12; Iter   293/ 1097] train: loss: 0.2140041
[Epoch 12; Iter   323/ 1097] train: loss: 0.1843669
[Epoch 12; Iter   353/ 1097] train: loss: 0.1160372
[Epoch 12; Iter   383/ 1097] train: loss: 0.0344902
[Epoch 12; Iter   413/ 1097] train: loss: 0.0237342
[Epoch 12; Iter   443/ 1097] train: loss: 0.0415390
[Epoch 12; Iter   473/ 1097] train: loss: 0.2869441
[Epoch 12; Iter   503/ 1097] train: loss: 0.2210728
[Epoch 12; Iter   533/ 1097] train: loss: 0.0343578
[Epoch 12; Iter   563/ 1097] train: loss: 0.1273078
[Epoch 12; Iter   593/ 1097] train: loss: 0.1609470
[Epoch 12; Iter   623/ 1097] train: loss: 0.0368830
[Epoch 12; Iter   653/ 1097] train: loss: 0.1625531
[Epoch 12; Iter   683/ 1097] train: loss: 0.3529477
[Epoch 12; Iter   713/ 1097] train: loss: 0.1366606
[Epoch 12; Iter   743/ 1097] train: loss: 0.0277857
[Epoch 12; Iter   773/ 1097] train: loss: 0.2795214
[Epoch 12; Iter   803/ 1097] train: loss: 0.1866549
[Epoch 12; Iter   833/ 1097] train: loss: 0.1517759
[Epoch 12; Iter   863/ 1097] train: loss: 0.0574149
[Epoch 12; Iter   893/ 1097] train: loss: 0.0963279
[Epoch 12; Iter   923/ 1097] train: loss: 0.0393672
[Epoch 12; Iter   953/ 1097] train: loss: 0.2357395
[Epoch 12; Iter   983/ 1097] train: loss: 0.3736056
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0309577
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0260355
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0308245
[Epoch 12] ogbg-molhiv: 0.748732 val loss: 1.364595
[Epoch 12] ogbg-molhiv: 0.692704 test loss: 1.428288
[Epoch 13; Iter     6/ 1097] train: loss: 0.1186429
[Epoch 13; Iter    36/ 1097] train: loss: 0.1605189
[Epoch 13; Iter    66/ 1097] train: loss: 0.1594039
[Epoch 13; Iter    96/ 1097] train: loss: 0.0328997
[Epoch 13; Iter   126/ 1097] train: loss: 0.0676990
[Epoch 13; Iter   156/ 1097] train: loss: 0.2064904
[Epoch 13; Iter   186/ 1097] train: loss: 0.3054772
[Epoch 13; Iter   216/ 1097] train: loss: 0.1655397
[Epoch 13; Iter   246/ 1097] train: loss: 0.0492559
[Epoch 13; Iter   276/ 1097] train: loss: 0.0263281
[Epoch 13; Iter   306/ 1097] train: loss: 0.3591182
[Epoch 13; Iter   336/ 1097] train: loss: 0.1760642
[Epoch 13; Iter   366/ 1097] train: loss: 0.3962553
[Epoch 13; Iter   396/ 1097] train: loss: 0.0500139
[Epoch 13; Iter   426/ 1097] train: loss: 0.0787506
[Epoch 13; Iter   456/ 1097] train: loss: 0.1410419
[Epoch 13; Iter   486/ 1097] train: loss: 0.0440682
[Epoch 13; Iter   516/ 1097] train: loss: 0.2329588
[Epoch 13; Iter   546/ 1097] train: loss: 0.0230328
[Epoch 13; Iter   576/ 1097] train: loss: 0.0887593
[Epoch 13; Iter   606/ 1097] train: loss: 0.2187512
[Epoch 13; Iter   636/ 1097] train: loss: 0.0569637
[Epoch 13; Iter   666/ 1097] train: loss: 0.1704980
[Epoch 13; Iter   696/ 1097] train: loss: 0.3634721
[Epoch 13; Iter   726/ 1097] train: loss: 0.1132100
[Epoch 13; Iter   756/ 1097] train: loss: 0.0446870
[Epoch 13; Iter   786/ 1097] train: loss: 0.2720211
[Epoch 13; Iter   816/ 1097] train: loss: 0.1251097
[Epoch 13; Iter   846/ 1097] train: loss: 0.0341320
[Epoch 13; Iter   876/ 1097] train: loss: 0.2393005
[Epoch 13; Iter   906/ 1097] train: loss: 0.2894531
[Epoch 13; Iter   936/ 1097] train: loss: 0.0315684
[Epoch 13; Iter   966/ 1097] train: loss: 0.0443426
[Epoch 13; Iter   996/ 1097] train: loss: 0.0326190
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0282750
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2860068
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1875171
[Epoch 13] ogbg-molhiv: 0.750824 val loss: 0.102196
[Epoch 13] ogbg-molhiv: 0.677163 test loss: 0.139429
[Epoch 14; Iter    19/ 1097] train: loss: 0.2667422
[Epoch 14; Iter    49/ 1097] train: loss: 0.1359113
[Epoch 14; Iter    79/ 1097] train: loss: 0.0551710
[Epoch 14; Iter   109/ 1097] train: loss: 0.1253061
[Epoch 14; Iter   139/ 1097] train: loss: 0.0283938
[Epoch 14; Iter   169/ 1097] train: loss: 0.1941328
[Epoch 14; Iter   199/ 1097] train: loss: 0.0334443
[Epoch 14; Iter   229/ 1097] train: loss: 0.3941102
[Epoch 14; Iter   259/ 1097] train: loss: 0.3338852
[Epoch 14; Iter   289/ 1097] train: loss: 0.1273038
[Epoch 14; Iter   319/ 1097] train: loss: 0.0730751
[Epoch 14; Iter   349/ 1097] train: loss: 0.0928146
[Epoch 14; Iter   379/ 1097] train: loss: 0.0375446
[Epoch 14; Iter   409/ 1097] train: loss: 0.1471492
[Epoch 14; Iter   439/ 1097] train: loss: 0.2200633
[Epoch 14; Iter   469/ 1097] train: loss: 0.2293742
[Epoch 14; Iter   499/ 1097] train: loss: 0.0295967
[Epoch 14; Iter   529/ 1097] train: loss: 0.3196643
[Epoch 14; Iter   559/ 1097] train: loss: 0.0232001
[Epoch 14; Iter   589/ 1097] train: loss: 0.1528350
[Epoch 14; Iter   619/ 1097] train: loss: 0.1935591
[Epoch 14; Iter   649/ 1097] train: loss: 0.0424764
[Epoch 14; Iter   679/ 1097] train: loss: 0.0338145
[Epoch 14; Iter   709/ 1097] train: loss: 0.2762978
[Epoch 14; Iter   739/ 1097] train: loss: 0.2196946
[Epoch 14; Iter   769/ 1097] train: loss: 0.0199522
[Epoch 14; Iter   799/ 1097] train: loss: 0.0468140
[Epoch 14; Iter   829/ 1097] train: loss: 0.1198700
[Epoch 14; Iter   859/ 1097] train: loss: 0.0269511
[Epoch 14; Iter   889/ 1097] train: loss: 0.0439915
[Epoch 14; Iter   919/ 1097] train: loss: 0.1308886
[Epoch 14; Iter   949/ 1097] train: loss: 0.1260706
[Epoch 14; Iter   979/ 1097] train: loss: 0.1351317
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2977454
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0359673
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0934661
[Epoch 14] ogbg-molhiv: 0.710997 val loss: 0.222749
[Epoch 14] ogbg-molhiv: 0.688287 test loss: 0.214103
[Epoch 15; Iter     2/ 1097] train: loss: 0.1469785
[Epoch 15; Iter    32/ 1097] train: loss: 0.1184557
[Epoch 15; Iter    62/ 1097] train: loss: 0.0465784
[Epoch 15; Iter    92/ 1097] train: loss: 0.0744358
[Epoch 15; Iter   122/ 1097] train: loss: 0.1579342
[Epoch 15; Iter   152/ 1097] train: loss: 0.0298755
[Epoch 15; Iter   182/ 1097] train: loss: 0.0453015
[Epoch 15; Iter   212/ 1097] train: loss: 0.1660856
[Epoch 15; Iter   242/ 1097] train: loss: 0.1472802
[Epoch 15; Iter   272/ 1097] train: loss: 0.3232601
[Epoch 15; Iter   302/ 1097] train: loss: 0.0959349
[Epoch 15; Iter   332/ 1097] train: loss: 0.1533289
[Epoch 15; Iter   362/ 1097] train: loss: 0.1193455
[Epoch 15; Iter   392/ 1097] train: loss: 0.1384445
[Epoch 15; Iter   422/ 1097] train: loss: 0.0752341
[Epoch 15; Iter   452/ 1097] train: loss: 0.0409812
[Epoch 15; Iter   482/ 1097] train: loss: 0.1284338
[Epoch 15; Iter   512/ 1097] train: loss: 0.3761809
[Epoch 15; Iter   542/ 1097] train: loss: 0.1471716
[Epoch 15; Iter   572/ 1097] train: loss: 0.1197060
[Epoch 15; Iter   602/ 1097] train: loss: 0.0253079
[Epoch 15; Iter   632/ 1097] train: loss: 0.2691023
[Epoch 15; Iter   662/ 1097] train: loss: 0.0284981
[Epoch 15; Iter   692/ 1097] train: loss: 0.0857080
[Epoch 15; Iter   722/ 1097] train: loss: 0.0342465
[Epoch 15; Iter   752/ 1097] train: loss: 0.1746834
[Epoch 15; Iter   782/ 1097] train: loss: 0.0995875
[Epoch 15; Iter   812/ 1097] train: loss: 0.0290910
[Epoch 15; Iter   842/ 1097] train: loss: 0.0554586
[Epoch 15; Iter   872/ 1097] train: loss: 0.0293985
[Epoch 15; Iter   902/ 1097] train: loss: 0.0447011
[Epoch 15; Iter   932/ 1097] train: loss: 0.1886611
[Epoch 15; Iter   962/ 1097] train: loss: 0.3400730
[Epoch 15; Iter   992/ 1097] train: loss: 0.0323416
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1744415
[Epoch 15; Iter  1052/ 1097] train: loss: 0.2145339
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0269616
[Epoch 15] ogbg-molhiv: 0.730670 val loss: 0.350713
[Epoch 15] ogbg-molhiv: 0.679565 test loss: 0.373786
[Epoch 16; Iter    15/ 1097] train: loss: 0.0336118
[Epoch 16; Iter    45/ 1097] train: loss: 0.1591382
[Epoch 16; Iter    75/ 1097] train: loss: 0.2765528
[Epoch 16; Iter   105/ 1097] train: loss: 0.0311795
[Epoch 16; Iter   135/ 1097] train: loss: 0.0698329
[Epoch 16; Iter   165/ 1097] train: loss: 0.1060654
[Epoch 16; Iter   195/ 1097] train: loss: 0.0403221
[Epoch 12; Iter   143/ 1097] train: loss: 0.3165896
[Epoch 12; Iter   173/ 1097] train: loss: 0.0327702
[Epoch 12; Iter   203/ 1097] train: loss: 0.0294957
[Epoch 12; Iter   233/ 1097] train: loss: 0.0274133
[Epoch 12; Iter   263/ 1097] train: loss: 0.1762577
[Epoch 12; Iter   293/ 1097] train: loss: 0.1778297
[Epoch 12; Iter   323/ 1097] train: loss: 0.1473771
[Epoch 12; Iter   353/ 1097] train: loss: 0.2605634
[Epoch 12; Iter   383/ 1097] train: loss: 0.0465331
[Epoch 12; Iter   413/ 1097] train: loss: 0.3172074
[Epoch 12; Iter   443/ 1097] train: loss: 0.3418845
[Epoch 12; Iter   473/ 1097] train: loss: 0.1468902
[Epoch 12; Iter   503/ 1097] train: loss: 0.2600967
[Epoch 12; Iter   533/ 1097] train: loss: 0.2258752
[Epoch 12; Iter   563/ 1097] train: loss: 0.2220038
[Epoch 12; Iter   593/ 1097] train: loss: 0.2618335
[Epoch 12; Iter   623/ 1097] train: loss: 0.3019989
[Epoch 12; Iter   653/ 1097] train: loss: 0.0619946
[Epoch 12; Iter   683/ 1097] train: loss: 0.1690579
[Epoch 12; Iter   713/ 1097] train: loss: 0.0458359
[Epoch 12; Iter   743/ 1097] train: loss: 0.2267528
[Epoch 12; Iter   773/ 1097] train: loss: 0.0615632
[Epoch 12; Iter   803/ 1097] train: loss: 0.1693534
[Epoch 12; Iter   833/ 1097] train: loss: 0.1792019
[Epoch 12; Iter   863/ 1097] train: loss: 0.2704730
[Epoch 12; Iter   893/ 1097] train: loss: 0.0323729
[Epoch 12; Iter   923/ 1097] train: loss: 0.1733607
[Epoch 12; Iter   953/ 1097] train: loss: 0.2321425
[Epoch 12; Iter   983/ 1097] train: loss: 0.0383577
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0431087
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1401753
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1331085
[Epoch 12] ogbg-molhiv: 0.737765 val loss: 0.862407
[Epoch 12] ogbg-molhiv: 0.698420 test loss: 1.369395
[Epoch 13; Iter     6/ 1097] train: loss: 0.1210340
[Epoch 13; Iter    36/ 1097] train: loss: 0.2552565
[Epoch 13; Iter    66/ 1097] train: loss: 0.1442672
[Epoch 13; Iter    96/ 1097] train: loss: 0.1373091
[Epoch 13; Iter   126/ 1097] train: loss: 0.0312942
[Epoch 13; Iter   156/ 1097] train: loss: 0.0325701
[Epoch 13; Iter   186/ 1097] train: loss: 0.1826172
[Epoch 13; Iter   216/ 1097] train: loss: 0.2398827
[Epoch 13; Iter   246/ 1097] train: loss: 0.0244406
[Epoch 13; Iter   276/ 1097] train: loss: 0.0652019
[Epoch 13; Iter   306/ 1097] train: loss: 0.0583841
[Epoch 13; Iter   336/ 1097] train: loss: 0.1150720
[Epoch 13; Iter   366/ 1097] train: loss: 0.1768226
[Epoch 13; Iter   396/ 1097] train: loss: 0.0878322
[Epoch 13; Iter   426/ 1097] train: loss: 0.0707711
[Epoch 13; Iter   456/ 1097] train: loss: 0.0472099
[Epoch 13; Iter   486/ 1097] train: loss: 0.0294806
[Epoch 13; Iter   516/ 1097] train: loss: 0.0299764
[Epoch 13; Iter   546/ 1097] train: loss: 0.0263978
[Epoch 13; Iter   576/ 1097] train: loss: 0.1623325
[Epoch 13; Iter   606/ 1097] train: loss: 0.1386102
[Epoch 13; Iter   636/ 1097] train: loss: 0.3042784
[Epoch 13; Iter   666/ 1097] train: loss: 0.0270915
[Epoch 13; Iter   696/ 1097] train: loss: 0.0577774
[Epoch 13; Iter   726/ 1097] train: loss: 0.1590489
[Epoch 13; Iter   756/ 1097] train: loss: 0.0386574
[Epoch 13; Iter   786/ 1097] train: loss: 0.1779291
[Epoch 13; Iter   816/ 1097] train: loss: 0.0270793
[Epoch 13; Iter   846/ 1097] train: loss: 0.0598406
[Epoch 13; Iter   876/ 1097] train: loss: 0.2464415
[Epoch 13; Iter   906/ 1097] train: loss: 0.3157032
[Epoch 13; Iter   936/ 1097] train: loss: 0.1781538
[Epoch 13; Iter   966/ 1097] train: loss: 0.1156287
[Epoch 13; Iter   996/ 1097] train: loss: 0.0917777
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3976809
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1868899
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1523824
[Epoch 13] ogbg-molhiv: 0.727501 val loss: 0.676264
[Epoch 13] ogbg-molhiv: 0.744796 test loss: 1.059782
[Epoch 14; Iter    19/ 1097] train: loss: 0.0303494
[Epoch 14; Iter    49/ 1097] train: loss: 0.3039944
[Epoch 14; Iter    79/ 1097] train: loss: 0.0296928
[Epoch 14; Iter   109/ 1097] train: loss: 0.0437958
[Epoch 14; Iter   139/ 1097] train: loss: 0.1207795
[Epoch 14; Iter   169/ 1097] train: loss: 0.1564346
[Epoch 14; Iter   199/ 1097] train: loss: 0.0336939
[Epoch 14; Iter   229/ 1097] train: loss: 0.0351946
[Epoch 14; Iter   259/ 1097] train: loss: 0.0526565
[Epoch 14; Iter   289/ 1097] train: loss: 0.1259516
[Epoch 14; Iter   319/ 1097] train: loss: 0.3237966
[Epoch 14; Iter   349/ 1097] train: loss: 0.2594137
[Epoch 14; Iter   379/ 1097] train: loss: 0.1536611
[Epoch 14; Iter   409/ 1097] train: loss: 0.0552588
[Epoch 14; Iter   439/ 1097] train: loss: 0.1126865
[Epoch 14; Iter   469/ 1097] train: loss: 0.1384205
[Epoch 14; Iter   499/ 1097] train: loss: 0.0315024
[Epoch 14; Iter   529/ 1097] train: loss: 0.0370905
[Epoch 14; Iter   559/ 1097] train: loss: 0.2549652
[Epoch 14; Iter   589/ 1097] train: loss: 0.0403738
[Epoch 14; Iter   619/ 1097] train: loss: 0.1256698
[Epoch 14; Iter   649/ 1097] train: loss: 0.0594492
[Epoch 14; Iter   679/ 1097] train: loss: 0.1220898
[Epoch 14; Iter   709/ 1097] train: loss: 0.1617315
[Epoch 14; Iter   739/ 1097] train: loss: 0.0998477
[Epoch 14; Iter   769/ 1097] train: loss: 0.1411289
[Epoch 14; Iter   799/ 1097] train: loss: 0.0354095
[Epoch 14; Iter   829/ 1097] train: loss: 0.1379070
[Epoch 14; Iter   859/ 1097] train: loss: 0.0385112
[Epoch 14; Iter   889/ 1097] train: loss: 0.0401009
[Epoch 14; Iter   919/ 1097] train: loss: 0.0849405
[Epoch 14; Iter   949/ 1097] train: loss: 0.0288093
[Epoch 14; Iter   979/ 1097] train: loss: 0.1601474
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0227020
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0472729
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1508844
[Epoch 14] ogbg-molhiv: 0.746494 val loss: 0.320205
[Epoch 14] ogbg-molhiv: 0.676639 test loss: 0.204450
[Epoch 15; Iter     2/ 1097] train: loss: 0.1543804
[Epoch 15; Iter    32/ 1097] train: loss: 0.0394514
[Epoch 15; Iter    62/ 1097] train: loss: 0.1502111
[Epoch 15; Iter    92/ 1097] train: loss: 0.0274789
[Epoch 15; Iter   122/ 1097] train: loss: 0.2728220
[Epoch 15; Iter   152/ 1097] train: loss: 0.1526987
[Epoch 15; Iter   182/ 1097] train: loss: 0.2282180
[Epoch 15; Iter   212/ 1097] train: loss: 0.0344809
[Epoch 15; Iter   242/ 1097] train: loss: 0.0425673
[Epoch 15; Iter   272/ 1097] train: loss: 0.1345153
[Epoch 15; Iter   302/ 1097] train: loss: 0.1708532
[Epoch 15; Iter   332/ 1097] train: loss: 0.0595999
[Epoch 15; Iter   362/ 1097] train: loss: 0.1611779
[Epoch 15; Iter   392/ 1097] train: loss: 0.1886840
[Epoch 15; Iter   422/ 1097] train: loss: 0.1948706
[Epoch 15; Iter   452/ 1097] train: loss: 0.0334153
[Epoch 15; Iter   482/ 1097] train: loss: 0.0964975
[Epoch 15; Iter   512/ 1097] train: loss: 0.2651535
[Epoch 15; Iter   542/ 1097] train: loss: 0.0480883
[Epoch 15; Iter   572/ 1097] train: loss: 0.0368959
[Epoch 15; Iter   602/ 1097] train: loss: 0.4319737
[Epoch 15; Iter   632/ 1097] train: loss: 0.0261937
[Epoch 15; Iter   662/ 1097] train: loss: 0.1846813
[Epoch 15; Iter   692/ 1097] train: loss: 0.0369438
[Epoch 15; Iter   722/ 1097] train: loss: 0.0797028
[Epoch 15; Iter   752/ 1097] train: loss: 0.1612065
[Epoch 15; Iter   782/ 1097] train: loss: 0.1796271
[Epoch 15; Iter   812/ 1097] train: loss: 0.1886315
[Epoch 15; Iter   842/ 1097] train: loss: 0.0352693
[Epoch 15; Iter   872/ 1097] train: loss: 0.0333819
[Epoch 15; Iter   902/ 1097] train: loss: 0.2113722
[Epoch 15; Iter   932/ 1097] train: loss: 0.0394151
[Epoch 15; Iter   962/ 1097] train: loss: 0.0427123
[Epoch 15; Iter   992/ 1097] train: loss: 0.0675514
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0216231
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1541918
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0402074
[Epoch 15] ogbg-molhiv: 0.694711 val loss: 8.035287
[Epoch 15] ogbg-molhiv: 0.604961 test loss: 10.733949
[Epoch 16; Iter    15/ 1097] train: loss: 0.1133020
[Epoch 16; Iter    45/ 1097] train: loss: 0.0318882
[Epoch 16; Iter    75/ 1097] train: loss: 0.0226736
[Epoch 16; Iter   105/ 1097] train: loss: 0.0329752
[Epoch 16; Iter   135/ 1097] train: loss: 0.0394867
[Epoch 16; Iter   165/ 1097] train: loss: 0.3905511
[Epoch 16; Iter   195/ 1097] train: loss: 0.1525391
[Epoch 16; Iter   195/ 1097] train: loss: 0.0321565
[Epoch 16; Iter   225/ 1097] train: loss: 0.0666764
[Epoch 16; Iter   255/ 1097] train: loss: 0.1970160
[Epoch 16; Iter   285/ 1097] train: loss: 0.0316886
[Epoch 16; Iter   315/ 1097] train: loss: 0.0764001
[Epoch 16; Iter   345/ 1097] train: loss: 0.0573660
[Epoch 16; Iter   375/ 1097] train: loss: 0.0515243
[Epoch 16; Iter   405/ 1097] train: loss: 0.0192408
[Epoch 16; Iter   435/ 1097] train: loss: 0.1339946
[Epoch 16; Iter   465/ 1097] train: loss: 0.1659247
[Epoch 16; Iter   495/ 1097] train: loss: 0.0668088
[Epoch 16; Iter   525/ 1097] train: loss: 0.0266215
[Epoch 16; Iter   555/ 1097] train: loss: 0.4460346
[Epoch 16; Iter   585/ 1097] train: loss: 0.0304384
[Epoch 16; Iter   615/ 1097] train: loss: 0.1538626
[Epoch 16; Iter   645/ 1097] train: loss: 0.0854204
[Epoch 16; Iter   675/ 1097] train: loss: 0.1195557
[Epoch 16; Iter   705/ 1097] train: loss: 0.0268010
[Epoch 16; Iter   735/ 1097] train: loss: 0.1581857
[Epoch 16; Iter   765/ 1097] train: loss: 0.3704987
[Epoch 16; Iter   795/ 1097] train: loss: 0.0541756
[Epoch 16; Iter   825/ 1097] train: loss: 0.0547749
[Epoch 16; Iter   855/ 1097] train: loss: 0.0234647
[Epoch 16; Iter   885/ 1097] train: loss: 0.1321175
[Epoch 16; Iter   915/ 1097] train: loss: 0.1278895
[Epoch 16; Iter   945/ 1097] train: loss: 0.0265841
[Epoch 16; Iter   975/ 1097] train: loss: 0.0289536
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0605367
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0492623
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0224297
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0219898
[Epoch 16] ogbg-molhiv: 0.750876 val loss: 0.154462
[Epoch 16] ogbg-molhiv: 0.736824 test loss: 0.177219
[Epoch 17; Iter    28/ 1097] train: loss: 0.1929500
[Epoch 17; Iter    58/ 1097] train: loss: 0.0647643
[Epoch 17; Iter    88/ 1097] train: loss: 0.1335271
[Epoch 17; Iter   118/ 1097] train: loss: 0.0253931
[Epoch 17; Iter   148/ 1097] train: loss: 0.0242168
[Epoch 17; Iter   178/ 1097] train: loss: 0.0203797
[Epoch 17; Iter   208/ 1097] train: loss: 0.0206993
[Epoch 17; Iter   238/ 1097] train: loss: 0.0933775
[Epoch 17; Iter   268/ 1097] train: loss: 0.0706490
[Epoch 17; Iter   298/ 1097] train: loss: 0.0377312
[Epoch 17; Iter   328/ 1097] train: loss: 0.1434840
[Epoch 17; Iter   358/ 1097] train: loss: 0.1770557
[Epoch 17; Iter   388/ 1097] train: loss: 0.0364320
[Epoch 17; Iter   418/ 1097] train: loss: 0.0837721
[Epoch 17; Iter   448/ 1097] train: loss: 0.1106373
[Epoch 17; Iter   478/ 1097] train: loss: 0.2062923
[Epoch 17; Iter   508/ 1097] train: loss: 0.0340454
[Epoch 17; Iter   538/ 1097] train: loss: 0.1522034
[Epoch 17; Iter   568/ 1097] train: loss: 0.0329680
[Epoch 17; Iter   598/ 1097] train: loss: 0.0866342
[Epoch 17; Iter   628/ 1097] train: loss: 0.0362951
[Epoch 17; Iter   658/ 1097] train: loss: 0.1455223
[Epoch 17; Iter   688/ 1097] train: loss: 0.0245811
[Epoch 17; Iter   718/ 1097] train: loss: 0.0853026
[Epoch 17; Iter   748/ 1097] train: loss: 0.1482543
[Epoch 17; Iter   778/ 1097] train: loss: 0.0490946
[Epoch 17; Iter   808/ 1097] train: loss: 0.1358499
[Epoch 17; Iter   838/ 1097] train: loss: 0.0746322
[Epoch 17; Iter   868/ 1097] train: loss: 0.0359563
[Epoch 17; Iter   898/ 1097] train: loss: 0.1578856
[Epoch 17; Iter   928/ 1097] train: loss: 0.1984565
[Epoch 17; Iter   958/ 1097] train: loss: 0.0230875
[Epoch 17; Iter   988/ 1097] train: loss: 0.1044795
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0426290
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2895752
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1992851
[Epoch 17] ogbg-molhiv: 0.774578 val loss: 0.341917
[Epoch 17] ogbg-molhiv: 0.715726 test loss: 0.195030
[Epoch 18; Iter    11/ 1097] train: loss: 0.0205031
[Epoch 18; Iter    41/ 1097] train: loss: 0.1866490
[Epoch 18; Iter    71/ 1097] train: loss: 0.2420441
[Epoch 18; Iter   101/ 1097] train: loss: 0.0185109
[Epoch 18; Iter   131/ 1097] train: loss: 0.0660923
[Epoch 18; Iter   161/ 1097] train: loss: 0.3538857
[Epoch 18; Iter   191/ 1097] train: loss: 0.0678086
[Epoch 18; Iter   221/ 1097] train: loss: 0.0447162
[Epoch 18; Iter   251/ 1097] train: loss: 0.0215443
[Epoch 18; Iter   281/ 1097] train: loss: 0.1431566
[Epoch 18; Iter   311/ 1097] train: loss: 0.0890327
[Epoch 18; Iter   341/ 1097] train: loss: 0.0315805
[Epoch 18; Iter   371/ 1097] train: loss: 0.0267738
[Epoch 18; Iter   401/ 1097] train: loss: 0.1517406
[Epoch 18; Iter   431/ 1097] train: loss: 0.0314884
[Epoch 18; Iter   461/ 1097] train: loss: 0.1080900
[Epoch 18; Iter   491/ 1097] train: loss: 0.0231450
[Epoch 18; Iter   521/ 1097] train: loss: 0.1651878
[Epoch 18; Iter   551/ 1097] train: loss: 0.0653931
[Epoch 18; Iter   581/ 1097] train: loss: 0.0274540
[Epoch 18; Iter   611/ 1097] train: loss: 0.0241241
[Epoch 18; Iter   641/ 1097] train: loss: 0.2353933
[Epoch 18; Iter   671/ 1097] train: loss: 0.0576769
[Epoch 18; Iter   701/ 1097] train: loss: 0.0472488
[Epoch 18; Iter   731/ 1097] train: loss: 0.0265801
[Epoch 18; Iter   761/ 1097] train: loss: 0.0397710
[Epoch 18; Iter   791/ 1097] train: loss: 0.0267056
[Epoch 18; Iter   821/ 1097] train: loss: 0.0722727
[Epoch 18; Iter   851/ 1097] train: loss: 0.0383179
[Epoch 18; Iter   881/ 1097] train: loss: 0.0583445
[Epoch 18; Iter   911/ 1097] train: loss: 0.0200153
[Epoch 18; Iter   941/ 1097] train: loss: 0.1058541
[Epoch 18; Iter   971/ 1097] train: loss: 0.0549521
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0663865
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0860666
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0944791
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0305831
[Epoch 18] ogbg-molhiv: 0.760319 val loss: 0.079733
[Epoch 18] ogbg-molhiv: 0.719583 test loss: 0.135981
[Epoch 19; Iter    24/ 1097] train: loss: 0.0227053
[Epoch 19; Iter    54/ 1097] train: loss: 0.1255652
[Epoch 19; Iter    84/ 1097] train: loss: 0.0460254
[Epoch 19; Iter   114/ 1097] train: loss: 0.0631116
[Epoch 19; Iter   144/ 1097] train: loss: 0.0706792
[Epoch 19; Iter   174/ 1097] train: loss: 0.0208021
[Epoch 19; Iter   204/ 1097] train: loss: 0.0399512
[Epoch 19; Iter   234/ 1097] train: loss: 0.0843269
[Epoch 19; Iter   264/ 1097] train: loss: 0.0173888
[Epoch 19; Iter   294/ 1097] train: loss: 0.0269049
[Epoch 19; Iter   324/ 1097] train: loss: 0.0279688
[Epoch 19; Iter   354/ 1097] train: loss: 0.1931680
[Epoch 19; Iter   384/ 1097] train: loss: 0.0381386
[Epoch 19; Iter   414/ 1097] train: loss: 0.1931039
[Epoch 19; Iter   444/ 1097] train: loss: 0.0393087
[Epoch 19; Iter   474/ 1097] train: loss: 0.2496884
[Epoch 19; Iter   504/ 1097] train: loss: 0.0479235
[Epoch 19; Iter   534/ 1097] train: loss: 0.0214195
[Epoch 19; Iter   564/ 1097] train: loss: 0.1308554
[Epoch 19; Iter   594/ 1097] train: loss: 0.1647408
[Epoch 19; Iter   624/ 1097] train: loss: 0.0363857
[Epoch 19; Iter   654/ 1097] train: loss: 0.0407078
[Epoch 19; Iter   684/ 1097] train: loss: 0.3376948
[Epoch 19; Iter   714/ 1097] train: loss: 0.0371282
[Epoch 19; Iter   744/ 1097] train: loss: 0.0485006
[Epoch 19; Iter   774/ 1097] train: loss: 0.0552603
[Epoch 19; Iter   804/ 1097] train: loss: 0.0159372
[Epoch 19; Iter   834/ 1097] train: loss: 0.0270526
[Epoch 19; Iter   864/ 1097] train: loss: 0.0519470
[Epoch 19; Iter   894/ 1097] train: loss: 0.3544873
[Epoch 19; Iter   924/ 1097] train: loss: 0.1155780
[Epoch 19; Iter   954/ 1097] train: loss: 0.0178444
[Epoch 19; Iter   984/ 1097] train: loss: 0.0607725
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1117556
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0471436
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3601575
[Epoch 19] ogbg-molhiv: 0.795421 val loss: 0.091782
[Epoch 19] ogbg-molhiv: 0.700938 test loss: 0.132990
[Epoch 20; Iter     7/ 1097] train: loss: 0.0593187
[Epoch 20; Iter    37/ 1097] train: loss: 0.0321642
[Epoch 20; Iter    67/ 1097] train: loss: 0.0221433
[Epoch 20; Iter    97/ 1097] train: loss: 0.0283956
[Epoch 20; Iter   127/ 1097] train: loss: 0.0504308
[Epoch 20; Iter   157/ 1097] train: loss: 0.0182158
[Epoch 20; Iter   187/ 1097] train: loss: 0.1274057
[Epoch 20; Iter   217/ 1097] train: loss: 0.1799799
[Epoch 20; Iter   247/ 1097] train: loss: 0.0352332
[Epoch 16; Iter   195/ 1097] train: loss: 0.1226687
[Epoch 16; Iter   225/ 1097] train: loss: 0.0745745
[Epoch 16; Iter   255/ 1097] train: loss: 0.0499943
[Epoch 16; Iter   285/ 1097] train: loss: 0.1537745
[Epoch 16; Iter   315/ 1097] train: loss: 0.0893151
[Epoch 16; Iter   345/ 1097] train: loss: 0.0429055
[Epoch 16; Iter   375/ 1097] train: loss: 0.2123537
[Epoch 16; Iter   405/ 1097] train: loss: 0.1351096
[Epoch 16; Iter   435/ 1097] train: loss: 0.1088998
[Epoch 16; Iter   465/ 1097] train: loss: 0.1267612
[Epoch 16; Iter   495/ 1097] train: loss: 0.0784003
[Epoch 16; Iter   525/ 1097] train: loss: 0.1387690
[Epoch 16; Iter   555/ 1097] train: loss: 0.0201903
[Epoch 16; Iter   585/ 1097] train: loss: 0.0704033
[Epoch 16; Iter   615/ 1097] train: loss: 0.1138209
[Epoch 16; Iter   645/ 1097] train: loss: 0.0291815
[Epoch 16; Iter   675/ 1097] train: loss: 0.1127733
[Epoch 16; Iter   705/ 1097] train: loss: 0.1197693
[Epoch 16; Iter   735/ 1097] train: loss: 0.0688202
[Epoch 16; Iter   765/ 1097] train: loss: 0.0421242
[Epoch 16; Iter   795/ 1097] train: loss: 0.0921463
[Epoch 16; Iter   825/ 1097] train: loss: 0.0237999
[Epoch 16; Iter   855/ 1097] train: loss: 0.0969669
[Epoch 16; Iter   885/ 1097] train: loss: 0.2050204
[Epoch 16; Iter   915/ 1097] train: loss: 0.0300484
[Epoch 16; Iter   945/ 1097] train: loss: 0.0232961
[Epoch 16; Iter   975/ 1097] train: loss: 0.0285730
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0372368
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0269278
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0308417
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1697311
[Epoch 16] ogbg-molhiv: 0.798727 val loss: 1.019611
[Epoch 16] ogbg-molhiv: 0.756135 test loss: 0.145960
[Epoch 17; Iter    28/ 1097] train: loss: 0.0210169
[Epoch 17; Iter    58/ 1097] train: loss: 0.0359456
[Epoch 17; Iter    88/ 1097] train: loss: 0.0247090
[Epoch 17; Iter   118/ 1097] train: loss: 0.1018988
[Epoch 17; Iter   148/ 1097] train: loss: 0.1509538
[Epoch 17; Iter   178/ 1097] train: loss: 0.0290086
[Epoch 17; Iter   208/ 1097] train: loss: 0.0187315
[Epoch 17; Iter   238/ 1097] train: loss: 0.2027372
[Epoch 17; Iter   268/ 1097] train: loss: 0.0252948
[Epoch 17; Iter   298/ 1097] train: loss: 0.0238227
[Epoch 17; Iter   328/ 1097] train: loss: 0.0318702
[Epoch 17; Iter   358/ 1097] train: loss: 0.0237790
[Epoch 17; Iter   388/ 1097] train: loss: 0.0478237
[Epoch 17; Iter   418/ 1097] train: loss: 0.2112092
[Epoch 17; Iter   448/ 1097] train: loss: 0.0438840
[Epoch 17; Iter   478/ 1097] train: loss: 0.0566526
[Epoch 17; Iter   508/ 1097] train: loss: 0.0392386
[Epoch 17; Iter   538/ 1097] train: loss: 0.3327979
[Epoch 17; Iter   568/ 1097] train: loss: 0.2250649
[Epoch 17; Iter   598/ 1097] train: loss: 0.1782316
[Epoch 17; Iter   628/ 1097] train: loss: 0.0361806
[Epoch 17; Iter   658/ 1097] train: loss: 0.0331073
[Epoch 17; Iter   688/ 1097] train: loss: 0.2575291
[Epoch 17; Iter   718/ 1097] train: loss: 0.0536537
[Epoch 17; Iter   748/ 1097] train: loss: 0.1347353
[Epoch 17; Iter   778/ 1097] train: loss: 0.0425773
[Epoch 17; Iter   808/ 1097] train: loss: 0.1203500
[Epoch 17; Iter   838/ 1097] train: loss: 0.0330512
[Epoch 17; Iter   868/ 1097] train: loss: 0.0204501
[Epoch 17; Iter   898/ 1097] train: loss: 0.3439117
[Epoch 17; Iter   928/ 1097] train: loss: 0.1510486
[Epoch 17; Iter   958/ 1097] train: loss: 0.1000248
[Epoch 17; Iter   988/ 1097] train: loss: 0.0421785
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0208420
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0273928
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2767590
[Epoch 17] ogbg-molhiv: 0.818143 val loss: 3.495853
[Epoch 17] ogbg-molhiv: 0.726783 test loss: 0.337208
[Epoch 18; Iter    11/ 1097] train: loss: 0.1332856
[Epoch 18; Iter    41/ 1097] train: loss: 0.2981036
[Epoch 18; Iter    71/ 1097] train: loss: 0.0988415
[Epoch 18; Iter   101/ 1097] train: loss: 0.1185799
[Epoch 18; Iter   131/ 1097] train: loss: 0.0638918
[Epoch 18; Iter   161/ 1097] train: loss: 0.0264430
[Epoch 18; Iter   191/ 1097] train: loss: 0.0801469
[Epoch 18; Iter   221/ 1097] train: loss: 0.0727761
[Epoch 18; Iter   251/ 1097] train: loss: 0.1497805
[Epoch 18; Iter   281/ 1097] train: loss: 0.0207446
[Epoch 18; Iter   311/ 1097] train: loss: 0.1573298
[Epoch 18; Iter   341/ 1097] train: loss: 0.0144342
[Epoch 18; Iter   371/ 1097] train: loss: 0.0243933
[Epoch 18; Iter   401/ 1097] train: loss: 0.2010034
[Epoch 18; Iter   431/ 1097] train: loss: 0.1931882
[Epoch 18; Iter   461/ 1097] train: loss: 0.0454510
[Epoch 18; Iter   491/ 1097] train: loss: 0.1580581
[Epoch 18; Iter   521/ 1097] train: loss: 0.2397591
[Epoch 18; Iter   551/ 1097] train: loss: 0.0317650
[Epoch 18; Iter   581/ 1097] train: loss: 0.0412900
[Epoch 18; Iter   611/ 1097] train: loss: 0.0193443
[Epoch 18; Iter   641/ 1097] train: loss: 0.2633910
[Epoch 18; Iter   671/ 1097] train: loss: 0.0262703
[Epoch 18; Iter   701/ 1097] train: loss: 0.2349612
[Epoch 18; Iter   731/ 1097] train: loss: 0.1427987
[Epoch 18; Iter   761/ 1097] train: loss: 0.2433678
[Epoch 18; Iter   791/ 1097] train: loss: 0.0440125
[Epoch 18; Iter   821/ 1097] train: loss: 0.0486077
[Epoch 18; Iter   851/ 1097] train: loss: 0.1516524
[Epoch 18; Iter   881/ 1097] train: loss: 0.0730371
[Epoch 18; Iter   911/ 1097] train: loss: 0.1991817
[Epoch 18; Iter   941/ 1097] train: loss: 0.0545930
[Epoch 18; Iter   971/ 1097] train: loss: 0.0724584
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0363007
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0878294
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0400120
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0304264
[Epoch 18] ogbg-molhiv: 0.821793 val loss: 2.789394
[Epoch 18] ogbg-molhiv: 0.743761 test loss: 0.285670
[Epoch 19; Iter    24/ 1097] train: loss: 0.1924692
[Epoch 19; Iter    54/ 1097] train: loss: 0.1145354
[Epoch 19; Iter    84/ 1097] train: loss: 0.2500163
[Epoch 19; Iter   114/ 1097] train: loss: 0.0508999
[Epoch 19; Iter   144/ 1097] train: loss: 0.1095519
[Epoch 19; Iter   174/ 1097] train: loss: 0.0560732
[Epoch 19; Iter   204/ 1097] train: loss: 0.0363870
[Epoch 19; Iter   234/ 1097] train: loss: 0.0333631
[Epoch 19; Iter   264/ 1097] train: loss: 0.0579238
[Epoch 19; Iter   294/ 1097] train: loss: 0.1343163
[Epoch 19; Iter   324/ 1097] train: loss: 0.0174948
[Epoch 19; Iter   354/ 1097] train: loss: 0.2855572
[Epoch 19; Iter   384/ 1097] train: loss: 0.0217492
[Epoch 19; Iter   414/ 1097] train: loss: 0.0320589
[Epoch 19; Iter   444/ 1097] train: loss: 0.1525930
[Epoch 19; Iter   474/ 1097] train: loss: 0.1803703
[Epoch 19; Iter   504/ 1097] train: loss: 0.1788221
[Epoch 19; Iter   534/ 1097] train: loss: 0.2208247
[Epoch 19; Iter   564/ 1097] train: loss: 0.0172212
[Epoch 19; Iter   594/ 1097] train: loss: 0.0233761
[Epoch 19; Iter   624/ 1097] train: loss: 0.0411650
[Epoch 19; Iter   654/ 1097] train: loss: 0.0683315
[Epoch 19; Iter   684/ 1097] train: loss: 0.0294082
[Epoch 19; Iter   714/ 1097] train: loss: 0.0700129
[Epoch 19; Iter   744/ 1097] train: loss: 0.0254945
[Epoch 19; Iter   774/ 1097] train: loss: 0.1043250
[Epoch 19; Iter   804/ 1097] train: loss: 0.0744422
[Epoch 19; Iter   834/ 1097] train: loss: 0.2074339
[Epoch 19; Iter   864/ 1097] train: loss: 0.3487757
[Epoch 19; Iter   894/ 1097] train: loss: 0.2694766
[Epoch 19; Iter   924/ 1097] train: loss: 0.4460261
[Epoch 19; Iter   954/ 1097] train: loss: 0.1054489
[Epoch 19; Iter   984/ 1097] train: loss: 0.3351637
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1899395
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0192467
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0489056
[Epoch 19] ogbg-molhiv: 0.825247 val loss: 2.821632
[Epoch 19] ogbg-molhiv: 0.753632 test loss: 0.388440
[Epoch 20; Iter     7/ 1097] train: loss: 0.1035452
[Epoch 20; Iter    37/ 1097] train: loss: 0.1439408
[Epoch 20; Iter    67/ 1097] train: loss: 0.0397263
[Epoch 20; Iter    97/ 1097] train: loss: 0.0234890
[Epoch 20; Iter   127/ 1097] train: loss: 0.0268856
[Epoch 20; Iter   157/ 1097] train: loss: 0.0658115
[Epoch 20; Iter   187/ 1097] train: loss: 0.0142591
[Epoch 20; Iter   217/ 1097] train: loss: 0.0552223
[Epoch 20; Iter   247/ 1097] train: loss: 0.0228467
[Epoch 16; Iter   195/ 1097] train: loss: 0.0250572
[Epoch 16; Iter   225/ 1097] train: loss: 0.1993181
[Epoch 16; Iter   255/ 1097] train: loss: 0.0689482
[Epoch 16; Iter   285/ 1097] train: loss: 0.1623106
[Epoch 16; Iter   315/ 1097] train: loss: 0.0330468
[Epoch 16; Iter   345/ 1097] train: loss: 0.1191481
[Epoch 16; Iter   375/ 1097] train: loss: 0.1030267
[Epoch 16; Iter   405/ 1097] train: loss: 0.0353794
[Epoch 16; Iter   435/ 1097] train: loss: 0.2599348
[Epoch 16; Iter   465/ 1097] train: loss: 0.0474929
[Epoch 16; Iter   495/ 1097] train: loss: 0.0205186
[Epoch 16; Iter   525/ 1097] train: loss: 0.2087929
[Epoch 16; Iter   555/ 1097] train: loss: 0.0281938
[Epoch 16; Iter   585/ 1097] train: loss: 0.1301491
[Epoch 16; Iter   615/ 1097] train: loss: 0.0906693
[Epoch 16; Iter   645/ 1097] train: loss: 0.1384183
[Epoch 16; Iter   675/ 1097] train: loss: 0.0568981
[Epoch 16; Iter   705/ 1097] train: loss: 0.0344919
[Epoch 16; Iter   735/ 1097] train: loss: 0.3047134
[Epoch 16; Iter   765/ 1097] train: loss: 0.0239509
[Epoch 16; Iter   795/ 1097] train: loss: 0.0381723
[Epoch 16; Iter   825/ 1097] train: loss: 0.2159391
[Epoch 16; Iter   855/ 1097] train: loss: 0.2439273
[Epoch 16; Iter   885/ 1097] train: loss: 0.0374916
[Epoch 16; Iter   915/ 1097] train: loss: 0.0686609
[Epoch 16; Iter   945/ 1097] train: loss: 0.1136623
[Epoch 16; Iter   975/ 1097] train: loss: 0.1688879
[Epoch 16; Iter  1005/ 1097] train: loss: 0.3060997
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0395941
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1842437
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1613783
[Epoch 16] ogbg-molhiv: 0.808131 val loss: 0.268420
[Epoch 16] ogbg-molhiv: 0.714023 test loss: 0.706286
[Epoch 17; Iter    28/ 1097] train: loss: 0.2621538
[Epoch 17; Iter    58/ 1097] train: loss: 0.0417212
[Epoch 17; Iter    88/ 1097] train: loss: 0.2365420
[Epoch 17; Iter   118/ 1097] train: loss: 0.2265833
[Epoch 17; Iter   148/ 1097] train: loss: 0.0235412
[Epoch 17; Iter   178/ 1097] train: loss: 0.1515178
[Epoch 17; Iter   208/ 1097] train: loss: 0.0263021
[Epoch 17; Iter   238/ 1097] train: loss: 0.1330531
[Epoch 17; Iter   268/ 1097] train: loss: 0.0416425
[Epoch 17; Iter   298/ 1097] train: loss: 0.1386117
[Epoch 17; Iter   328/ 1097] train: loss: 0.2211610
[Epoch 17; Iter   358/ 1097] train: loss: 0.0600684
[Epoch 17; Iter   388/ 1097] train: loss: 0.1377239
[Epoch 17; Iter   418/ 1097] train: loss: 0.2462583
[Epoch 17; Iter   448/ 1097] train: loss: 0.0315475
[Epoch 17; Iter   478/ 1097] train: loss: 0.0433306
[Epoch 17; Iter   508/ 1097] train: loss: 0.0840792
[Epoch 17; Iter   538/ 1097] train: loss: 0.0666447
[Epoch 17; Iter   568/ 1097] train: loss: 0.1406863
[Epoch 17; Iter   598/ 1097] train: loss: 0.0852249
[Epoch 17; Iter   628/ 1097] train: loss: 0.2043080
[Epoch 17; Iter   658/ 1097] train: loss: 0.0750772
[Epoch 17; Iter   688/ 1097] train: loss: 0.0378626
[Epoch 17; Iter   718/ 1097] train: loss: 0.1576122
[Epoch 17; Iter   748/ 1097] train: loss: 0.0244116
[Epoch 17; Iter   778/ 1097] train: loss: 0.1512494
[Epoch 17; Iter   808/ 1097] train: loss: 0.0230193
[Epoch 17; Iter   838/ 1097] train: loss: 0.0174355
[Epoch 17; Iter   868/ 1097] train: loss: 0.0361639
[Epoch 17; Iter   898/ 1097] train: loss: 0.0656983
[Epoch 17; Iter   928/ 1097] train: loss: 0.3631232
[Epoch 17; Iter   958/ 1097] train: loss: 0.1551859
[Epoch 17; Iter   988/ 1097] train: loss: 0.0269042
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0258681
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0220407
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0887209
[Epoch 17] ogbg-molhiv: 0.776296 val loss: 0.118701
[Epoch 17] ogbg-molhiv: 0.732158 test loss: 0.134986
[Epoch 18; Iter    11/ 1097] train: loss: 0.1058869
[Epoch 18; Iter    41/ 1097] train: loss: 0.0353276
[Epoch 18; Iter    71/ 1097] train: loss: 0.2065674
[Epoch 18; Iter   101/ 1097] train: loss: 0.0410716
[Epoch 18; Iter   131/ 1097] train: loss: 0.1763104
[Epoch 18; Iter   161/ 1097] train: loss: 0.1969819
[Epoch 18; Iter   191/ 1097] train: loss: 0.1065112
[Epoch 18; Iter   221/ 1097] train: loss: 0.0169071
[Epoch 18; Iter   251/ 1097] train: loss: 0.0334999
[Epoch 18; Iter   281/ 1097] train: loss: 0.0227401
[Epoch 18; Iter   311/ 1097] train: loss: 0.2304407
[Epoch 18; Iter   341/ 1097] train: loss: 0.0962711
[Epoch 18; Iter   371/ 1097] train: loss: 0.0382267
[Epoch 18; Iter   401/ 1097] train: loss: 0.0178311
[Epoch 18; Iter   431/ 1097] train: loss: 0.0314003
[Epoch 18; Iter   461/ 1097] train: loss: 0.0252199
[Epoch 18; Iter   491/ 1097] train: loss: 0.0823091
[Epoch 18; Iter   521/ 1097] train: loss: 0.0525503
[Epoch 18; Iter   551/ 1097] train: loss: 0.0314418
[Epoch 18; Iter   581/ 1097] train: loss: 0.0394923
[Epoch 18; Iter   611/ 1097] train: loss: 0.0535397
[Epoch 18; Iter   641/ 1097] train: loss: 0.0263380
[Epoch 18; Iter   671/ 1097] train: loss: 0.1443707
[Epoch 18; Iter   701/ 1097] train: loss: 0.2409538
[Epoch 18; Iter   731/ 1097] train: loss: 0.1352395
[Epoch 18; Iter   761/ 1097] train: loss: 0.0471739
[Epoch 18; Iter   791/ 1097] train: loss: 0.0469721
[Epoch 18; Iter   821/ 1097] train: loss: 0.0701015
[Epoch 18; Iter   851/ 1097] train: loss: 0.2410244
[Epoch 18; Iter   881/ 1097] train: loss: 0.0209107
[Epoch 18; Iter   911/ 1097] train: loss: 0.1435097
[Epoch 18; Iter   941/ 1097] train: loss: 0.0260933
[Epoch 18; Iter   971/ 1097] train: loss: 0.0449820
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0952509
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0407634
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0306500
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0372947
[Epoch 18] ogbg-molhiv: 0.798461 val loss: 0.833800
[Epoch 18] ogbg-molhiv: 0.716922 test loss: 0.447789
[Epoch 19; Iter    24/ 1097] train: loss: 0.0379585
[Epoch 19; Iter    54/ 1097] train: loss: 0.1345114
[Epoch 19; Iter    84/ 1097] train: loss: 0.0300785
[Epoch 19; Iter   114/ 1097] train: loss: 0.0856612
[Epoch 19; Iter   144/ 1097] train: loss: 0.1272765
[Epoch 19; Iter   174/ 1097] train: loss: 0.0843070
[Epoch 19; Iter   204/ 1097] train: loss: 0.1276045
[Epoch 19; Iter   234/ 1097] train: loss: 0.1796335
[Epoch 19; Iter   264/ 1097] train: loss: 0.0730245
[Epoch 19; Iter   294/ 1097] train: loss: 0.1316365
[Epoch 19; Iter   324/ 1097] train: loss: 0.2309794
[Epoch 19; Iter   354/ 1097] train: loss: 0.0283641
[Epoch 19; Iter   384/ 1097] train: loss: 0.1104958
[Epoch 19; Iter   414/ 1097] train: loss: 0.1883947
[Epoch 19; Iter   444/ 1097] train: loss: 0.0606222
[Epoch 19; Iter   474/ 1097] train: loss: 0.0201529
[Epoch 19; Iter   504/ 1097] train: loss: 0.1233166
[Epoch 19; Iter   534/ 1097] train: loss: 0.2582398
[Epoch 19; Iter   564/ 1097] train: loss: 0.1751606
[Epoch 19; Iter   594/ 1097] train: loss: 0.0474839
[Epoch 19; Iter   624/ 1097] train: loss: 0.0312203
[Epoch 19; Iter   654/ 1097] train: loss: 0.1569359
[Epoch 19; Iter   684/ 1097] train: loss: 0.1062297
[Epoch 19; Iter   714/ 1097] train: loss: 0.0771924
[Epoch 19; Iter   744/ 1097] train: loss: 0.1620430
[Epoch 19; Iter   774/ 1097] train: loss: 0.0585039
[Epoch 19; Iter   804/ 1097] train: loss: 0.0192169
[Epoch 19; Iter   834/ 1097] train: loss: 0.1717743
[Epoch 19; Iter   864/ 1097] train: loss: 0.1675294
[Epoch 19; Iter   894/ 1097] train: loss: 0.0407364
[Epoch 19; Iter   924/ 1097] train: loss: 0.0943094
[Epoch 19; Iter   954/ 1097] train: loss: 0.1472195
[Epoch 19; Iter   984/ 1097] train: loss: 0.0234613
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2472597
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0819284
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0214624
[Epoch 19] ogbg-molhiv: 0.786761 val loss: 0.676711
[Epoch 19] ogbg-molhiv: 0.696232 test loss: 0.974927
[Epoch 20; Iter     7/ 1097] train: loss: 0.1585387
[Epoch 20; Iter    37/ 1097] train: loss: 0.1781445
[Epoch 20; Iter    67/ 1097] train: loss: 0.0175148
[Epoch 20; Iter    97/ 1097] train: loss: 0.1186629
[Epoch 20; Iter   127/ 1097] train: loss: 0.1606138
[Epoch 20; Iter   157/ 1097] train: loss: 0.0157721
[Epoch 20; Iter   187/ 1097] train: loss: 0.0316194
[Epoch 20; Iter   217/ 1097] train: loss: 0.0124276
[Epoch 20; Iter   247/ 1097] train: loss: 0.0460313
[Epoch 16; Iter   225/ 1097] train: loss: 0.0901853
[Epoch 16; Iter   255/ 1097] train: loss: 0.2560735
[Epoch 16; Iter   285/ 1097] train: loss: 0.0344775
[Epoch 16; Iter   315/ 1097] train: loss: 0.0794133
[Epoch 16; Iter   345/ 1097] train: loss: 0.1093309
[Epoch 16; Iter   375/ 1097] train: loss: 0.0576207
[Epoch 16; Iter   405/ 1097] train: loss: 0.0219249
[Epoch 16; Iter   435/ 1097] train: loss: 0.0980303
[Epoch 16; Iter   465/ 1097] train: loss: 0.1704225
[Epoch 16; Iter   495/ 1097] train: loss: 0.0590712
[Epoch 16; Iter   525/ 1097] train: loss: 0.0556804
[Epoch 16; Iter   555/ 1097] train: loss: 0.3751549
[Epoch 16; Iter   585/ 1097] train: loss: 0.0373892
[Epoch 16; Iter   615/ 1097] train: loss: 0.1507383
[Epoch 16; Iter   645/ 1097] train: loss: 0.0934808
[Epoch 16; Iter   675/ 1097] train: loss: 0.0857113
[Epoch 16; Iter   705/ 1097] train: loss: 0.0249158
[Epoch 16; Iter   735/ 1097] train: loss: 0.0916047
[Epoch 16; Iter   765/ 1097] train: loss: 0.3848527
[Epoch 16; Iter   795/ 1097] train: loss: 0.0490625
[Epoch 16; Iter   825/ 1097] train: loss: 0.1715413
[Epoch 16; Iter   855/ 1097] train: loss: 0.0217513
[Epoch 16; Iter   885/ 1097] train: loss: 0.1771722
[Epoch 16; Iter   915/ 1097] train: loss: 0.0964325
[Epoch 16; Iter   945/ 1097] train: loss: 0.0352170
[Epoch 16; Iter   975/ 1097] train: loss: 0.0384129
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0841049
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0295443
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0455125
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0219272
[Epoch 16] ogbg-molhiv: 0.791198 val loss: 1.711934
[Epoch 16] ogbg-molhiv: 0.721167 test loss: 1.244582
[Epoch 17; Iter    28/ 1097] train: loss: 0.1724858
[Epoch 17; Iter    58/ 1097] train: loss: 0.1574933
[Epoch 17; Iter    88/ 1097] train: loss: 0.1114530
[Epoch 17; Iter   118/ 1097] train: loss: 0.0629016
[Epoch 17; Iter   148/ 1097] train: loss: 0.0207244
[Epoch 17; Iter   178/ 1097] train: loss: 0.0268419
[Epoch 17; Iter   208/ 1097] train: loss: 0.0269013
[Epoch 17; Iter   238/ 1097] train: loss: 0.1274833
[Epoch 17; Iter   268/ 1097] train: loss: 0.0505285
[Epoch 17; Iter   298/ 1097] train: loss: 0.0380644
[Epoch 17; Iter   328/ 1097] train: loss: 0.1056464
[Epoch 17; Iter   358/ 1097] train: loss: 0.2216473
[Epoch 17; Iter   388/ 1097] train: loss: 0.0331769
[Epoch 17; Iter   418/ 1097] train: loss: 0.0549352
[Epoch 17; Iter   448/ 1097] train: loss: 0.1194967
[Epoch 17; Iter   478/ 1097] train: loss: 0.2205523
[Epoch 17; Iter   508/ 1097] train: loss: 0.0785624
[Epoch 17; Iter   538/ 1097] train: loss: 0.0386703
[Epoch 17; Iter   568/ 1097] train: loss: 0.0246834
[Epoch 17; Iter   598/ 1097] train: loss: 0.0588243
[Epoch 17; Iter   628/ 1097] train: loss: 0.0282545
[Epoch 17; Iter   658/ 1097] train: loss: 0.1274571
[Epoch 17; Iter   688/ 1097] train: loss: 0.0544737
[Epoch 17; Iter   718/ 1097] train: loss: 0.1399812
[Epoch 17; Iter   748/ 1097] train: loss: 0.2129407
[Epoch 17; Iter   778/ 1097] train: loss: 0.0533773
[Epoch 17; Iter   808/ 1097] train: loss: 0.1979710
[Epoch 17; Iter   838/ 1097] train: loss: 0.0801349
[Epoch 17; Iter   868/ 1097] train: loss: 0.0371264
[Epoch 17; Iter   898/ 1097] train: loss: 0.1794696
[Epoch 17; Iter   928/ 1097] train: loss: 0.2268931
[Epoch 17; Iter   958/ 1097] train: loss: 0.0211454
[Epoch 17; Iter   988/ 1097] train: loss: 0.1402125
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0621382
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2934111
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2818953
[Epoch 17] ogbg-molhiv: 0.796970 val loss: 10.265841
[Epoch 17] ogbg-molhiv: 0.698046 test loss: 7.142258
[Epoch 18; Iter    11/ 1097] train: loss: 0.0255681
[Epoch 18; Iter    41/ 1097] train: loss: 0.2196168
[Epoch 18; Iter    71/ 1097] train: loss: 0.1626285
[Epoch 18; Iter   101/ 1097] train: loss: 0.0262356
[Epoch 18; Iter   131/ 1097] train: loss: 0.1138454
[Epoch 18; Iter   161/ 1097] train: loss: 0.2212329
[Epoch 18; Iter   191/ 1097] train: loss: 0.0204768
[Epoch 18; Iter   221/ 1097] train: loss: 0.0730837
[Epoch 18; Iter   251/ 1097] train: loss: 0.0277536
[Epoch 18; Iter   281/ 1097] train: loss: 0.1808663
[Epoch 18; Iter   311/ 1097] train: loss: 0.0685479
[Epoch 18; Iter   341/ 1097] train: loss: 0.0223200
[Epoch 18; Iter   371/ 1097] train: loss: 0.0238989
[Epoch 18; Iter   401/ 1097] train: loss: 0.1469422
[Epoch 18; Iter   431/ 1097] train: loss: 0.0272445
[Epoch 18; Iter   461/ 1097] train: loss: 0.1115636
[Epoch 18; Iter   491/ 1097] train: loss: 0.0298680
[Epoch 18; Iter   521/ 1097] train: loss: 0.0984960
[Epoch 18; Iter   551/ 1097] train: loss: 0.0802292
[Epoch 18; Iter   581/ 1097] train: loss: 0.0243745
[Epoch 18; Iter   611/ 1097] train: loss: 0.0262815
[Epoch 18; Iter   641/ 1097] train: loss: 0.1431545
[Epoch 18; Iter   671/ 1097] train: loss: 0.0403258
[Epoch 18; Iter   701/ 1097] train: loss: 0.0634487
[Epoch 18; Iter   731/ 1097] train: loss: 0.0283197
[Epoch 18; Iter   761/ 1097] train: loss: 0.0504707
[Epoch 18; Iter   791/ 1097] train: loss: 0.0483885
[Epoch 18; Iter   821/ 1097] train: loss: 0.1385460
[Epoch 18; Iter   851/ 1097] train: loss: 0.0260466
[Epoch 18; Iter   881/ 1097] train: loss: 0.0974540
[Epoch 18; Iter   911/ 1097] train: loss: 0.0336510
[Epoch 18; Iter   941/ 1097] train: loss: 0.1200690
[Epoch 18; Iter   971/ 1097] train: loss: 0.0408086
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0812586
[Epoch 18; Iter  1031/ 1097] train: loss: 0.1526929
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0246784
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0155277
[Epoch 18] ogbg-molhiv: 0.746470 val loss: 1.168816
[Epoch 18] ogbg-molhiv: 0.716613 test loss: 0.247868
[Epoch 19; Iter    24/ 1097] train: loss: 0.0243672
[Epoch 19; Iter    54/ 1097] train: loss: 0.0472784
[Epoch 19; Iter    84/ 1097] train: loss: 0.0416948
[Epoch 19; Iter   114/ 1097] train: loss: 0.0312315
[Epoch 19; Iter   144/ 1097] train: loss: 0.0496303
[Epoch 19; Iter   174/ 1097] train: loss: 0.0644935
[Epoch 19; Iter   204/ 1097] train: loss: 0.0808886
[Epoch 19; Iter   234/ 1097] train: loss: 0.1242866
[Epoch 19; Iter   264/ 1097] train: loss: 0.0524835
[Epoch 19; Iter   294/ 1097] train: loss: 0.0315381
[Epoch 19; Iter   324/ 1097] train: loss: 0.0381887
[Epoch 19; Iter   354/ 1097] train: loss: 0.2307601
[Epoch 19; Iter   384/ 1097] train: loss: 0.0602598
[Epoch 19; Iter   414/ 1097] train: loss: 0.0930958
[Epoch 19; Iter   444/ 1097] train: loss: 0.0250365
[Epoch 19; Iter   474/ 1097] train: loss: 0.2587819
[Epoch 19; Iter   504/ 1097] train: loss: 0.0550433
[Epoch 19; Iter   534/ 1097] train: loss: 0.0340591
[Epoch 19; Iter   564/ 1097] train: loss: 0.1167450
[Epoch 19; Iter   594/ 1097] train: loss: 0.1180891
[Epoch 19; Iter   624/ 1097] train: loss: 0.0717495
[Epoch 19; Iter   654/ 1097] train: loss: 0.0324799
[Epoch 19; Iter   684/ 1097] train: loss: 0.5221096
[Epoch 19; Iter   714/ 1097] train: loss: 0.0386306
[Epoch 19; Iter   744/ 1097] train: loss: 0.0576806
[Epoch 19; Iter   774/ 1097] train: loss: 0.1121226
[Epoch 19; Iter   804/ 1097] train: loss: 0.0292263
[Epoch 19; Iter   834/ 1097] train: loss: 0.0317189
[Epoch 19; Iter   864/ 1097] train: loss: 0.0390732
[Epoch 19; Iter   894/ 1097] train: loss: 0.4155333
[Epoch 19; Iter   924/ 1097] train: loss: 0.0640449
[Epoch 19; Iter   954/ 1097] train: loss: 0.0275950
[Epoch 19; Iter   984/ 1097] train: loss: 0.0864950
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1600838
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0934568
[Epoch 19; Iter  1074/ 1097] train: loss: 0.3932813
[Epoch 19] ogbg-molhiv: 0.802996 val loss: 11.377181
[Epoch 19] ogbg-molhiv: 0.753510 test loss: 9.646545
[Epoch 20; Iter     7/ 1097] train: loss: 0.0496872
[Epoch 20; Iter    37/ 1097] train: loss: 0.0422399
[Epoch 20; Iter    67/ 1097] train: loss: 0.0425793
[Epoch 20; Iter    97/ 1097] train: loss: 0.1019954
[Epoch 20; Iter   127/ 1097] train: loss: 0.0384344
[Epoch 20; Iter   157/ 1097] train: loss: 0.0387883
[Epoch 20; Iter   187/ 1097] train: loss: 0.1254120
[Epoch 20; Iter   217/ 1097] train: loss: 0.1905068
[Epoch 20; Iter   247/ 1097] train: loss: 0.0289151
[Epoch 20; Iter   277/ 1097] train: loss: 0.0333080
[Epoch 16; Iter   225/ 1097] train: loss: 0.0219667
[Epoch 16; Iter   255/ 1097] train: loss: 0.1095289
[Epoch 16; Iter   285/ 1097] train: loss: 0.1234681
[Epoch 16; Iter   315/ 1097] train: loss: 0.1099862
[Epoch 16; Iter   345/ 1097] train: loss: 0.0509328
[Epoch 16; Iter   375/ 1097] train: loss: 0.1720078
[Epoch 16; Iter   405/ 1097] train: loss: 0.2816237
[Epoch 16; Iter   435/ 1097] train: loss: 0.1312528
[Epoch 16; Iter   465/ 1097] train: loss: 0.0757716
[Epoch 16; Iter   495/ 1097] train: loss: 0.1262524
[Epoch 16; Iter   525/ 1097] train: loss: 0.1587665
[Epoch 16; Iter   555/ 1097] train: loss: 0.0407460
[Epoch 16; Iter   585/ 1097] train: loss: 0.1333949
[Epoch 16; Iter   615/ 1097] train: loss: 0.0749262
[Epoch 16; Iter   645/ 1097] train: loss: 0.0556812
[Epoch 16; Iter   675/ 1097] train: loss: 0.0907433
[Epoch 16; Iter   705/ 1097] train: loss: 0.1562438
[Epoch 16; Iter   735/ 1097] train: loss: 0.0679026
[Epoch 16; Iter   765/ 1097] train: loss: 0.0330181
[Epoch 16; Iter   795/ 1097] train: loss: 0.1009807
[Epoch 16; Iter   825/ 1097] train: loss: 0.0297140
[Epoch 16; Iter   855/ 1097] train: loss: 0.1651884
[Epoch 16; Iter   885/ 1097] train: loss: 0.2340915
[Epoch 16; Iter   915/ 1097] train: loss: 0.0352835
[Epoch 16; Iter   945/ 1097] train: loss: 0.0339452
[Epoch 16; Iter   975/ 1097] train: loss: 0.0244770
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0407729
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0269252
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1042382
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1223623
[Epoch 16] ogbg-molhiv: 0.703465 val loss: 0.088874
[Epoch 16] ogbg-molhiv: 0.737142 test loss: 0.132210
[Epoch 17; Iter    28/ 1097] train: loss: 0.0240049
[Epoch 17; Iter    58/ 1097] train: loss: 0.0333760
[Epoch 17; Iter    88/ 1097] train: loss: 0.0442661
[Epoch 17; Iter   118/ 1097] train: loss: 0.2014621
[Epoch 17; Iter   148/ 1097] train: loss: 0.3075664
[Epoch 17; Iter   178/ 1097] train: loss: 0.0594316
[Epoch 17; Iter   208/ 1097] train: loss: 0.0288350
[Epoch 17; Iter   238/ 1097] train: loss: 0.2670591
[Epoch 17; Iter   268/ 1097] train: loss: 0.0213607
[Epoch 17; Iter   298/ 1097] train: loss: 0.0325201
[Epoch 17; Iter   328/ 1097] train: loss: 0.0278266
[Epoch 17; Iter   358/ 1097] train: loss: 0.0351438
[Epoch 17; Iter   388/ 1097] train: loss: 0.0409231
[Epoch 17; Iter   418/ 1097] train: loss: 0.2089484
[Epoch 17; Iter   448/ 1097] train: loss: 0.0221393
[Epoch 17; Iter   478/ 1097] train: loss: 0.0394245
[Epoch 17; Iter   508/ 1097] train: loss: 0.0337159
[Epoch 17; Iter   538/ 1097] train: loss: 0.2633207
[Epoch 17; Iter   568/ 1097] train: loss: 0.2433926
[Epoch 17; Iter   598/ 1097] train: loss: 0.1591735
[Epoch 17; Iter   628/ 1097] train: loss: 0.0652158
[Epoch 17; Iter   658/ 1097] train: loss: 0.0530224
[Epoch 17; Iter   688/ 1097] train: loss: 0.1751823
[Epoch 17; Iter   718/ 1097] train: loss: 0.0513424
[Epoch 17; Iter   748/ 1097] train: loss: 0.1431800
[Epoch 17; Iter   778/ 1097] train: loss: 0.0619681
[Epoch 17; Iter   808/ 1097] train: loss: 0.1301581
[Epoch 17; Iter   838/ 1097] train: loss: 0.0746149
[Epoch 17; Iter   868/ 1097] train: loss: 0.0286625
[Epoch 17; Iter   898/ 1097] train: loss: 0.1719608
[Epoch 17; Iter   928/ 1097] train: loss: 0.2286096
[Epoch 17; Iter   958/ 1097] train: loss: 0.2266812
[Epoch 17; Iter   988/ 1097] train: loss: 0.0493103
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0598176
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0344431
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1697290
[Epoch 17] ogbg-molhiv: 0.685519 val loss: 0.257444
[Epoch 17] ogbg-molhiv: 0.711590 test loss: 0.123658
[Epoch 18; Iter    11/ 1097] train: loss: 0.1388666
[Epoch 18; Iter    41/ 1097] train: loss: 0.2823467
[Epoch 18; Iter    71/ 1097] train: loss: 0.0649529
[Epoch 18; Iter   101/ 1097] train: loss: 0.0735587
[Epoch 18; Iter   131/ 1097] train: loss: 0.1146352
[Epoch 18; Iter   161/ 1097] train: loss: 0.0524144
[Epoch 18; Iter   191/ 1097] train: loss: 0.1334888
[Epoch 18; Iter   221/ 1097] train: loss: 0.1735062
[Epoch 18; Iter   251/ 1097] train: loss: 0.1518483
[Epoch 18; Iter   281/ 1097] train: loss: 0.0268572
[Epoch 18; Iter   311/ 1097] train: loss: 0.1673330
[Epoch 18; Iter   341/ 1097] train: loss: 0.0636208
[Epoch 18; Iter   371/ 1097] train: loss: 0.0249371
[Epoch 18; Iter   401/ 1097] train: loss: 0.2323006
[Epoch 18; Iter   431/ 1097] train: loss: 0.2127683
[Epoch 18; Iter   461/ 1097] train: loss: 0.0429694
[Epoch 18; Iter   491/ 1097] train: loss: 0.2087754
[Epoch 18; Iter   521/ 1097] train: loss: 0.2388028
[Epoch 18; Iter   551/ 1097] train: loss: 0.0339291
[Epoch 18; Iter   581/ 1097] train: loss: 0.0954448
[Epoch 18; Iter   611/ 1097] train: loss: 0.0315038
[Epoch 18; Iter   641/ 1097] train: loss: 0.1530711
[Epoch 18; Iter   671/ 1097] train: loss: 0.1143470
[Epoch 18; Iter   701/ 1097] train: loss: 0.1796986
[Epoch 18; Iter   731/ 1097] train: loss: 0.1388003
[Epoch 18; Iter   761/ 1097] train: loss: 0.2507522
[Epoch 18; Iter   791/ 1097] train: loss: 0.0532519
[Epoch 18; Iter   821/ 1097] train: loss: 0.0813057
[Epoch 18; Iter   851/ 1097] train: loss: 0.1487727
[Epoch 18; Iter   881/ 1097] train: loss: 0.1357909
[Epoch 18; Iter   911/ 1097] train: loss: 0.1441324
[Epoch 18; Iter   941/ 1097] train: loss: 0.0187143
[Epoch 18; Iter   971/ 1097] train: loss: 0.1302458
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0275623
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0993998
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0946387
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1469837
[Epoch 18] ogbg-molhiv: 0.724479 val loss: 0.297582
[Epoch 18] ogbg-molhiv: 0.743384 test loss: 0.132200
[Epoch 19; Iter    24/ 1097] train: loss: 0.2909198
[Epoch 19; Iter    54/ 1097] train: loss: 0.0697525
[Epoch 19; Iter    84/ 1097] train: loss: 0.2782944
[Epoch 19; Iter   114/ 1097] train: loss: 0.0259857
[Epoch 19; Iter   144/ 1097] train: loss: 0.0392506
[Epoch 19; Iter   174/ 1097] train: loss: 0.0619747
[Epoch 19; Iter   204/ 1097] train: loss: 0.0294366
[Epoch 19; Iter   234/ 1097] train: loss: 0.0289397
[Epoch 19; Iter   264/ 1097] train: loss: 0.1132028
[Epoch 19; Iter   294/ 1097] train: loss: 0.1279930
[Epoch 19; Iter   324/ 1097] train: loss: 0.0226246
[Epoch 19; Iter   354/ 1097] train: loss: 0.2893145
[Epoch 19; Iter   384/ 1097] train: loss: 0.0376098
[Epoch 19; Iter   414/ 1097] train: loss: 0.0643379
[Epoch 19; Iter   444/ 1097] train: loss: 0.1741296
[Epoch 19; Iter   474/ 1097] train: loss: 0.0751929
[Epoch 19; Iter   504/ 1097] train: loss: 0.0633718
[Epoch 19; Iter   534/ 1097] train: loss: 0.1716827
[Epoch 19; Iter   564/ 1097] train: loss: 0.0435947
[Epoch 19; Iter   594/ 1097] train: loss: 0.0282526
[Epoch 19; Iter   624/ 1097] train: loss: 0.0742541
[Epoch 19; Iter   654/ 1097] train: loss: 0.0674118
[Epoch 19; Iter   684/ 1097] train: loss: 0.1176602
[Epoch 19; Iter   714/ 1097] train: loss: 0.1627293
[Epoch 19; Iter   744/ 1097] train: loss: 0.0287730
[Epoch 19; Iter   774/ 1097] train: loss: 0.1466884
[Epoch 19; Iter   804/ 1097] train: loss: 0.0838553
[Epoch 19; Iter   834/ 1097] train: loss: 0.1713224
[Epoch 19; Iter   864/ 1097] train: loss: 0.3833950
[Epoch 19; Iter   894/ 1097] train: loss: 0.1756350
[Epoch 19; Iter   924/ 1097] train: loss: 0.4113604
[Epoch 19; Iter   954/ 1097] train: loss: 0.1453806
[Epoch 19; Iter   984/ 1097] train: loss: 0.3239276
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1604581
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0422644
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0783464
[Epoch 19] ogbg-molhiv: 0.760028 val loss: 0.076832
[Epoch 19] ogbg-molhiv: 0.734991 test loss: 0.126732
[Epoch 20; Iter     7/ 1097] train: loss: 0.0597376
[Epoch 20; Iter    37/ 1097] train: loss: 0.2253273
[Epoch 20; Iter    67/ 1097] train: loss: 0.0685986
[Epoch 20; Iter    97/ 1097] train: loss: 0.0383692
[Epoch 20; Iter   127/ 1097] train: loss: 0.0245490
[Epoch 20; Iter   157/ 1097] train: loss: 0.0788237
[Epoch 20; Iter   187/ 1097] train: loss: 0.0167286
[Epoch 20; Iter   217/ 1097] train: loss: 0.0236385
[Epoch 20; Iter   247/ 1097] train: loss: 0.0566968
[Epoch 20; Iter   277/ 1097] train: loss: 0.1488160
[Epoch 16; Iter   225/ 1097] train: loss: 0.1770323
[Epoch 16; Iter   255/ 1097] train: loss: 0.0575244
[Epoch 16; Iter   285/ 1097] train: loss: 0.1553283
[Epoch 16; Iter   315/ 1097] train: loss: 0.0425751
[Epoch 16; Iter   345/ 1097] train: loss: 0.1225036
[Epoch 16; Iter   375/ 1097] train: loss: 0.1502959
[Epoch 16; Iter   405/ 1097] train: loss: 0.0301158
[Epoch 16; Iter   435/ 1097] train: loss: 0.2969273
[Epoch 16; Iter   465/ 1097] train: loss: 0.0814746
[Epoch 16; Iter   495/ 1097] train: loss: 0.0190115
[Epoch 16; Iter   525/ 1097] train: loss: 0.2797459
[Epoch 16; Iter   555/ 1097] train: loss: 0.0238624
[Epoch 16; Iter   585/ 1097] train: loss: 0.2699281
[Epoch 16; Iter   615/ 1097] train: loss: 0.1117602
[Epoch 16; Iter   645/ 1097] train: loss: 0.0700367
[Epoch 16; Iter   675/ 1097] train: loss: 0.0618557
[Epoch 16; Iter   705/ 1097] train: loss: 0.0288443
[Epoch 16; Iter   735/ 1097] train: loss: 0.2785732
[Epoch 16; Iter   765/ 1097] train: loss: 0.0325383
[Epoch 16; Iter   795/ 1097] train: loss: 0.0616362
[Epoch 16; Iter   825/ 1097] train: loss: 0.2695779
[Epoch 16; Iter   855/ 1097] train: loss: 0.2533748
[Epoch 16; Iter   885/ 1097] train: loss: 0.0234132
[Epoch 16; Iter   915/ 1097] train: loss: 0.0682483
[Epoch 16; Iter   945/ 1097] train: loss: 0.1312903
[Epoch 16; Iter   975/ 1097] train: loss: 0.1933596
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2147884
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0399039
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1451073
[Epoch 16; Iter  1095/ 1097] train: loss: 0.2307068
[Epoch 16] ogbg-molhiv: 0.762594 val loss: 0.080327
[Epoch 16] ogbg-molhiv: 0.726219 test loss: 0.121126
[Epoch 17; Iter    28/ 1097] train: loss: 0.2509921
[Epoch 17; Iter    58/ 1097] train: loss: 0.0297543
[Epoch 17; Iter    88/ 1097] train: loss: 0.2241514
[Epoch 17; Iter   118/ 1097] train: loss: 0.2290044
[Epoch 17; Iter   148/ 1097] train: loss: 0.0223523
[Epoch 17; Iter   178/ 1097] train: loss: 0.1484924
[Epoch 17; Iter   208/ 1097] train: loss: 0.0227757
[Epoch 17; Iter   238/ 1097] train: loss: 0.1904097
[Epoch 17; Iter   268/ 1097] train: loss: 0.0389943
[Epoch 17; Iter   298/ 1097] train: loss: 0.1429361
[Epoch 17; Iter   328/ 1097] train: loss: 0.2358556
[Epoch 17; Iter   358/ 1097] train: loss: 0.0299823
[Epoch 17; Iter   388/ 1097] train: loss: 0.1337601
[Epoch 17; Iter   418/ 1097] train: loss: 0.2620592
[Epoch 17; Iter   448/ 1097] train: loss: 0.0298980
[Epoch 17; Iter   478/ 1097] train: loss: 0.0661066
[Epoch 17; Iter   508/ 1097] train: loss: 0.1139109
[Epoch 17; Iter   538/ 1097] train: loss: 0.0242714
[Epoch 17; Iter   568/ 1097] train: loss: 0.1582504
[Epoch 17; Iter   598/ 1097] train: loss: 0.0294286
[Epoch 17; Iter   628/ 1097] train: loss: 0.2000501
[Epoch 17; Iter   658/ 1097] train: loss: 0.0782991
[Epoch 17; Iter   688/ 1097] train: loss: 0.0677252
[Epoch 17; Iter   718/ 1097] train: loss: 0.1680697
[Epoch 17; Iter   748/ 1097] train: loss: 0.0260646
[Epoch 17; Iter   778/ 1097] train: loss: 0.2342236
[Epoch 17; Iter   808/ 1097] train: loss: 0.0206538
[Epoch 17; Iter   838/ 1097] train: loss: 0.0240284
[Epoch 17; Iter   868/ 1097] train: loss: 0.0325148
[Epoch 17; Iter   898/ 1097] train: loss: 0.0345521
[Epoch 17; Iter   928/ 1097] train: loss: 0.3311141
[Epoch 17; Iter   958/ 1097] train: loss: 0.1233106
[Epoch 17; Iter   988/ 1097] train: loss: 0.0271055
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0331911
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0260570
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0893754
[Epoch 17] ogbg-molhiv: 0.686373 val loss: 0.113364
[Epoch 17] ogbg-molhiv: 0.667341 test loss: 0.506832
[Epoch 18; Iter    11/ 1097] train: loss: 0.2265126
[Epoch 18; Iter    41/ 1097] train: loss: 0.0529783
[Epoch 18; Iter    71/ 1097] train: loss: 0.1289748
[Epoch 18; Iter   101/ 1097] train: loss: 0.0364763
[Epoch 18; Iter   131/ 1097] train: loss: 0.2236701
[Epoch 18; Iter   161/ 1097] train: loss: 0.1209346
[Epoch 18; Iter   191/ 1097] train: loss: 0.1455427
[Epoch 18; Iter   221/ 1097] train: loss: 0.0212555
[Epoch 18; Iter   251/ 1097] train: loss: 0.0473694
[Epoch 18; Iter   281/ 1097] train: loss: 0.0280875
[Epoch 18; Iter   311/ 1097] train: loss: 0.3283754
[Epoch 18; Iter   341/ 1097] train: loss: 0.1470942
[Epoch 18; Iter   371/ 1097] train: loss: 0.0337606
[Epoch 18; Iter   401/ 1097] train: loss: 0.0285060
[Epoch 18; Iter   431/ 1097] train: loss: 0.0291541
[Epoch 18; Iter   461/ 1097] train: loss: 0.0902677
[Epoch 18; Iter   491/ 1097] train: loss: 0.0942264
[Epoch 18; Iter   521/ 1097] train: loss: 0.0561277
[Epoch 18; Iter   551/ 1097] train: loss: 0.0389768
[Epoch 18; Iter   581/ 1097] train: loss: 0.0313912
[Epoch 18; Iter   611/ 1097] train: loss: 0.1233972
[Epoch 18; Iter   641/ 1097] train: loss: 0.0985892
[Epoch 18; Iter   671/ 1097] train: loss: 0.0857996
[Epoch 18; Iter   701/ 1097] train: loss: 0.1542850
[Epoch 18; Iter   731/ 1097] train: loss: 0.1100720
[Epoch 18; Iter   761/ 1097] train: loss: 0.0436960
[Epoch 18; Iter   791/ 1097] train: loss: 0.0828547
[Epoch 18; Iter   821/ 1097] train: loss: 0.0255879
[Epoch 18; Iter   851/ 1097] train: loss: 0.2158114
[Epoch 18; Iter   881/ 1097] train: loss: 0.0451672
[Epoch 18; Iter   911/ 1097] train: loss: 0.1146226
[Epoch 18; Iter   941/ 1097] train: loss: 0.0369006
[Epoch 18; Iter   971/ 1097] train: loss: 0.0579012
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1455821
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0385471
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0349286
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0490058
[Epoch 18] ogbg-molhiv: 0.729066 val loss: 0.091028
[Epoch 18] ogbg-molhiv: 0.669520 test loss: 0.158957
[Epoch 19; Iter    24/ 1097] train: loss: 0.1187264
[Epoch 19; Iter    54/ 1097] train: loss: 0.0705104
[Epoch 19; Iter    84/ 1097] train: loss: 0.0233747
[Epoch 19; Iter   114/ 1097] train: loss: 0.0922992
[Epoch 19; Iter   144/ 1097] train: loss: 0.1669585
[Epoch 19; Iter   174/ 1097] train: loss: 0.0876107
[Epoch 19; Iter   204/ 1097] train: loss: 0.0970070
[Epoch 19; Iter   234/ 1097] train: loss: 0.2052718
[Epoch 19; Iter   264/ 1097] train: loss: 0.2357445
[Epoch 19; Iter   294/ 1097] train: loss: 0.2953721
[Epoch 19; Iter   324/ 1097] train: loss: 0.0402341
[Epoch 19; Iter   354/ 1097] train: loss: 0.0519443
[Epoch 19; Iter   384/ 1097] train: loss: 0.1600420
[Epoch 19; Iter   414/ 1097] train: loss: 0.2163257
[Epoch 19; Iter   444/ 1097] train: loss: 0.1427541
[Epoch 19; Iter   474/ 1097] train: loss: 0.0195425
[Epoch 19; Iter   504/ 1097] train: loss: 0.1503676
[Epoch 19; Iter   534/ 1097] train: loss: 0.3542374
[Epoch 19; Iter   564/ 1097] train: loss: 0.2075084
[Epoch 19; Iter   594/ 1097] train: loss: 0.0258774
[Epoch 19; Iter   624/ 1097] train: loss: 0.0246212
[Epoch 19; Iter   654/ 1097] train: loss: 0.1413857
[Epoch 19; Iter   684/ 1097] train: loss: 0.1052611
[Epoch 19; Iter   714/ 1097] train: loss: 0.1948854
[Epoch 19; Iter   744/ 1097] train: loss: 0.2060651
[Epoch 19; Iter   774/ 1097] train: loss: 0.1026229
[Epoch 19; Iter   804/ 1097] train: loss: 0.0233470
[Epoch 19; Iter   834/ 1097] train: loss: 0.2555499
[Epoch 19; Iter   864/ 1097] train: loss: 0.1473564
[Epoch 19; Iter   894/ 1097] train: loss: 0.0382980
[Epoch 19; Iter   924/ 1097] train: loss: 0.1132762
[Epoch 19; Iter   954/ 1097] train: loss: 0.1539577
[Epoch 19; Iter   984/ 1097] train: loss: 0.0363393
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1721296
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1904914
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0254433
[Epoch 19] ogbg-molhiv: 0.709028 val loss: 0.091767
[Epoch 19] ogbg-molhiv: 0.648506 test loss: 0.140007
[Epoch 20; Iter     7/ 1097] train: loss: 0.0641653
[Epoch 20; Iter    37/ 1097] train: loss: 0.2254927
[Epoch 20; Iter    67/ 1097] train: loss: 0.0807426
[Epoch 20; Iter    97/ 1097] train: loss: 0.0635292
[Epoch 20; Iter   127/ 1097] train: loss: 0.1596450
[Epoch 20; Iter   157/ 1097] train: loss: 0.0330558
[Epoch 20; Iter   187/ 1097] train: loss: 0.0560131
[Epoch 20; Iter   217/ 1097] train: loss: 0.0153677
[Epoch 20; Iter   247/ 1097] train: loss: 0.0890721
[Epoch 20; Iter   277/ 1097] train: loss: 0.2244404
[Epoch 16; Iter   225/ 1097] train: loss: 0.0565725
[Epoch 16; Iter   255/ 1097] train: loss: 0.1811558
[Epoch 16; Iter   285/ 1097] train: loss: 0.0386491
[Epoch 16; Iter   315/ 1097] train: loss: 0.0751899
[Epoch 16; Iter   345/ 1097] train: loss: 0.1105687
[Epoch 16; Iter   375/ 1097] train: loss: 0.0783437
[Epoch 16; Iter   405/ 1097] train: loss: 0.0433159
[Epoch 16; Iter   435/ 1097] train: loss: 0.1060973
[Epoch 16; Iter   465/ 1097] train: loss: 0.2335964
[Epoch 16; Iter   495/ 1097] train: loss: 0.0343259
[Epoch 16; Iter   525/ 1097] train: loss: 0.0242121
[Epoch 16; Iter   555/ 1097] train: loss: 0.3557605
[Epoch 16; Iter   585/ 1097] train: loss: 0.0481413
[Epoch 16; Iter   615/ 1097] train: loss: 0.1480653
[Epoch 16; Iter   645/ 1097] train: loss: 0.0795631
[Epoch 16; Iter   675/ 1097] train: loss: 0.1262514
[Epoch 16; Iter   705/ 1097] train: loss: 0.0289095
[Epoch 16; Iter   735/ 1097] train: loss: 0.1014120
[Epoch 16; Iter   765/ 1097] train: loss: 0.3593283
[Epoch 16; Iter   795/ 1097] train: loss: 0.0846477
[Epoch 16; Iter   825/ 1097] train: loss: 0.1798652
[Epoch 16; Iter   855/ 1097] train: loss: 0.0477074
[Epoch 16; Iter   885/ 1097] train: loss: 0.1993194
[Epoch 16; Iter   915/ 1097] train: loss: 0.1131636
[Epoch 16; Iter   945/ 1097] train: loss: 0.0218313
[Epoch 16; Iter   975/ 1097] train: loss: 0.0557368
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1109519
[Epoch 16; Iter  1035/ 1097] train: loss: 0.1302275
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0253519
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0272783
[Epoch 16] ogbg-molhiv: 0.665485 val loss: 0.826473
[Epoch 16] ogbg-molhiv: 0.687174 test loss: 0.558934
[Epoch 17; Iter    28/ 1097] train: loss: 0.1156338
[Epoch 17; Iter    58/ 1097] train: loss: 0.1025542
[Epoch 17; Iter    88/ 1097] train: loss: 0.1060744
[Epoch 17; Iter   118/ 1097] train: loss: 0.0275266
[Epoch 17; Iter   148/ 1097] train: loss: 0.0318699
[Epoch 17; Iter   178/ 1097] train: loss: 0.0294020
[Epoch 17; Iter   208/ 1097] train: loss: 0.0188568
[Epoch 17; Iter   238/ 1097] train: loss: 0.0720901
[Epoch 17; Iter   268/ 1097] train: loss: 0.1166412
[Epoch 17; Iter   298/ 1097] train: loss: 0.0362717
[Epoch 17; Iter   328/ 1097] train: loss: 0.0894333
[Epoch 17; Iter   358/ 1097] train: loss: 0.1634906
[Epoch 17; Iter   388/ 1097] train: loss: 0.0499578
[Epoch 17; Iter   418/ 1097] train: loss: 0.1130186
[Epoch 17; Iter   448/ 1097] train: loss: 0.1810891
[Epoch 17; Iter   478/ 1097] train: loss: 0.2611719
[Epoch 17; Iter   508/ 1097] train: loss: 0.0561058
[Epoch 17; Iter   538/ 1097] train: loss: 0.0877686
[Epoch 17; Iter   568/ 1097] train: loss: 0.0247904
[Epoch 17; Iter   598/ 1097] train: loss: 0.1841858
[Epoch 17; Iter   628/ 1097] train: loss: 0.0360608
[Epoch 17; Iter   658/ 1097] train: loss: 0.1506592
[Epoch 17; Iter   688/ 1097] train: loss: 0.0372966
[Epoch 17; Iter   718/ 1097] train: loss: 0.0812197
[Epoch 17; Iter   748/ 1097] train: loss: 0.3284909
[Epoch 17; Iter   778/ 1097] train: loss: 0.0703403
[Epoch 17; Iter   808/ 1097] train: loss: 0.0610801
[Epoch 17; Iter   838/ 1097] train: loss: 0.0849322
[Epoch 17; Iter   868/ 1097] train: loss: 0.0253941
[Epoch 17; Iter   898/ 1097] train: loss: 0.1469366
[Epoch 17; Iter   928/ 1097] train: loss: 0.2445212
[Epoch 17; Iter   958/ 1097] train: loss: 0.0357800
[Epoch 17; Iter   988/ 1097] train: loss: 0.1149963
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0923056
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2118982
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1439005
[Epoch 17] ogbg-molhiv: 0.752578 val loss: 0.177337
[Epoch 17] ogbg-molhiv: 0.700309 test loss: 0.222552
[Epoch 18; Iter    11/ 1097] train: loss: 0.0233280
[Epoch 18; Iter    41/ 1097] train: loss: 0.1743904
[Epoch 18; Iter    71/ 1097] train: loss: 0.2523137
[Epoch 18; Iter   101/ 1097] train: loss: 0.0351572
[Epoch 18; Iter   131/ 1097] train: loss: 0.1115209
[Epoch 18; Iter   161/ 1097] train: loss: 0.1703599
[Epoch 18; Iter   191/ 1097] train: loss: 0.0503908
[Epoch 18; Iter   221/ 1097] train: loss: 0.0959067
[Epoch 18; Iter   251/ 1097] train: loss: 0.0160140
[Epoch 18; Iter   281/ 1097] train: loss: 0.0683436
[Epoch 18; Iter   311/ 1097] train: loss: 0.0281496
[Epoch 18; Iter   341/ 1097] train: loss: 0.0376611
[Epoch 18; Iter   371/ 1097] train: loss: 0.0382741
[Epoch 18; Iter   401/ 1097] train: loss: 0.1663179
[Epoch 18; Iter   431/ 1097] train: loss: 0.0300356
[Epoch 18; Iter   461/ 1097] train: loss: 0.1573348
[Epoch 18; Iter   491/ 1097] train: loss: 0.0174992
[Epoch 18; Iter   521/ 1097] train: loss: 0.1377850
[Epoch 18; Iter   551/ 1097] train: loss: 0.0381479
[Epoch 18; Iter   581/ 1097] train: loss: 0.0406508
[Epoch 18; Iter   611/ 1097] train: loss: 0.0385581
[Epoch 18; Iter   641/ 1097] train: loss: 0.1235030
[Epoch 18; Iter   671/ 1097] train: loss: 0.0297976
[Epoch 18; Iter   701/ 1097] train: loss: 0.0410375
[Epoch 18; Iter   731/ 1097] train: loss: 0.0302734
[Epoch 18; Iter   761/ 1097] train: loss: 0.0344202
[Epoch 18; Iter   791/ 1097] train: loss: 0.0321132
[Epoch 18; Iter   821/ 1097] train: loss: 0.0781949
[Epoch 18; Iter   851/ 1097] train: loss: 0.0264029
[Epoch 18; Iter   881/ 1097] train: loss: 0.0323969
[Epoch 18; Iter   911/ 1097] train: loss: 0.0214415
[Epoch 18; Iter   941/ 1097] train: loss: 0.0921493
[Epoch 18; Iter   971/ 1097] train: loss: 0.0393722
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1129827
[Epoch 18; Iter  1031/ 1097] train: loss: 0.1803652
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0326699
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0127435
[Epoch 18] ogbg-molhiv: 0.663057 val loss: 0.136905
[Epoch 18] ogbg-molhiv: 0.705499 test loss: 0.247019
[Epoch 19; Iter    24/ 1097] train: loss: 0.0405236
[Epoch 19; Iter    54/ 1097] train: loss: 0.0774367
[Epoch 19; Iter    84/ 1097] train: loss: 0.0209555
[Epoch 19; Iter   114/ 1097] train: loss: 0.0397810
[Epoch 19; Iter   144/ 1097] train: loss: 0.0683099
[Epoch 19; Iter   174/ 1097] train: loss: 0.0289304
[Epoch 19; Iter   204/ 1097] train: loss: 0.0619889
[Epoch 19; Iter   234/ 1097] train: loss: 0.0751480
[Epoch 19; Iter   264/ 1097] train: loss: 0.0168237
[Epoch 19; Iter   294/ 1097] train: loss: 0.0336873
[Epoch 19; Iter   324/ 1097] train: loss: 0.0271622
[Epoch 19; Iter   354/ 1097] train: loss: 0.1447908
[Epoch 19; Iter   384/ 1097] train: loss: 0.0285614
[Epoch 19; Iter   414/ 1097] train: loss: 0.0207684
[Epoch 19; Iter   444/ 1097] train: loss: 0.0246294
[Epoch 19; Iter   474/ 1097] train: loss: 0.1579054
[Epoch 19; Iter   504/ 1097] train: loss: 0.0234030
[Epoch 19; Iter   534/ 1097] train: loss: 0.0739678
[Epoch 19; Iter   564/ 1097] train: loss: 0.0862844
[Epoch 19; Iter   594/ 1097] train: loss: 0.0947874
[Epoch 19; Iter   624/ 1097] train: loss: 0.0302235
[Epoch 19; Iter   654/ 1097] train: loss: 0.0339715
[Epoch 19; Iter   684/ 1097] train: loss: 0.3775789
[Epoch 19; Iter   714/ 1097] train: loss: 0.0160387
[Epoch 19; Iter   744/ 1097] train: loss: 0.0497551
[Epoch 19; Iter   774/ 1097] train: loss: 0.1160900
[Epoch 19; Iter   804/ 1097] train: loss: 0.0287771
[Epoch 19; Iter   834/ 1097] train: loss: 0.0971198
[Epoch 19; Iter   864/ 1097] train: loss: 0.0314591
[Epoch 19; Iter   894/ 1097] train: loss: 0.3794878
[Epoch 19; Iter   924/ 1097] train: loss: 0.0858597
[Epoch 19; Iter   954/ 1097] train: loss: 0.0157614
[Epoch 19; Iter   984/ 1097] train: loss: 0.0341815
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1307988
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0833009
[Epoch 19; Iter  1074/ 1097] train: loss: 0.2442515
[Epoch 19] ogbg-molhiv: 0.752269 val loss: 0.115464
[Epoch 19] ogbg-molhiv: 0.708627 test loss: 0.160831
[Epoch 20; Iter     7/ 1097] train: loss: 0.0185979
[Epoch 20; Iter    37/ 1097] train: loss: 0.0271634
[Epoch 20; Iter    67/ 1097] train: loss: 0.0272303
[Epoch 20; Iter    97/ 1097] train: loss: 0.0397165
[Epoch 20; Iter   127/ 1097] train: loss: 0.0540184
[Epoch 20; Iter   157/ 1097] train: loss: 0.0299484
[Epoch 20; Iter   187/ 1097] train: loss: 0.1009350
[Epoch 20; Iter   217/ 1097] train: loss: 0.1015168
[Epoch 20; Iter   247/ 1097] train: loss: 0.0755446
[Epoch 20; Iter   277/ 1097] train: loss: 0.0179302
[Epoch 16; Iter   225/ 1097] train: loss: 0.0950443
[Epoch 16; Iter   255/ 1097] train: loss: 0.0323030
[Epoch 16; Iter   285/ 1097] train: loss: 0.1930209
[Epoch 16; Iter   315/ 1097] train: loss: 0.0464230
[Epoch 16; Iter   345/ 1097] train: loss: 0.2204504
[Epoch 16; Iter   375/ 1097] train: loss: 0.1389011
[Epoch 16; Iter   405/ 1097] train: loss: 0.0276824
[Epoch 16; Iter   435/ 1097] train: loss: 0.2037689
[Epoch 16; Iter   465/ 1097] train: loss: 0.0661638
[Epoch 16; Iter   495/ 1097] train: loss: 0.0290717
[Epoch 16; Iter   525/ 1097] train: loss: 0.2373635
[Epoch 16; Iter   555/ 1097] train: loss: 0.0266653
[Epoch 16; Iter   585/ 1097] train: loss: 0.2707103
[Epoch 16; Iter   615/ 1097] train: loss: 0.1257821
[Epoch 16; Iter   645/ 1097] train: loss: 0.1667317
[Epoch 16; Iter   675/ 1097] train: loss: 0.0327087
[Epoch 16; Iter   705/ 1097] train: loss: 0.0330438
[Epoch 16; Iter   735/ 1097] train: loss: 0.3637562
[Epoch 16; Iter   765/ 1097] train: loss: 0.0217598
[Epoch 16; Iter   795/ 1097] train: loss: 0.0396331
[Epoch 16; Iter   825/ 1097] train: loss: 0.2135770
[Epoch 16; Iter   855/ 1097] train: loss: 0.2075919
[Epoch 16; Iter   885/ 1097] train: loss: 0.0305496
[Epoch 16; Iter   915/ 1097] train: loss: 0.0679390
[Epoch 16; Iter   945/ 1097] train: loss: 0.1391008
[Epoch 16; Iter   975/ 1097] train: loss: 0.1671762
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1790874
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0392399
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1643851
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1570210
[Epoch 16] ogbg-molhiv: 0.735652 val loss: 0.242397
[Epoch 16] ogbg-molhiv: 0.699525 test loss: 0.213283
[Epoch 17; Iter    28/ 1097] train: loss: 0.2869171
[Epoch 17; Iter    58/ 1097] train: loss: 0.0430973
[Epoch 17; Iter    88/ 1097] train: loss: 0.1886170
[Epoch 17; Iter   118/ 1097] train: loss: 0.2777158
[Epoch 17; Iter   148/ 1097] train: loss: 0.0264374
[Epoch 17; Iter   178/ 1097] train: loss: 0.1658553
[Epoch 17; Iter   208/ 1097] train: loss: 0.0671097
[Epoch 17; Iter   238/ 1097] train: loss: 0.1276778
[Epoch 17; Iter   268/ 1097] train: loss: 0.0629434
[Epoch 17; Iter   298/ 1097] train: loss: 0.1512174
[Epoch 17; Iter   328/ 1097] train: loss: 0.1905461
[Epoch 17; Iter   358/ 1097] train: loss: 0.0383322
[Epoch 17; Iter   388/ 1097] train: loss: 0.2136712
[Epoch 17; Iter   418/ 1097] train: loss: 0.1881183
[Epoch 17; Iter   448/ 1097] train: loss: 0.0285091
[Epoch 17; Iter   478/ 1097] train: loss: 0.1158958
[Epoch 17; Iter   508/ 1097] train: loss: 0.2115642
[Epoch 17; Iter   538/ 1097] train: loss: 0.0276673
[Epoch 17; Iter   568/ 1097] train: loss: 0.2644517
[Epoch 17; Iter   598/ 1097] train: loss: 0.0437051
[Epoch 17; Iter   628/ 1097] train: loss: 0.1626947
[Epoch 17; Iter   658/ 1097] train: loss: 0.0805846
[Epoch 17; Iter   688/ 1097] train: loss: 0.0759083
[Epoch 17; Iter   718/ 1097] train: loss: 0.1889953
[Epoch 17; Iter   748/ 1097] train: loss: 0.0236167
[Epoch 17; Iter   778/ 1097] train: loss: 0.2968003
[Epoch 17; Iter   808/ 1097] train: loss: 0.0229179
[Epoch 17; Iter   838/ 1097] train: loss: 0.0207272
[Epoch 17; Iter   868/ 1097] train: loss: 0.0293793
[Epoch 17; Iter   898/ 1097] train: loss: 0.0369750
[Epoch 17; Iter   928/ 1097] train: loss: 0.3147529
[Epoch 17; Iter   958/ 1097] train: loss: 0.0314004
[Epoch 17; Iter   988/ 1097] train: loss: 0.0206410
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0266598
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0479893
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0938850
[Epoch 17] ogbg-molhiv: 0.731393 val loss: 0.167376
[Epoch 17] ogbg-molhiv: 0.656357 test loss: 0.236002
[Epoch 18; Iter    11/ 1097] train: loss: 0.1476109
[Epoch 18; Iter    41/ 1097] train: loss: 0.0259121
[Epoch 18; Iter    71/ 1097] train: loss: 0.0691161
[Epoch 18; Iter   101/ 1097] train: loss: 0.0213253
[Epoch 18; Iter   131/ 1097] train: loss: 0.2572323
[Epoch 18; Iter   161/ 1097] train: loss: 0.2013439
[Epoch 18; Iter   191/ 1097] train: loss: 0.0525984
[Epoch 18; Iter   221/ 1097] train: loss: 0.0242649
[Epoch 18; Iter   251/ 1097] train: loss: 0.1219428
[Epoch 18; Iter   281/ 1097] train: loss: 0.0540287
[Epoch 18; Iter   311/ 1097] train: loss: 0.2197490
[Epoch 18; Iter   341/ 1097] train: loss: 0.1722048
[Epoch 18; Iter   371/ 1097] train: loss: 0.0236224
[Epoch 18; Iter   401/ 1097] train: loss: 0.0301803
[Epoch 18; Iter   431/ 1097] train: loss: 0.0210016
[Epoch 18; Iter   461/ 1097] train: loss: 0.1638023
[Epoch 18; Iter   491/ 1097] train: loss: 0.2212651
[Epoch 18; Iter   521/ 1097] train: loss: 0.0372791
[Epoch 18; Iter   551/ 1097] train: loss: 0.0366377
[Epoch 18; Iter   581/ 1097] train: loss: 0.0407869
[Epoch 18; Iter   611/ 1097] train: loss: 0.1542409
[Epoch 18; Iter   641/ 1097] train: loss: 0.0534321
[Epoch 18; Iter   671/ 1097] train: loss: 0.2544916
[Epoch 18; Iter   701/ 1097] train: loss: 0.2111673
[Epoch 18; Iter   731/ 1097] train: loss: 0.2176085
[Epoch 18; Iter   761/ 1097] train: loss: 0.0677729
[Epoch 18; Iter   791/ 1097] train: loss: 0.1467912
[Epoch 18; Iter   821/ 1097] train: loss: 0.0271067
[Epoch 18; Iter   851/ 1097] train: loss: 0.1680179
[Epoch 18; Iter   881/ 1097] train: loss: 0.0190498
[Epoch 18; Iter   911/ 1097] train: loss: 0.1715591
[Epoch 18; Iter   941/ 1097] train: loss: 0.0317739
[Epoch 18; Iter   971/ 1097] train: loss: 0.0478413
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1097626
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0283194
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0356767
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0298207
[Epoch 18] ogbg-molhiv: 0.697145 val loss: 0.372714
[Epoch 18] ogbg-molhiv: 0.671164 test loss: 0.230726
[Epoch 19; Iter    24/ 1097] train: loss: 0.0569911
[Epoch 19; Iter    54/ 1097] train: loss: 0.0905210
[Epoch 19; Iter    84/ 1097] train: loss: 0.0224845
[Epoch 19; Iter   114/ 1097] train: loss: 0.0306069
[Epoch 19; Iter   144/ 1097] train: loss: 0.1439169
[Epoch 19; Iter   174/ 1097] train: loss: 0.1440393
[Epoch 19; Iter   204/ 1097] train: loss: 0.1030499
[Epoch 19; Iter   234/ 1097] train: loss: 0.2530198
[Epoch 19; Iter   264/ 1097] train: loss: 0.1700285
[Epoch 19; Iter   294/ 1097] train: loss: 0.1937158
[Epoch 19; Iter   324/ 1097] train: loss: 0.0702343
[Epoch 19; Iter   354/ 1097] train: loss: 0.0487560
[Epoch 19; Iter   384/ 1097] train: loss: 0.1376087
[Epoch 19; Iter   414/ 1097] train: loss: 0.2511774
[Epoch 19; Iter   444/ 1097] train: loss: 0.0806896
[Epoch 19; Iter   474/ 1097] train: loss: 0.0209988
[Epoch 19; Iter   504/ 1097] train: loss: 0.2181577
[Epoch 19; Iter   534/ 1097] train: loss: 0.2601042
[Epoch 19; Iter   564/ 1097] train: loss: 0.1531673
[Epoch 19; Iter   594/ 1097] train: loss: 0.0249602
[Epoch 19; Iter   624/ 1097] train: loss: 0.0394927
[Epoch 19; Iter   654/ 1097] train: loss: 0.1489294
[Epoch 19; Iter   684/ 1097] train: loss: 0.0920401
[Epoch 19; Iter   714/ 1097] train: loss: 0.0396087
[Epoch 19; Iter   744/ 1097] train: loss: 0.0767299
[Epoch 19; Iter   774/ 1097] train: loss: 0.0638128
[Epoch 19; Iter   804/ 1097] train: loss: 0.0288453
[Epoch 19; Iter   834/ 1097] train: loss: 0.1036616
[Epoch 19; Iter   864/ 1097] train: loss: 0.1885356
[Epoch 19; Iter   894/ 1097] train: loss: 0.0391134
[Epoch 19; Iter   924/ 1097] train: loss: 0.1582144
[Epoch 19; Iter   954/ 1097] train: loss: 0.0786779
[Epoch 19; Iter   984/ 1097] train: loss: 0.0352340
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2261503
[Epoch 19; Iter  1044/ 1097] train: loss: 0.1600525
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0576162
[Epoch 19] ogbg-molhiv: 0.734384 val loss: 0.179466
[Epoch 19] ogbg-molhiv: 0.651737 test loss: 0.177735
[Epoch 20; Iter     7/ 1097] train: loss: 0.0440906
[Epoch 20; Iter    37/ 1097] train: loss: 0.1279341
[Epoch 20; Iter    67/ 1097] train: loss: 0.0473714
[Epoch 20; Iter    97/ 1097] train: loss: 0.0442777
[Epoch 20; Iter   127/ 1097] train: loss: 0.1988271
[Epoch 20; Iter   157/ 1097] train: loss: 0.0328143
[Epoch 20; Iter   187/ 1097] train: loss: 0.0380701
[Epoch 20; Iter   217/ 1097] train: loss: 0.0705569
[Epoch 20; Iter   247/ 1097] train: loss: 0.0892062
[Epoch 20; Iter   277/ 1097] train: loss: 0.2072339
[Epoch 16; Iter   225/ 1097] train: loss: 0.0360378
[Epoch 16; Iter   255/ 1097] train: loss: 0.1048868
[Epoch 16; Iter   285/ 1097] train: loss: 0.1807063
[Epoch 16; Iter   315/ 1097] train: loss: 0.0929673
[Epoch 16; Iter   345/ 1097] train: loss: 0.0397508
[Epoch 16; Iter   375/ 1097] train: loss: 0.1889403
[Epoch 16; Iter   405/ 1097] train: loss: 0.2240156
[Epoch 16; Iter   435/ 1097] train: loss: 0.1186682
[Epoch 16; Iter   465/ 1097] train: loss: 0.1860252
[Epoch 16; Iter   495/ 1097] train: loss: 0.1409411
[Epoch 16; Iter   525/ 1097] train: loss: 0.0948087
[Epoch 16; Iter   555/ 1097] train: loss: 0.0359364
[Epoch 16; Iter   585/ 1097] train: loss: 0.2211173
[Epoch 16; Iter   615/ 1097] train: loss: 0.1297031
[Epoch 16; Iter   645/ 1097] train: loss: 0.0582802
[Epoch 16; Iter   675/ 1097] train: loss: 0.0957149
[Epoch 16; Iter   705/ 1097] train: loss: 0.1658809
[Epoch 16; Iter   735/ 1097] train: loss: 0.1086278
[Epoch 16; Iter   765/ 1097] train: loss: 0.0717475
[Epoch 16; Iter   795/ 1097] train: loss: 0.1544528
[Epoch 16; Iter   825/ 1097] train: loss: 0.0279971
[Epoch 16; Iter   855/ 1097] train: loss: 0.1353789
[Epoch 16; Iter   885/ 1097] train: loss: 0.1671981
[Epoch 16; Iter   915/ 1097] train: loss: 0.0301834
[Epoch 16; Iter   945/ 1097] train: loss: 0.0285429
[Epoch 16; Iter   975/ 1097] train: loss: 0.0295579
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0358073
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0274618
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1169241
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1356294
[Epoch 16] ogbg-molhiv: 0.743319 val loss: 0.265499
[Epoch 16] ogbg-molhiv: 0.713992 test loss: 0.394613
[Epoch 17; Iter    28/ 1097] train: loss: 0.0474025
[Epoch 17; Iter    58/ 1097] train: loss: 0.0300409
[Epoch 17; Iter    88/ 1097] train: loss: 0.0370175
[Epoch 17; Iter   118/ 1097] train: loss: 0.1894835
[Epoch 17; Iter   148/ 1097] train: loss: 0.1771298
[Epoch 17; Iter   178/ 1097] train: loss: 0.0428990
[Epoch 17; Iter   208/ 1097] train: loss: 0.0223324
[Epoch 17; Iter   238/ 1097] train: loss: 0.2511934
[Epoch 17; Iter   268/ 1097] train: loss: 0.0489253
[Epoch 17; Iter   298/ 1097] train: loss: 0.0293517
[Epoch 17; Iter   328/ 1097] train: loss: 0.0408079
[Epoch 17; Iter   358/ 1097] train: loss: 0.0298264
[Epoch 17; Iter   388/ 1097] train: loss: 0.0327330
[Epoch 17; Iter   418/ 1097] train: loss: 0.1739853
[Epoch 17; Iter   448/ 1097] train: loss: 0.0259375
[Epoch 17; Iter   478/ 1097] train: loss: 0.0480239
[Epoch 17; Iter   508/ 1097] train: loss: 0.0431017
[Epoch 17; Iter   538/ 1097] train: loss: 0.3765792
[Epoch 17; Iter   568/ 1097] train: loss: 0.2421931
[Epoch 17; Iter   598/ 1097] train: loss: 0.1023984
[Epoch 17; Iter   628/ 1097] train: loss: 0.0566280
[Epoch 17; Iter   658/ 1097] train: loss: 0.0460830
[Epoch 17; Iter   688/ 1097] train: loss: 0.2098200
[Epoch 17; Iter   718/ 1097] train: loss: 0.0469976
[Epoch 17; Iter   748/ 1097] train: loss: 0.1480195
[Epoch 17; Iter   778/ 1097] train: loss: 0.0941406
[Epoch 17; Iter   808/ 1097] train: loss: 0.1891898
[Epoch 17; Iter   838/ 1097] train: loss: 0.1137625
[Epoch 17; Iter   868/ 1097] train: loss: 0.0225886
[Epoch 17; Iter   898/ 1097] train: loss: 0.1816901
[Epoch 17; Iter   928/ 1097] train: loss: 0.2350323
[Epoch 17; Iter   958/ 1097] train: loss: 0.1808592
[Epoch 17; Iter   988/ 1097] train: loss: 0.0621218
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0661633
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0321215
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2817588
[Epoch 17] ogbg-molhiv: 0.727890 val loss: 0.548508
[Epoch 17] ogbg-molhiv: 0.694050 test loss: 0.748448
[Epoch 18; Iter    11/ 1097] train: loss: 0.1586619
[Epoch 18; Iter    41/ 1097] train: loss: 0.2015786
[Epoch 18; Iter    71/ 1097] train: loss: 0.0843863
[Epoch 18; Iter   101/ 1097] train: loss: 0.1270781
[Epoch 18; Iter   131/ 1097] train: loss: 0.0876755
[Epoch 18; Iter   161/ 1097] train: loss: 0.0388496
[Epoch 18; Iter   191/ 1097] train: loss: 0.1292051
[Epoch 18; Iter   221/ 1097] train: loss: 0.1532628
[Epoch 18; Iter   251/ 1097] train: loss: 0.1256682
[Epoch 18; Iter   281/ 1097] train: loss: 0.0227724
[Epoch 18; Iter   311/ 1097] train: loss: 0.1297634
[Epoch 18; Iter   341/ 1097] train: loss: 0.0480700
[Epoch 18; Iter   371/ 1097] train: loss: 0.0337607
[Epoch 18; Iter   401/ 1097] train: loss: 0.3467443
[Epoch 18; Iter   431/ 1097] train: loss: 0.2000058
[Epoch 18; Iter   461/ 1097] train: loss: 0.0350941
[Epoch 18; Iter   491/ 1097] train: loss: 0.2800912
[Epoch 18; Iter   521/ 1097] train: loss: 0.2587621
[Epoch 18; Iter   551/ 1097] train: loss: 0.0342675
[Epoch 18; Iter   581/ 1097] train: loss: 0.0673521
[Epoch 18; Iter   611/ 1097] train: loss: 0.0317737
[Epoch 18; Iter   641/ 1097] train: loss: 0.2530830
[Epoch 18; Iter   671/ 1097] train: loss: 0.1272181
[Epoch 18; Iter   701/ 1097] train: loss: 0.2009146
[Epoch 18; Iter   731/ 1097] train: loss: 0.1282381
[Epoch 18; Iter   761/ 1097] train: loss: 0.2764609
[Epoch 18; Iter   791/ 1097] train: loss: 0.0443641
[Epoch 18; Iter   821/ 1097] train: loss: 0.1688611
[Epoch 18; Iter   851/ 1097] train: loss: 0.1248231
[Epoch 18; Iter   881/ 1097] train: loss: 0.0945042
[Epoch 18; Iter   911/ 1097] train: loss: 0.1728567
[Epoch 18; Iter   941/ 1097] train: loss: 0.0282986
[Epoch 18; Iter   971/ 1097] train: loss: 0.0737236
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0250641
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0947800
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0310513
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0827654
[Epoch 18] ogbg-molhiv: 0.732764 val loss: 0.426812
[Epoch 18] ogbg-molhiv: 0.692928 test loss: 0.517881
[Epoch 19; Iter    24/ 1097] train: loss: 0.2737677
[Epoch 19; Iter    54/ 1097] train: loss: 0.1033717
[Epoch 19; Iter    84/ 1097] train: loss: 0.3332827
[Epoch 19; Iter   114/ 1097] train: loss: 0.0256657
[Epoch 19; Iter   144/ 1097] train: loss: 0.1989382
[Epoch 19; Iter   174/ 1097] train: loss: 0.0887725
[Epoch 19; Iter   204/ 1097] train: loss: 0.0348519
[Epoch 19; Iter   234/ 1097] train: loss: 0.0286751
[Epoch 19; Iter   264/ 1097] train: loss: 0.1572741
[Epoch 19; Iter   294/ 1097] train: loss: 0.0746854
[Epoch 19; Iter   324/ 1097] train: loss: 0.0403949
[Epoch 19; Iter   354/ 1097] train: loss: 0.2123590
[Epoch 19; Iter   384/ 1097] train: loss: 0.0365652
[Epoch 19; Iter   414/ 1097] train: loss: 0.0204802
[Epoch 19; Iter   444/ 1097] train: loss: 0.1973496
[Epoch 19; Iter   474/ 1097] train: loss: 0.1622600
[Epoch 19; Iter   504/ 1097] train: loss: 0.1543734
[Epoch 19; Iter   534/ 1097] train: loss: 0.1679859
[Epoch 19; Iter   564/ 1097] train: loss: 0.0296304
[Epoch 19; Iter   594/ 1097] train: loss: 0.0290662
[Epoch 19; Iter   624/ 1097] train: loss: 0.1227461
[Epoch 19; Iter   654/ 1097] train: loss: 0.1112234
[Epoch 19; Iter   684/ 1097] train: loss: 0.0525288
[Epoch 19; Iter   714/ 1097] train: loss: 0.0994229
[Epoch 19; Iter   744/ 1097] train: loss: 0.0279438
[Epoch 19; Iter   774/ 1097] train: loss: 0.1937319
[Epoch 19; Iter   804/ 1097] train: loss: 0.0880222
[Epoch 19; Iter   834/ 1097] train: loss: 0.2867535
[Epoch 19; Iter   864/ 1097] train: loss: 0.3121454
[Epoch 19; Iter   894/ 1097] train: loss: 0.2036738
[Epoch 19; Iter   924/ 1097] train: loss: 0.4137874
[Epoch 19; Iter   954/ 1097] train: loss: 0.1140656
[Epoch 19; Iter   984/ 1097] train: loss: 0.3335664
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1577706
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0613513
[Epoch 19; Iter  1074/ 1097] train: loss: 0.1638540
[Epoch 19] ogbg-molhiv: 0.751231 val loss: 0.227911
[Epoch 19] ogbg-molhiv: 0.623764 test loss: 0.140425
[Epoch 20; Iter     7/ 1097] train: loss: 0.0770189
[Epoch 20; Iter    37/ 1097] train: loss: 0.2414046
[Epoch 20; Iter    67/ 1097] train: loss: 0.0774408
[Epoch 20; Iter    97/ 1097] train: loss: 0.0254896
[Epoch 20; Iter   127/ 1097] train: loss: 0.0284113
[Epoch 20; Iter   157/ 1097] train: loss: 0.0744187
[Epoch 20; Iter   187/ 1097] train: loss: 0.0524050
[Epoch 20; Iter   217/ 1097] train: loss: 0.0352251
[Epoch 20; Iter   247/ 1097] train: loss: 0.1369257
[Epoch 20; Iter   277/ 1097] train: loss: 0.1648183
[Epoch 16; Iter   225/ 1097] train: loss: 0.1810106
[Epoch 16; Iter   255/ 1097] train: loss: 0.0840761
[Epoch 16; Iter   285/ 1097] train: loss: 0.1580072
[Epoch 16; Iter   315/ 1097] train: loss: 0.0387657
[Epoch 16; Iter   345/ 1097] train: loss: 0.1699082
[Epoch 16; Iter   375/ 1097] train: loss: 0.1033683
[Epoch 16; Iter   405/ 1097] train: loss: 0.0251455
[Epoch 16; Iter   435/ 1097] train: loss: 0.4414364
[Epoch 16; Iter   465/ 1097] train: loss: 0.0476535
[Epoch 16; Iter   495/ 1097] train: loss: 0.0275293
[Epoch 16; Iter   525/ 1097] train: loss: 0.1782279
[Epoch 16; Iter   555/ 1097] train: loss: 0.0215119
[Epoch 16; Iter   585/ 1097] train: loss: 0.2293548
[Epoch 16; Iter   615/ 1097] train: loss: 0.0751121
[Epoch 16; Iter   645/ 1097] train: loss: 0.0689422
[Epoch 16; Iter   675/ 1097] train: loss: 0.0433906
[Epoch 16; Iter   705/ 1097] train: loss: 0.0387716
[Epoch 16; Iter   735/ 1097] train: loss: 0.3471978
[Epoch 16; Iter   765/ 1097] train: loss: 0.0248297
[Epoch 16; Iter   795/ 1097] train: loss: 0.0398351
[Epoch 16; Iter   825/ 1097] train: loss: 0.2695087
[Epoch 16; Iter   855/ 1097] train: loss: 0.1751651
[Epoch 16; Iter   885/ 1097] train: loss: 0.0215676
[Epoch 16; Iter   915/ 1097] train: loss: 0.0548779
[Epoch 16; Iter   945/ 1097] train: loss: 0.1451414
[Epoch 16; Iter   975/ 1097] train: loss: 0.1920796
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2452298
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0518059
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1802547
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1549170
[Epoch 16] ogbg-molhiv: 0.749011 val loss: 0.098673
[Epoch 16] ogbg-molhiv: 0.753643 test loss: 0.123940
[Epoch 17; Iter    28/ 1097] train: loss: 0.2560306
[Epoch 17; Iter    58/ 1097] train: loss: 0.0477158
[Epoch 17; Iter    88/ 1097] train: loss: 0.1416501
[Epoch 17; Iter   118/ 1097] train: loss: 0.1343221
[Epoch 17; Iter   148/ 1097] train: loss: 0.0238752
[Epoch 17; Iter   178/ 1097] train: loss: 0.2017000
[Epoch 17; Iter   208/ 1097] train: loss: 0.0249352
[Epoch 17; Iter   238/ 1097] train: loss: 0.2338932
[Epoch 17; Iter   268/ 1097] train: loss: 0.0607040
[Epoch 17; Iter   298/ 1097] train: loss: 0.1861655
[Epoch 17; Iter   328/ 1097] train: loss: 0.2494278
[Epoch 17; Iter   358/ 1097] train: loss: 0.0295828
[Epoch 17; Iter   388/ 1097] train: loss: 0.1378893
[Epoch 17; Iter   418/ 1097] train: loss: 0.1621025
[Epoch 17; Iter   448/ 1097] train: loss: 0.0353194
[Epoch 17; Iter   478/ 1097] train: loss: 0.0389005
[Epoch 17; Iter   508/ 1097] train: loss: 0.0628240
[Epoch 17; Iter   538/ 1097] train: loss: 0.0415814
[Epoch 17; Iter   568/ 1097] train: loss: 0.2447100
[Epoch 17; Iter   598/ 1097] train: loss: 0.0307578
[Epoch 17; Iter   628/ 1097] train: loss: 0.1824117
[Epoch 17; Iter   658/ 1097] train: loss: 0.0829686
[Epoch 17; Iter   688/ 1097] train: loss: 0.0503459
[Epoch 17; Iter   718/ 1097] train: loss: 0.1415100
[Epoch 17; Iter   748/ 1097] train: loss: 0.0238713
[Epoch 17; Iter   778/ 1097] train: loss: 0.2093990
[Epoch 17; Iter   808/ 1097] train: loss: 0.0307993
[Epoch 17; Iter   838/ 1097] train: loss: 0.0245483
[Epoch 17; Iter   868/ 1097] train: loss: 0.0337998
[Epoch 17; Iter   898/ 1097] train: loss: 0.0500577
[Epoch 17; Iter   928/ 1097] train: loss: 0.3375027
[Epoch 17; Iter   958/ 1097] train: loss: 0.1791064
[Epoch 17; Iter   988/ 1097] train: loss: 0.0416349
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0409125
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0394656
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1563053
[Epoch 17] ogbg-molhiv: 0.745707 val loss: 0.080429
[Epoch 17] ogbg-molhiv: 0.738340 test loss: 0.194656
[Epoch 18; Iter    11/ 1097] train: loss: 0.1388081
[Epoch 18; Iter    41/ 1097] train: loss: 0.0394188
[Epoch 18; Iter    71/ 1097] train: loss: 0.1533543
[Epoch 18; Iter   101/ 1097] train: loss: 0.0234275
[Epoch 18; Iter   131/ 1097] train: loss: 0.1516441
[Epoch 18; Iter   161/ 1097] train: loss: 0.2034871
[Epoch 18; Iter   191/ 1097] train: loss: 0.0580933
[Epoch 18; Iter   221/ 1097] train: loss: 0.0405443
[Epoch 18; Iter   251/ 1097] train: loss: 0.0620884
[Epoch 18; Iter   281/ 1097] train: loss: 0.0309119
[Epoch 18; Iter   311/ 1097] train: loss: 0.3464504
[Epoch 18; Iter   341/ 1097] train: loss: 0.1601790
[Epoch 18; Iter   371/ 1097] train: loss: 0.0470622
[Epoch 18; Iter   401/ 1097] train: loss: 0.0252940
[Epoch 18; Iter   431/ 1097] train: loss: 0.0513176
[Epoch 18; Iter   461/ 1097] train: loss: 0.0409003
[Epoch 18; Iter   491/ 1097] train: loss: 0.1265459
[Epoch 18; Iter   521/ 1097] train: loss: 0.0489830
[Epoch 18; Iter   551/ 1097] train: loss: 0.1039332
[Epoch 18; Iter   581/ 1097] train: loss: 0.0280449
[Epoch 18; Iter   611/ 1097] train: loss: 0.1744010
[Epoch 18; Iter   641/ 1097] train: loss: 0.1154694
[Epoch 18; Iter   671/ 1097] train: loss: 0.1121878
[Epoch 18; Iter   701/ 1097] train: loss: 0.1592238
[Epoch 18; Iter   731/ 1097] train: loss: 0.1800058
[Epoch 18; Iter   761/ 1097] train: loss: 0.0865182
[Epoch 18; Iter   791/ 1097] train: loss: 0.0763015
[Epoch 18; Iter   821/ 1097] train: loss: 0.0673507
[Epoch 18; Iter   851/ 1097] train: loss: 0.2489463
[Epoch 18; Iter   881/ 1097] train: loss: 0.0215629
[Epoch 18; Iter   911/ 1097] train: loss: 0.0593678
[Epoch 18; Iter   941/ 1097] train: loss: 0.0276116
[Epoch 18; Iter   971/ 1097] train: loss: 0.0421982
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1124446
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0265999
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0329497
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0353829
[Epoch 18] ogbg-molhiv: 0.721849 val loss: 0.089102
[Epoch 18] ogbg-molhiv: 0.739748 test loss: 0.194973
[Epoch 19; Iter    24/ 1097] train: loss: 0.1170084
[Epoch 19; Iter    54/ 1097] train: loss: 0.1221269
[Epoch 19; Iter    84/ 1097] train: loss: 0.0291417
[Epoch 19; Iter   114/ 1097] train: loss: 0.0956156
[Epoch 19; Iter   144/ 1097] train: loss: 0.1858568
[Epoch 19; Iter   174/ 1097] train: loss: 0.1222612
[Epoch 19; Iter   204/ 1097] train: loss: 0.1098760
[Epoch 19; Iter   234/ 1097] train: loss: 0.1236150
[Epoch 19; Iter   264/ 1097] train: loss: 0.2311419
[Epoch 19; Iter   294/ 1097] train: loss: 0.1476789
[Epoch 19; Iter   324/ 1097] train: loss: 0.2425800
[Epoch 19; Iter   354/ 1097] train: loss: 0.0349962
[Epoch 19; Iter   384/ 1097] train: loss: 0.2039195
[Epoch 19; Iter   414/ 1097] train: loss: 0.1606647
[Epoch 19; Iter   444/ 1097] train: loss: 0.1231175
[Epoch 19; Iter   474/ 1097] train: loss: 0.0207819
[Epoch 19; Iter   504/ 1097] train: loss: 0.0738679
[Epoch 19; Iter   534/ 1097] train: loss: 0.2948224
[Epoch 19; Iter   564/ 1097] train: loss: 0.2246269
[Epoch 19; Iter   594/ 1097] train: loss: 0.0392290
[Epoch 19; Iter   624/ 1097] train: loss: 0.0433818
[Epoch 19; Iter   654/ 1097] train: loss: 0.2168372
[Epoch 19; Iter   684/ 1097] train: loss: 0.1019991
[Epoch 19; Iter   714/ 1097] train: loss: 0.1297564
[Epoch 19; Iter   744/ 1097] train: loss: 0.1710452
[Epoch 19; Iter   774/ 1097] train: loss: 0.1411906
[Epoch 19; Iter   804/ 1097] train: loss: 0.0287635
[Epoch 19; Iter   834/ 1097] train: loss: 0.1554424
[Epoch 19; Iter   864/ 1097] train: loss: 0.1785938
[Epoch 19; Iter   894/ 1097] train: loss: 0.0452785
[Epoch 19; Iter   924/ 1097] train: loss: 0.1752800
[Epoch 19; Iter   954/ 1097] train: loss: 0.2131649
[Epoch 19; Iter   984/ 1097] train: loss: 0.0379782
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2006005
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0757662
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0272879
[Epoch 19] ogbg-molhiv: 0.707305 val loss: 0.084349
[Epoch 19] ogbg-molhiv: 0.731965 test loss: 0.201736
[Epoch 20; Iter     7/ 1097] train: loss: 0.1097698
[Epoch 20; Iter    37/ 1097] train: loss: 0.2370078
[Epoch 20; Iter    67/ 1097] train: loss: 0.0276798
[Epoch 20; Iter    97/ 1097] train: loss: 0.1510738
[Epoch 20; Iter   127/ 1097] train: loss: 0.2667215
[Epoch 20; Iter   157/ 1097] train: loss: 0.0335662
[Epoch 20; Iter   187/ 1097] train: loss: 0.0646158
[Epoch 20; Iter   217/ 1097] train: loss: 0.0205733
[Epoch 20; Iter   247/ 1097] train: loss: 0.0628111
[Epoch 20; Iter   277/ 1097] train: loss: 0.1863982
[Epoch 16; Iter   225/ 1097] train: loss: 0.0909102
[Epoch 16; Iter   255/ 1097] train: loss: 0.2251528
[Epoch 16; Iter   285/ 1097] train: loss: 0.0331136
[Epoch 16; Iter   315/ 1097] train: loss: 0.0444549
[Epoch 16; Iter   345/ 1097] train: loss: 0.0971289
[Epoch 16; Iter   375/ 1097] train: loss: 0.0735674
[Epoch 16; Iter   405/ 1097] train: loss: 0.0282343
[Epoch 16; Iter   435/ 1097] train: loss: 0.0776556
[Epoch 16; Iter   465/ 1097] train: loss: 0.1883137
[Epoch 16; Iter   495/ 1097] train: loss: 0.0589263
[Epoch 16; Iter   525/ 1097] train: loss: 0.0365449
[Epoch 16; Iter   555/ 1097] train: loss: 0.4837609
[Epoch 16; Iter   585/ 1097] train: loss: 0.0455081
[Epoch 16; Iter   615/ 1097] train: loss: 0.1859095
[Epoch 16; Iter   645/ 1097] train: loss: 0.0888836
[Epoch 16; Iter   675/ 1097] train: loss: 0.1410895
[Epoch 16; Iter   705/ 1097] train: loss: 0.0323821
[Epoch 16; Iter   735/ 1097] train: loss: 0.2177476
[Epoch 16; Iter   765/ 1097] train: loss: 0.4221572
[Epoch 16; Iter   795/ 1097] train: loss: 0.0539671
[Epoch 16; Iter   825/ 1097] train: loss: 0.0295330
[Epoch 16; Iter   855/ 1097] train: loss: 0.0372182
[Epoch 16; Iter   885/ 1097] train: loss: 0.2295278
[Epoch 16; Iter   915/ 1097] train: loss: 0.1483149
[Epoch 16; Iter   945/ 1097] train: loss: 0.0301119
[Epoch 16; Iter   975/ 1097] train: loss: 0.0228623
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1396526
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0533486
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0299898
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0321504
[Epoch 16] ogbg-molhiv: 0.798994 val loss: 0.271244
[Epoch 16] ogbg-molhiv: 0.775506 test loss: 0.247352
[Epoch 17; Iter    28/ 1097] train: loss: 0.1628100
[Epoch 17; Iter    58/ 1097] train: loss: 0.1857541
[Epoch 17; Iter    88/ 1097] train: loss: 0.1029724
[Epoch 17; Iter   118/ 1097] train: loss: 0.0286464
[Epoch 17; Iter   148/ 1097] train: loss: 0.0265287
[Epoch 17; Iter   178/ 1097] train: loss: 0.0267499
[Epoch 17; Iter   208/ 1097] train: loss: 0.0258796
[Epoch 17; Iter   238/ 1097] train: loss: 0.0691139
[Epoch 17; Iter   268/ 1097] train: loss: 0.0900915
[Epoch 17; Iter   298/ 1097] train: loss: 0.0433289
[Epoch 17; Iter   328/ 1097] train: loss: 0.2070220
[Epoch 17; Iter   358/ 1097] train: loss: 0.2771621
[Epoch 17; Iter   388/ 1097] train: loss: 0.0332731
[Epoch 17; Iter   418/ 1097] train: loss: 0.0585184
[Epoch 17; Iter   448/ 1097] train: loss: 0.0665179
[Epoch 17; Iter   478/ 1097] train: loss: 0.1843854
[Epoch 17; Iter   508/ 1097] train: loss: 0.0293407
[Epoch 17; Iter   538/ 1097] train: loss: 0.0849654
[Epoch 17; Iter   568/ 1097] train: loss: 0.0335519
[Epoch 17; Iter   598/ 1097] train: loss: 0.0705502
[Epoch 17; Iter   628/ 1097] train: loss: 0.0410381
[Epoch 17; Iter   658/ 1097] train: loss: 0.1957951
[Epoch 17; Iter   688/ 1097] train: loss: 0.0440908
[Epoch 17; Iter   718/ 1097] train: loss: 0.1256155
[Epoch 17; Iter   748/ 1097] train: loss: 0.1820419
[Epoch 17; Iter   778/ 1097] train: loss: 0.0549834
[Epoch 17; Iter   808/ 1097] train: loss: 0.1878138
[Epoch 17; Iter   838/ 1097] train: loss: 0.0685716
[Epoch 17; Iter   868/ 1097] train: loss: 0.0325545
[Epoch 17; Iter   898/ 1097] train: loss: 0.1585248
[Epoch 17; Iter   928/ 1097] train: loss: 0.2437805
[Epoch 17; Iter   958/ 1097] train: loss: 0.0238891
[Epoch 17; Iter   988/ 1097] train: loss: 0.1619965
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0450215
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2682252
[Epoch 17; Iter  1078/ 1097] train: loss: 0.3252003
[Epoch 17] ogbg-molhiv: 0.825954 val loss: 0.962782
[Epoch 17] ogbg-molhiv: 0.748977 test loss: 0.319533
[Epoch 18; Iter    11/ 1097] train: loss: 0.0263158
[Epoch 18; Iter    41/ 1097] train: loss: 0.1842879
[Epoch 18; Iter    71/ 1097] train: loss: 0.2494138
[Epoch 18; Iter   101/ 1097] train: loss: 0.0227716
[Epoch 18; Iter   131/ 1097] train: loss: 0.0853921
[Epoch 18; Iter   161/ 1097] train: loss: 0.2666537
[Epoch 18; Iter   191/ 1097] train: loss: 0.0483731
[Epoch 18; Iter   221/ 1097] train: loss: 0.1193678
[Epoch 18; Iter   251/ 1097] train: loss: 0.0323203
[Epoch 18; Iter   281/ 1097] train: loss: 0.1131716
[Epoch 18; Iter   311/ 1097] train: loss: 0.0362546
[Epoch 18; Iter   341/ 1097] train: loss: 0.0246958
[Epoch 18; Iter   371/ 1097] train: loss: 0.0272583
[Epoch 18; Iter   401/ 1097] train: loss: 0.1825922
[Epoch 18; Iter   431/ 1097] train: loss: 0.0340417
[Epoch 18; Iter   461/ 1097] train: loss: 0.1462900
[Epoch 18; Iter   491/ 1097] train: loss: 0.0240792
[Epoch 18; Iter   521/ 1097] train: loss: 0.2001422
[Epoch 18; Iter   551/ 1097] train: loss: 0.0779436
[Epoch 18; Iter   581/ 1097] train: loss: 0.0513355
[Epoch 18; Iter   611/ 1097] train: loss: 0.0288203
[Epoch 18; Iter   641/ 1097] train: loss: 0.1593665
[Epoch 18; Iter   671/ 1097] train: loss: 0.0418792
[Epoch 18; Iter   701/ 1097] train: loss: 0.0357550
[Epoch 18; Iter   731/ 1097] train: loss: 0.0343611
[Epoch 18; Iter   761/ 1097] train: loss: 0.0449017
[Epoch 18; Iter   791/ 1097] train: loss: 0.0308873
[Epoch 18; Iter   821/ 1097] train: loss: 0.1051819
[Epoch 18; Iter   851/ 1097] train: loss: 0.0289005
[Epoch 18; Iter   881/ 1097] train: loss: 0.1085458
[Epoch 18; Iter   911/ 1097] train: loss: 0.0331179
[Epoch 18; Iter   941/ 1097] train: loss: 0.1174620
[Epoch 18; Iter   971/ 1097] train: loss: 0.0281045
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1439822
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0607072
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0922111
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0273322
[Epoch 18] ogbg-molhiv: 0.823517 val loss: 0.111766
[Epoch 18] ogbg-molhiv: 0.760880 test loss: 0.225068
[Epoch 19; Iter    24/ 1097] train: loss: 0.0248390
[Epoch 19; Iter    54/ 1097] train: loss: 0.2170896
[Epoch 19; Iter    84/ 1097] train: loss: 0.0946212
[Epoch 19; Iter   114/ 1097] train: loss: 0.0253054
[Epoch 19; Iter   144/ 1097] train: loss: 0.0797373
[Epoch 19; Iter   174/ 1097] train: loss: 0.0414894
[Epoch 19; Iter   204/ 1097] train: loss: 0.0608164
[Epoch 19; Iter   234/ 1097] train: loss: 0.0778567
[Epoch 19; Iter   264/ 1097] train: loss: 0.0256434
[Epoch 19; Iter   294/ 1097] train: loss: 0.0380783
[Epoch 19; Iter   324/ 1097] train: loss: 0.0297257
[Epoch 19; Iter   354/ 1097] train: loss: 0.2686986
[Epoch 19; Iter   384/ 1097] train: loss: 0.0384119
[Epoch 19; Iter   414/ 1097] train: loss: 0.1710902
[Epoch 19; Iter   444/ 1097] train: loss: 0.0309088
[Epoch 19; Iter   474/ 1097] train: loss: 0.2997789
[Epoch 19; Iter   504/ 1097] train: loss: 0.0274256
[Epoch 19; Iter   534/ 1097] train: loss: 0.0175681
[Epoch 19; Iter   564/ 1097] train: loss: 0.1792638
[Epoch 19; Iter   594/ 1097] train: loss: 0.1076331
[Epoch 19; Iter   624/ 1097] train: loss: 0.0666126
[Epoch 19; Iter   654/ 1097] train: loss: 0.0230064
[Epoch 19; Iter   684/ 1097] train: loss: 0.4002364
[Epoch 19; Iter   714/ 1097] train: loss: 0.0276047
[Epoch 19; Iter   744/ 1097] train: loss: 0.0905015
[Epoch 19; Iter   774/ 1097] train: loss: 0.0856868
[Epoch 19; Iter   804/ 1097] train: loss: 0.0464431
[Epoch 19; Iter   834/ 1097] train: loss: 0.0223527
[Epoch 19; Iter   864/ 1097] train: loss: 0.0466012
[Epoch 19; Iter   894/ 1097] train: loss: 0.3797917
[Epoch 19; Iter   924/ 1097] train: loss: 0.1195648
[Epoch 19; Iter   954/ 1097] train: loss: 0.0289301
[Epoch 19; Iter   984/ 1097] train: loss: 0.1052256
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1964424
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0378064
[Epoch 19; Iter  1074/ 1097] train: loss: 0.4018948
[Epoch 19] ogbg-molhiv: 0.809842 val loss: 0.205320
[Epoch 19] ogbg-molhiv: 0.713030 test loss: 0.368914
[Epoch 20; Iter     7/ 1097] train: loss: 0.0624168
[Epoch 20; Iter    37/ 1097] train: loss: 0.0684442
[Epoch 20; Iter    67/ 1097] train: loss: 0.0201421
[Epoch 20; Iter    97/ 1097] train: loss: 0.0389045
[Epoch 20; Iter   127/ 1097] train: loss: 0.0377834
[Epoch 20; Iter   157/ 1097] train: loss: 0.0265018
[Epoch 20; Iter   187/ 1097] train: loss: 0.1123136
[Epoch 20; Iter   217/ 1097] train: loss: 0.3624072
[Epoch 20; Iter   247/ 1097] train: loss: 0.0565991
[Epoch 20; Iter   277/ 1097] train: loss: 0.0198986
[Epoch 16; Iter   225/ 1097] train: loss: 0.0321746
[Epoch 16; Iter   255/ 1097] train: loss: 0.0290689
[Epoch 16; Iter   285/ 1097] train: loss: 0.1545494
[Epoch 16; Iter   315/ 1097] train: loss: 0.0544070
[Epoch 16; Iter   345/ 1097] train: loss: 0.0578287
[Epoch 16; Iter   375/ 1097] train: loss: 0.1770975
[Epoch 16; Iter   405/ 1097] train: loss: 0.1690091
[Epoch 16; Iter   435/ 1097] train: loss: 0.1237445
[Epoch 16; Iter   465/ 1097] train: loss: 0.1538676
[Epoch 16; Iter   495/ 1097] train: loss: 0.0609530
[Epoch 16; Iter   525/ 1097] train: loss: 0.1470502
[Epoch 16; Iter   555/ 1097] train: loss: 0.0262647
[Epoch 16; Iter   585/ 1097] train: loss: 0.0478310
[Epoch 16; Iter   615/ 1097] train: loss: 0.0357469
[Epoch 16; Iter   645/ 1097] train: loss: 0.0396659
[Epoch 16; Iter   675/ 1097] train: loss: 0.1565046
[Epoch 16; Iter   705/ 1097] train: loss: 0.1901444
[Epoch 16; Iter   735/ 1097] train: loss: 0.0831341
[Epoch 16; Iter   765/ 1097] train: loss: 0.0363618
[Epoch 16; Iter   795/ 1097] train: loss: 0.1411643
[Epoch 16; Iter   825/ 1097] train: loss: 0.0296772
[Epoch 16; Iter   855/ 1097] train: loss: 0.1082203
[Epoch 16; Iter   885/ 1097] train: loss: 0.2523567
[Epoch 16; Iter   915/ 1097] train: loss: 0.0255653
[Epoch 16; Iter   945/ 1097] train: loss: 0.0262498
[Epoch 16; Iter   975/ 1097] train: loss: 0.0235821
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0373001
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0216401
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1437625
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0519278
[Epoch 16] ogbg-molhiv: 0.769260 val loss: 0.083132
[Epoch 16] ogbg-molhiv: 0.754570 test loss: 0.118560
[Epoch 17; Iter    28/ 1097] train: loss: 0.0329060
[Epoch 17; Iter    58/ 1097] train: loss: 0.0376305
[Epoch 17; Iter    88/ 1097] train: loss: 0.0178199
[Epoch 17; Iter   118/ 1097] train: loss: 0.1644384
[Epoch 17; Iter   148/ 1097] train: loss: 0.1271928
[Epoch 17; Iter   178/ 1097] train: loss: 0.0633316
[Epoch 17; Iter   208/ 1097] train: loss: 0.0241055
[Epoch 17; Iter   238/ 1097] train: loss: 0.2099025
[Epoch 17; Iter   268/ 1097] train: loss: 0.0304281
[Epoch 17; Iter   298/ 1097] train: loss: 0.0382947
[Epoch 17; Iter   328/ 1097] train: loss: 0.0249311
[Epoch 17; Iter   358/ 1097] train: loss: 0.0245160
[Epoch 17; Iter   388/ 1097] train: loss: 0.0330934
[Epoch 17; Iter   418/ 1097] train: loss: 0.1104297
[Epoch 17; Iter   448/ 1097] train: loss: 0.0205551
[Epoch 17; Iter   478/ 1097] train: loss: 0.0392255
[Epoch 17; Iter   508/ 1097] train: loss: 0.0492864
[Epoch 17; Iter   538/ 1097] train: loss: 0.3062733
[Epoch 17; Iter   568/ 1097] train: loss: 0.2261782
[Epoch 17; Iter   598/ 1097] train: loss: 0.1369033
[Epoch 17; Iter   628/ 1097] train: loss: 0.0653475
[Epoch 17; Iter   658/ 1097] train: loss: 0.0319173
[Epoch 17; Iter   688/ 1097] train: loss: 0.2338794
[Epoch 17; Iter   718/ 1097] train: loss: 0.0514536
[Epoch 17; Iter   748/ 1097] train: loss: 0.1632596
[Epoch 17; Iter   778/ 1097] train: loss: 0.0734155
[Epoch 17; Iter   808/ 1097] train: loss: 0.0999594
[Epoch 17; Iter   838/ 1097] train: loss: 0.0410956
[Epoch 17; Iter   868/ 1097] train: loss: 0.0205741
[Epoch 17; Iter   898/ 1097] train: loss: 0.1794077
[Epoch 17; Iter   928/ 1097] train: loss: 0.2364720
[Epoch 17; Iter   958/ 1097] train: loss: 0.1482346
[Epoch 17; Iter   988/ 1097] train: loss: 0.0310172
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0299174
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0266376
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1871610
[Epoch 17] ogbg-molhiv: 0.764899 val loss: 0.077882
[Epoch 17] ogbg-molhiv: 0.733960 test loss: 0.124306
[Epoch 18; Iter    11/ 1097] train: loss: 0.1386236
[Epoch 18; Iter    41/ 1097] train: loss: 0.2345475
[Epoch 18; Iter    71/ 1097] train: loss: 0.0821346
[Epoch 18; Iter   101/ 1097] train: loss: 0.1220617
[Epoch 18; Iter   131/ 1097] train: loss: 0.1209502
[Epoch 18; Iter   161/ 1097] train: loss: 0.0408310
[Epoch 18; Iter   191/ 1097] train: loss: 0.1447209
[Epoch 18; Iter   221/ 1097] train: loss: 0.1755297
[Epoch 18; Iter   251/ 1097] train: loss: 0.1334917
[Epoch 18; Iter   281/ 1097] train: loss: 0.0190154
[Epoch 18; Iter   311/ 1097] train: loss: 0.1633922
[Epoch 18; Iter   341/ 1097] train: loss: 0.0739612
[Epoch 18; Iter   371/ 1097] train: loss: 0.0708201
[Epoch 18; Iter   401/ 1097] train: loss: 0.1408400
[Epoch 18; Iter   431/ 1097] train: loss: 0.2121653
[Epoch 18; Iter   461/ 1097] train: loss: 0.0445160
[Epoch 18; Iter   491/ 1097] train: loss: 0.2126082
[Epoch 18; Iter   521/ 1097] train: loss: 0.2974404
[Epoch 18; Iter   551/ 1097] train: loss: 0.0416237
[Epoch 18; Iter   581/ 1097] train: loss: 0.0333479
[Epoch 18; Iter   611/ 1097] train: loss: 0.0197164
[Epoch 18; Iter   641/ 1097] train: loss: 0.1743431
[Epoch 18; Iter   671/ 1097] train: loss: 0.0322933
[Epoch 18; Iter   701/ 1097] train: loss: 0.2775362
[Epoch 18; Iter   731/ 1097] train: loss: 0.1398287
[Epoch 18; Iter   761/ 1097] train: loss: 0.2870038
[Epoch 18; Iter   791/ 1097] train: loss: 0.0739027
[Epoch 18; Iter   821/ 1097] train: loss: 0.0823142
[Epoch 18; Iter   851/ 1097] train: loss: 0.1907989
[Epoch 18; Iter   881/ 1097] train: loss: 0.1240001
[Epoch 18; Iter   911/ 1097] train: loss: 0.2086201
[Epoch 18; Iter   941/ 1097] train: loss: 0.0192750
[Epoch 18; Iter   971/ 1097] train: loss: 0.1197192
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0329320
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0499785
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0343359
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1155363
[Epoch 18] ogbg-molhiv: 0.743193 val loss: 0.092834
[Epoch 18] ogbg-molhiv: 0.730953 test loss: 0.126077
[Epoch 19; Iter    24/ 1097] train: loss: 0.2347196
[Epoch 19; Iter    54/ 1097] train: loss: 0.1020625
[Epoch 19; Iter    84/ 1097] train: loss: 0.3015066
[Epoch 19; Iter   114/ 1097] train: loss: 0.0272313
[Epoch 19; Iter   144/ 1097] train: loss: 0.1444002
[Epoch 19; Iter   174/ 1097] train: loss: 0.0341997
[Epoch 19; Iter   204/ 1097] train: loss: 0.0250109
[Epoch 19; Iter   234/ 1097] train: loss: 0.0285319
[Epoch 19; Iter   264/ 1097] train: loss: 0.1384277
[Epoch 19; Iter   294/ 1097] train: loss: 0.1260740
[Epoch 19; Iter   324/ 1097] train: loss: 0.0266982
[Epoch 19; Iter   354/ 1097] train: loss: 0.2612220
[Epoch 19; Iter   384/ 1097] train: loss: 0.0260447
[Epoch 19; Iter   414/ 1097] train: loss: 0.0282951
[Epoch 19; Iter   444/ 1097] train: loss: 0.1321113
[Epoch 19; Iter   474/ 1097] train: loss: 0.1344213
[Epoch 19; Iter   504/ 1097] train: loss: 0.2447585
[Epoch 19; Iter   534/ 1097] train: loss: 0.1591261
[Epoch 19; Iter   564/ 1097] train: loss: 0.0186772
[Epoch 19; Iter   594/ 1097] train: loss: 0.0192679
[Epoch 19; Iter   624/ 1097] train: loss: 0.0481342
[Epoch 19; Iter   654/ 1097] train: loss: 0.1303286
[Epoch 19; Iter   684/ 1097] train: loss: 0.0273784
[Epoch 19; Iter   714/ 1097] train: loss: 0.1391539
[Epoch 19; Iter   744/ 1097] train: loss: 0.0261737
[Epoch 19; Iter   774/ 1097] train: loss: 0.2092542
[Epoch 19; Iter   804/ 1097] train: loss: 0.1036195
[Epoch 19; Iter   834/ 1097] train: loss: 0.1400065
[Epoch 19; Iter   864/ 1097] train: loss: 0.2803279
[Epoch 19; Iter   894/ 1097] train: loss: 0.2079961
[Epoch 19; Iter   924/ 1097] train: loss: 0.5260098
[Epoch 19; Iter   954/ 1097] train: loss: 0.1408958
[Epoch 19; Iter   984/ 1097] train: loss: 0.3267741
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1539519
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0352296
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0349742
[Epoch 19] ogbg-molhiv: 0.830991 val loss: 0.074540
[Epoch 19] ogbg-molhiv: 0.754230 test loss: 0.118585
[Epoch 20; Iter     7/ 1097] train: loss: 0.0588088
[Epoch 20; Iter    37/ 1097] train: loss: 0.2735202
[Epoch 20; Iter    67/ 1097] train: loss: 0.0267412
[Epoch 20; Iter    97/ 1097] train: loss: 0.0280425
[Epoch 20; Iter   127/ 1097] train: loss: 0.0295748
[Epoch 20; Iter   157/ 1097] train: loss: 0.0628332
[Epoch 20; Iter   187/ 1097] train: loss: 0.0146359
[Epoch 20; Iter   217/ 1097] train: loss: 0.0234312
[Epoch 20; Iter   247/ 1097] train: loss: 0.0350030
[Epoch 20; Iter   277/ 1097] train: loss: 0.1046953
[Epoch 20; Iter   277/ 1097] train: loss: 0.0994123
[Epoch 20; Iter   307/ 1097] train: loss: 0.1277326
[Epoch 20; Iter   337/ 1097] train: loss: 0.0733646
[Epoch 20; Iter   367/ 1097] train: loss: 0.0653300
[Epoch 20; Iter   397/ 1097] train: loss: 0.0202083
[Epoch 20; Iter   427/ 1097] train: loss: 0.0333555
[Epoch 20; Iter   457/ 1097] train: loss: 0.1203215
[Epoch 20; Iter   487/ 1097] train: loss: 0.1364183
[Epoch 20; Iter   517/ 1097] train: loss: 0.0326115
[Epoch 20; Iter   547/ 1097] train: loss: 0.2113940
[Epoch 20; Iter   577/ 1097] train: loss: 0.0151692
[Epoch 20; Iter   607/ 1097] train: loss: 0.0177423
[Epoch 20; Iter   637/ 1097] train: loss: 0.0144155
[Epoch 20; Iter   667/ 1097] train: loss: 0.2649897
[Epoch 20; Iter   697/ 1097] train: loss: 0.0692805
[Epoch 20; Iter   727/ 1097] train: loss: 0.0735108
[Epoch 20; Iter   757/ 1097] train: loss: 0.0245174
[Epoch 20; Iter   787/ 1097] train: loss: 0.0227518
[Epoch 20; Iter   817/ 1097] train: loss: 0.0819757
[Epoch 20; Iter   847/ 1097] train: loss: 0.0436692
[Epoch 20; Iter   877/ 1097] train: loss: 0.1477499
[Epoch 20; Iter   907/ 1097] train: loss: 0.2381208
[Epoch 20; Iter   937/ 1097] train: loss: 0.0163169
[Epoch 20; Iter   967/ 1097] train: loss: 0.0899394
[Epoch 20; Iter   997/ 1097] train: loss: 0.1044335
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0338964
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0250553
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0562635
[Epoch 20] ogbg-molhiv: 0.818410 val loss: 2.887763
[Epoch 20] ogbg-molhiv: 0.753188 test loss: 0.623577
[Epoch 21; Iter    20/ 1097] train: loss: 0.0205295
[Epoch 21; Iter    50/ 1097] train: loss: 0.1582345
[Epoch 21; Iter    80/ 1097] train: loss: 0.0208585
[Epoch 21; Iter   110/ 1097] train: loss: 0.0429797
[Epoch 21; Iter   140/ 1097] train: loss: 0.0570471
[Epoch 21; Iter   170/ 1097] train: loss: 0.0850876
[Epoch 21; Iter   200/ 1097] train: loss: 0.1144216
[Epoch 21; Iter   230/ 1097] train: loss: 0.2158929
[Epoch 21; Iter   260/ 1097] train: loss: 0.1040215
[Epoch 21; Iter   290/ 1097] train: loss: 0.2323792
[Epoch 21; Iter   320/ 1097] train: loss: 0.1357020
[Epoch 21; Iter   350/ 1097] train: loss: 0.0299727
[Epoch 21; Iter   380/ 1097] train: loss: 0.0407269
[Epoch 21; Iter   410/ 1097] train: loss: 0.0197501
[Epoch 21; Iter   440/ 1097] train: loss: 0.1482420
[Epoch 21; Iter   470/ 1097] train: loss: 0.1509183
[Epoch 21; Iter   500/ 1097] train: loss: 0.0228650
[Epoch 21; Iter   530/ 1097] train: loss: 0.0237887
[Epoch 21; Iter   560/ 1097] train: loss: 0.0400816
[Epoch 21; Iter   590/ 1097] train: loss: 0.1344961
[Epoch 21; Iter   620/ 1097] train: loss: 0.0977164
[Epoch 21; Iter   650/ 1097] train: loss: 0.3195263
[Epoch 21; Iter   680/ 1097] train: loss: 0.0460452
[Epoch 21; Iter   710/ 1097] train: loss: 0.0463376
[Epoch 21; Iter   740/ 1097] train: loss: 0.0345431
[Epoch 21; Iter   770/ 1097] train: loss: 0.0565816
[Epoch 21; Iter   800/ 1097] train: loss: 0.0301627
[Epoch 21; Iter   830/ 1097] train: loss: 0.2295232
[Epoch 21; Iter   860/ 1097] train: loss: 0.0743800
[Epoch 21; Iter   890/ 1097] train: loss: 0.0260025
[Epoch 21; Iter   920/ 1097] train: loss: 0.0829506
[Epoch 21; Iter   950/ 1097] train: loss: 0.0461582
[Epoch 21; Iter   980/ 1097] train: loss: 0.0234545
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0246140
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2390568
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0379445
[Epoch 21] ogbg-molhiv: 0.825626 val loss: 0.829845
[Epoch 21] ogbg-molhiv: 0.760250 test loss: 0.454352
[Epoch 22; Iter     3/ 1097] train: loss: 0.1415877
[Epoch 22; Iter    33/ 1097] train: loss: 0.0335602
[Epoch 22; Iter    63/ 1097] train: loss: 0.0364879
[Epoch 22; Iter    93/ 1097] train: loss: 0.0342353
[Epoch 22; Iter   123/ 1097] train: loss: 0.0454227
[Epoch 22; Iter   153/ 1097] train: loss: 0.0235506
[Epoch 22; Iter   183/ 1097] train: loss: 0.1699073
[Epoch 22; Iter   213/ 1097] train: loss: 0.1920442
[Epoch 22; Iter   243/ 1097] train: loss: 0.1030346
[Epoch 22; Iter   273/ 1097] train: loss: 0.1430226
[Epoch 22; Iter   303/ 1097] train: loss: 0.1869934
[Epoch 22; Iter   333/ 1097] train: loss: 0.0346909
[Epoch 22; Iter   363/ 1097] train: loss: 0.0886446
[Epoch 22; Iter   393/ 1097] train: loss: 0.0452974
[Epoch 22; Iter   423/ 1097] train: loss: 0.0437310
[Epoch 22; Iter   453/ 1097] train: loss: 0.0307600
[Epoch 22; Iter   483/ 1097] train: loss: 0.0888581
[Epoch 22; Iter   513/ 1097] train: loss: 0.2581779
[Epoch 22; Iter   543/ 1097] train: loss: 0.1534761
[Epoch 22; Iter   573/ 1097] train: loss: 0.0207121
[Epoch 22; Iter   603/ 1097] train: loss: 0.0264324
[Epoch 22; Iter   633/ 1097] train: loss: 0.0172617
[Epoch 22; Iter   663/ 1097] train: loss: 0.0426458
[Epoch 22; Iter   693/ 1097] train: loss: 0.1941021
[Epoch 22; Iter   723/ 1097] train: loss: 0.1873800
[Epoch 22; Iter   753/ 1097] train: loss: 0.3275467
[Epoch 22; Iter   783/ 1097] train: loss: 0.0223098
[Epoch 22; Iter   813/ 1097] train: loss: 0.1434238
[Epoch 22; Iter   843/ 1097] train: loss: 0.0281048
[Epoch 22; Iter   873/ 1097] train: loss: 0.1147532
[Epoch 22; Iter   903/ 1097] train: loss: 0.2023475
[Epoch 22; Iter   933/ 1097] train: loss: 0.0169718
[Epoch 22; Iter   963/ 1097] train: loss: 0.2995396
[Epoch 22; Iter   993/ 1097] train: loss: 0.1707343
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3756679
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0250376
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0756958
[Epoch 22] ogbg-molhiv: 0.795154 val loss: 0.947135
[Epoch 22] ogbg-molhiv: 0.739922 test loss: 0.237235
[Epoch 23; Iter    16/ 1097] train: loss: 0.0464156
[Epoch 23; Iter    46/ 1097] train: loss: 0.1007813
[Epoch 23; Iter    76/ 1097] train: loss: 0.0344517
[Epoch 23; Iter   106/ 1097] train: loss: 0.1831759
[Epoch 23; Iter   136/ 1097] train: loss: 0.0387919
[Epoch 23; Iter   166/ 1097] train: loss: 0.2007965
[Epoch 23; Iter   196/ 1097] train: loss: 0.1565417
[Epoch 23; Iter   226/ 1097] train: loss: 0.0379824
[Epoch 23; Iter   256/ 1097] train: loss: 0.0899618
[Epoch 23; Iter   286/ 1097] train: loss: 0.0215717
[Epoch 23; Iter   316/ 1097] train: loss: 0.0390339
[Epoch 23; Iter   346/ 1097] train: loss: 0.0212420
[Epoch 23; Iter   376/ 1097] train: loss: 0.0220501
[Epoch 23; Iter   406/ 1097] train: loss: 0.1328712
[Epoch 23; Iter   436/ 1097] train: loss: 0.1482891
[Epoch 23; Iter   466/ 1097] train: loss: 0.0192441
[Epoch 23; Iter   496/ 1097] train: loss: 0.2454855
[Epoch 23; Iter   526/ 1097] train: loss: 0.0649229
[Epoch 23; Iter   556/ 1097] train: loss: 0.0577975
[Epoch 23; Iter   586/ 1097] train: loss: 0.1798425
[Epoch 23; Iter   616/ 1097] train: loss: 0.1116560
[Epoch 23; Iter   646/ 1097] train: loss: 0.0628814
[Epoch 23; Iter   676/ 1097] train: loss: 0.0251341
[Epoch 23; Iter   706/ 1097] train: loss: 0.0288734
[Epoch 23; Iter   736/ 1097] train: loss: 0.1730339
[Epoch 23; Iter   766/ 1097] train: loss: 0.0827595
[Epoch 23; Iter   796/ 1097] train: loss: 0.0152447
[Epoch 23; Iter   826/ 1097] train: loss: 0.2006468
[Epoch 23; Iter   856/ 1097] train: loss: 0.2315426
[Epoch 23; Iter   886/ 1097] train: loss: 0.1106965
[Epoch 23; Iter   916/ 1097] train: loss: 0.3523619
[Epoch 23; Iter   946/ 1097] train: loss: 0.0421197
[Epoch 23; Iter   976/ 1097] train: loss: 0.1821176
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0258469
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0162584
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1024648
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0800430
[Epoch 23] ogbg-molhiv: 0.795295 val loss: 0.367697
[Epoch 23] ogbg-molhiv: 0.738643 test loss: 0.162320
[Epoch 24; Iter    29/ 1097] train: loss: 0.0724632
[Epoch 24; Iter    59/ 1097] train: loss: 0.1789189
[Epoch 24; Iter    89/ 1097] train: loss: 0.2514529
[Epoch 24; Iter   119/ 1097] train: loss: 0.0175043
[Epoch 24; Iter   149/ 1097] train: loss: 0.0280409
[Epoch 24; Iter   179/ 1097] train: loss: 0.0191167
[Epoch 24; Iter   209/ 1097] train: loss: 0.1724219
[Epoch 24; Iter   239/ 1097] train: loss: 0.0157795
[Epoch 24; Iter   269/ 1097] train: loss: 0.3543063
[Epoch 24; Iter   299/ 1097] train: loss: 0.0210847
[Epoch 24; Iter   329/ 1097] train: loss: 0.0306183
[Epoch 20; Iter   277/ 1097] train: loss: 0.0250108
[Epoch 20; Iter   307/ 1097] train: loss: 0.0517872
[Epoch 20; Iter   337/ 1097] train: loss: 0.1984964
[Epoch 20; Iter   367/ 1097] train: loss: 0.3635241
[Epoch 20; Iter   397/ 1097] train: loss: 0.0331452
[Epoch 20; Iter   427/ 1097] train: loss: 0.0849776
[Epoch 20; Iter   457/ 1097] train: loss: 0.0757335
[Epoch 20; Iter   487/ 1097] train: loss: 0.1011127
[Epoch 20; Iter   517/ 1097] train: loss: 0.0696323
[Epoch 20; Iter   547/ 1097] train: loss: 0.2275884
[Epoch 20; Iter   577/ 1097] train: loss: 0.0510441
[Epoch 20; Iter   607/ 1097] train: loss: 0.2372836
[Epoch 20; Iter   637/ 1097] train: loss: 0.0534901
[Epoch 20; Iter   667/ 1097] train: loss: 0.0808401
[Epoch 20; Iter   697/ 1097] train: loss: 0.0155310
[Epoch 20; Iter   727/ 1097] train: loss: 0.0940253
[Epoch 20; Iter   757/ 1097] train: loss: 0.1950650
[Epoch 20; Iter   787/ 1097] train: loss: 0.0352325
[Epoch 20; Iter   817/ 1097] train: loss: 0.2179361
[Epoch 20; Iter   847/ 1097] train: loss: 0.0385442
[Epoch 20; Iter   877/ 1097] train: loss: 0.1332595
[Epoch 20; Iter   907/ 1097] train: loss: 0.0558009
[Epoch 20; Iter   937/ 1097] train: loss: 0.0570391
[Epoch 20; Iter   967/ 1097] train: loss: 0.0424715
[Epoch 20; Iter   997/ 1097] train: loss: 0.1358210
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1146089
[Epoch 20; Iter  1057/ 1097] train: loss: 0.3387688
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2006391
[Epoch 20] ogbg-molhiv: 0.768163 val loss: 0.078276
[Epoch 20] ogbg-molhiv: 0.731217 test loss: 0.127339
[Epoch 21; Iter    20/ 1097] train: loss: 0.0268050
[Epoch 21; Iter    50/ 1097] train: loss: 0.1159967
[Epoch 21; Iter    80/ 1097] train: loss: 0.0531205
[Epoch 21; Iter   110/ 1097] train: loss: 0.0279041
[Epoch 21; Iter   140/ 1097] train: loss: 0.1552138
[Epoch 21; Iter   170/ 1097] train: loss: 0.1666389
[Epoch 21; Iter   200/ 1097] train: loss: 0.0367902
[Epoch 21; Iter   230/ 1097] train: loss: 0.0706026
[Epoch 21; Iter   260/ 1097] train: loss: 0.1133072
[Epoch 21; Iter   290/ 1097] train: loss: 0.0407510
[Epoch 21; Iter   320/ 1097] train: loss: 0.0767671
[Epoch 21; Iter   350/ 1097] train: loss: 0.0661750
[Epoch 21; Iter   380/ 1097] train: loss: 0.0163406
[Epoch 21; Iter   410/ 1097] train: loss: 0.0490862
[Epoch 21; Iter   440/ 1097] train: loss: 0.1666922
[Epoch 21; Iter   470/ 1097] train: loss: 0.0998444
[Epoch 21; Iter   500/ 1097] train: loss: 0.1577971
[Epoch 21; Iter   530/ 1097] train: loss: 0.0459466
[Epoch 21; Iter   560/ 1097] train: loss: 0.0450835
[Epoch 21; Iter   590/ 1097] train: loss: 0.0769661
[Epoch 21; Iter   620/ 1097] train: loss: 0.1195224
[Epoch 21; Iter   650/ 1097] train: loss: 0.0349859
[Epoch 21; Iter   680/ 1097] train: loss: 0.0272761
[Epoch 21; Iter   710/ 1097] train: loss: 0.0206163
[Epoch 21; Iter   740/ 1097] train: loss: 0.0337054
[Epoch 21; Iter   770/ 1097] train: loss: 0.1602736
[Epoch 21; Iter   800/ 1097] train: loss: 0.0362651
[Epoch 21; Iter   830/ 1097] train: loss: 0.0637717
[Epoch 21; Iter   860/ 1097] train: loss: 0.0210352
[Epoch 21; Iter   890/ 1097] train: loss: 0.0236909
[Epoch 21; Iter   920/ 1097] train: loss: 0.1200967
[Epoch 21; Iter   950/ 1097] train: loss: 0.0446058
[Epoch 21; Iter   980/ 1097] train: loss: 0.1747037
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1228097
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0146967
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0215896
[Epoch 21] ogbg-molhiv: 0.767438 val loss: 0.076426
[Epoch 21] ogbg-molhiv: 0.727658 test loss: 0.148731
[Epoch 22; Iter     3/ 1097] train: loss: 0.0923032
[Epoch 22; Iter    33/ 1097] train: loss: 0.2077520
[Epoch 22; Iter    63/ 1097] train: loss: 0.1844280
[Epoch 22; Iter    93/ 1097] train: loss: 0.0480261
[Epoch 22; Iter   123/ 1097] train: loss: 0.1651246
[Epoch 22; Iter   153/ 1097] train: loss: 0.2771372
[Epoch 22; Iter   183/ 1097] train: loss: 0.1382424
[Epoch 22; Iter   213/ 1097] train: loss: 0.0708408
[Epoch 22; Iter   243/ 1097] train: loss: 0.0590118
[Epoch 22; Iter   273/ 1097] train: loss: 0.0205963
[Epoch 22; Iter   303/ 1097] train: loss: 0.0267802
[Epoch 22; Iter   333/ 1097] train: loss: 0.0810625
[Epoch 22; Iter   363/ 1097] train: loss: 0.0615869
[Epoch 22; Iter   393/ 1097] train: loss: 0.1323532
[Epoch 22; Iter   423/ 1097] train: loss: 0.0519031
[Epoch 22; Iter   453/ 1097] train: loss: 0.0722505
[Epoch 22; Iter   483/ 1097] train: loss: 0.2394654
[Epoch 22; Iter   513/ 1097] train: loss: 0.0810138
[Epoch 22; Iter   543/ 1097] train: loss: 0.0326390
[Epoch 22; Iter   573/ 1097] train: loss: 0.0840550
[Epoch 22; Iter   603/ 1097] train: loss: 0.0145469
[Epoch 22; Iter   633/ 1097] train: loss: 0.0572350
[Epoch 22; Iter   663/ 1097] train: loss: 0.1124530
[Epoch 22; Iter   693/ 1097] train: loss: 0.0142295
[Epoch 22; Iter   723/ 1097] train: loss: 0.0468845
[Epoch 22; Iter   753/ 1097] train: loss: 0.1604413
[Epoch 22; Iter   783/ 1097] train: loss: 0.1880689
[Epoch 22; Iter   813/ 1097] train: loss: 0.0204369
[Epoch 22; Iter   843/ 1097] train: loss: 0.0219346
[Epoch 22; Iter   873/ 1097] train: loss: 0.1112182
[Epoch 22; Iter   903/ 1097] train: loss: 0.0229288
[Epoch 22; Iter   933/ 1097] train: loss: 0.0800254
[Epoch 22; Iter   963/ 1097] train: loss: 0.2692015
[Epoch 22; Iter   993/ 1097] train: loss: 0.0531895
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0284445
[Epoch 22; Iter  1053/ 1097] train: loss: 0.2179827
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0203827
[Epoch 22] ogbg-molhiv: 0.763059 val loss: 0.084768
[Epoch 22] ogbg-molhiv: 0.733210 test loss: 0.126162
[Epoch 23; Iter    16/ 1097] train: loss: 0.0154176
[Epoch 23; Iter    46/ 1097] train: loss: 0.0603516
[Epoch 23; Iter    76/ 1097] train: loss: 0.0385583
[Epoch 23; Iter   106/ 1097] train: loss: 0.0162068
[Epoch 23; Iter   136/ 1097] train: loss: 0.1127450
[Epoch 23; Iter   166/ 1097] train: loss: 0.0479851
[Epoch 23; Iter   196/ 1097] train: loss: 0.2365488
[Epoch 23; Iter   226/ 1097] train: loss: 0.0812988
[Epoch 23; Iter   256/ 1097] train: loss: 0.0513616
[Epoch 23; Iter   286/ 1097] train: loss: 0.0771622
[Epoch 23; Iter   316/ 1097] train: loss: 0.3567163
[Epoch 23; Iter   346/ 1097] train: loss: 0.1242774
[Epoch 23; Iter   376/ 1097] train: loss: 0.1977518
[Epoch 23; Iter   406/ 1097] train: loss: 0.0302617
[Epoch 23; Iter   436/ 1097] train: loss: 0.1359105
[Epoch 23; Iter   466/ 1097] train: loss: 0.1277493
[Epoch 23; Iter   496/ 1097] train: loss: 0.1171112
[Epoch 23; Iter   526/ 1097] train: loss: 0.0261201
[Epoch 23; Iter   556/ 1097] train: loss: 0.1538105
[Epoch 23; Iter   586/ 1097] train: loss: 0.0146041
[Epoch 23; Iter   616/ 1097] train: loss: 0.0322337
[Epoch 23; Iter   646/ 1097] train: loss: 0.0196053
[Epoch 23; Iter   676/ 1097] train: loss: 0.0671456
[Epoch 23; Iter   706/ 1097] train: loss: 0.0608015
[Epoch 23; Iter   736/ 1097] train: loss: 0.1238204
[Epoch 23; Iter   766/ 1097] train: loss: 0.0301959
[Epoch 23; Iter   796/ 1097] train: loss: 0.2431408
[Epoch 23; Iter   826/ 1097] train: loss: 0.0983207
[Epoch 23; Iter   856/ 1097] train: loss: 0.1321095
[Epoch 23; Iter   886/ 1097] train: loss: 0.1547873
[Epoch 23; Iter   916/ 1097] train: loss: 0.0318451
[Epoch 23; Iter   946/ 1097] train: loss: 0.2729112
[Epoch 23; Iter   976/ 1097] train: loss: 0.0243819
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1542899
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0482608
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2055584
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0142521
[Epoch 23] ogbg-molhiv: 0.763298 val loss: 0.077937
[Epoch 23] ogbg-molhiv: 0.688669 test loss: 0.140524
[Epoch 24; Iter    29/ 1097] train: loss: 0.0452908
[Epoch 24; Iter    59/ 1097] train: loss: 0.1086335
[Epoch 24; Iter    89/ 1097] train: loss: 0.0195384
[Epoch 24; Iter   119/ 1097] train: loss: 0.0549425
[Epoch 24; Iter   149/ 1097] train: loss: 0.1028170
[Epoch 24; Iter   179/ 1097] train: loss: 0.0348897
[Epoch 24; Iter   209/ 1097] train: loss: 0.0177520
[Epoch 24; Iter   239/ 1097] train: loss: 0.1234894
[Epoch 24; Iter   269/ 1097] train: loss: 0.0254563
[Epoch 24; Iter   299/ 1097] train: loss: 0.1025877
[Epoch 24; Iter   329/ 1097] train: loss: 0.0638503
[Epoch 20; Iter   277/ 1097] train: loss: 0.0660790
[Epoch 20; Iter   307/ 1097] train: loss: 0.0785116
[Epoch 20; Iter   337/ 1097] train: loss: 0.0656125
[Epoch 20; Iter   367/ 1097] train: loss: 0.0581351
[Epoch 20; Iter   397/ 1097] train: loss: 0.0301838
[Epoch 20; Iter   427/ 1097] train: loss: 0.3541409
[Epoch 20; Iter   457/ 1097] train: loss: 0.0886324
[Epoch 20; Iter   487/ 1097] train: loss: 0.0538251
[Epoch 20; Iter   517/ 1097] train: loss: 0.0490809
[Epoch 20; Iter   547/ 1097] train: loss: 0.0327520
[Epoch 20; Iter   577/ 1097] train: loss: 0.0184834
[Epoch 20; Iter   607/ 1097] train: loss: 0.0329368
[Epoch 20; Iter   637/ 1097] train: loss: 0.1750459
[Epoch 20; Iter   667/ 1097] train: loss: 0.3325335
[Epoch 20; Iter   697/ 1097] train: loss: 0.0188822
[Epoch 20; Iter   727/ 1097] train: loss: 0.0315895
[Epoch 20; Iter   757/ 1097] train: loss: 0.1826516
[Epoch 20; Iter   787/ 1097] train: loss: 0.0343968
[Epoch 20; Iter   817/ 1097] train: loss: 0.0168027
[Epoch 20; Iter   847/ 1097] train: loss: 0.1542366
[Epoch 20; Iter   877/ 1097] train: loss: 0.2617697
[Epoch 20; Iter   907/ 1097] train: loss: 0.0437112
[Epoch 20; Iter   937/ 1097] train: loss: 0.0758100
[Epoch 20; Iter   967/ 1097] train: loss: 0.0446349
[Epoch 20; Iter   997/ 1097] train: loss: 0.0254421
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0627187
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1584690
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0356711
[Epoch 20] ogbg-molhiv: 0.820531 val loss: 0.710618
[Epoch 20] ogbg-molhiv: 0.730864 test loss: 0.362836
[Epoch 21; Iter    20/ 1097] train: loss: 0.0299535
[Epoch 21; Iter    50/ 1097] train: loss: 0.0269643
[Epoch 21; Iter    80/ 1097] train: loss: 0.0267447
[Epoch 21; Iter   110/ 1097] train: loss: 0.0166291
[Epoch 21; Iter   140/ 1097] train: loss: 0.1764602
[Epoch 21; Iter   170/ 1097] train: loss: 0.0997143
[Epoch 21; Iter   200/ 1097] train: loss: 0.0146640
[Epoch 21; Iter   230/ 1097] train: loss: 0.0370680
[Epoch 21; Iter   260/ 1097] train: loss: 0.0198517
[Epoch 21; Iter   290/ 1097] train: loss: 0.0481896
[Epoch 21; Iter   320/ 1097] train: loss: 0.1702651
[Epoch 21; Iter   350/ 1097] train: loss: 0.1764804
[Epoch 21; Iter   380/ 1097] train: loss: 0.0271764
[Epoch 21; Iter   410/ 1097] train: loss: 0.1836053
[Epoch 21; Iter   440/ 1097] train: loss: 0.2830202
[Epoch 21; Iter   470/ 1097] train: loss: 0.0870134
[Epoch 21; Iter   500/ 1097] train: loss: 0.1411563
[Epoch 21; Iter   530/ 1097] train: loss: 0.0406697
[Epoch 21; Iter   560/ 1097] train: loss: 0.1009185
[Epoch 21; Iter   590/ 1097] train: loss: 0.1249314
[Epoch 21; Iter   620/ 1097] train: loss: 0.1794708
[Epoch 21; Iter   650/ 1097] train: loss: 0.0280246
[Epoch 21; Iter   680/ 1097] train: loss: 0.0246627
[Epoch 21; Iter   710/ 1097] train: loss: 0.2220680
[Epoch 21; Iter   740/ 1097] train: loss: 0.1786672
[Epoch 21; Iter   770/ 1097] train: loss: 0.0779364
[Epoch 21; Iter   800/ 1097] train: loss: 0.2645691
[Epoch 21; Iter   830/ 1097] train: loss: 0.5024959
[Epoch 21; Iter   860/ 1097] train: loss: 0.0135072
[Epoch 21; Iter   890/ 1097] train: loss: 0.0221504
[Epoch 21; Iter   920/ 1097] train: loss: 0.0799012
[Epoch 21; Iter   950/ 1097] train: loss: 0.2254102
[Epoch 21; Iter   980/ 1097] train: loss: 0.2635047
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0222114
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1780178
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0335964
[Epoch 21] ogbg-molhiv: 0.820620 val loss: 0.167769
[Epoch 21] ogbg-molhiv: 0.746080 test loss: 0.136280
[Epoch 22; Iter     3/ 1097] train: loss: 0.0302991
[Epoch 22; Iter    33/ 1097] train: loss: 0.0521504
[Epoch 22; Iter    63/ 1097] train: loss: 0.1784149
[Epoch 22; Iter    93/ 1097] train: loss: 0.0405615
[Epoch 22; Iter   123/ 1097] train: loss: 0.0316255
[Epoch 22; Iter   153/ 1097] train: loss: 0.0614359
[Epoch 22; Iter   183/ 1097] train: loss: 0.0476558
[Epoch 22; Iter   213/ 1097] train: loss: 0.0348203
[Epoch 22; Iter   243/ 1097] train: loss: 0.0494757
[Epoch 22; Iter   273/ 1097] train: loss: 0.0989303
[Epoch 22; Iter   303/ 1097] train: loss: 0.0208911
[Epoch 22; Iter   333/ 1097] train: loss: 0.0397016
[Epoch 22; Iter   363/ 1097] train: loss: 0.0400562
[Epoch 22; Iter   393/ 1097] train: loss: 0.0350152
[Epoch 22; Iter   423/ 1097] train: loss: 0.0333905
[Epoch 22; Iter   453/ 1097] train: loss: 0.0573626
[Epoch 22; Iter   483/ 1097] train: loss: 0.0633203
[Epoch 22; Iter   513/ 1097] train: loss: 0.0189051
[Epoch 22; Iter   543/ 1097] train: loss: 0.0652381
[Epoch 22; Iter   573/ 1097] train: loss: 0.0517786
[Epoch 22; Iter   603/ 1097] train: loss: 0.0751049
[Epoch 22; Iter   633/ 1097] train: loss: 0.0299943
[Epoch 22; Iter   663/ 1097] train: loss: 0.0717625
[Epoch 22; Iter   693/ 1097] train: loss: 0.0172082
[Epoch 22; Iter   723/ 1097] train: loss: 0.0232510
[Epoch 22; Iter   753/ 1097] train: loss: 0.0431736
[Epoch 22; Iter   783/ 1097] train: loss: 0.2995967
[Epoch 22; Iter   813/ 1097] train: loss: 0.0338533
[Epoch 22; Iter   843/ 1097] train: loss: 0.0667952
[Epoch 22; Iter   873/ 1097] train: loss: 0.1201500
[Epoch 22; Iter   903/ 1097] train: loss: 0.0467996
[Epoch 22; Iter   933/ 1097] train: loss: 0.0315070
[Epoch 22; Iter   963/ 1097] train: loss: 0.1501180
[Epoch 22; Iter   993/ 1097] train: loss: 0.0271928
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0891593
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0442223
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0350092
[Epoch 22] ogbg-molhiv: 0.824656 val loss: 0.081168
[Epoch 22] ogbg-molhiv: 0.703011 test loss: 0.137207
[Epoch 23; Iter    16/ 1097] train: loss: 0.1307172
[Epoch 23; Iter    46/ 1097] train: loss: 0.0637247
[Epoch 23; Iter    76/ 1097] train: loss: 0.0461569
[Epoch 23; Iter   106/ 1097] train: loss: 0.0401336
[Epoch 23; Iter   136/ 1097] train: loss: 0.0205191
[Epoch 23; Iter   166/ 1097] train: loss: 0.1309607
[Epoch 23; Iter   196/ 1097] train: loss: 0.1585643
[Epoch 23; Iter   226/ 1097] train: loss: 0.0355385
[Epoch 23; Iter   256/ 1097] train: loss: 0.0216391
[Epoch 23; Iter   286/ 1097] train: loss: 0.0209284
[Epoch 23; Iter   316/ 1097] train: loss: 0.0465771
[Epoch 23; Iter   346/ 1097] train: loss: 0.0575352
[Epoch 23; Iter   376/ 1097] train: loss: 0.0591429
[Epoch 23; Iter   406/ 1097] train: loss: 0.0513703
[Epoch 23; Iter   436/ 1097] train: loss: 0.0979693
[Epoch 23; Iter   466/ 1097] train: loss: 0.0352925
[Epoch 23; Iter   496/ 1097] train: loss: 0.1423057
[Epoch 23; Iter   526/ 1097] train: loss: 0.0191263
[Epoch 23; Iter   556/ 1097] train: loss: 0.0785883
[Epoch 23; Iter   586/ 1097] train: loss: 0.0413379
[Epoch 23; Iter   616/ 1097] train: loss: 0.0154062
[Epoch 23; Iter   646/ 1097] train: loss: 0.0331692
[Epoch 23; Iter   676/ 1097] train: loss: 0.1368189
[Epoch 23; Iter   706/ 1097] train: loss: 0.0508479
[Epoch 23; Iter   736/ 1097] train: loss: 0.0504708
[Epoch 23; Iter   766/ 1097] train: loss: 0.1421405
[Epoch 23; Iter   796/ 1097] train: loss: 0.0150699
[Epoch 23; Iter   826/ 1097] train: loss: 0.0392405
[Epoch 23; Iter   856/ 1097] train: loss: 0.0158984
[Epoch 23; Iter   886/ 1097] train: loss: 0.0728845
[Epoch 23; Iter   916/ 1097] train: loss: 0.0152304
[Epoch 23; Iter   946/ 1097] train: loss: 0.0178772
[Epoch 23; Iter   976/ 1097] train: loss: 0.0558218
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1245794
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0316726
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0233980
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0238529
[Epoch 23] ogbg-molhiv: 0.831340 val loss: 0.334841
[Epoch 23] ogbg-molhiv: 0.699658 test loss: 0.221063
[Epoch 24; Iter    29/ 1097] train: loss: 0.0220051
[Epoch 24; Iter    59/ 1097] train: loss: 0.0227301
[Epoch 24; Iter    89/ 1097] train: loss: 0.2241722
[Epoch 24; Iter   119/ 1097] train: loss: 0.1045836
[Epoch 24; Iter   149/ 1097] train: loss: 0.0728922
[Epoch 24; Iter   179/ 1097] train: loss: 0.2432736
[Epoch 24; Iter   209/ 1097] train: loss: 0.0650385
[Epoch 24; Iter   239/ 1097] train: loss: 0.2196279
[Epoch 24; Iter   269/ 1097] train: loss: 0.1661584
[Epoch 24; Iter   299/ 1097] train: loss: 0.0239080
[Epoch 24; Iter   329/ 1097] train: loss: 0.3225809
[Epoch 20; Iter   307/ 1097] train: loss: 0.1112731
[Epoch 20; Iter   337/ 1097] train: loss: 0.1453199
[Epoch 20; Iter   367/ 1097] train: loss: 0.6241269
[Epoch 20; Iter   397/ 1097] train: loss: 0.0553005
[Epoch 20; Iter   427/ 1097] train: loss: 0.0340708
[Epoch 20; Iter   457/ 1097] train: loss: 0.0888771
[Epoch 20; Iter   487/ 1097] train: loss: 0.0973135
[Epoch 20; Iter   517/ 1097] train: loss: 0.1143126
[Epoch 20; Iter   547/ 1097] train: loss: 0.3503840
[Epoch 20; Iter   577/ 1097] train: loss: 0.0538278
[Epoch 20; Iter   607/ 1097] train: loss: 0.2003895
[Epoch 20; Iter   637/ 1097] train: loss: 0.1599778
[Epoch 20; Iter   667/ 1097] train: loss: 0.0790811
[Epoch 20; Iter   697/ 1097] train: loss: 0.0184136
[Epoch 20; Iter   727/ 1097] train: loss: 0.1230523
[Epoch 20; Iter   757/ 1097] train: loss: 0.1328939
[Epoch 20; Iter   787/ 1097] train: loss: 0.0596752
[Epoch 20; Iter   817/ 1097] train: loss: 0.1027131
[Epoch 20; Iter   847/ 1097] train: loss: 0.0809660
[Epoch 20; Iter   877/ 1097] train: loss: 0.2131191
[Epoch 20; Iter   907/ 1097] train: loss: 0.0706031
[Epoch 20; Iter   937/ 1097] train: loss: 0.0542930
[Epoch 20; Iter   967/ 1097] train: loss: 0.0300101
[Epoch 20; Iter   997/ 1097] train: loss: 0.1887477
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1033191
[Epoch 20; Iter  1057/ 1097] train: loss: 0.3076136
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2207180
[Epoch 20] ogbg-molhiv: 0.791165 val loss: 0.090747
[Epoch 20] ogbg-molhiv: 0.750219 test loss: 0.131326
[Epoch 21; Iter    20/ 1097] train: loss: 0.0554443
[Epoch 21; Iter    50/ 1097] train: loss: 0.1023404
[Epoch 21; Iter    80/ 1097] train: loss: 0.0610006
[Epoch 21; Iter   110/ 1097] train: loss: 0.0447597
[Epoch 21; Iter   140/ 1097] train: loss: 0.2994376
[Epoch 21; Iter   170/ 1097] train: loss: 0.1139754
[Epoch 21; Iter   200/ 1097] train: loss: 0.0351846
[Epoch 21; Iter   230/ 1097] train: loss: 0.1196268
[Epoch 21; Iter   260/ 1097] train: loss: 0.1730477
[Epoch 21; Iter   290/ 1097] train: loss: 0.0469179
[Epoch 21; Iter   320/ 1097] train: loss: 0.1459614
[Epoch 21; Iter   350/ 1097] train: loss: 0.1914243
[Epoch 21; Iter   380/ 1097] train: loss: 0.0436624
[Epoch 21; Iter   410/ 1097] train: loss: 0.0266212
[Epoch 21; Iter   440/ 1097] train: loss: 0.2429395
[Epoch 21; Iter   470/ 1097] train: loss: 0.1780087
[Epoch 21; Iter   500/ 1097] train: loss: 0.1561933
[Epoch 21; Iter   530/ 1097] train: loss: 0.1056721
[Epoch 21; Iter   560/ 1097] train: loss: 0.0500410
[Epoch 21; Iter   590/ 1097] train: loss: 0.0362156
[Epoch 21; Iter   620/ 1097] train: loss: 0.1721244
[Epoch 21; Iter   650/ 1097] train: loss: 0.0299495
[Epoch 21; Iter   680/ 1097] train: loss: 0.0445555
[Epoch 21; Iter   710/ 1097] train: loss: 0.0182003
[Epoch 21; Iter   740/ 1097] train: loss: 0.0683664
[Epoch 21; Iter   770/ 1097] train: loss: 0.1049244
[Epoch 21; Iter   800/ 1097] train: loss: 0.0724574
[Epoch 21; Iter   830/ 1097] train: loss: 0.1001072
[Epoch 21; Iter   860/ 1097] train: loss: 0.0335917
[Epoch 21; Iter   890/ 1097] train: loss: 0.0860957
[Epoch 21; Iter   920/ 1097] train: loss: 0.1130794
[Epoch 21; Iter   950/ 1097] train: loss: 0.0565755
[Epoch 21; Iter   980/ 1097] train: loss: 0.1596381
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1830291
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0378466
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0173445
[Epoch 21] ogbg-molhiv: 0.783794 val loss: 0.404844
[Epoch 21] ogbg-molhiv: 0.757446 test loss: 0.330091
[Epoch 22; Iter     3/ 1097] train: loss: 0.0467374
[Epoch 22; Iter    33/ 1097] train: loss: 0.1346218
[Epoch 22; Iter    63/ 1097] train: loss: 0.1352263
[Epoch 22; Iter    93/ 1097] train: loss: 0.0261407
[Epoch 22; Iter   123/ 1097] train: loss: 0.0742378
[Epoch 22; Iter   153/ 1097] train: loss: 0.2328080
[Epoch 22; Iter   183/ 1097] train: loss: 0.0913727
[Epoch 22; Iter   213/ 1097] train: loss: 0.0358585
[Epoch 22; Iter   243/ 1097] train: loss: 0.0212632
[Epoch 22; Iter   273/ 1097] train: loss: 0.0206053
[Epoch 22; Iter   303/ 1097] train: loss: 0.0300675
[Epoch 22; Iter   333/ 1097] train: loss: 0.0962360
[Epoch 22; Iter   363/ 1097] train: loss: 0.0231982
[Epoch 22; Iter   393/ 1097] train: loss: 0.0955146
[Epoch 22; Iter   423/ 1097] train: loss: 0.0213399
[Epoch 22; Iter   453/ 1097] train: loss: 0.0536398
[Epoch 22; Iter   483/ 1097] train: loss: 0.2098203
[Epoch 22; Iter   513/ 1097] train: loss: 0.0404139
[Epoch 22; Iter   543/ 1097] train: loss: 0.0414013
[Epoch 22; Iter   573/ 1097] train: loss: 0.1448273
[Epoch 22; Iter   603/ 1097] train: loss: 0.0212264
[Epoch 22; Iter   633/ 1097] train: loss: 0.0276428
[Epoch 22; Iter   663/ 1097] train: loss: 0.0769067
[Epoch 22; Iter   693/ 1097] train: loss: 0.0266210
[Epoch 22; Iter   723/ 1097] train: loss: 0.0458964
[Epoch 22; Iter   753/ 1097] train: loss: 0.2063009
[Epoch 22; Iter   783/ 1097] train: loss: 0.1018868
[Epoch 22; Iter   813/ 1097] train: loss: 0.0268925
[Epoch 22; Iter   843/ 1097] train: loss: 0.0195755
[Epoch 22; Iter   873/ 1097] train: loss: 0.1183758
[Epoch 22; Iter   903/ 1097] train: loss: 0.0473723
[Epoch 22; Iter   933/ 1097] train: loss: 0.0201904
[Epoch 22; Iter   963/ 1097] train: loss: 0.1173734
[Epoch 22; Iter   993/ 1097] train: loss: 0.1446805
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0403178
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0625486
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0207496
[Epoch 22] ogbg-molhiv: 0.752900 val loss: 0.321322
[Epoch 22] ogbg-molhiv: 0.738898 test loss: 0.137127
[Epoch 23; Iter    16/ 1097] train: loss: 0.0928748
[Epoch 23; Iter    46/ 1097] train: loss: 0.0665308
[Epoch 23; Iter    76/ 1097] train: loss: 0.0254944
[Epoch 23; Iter   106/ 1097] train: loss: 0.0174566
[Epoch 23; Iter   136/ 1097] train: loss: 0.1817907
[Epoch 23; Iter   166/ 1097] train: loss: 0.0844381
[Epoch 23; Iter   196/ 1097] train: loss: 0.1788420
[Epoch 23; Iter   226/ 1097] train: loss: 0.1194156
[Epoch 23; Iter   256/ 1097] train: loss: 0.0250468
[Epoch 23; Iter   286/ 1097] train: loss: 0.0249348
[Epoch 23; Iter   316/ 1097] train: loss: 0.2217945
[Epoch 23; Iter   346/ 1097] train: loss: 0.1148491
[Epoch 23; Iter   376/ 1097] train: loss: 0.0724063
[Epoch 23; Iter   406/ 1097] train: loss: 0.0333858
[Epoch 23; Iter   436/ 1097] train: loss: 0.0682274
[Epoch 23; Iter   466/ 1097] train: loss: 0.0979592
[Epoch 23; Iter   496/ 1097] train: loss: 0.0327110
[Epoch 23; Iter   526/ 1097] train: loss: 0.0133947
[Epoch 23; Iter   556/ 1097] train: loss: 0.0366804
[Epoch 23; Iter   586/ 1097] train: loss: 0.0228021
[Epoch 23; Iter   616/ 1097] train: loss: 0.0336129
[Epoch 23; Iter   646/ 1097] train: loss: 0.0309595
[Epoch 23; Iter   676/ 1097] train: loss: 0.0417652
[Epoch 23; Iter   706/ 1097] train: loss: 0.0548318
[Epoch 23; Iter   736/ 1097] train: loss: 0.1998896
[Epoch 23; Iter   766/ 1097] train: loss: 0.0160295
[Epoch 23; Iter   796/ 1097] train: loss: 0.2789920
[Epoch 23; Iter   826/ 1097] train: loss: 0.0942748
[Epoch 23; Iter   856/ 1097] train: loss: 0.1900081
[Epoch 23; Iter   886/ 1097] train: loss: 0.2196746
[Epoch 23; Iter   916/ 1097] train: loss: 0.0347316
[Epoch 23; Iter   946/ 1097] train: loss: 0.0690682
[Epoch 23; Iter   976/ 1097] train: loss: 0.0160247
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1497913
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0268647
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1531460
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0627841
[Epoch 23] ogbg-molhiv: 0.768127 val loss: 0.507894
[Epoch 23] ogbg-molhiv: 0.727397 test loss: 0.140925
[Epoch 24; Iter    29/ 1097] train: loss: 0.0169348
[Epoch 24; Iter    59/ 1097] train: loss: 0.1035329
[Epoch 24; Iter    89/ 1097] train: loss: 0.0187727
[Epoch 24; Iter   119/ 1097] train: loss: 0.0507351
[Epoch 24; Iter   149/ 1097] train: loss: 0.1096715
[Epoch 24; Iter   179/ 1097] train: loss: 0.0484824
[Epoch 24; Iter   209/ 1097] train: loss: 0.0230202
[Epoch 24; Iter   239/ 1097] train: loss: 0.0836077
[Epoch 24; Iter   269/ 1097] train: loss: 0.0434412
[Epoch 24; Iter   299/ 1097] train: loss: 0.0153547
[Epoch 24; Iter   329/ 1097] train: loss: 0.0171123
[Epoch 24; Iter   359/ 1097] train: loss: 0.0381279
[Epoch 20; Iter   307/ 1097] train: loss: 0.1624652
[Epoch 20; Iter   337/ 1097] train: loss: 0.0681592
[Epoch 20; Iter   367/ 1097] train: loss: 0.0463567
[Epoch 20; Iter   397/ 1097] train: loss: 0.0356551
[Epoch 20; Iter   427/ 1097] train: loss: 0.0297389
[Epoch 20; Iter   457/ 1097] train: loss: 0.0730078
[Epoch 20; Iter   487/ 1097] train: loss: 0.1571564
[Epoch 20; Iter   517/ 1097] train: loss: 0.0298766
[Epoch 20; Iter   547/ 1097] train: loss: 0.1849060
[Epoch 20; Iter   577/ 1097] train: loss: 0.0336826
[Epoch 20; Iter   607/ 1097] train: loss: 0.0252353
[Epoch 20; Iter   637/ 1097] train: loss: 0.0545579
[Epoch 20; Iter   667/ 1097] train: loss: 0.1307106
[Epoch 20; Iter   697/ 1097] train: loss: 0.0685976
[Epoch 20; Iter   727/ 1097] train: loss: 0.0788070
[Epoch 20; Iter   757/ 1097] train: loss: 0.0222424
[Epoch 20; Iter   787/ 1097] train: loss: 0.0452533
[Epoch 20; Iter   817/ 1097] train: loss: 0.0963606
[Epoch 20; Iter   847/ 1097] train: loss: 0.0377219
[Epoch 20; Iter   877/ 1097] train: loss: 0.1836974
[Epoch 20; Iter   907/ 1097] train: loss: 0.2105478
[Epoch 20; Iter   937/ 1097] train: loss: 0.0140229
[Epoch 20; Iter   967/ 1097] train: loss: 0.0322121
[Epoch 20; Iter   997/ 1097] train: loss: 0.0917869
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0411042
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0904060
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0504060
[Epoch 20] ogbg-molhiv: 0.685654 val loss: 0.089980
[Epoch 20] ogbg-molhiv: 0.657751 test loss: 0.148791
[Epoch 21; Iter    20/ 1097] train: loss: 0.0225828
[Epoch 21; Iter    50/ 1097] train: loss: 0.1639967
[Epoch 21; Iter    80/ 1097] train: loss: 0.0481889
[Epoch 21; Iter   110/ 1097] train: loss: 0.0402767
[Epoch 21; Iter   140/ 1097] train: loss: 0.2501032
[Epoch 21; Iter   170/ 1097] train: loss: 0.1148902
[Epoch 21; Iter   200/ 1097] train: loss: 0.1482066
[Epoch 21; Iter   230/ 1097] train: loss: 0.1927831
[Epoch 21; Iter   260/ 1097] train: loss: 0.2069542
[Epoch 21; Iter   290/ 1097] train: loss: 0.1384560
[Epoch 21; Iter   320/ 1097] train: loss: 0.2678657
[Epoch 21; Iter   350/ 1097] train: loss: 0.0217709
[Epoch 21; Iter   380/ 1097] train: loss: 0.0535449
[Epoch 21; Iter   410/ 1097] train: loss: 0.0447500
[Epoch 21; Iter   440/ 1097] train: loss: 0.1528483
[Epoch 21; Iter   470/ 1097] train: loss: 0.1427244
[Epoch 21; Iter   500/ 1097] train: loss: 0.0284980
[Epoch 21; Iter   530/ 1097] train: loss: 0.0459211
[Epoch 21; Iter   560/ 1097] train: loss: 0.0190587
[Epoch 21; Iter   590/ 1097] train: loss: 0.1127403
[Epoch 21; Iter   620/ 1097] train: loss: 0.0846743
[Epoch 21; Iter   650/ 1097] train: loss: 0.3292316
[Epoch 21; Iter   680/ 1097] train: loss: 0.0611823
[Epoch 21; Iter   710/ 1097] train: loss: 0.0246756
[Epoch 21; Iter   740/ 1097] train: loss: 0.0326316
[Epoch 21; Iter   770/ 1097] train: loss: 0.0432199
[Epoch 21; Iter   800/ 1097] train: loss: 0.0807791
[Epoch 21; Iter   830/ 1097] train: loss: 0.2274271
[Epoch 21; Iter   860/ 1097] train: loss: 0.0561645
[Epoch 21; Iter   890/ 1097] train: loss: 0.0213305
[Epoch 21; Iter   920/ 1097] train: loss: 0.0564028
[Epoch 21; Iter   950/ 1097] train: loss: 0.0462593
[Epoch 21; Iter   980/ 1097] train: loss: 0.0227614
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0205470
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0651993
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0667633
[Epoch 21] ogbg-molhiv: 0.712813 val loss: 0.081821
[Epoch 21] ogbg-molhiv: 0.711551 test loss: 0.152139
[Epoch 22; Iter     3/ 1097] train: loss: 0.1722521
[Epoch 22; Iter    33/ 1097] train: loss: 0.0437849
[Epoch 22; Iter    63/ 1097] train: loss: 0.0189342
[Epoch 22; Iter    93/ 1097] train: loss: 0.0237692
[Epoch 22; Iter   123/ 1097] train: loss: 0.0273222
[Epoch 22; Iter   153/ 1097] train: loss: 0.0201836
[Epoch 22; Iter   183/ 1097] train: loss: 0.1403694
[Epoch 22; Iter   213/ 1097] train: loss: 0.1272792
[Epoch 22; Iter   243/ 1097] train: loss: 0.1632667
[Epoch 22; Iter   273/ 1097] train: loss: 0.1318910
[Epoch 22; Iter   303/ 1097] train: loss: 0.1943295
[Epoch 22; Iter   333/ 1097] train: loss: 0.0563615
[Epoch 22; Iter   363/ 1097] train: loss: 0.2392650
[Epoch 22; Iter   393/ 1097] train: loss: 0.0150902
[Epoch 22; Iter   423/ 1097] train: loss: 0.0216118
[Epoch 22; Iter   453/ 1097] train: loss: 0.0236269
[Epoch 22; Iter   483/ 1097] train: loss: 0.0666298
[Epoch 22; Iter   513/ 1097] train: loss: 0.2569877
[Epoch 22; Iter   543/ 1097] train: loss: 0.1640922
[Epoch 22; Iter   573/ 1097] train: loss: 0.0540450
[Epoch 22; Iter   603/ 1097] train: loss: 0.0306692
[Epoch 22; Iter   633/ 1097] train: loss: 0.0299347
[Epoch 22; Iter   663/ 1097] train: loss: 0.0535914
[Epoch 22; Iter   693/ 1097] train: loss: 0.1261789
[Epoch 22; Iter   723/ 1097] train: loss: 0.2345403
[Epoch 22; Iter   753/ 1097] train: loss: 0.2506895
[Epoch 22; Iter   783/ 1097] train: loss: 0.0393733
[Epoch 22; Iter   813/ 1097] train: loss: 0.1643958
[Epoch 22; Iter   843/ 1097] train: loss: 0.0365227
[Epoch 22; Iter   873/ 1097] train: loss: 0.0548068
[Epoch 22; Iter   903/ 1097] train: loss: 0.1044961
[Epoch 22; Iter   933/ 1097] train: loss: 0.0234039
[Epoch 22; Iter   963/ 1097] train: loss: 0.1880211
[Epoch 22; Iter   993/ 1097] train: loss: 0.1538331
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3560051
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0694893
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0850709
[Epoch 22] ogbg-molhiv: 0.708241 val loss: 0.095885
[Epoch 22] ogbg-molhiv: 0.726470 test loss: 0.178131
[Epoch 23; Iter    16/ 1097] train: loss: 0.0564397
[Epoch 23; Iter    46/ 1097] train: loss: 0.2354507
[Epoch 23; Iter    76/ 1097] train: loss: 0.1532199
[Epoch 23; Iter   106/ 1097] train: loss: 0.2418673
[Epoch 23; Iter   136/ 1097] train: loss: 0.1275402
[Epoch 23; Iter   166/ 1097] train: loss: 0.2693871
[Epoch 23; Iter   196/ 1097] train: loss: 0.1184177
[Epoch 23; Iter   226/ 1097] train: loss: 0.0742505
[Epoch 23; Iter   256/ 1097] train: loss: 0.0540643
[Epoch 23; Iter   286/ 1097] train: loss: 0.0291279
[Epoch 23; Iter   316/ 1097] train: loss: 0.0341349
[Epoch 23; Iter   346/ 1097] train: loss: 0.0358967
[Epoch 23; Iter   376/ 1097] train: loss: 0.0173456
[Epoch 23; Iter   406/ 1097] train: loss: 0.1612445
[Epoch 23; Iter   436/ 1097] train: loss: 0.0343254
[Epoch 23; Iter   466/ 1097] train: loss: 0.0492904
[Epoch 23; Iter   496/ 1097] train: loss: 0.2344318
[Epoch 23; Iter   526/ 1097] train: loss: 0.0773721
[Epoch 23; Iter   556/ 1097] train: loss: 0.0531083
[Epoch 23; Iter   586/ 1097] train: loss: 0.1141451
[Epoch 23; Iter   616/ 1097] train: loss: 0.1200468
[Epoch 23; Iter   646/ 1097] train: loss: 0.1408582
[Epoch 23; Iter   676/ 1097] train: loss: 0.0381391
[Epoch 23; Iter   706/ 1097] train: loss: 0.0747095
[Epoch 23; Iter   736/ 1097] train: loss: 0.3647133
[Epoch 23; Iter   766/ 1097] train: loss: 0.1415275
[Epoch 23; Iter   796/ 1097] train: loss: 0.0281310
[Epoch 23; Iter   826/ 1097] train: loss: 0.2161227
[Epoch 23; Iter   856/ 1097] train: loss: 0.2885898
[Epoch 23; Iter   886/ 1097] train: loss: 0.1523275
[Epoch 23; Iter   916/ 1097] train: loss: 0.3551690
[Epoch 23; Iter   946/ 1097] train: loss: 0.0427972
[Epoch 23; Iter   976/ 1097] train: loss: 0.1842346
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0296252
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0372968
[Epoch 23; Iter  1066/ 1097] train: loss: 0.2661141
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0820287
[Epoch 23] ogbg-molhiv: 0.697727 val loss: 0.095530
[Epoch 23] ogbg-molhiv: 0.706310 test loss: 0.170586
[Epoch 24; Iter    29/ 1097] train: loss: 0.0631329
[Epoch 24; Iter    59/ 1097] train: loss: 0.2194039
[Epoch 24; Iter    89/ 1097] train: loss: 0.2124458
[Epoch 24; Iter   119/ 1097] train: loss: 0.0382450
[Epoch 24; Iter   149/ 1097] train: loss: 0.0284491
[Epoch 24; Iter   179/ 1097] train: loss: 0.0282102
[Epoch 24; Iter   209/ 1097] train: loss: 0.1309807
[Epoch 24; Iter   239/ 1097] train: loss: 0.0192836
[Epoch 24; Iter   269/ 1097] train: loss: 0.3105667
[Epoch 24; Iter   299/ 1097] train: loss: 0.0371603
[Epoch 24; Iter   329/ 1097] train: loss: 0.1198736
[Epoch 24; Iter   359/ 1097] train: loss: 0.0850792
[Epoch 20; Iter   307/ 1097] train: loss: 0.0488362
[Epoch 20; Iter   337/ 1097] train: loss: 0.0907662
[Epoch 20; Iter   367/ 1097] train: loss: 0.0338228
[Epoch 20; Iter   397/ 1097] train: loss: 0.0231240
[Epoch 20; Iter   427/ 1097] train: loss: 0.3248779
[Epoch 20; Iter   457/ 1097] train: loss: 0.2026815
[Epoch 20; Iter   487/ 1097] train: loss: 0.0957806
[Epoch 20; Iter   517/ 1097] train: loss: 0.0219736
[Epoch 20; Iter   547/ 1097] train: loss: 0.0267424
[Epoch 20; Iter   577/ 1097] train: loss: 0.0179176
[Epoch 20; Iter   607/ 1097] train: loss: 0.0259236
[Epoch 20; Iter   637/ 1097] train: loss: 0.0970270
[Epoch 20; Iter   667/ 1097] train: loss: 0.2265109
[Epoch 20; Iter   697/ 1097] train: loss: 0.0247208
[Epoch 20; Iter   727/ 1097] train: loss: 0.0180379
[Epoch 20; Iter   757/ 1097] train: loss: 0.1228020
[Epoch 20; Iter   787/ 1097] train: loss: 0.0223911
[Epoch 20; Iter   817/ 1097] train: loss: 0.0219080
[Epoch 20; Iter   847/ 1097] train: loss: 0.1667096
[Epoch 20; Iter   877/ 1097] train: loss: 0.2050071
[Epoch 20; Iter   907/ 1097] train: loss: 0.0348037
[Epoch 20; Iter   937/ 1097] train: loss: 0.1131302
[Epoch 20; Iter   967/ 1097] train: loss: 0.0201630
[Epoch 20; Iter   997/ 1097] train: loss: 0.0254330
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0577458
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1459424
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0337402
[Epoch 20] ogbg-molhiv: 0.711110 val loss: 0.114999
[Epoch 20] ogbg-molhiv: 0.689579 test loss: 0.149325
[Epoch 21; Iter    20/ 1097] train: loss: 0.0227227
[Epoch 21; Iter    50/ 1097] train: loss: 0.0309933
[Epoch 21; Iter    80/ 1097] train: loss: 0.0685032
[Epoch 21; Iter   110/ 1097] train: loss: 0.0452370
[Epoch 21; Iter   140/ 1097] train: loss: 0.2380487
[Epoch 21; Iter   170/ 1097] train: loss: 0.1462298
[Epoch 21; Iter   200/ 1097] train: loss: 0.0596718
[Epoch 21; Iter   230/ 1097] train: loss: 0.0159315
[Epoch 21; Iter   260/ 1097] train: loss: 0.0312386
[Epoch 21; Iter   290/ 1097] train: loss: 0.0564501
[Epoch 21; Iter   320/ 1097] train: loss: 0.0886313
[Epoch 21; Iter   350/ 1097] train: loss: 0.1788304
[Epoch 21; Iter   380/ 1097] train: loss: 0.0277313
[Epoch 21; Iter   410/ 1097] train: loss: 0.1889093
[Epoch 21; Iter   440/ 1097] train: loss: 0.3763391
[Epoch 21; Iter   470/ 1097] train: loss: 0.0656454
[Epoch 21; Iter   500/ 1097] train: loss: 0.1431687
[Epoch 21; Iter   530/ 1097] train: loss: 0.1101382
[Epoch 21; Iter   560/ 1097] train: loss: 0.1231600
[Epoch 21; Iter   590/ 1097] train: loss: 0.1501699
[Epoch 21; Iter   620/ 1097] train: loss: 0.2523574
[Epoch 21; Iter   650/ 1097] train: loss: 0.0406549
[Epoch 21; Iter   680/ 1097] train: loss: 0.0591680
[Epoch 21; Iter   710/ 1097] train: loss: 0.2299297
[Epoch 21; Iter   740/ 1097] train: loss: 0.1595676
[Epoch 21; Iter   770/ 1097] train: loss: 0.0218456
[Epoch 21; Iter   800/ 1097] train: loss: 0.1769600
[Epoch 21; Iter   830/ 1097] train: loss: 0.4748526
[Epoch 21; Iter   860/ 1097] train: loss: 0.0163704
[Epoch 21; Iter   890/ 1097] train: loss: 0.0345213
[Epoch 21; Iter   920/ 1097] train: loss: 0.2154305
[Epoch 21; Iter   950/ 1097] train: loss: 0.2141651
[Epoch 21; Iter   980/ 1097] train: loss: 0.2608549
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0224431
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2110226
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0237225
[Epoch 21] ogbg-molhiv: 0.727740 val loss: 0.092963
[Epoch 21] ogbg-molhiv: 0.666394 test loss: 0.146363
[Epoch 22; Iter     3/ 1097] train: loss: 0.0220575
[Epoch 22; Iter    33/ 1097] train: loss: 0.0270173
[Epoch 22; Iter    63/ 1097] train: loss: 0.1118541
[Epoch 22; Iter    93/ 1097] train: loss: 0.0468800
[Epoch 22; Iter   123/ 1097] train: loss: 0.0454844
[Epoch 22; Iter   153/ 1097] train: loss: 0.0346003
[Epoch 22; Iter   183/ 1097] train: loss: 0.0364491
[Epoch 22; Iter   213/ 1097] train: loss: 0.0237281
[Epoch 22; Iter   243/ 1097] train: loss: 0.0642791
[Epoch 22; Iter   273/ 1097] train: loss: 0.1471627
[Epoch 22; Iter   303/ 1097] train: loss: 0.0118163
[Epoch 22; Iter   333/ 1097] train: loss: 0.0147710
[Epoch 22; Iter   363/ 1097] train: loss: 0.0211785
[Epoch 22; Iter   393/ 1097] train: loss: 0.0262553
[Epoch 22; Iter   423/ 1097] train: loss: 0.0964698
[Epoch 22; Iter   453/ 1097] train: loss: 0.0501528
[Epoch 22; Iter   483/ 1097] train: loss: 0.0347826
[Epoch 22; Iter   513/ 1097] train: loss: 0.0203878
[Epoch 22; Iter   543/ 1097] train: loss: 0.0481878
[Epoch 22; Iter   573/ 1097] train: loss: 0.0463949
[Epoch 22; Iter   603/ 1097] train: loss: 0.0343096
[Epoch 22; Iter   633/ 1097] train: loss: 0.0124530
[Epoch 22; Iter   663/ 1097] train: loss: 0.0413265
[Epoch 22; Iter   693/ 1097] train: loss: 0.0260878
[Epoch 22; Iter   723/ 1097] train: loss: 0.0337868
[Epoch 22; Iter   753/ 1097] train: loss: 0.0146625
[Epoch 22; Iter   783/ 1097] train: loss: 0.2714965
[Epoch 22; Iter   813/ 1097] train: loss: 0.0198225
[Epoch 22; Iter   843/ 1097] train: loss: 0.1491601
[Epoch 22; Iter   873/ 1097] train: loss: 0.0595051
[Epoch 22; Iter   903/ 1097] train: loss: 0.1211223
[Epoch 22; Iter   933/ 1097] train: loss: 0.0148407
[Epoch 22; Iter   963/ 1097] train: loss: 0.2659813
[Epoch 22; Iter   993/ 1097] train: loss: 0.0232696
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0534327
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0614729
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0292835
[Epoch 22] ogbg-molhiv: 0.700026 val loss: 0.096639
[Epoch 22] ogbg-molhiv: 0.684496 test loss: 0.142112
[Epoch 23; Iter    16/ 1097] train: loss: 0.0644922
[Epoch 23; Iter    46/ 1097] train: loss: 0.0639795
[Epoch 23; Iter    76/ 1097] train: loss: 0.0568181
[Epoch 23; Iter   106/ 1097] train: loss: 0.0628735
[Epoch 23; Iter   136/ 1097] train: loss: 0.0555367
[Epoch 23; Iter   166/ 1097] train: loss: 0.2181363
[Epoch 23; Iter   196/ 1097] train: loss: 0.3238482
[Epoch 23; Iter   226/ 1097] train: loss: 0.0464579
[Epoch 23; Iter   256/ 1097] train: loss: 0.0396452
[Epoch 23; Iter   286/ 1097] train: loss: 0.0566439
[Epoch 23; Iter   316/ 1097] train: loss: 0.0192916
[Epoch 23; Iter   346/ 1097] train: loss: 0.1399251
[Epoch 23; Iter   376/ 1097] train: loss: 0.0550274
[Epoch 23; Iter   406/ 1097] train: loss: 0.0776410
[Epoch 23; Iter   436/ 1097] train: loss: 0.1558359
[Epoch 23; Iter   466/ 1097] train: loss: 0.0168772
[Epoch 23; Iter   496/ 1097] train: loss: 0.1766848
[Epoch 23; Iter   526/ 1097] train: loss: 0.0220479
[Epoch 23; Iter   556/ 1097] train: loss: 0.0983214
[Epoch 23; Iter   586/ 1097] train: loss: 0.0209628
[Epoch 23; Iter   616/ 1097] train: loss: 0.0215730
[Epoch 23; Iter   646/ 1097] train: loss: 0.0205705
[Epoch 23; Iter   676/ 1097] train: loss: 0.2184665
[Epoch 23; Iter   706/ 1097] train: loss: 0.0659880
[Epoch 23; Iter   736/ 1097] train: loss: 0.0381258
[Epoch 23; Iter   766/ 1097] train: loss: 0.2270519
[Epoch 23; Iter   796/ 1097] train: loss: 0.0735421
[Epoch 23; Iter   826/ 1097] train: loss: 0.0711321
[Epoch 23; Iter   856/ 1097] train: loss: 0.0190919
[Epoch 23; Iter   886/ 1097] train: loss: 0.0763657
[Epoch 23; Iter   916/ 1097] train: loss: 0.0421810
[Epoch 23; Iter   946/ 1097] train: loss: 0.0650510
[Epoch 23; Iter   976/ 1097] train: loss: 0.0258818
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1671297
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0258797
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0194147
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0632406
[Epoch 23] ogbg-molhiv: 0.712464 val loss: 0.097852
[Epoch 23] ogbg-molhiv: 0.650805 test loss: 0.149061
[Epoch 24; Iter    29/ 1097] train: loss: 0.0246729
[Epoch 24; Iter    59/ 1097] train: loss: 0.0327737
[Epoch 24; Iter    89/ 1097] train: loss: 0.1998940
[Epoch 24; Iter   119/ 1097] train: loss: 0.0171049
[Epoch 24; Iter   149/ 1097] train: loss: 0.1527393
[Epoch 24; Iter   179/ 1097] train: loss: 0.2895066
[Epoch 24; Iter   209/ 1097] train: loss: 0.0309738
[Epoch 24; Iter   239/ 1097] train: loss: 0.1277121
[Epoch 24; Iter   269/ 1097] train: loss: 0.1125022
[Epoch 24; Iter   299/ 1097] train: loss: 0.0227598
[Epoch 24; Iter   329/ 1097] train: loss: 0.3491712
[Epoch 24; Iter   359/ 1097] train: loss: 0.0977551
[Epoch 20; Iter   307/ 1097] train: loss: 0.0335427
[Epoch 20; Iter   337/ 1097] train: loss: 0.0664833
[Epoch 20; Iter   367/ 1097] train: loss: 0.3450362
[Epoch 20; Iter   397/ 1097] train: loss: 0.0661272
[Epoch 20; Iter   427/ 1097] train: loss: 0.0667416
[Epoch 20; Iter   457/ 1097] train: loss: 0.0365610
[Epoch 20; Iter   487/ 1097] train: loss: 0.1347461
[Epoch 20; Iter   517/ 1097] train: loss: 0.1239966
[Epoch 20; Iter   547/ 1097] train: loss: 0.2327385
[Epoch 20; Iter   577/ 1097] train: loss: 0.0244448
[Epoch 20; Iter   607/ 1097] train: loss: 0.2341564
[Epoch 20; Iter   637/ 1097] train: loss: 0.0176705
[Epoch 20; Iter   667/ 1097] train: loss: 0.0412030
[Epoch 20; Iter   697/ 1097] train: loss: 0.0133487
[Epoch 20; Iter   727/ 1097] train: loss: 0.0582945
[Epoch 20; Iter   757/ 1097] train: loss: 0.1860852
[Epoch 20; Iter   787/ 1097] train: loss: 0.0540453
[Epoch 20; Iter   817/ 1097] train: loss: 0.0554572
[Epoch 20; Iter   847/ 1097] train: loss: 0.0922720
[Epoch 20; Iter   877/ 1097] train: loss: 0.1431578
[Epoch 20; Iter   907/ 1097] train: loss: 0.0280400
[Epoch 20; Iter   937/ 1097] train: loss: 0.0259607
[Epoch 20; Iter   967/ 1097] train: loss: 0.0371909
[Epoch 20; Iter   997/ 1097] train: loss: 0.0823911
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0933331
[Epoch 20; Iter  1057/ 1097] train: loss: 0.3692910
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2150564
[Epoch 20] ogbg-molhiv: 0.629495 val loss: 0.624069
[Epoch 20] ogbg-molhiv: 0.707327 test loss: 0.511576
[Epoch 21; Iter    20/ 1097] train: loss: 0.0494917
[Epoch 21; Iter    50/ 1097] train: loss: 0.1817291
[Epoch 21; Iter    80/ 1097] train: loss: 0.0211564
[Epoch 21; Iter   110/ 1097] train: loss: 0.0226824
[Epoch 21; Iter   140/ 1097] train: loss: 0.2230758
[Epoch 21; Iter   170/ 1097] train: loss: 0.0623463
[Epoch 21; Iter   200/ 1097] train: loss: 0.0331130
[Epoch 21; Iter   230/ 1097] train: loss: 0.0896286
[Epoch 21; Iter   260/ 1097] train: loss: 0.1414096
[Epoch 21; Iter   290/ 1097] train: loss: 0.0616799
[Epoch 21; Iter   320/ 1097] train: loss: 0.0236198
[Epoch 21; Iter   350/ 1097] train: loss: 0.1246750
[Epoch 21; Iter   380/ 1097] train: loss: 0.0441933
[Epoch 21; Iter   410/ 1097] train: loss: 0.0321783
[Epoch 21; Iter   440/ 1097] train: loss: 0.2018393
[Epoch 21; Iter   470/ 1097] train: loss: 0.0746417
[Epoch 21; Iter   500/ 1097] train: loss: 0.1662788
[Epoch 21; Iter   530/ 1097] train: loss: 0.1363416
[Epoch 21; Iter   560/ 1097] train: loss: 0.0373025
[Epoch 21; Iter   590/ 1097] train: loss: 0.0177139
[Epoch 21; Iter   620/ 1097] train: loss: 0.0346432
[Epoch 21; Iter   650/ 1097] train: loss: 0.0205643
[Epoch 21; Iter   680/ 1097] train: loss: 0.0222135
[Epoch 21; Iter   710/ 1097] train: loss: 0.0182213
[Epoch 21; Iter   740/ 1097] train: loss: 0.0315288
[Epoch 21; Iter   770/ 1097] train: loss: 0.0888656
[Epoch 21; Iter   800/ 1097] train: loss: 0.0253178
[Epoch 21; Iter   830/ 1097] train: loss: 0.0677194
[Epoch 21; Iter   860/ 1097] train: loss: 0.0478226
[Epoch 21; Iter   890/ 1097] train: loss: 0.0524791
[Epoch 21; Iter   920/ 1097] train: loss: 0.0525098
[Epoch 21; Iter   950/ 1097] train: loss: 0.0496872
[Epoch 21; Iter   980/ 1097] train: loss: 0.2021520
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1418621
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0161302
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0230598
[Epoch 21] ogbg-molhiv: 0.703275 val loss: 0.120942
[Epoch 21] ogbg-molhiv: 0.729083 test loss: 0.166907
[Epoch 22; Iter     3/ 1097] train: loss: 0.0610329
[Epoch 22; Iter    33/ 1097] train: loss: 0.1419090
[Epoch 22; Iter    63/ 1097] train: loss: 0.1396327
[Epoch 22; Iter    93/ 1097] train: loss: 0.0986761
[Epoch 22; Iter   123/ 1097] train: loss: 0.1502153
[Epoch 22; Iter   153/ 1097] train: loss: 0.2519064
[Epoch 22; Iter   183/ 1097] train: loss: 0.1156381
[Epoch 22; Iter   213/ 1097] train: loss: 0.0483964
[Epoch 22; Iter   243/ 1097] train: loss: 0.0312884
[Epoch 22; Iter   273/ 1097] train: loss: 0.0428165
[Epoch 22; Iter   303/ 1097] train: loss: 0.0163156
[Epoch 22; Iter   333/ 1097] train: loss: 0.2035287
[Epoch 22; Iter   363/ 1097] train: loss: 0.0667843
[Epoch 22; Iter   393/ 1097] train: loss: 0.2511169
[Epoch 22; Iter   423/ 1097] train: loss: 0.0250576
[Epoch 22; Iter   453/ 1097] train: loss: 0.0576287
[Epoch 22; Iter   483/ 1097] train: loss: 0.0902667
[Epoch 22; Iter   513/ 1097] train: loss: 0.0144962
[Epoch 22; Iter   543/ 1097] train: loss: 0.0477873
[Epoch 22; Iter   573/ 1097] train: loss: 0.1294556
[Epoch 22; Iter   603/ 1097] train: loss: 0.0109951
[Epoch 22; Iter   633/ 1097] train: loss: 0.0193809
[Epoch 22; Iter   663/ 1097] train: loss: 0.0832915
[Epoch 22; Iter   693/ 1097] train: loss: 0.0223019
[Epoch 22; Iter   723/ 1097] train: loss: 0.0199610
[Epoch 22; Iter   753/ 1097] train: loss: 0.2002184
[Epoch 22; Iter   783/ 1097] train: loss: 0.1371901
[Epoch 22; Iter   813/ 1097] train: loss: 0.0226220
[Epoch 22; Iter   843/ 1097] train: loss: 0.0266194
[Epoch 22; Iter   873/ 1097] train: loss: 0.1362364
[Epoch 22; Iter   903/ 1097] train: loss: 0.0159786
[Epoch 22; Iter   933/ 1097] train: loss: 0.0149497
[Epoch 22; Iter   963/ 1097] train: loss: 0.1322424
[Epoch 22; Iter   993/ 1097] train: loss: 0.0197919
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0133365
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1857435
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0375899
[Epoch 22] ogbg-molhiv: 0.726950 val loss: 0.134570
[Epoch 22] ogbg-molhiv: 0.735219 test loss: 0.170370
[Epoch 23; Iter    16/ 1097] train: loss: 0.0212324
[Epoch 23; Iter    46/ 1097] train: loss: 0.0348106
[Epoch 23; Iter    76/ 1097] train: loss: 0.0606397
[Epoch 23; Iter   106/ 1097] train: loss: 0.0100737
[Epoch 23; Iter   136/ 1097] train: loss: 0.1537914
[Epoch 23; Iter   166/ 1097] train: loss: 0.0260668
[Epoch 23; Iter   196/ 1097] train: loss: 0.3549091
[Epoch 23; Iter   226/ 1097] train: loss: 0.0342871
[Epoch 23; Iter   256/ 1097] train: loss: 0.0277578
[Epoch 23; Iter   286/ 1097] train: loss: 0.0389603
[Epoch 23; Iter   316/ 1097] train: loss: 0.1185075
[Epoch 23; Iter   346/ 1097] train: loss: 0.1616584
[Epoch 23; Iter   376/ 1097] train: loss: 0.0260550
[Epoch 23; Iter   406/ 1097] train: loss: 0.0186918
[Epoch 23; Iter   436/ 1097] train: loss: 0.0949971
[Epoch 23; Iter   466/ 1097] train: loss: 0.1582502
[Epoch 23; Iter   496/ 1097] train: loss: 0.0638380
[Epoch 23; Iter   526/ 1097] train: loss: 0.0278003
[Epoch 23; Iter   556/ 1097] train: loss: 0.0999100
[Epoch 23; Iter   586/ 1097] train: loss: 0.0234859
[Epoch 23; Iter   616/ 1097] train: loss: 0.0191075
[Epoch 23; Iter   646/ 1097] train: loss: 0.0177535
[Epoch 23; Iter   676/ 1097] train: loss: 0.1220644
[Epoch 23; Iter   706/ 1097] train: loss: 0.0238736
[Epoch 23; Iter   736/ 1097] train: loss: 0.1380678
[Epoch 23; Iter   766/ 1097] train: loss: 0.0579301
[Epoch 23; Iter   796/ 1097] train: loss: 0.3366233
[Epoch 23; Iter   826/ 1097] train: loss: 0.0109952
[Epoch 23; Iter   856/ 1097] train: loss: 0.1171928
[Epoch 23; Iter   886/ 1097] train: loss: 0.1449992
[Epoch 23; Iter   916/ 1097] train: loss: 0.0586625
[Epoch 23; Iter   946/ 1097] train: loss: 0.2955559
[Epoch 23; Iter   976/ 1097] train: loss: 0.0184746
[Epoch 23; Iter  1006/ 1097] train: loss: 0.2131693
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1362749
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1096604
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0130505
[Epoch 23] ogbg-molhiv: 0.716331 val loss: 0.451137
[Epoch 23] ogbg-molhiv: 0.716424 test loss: 0.327829
[Epoch 24; Iter    29/ 1097] train: loss: 0.0208362
[Epoch 24; Iter    59/ 1097] train: loss: 0.0122577
[Epoch 24; Iter    89/ 1097] train: loss: 0.0242867
[Epoch 24; Iter   119/ 1097] train: loss: 0.0553015
[Epoch 24; Iter   149/ 1097] train: loss: 0.2077818
[Epoch 24; Iter   179/ 1097] train: loss: 0.0728304
[Epoch 24; Iter   209/ 1097] train: loss: 0.0130174
[Epoch 24; Iter   239/ 1097] train: loss: 0.0633715
[Epoch 24; Iter   269/ 1097] train: loss: 0.0151690
[Epoch 24; Iter   299/ 1097] train: loss: 0.0272216
[Epoch 24; Iter   329/ 1097] train: loss: 0.0233354
[Epoch 24; Iter   359/ 1097] train: loss: 0.0190064
[Epoch 20; Iter   307/ 1097] train: loss: 0.0411910
[Epoch 20; Iter   337/ 1097] train: loss: 0.0416726
[Epoch 20; Iter   367/ 1097] train: loss: 0.0386768
[Epoch 20; Iter   397/ 1097] train: loss: 0.0510525
[Epoch 20; Iter   427/ 1097] train: loss: 0.3357047
[Epoch 20; Iter   457/ 1097] train: loss: 0.0849378
[Epoch 20; Iter   487/ 1097] train: loss: 0.0408349
[Epoch 20; Iter   517/ 1097] train: loss: 0.0446349
[Epoch 20; Iter   547/ 1097] train: loss: 0.0235957
[Epoch 20; Iter   577/ 1097] train: loss: 0.0187720
[Epoch 20; Iter   607/ 1097] train: loss: 0.0170000
[Epoch 20; Iter   637/ 1097] train: loss: 0.1171440
[Epoch 20; Iter   667/ 1097] train: loss: 0.1977795
[Epoch 20; Iter   697/ 1097] train: loss: 0.0174661
[Epoch 20; Iter   727/ 1097] train: loss: 0.0216468
[Epoch 20; Iter   757/ 1097] train: loss: 0.2966595
[Epoch 20; Iter   787/ 1097] train: loss: 0.0201290
[Epoch 20; Iter   817/ 1097] train: loss: 0.0313139
[Epoch 20; Iter   847/ 1097] train: loss: 0.0869736
[Epoch 20; Iter   877/ 1097] train: loss: 0.3440576
[Epoch 20; Iter   907/ 1097] train: loss: 0.0267798
[Epoch 20; Iter   937/ 1097] train: loss: 0.0787769
[Epoch 20; Iter   967/ 1097] train: loss: 0.1128532
[Epoch 20; Iter   997/ 1097] train: loss: 0.0513001
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1566577
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0848759
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0257782
[Epoch 20] ogbg-molhiv: 0.720057 val loss: 0.511189
[Epoch 20] ogbg-molhiv: 0.660302 test loss: 0.370226
[Epoch 21; Iter    20/ 1097] train: loss: 0.0278942
[Epoch 21; Iter    50/ 1097] train: loss: 0.0356436
[Epoch 21; Iter    80/ 1097] train: loss: 0.0761186
[Epoch 21; Iter   110/ 1097] train: loss: 0.0475659
[Epoch 21; Iter   140/ 1097] train: loss: 0.1401114
[Epoch 21; Iter   170/ 1097] train: loss: 0.1575908
[Epoch 21; Iter   200/ 1097] train: loss: 0.0146840
[Epoch 21; Iter   230/ 1097] train: loss: 0.0572316
[Epoch 21; Iter   260/ 1097] train: loss: 0.0307778
[Epoch 21; Iter   290/ 1097] train: loss: 0.0424112
[Epoch 21; Iter   320/ 1097] train: loss: 0.0892151
[Epoch 21; Iter   350/ 1097] train: loss: 0.0453975
[Epoch 21; Iter   380/ 1097] train: loss: 0.0328712
[Epoch 21; Iter   410/ 1097] train: loss: 0.2838467
[Epoch 21; Iter   440/ 1097] train: loss: 0.2923259
[Epoch 21; Iter   470/ 1097] train: loss: 0.0759107
[Epoch 21; Iter   500/ 1097] train: loss: 0.1008190
[Epoch 21; Iter   530/ 1097] train: loss: 0.1219246
[Epoch 21; Iter   560/ 1097] train: loss: 0.1254768
[Epoch 21; Iter   590/ 1097] train: loss: 0.0582190
[Epoch 21; Iter   620/ 1097] train: loss: 0.1827314
[Epoch 21; Iter   650/ 1097] train: loss: 0.0236109
[Epoch 21; Iter   680/ 1097] train: loss: 0.0200933
[Epoch 21; Iter   710/ 1097] train: loss: 0.2671431
[Epoch 21; Iter   740/ 1097] train: loss: 0.1918443
[Epoch 21; Iter   770/ 1097] train: loss: 0.0627831
[Epoch 21; Iter   800/ 1097] train: loss: 0.1970472
[Epoch 21; Iter   830/ 1097] train: loss: 0.4328639
[Epoch 21; Iter   860/ 1097] train: loss: 0.0192583
[Epoch 21; Iter   890/ 1097] train: loss: 0.0648821
[Epoch 21; Iter   920/ 1097] train: loss: 0.2228436
[Epoch 21; Iter   950/ 1097] train: loss: 0.2463194
[Epoch 21; Iter   980/ 1097] train: loss: 0.2807871
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0156721
[Epoch 21; Iter  1040/ 1097] train: loss: 0.2157625
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0554791
[Epoch 21] ogbg-molhiv: 0.700382 val loss: 0.394386
[Epoch 21] ogbg-molhiv: 0.622818 test loss: 0.623344
[Epoch 22; Iter     3/ 1097] train: loss: 0.0438122
[Epoch 22; Iter    33/ 1097] train: loss: 0.0517474
[Epoch 22; Iter    63/ 1097] train: loss: 0.0258238
[Epoch 22; Iter    93/ 1097] train: loss: 0.0260137
[Epoch 22; Iter   123/ 1097] train: loss: 0.0253503
[Epoch 22; Iter   153/ 1097] train: loss: 0.0760784
[Epoch 22; Iter   183/ 1097] train: loss: 0.0256526
[Epoch 22; Iter   213/ 1097] train: loss: 0.0303833
[Epoch 22; Iter   243/ 1097] train: loss: 0.0715398
[Epoch 22; Iter   273/ 1097] train: loss: 0.1585506
[Epoch 22; Iter   303/ 1097] train: loss: 0.0206732
[Epoch 22; Iter   333/ 1097] train: loss: 0.0172467
[Epoch 22; Iter   363/ 1097] train: loss: 0.0170264
[Epoch 22; Iter   393/ 1097] train: loss: 0.0202162
[Epoch 22; Iter   423/ 1097] train: loss: 0.1467714
[Epoch 22; Iter   453/ 1097] train: loss: 0.0308157
[Epoch 22; Iter   483/ 1097] train: loss: 0.0228964
[Epoch 22; Iter   513/ 1097] train: loss: 0.0139466
[Epoch 22; Iter   543/ 1097] train: loss: 0.0219623
[Epoch 22; Iter   573/ 1097] train: loss: 0.0310112
[Epoch 22; Iter   603/ 1097] train: loss: 0.1192895
[Epoch 22; Iter   633/ 1097] train: loss: 0.0131876
[Epoch 22; Iter   663/ 1097] train: loss: 0.0122629
[Epoch 22; Iter   693/ 1097] train: loss: 0.0133700
[Epoch 22; Iter   723/ 1097] train: loss: 0.0163678
[Epoch 22; Iter   753/ 1097] train: loss: 0.1139577
[Epoch 22; Iter   783/ 1097] train: loss: 0.2903832
[Epoch 22; Iter   813/ 1097] train: loss: 0.0288361
[Epoch 22; Iter   843/ 1097] train: loss: 0.1177877
[Epoch 22; Iter   873/ 1097] train: loss: 0.0243599
[Epoch 22; Iter   903/ 1097] train: loss: 0.0624794
[Epoch 22; Iter   933/ 1097] train: loss: 0.0221034
[Epoch 22; Iter   963/ 1097] train: loss: 0.1090975
[Epoch 22; Iter   993/ 1097] train: loss: 0.0395842
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0531716
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0445356
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0786009
[Epoch 22] ogbg-molhiv: 0.732143 val loss: 0.966535
[Epoch 22] ogbg-molhiv: 0.635047 test loss: 1.458438
[Epoch 23; Iter    16/ 1097] train: loss: 0.1343042
[Epoch 23; Iter    46/ 1097] train: loss: 0.0203672
[Epoch 23; Iter    76/ 1097] train: loss: 0.0612329
[Epoch 23; Iter   106/ 1097] train: loss: 0.0439217
[Epoch 23; Iter   136/ 1097] train: loss: 0.1137788
[Epoch 23; Iter   166/ 1097] train: loss: 0.0334232
[Epoch 23; Iter   196/ 1097] train: loss: 0.1901313
[Epoch 23; Iter   226/ 1097] train: loss: 0.0221912
[Epoch 23; Iter   256/ 1097] train: loss: 0.0282642
[Epoch 23; Iter   286/ 1097] train: loss: 0.0163172
[Epoch 23; Iter   316/ 1097] train: loss: 0.0325218
[Epoch 23; Iter   346/ 1097] train: loss: 0.0425393
[Epoch 23; Iter   376/ 1097] train: loss: 0.0411429
[Epoch 23; Iter   406/ 1097] train: loss: 0.0204484
[Epoch 23; Iter   436/ 1097] train: loss: 0.1841560
[Epoch 23; Iter   466/ 1097] train: loss: 0.0147735
[Epoch 23; Iter   496/ 1097] train: loss: 0.0468314
[Epoch 23; Iter   526/ 1097] train: loss: 0.0174482
[Epoch 23; Iter   556/ 1097] train: loss: 0.0215210
[Epoch 23; Iter   586/ 1097] train: loss: 0.0236566
[Epoch 23; Iter   616/ 1097] train: loss: 0.0734327
[Epoch 23; Iter   646/ 1097] train: loss: 0.1277031
[Epoch 23; Iter   676/ 1097] train: loss: 0.1963164
[Epoch 23; Iter   706/ 1097] train: loss: 0.0753398
[Epoch 23; Iter   736/ 1097] train: loss: 0.0355550
[Epoch 23; Iter   766/ 1097] train: loss: 0.3201431
[Epoch 23; Iter   796/ 1097] train: loss: 0.0376726
[Epoch 23; Iter   826/ 1097] train: loss: 0.0155407
[Epoch 23; Iter   856/ 1097] train: loss: 0.0140458
[Epoch 23; Iter   886/ 1097] train: loss: 0.0271882
[Epoch 23; Iter   916/ 1097] train: loss: 0.0479104
[Epoch 23; Iter   946/ 1097] train: loss: 0.0104543
[Epoch 23; Iter   976/ 1097] train: loss: 0.0671458
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1810015
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1284737
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0209177
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1269448
[Epoch 23] ogbg-molhiv: 0.717663 val loss: 0.806258
[Epoch 23] ogbg-molhiv: 0.644012 test loss: 1.372133
[Epoch 24; Iter    29/ 1097] train: loss: 0.0246248
[Epoch 24; Iter    59/ 1097] train: loss: 0.0817360
[Epoch 24; Iter    89/ 1097] train: loss: 0.2183260
[Epoch 24; Iter   119/ 1097] train: loss: 0.1130499
[Epoch 24; Iter   149/ 1097] train: loss: 0.1841778
[Epoch 24; Iter   179/ 1097] train: loss: 0.1864975
[Epoch 24; Iter   209/ 1097] train: loss: 0.0269940
[Epoch 24; Iter   239/ 1097] train: loss: 0.2190531
[Epoch 24; Iter   269/ 1097] train: loss: 0.0258272
[Epoch 24; Iter   299/ 1097] train: loss: 0.0180636
[Epoch 24; Iter   329/ 1097] train: loss: 0.3247376
[Epoch 24; Iter   359/ 1097] train: loss: 0.1422504
[Epoch 20; Iter   307/ 1097] train: loss: 0.1909851
[Epoch 20; Iter   337/ 1097] train: loss: 0.0933630
[Epoch 20; Iter   367/ 1097] train: loss: 0.0771224
[Epoch 20; Iter   397/ 1097] train: loss: 0.0215001
[Epoch 20; Iter   427/ 1097] train: loss: 0.0980012
[Epoch 20; Iter   457/ 1097] train: loss: 0.1431122
[Epoch 20; Iter   487/ 1097] train: loss: 0.1004635
[Epoch 20; Iter   517/ 1097] train: loss: 0.0266843
[Epoch 20; Iter   547/ 1097] train: loss: 0.1694508
[Epoch 20; Iter   577/ 1097] train: loss: 0.0325578
[Epoch 20; Iter   607/ 1097] train: loss: 0.0296413
[Epoch 20; Iter   637/ 1097] train: loss: 0.0255463
[Epoch 20; Iter   667/ 1097] train: loss: 0.2727493
[Epoch 20; Iter   697/ 1097] train: loss: 0.1430447
[Epoch 20; Iter   727/ 1097] train: loss: 0.1486908
[Epoch 20; Iter   757/ 1097] train: loss: 0.0273003
[Epoch 20; Iter   787/ 1097] train: loss: 0.0410722
[Epoch 20; Iter   817/ 1097] train: loss: 0.1439460
[Epoch 20; Iter   847/ 1097] train: loss: 0.0376653
[Epoch 20; Iter   877/ 1097] train: loss: 0.1705597
[Epoch 20; Iter   907/ 1097] train: loss: 0.2685483
[Epoch 20; Iter   937/ 1097] train: loss: 0.0204705
[Epoch 20; Iter   967/ 1097] train: loss: 0.1083798
[Epoch 20; Iter   997/ 1097] train: loss: 0.1574666
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0533724
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1285613
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0441084
[Epoch 20] ogbg-molhiv: 0.708563 val loss: 0.123691
[Epoch 20] ogbg-molhiv: 0.623724 test loss: 0.149252
[Epoch 21; Iter    20/ 1097] train: loss: 0.0365432
[Epoch 21; Iter    50/ 1097] train: loss: 0.3043904
[Epoch 21; Iter    80/ 1097] train: loss: 0.0354498
[Epoch 21; Iter   110/ 1097] train: loss: 0.0291077
[Epoch 21; Iter   140/ 1097] train: loss: 0.1265100
[Epoch 21; Iter   170/ 1097] train: loss: 0.1036576
[Epoch 21; Iter   200/ 1097] train: loss: 0.1355589
[Epoch 21; Iter   230/ 1097] train: loss: 0.1258277
[Epoch 21; Iter   260/ 1097] train: loss: 0.1503005
[Epoch 21; Iter   290/ 1097] train: loss: 0.1367925
[Epoch 21; Iter   320/ 1097] train: loss: 0.2926186
[Epoch 21; Iter   350/ 1097] train: loss: 0.0259279
[Epoch 21; Iter   380/ 1097] train: loss: 0.1190144
[Epoch 21; Iter   410/ 1097] train: loss: 0.0705366
[Epoch 21; Iter   440/ 1097] train: loss: 0.1360685
[Epoch 21; Iter   470/ 1097] train: loss: 0.1876477
[Epoch 21; Iter   500/ 1097] train: loss: 0.0375998
[Epoch 21; Iter   530/ 1097] train: loss: 0.0337671
[Epoch 21; Iter   560/ 1097] train: loss: 0.0385065
[Epoch 21; Iter   590/ 1097] train: loss: 0.1422739
[Epoch 21; Iter   620/ 1097] train: loss: 0.1132925
[Epoch 21; Iter   650/ 1097] train: loss: 0.2020960
[Epoch 21; Iter   680/ 1097] train: loss: 0.1014722
[Epoch 21; Iter   710/ 1097] train: loss: 0.0711269
[Epoch 21; Iter   740/ 1097] train: loss: 0.0596598
[Epoch 21; Iter   770/ 1097] train: loss: 0.0956899
[Epoch 21; Iter   800/ 1097] train: loss: 0.1939313
[Epoch 21; Iter   830/ 1097] train: loss: 0.1497797
[Epoch 21; Iter   860/ 1097] train: loss: 0.0444577
[Epoch 21; Iter   890/ 1097] train: loss: 0.0392141
[Epoch 21; Iter   920/ 1097] train: loss: 0.1089995
[Epoch 21; Iter   950/ 1097] train: loss: 0.0435665
[Epoch 21; Iter   980/ 1097] train: loss: 0.0190124
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0245135
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1452832
[Epoch 21; Iter  1070/ 1097] train: loss: 0.1440138
[Epoch 21] ogbg-molhiv: 0.723444 val loss: 0.122057
[Epoch 21] ogbg-molhiv: 0.645590 test loss: 0.145909
[Epoch 22; Iter     3/ 1097] train: loss: 0.1275477
[Epoch 22; Iter    33/ 1097] train: loss: 0.0520442
[Epoch 22; Iter    63/ 1097] train: loss: 0.0945067
[Epoch 22; Iter    93/ 1097] train: loss: 0.0671819
[Epoch 22; Iter   123/ 1097] train: loss: 0.0467808
[Epoch 22; Iter   153/ 1097] train: loss: 0.0703914
[Epoch 22; Iter   183/ 1097] train: loss: 0.1489082
[Epoch 22; Iter   213/ 1097] train: loss: 0.1781808
[Epoch 22; Iter   243/ 1097] train: loss: 0.1187660
[Epoch 22; Iter   273/ 1097] train: loss: 0.1208519
[Epoch 22; Iter   303/ 1097] train: loss: 0.2697824
[Epoch 22; Iter   333/ 1097] train: loss: 0.0401003
[Epoch 22; Iter   363/ 1097] train: loss: 0.3235343
[Epoch 22; Iter   393/ 1097] train: loss: 0.0713632
[Epoch 22; Iter   423/ 1097] train: loss: 0.0542960
[Epoch 22; Iter   453/ 1097] train: loss: 0.0169880
[Epoch 22; Iter   483/ 1097] train: loss: 0.0407330
[Epoch 22; Iter   513/ 1097] train: loss: 0.3342171
[Epoch 22; Iter   543/ 1097] train: loss: 0.1683397
[Epoch 22; Iter   573/ 1097] train: loss: 0.0352714
[Epoch 22; Iter   603/ 1097] train: loss: 0.0273262
[Epoch 22; Iter   633/ 1097] train: loss: 0.0451227
[Epoch 22; Iter   663/ 1097] train: loss: 0.0330008
[Epoch 22; Iter   693/ 1097] train: loss: 0.1063064
[Epoch 22; Iter   723/ 1097] train: loss: 0.0584518
[Epoch 22; Iter   753/ 1097] train: loss: 0.2738324
[Epoch 22; Iter   783/ 1097] train: loss: 0.0301679
[Epoch 22; Iter   813/ 1097] train: loss: 0.1966799
[Epoch 22; Iter   843/ 1097] train: loss: 0.0310484
[Epoch 22; Iter   873/ 1097] train: loss: 0.0676262
[Epoch 22; Iter   903/ 1097] train: loss: 0.1560270
[Epoch 22; Iter   933/ 1097] train: loss: 0.0422125
[Epoch 22; Iter   963/ 1097] train: loss: 0.1714391
[Epoch 22; Iter   993/ 1097] train: loss: 0.1026809
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3385342
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0467646
[Epoch 22; Iter  1083/ 1097] train: loss: 0.2042454
[Epoch 22] ogbg-molhiv: 0.731237 val loss: 0.099085
[Epoch 22] ogbg-molhiv: 0.673321 test loss: 0.140630
[Epoch 23; Iter    16/ 1097] train: loss: 0.0447702
[Epoch 23; Iter    46/ 1097] train: loss: 0.1872901
[Epoch 23; Iter    76/ 1097] train: loss: 0.0486097
[Epoch 23; Iter   106/ 1097] train: loss: 0.1548188
[Epoch 23; Iter   136/ 1097] train: loss: 0.1133293
[Epoch 23; Iter   166/ 1097] train: loss: 0.2016506
[Epoch 23; Iter   196/ 1097] train: loss: 0.1356718
[Epoch 23; Iter   226/ 1097] train: loss: 0.1922907
[Epoch 23; Iter   256/ 1097] train: loss: 0.1200776
[Epoch 23; Iter   286/ 1097] train: loss: 0.0251906
[Epoch 23; Iter   316/ 1097] train: loss: 0.0283445
[Epoch 23; Iter   346/ 1097] train: loss: 0.0655000
[Epoch 23; Iter   376/ 1097] train: loss: 0.0253378
[Epoch 23; Iter   406/ 1097] train: loss: 0.2030009
[Epoch 23; Iter   436/ 1097] train: loss: 0.1164669
[Epoch 23; Iter   466/ 1097] train: loss: 0.0459176
[Epoch 23; Iter   496/ 1097] train: loss: 0.2132276
[Epoch 23; Iter   526/ 1097] train: loss: 0.0667270
[Epoch 23; Iter   556/ 1097] train: loss: 0.0608532
[Epoch 23; Iter   586/ 1097] train: loss: 0.1955508
[Epoch 23; Iter   616/ 1097] train: loss: 0.2130582
[Epoch 23; Iter   646/ 1097] train: loss: 0.1255108
[Epoch 23; Iter   676/ 1097] train: loss: 0.0328006
[Epoch 23; Iter   706/ 1097] train: loss: 0.1063674
[Epoch 23; Iter   736/ 1097] train: loss: 0.2650846
[Epoch 23; Iter   766/ 1097] train: loss: 0.2130021
[Epoch 23; Iter   796/ 1097] train: loss: 0.0348670
[Epoch 23; Iter   826/ 1097] train: loss: 0.2779133
[Epoch 23; Iter   856/ 1097] train: loss: 0.2135398
[Epoch 23; Iter   886/ 1097] train: loss: 0.1515735
[Epoch 23; Iter   916/ 1097] train: loss: 0.4121091
[Epoch 23; Iter   946/ 1097] train: loss: 0.0405576
[Epoch 23; Iter   976/ 1097] train: loss: 0.0941385
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0340976
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0321098
[Epoch 23; Iter  1066/ 1097] train: loss: 0.3228749
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1123159
[Epoch 23] ogbg-molhiv: 0.713897 val loss: 0.087582
[Epoch 23] ogbg-molhiv: 0.658047 test loss: 0.146160
[Epoch 24; Iter    29/ 1097] train: loss: 0.0750548
[Epoch 24; Iter    59/ 1097] train: loss: 0.2114842
[Epoch 24; Iter    89/ 1097] train: loss: 0.1863727
[Epoch 24; Iter   119/ 1097] train: loss: 0.0323116
[Epoch 24; Iter   149/ 1097] train: loss: 0.0465267
[Epoch 24; Iter   179/ 1097] train: loss: 0.0302826
[Epoch 24; Iter   209/ 1097] train: loss: 0.1283841
[Epoch 24; Iter   239/ 1097] train: loss: 0.0219935
[Epoch 24; Iter   269/ 1097] train: loss: 0.4333461
[Epoch 24; Iter   299/ 1097] train: loss: 0.0329955
[Epoch 24; Iter   329/ 1097] train: loss: 0.0843872
[Epoch 24; Iter   359/ 1097] train: loss: 0.1096332
[Epoch 20; Iter   307/ 1097] train: loss: 0.0384797
[Epoch 20; Iter   337/ 1097] train: loss: 0.1444360
[Epoch 20; Iter   367/ 1097] train: loss: 0.0350369
[Epoch 20; Iter   397/ 1097] train: loss: 0.0299659
[Epoch 20; Iter   427/ 1097] train: loss: 0.3576447
[Epoch 20; Iter   457/ 1097] train: loss: 0.1199534
[Epoch 20; Iter   487/ 1097] train: loss: 0.0943241
[Epoch 20; Iter   517/ 1097] train: loss: 0.0480373
[Epoch 20; Iter   547/ 1097] train: loss: 0.0256375
[Epoch 20; Iter   577/ 1097] train: loss: 0.0184464
[Epoch 20; Iter   607/ 1097] train: loss: 0.0243011
[Epoch 20; Iter   637/ 1097] train: loss: 0.2480425
[Epoch 20; Iter   667/ 1097] train: loss: 0.3316975
[Epoch 20; Iter   697/ 1097] train: loss: 0.0250091
[Epoch 20; Iter   727/ 1097] train: loss: 0.0223257
[Epoch 20; Iter   757/ 1097] train: loss: 0.2370970
[Epoch 20; Iter   787/ 1097] train: loss: 0.0337942
[Epoch 20; Iter   817/ 1097] train: loss: 0.0367211
[Epoch 20; Iter   847/ 1097] train: loss: 0.2925041
[Epoch 20; Iter   877/ 1097] train: loss: 0.2092906
[Epoch 20; Iter   907/ 1097] train: loss: 0.0616527
[Epoch 20; Iter   937/ 1097] train: loss: 0.1430957
[Epoch 20; Iter   967/ 1097] train: loss: 0.0438310
[Epoch 20; Iter   997/ 1097] train: loss: 0.0322796
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0711542
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1712683
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0491959
[Epoch 20] ogbg-molhiv: 0.773341 val loss: 0.302312
[Epoch 20] ogbg-molhiv: 0.777450 test loss: 0.285439
[Epoch 21; Iter    20/ 1097] train: loss: 0.0481883
[Epoch 21; Iter    50/ 1097] train: loss: 0.0288851
[Epoch 21; Iter    80/ 1097] train: loss: 0.0355024
[Epoch 21; Iter   110/ 1097] train: loss: 0.0346309
[Epoch 21; Iter   140/ 1097] train: loss: 0.2137221
[Epoch 21; Iter   170/ 1097] train: loss: 0.1647595
[Epoch 21; Iter   200/ 1097] train: loss: 0.0201008
[Epoch 21; Iter   230/ 1097] train: loss: 0.0688071
[Epoch 21; Iter   260/ 1097] train: loss: 0.0278624
[Epoch 21; Iter   290/ 1097] train: loss: 0.0532415
[Epoch 21; Iter   320/ 1097] train: loss: 0.1697983
[Epoch 21; Iter   350/ 1097] train: loss: 0.1618208
[Epoch 21; Iter   380/ 1097] train: loss: 0.0246667
[Epoch 21; Iter   410/ 1097] train: loss: 0.2820237
[Epoch 21; Iter   440/ 1097] train: loss: 0.3065719
[Epoch 21; Iter   470/ 1097] train: loss: 0.1331284
[Epoch 21; Iter   500/ 1097] train: loss: 0.1310048
[Epoch 21; Iter   530/ 1097] train: loss: 0.1023896
[Epoch 21; Iter   560/ 1097] train: loss: 0.1761233
[Epoch 21; Iter   590/ 1097] train: loss: 0.1504616
[Epoch 21; Iter   620/ 1097] train: loss: 0.2185814
[Epoch 21; Iter   650/ 1097] train: loss: 0.0256384
[Epoch 21; Iter   680/ 1097] train: loss: 0.0654872
[Epoch 21; Iter   710/ 1097] train: loss: 0.3113238
[Epoch 21; Iter   740/ 1097] train: loss: 0.0856737
[Epoch 21; Iter   770/ 1097] train: loss: 0.0662188
[Epoch 21; Iter   800/ 1097] train: loss: 0.2581063
[Epoch 21; Iter   830/ 1097] train: loss: 0.4463337
[Epoch 21; Iter   860/ 1097] train: loss: 0.0170319
[Epoch 21; Iter   890/ 1097] train: loss: 0.0435107
[Epoch 21; Iter   920/ 1097] train: loss: 0.1412588
[Epoch 21; Iter   950/ 1097] train: loss: 0.1873644
[Epoch 21; Iter   980/ 1097] train: loss: 0.1811428
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0422114
[Epoch 21; Iter  1040/ 1097] train: loss: 0.3155753
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0245805
[Epoch 21] ogbg-molhiv: 0.786073 val loss: 0.075023
[Epoch 21] ogbg-molhiv: 0.763514 test loss: 0.132018
[Epoch 22; Iter     3/ 1097] train: loss: 0.0347825
[Epoch 22; Iter    33/ 1097] train: loss: 0.0768408
[Epoch 22; Iter    63/ 1097] train: loss: 0.1666741
[Epoch 22; Iter    93/ 1097] train: loss: 0.0269058
[Epoch 22; Iter   123/ 1097] train: loss: 0.0230115
[Epoch 22; Iter   153/ 1097] train: loss: 0.0526606
[Epoch 22; Iter   183/ 1097] train: loss: 0.0544453
[Epoch 22; Iter   213/ 1097] train: loss: 0.0289785
[Epoch 22; Iter   243/ 1097] train: loss: 0.0299341
[Epoch 22; Iter   273/ 1097] train: loss: 0.1815428
[Epoch 22; Iter   303/ 1097] train: loss: 0.0279324
[Epoch 22; Iter   333/ 1097] train: loss: 0.0224406
[Epoch 22; Iter   363/ 1097] train: loss: 0.0506129
[Epoch 22; Iter   393/ 1097] train: loss: 0.0252072
[Epoch 22; Iter   423/ 1097] train: loss: 0.0478884
[Epoch 22; Iter   453/ 1097] train: loss: 0.1098576
[Epoch 22; Iter   483/ 1097] train: loss: 0.0441092
[Epoch 22; Iter   513/ 1097] train: loss: 0.0277553
[Epoch 22; Iter   543/ 1097] train: loss: 0.0955549
[Epoch 22; Iter   573/ 1097] train: loss: 0.0569314
[Epoch 22; Iter   603/ 1097] train: loss: 0.0702378
[Epoch 22; Iter   633/ 1097] train: loss: 0.0196222
[Epoch 22; Iter   663/ 1097] train: loss: 0.0608453
[Epoch 22; Iter   693/ 1097] train: loss: 0.0235898
[Epoch 22; Iter   723/ 1097] train: loss: 0.0230820
[Epoch 22; Iter   753/ 1097] train: loss: 0.0390282
[Epoch 22; Iter   783/ 1097] train: loss: 0.3084447
[Epoch 22; Iter   813/ 1097] train: loss: 0.0359389
[Epoch 22; Iter   843/ 1097] train: loss: 0.1693641
[Epoch 22; Iter   873/ 1097] train: loss: 0.0978028
[Epoch 22; Iter   903/ 1097] train: loss: 0.0319972
[Epoch 22; Iter   933/ 1097] train: loss: 0.0532025
[Epoch 22; Iter   963/ 1097] train: loss: 0.1789516
[Epoch 22; Iter   993/ 1097] train: loss: 0.0266612
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0597694
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0914183
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0345459
[Epoch 22] ogbg-molhiv: 0.790574 val loss: 0.077625
[Epoch 22] ogbg-molhiv: 0.783822 test loss: 0.113062
[Epoch 23; Iter    16/ 1097] train: loss: 0.1084606
[Epoch 23; Iter    46/ 1097] train: loss: 0.0324070
[Epoch 23; Iter    76/ 1097] train: loss: 0.0626053
[Epoch 23; Iter   106/ 1097] train: loss: 0.0222363
[Epoch 23; Iter   136/ 1097] train: loss: 0.1038566
[Epoch 23; Iter   166/ 1097] train: loss: 0.1813852
[Epoch 23; Iter   196/ 1097] train: loss: 0.2088676
[Epoch 23; Iter   226/ 1097] train: loss: 0.1165930
[Epoch 23; Iter   256/ 1097] train: loss: 0.0304095
[Epoch 23; Iter   286/ 1097] train: loss: 0.0672176
[Epoch 23; Iter   316/ 1097] train: loss: 0.0347961
[Epoch 23; Iter   346/ 1097] train: loss: 0.0476900
[Epoch 23; Iter   376/ 1097] train: loss: 0.1311478
[Epoch 23; Iter   406/ 1097] train: loss: 0.0593363
[Epoch 23; Iter   436/ 1097] train: loss: 0.1775497
[Epoch 23; Iter   466/ 1097] train: loss: 0.0564538
[Epoch 23; Iter   496/ 1097] train: loss: 0.0893765
[Epoch 23; Iter   526/ 1097] train: loss: 0.0262980
[Epoch 23; Iter   556/ 1097] train: loss: 0.0745250
[Epoch 23; Iter   586/ 1097] train: loss: 0.0490471
[Epoch 23; Iter   616/ 1097] train: loss: 0.0208725
[Epoch 23; Iter   646/ 1097] train: loss: 0.0310557
[Epoch 23; Iter   676/ 1097] train: loss: 0.2233839
[Epoch 23; Iter   706/ 1097] train: loss: 0.0403848
[Epoch 23; Iter   736/ 1097] train: loss: 0.0473306
[Epoch 23; Iter   766/ 1097] train: loss: 0.1908877
[Epoch 23; Iter   796/ 1097] train: loss: 0.1217505
[Epoch 23; Iter   826/ 1097] train: loss: 0.0933664
[Epoch 23; Iter   856/ 1097] train: loss: 0.0266955
[Epoch 23; Iter   886/ 1097] train: loss: 0.0336544
[Epoch 23; Iter   916/ 1097] train: loss: 0.0422740
[Epoch 23; Iter   946/ 1097] train: loss: 0.0302481
[Epoch 23; Iter   976/ 1097] train: loss: 0.0271334
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1530057
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0818322
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0238338
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1781314
[Epoch 23] ogbg-molhiv: 0.727865 val loss: 0.106662
[Epoch 23] ogbg-molhiv: 0.725221 test loss: 0.142425
[Epoch 24; Iter    29/ 1097] train: loss: 0.0188024
[Epoch 24; Iter    59/ 1097] train: loss: 0.0758630
[Epoch 24; Iter    89/ 1097] train: loss: 0.3071546
[Epoch 24; Iter   119/ 1097] train: loss: 0.0449337
[Epoch 24; Iter   149/ 1097] train: loss: 0.1236351
[Epoch 24; Iter   179/ 1097] train: loss: 0.1775485
[Epoch 24; Iter   209/ 1097] train: loss: 0.0538771
[Epoch 24; Iter   239/ 1097] train: loss: 0.3179088
[Epoch 24; Iter   269/ 1097] train: loss: 0.0731820
[Epoch 24; Iter   299/ 1097] train: loss: 0.0269014
[Epoch 24; Iter   329/ 1097] train: loss: 0.3814151
[Epoch 24; Iter   359/ 1097] train: loss: 0.1694825
[Epoch 24; Iter   359/ 1097] train: loss: 0.1511117
[Epoch 24; Iter   389/ 1097] train: loss: 0.1004988
[Epoch 24; Iter   419/ 1097] train: loss: 0.3419740
[Epoch 24; Iter   449/ 1097] train: loss: 0.0176928
[Epoch 24; Iter   479/ 1097] train: loss: 0.0226919
[Epoch 24; Iter   509/ 1097] train: loss: 0.0114065
[Epoch 24; Iter   539/ 1097] train: loss: 0.0131153
[Epoch 24; Iter   569/ 1097] train: loss: 0.1373117
[Epoch 24; Iter   599/ 1097] train: loss: 0.2518379
[Epoch 24; Iter   629/ 1097] train: loss: 0.0251693
[Epoch 24; Iter   659/ 1097] train: loss: 0.0139647
[Epoch 24; Iter   689/ 1097] train: loss: 0.0157931
[Epoch 24; Iter   719/ 1097] train: loss: 0.0222718
[Epoch 24; Iter   749/ 1097] train: loss: 0.0418959
[Epoch 24; Iter   779/ 1097] train: loss: 0.1114793
[Epoch 24; Iter   809/ 1097] train: loss: 0.0285989
[Epoch 24; Iter   839/ 1097] train: loss: 0.1034722
[Epoch 24; Iter   869/ 1097] train: loss: 0.1811600
[Epoch 24; Iter   899/ 1097] train: loss: 0.2596969
[Epoch 24; Iter   929/ 1097] train: loss: 0.1168389
[Epoch 24; Iter   959/ 1097] train: loss: 0.0213015
[Epoch 24; Iter   989/ 1097] train: loss: 0.0354757
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2188226
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0877458
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0609186
[Epoch 24] ogbg-molhiv: 0.817610 val loss: 1.141872
[Epoch 24] ogbg-molhiv: 0.761505 test loss: 0.338423
[Epoch 25; Iter    12/ 1097] train: loss: 0.0145691
[Epoch 25; Iter    42/ 1097] train: loss: 0.0998577
[Epoch 25; Iter    72/ 1097] train: loss: 0.0242631
[Epoch 25; Iter   102/ 1097] train: loss: 0.0725534
[Epoch 25; Iter   132/ 1097] train: loss: 0.0271498
[Epoch 25; Iter   162/ 1097] train: loss: 0.0211448
[Epoch 25; Iter   192/ 1097] train: loss: 0.1178366
[Epoch 25; Iter   222/ 1097] train: loss: 0.0140267
[Epoch 25; Iter   252/ 1097] train: loss: 0.0579946
[Epoch 25; Iter   282/ 1097] train: loss: 0.1539342
[Epoch 25; Iter   312/ 1097] train: loss: 0.0114002
[Epoch 25; Iter   342/ 1097] train: loss: 0.0361224
[Epoch 25; Iter   372/ 1097] train: loss: 0.3335908
[Epoch 25; Iter   402/ 1097] train: loss: 0.0211196
[Epoch 25; Iter   432/ 1097] train: loss: 0.2282488
[Epoch 25; Iter   462/ 1097] train: loss: 0.0480338
[Epoch 25; Iter   492/ 1097] train: loss: 0.1592331
[Epoch 25; Iter   522/ 1097] train: loss: 0.0205501
[Epoch 25; Iter   552/ 1097] train: loss: 0.1126676
[Epoch 25; Iter   582/ 1097] train: loss: 0.0846952
[Epoch 25; Iter   612/ 1097] train: loss: 0.1168246
[Epoch 25; Iter   642/ 1097] train: loss: 0.1335362
[Epoch 25; Iter   672/ 1097] train: loss: 0.0261384
[Epoch 25; Iter   702/ 1097] train: loss: 0.1471384
[Epoch 25; Iter   732/ 1097] train: loss: 0.0287996
[Epoch 25; Iter   762/ 1097] train: loss: 0.1676712
[Epoch 25; Iter   792/ 1097] train: loss: 0.0131968
[Epoch 25; Iter   822/ 1097] train: loss: 0.0611207
[Epoch 25; Iter   852/ 1097] train: loss: 0.0333453
[Epoch 25; Iter   882/ 1097] train: loss: 0.1263848
[Epoch 25; Iter   912/ 1097] train: loss: 0.0789741
[Epoch 25; Iter   942/ 1097] train: loss: 0.0307219
[Epoch 25; Iter   972/ 1097] train: loss: 0.0535504
[Epoch 25; Iter  1002/ 1097] train: loss: 0.3459518
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2761637
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0366014
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1715873
[Epoch 25] ogbg-molhiv: 0.824328 val loss: 1.245805
[Epoch 25] ogbg-molhiv: 0.711999 test loss: 0.540707
[Epoch 26; Iter    25/ 1097] train: loss: 0.0306030
[Epoch 26; Iter    55/ 1097] train: loss: 0.0283974
[Epoch 26; Iter    85/ 1097] train: loss: 0.0882052
[Epoch 26; Iter   115/ 1097] train: loss: 0.1133520
[Epoch 26; Iter   145/ 1097] train: loss: 0.0230693
[Epoch 26; Iter   175/ 1097] train: loss: 0.0712228
[Epoch 26; Iter   205/ 1097] train: loss: 0.3990269
[Epoch 26; Iter   235/ 1097] train: loss: 0.0155980
[Epoch 26; Iter   265/ 1097] train: loss: 0.0169352
[Epoch 26; Iter   295/ 1097] train: loss: 0.1114658
[Epoch 26; Iter   325/ 1097] train: loss: 0.0402176
[Epoch 26; Iter   355/ 1097] train: loss: 0.0134309
[Epoch 26; Iter   385/ 1097] train: loss: 0.0208930
[Epoch 26; Iter   415/ 1097] train: loss: 0.0263098
[Epoch 26; Iter   445/ 1097] train: loss: 0.0242065
[Epoch 26; Iter   475/ 1097] train: loss: 0.0956393
[Epoch 26; Iter   505/ 1097] train: loss: 0.1103196
[Epoch 26; Iter   535/ 1097] train: loss: 0.0629956
[Epoch 26; Iter   565/ 1097] train: loss: 0.1182200
[Epoch 26; Iter   595/ 1097] train: loss: 0.0341118
[Epoch 26; Iter   625/ 1097] train: loss: 0.0639390
[Epoch 26; Iter   655/ 1097] train: loss: 0.0222456
[Epoch 26; Iter   685/ 1097] train: loss: 0.0789324
[Epoch 26; Iter   715/ 1097] train: loss: 0.0189613
[Epoch 26; Iter   745/ 1097] train: loss: 0.0253772
[Epoch 26; Iter   775/ 1097] train: loss: 0.0413306
[Epoch 26; Iter   805/ 1097] train: loss: 0.1237791
[Epoch 26; Iter   835/ 1097] train: loss: 0.0774705
[Epoch 26; Iter   865/ 1097] train: loss: 0.1240562
[Epoch 26; Iter   895/ 1097] train: loss: 0.0241226
[Epoch 26; Iter   925/ 1097] train: loss: 0.2506853
[Epoch 26; Iter   955/ 1097] train: loss: 0.0392104
[Epoch 26; Iter   985/ 1097] train: loss: 0.0762719
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0226122
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0280519
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1043076
[Epoch 26] ogbg-molhiv: 0.814729 val loss: 2.122447
[Epoch 26] ogbg-molhiv: 0.747523 test loss: 0.893791
[Epoch 27; Iter     8/ 1097] train: loss: 0.0176187
[Epoch 27; Iter    38/ 1097] train: loss: 0.0185071
[Epoch 27; Iter    68/ 1097] train: loss: 0.0307337
[Epoch 27; Iter    98/ 1097] train: loss: 0.3481110
[Epoch 27; Iter   128/ 1097] train: loss: 0.1680071
[Epoch 27; Iter   158/ 1097] train: loss: 0.0556573
[Epoch 27; Iter   188/ 1097] train: loss: 0.0152811
[Epoch 27; Iter   218/ 1097] train: loss: 0.0371126
[Epoch 27; Iter   248/ 1097] train: loss: 0.0780047
[Epoch 27; Iter   278/ 1097] train: loss: 0.0273525
[Epoch 27; Iter   308/ 1097] train: loss: 0.0295130
[Epoch 27; Iter   338/ 1097] train: loss: 0.0161714
[Epoch 27; Iter   368/ 1097] train: loss: 0.2396028
[Epoch 27; Iter   398/ 1097] train: loss: 0.0200617
[Epoch 27; Iter   428/ 1097] train: loss: 0.0756947
[Epoch 27; Iter   458/ 1097] train: loss: 0.0145241
[Epoch 27; Iter   488/ 1097] train: loss: 0.0958791
[Epoch 27; Iter   518/ 1097] train: loss: 0.0401180
[Epoch 27; Iter   548/ 1097] train: loss: 0.2015164
[Epoch 27; Iter   578/ 1097] train: loss: 0.0995413
[Epoch 27; Iter   608/ 1097] train: loss: 0.1210023
[Epoch 27; Iter   638/ 1097] train: loss: 0.0260185
[Epoch 27; Iter   668/ 1097] train: loss: 0.0393298
[Epoch 27; Iter   698/ 1097] train: loss: 0.0547734
[Epoch 27; Iter   728/ 1097] train: loss: 0.1514109
[Epoch 27; Iter   758/ 1097] train: loss: 0.0245984
[Epoch 27; Iter   788/ 1097] train: loss: 0.0139738
[Epoch 27; Iter   818/ 1097] train: loss: 0.0347288
[Epoch 27; Iter   848/ 1097] train: loss: 0.1137583
[Epoch 27; Iter   878/ 1097] train: loss: 0.0136349
[Epoch 27; Iter   908/ 1097] train: loss: 0.0272991
[Epoch 27; Iter   938/ 1097] train: loss: 0.1359738
[Epoch 27; Iter   968/ 1097] train: loss: 0.0264943
[Epoch 27; Iter   998/ 1097] train: loss: 0.1172263
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0185113
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2395762
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0462862
[Epoch 27] ogbg-molhiv: 0.825314 val loss: 0.258720
[Epoch 27] ogbg-molhiv: 0.734112 test loss: 0.314616
[Epoch 28; Iter    21/ 1097] train: loss: 0.0298340
[Epoch 28; Iter    51/ 1097] train: loss: 0.0443646
[Epoch 28; Iter    81/ 1097] train: loss: 0.0189729
[Epoch 28; Iter   111/ 1097] train: loss: 0.1440660
[Epoch 28; Iter   141/ 1097] train: loss: 0.1004468
[Epoch 28; Iter   171/ 1097] train: loss: 0.2291115
[Epoch 28; Iter   201/ 1097] train: loss: 0.0580558
[Epoch 28; Iter   231/ 1097] train: loss: 0.0182590
[Epoch 28; Iter   261/ 1097] train: loss: 0.0846982
[Epoch 28; Iter   291/ 1097] train: loss: 0.0305746
[Epoch 28; Iter   321/ 1097] train: loss: 0.0351899
[Epoch 28; Iter   351/ 1097] train: loss: 0.0095893
[Epoch 28; Iter   381/ 1097] train: loss: 0.0695930
[Epoch 28; Iter   411/ 1097] train: loss: 0.0224257
[Epoch 20; Iter   307/ 1097] train: loss: 0.0759518
[Epoch 20; Iter   337/ 1097] train: loss: 0.2170752
[Epoch 20; Iter   367/ 1097] train: loss: 0.4048352
[Epoch 20; Iter   397/ 1097] train: loss: 0.0492287
[Epoch 20; Iter   427/ 1097] train: loss: 0.0433664
[Epoch 20; Iter   457/ 1097] train: loss: 0.0641990
[Epoch 20; Iter   487/ 1097] train: loss: 0.1162904
[Epoch 20; Iter   517/ 1097] train: loss: 0.0713770
[Epoch 20; Iter   547/ 1097] train: loss: 0.1953576
[Epoch 20; Iter   577/ 1097] train: loss: 0.0379951
[Epoch 20; Iter   607/ 1097] train: loss: 0.2598737
[Epoch 20; Iter   637/ 1097] train: loss: 0.1110846
[Epoch 20; Iter   667/ 1097] train: loss: 0.1093866
[Epoch 20; Iter   697/ 1097] train: loss: 0.0324807
[Epoch 20; Iter   727/ 1097] train: loss: 0.1258023
[Epoch 20; Iter   757/ 1097] train: loss: 0.1535759
[Epoch 20; Iter   787/ 1097] train: loss: 0.0761190
[Epoch 20; Iter   817/ 1097] train: loss: 0.1886587
[Epoch 20; Iter   847/ 1097] train: loss: 0.0268271
[Epoch 20; Iter   877/ 1097] train: loss: 0.1664642
[Epoch 20; Iter   907/ 1097] train: loss: 0.2018102
[Epoch 20; Iter   937/ 1097] train: loss: 0.0583500
[Epoch 20; Iter   967/ 1097] train: loss: 0.0652645
[Epoch 20; Iter   997/ 1097] train: loss: 0.1199539
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1552399
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4169936
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2454712
[Epoch 20] ogbg-molhiv: 0.824365 val loss: 0.366165
[Epoch 20] ogbg-molhiv: 0.771967 test loss: 0.247342
[Epoch 21; Iter    20/ 1097] train: loss: 0.0349087
[Epoch 21; Iter    50/ 1097] train: loss: 0.2103157
[Epoch 21; Iter    80/ 1097] train: loss: 0.0326737
[Epoch 21; Iter   110/ 1097] train: loss: 0.0462843
[Epoch 21; Iter   140/ 1097] train: loss: 0.1717364
[Epoch 21; Iter   170/ 1097] train: loss: 0.1193364
[Epoch 21; Iter   200/ 1097] train: loss: 0.0254698
[Epoch 21; Iter   230/ 1097] train: loss: 0.0672900
[Epoch 21; Iter   260/ 1097] train: loss: 0.2337340
[Epoch 21; Iter   290/ 1097] train: loss: 0.0845674
[Epoch 21; Iter   320/ 1097] train: loss: 0.1051127
[Epoch 21; Iter   350/ 1097] train: loss: 0.1958246
[Epoch 21; Iter   380/ 1097] train: loss: 0.0580832
[Epoch 21; Iter   410/ 1097] train: loss: 0.0384727
[Epoch 21; Iter   440/ 1097] train: loss: 0.2302276
[Epoch 21; Iter   470/ 1097] train: loss: 0.0832819
[Epoch 21; Iter   500/ 1097] train: loss: 0.2876660
[Epoch 21; Iter   530/ 1097] train: loss: 0.1809234
[Epoch 21; Iter   560/ 1097] train: loss: 0.0489090
[Epoch 21; Iter   590/ 1097] train: loss: 0.0272355
[Epoch 21; Iter   620/ 1097] train: loss: 0.2063293
[Epoch 21; Iter   650/ 1097] train: loss: 0.0496739
[Epoch 21; Iter   680/ 1097] train: loss: 0.0289985
[Epoch 21; Iter   710/ 1097] train: loss: 0.0184892
[Epoch 21; Iter   740/ 1097] train: loss: 0.0392196
[Epoch 21; Iter   770/ 1097] train: loss: 0.1625542
[Epoch 21; Iter   800/ 1097] train: loss: 0.0477484
[Epoch 21; Iter   830/ 1097] train: loss: 0.0759743
[Epoch 21; Iter   860/ 1097] train: loss: 0.0297225
[Epoch 21; Iter   890/ 1097] train: loss: 0.0497529
[Epoch 21; Iter   920/ 1097] train: loss: 0.0934040
[Epoch 21; Iter   950/ 1097] train: loss: 0.0460175
[Epoch 21; Iter   980/ 1097] train: loss: 0.2309618
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1679554
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0261370
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0212955
[Epoch 21] ogbg-molhiv: 0.798054 val loss: 0.432664
[Epoch 21] ogbg-molhiv: 0.728674 test loss: 0.265075
[Epoch 22; Iter     3/ 1097] train: loss: 0.0431253
[Epoch 22; Iter    33/ 1097] train: loss: 0.3791707
[Epoch 22; Iter    63/ 1097] train: loss: 0.2303277
[Epoch 22; Iter    93/ 1097] train: loss: 0.0324998
[Epoch 22; Iter   123/ 1097] train: loss: 0.1886307
[Epoch 22; Iter   153/ 1097] train: loss: 0.2961527
[Epoch 22; Iter   183/ 1097] train: loss: 0.1794580
[Epoch 22; Iter   213/ 1097] train: loss: 0.0402684
[Epoch 22; Iter   243/ 1097] train: loss: 0.0284182
[Epoch 22; Iter   273/ 1097] train: loss: 0.0639151
[Epoch 22; Iter   303/ 1097] train: loss: 0.0853607
[Epoch 22; Iter   333/ 1097] train: loss: 0.1524242
[Epoch 22; Iter   363/ 1097] train: loss: 0.0609771
[Epoch 22; Iter   393/ 1097] train: loss: 0.1508750
[Epoch 22; Iter   423/ 1097] train: loss: 0.0255306
[Epoch 22; Iter   453/ 1097] train: loss: 0.0337657
[Epoch 22; Iter   483/ 1097] train: loss: 0.1902502
[Epoch 22; Iter   513/ 1097] train: loss: 0.0440962
[Epoch 22; Iter   543/ 1097] train: loss: 0.0294879
[Epoch 22; Iter   573/ 1097] train: loss: 0.1148247
[Epoch 22; Iter   603/ 1097] train: loss: 0.0206557
[Epoch 22; Iter   633/ 1097] train: loss: 0.0301539
[Epoch 22; Iter   663/ 1097] train: loss: 0.0705151
[Epoch 22; Iter   693/ 1097] train: loss: 0.0207147
[Epoch 22; Iter   723/ 1097] train: loss: 0.0481372
[Epoch 22; Iter   753/ 1097] train: loss: 0.2030466
[Epoch 22; Iter   783/ 1097] train: loss: 0.1936544
[Epoch 22; Iter   813/ 1097] train: loss: 0.0201168
[Epoch 22; Iter   843/ 1097] train: loss: 0.0254969
[Epoch 22; Iter   873/ 1097] train: loss: 0.1382969
[Epoch 22; Iter   903/ 1097] train: loss: 0.0316929
[Epoch 22; Iter   933/ 1097] train: loss: 0.0242214
[Epoch 22; Iter   963/ 1097] train: loss: 0.2605142
[Epoch 22; Iter   993/ 1097] train: loss: 0.0803618
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0286003
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1294989
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0189063
[Epoch 22] ogbg-molhiv: 0.818492 val loss: 0.714295
[Epoch 22] ogbg-molhiv: 0.744613 test loss: 0.579448
[Epoch 23; Iter    16/ 1097] train: loss: 0.0210972
[Epoch 23; Iter    46/ 1097] train: loss: 0.0824506
[Epoch 23; Iter    76/ 1097] train: loss: 0.0435916
[Epoch 23; Iter   106/ 1097] train: loss: 0.0254406
[Epoch 23; Iter   136/ 1097] train: loss: 0.1802909
[Epoch 23; Iter   166/ 1097] train: loss: 0.0584729
[Epoch 23; Iter   196/ 1097] train: loss: 0.3779446
[Epoch 23; Iter   226/ 1097] train: loss: 0.0913657
[Epoch 23; Iter   256/ 1097] train: loss: 0.0507666
[Epoch 23; Iter   286/ 1097] train: loss: 0.0277641
[Epoch 23; Iter   316/ 1097] train: loss: 0.3891622
[Epoch 23; Iter   346/ 1097] train: loss: 0.1777428
[Epoch 23; Iter   376/ 1097] train: loss: 0.2169679
[Epoch 23; Iter   406/ 1097] train: loss: 0.0872140
[Epoch 23; Iter   436/ 1097] train: loss: 0.1941264
[Epoch 23; Iter   466/ 1097] train: loss: 0.1426800
[Epoch 23; Iter   496/ 1097] train: loss: 0.0975770
[Epoch 23; Iter   526/ 1097] train: loss: 0.0247851
[Epoch 23; Iter   556/ 1097] train: loss: 0.1796378
[Epoch 23; Iter   586/ 1097] train: loss: 0.0330696
[Epoch 23; Iter   616/ 1097] train: loss: 0.0267410
[Epoch 23; Iter   646/ 1097] train: loss: 0.0250763
[Epoch 23; Iter   676/ 1097] train: loss: 0.0236375
[Epoch 23; Iter   706/ 1097] train: loss: 0.0618888
[Epoch 23; Iter   736/ 1097] train: loss: 0.1650427
[Epoch 23; Iter   766/ 1097] train: loss: 0.0347637
[Epoch 23; Iter   796/ 1097] train: loss: 0.2789969
[Epoch 23; Iter   826/ 1097] train: loss: 0.0392285
[Epoch 23; Iter   856/ 1097] train: loss: 0.2325430
[Epoch 23; Iter   886/ 1097] train: loss: 0.1022836
[Epoch 23; Iter   916/ 1097] train: loss: 0.0878835
[Epoch 23; Iter   946/ 1097] train: loss: 0.2444933
[Epoch 23; Iter   976/ 1097] train: loss: 0.0232802
[Epoch 23; Iter  1006/ 1097] train: loss: 0.2324053
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0547909
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1847824
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0392368
[Epoch 23] ogbg-molhiv: 0.807812 val loss: 6.266941
[Epoch 23] ogbg-molhiv: 0.699527 test loss: 1.323739
[Epoch 24; Iter    29/ 1097] train: loss: 0.0185911
[Epoch 24; Iter    59/ 1097] train: loss: 0.1344338
[Epoch 24; Iter    89/ 1097] train: loss: 0.0282502
[Epoch 24; Iter   119/ 1097] train: loss: 0.0737797
[Epoch 24; Iter   149/ 1097] train: loss: 0.3668453
[Epoch 24; Iter   179/ 1097] train: loss: 0.0402721
[Epoch 24; Iter   209/ 1097] train: loss: 0.0410096
[Epoch 24; Iter   239/ 1097] train: loss: 0.0790563
[Epoch 24; Iter   269/ 1097] train: loss: 0.0314267
[Epoch 24; Iter   299/ 1097] train: loss: 0.1168493
[Epoch 24; Iter   329/ 1097] train: loss: 0.0530753
[Epoch 24; Iter   359/ 1097] train: loss: 0.0756894
[Epoch 20; Iter   307/ 1097] train: loss: 0.1633679
[Epoch 20; Iter   337/ 1097] train: loss: 0.1582126
[Epoch 20; Iter   367/ 1097] train: loss: 0.0405457
[Epoch 20; Iter   397/ 1097] train: loss: 0.0337595
[Epoch 20; Iter   427/ 1097] train: loss: 0.0162316
[Epoch 20; Iter   457/ 1097] train: loss: 0.1409997
[Epoch 20; Iter   487/ 1097] train: loss: 0.1695321
[Epoch 20; Iter   517/ 1097] train: loss: 0.0320811
[Epoch 20; Iter   547/ 1097] train: loss: 0.1534262
[Epoch 20; Iter   577/ 1097] train: loss: 0.0214867
[Epoch 20; Iter   607/ 1097] train: loss: 0.0189765
[Epoch 20; Iter   637/ 1097] train: loss: 0.0351985
[Epoch 20; Iter   667/ 1097] train: loss: 0.2136413
[Epoch 20; Iter   697/ 1097] train: loss: 0.0906451
[Epoch 20; Iter   727/ 1097] train: loss: 0.1078795
[Epoch 20; Iter   757/ 1097] train: loss: 0.0173600
[Epoch 20; Iter   787/ 1097] train: loss: 0.0264493
[Epoch 20; Iter   817/ 1097] train: loss: 0.1192115
[Epoch 20; Iter   847/ 1097] train: loss: 0.0328745
[Epoch 20; Iter   877/ 1097] train: loss: 0.1435462
[Epoch 20; Iter   907/ 1097] train: loss: 0.2349509
[Epoch 20; Iter   937/ 1097] train: loss: 0.0172823
[Epoch 20; Iter   967/ 1097] train: loss: 0.0884388
[Epoch 20; Iter   997/ 1097] train: loss: 0.1304158
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0316457
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0553759
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0247422
[Epoch 20] ogbg-molhiv: 0.813866 val loss: 0.113636
[Epoch 20] ogbg-molhiv: 0.754692 test loss: 0.115516
[Epoch 21; Iter    20/ 1097] train: loss: 0.0237990
[Epoch 21; Iter    50/ 1097] train: loss: 0.2312318
[Epoch 21; Iter    80/ 1097] train: loss: 0.0440411
[Epoch 21; Iter   110/ 1097] train: loss: 0.0482074
[Epoch 21; Iter   140/ 1097] train: loss: 0.1334821
[Epoch 21; Iter   170/ 1097] train: loss: 0.1440662
[Epoch 21; Iter   200/ 1097] train: loss: 0.1441502
[Epoch 21; Iter   230/ 1097] train: loss: 0.1585799
[Epoch 21; Iter   260/ 1097] train: loss: 0.1956731
[Epoch 21; Iter   290/ 1097] train: loss: 0.1919216
[Epoch 21; Iter   320/ 1097] train: loss: 0.2628069
[Epoch 21; Iter   350/ 1097] train: loss: 0.0187993
[Epoch 21; Iter   380/ 1097] train: loss: 0.0488142
[Epoch 21; Iter   410/ 1097] train: loss: 0.0723558
[Epoch 21; Iter   440/ 1097] train: loss: 0.1133730
[Epoch 21; Iter   470/ 1097] train: loss: 0.1214610
[Epoch 21; Iter   500/ 1097] train: loss: 0.0227979
[Epoch 21; Iter   530/ 1097] train: loss: 0.0228778
[Epoch 21; Iter   560/ 1097] train: loss: 0.0359510
[Epoch 21; Iter   590/ 1097] train: loss: 0.1731501
[Epoch 21; Iter   620/ 1097] train: loss: 0.1509816
[Epoch 21; Iter   650/ 1097] train: loss: 0.2213881
[Epoch 21; Iter   680/ 1097] train: loss: 0.0632554
[Epoch 21; Iter   710/ 1097] train: loss: 0.0317930
[Epoch 21; Iter   740/ 1097] train: loss: 0.0540482
[Epoch 21; Iter   770/ 1097] train: loss: 0.0551159
[Epoch 21; Iter   800/ 1097] train: loss: 0.0401318
[Epoch 21; Iter   830/ 1097] train: loss: 0.1888841
[Epoch 21; Iter   860/ 1097] train: loss: 0.0454547
[Epoch 21; Iter   890/ 1097] train: loss: 0.0236690
[Epoch 21; Iter   920/ 1097] train: loss: 0.1357593
[Epoch 21; Iter   950/ 1097] train: loss: 0.0395824
[Epoch 21; Iter   980/ 1097] train: loss: 0.0229479
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0236946
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1563823
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0370563
[Epoch 21] ogbg-molhiv: 0.820293 val loss: 0.124400
[Epoch 21] ogbg-molhiv: 0.766940 test loss: 0.114990
[Epoch 22; Iter     3/ 1097] train: loss: 0.1374613
[Epoch 22; Iter    33/ 1097] train: loss: 0.0238389
[Epoch 22; Iter    63/ 1097] train: loss: 0.0509411
[Epoch 22; Iter    93/ 1097] train: loss: 0.0434598
[Epoch 22; Iter   123/ 1097] train: loss: 0.0707780
[Epoch 22; Iter   153/ 1097] train: loss: 0.0508950
[Epoch 22; Iter   183/ 1097] train: loss: 0.0308815
[Epoch 22; Iter   213/ 1097] train: loss: 0.1353578
[Epoch 22; Iter   243/ 1097] train: loss: 0.1521333
[Epoch 22; Iter   273/ 1097] train: loss: 0.1647282
[Epoch 22; Iter   303/ 1097] train: loss: 0.1501414
[Epoch 22; Iter   333/ 1097] train: loss: 0.0287165
[Epoch 22; Iter   363/ 1097] train: loss: 0.2768609
[Epoch 22; Iter   393/ 1097] train: loss: 0.0319897
[Epoch 22; Iter   423/ 1097] train: loss: 0.0540400
[Epoch 22; Iter   453/ 1097] train: loss: 0.0135853
[Epoch 22; Iter   483/ 1097] train: loss: 0.0913835
[Epoch 22; Iter   513/ 1097] train: loss: 0.4325496
[Epoch 22; Iter   543/ 1097] train: loss: 0.1410353
[Epoch 22; Iter   573/ 1097] train: loss: 0.0606623
[Epoch 22; Iter   603/ 1097] train: loss: 0.0319044
[Epoch 22; Iter   633/ 1097] train: loss: 0.0223231
[Epoch 22; Iter   663/ 1097] train: loss: 0.0365594
[Epoch 22; Iter   693/ 1097] train: loss: 0.1601581
[Epoch 22; Iter   723/ 1097] train: loss: 0.2019242
[Epoch 22; Iter   753/ 1097] train: loss: 0.2327008
[Epoch 22; Iter   783/ 1097] train: loss: 0.0275442
[Epoch 22; Iter   813/ 1097] train: loss: 0.1698862
[Epoch 22; Iter   843/ 1097] train: loss: 0.0310608
[Epoch 22; Iter   873/ 1097] train: loss: 0.1441360
[Epoch 22; Iter   903/ 1097] train: loss: 0.2105766
[Epoch 22; Iter   933/ 1097] train: loss: 0.0282392
[Epoch 22; Iter   963/ 1097] train: loss: 0.2809891
[Epoch 22; Iter   993/ 1097] train: loss: 0.2353135
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3894172
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0178531
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1128246
[Epoch 22] ogbg-molhiv: 0.755628 val loss: 0.084491
[Epoch 22] ogbg-molhiv: 0.729728 test loss: 0.118559
[Epoch 23; Iter    16/ 1097] train: loss: 0.0951498
[Epoch 23; Iter    46/ 1097] train: loss: 0.2380370
[Epoch 23; Iter    76/ 1097] train: loss: 0.1154134
[Epoch 23; Iter   106/ 1097] train: loss: 0.1869825
[Epoch 23; Iter   136/ 1097] train: loss: 0.0979901
[Epoch 23; Iter   166/ 1097] train: loss: 0.1815917
[Epoch 23; Iter   196/ 1097] train: loss: 0.1174623
[Epoch 23; Iter   226/ 1097] train: loss: 0.0636590
[Epoch 23; Iter   256/ 1097] train: loss: 0.1523606
[Epoch 23; Iter   286/ 1097] train: loss: 0.0263816
[Epoch 23; Iter   316/ 1097] train: loss: 0.0480059
[Epoch 23; Iter   346/ 1097] train: loss: 0.0299418
[Epoch 23; Iter   376/ 1097] train: loss: 0.0237194
[Epoch 23; Iter   406/ 1097] train: loss: 0.1934955
[Epoch 23; Iter   436/ 1097] train: loss: 0.0603387
[Epoch 23; Iter   466/ 1097] train: loss: 0.0202910
[Epoch 23; Iter   496/ 1097] train: loss: 0.1857125
[Epoch 23; Iter   526/ 1097] train: loss: 0.0515104
[Epoch 23; Iter   556/ 1097] train: loss: 0.0280769
[Epoch 23; Iter   586/ 1097] train: loss: 0.1444896
[Epoch 23; Iter   616/ 1097] train: loss: 0.1070198
[Epoch 23; Iter   646/ 1097] train: loss: 0.1575769
[Epoch 23; Iter   676/ 1097] train: loss: 0.1063209
[Epoch 23; Iter   706/ 1097] train: loss: 0.0251784
[Epoch 23; Iter   736/ 1097] train: loss: 0.2353632
[Epoch 23; Iter   766/ 1097] train: loss: 0.1392878
[Epoch 23; Iter   796/ 1097] train: loss: 0.0473424
[Epoch 23; Iter   826/ 1097] train: loss: 0.2250511
[Epoch 23; Iter   856/ 1097] train: loss: 0.2248841
[Epoch 23; Iter   886/ 1097] train: loss: 0.1450322
[Epoch 23; Iter   916/ 1097] train: loss: 0.2761359
[Epoch 23; Iter   946/ 1097] train: loss: 0.0312308
[Epoch 23; Iter   976/ 1097] train: loss: 0.2366078
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0187088
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0263886
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1878721
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0965749
[Epoch 23] ogbg-molhiv: 0.811649 val loss: 0.072665
[Epoch 23] ogbg-molhiv: 0.758856 test loss: 0.114178
[Epoch 24; Iter    29/ 1097] train: loss: 0.0462143
[Epoch 24; Iter    59/ 1097] train: loss: 0.2925861
[Epoch 24; Iter    89/ 1097] train: loss: 0.1434352
[Epoch 24; Iter   119/ 1097] train: loss: 0.0256487
[Epoch 24; Iter   149/ 1097] train: loss: 0.0664666
[Epoch 24; Iter   179/ 1097] train: loss: 0.0244180
[Epoch 24; Iter   209/ 1097] train: loss: 0.1469775
[Epoch 24; Iter   239/ 1097] train: loss: 0.0245612
[Epoch 24; Iter   269/ 1097] train: loss: 0.2263792
[Epoch 24; Iter   299/ 1097] train: loss: 0.0298448
[Epoch 24; Iter   329/ 1097] train: loss: 0.0210462
[Epoch 24; Iter   359/ 1097] train: loss: 0.0311746
[Epoch 24; Iter   359/ 1097] train: loss: 0.0169287
[Epoch 24; Iter   389/ 1097] train: loss: 0.0351155
[Epoch 24; Iter   419/ 1097] train: loss: 0.3186045
[Epoch 24; Iter   449/ 1097] train: loss: 0.0536216
[Epoch 24; Iter   479/ 1097] train: loss: 0.1561822
[Epoch 24; Iter   509/ 1097] train: loss: 0.1254864
[Epoch 24; Iter   539/ 1097] train: loss: 0.0208616
[Epoch 24; Iter   569/ 1097] train: loss: 0.2125265
[Epoch 24; Iter   599/ 1097] train: loss: 0.1181525
[Epoch 24; Iter   629/ 1097] train: loss: 0.0765875
[Epoch 24; Iter   659/ 1097] train: loss: 0.0142775
[Epoch 24; Iter   689/ 1097] train: loss: 0.0090560
[Epoch 24; Iter   719/ 1097] train: loss: 0.2594519
[Epoch 24; Iter   749/ 1097] train: loss: 0.0658846
[Epoch 24; Iter   779/ 1097] train: loss: 0.1693820
[Epoch 24; Iter   809/ 1097] train: loss: 0.1218779
[Epoch 24; Iter   839/ 1097] train: loss: 0.0495326
[Epoch 24; Iter   869/ 1097] train: loss: 0.0289008
[Epoch 24; Iter   899/ 1097] train: loss: 0.2344190
[Epoch 24; Iter   929/ 1097] train: loss: 0.0739390
[Epoch 24; Iter   959/ 1097] train: loss: 0.1332505
[Epoch 24; Iter   989/ 1097] train: loss: 0.0286160
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1685949
[Epoch 24; Iter  1049/ 1097] train: loss: 0.2492092
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2226773
[Epoch 24] ogbg-molhiv: 0.760855 val loss: 0.085944
[Epoch 24] ogbg-molhiv: 0.721431 test loss: 0.132493
[Epoch 25; Iter    12/ 1097] train: loss: 0.1860747
[Epoch 25; Iter    42/ 1097] train: loss: 0.0338297
[Epoch 25; Iter    72/ 1097] train: loss: 0.0156175
[Epoch 25; Iter   102/ 1097] train: loss: 0.1270223
[Epoch 25; Iter   132/ 1097] train: loss: 0.2610033
[Epoch 25; Iter   162/ 1097] train: loss: 0.0193289
[Epoch 25; Iter   192/ 1097] train: loss: 0.0812546
[Epoch 25; Iter   222/ 1097] train: loss: 0.1176702
[Epoch 25; Iter   252/ 1097] train: loss: 0.0152660
[Epoch 25; Iter   282/ 1097] train: loss: 0.0826919
[Epoch 25; Iter   312/ 1097] train: loss: 0.1054391
[Epoch 25; Iter   342/ 1097] train: loss: 0.0512978
[Epoch 25; Iter   372/ 1097] train: loss: 0.0523012
[Epoch 25; Iter   402/ 1097] train: loss: 0.0272727
[Epoch 25; Iter   432/ 1097] train: loss: 0.0358378
[Epoch 25; Iter   462/ 1097] train: loss: 0.0875346
[Epoch 25; Iter   492/ 1097] train: loss: 0.0925515
[Epoch 25; Iter   522/ 1097] train: loss: 0.1276116
[Epoch 25; Iter   552/ 1097] train: loss: 0.0941287
[Epoch 25; Iter   582/ 1097] train: loss: 0.0837531
[Epoch 25; Iter   612/ 1097] train: loss: 0.0279424
[Epoch 25; Iter   642/ 1097] train: loss: 0.0270438
[Epoch 25; Iter   672/ 1097] train: loss: 0.0441322
[Epoch 25; Iter   702/ 1097] train: loss: 0.0600072
[Epoch 25; Iter   732/ 1097] train: loss: 0.0664182
[Epoch 25; Iter   762/ 1097] train: loss: 0.0421441
[Epoch 25; Iter   792/ 1097] train: loss: 0.0288849
[Epoch 25; Iter   822/ 1097] train: loss: 0.0187589
[Epoch 25; Iter   852/ 1097] train: loss: 0.0144159
[Epoch 25; Iter   882/ 1097] train: loss: 0.0324497
[Epoch 25; Iter   912/ 1097] train: loss: 0.0369125
[Epoch 25; Iter   942/ 1097] train: loss: 0.1012549
[Epoch 25; Iter   972/ 1097] train: loss: 0.1214033
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0444020
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0464902
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0180916
[Epoch 25; Iter  1092/ 1097] train: loss: 0.2819326
[Epoch 25] ogbg-molhiv: 0.807172 val loss: 0.261849
[Epoch 25] ogbg-molhiv: 0.719083 test loss: 0.260469
[Epoch 26; Iter    25/ 1097] train: loss: 0.0443466
[Epoch 26; Iter    55/ 1097] train: loss: 0.0161427
[Epoch 26; Iter    85/ 1097] train: loss: 0.0119529
[Epoch 26; Iter   115/ 1097] train: loss: 0.0208616
[Epoch 26; Iter   145/ 1097] train: loss: 0.2564153
[Epoch 26; Iter   175/ 1097] train: loss: 0.0405832
[Epoch 26; Iter   205/ 1097] train: loss: 0.2728111
[Epoch 26; Iter   235/ 1097] train: loss: 0.0951501
[Epoch 26; Iter   265/ 1097] train: loss: 0.1743743
[Epoch 26; Iter   295/ 1097] train: loss: 0.0248890
[Epoch 26; Iter   325/ 1097] train: loss: 0.0319759
[Epoch 26; Iter   355/ 1097] train: loss: 0.0199326
[Epoch 26; Iter   385/ 1097] train: loss: 0.0434431
[Epoch 26; Iter   415/ 1097] train: loss: 0.0240256
[Epoch 26; Iter   445/ 1097] train: loss: 0.0302486
[Epoch 26; Iter   475/ 1097] train: loss: 0.0509654
[Epoch 26; Iter   505/ 1097] train: loss: 0.0637290
[Epoch 26; Iter   535/ 1097] train: loss: 0.1432007
[Epoch 26; Iter   565/ 1097] train: loss: 0.2382004
[Epoch 26; Iter   595/ 1097] train: loss: 0.0184811
[Epoch 26; Iter   625/ 1097] train: loss: 0.0631295
[Epoch 26; Iter   655/ 1097] train: loss: 0.0673676
[Epoch 26; Iter   685/ 1097] train: loss: 0.0209350
[Epoch 26; Iter   715/ 1097] train: loss: 0.1748793
[Epoch 26; Iter   745/ 1097] train: loss: 0.0700686
[Epoch 26; Iter   775/ 1097] train: loss: 0.0384509
[Epoch 26; Iter   805/ 1097] train: loss: 0.0600643
[Epoch 26; Iter   835/ 1097] train: loss: 0.1860689
[Epoch 26; Iter   865/ 1097] train: loss: 0.0435449
[Epoch 26; Iter   895/ 1097] train: loss: 0.0277135
[Epoch 26; Iter   925/ 1097] train: loss: 0.2097830
[Epoch 26; Iter   955/ 1097] train: loss: 0.0292590
[Epoch 26; Iter   985/ 1097] train: loss: 0.0328157
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0260117
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0261689
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1535159
[Epoch 26] ogbg-molhiv: 0.784710 val loss: 0.087704
[Epoch 26] ogbg-molhiv: 0.703743 test loss: 0.191945
[Epoch 27; Iter     8/ 1097] train: loss: 0.0336497
[Epoch 27; Iter    38/ 1097] train: loss: 0.1177125
[Epoch 27; Iter    68/ 1097] train: loss: 0.1361264
[Epoch 27; Iter    98/ 1097] train: loss: 0.0310895
[Epoch 27; Iter   128/ 1097] train: loss: 0.0289823
[Epoch 27; Iter   158/ 1097] train: loss: 0.1782713
[Epoch 27; Iter   188/ 1097] train: loss: 0.0391688
[Epoch 27; Iter   218/ 1097] train: loss: 0.0226188
[Epoch 27; Iter   248/ 1097] train: loss: 0.0426067
[Epoch 27; Iter   278/ 1097] train: loss: 0.0172698
[Epoch 27; Iter   308/ 1097] train: loss: 0.0204418
[Epoch 27; Iter   338/ 1097] train: loss: 0.1778229
[Epoch 27; Iter   368/ 1097] train: loss: 0.1874226
[Epoch 27; Iter   398/ 1097] train: loss: 0.0303958
[Epoch 27; Iter   428/ 1097] train: loss: 0.0392271
[Epoch 27; Iter   458/ 1097] train: loss: 0.0117265
[Epoch 27; Iter   488/ 1097] train: loss: 0.0125168
[Epoch 27; Iter   518/ 1097] train: loss: 0.1888778
[Epoch 27; Iter   548/ 1097] train: loss: 0.0446773
[Epoch 27; Iter   578/ 1097] train: loss: 0.0800549
[Epoch 27; Iter   608/ 1097] train: loss: 0.0335084
[Epoch 27; Iter   638/ 1097] train: loss: 0.1278128
[Epoch 27; Iter   668/ 1097] train: loss: 0.1857901
[Epoch 27; Iter   698/ 1097] train: loss: 0.0473874
[Epoch 27; Iter   728/ 1097] train: loss: 0.0378455
[Epoch 27; Iter   758/ 1097] train: loss: 0.0344381
[Epoch 27; Iter   788/ 1097] train: loss: 0.0218190
[Epoch 27; Iter   818/ 1097] train: loss: 0.0181469
[Epoch 27; Iter   848/ 1097] train: loss: 0.0463562
[Epoch 27; Iter   878/ 1097] train: loss: 0.2742307
[Epoch 27; Iter   908/ 1097] train: loss: 0.1853467
[Epoch 27; Iter   938/ 1097] train: loss: 0.0808238
[Epoch 27; Iter   968/ 1097] train: loss: 0.0196365
[Epoch 27; Iter   998/ 1097] train: loss: 0.0212914
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1415669
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0935750
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1806646
[Epoch 27] ogbg-molhiv: 0.804502 val loss: 0.091747
[Epoch 27] ogbg-molhiv: 0.708889 test loss: 0.153372
[Epoch 28; Iter    21/ 1097] train: loss: 0.1413779
[Epoch 28; Iter    51/ 1097] train: loss: 0.1251450
[Epoch 28; Iter    81/ 1097] train: loss: 0.0491308
[Epoch 28; Iter   111/ 1097] train: loss: 0.1103394
[Epoch 28; Iter   141/ 1097] train: loss: 0.0278432
[Epoch 28; Iter   171/ 1097] train: loss: 0.0721007
[Epoch 28; Iter   201/ 1097] train: loss: 0.0324763
[Epoch 28; Iter   231/ 1097] train: loss: 0.0148369
[Epoch 28; Iter   261/ 1097] train: loss: 0.0347426
[Epoch 28; Iter   291/ 1097] train: loss: 0.0123263
[Epoch 28; Iter   321/ 1097] train: loss: 0.0189100
[Epoch 28; Iter   351/ 1097] train: loss: 0.0126435
[Epoch 28; Iter   381/ 1097] train: loss: 0.0204323
[Epoch 28; Iter   411/ 1097] train: loss: 0.1686953
[Epoch 24; Iter   359/ 1097] train: loss: 0.1295238
[Epoch 24; Iter   389/ 1097] train: loss: 0.0286221
[Epoch 24; Iter   419/ 1097] train: loss: 0.0444552
[Epoch 24; Iter   449/ 1097] train: loss: 0.0238865
[Epoch 24; Iter   479/ 1097] train: loss: 0.2816095
[Epoch 24; Iter   509/ 1097] train: loss: 0.1665904
[Epoch 24; Iter   539/ 1097] train: loss: 0.0898528
[Epoch 24; Iter   569/ 1097] train: loss: 0.0710471
[Epoch 24; Iter   599/ 1097] train: loss: 0.0465850
[Epoch 24; Iter   629/ 1097] train: loss: 0.0315984
[Epoch 24; Iter   659/ 1097] train: loss: 0.1205505
[Epoch 24; Iter   689/ 1097] train: loss: 0.1347534
[Epoch 24; Iter   719/ 1097] train: loss: 0.0225375
[Epoch 24; Iter   749/ 1097] train: loss: 0.0124794
[Epoch 24; Iter   779/ 1097] train: loss: 0.2672789
[Epoch 24; Iter   809/ 1097] train: loss: 0.1225969
[Epoch 24; Iter   839/ 1097] train: loss: 0.1407769
[Epoch 24; Iter   869/ 1097] train: loss: 0.0311316
[Epoch 24; Iter   899/ 1097] train: loss: 0.0155486
[Epoch 24; Iter   929/ 1097] train: loss: 0.0477414
[Epoch 24; Iter   959/ 1097] train: loss: 0.0128965
[Epoch 24; Iter   989/ 1097] train: loss: 0.0322775
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1756549
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0461954
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0624026
[Epoch 24] ogbg-molhiv: 0.806143 val loss: 0.100507
[Epoch 24] ogbg-molhiv: 0.727187 test loss: 0.135788
[Epoch 25; Iter    12/ 1097] train: loss: 0.0655275
[Epoch 25; Iter    42/ 1097] train: loss: 0.0843143
[Epoch 25; Iter    72/ 1097] train: loss: 0.3018988
[Epoch 25; Iter   102/ 1097] train: loss: 0.0315320
[Epoch 25; Iter   132/ 1097] train: loss: 0.0273572
[Epoch 25; Iter   162/ 1097] train: loss: 0.0186309
[Epoch 25; Iter   192/ 1097] train: loss: 0.1232968
[Epoch 25; Iter   222/ 1097] train: loss: 0.1677959
[Epoch 25; Iter   252/ 1097] train: loss: 0.0252504
[Epoch 25; Iter   282/ 1097] train: loss: 0.0630817
[Epoch 25; Iter   312/ 1097] train: loss: 0.0192251
[Epoch 25; Iter   342/ 1097] train: loss: 0.0197819
[Epoch 25; Iter   372/ 1097] train: loss: 0.0256328
[Epoch 25; Iter   402/ 1097] train: loss: 0.1013220
[Epoch 25; Iter   432/ 1097] train: loss: 0.0632074
[Epoch 25; Iter   462/ 1097] train: loss: 0.0505284
[Epoch 25; Iter   492/ 1097] train: loss: 0.0274666
[Epoch 25; Iter   522/ 1097] train: loss: 0.0251680
[Epoch 25; Iter   552/ 1097] train: loss: 0.1996133
[Epoch 25; Iter   582/ 1097] train: loss: 0.2918564
[Epoch 25; Iter   612/ 1097] train: loss: 0.0141766
[Epoch 25; Iter   642/ 1097] train: loss: 0.2665207
[Epoch 25; Iter   672/ 1097] train: loss: 0.0831360
[Epoch 25; Iter   702/ 1097] train: loss: 0.0215415
[Epoch 25; Iter   732/ 1097] train: loss: 0.0589104
[Epoch 25; Iter   762/ 1097] train: loss: 0.0429278
[Epoch 25; Iter   792/ 1097] train: loss: 0.1344350
[Epoch 25; Iter   822/ 1097] train: loss: 0.0251153
[Epoch 25; Iter   852/ 1097] train: loss: 0.0260412
[Epoch 25; Iter   882/ 1097] train: loss: 0.0380915
[Epoch 25; Iter   912/ 1097] train: loss: 0.0683895
[Epoch 25; Iter   942/ 1097] train: loss: 0.1597490
[Epoch 25; Iter   972/ 1097] train: loss: 0.0534088
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1557347
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0422028
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0527595
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0116926
[Epoch 25] ogbg-molhiv: 0.803939 val loss: 0.222161
[Epoch 25] ogbg-molhiv: 0.723934 test loss: 0.637850
[Epoch 26; Iter    25/ 1097] train: loss: 0.0985191
[Epoch 26; Iter    55/ 1097] train: loss: 0.0290757
[Epoch 26; Iter    85/ 1097] train: loss: 0.2401635
[Epoch 26; Iter   115/ 1097] train: loss: 0.0253213
[Epoch 26; Iter   145/ 1097] train: loss: 0.0595646
[Epoch 26; Iter   175/ 1097] train: loss: 0.0733782
[Epoch 26; Iter   205/ 1097] train: loss: 0.0234478
[Epoch 26; Iter   235/ 1097] train: loss: 0.0105913
[Epoch 26; Iter   265/ 1097] train: loss: 0.0172000
[Epoch 26; Iter   295/ 1097] train: loss: 0.0563967
[Epoch 26; Iter   325/ 1097] train: loss: 0.0207120
[Epoch 26; Iter   355/ 1097] train: loss: 0.0371430
[Epoch 26; Iter   385/ 1097] train: loss: 0.0678509
[Epoch 26; Iter   415/ 1097] train: loss: 0.0968685
[Epoch 26; Iter   445/ 1097] train: loss: 0.0613235
[Epoch 26; Iter   475/ 1097] train: loss: 0.0645285
[Epoch 26; Iter   505/ 1097] train: loss: 0.0846024
[Epoch 26; Iter   535/ 1097] train: loss: 0.0090727
[Epoch 26; Iter   565/ 1097] train: loss: 0.0898339
[Epoch 26; Iter   595/ 1097] train: loss: 0.0223782
[Epoch 26; Iter   625/ 1097] train: loss: 0.1481753
[Epoch 26; Iter   655/ 1097] train: loss: 0.0379984
[Epoch 26; Iter   685/ 1097] train: loss: 0.0971170
[Epoch 26; Iter   715/ 1097] train: loss: 0.0140169
[Epoch 26; Iter   745/ 1097] train: loss: 0.0365037
[Epoch 26; Iter   775/ 1097] train: loss: 0.2465761
[Epoch 26; Iter   805/ 1097] train: loss: 0.0173605
[Epoch 26; Iter   835/ 1097] train: loss: 0.0160869
[Epoch 26; Iter   865/ 1097] train: loss: 0.1413759
[Epoch 26; Iter   895/ 1097] train: loss: 0.0310420
[Epoch 26; Iter   925/ 1097] train: loss: 0.1024592
[Epoch 26; Iter   955/ 1097] train: loss: 0.0499120
[Epoch 26; Iter   985/ 1097] train: loss: 0.0382824
[Epoch 26; Iter  1015/ 1097] train: loss: 0.1427018
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0199919
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1471730
[Epoch 26] ogbg-molhiv: 0.809576 val loss: 0.242902
[Epoch 26] ogbg-molhiv: 0.720346 test loss: 0.317482
[Epoch 27; Iter     8/ 1097] train: loss: 0.0164963
[Epoch 27; Iter    38/ 1097] train: loss: 0.0677882
[Epoch 27; Iter    68/ 1097] train: loss: 0.0193891
[Epoch 27; Iter    98/ 1097] train: loss: 0.0200311
[Epoch 27; Iter   128/ 1097] train: loss: 0.0578587
[Epoch 27; Iter   158/ 1097] train: loss: 0.2130339
[Epoch 27; Iter   188/ 1097] train: loss: 0.0238188
[Epoch 27; Iter   218/ 1097] train: loss: 0.0140340
[Epoch 27; Iter   248/ 1097] train: loss: 0.0405505
[Epoch 27; Iter   278/ 1097] train: loss: 0.0374948
[Epoch 27; Iter   308/ 1097] train: loss: 0.0626194
[Epoch 27; Iter   338/ 1097] train: loss: 0.0156556
[Epoch 27; Iter   368/ 1097] train: loss: 0.1660413
[Epoch 27; Iter   398/ 1097] train: loss: 0.1828374
[Epoch 27; Iter   428/ 1097] train: loss: 0.1305752
[Epoch 27; Iter   458/ 1097] train: loss: 0.0261854
[Epoch 27; Iter   488/ 1097] train: loss: 0.0236655
[Epoch 27; Iter   518/ 1097] train: loss: 0.2975341
[Epoch 27; Iter   548/ 1097] train: loss: 0.0347379
[Epoch 27; Iter   578/ 1097] train: loss: 0.1124600
[Epoch 27; Iter   608/ 1097] train: loss: 0.0146925
[Epoch 27; Iter   638/ 1097] train: loss: 0.0316888
[Epoch 27; Iter   668/ 1097] train: loss: 0.0399856
[Epoch 27; Iter   698/ 1097] train: loss: 0.0632484
[Epoch 27; Iter   728/ 1097] train: loss: 0.0959481
[Epoch 27; Iter   758/ 1097] train: loss: 0.0108383
[Epoch 27; Iter   788/ 1097] train: loss: 0.2065116
[Epoch 27; Iter   818/ 1097] train: loss: 0.0393354
[Epoch 27; Iter   848/ 1097] train: loss: 0.0357304
[Epoch 27; Iter   878/ 1097] train: loss: 0.0198402
[Epoch 27; Iter   908/ 1097] train: loss: 0.1384770
[Epoch 27; Iter   938/ 1097] train: loss: 0.0483364
[Epoch 27; Iter   968/ 1097] train: loss: 0.0851729
[Epoch 27; Iter   998/ 1097] train: loss: 0.0854249
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1690885
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0155065
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0354953
[Epoch 27] ogbg-molhiv: 0.810231 val loss: 0.331579
[Epoch 27] ogbg-molhiv: 0.727598 test loss: 0.285585
[Epoch 28; Iter    21/ 1097] train: loss: 0.1130589
[Epoch 28; Iter    51/ 1097] train: loss: 0.0741798
[Epoch 28; Iter    81/ 1097] train: loss: 0.0148167
[Epoch 28; Iter   111/ 1097] train: loss: 0.0151997
[Epoch 28; Iter   141/ 1097] train: loss: 0.0165628
[Epoch 28; Iter   171/ 1097] train: loss: 0.1228622
[Epoch 28; Iter   201/ 1097] train: loss: 0.0266495
[Epoch 28; Iter   231/ 1097] train: loss: 0.0128325
[Epoch 28; Iter   261/ 1097] train: loss: 0.2181278
[Epoch 28; Iter   291/ 1097] train: loss: 0.0581764
[Epoch 28; Iter   321/ 1097] train: loss: 0.0258186
[Epoch 28; Iter   351/ 1097] train: loss: 0.0506658
[Epoch 28; Iter   381/ 1097] train: loss: 0.0193932
[Epoch 28; Iter   411/ 1097] train: loss: 0.0254681
[Epoch 24; Iter   389/ 1097] train: loss: 0.0411033
[Epoch 24; Iter   419/ 1097] train: loss: 0.0734137
[Epoch 24; Iter   449/ 1097] train: loss: 0.0321786
[Epoch 24; Iter   479/ 1097] train: loss: 0.0633575
[Epoch 24; Iter   509/ 1097] train: loss: 0.1007906
[Epoch 24; Iter   539/ 1097] train: loss: 0.0559204
[Epoch 24; Iter   569/ 1097] train: loss: 0.1855099
[Epoch 24; Iter   599/ 1097] train: loss: 0.1116245
[Epoch 24; Iter   629/ 1097] train: loss: 0.0551774
[Epoch 24; Iter   659/ 1097] train: loss: 0.0253744
[Epoch 24; Iter   689/ 1097] train: loss: 0.0156646
[Epoch 24; Iter   719/ 1097] train: loss: 0.0813843
[Epoch 24; Iter   749/ 1097] train: loss: 0.1195574
[Epoch 24; Iter   779/ 1097] train: loss: 0.1390907
[Epoch 24; Iter   809/ 1097] train: loss: 0.0539358
[Epoch 24; Iter   839/ 1097] train: loss: 0.0300688
[Epoch 24; Iter   869/ 1097] train: loss: 0.0212492
[Epoch 24; Iter   899/ 1097] train: loss: 0.2281043
[Epoch 24; Iter   929/ 1097] train: loss: 0.1341292
[Epoch 24; Iter   959/ 1097] train: loss: 0.1803089
[Epoch 24; Iter   989/ 1097] train: loss: 0.1076634
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0781521
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1631240
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2773063
[Epoch 24] ogbg-molhiv: 0.775775 val loss: 0.476081
[Epoch 24] ogbg-molhiv: 0.715933 test loss: 0.154721
[Epoch 25; Iter    12/ 1097] train: loss: 0.0987734
[Epoch 25; Iter    42/ 1097] train: loss: 0.0459402
[Epoch 25; Iter    72/ 1097] train: loss: 0.0169093
[Epoch 25; Iter   102/ 1097] train: loss: 0.2035345
[Epoch 25; Iter   132/ 1097] train: loss: 0.3010557
[Epoch 25; Iter   162/ 1097] train: loss: 0.0349945
[Epoch 25; Iter   192/ 1097] train: loss: 0.0623846
[Epoch 25; Iter   222/ 1097] train: loss: 0.1247463
[Epoch 25; Iter   252/ 1097] train: loss: 0.0323076
[Epoch 25; Iter   282/ 1097] train: loss: 0.0897517
[Epoch 25; Iter   312/ 1097] train: loss: 0.0385337
[Epoch 25; Iter   342/ 1097] train: loss: 0.0118903
[Epoch 25; Iter   372/ 1097] train: loss: 0.0609194
[Epoch 25; Iter   402/ 1097] train: loss: 0.0329752
[Epoch 25; Iter   432/ 1097] train: loss: 0.1086988
[Epoch 25; Iter   462/ 1097] train: loss: 0.0406402
[Epoch 25; Iter   492/ 1097] train: loss: 0.1253227
[Epoch 25; Iter   522/ 1097] train: loss: 0.0943498
[Epoch 25; Iter   552/ 1097] train: loss: 0.0512072
[Epoch 25; Iter   582/ 1097] train: loss: 0.1741358
[Epoch 25; Iter   612/ 1097] train: loss: 0.0197559
[Epoch 25; Iter   642/ 1097] train: loss: 0.0702274
[Epoch 25; Iter   672/ 1097] train: loss: 0.0694749
[Epoch 25; Iter   702/ 1097] train: loss: 0.0442743
[Epoch 25; Iter   732/ 1097] train: loss: 0.0212789
[Epoch 25; Iter   762/ 1097] train: loss: 0.0243502
[Epoch 25; Iter   792/ 1097] train: loss: 0.0277499
[Epoch 25; Iter   822/ 1097] train: loss: 0.0304163
[Epoch 25; Iter   852/ 1097] train: loss: 0.0219923
[Epoch 25; Iter   882/ 1097] train: loss: 0.0655548
[Epoch 25; Iter   912/ 1097] train: loss: 0.0172907
[Epoch 25; Iter   942/ 1097] train: loss: 0.1291275
[Epoch 25; Iter   972/ 1097] train: loss: 0.0392990
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1103043
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0804662
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0353162
[Epoch 25; Iter  1092/ 1097] train: loss: 0.2219561
[Epoch 25] ogbg-molhiv: 0.768840 val loss: 0.181594
[Epoch 25] ogbg-molhiv: 0.725572 test loss: 0.152940
[Epoch 26; Iter    25/ 1097] train: loss: 0.0250004
[Epoch 26; Iter    55/ 1097] train: loss: 0.0407750
[Epoch 26; Iter    85/ 1097] train: loss: 0.1289427
[Epoch 26; Iter   115/ 1097] train: loss: 0.0392976
[Epoch 26; Iter   145/ 1097] train: loss: 0.1935543
[Epoch 26; Iter   175/ 1097] train: loss: 0.0694156
[Epoch 26; Iter   205/ 1097] train: loss: 0.0801464
[Epoch 26; Iter   235/ 1097] train: loss: 0.0522877
[Epoch 26; Iter   265/ 1097] train: loss: 0.0544393
[Epoch 26; Iter   295/ 1097] train: loss: 0.0314620
[Epoch 26; Iter   325/ 1097] train: loss: 0.0702941
[Epoch 26; Iter   355/ 1097] train: loss: 0.0140176
[Epoch 26; Iter   385/ 1097] train: loss: 0.0262025
[Epoch 26; Iter   415/ 1097] train: loss: 0.0124419
[Epoch 26; Iter   445/ 1097] train: loss: 0.0137983
[Epoch 26; Iter   475/ 1097] train: loss: 0.0421133
[Epoch 26; Iter   505/ 1097] train: loss: 0.0182129
[Epoch 26; Iter   535/ 1097] train: loss: 0.1617897
[Epoch 26; Iter   565/ 1097] train: loss: 0.1249157
[Epoch 26; Iter   595/ 1097] train: loss: 0.0789071
[Epoch 26; Iter   625/ 1097] train: loss: 0.0726074
[Epoch 26; Iter   655/ 1097] train: loss: 0.0230067
[Epoch 26; Iter   685/ 1097] train: loss: 0.0950615
[Epoch 26; Iter   715/ 1097] train: loss: 0.2074540
[Epoch 26; Iter   745/ 1097] train: loss: 0.0198817
[Epoch 26; Iter   775/ 1097] train: loss: 0.0575215
[Epoch 26; Iter   805/ 1097] train: loss: 0.0637256
[Epoch 26; Iter   835/ 1097] train: loss: 0.1080774
[Epoch 26; Iter   865/ 1097] train: loss: 0.0629750
[Epoch 26; Iter   895/ 1097] train: loss: 0.0637001
[Epoch 26; Iter   925/ 1097] train: loss: 0.2309477
[Epoch 26; Iter   955/ 1097] train: loss: 0.0252317
[Epoch 26; Iter   985/ 1097] train: loss: 0.0518542
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0390511
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0328798
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0962466
[Epoch 26] ogbg-molhiv: 0.652328 val loss: 0.135573
[Epoch 26] ogbg-molhiv: 0.669233 test loss: 0.164920
[Epoch 27; Iter     8/ 1097] train: loss: 0.0201059
[Epoch 27; Iter    38/ 1097] train: loss: 0.0803161
[Epoch 27; Iter    68/ 1097] train: loss: 0.2178762
[Epoch 27; Iter    98/ 1097] train: loss: 0.0261355
[Epoch 27; Iter   128/ 1097] train: loss: 0.0322005
[Epoch 27; Iter   158/ 1097] train: loss: 0.0300366
[Epoch 27; Iter   188/ 1097] train: loss: 0.0128012
[Epoch 27; Iter   218/ 1097] train: loss: 0.0182233
[Epoch 27; Iter   248/ 1097] train: loss: 0.0112660
[Epoch 27; Iter   278/ 1097] train: loss: 0.0165504
[Epoch 27; Iter   308/ 1097] train: loss: 0.0153258
[Epoch 27; Iter   338/ 1097] train: loss: 0.2265040
[Epoch 27; Iter   368/ 1097] train: loss: 0.0637080
[Epoch 27; Iter   398/ 1097] train: loss: 0.0155078
[Epoch 27; Iter   428/ 1097] train: loss: 0.0385101
[Epoch 27; Iter   458/ 1097] train: loss: 0.0198087
[Epoch 27; Iter   488/ 1097] train: loss: 0.0085365
[Epoch 27; Iter   518/ 1097] train: loss: 0.0461851
[Epoch 27; Iter   548/ 1097] train: loss: 0.0199361
[Epoch 27; Iter   578/ 1097] train: loss: 0.0286829
[Epoch 27; Iter   608/ 1097] train: loss: 0.0331853
[Epoch 27; Iter   638/ 1097] train: loss: 0.0788648
[Epoch 27; Iter   668/ 1097] train: loss: 0.1407622
[Epoch 27; Iter   698/ 1097] train: loss: 0.0254540
[Epoch 27; Iter   728/ 1097] train: loss: 0.0626429
[Epoch 27; Iter   758/ 1097] train: loss: 0.0307671
[Epoch 27; Iter   788/ 1097] train: loss: 0.0471608
[Epoch 27; Iter   818/ 1097] train: loss: 0.0115635
[Epoch 27; Iter   848/ 1097] train: loss: 0.0283468
[Epoch 27; Iter   878/ 1097] train: loss: 0.2522011
[Epoch 27; Iter   908/ 1097] train: loss: 0.1634514
[Epoch 27; Iter   938/ 1097] train: loss: 0.0634014
[Epoch 27; Iter   968/ 1097] train: loss: 0.0253129
[Epoch 27; Iter   998/ 1097] train: loss: 0.0182007
[Epoch 27; Iter  1028/ 1097] train: loss: 0.3106335
[Epoch 27; Iter  1058/ 1097] train: loss: 0.1562010
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1915215
[Epoch 27] ogbg-molhiv: 0.752468 val loss: 0.384543
[Epoch 27] ogbg-molhiv: 0.696367 test loss: 0.243750
[Epoch 28; Iter    21/ 1097] train: loss: 0.1164010
[Epoch 28; Iter    51/ 1097] train: loss: 0.0189848
[Epoch 28; Iter    81/ 1097] train: loss: 0.0892017
[Epoch 28; Iter   111/ 1097] train: loss: 0.0866783
[Epoch 28; Iter   141/ 1097] train: loss: 0.0538487
[Epoch 28; Iter   171/ 1097] train: loss: 0.0320076
[Epoch 28; Iter   201/ 1097] train: loss: 0.0251296
[Epoch 28; Iter   231/ 1097] train: loss: 0.0319101
[Epoch 28; Iter   261/ 1097] train: loss: 0.0202690
[Epoch 28; Iter   291/ 1097] train: loss: 0.0145204
[Epoch 28; Iter   321/ 1097] train: loss: 0.0143110
[Epoch 28; Iter   351/ 1097] train: loss: 0.0067620
[Epoch 28; Iter   381/ 1097] train: loss: 0.0163949
[Epoch 28; Iter   411/ 1097] train: loss: 0.1582969
[Epoch 28; Iter   441/ 1097] train: loss: 0.1571541
[Epoch 24; Iter   389/ 1097] train: loss: 0.0663404
[Epoch 24; Iter   419/ 1097] train: loss: 0.0192712
[Epoch 24; Iter   449/ 1097] train: loss: 0.0242327
[Epoch 24; Iter   479/ 1097] train: loss: 0.1219205
[Epoch 24; Iter   509/ 1097] train: loss: 0.0715192
[Epoch 24; Iter   539/ 1097] train: loss: 0.0363067
[Epoch 24; Iter   569/ 1097] train: loss: 0.0979473
[Epoch 24; Iter   599/ 1097] train: loss: 0.0781790
[Epoch 24; Iter   629/ 1097] train: loss: 0.0369949
[Epoch 24; Iter   659/ 1097] train: loss: 0.0778922
[Epoch 24; Iter   689/ 1097] train: loss: 0.0306883
[Epoch 24; Iter   719/ 1097] train: loss: 0.1056047
[Epoch 24; Iter   749/ 1097] train: loss: 0.0157128
[Epoch 24; Iter   779/ 1097] train: loss: 0.2436269
[Epoch 24; Iter   809/ 1097] train: loss: 0.0934043
[Epoch 24; Iter   839/ 1097] train: loss: 0.0957282
[Epoch 24; Iter   869/ 1097] train: loss: 0.0179070
[Epoch 24; Iter   899/ 1097] train: loss: 0.0146506
[Epoch 24; Iter   929/ 1097] train: loss: 0.0514839
[Epoch 24; Iter   959/ 1097] train: loss: 0.0249728
[Epoch 24; Iter   989/ 1097] train: loss: 0.1039777
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2466629
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0325471
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0657123
[Epoch 24] ogbg-molhiv: 0.756158 val loss: 0.102910
[Epoch 24] ogbg-molhiv: 0.715186 test loss: 0.137913
[Epoch 25; Iter    12/ 1097] train: loss: 0.0509891
[Epoch 25; Iter    42/ 1097] train: loss: 0.2059024
[Epoch 25; Iter    72/ 1097] train: loss: 0.2059331
[Epoch 25; Iter   102/ 1097] train: loss: 0.0161120
[Epoch 25; Iter   132/ 1097] train: loss: 0.0599831
[Epoch 25; Iter   162/ 1097] train: loss: 0.0229908
[Epoch 25; Iter   192/ 1097] train: loss: 0.0447304
[Epoch 25; Iter   222/ 1097] train: loss: 0.0678359
[Epoch 25; Iter   252/ 1097] train: loss: 0.0163251
[Epoch 25; Iter   282/ 1097] train: loss: 0.0414625
[Epoch 25; Iter   312/ 1097] train: loss: 0.0193544
[Epoch 25; Iter   342/ 1097] train: loss: 0.0563156
[Epoch 25; Iter   372/ 1097] train: loss: 0.0139753
[Epoch 25; Iter   402/ 1097] train: loss: 0.0304525
[Epoch 25; Iter   432/ 1097] train: loss: 0.1751461
[Epoch 25; Iter   462/ 1097] train: loss: 0.0316709
[Epoch 25; Iter   492/ 1097] train: loss: 0.0781881
[Epoch 25; Iter   522/ 1097] train: loss: 0.0193010
[Epoch 25; Iter   552/ 1097] train: loss: 0.1683982
[Epoch 25; Iter   582/ 1097] train: loss: 0.1878835
[Epoch 25; Iter   612/ 1097] train: loss: 0.0135921
[Epoch 25; Iter   642/ 1097] train: loss: 0.3783328
[Epoch 25; Iter   672/ 1097] train: loss: 0.1072293
[Epoch 25; Iter   702/ 1097] train: loss: 0.0724187
[Epoch 25; Iter   732/ 1097] train: loss: 0.1751634
[Epoch 25; Iter   762/ 1097] train: loss: 0.0899586
[Epoch 25; Iter   792/ 1097] train: loss: 0.1763113
[Epoch 25; Iter   822/ 1097] train: loss: 0.0353291
[Epoch 25; Iter   852/ 1097] train: loss: 0.0153341
[Epoch 25; Iter   882/ 1097] train: loss: 0.0242189
[Epoch 25; Iter   912/ 1097] train: loss: 0.0378977
[Epoch 25; Iter   942/ 1097] train: loss: 0.0953870
[Epoch 25; Iter   972/ 1097] train: loss: 0.1456436
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1472625
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0429256
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1044195
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0146540
[Epoch 25] ogbg-molhiv: 0.762125 val loss: 0.087117
[Epoch 25] ogbg-molhiv: 0.708826 test loss: 0.140106
[Epoch 26; Iter    25/ 1097] train: loss: 0.1244544
[Epoch 26; Iter    55/ 1097] train: loss: 0.0298532
[Epoch 26; Iter    85/ 1097] train: loss: 0.1229427
[Epoch 26; Iter   115/ 1097] train: loss: 0.0804678
[Epoch 26; Iter   145/ 1097] train: loss: 0.0861790
[Epoch 26; Iter   175/ 1097] train: loss: 0.1061342
[Epoch 26; Iter   205/ 1097] train: loss: 0.0363781
[Epoch 26; Iter   235/ 1097] train: loss: 0.0137034
[Epoch 26; Iter   265/ 1097] train: loss: 0.1117577
[Epoch 26; Iter   295/ 1097] train: loss: 0.0514196
[Epoch 26; Iter   325/ 1097] train: loss: 0.0683726
[Epoch 26; Iter   355/ 1097] train: loss: 0.0472703
[Epoch 26; Iter   385/ 1097] train: loss: 0.0757275
[Epoch 26; Iter   415/ 1097] train: loss: 0.0599761
[Epoch 26; Iter   445/ 1097] train: loss: 0.0365679
[Epoch 26; Iter   475/ 1097] train: loss: 0.0192315
[Epoch 26; Iter   505/ 1097] train: loss: 0.1133514
[Epoch 26; Iter   535/ 1097] train: loss: 0.0269292
[Epoch 26; Iter   565/ 1097] train: loss: 0.0911955
[Epoch 26; Iter   595/ 1097] train: loss: 0.0452396
[Epoch 26; Iter   625/ 1097] train: loss: 0.1333959
[Epoch 26; Iter   655/ 1097] train: loss: 0.1897070
[Epoch 26; Iter   685/ 1097] train: loss: 0.0591645
[Epoch 26; Iter   715/ 1097] train: loss: 0.0625261
[Epoch 26; Iter   745/ 1097] train: loss: 0.0399393
[Epoch 26; Iter   775/ 1097] train: loss: 0.1719510
[Epoch 26; Iter   805/ 1097] train: loss: 0.0577659
[Epoch 26; Iter   835/ 1097] train: loss: 0.0347439
[Epoch 26; Iter   865/ 1097] train: loss: 0.1995740
[Epoch 26; Iter   895/ 1097] train: loss: 0.0242135
[Epoch 26; Iter   925/ 1097] train: loss: 0.1328288
[Epoch 26; Iter   955/ 1097] train: loss: 0.0377172
[Epoch 26; Iter   985/ 1097] train: loss: 0.0091983
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2974350
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0130097
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1292223
[Epoch 26] ogbg-molhiv: 0.743738 val loss: 0.336030
[Epoch 26] ogbg-molhiv: 0.709195 test loss: 0.163958
[Epoch 27; Iter     8/ 1097] train: loss: 0.0179994
[Epoch 27; Iter    38/ 1097] train: loss: 0.0577083
[Epoch 27; Iter    68/ 1097] train: loss: 0.0361727
[Epoch 27; Iter    98/ 1097] train: loss: 0.0410881
[Epoch 27; Iter   128/ 1097] train: loss: 0.0181911
[Epoch 27; Iter   158/ 1097] train: loss: 0.1513120
[Epoch 27; Iter   188/ 1097] train: loss: 0.0142397
[Epoch 27; Iter   218/ 1097] train: loss: 0.0477996
[Epoch 27; Iter   248/ 1097] train: loss: 0.0475470
[Epoch 27; Iter   278/ 1097] train: loss: 0.2072386
[Epoch 27; Iter   308/ 1097] train: loss: 0.0414093
[Epoch 27; Iter   338/ 1097] train: loss: 0.0156402
[Epoch 27; Iter   368/ 1097] train: loss: 0.0437206
[Epoch 27; Iter   398/ 1097] train: loss: 0.1079333
[Epoch 27; Iter   428/ 1097] train: loss: 0.0322870
[Epoch 27; Iter   458/ 1097] train: loss: 0.0074417
[Epoch 27; Iter   488/ 1097] train: loss: 0.0444812
[Epoch 27; Iter   518/ 1097] train: loss: 0.2029187
[Epoch 27; Iter   548/ 1097] train: loss: 0.0338996
[Epoch 27; Iter   578/ 1097] train: loss: 0.1371064
[Epoch 27; Iter   608/ 1097] train: loss: 0.0269302
[Epoch 27; Iter   638/ 1097] train: loss: 0.0231769
[Epoch 27; Iter   668/ 1097] train: loss: 0.0240160
[Epoch 27; Iter   698/ 1097] train: loss: 0.0627191
[Epoch 27; Iter   728/ 1097] train: loss: 0.0567346
[Epoch 27; Iter   758/ 1097] train: loss: 0.0092711
[Epoch 27; Iter   788/ 1097] train: loss: 0.1547243
[Epoch 27; Iter   818/ 1097] train: loss: 0.0238457
[Epoch 27; Iter   848/ 1097] train: loss: 0.0085263
[Epoch 27; Iter   878/ 1097] train: loss: 0.0480739
[Epoch 27; Iter   908/ 1097] train: loss: 0.1965953
[Epoch 27; Iter   938/ 1097] train: loss: 0.0753951
[Epoch 27; Iter   968/ 1097] train: loss: 0.0509505
[Epoch 27; Iter   998/ 1097] train: loss: 0.0965021
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0935274
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0231607
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0239310
[Epoch 27] ogbg-molhiv: 0.750729 val loss: 0.127214
[Epoch 27] ogbg-molhiv: 0.720960 test loss: 0.166318
[Epoch 28; Iter    21/ 1097] train: loss: 0.0723759
[Epoch 28; Iter    51/ 1097] train: loss: 0.1500944
[Epoch 28; Iter    81/ 1097] train: loss: 0.0301286
[Epoch 28; Iter   111/ 1097] train: loss: 0.0121383
[Epoch 28; Iter   141/ 1097] train: loss: 0.0200362
[Epoch 28; Iter   171/ 1097] train: loss: 0.1295200
[Epoch 28; Iter   201/ 1097] train: loss: 0.0332460
[Epoch 28; Iter   231/ 1097] train: loss: 0.0078610
[Epoch 28; Iter   261/ 1097] train: loss: 0.0486879
[Epoch 28; Iter   291/ 1097] train: loss: 0.0337833
[Epoch 28; Iter   321/ 1097] train: loss: 0.0137298
[Epoch 28; Iter   351/ 1097] train: loss: 0.0674764
[Epoch 28; Iter   381/ 1097] train: loss: 0.0446838
[Epoch 28; Iter   411/ 1097] train: loss: 0.0776917
[Epoch 28; Iter   441/ 1097] train: loss: 0.0420124
[Epoch 24; Iter   389/ 1097] train: loss: 0.0777884
[Epoch 24; Iter   419/ 1097] train: loss: 0.3030218
[Epoch 24; Iter   449/ 1097] train: loss: 0.0165760
[Epoch 24; Iter   479/ 1097] train: loss: 0.0507735
[Epoch 24; Iter   509/ 1097] train: loss: 0.0367510
[Epoch 24; Iter   539/ 1097] train: loss: 0.0147148
[Epoch 24; Iter   569/ 1097] train: loss: 0.2302381
[Epoch 24; Iter   599/ 1097] train: loss: 0.2093957
[Epoch 24; Iter   629/ 1097] train: loss: 0.0427298
[Epoch 24; Iter   659/ 1097] train: loss: 0.0315637
[Epoch 24; Iter   689/ 1097] train: loss: 0.0135201
[Epoch 24; Iter   719/ 1097] train: loss: 0.0213039
[Epoch 24; Iter   749/ 1097] train: loss: 0.0250958
[Epoch 24; Iter   779/ 1097] train: loss: 0.1896913
[Epoch 24; Iter   809/ 1097] train: loss: 0.0310290
[Epoch 24; Iter   839/ 1097] train: loss: 0.2539099
[Epoch 24; Iter   869/ 1097] train: loss: 0.1874690
[Epoch 24; Iter   899/ 1097] train: loss: 0.2499793
[Epoch 24; Iter   929/ 1097] train: loss: 0.2830532
[Epoch 24; Iter   959/ 1097] train: loss: 0.0277801
[Epoch 24; Iter   989/ 1097] train: loss: 0.0210593
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1377852
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0944111
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0505275
[Epoch 24] ogbg-molhiv: 0.706184 val loss: 0.084281
[Epoch 24] ogbg-molhiv: 0.731034 test loss: 0.134151
[Epoch 25; Iter    12/ 1097] train: loss: 0.0395169
[Epoch 25; Iter    42/ 1097] train: loss: 0.0485969
[Epoch 25; Iter    72/ 1097] train: loss: 0.0242969
[Epoch 25; Iter   102/ 1097] train: loss: 0.0644219
[Epoch 25; Iter   132/ 1097] train: loss: 0.0222078
[Epoch 25; Iter   162/ 1097] train: loss: 0.0425628
[Epoch 25; Iter   192/ 1097] train: loss: 0.0469714
[Epoch 25; Iter   222/ 1097] train: loss: 0.0198169
[Epoch 25; Iter   252/ 1097] train: loss: 0.0509191
[Epoch 25; Iter   282/ 1097] train: loss: 0.1928560
[Epoch 25; Iter   312/ 1097] train: loss: 0.0153838
[Epoch 25; Iter   342/ 1097] train: loss: 0.0470887
[Epoch 25; Iter   372/ 1097] train: loss: 0.2569610
[Epoch 25; Iter   402/ 1097] train: loss: 0.0209426
[Epoch 25; Iter   432/ 1097] train: loss: 0.2531318
[Epoch 25; Iter   462/ 1097] train: loss: 0.0231490
[Epoch 25; Iter   492/ 1097] train: loss: 0.2327475
[Epoch 25; Iter   522/ 1097] train: loss: 0.0175937
[Epoch 25; Iter   552/ 1097] train: loss: 0.1815883
[Epoch 25; Iter   582/ 1097] train: loss: 0.1622099
[Epoch 25; Iter   612/ 1097] train: loss: 0.1376826
[Epoch 25; Iter   642/ 1097] train: loss: 0.1319604
[Epoch 25; Iter   672/ 1097] train: loss: 0.0288564
[Epoch 25; Iter   702/ 1097] train: loss: 0.0486879
[Epoch 25; Iter   732/ 1097] train: loss: 0.0696583
[Epoch 25; Iter   762/ 1097] train: loss: 0.1706587
[Epoch 25; Iter   792/ 1097] train: loss: 0.0256418
[Epoch 25; Iter   822/ 1097] train: loss: 0.0506079
[Epoch 25; Iter   852/ 1097] train: loss: 0.0199538
[Epoch 25; Iter   882/ 1097] train: loss: 0.0505342
[Epoch 25; Iter   912/ 1097] train: loss: 0.1892997
[Epoch 25; Iter   942/ 1097] train: loss: 0.0460343
[Epoch 25; Iter   972/ 1097] train: loss: 0.0816616
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2711327
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2491047
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0198946
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1574532
[Epoch 25] ogbg-molhiv: 0.726099 val loss: 0.092704
[Epoch 25] ogbg-molhiv: 0.696923 test loss: 0.154075
[Epoch 26; Iter    25/ 1097] train: loss: 0.0238252
[Epoch 26; Iter    55/ 1097] train: loss: 0.0408678
[Epoch 26; Iter    85/ 1097] train: loss: 0.1267556
[Epoch 26; Iter   115/ 1097] train: loss: 0.0546240
[Epoch 26; Iter   145/ 1097] train: loss: 0.0386846
[Epoch 26; Iter   175/ 1097] train: loss: 0.0713346
[Epoch 26; Iter   205/ 1097] train: loss: 0.4960547
[Epoch 26; Iter   235/ 1097] train: loss: 0.0281096
[Epoch 26; Iter   265/ 1097] train: loss: 0.0121597
[Epoch 26; Iter   295/ 1097] train: loss: 0.1048753
[Epoch 26; Iter   325/ 1097] train: loss: 0.0276704
[Epoch 26; Iter   355/ 1097] train: loss: 0.0176767
[Epoch 26; Iter   385/ 1097] train: loss: 0.0569553
[Epoch 26; Iter   415/ 1097] train: loss: 0.0355377
[Epoch 26; Iter   445/ 1097] train: loss: 0.0242567
[Epoch 26; Iter   475/ 1097] train: loss: 0.1078492
[Epoch 26; Iter   505/ 1097] train: loss: 0.0289423
[Epoch 26; Iter   535/ 1097] train: loss: 0.0708911
[Epoch 26; Iter   565/ 1097] train: loss: 0.0851693
[Epoch 26; Iter   595/ 1097] train: loss: 0.0506940
[Epoch 26; Iter   625/ 1097] train: loss: 0.0386688
[Epoch 26; Iter   655/ 1097] train: loss: 0.0231955
[Epoch 26; Iter   685/ 1097] train: loss: 0.0771791
[Epoch 26; Iter   715/ 1097] train: loss: 0.0218667
[Epoch 26; Iter   745/ 1097] train: loss: 0.0240834
[Epoch 26; Iter   775/ 1097] train: loss: 0.0806657
[Epoch 26; Iter   805/ 1097] train: loss: 0.0958445
[Epoch 26; Iter   835/ 1097] train: loss: 0.0698911
[Epoch 26; Iter   865/ 1097] train: loss: 0.2001621
[Epoch 26; Iter   895/ 1097] train: loss: 0.0275643
[Epoch 26; Iter   925/ 1097] train: loss: 0.2596669
[Epoch 26; Iter   955/ 1097] train: loss: 0.0457929
[Epoch 26; Iter   985/ 1097] train: loss: 0.0655218
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0208914
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0466215
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0536526
[Epoch 26] ogbg-molhiv: 0.736249 val loss: 0.211616
[Epoch 26] ogbg-molhiv: 0.740669 test loss: 0.205694
[Epoch 27; Iter     8/ 1097] train: loss: 0.0497856
[Epoch 27; Iter    38/ 1097] train: loss: 0.0305955
[Epoch 27; Iter    68/ 1097] train: loss: 0.0368515
[Epoch 27; Iter    98/ 1097] train: loss: 0.0671219
[Epoch 27; Iter   128/ 1097] train: loss: 0.1582308
[Epoch 27; Iter   158/ 1097] train: loss: 0.0832874
[Epoch 27; Iter   188/ 1097] train: loss: 0.0312308
[Epoch 27; Iter   218/ 1097] train: loss: 0.1059386
[Epoch 27; Iter   248/ 1097] train: loss: 0.0955512
[Epoch 27; Iter   278/ 1097] train: loss: 0.0150107
[Epoch 27; Iter   308/ 1097] train: loss: 0.0335693
[Epoch 27; Iter   338/ 1097] train: loss: 0.0261974
[Epoch 27; Iter   368/ 1097] train: loss: 0.0461440
[Epoch 27; Iter   398/ 1097] train: loss: 0.0139089
[Epoch 27; Iter   428/ 1097] train: loss: 0.1882114
[Epoch 27; Iter   458/ 1097] train: loss: 0.0205925
[Epoch 27; Iter   488/ 1097] train: loss: 0.0136373
[Epoch 27; Iter   518/ 1097] train: loss: 0.2581726
[Epoch 27; Iter   548/ 1097] train: loss: 0.1285922
[Epoch 27; Iter   578/ 1097] train: loss: 0.1606031
[Epoch 27; Iter   608/ 1097] train: loss: 0.1448996
[Epoch 27; Iter   638/ 1097] train: loss: 0.0649992
[Epoch 27; Iter   668/ 1097] train: loss: 0.0190347
[Epoch 27; Iter   698/ 1097] train: loss: 0.0173499
[Epoch 27; Iter   728/ 1097] train: loss: 0.2045766
[Epoch 27; Iter   758/ 1097] train: loss: 0.0365474
[Epoch 27; Iter   788/ 1097] train: loss: 0.1092819
[Epoch 27; Iter   818/ 1097] train: loss: 0.0680978
[Epoch 27; Iter   848/ 1097] train: loss: 0.1420138
[Epoch 27; Iter   878/ 1097] train: loss: 0.0814951
[Epoch 27; Iter   908/ 1097] train: loss: 0.0292979
[Epoch 27; Iter   938/ 1097] train: loss: 0.2894546
[Epoch 27; Iter   968/ 1097] train: loss: 0.0187471
[Epoch 27; Iter   998/ 1097] train: loss: 0.1767622
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0233813
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2535430
[Epoch 27; Iter  1088/ 1097] train: loss: 0.2115894
[Epoch 27] ogbg-molhiv: 0.741935 val loss: 0.088438
[Epoch 27] ogbg-molhiv: 0.723058 test loss: 0.198341
[Epoch 28; Iter    21/ 1097] train: loss: 0.0368008
[Epoch 28; Iter    51/ 1097] train: loss: 0.0427128
[Epoch 28; Iter    81/ 1097] train: loss: 0.0216136
[Epoch 28; Iter   111/ 1097] train: loss: 0.1958256
[Epoch 28; Iter   141/ 1097] train: loss: 0.1121380
[Epoch 28; Iter   171/ 1097] train: loss: 0.0383216
[Epoch 28; Iter   201/ 1097] train: loss: 0.0492613
[Epoch 28; Iter   231/ 1097] train: loss: 0.0372539
[Epoch 28; Iter   261/ 1097] train: loss: 0.1556443
[Epoch 28; Iter   291/ 1097] train: loss: 0.0178379
[Epoch 28; Iter   321/ 1097] train: loss: 0.0220593
[Epoch 28; Iter   351/ 1097] train: loss: 0.0445312
[Epoch 28; Iter   381/ 1097] train: loss: 0.0285433
[Epoch 28; Iter   411/ 1097] train: loss: 0.0172416
[Epoch 28; Iter   441/ 1097] train: loss: 0.6681845
[Epoch 24; Iter   389/ 1097] train: loss: 0.0729716
[Epoch 24; Iter   419/ 1097] train: loss: 0.0326909
[Epoch 24; Iter   449/ 1097] train: loss: 0.0175745
[Epoch 24; Iter   479/ 1097] train: loss: 0.1427976
[Epoch 24; Iter   509/ 1097] train: loss: 0.1326715
[Epoch 24; Iter   539/ 1097] train: loss: 0.0371036
[Epoch 24; Iter   569/ 1097] train: loss: 0.1375974
[Epoch 24; Iter   599/ 1097] train: loss: 0.0232669
[Epoch 24; Iter   629/ 1097] train: loss: 0.0087610
[Epoch 24; Iter   659/ 1097] train: loss: 0.0228531
[Epoch 24; Iter   689/ 1097] train: loss: 0.0047368
[Epoch 24; Iter   719/ 1097] train: loss: 0.0217283
[Epoch 24; Iter   749/ 1097] train: loss: 0.1160673
[Epoch 24; Iter   779/ 1097] train: loss: 0.1060036
[Epoch 24; Iter   809/ 1097] train: loss: 0.1476821
[Epoch 24; Iter   839/ 1097] train: loss: 0.0285093
[Epoch 24; Iter   869/ 1097] train: loss: 0.0275955
[Epoch 24; Iter   899/ 1097] train: loss: 0.0912275
[Epoch 24; Iter   929/ 1097] train: loss: 0.1196894
[Epoch 24; Iter   959/ 1097] train: loss: 0.2334723
[Epoch 24; Iter   989/ 1097] train: loss: 0.0182332
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0686426
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0454111
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1654391
[Epoch 24] ogbg-molhiv: 0.704613 val loss: 0.434920
[Epoch 24] ogbg-molhiv: 0.709738 test loss: 0.202060
[Epoch 25; Iter    12/ 1097] train: loss: 0.1621170
[Epoch 25; Iter    42/ 1097] train: loss: 0.0128880
[Epoch 25; Iter    72/ 1097] train: loss: 0.0312417
[Epoch 25; Iter   102/ 1097] train: loss: 0.4135497
[Epoch 25; Iter   132/ 1097] train: loss: 0.2292318
[Epoch 25; Iter   162/ 1097] train: loss: 0.0582764
[Epoch 25; Iter   192/ 1097] train: loss: 0.0501485
[Epoch 25; Iter   222/ 1097] train: loss: 0.0276771
[Epoch 25; Iter   252/ 1097] train: loss: 0.0550765
[Epoch 25; Iter   282/ 1097] train: loss: 0.0770867
[Epoch 25; Iter   312/ 1097] train: loss: 0.0163781
[Epoch 25; Iter   342/ 1097] train: loss: 0.0084769
[Epoch 25; Iter   372/ 1097] train: loss: 0.0169800
[Epoch 25; Iter   402/ 1097] train: loss: 0.0218898
[Epoch 25; Iter   432/ 1097] train: loss: 0.0886074
[Epoch 25; Iter   462/ 1097] train: loss: 0.0616850
[Epoch 25; Iter   492/ 1097] train: loss: 0.0941471
[Epoch 25; Iter   522/ 1097] train: loss: 0.2177533
[Epoch 25; Iter   552/ 1097] train: loss: 0.0298789
[Epoch 25; Iter   582/ 1097] train: loss: 0.0208943
[Epoch 25; Iter   612/ 1097] train: loss: 0.0357888
[Epoch 25; Iter   642/ 1097] train: loss: 0.1207115
[Epoch 25; Iter   672/ 1097] train: loss: 0.0426461
[Epoch 25; Iter   702/ 1097] train: loss: 0.0738768
[Epoch 25; Iter   732/ 1097] train: loss: 0.0398915
[Epoch 25; Iter   762/ 1097] train: loss: 0.0323137
[Epoch 25; Iter   792/ 1097] train: loss: 0.0357441
[Epoch 25; Iter   822/ 1097] train: loss: 0.0132962
[Epoch 25; Iter   852/ 1097] train: loss: 0.0299116
[Epoch 25; Iter   882/ 1097] train: loss: 0.0238851
[Epoch 25; Iter   912/ 1097] train: loss: 0.0071652
[Epoch 25; Iter   942/ 1097] train: loss: 0.0157958
[Epoch 25; Iter   972/ 1097] train: loss: 0.1591067
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0368748
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0779218
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0174270
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1248780
[Epoch 25] ogbg-molhiv: 0.741806 val loss: 0.138413
[Epoch 25] ogbg-molhiv: 0.681342 test loss: 0.198716
[Epoch 26; Iter    25/ 1097] train: loss: 0.0439409
[Epoch 26; Iter    55/ 1097] train: loss: 0.0130958
[Epoch 26; Iter    85/ 1097] train: loss: 0.0275897
[Epoch 26; Iter   115/ 1097] train: loss: 0.0093245
[Epoch 26; Iter   145/ 1097] train: loss: 0.0842471
[Epoch 26; Iter   175/ 1097] train: loss: 0.0274497
[Epoch 26; Iter   205/ 1097] train: loss: 0.1504772
[Epoch 26; Iter   235/ 1097] train: loss: 0.0317733
[Epoch 26; Iter   265/ 1097] train: loss: 0.0581067
[Epoch 26; Iter   295/ 1097] train: loss: 0.0535910
[Epoch 26; Iter   325/ 1097] train: loss: 0.0110486
[Epoch 26; Iter   355/ 1097] train: loss: 0.0104123
[Epoch 26; Iter   385/ 1097] train: loss: 0.0187861
[Epoch 26; Iter   415/ 1097] train: loss: 0.0212914
[Epoch 26; Iter   445/ 1097] train: loss: 0.0117184
[Epoch 26; Iter   475/ 1097] train: loss: 0.0531627
[Epoch 26; Iter   505/ 1097] train: loss: 0.0426081
[Epoch 26; Iter   535/ 1097] train: loss: 0.0272020
[Epoch 26; Iter   565/ 1097] train: loss: 0.1238411
[Epoch 26; Iter   595/ 1097] train: loss: 0.0675030
[Epoch 26; Iter   625/ 1097] train: loss: 0.0164298
[Epoch 26; Iter   655/ 1097] train: loss: 0.0208262
[Epoch 26; Iter   685/ 1097] train: loss: 0.0159424
[Epoch 26; Iter   715/ 1097] train: loss: 0.0457973
[Epoch 26; Iter   745/ 1097] train: loss: 0.0480255
[Epoch 26; Iter   775/ 1097] train: loss: 0.0284743
[Epoch 26; Iter   805/ 1097] train: loss: 0.1146281
[Epoch 26; Iter   835/ 1097] train: loss: 0.1694580
[Epoch 26; Iter   865/ 1097] train: loss: 0.1479055
[Epoch 26; Iter   895/ 1097] train: loss: 0.0347053
[Epoch 26; Iter   925/ 1097] train: loss: 0.2328816
[Epoch 26; Iter   955/ 1097] train: loss: 0.0207496
[Epoch 26; Iter   985/ 1097] train: loss: 0.0487495
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0215582
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0212763
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1098431
[Epoch 26] ogbg-molhiv: 0.721846 val loss: 0.136681
[Epoch 26] ogbg-molhiv: 0.680251 test loss: 0.214161
[Epoch 27; Iter     8/ 1097] train: loss: 0.0148095
[Epoch 27; Iter    38/ 1097] train: loss: 0.0485310
[Epoch 27; Iter    68/ 1097] train: loss: 0.0942167
[Epoch 27; Iter    98/ 1097] train: loss: 0.0097166
[Epoch 27; Iter   128/ 1097] train: loss: 0.0425343
[Epoch 27; Iter   158/ 1097] train: loss: 0.0112467
[Epoch 27; Iter   188/ 1097] train: loss: 0.0204167
[Epoch 27; Iter   218/ 1097] train: loss: 0.0235033
[Epoch 27; Iter   248/ 1097] train: loss: 0.0124929
[Epoch 27; Iter   278/ 1097] train: loss: 0.0530693
[Epoch 27; Iter   308/ 1097] train: loss: 0.0075986
[Epoch 27; Iter   338/ 1097] train: loss: 0.2128373
[Epoch 27; Iter   368/ 1097] train: loss: 0.0815186
[Epoch 27; Iter   398/ 1097] train: loss: 0.0448874
[Epoch 27; Iter   428/ 1097] train: loss: 0.1066234
[Epoch 27; Iter   458/ 1097] train: loss: 0.0342273
[Epoch 27; Iter   488/ 1097] train: loss: 0.0102900
[Epoch 27; Iter   518/ 1097] train: loss: 0.0667024
[Epoch 27; Iter   548/ 1097] train: loss: 0.0177379
[Epoch 27; Iter   578/ 1097] train: loss: 0.0728742
[Epoch 27; Iter   608/ 1097] train: loss: 0.0349806
[Epoch 27; Iter   638/ 1097] train: loss: 0.0828604
[Epoch 27; Iter   668/ 1097] train: loss: 0.1056005
[Epoch 27; Iter   698/ 1097] train: loss: 0.0330359
[Epoch 27; Iter   728/ 1097] train: loss: 0.0461280
[Epoch 27; Iter   758/ 1097] train: loss: 0.0206238
[Epoch 27; Iter   788/ 1097] train: loss: 0.0268191
[Epoch 27; Iter   818/ 1097] train: loss: 0.0344496
[Epoch 27; Iter   848/ 1097] train: loss: 0.0752994
[Epoch 27; Iter   878/ 1097] train: loss: 0.1034283
[Epoch 27; Iter   908/ 1097] train: loss: 0.0477423
[Epoch 27; Iter   938/ 1097] train: loss: 0.0146772
[Epoch 27; Iter   968/ 1097] train: loss: 0.0212274
[Epoch 27; Iter   998/ 1097] train: loss: 0.0106193
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1660302
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0603040
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1220689
[Epoch 27] ogbg-molhiv: 0.748301 val loss: 0.159803
[Epoch 27] ogbg-molhiv: 0.727220 test loss: 0.192563
[Epoch 28; Iter    21/ 1097] train: loss: 0.0177235
[Epoch 28; Iter    51/ 1097] train: loss: 0.0092166
[Epoch 28; Iter    81/ 1097] train: loss: 0.0111542
[Epoch 28; Iter   111/ 1097] train: loss: 0.0631268
[Epoch 28; Iter   141/ 1097] train: loss: 0.0138901
[Epoch 28; Iter   171/ 1097] train: loss: 0.0225336
[Epoch 28; Iter   201/ 1097] train: loss: 0.0290626
[Epoch 28; Iter   231/ 1097] train: loss: 0.0093615
[Epoch 28; Iter   261/ 1097] train: loss: 0.0269084
[Epoch 28; Iter   291/ 1097] train: loss: 0.0069196
[Epoch 28; Iter   321/ 1097] train: loss: 0.0392066
[Epoch 28; Iter   351/ 1097] train: loss: 0.0589272
[Epoch 28; Iter   381/ 1097] train: loss: 0.1227988
[Epoch 28; Iter   411/ 1097] train: loss: 0.2335405
[Epoch 28; Iter   441/ 1097] train: loss: 0.0132211
[Epoch 24; Iter   389/ 1097] train: loss: 0.0815351
[Epoch 24; Iter   419/ 1097] train: loss: 0.0528488
[Epoch 24; Iter   449/ 1097] train: loss: 0.0441958
[Epoch 24; Iter   479/ 1097] train: loss: 0.0788606
[Epoch 24; Iter   509/ 1097] train: loss: 0.1073321
[Epoch 24; Iter   539/ 1097] train: loss: 0.1000170
[Epoch 24; Iter   569/ 1097] train: loss: 0.0819538
[Epoch 24; Iter   599/ 1097] train: loss: 0.1052014
[Epoch 24; Iter   629/ 1097] train: loss: 0.0349320
[Epoch 24; Iter   659/ 1097] train: loss: 0.0418820
[Epoch 24; Iter   689/ 1097] train: loss: 0.1292515
[Epoch 24; Iter   719/ 1097] train: loss: 0.0252146
[Epoch 24; Iter   749/ 1097] train: loss: 0.0308525
[Epoch 24; Iter   779/ 1097] train: loss: 0.3434286
[Epoch 24; Iter   809/ 1097] train: loss: 0.1640014
[Epoch 24; Iter   839/ 1097] train: loss: 0.1195911
[Epoch 24; Iter   869/ 1097] train: loss: 0.0291080
[Epoch 24; Iter   899/ 1097] train: loss: 0.0175864
[Epoch 24; Iter   929/ 1097] train: loss: 0.0308333
[Epoch 24; Iter   959/ 1097] train: loss: 0.0282063
[Epoch 24; Iter   989/ 1097] train: loss: 0.1111445
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2337869
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0675107
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1393581
[Epoch 24] ogbg-molhiv: 0.706227 val loss: 10.886926
[Epoch 24] ogbg-molhiv: 0.618985 test loss: 6.257785
[Epoch 25; Iter    12/ 1097] train: loss: 0.0695780
[Epoch 25; Iter    42/ 1097] train: loss: 0.0560841
[Epoch 25; Iter    72/ 1097] train: loss: 0.2536415
[Epoch 25; Iter   102/ 1097] train: loss: 0.0222388
[Epoch 25; Iter   132/ 1097] train: loss: 0.0532613
[Epoch 25; Iter   162/ 1097] train: loss: 0.0197532
[Epoch 25; Iter   192/ 1097] train: loss: 0.0373751
[Epoch 25; Iter   222/ 1097] train: loss: 0.0205735
[Epoch 25; Iter   252/ 1097] train: loss: 0.0167310
[Epoch 25; Iter   282/ 1097] train: loss: 0.0245470
[Epoch 25; Iter   312/ 1097] train: loss: 0.0526320
[Epoch 25; Iter   342/ 1097] train: loss: 0.0350910
[Epoch 25; Iter   372/ 1097] train: loss: 0.0482710
[Epoch 25; Iter   402/ 1097] train: loss: 0.0566088
[Epoch 25; Iter   432/ 1097] train: loss: 0.0421830
[Epoch 25; Iter   462/ 1097] train: loss: 0.0670528
[Epoch 25; Iter   492/ 1097] train: loss: 0.0546427
[Epoch 25; Iter   522/ 1097] train: loss: 0.0802643
[Epoch 25; Iter   552/ 1097] train: loss: 0.0798083
[Epoch 25; Iter   582/ 1097] train: loss: 0.1149371
[Epoch 25; Iter   612/ 1097] train: loss: 0.0128976
[Epoch 25; Iter   642/ 1097] train: loss: 0.2076561
[Epoch 25; Iter   672/ 1097] train: loss: 0.0374061
[Epoch 25; Iter   702/ 1097] train: loss: 0.1149099
[Epoch 25; Iter   732/ 1097] train: loss: 0.1764291
[Epoch 25; Iter   762/ 1097] train: loss: 0.0639545
[Epoch 25; Iter   792/ 1097] train: loss: 0.1423355
[Epoch 25; Iter   822/ 1097] train: loss: 0.0193520
[Epoch 25; Iter   852/ 1097] train: loss: 0.0423373
[Epoch 25; Iter   882/ 1097] train: loss: 0.0231205
[Epoch 25; Iter   912/ 1097] train: loss: 0.0446662
[Epoch 25; Iter   942/ 1097] train: loss: 0.1979426
[Epoch 25; Iter   972/ 1097] train: loss: 0.0945675
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1064542
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0406117
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1028677
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0514693
[Epoch 25] ogbg-molhiv: 0.677426 val loss: 11.554890
[Epoch 25] ogbg-molhiv: 0.628954 test loss: 4.454416
[Epoch 26; Iter    25/ 1097] train: loss: 0.1425185
[Epoch 26; Iter    55/ 1097] train: loss: 0.0185922
[Epoch 26; Iter    85/ 1097] train: loss: 0.1691213
[Epoch 26; Iter   115/ 1097] train: loss: 0.0528277
[Epoch 26; Iter   145/ 1097] train: loss: 0.0199078
[Epoch 26; Iter   175/ 1097] train: loss: 0.0871388
[Epoch 26; Iter   205/ 1097] train: loss: 0.0221975
[Epoch 26; Iter   235/ 1097] train: loss: 0.0157396
[Epoch 26; Iter   265/ 1097] train: loss: 0.0754075
[Epoch 26; Iter   295/ 1097] train: loss: 0.0237027
[Epoch 26; Iter   325/ 1097] train: loss: 0.0164422
[Epoch 26; Iter   355/ 1097] train: loss: 0.0107091
[Epoch 26; Iter   385/ 1097] train: loss: 0.0439562
[Epoch 26; Iter   415/ 1097] train: loss: 0.0268416
[Epoch 26; Iter   445/ 1097] train: loss: 0.1155260
[Epoch 26; Iter   475/ 1097] train: loss: 0.0635459
[Epoch 26; Iter   505/ 1097] train: loss: 0.1671937
[Epoch 26; Iter   535/ 1097] train: loss: 0.0160506
[Epoch 26; Iter   565/ 1097] train: loss: 0.1456249
[Epoch 26; Iter   595/ 1097] train: loss: 0.0286013
[Epoch 26; Iter   625/ 1097] train: loss: 0.1201158
[Epoch 26; Iter   655/ 1097] train: loss: 0.0121931
[Epoch 26; Iter   685/ 1097] train: loss: 0.0509436
[Epoch 26; Iter   715/ 1097] train: loss: 0.0323308
[Epoch 26; Iter   745/ 1097] train: loss: 0.1271258
[Epoch 26; Iter   775/ 1097] train: loss: 0.2220140
[Epoch 26; Iter   805/ 1097] train: loss: 0.0970800
[Epoch 26; Iter   835/ 1097] train: loss: 0.0268298
[Epoch 26; Iter   865/ 1097] train: loss: 0.2328149
[Epoch 26; Iter   895/ 1097] train: loss: 0.0238876
[Epoch 26; Iter   925/ 1097] train: loss: 0.0778816
[Epoch 26; Iter   955/ 1097] train: loss: 0.0375707
[Epoch 26; Iter   985/ 1097] train: loss: 0.0109112
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2390177
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0459376
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2116628
[Epoch 26] ogbg-molhiv: 0.720627 val loss: 2.085754
[Epoch 26] ogbg-molhiv: 0.610350 test loss: 2.315130
[Epoch 27; Iter     8/ 1097] train: loss: 0.0220885
[Epoch 27; Iter    38/ 1097] train: loss: 0.0832286
[Epoch 27; Iter    68/ 1097] train: loss: 0.0542527
[Epoch 27; Iter    98/ 1097] train: loss: 0.0286635
[Epoch 27; Iter   128/ 1097] train: loss: 0.0782507
[Epoch 27; Iter   158/ 1097] train: loss: 0.0606509
[Epoch 27; Iter   188/ 1097] train: loss: 0.0293457
[Epoch 27; Iter   218/ 1097] train: loss: 0.1513045
[Epoch 27; Iter   248/ 1097] train: loss: 0.0364711
[Epoch 27; Iter   278/ 1097] train: loss: 0.0171995
[Epoch 27; Iter   308/ 1097] train: loss: 0.0221165
[Epoch 27; Iter   338/ 1097] train: loss: 0.0197142
[Epoch 27; Iter   368/ 1097] train: loss: 0.0997301
[Epoch 27; Iter   398/ 1097] train: loss: 0.1462495
[Epoch 27; Iter   428/ 1097] train: loss: 0.0166151
[Epoch 27; Iter   458/ 1097] train: loss: 0.0073847
[Epoch 27; Iter   488/ 1097] train: loss: 0.1071643
[Epoch 27; Iter   518/ 1097] train: loss: 0.0631735
[Epoch 27; Iter   548/ 1097] train: loss: 0.0152605
[Epoch 27; Iter   578/ 1097] train: loss: 0.1043604
[Epoch 27; Iter   608/ 1097] train: loss: 0.0582687
[Epoch 27; Iter   638/ 1097] train: loss: 0.0201029
[Epoch 27; Iter   668/ 1097] train: loss: 0.0319361
[Epoch 27; Iter   698/ 1097] train: loss: 0.1656369
[Epoch 27; Iter   728/ 1097] train: loss: 0.1647203
[Epoch 27; Iter   758/ 1097] train: loss: 0.0256166
[Epoch 27; Iter   788/ 1097] train: loss: 0.1455986
[Epoch 27; Iter   818/ 1097] train: loss: 0.0171020
[Epoch 27; Iter   848/ 1097] train: loss: 0.0194818
[Epoch 27; Iter   878/ 1097] train: loss: 0.0387069
[Epoch 27; Iter   908/ 1097] train: loss: 0.1560633
[Epoch 27; Iter   938/ 1097] train: loss: 0.0388211
[Epoch 27; Iter   968/ 1097] train: loss: 0.0078504
[Epoch 27; Iter   998/ 1097] train: loss: 0.0485256
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1098857
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0475203
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0087483
[Epoch 27] ogbg-molhiv: 0.734767 val loss: 12.055619
[Epoch 27] ogbg-molhiv: 0.635356 test loss: 9.871751
[Epoch 28; Iter    21/ 1097] train: loss: 0.0597887
[Epoch 28; Iter    51/ 1097] train: loss: 0.0371691
[Epoch 28; Iter    81/ 1097] train: loss: 0.0353948
[Epoch 28; Iter   111/ 1097] train: loss: 0.0448002
[Epoch 28; Iter   141/ 1097] train: loss: 0.0100341
[Epoch 28; Iter   171/ 1097] train: loss: 0.1678805
[Epoch 28; Iter   201/ 1097] train: loss: 0.0111794
[Epoch 28; Iter   231/ 1097] train: loss: 0.0191056
[Epoch 28; Iter   261/ 1097] train: loss: 0.0464335
[Epoch 28; Iter   291/ 1097] train: loss: 0.0321293
[Epoch 28; Iter   321/ 1097] train: loss: 0.0051216
[Epoch 28; Iter   351/ 1097] train: loss: 0.0807671
[Epoch 28; Iter   381/ 1097] train: loss: 0.0335156
[Epoch 28; Iter   411/ 1097] train: loss: 0.0310316
[Epoch 28; Iter   441/ 1097] train: loss: 0.0139557
[Epoch 24; Iter   389/ 1097] train: loss: 0.2093373
[Epoch 24; Iter   419/ 1097] train: loss: 0.5325453
[Epoch 24; Iter   449/ 1097] train: loss: 0.0299747
[Epoch 24; Iter   479/ 1097] train: loss: 0.0916005
[Epoch 24; Iter   509/ 1097] train: loss: 0.0207804
[Epoch 24; Iter   539/ 1097] train: loss: 0.0238143
[Epoch 24; Iter   569/ 1097] train: loss: 0.1328837
[Epoch 24; Iter   599/ 1097] train: loss: 0.2167560
[Epoch 24; Iter   629/ 1097] train: loss: 0.0232047
[Epoch 24; Iter   659/ 1097] train: loss: 0.0268228
[Epoch 24; Iter   689/ 1097] train: loss: 0.0174654
[Epoch 24; Iter   719/ 1097] train: loss: 0.0208064
[Epoch 24; Iter   749/ 1097] train: loss: 0.0278130
[Epoch 24; Iter   779/ 1097] train: loss: 0.0854040
[Epoch 24; Iter   809/ 1097] train: loss: 0.0258483
[Epoch 24; Iter   839/ 1097] train: loss: 0.2233053
[Epoch 24; Iter   869/ 1097] train: loss: 0.1733495
[Epoch 24; Iter   899/ 1097] train: loss: 0.1839302
[Epoch 24; Iter   929/ 1097] train: loss: 0.2490823
[Epoch 24; Iter   959/ 1097] train: loss: 0.0235905
[Epoch 24; Iter   989/ 1097] train: loss: 0.0365030
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1424507
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0304865
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0487587
[Epoch 24] ogbg-molhiv: 0.724090 val loss: 0.115924
[Epoch 24] ogbg-molhiv: 0.675691 test loss: 0.157817
[Epoch 25; Iter    12/ 1097] train: loss: 0.0239441
[Epoch 25; Iter    42/ 1097] train: loss: 0.1575669
[Epoch 25; Iter    72/ 1097] train: loss: 0.0556362
[Epoch 25; Iter   102/ 1097] train: loss: 0.0417605
[Epoch 25; Iter   132/ 1097] train: loss: 0.0530799
[Epoch 25; Iter   162/ 1097] train: loss: 0.0520592
[Epoch 25; Iter   192/ 1097] train: loss: 0.1684679
[Epoch 25; Iter   222/ 1097] train: loss: 0.0288605
[Epoch 25; Iter   252/ 1097] train: loss: 0.0183252
[Epoch 25; Iter   282/ 1097] train: loss: 0.1553314
[Epoch 25; Iter   312/ 1097] train: loss: 0.0319852
[Epoch 25; Iter   342/ 1097] train: loss: 0.0783784
[Epoch 25; Iter   372/ 1097] train: loss: 0.1355734
[Epoch 25; Iter   402/ 1097] train: loss: 0.0196560
[Epoch 25; Iter   432/ 1097] train: loss: 0.3833064
[Epoch 25; Iter   462/ 1097] train: loss: 0.0203799
[Epoch 25; Iter   492/ 1097] train: loss: 0.2362129
[Epoch 25; Iter   522/ 1097] train: loss: 0.0101156
[Epoch 25; Iter   552/ 1097] train: loss: 0.2031929
[Epoch 25; Iter   582/ 1097] train: loss: 0.1336562
[Epoch 25; Iter   612/ 1097] train: loss: 0.2406092
[Epoch 25; Iter   642/ 1097] train: loss: 0.1842119
[Epoch 25; Iter   672/ 1097] train: loss: 0.0262135
[Epoch 25; Iter   702/ 1097] train: loss: 0.0675154
[Epoch 25; Iter   732/ 1097] train: loss: 0.0217454
[Epoch 25; Iter   762/ 1097] train: loss: 0.1300510
[Epoch 25; Iter   792/ 1097] train: loss: 0.0924256
[Epoch 25; Iter   822/ 1097] train: loss: 0.1238156
[Epoch 25; Iter   852/ 1097] train: loss: 0.0329279
[Epoch 25; Iter   882/ 1097] train: loss: 0.0559986
[Epoch 25; Iter   912/ 1097] train: loss: 0.1532410
[Epoch 25; Iter   942/ 1097] train: loss: 0.0796730
[Epoch 25; Iter   972/ 1097] train: loss: 0.0703908
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2089953
[Epoch 25; Iter  1032/ 1097] train: loss: 0.1827428
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0273643
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0965541
[Epoch 25] ogbg-molhiv: 0.752694 val loss: 0.121566
[Epoch 25] ogbg-molhiv: 0.669026 test loss: 0.138726
[Epoch 26; Iter    25/ 1097] train: loss: 0.0204411
[Epoch 26; Iter    55/ 1097] train: loss: 0.0297160
[Epoch 26; Iter    85/ 1097] train: loss: 0.1386160
[Epoch 26; Iter   115/ 1097] train: loss: 0.1796853
[Epoch 26; Iter   145/ 1097] train: loss: 0.0957519
[Epoch 26; Iter   175/ 1097] train: loss: 0.0680131
[Epoch 26; Iter   205/ 1097] train: loss: 0.3846610
[Epoch 26; Iter   235/ 1097] train: loss: 0.0255540
[Epoch 26; Iter   265/ 1097] train: loss: 0.1358392
[Epoch 26; Iter   295/ 1097] train: loss: 0.1303637
[Epoch 26; Iter   325/ 1097] train: loss: 0.0397166
[Epoch 26; Iter   355/ 1097] train: loss: 0.0295832
[Epoch 26; Iter   385/ 1097] train: loss: 0.0725579
[Epoch 26; Iter   415/ 1097] train: loss: 0.0444932
[Epoch 26; Iter   445/ 1097] train: loss: 0.0216238
[Epoch 26; Iter   475/ 1097] train: loss: 0.1099616
[Epoch 26; Iter   505/ 1097] train: loss: 0.1218347
[Epoch 26; Iter   535/ 1097] train: loss: 0.2000040
[Epoch 26; Iter   565/ 1097] train: loss: 0.0346450
[Epoch 26; Iter   595/ 1097] train: loss: 0.0265858
[Epoch 26; Iter   625/ 1097] train: loss: 0.0529983
[Epoch 26; Iter   655/ 1097] train: loss: 0.0368446
[Epoch 26; Iter   685/ 1097] train: loss: 0.2402616
[Epoch 26; Iter   715/ 1097] train: loss: 0.0304102
[Epoch 26; Iter   745/ 1097] train: loss: 0.0158300
[Epoch 26; Iter   775/ 1097] train: loss: 0.0468903
[Epoch 26; Iter   805/ 1097] train: loss: 0.1022428
[Epoch 26; Iter   835/ 1097] train: loss: 0.1521456
[Epoch 26; Iter   865/ 1097] train: loss: 0.1812565
[Epoch 26; Iter   895/ 1097] train: loss: 0.0363168
[Epoch 26; Iter   925/ 1097] train: loss: 0.2405567
[Epoch 26; Iter   955/ 1097] train: loss: 0.0154994
[Epoch 26; Iter   985/ 1097] train: loss: 0.1472396
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0333580
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0261334
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1042716
[Epoch 26] ogbg-molhiv: 0.730982 val loss: 0.314085
[Epoch 26] ogbg-molhiv: 0.657042 test loss: 0.387197
[Epoch 27; Iter     8/ 1097] train: loss: 0.0389741
[Epoch 27; Iter    38/ 1097] train: loss: 0.0419089
[Epoch 27; Iter    68/ 1097] train: loss: 0.0484089
[Epoch 27; Iter    98/ 1097] train: loss: 0.1265843
[Epoch 27; Iter   128/ 1097] train: loss: 0.2141987
[Epoch 27; Iter   158/ 1097] train: loss: 0.0504030
[Epoch 27; Iter   188/ 1097] train: loss: 0.0384025
[Epoch 27; Iter   218/ 1097] train: loss: 0.0292822
[Epoch 27; Iter   248/ 1097] train: loss: 0.0917493
[Epoch 27; Iter   278/ 1097] train: loss: 0.0158496
[Epoch 27; Iter   308/ 1097] train: loss: 0.0566369
[Epoch 27; Iter   338/ 1097] train: loss: 0.0085023
[Epoch 27; Iter   368/ 1097] train: loss: 0.1252606
[Epoch 27; Iter   398/ 1097] train: loss: 0.0214205
[Epoch 27; Iter   428/ 1097] train: loss: 0.1098033
[Epoch 27; Iter   458/ 1097] train: loss: 0.0164671
[Epoch 27; Iter   488/ 1097] train: loss: 0.1415933
[Epoch 27; Iter   518/ 1097] train: loss: 0.3389515
[Epoch 27; Iter   548/ 1097] train: loss: 0.2031828
[Epoch 27; Iter   578/ 1097] train: loss: 0.0557728
[Epoch 27; Iter   608/ 1097] train: loss: 0.1904997
[Epoch 27; Iter   638/ 1097] train: loss: 0.0607143
[Epoch 27; Iter   668/ 1097] train: loss: 0.0783895
[Epoch 27; Iter   698/ 1097] train: loss: 0.0246620
[Epoch 27; Iter   728/ 1097] train: loss: 0.3401280
[Epoch 27; Iter   758/ 1097] train: loss: 0.0260289
[Epoch 27; Iter   788/ 1097] train: loss: 0.0261547
[Epoch 27; Iter   818/ 1097] train: loss: 0.0962105
[Epoch 27; Iter   848/ 1097] train: loss: 0.1339952
[Epoch 27; Iter   878/ 1097] train: loss: 0.0700340
[Epoch 27; Iter   908/ 1097] train: loss: 0.0356359
[Epoch 27; Iter   938/ 1097] train: loss: 0.1344720
[Epoch 27; Iter   968/ 1097] train: loss: 0.0315803
[Epoch 27; Iter   998/ 1097] train: loss: 0.1564154
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1017523
[Epoch 27; Iter  1058/ 1097] train: loss: 0.3462632
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1432066
[Epoch 27] ogbg-molhiv: 0.679144 val loss: 1.061622
[Epoch 27] ogbg-molhiv: 0.605126 test loss: 0.923348
[Epoch 28; Iter    21/ 1097] train: loss: 0.0203157
[Epoch 28; Iter    51/ 1097] train: loss: 0.0643624
[Epoch 28; Iter    81/ 1097] train: loss: 0.0324675
[Epoch 28; Iter   111/ 1097] train: loss: 0.1307637
[Epoch 28; Iter   141/ 1097] train: loss: 0.2969389
[Epoch 28; Iter   171/ 1097] train: loss: 0.0927653
[Epoch 28; Iter   201/ 1097] train: loss: 0.1271012
[Epoch 28; Iter   231/ 1097] train: loss: 0.0675175
[Epoch 28; Iter   261/ 1097] train: loss: 0.2120354
[Epoch 28; Iter   291/ 1097] train: loss: 0.0432237
[Epoch 28; Iter   321/ 1097] train: loss: 0.0403505
[Epoch 28; Iter   351/ 1097] train: loss: 0.0219693
[Epoch 28; Iter   381/ 1097] train: loss: 0.0978868
[Epoch 28; Iter   411/ 1097] train: loss: 0.0186445
[Epoch 28; Iter   441/ 1097] train: loss: 0.6482431
[Epoch 28; Iter   441/ 1097] train: loss: 0.5815949
[Epoch 28; Iter   471/ 1097] train: loss: 0.0312622
[Epoch 28; Iter   501/ 1097] train: loss: 0.0932919
[Epoch 28; Iter   531/ 1097] train: loss: 0.0098081
[Epoch 28; Iter   561/ 1097] train: loss: 0.0664732
[Epoch 28; Iter   591/ 1097] train: loss: 0.1084433
[Epoch 28; Iter   621/ 1097] train: loss: 0.1336687
[Epoch 28; Iter   651/ 1097] train: loss: 0.0324320
[Epoch 28; Iter   681/ 1097] train: loss: 0.0157664
[Epoch 28; Iter   711/ 1097] train: loss: 0.0357939
[Epoch 28; Iter   741/ 1097] train: loss: 0.0105271
[Epoch 28; Iter   771/ 1097] train: loss: 0.0751436
[Epoch 28; Iter   801/ 1097] train: loss: 0.0104516
[Epoch 28; Iter   831/ 1097] train: loss: 0.0443438
[Epoch 28; Iter   861/ 1097] train: loss: 0.2477482
[Epoch 28; Iter   891/ 1097] train: loss: 0.0607142
[Epoch 28; Iter   921/ 1097] train: loss: 0.0353584
[Epoch 28; Iter   951/ 1097] train: loss: 0.0112776
[Epoch 28; Iter   981/ 1097] train: loss: 0.0339792
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0234098
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0142814
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0229358
[Epoch 28] ogbg-molhiv: 0.811162 val loss: 0.167605
[Epoch 28] ogbg-molhiv: 0.755057 test loss: 0.135933
[Epoch 29; Iter     4/ 1097] train: loss: 0.0065934
[Epoch 29; Iter    34/ 1097] train: loss: 0.0143184
[Epoch 29; Iter    64/ 1097] train: loss: 0.0536306
[Epoch 29; Iter    94/ 1097] train: loss: 0.0270908
[Epoch 29; Iter   124/ 1097] train: loss: 0.1018075
[Epoch 29; Iter   154/ 1097] train: loss: 0.0535412
[Epoch 29; Iter   184/ 1097] train: loss: 0.0157371
[Epoch 29; Iter   214/ 1097] train: loss: 0.0111696
[Epoch 29; Iter   244/ 1097] train: loss: 0.0226158
[Epoch 29; Iter   274/ 1097] train: loss: 0.0206086
[Epoch 29; Iter   304/ 1097] train: loss: 0.1121656
[Epoch 29; Iter   334/ 1097] train: loss: 0.0215782
[Epoch 29; Iter   364/ 1097] train: loss: 0.0340598
[Epoch 29; Iter   394/ 1097] train: loss: 0.0290596
[Epoch 29; Iter   424/ 1097] train: loss: 0.0184435
[Epoch 29; Iter   454/ 1097] train: loss: 0.0213133
[Epoch 29; Iter   484/ 1097] train: loss: 0.0198294
[Epoch 29; Iter   514/ 1097] train: loss: 0.0461457
[Epoch 29; Iter   544/ 1097] train: loss: 0.0205514
[Epoch 29; Iter   574/ 1097] train: loss: 0.0067195
[Epoch 29; Iter   604/ 1097] train: loss: 0.0229036
[Epoch 29; Iter   634/ 1097] train: loss: 0.2527081
[Epoch 29; Iter   664/ 1097] train: loss: 0.0121645
[Epoch 29; Iter   694/ 1097] train: loss: 0.0098513
[Epoch 29; Iter   724/ 1097] train: loss: 0.0122658
[Epoch 29; Iter   754/ 1097] train: loss: 0.0617930
[Epoch 29; Iter   784/ 1097] train: loss: 0.0480132
[Epoch 29; Iter   814/ 1097] train: loss: 0.0223182
[Epoch 29; Iter   844/ 1097] train: loss: 0.0495727
[Epoch 29; Iter   874/ 1097] train: loss: 0.1328781
[Epoch 29; Iter   904/ 1097] train: loss: 0.0159986
[Epoch 29; Iter   934/ 1097] train: loss: 0.2501986
[Epoch 29; Iter   964/ 1097] train: loss: 0.0093703
[Epoch 29; Iter   994/ 1097] train: loss: 0.0241562
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0391835
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0228868
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0672131
[Epoch 29] ogbg-molhiv: 0.829316 val loss: 1.018764
[Epoch 29] ogbg-molhiv: 0.747598 test loss: 0.509222
[Epoch 30; Iter    17/ 1097] train: loss: 0.0068121
[Epoch 30; Iter    47/ 1097] train: loss: 0.1032788
[Epoch 30; Iter    77/ 1097] train: loss: 0.0275292
[Epoch 30; Iter   107/ 1097] train: loss: 0.0951431
[Epoch 30; Iter   137/ 1097] train: loss: 0.0055408
[Epoch 30; Iter   167/ 1097] train: loss: 0.0060673
[Epoch 30; Iter   197/ 1097] train: loss: 0.0117108
[Epoch 30; Iter   227/ 1097] train: loss: 0.0119696
[Epoch 30; Iter   257/ 1097] train: loss: 0.0884373
[Epoch 30; Iter   287/ 1097] train: loss: 0.0155551
[Epoch 30; Iter   317/ 1097] train: loss: 0.0455544
[Epoch 30; Iter   347/ 1097] train: loss: 0.0741602
[Epoch 30; Iter   377/ 1097] train: loss: 0.0500695
[Epoch 30; Iter   407/ 1097] train: loss: 0.0190992
[Epoch 30; Iter   437/ 1097] train: loss: 0.0149388
[Epoch 30; Iter   467/ 1097] train: loss: 0.0094053
[Epoch 30; Iter   497/ 1097] train: loss: 0.0724710
[Epoch 30; Iter   527/ 1097] train: loss: 0.0123145
[Epoch 30; Iter   557/ 1097] train: loss: 0.0762525
[Epoch 30; Iter   587/ 1097] train: loss: 0.0596947
[Epoch 30; Iter   617/ 1097] train: loss: 0.0106151
[Epoch 30; Iter   647/ 1097] train: loss: 0.0245318
[Epoch 30; Iter   677/ 1097] train: loss: 0.0225242
[Epoch 30; Iter   707/ 1097] train: loss: 0.1138954
[Epoch 30; Iter   737/ 1097] train: loss: 0.1167697
[Epoch 30; Iter   767/ 1097] train: loss: 0.0822461
[Epoch 30; Iter   797/ 1097] train: loss: 0.1420215
[Epoch 30; Iter   827/ 1097] train: loss: 0.0978426
[Epoch 30; Iter   857/ 1097] train: loss: 0.0093350
[Epoch 30; Iter   887/ 1097] train: loss: 0.0245677
[Epoch 30; Iter   917/ 1097] train: loss: 0.0253860
[Epoch 30; Iter   947/ 1097] train: loss: 0.0389408
[Epoch 30; Iter   977/ 1097] train: loss: 0.0063633
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0545687
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1282380
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0170316
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0170044
[Epoch 30] ogbg-molhiv: 0.819950 val loss: 0.648767
[Epoch 30] ogbg-molhiv: 0.733573 test loss: 0.235568
[Epoch 31; Iter    30/ 1097] train: loss: 0.0051875
[Epoch 31; Iter    60/ 1097] train: loss: 0.1543587
[Epoch 31; Iter    90/ 1097] train: loss: 0.0169278
[Epoch 31; Iter   120/ 1097] train: loss: 0.0128978
[Epoch 31; Iter   150/ 1097] train: loss: 0.1209767
[Epoch 31; Iter   180/ 1097] train: loss: 0.0776983
[Epoch 31; Iter   210/ 1097] train: loss: 0.0070699
[Epoch 31; Iter   240/ 1097] train: loss: 0.0281310
[Epoch 31; Iter   270/ 1097] train: loss: 0.0176196
[Epoch 31; Iter   300/ 1097] train: loss: 0.0244425
[Epoch 31; Iter   330/ 1097] train: loss: 0.0794818
[Epoch 31; Iter   360/ 1097] train: loss: 0.0575512
[Epoch 31; Iter   390/ 1097] train: loss: 0.0062500
[Epoch 31; Iter   420/ 1097] train: loss: 0.0881689
[Epoch 31; Iter   450/ 1097] train: loss: 0.0817943
[Epoch 31; Iter   480/ 1097] train: loss: 0.1726903
[Epoch 31; Iter   510/ 1097] train: loss: 0.0204515
[Epoch 31; Iter   540/ 1097] train: loss: 0.0168036
[Epoch 31; Iter   570/ 1097] train: loss: 0.1307640
[Epoch 31; Iter   600/ 1097] train: loss: 0.0418238
[Epoch 31; Iter   630/ 1097] train: loss: 0.0056823
[Epoch 31; Iter   660/ 1097] train: loss: 0.0156164
[Epoch 31; Iter   690/ 1097] train: loss: 0.0070631
[Epoch 31; Iter   720/ 1097] train: loss: 0.0386827
[Epoch 31; Iter   750/ 1097] train: loss: 0.0243038
[Epoch 31; Iter   780/ 1097] train: loss: 0.0432198
[Epoch 31; Iter   810/ 1097] train: loss: 0.0201272
[Epoch 31; Iter   840/ 1097] train: loss: 0.0811351
[Epoch 31; Iter   870/ 1097] train: loss: 0.0570918
[Epoch 31; Iter   900/ 1097] train: loss: 0.0150712
[Epoch 31; Iter   930/ 1097] train: loss: 0.0057709
[Epoch 31; Iter   960/ 1097] train: loss: 0.0208603
[Epoch 31; Iter   990/ 1097] train: loss: 0.0147057
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0514781
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1910937
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0259038
[Epoch 31] ogbg-molhiv: 0.835471 val loss: 1.156229
[Epoch 31] ogbg-molhiv: 0.740107 test loss: 0.365508
[Epoch 32; Iter    13/ 1097] train: loss: 0.0106507
[Epoch 32; Iter    43/ 1097] train: loss: 0.0433540
[Epoch 32; Iter    73/ 1097] train: loss: 0.0089581
[Epoch 32; Iter   103/ 1097] train: loss: 0.0089164
[Epoch 32; Iter   133/ 1097] train: loss: 0.0041077
[Epoch 32; Iter   163/ 1097] train: loss: 0.1510288
[Epoch 32; Iter   193/ 1097] train: loss: 0.0995540
[Epoch 32; Iter   223/ 1097] train: loss: 0.0085167
[Epoch 32; Iter   253/ 1097] train: loss: 0.0073727
[Epoch 32; Iter   283/ 1097] train: loss: 0.0389474
[Epoch 32; Iter   313/ 1097] train: loss: 0.0168892
[Epoch 32; Iter   343/ 1097] train: loss: 0.0795338
[Epoch 32; Iter   373/ 1097] train: loss: 0.1023643
[Epoch 32; Iter   403/ 1097] train: loss: 0.0484604
[Epoch 32; Iter   433/ 1097] train: loss: 0.0117125
[Epoch 32; Iter   463/ 1097] train: loss: 0.1376171
[Epoch 32; Iter   493/ 1097] train: loss: 0.0812786
[Epoch 28; Iter   441/ 1097] train: loss: 0.0101249
[Epoch 28; Iter   471/ 1097] train: loss: 0.0251524
[Epoch 28; Iter   501/ 1097] train: loss: 0.0392266
[Epoch 28; Iter   531/ 1097] train: loss: 0.2948354
[Epoch 28; Iter   561/ 1097] train: loss: 0.0155303
[Epoch 28; Iter   591/ 1097] train: loss: 0.3159563
[Epoch 28; Iter   621/ 1097] train: loss: 0.0337225
[Epoch 28; Iter   651/ 1097] train: loss: 0.2415306
[Epoch 28; Iter   681/ 1097] train: loss: 0.0253638
[Epoch 28; Iter   711/ 1097] train: loss: 0.0382640
[Epoch 28; Iter   741/ 1097] train: loss: 0.0173792
[Epoch 28; Iter   771/ 1097] train: loss: 0.0413790
[Epoch 28; Iter   801/ 1097] train: loss: 0.2934102
[Epoch 28; Iter   831/ 1097] train: loss: 0.0382486
[Epoch 28; Iter   861/ 1097] train: loss: 0.0438770
[Epoch 28; Iter   891/ 1097] train: loss: 0.1614088
[Epoch 28; Iter   921/ 1097] train: loss: 0.0684575
[Epoch 28; Iter   951/ 1097] train: loss: 0.0190398
[Epoch 28; Iter   981/ 1097] train: loss: 0.0195581
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0100894
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0783989
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1804647
[Epoch 28] ogbg-molhiv: 0.826658 val loss: 0.169696
[Epoch 28] ogbg-molhiv: 0.720064 test loss: 0.323831
[Epoch 29; Iter     4/ 1097] train: loss: 0.1039673
[Epoch 29; Iter    34/ 1097] train: loss: 0.0120833
[Epoch 29; Iter    64/ 1097] train: loss: 0.2594546
[Epoch 29; Iter    94/ 1097] train: loss: 0.0139374
[Epoch 29; Iter   124/ 1097] train: loss: 0.0650666
[Epoch 29; Iter   154/ 1097] train: loss: 0.1411967
[Epoch 29; Iter   184/ 1097] train: loss: 0.0615481
[Epoch 29; Iter   214/ 1097] train: loss: 0.0599359
[Epoch 29; Iter   244/ 1097] train: loss: 0.0144715
[Epoch 29; Iter   274/ 1097] train: loss: 0.0700111
[Epoch 29; Iter   304/ 1097] train: loss: 0.0382547
[Epoch 29; Iter   334/ 1097] train: loss: 0.0514780
[Epoch 29; Iter   364/ 1097] train: loss: 0.0992598
[Epoch 29; Iter   394/ 1097] train: loss: 0.0728632
[Epoch 29; Iter   424/ 1097] train: loss: 0.0370358
[Epoch 29; Iter   454/ 1097] train: loss: 0.0185460
[Epoch 29; Iter   484/ 1097] train: loss: 0.0400474
[Epoch 29; Iter   514/ 1097] train: loss: 0.0304593
[Epoch 29; Iter   544/ 1097] train: loss: 0.0135955
[Epoch 29; Iter   574/ 1097] train: loss: 0.0279435
[Epoch 29; Iter   604/ 1097] train: loss: 0.0129304
[Epoch 29; Iter   634/ 1097] train: loss: 0.0058857
[Epoch 29; Iter   664/ 1097] train: loss: 0.0138275
[Epoch 29; Iter   694/ 1097] train: loss: 0.0577671
[Epoch 29; Iter   724/ 1097] train: loss: 0.0178836
[Epoch 29; Iter   754/ 1097] train: loss: 0.0217167
[Epoch 29; Iter   784/ 1097] train: loss: 0.2716828
[Epoch 29; Iter   814/ 1097] train: loss: 0.0919751
[Epoch 29; Iter   844/ 1097] train: loss: 0.0083790
[Epoch 29; Iter   874/ 1097] train: loss: 0.0658746
[Epoch 29; Iter   904/ 1097] train: loss: 0.0094400
[Epoch 29; Iter   934/ 1097] train: loss: 0.0066859
[Epoch 29; Iter   964/ 1097] train: loss: 0.0297921
[Epoch 29; Iter   994/ 1097] train: loss: 0.0160204
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0463931
[Epoch 29; Iter  1054/ 1097] train: loss: 0.2068173
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1439058
[Epoch 29] ogbg-molhiv: 0.823746 val loss: 0.512861
[Epoch 29] ogbg-molhiv: 0.710921 test loss: 0.201117
[Epoch 30; Iter    17/ 1097] train: loss: 0.0240474
[Epoch 30; Iter    47/ 1097] train: loss: 0.0118515
[Epoch 30; Iter    77/ 1097] train: loss: 0.0031497
[Epoch 30; Iter   107/ 1097] train: loss: 0.0116517
[Epoch 30; Iter   137/ 1097] train: loss: 0.0116734
[Epoch 30; Iter   167/ 1097] train: loss: 0.1038186
[Epoch 30; Iter   197/ 1097] train: loss: 0.1041827
[Epoch 30; Iter   227/ 1097] train: loss: 0.0124711
[Epoch 30; Iter   257/ 1097] train: loss: 0.1036858
[Epoch 30; Iter   287/ 1097] train: loss: 0.0109370
[Epoch 30; Iter   317/ 1097] train: loss: 0.0965631
[Epoch 30; Iter   347/ 1097] train: loss: 0.0073602
[Epoch 30; Iter   377/ 1097] train: loss: 0.1204185
[Epoch 30; Iter   407/ 1097] train: loss: 0.0103389
[Epoch 30; Iter   437/ 1097] train: loss: 0.0128746
[Epoch 30; Iter   467/ 1097] train: loss: 0.0085795
[Epoch 30; Iter   497/ 1097] train: loss: 0.1104093
[Epoch 30; Iter   527/ 1097] train: loss: 0.0469533
[Epoch 30; Iter   557/ 1097] train: loss: 0.0263646
[Epoch 30; Iter   587/ 1097] train: loss: 0.0584754
[Epoch 30; Iter   617/ 1097] train: loss: 0.0149417
[Epoch 30; Iter   647/ 1097] train: loss: 0.0360980
[Epoch 30; Iter   677/ 1097] train: loss: 0.0181952
[Epoch 30; Iter   707/ 1097] train: loss: 0.0108159
[Epoch 30; Iter   737/ 1097] train: loss: 0.0086701
[Epoch 30; Iter   767/ 1097] train: loss: 0.0234524
[Epoch 30; Iter   797/ 1097] train: loss: 0.0344271
[Epoch 30; Iter   827/ 1097] train: loss: 0.0599775
[Epoch 30; Iter   857/ 1097] train: loss: 0.0166176
[Epoch 30; Iter   887/ 1097] train: loss: 0.0064811
[Epoch 30; Iter   917/ 1097] train: loss: 0.0797298
[Epoch 30; Iter   947/ 1097] train: loss: 0.0428251
[Epoch 30; Iter   977/ 1097] train: loss: 0.0654688
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0084858
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0368095
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0234741
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0038785
[Epoch 30] ogbg-molhiv: 0.817757 val loss: 1.387415
[Epoch 30] ogbg-molhiv: 0.706622 test loss: 0.239673
[Epoch 31; Iter    30/ 1097] train: loss: 0.0094712
[Epoch 31; Iter    60/ 1097] train: loss: 0.0461076
[Epoch 31; Iter    90/ 1097] train: loss: 0.0283928
[Epoch 31; Iter   120/ 1097] train: loss: 0.0080001
[Epoch 31; Iter   150/ 1097] train: loss: 0.0164713
[Epoch 31; Iter   180/ 1097] train: loss: 0.0613960
[Epoch 31; Iter   210/ 1097] train: loss: 0.0083241
[Epoch 31; Iter   240/ 1097] train: loss: 0.1438998
[Epoch 31; Iter   270/ 1097] train: loss: 0.0046613
[Epoch 31; Iter   300/ 1097] train: loss: 0.0114616
[Epoch 31; Iter   330/ 1097] train: loss: 0.0180183
[Epoch 31; Iter   360/ 1097] train: loss: 0.0630475
[Epoch 31; Iter   390/ 1097] train: loss: 0.0580924
[Epoch 31; Iter   420/ 1097] train: loss: 0.0231232
[Epoch 31; Iter   450/ 1097] train: loss: 0.0210974
[Epoch 31; Iter   480/ 1097] train: loss: 0.0118862
[Epoch 31; Iter   510/ 1097] train: loss: 0.0321896
[Epoch 31; Iter   540/ 1097] train: loss: 0.1000481
[Epoch 31; Iter   570/ 1097] train: loss: 0.0102385
[Epoch 31; Iter   600/ 1097] train: loss: 0.0108014
[Epoch 31; Iter   630/ 1097] train: loss: 0.1585201
[Epoch 31; Iter   660/ 1097] train: loss: 0.0094601
[Epoch 31; Iter   690/ 1097] train: loss: 0.1889621
[Epoch 31; Iter   720/ 1097] train: loss: 0.1099760
[Epoch 31; Iter   750/ 1097] train: loss: 0.0742902
[Epoch 31; Iter   780/ 1097] train: loss: 0.0341337
[Epoch 31; Iter   810/ 1097] train: loss: 0.0204779
[Epoch 31; Iter   840/ 1097] train: loss: 0.0049397
[Epoch 31; Iter   870/ 1097] train: loss: 0.0033493
[Epoch 31; Iter   900/ 1097] train: loss: 0.0854508
[Epoch 31; Iter   930/ 1097] train: loss: 0.0312479
[Epoch 31; Iter   960/ 1097] train: loss: 0.0250769
[Epoch 31; Iter   990/ 1097] train: loss: 0.0444807
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0309513
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0481046
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0098295
[Epoch 31] ogbg-molhiv: 0.797163 val loss: 0.833661
[Epoch 31] ogbg-molhiv: 0.660509 test loss: 1.597122
[Epoch 32; Iter    13/ 1097] train: loss: 0.3421840
[Epoch 32; Iter    43/ 1097] train: loss: 0.0264558
[Epoch 32; Iter    73/ 1097] train: loss: 0.0054448
[Epoch 32; Iter   103/ 1097] train: loss: 0.0704223
[Epoch 32; Iter   133/ 1097] train: loss: 0.0202805
[Epoch 32; Iter   163/ 1097] train: loss: 0.0029018
[Epoch 32; Iter   193/ 1097] train: loss: 0.0301365
[Epoch 32; Iter   223/ 1097] train: loss: 0.0164577
[Epoch 32; Iter   253/ 1097] train: loss: 0.0397422
[Epoch 32; Iter   283/ 1097] train: loss: 0.0131036
[Epoch 32; Iter   313/ 1097] train: loss: 0.0222761
[Epoch 32; Iter   343/ 1097] train: loss: 0.0257328
[Epoch 32; Iter   373/ 1097] train: loss: 0.0145835
[Epoch 32; Iter   403/ 1097] train: loss: 0.2358964
[Epoch 32; Iter   433/ 1097] train: loss: 0.0410593
[Epoch 32; Iter   463/ 1097] train: loss: 0.0043045
[Epoch 32; Iter   493/ 1097] train: loss: 0.0100888
[Epoch 28; Iter   471/ 1097] train: loss: 0.1535829
[Epoch 28; Iter   501/ 1097] train: loss: 0.0745196
[Epoch 28; Iter   531/ 1097] train: loss: 0.0183368
[Epoch 28; Iter   561/ 1097] train: loss: 0.0182907
[Epoch 28; Iter   591/ 1097] train: loss: 0.0471218
[Epoch 28; Iter   621/ 1097] train: loss: 0.0227198
[Epoch 28; Iter   651/ 1097] train: loss: 0.0142274
[Epoch 28; Iter   681/ 1097] train: loss: 0.1179534
[Epoch 28; Iter   711/ 1097] train: loss: 0.0405655
[Epoch 28; Iter   741/ 1097] train: loss: 0.0084225
[Epoch 28; Iter   771/ 1097] train: loss: 0.0235148
[Epoch 28; Iter   801/ 1097] train: loss: 0.0183199
[Epoch 28; Iter   831/ 1097] train: loss: 0.1404321
[Epoch 28; Iter   861/ 1097] train: loss: 0.0125141
[Epoch 28; Iter   891/ 1097] train: loss: 0.0105821
[Epoch 28; Iter   921/ 1097] train: loss: 0.0729286
[Epoch 28; Iter   951/ 1097] train: loss: 0.0319033
[Epoch 28; Iter   981/ 1097] train: loss: 0.0582679
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0595349
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0075334
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0925568
[Epoch 28] ogbg-molhiv: 0.773773 val loss: 0.093489
[Epoch 28] ogbg-molhiv: 0.695529 test loss: 0.153929
[Epoch 29; Iter     4/ 1097] train: loss: 0.0207804
[Epoch 29; Iter    34/ 1097] train: loss: 0.0941321
[Epoch 29; Iter    64/ 1097] train: loss: 0.0599001
[Epoch 29; Iter    94/ 1097] train: loss: 0.0414686
[Epoch 29; Iter   124/ 1097] train: loss: 0.0274708
[Epoch 29; Iter   154/ 1097] train: loss: 0.0342277
[Epoch 29; Iter   184/ 1097] train: loss: 0.0334378
[Epoch 29; Iter   214/ 1097] train: loss: 0.0402338
[Epoch 29; Iter   244/ 1097] train: loss: 0.2526251
[Epoch 29; Iter   274/ 1097] train: loss: 0.0151643
[Epoch 29; Iter   304/ 1097] train: loss: 0.0094927
[Epoch 29; Iter   334/ 1097] train: loss: 0.2993347
[Epoch 29; Iter   364/ 1097] train: loss: 0.0117757
[Epoch 29; Iter   394/ 1097] train: loss: 0.0663503
[Epoch 29; Iter   424/ 1097] train: loss: 0.0196512
[Epoch 29; Iter   454/ 1097] train: loss: 0.0447632
[Epoch 29; Iter   484/ 1097] train: loss: 0.0533566
[Epoch 29; Iter   514/ 1097] train: loss: 0.0292945
[Epoch 29; Iter   544/ 1097] train: loss: 0.0076030
[Epoch 29; Iter   574/ 1097] train: loss: 0.0573552
[Epoch 29; Iter   604/ 1097] train: loss: 0.1020322
[Epoch 29; Iter   634/ 1097] train: loss: 0.0189194
[Epoch 29; Iter   664/ 1097] train: loss: 0.0228322
[Epoch 29; Iter   694/ 1097] train: loss: 0.1575110
[Epoch 29; Iter   724/ 1097] train: loss: 0.0441878
[Epoch 29; Iter   754/ 1097] train: loss: 0.0208107
[Epoch 29; Iter   784/ 1097] train: loss: 0.0187341
[Epoch 29; Iter   814/ 1097] train: loss: 0.0562886
[Epoch 29; Iter   844/ 1097] train: loss: 0.0898800
[Epoch 29; Iter   874/ 1097] train: loss: 0.0215119
[Epoch 29; Iter   904/ 1097] train: loss: 0.0923223
[Epoch 29; Iter   934/ 1097] train: loss: 0.0185038
[Epoch 29; Iter   964/ 1097] train: loss: 0.0187021
[Epoch 29; Iter   994/ 1097] train: loss: 0.2157454
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0728068
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0205916
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0108711
[Epoch 29] ogbg-molhiv: 0.660531 val loss: 1.930208
[Epoch 29] ogbg-molhiv: 0.665770 test loss: 0.868787
[Epoch 30; Iter    17/ 1097] train: loss: 0.0113395
[Epoch 30; Iter    47/ 1097] train: loss: 0.0782271
[Epoch 30; Iter    77/ 1097] train: loss: 0.0543298
[Epoch 30; Iter   107/ 1097] train: loss: 0.0081726
[Epoch 30; Iter   137/ 1097] train: loss: 0.0429421
[Epoch 30; Iter   167/ 1097] train: loss: 0.0137718
[Epoch 30; Iter   197/ 1097] train: loss: 0.0706752
[Epoch 30; Iter   227/ 1097] train: loss: 0.0133061
[Epoch 30; Iter   257/ 1097] train: loss: 0.1112704
[Epoch 30; Iter   287/ 1097] train: loss: 0.0237125
[Epoch 30; Iter   317/ 1097] train: loss: 0.0710564
[Epoch 30; Iter   347/ 1097] train: loss: 0.0071583
[Epoch 30; Iter   377/ 1097] train: loss: 0.0113173
[Epoch 30; Iter   407/ 1097] train: loss: 0.0126753
[Epoch 30; Iter   437/ 1097] train: loss: 0.0124133
[Epoch 30; Iter   467/ 1097] train: loss: 0.0121960
[Epoch 30; Iter   497/ 1097] train: loss: 0.0447999
[Epoch 30; Iter   527/ 1097] train: loss: 0.0367567
[Epoch 30; Iter   557/ 1097] train: loss: 0.0108259
[Epoch 30; Iter   587/ 1097] train: loss: 0.0086267
[Epoch 30; Iter   617/ 1097] train: loss: 0.1370610
[Epoch 30; Iter   647/ 1097] train: loss: 0.0320977
[Epoch 30; Iter   677/ 1097] train: loss: 0.0083870
[Epoch 30; Iter   707/ 1097] train: loss: 0.0079996
[Epoch 30; Iter   737/ 1097] train: loss: 0.0150694
[Epoch 30; Iter   767/ 1097] train: loss: 0.0081068
[Epoch 30; Iter   797/ 1097] train: loss: 0.0798773
[Epoch 30; Iter   827/ 1097] train: loss: 0.0249160
[Epoch 30; Iter   857/ 1097] train: loss: 0.0211151
[Epoch 30; Iter   887/ 1097] train: loss: 0.0133002
[Epoch 30; Iter   917/ 1097] train: loss: 0.0163974
[Epoch 30; Iter   947/ 1097] train: loss: 0.1006867
[Epoch 30; Iter   977/ 1097] train: loss: 0.0220288
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0080285
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0042422
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0251577
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0097195
[Epoch 30] ogbg-molhiv: 0.744580 val loss: 0.972654
[Epoch 30] ogbg-molhiv: 0.704104 test loss: 0.650709
[Epoch 31; Iter    30/ 1097] train: loss: 0.0032843
[Epoch 31; Iter    60/ 1097] train: loss: 0.0193551
[Epoch 31; Iter    90/ 1097] train: loss: 0.0151474
[Epoch 31; Iter   120/ 1097] train: loss: 0.0440045
[Epoch 31; Iter   150/ 1097] train: loss: 0.0295081
[Epoch 31; Iter   180/ 1097] train: loss: 0.0130058
[Epoch 31; Iter   210/ 1097] train: loss: 0.0638233
[Epoch 31; Iter   240/ 1097] train: loss: 0.0459871
[Epoch 31; Iter   270/ 1097] train: loss: 0.0047997
[Epoch 31; Iter   300/ 1097] train: loss: 0.0282115
[Epoch 31; Iter   330/ 1097] train: loss: 0.0103765
[Epoch 31; Iter   360/ 1097] train: loss: 0.0038182
[Epoch 31; Iter   390/ 1097] train: loss: 0.0088445
[Epoch 31; Iter   420/ 1097] train: loss: 0.0073798
[Epoch 31; Iter   450/ 1097] train: loss: 0.0176479
[Epoch 31; Iter   480/ 1097] train: loss: 0.0034124
[Epoch 31; Iter   510/ 1097] train: loss: 0.0246267
[Epoch 31; Iter   540/ 1097] train: loss: 0.0526838
[Epoch 31; Iter   570/ 1097] train: loss: 0.0189383
[Epoch 31; Iter   600/ 1097] train: loss: 0.0223343
[Epoch 31; Iter   630/ 1097] train: loss: 0.0401368
[Epoch 31; Iter   660/ 1097] train: loss: 0.0200187
[Epoch 31; Iter   690/ 1097] train: loss: 0.0052348
[Epoch 31; Iter   720/ 1097] train: loss: 0.0204134
[Epoch 31; Iter   750/ 1097] train: loss: 0.0054289
[Epoch 31; Iter   780/ 1097] train: loss: 0.0726720
[Epoch 31; Iter   810/ 1097] train: loss: 0.0729452
[Epoch 31; Iter   840/ 1097] train: loss: 0.0141469
[Epoch 31; Iter   870/ 1097] train: loss: 0.0652847
[Epoch 31; Iter   900/ 1097] train: loss: 0.0088704
[Epoch 31; Iter   930/ 1097] train: loss: 0.0182132
[Epoch 31; Iter   960/ 1097] train: loss: 0.0146970
[Epoch 31; Iter   990/ 1097] train: loss: 0.0063165
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0059646
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0054667
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0325862
[Epoch 31] ogbg-molhiv: 0.714188 val loss: 0.323861
[Epoch 31] ogbg-molhiv: 0.704849 test loss: 0.582104
[Epoch 32; Iter    13/ 1097] train: loss: 0.0254215
[Epoch 32; Iter    43/ 1097] train: loss: 0.1473569
[Epoch 32; Iter    73/ 1097] train: loss: 0.0208154
[Epoch 32; Iter   103/ 1097] train: loss: 0.0166814
[Epoch 32; Iter   133/ 1097] train: loss: 0.0113786
[Epoch 32; Iter   163/ 1097] train: loss: 0.0057665
[Epoch 32; Iter   193/ 1097] train: loss: 0.0887027
[Epoch 32; Iter   223/ 1097] train: loss: 0.0235733
[Epoch 32; Iter   253/ 1097] train: loss: 0.0085063
[Epoch 32; Iter   283/ 1097] train: loss: 0.0111473
[Epoch 32; Iter   313/ 1097] train: loss: 0.3565427
[Epoch 32; Iter   343/ 1097] train: loss: 0.0256210
[Epoch 32; Iter   373/ 1097] train: loss: 0.0506283
[Epoch 32; Iter   403/ 1097] train: loss: 0.0039230
[Epoch 32; Iter   433/ 1097] train: loss: 0.0091836
[Epoch 32; Iter   463/ 1097] train: loss: 0.0037746
[Epoch 32; Iter   493/ 1097] train: loss: 0.0224238
[Epoch 32; Iter   523/ 1097] train: loss: 0.0083996
[Epoch 28; Iter   441/ 1097] train: loss: 0.2009169
[Epoch 28; Iter   471/ 1097] train: loss: 0.1380542
[Epoch 28; Iter   501/ 1097] train: loss: 0.0235957
[Epoch 28; Iter   531/ 1097] train: loss: 0.0235640
[Epoch 28; Iter   561/ 1097] train: loss: 0.1238990
[Epoch 28; Iter   591/ 1097] train: loss: 0.0472946
[Epoch 28; Iter   621/ 1097] train: loss: 0.0375500
[Epoch 28; Iter   651/ 1097] train: loss: 0.0366741
[Epoch 28; Iter   681/ 1097] train: loss: 0.0360037
[Epoch 28; Iter   711/ 1097] train: loss: 0.0224810
[Epoch 28; Iter   741/ 1097] train: loss: 0.0181591
[Epoch 28; Iter   771/ 1097] train: loss: 0.1020733
[Epoch 28; Iter   801/ 1097] train: loss: 0.0269043
[Epoch 28; Iter   831/ 1097] train: loss: 0.2169600
[Epoch 28; Iter   861/ 1097] train: loss: 0.0398315
[Epoch 28; Iter   891/ 1097] train: loss: 0.0095230
[Epoch 28; Iter   921/ 1097] train: loss: 0.0225725
[Epoch 28; Iter   951/ 1097] train: loss: 0.0146918
[Epoch 28; Iter   981/ 1097] train: loss: 0.0410641
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0179213
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0270270
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0321997
[Epoch 28] ogbg-molhiv: 0.806015 val loss: 0.151430
[Epoch 28] ogbg-molhiv: 0.700927 test loss: 0.166059
[Epoch 29; Iter     4/ 1097] train: loss: 0.0651025
[Epoch 29; Iter    34/ 1097] train: loss: 0.0906126
[Epoch 29; Iter    64/ 1097] train: loss: 0.0289071
[Epoch 29; Iter    94/ 1097] train: loss: 0.0501558
[Epoch 29; Iter   124/ 1097] train: loss: 0.0442596
[Epoch 29; Iter   154/ 1097] train: loss: 0.0189250
[Epoch 29; Iter   184/ 1097] train: loss: 0.0180597
[Epoch 29; Iter   214/ 1097] train: loss: 0.1115966
[Epoch 29; Iter   244/ 1097] train: loss: 0.1426357
[Epoch 29; Iter   274/ 1097] train: loss: 0.0106233
[Epoch 29; Iter   304/ 1097] train: loss: 0.0190978
[Epoch 29; Iter   334/ 1097] train: loss: 0.2624929
[Epoch 29; Iter   364/ 1097] train: loss: 0.0182599
[Epoch 29; Iter   394/ 1097] train: loss: 0.0393308
[Epoch 29; Iter   424/ 1097] train: loss: 0.0223138
[Epoch 29; Iter   454/ 1097] train: loss: 0.1715289
[Epoch 29; Iter   484/ 1097] train: loss: 0.0095461
[Epoch 29; Iter   514/ 1097] train: loss: 0.0303377
[Epoch 29; Iter   544/ 1097] train: loss: 0.0337556
[Epoch 29; Iter   574/ 1097] train: loss: 0.0277936
[Epoch 29; Iter   604/ 1097] train: loss: 0.0227516
[Epoch 29; Iter   634/ 1097] train: loss: 0.0876824
[Epoch 29; Iter   664/ 1097] train: loss: 0.0572884
[Epoch 29; Iter   694/ 1097] train: loss: 0.1877917
[Epoch 29; Iter   724/ 1097] train: loss: 0.0329382
[Epoch 29; Iter   754/ 1097] train: loss: 0.0181701
[Epoch 29; Iter   784/ 1097] train: loss: 0.0935226
[Epoch 29; Iter   814/ 1097] train: loss: 0.0131491
[Epoch 29; Iter   844/ 1097] train: loss: 0.1252390
[Epoch 29; Iter   874/ 1097] train: loss: 0.0237873
[Epoch 29; Iter   904/ 1097] train: loss: 0.0513204
[Epoch 29; Iter   934/ 1097] train: loss: 0.0262126
[Epoch 29; Iter   964/ 1097] train: loss: 0.0140920
[Epoch 29; Iter   994/ 1097] train: loss: 0.2326765
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0264205
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0207460
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0150088
[Epoch 29] ogbg-molhiv: 0.784162 val loss: 0.166175
[Epoch 29] ogbg-molhiv: 0.684561 test loss: 0.221143
[Epoch 30; Iter    17/ 1097] train: loss: 0.0225246
[Epoch 30; Iter    47/ 1097] train: loss: 0.0182221
[Epoch 30; Iter    77/ 1097] train: loss: 0.0235872
[Epoch 30; Iter   107/ 1097] train: loss: 0.0351676
[Epoch 30; Iter   137/ 1097] train: loss: 0.0744905
[Epoch 30; Iter   167/ 1097] train: loss: 0.0144690
[Epoch 30; Iter   197/ 1097] train: loss: 0.1638377
[Epoch 30; Iter   227/ 1097] train: loss: 0.0083490
[Epoch 30; Iter   257/ 1097] train: loss: 0.0715255
[Epoch 30; Iter   287/ 1097] train: loss: 0.0180365
[Epoch 30; Iter   317/ 1097] train: loss: 0.1789147
[Epoch 30; Iter   347/ 1097] train: loss: 0.0172013
[Epoch 30; Iter   377/ 1097] train: loss: 0.0582542
[Epoch 30; Iter   407/ 1097] train: loss: 0.0164690
[Epoch 30; Iter   437/ 1097] train: loss: 0.0682598
[Epoch 30; Iter   467/ 1097] train: loss: 0.0185539
[Epoch 30; Iter   497/ 1097] train: loss: 0.0807529
[Epoch 30; Iter   527/ 1097] train: loss: 0.0076640
[Epoch 30; Iter   557/ 1097] train: loss: 0.0431790
[Epoch 30; Iter   587/ 1097] train: loss: 0.0185896
[Epoch 30; Iter   617/ 1097] train: loss: 0.0908710
[Epoch 30; Iter   647/ 1097] train: loss: 0.0803347
[Epoch 30; Iter   677/ 1097] train: loss: 0.0365744
[Epoch 30; Iter   707/ 1097] train: loss: 0.0671761
[Epoch 30; Iter   737/ 1097] train: loss: 0.0133745
[Epoch 30; Iter   767/ 1097] train: loss: 0.0107207
[Epoch 30; Iter   797/ 1097] train: loss: 0.0205186
[Epoch 30; Iter   827/ 1097] train: loss: 0.1459424
[Epoch 30; Iter   857/ 1097] train: loss: 0.0075650
[Epoch 30; Iter   887/ 1097] train: loss: 0.0212820
[Epoch 30; Iter   917/ 1097] train: loss: 0.0643951
[Epoch 30; Iter   947/ 1097] train: loss: 0.0201732
[Epoch 30; Iter   977/ 1097] train: loss: 0.0262439
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0053095
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0358439
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0114510
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0212546
[Epoch 30] ogbg-molhiv: 0.791621 val loss: 0.236263
[Epoch 30] ogbg-molhiv: 0.693702 test loss: 0.265932
[Epoch 31; Iter    30/ 1097] train: loss: 0.0186064
[Epoch 31; Iter    60/ 1097] train: loss: 0.0300457
[Epoch 31; Iter    90/ 1097] train: loss: 0.0294866
[Epoch 31; Iter   120/ 1097] train: loss: 0.0206239
[Epoch 31; Iter   150/ 1097] train: loss: 0.1489904
[Epoch 31; Iter   180/ 1097] train: loss: 0.0110684
[Epoch 31; Iter   210/ 1097] train: loss: 0.0167079
[Epoch 31; Iter   240/ 1097] train: loss: 0.0434488
[Epoch 31; Iter   270/ 1097] train: loss: 0.0132202
[Epoch 31; Iter   300/ 1097] train: loss: 0.0192914
[Epoch 31; Iter   330/ 1097] train: loss: 0.0505473
[Epoch 31; Iter   360/ 1097] train: loss: 0.0236552
[Epoch 31; Iter   390/ 1097] train: loss: 0.1571813
[Epoch 31; Iter   420/ 1097] train: loss: 0.1340050
[Epoch 31; Iter   450/ 1097] train: loss: 0.0363108
[Epoch 31; Iter   480/ 1097] train: loss: 0.0127123
[Epoch 31; Iter   510/ 1097] train: loss: 0.0063178
[Epoch 31; Iter   540/ 1097] train: loss: 0.0099884
[Epoch 31; Iter   570/ 1097] train: loss: 0.0240752
[Epoch 31; Iter   600/ 1097] train: loss: 0.0094281
[Epoch 31; Iter   630/ 1097] train: loss: 0.0247652
[Epoch 31; Iter   660/ 1097] train: loss: 0.1186045
[Epoch 31; Iter   690/ 1097] train: loss: 0.0278562
[Epoch 31; Iter   720/ 1097] train: loss: 0.0130270
[Epoch 31; Iter   750/ 1097] train: loss: 0.0103708
[Epoch 31; Iter   780/ 1097] train: loss: 0.0699513
[Epoch 31; Iter   810/ 1097] train: loss: 0.0147285
[Epoch 31; Iter   840/ 1097] train: loss: 0.0600625
[Epoch 31; Iter   870/ 1097] train: loss: 0.0178225
[Epoch 31; Iter   900/ 1097] train: loss: 0.0141188
[Epoch 31; Iter   930/ 1097] train: loss: 0.0101222
[Epoch 31; Iter   960/ 1097] train: loss: 0.0195336
[Epoch 31; Iter   990/ 1097] train: loss: 0.0233554
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0778771
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0116326
[Epoch 31; Iter  1080/ 1097] train: loss: 0.1813112
[Epoch 31] ogbg-molhiv: 0.797815 val loss: 0.290018
[Epoch 31] ogbg-molhiv: 0.680479 test loss: 0.323362
[Epoch 32; Iter    13/ 1097] train: loss: 0.0434563
[Epoch 32; Iter    43/ 1097] train: loss: 0.2003624
[Epoch 32; Iter    73/ 1097] train: loss: 0.1622868
[Epoch 32; Iter   103/ 1097] train: loss: 0.0097009
[Epoch 32; Iter   133/ 1097] train: loss: 0.0131338
[Epoch 32; Iter   163/ 1097] train: loss: 0.0078610
[Epoch 32; Iter   193/ 1097] train: loss: 0.0609070
[Epoch 32; Iter   223/ 1097] train: loss: 0.0216642
[Epoch 32; Iter   253/ 1097] train: loss: 0.0369752
[Epoch 32; Iter   283/ 1097] train: loss: 0.0233760
[Epoch 32; Iter   313/ 1097] train: loss: 0.1665438
[Epoch 32; Iter   343/ 1097] train: loss: 0.0240307
[Epoch 32; Iter   373/ 1097] train: loss: 0.0635805
[Epoch 32; Iter   403/ 1097] train: loss: 0.0271665
[Epoch 32; Iter   433/ 1097] train: loss: 0.0050847
[Epoch 32; Iter   463/ 1097] train: loss: 0.1919495
[Epoch 32; Iter   493/ 1097] train: loss: 0.0393125
[Epoch 24; Iter   389/ 1097] train: loss: 0.0490673
[Epoch 24; Iter   419/ 1097] train: loss: 0.0258358
[Epoch 24; Iter   449/ 1097] train: loss: 0.0326256
[Epoch 24; Iter   479/ 1097] train: loss: 0.2052758
[Epoch 24; Iter   509/ 1097] train: loss: 0.1376240
[Epoch 24; Iter   539/ 1097] train: loss: 0.0442625
[Epoch 24; Iter   569/ 1097] train: loss: 0.0980712
[Epoch 24; Iter   599/ 1097] train: loss: 0.0827179
[Epoch 24; Iter   629/ 1097] train: loss: 0.0320439
[Epoch 24; Iter   659/ 1097] train: loss: 0.1300054
[Epoch 24; Iter   689/ 1097] train: loss: 0.0953363
[Epoch 24; Iter   719/ 1097] train: loss: 0.0474376
[Epoch 24; Iter   749/ 1097] train: loss: 0.0372154
[Epoch 24; Iter   779/ 1097] train: loss: 0.3329631
[Epoch 24; Iter   809/ 1097] train: loss: 0.2279726
[Epoch 24; Iter   839/ 1097] train: loss: 0.0768706
[Epoch 24; Iter   869/ 1097] train: loss: 0.0491074
[Epoch 24; Iter   899/ 1097] train: loss: 0.0205419
[Epoch 24; Iter   929/ 1097] train: loss: 0.0381540
[Epoch 24; Iter   959/ 1097] train: loss: 0.0229189
[Epoch 24; Iter   989/ 1097] train: loss: 0.0492625
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3497434
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0258527
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0969596
[Epoch 24] ogbg-molhiv: 0.780322 val loss: 0.204882
[Epoch 24] ogbg-molhiv: 0.772137 test loss: 0.130316
[Epoch 25; Iter    12/ 1097] train: loss: 0.0644233
[Epoch 25; Iter    42/ 1097] train: loss: 0.2332772
[Epoch 25; Iter    72/ 1097] train: loss: 0.2818764
[Epoch 25; Iter   102/ 1097] train: loss: 0.0826283
[Epoch 25; Iter   132/ 1097] train: loss: 0.0554583
[Epoch 25; Iter   162/ 1097] train: loss: 0.0235212
[Epoch 25; Iter   192/ 1097] train: loss: 0.0762038
[Epoch 25; Iter   222/ 1097] train: loss: 0.1559597
[Epoch 25; Iter   252/ 1097] train: loss: 0.0195976
[Epoch 25; Iter   282/ 1097] train: loss: 0.0409418
[Epoch 25; Iter   312/ 1097] train: loss: 0.0258073
[Epoch 25; Iter   342/ 1097] train: loss: 0.0483839
[Epoch 25; Iter   372/ 1097] train: loss: 0.0211140
[Epoch 25; Iter   402/ 1097] train: loss: 0.0349154
[Epoch 25; Iter   432/ 1097] train: loss: 0.1144565
[Epoch 25; Iter   462/ 1097] train: loss: 0.1852913
[Epoch 25; Iter   492/ 1097] train: loss: 0.0935045
[Epoch 25; Iter   522/ 1097] train: loss: 0.0213385
[Epoch 25; Iter   552/ 1097] train: loss: 0.3188896
[Epoch 25; Iter   582/ 1097] train: loss: 0.3423743
[Epoch 25; Iter   612/ 1097] train: loss: 0.0268873
[Epoch 25; Iter   642/ 1097] train: loss: 0.3171827
[Epoch 25; Iter   672/ 1097] train: loss: 0.0867973
[Epoch 25; Iter   702/ 1097] train: loss: 0.0274190
[Epoch 25; Iter   732/ 1097] train: loss: 0.2205072
[Epoch 25; Iter   762/ 1097] train: loss: 0.0498342
[Epoch 25; Iter   792/ 1097] train: loss: 0.2619268
[Epoch 25; Iter   822/ 1097] train: loss: 0.0236784
[Epoch 25; Iter   852/ 1097] train: loss: 0.0266844
[Epoch 25; Iter   882/ 1097] train: loss: 0.0339085
[Epoch 25; Iter   912/ 1097] train: loss: 0.0378128
[Epoch 25; Iter   942/ 1097] train: loss: 0.2359845
[Epoch 25; Iter   972/ 1097] train: loss: 0.1382167
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1190835
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0491707
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1890774
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0183475
[Epoch 25] ogbg-molhiv: 0.791691 val loss: 0.308142
[Epoch 25] ogbg-molhiv: 0.781336 test loss: 0.173298
[Epoch 26; Iter    25/ 1097] train: loss: 0.1671139
[Epoch 26; Iter    55/ 1097] train: loss: 0.0386736
[Epoch 26; Iter    85/ 1097] train: loss: 0.3348795
[Epoch 26; Iter   115/ 1097] train: loss: 0.0420994
[Epoch 26; Iter   145/ 1097] train: loss: 0.0235381
[Epoch 26; Iter   175/ 1097] train: loss: 0.0394213
[Epoch 26; Iter   205/ 1097] train: loss: 0.0161253
[Epoch 26; Iter   235/ 1097] train: loss: 0.0363745
[Epoch 26; Iter   265/ 1097] train: loss: 0.0604204
[Epoch 26; Iter   295/ 1097] train: loss: 0.1132010
[Epoch 26; Iter   325/ 1097] train: loss: 0.0358995
[Epoch 26; Iter   355/ 1097] train: loss: 0.0955745
[Epoch 26; Iter   385/ 1097] train: loss: 0.1998967
[Epoch 26; Iter   415/ 1097] train: loss: 0.0824672
[Epoch 26; Iter   445/ 1097] train: loss: 0.0739496
[Epoch 26; Iter   475/ 1097] train: loss: 0.0416018
[Epoch 26; Iter   505/ 1097] train: loss: 0.1511109
[Epoch 26; Iter   535/ 1097] train: loss: 0.0207321
[Epoch 26; Iter   565/ 1097] train: loss: 0.1279391
[Epoch 26; Iter   595/ 1097] train: loss: 0.0201958
[Epoch 26; Iter   625/ 1097] train: loss: 0.0878641
[Epoch 26; Iter   655/ 1097] train: loss: 0.1026461
[Epoch 26; Iter   685/ 1097] train: loss: 0.1229280
[Epoch 26; Iter   715/ 1097] train: loss: 0.0440174
[Epoch 26; Iter   745/ 1097] train: loss: 0.0619435
[Epoch 26; Iter   775/ 1097] train: loss: 0.3349276
[Epoch 26; Iter   805/ 1097] train: loss: 0.0388342
[Epoch 26; Iter   835/ 1097] train: loss: 0.0229015
[Epoch 26; Iter   865/ 1097] train: loss: 0.1904689
[Epoch 26; Iter   895/ 1097] train: loss: 0.0216216
[Epoch 26; Iter   925/ 1097] train: loss: 0.0912979
[Epoch 26; Iter   955/ 1097] train: loss: 0.0657437
[Epoch 26; Iter   985/ 1097] train: loss: 0.0579988
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2736733
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0313071
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2615121
[Epoch 26] ogbg-molhiv: 0.781697 val loss: 0.161561
[Epoch 26] ogbg-molhiv: 0.760909 test loss: 0.220358
[Epoch 27; Iter     8/ 1097] train: loss: 0.0331099
[Epoch 27; Iter    38/ 1097] train: loss: 0.1855457
[Epoch 27; Iter    68/ 1097] train: loss: 0.0374178
[Epoch 27; Iter    98/ 1097] train: loss: 0.0803175
[Epoch 27; Iter   128/ 1097] train: loss: 0.0335311
[Epoch 27; Iter   158/ 1097] train: loss: 0.1403312
[Epoch 27; Iter   188/ 1097] train: loss: 0.0656388
[Epoch 27; Iter   218/ 1097] train: loss: 0.1047871
[Epoch 27; Iter   248/ 1097] train: loss: 0.1084366
[Epoch 27; Iter   278/ 1097] train: loss: 0.0942112
[Epoch 27; Iter   308/ 1097] train: loss: 0.1349090
[Epoch 27; Iter   338/ 1097] train: loss: 0.0287177
[Epoch 27; Iter   368/ 1097] train: loss: 0.1168626
[Epoch 27; Iter   398/ 1097] train: loss: 0.2538771
[Epoch 27; Iter   428/ 1097] train: loss: 0.0280686
[Epoch 27; Iter   458/ 1097] train: loss: 0.0537655
[Epoch 27; Iter   488/ 1097] train: loss: 0.1121415
[Epoch 27; Iter   518/ 1097] train: loss: 0.3158606
[Epoch 27; Iter   548/ 1097] train: loss: 0.1682632
[Epoch 27; Iter   578/ 1097] train: loss: 0.1917085
[Epoch 27; Iter   608/ 1097] train: loss: 0.0221002
[Epoch 27; Iter   638/ 1097] train: loss: 0.0242201
[Epoch 27; Iter   668/ 1097] train: loss: 0.0249136
[Epoch 27; Iter   698/ 1097] train: loss: 0.1434197
[Epoch 27; Iter   728/ 1097] train: loss: 0.2065467
[Epoch 27; Iter   758/ 1097] train: loss: 0.0562419
[Epoch 27; Iter   788/ 1097] train: loss: 0.1623591
[Epoch 27; Iter   818/ 1097] train: loss: 0.0305806
[Epoch 27; Iter   848/ 1097] train: loss: 0.0182322
[Epoch 27; Iter   878/ 1097] train: loss: 0.0242229
[Epoch 27; Iter   908/ 1097] train: loss: 0.1589317
[Epoch 27; Iter   938/ 1097] train: loss: 0.1033080
[Epoch 27; Iter   968/ 1097] train: loss: 0.1980717
[Epoch 27; Iter   998/ 1097] train: loss: 0.1119970
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1757975
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0329423
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0312167
[Epoch 27] ogbg-molhiv: 0.786501 val loss: 0.127681
[Epoch 27] ogbg-molhiv: 0.761643 test loss: 0.236890
[Epoch 28; Iter    21/ 1097] train: loss: 0.1842244
[Epoch 28; Iter    51/ 1097] train: loss: 0.0662552
[Epoch 28; Iter    81/ 1097] train: loss: 0.0309957
[Epoch 28; Iter   111/ 1097] train: loss: 0.0216279
[Epoch 28; Iter   141/ 1097] train: loss: 0.0337316
[Epoch 28; Iter   171/ 1097] train: loss: 0.1791841
[Epoch 28; Iter   201/ 1097] train: loss: 0.0313036
[Epoch 28; Iter   231/ 1097] train: loss: 0.0230538
[Epoch 28; Iter   261/ 1097] train: loss: 0.0488279
[Epoch 28; Iter   291/ 1097] train: loss: 0.2136821
[Epoch 28; Iter   321/ 1097] train: loss: 0.1043837
[Epoch 28; Iter   351/ 1097] train: loss: 0.1171145
[Epoch 28; Iter   381/ 1097] train: loss: 0.0227834
[Epoch 28; Iter   411/ 1097] train: loss: 0.0823218
[Epoch 28; Iter   441/ 1097] train: loss: 0.0205422
[Epoch 28; Iter   471/ 1097] train: loss: 0.0184411
[Epoch 28; Iter   501/ 1097] train: loss: 0.0150936
[Epoch 28; Iter   531/ 1097] train: loss: 0.1390776
[Epoch 28; Iter   561/ 1097] train: loss: 0.0407147
[Epoch 28; Iter   591/ 1097] train: loss: 0.0585468
[Epoch 28; Iter   621/ 1097] train: loss: 0.1001084
[Epoch 28; Iter   651/ 1097] train: loss: 0.0802291
[Epoch 28; Iter   681/ 1097] train: loss: 0.0394428
[Epoch 28; Iter   711/ 1097] train: loss: 0.0338881
[Epoch 28; Iter   741/ 1097] train: loss: 0.2456476
[Epoch 28; Iter   771/ 1097] train: loss: 0.0389887
[Epoch 28; Iter   801/ 1097] train: loss: 0.2679240
[Epoch 28; Iter   831/ 1097] train: loss: 0.0173138
[Epoch 28; Iter   861/ 1097] train: loss: 0.0252441
[Epoch 28; Iter   891/ 1097] train: loss: 0.0688157
[Epoch 28; Iter   921/ 1097] train: loss: 0.0300338
[Epoch 28; Iter   951/ 1097] train: loss: 0.0264557
[Epoch 28; Iter   981/ 1097] train: loss: 0.0435200
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0119732
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0217829
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1359590
[Epoch 28] ogbg-molhiv: 0.760236 val loss: 0.101053
[Epoch 28] ogbg-molhiv: 0.715788 test loss: 0.154331
[Epoch 29; Iter     4/ 1097] train: loss: 0.0551297
[Epoch 29; Iter    34/ 1097] train: loss: 0.0188835
[Epoch 29; Iter    64/ 1097] train: loss: 0.1565676
[Epoch 29; Iter    94/ 1097] train: loss: 0.0135459
[Epoch 29; Iter   124/ 1097] train: loss: 0.0072639
[Epoch 29; Iter   154/ 1097] train: loss: 0.0472724
[Epoch 29; Iter   184/ 1097] train: loss: 0.0615227
[Epoch 29; Iter   214/ 1097] train: loss: 0.1619890
[Epoch 29; Iter   244/ 1097] train: loss: 0.0161189
[Epoch 29; Iter   274/ 1097] train: loss: 0.0221489
[Epoch 29; Iter   304/ 1097] train: loss: 0.0106360
[Epoch 29; Iter   334/ 1097] train: loss: 0.0181247
[Epoch 29; Iter   364/ 1097] train: loss: 0.0990035
[Epoch 29; Iter   394/ 1097] train: loss: 0.0297469
[Epoch 29; Iter   424/ 1097] train: loss: 0.0658824
[Epoch 29; Iter   454/ 1097] train: loss: 0.0146688
[Epoch 29; Iter   484/ 1097] train: loss: 0.0274266
[Epoch 29; Iter   514/ 1097] train: loss: 0.1749463
[Epoch 29; Iter   544/ 1097] train: loss: 0.0036386
[Epoch 29; Iter   574/ 1097] train: loss: 0.0337980
[Epoch 29; Iter   604/ 1097] train: loss: 0.0165401
[Epoch 29; Iter   634/ 1097] train: loss: 0.0123780
[Epoch 29; Iter   664/ 1097] train: loss: 0.0120765
[Epoch 29; Iter   694/ 1097] train: loss: 0.0240870
[Epoch 29; Iter   724/ 1097] train: loss: 0.0269732
[Epoch 29; Iter   754/ 1097] train: loss: 0.0121876
[Epoch 29; Iter   784/ 1097] train: loss: 0.0205020
[Epoch 29; Iter   814/ 1097] train: loss: 0.0486324
[Epoch 29; Iter   844/ 1097] train: loss: 0.0309177
[Epoch 29; Iter   874/ 1097] train: loss: 0.0130578
[Epoch 29; Iter   904/ 1097] train: loss: 0.0436124
[Epoch 29; Iter   934/ 1097] train: loss: 0.0144484
[Epoch 29; Iter   964/ 1097] train: loss: 0.0463727
[Epoch 29; Iter   994/ 1097] train: loss: 0.0226881
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0242896
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0085697
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1352680
[Epoch 29] ogbg-molhiv: 0.773816 val loss: 0.112967
[Epoch 29] ogbg-molhiv: 0.709726 test loss: 0.170275
[Epoch 30; Iter    17/ 1097] train: loss: 0.0206386
[Epoch 30; Iter    47/ 1097] train: loss: 0.0031721
[Epoch 30; Iter    77/ 1097] train: loss: 0.0137965
[Epoch 30; Iter   107/ 1097] train: loss: 0.0088758
[Epoch 30; Iter   137/ 1097] train: loss: 0.0116269
[Epoch 30; Iter   167/ 1097] train: loss: 0.0525791
[Epoch 30; Iter   197/ 1097] train: loss: 0.0501139
[Epoch 30; Iter   227/ 1097] train: loss: 0.0321504
[Epoch 30; Iter   257/ 1097] train: loss: 0.1201637
[Epoch 30; Iter   287/ 1097] train: loss: 0.0363988
[Epoch 30; Iter   317/ 1097] train: loss: 0.0950960
[Epoch 30; Iter   347/ 1097] train: loss: 0.0075454
[Epoch 30; Iter   377/ 1097] train: loss: 0.1113551
[Epoch 30; Iter   407/ 1097] train: loss: 0.0115487
[Epoch 30; Iter   437/ 1097] train: loss: 0.0120955
[Epoch 30; Iter   467/ 1097] train: loss: 0.0552503
[Epoch 30; Iter   497/ 1097] train: loss: 0.2675856
[Epoch 30; Iter   527/ 1097] train: loss: 0.1255272
[Epoch 30; Iter   557/ 1097] train: loss: 0.0723773
[Epoch 30; Iter   587/ 1097] train: loss: 0.0813681
[Epoch 30; Iter   617/ 1097] train: loss: 0.0049175
[Epoch 30; Iter   647/ 1097] train: loss: 0.0276575
[Epoch 30; Iter   677/ 1097] train: loss: 0.0135229
[Epoch 30; Iter   707/ 1097] train: loss: 0.0336780
[Epoch 30; Iter   737/ 1097] train: loss: 0.0040609
[Epoch 30; Iter   767/ 1097] train: loss: 0.0362637
[Epoch 30; Iter   797/ 1097] train: loss: 0.0362910
[Epoch 30; Iter   827/ 1097] train: loss: 0.0461254
[Epoch 30; Iter   857/ 1097] train: loss: 0.1151892
[Epoch 30; Iter   887/ 1097] train: loss: 0.0233247
[Epoch 30; Iter   917/ 1097] train: loss: 0.0546055
[Epoch 30; Iter   947/ 1097] train: loss: 0.0144535
[Epoch 30; Iter   977/ 1097] train: loss: 0.0144885
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0210120
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0131756
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0134711
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0365775
[Epoch 30] ogbg-molhiv: 0.750435 val loss: 0.123673
[Epoch 30] ogbg-molhiv: 0.709678 test loss: 0.182492
[Epoch 31; Iter    30/ 1097] train: loss: 0.0143368
[Epoch 31; Iter    60/ 1097] train: loss: 0.1052914
[Epoch 31; Iter    90/ 1097] train: loss: 0.0127615
[Epoch 31; Iter   120/ 1097] train: loss: 0.0108925
[Epoch 31; Iter   150/ 1097] train: loss: 0.0379569
[Epoch 31; Iter   180/ 1097] train: loss: 0.0370220
[Epoch 31; Iter   210/ 1097] train: loss: 0.0560248
[Epoch 31; Iter   240/ 1097] train: loss: 0.0148395
[Epoch 31; Iter   270/ 1097] train: loss: 0.0057993
[Epoch 31; Iter   300/ 1097] train: loss: 0.0198318
[Epoch 31; Iter   330/ 1097] train: loss: 0.0060360
[Epoch 31; Iter   360/ 1097] train: loss: 0.0194712
[Epoch 31; Iter   390/ 1097] train: loss: 0.0366820
[Epoch 31; Iter   420/ 1097] train: loss: 0.0676119
[Epoch 31; Iter   450/ 1097] train: loss: 0.0159511
[Epoch 31; Iter   480/ 1097] train: loss: 0.0071030
[Epoch 31; Iter   510/ 1097] train: loss: 0.0094614
[Epoch 31; Iter   540/ 1097] train: loss: 0.0210033
[Epoch 31; Iter   570/ 1097] train: loss: 0.0087236
[Epoch 31; Iter   600/ 1097] train: loss: 0.0076578
[Epoch 31; Iter   630/ 1097] train: loss: 0.0203311
[Epoch 31; Iter   660/ 1097] train: loss: 0.0028312
[Epoch 31; Iter   690/ 1097] train: loss: 0.0118837
[Epoch 31; Iter   720/ 1097] train: loss: 0.0067448
[Epoch 31; Iter   750/ 1097] train: loss: 0.0684094
[Epoch 31; Iter   780/ 1097] train: loss: 0.0106054
[Epoch 31; Iter   810/ 1097] train: loss: 0.0068367
[Epoch 31; Iter   840/ 1097] train: loss: 0.0619283
[Epoch 31; Iter   870/ 1097] train: loss: 0.0377387
[Epoch 31; Iter   900/ 1097] train: loss: 0.0576112
[Epoch 31; Iter   930/ 1097] train: loss: 0.0061279
[Epoch 31; Iter   960/ 1097] train: loss: 0.0270267
[Epoch 31; Iter   990/ 1097] train: loss: 0.0065473
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0143422
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0462439
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0090930
[Epoch 31] ogbg-molhiv: 0.771014 val loss: 0.131598
[Epoch 31] ogbg-molhiv: 0.714015 test loss: 0.182054
[Epoch 32; Iter    13/ 1097] train: loss: 0.2960798
[Epoch 32; Iter    43/ 1097] train: loss: 0.0270973
[Epoch 32; Iter    73/ 1097] train: loss: 0.0069059
[Epoch 32; Iter   103/ 1097] train: loss: 0.0140257
[Epoch 32; Iter   133/ 1097] train: loss: 0.0224354
[Epoch 32; Iter   163/ 1097] train: loss: 0.0208313
[Epoch 32; Iter   193/ 1097] train: loss: 0.0296208
[Epoch 32; Iter   223/ 1097] train: loss: 0.0195017
[Epoch 32; Iter   253/ 1097] train: loss: 0.0058769
[Epoch 32; Iter   283/ 1097] train: loss: 0.0128272
[Epoch 32; Iter   313/ 1097] train: loss: 0.0066324
[Epoch 32; Iter   343/ 1097] train: loss: 0.0141094
[Epoch 32; Iter   373/ 1097] train: loss: 0.0308589
[Epoch 32; Iter   403/ 1097] train: loss: 0.0975523
[Epoch 32; Iter   433/ 1097] train: loss: 0.0049247
[Epoch 32; Iter   463/ 1097] train: loss: 0.0240078
[Epoch 32; Iter   493/ 1097] train: loss: 0.0287033
[Epoch 32; Iter   523/ 1097] train: loss: 0.0263687
[Epoch 28; Iter   471/ 1097] train: loss: 0.0117436
[Epoch 28; Iter   501/ 1097] train: loss: 0.1156541
[Epoch 28; Iter   531/ 1097] train: loss: 0.0091024
[Epoch 28; Iter   561/ 1097] train: loss: 0.0873635
[Epoch 28; Iter   591/ 1097] train: loss: 0.1338996
[Epoch 28; Iter   621/ 1097] train: loss: 0.0649022
[Epoch 28; Iter   651/ 1097] train: loss: 0.0101273
[Epoch 28; Iter   681/ 1097] train: loss: 0.0171996
[Epoch 28; Iter   711/ 1097] train: loss: 0.0178565
[Epoch 28; Iter   741/ 1097] train: loss: 0.0115910
[Epoch 28; Iter   771/ 1097] train: loss: 0.2312048
[Epoch 28; Iter   801/ 1097] train: loss: 0.0144298
[Epoch 28; Iter   831/ 1097] train: loss: 0.0097012
[Epoch 28; Iter   861/ 1097] train: loss: 0.1132491
[Epoch 28; Iter   891/ 1097] train: loss: 0.0270880
[Epoch 28; Iter   921/ 1097] train: loss: 0.0280624
[Epoch 28; Iter   951/ 1097] train: loss: 0.0132921
[Epoch 28; Iter   981/ 1097] train: loss: 0.0873229
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0311223
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0162520
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0125308
[Epoch 28] ogbg-molhiv: 0.723968 val loss: 0.092175
[Epoch 28] ogbg-molhiv: 0.715334 test loss: 0.226159
[Epoch 29; Iter     4/ 1097] train: loss: 0.0114491
[Epoch 29; Iter    34/ 1097] train: loss: 0.0075839
[Epoch 29; Iter    64/ 1097] train: loss: 0.0622941
[Epoch 29; Iter    94/ 1097] train: loss: 0.0182162
[Epoch 29; Iter   124/ 1097] train: loss: 0.0307233
[Epoch 29; Iter   154/ 1097] train: loss: 0.0780628
[Epoch 29; Iter   184/ 1097] train: loss: 0.0429550
[Epoch 29; Iter   214/ 1097] train: loss: 0.0343084
[Epoch 29; Iter   244/ 1097] train: loss: 0.0748377
[Epoch 29; Iter   274/ 1097] train: loss: 0.0291355
[Epoch 29; Iter   304/ 1097] train: loss: 0.1236714
[Epoch 29; Iter   334/ 1097] train: loss: 0.0517630
[Epoch 29; Iter   364/ 1097] train: loss: 0.0313240
[Epoch 29; Iter   394/ 1097] train: loss: 0.0334895
[Epoch 29; Iter   424/ 1097] train: loss: 0.0434131
[Epoch 29; Iter   454/ 1097] train: loss: 0.0493860
[Epoch 29; Iter   484/ 1097] train: loss: 0.0335044
[Epoch 29; Iter   514/ 1097] train: loss: 0.0184186
[Epoch 29; Iter   544/ 1097] train: loss: 0.0207850
[Epoch 29; Iter   574/ 1097] train: loss: 0.0868843
[Epoch 29; Iter   604/ 1097] train: loss: 0.1410607
[Epoch 29; Iter   634/ 1097] train: loss: 0.1316173
[Epoch 29; Iter   664/ 1097] train: loss: 0.0054186
[Epoch 29; Iter   694/ 1097] train: loss: 0.0279544
[Epoch 29; Iter   724/ 1097] train: loss: 0.0180459
[Epoch 29; Iter   754/ 1097] train: loss: 0.0174131
[Epoch 29; Iter   784/ 1097] train: loss: 0.0108421
[Epoch 29; Iter   814/ 1097] train: loss: 0.0097921
[Epoch 29; Iter   844/ 1097] train: loss: 0.0461873
[Epoch 29; Iter   874/ 1097] train: loss: 0.2659709
[Epoch 29; Iter   904/ 1097] train: loss: 0.0239875
[Epoch 29; Iter   934/ 1097] train: loss: 0.3801042
[Epoch 29; Iter   964/ 1097] train: loss: 0.0193961
[Epoch 29; Iter   994/ 1097] train: loss: 0.0339390
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0659653
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0369798
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0150735
[Epoch 29] ogbg-molhiv: 0.705305 val loss: 0.103081
[Epoch 29] ogbg-molhiv: 0.700896 test loss: 0.161556
[Epoch 30; Iter    17/ 1097] train: loss: 0.0144128
[Epoch 30; Iter    47/ 1097] train: loss: 0.1705168
[Epoch 30; Iter    77/ 1097] train: loss: 0.0141280
[Epoch 30; Iter   107/ 1097] train: loss: 0.0097459
[Epoch 30; Iter   137/ 1097] train: loss: 0.0550087
[Epoch 30; Iter   167/ 1097] train: loss: 0.0156263
[Epoch 30; Iter   197/ 1097] train: loss: 0.0386842
[Epoch 30; Iter   227/ 1097] train: loss: 0.0125628
[Epoch 30; Iter   257/ 1097] train: loss: 0.0453314
[Epoch 30; Iter   287/ 1097] train: loss: 0.0101434
[Epoch 30; Iter   317/ 1097] train: loss: 0.1820744
[Epoch 30; Iter   347/ 1097] train: loss: 0.0235562
[Epoch 30; Iter   377/ 1097] train: loss: 0.1246920
[Epoch 30; Iter   407/ 1097] train: loss: 0.0172811
[Epoch 30; Iter   437/ 1097] train: loss: 0.0357495
[Epoch 30; Iter   467/ 1097] train: loss: 0.0334013
[Epoch 30; Iter   497/ 1097] train: loss: 0.1212270
[Epoch 30; Iter   527/ 1097] train: loss: 0.1376889
[Epoch 30; Iter   557/ 1097] train: loss: 0.1723294
[Epoch 30; Iter   587/ 1097] train: loss: 0.0481663
[Epoch 30; Iter   617/ 1097] train: loss: 0.0078962
[Epoch 30; Iter   647/ 1097] train: loss: 0.0276585
[Epoch 30; Iter   677/ 1097] train: loss: 0.1230449
[Epoch 30; Iter   707/ 1097] train: loss: 0.1154907
[Epoch 30; Iter   737/ 1097] train: loss: 0.0085396
[Epoch 30; Iter   767/ 1097] train: loss: 0.1526243
[Epoch 30; Iter   797/ 1097] train: loss: 0.2013115
[Epoch 30; Iter   827/ 1097] train: loss: 0.2335835
[Epoch 30; Iter   857/ 1097] train: loss: 0.1131755
[Epoch 30; Iter   887/ 1097] train: loss: 0.0855792
[Epoch 30; Iter   917/ 1097] train: loss: 0.1028801
[Epoch 30; Iter   947/ 1097] train: loss: 0.0299111
[Epoch 30; Iter   977/ 1097] train: loss: 0.0267060
[Epoch 30; Iter  1007/ 1097] train: loss: 0.1038972
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1104536
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0126253
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0138286
[Epoch 30] ogbg-molhiv: 0.711456 val loss: 0.107945
[Epoch 30] ogbg-molhiv: 0.713842 test loss: 0.165066
[Epoch 31; Iter    30/ 1097] train: loss: 0.0612377
[Epoch 31; Iter    60/ 1097] train: loss: 0.1758513
[Epoch 31; Iter    90/ 1097] train: loss: 0.0434537
[Epoch 31; Iter   120/ 1097] train: loss: 0.0183820
[Epoch 31; Iter   150/ 1097] train: loss: 0.2980798
[Epoch 31; Iter   180/ 1097] train: loss: 0.0250160
[Epoch 31; Iter   210/ 1097] train: loss: 0.0084526
[Epoch 31; Iter   240/ 1097] train: loss: 0.0202368
[Epoch 31; Iter   270/ 1097] train: loss: 0.0577667
[Epoch 31; Iter   300/ 1097] train: loss: 0.0103890
[Epoch 31; Iter   330/ 1097] train: loss: 0.0123358
[Epoch 31; Iter   360/ 1097] train: loss: 0.1305972
[Epoch 31; Iter   390/ 1097] train: loss: 0.0333210
[Epoch 31; Iter   420/ 1097] train: loss: 0.0471373
[Epoch 31; Iter   450/ 1097] train: loss: 0.1026892
[Epoch 31; Iter   480/ 1097] train: loss: 0.1963614
[Epoch 31; Iter   510/ 1097] train: loss: 0.0460234
[Epoch 31; Iter   540/ 1097] train: loss: 0.0338742
[Epoch 31; Iter   570/ 1097] train: loss: 0.0839596
[Epoch 31; Iter   600/ 1097] train: loss: 0.0061946
[Epoch 31; Iter   630/ 1097] train: loss: 0.0256866
[Epoch 31; Iter   660/ 1097] train: loss: 0.0361764
[Epoch 31; Iter   690/ 1097] train: loss: 0.0113042
[Epoch 31; Iter   720/ 1097] train: loss: 0.0118643
[Epoch 31; Iter   750/ 1097] train: loss: 0.0071135
[Epoch 31; Iter   780/ 1097] train: loss: 0.0435433
[Epoch 31; Iter   810/ 1097] train: loss: 0.0075073
[Epoch 31; Iter   840/ 1097] train: loss: 0.1363163
[Epoch 31; Iter   870/ 1097] train: loss: 0.1625897
[Epoch 31; Iter   900/ 1097] train: loss: 0.0346798
[Epoch 31; Iter   930/ 1097] train: loss: 0.0443849
[Epoch 31; Iter   960/ 1097] train: loss: 0.0774694
[Epoch 31; Iter   990/ 1097] train: loss: 0.0899906
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1194183
[Epoch 31; Iter  1050/ 1097] train: loss: 0.2503449
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0460369
[Epoch 31] ogbg-molhiv: 0.725851 val loss: 0.111857
[Epoch 31] ogbg-molhiv: 0.726381 test loss: 0.192760
[Epoch 32; Iter    13/ 1097] train: loss: 0.0118841
[Epoch 32; Iter    43/ 1097] train: loss: 0.1424531
[Epoch 32; Iter    73/ 1097] train: loss: 0.0168808
[Epoch 32; Iter   103/ 1097] train: loss: 0.1097868
[Epoch 32; Iter   133/ 1097] train: loss: 0.0216519
[Epoch 32; Iter   163/ 1097] train: loss: 0.1865613
[Epoch 32; Iter   193/ 1097] train: loss: 0.0584456
[Epoch 32; Iter   223/ 1097] train: loss: 0.0294800
[Epoch 32; Iter   253/ 1097] train: loss: 0.0112303
[Epoch 32; Iter   283/ 1097] train: loss: 0.0297587
[Epoch 32; Iter   313/ 1097] train: loss: 0.0106234
[Epoch 32; Iter   343/ 1097] train: loss: 0.0395635
[Epoch 32; Iter   373/ 1097] train: loss: 0.1065533
[Epoch 32; Iter   403/ 1097] train: loss: 0.0289205
[Epoch 32; Iter   433/ 1097] train: loss: 0.0592526
[Epoch 32; Iter   463/ 1097] train: loss: 0.0329492
[Epoch 32; Iter   493/ 1097] train: loss: 0.1469885
[Epoch 32; Iter   523/ 1097] train: loss: 0.1900280
[Epoch 24; Iter   389/ 1097] train: loss: 0.0636760
[Epoch 24; Iter   419/ 1097] train: loss: 0.3666018
[Epoch 24; Iter   449/ 1097] train: loss: 0.0569198
[Epoch 24; Iter   479/ 1097] train: loss: 0.1908200
[Epoch 24; Iter   509/ 1097] train: loss: 0.2296652
[Epoch 24; Iter   539/ 1097] train: loss: 0.0349755
[Epoch 24; Iter   569/ 1097] train: loss: 0.2112421
[Epoch 24; Iter   599/ 1097] train: loss: 0.1614069
[Epoch 24; Iter   629/ 1097] train: loss: 0.0505209
[Epoch 24; Iter   659/ 1097] train: loss: 0.0350355
[Epoch 24; Iter   689/ 1097] train: loss: 0.0128634
[Epoch 24; Iter   719/ 1097] train: loss: 0.1347784
[Epoch 24; Iter   749/ 1097] train: loss: 0.0444830
[Epoch 24; Iter   779/ 1097] train: loss: 0.1461649
[Epoch 24; Iter   809/ 1097] train: loss: 0.1606621
[Epoch 24; Iter   839/ 1097] train: loss: 0.0852317
[Epoch 24; Iter   869/ 1097] train: loss: 0.0501556
[Epoch 24; Iter   899/ 1097] train: loss: 0.2154637
[Epoch 24; Iter   929/ 1097] train: loss: 0.0919147
[Epoch 24; Iter   959/ 1097] train: loss: 0.2043215
[Epoch 24; Iter   989/ 1097] train: loss: 0.0461429
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1761258
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1363100
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2926192
[Epoch 24] ogbg-molhiv: 0.815146 val loss: 0.557257
[Epoch 24] ogbg-molhiv: 0.759854 test loss: 0.404942
[Epoch 25; Iter    12/ 1097] train: loss: 0.2217086
[Epoch 25; Iter    42/ 1097] train: loss: 0.0421085
[Epoch 25; Iter    72/ 1097] train: loss: 0.0269858
[Epoch 25; Iter   102/ 1097] train: loss: 0.2568963
[Epoch 25; Iter   132/ 1097] train: loss: 0.2528175
[Epoch 25; Iter   162/ 1097] train: loss: 0.0213213
[Epoch 25; Iter   192/ 1097] train: loss: 0.0339410
[Epoch 25; Iter   222/ 1097] train: loss: 0.1561230
[Epoch 25; Iter   252/ 1097] train: loss: 0.0231457
[Epoch 25; Iter   282/ 1097] train: loss: 0.1367463
[Epoch 25; Iter   312/ 1097] train: loss: 0.0868357
[Epoch 25; Iter   342/ 1097] train: loss: 0.0749414
[Epoch 25; Iter   372/ 1097] train: loss: 0.0337065
[Epoch 25; Iter   402/ 1097] train: loss: 0.0217142
[Epoch 25; Iter   432/ 1097] train: loss: 0.0830733
[Epoch 25; Iter   462/ 1097] train: loss: 0.1417942
[Epoch 25; Iter   492/ 1097] train: loss: 0.2023820
[Epoch 25; Iter   522/ 1097] train: loss: 0.2614338
[Epoch 25; Iter   552/ 1097] train: loss: 0.1880790
[Epoch 25; Iter   582/ 1097] train: loss: 0.1403095
[Epoch 25; Iter   612/ 1097] train: loss: 0.0284525
[Epoch 25; Iter   642/ 1097] train: loss: 0.0279056
[Epoch 25; Iter   672/ 1097] train: loss: 0.0235910
[Epoch 25; Iter   702/ 1097] train: loss: 0.0380112
[Epoch 25; Iter   732/ 1097] train: loss: 0.1322133
[Epoch 25; Iter   762/ 1097] train: loss: 0.0283297
[Epoch 25; Iter   792/ 1097] train: loss: 0.0370313
[Epoch 25; Iter   822/ 1097] train: loss: 0.0209321
[Epoch 25; Iter   852/ 1097] train: loss: 0.0213390
[Epoch 25; Iter   882/ 1097] train: loss: 0.0706472
[Epoch 25; Iter   912/ 1097] train: loss: 0.0239502
[Epoch 25; Iter   942/ 1097] train: loss: 0.1629658
[Epoch 25; Iter   972/ 1097] train: loss: 0.2272709
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0266181
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0537133
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0383861
[Epoch 25; Iter  1092/ 1097] train: loss: 0.4255165
[Epoch 25] ogbg-molhiv: 0.804058 val loss: 0.155429
[Epoch 25] ogbg-molhiv: 0.742799 test loss: 0.279255
[Epoch 26; Iter    25/ 1097] train: loss: 0.0466988
[Epoch 26; Iter    55/ 1097] train: loss: 0.0208836
[Epoch 26; Iter    85/ 1097] train: loss: 0.0709555
[Epoch 26; Iter   115/ 1097] train: loss: 0.0202059
[Epoch 26; Iter   145/ 1097] train: loss: 0.3287059
[Epoch 26; Iter   175/ 1097] train: loss: 0.0494081
[Epoch 26; Iter   205/ 1097] train: loss: 0.3411648
[Epoch 26; Iter   235/ 1097] train: loss: 0.0981473
[Epoch 26; Iter   265/ 1097] train: loss: 0.2993323
[Epoch 26; Iter   295/ 1097] train: loss: 0.0663053
[Epoch 26; Iter   325/ 1097] train: loss: 0.0395534
[Epoch 26; Iter   355/ 1097] train: loss: 0.0191457
[Epoch 26; Iter   385/ 1097] train: loss: 0.0867541
[Epoch 26; Iter   415/ 1097] train: loss: 0.0555681
[Epoch 26; Iter   445/ 1097] train: loss: 0.0422230
[Epoch 26; Iter   475/ 1097] train: loss: 0.0274738
[Epoch 26; Iter   505/ 1097] train: loss: 0.0587788
[Epoch 26; Iter   535/ 1097] train: loss: 0.1696242
[Epoch 26; Iter   565/ 1097] train: loss: 0.2866185
[Epoch 26; Iter   595/ 1097] train: loss: 0.0462239
[Epoch 26; Iter   625/ 1097] train: loss: 0.0556957
[Epoch 26; Iter   655/ 1097] train: loss: 0.1404549
[Epoch 26; Iter   685/ 1097] train: loss: 0.0652552
[Epoch 26; Iter   715/ 1097] train: loss: 0.2068789
[Epoch 26; Iter   745/ 1097] train: loss: 0.0882958
[Epoch 26; Iter   775/ 1097] train: loss: 0.0494047
[Epoch 26; Iter   805/ 1097] train: loss: 0.0803747
[Epoch 26; Iter   835/ 1097] train: loss: 0.1820546
[Epoch 26; Iter   865/ 1097] train: loss: 0.0495055
[Epoch 26; Iter   895/ 1097] train: loss: 0.0198226
[Epoch 26; Iter   925/ 1097] train: loss: 0.2713567
[Epoch 26; Iter   955/ 1097] train: loss: 0.0319805
[Epoch 26; Iter   985/ 1097] train: loss: 0.0552023
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0220636
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0417275
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1821379
[Epoch 26] ogbg-molhiv: 0.814356 val loss: 0.111821
[Epoch 26] ogbg-molhiv: 0.737181 test loss: 0.294080
[Epoch 27; Iter     8/ 1097] train: loss: 0.0430278
[Epoch 27; Iter    38/ 1097] train: loss: 0.1741575
[Epoch 27; Iter    68/ 1097] train: loss: 0.3843353
[Epoch 27; Iter    98/ 1097] train: loss: 0.0278861
[Epoch 27; Iter   128/ 1097] train: loss: 0.0333932
[Epoch 27; Iter   158/ 1097] train: loss: 0.0687854
[Epoch 27; Iter   188/ 1097] train: loss: 0.1014835
[Epoch 27; Iter   218/ 1097] train: loss: 0.0410951
[Epoch 27; Iter   248/ 1097] train: loss: 0.0204260
[Epoch 27; Iter   278/ 1097] train: loss: 0.0398450
[Epoch 27; Iter   308/ 1097] train: loss: 0.0470125
[Epoch 27; Iter   338/ 1097] train: loss: 0.2017415
[Epoch 27; Iter   368/ 1097] train: loss: 0.2149797
[Epoch 27; Iter   398/ 1097] train: loss: 0.0278516
[Epoch 27; Iter   428/ 1097] train: loss: 0.0706272
[Epoch 27; Iter   458/ 1097] train: loss: 0.0192172
[Epoch 27; Iter   488/ 1097] train: loss: 0.0202424
[Epoch 27; Iter   518/ 1097] train: loss: 0.1799415
[Epoch 27; Iter   548/ 1097] train: loss: 0.0272146
[Epoch 27; Iter   578/ 1097] train: loss: 0.0333293
[Epoch 27; Iter   608/ 1097] train: loss: 0.0632846
[Epoch 27; Iter   638/ 1097] train: loss: 0.1747191
[Epoch 27; Iter   668/ 1097] train: loss: 0.1596105
[Epoch 27; Iter   698/ 1097] train: loss: 0.0387121
[Epoch 27; Iter   728/ 1097] train: loss: 0.0934414
[Epoch 27; Iter   758/ 1097] train: loss: 0.0557970
[Epoch 27; Iter   788/ 1097] train: loss: 0.0542073
[Epoch 27; Iter   818/ 1097] train: loss: 0.0262776
[Epoch 27; Iter   848/ 1097] train: loss: 0.0437666
[Epoch 27; Iter   878/ 1097] train: loss: 0.3784348
[Epoch 27; Iter   908/ 1097] train: loss: 0.1816305
[Epoch 27; Iter   938/ 1097] train: loss: 0.1025805
[Epoch 27; Iter   968/ 1097] train: loss: 0.0514882
[Epoch 27; Iter   998/ 1097] train: loss: 0.0304160
[Epoch 27; Iter  1028/ 1097] train: loss: 0.3775851
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0811328
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1624761
[Epoch 27] ogbg-molhiv: 0.829359 val loss: 0.795858
[Epoch 27] ogbg-molhiv: 0.749987 test loss: 0.440504
[Epoch 28; Iter    21/ 1097] train: loss: 0.1507055
[Epoch 28; Iter    51/ 1097] train: loss: 0.0373453
[Epoch 28; Iter    81/ 1097] train: loss: 0.1685582
[Epoch 28; Iter   111/ 1097] train: loss: 0.1854794
[Epoch 28; Iter   141/ 1097] train: loss: 0.0210569
[Epoch 28; Iter   171/ 1097] train: loss: 0.0293813
[Epoch 28; Iter   201/ 1097] train: loss: 0.0233190
[Epoch 28; Iter   231/ 1097] train: loss: 0.0410719
[Epoch 28; Iter   261/ 1097] train: loss: 0.0352416
[Epoch 28; Iter   291/ 1097] train: loss: 0.0172671
[Epoch 28; Iter   321/ 1097] train: loss: 0.0830660
[Epoch 28; Iter   351/ 1097] train: loss: 0.0323209
[Epoch 28; Iter   381/ 1097] train: loss: 0.0475693
[Epoch 28; Iter   411/ 1097] train: loss: 0.2144006
[Epoch 28; Iter   441/ 1097] train: loss: 0.1887440
[Epoch 24; Iter   389/ 1097] train: loss: 0.0989186
[Epoch 24; Iter   419/ 1097] train: loss: 0.3312870
[Epoch 24; Iter   449/ 1097] train: loss: 0.0197862
[Epoch 24; Iter   479/ 1097] train: loss: 0.0665772
[Epoch 24; Iter   509/ 1097] train: loss: 0.0266293
[Epoch 24; Iter   539/ 1097] train: loss: 0.0227799
[Epoch 24; Iter   569/ 1097] train: loss: 0.1603107
[Epoch 24; Iter   599/ 1097] train: loss: 0.1204942
[Epoch 24; Iter   629/ 1097] train: loss: 0.0186442
[Epoch 24; Iter   659/ 1097] train: loss: 0.0193187
[Epoch 24; Iter   689/ 1097] train: loss: 0.0361256
[Epoch 24; Iter   719/ 1097] train: loss: 0.0138432
[Epoch 24; Iter   749/ 1097] train: loss: 0.0321562
[Epoch 24; Iter   779/ 1097] train: loss: 0.1089147
[Epoch 24; Iter   809/ 1097] train: loss: 0.0530985
[Epoch 24; Iter   839/ 1097] train: loss: 0.1663302
[Epoch 24; Iter   869/ 1097] train: loss: 0.1298615
[Epoch 24; Iter   899/ 1097] train: loss: 0.3050092
[Epoch 24; Iter   929/ 1097] train: loss: 0.3210332
[Epoch 24; Iter   959/ 1097] train: loss: 0.0243981
[Epoch 24; Iter   989/ 1097] train: loss: 0.0227342
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1612119
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0546559
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0296940
[Epoch 24] ogbg-molhiv: 0.807518 val loss: 0.083314
[Epoch 24] ogbg-molhiv: 0.729676 test loss: 0.126419
[Epoch 25; Iter    12/ 1097] train: loss: 0.0676899
[Epoch 25; Iter    42/ 1097] train: loss: 0.2043344
[Epoch 25; Iter    72/ 1097] train: loss: 0.0305148
[Epoch 25; Iter   102/ 1097] train: loss: 0.0744945
[Epoch 25; Iter   132/ 1097] train: loss: 0.0416196
[Epoch 25; Iter   162/ 1097] train: loss: 0.0211911
[Epoch 25; Iter   192/ 1097] train: loss: 0.0799771
[Epoch 25; Iter   222/ 1097] train: loss: 0.0192808
[Epoch 25; Iter   252/ 1097] train: loss: 0.0830474
[Epoch 25; Iter   282/ 1097] train: loss: 0.0941169
[Epoch 25; Iter   312/ 1097] train: loss: 0.0590209
[Epoch 25; Iter   342/ 1097] train: loss: 0.0344623
[Epoch 25; Iter   372/ 1097] train: loss: 0.2658708
[Epoch 25; Iter   402/ 1097] train: loss: 0.0245387
[Epoch 25; Iter   432/ 1097] train: loss: 0.2045550
[Epoch 25; Iter   462/ 1097] train: loss: 0.0331544
[Epoch 25; Iter   492/ 1097] train: loss: 0.2088592
[Epoch 25; Iter   522/ 1097] train: loss: 0.0142180
[Epoch 25; Iter   552/ 1097] train: loss: 0.1583553
[Epoch 25; Iter   582/ 1097] train: loss: 0.1781278
[Epoch 25; Iter   612/ 1097] train: loss: 0.1747767
[Epoch 25; Iter   642/ 1097] train: loss: 0.1442976
[Epoch 25; Iter   672/ 1097] train: loss: 0.0179832
[Epoch 25; Iter   702/ 1097] train: loss: 0.1134564
[Epoch 25; Iter   732/ 1097] train: loss: 0.0543382
[Epoch 25; Iter   762/ 1097] train: loss: 0.1670821
[Epoch 25; Iter   792/ 1097] train: loss: 0.0358732
[Epoch 25; Iter   822/ 1097] train: loss: 0.0753154
[Epoch 25; Iter   852/ 1097] train: loss: 0.0312494
[Epoch 25; Iter   882/ 1097] train: loss: 0.0619159
[Epoch 25; Iter   912/ 1097] train: loss: 0.1473571
[Epoch 25; Iter   942/ 1097] train: loss: 0.0361434
[Epoch 25; Iter   972/ 1097] train: loss: 0.1001237
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2796023
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2557904
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0270433
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1381773
[Epoch 25] ogbg-molhiv: 0.780209 val loss: 0.119780
[Epoch 25] ogbg-molhiv: 0.729396 test loss: 0.124256
[Epoch 26; Iter    25/ 1097] train: loss: 0.0330359
[Epoch 26; Iter    55/ 1097] train: loss: 0.0544619
[Epoch 26; Iter    85/ 1097] train: loss: 0.1081673
[Epoch 26; Iter   115/ 1097] train: loss: 0.2069231
[Epoch 26; Iter   145/ 1097] train: loss: 0.0909160
[Epoch 26; Iter   175/ 1097] train: loss: 0.1597927
[Epoch 26; Iter   205/ 1097] train: loss: 0.3801391
[Epoch 26; Iter   235/ 1097] train: loss: 0.0368545
[Epoch 26; Iter   265/ 1097] train: loss: 0.0405175
[Epoch 26; Iter   295/ 1097] train: loss: 0.1467571
[Epoch 26; Iter   325/ 1097] train: loss: 0.0625580
[Epoch 26; Iter   355/ 1097] train: loss: 0.0334465
[Epoch 26; Iter   385/ 1097] train: loss: 0.0346240
[Epoch 26; Iter   415/ 1097] train: loss: 0.0531525
[Epoch 26; Iter   445/ 1097] train: loss: 0.0335108
[Epoch 26; Iter   475/ 1097] train: loss: 0.0469636
[Epoch 26; Iter   505/ 1097] train: loss: 0.1385878
[Epoch 26; Iter   535/ 1097] train: loss: 0.0659994
[Epoch 26; Iter   565/ 1097] train: loss: 0.1415316
[Epoch 26; Iter   595/ 1097] train: loss: 0.0519661
[Epoch 26; Iter   625/ 1097] train: loss: 0.1143129
[Epoch 26; Iter   655/ 1097] train: loss: 0.0302595
[Epoch 26; Iter   685/ 1097] train: loss: 0.1718633
[Epoch 26; Iter   715/ 1097] train: loss: 0.0231086
[Epoch 26; Iter   745/ 1097] train: loss: 0.0173872
[Epoch 26; Iter   775/ 1097] train: loss: 0.0582290
[Epoch 26; Iter   805/ 1097] train: loss: 0.1412613
[Epoch 26; Iter   835/ 1097] train: loss: 0.1976656
[Epoch 26; Iter   865/ 1097] train: loss: 0.1538664
[Epoch 26; Iter   895/ 1097] train: loss: 0.0223730
[Epoch 26; Iter   925/ 1097] train: loss: 0.4425340
[Epoch 26; Iter   955/ 1097] train: loss: 0.0230494
[Epoch 26; Iter   985/ 1097] train: loss: 0.0898554
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0371000
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0457665
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0905547
[Epoch 26] ogbg-molhiv: 0.813140 val loss: 0.075685
[Epoch 26] ogbg-molhiv: 0.755841 test loss: 0.116308
[Epoch 27; Iter     8/ 1097] train: loss: 0.0680514
[Epoch 27; Iter    38/ 1097] train: loss: 0.1229907
[Epoch 27; Iter    68/ 1097] train: loss: 0.0184062
[Epoch 27; Iter    98/ 1097] train: loss: 0.1622553
[Epoch 27; Iter   128/ 1097] train: loss: 0.1476710
[Epoch 27; Iter   158/ 1097] train: loss: 0.0577322
[Epoch 27; Iter   188/ 1097] train: loss: 0.0190298
[Epoch 27; Iter   218/ 1097] train: loss: 0.1058179
[Epoch 27; Iter   248/ 1097] train: loss: 0.0394334
[Epoch 27; Iter   278/ 1097] train: loss: 0.0326703
[Epoch 27; Iter   308/ 1097] train: loss: 0.0401116
[Epoch 27; Iter   338/ 1097] train: loss: 0.0424468
[Epoch 27; Iter   368/ 1097] train: loss: 0.1853589
[Epoch 27; Iter   398/ 1097] train: loss: 0.0186787
[Epoch 27; Iter   428/ 1097] train: loss: 0.1455160
[Epoch 27; Iter   458/ 1097] train: loss: 0.0388155
[Epoch 27; Iter   488/ 1097] train: loss: 0.1080906
[Epoch 27; Iter   518/ 1097] train: loss: 0.1509113
[Epoch 27; Iter   548/ 1097] train: loss: 0.0966119
[Epoch 27; Iter   578/ 1097] train: loss: 0.1497625
[Epoch 27; Iter   608/ 1097] train: loss: 0.1691113
[Epoch 27; Iter   638/ 1097] train: loss: 0.0556321
[Epoch 27; Iter   668/ 1097] train: loss: 0.0573660
[Epoch 27; Iter   698/ 1097] train: loss: 0.0239253
[Epoch 27; Iter   728/ 1097] train: loss: 0.2233212
[Epoch 27; Iter   758/ 1097] train: loss: 0.0204765
[Epoch 27; Iter   788/ 1097] train: loss: 0.0303845
[Epoch 27; Iter   818/ 1097] train: loss: 0.0998605
[Epoch 27; Iter   848/ 1097] train: loss: 0.1183707
[Epoch 27; Iter   878/ 1097] train: loss: 0.0478597
[Epoch 27; Iter   908/ 1097] train: loss: 0.0287735
[Epoch 27; Iter   938/ 1097] train: loss: 0.2765766
[Epoch 27; Iter   968/ 1097] train: loss: 0.0222082
[Epoch 27; Iter   998/ 1097] train: loss: 0.1273036
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0210001
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2859644
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1375800
[Epoch 27] ogbg-molhiv: 0.807990 val loss: 0.074350
[Epoch 27] ogbg-molhiv: 0.737378 test loss: 0.125118
[Epoch 28; Iter    21/ 1097] train: loss: 0.0210383
[Epoch 28; Iter    51/ 1097] train: loss: 0.0455050
[Epoch 28; Iter    81/ 1097] train: loss: 0.0137921
[Epoch 28; Iter   111/ 1097] train: loss: 0.1034644
[Epoch 28; Iter   141/ 1097] train: loss: 0.1743727
[Epoch 28; Iter   171/ 1097] train: loss: 0.1677454
[Epoch 28; Iter   201/ 1097] train: loss: 0.0955662
[Epoch 28; Iter   231/ 1097] train: loss: 0.1277795
[Epoch 28; Iter   261/ 1097] train: loss: 0.1569111
[Epoch 28; Iter   291/ 1097] train: loss: 0.0207047
[Epoch 28; Iter   321/ 1097] train: loss: 0.0290484
[Epoch 28; Iter   351/ 1097] train: loss: 0.0374622
[Epoch 28; Iter   381/ 1097] train: loss: 0.2586946
[Epoch 28; Iter   411/ 1097] train: loss: 0.0178216
[Epoch 28; Iter   441/ 1097] train: loss: 0.6966368
[Epoch 28; Iter   471/ 1097] train: loss: 0.1487729
[Epoch 28; Iter   501/ 1097] train: loss: 0.0350043
[Epoch 28; Iter   531/ 1097] train: loss: 0.0442455
[Epoch 28; Iter   561/ 1097] train: loss: 0.0582432
[Epoch 28; Iter   591/ 1097] train: loss: 0.0494256
[Epoch 28; Iter   621/ 1097] train: loss: 0.0377967
[Epoch 28; Iter   651/ 1097] train: loss: 0.0104823
[Epoch 28; Iter   681/ 1097] train: loss: 0.1313768
[Epoch 28; Iter   711/ 1097] train: loss: 0.0284916
[Epoch 28; Iter   741/ 1097] train: loss: 0.0437165
[Epoch 28; Iter   771/ 1097] train: loss: 0.0623535
[Epoch 28; Iter   801/ 1097] train: loss: 0.0144427
[Epoch 28; Iter   831/ 1097] train: loss: 0.1447515
[Epoch 28; Iter   861/ 1097] train: loss: 0.0260590
[Epoch 28; Iter   891/ 1097] train: loss: 0.0098725
[Epoch 28; Iter   921/ 1097] train: loss: 0.0048884
[Epoch 28; Iter   951/ 1097] train: loss: 0.0444749
[Epoch 28; Iter   981/ 1097] train: loss: 0.1802649
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0112046
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0052093
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0086869
[Epoch 28] ogbg-molhiv: 0.740719 val loss: 0.191899
[Epoch 28] ogbg-molhiv: 0.708080 test loss: 0.254659
[Epoch 29; Iter     4/ 1097] train: loss: 0.0106063
[Epoch 29; Iter    34/ 1097] train: loss: 0.0158189
[Epoch 29; Iter    64/ 1097] train: loss: 0.0098833
[Epoch 29; Iter    94/ 1097] train: loss: 0.0226242
[Epoch 29; Iter   124/ 1097] train: loss: 0.0412169
[Epoch 29; Iter   154/ 1097] train: loss: 0.0139936
[Epoch 29; Iter   184/ 1097] train: loss: 0.0062126
[Epoch 29; Iter   214/ 1097] train: loss: 0.1143764
[Epoch 29; Iter   244/ 1097] train: loss: 0.0631082
[Epoch 29; Iter   274/ 1097] train: loss: 0.0067580
[Epoch 29; Iter   304/ 1097] train: loss: 0.0044336
[Epoch 29; Iter   334/ 1097] train: loss: 0.2412724
[Epoch 29; Iter   364/ 1097] train: loss: 0.0879406
[Epoch 29; Iter   394/ 1097] train: loss: 0.1702641
[Epoch 29; Iter   424/ 1097] train: loss: 0.0511371
[Epoch 29; Iter   454/ 1097] train: loss: 0.0632123
[Epoch 29; Iter   484/ 1097] train: loss: 0.0276472
[Epoch 29; Iter   514/ 1097] train: loss: 0.0932951
[Epoch 29; Iter   544/ 1097] train: loss: 0.0834053
[Epoch 29; Iter   574/ 1097] train: loss: 0.0194314
[Epoch 29; Iter   604/ 1097] train: loss: 0.0061441
[Epoch 29; Iter   634/ 1097] train: loss: 0.1568851
[Epoch 29; Iter   664/ 1097] train: loss: 0.0327977
[Epoch 29; Iter   694/ 1097] train: loss: 0.0913145
[Epoch 29; Iter   724/ 1097] train: loss: 0.0392057
[Epoch 29; Iter   754/ 1097] train: loss: 0.0095089
[Epoch 29; Iter   784/ 1097] train: loss: 0.0146060
[Epoch 29; Iter   814/ 1097] train: loss: 0.0208493
[Epoch 29; Iter   844/ 1097] train: loss: 0.2286851
[Epoch 29; Iter   874/ 1097] train: loss: 0.0071070
[Epoch 29; Iter   904/ 1097] train: loss: 0.2001581
[Epoch 29; Iter   934/ 1097] train: loss: 0.0242194
[Epoch 29; Iter   964/ 1097] train: loss: 0.0249432
[Epoch 29; Iter   994/ 1097] train: loss: 0.1725998
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0358882
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0134040
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0237055
[Epoch 29] ogbg-molhiv: 0.718027 val loss: 0.287398
[Epoch 29] ogbg-molhiv: 0.683406 test loss: 0.224960
[Epoch 30; Iter    17/ 1097] train: loss: 0.0228759
[Epoch 30; Iter    47/ 1097] train: loss: 0.0168150
[Epoch 30; Iter    77/ 1097] train: loss: 0.0343730
[Epoch 30; Iter   107/ 1097] train: loss: 0.0619188
[Epoch 30; Iter   137/ 1097] train: loss: 0.0183150
[Epoch 30; Iter   167/ 1097] train: loss: 0.0527310
[Epoch 30; Iter   197/ 1097] train: loss: 0.0133068
[Epoch 30; Iter   227/ 1097] train: loss: 0.0146986
[Epoch 30; Iter   257/ 1097] train: loss: 0.0091799
[Epoch 30; Iter   287/ 1097] train: loss: 0.0252338
[Epoch 30; Iter   317/ 1097] train: loss: 0.0401530
[Epoch 30; Iter   347/ 1097] train: loss: 0.0071972
[Epoch 30; Iter   377/ 1097] train: loss: 0.0033891
[Epoch 30; Iter   407/ 1097] train: loss: 0.0076088
[Epoch 30; Iter   437/ 1097] train: loss: 0.1469286
[Epoch 30; Iter   467/ 1097] train: loss: 0.0104785
[Epoch 30; Iter   497/ 1097] train: loss: 0.0429521
[Epoch 30; Iter   527/ 1097] train: loss: 0.0053268
[Epoch 30; Iter   557/ 1097] train: loss: 0.0046951
[Epoch 30; Iter   587/ 1097] train: loss: 0.0165410
[Epoch 30; Iter   617/ 1097] train: loss: 0.0133374
[Epoch 30; Iter   647/ 1097] train: loss: 0.0451779
[Epoch 30; Iter   677/ 1097] train: loss: 0.0055479
[Epoch 30; Iter   707/ 1097] train: loss: 0.1300320
[Epoch 30; Iter   737/ 1097] train: loss: 0.0334758
[Epoch 30; Iter   767/ 1097] train: loss: 0.0134455
[Epoch 30; Iter   797/ 1097] train: loss: 0.0282560
[Epoch 30; Iter   827/ 1097] train: loss: 0.0174056
[Epoch 30; Iter   857/ 1097] train: loss: 0.0325773
[Epoch 30; Iter   887/ 1097] train: loss: 0.0663508
[Epoch 30; Iter   917/ 1097] train: loss: 0.1246957
[Epoch 30; Iter   947/ 1097] train: loss: 0.1948313
[Epoch 30; Iter   977/ 1097] train: loss: 0.0756124
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0046059
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0173423
[Epoch 30; Iter  1067/ 1097] train: loss: 0.1336029
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0027292
[Epoch 30] ogbg-molhiv: 0.754054 val loss: 0.138425
[Epoch 30] ogbg-molhiv: 0.706646 test loss: 0.208714
[Epoch 31; Iter    30/ 1097] train: loss: 0.0050026
[Epoch 31; Iter    60/ 1097] train: loss: 0.0351064
[Epoch 31; Iter    90/ 1097] train: loss: 0.0264236
[Epoch 31; Iter   120/ 1097] train: loss: 0.1299701
[Epoch 31; Iter   150/ 1097] train: loss: 0.0184201
[Epoch 31; Iter   180/ 1097] train: loss: 0.0129155
[Epoch 31; Iter   210/ 1097] train: loss: 0.0187194
[Epoch 31; Iter   240/ 1097] train: loss: 0.0398944
[Epoch 31; Iter   270/ 1097] train: loss: 0.0185356
[Epoch 31; Iter   300/ 1097] train: loss: 0.0128031
[Epoch 31; Iter   330/ 1097] train: loss: 0.0245194
[Epoch 31; Iter   360/ 1097] train: loss: 0.0034609
[Epoch 31; Iter   390/ 1097] train: loss: 0.1782646
[Epoch 31; Iter   420/ 1097] train: loss: 0.0216158
[Epoch 31; Iter   450/ 1097] train: loss: 0.0555606
[Epoch 31; Iter   480/ 1097] train: loss: 0.0119599
[Epoch 31; Iter   510/ 1097] train: loss: 0.0213399
[Epoch 31; Iter   540/ 1097] train: loss: 0.0317558
[Epoch 31; Iter   570/ 1097] train: loss: 0.0202543
[Epoch 31; Iter   600/ 1097] train: loss: 0.0148324
[Epoch 31; Iter   630/ 1097] train: loss: 0.0381666
[Epoch 31; Iter   660/ 1097] train: loss: 0.0139397
[Epoch 31; Iter   690/ 1097] train: loss: 0.0201049
[Epoch 31; Iter   720/ 1097] train: loss: 0.0058682
[Epoch 31; Iter   750/ 1097] train: loss: 0.0083641
[Epoch 31; Iter   780/ 1097] train: loss: 0.0616282
[Epoch 31; Iter   810/ 1097] train: loss: 0.0662792
[Epoch 31; Iter   840/ 1097] train: loss: 0.0069951
[Epoch 31; Iter   870/ 1097] train: loss: 0.0677104
[Epoch 31; Iter   900/ 1097] train: loss: 0.0083444
[Epoch 31; Iter   930/ 1097] train: loss: 0.0757662
[Epoch 31; Iter   960/ 1097] train: loss: 0.0051900
[Epoch 31; Iter   990/ 1097] train: loss: 0.0374536
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0499372
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0052408
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0483238
[Epoch 31] ogbg-molhiv: 0.738362 val loss: 0.321713
[Epoch 31] ogbg-molhiv: 0.687943 test loss: 0.254164
[Epoch 32; Iter    13/ 1097] train: loss: 0.1128983
[Epoch 32; Iter    43/ 1097] train: loss: 0.1071786
[Epoch 32; Iter    73/ 1097] train: loss: 0.0660248
[Epoch 32; Iter   103/ 1097] train: loss: 0.0068580
[Epoch 32; Iter   133/ 1097] train: loss: 0.1423045
[Epoch 32; Iter   163/ 1097] train: loss: 0.0235284
[Epoch 32; Iter   193/ 1097] train: loss: 0.0991636
[Epoch 32; Iter   223/ 1097] train: loss: 0.0110852
[Epoch 32; Iter   253/ 1097] train: loss: 0.0046181
[Epoch 32; Iter   283/ 1097] train: loss: 0.0767238
[Epoch 32; Iter   313/ 1097] train: loss: 0.2853362
[Epoch 32; Iter   343/ 1097] train: loss: 0.0210553
[Epoch 32; Iter   373/ 1097] train: loss: 0.0625054
[Epoch 32; Iter   403/ 1097] train: loss: 0.0035057
[Epoch 32; Iter   433/ 1097] train: loss: 0.0662216
[Epoch 32; Iter   463/ 1097] train: loss: 0.0796187
[Epoch 32; Iter   493/ 1097] train: loss: 0.0153386
[Epoch 32; Iter   523/ 1097] train: loss: 0.0071380
[Epoch 28; Iter   471/ 1097] train: loss: 0.0088993
[Epoch 28; Iter   501/ 1097] train: loss: 0.0465411
[Epoch 28; Iter   531/ 1097] train: loss: 0.0816341
[Epoch 28; Iter   561/ 1097] train: loss: 0.0168031
[Epoch 28; Iter   591/ 1097] train: loss: 0.0169431
[Epoch 28; Iter   621/ 1097] train: loss: 0.0484239
[Epoch 28; Iter   651/ 1097] train: loss: 0.1084331
[Epoch 28; Iter   681/ 1097] train: loss: 0.0509843
[Epoch 28; Iter   711/ 1097] train: loss: 0.0430060
[Epoch 28; Iter   741/ 1097] train: loss: 0.0537120
[Epoch 28; Iter   771/ 1097] train: loss: 0.0515706
[Epoch 28; Iter   801/ 1097] train: loss: 0.2161033
[Epoch 28; Iter   831/ 1097] train: loss: 0.0195063
[Epoch 28; Iter   861/ 1097] train: loss: 0.0550531
[Epoch 28; Iter   891/ 1097] train: loss: 0.1022379
[Epoch 28; Iter   921/ 1097] train: loss: 0.0344048
[Epoch 28; Iter   951/ 1097] train: loss: 0.0898130
[Epoch 28; Iter   981/ 1097] train: loss: 0.0389789
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0598688
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0685898
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1097455
[Epoch 28] ogbg-molhiv: 0.704647 val loss: 6.305278
[Epoch 28] ogbg-molhiv: 0.614485 test loss: 4.774750
[Epoch 29; Iter     4/ 1097] train: loss: 0.0098197
[Epoch 29; Iter    34/ 1097] train: loss: 0.0399356
[Epoch 29; Iter    64/ 1097] train: loss: 0.1580691
[Epoch 29; Iter    94/ 1097] train: loss: 0.0131672
[Epoch 29; Iter   124/ 1097] train: loss: 0.0090643
[Epoch 29; Iter   154/ 1097] train: loss: 0.1485016
[Epoch 29; Iter   184/ 1097] train: loss: 0.0290043
[Epoch 29; Iter   214/ 1097] train: loss: 0.1887568
[Epoch 29; Iter   244/ 1097] train: loss: 0.0181240
[Epoch 29; Iter   274/ 1097] train: loss: 0.0133235
[Epoch 29; Iter   304/ 1097] train: loss: 0.0387407
[Epoch 29; Iter   334/ 1097] train: loss: 0.0079411
[Epoch 29; Iter   364/ 1097] train: loss: 0.1192310
[Epoch 29; Iter   394/ 1097] train: loss: 0.0306205
[Epoch 29; Iter   424/ 1097] train: loss: 0.0384485
[Epoch 29; Iter   454/ 1097] train: loss: 0.0167063
[Epoch 29; Iter   484/ 1097] train: loss: 0.0072968
[Epoch 29; Iter   514/ 1097] train: loss: 0.0977208
[Epoch 29; Iter   544/ 1097] train: loss: 0.0100508
[Epoch 29; Iter   574/ 1097] train: loss: 0.0228209
[Epoch 29; Iter   604/ 1097] train: loss: 0.0288381
[Epoch 29; Iter   634/ 1097] train: loss: 0.0149985
[Epoch 29; Iter   664/ 1097] train: loss: 0.0690677
[Epoch 29; Iter   694/ 1097] train: loss: 0.0920047
[Epoch 29; Iter   724/ 1097] train: loss: 0.0294336
[Epoch 29; Iter   754/ 1097] train: loss: 0.0548539
[Epoch 29; Iter   784/ 1097] train: loss: 0.0288768
[Epoch 29; Iter   814/ 1097] train: loss: 0.0165542
[Epoch 29; Iter   844/ 1097] train: loss: 0.0120998
[Epoch 29; Iter   874/ 1097] train: loss: 0.0125070
[Epoch 29; Iter   904/ 1097] train: loss: 0.0986093
[Epoch 29; Iter   934/ 1097] train: loss: 0.0372266
[Epoch 29; Iter   964/ 1097] train: loss: 0.0095207
[Epoch 29; Iter   994/ 1097] train: loss: 0.2101047
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0161755
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1038499
[Epoch 29; Iter  1084/ 1097] train: loss: 0.2104319
[Epoch 29] ogbg-molhiv: 0.699040 val loss: 18.081788
[Epoch 29] ogbg-molhiv: 0.602354 test loss: 9.813484
[Epoch 30; Iter    17/ 1097] train: loss: 0.0364756
[Epoch 30; Iter    47/ 1097] train: loss: 0.0076800
[Epoch 30; Iter    77/ 1097] train: loss: 0.0248493
[Epoch 30; Iter   107/ 1097] train: loss: 0.0164225
[Epoch 30; Iter   137/ 1097] train: loss: 0.0065672
[Epoch 30; Iter   167/ 1097] train: loss: 0.0766011
[Epoch 30; Iter   197/ 1097] train: loss: 0.0094416
[Epoch 30; Iter   227/ 1097] train: loss: 0.0039416
[Epoch 30; Iter   257/ 1097] train: loss: 0.0678216
[Epoch 30; Iter   287/ 1097] train: loss: 0.1448296
[Epoch 30; Iter   317/ 1097] train: loss: 0.0704432
[Epoch 30; Iter   347/ 1097] train: loss: 0.0120954
[Epoch 30; Iter   377/ 1097] train: loss: 0.0139381
[Epoch 30; Iter   407/ 1097] train: loss: 0.0151839
[Epoch 30; Iter   437/ 1097] train: loss: 0.0234035
[Epoch 30; Iter   467/ 1097] train: loss: 0.0052276
[Epoch 30; Iter   497/ 1097] train: loss: 0.1181613
[Epoch 30; Iter   527/ 1097] train: loss: 0.0120736
[Epoch 30; Iter   557/ 1097] train: loss: 0.0119091
[Epoch 30; Iter   587/ 1097] train: loss: 0.0723384
[Epoch 30; Iter   617/ 1097] train: loss: 0.0381024
[Epoch 30; Iter   647/ 1097] train: loss: 0.0283626
[Epoch 30; Iter   677/ 1097] train: loss: 0.0274653
[Epoch 30; Iter   707/ 1097] train: loss: 0.0189903
[Epoch 30; Iter   737/ 1097] train: loss: 0.0400466
[Epoch 30; Iter   767/ 1097] train: loss: 0.0145310
[Epoch 30; Iter   797/ 1097] train: loss: 0.0096497
[Epoch 30; Iter   827/ 1097] train: loss: 0.0513933
[Epoch 30; Iter   857/ 1097] train: loss: 0.0268922
[Epoch 30; Iter   887/ 1097] train: loss: 0.0096543
[Epoch 30; Iter   917/ 1097] train: loss: 0.0091188
[Epoch 30; Iter   947/ 1097] train: loss: 0.0265760
[Epoch 30; Iter   977/ 1097] train: loss: 0.0835429
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0070692
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0174494
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0072001
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0083168
[Epoch 30] ogbg-molhiv: 0.718539 val loss: 10.923857
[Epoch 30] ogbg-molhiv: 0.634379 test loss: 7.039533
[Epoch 31; Iter    30/ 1097] train: loss: 0.0108571
[Epoch 31; Iter    60/ 1097] train: loss: 0.0121420
[Epoch 31; Iter    90/ 1097] train: loss: 0.0118691
[Epoch 31; Iter   120/ 1097] train: loss: 0.0093776
[Epoch 31; Iter   150/ 1097] train: loss: 0.0169825
[Epoch 31; Iter   180/ 1097] train: loss: 0.1217033
[Epoch 31; Iter   210/ 1097] train: loss: 0.0283620
[Epoch 31; Iter   240/ 1097] train: loss: 0.0044179
[Epoch 31; Iter   270/ 1097] train: loss: 0.0109716
[Epoch 31; Iter   300/ 1097] train: loss: 0.0042161
[Epoch 31; Iter   330/ 1097] train: loss: 0.0088793
[Epoch 31; Iter   360/ 1097] train: loss: 0.0353623
[Epoch 31; Iter   390/ 1097] train: loss: 0.0181733
[Epoch 31; Iter   420/ 1097] train: loss: 0.0257449
[Epoch 31; Iter   450/ 1097] train: loss: 0.0132770
[Epoch 31; Iter   480/ 1097] train: loss: 0.0225248
[Epoch 31; Iter   510/ 1097] train: loss: 0.0052481
[Epoch 31; Iter   540/ 1097] train: loss: 0.0285583
[Epoch 31; Iter   570/ 1097] train: loss: 0.0279760
[Epoch 31; Iter   600/ 1097] train: loss: 0.0044407
[Epoch 31; Iter   630/ 1097] train: loss: 0.0247183
[Epoch 31; Iter   660/ 1097] train: loss: 0.0046971
[Epoch 31; Iter   690/ 1097] train: loss: 0.0579842
[Epoch 31; Iter   720/ 1097] train: loss: 0.0123880
[Epoch 31; Iter   750/ 1097] train: loss: 0.0722769
[Epoch 31; Iter   780/ 1097] train: loss: 0.0432706
[Epoch 31; Iter   810/ 1097] train: loss: 0.0725239
[Epoch 31; Iter   840/ 1097] train: loss: 0.0502642
[Epoch 31; Iter   870/ 1097] train: loss: 0.0482599
[Epoch 31; Iter   900/ 1097] train: loss: 0.1425023
[Epoch 31; Iter   930/ 1097] train: loss: 0.0179230
[Epoch 31; Iter   960/ 1097] train: loss: 0.0705786
[Epoch 31; Iter   990/ 1097] train: loss: 0.0457997
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0264295
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0095097
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0119090
[Epoch 31] ogbg-molhiv: 0.719816 val loss: 15.415938
[Epoch 31] ogbg-molhiv: 0.609587 test loss: 8.271342
[Epoch 32; Iter    13/ 1097] train: loss: 0.0748092
[Epoch 32; Iter    43/ 1097] train: loss: 0.0071375
[Epoch 32; Iter    73/ 1097] train: loss: 0.0074918
[Epoch 32; Iter   103/ 1097] train: loss: 0.0040007
[Epoch 32; Iter   133/ 1097] train: loss: 0.0347401
[Epoch 32; Iter   163/ 1097] train: loss: 0.0098855
[Epoch 32; Iter   193/ 1097] train: loss: 0.0065817
[Epoch 32; Iter   223/ 1097] train: loss: 0.0480232
[Epoch 32; Iter   253/ 1097] train: loss: 0.0173928
[Epoch 32; Iter   283/ 1097] train: loss: 0.0080402
[Epoch 32; Iter   313/ 1097] train: loss: 0.0263109
[Epoch 32; Iter   343/ 1097] train: loss: 0.0067605
[Epoch 32; Iter   373/ 1097] train: loss: 0.0083525
[Epoch 32; Iter   403/ 1097] train: loss: 0.0235581
[Epoch 32; Iter   433/ 1097] train: loss: 0.0041673
[Epoch 32; Iter   463/ 1097] train: loss: 0.0042024
[Epoch 32; Iter   493/ 1097] train: loss: 0.0086239
[Epoch 32; Iter   523/ 1097] train: loss: 0.0023071
[Epoch 28; Iter   471/ 1097] train: loss: 0.0181534
[Epoch 28; Iter   501/ 1097] train: loss: 0.0550036
[Epoch 28; Iter   531/ 1097] train: loss: 0.0181286
[Epoch 28; Iter   561/ 1097] train: loss: 0.0871017
[Epoch 28; Iter   591/ 1097] train: loss: 0.1088698
[Epoch 28; Iter   621/ 1097] train: loss: 0.1553031
[Epoch 28; Iter   651/ 1097] train: loss: 0.0227116
[Epoch 28; Iter   681/ 1097] train: loss: 0.0307548
[Epoch 28; Iter   711/ 1097] train: loss: 0.0390938
[Epoch 28; Iter   741/ 1097] train: loss: 0.0113663
[Epoch 28; Iter   771/ 1097] train: loss: 0.0649367
[Epoch 28; Iter   801/ 1097] train: loss: 0.0308425
[Epoch 28; Iter   831/ 1097] train: loss: 0.0141744
[Epoch 28; Iter   861/ 1097] train: loss: 0.1475871
[Epoch 28; Iter   891/ 1097] train: loss: 0.0553244
[Epoch 28; Iter   921/ 1097] train: loss: 0.0178948
[Epoch 28; Iter   951/ 1097] train: loss: 0.0389123
[Epoch 28; Iter   981/ 1097] train: loss: 0.0321594
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0230694
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0447074
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0167433
[Epoch 28] ogbg-molhiv: 0.744185 val loss: 1.216563
[Epoch 28] ogbg-molhiv: 0.656770 test loss: 1.733895
[Epoch 29; Iter     4/ 1097] train: loss: 0.0109490
[Epoch 29; Iter    34/ 1097] train: loss: 0.0586723
[Epoch 29; Iter    64/ 1097] train: loss: 0.1467613
[Epoch 29; Iter    94/ 1097] train: loss: 0.0155227
[Epoch 29; Iter   124/ 1097] train: loss: 0.1430198
[Epoch 29; Iter   154/ 1097] train: loss: 0.1315196
[Epoch 29; Iter   184/ 1097] train: loss: 0.0180891
[Epoch 29; Iter   214/ 1097] train: loss: 0.0488021
[Epoch 29; Iter   244/ 1097] train: loss: 0.0927742
[Epoch 29; Iter   274/ 1097] train: loss: 0.0139538
[Epoch 29; Iter   304/ 1097] train: loss: 0.2165933
[Epoch 29; Iter   334/ 1097] train: loss: 0.0562748
[Epoch 29; Iter   364/ 1097] train: loss: 0.0205138
[Epoch 29; Iter   394/ 1097] train: loss: 0.1146706
[Epoch 29; Iter   424/ 1097] train: loss: 0.0354429
[Epoch 29; Iter   454/ 1097] train: loss: 0.0124339
[Epoch 29; Iter   484/ 1097] train: loss: 0.0502954
[Epoch 29; Iter   514/ 1097] train: loss: 0.0242569
[Epoch 29; Iter   544/ 1097] train: loss: 0.0236765
[Epoch 29; Iter   574/ 1097] train: loss: 0.0171121
[Epoch 29; Iter   604/ 1097] train: loss: 0.1254928
[Epoch 29; Iter   634/ 1097] train: loss: 0.2312074
[Epoch 29; Iter   664/ 1097] train: loss: 0.0092152
[Epoch 29; Iter   694/ 1097] train: loss: 0.0299281
[Epoch 29; Iter   724/ 1097] train: loss: 0.0245479
[Epoch 29; Iter   754/ 1097] train: loss: 0.0935214
[Epoch 29; Iter   784/ 1097] train: loss: 0.1388530
[Epoch 29; Iter   814/ 1097] train: loss: 0.0154175
[Epoch 29; Iter   844/ 1097] train: loss: 0.0726667
[Epoch 29; Iter   874/ 1097] train: loss: 0.4411964
[Epoch 29; Iter   904/ 1097] train: loss: 0.0173245
[Epoch 29; Iter   934/ 1097] train: loss: 0.2538338
[Epoch 29; Iter   964/ 1097] train: loss: 0.0262573
[Epoch 29; Iter   994/ 1097] train: loss: 0.0557949
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0220751
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1135237
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0202883
[Epoch 29] ogbg-molhiv: 0.754495 val loss: 0.576525
[Epoch 29] ogbg-molhiv: 0.641550 test loss: 0.729933
[Epoch 30; Iter    17/ 1097] train: loss: 0.0146489
[Epoch 30; Iter    47/ 1097] train: loss: 0.1132538
[Epoch 30; Iter    77/ 1097] train: loss: 0.0373339
[Epoch 30; Iter   107/ 1097] train: loss: 0.0661945
[Epoch 30; Iter   137/ 1097] train: loss: 0.0681598
[Epoch 30; Iter   167/ 1097] train: loss: 0.0217159
[Epoch 30; Iter   197/ 1097] train: loss: 0.0223102
[Epoch 30; Iter   227/ 1097] train: loss: 0.0166465
[Epoch 30; Iter   257/ 1097] train: loss: 0.0637543
[Epoch 30; Iter   287/ 1097] train: loss: 0.0103165
[Epoch 30; Iter   317/ 1097] train: loss: 0.1142292
[Epoch 30; Iter   347/ 1097] train: loss: 0.0594900
[Epoch 30; Iter   377/ 1097] train: loss: 0.0558475
[Epoch 30; Iter   407/ 1097] train: loss: 0.0167102
[Epoch 30; Iter   437/ 1097] train: loss: 0.0330890
[Epoch 30; Iter   467/ 1097] train: loss: 0.0190963
[Epoch 30; Iter   497/ 1097] train: loss: 0.1885862
[Epoch 30; Iter   527/ 1097] train: loss: 0.1294946
[Epoch 30; Iter   557/ 1097] train: loss: 0.1733941
[Epoch 30; Iter   587/ 1097] train: loss: 0.0235663
[Epoch 30; Iter   617/ 1097] train: loss: 0.0258771
[Epoch 30; Iter   647/ 1097] train: loss: 0.0146838
[Epoch 30; Iter   677/ 1097] train: loss: 0.0769662
[Epoch 30; Iter   707/ 1097] train: loss: 0.1207709
[Epoch 30; Iter   737/ 1097] train: loss: 0.0944296
[Epoch 30; Iter   767/ 1097] train: loss: 0.2404074
[Epoch 30; Iter   797/ 1097] train: loss: 0.2236543
[Epoch 30; Iter   827/ 1097] train: loss: 0.2135587
[Epoch 30; Iter   857/ 1097] train: loss: 0.0269383
[Epoch 30; Iter   887/ 1097] train: loss: 0.0211473
[Epoch 30; Iter   917/ 1097] train: loss: 0.1097301
[Epoch 30; Iter   947/ 1097] train: loss: 0.0136983
[Epoch 30; Iter   977/ 1097] train: loss: 0.0343544
[Epoch 30; Iter  1007/ 1097] train: loss: 0.1319777
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1586678
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0159902
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0275773
[Epoch 30] ogbg-molhiv: 0.736570 val loss: 0.233805
[Epoch 30] ogbg-molhiv: 0.677269 test loss: 0.292937
[Epoch 31; Iter    30/ 1097] train: loss: 0.0969706
[Epoch 31; Iter    60/ 1097] train: loss: 0.0698232
[Epoch 31; Iter    90/ 1097] train: loss: 0.0335874
[Epoch 31; Iter   120/ 1097] train: loss: 0.0171138
[Epoch 31; Iter   150/ 1097] train: loss: 0.2466589
[Epoch 31; Iter   180/ 1097] train: loss: 0.0160197
[Epoch 31; Iter   210/ 1097] train: loss: 0.0294461
[Epoch 31; Iter   240/ 1097] train: loss: 0.0372780
[Epoch 31; Iter   270/ 1097] train: loss: 0.0433033
[Epoch 31; Iter   300/ 1097] train: loss: 0.1211029
[Epoch 31; Iter   330/ 1097] train: loss: 0.0883626
[Epoch 31; Iter   360/ 1097] train: loss: 0.1470818
[Epoch 31; Iter   390/ 1097] train: loss: 0.0661873
[Epoch 31; Iter   420/ 1097] train: loss: 0.2773715
[Epoch 31; Iter   450/ 1097] train: loss: 0.0711159
[Epoch 31; Iter   480/ 1097] train: loss: 0.0978472
[Epoch 31; Iter   510/ 1097] train: loss: 0.0367143
[Epoch 31; Iter   540/ 1097] train: loss: 0.0789169
[Epoch 31; Iter   570/ 1097] train: loss: 0.2117886
[Epoch 31; Iter   600/ 1097] train: loss: 0.0260549
[Epoch 31; Iter   630/ 1097] train: loss: 0.0129587
[Epoch 31; Iter   660/ 1097] train: loss: 0.0718930
[Epoch 31; Iter   690/ 1097] train: loss: 0.0640796
[Epoch 31; Iter   720/ 1097] train: loss: 0.0835510
[Epoch 31; Iter   750/ 1097] train: loss: 0.0094712
[Epoch 31; Iter   780/ 1097] train: loss: 0.0136769
[Epoch 31; Iter   810/ 1097] train: loss: 0.0086108
[Epoch 31; Iter   840/ 1097] train: loss: 0.1924531
[Epoch 31; Iter   870/ 1097] train: loss: 0.0753134
[Epoch 31; Iter   900/ 1097] train: loss: 0.0122924
[Epoch 31; Iter   930/ 1097] train: loss: 0.0135055
[Epoch 31; Iter   960/ 1097] train: loss: 0.0269568
[Epoch 31; Iter   990/ 1097] train: loss: 0.1440385
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1492911
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0467593
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0150688
[Epoch 31] ogbg-molhiv: 0.735863 val loss: 0.149414
[Epoch 31] ogbg-molhiv: 0.669835 test loss: 0.377265
[Epoch 32; Iter    13/ 1097] train: loss: 0.0189245
[Epoch 32; Iter    43/ 1097] train: loss: 0.1807716
[Epoch 32; Iter    73/ 1097] train: loss: 0.0387444
[Epoch 32; Iter   103/ 1097] train: loss: 0.1098312
[Epoch 32; Iter   133/ 1097] train: loss: 0.0337594
[Epoch 32; Iter   163/ 1097] train: loss: 0.0679280
[Epoch 32; Iter   193/ 1097] train: loss: 0.0647293
[Epoch 32; Iter   223/ 1097] train: loss: 0.0170018
[Epoch 32; Iter   253/ 1097] train: loss: 0.0967985
[Epoch 32; Iter   283/ 1097] train: loss: 0.0464698
[Epoch 32; Iter   313/ 1097] train: loss: 0.0104811
[Epoch 32; Iter   343/ 1097] train: loss: 0.1392580
[Epoch 32; Iter   373/ 1097] train: loss: 0.0832966
[Epoch 32; Iter   403/ 1097] train: loss: 0.0192549
[Epoch 32; Iter   433/ 1097] train: loss: 0.0808389
[Epoch 32; Iter   463/ 1097] train: loss: 0.0474253
[Epoch 32; Iter   493/ 1097] train: loss: 0.0316758
[Epoch 32; Iter   523/ 1097] train: loss: 0.0757470
[Epoch 32; Iter   523/ 1097] train: loss: 0.0180729
[Epoch 32; Iter   553/ 1097] train: loss: 0.0075981
[Epoch 32; Iter   583/ 1097] train: loss: 0.1369879
[Epoch 32; Iter   613/ 1097] train: loss: 0.0061458
[Epoch 32; Iter   643/ 1097] train: loss: 0.2467189
[Epoch 32; Iter   673/ 1097] train: loss: 0.0097491
[Epoch 32; Iter   703/ 1097] train: loss: 0.0509861
[Epoch 32; Iter   733/ 1097] train: loss: 0.0416608
[Epoch 32; Iter   763/ 1097] train: loss: 0.0054085
[Epoch 32; Iter   793/ 1097] train: loss: 0.0253735
[Epoch 32; Iter   823/ 1097] train: loss: 0.0076569
[Epoch 32; Iter   853/ 1097] train: loss: 0.0188808
[Epoch 32; Iter   883/ 1097] train: loss: 0.0438311
[Epoch 32; Iter   913/ 1097] train: loss: 0.0136136
[Epoch 32; Iter   943/ 1097] train: loss: 0.0022908
[Epoch 32; Iter   973/ 1097] train: loss: 0.0178796
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0027732
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0071117
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0227099
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0332440
[Epoch 32] ogbg-molhiv: 0.833367 val loss: 0.743654
[Epoch 32] ogbg-molhiv: 0.749174 test loss: 0.191538
[Epoch 33; Iter    26/ 1097] train: loss: 0.1058791
[Epoch 33; Iter    56/ 1097] train: loss: 0.0118393
[Epoch 33; Iter    86/ 1097] train: loss: 0.0100442
[Epoch 33; Iter   116/ 1097] train: loss: 0.0932890
[Epoch 33; Iter   146/ 1097] train: loss: 0.0396784
[Epoch 33; Iter   176/ 1097] train: loss: 0.0036908
[Epoch 33; Iter   206/ 1097] train: loss: 0.0614108
[Epoch 33; Iter   236/ 1097] train: loss: 0.0938953
[Epoch 33; Iter   266/ 1097] train: loss: 0.0116570
[Epoch 33; Iter   296/ 1097] train: loss: 0.0834832
[Epoch 33; Iter   326/ 1097] train: loss: 0.1524054
[Epoch 33; Iter   356/ 1097] train: loss: 0.2628636
[Epoch 33; Iter   386/ 1097] train: loss: 0.0114879
[Epoch 33; Iter   416/ 1097] train: loss: 0.0050705
[Epoch 33; Iter   446/ 1097] train: loss: 0.0106230
[Epoch 33; Iter   476/ 1097] train: loss: 0.0047082
[Epoch 33; Iter   506/ 1097] train: loss: 0.0643975
[Epoch 33; Iter   536/ 1097] train: loss: 0.0058969
[Epoch 33; Iter   566/ 1097] train: loss: 0.0159271
[Epoch 33; Iter   596/ 1097] train: loss: 0.0172043
[Epoch 33; Iter   626/ 1097] train: loss: 0.0189041
[Epoch 33; Iter   656/ 1097] train: loss: 0.0684674
[Epoch 33; Iter   686/ 1097] train: loss: 0.0112840
[Epoch 33; Iter   716/ 1097] train: loss: 0.3654737
[Epoch 33; Iter   746/ 1097] train: loss: 0.0075913
[Epoch 33; Iter   776/ 1097] train: loss: 0.3163555
[Epoch 33; Iter   806/ 1097] train: loss: 0.0112238
[Epoch 33; Iter   836/ 1097] train: loss: 0.0667007
[Epoch 33; Iter   866/ 1097] train: loss: 0.0212036
[Epoch 33; Iter   896/ 1097] train: loss: 0.0209346
[Epoch 33; Iter   926/ 1097] train: loss: 0.0140562
[Epoch 33; Iter   956/ 1097] train: loss: 0.0037085
[Epoch 33; Iter   986/ 1097] train: loss: 0.0246495
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0027040
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0066359
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0432085
[Epoch 33] ogbg-molhiv: 0.810170 val loss: 1.122628
[Epoch 33] ogbg-molhiv: 0.738510 test loss: 0.275254
[Epoch 34; Iter     9/ 1097] train: loss: 0.0309448
[Epoch 34; Iter    39/ 1097] train: loss: 0.0124486
[Epoch 34; Iter    69/ 1097] train: loss: 0.0075989
[Epoch 34; Iter    99/ 1097] train: loss: 0.0653517
[Epoch 34; Iter   129/ 1097] train: loss: 0.0072434
[Epoch 34; Iter   159/ 1097] train: loss: 0.0165102
[Epoch 34; Iter   189/ 1097] train: loss: 0.0239694
[Epoch 34; Iter   219/ 1097] train: loss: 0.0145003
[Epoch 34; Iter   249/ 1097] train: loss: 0.0034614
[Epoch 34; Iter   279/ 1097] train: loss: 0.0319626
[Epoch 34; Iter   309/ 1097] train: loss: 0.0176469
[Epoch 34; Iter   339/ 1097] train: loss: 0.0161758
[Epoch 34; Iter   369/ 1097] train: loss: 0.0066744
[Epoch 34; Iter   399/ 1097] train: loss: 0.0106374
[Epoch 34; Iter   429/ 1097] train: loss: 0.0328587
[Epoch 34; Iter   459/ 1097] train: loss: 0.0225584
[Epoch 34; Iter   489/ 1097] train: loss: 0.0487055
[Epoch 34; Iter   519/ 1097] train: loss: 0.0071323
[Epoch 34; Iter   549/ 1097] train: loss: 0.0173132
[Epoch 34; Iter   579/ 1097] train: loss: 0.0343863
[Epoch 34; Iter   609/ 1097] train: loss: 0.0219197
[Epoch 34; Iter   639/ 1097] train: loss: 0.0341121
[Epoch 34; Iter   669/ 1097] train: loss: 0.0045096
[Epoch 34; Iter   699/ 1097] train: loss: 0.0744746
[Epoch 34; Iter   729/ 1097] train: loss: 0.0409984
[Epoch 34; Iter   759/ 1097] train: loss: 0.0822600
[Epoch 34; Iter   789/ 1097] train: loss: 0.0305542
[Epoch 34; Iter   819/ 1097] train: loss: 0.0180431
[Epoch 34; Iter   849/ 1097] train: loss: 0.1721955
[Epoch 34; Iter   879/ 1097] train: loss: 0.0019795
[Epoch 34; Iter   909/ 1097] train: loss: 0.0051654
[Epoch 34; Iter   939/ 1097] train: loss: 0.0096536
[Epoch 34; Iter   969/ 1097] train: loss: 0.0183333
[Epoch 34; Iter   999/ 1097] train: loss: 0.0111038
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0340617
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1913258
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0131713
[Epoch 34] ogbg-molhiv: 0.817564 val loss: 0.577322
[Epoch 34] ogbg-molhiv: 0.732135 test loss: 0.246302
[Epoch 35; Iter    22/ 1097] train: loss: 0.0023725
[Epoch 35; Iter    52/ 1097] train: loss: 0.0049852
[Epoch 35; Iter    82/ 1097] train: loss: 0.1906053
[Epoch 35; Iter   112/ 1097] train: loss: 0.0077259
[Epoch 35; Iter   142/ 1097] train: loss: 0.0581502
[Epoch 35; Iter   172/ 1097] train: loss: 0.0023933
[Epoch 35; Iter   202/ 1097] train: loss: 0.0152147
[Epoch 35; Iter   232/ 1097] train: loss: 0.0105288
[Epoch 35; Iter   262/ 1097] train: loss: 0.0436575
[Epoch 35; Iter   292/ 1097] train: loss: 0.0234511
[Epoch 35; Iter   322/ 1097] train: loss: 0.0118720
[Epoch 35; Iter   352/ 1097] train: loss: 0.0177096
[Epoch 35; Iter   382/ 1097] train: loss: 0.0033205
[Epoch 35; Iter   412/ 1097] train: loss: 0.0126395
[Epoch 35; Iter   442/ 1097] train: loss: 0.0182138
[Epoch 35; Iter   472/ 1097] train: loss: 0.0156564
[Epoch 35; Iter   502/ 1097] train: loss: 0.0170201
[Epoch 35; Iter   532/ 1097] train: loss: 0.0452306
[Epoch 35; Iter   562/ 1097] train: loss: 0.0576696
[Epoch 35; Iter   592/ 1097] train: loss: 0.0158402
[Epoch 35; Iter   622/ 1097] train: loss: 0.0198212
[Epoch 35; Iter   652/ 1097] train: loss: 0.0719789
[Epoch 35; Iter   682/ 1097] train: loss: 0.1116408
[Epoch 35; Iter   712/ 1097] train: loss: 0.0503145
[Epoch 35; Iter   742/ 1097] train: loss: 0.0127180
[Epoch 35; Iter   772/ 1097] train: loss: 0.0077215
[Epoch 35; Iter   802/ 1097] train: loss: 0.0056295
[Epoch 35; Iter   832/ 1097] train: loss: 0.1042962
[Epoch 35; Iter   862/ 1097] train: loss: 0.0135435
[Epoch 35; Iter   892/ 1097] train: loss: 0.1305316
[Epoch 35; Iter   922/ 1097] train: loss: 0.0027211
[Epoch 35; Iter   952/ 1097] train: loss: 0.0048366
[Epoch 35; Iter   982/ 1097] train: loss: 0.0025485
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0022634
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1151919
[Epoch 35; Iter  1072/ 1097] train: loss: 0.1257074
[Epoch 35] ogbg-molhiv: 0.814723 val loss: 1.368575
[Epoch 35] ogbg-molhiv: 0.715074 test loss: 0.387647
[Epoch 36; Iter     5/ 1097] train: loss: 0.0506704
[Epoch 36; Iter    35/ 1097] train: loss: 0.0036845
[Epoch 36; Iter    65/ 1097] train: loss: 0.0024840
[Epoch 36; Iter    95/ 1097] train: loss: 0.0399313
[Epoch 36; Iter   125/ 1097] train: loss: 0.0377174
[Epoch 36; Iter   155/ 1097] train: loss: 0.0028315
[Epoch 36; Iter   185/ 1097] train: loss: 0.0049119
[Epoch 36; Iter   215/ 1097] train: loss: 0.0084454
[Epoch 36; Iter   245/ 1097] train: loss: 0.0126368
[Epoch 36; Iter   275/ 1097] train: loss: 0.0084089
[Epoch 36; Iter   305/ 1097] train: loss: 0.0023069
[Epoch 36; Iter   335/ 1097] train: loss: 0.0029736
[Epoch 36; Iter   365/ 1097] train: loss: 0.1697538
[Epoch 36; Iter   395/ 1097] train: loss: 0.0067105
[Epoch 36; Iter   425/ 1097] train: loss: 0.0045516
[Epoch 36; Iter   455/ 1097] train: loss: 0.0178444
[Epoch 36; Iter   485/ 1097] train: loss: 0.0015198
[Epoch 36; Iter   515/ 1097] train: loss: 0.2270184
[Epoch 36; Iter   545/ 1097] train: loss: 0.0039558
[Epoch 36; Iter   575/ 1097] train: loss: 0.0043331
[Epoch 32; Iter   523/ 1097] train: loss: 0.0086639
[Epoch 32; Iter   553/ 1097] train: loss: 0.0236075
[Epoch 32; Iter   583/ 1097] train: loss: 0.0074886
[Epoch 32; Iter   613/ 1097] train: loss: 0.1195919
[Epoch 32; Iter   643/ 1097] train: loss: 0.0088434
[Epoch 32; Iter   673/ 1097] train: loss: 0.0063089
[Epoch 32; Iter   703/ 1097] train: loss: 0.0054510
[Epoch 32; Iter   733/ 1097] train: loss: 0.0214347
[Epoch 32; Iter   763/ 1097] train: loss: 0.0147364
[Epoch 32; Iter   793/ 1097] train: loss: 0.1418478
[Epoch 32; Iter   823/ 1097] train: loss: 0.0732037
[Epoch 32; Iter   853/ 1097] train: loss: 0.0074412
[Epoch 32; Iter   883/ 1097] train: loss: 0.0248736
[Epoch 32; Iter   913/ 1097] train: loss: 0.0055089
[Epoch 32; Iter   943/ 1097] train: loss: 0.0021718
[Epoch 32; Iter   973/ 1097] train: loss: 0.0028420
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0035853
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0380834
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0385973
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0061998
[Epoch 32] ogbg-molhiv: 0.769113 val loss: 0.410115
[Epoch 32] ogbg-molhiv: 0.708000 test loss: 0.452004
[Epoch 33; Iter    26/ 1097] train: loss: 0.0130127
[Epoch 33; Iter    56/ 1097] train: loss: 0.0241043
[Epoch 33; Iter    86/ 1097] train: loss: 0.0028981
[Epoch 33; Iter   116/ 1097] train: loss: 0.0255284
[Epoch 33; Iter   146/ 1097] train: loss: 0.0058745
[Epoch 33; Iter   176/ 1097] train: loss: 0.0102786
[Epoch 33; Iter   206/ 1097] train: loss: 0.0254131
[Epoch 33; Iter   236/ 1097] train: loss: 0.0320985
[Epoch 33; Iter   266/ 1097] train: loss: 0.0294794
[Epoch 33; Iter   296/ 1097] train: loss: 0.0065608
[Epoch 33; Iter   326/ 1097] train: loss: 0.0094853
[Epoch 33; Iter   356/ 1097] train: loss: 0.0086856
[Epoch 33; Iter   386/ 1097] train: loss: 0.0161139
[Epoch 33; Iter   416/ 1097] train: loss: 0.0601827
[Epoch 33; Iter   446/ 1097] train: loss: 0.0097807
[Epoch 33; Iter   476/ 1097] train: loss: 0.0773916
[Epoch 33; Iter   506/ 1097] train: loss: 0.1211793
[Epoch 33; Iter   536/ 1097] train: loss: 0.0642164
[Epoch 33; Iter   566/ 1097] train: loss: 0.0209891
[Epoch 33; Iter   596/ 1097] train: loss: 0.0272769
[Epoch 33; Iter   626/ 1097] train: loss: 0.0061430
[Epoch 33; Iter   656/ 1097] train: loss: 0.1409106
[Epoch 33; Iter   686/ 1097] train: loss: 0.0110115
[Epoch 33; Iter   716/ 1097] train: loss: 0.0936002
[Epoch 33; Iter   746/ 1097] train: loss: 0.1533411
[Epoch 33; Iter   776/ 1097] train: loss: 0.0032146
[Epoch 33; Iter   806/ 1097] train: loss: 0.0318240
[Epoch 33; Iter   836/ 1097] train: loss: 0.0029795
[Epoch 33; Iter   866/ 1097] train: loss: 0.0122372
[Epoch 33; Iter   896/ 1097] train: loss: 0.0057419
[Epoch 33; Iter   926/ 1097] train: loss: 0.0087947
[Epoch 33; Iter   956/ 1097] train: loss: 0.0057380
[Epoch 33; Iter   986/ 1097] train: loss: 0.0077461
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0062338
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0604513
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0257160
[Epoch 33] ogbg-molhiv: 0.808963 val loss: 0.645357
[Epoch 33] ogbg-molhiv: 0.692086 test loss: 0.477442
[Epoch 34; Iter     9/ 1097] train: loss: 0.0103742
[Epoch 34; Iter    39/ 1097] train: loss: 0.0193322
[Epoch 34; Iter    69/ 1097] train: loss: 0.0050877
[Epoch 34; Iter    99/ 1097] train: loss: 0.0057997
[Epoch 34; Iter   129/ 1097] train: loss: 0.0629876
[Epoch 34; Iter   159/ 1097] train: loss: 0.0043411
[Epoch 34; Iter   189/ 1097] train: loss: 0.0402653
[Epoch 34; Iter   219/ 1097] train: loss: 0.0705486
[Epoch 34; Iter   249/ 1097] train: loss: 0.0070806
[Epoch 34; Iter   279/ 1097] train: loss: 0.0919510
[Epoch 34; Iter   309/ 1097] train: loss: 0.0220920
[Epoch 34; Iter   339/ 1097] train: loss: 0.0183582
[Epoch 34; Iter   369/ 1097] train: loss: 0.0294114
[Epoch 34; Iter   399/ 1097] train: loss: 0.0200014
[Epoch 34; Iter   429/ 1097] train: loss: 0.0085992
[Epoch 34; Iter   459/ 1097] train: loss: 0.0230743
[Epoch 34; Iter   489/ 1097] train: loss: 0.0188011
[Epoch 34; Iter   519/ 1097] train: loss: 0.0144072
[Epoch 34; Iter   549/ 1097] train: loss: 0.0810614
[Epoch 34; Iter   579/ 1097] train: loss: 0.0137394
[Epoch 34; Iter   609/ 1097] train: loss: 0.0026855
[Epoch 34; Iter   639/ 1097] train: loss: 0.0054949
[Epoch 34; Iter   669/ 1097] train: loss: 0.0030931
[Epoch 34; Iter   699/ 1097] train: loss: 0.1048572
[Epoch 34; Iter   729/ 1097] train: loss: 0.1195680
[Epoch 34; Iter   759/ 1097] train: loss: 0.0064819
[Epoch 34; Iter   789/ 1097] train: loss: 0.0146198
[Epoch 34; Iter   819/ 1097] train: loss: 0.0531006
[Epoch 34; Iter   849/ 1097] train: loss: 0.0081329
[Epoch 34; Iter   879/ 1097] train: loss: 0.0127956
[Epoch 34; Iter   909/ 1097] train: loss: 0.0132109
[Epoch 34; Iter   939/ 1097] train: loss: 0.0401787
[Epoch 34; Iter   969/ 1097] train: loss: 0.0499098
[Epoch 34; Iter   999/ 1097] train: loss: 0.0040332
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1798702
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0112342
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0296290
[Epoch 34] ogbg-molhiv: 0.759418 val loss: 0.480763
[Epoch 34] ogbg-molhiv: 0.711775 test loss: 0.560256
[Epoch 35; Iter    22/ 1097] train: loss: 0.0039135
[Epoch 35; Iter    52/ 1097] train: loss: 0.0023702
[Epoch 35; Iter    82/ 1097] train: loss: 0.0258795
[Epoch 35; Iter   112/ 1097] train: loss: 0.0095254
[Epoch 35; Iter   142/ 1097] train: loss: 0.0054213
[Epoch 35; Iter   172/ 1097] train: loss: 0.0438038
[Epoch 35; Iter   202/ 1097] train: loss: 0.0379595
[Epoch 35; Iter   232/ 1097] train: loss: 0.2429338
[Epoch 35; Iter   262/ 1097] train: loss: 0.0365795
[Epoch 35; Iter   292/ 1097] train: loss: 0.0332967
[Epoch 35; Iter   322/ 1097] train: loss: 0.0088133
[Epoch 35; Iter   352/ 1097] train: loss: 0.0078294
[Epoch 35; Iter   382/ 1097] train: loss: 0.0035248
[Epoch 35; Iter   412/ 1097] train: loss: 0.0034219
[Epoch 35; Iter   442/ 1097] train: loss: 0.0330000
[Epoch 35; Iter   472/ 1097] train: loss: 0.0269098
[Epoch 35; Iter   502/ 1097] train: loss: 0.0384436
[Epoch 35; Iter   532/ 1097] train: loss: 0.0100257
[Epoch 35; Iter   562/ 1097] train: loss: 0.0038175
[Epoch 35; Iter   592/ 1097] train: loss: 0.0117904
[Epoch 35; Iter   622/ 1097] train: loss: 0.0047663
[Epoch 35; Iter   652/ 1097] train: loss: 0.0225047
[Epoch 35; Iter   682/ 1097] train: loss: 0.0197494
[Epoch 35; Iter   712/ 1097] train: loss: 0.0082988
[Epoch 35; Iter   742/ 1097] train: loss: 0.0587824
[Epoch 35; Iter   772/ 1097] train: loss: 0.0082403
[Epoch 35; Iter   802/ 1097] train: loss: 0.0038736
[Epoch 35; Iter   832/ 1097] train: loss: 0.0076815
[Epoch 35; Iter   862/ 1097] train: loss: 0.0131034
[Epoch 35; Iter   892/ 1097] train: loss: 0.0066208
[Epoch 35; Iter   922/ 1097] train: loss: 0.0175590
[Epoch 35; Iter   952/ 1097] train: loss: 0.0862060
[Epoch 35; Iter   982/ 1097] train: loss: 0.0048410
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0120897
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0159250
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0395888
[Epoch 35] ogbg-molhiv: 0.810684 val loss: 0.305473
[Epoch 35] ogbg-molhiv: 0.702348 test loss: 0.587720
[Epoch 36; Iter     5/ 1097] train: loss: 0.0058883
[Epoch 36; Iter    35/ 1097] train: loss: 0.0262581
[Epoch 36; Iter    65/ 1097] train: loss: 0.0026115
[Epoch 36; Iter    95/ 1097] train: loss: 0.0054872
[Epoch 36; Iter   125/ 1097] train: loss: 0.0008146
[Epoch 36; Iter   155/ 1097] train: loss: 0.0057112
[Epoch 36; Iter   185/ 1097] train: loss: 0.0087245
[Epoch 36; Iter   215/ 1097] train: loss: 0.0619395
[Epoch 36; Iter   245/ 1097] train: loss: 0.0719918
[Epoch 36; Iter   275/ 1097] train: loss: 0.0077332
[Epoch 36; Iter   305/ 1097] train: loss: 0.0185273
[Epoch 36; Iter   335/ 1097] train: loss: 0.0049087
[Epoch 36; Iter   365/ 1097] train: loss: 0.0055358
[Epoch 36; Iter   395/ 1097] train: loss: 0.0254580
[Epoch 36; Iter   425/ 1097] train: loss: 0.0843294
[Epoch 36; Iter   455/ 1097] train: loss: 0.0652149
[Epoch 36; Iter   485/ 1097] train: loss: 0.0197958
[Epoch 36; Iter   515/ 1097] train: loss: 0.0044277
[Epoch 36; Iter   545/ 1097] train: loss: 0.0060329
[Epoch 36; Iter   575/ 1097] train: loss: 0.0044848
[Epoch 32; Iter   553/ 1097] train: loss: 0.0034903
[Epoch 32; Iter   583/ 1097] train: loss: 0.0165071
[Epoch 32; Iter   613/ 1097] train: loss: 0.0101845
[Epoch 32; Iter   643/ 1097] train: loss: 0.0034907
[Epoch 32; Iter   673/ 1097] train: loss: 0.1811052
[Epoch 32; Iter   703/ 1097] train: loss: 0.0048571
[Epoch 32; Iter   733/ 1097] train: loss: 0.0086386
[Epoch 32; Iter   763/ 1097] train: loss: 0.0216056
[Epoch 32; Iter   793/ 1097] train: loss: 0.0119806
[Epoch 32; Iter   823/ 1097] train: loss: 0.0130682
[Epoch 32; Iter   853/ 1097] train: loss: 0.0516696
[Epoch 32; Iter   883/ 1097] train: loss: 0.0565019
[Epoch 32; Iter   913/ 1097] train: loss: 0.0070072
[Epoch 32; Iter   943/ 1097] train: loss: 0.0041784
[Epoch 32; Iter   973/ 1097] train: loss: 0.0122113
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0091761
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0107371
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0244672
[Epoch 32; Iter  1093/ 1097] train: loss: 0.2050344
[Epoch 32] ogbg-molhiv: 0.698293 val loss: 0.976982
[Epoch 32] ogbg-molhiv: 0.675436 test loss: 0.754627
[Epoch 33; Iter    26/ 1097] train: loss: 0.0033739
[Epoch 33; Iter    56/ 1097] train: loss: 0.1720692
[Epoch 33; Iter    86/ 1097] train: loss: 0.0060929
[Epoch 33; Iter   116/ 1097] train: loss: 0.2608968
[Epoch 33; Iter   146/ 1097] train: loss: 0.0134774
[Epoch 33; Iter   176/ 1097] train: loss: 0.0030319
[Epoch 33; Iter   206/ 1097] train: loss: 0.0077564
[Epoch 33; Iter   236/ 1097] train: loss: 0.0030064
[Epoch 33; Iter   266/ 1097] train: loss: 0.0043564
[Epoch 33; Iter   296/ 1097] train: loss: 0.1332336
[Epoch 33; Iter   326/ 1097] train: loss: 0.0299529
[Epoch 33; Iter   356/ 1097] train: loss: 0.1536565
[Epoch 33; Iter   386/ 1097] train: loss: 0.0166950
[Epoch 33; Iter   416/ 1097] train: loss: 0.0169856
[Epoch 33; Iter   446/ 1097] train: loss: 0.0237823
[Epoch 33; Iter   476/ 1097] train: loss: 0.0555768
[Epoch 33; Iter   506/ 1097] train: loss: 0.1769063
[Epoch 33; Iter   536/ 1097] train: loss: 0.0091809
[Epoch 33; Iter   566/ 1097] train: loss: 0.0092451
[Epoch 33; Iter   596/ 1097] train: loss: 0.0252563
[Epoch 33; Iter   626/ 1097] train: loss: 0.0424038
[Epoch 33; Iter   656/ 1097] train: loss: 0.0071867
[Epoch 33; Iter   686/ 1097] train: loss: 0.0096513
[Epoch 33; Iter   716/ 1097] train: loss: 0.0203525
[Epoch 33; Iter   746/ 1097] train: loss: 0.0035679
[Epoch 33; Iter   776/ 1097] train: loss: 0.0986329
[Epoch 33; Iter   806/ 1097] train: loss: 0.0451381
[Epoch 33; Iter   836/ 1097] train: loss: 0.0297639
[Epoch 33; Iter   866/ 1097] train: loss: 0.0252791
[Epoch 33; Iter   896/ 1097] train: loss: 0.0484096
[Epoch 33; Iter   926/ 1097] train: loss: 0.0038589
[Epoch 33; Iter   956/ 1097] train: loss: 0.0257787
[Epoch 33; Iter   986/ 1097] train: loss: 0.0018476
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0082983
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0186278
[Epoch 33; Iter  1076/ 1097] train: loss: 0.3473623
[Epoch 33] ogbg-molhiv: 0.704206 val loss: 0.248460
[Epoch 33] ogbg-molhiv: 0.723919 test loss: 0.240504
[Epoch 34; Iter     9/ 1097] train: loss: 0.0026190
[Epoch 34; Iter    39/ 1097] train: loss: 0.0102026
[Epoch 34; Iter    69/ 1097] train: loss: 0.0106403
[Epoch 34; Iter    99/ 1097] train: loss: 0.0778259
[Epoch 34; Iter   129/ 1097] train: loss: 0.2964227
[Epoch 34; Iter   159/ 1097] train: loss: 0.0064134
[Epoch 34; Iter   189/ 1097] train: loss: 0.0276174
[Epoch 34; Iter   219/ 1097] train: loss: 0.0039344
[Epoch 34; Iter   249/ 1097] train: loss: 0.0340373
[Epoch 34; Iter   279/ 1097] train: loss: 0.0076547
[Epoch 34; Iter   309/ 1097] train: loss: 0.0615048
[Epoch 34; Iter   339/ 1097] train: loss: 0.0184536
[Epoch 34; Iter   369/ 1097] train: loss: 0.0504929
[Epoch 34; Iter   399/ 1097] train: loss: 0.0122128
[Epoch 34; Iter   429/ 1097] train: loss: 0.0056755
[Epoch 34; Iter   459/ 1097] train: loss: 0.0284725
[Epoch 34; Iter   489/ 1097] train: loss: 0.0035441
[Epoch 34; Iter   519/ 1097] train: loss: 0.0074927
[Epoch 34; Iter   549/ 1097] train: loss: 0.0058394
[Epoch 34; Iter   579/ 1097] train: loss: 0.0109960
[Epoch 34; Iter   609/ 1097] train: loss: 0.0090480
[Epoch 34; Iter   639/ 1097] train: loss: 0.0060766
[Epoch 34; Iter   669/ 1097] train: loss: 0.0086724
[Epoch 34; Iter   699/ 1097] train: loss: 0.0153832
[Epoch 34; Iter   729/ 1097] train: loss: 0.2596069
[Epoch 34; Iter   759/ 1097] train: loss: 0.0014048
[Epoch 34; Iter   789/ 1097] train: loss: 0.0228467
[Epoch 34; Iter   819/ 1097] train: loss: 0.0616174
[Epoch 34; Iter   849/ 1097] train: loss: 0.0819704
[Epoch 34; Iter   879/ 1097] train: loss: 0.0321516
[Epoch 34; Iter   909/ 1097] train: loss: 0.0084963
[Epoch 34; Iter   939/ 1097] train: loss: 0.1357429
[Epoch 34; Iter   969/ 1097] train: loss: 0.0186736
[Epoch 34; Iter   999/ 1097] train: loss: 0.0465417
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0091079
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0031302
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0022907
[Epoch 34] ogbg-molhiv: 0.678069 val loss: 1.664511
[Epoch 34] ogbg-molhiv: 0.721571 test loss: 0.895912
[Epoch 35; Iter    22/ 1097] train: loss: 0.0019626
[Epoch 35; Iter    52/ 1097] train: loss: 0.0014242
[Epoch 35; Iter    82/ 1097] train: loss: 0.0230867
[Epoch 35; Iter   112/ 1097] train: loss: 0.0080058
[Epoch 35; Iter   142/ 1097] train: loss: 0.0037454
[Epoch 35; Iter   172/ 1097] train: loss: 0.0042274
[Epoch 35; Iter   202/ 1097] train: loss: 0.0043911
[Epoch 35; Iter   232/ 1097] train: loss: 0.0119383
[Epoch 35; Iter   262/ 1097] train: loss: 0.0027582
[Epoch 35; Iter   292/ 1097] train: loss: 0.0565731
[Epoch 35; Iter   322/ 1097] train: loss: 0.0887594
[Epoch 35; Iter   352/ 1097] train: loss: 0.0310247
[Epoch 35; Iter   382/ 1097] train: loss: 0.0304169
[Epoch 35; Iter   412/ 1097] train: loss: 0.1387691
[Epoch 35; Iter   442/ 1097] train: loss: 0.0242533
[Epoch 35; Iter   472/ 1097] train: loss: 0.0031635
[Epoch 35; Iter   502/ 1097] train: loss: 0.0257780
[Epoch 35; Iter   532/ 1097] train: loss: 0.0609414
[Epoch 35; Iter   562/ 1097] train: loss: 0.0479281
[Epoch 35; Iter   592/ 1097] train: loss: 0.0086396
[Epoch 35; Iter   622/ 1097] train: loss: 0.0305856
[Epoch 35; Iter   652/ 1097] train: loss: 0.1119201
[Epoch 35; Iter   682/ 1097] train: loss: 0.0078374
[Epoch 35; Iter   712/ 1097] train: loss: 0.1387663
[Epoch 35; Iter   742/ 1097] train: loss: 0.0662387
[Epoch 35; Iter   772/ 1097] train: loss: 0.0161197
[Epoch 35; Iter   802/ 1097] train: loss: 0.0243921
[Epoch 35; Iter   832/ 1097] train: loss: 0.0208303
[Epoch 35; Iter   862/ 1097] train: loss: 0.0049592
[Epoch 35; Iter   892/ 1097] train: loss: 0.0800404
[Epoch 35; Iter   922/ 1097] train: loss: 0.0263597
[Epoch 35; Iter   952/ 1097] train: loss: 0.0321240
[Epoch 35; Iter   982/ 1097] train: loss: 0.0659421
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0061305
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0653813
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0054933
[Epoch 35] ogbg-molhiv: 0.670467 val loss: 3.406083
[Epoch 35] ogbg-molhiv: 0.646548 test loss: 1.301552
[Epoch 36; Iter     5/ 1097] train: loss: 0.0687146
[Epoch 36; Iter    35/ 1097] train: loss: 0.0053748
[Epoch 36; Iter    65/ 1097] train: loss: 0.0079009
[Epoch 36; Iter    95/ 1097] train: loss: 0.0013222
[Epoch 36; Iter   125/ 1097] train: loss: 0.0961367
[Epoch 36; Iter   155/ 1097] train: loss: 0.0040229
[Epoch 36; Iter   185/ 1097] train: loss: 0.0515446
[Epoch 36; Iter   215/ 1097] train: loss: 0.0092422
[Epoch 36; Iter   245/ 1097] train: loss: 0.0364216
[Epoch 36; Iter   275/ 1097] train: loss: 0.0818050
[Epoch 36; Iter   305/ 1097] train: loss: 0.0567838
[Epoch 36; Iter   335/ 1097] train: loss: 0.0125209
[Epoch 36; Iter   365/ 1097] train: loss: 0.0012478
[Epoch 36; Iter   395/ 1097] train: loss: 0.0048829
[Epoch 36; Iter   425/ 1097] train: loss: 0.0009856
[Epoch 36; Iter   455/ 1097] train: loss: 0.0123006
[Epoch 36; Iter   485/ 1097] train: loss: 0.0271330
[Epoch 36; Iter   515/ 1097] train: loss: 0.0052975
[Epoch 36; Iter   545/ 1097] train: loss: 0.0236752
[Epoch 36; Iter   575/ 1097] train: loss: 0.0094609
[Epoch 36; Iter   605/ 1097] train: loss: 0.0082830
[Epoch 32; Iter   523/ 1097] train: loss: 0.0368841
[Epoch 32; Iter   553/ 1097] train: loss: 0.0279256
[Epoch 32; Iter   583/ 1097] train: loss: 0.0171294
[Epoch 32; Iter   613/ 1097] train: loss: 0.0155407
[Epoch 32; Iter   643/ 1097] train: loss: 0.0117443
[Epoch 32; Iter   673/ 1097] train: loss: 0.1425776
[Epoch 32; Iter   703/ 1097] train: loss: 0.0040072
[Epoch 32; Iter   733/ 1097] train: loss: 0.0054231
[Epoch 32; Iter   763/ 1097] train: loss: 0.0668095
[Epoch 32; Iter   793/ 1097] train: loss: 0.0191771
[Epoch 32; Iter   823/ 1097] train: loss: 0.0655981
[Epoch 32; Iter   853/ 1097] train: loss: 0.0126857
[Epoch 32; Iter   883/ 1097] train: loss: 0.0063424
[Epoch 32; Iter   913/ 1097] train: loss: 0.0387316
[Epoch 32; Iter   943/ 1097] train: loss: 0.2028773
[Epoch 32; Iter   973/ 1097] train: loss: 0.0245685
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0103815
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0100940
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1015565
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0141134
[Epoch 32] ogbg-molhiv: 0.801829 val loss: 0.152660
[Epoch 32] ogbg-molhiv: 0.706593 test loss: 0.290988
[Epoch 33; Iter    26/ 1097] train: loss: 0.0160472
[Epoch 33; Iter    56/ 1097] train: loss: 0.1593152
[Epoch 33; Iter    86/ 1097] train: loss: 0.0065273
[Epoch 33; Iter   116/ 1097] train: loss: 0.1890739
[Epoch 33; Iter   146/ 1097] train: loss: 0.0187835
[Epoch 33; Iter   176/ 1097] train: loss: 0.0034440
[Epoch 33; Iter   206/ 1097] train: loss: 0.0108680
[Epoch 33; Iter   236/ 1097] train: loss: 0.1046454
[Epoch 33; Iter   266/ 1097] train: loss: 0.0236395
[Epoch 33; Iter   296/ 1097] train: loss: 0.0620523
[Epoch 33; Iter   326/ 1097] train: loss: 0.0162209
[Epoch 33; Iter   356/ 1097] train: loss: 0.0278620
[Epoch 33; Iter   386/ 1097] train: loss: 0.0431118
[Epoch 33; Iter   416/ 1097] train: loss: 0.0047620
[Epoch 33; Iter   446/ 1097] train: loss: 0.0564966
[Epoch 33; Iter   476/ 1097] train: loss: 0.0541242
[Epoch 33; Iter   506/ 1097] train: loss: 0.0783426
[Epoch 33; Iter   536/ 1097] train: loss: 0.0209500
[Epoch 33; Iter   566/ 1097] train: loss: 0.0343122
[Epoch 33; Iter   596/ 1097] train: loss: 0.1141644
[Epoch 33; Iter   626/ 1097] train: loss: 0.0101367
[Epoch 33; Iter   656/ 1097] train: loss: 0.0063776
[Epoch 33; Iter   686/ 1097] train: loss: 0.0285570
[Epoch 33; Iter   716/ 1097] train: loss: 0.0081172
[Epoch 33; Iter   746/ 1097] train: loss: 0.0122306
[Epoch 33; Iter   776/ 1097] train: loss: 0.0620524
[Epoch 33; Iter   806/ 1097] train: loss: 0.1274181
[Epoch 33; Iter   836/ 1097] train: loss: 0.0312029
[Epoch 33; Iter   866/ 1097] train: loss: 0.0250736
[Epoch 33; Iter   896/ 1097] train: loss: 0.0635717
[Epoch 33; Iter   926/ 1097] train: loss: 0.0759239
[Epoch 33; Iter   956/ 1097] train: loss: 0.0197471
[Epoch 33; Iter   986/ 1097] train: loss: 0.0049034
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0526898
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0437893
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2666727
[Epoch 33] ogbg-molhiv: 0.788020 val loss: 0.141654
[Epoch 33] ogbg-molhiv: 0.705776 test loss: 0.299914
[Epoch 34; Iter     9/ 1097] train: loss: 0.0085887
[Epoch 34; Iter    39/ 1097] train: loss: 0.0089630
[Epoch 34; Iter    69/ 1097] train: loss: 0.0351408
[Epoch 34; Iter    99/ 1097] train: loss: 0.0240890
[Epoch 34; Iter   129/ 1097] train: loss: 0.0323853
[Epoch 34; Iter   159/ 1097] train: loss: 0.0056615
[Epoch 34; Iter   189/ 1097] train: loss: 0.0863482
[Epoch 34; Iter   219/ 1097] train: loss: 0.0082392
[Epoch 34; Iter   249/ 1097] train: loss: 0.0116838
[Epoch 34; Iter   279/ 1097] train: loss: 0.1156235
[Epoch 34; Iter   309/ 1097] train: loss: 0.0180322
[Epoch 34; Iter   339/ 1097] train: loss: 0.0305768
[Epoch 34; Iter   369/ 1097] train: loss: 0.0702545
[Epoch 34; Iter   399/ 1097] train: loss: 0.0236718
[Epoch 34; Iter   429/ 1097] train: loss: 0.0067238
[Epoch 34; Iter   459/ 1097] train: loss: 0.1140791
[Epoch 34; Iter   489/ 1097] train: loss: 0.0131136
[Epoch 34; Iter   519/ 1097] train: loss: 0.0033918
[Epoch 34; Iter   549/ 1097] train: loss: 0.0158660
[Epoch 34; Iter   579/ 1097] train: loss: 0.1140787
[Epoch 34; Iter   609/ 1097] train: loss: 0.0194738
[Epoch 34; Iter   639/ 1097] train: loss: 0.0315727
[Epoch 34; Iter   669/ 1097] train: loss: 0.0046404
[Epoch 34; Iter   699/ 1097] train: loss: 0.0074134
[Epoch 34; Iter   729/ 1097] train: loss: 0.0619870
[Epoch 34; Iter   759/ 1097] train: loss: 0.0051928
[Epoch 34; Iter   789/ 1097] train: loss: 0.0418986
[Epoch 34; Iter   819/ 1097] train: loss: 0.2400855
[Epoch 34; Iter   849/ 1097] train: loss: 0.0109892
[Epoch 34; Iter   879/ 1097] train: loss: 0.0157855
[Epoch 34; Iter   909/ 1097] train: loss: 0.0115472
[Epoch 34; Iter   939/ 1097] train: loss: 0.2308085
[Epoch 34; Iter   969/ 1097] train: loss: 0.0267813
[Epoch 34; Iter   999/ 1097] train: loss: 0.0102550
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0428038
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0243018
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0067073
[Epoch 34] ogbg-molhiv: 0.791596 val loss: 0.287354
[Epoch 34] ogbg-molhiv: 0.691218 test loss: 0.306153
[Epoch 35; Iter    22/ 1097] train: loss: 0.0135646
[Epoch 35; Iter    52/ 1097] train: loss: 0.0261973
[Epoch 35; Iter    82/ 1097] train: loss: 0.0378544
[Epoch 35; Iter   112/ 1097] train: loss: 0.1801746
[Epoch 35; Iter   142/ 1097] train: loss: 0.0077396
[Epoch 35; Iter   172/ 1097] train: loss: 0.0026381
[Epoch 35; Iter   202/ 1097] train: loss: 0.0134786
[Epoch 35; Iter   232/ 1097] train: loss: 0.0884003
[Epoch 35; Iter   262/ 1097] train: loss: 0.0065588
[Epoch 35; Iter   292/ 1097] train: loss: 0.0135370
[Epoch 35; Iter   322/ 1097] train: loss: 0.0142390
[Epoch 35; Iter   352/ 1097] train: loss: 0.2157358
[Epoch 35; Iter   382/ 1097] train: loss: 0.1671442
[Epoch 35; Iter   412/ 1097] train: loss: 0.0241431
[Epoch 35; Iter   442/ 1097] train: loss: 0.0195608
[Epoch 35; Iter   472/ 1097] train: loss: 0.0905838
[Epoch 35; Iter   502/ 1097] train: loss: 0.0108141
[Epoch 35; Iter   532/ 1097] train: loss: 0.0121361
[Epoch 35; Iter   562/ 1097] train: loss: 0.0188351
[Epoch 35; Iter   592/ 1097] train: loss: 0.0268609
[Epoch 35; Iter   622/ 1097] train: loss: 0.0406884
[Epoch 35; Iter   652/ 1097] train: loss: 0.0737050
[Epoch 35; Iter   682/ 1097] train: loss: 0.0383312
[Epoch 35; Iter   712/ 1097] train: loss: 0.0376948
[Epoch 35; Iter   742/ 1097] train: loss: 0.0971044
[Epoch 35; Iter   772/ 1097] train: loss: 0.0086837
[Epoch 35; Iter   802/ 1097] train: loss: 0.0057907
[Epoch 35; Iter   832/ 1097] train: loss: 0.0413793
[Epoch 35; Iter   862/ 1097] train: loss: 0.0496939
[Epoch 35; Iter   892/ 1097] train: loss: 0.0105491
[Epoch 35; Iter   922/ 1097] train: loss: 0.0054983
[Epoch 35; Iter   952/ 1097] train: loss: 0.1039717
[Epoch 35; Iter   982/ 1097] train: loss: 0.1192647
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0935446
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0943529
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0264437
[Epoch 35] ogbg-molhiv: 0.756393 val loss: 0.395214
[Epoch 35] ogbg-molhiv: 0.699554 test loss: 0.443764
[Epoch 36; Iter     5/ 1097] train: loss: 0.0170543
[Epoch 36; Iter    35/ 1097] train: loss: 0.0109885
[Epoch 36; Iter    65/ 1097] train: loss: 0.0042134
[Epoch 36; Iter    95/ 1097] train: loss: 0.0079094
[Epoch 36; Iter   125/ 1097] train: loss: 0.0076276
[Epoch 36; Iter   155/ 1097] train: loss: 0.1766905
[Epoch 36; Iter   185/ 1097] train: loss: 0.0197092
[Epoch 36; Iter   215/ 1097] train: loss: 0.0226059
[Epoch 36; Iter   245/ 1097] train: loss: 0.0105018
[Epoch 36; Iter   275/ 1097] train: loss: 0.0269367
[Epoch 36; Iter   305/ 1097] train: loss: 0.0233738
[Epoch 36; Iter   335/ 1097] train: loss: 0.0579348
[Epoch 36; Iter   365/ 1097] train: loss: 0.0745433
[Epoch 36; Iter   395/ 1097] train: loss: 0.0358406
[Epoch 36; Iter   425/ 1097] train: loss: 0.0073656
[Epoch 36; Iter   455/ 1097] train: loss: 0.0198034
[Epoch 36; Iter   485/ 1097] train: loss: 0.0072618
[Epoch 36; Iter   515/ 1097] train: loss: 0.0067523
[Epoch 36; Iter   545/ 1097] train: loss: 0.0661353
[Epoch 36; Iter   575/ 1097] train: loss: 0.0191089
[Epoch 32; Iter   553/ 1097] train: loss: 0.0947861
[Epoch 32; Iter   583/ 1097] train: loss: 0.0304893
[Epoch 32; Iter   613/ 1097] train: loss: 0.0306146
[Epoch 32; Iter   643/ 1097] train: loss: 0.0036774
[Epoch 32; Iter   673/ 1097] train: loss: 0.0199047
[Epoch 32; Iter   703/ 1097] train: loss: 0.0829904
[Epoch 32; Iter   733/ 1097] train: loss: 0.0073353
[Epoch 32; Iter   763/ 1097] train: loss: 0.0082874
[Epoch 32; Iter   793/ 1097] train: loss: 0.0381854
[Epoch 32; Iter   823/ 1097] train: loss: 0.1130116
[Epoch 32; Iter   853/ 1097] train: loss: 0.0030526
[Epoch 32; Iter   883/ 1097] train: loss: 0.0023261
[Epoch 32; Iter   913/ 1097] train: loss: 0.0107886
[Epoch 32; Iter   943/ 1097] train: loss: 0.0034010
[Epoch 32; Iter   973/ 1097] train: loss: 0.0357282
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0085416
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0190529
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0280954
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0054301
[Epoch 32] ogbg-molhiv: 0.749051 val loss: 0.124738
[Epoch 32] ogbg-molhiv: 0.686551 test loss: 0.198454
[Epoch 33; Iter    26/ 1097] train: loss: 0.0148555
[Epoch 33; Iter    56/ 1097] train: loss: 0.0173358
[Epoch 33; Iter    86/ 1097] train: loss: 0.0077311
[Epoch 33; Iter   116/ 1097] train: loss: 0.0058718
[Epoch 33; Iter   146/ 1097] train: loss: 0.0046922
[Epoch 33; Iter   176/ 1097] train: loss: 0.0263957
[Epoch 33; Iter   206/ 1097] train: loss: 0.0844271
[Epoch 33; Iter   236/ 1097] train: loss: 0.0059256
[Epoch 33; Iter   266/ 1097] train: loss: 0.0172372
[Epoch 33; Iter   296/ 1097] train: loss: 0.0015342
[Epoch 33; Iter   326/ 1097] train: loss: 0.0045771
[Epoch 33; Iter   356/ 1097] train: loss: 0.0032713
[Epoch 33; Iter   386/ 1097] train: loss: 0.1064430
[Epoch 33; Iter   416/ 1097] train: loss: 0.0249936
[Epoch 33; Iter   446/ 1097] train: loss: 0.0065378
[Epoch 33; Iter   476/ 1097] train: loss: 0.0559911
[Epoch 33; Iter   506/ 1097] train: loss: 0.0075856
[Epoch 33; Iter   536/ 1097] train: loss: 0.0207274
[Epoch 33; Iter   566/ 1097] train: loss: 0.0066474
[Epoch 33; Iter   596/ 1097] train: loss: 0.0102572
[Epoch 33; Iter   626/ 1097] train: loss: 0.0109148
[Epoch 33; Iter   656/ 1097] train: loss: 0.0058888
[Epoch 33; Iter   686/ 1097] train: loss: 0.0086638
[Epoch 33; Iter   716/ 1097] train: loss: 0.0244613
[Epoch 33; Iter   746/ 1097] train: loss: 0.0159456
[Epoch 33; Iter   776/ 1097] train: loss: 0.0070583
[Epoch 33; Iter   806/ 1097] train: loss: 0.0091046
[Epoch 33; Iter   836/ 1097] train: loss: 0.0688570
[Epoch 33; Iter   866/ 1097] train: loss: 0.0462523
[Epoch 33; Iter   896/ 1097] train: loss: 0.0765014
[Epoch 33; Iter   926/ 1097] train: loss: 0.0676871
[Epoch 33; Iter   956/ 1097] train: loss: 0.0021684
[Epoch 33; Iter   986/ 1097] train: loss: 0.0779614
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0078600
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1034420
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0109395
[Epoch 33] ogbg-molhiv: 0.747244 val loss: 0.261778
[Epoch 33] ogbg-molhiv: 0.697551 test loss: 0.200980
[Epoch 34; Iter     9/ 1097] train: loss: 0.0056336
[Epoch 34; Iter    39/ 1097] train: loss: 0.0141510
[Epoch 34; Iter    69/ 1097] train: loss: 0.0044679
[Epoch 34; Iter    99/ 1097] train: loss: 0.0027917
[Epoch 34; Iter   129/ 1097] train: loss: 0.0975815
[Epoch 34; Iter   159/ 1097] train: loss: 0.0052523
[Epoch 34; Iter   189/ 1097] train: loss: 0.0160364
[Epoch 34; Iter   219/ 1097] train: loss: 0.0217790
[Epoch 34; Iter   249/ 1097] train: loss: 0.0152071
[Epoch 34; Iter   279/ 1097] train: loss: 0.0954293
[Epoch 34; Iter   309/ 1097] train: loss: 0.0109899
[Epoch 34; Iter   339/ 1097] train: loss: 0.0050606
[Epoch 34; Iter   369/ 1097] train: loss: 0.0135905
[Epoch 34; Iter   399/ 1097] train: loss: 0.0156380
[Epoch 34; Iter   429/ 1097] train: loss: 0.0014307
[Epoch 34; Iter   459/ 1097] train: loss: 0.1169314
[Epoch 34; Iter   489/ 1097] train: loss: 0.0747572
[Epoch 34; Iter   519/ 1097] train: loss: 0.0090936
[Epoch 34; Iter   549/ 1097] train: loss: 0.0199504
[Epoch 34; Iter   579/ 1097] train: loss: 0.0285575
[Epoch 34; Iter   609/ 1097] train: loss: 0.0222688
[Epoch 34; Iter   639/ 1097] train: loss: 0.0025589
[Epoch 34; Iter   669/ 1097] train: loss: 0.0217240
[Epoch 34; Iter   699/ 1097] train: loss: 0.2249827
[Epoch 34; Iter   729/ 1097] train: loss: 0.0426486
[Epoch 34; Iter   759/ 1097] train: loss: 0.0018644
[Epoch 34; Iter   789/ 1097] train: loss: 0.0375919
[Epoch 34; Iter   819/ 1097] train: loss: 0.0068804
[Epoch 34; Iter   849/ 1097] train: loss: 0.0038772
[Epoch 34; Iter   879/ 1097] train: loss: 0.0036507
[Epoch 34; Iter   909/ 1097] train: loss: 0.0132730
[Epoch 34; Iter   939/ 1097] train: loss: 0.0099550
[Epoch 34; Iter   969/ 1097] train: loss: 0.0047111
[Epoch 34; Iter   999/ 1097] train: loss: 0.0018071
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0606431
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0033564
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0150815
[Epoch 34] ogbg-molhiv: 0.756295 val loss: 0.174429
[Epoch 34] ogbg-molhiv: 0.710108 test loss: 0.211573
[Epoch 35; Iter    22/ 1097] train: loss: 0.0024100
[Epoch 35; Iter    52/ 1097] train: loss: 0.0042348
[Epoch 35; Iter    82/ 1097] train: loss: 0.0139235
[Epoch 35; Iter   112/ 1097] train: loss: 0.0149192
[Epoch 35; Iter   142/ 1097] train: loss: 0.0066127
[Epoch 35; Iter   172/ 1097] train: loss: 0.0020449
[Epoch 35; Iter   202/ 1097] train: loss: 0.0260240
[Epoch 35; Iter   232/ 1097] train: loss: 0.0270644
[Epoch 35; Iter   262/ 1097] train: loss: 0.0081436
[Epoch 35; Iter   292/ 1097] train: loss: 0.0301982
[Epoch 35; Iter   322/ 1097] train: loss: 0.0296551
[Epoch 35; Iter   352/ 1097] train: loss: 0.0123598
[Epoch 35; Iter   382/ 1097] train: loss: 0.0008453
[Epoch 35; Iter   412/ 1097] train: loss: 0.0154846
[Epoch 35; Iter   442/ 1097] train: loss: 0.0036720
[Epoch 35; Iter   472/ 1097] train: loss: 0.0057133
[Epoch 35; Iter   502/ 1097] train: loss: 0.0195511
[Epoch 35; Iter   532/ 1097] train: loss: 0.0009987
[Epoch 35; Iter   562/ 1097] train: loss: 0.0324106
[Epoch 35; Iter   592/ 1097] train: loss: 0.0223827
[Epoch 35; Iter   622/ 1097] train: loss: 0.0036349
[Epoch 35; Iter   652/ 1097] train: loss: 0.0274694
[Epoch 35; Iter   682/ 1097] train: loss: 0.0033407
[Epoch 35; Iter   712/ 1097] train: loss: 0.0174529
[Epoch 35; Iter   742/ 1097] train: loss: 0.0021113
[Epoch 35; Iter   772/ 1097] train: loss: 0.0547423
[Epoch 35; Iter   802/ 1097] train: loss: 0.0596401
[Epoch 35; Iter   832/ 1097] train: loss: 0.0307753
[Epoch 35; Iter   862/ 1097] train: loss: 0.0124521
[Epoch 35; Iter   892/ 1097] train: loss: 0.0055330
[Epoch 35; Iter   922/ 1097] train: loss: 0.1394799
[Epoch 35; Iter   952/ 1097] train: loss: 0.0029084
[Epoch 35; Iter   982/ 1097] train: loss: 0.0181317
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0022294
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0022163
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0035256
[Epoch 35] ogbg-molhiv: 0.748564 val loss: 0.263697
[Epoch 35] ogbg-molhiv: 0.715923 test loss: 0.222694
[Epoch 36; Iter     5/ 1097] train: loss: 0.0044794
[Epoch 36; Iter    35/ 1097] train: loss: 0.0214212
[Epoch 36; Iter    65/ 1097] train: loss: 0.0045073
[Epoch 36; Iter    95/ 1097] train: loss: 0.0558901
[Epoch 36; Iter   125/ 1097] train: loss: 0.0036129
[Epoch 36; Iter   155/ 1097] train: loss: 0.0020133
[Epoch 36; Iter   185/ 1097] train: loss: 0.0040153
[Epoch 36; Iter   215/ 1097] train: loss: 0.3221253
[Epoch 36; Iter   245/ 1097] train: loss: 0.0012908
[Epoch 36; Iter   275/ 1097] train: loss: 0.0130097
[Epoch 36; Iter   305/ 1097] train: loss: 0.0678199
[Epoch 36; Iter   335/ 1097] train: loss: 0.0881338
[Epoch 36; Iter   365/ 1097] train: loss: 0.0054506
[Epoch 36; Iter   395/ 1097] train: loss: 0.0060079
[Epoch 36; Iter   425/ 1097] train: loss: 0.0293984
[Epoch 36; Iter   455/ 1097] train: loss: 0.0619459
[Epoch 36; Iter   485/ 1097] train: loss: 0.0064616
[Epoch 36; Iter   515/ 1097] train: loss: 0.0077907
[Epoch 36; Iter   545/ 1097] train: loss: 0.0016048
[Epoch 36; Iter   575/ 1097] train: loss: 0.0028994
[Epoch 36; Iter   605/ 1097] train: loss: 0.0315061
[Epoch 32; Iter   553/ 1097] train: loss: 0.0070717
[Epoch 32; Iter   583/ 1097] train: loss: 0.2018417
[Epoch 32; Iter   613/ 1097] train: loss: 0.0320083
[Epoch 32; Iter   643/ 1097] train: loss: 0.1690434
[Epoch 32; Iter   673/ 1097] train: loss: 0.2349572
[Epoch 32; Iter   703/ 1097] train: loss: 0.0486189
[Epoch 32; Iter   733/ 1097] train: loss: 0.0213310
[Epoch 32; Iter   763/ 1097] train: loss: 0.0081693
[Epoch 32; Iter   793/ 1097] train: loss: 0.0572953
[Epoch 32; Iter   823/ 1097] train: loss: 0.1273416
[Epoch 32; Iter   853/ 1097] train: loss: 0.0378154
[Epoch 32; Iter   883/ 1097] train: loss: 0.0130146
[Epoch 32; Iter   913/ 1097] train: loss: 0.1076242
[Epoch 32; Iter   943/ 1097] train: loss: 0.0141944
[Epoch 32; Iter   973/ 1097] train: loss: 0.0549012
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1579705
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0255704
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0179151
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0104310
[Epoch 32] ogbg-molhiv: 0.691946 val loss: 0.117395
[Epoch 32] ogbg-molhiv: 0.716847 test loss: 0.168958
[Epoch 33; Iter    26/ 1097] train: loss: 0.0099552
[Epoch 33; Iter    56/ 1097] train: loss: 0.0120954
[Epoch 33; Iter    86/ 1097] train: loss: 0.0154254
[Epoch 33; Iter   116/ 1097] train: loss: 0.1484921
[Epoch 33; Iter   146/ 1097] train: loss: 0.0185244
[Epoch 33; Iter   176/ 1097] train: loss: 0.0161599
[Epoch 33; Iter   206/ 1097] train: loss: 0.0147226
[Epoch 33; Iter   236/ 1097] train: loss: 0.1015298
[Epoch 33; Iter   266/ 1097] train: loss: 0.0084716
[Epoch 33; Iter   296/ 1097] train: loss: 0.1180381
[Epoch 33; Iter   326/ 1097] train: loss: 0.0369482
[Epoch 33; Iter   356/ 1097] train: loss: 0.2047831
[Epoch 33; Iter   386/ 1097] train: loss: 0.0316304
[Epoch 33; Iter   416/ 1097] train: loss: 0.0053450
[Epoch 33; Iter   446/ 1097] train: loss: 0.0488206
[Epoch 33; Iter   476/ 1097] train: loss: 0.0163021
[Epoch 33; Iter   506/ 1097] train: loss: 0.0338953
[Epoch 33; Iter   536/ 1097] train: loss: 0.0280358
[Epoch 33; Iter   566/ 1097] train: loss: 0.0273542
[Epoch 33; Iter   596/ 1097] train: loss: 0.0238596
[Epoch 33; Iter   626/ 1097] train: loss: 0.0189745
[Epoch 33; Iter   656/ 1097] train: loss: 0.0145435
[Epoch 33; Iter   686/ 1097] train: loss: 0.1124138
[Epoch 33; Iter   716/ 1097] train: loss: 0.2000514
[Epoch 33; Iter   746/ 1097] train: loss: 0.0479444
[Epoch 33; Iter   776/ 1097] train: loss: 0.2646970
[Epoch 33; Iter   806/ 1097] train: loss: 0.0439663
[Epoch 33; Iter   836/ 1097] train: loss: 0.0677428
[Epoch 33; Iter   866/ 1097] train: loss: 0.1072997
[Epoch 33; Iter   896/ 1097] train: loss: 0.0525941
[Epoch 33; Iter   926/ 1097] train: loss: 0.0308029
[Epoch 33; Iter   956/ 1097] train: loss: 0.0097415
[Epoch 33; Iter   986/ 1097] train: loss: 0.0805334
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0388541
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0881731
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0935740
[Epoch 33] ogbg-molhiv: 0.764232 val loss: 0.108556
[Epoch 33] ogbg-molhiv: 0.763313 test loss: 0.162109
[Epoch 34; Iter     9/ 1097] train: loss: 0.0144286
[Epoch 34; Iter    39/ 1097] train: loss: 0.0513159
[Epoch 34; Iter    69/ 1097] train: loss: 0.0215312
[Epoch 34; Iter    99/ 1097] train: loss: 0.0339403
[Epoch 34; Iter   129/ 1097] train: loss: 0.0770596
[Epoch 34; Iter   159/ 1097] train: loss: 0.0153492
[Epoch 34; Iter   189/ 1097] train: loss: 0.0076729
[Epoch 34; Iter   219/ 1097] train: loss: 0.0466529
[Epoch 34; Iter   249/ 1097] train: loss: 0.0458793
[Epoch 34; Iter   279/ 1097] train: loss: 0.0603956
[Epoch 34; Iter   309/ 1097] train: loss: 0.0205364
[Epoch 34; Iter   339/ 1097] train: loss: 0.0884201
[Epoch 34; Iter   369/ 1097] train: loss: 0.0133830
[Epoch 34; Iter   399/ 1097] train: loss: 0.0084606
[Epoch 34; Iter   429/ 1097] train: loss: 0.0121525
[Epoch 34; Iter   459/ 1097] train: loss: 0.0127601
[Epoch 34; Iter   489/ 1097] train: loss: 0.0129113
[Epoch 34; Iter   519/ 1097] train: loss: 0.0100888
[Epoch 34; Iter   549/ 1097] train: loss: 0.0061396
[Epoch 34; Iter   579/ 1097] train: loss: 0.1017525
[Epoch 34; Iter   609/ 1097] train: loss: 0.0183701
[Epoch 34; Iter   639/ 1097] train: loss: 0.0054086
[Epoch 34; Iter   669/ 1097] train: loss: 0.0073305
[Epoch 34; Iter   699/ 1097] train: loss: 0.1283988
[Epoch 34; Iter   729/ 1097] train: loss: 0.0132190
[Epoch 34; Iter   759/ 1097] train: loss: 0.2889188
[Epoch 34; Iter   789/ 1097] train: loss: 0.0084236
[Epoch 34; Iter   819/ 1097] train: loss: 0.0250463
[Epoch 34; Iter   849/ 1097] train: loss: 0.1949125
[Epoch 34; Iter   879/ 1097] train: loss: 0.0106235
[Epoch 34; Iter   909/ 1097] train: loss: 0.0140640
[Epoch 34; Iter   939/ 1097] train: loss: 0.0076136
[Epoch 34; Iter   969/ 1097] train: loss: 0.0310351
[Epoch 34; Iter   999/ 1097] train: loss: 0.3240645
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0388512
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1496296
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0514014
[Epoch 34] ogbg-molhiv: 0.708245 val loss: 0.159526
[Epoch 34] ogbg-molhiv: 0.730016 test loss: 0.273961
[Epoch 35; Iter    22/ 1097] train: loss: 0.0258348
[Epoch 35; Iter    52/ 1097] train: loss: 0.0059836
[Epoch 35; Iter    82/ 1097] train: loss: 0.2409323
[Epoch 35; Iter   112/ 1097] train: loss: 0.1606249
[Epoch 35; Iter   142/ 1097] train: loss: 0.0098431
[Epoch 35; Iter   172/ 1097] train: loss: 0.0137863
[Epoch 35; Iter   202/ 1097] train: loss: 0.0515680
[Epoch 35; Iter   232/ 1097] train: loss: 0.0285067
[Epoch 35; Iter   262/ 1097] train: loss: 0.0077621
[Epoch 35; Iter   292/ 1097] train: loss: 0.0106149
[Epoch 35; Iter   322/ 1097] train: loss: 0.0488961
[Epoch 35; Iter   352/ 1097] train: loss: 0.0208871
[Epoch 35; Iter   382/ 1097] train: loss: 0.0059174
[Epoch 35; Iter   412/ 1097] train: loss: 0.0450582
[Epoch 35; Iter   442/ 1097] train: loss: 0.0135111
[Epoch 35; Iter   472/ 1097] train: loss: 0.0114357
[Epoch 35; Iter   502/ 1097] train: loss: 0.0137536
[Epoch 35; Iter   532/ 1097] train: loss: 0.0247468
[Epoch 35; Iter   562/ 1097] train: loss: 0.1999056
[Epoch 35; Iter   592/ 1097] train: loss: 0.0282240
[Epoch 35; Iter   622/ 1097] train: loss: 0.0151090
[Epoch 35; Iter   652/ 1097] train: loss: 0.0182165
[Epoch 35; Iter   682/ 1097] train: loss: 0.1933224
[Epoch 35; Iter   712/ 1097] train: loss: 0.0737172
[Epoch 35; Iter   742/ 1097] train: loss: 0.0075916
[Epoch 35; Iter   772/ 1097] train: loss: 0.0086673
[Epoch 35; Iter   802/ 1097] train: loss: 0.0052942
[Epoch 35; Iter   832/ 1097] train: loss: 0.1231700
[Epoch 35; Iter   862/ 1097] train: loss: 0.0228735
[Epoch 35; Iter   892/ 1097] train: loss: 0.1252423
[Epoch 35; Iter   922/ 1097] train: loss: 0.0060393
[Epoch 35; Iter   952/ 1097] train: loss: 0.0600644
[Epoch 35; Iter   982/ 1097] train: loss: 0.0191122
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0200730
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0364754
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0719755
[Epoch 35] ogbg-molhiv: 0.734752 val loss: 0.185125
[Epoch 35] ogbg-molhiv: 0.700693 test loss: 0.196871
[Epoch 36; Iter     5/ 1097] train: loss: 0.0098802
[Epoch 36; Iter    35/ 1097] train: loss: 0.0186035
[Epoch 36; Iter    65/ 1097] train: loss: 0.0226083
[Epoch 36; Iter    95/ 1097] train: loss: 0.0202126
[Epoch 36; Iter   125/ 1097] train: loss: 0.0210470
[Epoch 36; Iter   155/ 1097] train: loss: 0.0125946
[Epoch 36; Iter   185/ 1097] train: loss: 0.0405678
[Epoch 36; Iter   215/ 1097] train: loss: 0.0404812
[Epoch 36; Iter   245/ 1097] train: loss: 0.1179235
[Epoch 36; Iter   275/ 1097] train: loss: 0.0641629
[Epoch 36; Iter   305/ 1097] train: loss: 0.0084570
[Epoch 36; Iter   335/ 1097] train: loss: 0.0177229
[Epoch 36; Iter   365/ 1097] train: loss: 0.1871132
[Epoch 36; Iter   395/ 1097] train: loss: 0.0418236
[Epoch 36; Iter   425/ 1097] train: loss: 0.0350965
[Epoch 36; Iter   455/ 1097] train: loss: 0.0210751
[Epoch 36; Iter   485/ 1097] train: loss: 0.0056633
[Epoch 36; Iter   515/ 1097] train: loss: 0.1386879
[Epoch 36; Iter   545/ 1097] train: loss: 0.0069916
[Epoch 36; Iter   575/ 1097] train: loss: 0.0914302
[Epoch 36; Iter   605/ 1097] train: loss: 0.0312503
[Epoch 32; Iter   553/ 1097] train: loss: 0.1240204
[Epoch 32; Iter   583/ 1097] train: loss: 0.0068969
[Epoch 32; Iter   613/ 1097] train: loss: 0.0076887
[Epoch 32; Iter   643/ 1097] train: loss: 0.0109650
[Epoch 32; Iter   673/ 1097] train: loss: 0.0984483
[Epoch 32; Iter   703/ 1097] train: loss: 0.0179493
[Epoch 32; Iter   733/ 1097] train: loss: 0.0110794
[Epoch 32; Iter   763/ 1097] train: loss: 0.0712083
[Epoch 32; Iter   793/ 1097] train: loss: 0.0254198
[Epoch 32; Iter   823/ 1097] train: loss: 0.0673859
[Epoch 32; Iter   853/ 1097] train: loss: 0.0078973
[Epoch 32; Iter   883/ 1097] train: loss: 0.0324575
[Epoch 32; Iter   913/ 1097] train: loss: 0.0128666
[Epoch 32; Iter   943/ 1097] train: loss: 0.0350943
[Epoch 32; Iter   973/ 1097] train: loss: 0.0118907
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0370940
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0067118
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0532866
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0993555
[Epoch 32] ogbg-molhiv: 0.706567 val loss: 0.188286
[Epoch 32] ogbg-molhiv: 0.646198 test loss: 0.287084
[Epoch 33; Iter    26/ 1097] train: loss: 0.0021592
[Epoch 33; Iter    56/ 1097] train: loss: 0.1438159
[Epoch 33; Iter    86/ 1097] train: loss: 0.0355743
[Epoch 33; Iter   116/ 1097] train: loss: 0.1230493
[Epoch 33; Iter   146/ 1097] train: loss: 0.0120117
[Epoch 33; Iter   176/ 1097] train: loss: 0.0073896
[Epoch 33; Iter   206/ 1097] train: loss: 0.0256704
[Epoch 33; Iter   236/ 1097] train: loss: 0.0626777
[Epoch 33; Iter   266/ 1097] train: loss: 0.0233872
[Epoch 33; Iter   296/ 1097] train: loss: 0.0980491
[Epoch 33; Iter   326/ 1097] train: loss: 0.0083797
[Epoch 33; Iter   356/ 1097] train: loss: 0.1972378
[Epoch 33; Iter   386/ 1097] train: loss: 0.0286242
[Epoch 33; Iter   416/ 1097] train: loss: 0.0124268
[Epoch 33; Iter   446/ 1097] train: loss: 0.0062625
[Epoch 33; Iter   476/ 1097] train: loss: 0.0116197
[Epoch 33; Iter   506/ 1097] train: loss: 0.1111857
[Epoch 33; Iter   536/ 1097] train: loss: 0.0019733
[Epoch 33; Iter   566/ 1097] train: loss: 0.0141919
[Epoch 33; Iter   596/ 1097] train: loss: 0.0112808
[Epoch 33; Iter   626/ 1097] train: loss: 0.0092310
[Epoch 33; Iter   656/ 1097] train: loss: 0.0229297
[Epoch 33; Iter   686/ 1097] train: loss: 0.0051951
[Epoch 33; Iter   716/ 1097] train: loss: 0.0075255
[Epoch 33; Iter   746/ 1097] train: loss: 0.1005748
[Epoch 33; Iter   776/ 1097] train: loss: 0.2022161
[Epoch 33; Iter   806/ 1097] train: loss: 0.1554795
[Epoch 33; Iter   836/ 1097] train: loss: 0.0901071
[Epoch 33; Iter   866/ 1097] train: loss: 0.0512397
[Epoch 33; Iter   896/ 1097] train: loss: 0.0108086
[Epoch 33; Iter   926/ 1097] train: loss: 0.0095345
[Epoch 33; Iter   956/ 1097] train: loss: 0.0064037
[Epoch 33; Iter   986/ 1097] train: loss: 0.0085216
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0119966
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0257954
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0864653
[Epoch 33] ogbg-molhiv: 0.740866 val loss: 0.166138
[Epoch 33] ogbg-molhiv: 0.707840 test loss: 0.293934
[Epoch 34; Iter     9/ 1097] train: loss: 0.0196013
[Epoch 34; Iter    39/ 1097] train: loss: 0.0318897
[Epoch 34; Iter    69/ 1097] train: loss: 0.0255980
[Epoch 34; Iter    99/ 1097] train: loss: 0.1066898
[Epoch 34; Iter   129/ 1097] train: loss: 0.0085457
[Epoch 34; Iter   159/ 1097] train: loss: 0.0097809
[Epoch 34; Iter   189/ 1097] train: loss: 0.0245745
[Epoch 34; Iter   219/ 1097] train: loss: 0.0793731
[Epoch 34; Iter   249/ 1097] train: loss: 0.0019048
[Epoch 34; Iter   279/ 1097] train: loss: 0.0020430
[Epoch 34; Iter   309/ 1097] train: loss: 0.0060053
[Epoch 34; Iter   339/ 1097] train: loss: 0.0410739
[Epoch 34; Iter   369/ 1097] train: loss: 0.1236852
[Epoch 34; Iter   399/ 1097] train: loss: 0.0165136
[Epoch 34; Iter   429/ 1097] train: loss: 0.0149643
[Epoch 34; Iter   459/ 1097] train: loss: 0.0123379
[Epoch 34; Iter   489/ 1097] train: loss: 0.0248197
[Epoch 34; Iter   519/ 1097] train: loss: 0.0423257
[Epoch 34; Iter   549/ 1097] train: loss: 0.0070218
[Epoch 34; Iter   579/ 1097] train: loss: 0.0335395
[Epoch 34; Iter   609/ 1097] train: loss: 0.0402079
[Epoch 34; Iter   639/ 1097] train: loss: 0.0687230
[Epoch 34; Iter   669/ 1097] train: loss: 0.0026837
[Epoch 34; Iter   699/ 1097] train: loss: 0.0088117
[Epoch 34; Iter   729/ 1097] train: loss: 0.0305046
[Epoch 34; Iter   759/ 1097] train: loss: 0.0043550
[Epoch 34; Iter   789/ 1097] train: loss: 0.0056715
[Epoch 34; Iter   819/ 1097] train: loss: 0.0400685
[Epoch 34; Iter   849/ 1097] train: loss: 0.0217191
[Epoch 34; Iter   879/ 1097] train: loss: 0.0032252
[Epoch 34; Iter   909/ 1097] train: loss: 0.0056415
[Epoch 34; Iter   939/ 1097] train: loss: 0.0164059
[Epoch 34; Iter   969/ 1097] train: loss: 0.0510934
[Epoch 34; Iter   999/ 1097] train: loss: 0.0019034
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1531436
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0230323
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0075602
[Epoch 34] ogbg-molhiv: 0.705241 val loss: 0.522903
[Epoch 34] ogbg-molhiv: 0.680830 test loss: 0.496997
[Epoch 35; Iter    22/ 1097] train: loss: 0.0072039
[Epoch 35; Iter    52/ 1097] train: loss: 0.0071170
[Epoch 35; Iter    82/ 1097] train: loss: 0.0339466
[Epoch 35; Iter   112/ 1097] train: loss: 0.0059630
[Epoch 35; Iter   142/ 1097] train: loss: 0.0031414
[Epoch 35; Iter   172/ 1097] train: loss: 0.0355163
[Epoch 35; Iter   202/ 1097] train: loss: 0.0062697
[Epoch 35; Iter   232/ 1097] train: loss: 0.0068860
[Epoch 35; Iter   262/ 1097] train: loss: 0.0169044
[Epoch 35; Iter   292/ 1097] train: loss: 0.0087880
[Epoch 35; Iter   322/ 1097] train: loss: 0.0300539
[Epoch 35; Iter   352/ 1097] train: loss: 0.0442011
[Epoch 35; Iter   382/ 1097] train: loss: 0.0257452
[Epoch 35; Iter   412/ 1097] train: loss: 0.0192217
[Epoch 35; Iter   442/ 1097] train: loss: 0.0151054
[Epoch 35; Iter   472/ 1097] train: loss: 0.0094209
[Epoch 35; Iter   502/ 1097] train: loss: 0.0370200
[Epoch 35; Iter   532/ 1097] train: loss: 0.0870278
[Epoch 35; Iter   562/ 1097] train: loss: 0.0622714
[Epoch 35; Iter   592/ 1097] train: loss: 0.0010899
[Epoch 35; Iter   622/ 1097] train: loss: 0.0073065
[Epoch 35; Iter   652/ 1097] train: loss: 0.1153941
[Epoch 35; Iter   682/ 1097] train: loss: 0.0275516
[Epoch 35; Iter   712/ 1097] train: loss: 0.0215386
[Epoch 35; Iter   742/ 1097] train: loss: 0.0194363
[Epoch 35; Iter   772/ 1097] train: loss: 0.0246870
[Epoch 35; Iter   802/ 1097] train: loss: 0.0077661
[Epoch 35; Iter   832/ 1097] train: loss: 0.0831316
[Epoch 35; Iter   862/ 1097] train: loss: 0.0152906
[Epoch 35; Iter   892/ 1097] train: loss: 0.0140614
[Epoch 35; Iter   922/ 1097] train: loss: 0.0122780
[Epoch 35; Iter   952/ 1097] train: loss: 0.0901157
[Epoch 35; Iter   982/ 1097] train: loss: 0.0297214
[Epoch 35; Iter  1012/ 1097] train: loss: 0.1152809
[Epoch 35; Iter  1042/ 1097] train: loss: 0.2300477
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0302913
[Epoch 35] ogbg-molhiv: 0.756954 val loss: 0.246623
[Epoch 35] ogbg-molhiv: 0.722328 test loss: 0.266275
[Epoch 36; Iter     5/ 1097] train: loss: 0.0722981
[Epoch 36; Iter    35/ 1097] train: loss: 0.0078874
[Epoch 36; Iter    65/ 1097] train: loss: 0.0034840
[Epoch 36; Iter    95/ 1097] train: loss: 0.0018499
[Epoch 36; Iter   125/ 1097] train: loss: 0.0047695
[Epoch 36; Iter   155/ 1097] train: loss: 0.0029346
[Epoch 36; Iter   185/ 1097] train: loss: 0.0273139
[Epoch 36; Iter   215/ 1097] train: loss: 0.0238151
[Epoch 36; Iter   245/ 1097] train: loss: 0.0729044
[Epoch 36; Iter   275/ 1097] train: loss: 0.0298512
[Epoch 36; Iter   305/ 1097] train: loss: 0.2174146
[Epoch 36; Iter   335/ 1097] train: loss: 0.0085776
[Epoch 36; Iter   365/ 1097] train: loss: 0.0159851
[Epoch 36; Iter   395/ 1097] train: loss: 0.0024555
[Epoch 36; Iter   425/ 1097] train: loss: 0.0082025
[Epoch 36; Iter   455/ 1097] train: loss: 0.0431943
[Epoch 36; Iter   485/ 1097] train: loss: 0.0079007
[Epoch 36; Iter   515/ 1097] train: loss: 0.0023018
[Epoch 36; Iter   545/ 1097] train: loss: 0.0091934
[Epoch 36; Iter   575/ 1097] train: loss: 0.0092606
[Epoch 36; Iter   605/ 1097] train: loss: 0.0023864
[Epoch 32; Iter   553/ 1097] train: loss: 0.0318959
[Epoch 32; Iter   583/ 1097] train: loss: 0.0027571
[Epoch 32; Iter   613/ 1097] train: loss: 0.0359013
[Epoch 32; Iter   643/ 1097] train: loss: 0.0064826
[Epoch 32; Iter   673/ 1097] train: loss: 0.0030106
[Epoch 32; Iter   703/ 1097] train: loss: 0.0105902
[Epoch 32; Iter   733/ 1097] train: loss: 0.0048303
[Epoch 32; Iter   763/ 1097] train: loss: 0.0044627
[Epoch 32; Iter   793/ 1097] train: loss: 0.1637144
[Epoch 32; Iter   823/ 1097] train: loss: 0.0329750
[Epoch 32; Iter   853/ 1097] train: loss: 0.0313498
[Epoch 32; Iter   883/ 1097] train: loss: 0.0069946
[Epoch 32; Iter   913/ 1097] train: loss: 0.0156834
[Epoch 32; Iter   943/ 1097] train: loss: 0.0031074
[Epoch 32; Iter   973/ 1097] train: loss: 0.0041367
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0030585
[Epoch 32; Iter  1033/ 1097] train: loss: 0.2290598
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0189173
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0291870
[Epoch 32] ogbg-molhiv: 0.709635 val loss: 10.821080
[Epoch 32] ogbg-molhiv: 0.640323 test loss: 7.860087
[Epoch 33; Iter    26/ 1097] train: loss: 0.0229929
[Epoch 33; Iter    56/ 1097] train: loss: 0.0400419
[Epoch 33; Iter    86/ 1097] train: loss: 0.0040471
[Epoch 33; Iter   116/ 1097] train: loss: 0.0023642
[Epoch 33; Iter   146/ 1097] train: loss: 0.0035591
[Epoch 33; Iter   176/ 1097] train: loss: 0.0402487
[Epoch 33; Iter   206/ 1097] train: loss: 0.0116786
[Epoch 33; Iter   236/ 1097] train: loss: 0.0101126
[Epoch 33; Iter   266/ 1097] train: loss: 0.0103233
[Epoch 33; Iter   296/ 1097] train: loss: 0.0004512
[Epoch 33; Iter   326/ 1097] train: loss: 0.0225787
[Epoch 33; Iter   356/ 1097] train: loss: 0.0052728
[Epoch 33; Iter   386/ 1097] train: loss: 0.0157505
[Epoch 33; Iter   416/ 1097] train: loss: 0.1420915
[Epoch 33; Iter   446/ 1097] train: loss: 0.0081322
[Epoch 33; Iter   476/ 1097] train: loss: 0.0513051
[Epoch 33; Iter   506/ 1097] train: loss: 0.0031392
[Epoch 33; Iter   536/ 1097] train: loss: 0.0046280
[Epoch 33; Iter   566/ 1097] train: loss: 0.0091444
[Epoch 33; Iter   596/ 1097] train: loss: 0.0003695
[Epoch 33; Iter   626/ 1097] train: loss: 0.0059811
[Epoch 33; Iter   656/ 1097] train: loss: 0.0881994
[Epoch 33; Iter   686/ 1097] train: loss: 0.0162720
[Epoch 33; Iter   716/ 1097] train: loss: 0.1064602
[Epoch 33; Iter   746/ 1097] train: loss: 0.0089848
[Epoch 33; Iter   776/ 1097] train: loss: 0.0142704
[Epoch 33; Iter   806/ 1097] train: loss: 0.0376816
[Epoch 33; Iter   836/ 1097] train: loss: 0.0104775
[Epoch 33; Iter   866/ 1097] train: loss: 0.0053725
[Epoch 33; Iter   896/ 1097] train: loss: 0.0008949
[Epoch 33; Iter   926/ 1097] train: loss: 0.0188800
[Epoch 33; Iter   956/ 1097] train: loss: 0.0011679
[Epoch 33; Iter   986/ 1097] train: loss: 0.0038146
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0013172
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0102714
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0125034
[Epoch 33] ogbg-molhiv: 0.685311 val loss: 7.989436
[Epoch 33] ogbg-molhiv: 0.618326 test loss: 5.273705
[Epoch 34; Iter     9/ 1097] train: loss: 0.0030937
[Epoch 34; Iter    39/ 1097] train: loss: 0.0152655
[Epoch 34; Iter    69/ 1097] train: loss: 0.0036730
[Epoch 34; Iter    99/ 1097] train: loss: 0.0104144
[Epoch 34; Iter   129/ 1097] train: loss: 0.0274145
[Epoch 34; Iter   159/ 1097] train: loss: 0.0118931
[Epoch 34; Iter   189/ 1097] train: loss: 0.0129887
[Epoch 34; Iter   219/ 1097] train: loss: 0.0075715
[Epoch 34; Iter   249/ 1097] train: loss: 0.0360911
[Epoch 34; Iter   279/ 1097] train: loss: 0.1027820
[Epoch 34; Iter   309/ 1097] train: loss: 0.0429097
[Epoch 34; Iter   339/ 1097] train: loss: 0.0030197
[Epoch 34; Iter   369/ 1097] train: loss: 0.0059455
[Epoch 34; Iter   399/ 1097] train: loss: 0.0119321
[Epoch 34; Iter   429/ 1097] train: loss: 0.0149601
[Epoch 34; Iter   459/ 1097] train: loss: 0.1844980
[Epoch 34; Iter   489/ 1097] train: loss: 0.0077469
[Epoch 34; Iter   519/ 1097] train: loss: 0.0044113
[Epoch 34; Iter   549/ 1097] train: loss: 0.1117875
[Epoch 34; Iter   579/ 1097] train: loss: 0.0038649
[Epoch 34; Iter   609/ 1097] train: loss: 0.0035430
[Epoch 34; Iter   639/ 1097] train: loss: 0.0025681
[Epoch 34; Iter   669/ 1097] train: loss: 0.0247779
[Epoch 34; Iter   699/ 1097] train: loss: 0.0284088
[Epoch 34; Iter   729/ 1097] train: loss: 0.0415881
[Epoch 34; Iter   759/ 1097] train: loss: 0.0075515
[Epoch 34; Iter   789/ 1097] train: loss: 0.0249236
[Epoch 34; Iter   819/ 1097] train: loss: 0.0054198
[Epoch 34; Iter   849/ 1097] train: loss: 0.0015340
[Epoch 34; Iter   879/ 1097] train: loss: 0.0103352
[Epoch 34; Iter   909/ 1097] train: loss: 0.0202928
[Epoch 34; Iter   939/ 1097] train: loss: 0.0113525
[Epoch 34; Iter   969/ 1097] train: loss: 0.0183822
[Epoch 34; Iter   999/ 1097] train: loss: 0.0168854
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0360995
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0027304
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0031611
[Epoch 34] ogbg-molhiv: 0.707559 val loss: 11.123540
[Epoch 34] ogbg-molhiv: 0.599428 test loss: 7.340365
[Epoch 35; Iter    22/ 1097] train: loss: 0.0097419
[Epoch 35; Iter    52/ 1097] train: loss: 0.0027132
[Epoch 35; Iter    82/ 1097] train: loss: 0.0033250
[Epoch 35; Iter   112/ 1097] train: loss: 0.0034580
[Epoch 35; Iter   142/ 1097] train: loss: 0.0048634
[Epoch 35; Iter   172/ 1097] train: loss: 0.0037435
[Epoch 35; Iter   202/ 1097] train: loss: 0.0410507
[Epoch 35; Iter   232/ 1097] train: loss: 0.1023164
[Epoch 35; Iter   262/ 1097] train: loss: 0.0127036
[Epoch 35; Iter   292/ 1097] train: loss: 0.0026706
[Epoch 35; Iter   322/ 1097] train: loss: 0.0116328
[Epoch 35; Iter   352/ 1097] train: loss: 0.0016636
[Epoch 35; Iter   382/ 1097] train: loss: 0.0025818
[Epoch 35; Iter   412/ 1097] train: loss: 0.0293148
[Epoch 35; Iter   442/ 1097] train: loss: 0.0011474
[Epoch 35; Iter   472/ 1097] train: loss: 0.0071784
[Epoch 35; Iter   502/ 1097] train: loss: 0.0754968
[Epoch 35; Iter   532/ 1097] train: loss: 0.0034994
[Epoch 35; Iter   562/ 1097] train: loss: 0.0071738
[Epoch 35; Iter   592/ 1097] train: loss: 0.0034792
[Epoch 35; Iter   622/ 1097] train: loss: 0.0984239
[Epoch 35; Iter   652/ 1097] train: loss: 0.0034974
[Epoch 35; Iter   682/ 1097] train: loss: 0.0285928
[Epoch 35; Iter   712/ 1097] train: loss: 0.0053668
[Epoch 35; Iter   742/ 1097] train: loss: 0.0604710
[Epoch 35; Iter   772/ 1097] train: loss: 0.0093481
[Epoch 35; Iter   802/ 1097] train: loss: 0.0091085
[Epoch 35; Iter   832/ 1097] train: loss: 0.0050402
[Epoch 35; Iter   862/ 1097] train: loss: 0.0085491
[Epoch 35; Iter   892/ 1097] train: loss: 0.0143463
[Epoch 35; Iter   922/ 1097] train: loss: 0.0190300
[Epoch 35; Iter   952/ 1097] train: loss: 0.0037623
[Epoch 35; Iter   982/ 1097] train: loss: 0.0184774
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0012274
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0519896
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0107602
[Epoch 35] ogbg-molhiv: 0.688195 val loss: 7.664015
[Epoch 35] ogbg-molhiv: 0.622426 test loss: 4.882474
[Epoch 36; Iter     5/ 1097] train: loss: 0.0075428
[Epoch 36; Iter    35/ 1097] train: loss: 0.0029150
[Epoch 36; Iter    65/ 1097] train: loss: 0.0077474
[Epoch 36; Iter    95/ 1097] train: loss: 0.0051280
[Epoch 36; Iter   125/ 1097] train: loss: 0.0081775
[Epoch 36; Iter   155/ 1097] train: loss: 0.0008939
[Epoch 36; Iter   185/ 1097] train: loss: 0.0022619
[Epoch 36; Iter   215/ 1097] train: loss: 0.1448857
[Epoch 36; Iter   245/ 1097] train: loss: 0.0060064
[Epoch 36; Iter   275/ 1097] train: loss: 0.0050148
[Epoch 36; Iter   305/ 1097] train: loss: 0.0317994
[Epoch 36; Iter   335/ 1097] train: loss: 0.1020476
[Epoch 36; Iter   365/ 1097] train: loss: 0.0049953
[Epoch 36; Iter   395/ 1097] train: loss: 0.0380207
[Epoch 36; Iter   425/ 1097] train: loss: 0.0470775
[Epoch 36; Iter   455/ 1097] train: loss: 0.0683331
[Epoch 36; Iter   485/ 1097] train: loss: 0.0022414
[Epoch 36; Iter   515/ 1097] train: loss: 0.0048705
[Epoch 36; Iter   545/ 1097] train: loss: 0.0038346
[Epoch 36; Iter   575/ 1097] train: loss: 0.0008234
[Epoch 36; Iter   605/ 1097] train: loss: 0.0042748
[Epoch 28; Iter   471/ 1097] train: loss: 0.0398007
[Epoch 28; Iter   501/ 1097] train: loss: 0.0403183
[Epoch 28; Iter   531/ 1097] train: loss: 0.1604839
[Epoch 28; Iter   561/ 1097] train: loss: 0.0420649
[Epoch 28; Iter   591/ 1097] train: loss: 0.1976247
[Epoch 28; Iter   621/ 1097] train: loss: 0.0942912
[Epoch 28; Iter   651/ 1097] train: loss: 0.2131300
[Epoch 28; Iter   681/ 1097] train: loss: 0.0485106
[Epoch 28; Iter   711/ 1097] train: loss: 0.0594077
[Epoch 28; Iter   741/ 1097] train: loss: 0.1576588
[Epoch 28; Iter   771/ 1097] train: loss: 0.0698426
[Epoch 28; Iter   801/ 1097] train: loss: 0.2310351
[Epoch 28; Iter   831/ 1097] train: loss: 0.0483831
[Epoch 28; Iter   861/ 1097] train: loss: 0.0377594
[Epoch 28; Iter   891/ 1097] train: loss: 0.3145282
[Epoch 28; Iter   921/ 1097] train: loss: 0.0924378
[Epoch 28; Iter   951/ 1097] train: loss: 0.0290259
[Epoch 28; Iter   981/ 1097] train: loss: 0.0379344
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0227418
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1469226
[Epoch 28; Iter  1071/ 1097] train: loss: 0.2207770
[Epoch 28] ogbg-molhiv: 0.766749 val loss: 0.334228
[Epoch 28] ogbg-molhiv: 0.748773 test loss: 0.192134
[Epoch 29; Iter     4/ 1097] train: loss: 0.0693788
[Epoch 29; Iter    34/ 1097] train: loss: 0.0786953
[Epoch 29; Iter    64/ 1097] train: loss: 0.4794202
[Epoch 29; Iter    94/ 1097] train: loss: 0.0295529
[Epoch 29; Iter   124/ 1097] train: loss: 0.0350381
[Epoch 29; Iter   154/ 1097] train: loss: 0.1662599
[Epoch 29; Iter   184/ 1097] train: loss: 0.1774241
[Epoch 29; Iter   214/ 1097] train: loss: 0.1736874
[Epoch 29; Iter   244/ 1097] train: loss: 0.0344606
[Epoch 29; Iter   274/ 1097] train: loss: 0.0762219
[Epoch 29; Iter   304/ 1097] train: loss: 0.0301227
[Epoch 29; Iter   334/ 1097] train: loss: 0.0457217
[Epoch 29; Iter   364/ 1097] train: loss: 0.1080009
[Epoch 29; Iter   394/ 1097] train: loss: 0.0281769
[Epoch 29; Iter   424/ 1097] train: loss: 0.0480079
[Epoch 29; Iter   454/ 1097] train: loss: 0.0226668
[Epoch 29; Iter   484/ 1097] train: loss: 0.0296281
[Epoch 29; Iter   514/ 1097] train: loss: 0.2746204
[Epoch 29; Iter   544/ 1097] train: loss: 0.0328618
[Epoch 29; Iter   574/ 1097] train: loss: 0.0203560
[Epoch 29; Iter   604/ 1097] train: loss: 0.0250774
[Epoch 29; Iter   634/ 1097] train: loss: 0.0148235
[Epoch 29; Iter   664/ 1097] train: loss: 0.0515888
[Epoch 29; Iter   694/ 1097] train: loss: 0.2202180
[Epoch 29; Iter   724/ 1097] train: loss: 0.0291620
[Epoch 29; Iter   754/ 1097] train: loss: 0.0408905
[Epoch 29; Iter   784/ 1097] train: loss: 0.1685415
[Epoch 29; Iter   814/ 1097] train: loss: 0.2169015
[Epoch 29; Iter   844/ 1097] train: loss: 0.0559564
[Epoch 29; Iter   874/ 1097] train: loss: 0.0388519
[Epoch 29; Iter   904/ 1097] train: loss: 0.0429750
[Epoch 29; Iter   934/ 1097] train: loss: 0.0844850
[Epoch 29; Iter   964/ 1097] train: loss: 0.0226081
[Epoch 29; Iter   994/ 1097] train: loss: 0.1047678
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0299102
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1819915
[Epoch 29; Iter  1084/ 1097] train: loss: 0.2594331
[Epoch 29] ogbg-molhiv: 0.806897 val loss: 0.264044
[Epoch 29] ogbg-molhiv: 0.763350 test loss: 0.155320
[Epoch 30; Iter    17/ 1097] train: loss: 0.2737460
[Epoch 30; Iter    47/ 1097] train: loss: 0.0595605
[Epoch 30; Iter    77/ 1097] train: loss: 0.0139966
[Epoch 30; Iter   107/ 1097] train: loss: 0.1617547
[Epoch 30; Iter   137/ 1097] train: loss: 0.0495739
[Epoch 30; Iter   167/ 1097] train: loss: 0.3768342
[Epoch 30; Iter   197/ 1097] train: loss: 0.0806849
[Epoch 30; Iter   227/ 1097] train: loss: 0.0538832
[Epoch 30; Iter   257/ 1097] train: loss: 0.1382871
[Epoch 30; Iter   287/ 1097] train: loss: 0.1198976
[Epoch 30; Iter   317/ 1097] train: loss: 0.1175760
[Epoch 30; Iter   347/ 1097] train: loss: 0.0223661
[Epoch 30; Iter   377/ 1097] train: loss: 0.2582862
[Epoch 30; Iter   407/ 1097] train: loss: 0.0231994
[Epoch 30; Iter   437/ 1097] train: loss: 0.1443353
[Epoch 30; Iter   467/ 1097] train: loss: 0.0285379
[Epoch 30; Iter   497/ 1097] train: loss: 0.1454941
[Epoch 30; Iter   527/ 1097] train: loss: 0.2348730
[Epoch 30; Iter   557/ 1097] train: loss: 0.1512847
[Epoch 30; Iter   587/ 1097] train: loss: 0.2013841
[Epoch 30; Iter   617/ 1097] train: loss: 0.0205917
[Epoch 30; Iter   647/ 1097] train: loss: 0.1111551
[Epoch 30; Iter   677/ 1097] train: loss: 0.1123307
[Epoch 30; Iter   707/ 1097] train: loss: 0.0313779
[Epoch 30; Iter   737/ 1097] train: loss: 0.0200756
[Epoch 30; Iter   767/ 1097] train: loss: 0.0223668
[Epoch 30; Iter   797/ 1097] train: loss: 0.0659487
[Epoch 30; Iter   827/ 1097] train: loss: 0.1019478
[Epoch 30; Iter   857/ 1097] train: loss: 0.1335311
[Epoch 30; Iter   887/ 1097] train: loss: 0.0850538
[Epoch 30; Iter   917/ 1097] train: loss: 0.1518758
[Epoch 30; Iter   947/ 1097] train: loss: 0.2982038
[Epoch 30; Iter   977/ 1097] train: loss: 0.1353935
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0238023
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1436057
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0254936
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0315292
[Epoch 30] ogbg-molhiv: 0.793225 val loss: 0.495027
[Epoch 30] ogbg-molhiv: 0.769511 test loss: 0.245388
[Epoch 31; Iter    30/ 1097] train: loss: 0.0289598
[Epoch 31; Iter    60/ 1097] train: loss: 0.1676914
[Epoch 31; Iter    90/ 1097] train: loss: 0.0198574
[Epoch 31; Iter   120/ 1097] train: loss: 0.0181871
[Epoch 31; Iter   150/ 1097] train: loss: 0.0879577
[Epoch 31; Iter   180/ 1097] train: loss: 0.0396042
[Epoch 31; Iter   210/ 1097] train: loss: 0.2289516
[Epoch 31; Iter   240/ 1097] train: loss: 0.1816540
[Epoch 31; Iter   270/ 1097] train: loss: 0.0757687
[Epoch 31; Iter   300/ 1097] train: loss: 0.0332817
[Epoch 31; Iter   330/ 1097] train: loss: 0.0317333
[Epoch 31; Iter   360/ 1097] train: loss: 0.0504742
[Epoch 31; Iter   390/ 1097] train: loss: 0.1323069
[Epoch 31; Iter   420/ 1097] train: loss: 0.0306426
[Epoch 31; Iter   450/ 1097] train: loss: 0.0274728
[Epoch 31; Iter   480/ 1097] train: loss: 0.0619166
[Epoch 31; Iter   510/ 1097] train: loss: 0.0159763
[Epoch 31; Iter   540/ 1097] train: loss: 0.1713026
[Epoch 31; Iter   570/ 1097] train: loss: 0.0605711
[Epoch 31; Iter   600/ 1097] train: loss: 0.0136680
[Epoch 31; Iter   630/ 1097] train: loss: 0.1833207
[Epoch 31; Iter   660/ 1097] train: loss: 0.0143218
[Epoch 31; Iter   690/ 1097] train: loss: 0.1698687
[Epoch 31; Iter   720/ 1097] train: loss: 0.1188565
[Epoch 31; Iter   750/ 1097] train: loss: 0.1598779
[Epoch 31; Iter   780/ 1097] train: loss: 0.0894904
[Epoch 31; Iter   810/ 1097] train: loss: 0.0320721
[Epoch 31; Iter   840/ 1097] train: loss: 0.0227702
[Epoch 31; Iter   870/ 1097] train: loss: 0.0326657
[Epoch 31; Iter   900/ 1097] train: loss: 0.1751568
[Epoch 31; Iter   930/ 1097] train: loss: 0.1831845
[Epoch 31; Iter   960/ 1097] train: loss: 0.1679948
[Epoch 31; Iter   990/ 1097] train: loss: 0.0259282
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0635609
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0330800
[Epoch 31; Iter  1080/ 1097] train: loss: 0.1211199
[Epoch 31] ogbg-molhiv: 0.811441 val loss: 0.278856
[Epoch 31] ogbg-molhiv: 0.772176 test loss: 0.231471
[Epoch 32; Iter    13/ 1097] train: loss: 0.5855679
[Epoch 32; Iter    43/ 1097] train: loss: 0.0905201
[Epoch 32; Iter    73/ 1097] train: loss: 0.0260114
[Epoch 32; Iter   103/ 1097] train: loss: 0.0204805
[Epoch 32; Iter   133/ 1097] train: loss: 0.0272677
[Epoch 32; Iter   163/ 1097] train: loss: 0.0898326
[Epoch 32; Iter   193/ 1097] train: loss: 0.0267795
[Epoch 32; Iter   223/ 1097] train: loss: 0.0844129
[Epoch 32; Iter   253/ 1097] train: loss: 0.0181975
[Epoch 32; Iter   283/ 1097] train: loss: 0.0443110
[Epoch 32; Iter   313/ 1097] train: loss: 0.0376471
[Epoch 32; Iter   343/ 1097] train: loss: 0.0664294
[Epoch 32; Iter   373/ 1097] train: loss: 0.0209065
[Epoch 32; Iter   403/ 1097] train: loss: 0.2718734
[Epoch 32; Iter   433/ 1097] train: loss: 0.0444655
[Epoch 32; Iter   463/ 1097] train: loss: 0.0505122
[Epoch 32; Iter   493/ 1097] train: loss: 0.0877752
[Epoch 32; Iter   523/ 1097] train: loss: 0.0444658
[Epoch 32; Iter   553/ 1097] train: loss: 0.0096784
[Epoch 32; Iter   583/ 1097] train: loss: 0.1644190
[Epoch 32; Iter   613/ 1097] train: loss: 0.0079480
[Epoch 32; Iter   643/ 1097] train: loss: 0.1550944
[Epoch 32; Iter   673/ 1097] train: loss: 0.1542414
[Epoch 32; Iter   703/ 1097] train: loss: 0.0751618
[Epoch 32; Iter   733/ 1097] train: loss: 0.0143696
[Epoch 32; Iter   763/ 1097] train: loss: 0.0182821
[Epoch 32; Iter   793/ 1097] train: loss: 0.0322269
[Epoch 32; Iter   823/ 1097] train: loss: 0.0872032
[Epoch 32; Iter   853/ 1097] train: loss: 0.0624444
[Epoch 32; Iter   883/ 1097] train: loss: 0.0559390
[Epoch 32; Iter   913/ 1097] train: loss: 0.1901128
[Epoch 32; Iter   943/ 1097] train: loss: 0.0490900
[Epoch 32; Iter   973/ 1097] train: loss: 0.0347548
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0543190
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0216112
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0640967
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0557579
[Epoch 32] ogbg-molhiv: 0.730946 val loss: 0.218811
[Epoch 32] ogbg-molhiv: 0.683175 test loss: 0.440394
[Epoch 33; Iter    26/ 1097] train: loss: 0.1317894
[Epoch 33; Iter    56/ 1097] train: loss: 0.0187200
[Epoch 33; Iter    86/ 1097] train: loss: 0.0177299
[Epoch 33; Iter   116/ 1097] train: loss: 0.0227354
[Epoch 33; Iter   146/ 1097] train: loss: 0.1275128
[Epoch 33; Iter   176/ 1097] train: loss: 0.0399892
[Epoch 33; Iter   206/ 1097] train: loss: 0.0168647
[Epoch 33; Iter   236/ 1097] train: loss: 0.1697127
[Epoch 33; Iter   266/ 1097] train: loss: 0.0104068
[Epoch 33; Iter   296/ 1097] train: loss: 0.0235593
[Epoch 33; Iter   326/ 1097] train: loss: 0.1136492
[Epoch 33; Iter   356/ 1097] train: loss: 0.2121384
[Epoch 33; Iter   386/ 1097] train: loss: 0.0470194
[Epoch 33; Iter   416/ 1097] train: loss: 0.0141358
[Epoch 33; Iter   446/ 1097] train: loss: 0.0267220
[Epoch 33; Iter   476/ 1097] train: loss: 0.0323495
[Epoch 33; Iter   506/ 1097] train: loss: 0.1259505
[Epoch 33; Iter   536/ 1097] train: loss: 0.0712159
[Epoch 33; Iter   566/ 1097] train: loss: 0.1221514
[Epoch 33; Iter   596/ 1097] train: loss: 0.0500439
[Epoch 33; Iter   626/ 1097] train: loss: 0.0128785
[Epoch 33; Iter   656/ 1097] train: loss: 0.1702694
[Epoch 33; Iter   686/ 1097] train: loss: 0.0672120
[Epoch 33; Iter   716/ 1097] train: loss: 0.4959682
[Epoch 33; Iter   746/ 1097] train: loss: 0.0851260
[Epoch 33; Iter   776/ 1097] train: loss: 0.1987035
[Epoch 33; Iter   806/ 1097] train: loss: 0.0845260
[Epoch 33; Iter   836/ 1097] train: loss: 0.0882239
[Epoch 33; Iter   866/ 1097] train: loss: 0.1058189
[Epoch 33; Iter   896/ 1097] train: loss: 0.0152067
[Epoch 33; Iter   926/ 1097] train: loss: 0.0126874
[Epoch 33; Iter   956/ 1097] train: loss: 0.1196249
[Epoch 33; Iter   986/ 1097] train: loss: 0.1568229
[Epoch 33; Iter  1016/ 1097] train: loss: 0.1628632
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0734588
[Epoch 33; Iter  1076/ 1097] train: loss: 0.1716851
[Epoch 33] ogbg-molhiv: 0.724999 val loss: 0.117312
[Epoch 33] ogbg-molhiv: 0.623519 test loss: 0.427620
[Epoch 34; Iter     9/ 1097] train: loss: 0.0308056
[Epoch 34; Iter    39/ 1097] train: loss: 0.0378623
[Epoch 34; Iter    69/ 1097] train: loss: 0.0176528
[Epoch 34; Iter    99/ 1097] train: loss: 0.0678195
[Epoch 34; Iter   129/ 1097] train: loss: 0.0360936
[Epoch 34; Iter   159/ 1097] train: loss: 0.0352981
[Epoch 34; Iter   189/ 1097] train: loss: 0.0102643
[Epoch 34; Iter   219/ 1097] train: loss: 0.1795675
[Epoch 34; Iter   249/ 1097] train: loss: 0.0071018
[Epoch 34; Iter   279/ 1097] train: loss: 0.0572007
[Epoch 34; Iter   309/ 1097] train: loss: 0.0290168
[Epoch 34; Iter   339/ 1097] train: loss: 0.0445657
[Epoch 34; Iter   369/ 1097] train: loss: 0.0068506
[Epoch 34; Iter   399/ 1097] train: loss: 0.0523004
[Epoch 34; Iter   429/ 1097] train: loss: 0.0279573
[Epoch 34; Iter   459/ 1097] train: loss: 0.0066721
[Epoch 34; Iter   489/ 1097] train: loss: 0.0078664
[Epoch 34; Iter   519/ 1097] train: loss: 0.0882894
[Epoch 34; Iter   549/ 1097] train: loss: 0.0127251
[Epoch 34; Iter   579/ 1097] train: loss: 0.1251969
[Epoch 34; Iter   609/ 1097] train: loss: 0.0172041
[Epoch 34; Iter   639/ 1097] train: loss: 0.1186416
[Epoch 34; Iter   669/ 1097] train: loss: 0.0143839
[Epoch 34; Iter   699/ 1097] train: loss: 0.2267350
[Epoch 34; Iter   729/ 1097] train: loss: 0.0540272
[Epoch 34; Iter   759/ 1097] train: loss: 0.2458115
[Epoch 34; Iter   789/ 1097] train: loss: 0.0939212
[Epoch 34; Iter   819/ 1097] train: loss: 0.0172459
[Epoch 34; Iter   849/ 1097] train: loss: 0.2093721
[Epoch 34; Iter   879/ 1097] train: loss: 0.0181756
[Epoch 34; Iter   909/ 1097] train: loss: 0.0101759
[Epoch 34; Iter   939/ 1097] train: loss: 0.0257713
[Epoch 34; Iter   969/ 1097] train: loss: 0.0946701
[Epoch 34; Iter   999/ 1097] train: loss: 0.0270061
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0156344
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1209850
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0263629
[Epoch 34] ogbg-molhiv: 0.716515 val loss: 0.180218
[Epoch 34] ogbg-molhiv: 0.612490 test loss: 0.352327
[Epoch 35; Iter    22/ 1097] train: loss: 0.0168310
[Epoch 35; Iter    52/ 1097] train: loss: 0.0153147
[Epoch 35; Iter    82/ 1097] train: loss: 0.1382389
[Epoch 35; Iter   112/ 1097] train: loss: 0.0705674
[Epoch 35; Iter   142/ 1097] train: loss: 0.0167821
[Epoch 35; Iter   172/ 1097] train: loss: 0.0091705
[Epoch 35; Iter   202/ 1097] train: loss: 0.0076474
[Epoch 35; Iter   232/ 1097] train: loss: 0.0135332
[Epoch 35; Iter   262/ 1097] train: loss: 0.1500463
[Epoch 35; Iter   292/ 1097] train: loss: 0.0050188
[Epoch 35; Iter   322/ 1097] train: loss: 0.0250745
[Epoch 35; Iter   352/ 1097] train: loss: 0.0140022
[Epoch 35; Iter   382/ 1097] train: loss: 0.0104889
[Epoch 35; Iter   412/ 1097] train: loss: 0.0439812
[Epoch 35; Iter   442/ 1097] train: loss: 0.0920750
[Epoch 35; Iter   472/ 1097] train: loss: 0.0183189
[Epoch 35; Iter   502/ 1097] train: loss: 0.0234938
[Epoch 35; Iter   532/ 1097] train: loss: 0.0647515
[Epoch 35; Iter   562/ 1097] train: loss: 0.2290603
[Epoch 35; Iter   592/ 1097] train: loss: 0.0090220
[Epoch 35; Iter   622/ 1097] train: loss: 0.0202641
[Epoch 35; Iter   652/ 1097] train: loss: 0.0222201
[Epoch 35; Iter   682/ 1097] train: loss: 0.0114736
[Epoch 35; Iter   712/ 1097] train: loss: 0.0975156
[Epoch 35; Iter   742/ 1097] train: loss: 0.0121816
[Epoch 35; Iter   772/ 1097] train: loss: 0.0110890
[Epoch 35; Iter   802/ 1097] train: loss: 0.0097664
[Epoch 35; Iter   832/ 1097] train: loss: 0.0293107
[Epoch 35; Iter   862/ 1097] train: loss: 0.0564423
[Epoch 35; Iter   892/ 1097] train: loss: 0.1046034
[Epoch 35; Iter   922/ 1097] train: loss: 0.0032069
[Epoch 35; Iter   952/ 1097] train: loss: 0.0763206
[Epoch 35; Iter   982/ 1097] train: loss: 0.0971678
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0203341
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0078205
[Epoch 35; Iter  1072/ 1097] train: loss: 0.1366714
[Epoch 35] ogbg-molhiv: 0.734990 val loss: 0.166082
[Epoch 35] ogbg-molhiv: 0.625136 test loss: 0.247517
[Epoch 36; Iter     5/ 1097] train: loss: 0.0160521
[Epoch 36; Iter    35/ 1097] train: loss: 0.1009538
[Epoch 36; Iter    65/ 1097] train: loss: 0.0092810
[Epoch 36; Iter    95/ 1097] train: loss: 0.0315410
[Epoch 36; Iter   125/ 1097] train: loss: 0.0716304
[Epoch 36; Iter   155/ 1097] train: loss: 0.0295197
[Epoch 36; Iter   185/ 1097] train: loss: 0.0364069
[Epoch 36; Iter   215/ 1097] train: loss: 0.0137207
[Epoch 36; Iter   245/ 1097] train: loss: 0.0245523
[Epoch 36; Iter   275/ 1097] train: loss: 0.0158852
[Epoch 36; Iter   305/ 1097] train: loss: 0.0232723
[Epoch 36; Iter   335/ 1097] train: loss: 0.0695959
[Epoch 36; Iter   365/ 1097] train: loss: 0.1739779
[Epoch 36; Iter   395/ 1097] train: loss: 0.0251985
[Epoch 36; Iter   425/ 1097] train: loss: 0.0068314
[Epoch 36; Iter   455/ 1097] train: loss: 0.0371726
[Epoch 36; Iter   485/ 1097] train: loss: 0.0165274
[Epoch 36; Iter   515/ 1097] train: loss: 0.1097709
[Epoch 36; Iter   545/ 1097] train: loss: 0.2162836
[Epoch 36; Iter   575/ 1097] train: loss: 0.0207399
[Epoch 36; Iter   605/ 1097] train: loss: 0.1000902
[Epoch 28; Iter   471/ 1097] train: loss: 0.2181466
[Epoch 28; Iter   501/ 1097] train: loss: 0.0340250
[Epoch 28; Iter   531/ 1097] train: loss: 0.0380342
[Epoch 28; Iter   561/ 1097] train: loss: 0.1254087
[Epoch 28; Iter   591/ 1097] train: loss: 0.0568798
[Epoch 28; Iter   621/ 1097] train: loss: 0.0261036
[Epoch 28; Iter   651/ 1097] train: loss: 0.0268183
[Epoch 28; Iter   681/ 1097] train: loss: 0.0833858
[Epoch 28; Iter   711/ 1097] train: loss: 0.0294245
[Epoch 28; Iter   741/ 1097] train: loss: 0.0258995
[Epoch 28; Iter   771/ 1097] train: loss: 0.0538616
[Epoch 28; Iter   801/ 1097] train: loss: 0.0175310
[Epoch 28; Iter   831/ 1097] train: loss: 0.1743227
[Epoch 28; Iter   861/ 1097] train: loss: 0.0191834
[Epoch 28; Iter   891/ 1097] train: loss: 0.0296347
[Epoch 28; Iter   921/ 1097] train: loss: 0.0179105
[Epoch 28; Iter   951/ 1097] train: loss: 0.0198370
[Epoch 28; Iter   981/ 1097] train: loss: 0.1025187
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0261887
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0543028
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0332426
[Epoch 28] ogbg-molhiv: 0.802405 val loss: 0.470593
[Epoch 28] ogbg-molhiv: 0.759389 test loss: 0.264948
[Epoch 29; Iter     4/ 1097] train: loss: 0.0260991
[Epoch 29; Iter    34/ 1097] train: loss: 0.2033971
[Epoch 29; Iter    64/ 1097] train: loss: 0.0823949
[Epoch 29; Iter    94/ 1097] train: loss: 0.0549965
[Epoch 29; Iter   124/ 1097] train: loss: 0.2227631
[Epoch 29; Iter   154/ 1097] train: loss: 0.0281750
[Epoch 29; Iter   184/ 1097] train: loss: 0.0135071
[Epoch 29; Iter   214/ 1097] train: loss: 0.1364858
[Epoch 29; Iter   244/ 1097] train: loss: 0.1603668
[Epoch 29; Iter   274/ 1097] train: loss: 0.0392915
[Epoch 29; Iter   304/ 1097] train: loss: 0.0281344
[Epoch 29; Iter   334/ 1097] train: loss: 0.1909395
[Epoch 29; Iter   364/ 1097] train: loss: 0.0282509
[Epoch 29; Iter   394/ 1097] train: loss: 0.2216738
[Epoch 29; Iter   424/ 1097] train: loss: 0.0500060
[Epoch 29; Iter   454/ 1097] train: loss: 0.1388420
[Epoch 29; Iter   484/ 1097] train: loss: 0.0208813
[Epoch 29; Iter   514/ 1097] train: loss: 0.0257350
[Epoch 29; Iter   544/ 1097] train: loss: 0.0303725
[Epoch 29; Iter   574/ 1097] train: loss: 0.0196918
[Epoch 29; Iter   604/ 1097] train: loss: 0.0587029
[Epoch 29; Iter   634/ 1097] train: loss: 0.1319624
[Epoch 29; Iter   664/ 1097] train: loss: 0.0399302
[Epoch 29; Iter   694/ 1097] train: loss: 0.3508860
[Epoch 29; Iter   724/ 1097] train: loss: 0.0564471
[Epoch 29; Iter   754/ 1097] train: loss: 0.0276665
[Epoch 29; Iter   784/ 1097] train: loss: 0.0396577
[Epoch 29; Iter   814/ 1097] train: loss: 0.0667021
[Epoch 29; Iter   844/ 1097] train: loss: 0.1901926
[Epoch 29; Iter   874/ 1097] train: loss: 0.0290564
[Epoch 29; Iter   904/ 1097] train: loss: 0.1518511
[Epoch 29; Iter   934/ 1097] train: loss: 0.0906048
[Epoch 29; Iter   964/ 1097] train: loss: 0.0257397
[Epoch 29; Iter   994/ 1097] train: loss: 0.3089812
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0266817
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0196904
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0575016
[Epoch 29] ogbg-molhiv: 0.798476 val loss: 0.408826
[Epoch 29] ogbg-molhiv: 0.731731 test loss: 0.363330
[Epoch 30; Iter    17/ 1097] train: loss: 0.0268899
[Epoch 30; Iter    47/ 1097] train: loss: 0.0236887
[Epoch 30; Iter    77/ 1097] train: loss: 0.1535723
[Epoch 30; Iter   107/ 1097] train: loss: 0.0326274
[Epoch 30; Iter   137/ 1097] train: loss: 0.0585455
[Epoch 30; Iter   167/ 1097] train: loss: 0.0181119
[Epoch 30; Iter   197/ 1097] train: loss: 0.1346426
[Epoch 30; Iter   227/ 1097] train: loss: 0.0217510
[Epoch 30; Iter   257/ 1097] train: loss: 0.0533610
[Epoch 30; Iter   287/ 1097] train: loss: 0.0195810
[Epoch 30; Iter   317/ 1097] train: loss: 0.2490233
[Epoch 30; Iter   347/ 1097] train: loss: 0.0308451
[Epoch 30; Iter   377/ 1097] train: loss: 0.0174551
[Epoch 30; Iter   407/ 1097] train: loss: 0.0988517
[Epoch 30; Iter   437/ 1097] train: loss: 0.1581365
[Epoch 30; Iter   467/ 1097] train: loss: 0.0529511
[Epoch 30; Iter   497/ 1097] train: loss: 0.1301495
[Epoch 30; Iter   527/ 1097] train: loss: 0.0541922
[Epoch 30; Iter   557/ 1097] train: loss: 0.0989980
[Epoch 30; Iter   587/ 1097] train: loss: 0.0258507
[Epoch 30; Iter   617/ 1097] train: loss: 0.0622058
[Epoch 30; Iter   647/ 1097] train: loss: 0.1595221
[Epoch 30; Iter   677/ 1097] train: loss: 0.1019295
[Epoch 30; Iter   707/ 1097] train: loss: 0.0808552
[Epoch 30; Iter   737/ 1097] train: loss: 0.0222635
[Epoch 30; Iter   767/ 1097] train: loss: 0.0152073
[Epoch 30; Iter   797/ 1097] train: loss: 0.0539787
[Epoch 30; Iter   827/ 1097] train: loss: 0.1214440
[Epoch 30; Iter   857/ 1097] train: loss: 0.0265994
[Epoch 30; Iter   887/ 1097] train: loss: 0.0375436
[Epoch 30; Iter   917/ 1097] train: loss: 0.1829869
[Epoch 30; Iter   947/ 1097] train: loss: 0.0494467
[Epoch 30; Iter   977/ 1097] train: loss: 0.1551267
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0193692
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1229522
[Epoch 30; Iter  1067/ 1097] train: loss: 0.1731041
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0236817
[Epoch 30] ogbg-molhiv: 0.822313 val loss: 0.344417
[Epoch 30] ogbg-molhiv: 0.756048 test loss: 0.756832
[Epoch 31; Iter    30/ 1097] train: loss: 0.0627167
[Epoch 31; Iter    60/ 1097] train: loss: 0.1270743
[Epoch 31; Iter    90/ 1097] train: loss: 0.0527254
[Epoch 31; Iter   120/ 1097] train: loss: 0.0292773
[Epoch 31; Iter   150/ 1097] train: loss: 0.1280293
[Epoch 31; Iter   180/ 1097] train: loss: 0.0205764
[Epoch 31; Iter   210/ 1097] train: loss: 0.0444984
[Epoch 31; Iter   240/ 1097] train: loss: 0.0216860
[Epoch 31; Iter   270/ 1097] train: loss: 0.0730147
[Epoch 31; Iter   300/ 1097] train: loss: 0.0425600
[Epoch 31; Iter   330/ 1097] train: loss: 0.1145478
[Epoch 31; Iter   360/ 1097] train: loss: 0.1030971
[Epoch 31; Iter   390/ 1097] train: loss: 0.1589075
[Epoch 31; Iter   420/ 1097] train: loss: 0.0296421
[Epoch 31; Iter   450/ 1097] train: loss: 0.0632339
[Epoch 31; Iter   480/ 1097] train: loss: 0.1056252
[Epoch 31; Iter   510/ 1097] train: loss: 0.0197050
[Epoch 31; Iter   540/ 1097] train: loss: 0.0280560
[Epoch 31; Iter   570/ 1097] train: loss: 0.1354678
[Epoch 31; Iter   600/ 1097] train: loss: 0.0328126
[Epoch 31; Iter   630/ 1097] train: loss: 0.0445946
[Epoch 31; Iter   660/ 1097] train: loss: 0.1594609
[Epoch 31; Iter   690/ 1097] train: loss: 0.0347806
[Epoch 31; Iter   720/ 1097] train: loss: 0.0282589
[Epoch 31; Iter   750/ 1097] train: loss: 0.0627579
[Epoch 31; Iter   780/ 1097] train: loss: 0.0227363
[Epoch 31; Iter   810/ 1097] train: loss: 0.0288632
[Epoch 31; Iter   840/ 1097] train: loss: 0.0479118
[Epoch 31; Iter   870/ 1097] train: loss: 0.0532890
[Epoch 31; Iter   900/ 1097] train: loss: 0.0298296
[Epoch 31; Iter   930/ 1097] train: loss: 0.2098057
[Epoch 31; Iter   960/ 1097] train: loss: 0.0186381
[Epoch 31; Iter   990/ 1097] train: loss: 0.0395992
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0352203
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0176330
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2028577
[Epoch 31] ogbg-molhiv: 0.817053 val loss: 0.278094
[Epoch 31] ogbg-molhiv: 0.736625 test loss: 0.308103
[Epoch 32; Iter    13/ 1097] train: loss: 0.1001581
[Epoch 32; Iter    43/ 1097] train: loss: 0.4139540
[Epoch 32; Iter    73/ 1097] train: loss: 0.1390442
[Epoch 32; Iter   103/ 1097] train: loss: 0.0320742
[Epoch 32; Iter   133/ 1097] train: loss: 0.0173517
[Epoch 32; Iter   163/ 1097] train: loss: 0.0244202
[Epoch 32; Iter   193/ 1097] train: loss: 0.0457846
[Epoch 32; Iter   223/ 1097] train: loss: 0.0208611
[Epoch 32; Iter   253/ 1097] train: loss: 0.0662841
[Epoch 32; Iter   283/ 1097] train: loss: 0.0346832
[Epoch 32; Iter   313/ 1097] train: loss: 0.2059423
[Epoch 32; Iter   343/ 1097] train: loss: 0.1282786
[Epoch 32; Iter   373/ 1097] train: loss: 0.1247064
[Epoch 32; Iter   403/ 1097] train: loss: 0.0467254
[Epoch 32; Iter   433/ 1097] train: loss: 0.0158976
[Epoch 32; Iter   463/ 1097] train: loss: 0.2203214
[Epoch 32; Iter   493/ 1097] train: loss: 0.0160333
[Epoch 32; Iter   523/ 1097] train: loss: 0.0233771
[Epoch 28; Iter   471/ 1097] train: loss: 0.0384799
[Epoch 28; Iter   501/ 1097] train: loss: 0.1766954
[Epoch 28; Iter   531/ 1097] train: loss: 0.0188091
[Epoch 28; Iter   561/ 1097] train: loss: 0.0847957
[Epoch 28; Iter   591/ 1097] train: loss: 0.1755349
[Epoch 28; Iter   621/ 1097] train: loss: 0.0969751
[Epoch 28; Iter   651/ 1097] train: loss: 0.0660566
[Epoch 28; Iter   681/ 1097] train: loss: 0.0263513
[Epoch 28; Iter   711/ 1097] train: loss: 0.0620240
[Epoch 28; Iter   741/ 1097] train: loss: 0.0205688
[Epoch 28; Iter   771/ 1097] train: loss: 0.0854562
[Epoch 28; Iter   801/ 1097] train: loss: 0.0178744
[Epoch 28; Iter   831/ 1097] train: loss: 0.0208023
[Epoch 28; Iter   861/ 1097] train: loss: 0.2435906
[Epoch 28; Iter   891/ 1097] train: loss: 0.0817296
[Epoch 28; Iter   921/ 1097] train: loss: 0.0640845
[Epoch 28; Iter   951/ 1097] train: loss: 0.0697260
[Epoch 28; Iter   981/ 1097] train: loss: 0.0332591
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0184192
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0244018
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0330128
[Epoch 28] ogbg-molhiv: 0.813670 val loss: 0.082619
[Epoch 28] ogbg-molhiv: 0.772979 test loss: 0.118925
[Epoch 29; Iter     4/ 1097] train: loss: 0.0175832
[Epoch 29; Iter    34/ 1097] train: loss: 0.0332851
[Epoch 29; Iter    64/ 1097] train: loss: 0.0522397
[Epoch 29; Iter    94/ 1097] train: loss: 0.0408491
[Epoch 29; Iter   124/ 1097] train: loss: 0.0935524
[Epoch 29; Iter   154/ 1097] train: loss: 0.1675136
[Epoch 29; Iter   184/ 1097] train: loss: 0.0205510
[Epoch 29; Iter   214/ 1097] train: loss: 0.0212766
[Epoch 29; Iter   244/ 1097] train: loss: 0.0391366
[Epoch 29; Iter   274/ 1097] train: loss: 0.0191421
[Epoch 29; Iter   304/ 1097] train: loss: 0.1483885
[Epoch 29; Iter   334/ 1097] train: loss: 0.0655554
[Epoch 29; Iter   364/ 1097] train: loss: 0.0356821
[Epoch 29; Iter   394/ 1097] train: loss: 0.0630953
[Epoch 29; Iter   424/ 1097] train: loss: 0.0569472
[Epoch 29; Iter   454/ 1097] train: loss: 0.0330405
[Epoch 29; Iter   484/ 1097] train: loss: 0.1179802
[Epoch 29; Iter   514/ 1097] train: loss: 0.0750402
[Epoch 29; Iter   544/ 1097] train: loss: 0.0321182
[Epoch 29; Iter   574/ 1097] train: loss: 0.0301684
[Epoch 29; Iter   604/ 1097] train: loss: 0.1768723
[Epoch 29; Iter   634/ 1097] train: loss: 0.2013478
[Epoch 29; Iter   664/ 1097] train: loss: 0.0288012
[Epoch 29; Iter   694/ 1097] train: loss: 0.0325358
[Epoch 29; Iter   724/ 1097] train: loss: 0.0369602
[Epoch 29; Iter   754/ 1097] train: loss: 0.0524322
[Epoch 29; Iter   784/ 1097] train: loss: 0.0650270
[Epoch 29; Iter   814/ 1097] train: loss: 0.0263018
[Epoch 29; Iter   844/ 1097] train: loss: 0.0480929
[Epoch 29; Iter   874/ 1097] train: loss: 0.3547775
[Epoch 29; Iter   904/ 1097] train: loss: 0.0364691
[Epoch 29; Iter   934/ 1097] train: loss: 0.2506530
[Epoch 29; Iter   964/ 1097] train: loss: 0.0440675
[Epoch 29; Iter   994/ 1097] train: loss: 0.0721978
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0329087
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0319826
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0210934
[Epoch 29] ogbg-molhiv: 0.815292 val loss: 0.075031
[Epoch 29] ogbg-molhiv: 0.771417 test loss: 0.120407
[Epoch 30; Iter    17/ 1097] train: loss: 0.0620891
[Epoch 30; Iter    47/ 1097] train: loss: 0.2107285
[Epoch 30; Iter    77/ 1097] train: loss: 0.0830793
[Epoch 30; Iter   107/ 1097] train: loss: 0.0670397
[Epoch 30; Iter   137/ 1097] train: loss: 0.2428737
[Epoch 30; Iter   167/ 1097] train: loss: 0.0195268
[Epoch 30; Iter   197/ 1097] train: loss: 0.0311663
[Epoch 30; Iter   227/ 1097] train: loss: 0.0469832
[Epoch 30; Iter   257/ 1097] train: loss: 0.0849658
[Epoch 30; Iter   287/ 1097] train: loss: 0.0363216
[Epoch 30; Iter   317/ 1097] train: loss: 0.1093249
[Epoch 30; Iter   347/ 1097] train: loss: 0.1060651
[Epoch 30; Iter   377/ 1097] train: loss: 0.0861079
[Epoch 30; Iter   407/ 1097] train: loss: 0.0407219
[Epoch 30; Iter   437/ 1097] train: loss: 0.0413578
[Epoch 30; Iter   467/ 1097] train: loss: 0.0157119
[Epoch 30; Iter   497/ 1097] train: loss: 0.0602702
[Epoch 30; Iter   527/ 1097] train: loss: 0.1577114
[Epoch 30; Iter   557/ 1097] train: loss: 0.1729195
[Epoch 30; Iter   587/ 1097] train: loss: 0.0496427
[Epoch 30; Iter   617/ 1097] train: loss: 0.0204297
[Epoch 30; Iter   647/ 1097] train: loss: 0.0129249
[Epoch 30; Iter   677/ 1097] train: loss: 0.2396065
[Epoch 30; Iter   707/ 1097] train: loss: 0.1478944
[Epoch 30; Iter   737/ 1097] train: loss: 0.0685880
[Epoch 30; Iter   767/ 1097] train: loss: 0.0231376
[Epoch 30; Iter   797/ 1097] train: loss: 0.2701673
[Epoch 30; Iter   827/ 1097] train: loss: 0.3001040
[Epoch 30; Iter   857/ 1097] train: loss: 0.1592291
[Epoch 30; Iter   887/ 1097] train: loss: 0.0682144
[Epoch 30; Iter   917/ 1097] train: loss: 0.2029456
[Epoch 30; Iter   947/ 1097] train: loss: 0.0480159
[Epoch 30; Iter   977/ 1097] train: loss: 0.0912747
[Epoch 30; Iter  1007/ 1097] train: loss: 0.1230386
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1104262
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0391724
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0170708
[Epoch 30] ogbg-molhiv: 0.826294 val loss: 0.074875
[Epoch 30] ogbg-molhiv: 0.758271 test loss: 0.255844
[Epoch 31; Iter    30/ 1097] train: loss: 0.1171868
[Epoch 31; Iter    60/ 1097] train: loss: 0.1531885
[Epoch 31; Iter    90/ 1097] train: loss: 0.0154826
[Epoch 31; Iter   120/ 1097] train: loss: 0.0299095
[Epoch 31; Iter   150/ 1097] train: loss: 0.2857468
[Epoch 31; Iter   180/ 1097] train: loss: 0.0504216
[Epoch 31; Iter   210/ 1097] train: loss: 0.0198135
[Epoch 31; Iter   240/ 1097] train: loss: 0.0801231
[Epoch 31; Iter   270/ 1097] train: loss: 0.1586810
[Epoch 31; Iter   300/ 1097] train: loss: 0.0663582
[Epoch 31; Iter   330/ 1097] train: loss: 0.0797446
[Epoch 31; Iter   360/ 1097] train: loss: 0.0941245
[Epoch 31; Iter   390/ 1097] train: loss: 0.1209531
[Epoch 31; Iter   420/ 1097] train: loss: 0.1519430
[Epoch 31; Iter   450/ 1097] train: loss: 0.0318714
[Epoch 31; Iter   480/ 1097] train: loss: 0.1354437
[Epoch 31; Iter   510/ 1097] train: loss: 0.0270908
[Epoch 31; Iter   540/ 1097] train: loss: 0.1630533
[Epoch 31; Iter   570/ 1097] train: loss: 0.1906020
[Epoch 31; Iter   600/ 1097] train: loss: 0.0110202
[Epoch 31; Iter   630/ 1097] train: loss: 0.0557800
[Epoch 31; Iter   660/ 1097] train: loss: 0.0714119
[Epoch 31; Iter   690/ 1097] train: loss: 0.0370853
[Epoch 31; Iter   720/ 1097] train: loss: 0.0191029
[Epoch 31; Iter   750/ 1097] train: loss: 0.0120441
[Epoch 31; Iter   780/ 1097] train: loss: 0.0702120
[Epoch 31; Iter   810/ 1097] train: loss: 0.0261624
[Epoch 31; Iter   840/ 1097] train: loss: 0.1167311
[Epoch 31; Iter   870/ 1097] train: loss: 0.1438636
[Epoch 31; Iter   900/ 1097] train: loss: 0.0292195
[Epoch 31; Iter   930/ 1097] train: loss: 0.0469123
[Epoch 31; Iter   960/ 1097] train: loss: 0.0510975
[Epoch 31; Iter   990/ 1097] train: loss: 0.1766870
[Epoch 31; Iter  1020/ 1097] train: loss: 0.2103628
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1905220
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0274690
[Epoch 31] ogbg-molhiv: 0.816049 val loss: 0.091687
[Epoch 31] ogbg-molhiv: 0.748655 test loss: 0.205594
[Epoch 32; Iter    13/ 1097] train: loss: 0.0167781
[Epoch 32; Iter    43/ 1097] train: loss: 0.1279634
[Epoch 32; Iter    73/ 1097] train: loss: 0.0211922
[Epoch 32; Iter   103/ 1097] train: loss: 0.0226440
[Epoch 32; Iter   133/ 1097] train: loss: 0.0250937
[Epoch 32; Iter   163/ 1097] train: loss: 0.0838292
[Epoch 32; Iter   193/ 1097] train: loss: 0.1302868
[Epoch 32; Iter   223/ 1097] train: loss: 0.0532850
[Epoch 32; Iter   253/ 1097] train: loss: 0.0516591
[Epoch 32; Iter   283/ 1097] train: loss: 0.0164326
[Epoch 32; Iter   313/ 1097] train: loss: 0.0340869
[Epoch 32; Iter   343/ 1097] train: loss: 0.0997767
[Epoch 32; Iter   373/ 1097] train: loss: 0.1923041
[Epoch 32; Iter   403/ 1097] train: loss: 0.0321680
[Epoch 32; Iter   433/ 1097] train: loss: 0.0113327
[Epoch 32; Iter   463/ 1097] train: loss: 0.2309390
[Epoch 32; Iter   493/ 1097] train: loss: 0.0713995
[Epoch 32; Iter   523/ 1097] train: loss: 0.2380617
[Epoch 36; Iter   605/ 1097] train: loss: 0.0130137
[Epoch 36; Iter   635/ 1097] train: loss: 0.0869195
[Epoch 36; Iter   665/ 1097] train: loss: 0.0046615
[Epoch 36; Iter   695/ 1097] train: loss: 0.0535695
[Epoch 36; Iter   725/ 1097] train: loss: 0.0073117
[Epoch 36; Iter   755/ 1097] train: loss: 0.0058591
[Epoch 36; Iter   785/ 1097] train: loss: 0.0052990
[Epoch 36; Iter   815/ 1097] train: loss: 0.0074471
[Epoch 36; Iter   845/ 1097] train: loss: 0.0077430
[Epoch 36; Iter   875/ 1097] train: loss: 0.0077727
[Epoch 36; Iter   905/ 1097] train: loss: 0.1166744
[Epoch 36; Iter   935/ 1097] train: loss: 0.0054795
[Epoch 36; Iter   965/ 1097] train: loss: 0.0687992
[Epoch 36; Iter   995/ 1097] train: loss: 0.0032712
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0144650
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1017088
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1108657
[Epoch 36] ogbg-molhiv: 0.819876 val loss: 1.000396
[Epoch 36] ogbg-molhiv: 0.748898 test loss: 0.442057
[Epoch 37; Iter    18/ 1097] train: loss: 0.0289143
[Epoch 37; Iter    48/ 1097] train: loss: 0.0112895
[Epoch 37; Iter    78/ 1097] train: loss: 0.0041064
[Epoch 37; Iter   108/ 1097] train: loss: 0.0249179
[Epoch 37; Iter   138/ 1097] train: loss: 0.0014554
[Epoch 37; Iter   168/ 1097] train: loss: 0.0041529
[Epoch 37; Iter   198/ 1097] train: loss: 0.0090730
[Epoch 37; Iter   228/ 1097] train: loss: 0.0036448
[Epoch 37; Iter   258/ 1097] train: loss: 0.0018781
[Epoch 37; Iter   288/ 1097] train: loss: 0.0116982
[Epoch 37; Iter   318/ 1097] train: loss: 0.0030326
[Epoch 37; Iter   348/ 1097] train: loss: 0.0109236
[Epoch 37; Iter   378/ 1097] train: loss: 0.1984905
[Epoch 37; Iter   408/ 1097] train: loss: 0.1571753
[Epoch 37; Iter   438/ 1097] train: loss: 0.1795404
[Epoch 37; Iter   468/ 1097] train: loss: 0.0134796
[Epoch 37; Iter   498/ 1097] train: loss: 0.0240332
[Epoch 37; Iter   528/ 1097] train: loss: 0.0036707
[Epoch 37; Iter   558/ 1097] train: loss: 0.0016479
[Epoch 37; Iter   588/ 1097] train: loss: 0.0052696
[Epoch 37; Iter   618/ 1097] train: loss: 0.0035967
[Epoch 37; Iter   648/ 1097] train: loss: 0.0123941
[Epoch 37; Iter   678/ 1097] train: loss: 0.0161778
[Epoch 37; Iter   708/ 1097] train: loss: 0.0027734
[Epoch 37; Iter   738/ 1097] train: loss: 0.0155008
[Epoch 37; Iter   768/ 1097] train: loss: 0.0007645
[Epoch 37; Iter   798/ 1097] train: loss: 0.1720078
[Epoch 37; Iter   828/ 1097] train: loss: 0.0010693
[Epoch 37; Iter   858/ 1097] train: loss: 0.0042820
[Epoch 37; Iter   888/ 1097] train: loss: 0.0058390
[Epoch 37; Iter   918/ 1097] train: loss: 0.1592201
[Epoch 37; Iter   948/ 1097] train: loss: 0.0141010
[Epoch 37; Iter   978/ 1097] train: loss: 0.1038633
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0029290
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0237838
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0093882
[Epoch 37] ogbg-molhiv: 0.845224 val loss: 0.919073
[Epoch 37] ogbg-molhiv: 0.734190 test loss: 0.202772
[Epoch 38; Iter     1/ 1097] train: loss: 0.0008892
[Epoch 38; Iter    31/ 1097] train: loss: 0.0053208
[Epoch 38; Iter    61/ 1097] train: loss: 0.0234094
[Epoch 38; Iter    91/ 1097] train: loss: 0.0011430
[Epoch 38; Iter   121/ 1097] train: loss: 0.0054191
[Epoch 38; Iter   151/ 1097] train: loss: 0.0050958
[Epoch 38; Iter   181/ 1097] train: loss: 0.0983222
[Epoch 38; Iter   211/ 1097] train: loss: 0.0121080
[Epoch 38; Iter   241/ 1097] train: loss: 0.0044562
[Epoch 38; Iter   271/ 1097] train: loss: 0.0357078
[Epoch 38; Iter   301/ 1097] train: loss: 0.0040713
[Epoch 38; Iter   331/ 1097] train: loss: 0.0455135
[Epoch 38; Iter   361/ 1097] train: loss: 0.0428058
[Epoch 38; Iter   391/ 1097] train: loss: 0.0082402
[Epoch 38; Iter   421/ 1097] train: loss: 0.0519647
[Epoch 38; Iter   451/ 1097] train: loss: 0.0033920
[Epoch 38; Iter   481/ 1097] train: loss: 0.0973710
[Epoch 38; Iter   511/ 1097] train: loss: 0.0072513
[Epoch 38; Iter   541/ 1097] train: loss: 0.0594580
[Epoch 38; Iter   571/ 1097] train: loss: 0.0754594
[Epoch 38; Iter   601/ 1097] train: loss: 0.0583338
[Epoch 38; Iter   631/ 1097] train: loss: 0.0667265
[Epoch 38; Iter   661/ 1097] train: loss: 0.0074828
[Epoch 38; Iter   691/ 1097] train: loss: 0.0040040
[Epoch 38; Iter   721/ 1097] train: loss: 0.0963893
[Epoch 38; Iter   751/ 1097] train: loss: 0.0048408
[Epoch 38; Iter   781/ 1097] train: loss: 0.0045251
[Epoch 38; Iter   811/ 1097] train: loss: 0.0067531
[Epoch 38; Iter   841/ 1097] train: loss: 0.1676376
[Epoch 38; Iter   871/ 1097] train: loss: 0.0106753
[Epoch 38; Iter   901/ 1097] train: loss: 0.0086509
[Epoch 38; Iter   931/ 1097] train: loss: 0.0064488
[Epoch 38; Iter   961/ 1097] train: loss: 0.0056377
[Epoch 38; Iter   991/ 1097] train: loss: 0.0082741
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0085704
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0295181
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0216412
[Epoch 38] ogbg-molhiv: 0.809809 val loss: 1.272410
[Epoch 38] ogbg-molhiv: 0.751113 test loss: 0.501995
[Epoch 39; Iter    14/ 1097] train: loss: 0.0331013
[Epoch 39; Iter    44/ 1097] train: loss: 0.0628601
[Epoch 39; Iter    74/ 1097] train: loss: 0.0038630
[Epoch 39; Iter   104/ 1097] train: loss: 0.0154730
[Epoch 39; Iter   134/ 1097] train: loss: 0.0071692
[Epoch 39; Iter   164/ 1097] train: loss: 0.0908856
[Epoch 39; Iter   194/ 1097] train: loss: 0.0037478
[Epoch 39; Iter   224/ 1097] train: loss: 0.0254128
[Epoch 39; Iter   254/ 1097] train: loss: 0.0349821
[Epoch 39; Iter   284/ 1097] train: loss: 0.0105789
[Epoch 39; Iter   314/ 1097] train: loss: 0.0010880
[Epoch 39; Iter   344/ 1097] train: loss: 0.0016447
[Epoch 39; Iter   374/ 1097] train: loss: 0.0006115
[Epoch 39; Iter   404/ 1097] train: loss: 0.0055356
[Epoch 39; Iter   434/ 1097] train: loss: 0.0009469
[Epoch 39; Iter   464/ 1097] train: loss: 0.0096100
[Epoch 39; Iter   494/ 1097] train: loss: 0.0583590
[Epoch 39; Iter   524/ 1097] train: loss: 0.0115281
[Epoch 39; Iter   554/ 1097] train: loss: 0.0056207
[Epoch 39; Iter   584/ 1097] train: loss: 0.0305817
[Epoch 39; Iter   614/ 1097] train: loss: 0.0004647
[Epoch 39; Iter   644/ 1097] train: loss: 0.0047292
[Epoch 39; Iter   674/ 1097] train: loss: 0.0301066
[Epoch 39; Iter   704/ 1097] train: loss: 0.0235126
[Epoch 39; Iter   734/ 1097] train: loss: 0.0046766
[Epoch 39; Iter   764/ 1097] train: loss: 0.0137351
[Epoch 39; Iter   794/ 1097] train: loss: 0.1312474
[Epoch 39; Iter   824/ 1097] train: loss: 0.0153716
[Epoch 39; Iter   854/ 1097] train: loss: 0.0031975
[Epoch 39; Iter   884/ 1097] train: loss: 0.0052628
[Epoch 39; Iter   914/ 1097] train: loss: 0.0036513
[Epoch 39; Iter   944/ 1097] train: loss: 0.0118459
[Epoch 39; Iter   974/ 1097] train: loss: 0.0610732
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0586968
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0027675
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0023794
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0055708
[Epoch 39] ogbg-molhiv: 0.808051 val loss: 1.772778
[Epoch 39] ogbg-molhiv: 0.713515 test loss: 0.533916
[Epoch 40; Iter    27/ 1097] train: loss: 0.0125693
[Epoch 40; Iter    57/ 1097] train: loss: 0.0256654
[Epoch 40; Iter    87/ 1097] train: loss: 0.0415781
[Epoch 40; Iter   117/ 1097] train: loss: 0.0220911
[Epoch 40; Iter   147/ 1097] train: loss: 0.0002115
[Epoch 40; Iter   177/ 1097] train: loss: 0.0091283
[Epoch 40; Iter   207/ 1097] train: loss: 0.0086136
[Epoch 40; Iter   237/ 1097] train: loss: 0.0035154
[Epoch 40; Iter   267/ 1097] train: loss: 0.0382336
[Epoch 40; Iter   297/ 1097] train: loss: 0.0060635
[Epoch 40; Iter   327/ 1097] train: loss: 0.0084605
[Epoch 40; Iter   357/ 1097] train: loss: 0.0091414
[Epoch 40; Iter   387/ 1097] train: loss: 0.0309904
[Epoch 40; Iter   417/ 1097] train: loss: 0.0065668
[Epoch 40; Iter   447/ 1097] train: loss: 0.1421275
[Epoch 40; Iter   477/ 1097] train: loss: 0.0135527
[Epoch 40; Iter   507/ 1097] train: loss: 0.0011938
[Epoch 40; Iter   537/ 1097] train: loss: 0.0255217
[Epoch 40; Iter   567/ 1097] train: loss: 0.0081295
[Epoch 40; Iter   597/ 1097] train: loss: 0.0222796
[Epoch 40; Iter   627/ 1097] train: loss: 0.0019808
[Epoch 40; Iter   657/ 1097] train: loss: 0.0015981
[Epoch 36; Iter   605/ 1097] train: loss: 0.0818598
[Epoch 36; Iter   635/ 1097] train: loss: 0.0569434
[Epoch 36; Iter   665/ 1097] train: loss: 0.0067651
[Epoch 36; Iter   695/ 1097] train: loss: 0.0692919
[Epoch 36; Iter   725/ 1097] train: loss: 0.0164766
[Epoch 36; Iter   755/ 1097] train: loss: 0.0011491
[Epoch 36; Iter   785/ 1097] train: loss: 0.0363702
[Epoch 36; Iter   815/ 1097] train: loss: 0.0202364
[Epoch 36; Iter   845/ 1097] train: loss: 0.0589168
[Epoch 36; Iter   875/ 1097] train: loss: 0.0051537
[Epoch 36; Iter   905/ 1097] train: loss: 0.0031719
[Epoch 36; Iter   935/ 1097] train: loss: 0.0249157
[Epoch 36; Iter   965/ 1097] train: loss: 0.0296477
[Epoch 36; Iter   995/ 1097] train: loss: 0.0357785
[Epoch 36; Iter  1025/ 1097] train: loss: 0.3454093
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0155586
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0043271
[Epoch 36] ogbg-molhiv: 0.789003 val loss: 0.377447
[Epoch 36] ogbg-molhiv: 0.668226 test loss: 0.371152
[Epoch 37; Iter    18/ 1097] train: loss: 0.0107088
[Epoch 37; Iter    48/ 1097] train: loss: 0.0122081
[Epoch 37; Iter    78/ 1097] train: loss: 0.0440037
[Epoch 37; Iter   108/ 1097] train: loss: 0.0073546
[Epoch 37; Iter   138/ 1097] train: loss: 0.0049339
[Epoch 37; Iter   168/ 1097] train: loss: 0.1199846
[Epoch 37; Iter   198/ 1097] train: loss: 0.0166213
[Epoch 37; Iter   228/ 1097] train: loss: 0.0074530
[Epoch 37; Iter   258/ 1097] train: loss: 0.0528119
[Epoch 37; Iter   288/ 1097] train: loss: 0.0208881
[Epoch 37; Iter   318/ 1097] train: loss: 0.0645030
[Epoch 37; Iter   348/ 1097] train: loss: 0.0218595
[Epoch 37; Iter   378/ 1097] train: loss: 0.0081195
[Epoch 37; Iter   408/ 1097] train: loss: 0.0087043
[Epoch 37; Iter   438/ 1097] train: loss: 0.0047188
[Epoch 37; Iter   468/ 1097] train: loss: 0.0049767
[Epoch 37; Iter   498/ 1097] train: loss: 0.0016978
[Epoch 37; Iter   528/ 1097] train: loss: 0.1403403
[Epoch 37; Iter   558/ 1097] train: loss: 0.1935827
[Epoch 37; Iter   588/ 1097] train: loss: 0.0361854
[Epoch 37; Iter   618/ 1097] train: loss: 0.0156786
[Epoch 37; Iter   648/ 1097] train: loss: 0.0083016
[Epoch 37; Iter   678/ 1097] train: loss: 0.0092242
[Epoch 37; Iter   708/ 1097] train: loss: 0.0084468
[Epoch 37; Iter   738/ 1097] train: loss: 0.0964786
[Epoch 37; Iter   768/ 1097] train: loss: 0.0180949
[Epoch 37; Iter   798/ 1097] train: loss: 0.0517555
[Epoch 37; Iter   828/ 1097] train: loss: 0.0026612
[Epoch 37; Iter   858/ 1097] train: loss: 0.0109186
[Epoch 37; Iter   888/ 1097] train: loss: 0.0306273
[Epoch 37; Iter   918/ 1097] train: loss: 0.2319668
[Epoch 37; Iter   948/ 1097] train: loss: 0.0589693
[Epoch 37; Iter   978/ 1097] train: loss: 0.0134634
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0085632
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0160558
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0209278
[Epoch 37] ogbg-molhiv: 0.773990 val loss: 0.260394
[Epoch 37] ogbg-molhiv: 0.686989 test loss: 0.337459
[Epoch 38; Iter     1/ 1097] train: loss: 0.1009587
[Epoch 38; Iter    31/ 1097] train: loss: 0.0062228
[Epoch 38; Iter    61/ 1097] train: loss: 0.0139873
[Epoch 38; Iter    91/ 1097] train: loss: 0.0116488
[Epoch 38; Iter   121/ 1097] train: loss: 0.0028512
[Epoch 38; Iter   151/ 1097] train: loss: 0.0067039
[Epoch 38; Iter   181/ 1097] train: loss: 0.0062741
[Epoch 38; Iter   211/ 1097] train: loss: 0.0052782
[Epoch 38; Iter   241/ 1097] train: loss: 0.0094361
[Epoch 38; Iter   271/ 1097] train: loss: 0.0239655
[Epoch 38; Iter   301/ 1097] train: loss: 0.0022204
[Epoch 38; Iter   331/ 1097] train: loss: 0.0171053
[Epoch 38; Iter   361/ 1097] train: loss: 0.0750356
[Epoch 38; Iter   391/ 1097] train: loss: 0.0507919
[Epoch 38; Iter   421/ 1097] train: loss: 0.0163205
[Epoch 38; Iter   451/ 1097] train: loss: 0.0493999
[Epoch 38; Iter   481/ 1097] train: loss: 0.0899849
[Epoch 38; Iter   511/ 1097] train: loss: 0.1793266
[Epoch 38; Iter   541/ 1097] train: loss: 0.0091772
[Epoch 38; Iter   571/ 1097] train: loss: 0.0049525
[Epoch 38; Iter   601/ 1097] train: loss: 0.0460688
[Epoch 38; Iter   631/ 1097] train: loss: 0.0017935
[Epoch 38; Iter   661/ 1097] train: loss: 0.0125550
[Epoch 38; Iter   691/ 1097] train: loss: 0.0077273
[Epoch 38; Iter   721/ 1097] train: loss: 0.0183031
[Epoch 38; Iter   751/ 1097] train: loss: 0.0730471
[Epoch 38; Iter   781/ 1097] train: loss: 0.0337462
[Epoch 38; Iter   811/ 1097] train: loss: 0.0011123
[Epoch 38; Iter   841/ 1097] train: loss: 0.0209689
[Epoch 38; Iter   871/ 1097] train: loss: 0.0098713
[Epoch 38; Iter   901/ 1097] train: loss: 0.0020596
[Epoch 38; Iter   931/ 1097] train: loss: 0.0074645
[Epoch 38; Iter   961/ 1097] train: loss: 0.0071144
[Epoch 38; Iter   991/ 1097] train: loss: 0.0236718
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0062507
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0037201
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0321038
[Epoch 38] ogbg-molhiv: 0.781388 val loss: 0.365329
[Epoch 38] ogbg-molhiv: 0.658337 test loss: 0.344205
[Epoch 39; Iter    14/ 1097] train: loss: 0.0430879
[Epoch 39; Iter    44/ 1097] train: loss: 0.0086903
[Epoch 39; Iter    74/ 1097] train: loss: 0.0049813
[Epoch 39; Iter   104/ 1097] train: loss: 0.0485257
[Epoch 39; Iter   134/ 1097] train: loss: 0.0119666
[Epoch 39; Iter   164/ 1097] train: loss: 0.0041774
[Epoch 39; Iter   194/ 1097] train: loss: 0.0240049
[Epoch 39; Iter   224/ 1097] train: loss: 0.0027421
[Epoch 39; Iter   254/ 1097] train: loss: 0.0036595
[Epoch 39; Iter   284/ 1097] train: loss: 0.0006922
[Epoch 39; Iter   314/ 1097] train: loss: 0.0464829
[Epoch 39; Iter   344/ 1097] train: loss: 0.0936364
[Epoch 39; Iter   374/ 1097] train: loss: 0.0215660
[Epoch 39; Iter   404/ 1097] train: loss: 0.0021526
[Epoch 39; Iter   434/ 1097] train: loss: 0.0059971
[Epoch 39; Iter   464/ 1097] train: loss: 0.0059424
[Epoch 39; Iter   494/ 1097] train: loss: 0.0071059
[Epoch 39; Iter   524/ 1097] train: loss: 0.0165964
[Epoch 39; Iter   554/ 1097] train: loss: 0.0065138
[Epoch 39; Iter   584/ 1097] train: loss: 0.0096194
[Epoch 39; Iter   614/ 1097] train: loss: 0.0099703
[Epoch 39; Iter   644/ 1097] train: loss: 0.0048765
[Epoch 39; Iter   674/ 1097] train: loss: 0.0248649
[Epoch 39; Iter   704/ 1097] train: loss: 0.0059202
[Epoch 39; Iter   734/ 1097] train: loss: 0.0957902
[Epoch 39; Iter   764/ 1097] train: loss: 0.0548223
[Epoch 39; Iter   794/ 1097] train: loss: 0.0838560
[Epoch 39; Iter   824/ 1097] train: loss: 0.0066727
[Epoch 39; Iter   854/ 1097] train: loss: 0.1079897
[Epoch 39; Iter   884/ 1097] train: loss: 0.0041464
[Epoch 39; Iter   914/ 1097] train: loss: 0.0042964
[Epoch 39; Iter   944/ 1097] train: loss: 0.0675182
[Epoch 39; Iter   974/ 1097] train: loss: 0.0019595
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0261606
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0023315
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0114633
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0261399
[Epoch 39] ogbg-molhiv: 0.779434 val loss: 0.609046
[Epoch 39] ogbg-molhiv: 0.697514 test loss: 0.339764
[Epoch 40; Iter    27/ 1097] train: loss: 0.0022517
[Epoch 40; Iter    57/ 1097] train: loss: 0.0116708
[Epoch 40; Iter    87/ 1097] train: loss: 0.0153890
[Epoch 40; Iter   117/ 1097] train: loss: 0.0116190
[Epoch 40; Iter   147/ 1097] train: loss: 0.0064637
[Epoch 40; Iter   177/ 1097] train: loss: 0.0108575
[Epoch 40; Iter   207/ 1097] train: loss: 0.0100738
[Epoch 40; Iter   237/ 1097] train: loss: 0.0043737
[Epoch 40; Iter   267/ 1097] train: loss: 0.0065997
[Epoch 40; Iter   297/ 1097] train: loss: 0.0335491
[Epoch 40; Iter   327/ 1097] train: loss: 0.0835474
[Epoch 40; Iter   357/ 1097] train: loss: 0.0195645
[Epoch 40; Iter   387/ 1097] train: loss: 0.0418559
[Epoch 40; Iter   417/ 1097] train: loss: 0.0228962
[Epoch 40; Iter   447/ 1097] train: loss: 0.0048306
[Epoch 40; Iter   477/ 1097] train: loss: 0.0011820
[Epoch 40; Iter   507/ 1097] train: loss: 0.0025836
[Epoch 40; Iter   537/ 1097] train: loss: 0.0400084
[Epoch 40; Iter   567/ 1097] train: loss: 0.0123658
[Epoch 40; Iter   597/ 1097] train: loss: 0.0462019
[Epoch 40; Iter   627/ 1097] train: loss: 0.0050042
[Epoch 40; Iter   657/ 1097] train: loss: 0.0023980
[Epoch 36; Iter   605/ 1097] train: loss: 0.0209632
[Epoch 36; Iter   635/ 1097] train: loss: 0.0013716
[Epoch 36; Iter   665/ 1097] train: loss: 0.0452417
[Epoch 36; Iter   695/ 1097] train: loss: 0.1327697
[Epoch 36; Iter   725/ 1097] train: loss: 0.0028777
[Epoch 36; Iter   755/ 1097] train: loss: 0.0136581
[Epoch 36; Iter   785/ 1097] train: loss: 0.0094759
[Epoch 36; Iter   815/ 1097] train: loss: 0.0082011
[Epoch 36; Iter   845/ 1097] train: loss: 0.0016147
[Epoch 36; Iter   875/ 1097] train: loss: 0.0085299
[Epoch 36; Iter   905/ 1097] train: loss: 0.0008584
[Epoch 36; Iter   935/ 1097] train: loss: 0.0848025
[Epoch 36; Iter   965/ 1097] train: loss: 0.0200443
[Epoch 36; Iter   995/ 1097] train: loss: 0.1318757
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0358457
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0654779
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0071354
[Epoch 36] ogbg-molhiv: 0.810614 val loss: 0.276002
[Epoch 36] ogbg-molhiv: 0.704374 test loss: 0.347240
[Epoch 37; Iter    18/ 1097] train: loss: 0.0053113
[Epoch 37; Iter    48/ 1097] train: loss: 0.0290377
[Epoch 37; Iter    78/ 1097] train: loss: 0.0093606
[Epoch 37; Iter   108/ 1097] train: loss: 0.0899851
[Epoch 37; Iter   138/ 1097] train: loss: 0.0263544
[Epoch 37; Iter   168/ 1097] train: loss: 0.0163084
[Epoch 37; Iter   198/ 1097] train: loss: 0.0073490
[Epoch 37; Iter   228/ 1097] train: loss: 0.0063091
[Epoch 37; Iter   258/ 1097] train: loss: 0.0061351
[Epoch 37; Iter   288/ 1097] train: loss: 0.0544189
[Epoch 37; Iter   318/ 1097] train: loss: 0.0080020
[Epoch 37; Iter   348/ 1097] train: loss: 0.0074295
[Epoch 37; Iter   378/ 1097] train: loss: 0.0092280
[Epoch 37; Iter   408/ 1097] train: loss: 0.0100969
[Epoch 37; Iter   438/ 1097] train: loss: 0.0022912
[Epoch 37; Iter   468/ 1097] train: loss: 0.0094189
[Epoch 37; Iter   498/ 1097] train: loss: 0.0016587
[Epoch 37; Iter   528/ 1097] train: loss: 0.0030611
[Epoch 37; Iter   558/ 1097] train: loss: 0.0006298
[Epoch 37; Iter   588/ 1097] train: loss: 0.0156695
[Epoch 37; Iter   618/ 1097] train: loss: 0.0765389
[Epoch 37; Iter   648/ 1097] train: loss: 0.0011549
[Epoch 37; Iter   678/ 1097] train: loss: 0.0024300
[Epoch 37; Iter   708/ 1097] train: loss: 0.0065022
[Epoch 37; Iter   738/ 1097] train: loss: 0.0226670
[Epoch 37; Iter   768/ 1097] train: loss: 0.0103191
[Epoch 37; Iter   798/ 1097] train: loss: 0.0386558
[Epoch 37; Iter   828/ 1097] train: loss: 0.0050765
[Epoch 37; Iter   858/ 1097] train: loss: 0.0585286
[Epoch 37; Iter   888/ 1097] train: loss: 0.0336350
[Epoch 37; Iter   918/ 1097] train: loss: 0.0155192
[Epoch 37; Iter   948/ 1097] train: loss: 0.0839595
[Epoch 37; Iter   978/ 1097] train: loss: 0.0205103
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0013078
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0930551
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0377920
[Epoch 37] ogbg-molhiv: 0.804701 val loss: 0.186496
[Epoch 37] ogbg-molhiv: 0.716037 test loss: 0.239490
[Epoch 38; Iter     1/ 1097] train: loss: 0.0128591
[Epoch 38; Iter    31/ 1097] train: loss: 0.0086621
[Epoch 38; Iter    61/ 1097] train: loss: 0.0069138
[Epoch 38; Iter    91/ 1097] train: loss: 0.0035153
[Epoch 38; Iter   121/ 1097] train: loss: 0.0907955
[Epoch 38; Iter   151/ 1097] train: loss: 0.0016421
[Epoch 38; Iter   181/ 1097] train: loss: 0.0515209
[Epoch 38; Iter   211/ 1097] train: loss: 0.0042191
[Epoch 38; Iter   241/ 1097] train: loss: 0.0534152
[Epoch 38; Iter   271/ 1097] train: loss: 0.0046923
[Epoch 38; Iter   301/ 1097] train: loss: 0.0151099
[Epoch 38; Iter   331/ 1097] train: loss: 0.0266133
[Epoch 38; Iter   361/ 1097] train: loss: 0.0570882
[Epoch 38; Iter   391/ 1097] train: loss: 0.0102049
[Epoch 38; Iter   421/ 1097] train: loss: 0.0116803
[Epoch 38; Iter   451/ 1097] train: loss: 0.1391935
[Epoch 38; Iter   481/ 1097] train: loss: 0.1355972
[Epoch 38; Iter   511/ 1097] train: loss: 0.0057531
[Epoch 38; Iter   541/ 1097] train: loss: 0.0510458
[Epoch 38; Iter   571/ 1097] train: loss: 0.0084561
[Epoch 38; Iter   601/ 1097] train: loss: 0.0554171
[Epoch 38; Iter   631/ 1097] train: loss: 0.0160208
[Epoch 38; Iter   661/ 1097] train: loss: 0.0054787
[Epoch 38; Iter   691/ 1097] train: loss: 0.0044719
[Epoch 38; Iter   721/ 1097] train: loss: 0.0039952
[Epoch 38; Iter   751/ 1097] train: loss: 0.0131787
[Epoch 38; Iter   781/ 1097] train: loss: 0.0351126
[Epoch 38; Iter   811/ 1097] train: loss: 0.0050838
[Epoch 38; Iter   841/ 1097] train: loss: 0.0035990
[Epoch 38; Iter   871/ 1097] train: loss: 0.0402189
[Epoch 38; Iter   901/ 1097] train: loss: 0.0077808
[Epoch 38; Iter   931/ 1097] train: loss: 0.0071739
[Epoch 38; Iter   961/ 1097] train: loss: 0.0026520
[Epoch 38; Iter   991/ 1097] train: loss: 0.0231622
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0015221
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0166293
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0049920
[Epoch 38] ogbg-molhiv: 0.774483 val loss: 0.579816
[Epoch 38] ogbg-molhiv: 0.684523 test loss: 0.513093
[Epoch 39; Iter    14/ 1097] train: loss: 0.0293120
[Epoch 39; Iter    44/ 1097] train: loss: 0.0169440
[Epoch 39; Iter    74/ 1097] train: loss: 0.1386746
[Epoch 39; Iter   104/ 1097] train: loss: 0.0008466
[Epoch 39; Iter   134/ 1097] train: loss: 0.0089140
[Epoch 39; Iter   164/ 1097] train: loss: 0.0760346
[Epoch 39; Iter   194/ 1097] train: loss: 0.0078081
[Epoch 39; Iter   224/ 1097] train: loss: 0.0050809
[Epoch 39; Iter   254/ 1097] train: loss: 0.0091405
[Epoch 39; Iter   284/ 1097] train: loss: 0.0402545
[Epoch 39; Iter   314/ 1097] train: loss: 0.0034513
[Epoch 39; Iter   344/ 1097] train: loss: 0.0080041
[Epoch 39; Iter   374/ 1097] train: loss: 0.0182245
[Epoch 39; Iter   404/ 1097] train: loss: 0.0007556
[Epoch 39; Iter   434/ 1097] train: loss: 0.0088743
[Epoch 39; Iter   464/ 1097] train: loss: 0.0083726
[Epoch 39; Iter   494/ 1097] train: loss: 0.0024240
[Epoch 39; Iter   524/ 1097] train: loss: 0.0656806
[Epoch 39; Iter   554/ 1097] train: loss: 0.0102228
[Epoch 39; Iter   584/ 1097] train: loss: 0.0150588
[Epoch 39; Iter   614/ 1097] train: loss: 0.0622398
[Epoch 39; Iter   644/ 1097] train: loss: 0.0440904
[Epoch 39; Iter   674/ 1097] train: loss: 0.0080619
[Epoch 39; Iter   704/ 1097] train: loss: 0.0050865
[Epoch 39; Iter   734/ 1097] train: loss: 0.0071418
[Epoch 39; Iter   764/ 1097] train: loss: 0.0201578
[Epoch 39; Iter   794/ 1097] train: loss: 0.0066389
[Epoch 39; Iter   824/ 1097] train: loss: 0.1055217
[Epoch 39; Iter   854/ 1097] train: loss: 0.0258511
[Epoch 39; Iter   884/ 1097] train: loss: 0.0021857
[Epoch 39; Iter   914/ 1097] train: loss: 0.0056753
[Epoch 39; Iter   944/ 1097] train: loss: 0.0224615
[Epoch 39; Iter   974/ 1097] train: loss: 0.0179425
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0047688
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0049235
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0133190
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0029058
[Epoch 39] ogbg-molhiv: 0.821986 val loss: 0.592536
[Epoch 39] ogbg-molhiv: 0.694098 test loss: 0.593362
[Epoch 40; Iter    27/ 1097] train: loss: 0.0038546
[Epoch 40; Iter    57/ 1097] train: loss: 0.0040080
[Epoch 40; Iter    87/ 1097] train: loss: 0.0251539
[Epoch 40; Iter   117/ 1097] train: loss: 0.0073342
[Epoch 40; Iter   147/ 1097] train: loss: 0.0085560
[Epoch 40; Iter   177/ 1097] train: loss: 0.0196142
[Epoch 40; Iter   207/ 1097] train: loss: 0.0012590
[Epoch 40; Iter   237/ 1097] train: loss: 0.0147506
[Epoch 40; Iter   267/ 1097] train: loss: 0.0100787
[Epoch 40; Iter   297/ 1097] train: loss: 0.0006538
[Epoch 40; Iter   327/ 1097] train: loss: 0.0396237
[Epoch 40; Iter   357/ 1097] train: loss: 0.0051277
[Epoch 40; Iter   387/ 1097] train: loss: 0.0034501
[Epoch 40; Iter   417/ 1097] train: loss: 0.0093976
[Epoch 40; Iter   447/ 1097] train: loss: 0.0215186
[Epoch 40; Iter   477/ 1097] train: loss: 0.0070777
[Epoch 40; Iter   507/ 1097] train: loss: 0.0553403
[Epoch 40; Iter   537/ 1097] train: loss: 0.0098145
[Epoch 40; Iter   567/ 1097] train: loss: 0.0070382
[Epoch 40; Iter   597/ 1097] train: loss: 0.0025860
[Epoch 40; Iter   627/ 1097] train: loss: 0.0007975
[Epoch 40; Iter   657/ 1097] train: loss: 0.0336311
[Epoch 36; Iter   635/ 1097] train: loss: 0.0026620
[Epoch 36; Iter   665/ 1097] train: loss: 0.0054590
[Epoch 36; Iter   695/ 1097] train: loss: 0.0106483
[Epoch 36; Iter   725/ 1097] train: loss: 0.0063183
[Epoch 36; Iter   755/ 1097] train: loss: 0.0040016
[Epoch 36; Iter   785/ 1097] train: loss: 0.0574120
[Epoch 36; Iter   815/ 1097] train: loss: 0.0672808
[Epoch 36; Iter   845/ 1097] train: loss: 0.0222065
[Epoch 36; Iter   875/ 1097] train: loss: 0.0365547
[Epoch 36; Iter   905/ 1097] train: loss: 0.0176383
[Epoch 36; Iter   935/ 1097] train: loss: 0.0069610
[Epoch 36; Iter   965/ 1097] train: loss: 0.0142795
[Epoch 36; Iter   995/ 1097] train: loss: 0.0026612
[Epoch 36; Iter  1025/ 1097] train: loss: 0.2426698
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0255774
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0040771
[Epoch 36] ogbg-molhiv: 0.696070 val loss: 1.932293
[Epoch 36] ogbg-molhiv: 0.659329 test loss: 0.808900
[Epoch 37; Iter    18/ 1097] train: loss: 0.0119333
[Epoch 37; Iter    48/ 1097] train: loss: 0.0282799
[Epoch 37; Iter    78/ 1097] train: loss: 0.0055068
[Epoch 37; Iter   108/ 1097] train: loss: 0.0048425
[Epoch 37; Iter   138/ 1097] train: loss: 0.0306546
[Epoch 37; Iter   168/ 1097] train: loss: 0.1120711
[Epoch 37; Iter   198/ 1097] train: loss: 0.0146249
[Epoch 37; Iter   228/ 1097] train: loss: 0.0073937
[Epoch 37; Iter   258/ 1097] train: loss: 0.0748543
[Epoch 37; Iter   288/ 1097] train: loss: 0.0542948
[Epoch 37; Iter   318/ 1097] train: loss: 0.0069277
[Epoch 37; Iter   348/ 1097] train: loss: 0.0099657
[Epoch 37; Iter   378/ 1097] train: loss: 0.0802510
[Epoch 37; Iter   408/ 1097] train: loss: 0.0098867
[Epoch 37; Iter   438/ 1097] train: loss: 0.0074442
[Epoch 37; Iter   468/ 1097] train: loss: 0.0038763
[Epoch 37; Iter   498/ 1097] train: loss: 0.0065046
[Epoch 37; Iter   528/ 1097] train: loss: 0.1152609
[Epoch 37; Iter   558/ 1097] train: loss: 0.0984682
[Epoch 37; Iter   588/ 1097] train: loss: 0.0168903
[Epoch 37; Iter   618/ 1097] train: loss: 0.0017129
[Epoch 37; Iter   648/ 1097] train: loss: 0.0017767
[Epoch 37; Iter   678/ 1097] train: loss: 0.0067277
[Epoch 37; Iter   708/ 1097] train: loss: 0.0101796
[Epoch 37; Iter   738/ 1097] train: loss: 0.0352666
[Epoch 37; Iter   768/ 1097] train: loss: 0.0075182
[Epoch 37; Iter   798/ 1097] train: loss: 0.0098224
[Epoch 37; Iter   828/ 1097] train: loss: 0.0141890
[Epoch 37; Iter   858/ 1097] train: loss: 0.0065636
[Epoch 37; Iter   888/ 1097] train: loss: 0.0405878
[Epoch 37; Iter   918/ 1097] train: loss: 0.1947868
[Epoch 37; Iter   948/ 1097] train: loss: 0.0074551
[Epoch 37; Iter   978/ 1097] train: loss: 0.0190489
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0279287
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0428945
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0232515
[Epoch 37] ogbg-molhiv: 0.656048 val loss: 1.489390
[Epoch 37] ogbg-molhiv: 0.629050 test loss: 0.844542
[Epoch 38; Iter     1/ 1097] train: loss: 0.0126812
[Epoch 38; Iter    31/ 1097] train: loss: 0.0271672
[Epoch 38; Iter    61/ 1097] train: loss: 0.0233262
[Epoch 38; Iter    91/ 1097] train: loss: 0.0089394
[Epoch 38; Iter   121/ 1097] train: loss: 0.0066378
[Epoch 38; Iter   151/ 1097] train: loss: 0.0037129
[Epoch 38; Iter   181/ 1097] train: loss: 0.0013520
[Epoch 38; Iter   211/ 1097] train: loss: 0.0043122
[Epoch 38; Iter   241/ 1097] train: loss: 0.0018799
[Epoch 38; Iter   271/ 1097] train: loss: 0.1218916
[Epoch 38; Iter   301/ 1097] train: loss: 0.0022750
[Epoch 38; Iter   331/ 1097] train: loss: 0.0043826
[Epoch 38; Iter   361/ 1097] train: loss: 0.0029615
[Epoch 38; Iter   391/ 1097] train: loss: 0.0032154
[Epoch 38; Iter   421/ 1097] train: loss: 0.0199246
[Epoch 38; Iter   451/ 1097] train: loss: 0.0106430
[Epoch 38; Iter   481/ 1097] train: loss: 0.0199836
[Epoch 38; Iter   511/ 1097] train: loss: 0.0698694
[Epoch 38; Iter   541/ 1097] train: loss: 0.0032659
[Epoch 38; Iter   571/ 1097] train: loss: 0.0136803
[Epoch 38; Iter   601/ 1097] train: loss: 0.0016410
[Epoch 38; Iter   631/ 1097] train: loss: 0.1369567
[Epoch 38; Iter   661/ 1097] train: loss: 0.0049684
[Epoch 38; Iter   691/ 1097] train: loss: 0.0007452
[Epoch 38; Iter   721/ 1097] train: loss: 0.0076706
[Epoch 38; Iter   751/ 1097] train: loss: 0.0041589
[Epoch 38; Iter   781/ 1097] train: loss: 0.0134874
[Epoch 38; Iter   811/ 1097] train: loss: 0.0104991
[Epoch 38; Iter   841/ 1097] train: loss: 0.0065534
[Epoch 38; Iter   871/ 1097] train: loss: 0.0014000
[Epoch 38; Iter   901/ 1097] train: loss: 0.0061032
[Epoch 38; Iter   931/ 1097] train: loss: 0.0063785
[Epoch 38; Iter   961/ 1097] train: loss: 0.0060425
[Epoch 38; Iter   991/ 1097] train: loss: 0.0026955
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0110652
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0058440
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0120170
[Epoch 38] ogbg-molhiv: 0.700388 val loss: 1.450658
[Epoch 38] ogbg-molhiv: 0.699396 test loss: 0.827817
[Epoch 39; Iter    14/ 1097] train: loss: 0.0003438
[Epoch 39; Iter    44/ 1097] train: loss: 0.0246973
[Epoch 39; Iter    74/ 1097] train: loss: 0.0114626
[Epoch 39; Iter   104/ 1097] train: loss: 0.0074240
[Epoch 39; Iter   134/ 1097] train: loss: 0.0036270
[Epoch 39; Iter   164/ 1097] train: loss: 0.0018295
[Epoch 39; Iter   194/ 1097] train: loss: 0.0092974
[Epoch 39; Iter   224/ 1097] train: loss: 0.0334610
[Epoch 39; Iter   254/ 1097] train: loss: 0.0082853
[Epoch 39; Iter   284/ 1097] train: loss: 0.0032939
[Epoch 39; Iter   314/ 1097] train: loss: 0.0013188
[Epoch 39; Iter   344/ 1097] train: loss: 0.0033397
[Epoch 39; Iter   374/ 1097] train: loss: 0.0018611
[Epoch 39; Iter   404/ 1097] train: loss: 0.0120232
[Epoch 39; Iter   434/ 1097] train: loss: 0.0103501
[Epoch 39; Iter   464/ 1097] train: loss: 0.0034276
[Epoch 39; Iter   494/ 1097] train: loss: 0.0195236
[Epoch 39; Iter   524/ 1097] train: loss: 0.0039535
[Epoch 39; Iter   554/ 1097] train: loss: 0.0244750
[Epoch 39; Iter   584/ 1097] train: loss: 0.0068687
[Epoch 39; Iter   614/ 1097] train: loss: 0.0077495
[Epoch 39; Iter   644/ 1097] train: loss: 0.0132221
[Epoch 39; Iter   674/ 1097] train: loss: 0.0042926
[Epoch 39; Iter   704/ 1097] train: loss: 0.0355722
[Epoch 39; Iter   734/ 1097] train: loss: 0.0540519
[Epoch 39; Iter   764/ 1097] train: loss: 0.0039715
[Epoch 39; Iter   794/ 1097] train: loss: 0.0006113
[Epoch 39; Iter   824/ 1097] train: loss: 0.0053973
[Epoch 39; Iter   854/ 1097] train: loss: 0.0057084
[Epoch 39; Iter   884/ 1097] train: loss: 0.0476546
[Epoch 39; Iter   914/ 1097] train: loss: 0.0066735
[Epoch 39; Iter   944/ 1097] train: loss: 0.0329186
[Epoch 39; Iter   974/ 1097] train: loss: 0.0011079
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0003602
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0754627
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0776896
[Epoch 39; Iter  1094/ 1097] train: loss: 0.2175573
[Epoch 39] ogbg-molhiv: 0.720272 val loss: 0.254557
[Epoch 39] ogbg-molhiv: 0.708546 test loss: 0.296992
[Epoch 40; Iter    27/ 1097] train: loss: 0.0010740
[Epoch 40; Iter    57/ 1097] train: loss: 0.0176188
[Epoch 40; Iter    87/ 1097] train: loss: 0.0011767
[Epoch 40; Iter   117/ 1097] train: loss: 0.0199544
[Epoch 40; Iter   147/ 1097] train: loss: 0.0047461
[Epoch 40; Iter   177/ 1097] train: loss: 0.1053744
[Epoch 40; Iter   207/ 1097] train: loss: 0.0124751
[Epoch 40; Iter   237/ 1097] train: loss: 0.0121798
[Epoch 40; Iter   267/ 1097] train: loss: 0.0014034
[Epoch 40; Iter   297/ 1097] train: loss: 0.0187608
[Epoch 40; Iter   327/ 1097] train: loss: 0.1484212
[Epoch 40; Iter   357/ 1097] train: loss: 0.0026332
[Epoch 40; Iter   387/ 1097] train: loss: 0.0003598
[Epoch 40; Iter   417/ 1097] train: loss: 0.0004256
[Epoch 40; Iter   447/ 1097] train: loss: 0.0060930
[Epoch 40; Iter   477/ 1097] train: loss: 0.0151251
[Epoch 40; Iter   507/ 1097] train: loss: 0.0049854
[Epoch 40; Iter   537/ 1097] train: loss: 0.0302554
[Epoch 40; Iter   567/ 1097] train: loss: 0.0014973
[Epoch 40; Iter   597/ 1097] train: loss: 0.0518050
[Epoch 40; Iter   627/ 1097] train: loss: 0.0011578
[Epoch 40; Iter   657/ 1097] train: loss: 0.0270625
[Epoch 40; Iter   687/ 1097] train: loss: 0.0017110
[Epoch 36; Iter   635/ 1097] train: loss: 0.0051377
[Epoch 36; Iter   665/ 1097] train: loss: 0.0050400
[Epoch 36; Iter   695/ 1097] train: loss: 0.0105721
[Epoch 36; Iter   725/ 1097] train: loss: 0.0029660
[Epoch 36; Iter   755/ 1097] train: loss: 0.0123747
[Epoch 36; Iter   785/ 1097] train: loss: 0.0059341
[Epoch 36; Iter   815/ 1097] train: loss: 0.0162154
[Epoch 36; Iter   845/ 1097] train: loss: 0.0349649
[Epoch 36; Iter   875/ 1097] train: loss: 0.0030352
[Epoch 36; Iter   905/ 1097] train: loss: 0.0020213
[Epoch 36; Iter   935/ 1097] train: loss: 0.0492601
[Epoch 36; Iter   965/ 1097] train: loss: 0.0035386
[Epoch 36; Iter   995/ 1097] train: loss: 0.0028089
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0071373
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0020566
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0046329
[Epoch 36] ogbg-molhiv: 0.752627 val loss: 0.145890
[Epoch 36] ogbg-molhiv: 0.713359 test loss: 0.225963
[Epoch 37; Iter    18/ 1097] train: loss: 0.0082567
[Epoch 37; Iter    48/ 1097] train: loss: 0.0181580
[Epoch 37; Iter    78/ 1097] train: loss: 0.0016365
[Epoch 37; Iter   108/ 1097] train: loss: 0.0630208
[Epoch 37; Iter   138/ 1097] train: loss: 0.0862574
[Epoch 37; Iter   168/ 1097] train: loss: 0.0126498
[Epoch 37; Iter   198/ 1097] train: loss: 0.1052212
[Epoch 37; Iter   228/ 1097] train: loss: 0.0023694
[Epoch 37; Iter   258/ 1097] train: loss: 0.0010394
[Epoch 37; Iter   288/ 1097] train: loss: 0.0393589
[Epoch 37; Iter   318/ 1097] train: loss: 0.0040107
[Epoch 37; Iter   348/ 1097] train: loss: 0.0011558
[Epoch 37; Iter   378/ 1097] train: loss: 0.0040677
[Epoch 37; Iter   408/ 1097] train: loss: 0.1674065
[Epoch 37; Iter   438/ 1097] train: loss: 0.0021109
[Epoch 37; Iter   468/ 1097] train: loss: 0.0019739
[Epoch 37; Iter   498/ 1097] train: loss: 0.0280657
[Epoch 37; Iter   528/ 1097] train: loss: 0.0170972
[Epoch 37; Iter   558/ 1097] train: loss: 0.0037322
[Epoch 37; Iter   588/ 1097] train: loss: 0.0416247
[Epoch 37; Iter   618/ 1097] train: loss: 0.1085219
[Epoch 37; Iter   648/ 1097] train: loss: 0.0076632
[Epoch 37; Iter   678/ 1097] train: loss: 0.0132073
[Epoch 37; Iter   708/ 1097] train: loss: 0.0717004
[Epoch 37; Iter   738/ 1097] train: loss: 0.0150571
[Epoch 37; Iter   768/ 1097] train: loss: 0.0030560
[Epoch 37; Iter   798/ 1097] train: loss: 0.0042363
[Epoch 37; Iter   828/ 1097] train: loss: 0.0019236
[Epoch 37; Iter   858/ 1097] train: loss: 0.0072411
[Epoch 37; Iter   888/ 1097] train: loss: 0.0394998
[Epoch 37; Iter   918/ 1097] train: loss: 0.0101740
[Epoch 37; Iter   948/ 1097] train: loss: 0.0010211
[Epoch 37; Iter   978/ 1097] train: loss: 0.0038822
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0021817
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0034659
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0138387
[Epoch 37] ogbg-molhiv: 0.753233 val loss: 0.313596
[Epoch 37] ogbg-molhiv: 0.697151 test loss: 0.257492
[Epoch 38; Iter     1/ 1097] train: loss: 0.0020944
[Epoch 38; Iter    31/ 1097] train: loss: 0.0104547
[Epoch 38; Iter    61/ 1097] train: loss: 0.0021710
[Epoch 38; Iter    91/ 1097] train: loss: 0.0112778
[Epoch 38; Iter   121/ 1097] train: loss: 0.0087239
[Epoch 38; Iter   151/ 1097] train: loss: 0.0068784
[Epoch 38; Iter   181/ 1097] train: loss: 0.0034216
[Epoch 38; Iter   211/ 1097] train: loss: 0.0012558
[Epoch 38; Iter   241/ 1097] train: loss: 0.0242781
[Epoch 38; Iter   271/ 1097] train: loss: 0.0005872
[Epoch 38; Iter   301/ 1097] train: loss: 0.0282152
[Epoch 38; Iter   331/ 1097] train: loss: 0.0168367
[Epoch 38; Iter   361/ 1097] train: loss: 0.0202738
[Epoch 38; Iter   391/ 1097] train: loss: 0.0677995
[Epoch 38; Iter   421/ 1097] train: loss: 0.0067195
[Epoch 38; Iter   451/ 1097] train: loss: 0.0023594
[Epoch 38; Iter   481/ 1097] train: loss: 0.0091234
[Epoch 38; Iter   511/ 1097] train: loss: 0.0278973
[Epoch 38; Iter   541/ 1097] train: loss: 0.0970340
[Epoch 38; Iter   571/ 1097] train: loss: 0.0043664
[Epoch 38; Iter   601/ 1097] train: loss: 0.0106587
[Epoch 38; Iter   631/ 1097] train: loss: 0.0139711
[Epoch 38; Iter   661/ 1097] train: loss: 0.0154360
[Epoch 38; Iter   691/ 1097] train: loss: 0.0085211
[Epoch 38; Iter   721/ 1097] train: loss: 0.0181096
[Epoch 38; Iter   751/ 1097] train: loss: 0.1273142
[Epoch 38; Iter   781/ 1097] train: loss: 0.0192595
[Epoch 38; Iter   811/ 1097] train: loss: 0.0077097
[Epoch 38; Iter   841/ 1097] train: loss: 0.0008634
[Epoch 38; Iter   871/ 1097] train: loss: 0.0155354
[Epoch 38; Iter   901/ 1097] train: loss: 0.0033303
[Epoch 38; Iter   931/ 1097] train: loss: 0.0054961
[Epoch 38; Iter   961/ 1097] train: loss: 0.0019590
[Epoch 38; Iter   991/ 1097] train: loss: 0.0043283
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0184795
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0134110
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0120166
[Epoch 38] ogbg-molhiv: 0.757300 val loss: 0.303967
[Epoch 38] ogbg-molhiv: 0.696989 test loss: 0.237397
[Epoch 39; Iter    14/ 1097] train: loss: 0.0036097
[Epoch 39; Iter    44/ 1097] train: loss: 0.0111586
[Epoch 39; Iter    74/ 1097] train: loss: 0.0226019
[Epoch 39; Iter   104/ 1097] train: loss: 0.0018277
[Epoch 39; Iter   134/ 1097] train: loss: 0.0050008
[Epoch 39; Iter   164/ 1097] train: loss: 0.0044347
[Epoch 39; Iter   194/ 1097] train: loss: 0.0062800
[Epoch 39; Iter   224/ 1097] train: loss: 0.0082670
[Epoch 39; Iter   254/ 1097] train: loss: 0.0146134
[Epoch 39; Iter   284/ 1097] train: loss: 0.0298730
[Epoch 39; Iter   314/ 1097] train: loss: 0.0582517
[Epoch 39; Iter   344/ 1097] train: loss: 0.0058573
[Epoch 39; Iter   374/ 1097] train: loss: 0.0027232
[Epoch 39; Iter   404/ 1097] train: loss: 0.0091697
[Epoch 39; Iter   434/ 1097] train: loss: 0.1633536
[Epoch 39; Iter   464/ 1097] train: loss: 0.0012369
[Epoch 39; Iter   494/ 1097] train: loss: 0.0016266
[Epoch 39; Iter   524/ 1097] train: loss: 0.0166328
[Epoch 39; Iter   554/ 1097] train: loss: 0.0803811
[Epoch 39; Iter   584/ 1097] train: loss: 0.0153117
[Epoch 39; Iter   614/ 1097] train: loss: 0.0640205
[Epoch 39; Iter   644/ 1097] train: loss: 0.0580508
[Epoch 39; Iter   674/ 1097] train: loss: 0.0020678
[Epoch 39; Iter   704/ 1097] train: loss: 0.0040522
[Epoch 39; Iter   734/ 1097] train: loss: 0.0584990
[Epoch 39; Iter   764/ 1097] train: loss: 0.0015667
[Epoch 39; Iter   794/ 1097] train: loss: 0.0041744
[Epoch 39; Iter   824/ 1097] train: loss: 0.0130375
[Epoch 39; Iter   854/ 1097] train: loss: 0.0170614
[Epoch 39; Iter   884/ 1097] train: loss: 0.0248063
[Epoch 39; Iter   914/ 1097] train: loss: 0.0215752
[Epoch 39; Iter   944/ 1097] train: loss: 0.0138707
[Epoch 39; Iter   974/ 1097] train: loss: 0.1942302
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0147366
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0011324
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0003927
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0014758
[Epoch 39] ogbg-molhiv: 0.769100 val loss: 0.365529
[Epoch 39] ogbg-molhiv: 0.713942 test loss: 0.229272
[Epoch 40; Iter    27/ 1097] train: loss: 0.0149467
[Epoch 40; Iter    57/ 1097] train: loss: 0.0157419
[Epoch 40; Iter    87/ 1097] train: loss: 0.0050375
[Epoch 40; Iter   117/ 1097] train: loss: 0.0009422
[Epoch 40; Iter   147/ 1097] train: loss: 0.0089520
[Epoch 40; Iter   177/ 1097] train: loss: 0.0043784
[Epoch 40; Iter   207/ 1097] train: loss: 0.0184005
[Epoch 40; Iter   237/ 1097] train: loss: 0.0064348
[Epoch 40; Iter   267/ 1097] train: loss: 0.0338609
[Epoch 40; Iter   297/ 1097] train: loss: 0.0025969
[Epoch 40; Iter   327/ 1097] train: loss: 0.0373181
[Epoch 40; Iter   357/ 1097] train: loss: 0.0040819
[Epoch 40; Iter   387/ 1097] train: loss: 0.0011129
[Epoch 40; Iter   417/ 1097] train: loss: 0.0966098
[Epoch 40; Iter   447/ 1097] train: loss: 0.0514821
[Epoch 40; Iter   477/ 1097] train: loss: 0.0201500
[Epoch 40; Iter   507/ 1097] train: loss: 0.0297136
[Epoch 40; Iter   537/ 1097] train: loss: 0.0030681
[Epoch 40; Iter   567/ 1097] train: loss: 0.0006061
[Epoch 40; Iter   597/ 1097] train: loss: 0.0017440
[Epoch 40; Iter   627/ 1097] train: loss: 0.0565129
[Epoch 40; Iter   657/ 1097] train: loss: 0.0077857
[Epoch 40; Iter   687/ 1097] train: loss: 0.0103376
[Epoch 36; Iter   635/ 1097] train: loss: 0.0318429
[Epoch 36; Iter   665/ 1097] train: loss: 0.0117769
[Epoch 36; Iter   695/ 1097] train: loss: 0.1020292
[Epoch 36; Iter   725/ 1097] train: loss: 0.0138398
[Epoch 36; Iter   755/ 1097] train: loss: 0.0101948
[Epoch 36; Iter   785/ 1097] train: loss: 0.0082286
[Epoch 36; Iter   815/ 1097] train: loss: 0.0783720
[Epoch 36; Iter   845/ 1097] train: loss: 0.0899948
[Epoch 36; Iter   875/ 1097] train: loss: 0.0548705
[Epoch 36; Iter   905/ 1097] train: loss: 0.0031434
[Epoch 36; Iter   935/ 1097] train: loss: 0.2342883
[Epoch 36; Iter   965/ 1097] train: loss: 0.0080937
[Epoch 36; Iter   995/ 1097] train: loss: 0.0185226
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0051992
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1682666
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0993176
[Epoch 36] ogbg-molhiv: 0.744614 val loss: 0.117244
[Epoch 36] ogbg-molhiv: 0.724394 test loss: 0.191765
[Epoch 37; Iter    18/ 1097] train: loss: 0.0386693
[Epoch 37; Iter    48/ 1097] train: loss: 0.0231779
[Epoch 37; Iter    78/ 1097] train: loss: 0.0289516
[Epoch 37; Iter   108/ 1097] train: loss: 0.0127576
[Epoch 37; Iter   138/ 1097] train: loss: 0.0113299
[Epoch 37; Iter   168/ 1097] train: loss: 0.0361071
[Epoch 37; Iter   198/ 1097] train: loss: 0.0020157
[Epoch 37; Iter   228/ 1097] train: loss: 0.0034213
[Epoch 37; Iter   258/ 1097] train: loss: 0.0135436
[Epoch 37; Iter   288/ 1097] train: loss: 0.0108083
[Epoch 37; Iter   318/ 1097] train: loss: 0.0027246
[Epoch 37; Iter   348/ 1097] train: loss: 0.0369306
[Epoch 37; Iter   378/ 1097] train: loss: 0.1183543
[Epoch 37; Iter   408/ 1097] train: loss: 0.0830658
[Epoch 37; Iter   438/ 1097] train: loss: 0.1518240
[Epoch 37; Iter   468/ 1097] train: loss: 0.0038437
[Epoch 37; Iter   498/ 1097] train: loss: 0.0095505
[Epoch 37; Iter   528/ 1097] train: loss: 0.1490722
[Epoch 37; Iter   558/ 1097] train: loss: 0.0032099
[Epoch 37; Iter   588/ 1097] train: loss: 0.0054095
[Epoch 37; Iter   618/ 1097] train: loss: 0.1773954
[Epoch 37; Iter   648/ 1097] train: loss: 0.0324659
[Epoch 37; Iter   678/ 1097] train: loss: 0.1004865
[Epoch 37; Iter   708/ 1097] train: loss: 0.0759317
[Epoch 37; Iter   738/ 1097] train: loss: 0.0169350
[Epoch 37; Iter   768/ 1097] train: loss: 0.0579050
[Epoch 37; Iter   798/ 1097] train: loss: 0.2275095
[Epoch 37; Iter   828/ 1097] train: loss: 0.0309982
[Epoch 37; Iter   858/ 1097] train: loss: 0.0386528
[Epoch 37; Iter   888/ 1097] train: loss: 0.0479254
[Epoch 37; Iter   918/ 1097] train: loss: 0.1366291
[Epoch 37; Iter   948/ 1097] train: loss: 0.0147862
[Epoch 37; Iter   978/ 1097] train: loss: 0.0785123
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0179266
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0130047
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0736008
[Epoch 37] ogbg-molhiv: 0.695767 val loss: 0.125436
[Epoch 37] ogbg-molhiv: 0.706885 test loss: 0.241239
[Epoch 38; Iter     1/ 1097] train: loss: 0.0145781
[Epoch 38; Iter    31/ 1097] train: loss: 0.0101147
[Epoch 38; Iter    61/ 1097] train: loss: 0.1282001
[Epoch 38; Iter    91/ 1097] train: loss: 0.1614759
[Epoch 38; Iter   121/ 1097] train: loss: 0.0297326
[Epoch 38; Iter   151/ 1097] train: loss: 0.0112454
[Epoch 38; Iter   181/ 1097] train: loss: 0.0881641
[Epoch 38; Iter   211/ 1097] train: loss: 0.0071168
[Epoch 38; Iter   241/ 1097] train: loss: 0.0422633
[Epoch 38; Iter   271/ 1097] train: loss: 0.0255045
[Epoch 38; Iter   301/ 1097] train: loss: 0.0907957
[Epoch 38; Iter   331/ 1097] train: loss: 0.0375285
[Epoch 38; Iter   361/ 1097] train: loss: 0.0113692
[Epoch 38; Iter   391/ 1097] train: loss: 0.0056688
[Epoch 38; Iter   421/ 1097] train: loss: 0.0809341
[Epoch 38; Iter   451/ 1097] train: loss: 0.0219258
[Epoch 38; Iter   481/ 1097] train: loss: 0.0800727
[Epoch 38; Iter   511/ 1097] train: loss: 0.2707022
[Epoch 38; Iter   541/ 1097] train: loss: 0.0762528
[Epoch 38; Iter   571/ 1097] train: loss: 0.0060919
[Epoch 38; Iter   601/ 1097] train: loss: 0.0278660
[Epoch 38; Iter   631/ 1097] train: loss: 0.2092181
[Epoch 38; Iter   661/ 1097] train: loss: 0.0047704
[Epoch 38; Iter   691/ 1097] train: loss: 0.0064621
[Epoch 38; Iter   721/ 1097] train: loss: 0.1291971
[Epoch 38; Iter   751/ 1097] train: loss: 0.0113160
[Epoch 38; Iter   781/ 1097] train: loss: 0.1503840
[Epoch 38; Iter   811/ 1097] train: loss: 0.0444644
[Epoch 38; Iter   841/ 1097] train: loss: 0.2076569
[Epoch 38; Iter   871/ 1097] train: loss: 0.0142037
[Epoch 38; Iter   901/ 1097] train: loss: 0.0401191
[Epoch 38; Iter   931/ 1097] train: loss: 0.0060704
[Epoch 38; Iter   961/ 1097] train: loss: 0.0283009
[Epoch 38; Iter   991/ 1097] train: loss: 0.0168147
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0079862
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0424950
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0470108
[Epoch 38] ogbg-molhiv: 0.726129 val loss: 0.145963
[Epoch 38] ogbg-molhiv: 0.748751 test loss: 0.203020
[Epoch 39; Iter    14/ 1097] train: loss: 0.0214993
[Epoch 39; Iter    44/ 1097] train: loss: 0.0498344
[Epoch 39; Iter    74/ 1097] train: loss: 0.0142928
[Epoch 39; Iter   104/ 1097] train: loss: 0.0364301
[Epoch 39; Iter   134/ 1097] train: loss: 0.0096553
[Epoch 39; Iter   164/ 1097] train: loss: 0.0407091
[Epoch 39; Iter   194/ 1097] train: loss: 0.0084416
[Epoch 39; Iter   224/ 1097] train: loss: 0.1282074
[Epoch 39; Iter   254/ 1097] train: loss: 0.0452992
[Epoch 39; Iter   284/ 1097] train: loss: 0.0056392
[Epoch 39; Iter   314/ 1097] train: loss: 0.0036535
[Epoch 39; Iter   344/ 1097] train: loss: 0.0042355
[Epoch 39; Iter   374/ 1097] train: loss: 0.0036679
[Epoch 39; Iter   404/ 1097] train: loss: 0.0129809
[Epoch 39; Iter   434/ 1097] train: loss: 0.0118094
[Epoch 39; Iter   464/ 1097] train: loss: 0.0030442
[Epoch 39; Iter   494/ 1097] train: loss: 0.0092728
[Epoch 39; Iter   524/ 1097] train: loss: 0.0123637
[Epoch 39; Iter   554/ 1097] train: loss: 0.0264399
[Epoch 39; Iter   584/ 1097] train: loss: 0.0067568
[Epoch 39; Iter   614/ 1097] train: loss: 0.0085916
[Epoch 39; Iter   644/ 1097] train: loss: 0.0063926
[Epoch 39; Iter   674/ 1097] train: loss: 0.0016550
[Epoch 39; Iter   704/ 1097] train: loss: 0.0321086
[Epoch 39; Iter   734/ 1097] train: loss: 0.0061170
[Epoch 39; Iter   764/ 1097] train: loss: 0.1826708
[Epoch 39; Iter   794/ 1097] train: loss: 0.0507856
[Epoch 39; Iter   824/ 1097] train: loss: 0.0088462
[Epoch 39; Iter   854/ 1097] train: loss: 0.0017658
[Epoch 39; Iter   884/ 1097] train: loss: 0.0040312
[Epoch 39; Iter   914/ 1097] train: loss: 0.0013118
[Epoch 39; Iter   944/ 1097] train: loss: 0.0027743
[Epoch 39; Iter   974/ 1097] train: loss: 0.0749851
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0041518
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0028071
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0037035
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0536564
[Epoch 39] ogbg-molhiv: 0.714188 val loss: 0.145421
[Epoch 39] ogbg-molhiv: 0.742148 test loss: 0.212314
[Epoch 40; Iter    27/ 1097] train: loss: 0.0061851
[Epoch 40; Iter    57/ 1097] train: loss: 0.0022539
[Epoch 40; Iter    87/ 1097] train: loss: 0.0233002
[Epoch 40; Iter   117/ 1097] train: loss: 0.0475785
[Epoch 40; Iter   147/ 1097] train: loss: 0.0011080
[Epoch 40; Iter   177/ 1097] train: loss: 0.0029937
[Epoch 40; Iter   207/ 1097] train: loss: 0.0050864
[Epoch 40; Iter   237/ 1097] train: loss: 0.0092903
[Epoch 40; Iter   267/ 1097] train: loss: 0.0684876
[Epoch 40; Iter   297/ 1097] train: loss: 0.0086934
[Epoch 40; Iter   327/ 1097] train: loss: 0.0036594
[Epoch 40; Iter   357/ 1097] train: loss: 0.0008608
[Epoch 40; Iter   387/ 1097] train: loss: 0.0045655
[Epoch 40; Iter   417/ 1097] train: loss: 0.0069583
[Epoch 40; Iter   447/ 1097] train: loss: 0.0636418
[Epoch 40; Iter   477/ 1097] train: loss: 0.0044743
[Epoch 40; Iter   507/ 1097] train: loss: 0.0158827
[Epoch 40; Iter   537/ 1097] train: loss: 0.0045736
[Epoch 40; Iter   567/ 1097] train: loss: 0.0035539
[Epoch 40; Iter   597/ 1097] train: loss: 0.0575706
[Epoch 40; Iter   627/ 1097] train: loss: 0.0012343
[Epoch 40; Iter   657/ 1097] train: loss: 0.0144076
[Epoch 40; Iter   687/ 1097] train: loss: 0.0277764
[Epoch 36; Iter   635/ 1097] train: loss: 0.0119531
[Epoch 36; Iter   665/ 1097] train: loss: 0.0061604
[Epoch 36; Iter   695/ 1097] train: loss: 0.0050988
[Epoch 36; Iter   725/ 1097] train: loss: 0.0237737
[Epoch 36; Iter   755/ 1097] train: loss: 0.0057825
[Epoch 36; Iter   785/ 1097] train: loss: 0.0146962
[Epoch 36; Iter   815/ 1097] train: loss: 0.2169299
[Epoch 36; Iter   845/ 1097] train: loss: 0.0033460
[Epoch 36; Iter   875/ 1097] train: loss: 0.0036996
[Epoch 36; Iter   905/ 1097] train: loss: 0.0072467
[Epoch 36; Iter   935/ 1097] train: loss: 0.0521650
[Epoch 36; Iter   965/ 1097] train: loss: 0.0082725
[Epoch 36; Iter   995/ 1097] train: loss: 0.0114857
[Epoch 36; Iter  1025/ 1097] train: loss: 0.2634643
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0557625
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0087032
[Epoch 36] ogbg-molhiv: 0.683412 val loss: 0.402534
[Epoch 36] ogbg-molhiv: 0.633266 test loss: 0.599013
[Epoch 37; Iter    18/ 1097] train: loss: 0.0821409
[Epoch 37; Iter    48/ 1097] train: loss: 0.0137096
[Epoch 37; Iter    78/ 1097] train: loss: 0.0079920
[Epoch 37; Iter   108/ 1097] train: loss: 0.0468355
[Epoch 37; Iter   138/ 1097] train: loss: 0.0044120
[Epoch 37; Iter   168/ 1097] train: loss: 0.0035452
[Epoch 37; Iter   198/ 1097] train: loss: 0.0282054
[Epoch 37; Iter   228/ 1097] train: loss: 0.0032342
[Epoch 37; Iter   258/ 1097] train: loss: 0.0070459
[Epoch 37; Iter   288/ 1097] train: loss: 0.0541486
[Epoch 37; Iter   318/ 1097] train: loss: 0.0308078
[Epoch 37; Iter   348/ 1097] train: loss: 0.0127463
[Epoch 37; Iter   378/ 1097] train: loss: 0.0056045
[Epoch 37; Iter   408/ 1097] train: loss: 0.0366249
[Epoch 37; Iter   438/ 1097] train: loss: 0.0033799
[Epoch 37; Iter   468/ 1097] train: loss: 0.0188727
[Epoch 37; Iter   498/ 1097] train: loss: 0.0004395
[Epoch 37; Iter   528/ 1097] train: loss: 0.0525405
[Epoch 37; Iter   558/ 1097] train: loss: 0.1196875
[Epoch 37; Iter   588/ 1097] train: loss: 0.0014725
[Epoch 37; Iter   618/ 1097] train: loss: 0.0189563
[Epoch 37; Iter   648/ 1097] train: loss: 0.0014501
[Epoch 37; Iter   678/ 1097] train: loss: 0.0071651
[Epoch 37; Iter   708/ 1097] train: loss: 0.0021249
[Epoch 37; Iter   738/ 1097] train: loss: 0.0733917
[Epoch 37; Iter   768/ 1097] train: loss: 0.0026550
[Epoch 37; Iter   798/ 1097] train: loss: 0.0908849
[Epoch 37; Iter   828/ 1097] train: loss: 0.0026553
[Epoch 37; Iter   858/ 1097] train: loss: 0.0009180
[Epoch 37; Iter   888/ 1097] train: loss: 0.0035148
[Epoch 37; Iter   918/ 1097] train: loss: 0.0012664
[Epoch 37; Iter   948/ 1097] train: loss: 0.0223505
[Epoch 37; Iter   978/ 1097] train: loss: 0.0053846
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0010540
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0509065
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0037025
[Epoch 37] ogbg-molhiv: 0.727761 val loss: 0.297430
[Epoch 37] ogbg-molhiv: 0.689600 test loss: 0.334094
[Epoch 38; Iter     1/ 1097] train: loss: 0.0050146
[Epoch 38; Iter    31/ 1097] train: loss: 0.0024397
[Epoch 38; Iter    61/ 1097] train: loss: 0.0024857
[Epoch 38; Iter    91/ 1097] train: loss: 0.0008137
[Epoch 38; Iter   121/ 1097] train: loss: 0.0025546
[Epoch 38; Iter   151/ 1097] train: loss: 0.0038813
[Epoch 38; Iter   181/ 1097] train: loss: 0.0114930
[Epoch 38; Iter   211/ 1097] train: loss: 0.0056782
[Epoch 38; Iter   241/ 1097] train: loss: 0.0017854
[Epoch 38; Iter   271/ 1097] train: loss: 0.0035463
[Epoch 38; Iter   301/ 1097] train: loss: 0.0029164
[Epoch 38; Iter   331/ 1097] train: loss: 0.0030043
[Epoch 38; Iter   361/ 1097] train: loss: 0.0074983
[Epoch 38; Iter   391/ 1097] train: loss: 0.0001908
[Epoch 38; Iter   421/ 1097] train: loss: 0.0025262
[Epoch 38; Iter   451/ 1097] train: loss: 0.0014885
[Epoch 38; Iter   481/ 1097] train: loss: 0.0829351
[Epoch 38; Iter   511/ 1097] train: loss: 0.0051269
[Epoch 38; Iter   541/ 1097] train: loss: 0.0017204
[Epoch 38; Iter   571/ 1097] train: loss: 0.0065776
[Epoch 38; Iter   601/ 1097] train: loss: 0.0520267
[Epoch 38; Iter   631/ 1097] train: loss: 0.0007338
[Epoch 38; Iter   661/ 1097] train: loss: 0.0014518
[Epoch 38; Iter   691/ 1097] train: loss: 0.0014822
[Epoch 38; Iter   721/ 1097] train: loss: 0.0014509
[Epoch 38; Iter   751/ 1097] train: loss: 0.0024839
[Epoch 38; Iter   781/ 1097] train: loss: 0.0101149
[Epoch 38; Iter   811/ 1097] train: loss: 0.0017845
[Epoch 38; Iter   841/ 1097] train: loss: 0.0032452
[Epoch 38; Iter   871/ 1097] train: loss: 0.0010434
[Epoch 38; Iter   901/ 1097] train: loss: 0.0012836
[Epoch 38; Iter   931/ 1097] train: loss: 0.0010350
[Epoch 38; Iter   961/ 1097] train: loss: 0.0008004
[Epoch 38; Iter   991/ 1097] train: loss: 0.0056493
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0008446
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0021894
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0133382
[Epoch 38] ogbg-molhiv: 0.725906 val loss: 0.335697
[Epoch 38] ogbg-molhiv: 0.697652 test loss: 0.883103
[Epoch 39; Iter    14/ 1097] train: loss: 0.0030739
[Epoch 39; Iter    44/ 1097] train: loss: 0.0026894
[Epoch 39; Iter    74/ 1097] train: loss: 0.0005335
[Epoch 39; Iter   104/ 1097] train: loss: 0.0008636
[Epoch 39; Iter   134/ 1097] train: loss: 0.0038326
[Epoch 39; Iter   164/ 1097] train: loss: 0.0009893
[Epoch 39; Iter   194/ 1097] train: loss: 0.0063840
[Epoch 39; Iter   224/ 1097] train: loss: 0.0028363
[Epoch 39; Iter   254/ 1097] train: loss: 0.0113998
[Epoch 39; Iter   284/ 1097] train: loss: 0.0015167
[Epoch 39; Iter   314/ 1097] train: loss: 0.0149418
[Epoch 39; Iter   344/ 1097] train: loss: 0.0003748
[Epoch 39; Iter   374/ 1097] train: loss: 0.0039922
[Epoch 39; Iter   404/ 1097] train: loss: 0.0035642
[Epoch 39; Iter   434/ 1097] train: loss: 0.0028683
[Epoch 39; Iter   464/ 1097] train: loss: 0.0060894
[Epoch 39; Iter   494/ 1097] train: loss: 0.0135689
[Epoch 39; Iter   524/ 1097] train: loss: 0.0226680
[Epoch 39; Iter   554/ 1097] train: loss: 0.0003624
[Epoch 39; Iter   584/ 1097] train: loss: 0.0040659
[Epoch 39; Iter   614/ 1097] train: loss: 0.0122249
[Epoch 39; Iter   644/ 1097] train: loss: 0.0339697
[Epoch 39; Iter   674/ 1097] train: loss: 0.0010806
[Epoch 39; Iter   704/ 1097] train: loss: 0.0007360
[Epoch 39; Iter   734/ 1097] train: loss: 0.0010414
[Epoch 39; Iter   764/ 1097] train: loss: 0.0215224
[Epoch 39; Iter   794/ 1097] train: loss: 0.0133235
[Epoch 39; Iter   824/ 1097] train: loss: 0.0025003
[Epoch 39; Iter   854/ 1097] train: loss: 0.0009143
[Epoch 39; Iter   884/ 1097] train: loss: 0.0129063
[Epoch 39; Iter   914/ 1097] train: loss: 0.0006800
[Epoch 39; Iter   944/ 1097] train: loss: 0.0339637
[Epoch 39; Iter   974/ 1097] train: loss: 0.0186107
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0030365
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0623443
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0026387
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0150159
[Epoch 39] ogbg-molhiv: 0.758463 val loss: 0.323143
[Epoch 39] ogbg-molhiv: 0.723033 test loss: 1.250993
[Epoch 40; Iter    27/ 1097] train: loss: 0.0130275
[Epoch 40; Iter    57/ 1097] train: loss: 0.0012948
[Epoch 40; Iter    87/ 1097] train: loss: 0.0023586
[Epoch 40; Iter   117/ 1097] train: loss: 0.0004696
[Epoch 40; Iter   147/ 1097] train: loss: 0.0009348
[Epoch 40; Iter   177/ 1097] train: loss: 0.0088417
[Epoch 40; Iter   207/ 1097] train: loss: 0.0031786
[Epoch 40; Iter   237/ 1097] train: loss: 0.0014085
[Epoch 40; Iter   267/ 1097] train: loss: 0.0008289
[Epoch 40; Iter   297/ 1097] train: loss: 0.0213194
[Epoch 40; Iter   327/ 1097] train: loss: 0.0521554
[Epoch 40; Iter   357/ 1097] train: loss: 0.0045536
[Epoch 40; Iter   387/ 1097] train: loss: 0.0004521
[Epoch 40; Iter   417/ 1097] train: loss: 0.0006157
[Epoch 40; Iter   447/ 1097] train: loss: 0.0166127
[Epoch 40; Iter   477/ 1097] train: loss: 0.0002749
[Epoch 40; Iter   507/ 1097] train: loss: 0.0012545
[Epoch 40; Iter   537/ 1097] train: loss: 0.2557522
[Epoch 40; Iter   567/ 1097] train: loss: 0.0075240
[Epoch 40; Iter   597/ 1097] train: loss: 0.0106140
[Epoch 40; Iter   627/ 1097] train: loss: 0.0018593
[Epoch 40; Iter   657/ 1097] train: loss: 0.0018032
[Epoch 40; Iter   687/ 1097] train: loss: 0.0306890
[Epoch 36; Iter   635/ 1097] train: loss: 0.0751700
[Epoch 36; Iter   665/ 1097] train: loss: 0.0527726
[Epoch 36; Iter   695/ 1097] train: loss: 0.0044984
[Epoch 36; Iter   725/ 1097] train: loss: 0.0028820
[Epoch 36; Iter   755/ 1097] train: loss: 0.1376246
[Epoch 36; Iter   785/ 1097] train: loss: 0.0032810
[Epoch 36; Iter   815/ 1097] train: loss: 0.0199396
[Epoch 36; Iter   845/ 1097] train: loss: 0.0047646
[Epoch 36; Iter   875/ 1097] train: loss: 0.0489103
[Epoch 36; Iter   905/ 1097] train: loss: 0.0040391
[Epoch 36; Iter   935/ 1097] train: loss: 0.0025895
[Epoch 36; Iter   965/ 1097] train: loss: 0.0164477
[Epoch 36; Iter   995/ 1097] train: loss: 0.0045897
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0032399
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0095919
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0073807
[Epoch 36] ogbg-molhiv: 0.715563 val loss: 8.808216
[Epoch 36] ogbg-molhiv: 0.628361 test loss: 5.185720
[Epoch 37; Iter    18/ 1097] train: loss: 0.0147075
[Epoch 37; Iter    48/ 1097] train: loss: 0.0899411
[Epoch 37; Iter    78/ 1097] train: loss: 0.0037224
[Epoch 37; Iter   108/ 1097] train: loss: 0.2052957
[Epoch 37; Iter   138/ 1097] train: loss: 0.0096974
[Epoch 37; Iter   168/ 1097] train: loss: 0.0014618
[Epoch 37; Iter   198/ 1097] train: loss: 0.0287635
[Epoch 37; Iter   228/ 1097] train: loss: 0.0022148
[Epoch 37; Iter   258/ 1097] train: loss: 0.0085353
[Epoch 37; Iter   288/ 1097] train: loss: 0.0015586
[Epoch 37; Iter   318/ 1097] train: loss: 0.0079264
[Epoch 37; Iter   348/ 1097] train: loss: 0.0034711
[Epoch 37; Iter   378/ 1097] train: loss: 0.0035195
[Epoch 37; Iter   408/ 1097] train: loss: 0.0065819
[Epoch 37; Iter   438/ 1097] train: loss: 0.0039349
[Epoch 37; Iter   468/ 1097] train: loss: 0.0814346
[Epoch 37; Iter   498/ 1097] train: loss: 0.0598069
[Epoch 37; Iter   528/ 1097] train: loss: 0.0281064
[Epoch 37; Iter   558/ 1097] train: loss: 0.0032731
[Epoch 37; Iter   588/ 1097] train: loss: 0.0047422
[Epoch 37; Iter   618/ 1097] train: loss: 0.0006086
[Epoch 37; Iter   648/ 1097] train: loss: 0.0056922
[Epoch 37; Iter   678/ 1097] train: loss: 0.0050501
[Epoch 37; Iter   708/ 1097] train: loss: 0.0220028
[Epoch 37; Iter   738/ 1097] train: loss: 0.1276823
[Epoch 37; Iter   768/ 1097] train: loss: 0.0129259
[Epoch 37; Iter   798/ 1097] train: loss: 0.1604228
[Epoch 37; Iter   828/ 1097] train: loss: 0.0025746
[Epoch 37; Iter   858/ 1097] train: loss: 0.0058515
[Epoch 37; Iter   888/ 1097] train: loss: 0.0034820
[Epoch 37; Iter   918/ 1097] train: loss: 0.0024830
[Epoch 37; Iter   948/ 1097] train: loss: 0.0133620
[Epoch 37; Iter   978/ 1097] train: loss: 0.0074484
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0012073
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0184367
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0114092
[Epoch 37] ogbg-molhiv: 0.707837 val loss: 4.112815
[Epoch 37] ogbg-molhiv: 0.622380 test loss: 2.243608
[Epoch 38; Iter     1/ 1097] train: loss: 0.0141176
[Epoch 38; Iter    31/ 1097] train: loss: 0.0166739
[Epoch 38; Iter    61/ 1097] train: loss: 0.0080537
[Epoch 38; Iter    91/ 1097] train: loss: 0.0057107
[Epoch 38; Iter   121/ 1097] train: loss: 0.0224098
[Epoch 38; Iter   151/ 1097] train: loss: 0.0239317
[Epoch 38; Iter   181/ 1097] train: loss: 0.0068142
[Epoch 38; Iter   211/ 1097] train: loss: 0.0030065
[Epoch 38; Iter   241/ 1097] train: loss: 0.0297412
[Epoch 38; Iter   271/ 1097] train: loss: 0.0044997
[Epoch 38; Iter   301/ 1097] train: loss: 0.0021360
[Epoch 38; Iter   331/ 1097] train: loss: 0.0024186
[Epoch 38; Iter   361/ 1097] train: loss: 0.0483647
[Epoch 38; Iter   391/ 1097] train: loss: 0.0021815
[Epoch 38; Iter   421/ 1097] train: loss: 0.0169268
[Epoch 38; Iter   451/ 1097] train: loss: 0.0421667
[Epoch 38; Iter   481/ 1097] train: loss: 0.0115822
[Epoch 38; Iter   511/ 1097] train: loss: 0.0068943
[Epoch 38; Iter   541/ 1097] train: loss: 0.0303833
[Epoch 38; Iter   571/ 1097] train: loss: 0.0523893
[Epoch 38; Iter   601/ 1097] train: loss: 0.0445435
[Epoch 38; Iter   631/ 1097] train: loss: 0.0046045
[Epoch 38; Iter   661/ 1097] train: loss: 0.0031585
[Epoch 38; Iter   691/ 1097] train: loss: 0.0008619
[Epoch 38; Iter   721/ 1097] train: loss: 0.0135419
[Epoch 38; Iter   751/ 1097] train: loss: 0.0017625
[Epoch 38; Iter   781/ 1097] train: loss: 0.0021734
[Epoch 38; Iter   811/ 1097] train: loss: 0.0052915
[Epoch 38; Iter   841/ 1097] train: loss: 0.0048324
[Epoch 38; Iter   871/ 1097] train: loss: 0.0392092
[Epoch 38; Iter   901/ 1097] train: loss: 0.0105747
[Epoch 38; Iter   931/ 1097] train: loss: 0.0086592
[Epoch 38; Iter   961/ 1097] train: loss: 0.0018737
[Epoch 38; Iter   991/ 1097] train: loss: 0.0087698
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0007644
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0083608
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0021044
[Epoch 38] ogbg-molhiv: 0.692623 val loss: 7.573976
[Epoch 38] ogbg-molhiv: 0.602291 test loss: 4.055255
[Epoch 39; Iter    14/ 1097] train: loss: 0.0044112
[Epoch 39; Iter    44/ 1097] train: loss: 0.0053285
[Epoch 39; Iter    74/ 1097] train: loss: 0.0057989
[Epoch 39; Iter   104/ 1097] train: loss: 0.0006921
[Epoch 39; Iter   134/ 1097] train: loss: 0.0190559
[Epoch 39; Iter   164/ 1097] train: loss: 0.0092237
[Epoch 39; Iter   194/ 1097] train: loss: 0.0061637
[Epoch 39; Iter   224/ 1097] train: loss: 0.0171624
[Epoch 39; Iter   254/ 1097] train: loss: 0.0048152
[Epoch 39; Iter   284/ 1097] train: loss: 0.0207938
[Epoch 39; Iter   314/ 1097] train: loss: 0.0020537
[Epoch 39; Iter   344/ 1097] train: loss: 0.0080112
[Epoch 39; Iter   374/ 1097] train: loss: 0.0009471
[Epoch 39; Iter   404/ 1097] train: loss: 0.0058227
[Epoch 39; Iter   434/ 1097] train: loss: 0.0032175
[Epoch 39; Iter   464/ 1097] train: loss: 0.0261523
[Epoch 39; Iter   494/ 1097] train: loss: 0.0416227
[Epoch 39; Iter   524/ 1097] train: loss: 0.0029225
[Epoch 39; Iter   554/ 1097] train: loss: 0.0748532
[Epoch 39; Iter   584/ 1097] train: loss: 0.0066361
[Epoch 39; Iter   614/ 1097] train: loss: 0.0932290
[Epoch 39; Iter   644/ 1097] train: loss: 0.0050301
[Epoch 39; Iter   674/ 1097] train: loss: 0.0512706
[Epoch 39; Iter   704/ 1097] train: loss: 0.1352760
[Epoch 39; Iter   734/ 1097] train: loss: 0.0135243
[Epoch 39; Iter   764/ 1097] train: loss: 0.0665136
[Epoch 39; Iter   794/ 1097] train: loss: 0.0114299
[Epoch 39; Iter   824/ 1097] train: loss: 0.0010574
[Epoch 39; Iter   854/ 1097] train: loss: 0.0415220
[Epoch 39; Iter   884/ 1097] train: loss: 0.0051944
[Epoch 39; Iter   914/ 1097] train: loss: 0.0036174
[Epoch 39; Iter   944/ 1097] train: loss: 0.0910102
[Epoch 39; Iter   974/ 1097] train: loss: 0.0206444
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0285236
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0008955
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0124424
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0058813
[Epoch 39] ogbg-molhiv: 0.716548 val loss: 23.302725
[Epoch 39] ogbg-molhiv: 0.600941 test loss: 17.380484
[Epoch 40; Iter    27/ 1097] train: loss: 0.0150100
[Epoch 40; Iter    57/ 1097] train: loss: 0.0022375
[Epoch 40; Iter    87/ 1097] train: loss: 0.0609385
[Epoch 40; Iter   117/ 1097] train: loss: 0.0104632
[Epoch 40; Iter   147/ 1097] train: loss: 0.0410318
[Epoch 40; Iter   177/ 1097] train: loss: 0.0018044
[Epoch 40; Iter   207/ 1097] train: loss: 0.0153089
[Epoch 40; Iter   237/ 1097] train: loss: 0.0004289
[Epoch 40; Iter   267/ 1097] train: loss: 0.0067209
[Epoch 40; Iter   297/ 1097] train: loss: 0.0062416
[Epoch 40; Iter   327/ 1097] train: loss: 0.1245183
[Epoch 40; Iter   357/ 1097] train: loss: 0.0260359
[Epoch 40; Iter   387/ 1097] train: loss: 0.0047558
[Epoch 40; Iter   417/ 1097] train: loss: 0.0065581
[Epoch 40; Iter   447/ 1097] train: loss: 0.0258590
[Epoch 40; Iter   477/ 1097] train: loss: 0.0042913
[Epoch 40; Iter   507/ 1097] train: loss: 0.0041715
[Epoch 40; Iter   537/ 1097] train: loss: 0.0066958
[Epoch 40; Iter   567/ 1097] train: loss: 0.0052926
[Epoch 40; Iter   597/ 1097] train: loss: 0.0379701
[Epoch 40; Iter   627/ 1097] train: loss: 0.0113747
[Epoch 40; Iter   657/ 1097] train: loss: 0.0235357
[Epoch 40; Iter   687/ 1097] train: loss: 0.0288116
[Epoch 36; Iter   635/ 1097] train: loss: 0.0118286
[Epoch 36; Iter   665/ 1097] train: loss: 0.0261620
[Epoch 36; Iter   695/ 1097] train: loss: 0.0251038
[Epoch 36; Iter   725/ 1097] train: loss: 0.0258686
[Epoch 36; Iter   755/ 1097] train: loss: 0.0793454
[Epoch 36; Iter   785/ 1097] train: loss: 0.0201816
[Epoch 36; Iter   815/ 1097] train: loss: 0.0420263
[Epoch 36; Iter   845/ 1097] train: loss: 0.0067167
[Epoch 36; Iter   875/ 1097] train: loss: 0.0158794
[Epoch 36; Iter   905/ 1097] train: loss: 0.1177612
[Epoch 36; Iter   935/ 1097] train: loss: 0.0961389
[Epoch 36; Iter   965/ 1097] train: loss: 0.0127027
[Epoch 36; Iter   995/ 1097] train: loss: 0.0188739
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0188979
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0534469
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1934450
[Epoch 36] ogbg-molhiv: 0.753533 val loss: 0.449534
[Epoch 36] ogbg-molhiv: 0.625159 test loss: 0.705400
[Epoch 37; Iter    18/ 1097] train: loss: 0.1484202
[Epoch 37; Iter    48/ 1097] train: loss: 0.0099235
[Epoch 37; Iter    78/ 1097] train: loss: 0.0297572
[Epoch 37; Iter   108/ 1097] train: loss: 0.0160811
[Epoch 37; Iter   138/ 1097] train: loss: 0.0310659
[Epoch 37; Iter   168/ 1097] train: loss: 0.0128669
[Epoch 37; Iter   198/ 1097] train: loss: 0.0089382
[Epoch 37; Iter   228/ 1097] train: loss: 0.0045779
[Epoch 37; Iter   258/ 1097] train: loss: 0.0206747
[Epoch 37; Iter   288/ 1097] train: loss: 0.0149325
[Epoch 37; Iter   318/ 1097] train: loss: 0.0095683
[Epoch 37; Iter   348/ 1097] train: loss: 0.0099314
[Epoch 37; Iter   378/ 1097] train: loss: 0.2144229
[Epoch 37; Iter   408/ 1097] train: loss: 0.1508845
[Epoch 37; Iter   438/ 1097] train: loss: 0.0231745
[Epoch 37; Iter   468/ 1097] train: loss: 0.0239112
[Epoch 37; Iter   498/ 1097] train: loss: 0.0593176
[Epoch 37; Iter   528/ 1097] train: loss: 0.0343941
[Epoch 37; Iter   558/ 1097] train: loss: 0.0095147
[Epoch 37; Iter   588/ 1097] train: loss: 0.0074313
[Epoch 37; Iter   618/ 1097] train: loss: 0.0059604
[Epoch 37; Iter   648/ 1097] train: loss: 0.0210401
[Epoch 37; Iter   678/ 1097] train: loss: 0.0371165
[Epoch 37; Iter   708/ 1097] train: loss: 0.0340731
[Epoch 37; Iter   738/ 1097] train: loss: 0.0469123
[Epoch 37; Iter   768/ 1097] train: loss: 0.1068513
[Epoch 37; Iter   798/ 1097] train: loss: 0.2567037
[Epoch 37; Iter   828/ 1097] train: loss: 0.0186104
[Epoch 37; Iter   858/ 1097] train: loss: 0.0997181
[Epoch 37; Iter   888/ 1097] train: loss: 0.0406170
[Epoch 37; Iter   918/ 1097] train: loss: 0.2643449
[Epoch 37; Iter   948/ 1097] train: loss: 0.0120016
[Epoch 37; Iter   978/ 1097] train: loss: 0.1246913
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0113423
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0399383
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0129934
[Epoch 37] ogbg-molhiv: 0.756455 val loss: 0.211899
[Epoch 37] ogbg-molhiv: 0.642253 test loss: 0.486743
[Epoch 38; Iter     1/ 1097] train: loss: 0.0040699
[Epoch 38; Iter    31/ 1097] train: loss: 0.0125204
[Epoch 38; Iter    61/ 1097] train: loss: 0.0868520
[Epoch 38; Iter    91/ 1097] train: loss: 0.0207375
[Epoch 38; Iter   121/ 1097] train: loss: 0.0065483
[Epoch 38; Iter   151/ 1097] train: loss: 0.0034800
[Epoch 38; Iter   181/ 1097] train: loss: 0.0256465
[Epoch 38; Iter   211/ 1097] train: loss: 0.0037644
[Epoch 38; Iter   241/ 1097] train: loss: 0.1213052
[Epoch 38; Iter   271/ 1097] train: loss: 0.0353113
[Epoch 38; Iter   301/ 1097] train: loss: 0.0163956
[Epoch 38; Iter   331/ 1097] train: loss: 0.0012853
[Epoch 38; Iter   361/ 1097] train: loss: 0.0063076
[Epoch 38; Iter   391/ 1097] train: loss: 0.0043536
[Epoch 38; Iter   421/ 1097] train: loss: 0.0445985
[Epoch 38; Iter   451/ 1097] train: loss: 0.0038767
[Epoch 38; Iter   481/ 1097] train: loss: 0.2076016
[Epoch 38; Iter   511/ 1097] train: loss: 0.0327035
[Epoch 38; Iter   541/ 1097] train: loss: 0.0410757
[Epoch 38; Iter   571/ 1097] train: loss: 0.0034807
[Epoch 38; Iter   601/ 1097] train: loss: 0.0192743
[Epoch 38; Iter   631/ 1097] train: loss: 0.2101133
[Epoch 38; Iter   661/ 1097] train: loss: 0.0170088
[Epoch 38; Iter   691/ 1097] train: loss: 0.0328946
[Epoch 38; Iter   721/ 1097] train: loss: 0.0397450
[Epoch 38; Iter   751/ 1097] train: loss: 0.0089064
[Epoch 38; Iter   781/ 1097] train: loss: 0.0150394
[Epoch 38; Iter   811/ 1097] train: loss: 0.0356122
[Epoch 38; Iter   841/ 1097] train: loss: 0.1578085
[Epoch 38; Iter   871/ 1097] train: loss: 0.0338313
[Epoch 38; Iter   901/ 1097] train: loss: 0.0128976
[Epoch 38; Iter   931/ 1097] train: loss: 0.0060855
[Epoch 38; Iter   961/ 1097] train: loss: 0.0241753
[Epoch 38; Iter   991/ 1097] train: loss: 0.0179945
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0151283
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0566296
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0106972
[Epoch 38] ogbg-molhiv: 0.766005 val loss: 0.162013
[Epoch 38] ogbg-molhiv: 0.641469 test loss: 0.261950
[Epoch 39; Iter    14/ 1097] train: loss: 0.0374028
[Epoch 39; Iter    44/ 1097] train: loss: 0.0607934
[Epoch 39; Iter    74/ 1097] train: loss: 0.0329107
[Epoch 39; Iter   104/ 1097] train: loss: 0.0098842
[Epoch 39; Iter   134/ 1097] train: loss: 0.0250140
[Epoch 39; Iter   164/ 1097] train: loss: 0.0448476
[Epoch 39; Iter   194/ 1097] train: loss: 0.0100368
[Epoch 39; Iter   224/ 1097] train: loss: 0.0349385
[Epoch 39; Iter   254/ 1097] train: loss: 0.0373881
[Epoch 39; Iter   284/ 1097] train: loss: 0.0090648
[Epoch 39; Iter   314/ 1097] train: loss: 0.0065955
[Epoch 39; Iter   344/ 1097] train: loss: 0.0073210
[Epoch 39; Iter   374/ 1097] train: loss: 0.0043355
[Epoch 39; Iter   404/ 1097] train: loss: 0.0501712
[Epoch 39; Iter   434/ 1097] train: loss: 0.0130608
[Epoch 39; Iter   464/ 1097] train: loss: 0.0087106
[Epoch 39; Iter   494/ 1097] train: loss: 0.0953184
[Epoch 39; Iter   524/ 1097] train: loss: 0.1021231
[Epoch 39; Iter   554/ 1097] train: loss: 0.0147800
[Epoch 39; Iter   584/ 1097] train: loss: 0.0386507
[Epoch 39; Iter   614/ 1097] train: loss: 0.0108273
[Epoch 39; Iter   644/ 1097] train: loss: 0.1015917
[Epoch 39; Iter   674/ 1097] train: loss: 0.0730150
[Epoch 39; Iter   704/ 1097] train: loss: 0.0590861
[Epoch 39; Iter   734/ 1097] train: loss: 0.0118680
[Epoch 39; Iter   764/ 1097] train: loss: 0.1212498
[Epoch 39; Iter   794/ 1097] train: loss: 0.0058148
[Epoch 39; Iter   824/ 1097] train: loss: 0.0482018
[Epoch 39; Iter   854/ 1097] train: loss: 0.0040572
[Epoch 39; Iter   884/ 1097] train: loss: 0.0085711
[Epoch 39; Iter   914/ 1097] train: loss: 0.0124117
[Epoch 39; Iter   944/ 1097] train: loss: 0.0192745
[Epoch 39; Iter   974/ 1097] train: loss: 0.0330072
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0262072
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0027136
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0023838
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0051615
[Epoch 39] ogbg-molhiv: 0.734305 val loss: 0.769547
[Epoch 39] ogbg-molhiv: 0.608480 test loss: 0.533260
[Epoch 40; Iter    27/ 1097] train: loss: 0.0287430
[Epoch 40; Iter    57/ 1097] train: loss: 0.0097566
[Epoch 40; Iter    87/ 1097] train: loss: 0.1375548
[Epoch 40; Iter   117/ 1097] train: loss: 0.1156243
[Epoch 40; Iter   147/ 1097] train: loss: 0.0060437
[Epoch 40; Iter   177/ 1097] train: loss: 0.0585814
[Epoch 40; Iter   207/ 1097] train: loss: 0.0086346
[Epoch 40; Iter   237/ 1097] train: loss: 0.0029220
[Epoch 40; Iter   267/ 1097] train: loss: 0.2052966
[Epoch 40; Iter   297/ 1097] train: loss: 0.0995764
[Epoch 40; Iter   327/ 1097] train: loss: 0.0411090
[Epoch 40; Iter   357/ 1097] train: loss: 0.0046472
[Epoch 40; Iter   387/ 1097] train: loss: 0.0157127
[Epoch 40; Iter   417/ 1097] train: loss: 0.0304778
[Epoch 40; Iter   447/ 1097] train: loss: 0.0230145
[Epoch 40; Iter   477/ 1097] train: loss: 0.0057920
[Epoch 40; Iter   507/ 1097] train: loss: 0.0404650
[Epoch 40; Iter   537/ 1097] train: loss: 0.0051238
[Epoch 40; Iter   567/ 1097] train: loss: 0.0741850
[Epoch 40; Iter   597/ 1097] train: loss: 0.1289411
[Epoch 40; Iter   627/ 1097] train: loss: 0.0026270
[Epoch 40; Iter   657/ 1097] train: loss: 0.0018327
[Epoch 40; Iter   687/ 1097] train: loss: 0.0041515
[Epoch 32; Iter   553/ 1097] train: loss: 0.0779147
[Epoch 32; Iter   583/ 1097] train: loss: 0.0520319
[Epoch 32; Iter   613/ 1097] train: loss: 0.2988488
[Epoch 32; Iter   643/ 1097] train: loss: 0.0206768
[Epoch 32; Iter   673/ 1097] train: loss: 0.0256658
[Epoch 32; Iter   703/ 1097] train: loss: 0.1099292
[Epoch 32; Iter   733/ 1097] train: loss: 0.0229656
[Epoch 32; Iter   763/ 1097] train: loss: 0.0248731
[Epoch 32; Iter   793/ 1097] train: loss: 0.1821240
[Epoch 32; Iter   823/ 1097] train: loss: 0.1490050
[Epoch 32; Iter   853/ 1097] train: loss: 0.0510058
[Epoch 32; Iter   883/ 1097] train: loss: 0.0342914
[Epoch 32; Iter   913/ 1097] train: loss: 0.1077473
[Epoch 32; Iter   943/ 1097] train: loss: 0.0519802
[Epoch 32; Iter   973/ 1097] train: loss: 0.0506155
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0234281
[Epoch 32; Iter  1033/ 1097] train: loss: 0.2057422
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1009328
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0190308
[Epoch 32] ogbg-molhiv: 0.795026 val loss: 0.254775
[Epoch 32] ogbg-molhiv: 0.763763 test loss: 0.230751
[Epoch 33; Iter    26/ 1097] train: loss: 0.0553106
[Epoch 33; Iter    56/ 1097] train: loss: 0.1217571
[Epoch 33; Iter    86/ 1097] train: loss: 0.0167172
[Epoch 33; Iter   116/ 1097] train: loss: 0.0741782
[Epoch 33; Iter   146/ 1097] train: loss: 0.0338086
[Epoch 33; Iter   176/ 1097] train: loss: 0.0868917
[Epoch 33; Iter   206/ 1097] train: loss: 0.1992855
[Epoch 33; Iter   236/ 1097] train: loss: 0.0188178
[Epoch 33; Iter   266/ 1097] train: loss: 0.0928814
[Epoch 33; Iter   296/ 1097] train: loss: 0.0268640
[Epoch 33; Iter   326/ 1097] train: loss: 0.0557870
[Epoch 33; Iter   356/ 1097] train: loss: 0.0576513
[Epoch 33; Iter   386/ 1097] train: loss: 0.1946693
[Epoch 33; Iter   416/ 1097] train: loss: 0.2048893
[Epoch 33; Iter   446/ 1097] train: loss: 0.0412845
[Epoch 33; Iter   476/ 1097] train: loss: 0.1083695
[Epoch 33; Iter   506/ 1097] train: loss: 0.0457557
[Epoch 33; Iter   536/ 1097] train: loss: 0.0359351
[Epoch 33; Iter   566/ 1097] train: loss: 0.0221991
[Epoch 33; Iter   596/ 1097] train: loss: 0.0540564
[Epoch 33; Iter   626/ 1097] train: loss: 0.0180123
[Epoch 33; Iter   656/ 1097] train: loss: 0.2320588
[Epoch 33; Iter   686/ 1097] train: loss: 0.0197602
[Epoch 33; Iter   716/ 1097] train: loss: 0.0686514
[Epoch 33; Iter   746/ 1097] train: loss: 0.0384718
[Epoch 33; Iter   776/ 1097] train: loss: 0.0187789
[Epoch 33; Iter   806/ 1097] train: loss: 0.0294210
[Epoch 33; Iter   836/ 1097] train: loss: 0.0372469
[Epoch 33; Iter   866/ 1097] train: loss: 0.0611813
[Epoch 33; Iter   896/ 1097] train: loss: 0.0611642
[Epoch 33; Iter   926/ 1097] train: loss: 0.1232104
[Epoch 33; Iter   956/ 1097] train: loss: 0.0163845
[Epoch 33; Iter   986/ 1097] train: loss: 0.0989442
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0209675
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1629909
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0193417
[Epoch 33] ogbg-molhiv: 0.789826 val loss: 0.132653
[Epoch 33] ogbg-molhiv: 0.734348 test loss: 0.263225
[Epoch 34; Iter     9/ 1097] train: loss: 0.0243947
[Epoch 34; Iter    39/ 1097] train: loss: 0.0866866
[Epoch 34; Iter    69/ 1097] train: loss: 0.0648462
[Epoch 34; Iter    99/ 1097] train: loss: 0.0266789
[Epoch 34; Iter   129/ 1097] train: loss: 0.3138874
[Epoch 34; Iter   159/ 1097] train: loss: 0.0171296
[Epoch 34; Iter   189/ 1097] train: loss: 0.0574869
[Epoch 34; Iter   219/ 1097] train: loss: 0.1654374
[Epoch 34; Iter   249/ 1097] train: loss: 0.0367804
[Epoch 34; Iter   279/ 1097] train: loss: 0.3562710
[Epoch 34; Iter   309/ 1097] train: loss: 0.0307602
[Epoch 34; Iter   339/ 1097] train: loss: 0.0965658
[Epoch 34; Iter   369/ 1097] train: loss: 0.0256630
[Epoch 34; Iter   399/ 1097] train: loss: 0.0320429
[Epoch 34; Iter   429/ 1097] train: loss: 0.0375530
[Epoch 34; Iter   459/ 1097] train: loss: 0.1247377
[Epoch 34; Iter   489/ 1097] train: loss: 0.0228900
[Epoch 34; Iter   519/ 1097] train: loss: 0.0151044
[Epoch 34; Iter   549/ 1097] train: loss: 0.2838529
[Epoch 34; Iter   579/ 1097] train: loss: 0.0192915
[Epoch 34; Iter   609/ 1097] train: loss: 0.0590856
[Epoch 34; Iter   639/ 1097] train: loss: 0.0332483
[Epoch 34; Iter   669/ 1097] train: loss: 0.0499101
[Epoch 34; Iter   699/ 1097] train: loss: 0.1845695
[Epoch 34; Iter   729/ 1097] train: loss: 0.2643612
[Epoch 34; Iter   759/ 1097] train: loss: 0.0707970
[Epoch 34; Iter   789/ 1097] train: loss: 0.0282494
[Epoch 34; Iter   819/ 1097] train: loss: 0.1475062
[Epoch 34; Iter   849/ 1097] train: loss: 0.0144995
[Epoch 34; Iter   879/ 1097] train: loss: 0.0712886
[Epoch 34; Iter   909/ 1097] train: loss: 0.0273236
[Epoch 34; Iter   939/ 1097] train: loss: 0.0380747
[Epoch 34; Iter   969/ 1097] train: loss: 0.0684701
[Epoch 34; Iter   999/ 1097] train: loss: 0.0219553
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1774746
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0148948
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0144807
[Epoch 34] ogbg-molhiv: 0.790041 val loss: 0.076819
[Epoch 34] ogbg-molhiv: 0.772164 test loss: 0.165326
[Epoch 35; Iter    22/ 1097] train: loss: 0.0203826
[Epoch 35; Iter    52/ 1097] train: loss: 0.0155111
[Epoch 35; Iter    82/ 1097] train: loss: 0.0388047
[Epoch 35; Iter   112/ 1097] train: loss: 0.1362960
[Epoch 35; Iter   142/ 1097] train: loss: 0.1370900
[Epoch 35; Iter   172/ 1097] train: loss: 0.0794817
[Epoch 35; Iter   202/ 1097] train: loss: 0.1523219
[Epoch 35; Iter   232/ 1097] train: loss: 0.4793644
[Epoch 35; Iter   262/ 1097] train: loss: 0.0868047
[Epoch 35; Iter   292/ 1097] train: loss: 0.1094955
[Epoch 35; Iter   322/ 1097] train: loss: 0.1199592
[Epoch 35; Iter   352/ 1097] train: loss: 0.0225870
[Epoch 35; Iter   382/ 1097] train: loss: 0.0188108
[Epoch 35; Iter   412/ 1097] train: loss: 0.0262676
[Epoch 35; Iter   442/ 1097] train: loss: 0.1280337
[Epoch 35; Iter   472/ 1097] train: loss: 0.0389975
[Epoch 35; Iter   502/ 1097] train: loss: 0.2622406
[Epoch 35; Iter   532/ 1097] train: loss: 0.0524155
[Epoch 35; Iter   562/ 1097] train: loss: 0.0375479
[Epoch 35; Iter   592/ 1097] train: loss: 0.0262900
[Epoch 35; Iter   622/ 1097] train: loss: 0.0601245
[Epoch 35; Iter   652/ 1097] train: loss: 0.0941693
[Epoch 35; Iter   682/ 1097] train: loss: 0.0714976
[Epoch 35; Iter   712/ 1097] train: loss: 0.1349741
[Epoch 35; Iter   742/ 1097] train: loss: 0.0936401
[Epoch 35; Iter   772/ 1097] train: loss: 0.0330746
[Epoch 35; Iter   802/ 1097] train: loss: 0.0335375
[Epoch 35; Iter   832/ 1097] train: loss: 0.0669115
[Epoch 35; Iter   862/ 1097] train: loss: 0.1716033
[Epoch 35; Iter   892/ 1097] train: loss: 0.0350457
[Epoch 35; Iter   922/ 1097] train: loss: 0.1680972
[Epoch 35; Iter   952/ 1097] train: loss: 0.0723229
[Epoch 35; Iter   982/ 1097] train: loss: 0.1860136
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0450499
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0177155
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0366560
[Epoch 35] ogbg-molhiv: 0.801704 val loss: 0.078223
[Epoch 35] ogbg-molhiv: 0.754592 test loss: 0.122824
[Epoch 36; Iter     5/ 1097] train: loss: 0.1617861
[Epoch 36; Iter    35/ 1097] train: loss: 0.0319950
[Epoch 36; Iter    65/ 1097] train: loss: 0.0488390
[Epoch 36; Iter    95/ 1097] train: loss: 0.2058340
[Epoch 36; Iter   125/ 1097] train: loss: 0.0507264
[Epoch 36; Iter   155/ 1097] train: loss: 0.0300526
[Epoch 36; Iter   185/ 1097] train: loss: 0.0356165
[Epoch 36; Iter   215/ 1097] train: loss: 0.4009408
[Epoch 36; Iter   245/ 1097] train: loss: 0.1235583
[Epoch 36; Iter   275/ 1097] train: loss: 0.0274868
[Epoch 36; Iter   305/ 1097] train: loss: 0.1821356
[Epoch 36; Iter   335/ 1097] train: loss: 0.1065081
[Epoch 36; Iter   365/ 1097] train: loss: 0.0361885
[Epoch 36; Iter   395/ 1097] train: loss: 0.0835270
[Epoch 36; Iter   425/ 1097] train: loss: 0.1570663
[Epoch 36; Iter   455/ 1097] train: loss: 0.2224831
[Epoch 36; Iter   485/ 1097] train: loss: 0.0279737
[Epoch 36; Iter   515/ 1097] train: loss: 0.0408242
[Epoch 36; Iter   545/ 1097] train: loss: 0.0418642
[Epoch 36; Iter   575/ 1097] train: loss: 0.0187576
[Epoch 36; Iter   605/ 1097] train: loss: 0.0182751
[Epoch 32; Iter   553/ 1097] train: loss: 0.0168381
[Epoch 32; Iter   583/ 1097] train: loss: 0.2043046
[Epoch 32; Iter   613/ 1097] train: loss: 0.0198453
[Epoch 32; Iter   643/ 1097] train: loss: 0.2147056
[Epoch 32; Iter   673/ 1097] train: loss: 0.1827442
[Epoch 32; Iter   703/ 1097] train: loss: 0.1066634
[Epoch 32; Iter   733/ 1097] train: loss: 0.0295444
[Epoch 32; Iter   763/ 1097] train: loss: 0.0112931
[Epoch 32; Iter   793/ 1097] train: loss: 0.1905513
[Epoch 32; Iter   823/ 1097] train: loss: 0.0442658
[Epoch 32; Iter   853/ 1097] train: loss: 0.0572427
[Epoch 32; Iter   883/ 1097] train: loss: 0.0437505
[Epoch 32; Iter   913/ 1097] train: loss: 0.1817598
[Epoch 32; Iter   943/ 1097] train: loss: 0.0372190
[Epoch 32; Iter   973/ 1097] train: loss: 0.0242539
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1015433
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0948560
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0477790
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0192756
[Epoch 32] ogbg-molhiv: 0.818507 val loss: 0.083065
[Epoch 32] ogbg-molhiv: 0.751878 test loss: 0.172568
[Epoch 33; Iter    26/ 1097] train: loss: 0.1037921
[Epoch 33; Iter    56/ 1097] train: loss: 0.0465691
[Epoch 33; Iter    86/ 1097] train: loss: 0.0093359
[Epoch 33; Iter   116/ 1097] train: loss: 0.1297738
[Epoch 33; Iter   146/ 1097] train: loss: 0.0619529
[Epoch 33; Iter   176/ 1097] train: loss: 0.0147313
[Epoch 33; Iter   206/ 1097] train: loss: 0.0246958
[Epoch 33; Iter   236/ 1097] train: loss: 0.1360289
[Epoch 33; Iter   266/ 1097] train: loss: 0.0080520
[Epoch 33; Iter   296/ 1097] train: loss: 0.1520746
[Epoch 33; Iter   326/ 1097] train: loss: 0.0764058
[Epoch 33; Iter   356/ 1097] train: loss: 0.3569131
[Epoch 33; Iter   386/ 1097] train: loss: 0.0783070
[Epoch 33; Iter   416/ 1097] train: loss: 0.0111046
[Epoch 33; Iter   446/ 1097] train: loss: 0.0359020
[Epoch 33; Iter   476/ 1097] train: loss: 0.0792904
[Epoch 33; Iter   506/ 1097] train: loss: 0.0638466
[Epoch 33; Iter   536/ 1097] train: loss: 0.0580292
[Epoch 33; Iter   566/ 1097] train: loss: 0.0979532
[Epoch 33; Iter   596/ 1097] train: loss: 0.1315788
[Epoch 33; Iter   626/ 1097] train: loss: 0.2109134
[Epoch 33; Iter   656/ 1097] train: loss: 0.0099147
[Epoch 33; Iter   686/ 1097] train: loss: 0.0596195
[Epoch 33; Iter   716/ 1097] train: loss: 0.4725351
[Epoch 33; Iter   746/ 1097] train: loss: 0.1208873
[Epoch 33; Iter   776/ 1097] train: loss: 0.3429438
[Epoch 33; Iter   806/ 1097] train: loss: 0.0413770
[Epoch 33; Iter   836/ 1097] train: loss: 0.0492070
[Epoch 33; Iter   866/ 1097] train: loss: 0.0459456
[Epoch 33; Iter   896/ 1097] train: loss: 0.0198464
[Epoch 33; Iter   926/ 1097] train: loss: 0.0708423
[Epoch 33; Iter   956/ 1097] train: loss: 0.0245302
[Epoch 33; Iter   986/ 1097] train: loss: 0.2323832
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0553076
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0271839
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2574719
[Epoch 33] ogbg-molhiv: 0.814444 val loss: 0.079117
[Epoch 33] ogbg-molhiv: 0.754497 test loss: 0.165012
[Epoch 34; Iter     9/ 1097] train: loss: 0.0445359
[Epoch 34; Iter    39/ 1097] train: loss: 0.0596819
[Epoch 34; Iter    69/ 1097] train: loss: 0.0407208
[Epoch 34; Iter    99/ 1097] train: loss: 0.1200538
[Epoch 34; Iter   129/ 1097] train: loss: 0.0194261
[Epoch 34; Iter   159/ 1097] train: loss: 0.0472628
[Epoch 34; Iter   189/ 1097] train: loss: 0.0182037
[Epoch 34; Iter   219/ 1097] train: loss: 0.1133327
[Epoch 34; Iter   249/ 1097] train: loss: 0.0564461
[Epoch 34; Iter   279/ 1097] train: loss: 0.1108390
[Epoch 34; Iter   309/ 1097] train: loss: 0.0575874
[Epoch 34; Iter   339/ 1097] train: loss: 0.0805324
[Epoch 34; Iter   369/ 1097] train: loss: 0.0553606
[Epoch 34; Iter   399/ 1097] train: loss: 0.0396632
[Epoch 34; Iter   429/ 1097] train: loss: 0.0321160
[Epoch 34; Iter   459/ 1097] train: loss: 0.0306283
[Epoch 34; Iter   489/ 1097] train: loss: 0.0546038
[Epoch 34; Iter   519/ 1097] train: loss: 0.0157837
[Epoch 34; Iter   549/ 1097] train: loss: 0.0091297
[Epoch 34; Iter   579/ 1097] train: loss: 0.1387412
[Epoch 34; Iter   609/ 1097] train: loss: 0.0367649
[Epoch 34; Iter   639/ 1097] train: loss: 0.1050822
[Epoch 34; Iter   669/ 1097] train: loss: 0.0487948
[Epoch 34; Iter   699/ 1097] train: loss: 0.1727240
[Epoch 34; Iter   729/ 1097] train: loss: 0.0127006
[Epoch 34; Iter   759/ 1097] train: loss: 0.4002478
[Epoch 34; Iter   789/ 1097] train: loss: 0.0096628
[Epoch 34; Iter   819/ 1097] train: loss: 0.0143558
[Epoch 34; Iter   849/ 1097] train: loss: 0.2278444
[Epoch 34; Iter   879/ 1097] train: loss: 0.0397421
[Epoch 34; Iter   909/ 1097] train: loss: 0.0412022
[Epoch 34; Iter   939/ 1097] train: loss: 0.0131656
[Epoch 34; Iter   969/ 1097] train: loss: 0.1352473
[Epoch 34; Iter   999/ 1097] train: loss: 0.0317527
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0391247
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1322522
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0329448
[Epoch 34] ogbg-molhiv: 0.825336 val loss: 0.079417
[Epoch 34] ogbg-molhiv: 0.745793 test loss: 0.207080
[Epoch 35; Iter    22/ 1097] train: loss: 0.0152711
[Epoch 35; Iter    52/ 1097] train: loss: 0.0206399
[Epoch 35; Iter    82/ 1097] train: loss: 0.0977983
[Epoch 35; Iter   112/ 1097] train: loss: 0.1478560
[Epoch 35; Iter   142/ 1097] train: loss: 0.0133758
[Epoch 35; Iter   172/ 1097] train: loss: 0.0238353
[Epoch 35; Iter   202/ 1097] train: loss: 0.0296027
[Epoch 35; Iter   232/ 1097] train: loss: 0.0156245
[Epoch 35; Iter   262/ 1097] train: loss: 0.0845479
[Epoch 35; Iter   292/ 1097] train: loss: 0.0121051
[Epoch 35; Iter   322/ 1097] train: loss: 0.0182747
[Epoch 35; Iter   352/ 1097] train: loss: 0.0178436
[Epoch 35; Iter   382/ 1097] train: loss: 0.0148633
[Epoch 35; Iter   412/ 1097] train: loss: 0.0159729
[Epoch 35; Iter   442/ 1097] train: loss: 0.0947485
[Epoch 35; Iter   472/ 1097] train: loss: 0.0236804
[Epoch 35; Iter   502/ 1097] train: loss: 0.0222233
[Epoch 35; Iter   532/ 1097] train: loss: 0.0326154
[Epoch 35; Iter   562/ 1097] train: loss: 0.1881119
[Epoch 35; Iter   592/ 1097] train: loss: 0.0324601
[Epoch 35; Iter   622/ 1097] train: loss: 0.1756682
[Epoch 35; Iter   652/ 1097] train: loss: 0.0366506
[Epoch 35; Iter   682/ 1097] train: loss: 0.1958652
[Epoch 35; Iter   712/ 1097] train: loss: 0.1603533
[Epoch 35; Iter   742/ 1097] train: loss: 0.0198922
[Epoch 35; Iter   772/ 1097] train: loss: 0.1925818
[Epoch 35; Iter   802/ 1097] train: loss: 0.0175950
[Epoch 35; Iter   832/ 1097] train: loss: 0.0233026
[Epoch 35; Iter   862/ 1097] train: loss: 0.0437007
[Epoch 35; Iter   892/ 1097] train: loss: 0.2659454
[Epoch 35; Iter   922/ 1097] train: loss: 0.0117390
[Epoch 35; Iter   952/ 1097] train: loss: 0.0513219
[Epoch 35; Iter   982/ 1097] train: loss: 0.0156408
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0245180
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0127446
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0221683
[Epoch 35] ogbg-molhiv: 0.804606 val loss: 0.503451
[Epoch 35] ogbg-molhiv: 0.763066 test loss: 1.015176
[Epoch 36; Iter     5/ 1097] train: loss: 0.0270298
[Epoch 36; Iter    35/ 1097] train: loss: 0.0398179
[Epoch 36; Iter    65/ 1097] train: loss: 0.0333457
[Epoch 36; Iter    95/ 1097] train: loss: 0.0708680
[Epoch 36; Iter   125/ 1097] train: loss: 0.0154347
[Epoch 36; Iter   155/ 1097] train: loss: 0.0329117
[Epoch 36; Iter   185/ 1097] train: loss: 0.0935713
[Epoch 36; Iter   215/ 1097] train: loss: 0.0278866
[Epoch 36; Iter   245/ 1097] train: loss: 0.2960336
[Epoch 36; Iter   275/ 1097] train: loss: 0.0379637
[Epoch 36; Iter   305/ 1097] train: loss: 0.0165208
[Epoch 36; Iter   335/ 1097] train: loss: 0.1329564
[Epoch 36; Iter   365/ 1097] train: loss: 0.2058199
[Epoch 36; Iter   395/ 1097] train: loss: 0.0126561
[Epoch 36; Iter   425/ 1097] train: loss: 0.0592173
[Epoch 36; Iter   455/ 1097] train: loss: 0.0291229
[Epoch 36; Iter   485/ 1097] train: loss: 0.0196664
[Epoch 36; Iter   515/ 1097] train: loss: 0.2944173
[Epoch 36; Iter   545/ 1097] train: loss: 0.1949914
[Epoch 36; Iter   575/ 1097] train: loss: 0.0734670
[Epoch 36; Iter   605/ 1097] train: loss: 0.0205597
[Epoch 32; Iter   553/ 1097] train: loss: 0.0499926
[Epoch 32; Iter   583/ 1097] train: loss: 0.0486959
[Epoch 32; Iter   613/ 1097] train: loss: 0.0175733
[Epoch 32; Iter   643/ 1097] train: loss: 0.0202108
[Epoch 32; Iter   673/ 1097] train: loss: 0.3345773
[Epoch 32; Iter   703/ 1097] train: loss: 0.0256662
[Epoch 32; Iter   733/ 1097] train: loss: 0.0356609
[Epoch 32; Iter   763/ 1097] train: loss: 0.1080685
[Epoch 32; Iter   793/ 1097] train: loss: 0.0160174
[Epoch 32; Iter   823/ 1097] train: loss: 0.0591138
[Epoch 32; Iter   853/ 1097] train: loss: 0.0396423
[Epoch 32; Iter   883/ 1097] train: loss: 0.0324217
[Epoch 32; Iter   913/ 1097] train: loss: 0.1725264
[Epoch 32; Iter   943/ 1097] train: loss: 0.2039087
[Epoch 32; Iter   973/ 1097] train: loss: 0.0268435
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0865279
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0249622
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1760300
[Epoch 32; Iter  1093/ 1097] train: loss: 0.1204028
[Epoch 32] ogbg-molhiv: 0.814236 val loss: 0.843074
[Epoch 32] ogbg-molhiv: 0.735775 test loss: 0.979654
[Epoch 33; Iter    26/ 1097] train: loss: 0.0440595
[Epoch 33; Iter    56/ 1097] train: loss: 0.2203971
[Epoch 33; Iter    86/ 1097] train: loss: 0.0424055
[Epoch 33; Iter   116/ 1097] train: loss: 0.2654695
[Epoch 33; Iter   146/ 1097] train: loss: 0.0475084
[Epoch 33; Iter   176/ 1097] train: loss: 0.0178153
[Epoch 33; Iter   206/ 1097] train: loss: 0.0161450
[Epoch 33; Iter   236/ 1097] train: loss: 0.2374778
[Epoch 33; Iter   266/ 1097] train: loss: 0.0182340
[Epoch 33; Iter   296/ 1097] train: loss: 0.1784775
[Epoch 33; Iter   326/ 1097] train: loss: 0.2553917
[Epoch 33; Iter   356/ 1097] train: loss: 0.2923243
[Epoch 33; Iter   386/ 1097] train: loss: 0.0537270
[Epoch 33; Iter   416/ 1097] train: loss: 0.0721243
[Epoch 33; Iter   446/ 1097] train: loss: 0.0198855
[Epoch 33; Iter   476/ 1097] train: loss: 0.1534503
[Epoch 33; Iter   506/ 1097] train: loss: 0.1434242
[Epoch 33; Iter   536/ 1097] train: loss: 0.0212686
[Epoch 33; Iter   566/ 1097] train: loss: 0.0363847
[Epoch 33; Iter   596/ 1097] train: loss: 0.0545325
[Epoch 33; Iter   626/ 1097] train: loss: 0.0354813
[Epoch 33; Iter   656/ 1097] train: loss: 0.0294402
[Epoch 33; Iter   686/ 1097] train: loss: 0.0286212
[Epoch 33; Iter   716/ 1097] train: loss: 0.0295630
[Epoch 33; Iter   746/ 1097] train: loss: 0.0198209
[Epoch 33; Iter   776/ 1097] train: loss: 0.1639010
[Epoch 33; Iter   806/ 1097] train: loss: 0.1063739
[Epoch 33; Iter   836/ 1097] train: loss: 0.0381868
[Epoch 33; Iter   866/ 1097] train: loss: 0.0954198
[Epoch 33; Iter   896/ 1097] train: loss: 0.0712294
[Epoch 33; Iter   926/ 1097] train: loss: 0.0347891
[Epoch 33; Iter   956/ 1097] train: loss: 0.0156198
[Epoch 33; Iter   986/ 1097] train: loss: 0.0206602
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0277013
[Epoch 33; Iter  1046/ 1097] train: loss: 0.2451035
[Epoch 33; Iter  1076/ 1097] train: loss: 0.3179775
[Epoch 33] ogbg-molhiv: 0.809913 val loss: 0.218247
[Epoch 33] ogbg-molhiv: 0.738929 test loss: 0.225796
[Epoch 34; Iter     9/ 1097] train: loss: 0.0180481
[Epoch 34; Iter    39/ 1097] train: loss: 0.1655704
[Epoch 34; Iter    69/ 1097] train: loss: 0.0365786
[Epoch 34; Iter    99/ 1097] train: loss: 0.0358849
[Epoch 34; Iter   129/ 1097] train: loss: 0.1651353
[Epoch 34; Iter   159/ 1097] train: loss: 0.0227599
[Epoch 34; Iter   189/ 1097] train: loss: 0.1351760
[Epoch 34; Iter   219/ 1097] train: loss: 0.0189758
[Epoch 34; Iter   249/ 1097] train: loss: 0.0554104
[Epoch 34; Iter   279/ 1097] train: loss: 0.1393916
[Epoch 34; Iter   309/ 1097] train: loss: 0.0229885
[Epoch 34; Iter   339/ 1097] train: loss: 0.1960525
[Epoch 34; Iter   369/ 1097] train: loss: 0.2490610
[Epoch 34; Iter   399/ 1097] train: loss: 0.1564249
[Epoch 34; Iter   429/ 1097] train: loss: 0.0361518
[Epoch 34; Iter   459/ 1097] train: loss: 0.1072713
[Epoch 34; Iter   489/ 1097] train: loss: 0.0296823
[Epoch 34; Iter   519/ 1097] train: loss: 0.0174147
[Epoch 34; Iter   549/ 1097] train: loss: 0.0356797
[Epoch 34; Iter   579/ 1097] train: loss: 0.1131475
[Epoch 34; Iter   609/ 1097] train: loss: 0.0611637
[Epoch 34; Iter   639/ 1097] train: loss: 0.1535026
[Epoch 34; Iter   669/ 1097] train: loss: 0.0301768
[Epoch 34; Iter   699/ 1097] train: loss: 0.0436287
[Epoch 34; Iter   729/ 1097] train: loss: 0.4090362
[Epoch 34; Iter   759/ 1097] train: loss: 0.0421831
[Epoch 34; Iter   789/ 1097] train: loss: 0.0151953
[Epoch 34; Iter   819/ 1097] train: loss: 0.2217678
[Epoch 34; Iter   849/ 1097] train: loss: 0.0194217
[Epoch 34; Iter   879/ 1097] train: loss: 0.2041299
[Epoch 34; Iter   909/ 1097] train: loss: 0.0466599
[Epoch 34; Iter   939/ 1097] train: loss: 0.1080698
[Epoch 34; Iter   969/ 1097] train: loss: 0.0374031
[Epoch 34; Iter   999/ 1097] train: loss: 0.0225399
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0286404
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0383841
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0162615
[Epoch 34] ogbg-molhiv: 0.797895 val loss: 0.421359
[Epoch 34] ogbg-molhiv: 0.737348 test loss: 0.819215
[Epoch 35; Iter    22/ 1097] train: loss: 0.0337083
[Epoch 35; Iter    52/ 1097] train: loss: 0.0786276
[Epoch 35; Iter    82/ 1097] train: loss: 0.1690146
[Epoch 35; Iter   112/ 1097] train: loss: 0.1621572
[Epoch 35; Iter   142/ 1097] train: loss: 0.0197639
[Epoch 35; Iter   172/ 1097] train: loss: 0.0365826
[Epoch 35; Iter   202/ 1097] train: loss: 0.0349757
[Epoch 35; Iter   232/ 1097] train: loss: 0.0743523
[Epoch 35; Iter   262/ 1097] train: loss: 0.0098144
[Epoch 35; Iter   292/ 1097] train: loss: 0.0156330
[Epoch 35; Iter   322/ 1097] train: loss: 0.1937278
[Epoch 35; Iter   352/ 1097] train: loss: 0.3267303
[Epoch 35; Iter   382/ 1097] train: loss: 0.2564136
[Epoch 35; Iter   412/ 1097] train: loss: 0.0724753
[Epoch 35; Iter   442/ 1097] train: loss: 0.0758542
[Epoch 35; Iter   472/ 1097] train: loss: 0.0266397
[Epoch 35; Iter   502/ 1097] train: loss: 0.0388201
[Epoch 35; Iter   532/ 1097] train: loss: 0.1968105
[Epoch 35; Iter   562/ 1097] train: loss: 0.1933540
[Epoch 35; Iter   592/ 1097] train: loss: 0.0416833
[Epoch 35; Iter   622/ 1097] train: loss: 0.2158146
[Epoch 35; Iter   652/ 1097] train: loss: 0.1386764
[Epoch 35; Iter   682/ 1097] train: loss: 0.0271256
[Epoch 35; Iter   712/ 1097] train: loss: 0.1507083
[Epoch 35; Iter   742/ 1097] train: loss: 0.1420578
[Epoch 35; Iter   772/ 1097] train: loss: 0.0709766
[Epoch 35; Iter   802/ 1097] train: loss: 0.0644220
[Epoch 35; Iter   832/ 1097] train: loss: 0.0733696
[Epoch 35; Iter   862/ 1097] train: loss: 0.0791661
[Epoch 35; Iter   892/ 1097] train: loss: 0.0221534
[Epoch 35; Iter   922/ 1097] train: loss: 0.0289721
[Epoch 35; Iter   952/ 1097] train: loss: 0.1105629
[Epoch 35; Iter   982/ 1097] train: loss: 0.1274244
[Epoch 35; Iter  1012/ 1097] train: loss: 0.1539416
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1571165
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0229224
[Epoch 35] ogbg-molhiv: 0.810314 val loss: 0.102277
[Epoch 35] ogbg-molhiv: 0.731633 test loss: 0.311875
[Epoch 36; Iter     5/ 1097] train: loss: 0.0193120
[Epoch 36; Iter    35/ 1097] train: loss: 0.0241021
[Epoch 36; Iter    65/ 1097] train: loss: 0.0409514
[Epoch 36; Iter    95/ 1097] train: loss: 0.0234353
[Epoch 36; Iter   125/ 1097] train: loss: 0.2158387
[Epoch 36; Iter   155/ 1097] train: loss: 0.0539370
[Epoch 36; Iter   185/ 1097] train: loss: 0.0589123
[Epoch 36; Iter   215/ 1097] train: loss: 0.1432532
[Epoch 36; Iter   245/ 1097] train: loss: 0.0288774
[Epoch 36; Iter   275/ 1097] train: loss: 0.2197514
[Epoch 36; Iter   305/ 1097] train: loss: 0.2641646
[Epoch 36; Iter   335/ 1097] train: loss: 0.0252627
[Epoch 36; Iter   365/ 1097] train: loss: 0.1339642
[Epoch 36; Iter   395/ 1097] train: loss: 0.0201547
[Epoch 36; Iter   425/ 1097] train: loss: 0.0333401
[Epoch 36; Iter   455/ 1097] train: loss: 0.0313559
[Epoch 36; Iter   485/ 1097] train: loss: 0.0338108
[Epoch 36; Iter   515/ 1097] train: loss: 0.0851588
[Epoch 36; Iter   545/ 1097] train: loss: 0.1490049
[Epoch 36; Iter   575/ 1097] train: loss: 0.0307595
[Epoch 36; Iter   605/ 1097] train: loss: 0.1781403
[Epoch 40; Iter   687/ 1097] train: loss: 0.0871999
[Epoch 40; Iter   717/ 1097] train: loss: 0.1012689
[Epoch 40; Iter   747/ 1097] train: loss: 0.0154786
[Epoch 40; Iter   777/ 1097] train: loss: 0.1610481
[Epoch 40; Iter   807/ 1097] train: loss: 0.0114343
[Epoch 40; Iter   837/ 1097] train: loss: 0.0093262
[Epoch 40; Iter   867/ 1097] train: loss: 0.0039697
[Epoch 40; Iter   897/ 1097] train: loss: 0.0089566
[Epoch 40; Iter   927/ 1097] train: loss: 0.0737053
[Epoch 40; Iter   957/ 1097] train: loss: 0.2621825
[Epoch 40; Iter   987/ 1097] train: loss: 0.0203595
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0035930
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0069456
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0572164
[Epoch 40] ogbg-molhiv: 0.757664 val loss: 0.219505
[Epoch 40] ogbg-molhiv: 0.678823 test loss: 0.292260
[Epoch 41; Iter    10/ 1097] train: loss: 0.0300848
[Epoch 41; Iter    40/ 1097] train: loss: 0.0010095
[Epoch 41; Iter    70/ 1097] train: loss: 0.0037100
[Epoch 41; Iter   100/ 1097] train: loss: 0.0093436
[Epoch 41; Iter   130/ 1097] train: loss: 0.0069300
[Epoch 41; Iter   160/ 1097] train: loss: 0.0126933
[Epoch 41; Iter   190/ 1097] train: loss: 0.0112850
[Epoch 41; Iter   220/ 1097] train: loss: 0.0020431
[Epoch 41; Iter   250/ 1097] train: loss: 0.0139617
[Epoch 41; Iter   280/ 1097] train: loss: 0.0987694
[Epoch 41; Iter   310/ 1097] train: loss: 0.0081885
[Epoch 41; Iter   340/ 1097] train: loss: 0.0153986
[Epoch 41; Iter   370/ 1097] train: loss: 0.0017896
[Epoch 41; Iter   400/ 1097] train: loss: 0.0086279
[Epoch 41; Iter   430/ 1097] train: loss: 0.0054690
[Epoch 41; Iter   460/ 1097] train: loss: 0.0021618
[Epoch 41; Iter   490/ 1097] train: loss: 0.0271195
[Epoch 41; Iter   520/ 1097] train: loss: 0.0019911
[Epoch 41; Iter   550/ 1097] train: loss: 0.0053974
[Epoch 41; Iter   580/ 1097] train: loss: 0.0112595
[Epoch 41; Iter   610/ 1097] train: loss: 0.0225766
[Epoch 41; Iter   640/ 1097] train: loss: 0.0033777
[Epoch 41; Iter   670/ 1097] train: loss: 0.0080617
[Epoch 41; Iter   700/ 1097] train: loss: 0.0397269
[Epoch 41; Iter   730/ 1097] train: loss: 0.0021236
[Epoch 41; Iter   760/ 1097] train: loss: 0.0152038
[Epoch 41; Iter   790/ 1097] train: loss: 0.0050195
[Epoch 41; Iter   820/ 1097] train: loss: 0.0197590
[Epoch 41; Iter   850/ 1097] train: loss: 0.2121156
[Epoch 41; Iter   880/ 1097] train: loss: 0.0059639
[Epoch 41; Iter   910/ 1097] train: loss: 0.0053049
[Epoch 41; Iter   940/ 1097] train: loss: 0.0855858
[Epoch 41; Iter   970/ 1097] train: loss: 0.0013265
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0116226
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0865152
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0026935
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0156729
[Epoch 41] ogbg-molhiv: 0.784422 val loss: 0.733886
[Epoch 41] ogbg-molhiv: 0.692771 test loss: 0.358635
[Epoch 42; Iter    23/ 1097] train: loss: 0.0039128
[Epoch 42; Iter    53/ 1097] train: loss: 0.0006812
[Epoch 42; Iter    83/ 1097] train: loss: 0.0035333
[Epoch 42; Iter   113/ 1097] train: loss: 0.0246933
[Epoch 42; Iter   143/ 1097] train: loss: 0.0092311
[Epoch 42; Iter   173/ 1097] train: loss: 0.0028497
[Epoch 42; Iter   203/ 1097] train: loss: 0.0020796
[Epoch 42; Iter   233/ 1097] train: loss: 0.0169267
[Epoch 42; Iter   263/ 1097] train: loss: 0.0182032
[Epoch 42; Iter   293/ 1097] train: loss: 0.0008181
[Epoch 42; Iter   323/ 1097] train: loss: 0.0169967
[Epoch 42; Iter   353/ 1097] train: loss: 0.0240356
[Epoch 42; Iter   383/ 1097] train: loss: 0.0415578
[Epoch 42; Iter   413/ 1097] train: loss: 0.0335526
[Epoch 42; Iter   443/ 1097] train: loss: 0.0126876
[Epoch 42; Iter   473/ 1097] train: loss: 0.0017160
[Epoch 42; Iter   503/ 1097] train: loss: 0.0033855
[Epoch 42; Iter   533/ 1097] train: loss: 0.0028498
[Epoch 42; Iter   563/ 1097] train: loss: 0.0017864
[Epoch 42; Iter   593/ 1097] train: loss: 0.0021004
[Epoch 42; Iter   623/ 1097] train: loss: 0.0042276
[Epoch 42; Iter   653/ 1097] train: loss: 0.0109227
[Epoch 42; Iter   683/ 1097] train: loss: 0.0072307
[Epoch 42; Iter   713/ 1097] train: loss: 0.0107535
[Epoch 42; Iter   743/ 1097] train: loss: 0.0034358
[Epoch 42; Iter   773/ 1097] train: loss: 0.0080542
[Epoch 42; Iter   803/ 1097] train: loss: 0.3124732
[Epoch 42; Iter   833/ 1097] train: loss: 0.0063881
[Epoch 42; Iter   863/ 1097] train: loss: 0.0010991
[Epoch 42; Iter   893/ 1097] train: loss: 0.0473177
[Epoch 42; Iter   923/ 1097] train: loss: 0.1355175
[Epoch 42; Iter   953/ 1097] train: loss: 0.0191671
[Epoch 42; Iter   983/ 1097] train: loss: 0.0022311
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0209874
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0017080
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0097745
[Epoch 42] ogbg-molhiv: 0.776685 val loss: 1.118053
[Epoch 42] ogbg-molhiv: 0.685504 test loss: 0.372422
[Epoch 43; Iter     6/ 1097] train: loss: 0.0098558
[Epoch 43; Iter    36/ 1097] train: loss: 0.0006532
[Epoch 43; Iter    66/ 1097] train: loss: 0.0529369
[Epoch 43; Iter    96/ 1097] train: loss: 0.0057999
[Epoch 43; Iter   126/ 1097] train: loss: 0.0022278
[Epoch 43; Iter   156/ 1097] train: loss: 0.0377564
[Epoch 43; Iter   186/ 1097] train: loss: 0.0381005
[Epoch 43; Iter   216/ 1097] train: loss: 0.0083607
[Epoch 43; Iter   246/ 1097] train: loss: 0.0310697
[Epoch 43; Iter   276/ 1097] train: loss: 0.0025553
[Epoch 43; Iter   306/ 1097] train: loss: 0.1347478
[Epoch 43; Iter   336/ 1097] train: loss: 0.0011903
[Epoch 43; Iter   366/ 1097] train: loss: 0.0059671
[Epoch 43; Iter   396/ 1097] train: loss: 0.0023147
[Epoch 43; Iter   426/ 1097] train: loss: 0.0211303
[Epoch 43; Iter   456/ 1097] train: loss: 0.0076048
[Epoch 43; Iter   486/ 1097] train: loss: 0.0403815
[Epoch 43; Iter   516/ 1097] train: loss: 0.0140412
[Epoch 43; Iter   546/ 1097] train: loss: 0.0548176
[Epoch 43; Iter   576/ 1097] train: loss: 0.0013991
[Epoch 43; Iter   606/ 1097] train: loss: 0.0157803
[Epoch 43; Iter   636/ 1097] train: loss: 0.0011224
[Epoch 43; Iter   666/ 1097] train: loss: 0.0043909
[Epoch 43; Iter   696/ 1097] train: loss: 0.0925303
[Epoch 43; Iter   726/ 1097] train: loss: 0.0117044
[Epoch 43; Iter   756/ 1097] train: loss: 0.0089200
[Epoch 43; Iter   786/ 1097] train: loss: 0.0128595
[Epoch 43; Iter   816/ 1097] train: loss: 0.0287167
[Epoch 43; Iter   846/ 1097] train: loss: 0.0072220
[Epoch 43; Iter   876/ 1097] train: loss: 0.0801456
[Epoch 43; Iter   906/ 1097] train: loss: 0.0531214
[Epoch 43; Iter   936/ 1097] train: loss: 0.0495323
[Epoch 43; Iter   966/ 1097] train: loss: 0.0164817
[Epoch 43; Iter   996/ 1097] train: loss: 0.0241606
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0222514
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0012519
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0049306
[Epoch 43] ogbg-molhiv: 0.765616 val loss: 1.295791
[Epoch 43] ogbg-molhiv: 0.674353 test loss: 0.380730
[Epoch 44; Iter    19/ 1097] train: loss: 0.0412690
[Epoch 44; Iter    49/ 1097] train: loss: 0.0031946
[Epoch 44; Iter    79/ 1097] train: loss: 0.0063786
[Epoch 44; Iter   109/ 1097] train: loss: 0.0519780
[Epoch 44; Iter   139/ 1097] train: loss: 0.0004045
[Epoch 44; Iter   169/ 1097] train: loss: 0.0019701
[Epoch 44; Iter   199/ 1097] train: loss: 0.0328090
[Epoch 44; Iter   229/ 1097] train: loss: 0.0018422
[Epoch 44; Iter   259/ 1097] train: loss: 0.0020124
[Epoch 44; Iter   289/ 1097] train: loss: 0.0125892
[Epoch 44; Iter   319/ 1097] train: loss: 0.0047445
[Epoch 44; Iter   349/ 1097] train: loss: 0.0036939
[Epoch 44; Iter   379/ 1097] train: loss: 0.0098720
[Epoch 44; Iter   409/ 1097] train: loss: 0.0073318
[Epoch 44; Iter   439/ 1097] train: loss: 0.0049874
[Epoch 44; Iter   469/ 1097] train: loss: 0.0012976
[Epoch 44; Iter   499/ 1097] train: loss: 0.0347422
[Epoch 44; Iter   529/ 1097] train: loss: 0.0190662
[Epoch 44; Iter   559/ 1097] train: loss: 0.0142165
[Epoch 44; Iter   589/ 1097] train: loss: 0.0083043
[Epoch 44; Iter   619/ 1097] train: loss: 0.0012455
[Epoch 44; Iter   649/ 1097] train: loss: 0.0059053
[Epoch 44; Iter   679/ 1097] train: loss: 0.0250787
[Epoch 44; Iter   709/ 1097] train: loss: 0.0015343
[Epoch 44; Iter   739/ 1097] train: loss: 0.0155784
[Epoch 40; Iter   687/ 1097] train: loss: 0.0016915
[Epoch 40; Iter   717/ 1097] train: loss: 0.0239752
[Epoch 40; Iter   747/ 1097] train: loss: 0.0013532
[Epoch 40; Iter   777/ 1097] train: loss: 0.0015098
[Epoch 40; Iter   807/ 1097] train: loss: 0.0036418
[Epoch 40; Iter   837/ 1097] train: loss: 0.0345368
[Epoch 40; Iter   867/ 1097] train: loss: 0.0021480
[Epoch 40; Iter   897/ 1097] train: loss: 0.0009965
[Epoch 40; Iter   927/ 1097] train: loss: 0.0899308
[Epoch 40; Iter   957/ 1097] train: loss: 0.0892115
[Epoch 40; Iter   987/ 1097] train: loss: 0.0097702
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0230459
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0009086
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0246436
[Epoch 40] ogbg-molhiv: 0.819490 val loss: 1.672759
[Epoch 40] ogbg-molhiv: 0.725559 test loss: 0.432428
[Epoch 41; Iter    10/ 1097] train: loss: 0.0027167
[Epoch 41; Iter    40/ 1097] train: loss: 0.0017280
[Epoch 41; Iter    70/ 1097] train: loss: 0.0018203
[Epoch 41; Iter   100/ 1097] train: loss: 0.0015173
[Epoch 41; Iter   130/ 1097] train: loss: 0.0044497
[Epoch 41; Iter   160/ 1097] train: loss: 0.0004750
[Epoch 41; Iter   190/ 1097] train: loss: 0.0050079
[Epoch 41; Iter   220/ 1097] train: loss: 0.0091558
[Epoch 41; Iter   250/ 1097] train: loss: 0.0005717
[Epoch 41; Iter   280/ 1097] train: loss: 0.0528582
[Epoch 41; Iter   310/ 1097] train: loss: 0.0727492
[Epoch 41; Iter   340/ 1097] train: loss: 0.0471704
[Epoch 41; Iter   370/ 1097] train: loss: 0.0010438
[Epoch 41; Iter   400/ 1097] train: loss: 0.0142238
[Epoch 41; Iter   430/ 1097] train: loss: 0.0047086
[Epoch 41; Iter   460/ 1097] train: loss: 0.0050875
[Epoch 41; Iter   490/ 1097] train: loss: 0.0074229
[Epoch 41; Iter   520/ 1097] train: loss: 0.0440809
[Epoch 41; Iter   550/ 1097] train: loss: 0.0010587
[Epoch 41; Iter   580/ 1097] train: loss: 0.0039571
[Epoch 41; Iter   610/ 1097] train: loss: 0.0027995
[Epoch 41; Iter   640/ 1097] train: loss: 0.0055862
[Epoch 41; Iter   670/ 1097] train: loss: 0.0048334
[Epoch 41; Iter   700/ 1097] train: loss: 0.0062290
[Epoch 41; Iter   730/ 1097] train: loss: 0.0039101
[Epoch 41; Iter   760/ 1097] train: loss: 0.0650670
[Epoch 41; Iter   790/ 1097] train: loss: 0.0580153
[Epoch 41; Iter   820/ 1097] train: loss: 0.0522411
[Epoch 41; Iter   850/ 1097] train: loss: 0.0064981
[Epoch 41; Iter   880/ 1097] train: loss: 0.0557206
[Epoch 41; Iter   910/ 1097] train: loss: 0.0088836
[Epoch 41; Iter   940/ 1097] train: loss: 0.0059609
[Epoch 41; Iter   970/ 1097] train: loss: 0.0975940
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0306411
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0012837
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0245469
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0025061
[Epoch 41] ogbg-molhiv: 0.811973 val loss: 0.966011
[Epoch 41] ogbg-molhiv: 0.728467 test loss: 0.325585
[Epoch 42; Iter    23/ 1097] train: loss: 0.0083604
[Epoch 42; Iter    53/ 1097] train: loss: 0.0009282
[Epoch 42; Iter    83/ 1097] train: loss: 0.0038038
[Epoch 42; Iter   113/ 1097] train: loss: 0.0029291
[Epoch 42; Iter   143/ 1097] train: loss: 0.0008226
[Epoch 42; Iter   173/ 1097] train: loss: 0.0075988
[Epoch 42; Iter   203/ 1097] train: loss: 0.0849156
[Epoch 42; Iter   233/ 1097] train: loss: 0.0026964
[Epoch 42; Iter   263/ 1097] train: loss: 0.0487914
[Epoch 42; Iter   293/ 1097] train: loss: 0.0210173
[Epoch 42; Iter   323/ 1097] train: loss: 0.0133863
[Epoch 42; Iter   353/ 1097] train: loss: 0.0094211
[Epoch 42; Iter   383/ 1097] train: loss: 0.0025145
[Epoch 42; Iter   413/ 1097] train: loss: 0.0012039
[Epoch 42; Iter   443/ 1097] train: loss: 0.0500811
[Epoch 42; Iter   473/ 1097] train: loss: 0.0051577
[Epoch 42; Iter   503/ 1097] train: loss: 0.0293260
[Epoch 42; Iter   533/ 1097] train: loss: 0.0119745
[Epoch 42; Iter   563/ 1097] train: loss: 0.0069122
[Epoch 42; Iter   593/ 1097] train: loss: 0.0086595
[Epoch 42; Iter   623/ 1097] train: loss: 0.0127402
[Epoch 42; Iter   653/ 1097] train: loss: 0.0146388
[Epoch 42; Iter   683/ 1097] train: loss: 0.0006970
[Epoch 42; Iter   713/ 1097] train: loss: 0.0024731
[Epoch 42; Iter   743/ 1097] train: loss: 0.0078738
[Epoch 42; Iter   773/ 1097] train: loss: 0.0610366
[Epoch 42; Iter   803/ 1097] train: loss: 0.0522873
[Epoch 42; Iter   833/ 1097] train: loss: 0.0050353
[Epoch 42; Iter   863/ 1097] train: loss: 0.0360519
[Epoch 42; Iter   893/ 1097] train: loss: 0.0917044
[Epoch 42; Iter   923/ 1097] train: loss: 0.0078655
[Epoch 42; Iter   953/ 1097] train: loss: 0.0069409
[Epoch 42; Iter   983/ 1097] train: loss: 0.0109177
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0084673
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0305185
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0009389
[Epoch 42] ogbg-molhiv: 0.794392 val loss: 1.434722
[Epoch 42] ogbg-molhiv: 0.725095 test loss: 0.479669
[Epoch 43; Iter     6/ 1097] train: loss: 0.0038218
[Epoch 43; Iter    36/ 1097] train: loss: 0.0018309
[Epoch 43; Iter    66/ 1097] train: loss: 0.0284059
[Epoch 43; Iter    96/ 1097] train: loss: 0.0008671
[Epoch 43; Iter   126/ 1097] train: loss: 0.0049544
[Epoch 43; Iter   156/ 1097] train: loss: 0.0143979
[Epoch 43; Iter   186/ 1097] train: loss: 0.0337723
[Epoch 43; Iter   216/ 1097] train: loss: 0.0031734
[Epoch 43; Iter   246/ 1097] train: loss: 0.1006950
[Epoch 43; Iter   276/ 1097] train: loss: 0.0064592
[Epoch 43; Iter   306/ 1097] train: loss: 0.0004126
[Epoch 43; Iter   336/ 1097] train: loss: 0.0011514
[Epoch 43; Iter   366/ 1097] train: loss: 0.0055309
[Epoch 43; Iter   396/ 1097] train: loss: 0.1695750
[Epoch 43; Iter   426/ 1097] train: loss: 0.0014843
[Epoch 43; Iter   456/ 1097] train: loss: 0.0071910
[Epoch 43; Iter   486/ 1097] train: loss: 0.0073963
[Epoch 43; Iter   516/ 1097] train: loss: 0.0031248
[Epoch 43; Iter   546/ 1097] train: loss: 0.0094216
[Epoch 43; Iter   576/ 1097] train: loss: 0.0158263
[Epoch 43; Iter   606/ 1097] train: loss: 0.0949781
[Epoch 43; Iter   636/ 1097] train: loss: 0.0037772
[Epoch 43; Iter   666/ 1097] train: loss: 0.0039785
[Epoch 43; Iter   696/ 1097] train: loss: 0.0057684
[Epoch 43; Iter   726/ 1097] train: loss: 0.0020502
[Epoch 43; Iter   756/ 1097] train: loss: 0.0181512
[Epoch 43; Iter   786/ 1097] train: loss: 0.0004638
[Epoch 43; Iter   816/ 1097] train: loss: 0.0517222
[Epoch 43; Iter   846/ 1097] train: loss: 0.0239373
[Epoch 43; Iter   876/ 1097] train: loss: 0.0014178
[Epoch 43; Iter   906/ 1097] train: loss: 0.0002941
[Epoch 43; Iter   936/ 1097] train: loss: 0.0036148
[Epoch 43; Iter   966/ 1097] train: loss: 0.0031474
[Epoch 43; Iter   996/ 1097] train: loss: 0.0261459
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0322176
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0633948
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0032483
[Epoch 43] ogbg-molhiv: 0.794404 val loss: 1.272127
[Epoch 43] ogbg-molhiv: 0.706294 test loss: 0.576882
[Epoch 44; Iter    19/ 1097] train: loss: 0.0019940
[Epoch 44; Iter    49/ 1097] train: loss: 0.0066853
[Epoch 44; Iter    79/ 1097] train: loss: 0.0046316
[Epoch 44; Iter   109/ 1097] train: loss: 0.0104298
[Epoch 44; Iter   139/ 1097] train: loss: 0.0004217
[Epoch 44; Iter   169/ 1097] train: loss: 0.0485504
[Epoch 44; Iter   199/ 1097] train: loss: 0.0037182
[Epoch 44; Iter   229/ 1097] train: loss: 0.0010881
[Epoch 44; Iter   259/ 1097] train: loss: 0.0025865
[Epoch 44; Iter   289/ 1097] train: loss: 0.0030428
[Epoch 44; Iter   319/ 1097] train: loss: 0.0279949
[Epoch 44; Iter   349/ 1097] train: loss: 0.0206155
[Epoch 44; Iter   379/ 1097] train: loss: 0.0107133
[Epoch 44; Iter   409/ 1097] train: loss: 0.0707512
[Epoch 44; Iter   439/ 1097] train: loss: 0.0002908
[Epoch 44; Iter   469/ 1097] train: loss: 0.0007404
[Epoch 44; Iter   499/ 1097] train: loss: 0.0007813
[Epoch 44; Iter   529/ 1097] train: loss: 0.0037194
[Epoch 44; Iter   559/ 1097] train: loss: 0.0037640
[Epoch 44; Iter   589/ 1097] train: loss: 0.0070217
[Epoch 44; Iter   619/ 1097] train: loss: 0.0040399
[Epoch 44; Iter   649/ 1097] train: loss: 0.0015804
[Epoch 44; Iter   679/ 1097] train: loss: 0.0018283
[Epoch 44; Iter   709/ 1097] train: loss: 0.0430586
[Epoch 44; Iter   739/ 1097] train: loss: 0.0072597
[Epoch 40; Iter   687/ 1097] train: loss: 0.0349906
[Epoch 40; Iter   717/ 1097] train: loss: 0.0019944
[Epoch 40; Iter   747/ 1097] train: loss: 0.0071883
[Epoch 40; Iter   777/ 1097] train: loss: 0.2662808
[Epoch 40; Iter   807/ 1097] train: loss: 0.0174364
[Epoch 40; Iter   837/ 1097] train: loss: 0.1109966
[Epoch 40; Iter   867/ 1097] train: loss: 0.0014439
[Epoch 40; Iter   897/ 1097] train: loss: 0.0064646
[Epoch 40; Iter   927/ 1097] train: loss: 0.0326396
[Epoch 40; Iter   957/ 1097] train: loss: 0.0074656
[Epoch 40; Iter   987/ 1097] train: loss: 0.0014087
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0017821
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0816197
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0249780
[Epoch 40] ogbg-molhiv: 0.780892 val loss: 0.297563
[Epoch 40] ogbg-molhiv: 0.711064 test loss: 0.271663
[Epoch 41; Iter    10/ 1097] train: loss: 0.0079131
[Epoch 41; Iter    40/ 1097] train: loss: 0.0054347
[Epoch 41; Iter    70/ 1097] train: loss: 0.0343556
[Epoch 41; Iter   100/ 1097] train: loss: 0.0031526
[Epoch 41; Iter   130/ 1097] train: loss: 0.0064346
[Epoch 41; Iter   160/ 1097] train: loss: 0.0073676
[Epoch 41; Iter   190/ 1097] train: loss: 0.0057842
[Epoch 41; Iter   220/ 1097] train: loss: 0.0691504
[Epoch 41; Iter   250/ 1097] train: loss: 0.0062146
[Epoch 41; Iter   280/ 1097] train: loss: 0.0080943
[Epoch 41; Iter   310/ 1097] train: loss: 0.0642655
[Epoch 41; Iter   340/ 1097] train: loss: 0.0078017
[Epoch 41; Iter   370/ 1097] train: loss: 0.0817995
[Epoch 41; Iter   400/ 1097] train: loss: 0.0055354
[Epoch 41; Iter   430/ 1097] train: loss: 0.0106994
[Epoch 41; Iter   460/ 1097] train: loss: 0.0336323
[Epoch 41; Iter   490/ 1097] train: loss: 0.2031301
[Epoch 41; Iter   520/ 1097] train: loss: 0.0149377
[Epoch 41; Iter   550/ 1097] train: loss: 0.0108943
[Epoch 41; Iter   580/ 1097] train: loss: 0.0096520
[Epoch 41; Iter   610/ 1097] train: loss: 0.0127430
[Epoch 41; Iter   640/ 1097] train: loss: 0.0017158
[Epoch 41; Iter   670/ 1097] train: loss: 0.0481968
[Epoch 41; Iter   700/ 1097] train: loss: 0.0452954
[Epoch 41; Iter   730/ 1097] train: loss: 0.0117515
[Epoch 41; Iter   760/ 1097] train: loss: 0.0560446
[Epoch 41; Iter   790/ 1097] train: loss: 0.0302496
[Epoch 41; Iter   820/ 1097] train: loss: 0.0064487
[Epoch 41; Iter   850/ 1097] train: loss: 0.0064411
[Epoch 41; Iter   880/ 1097] train: loss: 0.0123286
[Epoch 41; Iter   910/ 1097] train: loss: 0.0082235
[Epoch 41; Iter   940/ 1097] train: loss: 0.0380355
[Epoch 41; Iter   970/ 1097] train: loss: 0.0079168
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0110779
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0107994
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0047313
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1357909
[Epoch 41] ogbg-molhiv: 0.786853 val loss: 0.274178
[Epoch 41] ogbg-molhiv: 0.697930 test loss: 0.312209
[Epoch 42; Iter    23/ 1097] train: loss: 0.0006892
[Epoch 42; Iter    53/ 1097] train: loss: 0.0029074
[Epoch 42; Iter    83/ 1097] train: loss: 0.0057710
[Epoch 42; Iter   113/ 1097] train: loss: 0.0067597
[Epoch 42; Iter   143/ 1097] train: loss: 0.0519151
[Epoch 42; Iter   173/ 1097] train: loss: 0.0050644
[Epoch 42; Iter   203/ 1097] train: loss: 0.0035368
[Epoch 42; Iter   233/ 1097] train: loss: 0.0010855
[Epoch 42; Iter   263/ 1097] train: loss: 0.0099140
[Epoch 42; Iter   293/ 1097] train: loss: 0.0189910
[Epoch 42; Iter   323/ 1097] train: loss: 0.0259538
[Epoch 42; Iter   353/ 1097] train: loss: 0.0095821
[Epoch 42; Iter   383/ 1097] train: loss: 0.0029278
[Epoch 42; Iter   413/ 1097] train: loss: 0.0029737
[Epoch 42; Iter   443/ 1097] train: loss: 0.0023330
[Epoch 42; Iter   473/ 1097] train: loss: 0.0632481
[Epoch 42; Iter   503/ 1097] train: loss: 0.0749455
[Epoch 42; Iter   533/ 1097] train: loss: 0.0046137
[Epoch 42; Iter   563/ 1097] train: loss: 0.0087420
[Epoch 42; Iter   593/ 1097] train: loss: 0.0295402
[Epoch 42; Iter   623/ 1097] train: loss: 0.0027871
[Epoch 42; Iter   653/ 1097] train: loss: 0.0236512
[Epoch 42; Iter   683/ 1097] train: loss: 0.0010810
[Epoch 42; Iter   713/ 1097] train: loss: 0.0007335
[Epoch 42; Iter   743/ 1097] train: loss: 0.0130866
[Epoch 42; Iter   773/ 1097] train: loss: 0.0422350
[Epoch 42; Iter   803/ 1097] train: loss: 0.0083518
[Epoch 42; Iter   833/ 1097] train: loss: 0.0085854
[Epoch 42; Iter   863/ 1097] train: loss: 0.0011902
[Epoch 42; Iter   893/ 1097] train: loss: 0.0015712
[Epoch 42; Iter   923/ 1097] train: loss: 0.0025829
[Epoch 42; Iter   953/ 1097] train: loss: 0.0160201
[Epoch 42; Iter   983/ 1097] train: loss: 0.0222544
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0025836
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0169472
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0040865
[Epoch 42] ogbg-molhiv: 0.774085 val loss: 0.258169
[Epoch 42] ogbg-molhiv: 0.668588 test loss: 0.268747
[Epoch 43; Iter     6/ 1097] train: loss: 0.1250195
[Epoch 43; Iter    36/ 1097] train: loss: 0.0079510
[Epoch 43; Iter    66/ 1097] train: loss: 0.0068545
[Epoch 43; Iter    96/ 1097] train: loss: 0.0015137
[Epoch 43; Iter   126/ 1097] train: loss: 0.0030785
[Epoch 43; Iter   156/ 1097] train: loss: 0.0291126
[Epoch 43; Iter   186/ 1097] train: loss: 0.0292561
[Epoch 43; Iter   216/ 1097] train: loss: 0.0398339
[Epoch 43; Iter   246/ 1097] train: loss: 0.0028178
[Epoch 43; Iter   276/ 1097] train: loss: 0.0158128
[Epoch 43; Iter   306/ 1097] train: loss: 0.0012831
[Epoch 43; Iter   336/ 1097] train: loss: 0.0482506
[Epoch 43; Iter   366/ 1097] train: loss: 0.0029694
[Epoch 43; Iter   396/ 1097] train: loss: 0.0033107
[Epoch 43; Iter   426/ 1097] train: loss: 0.0043019
[Epoch 43; Iter   456/ 1097] train: loss: 0.0023982
[Epoch 43; Iter   486/ 1097] train: loss: 0.0091717
[Epoch 43; Iter   516/ 1097] train: loss: 0.0073563
[Epoch 43; Iter   546/ 1097] train: loss: 0.0002081
[Epoch 43; Iter   576/ 1097] train: loss: 0.0111582
[Epoch 43; Iter   606/ 1097] train: loss: 0.0007772
[Epoch 43; Iter   636/ 1097] train: loss: 0.0010773
[Epoch 43; Iter   666/ 1097] train: loss: 0.0043235
[Epoch 43; Iter   696/ 1097] train: loss: 0.0055084
[Epoch 43; Iter   726/ 1097] train: loss: 0.0026861
[Epoch 43; Iter   756/ 1097] train: loss: 0.0007558
[Epoch 43; Iter   786/ 1097] train: loss: 0.0165019
[Epoch 43; Iter   816/ 1097] train: loss: 0.0016676
[Epoch 43; Iter   846/ 1097] train: loss: 0.0174623
[Epoch 43; Iter   876/ 1097] train: loss: 0.0259581
[Epoch 43; Iter   906/ 1097] train: loss: 0.0008197
[Epoch 43; Iter   936/ 1097] train: loss: 0.0118855
[Epoch 43; Iter   966/ 1097] train: loss: 0.0007088
[Epoch 43; Iter   996/ 1097] train: loss: 0.0026587
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0026284
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0014095
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0024910
[Epoch 43] ogbg-molhiv: 0.814726 val loss: 0.686838
[Epoch 43] ogbg-molhiv: 0.706982 test loss: 0.561513
[Epoch 44; Iter    19/ 1097] train: loss: 0.0085688
[Epoch 44; Iter    49/ 1097] train: loss: 0.0014601
[Epoch 44; Iter    79/ 1097] train: loss: 0.0024392
[Epoch 44; Iter   109/ 1097] train: loss: 0.0034684
[Epoch 44; Iter   139/ 1097] train: loss: 0.0059821
[Epoch 44; Iter   169/ 1097] train: loss: 0.0203853
[Epoch 44; Iter   199/ 1097] train: loss: 0.0003061
[Epoch 44; Iter   229/ 1097] train: loss: 0.0160613
[Epoch 44; Iter   259/ 1097] train: loss: 0.0021900
[Epoch 44; Iter   289/ 1097] train: loss: 0.0031921
[Epoch 44; Iter   319/ 1097] train: loss: 0.0057647
[Epoch 44; Iter   349/ 1097] train: loss: 0.0094388
[Epoch 44; Iter   379/ 1097] train: loss: 0.0061168
[Epoch 44; Iter   409/ 1097] train: loss: 0.0011484
[Epoch 44; Iter   439/ 1097] train: loss: 0.0162833
[Epoch 44; Iter   469/ 1097] train: loss: 0.1101492
[Epoch 44; Iter   499/ 1097] train: loss: 0.0292471
[Epoch 44; Iter   529/ 1097] train: loss: 0.0432217
[Epoch 44; Iter   559/ 1097] train: loss: 0.0036901
[Epoch 44; Iter   589/ 1097] train: loss: 0.0183308
[Epoch 44; Iter   619/ 1097] train: loss: 0.0089593
[Epoch 44; Iter   649/ 1097] train: loss: 0.0057567
[Epoch 44; Iter   679/ 1097] train: loss: 0.0063245
[Epoch 44; Iter   709/ 1097] train: loss: 0.0043739
[Epoch 44; Iter   739/ 1097] train: loss: 0.0007699
[Epoch 40; Iter   717/ 1097] train: loss: 0.0735003
[Epoch 40; Iter   747/ 1097] train: loss: 0.0079493
[Epoch 40; Iter   777/ 1097] train: loss: 0.0276408
[Epoch 40; Iter   807/ 1097] train: loss: 0.2490501
[Epoch 40; Iter   837/ 1097] train: loss: 0.0290522
[Epoch 40; Iter   867/ 1097] train: loss: 0.0024182
[Epoch 40; Iter   897/ 1097] train: loss: 0.0014170
[Epoch 40; Iter   927/ 1097] train: loss: 0.0010167
[Epoch 40; Iter   957/ 1097] train: loss: 0.0633565
[Epoch 40; Iter   987/ 1097] train: loss: 0.0485802
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0055327
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0067404
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1971546
[Epoch 40] ogbg-molhiv: 0.680666 val loss: 0.562840
[Epoch 40] ogbg-molhiv: 0.673876 test loss: 0.669241
[Epoch 41; Iter    10/ 1097] train: loss: 0.0074503
[Epoch 41; Iter    40/ 1097] train: loss: 0.0101638
[Epoch 41; Iter    70/ 1097] train: loss: 0.0006111
[Epoch 41; Iter   100/ 1097] train: loss: 0.0167315
[Epoch 41; Iter   130/ 1097] train: loss: 0.0011950
[Epoch 41; Iter   160/ 1097] train: loss: 0.2139874
[Epoch 41; Iter   190/ 1097] train: loss: 0.0288866
[Epoch 41; Iter   220/ 1097] train: loss: 0.0071810
[Epoch 41; Iter   250/ 1097] train: loss: 0.0361211
[Epoch 41; Iter   280/ 1097] train: loss: 0.0220616
[Epoch 41; Iter   310/ 1097] train: loss: 0.0072238
[Epoch 41; Iter   340/ 1097] train: loss: 0.0303403
[Epoch 41; Iter   370/ 1097] train: loss: 0.0027082
[Epoch 41; Iter   400/ 1097] train: loss: 0.0078837
[Epoch 41; Iter   430/ 1097] train: loss: 0.0032032
[Epoch 41; Iter   460/ 1097] train: loss: 0.0654084
[Epoch 41; Iter   490/ 1097] train: loss: 0.0029776
[Epoch 41; Iter   520/ 1097] train: loss: 0.0078223
[Epoch 41; Iter   550/ 1097] train: loss: 0.0011177
[Epoch 41; Iter   580/ 1097] train: loss: 0.0091215
[Epoch 41; Iter   610/ 1097] train: loss: 0.0011752
[Epoch 41; Iter   640/ 1097] train: loss: 0.0077378
[Epoch 41; Iter   670/ 1097] train: loss: 0.0048459
[Epoch 41; Iter   700/ 1097] train: loss: 0.0113461
[Epoch 41; Iter   730/ 1097] train: loss: 0.0048531
[Epoch 41; Iter   760/ 1097] train: loss: 0.0012418
[Epoch 41; Iter   790/ 1097] train: loss: 0.0029080
[Epoch 41; Iter   820/ 1097] train: loss: 0.0101255
[Epoch 41; Iter   850/ 1097] train: loss: 0.2046437
[Epoch 41; Iter   880/ 1097] train: loss: 0.0031999
[Epoch 41; Iter   910/ 1097] train: loss: 0.0056837
[Epoch 41; Iter   940/ 1097] train: loss: 0.0005811
[Epoch 41; Iter   970/ 1097] train: loss: 0.0036278
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0073073
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0249701
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0011924
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0032851
[Epoch 41] ogbg-molhiv: 0.700198 val loss: 1.159110
[Epoch 41] ogbg-molhiv: 0.702762 test loss: 0.752140
[Epoch 42; Iter    23/ 1097] train: loss: 0.0017852
[Epoch 42; Iter    53/ 1097] train: loss: 0.0034106
[Epoch 42; Iter    83/ 1097] train: loss: 0.0098486
[Epoch 42; Iter   113/ 1097] train: loss: 0.0196618
[Epoch 42; Iter   143/ 1097] train: loss: 0.0318257
[Epoch 42; Iter   173/ 1097] train: loss: 0.0054611
[Epoch 42; Iter   203/ 1097] train: loss: 0.0012636
[Epoch 42; Iter   233/ 1097] train: loss: 0.0006017
[Epoch 42; Iter   263/ 1097] train: loss: 0.0024972
[Epoch 42; Iter   293/ 1097] train: loss: 0.0016906
[Epoch 42; Iter   323/ 1097] train: loss: 0.0070863
[Epoch 42; Iter   353/ 1097] train: loss: 0.0052055
[Epoch 42; Iter   383/ 1097] train: loss: 0.0083024
[Epoch 42; Iter   413/ 1097] train: loss: 0.1496821
[Epoch 42; Iter   443/ 1097] train: loss: 0.0016445
[Epoch 42; Iter   473/ 1097] train: loss: 0.0029975
[Epoch 42; Iter   503/ 1097] train: loss: 0.0348517
[Epoch 42; Iter   533/ 1097] train: loss: 0.0029220
[Epoch 42; Iter   563/ 1097] train: loss: 0.0025646
[Epoch 42; Iter   593/ 1097] train: loss: 0.0014622
[Epoch 42; Iter   623/ 1097] train: loss: 0.0143643
[Epoch 42; Iter   653/ 1097] train: loss: 0.0015733
[Epoch 42; Iter   683/ 1097] train: loss: 0.0041689
[Epoch 42; Iter   713/ 1097] train: loss: 0.0015281
[Epoch 42; Iter   743/ 1097] train: loss: 0.0013153
[Epoch 42; Iter   773/ 1097] train: loss: 0.0108222
[Epoch 42; Iter   803/ 1097] train: loss: 0.0062792
[Epoch 42; Iter   833/ 1097] train: loss: 0.0006634
[Epoch 42; Iter   863/ 1097] train: loss: 0.0014087
[Epoch 42; Iter   893/ 1097] train: loss: 0.0170790
[Epoch 42; Iter   923/ 1097] train: loss: 0.0031310
[Epoch 42; Iter   953/ 1097] train: loss: 0.0022100
[Epoch 42; Iter   983/ 1097] train: loss: 0.0010171
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0260843
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0136117
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0089217
[Epoch 42] ogbg-molhiv: 0.646930 val loss: 2.488616
[Epoch 42] ogbg-molhiv: 0.637480 test loss: 0.957084
[Epoch 43; Iter     6/ 1097] train: loss: 0.0186174
[Epoch 43; Iter    36/ 1097] train: loss: 0.0142351
[Epoch 43; Iter    66/ 1097] train: loss: 0.1052385
[Epoch 43; Iter    96/ 1097] train: loss: 0.0331871
[Epoch 43; Iter   126/ 1097] train: loss: 0.0016664
[Epoch 43; Iter   156/ 1097] train: loss: 0.0006712
[Epoch 43; Iter   186/ 1097] train: loss: 0.0035284
[Epoch 43; Iter   216/ 1097] train: loss: 0.0025577
[Epoch 43; Iter   246/ 1097] train: loss: 0.0051829
[Epoch 43; Iter   276/ 1097] train: loss: 0.0012963
[Epoch 43; Iter   306/ 1097] train: loss: 0.0536586
[Epoch 43; Iter   336/ 1097] train: loss: 0.0203196
[Epoch 43; Iter   366/ 1097] train: loss: 0.0020903
[Epoch 43; Iter   396/ 1097] train: loss: 0.0018277
[Epoch 43; Iter   426/ 1097] train: loss: 0.0239582
[Epoch 43; Iter   456/ 1097] train: loss: 0.0011335
[Epoch 43; Iter   486/ 1097] train: loss: 0.0006858
[Epoch 43; Iter   516/ 1097] train: loss: 0.0165522
[Epoch 43; Iter   546/ 1097] train: loss: 0.0474324
[Epoch 43; Iter   576/ 1097] train: loss: 0.0105385
[Epoch 43; Iter   606/ 1097] train: loss: 0.0214207
[Epoch 43; Iter   636/ 1097] train: loss: 0.0025072
[Epoch 43; Iter   666/ 1097] train: loss: 0.0009031
[Epoch 43; Iter   696/ 1097] train: loss: 0.0102739
[Epoch 43; Iter   726/ 1097] train: loss: 0.0069755
[Epoch 43; Iter   756/ 1097] train: loss: 0.0056601
[Epoch 43; Iter   786/ 1097] train: loss: 0.0731405
[Epoch 43; Iter   816/ 1097] train: loss: 0.0016096
[Epoch 43; Iter   846/ 1097] train: loss: 0.0018417
[Epoch 43; Iter   876/ 1097] train: loss: 0.0860875
[Epoch 43; Iter   906/ 1097] train: loss: 0.1927717
[Epoch 43; Iter   936/ 1097] train: loss: 0.0216612
[Epoch 43; Iter   966/ 1097] train: loss: 0.0070520
[Epoch 43; Iter   996/ 1097] train: loss: 0.0042015
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0169215
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0002166
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0564503
[Epoch 43] ogbg-molhiv: 0.675807 val loss: 2.123760
[Epoch 43] ogbg-molhiv: 0.625062 test loss: 0.778549
[Epoch 44; Iter    19/ 1097] train: loss: 0.0064819
[Epoch 44; Iter    49/ 1097] train: loss: 0.0190082
[Epoch 44; Iter    79/ 1097] train: loss: 0.0004409
[Epoch 44; Iter   109/ 1097] train: loss: 0.0381479
[Epoch 44; Iter   139/ 1097] train: loss: 0.0047803
[Epoch 44; Iter   169/ 1097] train: loss: 0.0034093
[Epoch 44; Iter   199/ 1097] train: loss: 0.1669324
[Epoch 44; Iter   229/ 1097] train: loss: 0.0109626
[Epoch 44; Iter   259/ 1097] train: loss: 0.0060700
[Epoch 44; Iter   289/ 1097] train: loss: 0.0006059
[Epoch 44; Iter   319/ 1097] train: loss: 0.0116980
[Epoch 44; Iter   349/ 1097] train: loss: 0.0125990
[Epoch 44; Iter   379/ 1097] train: loss: 0.0003074
[Epoch 44; Iter   409/ 1097] train: loss: 0.0027818
[Epoch 44; Iter   439/ 1097] train: loss: 0.0047758
[Epoch 44; Iter   469/ 1097] train: loss: 0.0033883
[Epoch 44; Iter   499/ 1097] train: loss: 0.0010565
[Epoch 44; Iter   529/ 1097] train: loss: 0.0004309
[Epoch 44; Iter   559/ 1097] train: loss: 0.0006514
[Epoch 44; Iter   589/ 1097] train: loss: 0.0020967
[Epoch 44; Iter   619/ 1097] train: loss: 0.0048438
[Epoch 44; Iter   649/ 1097] train: loss: 0.0002814
[Epoch 44; Iter   679/ 1097] train: loss: 0.2185221
[Epoch 44; Iter   709/ 1097] train: loss: 0.0120948
[Epoch 44; Iter   739/ 1097] train: loss: 0.0009793
[Epoch 44; Iter   769/ 1097] train: loss: 0.0181619
[Epoch 40; Iter   717/ 1097] train: loss: 0.0053612
[Epoch 40; Iter   747/ 1097] train: loss: 0.0065450
[Epoch 40; Iter   777/ 1097] train: loss: 0.2031536
[Epoch 40; Iter   807/ 1097] train: loss: 0.0051866
[Epoch 40; Iter   837/ 1097] train: loss: 0.0005250
[Epoch 40; Iter   867/ 1097] train: loss: 0.0034203
[Epoch 40; Iter   897/ 1097] train: loss: 0.0070016
[Epoch 40; Iter   927/ 1097] train: loss: 0.0096110
[Epoch 40; Iter   957/ 1097] train: loss: 0.0983998
[Epoch 40; Iter   987/ 1097] train: loss: 0.0335148
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0093723
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0077104
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0088578
[Epoch 40] ogbg-molhiv: 0.749219 val loss: 0.442071
[Epoch 40] ogbg-molhiv: 0.696002 test loss: 0.260068
[Epoch 41; Iter    10/ 1097] train: loss: 0.0514822
[Epoch 41; Iter    40/ 1097] train: loss: 0.0181796
[Epoch 41; Iter    70/ 1097] train: loss: 0.0597381
[Epoch 41; Iter   100/ 1097] train: loss: 0.0014447
[Epoch 41; Iter   130/ 1097] train: loss: 0.0031065
[Epoch 41; Iter   160/ 1097] train: loss: 0.0059100
[Epoch 41; Iter   190/ 1097] train: loss: 0.0397898
[Epoch 41; Iter   220/ 1097] train: loss: 0.0162997
[Epoch 41; Iter   250/ 1097] train: loss: 0.0030930
[Epoch 41; Iter   280/ 1097] train: loss: 0.0043398
[Epoch 41; Iter   310/ 1097] train: loss: 0.0292905
[Epoch 41; Iter   340/ 1097] train: loss: 0.0050721
[Epoch 41; Iter   370/ 1097] train: loss: 0.0149273
[Epoch 41; Iter   400/ 1097] train: loss: 0.0023688
[Epoch 41; Iter   430/ 1097] train: loss: 0.0097177
[Epoch 41; Iter   460/ 1097] train: loss: 0.0644737
[Epoch 41; Iter   490/ 1097] train: loss: 0.0933102
[Epoch 41; Iter   520/ 1097] train: loss: 0.0010440
[Epoch 41; Iter   550/ 1097] train: loss: 0.0894894
[Epoch 41; Iter   580/ 1097] train: loss: 0.0015976
[Epoch 41; Iter   610/ 1097] train: loss: 0.0006487
[Epoch 41; Iter   640/ 1097] train: loss: 0.0035053
[Epoch 41; Iter   670/ 1097] train: loss: 0.0032509
[Epoch 41; Iter   700/ 1097] train: loss: 0.0013833
[Epoch 41; Iter   730/ 1097] train: loss: 0.0028536
[Epoch 41; Iter   760/ 1097] train: loss: 0.0076390
[Epoch 41; Iter   790/ 1097] train: loss: 0.0084858
[Epoch 41; Iter   820/ 1097] train: loss: 0.0002983
[Epoch 41; Iter   850/ 1097] train: loss: 0.0202896
[Epoch 41; Iter   880/ 1097] train: loss: 0.0129655
[Epoch 41; Iter   910/ 1097] train: loss: 0.0011942
[Epoch 41; Iter   940/ 1097] train: loss: 0.0043100
[Epoch 41; Iter   970/ 1097] train: loss: 0.0150322
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0097668
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0131013
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0266261
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0516467
[Epoch 41] ogbg-molhiv: 0.745058 val loss: 0.457687
[Epoch 41] ogbg-molhiv: 0.695674 test loss: 0.255738
[Epoch 42; Iter    23/ 1097] train: loss: 0.0046911
[Epoch 42; Iter    53/ 1097] train: loss: 0.0874149
[Epoch 42; Iter    83/ 1097] train: loss: 0.0425147
[Epoch 42; Iter   113/ 1097] train: loss: 0.0537986
[Epoch 42; Iter   143/ 1097] train: loss: 0.0567501
[Epoch 42; Iter   173/ 1097] train: loss: 0.0007017
[Epoch 42; Iter   203/ 1097] train: loss: 0.0006190
[Epoch 42; Iter   233/ 1097] train: loss: 0.0013510
[Epoch 42; Iter   263/ 1097] train: loss: 0.0223125
[Epoch 42; Iter   293/ 1097] train: loss: 0.0412451
[Epoch 42; Iter   323/ 1097] train: loss: 0.0791773
[Epoch 42; Iter   353/ 1097] train: loss: 0.0021183
[Epoch 42; Iter   383/ 1097] train: loss: 0.0163030
[Epoch 42; Iter   413/ 1097] train: loss: 0.0036426
[Epoch 42; Iter   443/ 1097] train: loss: 0.0138512
[Epoch 42; Iter   473/ 1097] train: loss: 0.0131307
[Epoch 42; Iter   503/ 1097] train: loss: 0.0421352
[Epoch 42; Iter   533/ 1097] train: loss: 0.0104845
[Epoch 42; Iter   563/ 1097] train: loss: 0.0032049
[Epoch 42; Iter   593/ 1097] train: loss: 0.0015560
[Epoch 42; Iter   623/ 1097] train: loss: 0.0012181
[Epoch 42; Iter   653/ 1097] train: loss: 0.0125176
[Epoch 42; Iter   683/ 1097] train: loss: 0.0001878
[Epoch 42; Iter   713/ 1097] train: loss: 0.0019471
[Epoch 42; Iter   743/ 1097] train: loss: 0.1042717
[Epoch 42; Iter   773/ 1097] train: loss: 0.1016460
[Epoch 42; Iter   803/ 1097] train: loss: 0.0395046
[Epoch 42; Iter   833/ 1097] train: loss: 0.0032565
[Epoch 42; Iter   863/ 1097] train: loss: 0.0003417
[Epoch 42; Iter   893/ 1097] train: loss: 0.0018016
[Epoch 42; Iter   923/ 1097] train: loss: 0.0056723
[Epoch 42; Iter   953/ 1097] train: loss: 0.0006431
[Epoch 42; Iter   983/ 1097] train: loss: 0.0043404
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0007346
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0113190
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0022284
[Epoch 42] ogbg-molhiv: 0.769553 val loss: 0.460626
[Epoch 42] ogbg-molhiv: 0.703359 test loss: 0.286659
[Epoch 43; Iter     6/ 1097] train: loss: 0.0063404
[Epoch 43; Iter    36/ 1097] train: loss: 0.0059568
[Epoch 43; Iter    66/ 1097] train: loss: 0.0017518
[Epoch 43; Iter    96/ 1097] train: loss: 0.0018373
[Epoch 43; Iter   126/ 1097] train: loss: 0.0010482
[Epoch 43; Iter   156/ 1097] train: loss: 0.0018948
[Epoch 43; Iter   186/ 1097] train: loss: 0.0132020
[Epoch 43; Iter   216/ 1097] train: loss: 0.0227402
[Epoch 43; Iter   246/ 1097] train: loss: 0.0070642
[Epoch 43; Iter   276/ 1097] train: loss: 0.0047540
[Epoch 43; Iter   306/ 1097] train: loss: 0.0024618
[Epoch 43; Iter   336/ 1097] train: loss: 0.0348104
[Epoch 43; Iter   366/ 1097] train: loss: 0.0019527
[Epoch 43; Iter   396/ 1097] train: loss: 0.0003689
[Epoch 43; Iter   426/ 1097] train: loss: 0.0005923
[Epoch 43; Iter   456/ 1097] train: loss: 0.0109503
[Epoch 43; Iter   486/ 1097] train: loss: 0.0771957
[Epoch 43; Iter   516/ 1097] train: loss: 0.0154456
[Epoch 43; Iter   546/ 1097] train: loss: 0.0008611
[Epoch 43; Iter   576/ 1097] train: loss: 0.0076804
[Epoch 43; Iter   606/ 1097] train: loss: 0.0142756
[Epoch 43; Iter   636/ 1097] train: loss: 0.0041260
[Epoch 43; Iter   666/ 1097] train: loss: 0.0187323
[Epoch 43; Iter   696/ 1097] train: loss: 0.0010340
[Epoch 43; Iter   726/ 1097] train: loss: 0.0262761
[Epoch 43; Iter   756/ 1097] train: loss: 0.0013024
[Epoch 43; Iter   786/ 1097] train: loss: 0.0050247
[Epoch 43; Iter   816/ 1097] train: loss: 0.0012835
[Epoch 43; Iter   846/ 1097] train: loss: 0.0095446
[Epoch 43; Iter   876/ 1097] train: loss: 0.0119732
[Epoch 43; Iter   906/ 1097] train: loss: 0.0095832
[Epoch 43; Iter   936/ 1097] train: loss: 0.0150109
[Epoch 43; Iter   966/ 1097] train: loss: 0.0008371
[Epoch 43; Iter   996/ 1097] train: loss: 0.0018796
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0005450
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0066804
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0027811
[Epoch 43] ogbg-molhiv: 0.769361 val loss: 0.181385
[Epoch 43] ogbg-molhiv: 0.741525 test loss: 0.323133
[Epoch 44; Iter    19/ 1097] train: loss: 0.0054260
[Epoch 44; Iter    49/ 1097] train: loss: 0.0386263
[Epoch 44; Iter    79/ 1097] train: loss: 0.0007569
[Epoch 44; Iter   109/ 1097] train: loss: 0.0014097
[Epoch 44; Iter   139/ 1097] train: loss: 0.0008527
[Epoch 44; Iter   169/ 1097] train: loss: 0.0177257
[Epoch 44; Iter   199/ 1097] train: loss: 0.0216613
[Epoch 44; Iter   229/ 1097] train: loss: 0.0017135
[Epoch 44; Iter   259/ 1097] train: loss: 0.0021677
[Epoch 44; Iter   289/ 1097] train: loss: 0.0003939
[Epoch 44; Iter   319/ 1097] train: loss: 0.0007333
[Epoch 44; Iter   349/ 1097] train: loss: 0.0974664
[Epoch 44; Iter   379/ 1097] train: loss: 0.0144150
[Epoch 44; Iter   409/ 1097] train: loss: 0.0015925
[Epoch 44; Iter   439/ 1097] train: loss: 0.0006731
[Epoch 44; Iter   469/ 1097] train: loss: 0.0162509
[Epoch 44; Iter   499/ 1097] train: loss: 0.0091590
[Epoch 44; Iter   529/ 1097] train: loss: 0.0104339
[Epoch 44; Iter   559/ 1097] train: loss: 0.0065775
[Epoch 44; Iter   589/ 1097] train: loss: 0.0096592
[Epoch 44; Iter   619/ 1097] train: loss: 0.0023999
[Epoch 44; Iter   649/ 1097] train: loss: 0.0006099
[Epoch 44; Iter   679/ 1097] train: loss: 0.0751088
[Epoch 44; Iter   709/ 1097] train: loss: 0.0662812
[Epoch 44; Iter   739/ 1097] train: loss: 0.0007202
[Epoch 44; Iter   769/ 1097] train: loss: 0.0147160
[Epoch 40; Iter   717/ 1097] train: loss: 0.0543001
[Epoch 40; Iter   747/ 1097] train: loss: 0.1517185
[Epoch 40; Iter   777/ 1097] train: loss: 0.0023604
[Epoch 40; Iter   807/ 1097] train: loss: 0.0454012
[Epoch 40; Iter   837/ 1097] train: loss: 0.0445384
[Epoch 40; Iter   867/ 1097] train: loss: 0.0037424
[Epoch 40; Iter   897/ 1097] train: loss: 0.0035791
[Epoch 40; Iter   927/ 1097] train: loss: 0.0674517
[Epoch 40; Iter   957/ 1097] train: loss: 0.0076788
[Epoch 40; Iter   987/ 1097] train: loss: 0.0087177
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0116751
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0021123
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0020102
[Epoch 40] ogbg-molhiv: 0.725303 val loss: 0.153461
[Epoch 40] ogbg-molhiv: 0.745517 test loss: 0.223645
[Epoch 41; Iter    10/ 1097] train: loss: 0.0012392
[Epoch 41; Iter    40/ 1097] train: loss: 0.0008974
[Epoch 41; Iter    70/ 1097] train: loss: 0.0060238
[Epoch 41; Iter   100/ 1097] train: loss: 0.0012506
[Epoch 41; Iter   130/ 1097] train: loss: 0.0082922
[Epoch 41; Iter   160/ 1097] train: loss: 0.0008145
[Epoch 41; Iter   190/ 1097] train: loss: 0.0985460
[Epoch 41; Iter   220/ 1097] train: loss: 0.0006263
[Epoch 41; Iter   250/ 1097] train: loss: 0.0050082
[Epoch 41; Iter   280/ 1097] train: loss: 0.0021638
[Epoch 41; Iter   310/ 1097] train: loss: 0.0733988
[Epoch 41; Iter   340/ 1097] train: loss: 0.0014966
[Epoch 41; Iter   370/ 1097] train: loss: 0.0043819
[Epoch 41; Iter   400/ 1097] train: loss: 0.0488448
[Epoch 41; Iter   430/ 1097] train: loss: 0.0011696
[Epoch 41; Iter   460/ 1097] train: loss: 0.0216341
[Epoch 41; Iter   490/ 1097] train: loss: 0.0543192
[Epoch 41; Iter   520/ 1097] train: loss: 0.0051540
[Epoch 41; Iter   550/ 1097] train: loss: 0.0209580
[Epoch 41; Iter   580/ 1097] train: loss: 0.0038493
[Epoch 41; Iter   610/ 1097] train: loss: 0.0043000
[Epoch 41; Iter   640/ 1097] train: loss: 0.0063317
[Epoch 41; Iter   670/ 1097] train: loss: 0.0188828
[Epoch 41; Iter   700/ 1097] train: loss: 0.0011804
[Epoch 41; Iter   730/ 1097] train: loss: 0.0038400
[Epoch 41; Iter   760/ 1097] train: loss: 0.1442193
[Epoch 41; Iter   790/ 1097] train: loss: 0.0048258
[Epoch 41; Iter   820/ 1097] train: loss: 0.0148237
[Epoch 41; Iter   850/ 1097] train: loss: 0.0162570
[Epoch 41; Iter   880/ 1097] train: loss: 0.0009036
[Epoch 41; Iter   910/ 1097] train: loss: 0.0017730
[Epoch 41; Iter   940/ 1097] train: loss: 0.0111737
[Epoch 41; Iter   970/ 1097] train: loss: 0.0131846
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0071601
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0009070
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0341512
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0138248
[Epoch 41] ogbg-molhiv: 0.752094 val loss: 0.164450
[Epoch 41] ogbg-molhiv: 0.759377 test loss: 0.234910
[Epoch 42; Iter    23/ 1097] train: loss: 0.0010523
[Epoch 42; Iter    53/ 1097] train: loss: 0.0737718
[Epoch 42; Iter    83/ 1097] train: loss: 0.0017457
[Epoch 42; Iter   113/ 1097] train: loss: 0.0034217
[Epoch 42; Iter   143/ 1097] train: loss: 0.0009762
[Epoch 42; Iter   173/ 1097] train: loss: 0.0098067
[Epoch 42; Iter   203/ 1097] train: loss: 0.0336452
[Epoch 42; Iter   233/ 1097] train: loss: 0.0195836
[Epoch 42; Iter   263/ 1097] train: loss: 0.0080332
[Epoch 42; Iter   293/ 1097] train: loss: 0.0638898
[Epoch 42; Iter   323/ 1097] train: loss: 0.0012966
[Epoch 42; Iter   353/ 1097] train: loss: 0.0014482
[Epoch 42; Iter   383/ 1097] train: loss: 0.0020049
[Epoch 42; Iter   413/ 1097] train: loss: 0.0046480
[Epoch 42; Iter   443/ 1097] train: loss: 0.0394343
[Epoch 42; Iter   473/ 1097] train: loss: 0.0029137
[Epoch 42; Iter   503/ 1097] train: loss: 0.0069359
[Epoch 42; Iter   533/ 1097] train: loss: 0.0061654
[Epoch 42; Iter   563/ 1097] train: loss: 0.0021989
[Epoch 42; Iter   593/ 1097] train: loss: 0.0186437
[Epoch 42; Iter   623/ 1097] train: loss: 0.0080110
[Epoch 42; Iter   653/ 1097] train: loss: 0.0999200
[Epoch 42; Iter   683/ 1097] train: loss: 0.0186224
[Epoch 42; Iter   713/ 1097] train: loss: 0.0005502
[Epoch 42; Iter   743/ 1097] train: loss: 0.0060666
[Epoch 42; Iter   773/ 1097] train: loss: 0.1755988
[Epoch 42; Iter   803/ 1097] train: loss: 0.0170329
[Epoch 42; Iter   833/ 1097] train: loss: 0.0005133
[Epoch 42; Iter   863/ 1097] train: loss: 0.0005524
[Epoch 42; Iter   893/ 1097] train: loss: 0.0019163
[Epoch 42; Iter   923/ 1097] train: loss: 0.0016231
[Epoch 42; Iter   953/ 1097] train: loss: 0.0189379
[Epoch 42; Iter   983/ 1097] train: loss: 0.0015779
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0545907
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0091870
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0037073
[Epoch 42] ogbg-molhiv: 0.712436 val loss: 0.180539
[Epoch 42] ogbg-molhiv: 0.727198 test loss: 0.266926
[Epoch 43; Iter     6/ 1097] train: loss: 0.0007008
[Epoch 43; Iter    36/ 1097] train: loss: 0.0104079
[Epoch 43; Iter    66/ 1097] train: loss: 0.0070608
[Epoch 43; Iter    96/ 1097] train: loss: 0.0275857
[Epoch 43; Iter   126/ 1097] train: loss: 0.0235998
[Epoch 43; Iter   156/ 1097] train: loss: 0.0084651
[Epoch 43; Iter   186/ 1097] train: loss: 0.0048823
[Epoch 43; Iter   216/ 1097] train: loss: 0.0005589
[Epoch 43; Iter   246/ 1097] train: loss: 0.0060089
[Epoch 43; Iter   276/ 1097] train: loss: 0.0016526
[Epoch 43; Iter   306/ 1097] train: loss: 0.0021677
[Epoch 43; Iter   336/ 1097] train: loss: 0.0019581
[Epoch 43; Iter   366/ 1097] train: loss: 0.0059824
[Epoch 43; Iter   396/ 1097] train: loss: 0.1303540
[Epoch 43; Iter   426/ 1097] train: loss: 0.0022048
[Epoch 43; Iter   456/ 1097] train: loss: 0.0125303
[Epoch 43; Iter   486/ 1097] train: loss: 0.0008494
[Epoch 43; Iter   516/ 1097] train: loss: 0.0030185
[Epoch 43; Iter   546/ 1097] train: loss: 0.0049673
[Epoch 43; Iter   576/ 1097] train: loss: 0.0481883
[Epoch 43; Iter   606/ 1097] train: loss: 0.0016438
[Epoch 43; Iter   636/ 1097] train: loss: 0.0488316
[Epoch 43; Iter   666/ 1097] train: loss: 0.0061837
[Epoch 43; Iter   696/ 1097] train: loss: 0.0254663
[Epoch 43; Iter   726/ 1097] train: loss: 0.0028216
[Epoch 43; Iter   756/ 1097] train: loss: 0.0709896
[Epoch 43; Iter   786/ 1097] train: loss: 0.0024812
[Epoch 43; Iter   816/ 1097] train: loss: 0.0024428
[Epoch 43; Iter   846/ 1097] train: loss: 0.0005604
[Epoch 43; Iter   876/ 1097] train: loss: 0.0019800
[Epoch 43; Iter   906/ 1097] train: loss: 0.0072535
[Epoch 43; Iter   936/ 1097] train: loss: 0.0069959
[Epoch 43; Iter   966/ 1097] train: loss: 0.0006458
[Epoch 43; Iter   996/ 1097] train: loss: 0.0018950
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0008156
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0014710
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0042492
[Epoch 43] ogbg-molhiv: 0.724715 val loss: 0.183040
[Epoch 43] ogbg-molhiv: 0.735190 test loss: 0.269374
[Epoch 44; Iter    19/ 1097] train: loss: 0.0036504
[Epoch 44; Iter    49/ 1097] train: loss: 0.0068226
[Epoch 44; Iter    79/ 1097] train: loss: 0.0135412
[Epoch 44; Iter   109/ 1097] train: loss: 0.0038109
[Epoch 44; Iter   139/ 1097] train: loss: 0.0011867
[Epoch 44; Iter   169/ 1097] train: loss: 0.0112171
[Epoch 44; Iter   199/ 1097] train: loss: 0.0043939
[Epoch 44; Iter   229/ 1097] train: loss: 0.0008435
[Epoch 44; Iter   259/ 1097] train: loss: 0.0011049
[Epoch 44; Iter   289/ 1097] train: loss: 0.0021044
[Epoch 44; Iter   319/ 1097] train: loss: 0.0023565
[Epoch 44; Iter   349/ 1097] train: loss: 0.0004092
[Epoch 44; Iter   379/ 1097] train: loss: 0.0027220
[Epoch 44; Iter   409/ 1097] train: loss: 0.0076257
[Epoch 44; Iter   439/ 1097] train: loss: 0.0080350
[Epoch 44; Iter   469/ 1097] train: loss: 0.0081565
[Epoch 44; Iter   499/ 1097] train: loss: 0.0002074
[Epoch 44; Iter   529/ 1097] train: loss: 0.0938791
[Epoch 44; Iter   559/ 1097] train: loss: 0.1274329
[Epoch 44; Iter   589/ 1097] train: loss: 0.0014214
[Epoch 44; Iter   619/ 1097] train: loss: 0.0027623
[Epoch 44; Iter   649/ 1097] train: loss: 0.0018852
[Epoch 44; Iter   679/ 1097] train: loss: 0.0202128
[Epoch 44; Iter   709/ 1097] train: loss: 0.0013137
[Epoch 44; Iter   739/ 1097] train: loss: 0.0002223
[Epoch 44; Iter   769/ 1097] train: loss: 0.0506593
[Epoch 40; Iter   717/ 1097] train: loss: 0.0009666
[Epoch 40; Iter   747/ 1097] train: loss: 0.0069519
[Epoch 40; Iter   777/ 1097] train: loss: 0.0112886
[Epoch 40; Iter   807/ 1097] train: loss: 0.0205278
[Epoch 40; Iter   837/ 1097] train: loss: 0.0069191
[Epoch 40; Iter   867/ 1097] train: loss: 0.0099645
[Epoch 40; Iter   897/ 1097] train: loss: 0.0017873
[Epoch 40; Iter   927/ 1097] train: loss: 0.0159304
[Epoch 40; Iter   957/ 1097] train: loss: 0.1435510
[Epoch 40; Iter   987/ 1097] train: loss: 0.0001503
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0177636
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0171955
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0010398
[Epoch 40] ogbg-molhiv: 0.747609 val loss: 0.668778
[Epoch 40] ogbg-molhiv: 0.698047 test loss: 3.625776
[Epoch 41; Iter    10/ 1097] train: loss: 0.0007072
[Epoch 41; Iter    40/ 1097] train: loss: 0.0035514
[Epoch 41; Iter    70/ 1097] train: loss: 0.0945474
[Epoch 41; Iter   100/ 1097] train: loss: 0.0006177
[Epoch 41; Iter   130/ 1097] train: loss: 0.0033159
[Epoch 41; Iter   160/ 1097] train: loss: 0.0003254
[Epoch 41; Iter   190/ 1097] train: loss: 0.0005490
[Epoch 41; Iter   220/ 1097] train: loss: 0.0020298
[Epoch 41; Iter   250/ 1097] train: loss: 0.0019983
[Epoch 41; Iter   280/ 1097] train: loss: 0.0935535
[Epoch 41; Iter   310/ 1097] train: loss: 0.0006957
[Epoch 41; Iter   340/ 1097] train: loss: 0.0047615
[Epoch 41; Iter   370/ 1097] train: loss: 0.0000867
[Epoch 41; Iter   400/ 1097] train: loss: 0.0079794
[Epoch 41; Iter   430/ 1097] train: loss: 0.0027596
[Epoch 41; Iter   460/ 1097] train: loss: 0.0011830
[Epoch 41; Iter   490/ 1097] train: loss: 0.0004249
[Epoch 41; Iter   520/ 1097] train: loss: 0.0016138
[Epoch 41; Iter   550/ 1097] train: loss: 0.0053224
[Epoch 41; Iter   580/ 1097] train: loss: 0.0065131
[Epoch 41; Iter   610/ 1097] train: loss: 0.0086157
[Epoch 41; Iter   640/ 1097] train: loss: 0.0490823
[Epoch 41; Iter   670/ 1097] train: loss: 0.0034396
[Epoch 41; Iter   700/ 1097] train: loss: 0.0039517
[Epoch 41; Iter   730/ 1097] train: loss: 0.0175156
[Epoch 41; Iter   760/ 1097] train: loss: 0.0008931
[Epoch 41; Iter   790/ 1097] train: loss: 0.0225822
[Epoch 41; Iter   820/ 1097] train: loss: 0.0364826
[Epoch 41; Iter   850/ 1097] train: loss: 0.1982595
[Epoch 41; Iter   880/ 1097] train: loss: 0.0003064
[Epoch 41; Iter   910/ 1097] train: loss: 0.0013880
[Epoch 41; Iter   940/ 1097] train: loss: 0.0001512
[Epoch 41; Iter   970/ 1097] train: loss: 0.0017542
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0199627
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0200886
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0131630
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0065869
[Epoch 41] ogbg-molhiv: 0.740272 val loss: 0.435232
[Epoch 41] ogbg-molhiv: 0.692547 test loss: 0.515618
[Epoch 42; Iter    23/ 1097] train: loss: 0.0003900
[Epoch 42; Iter    53/ 1097] train: loss: 0.0315639
[Epoch 42; Iter    83/ 1097] train: loss: 0.0021075
[Epoch 42; Iter   113/ 1097] train: loss: 0.0043377
[Epoch 42; Iter   143/ 1097] train: loss: 0.0017943
[Epoch 42; Iter   173/ 1097] train: loss: 0.0044697
[Epoch 42; Iter   203/ 1097] train: loss: 0.0016096
[Epoch 42; Iter   233/ 1097] train: loss: 0.0004219
[Epoch 42; Iter   263/ 1097] train: loss: 0.0005974
[Epoch 42; Iter   293/ 1097] train: loss: 0.0005680
[Epoch 42; Iter   323/ 1097] train: loss: 0.0052965
[Epoch 42; Iter   353/ 1097] train: loss: 0.0009992
[Epoch 42; Iter   383/ 1097] train: loss: 0.0412116
[Epoch 42; Iter   413/ 1097] train: loss: 0.0013984
[Epoch 42; Iter   443/ 1097] train: loss: 0.0101067
[Epoch 42; Iter   473/ 1097] train: loss: 0.0003799
[Epoch 42; Iter   503/ 1097] train: loss: 0.0019178
[Epoch 42; Iter   533/ 1097] train: loss: 0.0034517
[Epoch 42; Iter   563/ 1097] train: loss: 0.0010081
[Epoch 42; Iter   593/ 1097] train: loss: 0.0001870
[Epoch 42; Iter   623/ 1097] train: loss: 0.0000715
[Epoch 42; Iter   653/ 1097] train: loss: 0.0028592
[Epoch 42; Iter   683/ 1097] train: loss: 0.0011955
[Epoch 42; Iter   713/ 1097] train: loss: 0.0091225
[Epoch 42; Iter   743/ 1097] train: loss: 0.0001482
[Epoch 42; Iter   773/ 1097] train: loss: 0.1903461
[Epoch 42; Iter   803/ 1097] train: loss: 0.0053119
[Epoch 42; Iter   833/ 1097] train: loss: 0.0163507
[Epoch 42; Iter   863/ 1097] train: loss: 0.0059725
[Epoch 42; Iter   893/ 1097] train: loss: 0.0016318
[Epoch 42; Iter   923/ 1097] train: loss: 0.0002816
[Epoch 42; Iter   953/ 1097] train: loss: 0.0629390
[Epoch 42; Iter   983/ 1097] train: loss: 0.0157584
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0005727
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0080986
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0011568
[Epoch 42] ogbg-molhiv: 0.715364 val loss: 0.611265
[Epoch 42] ogbg-molhiv: 0.686023 test loss: 1.172472
[Epoch 43; Iter     6/ 1097] train: loss: 0.0079035
[Epoch 43; Iter    36/ 1097] train: loss: 0.0043647
[Epoch 43; Iter    66/ 1097] train: loss: 0.0168099
[Epoch 43; Iter    96/ 1097] train: loss: 0.0029006
[Epoch 43; Iter   126/ 1097] train: loss: 0.0015285
[Epoch 43; Iter   156/ 1097] train: loss: 0.0002022
[Epoch 43; Iter   186/ 1097] train: loss: 0.0215638
[Epoch 43; Iter   216/ 1097] train: loss: 0.0019462
[Epoch 43; Iter   246/ 1097] train: loss: 0.0001163
[Epoch 43; Iter   276/ 1097] train: loss: 0.0015356
[Epoch 43; Iter   306/ 1097] train: loss: 0.0360664
[Epoch 43; Iter   336/ 1097] train: loss: 0.0003692
[Epoch 43; Iter   366/ 1097] train: loss: 0.0299999
[Epoch 43; Iter   396/ 1097] train: loss: 0.0097164
[Epoch 43; Iter   426/ 1097] train: loss: 0.0002262
[Epoch 43; Iter   456/ 1097] train: loss: 0.0011458
[Epoch 43; Iter   486/ 1097] train: loss: 0.0002382
[Epoch 43; Iter   516/ 1097] train: loss: 0.0006217
[Epoch 43; Iter   546/ 1097] train: loss: 0.0003613
[Epoch 43; Iter   576/ 1097] train: loss: 0.0054391
[Epoch 43; Iter   606/ 1097] train: loss: 0.0157409
[Epoch 43; Iter   636/ 1097] train: loss: 0.0009854
[Epoch 43; Iter   666/ 1097] train: loss: 0.0001128
[Epoch 43; Iter   696/ 1097] train: loss: 0.0012392
[Epoch 43; Iter   726/ 1097] train: loss: 0.0035340
[Epoch 43; Iter   756/ 1097] train: loss: 0.0067676
[Epoch 43; Iter   786/ 1097] train: loss: 0.0057930
[Epoch 43; Iter   816/ 1097] train: loss: 0.0146586
[Epoch 43; Iter   846/ 1097] train: loss: 0.0054404
[Epoch 43; Iter   876/ 1097] train: loss: 0.0455659
[Epoch 43; Iter   906/ 1097] train: loss: 0.0366019
[Epoch 43; Iter   936/ 1097] train: loss: 0.0001162
[Epoch 43; Iter   966/ 1097] train: loss: 0.0928195
[Epoch 43; Iter   996/ 1097] train: loss: 0.0006656
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0006318
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0004569
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0002155
[Epoch 43] ogbg-molhiv: 0.709347 val loss: 4.228778
[Epoch 43] ogbg-molhiv: 0.674370 test loss: 6.535524
[Epoch 44; Iter    19/ 1097] train: loss: 0.0105564
[Epoch 44; Iter    49/ 1097] train: loss: 0.0028583
[Epoch 44; Iter    79/ 1097] train: loss: 0.0138102
[Epoch 44; Iter   109/ 1097] train: loss: 0.0034924
[Epoch 44; Iter   139/ 1097] train: loss: 0.0011003
[Epoch 44; Iter   169/ 1097] train: loss: 0.0043164
[Epoch 44; Iter   199/ 1097] train: loss: 0.0299730
[Epoch 44; Iter   229/ 1097] train: loss: 0.0002482
[Epoch 44; Iter   259/ 1097] train: loss: 0.0056843
[Epoch 44; Iter   289/ 1097] train: loss: 0.0004189
[Epoch 44; Iter   319/ 1097] train: loss: 0.0005567
[Epoch 44; Iter   349/ 1097] train: loss: 0.0047176
[Epoch 44; Iter   379/ 1097] train: loss: 0.0017963
[Epoch 44; Iter   409/ 1097] train: loss: 0.0000366
[Epoch 44; Iter   439/ 1097] train: loss: 0.0003556
[Epoch 44; Iter   469/ 1097] train: loss: 0.0017935
[Epoch 44; Iter   499/ 1097] train: loss: 0.0001554
[Epoch 44; Iter   529/ 1097] train: loss: 0.0003992
[Epoch 44; Iter   559/ 1097] train: loss: 0.0142598
[Epoch 44; Iter   589/ 1097] train: loss: 0.0005490
[Epoch 44; Iter   619/ 1097] train: loss: 0.0003940
[Epoch 44; Iter   649/ 1097] train: loss: 0.0001849
[Epoch 44; Iter   679/ 1097] train: loss: 0.1115082
[Epoch 44; Iter   709/ 1097] train: loss: 0.0138523
[Epoch 44; Iter   739/ 1097] train: loss: 0.0023316
[Epoch 44; Iter   769/ 1097] train: loss: 0.0026976
[Epoch 40; Iter   717/ 1097] train: loss: 0.0324319
[Epoch 40; Iter   747/ 1097] train: loss: 0.0254865
[Epoch 40; Iter   777/ 1097] train: loss: 0.0614694
[Epoch 40; Iter   807/ 1097] train: loss: 0.0029545
[Epoch 40; Iter   837/ 1097] train: loss: 0.0055826
[Epoch 40; Iter   867/ 1097] train: loss: 0.0032425
[Epoch 40; Iter   897/ 1097] train: loss: 0.0321905
[Epoch 40; Iter   927/ 1097] train: loss: 0.0188462
[Epoch 40; Iter   957/ 1097] train: loss: 0.0017679
[Epoch 40; Iter   987/ 1097] train: loss: 0.0027871
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0360791
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0043862
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0013173
[Epoch 40] ogbg-molhiv: 0.681110 val loss: 14.843440
[Epoch 40] ogbg-molhiv: 0.593775 test loss: 9.856661
[Epoch 41; Iter    10/ 1097] train: loss: 0.0106215
[Epoch 41; Iter    40/ 1097] train: loss: 0.0051132
[Epoch 41; Iter    70/ 1097] train: loss: 0.0164943
[Epoch 41; Iter   100/ 1097] train: loss: 0.0194445
[Epoch 41; Iter   130/ 1097] train: loss: 0.0014392
[Epoch 41; Iter   160/ 1097] train: loss: 0.0074190
[Epoch 41; Iter   190/ 1097] train: loss: 0.0718514
[Epoch 41; Iter   220/ 1097] train: loss: 0.1000866
[Epoch 41; Iter   250/ 1097] train: loss: 0.0024030
[Epoch 41; Iter   280/ 1097] train: loss: 0.0078272
[Epoch 41; Iter   310/ 1097] train: loss: 0.0925892
[Epoch 41; Iter   340/ 1097] train: loss: 0.0059058
[Epoch 41; Iter   370/ 1097] train: loss: 0.0108691
[Epoch 41; Iter   400/ 1097] train: loss: 0.0093928
[Epoch 41; Iter   430/ 1097] train: loss: 0.0042812
[Epoch 41; Iter   460/ 1097] train: loss: 0.0009840
[Epoch 41; Iter   490/ 1097] train: loss: 0.1314024
[Epoch 41; Iter   520/ 1097] train: loss: 0.0070934
[Epoch 41; Iter   550/ 1097] train: loss: 0.0015434
[Epoch 41; Iter   580/ 1097] train: loss: 0.0040233
[Epoch 41; Iter   610/ 1097] train: loss: 0.0834228
[Epoch 41; Iter   640/ 1097] train: loss: 0.0299598
[Epoch 41; Iter   670/ 1097] train: loss: 0.0010225
[Epoch 41; Iter   700/ 1097] train: loss: 0.0003221
[Epoch 41; Iter   730/ 1097] train: loss: 0.0151766
[Epoch 41; Iter   760/ 1097] train: loss: 0.0755880
[Epoch 41; Iter   790/ 1097] train: loss: 0.0000859
[Epoch 41; Iter   820/ 1097] train: loss: 0.0004768
[Epoch 41; Iter   850/ 1097] train: loss: 0.0037374
[Epoch 41; Iter   880/ 1097] train: loss: 0.0029393
[Epoch 41; Iter   910/ 1097] train: loss: 0.0047955
[Epoch 41; Iter   940/ 1097] train: loss: 0.0032538
[Epoch 41; Iter   970/ 1097] train: loss: 0.0175911
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0013306
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0021032
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0032657
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0042263
[Epoch 41] ogbg-molhiv: 0.700792 val loss: 22.630853
[Epoch 41] ogbg-molhiv: 0.602256 test loss: 13.931846
[Epoch 42; Iter    23/ 1097] train: loss: 0.0030114
[Epoch 42; Iter    53/ 1097] train: loss: 0.0125689
[Epoch 42; Iter    83/ 1097] train: loss: 0.0024804
[Epoch 42; Iter   113/ 1097] train: loss: 0.0011293
[Epoch 42; Iter   143/ 1097] train: loss: 0.0047841
[Epoch 42; Iter   173/ 1097] train: loss: 0.0009924
[Epoch 42; Iter   203/ 1097] train: loss: 0.0223074
[Epoch 42; Iter   233/ 1097] train: loss: 0.0004007
[Epoch 42; Iter   263/ 1097] train: loss: 0.0148907
[Epoch 42; Iter   293/ 1097] train: loss: 0.0026847
[Epoch 42; Iter   323/ 1097] train: loss: 0.0025939
[Epoch 42; Iter   353/ 1097] train: loss: 0.0007925
[Epoch 42; Iter   383/ 1097] train: loss: 0.0033770
[Epoch 42; Iter   413/ 1097] train: loss: 0.0123533
[Epoch 42; Iter   443/ 1097] train: loss: 0.0010889
[Epoch 42; Iter   473/ 1097] train: loss: 0.0266585
[Epoch 42; Iter   503/ 1097] train: loss: 0.0009972
[Epoch 42; Iter   533/ 1097] train: loss: 0.0003754
[Epoch 42; Iter   563/ 1097] train: loss: 0.0001877
[Epoch 42; Iter   593/ 1097] train: loss: 0.0055665
[Epoch 42; Iter   623/ 1097] train: loss: 0.0035619
[Epoch 42; Iter   653/ 1097] train: loss: 0.0041957
[Epoch 42; Iter   683/ 1097] train: loss: 0.0516809
[Epoch 42; Iter   713/ 1097] train: loss: 0.0017860
[Epoch 42; Iter   743/ 1097] train: loss: 0.0007769
[Epoch 42; Iter   773/ 1097] train: loss: 0.0675617
[Epoch 42; Iter   803/ 1097] train: loss: 0.0491196
[Epoch 42; Iter   833/ 1097] train: loss: 0.1530188
[Epoch 42; Iter   863/ 1097] train: loss: 0.0005284
[Epoch 42; Iter   893/ 1097] train: loss: 0.0017263
[Epoch 42; Iter   923/ 1097] train: loss: 0.0298589
[Epoch 42; Iter   953/ 1097] train: loss: 0.0166961
[Epoch 42; Iter   983/ 1097] train: loss: 0.0012620
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0386963
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0472183
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0032048
[Epoch 42] ogbg-molhiv: 0.700305 val loss: 15.267127
[Epoch 42] ogbg-molhiv: 0.579453 test loss: 10.844622
[Epoch 43; Iter     6/ 1097] train: loss: 0.0010930
[Epoch 43; Iter    36/ 1097] train: loss: 0.0013144
[Epoch 43; Iter    66/ 1097] train: loss: 0.0753957
[Epoch 43; Iter    96/ 1097] train: loss: 0.0026848
[Epoch 43; Iter   126/ 1097] train: loss: 0.0008453
[Epoch 43; Iter   156/ 1097] train: loss: 0.0016905
[Epoch 43; Iter   186/ 1097] train: loss: 0.0130971
[Epoch 43; Iter   216/ 1097] train: loss: 0.0011761
[Epoch 43; Iter   246/ 1097] train: loss: 0.0021769
[Epoch 43; Iter   276/ 1097] train: loss: 0.0015762
[Epoch 43; Iter   306/ 1097] train: loss: 0.0380344
[Epoch 43; Iter   336/ 1097] train: loss: 0.0245497
[Epoch 43; Iter   366/ 1097] train: loss: 0.1580872
[Epoch 43; Iter   396/ 1097] train: loss: 0.0085157
[Epoch 43; Iter   426/ 1097] train: loss: 0.0002193
[Epoch 43; Iter   456/ 1097] train: loss: 0.0014168
[Epoch 43; Iter   486/ 1097] train: loss: 0.0063697
[Epoch 43; Iter   516/ 1097] train: loss: 0.0075221
[Epoch 43; Iter   546/ 1097] train: loss: 0.0171528
[Epoch 43; Iter   576/ 1097] train: loss: 0.0159271
[Epoch 43; Iter   606/ 1097] train: loss: 0.0001993
[Epoch 43; Iter   636/ 1097] train: loss: 0.0005640
[Epoch 43; Iter   666/ 1097] train: loss: 0.0004486
[Epoch 43; Iter   696/ 1097] train: loss: 0.0226886
[Epoch 43; Iter   726/ 1097] train: loss: 0.0049062
[Epoch 43; Iter   756/ 1097] train: loss: 0.0020635
[Epoch 43; Iter   786/ 1097] train: loss: 0.0173491
[Epoch 43; Iter   816/ 1097] train: loss: 0.0585254
[Epoch 43; Iter   846/ 1097] train: loss: 0.0044682
[Epoch 43; Iter   876/ 1097] train: loss: 0.0033562
[Epoch 43; Iter   906/ 1097] train: loss: 0.0096196
[Epoch 43; Iter   936/ 1097] train: loss: 0.0024000
[Epoch 43; Iter   966/ 1097] train: loss: 0.0531522
[Epoch 43; Iter   996/ 1097] train: loss: 0.0107044
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0044697
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0012309
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0066573
[Epoch 43] ogbg-molhiv: 0.695143 val loss: 8.377270
[Epoch 43] ogbg-molhiv: 0.594042 test loss: 7.440106
[Epoch 44; Iter    19/ 1097] train: loss: 0.0280948
[Epoch 44; Iter    49/ 1097] train: loss: 0.0092979
[Epoch 44; Iter    79/ 1097] train: loss: 0.0262201
[Epoch 44; Iter   109/ 1097] train: loss: 0.0049938
[Epoch 44; Iter   139/ 1097] train: loss: 0.0064948
[Epoch 44; Iter   169/ 1097] train: loss: 0.0019261
[Epoch 44; Iter   199/ 1097] train: loss: 0.0019677
[Epoch 44; Iter   229/ 1097] train: loss: 0.0023949
[Epoch 44; Iter   259/ 1097] train: loss: 0.0029069
[Epoch 44; Iter   289/ 1097] train: loss: 0.0071394
[Epoch 44; Iter   319/ 1097] train: loss: 0.0014815
[Epoch 44; Iter   349/ 1097] train: loss: 0.0083893
[Epoch 44; Iter   379/ 1097] train: loss: 0.0088333
[Epoch 44; Iter   409/ 1097] train: loss: 0.0004600
[Epoch 44; Iter   439/ 1097] train: loss: 0.0112580
[Epoch 44; Iter   469/ 1097] train: loss: 0.0152742
[Epoch 44; Iter   499/ 1097] train: loss: 0.0077990
[Epoch 44; Iter   529/ 1097] train: loss: 0.0169413
[Epoch 44; Iter   559/ 1097] train: loss: 0.0002880
[Epoch 44; Iter   589/ 1097] train: loss: 0.0094284
[Epoch 44; Iter   619/ 1097] train: loss: 0.0005941
[Epoch 44; Iter   649/ 1097] train: loss: 0.0304027
[Epoch 44; Iter   679/ 1097] train: loss: 0.0023278
[Epoch 44; Iter   709/ 1097] train: loss: 0.0045988
[Epoch 44; Iter   739/ 1097] train: loss: 0.0016374
[Epoch 44; Iter   769/ 1097] train: loss: 0.0010613
[Epoch 40; Iter   717/ 1097] train: loss: 0.0509750
[Epoch 40; Iter   747/ 1097] train: loss: 0.0261258
[Epoch 40; Iter   777/ 1097] train: loss: 0.0019638
[Epoch 40; Iter   807/ 1097] train: loss: 0.0191529
[Epoch 40; Iter   837/ 1097] train: loss: 0.1004039
[Epoch 40; Iter   867/ 1097] train: loss: 0.0237039
[Epoch 40; Iter   897/ 1097] train: loss: 0.0181268
[Epoch 40; Iter   927/ 1097] train: loss: 0.0424035
[Epoch 40; Iter   957/ 1097] train: loss: 0.1312170
[Epoch 40; Iter   987/ 1097] train: loss: 0.0172539
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0306486
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0079562
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0078275
[Epoch 40] ogbg-molhiv: 0.761289 val loss: 0.493018
[Epoch 40] ogbg-molhiv: 0.650155 test loss: 0.890526
[Epoch 41; Iter    10/ 1097] train: loss: 0.0040951
[Epoch 41; Iter    40/ 1097] train: loss: 0.0041522
[Epoch 41; Iter    70/ 1097] train: loss: 0.0034549
[Epoch 41; Iter   100/ 1097] train: loss: 0.0019239
[Epoch 41; Iter   130/ 1097] train: loss: 0.0297376
[Epoch 41; Iter   160/ 1097] train: loss: 0.0098631
[Epoch 41; Iter   190/ 1097] train: loss: 0.0083899
[Epoch 41; Iter   220/ 1097] train: loss: 0.0197266
[Epoch 41; Iter   250/ 1097] train: loss: 0.0019585
[Epoch 41; Iter   280/ 1097] train: loss: 0.0034385
[Epoch 41; Iter   310/ 1097] train: loss: 0.1083336
[Epoch 41; Iter   340/ 1097] train: loss: 0.1008860
[Epoch 41; Iter   370/ 1097] train: loss: 0.0060874
[Epoch 41; Iter   400/ 1097] train: loss: 0.0089030
[Epoch 41; Iter   430/ 1097] train: loss: 0.0203153
[Epoch 41; Iter   460/ 1097] train: loss: 0.0084210
[Epoch 41; Iter   490/ 1097] train: loss: 0.0163301
[Epoch 41; Iter   520/ 1097] train: loss: 0.0160683
[Epoch 41; Iter   550/ 1097] train: loss: 0.0173470
[Epoch 41; Iter   580/ 1097] train: loss: 0.0807839
[Epoch 41; Iter   610/ 1097] train: loss: 0.0236535
[Epoch 41; Iter   640/ 1097] train: loss: 0.0227285
[Epoch 41; Iter   670/ 1097] train: loss: 0.0139128
[Epoch 41; Iter   700/ 1097] train: loss: 0.0201959
[Epoch 41; Iter   730/ 1097] train: loss: 0.0098433
[Epoch 41; Iter   760/ 1097] train: loss: 0.0228030
[Epoch 41; Iter   790/ 1097] train: loss: 0.1287533
[Epoch 41; Iter   820/ 1097] train: loss: 0.0401393
[Epoch 41; Iter   850/ 1097] train: loss: 0.0359523
[Epoch 41; Iter   880/ 1097] train: loss: 0.0104166
[Epoch 41; Iter   910/ 1097] train: loss: 0.0069376
[Epoch 41; Iter   940/ 1097] train: loss: 0.0596210
[Epoch 41; Iter   970/ 1097] train: loss: 0.2087683
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0547722
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0041686
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0691629
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0416110
[Epoch 41] ogbg-molhiv: 0.760478 val loss: 0.258010
[Epoch 41] ogbg-molhiv: 0.671293 test loss: 0.859389
[Epoch 42; Iter    23/ 1097] train: loss: 0.1376873
[Epoch 42; Iter    53/ 1097] train: loss: 0.0544652
[Epoch 42; Iter    83/ 1097] train: loss: 0.0020778
[Epoch 42; Iter   113/ 1097] train: loss: 0.0030203
[Epoch 42; Iter   143/ 1097] train: loss: 0.0017072
[Epoch 42; Iter   173/ 1097] train: loss: 0.0004186
[Epoch 42; Iter   203/ 1097] train: loss: 0.0256702
[Epoch 42; Iter   233/ 1097] train: loss: 0.0326522
[Epoch 42; Iter   263/ 1097] train: loss: 0.0530463
[Epoch 42; Iter   293/ 1097] train: loss: 0.0015878
[Epoch 42; Iter   323/ 1097] train: loss: 0.0042677
[Epoch 42; Iter   353/ 1097] train: loss: 0.0036232
[Epoch 42; Iter   383/ 1097] train: loss: 0.0471611
[Epoch 42; Iter   413/ 1097] train: loss: 0.0324636
[Epoch 42; Iter   443/ 1097] train: loss: 0.0386334
[Epoch 42; Iter   473/ 1097] train: loss: 0.0016103
[Epoch 42; Iter   503/ 1097] train: loss: 0.0227692
[Epoch 42; Iter   533/ 1097] train: loss: 0.0508255
[Epoch 42; Iter   563/ 1097] train: loss: 0.0592426
[Epoch 42; Iter   593/ 1097] train: loss: 0.0833117
[Epoch 42; Iter   623/ 1097] train: loss: 0.0134090
[Epoch 42; Iter   653/ 1097] train: loss: 0.0241482
[Epoch 42; Iter   683/ 1097] train: loss: 0.0153279
[Epoch 42; Iter   713/ 1097] train: loss: 0.0104581
[Epoch 42; Iter   743/ 1097] train: loss: 0.0404621
[Epoch 42; Iter   773/ 1097] train: loss: 0.2825568
[Epoch 42; Iter   803/ 1097] train: loss: 0.0401098
[Epoch 42; Iter   833/ 1097] train: loss: 0.0288281
[Epoch 42; Iter   863/ 1097] train: loss: 0.0041950
[Epoch 42; Iter   893/ 1097] train: loss: 0.1287482
[Epoch 42; Iter   923/ 1097] train: loss: 0.0208948
[Epoch 42; Iter   953/ 1097] train: loss: 0.0072183
[Epoch 42; Iter   983/ 1097] train: loss: 0.0025673
[Epoch 42; Iter  1013/ 1097] train: loss: 0.2727204
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0726528
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0604236
[Epoch 42] ogbg-molhiv: 0.757851 val loss: 0.637987
[Epoch 42] ogbg-molhiv: 0.685701 test loss: 1.324852
[Epoch 43; Iter     6/ 1097] train: loss: 0.0217858
[Epoch 43; Iter    36/ 1097] train: loss: 0.0031349
[Epoch 43; Iter    66/ 1097] train: loss: 0.0180967
[Epoch 43; Iter    96/ 1097] train: loss: 0.0009269
[Epoch 43; Iter   126/ 1097] train: loss: 0.0066123
[Epoch 43; Iter   156/ 1097] train: loss: 0.0028055
[Epoch 43; Iter   186/ 1097] train: loss: 0.1512287
[Epoch 43; Iter   216/ 1097] train: loss: 0.0285850
[Epoch 43; Iter   246/ 1097] train: loss: 0.0722506
[Epoch 43; Iter   276/ 1097] train: loss: 0.0023502
[Epoch 43; Iter   306/ 1097] train: loss: 0.0111716
[Epoch 43; Iter   336/ 1097] train: loss: 0.0377234
[Epoch 43; Iter   366/ 1097] train: loss: 0.0054198
[Epoch 43; Iter   396/ 1097] train: loss: 0.0540457
[Epoch 43; Iter   426/ 1097] train: loss: 0.0211389
[Epoch 43; Iter   456/ 1097] train: loss: 0.0673234
[Epoch 43; Iter   486/ 1097] train: loss: 0.0019643
[Epoch 43; Iter   516/ 1097] train: loss: 0.0069671
[Epoch 43; Iter   546/ 1097] train: loss: 0.0148920
[Epoch 43; Iter   576/ 1097] train: loss: 0.0102327
[Epoch 43; Iter   606/ 1097] train: loss: 0.0201872
[Epoch 43; Iter   636/ 1097] train: loss: 0.0051036
[Epoch 43; Iter   666/ 1097] train: loss: 0.0136584
[Epoch 43; Iter   696/ 1097] train: loss: 0.0116339
[Epoch 43; Iter   726/ 1097] train: loss: 0.0119124
[Epoch 43; Iter   756/ 1097] train: loss: 0.0328575
[Epoch 43; Iter   786/ 1097] train: loss: 0.0013565
[Epoch 43; Iter   816/ 1097] train: loss: 0.0107257
[Epoch 43; Iter   846/ 1097] train: loss: 0.0104255
[Epoch 43; Iter   876/ 1097] train: loss: 0.0241822
[Epoch 43; Iter   906/ 1097] train: loss: 0.0380478
[Epoch 43; Iter   936/ 1097] train: loss: 0.0053219
[Epoch 43; Iter   966/ 1097] train: loss: 0.0012214
[Epoch 43; Iter   996/ 1097] train: loss: 0.0080943
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0021243
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0883975
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0035577
[Epoch 43] ogbg-molhiv: 0.677907 val loss: 5.577288
[Epoch 43] ogbg-molhiv: 0.605863 test loss: 5.960753
[Epoch 44; Iter    19/ 1097] train: loss: 0.0066688
[Epoch 44; Iter    49/ 1097] train: loss: 0.0134789
[Epoch 44; Iter    79/ 1097] train: loss: 0.0056244
[Epoch 44; Iter   109/ 1097] train: loss: 0.0015437
[Epoch 44; Iter   139/ 1097] train: loss: 0.1201054
[Epoch 44; Iter   169/ 1097] train: loss: 0.0204104
[Epoch 44; Iter   199/ 1097] train: loss: 0.0031328
[Epoch 44; Iter   229/ 1097] train: loss: 0.0085804
[Epoch 44; Iter   259/ 1097] train: loss: 0.0434133
[Epoch 44; Iter   289/ 1097] train: loss: 0.0025795
[Epoch 44; Iter   319/ 1097] train: loss: 0.3707560
[Epoch 44; Iter   349/ 1097] train: loss: 0.0182029
[Epoch 44; Iter   379/ 1097] train: loss: 0.0038554
[Epoch 44; Iter   409/ 1097] train: loss: 0.1189911
[Epoch 44; Iter   439/ 1097] train: loss: 0.0140592
[Epoch 44; Iter   469/ 1097] train: loss: 0.0175667
[Epoch 44; Iter   499/ 1097] train: loss: 0.0031240
[Epoch 44; Iter   529/ 1097] train: loss: 0.0319855
[Epoch 44; Iter   559/ 1097] train: loss: 0.0018446
[Epoch 44; Iter   589/ 1097] train: loss: 0.0087574
[Epoch 44; Iter   619/ 1097] train: loss: 0.0088679
[Epoch 44; Iter   649/ 1097] train: loss: 0.0680214
[Epoch 44; Iter   679/ 1097] train: loss: 0.1740221
[Epoch 44; Iter   709/ 1097] train: loss: 0.0539351
[Epoch 44; Iter   739/ 1097] train: loss: 0.0029223
[Epoch 44; Iter   769/ 1097] train: loss: 0.0341906
[Epoch 44; Iter   769/ 1097] train: loss: 0.0005168
[Epoch 44; Iter   799/ 1097] train: loss: 0.0208826
[Epoch 44; Iter   829/ 1097] train: loss: 0.0080041
[Epoch 44; Iter   859/ 1097] train: loss: 0.0022348
[Epoch 44; Iter   889/ 1097] train: loss: 0.0205722
[Epoch 44; Iter   919/ 1097] train: loss: 0.0191956
[Epoch 44; Iter   949/ 1097] train: loss: 0.0402956
[Epoch 44; Iter   979/ 1097] train: loss: 0.0029310
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0284151
[Epoch 44; Iter  1039/ 1097] train: loss: 0.1311683
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0011307
[Epoch 44] ogbg-molhiv: 0.809735 val loss: 1.006536
[Epoch 44] ogbg-molhiv: 0.725450 test loss: 0.434682
[Epoch 45; Iter     2/ 1097] train: loss: 0.0032882
[Epoch 45; Iter    32/ 1097] train: loss: 0.0003588
[Epoch 45; Iter    62/ 1097] train: loss: 0.0124104
[Epoch 45; Iter    92/ 1097] train: loss: 0.0049150
[Epoch 45; Iter   122/ 1097] train: loss: 0.0118168
[Epoch 45; Iter   152/ 1097] train: loss: 0.0046620
[Epoch 45; Iter   182/ 1097] train: loss: 0.0063071
[Epoch 45; Iter   212/ 1097] train: loss: 0.0011260
[Epoch 45; Iter   242/ 1097] train: loss: 0.0021623
[Epoch 45; Iter   272/ 1097] train: loss: 0.0737355
[Epoch 45; Iter   302/ 1097] train: loss: 0.0054805
[Epoch 45; Iter   332/ 1097] train: loss: 0.0235022
[Epoch 45; Iter   362/ 1097] train: loss: 0.0020666
[Epoch 45; Iter   392/ 1097] train: loss: 0.2082111
[Epoch 45; Iter   422/ 1097] train: loss: 0.0045463
[Epoch 45; Iter   452/ 1097] train: loss: 0.0409212
[Epoch 45; Iter   482/ 1097] train: loss: 0.0084064
[Epoch 45; Iter   512/ 1097] train: loss: 0.0003840
[Epoch 45; Iter   542/ 1097] train: loss: 0.0009990
[Epoch 45; Iter   572/ 1097] train: loss: 0.0073795
[Epoch 45; Iter   602/ 1097] train: loss: 0.0008100
[Epoch 45; Iter   632/ 1097] train: loss: 0.0005574
[Epoch 45; Iter   662/ 1097] train: loss: 0.0093583
[Epoch 45; Iter   692/ 1097] train: loss: 0.0368862
[Epoch 45; Iter   722/ 1097] train: loss: 0.0015754
[Epoch 45; Iter   752/ 1097] train: loss: 0.0032294
[Epoch 45; Iter   782/ 1097] train: loss: 0.0014780
[Epoch 45; Iter   812/ 1097] train: loss: 0.0012067
[Epoch 45; Iter   842/ 1097] train: loss: 0.0110016
[Epoch 45; Iter   872/ 1097] train: loss: 0.0137493
[Epoch 45; Iter   902/ 1097] train: loss: 0.0253019
[Epoch 45; Iter   932/ 1097] train: loss: 0.0211296
[Epoch 45; Iter   962/ 1097] train: loss: 0.0061639
[Epoch 45; Iter   992/ 1097] train: loss: 0.1522149
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0111155
[Epoch 45; Iter  1052/ 1097] train: loss: 0.1140337
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0029045
[Epoch 45] ogbg-molhiv: 0.817822 val loss: 1.869126
[Epoch 45] ogbg-molhiv: 0.731808 test loss: 0.747599
[Epoch 46; Iter    15/ 1097] train: loss: 0.0026001
[Epoch 46; Iter    45/ 1097] train: loss: 0.0009827
[Epoch 46; Iter    75/ 1097] train: loss: 0.0022322
[Epoch 46; Iter   105/ 1097] train: loss: 0.0134149
[Epoch 46; Iter   135/ 1097] train: loss: 0.0423801
[Epoch 46; Iter   165/ 1097] train: loss: 0.0047002
[Epoch 46; Iter   195/ 1097] train: loss: 0.0017804
[Epoch 46; Iter   225/ 1097] train: loss: 0.0124923
[Epoch 46; Iter   255/ 1097] train: loss: 0.0015548
[Epoch 46; Iter   285/ 1097] train: loss: 0.0156029
[Epoch 46; Iter   315/ 1097] train: loss: 0.0793277
[Epoch 46; Iter   345/ 1097] train: loss: 0.0010135
[Epoch 46; Iter   375/ 1097] train: loss: 0.0028700
[Epoch 46; Iter   405/ 1097] train: loss: 0.0019225
[Epoch 46; Iter   435/ 1097] train: loss: 0.0011615
[Epoch 46; Iter   465/ 1097] train: loss: 0.0003282
[Epoch 46; Iter   495/ 1097] train: loss: 0.0417685
[Epoch 46; Iter   525/ 1097] train: loss: 0.0039005
[Epoch 46; Iter   555/ 1097] train: loss: 0.0007687
[Epoch 46; Iter   585/ 1097] train: loss: 0.0305271
[Epoch 46; Iter   615/ 1097] train: loss: 0.1334033
[Epoch 46; Iter   645/ 1097] train: loss: 0.0004859
[Epoch 46; Iter   675/ 1097] train: loss: 0.0002595
[Epoch 46; Iter   705/ 1097] train: loss: 0.0009277
[Epoch 46; Iter   735/ 1097] train: loss: 0.0028293
[Epoch 46; Iter   765/ 1097] train: loss: 0.0148571
[Epoch 46; Iter   795/ 1097] train: loss: 0.0319393
[Epoch 46; Iter   825/ 1097] train: loss: 0.0982252
[Epoch 46; Iter   855/ 1097] train: loss: 0.0032448
[Epoch 46; Iter   885/ 1097] train: loss: 0.0013768
[Epoch 46; Iter   915/ 1097] train: loss: 0.0474119
[Epoch 46; Iter   945/ 1097] train: loss: 0.0034722
[Epoch 46; Iter   975/ 1097] train: loss: 0.1960241
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0694856
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0031445
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0428610
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0104103
[Epoch 46] ogbg-molhiv: 0.809659 val loss: 1.663215
[Epoch 46] ogbg-molhiv: 0.744232 test loss: 1.292737
[Epoch 47; Iter    28/ 1097] train: loss: 0.0024957
[Epoch 47; Iter    58/ 1097] train: loss: 0.0067671
[Epoch 47; Iter    88/ 1097] train: loss: 0.0144542
[Epoch 47; Iter   118/ 1097] train: loss: 0.0002396
[Epoch 47; Iter   148/ 1097] train: loss: 0.0063795
[Epoch 47; Iter   178/ 1097] train: loss: 0.0017729
[Epoch 47; Iter   208/ 1097] train: loss: 0.0326370
[Epoch 47; Iter   238/ 1097] train: loss: 0.0009239
[Epoch 47; Iter   268/ 1097] train: loss: 0.0015087
[Epoch 47; Iter   298/ 1097] train: loss: 0.0019264
[Epoch 47; Iter   328/ 1097] train: loss: 0.0035788
[Epoch 47; Iter   358/ 1097] train: loss: 0.0211550
[Epoch 47; Iter   388/ 1097] train: loss: 0.0209419
[Epoch 47; Iter   418/ 1097] train: loss: 0.0010761
[Epoch 47; Iter   448/ 1097] train: loss: 0.0177987
[Epoch 47; Iter   478/ 1097] train: loss: 0.0003888
[Epoch 47; Iter   508/ 1097] train: loss: 0.0126047
[Epoch 47; Iter   538/ 1097] train: loss: 0.0003007
[Epoch 47; Iter   568/ 1097] train: loss: 0.0132961
[Epoch 47; Iter   598/ 1097] train: loss: 0.0014355
[Epoch 47; Iter   628/ 1097] train: loss: 0.0011801
[Epoch 47; Iter   658/ 1097] train: loss: 0.0013035
[Epoch 47; Iter   688/ 1097] train: loss: 0.1410481
[Epoch 47; Iter   718/ 1097] train: loss: 0.0014849
[Epoch 47; Iter   748/ 1097] train: loss: 0.0194507
[Epoch 47; Iter   778/ 1097] train: loss: 0.0006578
[Epoch 47; Iter   808/ 1097] train: loss: 0.0006047
[Epoch 47; Iter   838/ 1097] train: loss: 0.0093293
[Epoch 47; Iter   868/ 1097] train: loss: 0.0111543
[Epoch 47; Iter   898/ 1097] train: loss: 0.0035885
[Epoch 47; Iter   928/ 1097] train: loss: 0.0830065
[Epoch 47; Iter   958/ 1097] train: loss: 0.0033245
[Epoch 47; Iter   988/ 1097] train: loss: 0.0034446
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0025879
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0355547
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0154690
[Epoch 47] ogbg-molhiv: 0.806122 val loss: 1.252228
[Epoch 47] ogbg-molhiv: 0.744180 test loss: 0.989182
[Epoch 48; Iter    11/ 1097] train: loss: 0.0148203
[Epoch 48; Iter    41/ 1097] train: loss: 0.0290883
[Epoch 48; Iter    71/ 1097] train: loss: 0.0353965
[Epoch 48; Iter   101/ 1097] train: loss: 0.0029351
[Epoch 48; Iter   131/ 1097] train: loss: 0.0036640
[Epoch 48; Iter   161/ 1097] train: loss: 0.0006523
[Epoch 48; Iter   191/ 1097] train: loss: 0.0698084
[Epoch 48; Iter   221/ 1097] train: loss: 0.0031004
[Epoch 48; Iter   251/ 1097] train: loss: 0.0438418
[Epoch 48; Iter   281/ 1097] train: loss: 0.0059816
[Epoch 48; Iter   311/ 1097] train: loss: 0.0020706
[Epoch 48; Iter   341/ 1097] train: loss: 0.0064302
[Epoch 48; Iter   371/ 1097] train: loss: 0.0065903
[Epoch 48; Iter   401/ 1097] train: loss: 0.0053812
[Epoch 48; Iter   431/ 1097] train: loss: 0.0007093
[Epoch 48; Iter   461/ 1097] train: loss: 0.0007979
[Epoch 48; Iter   491/ 1097] train: loss: 0.0051175
[Epoch 48; Iter   521/ 1097] train: loss: 0.0075886
[Epoch 48; Iter   551/ 1097] train: loss: 0.0124161
[Epoch 48; Iter   581/ 1097] train: loss: 0.0216795
[Epoch 48; Iter   611/ 1097] train: loss: 0.0014444
[Epoch 48; Iter   641/ 1097] train: loss: 0.0199605
[Epoch 48; Iter   671/ 1097] train: loss: 0.0007055
[Epoch 48; Iter   701/ 1097] train: loss: 0.0048044
[Epoch 48; Iter   731/ 1097] train: loss: 0.0068655
[Epoch 48; Iter   761/ 1097] train: loss: 0.0655737
[Epoch 48; Iter   791/ 1097] train: loss: 0.0616941
[Epoch 48; Iter   821/ 1097] train: loss: 0.0038083
[Epoch 44; Iter   769/ 1097] train: loss: 0.0339680
[Epoch 44; Iter   799/ 1097] train: loss: 0.0043181
[Epoch 44; Iter   829/ 1097] train: loss: 0.2005531
[Epoch 44; Iter   859/ 1097] train: loss: 0.0009506
[Epoch 44; Iter   889/ 1097] train: loss: 0.0014308
[Epoch 44; Iter   919/ 1097] train: loss: 0.0011660
[Epoch 44; Iter   949/ 1097] train: loss: 0.0123564
[Epoch 44; Iter   979/ 1097] train: loss: 0.0051849
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0006583
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0025830
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0085988
[Epoch 44] ogbg-molhiv: 0.776449 val loss: 0.795211
[Epoch 44] ogbg-molhiv: 0.700052 test loss: 0.469714
[Epoch 45; Iter     2/ 1097] train: loss: 0.0002997
[Epoch 45; Iter    32/ 1097] train: loss: 0.0050236
[Epoch 45; Iter    62/ 1097] train: loss: 0.0131790
[Epoch 45; Iter    92/ 1097] train: loss: 0.0043648
[Epoch 45; Iter   122/ 1097] train: loss: 0.0147405
[Epoch 45; Iter   152/ 1097] train: loss: 0.0097893
[Epoch 45; Iter   182/ 1097] train: loss: 0.0249394
[Epoch 45; Iter   212/ 1097] train: loss: 0.0030315
[Epoch 45; Iter   242/ 1097] train: loss: 0.0015615
[Epoch 45; Iter   272/ 1097] train: loss: 0.0228908
[Epoch 45; Iter   302/ 1097] train: loss: 0.0059721
[Epoch 45; Iter   332/ 1097] train: loss: 0.0074934
[Epoch 45; Iter   362/ 1097] train: loss: 0.0008876
[Epoch 45; Iter   392/ 1097] train: loss: 0.0859695
[Epoch 45; Iter   422/ 1097] train: loss: 0.0117192
[Epoch 45; Iter   452/ 1097] train: loss: 0.0123979
[Epoch 45; Iter   482/ 1097] train: loss: 0.0151011
[Epoch 45; Iter   512/ 1097] train: loss: 0.0123481
[Epoch 45; Iter   542/ 1097] train: loss: 0.0010339
[Epoch 45; Iter   572/ 1097] train: loss: 0.0237395
[Epoch 45; Iter   602/ 1097] train: loss: 0.0543804
[Epoch 45; Iter   632/ 1097] train: loss: 0.0082107
[Epoch 45; Iter   662/ 1097] train: loss: 0.0014686
[Epoch 45; Iter   692/ 1097] train: loss: 0.0048462
[Epoch 45; Iter   722/ 1097] train: loss: 0.0072969
[Epoch 45; Iter   752/ 1097] train: loss: 0.0324786
[Epoch 45; Iter   782/ 1097] train: loss: 0.0827949
[Epoch 45; Iter   812/ 1097] train: loss: 0.0107222
[Epoch 45; Iter   842/ 1097] train: loss: 0.0260917
[Epoch 45; Iter   872/ 1097] train: loss: 0.0271232
[Epoch 45; Iter   902/ 1097] train: loss: 0.0046769
[Epoch 45; Iter   932/ 1097] train: loss: 0.0270916
[Epoch 45; Iter   962/ 1097] train: loss: 0.0065205
[Epoch 45; Iter   992/ 1097] train: loss: 0.0838641
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0021360
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0056393
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0214478
[Epoch 45] ogbg-molhiv: 0.757627 val loss: 2.892592
[Epoch 45] ogbg-molhiv: 0.680524 test loss: 0.416183
[Epoch 46; Iter    15/ 1097] train: loss: 0.0198595
[Epoch 46; Iter    45/ 1097] train: loss: 0.0014488
[Epoch 46; Iter    75/ 1097] train: loss: 0.0049644
[Epoch 46; Iter   105/ 1097] train: loss: 0.0061901
[Epoch 46; Iter   135/ 1097] train: loss: 0.0080305
[Epoch 46; Iter   165/ 1097] train: loss: 0.0573382
[Epoch 46; Iter   195/ 1097] train: loss: 0.0439557
[Epoch 46; Iter   225/ 1097] train: loss: 0.0053392
[Epoch 46; Iter   255/ 1097] train: loss: 0.0067878
[Epoch 46; Iter   285/ 1097] train: loss: 0.0058887
[Epoch 46; Iter   315/ 1097] train: loss: 0.0579300
[Epoch 46; Iter   345/ 1097] train: loss: 0.0064374
[Epoch 46; Iter   375/ 1097] train: loss: 0.0025117
[Epoch 46; Iter   405/ 1097] train: loss: 0.0061308
[Epoch 46; Iter   435/ 1097] train: loss: 0.0061818
[Epoch 46; Iter   465/ 1097] train: loss: 0.0027327
[Epoch 46; Iter   495/ 1097] train: loss: 0.0170947
[Epoch 46; Iter   525/ 1097] train: loss: 0.0117024
[Epoch 46; Iter   555/ 1097] train: loss: 0.0541483
[Epoch 46; Iter   585/ 1097] train: loss: 0.0063273
[Epoch 46; Iter   615/ 1097] train: loss: 0.0032138
[Epoch 46; Iter   645/ 1097] train: loss: 0.0166442
[Epoch 46; Iter   675/ 1097] train: loss: 0.0043394
[Epoch 46; Iter   705/ 1097] train: loss: 0.0002519
[Epoch 46; Iter   735/ 1097] train: loss: 0.0190628
[Epoch 46; Iter   765/ 1097] train: loss: 0.0421965
[Epoch 46; Iter   795/ 1097] train: loss: 0.0009727
[Epoch 46; Iter   825/ 1097] train: loss: 0.0067520
[Epoch 46; Iter   855/ 1097] train: loss: 0.0016809
[Epoch 46; Iter   885/ 1097] train: loss: 0.1202474
[Epoch 46; Iter   915/ 1097] train: loss: 0.0116042
[Epoch 46; Iter   945/ 1097] train: loss: 0.0017419
[Epoch 46; Iter   975/ 1097] train: loss: 0.0043274
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0012617
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0074075
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0048358
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0004213
[Epoch 46] ogbg-molhiv: 0.796204 val loss: 0.286090
[Epoch 46] ogbg-molhiv: 0.712042 test loss: 0.311432
[Epoch 47; Iter    28/ 1097] train: loss: 0.0030176
[Epoch 47; Iter    58/ 1097] train: loss: 0.0109968
[Epoch 47; Iter    88/ 1097] train: loss: 0.0020316
[Epoch 47; Iter   118/ 1097] train: loss: 0.0614532
[Epoch 47; Iter   148/ 1097] train: loss: 0.0102211
[Epoch 47; Iter   178/ 1097] train: loss: 0.0755864
[Epoch 47; Iter   208/ 1097] train: loss: 0.0063493
[Epoch 47; Iter   238/ 1097] train: loss: 0.0021895
[Epoch 47; Iter   268/ 1097] train: loss: 0.0233232
[Epoch 47; Iter   298/ 1097] train: loss: 0.0016720
[Epoch 47; Iter   328/ 1097] train: loss: 0.0025379
[Epoch 47; Iter   358/ 1097] train: loss: 0.0144948
[Epoch 47; Iter   388/ 1097] train: loss: 0.0012475
[Epoch 47; Iter   418/ 1097] train: loss: 0.0009533
[Epoch 47; Iter   448/ 1097] train: loss: 0.0648444
[Epoch 47; Iter   478/ 1097] train: loss: 0.0549116
[Epoch 47; Iter   508/ 1097] train: loss: 0.0035030
[Epoch 47; Iter   538/ 1097] train: loss: 0.0105845
[Epoch 47; Iter   568/ 1097] train: loss: 0.0491074
[Epoch 47; Iter   598/ 1097] train: loss: 0.0332202
[Epoch 47; Iter   628/ 1097] train: loss: 0.0013404
[Epoch 47; Iter   658/ 1097] train: loss: 0.0039014
[Epoch 47; Iter   688/ 1097] train: loss: 0.0123482
[Epoch 47; Iter   718/ 1097] train: loss: 0.0026829
[Epoch 47; Iter   748/ 1097] train: loss: 0.0011330
[Epoch 47; Iter   778/ 1097] train: loss: 0.0070133
[Epoch 47; Iter   808/ 1097] train: loss: 0.0295984
[Epoch 47; Iter   838/ 1097] train: loss: 0.0015435
[Epoch 47; Iter   868/ 1097] train: loss: 0.0036521
[Epoch 47; Iter   898/ 1097] train: loss: 0.0033307
[Epoch 47; Iter   928/ 1097] train: loss: 0.0035718
[Epoch 47; Iter   958/ 1097] train: loss: 0.0085658
[Epoch 47; Iter   988/ 1097] train: loss: 0.0816899
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0132619
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0035853
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0032141
[Epoch 47] ogbg-molhiv: 0.775607 val loss: 1.354083
[Epoch 47] ogbg-molhiv: 0.699071 test loss: 0.290460
[Epoch 48; Iter    11/ 1097] train: loss: 0.0042363
[Epoch 48; Iter    41/ 1097] train: loss: 0.0005092
[Epoch 48; Iter    71/ 1097] train: loss: 0.0050576
[Epoch 48; Iter   101/ 1097] train: loss: 0.0268422
[Epoch 48; Iter   131/ 1097] train: loss: 0.0033019
[Epoch 48; Iter   161/ 1097] train: loss: 0.0383499
[Epoch 48; Iter   191/ 1097] train: loss: 0.0057121
[Epoch 48; Iter   221/ 1097] train: loss: 0.0003128
[Epoch 48; Iter   251/ 1097] train: loss: 0.0288720
[Epoch 48; Iter   281/ 1097] train: loss: 0.0014805
[Epoch 48; Iter   311/ 1097] train: loss: 0.0045536
[Epoch 48; Iter   341/ 1097] train: loss: 0.0002371
[Epoch 48; Iter   371/ 1097] train: loss: 0.0022140
[Epoch 48; Iter   401/ 1097] train: loss: 0.0011061
[Epoch 48; Iter   431/ 1097] train: loss: 0.0137143
[Epoch 48; Iter   461/ 1097] train: loss: 0.0013646
[Epoch 48; Iter   491/ 1097] train: loss: 0.0042638
[Epoch 48; Iter   521/ 1097] train: loss: 0.0003618
[Epoch 48; Iter   551/ 1097] train: loss: 0.0080973
[Epoch 48; Iter   581/ 1097] train: loss: 0.0642007
[Epoch 48; Iter   611/ 1097] train: loss: 0.0426180
[Epoch 48; Iter   641/ 1097] train: loss: 0.0028598
[Epoch 48; Iter   671/ 1097] train: loss: 0.0003816
[Epoch 48; Iter   701/ 1097] train: loss: 0.0022356
[Epoch 48; Iter   731/ 1097] train: loss: 0.0177576
[Epoch 48; Iter   761/ 1097] train: loss: 0.0151506
[Epoch 48; Iter   791/ 1097] train: loss: 0.0017182
[Epoch 48; Iter   821/ 1097] train: loss: 0.0054034
[Epoch 44; Iter   769/ 1097] train: loss: 0.0193821
[Epoch 44; Iter   799/ 1097] train: loss: 0.0068606
[Epoch 44; Iter   829/ 1097] train: loss: 0.0231048
[Epoch 44; Iter   859/ 1097] train: loss: 0.0155981
[Epoch 44; Iter   889/ 1097] train: loss: 0.0390645
[Epoch 44; Iter   919/ 1097] train: loss: 0.0081572
[Epoch 44; Iter   949/ 1097] train: loss: 0.0075964
[Epoch 44; Iter   979/ 1097] train: loss: 0.0008721
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1291416
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0018449
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0027351
[Epoch 44] ogbg-molhiv: 0.775788 val loss: 1.163411
[Epoch 44] ogbg-molhiv: 0.686941 test loss: 1.201919
[Epoch 45; Iter     2/ 1097] train: loss: 0.0081011
[Epoch 45; Iter    32/ 1097] train: loss: 0.0556645
[Epoch 45; Iter    62/ 1097] train: loss: 0.0342058
[Epoch 45; Iter    92/ 1097] train: loss: 0.0057036
[Epoch 45; Iter   122/ 1097] train: loss: 0.0138346
[Epoch 45; Iter   152/ 1097] train: loss: 0.0087258
[Epoch 45; Iter   182/ 1097] train: loss: 0.0155525
[Epoch 45; Iter   212/ 1097] train: loss: 0.0187171
[Epoch 45; Iter   242/ 1097] train: loss: 0.0018980
[Epoch 45; Iter   272/ 1097] train: loss: 0.0022511
[Epoch 45; Iter   302/ 1097] train: loss: 0.0002211
[Epoch 45; Iter   332/ 1097] train: loss: 0.0122921
[Epoch 45; Iter   362/ 1097] train: loss: 0.0244550
[Epoch 45; Iter   392/ 1097] train: loss: 0.0028328
[Epoch 45; Iter   422/ 1097] train: loss: 0.0105868
[Epoch 45; Iter   452/ 1097] train: loss: 0.0027822
[Epoch 45; Iter   482/ 1097] train: loss: 0.0862390
[Epoch 45; Iter   512/ 1097] train: loss: 0.0185833
[Epoch 45; Iter   542/ 1097] train: loss: 0.0243944
[Epoch 45; Iter   572/ 1097] train: loss: 0.0073065
[Epoch 45; Iter   602/ 1097] train: loss: 0.0129278
[Epoch 45; Iter   632/ 1097] train: loss: 0.0221295
[Epoch 45; Iter   662/ 1097] train: loss: 0.0129110
[Epoch 45; Iter   692/ 1097] train: loss: 0.0015317
[Epoch 45; Iter   722/ 1097] train: loss: 0.0181969
[Epoch 45; Iter   752/ 1097] train: loss: 0.0034374
[Epoch 45; Iter   782/ 1097] train: loss: 0.0036917
[Epoch 45; Iter   812/ 1097] train: loss: 0.0061003
[Epoch 45; Iter   842/ 1097] train: loss: 0.0256383
[Epoch 45; Iter   872/ 1097] train: loss: 0.0109600
[Epoch 45; Iter   902/ 1097] train: loss: 0.0052541
[Epoch 45; Iter   932/ 1097] train: loss: 0.0010895
[Epoch 45; Iter   962/ 1097] train: loss: 0.0745194
[Epoch 45; Iter   992/ 1097] train: loss: 0.0061388
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0157843
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0346317
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0022272
[Epoch 45] ogbg-molhiv: 0.789260 val loss: 1.622801
[Epoch 45] ogbg-molhiv: 0.691139 test loss: 1.461934
[Epoch 46; Iter    15/ 1097] train: loss: 0.0005486
[Epoch 46; Iter    45/ 1097] train: loss: 0.0177830
[Epoch 46; Iter    75/ 1097] train: loss: 0.0004427
[Epoch 46; Iter   105/ 1097] train: loss: 0.0012436
[Epoch 46; Iter   135/ 1097] train: loss: 0.0081774
[Epoch 46; Iter   165/ 1097] train: loss: 0.0046077
[Epoch 46; Iter   195/ 1097] train: loss: 0.0024900
[Epoch 46; Iter   225/ 1097] train: loss: 0.0345404
[Epoch 46; Iter   255/ 1097] train: loss: 0.0019798
[Epoch 46; Iter   285/ 1097] train: loss: 0.0050190
[Epoch 46; Iter   315/ 1097] train: loss: 0.0063114
[Epoch 46; Iter   345/ 1097] train: loss: 0.0017275
[Epoch 46; Iter   375/ 1097] train: loss: 0.0014579
[Epoch 46; Iter   405/ 1097] train: loss: 0.0950092
[Epoch 46; Iter   435/ 1097] train: loss: 0.0018406
[Epoch 46; Iter   465/ 1097] train: loss: 0.0069377
[Epoch 46; Iter   495/ 1097] train: loss: 0.0107017
[Epoch 46; Iter   525/ 1097] train: loss: 0.0244156
[Epoch 46; Iter   555/ 1097] train: loss: 0.0054861
[Epoch 46; Iter   585/ 1097] train: loss: 0.0005277
[Epoch 46; Iter   615/ 1097] train: loss: 0.0041093
[Epoch 46; Iter   645/ 1097] train: loss: 0.0326644
[Epoch 46; Iter   675/ 1097] train: loss: 0.0119835
[Epoch 46; Iter   705/ 1097] train: loss: 0.0019772
[Epoch 46; Iter   735/ 1097] train: loss: 0.0006890
[Epoch 46; Iter   765/ 1097] train: loss: 0.0031925
[Epoch 46; Iter   795/ 1097] train: loss: 0.0416753
[Epoch 46; Iter   825/ 1097] train: loss: 0.0363027
[Epoch 46; Iter   855/ 1097] train: loss: 0.0071357
[Epoch 46; Iter   885/ 1097] train: loss: 0.0043934
[Epoch 46; Iter   915/ 1097] train: loss: 0.0008837
[Epoch 46; Iter   945/ 1097] train: loss: 0.0009611
[Epoch 46; Iter   975/ 1097] train: loss: 0.0742228
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0044720
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0014705
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0357601
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0021838
[Epoch 46] ogbg-molhiv: 0.787548 val loss: 0.617456
[Epoch 46] ogbg-molhiv: 0.697470 test loss: 0.611881
[Epoch 47; Iter    28/ 1097] train: loss: 0.0243729
[Epoch 47; Iter    58/ 1097] train: loss: 0.0167865
[Epoch 47; Iter    88/ 1097] train: loss: 0.0023426
[Epoch 47; Iter   118/ 1097] train: loss: 0.0032498
[Epoch 47; Iter   148/ 1097] train: loss: 0.0032696
[Epoch 47; Iter   178/ 1097] train: loss: 0.0049062
[Epoch 47; Iter   208/ 1097] train: loss: 0.0228303
[Epoch 47; Iter   238/ 1097] train: loss: 0.0002840
[Epoch 47; Iter   268/ 1097] train: loss: 0.0067928
[Epoch 47; Iter   298/ 1097] train: loss: 0.0045334
[Epoch 47; Iter   328/ 1097] train: loss: 0.0214126
[Epoch 47; Iter   358/ 1097] train: loss: 0.0034935
[Epoch 47; Iter   388/ 1097] train: loss: 0.0012469
[Epoch 47; Iter   418/ 1097] train: loss: 0.0053489
[Epoch 47; Iter   448/ 1097] train: loss: 0.0021957
[Epoch 47; Iter   478/ 1097] train: loss: 0.1464143
[Epoch 47; Iter   508/ 1097] train: loss: 0.0029381
[Epoch 47; Iter   538/ 1097] train: loss: 0.0051109
[Epoch 47; Iter   568/ 1097] train: loss: 0.0233223
[Epoch 47; Iter   598/ 1097] train: loss: 0.0123878
[Epoch 47; Iter   628/ 1097] train: loss: 0.0020381
[Epoch 47; Iter   658/ 1097] train: loss: 0.0038582
[Epoch 47; Iter   688/ 1097] train: loss: 0.0413092
[Epoch 47; Iter   718/ 1097] train: loss: 0.0079011
[Epoch 47; Iter   748/ 1097] train: loss: 0.0015783
[Epoch 47; Iter   778/ 1097] train: loss: 0.0067369
[Epoch 47; Iter   808/ 1097] train: loss: 0.0021944
[Epoch 47; Iter   838/ 1097] train: loss: 0.0015762
[Epoch 47; Iter   868/ 1097] train: loss: 0.0012916
[Epoch 47; Iter   898/ 1097] train: loss: 0.0067029
[Epoch 47; Iter   928/ 1097] train: loss: 0.0155989
[Epoch 47; Iter   958/ 1097] train: loss: 0.0011093
[Epoch 47; Iter   988/ 1097] train: loss: 0.0125742
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0009238
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0044018
[Epoch 47; Iter  1078/ 1097] train: loss: 0.1075268
[Epoch 47] ogbg-molhiv: 0.797888 val loss: 0.627501
[Epoch 47] ogbg-molhiv: 0.700278 test loss: 0.795492
[Epoch 48; Iter    11/ 1097] train: loss: 0.0013174
[Epoch 48; Iter    41/ 1097] train: loss: 0.0059784
[Epoch 48; Iter    71/ 1097] train: loss: 0.0004573
[Epoch 48; Iter   101/ 1097] train: loss: 0.0356253
[Epoch 48; Iter   131/ 1097] train: loss: 0.0021219
[Epoch 48; Iter   161/ 1097] train: loss: 0.0004746
[Epoch 48; Iter   191/ 1097] train: loss: 0.0091614
[Epoch 48; Iter   221/ 1097] train: loss: 0.0017989
[Epoch 48; Iter   251/ 1097] train: loss: 0.0042236
[Epoch 48; Iter   281/ 1097] train: loss: 0.0016826
[Epoch 48; Iter   311/ 1097] train: loss: 0.0018490
[Epoch 48; Iter   341/ 1097] train: loss: 0.0045990
[Epoch 48; Iter   371/ 1097] train: loss: 0.0646126
[Epoch 48; Iter   401/ 1097] train: loss: 0.0032055
[Epoch 48; Iter   431/ 1097] train: loss: 0.0013675
[Epoch 48; Iter   461/ 1097] train: loss: 0.0075483
[Epoch 48; Iter   491/ 1097] train: loss: 0.0012089
[Epoch 48; Iter   521/ 1097] train: loss: 0.0502937
[Epoch 48; Iter   551/ 1097] train: loss: 0.0033340
[Epoch 48; Iter   581/ 1097] train: loss: 0.0094233
[Epoch 48; Iter   611/ 1097] train: loss: 0.0032886
[Epoch 48; Iter   641/ 1097] train: loss: 0.0007690
[Epoch 48; Iter   671/ 1097] train: loss: 0.0137865
[Epoch 48; Iter   701/ 1097] train: loss: 0.0043506
[Epoch 48; Iter   731/ 1097] train: loss: 0.0004267
[Epoch 48; Iter   761/ 1097] train: loss: 0.0234665
[Epoch 48; Iter   791/ 1097] train: loss: 0.0040054
[Epoch 48; Iter   821/ 1097] train: loss: 0.0975162
[Epoch 44; Iter   799/ 1097] train: loss: 0.0037846
[Epoch 44; Iter   829/ 1097] train: loss: 0.2253809
[Epoch 44; Iter   859/ 1097] train: loss: 0.0007240
[Epoch 44; Iter   889/ 1097] train: loss: 0.0004067
[Epoch 44; Iter   919/ 1097] train: loss: 0.0157067
[Epoch 44; Iter   949/ 1097] train: loss: 0.0029672
[Epoch 44; Iter   979/ 1097] train: loss: 0.0004779
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0003953
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0099582
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0006966
[Epoch 44] ogbg-molhiv: 0.717988 val loss: 1.637460
[Epoch 44] ogbg-molhiv: 0.700844 test loss: 0.667946
[Epoch 45; Iter     2/ 1097] train: loss: 0.0044016
[Epoch 45; Iter    32/ 1097] train: loss: 0.0011188
[Epoch 45; Iter    62/ 1097] train: loss: 0.0002545
[Epoch 45; Iter    92/ 1097] train: loss: 0.0292323
[Epoch 45; Iter   122/ 1097] train: loss: 0.0163218
[Epoch 45; Iter   152/ 1097] train: loss: 0.0211293
[Epoch 45; Iter   182/ 1097] train: loss: 0.0046764
[Epoch 45; Iter   212/ 1097] train: loss: 0.0003008
[Epoch 45; Iter   242/ 1097] train: loss: 0.0126012
[Epoch 45; Iter   272/ 1097] train: loss: 0.0048046
[Epoch 45; Iter   302/ 1097] train: loss: 0.0008542
[Epoch 45; Iter   332/ 1097] train: loss: 0.0007455
[Epoch 45; Iter   362/ 1097] train: loss: 0.0006366
[Epoch 45; Iter   392/ 1097] train: loss: 0.0331704
[Epoch 45; Iter   422/ 1097] train: loss: 0.0184474
[Epoch 45; Iter   452/ 1097] train: loss: 0.0197478
[Epoch 45; Iter   482/ 1097] train: loss: 0.0190438
[Epoch 45; Iter   512/ 1097] train: loss: 0.0005288
[Epoch 45; Iter   542/ 1097] train: loss: 0.0028586
[Epoch 45; Iter   572/ 1097] train: loss: 0.0025771
[Epoch 45; Iter   602/ 1097] train: loss: 0.0098442
[Epoch 45; Iter   632/ 1097] train: loss: 0.0009381
[Epoch 45; Iter   662/ 1097] train: loss: 0.0012654
[Epoch 45; Iter   692/ 1097] train: loss: 0.0035557
[Epoch 45; Iter   722/ 1097] train: loss: 0.0004092
[Epoch 45; Iter   752/ 1097] train: loss: 0.0002835
[Epoch 45; Iter   782/ 1097] train: loss: 0.1620450
[Epoch 45; Iter   812/ 1097] train: loss: 0.0041869
[Epoch 45; Iter   842/ 1097] train: loss: 0.0003799
[Epoch 45; Iter   872/ 1097] train: loss: 0.0007702
[Epoch 45; Iter   902/ 1097] train: loss: 0.0037007
[Epoch 45; Iter   932/ 1097] train: loss: 0.0107501
[Epoch 45; Iter   962/ 1097] train: loss: 0.0009380
[Epoch 45; Iter   992/ 1097] train: loss: 0.0011970
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0021000
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0048488
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0203425
[Epoch 45] ogbg-molhiv: 0.695473 val loss: 0.368208
[Epoch 45] ogbg-molhiv: 0.671156 test loss: 0.362008
[Epoch 46; Iter    15/ 1097] train: loss: 0.0133707
[Epoch 46; Iter    45/ 1097] train: loss: 0.0036507
[Epoch 46; Iter    75/ 1097] train: loss: 0.0010574
[Epoch 46; Iter   105/ 1097] train: loss: 0.0046615
[Epoch 46; Iter   135/ 1097] train: loss: 0.0525097
[Epoch 46; Iter   165/ 1097] train: loss: 0.0030544
[Epoch 46; Iter   195/ 1097] train: loss: 0.0034293
[Epoch 46; Iter   225/ 1097] train: loss: 0.0006434
[Epoch 46; Iter   255/ 1097] train: loss: 0.0009419
[Epoch 46; Iter   285/ 1097] train: loss: 0.0226554
[Epoch 46; Iter   315/ 1097] train: loss: 0.0468534
[Epoch 46; Iter   345/ 1097] train: loss: 0.0001717
[Epoch 46; Iter   375/ 1097] train: loss: 0.0033394
[Epoch 46; Iter   405/ 1097] train: loss: 0.0015897
[Epoch 46; Iter   435/ 1097] train: loss: 0.0048348
[Epoch 46; Iter   465/ 1097] train: loss: 0.0008533
[Epoch 46; Iter   495/ 1097] train: loss: 0.0105824
[Epoch 46; Iter   525/ 1097] train: loss: 0.0015718
[Epoch 46; Iter   555/ 1097] train: loss: 0.0015102
[Epoch 46; Iter   585/ 1097] train: loss: 0.0942949
[Epoch 46; Iter   615/ 1097] train: loss: 0.0128039
[Epoch 46; Iter   645/ 1097] train: loss: 0.0018086
[Epoch 46; Iter   675/ 1097] train: loss: 0.0156487
[Epoch 46; Iter   705/ 1097] train: loss: 0.0080209
[Epoch 46; Iter   735/ 1097] train: loss: 0.0038595
[Epoch 46; Iter   765/ 1097] train: loss: 0.0162827
[Epoch 46; Iter   795/ 1097] train: loss: 0.0102081
[Epoch 46; Iter   825/ 1097] train: loss: 0.0001239
[Epoch 46; Iter   855/ 1097] train: loss: 0.0037874
[Epoch 46; Iter   885/ 1097] train: loss: 0.0022649
[Epoch 46; Iter   915/ 1097] train: loss: 0.0019396
[Epoch 46; Iter   945/ 1097] train: loss: 0.0031633
[Epoch 46; Iter   975/ 1097] train: loss: 0.0007287
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0003297
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0178742
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0162908
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0023946
[Epoch 46] ogbg-molhiv: 0.737596 val loss: 1.587645
[Epoch 46] ogbg-molhiv: 0.718772 test loss: 0.950727
[Epoch 47; Iter    28/ 1097] train: loss: 0.0081889
[Epoch 47; Iter    58/ 1097] train: loss: 0.0010693
[Epoch 47; Iter    88/ 1097] train: loss: 0.0153945
[Epoch 47; Iter   118/ 1097] train: loss: 0.0058150
[Epoch 47; Iter   148/ 1097] train: loss: 0.0078383
[Epoch 47; Iter   178/ 1097] train: loss: 0.0029856
[Epoch 47; Iter   208/ 1097] train: loss: 0.0259076
[Epoch 47; Iter   238/ 1097] train: loss: 0.0008654
[Epoch 47; Iter   268/ 1097] train: loss: 0.0038986
[Epoch 47; Iter   298/ 1097] train: loss: 0.0003942
[Epoch 47; Iter   328/ 1097] train: loss: 0.0002022
[Epoch 47; Iter   358/ 1097] train: loss: 0.0013692
[Epoch 47; Iter   388/ 1097] train: loss: 0.1161893
[Epoch 47; Iter   418/ 1097] train: loss: 0.2659999
[Epoch 47; Iter   448/ 1097] train: loss: 0.0029155
[Epoch 47; Iter   478/ 1097] train: loss: 0.0403829
[Epoch 47; Iter   508/ 1097] train: loss: 0.0149453
[Epoch 47; Iter   538/ 1097] train: loss: 0.0128958
[Epoch 47; Iter   568/ 1097] train: loss: 0.0055656
[Epoch 47; Iter   598/ 1097] train: loss: 0.0514735
[Epoch 47; Iter   628/ 1097] train: loss: 0.0026463
[Epoch 47; Iter   658/ 1097] train: loss: 0.0069914
[Epoch 47; Iter   688/ 1097] train: loss: 0.0018629
[Epoch 47; Iter   718/ 1097] train: loss: 0.0001135
[Epoch 47; Iter   748/ 1097] train: loss: 0.0011126
[Epoch 47; Iter   778/ 1097] train: loss: 0.0029723
[Epoch 47; Iter   808/ 1097] train: loss: 0.0020438
[Epoch 47; Iter   838/ 1097] train: loss: 0.0124460
[Epoch 47; Iter   868/ 1097] train: loss: 0.0486435
[Epoch 47; Iter   898/ 1097] train: loss: 0.0515802
[Epoch 47; Iter   928/ 1097] train: loss: 0.0115355
[Epoch 47; Iter   958/ 1097] train: loss: 0.0017114
[Epoch 47; Iter   988/ 1097] train: loss: 0.1404218
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0156961
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0051582
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0054881
[Epoch 47] ogbg-molhiv: 0.655794 val loss: 1.046273
[Epoch 47] ogbg-molhiv: 0.665517 test loss: 0.821152
[Epoch 48; Iter    11/ 1097] train: loss: 0.0035003
[Epoch 48; Iter    41/ 1097] train: loss: 0.0063092
[Epoch 48; Iter    71/ 1097] train: loss: 0.0083109
[Epoch 48; Iter   101/ 1097] train: loss: 0.0010949
[Epoch 48; Iter   131/ 1097] train: loss: 0.0006037
[Epoch 48; Iter   161/ 1097] train: loss: 0.0064525
[Epoch 48; Iter   191/ 1097] train: loss: 0.0012982
[Epoch 48; Iter   221/ 1097] train: loss: 0.0035774
[Epoch 48; Iter   251/ 1097] train: loss: 0.0024468
[Epoch 48; Iter   281/ 1097] train: loss: 0.0035649
[Epoch 48; Iter   311/ 1097] train: loss: 0.0009923
[Epoch 48; Iter   341/ 1097] train: loss: 0.0034950
[Epoch 48; Iter   371/ 1097] train: loss: 0.0002787
[Epoch 48; Iter   401/ 1097] train: loss: 0.0652971
[Epoch 48; Iter   431/ 1097] train: loss: 0.0032981
[Epoch 48; Iter   461/ 1097] train: loss: 0.0039682
[Epoch 48; Iter   491/ 1097] train: loss: 0.0019312
[Epoch 48; Iter   521/ 1097] train: loss: 0.0005443
[Epoch 48; Iter   551/ 1097] train: loss: 0.0021571
[Epoch 48; Iter   581/ 1097] train: loss: 0.0037841
[Epoch 48; Iter   611/ 1097] train: loss: 0.0267728
[Epoch 48; Iter   641/ 1097] train: loss: 0.1127070
[Epoch 48; Iter   671/ 1097] train: loss: 0.0001846
[Epoch 48; Iter   701/ 1097] train: loss: 0.0010029
[Epoch 48; Iter   731/ 1097] train: loss: 0.0190693
[Epoch 48; Iter   761/ 1097] train: loss: 0.0009864
[Epoch 48; Iter   791/ 1097] train: loss: 0.0006641
[Epoch 48; Iter   821/ 1097] train: loss: 0.0001015
[Epoch 48; Iter   851/ 1097] train: loss: 0.0006628
[Epoch 36; Iter   635/ 1097] train: loss: 0.0217665
[Epoch 36; Iter   665/ 1097] train: loss: 0.0390337
[Epoch 36; Iter   695/ 1097] train: loss: 0.2065053
[Epoch 36; Iter   725/ 1097] train: loss: 0.0352590
[Epoch 36; Iter   755/ 1097] train: loss: 0.1904805
[Epoch 36; Iter   785/ 1097] train: loss: 0.0220569
[Epoch 36; Iter   815/ 1097] train: loss: 0.0723818
[Epoch 36; Iter   845/ 1097] train: loss: 0.0221792
[Epoch 36; Iter   875/ 1097] train: loss: 0.0256778
[Epoch 36; Iter   905/ 1097] train: loss: 0.0169421
[Epoch 36; Iter   935/ 1097] train: loss: 0.1959257
[Epoch 36; Iter   965/ 1097] train: loss: 0.0478342
[Epoch 36; Iter   995/ 1097] train: loss: 0.0406963
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0322565
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1128950
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0263787
[Epoch 36] ogbg-molhiv: 0.794701 val loss: 0.081623
[Epoch 36] ogbg-molhiv: 0.745345 test loss: 0.126671
[Epoch 37; Iter    18/ 1097] train: loss: 0.0865573
[Epoch 37; Iter    48/ 1097] train: loss: 0.0340831
[Epoch 37; Iter    78/ 1097] train: loss: 0.0252285
[Epoch 37; Iter   108/ 1097] train: loss: 0.0749365
[Epoch 37; Iter   138/ 1097] train: loss: 0.0421695
[Epoch 37; Iter   168/ 1097] train: loss: 0.0708986
[Epoch 37; Iter   198/ 1097] train: loss: 0.2788543
[Epoch 37; Iter   228/ 1097] train: loss: 0.0298963
[Epoch 37; Iter   258/ 1097] train: loss: 0.0201673
[Epoch 37; Iter   288/ 1097] train: loss: 0.1133720
[Epoch 37; Iter   318/ 1097] train: loss: 0.0342305
[Epoch 37; Iter   348/ 1097] train: loss: 0.1497628
[Epoch 37; Iter   378/ 1097] train: loss: 0.0418878
[Epoch 37; Iter   408/ 1097] train: loss: 0.0216068
[Epoch 37; Iter   438/ 1097] train: loss: 0.0203471
[Epoch 37; Iter   468/ 1097] train: loss: 0.0753089
[Epoch 37; Iter   498/ 1097] train: loss: 0.1612180
[Epoch 37; Iter   528/ 1097] train: loss: 0.0977396
[Epoch 37; Iter   558/ 1097] train: loss: 0.0136488
[Epoch 37; Iter   588/ 1097] train: loss: 0.1443816
[Epoch 37; Iter   618/ 1097] train: loss: 0.0719000
[Epoch 37; Iter   648/ 1097] train: loss: 0.1028309
[Epoch 37; Iter   678/ 1097] train: loss: 0.1725114
[Epoch 37; Iter   708/ 1097] train: loss: 0.0148801
[Epoch 37; Iter   738/ 1097] train: loss: 0.0382701
[Epoch 37; Iter   768/ 1097] train: loss: 0.0161041
[Epoch 37; Iter   798/ 1097] train: loss: 0.2251067
[Epoch 37; Iter   828/ 1097] train: loss: 0.0260476
[Epoch 37; Iter   858/ 1097] train: loss: 0.0264517
[Epoch 37; Iter   888/ 1097] train: loss: 0.0605094
[Epoch 37; Iter   918/ 1097] train: loss: 0.0695951
[Epoch 37; Iter   948/ 1097] train: loss: 0.0153348
[Epoch 37; Iter   978/ 1097] train: loss: 0.1107963
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0115396
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0621472
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0651927
[Epoch 37] ogbg-molhiv: 0.804037 val loss: 0.084916
[Epoch 37] ogbg-molhiv: 0.774747 test loss: 0.147339
[Epoch 38; Iter     1/ 1097] train: loss: 0.1950727
[Epoch 38; Iter    31/ 1097] train: loss: 0.0205282
[Epoch 38; Iter    61/ 1097] train: loss: 0.0639279
[Epoch 38; Iter    91/ 1097] train: loss: 0.0154131
[Epoch 38; Iter   121/ 1097] train: loss: 0.1664238
[Epoch 38; Iter   151/ 1097] train: loss: 0.0213836
[Epoch 38; Iter   181/ 1097] train: loss: 0.1515092
[Epoch 38; Iter   211/ 1097] train: loss: 0.0394858
[Epoch 38; Iter   241/ 1097] train: loss: 0.1178740
[Epoch 38; Iter   271/ 1097] train: loss: 0.0883697
[Epoch 38; Iter   301/ 1097] train: loss: 0.1257894
[Epoch 38; Iter   331/ 1097] train: loss: 0.2011155
[Epoch 38; Iter   361/ 1097] train: loss: 0.2478502
[Epoch 38; Iter   391/ 1097] train: loss: 0.0137955
[Epoch 38; Iter   421/ 1097] train: loss: 0.0659356
[Epoch 38; Iter   451/ 1097] train: loss: 0.1387076
[Epoch 38; Iter   481/ 1097] train: loss: 0.1914490
[Epoch 38; Iter   511/ 1097] train: loss: 0.0726221
[Epoch 38; Iter   541/ 1097] train: loss: 0.0142872
[Epoch 38; Iter   571/ 1097] train: loss: 0.0233556
[Epoch 38; Iter   601/ 1097] train: loss: 0.1482897
[Epoch 38; Iter   631/ 1097] train: loss: 0.0293833
[Epoch 38; Iter   661/ 1097] train: loss: 0.0229399
[Epoch 38; Iter   691/ 1097] train: loss: 0.0485746
[Epoch 38; Iter   721/ 1097] train: loss: 0.0605561
[Epoch 38; Iter   751/ 1097] train: loss: 0.1220658
[Epoch 38; Iter   781/ 1097] train: loss: 0.1730061
[Epoch 38; Iter   811/ 1097] train: loss: 0.2516562
[Epoch 38; Iter   841/ 1097] train: loss: 0.0407773
[Epoch 38; Iter   871/ 1097] train: loss: 0.1916854
[Epoch 38; Iter   901/ 1097] train: loss: 0.0584458
[Epoch 38; Iter   931/ 1097] train: loss: 0.0149641
[Epoch 38; Iter   961/ 1097] train: loss: 0.0186588
[Epoch 38; Iter   991/ 1097] train: loss: 0.0226452
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0147686
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0305153
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0347017
[Epoch 38] ogbg-molhiv: 0.786348 val loss: 0.107226
[Epoch 38] ogbg-molhiv: 0.740256 test loss: 0.129351
[Epoch 39; Iter    14/ 1097] train: loss: 0.0196770
[Epoch 39; Iter    44/ 1097] train: loss: 0.2060869
[Epoch 39; Iter    74/ 1097] train: loss: 0.2365381
[Epoch 39; Iter   104/ 1097] train: loss: 0.0633461
[Epoch 39; Iter   134/ 1097] train: loss: 0.0288575
[Epoch 39; Iter   164/ 1097] train: loss: 0.0714422
[Epoch 39; Iter   194/ 1097] train: loss: 0.0892286
[Epoch 39; Iter   224/ 1097] train: loss: 0.0188015
[Epoch 39; Iter   254/ 1097] train: loss: 0.0195136
[Epoch 39; Iter   284/ 1097] train: loss: 0.1692029
[Epoch 39; Iter   314/ 1097] train: loss: 0.0204155
[Epoch 39; Iter   344/ 1097] train: loss: 0.0145778
[Epoch 39; Iter   374/ 1097] train: loss: 0.0633389
[Epoch 39; Iter   404/ 1097] train: loss: 0.0230239
[Epoch 39; Iter   434/ 1097] train: loss: 0.0724463
[Epoch 39; Iter   464/ 1097] train: loss: 0.0467968
[Epoch 39; Iter   494/ 1097] train: loss: 0.0233893
[Epoch 39; Iter   524/ 1097] train: loss: 0.0912528
[Epoch 39; Iter   554/ 1097] train: loss: 0.0515081
[Epoch 39; Iter   584/ 1097] train: loss: 0.0219372
[Epoch 39; Iter   614/ 1097] train: loss: 0.3167893
[Epoch 39; Iter   644/ 1097] train: loss: 0.0832172
[Epoch 39; Iter   674/ 1097] train: loss: 0.0423299
[Epoch 39; Iter   704/ 1097] train: loss: 0.1241008
[Epoch 39; Iter   734/ 1097] train: loss: 0.0279870
[Epoch 39; Iter   764/ 1097] train: loss: 0.0194915
[Epoch 39; Iter   794/ 1097] train: loss: 0.0131453
[Epoch 39; Iter   824/ 1097] train: loss: 0.0200289
[Epoch 39; Iter   854/ 1097] train: loss: 0.1206635
[Epoch 39; Iter   884/ 1097] train: loss: 0.0151772
[Epoch 39; Iter   914/ 1097] train: loss: 0.1750763
[Epoch 39; Iter   944/ 1097] train: loss: 0.1077039
[Epoch 39; Iter   974/ 1097] train: loss: 0.0958341
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0236697
[Epoch 39; Iter  1034/ 1097] train: loss: 0.1108683
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0371110
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0654218
[Epoch 39] ogbg-molhiv: 0.803127 val loss: 0.164868
[Epoch 39] ogbg-molhiv: 0.758698 test loss: 0.249691
[Epoch 40; Iter    27/ 1097] train: loss: 0.1013294
[Epoch 40; Iter    57/ 1097] train: loss: 0.1805120
[Epoch 40; Iter    87/ 1097] train: loss: 0.2217016
[Epoch 40; Iter   117/ 1097] train: loss: 0.0152559
[Epoch 40; Iter   147/ 1097] train: loss: 0.0368441
[Epoch 40; Iter   177/ 1097] train: loss: 0.0603476
[Epoch 40; Iter   207/ 1097] train: loss: 0.2330886
[Epoch 40; Iter   237/ 1097] train: loss: 0.0686848
[Epoch 40; Iter   267/ 1097] train: loss: 0.1246214
[Epoch 40; Iter   297/ 1097] train: loss: 0.2177535
[Epoch 40; Iter   327/ 1097] train: loss: 0.2781167
[Epoch 40; Iter   357/ 1097] train: loss: 0.0377812
[Epoch 40; Iter   387/ 1097] train: loss: 0.0208070
[Epoch 40; Iter   417/ 1097] train: loss: 0.1923930
[Epoch 40; Iter   447/ 1097] train: loss: 0.0187770
[Epoch 40; Iter   477/ 1097] train: loss: 0.1988180
[Epoch 40; Iter   507/ 1097] train: loss: 0.0176383
[Epoch 40; Iter   537/ 1097] train: loss: 0.0736141
[Epoch 40; Iter   567/ 1097] train: loss: 0.0551032
[Epoch 40; Iter   597/ 1097] train: loss: 0.0238992
[Epoch 40; Iter   627/ 1097] train: loss: 0.0646004
[Epoch 40; Iter   657/ 1097] train: loss: 0.1580459
[Epoch 40; Iter   687/ 1097] train: loss: 0.0682096
[Epoch 44; Iter   799/ 1097] train: loss: 0.0009874
[Epoch 44; Iter   829/ 1097] train: loss: 0.0040424
[Epoch 44; Iter   859/ 1097] train: loss: 0.0154450
[Epoch 44; Iter   889/ 1097] train: loss: 0.0020913
[Epoch 44; Iter   919/ 1097] train: loss: 0.0072280
[Epoch 44; Iter   949/ 1097] train: loss: 0.0140701
[Epoch 44; Iter   979/ 1097] train: loss: 0.0019517
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1654709
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0024090
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0183865
[Epoch 44] ogbg-molhiv: 0.771201 val loss: 0.182828
[Epoch 44] ogbg-molhiv: 0.725611 test loss: 0.309602
[Epoch 45; Iter     2/ 1097] train: loss: 0.0206312
[Epoch 45; Iter    32/ 1097] train: loss: 0.0003571
[Epoch 45; Iter    62/ 1097] train: loss: 0.0012958
[Epoch 45; Iter    92/ 1097] train: loss: 0.0039399
[Epoch 45; Iter   122/ 1097] train: loss: 0.0034842
[Epoch 45; Iter   152/ 1097] train: loss: 0.0307981
[Epoch 45; Iter   182/ 1097] train: loss: 0.0046431
[Epoch 45; Iter   212/ 1097] train: loss: 0.1024897
[Epoch 45; Iter   242/ 1097] train: loss: 0.0114866
[Epoch 45; Iter   272/ 1097] train: loss: 0.0021668
[Epoch 45; Iter   302/ 1097] train: loss: 0.0045885
[Epoch 45; Iter   332/ 1097] train: loss: 0.0312378
[Epoch 45; Iter   362/ 1097] train: loss: 0.1215236
[Epoch 45; Iter   392/ 1097] train: loss: 0.0130219
[Epoch 45; Iter   422/ 1097] train: loss: 0.0218806
[Epoch 45; Iter   452/ 1097] train: loss: 0.0014385
[Epoch 45; Iter   482/ 1097] train: loss: 0.0018606
[Epoch 45; Iter   512/ 1097] train: loss: 0.0001178
[Epoch 45; Iter   542/ 1097] train: loss: 0.0101264
[Epoch 45; Iter   572/ 1097] train: loss: 0.0107503
[Epoch 45; Iter   602/ 1097] train: loss: 0.0886687
[Epoch 45; Iter   632/ 1097] train: loss: 0.0239911
[Epoch 45; Iter   662/ 1097] train: loss: 0.0053768
[Epoch 45; Iter   692/ 1097] train: loss: 0.0064186
[Epoch 45; Iter   722/ 1097] train: loss: 0.1935839
[Epoch 45; Iter   752/ 1097] train: loss: 0.0194665
[Epoch 45; Iter   782/ 1097] train: loss: 0.0178887
[Epoch 45; Iter   812/ 1097] train: loss: 0.0042127
[Epoch 45; Iter   842/ 1097] train: loss: 0.0378359
[Epoch 45; Iter   872/ 1097] train: loss: 0.0117524
[Epoch 45; Iter   902/ 1097] train: loss: 0.0006711
[Epoch 45; Iter   932/ 1097] train: loss: 0.0041799
[Epoch 45; Iter   962/ 1097] train: loss: 0.0183772
[Epoch 45; Iter   992/ 1097] train: loss: 0.0121682
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0078167
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0162889
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0022146
[Epoch 45] ogbg-molhiv: 0.754960 val loss: 0.181059
[Epoch 45] ogbg-molhiv: 0.721748 test loss: 0.265482
[Epoch 46; Iter    15/ 1097] train: loss: 0.0011209
[Epoch 46; Iter    45/ 1097] train: loss: 0.0055185
[Epoch 46; Iter    75/ 1097] train: loss: 0.0004416
[Epoch 46; Iter   105/ 1097] train: loss: 0.0038377
[Epoch 46; Iter   135/ 1097] train: loss: 0.0005044
[Epoch 46; Iter   165/ 1097] train: loss: 0.0204592
[Epoch 46; Iter   195/ 1097] train: loss: 0.0249907
[Epoch 46; Iter   225/ 1097] train: loss: 0.0011371
[Epoch 46; Iter   255/ 1097] train: loss: 0.0064000
[Epoch 46; Iter   285/ 1097] train: loss: 0.0051970
[Epoch 46; Iter   315/ 1097] train: loss: 0.0010808
[Epoch 46; Iter   345/ 1097] train: loss: 0.0017062
[Epoch 46; Iter   375/ 1097] train: loss: 0.0012768
[Epoch 46; Iter   405/ 1097] train: loss: 0.0014703
[Epoch 46; Iter   435/ 1097] train: loss: 0.0009858
[Epoch 46; Iter   465/ 1097] train: loss: 0.0009724
[Epoch 46; Iter   495/ 1097] train: loss: 0.0075331
[Epoch 46; Iter   525/ 1097] train: loss: 0.0068222
[Epoch 46; Iter   555/ 1097] train: loss: 0.0265325
[Epoch 46; Iter   585/ 1097] train: loss: 0.0018393
[Epoch 46; Iter   615/ 1097] train: loss: 0.0020146
[Epoch 46; Iter   645/ 1097] train: loss: 0.0067104
[Epoch 46; Iter   675/ 1097] train: loss: 0.0034041
[Epoch 46; Iter   705/ 1097] train: loss: 0.0022259
[Epoch 46; Iter   735/ 1097] train: loss: 0.0041611
[Epoch 46; Iter   765/ 1097] train: loss: 0.0274974
[Epoch 46; Iter   795/ 1097] train: loss: 0.0188215
[Epoch 46; Iter   825/ 1097] train: loss: 0.0013956
[Epoch 46; Iter   855/ 1097] train: loss: 0.0010641
[Epoch 46; Iter   885/ 1097] train: loss: 0.0004209
[Epoch 46; Iter   915/ 1097] train: loss: 0.0025873
[Epoch 46; Iter   945/ 1097] train: loss: 0.0002485
[Epoch 46; Iter   975/ 1097] train: loss: 0.0151603
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0269528
[Epoch 46; Iter  1035/ 1097] train: loss: 0.1016043
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0099963
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0189872
[Epoch 46] ogbg-molhiv: 0.757033 val loss: 0.680159
[Epoch 46] ogbg-molhiv: 0.722882 test loss: 1.163711
[Epoch 47; Iter    28/ 1097] train: loss: 0.0340697
[Epoch 47; Iter    58/ 1097] train: loss: 0.0093885
[Epoch 47; Iter    88/ 1097] train: loss: 0.0348026
[Epoch 47; Iter   118/ 1097] train: loss: 0.0045459
[Epoch 47; Iter   148/ 1097] train: loss: 0.0024022
[Epoch 47; Iter   178/ 1097] train: loss: 0.0152892
[Epoch 47; Iter   208/ 1097] train: loss: 0.0024515
[Epoch 47; Iter   238/ 1097] train: loss: 0.0010006
[Epoch 47; Iter   268/ 1097] train: loss: 0.0304522
[Epoch 47; Iter   298/ 1097] train: loss: 0.0033310
[Epoch 47; Iter   328/ 1097] train: loss: 0.0051421
[Epoch 47; Iter   358/ 1097] train: loss: 0.0987521
[Epoch 47; Iter   388/ 1097] train: loss: 0.0287643
[Epoch 47; Iter   418/ 1097] train: loss: 0.0046307
[Epoch 47; Iter   448/ 1097] train: loss: 0.0007632
[Epoch 47; Iter   478/ 1097] train: loss: 0.0117525
[Epoch 47; Iter   508/ 1097] train: loss: 0.0170987
[Epoch 47; Iter   538/ 1097] train: loss: 0.0027564
[Epoch 47; Iter   568/ 1097] train: loss: 0.0006092
[Epoch 47; Iter   598/ 1097] train: loss: 0.0005858
[Epoch 47; Iter   628/ 1097] train: loss: 0.0011139
[Epoch 47; Iter   658/ 1097] train: loss: 0.0013420
[Epoch 47; Iter   688/ 1097] train: loss: 0.0058314
[Epoch 47; Iter   718/ 1097] train: loss: 0.0039805
[Epoch 47; Iter   748/ 1097] train: loss: 0.0012295
[Epoch 47; Iter   778/ 1097] train: loss: 0.0105925
[Epoch 47; Iter   808/ 1097] train: loss: 0.0008469
[Epoch 47; Iter   838/ 1097] train: loss: 0.0014379
[Epoch 47; Iter   868/ 1097] train: loss: 0.0264825
[Epoch 47; Iter   898/ 1097] train: loss: 0.0013381
[Epoch 47; Iter   928/ 1097] train: loss: 0.0006346
[Epoch 47; Iter   958/ 1097] train: loss: 0.0038572
[Epoch 47; Iter   988/ 1097] train: loss: 0.0019959
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0183389
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0008193
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0039508
[Epoch 47] ogbg-molhiv: 0.784891 val loss: 2.276523
[Epoch 47] ogbg-molhiv: 0.735516 test loss: 4.189488
[Epoch 48; Iter    11/ 1097] train: loss: 0.0081085
[Epoch 48; Iter    41/ 1097] train: loss: 0.0024411
[Epoch 48; Iter    71/ 1097] train: loss: 0.0022807
[Epoch 48; Iter   101/ 1097] train: loss: 0.0016591
[Epoch 48; Iter   131/ 1097] train: loss: 0.0192240
[Epoch 48; Iter   161/ 1097] train: loss: 0.0011690
[Epoch 48; Iter   191/ 1097] train: loss: 0.0003291
[Epoch 48; Iter   221/ 1097] train: loss: 0.0030745
[Epoch 48; Iter   251/ 1097] train: loss: 0.0185177
[Epoch 48; Iter   281/ 1097] train: loss: 0.0032619
[Epoch 48; Iter   311/ 1097] train: loss: 0.0024330
[Epoch 48; Iter   341/ 1097] train: loss: 0.0018783
[Epoch 48; Iter   371/ 1097] train: loss: 0.0105346
[Epoch 48; Iter   401/ 1097] train: loss: 0.0015730
[Epoch 48; Iter   431/ 1097] train: loss: 0.0002500
[Epoch 48; Iter   461/ 1097] train: loss: 0.0180416
[Epoch 48; Iter   491/ 1097] train: loss: 0.0023464
[Epoch 48; Iter   521/ 1097] train: loss: 0.0025506
[Epoch 48; Iter   551/ 1097] train: loss: 0.0077264
[Epoch 48; Iter   581/ 1097] train: loss: 0.0071958
[Epoch 48; Iter   611/ 1097] train: loss: 0.0005905
[Epoch 48; Iter   641/ 1097] train: loss: 0.0012516
[Epoch 48; Iter   671/ 1097] train: loss: 0.0010511
[Epoch 48; Iter   701/ 1097] train: loss: 0.0003188
[Epoch 48; Iter   731/ 1097] train: loss: 0.0048143
[Epoch 48; Iter   761/ 1097] train: loss: 0.0088191
[Epoch 48; Iter   791/ 1097] train: loss: 0.0036082
[Epoch 48; Iter   821/ 1097] train: loss: 0.0028777
[Epoch 48; Iter   851/ 1097] train: loss: 0.0024069
[Epoch 36; Iter   635/ 1097] train: loss: 0.0218368
[Epoch 36; Iter   665/ 1097] train: loss: 0.0890739
[Epoch 36; Iter   695/ 1097] train: loss: 0.3547428
[Epoch 36; Iter   725/ 1097] train: loss: 0.0331863
[Epoch 36; Iter   755/ 1097] train: loss: 0.0173232
[Epoch 36; Iter   785/ 1097] train: loss: 0.0150493
[Epoch 36; Iter   815/ 1097] train: loss: 0.0133686
[Epoch 36; Iter   845/ 1097] train: loss: 0.0234181
[Epoch 36; Iter   875/ 1097] train: loss: 0.0213639
[Epoch 36; Iter   905/ 1097] train: loss: 0.1206979
[Epoch 36; Iter   935/ 1097] train: loss: 0.1735412
[Epoch 36; Iter   965/ 1097] train: loss: 0.0308910
[Epoch 36; Iter   995/ 1097] train: loss: 0.0218011
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0391813
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1563357
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1835256
[Epoch 36] ogbg-molhiv: 0.813272 val loss: 0.102222
[Epoch 36] ogbg-molhiv: 0.757268 test loss: 0.456739
[Epoch 37; Iter    18/ 1097] train: loss: 0.0336496
[Epoch 37; Iter    48/ 1097] train: loss: 0.0119731
[Epoch 37; Iter    78/ 1097] train: loss: 0.0450694
[Epoch 37; Iter   108/ 1097] train: loss: 0.0200999
[Epoch 37; Iter   138/ 1097] train: loss: 0.1377966
[Epoch 37; Iter   168/ 1097] train: loss: 0.0567208
[Epoch 37; Iter   198/ 1097] train: loss: 0.0168021
[Epoch 37; Iter   228/ 1097] train: loss: 0.0173442
[Epoch 37; Iter   258/ 1097] train: loss: 0.0637577
[Epoch 37; Iter   288/ 1097] train: loss: 0.0102035
[Epoch 37; Iter   318/ 1097] train: loss: 0.0128013
[Epoch 37; Iter   348/ 1097] train: loss: 0.0094413
[Epoch 37; Iter   378/ 1097] train: loss: 0.1841141
[Epoch 37; Iter   408/ 1097] train: loss: 0.1467428
[Epoch 37; Iter   438/ 1097] train: loss: 0.0641608
[Epoch 37; Iter   468/ 1097] train: loss: 0.0160017
[Epoch 37; Iter   498/ 1097] train: loss: 0.0450300
[Epoch 37; Iter   528/ 1097] train: loss: 0.0201316
[Epoch 37; Iter   558/ 1097] train: loss: 0.0685339
[Epoch 37; Iter   588/ 1097] train: loss: 0.0365913
[Epoch 37; Iter   618/ 1097] train: loss: 0.1583209
[Epoch 37; Iter   648/ 1097] train: loss: 0.0374885
[Epoch 37; Iter   678/ 1097] train: loss: 0.0898061
[Epoch 37; Iter   708/ 1097] train: loss: 0.0235196
[Epoch 37; Iter   738/ 1097] train: loss: 0.0109618
[Epoch 37; Iter   768/ 1097] train: loss: 0.0709190
[Epoch 37; Iter   798/ 1097] train: loss: 0.1166238
[Epoch 37; Iter   828/ 1097] train: loss: 0.0123999
[Epoch 37; Iter   858/ 1097] train: loss: 0.0185759
[Epoch 37; Iter   888/ 1097] train: loss: 0.0142703
[Epoch 37; Iter   918/ 1097] train: loss: 0.2161033
[Epoch 37; Iter   948/ 1097] train: loss: 0.0433166
[Epoch 37; Iter   978/ 1097] train: loss: 0.2032759
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0135489
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0181038
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0684910
[Epoch 37] ogbg-molhiv: 0.798532 val loss: 0.314466
[Epoch 37] ogbg-molhiv: 0.753628 test loss: 0.776911
[Epoch 38; Iter     1/ 1097] train: loss: 0.0361938
[Epoch 38; Iter    31/ 1097] train: loss: 0.0075873
[Epoch 38; Iter    61/ 1097] train: loss: 0.2260159
[Epoch 38; Iter    91/ 1097] train: loss: 0.1517890
[Epoch 38; Iter   121/ 1097] train: loss: 0.0100514
[Epoch 38; Iter   151/ 1097] train: loss: 0.0131588
[Epoch 38; Iter   181/ 1097] train: loss: 0.0648134
[Epoch 38; Iter   211/ 1097] train: loss: 0.0129045
[Epoch 38; Iter   241/ 1097] train: loss: 0.1141055
[Epoch 38; Iter   271/ 1097] train: loss: 0.0161827
[Epoch 38; Iter   301/ 1097] train: loss: 0.2324508
[Epoch 38; Iter   331/ 1097] train: loss: 0.2194939
[Epoch 38; Iter   361/ 1097] train: loss: 0.0190431
[Epoch 38; Iter   391/ 1097] train: loss: 0.0210684
[Epoch 38; Iter   421/ 1097] train: loss: 0.0958697
[Epoch 38; Iter   451/ 1097] train: loss: 0.0268323
[Epoch 38; Iter   481/ 1097] train: loss: 0.0565764
[Epoch 38; Iter   511/ 1097] train: loss: 0.0847661
[Epoch 38; Iter   541/ 1097] train: loss: 0.0501563
[Epoch 38; Iter   571/ 1097] train: loss: 0.0220618
[Epoch 38; Iter   601/ 1097] train: loss: 0.2267798
[Epoch 38; Iter   631/ 1097] train: loss: 0.1995584
[Epoch 38; Iter   661/ 1097] train: loss: 0.0365516
[Epoch 38; Iter   691/ 1097] train: loss: 0.0678437
[Epoch 38; Iter   721/ 1097] train: loss: 0.1566347
[Epoch 38; Iter   751/ 1097] train: loss: 0.0243820
[Epoch 38; Iter   781/ 1097] train: loss: 0.1482550
[Epoch 38; Iter   811/ 1097] train: loss: 0.1149666
[Epoch 38; Iter   841/ 1097] train: loss: 0.1558592
[Epoch 38; Iter   871/ 1097] train: loss: 0.0265877
[Epoch 38; Iter   901/ 1097] train: loss: 0.0190616
[Epoch 38; Iter   931/ 1097] train: loss: 0.0606164
[Epoch 38; Iter   961/ 1097] train: loss: 0.0171384
[Epoch 38; Iter   991/ 1097] train: loss: 0.0276866
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0237942
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0309581
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0308407
[Epoch 38] ogbg-molhiv: 0.815942 val loss: 0.081258
[Epoch 38] ogbg-molhiv: 0.768555 test loss: 0.283499
[Epoch 39; Iter    14/ 1097] train: loss: 0.1688989
[Epoch 39; Iter    44/ 1097] train: loss: 0.2829925
[Epoch 39; Iter    74/ 1097] train: loss: 0.0373922
[Epoch 39; Iter   104/ 1097] train: loss: 0.0212329
[Epoch 39; Iter   134/ 1097] train: loss: 0.0158862
[Epoch 39; Iter   164/ 1097] train: loss: 0.2390833
[Epoch 39; Iter   194/ 1097] train: loss: 0.0193651
[Epoch 39; Iter   224/ 1097] train: loss: 0.0302463
[Epoch 39; Iter   254/ 1097] train: loss: 0.0840529
[Epoch 39; Iter   284/ 1097] train: loss: 0.0366496
[Epoch 39; Iter   314/ 1097] train: loss: 0.0921090
[Epoch 39; Iter   344/ 1097] train: loss: 0.0666263
[Epoch 39; Iter   374/ 1097] train: loss: 0.0082963
[Epoch 39; Iter   404/ 1097] train: loss: 0.1289169
[Epoch 39; Iter   434/ 1097] train: loss: 0.0100059
[Epoch 39; Iter   464/ 1097] train: loss: 0.1283828
[Epoch 39; Iter   494/ 1097] train: loss: 0.0637188
[Epoch 39; Iter   524/ 1097] train: loss: 0.0243782
[Epoch 39; Iter   554/ 1097] train: loss: 0.0409865
[Epoch 39; Iter   584/ 1097] train: loss: 0.0251677
[Epoch 39; Iter   614/ 1097] train: loss: 0.0597832
[Epoch 39; Iter   644/ 1097] train: loss: 0.0617745
[Epoch 39; Iter   674/ 1097] train: loss: 0.0697534
[Epoch 39; Iter   704/ 1097] train: loss: 0.1486835
[Epoch 39; Iter   734/ 1097] train: loss: 0.0109186
[Epoch 39; Iter   764/ 1097] train: loss: 0.2037873
[Epoch 39; Iter   794/ 1097] train: loss: 0.0816992
[Epoch 39; Iter   824/ 1097] train: loss: 0.1395824
[Epoch 39; Iter   854/ 1097] train: loss: 0.0493403
[Epoch 39; Iter   884/ 1097] train: loss: 0.0196614
[Epoch 39; Iter   914/ 1097] train: loss: 0.0470641
[Epoch 39; Iter   944/ 1097] train: loss: 0.0490162
[Epoch 39; Iter   974/ 1097] train: loss: 0.0540188
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0470870
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0203458
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0138430
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1330855
[Epoch 39] ogbg-molhiv: 0.806128 val loss: 0.102226
[Epoch 39] ogbg-molhiv: 0.755389 test loss: 0.369137
[Epoch 40; Iter    27/ 1097] train: loss: 0.1781709
[Epoch 40; Iter    57/ 1097] train: loss: 0.0349325
[Epoch 40; Iter    87/ 1097] train: loss: 0.0466141
[Epoch 40; Iter   117/ 1097] train: loss: 0.1962736
[Epoch 40; Iter   147/ 1097] train: loss: 0.0435533
[Epoch 40; Iter   177/ 1097] train: loss: 0.0228261
[Epoch 40; Iter   207/ 1097] train: loss: 0.1096773
[Epoch 40; Iter   237/ 1097] train: loss: 0.0405720
[Epoch 40; Iter   267/ 1097] train: loss: 0.2528639
[Epoch 40; Iter   297/ 1097] train: loss: 0.0998236
[Epoch 40; Iter   327/ 1097] train: loss: 0.0504341
[Epoch 40; Iter   357/ 1097] train: loss: 0.2022885
[Epoch 40; Iter   387/ 1097] train: loss: 0.0995839
[Epoch 40; Iter   417/ 1097] train: loss: 0.1011667
[Epoch 40; Iter   447/ 1097] train: loss: 0.1580512
[Epoch 40; Iter   477/ 1097] train: loss: 0.0132671
[Epoch 40; Iter   507/ 1097] train: loss: 0.1018704
[Epoch 40; Iter   537/ 1097] train: loss: 0.0745772
[Epoch 40; Iter   567/ 1097] train: loss: 0.0244401
[Epoch 40; Iter   597/ 1097] train: loss: 0.0356005
[Epoch 40; Iter   627/ 1097] train: loss: 0.0111648
[Epoch 40; Iter   657/ 1097] train: loss: 0.0961781
[Epoch 40; Iter   687/ 1097] train: loss: 0.0265341
[Epoch 44; Iter   799/ 1097] train: loss: 0.0029922
[Epoch 44; Iter   829/ 1097] train: loss: 0.0048227
[Epoch 44; Iter   859/ 1097] train: loss: 0.0004186
[Epoch 44; Iter   889/ 1097] train: loss: 0.0014243
[Epoch 44; Iter   919/ 1097] train: loss: 0.0011152
[Epoch 44; Iter   949/ 1097] train: loss: 0.0044789
[Epoch 44; Iter   979/ 1097] train: loss: 0.0136440
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0004652
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0014746
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0019136
[Epoch 44] ogbg-molhiv: 0.706854 val loss: 0.201158
[Epoch 44] ogbg-molhiv: 0.748392 test loss: 0.266786
[Epoch 45; Iter     2/ 1097] train: loss: 0.0009205
[Epoch 45; Iter    32/ 1097] train: loss: 0.0016044
[Epoch 45; Iter    62/ 1097] train: loss: 0.0051473
[Epoch 45; Iter    92/ 1097] train: loss: 0.0062070
[Epoch 45; Iter   122/ 1097] train: loss: 0.0503200
[Epoch 45; Iter   152/ 1097] train: loss: 0.0113556
[Epoch 45; Iter   182/ 1097] train: loss: 0.0167218
[Epoch 45; Iter   212/ 1097] train: loss: 0.0020639
[Epoch 45; Iter   242/ 1097] train: loss: 0.0107411
[Epoch 45; Iter   272/ 1097] train: loss: 0.0049849
[Epoch 45; Iter   302/ 1097] train: loss: 0.0110454
[Epoch 45; Iter   332/ 1097] train: loss: 0.0017599
[Epoch 45; Iter   362/ 1097] train: loss: 0.0131379
[Epoch 45; Iter   392/ 1097] train: loss: 0.0900813
[Epoch 45; Iter   422/ 1097] train: loss: 0.0758859
[Epoch 45; Iter   452/ 1097] train: loss: 0.0148361
[Epoch 45; Iter   482/ 1097] train: loss: 0.0778066
[Epoch 45; Iter   512/ 1097] train: loss: 0.0011745
[Epoch 45; Iter   542/ 1097] train: loss: 0.0003608
[Epoch 45; Iter   572/ 1097] train: loss: 0.0125068
[Epoch 45; Iter   602/ 1097] train: loss: 0.0061405
[Epoch 45; Iter   632/ 1097] train: loss: 0.0034672
[Epoch 45; Iter   662/ 1097] train: loss: 0.0010474
[Epoch 45; Iter   692/ 1097] train: loss: 0.0077997
[Epoch 45; Iter   722/ 1097] train: loss: 0.0851989
[Epoch 45; Iter   752/ 1097] train: loss: 0.0036136
[Epoch 45; Iter   782/ 1097] train: loss: 0.0036642
[Epoch 45; Iter   812/ 1097] train: loss: 0.0044590
[Epoch 45; Iter   842/ 1097] train: loss: 0.0091356
[Epoch 45; Iter   872/ 1097] train: loss: 0.0016434
[Epoch 45; Iter   902/ 1097] train: loss: 0.0099521
[Epoch 45; Iter   932/ 1097] train: loss: 0.0318157
[Epoch 45; Iter   962/ 1097] train: loss: 0.0004220
[Epoch 45; Iter   992/ 1097] train: loss: 0.1473448
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0026957
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0007709
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0015705
[Epoch 45] ogbg-molhiv: 0.700519 val loss: 0.198859
[Epoch 45] ogbg-molhiv: 0.707791 test loss: 0.311887
[Epoch 46; Iter    15/ 1097] train: loss: 0.0151199
[Epoch 46; Iter    45/ 1097] train: loss: 0.0002899
[Epoch 46; Iter    75/ 1097] train: loss: 0.0025866
[Epoch 46; Iter   105/ 1097] train: loss: 0.0014147
[Epoch 46; Iter   135/ 1097] train: loss: 0.0014907
[Epoch 46; Iter   165/ 1097] train: loss: 0.0002404
[Epoch 46; Iter   195/ 1097] train: loss: 0.0002032
[Epoch 46; Iter   225/ 1097] train: loss: 0.0026751
[Epoch 46; Iter   255/ 1097] train: loss: 0.0116616
[Epoch 46; Iter   285/ 1097] train: loss: 0.0118929
[Epoch 46; Iter   315/ 1097] train: loss: 0.0086967
[Epoch 46; Iter   345/ 1097] train: loss: 0.0007680
[Epoch 46; Iter   375/ 1097] train: loss: 0.0014298
[Epoch 46; Iter   405/ 1097] train: loss: 0.0849057
[Epoch 46; Iter   435/ 1097] train: loss: 0.0296386
[Epoch 46; Iter   465/ 1097] train: loss: 0.0009527
[Epoch 46; Iter   495/ 1097] train: loss: 0.0002729
[Epoch 46; Iter   525/ 1097] train: loss: 0.0008452
[Epoch 46; Iter   555/ 1097] train: loss: 0.0031714
[Epoch 46; Iter   585/ 1097] train: loss: 0.0044566
[Epoch 46; Iter   615/ 1097] train: loss: 0.0486260
[Epoch 46; Iter   645/ 1097] train: loss: 0.0725871
[Epoch 46; Iter   675/ 1097] train: loss: 0.0002101
[Epoch 46; Iter   705/ 1097] train: loss: 0.0048579
[Epoch 46; Iter   735/ 1097] train: loss: 0.0030417
[Epoch 46; Iter   765/ 1097] train: loss: 0.0022685
[Epoch 46; Iter   795/ 1097] train: loss: 0.0018063
[Epoch 46; Iter   825/ 1097] train: loss: 0.1409065
[Epoch 46; Iter   855/ 1097] train: loss: 0.0069629
[Epoch 46; Iter   885/ 1097] train: loss: 0.0226583
[Epoch 46; Iter   915/ 1097] train: loss: 0.0975714
[Epoch 46; Iter   945/ 1097] train: loss: 0.0038546
[Epoch 46; Iter   975/ 1097] train: loss: 0.0570170
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0023215
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0068462
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0098817
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0017042
[Epoch 46] ogbg-molhiv: 0.727363 val loss: 0.200855
[Epoch 46] ogbg-molhiv: 0.738232 test loss: 0.285503
[Epoch 47; Iter    28/ 1097] train: loss: 0.0077298
[Epoch 47; Iter    58/ 1097] train: loss: 0.0010495
[Epoch 47; Iter    88/ 1097] train: loss: 0.0001667
[Epoch 47; Iter   118/ 1097] train: loss: 0.0064762
[Epoch 47; Iter   148/ 1097] train: loss: 0.0253534
[Epoch 47; Iter   178/ 1097] train: loss: 0.0872440
[Epoch 47; Iter   208/ 1097] train: loss: 0.0007269
[Epoch 47; Iter   238/ 1097] train: loss: 0.0004416
[Epoch 47; Iter   268/ 1097] train: loss: 0.0019823
[Epoch 47; Iter   298/ 1097] train: loss: 0.0053112
[Epoch 47; Iter   328/ 1097] train: loss: 0.0033513
[Epoch 47; Iter   358/ 1097] train: loss: 0.0011298
[Epoch 47; Iter   388/ 1097] train: loss: 0.0045224
[Epoch 47; Iter   418/ 1097] train: loss: 0.0032524
[Epoch 47; Iter   448/ 1097] train: loss: 0.0002480
[Epoch 47; Iter   478/ 1097] train: loss: 0.0000772
[Epoch 47; Iter   508/ 1097] train: loss: 0.0035439
[Epoch 47; Iter   538/ 1097] train: loss: 0.0055208
[Epoch 47; Iter   568/ 1097] train: loss: 0.0067869
[Epoch 47; Iter   598/ 1097] train: loss: 0.0389046
[Epoch 47; Iter   628/ 1097] train: loss: 0.0019422
[Epoch 47; Iter   658/ 1097] train: loss: 0.0001378
[Epoch 47; Iter   688/ 1097] train: loss: 0.0237880
[Epoch 47; Iter   718/ 1097] train: loss: 0.0013584
[Epoch 47; Iter   748/ 1097] train: loss: 0.0048584
[Epoch 47; Iter   778/ 1097] train: loss: 0.0002917
[Epoch 47; Iter   808/ 1097] train: loss: 0.0015048
[Epoch 47; Iter   838/ 1097] train: loss: 0.0008453
[Epoch 47; Iter   868/ 1097] train: loss: 0.0338366
[Epoch 47; Iter   898/ 1097] train: loss: 0.0048239
[Epoch 47; Iter   928/ 1097] train: loss: 0.0027006
[Epoch 47; Iter   958/ 1097] train: loss: 0.0053812
[Epoch 47; Iter   988/ 1097] train: loss: 0.0091909
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0020709
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0394085
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0077384
[Epoch 47] ogbg-molhiv: 0.730257 val loss: 0.199472
[Epoch 47] ogbg-molhiv: 0.741329 test loss: 0.290306
[Epoch 48; Iter    11/ 1097] train: loss: 0.0043132
[Epoch 48; Iter    41/ 1097] train: loss: 0.0016910
[Epoch 48; Iter    71/ 1097] train: loss: 0.0032283
[Epoch 48; Iter   101/ 1097] train: loss: 0.0072864
[Epoch 48; Iter   131/ 1097] train: loss: 0.0081155
[Epoch 48; Iter   161/ 1097] train: loss: 0.0019145
[Epoch 48; Iter   191/ 1097] train: loss: 0.0032973
[Epoch 48; Iter   221/ 1097] train: loss: 0.0059840
[Epoch 48; Iter   251/ 1097] train: loss: 0.0006940
[Epoch 48; Iter   281/ 1097] train: loss: 0.0040623
[Epoch 48; Iter   311/ 1097] train: loss: 0.0043658
[Epoch 48; Iter   341/ 1097] train: loss: 0.0082761
[Epoch 48; Iter   371/ 1097] train: loss: 0.0005250
[Epoch 48; Iter   401/ 1097] train: loss: 0.0211347
[Epoch 48; Iter   431/ 1097] train: loss: 0.0070544
[Epoch 48; Iter   461/ 1097] train: loss: 0.0045412
[Epoch 48; Iter   491/ 1097] train: loss: 0.0008310
[Epoch 48; Iter   521/ 1097] train: loss: 0.0492126
[Epoch 48; Iter   551/ 1097] train: loss: 0.0036904
[Epoch 48; Iter   581/ 1097] train: loss: 0.0366799
[Epoch 48; Iter   611/ 1097] train: loss: 0.0005395
[Epoch 48; Iter   641/ 1097] train: loss: 0.0095813
[Epoch 48; Iter   671/ 1097] train: loss: 0.0000547
[Epoch 48; Iter   701/ 1097] train: loss: 0.0099035
[Epoch 48; Iter   731/ 1097] train: loss: 0.0002954
[Epoch 48; Iter   761/ 1097] train: loss: 0.0048922
[Epoch 48; Iter   791/ 1097] train: loss: 0.0021699
[Epoch 48; Iter   821/ 1097] train: loss: 0.0007357
[Epoch 48; Iter   851/ 1097] train: loss: 0.0006309
[Epoch 36; Iter   635/ 1097] train: loss: 0.2356663
[Epoch 36; Iter   665/ 1097] train: loss: 0.0852890
[Epoch 36; Iter   695/ 1097] train: loss: 0.0488978
[Epoch 36; Iter   725/ 1097] train: loss: 0.1822102
[Epoch 36; Iter   755/ 1097] train: loss: 0.0251163
[Epoch 36; Iter   785/ 1097] train: loss: 0.0522725
[Epoch 36; Iter   815/ 1097] train: loss: 0.1863638
[Epoch 36; Iter   845/ 1097] train: loss: 0.1153798
[Epoch 36; Iter   875/ 1097] train: loss: 0.0492298
[Epoch 36; Iter   905/ 1097] train: loss: 0.0784796
[Epoch 36; Iter   935/ 1097] train: loss: 0.0219372
[Epoch 36; Iter   965/ 1097] train: loss: 0.1446547
[Epoch 36; Iter   995/ 1097] train: loss: 0.0194180
[Epoch 36; Iter  1025/ 1097] train: loss: 0.3888859
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0469488
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0275179
[Epoch 36] ogbg-molhiv: 0.811434 val loss: 0.219532
[Epoch 36] ogbg-molhiv: 0.732229 test loss: 0.349169
[Epoch 37; Iter    18/ 1097] train: loss: 0.0414632
[Epoch 37; Iter    48/ 1097] train: loss: 0.0199685
[Epoch 37; Iter    78/ 1097] train: loss: 0.0446148
[Epoch 37; Iter   108/ 1097] train: loss: 0.1966535
[Epoch 37; Iter   138/ 1097] train: loss: 0.0139257
[Epoch 37; Iter   168/ 1097] train: loss: 0.2130581
[Epoch 37; Iter   198/ 1097] train: loss: 0.0915987
[Epoch 37; Iter   228/ 1097] train: loss: 0.0230361
[Epoch 37; Iter   258/ 1097] train: loss: 0.1656421
[Epoch 37; Iter   288/ 1097] train: loss: 0.1310250
[Epoch 37; Iter   318/ 1097] train: loss: 0.0273372
[Epoch 37; Iter   348/ 1097] train: loss: 0.1787532
[Epoch 37; Iter   378/ 1097] train: loss: 0.0608426
[Epoch 37; Iter   408/ 1097] train: loss: 0.0392562
[Epoch 37; Iter   438/ 1097] train: loss: 0.0176832
[Epoch 37; Iter   468/ 1097] train: loss: 0.1074747
[Epoch 37; Iter   498/ 1097] train: loss: 0.0114334
[Epoch 37; Iter   528/ 1097] train: loss: 0.4206263
[Epoch 37; Iter   558/ 1097] train: loss: 0.4481124
[Epoch 37; Iter   588/ 1097] train: loss: 0.0103009
[Epoch 37; Iter   618/ 1097] train: loss: 0.0434808
[Epoch 37; Iter   648/ 1097] train: loss: 0.0465885
[Epoch 37; Iter   678/ 1097] train: loss: 0.0284219
[Epoch 37; Iter   708/ 1097] train: loss: 0.0393620
[Epoch 37; Iter   738/ 1097] train: loss: 0.1703804
[Epoch 37; Iter   768/ 1097] train: loss: 0.0652545
[Epoch 37; Iter   798/ 1097] train: loss: 0.0746463
[Epoch 37; Iter   828/ 1097] train: loss: 0.0372978
[Epoch 37; Iter   858/ 1097] train: loss: 0.1658378
[Epoch 37; Iter   888/ 1097] train: loss: 0.0567034
[Epoch 37; Iter   918/ 1097] train: loss: 0.1502077
[Epoch 37; Iter   948/ 1097] train: loss: 0.0147017
[Epoch 37; Iter   978/ 1097] train: loss: 0.0560084
[Epoch 37; Iter  1008/ 1097] train: loss: 0.1300695
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0925591
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0518852
[Epoch 37] ogbg-molhiv: 0.810746 val loss: 0.276061
[Epoch 37] ogbg-molhiv: 0.707283 test loss: 0.397565
[Epoch 38; Iter     1/ 1097] train: loss: 0.1681211
[Epoch 38; Iter    31/ 1097] train: loss: 0.0215868
[Epoch 38; Iter    61/ 1097] train: loss: 0.0340600
[Epoch 38; Iter    91/ 1097] train: loss: 0.0355746
[Epoch 38; Iter   121/ 1097] train: loss: 0.0192870
[Epoch 38; Iter   151/ 1097] train: loss: 0.0225849
[Epoch 38; Iter   181/ 1097] train: loss: 0.0265444
[Epoch 38; Iter   211/ 1097] train: loss: 0.0212514
[Epoch 38; Iter   241/ 1097] train: loss: 0.0181646
[Epoch 38; Iter   271/ 1097] train: loss: 0.0323464
[Epoch 38; Iter   301/ 1097] train: loss: 0.0185172
[Epoch 38; Iter   331/ 1097] train: loss: 0.0654687
[Epoch 38; Iter   361/ 1097] train: loss: 0.1137488
[Epoch 38; Iter   391/ 1097] train: loss: 0.0749728
[Epoch 38; Iter   421/ 1097] train: loss: 0.0813939
[Epoch 38; Iter   451/ 1097] train: loss: 0.0444177
[Epoch 38; Iter   481/ 1097] train: loss: 0.3283677
[Epoch 38; Iter   511/ 1097] train: loss: 0.1269264
[Epoch 38; Iter   541/ 1097] train: loss: 0.2029234
[Epoch 38; Iter   571/ 1097] train: loss: 0.0160329
[Epoch 38; Iter   601/ 1097] train: loss: 0.2342164
[Epoch 38; Iter   631/ 1097] train: loss: 0.0547288
[Epoch 38; Iter   661/ 1097] train: loss: 0.0500790
[Epoch 38; Iter   691/ 1097] train: loss: 0.0234887
[Epoch 38; Iter   721/ 1097] train: loss: 0.1403228
[Epoch 38; Iter   751/ 1097] train: loss: 0.1766219
[Epoch 38; Iter   781/ 1097] train: loss: 0.0478720
[Epoch 38; Iter   811/ 1097] train: loss: 0.2176786
[Epoch 38; Iter   841/ 1097] train: loss: 0.0175771
[Epoch 38; Iter   871/ 1097] train: loss: 0.0462964
[Epoch 38; Iter   901/ 1097] train: loss: 0.0121950
[Epoch 38; Iter   931/ 1097] train: loss: 0.0512001
[Epoch 38; Iter   961/ 1097] train: loss: 0.0589076
[Epoch 38; Iter   991/ 1097] train: loss: 0.0743794
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0104214
[Epoch 38; Iter  1051/ 1097] train: loss: 0.1050432
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0875736
[Epoch 38] ogbg-molhiv: 0.779076 val loss: 0.080049
[Epoch 38] ogbg-molhiv: 0.728680 test loss: 0.303669
[Epoch 39; Iter    14/ 1097] train: loss: 0.0958122
[Epoch 39; Iter    44/ 1097] train: loss: 0.1460152
[Epoch 39; Iter    74/ 1097] train: loss: 0.0304836
[Epoch 39; Iter   104/ 1097] train: loss: 0.1070247
[Epoch 39; Iter   134/ 1097] train: loss: 0.1441731
[Epoch 39; Iter   164/ 1097] train: loss: 0.0238275
[Epoch 39; Iter   194/ 1097] train: loss: 0.0384949
[Epoch 39; Iter   224/ 1097] train: loss: 0.0507931
[Epoch 39; Iter   254/ 1097] train: loss: 0.0129650
[Epoch 39; Iter   284/ 1097] train: loss: 0.0178531
[Epoch 39; Iter   314/ 1097] train: loss: 0.0575180
[Epoch 39; Iter   344/ 1097] train: loss: 0.0838027
[Epoch 39; Iter   374/ 1097] train: loss: 0.0746525
[Epoch 39; Iter   404/ 1097] train: loss: 0.1525355
[Epoch 39; Iter   434/ 1097] train: loss: 0.0273803
[Epoch 39; Iter   464/ 1097] train: loss: 0.0504691
[Epoch 39; Iter   494/ 1097] train: loss: 0.0370792
[Epoch 39; Iter   524/ 1097] train: loss: 0.0236555
[Epoch 39; Iter   554/ 1097] train: loss: 0.0229909
[Epoch 39; Iter   584/ 1097] train: loss: 0.0364970
[Epoch 39; Iter   614/ 1097] train: loss: 0.0278168
[Epoch 39; Iter   644/ 1097] train: loss: 0.1247448
[Epoch 39; Iter   674/ 1097] train: loss: 0.0243423
[Epoch 39; Iter   704/ 1097] train: loss: 0.0252319
[Epoch 39; Iter   734/ 1097] train: loss: 0.1830450
[Epoch 39; Iter   764/ 1097] train: loss: 0.1233471
[Epoch 39; Iter   794/ 1097] train: loss: 0.1603397
[Epoch 39; Iter   824/ 1097] train: loss: 0.0455130
[Epoch 39; Iter   854/ 1097] train: loss: 0.1851907
[Epoch 39; Iter   884/ 1097] train: loss: 0.0608912
[Epoch 39; Iter   914/ 1097] train: loss: 0.0283691
[Epoch 39; Iter   944/ 1097] train: loss: 0.0593600
[Epoch 39; Iter   974/ 1097] train: loss: 0.0143218
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0417651
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0227317
[Epoch 39; Iter  1064/ 1097] train: loss: 0.1355374
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1647232
[Epoch 39] ogbg-molhiv: 0.791474 val loss: 0.200611
[Epoch 39] ogbg-molhiv: 0.738299 test loss: 0.325443
[Epoch 40; Iter    27/ 1097] train: loss: 0.0166975
[Epoch 40; Iter    57/ 1097] train: loss: 0.0301902
[Epoch 40; Iter    87/ 1097] train: loss: 0.0556447
[Epoch 40; Iter   117/ 1097] train: loss: 0.1153136
[Epoch 40; Iter   147/ 1097] train: loss: 0.0314563
[Epoch 40; Iter   177/ 1097] train: loss: 0.0284697
[Epoch 40; Iter   207/ 1097] train: loss: 0.1002380
[Epoch 40; Iter   237/ 1097] train: loss: 0.0155583
[Epoch 40; Iter   267/ 1097] train: loss: 0.0167936
[Epoch 40; Iter   297/ 1097] train: loss: 0.3022866
[Epoch 40; Iter   327/ 1097] train: loss: 0.2189459
[Epoch 40; Iter   357/ 1097] train: loss: 0.0178946
[Epoch 40; Iter   387/ 1097] train: loss: 0.0768424
[Epoch 40; Iter   417/ 1097] train: loss: 0.1228264
[Epoch 40; Iter   447/ 1097] train: loss: 0.1416006
[Epoch 40; Iter   477/ 1097] train: loss: 0.0162697
[Epoch 40; Iter   507/ 1097] train: loss: 0.0200478
[Epoch 40; Iter   537/ 1097] train: loss: 0.2074584
[Epoch 40; Iter   567/ 1097] train: loss: 0.0232451
[Epoch 40; Iter   597/ 1097] train: loss: 0.0202612
[Epoch 40; Iter   627/ 1097] train: loss: 0.0321163
[Epoch 40; Iter   657/ 1097] train: loss: 0.0261313
[Epoch 40; Iter   687/ 1097] train: loss: 0.0598989
[Epoch 44; Iter   799/ 1097] train: loss: 0.0006292
[Epoch 44; Iter   829/ 1097] train: loss: 0.0090281
[Epoch 44; Iter   859/ 1097] train: loss: 0.0032661
[Epoch 44; Iter   889/ 1097] train: loss: 0.0074296
[Epoch 44; Iter   919/ 1097] train: loss: 0.0008064
[Epoch 44; Iter   949/ 1097] train: loss: 0.0022861
[Epoch 44; Iter   979/ 1097] train: loss: 0.0009209
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0060882
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0013063
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0045853
[Epoch 44] ogbg-molhiv: 0.712663 val loss: 0.567300
[Epoch 44] ogbg-molhiv: 0.681643 test loss: 1.940109
[Epoch 45; Iter     2/ 1097] train: loss: 0.0043571
[Epoch 45; Iter    32/ 1097] train: loss: 0.0088512
[Epoch 45; Iter    62/ 1097] train: loss: 0.0004455
[Epoch 45; Iter    92/ 1097] train: loss: 0.0028817
[Epoch 45; Iter   122/ 1097] train: loss: 0.0017535
[Epoch 45; Iter   152/ 1097] train: loss: 0.0017813
[Epoch 45; Iter   182/ 1097] train: loss: 0.0002386
[Epoch 45; Iter   212/ 1097] train: loss: 0.0012408
[Epoch 45; Iter   242/ 1097] train: loss: 0.0059780
[Epoch 45; Iter   272/ 1097] train: loss: 0.0181990
[Epoch 45; Iter   302/ 1097] train: loss: 0.0004960
[Epoch 45; Iter   332/ 1097] train: loss: 0.0001427
[Epoch 45; Iter   362/ 1097] train: loss: 0.0022621
[Epoch 45; Iter   392/ 1097] train: loss: 0.0414841
[Epoch 45; Iter   422/ 1097] train: loss: 0.0042986
[Epoch 45; Iter   452/ 1097] train: loss: 0.0016326
[Epoch 45; Iter   482/ 1097] train: loss: 0.0049766
[Epoch 45; Iter   512/ 1097] train: loss: 0.0027710
[Epoch 45; Iter   542/ 1097] train: loss: 0.0103611
[Epoch 45; Iter   572/ 1097] train: loss: 0.0001737
[Epoch 45; Iter   602/ 1097] train: loss: 0.0009164
[Epoch 45; Iter   632/ 1097] train: loss: 0.0004863
[Epoch 45; Iter   662/ 1097] train: loss: 0.0096741
[Epoch 45; Iter   692/ 1097] train: loss: 0.0143651
[Epoch 45; Iter   722/ 1097] train: loss: 0.0024561
[Epoch 45; Iter   752/ 1097] train: loss: 0.0006057
[Epoch 45; Iter   782/ 1097] train: loss: 0.0083443
[Epoch 45; Iter   812/ 1097] train: loss: 0.0029413
[Epoch 45; Iter   842/ 1097] train: loss: 0.0037022
[Epoch 45; Iter   872/ 1097] train: loss: 0.0140070
[Epoch 45; Iter   902/ 1097] train: loss: 0.0007373
[Epoch 45; Iter   932/ 1097] train: loss: 0.0002038
[Epoch 45; Iter   962/ 1097] train: loss: 0.0000915
[Epoch 45; Iter   992/ 1097] train: loss: 0.0012308
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0059818
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0017367
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0014932
[Epoch 45] ogbg-molhiv: 0.738622 val loss: 0.269163
[Epoch 45] ogbg-molhiv: 0.691655 test loss: 0.492003
[Epoch 46; Iter    15/ 1097] train: loss: 0.1313169
[Epoch 46; Iter    45/ 1097] train: loss: 0.0002496
[Epoch 46; Iter    75/ 1097] train: loss: 0.0002201
[Epoch 46; Iter   105/ 1097] train: loss: 0.0007700
[Epoch 46; Iter   135/ 1097] train: loss: 0.0017780
[Epoch 46; Iter   165/ 1097] train: loss: 0.0006066
[Epoch 46; Iter   195/ 1097] train: loss: 0.0010241
[Epoch 46; Iter   225/ 1097] train: loss: 0.0002385
[Epoch 46; Iter   255/ 1097] train: loss: 0.0003290
[Epoch 46; Iter   285/ 1097] train: loss: 0.0012282
[Epoch 46; Iter   315/ 1097] train: loss: 0.0008848
[Epoch 46; Iter   345/ 1097] train: loss: 0.0000365
[Epoch 46; Iter   375/ 1097] train: loss: 0.0102952
[Epoch 46; Iter   405/ 1097] train: loss: 0.0000175
[Epoch 46; Iter   435/ 1097] train: loss: 0.0002040
[Epoch 46; Iter   465/ 1097] train: loss: 0.0002343
[Epoch 46; Iter   495/ 1097] train: loss: 0.0023493
[Epoch 46; Iter   525/ 1097] train: loss: 0.0005110
[Epoch 46; Iter   555/ 1097] train: loss: 0.0146786
[Epoch 46; Iter   585/ 1097] train: loss: 0.2138797
[Epoch 46; Iter   615/ 1097] train: loss: 0.0025871
[Epoch 46; Iter   645/ 1097] train: loss: 0.0001521
[Epoch 46; Iter   675/ 1097] train: loss: 0.0040101
[Epoch 46; Iter   705/ 1097] train: loss: 0.0026792
[Epoch 46; Iter   735/ 1097] train: loss: 0.0013760
[Epoch 46; Iter   765/ 1097] train: loss: 0.0020675
[Epoch 46; Iter   795/ 1097] train: loss: 0.0251092
[Epoch 46; Iter   825/ 1097] train: loss: 0.0272648
[Epoch 46; Iter   855/ 1097] train: loss: 0.0018313
[Epoch 46; Iter   885/ 1097] train: loss: 0.0001774
[Epoch 46; Iter   915/ 1097] train: loss: 0.0075090
[Epoch 46; Iter   945/ 1097] train: loss: 0.0003511
[Epoch 46; Iter   975/ 1097] train: loss: 0.0004291
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0004337
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0058881
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0021402
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0000560
[Epoch 46] ogbg-molhiv: 0.750805 val loss: 5.501337
[Epoch 46] ogbg-molhiv: 0.679530 test loss: 8.990308
[Epoch 47; Iter    28/ 1097] train: loss: 0.0004152
[Epoch 47; Iter    58/ 1097] train: loss: 0.0015771
[Epoch 47; Iter    88/ 1097] train: loss: 0.0003925
[Epoch 47; Iter   118/ 1097] train: loss: 0.0128253
[Epoch 47; Iter   148/ 1097] train: loss: 0.0018036
[Epoch 47; Iter   178/ 1097] train: loss: 0.0000086
[Epoch 47; Iter   208/ 1097] train: loss: 0.0093021
[Epoch 47; Iter   238/ 1097] train: loss: 0.0103191
[Epoch 47; Iter   268/ 1097] train: loss: 0.0010279
[Epoch 47; Iter   298/ 1097] train: loss: 0.0001060
[Epoch 47; Iter   328/ 1097] train: loss: 0.0056799
[Epoch 47; Iter   358/ 1097] train: loss: 0.0005208
[Epoch 47; Iter   388/ 1097] train: loss: 0.0062135
[Epoch 47; Iter   418/ 1097] train: loss: 0.0021168
[Epoch 47; Iter   448/ 1097] train: loss: 0.0033812
[Epoch 47; Iter   478/ 1097] train: loss: 0.0005014
[Epoch 47; Iter   508/ 1097] train: loss: 0.0000491
[Epoch 47; Iter   538/ 1097] train: loss: 0.0016993
[Epoch 47; Iter   568/ 1097] train: loss: 0.0001940
[Epoch 47; Iter   598/ 1097] train: loss: 0.0215183
[Epoch 47; Iter   628/ 1097] train: loss: 0.0039644
[Epoch 47; Iter   658/ 1097] train: loss: 0.0889187
[Epoch 47; Iter   688/ 1097] train: loss: 0.0004434
[Epoch 47; Iter   718/ 1097] train: loss: 0.0002910
[Epoch 47; Iter   748/ 1097] train: loss: 0.0417648
[Epoch 47; Iter   778/ 1097] train: loss: 0.0029222
[Epoch 47; Iter   808/ 1097] train: loss: 0.0046329
[Epoch 47; Iter   838/ 1097] train: loss: 0.0021850
[Epoch 47; Iter   868/ 1097] train: loss: 0.0000988
[Epoch 47; Iter   898/ 1097] train: loss: 0.0009481
[Epoch 47; Iter   928/ 1097] train: loss: 0.0037416
[Epoch 47; Iter   958/ 1097] train: loss: 0.0989308
[Epoch 47; Iter   988/ 1097] train: loss: 0.0021666
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0032224
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0009480
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0003264
[Epoch 47] ogbg-molhiv: 0.701475 val loss: 1.084763
[Epoch 47] ogbg-molhiv: 0.675554 test loss: 3.068078
[Epoch 48; Iter    11/ 1097] train: loss: 0.0009488
[Epoch 48; Iter    41/ 1097] train: loss: 0.0019952
[Epoch 48; Iter    71/ 1097] train: loss: 0.0008640
[Epoch 48; Iter   101/ 1097] train: loss: 0.0119589
[Epoch 48; Iter   131/ 1097] train: loss: 0.0031688
[Epoch 48; Iter   161/ 1097] train: loss: 0.0009009
[Epoch 48; Iter   191/ 1097] train: loss: 0.0002752
[Epoch 48; Iter   221/ 1097] train: loss: 0.0001472
[Epoch 48; Iter   251/ 1097] train: loss: 0.0002914
[Epoch 48; Iter   281/ 1097] train: loss: 0.0056707
[Epoch 48; Iter   311/ 1097] train: loss: 0.0003714
[Epoch 48; Iter   341/ 1097] train: loss: 0.0000149
[Epoch 48; Iter   371/ 1097] train: loss: 0.0005663
[Epoch 48; Iter   401/ 1097] train: loss: 0.0001457
[Epoch 48; Iter   431/ 1097] train: loss: 0.0015187
[Epoch 48; Iter   461/ 1097] train: loss: 0.0251023
[Epoch 48; Iter   491/ 1097] train: loss: 0.0005547
[Epoch 48; Iter   521/ 1097] train: loss: 0.0014484
[Epoch 48; Iter   551/ 1097] train: loss: 0.0102761
[Epoch 48; Iter   581/ 1097] train: loss: 0.0013055
[Epoch 48; Iter   611/ 1097] train: loss: 0.0026315
[Epoch 48; Iter   641/ 1097] train: loss: 0.0000267
[Epoch 48; Iter   671/ 1097] train: loss: 0.0001173
[Epoch 48; Iter   701/ 1097] train: loss: 0.0041607
[Epoch 48; Iter   731/ 1097] train: loss: 0.0001218
[Epoch 48; Iter   761/ 1097] train: loss: 0.0002892
[Epoch 48; Iter   791/ 1097] train: loss: 0.0039943
[Epoch 48; Iter   821/ 1097] train: loss: 0.0067481
[Epoch 48; Iter   851/ 1097] train: loss: 0.0019635
[Epoch 44; Iter   799/ 1097] train: loss: 0.0065953
[Epoch 44; Iter   829/ 1097] train: loss: 0.0004096
[Epoch 44; Iter   859/ 1097] train: loss: 0.0102962
[Epoch 44; Iter   889/ 1097] train: loss: 0.0190147
[Epoch 44; Iter   919/ 1097] train: loss: 0.0387009
[Epoch 44; Iter   949/ 1097] train: loss: 0.0034457
[Epoch 44; Iter   979/ 1097] train: loss: 0.0294091
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1868655
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0013415
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0002709
[Epoch 44] ogbg-molhiv: 0.693134 val loss: 25.710217
[Epoch 44] ogbg-molhiv: 0.592213 test loss: 19.735239
[Epoch 45; Iter     2/ 1097] train: loss: 0.0229366
[Epoch 45; Iter    32/ 1097] train: loss: 0.0210682
[Epoch 45; Iter    62/ 1097] train: loss: 0.0059792
[Epoch 45; Iter    92/ 1097] train: loss: 0.0401558
[Epoch 45; Iter   122/ 1097] train: loss: 0.0068189
[Epoch 45; Iter   152/ 1097] train: loss: 0.0132887
[Epoch 45; Iter   182/ 1097] train: loss: 0.0008810
[Epoch 45; Iter   212/ 1097] train: loss: 0.0763398
[Epoch 45; Iter   242/ 1097] train: loss: 0.0020176
[Epoch 45; Iter   272/ 1097] train: loss: 0.0012651
[Epoch 45; Iter   302/ 1097] train: loss: 0.0586950
[Epoch 45; Iter   332/ 1097] train: loss: 0.0025146
[Epoch 45; Iter   362/ 1097] train: loss: 0.0008907
[Epoch 45; Iter   392/ 1097] train: loss: 0.0409239
[Epoch 45; Iter   422/ 1097] train: loss: 0.0004885
[Epoch 45; Iter   452/ 1097] train: loss: 0.0186567
[Epoch 45; Iter   482/ 1097] train: loss: 0.0200361
[Epoch 45; Iter   512/ 1097] train: loss: 0.0014921
[Epoch 45; Iter   542/ 1097] train: loss: 0.0102905
[Epoch 45; Iter   572/ 1097] train: loss: 0.0091603
[Epoch 45; Iter   602/ 1097] train: loss: 0.0064551
[Epoch 45; Iter   632/ 1097] train: loss: 0.0006492
[Epoch 45; Iter   662/ 1097] train: loss: 0.0009633
[Epoch 45; Iter   692/ 1097] train: loss: 0.0019679
[Epoch 45; Iter   722/ 1097] train: loss: 0.0008572
[Epoch 45; Iter   752/ 1097] train: loss: 0.0985607
[Epoch 45; Iter   782/ 1097] train: loss: 0.0031524
[Epoch 45; Iter   812/ 1097] train: loss: 0.0166255
[Epoch 45; Iter   842/ 1097] train: loss: 0.0003836
[Epoch 45; Iter   872/ 1097] train: loss: 0.0005251
[Epoch 45; Iter   902/ 1097] train: loss: 0.0132365
[Epoch 45; Iter   932/ 1097] train: loss: 0.0098832
[Epoch 45; Iter   962/ 1097] train: loss: 0.0387119
[Epoch 45; Iter   992/ 1097] train: loss: 0.0012860
[Epoch 45; Iter  1022/ 1097] train: loss: 0.2037888
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0013564
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0004840
[Epoch 45] ogbg-molhiv: 0.684760 val loss: 9.958219
[Epoch 45] ogbg-molhiv: 0.613793 test loss: 6.514824
[Epoch 46; Iter    15/ 1097] train: loss: 0.0005709
[Epoch 46; Iter    45/ 1097] train: loss: 0.0995774
[Epoch 46; Iter    75/ 1097] train: loss: 0.0037582
[Epoch 46; Iter   105/ 1097] train: loss: 0.0083075
[Epoch 46; Iter   135/ 1097] train: loss: 0.0003233
[Epoch 46; Iter   165/ 1097] train: loss: 0.0020907
[Epoch 46; Iter   195/ 1097] train: loss: 0.0004745
[Epoch 46; Iter   225/ 1097] train: loss: 0.0047682
[Epoch 46; Iter   255/ 1097] train: loss: 0.0098795
[Epoch 46; Iter   285/ 1097] train: loss: 0.0039688
[Epoch 46; Iter   315/ 1097] train: loss: 0.0050846
[Epoch 46; Iter   345/ 1097] train: loss: 0.0002671
[Epoch 46; Iter   375/ 1097] train: loss: 0.0014935
[Epoch 46; Iter   405/ 1097] train: loss: 0.0038083
[Epoch 46; Iter   435/ 1097] train: loss: 0.0036267
[Epoch 46; Iter   465/ 1097] train: loss: 0.0012602
[Epoch 46; Iter   495/ 1097] train: loss: 0.0011018
[Epoch 46; Iter   525/ 1097] train: loss: 0.0004642
[Epoch 46; Iter   555/ 1097] train: loss: 0.0003277
[Epoch 46; Iter   585/ 1097] train: loss: 0.1796269
[Epoch 46; Iter   615/ 1097] train: loss: 0.0461005
[Epoch 46; Iter   645/ 1097] train: loss: 0.0082080
[Epoch 46; Iter   675/ 1097] train: loss: 0.0112621
[Epoch 46; Iter   705/ 1097] train: loss: 0.1016068
[Epoch 46; Iter   735/ 1097] train: loss: 0.0013268
[Epoch 46; Iter   765/ 1097] train: loss: 0.0729756
[Epoch 46; Iter   795/ 1097] train: loss: 0.0067536
[Epoch 46; Iter   825/ 1097] train: loss: 0.0027579
[Epoch 46; Iter   855/ 1097] train: loss: 0.0018246
[Epoch 46; Iter   885/ 1097] train: loss: 0.0005391
[Epoch 46; Iter   915/ 1097] train: loss: 0.0013592
[Epoch 46; Iter   945/ 1097] train: loss: 0.0008143
[Epoch 46; Iter   975/ 1097] train: loss: 0.0014114
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0216458
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0018362
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0222625
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0013149
[Epoch 46] ogbg-molhiv: 0.711319 val loss: 15.557457
[Epoch 46] ogbg-molhiv: 0.606659 test loss: 12.000585
[Epoch 47; Iter    28/ 1097] train: loss: 0.0454659
[Epoch 47; Iter    58/ 1097] train: loss: 0.0001624
[Epoch 47; Iter    88/ 1097] train: loss: 0.0000979
[Epoch 47; Iter   118/ 1097] train: loss: 0.0002512
[Epoch 47; Iter   148/ 1097] train: loss: 0.0050036
[Epoch 47; Iter   178/ 1097] train: loss: 0.0061343
[Epoch 47; Iter   208/ 1097] train: loss: 0.0033664
[Epoch 47; Iter   238/ 1097] train: loss: 0.0094485
[Epoch 47; Iter   268/ 1097] train: loss: 0.0015800
[Epoch 47; Iter   298/ 1097] train: loss: 0.0004610
[Epoch 47; Iter   328/ 1097] train: loss: 0.0209581
[Epoch 47; Iter   358/ 1097] train: loss: 0.0060623
[Epoch 47; Iter   388/ 1097] train: loss: 0.1153255
[Epoch 47; Iter   418/ 1097] train: loss: 0.0034073
[Epoch 47; Iter   448/ 1097] train: loss: 0.0060254
[Epoch 47; Iter   478/ 1097] train: loss: 0.0630924
[Epoch 47; Iter   508/ 1097] train: loss: 0.0119051
[Epoch 47; Iter   538/ 1097] train: loss: 0.0044829
[Epoch 47; Iter   568/ 1097] train: loss: 0.0033028
[Epoch 47; Iter   598/ 1097] train: loss: 0.0007042
[Epoch 47; Iter   628/ 1097] train: loss: 0.0017319
[Epoch 47; Iter   658/ 1097] train: loss: 0.0014949
[Epoch 47; Iter   688/ 1097] train: loss: 0.0024563
[Epoch 47; Iter   718/ 1097] train: loss: 0.0011654
[Epoch 47; Iter   748/ 1097] train: loss: 0.0132389
[Epoch 47; Iter   778/ 1097] train: loss: 0.0003367
[Epoch 47; Iter   808/ 1097] train: loss: 0.0009551
[Epoch 47; Iter   838/ 1097] train: loss: 0.0021117
[Epoch 47; Iter   868/ 1097] train: loss: 0.0031606
[Epoch 47; Iter   898/ 1097] train: loss: 0.0327317
[Epoch 47; Iter   928/ 1097] train: loss: 0.0006953
[Epoch 47; Iter   958/ 1097] train: loss: 0.0005432
[Epoch 47; Iter   988/ 1097] train: loss: 0.0000773
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0005005
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0005767
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0001268
[Epoch 47] ogbg-molhiv: 0.695017 val loss: 7.762023
[Epoch 47] ogbg-molhiv: 0.577694 test loss: 6.084485
[Epoch 48; Iter    11/ 1097] train: loss: 0.0805915
[Epoch 48; Iter    41/ 1097] train: loss: 0.0554893
[Epoch 48; Iter    71/ 1097] train: loss: 0.0014871
[Epoch 48; Iter   101/ 1097] train: loss: 0.0362237
[Epoch 48; Iter   131/ 1097] train: loss: 0.0066088
[Epoch 48; Iter   161/ 1097] train: loss: 0.0014458
[Epoch 48; Iter   191/ 1097] train: loss: 0.0056038
[Epoch 48; Iter   221/ 1097] train: loss: 0.0070277
[Epoch 48; Iter   251/ 1097] train: loss: 0.0708948
[Epoch 48; Iter   281/ 1097] train: loss: 0.0546846
[Epoch 48; Iter   311/ 1097] train: loss: 0.0224569
[Epoch 48; Iter   341/ 1097] train: loss: 0.0094591
[Epoch 48; Iter   371/ 1097] train: loss: 0.0059717
[Epoch 48; Iter   401/ 1097] train: loss: 0.0040394
[Epoch 48; Iter   431/ 1097] train: loss: 0.0026444
[Epoch 48; Iter   461/ 1097] train: loss: 0.0052960
[Epoch 48; Iter   491/ 1097] train: loss: 0.0041409
[Epoch 48; Iter   521/ 1097] train: loss: 0.0257805
[Epoch 48; Iter   551/ 1097] train: loss: 0.0416471
[Epoch 48; Iter   581/ 1097] train: loss: 0.0019046
[Epoch 48; Iter   611/ 1097] train: loss: 0.0006595
[Epoch 48; Iter   641/ 1097] train: loss: 0.0075660
[Epoch 48; Iter   671/ 1097] train: loss: 0.0004693
[Epoch 48; Iter   701/ 1097] train: loss: 0.0040522
[Epoch 48; Iter   731/ 1097] train: loss: 0.0021127
[Epoch 48; Iter   761/ 1097] train: loss: 0.0345291
[Epoch 48; Iter   791/ 1097] train: loss: 0.0014961
[Epoch 48; Iter   821/ 1097] train: loss: 0.0098370
[Epoch 48; Iter   851/ 1097] train: loss: 0.0020495
[Epoch 44; Iter   799/ 1097] train: loss: 0.0554583
[Epoch 44; Iter   829/ 1097] train: loss: 0.0331661
[Epoch 44; Iter   859/ 1097] train: loss: 0.0600363
[Epoch 44; Iter   889/ 1097] train: loss: 0.0164482
[Epoch 44; Iter   919/ 1097] train: loss: 0.0055022
[Epoch 44; Iter   949/ 1097] train: loss: 0.1954294
[Epoch 44; Iter   979/ 1097] train: loss: 0.0087817
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0014898
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0334699
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0204204
[Epoch 44] ogbg-molhiv: 0.768292 val loss: 0.202626
[Epoch 44] ogbg-molhiv: 0.671266 test loss: 0.297235
[Epoch 45; Iter     2/ 1097] train: loss: 0.0026246
[Epoch 45; Iter    32/ 1097] train: loss: 0.0065114
[Epoch 45; Iter    62/ 1097] train: loss: 0.0189026
[Epoch 45; Iter    92/ 1097] train: loss: 0.0053038
[Epoch 45; Iter   122/ 1097] train: loss: 0.0043313
[Epoch 45; Iter   152/ 1097] train: loss: 0.0013851
[Epoch 45; Iter   182/ 1097] train: loss: 0.0028494
[Epoch 45; Iter   212/ 1097] train: loss: 0.0039078
[Epoch 45; Iter   242/ 1097] train: loss: 0.0075901
[Epoch 45; Iter   272/ 1097] train: loss: 0.0013639
[Epoch 45; Iter   302/ 1097] train: loss: 0.0237362
[Epoch 45; Iter   332/ 1097] train: loss: 0.0489076
[Epoch 45; Iter   362/ 1097] train: loss: 0.0037859
[Epoch 45; Iter   392/ 1097] train: loss: 0.2376625
[Epoch 45; Iter   422/ 1097] train: loss: 0.0589249
[Epoch 45; Iter   452/ 1097] train: loss: 0.0225258
[Epoch 45; Iter   482/ 1097] train: loss: 0.0032903
[Epoch 45; Iter   512/ 1097] train: loss: 0.0778676
[Epoch 45; Iter   542/ 1097] train: loss: 0.0016420
[Epoch 45; Iter   572/ 1097] train: loss: 0.0623169
[Epoch 45; Iter   602/ 1097] train: loss: 0.0063899
[Epoch 45; Iter   632/ 1097] train: loss: 0.3124640
[Epoch 45; Iter   662/ 1097] train: loss: 0.0029295
[Epoch 45; Iter   692/ 1097] train: loss: 0.0090163
[Epoch 45; Iter   722/ 1097] train: loss: 0.0109442
[Epoch 45; Iter   752/ 1097] train: loss: 0.0321722
[Epoch 45; Iter   782/ 1097] train: loss: 0.0095887
[Epoch 45; Iter   812/ 1097] train: loss: 0.0096129
[Epoch 45; Iter   842/ 1097] train: loss: 0.0178237
[Epoch 45; Iter   872/ 1097] train: loss: 0.0152599
[Epoch 45; Iter   902/ 1097] train: loss: 0.1296773
[Epoch 45; Iter   932/ 1097] train: loss: 0.1010450
[Epoch 45; Iter   962/ 1097] train: loss: 0.0008807
[Epoch 45; Iter   992/ 1097] train: loss: 0.1161931
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0546178
[Epoch 45; Iter  1052/ 1097] train: loss: 0.1648246
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0107280
[Epoch 45] ogbg-molhiv: 0.710654 val loss: 0.449614
[Epoch 45] ogbg-molhiv: 0.558213 test loss: 0.585951
[Epoch 46; Iter    15/ 1097] train: loss: 0.0283965
[Epoch 46; Iter    45/ 1097] train: loss: 0.0107638
[Epoch 46; Iter    75/ 1097] train: loss: 0.0043376
[Epoch 46; Iter   105/ 1097] train: loss: 0.0200210
[Epoch 46; Iter   135/ 1097] train: loss: 0.0132227
[Epoch 46; Iter   165/ 1097] train: loss: 0.0117776
[Epoch 46; Iter   195/ 1097] train: loss: 0.0025181
[Epoch 46; Iter   225/ 1097] train: loss: 0.0050441
[Epoch 46; Iter   255/ 1097] train: loss: 0.0361873
[Epoch 46; Iter   285/ 1097] train: loss: 0.0115118
[Epoch 46; Iter   315/ 1097] train: loss: 0.0168350
[Epoch 46; Iter   345/ 1097] train: loss: 0.0033267
[Epoch 46; Iter   375/ 1097] train: loss: 0.0111469
[Epoch 46; Iter   405/ 1097] train: loss: 0.0077456
[Epoch 46; Iter   435/ 1097] train: loss: 0.0138990
[Epoch 46; Iter   465/ 1097] train: loss: 0.0170267
[Epoch 46; Iter   495/ 1097] train: loss: 0.0014142
[Epoch 46; Iter   525/ 1097] train: loss: 0.0044361
[Epoch 46; Iter   555/ 1097] train: loss: 0.0005803
[Epoch 46; Iter   585/ 1097] train: loss: 0.0115336
[Epoch 46; Iter   615/ 1097] train: loss: 0.0687628
[Epoch 46; Iter   645/ 1097] train: loss: 0.0823932
[Epoch 46; Iter   675/ 1097] train: loss: 0.0064592
[Epoch 46; Iter   705/ 1097] train: loss: 0.0013544
[Epoch 46; Iter   735/ 1097] train: loss: 0.0071869
[Epoch 46; Iter   765/ 1097] train: loss: 0.0238156
[Epoch 46; Iter   795/ 1097] train: loss: 0.0021716
[Epoch 46; Iter   825/ 1097] train: loss: 0.0238948
[Epoch 46; Iter   855/ 1097] train: loss: 0.0005591
[Epoch 46; Iter   885/ 1097] train: loss: 0.0891899
[Epoch 46; Iter   915/ 1097] train: loss: 0.1174346
[Epoch 46; Iter   945/ 1097] train: loss: 0.0081533
[Epoch 46; Iter   975/ 1097] train: loss: 0.0301428
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0317774
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0111048
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0358420
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0226990
[Epoch 46] ogbg-molhiv: 0.773090 val loss: 0.347181
[Epoch 46] ogbg-molhiv: 0.664206 test loss: 0.423137
[Epoch 47; Iter    28/ 1097] train: loss: 0.0031896
[Epoch 47; Iter    58/ 1097] train: loss: 0.0085790
[Epoch 47; Iter    88/ 1097] train: loss: 0.0591998
[Epoch 47; Iter   118/ 1097] train: loss: 0.0013314
[Epoch 47; Iter   148/ 1097] train: loss: 0.0009515
[Epoch 47; Iter   178/ 1097] train: loss: 0.1220659
[Epoch 47; Iter   208/ 1097] train: loss: 0.0026958
[Epoch 47; Iter   238/ 1097] train: loss: 0.0048353
[Epoch 47; Iter   268/ 1097] train: loss: 0.0116219
[Epoch 47; Iter   298/ 1097] train: loss: 0.0037219
[Epoch 47; Iter   328/ 1097] train: loss: 0.0061246
[Epoch 47; Iter   358/ 1097] train: loss: 0.0482061
[Epoch 47; Iter   388/ 1097] train: loss: 0.0068192
[Epoch 47; Iter   418/ 1097] train: loss: 0.0003665
[Epoch 47; Iter   448/ 1097] train: loss: 0.0094027
[Epoch 47; Iter   478/ 1097] train: loss: 0.0021355
[Epoch 47; Iter   508/ 1097] train: loss: 0.0037738
[Epoch 47; Iter   538/ 1097] train: loss: 0.0098695
[Epoch 47; Iter   568/ 1097] train: loss: 0.0081161
[Epoch 47; Iter   598/ 1097] train: loss: 0.1829546
[Epoch 47; Iter   628/ 1097] train: loss: 0.0829169
[Epoch 47; Iter   658/ 1097] train: loss: 0.0033801
[Epoch 47; Iter   688/ 1097] train: loss: 0.0134319
[Epoch 47; Iter   718/ 1097] train: loss: 0.0036338
[Epoch 47; Iter   748/ 1097] train: loss: 0.1263297
[Epoch 47; Iter   778/ 1097] train: loss: 0.0025315
[Epoch 47; Iter   808/ 1097] train: loss: 0.0341287
[Epoch 47; Iter   838/ 1097] train: loss: 0.0145779
[Epoch 47; Iter   868/ 1097] train: loss: 0.0719261
[Epoch 47; Iter   898/ 1097] train: loss: 0.1002644
[Epoch 47; Iter   928/ 1097] train: loss: 0.0154429
[Epoch 47; Iter   958/ 1097] train: loss: 0.0048639
[Epoch 47; Iter   988/ 1097] train: loss: 0.0031758
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0058838
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0103569
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0450140
[Epoch 47] ogbg-molhiv: 0.764731 val loss: 0.266724
[Epoch 47] ogbg-molhiv: 0.666878 test loss: 0.323350
[Epoch 48; Iter    11/ 1097] train: loss: 0.0269572
[Epoch 48; Iter    41/ 1097] train: loss: 0.1196058
[Epoch 48; Iter    71/ 1097] train: loss: 0.0009408
[Epoch 48; Iter   101/ 1097] train: loss: 0.0294624
[Epoch 48; Iter   131/ 1097] train: loss: 0.0359595
[Epoch 48; Iter   161/ 1097] train: loss: 0.0010409
[Epoch 48; Iter   191/ 1097] train: loss: 0.0163195
[Epoch 48; Iter   221/ 1097] train: loss: 0.0357770
[Epoch 48; Iter   251/ 1097] train: loss: 0.0008447
[Epoch 48; Iter   281/ 1097] train: loss: 0.0314065
[Epoch 48; Iter   311/ 1097] train: loss: 0.0011726
[Epoch 48; Iter   341/ 1097] train: loss: 0.0297246
[Epoch 48; Iter   371/ 1097] train: loss: 0.0085704
[Epoch 48; Iter   401/ 1097] train: loss: 0.0029180
[Epoch 48; Iter   431/ 1097] train: loss: 0.1239392
[Epoch 48; Iter   461/ 1097] train: loss: 0.0060408
[Epoch 48; Iter   491/ 1097] train: loss: 0.0084913
[Epoch 48; Iter   521/ 1097] train: loss: 0.0029703
[Epoch 48; Iter   551/ 1097] train: loss: 0.0268364
[Epoch 48; Iter   581/ 1097] train: loss: 0.0025998
[Epoch 48; Iter   611/ 1097] train: loss: 0.0116470
[Epoch 48; Iter   641/ 1097] train: loss: 0.0110169
[Epoch 48; Iter   671/ 1097] train: loss: 0.0658876
[Epoch 48; Iter   701/ 1097] train: loss: 0.0050545
[Epoch 48; Iter   731/ 1097] train: loss: 0.0104801
[Epoch 48; Iter   761/ 1097] train: loss: 0.0337852
[Epoch 48; Iter   791/ 1097] train: loss: 0.0286471
[Epoch 48; Iter   821/ 1097] train: loss: 0.0052579
[Epoch 48; Iter   851/ 1097] train: loss: 0.0488517
[Epoch 48; Iter   851/ 1097] train: loss: 0.0024074
[Epoch 48; Iter   881/ 1097] train: loss: 0.0119867
[Epoch 48; Iter   911/ 1097] train: loss: 0.0003077
[Epoch 48; Iter   941/ 1097] train: loss: 0.0011183
[Epoch 48; Iter   971/ 1097] train: loss: 0.0009247
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0034323
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0068071
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0017818
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0010543
[Epoch 48] ogbg-molhiv: 0.800451 val loss: 2.069387
[Epoch 48] ogbg-molhiv: 0.744547 test loss: 1.368659
[Epoch 49; Iter    24/ 1097] train: loss: 0.0028028
[Epoch 49; Iter    54/ 1097] train: loss: 0.0002581
[Epoch 49; Iter    84/ 1097] train: loss: 0.0125603
[Epoch 49; Iter   114/ 1097] train: loss: 0.0012142
[Epoch 49; Iter   144/ 1097] train: loss: 0.0022457
[Epoch 49; Iter   174/ 1097] train: loss: 0.0249408
[Epoch 49; Iter   204/ 1097] train: loss: 0.0010150
[Epoch 49; Iter   234/ 1097] train: loss: 0.0157994
[Epoch 49; Iter   264/ 1097] train: loss: 0.0101553
[Epoch 49; Iter   294/ 1097] train: loss: 0.0148439
[Epoch 49; Iter   324/ 1097] train: loss: 0.0831602
[Epoch 49; Iter   354/ 1097] train: loss: 0.0015923
[Epoch 49; Iter   384/ 1097] train: loss: 0.0014407
[Epoch 49; Iter   414/ 1097] train: loss: 0.0120685
[Epoch 49; Iter   444/ 1097] train: loss: 0.0059094
[Epoch 49; Iter   474/ 1097] train: loss: 0.0004129
[Epoch 49; Iter   504/ 1097] train: loss: 0.0029443
[Epoch 49; Iter   534/ 1097] train: loss: 0.0015603
[Epoch 49; Iter   564/ 1097] train: loss: 0.0048385
[Epoch 49; Iter   594/ 1097] train: loss: 0.0218387
[Epoch 49; Iter   624/ 1097] train: loss: 0.0017266
[Epoch 49; Iter   654/ 1097] train: loss: 0.0023703
[Epoch 49; Iter   684/ 1097] train: loss: 0.0048861
[Epoch 49; Iter   714/ 1097] train: loss: 0.0042969
[Epoch 49; Iter   744/ 1097] train: loss: 0.0005348
[Epoch 49; Iter   774/ 1097] train: loss: 0.0002804
[Epoch 49; Iter   804/ 1097] train: loss: 0.0004467
[Epoch 49; Iter   834/ 1097] train: loss: 0.0236649
[Epoch 49; Iter   864/ 1097] train: loss: 0.0008804
[Epoch 49; Iter   894/ 1097] train: loss: 0.0136733
[Epoch 49; Iter   924/ 1097] train: loss: 0.0013688
[Epoch 49; Iter   954/ 1097] train: loss: 0.0325796
[Epoch 49; Iter   984/ 1097] train: loss: 0.0020246
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0007162
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0001552
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0023215
[Epoch 49] ogbg-molhiv: 0.802426 val loss: 1.593927
[Epoch 49] ogbg-molhiv: 0.747218 test loss: 1.363451
[Epoch 50; Iter     7/ 1097] train: loss: 0.0281405
[Epoch 50; Iter    37/ 1097] train: loss: 0.0077020
[Epoch 50; Iter    67/ 1097] train: loss: 0.1010112
[Epoch 50; Iter    97/ 1097] train: loss: 0.0014352
[Epoch 50; Iter   127/ 1097] train: loss: 0.0064446
[Epoch 50; Iter   157/ 1097] train: loss: 0.0019613
[Epoch 50; Iter   187/ 1097] train: loss: 0.0023943
[Epoch 50; Iter   217/ 1097] train: loss: 0.0007732
[Epoch 50; Iter   247/ 1097] train: loss: 0.0012735
[Epoch 50; Iter   277/ 1097] train: loss: 0.0009324
[Epoch 50; Iter   307/ 1097] train: loss: 0.0013504
[Epoch 50; Iter   337/ 1097] train: loss: 0.0551996
[Epoch 50; Iter   367/ 1097] train: loss: 0.0186959
[Epoch 50; Iter   397/ 1097] train: loss: 0.0151706
[Epoch 50; Iter   427/ 1097] train: loss: 0.0004754
[Epoch 50; Iter   457/ 1097] train: loss: 0.0020678
[Epoch 50; Iter   487/ 1097] train: loss: 0.0062302
[Epoch 50; Iter   517/ 1097] train: loss: 0.0361518
[Epoch 50; Iter   547/ 1097] train: loss: 0.0072095
[Epoch 50; Iter   577/ 1097] train: loss: 0.0043763
[Epoch 50; Iter   607/ 1097] train: loss: 0.1257697
[Epoch 50; Iter   637/ 1097] train: loss: 0.0080018
[Epoch 50; Iter   667/ 1097] train: loss: 0.0067928
[Epoch 50; Iter   697/ 1097] train: loss: 0.0100778
[Epoch 50; Iter   727/ 1097] train: loss: 0.0024167
[Epoch 50; Iter   757/ 1097] train: loss: 0.0054759
[Epoch 50; Iter   787/ 1097] train: loss: 0.0005464
[Epoch 50; Iter   817/ 1097] train: loss: 0.0009738
[Epoch 50; Iter   847/ 1097] train: loss: 0.0019986
[Epoch 50; Iter   877/ 1097] train: loss: 0.0035482
[Epoch 50; Iter   907/ 1097] train: loss: 0.0363070
[Epoch 50; Iter   937/ 1097] train: loss: 0.0179552
[Epoch 50; Iter   967/ 1097] train: loss: 0.0575737
[Epoch 50; Iter   997/ 1097] train: loss: 0.0005852
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0006258
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0001498
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0062558
[Epoch 50] ogbg-molhiv: 0.787322 val loss: 0.947140
[Epoch 50] ogbg-molhiv: 0.719230 test loss: 1.006186
[Epoch 51; Iter    20/ 1097] train: loss: 0.0001692
[Epoch 51; Iter    50/ 1097] train: loss: 0.0482964
[Epoch 51; Iter    80/ 1097] train: loss: 0.0010845
[Epoch 51; Iter   110/ 1097] train: loss: 0.0136200
[Epoch 51; Iter   140/ 1097] train: loss: 0.0012606
[Epoch 51; Iter   170/ 1097] train: loss: 0.0005422
[Epoch 51; Iter   200/ 1097] train: loss: 0.0147344
[Epoch 51; Iter   230/ 1097] train: loss: 0.0392677
[Epoch 51; Iter   260/ 1097] train: loss: 0.0020926
[Epoch 51; Iter   290/ 1097] train: loss: 0.0053412
[Epoch 51; Iter   320/ 1097] train: loss: 0.0413296
[Epoch 51; Iter   350/ 1097] train: loss: 0.0004461
[Epoch 51; Iter   380/ 1097] train: loss: 0.0011844
[Epoch 51; Iter   410/ 1097] train: loss: 0.0052901
[Epoch 51; Iter   440/ 1097] train: loss: 0.0010100
[Epoch 51; Iter   470/ 1097] train: loss: 0.0469547
[Epoch 51; Iter   500/ 1097] train: loss: 0.0007194
[Epoch 51; Iter   530/ 1097] train: loss: 0.0040075
[Epoch 51; Iter   560/ 1097] train: loss: 0.0030155
[Epoch 51; Iter   590/ 1097] train: loss: 0.0054782
[Epoch 51; Iter   620/ 1097] train: loss: 0.1532777
[Epoch 51; Iter   650/ 1097] train: loss: 0.0068713
[Epoch 51; Iter   680/ 1097] train: loss: 0.0031778
[Epoch 51; Iter   710/ 1097] train: loss: 0.0001886
[Epoch 51; Iter   740/ 1097] train: loss: 0.0015581
[Epoch 51; Iter   770/ 1097] train: loss: 0.0149471
[Epoch 51; Iter   800/ 1097] train: loss: 0.0530101
[Epoch 51; Iter   830/ 1097] train: loss: 0.0715333
[Epoch 51; Iter   860/ 1097] train: loss: 0.0110548
[Epoch 51; Iter   890/ 1097] train: loss: 0.0039185
[Epoch 51; Iter   920/ 1097] train: loss: 0.0030816
[Epoch 51; Iter   950/ 1097] train: loss: 0.0005963
[Epoch 51; Iter   980/ 1097] train: loss: 0.0086743
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0067687
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0022193
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0015834
[Epoch 51] ogbg-molhiv: 0.813011 val loss: 1.151481
[Epoch 51] ogbg-molhiv: 0.726022 test loss: 0.590681
[Epoch 52; Iter     3/ 1097] train: loss: 0.0716780
[Epoch 52; Iter    33/ 1097] train: loss: 0.0077003
[Epoch 52; Iter    63/ 1097] train: loss: 0.0014240
[Epoch 52; Iter    93/ 1097] train: loss: 0.0257468
[Epoch 52; Iter   123/ 1097] train: loss: 0.0006852
[Epoch 52; Iter   153/ 1097] train: loss: 0.0015353
[Epoch 52; Iter   183/ 1097] train: loss: 0.0012453
[Epoch 52; Iter   213/ 1097] train: loss: 0.0071090
[Epoch 52; Iter   243/ 1097] train: loss: 0.0011767
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002771
[Epoch 52; Iter   303/ 1097] train: loss: 0.0011848
[Epoch 52; Iter   333/ 1097] train: loss: 0.0009577
[Epoch 52; Iter   363/ 1097] train: loss: 0.0188175
[Epoch 52; Iter   393/ 1097] train: loss: 0.0151989
[Epoch 52; Iter   423/ 1097] train: loss: 0.1416323
[Epoch 52; Iter   453/ 1097] train: loss: 0.0046670
[Epoch 52; Iter   483/ 1097] train: loss: 0.0004121
[Epoch 52; Iter   513/ 1097] train: loss: 0.0032742
[Epoch 52; Iter   543/ 1097] train: loss: 0.0034895
[Epoch 52; Iter   573/ 1097] train: loss: 0.0002008
[Epoch 52; Iter   603/ 1097] train: loss: 0.0104892
[Epoch 52; Iter   633/ 1097] train: loss: 0.0010981
[Epoch 52; Iter   663/ 1097] train: loss: 0.1655363
[Epoch 52; Iter   693/ 1097] train: loss: 0.0002015
[Epoch 52; Iter   723/ 1097] train: loss: 0.0213122
[Epoch 52; Iter   753/ 1097] train: loss: 0.0004212
[Epoch 52; Iter   783/ 1097] train: loss: 0.0013457
[Epoch 52; Iter   813/ 1097] train: loss: 0.0077736
[Epoch 52; Iter   843/ 1097] train: loss: 0.0034300
[Epoch 52; Iter   873/ 1097] train: loss: 0.0713444
[Epoch 52; Iter   903/ 1097] train: loss: 0.0017543
[Epoch 48; Iter   851/ 1097] train: loss: 0.0003602
[Epoch 48; Iter   881/ 1097] train: loss: 0.0830033
[Epoch 48; Iter   911/ 1097] train: loss: 0.0603875
[Epoch 48; Iter   941/ 1097] train: loss: 0.0123918
[Epoch 48; Iter   971/ 1097] train: loss: 0.0024049
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0007452
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0009172
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0004137
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0184501
[Epoch 48] ogbg-molhiv: 0.780025 val loss: 0.571570
[Epoch 48] ogbg-molhiv: 0.702625 test loss: 0.351400
[Epoch 49; Iter    24/ 1097] train: loss: 0.0035139
[Epoch 49; Iter    54/ 1097] train: loss: 0.0041105
[Epoch 49; Iter    84/ 1097] train: loss: 0.0000586
[Epoch 49; Iter   114/ 1097] train: loss: 0.0011668
[Epoch 49; Iter   144/ 1097] train: loss: 0.0097802
[Epoch 49; Iter   174/ 1097] train: loss: 0.0023362
[Epoch 49; Iter   204/ 1097] train: loss: 0.0011162
[Epoch 49; Iter   234/ 1097] train: loss: 0.0007008
[Epoch 49; Iter   264/ 1097] train: loss: 0.0002579
[Epoch 49; Iter   294/ 1097] train: loss: 0.0028839
[Epoch 49; Iter   324/ 1097] train: loss: 0.0014416
[Epoch 49; Iter   354/ 1097] train: loss: 0.0160242
[Epoch 49; Iter   384/ 1097] train: loss: 0.0061886
[Epoch 49; Iter   414/ 1097] train: loss: 0.0128098
[Epoch 49; Iter   444/ 1097] train: loss: 0.0140441
[Epoch 49; Iter   474/ 1097] train: loss: 0.0348556
[Epoch 49; Iter   504/ 1097] train: loss: 0.0005525
[Epoch 49; Iter   534/ 1097] train: loss: 0.0175613
[Epoch 49; Iter   564/ 1097] train: loss: 0.0182395
[Epoch 49; Iter   594/ 1097] train: loss: 0.0275737
[Epoch 49; Iter   624/ 1097] train: loss: 0.0638136
[Epoch 49; Iter   654/ 1097] train: loss: 0.0002569
[Epoch 49; Iter   684/ 1097] train: loss: 0.0265299
[Epoch 49; Iter   714/ 1097] train: loss: 0.0024427
[Epoch 49; Iter   744/ 1097] train: loss: 0.0011775
[Epoch 49; Iter   774/ 1097] train: loss: 0.0014688
[Epoch 49; Iter   804/ 1097] train: loss: 0.0010559
[Epoch 49; Iter   834/ 1097] train: loss: 0.0117406
[Epoch 49; Iter   864/ 1097] train: loss: 0.0042347
[Epoch 49; Iter   894/ 1097] train: loss: 0.0020362
[Epoch 49; Iter   924/ 1097] train: loss: 0.0046353
[Epoch 49; Iter   954/ 1097] train: loss: 0.0121509
[Epoch 49; Iter   984/ 1097] train: loss: 0.0068610
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0127066
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0222582
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0049680
[Epoch 49] ogbg-molhiv: 0.813431 val loss: 0.837100
[Epoch 49] ogbg-molhiv: 0.714604 test loss: 1.116544
[Epoch 50; Iter     7/ 1097] train: loss: 0.1815769
[Epoch 50; Iter    37/ 1097] train: loss: 0.0004571
[Epoch 50; Iter    67/ 1097] train: loss: 0.0077315
[Epoch 50; Iter    97/ 1097] train: loss: 0.0026835
[Epoch 50; Iter   127/ 1097] train: loss: 0.0042007
[Epoch 50; Iter   157/ 1097] train: loss: 0.0614671
[Epoch 50; Iter   187/ 1097] train: loss: 0.0015194
[Epoch 50; Iter   217/ 1097] train: loss: 0.0022236
[Epoch 50; Iter   247/ 1097] train: loss: 0.0045644
[Epoch 50; Iter   277/ 1097] train: loss: 0.0136651
[Epoch 50; Iter   307/ 1097] train: loss: 0.0100698
[Epoch 50; Iter   337/ 1097] train: loss: 0.0037907
[Epoch 50; Iter   367/ 1097] train: loss: 0.0018795
[Epoch 50; Iter   397/ 1097] train: loss: 0.0006642
[Epoch 50; Iter   427/ 1097] train: loss: 0.1324256
[Epoch 50; Iter   457/ 1097] train: loss: 0.0011244
[Epoch 50; Iter   487/ 1097] train: loss: 0.0483832
[Epoch 50; Iter   517/ 1097] train: loss: 0.0156303
[Epoch 50; Iter   547/ 1097] train: loss: 0.0007248
[Epoch 50; Iter   577/ 1097] train: loss: 0.0957290
[Epoch 50; Iter   607/ 1097] train: loss: 0.0010061
[Epoch 50; Iter   637/ 1097] train: loss: 0.0009013
[Epoch 50; Iter   667/ 1097] train: loss: 0.0987382
[Epoch 50; Iter   697/ 1097] train: loss: 0.0021719
[Epoch 50; Iter   727/ 1097] train: loss: 0.0860136
[Epoch 50; Iter   757/ 1097] train: loss: 0.0039246
[Epoch 50; Iter   787/ 1097] train: loss: 0.0345249
[Epoch 50; Iter   817/ 1097] train: loss: 0.0205113
[Epoch 50; Iter   847/ 1097] train: loss: 0.0113242
[Epoch 50; Iter   877/ 1097] train: loss: 0.0147883
[Epoch 50; Iter   907/ 1097] train: loss: 0.0445063
[Epoch 50; Iter   937/ 1097] train: loss: 0.0030352
[Epoch 50; Iter   967/ 1097] train: loss: 0.0023233
[Epoch 50; Iter   997/ 1097] train: loss: 0.0065944
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0407175
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0012892
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0039254
[Epoch 50] ogbg-molhiv: 0.809395 val loss: 1.280258
[Epoch 50] ogbg-molhiv: 0.694283 test loss: 1.479408
[Epoch 51; Iter    20/ 1097] train: loss: 0.0115575
[Epoch 51; Iter    50/ 1097] train: loss: 0.0007927
[Epoch 51; Iter    80/ 1097] train: loss: 0.0003598
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007443
[Epoch 51; Iter   140/ 1097] train: loss: 0.0008905
[Epoch 51; Iter   170/ 1097] train: loss: 0.0010967
[Epoch 51; Iter   200/ 1097] train: loss: 0.0106032
[Epoch 51; Iter   230/ 1097] train: loss: 0.0043396
[Epoch 51; Iter   260/ 1097] train: loss: 0.0015588
[Epoch 51; Iter   290/ 1097] train: loss: 0.0021934
[Epoch 51; Iter   320/ 1097] train: loss: 0.0059629
[Epoch 51; Iter   350/ 1097] train: loss: 0.0021473
[Epoch 51; Iter   380/ 1097] train: loss: 0.0026663
[Epoch 51; Iter   410/ 1097] train: loss: 0.0041796
[Epoch 51; Iter   440/ 1097] train: loss: 0.0002713
[Epoch 51; Iter   470/ 1097] train: loss: 0.0007784
[Epoch 51; Iter   500/ 1097] train: loss: 0.0028474
[Epoch 51; Iter   530/ 1097] train: loss: 0.0147508
[Epoch 51; Iter   560/ 1097] train: loss: 0.0003017
[Epoch 51; Iter   590/ 1097] train: loss: 0.0027283
[Epoch 51; Iter   620/ 1097] train: loss: 0.0110150
[Epoch 51; Iter   650/ 1097] train: loss: 0.0018536
[Epoch 51; Iter   680/ 1097] train: loss: 0.0008151
[Epoch 51; Iter   710/ 1097] train: loss: 0.0137411
[Epoch 51; Iter   740/ 1097] train: loss: 0.1048398
[Epoch 51; Iter   770/ 1097] train: loss: 0.0781989
[Epoch 51; Iter   800/ 1097] train: loss: 0.0318972
[Epoch 51; Iter   830/ 1097] train: loss: 0.0240946
[Epoch 51; Iter   860/ 1097] train: loss: 0.0036665
[Epoch 51; Iter   890/ 1097] train: loss: 0.0005394
[Epoch 51; Iter   920/ 1097] train: loss: 0.0009819
[Epoch 51; Iter   950/ 1097] train: loss: 0.0008670
[Epoch 51; Iter   980/ 1097] train: loss: 0.0832643
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0052293
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0020471
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0094628
[Epoch 51] ogbg-molhiv: 0.748417 val loss: 1.264959
[Epoch 51] ogbg-molhiv: 0.691240 test loss: 1.197027
[Epoch 52; Iter     3/ 1097] train: loss: 0.0690738
[Epoch 52; Iter    33/ 1097] train: loss: 0.0244438
[Epoch 52; Iter    63/ 1097] train: loss: 0.0007137
[Epoch 52; Iter    93/ 1097] train: loss: 0.0063500
[Epoch 52; Iter   123/ 1097] train: loss: 0.0007458
[Epoch 52; Iter   153/ 1097] train: loss: 0.0063520
[Epoch 52; Iter   183/ 1097] train: loss: 0.0220863
[Epoch 52; Iter   213/ 1097] train: loss: 0.0018869
[Epoch 52; Iter   243/ 1097] train: loss: 0.0791178
[Epoch 52; Iter   273/ 1097] train: loss: 0.0104108
[Epoch 52; Iter   303/ 1097] train: loss: 0.0215510
[Epoch 52; Iter   333/ 1097] train: loss: 0.0039368
[Epoch 52; Iter   363/ 1097] train: loss: 0.0064809
[Epoch 52; Iter   393/ 1097] train: loss: 0.0006158
[Epoch 52; Iter   423/ 1097] train: loss: 0.0058533
[Epoch 52; Iter   453/ 1097] train: loss: 0.0036998
[Epoch 52; Iter   483/ 1097] train: loss: 0.0128649
[Epoch 52; Iter   513/ 1097] train: loss: 0.1607540
[Epoch 52; Iter   543/ 1097] train: loss: 0.1318447
[Epoch 52; Iter   573/ 1097] train: loss: 0.0077553
[Epoch 52; Iter   603/ 1097] train: loss: 0.0010563
[Epoch 52; Iter   633/ 1097] train: loss: 0.0324895
[Epoch 52; Iter   663/ 1097] train: loss: 0.0058588
[Epoch 52; Iter   693/ 1097] train: loss: 0.0004880
[Epoch 52; Iter   723/ 1097] train: loss: 0.0031886
[Epoch 52; Iter   753/ 1097] train: loss: 0.0060255
[Epoch 52; Iter   783/ 1097] train: loss: 0.0025347
[Epoch 52; Iter   813/ 1097] train: loss: 0.0005531
[Epoch 52; Iter   843/ 1097] train: loss: 0.0009180
[Epoch 52; Iter   873/ 1097] train: loss: 0.0024538
[Epoch 52; Iter   903/ 1097] train: loss: 0.0002667
[Epoch 48; Iter   851/ 1097] train: loss: 0.0003453
[Epoch 48; Iter   881/ 1097] train: loss: 0.0448932
[Epoch 48; Iter   911/ 1097] train: loss: 0.0569667
[Epoch 48; Iter   941/ 1097] train: loss: 0.0837456
[Epoch 48; Iter   971/ 1097] train: loss: 0.0037454
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0028032
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0070733
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0140456
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0006198
[Epoch 48] ogbg-molhiv: 0.790016 val loss: 1.574894
[Epoch 48] ogbg-molhiv: 0.695102 test loss: 0.325529
[Epoch 49; Iter    24/ 1097] train: loss: 0.0013182
[Epoch 49; Iter    54/ 1097] train: loss: 0.0260678
[Epoch 49; Iter    84/ 1097] train: loss: 0.0003762
[Epoch 49; Iter   114/ 1097] train: loss: 0.0694206
[Epoch 49; Iter   144/ 1097] train: loss: 0.0003196
[Epoch 49; Iter   174/ 1097] train: loss: 0.0012855
[Epoch 49; Iter   204/ 1097] train: loss: 0.0201619
[Epoch 49; Iter   234/ 1097] train: loss: 0.0014634
[Epoch 49; Iter   264/ 1097] train: loss: 0.0100968
[Epoch 49; Iter   294/ 1097] train: loss: 0.0646336
[Epoch 49; Iter   324/ 1097] train: loss: 0.0001675
[Epoch 49; Iter   354/ 1097] train: loss: 0.0185953
[Epoch 49; Iter   384/ 1097] train: loss: 0.0346237
[Epoch 49; Iter   414/ 1097] train: loss: 0.0020259
[Epoch 49; Iter   444/ 1097] train: loss: 0.0068633
[Epoch 49; Iter   474/ 1097] train: loss: 0.0774070
[Epoch 49; Iter   504/ 1097] train: loss: 0.0141482
[Epoch 49; Iter   534/ 1097] train: loss: 0.0376750
[Epoch 49; Iter   564/ 1097] train: loss: 0.0071573
[Epoch 49; Iter   594/ 1097] train: loss: 0.0040678
[Epoch 49; Iter   624/ 1097] train: loss: 0.0126894
[Epoch 49; Iter   654/ 1097] train: loss: 0.0011323
[Epoch 49; Iter   684/ 1097] train: loss: 0.0132431
[Epoch 49; Iter   714/ 1097] train: loss: 0.0046436
[Epoch 49; Iter   744/ 1097] train: loss: 0.0118381
[Epoch 49; Iter   774/ 1097] train: loss: 0.0186205
[Epoch 49; Iter   804/ 1097] train: loss: 0.1998811
[Epoch 49; Iter   834/ 1097] train: loss: 0.0078483
[Epoch 49; Iter   864/ 1097] train: loss: 0.0028808
[Epoch 49; Iter   894/ 1097] train: loss: 0.0016460
[Epoch 49; Iter   924/ 1097] train: loss: 0.0482261
[Epoch 49; Iter   954/ 1097] train: loss: 0.0183625
[Epoch 49; Iter   984/ 1097] train: loss: 0.0016322
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0028199
[Epoch 49; Iter  1044/ 1097] train: loss: 0.1369659
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0019775
[Epoch 49] ogbg-molhiv: 0.756589 val loss: 2.238944
[Epoch 49] ogbg-molhiv: 0.682024 test loss: 0.410368
[Epoch 50; Iter     7/ 1097] train: loss: 0.0257367
[Epoch 50; Iter    37/ 1097] train: loss: 0.0149765
[Epoch 50; Iter    67/ 1097] train: loss: 0.0107810
[Epoch 50; Iter    97/ 1097] train: loss: 0.0020066
[Epoch 50; Iter   127/ 1097] train: loss: 0.0013108
[Epoch 50; Iter   157/ 1097] train: loss: 0.0432415
[Epoch 50; Iter   187/ 1097] train: loss: 0.0140973
[Epoch 50; Iter   217/ 1097] train: loss: 0.0010628
[Epoch 50; Iter   247/ 1097] train: loss: 0.0029104
[Epoch 50; Iter   277/ 1097] train: loss: 0.0012172
[Epoch 50; Iter   307/ 1097] train: loss: 0.1209538
[Epoch 50; Iter   337/ 1097] train: loss: 0.0082783
[Epoch 50; Iter   367/ 1097] train: loss: 0.0002462
[Epoch 50; Iter   397/ 1097] train: loss: 0.0210362
[Epoch 50; Iter   427/ 1097] train: loss: 0.0007889
[Epoch 50; Iter   457/ 1097] train: loss: 0.0021985
[Epoch 50; Iter   487/ 1097] train: loss: 0.0051056
[Epoch 50; Iter   517/ 1097] train: loss: 0.0014539
[Epoch 50; Iter   547/ 1097] train: loss: 0.0035384
[Epoch 50; Iter   577/ 1097] train: loss: 0.0006924
[Epoch 50; Iter   607/ 1097] train: loss: 0.0004859
[Epoch 50; Iter   637/ 1097] train: loss: 0.1899315
[Epoch 50; Iter   667/ 1097] train: loss: 0.0001121
[Epoch 50; Iter   697/ 1097] train: loss: 0.0013000
[Epoch 50; Iter   727/ 1097] train: loss: 0.0023818
[Epoch 50; Iter   757/ 1097] train: loss: 0.0017067
[Epoch 50; Iter   787/ 1097] train: loss: 0.0382117
[Epoch 50; Iter   817/ 1097] train: loss: 0.0355613
[Epoch 50; Iter   847/ 1097] train: loss: 0.0030952
[Epoch 50; Iter   877/ 1097] train: loss: 0.0001875
[Epoch 50; Iter   907/ 1097] train: loss: 0.0005045
[Epoch 50; Iter   937/ 1097] train: loss: 0.0025228
[Epoch 50; Iter   967/ 1097] train: loss: 0.0010212
[Epoch 50; Iter   997/ 1097] train: loss: 0.0009384
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0769477
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0031730
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0014531
[Epoch 50] ogbg-molhiv: 0.777214 val loss: 1.657887
[Epoch 50] ogbg-molhiv: 0.680415 test loss: 0.400297
[Epoch 51; Iter    20/ 1097] train: loss: 0.0000854
[Epoch 51; Iter    50/ 1097] train: loss: 0.0003781
[Epoch 51; Iter    80/ 1097] train: loss: 0.0013016
[Epoch 51; Iter   110/ 1097] train: loss: 0.0007573
[Epoch 51; Iter   140/ 1097] train: loss: 0.0252928
[Epoch 51; Iter   170/ 1097] train: loss: 0.0272041
[Epoch 51; Iter   200/ 1097] train: loss: 0.0055753
[Epoch 51; Iter   230/ 1097] train: loss: 0.0630813
[Epoch 51; Iter   260/ 1097] train: loss: 0.0022876
[Epoch 51; Iter   290/ 1097] train: loss: 0.0015358
[Epoch 51; Iter   320/ 1097] train: loss: 0.0086458
[Epoch 51; Iter   350/ 1097] train: loss: 0.0019294
[Epoch 51; Iter   380/ 1097] train: loss: 0.0099181
[Epoch 51; Iter   410/ 1097] train: loss: 0.0006310
[Epoch 51; Iter   440/ 1097] train: loss: 0.0537122
[Epoch 51; Iter   470/ 1097] train: loss: 0.0013352
[Epoch 51; Iter   500/ 1097] train: loss: 0.0130899
[Epoch 51; Iter   530/ 1097] train: loss: 0.0074782
[Epoch 51; Iter   560/ 1097] train: loss: 0.0013252
[Epoch 51; Iter   590/ 1097] train: loss: 0.0076483
[Epoch 51; Iter   620/ 1097] train: loss: 0.0082814
[Epoch 51; Iter   650/ 1097] train: loss: 0.0037314
[Epoch 51; Iter   680/ 1097] train: loss: 0.0047142
[Epoch 51; Iter   710/ 1097] train: loss: 0.0342213
[Epoch 51; Iter   740/ 1097] train: loss: 0.0008453
[Epoch 51; Iter   770/ 1097] train: loss: 0.0275340
[Epoch 51; Iter   800/ 1097] train: loss: 0.0002705
[Epoch 51; Iter   830/ 1097] train: loss: 0.0004000
[Epoch 51; Iter   860/ 1097] train: loss: 0.0214036
[Epoch 51; Iter   890/ 1097] train: loss: 0.0029252
[Epoch 51; Iter   920/ 1097] train: loss: 0.0045024
[Epoch 51; Iter   950/ 1097] train: loss: 0.0009087
[Epoch 51; Iter   980/ 1097] train: loss: 0.0034185
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0239093
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0014904
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0051412
[Epoch 51] ogbg-molhiv: 0.783424 val loss: 1.284381
[Epoch 51] ogbg-molhiv: 0.691582 test loss: 0.301509
[Epoch 52; Iter     3/ 1097] train: loss: 0.0124275
[Epoch 52; Iter    33/ 1097] train: loss: 0.3097504
[Epoch 52; Iter    63/ 1097] train: loss: 0.0003081
[Epoch 52; Iter    93/ 1097] train: loss: 0.0607350
[Epoch 52; Iter   123/ 1097] train: loss: 0.0020515
[Epoch 52; Iter   153/ 1097] train: loss: 0.0149591
[Epoch 52; Iter   183/ 1097] train: loss: 0.0003380
[Epoch 52; Iter   213/ 1097] train: loss: 0.0015801
[Epoch 52; Iter   243/ 1097] train: loss: 0.0048307
[Epoch 52; Iter   273/ 1097] train: loss: 0.0021130
[Epoch 52; Iter   303/ 1097] train: loss: 0.0212590
[Epoch 52; Iter   333/ 1097] train: loss: 0.0002979
[Epoch 52; Iter   363/ 1097] train: loss: 0.0007210
[Epoch 52; Iter   393/ 1097] train: loss: 0.0007719
[Epoch 52; Iter   423/ 1097] train: loss: 0.0032471
[Epoch 52; Iter   453/ 1097] train: loss: 0.0005651
[Epoch 52; Iter   483/ 1097] train: loss: 0.0024314
[Epoch 52; Iter   513/ 1097] train: loss: 0.0028284
[Epoch 52; Iter   543/ 1097] train: loss: 0.0028461
[Epoch 52; Iter   573/ 1097] train: loss: 0.0009254
[Epoch 52; Iter   603/ 1097] train: loss: 0.0039269
[Epoch 52; Iter   633/ 1097] train: loss: 0.0249331
[Epoch 52; Iter   663/ 1097] train: loss: 0.0013199
[Epoch 52; Iter   693/ 1097] train: loss: 0.0078618
[Epoch 52; Iter   723/ 1097] train: loss: 0.0012945
[Epoch 52; Iter   753/ 1097] train: loss: 0.0300868
[Epoch 52; Iter   783/ 1097] train: loss: 0.0183716
[Epoch 52; Iter   813/ 1097] train: loss: 0.0014894
[Epoch 52; Iter   843/ 1097] train: loss: 0.0115731
[Epoch 52; Iter   873/ 1097] train: loss: 0.0934560
[Epoch 52; Iter   903/ 1097] train: loss: 0.0886745
[Epoch 48; Iter   881/ 1097] train: loss: 0.0084287
[Epoch 48; Iter   911/ 1097] train: loss: 0.0233808
[Epoch 48; Iter   941/ 1097] train: loss: 0.0008048
[Epoch 48; Iter   971/ 1097] train: loss: 0.0007918
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0236587
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0013861
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0001749
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0039912
[Epoch 48] ogbg-molhiv: 0.724675 val loss: 2.571483
[Epoch 48] ogbg-molhiv: 0.698974 test loss: 0.778907
[Epoch 49; Iter    24/ 1097] train: loss: 0.0022237
[Epoch 49; Iter    54/ 1097] train: loss: 0.0009795
[Epoch 49; Iter    84/ 1097] train: loss: 0.0003408
[Epoch 49; Iter   114/ 1097] train: loss: 0.0024696
[Epoch 49; Iter   144/ 1097] train: loss: 0.0033973
[Epoch 49; Iter   174/ 1097] train: loss: 0.0022786
[Epoch 49; Iter   204/ 1097] train: loss: 0.0006591
[Epoch 49; Iter   234/ 1097] train: loss: 0.0018449
[Epoch 49; Iter   264/ 1097] train: loss: 0.0180396
[Epoch 49; Iter   294/ 1097] train: loss: 0.0049226
[Epoch 49; Iter   324/ 1097] train: loss: 0.0054315
[Epoch 49; Iter   354/ 1097] train: loss: 0.0039081
[Epoch 49; Iter   384/ 1097] train: loss: 0.0127953
[Epoch 49; Iter   414/ 1097] train: loss: 0.0010034
[Epoch 49; Iter   444/ 1097] train: loss: 0.0165905
[Epoch 49; Iter   474/ 1097] train: loss: 0.0015490
[Epoch 49; Iter   504/ 1097] train: loss: 0.0026170
[Epoch 49; Iter   534/ 1097] train: loss: 0.0029853
[Epoch 49; Iter   564/ 1097] train: loss: 0.0361788
[Epoch 49; Iter   594/ 1097] train: loss: 0.0018952
[Epoch 49; Iter   624/ 1097] train: loss: 0.0080020
[Epoch 49; Iter   654/ 1097] train: loss: 0.0080003
[Epoch 49; Iter   684/ 1097] train: loss: 0.0038532
[Epoch 49; Iter   714/ 1097] train: loss: 0.0038813
[Epoch 49; Iter   744/ 1097] train: loss: 0.0004357
[Epoch 49; Iter   774/ 1097] train: loss: 0.0114000
[Epoch 49; Iter   804/ 1097] train: loss: 0.0049691
[Epoch 49; Iter   834/ 1097] train: loss: 0.0207978
[Epoch 49; Iter   864/ 1097] train: loss: 0.0053911
[Epoch 49; Iter   894/ 1097] train: loss: 0.0015460
[Epoch 49; Iter   924/ 1097] train: loss: 0.0086126
[Epoch 49; Iter   954/ 1097] train: loss: 0.0044308
[Epoch 49; Iter   984/ 1097] train: loss: 0.0017949
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0009912
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0023885
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0009384
[Epoch 49] ogbg-molhiv: 0.711570 val loss: 3.800753
[Epoch 49] ogbg-molhiv: 0.677786 test loss: 1.504489
[Epoch 50; Iter     7/ 1097] train: loss: 0.0135909
[Epoch 50; Iter    37/ 1097] train: loss: 0.0029600
[Epoch 50; Iter    67/ 1097] train: loss: 0.0045778
[Epoch 50; Iter    97/ 1097] train: loss: 0.0089487
[Epoch 50; Iter   127/ 1097] train: loss: 0.0118267
[Epoch 50; Iter   157/ 1097] train: loss: 0.0062641
[Epoch 50; Iter   187/ 1097] train: loss: 0.0050388
[Epoch 50; Iter   217/ 1097] train: loss: 0.0156975
[Epoch 50; Iter   247/ 1097] train: loss: 0.0003316
[Epoch 50; Iter   277/ 1097] train: loss: 0.0007596
[Epoch 50; Iter   307/ 1097] train: loss: 0.0012949
[Epoch 50; Iter   337/ 1097] train: loss: 0.0004342
[Epoch 50; Iter   367/ 1097] train: loss: 0.0175950
[Epoch 50; Iter   397/ 1097] train: loss: 0.0042054
[Epoch 50; Iter   427/ 1097] train: loss: 0.0011025
[Epoch 50; Iter   457/ 1097] train: loss: 0.0126352
[Epoch 50; Iter   487/ 1097] train: loss: 0.0080674
[Epoch 50; Iter   517/ 1097] train: loss: 0.0068291
[Epoch 50; Iter   547/ 1097] train: loss: 0.0536729
[Epoch 50; Iter   577/ 1097] train: loss: 0.0289486
[Epoch 50; Iter   607/ 1097] train: loss: 0.0023649
[Epoch 50; Iter   637/ 1097] train: loss: 0.0138805
[Epoch 50; Iter   667/ 1097] train: loss: 0.0118174
[Epoch 50; Iter   697/ 1097] train: loss: 0.0247468
[Epoch 50; Iter   727/ 1097] train: loss: 0.0059094
[Epoch 50; Iter   757/ 1097] train: loss: 0.0074359
[Epoch 50; Iter   787/ 1097] train: loss: 0.0050738
[Epoch 50; Iter   817/ 1097] train: loss: 0.0061296
[Epoch 50; Iter   847/ 1097] train: loss: 0.0971219
[Epoch 50; Iter   877/ 1097] train: loss: 0.0036192
[Epoch 50; Iter   907/ 1097] train: loss: 0.0327882
[Epoch 50; Iter   937/ 1097] train: loss: 0.0004805
[Epoch 50; Iter   967/ 1097] train: loss: 0.0021884
[Epoch 50; Iter   997/ 1097] train: loss: 0.1063514
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0213586
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0009383
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0733030
[Epoch 50] ogbg-molhiv: 0.714371 val loss: 2.991826
[Epoch 50] ogbg-molhiv: 0.683802 test loss: 1.384204
[Epoch 51; Iter    20/ 1097] train: loss: 0.0412767
[Epoch 51; Iter    50/ 1097] train: loss: 0.0039964
[Epoch 51; Iter    80/ 1097] train: loss: 0.0014502
[Epoch 51; Iter   110/ 1097] train: loss: 0.0013059
[Epoch 51; Iter   140/ 1097] train: loss: 0.0217761
[Epoch 51; Iter   170/ 1097] train: loss: 0.0081300
[Epoch 51; Iter   200/ 1097] train: loss: 0.0221183
[Epoch 51; Iter   230/ 1097] train: loss: 0.0102135
[Epoch 51; Iter   260/ 1097] train: loss: 0.0052050
[Epoch 51; Iter   290/ 1097] train: loss: 0.0033542
[Epoch 51; Iter   320/ 1097] train: loss: 0.0010869
[Epoch 51; Iter   350/ 1097] train: loss: 0.0016110
[Epoch 51; Iter   380/ 1097] train: loss: 0.0010934
[Epoch 51; Iter   410/ 1097] train: loss: 0.0019043
[Epoch 51; Iter   440/ 1097] train: loss: 0.0590876
[Epoch 51; Iter   470/ 1097] train: loss: 0.0421855
[Epoch 51; Iter   500/ 1097] train: loss: 0.0062282
[Epoch 51; Iter   530/ 1097] train: loss: 0.0320041
[Epoch 51; Iter   560/ 1097] train: loss: 0.0387262
[Epoch 51; Iter   590/ 1097] train: loss: 0.0317162
[Epoch 51; Iter   620/ 1097] train: loss: 0.0320916
[Epoch 51; Iter   650/ 1097] train: loss: 0.0029447
[Epoch 51; Iter   680/ 1097] train: loss: 0.0053236
[Epoch 51; Iter   710/ 1097] train: loss: 0.0059676
[Epoch 51; Iter   740/ 1097] train: loss: 0.0001806
[Epoch 51; Iter   770/ 1097] train: loss: 0.0024391
[Epoch 51; Iter   800/ 1097] train: loss: 0.0005853
[Epoch 51; Iter   830/ 1097] train: loss: 0.0098793
[Epoch 51; Iter   860/ 1097] train: loss: 0.0036404
[Epoch 51; Iter   890/ 1097] train: loss: 0.0106631
[Epoch 51; Iter   920/ 1097] train: loss: 0.0009036
[Epoch 51; Iter   950/ 1097] train: loss: 0.1423400
[Epoch 51; Iter   980/ 1097] train: loss: 0.0034447
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0163987
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0009136
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0016309
[Epoch 51] ogbg-molhiv: 0.686578 val loss: 0.227030
[Epoch 51] ogbg-molhiv: 0.691056 test loss: 0.341997
[Epoch 52; Iter     3/ 1097] train: loss: 0.0013779
[Epoch 52; Iter    33/ 1097] train: loss: 0.0112409
[Epoch 52; Iter    63/ 1097] train: loss: 0.0062954
[Epoch 52; Iter    93/ 1097] train: loss: 0.0037678
[Epoch 52; Iter   123/ 1097] train: loss: 0.0300394
[Epoch 52; Iter   153/ 1097] train: loss: 0.0032304
[Epoch 52; Iter   183/ 1097] train: loss: 0.0003119
[Epoch 52; Iter   213/ 1097] train: loss: 0.0011444
[Epoch 52; Iter   243/ 1097] train: loss: 0.0054108
[Epoch 52; Iter   273/ 1097] train: loss: 0.0006731
[Epoch 52; Iter   303/ 1097] train: loss: 0.0033677
[Epoch 52; Iter   333/ 1097] train: loss: 0.0072534
[Epoch 52; Iter   363/ 1097] train: loss: 0.0036622
[Epoch 52; Iter   393/ 1097] train: loss: 0.0244786
[Epoch 52; Iter   423/ 1097] train: loss: 0.0105289
[Epoch 52; Iter   453/ 1097] train: loss: 0.0002895
[Epoch 52; Iter   483/ 1097] train: loss: 0.0387704
[Epoch 52; Iter   513/ 1097] train: loss: 0.0008174
[Epoch 52; Iter   543/ 1097] train: loss: 0.0236732
[Epoch 52; Iter   573/ 1097] train: loss: 0.0013801
[Epoch 52; Iter   603/ 1097] train: loss: 0.0021654
[Epoch 52; Iter   633/ 1097] train: loss: 0.0006907
[Epoch 52; Iter   663/ 1097] train: loss: 0.0020234
[Epoch 52; Iter   693/ 1097] train: loss: 0.0534925
[Epoch 52; Iter   723/ 1097] train: loss: 0.0009764
[Epoch 52; Iter   753/ 1097] train: loss: 0.0022775
[Epoch 52; Iter   783/ 1097] train: loss: 0.0217165
[Epoch 52; Iter   813/ 1097] train: loss: 0.0018710
[Epoch 52; Iter   843/ 1097] train: loss: 0.0086927
[Epoch 52; Iter   873/ 1097] train: loss: 0.0017012
[Epoch 52; Iter   903/ 1097] train: loss: 0.0017822
[Epoch 52; Iter   933/ 1097] train: loss: 0.0582430
[Epoch 48; Iter   881/ 1097] train: loss: 0.0150617
[Epoch 48; Iter   911/ 1097] train: loss: 0.0067722
[Epoch 48; Iter   941/ 1097] train: loss: 0.0011208
[Epoch 48; Iter   971/ 1097] train: loss: 0.0004423
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0014606
[Epoch 48; Iter  1031/ 1097] train: loss: 0.1102997
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0012898
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0006037
[Epoch 48] ogbg-molhiv: 0.751494 val loss: 0.460250
[Epoch 48] ogbg-molhiv: 0.720497 test loss: 0.621820
[Epoch 49; Iter    24/ 1097] train: loss: 0.0004292
[Epoch 49; Iter    54/ 1097] train: loss: 0.0001060
[Epoch 49; Iter    84/ 1097] train: loss: 0.0003026
[Epoch 49; Iter   114/ 1097] train: loss: 0.0285642
[Epoch 49; Iter   144/ 1097] train: loss: 0.0604726
[Epoch 49; Iter   174/ 1097] train: loss: 0.0103399
[Epoch 49; Iter   204/ 1097] train: loss: 0.0021064
[Epoch 49; Iter   234/ 1097] train: loss: 0.0322489
[Epoch 49; Iter   264/ 1097] train: loss: 0.0107566
[Epoch 49; Iter   294/ 1097] train: loss: 0.0151059
[Epoch 49; Iter   324/ 1097] train: loss: 0.0027300
[Epoch 49; Iter   354/ 1097] train: loss: 0.0308281
[Epoch 49; Iter   384/ 1097] train: loss: 0.0006489
[Epoch 49; Iter   414/ 1097] train: loss: 0.0864280
[Epoch 49; Iter   444/ 1097] train: loss: 0.2107276
[Epoch 49; Iter   474/ 1097] train: loss: 0.0135553
[Epoch 49; Iter   504/ 1097] train: loss: 0.0001605
[Epoch 49; Iter   534/ 1097] train: loss: 0.0128199
[Epoch 49; Iter   564/ 1097] train: loss: 0.0169627
[Epoch 49; Iter   594/ 1097] train: loss: 0.0044934
[Epoch 49; Iter   624/ 1097] train: loss: 0.1069458
[Epoch 49; Iter   654/ 1097] train: loss: 0.0679775
[Epoch 49; Iter   684/ 1097] train: loss: 0.0329944
[Epoch 49; Iter   714/ 1097] train: loss: 0.0006529
[Epoch 49; Iter   744/ 1097] train: loss: 0.0016600
[Epoch 49; Iter   774/ 1097] train: loss: 0.0169541
[Epoch 49; Iter   804/ 1097] train: loss: 0.0299603
[Epoch 49; Iter   834/ 1097] train: loss: 0.0019362
[Epoch 49; Iter   864/ 1097] train: loss: 0.0047740
[Epoch 49; Iter   894/ 1097] train: loss: 0.0005019
[Epoch 49; Iter   924/ 1097] train: loss: 0.0009688
[Epoch 49; Iter   954/ 1097] train: loss: 0.0106032
[Epoch 49; Iter   984/ 1097] train: loss: 0.0113250
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0012804
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0018475
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0152872
[Epoch 49] ogbg-molhiv: 0.761436 val loss: 0.279727
[Epoch 49] ogbg-molhiv: 0.728152 test loss: 0.398794
[Epoch 50; Iter     7/ 1097] train: loss: 0.1782497
[Epoch 50; Iter    37/ 1097] train: loss: 0.0041494
[Epoch 50; Iter    67/ 1097] train: loss: 0.0009787
[Epoch 50; Iter    97/ 1097] train: loss: 0.0021841
[Epoch 50; Iter   127/ 1097] train: loss: 0.0274367
[Epoch 50; Iter   157/ 1097] train: loss: 0.0015867
[Epoch 50; Iter   187/ 1097] train: loss: 0.0024101
[Epoch 50; Iter   217/ 1097] train: loss: 0.0003993
[Epoch 50; Iter   247/ 1097] train: loss: 0.0002282
[Epoch 50; Iter   277/ 1097] train: loss: 0.0032929
[Epoch 50; Iter   307/ 1097] train: loss: 0.0001843
[Epoch 50; Iter   337/ 1097] train: loss: 0.0007469
[Epoch 50; Iter   367/ 1097] train: loss: 0.0011534
[Epoch 50; Iter   397/ 1097] train: loss: 0.0105812
[Epoch 50; Iter   427/ 1097] train: loss: 0.0060275
[Epoch 50; Iter   457/ 1097] train: loss: 0.0014604
[Epoch 50; Iter   487/ 1097] train: loss: 0.0011635
[Epoch 50; Iter   517/ 1097] train: loss: 0.0039566
[Epoch 50; Iter   547/ 1097] train: loss: 0.0103782
[Epoch 50; Iter   577/ 1097] train: loss: 0.0005564
[Epoch 50; Iter   607/ 1097] train: loss: 0.0329158
[Epoch 50; Iter   637/ 1097] train: loss: 0.0018328
[Epoch 50; Iter   667/ 1097] train: loss: 0.0053787
[Epoch 50; Iter   697/ 1097] train: loss: 0.0055395
[Epoch 50; Iter   727/ 1097] train: loss: 0.0341329
[Epoch 50; Iter   757/ 1097] train: loss: 0.0051484
[Epoch 50; Iter   787/ 1097] train: loss: 0.0005898
[Epoch 50; Iter   817/ 1097] train: loss: 0.0010376
[Epoch 50; Iter   847/ 1097] train: loss: 0.0059886
[Epoch 50; Iter   877/ 1097] train: loss: 0.0391296
[Epoch 50; Iter   907/ 1097] train: loss: 0.0030831
[Epoch 50; Iter   937/ 1097] train: loss: 0.0093588
[Epoch 50; Iter   967/ 1097] train: loss: 0.0070674
[Epoch 50; Iter   997/ 1097] train: loss: 0.0018780
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0617295
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0009315
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0005090
[Epoch 50] ogbg-molhiv: 0.755560 val loss: 1.484083
[Epoch 50] ogbg-molhiv: 0.722851 test loss: 1.530072
[Epoch 51; Iter    20/ 1097] train: loss: 0.0010360
[Epoch 51; Iter    50/ 1097] train: loss: 0.0061576
[Epoch 51; Iter    80/ 1097] train: loss: 0.0036399
[Epoch 51; Iter   110/ 1097] train: loss: 0.0009320
[Epoch 51; Iter   140/ 1097] train: loss: 0.0004656
[Epoch 51; Iter   170/ 1097] train: loss: 0.0040006
[Epoch 51; Iter   200/ 1097] train: loss: 0.0023580
[Epoch 51; Iter   230/ 1097] train: loss: 0.0003440
[Epoch 51; Iter   260/ 1097] train: loss: 0.0005183
[Epoch 51; Iter   290/ 1097] train: loss: 0.0448917
[Epoch 51; Iter   320/ 1097] train: loss: 0.0412165
[Epoch 51; Iter   350/ 1097] train: loss: 0.0003171
[Epoch 51; Iter   380/ 1097] train: loss: 0.0099832
[Epoch 51; Iter   410/ 1097] train: loss: 0.0050478
[Epoch 51; Iter   440/ 1097] train: loss: 0.0045591
[Epoch 51; Iter   470/ 1097] train: loss: 0.0007553
[Epoch 51; Iter   500/ 1097] train: loss: 0.0028355
[Epoch 51; Iter   530/ 1097] train: loss: 0.0256519
[Epoch 51; Iter   560/ 1097] train: loss: 0.0603532
[Epoch 51; Iter   590/ 1097] train: loss: 0.0464787
[Epoch 51; Iter   620/ 1097] train: loss: 0.0075903
[Epoch 51; Iter   650/ 1097] train: loss: 0.0006816
[Epoch 51; Iter   680/ 1097] train: loss: 0.0110159
[Epoch 51; Iter   710/ 1097] train: loss: 0.0173460
[Epoch 51; Iter   740/ 1097] train: loss: 0.0053608
[Epoch 51; Iter   770/ 1097] train: loss: 0.0039147
[Epoch 51; Iter   800/ 1097] train: loss: 0.0111751
[Epoch 51; Iter   830/ 1097] train: loss: 0.0003185
[Epoch 51; Iter   860/ 1097] train: loss: 0.0008640
[Epoch 51; Iter   890/ 1097] train: loss: 0.0007603
[Epoch 51; Iter   920/ 1097] train: loss: 0.0013170
[Epoch 51; Iter   950/ 1097] train: loss: 0.0008751
[Epoch 51; Iter   980/ 1097] train: loss: 0.0039063
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0034788
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0032778
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0332944
[Epoch 51] ogbg-molhiv: 0.748941 val loss: 0.478236
[Epoch 51] ogbg-molhiv: 0.717551 test loss: 0.617551
[Epoch 52; Iter     3/ 1097] train: loss: 0.0061123
[Epoch 52; Iter    33/ 1097] train: loss: 0.0050136
[Epoch 52; Iter    63/ 1097] train: loss: 0.0019049
[Epoch 52; Iter    93/ 1097] train: loss: 0.0146691
[Epoch 52; Iter   123/ 1097] train: loss: 0.0022216
[Epoch 52; Iter   153/ 1097] train: loss: 0.0003217
[Epoch 52; Iter   183/ 1097] train: loss: 0.0018405
[Epoch 52; Iter   213/ 1097] train: loss: 0.0006101
[Epoch 52; Iter   243/ 1097] train: loss: 0.0010614
[Epoch 52; Iter   273/ 1097] train: loss: 0.0001754
[Epoch 52; Iter   303/ 1097] train: loss: 0.0002400
[Epoch 52; Iter   333/ 1097] train: loss: 0.0018568
[Epoch 52; Iter   363/ 1097] train: loss: 0.0020918
[Epoch 52; Iter   393/ 1097] train: loss: 0.0013453
[Epoch 52; Iter   423/ 1097] train: loss: 0.0089943
[Epoch 52; Iter   453/ 1097] train: loss: 0.1823126
[Epoch 52; Iter   483/ 1097] train: loss: 0.0001498
[Epoch 52; Iter   513/ 1097] train: loss: 0.0041657
[Epoch 52; Iter   543/ 1097] train: loss: 0.0069755
[Epoch 52; Iter   573/ 1097] train: loss: 0.0213374
[Epoch 52; Iter   603/ 1097] train: loss: 0.0083744
[Epoch 52; Iter   633/ 1097] train: loss: 0.0722160
[Epoch 52; Iter   663/ 1097] train: loss: 0.0098572
[Epoch 52; Iter   693/ 1097] train: loss: 0.0001150
[Epoch 52; Iter   723/ 1097] train: loss: 0.0023330
[Epoch 52; Iter   753/ 1097] train: loss: 0.0027280
[Epoch 52; Iter   783/ 1097] train: loss: 0.0032203
[Epoch 52; Iter   813/ 1097] train: loss: 0.0017365
[Epoch 52; Iter   843/ 1097] train: loss: 0.0512543
[Epoch 52; Iter   873/ 1097] train: loss: 0.0026013
[Epoch 52; Iter   903/ 1097] train: loss: 0.0016066
[Epoch 52; Iter   933/ 1097] train: loss: 0.0012539
[Epoch 48; Iter   881/ 1097] train: loss: 0.0042224
[Epoch 48; Iter   911/ 1097] train: loss: 0.0021147
[Epoch 48; Iter   941/ 1097] train: loss: 0.0014079
[Epoch 48; Iter   971/ 1097] train: loss: 0.0684867
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0019033
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0051214
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0025676
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0343092
[Epoch 48] ogbg-molhiv: 0.710354 val loss: 0.213870
[Epoch 48] ogbg-molhiv: 0.729782 test loss: 0.302552
[Epoch 49; Iter    24/ 1097] train: loss: 0.0016725
[Epoch 49; Iter    54/ 1097] train: loss: 0.0003524
[Epoch 49; Iter    84/ 1097] train: loss: 0.0104027
[Epoch 49; Iter   114/ 1097] train: loss: 0.0002392
[Epoch 49; Iter   144/ 1097] train: loss: 0.0000913
[Epoch 49; Iter   174/ 1097] train: loss: 0.0029997
[Epoch 49; Iter   204/ 1097] train: loss: 0.0590579
[Epoch 49; Iter   234/ 1097] train: loss: 0.0016609
[Epoch 49; Iter   264/ 1097] train: loss: 0.0010875
[Epoch 49; Iter   294/ 1097] train: loss: 0.0041895
[Epoch 49; Iter   324/ 1097] train: loss: 0.0741053
[Epoch 49; Iter   354/ 1097] train: loss: 0.0005519
[Epoch 49; Iter   384/ 1097] train: loss: 0.0232033
[Epoch 49; Iter   414/ 1097] train: loss: 0.1262142
[Epoch 49; Iter   444/ 1097] train: loss: 0.0001025
[Epoch 49; Iter   474/ 1097] train: loss: 0.0047101
[Epoch 49; Iter   504/ 1097] train: loss: 0.0011424
[Epoch 49; Iter   534/ 1097] train: loss: 0.0021230
[Epoch 49; Iter   564/ 1097] train: loss: 0.0135860
[Epoch 49; Iter   594/ 1097] train: loss: 0.0086896
[Epoch 49; Iter   624/ 1097] train: loss: 0.0017382
[Epoch 49; Iter   654/ 1097] train: loss: 0.0004348
[Epoch 49; Iter   684/ 1097] train: loss: 0.0004417
[Epoch 49; Iter   714/ 1097] train: loss: 0.0213267
[Epoch 49; Iter   744/ 1097] train: loss: 0.0001110
[Epoch 49; Iter   774/ 1097] train: loss: 0.0002770
[Epoch 49; Iter   804/ 1097] train: loss: 0.0001902
[Epoch 49; Iter   834/ 1097] train: loss: 0.0049823
[Epoch 49; Iter   864/ 1097] train: loss: 0.0017621
[Epoch 49; Iter   894/ 1097] train: loss: 0.0046703
[Epoch 49; Iter   924/ 1097] train: loss: 0.0013466
[Epoch 49; Iter   954/ 1097] train: loss: 0.0027495
[Epoch 49; Iter   984/ 1097] train: loss: 0.0192602
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0002792
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0009379
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0266479
[Epoch 49] ogbg-molhiv: 0.729690 val loss: 0.210128
[Epoch 49] ogbg-molhiv: 0.726559 test loss: 0.324974
[Epoch 50; Iter     7/ 1097] train: loss: 0.0012051
[Epoch 50; Iter    37/ 1097] train: loss: 0.0015093
[Epoch 50; Iter    67/ 1097] train: loss: 0.0004554
[Epoch 50; Iter    97/ 1097] train: loss: 0.0021448
[Epoch 50; Iter   127/ 1097] train: loss: 0.0002696
[Epoch 50; Iter   157/ 1097] train: loss: 0.0002326
[Epoch 50; Iter   187/ 1097] train: loss: 0.0045084
[Epoch 50; Iter   217/ 1097] train: loss: 0.0005757
[Epoch 50; Iter   247/ 1097] train: loss: 0.0007220
[Epoch 50; Iter   277/ 1097] train: loss: 0.0201760
[Epoch 50; Iter   307/ 1097] train: loss: 0.0018802
[Epoch 50; Iter   337/ 1097] train: loss: 0.0006616
[Epoch 50; Iter   367/ 1097] train: loss: 0.0227785
[Epoch 50; Iter   397/ 1097] train: loss: 0.0013859
[Epoch 50; Iter   427/ 1097] train: loss: 0.0007252
[Epoch 50; Iter   457/ 1097] train: loss: 0.0020429
[Epoch 50; Iter   487/ 1097] train: loss: 0.0060320
[Epoch 50; Iter   517/ 1097] train: loss: 0.0003266
[Epoch 50; Iter   547/ 1097] train: loss: 0.0026051
[Epoch 50; Iter   577/ 1097] train: loss: 0.0018484
[Epoch 50; Iter   607/ 1097] train: loss: 0.0065364
[Epoch 50; Iter   637/ 1097] train: loss: 0.0131899
[Epoch 50; Iter   667/ 1097] train: loss: 0.0004236
[Epoch 50; Iter   697/ 1097] train: loss: 0.0001093
[Epoch 50; Iter   727/ 1097] train: loss: 0.0004597
[Epoch 50; Iter   757/ 1097] train: loss: 0.0000938
[Epoch 50; Iter   787/ 1097] train: loss: 0.0006626
[Epoch 50; Iter   817/ 1097] train: loss: 0.0026623
[Epoch 50; Iter   847/ 1097] train: loss: 0.0058076
[Epoch 50; Iter   877/ 1097] train: loss: 0.0107356
[Epoch 50; Iter   907/ 1097] train: loss: 0.0008221
[Epoch 50; Iter   937/ 1097] train: loss: 0.0023257
[Epoch 50; Iter   967/ 1097] train: loss: 0.0329000
[Epoch 50; Iter   997/ 1097] train: loss: 0.0062583
[Epoch 50; Iter  1027/ 1097] train: loss: 0.1668506
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0002571
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0013129
[Epoch 50] ogbg-molhiv: 0.690314 val loss: 0.233473
[Epoch 50] ogbg-molhiv: 0.736250 test loss: 0.318842
[Epoch 51; Iter    20/ 1097] train: loss: 0.0260679
[Epoch 51; Iter    50/ 1097] train: loss: 0.0008610
[Epoch 51; Iter    80/ 1097] train: loss: 0.0000964
[Epoch 51; Iter   110/ 1097] train: loss: 0.0090642
[Epoch 51; Iter   140/ 1097] train: loss: 0.0003191
[Epoch 51; Iter   170/ 1097] train: loss: 0.0020946
[Epoch 51; Iter   200/ 1097] train: loss: 0.0030155
[Epoch 51; Iter   230/ 1097] train: loss: 0.0108213
[Epoch 51; Iter   260/ 1097] train: loss: 0.0002016
[Epoch 51; Iter   290/ 1097] train: loss: 0.0004972
[Epoch 51; Iter   320/ 1097] train: loss: 0.0024347
[Epoch 51; Iter   350/ 1097] train: loss: 0.0001962
[Epoch 51; Iter   380/ 1097] train: loss: 0.0003899
[Epoch 51; Iter   410/ 1097] train: loss: 0.0018012
[Epoch 51; Iter   440/ 1097] train: loss: 0.0001636
[Epoch 51; Iter   470/ 1097] train: loss: 0.0112351
[Epoch 51; Iter   500/ 1097] train: loss: 0.0270540
[Epoch 51; Iter   530/ 1097] train: loss: 0.0019870
[Epoch 51; Iter   560/ 1097] train: loss: 0.0019888
[Epoch 51; Iter   590/ 1097] train: loss: 0.0246697
[Epoch 51; Iter   620/ 1097] train: loss: 0.0124383
[Epoch 51; Iter   650/ 1097] train: loss: 0.0011249
[Epoch 51; Iter   680/ 1097] train: loss: 0.0138937
[Epoch 51; Iter   710/ 1097] train: loss: 0.0028397
[Epoch 51; Iter   740/ 1097] train: loss: 0.0006605
[Epoch 51; Iter   770/ 1097] train: loss: 0.0246814
[Epoch 51; Iter   800/ 1097] train: loss: 0.2503860
[Epoch 51; Iter   830/ 1097] train: loss: 0.0017755
[Epoch 51; Iter   860/ 1097] train: loss: 0.2953911
[Epoch 51; Iter   890/ 1097] train: loss: 0.0051204
[Epoch 51; Iter   920/ 1097] train: loss: 0.0067677
[Epoch 51; Iter   950/ 1097] train: loss: 0.0132536
[Epoch 51; Iter   980/ 1097] train: loss: 0.0025045
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0005642
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0001537
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0001381
[Epoch 51] ogbg-molhiv: 0.722271 val loss: 0.198372
[Epoch 51] ogbg-molhiv: 0.734493 test loss: 0.302117
[Epoch 52; Iter     3/ 1097] train: loss: 0.0017939
[Epoch 52; Iter    33/ 1097] train: loss: 0.0012714
[Epoch 52; Iter    63/ 1097] train: loss: 0.0002184
[Epoch 52; Iter    93/ 1097] train: loss: 0.0005812
[Epoch 52; Iter   123/ 1097] train: loss: 0.0001185
[Epoch 52; Iter   153/ 1097] train: loss: 0.0003148
[Epoch 52; Iter   183/ 1097] train: loss: 0.0004027
[Epoch 52; Iter   213/ 1097] train: loss: 0.0002633
[Epoch 52; Iter   243/ 1097] train: loss: 0.0008452
[Epoch 52; Iter   273/ 1097] train: loss: 0.0001434
[Epoch 52; Iter   303/ 1097] train: loss: 0.0014926
[Epoch 52; Iter   333/ 1097] train: loss: 0.0001678
[Epoch 52; Iter   363/ 1097] train: loss: 0.0003294
[Epoch 52; Iter   393/ 1097] train: loss: 0.0323404
[Epoch 52; Iter   423/ 1097] train: loss: 0.0229630
[Epoch 52; Iter   453/ 1097] train: loss: 0.0111349
[Epoch 52; Iter   483/ 1097] train: loss: 0.0299065
[Epoch 52; Iter   513/ 1097] train: loss: 0.0280619
[Epoch 52; Iter   543/ 1097] train: loss: 0.0019568
[Epoch 52; Iter   573/ 1097] train: loss: 0.0075981
[Epoch 52; Iter   603/ 1097] train: loss: 0.0000681
[Epoch 52; Iter   633/ 1097] train: loss: 0.0018246
[Epoch 52; Iter   663/ 1097] train: loss: 0.0055851
[Epoch 52; Iter   693/ 1097] train: loss: 0.0406183
[Epoch 52; Iter   723/ 1097] train: loss: 0.0025121
[Epoch 52; Iter   753/ 1097] train: loss: 0.0011628
[Epoch 52; Iter   783/ 1097] train: loss: 0.0041926
[Epoch 52; Iter   813/ 1097] train: loss: 0.0006234
[Epoch 52; Iter   843/ 1097] train: loss: 0.0000824
[Epoch 52; Iter   873/ 1097] train: loss: 0.0006119
[Epoch 52; Iter   903/ 1097] train: loss: 0.0003692
[Epoch 52; Iter   933/ 1097] train: loss: 0.0066228
[Epoch 48; Iter   881/ 1097] train: loss: 0.1025079
[Epoch 48; Iter   911/ 1097] train: loss: 0.0079320
[Epoch 48; Iter   941/ 1097] train: loss: 0.0042967
[Epoch 48; Iter   971/ 1097] train: loss: 0.0116556
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0037083
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0006732
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0007730
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0027250
[Epoch 48] ogbg-molhiv: 0.723043 val loss: 2.609398
[Epoch 48] ogbg-molhiv: 0.659700 test loss: 5.116315
[Epoch 49; Iter    24/ 1097] train: loss: 0.0000763
[Epoch 49; Iter    54/ 1097] train: loss: 0.0011246
[Epoch 49; Iter    84/ 1097] train: loss: 0.0003415
[Epoch 49; Iter   114/ 1097] train: loss: 0.0064653
[Epoch 49; Iter   144/ 1097] train: loss: 0.0006601
[Epoch 49; Iter   174/ 1097] train: loss: 0.0497025
[Epoch 49; Iter   204/ 1097] train: loss: 0.0044842
[Epoch 49; Iter   234/ 1097] train: loss: 0.0032841
[Epoch 49; Iter   264/ 1097] train: loss: 0.0090724
[Epoch 49; Iter   294/ 1097] train: loss: 0.0189386
[Epoch 49; Iter   324/ 1097] train: loss: 0.0029624
[Epoch 49; Iter   354/ 1097] train: loss: 0.0022699
[Epoch 49; Iter   384/ 1097] train: loss: 0.0009437
[Epoch 49; Iter   414/ 1097] train: loss: 0.0103515
[Epoch 49; Iter   444/ 1097] train: loss: 0.0087597
[Epoch 49; Iter   474/ 1097] train: loss: 0.1234006
[Epoch 49; Iter   504/ 1097] train: loss: 0.0002230
[Epoch 49; Iter   534/ 1097] train: loss: 0.0083070
[Epoch 49; Iter   564/ 1097] train: loss: 0.0055023
[Epoch 49; Iter   594/ 1097] train: loss: 0.0002063
[Epoch 49; Iter   624/ 1097] train: loss: 0.0007905
[Epoch 49; Iter   654/ 1097] train: loss: 0.0001297
[Epoch 49; Iter   684/ 1097] train: loss: 0.0001364
[Epoch 49; Iter   714/ 1097] train: loss: 0.0005175
[Epoch 49; Iter   744/ 1097] train: loss: 0.0002801
[Epoch 49; Iter   774/ 1097] train: loss: 0.0000117
[Epoch 49; Iter   804/ 1097] train: loss: 0.0003944
[Epoch 49; Iter   834/ 1097] train: loss: 0.0012431
[Epoch 49; Iter   864/ 1097] train: loss: 0.0022626
[Epoch 49; Iter   894/ 1097] train: loss: 0.0009953
[Epoch 49; Iter   924/ 1097] train: loss: 0.0519651
[Epoch 49; Iter   954/ 1097] train: loss: 0.0034551
[Epoch 49; Iter   984/ 1097] train: loss: 0.0048743
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0000998
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0001005
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0000611
[Epoch 49] ogbg-molhiv: 0.732339 val loss: 1.516463
[Epoch 49] ogbg-molhiv: 0.666745 test loss: 1.833824
[Epoch 50; Iter     7/ 1097] train: loss: 0.0000181
[Epoch 50; Iter    37/ 1097] train: loss: 0.0043623
[Epoch 50; Iter    67/ 1097] train: loss: 0.0005937
[Epoch 50; Iter    97/ 1097] train: loss: 0.0016849
[Epoch 50; Iter   127/ 1097] train: loss: 0.0008797
[Epoch 50; Iter   157/ 1097] train: loss: 0.0004541
[Epoch 50; Iter   187/ 1097] train: loss: 0.0011206
[Epoch 50; Iter   217/ 1097] train: loss: 0.0003665
[Epoch 50; Iter   247/ 1097] train: loss: 0.0002302
[Epoch 50; Iter   277/ 1097] train: loss: 0.0122629
[Epoch 50; Iter   307/ 1097] train: loss: 0.0017615
[Epoch 50; Iter   337/ 1097] train: loss: 0.0025031
[Epoch 50; Iter   367/ 1097] train: loss: 0.0519120
[Epoch 50; Iter   397/ 1097] train: loss: 0.0015673
[Epoch 50; Iter   427/ 1097] train: loss: 0.0003160
[Epoch 50; Iter   457/ 1097] train: loss: 0.0005160
[Epoch 50; Iter   487/ 1097] train: loss: 0.0008410
[Epoch 50; Iter   517/ 1097] train: loss: 0.0001060
[Epoch 50; Iter   547/ 1097] train: loss: 0.0008921
[Epoch 50; Iter   577/ 1097] train: loss: 0.0020580
[Epoch 50; Iter   607/ 1097] train: loss: 0.0013424
[Epoch 50; Iter   637/ 1097] train: loss: 0.0012683
[Epoch 50; Iter   667/ 1097] train: loss: 0.0005392
[Epoch 50; Iter   697/ 1097] train: loss: 0.0005225
[Epoch 50; Iter   727/ 1097] train: loss: 0.0001684
[Epoch 50; Iter   757/ 1097] train: loss: 0.0057751
[Epoch 50; Iter   787/ 1097] train: loss: 0.0000617
[Epoch 50; Iter   817/ 1097] train: loss: 0.0003721
[Epoch 50; Iter   847/ 1097] train: loss: 0.0031521
[Epoch 50; Iter   877/ 1097] train: loss: 0.0076634
[Epoch 50; Iter   907/ 1097] train: loss: 0.0001922
[Epoch 50; Iter   937/ 1097] train: loss: 0.0005961
[Epoch 50; Iter   967/ 1097] train: loss: 0.0011194
[Epoch 50; Iter   997/ 1097] train: loss: 0.0321954
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0021103
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0006529
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0949231
[Epoch 50] ogbg-molhiv: 0.713848 val loss: 0.501936
[Epoch 50] ogbg-molhiv: 0.658412 test loss: 0.917980
[Epoch 51; Iter    20/ 1097] train: loss: 0.0000968
[Epoch 51; Iter    50/ 1097] train: loss: 0.0020482
[Epoch 51; Iter    80/ 1097] train: loss: 0.0005130
[Epoch 51; Iter   110/ 1097] train: loss: 0.0000670
[Epoch 51; Iter   140/ 1097] train: loss: 0.0004356
[Epoch 51; Iter   170/ 1097] train: loss: 0.0002241
[Epoch 51; Iter   200/ 1097] train: loss: 0.0003937
[Epoch 51; Iter   230/ 1097] train: loss: 0.0005846
[Epoch 51; Iter   260/ 1097] train: loss: 0.0004394
[Epoch 51; Iter   290/ 1097] train: loss: 0.0021342
[Epoch 51; Iter   320/ 1097] train: loss: 0.0014513
[Epoch 51; Iter   350/ 1097] train: loss: 0.0001215
[Epoch 51; Iter   380/ 1097] train: loss: 0.0001315
[Epoch 51; Iter   410/ 1097] train: loss: 0.0034781
[Epoch 51; Iter   440/ 1097] train: loss: 0.0002841
[Epoch 51; Iter   470/ 1097] train: loss: 0.0001706
[Epoch 51; Iter   500/ 1097] train: loss: 0.0016964
[Epoch 51; Iter   530/ 1097] train: loss: 0.0021810
[Epoch 51; Iter   560/ 1097] train: loss: 0.0003884
[Epoch 51; Iter   590/ 1097] train: loss: 0.0155521
[Epoch 51; Iter   620/ 1097] train: loss: 0.0184390
[Epoch 51; Iter   650/ 1097] train: loss: 0.0153272
[Epoch 51; Iter   680/ 1097] train: loss: 0.0001865
[Epoch 51; Iter   710/ 1097] train: loss: 0.0010791
[Epoch 51; Iter   740/ 1097] train: loss: 0.0010912
[Epoch 51; Iter   770/ 1097] train: loss: 0.0002293
[Epoch 51; Iter   800/ 1097] train: loss: 0.0000240
[Epoch 51; Iter   830/ 1097] train: loss: 0.0000900
[Epoch 51; Iter   860/ 1097] train: loss: 0.0052359
[Epoch 51; Iter   890/ 1097] train: loss: 0.0007424
[Epoch 51; Iter   920/ 1097] train: loss: 0.0003188
[Epoch 51; Iter   950/ 1097] train: loss: 0.0008663
[Epoch 51; Iter   980/ 1097] train: loss: 0.0001565
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0005958
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0002001
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0013848
[Epoch 51] ogbg-molhiv: 0.719868 val loss: 0.906453
[Epoch 51] ogbg-molhiv: 0.700002 test loss: 1.731352
[Epoch 52; Iter     3/ 1097] train: loss: 0.0117219
[Epoch 52; Iter    33/ 1097] train: loss: 0.0002798
[Epoch 52; Iter    63/ 1097] train: loss: 0.0005998
[Epoch 52; Iter    93/ 1097] train: loss: 0.0018467
[Epoch 52; Iter   123/ 1097] train: loss: 0.0009046
[Epoch 52; Iter   153/ 1097] train: loss: 0.0005994
[Epoch 52; Iter   183/ 1097] train: loss: 0.0004396
[Epoch 52; Iter   213/ 1097] train: loss: 0.0003258
[Epoch 52; Iter   243/ 1097] train: loss: 0.0016934
[Epoch 52; Iter   273/ 1097] train: loss: 0.0002489
[Epoch 52; Iter   303/ 1097] train: loss: 0.0025047
[Epoch 52; Iter   333/ 1097] train: loss: 0.0017700
[Epoch 52; Iter   363/ 1097] train: loss: 0.0217426
[Epoch 52; Iter   393/ 1097] train: loss: 0.0075606
[Epoch 52; Iter   423/ 1097] train: loss: 0.0014374
[Epoch 52; Iter   453/ 1097] train: loss: 0.0000800
[Epoch 52; Iter   483/ 1097] train: loss: 0.0001445
[Epoch 52; Iter   513/ 1097] train: loss: 0.0023688
[Epoch 52; Iter   543/ 1097] train: loss: 0.0003046
[Epoch 52; Iter   573/ 1097] train: loss: 0.0002438
[Epoch 52; Iter   603/ 1097] train: loss: 0.0033768
[Epoch 52; Iter   633/ 1097] train: loss: 0.0029307
[Epoch 52; Iter   663/ 1097] train: loss: 0.0009697
[Epoch 52; Iter   693/ 1097] train: loss: 0.0007102
[Epoch 52; Iter   723/ 1097] train: loss: 0.0068549
[Epoch 52; Iter   753/ 1097] train: loss: 0.0014836
[Epoch 52; Iter   783/ 1097] train: loss: 0.0073245
[Epoch 52; Iter   813/ 1097] train: loss: 0.0001338
[Epoch 52; Iter   843/ 1097] train: loss: 0.0002215
[Epoch 52; Iter   873/ 1097] train: loss: 0.0003000
[Epoch 52; Iter   903/ 1097] train: loss: 0.0000377
[Epoch 52; Iter   933/ 1097] train: loss: 0.0002741
[Epoch 40; Iter   717/ 1097] train: loss: 0.0179826
[Epoch 40; Iter   747/ 1097] train: loss: 0.0373634
[Epoch 40; Iter   777/ 1097] train: loss: 0.2208147
[Epoch 40; Iter   807/ 1097] train: loss: 0.0345381
[Epoch 40; Iter   837/ 1097] train: loss: 0.0287909
[Epoch 40; Iter   867/ 1097] train: loss: 0.1462679
[Epoch 40; Iter   897/ 1097] train: loss: 0.0371382
[Epoch 40; Iter   927/ 1097] train: loss: 0.1765155
[Epoch 40; Iter   957/ 1097] train: loss: 0.0490396
[Epoch 40; Iter   987/ 1097] train: loss: 0.0294891
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0767360
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0484667
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0584284
[Epoch 40] ogbg-molhiv: 0.794312 val loss: 0.081567
[Epoch 40] ogbg-molhiv: 0.755945 test loss: 0.123892
[Epoch 41; Iter    10/ 1097] train: loss: 0.1520890
[Epoch 41; Iter    40/ 1097] train: loss: 0.3187445
[Epoch 41; Iter    70/ 1097] train: loss: 0.0318326
[Epoch 41; Iter   100/ 1097] train: loss: 0.0155026
[Epoch 41; Iter   130/ 1097] train: loss: 0.0838684
[Epoch 41; Iter   160/ 1097] train: loss: 0.0285623
[Epoch 41; Iter   190/ 1097] train: loss: 0.2288283
[Epoch 41; Iter   220/ 1097] train: loss: 0.1974891
[Epoch 41; Iter   250/ 1097] train: loss: 0.0653094
[Epoch 41; Iter   280/ 1097] train: loss: 0.0739906
[Epoch 41; Iter   310/ 1097] train: loss: 0.1567525
[Epoch 41; Iter   340/ 1097] train: loss: 0.0155808
[Epoch 41; Iter   370/ 1097] train: loss: 0.2949490
[Epoch 41; Iter   400/ 1097] train: loss: 0.0649880
[Epoch 41; Iter   430/ 1097] train: loss: 0.0704670
[Epoch 41; Iter   460/ 1097] train: loss: 0.1292473
[Epoch 41; Iter   490/ 1097] train: loss: 0.4987895
[Epoch 41; Iter   520/ 1097] train: loss: 0.0307870
[Epoch 41; Iter   550/ 1097] train: loss: 0.0405550
[Epoch 41; Iter   580/ 1097] train: loss: 0.0927147
[Epoch 41; Iter   610/ 1097] train: loss: 0.1217094
[Epoch 41; Iter   640/ 1097] train: loss: 0.0251757
[Epoch 41; Iter   670/ 1097] train: loss: 0.0482392
[Epoch 41; Iter   700/ 1097] train: loss: 0.1420401
[Epoch 41; Iter   730/ 1097] train: loss: 0.0095079
[Epoch 41; Iter   760/ 1097] train: loss: 0.1281936
[Epoch 41; Iter   790/ 1097] train: loss: 0.1020823
[Epoch 41; Iter   820/ 1097] train: loss: 0.0419125
[Epoch 41; Iter   850/ 1097] train: loss: 0.0179276
[Epoch 41; Iter   880/ 1097] train: loss: 0.0268082
[Epoch 41; Iter   910/ 1097] train: loss: 0.1494210
[Epoch 41; Iter   940/ 1097] train: loss: 0.0249458
[Epoch 41; Iter   970/ 1097] train: loss: 0.1562842
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2218004
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0552260
[Epoch 41; Iter  1060/ 1097] train: loss: 0.1748153
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1233206
[Epoch 41] ogbg-molhiv: 0.809518 val loss: 0.080323
[Epoch 41] ogbg-molhiv: 0.742245 test loss: 0.134570
[Epoch 42; Iter    23/ 1097] train: loss: 0.0297776
[Epoch 42; Iter    53/ 1097] train: loss: 0.1161657
[Epoch 42; Iter    83/ 1097] train: loss: 0.1054099
[Epoch 42; Iter   113/ 1097] train: loss: 0.0583852
[Epoch 42; Iter   143/ 1097] train: loss: 0.1302894
[Epoch 42; Iter   173/ 1097] train: loss: 0.0212271
[Epoch 42; Iter   203/ 1097] train: loss: 0.0573354
[Epoch 42; Iter   233/ 1097] train: loss: 0.0334332
[Epoch 42; Iter   263/ 1097] train: loss: 0.0491230
[Epoch 42; Iter   293/ 1097] train: loss: 0.0567307
[Epoch 42; Iter   323/ 1097] train: loss: 0.0797623
[Epoch 42; Iter   353/ 1097] train: loss: 0.0162909
[Epoch 42; Iter   383/ 1097] train: loss: 0.1161632
[Epoch 42; Iter   413/ 1097] train: loss: 0.2139955
[Epoch 42; Iter   443/ 1097] train: loss: 0.0259288
[Epoch 42; Iter   473/ 1097] train: loss: 0.1476386
[Epoch 42; Iter   503/ 1097] train: loss: 0.0986449
[Epoch 42; Iter   533/ 1097] train: loss: 0.0280773
[Epoch 42; Iter   563/ 1097] train: loss: 0.0728286
[Epoch 42; Iter   593/ 1097] train: loss: 0.0239749
[Epoch 42; Iter   623/ 1097] train: loss: 0.0305900
[Epoch 42; Iter   653/ 1097] train: loss: 0.2355943
[Epoch 42; Iter   683/ 1097] train: loss: 0.0325629
[Epoch 42; Iter   713/ 1097] train: loss: 0.0665282
[Epoch 42; Iter   743/ 1097] train: loss: 0.0574248
[Epoch 42; Iter   773/ 1097] train: loss: 0.0556636
[Epoch 42; Iter   803/ 1097] train: loss: 0.0236860
[Epoch 42; Iter   833/ 1097] train: loss: 0.0385979
[Epoch 42; Iter   863/ 1097] train: loss: 0.0261490
[Epoch 42; Iter   893/ 1097] train: loss: 0.0593259
[Epoch 42; Iter   923/ 1097] train: loss: 0.1356063
[Epoch 42; Iter   953/ 1097] train: loss: 0.0233388
[Epoch 42; Iter   983/ 1097] train: loss: 0.0127687
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1531448
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1671816
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0831929
[Epoch 42] ogbg-molhiv: 0.795084 val loss: 0.084458
[Epoch 42] ogbg-molhiv: 0.740478 test loss: 0.140035
[Epoch 43; Iter     6/ 1097] train: loss: 0.1411350
[Epoch 43; Iter    36/ 1097] train: loss: 0.0284712
[Epoch 43; Iter    66/ 1097] train: loss: 0.3235420
[Epoch 43; Iter    96/ 1097] train: loss: 0.0357756
[Epoch 43; Iter   126/ 1097] train: loss: 0.1576814
[Epoch 43; Iter   156/ 1097] train: loss: 0.2903256
[Epoch 43; Iter   186/ 1097] train: loss: 0.1360969
[Epoch 43; Iter   216/ 1097] train: loss: 0.1134779
[Epoch 43; Iter   246/ 1097] train: loss: 0.0906036
[Epoch 43; Iter   276/ 1097] train: loss: 0.3524557
[Epoch 43; Iter   306/ 1097] train: loss: 0.0262511
[Epoch 43; Iter   336/ 1097] train: loss: 0.2842358
[Epoch 43; Iter   366/ 1097] train: loss: 0.0320238
[Epoch 43; Iter   396/ 1097] train: loss: 0.0212415
[Epoch 43; Iter   426/ 1097] train: loss: 0.1272228
[Epoch 43; Iter   456/ 1097] train: loss: 0.1773448
[Epoch 43; Iter   486/ 1097] train: loss: 0.1049647
[Epoch 43; Iter   516/ 1097] train: loss: 0.0587330
[Epoch 43; Iter   546/ 1097] train: loss: 0.0622177
[Epoch 43; Iter   576/ 1097] train: loss: 0.3614439
[Epoch 43; Iter   606/ 1097] train: loss: 0.0364053
[Epoch 43; Iter   636/ 1097] train: loss: 0.1009370
[Epoch 43; Iter   666/ 1097] train: loss: 0.0590857
[Epoch 43; Iter   696/ 1097] train: loss: 0.2142076
[Epoch 43; Iter   726/ 1097] train: loss: 0.0193018
[Epoch 43; Iter   756/ 1097] train: loss: 0.0950589
[Epoch 43; Iter   786/ 1097] train: loss: 0.0140156
[Epoch 43; Iter   816/ 1097] train: loss: 0.0236372
[Epoch 43; Iter   846/ 1097] train: loss: 0.1091077
[Epoch 43; Iter   876/ 1097] train: loss: 0.1453847
[Epoch 43; Iter   906/ 1097] train: loss: 0.1126375
[Epoch 43; Iter   936/ 1097] train: loss: 0.0273423
[Epoch 43; Iter   966/ 1097] train: loss: 0.0379336
[Epoch 43; Iter   996/ 1097] train: loss: 0.1160784
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0160725
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1318081
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0105187
[Epoch 43] ogbg-molhiv: 0.794784 val loss: 0.083718
[Epoch 43] ogbg-molhiv: 0.738940 test loss: 0.134478
[Epoch 44; Iter    19/ 1097] train: loss: 0.0441390
[Epoch 44; Iter    49/ 1097] train: loss: 0.0197533
[Epoch 44; Iter    79/ 1097] train: loss: 0.0629959
[Epoch 44; Iter   109/ 1097] train: loss: 0.0974095
[Epoch 44; Iter   139/ 1097] train: loss: 0.0228449
[Epoch 44; Iter   169/ 1097] train: loss: 0.1190960
[Epoch 44; Iter   199/ 1097] train: loss: 0.0079587
[Epoch 44; Iter   229/ 1097] train: loss: 0.0867713
[Epoch 44; Iter   259/ 1097] train: loss: 0.0576736
[Epoch 44; Iter   289/ 1097] train: loss: 0.0303415
[Epoch 44; Iter   319/ 1097] train: loss: 0.0207454
[Epoch 44; Iter   349/ 1097] train: loss: 0.1359484
[Epoch 44; Iter   379/ 1097] train: loss: 0.0262734
[Epoch 44; Iter   409/ 1097] train: loss: 0.0597478
[Epoch 44; Iter   439/ 1097] train: loss: 0.0242684
[Epoch 44; Iter   469/ 1097] train: loss: 0.2259989
[Epoch 44; Iter   499/ 1097] train: loss: 0.1780837
[Epoch 44; Iter   529/ 1097] train: loss: 0.1165037
[Epoch 44; Iter   559/ 1097] train: loss: 0.1014458
[Epoch 44; Iter   589/ 1097] train: loss: 0.1101074
[Epoch 44; Iter   619/ 1097] train: loss: 0.0269199
[Epoch 44; Iter   649/ 1097] train: loss: 0.0224416
[Epoch 44; Iter   679/ 1097] train: loss: 0.2669498
[Epoch 44; Iter   709/ 1097] train: loss: 0.0139090
[Epoch 44; Iter   739/ 1097] train: loss: 0.0331217
[Epoch 44; Iter   769/ 1097] train: loss: 0.1039118
[Epoch 48; Iter   881/ 1097] train: loss: 0.0351942
[Epoch 48; Iter   911/ 1097] train: loss: 0.0016708
[Epoch 48; Iter   941/ 1097] train: loss: 0.0129876
[Epoch 48; Iter   971/ 1097] train: loss: 0.0003471
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0007211
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0001744
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0006919
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0014812
[Epoch 48] ogbg-molhiv: 0.710786 val loss: 5.193261
[Epoch 48] ogbg-molhiv: 0.597449 test loss: 3.392855
[Epoch 49; Iter    24/ 1097] train: loss: 0.0008822
[Epoch 49; Iter    54/ 1097] train: loss: 0.0010382
[Epoch 49; Iter    84/ 1097] train: loss: 0.0007410
[Epoch 49; Iter   114/ 1097] train: loss: 0.0012732
[Epoch 49; Iter   144/ 1097] train: loss: 0.0009384
[Epoch 49; Iter   174/ 1097] train: loss: 0.0004608
[Epoch 49; Iter   204/ 1097] train: loss: 0.0013644
[Epoch 49; Iter   234/ 1097] train: loss: 0.0058519
[Epoch 49; Iter   264/ 1097] train: loss: 0.0057839
[Epoch 49; Iter   294/ 1097] train: loss: 0.0001232
[Epoch 49; Iter   324/ 1097] train: loss: 0.0045477
[Epoch 49; Iter   354/ 1097] train: loss: 0.0110253
[Epoch 49; Iter   384/ 1097] train: loss: 0.0782968
[Epoch 49; Iter   414/ 1097] train: loss: 0.0015388
[Epoch 49; Iter   444/ 1097] train: loss: 0.0091022
[Epoch 49; Iter   474/ 1097] train: loss: 0.0029966
[Epoch 49; Iter   504/ 1097] train: loss: 0.0007421
[Epoch 49; Iter   534/ 1097] train: loss: 0.0018341
[Epoch 49; Iter   564/ 1097] train: loss: 0.0659769
[Epoch 49; Iter   594/ 1097] train: loss: 0.0037778
[Epoch 49; Iter   624/ 1097] train: loss: 0.0005610
[Epoch 49; Iter   654/ 1097] train: loss: 0.0126734
[Epoch 49; Iter   684/ 1097] train: loss: 0.0007313
[Epoch 49; Iter   714/ 1097] train: loss: 0.0002333
[Epoch 49; Iter   744/ 1097] train: loss: 0.0069578
[Epoch 49; Iter   774/ 1097] train: loss: 0.0055699
[Epoch 49; Iter   804/ 1097] train: loss: 0.0095009
[Epoch 49; Iter   834/ 1097] train: loss: 0.0025020
[Epoch 49; Iter   864/ 1097] train: loss: 0.0041192
[Epoch 49; Iter   894/ 1097] train: loss: 0.0005527
[Epoch 49; Iter   924/ 1097] train: loss: 0.0037550
[Epoch 49; Iter   954/ 1097] train: loss: 0.0092213
[Epoch 49; Iter   984/ 1097] train: loss: 0.0293799
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0011789
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0034215
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0010689
[Epoch 49] ogbg-molhiv: 0.709518 val loss: 10.674890
[Epoch 49] ogbg-molhiv: 0.594637 test loss: 7.935972
[Epoch 50; Iter     7/ 1097] train: loss: 0.1040971
[Epoch 50; Iter    37/ 1097] train: loss: 0.0000727
[Epoch 50; Iter    67/ 1097] train: loss: 0.0002085
[Epoch 50; Iter    97/ 1097] train: loss: 0.0001833
[Epoch 50; Iter   127/ 1097] train: loss: 0.0033425
[Epoch 50; Iter   157/ 1097] train: loss: 0.0013405
[Epoch 50; Iter   187/ 1097] train: loss: 0.0841381
[Epoch 50; Iter   217/ 1097] train: loss: 0.0223703
[Epoch 50; Iter   247/ 1097] train: loss: 0.0090895
[Epoch 50; Iter   277/ 1097] train: loss: 0.0075616
[Epoch 50; Iter   307/ 1097] train: loss: 0.0002328
[Epoch 50; Iter   337/ 1097] train: loss: 0.0050566
[Epoch 50; Iter   367/ 1097] train: loss: 0.0024122
[Epoch 50; Iter   397/ 1097] train: loss: 0.0131346
[Epoch 50; Iter   427/ 1097] train: loss: 0.0679532
[Epoch 50; Iter   457/ 1097] train: loss: 0.0021391
[Epoch 50; Iter   487/ 1097] train: loss: 0.0016776
[Epoch 50; Iter   517/ 1097] train: loss: 0.0174244
[Epoch 50; Iter   547/ 1097] train: loss: 0.0137358
[Epoch 50; Iter   577/ 1097] train: loss: 0.0037227
[Epoch 50; Iter   607/ 1097] train: loss: 0.0018399
[Epoch 50; Iter   637/ 1097] train: loss: 0.0006366
[Epoch 50; Iter   667/ 1097] train: loss: 0.0027376
[Epoch 50; Iter   697/ 1097] train: loss: 0.0137192
[Epoch 50; Iter   727/ 1097] train: loss: 0.0136752
[Epoch 50; Iter   757/ 1097] train: loss: 0.0002304
[Epoch 50; Iter   787/ 1097] train: loss: 0.0008290
[Epoch 50; Iter   817/ 1097] train: loss: 0.0055502
[Epoch 50; Iter   847/ 1097] train: loss: 0.0316673
[Epoch 50; Iter   877/ 1097] train: loss: 0.0846144
[Epoch 50; Iter   907/ 1097] train: loss: 0.0083099
[Epoch 50; Iter   937/ 1097] train: loss: 0.0324227
[Epoch 50; Iter   967/ 1097] train: loss: 0.0001658
[Epoch 50; Iter   997/ 1097] train: loss: 0.0035777
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0006238
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0021095
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0075640
[Epoch 50] ogbg-molhiv: 0.700045 val loss: 5.512894
[Epoch 50] ogbg-molhiv: 0.568242 test loss: 4.838530
[Epoch 51; Iter    20/ 1097] train: loss: 0.0181168
[Epoch 51; Iter    50/ 1097] train: loss: 0.0004433
[Epoch 51; Iter    80/ 1097] train: loss: 0.0178798
[Epoch 51; Iter   110/ 1097] train: loss: 0.0151752
[Epoch 51; Iter   140/ 1097] train: loss: 0.0005619
[Epoch 51; Iter   170/ 1097] train: loss: 0.0008626
[Epoch 51; Iter   200/ 1097] train: loss: 0.0043203
[Epoch 51; Iter   230/ 1097] train: loss: 0.0023711
[Epoch 51; Iter   260/ 1097] train: loss: 0.0065970
[Epoch 51; Iter   290/ 1097] train: loss: 0.0009212
[Epoch 51; Iter   320/ 1097] train: loss: 0.0026909
[Epoch 51; Iter   350/ 1097] train: loss: 0.0005266
[Epoch 51; Iter   380/ 1097] train: loss: 0.0001684
[Epoch 51; Iter   410/ 1097] train: loss: 0.0010380
[Epoch 51; Iter   440/ 1097] train: loss: 0.0072457
[Epoch 51; Iter   470/ 1097] train: loss: 0.0410080
[Epoch 51; Iter   500/ 1097] train: loss: 0.0002544
[Epoch 51; Iter   530/ 1097] train: loss: 0.0000946
[Epoch 51; Iter   560/ 1097] train: loss: 0.0024139
[Epoch 51; Iter   590/ 1097] train: loss: 0.0037745
[Epoch 51; Iter   620/ 1097] train: loss: 0.0003507
[Epoch 51; Iter   650/ 1097] train: loss: 0.0012003
[Epoch 51; Iter   680/ 1097] train: loss: 0.0011093
[Epoch 51; Iter   710/ 1097] train: loss: 0.0201959
[Epoch 51; Iter   740/ 1097] train: loss: 0.0141416
[Epoch 51; Iter   770/ 1097] train: loss: 0.0143007
[Epoch 51; Iter   800/ 1097] train: loss: 0.0439522
[Epoch 51; Iter   830/ 1097] train: loss: 0.0036872
[Epoch 51; Iter   860/ 1097] train: loss: 0.0005853
[Epoch 51; Iter   890/ 1097] train: loss: 0.0003996
[Epoch 51; Iter   920/ 1097] train: loss: 0.0089490
[Epoch 51; Iter   950/ 1097] train: loss: 0.0029112
[Epoch 51; Iter   980/ 1097] train: loss: 0.0083420
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0083085
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0001167
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0020659
[Epoch 51] ogbg-molhiv: 0.709093 val loss: 3.663715
[Epoch 51] ogbg-molhiv: 0.595691 test loss: 3.193329
[Epoch 52; Iter     3/ 1097] train: loss: 0.0003442
[Epoch 52; Iter    33/ 1097] train: loss: 0.0019441
[Epoch 52; Iter    63/ 1097] train: loss: 0.0008397
[Epoch 52; Iter    93/ 1097] train: loss: 0.0045075
[Epoch 52; Iter   123/ 1097] train: loss: 0.0037998
[Epoch 52; Iter   153/ 1097] train: loss: 0.0002989
[Epoch 52; Iter   183/ 1097] train: loss: 0.0001502
[Epoch 52; Iter   213/ 1097] train: loss: 0.0007505
[Epoch 52; Iter   243/ 1097] train: loss: 0.0010311
[Epoch 52; Iter   273/ 1097] train: loss: 0.0103341
[Epoch 52; Iter   303/ 1097] train: loss: 0.0018382
[Epoch 52; Iter   333/ 1097] train: loss: 0.0002448
[Epoch 52; Iter   363/ 1097] train: loss: 0.0263684
[Epoch 52; Iter   393/ 1097] train: loss: 0.0011550
[Epoch 52; Iter   423/ 1097] train: loss: 0.0020761
[Epoch 52; Iter   453/ 1097] train: loss: 0.0044127
[Epoch 52; Iter   483/ 1097] train: loss: 0.0174069
[Epoch 52; Iter   513/ 1097] train: loss: 0.0043017
[Epoch 52; Iter   543/ 1097] train: loss: 0.0073987
[Epoch 52; Iter   573/ 1097] train: loss: 0.0002917
[Epoch 52; Iter   603/ 1097] train: loss: 0.0015778
[Epoch 52; Iter   633/ 1097] train: loss: 0.1718742
[Epoch 52; Iter   663/ 1097] train: loss: 0.0429859
[Epoch 52; Iter   693/ 1097] train: loss: 0.0056554
[Epoch 52; Iter   723/ 1097] train: loss: 0.0032776
[Epoch 52; Iter   753/ 1097] train: loss: 0.0004077
[Epoch 52; Iter   783/ 1097] train: loss: 0.0031213
[Epoch 52; Iter   813/ 1097] train: loss: 0.0134466
[Epoch 52; Iter   843/ 1097] train: loss: 0.0007052
[Epoch 52; Iter   873/ 1097] train: loss: 0.0006587
[Epoch 52; Iter   903/ 1097] train: loss: 0.0010111
[Epoch 52; Iter   933/ 1097] train: loss: 0.0032215
[Epoch 40; Iter   717/ 1097] train: loss: 0.1475891
[Epoch 40; Iter   747/ 1097] train: loss: 0.0472940
[Epoch 40; Iter   777/ 1097] train: loss: 0.0070625
[Epoch 40; Iter   807/ 1097] train: loss: 0.0405216
[Epoch 40; Iter   837/ 1097] train: loss: 0.0129339
[Epoch 40; Iter   867/ 1097] train: loss: 0.1259705
[Epoch 40; Iter   897/ 1097] train: loss: 0.0129485
[Epoch 40; Iter   927/ 1097] train: loss: 0.1578562
[Epoch 40; Iter   957/ 1097] train: loss: 0.2113395
[Epoch 40; Iter   987/ 1097] train: loss: 0.0394442
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0681942
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0133964
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0246402
[Epoch 40] ogbg-molhiv: 0.810889 val loss: 0.078770
[Epoch 40] ogbg-molhiv: 0.751770 test loss: 0.328874
[Epoch 41; Iter    10/ 1097] train: loss: 0.1014234
[Epoch 41; Iter    40/ 1097] train: loss: 0.0090807
[Epoch 41; Iter    70/ 1097] train: loss: 0.0208239
[Epoch 41; Iter   100/ 1097] train: loss: 0.0185642
[Epoch 41; Iter   130/ 1097] train: loss: 0.0647152
[Epoch 41; Iter   160/ 1097] train: loss: 0.0446481
[Epoch 41; Iter   190/ 1097] train: loss: 0.0154048
[Epoch 41; Iter   220/ 1097] train: loss: 0.0095591
[Epoch 41; Iter   250/ 1097] train: loss: 0.0127335
[Epoch 41; Iter   280/ 1097] train: loss: 0.0782205
[Epoch 41; Iter   310/ 1097] train: loss: 0.2242315
[Epoch 41; Iter   340/ 1097] train: loss: 0.1105188
[Epoch 41; Iter   370/ 1097] train: loss: 0.0090794
[Epoch 41; Iter   400/ 1097] train: loss: 0.0098756
[Epoch 41; Iter   430/ 1097] train: loss: 0.0126791
[Epoch 41; Iter   460/ 1097] train: loss: 0.0885290
[Epoch 41; Iter   490/ 1097] train: loss: 0.2381130
[Epoch 41; Iter   520/ 1097] train: loss: 0.0546755
[Epoch 41; Iter   550/ 1097] train: loss: 0.0262190
[Epoch 41; Iter   580/ 1097] train: loss: 0.1226511
[Epoch 41; Iter   610/ 1097] train: loss: 0.0221264
[Epoch 41; Iter   640/ 1097] train: loss: 0.1934514
[Epoch 41; Iter   670/ 1097] train: loss: 0.0444031
[Epoch 41; Iter   700/ 1097] train: loss: 0.0169454
[Epoch 41; Iter   730/ 1097] train: loss: 0.0199128
[Epoch 41; Iter   760/ 1097] train: loss: 0.0530698
[Epoch 41; Iter   790/ 1097] train: loss: 0.0787781
[Epoch 41; Iter   820/ 1097] train: loss: 0.0781397
[Epoch 41; Iter   850/ 1097] train: loss: 0.0141175
[Epoch 41; Iter   880/ 1097] train: loss: 0.0296233
[Epoch 41; Iter   910/ 1097] train: loss: 0.0247993
[Epoch 41; Iter   940/ 1097] train: loss: 0.0094966
[Epoch 41; Iter   970/ 1097] train: loss: 0.0973528
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0410392
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1295675
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0939906
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0874013
[Epoch 41] ogbg-molhiv: 0.806860 val loss: 0.081325
[Epoch 41] ogbg-molhiv: 0.773711 test loss: 0.570706
[Epoch 42; Iter    23/ 1097] train: loss: 0.0360139
[Epoch 42; Iter    53/ 1097] train: loss: 0.0502208
[Epoch 42; Iter    83/ 1097] train: loss: 0.0218849
[Epoch 42; Iter   113/ 1097] train: loss: 0.0164125
[Epoch 42; Iter   143/ 1097] train: loss: 0.0156234
[Epoch 42; Iter   173/ 1097] train: loss: 0.0465549
[Epoch 42; Iter   203/ 1097] train: loss: 0.1677294
[Epoch 42; Iter   233/ 1097] train: loss: 0.0994692
[Epoch 42; Iter   263/ 1097] train: loss: 0.1941619
[Epoch 42; Iter   293/ 1097] train: loss: 0.1093255
[Epoch 42; Iter   323/ 1097] train: loss: 0.0225104
[Epoch 42; Iter   353/ 1097] train: loss: 0.0409978
[Epoch 42; Iter   383/ 1097] train: loss: 0.1249191
[Epoch 42; Iter   413/ 1097] train: loss: 0.0242776
[Epoch 42; Iter   443/ 1097] train: loss: 0.2239212
[Epoch 42; Iter   473/ 1097] train: loss: 0.0356414
[Epoch 42; Iter   503/ 1097] train: loss: 0.0840710
[Epoch 42; Iter   533/ 1097] train: loss: 0.0835542
[Epoch 42; Iter   563/ 1097] train: loss: 0.0333104
[Epoch 42; Iter   593/ 1097] train: loss: 0.0303451
[Epoch 42; Iter   623/ 1097] train: loss: 0.0258284
[Epoch 42; Iter   653/ 1097] train: loss: 0.2053165
[Epoch 42; Iter   683/ 1097] train: loss: 0.2095761
[Epoch 42; Iter   713/ 1097] train: loss: 0.0083862
[Epoch 42; Iter   743/ 1097] train: loss: 0.1378704
[Epoch 42; Iter   773/ 1097] train: loss: 0.3026192
[Epoch 42; Iter   803/ 1097] train: loss: 0.2372197
[Epoch 42; Iter   833/ 1097] train: loss: 0.0184717
[Epoch 42; Iter   863/ 1097] train: loss: 0.1135671
[Epoch 42; Iter   893/ 1097] train: loss: 0.1069573
[Epoch 42; Iter   923/ 1097] train: loss: 0.0220168
[Epoch 42; Iter   953/ 1097] train: loss: 0.1514161
[Epoch 42; Iter   983/ 1097] train: loss: 0.0209397
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1425965
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1532590
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0248018
[Epoch 42] ogbg-molhiv: 0.817959 val loss: 0.083838
[Epoch 42] ogbg-molhiv: 0.770341 test loss: 0.487466
[Epoch 43; Iter     6/ 1097] train: loss: 0.0622464
[Epoch 43; Iter    36/ 1097] train: loss: 0.0682503
[Epoch 43; Iter    66/ 1097] train: loss: 0.1465969
[Epoch 43; Iter    96/ 1097] train: loss: 0.1696530
[Epoch 43; Iter   126/ 1097] train: loss: 0.0382664
[Epoch 43; Iter   156/ 1097] train: loss: 0.0220362
[Epoch 43; Iter   186/ 1097] train: loss: 0.2204294
[Epoch 43; Iter   216/ 1097] train: loss: 0.1716877
[Epoch 43; Iter   246/ 1097] train: loss: 0.1875116
[Epoch 43; Iter   276/ 1097] train: loss: 0.0207666
[Epoch 43; Iter   306/ 1097] train: loss: 0.0209318
[Epoch 43; Iter   336/ 1097] train: loss: 0.0164403
[Epoch 43; Iter   366/ 1097] train: loss: 0.0094115
[Epoch 43; Iter   396/ 1097] train: loss: 0.1834781
[Epoch 43; Iter   426/ 1097] train: loss: 0.0362430
[Epoch 43; Iter   456/ 1097] train: loss: 0.0365771
[Epoch 43; Iter   486/ 1097] train: loss: 0.0155321
[Epoch 43; Iter   516/ 1097] train: loss: 0.0227236
[Epoch 43; Iter   546/ 1097] train: loss: 0.0098593
[Epoch 43; Iter   576/ 1097] train: loss: 0.0648083
[Epoch 43; Iter   606/ 1097] train: loss: 0.1006159
[Epoch 43; Iter   636/ 1097] train: loss: 0.0086566
[Epoch 43; Iter   666/ 1097] train: loss: 0.0548289
[Epoch 43; Iter   696/ 1097] train: loss: 0.0382973
[Epoch 43; Iter   726/ 1097] train: loss: 0.0440454
[Epoch 43; Iter   756/ 1097] train: loss: 0.2210917
[Epoch 43; Iter   786/ 1097] train: loss: 0.1115110
[Epoch 43; Iter   816/ 1097] train: loss: 0.0192258
[Epoch 43; Iter   846/ 1097] train: loss: 0.0357160
[Epoch 43; Iter   876/ 1097] train: loss: 0.0814311
[Epoch 43; Iter   906/ 1097] train: loss: 0.1107718
[Epoch 43; Iter   936/ 1097] train: loss: 0.0298486
[Epoch 43; Iter   966/ 1097] train: loss: 0.0214501
[Epoch 43; Iter   996/ 1097] train: loss: 0.0076245
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0126735
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1855614
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0123007
[Epoch 43] ogbg-molhiv: 0.789444 val loss: 0.382700
[Epoch 43] ogbg-molhiv: 0.727248 test loss: 0.615688
[Epoch 44; Iter    19/ 1097] train: loss: 0.0391602
[Epoch 44; Iter    49/ 1097] train: loss: 0.0074412
[Epoch 44; Iter    79/ 1097] train: loss: 0.0985170
[Epoch 44; Iter   109/ 1097] train: loss: 0.0211397
[Epoch 44; Iter   139/ 1097] train: loss: 0.0165474
[Epoch 44; Iter   169/ 1097] train: loss: 0.0112665
[Epoch 44; Iter   199/ 1097] train: loss: 0.0410511
[Epoch 44; Iter   229/ 1097] train: loss: 0.0114880
[Epoch 44; Iter   259/ 1097] train: loss: 0.0111235
[Epoch 44; Iter   289/ 1097] train: loss: 0.0046752
[Epoch 44; Iter   319/ 1097] train: loss: 0.2136616
[Epoch 44; Iter   349/ 1097] train: loss: 0.1355219
[Epoch 44; Iter   379/ 1097] train: loss: 0.0190590
[Epoch 44; Iter   409/ 1097] train: loss: 0.1759839
[Epoch 44; Iter   439/ 1097] train: loss: 0.0075202
[Epoch 44; Iter   469/ 1097] train: loss: 0.1378566
[Epoch 44; Iter   499/ 1097] train: loss: 0.0641139
[Epoch 44; Iter   529/ 1097] train: loss: 0.0849106
[Epoch 44; Iter   559/ 1097] train: loss: 0.0426882
[Epoch 44; Iter   589/ 1097] train: loss: 0.0362524
[Epoch 44; Iter   619/ 1097] train: loss: 0.0122656
[Epoch 44; Iter   649/ 1097] train: loss: 0.0607166
[Epoch 44; Iter   679/ 1097] train: loss: 0.1515624
[Epoch 44; Iter   709/ 1097] train: loss: 0.1717832
[Epoch 44; Iter   739/ 1097] train: loss: 0.0376855
[Epoch 44; Iter   769/ 1097] train: loss: 0.0368094
